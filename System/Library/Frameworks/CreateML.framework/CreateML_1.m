uint64_t lazy protocol witness table accessor for type [String] and conformance <A> [A](unint64_t *a1, uint64_t *a2)
{
  uint64_t result;

  result = *a1;
  if (!result)
  {
    __swift_instantiateConcreteTypeFromMangledNameAbstract(a2);
    result = swift_getWitnessTable();
    atomic_store(result, a1);
  }
  return result;
}

ValueMetadata *type metadata accessor for _MetricUtilities()
{
  return &type metadata for _MetricUtilities;
}

BOOL OUTLINED_FUNCTION_1_17@<W0>(unint64_t a1@<X8>)
{
  return a1 > 1;
}

__n128 OUTLINED_FUNCTION_4_13(__n128 *a1)
{
  __n128 result = v1[12];
  a1[1] = result;
  return result;
}

uint64_t OUTLINED_FUNCTION_6_11()
{
  return _stringCompareWithSmolCheck(_:_:expecting:)();
}

uint64_t OUTLINED_FUNCTION_9_8()
{
  return swift_allocObject();
}

void OUTLINED_FUNCTION_10_8()
{
  uint64_t v1 = 0x20746F6E206F6420;
  unint64_t v2 = 0xED0000686374616DLL;
  String.append(_:)(*(Swift::String *)&v1);
}

uint64_t OUTLINED_FUNCTION_11_8()
{
  return 0;
}

uint64_t OUTLINED_FUNCTION_13_7@<X0>(uint64_t result@<X0>, uint64_t a2@<X8>)
{
  *(void *)(result + 64) = a2;
  *(void *)(result + 32) = *(void *)(v2 + 184);
  return result;
}

uint64_t OUTLINED_FUNCTION_15_8()
{
  return dispatch thunk of CustomStringConvertible.description.getter();
}

uint64_t OUTLINED_FUNCTION_17_8()
{
  return _assertionFailure(_:_:file:line:flags:)();
}

void OUTLINED_FUNCTION_19_7()
{
  char v2 = *(unsigned char *)(v0 - 112);
  *(void *)(v0 - 120) = *(void *)(v0 - 120);
  *(unsigned char *)(v0 - 112) = v2;
  MLDataTable.append(contentsOf:)();
}

id OUTLINED_FUNCTION_21_7()
{
  return outlined copy of Result<_DataTable, Error>(v1, v0);
}

uint64_t OUTLINED_FUNCTION_26_6()
{
  return Tensor.scalar<A>(as:)();
}

void OUTLINED_FUNCTION_30_6(uint64_t a1@<X8>)
{
  MLDataTable.subscript.getter(0x7373616C63, (void *)0xE500000000000000, a1);
}

BOOL OUTLINED_FUNCTION_32_5@<W0>(unint64_t a1@<X8>)
{
  return a1 > 1;
}

void OUTLINED_FUNCTION_34_4()
{
  _sSTsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFs12Zip2SequenceVySaySdGAHG_Sds5NeverOTg5022_sS3dIegyyd_Sd_SdtSds5f68OIegnrzr_TR059_s8CreateML16_MetricUtilitiesV4rmse6target10predictionJ35SayH19G_AGtFZS2d_Sdtcfu0_Tf3nnnpf_nTf1cn_nTm(v0, v1);
}

void OUTLINED_FUNCTION_37_3()
{
  specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
}

__n128 OUTLINED_FUNCTION_38_4(__n128 *a1)
{
  __n128 result = v1[12];
  a1[1] = result;
  a1[3].n128_u64[1] = v2;
  return result;
}

uint64_t _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lF11TabularData0D5FrameV_s5NeverO8CreateML23MLRandomForestRegressorV15ModelParametersV010ValidationD0OTg503_s8g4ML23ijk3V15lm76V13configuration10validationAE0A12MLComponents24BoostedTreeConfigurationV_11c7Data0O5e12VSgtcfcAE010N21O0OAMcAPmcfu_ApMcfu0_AOXMtTf1ncn_n@<X0>(uint64_t a1@<X0>, uint64_t a2@<X8>)
{
  uint64_t v4 = type metadata accessor for DataFrame();
  uint64_t v5 = *(void *)(v4 - 8);
  MEMORY[0x270FA5388](v4);
  v7 = (char *)&v16 - ((v6 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
  MEMORY[0x270FA5388](v8 - 8);
  v10 = (char *)&v16 - ((v9 + 15) & 0xFFFFFFFFFFFFFFF0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(a1, (uint64_t)v10, &demangling cache variable for type metadata for DataFrame?);
  if (__swift_getEnumTagSinglePayload((uint64_t)v10, 1, v4) == 1)
  {
    uint64_t v11 = type metadata accessor for MLRandomForestRegressor.ModelParameters.ValidationData();
    uint64_t v12 = a2;
    uint64_t v13 = 1;
  }
  else
  {
    (*(void (**)(char *, char *, uint64_t))(v5 + 32))(v7, v10, v4);
    (*(void (**)(uint64_t, char *, uint64_t))(v5 + 16))(a2, v7, v4);
    uint64_t v14 = type metadata accessor for MLRandomForestRegressor.ModelParameters.ValidationData();
    swift_storeEnumTagMultiPayload();
    (*(void (**)(char *, uint64_t))(v5 + 8))(v7, v4);
    uint64_t v12 = a2;
    uint64_t v13 = 0;
    uint64_t v11 = v14;
  }
  return __swift_storeEnumTagSinglePayload(v12, v13, 1, v11);
}

uint64_t MLRandomForestRegressor.ModelParameters.init(validation:maxDepth:maxIterations:minLossReduction:minChildWeight:randomSeed:rowSubsample:columnSubsample:)@<X0>(uint64_t a1@<X0>, uint64_t a2@<X1>, uint64_t a3@<X2>, uint64_t a4@<X3>, uint64_t a5@<X8>, double a6@<D0>, double a7@<D1>, double a8@<D2>, double a9@<D3>)
{
  uint64_t v19 = type metadata accessor for MLRandomForestRegressor.ModelParameters.ValidationData();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v20);
  *(double *)&long long v21 = OUTLINED_FUNCTION_2_15();
  *(_OWORD *)a5 = v21;
  *(_OWORD *)(a5 + 16) = v21;
  *(void *)(a5 + 96) = 0;
  *(void *)(a5 + 104) = 0;
  *(void *)(a5 + 88) = 0;
  *(void *)(a5 + 32) = a2;
  *(void *)(a5 + 40) = a3;
  *(double *)(a5 + 48) = a6;
  *(double *)(a5 + 56) = a7;
  *(void *)(a5 + 64) = a4;
  *(double *)(a5 + 72) = a8;
  *(double *)(a5 + 80) = a9;
  outlined init with copy of MLRandomForestRegressor.ModelParameters.ValidationData(a1, v9);
  v24[3] = v19;
  boxed_opaque_existential_0 = __swift_allocate_boxed_opaque_existential_0(v24);
  outlined init with take of MLRandomForestRegressor.ModelParameters.ValidationData(v9, (uint64_t)boxed_opaque_existential_0);
  outlined assign with take of Any?((uint64_t)v24, a5);
  return outlined destroy of MLRandomForestRegressor.ModelParameters.ValidationData(a1);
}

uint64_t outlined init with copy of MLRandomForestRegressor.ModelParameters.ValidationData(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = type metadata accessor for MLRandomForestRegressor.ModelParameters.ValidationData();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 16))(a2, a1, v4);
  return a2;
}

uint64_t MLRandomForestRegressor.ModelParameters.validation.getter()
{
  uint64_t result = outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v0, (uint64_t)&v2, &demangling cache variable for type metadata for Any?);
  if (v3)
  {
    outlined init with take of Any(&v2, &v4);
    type metadata accessor for MLRandomForestRegressor.ModelParameters.ValidationData();
    return swift_dynamicCast();
  }
  else
  {
    __break(1u);
  }
  return result;
}

uint64_t MLRandomForestRegressor.ModelParameters.init(validationData:maxDepth:maxIterations:minLossReduction:minChildWeight:randomSeed:rowSubsample:columnSubsample:)@<X0>(uint64_t *a1@<X0>, uint64_t a2@<X1>, uint64_t a3@<X2>, uint64_t a4@<X3>, uint64_t a5@<X8>, double a6@<D0>, double a7@<D1>, double a8@<D2>, double a9@<D3>)
{
  uint64_t v9 = *a1;
  char v10 = *((unsigned char *)a1 + 8);
  *(_OWORD *)a5 = 0u;
  *(_OWORD *)(a5 + 16) = 0u;
  *(void *)(a5 + 96) = 0;
  *(void *)(a5 + 104) = 0;
  *(void *)(a5 + 88) = 0;
  *(void *)(a5 + 32) = a2;
  *(void *)(a5 + 40) = a3;
  *(double *)(a5 + 48) = a6;
  *(double *)(a5 + 56) = a7;
  *(void *)(a5 + 64) = a4;
  *(double *)(a5 + 72) = a8;
  *(double *)(a5 + 80) = a9;
  uint64_t v12 = v9;
  char v13 = v10;
  return MLRandomForestRegressor.ModelParameters.validationData.setter((uint64_t)&v12);
}

uint64_t MLRandomForestRegressor.ModelParameters.init(configuration:validation:)@<X0>(uint64_t a1@<X0>, uint64_t a2@<X1>, uint64_t a3@<X8>)
{
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLRandomForestRegressor.ModelParameters.ValidationData?);
  MEMORY[0x270FA5388](v7 - 8);
  OUTLINED_FUNCTION_3_0();
  uint64_t v10 = v9 - v8;
  uint64_t v11 = type metadata accessor for MLRandomForestRegressor.ModelParameters.ValidationData();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v12);
  *(double *)&long long v13 = OUTLINED_FUNCTION_2_15();
  *(_OWORD *)a3 = v13;
  *(_OWORD *)(a3 + 16) = v13;
  *(void *)(a3 + 96) = 0;
  *(void *)(a3 + 104) = 0;
  *(void *)(a3 + 88) = 0;
  *(void *)(a3 + 32) = BoostedTreeConfiguration.maximumDepth.getter();
  *(void *)(a3 + 40) = BoostedTreeConfiguration.maximumIterations.getter();
  BoostedTreeConfiguration.minimumLossReduction.getter();
  *(void *)(a3 + 48) = v14;
  BoostedTreeConfiguration.minimumChildWeight.getter();
  *(void *)(a3 + 56) = v15;
  *(void *)(a3 + 64) = BoostedTreeConfiguration.randomSeed.getter();
  BoostedTreeConfiguration.rowSubsample.getter();
  *(void *)(a3 + 72) = v16;
  BoostedTreeConfiguration.columnSubsample.getter();
  *(void *)(a3 + 80) = v17;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lF11TabularData0D5FrameV_s5NeverO8CreateML23MLRandomForestRegressorV15ModelParametersV010ValidationD0OTg503_s8g4ML23ijk3V15lm76V13configuration10validationAE0A12MLComponents24BoostedTreeConfigurationV_11c7Data0O5e12VSgtcfcAE010N21O0OAMcAPmcfu_ApMcfu0_AOXMtTf1ncn_n(a2, v10);
  if (__swift_getEnumTagSinglePayload(v10, 1, v11) == 1)
  {
    swift_storeEnumTagMultiPayload();
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v10, &demangling cache variable for type metadata for MLRandomForestRegressor.ModelParameters.ValidationData?);
  }
  else
  {
    outlined init with take of MLRandomForestRegressor.ModelParameters.ValidationData(v10, v3);
  }
  v21[3] = v11;
  boxed_opaque_existential_0 = __swift_allocate_boxed_opaque_existential_0(v21);
  outlined init with take of MLRandomForestRegressor.ModelParameters.ValidationData(v3, (uint64_t)boxed_opaque_existential_0);
  outlined assign with take of Any?((uint64_t)v21, a3);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(a2, &demangling cache variable for type metadata for DataFrame?);
  type metadata accessor for BoostedTreeConfiguration();
  OUTLINED_FUNCTION_8();
  return (*(uint64_t (**)(uint64_t))(v19 + 8))(a1);
}

uint64_t MLRandomForestRegressor.ModelParameters.description.getter()
{
  v0._countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter();
  String.append(_:)(v0);
  swift_bridgeObjectRelease();
  v1._countAndFlagsBits = 10;
  v1._object = (void *)0xE100000000000000;
  String.append(_:)(v1);
  OUTLINED_FUNCTION_4_0();
  _StringGuts.grow(_:)(19);
  swift_bridgeObjectRelease();
  v2._countAndFlagsBits = OUTLINED_FUNCTION_8_9();
  String.append(_:)(v2);
  swift_bridgeObjectRelease();
  OUTLINED_FUNCTION_1_1();
  v3._countAndFlagsBits = 0xD000000000000010;
  v3._object = (void *)0x80000002272D3F00;
  String.append(_:)(v3);
  swift_bridgeObjectRelease();
  OUTLINED_FUNCTION_4_0();
  _StringGuts.grow(_:)(23);
  OUTLINED_FUNCTION_7_0();
  v4._countAndFlagsBits = 0xD000000000000014;
  v4._object = (void *)0x80000002272D3F20;
  String.append(_:)(v4);
  OUTLINED_FUNCTION_3_10();
  OUTLINED_FUNCTION_1_1();
  v5._countAndFlagsBits = 0xD000000000000010;
  v5._object = (void *)0x80000002272D3F00;
  String.append(_:)(v5);
  swift_bridgeObjectRelease();
  _StringGuts.grow(_:)(21);
  OUTLINED_FUNCTION_7_0();
  OUTLINED_FUNCTION_5_0((uint64_t)"Min Child Weight: ");
  OUTLINED_FUNCTION_3_10();
  OUTLINED_FUNCTION_1_1();
  v6._countAndFlagsBits = 0;
  v6._object = (void *)0xE000000000000000;
  String.append(_:)(v6);
  swift_bridgeObjectRelease();
  OUTLINED_FUNCTION_4_0();
  _StringGuts.grow(_:)(16);
  swift_bridgeObjectRelease();
  strcpy((char *)&v11, "Random Seed: ");
  HIWORD(v11._object) = -4864;
  v7._countAndFlagsBits = OUTLINED_FUNCTION_8_9();
  String.append(_:)(v7);
  swift_bridgeObjectRelease();
  OUTLINED_FUNCTION_1_1();
  String.append(_:)(v11);
  swift_bridgeObjectRelease();
  OUTLINED_FUNCTION_4_0();
  _StringGuts.grow(_:)(18);
  OUTLINED_FUNCTION_7_0();
  v8._countAndFlagsBits = 0x7362755320776F52;
  v8._object = (void *)0xEF203A656C706D61;
  String.append(_:)(v8);
  Double.write<A>(to:)();
  OUTLINED_FUNCTION_1_1();
  String.append(_:)(v11);
  swift_bridgeObjectRelease();
  _StringGuts.grow(_:)(21);
  OUTLINED_FUNCTION_7_0();
  OUTLINED_FUNCTION_5_0((uint64_t)"Column Subsample: ");
  Double.write<A>(to:)();
  OUTLINED_FUNCTION_1_1();
  v9._countAndFlagsBits = 0;
  v9._object = (void *)0xE000000000000000;
  String.append(_:)(v9);
  swift_bridgeObjectRelease();
  return 0x747065442078614DLL;
}

uint64_t MLRandomForestRegressor.ModelParameters.validationData.getter@<X0>(uint64_t a1@<X8>)
{
  type metadata accessor for MLRandomForestRegressor.ModelParameters.ValidationData();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v3);
  OUTLINED_FUNCTION_3_0();
  uint64_t v6 = v5 - v4;
  uint64_t result = outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v1, (uint64_t)&v8, &demangling cache variable for type metadata for Any?);
  if (v9)
  {
    outlined init with take of Any(&v8, &v10);
    swift_dynamicCast();
    MLRandomForestRegressor.ModelParameters.ValidationData.table.getter(a1);
    return outlined destroy of MLRandomForestRegressor.ModelParameters.ValidationData(v6);
  }
  else
  {
    __break(1u);
  }
  return result;
}

uint64_t key path getter for MLRandomForestRegressor.ModelParameters.validationData : MLRandomForestRegressor.ModelParameters@<X0>(uint64_t a1@<X8>)
{
  uint64_t result = MLRandomForestRegressor.ModelParameters.validationData.getter((uint64_t)&v4);
  char v3 = v5;
  *(void *)a1 = v4;
  *(unsigned char *)(a1 + 8) = v3;
  return result;
}

uint64_t key path setter for MLRandomForestRegressor.ModelParameters.validationData : MLRandomForestRegressor.ModelParameters(uint64_t a1)
{
  unsigned __int8 v1 = *(unsigned char *)(a1 + 8);
  id v3 = *(id *)a1;
  unsigned __int8 v4 = v1;
  outlined copy of MLDataTable?(v3, v1);
  return MLRandomForestRegressor.ModelParameters.validationData.setter((uint64_t)&v3);
}

uint64_t MLRandomForestRegressor.ModelParameters.validationData.setter(uint64_t a1)
{
  uint64_t v2 = v1;
  type metadata accessor for MLRandomForestRegressor.ModelParameters.ValidationData();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v4);
  OUTLINED_FUNCTION_3_0();
  uint64_t v7 = v6 - v5;
  long long v8 = *(void **)a1;
  int v9 = *(unsigned __int8 *)(a1 + 8);
  v13[3] = v10;
  boxed_opaque_existential_0 = __swift_allocate_boxed_opaque_existential_0(v13);
  if (v9 == 255)
  {
    *(void *)uint64_t v7 = 0;
    *(void *)(v7 + 8) = 0;
    *(_WORD *)(v7 + 16) = 256;
  }
  else if (MLDataTable.size.getter())
  {
    *(void *)uint64_t v7 = v8;
    *(unsigned char *)(v7 + 8) = v9 & 1;
  }
  else
  {
    outlined consume of MLDataTable?(v8, v9);
  }
  swift_storeEnumTagMultiPayload();
  outlined init with take of MLRandomForestRegressor.ModelParameters.ValidationData(v7, (uint64_t)boxed_opaque_existential_0);
  return outlined assign with take of Any?((uint64_t)v13, v2);
}

void (*MLRandomForestRegressor.ModelParameters.validationData.modify(uint64_t a1))(uint64_t a1, char a2)
{
  *(void *)(a1 + 16) = v1;
  MLRandomForestRegressor.ModelParameters.validationData.getter(a1);
  return MLRandomForestRegressor.ModelParameters.validationData.modify;
}

void MLRandomForestRegressor.ModelParameters.validationData.modify(uint64_t a1, char a2)
{
  uint64_t v2 = *(void **)a1;
  unsigned __int8 v3 = *(unsigned char *)(a1 + 8);
  if (a2)
  {
    uint64_t v4 = *(void **)a1;
    unsigned __int8 v5 = v3;
    outlined copy of MLDataTable?(v2, v3);
    MLRandomForestRegressor.ModelParameters.validationData.setter((uint64_t)&v4);
    outlined consume of MLDataTable?(v2, v3);
  }
  else
  {
    uint64_t v4 = *(void **)a1;
    unsigned __int8 v5 = v3;
    MLRandomForestRegressor.ModelParameters.validationData.setter((uint64_t)&v4);
  }
}

uint64_t key path setter for MLRandomForestRegressor.ModelParameters.validation : MLRandomForestRegressor.ModelParameters(uint64_t a1)
{
  uint64_t v2 = type metadata accessor for MLRandomForestRegressor.ModelParameters.ValidationData();
  MEMORY[0x270FA5388](v2 - 8);
  uint64_t v4 = (char *)&v6 - ((v3 + 15) & 0xFFFFFFFFFFFFFFF0);
  outlined init with copy of MLRandomForestRegressor.ModelParameters.ValidationData(a1, (uint64_t)v4);
  return MLRandomForestRegressor.ModelParameters.validation.setter((uint64_t)v4);
}

uint64_t MLRandomForestRegressor.ModelParameters.validation.setter(uint64_t a1)
{
  v5[3] = type metadata accessor for MLRandomForestRegressor.ModelParameters.ValidationData();
  boxed_opaque_existential_0 = __swift_allocate_boxed_opaque_existential_0(v5);
  outlined init with take of MLRandomForestRegressor.ModelParameters.ValidationData(a1, (uint64_t)boxed_opaque_existential_0);
  return outlined assign with take of Any?((uint64_t)v5, v1);
}

uint64_t outlined init with take of MLRandomForestRegressor.ModelParameters.ValidationData(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = type metadata accessor for MLRandomForestRegressor.ModelParameters.ValidationData();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 32))(a2, a1, v4);
  return a2;
}

uint64_t outlined destroy of MLRandomForestRegressor.ModelParameters.ValidationData(uint64_t a1)
{
  uint64_t v2 = type metadata accessor for MLRandomForestRegressor.ModelParameters.ValidationData();
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v2 - 8) + 8))(a1, v2);
  return a1;
}

void (*MLRandomForestRegressor.ModelParameters.validation.modify(void *a1))(uint64_t **a1, char a2)
{
  uint64_t v2 = v1;
  uint64_t v4 = malloc(0xA0uLL);
  *a1 = v4;
  v4[16] = v2;
  v4[17] = type metadata accessor for MLRandomForestRegressor.ModelParameters.ValidationData();
  OUTLINED_FUNCTION_8();
  size_t v6 = *(void *)(v5 + 64);
  v4[18] = malloc(v6);
  v4[19] = malloc(v6);
  uint64_t result = (void (*)(uint64_t **, char))outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v2, (uint64_t)(v4 + 4), &demangling cache variable for type metadata for Any?);
  if (v4[7])
  {
    outlined init with take of Any((_OWORD *)v4 + 2, v4);
    swift_dynamicCast();
    return MLRandomForestRegressor.ModelParameters.validation.modify;
  }
  else
  {
    __break(1u);
  }
  return result;
}

void MLRandomForestRegressor.ModelParameters.validation.modify(uint64_t **a1, char a2)
{
  uint64_t v2 = *a1;
  uint64_t v3 = (void *)(*a1)[18];
  uint64_t v4 = (void *)(*a1)[19];
  uint64_t v5 = (*a1)[16];
  uint64_t v6 = (*a1)[17];
  if (a2)
  {
    outlined init with copy of MLRandomForestRegressor.ModelParameters.ValidationData((*a1)[19], (uint64_t)v3);
    v2[11] = v6;
    boxed_opaque_existential_0 = __swift_allocate_boxed_opaque_existential_0(v2 + 8);
    outlined init with take of MLRandomForestRegressor.ModelParameters.ValidationData((uint64_t)v3, (uint64_t)boxed_opaque_existential_0);
    outlined assign with take of Any?((uint64_t)(v2 + 8), v5);
    outlined destroy of MLRandomForestRegressor.ModelParameters.ValidationData((uint64_t)v4);
  }
  else
  {
    v2[15] = v6;
    long long v8 = __swift_allocate_boxed_opaque_existential_0(v2 + 12);
    outlined init with take of MLRandomForestRegressor.ModelParameters.ValidationData((uint64_t)v4, (uint64_t)v8);
    outlined assign with take of Any?((uint64_t)(v2 + 12), v5);
  }
  free(v4);
  free(v3);

  free(v2);
}

uint64_t MLRandomForestRegressor.ModelParameters.maxDepth.getter()
{
  return *(void *)(v0 + 32);
}

uint64_t MLRandomForestRegressor.ModelParameters.maxDepth.setter(uint64_t result)
{
  *(void *)(v1 + 32) = result;
  return result;
}

uint64_t (*MLRandomForestRegressor.ModelParameters.maxDepth.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLRandomForestRegressor.ModelParameters.maxIterations.getter()
{
  return *(void *)(v0 + 40);
}

uint64_t MLRandomForestRegressor.ModelParameters.maxIterations.setter(uint64_t result)
{
  *(void *)(v1 + 40) = result;
  return result;
}

uint64_t (*MLRandomForestRegressor.ModelParameters.maxIterations.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

double MLRandomForestRegressor.ModelParameters.minLossReduction.getter()
{
  return *(double *)(v0 + 48);
}

void MLRandomForestRegressor.ModelParameters.minLossReduction.setter(double a1)
{
  *(double *)(v1 + 48) = a1;
}

uint64_t (*MLRandomForestRegressor.ModelParameters.minLossReduction.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

double MLRandomForestRegressor.ModelParameters.minChildWeight.getter()
{
  return *(double *)(v0 + 56);
}

void MLRandomForestRegressor.ModelParameters.minChildWeight.setter(double a1)
{
  *(double *)(v1 + 56) = a1;
}

uint64_t (*MLRandomForestRegressor.ModelParameters.minChildWeight.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLRandomForestRegressor.ModelParameters.randomSeed.getter()
{
  return *(void *)(v0 + 64);
}

uint64_t MLRandomForestRegressor.ModelParameters.randomSeed.setter(uint64_t result)
{
  *(void *)(v1 + 64) = result;
  return result;
}

uint64_t (*MLRandomForestRegressor.ModelParameters.randomSeed.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

double MLRandomForestRegressor.ModelParameters.rowSubsample.getter()
{
  return *(double *)(v0 + 72);
}

void MLRandomForestRegressor.ModelParameters.rowSubsample.setter(double a1)
{
  *(double *)(v1 + 72) = a1;
}

uint64_t (*MLRandomForestRegressor.ModelParameters.rowSubsample.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

double MLRandomForestRegressor.ModelParameters.columnSubsample.getter()
{
  return *(double *)(v0 + 80);
}

void MLRandomForestRegressor.ModelParameters.columnSubsample.setter(double a1)
{
  *(double *)(v1 + 80) = a1;
}

uint64_t (*MLRandomForestRegressor.ModelParameters.columnSubsample.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLRandomForestRegressor.ModelParameters.playgroundDescription.getter@<X0>(uint64_t *a1@<X8>)
{
  uint64_t result = MLRandomForestRegressor.ModelParameters.description.getter();
  a1[3] = MEMORY[0x263F8D310];
  *a1 = result;
  a1[1] = v3;
  return result;
}

uint64_t sub_2270D5038()
{
  return MLRandomForestRegressor.ModelParameters.validation.getter();
}

uint64_t initializeWithCopy for MLRandomForestRegressor.ModelParameters(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = *(void *)(a2 + 24);
  if (v4)
  {
    *(void *)(a1 + 24) = v4;
    (**(void (***)(uint64_t, uint64_t))(v4 - 8))(a1, a2);
  }
  else
  {
    long long v5 = *(_OWORD *)(a2 + 16);
    *(_OWORD *)a1 = *(_OWORD *)a2;
    *(_OWORD *)(a1 + 16) = v5;
  }
  long long v6 = *(_OWORD *)(a2 + 48);
  *(_OWORD *)(a1 + 32) = *(_OWORD *)(a2 + 32);
  *(_OWORD *)(a1 + 48) = v6;
  long long v7 = *(_OWORD *)(a2 + 80);
  *(_OWORD *)(a1 + 64) = *(_OWORD *)(a2 + 64);
  *(_OWORD *)(a1 + 80) = v7;
  *(_OWORD *)(a1 + 96) = *(_OWORD *)(a2 + 96);
  return a1;
}

uint64_t assignWithCopy for MLRandomForestRegressor.ModelParameters(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = *(void *)(a2 + 24);
  if (!*(void *)(a1 + 24))
  {
    if (v4)
    {
      *(void *)(a1 + 24) = v4;
      (**(void (***)(uint64_t, uint64_t))(v4 - 8))(a1, a2);
      goto LABEL_8;
    }
LABEL_7:
    long long v5 = *(_OWORD *)(a2 + 16);
    *(_OWORD *)a1 = *(_OWORD *)a2;
    *(_OWORD *)(a1 + 16) = v5;
    goto LABEL_8;
  }
  if (!v4)
  {
    __swift_destroy_boxed_opaque_existential_0(a1);
    goto LABEL_7;
  }
  __swift_assign_boxed_opaque_existential_0((uint64_t *)a1, (uint64_t *)a2);
LABEL_8:
  *(void *)(a1 + 32) = *(void *)(a2 + 32);
  *(void *)(a1 + 40) = *(void *)(a2 + 40);
  *(void *)(a1 + 48) = *(void *)(a2 + 48);
  *(void *)(a1 + 56) = *(void *)(a2 + 56);
  *(void *)(a1 + 64) = *(void *)(a2 + 64);
  *(void *)(a1 + 72) = *(void *)(a2 + 72);
  *(void *)(a1 + 80) = *(void *)(a2 + 80);
  *(void *)(a1 + 88) = *(void *)(a2 + 88);
  *(void *)(a1 + 96) = *(void *)(a2 + 96);
  *(void *)(a1 + 104) = *(void *)(a2 + 104);
  return a1;
}

uint64_t assignWithTake for MLRandomForestRegressor.ModelParameters(uint64_t a1, uint64_t a2)
{
  if (*(void *)(a1 + 24)) {
    __swift_destroy_boxed_opaque_existential_0(a1);
  }
  long long v4 = *(_OWORD *)(a2 + 16);
  *(_OWORD *)a1 = *(_OWORD *)a2;
  *(_OWORD *)(a1 + 16) = v4;
  long long v5 = *(_OWORD *)(a2 + 48);
  *(_OWORD *)(a1 + 32) = *(_OWORD *)(a2 + 32);
  *(_OWORD *)(a1 + 48) = v5;
  *(void *)(a1 + 64) = *(void *)(a2 + 64);
  *(_OWORD *)(a1 + 72) = *(_OWORD *)(a2 + 72);
  *(_OWORD *)(a1 + 88) = *(_OWORD *)(a2 + 88);
  *(void *)(a1 + 104) = *(void *)(a2 + 104);
  return a1;
}

ValueMetadata *type metadata accessor for MLRandomForestRegressor.ModelParameters()
{
  return &type metadata for MLRandomForestRegressor.ModelParameters;
}

double OUTLINED_FUNCTION_2_15()
{
  return 0.0;
}

uint64_t OUTLINED_FUNCTION_8_9()
{
  return dispatch thunk of CustomStringConvertible.description.getter();
}

void static Conv2D.loadLayer(from:layerName:)(uint64_t a1@<X1>, uint64_t a2@<X2>, uint64_t a3@<X8>)
{
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Tensor?);
  uint64_t v7 = MEMORY[0x270FA5388](v6 - 8);
  int v9 = (char *)&v87 - ((v8 + 15) & 0xFFFFFFFFFFFFFFF0);
  MEMORY[0x270FA5388](v7);
  Swift::String v11 = (char *)&v87 - v10;
  uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for TensorShape?);
  MEMORY[0x270FA5388](v12 - 8);
  v102 = (char *)&v87 - ((v13 + 15) & 0xFFFFFFFFFFFFFFF0);
  type metadata accessor for Tensor();
  OUTLINED_FUNCTION_0();
  uint64_t v100 = v15;
  uint64_t v101 = v14;
  MEMORY[0x270FA5388](v14);
  OUTLINED_FUNCTION_49();
  uint64_t v99 = v16;
  MEMORY[0x270FA5388](v17);
  uint64_t v108 = (uint64_t)&v87 - v18;
  type metadata accessor for TensorShape();
  OUTLINED_FUNCTION_0();
  uint64_t v104 = v20;
  uint64_t v105 = v19;
  MEMORY[0x270FA5388](v19);
  OUTLINED_FUNCTION_49();
  uint64_t v98 = v21;
  MEMORY[0x270FA5388](v22);
  v103 = (char *)&v87 - v23;
  OUTLINED_FUNCTION_2_16();
  v24._countAndFlagsBits = OUTLINED_FUNCTION_9_9() & 0xFFFFFFFFFFFFLL | 0x74000000000000;
  v24._object = (void *)0xE700000000000000;
  String.append(_:)(v24);
  uint64_t v25 = OUTLINED_FUNCTION_0_11();
  swift_bridgeObjectRelease();
  if (!v25)
  {
    OUTLINED_FUNCTION_3_17();
    _StringGuts.grow(_:)(39);
    OUTLINED_FUNCTION_5_13();
    swift_bridgeObjectRelease();
    OUTLINED_FUNCTION_4_14();
    unint64_t v43 = v42 - 1;
    v44 = ".weight not found in state dictionary";
LABEL_22:
    unint64_t v46 = (unint64_t)(v44 - 32) | 0x8000000000000000;
LABEL_28:
    String.append(_:)(*(Swift::String *)&v43);
    uint64_t v49 = v106;
    uint64_t v48 = v107;
    lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError();
    *(void *)uint64_t v50 = v49;
    *(void *)(v50 + 8) = v48;
    *(_OWORD *)(v50 + 16) = 0u;
    *(_OWORD *)(v50 + 32) = 0u;
    *(unsigned char *)(v50 + 48) = 2;
    swift_willThrow();
    return;
  }
  v97 = v9;
  OUTLINED_FUNCTION_2_16();
  v26._countAndFlagsBits = OUTLINED_FUNCTION_9_9() & 0xFFFFFFFFFFFFLL | 0x2E74000000000000;
  v26._object = (void *)0xED00006570616873;
  String.append(_:)(v26);
  uint64_t v27 = OUTLINED_FUNCTION_0_11();
  swift_bridgeObjectRelease();
  if (!v27)
  {
    swift_bridgeObjectRelease();
    OUTLINED_FUNCTION_3_17();
    _StringGuts.grow(_:)(45);
    OUTLINED_FUNCTION_5_13();
    swift_bridgeObjectRelease();
    OUTLINED_FUNCTION_4_14();
    unint64_t v43 = v45 + 5;
    v44 = ".weight.shape not found in state dictionary";
    goto LABEL_22;
  }
  uint64_t v96 = a3;
  OUTLINED_FUNCTION_2_16();
  v28._countAndFlagsBits = 0x736564697274732ELL;
  v28._object = (void *)0xE800000000000000;
  String.append(_:)(v28);
  uint64_t v29 = OUTLINED_FUNCTION_0_11();
  swift_bridgeObjectRelease();
  if (!v29)
  {
LABEL_24:
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    OUTLINED_FUNCTION_6_12();
    OUTLINED_FUNCTION_5_13();
    swift_bridgeObjectRelease();
    uint64_t v106 = a1;
    uint64_t v107 = a2;
    v47 = ".strides not found in state dictionary";
LABEL_27:
    unint64_t v46 = (unint64_t)(v47 - 32) | 0x8000000000000000;
    unint64_t v43 = 0xD000000000000026;
    goto LABEL_28;
  }
  if (*(void *)(v29 + 16) != 2)
  {
    swift_bridgeObjectRelease();
    goto LABEL_24;
  }
  uint64_t v95 = v29;
  OUTLINED_FUNCTION_2_16();
  v30._countAndFlagsBits = 0x676E69646461702ELL;
  v30._object = (void *)0xE800000000000000;
  String.append(_:)(v30);
  uint64_t v31 = OUTLINED_FUNCTION_0_11();
  swift_bridgeObjectRelease();
  if (!v31)
  {
LABEL_26:
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    OUTLINED_FUNCTION_6_12();
    OUTLINED_FUNCTION_5_13();
    swift_bridgeObjectRelease();
    uint64_t v106 = a1;
    uint64_t v107 = a2;
    v47 = ".padding not found in state dictionary";
    goto LABEL_27;
  }
  if (*(void *)(v31 + 16) != 2)
  {
    swift_bridgeObjectRelease();
    goto LABEL_26;
  }
  OUTLINED_FUNCTION_2_16();
  v32._countAndFlagsBits = 0x6F6974616C69642ELL;
  v32._object = (void *)0xEA0000000000736ELL;
  String.append(_:)(v32);
  uint64_t v93 = OUTLINED_FUNCTION_0_11();
  swift_bridgeObjectRelease();
  if (!v93)
  {
LABEL_30:
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    OUTLINED_FUNCTION_3_17();
    _StringGuts.grow(_:)(42);
    OUTLINED_FUNCTION_5_13();
    swift_bridgeObjectRelease();
    OUTLINED_FUNCTION_4_14();
    unint64_t v43 = v51 + 2;
    v44 = ".dilations not found in state dictionary";
    goto LABEL_22;
  }
  if (*(void *)(v93 + 16) != 2)
  {
    swift_bridgeObjectRelease();
    goto LABEL_30;
  }
  OUTLINED_FUNCTION_2_16();
  v33._countAndFlagsBits = 0x6F4370756F72672ELL;
  v33._object = (void *)0xEB00000000746E75;
  String.append(_:)(v33);
  uint64_t v92 = OUTLINED_FUNCTION_0_11();
  swift_bridgeObjectRelease();
  if (!v92)
  {
LABEL_32:
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    OUTLINED_FUNCTION_3_17();
    _StringGuts.grow(_:)(43);
    OUTLINED_FUNCTION_5_13();
    swift_bridgeObjectRelease();
    OUTLINED_FUNCTION_4_14();
    unint64_t v43 = v52 + 3;
    v44 = ".groupCount not found in state dictionary";
    goto LABEL_22;
  }
  if (*(void *)(v92 + 16) != 1)
  {
    swift_bridgeObjectRelease();
    goto LABEL_32;
  }
  uint64_t v91 = v31;
  uint64_t v34 = *(void *)(v27 + 16);
  v94 = v11;
  if (v34)
  {
    uint64_t v106 = MEMORY[0x263F8EE78];
    uint64_t v90 = v34;
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v34, 0);
    uint64_t v35 = v90;
    uint64_t v36 = 0;
    uint64_t v37 = v106;
    while (1)
    {
      double v38 = *(double *)(v27 + 8 * v36 + 32);
      if ((~*(void *)&v38 & 0x7FF0000000000000) == 0) {
        break;
      }
      if (v38 <= -9.22337204e18) {
        goto LABEL_78;
      }
      if (v38 >= 9.22337204e18) {
        goto LABEL_79;
      }
      uint64_t v106 = v37;
      unint64_t v40 = *(void *)(v37 + 16);
      unint64_t v39 = *(void *)(v37 + 24);
      unint64_t v41 = v40 + 1;
      if (v40 >= v39 >> 1)
      {
        unint64_t v89 = v40 + 1;
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v39 > 1, v40 + 1, 1);
        unint64_t v41 = v89;
        uint64_t v35 = v90;
        uint64_t v37 = v106;
      }
      ++v36;
      *(void *)(v37 + 16) = v41;
      *(void *)(v37 + 8 * v40 + 32) = (uint64_t)v38;
      Swift::String v11 = v94;
      if (v35 == v36)
      {
        swift_bridgeObjectRelease();
        goto LABEL_34;
      }
    }
    __break(1u);
LABEL_78:
    __break(1u);
LABEL_79:
    __break(1u);
    goto LABEL_80;
  }
  swift_bridgeObjectRelease();
  uint64_t v37 = MEMORY[0x263F8EE78];
LABEL_34:
  v53 = v103;
  MEMORY[0x22A672540](v37);
  v54 = *(void (**)(char *, uint64_t, uint64_t))(v104 + 16);
  uint64_t v55 = (uint64_t)v102;
  v56 = v53;
  uint64_t v57 = v105;
  unint64_t v89 = v104 + 16;
  v88 = v54;
  v54(v102, (uint64_t)v56, v105);
  __swift_storeEnumTagSinglePayload(v55, 0, 1, v57);
  Array<A>.floatTensor(shape:)(v55, v25, v108);
  swift_bridgeObjectRelease();
  outlined destroy of (key: String, value: Any?)(v55, &demangling cache variable for type metadata for TensorShape?);
  uint64_t v58 = v101;
  __swift_storeEnumTagSinglePayload((uint64_t)v11, 1, 1, v101);
  OUTLINED_FUNCTION_2_16();
  v59._countAndFlagsBits = 0x736169622ELL;
  v59._object = (void *)0xE500000000000000;
  String.append(_:)(v59);
  uint64_t v60 = OUTLINED_FUNCTION_0_11();
  swift_bridgeObjectRelease();
  uint64_t v61 = (uint64_t)v97;
  uint64_t v90 = v60;
  if (v60)
  {
    OUTLINED_FUNCTION_2_16();
    v62._countAndFlagsBits = 0x68732E736169622ELL;
    v62._object = (void *)0xEB00000000657061;
    String.append(_:)(v62);
    uint64_t v63 = OUTLINED_FUNCTION_0_11();
    swift_bridgeObjectRelease();
    if (v63)
    {
      uint64_t v64 = *(void *)(v63 + 16);
      if (v64)
      {
        uint64_t v106 = MEMORY[0x263F8EE78];
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v64, 0);
        uint64_t v65 = 0;
        uint64_t v66 = v106;
        while (1)
        {
          double v67 = *(double *)(v63 + 8 * v65 + 32);
          if ((~*(void *)&v67 & 0x7FF0000000000000) == 0) {
            break;
          }
          if (v67 <= -9.22337204e18) {
            goto LABEL_81;
          }
          if (v67 >= 9.22337204e18) {
            goto LABEL_82;
          }
          uint64_t v106 = v66;
          unint64_t v69 = *(void *)(v66 + 16);
          unint64_t v68 = *(void *)(v66 + 24);
          if (v69 >= v68 >> 1)
          {
            specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v68 > 1, v69 + 1, 1);
            uint64_t v66 = v106;
          }
          ++v65;
          *(void *)(v66 + 16) = v69 + 1;
          *(void *)(v66 + 8 * v69 + 32) = (uint64_t)v67;
          Swift::String v11 = v94;
          if (v64 == v65)
          {
            swift_bridgeObjectRelease();
            uint64_t v61 = (uint64_t)v97;
            uint64_t v58 = v101;
            goto LABEL_47;
          }
        }
LABEL_80:
        __break(1u);
LABEL_81:
        __break(1u);
LABEL_82:
        __break(1u);
        goto LABEL_83;
      }
      swift_bridgeObjectRelease();
      uint64_t v66 = MEMORY[0x263F8EE78];
LABEL_47:
      uint64_t v70 = v98;
      MEMORY[0x22A672540](v66);
      uint64_t v71 = (uint64_t)v102;
      uint64_t v72 = v105;
      v88(v102, v70, v105);
      __swift_storeEnumTagSinglePayload(v71, 0, 1, v72);
      Array<A>.floatTensor(shape:)(v71, v90, v61);
      swift_bridgeObjectRelease();
      outlined destroy of (key: String, value: Any?)(v71, &demangling cache variable for type metadata for TensorShape?);
      (*(void (**)(uint64_t, uint64_t))(v104 + 8))(v70, v72);
      outlined destroy of (key: String, value: Any?)((uint64_t)v11, &demangling cache variable for type metadata for Tensor?);
      __swift_storeEnumTagSinglePayload(v61, 0, 1, v58);
      outlined init with take of Tensor?(v61, (uint64_t)v11);
    }
    else
    {
      swift_bridgeObjectRelease();
    }
  }
  uint64_t v73 = v100;
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v100 + 16))(v99, v108, v58);
  outlined init with copy of Tensor?((uint64_t)v11, v61);
  unint64_t v74 = *(void *)(v95 + 16);
  if (!v74)
  {
LABEL_83:
    __break(1u);
    goto LABEL_84;
  }
  double v75 = *(double *)(v95 + 32);
  if ((~*(void *)&v75 & 0x7FF0000000000000) == 0)
  {
LABEL_84:
    __break(1u);
    goto LABEL_85;
  }
  if (v75 <= -9.22337204e18)
  {
LABEL_85:
    __break(1u);
    goto LABEL_86;
  }
  if (v75 >= 9.22337204e18)
  {
LABEL_86:
    __break(1u);
    goto LABEL_87;
  }
  if (v74 < 2)
  {
LABEL_87:
    __break(1u);
    goto LABEL_88;
  }
  double v76 = *(double *)(v95 + 40);
  swift_bridgeObjectRelease();
  OUTLINED_FUNCTION_8_10();
  if (v77)
  {
LABEL_88:
    __break(1u);
    goto LABEL_89;
  }
  if (v76 <= -9.22337204e18)
  {
LABEL_89:
    __break(1u);
    goto LABEL_90;
  }
  if (v76 >= OUTLINED_FUNCTION_7_13())
  {
LABEL_90:
    __break(1u);
    goto LABEL_91;
  }
  unint64_t v78 = *(void *)(v91 + 16);
  if (!v78)
  {
LABEL_91:
    __break(1u);
    goto LABEL_92;
  }
  double v79 = *(double *)(v91 + 32);
  if ((~*(void *)&v79 & 0x7FF0000000000000) == 0)
  {
LABEL_92:
    __break(1u);
    goto LABEL_93;
  }
  if (v79 <= -9.22337204e18)
  {
LABEL_93:
    __break(1u);
    goto LABEL_94;
  }
  if (v79 >= 9.22337204e18)
  {
LABEL_94:
    __break(1u);
    goto LABEL_95;
  }
  if (v78 < 2)
  {
LABEL_95:
    __break(1u);
    goto LABEL_96;
  }
  double v80 = *(double *)(v91 + 40);
  swift_bridgeObjectRelease();
  OUTLINED_FUNCTION_8_10();
  if (v77)
  {
LABEL_96:
    __break(1u);
    goto LABEL_97;
  }
  if (v80 <= -9.22337204e18)
  {
LABEL_97:
    __break(1u);
    goto LABEL_98;
  }
  if (v80 >= OUTLINED_FUNCTION_7_13())
  {
LABEL_98:
    __break(1u);
    goto LABEL_99;
  }
  unint64_t v82 = *(void *)(v81 + 16);
  if (!v82)
  {
LABEL_99:
    __break(1u);
    goto LABEL_100;
  }
  double v83 = *(double *)(v81 + 32);
  if ((~*(void *)&v83 & 0x7FF0000000000000) == 0)
  {
LABEL_100:
    __break(1u);
    goto LABEL_101;
  }
  if (v83 <= -9.22337204e18)
  {
LABEL_101:
    __break(1u);
    goto LABEL_102;
  }
  if (v83 >= 9.22337204e18)
  {
LABEL_102:
    __break(1u);
    goto LABEL_103;
  }
  if (v82 < 2)
  {
LABEL_103:
    __break(1u);
    goto LABEL_104;
  }
  double v84 = *(double *)(v81 + 40);
  swift_bridgeObjectRelease();
  OUTLINED_FUNCTION_8_10();
  if (v77)
  {
LABEL_104:
    __break(1u);
    goto LABEL_105;
  }
  if (v84 <= -9.22337204e18)
  {
LABEL_105:
    __break(1u);
    goto LABEL_106;
  }
  if (v84 >= OUTLINED_FUNCTION_7_13())
  {
LABEL_106:
    __break(1u);
    goto LABEL_107;
  }
  if (!*(void *)(v85 + 16))
  {
LABEL_107:
    __break(1u);
    goto LABEL_108;
  }
  double v86 = *(double *)(v85 + 32);
  swift_bridgeObjectRelease();
  OUTLINED_FUNCTION_8_10();
  if (v77)
  {
LABEL_108:
    __break(1u);
    goto LABEL_109;
  }
  if (v86 <= -9.22337204e18)
  {
LABEL_109:
    __break(1u);
    goto LABEL_110;
  }
  if (v86 < OUTLINED_FUNCTION_7_13())
  {
    Conv2D.init(weight:bias:stride:padding:dilation:groupCount:)();
    outlined destroy of (key: String, value: Any?)((uint64_t)v11, &demangling cache variable for type metadata for Tensor?);
    (*(void (**)(uint64_t, uint64_t))(v73 + 8))(v108, v58);
    (*(void (**)(char *, uint64_t))(v104 + 8))(v103, v105);
    return;
  }
LABEL_110:
  __break(1u);
}

uint64_t outlined init with copy of Tensor?(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Tensor?);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 16))(a2, a1, v4);
  return a2;
}

uint64_t outlined init with take of Tensor?(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Tensor?);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 32))(a2, a1, v4);
  return a2;
}

uint64_t OUTLINED_FUNCTION_0_11()
{
  uint64_t v3 = *(void *)(v1 - 168);
  uint64_t v4 = *(void *)(v1 - 160);
  return specialized Dictionary.subscript.getter(v3, v4, v0);
}

uint64_t OUTLINED_FUNCTION_2_16()
{
  *(void *)(v2 - 168) = v1;
  *(void *)(v2 - 160) = v0;
  return swift_bridgeObjectRetain();
}

void OUTLINED_FUNCTION_3_17()
{
  *(void *)(v0 - 168) = 0;
  *(void *)(v0 - 160) = 0xE000000000000000;
}

void OUTLINED_FUNCTION_4_14()
{
  *(void *)(v2 - 168) = v1;
  *(void *)(v2 - 160) = v0;
}

uint64_t OUTLINED_FUNCTION_5_13()
{
  return swift_bridgeObjectRetain();
}

void OUTLINED_FUNCTION_6_12()
{
  *(void *)(v0 - 168) = 0;
  *(void *)(v0 - 160) = 0xE000000000000000;
  _StringGuts.grow(_:)(40);
}

double OUTLINED_FUNCTION_7_13()
{
  return 9.22337204e18;
}

uint64_t OUTLINED_FUNCTION_9_9()
{
  return 0x68676965772ELL;
}

id AnalyticsReporter.init()()
{
  id v0 = objc_msgSend(self, sel_standardUserDefaults);
  uint64_t v1 = (void *)MEMORY[0x22A674AE0](0xD00000000000002ALL, 0x80000002272D62F0);
  id v2 = objc_msgSend(v0, sel_BOOLForKey_, v1);

  return v2;
}

Swift::Bool __swiftcall AnalyticsReporter.reportDataMetrics(model:metricName:quantity:)(CreateML::ModelType model, Swift::String metricName, Swift::Int quantity)
{
  object = metricName._object;
  uint64_t countAndFlagsBits = metricName._countAndFlagsBits;
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, NSObject)>);
  inited = (__n128 *)swift_initStackObject();
  uint64_t v7 = OUTLINED_FUNCTION_5_14(inited, (__n128)xmmword_2272CB360);
  v7[2].n128_u64[0] = v8;
  v7[2].n128_u64[1] = 0xE800000000000000;
  ModelType.description.getter(model);
  uint64_t v9 = MEMORY[0x22A674AE0]();
  swift_bridgeObjectRelease();
  OUTLINED_FUNCTION_9_10();
  inited[3].n128_u64[0] = v9;
  inited[3].n128_u64[1] = v10;
  inited[4].n128_u64[0] = 0xEA0000000000656DLL;
  uint64_t v11 = MEMORY[0x22A674AE0](countAndFlagsBits, object);
  OUTLINED_FUNCTION_7_14(v11);
  inited[5].n128_u64[1] = 0xE800000000000000;
  v12.super.super.isa = Int._bridgeToObjectiveC()().super.super.isa;
  OUTLINED_FUNCTION_0_12((uint64_t)v12.super.super.isa);
  id v13 = objc_msgSend(self, sel_mainBundle);
  outlined bridged method (ob) of @objc NSBundle.bundleIdentifier.getter(v13);
  OUTLINED_FUNCTION_3_18();
  unint64_t v18 = countAndFlagsBits & 0xFFFFFFFFFFFFLL | 0xD000000000000000;
  if (v14) {
    unint64_t v15 = v18;
  }
  unint64_t v19 = v17 | 0x8000000000000000;
  if (v14) {
    unint64_t v20 = v19;
  }
  else {
    unint64_t v20 = v16;
  }
  MEMORY[0x22A674AE0](v15, v20);
  OUTLINED_FUNCTION_18_1();
  OUTLINED_FUNCTION_8_11();
  Dictionary.init(dictionaryLiteral:)();
  OUTLINED_FUNCTION_1_18(v18 | 0xB, (uint64_t)"com.apple.createml.data_metrics");
  OUTLINED_FUNCTION_6_13();
  return v20 & 1;
}

Swift::Bool __swiftcall AnalyticsReporter.reportDataMetrics(model:metricName:quantity:)(CreateML::ModelType model, Swift::String metricName, Swift::Float quantity)
{
  object = metricName._object;
  uint64_t countAndFlagsBits = metricName._countAndFlagsBits;
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, NSObject)>);
  inited = (__n128 *)swift_initStackObject();
  OUTLINED_FUNCTION_2_17(inited, (__n128)xmmword_2272CB360);
  uint64_t v8 = v7;
  uint64_t v9 = MEMORY[0x22A674AE0]();
  swift_bridgeObjectRelease();
  OUTLINED_FUNCTION_9_10();
  inited[3].n128_u64[0] = v9;
  inited[3].n128_u64[1] = v10;
  inited[4].n128_u64[0] = 0xEA0000000000656DLL;
  uint64_t v11 = MEMORY[0x22A674AE0](countAndFlagsBits, object);
  OUTLINED_FUNCTION_7_14(v11);
  inited[5].n128_u64[1] = v3;
  v12.super.super.isa = Float._bridgeToObjectiveC()().super.super.isa;
  OUTLINED_FUNCTION_0_12((uint64_t)v12.super.super.isa);
  id v13 = objc_msgSend(self, sel_mainBundle);
  outlined bridged method (ob) of @objc NSBundle.bundleIdentifier.getter(v13);
  OUTLINED_FUNCTION_3_18();
  unint64_t v18 = v8 & 0xFFFFFFFFFFFFLL | 0xD000000000000000;
  if (v14) {
    unint64_t v15 = v18;
  }
  unint64_t v19 = v17 | 0x8000000000000000;
  if (v14) {
    unint64_t v20 = v19;
  }
  else {
    unint64_t v20 = v16;
  }
  MEMORY[0x22A674AE0](v15, v20);
  OUTLINED_FUNCTION_18_1();
  OUTLINED_FUNCTION_8_11();
  Dictionary.init(dictionaryLiteral:)();
  OUTLINED_FUNCTION_1_18(v18 | 0xB, (uint64_t)"com.apple.createml.data_metrics");
  OUTLINED_FUNCTION_6_13();
  return v20 & 1;
}

Swift::Bool __swiftcall AnalyticsReporter.reportParameterSettings(model:parameterName:parameterValue:)(CreateML::ModelType model, Swift::String parameterName, Swift::String parameterValue)
{
  object = parameterValue._object;
  uint64_t countAndFlagsBits = parameterValue._countAndFlagsBits;
  unint64_t v5 = (unint64_t)parameterName._object;
  uint64_t v6 = parameterName._countAndFlagsBits;
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, NSObject)>);
  inited = (__n128 *)swift_initStackObject();
  uint64_t v9 = OUTLINED_FUNCTION_5_14(inited, (__n128)xmmword_2272CB360);
  v9[2].n128_u64[0] = v10;
  v9[2].n128_u64[1] = 0xE800000000000000;
  ModelType.description.getter(model);
  uint64_t v11 = MEMORY[0x22A674AE0]();
  swift_bridgeObjectRelease();
  inited[3].n128_u64[0] = v11;
  strcpy(&inited[3].n128_i8[8], "ParameterName");
  inited[4].n128_u16[3] = -4864;
  inited[4].n128_u64[1] = MEMORY[0x22A674AE0](v6, v5);
  strcpy((char *)&inited[5], "ParameterValue");
  inited[5].n128_u8[15] = -18;
  uint64_t v12 = MEMORY[0x22A674AE0](countAndFlagsBits, object);
  OUTLINED_FUNCTION_0_12(v12);
  id v13 = objc_msgSend(self, sel_mainBundle);
  outlined bridged method (ob) of @objc NSBundle.bundleIdentifier.getter(v13);
  OUTLINED_FUNCTION_3_18();
  unint64_t v18 = v5 & 0xFFFFFFFFFFFFLL | 0xD000000000000000;
  if (v14) {
    unint64_t v15 = v18;
  }
  unint64_t v19 = v17 | 0x8000000000000000;
  if (v14) {
    unint64_t v20 = v19;
  }
  else {
    unint64_t v20 = v16;
  }
  MEMORY[0x22A674AE0](v15, v20);
  OUTLINED_FUNCTION_18_1();
  OUTLINED_FUNCTION_8_11();
  Dictionary.init(dictionaryLiteral:)();
  OUTLINED_FUNCTION_1_18(v18 + 16, (uint64_t)"com.apple.createml.parameter_setting");
  OUTLINED_FUNCTION_6_13();
  return v20 & 1;
}

Swift::Bool __swiftcall AnalyticsReporter.analyticsSendEventWrapper(_:_:)(Swift::String a1, Swift::OpaquePointer a2)
{
  unint64_t v3 = (void *)MEMORY[0x22A674AE0](a1._countAndFlagsBits, a1._object);
  uint64_t v4 = (Swift::OpaquePointer *)swift_allocObject();
  v4[2]._rawValue = a2._rawValue;
  v7[4] = partial apply for closure #1 in AnalyticsReporter.analyticsSendEventWrapper(_:_:);
  v7[5] = v4;
  v7[0] = MEMORY[0x263EF8330];
  v7[1] = 1107296256;
  v7[2] = thunk for @escaping @callee_guaranteed () -> (@owned [String : NSObject]?);
  v7[3] = &block_descriptor_3;
  unint64_t v5 = _Block_copy(v7);
  swift_bridgeObjectRetain();
  swift_release();
  LOBYTE(a2._rawValue) = AnalyticsSendEventLazy();
  _Block_release(v5);

  return (Swift::Bool)a2._rawValue;
}

uint64_t AnalyticsReporter.reportTemplateUsed(model:mode:)(uint64_t a1, unsigned __int8 a2)
{
  int v3 = a2;
  ModelType.description.getter(a1);
  uint64_t v15 = v4;
  uint64_t v16 = v5;
  if (v3 != 2)
  {
    if (v3) {
      uint64_t v6 = 0x68636E7953202D20;
    }
    else {
      uint64_t v6 = 0x636E797341202D20;
    }
    if (v3) {
      unint64_t v7 = 0xEE0073756F6E6F72;
    }
    else {
      unint64_t v7 = 0xEF73756F6E6F7268;
    }
    unint64_t v8 = v7;
    String.append(_:)(*(Swift::String *)&v6);
    swift_bridgeObjectRelease();
  }
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, NSObject)>);
  uint64_t inited = swift_initStackObject();
  *(_OWORD *)(inited + 16) = xmmword_2272CB4A0;
  *(void *)(inited + 32) = 0x6574616C706D6554;
  *(void *)(inited + 40) = 0xE800000000000000;
  ModelType.description.getter(a1);
  MEMORY[0x22A674AE0]();
  OUTLINED_FUNCTION_18_1();
  *(void *)(inited + 48) = a1;
  *(void *)(inited + 56) = 0x656C646E7542;
  *(void *)(inited + 64) = 0xE600000000000000;
  id v10 = objc_msgSend(self, sel_mainBundle);
  uint64_t v11 = outlined bridged method (ob) of @objc NSBundle.bundleIdentifier.getter(v10);
  if (v12)
  {
    unint64_t v13 = v12;
  }
  else
  {
    uint64_t v11 = 0xD000000000000014;
    unint64_t v13 = 0x80000002272D6200;
  }
  MEMORY[0x22A674AE0](v11, v13);
  OUTLINED_FUNCTION_18_1();
  *(void *)(inited + 72) = a1;
  *(void *)(inited + 80) = 0x6574616C706D6554;
  *(void *)(inited + 88) = 0xEF65736F62726556;
  MEMORY[0x22A674AE0](v15, v16);
  OUTLINED_FUNCTION_18_1();
  *(void *)(inited + 96) = a1;
  type metadata accessor for NSObject();
  Dictionary.init(dictionaryLiteral:)();
  OUTLINED_FUNCTION_1_18(0xD000000000000020, (uint64_t)"com.apple.createml.template_used");
  OUTLINED_FUNCTION_6_13();
  return v16 & 1;
}

Swift::Bool __swiftcall AnalyticsReporter.reportEventDuration(model:task:startTime:)(CreateML::ModelType model, Swift::String task, Swift::Double startTime)
{
  object = task._object;
  uint64_t countAndFlagsBits = task._countAndFlagsBits;
  double v6 = CFAbsoluteTimeGetCurrent() - startTime;
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, NSObject)>);
  uint64_t inited = (__n128 *)swift_initStackObject();
  OUTLINED_FUNCTION_2_17(inited, (__n128)xmmword_2272CB360);
  uint64_t v9 = v8;
  uint64_t v10 = MEMORY[0x22A674AE0]();
  swift_bridgeObjectRelease();
  inited[3].n128_u64[0] = v10;
  inited[3].n128_u64[1] = 1802723668;
  inited[4].n128_u64[0] = 0xE400000000000000;
  inited[4].n128_u64[1] = MEMORY[0x22A674AE0](countAndFlagsBits, object);
  inited[5].n128_u64[0] = 0x6E6F697461727544;
  inited[5].n128_u64[1] = v3;
  uint64_t v11 = MEMORY[0x22A674EA0](v6);
  OUTLINED_FUNCTION_0_12(v11);
  id v12 = objc_msgSend(self, sel_mainBundle);
  outlined bridged method (ob) of @objc NSBundle.bundleIdentifier.getter(v12);
  OUTLINED_FUNCTION_3_18();
  unint64_t v17 = v9 & 0xFFFFFFFFFFFFLL | 0xD000000000000000;
  if (v13) {
    unint64_t v14 = v17;
  }
  unint64_t v18 = v16 | 0x8000000000000000;
  if (v13) {
    unint64_t v19 = v18;
  }
  else {
    unint64_t v19 = v15;
  }
  MEMORY[0x22A674AE0](v14, v19);
  OUTLINED_FUNCTION_18_1();
  OUTLINED_FUNCTION_8_11();
  Dictionary.init(dictionaryLiteral:)();
  OUTLINED_FUNCTION_1_18(v17 + 13, (uint64_t)"com.apple.createml.event_duration");
  OUTLINED_FUNCTION_6_13();
  return v19 & 1;
}

uint64_t outlined bridged method (ob) of @objc NSBundle.bundleIdentifier.getter(void *a1)
{
  id v2 = objc_msgSend(a1, sel_bundleIdentifier);

  if (!v2) {
    return 0;
  }
  uint64_t v3 = static String._unconditionallyBridgeFromObjectiveC(_:)();

  return v3;
}

unint64_t type metadata accessor for NSObject()
{
  unint64_t result = lazy cache variable for type metadata for NSObject;
  if (!lazy cache variable for type metadata for NSObject)
  {
    self;
    unint64_t result = swift_getObjCClassMetadata();
    atomic_store(result, (unint64_t *)&lazy cache variable for type metadata for NSObject);
  }
  return result;
}

uint64_t sub_2270D6A14()
{
  swift_bridgeObjectRelease();

  return MEMORY[0x270FA0238](v0, 24, 7);
}

uint64_t partial apply for closure #1 in AnalyticsReporter.analyticsSendEventWrapper(_:_:)()
{
  return swift_bridgeObjectRetain();
}

uint64_t block_copy_helper_1(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = *(void *)(a2 + 40);
  *(void *)(a1 + 32) = *(void *)(a2 + 32);
  *(void *)(a1 + 40) = v2;
  return swift_retain();
}

uint64_t block_destroy_helper_1()
{
  return swift_release();
}

uint64_t OUTLINED_FUNCTION_0_12(uint64_t result)
{
  v1[12] = result;
  v1[13] = 0x656C646E7542;
  v1[14] = 0xE600000000000000;
  return result;
}

BOOL OUTLINED_FUNCTION_1_18@<W0>(uint64_t a1@<X0>, uint64_t a2@<X8>)
{
  unint64_t v4 = (a2 - 32) | 0x8000000000000000;
  return AnalyticsReporter.analyticsSendEventWrapper(_:_:)(*(Swift::String *)&a1, v2);
}

void OUTLINED_FUNCTION_2_17(__n128 *a1, __n128 a2)
{
  a1[1] = a2;
  a1[2].n128_u64[0] = 0x6574616C706D6554;
  a1[2].n128_u64[1] = 0xE800000000000000;
  ModelType.description.getter(v2);
}

__n128 *OUTLINED_FUNCTION_5_14(__n128 *result, __n128 a2)
{
  result[1] = a2;
  return result;
}

uint64_t OUTLINED_FUNCTION_6_13()
{
  return swift_bridgeObjectRelease();
}

uint64_t OUTLINED_FUNCTION_7_14(uint64_t result)
{
  *(void *)(v1 + 72) = result;
  *(void *)(v1 + 80) = 0x797469746E617551;
  return result;
}

unint64_t OUTLINED_FUNCTION_8_11()
{
  *(void *)(v0 + 120) = v1;
  return type metadata accessor for NSObject();
}

Swift::Void __swiftcall __spoils<CF,ZF,NF,VF,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13,X14,X15,X16,X17,X21,Q0,Q1,Q2,Q3,Q4,Q5,Q6,Q7,Q16,Q17,Q18,Q19,Q20,Q21,Q22,Q23,Q24,Q25,Q26,Q27,Q28,Q29,Q30,Q31> DataFrame.flattenNestedArrays(in:shape:)(Swift::String in, Swift::OpaquePointer shape)
{
  rawValue = shape._rawValue;
  object = in._object;
  uint64_t countAndFlagsBits = in._countAndFlagsBits;
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Any?]>);
  OUTLINED_FUNCTION_0();
  uint64_t v54 = v5;
  uint64_t v55 = v4;
  MEMORY[0x270FA5388](v4);
  v53 = (char *)&v49 - ((v6 + 15) & 0xFFFFFFFFFFFFFFF0);
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Any]>);
  OUTLINED_FUNCTION_0();
  v56 = v8;
  uint64_t v57 = v7;
  MEMORY[0x270FA5388](v7);
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<MLShapedArray<Double>>);
  OUTLINED_FUNCTION_0();
  uint64_t v50 = v10;
  uint64_t v51 = v9;
  uint64_t v11 = MEMORY[0x270FA5388](v9);
  uint64_t v52 = (char *)&v49 - ((v12 + 15) & 0xFFFFFFFFFFFFFFF0);
  MEMORY[0x270FA5388](v11);
  unint64_t v14 = (char *)&v49 - v13;
  type metadata accessor for AnyColumn();
  OUTLINED_FUNCTION_0();
  uint64_t v58 = v16;
  uint64_t v59 = v15;
  uint64_t v17 = MEMORY[0x270FA5388](v15);
  unint64_t v19 = (char *)&v49 - ((v18 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v20 = MEMORY[0x270FA5388](v17);
  uint64_t v22 = (char *)&v49 - v21;
  MEMORY[0x270FA5388](v20);
  MEMORY[0x22A672220](countAndFlagsBits, object);
  uint64_t v23 = AnyColumn.wrappedElementType.getter();
  if (v23 == __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Any]))
  {
    uint64_t v33 = DataFrame.subscript.getter();
    MEMORY[0x270FA5388](v33);
    *(&v49 - 2) = (uint64_t)rawValue;
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Double>);
    uint64_t v34 = v63;
    Column.mapNonNil<A>(_:)();
    if (v34)
    {
      uint64_t v35 = OUTLINED_FUNCTION_3_19();
      v36(v35);
      goto LABEL_12;
    }
    uint64_t v63 = 0;
    uint64_t v41 = OUTLINED_FUNCTION_3_19();
    v42(v41);
    uint64_t v43 = v51;
    Column.eraseToAnyColumn()();
LABEL_11:
    (*(void (**)(char *, uint64_t))(v50 + 8))(v14, v43);
    swift_bridgeObjectRetain();
    MEMORY[0x22A672230](v22, countAndFlagsBits, object);
    goto LABEL_12;
  }
  uint64_t v24 = (uint64_t)rawValue;
  uint64_t v25 = AnyColumn.wrappedElementType.getter();
  if (v25 == __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Any?]))
  {
    v56 = object;
    uint64_t v57 = countAndFlagsBits;
    uint64_t v37 = DataFrame.subscript.getter();
    MEMORY[0x270FA5388](v37);
    *(&v49 - 2) = v24;
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Double>);
    unint64_t v14 = v52;
    uint64_t v38 = v63;
    Column.mapNonNil<A>(_:)();
    if (v38)
    {
      uint64_t v39 = OUTLINED_FUNCTION_1_19();
      v40(v39);
      goto LABEL_12;
    }
    uint64_t v63 = 0;
    uint64_t v44 = OUTLINED_FUNCTION_1_19();
    v45(v44);
    uint64_t v46 = v51;
    Column.eraseToAnyColumn()();
    uint64_t v22 = v19;
    uint64_t v43 = v46;
    object = v56;
    uint64_t countAndFlagsBits = v57;
    goto LABEL_11;
  }
  uint64_t v26 = AnyColumn.wrappedElementType.getter();
  if (v26 != __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Double>))
  {
    uint64_t v61 = 0;
    unint64_t v62 = 0xE000000000000000;
    _StringGuts.grow(_:)(73);
    v27._uint64_t countAndFlagsBits = 0x27206E6D756C6F43;
    v27._object = (void *)0xE800000000000000;
    String.append(_:)(v27);
    v28._uint64_t countAndFlagsBits = countAndFlagsBits;
    v28._object = object;
    String.append(_:)(v28);
    v29._object = (void *)0x80000002272D6320;
    v29._uint64_t countAndFlagsBits = 0xD00000000000003FLL;
    String.append(_:)(v29);
    uint64_t v30 = v61;
    unint64_t v31 = v62;
    lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError();
    *(void *)uint64_t v32 = v30;
    *(void *)(v32 + 8) = v31;
    *(_OWORD *)(v32 + 16) = 0u;
    *(_OWORD *)(v32 + 32) = 0u;
    *(unsigned char *)(v32 + 48) = 1;
    swift_willThrow();
  }
LABEL_12:
  uint64_t v47 = OUTLINED_FUNCTION_2_18();
  v48(v47);
}

uint64_t closure #1 in DataFrame.flattenNestedArrays(in:shape:)@<X0>(uint64_t *a1@<X0>, uint64_t a2@<X1>, uint64_t (*a3)(uint64_t, uint64_t)@<X2>, uint64_t a4@<X8>)
{
  uint64_t v8 = *a1;
  swift_bridgeObjectRetain();
  swift_bridgeObjectRetain();
  uint64_t result = a3(a2, v8);
  if (!v4)
  {
    uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Double>);
    return __swift_storeEnumTagSinglePayload(a4, 0, 1, v10);
  }
  return result;
}

uint64_t partial apply for closure #2 in DataFrame.flattenNestedArrays(in:shape:)@<X0>(uint64_t *a1@<X0>, uint64_t a2@<X8>)
{
  return closure #1 in DataFrame.flattenNestedArrays(in:shape:)(a1, *(void *)(v2 + 16), (uint64_t (*)(uint64_t, uint64_t))MLShapedArray<>.init(shape:nestedArray:), a2);
}

uint64_t partial apply for closure #1 in DataFrame.flattenNestedArrays(in:shape:)@<X0>(uint64_t *a1@<X0>, uint64_t a2@<X8>)
{
  return closure #1 in DataFrame.flattenNestedArrays(in:shape:)(a1, *(void *)(v2 + 16), (uint64_t (*)(uint64_t, uint64_t))MLShapedArray<>.init(shape:nestedArray:), a2);
}

uint64_t OUTLINED_FUNCTION_1_19()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_2_18()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_3_19()
{
  return v0;
}

uint64_t CMLParameters.setOptions(dictionary:)()
{
  type metadata accessor for CMLFeatureValue();
  uint64_t v1 = swift_retain();
  uint64_t result = CMLFeatureValue.__allocating_init(_:)(v1);
  if (!v0)
  {
    CMLParameters.add(key:featureValue:)(6, result);
    return swift_release();
  }
  return result;
}

uint64_t MLImageClassifier.write(to:metadata:)(uint64_t a1, uint64_t *a2)
{
  uint64_t v3 = type metadata accessor for MLImageClassifier.Model();
  MEMORY[0x270FA5388](v3 - 8);
  OUTLINED_FUNCTION_33_0();
  uint64_t v32 = v4;
  type metadata accessor for Model();
  OUTLINED_FUNCTION_0();
  uint64_t v24 = v5;
  uint64_t v25 = v6;
  MEMORY[0x270FA5388](v5);
  OUTLINED_FUNCTION_33_0();
  uint64_t v29 = v7;
  uint64_t v8 = type metadata accessor for MLImageClassifier.FeatureExtractorType(0);
  MEMORY[0x270FA5388](v8 - 8);
  OUTLINED_FUNCTION_33_0();
  uint64_t v31 = v9;
  uint64_t v10 = type metadata accessor for MLImageClassifier.ModelParameters.ModelAlgorithmType();
  MEMORY[0x270FA5388](v10 - 8);
  OUTLINED_FUNCTION_3_0();
  uint64_t v13 = v12 - v11;
  uint64_t v14 = type metadata accessor for URL();
  OUTLINED_FUNCTION_0();
  uint64_t v30 = v15;
  MEMORY[0x270FA5388](v16);
  OUTLINED_FUNCTION_3_0();
  uint64_t v19 = v18 - v17;
  uint64_t v26 = a2[1];
  uint64_t v27 = *a2;
  uint64_t result = static _ValidationUtilities.validateWriteLocation(atURL:defaultName:fileExtension:)(a1, 0x616C436567616D49, (void *)0xEF72656966697373, 0x6C65646F6D6C6DLL, (void *)0xE700000000000000, v18 - v17);
  if (!v34)
  {
    MLImageClassifier.ModelParameters.algorithm.getter(v13);
    outlined init with take of MLImageClassifier.FeatureExtractorType(v13, v31);
    uint64_t v21 = type metadata accessor for MLImageClassifier();
    outlined init with copy of MLImageClassifier.Model(v28 + *(int *)(v21 + 32), v32);
    uint64_t v22 = v26;
    if (!v26)
    {
      uint64_t v23 = NSFullUserName();
      static String._unconditionallyBridgeFromObjectiveC(_:)();

      uint64_t v22 = 0;
    }
    outlined copy of MLModelMetadata?(v27, v22);
    MLImageClassifier.Model.export(metadata:featureExtractorType:)();
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    outlined destroy of MLImageClassifier.Model(v32, (uint64_t (*)(void))type metadata accessor for MLImageClassifier.Model);
    Model.write(to:)();
    (*(void (**)(uint64_t, uint64_t))(v25 + 8))(v29, v24);
    outlined destroy of MLImageClassifier.Model(v31, type metadata accessor for MLImageClassifier.FeatureExtractorType);
    return (*(uint64_t (**)(uint64_t, uint64_t))(v30 + 8))(v19, v14);
  }
  return result;
}

uint64_t outlined init with take of MLImageClassifier.FeatureExtractorType(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = type metadata accessor for MLImageClassifier.FeatureExtractorType(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 32))(a2, a1, v4);
  return a2;
}

uint64_t outlined init with copy of MLImageClassifier.Model(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = type metadata accessor for MLImageClassifier.Model();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 16))(a2, a1, v4);
  return a2;
}

uint64_t outlined destroy of MLImageClassifier.Model(uint64_t a1, uint64_t (*a2)(void))
{
  uint64_t v3 = a2(0);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v3 - 8) + 8))(a1, v3);
  return a1;
}

uint64_t MLImageClassifier.write(toFile:metadata:)(uint64_t a1, void *a2, uint64_t *a3)
{
  uint64_t v7 = type metadata accessor for URL();
  OUTLINED_FUNCTION_0();
  uint64_t v24 = v8;
  MEMORY[0x270FA5388](v9);
  OUTLINED_FUNCTION_3_0();
  uint64_t v12 = v11 - v10;
  uint64_t v14 = *a3;
  uint64_t v13 = a3[1];
  uint64_t v15 = a3[3];
  uint64_t v22 = a3[4];
  uint64_t v23 = a3[2];
  uint64_t v20 = a3[6];
  uint64_t v21 = a3[5];
  uint64_t v16 = a3[7];
  uint64_t v17 = a3[8];
  uint64_t v19 = v16;
  uint64_t result = static _ValidationUtilities.validateWriteLocation(atPath:defaultName:)(a1, a2, 0x616C436567616D49, (void *)0xEF72656966697373);
  if (!v3)
  {
    v25[0] = v14;
    v25[1] = v13;
    v25[2] = v23;
    v25[3] = v15;
    v25[4] = v22;
    v25[5] = v21;
    v25[6] = v20;
    v25[7] = v19;
    v25[8] = v17;
    MLImageClassifier.write(to:metadata:)(v12, v25);
    return (*(uint64_t (**)(uint64_t, uint64_t))(v24 + 8))(v12, v7);
  }
  return result;
}

uint64_t MLSoundClassifier.ModelParameters.validation.getter@<X0>(uint64_t a1@<X8>)
{
  return outlined init with copy of MLSoundClassifier.ModelParameters.ValidationData(v1, a1);
}

uint64_t outlined init with copy of MLSoundClassifier.ModelParameters.ValidationData(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 16))(a2, a1, v4);
  return a2;
}

uint64_t MLSoundClassifier.ModelParameters.validation.setter(uint64_t a1)
{
  return outlined assign with take of MLSoundClassifier.ModelParameters.ValidationData(a1, v1);
}

uint64_t outlined assign with take of MLSoundClassifier.ModelParameters.ValidationData(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 40))(a2, a1, v4);
  return a2;
}

uint64_t (*MLSoundClassifier.ModelParameters.validation.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLSoundClassifier.ModelParameters.maxIterations.getter()
{
  return *(void *)(v0 + *(int *)(type metadata accessor for MLSoundClassifier.ModelParameters() + 20));
}

uint64_t type metadata accessor for MLSoundClassifier.ModelParameters()
{
  uint64_t result = type metadata singleton initialization cache for MLSoundClassifier.ModelParameters;
  if (!type metadata singleton initialization cache for MLSoundClassifier.ModelParameters) {
    return swift_getSingletonMetadata();
  }
  return result;
}

uint64_t MLSoundClassifier.ModelParameters.maxIterations.setter(uint64_t a1)
{
  uint64_t result = type metadata accessor for MLSoundClassifier.ModelParameters();
  *(void *)(v1 + *(int *)(result + 20)) = a1;
  return result;
}

uint64_t (*MLSoundClassifier.ModelParameters.maxIterations.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

double MLSoundClassifier.ModelParameters.overlapFactor.getter()
{
  return *(double *)(v0 + *(int *)(type metadata accessor for MLSoundClassifier.ModelParameters() + 24));
}

uint64_t MLSoundClassifier.ModelParameters.overlapFactor.setter(double a1)
{
  uint64_t result = type metadata accessor for MLSoundClassifier.ModelParameters();
  *(double *)(v1 + *(int *)(result + 24)) = a1;
  return result;
}

uint64_t (*MLSoundClassifier.ModelParameters.overlapFactor.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

void MLSoundClassifier.ModelParameters.algorithm.getter(uint64_t a1@<X8>)
{
  uint64_t v3 = type metadata accessor for MLSoundClassifier.ModelParameters();
  outlined init with copy of Any?(v1 + *(int *)(v3 + 28), (uint64_t)v8);
  if (!v9)
  {
    outlined destroy of Any?((uint64_t)v8);
    goto LABEL_5;
  }
  if (!OUTLINED_FUNCTION_2_19())
  {
LABEL_5:
    OUTLINED_FUNCTION_6_14();
    goto LABEL_6;
  }
  uint64_t v4 = v6;
  char v5 = v7;
LABEL_6:
  *(void *)a1 = v4;
  *(unsigned char *)(a1 + 8) = v5;
}

void key path getter for MLSoundClassifier.ModelParameters.algorithm : MLSoundClassifier.ModelParameters(uint64_t a1@<X8>)
{
  MLSoundClassifier.ModelParameters.algorithm.getter((uint64_t)&v3);
  char v2 = v4;
  *(void *)a1 = v3;
  *(unsigned char *)(a1 + 8) = v2;
}

uint64_t key path setter for MLSoundClassifier.ModelParameters.algorithm : MLSoundClassifier.ModelParameters(uint64_t a1)
{
  char v1 = *(unsigned char *)(a1 + 8);
  uint64_t v3 = *(void *)a1;
  char v4 = v1;
  return MLSoundClassifier.ModelParameters.algorithm.setter(&v3);
}

uint64_t MLSoundClassifier.ModelParameters.algorithm.setter(uint64_t *a1)
{
  uint64_t v2 = *a1;
  char v3 = *((unsigned char *)a1 + 8);
  uint64_t v8 = &type metadata for MLSoundClassifier.ModelParameters.ModelAlgorithmType;
  uint64_t v6 = v2;
  char v7 = v3;
  uint64_t v4 = type metadata accessor for MLSoundClassifier.ModelParameters();
  return outlined assign with take of Any?((uint64_t)&v6, v1 + *(int *)(v4 + 28));
}

void (*MLSoundClassifier.ModelParameters.algorithm.modify(void *a1))(uint64_t a1)
{
  char v3 = malloc(0x48uLL);
  *a1 = v3;
  v3[8] = v1;
  uint64_t v4 = *(int *)(type metadata accessor for MLSoundClassifier.ModelParameters() + 28);
  *((_DWORD *)v3 + 11) = v4;
  outlined init with copy of Any?(v1 + v4, (uint64_t)v3);
  if (!v3[3])
  {
    outlined destroy of Any?((uint64_t)v3);
    goto LABEL_5;
  }
  if ((swift_dynamicCast() & 1) == 0)
  {
LABEL_5:
    OUTLINED_FUNCTION_6_14();
    goto LABEL_6;
  }
  uint64_t v5 = v3[6];
  char v6 = *((unsigned char *)v3 + 56);
LABEL_6:
  v3[4] = v5;
  *((unsigned char *)v3 + 40) = v6;
  return MLSoundClassifier.ModelParameters.algorithm.modify;
}

void MLSoundClassifier.ModelParameters.algorithm.modify(uint64_t a1)
{
  uint64_t v1 = *(void **)a1;
  uint64_t v2 = *(void *)(*(void *)a1 + 32);
  char v3 = *(unsigned char *)(*(void *)a1 + 40);
  uint64_t v4 = *(void *)(*(void *)a1 + 64) + *(int *)(*(void *)a1 + 44);
  v1[3] = &type metadata for MLSoundClassifier.ModelParameters.ModelAlgorithmType;
  void *v1 = v2;
  *((unsigned char *)v1 + 8) = v3;
  outlined assign with take of Any?((uint64_t)v1, v4);

  free(v1);
}

double MLSoundClassifier.ModelParameters.featureExtractionTimeWindowSize.getter()
{
  uint64_t v1 = type metadata accessor for MLSoundClassifier.ModelParameters();
  outlined init with copy of Any?(v0 + *(int *)(v1 + 28), (uint64_t)v6);
  if (v7)
  {
    if ((OUTLINED_FUNCTION_2_19() & 1) != 0 && (v5 & 1) == 0 && v4 == 1) {
      return 0.975;
    }
  }
  else
  {
    outlined destroy of Any?((uint64_t)v6);
  }
  uint64_t v3 = v0 + *(int *)(v1 + 32);
  double result = *(double *)v3;
  if (*(unsigned char *)(v3 + 8)) {
    return 0.975;
  }
  return result;
}

uint64_t MLSoundClassifier.ModelParameters.featureExtractionTimeWindowSize.setter(double a1)
{
  uint64_t result = type metadata accessor for MLSoundClassifier.ModelParameters();
  uint64_t v4 = v1 + *(int *)(result + 32);
  *(double *)uint64_t v4 = a1;
  *(unsigned char *)(v4 + 8) = 0;
  return result;
}

uint64_t (*MLSoundClassifier.ModelParameters.featureExtractionTimeWindowSize.modify(uint64_t a1))(uint64_t *a1)
{
  *(void *)(a1 + 8) = v1;
  *(double *)a1 = MLSoundClassifier.ModelParameters.featureExtractionTimeWindowSize.getter();
  return MLSoundClassifier.ModelParameters.featureExtractionTimeWindowSize.modify;
}

uint64_t MLSoundClassifier.ModelParameters.featureExtractionTimeWindowSize.modify(uint64_t *a1)
{
  uint64_t v2 = *a1;
  uint64_t v1 = a1[1];
  uint64_t result = type metadata accessor for MLSoundClassifier.ModelParameters();
  uint64_t v4 = v1 + *(int *)(result + 32);
  *(void *)uint64_t v4 = v2;
  *(unsigned char *)(v4 + 8) = 0;
  return result;
}

uint64_t MLSoundClassifier.ModelParameters.init(validation:maxIterations:overlapFactor:algorithm:)()
{
  OUTLINED_FUNCTION_9_11();
  uint64_t v3 = *v2;
  char v4 = *((unsigned char *)v2 + 8);
  uint64_t v5 = type metadata accessor for MLSoundClassifier.ModelParameters();
  char v6 = (_OWORD *)(v1 + *(int *)(v5 + 28));
  *char v6 = 0u;
  v6[1] = 0u;
  uint64_t v7 = OUTLINED_FUNCTION_0_13(v5);
  outlined init with copy of MLSoundClassifier.ModelParameters.ValidationData(v7, v8);
  OUTLINED_FUNCTION_8_12();
  uint64_t v12 = &type metadata for MLSoundClassifier.ModelParameters.ModelAlgorithmType;
  uint64_t v10 = v3;
  char v11 = v4;
  outlined assign with take of Any?((uint64_t)&v10, (uint64_t)v6);
  return outlined destroy of MLSoundClassifier.ModelParameters.ValidationData(v0);
}

uint64_t outlined destroy of MLSoundClassifier.ModelParameters.ValidationData(uint64_t a1)
{
  uint64_t v2 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData();
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v2 - 8) + 8))(a1, v2);
  return a1;
}

void MLSoundClassifier.ModelParameters.init(validation:maxIterations:overlapFactor:)()
{
  OUTLINED_FUNCTION_9_11();
  uint64_t v1 = type metadata accessor for MLSoundClassifier.ModelParameters();
  uint64_t v2 = (_OWORD *)(v0 + *(int *)(v1 + 28));
  *uint64_t v2 = 0u;
  v2[1] = 0u;
  uint64_t v3 = OUTLINED_FUNCTION_0_13(v1);
  outlined init with take of MLSoundClassifier.ModelParameters.ValidationData(v3, v4);
  OUTLINED_FUNCTION_8_12();
}

uint64_t outlined init with take of MLSoundClassifier.ModelParameters.ValidationData(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 32))(a2, a1, v4);
  return a2;
}

uint64_t MLSoundClassifier.ModelParameters.init(validation:maxIterations:overlapFactor:algorithm:featureExtractionTimeWindowSize:)@<X0>(uint64_t a1@<X0>, uint64_t a2@<X1>, uint64_t a3@<X2>, uint64_t a4@<X8>, double a5@<D0>, double a6@<D1>)
{
  uint64_t v11 = *(void *)a3;
  char v12 = *(unsigned char *)(a3 + 8);
  uint64_t v13 = (int *)type metadata accessor for MLSoundClassifier.ModelParameters();
  uint64_t v14 = (_OWORD *)(a4 + v13[7]);
  *uint64_t v14 = 0u;
  v14[1] = 0u;
  uint64_t v15 = a4 + v13[8];
  *(void *)uint64_t v15 = 0;
  *(unsigned char *)(v15 + 8) = 1;
  *(void *)(a4 + v13[9]) = 32;
  outlined init with copy of MLSoundClassifier.ModelParameters.ValidationData(a1, a4);
  *(void *)(a4 + v13[5]) = a2;
  *(double *)(a4 + v13[6]) = a5;
  uint64_t v32 = &type metadata for MLSoundClassifier.ModelParameters.ModelAlgorithmType;
  uint64_t v30 = v11;
  LOBYTE(v31) = v12;
  outlined assign with take of Any?((uint64_t)&v30, (uint64_t)v14);
  *(double *)uint64_t v15 = a6;
  *(unsigned char *)(v15 + 8) = 0;
  if (a6 < 0.5)
  {
    OUTLINED_FUNCTION_5_15();
    v16._uint64_t countAndFlagsBits = OUTLINED_FUNCTION_3_20();
    v16._object = (void *)0x80000002272D63E0;
    String.append(_:)(v16);
    OUTLINED_FUNCTION_3_1();
    OUTLINED_FUNCTION_4_15((uint64_t)". Clamping it to ");
    OUTLINED_FUNCTION_3_1();
    v17._uint64_t countAndFlagsBits = 46;
    v17._object = (void *)0xE100000000000000;
    String.append(_:)(v17);
    uint64_t v18 = v30;
    uint64_t v19 = v31;
    os_log_type_t v20 = static os_log_type_t.default.getter();
    v21._uint64_t countAndFlagsBits = v18;
    v21._object = v19;
    log(_:type:)(v21, v20);
    swift_bridgeObjectRelease();
    uint64_t result = outlined destroy of MLSoundClassifier.ModelParameters.ValidationData(a1);
    uint64_t v23 = 0x3FE0000000000000;
LABEL_5:
    *(void *)uint64_t v15 = v23;
    *(unsigned char *)(v15 + 8) = 0;
    return result;
  }
  if (a6 > 15.0)
  {
    OUTLINED_FUNCTION_5_15();
    v24._uint64_t countAndFlagsBits = OUTLINED_FUNCTION_3_20();
    v24._object = (void *)0x80000002272D6360;
    String.append(_:)(v24);
    OUTLINED_FUNCTION_3_1();
    OUTLINED_FUNCTION_4_15((uint64_t)". Clamping it to ");
    OUTLINED_FUNCTION_3_1();
    v25._uint64_t countAndFlagsBits = 46;
    v25._object = (void *)0xE100000000000000;
    String.append(_:)(v25);
    uint64_t v26 = v30;
    uint64_t v27 = v31;
    os_log_type_t v28 = static os_log_type_t.default.getter();
    v29._uint64_t countAndFlagsBits = v26;
    v29._object = v27;
    log(_:type:)(v29, v28);
    swift_bridgeObjectRelease();
    uint64_t result = outlined destroy of MLSoundClassifier.ModelParameters.ValidationData(a1);
    uint64_t v23 = 0x402E000000000000;
    goto LABEL_5;
  }
  return outlined destroy of MLSoundClassifier.ModelParameters.ValidationData(a1);
}

uint64_t MLSoundClassifier.ModelParameters.FeaturePrintType.description.getter()
{
  return 0x756F732065707974;
}

void MLSoundClassifier.ModelParameters.FeaturePrintType.hash(into:)()
{
}

uint64_t static MLSoundClassifier.ModelParameters.FeaturePrintType.== infix(_:_:)()
{
  return 1;
}

Swift::Int MLSoundClassifier.ModelParameters.FeaturePrintType.hashValue.getter()
{
  return Hasher._finalize()();
}

Swift::Int protocol witness for Hashable.hashValue.getter in conformance MLSoundClassifier.ModelParameters.FeaturePrintType()
{
  return MLSoundClassifier.ModelParameters.FeaturePrintType.hashValue.getter();
}

void protocol witness for Hashable.hash(into:) in conformance MLSoundClassifier.ModelParameters.FeaturePrintType()
{
}

uint64_t protocol witness for CustomStringConvertible.description.getter in conformance MLSoundClassifier.ModelParameters.FeaturePrintType()
{
  return 0x756F732065707974;
}

Swift::Void __swiftcall __spoils<CF,ZF,NF,VF,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13,X14,X15,X16,X17,X21,Q0,Q1,Q2,Q3,Q4,Q5,Q6,Q7,Q16,Q17,Q18,Q19,Q20,Q21,Q22,Q23,Q24,Q25,Q26,Q27,Q28,Q29,Q30,Q31> MLSoundClassifier.ModelParameters.validate()()
{
  uint64_t v1 = type metadata accessor for MLSoundClassifier.ModelParameters();
  outlined init with copy of Any?(v0 + *(int *)(v1 + 28), (uint64_t)&v6);
  if (!v8)
  {
    outlined destroy of Any?((uint64_t)&v6);
    goto LABEL_5;
  }
  if ((swift_dynamicCast() & 1) == 0)
  {
LABEL_5:
    OUTLINED_FUNCTION_6_14();
    goto LABEL_6;
  }
  uint64_t v2 = v4;
  char v3 = v5;
LABEL_6:
  uint64_t v6 = v2;
  char v7 = v3;
  MLSoundClassifier.ModelParameters.FeatureExtractorType.validate()();
}

uint64_t MLSoundClassifier.ModelParameters.description.getter()
{
  _StringGuts.grow(_:)(19);
  swift_bridgeObjectRelease();
  uint64_t v1 = type metadata accessor for MLSoundClassifier.ModelParameters();
  v2._uint64_t countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter();
  String.append(_:)(v2);
  swift_bridgeObjectRelease();
  v3._uint64_t countAndFlagsBits = 10;
  v3._object = (void *)0xE100000000000000;
  String.append(_:)(v3);
  _StringGuts.grow(_:)(19);
  v4._object = (void *)0x80000002272D6440;
  v4._uint64_t countAndFlagsBits = 0xD000000000000010;
  String.append(_:)(v4);
  Double.write<A>(to:)();
  v5._uint64_t countAndFlagsBits = 10;
  v5._object = (void *)0xE100000000000000;
  String.append(_:)(v5);
  swift_bridgeObjectRetain();
  v6._uint64_t countAndFlagsBits = 0;
  v6._object = (void *)0xE000000000000000;
  String.append(_:)(v6);
  swift_bridgeObjectRelease();
  swift_bridgeObjectRelease();
  v17._uint64_t countAndFlagsBits = 0;
  v17._object = (void *)0xE000000000000000;
  _StringGuts.grow(_:)(18);
  swift_bridgeObjectRelease();
  unint64_t v19 = 0xD000000000000010;
  unint64_t v20 = 0x80000002272D6460;
  outlined init with copy of Any?(v0 + *(int *)(v1 + 28), (uint64_t)&v17);
  if (!v18)
  {
    outlined destroy of Any?((uint64_t)&v17);
    goto LABEL_5;
  }
  if ((OUTLINED_FUNCTION_2_19() & 1) == 0)
  {
LABEL_5:
    OUTLINED_FUNCTION_6_14();
    goto LABEL_6;
  }
  uint64_t v7 = v15;
  char v8 = v16;
LABEL_6:
  v17._uint64_t countAndFlagsBits = v7;
  LOBYTE(v17._object) = v8;
  v17._uint64_t countAndFlagsBits = MLSoundClassifier.ModelParameters.FeatureExtractorType.description.getter();
  v17._object = v9;
  swift_bridgeObjectRetain();
  v10._uint64_t countAndFlagsBits = 0xD000000000000012;
  v10._object = (void *)0x80000002272D6480;
  String.append(_:)(v10);
  swift_bridgeObjectRelease();
  String.append(_:)(v17);
  swift_bridgeObjectRelease();
  uint64_t v11 = v19;
  char v12 = (void *)v20;
  v17._uint64_t countAndFlagsBits = 0xD000000000000010;
  v17._object = (void *)0x80000002272D3F00;
  swift_bridgeObjectRetain();
  v13._uint64_t countAndFlagsBits = v11;
  v13._object = v12;
  String.append(_:)(v13);
  swift_bridgeObjectRelease();
  swift_bridgeObjectRelease();
  return v17._countAndFlagsBits;
}

uint64_t MLSoundClassifier.ModelParameters.playgroundDescription.getter@<X0>(uint64_t *a1@<X8>)
{
  uint64_t result = MLSoundClassifier.ModelParameters.description.getter();
  a1[3] = MEMORY[0x263F8D310];
  *a1 = result;
  a1[1] = v3;
  return result;
}

unint64_t lazy protocol witness table accessor for type MLSoundClassifier.ModelParameters.FeaturePrintType and conformance MLSoundClassifier.ModelParameters.FeaturePrintType()
{
  unint64_t result = lazy protocol witness table cache variable for type MLSoundClassifier.ModelParameters.FeaturePrintType and conformance MLSoundClassifier.ModelParameters.FeaturePrintType;
  if (!lazy protocol witness table cache variable for type MLSoundClassifier.ModelParameters.FeaturePrintType and conformance MLSoundClassifier.ModelParameters.FeaturePrintType)
  {
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type MLSoundClassifier.ModelParameters.FeaturePrintType and conformance MLSoundClassifier.ModelParameters.FeaturePrintType);
  }
  return result;
}

void sub_2270D8858(double *a1@<X8>)
{
  *a1 = MLSoundClassifier.ModelParameters.featureExtractionTimeWindowSize.getter();
}

uint64_t sub_2270D8884(double *a1)
{
  return MLSoundClassifier.ModelParameters.featureExtractionTimeWindowSize.setter(*a1);
}

char *initializeBufferWithCopyOfBuffer for MLSoundClassifier.ModelParameters(char *a1, char **a2, int *a3)
{
  int v5 = *(_DWORD *)(*((void *)a3 - 1) + 80);
  if ((v5 & 0x20000) != 0)
  {
    Swift::String v10 = *a2;
    *(void *)a1 = *a2;
    a1 = &v10[(v5 + 16) & ~(unint64_t)v5];
    swift_retain();
    return a1;
  }
  uint64_t v7 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData();
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload();
  if (EnumCaseMultiPayload == 2)
  {
    *(void *)a1 = *a2;
    swift_bridgeObjectRetain();
LABEL_13:
    swift_storeEnumTagMultiPayload();
    goto LABEL_14;
  }
  if (EnumCaseMultiPayload == 1)
  {
    type metadata accessor for MLSoundClassifier.DataSource();
    switch(swift_getEnumCaseMultiPayload())
    {
      case 2u:
        *(void *)a1 = *a2;
        swift_bridgeObjectRetain();
        break;
      case 3u:
        uint64_t v11 = *a2;
        char v12 = *((unsigned char *)a2 + 8);
        outlined copy of Result<_DataTable, Error>(*a2, v12);
        *(void *)a1 = v11;
        a1[8] = v12;
        Swift::String v13 = a2[3];
        *((void *)a1 + 2) = a2[2];
        *((void *)a1 + 3) = v13;
        uint64_t v14 = a2[5];
        *((void *)a1 + 4) = a2[4];
        *((void *)a1 + 5) = v14;
        long long v15 = *((_OWORD *)a2 + 4);
        *((_OWORD *)a1 + 3) = *((_OWORD *)a2 + 3);
        *((_OWORD *)a1 + 4) = v15;
        a1[80] = *((unsigned char *)a2 + 80);
        swift_bridgeObjectRetain();
        swift_bridgeObjectRetain();
        break;
      case 4u:
        uint64_t v16 = type metadata accessor for DataFrame();
        (*(void (**)(char *, char **, uint64_t))(*(void *)(v16 - 8) + 16))(a1, a2, v16);
        Swift::String v17 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, featureColumn: String, labelColumn: String, parameters: MLSoundClassifier.FeatureExtractionParameters));
        uint64_t v18 = v17[12];
        unint64_t v19 = &a1[v18];
        unint64_t v20 = (uint64_t *)((char *)a2 + v18);
        uint64_t v22 = *v20;
        uint64_t v21 = v20[1];
        *(void *)unint64_t v19 = v22;
        *((void *)v19 + 1) = v21;
        uint64_t v23 = v17[16];
        Swift::String v24 = &a1[v23];
        Swift::String v25 = (char **)((char *)a2 + v23);
        uint64_t v26 = v25[1];
        *(void *)Swift::String v24 = *v25;
        *((void *)v24 + 1) = v26;
        uint64_t v27 = v17[20];
        os_log_type_t v28 = &a1[v27];
        uint64_t v29 = (uint64_t)a2 + v27;
        long long v30 = *(_OWORD *)(v29 + 16);
        *(_OWORD *)os_log_type_t v28 = *(_OWORD *)v29;
        *((_OWORD *)v28 + 1) = v30;
        v28[32] = *(unsigned char *)(v29 + 32);
        swift_bridgeObjectRetain();
        swift_bridgeObjectRetain();
        break;
      default:
        uint64_t v9 = type metadata accessor for URL();
        (*(void (**)(char *, char **, uint64_t))(*(void *)(v9 - 8) + 16))(a1, a2, v9);
        break;
    }
    swift_storeEnumTagMultiPayload();
    goto LABEL_13;
  }
  memcpy(a1, a2, *(void *)(*(void *)(v7 - 8) + 64));
LABEL_14:
  uint64_t v31 = a3[6];
  *(void *)&a1[a3[5]] = *(char **)((char *)a2 + a3[5]);
  *(void *)&a1[v31] = *(char **)((char *)a2 + v31);
  uint64_t v32 = a3[7];
  uint64_t v33 = &a1[v32];
  uint64_t v34 = (_OWORD *)((char *)a2 + v32);
  uint64_t v35 = *(uint64_t *)((char *)a2 + v32 + 24);
  if (v35)
  {
    *((void *)v33 + 3) = v35;
    (**(void (***)(void))(v35 - 8))();
  }
  else
  {
    long long v36 = v34[1];
    *(_OWORD *)uint64_t v33 = *v34;
    *((_OWORD *)v33 + 1) = v36;
  }
  uint64_t v37 = a3[8];
  uint64_t v38 = a3[9];
  uint64_t v39 = &a1[v37];
  uint64_t v40 = (uint64_t)a2 + v37;
  *(void *)uint64_t v39 = *(void *)v40;
  v39[8] = *(unsigned char *)(v40 + 8);
  *(void *)&a1[v38] = *(char **)((char *)a2 + v38);
  return a1;
}

uint64_t destroy for MLSoundClassifier.ModelParameters(uint64_t a1, uint64_t a2)
{
  type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData();
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload();
  if (EnumCaseMultiPayload == 2)
  {
LABEL_5:
    swift_bridgeObjectRelease();
  }
  else if (EnumCaseMultiPayload == 1)
  {
    type metadata accessor for MLSoundClassifier.DataSource();
    switch(swift_getEnumCaseMultiPayload())
    {
      case 0u:
      case 1u:
        uint64_t v5 = type metadata accessor for URL();
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v5 - 8) + 8))(a1, v5);
        break;
      case 2u:
        goto LABEL_5;
      case 3u:
        outlined consume of Result<_DataTable, Error>(*(id *)a1, *(unsigned char *)(a1 + 8));
        swift_bridgeObjectRelease();
        goto LABEL_5;
      case 4u:
        uint64_t v7 = type metadata accessor for DataFrame();
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v7 - 8) + 8))(a1, v7);
        __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, featureColumn: String, labelColumn: String, parameters: MLSoundClassifier.FeatureExtractionParameters));
        swift_bridgeObjectRelease();
        goto LABEL_5;
      default:
        break;
    }
  }
  uint64_t result = a1 + *(int *)(a2 + 28);
  if (*(void *)(result + 24))
  {
    return __swift_destroy_boxed_opaque_existential_0(result);
  }
  return result;
}

void *initializeWithCopy for MLSoundClassifier.ModelParameters(void *a1, char *a2, int *a3)
{
  uint64_t v6 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData();
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload();
  if (EnumCaseMultiPayload == 2)
  {
    *a1 = *(void *)a2;
    swift_bridgeObjectRetain();
  }
  else
  {
    if (EnumCaseMultiPayload != 1)
    {
      memcpy(a1, a2, *(void *)(*(void *)(v6 - 8) + 64));
      goto LABEL_12;
    }
    type metadata accessor for MLSoundClassifier.DataSource();
    switch(swift_getEnumCaseMultiPayload())
    {
      case 2u:
        *a1 = *(void *)a2;
        swift_bridgeObjectRetain();
        break;
      case 3u:
        uint64_t v9 = *(void *)a2;
        char v10 = a2[8];
        outlined copy of Result<_DataTable, Error>(*(id *)a2, v10);
        *a1 = v9;
        *((unsigned char *)a1 + 8) = v10;
        uint64_t v11 = *((void *)a2 + 3);
        a1[2] = *((void *)a2 + 2);
        a1[3] = v11;
        uint64_t v12 = *((void *)a2 + 5);
        a1[4] = *((void *)a2 + 4);
        a1[5] = v12;
        long long v13 = *((_OWORD *)a2 + 4);
        *((_OWORD *)a1 + 3) = *((_OWORD *)a2 + 3);
        *((_OWORD *)a1 + 4) = v13;
        *((unsigned char *)a1 + 80) = a2[80];
        swift_bridgeObjectRetain();
        swift_bridgeObjectRetain();
        break;
      case 4u:
        uint64_t v14 = type metadata accessor for DataFrame();
        (*(void (**)(void *, char *, uint64_t))(*(void *)(v14 - 8) + 16))(a1, a2, v14);
        long long v15 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, featureColumn: String, labelColumn: String, parameters: MLSoundClassifier.FeatureExtractionParameters));
        uint64_t v16 = v15[12];
        Swift::String v17 = (void *)((char *)a1 + v16);
        uint64_t v18 = &a2[v16];
        uint64_t v20 = *(void *)v18;
        uint64_t v19 = *((void *)v18 + 1);
        *Swift::String v17 = v20;
        v17[1] = v19;
        uint64_t v21 = v15[16];
        uint64_t v22 = (void *)((char *)a1 + v21);
        uint64_t v23 = &a2[v21];
        uint64_t v24 = *((void *)v23 + 1);
        *uint64_t v22 = *(void *)v23;
        v22[1] = v24;
        uint64_t v25 = v15[20];
        uint64_t v26 = (char *)a1 + v25;
        uint64_t v27 = &a2[v25];
        long long v28 = *((_OWORD *)v27 + 1);
        *(_OWORD *)uint64_t v26 = *(_OWORD *)v27;
        *((_OWORD *)v26 + 1) = v28;
        v26[32] = v27[32];
        swift_bridgeObjectRetain();
        swift_bridgeObjectRetain();
        break;
      default:
        uint64_t v8 = type metadata accessor for URL();
        (*(void (**)(void *, char *, uint64_t))(*(void *)(v8 - 8) + 16))(a1, a2, v8);
        break;
    }
    swift_storeEnumTagMultiPayload();
  }
  swift_storeEnumTagMultiPayload();
LABEL_12:
  uint64_t v29 = a3[6];
  *(void *)((char *)a1 + a3[5]) = *(void *)&a2[a3[5]];
  *(void *)((char *)a1 + v29) = *(void *)&a2[v29];
  uint64_t v30 = a3[7];
  uint64_t v31 = (char *)a1 + v30;
  uint64_t v32 = &a2[v30];
  uint64_t v33 = *(void *)&a2[v30 + 24];
  if (v33)
  {
    *((void *)v31 + 3) = v33;
    (**(void (***)(void))(v33 - 8))();
  }
  else
  {
    long long v34 = *((_OWORD *)v32 + 1);
    *(_OWORD *)uint64_t v31 = *(_OWORD *)v32;
    *((_OWORD *)v31 + 1) = v34;
  }
  uint64_t v35 = a3[8];
  uint64_t v36 = a3[9];
  uint64_t v37 = (char *)a1 + v35;
  uint64_t v38 = &a2[v35];
  *(void *)uint64_t v37 = *(void *)v38;
  v37[8] = v38[8];
  *(void *)((char *)a1 + v36) = *(void *)&a2[v36];
  return a1;
}

void *assignWithCopy for MLSoundClassifier.ModelParameters(void *a1, char *a2, int *a3)
{
  if (a1 != (void *)a2)
  {
    outlined destroy of MLSoundClassifier.ModelParameters.ValidationData((uint64_t)a1);
    uint64_t v6 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData();
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload();
    if (EnumCaseMultiPayload == 2)
    {
      *a1 = *(void *)a2;
      swift_bridgeObjectRetain();
    }
    else
    {
      if (EnumCaseMultiPayload != 1)
      {
        memcpy(a1, a2, *(void *)(*(void *)(v6 - 8) + 64));
        goto LABEL_13;
      }
      type metadata accessor for MLSoundClassifier.DataSource();
      switch(swift_getEnumCaseMultiPayload())
      {
        case 2u:
          *a1 = *(void *)a2;
          swift_bridgeObjectRetain();
          break;
        case 3u:
          uint64_t v9 = *(void *)a2;
          char v10 = a2[8];
          outlined copy of Result<_DataTable, Error>(*(id *)a2, v10);
          *a1 = v9;
          *((unsigned char *)a1 + 8) = v10;
          a1[2] = *((void *)a2 + 2);
          a1[3] = *((void *)a2 + 3);
          a1[4] = *((void *)a2 + 4);
          a1[5] = *((void *)a2 + 5);
          long long v11 = *((_OWORD *)a2 + 3);
          long long v12 = *((_OWORD *)a2 + 4);
          *((unsigned char *)a1 + 80) = a2[80];
          *((_OWORD *)a1 + 3) = v11;
          *((_OWORD *)a1 + 4) = v12;
          swift_bridgeObjectRetain();
          swift_bridgeObjectRetain();
          break;
        case 4u:
          uint64_t v13 = type metadata accessor for DataFrame();
          (*(void (**)(void *, char *, uint64_t))(*(void *)(v13 - 8) + 16))(a1, a2, v13);
          uint64_t v14 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, featureColumn: String, labelColumn: String, parameters: MLSoundClassifier.FeatureExtractionParameters));
          uint64_t v15 = v14[12];
          uint64_t v16 = (void *)((char *)a1 + v15);
          Swift::String v17 = &a2[v15];
          *uint64_t v16 = *(void *)v17;
          v16[1] = *((void *)v17 + 1);
          uint64_t v18 = v14[16];
          uint64_t v19 = (void *)((char *)a1 + v18);
          uint64_t v20 = &a2[v18];
          *uint64_t v19 = *(void *)v20;
          v19[1] = *((void *)v20 + 1);
          uint64_t v21 = v14[20];
          uint64_t v22 = (char *)a1 + v21;
          uint64_t v23 = &a2[v21];
          char v24 = v23[32];
          long long v25 = *((_OWORD *)v23 + 1);
          *(_OWORD *)uint64_t v22 = *(_OWORD *)v23;
          *((_OWORD *)v22 + 1) = v25;
          v22[32] = v24;
          swift_bridgeObjectRetain();
          swift_bridgeObjectRetain();
          break;
        default:
          uint64_t v8 = type metadata accessor for URL();
          (*(void (**)(void *, char *, uint64_t))(*(void *)(v8 - 8) + 16))(a1, a2, v8);
          break;
      }
      swift_storeEnumTagMultiPayload();
    }
    swift_storeEnumTagMultiPayload();
  }
LABEL_13:
  *(void *)((char *)a1 + a3[5]) = *(void *)&a2[a3[5]];
  *(void *)((char *)a1 + a3[6]) = *(void *)&a2[a3[6]];
  uint64_t v26 = a3[7];
  uint64_t v27 = (uint64_t)a1 + v26;
  long long v28 = &a2[v26];
  uint64_t v29 = *(void *)&a2[v26 + 24];
  if (!*(void *)((char *)a1 + v26 + 24))
  {
    if (v29)
    {
      *(void *)(v27 + 24) = v29;
      (**(void (***)(uint64_t, char *))(v29 - 8))(v27, v28);
      goto LABEL_20;
    }
LABEL_19:
    long long v30 = *((_OWORD *)v28 + 1);
    *(_OWORD *)uint64_t v27 = *(_OWORD *)v28;
    *(_OWORD *)(v27 + 16) = v30;
    goto LABEL_20;
  }
  if (!v29)
  {
    __swift_destroy_boxed_opaque_existential_0(v27);
    goto LABEL_19;
  }
  __swift_assign_boxed_opaque_existential_0((uint64_t *)v27, (uint64_t *)v28);
LABEL_20:
  uint64_t v31 = a3[8];
  uint64_t v32 = (char *)a1 + v31;
  uint64_t v33 = &a2[v31];
  uint64_t v34 = *(void *)v33;
  v32[8] = v33[8];
  *(void *)uint64_t v32 = v34;
  *(void *)((char *)a1 + a3[9]) = *(void *)&a2[a3[9]];
  return a1;
}

char *initializeWithTake for MLSoundClassifier.ModelParameters(char *a1, char *a2, int *a3)
{
  uint64_t v6 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData();
  if (swift_getEnumCaseMultiPayload() == 1)
  {
    uint64_t v7 = type metadata accessor for MLSoundClassifier.DataSource();
    unsigned int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload();
    if (EnumCaseMultiPayload == 4)
    {
      uint64_t v9 = type metadata accessor for DataFrame();
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v9 - 8) + 32))(a1, a2, v9);
      char v10 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, featureColumn: String, labelColumn: String, parameters: MLSoundClassifier.FeatureExtractionParameters));
      *(_OWORD *)&a1[v10[12]] = *(_OWORD *)&a2[v10[12]];
      *(_OWORD *)&a1[v10[16]] = *(_OWORD *)&a2[v10[16]];
      uint64_t v11 = v10[20];
      long long v12 = &a1[v11];
      uint64_t v13 = &a2[v11];
      long long v14 = *((_OWORD *)v13 + 1);
      *(_OWORD *)long long v12 = *(_OWORD *)v13;
      *((_OWORD *)v12 + 1) = v14;
      v12[32] = v13[32];
    }
    else
    {
      if (EnumCaseMultiPayload > 1)
      {
        memcpy(a1, a2, *(void *)(*(void *)(v7 - 8) + 64));
        goto LABEL_9;
      }
      uint64_t v15 = type metadata accessor for URL();
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v15 - 8) + 32))(a1, a2, v15);
    }
    swift_storeEnumTagMultiPayload();
LABEL_9:
    swift_storeEnumTagMultiPayload();
    goto LABEL_10;
  }
  memcpy(a1, a2, *(void *)(*(void *)(v6 - 8) + 64));
LABEL_10:
  uint64_t v16 = a3[6];
  *(void *)&a1[a3[5]] = *(void *)&a2[a3[5]];
  *(void *)&a1[v16] = *(void *)&a2[v16];
  uint64_t v17 = a3[7];
  uint64_t v18 = a3[8];
  uint64_t v19 = &a1[v17];
  uint64_t v20 = &a2[v17];
  long long v21 = *((_OWORD *)v20 + 1);
  *(_OWORD *)uint64_t v19 = *(_OWORD *)v20;
  *((_OWORD *)v19 + 1) = v21;
  uint64_t v22 = &a1[v18];
  uint64_t v23 = &a2[v18];
  *(void *)uint64_t v22 = *(void *)v23;
  v22[8] = v23[8];
  *(void *)&a1[a3[9]] = *(void *)&a2[a3[9]];
  return a1;
}

char *assignWithTake for MLSoundClassifier.ModelParameters(char *a1, char *a2, int *a3)
{
  if (a1 != a2)
  {
    outlined destroy of MLSoundClassifier.ModelParameters.ValidationData((uint64_t)a1);
    uint64_t v6 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData();
    if (swift_getEnumCaseMultiPayload() != 1)
    {
      memcpy(a1, a2, *(void *)(*(void *)(v6 - 8) + 64));
      goto LABEL_11;
    }
    uint64_t v7 = type metadata accessor for MLSoundClassifier.DataSource();
    unsigned int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload();
    if (EnumCaseMultiPayload == 4)
    {
      uint64_t v9 = type metadata accessor for DataFrame();
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v9 - 8) + 32))(a1, a2, v9);
      char v10 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, featureColumn: String, labelColumn: String, parameters: MLSoundClassifier.FeatureExtractionParameters));
      *(_OWORD *)&a1[v10[12]] = *(_OWORD *)&a2[v10[12]];
      *(_OWORD *)&a1[v10[16]] = *(_OWORD *)&a2[v10[16]];
      uint64_t v11 = v10[20];
      long long v12 = &a1[v11];
      uint64_t v13 = &a2[v11];
      long long v14 = *((_OWORD *)v13 + 1);
      *(_OWORD *)long long v12 = *(_OWORD *)v13;
      *((_OWORD *)v12 + 1) = v14;
      v12[32] = v13[32];
    }
    else
    {
      if (EnumCaseMultiPayload > 1)
      {
        memcpy(a1, a2, *(void *)(*(void *)(v7 - 8) + 64));
        goto LABEL_10;
      }
      uint64_t v15 = type metadata accessor for URL();
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v15 - 8) + 32))(a1, a2, v15);
    }
    swift_storeEnumTagMultiPayload();
LABEL_10:
    swift_storeEnumTagMultiPayload();
  }
LABEL_11:
  uint64_t v16 = a3[6];
  *(void *)&a1[a3[5]] = *(void *)&a2[a3[5]];
  *(void *)&a1[v16] = *(void *)&a2[v16];
  uint64_t v17 = a3[7];
  uint64_t v18 = &a1[v17];
  if (*(void *)&a1[v17 + 24]) {
    __swift_destroy_boxed_opaque_existential_0((uint64_t)&a1[v17]);
  }
  long long v19 = *(_OWORD *)&a2[v17 + 16];
  *(_OWORD *)uint64_t v18 = *(_OWORD *)&a2[v17];
  *((_OWORD *)v18 + 1) = v19;
  uint64_t v20 = a3[8];
  uint64_t v21 = a3[9];
  uint64_t v22 = &a1[v20];
  uint64_t v23 = &a2[v20];
  *(void *)uint64_t v22 = *(void *)v23;
  v22[8] = v23[8];
  *(void *)&a1[v21] = *(void *)&a2[v21];
  return a1;
}

uint64_t getEnumTagSinglePayload for MLSoundClassifier.ModelParameters(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return MEMORY[0x270FA0340](a1, a2, a3, sub_2270D99A8);
}

uint64_t sub_2270D99A8(uint64_t a1, uint64_t a2, uint64_t a3)
{
  type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData();
  OUTLINED_FUNCTION_6_1();
  if (*(_DWORD *)(v7 + 84) == a2)
  {
    return __swift_getEnumTagSinglePayload(a1, a2, v6);
  }
  else
  {
    unint64_t v9 = *(void *)(a1 + *(int *)(a3 + 28) + 24);
    if (v9 >= 0xFFFFFFFF) {
      LODWORD(v9) = -1;
    }
    int v10 = v9 - 1;
    if (v10 < 0) {
      int v10 = -1;
    }
    return (v10 + 1);
  }
}

uint64_t storeEnumTagSinglePayload for MLSoundClassifier.ModelParameters(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return MEMORY[0x270FA0580](a1, a2, a3, a4, sub_2270D9A58);
}

void sub_2270D9A58(uint64_t a1, uint64_t a2, int a3, uint64_t a4)
{
  type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData();
  OUTLINED_FUNCTION_6_1();
  if (*(_DWORD *)(v9 + 84) == a3)
  {
    __swift_storeEnumTagSinglePayload(a1, a2, a2, v8);
  }
  else
  {
    *(void *)(a1 + *(int *)(a4 + 28) + 24) = a2;
  }
}

uint64_t type metadata completion function for MLSoundClassifier.ModelParameters()
{
  uint64_t result = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData();
  if (v1 <= 0x3F)
  {
    swift_initStructMetadata();
    return 0;
  }
  return result;
}

unsigned char *storeEnumTagSinglePayload for MLSoundClassifier.ModelParameters.FeaturePrintType(unsigned char *result, int a2, int a3)
{
  if ((a3 + 1) >= 0x10000) {
    int v3 = 4;
  }
  else {
    int v3 = 2;
  }
  if ((a3 + 1) < 0x100) {
    unsigned int v4 = 1;
  }
  else {
    unsigned int v4 = v3;
  }
  if (a3) {
    uint64_t v5 = v4;
  }
  else {
    uint64_t v5 = 0;
  }
  if (a2)
  {
    switch(v5)
    {
      case 1:
        *uint64_t result = a2;
        return result;
      case 2:
        *(_WORD *)uint64_t result = a2;
        return result;
      case 3:
        goto LABEL_19;
      case 4:
        *(_DWORD *)uint64_t result = a2;
        return result;
      default:
        return result;
    }
  }
  switch(v5)
  {
    case 1:
      *uint64_t result = 0;
      break;
    case 2:
      *(_WORD *)uint64_t result = 0;
      break;
    case 3:
LABEL_19:
      __break(1u);
      JUMPOUT(0x2270D9C30);
    case 4:
      *(_DWORD *)uint64_t result = 0;
      break;
    default:
      return result;
  }
  return result;
}

ValueMetadata *type metadata accessor for MLSoundClassifier.ModelParameters.FeaturePrintType()
{
  return &type metadata for MLSoundClassifier.ModelParameters.FeaturePrintType;
}

uint64_t OUTLINED_FUNCTION_0_13(uint64_t a1)
{
  uint64_t v3 = v2 + *(int *)(a1 + 32);
  *(void *)uint64_t v3 = 0;
  *(unsigned char *)(v3 + 8) = 1;
  *(void *)(v2 + *(int *)(a1 + 36)) = 32;
  return v1;
}

uint64_t OUTLINED_FUNCTION_2_19()
{
  return swift_dynamicCast();
}

unint64_t OUTLINED_FUNCTION_3_20()
{
  return 0xD000000000000056;
}

void OUTLINED_FUNCTION_4_15(uint64_t a1@<X8>)
{
  unint64_t v3 = 0xD000000000000011;
  unint64_t v2 = (a1 - 32) | 0x8000000000000000;
  String.append(_:)(*(Swift::String *)&v3);
}

void OUTLINED_FUNCTION_5_15()
{
  _StringGuts.grow(_:)(108);
}

void OUTLINED_FUNCTION_8_12()
{
  *(void *)(v1 + *(int *)(v2 + 20)) = v0;
  *(void *)(v1 + *(int *)(v2 + 24)) = v3;
}

id MLDataTable.rows.getter@<X0>(uint64_t a1@<X8>)
{
  uint64_t v2 = *(void **)v1;
  char v3 = *(unsigned char *)(v1 + 8);
  *(void *)a1 = *(void *)v1;
  *(unsigned char *)(a1 + 8) = v3;
  return outlined copy of Result<_DataTable, Error>(v2, v3);
}

void MLDataTable.Rows.subscript.getter(uint64_t a1@<X0>, uint64_t *a2@<X8>)
{
  id v4 = *(id *)v2;
  if (*(unsigned char *)(v2 + 8))
  {
    outlined copy of Result<_DataTable, Error>(*(id *)v2, 1);
    uint64_t v5 = MEMORY[0x22A676370](0);
    if (v5)
    {
      uint64_t v6 = v5;
      type metadata accessor for CMLSequence();
      uint64_t v7 = swift_allocObject();
      *(void *)(v7 + 16) = v6;
      *(unsigned char *)(v7 + 24) = 1;
      outlined consume of Result<_DataTable, Error>(v4, 1);
      uint64_t v8 = MEMORY[0x22A676370](0);
      if (v8)
      {
        uint64_t v9 = v8;
        uint64_t v10 = swift_allocObject();
        *(void *)(v10 + 16) = v9;
        *(unsigned char *)(v10 + 24) = 1;
        uint64_t v11 = MEMORY[0x263F8EE80];
        *a2 = v7;
        a2[1] = v11;
        a2[2] = v10;
        return;
      }
    }
    else
    {
      __break(1u);
    }
    __break(1u);
    __break(1u);
  }
  else
  {
    outlined copy of Result<_DataTable, Error>(v4, 0);
    swift_retain();
    CMLTable.row(at:)(a1);
    uint64_t v14 = v13;
    swift_release();
    outlined copy of Result<_DataTable, Error>(v4, 0);
    _DataTable.columnNames.getter(&v17);
    outlined consume of Result<_DataTable, Error>(v4, 0);
    uint64_t v15 = v17;
    outlined copy of Result<_DataTable, Error>(v4, 0);
    uint64_t v16 = _DataTable.columnIndexes.getter();
    outlined consume of Result<_DataTable, Error>(v4, 0);
    outlined consume of Result<_DataTable, Error>(v4, 0);
    *a2 = v15;
    a2[1] = v16;
    a2[2] = v14;
  }
}

uint64_t MLDataTable.Rows.startIndex.getter()
{
  return 0;
}

uint64_t MLDataTable.Rows.endIndex.getter()
{
  return MLDataTable.size.getter();
}

uint64_t protocol witness for BidirectionalCollection.index(before:) in conformance MLDataTable.Rows@<X0>(uint64_t *a1@<X0>, uint64_t *a2@<X8>)
{
  uint64_t result = specialized RandomAccessCollection<>.index(before:)(*a1);
  *a2 = result;
  return result;
}

uint64_t protocol witness for BidirectionalCollection.formIndex(before:) in conformance MLDataTable.Rows(uint64_t *a1)
{
  uint64_t result = specialized RandomAccessCollection<>.index(before:)(*a1);
  *a1 = result;
  return result;
}

uint64_t protocol witness for BidirectionalCollection.index(_:offsetBy:) in conformance MLDataTable.Rows@<X0>(uint64_t *a1@<X0>, uint64_t a2@<X1>, uint64_t *a3@<X8>)
{
  uint64_t result = specialized RandomAccessCollection<>.index(_:offsetBy:)(*a1, a2);
  *a3 = result;
  return result;
}

uint64_t protocol witness for BidirectionalCollection.distance(from:to:) in conformance MLDataTable.Rows()
{
  return specialized RandomAccessCollection<>.distance(from:to:)();
}

uint64_t protocol witness for Collection.endIndex.getter in conformance MLDataTable.Rows@<X0>(uint64_t *a1@<X8>)
{
  uint64_t result = MLDataTable.Rows.endIndex.getter();
  *a1 = result;
  return result;
}

uint64_t (*protocol witness for Collection.subscript.read in conformance MLDataTable.Rows(uint64_t *a1, uint64_t *a2))()
{
  return protocol witness for Collection.subscript.read in conformance MLDataTable.Rows;
}

uint64_t protocol witness for Collection.subscript.read in conformance MLDataTable.Rows()
{
  swift_release();
  swift_bridgeObjectRelease();

  return swift_release();
}

uint64_t protocol witness for Collection.subscript.getter in conformance MLDataTable.Rows@<X0>(uint64_t *a1@<X0>, uint64_t a2@<X8>)
{
  return specialized Collection<>.subscript.getter(*a1, a1[1], *(void **)v2, *(unsigned char *)(v2 + 8), a2);
}

uint64_t protocol witness for Collection.indices.getter in conformance MLDataTable.Rows@<X0>(uint64_t *a1@<X8>)
{
  uint64_t result = specialized RandomAccessCollection<>.indices.getter();
  *a1 = result;
  a1[1] = v3;
  return result;
}

BOOL protocol witness for Collection.isEmpty.getter in conformance MLDataTable.Rows()
{
  return specialized Collection.isEmpty.getter();
}

uint64_t protocol witness for Collection.count.getter in conformance MLDataTable.Rows()
{
  return specialized Collection.count.getter();
}

uint64_t protocol witness for RandomAccessCollection.index(_:offsetBy:limitedBy:) in conformance MLDataTable.Rows@<X0>(uint64_t *a1@<X0>, uint64_t a2@<X1>, uint64_t a3@<X8>)
{
  uint64_t result = specialized RandomAccessCollection.index(_:offsetBy:limitedBy:)(*a1, a2);
  *(void *)a3 = result;
  *(unsigned char *)(a3 + 8) = v5 & 1;
  return result;
}

uint64_t protocol witness for Collection._failEarlyRangeCheck(_:bounds:) in conformance MLDataTable.Rows(uint64_t *a1, uint64_t *a2)
{
  return specialized Collection._failEarlyRangeCheck(_:bounds:)(*a1, *a2, a2[1]);
}

{
  return specialized Collection._failEarlyRangeCheck(_:bounds:)(*a1, *a2, a2[1]);
}

{
  return specialized Collection._failEarlyRangeCheck(_:bounds:)(*a1, a1[1], *a2, a2[1]);
}

uint64_t protocol witness for Collection.index(after:) in conformance MLDataTable.Rows@<X0>(uint64_t *a1@<X0>, uint64_t *a2@<X8>)
{
  uint64_t result = specialized RandomAccessCollection<>.index(after:)(*a1);
  *a2 = result;
  return result;
}

uint64_t protocol witness for Collection.formIndex(after:) in conformance MLDataTable.Rows(uint64_t *a1)
{
  uint64_t result = specialized RandomAccessCollection<>.index(after:)(*a1);
  *a1 = result;
  return result;
}

void protocol witness for Sequence.makeIterator() in conformance MLDataTable.Rows(uint64_t a1@<X8>)
{
  char v2 = *(unsigned char *)(v1 + 8);
  *(void *)a1 = *(void *)v1;
  *(unsigned char *)(a1 + 8) = v2;
  *(void *)(a1 + 16) = 0;
}

uint64_t protocol witness for Sequence._copyToContiguousArray() in conformance MLDataTable.Rows()
{
  return specialized Collection._copyToContiguousArray()(*(void **)v0, *(unsigned char *)(v0 + 8));
}

uint64_t protocol witness for Sequence._copyContents(initializing:) in conformance MLDataTable.Rows(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return specialized Sequence._copyContents(initializing:)(a1, a2, a3, *(void *)v3, *(unsigned char *)(v3 + 8));
}

uint64_t MLDataTable.Rows.description.getter()
{
  char v2 = *(void **)v1;
  int v3 = *(unsigned __int8 *)(v1 + 8);
  v68._uint64_t countAndFlagsBits = (uint64_t)v2;
  LOBYTE(v68._object) = v3;
  outlined copy of Result<_DataTable, Error>(v2, v3);
  MLDataTable.size.getter();
  OUTLINED_FUNCTION_0_14();
  OUTLINED_FUNCTION_3_21();
  uint64_t v63 = object;
  uint64_t v4 = 0x2020203A7379654BLL;
  if (object < 1) {
    uint64_t v4 = 0x2020203A79654BLL;
  }
  unint64_t v5 = 0xE800000000000000;
  if (object < 1) {
    unint64_t v5 = 0xE700000000000000;
  }
  uint64_t v69 = v4;
  unint64_t v70 = v5;
  v68._uint64_t countAndFlagsBits = (uint64_t)v2;
  LOBYTE(v68._object) = v3;
  outlined copy of Result<_DataTable, Error>(v2, v3);
  MLDataTable.size.getter();
  OUTLINED_FUNCTION_0_14();
  OUTLINED_FUNCTION_3_21();
  if (object >= 10) {
    uint64_t v14 = 10;
  }
  else {
    uint64_t v14 = object;
  }
  if ((v14 & 0x8000000000000000) == 0)
  {
    if (!v14)
    {
LABEL_31:
      v68._uint64_t countAndFlagsBits = (uint64_t)v2;
      LOBYTE(v68._object) = v3;
      outlined copy of Result<_DataTable, Error>(v2, v3);
      MLDataTable.size.getter();
      OUTLINED_FUNCTION_0_14();
      OUTLINED_FUNCTION_3_21();
      if (v14 < object)
      {
        v56._uint64_t countAndFlagsBits = 0x2E2E2E202CLL;
        v56._uint64_t object = (void *)0xE500000000000000;
        String.append(_:)(v56);
      }
      return v69;
    }
    uint64_t v15 = 0;
    uint64_t v61 = (uint64_t)v2;
    uint64_t v62 = v14;
    HIDWORD(v60) = v3;
    while (v15 != v14)
    {
      if (v15)
      {
        LOBYTE(v66._object) = v3;
        MLDataTable.Rows.subscript.getter(v15, &v68._countAndFlagsBits);
        swift_bridgeObjectRelease();
        swift_release();
        MLDataTable.Row.Values.description.getter();
        int v16 = swift_release();
        OUTLINED_FUNCTION_4_16(v16, v17, v18, v19, v20, v21, v22, v23, v58, v60, v61, v62, v63, v64, v65, 32, (uint64_t)v66._object);
        swift_bridgeObjectRelease();
        Swift::String v68 = v66;
        swift_bridgeObjectRetain();
        v24._uint64_t countAndFlagsBits = 32;
        v24._uint64_t object = (void *)0xE100000000000000;
        String.append(_:)(v24);
        swift_bridgeObjectRelease();
        uint64_t object = (uint64_t)v68._object;
        String.append(_:)(v68);
        uint64_t v6 = swift_bridgeObjectRelease();
      }
      else
      {
        uint64_t v64 = 0;
        OUTLINED_FUNCTION_1_20(v6, v7, v8, v9, v10, v11, v12, v13, v58);
        swift_release();
        swift_bridgeObjectRelease();
        swift_retain();
        uint64_t v25 = CMLSequence.size.getter();
        uint64_t v26 = specialized RandomAccessCollection<>.distance(from:to:)(0, v25);
        swift_retain();
        uint64_t v27 = CMLSequence.size.getter();
        uint64_t v28 = specialized RandomAccessCollection<>.distance(from:to:)(0, v27);
        swift_release();
        if (v28 < 0) {
          goto LABEL_36;
        }
        swift_retain();
        uint64_t v29 = CMLSequence.size.getter();
        uint64_t v30 = specialized RandomAccessCollection<>.distance(from:to:)(0, v29);
        swift_release_n();
        if (v26 < 0 || v30 < v26) {
          goto LABEL_37;
        }
        if (v26)
        {
          *(void *)double v67 = MEMORY[0x263F8EE78];
          specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
          uint64_t v31 = 0;
          uint64_t v32 = *(void *)v67;
          while (v26 != v31)
          {
            CMLSequence.value(at:)(v31);
            Swift::String v33 = CMLFeatureValue.stringValue()();
            swift_release();
            if (v34) {
              goto LABEL_39;
            }
            unint64_t v35 = *(void *)(*(void *)v67 + 16);
            if (v35 >= *(void *)(*(void *)v67 + 24) >> 1) {
              specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
            }
            ++v31;
            *(void *)(*(void *)v67 + 16) = v35 + 1;
            *(Swift::String *)(*(void *)v67 + 16 * v35 + 32) = v33;
            if (v26 == v31)
            {
              char v2 = (void *)v61;
              LOBYTE(v3) = BYTE4(v60);
              goto LABEL_26;
            }
          }
          __break(1u);
          break;
        }
        uint64_t v32 = MEMORY[0x263F8EE78];
LABEL_26:
        uint64_t object = MEMORY[0x22A674D80](v32, MEMORY[0x263F8D310]);
        uint64_t v37 = v36;
        swift_release();
        swift_bridgeObjectRelease();
        v38._uint64_t countAndFlagsBits = object;
        v38._uint64_t object = v37;
        String.append(_:)(v38);
        uint64_t v39 = swift_bridgeObjectRelease();
        if (v63 < 1)
        {
          v55._uint64_t countAndFlagsBits = 0x203A65756C61560ALL;
          v55._uint64_t object = (void *)0xE800000000000000;
          String.append(_:)(v55);
        }
        else
        {
          OUTLINED_FUNCTION_1_20(v39, v40, v41, v42, v43, v44, v45, v46, v58);
          swift_bridgeObjectRelease();
          swift_release();
          MLDataTable.Row.Values.description.getter();
          int v47 = swift_release();
          OUTLINED_FUNCTION_4_16(v47, v48, v49, v50, v51, v52, v53, v54, v59, v60, v61, v62, v63, 0, v65, 10, (uint64_t)v66._object);
          swift_bridgeObjectRelease();
          uint64_t object = (uint64_t)v66._object;
          String.append(_:)(v66);
          uint64_t v6 = swift_bridgeObjectRelease();
        }
        uint64_t v14 = v62;
        uint64_t v15 = v64;
      }
      if (++v15 == v14) {
        goto LABEL_31;
      }
    }
    __break(1u);
LABEL_36:
    __break(1u);
LABEL_37:
    __break(1u);
  }
  __break(1u);
LABEL_39:
  uint64_t result = swift_unexpectedError();
  __break(1u);
  return result;
}

uint64_t MLDataTable.Rows.debugDescription.getter()
{
  return OUTLINED_FUNCTION_2_20();
}

unint64_t MLDataTable.Rows.playgroundDescription.getter@<X0>(void *a1@<X8>)
{
  uint64_t v2 = OUTLINED_FUNCTION_2_20();
  uint64_t v4 = v3;
  id v5 = objc_allocWithZone(MEMORY[0x263F086A0]);
  id v6 = @nonobjc NSAttributedString.init(string:attributes:)(v2, v4, 0);
  unint64_t result = type metadata accessor for NSAttributedString();
  a1[3] = result;
  *a1 = v6;
  return result;
}

unint64_t lazy protocol witness table accessor for type MLDataTable.Rows and conformance MLDataTable.Rows()
{
  unint64_t result = lazy protocol witness table cache variable for type MLDataTable.Rows and conformance MLDataTable.Rows;
  if (!lazy protocol witness table cache variable for type MLDataTable.Rows and conformance MLDataTable.Rows)
  {
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type MLDataTable.Rows and conformance MLDataTable.Rows);
  }
  return result;
}

{
  unint64_t result;

  unint64_t result = lazy protocol witness table cache variable for type MLDataTable.Rows and conformance MLDataTable.Rows;
  if (!lazy protocol witness table cache variable for type MLDataTable.Rows and conformance MLDataTable.Rows)
  {
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type MLDataTable.Rows and conformance MLDataTable.Rows);
  }
  return result;
}

{
  unint64_t result;

  unint64_t result = lazy protocol witness table cache variable for type MLDataTable.Rows and conformance MLDataTable.Rows;
  if (!lazy protocol witness table cache variable for type MLDataTable.Rows and conformance MLDataTable.Rows)
  {
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type MLDataTable.Rows and conformance MLDataTable.Rows);
  }
  return result;
}

{
  unint64_t result;

  unint64_t result = lazy protocol witness table cache variable for type MLDataTable.Rows and conformance MLDataTable.Rows;
  if (!lazy protocol witness table cache variable for type MLDataTable.Rows and conformance MLDataTable.Rows)
  {
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type MLDataTable.Rows and conformance MLDataTable.Rows);
  }
  return result;
}

uint64_t associated type witness table accessor for Collection.SubSequence : RandomAccessCollection in MLDataTable.Rows()
{
  return lazy protocol witness table accessor for type Slice<MLDataTable.Rows> and conformance <> Slice<A>(&lazy protocol witness table cache variable for type Slice<MLDataTable.Rows> and conformance <> Slice<A>, (void (*)(void))lazy protocol witness table accessor for type MLDataTable.Rows and conformance MLDataTable.Rows);
}

uint64_t associated type witness table accessor for Collection.SubSequence : BidirectionalCollection in MLDataTable.Rows()
{
  return lazy protocol witness table accessor for type Slice<MLDataTable.Rows> and conformance <> Slice<A>(&lazy protocol witness table cache variable for type Slice<MLDataTable.Rows> and conformance <> Slice<A>, (void (*)(void))lazy protocol witness table accessor for type MLDataTable.Rows and conformance MLDataTable.Rows);
}

uint64_t lazy protocol witness table accessor for type Slice<MLDataTable.Rows> and conformance <> Slice<A>(unint64_t *a1, void (*a2)(void))
{
  uint64_t result = *a1;
  if (!result)
  {
    __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for Slice<MLDataTable.Rows>);
    a2();
    uint64_t result = swift_getWitnessTable();
    atomic_store(result, a1);
  }
  return result;
}

uint64_t associated type witness table accessor for Collection.SubSequence : Collection in MLDataTable.Rows()
{
  return lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Slice<MLDataTable.Rows> and conformance Slice<A>, &demangling cache variable for type metadata for Slice<MLDataTable.Rows>);
}

uint64_t associated type witness table accessor for Sequence.Iterator : IteratorProtocol in MLDataTable.Rows()
{
  return lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type IndexingIterator<MLDataTable.Rows> and conformance IndexingIterator<A>, &demangling cache variable for type metadata for IndexingIterator<MLDataTable.Rows>);
}

uint64_t initializeBufferWithCopyOfBuffer for MLDataTable.Rows(uint64_t a1, uint64_t a2)
{
  id v3 = *(id *)a2;
  char v4 = *(unsigned char *)(a2 + 8);
  outlined copy of Result<_DataTable, Error>(*(id *)a2, v4);
  *(void *)a1 = v3;
  *(unsigned char *)(a1 + 8) = v4;
  return a1;
}

void destroy for MLDataTable.Rows(uint64_t a1)
{
}

uint64_t assignWithCopy for MLDataTable.Rows(uint64_t a1, uint64_t a2)
{
  id v3 = *(id *)a2;
  char v4 = *(unsigned char *)(a2 + 8);
  outlined copy of Result<_DataTable, Error>(*(id *)a2, v4);
  id v5 = *(void **)a1;
  char v6 = *(unsigned char *)(a1 + 8);
  *(void *)a1 = v3;
  *(unsigned char *)(a1 + 8) = v4;
  outlined consume of Result<_DataTable, Error>(v5, v6);
  return a1;
}

uint64_t __swift_memcpy9_8(uint64_t result, uint64_t *a2)
{
  uint64_t v2 = *a2;
  *(unsigned char *)(result + 8) = *((unsigned char *)a2 + 8);
  *(void *)uint64_t result = v2;
  return result;
}

uint64_t assignWithTake for MLDataTable.Rows(uint64_t a1, uint64_t *a2)
{
  uint64_t v3 = *a2;
  char v4 = *((unsigned char *)a2 + 8);
  id v5 = *(void **)a1;
  char v6 = *(unsigned char *)(a1 + 8);
  *(void *)a1 = v3;
  *(unsigned char *)(a1 + 8) = v4;
  outlined consume of Result<_DataTable, Error>(v5, v6);
  return a1;
}

uint64_t getEnumTagSinglePayload for MLDataTable.Rows(uint64_t a1, unsigned int a2)
{
  if (a2)
  {
    if (a2 >= 0xFF && *(unsigned char *)(a1 + 9))
    {
      int v2 = *(_DWORD *)a1 + 254;
    }
    else
    {
      unsigned int v3 = *(unsigned __int8 *)(a1 + 8);
      if (v3 <= 1) {
        int v2 = -1;
      }
      else {
        int v2 = v3 ^ 0xFF;
      }
    }
  }
  else
  {
    int v2 = -1;
  }
  return (v2 + 1);
}

uint64_t storeEnumTagSinglePayload for MLDataTable.Rows(uint64_t result, unsigned int a2, unsigned int a3)
{
  if (a2 > 0xFE)
  {
    *(unsigned char *)(result + 8) = 0;
    *(void *)uint64_t result = a2 - 255;
    if (a3 >= 0xFF) {
      *(unsigned char *)(result + 9) = 1;
    }
  }
  else
  {
    if (a3 >= 0xFF) {
      *(unsigned char *)(result + 9) = 0;
    }
    if (a2) {
      *(unsigned char *)(result + 8) = -(char)a2;
    }
  }
  return result;
}

ValueMetadata *type metadata accessor for MLDataTable.Rows()
{
  return &type metadata for MLDataTable.Rows;
}

uint64_t OUTLINED_FUNCTION_0_14()
{
  return specialized RandomAccessCollection<>.distance(from:to:)();
}

void OUTLINED_FUNCTION_1_20(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, ...)
{
  va_start(va, a9);
  MLDataTable.Rows.subscript.getter(0, (uint64_t *)va);
}

uint64_t OUTLINED_FUNCTION_2_20()
{
  return MLDataTable.Rows.description.getter();
}

void OUTLINED_FUNCTION_3_21()
{
  outlined consume of Result<_DataTable, Error>(v0, v1);
}

void OUTLINED_FUNCTION_4_16(int a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, char a16, uint64_t a17)
{
  uint64_t v20 = v17;
  uint64_t v21 = v18;
  String.append(_:)(*(Swift::String *)&v20);
}

uint64_t _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML30MLLogisticRegressionClassifierV_s5Error_pTgm503_s8c4ML30efg80V12handleResult33_66687B25F10324110578427E448BFE6CLL_7session7fulfillys0G0Oyyts5H55_pG_AA17MLTrainingSessionCyACGyAIyACsAJ_pGctFZACyKXEfU_AE08Logisticfg8TrainingW8DelegateCTf1nc_n@<X0>(uint64_t a1@<X8>)
{
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Result<MLLogisticRegressionClassifier, Error>);
  uint64_t v3 = MEMORY[0x270FA5388](v2);
  id v5 = &v9[-((v4 + 15) & 0xFFFFFFFFFFFFFFF0)];
  MEMORY[0x270FA5388](v3);
  uint64_t v7 = &v9[-v6];
  swift_retain();
  MLLogisticRegressionClassifier.init(delegate:)();
  swift_storeEnumTagMultiPayload();
  outlined init with take of DataFrame?((uint64_t)v5, (uint64_t)v7, &demangling cache variable for type metadata for Result<MLLogisticRegressionClassifier, Error>);
  outlined init with take of DataFrame?((uint64_t)v7, a1, &demangling cache variable for type metadata for Result<MLLogisticRegressionClassifier, Error>);
  return swift_release();
}

id MLLogisticRegressionClassifier.model.getter()
{
  char v1 = *(void **)(v0 + *(int *)(type metadata accessor for MLLogisticRegressionClassifier() + 20));

  return v1;
}

uint64_t type metadata accessor for MLLogisticRegressionClassifier()
{
  uint64_t result = type metadata singleton initialization cache for MLLogisticRegressionClassifier;
  if (!type metadata singleton initialization cache for MLLogisticRegressionClassifier) {
    return swift_getSingletonMetadata();
  }
  return result;
}

void key path setter for MLLogisticRegressionClassifier.model : MLLogisticRegressionClassifier(id *a1)
{
  id v1 = *a1;
  MLLogisticRegressionClassifier.model.setter();
}

void MLLogisticRegressionClassifier.model.setter()
{
  uint64_t v2 = *(int *)(OUTLINED_FUNCTION_56_5() + 20);

  *(void *)(v1 + v2) = v0;
}

void (*MLLogisticRegressionClassifier.model.modify(uint64_t a1))(uint64_t a1, char a2)
{
  *(void *)(a1 + 8) = v1;
  uint64_t v3 = *(int *)(type metadata accessor for MLLogisticRegressionClassifier() + 20);
  *(_DWORD *)(a1 + 16) = v3;
  uint64_t v4 = *(void **)(v1 + v3);
  *(void *)a1 = v4;
  id v5 = v4;
  return MLRandomForestRegressor.model.modify;
}

uint64_t MLLogisticRegressionClassifier.targetColumn.getter()
{
  uint64_t v1 = *(void *)(v0 + *(int *)(type metadata accessor for MLLogisticRegressionClassifier() + 24));
  swift_bridgeObjectRetain();
  return v1;
}

uint64_t MLLogisticRegressionClassifier.targetColumn.setter(uint64_t a1, uint64_t a2)
{
  id v5 = (void *)(v2 + *(int *)(type metadata accessor for MLLogisticRegressionClassifier() + 24));
  uint64_t result = swift_bridgeObjectRelease();
  *id v5 = a1;
  v5[1] = a2;
  return result;
}

uint64_t (*MLLogisticRegressionClassifier.targetColumn.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLLogisticRegressionClassifier.featureColumns.getter()
{
  type metadata accessor for MLLogisticRegressionClassifier();

  return swift_bridgeObjectRetain();
}

uint64_t MLLogisticRegressionClassifier.featureColumns.setter()
{
  uint64_t v2 = *(int *)(OUTLINED_FUNCTION_56_5() + 28);
  uint64_t result = swift_bridgeObjectRelease();
  *(void *)(v1 + v2) = v0;
  return result;
}

uint64_t (*MLLogisticRegressionClassifier.featureColumns.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLLogisticRegressionClassifier.modelParameters.getter@<X0>(uint64_t a1@<X8>)
{
  uint64_t v3 = v1 + *(int *)(type metadata accessor for MLLogisticRegressionClassifier() + 32);

  return outlined init with copy of MLLogisticRegressionClassifier.ModelParameters(v3, a1);
}

uint64_t outlined init with copy of MLLogisticRegressionClassifier.ModelParameters(uint64_t a1, uint64_t a2)
{
  return a2;
}

uint64_t MLLogisticRegressionClassifier.trainingMetrics.getter@<X0>(uint64_t a1@<X8>)
{
  uint64_t v3 = type metadata accessor for MLLogisticRegressionClassifier();
  return outlined init with copy of MLClassifierMetrics(v1 + *(int *)(v3 + 36), a1, (void (*)(void))type metadata accessor for MLClassifierMetrics);
}

uint64_t MLLogisticRegressionClassifier.validationMetrics.getter@<X0>(uint64_t a1@<X8>)
{
  uint64_t v3 = type metadata accessor for MLLogisticRegressionClassifier();
  return outlined init with copy of MLClassifierMetrics(v1 + *(int *)(v3 + 40), a1, (void (*)(void))type metadata accessor for MLClassifierMetrics);
}

uint64_t static MLLogisticRegressionClassifier._defaultSessionParameters.getter@<X0>(uint64_t a1@<X8>)
{
  if (one-time initialization token for _defaultSessionParameters != -1) {
    swift_once();
  }
  uint64_t v2 = type metadata accessor for MLTrainingSessionParameters();
  uint64_t v3 = __swift_project_value_buffer(v2, (uint64_t)static MLLogisticRegressionClassifier._defaultSessionParameters);
  return outlined init with copy of MLClassifierMetrics(v3, a1, (void (*)(void))type metadata accessor for MLTrainingSessionParameters);
}

#error "2270DB31C: call analysis failed (funcsize=139)"

uint64_t closure #1 in MLLogisticRegressionClassifier.init(_:targetColumn:featureColumns:parameters:)(uint64_t a1)
{
  *(void *)(v1 + 16) = a1;
  uint64_t v4 = (uint64_t (__cdecl *)())((char *)&async function pointer to specialized CoreMLExportable.exportAsCoreMLModel()
                             + async function pointer to specialized CoreMLExportable.exportAsCoreMLModel());
  uint64_t v2 = (void *)swift_task_alloc();
  *(void *)(v1 + 24) = v2;
  *uint64_t v2 = v1;
  v2[1] = closure #1 in MLLogisticRegressionClassifier.init(_:targetColumn:featureColumns:parameters:);
  return v4();
}

{
  uint64_t v1;
  uint64_t *v2;
  uint64_t v4;
  uint64_t v5;
  void *v6;
  uint64_t v7;
  void *v8;
  uint64_t (*v9)(void);
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;

  OUTLINED_FUNCTION_2();
  uint64_t v5 = v4;
  OUTLINED_FUNCTION_34_5();
  *uint64_t v6 = v5;
  uint64_t v7 = *v2;
  OUTLINED_FUNCTION_6();
  *uint64_t v8 = v7;
  swift_task_dealloc();
  if (v1)
  {
    OUTLINED_FUNCTION_33_5();
    return v9();
  }
  else
  {
    *(void *)(v5 + 32) = a1;
    OUTLINED_FUNCTION_32_6();
    return MEMORY[0x270FA2498](v11, v12, v13);
  }
}

void MLLogisticRegressionClassifier.init(trainingData:targetColumn:featureColumns:parameters:)()
{
  OUTLINED_FUNCTION_9_0();
  uint64_t v191 = v1;
  uint64_t v3 = v2;
  v190 = v4;
  v198 = v5;
  uint64_t v188 = v6;
  uint64_t v8 = v7;
  uint64_t v10 = v9;
  uint64_t v11 = type metadata accessor for AnyClassificationMetrics();
  uint64_t v12 = OUTLINED_FUNCTION_17(v11);
  MEMORY[0x270FA5388](v12);
  OUTLINED_FUNCTION_49();
  OUTLINED_FUNCTION_16_2();
  MEMORY[0x270FA5388](v13);
  OUTLINED_FUNCTION_106();
  uint64_t v15 = OUTLINED_FUNCTION_17_3(v14);
  uint64_t v16 = type metadata accessor for MLClassifierMetrics(v15);
  uint64_t v17 = OUTLINED_FUNCTION_17(v16);
  MEMORY[0x270FA5388](v17);
  OUTLINED_FUNCTION_49();
  OUTLINED_FUNCTION_16_2();
  MEMORY[0x270FA5388](v18);
  OUTLINED_FUNCTION_106();
  OUTLINED_FUNCTION_17_3(v19);
  uint64_t v20 = type metadata accessor for MLLogisticRegressionClassifier.Model();
  uint64_t v21 = OUTLINED_FUNCTION_1(v20);
  uint64_t v177 = v22;
  MEMORY[0x270FA5388](v21);
  OUTLINED_FUNCTION_45_2((uint64_t)&v158 - ((v23 + 15) & 0xFFFFFFFFFFFFFFF0));
  uint64_t v175 = v24;
  MEMORY[0x270FA5388](v25);
  OUTLINED_FUNCTION_106();
  OUTLINED_FUNCTION_45_2(v26);
  uint64_t v27 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
  uint64_t v28 = OUTLINED_FUNCTION_17(v27);
  MEMORY[0x270FA5388](v28);
  OUTLINED_FUNCTION_33_0();
  OUTLINED_FUNCTION_45_2(v29);
  uint64_t v30 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyColumn?);
  uint64_t v31 = OUTLINED_FUNCTION_17(v30);
  MEMORY[0x270FA5388](v31);
  OUTLINED_FUNCTION_33_0();
  OUTLINED_FUNCTION_17_3(v32);
  uint64_t v182 = type metadata accessor for AnyColumn();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v33);
  OUTLINED_FUNCTION_49();
  OUTLINED_FUNCTION_16_2();
  MEMORY[0x270FA5388](v34);
  OUTLINED_FUNCTION_45_3();
  OUTLINED_FUNCTION_16_2();
  MEMORY[0x270FA5388](v35);
  OUTLINED_FUNCTION_106();
  OUTLINED_FUNCTION_17_3(v36);
  uint64_t v37 = type metadata accessor for MLLogisticRegressionClassifier.Classifier();
  uint64_t v38 = OUTLINED_FUNCTION_17(v37);
  MEMORY[0x270FA5388](v38);
  OUTLINED_FUNCTION_33_0();
  OUTLINED_FUNCTION_17_3(v39);
  uint64_t v193 = type metadata accessor for DataFrame();
  OUTLINED_FUNCTION_0();
  uint64_t v194 = v40;
  MEMORY[0x270FA5388](v41);
  OUTLINED_FUNCTION_49();
  OUTLINED_FUNCTION_16_2();
  MEMORY[0x270FA5388](v42);
  OUTLINED_FUNCTION_45_3();
  OUTLINED_FUNCTION_16_2();
  MEMORY[0x270FA5388](v43);
  OUTLINED_FUNCTION_45_3();
  OUTLINED_FUNCTION_16_2();
  MEMORY[0x270FA5388](v44);
  OUTLINED_FUNCTION_106();
  OUTLINED_FUNCTION_17_3(v45);
  type metadata accessor for MLLogisticRegressionClassifier.ModelParameters.ValidationData();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v46);
  OUTLINED_FUNCTION_15();
  uint64_t v47 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v48);
  OUTLINED_FUNCTION_49();
  OUTLINED_FUNCTION_16_2();
  MEMORY[0x270FA5388](v49);
  OUTLINED_FUNCTION_45_3();
  OUTLINED_FUNCTION_16_2();
  uint64_t v51 = MEMORY[0x270FA5388](v50);
  int v53 = (char *)&v158 - v52;
  MEMORY[0x270FA5388](v51);
  Swift::String v55 = (char *)&v158 - v54;
  uint64_t v56 = type metadata accessor for MLLogisticRegressionClassifier();
  uint64_t v192 = v10 + *(int *)(v56 + 36);
  MLClassifierMetrics.init()(v56, v57, v58, v59, v60, v61, v62, v63, v158, v159, v160, v161, (uint64_t)v162, v163, (uint64_t)v164, v165, v166, v167, v168,
    v169);
  v176 = (int *)v56;
  uint64_t v64 = *(int *)(v56 + 40);
  uint64_t v179 = v10;
  uint64_t v65 = (void *)(v10 + v64);
  unint64_t v66 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  OUTLINED_FUNCTION_85();
  OUTLINED_FUNCTION_32_2(v67, 0xD0000000000000C0);
  *uint64_t v65 = v68;
  uint64_t v69 = type metadata accessor for MLClassifierMetrics.Contents(0);
  v189 = v65;
  uint64_t v70 = v3;
  uint64_t v173 = v69;
  swift_storeEnumTagMultiPayload();
  outlined init with copy of Any?(v3 + 8, (uint64_t)&v196, &demangling cache variable for type metadata for Any?);
  if (v197)
  {
    uint64_t v71 = (uint64_t)&v55[*(int *)(v47 + 48)];
    outlined init with take of Any(&v196, v195);
    swift_dynamicCast();
    uint64_t v72 = OUTLINED_FUNCTION_47_4();
    uint64_t v73 = v191;
    MLLogisticRegressionClassifier.ModelParameters.ValidationData.generateDataFrames(trainingData:)(v72, v74, v8);
    if (v73)
    {
      swift_bridgeObjectRelease();
      swift_bridgeObjectRelease();
      outlined destroy of MLLogisticRegressionClassifier.ModelParameters(v70);
      OUTLINED_FUNCTION_16_9();
      v75();
      outlined destroy of MLLogisticRegressionClassifier.ModelParameters.ValidationData((uint64_t)v0, (void (*)(void))type metadata accessor for MLLogisticRegressionClassifier.ModelParameters.ValidationData);
LABEL_17:
      OUTLINED_FUNCTION_51_4();
      goto LABEL_18;
    }
    uint64_t v191 = v71;
    uint64_t v165 = v47;
    outlined destroy of MLLogisticRegressionClassifier.ModelParameters.ValidationData((uint64_t)v0, (void (*)(void))type metadata accessor for MLLogisticRegressionClassifier.ModelParameters.ValidationData);
    static _FeatureUtilities.selectFeaturesFromTrainingData(trainingData:targetColumn:featureColumns:)((uint64_t)v55, v188, v198, (uint64_t)v190);
    uint64_t v77 = v76;
    unint64_t v160 = v66;
    swift_bridgeObjectRelease();
    OUTLINED_FUNCTION_31_4();
    uint64_t v79 = (uint64_t)&v53[v78];
    uint64_t v80 = v194;
    uint64_t v81 = *(void (**)(uint64_t, uint64_t, uint64_t))(v194 + 16);
    v164 = v55;
    uint64_t v82 = v193;
    v162 = v81;
    uint64_t v163 = v194 + 16;
    OUTLINED_FUNCTION_46_4();
    v83();
    outlined init with copy of Any?(v191, v79, &demangling cache variable for type metadata for DataFrame?);
    OUTLINED_FUNCTION_57_4(v79, 1, v82);
    if (v84)
    {
      uint64_t v161 = v77;
      outlined destroy of URL?(v79, &demangling cache variable for type metadata for DataFrame?);
      v190 = *(void (**)(void))(v80 + 8);
      ((void (*)(char *, uint64_t))v190)(v53, v82);
      uint64_t v85 = v82;
    }
    else
    {
      uint64_t v159 = v8;
      uint64_t v93 = v181;
      (*(void (**)(uint64_t (*)(), uint64_t, uint64_t))(v80 + 32))(v181, v79, v82);
      v94 = *(void (**)(void))(v80 + 8);
      OUTLINED_FUNCTION_25_10();
      v94();
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<String>);
      uint64_t inited = swift_initStackObject();
      *(_OWORD *)(inited + 16) = xmmword_2272CB370;
      *(void *)(inited + 32) = v188;
      *(void *)(inited + 40) = v198;
      swift_bridgeObjectRetain();
      v96._uint64_t countAndFlagsBits = 0xD00000000000001CLL;
      v96._uint64_t object = (void *)0x80000002272D64D0;
      DataFrame.validateContainsColumns(_:context:)((Swift::OpaquePointer)inited, v96);
      uint64_t v161 = v97;
      if (v97)
      {
        swift_setDeallocating();
        uint64_t v0 = (uint64_t (*)())inited;
        specialized _ContiguousArrayStorage.__deallocating_deinit();
        swift_bridgeObjectRelease();
        swift_bridgeObjectRelease();
        outlined destroy of MLLogisticRegressionClassifier.ModelParameters(v70);
        OUTLINED_FUNCTION_38_5();
        OUTLINED_FUNCTION_25_10();
        v94();
        OUTLINED_FUNCTION_25_10();
        uint64_t v98 = ((uint64_t (*)(void))v94)();
        OUTLINED_FUNCTION_55_4(v98, &demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
        OUTLINED_FUNCTION_51_4();
        goto LABEL_18;
      }
      v190 = v94;
      swift_setDeallocating();
      specialized _ContiguousArrayStorage.__deallocating_deinit();
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Any.Type>);
      uint64_t v106 = swift_allocObject();
      *(_OWORD *)(v106 + 16) = xmmword_2272CB4D0;
      uint64_t v107 = MEMORY[0x263F8D6C8];
      *(void *)(v106 + 32) = MEMORY[0x263F8D310];
      *(void *)(v106 + 40) = v107;
      v108._uint64_t countAndFlagsBits = v188;
      v108._uint64_t object = v198;
      v109._uint64_t countAndFlagsBits = 0xD00000000000001CLL;
      v109._uint64_t object = (void *)0x80000002272D64D0;
      uint64_t v0 = v93;
      DataFrame.validateColumnTypes(_:_:context:)(v108, (Swift::OpaquePointer)v106, v109);
      if (v110)
      {
        swift_bridgeObjectRelease();
        swift_bridgeObjectRelease();
        swift_bridgeObjectRelease();
        outlined destroy of MLLogisticRegressionClassifier.ModelParameters(v70);
        OUTLINED_FUNCTION_38_5();
        v111 = v190;
        OUTLINED_FUNCTION_25_10();
        v111();
        OUTLINED_FUNCTION_25_10();
        uint64_t v112 = ((uint64_t (*)(void))v111)();
        OUTLINED_FUNCTION_55_4(v112, &demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
        OUTLINED_FUNCTION_51_4();
        goto LABEL_18;
      }
      uint64_t v161 = v77;
      uint64_t v85 = v193;
      OUTLINED_FUNCTION_25_10();
      v115();
      swift_bridgeObjectRelease();
      uint64_t v8 = v159;
    }
    MEMORY[0x22A672220](v188, v198);
    OUTLINED_FUNCTION_31_4();
    uint64_t v86 = v184;
    uint64_t v88 = v184 + v87;
    OUTLINED_FUNCTION_46_4();
    v89();
    outlined init with copy of Any?(v191, v88, &demangling cache variable for type metadata for DataFrame?);
    uint64_t v90 = v88;
    uint64_t v91 = v185;
    outlined init with take of DataFrame?(v90, v185, &demangling cache variable for type metadata for DataFrame?);
    OUTLINED_FUNCTION_57_4(v91, 1, v85);
    uint64_t v0 = v187;
    if (v84)
    {
      OUTLINED_FUNCTION_15_9();
      v92();
      outlined destroy of URL?(v91, &demangling cache variable for type metadata for DataFrame?);
      __swift_storeEnumTagSinglePayload(v183, 1, 1, v182);
    }
    else
    {
      uint64_t v99 = v91;
      uint64_t v100 = v183;
      MEMORY[0x22A672220](v188, v198);
      uint64_t v101 = v99;
      v102 = v190;
      ((void (*)(uint64_t, uint64_t))v190)(v101, v85);
      __swift_storeEnumTagSinglePayload(v100, 0, 1, v182);
      ((void (*)(uint64_t, uint64_t))v102)(v86, v85);
      uint64_t v0 = v187;
    }
    outlined init with copy of MLLogisticRegressionClassifier.ModelParameters(v70, (uint64_t)v195);
    swift_bridgeObjectRetain();
    uint64_t v103 = v161;
    swift_bridgeObjectRetain();
    OUTLINED_FUNCTION_47_4();
    MLLogisticRegressionClassifier.Classifier.init(trainingLabelsColumn:validationLabelsColumn:annotationColumnName:featureColumnNames:parameters:)();
    uint64_t v104 = (uint64_t)v164;
    if (*(void *)(*((void *)v0 + 13) + 16) <= 1uLL)
    {
      swift_bridgeObjectRelease();
      swift_bridgeObjectRelease();
      OUTLINED_FUNCTION_85();
      OUTLINED_FUNCTION_32_2(v113, 0xD000000000000027);
      swift_willThrow();
      outlined destroy of MLLogisticRegressionClassifier.ModelParameters(v70);
      OUTLINED_FUNCTION_15_9();
      v114();
      outlined destroy of MLLogisticRegressionClassifier.ModelParameters.ValidationData((uint64_t)v0, (void (*)(void))type metadata accessor for MLLogisticRegressionClassifier.Classifier);
      outlined destroy of URL?(v104, &demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
      goto LABEL_17;
    }
    uint64_t v105 = v180;
    MLLogisticRegressionClassifier.Classifier.fitted(to:validateOn:eventHandler:)();
    uint64_t v159 = v8;
    v116 = v176;
    uint64_t v117 = v179;
    v118 = (void *)(v179 + v176[6]);
    v186 = v118;
    void *v118 = v188;
    v118[1] = v198;
    uint64_t v199 = v117 + v116[8];
    outlined init with copy of MLLogisticRegressionClassifier.ModelParameters(v70, v199);
    uint64_t v119 = (uint64_t)v105;
    uint64_t v120 = v70;
    uint64_t v188 = v116[7];
    *(void *)(v117 + v188) = v103;
    v121 = (void *)v119;
    uint64_t v122 = v178;
    outlined init with copy of MLClassifierMetrics(v119, v178, (void (*)(void))type metadata accessor for MLLogisticRegressionClassifier.Model);
    unint64_t v123 = (*(unsigned __int8 *)(v177 + 80) + 16) & ~(unint64_t)*(unsigned __int8 *)(v177 + 80);
    uint64_t v124 = swift_allocObject();
    outlined init with take of MLLogisticRegressionClassifier.Model(v122, v124 + v123, (void (*)(void))type metadata accessor for MLLogisticRegressionClassifier.Model);
    specialized blockAwait<A>(_:)();
    uint64_t v126 = v125;
    uint64_t v185 = v120;
    swift_release();
    uint64_t v127 = v116[5];
    *(void *)(v117 + v127) = v126;
    uint64_t v128 = OUTLINED_FUNCTION_42_4();
    outlined init with copy of MLClassifierMetrics(v128, v129, v130);
    uint64_t v131 = v174;
    uint64_t v132 = (uint64_t)v164;
    MLLogisticRegressionClassifier.Model.applied(to:eventHandler:)(v174);
    uint64_t v161 = 0;
    uint64_t v135 = *v121;
    uint64_t v136 = v121[1];
    MEMORY[0x22A672220](*v121, v136);
    MEMORY[0x22A672220](v135, v136);
    uint64_t v137 = v172;
    v138 = v190;
    AnyClassificationMetrics.init(_:_:)();
    uint64_t v139 = v194;
    uint64_t v140 = v193;
    uint64_t v184 = v194 + 8;
    ((void (*)(uint64_t, uint64_t))v138)(v131, v193);
    uint64_t v141 = v137;
    uint64_t v142 = v171;
    outlined init with take of MLLogisticRegressionClassifier.Model(v141, v171, (void (*)(void))type metadata accessor for AnyClassificationMetrics);
    swift_storeEnumTagMultiPayload();
    outlined assign with take of MLClassifierMetrics(v142, v192);
    OUTLINED_FUNCTION_31_4();
    uint64_t v143 = v170;
    uint64_t v145 = v170 + v144;
    v162(v170, v132, v140);
    outlined init with copy of Any?(v191, v145, &demangling cache variable for type metadata for DataFrame?);
    OUTLINED_FUNCTION_57_4(v145, 1, v140);
    if (v84)
    {
      OUTLINED_FUNCTION_54_4();
      OUTLINED_FUNCTION_53_5();
      OUTLINED_FUNCTION_11_3();
      v138();
      uint64_t v146 = outlined destroy of MLLogisticRegressionClassifier.ModelParameters.ValidationData((uint64_t)v121, (void (*)(void))type metadata accessor for MLLogisticRegressionClassifier.Model);
      OUTLINED_FUNCTION_48_3(v146, (void (*)(void))type metadata accessor for MLLogisticRegressionClassifier.Classifier);
      outlined destroy of URL?(v132, &demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
      outlined destroy of URL?(v145, &demangling cache variable for type metadata for DataFrame?);
      OUTLINED_FUNCTION_11_3();
      v138();
      goto LABEL_19;
    }
    uint64_t v147 = v169;
    (*(void (**)(uint64_t, uint64_t, uint64_t))(v139 + 32))(v169, v145, v140);
    ((void (*)(uint64_t, uint64_t))v138)(v143, v140);
    uint64_t v148 = v161;
    MLLogisticRegressionClassifier.Model.applied(to:eventHandler:)(v168);
    uint64_t v161 = v148;
    if (!v148)
    {
      v150 = v180;
      uint64_t v151 = *v180;
      uint64_t v152 = v180[1];
      MEMORY[0x22A672220](*v180, v152);
      MEMORY[0x22A672220](v151, v152);
      uint64_t v153 = v167;
      AnyClassificationMetrics.init(_:_:)();
      OUTLINED_FUNCTION_35_6();
      v138();
      OUTLINED_FUNCTION_54_4();
      OUTLINED_FUNCTION_35_6();
      v138();
      OUTLINED_FUNCTION_35_6();
      v138();
      uint64_t v154 = outlined destroy of MLLogisticRegressionClassifier.ModelParameters.ValidationData((uint64_t)v150, (void (*)(void))type metadata accessor for MLLogisticRegressionClassifier.Model);
      uint64_t v155 = OUTLINED_FUNCTION_48_3(v154, (void (*)(void))type metadata accessor for MLLogisticRegressionClassifier.Classifier);
      OUTLINED_FUNCTION_55_4(v155, &demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
      uint64_t v156 = v153;
      uint64_t v157 = v166;
      outlined init with take of MLLogisticRegressionClassifier.Model(v156, v166, (void (*)(void))type metadata accessor for AnyClassificationMetrics);
      swift_storeEnumTagMultiPayload();
      outlined assign with take of MLClassifierMetrics(v157, (uint64_t)v189);
      goto LABEL_19;
    }
    OUTLINED_FUNCTION_54_4();
    uint64_t v149 = OUTLINED_FUNCTION_53_5();
    ((void (*)(uint64_t))v138)(v149);
    ((void (*)(uint64_t, uint64_t))v138)(v147, v140);
    uint64_t v0 = type metadata accessor for MLLogisticRegressionClassifier.Model;
    uint64_t v133 = outlined destroy of MLLogisticRegressionClassifier.ModelParameters.ValidationData((uint64_t)v180, (void (*)(void))type metadata accessor for MLLogisticRegressionClassifier.Model);
    OUTLINED_FUNCTION_48_3(v133, (void (*)(void))type metadata accessor for MLLogisticRegressionClassifier.Classifier);
    outlined destroy of URL?(v132, &demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
    uint64_t v134 = v179;
    outlined destroy of MLLogisticRegressionClassifier.ModelParameters.ValidationData(v179, (void (*)(void))type metadata accessor for MLLogisticRegressionClassifier.Model);

    OUTLINED_FUNCTION_51_4();
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    outlined destroy of MLLogisticRegressionClassifier.ModelParameters(v199);
LABEL_18:
    outlined destroy of MLLogisticRegressionClassifier.ModelParameters.ValidationData(v192, (void (*)(void))type metadata accessor for MLClassifierMetrics);
    outlined destroy of MLLogisticRegressionClassifier.ModelParameters.ValidationData((uint64_t)v0, (void (*)(void))type metadata accessor for MLClassifierMetrics);
LABEL_19:
    OUTLINED_FUNCTION_8_1();
    return;
  }
  __break(1u);
}

uint64_t partial apply for closure #1 in MLLogisticRegressionClassifier.init(trainingData:targetColumn:featureColumns:parameters:)()
{
  OUTLINED_FUNCTION_11();
  uint64_t v0 = type metadata accessor for MLLogisticRegressionClassifier.Model();
  OUTLINED_FUNCTION_39_0(v0);
  OUTLINED_FUNCTION_40_3();
  uint64_t v1 = swift_task_alloc();
  uint64_t v2 = (void *)OUTLINED_FUNCTION_7_1(v1);
  *uint64_t v2 = v3;
  v2[1] = partial apply for closure #1 in MLLogisticRegressionClassifier.init(trainingData:targetColumn:featureColumns:parameters:);
  uint64_t v4 = OUTLINED_FUNCTION_36_4();
  return closure #1 in MLLogisticRegressionClassifier.init(_:targetColumn:featureColumns:parameters:)(v4);
}

uint64_t MLLogisticRegressionClassifier.init(trainingData:targetColumn:featureColumns:parameters:)(uint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v7 = type metadata accessor for DataFrame();
  uint64_t v8 = OUTLINED_FUNCTION_17(v7);
  MEMORY[0x270FA5388](v8);
  OUTLINED_FUNCTION_3_0();
  uint64_t v11 = v10 - v9;
  LOBYTE(v10) = *((unsigned char *)a1 + 8);
  uint64_t v13 = *a1;
  char v14 = v10;
  DataFrame.init(_:)((uint64_t)&v13, v11);
  outlined init with copy of MLLogisticRegressionClassifier.ModelParameters(a5, (uint64_t)&v13);
  MLLogisticRegressionClassifier.init(trainingData:targetColumn:featureColumns:parameters:)();
  return outlined destroy of MLLogisticRegressionClassifier.ModelParameters(a5);
}

void MLLogisticRegressionClassifier.init(checkpoint:)()
{
  OUTLINED_FUNCTION_9_0();
  uint64_t v55 = v1;
  uint64_t v3 = v2;
  uint64_t v5 = v4;
  uint64_t v50 = type metadata accessor for MLLogisticRegressionClassifier.ModelParameters.ValidationData();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v6);
  OUTLINED_FUNCTION_49();
  uint64_t v49 = v7;
  MEMORY[0x270FA5388](v8);
  OUTLINED_FUNCTION_106();
  uint64_t v51 = v9;
  uint64_t v10 = type metadata accessor for MLLogisticRegressionClassifier.Model();
  uint64_t v11 = OUTLINED_FUNCTION_1(v10);
  uint64_t v53 = v12;
  uint64_t v14 = *(void *)(v13 + 64);
  uint64_t v15 = MEMORY[0x270FA5388](v11);
  uint64_t v54 = (uint64_t)&v49 - ((v14 + 15) & 0xFFFFFFFFFFFFFFF0);
  MEMORY[0x270FA5388](v15);
  OUTLINED_FUNCTION_106();
  uint64_t v59 = v16;
  type metadata accessor for MLLogisticRegressionClassifier.Classifier();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v17);
  OUTLINED_FUNCTION_30_2();
  uint64_t v18 = (int *)type metadata accessor for MLLogisticRegressionClassifier();
  MLClassifierMetrics.init()((uint64_t)v18, v19, v20, v21, v22, v23, v24, v25, v49, v50, (uint64_t)v51, v52, v53, v54, v55, v5 + v18[9], v57[0], v57[1], v57[2],
    v58);
  uint64_t v26 = (void *)(v5 + v18[10]);
  lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  OUTLINED_FUNCTION_85();
  OUTLINED_FUNCTION_32_2(v27, 0xD0000000000000C0);
  *uint64_t v26 = v28;
  type metadata accessor for MLClassifierMetrics.Contents(0);
  swift_storeEnumTagMultiPayload();
  uint64_t v29 = *(unsigned __int8 *)(v3 + *(int *)(type metadata accessor for MLCheckpoint() + 20));
  uint64_t v52 = v5;
  switch(v29)
  {
    case 2:
      uint64_t v30 = v3;
      swift_bridgeObjectRelease();
      goto LABEL_4;
    default:
      uint64_t v30 = v3;
      char v31 = _stringCompareWithSmolCheck(_:_:expecting:)();
      swift_bridgeObjectRelease();
      if (v31)
      {
LABEL_4:
        MLLogisticRegressionClassifier.Classifier.init(labels:annotationColumnName:featureColumnNames:)(MEMORY[0x263F8EE78], 1, 0, 0xE000000000000000, MEMORY[0x263F8EE78], v0);
        lazy protocol witness table accessor for type MLLogisticRegressionClassifier.Classifier and conformance MLLogisticRegressionClassifier.Classifier();
        uint64_t v32 = v30;
        uint64_t v33 = v55;
        UpdatableSupervisedTabularEstimator.readWithOptimizer(from:)();
        if (!v33)
        {
          uint64_t v35 = v54;
          outlined init with copy of MLClassifierMetrics(v59, v54, (void (*)(void))type metadata accessor for MLLogisticRegressionClassifier.Model);
          unint64_t v36 = (*(unsigned __int8 *)(v53 + 80) + 16) & ~(unint64_t)*(unsigned __int8 *)(v53 + 80);
          uint64_t v37 = swift_allocObject();
          outlined init with take of MLLogisticRegressionClassifier.Model(v35, v37 + v36, (void (*)(void))type metadata accessor for MLLogisticRegressionClassifier.Model);
          specialized blockAwait<A>(_:)();
          uint64_t v39 = v38;
          swift_release();
          uint64_t v42 = v52;
          *(void *)(v52 + v18[5]) = v39;
          outlined init with copy of MLClassifierMetrics(v59, v42, (void (*)(void))type metadata accessor for MLLogisticRegressionClassifier.Model);
          uint64_t v44 = v50;
          uint64_t v43 = v51;
          *uint64_t v51 = 0;
          v43[1] = 0;
          *((_WORD *)v43 + 8) = 256;
          swift_storeEnumTagMultiPayload();
          uint64_t v45 = v42 + v18[8];
          *(_OWORD *)(v45 + 40) = xmmword_2272CC8C0;
          *(_OWORD *)(v45 + 56) = xmmword_2272CC8D0;
          *(_OWORD *)(v45 + 24) = 0u;
          *(void *)uint64_t v45 = 10;
          *(unsigned char *)(v45 + 72) = 1;
          *(_OWORD *)(v45 + 8) = 0u;
          uint64_t v46 = v49;
          outlined init with copy of MLClassifierMetrics((uint64_t)v43, v49, (void (*)(void))type metadata accessor for MLLogisticRegressionClassifier.ModelParameters.ValidationData);
          uint64_t v58 = v44;
          boxed_opaque_existential_0 = __swift_allocate_boxed_opaque_existential_0(v57);
          outlined init with take of MLLogisticRegressionClassifier.Model(v46, (uint64_t)boxed_opaque_existential_0, (void (*)(void))type metadata accessor for MLLogisticRegressionClassifier.ModelParameters.ValidationData);
          outlined assign with take of Any?((uint64_t)v57, v45 + 8);
          outlined destroy of MLLogisticRegressionClassifier.ModelParameters.ValidationData((uint64_t)v43, (void (*)(void))type metadata accessor for MLLogisticRegressionClassifier.ModelParameters.ValidationData);
          uint64_t v48 = (void *)(v42 + v18[6]);
          *uint64_t v48 = 0;
          v48[1] = 0xE000000000000000;
          outlined destroy of MLLogisticRegressionClassifier.ModelParameters.ValidationData(v32, (void (*)(void))type metadata accessor for MLCheckpoint);
          outlined destroy of MLLogisticRegressionClassifier.ModelParameters.ValidationData(v59, (void (*)(void))type metadata accessor for MLLogisticRegressionClassifier.Model);
          outlined destroy of MLLogisticRegressionClassifier.ModelParameters.ValidationData(v0, (void (*)(void))type metadata accessor for MLLogisticRegressionClassifier.Classifier);
          *(void *)(v42 + v18[7]) = MEMORY[0x263F8EE78];
          goto LABEL_9;
        }
        outlined destroy of MLLogisticRegressionClassifier.ModelParameters.ValidationData(v30, (void (*)(void))type metadata accessor for MLCheckpoint);
        uint64_t v40 = type metadata accessor for MLLogisticRegressionClassifier.Classifier;
        uint64_t v41 = v0;
      }
      else
      {
        OUTLINED_FUNCTION_85();
        *(void *)uint64_t v34 = 0xD000000000000049;
        *(void *)(v34 + 8) = 0x80000002272D64F0;
        *(_OWORD *)(v34 + 16) = 0u;
        *(_OWORD *)(v34 + 32) = 0u;
        *(unsigned char *)(v34 + 48) = 0;
        swift_willThrow();
        uint64_t v40 = type metadata accessor for MLCheckpoint;
        uint64_t v41 = v30;
      }
      outlined destroy of MLLogisticRegressionClassifier.ModelParameters.ValidationData(v41, (void (*)(void))v40);
      outlined destroy of MLLogisticRegressionClassifier.ModelParameters.ValidationData(v56, (void (*)(void))type metadata accessor for MLClassifierMetrics);
      outlined destroy of MLLogisticRegressionClassifier.ModelParameters.ValidationData((uint64_t)v26, (void (*)(void))type metadata accessor for MLClassifierMetrics);
LABEL_9:
      OUTLINED_FUNCTION_8_1();
      return;
  }
}

uint64_t closure #1 in MLLogisticRegressionClassifier.init(checkpoint:)(uint64_t a1)
{
  *(void *)(v1 + 16) = a1;
  uint64_t v4 = (uint64_t (__cdecl *)())((char *)&async function pointer to specialized CoreMLExportable.exportAsCoreMLModel()
                             + async function pointer to specialized CoreMLExportable.exportAsCoreMLModel());
  uint64_t v2 = (void *)swift_task_alloc();
  *(void *)(v1 + 24) = v2;
  *uint64_t v2 = v1;
  v2[1] = closure #1 in MLLogisticRegressionClassifier.init(checkpoint:);
  return v4();
}

{
  uint64_t v1;
  uint64_t *v2;
  uint64_t v4;
  uint64_t v5;
  void *v6;
  uint64_t v7;
  void *v8;
  uint64_t (*v9)(void);
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;

  OUTLINED_FUNCTION_2();
  uint64_t v5 = v4;
  OUTLINED_FUNCTION_34_5();
  *uint64_t v6 = v5;
  uint64_t v7 = *v2;
  OUTLINED_FUNCTION_6();
  *uint64_t v8 = v7;
  swift_task_dealloc();
  if (v1)
  {
    OUTLINED_FUNCTION_33_5();
    return v9();
  }
  else
  {
    *(void *)(v5 + 32) = a1;
    OUTLINED_FUNCTION_32_6();
    return MEMORY[0x270FA2498](v11, v12, v13);
  }
}

void static MLLogisticRegressionClassifier.train(trainingData:targetColumn:featureColumns:parameters:sessionParameters:)()
{
  OUTLINED_FUNCTION_9_0();
  OUTLINED_FUNCTION_42_0();
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v2);
  OUTLINED_FUNCTION_3_0();
  uint64_t v5 = v4 - v3;
  char v6 = *(unsigned char *)(v1 + 8);
  id v8 = *(id *)v1;
  char v9 = v6;
  outlined copy of Result<_DataTable, Error>(v8, v6);
  DataFrame.init(_:)((uint64_t)&v8, v5);
  static MLLogisticRegressionClassifier.makeTrainingSession(trainingData:targetColumn:featureColumns:parameters:sessionParameters:)();
  OUTLINED_FUNCTION_11_3();
  v7();
  if (!v0)
  {
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLJob<MLLogisticRegressionClassifier>);
    OUTLINED_FUNCTION_31_0();
    specialized MLJob.init(_:)();
  }
  OUTLINED_FUNCTION_8_1();
}

{
  uint64_t v0;

  static MLLogisticRegressionClassifier.makeTrainingSession(trainingData:targetColumn:featureColumns:parameters:sessionParameters:)();
  if (!v0)
  {
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLJob<MLLogisticRegressionClassifier>);
    OUTLINED_FUNCTION_31_0();
    specialized MLJob.init(_:)();
  }
}

void static MLLogisticRegressionClassifier.makeTrainingSession(trainingData:targetColumn:featureColumns:parameters:sessionParameters:)()
{
  OUTLINED_FUNCTION_9_0();
  uint64_t v2 = OUTLINED_FUNCTION_42_0();
  OUTLINED_FUNCTION_0();
  uint64_t v4 = v3;
  MEMORY[0x270FA5388](v5);
  OUTLINED_FUNCTION_15();
  char v6 = *(unsigned char *)(v1 + 8);
  id v7 = *(id *)v1;
  char v8 = v6;
  outlined copy of Result<_DataTable, Error>(v7, v6);
  DataFrame.init(_:)((uint64_t)&v7, v0);
  static MLLogisticRegressionClassifier.makeTrainingSession(trainingData:targetColumn:featureColumns:parameters:sessionParameters:)();
  (*(void (**)(uint64_t, uint64_t))(v4 + 8))(v0, v2);
  OUTLINED_FUNCTION_8_1();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  char *v20;
  uint64_t v21;
  uint64_t v22;
  char *v23;
  uint64_t v24;
  char *v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  char *v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  void (*v33)(uint64_t, char *, uint64_t);
  uint64_t v34;
  uint64_t v35;
  uint64_t v36;
  uint64_t v37;
  uint64_t v38;
  void (*v39)(void);
  uint64_t v40;
  void v41[4];
  uint64_t v42;
  uint64_t v43;
  uint64_t v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  long long v49;
  uint64_t v50;
  _UNKNOWN **v51;
  long long v52;
  uint64_t v53;
  uint64_t v54;

  OUTLINED_FUNCTION_9_0();
  uint64_t v54 = v2;
  uint64_t v4 = v3;
  uint64_t v47 = v5;
  uint64_t v48 = v6;
  uint64_t v46 = v7;
  char v9 = v8;
  uint64_t v10 = type metadata accessor for MLTrainingSessionParameters();
  uint64_t v11 = OUTLINED_FUNCTION_17(v10);
  MEMORY[0x270FA5388](v11);
  OUTLINED_FUNCTION_49();
  uint64_t v43 = v12;
  MEMORY[0x270FA5388](v13);
  OUTLINED_FUNCTION_106();
  uint64_t v45 = v14;
  type metadata accessor for MLLogisticRegressionClassifier.ModelParameters.ValidationData();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v15);
  OUTLINED_FUNCTION_15();
  uint64_t v16 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
  OUTLINED_FUNCTION_8();
  uint64_t v18 = MEMORY[0x270FA5388](v17);
  uint64_t v20 = (char *)v41 - ((v19 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v21 = MEMORY[0x270FA5388](v18);
  uint64_t v23 = (char *)v41 - v22;
  MEMORY[0x270FA5388](v21);
  uint64_t v25 = (char *)v41 - v24;
  uint64_t v44 = v4;
  outlined init with copy of Any?(v4 + 8, (uint64_t)&v52, &demangling cache variable for type metadata for Any?);
  if (v53)
  {
    uint64_t v26 = (uint64_t)&v25[*(int *)(v16 + 48)];
    outlined init with take of Any(&v52, &v49);
    swift_dynamicCast();
    MLLogisticRegressionClassifier.ModelParameters.ValidationData.generateDataFrames(trainingData:)((uint64_t)v25, v26, v9);
    outlined destroy of MLLogisticRegressionClassifier.ModelParameters.ValidationData(v0, (void (*)(void))type metadata accessor for MLLogisticRegressionClassifier.ModelParameters.ValidationData);
    if (!v1)
    {
      uint64_t v27 = (uint64_t)&v23[*(int *)(v16 + 48)];
      uint64_t v28 = type metadata accessor for DataFrame();
      v41[0] = v23;
      uint64_t v29 = v20;
      uint64_t v30 = v28;
      OUTLINED_FUNCTION_0();
      v41[1] = v31;
      uint64_t v33 = *(void (**)(uint64_t, char *, uint64_t))(v32 + 16);
      v33(v34, v25, v30);
      uint64_t v42 = v27;
      outlined init with copy of Any?(v26, v27, &demangling cache variable for type metadata for DataFrame?);
      uint64_t v35 = (uint64_t)&v29[*(int *)(v16 + 48)];
      v41[2] = v29;
      v41[3] = v30;
      v33((uint64_t)v29, v25, v30);
      outlined init with copy of Any?(v26, v35, &demangling cache variable for type metadata for DataFrame?);
      outlined init with copy of MLLogisticRegressionClassifier.ModelParameters(v44, (uint64_t)&v49);
      outlined init with copy of MLClassifierMetrics(v54, v45, (void (*)(void))type metadata accessor for MLTrainingSessionParameters);
      unint64_t v36 = type metadata accessor for LogisticRegressionClassifierTrainingSessionDelegate();
      OUTLINED_FUNCTION_31_0();
      swift_bridgeObjectRetain();
      swift_bridgeObjectRetain();
      LogisticRegressionClassifierTrainingSessionDelegate.init(trainingData:validationData:targetColumn:featureColumns:modelParameters:sessionParameters:)();
      uint64_t v38 = v37;
      OUTLINED_FUNCTION_16_9();
      v39();
      outlined destroy of URL?(v42, &demangling cache variable for type metadata for DataFrame?);
      uint64_t v50 = v36;
      uint64_t v51 = &protocol witness table for LogisticRegressionClassifierTrainingSessionDelegate;
      *(void *)&uint64_t v49 = v38;
      uint64_t v40 = v43;
      outlined init with copy of MLClassifierMetrics(v54, v43, (void (*)(void))type metadata accessor for MLTrainingSessionParameters);
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLLogisticRegressionClassifier>);
      OUTLINED_FUNCTION_31_0();
      swift_retain();
      specialized MLTrainingSession.init(delegate:parameters:modelType:)((uint64_t)&v49, v40, 8);
      outlined destroy of URL?((uint64_t)v25, &demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
      swift_release();
    }
    OUTLINED_FUNCTION_8_1();
  }
  else
  {
    __break(1u);
  }
}

uint64_t static MLLogisticRegressionClassifier.resume(_:)()
{
  return specialized MLJob.init(_:)();
}

void static MLLogisticRegressionClassifier.restoreTrainingSession(sessionParameters:)(uint64_t a1)
{
  uint64_t v3 = type metadata accessor for MLTrainingSessionParameters();
  uint64_t v4 = OUTLINED_FUNCTION_17(v3);
  uint64_t v5 = MEMORY[0x270FA5388](v4);
  id v7 = (char *)&v16[-1] - ((v6 + 15) & 0xFFFFFFFFFFFFFFF0);
  MEMORY[0x270FA5388](v5);
  char v9 = (char *)&v16[-1] - v8;
  outlined init with copy of MLClassifierMetrics(a1, (uint64_t)&v16[-1] - v8, (void (*)(void))type metadata accessor for MLTrainingSessionParameters);
  uint64_t v10 = type metadata accessor for LogisticRegressionClassifierTrainingSessionDelegate();
  OUTLINED_FUNCTION_31_0();
  uint64_t v11 = LogisticRegressionClassifierTrainingSessionDelegate.init(sessionParameters:)((uint64_t)v9);
  if (!v1)
  {
    v16[3] = v10;
    v16[4] = &protocol witness table for LogisticRegressionClassifierTrainingSessionDelegate;
    v16[0] = v11;
    uint64_t v12 = OUTLINED_FUNCTION_47_4();
    outlined init with copy of MLClassifierMetrics(v12, v13, v14);
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLLogisticRegressionClassifier>);
    OUTLINED_FUNCTION_31_0();
    specialized MLTrainingSession.init(delegate:parameters:modelType:)((uint64_t)v16, (uint64_t)v7, 8);
  }
}

uint64_t closure #1 in closure #1 in static MLLogisticRegressionClassifier.resume(_:)(void *a1, char a2, uint64_t a3, void (*a4)(void *))
{
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Result<MLLogisticRegressionClassifier, Error>);
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v8);
  OUTLINED_FUNCTION_3_0();
  uint64_t v11 = (void *)(v10 - v9);
  if (a2)
  {
    *uint64_t v11 = a1;
    swift_storeEnumTagMultiPayload();
    id v12 = a1;
    a4(v11);
  }
  else
  {
    outlined init with copy of TrainingSessionDelegate(a3 + direct field offset for MLTrainingSession.delegate, (uint64_t)v14);
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for TrainingSessionDelegate);
    type metadata accessor for LogisticRegressionClassifierTrainingSessionDelegate();
    swift_dynamicCast();
    swift_retain();
    _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML30MLLogisticRegressionClassifierV_s5Error_pTgm503_s8c4ML30efg80V12handleResult33_66687B25F10324110578427E448BFE6CLL_7session7fulfillys0G0Oyyts5H55_pG_AA17MLTrainingSessionCyACGyAIyACsAJ_pGctFZACyKXEfU_AE08Logisticfg8TrainingW8DelegateCTf1nc_n((uint64_t)v11);
    a4(v11);
    swift_release();
  }
  return outlined destroy of URL?((uint64_t)v11, &demangling cache variable for type metadata for Result<MLLogisticRegressionClassifier, Error>);
}

void MLLogisticRegressionClassifier.init(delegate:)()
{
  OUTLINED_FUNCTION_9_0();
  uint64_t v6 = v5;
  uint64_t v47 = v7;
  uint64_t v46 = type metadata accessor for MLClassifierMetrics(0);
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v8);
  OUTLINED_FUNCTION_33_0();
  OUTLINED_FUNCTION_45_2(v9);
  uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLClassifierMetrics?);
  uint64_t v11 = OUTLINED_FUNCTION_17(v10);
  MEMORY[0x270FA5388](v11);
  OUTLINED_FUNCTION_49();
  OUTLINED_FUNCTION_16_2();
  MEMORY[0x270FA5388](v12);
  uint64_t v14 = (char *)&v42 - v13;
  uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLLogisticRegressionClassifier.Model?);
  uint64_t v16 = OUTLINED_FUNCTION_17(v15);
  MEMORY[0x270FA5388](v16);
  OUTLINED_FUNCTION_24_8();
  uint64_t v44 = type metadata accessor for MLLogisticRegressionClassifier();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v17);
  OUTLINED_FUNCTION_15();
  uint64_t v18 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLLogisticRegressionClassifier.PersistentParameters?);
  uint64_t v19 = OUTLINED_FUNCTION_17(v18);
  MEMORY[0x270FA5388](v19);
  OUTLINED_FUNCTION_41_0();
  uint64_t v20 = (int *)type metadata accessor for MLLogisticRegressionClassifier.PersistentParameters();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v21);
  OUTLINED_FUNCTION_22_0();
  uint64_t v22 = v6 + OBJC_IVAR____TtC8CreateML51LogisticRegressionClassifierTrainingSessionDelegate_trainingParameters;
  OUTLINED_FUNCTION_53();
  outlined init with copy of Any?(v22, v3, &demangling cache variable for type metadata for MLLogisticRegressionClassifier.PersistentParameters?);
  OUTLINED_FUNCTION_57_4(v3, 1, (uint64_t)v20);
  if (v23)
  {
    __break(1u);
    goto LABEL_11;
  }
  outlined init with take of MLLogisticRegressionClassifier.Model(v3, v4, (void (*)(void))type metadata accessor for MLLogisticRegressionClassifier.PersistentParameters);
  outlined init with copy of MLLogisticRegressionClassifier.ModelParameters(v4 + v20[8], (uint64_t)v49);
  uint64_t v24 = v20[7];
  uint64_t v25 = (uint64_t *)(v4 + v20[6]);
  uint64_t v27 = *v25;
  uint64_t v26 = v25[1];
  uint64_t v28 = *(void *)(v4 + v24);
  OUTLINED_FUNCTION_53();
  uint64_t v29 = OUTLINED_FUNCTION_42_4();
  outlined init with copy of Any?(v29, v30, v31);
  uint64_t v32 = type metadata accessor for MLLogisticRegressionClassifier.Model();
  OUTLINED_FUNCTION_57_4(v0, 1, v32);
  if (v23)
  {
LABEL_11:
    __break(1u);
    goto LABEL_12;
  }
  outlined init with copy of MLLogisticRegressionClassifier.ModelParameters((uint64_t)v49, (uint64_t)v48);
  swift_bridgeObjectRetain();
  swift_bridgeObjectRetain();
  MLLogisticRegressionClassifier.init(_:targetColumn:featureColumns:parameters:)(v0, v27, v26, v28, v48);
  if (v2)
  {
    swift_release();
    outlined destroy of MLLogisticRegressionClassifier.ModelParameters((uint64_t)v49);
    outlined destroy of MLLogisticRegressionClassifier.ModelParameters.ValidationData(v4, (void (*)(void))type metadata accessor for MLLogisticRegressionClassifier.PersistentParameters);
LABEL_9:
    OUTLINED_FUNCTION_8_1();
    return;
  }
  uint64_t v33 = v47;
  outlined init with take of MLLogisticRegressionClassifier.Model(v1, v47, (void (*)(void))type metadata accessor for MLLogisticRegressionClassifier);
  uint64_t v34 = v6 + OBJC_IVAR____TtC8CreateML51LogisticRegressionClassifierTrainingSessionDelegate_trainingMetrics;
  OUTLINED_FUNCTION_53();
  outlined init with copy of Any?(v34, (uint64_t)v14, &demangling cache variable for type metadata for MLClassifierMetrics?);
  uint64_t v35 = v46;
  OUTLINED_FUNCTION_57_4((uint64_t)v14, 1, v46);
  if (!v23)
  {
    outlined destroy of MLLogisticRegressionClassifier.ModelParameters((uint64_t)v49);
    outlined destroy of MLLogisticRegressionClassifier.ModelParameters.ValidationData(v4, (void (*)(void))type metadata accessor for MLLogisticRegressionClassifier.PersistentParameters);
    uint64_t v36 = v44;
    outlined assign with take of MLClassifierMetrics((uint64_t)v14, v33 + *(int *)(v44 + 36));
    uint64_t v37 = v6 + OBJC_IVAR____TtC8CreateML51LogisticRegressionClassifierTrainingSessionDelegate_validationMetrics;
    OUTLINED_FUNCTION_53();
    uint64_t v38 = v37;
    uint64_t v39 = v45;
    outlined init with copy of Any?(v38, v45, &demangling cache variable for type metadata for MLClassifierMetrics?);
    swift_release();
    OUTLINED_FUNCTION_57_4(v39, 1, v35);
    if (v23)
    {
      outlined destroy of URL?(v39, &demangling cache variable for type metadata for MLClassifierMetrics?);
    }
    else
    {
      uint64_t v40 = v39;
      uint64_t v41 = v43;
      outlined init with take of MLLogisticRegressionClassifier.Model(v40, v43, (void (*)(void))type metadata accessor for MLClassifierMetrics);
      outlined assign with take of MLClassifierMetrics(v41, v33 + *(int *)(v36 + 40));
    }
    goto LABEL_9;
  }
LABEL_12:
  __break(1u);
}

void MLLogisticRegressionClassifier.predictions(from:)()
{
  type metadata accessor for DataFrame();
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v2);
  OUTLINED_FUNCTION_31_1();
  type metadata accessor for MLLogisticRegressionClassifier();
  OUTLINED_FUNCTION_39_1();
  DataFrame.validateContainsColumns(_:context:)(v3, v4);
  if (!v5)
  {
    MLLogisticRegressionClassifier.Model.applied(to:eventHandler:)(v1);
    MEMORY[0x22A672220](*v0, v0[1]);
    uint64_t v6 = OUTLINED_FUNCTION_42_4();
    v7(v6);
  }
}

uint64_t MLLogisticRegressionClassifier.predictions(from:)(uint64_t a1)
{
  OUTLINED_FUNCTION_50_3();
  type metadata accessor for DataFrame();
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v6);
  OUTLINED_FUNCTION_31_1();
  uint64_t v7 = type metadata accessor for AnyColumn();
  uint64_t v8 = OUTLINED_FUNCTION_17(v7);
  MEMORY[0x270FA5388](v8);
  OUTLINED_FUNCTION_27_7();
  char v9 = *(unsigned char *)(a1 + 8);
  id v13 = *(id *)a1;
  char v14 = v9;
  outlined copy of Result<_DataTable, Error>(v13, v9);
  DataFrame.init(_:)((uint64_t)&v13, v3);
  MLLogisticRegressionClassifier.predictions(from:)();
  uint64_t v10 = OUTLINED_FUNCTION_47_0();
  if (v2) {
    return v11(v10);
  }
  v11(v10);
  return MLUntypedColumn.init(_:convertArraysToShapedArrays:)(v4, 1, v1);
}

uint64_t MLLogisticRegressionClassifier.evaluation(on:)(uint64_t a1)
{
  OUTLINED_FUNCTION_50_3();
  uint64_t v5 = type metadata accessor for AnyClassificationMetrics();
  uint64_t v6 = OUTLINED_FUNCTION_17(v5);
  MEMORY[0x270FA5388](v6);
  OUTLINED_FUNCTION_31_1();
  uint64_t v7 = type metadata accessor for MLLogisticRegressionClassifier();
  OUTLINED_FUNCTION_39_1();
  DataFrame.validateContainsColumns(_:context:)(v8, v9);
  if (v10) {
    goto LABEL_5;
  }
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<String>);
  uint64_t inited = swift_initStackObject();
  *(_OWORD *)(inited + 16) = xmmword_2272CB370;
  uint64_t v12 = (void *)(v2 + *(int *)(v7 + 24));
  uint64_t v13 = v12[1];
  *(void *)(inited + 32) = *v12;
  *(void *)(inited + 40) = v13;
  swift_bridgeObjectRetain();
  v14._uint64_t countAndFlagsBits = 0x6C6562614CLL;
  v14._uint64_t object = (void *)0xE500000000000000;
  DataFrame.validateContainsColumns(_:context:)((Swift::OpaquePointer)inited, v14);
  if (v10)
  {
    swift_setDeallocating();
    specialized _ContiguousArrayStorage.__deallocating_deinit();
LABEL_5:
    void *v1 = v10;
    type metadata accessor for MLClassifierMetrics.Contents(0);
    return swift_storeEnumTagMultiPayload();
  }
  swift_setDeallocating();
  specialized _ContiguousArrayStorage.__deallocating_deinit();
  MLLogisticRegressionClassifier.Model.computeMetrics(on:)(a1, v3);
  uint64_t v16 = OUTLINED_FUNCTION_42_4();
  outlined init with take of MLLogisticRegressionClassifier.Model(v16, v17, v18);
  type metadata accessor for MLClassifierMetrics.Contents(0);
  return swift_storeEnumTagMultiPayload();
}

{
  uint64_t v1;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  char v7;
  id v9;
  char v10;

  uint64_t v3 = type metadata accessor for DataFrame();
  OUTLINED_FUNCTION_0();
  uint64_t v5 = v4;
  MEMORY[0x270FA5388](v6);
  OUTLINED_FUNCTION_41_0();
  uint64_t v7 = *(unsigned char *)(a1 + 8);
  Swift::String v9 = *(id *)a1;
  uint64_t v10 = v7;
  outlined copy of Result<_DataTable, Error>(v9, v7);
  DataFrame.init(_:)((uint64_t)&v9, v1);
  MLLogisticRegressionClassifier.evaluation(on:)(v1);
  return (*(uint64_t (**)(uint64_t, uint64_t))(v5 + 8))(v1, v3);
}

void MLLogisticRegressionClassifier.write(to:metadata:)()
{
  OUTLINED_FUNCTION_9_0();
  uint64_t v49 = v0;
  uint64_t v3 = v2;
  uint64_t v55 = v4;
  uint64_t v5 = type metadata accessor for MLLogisticRegressionClassifier.Model();
  uint64_t v6 = OUTLINED_FUNCTION_17(v5);
  MEMORY[0x270FA5388](v6);
  OUTLINED_FUNCTION_33_0();
  uint64_t v54 = v7;
  uint64_t v47 = type metadata accessor for Model();
  OUTLINED_FUNCTION_0();
  uint64_t v52 = v8;
  MEMORY[0x270FA5388](v9);
  OUTLINED_FUNCTION_30_2();
  uint64_t v10 = type metadata accessor for URL();
  OUTLINED_FUNCTION_0();
  uint64_t v53 = v11;
  MEMORY[0x270FA5388](v12);
  uint64_t v14 = *v3;
  uint64_t v48 = v3[1];
  unint64_t v15 = v3[3];
  unint64_t v50 = v3[2];
  uint64_t v51 = v14;
  uint64_t v16 = v3[4];
  uint64_t v17 = v3[5];
  uint64_t v18 = v3[6];
  unint64_t v19 = v3[7];
  uint64_t v20 = v3[8];
  static _ValidationUtilities.validateWriteLocation(atURL:defaultName:fileExtension:)(v55, 0xD00000000000001CLL, (void *)0x80000002272D64D0, 0x6C65646F6D6C6DLL, (void *)0xE700000000000000, (uint64_t)v39 - ((v13 + 15) & 0xFFFFFFFFFFFFFFF0));
  if (!v1)
  {
    uint64_t v40 = 0;
    uint64_t v41 = v20;
    unint64_t v42 = v19;
    uint64_t v43 = v18;
    uint64_t v44 = v17;
    uint64_t v45 = v16;
    unint64_t v46 = v15;
    uint64_t v55 = v0;
    v39[1] = v10;
    outlined init with copy of MLClassifierMetrics(v49, v54, (void (*)(void))type metadata accessor for MLLogisticRegressionClassifier.Model);
    uint64_t v21 = v48;
    if (v48)
    {
      uint64_t v22 = v51;
      uint64_t v23 = v51;
      uint64_t v24 = v48;
      unint64_t v25 = v50;
      unint64_t v26 = v46;
      uint64_t v27 = v45;
      uint64_t v28 = v44;
      uint64_t v29 = v43;
      unint64_t v30 = v42;
      uint64_t v31 = v41;
    }
    else
    {
      uint64_t v33 = NSFullUserName();
      uint64_t v23 = static String._unconditionallyBridgeFromObjectiveC(_:)();
      uint64_t v24 = v34;

      uint64_t v27 = 0;
      uint64_t v28 = 0;
      uint64_t v31 = 0;
      unint64_t v25 = 0xD000000000000033;
      unint64_t v26 = 0x80000002272D4DC0;
      unint64_t v30 = 0xE100000000000000;
      uint64_t v29 = 49;
      uint64_t v22 = v51;
    }
    uint64_t v32 = v52;
    v56[0] = v23;
    v56[1] = v24;
    v56[2] = v25;
    v56[3] = v26;
    v56[4] = v27;
    v56[5] = v28;
    v56[6] = v29;
    v56[7] = v30;
    v56[8] = v31;
    outlined copy of MLModelMetadata?(v22, v21);
    uint64_t v35 = v54;
    uint64_t v36 = v55;
    uint64_t v37 = v40;
    specialized CoreMLExportable.export(metadata:)(v56);
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    outlined destroy of MLLogisticRegressionClassifier.ModelParameters.ValidationData(v35, (void (*)(void))type metadata accessor for MLLogisticRegressionClassifier.Model);
    if (!v37)
    {
      Model.write(to:)();
      (*(void (**)(uint64_t, uint64_t))(v32 + 8))(v36, v47);
    }
    OUTLINED_FUNCTION_47_4();
    OUTLINED_FUNCTION_25_0();
    v38();
  }
  OUTLINED_FUNCTION_8_1();
}

void MLLogisticRegressionClassifier.write(toFile:metadata:)()
{
  OUTLINED_FUNCTION_9_0();
  uint64_t v1 = type metadata accessor for URL.DirectoryHint();
  OUTLINED_FUNCTION_0();
  uint64_t v3 = v2;
  MEMORY[0x270FA5388](v4);
  OUTLINED_FUNCTION_3_0();
  uint64_t v7 = v6 - v5;
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  uint64_t v9 = OUTLINED_FUNCTION_17(v8);
  MEMORY[0x270FA5388](v9);
  OUTLINED_FUNCTION_24_8();
  uint64_t v10 = type metadata accessor for URL();
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v11);
  OUTLINED_FUNCTION_22_0();
  __swift_storeEnumTagSinglePayload(v0, 1, 1, v10);
  (*(void (**)(uint64_t, void, uint64_t))(v3 + 104))(v7, *MEMORY[0x263F06E50], v1);
  swift_bridgeObjectRetain();
  URL.init(filePath:directoryHint:relativeTo:)();
  MLLogisticRegressionClassifier.write(to:metadata:)();
  OUTLINED_FUNCTION_11_3();
  v12();
  OUTLINED_FUNCTION_8_1();
}

unint64_t MLLogisticRegressionClassifier.debugDescription.getter()
{
  type metadata accessor for MLClassifierMetrics.Contents(0);
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v2);
  OUTLINED_FUNCTION_27_7();
  uint64_t v3 = type metadata accessor for MLLogisticRegressionClassifier();
  unint64_t v4 = MLLogisticRegressionClassifier.ModelParameters.description.getter();
  uint64_t v6 = v5;
  unint64_t v7 = MLClassifierMetrics.description.getter();
  uint64_t v9 = v8;
  outlined init with copy of MLClassifierMetrics(v0 + *(int *)(v3 + 40), v1, (void (*)(void))type metadata accessor for MLClassifierMetrics.Contents);
  LODWORD(v3) = swift_getEnumCaseMultiPayload();
  outlined destroy of MLLogisticRegressionClassifier.ModelParameters.ValidationData(v1, (void (*)(void))type metadata accessor for MLClassifierMetrics.Contents);
  unint64_t v10 = MLClassifierMetrics.description.getter();
  uint64_t v12 = v11;
  v13._uint64_t countAndFlagsBits = v4;
  v13._uint64_t object = v6;
  String.append(_:)(v13);
  v14._uint64_t countAndFlagsBits = v7;
  v14._uint64_t object = v9;
  String.append(_:)(v14);
  v15._uint64_t countAndFlagsBits = 0xD00000000000001ELL;
  v15._uint64_t object = (void *)0x80000002272D3FE0;
  String.append(_:)(v15);
  swift_bridgeObjectRelease();
  if (v3 <= 1)
  {
    v16._uint64_t countAndFlagsBits = v10;
    v16._uint64_t object = v12;
    String.append(_:)(v16);
    v17._uint64_t countAndFlagsBits = 0xD000000000000020;
    v17._uint64_t object = (void *)0x80000002272D4000;
    String.append(_:)(v17);
    swift_bridgeObjectRelease();
  }
  swift_bridgeObjectRelease();
  swift_bridgeObjectRelease();
  swift_bridgeObjectRelease();
  return 0xD000000000000029;
}

NSAttributedString MLLogisticRegressionClassifier.playgroundDescription.getter()
{
  OUTLINED_FUNCTION_50_3();
  unint64_t v1 = type metadata accessor for NSAttributedString();
  v2._uint64_t countAndFlagsBits = MLLogisticRegressionClassifier.debugDescription.getter();
  result.super.isa = NSAttributedString.__allocating_init(string:)(v2).super.isa;
  v0[3].super.isa = (Class)v1;
  v0->super.isa = result.super.isa;
  return result;
}

unint64_t lazy protocol witness table accessor for type MLLogisticRegressionClassifier.Classifier and conformance MLLogisticRegressionClassifier.Classifier()
{
  unint64_t result = lazy protocol witness table cache variable for type MLLogisticRegressionClassifier.Classifier and conformance MLLogisticRegressionClassifier.Classifier;
  if (!lazy protocol witness table cache variable for type MLLogisticRegressionClassifier.Classifier and conformance MLLogisticRegressionClassifier.Classifier)
  {
    type metadata accessor for MLLogisticRegressionClassifier.Classifier();
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type MLLogisticRegressionClassifier.Classifier and conformance MLLogisticRegressionClassifier.Classifier);
  }
  return result;
}

{
  unint64_t result;

  unint64_t result = lazy protocol witness table cache variable for type MLLogisticRegressionClassifier.Classifier and conformance MLLogisticRegressionClassifier.Classifier;
  if (!lazy protocol witness table cache variable for type MLLogisticRegressionClassifier.Classifier and conformance MLLogisticRegressionClassifier.Classifier)
  {
    type metadata accessor for MLLogisticRegressionClassifier.Classifier();
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type MLLogisticRegressionClassifier.Classifier and conformance MLLogisticRegressionClassifier.Classifier);
  }
  return result;
}

uint64_t partial apply for closure #1 in MLLogisticRegressionClassifier.init(checkpoint:)()
{
  OUTLINED_FUNCTION_11();
  uint64_t v0 = type metadata accessor for MLLogisticRegressionClassifier.Model();
  OUTLINED_FUNCTION_39_0(v0);
  OUTLINED_FUNCTION_40_3();
  uint64_t v1 = swift_task_alloc();
  Swift::String v2 = (void *)OUTLINED_FUNCTION_7_1(v1);
  *Swift::String v2 = v3;
  v2[1] = partial apply for closure #1 in MLLogisticRegressionClassifier.init(checkpoint:);
  uint64_t v4 = OUTLINED_FUNCTION_36_4();
  return closure #1 in MLLogisticRegressionClassifier.init(checkpoint:)(v4);
}

{
  uint64_t *v0;
  uint64_t v1;
  void *v2;
  uint64_t (*v3)(void);
  uint64_t v5;

  OUTLINED_FUNCTION_11();
  OUTLINED_FUNCTION_2();
  uint64_t v1 = *v0;
  OUTLINED_FUNCTION_6();
  *Swift::String v2 = v1;
  swift_task_dealloc();
  uint64_t v3 = *(uint64_t (**)(void))(v1 + 8);
  return v3();
}

uint64_t outlined init with copy of MLClassifierMetrics(uint64_t a1, uint64_t a2, void (*a3)(void))
{
  a3(0);
  OUTLINED_FUNCTION_8();
  OUTLINED_FUNCTION_46_4();
  v4();
  return a2;
}

id sub_2270DEDC0@<X0>(void *a1@<X8>)
{
  id result = MLLogisticRegressionClassifier.model.getter();
  *a1 = result;
  return result;
}

void *initializeBufferWithCopyOfBuffer for MLLogisticRegressionClassifier(void *a1, void *a2, int *a3)
{
  int v5 = *(_DWORD *)(*((void *)a3 - 1) + 80);
  if ((v5 & 0x20000) != 0)
  {
    uint64_t v12 = *a2;
    *a1 = *a2;
    a1 = (void *)(v12 + ((v5 + 16) & ~(unint64_t)v5));
    swift_retain();
  }
  else
  {
    uint64_t v7 = a2[1];
    *a1 = *a2;
    a1[1] = v7;
    uint64_t v9 = a2 + 2;
    uint64_t v8 = a2[2];
    swift_bridgeObjectRetain();
    if (v8)
    {
      uint64_t v10 = a2[3];
      uint64_t v11 = a2[4];
      a1[2] = v8;
      a1[3] = v10;
      a1[4] = v11;
      swift_bridgeObjectRetain();
      swift_bridgeObjectRetain();
    }
    else
    {
      *((_OWORD *)a1 + 1) = *v9;
      a1[4] = a2[4];
    }
    uint64_t v13 = type metadata accessor for MLLogisticRegressionClassifier.Model();
    uint64_t v14 = *(int *)(v13 + 24);
    Swift::String v15 = (char *)a1 + v14;
    Swift::String v16 = (char *)a2 + v14;
    uint64_t v17 = type metadata accessor for BaseLogisticRegressionClassifierModel();
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v17 - 8) + 16))(v15, v16, v17);
    uint64_t v18 = *(int *)(v13 + 28);
    unint64_t v19 = (char *)a1 + v18;
    uint64_t v20 = (char *)a2 + v18;
    uint64_t v21 = *(void *)v20;
    LOBYTE(v20) = v20[8];
    *(void *)unint64_t v19 = v21;
    v19[8] = (char)v20;
    uint64_t v22 = a3[5];
    uint64_t v23 = a3[6];
    uint64_t v24 = *(void **)((char *)a2 + v22);
    *(void *)((char *)a1 + v22) = v24;
    unint64_t v25 = (void *)((char *)a1 + v23);
    unint64_t v26 = (void *)((char *)a2 + v23);
    uint64_t v27 = v26[1];
    *unint64_t v25 = *v26;
    v25[1] = v27;
    uint64_t v28 = a3[8];
    unint64_t v66 = a3;
    *(void *)((char *)a1 + a3[7]) = *(void *)((char *)a2 + a3[7]);
    uint64_t v29 = (char *)a1 + v28;
    unint64_t v30 = (char *)a2 + v28;
    *(void *)((char *)a1 + v28) = *(void *)((char *)a2 + v28);
    uint64_t v31 = (_OWORD *)((char *)a1 + v28 + 8);
    uint64_t v32 = (_OWORD *)((char *)a2 + v28 + 8);
    uint64_t v33 = *(void *)((char *)a2 + v28 + 32);
    swift_bridgeObjectRetain();
    id v34 = v24;
    swift_bridgeObjectRetain();
    swift_bridgeObjectRetain();
    if (v33)
    {
      *((void *)v29 + 4) = v33;
      (**(void (***)(_OWORD *, _OWORD *, uint64_t))(v33 - 8))(v31, v32, v33);
    }
    else
    {
      long long v35 = v32[1];
      *uint64_t v31 = *v32;
      v31[1] = v35;
    }
    *(_OWORD *)(v29 + 40) = *(_OWORD *)(v30 + 40);
    *(_OWORD *)(v29 + 56) = *(_OWORD *)(v30 + 56);
    v29[72] = v30[72];
    uint64_t v36 = a3;
    uint64_t v37 = a3[9];
    uint64_t v38 = (void **)((char *)a1 + v37);
    uint64_t v39 = (void **)((char *)a2 + v37);
    type metadata accessor for MLClassifierMetrics.Contents(0);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload();
    if (EnumCaseMultiPayload == 2)
    {
      uint64_t v45 = *v39;
      id v46 = v45;
      *uint64_t v38 = v45;
    }
    else if (EnumCaseMultiPayload == 1)
    {
      *uint64_t v38 = *v39;
      uint64_t v41 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
      uint64_t v42 = *(int *)(v41 + 20);
      uint64_t v64 = (char *)v39 + v42;
      uint64_t v65 = (char *)v38 + v42;
      uint64_t v43 = type metadata accessor for DataFrame();
      uint64_t v44 = *(void (**)(char *, char *, uint64_t))(*(void *)(v43 - 8) + 16);
      v44(v65, v64, v43);
      v44((char *)v38 + *(int *)(v41 + 24), (char *)v39 + *(int *)(v41 + 24), v43);
      uint64_t v36 = v66;
    }
    else
    {
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
      if (swift_getEnumCaseMultiPayload() == 1) {
        uint64_t v47 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
      }
      else {
        uint64_t v47 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
      }
      uint64_t v48 = __swift_instantiateConcreteTypeFromMangledName(v47);
      (*(void (**)(void **, void **, uint64_t))(*(void *)(v48 - 8) + 16))(v38, v39, v48);
      swift_storeEnumTagMultiPayload();
    }
    swift_storeEnumTagMultiPayload();
    uint64_t v49 = v36[10];
    unint64_t v50 = (void **)((char *)a1 + v49);
    uint64_t v51 = (void **)((char *)a2 + v49);
    int v52 = swift_getEnumCaseMultiPayload();
    if (v52 == 2)
    {
      uint64_t v59 = *v51;
      id v60 = v59;
      *unint64_t v50 = v59;
    }
    else if (v52 == 1)
    {
      *unint64_t v50 = *v51;
      uint64_t v53 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
      uint64_t v54 = *(int *)(v53 + 20);
      uint64_t v55 = (char *)v50 + v54;
      uint64_t v56 = (char *)v51 + v54;
      uint64_t v57 = type metadata accessor for DataFrame();
      uint64_t v58 = *(void (**)(char *, char *, uint64_t))(*(void *)(v57 - 8) + 16);
      v58(v55, v56, v57);
      v58((char *)v50 + *(int *)(v53 + 24), (char *)v51 + *(int *)(v53 + 24), v57);
    }
    else
    {
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
      if (swift_getEnumCaseMultiPayload() == 1) {
        uint64_t v61 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
      }
      else {
        uint64_t v61 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
      }
      uint64_t v62 = __swift_instantiateConcreteTypeFromMangledName(v61);
      (*(void (**)(void **, void **, uint64_t))(*(void *)(v62 - 8) + 16))(v50, v51, v62);
      swift_storeEnumTagMultiPayload();
    }
    swift_storeEnumTagMultiPayload();
  }
  return a1;
}

void destroy for MLLogisticRegressionClassifier(uint64_t a1, int *a2)
{
  swift_bridgeObjectRelease();
  if (*(void *)(a1 + 16))
  {
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
  }
  uint64_t v4 = a1 + *(int *)(type metadata accessor for MLLogisticRegressionClassifier.Model() + 24);
  uint64_t v5 = type metadata accessor for BaseLogisticRegressionClassifierModel();
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v5 - 8) + 8))(v4, v5);
  swift_bridgeObjectRelease();

  swift_bridgeObjectRelease();
  swift_bridgeObjectRelease();
  uint64_t v6 = a1 + a2[8];
  if (*(void *)(v6 + 32)) {
    __swift_destroy_boxed_opaque_existential_0(v6 + 8);
  }
  uint64_t v7 = (id *)(a1 + a2[9]);
  type metadata accessor for MLClassifierMetrics.Contents(0);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload();
  switch(EnumCaseMultiPayload)
  {
    case 2:

      break;
    case 1:
      uint64_t v10 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
      uint64_t v11 = (char *)v7 + *(int *)(v10 + 20);
      uint64_t v12 = type metadata accessor for DataFrame();
      uint64_t v13 = *(void (**)(char *, uint64_t))(*(void *)(v12 - 8) + 8);
      v13(v11, v12);
      v13((char *)v7 + *(int *)(v10 + 24), v12);
      break;
    case 0:
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
      if (swift_getEnumCaseMultiPayload() == 1) {
        uint64_t v9 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
      }
      else {
        uint64_t v9 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
      }
      uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(v9);
      (*(void (**)(id *, uint64_t))(*(void *)(v14 - 8) + 8))(v7, v14);
      break;
  }
  Swift::String v15 = (void **)(a1 + a2[10]);
  int v16 = swift_getEnumCaseMultiPayload();
  if (v16 == 2)
  {
    uint64_t v18 = *v15;
  }
  else
  {
    if (v16 == 1)
    {
      uint64_t v19 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
      uint64_t v20 = (char *)v15 + *(int *)(v19 + 20);
      uint64_t v21 = type metadata accessor for DataFrame();
      unint64_t v26 = *(void (**)(void **, uint64_t))(*(void *)(v21 - 8) + 8);
      ((void (*)(void *__return_ptr, char *, uint64_t))v26)((void *)(v21 - 8), v20, v21);
      uint64_t v22 = (void **)((char *)v15 + *(int *)(v19 + 24));
      uint64_t v23 = v21;
      uint64_t v24 = v26;
    }
    else
    {
      if (v16) {
        return;
      }
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
      if (swift_getEnumCaseMultiPayload() == 1) {
        uint64_t v17 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
      }
      else {
        uint64_t v17 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
      }
      uint64_t v25 = __swift_instantiateConcreteTypeFromMangledName(v17);
      uint64_t v24 = *(void (**)(void **, uint64_t))(*(void *)(v25 - 8) + 8);
      uint64_t v23 = v25;
      uint64_t v22 = v15;
    }
    v24(v22, v23);
  }
}

void *initializeWithCopy for MLLogisticRegressionClassifier(void *a1, void *a2, int *a3)
{
  uint64_t v6 = a2[1];
  *a1 = *a2;
  a1[1] = v6;
  uint64_t v8 = a2 + 2;
  uint64_t v7 = a2[2];
  swift_bridgeObjectRetain();
  if (v7)
  {
    uint64_t v9 = a2[3];
    uint64_t v10 = a2[4];
    a1[2] = v7;
    a1[3] = v9;
    a1[4] = v10;
    swift_bridgeObjectRetain();
    swift_bridgeObjectRetain();
  }
  else
  {
    *((_OWORD *)a1 + 1) = *(_OWORD *)v8;
    a1[4] = v8[2];
  }
  uint64_t v11 = type metadata accessor for MLLogisticRegressionClassifier.Model();
  uint64_t v12 = *(int *)(v11 + 24);
  uint64_t v13 = (char *)a1 + v12;
  uint64_t v14 = (char *)a2 + v12;
  uint64_t v15 = type metadata accessor for BaseLogisticRegressionClassifierModel();
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v15 - 8) + 16))(v13, v14, v15);
  uint64_t v16 = *(int *)(v11 + 28);
  uint64_t v17 = (char *)a1 + v16;
  uint64_t v18 = (char *)a2 + v16;
  uint64_t v19 = *(void *)v18;
  LOBYTE(v18) = v18[8];
  *(void *)uint64_t v17 = v19;
  v17[8] = (char)v18;
  uint64_t v20 = a3[5];
  uint64_t v21 = a3[6];
  uint64_t v22 = *(void **)((char *)a2 + v20);
  *(void *)((char *)a1 + v20) = v22;
  uint64_t v23 = (void *)((char *)a1 + v21);
  uint64_t v24 = (void *)((char *)a2 + v21);
  uint64_t v25 = v24[1];
  *uint64_t v23 = *v24;
  v23[1] = v25;
  uint64_t v26 = a3[8];
  uint64_t v63 = a3;
  *(void *)((char *)a1 + a3[7]) = *(void *)((char *)a2 + a3[7]);
  uint64_t v27 = (char *)a1 + v26;
  uint64_t v28 = (char *)a2 + v26;
  *(void *)((char *)a1 + v26) = *(void *)((char *)a2 + v26);
  uint64_t v29 = (_OWORD *)((char *)a1 + v26 + 8);
  unint64_t v30 = (_OWORD *)((char *)a2 + v26 + 8);
  uint64_t v31 = *(void *)((char *)a2 + v26 + 32);
  swift_bridgeObjectRetain();
  id v32 = v22;
  swift_bridgeObjectRetain();
  swift_bridgeObjectRetain();
  if (v31)
  {
    *((void *)v27 + 4) = v31;
    (**(void (***)(_OWORD *, _OWORD *, uint64_t))(v31 - 8))(v29, v30, v31);
  }
  else
  {
    long long v33 = v30[1];
    *uint64_t v29 = *v30;
    v29[1] = v33;
  }
  *(_OWORD *)(v27 + 40) = *(_OWORD *)(v28 + 40);
  *(_OWORD *)(v27 + 56) = *(_OWORD *)(v28 + 56);
  v27[72] = v28[72];
  id v34 = a3;
  uint64_t v35 = a3[9];
  uint64_t v36 = (void **)((char *)a1 + v35);
  uint64_t v37 = (void **)((char *)a2 + v35);
  type metadata accessor for MLClassifierMetrics.Contents(0);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload();
  if (EnumCaseMultiPayload == 2)
  {
    uint64_t v43 = *v37;
    id v44 = v43;
    *uint64_t v36 = v43;
  }
  else if (EnumCaseMultiPayload == 1)
  {
    *uint64_t v36 = *v37;
    uint64_t v39 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
    uint64_t v40 = *(int *)(v39 + 20);
    uint64_t v61 = (char *)v37 + v40;
    uint64_t v62 = (char *)v36 + v40;
    uint64_t v41 = type metadata accessor for DataFrame();
    uint64_t v42 = *(void (**)(char *, char *, uint64_t))(*(void *)(v41 - 8) + 16);
    v42(v62, v61, v41);
    v42((char *)v36 + *(int *)(v39 + 24), (char *)v37 + *(int *)(v39 + 24), v41);
    id v34 = v63;
  }
  else
  {
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
    if (swift_getEnumCaseMultiPayload() == 1) {
      uint64_t v45 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
    }
    else {
      uint64_t v45 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
    }
    uint64_t v46 = __swift_instantiateConcreteTypeFromMangledName(v45);
    (*(void (**)(void **, void **, uint64_t))(*(void *)(v46 - 8) + 16))(v36, v37, v46);
    swift_storeEnumTagMultiPayload();
  }
  swift_storeEnumTagMultiPayload();
  uint64_t v47 = v34[10];
  uint64_t v48 = (void **)((char *)a1 + v47);
  uint64_t v49 = (void **)((char *)a2 + v47);
  int v50 = swift_getEnumCaseMultiPayload();
  if (v50 == 2)
  {
    uint64_t v56 = *v49;
    id v57 = v56;
    *uint64_t v48 = v56;
  }
  else if (v50 == 1)
  {
    *uint64_t v48 = *v49;
    uint64_t v51 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
    uint64_t v52 = *(int *)(v51 + 20);
    uint64_t v64 = (char *)v48 + v52;
    uint64_t v53 = (char *)v49 + v52;
    uint64_t v54 = type metadata accessor for DataFrame();
    uint64_t v55 = *(void (**)(char *, char *, uint64_t))(*(void *)(v54 - 8) + 16);
    v55(v64, v53, v54);
    v55((char *)v48 + *(int *)(v51 + 24), (char *)v49 + *(int *)(v51 + 24), v54);
  }
  else
  {
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
    if (swift_getEnumCaseMultiPayload() == 1) {
      uint64_t v58 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
    }
    else {
      uint64_t v58 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
    }
    uint64_t v59 = __swift_instantiateConcreteTypeFromMangledName(v58);
    (*(void (**)(void **, void **, uint64_t))(*(void *)(v59 - 8) + 16))(v48, v49, v59);
    swift_storeEnumTagMultiPayload();
  }
  swift_storeEnumTagMultiPayload();
  return a1;
}

void *assignWithCopy for MLLogisticRegressionClassifier(void *a1, void *a2, int *a3)
{
  *a1 = *a2;
  a1[1] = a2[1];
  swift_bridgeObjectRetain();
  swift_bridgeObjectRelease();
  uint64_t v6 = a1 + 2;
  uint64_t v8 = a2 + 2;
  uint64_t v7 = a2[2];
  if (a1[2])
  {
    if (v7)
    {
      a1[2] = v7;
      swift_bridgeObjectRetain();
      swift_bridgeObjectRelease();
      a1[3] = a2[3];
      a1[4] = a2[4];
      swift_bridgeObjectRetain();
      swift_bridgeObjectRelease();
    }
    else
    {
      outlined destroy of URL?((uint64_t)(a1 + 2), &demangling cache variable for type metadata for FeatureVectorizer<Double>.Transformer);
      uint64_t v9 = a2[4];
      *uint64_t v6 = *v8;
      a1[4] = v9;
    }
  }
  else if (v7)
  {
    a1[2] = v7;
    a1[3] = a2[3];
    a1[4] = a2[4];
    swift_bridgeObjectRetain();
    swift_bridgeObjectRetain();
  }
  else
  {
    long long v10 = *v8;
    a1[4] = a2[4];
    *uint64_t v6 = v10;
  }
  uint64_t v11 = type metadata accessor for MLLogisticRegressionClassifier.Model();
  uint64_t v12 = *(int *)(v11 + 24);
  uint64_t v13 = (char *)a1 + v12;
  uint64_t v14 = (char *)a2 + v12;
  uint64_t v15 = type metadata accessor for BaseLogisticRegressionClassifierModel();
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v15 - 8) + 24))(v13, v14, v15);
  uint64_t v16 = *(int *)(v11 + 28);
  uint64_t v17 = (char *)a1 + v16;
  uint64_t v18 = (char *)a2 + v16;
  uint64_t v19 = *(void *)v18;
  LOBYTE(v18) = v18[8];
  *(void *)uint64_t v17 = v19;
  v17[8] = (char)v18;
  swift_bridgeObjectRetain();
  swift_bridgeObjectRelease();
  uint64_t v20 = a3[5];
  uint64_t v21 = *(void **)((char *)a2 + v20);
  uint64_t v22 = *(void **)((char *)a1 + v20);
  *(void *)((char *)a1 + v20) = v21;
  id v23 = v21;

  uint64_t v24 = a3[6];
  uint64_t v25 = (void *)((char *)a1 + v24);
  uint64_t v26 = (void *)((char *)a2 + v24);
  *uint64_t v25 = *v26;
  v25[1] = v26[1];
  swift_bridgeObjectRetain();
  swift_bridgeObjectRelease();
  *(void *)((char *)a1 + a3[7]) = *(void *)((char *)a2 + a3[7]);
  swift_bridgeObjectRetain();
  swift_bridgeObjectRelease();
  uint64_t v27 = a3[8];
  uint64_t v28 = (char *)a1 + v27;
  uint64_t v29 = (char *)a2 + v27;
  *(void *)((char *)a1 + v27) = *(void *)((char *)a2 + v27);
  uint64_t v30 = (uint64_t)a1 + v27 + 8;
  uint64_t v31 = (uint64_t)a2 + v27 + 8;
  uint64_t v32 = *(void *)((char *)a2 + v27 + 32);
  if (*(void *)((char *)a1 + v27 + 32))
  {
    if (v32)
    {
      __swift_assign_boxed_opaque_existential_0((uint64_t *)v30, (uint64_t *)v31);
      goto LABEL_15;
    }
    __swift_destroy_boxed_opaque_existential_0(v30);
  }
  else if (v32)
  {
    *((void *)v28 + 4) = v32;
    (**(void (***)(uint64_t, uint64_t))(v32 - 8))(v30, v31);
    goto LABEL_15;
  }
  long long v33 = *(_OWORD *)(v31 + 16);
  *(_OWORD *)uint64_t v30 = *(_OWORD *)v31;
  *(_OWORD *)(v30 + 16) = v33;
LABEL_15:
  *((void *)v28 + 5) = *((void *)v29 + 5);
  *((void *)v28 + 6) = *((void *)v29 + 6);
  *((void *)v28 + 7) = *((void *)v29 + 7);
  *((void *)v28 + 8) = *((void *)v29 + 8);
  v28[72] = v29[72];
  if (a1 != a2)
  {
    uint64_t v34 = a3[9];
    uint64_t v35 = (void **)((char *)a1 + v34);
    uint64_t v36 = (void **)((char *)a2 + v34);
    outlined destroy of MLLogisticRegressionClassifier.ModelParameters.ValidationData((uint64_t)a1 + v34, (void (*)(void))type metadata accessor for MLClassifierMetrics.Contents);
    type metadata accessor for MLClassifierMetrics.Contents(0);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload();
    if (EnumCaseMultiPayload == 2)
    {
      uint64_t v42 = *v36;
      id v43 = v42;
      *uint64_t v35 = v42;
    }
    else if (EnumCaseMultiPayload == 1)
    {
      *uint64_t v35 = *v36;
      uint64_t v38 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
      uint64_t v39 = *(int *)(v38 + 20);
      uint64_t v61 = (char *)v36 + v39;
      uint64_t v62 = (char *)v35 + v39;
      uint64_t v40 = type metadata accessor for DataFrame();
      uint64_t v41 = *(void (**)(char *, char *, uint64_t))(*(void *)(v40 - 8) + 16);
      v41(v62, v61, v40);
      v41((char *)v35 + *(int *)(v38 + 24), (char *)v36 + *(int *)(v38 + 24), v40);
    }
    else
    {
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
      if (swift_getEnumCaseMultiPayload() == 1) {
        id v44 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
      }
      else {
        id v44 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
      }
      uint64_t v45 = __swift_instantiateConcreteTypeFromMangledName(v44);
      (*(void (**)(void **, void **, uint64_t))(*(void *)(v45 - 8) + 16))(v35, v36, v45);
      swift_storeEnumTagMultiPayload();
    }
    swift_storeEnumTagMultiPayload();
    uint64_t v46 = a3[10];
    uint64_t v47 = (void **)((char *)a1 + v46);
    uint64_t v48 = (void **)((char *)a2 + v46);
    outlined destroy of MLLogisticRegressionClassifier.ModelParameters.ValidationData((uint64_t)a1 + v46, (void (*)(void))type metadata accessor for MLClassifierMetrics.Contents);
    int v49 = swift_getEnumCaseMultiPayload();
    if (v49 == 2)
    {
      uint64_t v56 = *v48;
      id v57 = v56;
      uint64_t *v47 = v56;
    }
    else if (v49 == 1)
    {
      uint64_t *v47 = *v48;
      uint64_t v50 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
      uint64_t v51 = *(int *)(v50 + 20);
      uint64_t v52 = (char *)v47 + v51;
      uint64_t v53 = (char *)v48 + v51;
      uint64_t v54 = type metadata accessor for DataFrame();
      uint64_t v55 = *(void (**)(char *, char *, uint64_t))(*(void *)(v54 - 8) + 16);
      v55(v52, v53, v54);
      v55((char *)v47 + *(int *)(v50 + 24), (char *)v48 + *(int *)(v50 + 24), v54);
    }
    else
    {
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
      if (swift_getEnumCaseMultiPayload() == 1) {
        uint64_t v58 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
      }
      else {
        uint64_t v58 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
      }
      uint64_t v59 = __swift_instantiateConcreteTypeFromMangledName(v58);
      (*(void (**)(void **, void **, uint64_t))(*(void *)(v59 - 8) + 16))(v47, v48, v59);
      swift_storeEnumTagMultiPayload();
    }
    swift_storeEnumTagMultiPayload();
  }
  return a1;
}

uint64_t initializeWithTake for MLLogisticRegressionClassifier(uint64_t a1, uint64_t a2, int *a3)
{
  long long v6 = *(_OWORD *)(a2 + 16);
  *(_OWORD *)a1 = *(_OWORD *)a2;
  *(_OWORD *)(a1 + 16) = v6;
  *(void *)(a1 + 32) = *(void *)(a2 + 32);
  uint64_t v7 = type metadata accessor for MLLogisticRegressionClassifier.Model();
  uint64_t v8 = *(int *)(v7 + 24);
  uint64_t v9 = a1 + v8;
  uint64_t v10 = a2 + v8;
  uint64_t v11 = type metadata accessor for BaseLogisticRegressionClassifierModel();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v11 - 8) + 32))(v9, v10, v11);
  uint64_t v12 = *(int *)(v7 + 28);
  uint64_t v13 = a1 + v12;
  uint64_t v14 = a2 + v12;
  *(void *)uint64_t v13 = *(void *)v14;
  *(unsigned char *)(v13 + 8) = *(unsigned char *)(v14 + 8);
  uint64_t v15 = a3[6];
  *(void *)(a1 + a3[5]) = *(void *)(a2 + a3[5]);
  *(_OWORD *)(a1 + v15) = *(_OWORD *)(a2 + v15);
  uint64_t v16 = a3[8];
  *(void *)(a1 + a3[7]) = *(void *)(a2 + a3[7]);
  memcpy((void *)(a1 + v16), (const void *)(a2 + v16), 0x49uLL);
  uint64_t v17 = a3[9];
  uint64_t v18 = (char *)(a1 + v17);
  uint64_t v19 = (char *)(a2 + v17);
  uint64_t v20 = type metadata accessor for MLClassifierMetrics.Contents(0);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload();
  if (EnumCaseMultiPayload == 1)
  {
    *(void *)uint64_t v18 = *(void *)v19;
    uint64_t v24 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
    uint64_t v25 = *(int *)(v24 + 20);
    uint64_t v41 = &v19[v25];
    uint64_t v42 = &v18[v25];
    uint64_t v26 = type metadata accessor for DataFrame();
    uint64_t v27 = *(void (**)(char *, char *, uint64_t))(*(void *)(v26 - 8) + 32);
    v27(v42, v41, v26);
    v27(&v18[*(int *)(v24 + 24)], &v19[*(int *)(v24 + 24)], v26);
LABEL_8:
    swift_storeEnumTagMultiPayload();
    goto LABEL_10;
  }
  if (!EnumCaseMultiPayload)
  {
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
    if (swift_getEnumCaseMultiPayload() == 1) {
      uint64_t v22 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
    }
    else {
      uint64_t v22 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
    }
    uint64_t v23 = __swift_instantiateConcreteTypeFromMangledName(v22);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v23 - 8) + 32))(v18, v19, v23);
    swift_storeEnumTagMultiPayload();
    goto LABEL_8;
  }
  memcpy(v18, v19, *(void *)(*(void *)(v20 - 8) + 64));
LABEL_10:
  uint64_t v28 = a3[10];
  uint64_t v29 = (char *)(a1 + v28);
  uint64_t v30 = (char *)(a2 + v28);
  int v31 = swift_getEnumCaseMultiPayload();
  if (v31 == 1)
  {
    *(void *)uint64_t v29 = *(void *)v30;
    uint64_t v34 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
    uint64_t v35 = *(int *)(v34 + 20);
    uint64_t v36 = &v29[v35];
    uint64_t v37 = &v30[v35];
    uint64_t v38 = type metadata accessor for DataFrame();
    uint64_t v39 = *(void (**)(char *, char *, uint64_t))(*(void *)(v38 - 8) + 32);
    v39(v36, v37, v38);
    v39(&v29[*(int *)(v34 + 24)], &v30[*(int *)(v34 + 24)], v38);
  }
  else
  {
    if (v31)
    {
      memcpy(v29, v30, *(void *)(*(void *)(v20 - 8) + 64));
      return a1;
    }
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
    if (swift_getEnumCaseMultiPayload() == 1) {
      uint64_t v32 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
    }
    else {
      uint64_t v32 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
    }
    uint64_t v33 = __swift_instantiateConcreteTypeFromMangledName(v32);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v33 - 8) + 32))(v29, v30, v33);
    swift_storeEnumTagMultiPayload();
  }
  swift_storeEnumTagMultiPayload();
  return a1;
}

void *assignWithTake for MLLogisticRegressionClassifier(void *a1, void *a2, int *a3)
{
  uint64_t v6 = a2[1];
  *a1 = *a2;
  a1[1] = v6;
  swift_bridgeObjectRelease();
  uint64_t v7 = a2[2];
  if (a1[2])
  {
    if (v7)
    {
      a1[2] = v7;
      swift_bridgeObjectRelease();
      uint64_t v8 = a2[4];
      a1[3] = a2[3];
      a1[4] = v8;
      swift_bridgeObjectRelease();
      goto LABEL_6;
    }
    outlined destroy of URL?((uint64_t)(a1 + 2), &demangling cache variable for type metadata for FeatureVectorizer<Double>.Transformer);
  }
  *((_OWORD *)a1 + 1) = *((_OWORD *)a2 + 1);
  a1[4] = a2[4];
LABEL_6:
  uint64_t v9 = type metadata accessor for MLLogisticRegressionClassifier.Model();
  uint64_t v10 = *(int *)(v9 + 24);
  uint64_t v11 = (char *)a1 + v10;
  uint64_t v12 = (char *)a2 + v10;
  uint64_t v13 = type metadata accessor for BaseLogisticRegressionClassifierModel();
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v13 - 8) + 40))(v11, v12, v13);
  uint64_t v14 = *(int *)(v9 + 28);
  uint64_t v15 = (char *)a1 + v14;
  uint64_t v16 = (char *)a2 + v14;
  uint64_t v17 = *(void *)v16;
  LOBYTE(v16) = v16[8];
  *(void *)uint64_t v15 = v17;
  v15[8] = (char)v16;
  swift_bridgeObjectRelease();
  uint64_t v18 = a3[5];
  uint64_t v19 = *(void **)((char *)a1 + v18);
  *(void *)((char *)a1 + v18) = *(void *)((char *)a2 + v18);

  uint64_t v20 = a3[6];
  uint64_t v21 = (void *)((char *)a1 + v20);
  uint64_t v22 = (void *)((char *)a2 + v20);
  uint64_t v24 = *v22;
  uint64_t v23 = v22[1];
  *uint64_t v21 = v24;
  v21[1] = v23;
  swift_bridgeObjectRelease();
  *(void *)((char *)a1 + a3[7]) = *(void *)((char *)a2 + a3[7]);
  swift_bridgeObjectRelease();
  uint64_t v25 = a3[8];
  uint64_t v26 = (char *)a1 + v25;
  uint64_t v27 = (char *)a2 + v25;
  uint64_t v28 = (_OWORD *)((char *)a2 + v25 + 8);
  *(void *)((char *)a1 + v25) = *(void *)((char *)a2 + v25);
  uint64_t v29 = (_OWORD *)((char *)a1 + v25 + 8);
  if (*(void *)((char *)a1 + v25 + 32)) {
    __swift_destroy_boxed_opaque_existential_0((uint64_t)v29);
  }
  long long v30 = v28[1];
  *uint64_t v29 = *v28;
  v29[1] = v30;
  *(_OWORD *)(v26 + 40) = *(_OWORD *)(v27 + 40);
  *(_OWORD *)(v26 + 56) = *(_OWORD *)(v27 + 56);
  v26[72] = v27[72];
  if (a1 == a2) {
    return a1;
  }
  uint64_t v31 = a3[9];
  uint64_t v32 = (char *)a1 + v31;
  uint64_t v33 = (char *)a2 + v31;
  outlined destroy of MLLogisticRegressionClassifier.ModelParameters.ValidationData((uint64_t)a1 + v31, (void (*)(void))type metadata accessor for MLClassifierMetrics.Contents);
  uint64_t v34 = type metadata accessor for MLClassifierMetrics.Contents(0);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload();
  if (EnumCaseMultiPayload == 1)
  {
    *(void *)uint64_t v32 = *(void *)v33;
    uint64_t v38 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
    uint64_t v39 = *(int *)(v38 + 20);
    uint64_t v55 = &v33[v39];
    uint64_t v56 = &v32[v39];
    uint64_t v40 = type metadata accessor for DataFrame();
    uint64_t v41 = *(void (**)(char *, char *, uint64_t))(*(void *)(v40 - 8) + 32);
    v41(v56, v55, v40);
    v41(&v32[*(int *)(v38 + 24)], &v33[*(int *)(v38 + 24)], v40);
  }
  else
  {
    if (EnumCaseMultiPayload)
    {
      memcpy(v32, v33, *(void *)(*(void *)(v34 - 8) + 64));
      goto LABEL_18;
    }
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
    if (swift_getEnumCaseMultiPayload() == 1) {
      uint64_t v36 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
    }
    else {
      uint64_t v36 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
    }
    uint64_t v37 = __swift_instantiateConcreteTypeFromMangledName(v36);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v37 - 8) + 32))(v32, v33, v37);
    swift_storeEnumTagMultiPayload();
  }
  swift_storeEnumTagMultiPayload();
LABEL_18:
  uint64_t v42 = a3[10];
  id v43 = (char *)a1 + v42;
  id v44 = (char *)a2 + v42;
  outlined destroy of MLLogisticRegressionClassifier.ModelParameters.ValidationData((uint64_t)a1 + v42, (void (*)(void))type metadata accessor for MLClassifierMetrics.Contents);
  int v45 = swift_getEnumCaseMultiPayload();
  if (v45 == 1)
  {
    *(void *)id v43 = *(void *)v44;
    uint64_t v48 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
    uint64_t v49 = *(int *)(v48 + 20);
    uint64_t v50 = &v43[v49];
    uint64_t v51 = &v44[v49];
    uint64_t v52 = type metadata accessor for DataFrame();
    uint64_t v53 = *(void (**)(char *, char *, uint64_t))(*(void *)(v52 - 8) + 32);
    v53(v50, v51, v52);
    v53(&v43[*(int *)(v48 + 24)], &v44[*(int *)(v48 + 24)], v52);
  }
  else
  {
    if (v45)
    {
      memcpy(v43, v44, *(void *)(*(void *)(v34 - 8) + 64));
      return a1;
    }
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
    if (swift_getEnumCaseMultiPayload() == 1) {
      uint64_t v46 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
    }
    else {
      uint64_t v46 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
    }
    uint64_t v47 = __swift_instantiateConcreteTypeFromMangledName(v46);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v47 - 8) + 32))(v43, v44, v47);
    swift_storeEnumTagMultiPayload();
  }
  swift_storeEnumTagMultiPayload();
  return a1;
}

uint64_t getEnumTagSinglePayload for MLLogisticRegressionClassifier(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return MEMORY[0x270FA0340](a1, a2, a3, sub_2270E0940);
}

uint64_t sub_2270E0940(uint64_t a1, uint64_t a2, uint64_t a3)
{
  type metadata accessor for MLLogisticRegressionClassifier.Model();
  OUTLINED_FUNCTION_6_1();
  if (*(_DWORD *)(v7 + 84) == a2)
  {
    uint64_t v8 = v6;
    uint64_t v9 = a1;
LABEL_8:
    return __swift_getEnumTagSinglePayload(v9, a2, v8);
  }
  if (a2 != 0x7FFFFFFF)
  {
    uint64_t v8 = type metadata accessor for MLClassifierMetrics(0);
    uint64_t v9 = a1 + *(int *)(a3 + 36);
    goto LABEL_8;
  }
  unint64_t v10 = *(void *)(a1 + *(int *)(a3 + 20));
  if (v10 >= 0xFFFFFFFF) {
    LODWORD(v10) = -1;
  }
  return (v10 + 1);
}

uint64_t storeEnumTagSinglePayload for MLLogisticRegressionClassifier(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return MEMORY[0x270FA0580](a1, a2, a3, a4, sub_2270E0A04);
}

void sub_2270E0A04(uint64_t a1, uint64_t a2, int a3, uint64_t a4)
{
  type metadata accessor for MLLogisticRegressionClassifier.Model();
  OUTLINED_FUNCTION_6_1();
  if (*(_DWORD *)(v9 + 84) == a3)
  {
    uint64_t v10 = v8;
    uint64_t v11 = a1;
  }
  else
  {
    if (a3 == 0x7FFFFFFF)
    {
      *(void *)(a1 + *(int *)(a4 + 20)) = (a2 - 1);
      return;
    }
    uint64_t v10 = type metadata accessor for MLClassifierMetrics(0);
    uint64_t v11 = a1 + *(int *)(a4 + 36);
  }

  __swift_storeEnumTagSinglePayload(v11, a2, a2, v10);
}

uint64_t type metadata completion function for MLLogisticRegressionClassifier()
{
  uint64_t result = type metadata accessor for MLLogisticRegressionClassifier.Model();
  if (v1 <= 0x3F)
  {
    uint64_t result = type metadata accessor for MLClassifierMetrics.Contents(319);
    if (v2 <= 0x3F)
    {
      swift_initStructMetadata();
      return 0;
    }
  }
  return result;
}

uint64_t outlined init with take of DataFrame?(uint64_t a1, uint64_t a2, uint64_t *a3)
{
  __swift_instantiateConcreteTypeFromMangledName(a3);
  OUTLINED_FUNCTION_8();
  uint64_t v4 = OUTLINED_FUNCTION_52_3();
  v5(v4);
  return a2;
}

uint64_t outlined destroy of MLLogisticRegressionClassifier.ModelParameters.ValidationData(uint64_t a1, void (*a2)(void))
{
  a2(0);
  OUTLINED_FUNCTION_8();
  OUTLINED_FUNCTION_25_0();
  v3();
  return a1;
}

uint64_t outlined init with copy of Any?(uint64_t a1, uint64_t a2, uint64_t *a3)
{
  __swift_instantiateConcreteTypeFromMangledName(a3);
  OUTLINED_FUNCTION_8();
  OUTLINED_FUNCTION_46_4();
  v4();
  return a2;
}

uint64_t outlined init with take of MLLogisticRegressionClassifier.Model(uint64_t a1, uint64_t a2, void (*a3)(void))
{
  a3(0);
  OUTLINED_FUNCTION_8();
  uint64_t v4 = OUTLINED_FUNCTION_52_3();
  v5(v4);
  return a2;
}

uint64_t objectdestroyTm_0()
{
  uint64_t v1 = *(void *)(type metadata accessor for MLLogisticRegressionClassifier.Model() - 8);
  uint64_t v2 = *(unsigned __int8 *)(v1 + 80);
  uint64_t v3 = (v2 + 16) & ~v2;
  uint64_t v4 = *(void *)(v1 + 64);
  swift_bridgeObjectRelease();
  if (*(void *)(v0 + v3 + 16))
  {
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
  }
  type metadata accessor for BaseLogisticRegressionClassifierModel();
  OUTLINED_FUNCTION_8();
  OUTLINED_FUNCTION_25_0();
  v5();
  swift_bridgeObjectRelease();

  return MEMORY[0x270FA0238](v0, v3 + v4, v2 | 7);
}

uint64_t partial apply for closure #1 in MLLogisticRegressionClassifier.init(_:targetColumn:featureColumns:parameters:)()
{
  OUTLINED_FUNCTION_11();
  uint64_t v0 = type metadata accessor for MLLogisticRegressionClassifier.Model();
  OUTLINED_FUNCTION_39_0(v0);
  OUTLINED_FUNCTION_40_3();
  uint64_t v1 = swift_task_alloc();
  uint64_t v2 = (void *)OUTLINED_FUNCTION_7_1(v1);
  *uint64_t v2 = v3;
  v2[1] = partial apply for closure #1 in MLLogisticRegressionClassifier.init(trainingData:targetColumn:featureColumns:parameters:);
  uint64_t v4 = OUTLINED_FUNCTION_36_4();
  return closure #1 in MLLogisticRegressionClassifier.init(_:targetColumn:featureColumns:parameters:)(v4);
}

uint64_t OUTLINED_FUNCTION_24_8()
{
  return 0;
}

uint64_t OUTLINED_FUNCTION_26_7()
{
  return *(void *)(v0 - 552);
}

uint64_t OUTLINED_FUNCTION_33_5()
{
  return v0 + 8;
}

uint64_t OUTLINED_FUNCTION_36_4()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_38_5()
{
  return *(void *)(v0 - 552);
}

uint64_t OUTLINED_FUNCTION_42_4()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_47_4()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_48_3(uint64_t a1, void (*a2)(void))
{
  uint64_t v4 = *(void *)(v2 - 312);
  return outlined destroy of MLLogisticRegressionClassifier.ModelParameters.ValidationData(v4, a2);
}

uint64_t OUTLINED_FUNCTION_50_3()
{
  return 0;
}

uint64_t OUTLINED_FUNCTION_52_3()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_53_5()
{
  return *(void *)(v0 - 552);
}

uint64_t OUTLINED_FUNCTION_54_4()
{
  uint64_t v2 = *(void *)(v0 - 328);
  return outlined destroy of MLLogisticRegressionClassifier.ModelParameters(v2);
}

uint64_t OUTLINED_FUNCTION_55_4(uint64_t a1, uint64_t *a2)
{
  uint64_t v4 = *(void *)(v2 - 512);
  return outlined destroy of URL?(v4, a2);
}

uint64_t OUTLINED_FUNCTION_56_5()
{
  return type metadata accessor for MLLogisticRegressionClassifier();
}

uint64_t OUTLINED_FUNCTION_57_4(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return __swift_getEnumTagSinglePayload(a1, a2, a3);
}

uint64_t closure #1 in FeatureMatrixBuilder.fillArray(from:size:column:)@<X0>(id *a1@<X0>, uint64_t a2@<X8>)
{
  id v3 = *a1;
  MLShapedArray.init(_:)();
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Double>);
  return __swift_storeEnumTagSinglePayload(a2, 0, 1, v4);
}

void FeatureMatrixBuilder.fillArray<A, B>(_:descriptor:size:row:column:)(uint64_t a1, uint64_t a2, void *a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12)
{
  uint64_t v52 = a8;
  uint64_t v49 = a2;
  uint64_t v50 = a6;
  uint64_t v48 = a3;
  OUTLINED_FUNCTION_0_15();
  v43[1] = v13;
  MEMORY[0x270FA5388](v14);
  OUTLINED_FUNCTION_1_21(v15, v43[0]);
  MEMORY[0x270FA5388](v16);
  OUTLINED_FUNCTION_7_15(v17, v43[0]);
  uint64_t v53 = OUTLINED_FUNCTION_21_8(v18, MEMORY[0x263F8D6C8], v19);
  type metadata accessor for Optional();
  OUTLINED_FUNCTION_8_13();
  MEMORY[0x270FA5388](v20);
  uint64_t v22 = (uint64_t *)((char *)v43 - v21);
  uint64_t v23 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for PartialRangeFrom<Int>);
  unint64_t v24 = lazy protocol witness table accessor for type PartialRangeFrom<Int> and conformance <> PartialRangeFrom<A>();
  uint64_t v25 = *(void *)(a12 + 8);
  uint64_t v54 = v23;
  uint64_t v55 = a10;
  unint64_t v56 = v24;
  uint64_t v57 = v25;
  uint64_t v26 = type metadata accessor for Zip2Sequence();
  OUTLINED_FUNCTION_16_10(v26);
  OUTLINED_FUNCTION_8_13();
  MEMORY[0x270FA5388](v27);
  unint64_t v46 = v24;
  uint64_t v47 = v23;
  uint64_t v54 = v23;
  uint64_t v55 = a10;
  unint64_t v56 = v24;
  uint64_t v57 = v25;
  uint64_t v45 = v25;
  uint64_t v28 = type metadata accessor for Zip2Sequence.Iterator();
  OUTLINED_FUNCTION_0_15();
  uint64_t v44 = v29;
  OUTLINED_FUNCTION_8_13();
  MEMORY[0x270FA5388](v30);
  uint64_t v32 = (char *)v43 - v31;
  if (OUTLINED_FUNCTION_19_8() == v50)
  {
    OUTLINED_FUNCTION_4_17();
    Zip2Sequence.makeIterator()();
    Zip2Sequence.Iterator.next()();
    OUTLINED_FUNCTION_20_7((uint64_t)v22, 1);
    if (v33)
    {
LABEL_7:
      (*(void (**)(char *, uint64_t))(v44 + 8))(v32, v28);
    }
    else
    {
      OUTLINED_FUNCTION_10_9();
      uint64_t v51 = v32;
      while (!__OFADD__(v52, *v22))
      {
        uint64_t v34 = OUTLINED_FUNCTION_2_21();
        v35(v34);
        OUTLINED_FUNCTION_5_16();
        dispatch thunk of FloatingPoint.init<A>(_:)();
        OUTLINED_FUNCTION_13_8();
        uint64_t v32 = v51;
        type metadata accessor for DenseMatrix();
        DenseMatrix.subscript.setter();
        Zip2Sequence.Iterator.next()();
        OUTLINED_FUNCTION_20_7((uint64_t)v22, 1);
        if (v33) {
          goto LABEL_7;
        }
      }
      __break(1u);
    }
  }
  else
  {
    OUTLINED_FUNCTION_15_10();
    v36._uint64_t countAndFlagsBits = OUTLINED_FUNCTION_9_12();
    v36._uint64_t object = (void *)0x80000002272D6570;
    String.append(_:)(v36);
    uint64_t v58 = a12;
    v59._uint64_t countAndFlagsBits = OUTLINED_FUNCTION_12_6();
    OUTLINED_FUNCTION_17_9(v59);
    swift_bridgeObjectRelease();
    OUTLINED_FUNCTION_3_22();
    uint64_t v37 = v48;
    swift_bridgeObjectRetain();
    v38._uint64_t countAndFlagsBits = v49;
    v38._uint64_t object = v37;
    String.append(_:)(v38);
    swift_bridgeObjectRelease();
    OUTLINED_FUNCTION_18_8((uint64_t)"', but got size ");
    uint64_t v58 = dispatch thunk of Collection.count.getter();
    v60._uint64_t countAndFlagsBits = OUTLINED_FUNCTION_12_6();
    OUTLINED_FUNCTION_17_9(v60);
    swift_bridgeObjectRelease();
    OUTLINED_FUNCTION_14_8();
    uint64_t v58 = a7;
    v39._uint64_t countAndFlagsBits = OUTLINED_FUNCTION_12_6();
    String.append(_:)(v39);
    swift_bridgeObjectRelease();
    v40._uint64_t countAndFlagsBits = 46;
    v40._uint64_t object = (void *)0xE100000000000000;
    String.append(_:)(v40);
    lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    uint64_t v41 = swift_allocError();
    OUTLINED_FUNCTION_6_15(v41, v42);
  }
}

{
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  void *v22;
  uint64_t v23;
  unint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  char *v32;
  char v33;
  uint64_t v34;
  void (*v35)(uint64_t);
  Swift::String v36;
  void *v37;
  Swift::String v38;
  Swift::String v39;
  Swift::String v40;
  uint64_t v41;
  uint64_t v42;
  uint64_t v43[2];
  uint64_t v44;
  uint64_t v45;
  unint64_t v46;
  uint64_t v47;
  void *v48;
  uint64_t v49;
  uint64_t v50;
  uint64_t v51;
  uint64_t v52;
  uint64_t v53;
  uint64_t v54;
  uint64_t v55;
  unint64_t v56;
  uint64_t v57;
  uint64_t v58;
  Swift::String v59;
  Swift::String v60;

  uint64_t v52 = a8;
  uint64_t v49 = a2;
  uint64_t v50 = a6;
  uint64_t v48 = a3;
  OUTLINED_FUNCTION_0_15();
  v43[1] = v13;
  MEMORY[0x270FA5388](v14);
  OUTLINED_FUNCTION_1_21(v15, v43[0]);
  MEMORY[0x270FA5388](v16);
  OUTLINED_FUNCTION_7_15(v17, v43[0]);
  uint64_t v53 = OUTLINED_FUNCTION_21_8(v18, MEMORY[0x263F8D6C8], v19);
  type metadata accessor for Optional();
  OUTLINED_FUNCTION_8_13();
  MEMORY[0x270FA5388](v20);
  uint64_t v22 = (uint64_t *)((char *)v43 - v21);
  uint64_t v23 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for PartialRangeFrom<Int>);
  unint64_t v24 = lazy protocol witness table accessor for type PartialRangeFrom<Int> and conformance <> PartialRangeFrom<A>();
  uint64_t v25 = *(void *)(a12 + 8);
  uint64_t v54 = v23;
  uint64_t v55 = a10;
  unint64_t v56 = v24;
  uint64_t v57 = v25;
  uint64_t v26 = type metadata accessor for Zip2Sequence();
  OUTLINED_FUNCTION_16_10(v26);
  OUTLINED_FUNCTION_8_13();
  MEMORY[0x270FA5388](v27);
  unint64_t v46 = v24;
  uint64_t v47 = v23;
  uint64_t v54 = v23;
  uint64_t v55 = a10;
  unint64_t v56 = v24;
  uint64_t v57 = v25;
  uint64_t v45 = v25;
  uint64_t v28 = type metadata accessor for Zip2Sequence.Iterator();
  OUTLINED_FUNCTION_0_15();
  uint64_t v44 = v29;
  OUTLINED_FUNCTION_8_13();
  MEMORY[0x270FA5388](v30);
  uint64_t v32 = (char *)v43 - v31;
  if (OUTLINED_FUNCTION_19_8() == v50)
  {
    OUTLINED_FUNCTION_4_17();
    Zip2Sequence.makeIterator()();
    Zip2Sequence.Iterator.next()();
    OUTLINED_FUNCTION_20_7((uint64_t)v22, 1);
    if (v33)
    {
LABEL_7:
      (*(void (**)(char *, uint64_t))(v44 + 8))(v32, v28);
    }
    else
    {
      OUTLINED_FUNCTION_10_9();
      uint64_t v51 = a7;
      while (!__OFADD__(v52, *v22))
      {
        uint64_t v34 = OUTLINED_FUNCTION_2_21();
        v35(v34);
        OUTLINED_FUNCTION_5_16();
        dispatch thunk of BinaryFloatingPoint.init<A>(_:)();
        OUTLINED_FUNCTION_13_8();
        type metadata accessor for DenseMatrix();
        DenseMatrix.subscript.setter();
        Zip2Sequence.Iterator.next()();
        OUTLINED_FUNCTION_20_7((uint64_t)v22, 1);
        if (v33) {
          goto LABEL_7;
        }
      }
      __break(1u);
    }
  }
  else
  {
    OUTLINED_FUNCTION_15_10();
    v36._uint64_t countAndFlagsBits = OUTLINED_FUNCTION_9_12();
    v36._uint64_t object = (void *)0x80000002272D6570;
    String.append(_:)(v36);
    uint64_t v58 = a12;
    v59._uint64_t countAndFlagsBits = OUTLINED_FUNCTION_11_9();
    OUTLINED_FUNCTION_17_9(v59);
    swift_bridgeObjectRelease();
    OUTLINED_FUNCTION_3_22();
    uint64_t v37 = v48;
    swift_bridgeObjectRetain();
    v38._uint64_t countAndFlagsBits = v49;
    v38._uint64_t object = v37;
    String.append(_:)(v38);
    swift_bridgeObjectRelease();
    OUTLINED_FUNCTION_18_8((uint64_t)"', but got size ");
    uint64_t v58 = dispatch thunk of Collection.count.getter();
    v60._uint64_t countAndFlagsBits = OUTLINED_FUNCTION_11_9();
    OUTLINED_FUNCTION_17_9(v60);
    swift_bridgeObjectRelease();
    OUTLINED_FUNCTION_14_8();
    uint64_t v58 = a7;
    v39._uint64_t countAndFlagsBits = OUTLINED_FUNCTION_11_9();
    String.append(_:)(v39);
    swift_bridgeObjectRelease();
    v40._uint64_t countAndFlagsBits = 46;
    v40._uint64_t object = (void *)0xE100000000000000;
    String.append(_:)(v40);
    lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    uint64_t v41 = swift_allocError();
    OUTLINED_FUNCTION_6_15(v41, v42);
  }
}

unint64_t lazy protocol witness table accessor for type PartialRangeFrom<Int> and conformance <> PartialRangeFrom<A>()
{
  unint64_t result = lazy protocol witness table cache variable for type PartialRangeFrom<Int> and conformance <> PartialRangeFrom<A>;
  if (!lazy protocol witness table cache variable for type PartialRangeFrom<Int> and conformance <> PartialRangeFrom<A>)
  {
    __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for PartialRangeFrom<Int>);
    lazy protocol witness table accessor for type Int and conformance Int();
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type PartialRangeFrom<Int> and conformance <> PartialRangeFrom<A>);
  }
  return result;
}

uint64_t type metadata instantiation function for FeatureMatrixBuilder(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return MEMORY[0x270FA01A8](a1, a2, a3, 32);
}

uint64_t type metadata completion function for FeatureMatrixBuilder()
{
  uint64_t result = type metadata accessor for DenseMatrix();
  if (v1 <= 0x3F)
  {
    swift_initStructMetadata();
    return 0;
  }
  return result;
}

uint64_t initializeBufferWithCopyOfBuffer for FeatureMatrixBuilder(uint64_t a1, uint64_t *a2, uint64_t a3)
{
  int v3 = *(_DWORD *)(*(void *)(a3 - 8) + 80);
  uint64_t v4 = *a2;
  *(void *)a1 = *a2;
  if ((v3 & 0x20000) != 0)
  {
    uint64_t v5 = v4 + ((v3 + 16) & ~(unint64_t)v3);
    swift_retain();
  }
  else
  {
    uint64_t v5 = a1;
    *(void *)(a1 + 8) = a2[1];
    *(unsigned char *)(a1 + 16) = *((unsigned char *)a2 + 16);
    uint64_t v6 = *(int *)(a3 + 44);
    uint64_t v7 = a1 + v6;
    uint64_t v8 = (uint64_t)a2 + v6;
    uint64_t v9 = type metadata accessor for DenseMatrix();
    uint64_t v10 = *(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v9 - 8) + 16);
    swift_bridgeObjectRetain();
    swift_bridgeObjectRetain();
    v10(v7, v8, v9);
  }
  return v5;
}

uint64_t destroy for FeatureMatrixBuilder(uint64_t a1, uint64_t a2)
{
  swift_bridgeObjectRelease();
  swift_bridgeObjectRelease();
  uint64_t v4 = a1 + *(int *)(a2 + 44);
  uint64_t v5 = type metadata accessor for DenseMatrix();
  uint64_t v6 = *(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v5 - 8) + 8);

  return v6(v4, v5);
}

uint64_t initializeWithCopy for FeatureMatrixBuilder(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = *(void *)(a2 + 8);
  *(void *)a1 = *(void *)a2;
  *(void *)(a1 + 8) = v4;
  *(unsigned char *)(a1 + 16) = *(unsigned char *)(a2 + 16);
  uint64_t v5 = *(int *)(a3 + 44);
  uint64_t v6 = a1 + v5;
  uint64_t v7 = a2 + v5;
  uint64_t v8 = type metadata accessor for DenseMatrix();
  uint64_t v9 = *(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v8 - 8) + 16);
  swift_bridgeObjectRetain();
  swift_bridgeObjectRetain();
  v9(v6, v7, v8);
  return a1;
}

uint64_t assignWithCopy for FeatureMatrixBuilder(uint64_t a1, uint64_t a2, uint64_t a3)
{
  *(void *)a1 = *(void *)a2;
  swift_bridgeObjectRetain();
  swift_bridgeObjectRelease();
  *(void *)(a1 + 8) = *(void *)(a2 + 8);
  swift_bridgeObjectRetain();
  swift_bridgeObjectRelease();
  *(unsigned char *)(a1 + 16) = *(unsigned char *)(a2 + 16);
  uint64_t v6 = *(int *)(a3 + 44);
  uint64_t v7 = a1 + v6;
  uint64_t v8 = a2 + v6;
  uint64_t v9 = type metadata accessor for DenseMatrix();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v9 - 8) + 24))(v7, v8, v9);
  return a1;
}

uint64_t initializeWithTake for FeatureMatrixBuilder(uint64_t a1, uint64_t a2, uint64_t a3)
{
  *(_OWORD *)a1 = *(_OWORD *)a2;
  *(unsigned char *)(a1 + 16) = *(unsigned char *)(a2 + 16);
  uint64_t v4 = *(int *)(a3 + 44);
  uint64_t v5 = a1 + v4;
  uint64_t v6 = a2 + v4;
  uint64_t v7 = type metadata accessor for DenseMatrix();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v7 - 8) + 32))(v5, v6, v7);
  return a1;
}

uint64_t assignWithTake for FeatureMatrixBuilder(uint64_t a1, uint64_t a2, uint64_t a3)
{
  *(void *)a1 = *(void *)a2;
  swift_bridgeObjectRelease();
  *(void *)(a1 + 8) = *(void *)(a2 + 8);
  swift_bridgeObjectRelease();
  *(unsigned char *)(a1 + 16) = *(unsigned char *)(a2 + 16);
  uint64_t v6 = *(int *)(a3 + 44);
  uint64_t v7 = a1 + v6;
  uint64_t v8 = a2 + v6;
  uint64_t v9 = type metadata accessor for DenseMatrix();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v9 - 8) + 40))(v7, v8, v9);
  return a1;
}

uint64_t getEnumTagSinglePayload for FeatureMatrixBuilder(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return MEMORY[0x270FA0340](a1, a2, a3, sub_2270E1E04);
}

uint64_t sub_2270E1E04(uint64_t *a1, uint64_t a2, uint64_t a3)
{
  if (a2 == 0x7FFFFFFF)
  {
    uint64_t v4 = *a1;
    if ((unint64_t)*a1 >= 0xFFFFFFFF) {
      LODWORD(v4) = -1;
    }
    return (v4 + 1);
  }
  else
  {
    uint64_t v8 = type metadata accessor for DenseMatrix();
    uint64_t v9 = (uint64_t)a1 + *(int *)(a3 + 44);
    return __swift_getEnumTagSinglePayload(v9, a2, v8);
  }
}

uint64_t storeEnumTagSinglePayload for FeatureMatrixBuilder(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return MEMORY[0x270FA0580](a1, a2, a3, a4, sub_2270E1EA4);
}

void *sub_2270E1EA4(void *result, uint64_t a2, int a3, uint64_t a4)
{
  uint64_t v5 = result;
  if (a3 == 0x7FFFFFFF)
  {
    *uint64_t result = (a2 - 1);
  }
  else
  {
    uint64_t v7 = type metadata accessor for DenseMatrix();
    uint64_t v8 = (uint64_t)v5 + *(int *)(a4 + 44);
    return (void *)__swift_storeEnumTagSinglePayload(v8, a2, a2, v7);
  }
  return result;
}

uint64_t type metadata accessor for FeatureMatrixBuilder()
{
  return __swift_instantiateGenericMetadata();
}

uint64_t __swift_instantiateGenericMetadata()
{
  return swift_getGenericMetadata();
}

void OUTLINED_FUNCTION_1_21(uint64_t a1@<X8>, uint64_t a2)
{
  *(void *)(v3 - 168) = (char *)&a2 - ((a1 + 15) & 0xFFFFFFFFFFFFFFF0);
  *(void *)(v3 - 160) = v2;
  *(void *)(v3 - 184) = *(void *)(v2 + 16);
}

uint64_t OUTLINED_FUNCTION_2_21()
{
  return *(void *)(v0 - 168);
}

void OUTLINED_FUNCTION_3_22()
{
  uint64_t v1 = 0x61656620726F6620;
  unint64_t v2 = 0xEE00272065727574;
  String.append(_:)(*(Swift::String *)&v1);
}

uint64_t OUTLINED_FUNCTION_4_17()
{
  *(void *)(v0 - 120) = 0;
  return zip<A, B>(_:_:)();
}

uint64_t OUTLINED_FUNCTION_5_16()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_6_15(uint64_t a1, uint64_t a2)
{
  *(void *)a2 = v2;
  *(void *)(a2 + 8) = v3;
  *(_OWORD *)(a2 + 16) = 0u;
  *(_OWORD *)(a2 + 32) = 0u;
  *(unsigned char *)(a2 + 48) = 0;
  return swift_willThrow();
}

void OUTLINED_FUNCTION_7_15(uint64_t a1@<X8>, uint64_t a2)
{
  *(void *)(v2 - 176) = (char *)&a2 - ((a1 + 15) & 0xFFFFFFFFFFFFFFF0);
}

unint64_t OUTLINED_FUNCTION_9_12()
{
  uint64_t v1 = *(void *)(v0 - 112);
  *(void *)(v0 - 120) = *(void *)(v0 - 120);
  *(void *)(v0 - 112) = v1;
  return 0xD00000000000001ALL;
}

void OUTLINED_FUNCTION_10_9()
{
  *(void *)(v0 - 200) = *(void *)(v0 + 48);
  *(void *)(v0 - 208) = *(void *)(v0 - 280) + 32;
}

uint64_t OUTLINED_FUNCTION_11_9()
{
  return dispatch thunk of CustomStringConvertible.description.getter();
}

uint64_t OUTLINED_FUNCTION_12_6()
{
  return dispatch thunk of CustomStringConvertible.description.getter();
}

uint64_t OUTLINED_FUNCTION_13_8()
{
  return 0;
}

void OUTLINED_FUNCTION_14_8()
{
  uint64_t v1 = 0x20776F7220746120;
  unint64_t v2 = 0xE800000000000000;
  String.append(_:)(*(Swift::String *)&v1);
}

void OUTLINED_FUNCTION_15_10()
{
  *(void *)(v0 - 120) = 0;
  *(void *)(v0 - 112) = 0xE000000000000000;
  _StringGuts.grow(_:)(73);
}

uint64_t OUTLINED_FUNCTION_16_10(uint64_t result)
{
  *(void *)(v1 - 256) = result;
  return result;
}

void OUTLINED_FUNCTION_17_9(Swift::String a1)
{
  String.append(_:)(a1);
}

void OUTLINED_FUNCTION_18_8(uint64_t a1@<X8>)
{
  unint64_t v3 = 0xD000000000000010;
  unint64_t v2 = (a1 - 32) | 0x8000000000000000;
  String.append(_:)(*(Swift::String *)&v3);
}

uint64_t OUTLINED_FUNCTION_19_8()
{
  *(void *)(v1 - 200) = v0;
  return dispatch thunk of Collection.count.getter();
}

uint64_t OUTLINED_FUNCTION_20_7(uint64_t a1, uint64_t a2)
{
  return __swift_getEnumTagSinglePayload(a1, a2, v2);
}

uint64_t OUTLINED_FUNCTION_21_8(uint64_t a1, uint64_t a2, uint64_t a3)
{
  *(void *)(v3 - 152) = a3;
  return swift_getTupleTypeMetadata2();
}

void static MLDataColumn.== infix(_:_:)()
{
  static MLDataColumn.== infix(_:_:)();
}

{
  uint64_t (*v0)(void);
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  char v14;

  OUTLINED_FUNCTION_0_16();
  uint64_t v1 = v0();
  OUTLINED_FUNCTION_6_16(v1, v2, v3, v4, v5, v6, v7, v8, v9, v10, v11, v12, v13, v14);
}

void static MLDataColumn.!= infix(_:_:)()
{
  static MLDataColumn.== infix(_:_:)();
}

void static MLDataColumn.> infix(_:_:)()
{
  static MLDataColumn.== infix(_:_:)();
}

void static MLDataColumn.< infix(_:_:)()
{
  static MLDataColumn.== infix(_:_:)();
}

void static MLDataColumn.>= infix(_:_:)()
{
  static MLDataColumn.== infix(_:_:)();
}

void static MLDataColumn.<= infix(_:_:)()
{
  static MLDataColumn.== infix(_:_:)();
}

uint64_t static MLDataColumn.== infix(_:_:)@<X0>(uint64_t *a1@<X0>, uint64_t a2@<X2>, uint64_t a3@<X3>, uint64_t a4@<X8>)
{
  return static MLDataColumn.== infix(_:_:)(a1, a2, a3, (void (*)(char *))static MLUntypedColumn.== infix(_:_:), a4);
}

uint64_t static MLDataColumn.!= infix(_:_:)@<X0>(uint64_t *a1@<X0>, uint64_t a2@<X2>, uint64_t a3@<X3>, uint64_t a4@<X8>)
{
  return static MLDataColumn.== infix(_:_:)(a1, a2, a3, (void (*)(char *))static MLUntypedColumn.!= infix(_:_:), a4);
}

uint64_t static MLDataColumn.> infix(_:_:)@<X0>(uint64_t *a1@<X0>, uint64_t a2@<X2>, uint64_t a3@<X3>, uint64_t a4@<X8>)
{
  return static MLDataColumn.== infix(_:_:)(a1, a2, a3, (void (*)(char *))static MLUntypedColumn.> infix(_:_:), a4);
}

uint64_t static MLDataColumn.< infix(_:_:)@<X0>(uint64_t *a1@<X0>, uint64_t a2@<X2>, uint64_t a3@<X3>, uint64_t a4@<X8>)
{
  return static MLDataColumn.== infix(_:_:)(a1, a2, a3, (void (*)(char *))static MLUntypedColumn.< infix(_:_:), a4);
}

uint64_t static MLDataColumn.>= infix(_:_:)@<X0>(uint64_t *a1@<X0>, uint64_t a2@<X2>, uint64_t a3@<X3>, uint64_t a4@<X8>)
{
  return static MLDataColumn.== infix(_:_:)(a1, a2, a3, (void (*)(char *))static MLUntypedColumn.>= infix(_:_:), a4);
}

uint64_t static MLDataColumn.<= infix(_:_:)@<X0>(uint64_t *a1@<X0>, uint64_t a2@<X2>, uint64_t a3@<X3>, uint64_t a4@<X8>)
{
  return static MLDataColumn.== infix(_:_:)(a1, a2, a3, (void (*)(char *))static MLUntypedColumn.<= infix(_:_:), a4);
}

uint64_t static MLDataColumn.== infix(_:_:)@<X0>(uint64_t *a1@<X0>, uint64_t a2@<X2>, uint64_t a3@<X3>, void (*a4)(char *)@<X4>, uint64_t a5@<X8>)
{
  uint64_t v7 = *a1;
  char v8 = *((unsigned char *)a1 + 8);
  uint64_t v24 = a3;
  uint64_t v25 = v7;
  char v26 = v8;
  uint64_t v23 = a2;
  __swift_allocate_boxed_opaque_existential_0(v22);
  OUTLINED_FUNCTION_7_16();
  uint64_t v10 = v9();
  uint64_t v18 = OUTLINED_FUNCTION_4_18(v10, v11, v12, v13, v14, v15, v16, v17, v21, v22[0], v22[1], v22[2], v23, v24, v25);
  a4(v18);
  uint64_t result = __swift_destroy_boxed_opaque_existential_0((uint64_t)v22);
  char v20 = v28;
  *(void *)a5 = v27;
  *(unsigned char *)(a5 + 8) = v20;
  return result;
}

uint64_t static MLDataColumn.== infix(_:_:)@<X0>(uint64_t a1@<X1>, uint64_t a2@<X2>, uint64_t a3@<X3>, uint64_t a4@<X8>)
{
  return static MLDataColumn.== infix(_:_:)(a1, a2, a3, (void (*)(char *))static MLUntypedColumn.== infix(_:_:), a4);
}

uint64_t static MLDataColumn.!= infix(_:_:)@<X0>(uint64_t a1@<X1>, uint64_t a2@<X2>, uint64_t a3@<X3>, uint64_t a4@<X8>)
{
  return static MLDataColumn.== infix(_:_:)(a1, a2, a3, (void (*)(char *))static MLUntypedColumn.!= infix(_:_:), a4);
}

uint64_t static MLDataColumn.> infix(_:_:)@<X0>(uint64_t a1@<X1>, uint64_t a2@<X2>, uint64_t a3@<X3>, uint64_t a4@<X8>)
{
  return static MLDataColumn.== infix(_:_:)(a1, a2, a3, (void (*)(char *))static MLUntypedColumn.> infix(_:_:), a4);
}

uint64_t static MLDataColumn.< infix(_:_:)@<X0>(uint64_t a1@<X1>, uint64_t a2@<X2>, uint64_t a3@<X3>, uint64_t a4@<X8>)
{
  return static MLDataColumn.== infix(_:_:)(a1, a2, a3, (void (*)(char *))static MLUntypedColumn.< infix(_:_:), a4);
}

uint64_t static MLDataColumn.>= infix(_:_:)@<X0>(uint64_t a1@<X1>, uint64_t a2@<X2>, uint64_t a3@<X3>, uint64_t a4@<X8>)
{
  return static MLDataColumn.== infix(_:_:)(a1, a2, a3, (void (*)(char *))static MLUntypedColumn.>= infix(_:_:), a4);
}

uint64_t static MLDataColumn.<= infix(_:_:)@<X0>(uint64_t a1@<X1>, uint64_t a2@<X2>, uint64_t a3@<X3>, uint64_t a4@<X8>)
{
  return static MLDataColumn.== infix(_:_:)(a1, a2, a3, (void (*)(char *))static MLUntypedColumn.<= infix(_:_:), a4);
}

uint64_t static MLDataColumn.== infix(_:_:)@<X0>(uint64_t a1@<X1>, uint64_t a2@<X2>, uint64_t a3@<X3>, void (*a4)(char *)@<X4>, uint64_t a5@<X8>)
{
  uint64_t v7 = *(void *)a1;
  char v8 = *(unsigned char *)(a1 + 8);
  v23[3] = a2;
  v23[4] = a3;
  __swift_allocate_boxed_opaque_existential_0(v23);
  OUTLINED_FUNCTION_7_16();
  uint64_t v10 = v9();
  LOBYTE(v22) = v8;
  uint64_t v18 = OUTLINED_FUNCTION_8_14(v10, v11, v12, v13, v14, v15, v16, v17, v21, v7, v22, v23[0]);
  a4(v18);
  uint64_t result = __swift_destroy_boxed_opaque_existential_0((uint64_t)v23);
  char v20 = v24;
  *(void *)a5 = v23[5];
  *(unsigned char *)(a5 + 8) = v20;
  return result;
}

void static MLDataColumn<>.+ infix(_:_:)()
{
}

{
  static MLDataColumn<>.+ infix(_:_:)();
}

{
  uint64_t (*v0)(void);
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  char v14;

  OUTLINED_FUNCTION_0_16();
  uint64_t v1 = v0();
  OUTLINED_FUNCTION_6_16(v1, v2, v3, v4, v5, v6, v7, v8, v9, v10, v11, v12, v13, v14);
}

void static MLDataColumn<>.- infix(_:_:)()
{
}

{
  static MLDataColumn<>.+ infix(_:_:)();
}

void static MLDataColumn<>.* infix(_:_:)()
{
}

{
  static MLDataColumn<>.+ infix(_:_:)();
}

void static MLDataColumn<>./ infix(_:_:)()
{
  OUTLINED_FUNCTION_0_16();
  static MLUntypedColumn./ infix(_:_:)();
  OUTLINED_FUNCTION_3_23();

  outlined consume of Result<_DataTable, Error>(v0, v1);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  char *v8;
  uint64_t *v9;
  void *v10;
  char v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  char v15[40];
  void *v16;
  char v17;

  OUTLINED_FUNCTION_2_22();
  char v8 = OUTLINED_FUNCTION_8_14(v0, v1, v2, v3, v4, v5, v6, v7, v12, v13, v14, v15[0]);
  static MLUntypedColumn./ infix(_:_:)((uint64_t)v8, v9);
  __swift_destroy_boxed_opaque_existential_0((uint64_t)v15);
  uint64_t v10 = v16;
  uint64_t v11 = v17;
  OUTLINED_FUNCTION_3_23();
  outlined consume of Result<_DataTable, Error>(v10, v11);
}

{
  char v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  void *v9;
  char v10;
  uint64_t v11;
  void v12[3];
  char v13;
  char v14;
  void *v15;
  char v16;

  OUTLINED_FUNCTION_5_17();
  uint64_t v14 = v0;
  OUTLINED_FUNCTION_4_18(v1, v2, v3, v4, v5, v6, v7, v8, v11, v2, v12[1], v12[2], MEMORY[0x263F8D6C8], (uint64_t)&protocol witness table for Int, v13);
  static MLUntypedColumn./ infix(_:_:)();
  __swift_destroy_boxed_opaque_existential_0((uint64_t)v12);
  uint64_t v9 = v15;
  uint64_t v10 = v16;
  OUTLINED_FUNCTION_3_23();
  outlined consume of Result<_DataTable, Error>(v9, v10);
}

{
  static MLDataColumn<>.+ infix(_:_:)();
}

#error "2270E26A8: call analysis failed (funcsize=121)"

uint64_t static MLDataColumn<>.+ infix(_:_:)()
{
  return static MLDataColumn<>.+ infix(_:_:)();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  char *v8;
  void (*v9)(char *);
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  char v14[40];

  OUTLINED_FUNCTION_2_22();
  char v8 = OUTLINED_FUNCTION_8_14(v0, v1, v2, v3, v4, v5, v6, v7, v11, v12, v13, v14[0]);
  v9(v8);
  return OUTLINED_FUNCTION_1_22((uint64_t)v14);
}

{
  return static MLDataColumn<>.+ infix(_:_:)();
}

{
  char v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  char *v9;
  void (*v10)(char *);
  uint64_t v12;
  void v13[3];
  char v14;
  char v15;

  OUTLINED_FUNCTION_5_17();
  uint64_t v15 = v0;
  uint64_t v9 = OUTLINED_FUNCTION_4_18(v1, v2, v3, v4, v5, v6, v7, v8, v12, v2, v13[1], v13[2], MEMORY[0x263F8D6C8], (uint64_t)&protocol witness table for Int, v14);
  v10(v9);
  return OUTLINED_FUNCTION_1_22((uint64_t)v13);
}

uint64_t static MLDataColumn<>.- infix(_:_:)()
{
  return static MLDataColumn<>.+ infix(_:_:)();
}

{
  return static MLDataColumn<>.+ infix(_:_:)();
}

uint64_t static MLDataColumn<>.* infix(_:_:)()
{
  return static MLDataColumn<>.+ infix(_:_:)();
}

{
  return static MLDataColumn<>.+ infix(_:_:)();
}

uint64_t static MLDataColumn<>.+ infix(_:_:)(uint64_t a1, __n128 a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
  return static MLDataColumn<>.+ infix(_:_:)(a1, (uint64_t)static MLUntypedColumn.+ infix(_:_:), a4, a5, a6, a7, a8, a9, a2);
}

uint64_t static MLDataColumn<>.- infix(_:_:)(uint64_t a1, __n128 a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
  return static MLDataColumn<>.+ infix(_:_:)(a1, (uint64_t)static MLUntypedColumn.- infix(_:_:), a4, a5, a6, a7, a8, a9, a2);
}

uint64_t static MLDataColumn<>.* infix(_:_:)(uint64_t a1, __n128 a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
  return static MLDataColumn<>.+ infix(_:_:)(a1, (uint64_t)static MLUntypedColumn.* infix(_:_:), a4, a5, a6, a7, a8, a9, a2);
}

uint64_t static MLDataColumn<>./ infix(_:_:)(uint64_t a1, __n128 a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
  return static MLDataColumn<>.+ infix(_:_:)(a1, (uint64_t)static MLUntypedColumn./ infix(_:_:), a4, a5, a6, a7, a8, a9, a2);
}

uint64_t static MLDataColumn<>.+ infix(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, __n128 a9)
{
  uint64_t v9 = *(void *)a1;
  char v10 = *(unsigned char *)(a1 + 8);
  v16[3] = MEMORY[0x263F8D538];
  v16[4] = &protocol witness table for Double;
  LOBYTE(v15) = v10;
  uint64_t v11 = OUTLINED_FUNCTION_8_14(a1, a2, a3, a4, a5, a6, a7, a8, v14, v9, v15, a9.n128_i8[0]);
  v12(v11);
  return OUTLINED_FUNCTION_1_22((uint64_t)v16);
}

uint64_t static MLDataColumn<>.+ infix(_:_:)(uint64_t a1, double a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
  return static MLDataColumn<>.+ infix(_:_:)(a1, (uint64_t)static MLUntypedColumn.+ infix(_:_:), a4, a5, a6, a7, a8, a9, a2);
}

uint64_t static MLDataColumn<>.- infix(_:_:)(uint64_t a1, double a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
  return static MLDataColumn<>.+ infix(_:_:)(a1, (uint64_t)static MLUntypedColumn.- infix(_:_:), a4, a5, a6, a7, a8, a9, a2);
}

uint64_t static MLDataColumn<>.* infix(_:_:)(uint64_t a1, double a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
  return static MLDataColumn<>.+ infix(_:_:)(a1, (uint64_t)static MLUntypedColumn.* infix(_:_:), a4, a5, a6, a7, a8, a9, a2);
}

uint64_t static MLDataColumn<>./ infix(_:_:)(uint64_t a1, double a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
  return static MLDataColumn<>.+ infix(_:_:)(a1, (uint64_t)static MLUntypedColumn./ infix(_:_:), a4, a5, a6, a7, a8, a9, a2);
}

uint64_t static MLDataColumn<>.+ infix(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, double a9)
{
  char v9 = *(unsigned char *)(a1 + 8);
  uint64_t v15 = *(void *)a1;
  char v16 = v9;
  char v10 = OUTLINED_FUNCTION_4_18(a1, a2, a3, a4, a5, a6, a7, a8, v13, *(uint64_t *)&a9, v14[1], v14[2], MEMORY[0x263F8D538], (uint64_t)&protocol witness table for Double, v15);
  v11(v10);
  return OUTLINED_FUNCTION_1_22((uint64_t)v14);
}

void static MLDataColumn<>.|| infix(_:_:)()
{
}

void static MLDataColumn<>.&& infix(_:_:)()
{
}

uint64_t OUTLINED_FUNCTION_1_22(uint64_t a1)
{
  uint64_t result = __swift_destroy_boxed_opaque_existential_0(a1);
  char v4 = *(unsigned char *)(v2 - 24);
  *(void *)uint64_t v1 = *(void *)(v2 - 32);
  *(unsigned char *)(v1 + 8) = v4;
  return result;
}

uint64_t OUTLINED_FUNCTION_3_23()
{
  return specialized MLUntypedColumn.map<A>(to:)(v0, v1);
}

char *OUTLINED_FUNCTION_4_18(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, char a15)
{
  return &a15;
}

void OUTLINED_FUNCTION_6_16(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, char a14)
{
  *(void *)uint64_t v14 = a13;
  *(unsigned char *)(v14 + 8) = a14;
}

char *OUTLINED_FUNCTION_8_14(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, char a12)
{
  return &a12;
}

uint64_t static MLModel.compile(_:)(uint64_t a1)
{
  *(void *)(v1 + 128) = a1;
  return MEMORY[0x270FA2498](static MLModel.compile(_:), 0, 0);
}

uint64_t static MLModel.compile(_:)()
{
  uint64_t v1 = Model.serialized()();
  v0[17] = v1;
  v0[18] = v2;
  uint64_t v3 = v1;
  unint64_t v4 = v2;
  type metadata accessor for MLModelAsset();
  outlined copy of Data._Representation(v3, v4);
  id v5 = @nonobjc MLModelAsset.__allocating_init(specification:)(v3, v4);
  v0[19] = v5;
  id v6 = v5;
  uint64_t v7 = self;
  id v8 = objc_msgSend(objc_allocWithZone(MEMORY[0x263F00D98]), sel_init);
  v0[20] = v8;
  v0[2] = v0;
  v0[7] = v0 + 15;
  v0[3] = static MLModel.compile(_:);
  uint64_t v9 = swift_continuation_init();
  v0[10] = MEMORY[0x263EF8330];
  v0[11] = 0x40000000;
  v0[12] = @objc completion handler block implementation for @escaping @callee_unowned @convention(block) (@unowned MLModel?, @unowned NSError?) -> () with result type MLModel;
  v0[13] = &block_descriptor;
  v0[14] = v9;
  objc_msgSend(v7, sel_loadModelAsset_configuration_completionHandler_, v6, v8, v0 + 10);
  return MEMORY[0x270FA23F0](v0 + 2);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t (*v2)();
  uint64_t v4;

  uint64_t v1 = *(void *)(*(void *)v0 + 48);
  *(void *)(*(void *)v0 + 168) = v1;
  if (v1) {
    unint64_t v2 = static MLModel.compile(_:);
  }
  else {
    unint64_t v2 = static MLModel.compile(_:);
  }
  return MEMORY[0x270FA2498](v2, 0, 0);
}

{
  void *v0;
  void *v1;
  void *v2;
  uint64_t v3;
  uint64_t (*v4)(uint64_t);
  uint64_t v6;

  unint64_t v2 = (void *)v0[19];
  uint64_t v1 = (void *)v0[20];
  outlined consume of Data._Representation(v0[17], v0[18]);

  uint64_t v3 = v0[15];
  unint64_t v4 = (uint64_t (*)(uint64_t))v0[1];
  return v4(v3);
}

{
  void *v0;
  void *v1;
  unint64_t v2;
  void *v3;
  uint64_t v4;
  uint64_t (*v5)(void);
  uint64_t v7;

  uint64_t v1 = (void *)v0[20];
  unint64_t v2 = v0[18];
  uint64_t v3 = (void *)v0[19];
  unint64_t v4 = v0[17];
  swift_willThrow();
  outlined consume of Data._Representation(v4, v2);

  id v5 = (uint64_t (*)(void))v0[1];
  return v5();
}

unint64_t type metadata accessor for MLModelAsset()
{
  unint64_t result = lazy cache variable for type metadata for MLModelAsset;
  if (!lazy cache variable for type metadata for MLModelAsset)
  {
    self;
    unint64_t result = swift_getObjCClassMetadata();
    atomic_store(result, (unint64_t *)&lazy cache variable for type metadata for MLModelAsset);
  }
  return result;
}

id @nonobjc MLModelAsset.__allocating_init(specification:)(uint64_t a1, unint64_t a2)
{
  v9[1] = *(id *)MEMORY[0x263EF8340];
  Class isa = Data._bridgeToObjectiveC()().super.isa;
  v9[0] = 0;
  id v5 = objc_msgSend((id)swift_getObjCClassFromMetadata(), sel_modelAssetWithSpecificationData_error_, isa, v9);

  if (v5)
  {
    id v6 = v9[0];
  }
  else
  {
    id v7 = v9[0];
    _convertNSErrorToError(_:)();

    swift_willThrow();
  }
  outlined consume of Data._Representation(a1, a2);
  return v5;
}

uint64_t @objc completion handler block implementation for @escaping @callee_unowned @convention(block) (@unowned MLModel?, @unowned NSError?) -> () with result type MLModel(uint64_t result, void *a2, void *a3)
{
  uint64_t v3 = *(void *)(result + 32);
  if (a3)
  {
    id v4 = a3;
    return specialized _resumeUnsafeThrowingContinuationWithError<A>(_:_:)(v3, (uint64_t)v4);
  }
  else if (a2)
  {
    id v5 = a2;
    return specialized _resumeUnsafeThrowingContinuation<A>(_:_:)(v3, (uint64_t)v5);
  }
  else
  {
    __break(1u);
  }
  return result;
}

uint64_t specialized _resumeUnsafeThrowingContinuationWithError<A>(_:_:)(uint64_t a1, uint64_t a2)
{
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
  uint64_t v4 = swift_allocError();
  *id v5 = a2;

  return MEMORY[0x270FA2410](a1, v4);
}

uint64_t specialized _resumeUnsafeThrowingContinuation<A>(_:_:)(uint64_t a1, uint64_t a2)
{
  **(void **)(*(void *)(a1 + 64) + 40) = a2;
  return MEMORY[0x270FA2408]();
}

uint64_t _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lF11TabularData0D5FrameV_s5NeverO8CreateML23MLDecisionTreeRegressorV15ModelParametersV010ValidationD0OTg503_s8g4ML23ijk3V15lm75V13configuration10validationAE0A12MLComponents07BoostedD13ConfigurationV_11c7Data0N5e12VSgtcfcAE010N21N0OAMcAPmcfu_ApMcfu0_AOXMtTf1ncn_n@<X0>(uint64_t a1@<X0>, uint64_t a2@<X8>)
{
  uint64_t v4 = type metadata accessor for DataFrame();
  uint64_t v5 = *(void *)(v4 - 8);
  MEMORY[0x270FA5388](v4);
  id v7 = (char *)&v16 - ((v6 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
  MEMORY[0x270FA5388](v8 - 8);
  char v10 = (char *)&v16 - ((v9 + 15) & 0xFFFFFFFFFFFFFFF0);
  outlined init with copy of URL?(a1, (uint64_t)v10, &demangling cache variable for type metadata for DataFrame?);
  if (__swift_getEnumTagSinglePayload((uint64_t)v10, 1, v4) == 1)
  {
    uint64_t v11 = type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData();
    uint64_t v12 = a2;
    uint64_t v13 = 1;
  }
  else
  {
    (*(void (**)(char *, char *, uint64_t))(v5 + 32))(v7, v10, v4);
    (*(void (**)(uint64_t, char *, uint64_t))(v5 + 16))(a2, v7, v4);
    uint64_t v14 = type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData();
    swift_storeEnumTagMultiPayload();
    (*(void (**)(char *, uint64_t))(v5 + 8))(v7, v4);
    uint64_t v12 = a2;
    uint64_t v13 = 0;
    uint64_t v11 = v14;
  }
  return __swift_storeEnumTagSinglePayload(v12, v13, 1, v11);
}

id MLDecisionTreeRegressor.model.getter()
{
  uint64_t v1 = *(void **)(v0 + *(int *)(type metadata accessor for MLDecisionTreeRegressor() + 20));

  return v1;
}

uint64_t type metadata accessor for MLDecisionTreeRegressor()
{
  uint64_t result = type metadata singleton initialization cache for MLDecisionTreeRegressor;
  if (!type metadata singleton initialization cache for MLDecisionTreeRegressor) {
    return swift_getSingletonMetadata();
  }
  return result;
}

void key path setter for MLDecisionTreeRegressor.model : MLDecisionTreeRegressor(id *a1)
{
  id v1 = *a1;
  MLDecisionTreeRegressor.model.setter();
}

void MLDecisionTreeRegressor.model.setter()
{
  uint64_t v2 = *(int *)(OUTLINED_FUNCTION_44_1() + 20);

  *(void *)(v1 + v2) = v0;
}

void (*MLDecisionTreeRegressor.model.modify(uint64_t a1))(uint64_t a1, char a2)
{
  *(void *)(a1 + 8) = v1;
  uint64_t v3 = *(int *)(type metadata accessor for MLDecisionTreeRegressor() + 20);
  *(_DWORD *)(a1 + 16) = v3;
  uint64_t v4 = *(void **)(v1 + v3);
  *(void *)a1 = v4;
  id v5 = v4;
  return MLRandomForestRegressor.model.modify;
}

uint64_t MLDecisionTreeRegressor.targetColumn.getter()
{
  uint64_t v1 = *(void *)(v0 + *(int *)(type metadata accessor for MLDecisionTreeRegressor() + 24));
  swift_bridgeObjectRetain();
  return v1;
}

uint64_t MLDecisionTreeRegressor.targetColumn.setter(uint64_t a1, uint64_t a2)
{
  id v5 = (void *)(v2 + *(int *)(type metadata accessor for MLDecisionTreeRegressor() + 24));
  uint64_t result = swift_bridgeObjectRelease();
  *id v5 = a1;
  v5[1] = a2;
  return result;
}

uint64_t (*MLDecisionTreeRegressor.targetColumn.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLDecisionTreeRegressor.featureColumns.getter()
{
  type metadata accessor for MLDecisionTreeRegressor();

  return swift_bridgeObjectRetain();
}

uint64_t MLDecisionTreeRegressor.featureColumns.setter()
{
  uint64_t v2 = *(int *)(OUTLINED_FUNCTION_44_1() + 28);
  uint64_t result = swift_bridgeObjectRelease();
  *(void *)(v1 + v2) = v0;
  return result;
}

uint64_t (*MLDecisionTreeRegressor.featureColumns.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLDecisionTreeRegressor.modelParameters.getter()
{
  uint64_t v2 = v1 + *(int *)(OUTLINED_FUNCTION_40_4() + 32);

  return outlined init with copy of MLDecisionTreeRegressor.ModelParameters(v2, v0);
}

uint64_t outlined init with copy of MLDecisionTreeRegressor.ModelParameters(uint64_t a1, uint64_t a2)
{
  return a2;
}

id MLDecisionTreeRegressor.trainingMetrics.getter()
{
  uint64_t v0 = OUTLINED_FUNCTION_40_4();
  uint64_t v1 = (void *)OUTLINED_FUNCTION_45_0(*(int *)(v0 + 36));

  return outlined copy of Result<_RegressorMetrics, Error>(v1, v2, v3);
}

id MLDecisionTreeRegressor.validationMetrics.getter()
{
  uint64_t v0 = OUTLINED_FUNCTION_40_4();
  uint64_t v1 = (void *)OUTLINED_FUNCTION_45_0(*(int *)(v0 + 40));

  return outlined copy of Result<_RegressorMetrics, Error>(v1, v2, v3);
}

uint64_t static MLDecisionTreeRegressor._defaultSessionParameters.getter@<X0>(uint64_t a1@<X8>)
{
  if (one-time initialization token for _defaultSessionParameters != -1) {
    swift_once();
  }
  uint64_t v2 = type metadata accessor for MLTrainingSessionParameters();
  uint64_t v3 = __swift_project_value_buffer(v2, (uint64_t)static MLDecisionTreeRegressor._defaultSessionParameters);
  return _s8CreateML27MLTrainingSessionParametersVWOcTm_1(v3, a1, (void (*)(void))type metadata accessor for MLTrainingSessionParameters);
}

uint64_t MLDecisionTreeRegressor.init(_:targetColumn:featureColumns:parameters:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  v6[6] = a5;
  v6[7] = a6;
  v6[4] = a3;
  v6[5] = a4;
  v6[2] = a1;
  v6[3] = a2;
  OUTLINED_FUNCTION_14();
  return MEMORY[0x270FA2498](v7, v8, v9);
}

uint64_t MLDecisionTreeRegressor.init(_:targetColumn:featureColumns:parameters:)()
{
  uint64_t v2 = *(void *)(v0 + 40);
  uint64_t v1 = *(void *)(v0 + 48);
  uint64_t v3 = *(void *)(v0 + 32);
  uint64_t v4 = *(void *)(v0 + 16);
  id v5 = (int *)type metadata accessor for MLDecisionTreeRegressor();
  *(void *)(v0 + 64) = v5;
  uint64_t v6 = v5[9];
  *(_DWORD *)(v0 + 96) = v6;
  uint64_t v7 = v4 + v6;
  *(void *)uint64_t v7 = 0;
  *(void *)(v7 + 8) = 0;
  *(unsigned char *)(v7 + 16) = 0;
  *(_DWORD *)(v0 + 100) = v5[10];
  lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  uint64_t v8 = swift_allocError();
  OUTLINED_FUNCTION_21_2(v8, v9, 0xD0000000000000C0);
  uint64_t v10 = v5[7];
  *(_DWORD *)(v0 + 104) = v10;
  *(void *)(v4 + v10) = v1;
  uint64_t v11 = (void *)(v4 + v5[6]);
  *uint64_t v11 = v3;
  v11[1] = v2;
  uint64_t v14 = (uint64_t (*)(void))((char *)&async function pointer to specialized CoreMLExportable.exportAsCoreMLModel()
                          + async function pointer to specialized CoreMLExportable.exportAsCoreMLModel());
  uint64_t v12 = (void *)swift_task_alloc();
  *(void *)(v0 + 72) = v12;
  *uint64_t v12 = v0;
  v12[1] = MLDecisionTreeRegressor.init(_:targetColumn:featureColumns:parameters:);
  return v14();
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  void *v6;
  uint64_t v7;
  void *v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v13;

  OUTLINED_FUNCTION_60_0();
  uint64_t v3 = v2;
  OUTLINED_FUNCTION_2();
  id v5 = v4;
  OUTLINED_FUNCTION_7();
  *uint64_t v6 = v5;
  uint64_t v7 = *v1;
  OUTLINED_FUNCTION_6();
  *uint64_t v8 = v7;
  *(void *)(v5 + 80) = v0;
  swift_task_dealloc();
  if (!v0) {
    *(void *)(v5 + 88) = v3;
  }
  OUTLINED_FUNCTION_14();
  return MEMORY[0x270FA2498](v9, v10, v11);
}

{
  void *v0;
  uint64_t v1;
  _OWORD *v2;
  uint64_t v3;
  uint64_t v4;
  _OWORD *v5;
  long long v6;
  long long v7;
  long long v8;
  uint64_t (*v9)(void);
  uint64_t v11;

  OUTLINED_FUNCTION_60_0();
  uint64_t v2 = (_OWORD *)v0[7];
  uint64_t v1 = v0[8];
  uint64_t v4 = v0[2];
  uint64_t v3 = v0[3];
  *(void *)(v4 + *(int *)(v1 + 20)) = v0[11];
  _s8CreateML18TreeRegressorModelVWObTm_0(v3, v4, (void (*)(void))type metadata accessor for TreeRegressorModel);
  id v5 = (_OWORD *)(v4 + *(int *)(v1 + 32));
  uint64_t v7 = v2[2];
  uint64_t v6 = v2[3];
  uint64_t v8 = v2[1];
  *id v5 = *v2;
  v5[1] = v8;
  v5[2] = v7;
  v5[3] = v6;
  uint64_t v9 = (uint64_t (*)(void))v0[1];
  return v9();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t (*v5)(void);
  uint64_t v7;

  uint64_t v2 = *(void *)(v0 + 16);
  uint64_t v1 = *(void *)(v0 + 24);
  uint64_t v3 = v2 + *(int *)(v0 + 96);
  uint64_t v4 = v2 + *(int *)(v0 + 100);
  outlined destroy of MLDecisionTreeRegressor.ModelParameters(*(void *)(v0 + 56));
  outlined destroy of MLDecisionTreeRegressor.ModelParameters.ValidationData(v1, (void (*)(void))type metadata accessor for TreeRegressorModel);
  swift_bridgeObjectRelease();
  swift_bridgeObjectRelease();
  outlined consume of Result<_RegressorMetrics, Error>(*(id *)v3, *(void *)(v3 + 8), *(unsigned char *)(v3 + 16));
  outlined consume of Result<_RegressorMetrics, Error>(*(id *)v4, *(void *)(v4 + 8), *(unsigned char *)(v4 + 16));
  OUTLINED_FUNCTION_30();
  return v5();
}

void MLDecisionTreeRegressor.init(trainingData:targetColumn:featureColumns:parameters:)()
{
  OUTLINED_FUNCTION_9_0();
  uint64_t v137 = v0;
  uint64_t v3 = v2;
  uint64_t v135 = (char *)v4;
  uint64_t v147 = v5;
  uint64_t v133 = (void *)v6;
  uint64_t v8 = v7;
  uint64_t v10 = v9;
  type metadata accessor for DataFrame();
  OUTLINED_FUNCTION_0();
  uint64_t v139 = v12;
  uint64_t v140 = v11;
  MEMORY[0x270FA5388](v11);
  OUTLINED_FUNCTION_33_0();
  OUTLINED_FUNCTION_17_3(v13);
  uint64_t v14 = type metadata accessor for TreeRegressorModel();
  uint64_t v15 = OUTLINED_FUNCTION_1(v14);
  uint64_t v121 = v16;
  MEMORY[0x270FA5388](v15);
  OUTLINED_FUNCTION_50_0();
  uint64_t v123 = v17;
  uint64_t v122 = v18;
  MEMORY[0x270FA5388](v19);
  OUTLINED_FUNCTION_106();
  OUTLINED_FUNCTION_17_3(v20);
  uint64_t v130 = type metadata accessor for BaseTreeRegressor();
  OUTLINED_FUNCTION_0();
  uint64_t v129 = v21;
  MEMORY[0x270FA5388](v22);
  OUTLINED_FUNCTION_33_0();
  OUTLINED_FUNCTION_17_3(v23);
  uint64_t v127 = type metadata accessor for TreeRegressor();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v24);
  OUTLINED_FUNCTION_33_0();
  OUTLINED_FUNCTION_17_3(v25);
  type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v26);
  OUTLINED_FUNCTION_27_7();
  uint64_t v27 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v28);
  OUTLINED_FUNCTION_49();
  uint64_t v118 = v29;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v30);
  uint64_t v119 = (char *)&v114 - v31;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v32);
  uint64_t v34 = (char *)&v114 - v33;
  type metadata accessor for BoostedTreeConfiguration();
  OUTLINED_FUNCTION_0();
  uint64_t v141 = v35;
  uint64_t v142 = v36;
  MEMORY[0x270FA5388](v35);
  OUTLINED_FUNCTION_49();
  uint64_t v125 = v37;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v38);
  uint64_t v126 = (char *)&v114 - v39;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v40);
  uint64_t v42 = (char *)&v114 - v41;
  uint64_t v43 = type metadata accessor for MLDecisionTreeRegressor();
  uint64_t v44 = v10 + *(int *)(v43 + 36);
  *(void *)uint64_t v44 = 0;
  *(void *)(v44 + 8) = 0;
  uint64_t v136 = v44;
  *(unsigned char *)(v44 + 16) = 0;
  uint64_t v120 = (int *)v43;
  uint64_t v45 = *(int *)(v43 + 40);
  uint64_t v124 = v10;
  uint64_t v46 = v10 + v45;
  lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  swift_allocError();
  OUTLINED_FUNCTION_32_2(v47, 0xD0000000000000C0);
  *(void *)uint64_t v46 = v48;
  *(void *)(v46 + 8) = 0;
  uint64_t v134 = v46;
  *(unsigned char *)(v46 + 16) = 1;
  outlined init with copy of MLDecisionTreeRegressor.ModelParameters(v3, (uint64_t)&v145);
  BoostedTreeConfiguration.init()();
  BoostedTreeConfiguration.maximumIterations.setter();
  BoostedTreeConfiguration.learningRate.setter();
  BoostedTreeConfiguration.maximumDepth.setter();
  BoostedTreeConfiguration.minimumLossReduction.setter();
  BoostedTreeConfiguration.minimumChildWeight.setter();
  BoostedTreeConfiguration.randomSeed.setter();
  outlined destroy of MLDecisionTreeRegressor.ModelParameters((uint64_t)&v145);
  uint64_t v138 = v3;
  outlined init with copy of URL?(v3, (uint64_t)&v143, &demangling cache variable for type metadata for Any?);
  if (v144)
  {
    uint64_t v49 = (uint64_t)&v34[*(int *)(v27 + 48)];
    outlined init with take of Any(&v143, &v145);
    swift_dynamicCast();
    uint64_t v50 = OUTLINED_FUNCTION_39_6();
    uint64_t v51 = v137;
    MLDecisionTreeRegressor.ModelParameters.ValidationData.generateDataFrames(trainingData:)(v50, v52, v8);
    if (v51)
    {
      swift_bridgeObjectRelease();
      swift_bridgeObjectRelease();
      outlined destroy of MLDecisionTreeRegressor.ModelParameters(v138);
      OUTLINED_FUNCTION_25_0();
      v53();
      outlined destroy of MLDecisionTreeRegressor.ModelParameters.ValidationData(v1, (void (*)(void))type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData);
      (*(void (**)(char *, uint64_t))(v142 + 8))(v42, v141);
    }
    else
    {
      uint64_t v137 = v49;
      uint64_t v116 = v27;
      outlined destroy of MLDecisionTreeRegressor.ModelParameters.ValidationData(v1, (void (*)(void))type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData);
      uint64_t v54 = (uint64_t)v133;
      static _FeatureUtilities.selectFeaturesFromTrainingData(trainingData:targetColumn:featureColumns:)((uint64_t)v34, (uint64_t)v133, v147, (uint64_t)v135);
      uint64_t v114 = v8;
      uint64_t v58 = v55;
      swift_bridgeObjectRelease();
      uint64_t v115 = 0;
      uint64_t v59 = v141;
      Swift::String v60 = *(void (**)(char *, char *, uint64_t))(v142 + 16);
      uint64_t v61 = v126;
      uint64_t v135 = v34;
      v60(v126, v42, v141);
      uint64_t v62 = v131;
      *uint64_t v131 = v54;
      v62[1] = (uint64_t)v147;
      v62[2] = v58;
      v62[3] = v58;
      OUTLINED_FUNCTION_52_0();
      v62[4] = v64;
      v62[5] = v63;
      v60(v125, v61, v59);
      swift_bridgeObjectRetain_n();
      swift_bridgeObjectRetain();
      uint64_t v65 = v128;
      uint64_t v66 = v142;
      BaseTreeRegressor.init(configuration:)();
      uint64_t v67 = *(void (***)(char *, uint64_t, uint64_t))(v66 + 8);
      ((void (*)(char *, uint64_t))v67)(v61, v59);
      v129[4]((char *)v62 + *(int *)(v127 + 28), v65, v130);
      uint64_t v68 = v115;
      TreeRegressor.fitted(to:validateOn:eventHandler:)();
      if (!v68)
      {
        uint64_t v130 = v58;
        uint64_t v142 = v66 + 8;
        uint64_t v129 = v67;
        if ((AnalyticsReporter.init()() & 1) == 0)
        {
          uint64_t v70 = v119;
          uint64_t v71 = (uint64_t)&v119[*(int *)(v116 + 48)];
          uint64_t v72 = v139;
          uint64_t v73 = v140;
          (*(void (**)(char *, char *, uint64_t))(v139 + 16))(v119, v135, v140);
          uint64_t v74 = OUTLINED_FUNCTION_39_6();
          outlined init with copy of URL?(v74, v75, &demangling cache variable for type metadata for DataFrame?);
          Swift::Int v76 = DataFrame.shape.getter();
          (*(void (**)(char *, uint64_t))(v72 + 8))(v70, v73);
          v77._uint64_t countAndFlagsBits = 0xD000000000000015;
          v77._uint64_t object = (void *)0x80000002272D4D30;
          AnalyticsReporter.reportDataMetrics(model:metricName:quantity:)(CreateML_ModelType_decisionTreeRegressor, v77, v76);
          outlined destroy of URL?(v71, &demangling cache variable for type metadata for DataFrame?);
        }
        uint64_t v78 = v120;
        uint64_t v79 = v124;
        uint64_t v80 = (uint64_t *)(v124 + v120[6]);
        uint64_t v81 = (uint64_t)v133;
        uint64_t v133 = v80;
        *uint64_t v80 = v81;
        v80[1] = (uint64_t)v147;
        uint64_t v128 = v79 + v78[8];
        outlined init with copy of MLDecisionTreeRegressor.ModelParameters(v138, v128);
        *(void *)(v79 + v78[7]) = v130;
        uint64_t v82 = v123;
        _s8CreateML27MLTrainingSessionParametersVWOcTm_1(v132, v123, (void (*)(void))type metadata accessor for TreeRegressorModel);
        unint64_t v83 = (*(unsigned __int8 *)(v121 + 80) + 16) & ~(unint64_t)*(unsigned __int8 *)(v121 + 80);
        uint64_t v84 = swift_allocObject();
        _s8CreateML18TreeRegressorModelVWObTm_0(v82, v84 + v83, (void (*)(void))type metadata accessor for TreeRegressorModel);
        specialized blockAwait<A>(_:)();
        uint64_t v86 = v85;
        swift_release();
        uint64_t v87 = v78[5];
        *(void *)(v79 + v87) = v86;
        uint64_t v88 = OUTLINED_FUNCTION_39_6();
        _s8CreateML27MLTrainingSessionParametersVWOcTm_1(v88, v89, v90);
        uint64_t v91 = (uint64_t)v135;
        TreeRegressorModel.computeMetrics(on:)((uint64_t)&v145);
        uint64_t v115 = 0;
        uint64_t v57 = v136;
        long long v95 = v145;
        char v96 = v146;
        outlined consume of Result<_RegressorMetrics, Error>(*(id *)v136, *(void *)(v136 + 8), *(unsigned char *)(v136 + 16));
        *(_OWORD *)uint64_t v57 = v95;
        *(unsigned char *)(v57 + 16) = v96;
        uint64_t v97 = v139;
        uint64_t v98 = v140;
        uint64_t v99 = v118 + *(int *)(v116 + 48);
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v139 + 16))(v118, v91, v140);
        outlined init with copy of URL?(v137, v99, &demangling cache variable for type metadata for DataFrame?);
        if (__swift_getEnumTagSinglePayload(v99, 1, v98) == 1)
        {
          outlined destroy of MLDecisionTreeRegressor.ModelParameters(v138);
          uint64_t v100 = *(void (**)(void))(v97 + 8);
          OUTLINED_FUNCTION_14_3();
          v100();
          uint64_t v101 = outlined destroy of MLDecisionTreeRegressor.ModelParameters.ValidationData(v132, (void (*)(void))type metadata accessor for TreeRegressorModel);
          OUTLINED_FUNCTION_31_5(v101, (void (*)(void))type metadata accessor for TreeRegressor);
          outlined destroy of URL?(v91, &demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
          uint64_t v102 = OUTLINED_FUNCTION_4_19();
          v103(v102);
          outlined destroy of URL?(v99, &demangling cache variable for type metadata for DataFrame?);
          OUTLINED_FUNCTION_14_3();
          v100();
          goto LABEL_7;
        }
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v97 + 32))(v117, v99, v98);
        uint64_t v104 = *(void (**)(void))(v97 + 8);
        OUTLINED_FUNCTION_14_3();
        v104();
        uint64_t v105 = v124;
        uint64_t v106 = v115;
        TreeRegressorModel.computeMetrics(on:)((uint64_t)&v145);
        uint64_t v115 = v106;
        if (!v106)
        {
          outlined destroy of MLDecisionTreeRegressor.ModelParameters(v138);
          OUTLINED_FUNCTION_14_3();
          v104();
          OUTLINED_FUNCTION_14_3();
          v104();
          uint64_t v108 = outlined destroy of MLDecisionTreeRegressor.ModelParameters.ValidationData(v132, (void (*)(void))type metadata accessor for TreeRegressorModel);
          OUTLINED_FUNCTION_31_5(v108, (void (*)(void))type metadata accessor for TreeRegressor);
          outlined destroy of URL?((uint64_t)v135, &demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
          uint64_t v109 = OUTLINED_FUNCTION_4_19();
          v110(v109);
          long long v111 = v145;
          char v112 = v146;
          uint64_t v113 = v134;
          outlined consume of Result<_RegressorMetrics, Error>(*(id *)v134, *(void *)(v134 + 8), *(unsigned char *)(v134 + 16));
          *(_OWORD *)uint64_t v113 = v111;
          *(unsigned char *)(v113 + 16) = v112;
          goto LABEL_7;
        }
        outlined destroy of MLDecisionTreeRegressor.ModelParameters(v138);
        OUTLINED_FUNCTION_14_3();
        v104();
        OUTLINED_FUNCTION_14_3();
        v104();
        uint64_t v107 = outlined destroy of MLDecisionTreeRegressor.ModelParameters.ValidationData(v132, (void (*)(void))type metadata accessor for TreeRegressorModel);
        OUTLINED_FUNCTION_31_5(v107, (void (*)(void))type metadata accessor for TreeRegressor);
        outlined destroy of URL?((uint64_t)v135, &demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
        uint64_t v92 = OUTLINED_FUNCTION_4_19();
        v93(v92);
        outlined destroy of MLDecisionTreeRegressor.ModelParameters.ValidationData(v105, (void (*)(void))type metadata accessor for TreeRegressorModel);

        uint64_t v56 = v134;
        uint64_t v94 = v128;
        swift_bridgeObjectRelease();
        swift_bridgeObjectRelease();
        outlined destroy of MLDecisionTreeRegressor.ModelParameters(v94);
LABEL_6:
        outlined consume of Result<_RegressorMetrics, Error>(*(id *)v57, *(void *)(v57 + 8), *(unsigned char *)(v57 + 16));
        outlined consume of Result<_RegressorMetrics, Error>(*(id *)v56, *(void *)(v56 + 8), *(unsigned char *)(v56 + 16));
LABEL_7:
        OUTLINED_FUNCTION_8_1();
        return;
      }
      swift_bridgeObjectRelease();
      swift_bridgeObjectRelease();
      outlined destroy of MLDecisionTreeRegressor.ModelParameters(v138);
      OUTLINED_FUNCTION_25_0();
      v69();
      outlined destroy of MLDecisionTreeRegressor.ModelParameters.ValidationData((uint64_t)v62, (void (*)(void))type metadata accessor for TreeRegressor);
      outlined destroy of URL?((uint64_t)v135, &demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
      ((void (*)(char *, uint64_t))v67)(v42, v59);
    }
    uint64_t v56 = v134;
    uint64_t v57 = v136;
    goto LABEL_6;
  }
  __break(1u);
}

uint64_t outlined destroy of MLDecisionTreeRegressor.ModelParameters(uint64_t a1)
{
  return a1;
}

uint64_t partial apply for closure #1 in MLDecisionTreeRegressor.init(trainingData:targetColumn:featureColumns:parameters:)()
{
  OUTLINED_FUNCTION_11();
  uint64_t v1 = v0;
  uint64_t v2 = type metadata accessor for TreeRegressorModel();
  OUTLINED_FUNCTION_39_0(v2);
  uint64_t v3 = swift_task_alloc();
  uint64_t v4 = (void *)OUTLINED_FUNCTION_7_1(v3);
  *uint64_t v4 = v5;
  v4[1] = protocol witness for SupervisedEstimator.fitted<A>(to:eventHandler:) in conformance MLImageClassifier.Classifier;
  return closure #1 in MLRandomForestRegressor.init(trainingData:targetColumn:featureColumns:parameters:)(v1);
}

uint64_t MLDecisionTreeRegressor.init(trainingData:targetColumn:featureColumns:parameters:)(uint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v7 = type metadata accessor for DataFrame();
  uint64_t v8 = OUTLINED_FUNCTION_17(v7);
  MEMORY[0x270FA5388](v8);
  OUTLINED_FUNCTION_3_0();
  uint64_t v11 = v10 - v9;
  LOBYTE(v10) = *((unsigned char *)a1 + 8);
  uint64_t v13 = *a1;
  char v14 = v10;
  DataFrame.init(_:)((uint64_t)&v13, v11);
  outlined init with copy of MLDecisionTreeRegressor.ModelParameters(a5, (uint64_t)&v13);
  MLDecisionTreeRegressor.init(trainingData:targetColumn:featureColumns:parameters:)();
  return outlined destroy of MLDecisionTreeRegressor.ModelParameters(a5);
}

void MLDecisionTreeRegressor.init(checkpoint:)()
{
  OUTLINED_FUNCTION_9_0();
  uint64_t v73 = v1;
  uint64_t v3 = v2;
  uint64_t v5 = v4;
  uint64_t v61 = type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v6);
  OUTLINED_FUNCTION_49();
  uint64_t v60 = v7;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v8);
  OUTLINED_FUNCTION_106();
  uint64_t v62 = v9;
  uint64_t v10 = type metadata accessor for TreeRegressorModel();
  uint64_t v11 = OUTLINED_FUNCTION_1(v10);
  uint64_t v65 = v12;
  MEMORY[0x270FA5388](v11);
  OUTLINED_FUNCTION_50_0();
  uint64_t v66 = v14;
  uint64_t v67 = v13;
  MEMORY[0x270FA5388](v15);
  OUTLINED_FUNCTION_106();
  uint64_t v74 = v16;
  type metadata accessor for BaseTreeRegressor();
  OUTLINED_FUNCTION_0();
  uint64_t v71 = v18;
  uint64_t v72 = v17;
  MEMORY[0x270FA5388](v17);
  OUTLINED_FUNCTION_33_0();
  uint64_t v70 = v19;
  uint64_t v69 = type metadata accessor for BoostedTreeConfiguration();
  OUTLINED_FUNCTION_0();
  uint64_t v21 = v20;
  uint64_t v23 = MEMORY[0x270FA5388](v22);
  uint64_t v25 = (char *)&v59 - ((v24 + 15) & 0xFFFFFFFFFFFFFFF0);
  MEMORY[0x270FA5388](v23);
  uint64_t v27 = (char *)&v59 - v26;
  uint64_t v68 = type metadata accessor for TreeRegressor();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v28);
  OUTLINED_FUNCTION_30_2();
  uint64_t v29 = type metadata accessor for MLDecisionTreeRegressor();
  uint64_t v30 = v5 + *(int *)(v29 + 36);
  *(void *)uint64_t v30 = 0;
  *(void *)(v30 + 8) = 0;
  *(unsigned char *)(v30 + 16) = 0;
  uint64_t v63 = v5;
  uint64_t v64 = v29;
  uint64_t v31 = v5 + *(int *)(v29 + 40);
  lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  uint64_t v32 = swift_allocError();
  OUTLINED_FUNCTION_21_2(v32, v33, 0xD0000000000000C0);
  uint64_t v76 = v3;
  switch(*(unsigned char *)(v3 + *(int *)(type metadata accessor for MLCheckpoint() + 20)))
  {
    case 2:
      swift_bridgeObjectRelease();
      goto LABEL_4;
    default:
      char v34 = _stringCompareWithSmolCheck(_:_:expecting:)();
      swift_bridgeObjectRelease();
      if (v34)
      {
LABEL_4:
        BoostedTreeConfiguration.init()();
        uint64_t v35 = MEMORY[0x263F8EE78];
        *(void *)uint64_t v0 = 0;
        *((void *)v0 + 1) = 0xE000000000000000;
        *((void *)v0 + 2) = v35;
        *((void *)v0 + 3) = v35;
        OUTLINED_FUNCTION_52_0();
        *((void *)v0 + 4) = v37;
        *((void *)v0 + 5) = v36;
        uint64_t v38 = v69;
        (*(void (**)(char *, char *, uint64_t))(v21 + 16))(v25, v27, v69);
        uint64_t v39 = v70;
        BaseTreeRegressor.init(configuration:)();
        (*(void (**)(char *, uint64_t))(v21 + 8))(v27, v38);
        (*(void (**)(char *, uint64_t, uint64_t))(v71 + 32))(&v0[*(int *)(v68 + 28)], v39, v72);
        lazy protocol witness table accessor for type TreeRegressor and conformance TreeRegressor();
        uint64_t v40 = v73;
        uint64_t v41 = v74;
        OUTLINED_FUNCTION_39_6();
        UpdatableSupervisedTabularEstimator.readWithOptimizer(from:)();
        if (!v40)
        {
          uint64_t v43 = v67;
          _s8CreateML27MLTrainingSessionParametersVWOcTm_1(v41, v67, (void (*)(void))type metadata accessor for TreeRegressorModel);
          unint64_t v44 = (*(unsigned __int8 *)(v65 + 80) + 16) & ~(unint64_t)*(unsigned __int8 *)(v65 + 80);
          uint64_t v45 = swift_allocObject();
          _s8CreateML18TreeRegressorModelVWObTm_0(v43, v45 + v44, (void (*)(void))type metadata accessor for TreeRegressorModel);
          specialized blockAwait<A>(_:)();
          uint64_t v47 = v46;
          swift_release();
          uint64_t v50 = v63;
          uint64_t v51 = v64;
          *(void *)(v63 + *(int *)(v64 + 20)) = v47;
          _s8CreateML27MLTrainingSessionParametersVWOcTm_1(v41, v50, (void (*)(void))type metadata accessor for TreeRegressorModel);
          uint64_t v53 = v61;
          uint64_t v52 = (uint64_t)v62;
          *uint64_t v62 = 0;
          *(void *)(v52 + 8) = 0;
          *(_WORD *)(v52 + 16) = 256;
          swift_storeEnumTagMultiPayload();
          uint64_t v54 = v50 + *(int *)(v51 + 32);
          *(_OWORD *)uint64_t v54 = 0u;
          *(_OWORD *)(v54 + 16) = 0u;
          *(void *)(v54 + 32) = 6;
          *(_OWORD *)(v54 + 40) = xmmword_2272CB8D0;
          *(void *)(v54 + 56) = 42;
          uint64_t v55 = v60;
          _s8CreateML27MLTrainingSessionParametersVWOcTm_1(v52, v60, (void (*)(void))type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData);
          v75[3] = v53;
          boxed_opaque_existential_0 = __swift_allocate_boxed_opaque_existential_0(v75);
          _s8CreateML18TreeRegressorModelVWObTm_0(v55, (uint64_t)boxed_opaque_existential_0, (void (*)(void))type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData);
          outlined assign with take of Any?((uint64_t)v75, v54);
          outlined destroy of MLDecisionTreeRegressor.ModelParameters.ValidationData(v52, (void (*)(void))type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData);
          uint64_t v57 = v64;
          uint64_t v58 = (void *)(v50 + *(int *)(v64 + 24));
          *uint64_t v58 = 0;
          v58[1] = 0xE000000000000000;
          outlined destroy of MLDecisionTreeRegressor.ModelParameters.ValidationData(v76, (void (*)(void))type metadata accessor for MLCheckpoint);
          outlined destroy of MLDecisionTreeRegressor.ModelParameters.ValidationData(v41, (void (*)(void))type metadata accessor for TreeRegressorModel);
          outlined destroy of MLDecisionTreeRegressor.ModelParameters.ValidationData((uint64_t)v0, (void (*)(void))type metadata accessor for TreeRegressor);
          *(void *)(v50 + *(int *)(v57 + 28)) = MEMORY[0x263F8EE78];
          goto LABEL_9;
        }
        outlined destroy of MLDecisionTreeRegressor.ModelParameters.ValidationData(v76, (void (*)(void))type metadata accessor for MLCheckpoint);
        uint64_t v48 = type metadata accessor for TreeRegressor;
        uint64_t v49 = (uint64_t)v0;
      }
      else
      {
        swift_allocError();
        OUTLINED_FUNCTION_32_2(v42, 0xD000000000000042);
        swift_willThrow();
        uint64_t v48 = type metadata accessor for MLCheckpoint;
        uint64_t v49 = v76;
      }
      outlined destroy of MLDecisionTreeRegressor.ModelParameters.ValidationData(v49, (void (*)(void))v48);
      outlined consume of Result<_RegressorMetrics, Error>(*(id *)v30, *(void *)(v30 + 8), *(unsigned char *)(v30 + 16));
      outlined consume of Result<_RegressorMetrics, Error>(*(id *)v31, *(void *)(v31 + 8), *(unsigned char *)(v31 + 16));
LABEL_9:
      OUTLINED_FUNCTION_8_1();
      return;
  }
}

void static MLDecisionTreeRegressor.train(trainingData:targetColumn:featureColumns:parameters:sessionParameters:)()
{
  OUTLINED_FUNCTION_9_0();
  OUTLINED_FUNCTION_42_0();
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v3);
  OUTLINED_FUNCTION_41_1();
  char v4 = *(unsigned char *)(v2 + 8);
  id v7 = *(id *)v2;
  char v8 = v4;
  outlined copy of Result<_DataTable, Error>(v7, v4);
  DataFrame.init(_:)((uint64_t)&v7, v1);
  static MLDecisionTreeRegressor.makeTrainingSession(trainingData:targetColumn:featureColumns:parameters:sessionParameters:)();
  uint64_t v5 = OUTLINED_FUNCTION_38_1();
  v6(v5);
  if (!v0)
  {
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLJob<MLDecisionTreeRegressor>);
    OUTLINED_FUNCTION_31_0();
    specialized MLJob.init(_:)();
  }
  OUTLINED_FUNCTION_8_1();
}

{
  uint64_t v0;

  static MLDecisionTreeRegressor.makeTrainingSession(trainingData:targetColumn:featureColumns:parameters:sessionParameters:)();
  if (!v0)
  {
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLJob<MLDecisionTreeRegressor>);
    OUTLINED_FUNCTION_31_0();
    specialized MLJob.init(_:)();
  }
}

void static MLDecisionTreeRegressor.makeTrainingSession(trainingData:targetColumn:featureColumns:parameters:sessionParameters:)()
{
  OUTLINED_FUNCTION_9_0();
  uint64_t v2 = OUTLINED_FUNCTION_42_0();
  OUTLINED_FUNCTION_0();
  uint64_t v4 = v3;
  MEMORY[0x270FA5388](v5);
  OUTLINED_FUNCTION_15();
  char v6 = *(unsigned char *)(v1 + 8);
  id v7 = *(id *)v1;
  char v8 = v6;
  outlined copy of Result<_DataTable, Error>(v7, v6);
  DataFrame.init(_:)((uint64_t)&v7, v0);
  static MLDecisionTreeRegressor.makeTrainingSession(trainingData:targetColumn:featureColumns:parameters:sessionParameters:)();
  (*(void (**)(uint64_t, uint64_t))(v4 + 8))(v0, v2);
  OUTLINED_FUNCTION_8_1();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  char *v24;
  uint64_t v25;
  char *v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  void (*v33)(void);
  uint64_t v34;
  uint64_t v35;
  uint64_t v36;
  uint64_t v37;
  uint64_t v38;
  void (*v39)(void);
  uint64_t v40;
  void v41[3];
  uint64_t v42;
  uint64_t v43;
  uint64_t v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  uint64_t v49;
  long long v50;
  uint64_t v51;
  _UNKNOWN **v52;
  long long v53;
  uint64_t v54;
  uint64_t v55;

  OUTLINED_FUNCTION_9_0();
  uint64_t v48 = v2;
  uint64_t v49 = v3;
  uint64_t v5 = v4;
  uint64_t v46 = v6;
  uint64_t v47 = v7;
  uint64_t v9 = v8;
  uint64_t v10 = type metadata accessor for MLTrainingSessionParameters();
  uint64_t v11 = OUTLINED_FUNCTION_17(v10);
  MEMORY[0x270FA5388](v11);
  OUTLINED_FUNCTION_49();
  uint64_t v43 = v12;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v13);
  OUTLINED_FUNCTION_106();
  uint64_t v45 = v14;
  uint64_t v15 = type metadata accessor for BoostedTreeConfiguration();
  uint64_t v16 = OUTLINED_FUNCTION_17(v15);
  MEMORY[0x270FA5388](v16);
  OUTLINED_FUNCTION_41_1();
  type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v17);
  OUTLINED_FUNCTION_15();
  uint64_t v18 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v19);
  OUTLINED_FUNCTION_49();
  uint64_t v55 = v20;
  OUTLINED_FUNCTION_20_3();
  uint64_t v22 = MEMORY[0x270FA5388](v21);
  uint64_t v24 = (char *)v41 - v23;
  MEMORY[0x270FA5388](v22);
  uint64_t v26 = (char *)v41 - v25;
  unint64_t v44 = v5;
  outlined init with copy of URL?(v5, (uint64_t)&v53, &demangling cache variable for type metadata for Any?);
  if (v54)
  {
    uint64_t v27 = (uint64_t)&v26[*(int *)(v18 + 48)];
    outlined init with take of Any(&v53, &v50);
    swift_dynamicCast();
    MLDecisionTreeRegressor.ModelParameters.ValidationData.generateDataFrames(trainingData:)((uint64_t)v26, v27, v9);
    outlined destroy of MLDecisionTreeRegressor.ModelParameters.ValidationData(v0, (void (*)(void))type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData);
    if (!v1)
    {
      uint64_t v28 = (uint64_t)&v24[*(int *)(v18 + 48)];
      uint64_t v29 = type metadata accessor for DataFrame();
      v41[0] = v24;
      uint64_t v30 = v29;
      OUTLINED_FUNCTION_0();
      v41[1] = v31;
      uint64_t v33 = *(void (**)(void))(v32 + 16);
      ((void (*)(uint64_t, char *, uint64_t))v33)(v34, v26, v30);
      uint64_t v42 = v28;
      outlined init with copy of URL?(v27, v28, &demangling cache variable for type metadata for DataFrame?);
      uint64_t v35 = v55 + *(int *)(v18 + 48);
      v41[2] = v30;
      v33();
      outlined init with copy of URL?(v27, v35, &demangling cache variable for type metadata for DataFrame?);
      outlined init with copy of MLDecisionTreeRegressor.ModelParameters(v44, (uint64_t)&v50);
      swift_bridgeObjectRetain();
      swift_bridgeObjectRetain();
      BoostedTreeConfiguration.init()();
      BoostedTreeConfiguration.maximumIterations.setter();
      BoostedTreeConfiguration.learningRate.setter();
      BoostedTreeConfiguration.maximumDepth.setter();
      BoostedTreeConfiguration.minimumLossReduction.setter();
      BoostedTreeConfiguration.minimumChildWeight.setter();
      BoostedTreeConfiguration.randomSeed.setter();
      outlined destroy of MLDecisionTreeRegressor.ModelParameters((uint64_t)&v50);
      _s8CreateML27MLTrainingSessionParametersVWOcTm_1(v49, v45, (void (*)(void))type metadata accessor for MLTrainingSessionParameters);
      uint64_t v36 = type metadata accessor for TreeRegressorTrainingSessionDelegate();
      OUTLINED_FUNCTION_31_0();
      TreeRegressorTrainingSessionDelegate.init(trainingData:validationData:targetColumn:featureColumns:configuration:sessionParameters:)();
      uint64_t v38 = v37;
      OUTLINED_FUNCTION_25_0();
      v39();
      outlined destroy of URL?(v42, &demangling cache variable for type metadata for DataFrame?);
      uint64_t v51 = v36;
      uint64_t v52 = &protocol witness table for TreeRegressorTrainingSessionDelegate;
      *(void *)&uint64_t v50 = v38;
      uint64_t v40 = v43;
      _s8CreateML27MLTrainingSessionParametersVWOcTm_1(v49, v43, (void (*)(void))type metadata accessor for MLTrainingSessionParameters);
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLDecisionTreeRegressor>);
      OUTLINED_FUNCTION_31_0();
      swift_retain();
      specialized MLTrainingSession.init(delegate:parameters:modelType:)((uint64_t)&v50, v40, 2);
      outlined destroy of URL?((uint64_t)v26, &demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
      swift_release();
    }
    OUTLINED_FUNCTION_8_1();
  }
  else
  {
    __break(1u);
  }
}

uint64_t static MLDecisionTreeRegressor.resume(_:)()
{
  return specialized MLJob.init(_:)();
}

void static MLDecisionTreeRegressor.restoreTrainingSession(sessionParameters:)(uint64_t a1)
{
  uint64_t v3 = type metadata accessor for MLTrainingSessionParameters();
  uint64_t v4 = OUTLINED_FUNCTION_17(v3);
  uint64_t v5 = MEMORY[0x270FA5388](v4);
  id v7 = (char *)&v13[-1] - ((v6 + 15) & 0xFFFFFFFFFFFFFFF0);
  MEMORY[0x270FA5388](v5);
  uint64_t v9 = (char *)&v13[-1] - v8;
  _s8CreateML27MLTrainingSessionParametersVWOcTm_1(a1, (uint64_t)&v13[-1] - v8, (void (*)(void))type metadata accessor for MLTrainingSessionParameters);
  uint64_t v10 = type metadata accessor for TreeRegressorTrainingSessionDelegate();
  OUTLINED_FUNCTION_31_0();
  uint64_t v11 = TreeRegressorTrainingSessionDelegate.init(sessionParameters:)((uint64_t)v9);
  if (!v1)
  {
    v13[3] = v10;
    uint64_t v13[4] = &protocol witness table for TreeRegressorTrainingSessionDelegate;
    v13[0] = v11;
    _s8CreateML27MLTrainingSessionParametersVWOcTm_1(a1, (uint64_t)v7, (void (*)(void))type metadata accessor for MLTrainingSessionParameters);
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLDecisionTreeRegressor>);
    OUTLINED_FUNCTION_31_0();
    specialized MLTrainingSession.init(delegate:parameters:modelType:)((uint64_t)v13, (uint64_t)v7, 2);
  }
}

uint64_t closure #1 in closure #1 in static MLDecisionTreeRegressor.resume(_:)(void *a1, char a2, uint64_t a3, void (*a4)(void *), uint64_t a5)
{
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Result<MLDecisionTreeRegressor, Error>);
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v10);
  uint64_t v12 = &v24[-((v11 + 15) & 0xFFFFFFFFFFFFFFF0) - 8];
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for TaskPriority?);
  uint64_t v14 = OUTLINED_FUNCTION_17(v13);
  MEMORY[0x270FA5388](v14);
  OUTLINED_FUNCTION_3_0();
  uint64_t v17 = v16 - v15;
  if (a2)
  {
    *uint64_t v12 = a1;
    swift_storeEnumTagMultiPayload();
    id v22 = a1;
    a4(v12);
    return outlined destroy of URL?((uint64_t)v12, &demangling cache variable for type metadata for Result<MLDecisionTreeRegressor, Error>);
  }
  else
  {
    outlined init with copy of TrainingSessionDelegate(a3 + direct field offset for MLTrainingSession.delegate, (uint64_t)v24);
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for TrainingSessionDelegate);
    type metadata accessor for TreeRegressorTrainingSessionDelegate();
    swift_dynamicCast();
    uint64_t v18 = v23;
    uint64_t v19 = type metadata accessor for TaskPriority();
    __swift_storeEnumTagSinglePayload(v17, 1, 1, v19);
    uint64_t v20 = (void *)swift_allocObject();
    v20[2] = 0;
    v20[3] = 0;
    v20[4] = v18;
    v20[5] = a4;
    v20[6] = a5;
    swift_retain();
    _sScTss5NeverORs_rlE8priority9operationScTyxABGScPSg_xyYaYAcntcfCyt_Tgm5(v17, (uint64_t)&async function pointer to partial apply for closure #1 in static MLDecisionTreeRegressor.handleResult(_:session:fulfill:), (uint64_t)v20);
    return swift_release();
  }
}

uint64_t closure #1 in static MLDecisionTreeRegressor.handleResult(_:session:fulfill:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  v6[3] = a5;
  v6[4] = a6;
  v6[2] = a4;
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Result<MLDecisionTreeRegressor, Error>);
  v6[5] = swift_task_alloc();
  return MEMORY[0x270FA2498](closure #1 in static MLDecisionTreeRegressor.handleResult(_:session:fulfill:), 0, 0);
}

uint64_t closure #1 in static MLDecisionTreeRegressor.handleResult(_:session:fulfill:)()
{
  OUTLINED_FUNCTION_11();
  uint64_t v3 = (uint64_t (__cdecl *)())((char *)&async function pointer to specialized Result<>.init(catching:)
                             + async function pointer to specialized Result<>.init(catching:));
  swift_retain();
  uint64_t v1 = (void *)swift_task_alloc();
  *(void *)(v0 + 48) = v1;
  void *v1 = v0;
  v1[1] = closure #1 in static MLDecisionTreeRegressor.handleResult(_:session:fulfill:);
  return v3();
}

{
  uint64_t *v0;
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v7;

  OUTLINED_FUNCTION_11();
  OUTLINED_FUNCTION_2();
  uint64_t v1 = *v0;
  OUTLINED_FUNCTION_6();
  *uint64_t v2 = v1;
  swift_task_dealloc();
  OUTLINED_FUNCTION_14();
  return MEMORY[0x270FA2498](v3, v4, v5);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t (*v2)(void);
  uint64_t v4;

  OUTLINED_FUNCTION_11();
  uint64_t v1 = *(void *)(v0 + 40);
  (*(void (**)(uint64_t))(v0 + 24))(v1);
  outlined destroy of URL?(v1, &demangling cache variable for type metadata for Result<MLDecisionTreeRegressor, Error>);
  swift_task_dealloc();
  OUTLINED_FUNCTION_30();
  return v2();
}

uint64_t MLDecisionTreeRegressor.init(delegate:)()
{
  OUTLINED_FUNCTION_11();
  v0[29] = v1;
  v0[30] = v2;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for TreeRegressorModel?);
  OUTLINED_FUNCTION_17(v3);
  v0[31] = OUTLINED_FUNCTION_5();
  uint64_t v4 = type metadata accessor for MLDecisionTreeRegressor();
  v0[32] = v4;
  OUTLINED_FUNCTION_17(v4);
  v0[33] = OUTLINED_FUNCTION_5();
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLDecisionTreeRegressor.ModelParameters.ValidationData?);
  OUTLINED_FUNCTION_17(v5);
  v0[34] = OUTLINED_FUNCTION_5();
  uint64_t v6 = type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData();
  v0[35] = v6;
  OUTLINED_FUNCTION_17(v6);
  v0[36] = OUTLINED_FUNCTION_5();
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
  OUTLINED_FUNCTION_17(v7);
  v0[37] = OUTLINED_FUNCTION_5();
  uint64_t v8 = type metadata accessor for BoostedTreeConfiguration();
  v0[38] = v8;
  OUTLINED_FUNCTION_1(v8);
  v0[39] = v9;
  v0[40] = OUTLINED_FUNCTION_5();
  uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?);
  OUTLINED_FUNCTION_17(v10);
  v0[41] = OUTLINED_FUNCTION_5();
  uint64_t v11 = type metadata accessor for PersistentParametersForTreeBasedMethods();
  v0[42] = v11;
  OUTLINED_FUNCTION_17(v11);
  v0[43] = OUTLINED_FUNCTION_5();
  OUTLINED_FUNCTION_14();
  return MEMORY[0x270FA2498](v12, v13, v14);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t result;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t *boxed_opaque_existential_0;
  uint64_t v24;
  uint64_t *v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t v30;
  void *v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v34;
  uint64_t v35;
  uint64_t *v36;
  uint64_t v37;
  uint64_t v38;

  uint64_t v1 = *(void *)(v0 + 328);
  uint64_t v2 = *(void *)(v0 + 336);
  uint64_t v3 = *(void *)(v0 + 240) + OBJC_IVAR____TtC8CreateML36TreeRegressorTrainingSessionDelegate_trainingParameters;
  swift_beginAccess();
  outlined init with copy of URL?(v3, v1, &demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?);
  uint64_t result = __swift_getEnumTagSinglePayload(v1, 1, v2);
  if (result == 1)
  {
    __break(1u);
LABEL_10:
    __break(1u);
    return result;
  }
  uint64_t v5 = *(void *)(v0 + 336);
  uint64_t v6 = *(void *)(v0 + 344);
  uint64_t v36 = (uint64_t *)(v0 + 144);
  uint64_t v7 = *(void *)(v0 + 320);
  uint64_t v8 = *(void *)(v0 + 304);
  uint64_t v9 = *(void *)(v0 + 312);
  uint64_t v10 = *(void *)(v0 + 296);
  uint64_t v11 = *(void *)(v0 + 272);
  char v34 = *(void *)(v0 + 280);
  _s8CreateML18TreeRegressorModelVWObTm_0(*(void *)(v0 + 328), v6, (void (*)(void))type metadata accessor for PersistentParametersForTreeBasedMethods);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v9 + 16))(v7, v6 + *(int *)(v5 + 32), v8);
  outlined init with copy of URL?(v6 + *(int *)(v5 + 20), v10, &demangling cache variable for type metadata for DataFrame?);
  *(_OWORD *)(v0 + 16) = 0u;
  *(_OWORD *)(v0 + 32) = 0u;
  uint64_t v37 = v0 + 16;
  *(void *)(v0 + 48) = BoostedTreeConfiguration.maximumDepth.getter();
  BoostedTreeConfiguration.minimumLossReduction.getter();
  *(void *)(v0 + 56) = v12;
  BoostedTreeConfiguration.minimumChildWeight.getter();
  *(void *)(v0 + 64) = v13;
  *(void *)(v0 + 72) = BoostedTreeConfiguration.randomSeed.getter();
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lF11TabularData0D5FrameV_s5NeverO8CreateML23MLDecisionTreeRegressorV15ModelParametersV010ValidationD0OTg503_s8g4ML23ijk3V15lm75V13configuration10validationAE0A12MLComponents07BoostedD13ConfigurationV_11c7Data0N5e12VSgtcfcAE010N21N0OAMcAPmcfu_ApMcfu0_AOXMtTf1ncn_n(v10, v11);
  if (__swift_getEnumTagSinglePayload(v11, 1, v34) == 1)
  {
    uint64_t v14 = *(void *)(v0 + 272);
    swift_storeEnumTagMultiPayload();
    outlined destroy of URL?(v14, &demangling cache variable for type metadata for MLDecisionTreeRegressor.ModelParameters.ValidationData?);
  }
  else
  {
    _s8CreateML18TreeRegressorModelVWObTm_0(*(void *)(v0 + 272), *(void *)(v0 + 288), (void (*)(void))type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData);
  }
  uint64_t v15 = *(void *)(v0 + 336);
  uint64_t v16 = *(void *)(v0 + 344);
  uint64_t v18 = *(void *)(v0 + 312);
  uint64_t v17 = *(void *)(v0 + 320);
  uint64_t v20 = *(void *)(v0 + 296);
  uint64_t v19 = *(void *)(v0 + 304);
  uint64_t v21 = *(void *)(v0 + 288);
  id v22 = *(void *)(v0 + 248);
  uint64_t v35 = *(void *)(v0 + 240);
  *(void *)(v0 + 168) = *(void *)(v0 + 280);
  boxed_opaque_existential_0 = __swift_allocate_boxed_opaque_existential_0(v36);
  _s8CreateML18TreeRegressorModelVWObTm_0(v21, (uint64_t)boxed_opaque_existential_0, (void (*)(void))type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData);
  outlined assign with take of Any?((uint64_t)v36, v37);
  outlined destroy of URL?(v20, &demangling cache variable for type metadata for DataFrame?);
  (*(void (**)(uint64_t, uint64_t))(v18 + 8))(v17, v19);
  uint64_t v24 = *(int *)(v15 + 28);
  uint64_t v25 = (uint64_t *)(v16 + *(int *)(v15 + 24));
  uint64_t v27 = *v25;
  uint64_t v26 = v25[1];
  uint64_t v28 = *(void *)(v16 + v24);
  uint64_t v29 = v35 + OBJC_IVAR____TtC8CreateML36TreeRegressorTrainingSessionDelegate_model;
  swift_beginAccess();
  outlined init with copy of URL?(v29, v22, &demangling cache variable for type metadata for TreeRegressorModel?);
  uint64_t v30 = type metadata accessor for TreeRegressorModel();
  uint64_t result = __swift_getEnumTagSinglePayload(v22, 1, v30);
  if (result == 1) {
    goto LABEL_10;
  }
  outlined init with copy of MLDecisionTreeRegressor.ModelParameters(v37, v0 + 80);
  swift_bridgeObjectRetain();
  swift_bridgeObjectRetain();
  uint64_t v31 = (void *)swift_task_alloc();
  *(void *)(v0 + 352) = v31;
  *uint64_t v31 = v0;
  v31[1] = MLDecisionTreeRegressor.init(delegate:);
  uint64_t v32 = *(void *)(v0 + 264);
  uint64_t v33 = *(void *)(v0 + 248);
  return MLDecisionTreeRegressor.init(_:targetColumn:featureColumns:parameters:)(v32, v33, v27, v26, v28, v0 + 80);
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  void *v3;
  uint64_t v4;
  void *v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v11;

  OUTLINED_FUNCTION_11();
  OUTLINED_FUNCTION_2();
  OUTLINED_FUNCTION_7();
  *uint64_t v3 = v2;
  uint64_t v4 = *v1;
  OUTLINED_FUNCTION_6();
  *uint64_t v5 = v4;
  *(void *)(v6 + 360) = v0;
  swift_task_dealloc();
  OUTLINED_FUNCTION_14();
  return MEMORY[0x270FA2498](v7, v8, v9);
}

{
  void *v0;
  uint64_t v1;
  uint64_t result;
  uint64_t v3;
  int v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  char v9;
  uint64_t v10;
  id v11;
  uint64_t v12;
  uint64_t v13;
  void *v14;
  int v15;
  uint64_t v16;
  uint64_t (*v17)(void);
  uint64_t v18;

  uint64_t v1 = v0[30];
  uint64_t result = _s8CreateML18TreeRegressorModelVWObTm_0(v0[33], v0[29], (void (*)(void))type metadata accessor for MLDecisionTreeRegressor);
  uint64_t v3 = v1 + OBJC_IVAR____TtC8CreateML36TreeRegressorTrainingSessionDelegate_trainingMetrics;
  uint64_t v4 = *(unsigned __int8 *)(v1 + OBJC_IVAR____TtC8CreateML36TreeRegressorTrainingSessionDelegate_trainingMetrics + 16);
  if (v4 == 255)
  {
    __break(1u);
  }
  else
  {
    uint64_t v5 = v0[43];
    uint64_t v6 = v0[32];
    uint64_t v8 = v0[29];
    uint64_t v7 = v0[30];
    uint64_t v9 = v4 & 1;
    uint64_t v11 = *(id *)v3;
    uint64_t v10 = *(void *)(v3 + 8);
    outlined copy of Result<_RegressorMetrics, Error>(*(id *)v3, v10, v4 & 1);
    outlined destroy of MLDecisionTreeRegressor.ModelParameters((uint64_t)(v0 + 2));
    outlined destroy of MLDecisionTreeRegressor.ModelParameters.ValidationData(v5, (void (*)(void))type metadata accessor for PersistentParametersForTreeBasedMethods);
    uint64_t v12 = v8 + *(int *)(v6 + 36);
    outlined consume of Result<_RegressorMetrics, Error>(*(id *)v12, *(void *)(v12 + 8), *(unsigned char *)(v12 + 16));
    *(void *)uint64_t v12 = v11;
    *(void *)(v12 + 8) = v10;
    *(unsigned char *)(v12 + 16) = v9;
    uint64_t v14 = *(void **)(v7 + OBJC_IVAR____TtC8CreateML36TreeRegressorTrainingSessionDelegate_validationMetrics);
    uint64_t v13 = *(void *)(v7 + OBJC_IVAR____TtC8CreateML36TreeRegressorTrainingSessionDelegate_validationMetrics + 8);
    uint64_t v15 = *(unsigned __int8 *)(v7
                             + OBJC_IVAR____TtC8CreateML36TreeRegressorTrainingSessionDelegate_validationMetrics
                             + 16);
    outlined copy of MLRegressorMetrics?(v14, v13, *(unsigned char *)(v7 + OBJC_IVAR____TtC8CreateML36TreeRegressorTrainingSessionDelegate_validationMetrics + 16));
    swift_release();
    if (v15 != 255)
    {
      uint64_t v16 = v0[29] + *(int *)(v0[32] + 40);
      outlined consume of Result<_RegressorMetrics, Error>(*(id *)v16, *(void *)(v16 + 8), *(unsigned char *)(v16 + 16));
      *(void *)uint64_t v16 = v14;
      *(void *)(v16 + 8) = v13;
      *(unsigned char *)(v16 + 16) = v15 & 1;
    }
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    uint64_t v17 = (uint64_t (*)(void))v0[1];
    return v17();
  }
  return result;
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t (*v2)(void);
  uint64_t v4;

  uint64_t v1 = *(void *)(v0 + 344);
  swift_release();
  outlined destroy of MLDecisionTreeRegressor.ModelParameters(v0 + 16);
  outlined destroy of MLDecisionTreeRegressor.ModelParameters.ValidationData(v1, (void (*)(void))type metadata accessor for PersistentParametersForTreeBasedMethods);
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  OUTLINED_FUNCTION_30();
  return v2();
}

void MLDecisionTreeRegressor.predictions(from:)()
{
  uint64_t v2 = type metadata accessor for DataFrame();
  OUTLINED_FUNCTION_0();
  uint64_t v4 = v3;
  MEMORY[0x270FA5388](v5);
  OUTLINED_FUNCTION_31_1();
  type metadata accessor for MLDecisionTreeRegressor();
  OUTLINED_FUNCTION_39_1();
  DataFrame.validateContainsColumns(_:context:)(v6, v7);
  if (!v8)
  {
    OUTLINED_FUNCTION_14();
    TreeRegressorModel.applied(to:eventHandler:)();
    MEMORY[0x22A672220](*v0, v0[1]);
    (*(void (**)(uint64_t, uint64_t))(v4 + 8))(v1, v2);
  }
}

uint64_t MLDecisionTreeRegressor.predictions(from:)@<X0>(uint64_t a1@<X0>, uint64_t a2@<X8>)
{
  type metadata accessor for DataFrame();
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v7);
  OUTLINED_FUNCTION_31_1();
  uint64_t v8 = type metadata accessor for AnyColumn();
  uint64_t v9 = OUTLINED_FUNCTION_17(v8);
  MEMORY[0x270FA5388](v9);
  OUTLINED_FUNCTION_27_7();
  char v10 = *(unsigned char *)(a1 + 8);
  id v14 = *(id *)a1;
  char v15 = v10;
  outlined copy of Result<_DataTable, Error>(v14, v10);
  DataFrame.init(_:)((uint64_t)&v14, v3);
  MLDecisionTreeRegressor.predictions(from:)();
  uint64_t v11 = OUTLINED_FUNCTION_47_0();
  if (v2) {
    return v12(v11);
  }
  v12(v11);
  return MLUntypedColumn.init(_:convertArraysToShapedArrays:)(v4, 1, a2);
}

void MLDecisionTreeRegressor.evaluation(on:)()
{
  uint64_t v2 = OUTLINED_FUNCTION_40_4();
  OUTLINED_FUNCTION_39_1();
  DataFrame.validateContainsColumns(_:context:)(v3, v4);
  if (v5) {
    goto LABEL_4;
  }
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<String>);
  uint64_t inited = swift_initStackObject();
  *(_OWORD *)(inited + 16) = xmmword_2272CB370;
  uint64_t v7 = (void *)(v1 + *(int *)(v2 + 24));
  uint64_t v8 = v7[1];
  *(void *)(inited + 32) = *v7;
  *(void *)(inited + 40) = v8;
  swift_bridgeObjectRetain();
  v9._uint64_t countAndFlagsBits = 0x6C6562614CLL;
  v9._uint64_t object = (void *)0xE500000000000000;
  DataFrame.validateContainsColumns(_:context:)((Swift::OpaquePointer)inited, v9);
  swift_setDeallocating();
  specialized _ContiguousArrayStorage.__deallocating_deinit();
  if (v5)
  {
LABEL_4:
    *(void *)uint64_t v0 = v5;
    *(void *)(v0 + 8) = 0;
    *(unsigned char *)(v0 + 16) = 1;
  }
  else
  {
    TreeRegressorModel.computeMetrics(on:)(v0);
  }
}

uint64_t MLDecisionTreeRegressor.evaluation(on:)(uint64_t a1)
{
  uint64_t v2 = type metadata accessor for DataFrame();
  OUTLINED_FUNCTION_0();
  uint64_t v4 = v3;
  MEMORY[0x270FA5388](v5);
  OUTLINED_FUNCTION_3_0();
  uint64_t v8 = v7 - v6;
  char v9 = *(unsigned char *)(a1 + 8);
  id v11 = *(id *)a1;
  char v12 = v9;
  outlined copy of Result<_DataTable, Error>(v11, v9);
  DataFrame.init(_:)((uint64_t)&v11, v8);
  MLDecisionTreeRegressor.evaluation(on:)();
  return (*(uint64_t (**)(uint64_t, uint64_t))(v4 + 8))(v8, v2);
}

void MLDecisionTreeRegressor.write(to:metadata:)()
{
  OUTLINED_FUNCTION_9_0();
  uint64_t v4 = v3;
  uint64_t v37 = v5;
  uint64_t v6 = type metadata accessor for TreeRegressorModel();
  uint64_t v7 = OUTLINED_FUNCTION_17(v6);
  MEMORY[0x270FA5388](v7);
  OUTLINED_FUNCTION_33_0();
  uint64_t v36 = v8;
  uint64_t v31 = type metadata accessor for Model();
  OUTLINED_FUNCTION_0();
  uint64_t v35 = v9;
  MEMORY[0x270FA5388](v10);
  OUTLINED_FUNCTION_30_2();
  type metadata accessor for URL();
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v11);
  OUTLINED_FUNCTION_10();
  uint64_t v32 = v4[1];
  unint64_t v12 = v4[3];
  unint64_t v33 = v4[2];
  uint64_t v34 = *v4;
  uint64_t v13 = v4[4];
  uint64_t v14 = v4[5];
  uint64_t v15 = v4[6];
  unint64_t v16 = v4[7];
  uint64_t v17 = v4[8];
  static _ValidationUtilities.validateWriteLocation(atURL:defaultName:fileExtension:)(v37, 0xD000000000000015, (void *)0x80000002272D6640, 0x6C65646F6D6C6DLL, (void *)0xE700000000000000, v0);
  if (!v2)
  {
    unint64_t v29 = v16;
    uint64_t v30 = v13;
    _s8CreateML27MLTrainingSessionParametersVWOcTm_1(v1, v36, (void (*)(void))type metadata accessor for TreeRegressorModel);
    if (v32)
    {
      uint64_t v18 = v34;
      uint64_t v19 = v34;
      uint64_t v20 = v32;
      unint64_t v21 = v33;
      uint64_t v22 = v30;
      uint64_t v23 = v14;
      uint64_t v24 = v15;
      unint64_t v25 = v29;
    }
    else
    {
      uint64_t v26 = NSFullUserName();
      uint64_t v19 = static String._unconditionallyBridgeFromObjectiveC(_:)();
      uint64_t v20 = v27;

      uint64_t v22 = 0;
      uint64_t v23 = 0;
      uint64_t v17 = 0;
      unint64_t v21 = 0xD000000000000033;
      unint64_t v12 = 0x80000002272D4DC0;
      unint64_t v25 = 0xE100000000000000;
      uint64_t v24 = 49;
      uint64_t v18 = v34;
    }
    v38[0] = v19;
    v38[1] = v20;
    v38[2] = v21;
    v38[3] = v12;
    v38[4] = v22;
    v38[5] = v23;
    v38[6] = v24;
    v38[7] = v25;
    v38[8] = v17;
    outlined copy of MLModelMetadata?(v18, v32);
    specialized CoreMLExportable.export(metadata:)(v38);
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    outlined destroy of MLDecisionTreeRegressor.ModelParameters.ValidationData(v36, (void (*)(void))type metadata accessor for TreeRegressorModel);
    Model.write(to:)();
    (*(void (**)(uint64_t, uint64_t))(v35 + 8))(v1, v31);
    OUTLINED_FUNCTION_25_0();
    v28();
  }
  OUTLINED_FUNCTION_8_1();
}

void MLDecisionTreeRegressor.write(toFile:metadata:)()
{
  OUTLINED_FUNCTION_9_0();
  uint64_t v1 = type metadata accessor for URL.DirectoryHint();
  OUTLINED_FUNCTION_0();
  uint64_t v3 = v2;
  MEMORY[0x270FA5388](v4);
  OUTLINED_FUNCTION_3_0();
  uint64_t v7 = v6 - v5;
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  uint64_t v9 = OUTLINED_FUNCTION_17(v8);
  MEMORY[0x270FA5388](v9);
  OUTLINED_FUNCTION_10();
  uint64_t v10 = type metadata accessor for URL();
  OUTLINED_FUNCTION_0();
  uint64_t v12 = v11;
  MEMORY[0x270FA5388](v13);
  OUTLINED_FUNCTION_3_0();
  uint64_t v16 = v15 - v14;
  __swift_storeEnumTagSinglePayload(v0, 1, 1, v10);
  (*(void (**)(uint64_t, void, uint64_t))(v3 + 104))(v7, *MEMORY[0x263F06E50], v1);
  swift_bridgeObjectRetain();
  URL.init(filePath:directoryHint:relativeTo:)();
  MLDecisionTreeRegressor.write(to:metadata:)();
  (*(void (**)(uint64_t, uint64_t))(v12 + 8))(v16, v10);
  OUTLINED_FUNCTION_8_1();
}

unint64_t MLDecisionTreeRegressor.description.getter()
{
  uint64_t v1 = type metadata accessor for MLDecisionTreeRegressor();
  uint64_t v2 = MLDecisionTreeRegressor.ModelParameters.description.getter();
  uint64_t v4 = v3;
  unint64_t v5 = MLRegressorMetrics.description.getter();
  uint64_t v7 = v6;
  char v8 = *(unsigned char *)(v0 + *(int *)(v1 + 40) + 16);
  unint64_t v9 = MLRegressorMetrics.description.getter();
  uint64_t v11 = v10;
  v12._uint64_t countAndFlagsBits = v2;
  v12._uint64_t object = v4;
  String.append(_:)(v12);
  v13._uint64_t countAndFlagsBits = v5;
  v13._uint64_t object = v7;
  String.append(_:)(v13);
  v14._uint64_t countAndFlagsBits = 0xD00000000000001ELL;
  v14._uint64_t object = (void *)0x80000002272D3FE0;
  String.append(_:)(v14);
  swift_bridgeObjectRelease();
  if ((v8 & 1) == 0)
  {
    v15._uint64_t countAndFlagsBits = v9;
    v15._uint64_t object = v11;
    String.append(_:)(v15);
    v16._uint64_t countAndFlagsBits = 0xD000000000000020;
    v16._uint64_t object = (void *)0x80000002272D4000;
    String.append(_:)(v16);
    swift_bridgeObjectRelease();
  }
  swift_bridgeObjectRelease();
  swift_bridgeObjectRelease();
  swift_bridgeObjectRelease();
  return 0xD000000000000022;
}

NSAttributedString MLDecisionTreeRegressor.playgroundDescription.getter@<X0>(NSAttributedString *a1@<X8>)
{
  unint64_t v2 = type metadata accessor for NSAttributedString();
  v3._uint64_t countAndFlagsBits = MLDecisionTreeRegressor.description.getter();
  result.super.Class isa = NSAttributedString.__allocating_init(string:)(v3).super.isa;
  a1[3].super.Class isa = (Class)v2;
  a1->super.Class isa = result.super.isa;
  return result;
}

uint64_t partial apply for closure #1 in MLDecisionTreeRegressor.init(checkpoint:)()
{
  OUTLINED_FUNCTION_11();
  uint64_t v1 = v0;
  uint64_t v2 = type metadata accessor for TreeRegressorModel();
  OUTLINED_FUNCTION_39_0(v2);
  uint64_t v3 = swift_task_alloc();
  uint64_t v4 = (void *)OUTLINED_FUNCTION_7_1(v3);
  *uint64_t v4 = v5;
  v4[1] = protocol witness for SupervisedEstimator.fitted<A, B>(to:validateOn:eventHandler:) in conformance MLImageClassifier.Classifier;
  return closure #1 in MLRandomForestRegressor.init(checkpoint:)(v1);
}

uint64_t _s8CreateML27MLTrainingSessionParametersVWOcTm_1(uint64_t a1, uint64_t a2, void (*a3)(void))
{
  a3(0);
  OUTLINED_FUNCTION_8();
  uint64_t v4 = OUTLINED_FUNCTION_111();
  v5(v4);
  return a2;
}

id sub_2270E7500@<X0>(void *a1@<X8>)
{
  id result = MLDecisionTreeRegressor.model.getter();
  *a1 = result;
  return result;
}

void *initializeBufferWithCopyOfBuffer for MLDecisionTreeRegressor(void *a1, void *a2, int *a3)
{
  int v5 = *(_DWORD *)(*((void *)a3 - 1) + 80);
  if ((v5 & 0x20000) != 0)
  {
    uint64_t v12 = *a2;
    *a1 = *a2;
    a1 = (void *)(v12 + ((v5 + 16) & ~(unint64_t)v5));
    swift_retain();
  }
  else
  {
    uint64_t v7 = a2[1];
    *a1 = *a2;
    a1[1] = v7;
    unint64_t v9 = a2 + 2;
    uint64_t v8 = a2[2];
    swift_bridgeObjectRetain();
    if (v8)
    {
      uint64_t v10 = a2[3];
      uint64_t v11 = a2[4];
      a1[2] = v8;
      a1[3] = v10;
      a1[4] = v11;
      swift_bridgeObjectRetain();
      swift_bridgeObjectRetain();
    }
    else
    {
      *((_OWORD *)a1 + 1) = *v9;
      a1[4] = a2[4];
    }
    uint64_t v13 = *(int *)(type metadata accessor for TreeRegressorModel() + 24);
    Swift::String v14 = (char *)a1 + v13;
    Swift::String v15 = (char *)a2 + v13;
    uint64_t v16 = type metadata accessor for BaseTreeRegressorModel();
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v16 - 8) + 16))(v14, v15, v16);
    uint64_t v17 = a3[5];
    uint64_t v18 = a3[6];
    uint64_t v19 = *(void **)((char *)a2 + v17);
    *(void *)((char *)a1 + v17) = v19;
    uint64_t v20 = (void *)((char *)a1 + v18);
    unint64_t v21 = (void *)((char *)a2 + v18);
    uint64_t v22 = *v21;
    uint64_t v23 = v21[1];
    uint64_t v24 = a3[7];
    uint64_t v25 = a3[8];
    uint64_t v26 = *(void *)((char *)a2 + v24);
    *uint64_t v20 = v22;
    v20[1] = v23;
    *(void *)((char *)a1 + v24) = v26;
    uint64_t v27 = (char *)a1 + v25;
    uint64_t v28 = (_OWORD *)((char *)a2 + v25);
    uint64_t v29 = *(void *)((char *)a2 + v25 + 24);
    id v30 = v19;
    swift_bridgeObjectRetain();
    swift_bridgeObjectRetain();
    if (v29)
    {
      *((void *)v27 + 3) = v29;
      (**(void (***)(char *, _OWORD *, uint64_t))(v29 - 8))(v27, v28, v29);
    }
    else
    {
      long long v31 = v28[1];
      *(_OWORD *)uint64_t v27 = *v28;
      *((_OWORD *)v27 + 1) = v31;
    }
    long long v32 = v28[3];
    *((_OWORD *)v27 + 2) = v28[2];
    *((_OWORD *)v27 + 3) = v32;
    uint64_t v33 = a3[9];
    uint64_t v34 = (char *)a1 + v33;
    uint64_t v35 = (char *)a2 + v33;
    id v36 = *(id *)v35;
    uint64_t v37 = *((void *)v35 + 1);
    char v38 = v35[16];
    outlined copy of Result<_RegressorMetrics, Error>(*(id *)v35, v37, v38);
    *(void *)uint64_t v34 = v36;
    *((void *)v34 + 1) = v37;
    v34[16] = v38;
    uint64_t v39 = a3[10];
    uint64_t v40 = (char *)a1 + v39;
    uint64_t v41 = (char *)a2 + v39;
    id v42 = *(id *)v41;
    uint64_t v43 = *((void *)v41 + 1);
    LOBYTE(v36) = v41[16];
    outlined copy of Result<_RegressorMetrics, Error>(*(id *)v41, v43, (char)v36);
    *(void *)uint64_t v40 = v42;
    *((void *)v40 + 1) = v43;
    v40[16] = (char)v36;
  }
  return a1;
}

void *initializeWithCopy for MLDecisionTreeRegressor(void *a1, void *a2, int *a3)
{
  uint64_t v6 = a2[1];
  *a1 = *a2;
  a1[1] = v6;
  uint64_t v8 = a2 + 2;
  uint64_t v7 = a2[2];
  swift_bridgeObjectRetain();
  if (v7)
  {
    uint64_t v9 = a2[3];
    uint64_t v10 = a2[4];
    a1[2] = v7;
    a1[3] = v9;
    a1[4] = v10;
    swift_bridgeObjectRetain();
    swift_bridgeObjectRetain();
  }
  else
  {
    *((_OWORD *)a1 + 1) = *(_OWORD *)v8;
    a1[4] = v8[2];
  }
  uint64_t v11 = *(int *)(type metadata accessor for TreeRegressorModel() + 24);
  uint64_t v12 = (char *)a1 + v11;
  uint64_t v13 = (char *)a2 + v11;
  uint64_t v14 = type metadata accessor for BaseTreeRegressorModel();
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v14 - 8) + 16))(v12, v13, v14);
  uint64_t v15 = a3[5];
  uint64_t v16 = a3[6];
  uint64_t v17 = *(void **)((char *)a2 + v15);
  *(void *)((char *)a1 + v15) = v17;
  uint64_t v18 = (void *)((char *)a1 + v16);
  uint64_t v19 = (void *)((char *)a2 + v16);
  uint64_t v20 = *v19;
  uint64_t v21 = v19[1];
  uint64_t v22 = a3[7];
  uint64_t v23 = a3[8];
  uint64_t v24 = *(void *)((char *)a2 + v22);
  *uint64_t v18 = v20;
  v18[1] = v21;
  *(void *)((char *)a1 + v22) = v24;
  uint64_t v25 = (char *)a1 + v23;
  uint64_t v26 = (_OWORD *)((char *)a2 + v23);
  uint64_t v27 = *(void *)((char *)a2 + v23 + 24);
  id v28 = v17;
  swift_bridgeObjectRetain();
  swift_bridgeObjectRetain();
  if (v27)
  {
    *((void *)v25 + 3) = v27;
    (**(void (***)(char *, _OWORD *, uint64_t))(v27 - 8))(v25, v26, v27);
  }
  else
  {
    long long v29 = v26[1];
    *(_OWORD *)uint64_t v25 = *v26;
    *((_OWORD *)v25 + 1) = v29;
  }
  long long v30 = v26[3];
  *((_OWORD *)v25 + 2) = v26[2];
  *((_OWORD *)v25 + 3) = v30;
  uint64_t v31 = a3[9];
  long long v32 = (char *)a1 + v31;
  uint64_t v33 = (char *)a2 + v31;
  id v34 = *(id *)v33;
  uint64_t v35 = *((void *)v33 + 1);
  char v36 = v33[16];
  outlined copy of Result<_RegressorMetrics, Error>(*(id *)v33, v35, v36);
  *(void *)long long v32 = v34;
  *((void *)v32 + 1) = v35;
  v32[16] = v36;
  uint64_t v37 = a3[10];
  char v38 = (char *)a1 + v37;
  uint64_t v39 = (char *)a2 + v37;
  id v40 = *(id *)v39;
  uint64_t v41 = *((void *)v39 + 1);
  LOBYTE(v34) = v39[16];
  outlined copy of Result<_RegressorMetrics, Error>(*(id *)v39, v41, (char)v34);
  *(void *)char v38 = v40;
  *((void *)v38 + 1) = v41;
  v38[16] = (char)v34;
  return a1;
}

void *assignWithCopy for MLDecisionTreeRegressor(void *a1, void *a2, int *a3)
{
  *a1 = *a2;
  a1[1] = a2[1];
  swift_bridgeObjectRetain();
  swift_bridgeObjectRelease();
  uint64_t v6 = a1 + 2;
  uint64_t v8 = a2 + 2;
  uint64_t v7 = a2[2];
  if (a1[2])
  {
    if (v7)
    {
      a1[2] = v7;
      swift_bridgeObjectRetain();
      swift_bridgeObjectRelease();
      a1[3] = a2[3];
      a1[4] = a2[4];
      swift_bridgeObjectRetain();
      swift_bridgeObjectRelease();
    }
    else
    {
      outlined destroy of URL?((uint64_t)(a1 + 2), &demangling cache variable for type metadata for FeatureVectorizer<Float>.Transformer);
      uint64_t v9 = a2[4];
      *uint64_t v6 = *v8;
      a1[4] = v9;
    }
  }
  else if (v7)
  {
    a1[2] = v7;
    a1[3] = a2[3];
    a1[4] = a2[4];
    swift_bridgeObjectRetain();
    swift_bridgeObjectRetain();
  }
  else
  {
    long long v10 = *v8;
    a1[4] = a2[4];
    *uint64_t v6 = v10;
  }
  uint64_t v11 = *(int *)(type metadata accessor for TreeRegressorModel() + 24);
  uint64_t v12 = (char *)a1 + v11;
  uint64_t v13 = (char *)a2 + v11;
  uint64_t v14 = type metadata accessor for BaseTreeRegressorModel();
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v14 - 8) + 24))(v12, v13, v14);
  uint64_t v15 = a3[5];
  uint64_t v16 = *(void **)((char *)a2 + v15);
  uint64_t v17 = *(void **)((char *)a1 + v15);
  *(void *)((char *)a1 + v15) = v16;
  id v18 = v16;

  uint64_t v19 = a3[6];
  uint64_t v20 = (void *)((char *)a1 + v19);
  uint64_t v21 = (void *)((char *)a2 + v19);
  *uint64_t v20 = *v21;
  v20[1] = v21[1];
  swift_bridgeObjectRetain();
  swift_bridgeObjectRelease();
  *(void *)((char *)a1 + a3[7]) = *(void *)((char *)a2 + a3[7]);
  swift_bridgeObjectRetain();
  swift_bridgeObjectRelease();
  uint64_t v22 = a3[8];
  uint64_t v23 = (uint64_t)a1 + v22;
  uint64_t v24 = (char *)a2 + v22;
  uint64_t v25 = *(void *)((char *)a2 + v22 + 24);
  if (!*(void *)((char *)a1 + v22 + 24))
  {
    if (v25)
    {
      *(void *)(v23 + 24) = v25;
      (**(void (***)(uint64_t, char *))(v25 - 8))(v23, v24);
      goto LABEL_15;
    }
LABEL_14:
    long long v26 = *((_OWORD *)v24 + 1);
    *(_OWORD *)uint64_t v23 = *(_OWORD *)v24;
    *(_OWORD *)(v23 + 16) = v26;
    goto LABEL_15;
  }
  if (!v25)
  {
    __swift_destroy_boxed_opaque_existential_0(v23);
    goto LABEL_14;
  }
  __swift_assign_boxed_opaque_existential_0((uint64_t *)v23, (uint64_t *)v24);
LABEL_15:
  *(void *)(v23 + 32) = *((void *)v24 + 4);
  *(void *)(v23 + 40) = *((void *)v24 + 5);
  *(void *)(v23 + 48) = *((void *)v24 + 6);
  *(void *)(v23 + 56) = *((void *)v24 + 7);
  uint64_t v27 = a3[9];
  id v28 = (char *)a1 + v27;
  long long v29 = (char *)a2 + v27;
  id v30 = *(id *)v29;
  uint64_t v31 = *((void *)v29 + 1);
  char v32 = v29[16];
  outlined copy of Result<_RegressorMetrics, Error>(*(id *)v29, v31, v32);
  uint64_t v33 = *(void **)v28;
  uint64_t v34 = *((void *)v28 + 1);
  char v35 = v28[16];
  *(void *)id v28 = v30;
  *((void *)v28 + 1) = v31;
  v28[16] = v32;
  outlined consume of Result<_RegressorMetrics, Error>(v33, v34, v35);
  uint64_t v36 = a3[10];
  uint64_t v37 = (char *)a1 + v36;
  char v38 = (char *)a2 + v36;
  id v39 = *(id *)v38;
  uint64_t v40 = *((void *)v38 + 1);
  LOBYTE(v30) = v38[16];
  outlined copy of Result<_RegressorMetrics, Error>(*(id *)v38, v40, (char)v30);
  uint64_t v41 = *(void **)v37;
  uint64_t v42 = *((void *)v37 + 1);
  char v43 = v37[16];
  *(void *)uint64_t v37 = v39;
  *((void *)v37 + 1) = v40;
  v37[16] = (char)v30;
  outlined consume of Result<_RegressorMetrics, Error>(v41, v42, v43);
  return a1;
}

uint64_t initializeWithTake for MLDecisionTreeRegressor(uint64_t a1, uint64_t a2, int *a3)
{
  long long v6 = *(_OWORD *)(a2 + 16);
  *(_OWORD *)a1 = *(_OWORD *)a2;
  *(_OWORD *)(a1 + 16) = v6;
  *(void *)(a1 + 32) = *(void *)(a2 + 32);
  uint64_t v7 = *(int *)(type metadata accessor for TreeRegressorModel() + 24);
  uint64_t v8 = a1 + v7;
  uint64_t v9 = a2 + v7;
  uint64_t v10 = type metadata accessor for BaseTreeRegressorModel();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v10 - 8) + 32))(v8, v9, v10);
  uint64_t v11 = a3[6];
  *(void *)(a1 + a3[5]) = *(void *)(a2 + a3[5]);
  *(_OWORD *)(a1 + v11) = *(_OWORD *)(a2 + v11);
  uint64_t v12 = a3[8];
  *(void *)(a1 + a3[7]) = *(void *)(a2 + a3[7]);
  uint64_t v13 = (_OWORD *)(a1 + v12);
  uint64_t v14 = (_OWORD *)(a2 + v12);
  long long v15 = v14[1];
  *uint64_t v13 = *v14;
  v13[1] = v15;
  long long v16 = v14[3];
  v13[2] = v14[2];
  v13[3] = v16;
  uint64_t v17 = a3[9];
  uint64_t v18 = a3[10];
  uint64_t v19 = a1 + v17;
  uint64_t v20 = a2 + v17;
  *(_OWORD *)uint64_t v19 = *(_OWORD *)v20;
  *(unsigned char *)(v19 + 16) = *(unsigned char *)(v20 + 16);
  uint64_t v21 = a1 + v18;
  uint64_t v22 = a2 + v18;
  *(_OWORD *)uint64_t v21 = *(_OWORD *)v22;
  *(unsigned char *)(v21 + 16) = *(unsigned char *)(v22 + 16);
  return a1;
}

void *assignWithTake for MLDecisionTreeRegressor(void *a1, void *a2, int *a3)
{
  uint64_t v6 = a2[1];
  *a1 = *a2;
  a1[1] = v6;
  swift_bridgeObjectRelease();
  uint64_t v7 = a2[2];
  if (a1[2])
  {
    if (v7)
    {
      a1[2] = v7;
      swift_bridgeObjectRelease();
      uint64_t v8 = a2[4];
      a1[3] = a2[3];
      a1[4] = v8;
      swift_bridgeObjectRelease();
      goto LABEL_6;
    }
    outlined destroy of URL?((uint64_t)(a1 + 2), &demangling cache variable for type metadata for FeatureVectorizer<Float>.Transformer);
  }
  *((_OWORD *)a1 + 1) = *((_OWORD *)a2 + 1);
  a1[4] = a2[4];
LABEL_6:
  uint64_t v9 = *(int *)(type metadata accessor for TreeRegressorModel() + 24);
  uint64_t v10 = (char *)a1 + v9;
  uint64_t v11 = (char *)a2 + v9;
  uint64_t v12 = type metadata accessor for BaseTreeRegressorModel();
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 40))(v10, v11, v12);
  uint64_t v13 = a3[5];
  uint64_t v14 = *(void **)((char *)a1 + v13);
  *(void *)((char *)a1 + v13) = *(void *)((char *)a2 + v13);

  uint64_t v15 = a3[6];
  long long v16 = (void *)((char *)a1 + v15);
  uint64_t v17 = (void *)((char *)a2 + v15);
  uint64_t v19 = *v17;
  uint64_t v18 = v17[1];
  *long long v16 = v19;
  v16[1] = v18;
  swift_bridgeObjectRelease();
  *(void *)((char *)a1 + a3[7]) = *(void *)((char *)a2 + a3[7]);
  swift_bridgeObjectRelease();
  uint64_t v20 = a3[8];
  uint64_t v21 = (char *)a1 + v20;
  if (*(void *)((char *)a1 + v20 + 24)) {
    __swift_destroy_boxed_opaque_existential_0((uint64_t)a1 + v20);
  }
  long long v22 = *(_OWORD *)((char *)a2 + v20 + 16);
  *(_OWORD *)uint64_t v21 = *(_OWORD *)((char *)a2 + v20);
  *((_OWORD *)v21 + 1) = v22;
  *((void *)v21 + 4) = *(void *)((char *)a2 + v20 + 32);
  *(_OWORD *)(v21 + 40) = *(_OWORD *)((char *)a2 + v20 + 40);
  *((void *)v21 + 7) = *(void *)((char *)a2 + v20 + 56);
  uint64_t v23 = a3[9];
  uint64_t v24 = (char *)a1 + v23;
  uint64_t v25 = (char *)a2 + v23;
  char v26 = v25[16];
  uint64_t v27 = *(void **)v24;
  uint64_t v28 = *((void *)v24 + 1);
  char v29 = v24[16];
  *(_OWORD *)uint64_t v24 = *(_OWORD *)v25;
  v24[16] = v26;
  outlined consume of Result<_RegressorMetrics, Error>(v27, v28, v29);
  uint64_t v30 = a3[10];
  uint64_t v31 = (char *)a1 + v30;
  char v32 = (char *)a2 + v30;
  char v33 = v32[16];
  uint64_t v34 = *(void **)v31;
  uint64_t v35 = *((void *)v31 + 1);
  char v36 = v31[16];
  *(_OWORD *)uint64_t v31 = *(_OWORD *)v32;
  v31[16] = v33;
  outlined consume of Result<_RegressorMetrics, Error>(v34, v35, v36);
  return a1;
}

uint64_t getEnumTagSinglePayload for MLDecisionTreeRegressor(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return MEMORY[0x270FA0340](a1, a2, a3, sub_2270E7EBC);
}

uint64_t sub_2270E7EBC(uint64_t a1, uint64_t a2, uint64_t a3)
{
  type metadata accessor for TreeRegressorModel();
  OUTLINED_FUNCTION_6_1();
  if (*(_DWORD *)(v7 + 84) == a2)
  {
    return __swift_getEnumTagSinglePayload(a1, a2, v6);
  }
  else
  {
    unint64_t v9 = *(void *)(a1 + *(int *)(a3 + 20));
    if (v9 >= 0xFFFFFFFF) {
      LODWORD(v9) = -1;
    }
    return (v9 + 1);
  }
}

uint64_t storeEnumTagSinglePayload for MLDecisionTreeRegressor(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return MEMORY[0x270FA0580](a1, a2, a3, a4, sub_2270E7F5C);
}

void sub_2270E7F5C(uint64_t a1, uint64_t a2, int a3, uint64_t a4)
{
  type metadata accessor for TreeRegressorModel();
  OUTLINED_FUNCTION_6_1();
  if (*(_DWORD *)(v9 + 84) == a3)
  {
    __swift_storeEnumTagSinglePayload(a1, a2, a2, v8);
  }
  else
  {
    *(void *)(a1 + *(int *)(a4 + 20)) = (a2 - 1);
  }
}

uint64_t type metadata completion function for MLDecisionTreeRegressor()
{
  uint64_t result = type metadata accessor for TreeRegressorModel();
  if (v1 <= 0x3F)
  {
    swift_initStructMetadata();
    return 0;
  }
  return result;
}

uint64_t sub_2270E80AC()
{
  swift_unknownObjectRelease();
  swift_release();
  swift_release();

  return MEMORY[0x270FA0238](v0, 56, 7);
}

uint64_t partial apply for closure #1 in static MLDecisionTreeRegressor.handleResult(_:session:fulfill:)(uint64_t a1)
{
  uint64_t v3 = v1[2];
  uint64_t v4 = v1[3];
  uint64_t v5 = v1[4];
  uint64_t v6 = v1[5];
  uint64_t v7 = v1[6];
  uint64_t v8 = swift_task_alloc();
  uint64_t v9 = (void *)OUTLINED_FUNCTION_7_1(v8);
  *uint64_t v9 = v10;
  v9[1] = protocol witness for SupervisedEstimator.fitted<A, B>(to:validateOn:eventHandler:) in conformance MLImageClassifier.Classifier;
  return closure #1 in static MLDecisionTreeRegressor.handleResult(_:session:fulfill:)(a1, v3, v4, v5, v6, v7);
}

uint64_t outlined destroy of MLDecisionTreeRegressor.ModelParameters.ValidationData(uint64_t a1, void (*a2)(void))
{
  a2(0);
  OUTLINED_FUNCTION_8();
  OUTLINED_FUNCTION_25_0();
  v3();
  return a1;
}

uint64_t _s8CreateML18TreeRegressorModelVWObTm_0(uint64_t a1, uint64_t a2, void (*a3)(void))
{
  a3(0);
  OUTLINED_FUNCTION_8();
  (*(void (**)(uint64_t, uint64_t))(v5 + 32))(a2, a1);
  return a2;
}

uint64_t OUTLINED_FUNCTION_4_19()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_31_5(uint64_t a1, void (*a2)(void))
{
  uint64_t v4 = *(void *)(v2 - 280);
  return outlined destroy of MLDecisionTreeRegressor.ModelParameters.ValidationData(v4, a2);
}

uint64_t OUTLINED_FUNCTION_39_6()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_40_4()
{
  return type metadata accessor for MLDecisionTreeRegressor();
}

uint64_t OUTLINED_FUNCTION_44_1()
{
  return type metadata accessor for MLDecisionTreeRegressor();
}

uint64_t SortedSet.init(_:)()
{
  type metadata accessor for Set();
  swift_getWitnessTable();
  Array.init<A>(_:)();
  type metadata accessor for Array();
  swift_getWitnessTable();
  uint64_t v0 = Sequence.sorted(by:)();
  swift_bridgeObjectRelease();
  swift_bridgeObjectRetain();
  swift_getWitnessTable();
  RandomAccessCollection<>.indices.getter();
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Range<Int>);
  lazy protocol witness table accessor for type Int and conformance Int();
  swift_getWitnessTable();
  zip<A, B>(_:_:)();
  swift_bridgeObjectRelease();
  type metadata accessor for Zip2Sequence();
  swift_getWitnessTable();
  Dictionary.init<A>(uniqueKeysWithValues:)();
  return v0;
}

uint64_t partial apply for implicit closure #1 in SortedSet.init(_:)()
{
  return dispatch thunk of static Comparable.< infix(_:_:)() & 1;
}

uint64_t destroy for SortedSet()
{
  swift_bridgeObjectRelease();

  return swift_bridgeObjectRelease();
}

void *initializeBufferWithCopyOfBuffer for SortedSet(void *a1, void *a2)
{
  uint64_t v3 = a2[1];
  *a1 = *a2;
  a1[1] = v3;
  swift_bridgeObjectRetain();
  swift_bridgeObjectRetain();
  return a1;
}

void *assignWithCopy for SortedSet(void *a1, void *a2)
{
  *a1 = *a2;
  swift_bridgeObjectRetain();
  swift_bridgeObjectRelease();
  a1[1] = a2[1];
  swift_bridgeObjectRetain();
  swift_bridgeObjectRelease();
  return a1;
}

_OWORD *assignWithTake for SortedSet(_OWORD *a1, _OWORD *a2)
{
  *a1 = *a2;
  swift_bridgeObjectRelease();
  return a1;
}

uint64_t getEnumTagSinglePayload for SortedSet(uint64_t *a1, int a2)
{
  if (a2)
  {
    if (a2 < 0 && *((unsigned char *)a1 + 16))
    {
      LODWORD(v2) = *(_DWORD *)a1 + 0x7FFFFFFF;
    }
    else
    {
      uint64_t v2 = *a1;
      if ((unint64_t)*a1 >= 0xFFFFFFFF) {
        LODWORD(v2) = -1;
      }
    }
  }
  else
  {
    LODWORD(v2) = -1;
  }
  return (v2 + 1);
}

uint64_t storeEnumTagSinglePayload for SortedSet(uint64_t result, int a2, int a3)
{
  if (a2 < 0)
  {
    *(void *)uint64_t result = a2 ^ 0x80000000;
    *(void *)(result + 8) = 0;
    if (a3 < 0) {
      *(unsigned char *)(result + 16) = 1;
    }
  }
  else
  {
    if ((a3 & 0x80000000) == 0)
    {
      if (!a2) {
        return result;
      }
LABEL_8:
      *(void *)uint64_t result = (a2 - 1);
      return result;
    }
    *(unsigned char *)(result + 16) = 0;
    if (a2) {
      goto LABEL_8;
    }
  }
  return result;
}

uint64_t type metadata accessor for SortedSet()
{
  return __swift_instantiateGenericMetadata();
}

void *initializeBufferWithCopyOfBuffer for TreeRegressorModel(void *a1, void *a2, uint64_t a3)
{
  int v5 = *(_DWORD *)(*(void *)(a3 - 8) + 80);
  if ((v5 & 0x20000) != 0)
  {
    uint64_t v12 = *a2;
    *a1 = *a2;
    a1 = (void *)(v12 + ((v5 + 16) & ~(unint64_t)v5));
    swift_retain();
  }
  else
  {
    uint64_t v7 = a2[1];
    *a1 = *a2;
    a1[1] = v7;
    uint64_t v9 = a2 + 2;
    uint64_t v8 = a2[2];
    swift_bridgeObjectRetain();
    if (v8)
    {
      uint64_t v10 = a2[3];
      uint64_t v11 = a2[4];
      a1[2] = v8;
      a1[3] = v10;
      a1[4] = v11;
      swift_bridgeObjectRetain();
      swift_bridgeObjectRetain();
    }
    else
    {
      *((_OWORD *)a1 + 1) = *v9;
      a1[4] = a2[4];
    }
    uint64_t v13 = *(int *)(a3 + 24);
    uint64_t v14 = (char *)a1 + v13;
    uint64_t v15 = (char *)a2 + v13;
    uint64_t v16 = type metadata accessor for BaseTreeRegressorModel();
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v16 - 8) + 16))(v14, v15, v16);
  }
  return a1;
}

uint64_t destroy for TreeRegressorModel(uint64_t a1, uint64_t a2)
{
  swift_bridgeObjectRelease();
  if (*(void *)(a1 + 16))
  {
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
  }
  uint64_t v4 = a1 + *(int *)(a2 + 24);
  uint64_t v5 = type metadata accessor for BaseTreeRegressorModel();
  uint64_t v6 = *(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v5 - 8) + 8);

  return v6(v4, v5);
}

void *initializeWithCopy for TreeRegressorModel(void *a1, void *a2, uint64_t a3)
{
  uint64_t v6 = a2[1];
  *a1 = *a2;
  a1[1] = v6;
  uint64_t v8 = a2 + 2;
  uint64_t v7 = a2[2];
  swift_bridgeObjectRetain();
  if (v7)
  {
    uint64_t v9 = a2[3];
    uint64_t v10 = a2[4];
    a1[2] = v7;
    a1[3] = v9;
    a1[4] = v10;
    swift_bridgeObjectRetain();
    swift_bridgeObjectRetain();
  }
  else
  {
    *((_OWORD *)a1 + 1) = *(_OWORD *)v8;
    a1[4] = v8[2];
  }
  uint64_t v11 = *(int *)(a3 + 24);
  uint64_t v12 = (char *)a1 + v11;
  uint64_t v13 = (char *)a2 + v11;
  uint64_t v14 = type metadata accessor for BaseTreeRegressorModel();
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v14 - 8) + 16))(v12, v13, v14);
  return a1;
}

void *assignWithCopy for TreeRegressorModel(void *a1, void *a2, uint64_t a3)
{
  *a1 = *a2;
  a1[1] = a2[1];
  swift_bridgeObjectRetain();
  swift_bridgeObjectRelease();
  uint64_t v6 = a1 + 2;
  uint64_t v8 = a2 + 2;
  uint64_t v7 = a2[2];
  if (a1[2])
  {
    if (v7)
    {
      a1[2] = v7;
      swift_bridgeObjectRetain();
      swift_bridgeObjectRelease();
      a1[3] = a2[3];
      a1[4] = a2[4];
      swift_bridgeObjectRetain();
      swift_bridgeObjectRelease();
    }
    else
    {
      outlined destroy of FeatureVectorizer<Float>.Transformer((uint64_t)(a1 + 2));
      uint64_t v9 = a2[4];
      *uint64_t v6 = *v8;
      a1[4] = v9;
    }
  }
  else if (v7)
  {
    a1[2] = v7;
    a1[3] = a2[3];
    a1[4] = a2[4];
    swift_bridgeObjectRetain();
    swift_bridgeObjectRetain();
  }
  else
  {
    long long v10 = *v8;
    a1[4] = a2[4];
    *uint64_t v6 = v10;
  }
  uint64_t v11 = *(int *)(a3 + 24);
  uint64_t v12 = (char *)a1 + v11;
  uint64_t v13 = (char *)a2 + v11;
  uint64_t v14 = type metadata accessor for BaseTreeRegressorModel();
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v14 - 8) + 24))(v12, v13, v14);
  return a1;
}

uint64_t outlined destroy of FeatureVectorizer<Float>.Transformer(uint64_t a1)
{
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FeatureVectorizer<Float>.Transformer);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v2 - 8) + 8))(a1, v2);
  return a1;
}

uint64_t initializeWithTake for TreeRegressorModel(uint64_t a1, uint64_t a2, uint64_t a3)
{
  long long v4 = *(_OWORD *)(a2 + 16);
  *(_OWORD *)a1 = *(_OWORD *)a2;
  *(_OWORD *)(a1 + 16) = v4;
  *(void *)(a1 + 32) = *(void *)(a2 + 32);
  uint64_t v5 = *(int *)(a3 + 24);
  uint64_t v6 = a1 + v5;
  uint64_t v7 = a2 + v5;
  uint64_t v8 = type metadata accessor for BaseTreeRegressorModel();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v8 - 8) + 32))(v6, v7, v8);
  return a1;
}

void *assignWithTake for TreeRegressorModel(void *a1, void *a2, uint64_t a3)
{
  uint64_t v6 = a2[1];
  *a1 = *a2;
  a1[1] = v6;
  swift_bridgeObjectRelease();
  uint64_t v7 = a2[2];
  if (!a1[2]) {
    goto LABEL_5;
  }
  if (!v7)
  {
    outlined destroy of FeatureVectorizer<Float>.Transformer((uint64_t)(a1 + 2));
LABEL_5:
    *((_OWORD *)a1 + 1) = *((_OWORD *)a2 + 1);
    a1[4] = a2[4];
    goto LABEL_6;
  }
  a1[2] = v7;
  swift_bridgeObjectRelease();
  uint64_t v8 = a2[4];
  a1[3] = a2[3];
  a1[4] = v8;
  swift_bridgeObjectRelease();
LABEL_6:
  uint64_t v9 = *(int *)(a3 + 24);
  long long v10 = (char *)a1 + v9;
  uint64_t v11 = (char *)a2 + v9;
  uint64_t v12 = type metadata accessor for BaseTreeRegressorModel();
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 40))(v10, v11, v12);
  return a1;
}

uint64_t getEnumTagSinglePayload for TreeRegressorModel(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return MEMORY[0x270FA0340](a1, a2, a3, sub_2270E8C70);
}

uint64_t sub_2270E8C70(uint64_t a1, uint64_t a2, uint64_t a3)
{
  if (a2 == 0x7FFFFFFF)
  {
    unint64_t v4 = *(void *)(a1 + 8);
    if (v4 >= 0xFFFFFFFF) {
      LODWORD(v4) = -1;
    }
    return (v4 + 1);
  }
  else
  {
    uint64_t v8 = type metadata accessor for BaseTreeRegressorModel();
    uint64_t v9 = a1 + *(int *)(a3 + 24);
    return __swift_getEnumTagSinglePayload(v9, a2, v8);
  }
}

uint64_t storeEnumTagSinglePayload for TreeRegressorModel(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return MEMORY[0x270FA0580](a1, a2, a3, a4, sub_2270E8D0C);
}

uint64_t sub_2270E8D0C(uint64_t result, uint64_t a2, int a3, uint64_t a4)
{
  uint64_t v5 = result;
  if (a3 == 0x7FFFFFFF)
  {
    *(void *)(result + 8) = (a2 - 1);
  }
  else
  {
    uint64_t v7 = type metadata accessor for BaseTreeRegressorModel();
    uint64_t v8 = v5 + *(int *)(a4 + 24);
    return __swift_storeEnumTagSinglePayload(v8, a2, a2, v7);
  }
  return result;
}

uint64_t type metadata accessor for TreeRegressorModel()
{
  uint64_t result = type metadata singleton initialization cache for TreeRegressorModel;
  if (!type metadata singleton initialization cache for TreeRegressorModel) {
    return swift_getSingletonMetadata();
  }
  return result;
}

uint64_t type metadata completion function for TreeRegressorModel()
{
  uint64_t result = type metadata accessor for BaseTreeRegressorModel();
  if (v1 <= 0x3F)
  {
    swift_initStructMetadata();
    return 0;
  }
  return result;
}

void TreeRegressorModel.computeMetrics(on:)(uint64_t a1@<X8>)
{
  type metadata accessor for AnyColumn();
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v2);
  OUTLINED_FUNCTION_33_0();
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Double>);
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v3);
  OUTLINED_FUNCTION_3_0();
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FilledColumn<Column<Double>>);
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v4);
  OUTLINED_FUNCTION_33_0();
  type metadata accessor for DataFrame();
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v5);
  OUTLINED_FUNCTION_3_0();
  TreeRegressorModel.applied(to:eventHandler:)();
  if (!v13)
  {
    DataFrame.subscript.getter();
    lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<Double> and conformance Column<A>, &demangling cache variable for type metadata for Column<Double>);
    OptionalColumnProtocol.filled(with:)();
    OUTLINED_FUNCTION_25_0();
    v6();
    MEMORY[0x22A672220](*v1, v1[1]);
    AnyColumn.convertedToDoubles()();
    uint64_t v8 = v7;
    OUTLINED_FUNCTION_25_0();
    v9();
    if (v8)
    {
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ContiguousArray<Double>);
      lazy protocol witness table accessor for type Double and conformance Double();
      lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type FilledColumn<Column<Double>> and conformance FilledColumn<A>, &demangling cache variable for type metadata for FilledColumn<Column<Double>>);
      lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>((unint64_t *)&lazy protocol witness table cache variable for type ContiguousArray<Double> and conformance ContiguousArray<A>, &demangling cache variable for type metadata for ContiguousArray<Double>);
      OUTLINED_FUNCTION_2_23();
      maximumAbsoluteError<A, B, C>(_:_:)();
      OUTLINED_FUNCTION_2_23();
      rootMeanSquaredError<A, B, C>(_:_:)();
      OUTLINED_FUNCTION_25_0();
      v10();
      OUTLINED_FUNCTION_25_0();
      v11();
      swift_release();
      *(void *)a1 = 0;
      *(void *)(a1 + 8) = 0;
      *(unsigned char *)(a1 + 16) = 0;
    }
    else
    {
      __break(1u);
    }
  }
}

void TreeRegressorModel.applied(to:eventHandler:)()
{
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Double>);
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v2);
  OUTLINED_FUNCTION_33_0();
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DenseMatrix<Float>);
  OUTLINED_FUNCTION_0();
  uint64_t v17 = v4;
  uint64_t v18 = v3;
  MEMORY[0x270FA5388](v3);
  OUTLINED_FUNCTION_3_0();
  uint64_t v7 = v6 - v5;
  if (!*(void *)(v0 + 16))
  {
LABEL_14:
    _assertionFailure(_:_:file:line:flags:)();
    __break(1u);
    return;
  }
  specialized FeatureVectorizer.Transformer.vectorized(_:includingBias:)();
  if (!v1)
  {
    type metadata accessor for TreeRegressorModel();
    uint64_t v8 = BaseTreeRegressorModel.applied(features:eventHandler:)();
    uint64_t v16 = v7;
    DataFrame.init()();
    uint64_t v9 = *(void *)(v8 + 16);
    if (v9)
    {
      uint64_t v19 = MEMORY[0x263F8EE78];
      swift_bridgeObjectRetain();
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v9, 0);
      uint64_t v10 = 0;
      uint64_t v11 = *(void *)(v8 + 16);
      while (v11 != v10)
      {
        float v12 = *(float *)(v8 + 4 * v10 + 32);
        unint64_t v14 = *(void *)(v19 + 16);
        unint64_t v13 = *(void *)(v19 + 24);
        if (v14 >= v13 >> 1) {
          specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v13 > 1, v14 + 1, 1);
        }
        ++v10;
        *(void *)(v19 + 16) = v14 + 1;
        *(double *)(v19 + 8 * v14 + 32) = v12;
        if (v9 == v10)
        {
          swift_release();
          goto LABEL_11;
        }
      }
      __break(1u);
      goto LABEL_14;
    }
    swift_bridgeObjectRetain();
    swift_release();
LABEL_11:
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Double]);
    lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [Double] and conformance [A], &demangling cache variable for type metadata for [Double]);
    Column.init<A>(name:contents:)();
    DataFrame.append<A>(column:)();
    OUTLINED_FUNCTION_25_0();
    v15();
    (*(void (**)(uint64_t, uint64_t))(v17 + 8))(v16, v18);
  }
}

uint64_t protocol witness for Transformer.applied(to:eventHandler:) in conformance TreeRegressorModel()
{
  TreeRegressorModel.applied(to:eventHandler:)();
  uint64_t v1 = *(uint64_t (**)(void))(v0 + 8);
  return protocol witness for SupervisedTabularEstimator.fitted(to:validateOn:eventHandler:) in conformance TreeRegressor(v1);
}

unint64_t lazy protocol witness table accessor for type TreeRegressorModel and conformance TreeRegressorModel()
{
  unint64_t result = lazy protocol witness table cache variable for type TreeRegressorModel and conformance TreeRegressorModel;
  if (!lazy protocol witness table cache variable for type TreeRegressorModel and conformance TreeRegressorModel)
  {
    type metadata accessor for TreeRegressorModel();
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type TreeRegressorModel and conformance TreeRegressorModel);
  }
  return result;
}

uint64_t specialized Array.init<A>(_:)(uint64_t a1, uint64_t a2, uint64_t a3, unint64_t a4)
{
  return specialized Array.init<A>(_:)(a1, a2, a3, a4, (uint64_t (*)(uint64_t, uint64_t, uint64_t, unint64_t))specialized _copyCollectionToContiguousArray<A>(_:));
}

{
  return specialized Array.init<A>(_:)(a1, a2, a3, a4, (uint64_t (*)(uint64_t, uint64_t, uint64_t, unint64_t))specialized _copyCollectionToContiguousArray<A>(_:));
}

uint64_t specialized Array.init<A>(_:)(uint64_t a1, uint64_t a2, uint64_t a3, unint64_t a4, uint64_t (*a5)(uint64_t, uint64_t, uint64_t, unint64_t))
{
  if ((a4 & 1) == 0) {
    goto LABEL_2;
  }
  type metadata accessor for __ContiguousArrayStorageBase();
  swift_unknownObjectRetain_n();
  uint64_t v11 = swift_dynamicCastClass();
  if (!v11)
  {
    swift_unknownObjectRelease();
    uint64_t v11 = MEMORY[0x263F8EE78];
  }
  uint64_t v12 = *(void *)(v11 + 16);
  swift_release();
  if (__OFSUB__(a4 >> 1, a3))
  {
    __break(1u);
    goto LABEL_11;
  }
  if (v12 != (a4 >> 1) - a3)
  {
LABEL_11:
    swift_unknownObjectRelease();
LABEL_2:
    uint64_t v10 = a5(a1, a2, a3, a4);
    goto LABEL_9;
  }
  uint64_t v10 = swift_dynamicCastClass();
  if (!v10)
  {
    swift_unknownObjectRelease();
    uint64_t v10 = MEMORY[0x263F8EE78];
  }
LABEL_9:
  swift_unknownObjectRelease();
  return v10;
}

uint64_t _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D4LL10parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm(uint64_t a1, uint64_t a2, uint64_t *a3)
{
  uint64_t v3 = *(void *)(a1 + 16);
  uint64_t v4 = MEMORY[0x263F8EE78];
  if (v3)
  {
    uint64_t v17 = MEMORY[0x263F8EE78];
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
    uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(a3);
    OUTLINED_FUNCTION_1(v7);
    uint64_t v9 = a1 + ((*(unsigned __int8 *)(v8 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v8 + 80));
    uint64_t v11 = *(void *)(v10 + 72);
    do
    {
      swift_getKeyPath();
      swift_getAtKeyPath();
      swift_release();
      uint64_t v4 = v17;
      if ((swift_isUniquelyReferenced_nonNull_native() & 1) == 0)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
        uint64_t v4 = v17;
      }
      unint64_t v12 = *(void *)(v4 + 16);
      if (v12 >= *(void *)(v4 + 24) >> 1)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
        uint64_t v4 = v17;
      }
      *(void *)(v4 + 16) = v12 + 1;
      uint64_t v13 = v4 + 16 * v12;
      *(void *)(v13 + 32) = v15;
      *(void *)(v13 + 40) = v16;
      v9 += v11;
      --v3;
    }
    while (v3);
  }
  return v4;
}

uint64_t _sSTsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFs12Zip2SequenceVy11TabularData12FilledColumnVyAH0I0VySSGGAJyALySaySfGGGG_18CreateMLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGs5NeverOTg5012_sSSSaySfG18j14MLComponents16lm3Vy6n4ML13pq2Vyu20GSSGIgggr_SS_AAtAIs5r68OIegnrzr_TR03_s8a80ML38SoundClassifierTrainingSessionDelegateC13loadg44FrameySay0A12MLComponents16cd4Vy04e4B013gh36zu7GSSGG07F37I00iJ0VKFZALSS_SayZ7GtXEfU_Tf3nnnpf_nTf1cn_n(uint64_t a1)
{
  uint64_t v77 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Float>);
  MEMORY[0x270FA5388](v77);
  uint64_t v76 = (char *)&v63 - ((v2 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v75 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<MLShapedArray<Float>, String>);
  uint64_t v84 = *(void *)(v75 - 8);
  uint64_t v3 = MEMORY[0x270FA5388](v75);
  uint64_t v86 = (char *)&v63 - ((v4 + 15) & 0xFFFFFFFFFFFFFFF0);
  MEMORY[0x270FA5388](v3);
  uint64_t v66 = (char *)&v63 - v5;
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FilledColumn<Column<[Float]>>);
  uint64_t v65 = *(void *)(v6 - 8);
  MEMORY[0x270FA5388](v6);
  uint64_t v80 = (char *)&v63 - ((v7 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FilledColumn<Column<String>>);
  uint64_t v64 = *(void *)(v8 - 8);
  MEMORY[0x270FA5388](v8);
  unint64_t v83 = (char *)&v63 - ((v9 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Zip2Sequence<FilledColumn<Column<String>>, FilledColumn<Column<[Float]>>>);
  uint64_t v11 = v10 - 8;
  MEMORY[0x270FA5388](v10);
  uint64_t v85 = (char *)&v63 - ((v12 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Zip2Sequence<FilledColumn<Column<String>>, FilledColumn<Column<[Float]>>>.Iterator);
  uint64_t v14 = v13 - 8;
  MEMORY[0x270FA5388](v13);
  uint64_t v16 = (char *)&v63 - ((v15 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v17 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type FilledColumn<Column<String>> and conformance FilledColumn<A>, &demangling cache variable for type metadata for FilledColumn<Column<String>>);
  uint64_t v81 = a1;
  uint64_t v82 = v17;
  uint64_t v18 = dispatch thunk of Sequence.underestimatedCount.getter();
  lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type FilledColumn<Column<[Float]>> and conformance FilledColumn<A>, &demangling cache variable for type metadata for FilledColumn<Column<[Float]>>);
  uint64_t v19 = dispatch thunk of Sequence.underestimatedCount.getter();
  if (v19 >= v18) {
    uint64_t v20 = v18;
  }
  else {
    uint64_t v20 = v19;
  }
  uint64_t v89 = MEMORY[0x263F8EE78];
  specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
  uint64_t v21 = v85;
  outlined init with copy of URL?(v81, (uint64_t)v85, &demangling cache variable for type metadata for Zip2Sequence<FilledColumn<Column<String>>, FilledColumn<Column<[Float]>>>);
  (*(void (**)(char *, char *, uint64_t))(v64 + 32))(v83, v21, v8);
  dispatch thunk of Sequence.makeIterator()();
  (*(void (**)(char *, char *, uint64_t))(v65 + 32))(v80, &v21[*(int *)(v11 + 60)], v6);
  long long v22 = &v16[*(int *)(v14 + 60)];
  dispatch thunk of Sequence.makeIterator()();
  uint64_t v81 = *(int *)(v14 + 64);
  v16[v81] = 0;
  if (v20 < 0)
  {
LABEL_30:
    __break(1u);
LABEL_31:
    uint64_t result = swift_bridgeObjectRelease();
    __break(1u);
  }
  else
  {
    uint64_t v23 = (uint64_t)v16;
    uint64_t v78 = v16;
    uint64_t v79 = v22;
    uint64_t v82 = v8;
    if (v20)
    {
      uint64_t v24 = &v16[*(int *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for IndexingIterator<FilledColumn<Column<String>>>)
                        + 36)];
      uint64_t v25 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for IndexingIterator<FilledColumn<Column<[Float]>>>);
      uint64_t v74 = &v79[*(int *)(v25 + 36)];
      uint64_t v72 = (void (**)(char *, uint64_t))(v64 + 8);
      uint64_t v73 = (void (**)(char *, uint64_t))(v64 + 16);
      uint64_t v71 = (void (**)(char *, char *, uint64_t))(v65 + 16);
      *(void *)&long long v70 = v65 + 8;
      uint64_t v69 = v84 + 32;
      long long v67 = xmmword_2272CB370;
      uint64_t v26 = v82;
      uint64_t v68 = v24;
      do
      {
        if (*(unsigned char *)(v23 + v81))
        {
          __break(1u);
LABEL_29:
          __break(1u);
          goto LABEL_30;
        }
        uint64_t v27 = *(void (**)(char *, void, uint64_t))v24;
        lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type FilledColumn<Column<String>> and conformance FilledColumn<A>, &demangling cache variable for type metadata for FilledColumn<Column<String>>);
        dispatch thunk of Collection.endIndex.getter();
        if (v27 == v87) {
          goto LABEL_29;
        }
        uint64_t v85 = (char *)v20;
        uint64_t v28 = (void (*)(void (**)(char *, void, uint64_t), void))dispatch thunk of Collection.subscript.read();
        uint64_t v29 = v23;
        uint64_t v31 = (void (*)(char *, void, uint64_t))*v30;
        uint64_t v32 = v30[1];
        swift_bridgeObjectRetain();
        v28(&v87, 0);
        char v33 = v83;
        ((void (*)(char *, uint64_t, uint64_t))*v73)(v83, v29, v26);
        dispatch thunk of Collection.formIndex(after:)();
        (*v72)(v33, v26);
        uint64_t v34 = *(void (**)(char *, void, uint64_t))v74;
        lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type FilledColumn<Column<[Float]>> and conformance FilledColumn<A>, &demangling cache variable for type metadata for FilledColumn<Column<[Float]>>);
        uint64_t v35 = v79;
        dispatch thunk of Collection.endIndex.getter();
        if (v34 == v87) {
          goto LABEL_31;
        }
        char v36 = (void (*)(void (**)(char *, void, uint64_t), void))dispatch thunk of Collection.subscript.read();
        uint64_t v38 = *v37;
        swift_bridgeObjectRetain();
        v36(&v87, 0);
        id v39 = v80;
        (*v71)(v80, v35, v6);
        dispatch thunk of Collection.formIndex(after:)();
        (*(void (**)(char *, uint64_t))v70)(v39, v6);
        uint64_t v87 = (void (*)(char *, void, uint64_t))v38;
        __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
        uint64_t v40 = swift_allocObject();
        *(_OWORD *)(v40 + 16) = v67;
        *(void *)(v40 + 32) = *(void *)(v38 + 16);
        swift_bridgeObjectRetain();
        __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Float]);
        lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>((unint64_t *)&lazy protocol witness table cache variable for type [Float] and conformance [A], &demangling cache variable for type metadata for [Float]);
        MLShapedArray.init<A>(scalars:shape:)();
        uint64_t v87 = v31;
        uint64_t v88 = v32;
        AnnotatedFeature.init(feature:annotation:)();
        swift_bridgeObjectRelease();
        uint64_t v41 = v89;
        if ((swift_isUniquelyReferenced_nonNull_native() & 1) == 0)
        {
          specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
          uint64_t v41 = v89;
        }
        uint64_t v23 = (uint64_t)v78;
        uint64_t v24 = v68;
        uint64_t v42 = v85;
        unint64_t v43 = *(void *)(v41 + 16);
        if (v43 >= *(void *)(v41 + 24) >> 1)
        {
          specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
          uint64_t v41 = v89;
        }
        *(void *)(v41 + 16) = v43 + 1;
        (*(void (**)(unint64_t, char *, uint64_t))(v84 + 32))(v41+ ((*(unsigned __int8 *)(v84 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v84 + 80))+ *(void *)(v84 + 72) * v43, v86, v75);
        uint64_t v20 = (uint64_t)(v42 - 1);
        uint64_t v26 = v82;
      }
      while (v20);
      if (*(unsigned char *)(v23 + v81)) {
        goto LABEL_27;
      }
    }
    uint64_t v44 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type FilledColumn<Column<String>> and conformance FilledColumn<A>, &demangling cache variable for type metadata for FilledColumn<Column<String>>);
    uint64_t v85 = (char *)(v64 + 8);
    uint64_t v86 = (char *)(v64 + 16);
    uint64_t v73 = (void (**)(char *, uint64_t))(v65 + 8);
    uint64_t v74 = (char *)(v65 + 16);
    uint64_t v72 = (void (**)(char *, uint64_t))(v84 + 32);
    long long v70 = xmmword_2272CB370;
    uint64_t v71 = (void (**)(char *, char *, uint64_t))v44;
    while (1)
    {
      uint64_t v45 = *(void (**)(char *, void, uint64_t))(v23
                                                           + *(int *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for IndexingIterator<FilledColumn<Column<String>>>)
                                                                    + 36));
      uint64_t v46 = v82;
      dispatch thunk of Collection.endIndex.getter();
      if (v45 == v87) {
        break;
      }
      uint64_t v47 = (void (*)(void (**)(char *, void, uint64_t), void))dispatch thunk of Collection.subscript.read();
      uint64_t v49 = (void (*)(char *, void, uint64_t))*v48;
      uint64_t v50 = v48[1];
      swift_bridgeObjectRetain();
      v47(&v87, 0);
      uint64_t v51 = v83;
      (*(void (**)(char *, uint64_t, uint64_t))v86)(v83, v23, v46);
      dispatch thunk of Collection.formIndex(after:)();
      (*(void (**)(char *, uint64_t))v85)(v51, v46);
      uint64_t v52 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for IndexingIterator<FilledColumn<Column<[Float]>>>);
      uint64_t v53 = v79;
      uint64_t v54 = *(void (**)(char *, void, uint64_t))&v79[*(int *)(v52 + 36)];
      lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type FilledColumn<Column<[Float]>> and conformance FilledColumn<A>, &demangling cache variable for type metadata for FilledColumn<Column<[Float]>>);
      dispatch thunk of Collection.endIndex.getter();
      if (v54 == v87)
      {
        swift_bridgeObjectRelease();
        uint64_t v23 = (uint64_t)v78;
        break;
      }
      uint64_t v55 = (void (*)(void (**)(char *, void, uint64_t), void))dispatch thunk of Collection.subscript.read();
      uint64_t v57 = *v56;
      swift_bridgeObjectRetain();
      v55(&v87, 0);
      uint64_t v58 = v80;
      (*(void (**)(char *, char *, uint64_t))v74)(v80, v53, v6);
      dispatch thunk of Collection.formIndex(after:)();
      (*v73)(v58, v6);
      uint64_t v87 = (void (*)(char *, void, uint64_t))v57;
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
      uint64_t v59 = swift_allocObject();
      *(_OWORD *)(v59 + 16) = v70;
      *(void *)(v59 + 32) = *(void *)(v57 + 16);
      swift_bridgeObjectRetain();
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Float]);
      lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>((unint64_t *)&lazy protocol witness table cache variable for type [Float] and conformance [A], &demangling cache variable for type metadata for [Float]);
      MLShapedArray.init<A>(scalars:shape:)();
      uint64_t v87 = v49;
      uint64_t v88 = v50;
      AnnotatedFeature.init(feature:annotation:)();
      swift_bridgeObjectRelease();
      uint64_t v60 = v89;
      if ((swift_isUniquelyReferenced_nonNull_native() & 1) == 0)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
        uint64_t v60 = v89;
      }
      uint64_t v23 = (uint64_t)v78;
      unint64_t v61 = *(void *)(v60 + 16);
      if (v61 >= *(void *)(v60 + 24) >> 1)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
        uint64_t v60 = v89;
      }
      *(void *)(v60 + 16) = v61 + 1;
      (*(void (**)(unint64_t, char *, uint64_t))(v84 + 32))(v60+ ((*(unsigned __int8 *)(v84 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v84 + 80))+ *(void *)(v84 + 72) * v61, v66, v75);
      if (*(unsigned char *)(v23 + v81)) {
        goto LABEL_27;
      }
    }
    *(unsigned char *)(v23 + v81) = 1;
LABEL_27:
    outlined destroy of URL?(v23, &demangling cache variable for type metadata for Zip2Sequence<FilledColumn<Column<String>>, FilledColumn<Column<[Float]>>>.Iterator);
    return v89;
  }
  return result;
}

uint64_t key path getter for AnnotatedFeature.annotation : AnnotatedFeature<MLShapedArray<Float>, String>@<X0>(void *a1@<X8>)
{
  return key path getter for AnnotatedFeature.annotation : AnnotatedFeature<MLShapedArray<Float>, String>(&demangling cache variable for type metadata for AnnotatedFeature<MLShapedArray<Float>, String>, a1);
}

uint64_t key path setter for AnnotatedFeature.annotation : AnnotatedFeature<MLShapedArray<Float>, String>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return key path setter for AnnotatedFeature.annotation : AnnotatedFeature<MLShapedArray<Float>, String>(a1, a2, a3, a4, &demangling cache variable for type metadata for AnnotatedFeature<MLShapedArray<Float>, String>);
}

uint64_t SoundClassifierTrainingSessionDelegate.init(sessionParameters:)(uint64_t a1)
{
  *(void *)(v1 + 16) = 0xD000000000000010;
  *(void *)(v1 + 24) = 0x80000002272D69E0;
  OUTLINED_FUNCTION_108_0();
  uint64_t v4 = type metadata accessor for MLSoundClassifier.PersistentParameters();
  OUTLINED_FUNCTION_42_5(v4);
  uint64_t v5 = MEMORY[0x263F8EE78];
  *(void *)(v1 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingFiles) = MEMORY[0x263F8EE78];
  *(void *)(v1 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFiles) = v5;
  *(void *)(v1 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingFeatures) = v5;
  *(void *)(v1 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFeatures) = v5;
  *(void *)(v1 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_labels) = MEMORY[0x263F8EE88];
  *(unsigned char *)(v1 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_featureExtractionOnly) = 0;
  OUTLINED_FUNCTION_108_0();
  uint64_t v6 = type metadata accessor for MLSoundClassifier.Classifier();
  OUTLINED_FUNCTION_42_5(v6);
  OUTLINED_FUNCTION_108_0();
  uint64_t v7 = type metadata accessor for MLSoundClassifier.Model();
  OUTLINED_FUNCTION_42_5(v7);
  OUTLINED_FUNCTION_108_0();
  uint64_t v8 = type metadata accessor for MLSoundClassifier.ModelParameters();
  OUTLINED_FUNCTION_42_5(v8);
  uint64_t v9 = OUTLINED_FUNCTION_108_0();
  uint64_t v10 = type metadata accessor for MLClassifierMetrics(v9);
  __swift_storeEnumTagSinglePayload(v2, 1, 1, v10);
  __swift_storeEnumTagSinglePayload(v1 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationMetrics, 1, 1, v10);
  uint64_t v11 = OUTLINED_FUNCTION_108_0();
  uint64_t v12 = type metadata accessor for TrainingTablePrinter(v11);
  OUTLINED_FUNCTION_42_5(v12);
  outlined init with take of MLSoundClassifier.Model(a1, v1 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_sessionParameters, (void (*)(void))type metadata accessor for MLTrainingSessionParameters);
  return v1;
}

uint64_t SoundClassifierTrainingSessionDelegate.init(trainingData:featureExtractionOnly:modelParameters:sessionParameters:)(uint64_t a1, char a2, uint64_t a3, uint64_t a4)
{
  OUTLINED_FUNCTION_4_12();
  uint64_t v29 = v10;
  type metadata accessor for MLSoundClassifier.ModelParameters();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v11);
  OUTLINED_FUNCTION_24_8();
  uint64_t v12 = type metadata accessor for MLSoundClassifier.DataSource();
  uint64_t v13 = OUTLINED_FUNCTION_17(v12);
  MEMORY[0x270FA5388](v13);
  OUTLINED_FUNCTION_41_0();
  uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
  uint64_t v15 = OUTLINED_FUNCTION_17(v14);
  MEMORY[0x270FA5388](v15);
  OUTLINED_FUNCTION_40_0();
  *(void *)(v5 + 16) = 0xD000000000000010;
  *(void *)(v5 + 24) = 0x80000002272D69E0;
  uint64_t v16 = v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingParameters;
  uint64_t v17 = type metadata accessor for MLSoundClassifier.PersistentParameters();
  __swift_storeEnumTagSinglePayload(v16, 1, 1, v17);
  uint64_t v18 = MEMORY[0x263F8EE78];
  *(void *)(v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingFiles) = MEMORY[0x263F8EE78];
  *(void *)(v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFiles) = v18;
  *(void *)(v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingFeatures) = v18;
  *(void *)(v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFeatures) = v18;
  *(void *)(v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_labels) = MEMORY[0x263F8EE88];
  *(unsigned char *)(v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_featureExtractionOnly) = 0;
  OUTLINED_FUNCTION_151();
  uint64_t v19 = type metadata accessor for MLSoundClassifier.Classifier();
  OUTLINED_FUNCTION_45(v19);
  OUTLINED_FUNCTION_151();
  uint64_t v20 = type metadata accessor for MLSoundClassifier.Model();
  OUTLINED_FUNCTION_45(v20);
  OUTLINED_FUNCTION_124(v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_parameters);
  uint64_t v21 = OUTLINED_FUNCTION_151();
  type metadata accessor for MLClassifierMetrics(v21);
  OUTLINED_FUNCTION_124(v7);
  OUTLINED_FUNCTION_124(v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationMetrics);
  uint64_t v22 = OUTLINED_FUNCTION_151();
  uint64_t v23 = type metadata accessor for TrainingTablePrinter(v22);
  __swift_storeEnumTagSinglePayload(v7, 1, 1, v23);
  outlined init with copy of MLSoundClassifier.ModelParameters.ValidationData(v29, v6, (void (*)(void))type metadata accessor for MLSoundClassifier.DataSource);
  outlined init with copy of MLSoundClassifier.ModelParameters.ValidationData(a3, v4, (void (*)(void))type metadata accessor for MLSoundClassifier.ModelParameters);
  uint64_t v24 = OUTLINED_FUNCTION_160();
  MLSoundClassifier.PersistentParameters.init(trainingData:modelParameters:)(v24, v25, v26);
  if (v30)
  {
    outlined destroy of MLSoundClassifier.Model(a4, (void (*)(void))type metadata accessor for MLTrainingSessionParameters);
    outlined destroy of MLSoundClassifier.Model(a3, (void (*)(void))type metadata accessor for MLSoundClassifier.ModelParameters);
    outlined destroy of MLSoundClassifier.Model(v29, (void (*)(void))type metadata accessor for MLSoundClassifier.DataSource);
    swift_bridgeObjectRelease();
    outlined destroy of URL?(v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingParameters, &demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    outlined destroy of URL?(v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_classifier, &demangling cache variable for type metadata for MLSoundClassifier.Classifier?);
    outlined destroy of URL?(v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_model, &demangling cache variable for type metadata for MLSoundClassifier.Model?);
    outlined destroy of URL?(v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_parameters, &demangling cache variable for type metadata for MLSoundClassifier.ModelParameters?);
    outlined destroy of URL?(v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingMetrics, &demangling cache variable for type metadata for MLClassifierMetrics?);
    outlined destroy of URL?(v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationMetrics, &demangling cache variable for type metadata for MLClassifierMetrics?);
    outlined destroy of URL?(v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_tablePrinter, &demangling cache variable for type metadata for TrainingTablePrinter?);
    OUTLINED_FUNCTION_4_12();
    swift_deallocPartialClassInstance();
  }
  else
  {
    outlined destroy of MLSoundClassifier.Model(a3, (void (*)(void))type metadata accessor for MLSoundClassifier.ModelParameters);
    outlined destroy of MLSoundClassifier.Model(v29, (void (*)(void))type metadata accessor for MLSoundClassifier.DataSource);
    __swift_storeEnumTagSinglePayload(v8, 0, 1, v17);
    OUTLINED_FUNCTION_81_2();
    outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v8, v16, &demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
    swift_endAccess();
    outlined init with take of MLSoundClassifier.Model(a4, v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_sessionParameters, (void (*)(void))type metadata accessor for MLTrainingSessionParameters);
    *(unsigned char *)(v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_featureExtractionOnly) = a2 & 1;
  }
  return v5;
}

Swift::Void __swiftcall __spoils<CF,ZF,NF,VF,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13,X14,X15,X16,X17,X21,Q0,Q1,Q2,Q3,Q4,Q5,Q6,Q7,Q16,Q17,Q18,Q19,Q20,Q21,Q22,Q23,Q24,Q25,Q26,Q27,Q28,Q29,Q30,Q31> SoundClassifierTrainingSessionDelegate.setUp()()
{
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.Model?);
  uint64_t v5 = OUTLINED_FUNCTION_17(v4);
  MEMORY[0x270FA5388](v5);
  OUTLINED_FUNCTION_40_0();
  uint64_t v6 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData();
  uint64_t v7 = OUTLINED_FUNCTION_17(v6);
  MEMORY[0x270FA5388](v7);
  OUTLINED_FUNCTION_33_0();
  uint64_t v58 = v8;
  uint64_t v9 = (int *)type metadata accessor for MLSoundClassifier.ModelParameters();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v10);
  OUTLINED_FUNCTION_33();
  OUTLINED_FUNCTION_117_0();
  uint64_t v12 = MEMORY[0x270FA5388](v11);
  OUTLINED_FUNCTION_139(v12, v13, v14, v15, v16, v17, v18, v19, v53);
  uint64_t v20 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.Classifier?);
  uint64_t v21 = OUTLINED_FUNCTION_17(v20);
  MEMORY[0x270FA5388](v21);
  OUTLINED_FUNCTION_49();
  uint64_t v59 = v22;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v23);
  OUTLINED_FUNCTION_106();
  uint64_t v57 = v24;
  uint64_t v25 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
  uint64_t v26 = OUTLINED_FUNCTION_17(v25);
  MEMORY[0x270FA5388](v26);
  uint64_t v27 = (int *)OUTLINED_FUNCTION_103_0();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v28);
  OUTLINED_FUNCTION_3_0();
  uint64_t v31 = v30 - v29;
  uint64_t v32 = v0 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingParameters;
  OUTLINED_FUNCTION_53();
  outlined init with copy of URL?(v32, v2, &demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
  OUTLINED_FUNCTION_57_4(v2, 1, (uint64_t)v27);
  if (v33)
  {
    outlined destroy of URL?(v2, &demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
    __break(1u);
  }
  else
  {
    outlined init with take of MLSoundClassifier.Model(v2, v31, (void (*)(void))type metadata accessor for MLSoundClassifier.PersistentParameters);
    SoundClassifierTrainingSessionDelegate.populateFiles(parameters:)(v31);
    if (v60)
    {
      outlined destroy of MLSoundClassifier.Model(v31, (void (*)(void))type metadata accessor for MLSoundClassifier.PersistentParameters);
      return;
    }
    uint64_t v54 = v3;
    uint64_t v55 = *(void *)(v0 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_labels);
    outlined init with copy of MLSoundClassifier.ModelParameters.ValidationData(v31 + v27[5], v58, (void (*)(void))type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
    uint64_t v34 = v27[9];
    uint64_t v35 = *(void *)(v31 + v27[8]);
    uint64_t v36 = *(void *)(v31 + v27[6]);
    uint64_t v37 = *(void *)(v31 + v34);
    uint64_t v61 = v0;
    char v38 = *(unsigned char *)(v31 + v34 + 8);
    id v39 = (_OWORD *)(v1 + v9[7]);
    *id v39 = 0u;
    v39[1] = 0u;
    OUTLINED_FUNCTION_134(v1 + v9[8]);
    *(void *)(v1 + v40) = v41;
    outlined init with copy of MLSoundClassifier.ModelParameters.ValidationData(v58, v1, (void (*)(void))type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
    *(void *)(v1 + v9[5]) = v35;
    *(void *)(v1 + v9[6]) = v36;
    uint64_t v64 = &type metadata for MLSoundClassifier.ModelParameters.ModelAlgorithmType;
    uint64_t v62 = v37;
    char v63 = v38;
    swift_bridgeObjectRetain();
    outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata((uint64_t)&v62, (uint64_t)v39, &demangling cache variable for type metadata for Any?);
    outlined destroy of MLSoundClassifier.Model(v58, (void (*)(void))type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
    outlined init with take of MLSoundClassifier.Model(v1, v56, (void (*)(void))type metadata accessor for MLSoundClassifier.ModelParameters);
    MLSoundClassifier.Classifier.init(labels:parameters:)(v55, v56, v57);
    uint64_t v42 = type metadata accessor for MLSoundClassifier.Classifier();
    __swift_storeEnumTagSinglePayload(v57, 0, 1, v42);
    OUTLINED_FUNCTION_81_2();
    OUTLINED_FUNCTION_125();
    outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v43, v44, v45);
    swift_endAccess();
    OUTLINED_FUNCTION_125();
    outlined init with copy of URL?(v46, v47, v48);
    uint64_t v49 = OUTLINED_FUNCTION_133();
    OUTLINED_FUNCTION_57_4(v49, v50, v42);
    if (!v33)
    {
      MLSoundClassifier.Classifier.makeTransformer()(v54);
      outlined destroy of MLSoundClassifier.Model(v31, (void (*)(void))type metadata accessor for MLSoundClassifier.PersistentParameters);
      outlined destroy of MLSoundClassifier.Model(v59, (void (*)(void))type metadata accessor for MLSoundClassifier.Classifier);
      uint64_t v51 = type metadata accessor for MLSoundClassifier.Model();
      OUTLINED_FUNCTION_161(v51);
      uint64_t v52 = v61 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_model;
      OUTLINED_FUNCTION_81_2();
      outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v54, v52, &demangling cache variable for type metadata for MLSoundClassifier.Model?);
      swift_endAccess();
      return;
    }
  }
  __break(1u);
}

void SoundClassifierTrainingSessionDelegate.populateFiles(parameters:)(uint64_t a1)
{
  uint64_t v2 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData();
  uint64_t v3 = MEMORY[0x270FA5388](v2 - 8);
  uint64_t v5 = &v54[-((v4 + 15) & 0xFFFFFFFFFFFFFFF0)];
  uint64_t v6 = MEMORY[0x270FA5388](v3);
  uint64_t v8 = &v54[-v7];
  MEMORY[0x270FA5388](v6);
  uint64_t v10 = &v54[-v9];
  uint64_t v11 = (int *)type metadata accessor for MLSoundClassifier.ModelParameters();
  uint64_t v12 = MEMORY[0x270FA5388](v11);
  uint64_t v14 = &v54[-((v13 + 15) & 0xFFFFFFFFFFFFFFF0)];
  MEMORY[0x270FA5388](v12);
  uint64_t v16 = &v54[-v15];
  uint64_t v17 = (void *)MLSoundClassifier.DataSource.annotatedFeatures()();
  if (!v18)
  {
    if (v17)
    {
      v57._rawValue = v17;
      uint64_t v19 = (int *)type metadata accessor for MLSoundClassifier.PersistentParameters();
      outlined init with copy of MLSoundClassifier.ModelParameters.ValidationData(a1 + v19[5], (uint64_t)v10, (void (*)(void))type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
      uint64_t v20 = *(void *)(a1 + v19[8]);
      uint64_t v21 = *(void *)(a1 + v19[6]);
      uint64_t v22 = a1 + v19[9];
      uint64_t v23 = *(void *)v22;
      LODWORD(v56) = *(unsigned __int8 *)(v22 + 8);
      uint64_t v24 = &v16[v11[7]];
      *uint64_t v24 = 0u;
      v24[1] = 0u;
      uint64_t v25 = &v16[v11[8]];
      *(void *)uint64_t v25 = 0;
      v25[8] = 1;
      *(void *)&v16[v11[9]] = 32;
      outlined init with copy of MLSoundClassifier.ModelParameters.ValidationData((uint64_t)v10, (uint64_t)v16, (void (*)(void))type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
      *(void *)&v16[v11[5]] = v20;
      *(void *)&v16[v11[6]] = v21;
      char v63 = &type metadata for MLSoundClassifier.ModelParameters.ModelAlgorithmType;
      uint64_t v61 = v23;
      char v62 = v56;
      outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata((uint64_t)&v61, (uint64_t)v24, &demangling cache variable for type metadata for Any?);
      outlined destroy of MLSoundClassifier.Model((uint64_t)v10, (void (*)(void))type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
      outlined init with copy of MLSoundClassifier.ModelParameters.ValidationData((uint64_t)v16, (uint64_t)v8, (void (*)(void))type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
      outlined destroy of MLSoundClassifier.Model((uint64_t)v16, (void (*)(void))type metadata accessor for MLSoundClassifier.ModelParameters);
      rawValue = v57._rawValue;
      *(_OWORD *)&uint64_t v27 = (unsigned __int128)MLSoundClassifier.ModelParameters.ValidationData.splitFeatures(trainingData:)(v57);
      if (v29)
      {
        outlined destroy of MLSoundClassifier.Model((uint64_t)v8, (void (*)(void))type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
      }
      else
      {
        uint64_t v42 = v27;
        uint64_t v43 = v28;
        outlined destroy of MLSoundClassifier.Model((uint64_t)v8, (void (*)(void))type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
        uint64_t v44 = v58;
        uint64_t v45 = (void *)(v58 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingFeatures);
        swift_beginAccess();
        *uint64_t v45 = v42;
        swift_bridgeObjectRelease();
        if (v43) {
          uint64_t v46 = v43;
        }
        else {
          uint64_t v46 = MEMORY[0x263F8EE78];
        }
        uint64_t v47 = (void *)(v44 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFeatures);
        swift_beginAccess();
        void *v47 = v46;
        swift_bridgeObjectRelease();
        MLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm((uint64_t)rawValue, (uint64_t)v59, &demangling cache variable for type metadata for AnnotatedFeature<MLShapedArray<Float>, String>);
        swift_bridgeObjectRelease();
        *(void *)(v44 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_labels) = specialized Set.init<A>(_:)(MLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm);
      }
    }
    else
    {
      MLSoundClassifier.DataSource.labeledSounds()();
      uint64_t v56 = specialized Sequence.flatMap<A>(_:)(v30);
      v57._rawValue = 0;
      swift_bridgeObjectRelease();
      uint64_t v31 = (int *)type metadata accessor for MLSoundClassifier.PersistentParameters();
      outlined init with copy of MLSoundClassifier.ModelParameters.ValidationData(a1 + v31[5], (uint64_t)v10, (void (*)(void))type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
      uint64_t v32 = *(void *)(a1 + v31[8]);
      uint64_t v33 = *(void *)(a1 + v31[6]);
      uint64_t v34 = a1 + v31[9];
      uint64_t v35 = *(void *)v34;
      int v55 = *(unsigned __int8 *)(v34 + 8);
      uint64_t v36 = &v14[v11[7]];
      *uint64_t v36 = 0u;
      v36[1] = 0u;
      uint64_t v37 = &v14[v11[8]];
      *(void *)uint64_t v37 = 0;
      v37[8] = 1;
      *(void *)&v14[v11[9]] = 32;
      outlined init with copy of MLSoundClassifier.ModelParameters.ValidationData((uint64_t)v10, (uint64_t)v14, (void (*)(void))type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
      *(void *)&v14[v11[5]] = v32;
      uint64_t v38 = v56;
      *(void *)&v14[v11[6]] = v33;
      char v63 = &type metadata for MLSoundClassifier.ModelParameters.ModelAlgorithmType;
      uint64_t v61 = v35;
      char v62 = v55;
      outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata((uint64_t)&v61, (uint64_t)v36, &demangling cache variable for type metadata for Any?);
      outlined destroy of MLSoundClassifier.Model((uint64_t)v10, (void (*)(void))type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
      outlined init with copy of MLSoundClassifier.ModelParameters.ValidationData((uint64_t)v14, (uint64_t)v5, (void (*)(void))type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
      outlined destroy of MLSoundClassifier.Model((uint64_t)v14, (void (*)(void))type metadata accessor for MLSoundClassifier.ModelParameters);
      *(_OWORD *)&uint64_t v39 = (unsigned __int128)MLSoundClassifier.ModelParameters.ValidationData.splitFiles(trainingData:)((Swift::OpaquePointer)v38);
      if (v41)
      {
        outlined destroy of MLSoundClassifier.Model((uint64_t)v5, (void (*)(void))type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
      }
      else
      {
        uint64_t v49 = v39;
        uint64_t v50 = v40;
        outlined destroy of MLSoundClassifier.Model((uint64_t)v5, (void (*)(void))type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
        if (v50) {
          uint64_t v51 = v50;
        }
        else {
          uint64_t v51 = MEMORY[0x263F8EE78];
        }
        uint64_t v52 = v58;
        specialized SoundClassifierTrainingSessionDelegate.populateFiles<A, B>(training:validation:parameters:)(v49, v51, a1);
        swift_bridgeObjectRelease();
        swift_bridgeObjectRelease();
        uint64_t v53 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm(v38, (uint64_t)v60, &demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
        swift_bridgeObjectRelease();
        *(void *)(v52 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_labels) = specialized Set.init<A>(_:)(v53);
      }
    }
    swift_bridgeObjectRelease();
  }
}

Swift::Void __swiftcall __spoils<CF,ZF,NF,VF,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13,X14,X15,X16,X17,X21,Q0,Q1,Q2,Q3,Q4,Q5,Q6,Q7,Q16,Q17,Q18,Q19,Q20,Q21,Q22,Q23,Q24,Q25,Q26,Q27,Q28,Q29,Q30,Q31> SoundClassifierTrainingSessionDelegate.resume(from:)(Swift::OpaquePointer from)
{
  OUTLINED_FUNCTION_9_0();
  uint64_t v87 = v3;
  uint64_t v5 = v2;
  uint64_t v7 = v6;
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.Classifier?);
  uint64_t v9 = OUTLINED_FUNCTION_17(v8);
  MEMORY[0x270FA5388](v9);
  OUTLINED_FUNCTION_107_0(v10, v77);
  uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.Model?);
  uint64_t v12 = OUTLINED_FUNCTION_17(v11);
  MEMORY[0x270FA5388](v12);
  OUTLINED_FUNCTION_33_0();
  uint64_t v83 = v13;
  uint64_t v85 = type metadata accessor for URL();
  OUTLINED_FUNCTION_0();
  uint64_t v80 = v14;
  MEMORY[0x270FA5388](v15);
  OUTLINED_FUNCTION_49();
  uint64_t v79 = v16;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v17);
  OUTLINED_FUNCTION_106();
  uint64_t v82 = v18;
  uint64_t v19 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
  uint64_t v20 = OUTLINED_FUNCTION_17(v19);
  MEMORY[0x270FA5388](v20);
  OUTLINED_FUNCTION_3_0();
  uint64_t v23 = v22 - v21;
  uint64_t v24 = type metadata accessor for MLSoundClassifier.PersistentParameters();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v25);
  OUTLINED_FUNCTION_105_0(v26, v77);
  uint64_t v27 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?);
  uint64_t v28 = OUTLINED_FUNCTION_17(v27);
  MEMORY[0x270FA5388](v28);
  OUTLINED_FUNCTION_49();
  uint64_t v81 = v29;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v30);
  OUTLINED_FUNCTION_115_0();
  uint64_t v31 = type metadata accessor for MLCheckpoint();
  OUTLINED_FUNCTION_0();
  uint64_t v33 = v32;
  MEMORY[0x270FA5388](v34);
  OUTLINED_FUNCTION_63();
  MEMORY[0x270FA5388](v35);
  OUTLINED_FUNCTION_45_3();
  uint64_t v78 = v36;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v37);
  uint64_t v39 = (char *)&v77 - v38;
  specialized BidirectionalCollection.last.getter(v7, v4);
  uint64_t v40 = OUTLINED_FUNCTION_165();
  OUTLINED_FUNCTION_57_4(v40, v41, v31);
  if (!v46)
  {
    uint64_t v86 = v39;
    outlined init with take of MLSoundClassifier.Model(v4, (uint64_t)v39, (void (*)(void))type metadata accessor for MLCheckpoint);
    uint64_t v43 = v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingParameters;
    OUTLINED_FUNCTION_53();
    outlined init with copy of URL?(v43, v23, &demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
    uint64_t v44 = OUTLINED_FUNCTION_133();
    OUTLINED_FUNCTION_57_4(v44, v45, v24);
    if (v46)
    {
      outlined destroy of URL?(v23, &demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
      __break(1u);
    }
    else
    {
      uint64_t v47 = v88;
      outlined init with take of MLSoundClassifier.Model(v23, v88, (void (*)(void))type metadata accessor for MLSoundClassifier.PersistentParameters);
      uint64_t v48 = v87;
      SoundClassifierTrainingSessionDelegate.populateFiles(parameters:)(v47);
      if (v48)
      {
        outlined destroy of MLSoundClassifier.Model(v47, (void (*)(void))type metadata accessor for MLSoundClassifier.PersistentParameters);
        uint64_t v50 = (uint64_t)v86;
LABEL_22:
        outlined destroy of MLSoundClassifier.Model(v50, (void (*)(void))type metadata accessor for MLCheckpoint);
        goto LABEL_23;
      }
      uint64_t v51 = (uint64_t)v86;
      int v52 = v86[*(int *)(v31 + 20)];
      if (v52 != 2)
      {
        uint64_t v53 = v88;
        if (v52 == 1)
        {
          SoundClassifierTrainingSessionDelegate.resumeFeatureExtraction(from:)((uint64_t)v86);
        }
        else
        {
          lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
          OUTLINED_FUNCTION_85();
          OUTLINED_FUNCTION_19_0(v63, 0xD00000000000003ELL);
        }
        outlined destroy of MLSoundClassifier.Model(v53, (void (*)(void))type metadata accessor for MLSoundClassifier.PersistentParameters);
        uint64_t v50 = v51;
        goto LABEL_22;
      }
      uint64_t v89 = v7;
      uint64_t v54 = *(void *)(v7 + 16);
      if (v54)
      {
        uint64_t v55 = *(void *)(v33 + 72);
        uint64_t v56 = v54 - 1;
        unint64_t v57 = v7
            + ((*(unsigned __int8 *)(v33 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v33 + 80))
            + v55 * (v54 - 1);
        uint64_t v58 = -v55;
        while (2)
        {
          uint64_t v59 = OUTLINED_FUNCTION_148();
          outlined init with copy of MLSoundClassifier.ModelParameters.ValidationData(v59, v60, v61);
          switch(*(unsigned char *)(v1 + *(int *)(v31 + 20)))
          {
            case 1:
              swift_bridgeObjectRelease();
              uint64_t v49 = outlined destroy of MLSoundClassifier.Model(v1, (void (*)(void))type metadata accessor for MLCheckpoint);
              break;
            case 2:
              OUTLINED_FUNCTION_155();
              goto LABEL_16;
            case 3:
              OUTLINED_FUNCTION_154();
              goto LABEL_16;
            case 4:
              OUTLINED_FUNCTION_55_0();
              goto LABEL_16;
            default:
LABEL_16:
              char v62 = OUTLINED_FUNCTION_87_0();
              swift_bridgeObjectRelease();
              uint64_t v49 = outlined destroy of MLSoundClassifier.Model(v1, (void (*)(void))type metadata accessor for MLCheckpoint);
              if (v62) {
                break;
              }
              --v56;
              v57 += v58;
              if (v56 != -1) {
                continue;
              }
              uint64_t v56 = 0;
              break;
          }
          break;
        }
      }
      else
      {
        uint64_t v56 = 0;
      }
      uint64_t v64 = v81;
      MEMORY[0x270FA5388](v49);
      *(&v77 - 2) = (uint64_t)&v89;
      _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5((void *(*)(void *__return_ptr, uint64_t *))partial apply for specialized closure #1 in BidirectionalCollection.last(where:), v56, v65 & 1, v64);
      OUTLINED_FUNCTION_57_4((uint64_t)v64, 1, v31);
      uint64_t v66 = v80;
      if (v46)
      {
        outlined destroy of URL?((uint64_t)v64, &demangling cache variable for type metadata for MLCheckpoint?);
      }
      else
      {
        uint64_t v67 = v78;
        outlined init with take of MLSoundClassifier.Model((uint64_t)v64, v78, (void (*)(void))type metadata accessor for MLCheckpoint);
        SoundClassifierTrainingSessionDelegate.resumeFeatureExtraction(from:)(v67);
        outlined destroy of MLSoundClassifier.Model(v67, (void (*)(void))type metadata accessor for MLCheckpoint);
      }
      uint64_t v69 = v83;
      uint64_t v68 = v84;
      OUTLINED_FUNCTION_144();
      URL.appendingPathComponent(_:)();
      URL.appendingPathExtension(_:)();
      long long v70 = *(void (**)(void))(v66 + 8);
      OUTLINED_FUNCTION_10_4();
      v70();
      uint64_t v71 = v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_classifier;
      OUTLINED_FUNCTION_53();
      outlined init with copy of URL?(v71, v68, &demangling cache variable for type metadata for MLSoundClassifier.Classifier?);
      uint64_t v72 = type metadata accessor for MLSoundClassifier.Classifier();
      uint64_t v73 = OUTLINED_FUNCTION_165();
      OUTLINED_FUNCTION_57_4(v73, v74, v72);
      if (!v46)
      {
        lazy protocol witness table accessor for type MLSoundClassifier.Classifier and conformance MLSoundClassifier.Classifier(&lazy protocol witness table cache variable for type MLSoundClassifier.Classifier and conformance MLSoundClassifier.Classifier, (void (*)(uint64_t))type metadata accessor for MLSoundClassifier.Classifier);
        OUTLINED_FUNCTION_148();
        UpdatableSupervisedEstimator.readWithOptimizer(from:)();
        OUTLINED_FUNCTION_10_4();
        v70();
        outlined destroy of MLSoundClassifier.Model(v88, (void (*)(void))type metadata accessor for MLSoundClassifier.PersistentParameters);
        outlined destroy of MLSoundClassifier.Model((uint64_t)v86, (void (*)(void))type metadata accessor for MLCheckpoint);
        outlined destroy of MLSoundClassifier.Model(v68, (void (*)(void))type metadata accessor for MLSoundClassifier.Classifier);
        uint64_t v75 = type metadata accessor for MLSoundClassifier.Model();
        __swift_storeEnumTagSinglePayload(v69, 0, 1, v75);
        uint64_t v76 = v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_model;
        OUTLINED_FUNCTION_81_2();
        outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v69, v76, &demangling cache variable for type metadata for MLSoundClassifier.Model?);
        swift_endAccess();
        goto LABEL_23;
      }
    }
    __break(1u);
    JUMPOUT(0x2270EBE74);
  }
  outlined destroy of URL?(v4, &demangling cache variable for type metadata for MLCheckpoint?);
  lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  OUTLINED_FUNCTION_85();
  OUTLINED_FUNCTION_19_0(v42, 0xD00000000000001DLL);
LABEL_23:
  OUTLINED_FUNCTION_8_1();
}

uint64_t SoundClassifierTrainingSessionDelegate.resumeFeatureExtraction(from:)(uint64_t a1)
{
  uint64_t v171 = a1;
  uint64_t v166 = type metadata accessor for CSVType();
  OUTLINED_FUNCTION_0();
  uint64_t v165 = v5;
  MEMORY[0x270FA5388](v6);
  OUTLINED_FUNCTION_33_0();
  OUTLINED_FUNCTION_17_3(v7);
  uint64_t v8 = type metadata accessor for CSVReadingOptions();
  uint64_t v9 = OUTLINED_FUNCTION_17(v8);
  MEMORY[0x270FA5388](v9);
  OUTLINED_FUNCTION_49();
  OUTLINED_FUNCTION_16_2();
  uint64_t v11 = MEMORY[0x270FA5388](v10);
  OUTLINED_FUNCTION_114_0(v11, v12, v13, v14, v15, v16, v17, v18, v143);
  uint64_t v19 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.Model?);
  uint64_t v20 = OUTLINED_FUNCTION_17(v19);
  MEMORY[0x270FA5388](v20);
  OUTLINED_FUNCTION_33_0();
  OUTLINED_FUNCTION_17_3(v21);
  uint64_t v22 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData();
  uint64_t v23 = OUTLINED_FUNCTION_17(v22);
  MEMORY[0x270FA5388](v23);
  OUTLINED_FUNCTION_33_0();
  OUTLINED_FUNCTION_17_3(v24);
  uint64_t v154 = type metadata accessor for MLSoundClassifier.ModelParameters();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v25);
  OUTLINED_FUNCTION_49();
  OUTLINED_FUNCTION_16_2();
  MEMORY[0x270FA5388](v26);
  OUTLINED_FUNCTION_106();
  uint64_t v156 = v27;
  uint64_t v28 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.Classifier?);
  uint64_t v29 = OUTLINED_FUNCTION_17(v28);
  MEMORY[0x270FA5388](v29);
  OUTLINED_FUNCTION_49();
  OUTLINED_FUNCTION_16_2();
  MEMORY[0x270FA5388](v30);
  OUTLINED_FUNCTION_106();
  uint64_t v157 = v31;
  uint64_t v32 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
  uint64_t v33 = OUTLINED_FUNCTION_17(v32);
  MEMORY[0x270FA5388](v33);
  OUTLINED_FUNCTION_49();
  OUTLINED_FUNCTION_16_2();
  MEMORY[0x270FA5388](v34);
  OUTLINED_FUNCTION_45_3();
  OUTLINED_FUNCTION_16_2();
  MEMORY[0x270FA5388](v35);
  OUTLINED_FUNCTION_45_3();
  OUTLINED_FUNCTION_16_2();
  MEMORY[0x270FA5388](v36);
  OUTLINED_FUNCTION_106();
  OUTLINED_FUNCTION_17_3(v37);
  uint64_t v177 = type metadata accessor for DataFrame();
  OUTLINED_FUNCTION_0();
  uint64_t v174 = v38;
  MEMORY[0x270FA5388](v39);
  OUTLINED_FUNCTION_49();
  OUTLINED_FUNCTION_16_2();
  MEMORY[0x270FA5388](v40);
  OUTLINED_FUNCTION_45_3();
  OUTLINED_FUNCTION_16_2();
  MEMORY[0x270FA5388](v41);
  OUTLINED_FUNCTION_45_3();
  OUTLINED_FUNCTION_16_2();
  MEMORY[0x270FA5388](v42);
  OUTLINED_FUNCTION_106();
  uint64_t v173 = v43;
  uint64_t v44 = type metadata accessor for URL();
  OUTLINED_FUNCTION_0();
  uint64_t v178 = v45;
  MEMORY[0x270FA5388](v46);
  OUTLINED_FUNCTION_49();
  OUTLINED_FUNCTION_16_2();
  MEMORY[0x270FA5388](v47);
  OUTLINED_FUNCTION_45_3();
  uint64_t v176 = v48;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v49);
  OUTLINED_FUNCTION_45_3();
  OUTLINED_FUNCTION_16_2();
  uint64_t v51 = MEMORY[0x270FA5388](v50);
  MEMORY[0x270FA5388](v51);
  OUTLINED_FUNCTION_45_3();
  uint64_t v179 = v52;
  OUTLINED_FUNCTION_20_3();
  uint64_t v54 = MEMORY[0x270FA5388](v53);
  MEMORY[0x270FA5388](v54);
  uint64_t v56 = (char *)&v143 - v55;
  uint64_t v57 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
  uint64_t v58 = OUTLINED_FUNCTION_17(v57);
  MEMORY[0x270FA5388](v58);
  uint64_t v59 = OUTLINED_FUNCTION_104_0();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v60);
  OUTLINED_FUNCTION_24_4();
  uint64_t v164 = v1;
  uint64_t v61 = v1 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingParameters;
  OUTLINED_FUNCTION_53();
  outlined init with copy of URL?(v61, v3, &demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
  uint64_t v153 = (int *)v59;
  OUTLINED_FUNCTION_57_4(v3, 1, v59);
  if (v62)
  {
    uint64_t result = outlined destroy of URL?(v3, &demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
    __break(1u);
  }
  else
  {
    uint64_t v175 = v4;
    outlined init with take of MLSoundClassifier.Model(v3, v4, (void (*)(void))type metadata accessor for MLSoundClassifier.PersistentParameters);
    OUTLINED_FUNCTION_123();
    URL.appendingPathComponent(_:)();
    OUTLINED_FUNCTION_145();
    URL.appendingPathExtension(_:)();
    uint64_t v63 = v178;
    uint64_t v64 = v178;
    char v65 = *(void (**)(void))(v178 + 8);
    OUTLINED_FUNCTION_21_4();
    v65();
    OUTLINED_FUNCTION_172();
    URL.appendingPathComponent(_:)();
    uint64_t v66 = v179;
    URL.appendingPathExtension(_:)();
    uint64_t v171 = v64 + 8;
    uint64_t v168 = v65;
    OUTLINED_FUNCTION_21_4();
    v65();
    uint64_t v69 = *(void (**)(void))(v63 + 16);
    uint64_t v68 = v63 + 16;
    uint64_t v67 = v69;
    uint64_t v70 = OUTLINED_FUNCTION_148();
    ((void (*)(uint64_t))v69)(v70);
    OUTLINED_FUNCTION_128();
    id v172 = v2;
    uint64_t v71 = v44;
    uint64_t v169 = v56;
    if (v2)
    {
      OUTLINED_FUNCTION_125();
      uint64_t v178 = v68;
      uint64_t v163 = v67;
      v67();
      uint64_t v72 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, CSVType)>);
      uint64_t v73 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (String, CSVType));
      uint64_t v170 = v44;
      uint64_t v74 = v73;
      OUTLINED_FUNCTION_57_5();
      uint64_t v76 = *(void *)(v75 + 72);
      uint64_t v78 = *(unsigned __int8 *)(v77 + 80);
      uint64_t v79 = (v78 + 32) & ~v78;
      uint64_t v151 = v72;
      uint64_t v149 = v79 + 2 * v76;
      uint64_t v148 = v78 | 7;
      uint64_t v80 = swift_allocObject();
      long long v146 = xmmword_2272CB4D0;
      *(_OWORD *)(v80 + 16) = xmmword_2272CB4D0;
      uint64_t v150 = v79;
      uint64_t v81 = (void *)(v80 + v79);
      *uint64_t v81 = 0x7365727574616566;
      v81[1] = 0xE800000000000000;
      uint64_t v82 = *(void (**)(void))(v165 + 104);
      int v147 = *MEMORY[0x263F1BF30];
      OUTLINED_FUNCTION_56_6();
      v82();
      uint64_t v162 = v76;
      uint64_t v83 = (void *)((char *)v81 + v76);
      uint64_t v165 = v74;
      *uint64_t v83 = 0x62614C7373616C63;
      v83[1] = 0xEA00000000006C65;
      int v145 = *MEMORY[0x263F1BF40];
      OUTLINED_FUNCTION_56_6();
      v82();
      Dictionary.init(dictionaryLiteral:)();
      default argument 1 of CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:)();
      specialized Set.init(_nonEmptyArrayLiteral:)((uint64_t)&outlined read-only object #0 of default argument 2 of CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:));
      specialized Set.init(_nonEmptyArrayLiteral:)((uint64_t)&outlined read-only object #0 of default argument 3 of CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:));
      int v144 = *MEMORY[0x263F1BF38];
      OUTLINED_FUNCTION_56_6();
      v82();
      OUTLINED_FUNCTION_157();
      CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:)();
      OUTLINED_FUNCTION_171();
      DataFrame.init(contentsOfCSVFile:columns:rows:types:options:)();
      uint64_t v176 = *(void *)(v174 + 32);
      OUTLINED_FUNCTION_3();
      v85();
      OUTLINED_FUNCTION_18_3();
      v86();
      uint64_t v87 = swift_allocObject();
      *(_OWORD *)(v87 + 16) = v146;
      uint64_t v88 = (void *)(v87 + v150);
      *uint64_t v88 = 0x7365727574616566;
      v88[1] = 0xE800000000000000;
      OUTLINED_FUNCTION_56_6();
      v82();
      uint64_t v89 = (void *)((char *)v88 + v162);
      *uint64_t v89 = 0x62614C7373616C63;
      v89[1] = 0xEA00000000006C65;
      OUTLINED_FUNCTION_56_6();
      v82();
      uint64_t v178 = Dictionary.init(dictionaryLiteral:)();
      default argument 1 of CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:)();
      specialized Set.init(_nonEmptyArrayLiteral:)((uint64_t)&outlined read-only object #0 of default argument 2 of CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:));
      specialized Set.init(_nonEmptyArrayLiteral:)((uint64_t)&outlined read-only object #0 of default argument 3 of CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:));
      OUTLINED_FUNCTION_56_6();
      v82();
      OUTLINED_FUNCTION_157();
      CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:)();
      uint64_t v90 = v161;
      OUTLINED_FUNCTION_171();
      DataFrame.init(contentsOfCSVFile:columns:rows:types:options:)();
      uint64_t v91 = v167;

      uint64_t v92 = v177;
      __swift_storeEnumTagSinglePayload(v90, 0, 1, v177);
      uint64_t v93 = v90;
      uint64_t v71 = v170;
      uint64_t v94 = v175;
    }
    else
    {
      uint64_t v93 = v66;
      uint64_t v176 = *(void *)(v174 + 32);
      OUTLINED_FUNCTION_3();
      v84();
      ((void (*)(uint64_t, uint64_t, uint64_t))v67)(v162, v66, v44);
      OUTLINED_FUNCTION_164();
      OUTLINED_FUNCTION_128();
      uint64_t v91 = v167;
      uint64_t v94 = v175;
      uint64_t v92 = v177;
      __swift_storeEnumTagSinglePayload(v66, 0, 1, v177);
    }
    outlined init with take of DataFrame?(v93, v91);
    static SoundClassifierTrainingSessionDelegate.loadDataFrame(_:)();
    uint64_t v96 = v95;
    uint64_t v170 = v71;
    uint64_t v97 = v164;
    uint64_t v98 = (void *)(v164 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingFeatures);
    swift_beginAccess();
    *uint64_t v98 = v96;
    swift_bridgeObjectRelease();
    uint64_t v99 = v160;
    outlined init with copy of URL?(v91, v160, &demangling cache variable for type metadata for DataFrame?);
    uint64_t v100 = OUTLINED_FUNCTION_133();
    OUTLINED_FUNCTION_57_4(v100, v101, v92);
    if (v62)
    {
      outlined destroy of URL?(v99, &demangling cache variable for type metadata for DataFrame?);
    }
    else
    {
      OUTLINED_FUNCTION_126();
      OUTLINED_FUNCTION_3();
      v102();
      static SoundClassifierTrainingSessionDelegate.loadDataFrame(_:)();
      uint64_t v104 = v103;
      OUTLINED_FUNCTION_9();
      v105();
      uint64_t v106 = (void *)(v97 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFeatures);
      swift_beginAccess();
      *uint64_t v106 = v104;
      swift_bridgeObjectRelease();
    }
    uint64_t v178 = *(void *)(v97 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_labels);
    uint64_t v107 = v153;
    uint64_t v108 = v94 + v153[5];
    uint64_t v109 = v94;
    uint64_t v110 = v158;
    outlined init with copy of MLSoundClassifier.ModelParameters.ValidationData(v108, v158, (void (*)(void))type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
    uint64_t v111 = *(void *)(v109 + v107[8]);
    uint64_t v112 = *(void *)(v109 + v107[6]);
    uint64_t v113 = v109 + v107[9];
    uint64_t v114 = *(void *)v113;
    char v115 = *(unsigned char *)(v113 + 8);
    uint64_t v116 = (int *)v154;
    uint64_t v117 = v155;
    uint64_t v118 = (_OWORD *)(v155 + *(int *)(v154 + 28));
    _OWORD *v118 = 0u;
    v118[1] = 0u;
    uint64_t v119 = v117 + v116[8];
    *(void *)uint64_t v119 = 0;
    *(unsigned char *)(v119 + 8) = 1;
    *(void *)(v117 + v116[9]) = 32;
    OUTLINED_FUNCTION_125();
    outlined init with copy of MLSoundClassifier.ModelParameters.ValidationData(v120, v121, v122);
    *(void *)(v117 + v116[5]) = v111;
    uint64_t v123 = v164;
    *(void *)(v117 + v116[6]) = v112;
    uint64_t v182 = &type metadata for MLSoundClassifier.ModelParameters.ModelAlgorithmType;
    uint64_t v180 = v114;
    char v181 = v115;
    uint64_t v124 = v178;
    swift_bridgeObjectRetain();
    outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata((uint64_t)&v180, (uint64_t)v118, &demangling cache variable for type metadata for Any?);
    outlined destroy of MLSoundClassifier.Model(v110, (void (*)(void))type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
    uint64_t v125 = v156;
    outlined init with take of MLSoundClassifier.Model(v117, v156, (void (*)(void))type metadata accessor for MLSoundClassifier.ModelParameters);
    uint64_t v126 = v157;
    MLSoundClassifier.Classifier.init(labels:parameters:)(v124, v125, v157);
    uint64_t v127 = type metadata accessor for MLSoundClassifier.Classifier();
    uint64_t v128 = OUTLINED_FUNCTION_166();
    __swift_storeEnumTagSinglePayload(v128, v129, v130, v131);
    uint64_t v132 = v123 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_classifier;
    OUTLINED_FUNCTION_81_2();
    outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v126, v132, &demangling cache variable for type metadata for MLSoundClassifier.Classifier?);
    swift_endAccess();
    uint64_t v133 = v159;
    outlined init with copy of URL?(v132, v159, &demangling cache variable for type metadata for MLSoundClassifier.Classifier?);
    uint64_t v134 = OUTLINED_FUNCTION_165();
    uint64_t result = OUTLINED_FUNCTION_57_4(v134, v135, v127);
    if (!v62)
    {
      MLSoundClassifier.Classifier.makeTransformer()(v152);
      outlined destroy of URL?(v167, &demangling cache variable for type metadata for DataFrame?);
      OUTLINED_FUNCTION_25_0();
      v137();
      OUTLINED_FUNCTION_129();
      uint64_t v138 = v168;
      OUTLINED_FUNCTION_11_3();
      v138();
      OUTLINED_FUNCTION_11_3();
      v138();
      outlined destroy of MLSoundClassifier.Model(v175, (void (*)(void))type metadata accessor for MLSoundClassifier.PersistentParameters);
      outlined destroy of MLSoundClassifier.Model(v133, (void (*)(void))type metadata accessor for MLSoundClassifier.Classifier);
      uint64_t v139 = type metadata accessor for MLSoundClassifier.Model();
      OUTLINED_FUNCTION_161(v139);
      OUTLINED_FUNCTION_81_2();
      uint64_t v140 = OUTLINED_FUNCTION_126();
      outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v140, v141, v142);
      return swift_endAccess();
    }
  }
  __break(1u);
  return result;
}

void static SoundClassifierTrainingSessionDelegate.loadDataFrame(_:)()
{
  OUTLINED_FUNCTION_9_0();
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Zip2Sequence<FilledColumn<Column<String>>, FilledColumn<Column<[Float]>>>);
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v2);
  OUTLINED_FUNCTION_33_0();
  uint64_t v22 = v3;
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Float]>);
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v4);
  OUTLINED_FUNCTION_40_0();
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FilledColumn<Column<[Float]>>);
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v5);
  OUTLINED_FUNCTION_107_0(v6, v21);
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v7);
  OUTLINED_FUNCTION_24_4();
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FilledColumn<Column<String>>);
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v8);
  OUTLINED_FUNCTION_10();
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Data>);
  OUTLINED_FUNCTION_0();
  uint64_t v23 = v10;
  MEMORY[0x270FA5388](v11);
  OUTLINED_FUNCTION_41_0();
  OUTLINED_FUNCTION_77_2();
  DataFrame.subscript.getter();
  OUTLINED_FUNCTION_61_3();
  DataFrame.subscript.getter();
  lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>((unint64_t *)&lazy protocol witness table cache variable for type Column<String> and conformance Column<A>, &demangling cache variable for type metadata for Column<String>);
  OptionalColumnProtocol.filled(with:)();
  uint64_t v12 = OUTLINED_FUNCTION_75();
  v13(v12);
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Float]);
  type metadata accessor for JSONDecoder();
  swift_allocObject();
  JSONDecoder.init()();
  lazy protocol witness table accessor for type [Float] and conformance <A> [A](&lazy protocol witness table cache variable for type [Float] and conformance <A> [A]);
  lazy protocol witness table accessor for type MLSoundClassifier.Classifier and conformance MLSoundClassifier.Classifier(&lazy protocol witness table cache variable for type JSONDecoder and conformance JSONDecoder, MEMORY[0x263F06128]);
  Column.decoded<A, B>(_:using:)();
  swift_release();
  if (v0)
  {
    OUTLINED_FUNCTION_21_4();
    v14();
    OUTLINED_FUNCTION_25_0();
    v15();
  }
  else
  {
    lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<[Float]> and conformance Column<A>, &demangling cache variable for type metadata for Column<[Float]>);
    OptionalColumnProtocol.filled(with:)();
    OUTLINED_FUNCTION_148();
    OUTLINED_FUNCTION_25_0();
    v16();
    OUTLINED_FUNCTION_18_3();
    v17();
    OUTLINED_FUNCTION_18_3();
    v18();
    _sSTsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFs12Zip2SequenceVy11TabularData12FilledColumnVyAH0I0VySSGGAJyALySaySfGGGG_18CreateMLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGs5NeverOTg5012_sSSSaySfG18j14MLComponents16lm3Vy6n4ML13pq2Vyu20GSSGIgggr_SS_AAtAIs5r68OIegnrzr_TR03_s8a80ML38SoundClassifierTrainingSessionDelegateC13loadg44FrameySay0A12MLComponents16cd4Vy04e4B013gh36zu7GSSGG07F37I00iJ0VKFZALSS_SayZ7GtXEfU_Tf3nnnpf_nTf1cn_n(v22);
    outlined destroy of URL?(v22, &demangling cache variable for type metadata for Zip2Sequence<FilledColumn<Column<String>>, FilledColumn<Column<[Float]>>>);
    OUTLINED_FUNCTION_24_5();
    v19();
    OUTLINED_FUNCTION_21_4();
    v20();
    (*(void (**)(uint64_t, uint64_t))(v23 + 8))(v1, v9);
  }
  OUTLINED_FUNCTION_8_1();
}

uint64_t specialized SoundClassifierTrainingSessionDelegate.populateFiles<A, B>(training:validation:parameters:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  double v7 = *(double *)(a3 + *(int *)(type metadata accessor for MLSoundClassifier.PersistentParameters() + 28));
  uint64_t v9 = specialized static MLSoundClassifier.filterFilesForFeatureExtractor<A>(labeledFiles:featureExtractionTimeWindowSize:)(a1, v7);
  swift_bridgeObjectRetain();
  specialized MutableCollection<>.sort(by:)(&v9);
  if (v4)
  {
    uint64_t result = swift_release();
    __break(1u);
  }
  else
  {
    swift_bridgeObjectRelease();
    *(void *)(v3 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingFiles) = v9;
    swift_bridgeObjectRelease();
    uint64_t v9 = specialized static MLSoundClassifier.filterFilesForFeatureExtractor<A>(labeledFiles:featureExtractionTimeWindowSize:)(a2, v7);
    swift_bridgeObjectRetain();
    specialized MutableCollection<>.sort(by:)(&v9);
    swift_bridgeObjectRelease();
    *(void *)(v3 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFiles) = v9;
    return swift_bridgeObjectRelease();
  }
  return result;
}

uint64_t key path getter for AnnotatedFeature.annotation : AnnotatedFeature<URL, String>@<X0>(void *a1@<X8>)
{
  return key path getter for AnnotatedFeature.annotation : AnnotatedFeature<MLShapedArray<Float>, String>(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>, a1);
}

uint64_t key path getter for AnnotatedFeature.annotation : AnnotatedFeature<MLShapedArray<Float>, String>@<X0>(uint64_t *a1@<X3>, void *a2@<X8>)
{
  __swift_instantiateConcreteTypeFromMangledName(a1);
  uint64_t result = AnnotatedFeature.annotation.getter();
  *a2 = v4;
  a2[1] = v5;
  return result;
}

uint64_t key path setter for AnnotatedFeature.annotation : AnnotatedFeature<URL, String>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return key path setter for AnnotatedFeature.annotation : AnnotatedFeature<MLShapedArray<Float>, String>(a1, a2, a3, a4, &demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
}

uint64_t key path setter for AnnotatedFeature.annotation : AnnotatedFeature<MLShapedArray<Float>, String>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t *a5)
{
  return AnnotatedFeature.annotation.setter();
}

uint64_t specialized static MLSoundClassifier.filterFilesForFeatureExtractor<A>(labeledFiles:featureExtractionTimeWindowSize:)(uint64_t a1, double a2)
{
  uint64_t v4 = type metadata accessor for URL();
  MEMORY[0x270FA5388](v4 - 8);
  uint64_t v6 = (char *)&v33 - ((v5 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
  uint64_t v8 = *(void *)(v7 - 8);
  uint64_t v9 = MEMORY[0x270FA5388](v7);
  uint64_t v37 = (char *)&v33 - ((v10 + 15) & 0xFFFFFFFFFFFFFFF0);
  MEMORY[0x270FA5388](v9);
  uint64_t v12 = (char *)&v33 - v11;
  uint64_t v41 = a1;
  swift_bridgeObjectRetain();
  specialized MutableCollection<>.sort(by:)(&v41);
  uint64_t v13 = *(void *)(v41 + 16);
  if (v13)
  {
    double v14 = a2 * 1000.0;
    uint64_t v17 = *(void (**)(char *, uint64_t, uint64_t))(v8 + 16);
    uint64_t v15 = v8 + 16;
    uint64_t v16 = v17;
    unint64_t v35 = (*(unsigned __int8 *)(v15 + 64) + 32) & ~(unint64_t)*(unsigned __int8 *)(v15 + 64);
    uint64_t v18 = v41 + v35;
    uint64_t v33 = v41;
    uint64_t v34 = (void (**)(unint64_t, char *, uint64_t))(v15 + 16);
    uint64_t v19 = (void (**)(char *, uint64_t))(v15 - 8);
    uint64_t v20 = *(void *)(v15 + 56);
    uint64_t v39 = MEMORY[0x263F8EE78];
    uint64_t v40 = v20;
    uint64_t v36 = v15;
    uint64_t v38 = (void (*)(char *, char *, uint64_t))v17;
    do
    {
      v16(v12, v18, v7);
      AnnotatedFeature.feature.getter();
      id v21 = objc_allocWithZone(MEMORY[0x263EF9380]);
      id v22 = @nonobjc AVAudioFile.init(forReading:)((uint64_t)v6);
      uint64_t v23 = v22;
      if (v22)
      {
        double v24 = (double)(uint64_t)objc_msgSend(v22, sel_length, v33) * 1000.0;
        id v25 = objc_msgSend(v23, sel_fileFormat);
        objc_msgSend(v25, sel_sampleRate);
        double v27 = v26;

        if (v14 <= v24 / v27)
        {
          v38(v37, v12, v7);
          if (swift_isUniquelyReferenced_nonNull_native())
          {
            uint64_t v28 = v39;
          }
          else
          {
            specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
            uint64_t v28 = v30;
          }
          unint64_t v29 = *(void *)(v28 + 16);
          if (v29 >= *(void *)(v28 + 24) >> 1)
          {
            specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
            uint64_t v28 = v31;
          }
          *(void *)(v28 + 16) = v29 + 1;
          uint64_t v39 = v28;
          (*v34)(v28 + v35 + v29 * v40, v37, v7);

          (*v19)(v12, v7);
        }
        else
        {
          (*v19)(v12, v7);
        }
        uint64_t v16 = (void (*)(char *, uint64_t, uint64_t))v38;
      }
      else
      {
        (*v19)(v12, v7);
      }
      v18 += v40;
      --v13;
    }
    while (v13);
    swift_release();
    return v39;
  }
  else
  {
    swift_release();
    return MEMORY[0x263F8EE78];
  }
}

Swift::Int_optional __swiftcall SoundClassifierTrainingSessionDelegate.itemCount(phase:)(CreateML::MLPhase phase)
{
  uint64_t v2 = *(unsigned __int8 *)phase;
  Swift::Int v3 = 1;
  Swift::Bool v4 = 0;
  switch(v2)
  {
    case 1:
      uint64_t v5 = *(void *)(*(void *)(v1 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingFiles)
                     + 16);
      uint64_t v6 = *(void *)(*(void *)(v1 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFiles)
                     + 16);
      Swift::Int v3 = v5 + v6;
      if (!__OFADD__(v5, v6)) {
        goto LABEL_7;
      }
      __break(1u);
      goto LABEL_6;
    case 2:
      break;
    case 3:
LABEL_6:
      Swift::Int v3 = 0;
LABEL_7:
      Swift::Bool v4 = 0;
      break;
    default:
      Swift::Int v3 = 0;
      Swift::Bool v4 = 1;
      break;
  }
  result.value = v3;
  result.is_nil = v4;
  return result;
}

Swift::tuple_Int_finished_Bool __swiftcall __spoils<CF,ZF,NF,VF,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13,X14,X15,X16,X17,X21,Q0,Q1,Q2,Q3,Q4,Q5,Q6,Q7,Q16,Q17,Q18,Q19,Q20,Q21,Q22,Q23,Q24,Q25,Q26,Q27,Q28,Q29,Q30,Q31> SoundClassifierTrainingSessionDelegate.extractFeatures(from:)(Swift::Int from)
{
  uint64_t v4 = v1;
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
  uint64_t v7 = OUTLINED_FUNCTION_17(v6);
  MEMORY[0x270FA5388](v7);
  uint64_t v8 = (int *)OUTLINED_FUNCTION_103_0();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v9);
  OUTLINED_FUNCTION_41_0();
  uint64_t v10 = v4 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingParameters;
  OUTLINED_FUNCTION_53();
  outlined init with copy of URL?(v10, v3, &demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
  OUTLINED_FUNCTION_57_4(v3, 1, (uint64_t)v8);
  if (v11) {
    goto LABEL_42;
  }
  outlined init with take of MLSoundClassifier.Model(v3, v2, (void (*)(void))type metadata accessor for MLSoundClassifier.PersistentParameters);
  Swift::Int v12 = *(void *)(*(void *)(v4 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingFiles)
                  + 16);
  uint64_t v3 = *(void *)(v4 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFiles);
  Swift::Int v13 = *(void *)(v3 + 16);
  Swift::Int v14 = v12 + v13;
  if (__OFADD__(v12, v13))
  {
    __break(1u);
    goto LABEL_32;
  }
  if (v14 > from)
  {
    uint64_t v15 = *(void *)(v2 + v8[6]);
    uint64_t v16 = *(void *)(v2 + v8[7]);
    uint64_t v17 = v2 + v8[9];
    uint64_t v40 = *(void *)v17;
    char v41 = *(unsigned char *)(v17 + 8);
    uint64_t v18 = v4 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_sessionParameters;
    uint64_t v19 = *(void *)(v18 + *(int *)(type metadata accessor for MLTrainingSessionParameters() + 20));
    BOOL v20 = __OFADD__(from, v19);
    Swift::Int v21 = from + v19;
    char v22 = v20;
    Swift::Int v23 = from - v12;
    if (from >= v12)
    {
      if ((v22 & 1) == 0)
      {
        if (v14 < v21) {
          Swift::Int v21 = v12 + v13;
        }
        Swift::Int v39 = v21;
        Swift::Int v32 = v21 - v12;
        if (!__OFSUB__(v21, v12))
        {
          if (v32 >= v23)
          {
            if (v13 >= v23)
            {
              if ((v23 & 0x8000000000000000) == 0)
              {
                if (v13 >= v32)
                {
                  uint64_t v33 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
                  OUTLINED_FUNCTION_39_0(v33);
                  uint64_t v35 = v3
                      + ((*(unsigned __int8 *)(v34 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v34 + 80));
                  *(void *)&long long v42 = v15;
                  *((void *)&v42 + 1) = v16;
                  Swift::Int v43 = v12;
                  Swift::Int v44 = v14;
                  uint64_t v45 = v40;
                  char v46 = v41;
                  type metadata accessor for MLSoundClassifier.FeatureExtractor();
                  swift_allocObject();
                  swift_bridgeObjectRetain();
                  uint64_t v36 = swift_unknownObjectRetain();
                  uint64_t v37 = v47;
                  specialized MLSoundClassifier.FeatureExtractor.init<A>(files:options:)(v36, v35, from - v12, (2 * v32) | 1, &v42);
                  if (v37)
                  {
LABEL_25:
                    swift_bridgeObjectRelease();
                    Swift::Int v30 = outlined destroy of MLSoundClassifier.Model(v2, (void (*)(void))type metadata accessor for MLSoundClassifier.PersistentParameters);
                    goto LABEL_26;
                  }
                  MLSoundClassifier.FeatureExtractor.extractFeatures()();
                  swift_bridgeObjectRelease();
                  swift_release();
                  Swift::Int v12 = v39;
                  goto LABEL_29;
                }
LABEL_40:
                __break(1u);
LABEL_41:
                __break(1u);
LABEL_42:
                Swift::Int v30 = outlined destroy of URL?(v3, &demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
                __break(1u);
                goto LABEL_43;
              }
LABEL_39:
              __break(1u);
              goto LABEL_40;
            }
LABEL_38:
            __break(1u);
            goto LABEL_39;
          }
LABEL_37:
          __break(1u);
          goto LABEL_38;
        }
        goto LABEL_35;
      }
LABEL_34:
      __break(1u);
LABEL_35:
      __break(1u);
LABEL_36:
      __break(1u);
      goto LABEL_37;
    }
    if ((v22 & 1) == 0)
    {
      if (v12 >= v21) {
        Swift::Int v12 = v21;
      }
      if (v12 >= from)
      {
        if ((from & 0x8000000000000000) == 0)
        {
          uint64_t v24 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
          OUTLINED_FUNCTION_39_0(v24);
          type metadata accessor for MLSoundClassifier.FeatureExtractor();
          swift_allocObject();
          swift_bridgeObjectRetain();
          swift_unknownObjectRetain();
          OUTLINED_FUNCTION_125();
          uint64_t v29 = specialized MLSoundClassifier.FeatureExtractor.init<A>(files:options:)(v25, v26, v27, (2 * v12) | 1, v28);
          if (v47) {
            goto LABEL_25;
          }
          uint64_t v3 = v29;
          MLSoundClassifier.FeatureExtractor.extractFeatures()();
          swift_bridgeObjectRelease();
          swift_release();
LABEL_29:
          OUTLINED_FUNCTION_81_2();
          specialized Array.append<A>(contentsOf:)();
          swift_endAccess();
          outlined destroy of MLSoundClassifier.Model(v2, (void (*)(void))type metadata accessor for MLSoundClassifier.PersistentParameters);
          Swift::Int v30 = v12 - from;
          if (!__OFSUB__(v12, from))
          {
            BOOL v31 = v12 >= v14;
            goto LABEL_26;
          }
          goto LABEL_41;
        }
        goto LABEL_36;
      }
      goto LABEL_33;
    }
LABEL_32:
    __break(1u);
LABEL_33:
    __break(1u);
    goto LABEL_34;
  }
  outlined destroy of MLSoundClassifier.Model(v2, (void (*)(void))type metadata accessor for MLSoundClassifier.PersistentParameters);
  Swift::Int v30 = 0;
  BOOL v31 = 1;
LABEL_26:
  Swift::Bool v38 = v31;
LABEL_43:
  result._0 = v30;
  result.finished = v38;
  return result;
}

uint64_t SoundClassifierTrainingSessionDelegate.train(from:)()
{
  OUTLINED_FUNCTION_11();
  v1[39] = v2;
  v1[40] = v0;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.Classifier?);
  OUTLINED_FUNCTION_17(v3);
  v1[41] = OUTLINED_FUNCTION_24();
  v1[42] = swift_task_alloc();
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.Model?);
  OUTLINED_FUNCTION_17(v4);
  v1[43] = OUTLINED_FUNCTION_24();
  v1[44] = swift_task_alloc();
  uint64_t v5 = type metadata accessor for TrainingTablePrinter(0);
  v1[45] = v5;
  OUTLINED_FUNCTION_1(v5);
  v1[46] = v6;
  v1[47] = *(void *)(v7 + 64);
  v1[48] = OUTLINED_FUNCTION_24();
  v1[49] = swift_task_alloc();
  v1[50] = swift_task_alloc();
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for TrainingTablePrinter?);
  OUTLINED_FUNCTION_17(v8);
  v1[51] = OUTLINED_FUNCTION_24();
  v1[52] = swift_task_alloc();
  v1[53] = swift_task_alloc();
  v1[54] = swift_task_alloc();
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
  OUTLINED_FUNCTION_17(v9);
  v1[55] = OUTLINED_FUNCTION_5();
  OUTLINED_FUNCTION_14();
  return MEMORY[0x270FA2498](v10, v11, v12);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  int EnumTagSinglePayload;
  uint64_t result;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  BOOL v11;
  uint64_t v12;
  char v13;
  uint64_t v14;
  BOOL v15;
  uint64_t v16;
  char v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  int v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v34;
  uint64_t v35;
  uint64_t v36;
  int v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t *v40;
  uint64_t v41;
  uint64_t v42;
  uint64_t v43;
  uint64_t v44;
  uint64_t v45;
  uint64_t *v46;
  uint64_t v47;
  uint64_t v48;
  uint64_t v49;
  uint64_t v50;
  uint64_t *v51;
  uint64_t v52;
  unint64_t v53;
  uint64_t v54;
  void *v55;
  uint64_t v56;
  uint64_t v57;
  uint64_t v58;
  uint64_t v59;
  uint64_t v60;
  uint64_t *v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  void (*v65)(void);
  unint64_t v66;
  uint64_t v67;
  void *v68;
  uint64_t v69;
  uint64_t (*v70)(uint64_t, uint64_t, uint64_t, uint64_t (*)(uint64_t), uint64_t);
  uint64_t (*v71)(uint64_t, uint64_t, uint64_t (*)(uint64_t), uint64_t);
  uint64_t v72;

  OUTLINED_FUNCTION_138();
  uint64_t v1 = *(void *)(v0 + 440);
  OUTLINED_FUNCTION_53();
  uint64_t v2 = OUTLINED_FUNCTION_0_5();
  outlined init with copy of URL?(v2, v3, &demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
  uint64_t v4 = type metadata accessor for MLSoundClassifier.PersistentParameters();
  EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v1, 1, v4);
  Swift::tuple_Int_finished_Bool result = outlined destroy of URL?(v1, &demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
  if (EnumTagSinglePayload == 1)
  {
    __break(1u);
LABEL_25:
    __break(1u);
LABEL_26:
    __break(1u);
    goto LABEL_27;
  }
  uint64_t v7 = *(void *)(v0 + 312);
  uint64_t v8 = *(void *)(v0 + 320);
  uint64_t v9 = v8 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_sessionParameters;
  Swift::tuple_Int_finished_Bool result = type metadata accessor for MLTrainingSessionParameters();
  uint64_t v10 = *(void *)(v9 + *(int *)(result + 20));
  *(void *)(v0 + 448) = v10;
  uint64_t v11 = __OFADD__(v7, v10);
  uint64_t v12 = v7 + v10;
  Swift::Int v13 = v11;
  *(void *)(v0 + 280) = v12;
  *(unsigned char *)(v0 + 288) = v13;
  if (v11) {
    goto LABEL_25;
  }
  uint64_t v14 = *(void *)(v9 + *(int *)(result + 28));
  *(void *)(v0 + 456) = v14;
  uint64_t v15 = __OFSUB__(v14, v7);
  uint64_t v16 = v14 - v7;
  uint64_t v17 = v15;
  *(void *)(v0 + 296) = v16;
  *(unsigned char *)(v0 + 304) = v17;
  if (v15) {
    goto LABEL_26;
  }
  uint64_t v18 = *(void *)(v0 + 432);
  uint64_t v19 = *(void *)(v0 + 360);
  type metadata accessor for EventCollector();
  swift_allocObject();
  BOOL v20 = EventCollector.init()();
  *(void *)(v0 + 464) = v20;
  Swift::Int v21 = v8 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_tablePrinter;
  OUTLINED_FUNCTION_111_0();
  OUTLINED_FUNCTION_53();
  outlined init with copy of URL?(v21, v18, &demangling cache variable for type metadata for TrainingTablePrinter?);
  char v22 = OUTLINED_FUNCTION_165();
  uint64_t v24 = __swift_getEnumTagSinglePayload(v22, v23, v19);
  outlined destroy of URL?(v18, &demangling cache variable for type metadata for TrainingTablePrinter?);
  if (v24 != 1) {
    goto LABEL_13;
  }
  uint64_t v26 = *(void *)(v0 + 416);
  uint64_t v25 = *(void *)(v0 + 424);
  uint64_t v27 = *(void *)(v0 + 360);
  uint64_t v28 = *(void *)(v0 + 320) + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFeatures;
  OUTLINED_FUNCTION_53();
  static MLSoundClassifier.createTablePrinter(hasValidation:)(*(void *)(*(void *)v28 + 16) != 0, v25);
  uint64_t v29 = OUTLINED_FUNCTION_166();
  __swift_storeEnumTagSinglePayload(v29, v30, v31, v32);
  OUTLINED_FUNCTION_111_0();
  OUTLINED_FUNCTION_81_2();
  outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v25, v21, &demangling cache variable for type metadata for TrainingTablePrinter?);
  swift_endAccess();
  outlined init with copy of URL?(v21, v26, &demangling cache variable for type metadata for TrainingTablePrinter?);
  Swift::tuple_Int_finished_Bool result = __swift_getEnumTagSinglePayload(v26, 1, v27);
  if (result == 1)
  {
LABEL_27:
    __break(1u);
LABEL_28:
    __break(1u);
    goto LABEL_29;
  }
  uint64_t v33 = *(void *)(v0 + 416);
  TrainingTablePrinter.beginTable()();
  outlined destroy of MLSoundClassifier.Model(v33, (void (*)(void))type metadata accessor for TrainingTablePrinter);
LABEL_13:
  uint64_t v34 = *(void *)(v0 + 360);
  outlined init with copy of URL?(v21, *(void *)(v0 + 408), &demangling cache variable for type metadata for TrainingTablePrinter?);
  uint64_t v35 = OUTLINED_FUNCTION_133();
  uint64_t v37 = __swift_getEnumTagSinglePayload(v35, v36, v34);
  Swift::Bool v38 = *(void *)(v0 + 408);
  if (v37 == 1)
  {
    outlined destroy of URL?(v38, &demangling cache variable for type metadata for TrainingTablePrinter?);
    return _assertionFailure(_:_:file:line:flags:)();
  }
  Swift::Int v39 = *(void *)(v0 + 320);
  outlined init with take of MLSoundClassifier.Model(v38, *(void *)(v0 + 400), (void (*)(void))type metadata accessor for TrainingTablePrinter);
  uint64_t v40 = (uint64_t *)(v39 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFeatures);
  OUTLINED_FUNCTION_53();
  char v41 = *v40;
  *(void *)(v0 + 472) = *v40;
  long long v42 = v39 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_classifier;
  if (*(void *)(v41 + 16))
  {
    Swift::Int v43 = *(void *)(v0 + 328);
    OUTLINED_FUNCTION_53();
    Swift::Int v44 = OUTLINED_FUNCTION_111_0();
    outlined init with copy of URL?(v44, v45, v46);
    uint64_t v47 = type metadata accessor for MLSoundClassifier.Classifier();
    Swift::tuple_Int_finished_Bool result = __swift_getEnumTagSinglePayload(v43, 1, v47);
    if (result != 1)
    {
      uint64_t v48 = *(void *)(v0 + 400);
      uint64_t v49 = *(void *)(v0 + 384);
      uint64_t v50 = *(void *)(v0 + 368);
      uint64_t v51 = (uint64_t *)(*(void *)(v0 + 320)
                      + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingFeatures);
      OUTLINED_FUNCTION_53();
      uint64_t v52 = *v51;
      *(void *)(v0 + 512) = v52;
      outlined init with copy of MLSoundClassifier.ModelParameters.ValidationData(v48, v49, (void (*)(void))type metadata accessor for TrainingTablePrinter);
      uint64_t v53 = (*(unsigned __int8 *)(v50 + 80) + 24) & ~(unint64_t)*(unsigned __int8 *)(v50 + 80);
      uint64_t v54 = swift_allocObject();
      *(void *)(v0 + 520) = v54;
      *(void *)(v54 + 16) = v20;
      outlined init with take of MLSoundClassifier.Model(v49, v54 + v53, (void (*)(void))type metadata accessor for TrainingTablePrinter);
      uint64_t v70 = (uint64_t (*)(uint64_t, uint64_t, uint64_t, uint64_t (*)(uint64_t), uint64_t))((char *)&async function pointer to specialized MLSoundClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:) + async function pointer to specialized MLSoundClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:));
      swift_retain();
      swift_bridgeObjectRetain();
      swift_bridgeObjectRetain();
      uint64_t v55 = (void *)swift_task_alloc();
      *(void *)(v0 + 528) = v55;
      *uint64_t v55 = v0;
      v55[1] = SoundClassifierTrainingSessionDelegate.train(from:);
      uint64_t v56 = *(void *)(v0 + 344);
      return v70(v56, v52, v41, partial apply for closure #2 in SoundClassifierTrainingSessionDelegate.train(from:), v54);
    }
    goto LABEL_28;
  }
  uint64_t v57 = *(void *)(v0 + 336);
  OUTLINED_FUNCTION_53();
  outlined init with copy of URL?(v42, v57, &demangling cache variable for type metadata for MLSoundClassifier.Classifier?);
  uint64_t v58 = type metadata accessor for MLSoundClassifier.Classifier();
  Swift::tuple_Int_finished_Bool result = __swift_getEnumTagSinglePayload(v57, 1, v58);
  if (result == 1)
  {
LABEL_29:
    __break(1u);
    return result;
  }
  uint64_t v59 = *(void *)(v0 + 392);
  uint64_t v60 = *(void *)(v0 + 368);
  uint64_t v61 = (uint64_t *)(*(void *)(v0 + 320)
                  + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingFeatures);
  OUTLINED_FUNCTION_53();
  char v62 = *v61;
  *(void *)(v0 + 480) = *v61;
  uint64_t v63 = OUTLINED_FUNCTION_111_0();
  outlined init with copy of MLSoundClassifier.ModelParameters.ValidationData(v63, v64, v65);
  uint64_t v66 = (*(unsigned __int8 *)(v60 + 80) + 24) & ~(unint64_t)*(unsigned __int8 *)(v60 + 80);
  uint64_t v67 = swift_allocObject();
  *(void *)(v0 + 488) = v67;
  *(void *)(v67 + 16) = v20;
  outlined init with take of MLSoundClassifier.Model(v59, v67 + v66, (void (*)(void))type metadata accessor for TrainingTablePrinter);
  uint64_t v71 = (uint64_t (*)(uint64_t, uint64_t, uint64_t (*)(uint64_t), uint64_t))((char *)&async function pointer to specialized MLSoundClassifier.Classifier.fitted<A>(to:eventHandler:)
                                                                                           + async function pointer to specialized MLSoundClassifier.Classifier.fitted<A>(to:eventHandler:));
  swift_bridgeObjectRetain();
  swift_retain();
  uint64_t v68 = (void *)swift_task_alloc();
  *(void *)(v0 + 496) = v68;
  *uint64_t v68 = v0;
  v68[1] = SoundClassifierTrainingSessionDelegate.train(from:);
  uint64_t v69 = *(void *)(v0 + 352);
  return v71(v69, v62, partial apply for closure #1 in SoundClassifierTrainingSessionDelegate.train(from:), v67);
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  uint64_t v3;
  void *v4;
  uint64_t v5;
  void *v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v11;

  OUTLINED_FUNCTION_60_0();
  OUTLINED_FUNCTION_2();
  uint64_t v3 = v2;
  OUTLINED_FUNCTION_7();
  *uint64_t v4 = v3;
  uint64_t v5 = *v1;
  OUTLINED_FUNCTION_6();
  *uint64_t v6 = v5;
  *(void *)(v3 + 504) = v0;
  swift_task_dealloc();
  swift_release();
  swift_bridgeObjectRelease();
  if (!v0) {
    outlined destroy of MLSoundClassifier.Model(*(void *)(v3 + 336), (void (*)(void))type metadata accessor for MLSoundClassifier.Classifier);
  }
  OUTLINED_FUNCTION_14();
  return MEMORY[0x270FA2498](v7, v8, v9);
}

{
  void *v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  void *v7;
  uint64_t v8;
  uint64_t v10;

  OUTLINED_FUNCTION_60_0();
  uint64_t v1 = v0[44];
  uint64_t v2 = v0[40];
  uint64_t v3 = type metadata accessor for MLSoundClassifier.Model();
  OUTLINED_FUNCTION_162(v3);
  uint64_t v4 = v2 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_model;
  OUTLINED_FUNCTION_81_2();
  outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v1, v4, &demangling cache variable for type metadata for MLSoundClassifier.Model?);
  swift_endAccess();
  OUTLINED_FUNCTION_49_0();
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  uint64_t v5 = swift_allocObject();
  *(_OWORD *)(v5 + 16) = xmmword_2272CB370;
  uint64_t v6 = MEMORY[0x263F8D750];
  *(void *)(v5 + 56) = MEMORY[0x263F8D6C8];
  *(void *)(v5 + 64) = v6;
  *(void *)(v5 + 32) = 3;
  OUTLINED_FUNCTION_119();
  swift_bridgeObjectRelease();
  uint64_t v7 = (void *)swift_task_alloc();
  v0[70] = v7;
  void *v7 = v0;
  v7[1] = SoundClassifierTrainingSessionDelegate.train(from:);
  uint64_t v8 = OUTLINED_FUNCTION_147();
  return SoundClassifierTrainingSessionDelegate.buildMetrics(eventCollector:)(v8);
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  uint64_t v3;
  void *v4;
  uint64_t v5;
  void *v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v11;

  OUTLINED_FUNCTION_25();
  OUTLINED_FUNCTION_2();
  uint64_t v3 = v2;
  OUTLINED_FUNCTION_7();
  *uint64_t v4 = v3;
  uint64_t v5 = *v1;
  OUTLINED_FUNCTION_6();
  *uint64_t v6 = v5;
  *(void *)(v3 + 536) = v0;
  swift_task_dealloc();
  swift_release();
  swift_bridgeObjectRelease();
  swift_bridgeObjectRelease();
  if (!v0) {
    outlined destroy of MLSoundClassifier.Model(*(void *)(v3 + 328), (void (*)(void))type metadata accessor for MLSoundClassifier.Classifier);
  }
  OUTLINED_FUNCTION_14();
  return MEMORY[0x270FA2498](v7, v8, v9);
}

{
  void *v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  void *v7;
  uint64_t v8;
  uint64_t v10;

  OUTLINED_FUNCTION_60_0();
  uint64_t v1 = v0[43];
  uint64_t v2 = v0[40];
  uint64_t v3 = type metadata accessor for MLSoundClassifier.Model();
  OUTLINED_FUNCTION_162(v3);
  uint64_t v4 = v2 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_model;
  OUTLINED_FUNCTION_81_2();
  outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v1, v4, &demangling cache variable for type metadata for MLSoundClassifier.Model?);
  swift_endAccess();
  OUTLINED_FUNCTION_49_0();
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  uint64_t v5 = swift_allocObject();
  *(_OWORD *)(v5 + 16) = xmmword_2272CB370;
  uint64_t v6 = MEMORY[0x263F8D750];
  *(void *)(v5 + 56) = MEMORY[0x263F8D6C8];
  *(void *)(v5 + 64) = v6;
  *(void *)(v5 + 32) = 3;
  OUTLINED_FUNCTION_119();
  swift_bridgeObjectRelease();
  uint64_t v7 = (void *)swift_task_alloc();
  v0[70] = v7;
  void *v7 = v0;
  v7[1] = SoundClassifierTrainingSessionDelegate.train(from:);
  uint64_t v8 = OUTLINED_FUNCTION_147();
  return SoundClassifierTrainingSessionDelegate.buildMetrics(eventCollector:)(v8);
}

{
  void *v0;
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v8;

  OUTLINED_FUNCTION_11();
  OUTLINED_FUNCTION_2();
  OUTLINED_FUNCTION_7();
  *uint64_t v2 = v1;
  *uint64_t v2 = *v0;
  *(void *)(v1 + 568) = v3;
  swift_task_dealloc();
  OUTLINED_FUNCTION_14();
  return MEMORY[0x270FA2498](v4, v5, v6);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t (*v2)(uint64_t, void *, BOOL);
  uint64_t v3;
  BOOL v4;
  void *v6;
  uint64_t v7;

  uint64_t v1 = *(void *)(v0 + 400);
  uint64_t v6 = specialized _dictionaryUpCast<A, B, C, D>(_:)(*(void **)(v0 + 568));
  swift_bridgeObjectRelease();
  swift_release();
  outlined destroy of MLSoundClassifier.Model(v1, (void (*)(void))type metadata accessor for TrainingTablePrinter);
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  uint64_t v2 = *(uint64_t (**)(uint64_t, void *, BOOL))(v0 + 8);
  uint64_t v3 = *(void *)(v0 + 544);
  uint64_t v4 = *(void *)(v0 + 552) >= *(void *)(v0 + 456);
  return v2(v3, v6, v4);
}

uint64_t SoundClassifierTrainingSessionDelegate.train(from:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16)
{
  OUTLINED_FUNCTION_37_4();
  OUTLINED_FUNCTION_113_0();
  OUTLINED_FUNCTION_176();
  uint64_t v18 = v16[42];
  uint64_t v29 = v16[44];
  uint64_t v30 = v16[43];
  uint64_t v31 = v16[41];
  uint64_t v32 = v19;
  swift_release();
  outlined destroy of MLSoundClassifier.Model(v17, (void (*)(void))type metadata accessor for TrainingTablePrinter);
  outlined destroy of MLSoundClassifier.Model(v18, (void (*)(void))type metadata accessor for MLSoundClassifier.Classifier);
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  OUTLINED_FUNCTION_169();
  OUTLINED_FUNCTION_3_24();
  return v21(v20, v21, v22, v23, v24, v25, v26, v27, a9, v29, v30, v31, v32, a14, a15, a16);
}

{
  void *v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t (*v21)(uint64_t, void, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t);
  uint64_t v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;

  OUTLINED_FUNCTION_37_4();
  OUTLINED_FUNCTION_113_0();
  OUTLINED_FUNCTION_176();
  uint64_t v29 = v16[44];
  uint64_t v30 = v16[43];
  uint64_t v18 = v16[41];
  uint64_t v31 = v16[42];
  uint64_t v32 = v19;
  swift_release();
  outlined destroy of MLSoundClassifier.Model(v17, (void (*)(void))type metadata accessor for TrainingTablePrinter);
  outlined destroy of MLSoundClassifier.Model(v18, (void (*)(void))type metadata accessor for MLSoundClassifier.Classifier);
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  OUTLINED_FUNCTION_169();
  OUTLINED_FUNCTION_3_24();
  return v21(v20, v21, v22, v23, v24, v25, v26, v27, a9, v29, v30, v31, v32, a14, a15, a16);
}

uint64_t specialized MLSoundClassifier.Classifier.fitted<A>(to:eventHandler:)()
{
  OUTLINED_FUNCTION_11();
  uint64_t v3 = v2;
  v1[5] = v4;
  v1[6] = v0;
  v1[3] = v5;
  v1[4] = v6;
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>);
  v1[7] = v7;
  OUTLINED_FUNCTION_1(v7);
  v1[8] = v8;
  v1[9] = OUTLINED_FUNCTION_5();
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifier<Float, String>);
  v1[10] = v9;
  OUTLINED_FUNCTION_1(v9);
  v1[11] = v10;
  v1[12] = OUTLINED_FUNCTION_5();
  uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>);
  v1[13] = v11;
  OUTLINED_FUNCTION_1(v11);
  v1[14] = v12;
  v1[15] = OUTLINED_FUNCTION_5();
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifier<Float, String>);
  v1[16] = v13;
  OUTLINED_FUNCTION_1(v13);
  v1[17] = v14;
  v1[18] = OUTLINED_FUNCTION_5();
  uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
  v1[19] = v15;
  OUTLINED_FUNCTION_17(v15);
  v1[20] = OUTLINED_FUNCTION_5();
  v1[2] = v3;
  OUTLINED_FUNCTION_14();
  return MEMORY[0x270FA2498](v16, v17, v18);
}

{
  void *v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  void (*v5)(void);
  void *v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  void (*v13)(void);
  void *v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v22;

  OUTLINED_FUNCTION_25();
  uint64_t v1 = v0 + 2;
  uint64_t v2 = v0[20];
  uint64_t v3 = v0[6];
  uint64_t v4 = type metadata accessor for MLSoundClassifier.Classifier();
  outlined init with copy of URL?(v3 + *(int *)(v4 + 20), v2, &demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
  if (OUTLINED_FUNCTION_97_0() == 1)
  {
    OUTLINED_FUNCTION_10_10();
    v5();
    uint64_t v6 = (void *)swift_task_alloc();
    v0[23] = v6;
    uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Float>, String>]);
    uint64_t v8 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [AnnotatedFeature<MLShapedArray<Float>, String>] and conformance [A], &demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Float>, String>]);
    *uint64_t v6 = v0;
    v6[1] = specialized MLSoundClassifier.Classifier.fitted<A>(to:eventHandler:);
    uint64_t v9 = v0[9];
    uint64_t v10 = v0[10];
    uint64_t v11 = v0[4];
    uint64_t v12 = v0[5];
    return MEMORY[0x270EEA8D8](v9, v1, v11, v12, v10, v7, v8);
  }
  else
  {
    OUTLINED_FUNCTION_10_10();
    v13();
    uint64_t v14 = (void *)swift_task_alloc();
    v0[21] = v14;
    uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Float>, String>]);
    uint64_t v16 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [AnnotatedFeature<MLShapedArray<Float>, String>] and conformance [A], &demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Float>, String>]);
    *uint64_t v14 = v0;
    v14[1] = specialized MLSoundClassifier.Classifier.fitted<A>(to:eventHandler:);
    uint64_t v17 = v0[15];
    uint64_t v18 = v0[16];
    uint64_t v19 = v0[4];
    uint64_t v20 = v0[5];
    return MEMORY[0x270EEA880](v17, v1, v19, v20, v18, v15, v16);
  }
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  void *v3;
  uint64_t v4;
  void *v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v11;

  OUTLINED_FUNCTION_11();
  OUTLINED_FUNCTION_2();
  OUTLINED_FUNCTION_7();
  *uint64_t v3 = v2;
  uint64_t v4 = *v1;
  OUTLINED_FUNCTION_6();
  *uint64_t v5 = v4;
  *(void *)(v6 + 176) = v0;
  swift_task_dealloc();
  OUTLINED_FUNCTION_14();
  return MEMORY[0x270FA2498](v7, v8, v9);
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  void *v3;
  uint64_t v4;
  void *v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v11;

  OUTLINED_FUNCTION_11();
  OUTLINED_FUNCTION_2();
  OUTLINED_FUNCTION_7();
  *uint64_t v3 = v2;
  uint64_t v4 = *v1;
  OUTLINED_FUNCTION_6();
  *uint64_t v5 = v4;
  *(void *)(v6 + 192) = v0;
  swift_task_dealloc();
  OUTLINED_FUNCTION_14();
  return MEMORY[0x270FA2498](v7, v8, v9);
}

{
  void (*v0)(void);
  uint64_t (*v1)(void);
  uint64_t v3;

  OUTLINED_FUNCTION_25();
  OUTLINED_FUNCTION_9();
  v0();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  OUTLINED_FUNCTION_30();
  return v1();
}

{
  void (*v0)(void);
  uint64_t (*v1)(void);
  uint64_t v3;

  OUTLINED_FUNCTION_25();
  OUTLINED_FUNCTION_9();
  v0();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  OUTLINED_FUNCTION_30();
  return v1();
}

uint64_t specialized MLSoundClassifier.Classifier.fitted<A>(to:eventHandler:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12)
{
  OUTLINED_FUNCTION_36_5();
  OUTLINED_FUNCTION_91_0();
  OUTLINED_FUNCTION_9();
  uint64_t v13 = v12();
  OUTLINED_FUNCTION_177(v13, v14, (void (*)(void))type metadata accessor for MLSoundClassifier.ModelParameters);
  uint64_t v15 = type metadata accessor for MLSoundClassifier.Model();
  uint64_t v16 = OUTLINED_FUNCTION_83_2(v15);
  v17(v16);
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  swift_storeEnumTagMultiPayload();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  OUTLINED_FUNCTION_12();
  OUTLINED_FUNCTION_38_6();
  return v19(v18, v19, v20, v21, v22, v23, v24, v25, a9, a10, a11, a12);
}

{
  uint64_t (*v12)(void);
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  void (*v17)(uint64_t);
  uint64_t v18;
  uint64_t (*v19)(uint64_t, void, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t);
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;

  OUTLINED_FUNCTION_36_5();
  OUTLINED_FUNCTION_91_0();
  OUTLINED_FUNCTION_9();
  uint64_t v13 = v12();
  OUTLINED_FUNCTION_177(v13, v14, (void (*)(void))type metadata accessor for MLSoundClassifier.ModelParameters);
  uint64_t v15 = type metadata accessor for MLSoundClassifier.Model();
  uint64_t v16 = OUTLINED_FUNCTION_82_2(v15);
  v17(v16);
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  swift_storeEnumTagMultiPayload();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  OUTLINED_FUNCTION_12();
  OUTLINED_FUNCTION_38_6();
  return v19(v18, v19, v20, v21, v22, v23, v24, v25, a9, a10, a11, a12);
}

uint64_t closure #2 in SoundClassifierTrainingSessionDelegate.train(from:)(uint64_t a1)
{
  return TrainingTablePrinter.print(_:)(a1);
}

uint64_t specialized MLSoundClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:)()
{
  OUTLINED_FUNCTION_60_0();
  uint64_t v3 = v2;
  uint64_t v5 = v4;
  v1[6] = v6;
  v1[7] = v0;
  v1[4] = v7;
  v1[5] = v8;
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>);
  v1[8] = v9;
  OUTLINED_FUNCTION_1(v9);
  v1[9] = v10;
  v1[10] = OUTLINED_FUNCTION_5();
  uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifier<Float, String>);
  v1[11] = v11;
  OUTLINED_FUNCTION_1(v11);
  v1[12] = v12;
  v1[13] = OUTLINED_FUNCTION_5();
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>);
  v1[14] = v13;
  OUTLINED_FUNCTION_1(v13);
  v1[15] = v14;
  v1[16] = OUTLINED_FUNCTION_5();
  uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifier<Float, String>);
  v1[17] = v15;
  OUTLINED_FUNCTION_1(v15);
  v1[18] = v16;
  v1[19] = OUTLINED_FUNCTION_5();
  uint64_t v17 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
  v1[20] = v17;
  OUTLINED_FUNCTION_17(v17);
  v1[21] = OUTLINED_FUNCTION_5();
  v1[2] = v5;
  v1[3] = v3;
  OUTLINED_FUNCTION_14();
  return MEMORY[0x270FA2498](v18, v19, v20);
}

{
  void *v0;
  void *v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  void (*v6)(void);
  void *v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  void (*v13)(void);
  void *v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v21;

  OUTLINED_FUNCTION_25();
  uint64_t v1 = v0 + 2;
  uint64_t v2 = v0 + 3;
  uint64_t v3 = v0[21];
  uint64_t v4 = v0[7];
  uint64_t v5 = type metadata accessor for MLSoundClassifier.Classifier();
  outlined init with copy of URL?(v4 + *(int *)(v5 + 20), v3, &demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
  OUTLINED_FUNCTION_111_0();
  if (swift_getEnumCaseMultiPayload() == 1)
  {
    OUTLINED_FUNCTION_10_10();
    v6();
    uint64_t v7 = (void *)swift_task_alloc();
    v0[24] = v7;
    uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Float>, String>]);
    lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [AnnotatedFeature<MLShapedArray<Float>, String>] and conformance [A], &demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Float>, String>]);
    void *v7 = v0;
    v7[1] = specialized MLSoundClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:);
    uint64_t v9 = v0[11];
    uint64_t v10 = v0[5];
    uint64_t v11 = v0[6];
    uint64_t v12 = v0[10];
    return MEMORY[0x270EEA8D0](v12, v1, v2, v10, v11, v9, v8, v8);
  }
  else
  {
    OUTLINED_FUNCTION_10_10();
    v13();
    uint64_t v14 = (void *)swift_task_alloc();
    v0[22] = v14;
    uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Float>, String>]);
    lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [AnnotatedFeature<MLShapedArray<Float>, String>] and conformance [A], &demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Float>, String>]);
    *uint64_t v14 = v0;
    v14[1] = specialized MLSoundClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:);
    uint64_t v16 = v0[17];
    uint64_t v17 = v0[5];
    uint64_t v18 = v0[6];
    uint64_t v19 = v0[16];
    return MEMORY[0x270EEA878](v19, v1, v2, v17, v18, v16, v15, v15);
  }
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  void *v3;
  uint64_t v4;
  void *v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v11;

  OUTLINED_FUNCTION_11();
  OUTLINED_FUNCTION_2();
  OUTLINED_FUNCTION_7();
  *uint64_t v3 = v2;
  uint64_t v4 = *v1;
  OUTLINED_FUNCTION_6();
  *uint64_t v5 = v4;
  *(void *)(v6 + 184) = v0;
  swift_task_dealloc();
  OUTLINED_FUNCTION_14();
  return MEMORY[0x270FA2498](v7, v8, v9);
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  void *v3;
  uint64_t v4;
  void *v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v11;

  OUTLINED_FUNCTION_11();
  OUTLINED_FUNCTION_2();
  OUTLINED_FUNCTION_7();
  *uint64_t v3 = v2;
  uint64_t v4 = *v1;
  OUTLINED_FUNCTION_6();
  *uint64_t v5 = v4;
  *(void *)(v6 + 200) = v0;
  swift_task_dealloc();
  OUTLINED_FUNCTION_14();
  return MEMORY[0x270FA2498](v7, v8, v9);
}

{
  void (*v0)(void);
  uint64_t (*v1)(void);
  uint64_t v3;

  OUTLINED_FUNCTION_25();
  OUTLINED_FUNCTION_9();
  v0();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  OUTLINED_FUNCTION_30();
  return v1();
}

{
  void (*v0)(void);
  uint64_t (*v1)(void);
  uint64_t v3;

  OUTLINED_FUNCTION_25();
  OUTLINED_FUNCTION_9();
  v0();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  OUTLINED_FUNCTION_30();
  return v1();
}

uint64_t specialized MLSoundClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12)
{
  OUTLINED_FUNCTION_36_5();
  OUTLINED_FUNCTION_91_0();
  OUTLINED_FUNCTION_9();
  uint64_t v13 = v12();
  OUTLINED_FUNCTION_177(v13, v14, (void (*)(void))type metadata accessor for MLSoundClassifier.ModelParameters);
  uint64_t v15 = type metadata accessor for MLSoundClassifier.Model();
  uint64_t v16 = OUTLINED_FUNCTION_83_2(v15);
  v17(v16);
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  swift_storeEnumTagMultiPayload();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  OUTLINED_FUNCTION_12();
  OUTLINED_FUNCTION_38_6();
  return v19(v18, v19, v20, v21, v22, v23, v24, v25, a9, a10, a11, a12);
}

{
  uint64_t (*v12)(void);
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  void (*v17)(uint64_t);
  uint64_t v18;
  uint64_t (*v19)(uint64_t, void, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t);
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;

  OUTLINED_FUNCTION_36_5();
  OUTLINED_FUNCTION_91_0();
  OUTLINED_FUNCTION_9();
  uint64_t v13 = v12();
  OUTLINED_FUNCTION_177(v13, v14, (void (*)(void))type metadata accessor for MLSoundClassifier.ModelParameters);
  uint64_t v15 = type metadata accessor for MLSoundClassifier.Model();
  uint64_t v16 = OUTLINED_FUNCTION_82_2(v15);
  v17(v16);
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  swift_storeEnumTagMultiPayload();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  OUTLINED_FUNCTION_12();
  OUTLINED_FUNCTION_38_6();
  return v19(v18, v19, v20, v21, v22, v23, v24, v25, a9, a10, a11, a12);
}

uint64_t SoundClassifierTrainingSessionDelegate.buildMetrics(eventCollector:)(uint64_t a1)
{
  v1[2] = a1;
  uint64_t v2 = type metadata accessor for MetricsKey();
  v1[3] = v2;
  v1[4] = *(void *)(v2 - 8);
  v1[5] = swift_task_alloc();
  return MEMORY[0x270FA2498](SoundClassifierTrainingSessionDelegate.buildMetrics(eventCollector:), 0, 0);
}

uint64_t SoundClassifierTrainingSessionDelegate.buildMetrics(eventCollector:)()
{
  OUTLINED_FUNCTION_91_0();
  uint64_t v3 = v0[4];
  uint64_t v2 = v0[5];
  uint64_t v4 = v0[3];
  static MetricsKey.trainingAccuracy.getter();
  specialized EventCollector.getLast<A>(metric:type:)();
  char v6 = v5;
  uint64_t v7 = *(void (**)(uint64_t, uint64_t))(v3 + 8);
  v7(v2, v4);
  uint64_t v8 = MEMORY[0x263F8EE80];
  if ((v6 & 1) == 0)
  {
    OUTLINED_FUNCTION_141();
    double v9 = OUTLINED_FUNCTION_67_2();
    specialized _NativeDictionary.setValue(_:forKey:isUnique:)(3, v10, v9);
    OUTLINED_FUNCTION_140();
  }
  OUTLINED_FUNCTION_118_0();
  static MetricsKey.validationAccuracy.getter();
  specialized EventCollector.getLast<A>(metric:type:)();
  uint64_t v11 = OUTLINED_FUNCTION_62_2();
  ((void (*)(uint64_t))v7)(v11);
  if ((v1 & 1) == 0)
  {
    OUTLINED_FUNCTION_141();
    double v12 = OUTLINED_FUNCTION_67_2();
    specialized _NativeDictionary.setValue(_:forKey:isUnique:)(5, v13, v12);
    OUTLINED_FUNCTION_140();
  }
  OUTLINED_FUNCTION_118_0();
  static MetricsKey.trainingLoss.getter();
  specialized EventCollector.getLast<A>(metric:type:)();
  uint64_t v14 = OUTLINED_FUNCTION_62_2();
  ((void (*)(uint64_t))v7)(v14);
  if ((v1 & 1) == 0)
  {
    OUTLINED_FUNCTION_141();
    double v15 = OUTLINED_FUNCTION_67_2();
    specialized _NativeDictionary.setValue(_:forKey:isUnique:)(0, v16, v15);
    OUTLINED_FUNCTION_140();
  }
  OUTLINED_FUNCTION_118_0();
  static MetricsKey.validationLoss.getter();
  specialized EventCollector.getLast<A>(metric:type:)();
  uint64_t v17 = OUTLINED_FUNCTION_62_2();
  ((void (*)(uint64_t))v7)(v17);
  if ((v1 & 1) == 0)
  {
    OUTLINED_FUNCTION_141();
    double v18 = OUTLINED_FUNCTION_67_2();
    specialized _NativeDictionary.setValue(_:forKey:isUnique:)(4, v19, v18);
    OUTLINED_FUNCTION_140();
  }
  swift_task_dealloc();
  uint64_t v20 = (uint64_t (*)(uint64_t))v0[1];
  return v20(v8);
}

uint64_t SoundClassifierTrainingSessionDelegate.evaluate(from:)()
{
  OUTLINED_FUNCTION_11();
  v1[50] = v0;
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ClassificationMetrics<String>);
  v1[51] = v2;
  OUTLINED_FUNCTION_1(v2);
  v1[52] = v3;
  v1[53] = OUTLINED_FUNCTION_5();
  uint64_t v4 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData();
  OUTLINED_FUNCTION_17(v4);
  v1[54] = OUTLINED_FUNCTION_5();
  uint64_t v5 = type metadata accessor for MLSoundClassifier.ModelParameters();
  v1[55] = v5;
  OUTLINED_FUNCTION_17(v5);
  v1[56] = OUTLINED_FUNCTION_24();
  v1[57] = swift_task_alloc();
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
  OUTLINED_FUNCTION_17(v6);
  v1[58] = OUTLINED_FUNCTION_5();
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLClassifierMetrics?);
  OUTLINED_FUNCTION_17(v7);
  v1[59] = OUTLINED_FUNCTION_5();
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.Model?);
  OUTLINED_FUNCTION_17(v8);
  v1[60] = OUTLINED_FUNCTION_5();
  uint64_t v9 = type metadata accessor for MLSoundClassifier.Model();
  v1[61] = v9;
  OUTLINED_FUNCTION_17(v9);
  v1[62] = OUTLINED_FUNCTION_5();
  OUTLINED_FUNCTION_14();
  return MEMORY[0x270FA2498](v10, v11, v12);
}

{
  void *v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t *v5;
  uint64_t (*v6)(void, uint64_t);
  uint64_t v8;
  uint64_t v9;
  void *v10;
  void *v11;
  uint64_t (__cdecl *v12)();
  uint64_t v13;

  char v1 = v0[60];
  uint64_t v2 = v0[61];
  OUTLINED_FUNCTION_53();
  uint64_t v3 = OUTLINED_FUNCTION_173();
  outlined init with copy of URL?(v3, v4, v5);
  if (__swift_getEnumTagSinglePayload(v1, 1, v2) == 1)
  {
    outlined destroy of URL?(v0[60], &demangling cache variable for type metadata for MLSoundClassifier.Model?);
    OUTLINED_FUNCTION_78_2();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    uint64_t v6 = (uint64_t (*)(void, uint64_t))v0[1];
    return v6(0, 1);
  }
  else
  {
    uint64_t v8 = v0[50];
    outlined init with take of MLSoundClassifier.Model(v0[60], v0[62], (void (*)(void))type metadata accessor for MLSoundClassifier.Model);
    uint64_t v9 = OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingFeatures;
    v0[63] = OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingFeatures;
    uint64_t v10 = (void *)(v8 + v9);
    OUTLINED_FUNCTION_0_5();
    OUTLINED_FUNCTION_53();
    v0[64] = *v10;
    uint64_t v12 = (uint64_t (__cdecl *)())((char *)&async function pointer to specialized Transformer.prediction<A, B>(from:eventHandler:)
                                + async function pointer to specialized Transformer.prediction<A, B>(from:eventHandler:));
    swift_bridgeObjectRetain();
    uint64_t v11 = (void *)swift_task_alloc();
    v0[65] = v11;
    *uint64_t v11 = v0;
    v11[1] = SoundClassifierTrainingSessionDelegate.evaluate(from:);
    OUTLINED_FUNCTION_14();
    return v12();
  }
}

{
  uint64_t v0;
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  void *v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v10;

  OUTLINED_FUNCTION_25();
  OUTLINED_FUNCTION_55_5();
  uint64_t v4 = v3;
  OUTLINED_FUNCTION_6();
  *uint64_t v5 = v4;
  *uint64_t v5 = *v2;
  *(void *)(v4 + 528) = v0;
  swift_task_dealloc();
  swift_bridgeObjectRelease();
  if (!v0) {
    *(void *)(v4 + 536) = v1;
  }
  OUTLINED_FUNCTION_14();
  return MEMORY[0x270FA2498](v6, v7, v8);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t MLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t *v10;
  uint64_t v11;
  uint64_t v12;
  void *v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t *v17;
  uint64_t v18;
  void *v19;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t *v25;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  int *v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t result;
  uint64_t v34;
  uint64_t v35;
  int *v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  _OWORD *v42;
  uint64_t v43;
  uint64_t v44;
  uint64_t v45;
  uint64_t v46;
  double v47;
  uint64_t v48;
  uint64_t v49;
  char v50;
  uint64_t v51;
  uint64_t v52;
  uint64_t v54;
  void *v55;
  uint64_t v56;
  char v57;
  uint64_t v58;
  uint64_t v59;

  char v1 = *(void *)(v0 + 528);
  uint64_t v2 = *(void *)(v0 + 472);
  uint64_t v3 = *(void *)(v0 + 400);
  MLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm(*(void *)(v0 + 536), v0 + 384, &demangling cache variable for type metadata for AnnotatedPrediction<ClassificationDistribution<String>, String>);
  swift_bridgeObjectRelease();
  *(void *)(v0 + 376) = MLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm;
  uint64_t v5 = swift_bridgeObjectRetain();
  uint64_t v6 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm(v5, v0 + 368, &demangling cache variable for type metadata for AnnotatedFeature<MLShapedArray<Float>, String>);
  swift_bridgeObjectRelease();
  *(void *)(v0 + 360) = v6;
  *(void *)(v0 + 544) = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String]);
  *(void *)(v0 + 552) = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [String] and conformance [A], &demangling cache variable for type metadata for [String]);
  OUTLINED_FUNCTION_42_4();
  ClassificationMetrics.init<A, B>(_:_:)();
  *(void *)(v0 + 560) = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
  swift_storeEnumTagMultiPayload();
  *(void *)(v0 + 568) = type metadata accessor for MLClassifierMetrics.Contents(0);
  swift_storeEnumTagMultiPayload();
  uint64_t v7 = type metadata accessor for MLClassifierMetrics(0);
  *(void *)(v0 + 576) = v7;
  __swift_storeEnumTagSinglePayload(v2, 0, 1, v7);
  OUTLINED_FUNCTION_81_2();
  uint64_t v8 = OUTLINED_FUNCTION_160();
  outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v8, v9, v10);
  swift_endAccess();
  uint64_t v11 = OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFiles;
  uint64_t v59 = v3;
  uint64_t v12 = *(void *)(v3 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFiles);
  char v13 = &unk_268176000;
  if (!*(void *)(v12 + 16)) {
    goto LABEL_3;
  }
  uint64_t v14 = *(void *)(v0 + 400) + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFeatures;
  swift_beginAccess();
  if (*(void *)(*(void *)v14 + 16)) {
    goto LABEL_3;
  }
  uint64_t v55 = (void *)v14;
  uint64_t v58 = v1;
  uint64_t v28 = *(void *)(v0 + 464);
  uint64_t v29 = *(void *)(v0 + 400) + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingParameters;
  OUTLINED_FUNCTION_53();
  outlined init with copy of URL?(v29, v28, &demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
  uint64_t v30 = (int *)type metadata accessor for MLSoundClassifier.PersistentParameters();
  uint64_t v31 = OUTLINED_FUNCTION_133();
  Swift::tuple_Int_finished_Bool result = __swift_getEnumTagSinglePayload(v31, v32, (uint64_t)v30);
  if (result != 1)
  {
    uint64_t v34 = *(void *)(v0 + 456);
    uint64_t v35 = *(void *)(v0 + 464);
    uint64_t v36 = *(int **)(v0 + 440);
    uint64_t v37 = *(void *)(v0 + 448);
    Swift::Bool v38 = *(void *)(v0 + 432);
    outlined init with copy of MLSoundClassifier.ModelParameters.ValidationData(v35 + v30[5], v38, (void (*)(void))type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
    Swift::Int v39 = *(void *)(v35 + v30[8]);
    uint64_t v40 = *(void *)(v35 + v30[6]);
    char v41 = v35 + v30[9];
    uint64_t v56 = *(void *)v41;
    uint64_t v57 = *(unsigned char *)(v41 + 8);
    long long v42 = (_OWORD *)(v37 + v36[7]);
    *long long v42 = 0u;
    v42[1] = 0u;
    OUTLINED_FUNCTION_134(v37 + v36[8]);
    *(void *)(v37 + v43) = v44;
    outlined init with copy of MLSoundClassifier.ModelParameters.ValidationData(v38, v37, (void (*)(void))type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
    *(void *)(v37 + v36[5]) = v39;
    *(void *)(v37 + v36[6]) = v40;
    *(void *)(v0 + 88) = &type metadata for MLSoundClassifier.ModelParameters.ModelAlgorithmType;
    *(void *)(v0 + 64) = v56;
    *(unsigned char *)(v0 + 72) = v57;
    swift_bridgeObjectRetain();
    outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v0 + 64, (uint64_t)v42, &demangling cache variable for type metadata for Any?);
    outlined destroy of MLSoundClassifier.Model(v38, (void (*)(void))type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
    outlined init with take of MLSoundClassifier.Model(v37, v34, (void (*)(void))type metadata accessor for MLSoundClassifier.ModelParameters);
    outlined destroy of MLSoundClassifier.Model(v35, (void (*)(void))type metadata accessor for MLSoundClassifier.PersistentParameters);
    uint64_t v45 = *(void *)(*(void *)(v59 + v11) + 16);
    char v46 = *(void *)(v34 + v36[6]);
    uint64_t v47 = MLSoundClassifier.ModelParameters.featureExtractionTimeWindowSize.getter();
    outlined init with copy of URL?(v34 + v36[7], v0 + 96, &demangling cache variable for type metadata for Any?);
    if (*(void *)(v0 + 120))
    {
      uint64_t v48 = v58;
      if (swift_dynamicCast())
      {
        uint64_t v49 = *(void *)(v0 + 320);
        uint64_t v50 = *(unsigned char *)(v0 + 328);
      }
      else
      {
        uint64_t v49 = 1;
        uint64_t v50 = 1;
      }
    }
    else
    {
      outlined destroy of URL?(v0 + 96, &demangling cache variable for type metadata for Any?);
      uint64_t v49 = 1;
      uint64_t v50 = 1;
      uint64_t v48 = v58;
    }
    outlined destroy of MLSoundClassifier.Model(*(void *)(v0 + 456), (void (*)(void))type metadata accessor for MLSoundClassifier.ModelParameters);
    *(void *)(v0 + 16) = v46;
    *(double *)(v0 + 24) = v47;
    *(void *)(v0 + 32) = 0;
    *(void *)(v0 + 40) = v45;
    *(void *)(v0 + 48) = v49;
    *(unsigned char *)(v0 + 56) = v50;
    type metadata accessor for MLSoundClassifier.FeatureExtractor();
    swift_allocObject();
    uint64_t v51 = swift_bridgeObjectRetain();
    specialized MLSoundClassifier.FeatureExtractor.init<A>(files:options:)(v51, (_OWORD *)(v0 + 16));
    if (v48)
    {
      swift_bridgeObjectRelease();
      outlined destroy of MLSoundClassifier.Model(*(void *)(v0 + 496), (void (*)(void))type metadata accessor for MLSoundClassifier.Model);
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      OUTLINED_FUNCTION_127();
      OUTLINED_FUNCTION_92_0();
      __asm { BRAA            X2, X16 }
    }
    uint64_t v52 = MLSoundClassifier.FeatureExtractor.extractFeatures()();
    swift_release();
    swift_bridgeObjectRelease();
    *uint64_t v55 = v52;
    swift_bridgeObjectRelease();
    char v13 = (void *)&unk_268176000;
LABEL_3:
    double v15 = *(void *)(v0 + 400);
    char v16 = v13[434];
    *(void *)(v0 + 584) = v16;
    uint64_t v17 = (uint64_t *)(v15 + v16);
    OUTLINED_FUNCTION_53();
    double v18 = *v17;
    *(void *)(v0 + 592) = *v17;
    if (*(void *)(v18 + 16))
    {
      swift_bridgeObjectRetain();
      char v19 = (void *)swift_task_alloc();
      *(void *)(v0 + 600) = v19;
      *char v19 = v0;
      v19[1] = SoundClassifierTrainingSessionDelegate.evaluate(from:);
      OUTLINED_FUNCTION_14();
      OUTLINED_FUNCTION_92_0();
      __asm { BR              X3 }
    }
    uint64_t v22 = *(void *)(v0 + 472);
    outlined destroy of MLSoundClassifier.Model(*(void *)(v0 + 496), (void (*)(void))type metadata accessor for MLSoundClassifier.Model);
    __swift_storeEnumTagSinglePayload(v22, 1, 1, v7);
    OUTLINED_FUNCTION_0_5();
    OUTLINED_FUNCTION_81_2();
    uint64_t v23 = OUTLINED_FUNCTION_173();
    outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v23, v24, v25);
    swift_endAccess();
    OUTLINED_FUNCTION_78_2();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    OUTLINED_FUNCTION_135();
    OUTLINED_FUNCTION_92_0();
    __asm { BRAA            X3, X16 }
  }
  __break(1u);
  return result;
}

{
  uint64_t v0;
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  void *v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v10;

  OUTLINED_FUNCTION_25();
  OUTLINED_FUNCTION_55_5();
  uint64_t v4 = v3;
  OUTLINED_FUNCTION_6();
  *uint64_t v5 = v4;
  *uint64_t v5 = *v2;
  *(void *)(v4 + 608) = v0;
  swift_task_dealloc();
  swift_bridgeObjectRelease();
  if (!v0) {
    *(void *)(v4 + 616) = v1;
  }
  OUTLINED_FUNCTION_14();
  return MEMORY[0x270FA2498](v6, v7, v8);
}

{
  void *v0;
  uint64_t v1;
  uint64_t MLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  void (*v6)(uint64_t);
  uint64_t v7;
  uint64_t v8;
  uint64_t *v9;
  uint64_t v10;
  uint64_t (*v11)(uint64_t);
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;

  uint64_t v14 = v0[72];
  char v1 = v0[59];
  char v13 = v0[62];
  MLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm(v0[77], (uint64_t)(v0 + 49), &demangling cache variable for type metadata for AnnotatedPrediction<ClassificationDistribution<String>, String>);
  swift_bridgeObjectRelease();
  v0[44] = MLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm;
  uint64_t v3 = swift_bridgeObjectRetain();
  uint64_t v4 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm(v3, (uint64_t)(v0 + 42), &demangling cache variable for type metadata for AnnotatedFeature<MLShapedArray<Float>, String>);
  swift_bridgeObjectRelease();
  v0[43] = v4;
  ClassificationMetrics.init<A, B>(_:_:)();
  outlined destroy of MLSoundClassifier.Model(v13, (void (*)(void))type metadata accessor for MLSoundClassifier.Model);
  uint64_t v5 = OUTLINED_FUNCTION_0_5();
  v6(v5);
  swift_storeEnumTagMultiPayload();
  swift_storeEnumTagMultiPayload();
  __swift_storeEnumTagSinglePayload(v1, 0, 1, v14);
  OUTLINED_FUNCTION_81_2();
  uint64_t v7 = OUTLINED_FUNCTION_0_5();
  outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v7, v8, v9);
  swift_endAccess();
  OUTLINED_FUNCTION_78_2();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  uint64_t v10 = OUTLINED_FUNCTION_135();
  return v11(v10);
}

uint64_t SoundClassifierTrainingSessionDelegate.evaluate(from:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12)
{
  OUTLINED_FUNCTION_36_5();
  OUTLINED_FUNCTION_91_0();
  OUTLINED_FUNCTION_116();
  outlined destroy of MLSoundClassifier.Model(v12, (void (*)(void))type metadata accessor for MLSoundClassifier.Model);
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  OUTLINED_FUNCTION_127();
  OUTLINED_FUNCTION_38_6();
  return v15(v13, v14, v15, v16, v17, v18, v19, v20, a9, a10, a11, a12);
}

{
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t (*v15)(uint64_t, uint64_t, void, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t);
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;

  OUTLINED_FUNCTION_36_5();
  OUTLINED_FUNCTION_91_0();
  OUTLINED_FUNCTION_116();
  outlined destroy of MLSoundClassifier.Model(v12, (void (*)(void))type metadata accessor for MLSoundClassifier.Model);
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  OUTLINED_FUNCTION_127();
  OUTLINED_FUNCTION_38_6();
  return v15(v13, v14, v15, v16, v17, v18, v19, v20, a9, a10, a11, a12);
}

uint64_t specialized Transformer.prediction<A, B>(from:eventHandler:)()
{
  OUTLINED_FUNCTION_11();
  v1[6] = v2;
  v1[7] = v0;
  v1[4] = v3;
  v1[5] = v4;
  uint64_t v5 = type metadata accessor for MLSoundClassifier.Model();
  v1[8] = v5;
  OUTLINED_FUNCTION_17(v5);
  v1[9] = OUTLINED_FUNCTION_5();
  uint64_t v6 = type metadata accessor for Event();
  v1[10] = v6;
  OUTLINED_FUNCTION_1(v6);
  v1[11] = v7;
  v1[12] = OUTLINED_FUNCTION_5();
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedPrediction<ClassificationDistribution<String>, String>);
  v1[13] = v8;
  OUTLINED_FUNCTION_1(v8);
  v1[14] = v9;
  v1[15] = OUTLINED_FUNCTION_5();
  uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>);
  v1[16] = v10;
  OUTLINED_FUNCTION_1(v10);
  v1[17] = v11;
  v1[18] = OUTLINED_FUNCTION_5();
  uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>);
  v1[19] = v12;
  OUTLINED_FUNCTION_1(v12);
  v1[20] = v13;
  v1[21] = OUTLINED_FUNCTION_5();
  uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  v1[22] = v14;
  OUTLINED_FUNCTION_17(v14);
  v1[23] = OUTLINED_FUNCTION_5();
  uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Float>);
  v1[24] = v15;
  OUTLINED_FUNCTION_1(v15);
  v1[25] = v16;
  v1[26] = OUTLINED_FUNCTION_5();
  uint64_t v17 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ClassificationDistribution<String>);
  v1[27] = v17;
  OUTLINED_FUNCTION_1(v17);
  v1[28] = v18;
  v1[29] = OUTLINED_FUNCTION_24();
  v1[30] = swift_task_alloc();
  uint64_t v19 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<MLShapedArray<Float>, String>);
  v1[31] = v19;
  OUTLINED_FUNCTION_1(v19);
  v1[32] = v20;
  v1[33] = OUTLINED_FUNCTION_5();
  OUTLINED_FUNCTION_14();
  return MEMORY[0x270FA2498](v21, v22, v23);
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  void *v3;
  uint64_t v4;
  void *v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v11;

  OUTLINED_FUNCTION_11();
  OUTLINED_FUNCTION_2();
  OUTLINED_FUNCTION_7();
  *uint64_t v3 = v2;
  uint64_t v4 = *v1;
  OUTLINED_FUNCTION_6();
  *uint64_t v5 = v4;
  *(void *)(v6 + 320) = v0;
  swift_task_dealloc();
  OUTLINED_FUNCTION_14();
  return MEMORY[0x270FA2498](v7, v8, v9);
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  void *v3;
  uint64_t v4;
  void *v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v11;

  OUTLINED_FUNCTION_11();
  OUTLINED_FUNCTION_2();
  OUTLINED_FUNCTION_7();
  *uint64_t v3 = v2;
  uint64_t v4 = *v1;
  OUTLINED_FUNCTION_6();
  *uint64_t v5 = v4;
  *(void *)(v6 + 336) = v0;
  swift_task_dealloc();
  OUTLINED_FUNCTION_14();
  return MEMORY[0x270FA2498](v7, v8, v9);
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t v25;

  OUTLINED_FUNCTION_11();
  v1[6] = v2;
  v1[7] = v0;
  v1[4] = v3;
  v1[5] = v4;
  uint64_t v5 = type metadata accessor for MLImageClassifier.Model();
  v1[8] = v5;
  OUTLINED_FUNCTION_17(v5);
  v1[9] = OUTLINED_FUNCTION_5();
  uint64_t v6 = type metadata accessor for Event();
  v1[10] = v6;
  OUTLINED_FUNCTION_1(v6);
  v1[11] = v7;
  v1[12] = OUTLINED_FUNCTION_5();
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedPrediction<ClassificationDistribution<String>, String>);
  v1[13] = v8;
  OUTLINED_FUNCTION_1(v8);
  v1[14] = v9;
  v1[15] = OUTLINED_FUNCTION_5();
  uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>);
  v1[16] = v10;
  OUTLINED_FUNCTION_1(v10);
  v1[17] = v11;
  v1[18] = OUTLINED_FUNCTION_5();
  uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>);
  v1[19] = v12;
  OUTLINED_FUNCTION_1(v12);
  v1[20] = v13;
  v1[21] = OUTLINED_FUNCTION_5();
  uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  v1[22] = v14;
  OUTLINED_FUNCTION_17(v14);
  v1[23] = OUTLINED_FUNCTION_5();
  uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Float>);
  v1[24] = v15;
  OUTLINED_FUNCTION_1(v15);
  v1[25] = v16;
  v1[26] = OUTLINED_FUNCTION_5();
  uint64_t v17 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ClassificationDistribution<String>);
  v1[27] = v17;
  OUTLINED_FUNCTION_1(v17);
  v1[28] = v18;
  v1[29] = OUTLINED_FUNCTION_24();
  v1[30] = swift_task_alloc();
  uint64_t v19 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<MLShapedArray<Float>, String>);
  v1[31] = v19;
  OUTLINED_FUNCTION_1(v19);
  v1[32] = v20;
  v1[33] = OUTLINED_FUNCTION_5();
  OUTLINED_FUNCTION_14();
  return MEMORY[0x270FA2498](v21, v22, v23);
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  void *v3;
  uint64_t v4;
  void *v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v11;

  OUTLINED_FUNCTION_11();
  OUTLINED_FUNCTION_2();
  OUTLINED_FUNCTION_7();
  *uint64_t v3 = v2;
  uint64_t v4 = *v1;
  OUTLINED_FUNCTION_6();
  *uint64_t v5 = v4;
  *(void *)(v6 + 320) = v0;
  swift_task_dealloc();
  OUTLINED_FUNCTION_14();
  return MEMORY[0x270FA2498](v7, v8, v9);
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  void *v3;
  uint64_t v4;
  void *v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v11;

  OUTLINED_FUNCTION_11();
  OUTLINED_FUNCTION_2();
  OUTLINED_FUNCTION_7();
  *uint64_t v3 = v2;
  uint64_t v4 = *v1;
  OUTLINED_FUNCTION_6();
  *uint64_t v5 = v4;
  *(void *)(v6 + 336) = v0;
  swift_task_dealloc();
  OUTLINED_FUNCTION_14();
  return MEMORY[0x270FA2498](v7, v8, v9);
}

uint64_t specialized Transformer.prediction<A, B>(from:eventHandler:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16)
{
  OUTLINED_FUNCTION_80_2();
  OUTLINED_FUNCTION_138();
  uint64_t v18 = *(void *)(v16[4] + 16);
  v16[34] = v18;
  specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
  if (v18)
  {
    OUTLINED_FUNCTION_44_2();
    uint64_t v19 = OUTLINED_FUNCTION_130();
    v17(v19);
    static Task<>.checkCancellation()();
    uint64_t v29 = v16[23];
    uint64_t v31 = v16[7];
    uint64_t v30 = v16[8];
    AnnotatedFeature.feature.getter();
    outlined init with copy of URL?(v31 + *(int *)(v30 + 20), v29, &demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
    OUTLINED_FUNCTION_97_0();
    OUTLINED_FUNCTION_110_0();
    if (v32)
    {
      OUTLINED_FUNCTION_10_10();
      v33();
      uint64_t v34 = swift_task_alloc();
      uint64_t v35 = (void *)OUTLINED_FUNCTION_52_4(v34);
      *uint64_t v35 = v36;
      v35[1] = specialized Transformer.prediction<A, B>(from:eventHandler:);
      OUTLINED_FUNCTION_20_8();
      OUTLINED_FUNCTION_19_9();
      return MEMORY[0x270EEA930](v37, v38, v39, v40, v41, v42, v43, v44, a9, a10, a11, a12, a13, a14, a15, a16);
    }
    else
    {
      OUTLINED_FUNCTION_10_10();
      v45();
      uint64_t v46 = swift_task_alloc();
      uint64_t v47 = (void *)OUTLINED_FUNCTION_53_6(v46);
      void *v47 = v48;
      v47[1] = specialized Transformer.prediction<A, B>(from:eventHandler:);
      OUTLINED_FUNCTION_21_9();
      OUTLINED_FUNCTION_19_9();
      return MEMORY[0x270EEA920](v49, v50, v51, v52, v53, v54, v55, v56, a9, a10, a11, a12, a13, a14, a15, a16);
    }
  }
  else
  {
    OUTLINED_FUNCTION_72_1();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    OUTLINED_FUNCTION_174();
    OUTLINED_FUNCTION_19_9();
    return v22(v20, v21, v22, v23, v24, v25, v26, v27, a9, a10, a11, a12, a13, a14);
  }
}

{
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  void (*v21)(void);
  uint64_t v22;
  void (*v23)(uint64_t);
  uint64_t v24;
  void (*v25)(uint64_t);
  char v26;
  unint64_t v27;
  void (*v28)(unint64_t);
  uint64_t v29;
  void (*v30)(uint64_t);
  uint64_t v31;
  uint64_t v32;
  void (*v33)(uint64_t);
  uint64_t v34;
  void (*v35)(uint64_t);
  uint64_t v36;
  void (*v37)(void);
  uint64_t v38;
  uint64_t v39;
  uint64_t (*v40)(uint64_t, uint64_t, void, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t);
  uint64_t v41;
  uint64_t v42;
  uint64_t v43;
  uint64_t v44;
  uint64_t v45;
  uint64_t v47;
  void (*v48)(uint64_t);
  void (*v49)(void);
  uint64_t v50;
  uint64_t (*v51)(uint64_t, void, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t);
  uint64_t v52;
  uint64_t v53;
  uint64_t v54;
  uint64_t v55;
  uint64_t v56;
  uint64_t v57;
  char v58;
  void (*v59)(void);
  uint64_t v60;
  void *v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  uint64_t v65;
  uint64_t v66;
  uint64_t v67;
  uint64_t v68;
  uint64_t v69;
  uint64_t v70;
  void (*v71)(void);
  uint64_t v72;
  void *v73;
  uint64_t v74;
  uint64_t v75;
  uint64_t v76;
  uint64_t v77;
  uint64_t v78;
  uint64_t v79;
  uint64_t v80;
  uint64_t v81;
  uint64_t v82;

  OUTLINED_FUNCTION_37_4();
  OUTLINED_FUNCTION_113_0();
  OUTLINED_FUNCTION_9();
  v21();
  uint64_t v22 = OUTLINED_FUNCTION_11_10();
  v23(v22);
  uint64_t v24 = OUTLINED_FUNCTION_32_7();
  v25(v24);
  OUTLINED_FUNCTION_146();
  OUTLINED_FUNCTION_68_2();
  OUTLINED_FUNCTION_70_2();
  if (v26) {
    OUTLINED_FUNCTION_93_0();
  }
  uint64_t v27 = OUTLINED_FUNCTION_7_17();
  v28(v27);
  if (v16)
  {
    uint64_t v29 = OUTLINED_FUNCTION_29_6();
    outlined init with copy of MLSoundClassifier.ModelParameters.ValidationData(v29, v20, (void (*)(void))type metadata accessor for MLSoundClassifier.Model);
    swift_retain();
    OUTLINED_FUNCTION_149();
    uint64_t v30 = (void (*)(uint64_t))OUTLINED_FUNCTION_69_2();
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Sendable);
    OUTLINED_FUNCTION_150();
    lazy protocol witness table accessor for type MLSoundClassifier.Classifier and conformance MLSoundClassifier.Classifier(&lazy protocol witness table cache variable for type MetricsKey and conformance MetricsKey, MEMORY[0x263F042E0]);
    OUTLINED_FUNCTION_98_0();
    OUTLINED_FUNCTION_28_7();
    uint64_t v31 = OUTLINED_FUNCTION_89_0();
    v30(v31);
    char v32 = OUTLINED_FUNCTION_33_6();
    v33(v32);
  }
  uint64_t v34 = OUTLINED_FUNCTION_22_9();
  v35(v34);
  uint64_t v36 = v18 + 8;
  OUTLINED_FUNCTION_11_3();
  v37();
  if (v19 == v17 + 16)
  {
    swift_bridgeObjectRelease();
    OUTLINED_FUNCTION_12_7();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    OUTLINED_FUNCTION_71_2();
    OUTLINED_FUNCTION_3_24();
    return v40(v38, v39, v40, v41, v42, v43, v44, v45, a9, a10, a11, a12, a13, a14, a15, a16);
  }
  else
  {
    uint64_t v47 = OUTLINED_FUNCTION_4_20();
    v48(v47);
    static Task<>.checkCancellation()();
    if (a12)
    {
      OUTLINED_FUNCTION_9();
      v49();
      swift_bridgeObjectRelease();
      OUTLINED_FUNCTION_13_9();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      OUTLINED_FUNCTION_59_4();
      OUTLINED_FUNCTION_3_24();
      return v51(v50, v51, v52, v53, v54, v55, v56, v57, a9, a10, a11, a12, a13, a14, a15, a16);
    }
    else
    {
      OUTLINED_FUNCTION_159();
      outlined init with copy of URL?(v19 + *(int *)(v36 + 20), v17 + 16, &demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
      OUTLINED_FUNCTION_97_0();
      OUTLINED_FUNCTION_110_0();
      if (v58)
      {
        OUTLINED_FUNCTION_10_10();
        v59();
        uint64_t v60 = swift_task_alloc();
        uint64_t v61 = (void *)OUTLINED_FUNCTION_52_4(v60);
        *uint64_t v61 = v62;
        v61[1] = specialized Transformer.prediction<A, B>(from:eventHandler:);
        OUTLINED_FUNCTION_20_8();
        OUTLINED_FUNCTION_3_24();
        return MEMORY[0x270EEA930](v63, v64, v65, v66, v67, v68, v69, v70, a9, a10, a11, 0, a13, a14, a15, a16);
      }
      else
      {
        OUTLINED_FUNCTION_10_10();
        v71();
        uint64_t v72 = swift_task_alloc();
        uint64_t v73 = (void *)OUTLINED_FUNCTION_53_6(v72);
        *uint64_t v73 = v74;
        v73[1] = specialized Transformer.prediction<A, B>(from:eventHandler:);
        OUTLINED_FUNCTION_21_9();
        OUTLINED_FUNCTION_3_24();
        return MEMORY[0x270EEA920](v75, v76, v77, v78, v79, v80, v81, v82, a9, a10, a11, 0, a13, a14, a15, a16);
      }
    }
  }
}

{
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  void (*v21)(void);
  uint64_t v22;
  void (*v23)(uint64_t);
  uint64_t v24;
  void (*v25)(uint64_t);
  char v26;
  unint64_t v27;
  void (*v28)(unint64_t);
  uint64_t v29;
  void (*v30)(uint64_t);
  uint64_t v31;
  uint64_t v32;
  void (*v33)(uint64_t);
  uint64_t v34;
  void (*v35)(uint64_t);
  uint64_t v36;
  void (*v37)(void);
  uint64_t v38;
  uint64_t v39;
  uint64_t (*v40)(uint64_t, uint64_t, void, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t);
  uint64_t v41;
  uint64_t v42;
  uint64_t v43;
  uint64_t v44;
  uint64_t v45;
  uint64_t v47;
  void (*v48)(uint64_t);
  void (*v49)(void);
  uint64_t v50;
  uint64_t (*v51)(uint64_t, void, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t);
  uint64_t v52;
  uint64_t v53;
  uint64_t v54;
  uint64_t v55;
  uint64_t v56;
  uint64_t v57;
  char v58;
  void (*v59)(void);
  uint64_t v60;
  void *v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  uint64_t v65;
  uint64_t v66;
  uint64_t v67;
  uint64_t v68;
  uint64_t v69;
  uint64_t v70;
  void (*v71)(void);
  uint64_t v72;
  void *v73;
  uint64_t v74;
  uint64_t v75;
  uint64_t v76;
  uint64_t v77;
  uint64_t v78;
  uint64_t v79;
  uint64_t v80;
  uint64_t v81;
  uint64_t v82;

  OUTLINED_FUNCTION_37_4();
  OUTLINED_FUNCTION_113_0();
  OUTLINED_FUNCTION_9();
  v21();
  uint64_t v22 = OUTLINED_FUNCTION_11_10();
  v23(v22);
  uint64_t v24 = OUTLINED_FUNCTION_32_7();
  v25(v24);
  OUTLINED_FUNCTION_146();
  OUTLINED_FUNCTION_68_2();
  OUTLINED_FUNCTION_70_2();
  if (v26) {
    OUTLINED_FUNCTION_93_0();
  }
  uint64_t v27 = OUTLINED_FUNCTION_7_17();
  v28(v27);
  if (v16)
  {
    uint64_t v29 = OUTLINED_FUNCTION_29_6();
    outlined init with copy of MLSoundClassifier.ModelParameters.ValidationData(v29, v20, (void (*)(void))type metadata accessor for MLSoundClassifier.Model);
    swift_retain();
    OUTLINED_FUNCTION_149();
    uint64_t v30 = (void (*)(uint64_t))OUTLINED_FUNCTION_69_2();
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Sendable);
    OUTLINED_FUNCTION_150();
    lazy protocol witness table accessor for type MLSoundClassifier.Classifier and conformance MLSoundClassifier.Classifier(&lazy protocol witness table cache variable for type MetricsKey and conformance MetricsKey, MEMORY[0x263F042E0]);
    OUTLINED_FUNCTION_98_0();
    OUTLINED_FUNCTION_28_7();
    uint64_t v31 = OUTLINED_FUNCTION_89_0();
    v30(v31);
    char v32 = OUTLINED_FUNCTION_33_6();
    v33(v32);
  }
  uint64_t v34 = OUTLINED_FUNCTION_22_9();
  v35(v34);
  uint64_t v36 = v18 + 8;
  OUTLINED_FUNCTION_11_3();
  v37();
  if (v19 == v17 + 16)
  {
    swift_bridgeObjectRelease();
    OUTLINED_FUNCTION_12_7();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    OUTLINED_FUNCTION_71_2();
    OUTLINED_FUNCTION_3_24();
    return v40(v38, v39, v40, v41, v42, v43, v44, v45, a9, a10, a11, a12, a13, a14, a15, a16);
  }
  else
  {
    uint64_t v47 = OUTLINED_FUNCTION_4_20();
    v48(v47);
    static Task<>.checkCancellation()();
    if (a12)
    {
      OUTLINED_FUNCTION_9();
      v49();
      swift_bridgeObjectRelease();
      OUTLINED_FUNCTION_13_9();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      OUTLINED_FUNCTION_59_4();
      OUTLINED_FUNCTION_3_24();
      return v51(v50, v51, v52, v53, v54, v55, v56, v57, a9, a10, a11, a12, a13, a14, a15, a16);
    }
    else
    {
      OUTLINED_FUNCTION_159();
      outlined init with copy of URL?(v19 + *(int *)(v36 + 20), v17 + 16, &demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
      OUTLINED_FUNCTION_97_0();
      OUTLINED_FUNCTION_110_0();
      if (v58)
      {
        OUTLINED_FUNCTION_10_10();
        v59();
        uint64_t v60 = swift_task_alloc();
        uint64_t v61 = (void *)OUTLINED_FUNCTION_52_4(v60);
        *uint64_t v61 = v62;
        v61[1] = specialized Transformer.prediction<A, B>(from:eventHandler:);
        OUTLINED_FUNCTION_20_8();
        OUTLINED_FUNCTION_3_24();
        return MEMORY[0x270EEA930](v63, v64, v65, v66, v67, v68, v69, v70, a9, a10, a11, 0, a13, a14, a15, a16);
      }
      else
      {
        OUTLINED_FUNCTION_10_10();
        v71();
        uint64_t v72 = swift_task_alloc();
        uint64_t v73 = (void *)OUTLINED_FUNCTION_53_6(v72);
        *uint64_t v73 = v74;
        v73[1] = specialized Transformer.prediction<A, B>(from:eventHandler:);
        OUTLINED_FUNCTION_21_9();
        OUTLINED_FUNCTION_3_24();
        return MEMORY[0x270EEA920](v75, v76, v77, v78, v79, v80, v81, v82, a9, a10, a11, 0, a13, a14, a15, a16);
      }
    }
  }
}

{
  void *v16;
  void (*v17)(uint64_t);
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t (*v22)(uint64_t, uint64_t, void, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t);
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v29;
  uint64_t v30;
  char v31;
  void (*v32)(void);
  uint64_t v33;
  void *v34;
  uint64_t v35;
  uint64_t v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  uint64_t v42;
  uint64_t v43;
  void (*v44)(void);
  uint64_t v45;
  void *v46;
  uint64_t v47;
  uint64_t v48;
  uint64_t v49;
  uint64_t v50;
  uint64_t v51;
  uint64_t v52;
  uint64_t v53;
  uint64_t v54;
  uint64_t v55;

  OUTLINED_FUNCTION_80_2();
  OUTLINED_FUNCTION_138();
  uint64_t v18 = *(void *)(v16[4] + 16);
  v16[34] = v18;
  specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
  if (v18)
  {
    OUTLINED_FUNCTION_44_2();
    uint64_t v19 = OUTLINED_FUNCTION_130();
    v17(v19);
    static Task<>.checkCancellation()();
    uint64_t v29 = v16[23];
    uint64_t v30 = v16[7];
    AnnotatedFeature.feature.getter();
    outlined init with copy of URL?(v30, v29, &demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
    OUTLINED_FUNCTION_97_0();
    OUTLINED_FUNCTION_110_0();
    if (v31)
    {
      OUTLINED_FUNCTION_10_10();
      v32();
      uint64_t v33 = swift_task_alloc();
      uint64_t v34 = (void *)OUTLINED_FUNCTION_52_4(v33);
      *uint64_t v34 = v35;
      v34[1] = specialized Transformer.prediction<A, B>(from:eventHandler:);
      OUTLINED_FUNCTION_20_8();
      OUTLINED_FUNCTION_19_9();
      return MEMORY[0x270EEA930](v36, v37, v38, v39, v40, v41, v42, v43, a9, a10, a11, a12, a13, a14, a15, a16);
    }
    else
    {
      OUTLINED_FUNCTION_10_10();
      v44();
      uint64_t v45 = swift_task_alloc();
      uint64_t v46 = (void *)OUTLINED_FUNCTION_53_6(v45);
      *uint64_t v46 = v47;
      v46[1] = specialized Transformer.prediction<A, B>(from:eventHandler:);
      OUTLINED_FUNCTION_21_9();
      OUTLINED_FUNCTION_19_9();
      return MEMORY[0x270EEA920](v48, v49, v50, v51, v52, v53, v54, v55, a9, a10, a11, a12, a13, a14, a15, a16);
    }
  }
  else
  {
    OUTLINED_FUNCTION_72_1();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    OUTLINED_FUNCTION_174();
    OUTLINED_FUNCTION_19_9();
    return v22(v20, v21, v22, v23, v24, v25, v26, v27, a9, a10, a11, a12, a13, a14);
  }
}

{
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  void (*v21)(void);
  uint64_t v22;
  void (*v23)(uint64_t);
  uint64_t v24;
  void (*v25)(uint64_t);
  char v26;
  unint64_t v27;
  void (*v28)(unint64_t);
  uint64_t v29;
  void (*v30)(uint64_t);
  uint64_t v31;
  uint64_t v32;
  void (*v33)(uint64_t);
  uint64_t v34;
  void (*v35)(uint64_t);
  uint64_t v36;
  void (*v37)(void);
  uint64_t v38;
  uint64_t v39;
  uint64_t (*v40)(uint64_t, uint64_t, void, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t);
  uint64_t v41;
  uint64_t v42;
  uint64_t v43;
  uint64_t v44;
  uint64_t v45;
  uint64_t v47;
  void (*v48)(uint64_t);
  void (*v49)(void);
  uint64_t v50;
  uint64_t (*v51)(uint64_t, void, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t);
  uint64_t v52;
  uint64_t v53;
  uint64_t v54;
  uint64_t v55;
  uint64_t v56;
  uint64_t v57;
  char v58;
  void (*v59)(void);
  uint64_t v60;
  void *v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  uint64_t v65;
  uint64_t v66;
  uint64_t v67;
  uint64_t v68;
  uint64_t v69;
  uint64_t v70;
  void (*v71)(void);
  uint64_t v72;
  void *v73;
  uint64_t v74;
  uint64_t v75;
  uint64_t v76;
  uint64_t v77;
  uint64_t v78;
  uint64_t v79;
  uint64_t v80;
  uint64_t v81;
  uint64_t v82;

  OUTLINED_FUNCTION_37_4();
  OUTLINED_FUNCTION_113_0();
  OUTLINED_FUNCTION_9();
  v21();
  uint64_t v22 = OUTLINED_FUNCTION_11_10();
  v23(v22);
  uint64_t v24 = OUTLINED_FUNCTION_32_7();
  v25(v24);
  OUTLINED_FUNCTION_146();
  OUTLINED_FUNCTION_68_2();
  OUTLINED_FUNCTION_70_2();
  if (v26) {
    OUTLINED_FUNCTION_93_0();
  }
  uint64_t v27 = OUTLINED_FUNCTION_7_17();
  v28(v27);
  if (v16)
  {
    uint64_t v29 = OUTLINED_FUNCTION_29_6();
    outlined init with copy of MLSoundClassifier.ModelParameters.ValidationData(v29, v20, (void (*)(void))type metadata accessor for MLImageClassifier.Model);
    swift_retain();
    OUTLINED_FUNCTION_149();
    uint64_t v30 = (void (*)(uint64_t))OUTLINED_FUNCTION_69_2();
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Sendable);
    OUTLINED_FUNCTION_150();
    lazy protocol witness table accessor for type MLSoundClassifier.Classifier and conformance MLSoundClassifier.Classifier(&lazy protocol witness table cache variable for type MetricsKey and conformance MetricsKey, MEMORY[0x263F042E0]);
    OUTLINED_FUNCTION_98_0();
    OUTLINED_FUNCTION_28_7();
    uint64_t v31 = OUTLINED_FUNCTION_89_0();
    v30(v31);
    char v32 = OUTLINED_FUNCTION_33_6();
    v33(v32);
  }
  uint64_t v34 = OUTLINED_FUNCTION_22_9();
  v35(v34);
  uint64_t v36 = v18 + 8;
  OUTLINED_FUNCTION_11_3();
  v37();
  if (v19 == v17 + 16)
  {
    swift_bridgeObjectRelease();
    OUTLINED_FUNCTION_12_7();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    OUTLINED_FUNCTION_71_2();
    OUTLINED_FUNCTION_3_24();
    return v40(v38, v39, v40, v41, v42, v43, v44, v45, a9, a10, a11, a12, a13, a14, a15, a16);
  }
  else
  {
    uint64_t v47 = OUTLINED_FUNCTION_4_20();
    v48(v47);
    static Task<>.checkCancellation()();
    if (a12)
    {
      OUTLINED_FUNCTION_9();
      v49();
      swift_bridgeObjectRelease();
      OUTLINED_FUNCTION_13_9();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      OUTLINED_FUNCTION_59_4();
      OUTLINED_FUNCTION_3_24();
      return v51(v50, v51, v52, v53, v54, v55, v56, v57, a9, a10, a11, a12, a13, a14, a15, a16);
    }
    else
    {
      OUTLINED_FUNCTION_158();
      outlined init with copy of URL?(v36, v17 + 16, &demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
      OUTLINED_FUNCTION_97_0();
      OUTLINED_FUNCTION_110_0();
      if (v58)
      {
        OUTLINED_FUNCTION_10_10();
        v59();
        uint64_t v60 = swift_task_alloc();
        uint64_t v61 = (void *)OUTLINED_FUNCTION_52_4(v60);
        *uint64_t v61 = v62;
        v61[1] = specialized Transformer.prediction<A, B>(from:eventHandler:);
        OUTLINED_FUNCTION_20_8();
        OUTLINED_FUNCTION_3_24();
        return MEMORY[0x270EEA930](v63, v64, v65, v66, v67, v68, v69, v70, a9, a10, a11, 0, a13, a14, a15, a16);
      }
      else
      {
        OUTLINED_FUNCTION_10_10();
        v71();
        uint64_t v72 = swift_task_alloc();
        uint64_t v73 = (void *)OUTLINED_FUNCTION_53_6(v72);
        *uint64_t v73 = v74;
        v73[1] = specialized Transformer.prediction<A, B>(from:eventHandler:);
        OUTLINED_FUNCTION_21_9();
        OUTLINED_FUNCTION_3_24();
        return MEMORY[0x270EEA920](v75, v76, v77, v78, v79, v80, v81, v82, a9, a10, a11, 0, a13, a14, a15, a16);
      }
    }
  }
}

{
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  void (*v21)(void);
  uint64_t v22;
  void (*v23)(uint64_t);
  uint64_t v24;
  void (*v25)(uint64_t);
  char v26;
  unint64_t v27;
  void (*v28)(unint64_t);
  uint64_t v29;
  void (*v30)(uint64_t);
  uint64_t v31;
  uint64_t v32;
  void (*v33)(uint64_t);
  uint64_t v34;
  void (*v35)(uint64_t);
  uint64_t v36;
  void (*v37)(void);
  uint64_t v38;
  uint64_t v39;
  uint64_t (*v40)(uint64_t, uint64_t, void, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t);
  uint64_t v41;
  uint64_t v42;
  uint64_t v43;
  uint64_t v44;
  uint64_t v45;
  uint64_t v47;
  void (*v48)(uint64_t);
  void (*v49)(void);
  uint64_t v50;
  uint64_t (*v51)(uint64_t, void, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t);
  uint64_t v52;
  uint64_t v53;
  uint64_t v54;
  uint64_t v55;
  uint64_t v56;
  uint64_t v57;
  char v58;
  void (*v59)(void);
  uint64_t v60;
  void *v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  uint64_t v65;
  uint64_t v66;
  uint64_t v67;
  uint64_t v68;
  uint64_t v69;
  uint64_t v70;
  void (*v71)(void);
  uint64_t v72;
  void *v73;
  uint64_t v74;
  uint64_t v75;
  uint64_t v76;
  uint64_t v77;
  uint64_t v78;
  uint64_t v79;
  uint64_t v80;
  uint64_t v81;
  uint64_t v82;

  OUTLINED_FUNCTION_37_4();
  OUTLINED_FUNCTION_113_0();
  OUTLINED_FUNCTION_9();
  v21();
  uint64_t v22 = OUTLINED_FUNCTION_11_10();
  v23(v22);
  uint64_t v24 = OUTLINED_FUNCTION_32_7();
  v25(v24);
  OUTLINED_FUNCTION_146();
  OUTLINED_FUNCTION_68_2();
  OUTLINED_FUNCTION_70_2();
  if (v26) {
    OUTLINED_FUNCTION_93_0();
  }
  uint64_t v27 = OUTLINED_FUNCTION_7_17();
  v28(v27);
  if (v16)
  {
    uint64_t v29 = OUTLINED_FUNCTION_29_6();
    outlined init with copy of MLSoundClassifier.ModelParameters.ValidationData(v29, v20, (void (*)(void))type metadata accessor for MLImageClassifier.Model);
    swift_retain();
    OUTLINED_FUNCTION_149();
    uint64_t v30 = (void (*)(uint64_t))OUTLINED_FUNCTION_69_2();
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Sendable);
    OUTLINED_FUNCTION_150();
    lazy protocol witness table accessor for type MLSoundClassifier.Classifier and conformance MLSoundClassifier.Classifier(&lazy protocol witness table cache variable for type MetricsKey and conformance MetricsKey, MEMORY[0x263F042E0]);
    OUTLINED_FUNCTION_98_0();
    OUTLINED_FUNCTION_28_7();
    uint64_t v31 = OUTLINED_FUNCTION_89_0();
    v30(v31);
    char v32 = OUTLINED_FUNCTION_33_6();
    v33(v32);
  }
  uint64_t v34 = OUTLINED_FUNCTION_22_9();
  v35(v34);
  uint64_t v36 = v18 + 8;
  OUTLINED_FUNCTION_11_3();
  v37();
  if (v19 == v17 + 16)
  {
    swift_bridgeObjectRelease();
    OUTLINED_FUNCTION_12_7();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    OUTLINED_FUNCTION_71_2();
    OUTLINED_FUNCTION_3_24();
    return v40(v38, v39, v40, v41, v42, v43, v44, v45, a9, a10, a11, a12, a13, a14, a15, a16);
  }
  else
  {
    uint64_t v47 = OUTLINED_FUNCTION_4_20();
    v48(v47);
    static Task<>.checkCancellation()();
    if (a12)
    {
      OUTLINED_FUNCTION_9();
      v49();
      swift_bridgeObjectRelease();
      OUTLINED_FUNCTION_13_9();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      OUTLINED_FUNCTION_59_4();
      OUTLINED_FUNCTION_3_24();
      return v51(v50, v51, v52, v53, v54, v55, v56, v57, a9, a10, a11, a12, a13, a14, a15, a16);
    }
    else
    {
      OUTLINED_FUNCTION_158();
      outlined init with copy of URL?(v36, v17 + 16, &demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
      OUTLINED_FUNCTION_97_0();
      OUTLINED_FUNCTION_110_0();
      if (v58)
      {
        OUTLINED_FUNCTION_10_10();
        v59();
        uint64_t v60 = swift_task_alloc();
        uint64_t v61 = (void *)OUTLINED_FUNCTION_52_4(v60);
        *uint64_t v61 = v62;
        v61[1] = specialized Transformer.prediction<A, B>(from:eventHandler:);
        OUTLINED_FUNCTION_20_8();
        OUTLINED_FUNCTION_3_24();
        return MEMORY[0x270EEA930](v63, v64, v65, v66, v67, v68, v69, v70, a9, a10, a11, 0, a13, a14, a15, a16);
      }
      else
      {
        OUTLINED_FUNCTION_10_10();
        v71();
        uint64_t v72 = swift_task_alloc();
        uint64_t v73 = (void *)OUTLINED_FUNCTION_53_6(v72);
        *uint64_t v73 = v74;
        v73[1] = specialized Transformer.prediction<A, B>(from:eventHandler:);
        OUTLINED_FUNCTION_21_9();
        OUTLINED_FUNCTION_3_24();
        return MEMORY[0x270EEA920](v75, v76, v77, v78, v79, v80, v81, v82, a9, a10, a11, 0, a13, a14, a15, a16);
      }
    }
  }
}

uint64_t specialized Transformer.prediction<A, B>(from:eventHandler:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14)
{
  OUTLINED_FUNCTION_80_2();
  OUTLINED_FUNCTION_138();
  uint64_t v29 = *(void *)(v14 + 320);
  OUTLINED_FUNCTION_9();
  v15();
  uint64_t v16 = OUTLINED_FUNCTION_75();
  v17(v16);
  swift_bridgeObjectRelease();
  uint64_t v18 = OUTLINED_FUNCTION_122();
  v19(v18);
  OUTLINED_FUNCTION_50_4();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  OUTLINED_FUNCTION_19_9();
  return v21(v20, v21, v22, v23, v24, v25, v26, v27, a9, a10, v29, a12, a13, a14);
}

{
  uint64_t v14;
  void (*v15)(void);
  uint64_t v16;
  void (*v17)(uint64_t);
  uint64_t v18;
  void (*v19)(uint64_t);
  uint64_t v20;
  uint64_t (*v21)(uint64_t, void, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t);
  uint64_t v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v29;

  OUTLINED_FUNCTION_80_2();
  OUTLINED_FUNCTION_138();
  uint64_t v29 = *(void *)(v14 + 336);
  OUTLINED_FUNCTION_9();
  v15();
  uint64_t v16 = OUTLINED_FUNCTION_75();
  v17(v16);
  swift_bridgeObjectRelease();
  uint64_t v18 = OUTLINED_FUNCTION_122();
  v19(v18);
  OUTLINED_FUNCTION_50_4();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  OUTLINED_FUNCTION_19_9();
  return v21(v20, v21, v22, v23, v24, v25, v26, v27, a9, a10, v29, a12, a13, a14);
}

uint64_t key path getter for AnnotatedPrediction.prediction : AnnotatedPrediction<ClassificationDistribution<String>, String>()
{
  return AnnotatedPrediction.prediction.getter();
}

uint64_t key path setter for AnnotatedPrediction.prediction : AnnotatedPrediction<ClassificationDistribution<String>, String>()
{
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ClassificationDistribution<String>);
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v0);
  OUTLINED_FUNCTION_3_0();
  uint64_t v1 = OUTLINED_FUNCTION_173();
  v2(v1);
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedPrediction<ClassificationDistribution<String>, String>);
  return AnnotatedPrediction.prediction.setter();
}

double key path getter for ClassificationDistribution.mostLikelyLabel : ClassificationDistribution<String>@<D0>(_OWORD *a1@<X8>)
{
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ClassificationDistribution<String>);
  ClassificationDistribution.mostLikelyLabel.getter();
  double result = *(double *)&v3;
  *a1 = v3;
  return result;
}

Swift::Bool __swiftcall SoundClassifierTrainingSessionDelegate.shouldTransition(from:to:)(CreateML::MLPhase from, CreateML::MLPhase to)
{
  if (*(unsigned char *)from == 1 && *(unsigned char *)to == 2) {
    char v4 = *(unsigned char *)(v2 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_featureExtractionOnly) ^ 1;
  }
  else {
    char v4 = 1;
  }
  return v4 & 1;
}

void SoundClassifierTrainingSessionDelegate.saveCheckpoint(to:phase:iteration:)()
{
  OUTLINED_FUNCTION_9_0();
  uint64_t v74 = v1;
  uint64_t v75 = v2;
  uint64_t v5 = v4;
  v77[3] = *(id *)MEMORY[0x263EF8340];
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.Model?);
  uint64_t v7 = OUTLINED_FUNCTION_17(v6);
  MEMORY[0x270FA5388](v7);
  OUTLINED_FUNCTION_41_0();
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.Classifier?);
  uint64_t v9 = OUTLINED_FUNCTION_17(v8);
  MEMORY[0x270FA5388](v9);
  OUTLINED_FUNCTION_24_8();
  uint64_t v73 = type metadata accessor for CSVWritingOptions();
  OUTLINED_FUNCTION_0();
  uint64_t v69 = v10;
  MEMORY[0x270FA5388](v11);
  OUTLINED_FUNCTION_49();
  uint64_t v68 = v12;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v13);
  type metadata accessor for DataFrame();
  OUTLINED_FUNCTION_0();
  uint64_t v70 = v15;
  uint64_t v71 = v14;
  MEMORY[0x270FA5388](v14);
  OUTLINED_FUNCTION_49();
  uint64_t v67 = v16;
  OUTLINED_FUNCTION_20_3();
  uint64_t v18 = MEMORY[0x270FA5388](v17);
  OUTLINED_FUNCTION_139(v18, v19, v20, v21, v22, v23, v24, v25, v64);
  uint64_t v76 = type metadata accessor for URL();
  OUTLINED_FUNCTION_0();
  uint64_t v27 = v26;
  MEMORY[0x270FA5388](v28);
  OUTLINED_FUNCTION_33();
  uint64_t v30 = MEMORY[0x270FA5388](v29);
  MEMORY[0x270FA5388](v30);
  OUTLINED_FUNCTION_117_0();
  MEMORY[0x270FA5388](v31);
  uint64_t v34 = (char *)&v64 - v33;
  int v35 = *v5;
  if (v35 != 2)
  {
    if (v35 == 1)
    {
      uint64_t v36 = v32;
      OUTLINED_FUNCTION_123();
      URL.appendingPathComponent(_:)();
      URL.appendingPathExtension(_:)();
      uint64_t v37 = *(void (**)(void))(v27 + 8);
      OUTLINED_FUNCTION_38_0();
      v37();
      OUTLINED_FUNCTION_172();
      URL.appendingPathComponent(_:)();
      uint64_t v66 = v36;
      OUTLINED_FUNCTION_145();
      URL.appendingPathExtension(_:)();
      OUTLINED_FUNCTION_38_0();
      v37();
      id v38 = objc_msgSend(self, sel_defaultManager);
      URL._bridgeToObjectiveC()(v39);
      uint64_t v41 = v40;
      v77[0] = 0;
      unsigned int v42 = objc_msgSend(v38, sel_createDirectoryAtURL_withIntermediateDirectories_attributes_error_, v40, 1, 0, v77);

      id v43 = v77[0];
      if (v42)
      {
        char v65 = v37;
        OUTLINED_FUNCTION_53();
        id v44 = v43;
        uint64_t v45 = swift_bridgeObjectRetain();
        static SoundClassifierTrainingSessionDelegate.createJSONEncodedDataFrame(from:)(v45, v72);
        swift_bridgeObjectRelease();
        OUTLINED_FUNCTION_8_3();
        uint64_t v46 = v75;
        DataFrameProtocol.writeCSV(to:options:)();
        if (v46)
        {
          OUTLINED_FUNCTION_25_0();
          v47();
          OUTLINED_FUNCTION_160();
          OUTLINED_FUNCTION_25_0();
          v48();
          uint64_t v59 = v76;
          uint64_t v60 = v65;
          OUTLINED_FUNCTION_38_0();
          v60();
          ((void (*)(char *, uint64_t))v60)(v34, v59);
        }
        else
        {
          uint64_t v75 = *(void *)(v69 + 8);
          OUTLINED_FUNCTION_10_4();
          v57();
          OUTLINED_FUNCTION_53();
          uint64_t v58 = swift_bridgeObjectRetain();
          static SoundClassifierTrainingSessionDelegate.createJSONEncodedDataFrame(from:)(v58, v67);
          swift_bridgeObjectRelease();
          OUTLINED_FUNCTION_8_3();
          OUTLINED_FUNCTION_160();
          DataFrameProtocol.writeCSV(to:options:)();
          OUTLINED_FUNCTION_10_4();
          v61();
          char v62 = *(void (**)(void))(v70 + 8);
          OUTLINED_FUNCTION_21_4();
          v62();
          OUTLINED_FUNCTION_21_4();
          v62();
          uint64_t v63 = v65;
          OUTLINED_FUNCTION_38_0();
          v63();
          OUTLINED_FUNCTION_38_0();
          v63();
        }
      }
      else
      {
        id v56 = v77[0];
        _convertNSErrorToError(_:)();

        swift_willThrow();
        OUTLINED_FUNCTION_38_0();
        v37();
        OUTLINED_FUNCTION_38_0();
        v37();
      }
    }
    goto LABEL_12;
  }
  OUTLINED_FUNCTION_144();
  URL.appendingPathComponent(_:)();
  URL.appendingPathExtension(_:)();
  uint64_t v49 = *(void (**)(void))(v27 + 8);
  OUTLINED_FUNCTION_38_0();
  v49();
  uint64_t v50 = v74;
  uint64_t v51 = v74 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_classifier;
  OUTLINED_FUNCTION_53();
  outlined init with copy of URL?(v51, v0, &demangling cache variable for type metadata for MLSoundClassifier.Classifier?);
  uint64_t v52 = type metadata accessor for MLSoundClassifier.Classifier();
  OUTLINED_FUNCTION_57_4(v0, 1, v52);
  if (v53)
  {
    __break(1u);
  }
  else
  {
    uint64_t v54 = v50 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_model;
    OUTLINED_FUNCTION_53();
    outlined init with copy of URL?(v54, v3, &demangling cache variable for type metadata for MLSoundClassifier.Model?);
    uint64_t v55 = type metadata accessor for MLSoundClassifier.Model();
    OUTLINED_FUNCTION_57_4(v3, 1, v55);
    if (!v53)
    {
      lazy protocol witness table accessor for type MLSoundClassifier.Classifier and conformance MLSoundClassifier.Classifier(&lazy protocol witness table cache variable for type MLSoundClassifier.Classifier and conformance MLSoundClassifier.Classifier, (void (*)(uint64_t))type metadata accessor for MLSoundClassifier.Classifier);
      UpdatableSupervisedEstimator.writeWithOptimizer(_:to:overwrite:)();
      OUTLINED_FUNCTION_38_0();
      v49();
      outlined destroy of MLSoundClassifier.Model(v3, (void (*)(void))type metadata accessor for MLSoundClassifier.Model);
      outlined destroy of MLSoundClassifier.Model(v0, (void (*)(void))type metadata accessor for MLSoundClassifier.Classifier);
LABEL_12:
      OUTLINED_FUNCTION_8_1();
      return;
    }
  }
  __break(1u);
}

uint64_t static SoundClassifierTrainingSessionDelegate.createJSONEncodedDataFrame(from:)@<X0>(uint64_t a1@<X0>, uint64_t a2@<X8>)
{
  uint64_t v5 = type metadata accessor for String.Encoding();
  uint64_t v6 = OUTLINED_FUNCTION_17(v5);
  MEMORY[0x270FA5388](v6);
  OUTLINED_FUNCTION_105_0(v7, v38);
  uint64_t v47 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Float>);
  OUTLINED_FUNCTION_0();
  uint64_t v9 = v8;
  MEMORY[0x270FA5388](v10);
  OUTLINED_FUNCTION_29_3(v11, v38);
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<MLShapedArray<Float>, String>);
  OUTLINED_FUNCTION_0();
  uint64_t v13 = v12;
  MEMORY[0x270FA5388](v14);
  OUTLINED_FUNCTION_33_0();
  uint64_t v41 = v15;
  uint64_t v51 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  OUTLINED_FUNCTION_0();
  uint64_t v17 = v16;
  MEMORY[0x270FA5388](v18);
  OUTLINED_FUNCTION_63();
  MEMORY[0x270FA5388](v19);
  uint64_t v21 = (char *)&v38 - v20;
  type metadata accessor for JSONEncoder();
  swift_allocObject();
  uint64_t v48 = JSONEncoder.init()();
  uint64_t v22 = *(void *)(a1 + 16);
  uint64_t v49 = v21;
  OUTLINED_FUNCTION_77_2();
  Column.init(name:capacity:)();
  uint64_t v50 = v2;
  OUTLINED_FUNCTION_61_3();
  Column.init(name:capacity:)();
  if (v22)
  {
    uint64_t v39 = v17;
    uint64_t v40 = a2;
    uint64_t v24 = *(void *)(v13 + 16);
    uint64_t v23 = v13 + 16;
    unint64_t v25 = a1 + ((*(unsigned __int8 *)(v23 + 64) + 32) & ~(unint64_t)*(unsigned __int8 *)(v23 + 64));
    uint64_t v44 = v9 + 8;
    uint64_t v45 = v24;
    uint64_t v42 = *(void *)(v23 + 56);
    uint64_t v43 = v23 - 8;
    uint64_t v38 = a1;
    swift_bridgeObjectRetain();
    uint64_t v46 = v23;
    do
    {
      OUTLINED_FUNCTION_18_3();
      v26();
      AnnotatedFeature.feature.getter();
      lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type MLShapedArray<Float> and conformance MLShapedArray<A>, &demangling cache variable for type metadata for MLShapedArray<Float>);
      uint64_t v27 = MLShapedArrayProtocol.scalars.getter();
      OUTLINED_FUNCTION_25_0();
      v28();
      uint64_t v54 = v27;
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Float]);
      lazy protocol witness table accessor for type [Float] and conformance <A> [A](&lazy protocol witness table cache variable for type [Float] and conformance <A> [A]);
      uint64_t v29 = dispatch thunk of JSONEncoder.encode<A>(_:)();
      unint64_t v31 = v30;
      swift_bridgeObjectRelease();
      static String.Encoding.utf8.getter();
      uint64_t v54 = String.init(data:encoding:)();
      uint64_t v55 = v32;
      Column.append(_:)();
      swift_bridgeObjectRelease();
      AnnotatedFeature.annotation.getter();
      uint64_t v52 = v54;
      uint64_t v53 = v55;
      Column.append(_:)();
      outlined consume of Data._Representation(v29, v31);
      swift_bridgeObjectRelease();
      OUTLINED_FUNCTION_25_0();
      v33();
      v25 += v42;
      --v22;
    }
    while (v22);
    swift_bridgeObjectRelease();
    uint64_t v17 = v39;
  }
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<AnyColumn>);
  uint64_t v34 = type metadata accessor for AnyColumn();
  OUTLINED_FUNCTION_1(v34);
  uint64_t v35 = OUTLINED_FUNCTION_109_0();
  *(_OWORD *)(v35 + 16) = xmmword_2272CB4D0;
  Column.eraseToAnyColumn()();
  Column.eraseToAnyColumn()();
  uint64_t v54 = v35;
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [AnyColumn]);
  lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [AnyColumn] and conformance [A], &demangling cache variable for type metadata for [AnyColumn]);
  DataFrame.init<A>(columns:)();
  swift_release();
  uint64_t v36 = *(void (**)(void))(v17 + 8);
  OUTLINED_FUNCTION_111_0();
  OUTLINED_FUNCTION_24_5();
  v36();
  OUTLINED_FUNCTION_24_5();
  return ((uint64_t (*)(void))v36)();
}

uint64_t static SoundClassifierTrainingSessionDelegate.createDataFrame(from:)(uint64_t a1)
{
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Float>);
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v2);
  OUTLINED_FUNCTION_40_0();
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v3);
  OUTLINED_FUNCTION_10();
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<MLShapedArray<Float>>);
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v4);
  OUTLINED_FUNCTION_33_0();
  uint64_t v5 = *(void *)(a1 + 16);
  OUTLINED_FUNCTION_77_2();
  Column.init(name:capacity:)();
  OUTLINED_FUNCTION_61_3();
  Column.init(name:capacity:)();
  if (v5)
  {
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<MLShapedArray<Float>, String>);
    OUTLINED_FUNCTION_57_5();
    uint64_t v7 = a1 + ((*(unsigned __int8 *)(v6 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v6 + 80));
    uint64_t v14 = *(void *)(v8 + 72);
    swift_bridgeObjectRetain();
    do
    {
      AnnotatedFeature.feature.getter();
      Column.append(_:)();
      OUTLINED_FUNCTION_21_4();
      v9();
      AnnotatedFeature.annotation.getter();
      Column.append(_:)();
      swift_bridgeObjectRelease();
      v7 += v14;
      --v5;
    }
    while (v5);
    swift_bridgeObjectRelease();
  }
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<AnyColumn>);
  uint64_t v10 = type metadata accessor for AnyColumn();
  OUTLINED_FUNCTION_1(v10);
  *(_OWORD *)(OUTLINED_FUNCTION_109_0() + 16) = xmmword_2272CB4D0;
  Column.eraseToAnyColumn()();
  Column.eraseToAnyColumn()();
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [AnyColumn]);
  lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [AnyColumn] and conformance [A], &demangling cache variable for type metadata for [AnyColumn]);
  DataFrame.init<A>(columns:)();
  OUTLINED_FUNCTION_11_3();
  v11();
  OUTLINED_FUNCTION_137();
  return v12();
}

uint64_t SoundClassifierTrainingSessionDelegate.save(to:)(uint64_t a1)
{
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
  uint64_t v6 = OUTLINED_FUNCTION_17(v5);
  MEMORY[0x270FA5388](v6);
  uint64_t v7 = OUTLINED_FUNCTION_104_0();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v8);
  OUTLINED_FUNCTION_41_0();
  uint64_t v9 = v1 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingParameters;
  OUTLINED_FUNCTION_53();
  outlined init with copy of URL?(v9, v2, &demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
  OUTLINED_FUNCTION_57_4(v2, 1, v7);
  if (v10)
  {
    outlined destroy of URL?(v2, &demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
    lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    OUTLINED_FUNCTION_85();
    *(void *)uint64_t v11 = 0xD000000000000030;
    *(void *)(v11 + 8) = 0x80000002272D69A0;
    *(_OWORD *)(v11 + 16) = 0u;
    *(_OWORD *)(v11 + 32) = 0u;
    *(unsigned char *)(v11 + 48) = 2;
    return swift_willThrow();
  }
  else
  {
    outlined init with take of MLSoundClassifier.Model(v2, v3, (void (*)(void))type metadata accessor for MLSoundClassifier.PersistentParameters);
    MLSoundClassifier.PersistentParameters.save(toSessionDirectory:)(a1);
    return outlined destroy of MLSoundClassifier.Model(v3, (void (*)(void))type metadata accessor for MLSoundClassifier.PersistentParameters);
  }
}

void SoundClassifierTrainingSessionDelegate.restore(from:phase:)()
{
  OUTLINED_FUNCTION_9_0();
  uint64_t v31 = v0;
  uint64_t v32 = v4;
  uint64_t v6 = v5;
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
  uint64_t v8 = OUTLINED_FUNCTION_17(v7);
  MEMORY[0x270FA5388](v8);
  OUTLINED_FUNCTION_33();
  uint64_t v11 = v9 - v10;
  MEMORY[0x270FA5388](v12);
  uint64_t v14 = (char *)&v31 - v13;
  uint64_t v15 = type metadata accessor for URL();
  OUTLINED_FUNCTION_0();
  uint64_t v17 = v16;
  MEMORY[0x270FA5388](v18);
  OUTLINED_FUNCTION_41_0();
  uint64_t v19 = type metadata accessor for MLSoundClassifier.PersistentParameters();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v20);
  OUTLINED_FUNCTION_33();
  uint64_t v23 = v21 - v22;
  MEMORY[0x270FA5388](v24);
  OUTLINED_FUNCTION_115_0();
  unsigned __int8 v25 = *v6;
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v17 + 16))(v2, v32, v15);
  MLSoundClassifier.PersistentParameters.init(sessionDirectory:)(v2, v3);
  if (!v1)
  {
    uint64_t v26 = v11;
    uint64_t v27 = v31 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingParameters;
    OUTLINED_FUNCTION_53();
    outlined init with copy of URL?(v27, (uint64_t)v14, &demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
    OUTLINED_FUNCTION_57_4((uint64_t)v14, 1, v19);
    if (v28)
    {
      outlined destroy of URL?((uint64_t)v14, &demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
      outlined init with take of MLSoundClassifier.Model(v3, v26, (void (*)(void))type metadata accessor for MLSoundClassifier.PersistentParameters);
      __swift_storeEnumTagSinglePayload(v26, 0, 1, v19);
      OUTLINED_FUNCTION_81_2();
      outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v26, v27, &demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
      swift_endAccess();
    }
    else
    {
      outlined init with take of MLSoundClassifier.Model((uint64_t)v14, v23, (void (*)(void))type metadata accessor for MLSoundClassifier.PersistentParameters);
      unsigned __int8 v33 = v25;
      SoundClassifierTrainingSessionDelegate.verifyThatParametersAreCompatible(_:_:phase:)(v3, v23, &v33);
      outlined destroy of MLSoundClassifier.Model(v23, (void (*)(void))type metadata accessor for MLSoundClassifier.PersistentParameters);
      uint64_t v29 = OUTLINED_FUNCTION_42_4();
      outlined destroy of MLSoundClassifier.Model(v29, v30);
    }
  }
  OUTLINED_FUNCTION_8_1();
}

void SoundClassifierTrainingSessionDelegate.verifyThatParametersAreCompatible(_:_:phase:)(uint64_t a1, uint64_t a2, unsigned __int8 *a3)
{
  uint64_t v113 = a2;
  uint64_t v7 = type metadata accessor for MLSoundClassifier.DataSource();
  uint64_t v8 = OUTLINED_FUNCTION_17(v7);
  MEMORY[0x270FA5388](v8);
  uint64_t v112 = (char *)&v102 - ((v9 + 15) & 0xFFFFFFFFFFFFFFF0);
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v10);
  OUTLINED_FUNCTION_106();
  uint64_t v111 = v11;
  uint64_t v12 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v13);
  OUTLINED_FUNCTION_63();
  MEMORY[0x270FA5388](v14);
  uint64_t v16 = (char *)&v102 - v15;
  uint64_t v17 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (MLSoundClassifier.ModelParameters.ValidationData, MLSoundClassifier.ModelParameters.ValidationData));
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v18);
  OUTLINED_FUNCTION_24_4();
  uint64_t v19 = *a3;
  uint64_t v20 = a1;
  uint64_t v21 = v116;
  MLSoundClassifier.DataSource.labeledSounds()();
  if (v21) {
    return;
  }
  uint64_t v107 = v17;
  uint64_t v108 = v3;
  uint64_t v109 = v16;
  uint64_t v110 = v12;
  uint64_t v106 = v19;
  uint64_t v116 = v4;
  uint64_t v23 = specialized Sequence.flatMap<A>(_:)(v22);
  uint64_t v24 = v113;
  swift_bridgeObjectRelease();
  uint64_t v25 = type metadata accessor for MLSoundClassifier.PersistentParameters();
  uint64_t v26 = *(int *)(v25 + 28);
  double v27 = *(double *)(v20 + v26);
  uint64_t v28 = specialized static MLSoundClassifier.filterFilesForFeatureExtractor<A>(labeledFiles:featureExtractionTimeWindowSize:)(v23, v27);
  swift_bridgeObjectRelease();
  MLSoundClassifier.DataSource.labeledSounds()();
  uint64_t v105 = v20;
  uint64_t v30 = specialized Sequence.flatMap<A>(_:)(v29);
  swift_bridgeObjectRelease();
  uint64_t v31 = *(int *)(v25 + 28);
  double v32 = *(double *)(v24 + v31);
  uint64_t v33 = specialized static MLSoundClassifier.filterFilesForFeatureExtractor<A>(labeledFiles:featureExtractionTimeWindowSize:)(v30, v32);
  swift_bridgeObjectRelease();
  LOBYTE(v30) = specialized static Array<A>.== infix(_:_:)(v28, v33);
  swift_bridgeObjectRelease();
  swift_bridgeObjectRelease();
  if ((v30 & 1) == 0)
  {
    lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    OUTLINED_FUNCTION_85();
    *(void *)uint64_t v57 = 1;
    *(_OWORD *)(v57 + 8) = 0u;
    *(_OWORD *)(v57 + 24) = 0u;
    *(void *)(v57 + 40) = 0;
    char v58 = 4;
LABEL_26:
    *(unsigned char *)(v57 + 48) = v58;
    swift_willThrow();
    return;
  }
  uint64_t v103 = v31;
  uint64_t v104 = (int *)v25;
  uint64_t v34 = *(int *)(v25 + 20);
  uint64_t v35 = v24 + v34;
  uint64_t v36 = v116;
  uint64_t v37 = v116 + *(int *)(v107 + 48);
  outlined init with copy of MLSoundClassifier.ModelParameters.ValidationData(v105 + v34, v116, (void (*)(void))type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
  outlined init with copy of MLSoundClassifier.ModelParameters.ValidationData(v35, v37, (void (*)(void))type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload();
  uint64_t v39 = (uint64_t)v112;
  uint64_t v40 = (uint64_t)v109;
  switch(EnumCaseMultiPayload)
  {
    case 1:
      outlined init with copy of MLSoundClassifier.ModelParameters.ValidationData(v36, (uint64_t)v109, (void (*)(void))type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
      if (swift_getEnumCaseMultiPayload() != 1)
      {
        outlined destroy of MLSoundClassifier.Model(v40, (void (*)(void))type metadata accessor for MLSoundClassifier.DataSource);
LABEL_30:
        lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
        uint64_t v75 = OUTLINED_FUNCTION_85();
        OUTLINED_FUNCTION_30_7(v75, v76);
        outlined destroy of URL?(v36, &demangling cache variable for type metadata for (MLSoundClassifier.ModelParameters.ValidationData, MLSoundClassifier.ModelParameters.ValidationData));
        return;
      }
      uint64_t v110 = v26;
      uint64_t v59 = v40;
      uint64_t v60 = v111;
      outlined init with take of MLSoundClassifier.Model(v59, v111, (void (*)(void))type metadata accessor for MLSoundClassifier.DataSource);
      outlined init with take of MLSoundClassifier.Model(v37, v39, (void (*)(void))type metadata accessor for MLSoundClassifier.DataSource);
      MLSoundClassifier.DataSource.labeledSounds()();
      uint64_t v79 = specialized Sequence.flatMap<A>(_:)(v78);
      swift_bridgeObjectRelease();
      specialized static MLSoundClassifier.filterFilesForFeatureExtractor<A>(labeledFiles:featureExtractionTimeWindowSize:)(v79, v27);
      swift_bridgeObjectRelease();
      MLSoundClassifier.DataSource.labeledSounds()();
      uint64_t v90 = specialized Sequence.flatMap<A>(_:)(v80);
      swift_bridgeObjectRelease();
      specialized static MLSoundClassifier.filterFilesForFeatureExtractor<A>(labeledFiles:featureExtractionTimeWindowSize:)(v90, v32);
      swift_bridgeObjectRelease();
      uint64_t v91 = OUTLINED_FUNCTION_126();
      LOBYTE(v90) = specialized static Array<A>.== infix(_:_:)(v91, v92);
      swift_bridgeObjectRelease();
      swift_bridgeObjectRelease();
      if ((v90 & 1) == 0)
      {
        lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
        uint64_t v100 = OUTLINED_FUNCTION_85();
        OUTLINED_FUNCTION_30_7(v100, v101);
        outlined destroy of MLSoundClassifier.Model(v39, (void (*)(void))type metadata accessor for MLSoundClassifier.DataSource);
        outlined destroy of MLSoundClassifier.Model(v60, (void (*)(void))type metadata accessor for MLSoundClassifier.DataSource);
        goto LABEL_56;
      }
      outlined destroy of MLSoundClassifier.Model(v39, (void (*)(void))type metadata accessor for MLSoundClassifier.DataSource);
      outlined destroy of MLSoundClassifier.Model(v60, (void (*)(void))type metadata accessor for MLSoundClassifier.DataSource);
      uint64_t v26 = v110;
LABEL_7:
      outlined destroy of MLSoundClassifier.Model(v36, (void (*)(void))type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
      uint64_t v41 = v105;
      if (*(double *)(v105 + v104[6]) != *(double *)(v24 + v104[6]))
      {
        uint64_t v67 = Double.description.getter();
        uint64_t v69 = v68;
        uint64_t v70 = Double.description.getter();
        uint64_t v72 = v71;
        lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
        OUTLINED_FUNCTION_85();
        *(_OWORD *)uint64_t v57 = xmmword_2272CD520;
LABEL_24:
        *(void *)(v57 + 16) = v67;
        *(void *)(v57 + 24) = v69;
        *(void *)(v57 + 32) = v70;
        *(void *)(v57 + 40) = v72;
LABEL_25:
        char v58 = 3;
        goto LABEL_26;
      }
      if (*(double *)(v105 + v26) != *(double *)(v24 + v103))
      {
        uint64_t v67 = Double.description.getter();
        uint64_t v69 = v73;
        uint64_t v70 = Double.description.getter();
        uint64_t v72 = v74;
        lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
        OUTLINED_FUNCTION_85();
        *(void *)uint64_t v57 = 0xD000000000000023;
        *(void *)(v57 + 8) = 0x80000002272D6950;
        goto LABEL_24;
      }
      uint64_t v42 = v104[9];
      uint64_t v43 = *(void *)(v105 + v42);
      uint64_t v44 = *(unsigned __int8 *)(v105 + v42 + 8);
      uint64_t v45 = v24 + v42;
      uint64_t v46 = *(void *)v45;
      char v47 = *(unsigned char *)(v45 + 8);
      if (v44)
      {
        if (v43 == *(void *)v45) {
          char v48 = *(unsigned char *)(v45 + 8);
        }
        else {
          char v48 = 0;
        }
        if ((v48 & 1) == 0) {
          goto LABEL_14;
        }
      }
      else
      {
        if (v43 == *(void *)v45) {
          char v77 = *(unsigned char *)(v45 + 8);
        }
        else {
          char v77 = 1;
        }
        if (v77)
        {
LABEL_14:
          unint64_t v49 = OUTLINED_FUNCTION_143();
          OUTLINED_FUNCTION_96_0(v49, v50);
          OUTLINED_FUNCTION_86_1();
          swift_bridgeObjectRelease();
          uint64_t v51 = v114;
          uint64_t v52 = v115;
          uint64_t v114 = v44;
          LOBYTE(v115) = v47;
          unint64_t v53 = MLSoundClassifier.ModelParameters.FeatureExtractorType.description.getter();
          OUTLINED_FUNCTION_96_0(v53, v54);
          OUTLINED_FUNCTION_86_1();
          swift_bridgeObjectRelease();
          uint64_t v55 = v114;
          uint64_t v56 = v115;
          lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
          OUTLINED_FUNCTION_85();
          *(void *)uint64_t v57 = 0xD000000000000011;
          *(void *)(v57 + 8) = 0x80000002272D6980;
          *(void *)(v57 + 16) = v51;
          *(void *)(v57 + 24) = v52;
LABEL_15:
          *(void *)(v57 + 32) = v55;
          *(void *)(v57 + 40) = v56;
          goto LABEL_25;
        }
      }
      switch(v106)
      {
        case 1:
          swift_bridgeObjectRelease();
          return;
        case 2:
          OUTLINED_FUNCTION_155();
          goto LABEL_39;
        case 3:
          OUTLINED_FUNCTION_154();
          goto LABEL_39;
        case 4:
          OUTLINED_FUNCTION_55_0();
          goto LABEL_39;
        default:
LABEL_39:
          uint64_t v116 = v46;
          char v81 = OUTLINED_FUNCTION_87_0();
          swift_bridgeObjectRelease();
          if (v81) {
            return;
          }
          uint64_t v82 = v104[8];
          uint64_t v83 = *(void *)(v41 + v82);
          uint64_t v84 = *(void *)(v24 + v82);
          if (v83 != v84)
          {
            uint64_t v114 = v83;
            lazy protocol witness table accessor for type Int and conformance Int();
            uint64_t v86 = BinaryInteger.description.getter();
            uint64_t v88 = v87;
            uint64_t v114 = v84;
            uint64_t v55 = BinaryInteger.description.getter();
            uint64_t v56 = v89;
            lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
            OUTLINED_FUNCTION_85();
            *(_OWORD *)uint64_t v57 = xmmword_2272CD530;
            *(void *)(v57 + 16) = v86;
            *(void *)(v57 + 24) = v88;
            goto LABEL_15;
          }
          if (v44)
          {
            if (v43 == v116) {
              char v85 = v47;
            }
            else {
              char v85 = 0;
            }
            if ((v85 & 1) == 0)
            {
LABEL_54:
              unint64_t v94 = OUTLINED_FUNCTION_143();
              OUTLINED_FUNCTION_96_0(v94, v95);
              OUTLINED_FUNCTION_86_1();
              swift_bridgeObjectRelease();
              uint64_t v96 = v114;
              uint64_t v97 = v115;
              uint64_t v114 = v44;
              LOBYTE(v115) = v47;
              unint64_t v98 = MLSoundClassifier.ModelParameters.FeatureExtractorType.description.getter();
              OUTLINED_FUNCTION_96_0(v98, v99);
              OUTLINED_FUNCTION_86_1();
              swift_bridgeObjectRelease();
              uint64_t v55 = v114;
              uint64_t v56 = v115;
              lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
              OUTLINED_FUNCTION_85();
              *(_OWORD *)uint64_t v57 = xmmword_2272CD540;
              *(void *)(v57 + 16) = v96;
              *(void *)(v57 + 24) = v97;
              goto LABEL_15;
            }
          }
          else
          {
            if (v43 == v116) {
              char v93 = v47;
            }
            else {
              char v93 = 1;
            }
            if (v93) {
              goto LABEL_54;
            }
          }
          break;
      }
      return;
    case 2:
      outlined init with copy of MLSoundClassifier.ModelParameters.ValidationData(v36, v108, (void (*)(void))type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
      if (swift_getEnumCaseMultiPayload() == 2)
      {
        uint64_t v61 = (void *)OUTLINED_FUNCTION_126();
        specialized static Dictionary<>.== infix(_:_:)(v61, v62);
        char v64 = v63;
        swift_bridgeObjectRelease();
        swift_bridgeObjectRelease();
        if (v64) {
          goto LABEL_7;
        }
        lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
        uint64_t v65 = OUTLINED_FUNCTION_85();
        OUTLINED_FUNCTION_30_7(v65, v66);
LABEL_56:
        outlined destroy of MLSoundClassifier.Model(v36, (void (*)(void))type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
        return;
      }
      swift_bridgeObjectRelease();
      goto LABEL_30;
    default:
      outlined destroy of MLSoundClassifier.Model(v37, (void (*)(void))type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
      goto LABEL_7;
  }
}

uint64_t SoundClassifierTrainingSessionDelegate.deinit()
{
  swift_bridgeObjectRelease();
  outlined destroy of MLSoundClassifier.Model(v0 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_sessionParameters, (void (*)(void))type metadata accessor for MLTrainingSessionParameters);
  outlined destroy of URL?(v0 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingParameters, &demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
  swift_bridgeObjectRelease();
  swift_bridgeObjectRelease();
  swift_bridgeObjectRelease();
  swift_bridgeObjectRelease();
  swift_bridgeObjectRelease();
  outlined destroy of URL?(v0 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_classifier, &demangling cache variable for type metadata for MLSoundClassifier.Classifier?);
  outlined destroy of URL?(v0 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_model, &demangling cache variable for type metadata for MLSoundClassifier.Model?);
  outlined destroy of URL?(v0 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_parameters, &demangling cache variable for type metadata for MLSoundClassifier.ModelParameters?);
  outlined destroy of URL?(v0 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingMetrics, &demangling cache variable for type metadata for MLClassifierMetrics?);
  outlined destroy of URL?(v0 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationMetrics, &demangling cache variable for type metadata for MLClassifierMetrics?);
  outlined destroy of URL?(v0 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_tablePrinter, &demangling cache variable for type metadata for TrainingTablePrinter?);
  return v0;
}

uint64_t SoundClassifierTrainingSessionDelegate.__deallocating_deinit()
{
  SoundClassifierTrainingSessionDelegate.deinit();
  OUTLINED_FUNCTION_4_12();

  return swift_deallocClassInstance();
}

uint64_t ObjC metadata update function for SoundClassifierTrainingSessionDelegate()
{
  return type metadata accessor for SoundClassifierTrainingSessionDelegate();
}

uint64_t type metadata accessor for SoundClassifierTrainingSessionDelegate()
{
  uint64_t result = type metadata singleton initialization cache for SoundClassifierTrainingSessionDelegate;
  if (!type metadata singleton initialization cache for SoundClassifierTrainingSessionDelegate) {
    return swift_getSingletonMetadata();
  }
  return result;
}

void type metadata completion function for SoundClassifierTrainingSessionDelegate()
{
  type metadata accessor for MLTrainingSessionParameters();
  if (v0 <= 0x3F)
  {
    type metadata accessor for MLSoundClassifier.PersistentParameters?(319, &lazy cache variable for type metadata for MLSoundClassifier.PersistentParameters?, (void (*)(uint64_t))type metadata accessor for MLSoundClassifier.PersistentParameters);
    if (v1 <= 0x3F)
    {
      type metadata accessor for MLSoundClassifier.PersistentParameters?(319, &lazy cache variable for type metadata for MLSoundClassifier.Classifier?, (void (*)(uint64_t))type metadata accessor for MLSoundClassifier.Classifier);
      if (v2 <= 0x3F)
      {
        type metadata accessor for MLSoundClassifier.PersistentParameters?(319, &lazy cache variable for type metadata for MLSoundClassifier.Model?, (void (*)(uint64_t))type metadata accessor for MLSoundClassifier.Model);
        if (v3 <= 0x3F)
        {
          type metadata accessor for MLSoundClassifier.PersistentParameters?(319, &lazy cache variable for type metadata for MLSoundClassifier.ModelParameters?, (void (*)(uint64_t))type metadata accessor for MLSoundClassifier.ModelParameters);
          if (v4 <= 0x3F)
          {
            type metadata accessor for MLSoundClassifier.PersistentParameters?(319, &lazy cache variable for type metadata for MLClassifierMetrics?, (void (*)(uint64_t))type metadata accessor for MLClassifierMetrics);
            if (v5 <= 0x3F)
            {
              type metadata accessor for MLSoundClassifier.PersistentParameters?(319, (unint64_t *)&lazy cache variable for type metadata for TrainingTablePrinter?, (void (*)(uint64_t))type metadata accessor for TrainingTablePrinter);
              if (v6 <= 0x3F) {
                swift_updateClassMetadata2();
              }
            }
          }
        }
      }
    }
  }
}

void type metadata accessor for MLSoundClassifier.PersistentParameters?(uint64_t a1, unint64_t *a2, void (*a3)(uint64_t))
{
  if (!*a2)
  {
    a3(255);
    unint64_t v4 = type metadata accessor for Optional();
    if (!v5) {
      atomic_store(v4, a2);
    }
  }
}

void protocol witness for TrainingSessionDelegate.setUp() in conformance SoundClassifierTrainingSessionDelegate()
{
}

void protocol witness for TrainingSessionDelegate.resume(from:) in conformance SoundClassifierTrainingSessionDelegate(Swift::OpaquePointer a1)
{
}

unint64_t protocol witness for TrainingSessionDelegate.itemCount(phase:) in conformance SoundClassifierTrainingSessionDelegate(CreateML::MLPhase a1)
{
  return (unint64_t)SoundClassifierTrainingSessionDelegate.itemCount(phase:)(a1);
}

uint64_t protocol witness for TrainingSessionDelegate.extractFeatures(from:) in conformance SoundClassifierTrainingSessionDelegate(Swift::Int a1)
{
  Swift::tuple_Int_finished_Bool v9 = SoundClassifierTrainingSessionDelegate.extractFeatures(from:)(a1);
  if (v3)
  {
    unint64_t v4 = *(uint64_t (**)(uint64_t, uint64_t))(v1 + 8);
    uint64_t v5 = v1;
    BOOL finished = 0;
  }
  else
  {
    Swift::Int v2 = v9._0;
    v9._0 = *(void *)(v1 + 8);
    BOOL finished = v9.finished;
    uint64_t v5 = v1;
  }
  return protocol witness for TrainingSessionDelegate.extractFeatures(from:) in conformance SoundClassifierTrainingSessionDelegate(v4, v5, v2, finished);
}

uint64_t protocol witness for TrainingSessionDelegate.train(from:) in conformance SoundClassifierTrainingSessionDelegate()
{
  uint64_t v1 = (void *)swift_task_alloc();
  *(void *)(v0 + 16) = v1;
  void *v1 = v0;
  v1[1] = protocol witness for TrainingSessionDelegate.train(from:) in conformance SoundClassifierTrainingSessionDelegate;
  return SoundClassifierTrainingSessionDelegate.train(from:)();
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  void *v3;
  uint64_t v4;
  uint64_t (*v5)(uint64_t);
  uint64_t v7;

  OUTLINED_FUNCTION_60_0();
  OUTLINED_FUNCTION_2();
  Swift::Int v2 = *v1;
  OUTLINED_FUNCTION_6();
  *uint64_t v3 = v2;
  unint64_t v4 = swift_task_dealloc();
  uint64_t v5 = *(uint64_t (**)(uint64_t))(v2 + 8);
  if (!v0) {
    unint64_t v4 = OUTLINED_FUNCTION_173();
  }
  return v5(v4);
}

uint64_t protocol witness for TrainingSessionDelegate.evaluate(from:) in conformance SoundClassifierTrainingSessionDelegate()
{
  uint64_t v1 = (void *)swift_task_alloc();
  *(void *)(v0 + 16) = v1;
  void *v1 = v0;
  v1[1] = protocol witness for TrainingSessionDelegate.evaluate(from:) in conformance SoundClassifierTrainingSessionDelegate;
  return SoundClassifierTrainingSessionDelegate.evaluate(from:)();
}

{
  uint64_t v0;
  uint64_t *v1;
  char v2;
  char v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  void *v7;
  uint64_t v8;
  uint64_t (*v9)(uint64_t, uint64_t);
  uint64_t v10;
  uint64_t v12;

  OUTLINED_FUNCTION_60_0();
  uint64_t v3 = v2;
  uint64_t v5 = v4;
  OUTLINED_FUNCTION_2();
  unint64_t v6 = *v1;
  OUTLINED_FUNCTION_6();
  void *v7 = v6;
  uint64_t v8 = swift_task_dealloc();
  Swift::tuple_Int_finished_Bool v9 = *(uint64_t (**)(uint64_t, uint64_t))(v6 + 8);
  if (v0)
  {
    uint64_t v10 = 0;
  }
  else
  {
    uint64_t v10 = v3 & 1;
    uint64_t v8 = v5;
  }
  return v9(v8, v10);
}

uint64_t protocol witness for TrainingSessionDelegate.saveCheckpoint(to:phase:iteration:) in conformance SoundClassifierTrainingSessionDelegate()
{
  SoundClassifierTrainingSessionDelegate.saveCheckpoint(to:phase:iteration:)();
  return v0 & 1;
}

BOOL protocol witness for TrainingSessionDelegate.shouldTransition(from:to:) in conformance SoundClassifierTrainingSessionDelegate(CreateML::MLPhase a1, CreateML::MLPhase a2)
{
  return SoundClassifierTrainingSessionDelegate.shouldTransition(from:to:)(a1, a2);
}

uint64_t protocol witness for TrainingSessionCodable.save(to:) in conformance SoundClassifierTrainingSessionDelegate(uint64_t a1)
{
  return SoundClassifierTrainingSessionDelegate.save(to:)(a1);
}

void protocol witness for TrainingSessionCodable.restore(from:phase:) in conformance SoundClassifierTrainingSessionDelegate()
{
}

uint64_t specialized MLSoundClassifier.FeatureExtractor.init<A>(files:options:)(uint64_t a1, uint64_t a2, uint64_t a3, unint64_t a4, _OWORD *a5)
{
  uint64_t v6 = v5;
  *(void *)(v6 + 72) = MEMORY[0x263F8EE88];
  *(void *)(v6 + 80) = objc_msgSend(objc_allocWithZone(MEMORY[0x263F08958]), sel_init);
  long long v11 = a5[1];
  *(_OWORD *)(v6 + 16) = *a5;
  *(_OWORD *)(v6 + 32) = v11;
  *(_OWORD *)(v6 + 41) = *(_OWORD *)((char *)a5 + 25);
  uint64_t v12 = swift_unknownObjectRetain();
  *(void *)(v6 + 64) = specialized Array.init<A>(_:)(v12, a2, a3, a4, (uint64_t (*)(uint64_t, uint64_t, uint64_t, unint64_t))specialized _copyCollectionToContiguousArray<A>(_:));
  if (*(double *)a5 < 0.0 || *(double *)a5 >= 1.0)
  {
    swift_release();
    _StringGuts.grow(_:)(61);
    v14._uint64_t object = (void *)0x80000002272D6870;
    v14._uint64_t countAndFlagsBits = 0xD00000000000003ALL;
    String.append(_:)(v14);
    Double.write<A>(to:)();
    v15._uint64_t countAndFlagsBits = 46;
    v15._uint64_t object = (void *)0xE100000000000000;
    String.append(_:)(v15);
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Any>);
    uint64_t v16 = swift_allocObject();
    *(_OWORD *)(v16 + 16) = xmmword_2272CB370;
    *(void *)(v16 + 56) = MEMORY[0x263F8D310];
    *(void *)(v16 + 32) = 0;
    *(void *)(v16 + 40) = 0xE000000000000000;
    swift_bridgeObjectRetain();
    print(_:separator:terminator:)();
    swift_bridgeObjectRelease();
    lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError();
    *(void *)uint64_t v17 = 0;
    *(void *)(v17 + 8) = 0xE000000000000000;
    *(_OWORD *)(v17 + 16) = 0u;
    *(_OWORD *)(v17 + 32) = 0u;
    *(unsigned char *)(v17 + 48) = 0;
    swift_willThrow();
  }
  swift_unknownObjectRelease();
  return v6;
}

uint64_t specialized MLSoundClassifier.FeatureExtractor.init<A>(files:options:)(uint64_t a1, _OWORD *a2)
{
  uint64_t v3 = v2;
  *(void *)(v3 + 72) = MEMORY[0x263F8EE88];
  *(void *)(v3 + 80) = objc_msgSend(objc_allocWithZone(MEMORY[0x263F08958]), sel_init);
  long long v6 = a2[1];
  *(_OWORD *)(v3 + 16) = *a2;
  *(_OWORD *)(v3 + 32) = v6;
  *(_OWORD *)(v3 + 41) = *(_OWORD *)((char *)a2 + 25);
  *(void *)(v3 + 64) = a1;
  if (*(double *)a2 < 0.0 || *(double *)a2 >= 1.0)
  {
    swift_bridgeObjectRetain();
    swift_release();
    _StringGuts.grow(_:)(61);
    v8._uint64_t object = (void *)0x80000002272D6870;
    v8._uint64_t countAndFlagsBits = 0xD00000000000003ALL;
    String.append(_:)(v8);
    Double.write<A>(to:)();
    v9._uint64_t countAndFlagsBits = 46;
    v9._uint64_t object = (void *)0xE100000000000000;
    String.append(_:)(v9);
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Any>);
    uint64_t v10 = swift_allocObject();
    *(_OWORD *)(v10 + 16) = xmmword_2272CB370;
    *(void *)(v10 + 56) = MEMORY[0x263F8D310];
    *(void *)(v10 + 32) = 0;
    *(void *)(v10 + 40) = 0xE000000000000000;
    swift_bridgeObjectRetain();
    print(_:separator:terminator:)();
    swift_bridgeObjectRelease();
    lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    OUTLINED_FUNCTION_85();
    *(void *)uint64_t v11 = 0;
    *(void *)(v11 + 8) = 0xE000000000000000;
    *(_OWORD *)(v11 + 16) = 0u;
    *(_OWORD *)(v11 + 32) = 0u;
    *(unsigned char *)(v11 + 48) = 0;
    swift_willThrow();
    swift_bridgeObjectRelease();
  }
  return v3;
}

BOOL specialized Sequence<>.lexicographicallyPrecedes<A>(_:)()
{
  swift_bridgeObjectRetain();
  swift_bridgeObjectRetain();
  Swift::String_optional v0 = String.Iterator.next()();
  if (v0.value._object)
  {
    uint64_t countAndFlagsBits = v0.value._countAndFlagsBits;
    uint64_t object = v0.value._object;
    do
    {
      Swift::String_optional v3 = String.Iterator.next()();
      if (!v3.value._object)
      {
        swift_bridgeObjectRelease();
LABEL_15:
        swift_bridgeObjectRelease();
        BOOL v8 = 0;
        goto LABEL_17;
      }
      if (countAndFlagsBits == v3.value._countAndFlagsBits && object == v3.value._object)
      {
        swift_bridgeObjectRelease();
        swift_bridgeObjectRelease();
      }
      else
      {
        if (_stringCompareWithSmolCheck(_:_:expecting:)())
        {
          swift_bridgeObjectRelease();
          swift_bridgeObjectRelease();
          swift_bridgeObjectRelease();
          BOOL v8 = 1;
          goto LABEL_17;
        }
        char v5 = _stringCompareWithSmolCheck(_:_:expecting:)();
        swift_bridgeObjectRelease();
        swift_bridgeObjectRelease();
        if (v5) {
          goto LABEL_15;
        }
      }
      Swift::String_optional v6 = String.Iterator.next()();
      uint64_t countAndFlagsBits = v6.value._countAndFlagsBits;
      uint64_t object = v6.value._object;
    }
    while (v6.value._object);
  }
  swift_bridgeObjectRelease();
  uint64_t v7 = String.Iterator.next()().value._object;
  swift_bridgeObjectRelease();
  BOOL v8 = v7 != 0;
LABEL_17:
  swift_bridgeObjectRelease();
  return v8;
}

id @nonobjc AVAudioFile.init(forReading:)(uint64_t a1)
{
  uint64_t v2 = v1;
  Swift::String v15 = (NSURL *)*MEMORY[0x263EF8340];
  URL._bridgeToObjectiveC()(v15);
  char v5 = v4;
  id v14 = 0;
  id v6 = objc_msgSend(v2, sel_initForReading_error_, v4, &v14);

  id v7 = v14;
  if (v6)
  {
    type metadata accessor for URL();
    OUTLINED_FUNCTION_8();
    Swift::String v9 = *(void (**)(void))(v8 + 8);
    id v10 = v7;
    OUTLINED_FUNCTION_24_5();
    v9();
  }
  else
  {
    id v11 = v14;
    _convertNSErrorToError(_:)();

    swift_willThrow();
    type metadata accessor for URL();
    OUTLINED_FUNCTION_8();
    (*(void (**)(uint64_t))(v12 + 8))(a1);
  }
  return v6;
}

uint64_t sub_2270F5E48@<X0>(void *a1@<X8>)
{
  return key path getter for AnnotatedFeature.annotation : AnnotatedFeature<MLShapedArray<Float>, String>(&demangling cache variable for type metadata for AnnotatedFeature<MLShapedArray<Float>, String>, a1);
}

uint64_t sub_2270F5E68(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return key path setter for AnnotatedFeature.annotation : AnnotatedFeature<MLShapedArray<Float>, String>(a1, a2, a3, a4, &demangling cache variable for type metadata for AnnotatedFeature<MLShapedArray<Float>, String>);
}

uint64_t sub_2270F5E90()
{
  return MEMORY[0x263F8D320];
}

uint64_t outlined consume of (@escaping @callee_guaranteed @Sendable (@in_guaranteed Event) -> ())?(uint64_t result)
{
  if (result) {
    return swift_release();
  }
  return result;
}

uint64_t partial apply for closure #2 in SoundClassifierTrainingSessionDelegate.train(from:)(uint64_t a1)
{
  return partial apply for closure #2 in SoundClassifierTrainingSessionDelegate.train(from:)(a1, (uint64_t (*)(uint64_t, uint64_t, uint64_t))closure #2 in SoundClassifierTrainingSessionDelegate.train(from:));
}

uint64_t objectdestroyTm_1()
{
  uint64_t v1 = (int *)(type metadata accessor for TrainingTablePrinter(0) - 8);
  uint64_t v2 = *(unsigned __int8 *)(*(void *)v1 + 80);
  uint64_t v3 = (v2 + 24) & ~v2;
  uint64_t v4 = v3 + *(void *)(*(void *)v1 + 64);
  uint64_t v5 = v2 | 7;
  swift_release();
  type metadata accessor for Date();
  OUTLINED_FUNCTION_8();
  OUTLINED_FUNCTION_25_0();
  v6();

  swift_bridgeObjectRelease();

  return MEMORY[0x270FA0238](v0, v4, v5);
}

uint64_t partial apply for closure #1 in SoundClassifierTrainingSessionDelegate.train(from:)(uint64_t a1)
{
  return partial apply for closure #2 in SoundClassifierTrainingSessionDelegate.train(from:)(a1, (uint64_t (*)(uint64_t, uint64_t, uint64_t))closure #1 in SoundClassifierTrainingSessionDelegate.train(from:));
}

uint64_t partial apply for closure #2 in SoundClassifierTrainingSessionDelegate.train(from:)(uint64_t a1, uint64_t (*a2)(uint64_t, uint64_t, uint64_t))
{
  uint64_t v4 = type metadata accessor for TrainingTablePrinter(0);
  OUTLINED_FUNCTION_39_0(v4);
  uint64_t v6 = *(void *)(v2 + 16);
  uint64_t v7 = v2 + ((*(unsigned __int8 *)(v5 + 80) + 24) & ~(unint64_t)*(unsigned __int8 *)(v5 + 80));

  return a2(a1, v6, v7);
}

void specialized MutableCollection<>.sort(by:)(uint64_t *a1)
{
  uint64_t v2 = *(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>)
                 - 8);
  uint64_t v3 = *a1;
  if ((swift_isUniquelyReferenced_nonNull_native() & 1) == 0)
  {
    specialized _ContiguousArrayBuffer._consumeAndCreateNew()();
    uint64_t v3 = v4;
  }
  uint64_t v5 = *(void *)(v3 + 16);
  v6[0] = v3 + ((*(unsigned __int8 *)(v2 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v2 + 80));
  v6[1] = v5;
  specialized UnsafeMutableBufferPointer._stableSortImpl(by:)((unint64_t)v6);
  *a1 = v3;
}

{
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;

  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
  OUTLINED_FUNCTION_39_0(v2);
  uint64_t v3 = *a1;
  if ((swift_isUniquelyReferenced_nonNull_native() & 1) == 0)
  {
    specialized _ContiguousArrayBuffer._consumeAndCreateNew()();
    uint64_t v3 = v4;
  }
  specialized UnsafeMutableBufferPointer._stableSortImpl(by:)();
  *a1 = v3;
}

{
  specialized MutableCollection<>.sort(by:)(a1);
}

{
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5[2];

  uint64_t v2 = *a1;
  if ((swift_isUniquelyReferenced_nonNull_native() & 1) == 0)
  {
    specialized _ContiguousArrayBuffer._consumeAndCreateNew()();
    uint64_t v2 = v3;
  }
  uint64_t v4 = *(void *)(v2 + 16);
  v5[0] = v2 + 32;
  v5[1] = v4;
  specialized UnsafeMutableBufferPointer._stableSortImpl(by:)(v5);
  *a1 = v2;
}

void specialized UnsafeMutableBufferPointer._stableSortImpl(by:)(unint64_t a1)
{
  uint64_t v2 = v1;
  uint64_t v150 = type metadata accessor for URL();
  uint64_t v4 = *(void *)(v150 - 8);
  MEMORY[0x270FA5388](v150);
  uint64_t v149 = (char *)&v129 - ((v5 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
  uint64_t v7 = *(void *)(v6 - 8);
  uint64_t v8 = MEMORY[0x270FA5388](v6);
  uint64_t v137 = (char *)&v129 - ((v9 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v10 = MEMORY[0x270FA5388](v8);
  uint64_t v152 = (char *)&v129 - v11;
  uint64_t v12 = MEMORY[0x270FA5388](v10);
  uint64_t v159 = (char *)&v129 - v13;
  MEMORY[0x270FA5388](v12);
  uint64_t v158 = (char *)&v129 - v14;
  Swift::Int v15 = *(void *)(a1 + 8);
  Swift::Int v16 = _minimumMergeRunLength(_:)(v15);
  if (v16 >= v15)
  {
    if (v15 < 0) {
      goto LABEL_140;
    }
    if (v15) {
      specialized MutableCollection<>._insertionSort(within:sortedEnd:by:)(0, v15, 1, (void *)a1);
    }
    return;
  }
  Swift::Int v132 = v16;
  uint64_t v130 = specialized static Array._allocateUninitialized(_:)(v15 / 2);
  unint64_t v139 = v17;
  uint64_t v141 = v7;
  uint64_t v131 = v15;
  if (v15 <= 0) {
    goto LABEL_103;
  }
  Swift::Int v18 = 0;
  int v147 = (void (**)(char *, uint64_t))(v4 + 8);
  uint64_t v148 = v7 + 16;
  long long v146 = (void (**)(char *, uint64_t))(v7 + 8);
  uint64_t v157 = (void (**)(char *, char *, uint64_t))(v7 + 32);
  uint64_t v19 = (char *)MEMORY[0x263F8EE78];
  uint64_t v140 = (char *)a1;
  uint64_t v160 = v6;
  while (1)
  {
    Swift::Int v20 = v18;
    Swift::Int v21 = v18 + 1;
    uint64_t v136 = v19;
    if (v18 + 1 < v15)
    {
      uint64_t v133 = v2;
      uint64_t v134 = *(void *)a1;
      uint64_t v22 = v134;
      Swift::Int v23 = *(void *)(v7 + 72);
      Swift::Int v154 = v15;
      Swift::Int v155 = v23;
      Swift::Int v151 = v18 + 1;
      uint64_t v24 = *(void (**)(void))(v7 + 16);
      ((void (*)(char *, uint64_t, uint64_t))v24)(v158, v134 + v23 * v21, v6);
      int v145 = v24;
      ((void (*)(char *, uint64_t, uint64_t))v24)(v159, v22 + v23 * v20, v6);
      Swift::Int v138 = v20;
      uint64_t v25 = v149;
      AnnotatedFeature.feature.getter();
      uint64_t countAndFlagsBits = (void (*)(char *, char *, uint64_t))URL.path(percentEncoded:)(1)._countAndFlagsBits;
      uint64_t v26 = (char *)*v147;
      uint64_t v27 = v6;
      uint64_t v28 = v150;
      (*v147)(v25, v150);
      AnnotatedFeature.feature.getter();
      URL.path(percentEncoded:)(1);
      uint64_t v29 = v25;
      Swift::Int v20 = v138;
      int v144 = (void (*)(char *, uint64_t))v26;
      ((void (*)(char *, uint64_t))v26)(v29, v28);
      LODWORD(v153) = specialized Sequence<>.lexicographicallyPrecedes<A>(_:)();
      swift_bridgeObjectRelease();
      swift_bridgeObjectRelease();
      uint64_t v30 = v141;
      uint64_t v31 = *(void (**)(char *, uint64_t))(v141 + 8);
      v31(v159, v27);
      uint64_t v32 = v27;
      Swift::Int v15 = v154;
      uint64_t v143 = (char *)v31;
      v31(v158, v32);
      Swift::Int v33 = v155;
      Swift::Int v21 = v20 + 2;
      if (v20 + 2 >= v15)
      {
        uint64_t v2 = v133;
        uint64_t v7 = v30;
      }
      else
      {
        Swift::Int v142 = v155 * v151;
        uint64_t v34 = v134;
        Swift::Int v135 = v155 * v21;
        while (1)
        {
          Swift::Int v151 = v21;
          uint64_t v35 = v160;
          uint64_t v36 = v145;
          v145();
          ((void (*)(char *, uint64_t, uint64_t))v36)(v159, v34 + v142, v35);
          uint64_t v37 = v149;
          AnnotatedFeature.feature.getter();
          uint64_t countAndFlagsBits = (void (*)(char *, char *, uint64_t))URL.path(percentEncoded:)(1)._countAndFlagsBits;
          uint64_t v38 = v150;
          uint64_t v39 = v144;
          v144(v37, v150);
          AnnotatedFeature.feature.getter();
          URL.path(percentEncoded:)(1);
          v39(v37, v38);
          BOOL v40 = specialized Sequence<>.lexicographicallyPrecedes<A>(_:)();
          swift_bridgeObjectRelease();
          swift_bridgeObjectRelease();
          uint64_t v41 = (void (*)(char *, uint64_t))v143;
          ((void (*)(char *, uint64_t))v143)(v159, v35);
          v41(v158, v35);
          if ((v153 ^ v40)) {
            break;
          }
          Swift::Int v21 = v151 + 1;
          Swift::Int v15 = v154;
          Swift::Int v33 = v155;
          v34 += v155;
          if (v151 + 1 >= v154)
          {
            Swift::Int v21 = v154;
            uint64_t v2 = v133;
            a1 = (unint64_t)v140;
            uint64_t v7 = v141;
            Swift::Int v20 = v138;
            goto LABEL_12;
          }
        }
        uint64_t v2 = v133;
        a1 = (unint64_t)v140;
        uint64_t v7 = v141;
        Swift::Int v21 = v151;
        Swift::Int v20 = v138;
        Swift::Int v15 = v154;
        Swift::Int v33 = v155;
      }
LABEL_12:
      uint64_t v42 = v136;
      uint64_t v6 = v160;
      if (v153)
      {
        if (v21 < v20) {
          goto LABEL_141;
        }
        if (v20 < v21)
        {
          uint64_t v43 = 0;
          uint64_t v44 = v33 * (v21 - 1);
          Swift::Int v45 = v21 * v33;
          uint64_t v46 = v20 * v33;
          Swift::Int v151 = v21;
          do
          {
            if (v20 != v21 + v43 - 1)
            {
              uint64_t v47 = v134;
              if (!v134) {
                goto LABEL_147;
              }
              uint64_t v48 = v2;
              unint64_t v49 = v134 + v46;
              uint64_t v153 = (char *)(v134 + v44);
              uint64_t v50 = v160;
              uint64_t countAndFlagsBits = *v157;
              ((void (*)(char *, uint64_t, uint64_t, char *))countAndFlagsBits)(v137, v134 + v46, v160, v42);
              if (v46 < v44 || v49 >= v47 + v45)
              {
                uint64_t v52 = v153;
                swift_arrayInitWithTakeFrontToBack();
              }
              else
              {
                uint64_t v52 = v153;
                if (v46 != v44) {
                  swift_arrayInitWithTakeBackToFront();
                }
              }
              countAndFlagsBits(v52, v137, v50);
              a1 = (unint64_t)v140;
              uint64_t v42 = v136;
              uint64_t v2 = v48;
              Swift::Int v21 = v151;
              Swift::Int v33 = v155;
            }
            ++v20;
            --v43;
            v44 -= v33;
            v45 -= v33;
            v46 += v33;
          }
          while (v20 < v21 + v43);
          uint64_t v7 = v141;
          uint64_t v6 = v160;
          Swift::Int v20 = v138;
          Swift::Int v15 = v154;
        }
      }
    }
    if (v21 < v15)
    {
      if (__OFSUB__(v21, v20)) {
        goto LABEL_139;
      }
      if (v21 - v20 < v132)
      {
        if (__OFADD__(v20, v132)) {
          goto LABEL_142;
        }
        if (v20 + v132 >= v15) {
          Swift::Int v53 = v15;
        }
        else {
          Swift::Int v53 = v20 + v132;
        }
        if (v53 < v20)
        {
LABEL_143:
          __break(1u);
          goto LABEL_144;
        }
        if (v21 != v53)
        {
          Swift::Int v138 = v20;
          uint64_t v133 = v2;
          uint64_t v54 = *(char **)(v7 + 72);
          Swift::Int v142 = *(void *)(v7 + 16);
          uint64_t v143 = v54;
          uint64_t v55 = (void)v54 * (v21 - 1);
          Swift::Int v56 = v21 * (void)v54;
          Swift::Int v135 = v53;
          do
          {
            uint64_t v57 = 0;
            Swift::Int v58 = v138;
            Swift::Int v151 = v21;
            int v144 = (void (*)(char *, uint64_t))v56;
            int v145 = (void (*)(void))v55;
            while (1)
            {
              Swift::Int v155 = v58;
              uint64_t v59 = *(void *)a1;
              Swift::Int v154 = v56 + v57;
              uint64_t v60 = (void (*)(char *, uint64_t, uint64_t))v142;
              ((void (*)(void))v142)();
              uint64_t v153 = (char *)(v55 + v57);
              v60(v159, v55 + v57 + v59, v6);
              uint64_t v61 = v149;
              AnnotatedFeature.feature.getter();
              uint64_t countAndFlagsBits = (void (*)(char *, char *, uint64_t))URL.path(percentEncoded:)(1)._countAndFlagsBits;
              char v62 = *v147;
              uint64_t v63 = v150;
              (*v147)(v61, v150);
              AnnotatedFeature.feature.getter();
              URL.path(percentEncoded:)(1);
              char v64 = v61;
              uint64_t v6 = v160;
              v62(v64, v63);
              BOOL v65 = specialized Sequence<>.lexicographicallyPrecedes<A>(_:)();
              swift_bridgeObjectRelease();
              swift_bridgeObjectRelease();
              uint64_t v66 = *v146;
              (*v146)(v159, v6);
              v66(v158, v6);
              if (!v65) {
                break;
              }
              uint64_t v67 = *(void *)a1;
              if (!*(void *)a1) {
                goto LABEL_145;
              }
              Swift::Int v56 = (Swift::Int)v144;
              uint64_t v55 = (uint64_t)v145;
              uint64_t v68 = (char *)v145 + v67 + v57;
              uint64_t v69 = *v157;
              (*v157)(v152, (char *)v144 + v67 + v57, v6);
              swift_arrayInitWithTakeFrontToBack();
              v69(v68, v152, v6);
              v57 -= (uint64_t)v143;
              Swift::Int v58 = v155 + 1;
              Swift::Int v70 = v151;
              if (v151 == v155 + 1) {
                goto LABEL_45;
              }
            }
            Swift::Int v70 = v151;
            Swift::Int v56 = (Swift::Int)v144;
            uint64_t v55 = (uint64_t)v145;
LABEL_45:
            Swift::Int v21 = v70 + 1;
            v55 += (uint64_t)v143;
            v56 += (Swift::Int)v143;
          }
          while (v21 != v135);
          Swift::Int v21 = v135;
          uint64_t v2 = v133;
          Swift::Int v20 = v138;
        }
      }
    }
    if (v21 < v20) {
      goto LABEL_138;
    }
    char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native();
    Swift::Int v151 = v21;
    if (isUniquelyReferenced_nonNull_native) {
      uint64_t v19 = v136;
    }
    else {
      uint64_t v19 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *((void *)v136 + 2) + 1, 1, v136);
    }
    unint64_t v73 = *((void *)v19 + 2);
    unint64_t v72 = *((void *)v19 + 3);
    unint64_t v74 = v73 + 1;
    if (v73 >= v72 >> 1) {
      uint64_t v19 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)((char *)(v72 > 1), v73 + 1, 1, v19);
    }
    *((void *)v19 + 2) = v74;
    uint64_t v75 = v19 + 32;
    uint64_t v76 = &v19[16 * v73 + 32];
    Swift::Int v77 = v151;
    *(void *)uint64_t v76 = v20;
    *((void *)v76 + 1) = v77;
    if (v73) {
      break;
    }
    unint64_t v74 = 1;
LABEL_95:
    a1 = (unint64_t)v140;
    uint64_t v7 = v141;
    Swift::Int v15 = *((void *)v140 + 1);
    Swift::Int v18 = v151;
    if (v151 >= v15) {
      goto LABEL_104;
    }
  }
  while (1)
  {
    a1 = v74 - 1;
    if (v74 >= 4)
    {
      uint64_t v82 = &v75[16 * v74];
      uint64_t v83 = *((void *)v82 - 8);
      uint64_t v84 = *((void *)v82 - 7);
      BOOL v88 = __OFSUB__(v84, v83);
      uint64_t v85 = v84 - v83;
      if (v88) {
        goto LABEL_123;
      }
      uint64_t v87 = *((void *)v82 - 6);
      uint64_t v86 = *((void *)v82 - 5);
      BOOL v88 = __OFSUB__(v86, v87);
      uint64_t v80 = v86 - v87;
      char v81 = v88;
      if (v88) {
        goto LABEL_124;
      }
      uint64_t v89 = (char *)(v74 - 2);
      uint64_t v90 = &v75[16 * v74 - 32];
      uint64_t v92 = *(void *)v90;
      uint64_t v91 = *((void *)v90 + 1);
      BOOL v88 = __OFSUB__(v91, v92);
      uint64_t v93 = v91 - v92;
      if (v88) {
        goto LABEL_125;
      }
      BOOL v88 = __OFADD__(v80, v93);
      uint64_t v94 = v80 + v93;
      if (v88) {
        goto LABEL_127;
      }
      if (v94 >= v85)
      {
        uint64_t v112 = &v75[16 * a1];
        uint64_t v114 = *(void *)v112;
        uint64_t v113 = *((void *)v112 + 1);
        BOOL v88 = __OFSUB__(v113, v114);
        uint64_t v115 = v113 - v114;
        if (v88) {
          goto LABEL_133;
        }
        BOOL v105 = v80 < v115;
        goto LABEL_84;
      }
    }
    else
    {
      if (v74 != 3)
      {
        uint64_t v106 = *((void *)v19 + 4);
        uint64_t v107 = *((void *)v19 + 5);
        BOOL v88 = __OFSUB__(v107, v106);
        uint64_t v99 = v107 - v106;
        char v100 = v88;
        goto LABEL_78;
      }
      uint64_t v79 = *((void *)v19 + 4);
      uint64_t v78 = *((void *)v19 + 5);
      BOOL v88 = __OFSUB__(v78, v79);
      uint64_t v80 = v78 - v79;
      char v81 = v88;
    }
    if (v81) {
      goto LABEL_126;
    }
    uint64_t v89 = (char *)(v74 - 2);
    uint64_t v95 = &v75[16 * v74 - 32];
    uint64_t v97 = *(void *)v95;
    uint64_t v96 = *((void *)v95 + 1);
    BOOL v98 = __OFSUB__(v96, v97);
    uint64_t v99 = v96 - v97;
    char v100 = v98;
    if (v98) {
      goto LABEL_128;
    }
    uint64_t v101 = &v75[16 * a1];
    uint64_t v103 = *(void *)v101;
    uint64_t v102 = *((void *)v101 + 1);
    BOOL v88 = __OFSUB__(v102, v103);
    uint64_t v104 = v102 - v103;
    if (v88) {
      goto LABEL_130;
    }
    if (__OFADD__(v99, v104)) {
      goto LABEL_132;
    }
    if (v99 + v104 >= v80)
    {
      BOOL v105 = v80 < v104;
LABEL_84:
      if (v105) {
        a1 = (unint64_t)v89;
      }
      goto LABEL_86;
    }
LABEL_78:
    if (v100) {
      goto LABEL_129;
    }
    uint64_t v108 = &v75[16 * a1];
    uint64_t v110 = *(void *)v108;
    uint64_t v109 = *((void *)v108 + 1);
    BOOL v88 = __OFSUB__(v109, v110);
    uint64_t v111 = v109 - v110;
    if (v88) {
      goto LABEL_131;
    }
    if (v111 < v99) {
      goto LABEL_95;
    }
LABEL_86:
    unint64_t v116 = a1 - 1;
    if (a1 - 1 >= v74)
    {
      __break(1u);
LABEL_120:
      __break(1u);
LABEL_121:
      __break(1u);
LABEL_122:
      __break(1u);
LABEL_123:
      __break(1u);
LABEL_124:
      __break(1u);
LABEL_125:
      __break(1u);
LABEL_126:
      __break(1u);
LABEL_127:
      __break(1u);
LABEL_128:
      __break(1u);
LABEL_129:
      __break(1u);
LABEL_130:
      __break(1u);
LABEL_131:
      __break(1u);
LABEL_132:
      __break(1u);
LABEL_133:
      __break(1u);
      goto LABEL_134;
    }
    if (!*(void *)v140) {
      goto LABEL_146;
    }
    uint64_t v117 = v19;
    uint64_t v118 = &v75[16 * v116];
    uint64_t v119 = *(void *)v118;
    uint64_t v120 = &v75[16 * a1];
    uint64_t v121 = *((void *)v120 + 1);
    specialized _merge<A>(low:mid:high:buffer:by:)(*(void *)v140 + *(void *)(v141 + 72) * *(void *)v118, *(void *)v140 + *(void *)(v141 + 72) * *(void *)v120, *(void *)v140 + *(void *)(v141 + 72) * v121, v139);
    if (v2) {
      break;
    }
    if (v121 < v119) {
      goto LABEL_120;
    }
    if (a1 > *((void *)v117 + 2)) {
      goto LABEL_121;
    }
    *(void *)uint64_t v118 = v119;
    *(void *)&v75[16 * v116 + 8] = v121;
    unint64_t v122 = *((void *)v117 + 2);
    if (a1 >= v122) {
      goto LABEL_122;
    }
    unint64_t v74 = v122 - 1;
    memmove(&v75[16 * a1], v120 + 16, 16 * (v122 - 1 - a1));
    uint64_t v19 = v117;
    *((void *)v117 + 2) = v122 - 1;
    uint64_t v6 = v160;
    if (v122 <= 2) {
      goto LABEL_95;
    }
  }
LABEL_101:
  swift_bridgeObjectRelease();
  if (v131 >= -1) {
    goto LABEL_116;
  }
  __break(1u);
LABEL_103:
  uint64_t v19 = (char *)MEMORY[0x263F8EE78];
  unint64_t v74 = *(void *)(MEMORY[0x263F8EE78] + 16);
LABEL_104:
  if (v74 >= 2)
  {
    uint64_t v123 = *(void *)a1;
    while (1)
    {
      unint64_t v124 = v74 - 2;
      if (v74 < 2) {
        break;
      }
      if (!v123) {
        goto LABEL_148;
      }
      a1 = (unint64_t)v19;
      uint64_t v125 = *(void *)&v19[16 * v124 + 32];
      uint64_t v126 = *(void *)&v19[16 * v74 + 24];
      specialized _merge<A>(low:mid:high:buffer:by:)(v123 + *(void *)(v141 + 72) * v125, v123 + *(void *)(v141 + 72) * *(void *)&v19[16 * v74 + 16], v123 + *(void *)(v141 + 72) * v126, v139);
      if (v2) {
        goto LABEL_101;
      }
      if (v126 < v125) {
        goto LABEL_135;
      }
      if ((swift_isUniquelyReferenced_nonNull_native() & 1) == 0) {
        a1 = (unint64_t)specialized _ArrayBuffer._consumeAndCreateNew()();
      }
      if (v124 >= *(void *)(a1 + 16)) {
        goto LABEL_136;
      }
      uint64_t v127 = (char *)(a1 + 32 + 16 * v124);
      *(void *)uint64_t v127 = v125;
      *((void *)v127 + 1) = v126;
      unint64_t v128 = *(void *)(a1 + 16);
      if (v74 > v128) {
        goto LABEL_137;
      }
      memmove((void *)(a1 + 32 + 16 * (v74 - 1)), (const void *)(a1 + 32 + 16 * v74), 16 * (v128 - v74));
      uint64_t v19 = (char *)a1;
      *(void *)(a1 + 16) = v128 - 1;
      unint64_t v74 = v128 - 1;
      if (v128 <= 2) {
        goto LABEL_115;
      }
    }
LABEL_134:
    __break(1u);
LABEL_135:
    __break(1u);
LABEL_136:
    __break(1u);
LABEL_137:
    __break(1u);
LABEL_138:
    __break(1u);
LABEL_139:
    __break(1u);
LABEL_140:
    __break(1u);
LABEL_141:
    __break(1u);
LABEL_142:
    __break(1u);
    goto LABEL_143;
  }
LABEL_115:
  swift_bridgeObjectRelease();
  if (v131 >= -1)
  {
LABEL_116:
    *(void *)(v130 + 16) = 0;
    swift_bridgeObjectRelease();
    return;
  }
LABEL_144:
  __break(1u);
LABEL_145:
  __break(1u);
LABEL_146:
  __break(1u);
LABEL_147:
  __break(1u);
LABEL_148:
  __break(1u);
}

void specialized UnsafeMutableBufferPointer._stableSortImpl(by:)()
{
  OUTLINED_FUNCTION_9_0();
  uint64_t v2 = v0;
  uint64_t v4 = v3;
  uint64_t v170 = type metadata accessor for URL();
  OUTLINED_FUNCTION_0();
  uint64_t v6 = v5;
  MEMORY[0x270FA5388](v7);
  OUTLINED_FUNCTION_33_0();
  uint64_t v169 = v8;
  uint64_t v157 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
  OUTLINED_FUNCTION_0();
  uint64_t v161 = v9;
  MEMORY[0x270FA5388](v10);
  OUTLINED_FUNCTION_49();
  OUTLINED_FUNCTION_16_2();
  MEMORY[0x270FA5388](v11);
  OUTLINED_FUNCTION_45_3();
  uint64_t v174 = v12;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v13);
  OUTLINED_FUNCTION_117_0();
  uint64_t v15 = MEMORY[0x270FA5388](v14);
  unint64_t v17 = (char *)&v146 - v16;
  MEMORY[0x270FA5388](v15);
  OUTLINED_FUNCTION_45_3();
  uint64_t v159 = v18;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v19);
  OUTLINED_FUNCTION_45_3();
  OUTLINED_FUNCTION_16_2();
  MEMORY[0x270FA5388](v20);
  OUTLINED_FUNCTION_45_3();
  OUTLINED_FUNCTION_16_2();
  uint64_t v22 = MEMORY[0x270FA5388](v21);
  OUTLINED_FUNCTION_114_0(v22, v23, v24, v25, v26, v27, v28, v29, v146);
  uint64_t v180 = v4;
  Swift::Int v30 = v4[1];
  Swift::Int v31 = _minimumMergeRunLength(_:)(v30);
  if (v31 >= v30)
  {
    if (v30 < 0) {
      goto LABEL_156;
    }
    if (v30) {
      specialized MutableCollection<>._insertionSort(within:sortedEnd:by:)();
    }
LABEL_133:
    OUTLINED_FUNCTION_8_1();
    return;
  }
  Swift::Int v150 = v31;
  uint64_t v148 = specialized static Array._allocateUninitialized(_:)(v30 / 2);
  uint64_t v160 = v32;
  uint64_t v149 = v30;
  if (v30 <= 0) {
    goto LABEL_119;
  }
  Swift::Int v33 = 0;
  uint64_t v166 = (void (**)(void))(v6 + 8);
  uint64_t v167 = v161 + 16;
  uint64_t v168 = (void (**)(void))(v161 + 8);
  uint64_t v179 = (uint64_t *)(v161 + 32);
  uint64_t v34 = (char *)MEMORY[0x263F8EE78];
  uint64_t v171 = v1;
  id v172 = v17;
  while (1)
  {
    uint64_t v35 = (uint64_t)v33;
    uint64_t v36 = (uint64_t)(v33 + 1);
    Swift::Int v155 = v34;
    uint64_t v156 = (uint64_t)v33;
    if ((uint64_t)(v33 + 1) < v30)
    {
      uint64_t v176 = v30;
      uint64_t v37 = *v180;
      uint64_t v38 = *(void *)(v161 + 72);
      uint64_t v162 = (void (*)(void))(v33 + 1);
      uint64_t v39 = *(void (**)(uint64_t, uint64_t, uint64_t))(v161 + 16);
      uint64_t v40 = v157;
      v39(v151, v37 + v38 * v36, v157);
      uint64_t v153 = v37;
      uint64_t v178 = v38;
      uint64_t v165 = (void (*)(uint64_t, char *, uint64_t))v39;
      v39(v152, v37 + v38 * v35, v40);
      AnnotatedFeature.feature.getter();
      Swift::String v41 = URL.path(percentEncoded:)(1);
      uint64_t countAndFlagsBits = v41._countAndFlagsBits;
      uint64_t object = (char *)v41._object;
      uint64_t v35 = (uint64_t)v166;
      uint64_t v42 = *v166;
      OUTLINED_FUNCTION_24_5();
      v42();
      uint64_t v43 = object;
      AnnotatedFeature.feature.getter();
      Swift::String v44 = URL.path(percentEncoded:)(1);
      uint64_t v164 = v42;
      OUTLINED_FUNCTION_24_5();
      v42();
      if (countAndFlagsBits == v44._countAndFlagsBits && v43 == v44._object) {
        LODWORD(v175) = 0;
      }
      else {
        LODWORD(v175) = OUTLINED_FUNCTION_112();
      }
      swift_bridgeObjectRelease();
      swift_bridgeObjectRelease();
      uint64_t v46 = *v168;
      OUTLINED_FUNCTION_129();
      OUTLINED_FUNCTION_25_10();
      v46();
      uint64_t v163 = v46;
      OUTLINED_FUNCTION_25_10();
      v46();
      OUTLINED_FUNCTION_170();
      uint64_t v36 = v35 + 2;
      Swift::Int v30 = v176;
      if (v35 + 2 < v176)
      {
        uint64_t v147 = v2;
        uint64_t v162 = (void (*)(void))(v178 * (void)v162);
        uint64_t v47 = v153;
        uint64_t object = (char *)(v35 + 2);
        Swift::Int v154 = v178 * v36;
        uint64_t v48 = v157;
        while (1)
        {
          unint64_t v49 = v165;
          v165(v158, (char *)(v47 + v154), v48);
          v49(v159, (char *)v162 + v47, v48);
          uint64_t v2 = v169;
          AnnotatedFeature.feature.getter();
          uint64_t countAndFlagsBits = OUTLINED_FUNCTION_156();
          uint64_t v51 = v50;
          uint64_t v52 = v164;
          OUTLINED_FUNCTION_21_4();
          v52();
          AnnotatedFeature.feature.getter();
          uint64_t v53 = OUTLINED_FUNCTION_156();
          uint64_t v48 = v54;
          OUTLINED_FUNCTION_21_4();
          v52();
          if (countAndFlagsBits == v53 && v51 == v48)
          {
            uint64_t v35 = 0;
            uint64_t v48 = v51;
          }
          else
          {
            uint64_t v35 = OUTLINED_FUNCTION_112();
          }
          swift_bridgeObjectRelease();
          swift_bridgeObjectRelease();
          OUTLINED_FUNCTION_129();
          Swift::Int v56 = v163;
          OUTLINED_FUNCTION_25_10();
          v56();
          OUTLINED_FUNCTION_25_10();
          v56();
          if ((v175 ^ v35)) {
            break;
          }
          v47 += v178;
          ++object;
          Swift::Int v30 = v176;
          if ((uint64_t)object >= v176)
          {
            uint64_t v36 = v176;
            OUTLINED_FUNCTION_164();
            OUTLINED_FUNCTION_170();
            goto LABEL_23;
          }
        }
        OUTLINED_FUNCTION_164();
        uint64_t v36 = (uint64_t)object;
        OUTLINED_FUNCTION_170();
        Swift::Int v30 = v176;
      }
LABEL_23:
      if (v175)
      {
        if (v36 < v35) {
          goto LABEL_157;
        }
        if (v35 < v36)
        {
          uint64_t v57 = 0;
          uint64_t v58 = v178 * (v36 - 1);
          uint64_t v59 = v36 * v178;
          uint64_t v60 = v35;
          uint64_t v61 = v35 * v178;
          uint64_t object = (char *)v36;
          do
          {
            if (v60 != v36 + v57 - 1)
            {
              uint64_t v62 = v2;
              uint64_t v63 = v153;
              if (!v153) {
                goto LABEL_163;
              }
              uint64_t v35 = v153 + v61;
              uint64_t v175 = v153 + v58;
              uint64_t countAndFlagsBits = *v179;
              OUTLINED_FUNCTION_3();
              v64();
              if (v61 < v58 || v35 >= (unint64_t)(v63 + v59))
              {
                swift_arrayInitWithTakeFrontToBack();
              }
              else if (v61 != v58)
              {
                swift_arrayInitWithTakeBackToFront();
              }
              OUTLINED_FUNCTION_3();
              v66();
              uint64_t v2 = v62;
              uint64_t v36 = (uint64_t)object;
              OUTLINED_FUNCTION_170();
            }
            ++v60;
            --v57;
            v58 -= v178;
            v59 -= v178;
            v61 += v178;
          }
          while (v60 < v36 + v57);
          Swift::Int v30 = v176;
        }
      }
    }
    if (v36 < v30)
    {
      if (__OFSUB__(v36, v35)) {
        goto LABEL_155;
      }
      if (v36 - v35 < v150)
      {
        if (__OFADD__(v35, v150)) {
          goto LABEL_158;
        }
        if (v35 + v150 >= v30) {
          Swift::Int v67 = v30;
        }
        else {
          Swift::Int v67 = v35 + v150;
        }
        if (v67 < v35)
        {
LABEL_159:
          __break(1u);
          goto LABEL_160;
        }
        if (v36 != v67)
        {
          uint64_t v147 = v2;
          uint64_t v68 = *(void (**)(void))(v161 + 72);
          uint64_t v162 = *(void (**)(void))(v161 + 16);
          uint64_t v163 = v68;
          uint64_t v69 = (void)v68 * (v36 - 1);
          Swift::Int v70 = (void (*)(void))(v36 * (void)v68);
          uint64_t v2 = v157;
          Swift::Int v154 = v67;
          do
          {
            uint64_t v71 = 0;
            uint64_t object = (char *)v36;
            uint64_t v164 = v70;
            uint64_t v165 = (void (*)(uint64_t, char *, uint64_t))v69;
            while (1)
            {
              uint64_t v176 = (uint64_t)v70 + v71;
              uint64_t countAndFlagsBits = v35;
              uint64_t v72 = v71;
              unint64_t v73 = v162;
              OUTLINED_FUNCTION_79_2();
              v73();
              uint64_t v178 = v72;
              uint64_t v175 = v69 + v72;
              OUTLINED_FUNCTION_79_2();
              v73();
              AnnotatedFeature.feature.getter();
              Swift::String v74 = URL.path(percentEncoded:)(1);
              uint64_t v75 = *v166;
              OUTLINED_FUNCTION_137();
              v75();
              AnnotatedFeature.feature.getter();
              Swift::String v76 = URL.path(percentEncoded:)(1);
              OUTLINED_FUNCTION_137();
              v75();
              if (v74._countAndFlagsBits == v76._countAndFlagsBits && v74._object == v76._object) {
                break;
              }
              char v78 = OUTLINED_FUNCTION_112();
              swift_bridgeObjectRelease();
              swift_bridgeObjectRelease();
              uint64_t v79 = OUTLINED_FUNCTION_95_0();
              ((void (*)(uint64_t))v75)(v79);
              uint64_t v80 = OUTLINED_FUNCTION_142();
              ((void (*)(uint64_t))v75)(v80);
              if ((v78 & 1) == 0) {
                goto LABEL_60;
              }
              Swift::Int v70 = v164;
              uint64_t v69 = (uint64_t)v165;
              if (!*v180) {
                goto LABEL_161;
              }
              uint64_t v81 = v178;
              uint64_t v82 = (void (*)(void))*v179;
              OUTLINED_FUNCTION_3();
              v82();
              swift_arrayInitWithTakeFrontToBack();
              OUTLINED_FUNCTION_3();
              v82();
              uint64_t v71 = v81 - (void)v163;
              uint64_t v35 = countAndFlagsBits + 1;
              uint64_t v83 = object;
              if (object == (char *)(countAndFlagsBits + 1)) {
                goto LABEL_61;
              }
            }
            swift_bridgeObjectRelease_n();
            uint64_t v84 = OUTLINED_FUNCTION_95_0();
            ((void (*)(uint64_t))v75)(v84);
            uint64_t v85 = OUTLINED_FUNCTION_142();
            ((void (*)(uint64_t))v75)(v85);
LABEL_60:
            uint64_t v83 = object;
            Swift::Int v70 = v164;
            uint64_t v69 = (uint64_t)v165;
LABEL_61:
            uint64_t v36 = (uint64_t)(v83 + 1);
            v69 += (uint64_t)v163;
            Swift::Int v70 = (void (*)(void))((char *)v163 + (void)v70);
            uint64_t v35 = v156;
          }
          while (v36 != v154);
          uint64_t v36 = v154;
          OUTLINED_FUNCTION_164();
        }
      }
    }
    if (v36 < v35) {
      goto LABEL_154;
    }
    char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native();
    uint64_t object = (char *)v36;
    if (isUniquelyReferenced_nonNull_native) {
      uint64_t v34 = v155;
    }
    else {
      uint64_t v34 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *((void *)v155 + 2) + 1, 1, v155);
    }
    unint64_t v88 = *((void *)v34 + 2);
    unint64_t v87 = *((void *)v34 + 3);
    unint64_t v89 = v88 + 1;
    if (v88 >= v87 >> 1) {
      uint64_t v34 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)((char *)(v87 > 1), v88 + 1, 1, v34);
    }
    *((void *)v34 + 2) = v89;
    uint64_t v90 = v34 + 32;
    uint64_t v91 = (uint64_t *)&v34[16 * v88 + 32];
    uint64_t v92 = object;
    *uint64_t v91 = v35;
    v91[1] = (uint64_t)v92;
    if (v88) {
      break;
    }
    unint64_t v89 = 1;
LABEL_111:
    Swift::Int v30 = v180[1];
    Swift::Int v33 = object;
    if ((uint64_t)object >= v30) {
      goto LABEL_120;
    }
  }
  while (1)
  {
    unint64_t v93 = v89 - 1;
    if (v89 >= 4)
    {
      BOOL v98 = &v90[16 * v89];
      uint64_t v99 = *((void *)v98 - 8);
      uint64_t v100 = *((void *)v98 - 7);
      BOOL v104 = __OFSUB__(v100, v99);
      uint64_t v101 = v100 - v99;
      if (v104) {
        goto LABEL_139;
      }
      uint64_t v103 = *((void *)v98 - 6);
      uint64_t v102 = *((void *)v98 - 5);
      BOOL v104 = __OFSUB__(v102, v103);
      uint64_t v96 = v102 - v103;
      char v97 = v104;
      if (v104) {
        goto LABEL_140;
      }
      unint64_t v105 = v89 - 2;
      uint64_t v106 = &v90[16 * v89 - 32];
      uint64_t v108 = *(void *)v106;
      uint64_t v107 = *((void *)v106 + 1);
      BOOL v104 = __OFSUB__(v107, v108);
      uint64_t v109 = v107 - v108;
      if (v104) {
        goto LABEL_141;
      }
      BOOL v104 = __OFADD__(v96, v109);
      uint64_t v110 = v96 + v109;
      if (v104) {
        goto LABEL_143;
      }
      if (v110 >= v101)
      {
        unint64_t v128 = &v90[16 * v93];
        uint64_t v130 = *(void *)v128;
        uint64_t v129 = *((void *)v128 + 1);
        BOOL v104 = __OFSUB__(v129, v130);
        uint64_t v131 = v129 - v130;
        if (v104) {
          goto LABEL_149;
        }
        BOOL v121 = v96 < v131;
        goto LABEL_100;
      }
    }
    else
    {
      if (v89 != 3)
      {
        uint64_t v122 = *((void *)v34 + 4);
        uint64_t v123 = *((void *)v34 + 5);
        BOOL v104 = __OFSUB__(v123, v122);
        uint64_t v115 = v123 - v122;
        char v116 = v104;
        goto LABEL_94;
      }
      uint64_t v95 = *((void *)v34 + 4);
      uint64_t v94 = *((void *)v34 + 5);
      BOOL v104 = __OFSUB__(v94, v95);
      uint64_t v96 = v94 - v95;
      char v97 = v104;
    }
    if (v97) {
      goto LABEL_142;
    }
    unint64_t v105 = v89 - 2;
    uint64_t v111 = &v90[16 * v89 - 32];
    uint64_t v113 = *(void *)v111;
    uint64_t v112 = *((void *)v111 + 1);
    BOOL v114 = __OFSUB__(v112, v113);
    uint64_t v115 = v112 - v113;
    char v116 = v114;
    if (v114) {
      goto LABEL_144;
    }
    uint64_t v117 = &v90[16 * v93];
    uint64_t v119 = *(void *)v117;
    uint64_t v118 = *((void *)v117 + 1);
    BOOL v104 = __OFSUB__(v118, v119);
    uint64_t v120 = v118 - v119;
    if (v104) {
      goto LABEL_146;
    }
    if (__OFADD__(v115, v120)) {
      goto LABEL_148;
    }
    if (v115 + v120 >= v96)
    {
      BOOL v121 = v96 < v120;
LABEL_100:
      if (v121) {
        unint64_t v93 = v105;
      }
      goto LABEL_102;
    }
LABEL_94:
    if (v116) {
      goto LABEL_145;
    }
    unint64_t v124 = &v90[16 * v93];
    uint64_t v126 = *(void *)v124;
    uint64_t v125 = *((void *)v124 + 1);
    BOOL v104 = __OFSUB__(v125, v126);
    uint64_t v127 = v125 - v126;
    if (v104) {
      goto LABEL_147;
    }
    if (v127 < v115) {
      goto LABEL_111;
    }
LABEL_102:
    unint64_t v132 = v93 - 1;
    if (v93 - 1 >= v89)
    {
      __break(1u);
LABEL_136:
      __break(1u);
LABEL_137:
      __break(1u);
LABEL_138:
      __break(1u);
LABEL_139:
      __break(1u);
LABEL_140:
      __break(1u);
LABEL_141:
      __break(1u);
LABEL_142:
      __break(1u);
LABEL_143:
      __break(1u);
LABEL_144:
      __break(1u);
LABEL_145:
      __break(1u);
LABEL_146:
      __break(1u);
LABEL_147:
      __break(1u);
LABEL_148:
      __break(1u);
LABEL_149:
      __break(1u);
      goto LABEL_150;
    }
    if (!*v180) {
      goto LABEL_162;
    }
    uint64_t v133 = v34;
    uint64_t v134 = &v90[16 * v132];
    uint64_t v135 = *(void *)v134;
    uint64_t v136 = &v90[16 * v93];
    uint64_t v137 = *((void *)v136 + 1);
    specialized _merge<A>(low:mid:high:buffer:by:)();
    if (v2) {
      break;
    }
    if (v137 < v135) {
      goto LABEL_136;
    }
    if (v93 > *((void *)v133 + 2)) {
      goto LABEL_137;
    }
    *(void *)uint64_t v134 = v135;
    *(void *)&v90[16 * v132 + 8] = v137;
    unint64_t v138 = *((void *)v133 + 2);
    if (v93 >= v138) {
      goto LABEL_138;
    }
    unint64_t v89 = v138 - 1;
    memmove(&v90[16 * v93], v136 + 16, 16 * (v138 - 1 - v93));
    uint64_t v34 = v133;
    *((void *)v133 + 2) = v138 - 1;
    if (v138 <= 2) {
      goto LABEL_111;
    }
  }
LABEL_117:
  swift_bridgeObjectRelease();
  if (v149 >= -1) {
    goto LABEL_132;
  }
  __break(1u);
LABEL_119:
  uint64_t v34 = (char *)MEMORY[0x263F8EE78];
  unint64_t v89 = *(void *)(MEMORY[0x263F8EE78] + 16);
LABEL_120:
  if (v89 >= 2)
  {
    uint64_t v139 = *v180;
    while (1)
    {
      unint64_t v140 = v89 - 2;
      if (v89 < 2) {
        break;
      }
      if (!v139) {
        goto LABEL_164;
      }
      uint64_t v141 = v34;
      uint64_t v142 = *(void *)&v34[16 * v140 + 32];
      uint64_t v143 = *(void *)&v34[16 * v89 + 24];
      specialized _merge<A>(low:mid:high:buffer:by:)();
      if (v2) {
        goto LABEL_117;
      }
      if (v143 < v142) {
        goto LABEL_151;
      }
      if ((swift_isUniquelyReferenced_nonNull_native() & 1) == 0) {
        uint64_t v141 = specialized _ArrayBuffer._consumeAndCreateNew()();
      }
      if (v140 >= *((void *)v141 + 2)) {
        goto LABEL_152;
      }
      int v144 = &v141[16 * v140 + 32];
      *(void *)int v144 = v142;
      *((void *)v144 + 1) = v143;
      unint64_t v145 = *((void *)v141 + 2);
      if (v89 > v145) {
        goto LABEL_153;
      }
      memmove(&v141[16 * v89 + 16], &v141[16 * v89 + 32], 16 * (v145 - v89));
      uint64_t v34 = v141;
      *((void *)v141 + 2) = v145 - 1;
      unint64_t v89 = v145 - 1;
      if (v145 <= 2) {
        goto LABEL_131;
      }
    }
LABEL_150:
    __break(1u);
LABEL_151:
    __break(1u);
LABEL_152:
    __break(1u);
LABEL_153:
    __break(1u);
LABEL_154:
    __break(1u);
LABEL_155:
    __break(1u);
LABEL_156:
    __break(1u);
LABEL_157:
    __break(1u);
LABEL_158:
    __break(1u);
    goto LABEL_159;
  }
LABEL_131:
  swift_bridgeObjectRelease();
  if (v149 >= -1)
  {
LABEL_132:
    *(void *)(v148 + 16) = 0;
    swift_bridgeObjectRelease();
    goto LABEL_133;
  }
LABEL_160:
  __break(1u);
LABEL_161:
  __break(1u);
LABEL_162:
  __break(1u);
LABEL_163:
  __break(1u);
LABEL_164:
  __break(1u);
}

uint64_t specialized MutableCollection<>._insertionSort(within:sortedEnd:by:)(uint64_t a1, uint64_t a2, uint64_t a3, void *a4)
{
  uint64_t v38 = a1;
  uint64_t v45 = type metadata accessor for URL();
  uint64_t v7 = *(void *)(v45 - 8);
  MEMORY[0x270FA5388](v45);
  Swift::String v44 = (char *)&v36 - ((v8 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
  uint64_t v10 = MEMORY[0x270FA5388](v9);
  uint64_t v51 = (char *)&v36 - ((v11 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v12 = MEMORY[0x270FA5388](v10);
  uint64_t v57 = (char *)&v36 - v13;
  uint64_t result = MEMORY[0x270FA5388](v12);
  Swift::Int v56 = (char *)&v36 - v16;
  uint64_t v49 = a3;
  uint64_t v37 = a2;
  if (a3 != a2)
  {
    uint64_t v18 = *(void (**)(void))(v15 + 16);
    uint64_t v17 = v15 + 16;
    uint64_t v19 = *(void *)(v17 + 56);
    uint64_t v40 = (void (**)(char *, uint64_t))(v7 + 8);
    Swift::String v41 = v18;
    uint64_t v39 = (uint64_t (**)(char *, uint64_t))(v17 - 8);
    uint64_t v42 = a4;
    uint64_t v43 = v17;
    uint64_t v50 = (void (**)(char *, uint64_t, uint64_t))(v17 + 16);
    uint64_t v20 = v19 * (v49 - 1);
    uint64_t v46 = v19;
    uint64_t v21 = v19 * v49;
    while (2)
    {
      uint64_t v22 = 0;
      uint64_t v54 = v38;
      uint64_t v47 = v21;
      uint64_t v48 = v20;
      do
      {
        uint64_t v23 = *a4;
        uint64_t v53 = v21 + v22;
        uint64_t v24 = v41;
        v41();
        uint64_t v52 = v20 + v22;
        ((void (*)(char *, uint64_t, uint64_t))v24)(v57, v20 + v22 + v23, v9);
        uint64_t v25 = v44;
        AnnotatedFeature.feature.getter();
        uint64_t countAndFlagsBits = URL.path(percentEncoded:)(1)._countAndFlagsBits;
        uint64_t v26 = *v40;
        uint64_t v27 = v9;
        uint64_t v28 = v45;
        (*v40)(v25, v45);
        AnnotatedFeature.feature.getter();
        URL.path(percentEncoded:)(1);
        uint64_t v29 = v25;
        uint64_t v20 = v48;
        uint64_t v30 = v28;
        uint64_t v9 = v27;
        v26(v29, v30);
        BOOL v31 = specialized Sequence<>.lexicographicallyPrecedes<A>(_:)();
        swift_bridgeObjectRelease();
        a4 = v42;
        swift_bridgeObjectRelease();
        uint64_t v32 = *v39;
        (*v39)(v57, v27);
        uint64_t result = v32(v56, v27);
        uint64_t v21 = v47;
        if (!v31) {
          break;
        }
        uint64_t v33 = *a4;
        if (!*a4)
        {
          __break(1u);
          return result;
        }
        uint64_t v34 = v33 + v20 + v22;
        uint64_t v35 = *v50;
        (*v50)(v51, v33 + v47 + v22, v9);
        swift_arrayInitWithTakeFrontToBack();
        uint64_t result = ((uint64_t (*)(uint64_t, char *, uint64_t))v35)(v34, v51, v9);
        v22 -= v46;
        ++v54;
      }
      while (v49 != v54);
      v20 += v46;
      v21 += v46;
      if (++v49 != v37) {
        continue;
      }
      break;
    }
  }
  return result;
}

void specialized MutableCollection<>._insertionSort(within:sortedEnd:by:)()
{
  OUTLINED_FUNCTION_9_0();
  Swift::Int v56 = v1;
  uint64_t v3 = v2;
  uint64_t v5 = v4;
  uint64_t v41 = v6;
  uint64_t v47 = type metadata accessor for URL();
  OUTLINED_FUNCTION_0();
  uint64_t v8 = v7;
  MEMORY[0x270FA5388](v9);
  OUTLINED_FUNCTION_29_3(v10, v0);
  uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v12);
  uint64_t v53 = (char *)&v39 - ((v13 + 15) & 0xFFFFFFFFFFFFFFF0);
  OUTLINED_FUNCTION_20_3();
  uint64_t v15 = MEMORY[0x270FA5388](v14);
  uint64_t v17 = (char *)&v39 - v16;
  MEMORY[0x270FA5388](v15);
  OUTLINED_FUNCTION_115_0();
  uint64_t v51 = v3;
  uint64_t v40 = v5;
  if (v3 != v5)
  {
    uint64_t v20 = *(void (**)(void))(v18 + 16);
    uint64_t v19 = v18 + 16;
    uint64_t v21 = *(void *)(v19 + 56);
    uint64_t v42 = (void (**)(void))(v8 + 8);
    uint64_t v43 = v20;
    uint64_t v46 = (void (**)(void))(v19 - 8);
    uint64_t v44 = v19;
    uint64_t v45 = v17;
    uint64_t v52 = (void (**)(void))(v19 + 16);
    uint64_t v22 = v21 * (v51 - 1);
    uint64_t v48 = v21;
    uint64_t v23 = v21 * v51;
    while (2)
    {
      uint64_t v24 = 0;
      uint64_t v57 = v41;
      uint64_t v49 = v23;
      uint64_t v50 = v22;
      while (1)
      {
        uint64_t v55 = v23 + v24;
        uint64_t v25 = v43;
        OUTLINED_FUNCTION_79_2();
        v25();
        uint64_t v58 = v24;
        uint64_t v54 = v22 + v24;
        OUTLINED_FUNCTION_79_2();
        v25();
        AnnotatedFeature.feature.getter();
        uint64_t v26 = OUTLINED_FUNCTION_156();
        uint64_t v28 = v27;
        uint64_t v29 = *v42;
        OUTLINED_FUNCTION_137();
        v29();
        AnnotatedFeature.feature.getter();
        uint64_t v30 = v11;
        uint64_t v31 = OUTLINED_FUNCTION_156();
        uint64_t v33 = v32;
        OUTLINED_FUNCTION_137();
        v29();
        if (v26 == v31 && v28 == v33) {
          break;
        }
        char v35 = OUTLINED_FUNCTION_112();
        swift_bridgeObjectRelease();
        swift_bridgeObjectRelease();
        uint64_t v36 = *v46;
        OUTLINED_FUNCTION_11_3();
        v36();
        OUTLINED_FUNCTION_42_4();
        OUTLINED_FUNCTION_11_3();
        v36();
        uint64_t v11 = v30;
        uint64_t v23 = v49;
        uint64_t v22 = v50;
        if (v35)
        {
          if (!*v56)
          {
            __break(1u);
            return;
          }
          uint64_t v37 = *v52;
          OUTLINED_FUNCTION_3();
          v37();
          OUTLINED_FUNCTION_126();
          swift_arrayInitWithTakeFrontToBack();
          OUTLINED_FUNCTION_3();
          v37();
          uint64_t v24 = v58 - v48;
          if (v51 != ++v57) {
            continue;
          }
        }
        goto LABEL_13;
      }
      swift_bridgeObjectRelease_n();
      uint64_t v38 = *v46;
      OUTLINED_FUNCTION_21_4();
      v38();
      OUTLINED_FUNCTION_42_4();
      OUTLINED_FUNCTION_21_4();
      v38();
      uint64_t v11 = v30;
      uint64_t v23 = v49;
      uint64_t v22 = v50;
LABEL_13:
      v22 += v48;
      v23 += v48;
      if (++v51 != v40) {
        continue;
      }
      break;
    }
  }
  OUTLINED_FUNCTION_8_1();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t *v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t *v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  void *v13;
  BOOL v14;

  OUTLINED_FUNCTION_9_0();
  if (v2 != v1)
  {
    uint64_t v4 = v2;
    uint64_t v5 = v1;
    uint64_t v6 = v0;
    uint64_t v7 = *v3;
    uint64_t v8 = *v3 + 16 * v2;
    while (2)
    {
      uint64_t v9 = (uint64_t *)(v7 + 16 * v4);
      uint64_t v10 = *v9;
      uint64_t v11 = v9[1];
      uint64_t v12 = v6;
      uint64_t v13 = (void *)v8;
      do
      {
        uint64_t v14 = v10 == *(v13 - 2) && v11 == *(v13 - 1);
        if (v14 || (_stringCompareWithSmolCheck(_:_:expecting:)() & 1) == 0) {
          break;
        }
        if (!v7)
        {
          __break(1u);
          return;
        }
        uint64_t v10 = *v13;
        uint64_t v11 = v13[1];
        *(_OWORD *)uint64_t v13 = *((_OWORD *)v13 - 1);
        *(v13 - 1) = v11;
        *(v13 - 2) = v10;
        v13 -= 2;
        ++v12;
      }
      while (v4 != v12);
      ++v4;
      v8 += 16;
      if (v4 != v5) {
        continue;
      }
      break;
    }
  }
  OUTLINED_FUNCTION_8_1();
}

void specialized _merge<A>(low:mid:high:buffer:by:)(unint64_t a1, unint64_t a2, unint64_t a3, unint64_t a4)
{
  uint64_t v76 = type metadata accessor for URL();
  uint64_t v8 = *(void *)(v76 - 8);
  MEMORY[0x270FA5388](v76);
  uint64_t v75 = (char *)&v63 - ((v9 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v81 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
  uint64_t v10 = *(void *)(v81 - 8);
  uint64_t v11 = MEMORY[0x270FA5388](v81);
  Swift::String v74 = (char *)&v63 - ((v12 + 15) & 0xFFFFFFFFFFFFFFF0);
  MEMORY[0x270FA5388](v11);
  uint64_t v83 = (char *)&v63 - v13;
  uint64_t v15 = *(void *)(v14 + 72);
  if (!v15)
  {
    __break(1u);
LABEL_72:
    __break(1u);
LABEL_73:
    __break(1u);
    goto LABEL_74;
  }
  int64_t v16 = a2 - a1;
  if (a2 - a1 == 0x8000000000000000 && v15 == -1) {
    goto LABEL_72;
  }
  int64_t v18 = a3 - a2;
  if (a3 - a2 == 0x8000000000000000 && v15 == -1) {
    goto LABEL_73;
  }
  unint64_t v20 = a4;
  uint64_t v21 = v16 / v15;
  uint64_t v22 = v18 / v15;
  uint64_t v73 = v15;
  if (v16 / v15 >= v18 / v15)
  {
    unint64_t v41 = v20;
    specialized UnsafeMutablePointer.moveInitialize(from:count:)(a2, v18 / v15);
    uint64_t v42 = v22 * v15;
    unint64_t v23 = v41;
    uint64_t v24 = (void (*)(void))(v41 + v42);
    if (v42 < 1 || a1 >= a2) {
      goto LABEL_40;
    }
    uint64_t v67 = -v15;
    uint64_t v46 = *(void (**)(void))(v10 + 16);
    BOOL v65 = (void (**)(char *, uint64_t))(v8 + 8);
    uint64_t v66 = v46;
    uint64_t v72 = v10 + 16;
    char v64 = (void (**)(char *, uint64_t))(v10 + 8);
    unint64_t v78 = a1;
    unint64_t v79 = v41;
    uint64_t v47 = v74;
    while (1)
    {
      uint64_t v82 = (void (*)(void))a2;
      Swift::Int v77 = v24;
      uint64_t v48 = (void (*)(void))a3;
      uint64_t v50 = v66;
      uint64_t v49 = v67;
      Swift::Int v70 = v48;
      uint64_t v80 = (char *)v48 + v67;
      uint64_t v69 = (void (**)(char *, uint64_t))((char *)v24 + v67);
      uint64_t v51 = v81;
      v66();
      uint64_t v68 = (void (**)(char *, uint64_t))(a2 + v49);
      ((void (*)(char *))v50)(v47);
      uint64_t v52 = v75;
      AnnotatedFeature.feature.getter();
      uint64_t countAndFlagsBits = URL.path(percentEncoded:)(1)._countAndFlagsBits;
      uint64_t v53 = *v65;
      uint64_t v54 = v76;
      (*v65)(v52, v76);
      AnnotatedFeature.feature.getter();
      URL.path(percentEncoded:)(1);
      v53(v52, v54);
      BOOL v55 = specialized Sequence<>.lexicographicallyPrecedes<A>(_:)();
      swift_bridgeObjectRelease();
      swift_bridgeObjectRelease();
      Swift::Int v56 = *v64;
      (*v64)(v47, v51);
      v56(v83, v51);
      if (v55) {
        break;
      }
      a3 = (unint64_t)v80;
      BOOL v60 = (unint64_t)v70 < (unint64_t)v77 || v80 >= (char *)v77;
      a2 = (unint64_t)v82;
      if (!v60)
      {
        unint64_t v59 = v78;
        unint64_t v23 = v79;
        uint64_t v15 = v73;
        if (v70 == v77)
        {
          uint64_t v24 = (void (*)(void))v69;
          goto LABEL_65;
        }
        uint64_t v57 = (void (*)(void))v69;
LABEL_62:
        swift_arrayInitWithTakeBackToFront();
        goto LABEL_64;
      }
      uint64_t v61 = v69;
      swift_arrayInitWithTakeFrontToBack();
      uint64_t v24 = (void (*)(void))v61;
      unint64_t v59 = v78;
      unint64_t v23 = v79;
      uint64_t v15 = v73;
LABEL_65:
      if ((unint64_t)v24 <= v23 || a2 <= v59) {
        goto LABEL_40;
      }
    }
    uint64_t v57 = v77;
    a3 = (unint64_t)v80;
    if ((unint64_t)v70 < (unint64_t)v82 || v80 >= (char *)v82)
    {
      a2 = (unint64_t)v68;
      swift_arrayInitWithTakeFrontToBack();
      unint64_t v59 = v78;
      unint64_t v23 = v79;
      uint64_t v15 = v73;
    }
    else
    {
      unint64_t v59 = v78;
      unint64_t v23 = v79;
      uint64_t v15 = v73;
      if (v70 != v82)
      {
        a2 = (unint64_t)v68;
        goto LABEL_62;
      }
      a2 = (unint64_t)v68;
    }
LABEL_64:
    uint64_t v24 = v57;
    goto LABEL_65;
  }
  unint64_t v23 = v20;
  specialized UnsafeMutablePointer.moveInitialize(from:count:)(a1, v16 / v15);
  uint64_t v24 = (void (*)(void))(v23 + v21 * v15);
  if (v21 * v15 >= 1 && a2 < a3)
  {
    uint64_t v26 = *(void (**)(void))(v10 + 16);
    uint64_t v69 = (void (**)(char *, uint64_t))(v8 + 8);
    Swift::Int v70 = v26;
    uint64_t v72 = v10 + 16;
    uint64_t v68 = (void (**)(char *, uint64_t))(v10 + 8);
    uint64_t v80 = (char *)a3;
    Swift::Int v77 = (void (*)(void))(v23 + v21 * v15);
    uint64_t v27 = v81;
    uint64_t v28 = v74;
    do
    {
      uint64_t v82 = (void (*)(void))a2;
      unint64_t v78 = a1;
      unint64_t v79 = v23;
      uint64_t v29 = v70;
      v70();
      ((void (*)(char *, unint64_t, uint64_t))v29)(v28, v23, v27);
      uint64_t v30 = v75;
      AnnotatedFeature.feature.getter();
      uint64_t countAndFlagsBits = URL.path(percentEncoded:)(1)._countAndFlagsBits;
      uint64_t v31 = *v69;
      uint64_t v32 = v76;
      (*v69)(v30, v76);
      AnnotatedFeature.feature.getter();
      URL.path(percentEncoded:)(1);
      v31(v30, v32);
      BOOL v33 = specialized Sequence<>.lexicographicallyPrecedes<A>(_:)();
      swift_bridgeObjectRelease();
      swift_bridgeObjectRelease();
      uint64_t v34 = *v68;
      (*v68)(v28, v27);
      v34(v83, v27);
      if (v33)
      {
        uint64_t v15 = v73;
        unint64_t v35 = (unint64_t)v82;
        a2 = (unint64_t)v82 + v73;
        unint64_t v36 = v78;
        unint64_t v23 = v79;
        if (v78 >= (unint64_t)v82 && v78 < a2) {
          goto LABEL_27;
        }
      }
      else
      {
        a2 = (unint64_t)v82;
        uint64_t v15 = v73;
        unint64_t v36 = v78;
        unint64_t v35 = v79;
        unint64_t v23 = v79 + v73;
        if (v78 >= v79 && v78 < v23)
        {
LABEL_27:
          unint64_t v38 = (unint64_t)v80;
          if (v36 != v35) {
            swift_arrayInitWithTakeBackToFront();
          }
          goto LABEL_29;
        }
      }
      swift_arrayInitWithTakeFrontToBack();
      unint64_t v38 = (unint64_t)v80;
LABEL_29:
      uint64_t v24 = v77;
      a1 = v36 + v15;
    }
    while (v23 < (unint64_t)v77 && a2 < v38);
  }
LABEL_40:
  uint64_t v44 = (uint64_t)v24 - v23;
  if (v15 != -1 || v44 != 0x8000000000000000)
  {
    specialized UnsafeMutablePointer.moveInitialize(from:count:)(v23, v44 / v15);
    return;
  }
LABEL_74:
  __break(1u);
}

void specialized _merge<A>(low:mid:high:buffer:by:)()
{
  OUTLINED_FUNCTION_9_0();
  unint64_t v1 = v0;
  unint64_t v3 = v2;
  unint64_t v5 = v4;
  unint64_t v7 = v6;
  uint64_t v78 = type metadata accessor for URL();
  OUTLINED_FUNCTION_0();
  uint64_t v9 = v8;
  MEMORY[0x270FA5388](v10);
  OUTLINED_FUNCTION_33_0();
  uint64_t v76 = v11;
  uint64_t v82 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
  uint64_t v12 = *(void *)(v82 - 8);
  uint64_t v13 = MEMORY[0x270FA5388](v82);
  Swift::Int v77 = (void (*)(void))&v64[-((v14 + 15) & 0xFFFFFFFFFFFFFFF0)];
  uint64_t v15 = MEMORY[0x270FA5388](v13);
  uint64_t v75 = (void (**)(void))&v64[-v16];
  uint64_t v17 = MEMORY[0x270FA5388](v15);
  uint64_t v19 = &v64[-v18];
  MEMORY[0x270FA5388](v17);
  uint64_t countAndFlagsBits = &v64[-v20];
  uint64_t v22 = *(void *)(v21 + 72);
  if (!v22)
  {
    __break(1u);
LABEL_84:
    __break(1u);
LABEL_85:
    __break(1u);
    goto LABEL_86;
  }
  int64_t v23 = v5 - v7;
  if (v5 - v7 == 0x8000000000000000 && v22 == -1) {
    goto LABEL_84;
  }
  int64_t v25 = v3 - v5;
  if (v3 - v5 == 0x8000000000000000 && v22 == -1) {
    goto LABEL_85;
  }
  unint64_t v73 = v3;
  uint64_t v27 = v23 / v22;
  uint64_t v28 = v25 / v22;
  uint64_t v69 = v22;
  if (v23 / v22 >= v25 / v22)
  {
    specialized UnsafeMutablePointer.moveInitialize(from:count:)(v5, v25 / v22);
    uint64_t v29 = (char *)(v1 + v28 * v22);
    if (v28 * v22 < 1 || v7 >= v5) {
      goto LABEL_45;
    }
    uint64_t v48 = -v22;
    uint64_t v49 = *(void (**)(void))(v12 + 16);
    uint64_t v66 = v9 + 8;
    uint64_t v67 = v49;
    uint64_t v74 = v12 + 16;
    BOOL v65 = (void (**)(void))(v12 + 8);
    unint64_t v50 = v73;
    unint64_t v80 = v7;
    unint64_t v81 = v1;
    uint64_t v68 = v48;
    uint64_t v51 = (void (**)(void))(v9 + 8);
    while (1)
    {
      unint64_t v73 = v50;
      unint64_t v79 = (unint64_t)v29;
      uint64_t v71 = (void (**)(void))&v29[v48];
      uint64_t v52 = v67;
      OUTLINED_FUNCTION_79_2();
      v52();
      Swift::Int v70 = (unsigned char *)(v5 + v48);
      OUTLINED_FUNCTION_79_2();
      v52();
      AnnotatedFeature.feature.getter();
      Swift::String v53 = URL.path(percentEncoded:)(1);
      uint64_t countAndFlagsBits = (unsigned char *)v53._countAndFlagsBits;
      uint64_t v54 = *v51;
      OUTLINED_FUNCTION_38_0();
      v54();
      AnnotatedFeature.feature.getter();
      Swift::String v55 = URL.path(percentEncoded:)(1);
      OUTLINED_FUNCTION_38_0();
      v54();
      if (countAndFlagsBits == (unsigned char *)v55._countAndFlagsBits && v53._object == v55._object) {
        char v57 = 0;
      }
      else {
        char v57 = OUTLINED_FUNCTION_112();
      }
      swift_bridgeObjectRelease();
      swift_bridgeObjectRelease();
      uint64_t v48 = v68;
      unint64_t v58 = v73;
      unint64_t v50 = v73 + v68;
      unint64_t v59 = *v65;
      OUTLINED_FUNCTION_11_3();
      v59();
      OUTLINED_FUNCTION_11_3();
      v59();
      unint64_t v1 = v81;
      if (v57)
      {
        if (v58 < v5 || v50 >= v5)
        {
          OUTLINED_FUNCTION_131();
          swift_arrayInitWithTakeFrontToBack();
        }
        else if (v58 == v5)
        {
          unint64_t v5 = (unint64_t)v70;
        }
        else
        {
          OUTLINED_FUNCTION_131();
          swift_arrayInitWithTakeBackToFront();
        }
        uint64_t v29 = (char *)v79;
        unint64_t v62 = v80;
        goto LABEL_77;
      }
      if (v58 < v79 || v50 >= v79)
      {
        OUTLINED_FUNCTION_132();
        swift_arrayInitWithTakeFrontToBack();
      }
      else
      {
        if (v58 == v79)
        {
          uint64_t v29 = (char *)v71;
          goto LABEL_74;
        }
        OUTLINED_FUNCTION_132();
        swift_arrayInitWithTakeBackToFront();
      }
      uint64_t v29 = (char *)v59;
LABEL_74:
      unint64_t v62 = v80;
LABEL_77:
      if ((unint64_t)v29 <= v1 || v5 <= v62) {
        goto LABEL_39;
      }
    }
  }
  specialized UnsafeMutablePointer.moveInitialize(from:count:)(v7, v23 / v22);
  uint64_t v29 = (char *)(v1 + v27 * v22);
  if (v27 * v22 >= 1 && v5 < v73)
  {
    Swift::Int v77 = *(void (**)(void))(v12 + 16);
    uint64_t v74 = v12 + 16;
    uint64_t v75 = (void (**)(void))(v9 + 8);
    Swift::Int v70 = v19;
    uint64_t v71 = (void (**)(void))(v12 + 8);
    unint64_t v79 = v1 + v27 * v22;
    do
    {
      unint64_t v80 = v7;
      unint64_t v83 = v5;
      uint64_t v31 = v77;
      OUTLINED_FUNCTION_79_2();
      v31();
      unint64_t v81 = v1;
      OUTLINED_FUNCTION_79_2();
      v31();
      AnnotatedFeature.feature.getter();
      Swift::String v32 = URL.path(percentEncoded:)(1);
      BOOL v33 = *v75;
      OUTLINED_FUNCTION_11_3();
      v33();
      AnnotatedFeature.feature.getter();
      Swift::String v34 = URL.path(percentEncoded:)(1);
      OUTLINED_FUNCTION_11_3();
      v33();
      if (v32._countAndFlagsBits == v34._countAndFlagsBits && v32._object == v34._object)
      {
        swift_bridgeObjectRelease_n();
        uint64_t v42 = *v71;
        OUTLINED_FUNCTION_25_10();
        v42();
        OUTLINED_FUNCTION_25_10();
        v42();
        unint64_t v38 = v80;
        uint64_t v39 = v69;
      }
      else
      {
        char v36 = OUTLINED_FUNCTION_112();
        swift_bridgeObjectRelease();
        swift_bridgeObjectRelease();
        uint64_t v37 = *v71;
        OUTLINED_FUNCTION_25_10();
        v37();
        OUTLINED_FUNCTION_25_10();
        v37();
        unint64_t v38 = v80;
        uint64_t v39 = v69;
        if (v36)
        {
          unint64_t v40 = v5;
          v5 += v69;
          BOOL v41 = v80 < v83 || v80 >= v5;
          unint64_t v1 = v81;
          if (!v41) {
            goto LABEL_25;
          }
          goto LABEL_33;
        }
      }
      unint64_t v40 = v81;
      unint64_t v1 = v81 + v39;
      if (v38 >= v81 && v38 < v1)
      {
LABEL_25:
        if (v38 != v40) {
          swift_arrayInitWithTakeBackToFront();
        }
        goto LABEL_34;
      }
LABEL_33:
      swift_arrayInitWithTakeFrontToBack();
LABEL_34:
      uint64_t v29 = (char *)v79;
      unint64_t v7 = v38 + v39;
    }
    while (v1 < v79 && v5 < v73);
  }
LABEL_39:
  uint64_t v22 = v69;
LABEL_45:
  uint64_t v46 = &v29[-v1];
  if (v22 != -1 || v46 != (char *)0x8000000000000000)
  {
    specialized UnsafeMutablePointer.moveInitialize(from:count:)(v1, (uint64_t)v46 / v22);
    OUTLINED_FUNCTION_8_1();
    return;
  }
LABEL_86:
  __break(1u);
}

{
  char *v0;
  char *v1;
  unint64_t v2;
  char *v3;
  char *v4;
  unint64_t v5;
  char *v6;
  char *v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  unint64_t v12;
  BOOL v14;
  char *v15;
  char *v18;
  char *v19;
  char *v20;
  BOOL v21;
  BOOL v22;
  BOOL v23;

  OUTLINED_FUNCTION_9_0();
  unint64_t v4 = v3;
  unint64_t v5 = v2;
  unint64_t v6 = v1;
  unint64_t v7 = v0;
  uint64_t v8 = v1 - v0;
  uint64_t v9 = (v1 - v0) / 16;
  uint64_t v10 = v2 - (void)v1;
  uint64_t v11 = (uint64_t)(v2 - (void)v1) / 16;
  if (v9 >= v11)
  {
    specialized UnsafeMutablePointer.moveInitialize(from:count:)(v1, (uint64_t)(v2 - (void)v1) / 16, v3);
    uint64_t v12 = (unint64_t)&v4[16 * v11];
    if (v7 >= v6 || v10 < 16) {
      goto LABEL_47;
    }
    uint64_t v18 = (char *)(v5 - 16);
    while (1)
    {
      uint64_t v19 = v18 + 16;
      uint64_t v20 = (char *)(v12 - 16);
      uint64_t v21 = *(void *)(v12 - 16) == *((void *)v6 - 2) && *(void *)(v12 - 8) == *((void *)v6 - 1);
      if (v21 || (_stringCompareWithSmolCheck(_:_:expecting:)() & 1) == 0)
      {
        int64_t v23 = v19 != (char *)v12 || (unint64_t)v18 >= v12;
        v12 -= 16;
        if (!v23) {
          goto LABEL_43;
        }
      }
      else
      {
        uint64_t v22 = v19 != v6 || v18 >= v6;
        uint64_t v20 = v6 - 16;
        v6 -= 16;
        if (!v22) {
          goto LABEL_43;
        }
      }
      *(_OWORD *)uint64_t v18 = *(_OWORD *)v20;
LABEL_43:
      v18 -= 16;
      if (v6 <= v7 || v12 <= (unint64_t)v4) {
        goto LABEL_47;
      }
    }
  }
  specialized UnsafeMutablePointer.moveInitialize(from:count:)(v0, (v1 - v0) / 16, v3);
  uint64_t v12 = (unint64_t)&v4[16 * v9];
  if ((unint64_t)v6 < v5 && v8 >= 16)
  {
    while (1)
    {
      uint64_t v14 = *(void *)v6 == *(void *)v4 && *((void *)v6 + 1) == *((void *)v4 + 1);
      if (!v14 && (_stringCompareWithSmolCheck(_:_:expecting:)() & 1) != 0) {
        break;
      }
      uint64_t v15 = v4;
      uint64_t v14 = v7 == v4;
      v4 += 16;
      if (!v14) {
        goto LABEL_15;
      }
LABEL_16:
      v7 += 16;
      if ((unint64_t)v4 >= v12 || (unint64_t)v6 >= v5) {
        goto LABEL_21;
      }
    }
    uint64_t v15 = v6;
    uint64_t v14 = v7 == v6;
    v6 += 16;
    if (v14) {
      goto LABEL_16;
    }
LABEL_15:
    *(_OWORD *)unint64_t v7 = *(_OWORD *)v15;
    goto LABEL_16;
  }
LABEL_21:
  unint64_t v6 = v7;
LABEL_47:
  specialized UnsafeMutablePointer.moveInitialize(from:count:)(v4, (uint64_t)(v12 - (void)v4) / 16, v6);
  OUTLINED_FUNCTION_8_1();
}

uint64_t protocol witness for TrainingSessionDelegate.extractFeatures(from:) in conformance SoundClassifierTrainingSessionDelegate(uint64_t (*a1)(uint64_t, uint64_t), uint64_t a2, uint64_t a3, uint64_t a4)
{
  return a1(a3, a4);
}

unint64_t partial apply for specialized closure #1 in BidirectionalCollection.last(where:)@<X0>(unint64_t *a1@<X0>, uint64_t a2@<X8>)
{
  return specialized closure #1 in BidirectionalCollection.last(where:)(a1, *(uint64_t **)(v2 + 16), a2);
}

{
  uint64_t v2;

  return specialized closure #1 in BidirectionalCollection.last(where:)(a1, *(uint64_t **)(v2 + 16), a2);
}

uint64_t outlined init with take of DataFrame?(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 32))(a2, a1, v4);
  return a2;
}

uint64_t lazy protocol witness table accessor for type [Float] and conformance <A> [A](unint64_t *a1)
{
  uint64_t result = *a1;
  if (!result)
  {
    __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for [Float]);
    uint64_t result = swift_getWitnessTable();
    atomic_store(result, a1);
  }
  return result;
}

uint64_t lazy protocol witness table accessor for type MLSoundClassifier.Classifier and conformance MLSoundClassifier.Classifier(unint64_t *a1, void (*a2)(uint64_t))
{
  uint64_t result = *a1;
  if (!result)
  {
    a2(255);
    uint64_t result = swift_getWitnessTable();
    atomic_store(result, a1);
  }
  return result;
}

uint64_t sub_2270F91B0@<X0>(void *a1@<X8>)
{
  return key path getter for AnnotatedFeature.annotation : AnnotatedFeature<MLShapedArray<Float>, String>(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>, a1);
}

uint64_t sub_2270F91D0(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return key path setter for AnnotatedFeature.annotation : AnnotatedFeature<MLShapedArray<Float>, String>(a1, a2, a3, a4, &demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
}

uint64_t outlined destroy of MLSoundClassifier.Model(uint64_t a1, void (*a2)(void))
{
  a2(0);
  OUTLINED_FUNCTION_8();
  OUTLINED_FUNCTION_25_0();
  v3();
  return a1;
}

uint64_t outlined init with take of MLSoundClassifier.Model(uint64_t a1, uint64_t a2, void (*a3)(void))
{
  a3(0);
  OUTLINED_FUNCTION_8();
  (*(void (**)(uint64_t, uint64_t))(v5 + 32))(a2, a1);
  return a2;
}

uint64_t outlined init with copy of MLSoundClassifier.ModelParameters.ValidationData(uint64_t a1, uint64_t a2, void (*a3)(void))
{
  a3(0);
  OUTLINED_FUNCTION_8();
  uint64_t v4 = OUTLINED_FUNCTION_111();
  v5(v4);
  return a2;
}

uint64_t OUTLINED_FUNCTION_4_20()
{
  ++v0[37];
  v0[38] = v1;
  return v0[33];
}

unint64_t OUTLINED_FUNCTION_7_17()
{
  uint64_t v4 = *(void *)(v2 + 112);
  *(void *)(v3 + 16) = v1;
  return v3
       + ((*(unsigned __int8 *)(v4 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v4 + 80))
       + *(void *)(v4 + 72) * v0;
}

uint64_t OUTLINED_FUNCTION_11_10()
{
  return *(void *)(v0 + 208);
}

uint64_t OUTLINED_FUNCTION_12_7()
{
  return swift_task_dealloc();
}

uint64_t OUTLINED_FUNCTION_13_9()
{
  return swift_bridgeObjectRelease();
}

uint64_t OUTLINED_FUNCTION_20_8()
{
  return *(void *)(v0 + 240);
}

uint64_t OUTLINED_FUNCTION_21_9()
{
  return *(void *)(v0 + 240);
}

uint64_t OUTLINED_FUNCTION_22_9()
{
  return *(void *)(v0 + 240);
}

uint64_t OUTLINED_FUNCTION_28_7()
{
  return Event.init(origin:itemCount:totalItemCount:metrics:)();
}

uint64_t OUTLINED_FUNCTION_29_6()
{
  return *(void *)(v0 + 56);
}

uint64_t OUTLINED_FUNCTION_30_7(uint64_t a1, uint64_t a2)
{
  *(void *)a2 = 1;
  *(_OWORD *)(a2 + 8) = 0u;
  *(_OWORD *)(a2 + 24) = 0u;
  *(void *)(a2 + 40) = 0;
  *(unsigned char *)(a2 + 48) = 4;
  return swift_willThrow();
}

uint64_t OUTLINED_FUNCTION_32_7()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_33_6()
{
  outlined consume of (@escaping @callee_guaranteed @Sendable (@in_guaranteed Event) -> ())?(v0);
  return v1;
}

uint64_t OUTLINED_FUNCTION_42_5(uint64_t a1)
{
  return __swift_storeEnumTagSinglePayload(v1, 1, 1, a1);
}

uint64_t OUTLINED_FUNCTION_44_2()
{
  uint64_t v3 = *(void *)(v1 + 256);
  uint64_t v4 = *(void *)(v3 + 16);
  v3 += 16;
  *(_DWORD *)(v1 + 344) = *(_DWORD *)(v3 + 64);
  *(void *)(v1 + 280) = *(void *)(v3 + 56);
  *(void *)(v1 + 288) = v4;
  *(void *)(v1 + 296) = 0;
  *(void *)(v1 + 304) = v0;
  return swift_bridgeObjectRetain();
}

uint64_t OUTLINED_FUNCTION_49_0()
{
  uint64_t v2 = v0[37];
  uint64_t v3 = v0[35];
  if (v0[56] < v2) {
    uint64_t v2 = v0[56];
  }
  v0[68] = v2;
  v0[69] = v3;
  return static os_log_type_t.info.getter();
}

uint64_t OUTLINED_FUNCTION_50_4()
{
  return swift_bridgeObjectRelease();
}

uint64_t OUTLINED_FUNCTION_52_4(uint64_t result)
{
  *(void *)(v1 + 328) = result;
  return result;
}

uint64_t OUTLINED_FUNCTION_53_6(uint64_t result)
{
  *(void *)(v1 + 312) = result;
  return result;
}

uint64_t OUTLINED_FUNCTION_59_4()
{
  return v0 + 8;
}

uint64_t OUTLINED_FUNCTION_61_3()
{
  return 0x62614C7373616C63;
}

uint64_t OUTLINED_FUNCTION_62_2()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_63_2()
{
  return swift_bridgeObjectRelease();
}

double OUTLINED_FUNCTION_67_2()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_68_2()
{
  return MEMORY[0x270EEA5D0](v1, v0, v2);
}

uint64_t OUTLINED_FUNCTION_69_2()
{
  return type metadata accessor for MetricsKey();
}

uint64_t OUTLINED_FUNCTION_71_2()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_72_1()
{
  return swift_task_dealloc();
}

uint64_t OUTLINED_FUNCTION_75()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_77_2()
{
  return 0x7365727574616566;
}

uint64_t OUTLINED_FUNCTION_78_2()
{
  return swift_task_dealloc();
}

uint64_t OUTLINED_FUNCTION_81_2()
{
  return swift_beginAccess();
}

uint64_t OUTLINED_FUNCTION_82_2(uint64_t a1)
{
  return v1 + *(int *)(a1 + 20);
}

uint64_t OUTLINED_FUNCTION_83_2(uint64_t a1)
{
  return v1 + *(int *)(a1 + 20);
}

void OUTLINED_FUNCTION_86_1()
{
  unint64_t v2 = 0xD000000000000012;
  uint64_t v3 = v0;
  String.append(_:)(*(Swift::String *)&v2);
}

uint64_t OUTLINED_FUNCTION_87_0()
{
  return _stringCompareWithSmolCheck(_:_:expecting:)();
}

uint64_t OUTLINED_FUNCTION_89_0()
{
  return v0;
}

void OUTLINED_FUNCTION_93_0()
{
  specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
}

uint64_t OUTLINED_FUNCTION_95_0()
{
  return *(void *)(v0 - 160);
}

uint64_t OUTLINED_FUNCTION_96_0(uint64_t a1, uint64_t a2)
{
  *(void *)(v2 - 112) = a1;
  *(void *)(v2 - 104) = a2;
  return swift_bridgeObjectRetain();
}

uint64_t OUTLINED_FUNCTION_97_0()
{
  return swift_getEnumCaseMultiPayload();
}

uint64_t OUTLINED_FUNCTION_98_0()
{
  return Dictionary.init(dictionaryLiteral:)();
}

uint64_t OUTLINED_FUNCTION_103_0()
{
  return type metadata accessor for MLSoundClassifier.PersistentParameters();
}

uint64_t OUTLINED_FUNCTION_104_0()
{
  return type metadata accessor for MLSoundClassifier.PersistentParameters();
}

void OUTLINED_FUNCTION_105_0(uint64_t a1@<X8>, uint64_t a2)
{
  *(void *)(v2 - 168) = (char *)&a2 - ((a1 + 15) & 0xFFFFFFFFFFFFFFF0);
}

void OUTLINED_FUNCTION_107_0(uint64_t a1@<X8>, uint64_t a2)
{
  *(void *)(v2 - 200) = (char *)&a2 - ((a1 + 15) & 0xFFFFFFFFFFFFFFF0);
}

uint64_t OUTLINED_FUNCTION_108_0()
{
  return 0;
}

uint64_t OUTLINED_FUNCTION_109_0()
{
  return swift_allocObject();
}

uint64_t OUTLINED_FUNCTION_111_0()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_112()
{
  return _stringCompareWithSmolCheck(_:_:expecting:)();
}

void OUTLINED_FUNCTION_114_0(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
  *(void *)(v10 - 328) = (char *)&a9 - v9;
}

uint64_t OUTLINED_FUNCTION_119()
{
  return os_log(_:dso:log:type:_:)();
}

uint64_t OUTLINED_FUNCTION_122()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_123()
{
  return 0x676E696E69617274;
}

uint64_t OUTLINED_FUNCTION_124(uint64_t a1)
{
  return __swift_storeEnumTagSinglePayload(a1, 1, 1, v1);
}

uint64_t OUTLINED_FUNCTION_126()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_127()
{
  return v0 + 8;
}

uint64_t OUTLINED_FUNCTION_128()
{
  return DataFrame.init(contentsOfSFrameDirectory:columns:rows:)();
}

uint64_t OUTLINED_FUNCTION_130()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_131()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_132()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_133()
{
  return v0;
}

void OUTLINED_FUNCTION_134(uint64_t a1@<X8>)
{
  *(void *)a1 = 0;
  *(unsigned char *)(a1 + 8) = 1;
}

uint64_t OUTLINED_FUNCTION_135()
{
  return 1;
}

void OUTLINED_FUNCTION_139(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
  *(void *)(v10 - 176) = (char *)&a9 - v9;
}

uint64_t OUTLINED_FUNCTION_140()
{
  return swift_bridgeObjectRelease();
}

uint64_t OUTLINED_FUNCTION_141()
{
  return swift_isUniquelyReferenced_nonNull_native();
}

uint64_t OUTLINED_FUNCTION_142()
{
  return *(void *)(v0 - 152);
}

unint64_t OUTLINED_FUNCTION_143()
{
  *(void *)(v2 - 112) = v1;
  *(unsigned char *)(v2 - 104) = v0;
  return MLSoundClassifier.ModelParameters.FeatureExtractorType.description.getter();
}

uint64_t OUTLINED_FUNCTION_144()
{
  return 0x6C65646F6DLL;
}

uint64_t OUTLINED_FUNCTION_145()
{
  return 7762787;
}

uint64_t OUTLINED_FUNCTION_146()
{
  return AnnotatedFeature.annotation.getter();
}

uint64_t OUTLINED_FUNCTION_147()
{
  return *(void *)(v0 + 464);
}

uint64_t OUTLINED_FUNCTION_148()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_149()
{
  return String.init<A>(describing:)();
}

uint64_t OUTLINED_FUNCTION_151()
{
  return 0;
}

uint64_t OUTLINED_FUNCTION_154()
{
  return 0x697461756C617665;
}

uint64_t OUTLINED_FUNCTION_155()
{
  return 0x676E696E69617274;
}

uint64_t OUTLINED_FUNCTION_156()
{
  return URL.path(percentEncoded:)(1)._countAndFlagsBits;
}

uint64_t OUTLINED_FUNCTION_157()
{
  return 1;
}

uint64_t OUTLINED_FUNCTION_158()
{
  return AnnotatedFeature.feature.getter();
}

uint64_t OUTLINED_FUNCTION_159()
{
  return AnnotatedFeature.feature.getter();
}

uint64_t OUTLINED_FUNCTION_160()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_161(uint64_t a1)
{
  return __swift_storeEnumTagSinglePayload(v1, 0, 1, a1);
}

uint64_t OUTLINED_FUNCTION_162(uint64_t a1)
{
  return __swift_storeEnumTagSinglePayload(v1, 0, 1, a1);
}

uint64_t OUTLINED_FUNCTION_165()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_166()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_169()
{
  return v0 + 8;
}

uint64_t OUTLINED_FUNCTION_172()
{
  return 0x69746164696C6176;
}

uint64_t OUTLINED_FUNCTION_173()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_174()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_176()
{
  return *(void *)(v0 + 464);
}

uint64_t OUTLINED_FUNCTION_177(uint64_t a1, uint64_t a2, void (*a3)(void))
{
  return outlined init with copy of MLSoundClassifier.ModelParameters.ValidationData(v3, v4, a3);
}

uint64_t MLImageClassifier.ImageAugmentationOptions.rawValue.getter()
{
  return *(void *)v0;
}

uint64_t MLImageClassifier.ImageAugmentationOptions.init(rawValue:)@<X0>(uint64_t result@<X0>, void *a2@<X8>)
{
  *a2 = result;
  return result;
}

void static MLImageClassifier.ImageAugmentationOptions.blur.getter(void *a1@<X8>)
{
}

void static MLImageClassifier.ImageAugmentationOptions.flip.getter(void *a1@<X8>)
{
}

void static MLImageClassifier.ImageAugmentationOptions.exposure.getter(void *a1@<X8>)
{
}

void static MLImageClassifier.ImageAugmentationOptions.noise.getter(void *a1@<X8>)
{
}

void static MLImageClassifier.ImageAugmentationOptions.rotation.getter(void *a1@<X8>)
{
}

void static MLImageClassifier.ImageAugmentationOptions.crop.getter(void *a1@<X8>)
{
}

unint64_t lazy protocol witness table accessor for type MLImageClassifier.ImageAugmentationOptions and conformance MLImageClassifier.ImageAugmentationOptions()
{
  unint64_t result = lazy protocol witness table cache variable for type MLImageClassifier.ImageAugmentationOptions and conformance MLImageClassifier.ImageAugmentationOptions;
  if (!lazy protocol witness table cache variable for type MLImageClassifier.ImageAugmentationOptions and conformance MLImageClassifier.ImageAugmentationOptions)
  {
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type MLImageClassifier.ImageAugmentationOptions and conformance MLImageClassifier.ImageAugmentationOptions);
  }
  return result;
}

{
  unint64_t result;

  unint64_t result = lazy protocol witness table cache variable for type MLImageClassifier.ImageAugmentationOptions and conformance MLImageClassifier.ImageAugmentationOptions;
  if (!lazy protocol witness table cache variable for type MLImageClassifier.ImageAugmentationOptions and conformance MLImageClassifier.ImageAugmentationOptions)
  {
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type MLImageClassifier.ImageAugmentationOptions and conformance MLImageClassifier.ImageAugmentationOptions);
  }
  return result;
}

{
  unint64_t result;

  unint64_t result = lazy protocol witness table cache variable for type MLImageClassifier.ImageAugmentationOptions and conformance MLImageClassifier.ImageAugmentationOptions;
  if (!lazy protocol witness table cache variable for type MLImageClassifier.ImageAugmentationOptions and conformance MLImageClassifier.ImageAugmentationOptions)
  {
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type MLImageClassifier.ImageAugmentationOptions and conformance MLImageClassifier.ImageAugmentationOptions);
  }
  return result;
}

{
  unint64_t result;

  unint64_t result = lazy protocol witness table cache variable for type MLImageClassifier.ImageAugmentationOptions and conformance MLImageClassifier.ImageAugmentationOptions;
  if (!lazy protocol witness table cache variable for type MLImageClassifier.ImageAugmentationOptions and conformance MLImageClassifier.ImageAugmentationOptions)
  {
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type MLImageClassifier.ImageAugmentationOptions and conformance MLImageClassifier.ImageAugmentationOptions);
  }
  return result;
}

uint64_t protocol witness for OptionSet.init(rawValue:) in conformance MLImageClassifier.ImageAugmentationOptions@<X0>(uint64_t *a1@<X0>, void *a2@<X8>)
{
  return MLImageClassifier.ImageAugmentationOptions.init(rawValue:)(*a1, a2);
}

void protocol witness for SetAlgebra.union(_:) in conformance MLImageClassifier.ImageAugmentationOptions(void *a1@<X8>)
{
}

void protocol witness for SetAlgebra.intersection(_:) in conformance MLImageClassifier.ImageAugmentationOptions(void *a1@<X8>)
{
}

void specialized OptionSet.intersection(_:)(void *a1@<X8>)
{
}

void protocol witness for SetAlgebra.symmetricDifference(_:) in conformance MLImageClassifier.ImageAugmentationOptions(void *a1@<X8>)
{
}

BOOL protocol witness for SetAlgebra.insert(_:) in conformance MLImageClassifier.ImageAugmentationOptions(void *a1, uint64_t *a2)
{
  return specialized OptionSet<>.insert(_:)(a1, *a2);
}

uint64_t protocol witness for SetAlgebra.remove(_:) in conformance MLImageClassifier.ImageAugmentationOptions(void *a1)
{
  return specialized OptionSet<>.remove(_:)(*a1);
}

uint64_t protocol witness for SetAlgebra.update(with:) in conformance MLImageClassifier.ImageAugmentationOptions(void *a1)
{
  return specialized OptionSet<>.update(with:)(*a1);
}

void protocol witness for SetAlgebra.formUnion(_:) in conformance MLImageClassifier.ImageAugmentationOptions(uint64_t *a1)
{
}

uint64_t protocol witness for SetAlgebra.formIntersection(_:) in conformance MLImageClassifier.ImageAugmentationOptions(uint64_t *a1)
{
  return specialized OptionSet<>.formIntersection(_:)(*a1);
}

uint64_t specialized OptionSet<>.formIntersection(_:)(uint64_t result)
{
  *v1 &= result;
  return result;
}

void protocol witness for SetAlgebra.formSymmetricDifference(_:) in conformance MLImageClassifier.ImageAugmentationOptions(uint64_t *a1)
{
}

void protocol witness for SetAlgebra.subtracting(_:) in conformance MLImageClassifier.ImageAugmentationOptions(void *a1@<X8>)
{
}

BOOL protocol witness for SetAlgebra.isSubset(of:) in conformance MLImageClassifier.ImageAugmentationOptions(uint64_t *a1)
{
  return specialized SetAlgebra.isSubset(of:)(*a1, *v1);
}

BOOL specialized SetAlgebra.isSubset(of:)(uint64_t a1, uint64_t a2)
{
  return (a2 & ~a1) == 0;
}

BOOL protocol witness for SetAlgebra.isDisjoint(with:) in conformance MLImageClassifier.ImageAugmentationOptions(uint64_t *a1)
{
  return specialized SetAlgebra.isDisjoint(with:)(*a1, *v1);
}

BOOL protocol witness for SetAlgebra.isSuperset(of:) in conformance MLImageClassifier.ImageAugmentationOptions(uint64_t *a1)
{
  return specialized SetAlgebra.isSuperset(of:)(*a1, *v1);
}

BOOL specialized SetAlgebra.isSuperset(of:)(uint64_t a1, uint64_t a2)
{
  return (a1 & ~a2) == 0;
}

BOOL protocol witness for SetAlgebra.isEmpty.getter in conformance MLImageClassifier.ImageAugmentationOptions()
{
  return OUTLINED_FUNCTION_15_19(*v0);
}

uint64_t protocol witness for SetAlgebra.init<A>(_:) in conformance MLImageClassifier.ImageAugmentationOptions(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  return MEMORY[0x270F9E7D8](a1, a4, a2, a5, a3);
}

void protocol witness for SetAlgebra.subtract(_:) in conformance MLImageClassifier.ImageAugmentationOptions(uint64_t *a1)
{
}

uint64_t protocol witness for RawRepresentable.init(rawValue:) in conformance MLImageClassifier.ImageAugmentationOptions@<X0>(uint64_t *a1@<X0>, uint64_t a2@<X8>)
{
  uint64_t result = MLImageClassifier.ImageAugmentationOptions.init(rawValue:)(*a1, (void *)a2);
  *(unsigned char *)(a2 + 8) = 0;
  return result;
}

uint64_t protocol witness for RawRepresentable.rawValue.getter in conformance MLImageClassifier.ImageAugmentationOptions@<X0>(uint64_t *a1@<X8>)
{
  uint64_t result = MLImageClassifier.ImageAugmentationOptions.rawValue.getter();
  *a1 = result;
  return result;
}

BOOL protocol witness for static Equatable.== infix(_:_:) in conformance MLImageClassifier.ImageAugmentationOptions(uint64_t *a1, uint64_t *a2)
{
  return specialized == infix<A>(_:_:)(*a1, *a2);
}

ValueMetadata *type metadata accessor for MLImageClassifier.ImageAugmentationOptions()
{
  return &type metadata for MLImageClassifier.ImageAugmentationOptions;
}

uint64_t closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)@<X0>(uint64_t a1@<X8>)
{
  uint64_t v102 = a1;
  uint64_t v100 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A, B>(accumulated:next:)>>.0);
  OUTLINED_FUNCTION_0();
  uint64_t v101 = v1;
  MEMORY[0x270FA5388](v2);
  OUTLINED_FUNCTION_33_0();
  OUTLINED_FUNCTION_45_2(v3);
  uint64_t v96 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A, B>(accumulated:next:)>>.0);
  OUTLINED_FUNCTION_0();
  uint64_t v99 = v4;
  MEMORY[0x270FA5388](v5);
  OUTLINED_FUNCTION_33_0();
  OUTLINED_FUNCTION_45_2(v6);
  uint64_t v112 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A, B>(accumulated:next:)>>.0);
  OUTLINED_FUNCTION_0();
  uint64_t v98 = v7;
  MEMORY[0x270FA5388](v8);
  OUTLINED_FUNCTION_33_0();
  OUTLINED_FUNCTION_45_2(v9);
  uint64_t v111 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A, B>(accumulated:next:)>>.0);
  OUTLINED_FUNCTION_0();
  uint64_t v97 = v10;
  MEMORY[0x270FA5388](v11);
  OUTLINED_FUNCTION_33_0();
  OUTLINED_FUNCTION_45_2(v12);
  uint64_t v110 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A, B>(accumulated:next:)>>.0);
  OUTLINED_FUNCTION_0();
  uint64_t v95 = v13;
  MEMORY[0x270FA5388](v14);
  OUTLINED_FUNCTION_33_0();
  OUTLINED_FUNCTION_45_2(v15);
  uint64_t v108 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0);
  OUTLINED_FUNCTION_0();
  uint64_t v94 = v16;
  MEMORY[0x270FA5388](v17);
  OUTLINED_FUNCTION_33_0();
  OUTLINED_FUNCTION_45_2(v18);
  uint64_t v90 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0>);
  OUTLINED_FUNCTION_0();
  uint64_t v93 = v19;
  MEMORY[0x270FA5388](v20);
  OUTLINED_FUNCTION_33_0();
  OUTLINED_FUNCTION_45_2(v21);
  uint64_t v86 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0>);
  OUTLINED_FUNCTION_0();
  uint64_t v92 = v22;
  MEMORY[0x270FA5388](v23);
  OUTLINED_FUNCTION_33_0();
  OUTLINED_FUNCTION_45_2(v24);
  uint64_t v109 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0>);
  OUTLINED_FUNCTION_0();
  uint64_t v91 = v25;
  MEMORY[0x270FA5388](v26);
  OUTLINED_FUNCTION_3_0();
  uint64_t v104 = v28 - v27;
  uint64_t v107 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0>);
  OUTLINED_FUNCTION_0();
  uint64_t v89 = v29;
  MEMORY[0x270FA5388](v30);
  OUTLINED_FUNCTION_3_0();
  uint64_t v33 = v32 - v31;
  uint64_t v105 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0>);
  OUTLINED_FUNCTION_0();
  uint64_t v88 = v34;
  MEMORY[0x270FA5388](v35);
  uint64_t v106 = (char *)&v83 - ((v36 + 15) & 0xFFFFFFFFFFFFFFF0);
  MEMORY[0x270FA5388](v37);
  uint64_t v39 = (char *)&v83 - v38;
  uint64_t v103 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0>);
  OUTLINED_FUNCTION_0();
  uint64_t v87 = v40;
  MEMORY[0x270FA5388](v41);
  OUTLINED_FUNCTION_3_0();
  uint64_t v44 = v43 - v42;
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0);
  unint64_t v45 = type metadata accessor for CIImage();
  uint64_t v46 = type metadata accessor for ImageBlur();
  unint64_t v113 = v45;
  uint64_t v114 = v46;
  uint64_t v115 = MEMORY[0x263F044F8];
  swift_getOpaqueTypeConformance2();
  uint64_t v85 = v44;
  ApplyRandomly.init<A>(probability:_:)();
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0);
  uint64_t v47 = type metadata accessor for ImageFlipper();
  unint64_t v113 = v45;
  uint64_t v114 = v47;
  OUTLINED_FUNCTION_5_18(MEMORY[0x263F04328]);
  uint64_t v84 = v39;
  OUTLINED_FUNCTION_10_11();
  OUTLINED_FUNCTION_10_11();
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0);
  OUTLINED_FUNCTION_13_10();
  uint64_t v48 = type metadata accessor for ImageExposureAdjuster();
  unint64_t v113 = v45;
  uint64_t v114 = v48;
  OUTLINED_FUNCTION_5_18(MEMORY[0x263F043C0]);
  uint64_t v83 = v33;
  OUTLINED_FUNCTION_11_11();
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0);
  OUTLINED_FUNCTION_13_10();
  uint64_t v49 = type metadata accessor for RandomImageNoiseGenerator();
  unint64_t v113 = v45;
  uint64_t v114 = v49;
  OUTLINED_FUNCTION_5_18(MEMORY[0x263F04410]);
  OUTLINED_FUNCTION_11_11();
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0);
  OUTLINED_FUNCTION_13_10();
  uint64_t v50 = type metadata accessor for ImageRotator();
  unint64_t v113 = v45;
  uint64_t v114 = v50;
  OUTLINED_FUNCTION_5_18(MEMORY[0x263F04330]);
  OUTLINED_FUNCTION_11_11();
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0);
  OUTLINED_FUNCTION_13_10();
  uint64_t v51 = type metadata accessor for RandomImageCropper();
  unint64_t v113 = v45;
  uint64_t v114 = v51;
  uint64_t v115 = MEMORY[0x263F04380];
  swift_getOpaqueTypeConformance2();
  ApplyRandomly.init<A>(probability:_:)();
  uint64_t v52 = lazy protocol witness table accessor for type ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0> and conformance ApplyRandomly<A>(&lazy protocol witness table cache variable for type ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0> and conformance ApplyRandomly<A>, &demangling cache variable for type metadata for ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0>);
  uint64_t v53 = v103;
  static AugmentationBuilder.buildPartialBlock<A>(first:)();
  unint64_t v113 = v45;
  uint64_t v114 = v53;
  uint64_t v115 = v52;
  uint64_t OpaqueTypeConformance2 = swift_getOpaqueTypeConformance2();
  uint64_t v55 = lazy protocol witness table accessor for type ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0> and conformance ApplyRandomly<A>(&lazy protocol witness table cache variable for type ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0> and conformance ApplyRandomly<A>, &demangling cache variable for type metadata for ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0>);
  uint64_t v56 = v108;
  uint64_t v57 = v105;
  OUTLINED_FUNCTION_12_8();
  unint64_t v113 = v45;
  uint64_t v114 = v56;
  uint64_t v115 = v57;
  uint64_t v116 = OpaqueTypeConformance2;
  uint64_t v117 = v55;
  uint64_t v58 = swift_getOpaqueTypeConformance2();
  uint64_t v59 = v110;
  OUTLINED_FUNCTION_12_8();
  unint64_t v113 = v45;
  uint64_t v114 = v59;
  uint64_t v115 = v57;
  uint64_t v116 = v58;
  uint64_t v60 = OUTLINED_FUNCTION_6_17();
  lazy protocol witness table accessor for type ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0> and conformance ApplyRandomly<A>(&lazy protocol witness table cache variable for type ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0> and conformance ApplyRandomly<A>, &demangling cache variable for type metadata for ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0>);
  uint64_t v61 = v111;
  uint64_t v62 = v107;
  OUTLINED_FUNCTION_12_8();
  unint64_t v113 = v45;
  uint64_t v114 = v61;
  uint64_t v115 = v62;
  uint64_t v116 = v60;
  uint64_t v63 = OUTLINED_FUNCTION_6_17();
  lazy protocol witness table accessor for type ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0> and conformance ApplyRandomly<A>(&lazy protocol witness table cache variable for type ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0> and conformance ApplyRandomly<A>, &demangling cache variable for type metadata for ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0>);
  uint64_t v64 = v112;
  uint64_t v65 = v109;
  OUTLINED_FUNCTION_12_8();
  unint64_t v113 = v45;
  uint64_t v114 = v64;
  uint64_t v115 = v65;
  uint64_t v116 = v63;
  uint64_t v66 = OUTLINED_FUNCTION_6_17();
  lazy protocol witness table accessor for type ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0> and conformance ApplyRandomly<A>(&lazy protocol witness table cache variable for type ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0> and conformance ApplyRandomly<A>, &demangling cache variable for type metadata for ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0>);
  uint64_t v67 = v96;
  uint64_t v68 = v86;
  OUTLINED_FUNCTION_12_8();
  unint64_t v113 = v45;
  uint64_t v114 = v67;
  uint64_t v115 = v68;
  uint64_t v116 = v66;
  OUTLINED_FUNCTION_6_17();
  lazy protocol witness table accessor for type ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0> and conformance ApplyRandomly<A>(&lazy protocol witness table cache variable for type ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0> and conformance ApplyRandomly<A>, &demangling cache variable for type metadata for ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0>);
  static AugmentationBuilder.buildPartialBlock<A, B>(accumulated:next:)();
  OUTLINED_FUNCTION_3_25();
  OUTLINED_FUNCTION_25_0();
  v69();
  OUTLINED_FUNCTION_3_25();
  OUTLINED_FUNCTION_25_0();
  v70();
  OUTLINED_FUNCTION_3_25();
  OUTLINED_FUNCTION_2_24();
  v71();
  OUTLINED_FUNCTION_3_25();
  OUTLINED_FUNCTION_2_24();
  v72();
  OUTLINED_FUNCTION_3_25();
  OUTLINED_FUNCTION_2_24();
  v73();
  OUTLINED_FUNCTION_3_25();
  OUTLINED_FUNCTION_2_24();
  v74();
  OUTLINED_FUNCTION_3_25();
  OUTLINED_FUNCTION_25_0();
  v75();
  OUTLINED_FUNCTION_3_25();
  OUTLINED_FUNCTION_25_0();
  v76();
  OUTLINED_FUNCTION_3_25();
  OUTLINED_FUNCTION_2_24();
  v77();
  OUTLINED_FUNCTION_3_25();
  OUTLINED_FUNCTION_2_24();
  v78();
  unint64_t v79 = *(void (**)(char *, uint64_t))(v88 + 8);
  uint64_t v80 = v105;
  v79(v106, v105);
  v79(v84, v80);
  OUTLINED_FUNCTION_3_25();
  OUTLINED_FUNCTION_2_24();
  return v81();
}

uint64_t closure #1 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)()
{
  uint64_t v0 = type metadata accessor for ImageBlur();
  uint64_t v1 = *(void *)(v0 - 8);
  MEMORY[0x270FA5388](v0);
  uint64_t v3 = (char *)&v5 - ((v2 + 15) & 0xFFFFFFFFFFFFFFF0);
  specialized RandomNumberGenerator.next<A>(upperBound:)(0x20uLL);
  ImageBlur.init(radius:)();
  type metadata accessor for CIImage();
  static AugmentationBuilder.buildPartialBlock<A>(first:)();
  return (*(uint64_t (**)(char *, uint64_t))(v1 + 8))(v3, v0);
}

uint64_t partial apply for closure #1 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)()
{
  return closure #1 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)();
}

unint64_t type metadata accessor for CIImage()
{
  unint64_t result = lazy cache variable for type metadata for CIImage;
  if (!lazy cache variable for type metadata for CIImage)
  {
    self;
    unint64_t result = swift_getObjCClassMetadata();
    atomic_store(result, (unint64_t *)&lazy cache variable for type metadata for CIImage);
  }
  return result;
}

uint64_t closure #2 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)()
{
  return closure #2 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)(MEMORY[0x263F04318]);
}

uint64_t closure #3 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)()
{
  return closure #2 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)(MEMORY[0x263F04320]);
}

uint64_t closure #2 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)(unsigned int *a1)
{
  uint64_t v2 = type metadata accessor for ImageFlipper.Orientation();
  OUTLINED_FUNCTION_0();
  uint64_t v4 = v3;
  MEMORY[0x270FA5388](v5);
  OUTLINED_FUNCTION_3_0();
  uint64_t v8 = v7 - v6;
  uint64_t v9 = type metadata accessor for ImageFlipper();
  OUTLINED_FUNCTION_0();
  uint64_t v11 = v10;
  MEMORY[0x270FA5388](v12);
  OUTLINED_FUNCTION_3_0();
  uint64_t v15 = v14 - v13;
  (*(void (**)(uint64_t, void, uint64_t))(v4 + 104))(v8, *a1, v2);
  ImageFlipper.init(orientation:)();
  type metadata accessor for CIImage();
  static AugmentationBuilder.buildPartialBlock<A>(first:)();
  return (*(uint64_t (**)(uint64_t, uint64_t))(v11 + 8))(v15, v9);
}

uint64_t closure #4 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)()
{
  uint64_t v0 = type metadata accessor for ImageExposureAdjuster();
  uint64_t v1 = *(void *)(v0 - 8);
  MEMORY[0x270FA5388](v0);
  uint64_t v3 = (char *)&v5 - ((v2 + 15) & 0xFFFFFFFFFFFFFFF0);
  specialized RandomNumberGenerator.next<A>(upperBound:)(0xBuLL);
  ImageExposureAdjuster.init(amount:)();
  type metadata accessor for CIImage();
  static AugmentationBuilder.buildPartialBlock<A>(first:)();
  return (*(uint64_t (**)(char *, uint64_t))(v1 + 8))(v3, v0);
}

uint64_t partial apply for closure #4 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)()
{
  return closure #4 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)();
}

uint64_t closure #5 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)()
{
  uint64_t v0 = type metadata accessor for RandomImageNoiseGenerator();
  uint64_t v1 = *(void *)(v0 - 8);
  MEMORY[0x270FA5388](v0);
  uint64_t v3 = (char *)&v5 - ((v2 + 15) & 0xFFFFFFFFFFFFFFF0);
  specialized RandomNumberGenerator.next<A>(upperBound:)(0xBuLL);
  RandomImageNoiseGenerator.init(intensity:)();
  type metadata accessor for CIImage();
  static AugmentationBuilder.buildPartialBlock<A>(first:)();
  return (*(uint64_t (**)(char *, uint64_t))(v1 + 8))(v3, v0);
}

uint64_t partial apply for closure #5 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)()
{
  return closure #5 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)();
}

uint64_t closure #6 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)()
{
  uint64_t v0 = type metadata accessor for ImageRotator();
  uint64_t v1 = *(void *)(v0 - 8);
  MEMORY[0x270FA5388](v0);
  uint64_t v3 = (char *)&v5 - ((v2 + 15) & 0xFFFFFFFFFFFFFFF0);
  specialized RandomNumberGenerator.next<A>(upperBound:)(0xBuLL);
  ImageRotator.init(angle:)();
  type metadata accessor for CIImage();
  static AugmentationBuilder.buildPartialBlock<A>(first:)();
  return (*(uint64_t (**)(char *, uint64_t))(v1 + 8))(v3, v0);
}

uint64_t partial apply for closure #6 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)()
{
  return closure #6 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)();
}

uint64_t closure #7 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)()
{
  uint64_t v0 = type metadata accessor for RandomImageCropper();
  uint64_t v1 = *(void *)(v0 - 8);
  MEMORY[0x270FA5388](v0);
  uint64_t v3 = (char *)&v5 - ((v2 + 15) & 0xFFFFFFFFFFFFFFF0);
  RandomImageCropper.init(scale:aspectRatio:)();
  type metadata accessor for CIImage();
  static AugmentationBuilder.buildPartialBlock<A>(first:)();
  return (*(uint64_t (**)(char *, uint64_t))(v1 + 8))(v3, v0);
}

uint64_t lazy protocol witness table accessor for type ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0> and conformance ApplyRandomly<A>(unint64_t *a1, uint64_t *a2)
{
  uint64_t result = *a1;
  if (!result)
  {
    __swift_instantiateConcreteTypeFromMangledNameAbstract(a2);
    uint64_t result = swift_getWitnessTable();
    atomic_store(result, a1);
  }
  return result;
}

uint64_t OUTLINED_FUNCTION_5_18@<X0>(uint64_t a1@<X8>)
{
  *(void *)(v1 - 144) = a1;
  return swift_getOpaqueTypeConformance2();
}

uint64_t OUTLINED_FUNCTION_6_17()
{
  *(void *)(v1 - 128) = v0;
  return swift_getOpaqueTypeConformance2();
}

void OUTLINED_FUNCTION_9_13(void *a1@<X8>)
{
  *a1 = v1;
}

uint64_t OUTLINED_FUNCTION_10_11()
{
  return ApplyRandomly.init<A>(probability:_:)();
}

uint64_t OUTLINED_FUNCTION_11_11()
{
  return ApplyRandomly.init<A>(probability:_:)();
}

uint64_t OUTLINED_FUNCTION_12_8()
{
  return static AugmentationBuilder.buildPartialBlock<A, B>(accumulated:next:)();
}

uint64_t OUTLINED_FUNCTION_13_10()
{
  return 255;
}

uint64_t static _FileUtilities.prepareForWriting(to:isDirectory:)(uint64_t a1, char a2)
{
  v18[1] = *(id *)MEMORY[0x263EF8340];
  uint64_t v4 = type metadata accessor for URL();
  OUTLINED_FUNCTION_0();
  uint64_t v6 = v5;
  MEMORY[0x270FA5388](v7);
  OUTLINED_FUNCTION_41_0();
  if (a2)
  {
    OUTLINED_FUNCTION_18_3();
    v8();
  }
  else
  {
    URL.deletingLastPathComponent()();
  }
  id v9 = objc_msgSend(self, sel_defaultManager);
  URL._bridgeToObjectiveC()(v10);
  uint64_t v12 = v11;
  v18[0] = 0;
  unsigned __int8 v13 = objc_msgSend(v9, sel_createDirectoryAtURL_withIntermediateDirectories_attributes_error_, v11, 1, 0, v18);

  if (v13)
  {
    uint64_t v14 = *(uint64_t (**)(uint64_t, uint64_t))(v6 + 8);
    id v15 = v18[0];
    return v14(v2, v4);
  }
  else
  {
    id v17 = v18[0];
    _convertNSErrorToError(_:)();

    swift_willThrow();
    return (*(uint64_t (**)(uint64_t, uint64_t))(v6 + 8))(v2, v4);
  }
}

id static _FileUtilities.isReadableFile(at:of:)()
{
  uint64_t v0 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for UTType?);
  uint64_t v1 = OUTLINED_FUNCTION_17(v0);
  MEMORY[0x270FA5388](v1);
  uint64_t v3 = (char *)&v17 - ((v2 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v4 = type metadata accessor for UTType();
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v5);
  OUTLINED_FUNCTION_52_1();
  MEMORY[0x270FA5388](v6);
  URL.pathExtension.getter();
  static UTType.data.getter();
  UTType.init(filenameExtension:conformingTo:)();
  if (__swift_getEnumTagSinglePayload((uint64_t)v3, 1, v4) == 1)
  {
    outlined destroy of UTType?((uint64_t)v3, &demangling cache variable for type metadata for UTType?);
    return 0;
  }
  OUTLINED_FUNCTION_3();
  v7();
  if ((UTType.conforms(to:)() & 1) == 0)
  {
    uint64_t v14 = OUTLINED_FUNCTION_19_10();
    v15(v14);
    return 0;
  }
  id v8 = objc_msgSend(self, sel_defaultManager);
  uint64_t v9 = URL.path.getter();
  uint64_t v10 = (void *)MEMORY[0x22A674AE0](v9);
  swift_bridgeObjectRelease();
  id v11 = objc_msgSend(v8, sel_isReadableFileAtPath_, v10);

  uint64_t v12 = OUTLINED_FUNCTION_19_10();
  v13(v12);
  return v11;
}

uint64_t specialized _ArrayProtocol.filter(_:)(uint64_t (*a1)(char *), uint64_t a2, uint64_t a3)
{
  uint64_t v4 = v3;
  uint64_t v33 = a1;
  uint64_t v34 = a2;
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  MEMORY[0x270FA5388](v6 - 8);
  id v8 = (char *)&v25 - ((v7 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v9 = type metadata accessor for URL();
  uint64_t v10 = *(void *)(v9 - 8);
  uint64_t v11 = MEMORY[0x270FA5388](v9);
  uint64_t v30 = (char *)&v25 - ((v12 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t result = MEMORY[0x270FA5388](v11);
  uint64_t v36 = (char *)&v25 - v14;
  uint64_t v37 = MEMORY[0x263F8EE78];
  uint64_t v31 = *(void *)(a3 + 16);
  if (v31)
  {
    unint64_t v15 = 0;
    uint64_t v32 = v10 + 16;
    uint64_t v35 = (void (**)(char *, char *, uint64_t))(v10 + 32);
    uint64_t v26 = a3;
    uint64_t v27 = (void (**)(char *, uint64_t))(v10 + 8);
    uint64_t v29 = v10;
    while (v15 < *(void *)(a3 + 16))
    {
      unint64_t v16 = (*(unsigned __int8 *)(v10 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v10 + 80);
      uint64_t v17 = *(void *)(v10 + 72);
      (*(void (**)(char *, unint64_t, uint64_t))(v10 + 16))(v8, a3 + v16 + v17 * v15, v9);
      __swift_storeEnumTagSinglePayload((uint64_t)v8, 0, 1, v9);
      if (__swift_getEnumTagSinglePayload((uint64_t)v8, 1, v9) == 1) {
        goto LABEL_15;
      }
      uint64_t v18 = v36;
      uint64_t v19 = *v35;
      (*v35)(v36, v8, v9);
      char v20 = v33(v18);
      if (v4)
      {
        (*v27)(v36, v9);
        swift_bridgeObjectRelease();
        return swift_release();
      }
      if (v20)
      {
        v19(v30, v36, v9);
        uint64_t v21 = v37;
        char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native();
        uint64_t v28 = 0;
        if ((isUniquelyReferenced_nonNull_native & 1) == 0)
        {
          specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, *(void *)(v21 + 16) + 1, 1);
          uint64_t v21 = v37;
        }
        unint64_t v24 = *(void *)(v21 + 16);
        unint64_t v23 = *(void *)(v21 + 24);
        if (v24 >= v23 >> 1)
        {
          specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v23 > 1, v24 + 1, 1);
          uint64_t v21 = v37;
        }
        *(void *)(v21 + 16) = v24 + 1;
        uint64_t result = ((uint64_t (*)(unint64_t, char *, uint64_t))v19)(v21 + v16 + v24 * v17, v30, v9);
        uint64_t v37 = v21;
        uint64_t v4 = v28;
        a3 = v26;
      }
      else
      {
        uint64_t result = ((uint64_t (*)(char *, uint64_t))*v27)(v36, v9);
      }
      ++v15;
      uint64_t v10 = v29;
      if (v31 == v15) {
        goto LABEL_14;
      }
    }
    __break(1u);
  }
  else
  {
LABEL_14:
    __swift_storeEnumTagSinglePayload((uint64_t)v8, 1, 1, v9);
LABEL_15:
    swift_bridgeObjectRelease();
    outlined destroy of UTType?((uint64_t)v8, &demangling cache variable for type metadata for URL?);
    return v37;
  }
  return result;
}

void static _FileUtilities.collectFilesLabeledByDirectoryName(at:type:)()
{
  OUTLINED_FUNCTION_9_0();
  unint64_t v3 = v0;
  uint64_t v5 = v4;
  uint64_t v7 = v6;
  uint64_t v8 = type metadata accessor for URL();
  OUTLINED_FUNCTION_0();
  unint64_t v10 = v9;
  MEMORY[0x270FA5388](v11);
  OUTLINED_FUNCTION_52_1();
  MEMORY[0x270FA5388](v12);
  uint64_t v14 = (char *)v73 - v13;
  uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  uint64_t v16 = OUTLINED_FUNCTION_17(v15);
  MEMORY[0x270FA5388](v16);
  OUTLINED_FUNCTION_33();
  uint64_t v19 = v17 - v18;
  MEMORY[0x270FA5388](v20);
  OUTLINED_FUNCTION_15_11();
  static _FileUtilities.getReadableSubdirectoriesOfDirectory(at:)();
  if (v0)
  {
    swift_bridgeObjectRelease();
LABEL_51:
    OUTLINED_FUNCTION_8_1();
    return;
  }
  uint64_t v92 = v7;
  uint64_t v87 = v19;
  uint64_t v78 = v2;
  uint64_t v84 = v1;
  uint64_t v76 = v14;
  uint64_t v74 = *(void *)(v21 + 16);
  if (v74)
  {
    uint64_t v22 = v78;
  }
  else
  {
    swift_bridgeObjectRelease();
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<URL>);
    uint64_t v23 = swift_allocObject();
    *(_OWORD *)(v23 + 16) = xmmword_2272CB370;
    OUTLINED_FUNCTION_18_3();
    v24();
    uint64_t v21 = v23;
    uint64_t v22 = v78;
    uint64_t v74 = *(void *)(v23 + 16);
    if (!v74)
    {
      uint64_t v77 = v23;
      uint64_t v25 = 0;
LABEL_49:
      OUTLINED_FUNCTION_3_26(v22, 1);
LABEL_50:
      swift_bridgeObjectRelease();
      outlined consume of (@escaping @callee_guaranteed @Sendable (@in_guaranteed Event) -> ())?((uint64_t)v25);
      goto LABEL_51;
    }
  }
  uint64_t v25 = 0;
  unint64_t v26 = 0;
  unint64_t v85 = (*(unsigned __int8 *)(v10 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v10 + 80);
  unint64_t v75 = v21 + v85;
  unint64_t v89 = v10 + 16;
  uint64_t v91 = (uint64_t *)(v10 + 32);
  uint64_t v27 = MEMORY[0x263F8EE80];
  v73[2] = v5;
  v73[3] = v10 + 8;
  uint64_t v83 = v8;
  v73[1] = v10;
  uint64_t v77 = v21;
  while (v26 < *(void *)(v21 + 16))
  {
    uint64_t v28 = *(void *)(v10 + 72);
    unint64_t v82 = v26;
    uint64_t v86 = v28;
    uint64_t v88 = *(void *)(v10 + 16);
    OUTLINED_FUNCTION_18_3();
    v29();
    OUTLINED_FUNCTION_3_26(v22, 0);
    OUTLINED_FUNCTION_22_10(v22);
    if (v30) {
      goto LABEL_50;
    }
    uint64_t v90 = *v91;
    OUTLINED_FUNCTION_3();
    v31();
    uint64_t v92 = URL.lastPathComponent.getter();
    uint64_t v33 = v32;
    static _FileUtilities.readableFiles(at:type:)();
    if (v3)
    {
      swift_bridgeObjectRelease();
      OUTLINED_FUNCTION_25_0();
      v72();
      swift_bridgeObjectRelease();
      swift_bridgeObjectRelease();
      outlined consume of (@escaping @callee_guaranteed @Sendable (@in_guaranteed Event) -> ())?((uint64_t)v25);
      goto LABEL_51;
    }
    uint64_t v80 = 0;
    uint64_t v81 = v34;
    uint64_t v35 = *(void *)(v34 + 16);
    uint64_t v79 = v35;
    if (v35)
    {
      unint64_t v10 = v34 + v85;
      swift_bridgeObjectRetain();
      uint64_t v36 = v87;
      while (1)
      {
        OUTLINED_FUNCTION_18_3();
        v37();
        OUTLINED_FUNCTION_3_26(v36, 0);
        OUTLINED_FUNCTION_22_10(v36);
        if (v30)
        {
          swift_bridgeObjectRelease_n();
          goto LABEL_35;
        }
        OUTLINED_FUNCTION_3();
        v38();
        swift_bridgeObjectRetain();
        outlined consume of (@escaping @callee_guaranteed @Sendable (@in_guaranteed Event) -> ())?((uint64_t)v25);
        swift_isUniquelyReferenced_nonNull_native();
        OUTLINED_FUNCTION_12_9();
        OUTLINED_FUNCTION_20_9();
        if (v41) {
          break;
        }
        unint64_t v42 = v39;
        char v43 = v40;
        __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, [URL]>);
        if (OUTLINED_FUNCTION_16_11())
        {
          unint64_t v44 = specialized __RawDictionaryStorage.find<A>(_:)(v92, v33);
          if ((v43 & 1) != (v45 & 1)) {
            goto LABEL_57;
          }
          unint64_t v42 = v44;
        }
        swift_bridgeObjectRelease();
        if ((v43 & 1) == 0)
        {
          OUTLINED_FUNCTION_14_9(v27 + 8 * (v42 >> 6));
          uint64_t v47 = (void *)(v46 + 16 * v42);
          void *v47 = v92;
          v47[1] = v33;
          *(void *)(*(void *)(v27 + 56) + 8 * v42) = MEMORY[0x263F8EE78];
          uint64_t v48 = *(void *)(v27 + 16);
          uint64_t v49 = v48 + 1;
          BOOL v50 = __OFADD__(v48, 1);
          swift_bridgeObjectRetain();
          if (v50) {
            goto LABEL_53;
          }
          *(void *)(v27 + 16) = v49;
        }
        swift_bridgeObjectRetain();
        uint64_t v51 = *(void *)(v27 + 56);
        swift_bridgeObjectRelease();
        uint64_t v52 = *(void *)(v51 + 8 * v42);
        char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native();
        *(void *)(v51 + 8 * v42) = v52;
        if ((isUniquelyReferenced_nonNull_native & 1) == 0)
        {
          specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
          uint64_t v52 = v56;
          *(void *)(v51 + 8 * v42) = v56;
        }
        unint64_t v3 = *(void *)(v52 + 16);
        if (v3 >= *(void *)(v52 + 24) >> 1)
        {
          specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
          uint64_t v52 = v57;
          *(void *)(v51 + 8 * v42) = v57;
        }
        *(void *)(v52 + 16) = v3 + 1;
        uint64_t v54 = v86;
        OUTLINED_FUNCTION_3();
        v55();
        swift_bridgeObjectRelease();
        v10 += v54;
        uint64_t v25 = specialized thunk for @callee_guaranteed () -> (@owned [URL]);
        --v35;
        uint64_t v36 = v87;
        if (!v35) {
          goto LABEL_30;
        }
      }
      __break(1u);
LABEL_53:
      __break(1u);
      break;
    }
    swift_bridgeObjectRetain();
    uint64_t v36 = v87;
LABEL_30:
    OUTLINED_FUNCTION_3_26(v36, 1);
    swift_bridgeObjectRelease_n();
    if (v79
      || *(void *)(v27 + 16)
      && (swift_bridgeObjectRetain(), OUTLINED_FUNCTION_12_9(), char v59 = v58, swift_bridgeObjectRelease(), (v59 & 1) != 0))
    {
LABEL_35:
      OUTLINED_FUNCTION_18_9();
      OUTLINED_FUNCTION_25_0();
      v60();
      swift_bridgeObjectRelease();
      OUTLINED_FUNCTION_17_10();
    }
    else
    {
      swift_isUniquelyReferenced_nonNull_native();
      OUTLINED_FUNCTION_12_9();
      OUTLINED_FUNCTION_20_9();
      if (v41) {
        goto LABEL_55;
      }
      unint64_t v10 = v61;
      char v63 = v62;
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, [URL]>);
      if (OUTLINED_FUNCTION_16_11())
      {
        unint64_t v64 = specialized __RawDictionaryStorage.find<A>(_:)(v92, v33);
        if ((v63 & 1) != (v65 & 1)) {
          goto LABEL_57;
        }
        unint64_t v10 = v64;
      }
      if (v63)
      {
        uint64_t v66 = *(void *)(v27 + 56);
        swift_bridgeObjectRelease();
        *(void *)(v66 + 8 * v10) = MEMORY[0x263F8EE78];
      }
      else
      {
        OUTLINED_FUNCTION_14_9(v27 + 8 * (v10 >> 6));
        uint64_t v68 = (void *)(v67 + 16 * v10);
        *uint64_t v68 = v92;
        v68[1] = v33;
        *(void *)(*(void *)(v27 + 56) + 8 * v10) = MEMORY[0x263F8EE78];
        uint64_t v69 = *(void *)(v27 + 16);
        BOOL v41 = __OFADD__(v69, 1);
        uint64_t v70 = v69 + 1;
        if (v41) {
          goto LABEL_56;
        }
        *(void *)(v27 + 16) = v70;
        swift_bridgeObjectRetain();
      }
      swift_bridgeObjectRelease();
      swift_bridgeObjectRelease();
      OUTLINED_FUNCTION_18_9();
      OUTLINED_FUNCTION_25_0();
      v71();
      OUTLINED_FUNCTION_17_10();
    }
    unint64_t v26 = v82 + 1;
    uint64_t v21 = v77;
    uint64_t v22 = v78;
    if (v82 + 1 == v74) {
      goto LABEL_49;
    }
  }
  __break(1u);
LABEL_55:
  __break(1u);
LABEL_56:
  __break(1u);
LABEL_57:
  KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)();
  __break(1u);
}

void static _FileUtilities.getReadableSubdirectoriesOfDirectory(at:)()
{
  OUTLINED_FUNCTION_9_0();
  id v85 = v0;
  v87[7] = *(id *)MEMORY[0x263EF8340];
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URLResourceValues?);
  uint64_t v4 = OUTLINED_FUNCTION_17(v3);
  MEMORY[0x270FA5388](v4);
  OUTLINED_FUNCTION_33();
  uint64_t v67 = v5 - v6;
  uint64_t v8 = MEMORY[0x270FA5388](v7);
  uint64_t v83 = (uint64_t)&v65 - v9;
  MEMORY[0x270FA5388](v8);
  uint64_t v11 = (char *)&v65 - v10;
  uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  uint64_t v13 = OUTLINED_FUNCTION_17(v12);
  MEMORY[0x270FA5388](v13);
  OUTLINED_FUNCTION_41_0();
  uint64_t v14 = type metadata accessor for URL();
  OUTLINED_FUNCTION_0();
  uint64_t v81 = v15;
  MEMORY[0x270FA5388](v16);
  OUTLINED_FUNCTION_4_21();
  MEMORY[0x270FA5388](v17);
  uint64_t v84 = (char *)&v65 - v18;
  id v19 = objc_msgSend(self, sel_defaultManager);
  URL._bridgeToObjectiveC()(v20);
  uint64_t v22 = v21;
  uint64_t v80 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<NSURLResourceKey>);
  uint64_t v23 = swift_allocObject();
  long long v79 = xmmword_2272CB4D0;
  *(_OWORD *)(v23 + 16) = xmmword_2272CB4D0;
  unint64_t v24 = (void *)*MEMORY[0x263EFF6A8];
  uint64_t v25 = (void *)*MEMORY[0x263EFF6E0];
  *(void *)(v23 + 32) = *MEMORY[0x263EFF6A8];
  *(void *)(v23 + 40) = v25;
  v87[0] = 0;
  id v78 = v24;
  id v77 = v25;
  id v26 = outlined bridged method (mnbnnnn) of @objc NSFileManager.contentsOfDirectory(at:includingPropertiesForKeys:options:)((uint64_t)v22, v23, 0, (uint64_t)v87, v19);

  id v27 = v87[0];
  if (v26)
  {
    uint64_t v28 = static Array._unconditionallyBridgeFromObjectiveC(_:)();
    id v29 = v27;

    v87[0] = (id)MEMORY[0x263F8EE78];
    uint64_t v75 = *(void *)(v28 + 16);
    if (v75)
    {
      uint64_t v65 = v2;
      unint64_t v30 = 0;
      uint64_t v74 = v81 + 16;
      uint64_t v76 = (uint64_t *)(v81 + 32);
      uint64_t v69 = v81 + 8;
      uint64_t v73 = v1;
      unint64_t v82 = v11;
      uint64_t v72 = v14;
      uint64_t v71 = v28;
      while (1)
      {
        if (v30 >= *(void *)(v28 + 16)) {
          __break(1u);
        }
        unint64_t v31 = (*(unsigned __int8 *)(v81 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v81 + 80);
        (*(void (**)(uint64_t, unint64_t, uint64_t))(v81 + 16))(v1, v28 + v31 + *(void *)(v81 + 72) * v30, v14);
        OUTLINED_FUNCTION_3_26(v1, 0);
        OUTLINED_FUNCTION_22_10(v1);
        if (v32) {
          goto LABEL_26;
        }
        unint64_t v68 = v31;
        uint64_t v70 = *v76;
        OUTLINED_FUNCTION_3();
        v34(v33);
        uint64_t inited = swift_initStackObject();
        *(_OWORD *)(inited + 16) = v79;
        uint64_t v37 = v77;
        uint64_t v36 = v78;
        *(void *)(inited + 32) = v78;
        *(void *)(inited + 40) = v37;
        type metadata accessor for NSURLResourceKey(0);
        lazy protocol witness table accessor for type NSURLResourceKey and conformance NSURLResourceKey();
        id v38 = v36;
        id v39 = v37;
        v86[1] = (id)Set.init(minimumCapacity:)();
        specialized Set._Variant.insert(_:)(v86, *(id *)(inited + 32));

        specialized Set._Variant.insert(_:)(v86, *(id *)(inited + 40));
        swift_setDeallocating();
        specialized _ContiguousArrayStorage.__deallocating_deinit();
        id v40 = v85;
        URL.resourceValues(forKeys:)();
        id v85 = v40;
        if (v40)
        {

          swift_bridgeObjectRelease();
          uint64_t v41 = type metadata accessor for URLResourceValues();
          __swift_storeEnumTagSinglePayload((uint64_t)v11, 1, 1, v41);
          id v85 = 0;
        }
        else
        {
          swift_bridgeObjectRelease();
          uint64_t v41 = type metadata accessor for URLResourceValues();
          __swift_storeEnumTagSinglePayload((uint64_t)v11, 0, 1, v41);
        }
        uint64_t v42 = v83;
        outlined init with copy of URLResourceValues?((uint64_t)v11, v83);
        type metadata accessor for URLResourceValues();
        int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v42, 1, v41);
        uint64_t v44 = v42;
        uint64_t v45 = (uint64_t)v11;
        if (EnumTagSinglePayload == 1) {
          break;
        }
        char v46 = URLResourceValues.isDirectory.getter();
        uint64_t v47 = *(void (**)(uint64_t))(*(void *)(v41 - 8) + 8);
        uint64_t v48 = OUTLINED_FUNCTION_21_10();
        v47(v48);
        uint64_t v45 = (uint64_t)v11;
        if (v46 == 2) {
          goto LABEL_12;
        }
        uint64_t v51 = (uint64_t)v82;
        uint64_t v45 = v67;
        outlined init with copy of URLResourceValues?((uint64_t)v82, v67);
        int v52 = __swift_getEnumTagSinglePayload(v45, 1, v41);
        uint64_t v44 = v51;
        if (v52 == 1) {
          break;
        }
        int v66 = URLResourceValues.isReadable.getter();
        int v53 = v66;
        outlined destroy of UTType?(v51, &demangling cache variable for type metadata for URLResourceValues?);
        uint64_t v54 = OUTLINED_FUNCTION_21_10();
        v47(v54);
        if (v53 != 2 && (v46 & 1) != 0 && (v66 & 1) != 0)
        {
          uint64_t v14 = v72;
          OUTLINED_FUNCTION_3();
          v56(v55);
          uint64_t v57 = v87[0];
          char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native();
          uint64_t v11 = v82;
          uint64_t v28 = v71;
          if ((isUniquelyReferenced_nonNull_native & 1) == 0)
          {
            specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v57[2] + 1, 1);
            uint64_t v57 = v87[0];
          }
          unint64_t v60 = v57[2];
          unint64_t v59 = v57[3];
          if (v60 >= v59 >> 1)
          {
            specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v59 > 1, v60 + 1, 1);
            uint64_t v57 = v87[0];
          }
          v57[2] = v60 + 1;
          OUTLINED_FUNCTION_3();
          v62(v61);
          v87[0] = v57;
          uint64_t v1 = v73;
          goto LABEL_14;
        }
LABEL_13:
        uint64_t v14 = v72;
        OUTLINED_FUNCTION_25_0();
        v50(v49);
        uint64_t v1 = v73;
        uint64_t v11 = v82;
        uint64_t v28 = v71;
LABEL_14:
        if (v75 == ++v30) {
          goto LABEL_25;
        }
      }
      outlined destroy of UTType?(v44, &demangling cache variable for type metadata for URLResourceValues?);
LABEL_12:
      outlined destroy of UTType?(v45, &demangling cache variable for type metadata for URLResourceValues?);
      goto LABEL_13;
    }
LABEL_25:
    OUTLINED_FUNCTION_3_26(v1, 1);
LABEL_26:
    swift_bridgeObjectRelease();
    outlined destroy of UTType?(v1, &demangling cache variable for type metadata for URL?);
  }
  else
  {
    id v63 = v87[0];
    unint64_t v64 = (void *)_convertNSErrorToError(_:)();

    id v85 = v64;
    swift_willThrow();
  }
  OUTLINED_FUNCTION_8_1();
}

void static _FileUtilities.readableFiles(at:type:)()
{
  OUTLINED_FUNCTION_9_0();
  uint64_t v3 = v2;
  uint64_t v4 = type metadata accessor for URL();
  OUTLINED_FUNCTION_0();
  uint64_t v6 = v5;
  MEMORY[0x270FA5388](v7);
  OUTLINED_FUNCTION_4_21();
  MEMORY[0x270FA5388](v8);
  OUTLINED_FUNCTION_15_11();
  uint64_t v9 = static _FileUtilities.getNonHiddenFilesInDirectory(at:)();
  if (!v0)
  {
    uint64_t v10 = v9;
    uint64_t v32 = v1;
    uint64_t v11 = v9[2];
    if (v11)
    {
      v25[6] = 0;
      uint64_t v26 = v3;
      uint64_t v33 = MEMORY[0x263F8EE78];
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v11, 0);
      uint64_t v13 = *(void *)(v6 + 16);
      uint64_t v12 = v6 + 16;
      unint64_t v14 = (*(unsigned __int8 *)(v12 + 64) + 32) & ~(unint64_t)*(unsigned __int8 *)(v12 + 64);
      v25[5] = v10;
      unint64_t v29 = v14;
      uint64_t v30 = v13;
      uint64_t v15 = (char *)v10 + v14;
      uint64_t v16 = *(void *)(v12 + 56);
      uint64_t v27 = v12 - 8;
      uint64_t v28 = v16;
      uint64_t v31 = v12;
      uint64_t v17 = (void (**)(uint64_t, uint64_t, uint64_t))(v12 + 16);
      uint64_t v18 = v16;
      do
      {
        OUTLINED_FUNCTION_18_3();
        v19();
        URL.resolvingSymlinksInPath()();
        OUTLINED_FUNCTION_25_0();
        v20();
        uint64_t v21 = v33;
        if ((swift_isUniquelyReferenced_nonNull_native() & 1) == 0)
        {
          specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, *(void *)(v33 + 16) + 1, 1);
          uint64_t v21 = v33;
        }
        unint64_t v23 = *(void *)(v21 + 16);
        unint64_t v22 = *(void *)(v21 + 24);
        if (v23 >= v22 >> 1)
        {
          specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v22 > 1, v23 + 1, 1);
          uint64_t v21 = v33;
        }
        *(void *)(v21 + 16) = v23 + 1;
        (*v17)(v21 + v29 + v23 * v18, v32, v4);
        uint64_t v33 = v21;
        v15 += v18;
        --v11;
      }
      while (v11);
      uint64_t v24 = swift_bridgeObjectRelease();
      uint64_t v3 = v26;
    }
    else
    {
      uint64_t v24 = swift_bridgeObjectRelease();
      uint64_t v21 = MEMORY[0x263F8EE78];
    }
    MEMORY[0x270FA5388](v24);
    v25[2] = v3;
    specialized _ArrayProtocol.filter(_:)((uint64_t (*)(char *))partial apply for closure #2 in static _FileUtilities.readableFiles(at:type:), (uint64_t)v25, v21);
  }
  OUTLINED_FUNCTION_8_1();
}

void specialized thunk for @callee_guaranteed () -> (@owned [URL])(void *a1@<X8>)
{
  *a1 = MEMORY[0x263F8EE78];
}

void static _FileUtilities.collectFilesLabeledByFileName(at:type:)()
{
  OUTLINED_FUNCTION_9_0();
  uint64_t v1 = type metadata accessor for URL();
  OUTLINED_FUNCTION_0();
  uint64_t v3 = v2;
  MEMORY[0x270FA5388](v4);
  OUTLINED_FUNCTION_33();
  uint64_t v7 = v5 - v6;
  MEMORY[0x270FA5388](v8);
  uint64_t v10 = (char *)v62 - v9;
  uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  uint64_t v12 = OUTLINED_FUNCTION_17(v11);
  MEMORY[0x270FA5388](v12);
  unint64_t v14 = (char *)v62 - ((v13 + 15) & 0xFFFFFFFFFFFFFFF0);
  static _FileUtilities.readableFiles(at:type:)();
  if (v0)
  {
    swift_bridgeObjectRelease();
  }
  else
  {
    uint64_t v70 = v10;
    v62[1] = v15;
    v62[2] = 0;
    uint64_t v16 = *(void *)(v15 + 16);
    if (v16)
    {
      uint64_t v71 = 0;
      uint64_t v18 = *(void *)(v3 + 16);
      uint64_t v17 = v3 + 16;
      unint64_t v63 = (*(unsigned __int8 *)(v17 + 64) + 32) & ~(unint64_t)*(unsigned __int8 *)(v17 + 64);
      uint64_t v19 = v15 + v63;
      uint64_t v20 = *(void *)(v17 + 56);
      uint64_t v74 = (uint64_t *)(v17 + 16);
      uint64_t v75 = v18;
      uint64_t v68 = v17 - 8;
      uint64_t v72 = MEMORY[0x263F8EE80];
      uint64_t v65 = v17;
      uint64_t v66 = v1;
      unint64_t v64 = v14;
      uint64_t v69 = v20;
      while (1)
      {
        OUTLINED_FUNCTION_13_11();
        v21();
        __swift_storeEnumTagSinglePayload((uint64_t)v14, 0, 1, v1);
        if (__swift_getEnumTagSinglePayload((uint64_t)v14, 1, v1) == 1) {
          break;
        }
        uint64_t v73 = *v74;
        OUTLINED_FUNCTION_3();
        v22();
        uint64_t v23 = URL.lastPathComponent.getter();
        unint64_t v25 = specialized Collection<>.firstIndex(of:)(46, 0xE100000000000000, v23, v24);
        if ((v26 & 1) != 0 || v25 < 0x4000)
        {
          OUTLINED_FUNCTION_25_0();
          v61();
          swift_bridgeObjectRelease();
          uint64_t v58 = v69;
        }
        else
        {
          uint64_t v67 = v16;
          uint64_t v27 = String.subscript.getter();
          uint64_t v29 = v28;
          uint64_t v31 = v30;
          uint64_t v32 = v7;
          uint64_t v34 = v33;
          swift_bridgeObjectRelease();
          uint64_t v35 = MEMORY[0x22A674BA0](v27, v29, v31, v34);
          uint64_t v37 = v36;
          swift_bridgeObjectRelease();
          uint64_t v38 = v32;
          OUTLINED_FUNCTION_13_11();
          v39();
          outlined consume of (@escaping @callee_guaranteed @Sendable (@in_guaranteed Event) -> ())?((uint64_t)v71);
          uint64_t v40 = v72;
          char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native();
          uint64_t v76 = v40;
          uint64_t v42 = v35;
          uint64_t v43 = v35;
          uint64_t v44 = v37;
          unint64_t v45 = specialized __RawDictionaryStorage.find<A>(_:)(v43, v37);
          uint64_t v47 = *(void *)(v40 + 16);
          BOOL v48 = (v46 & 1) == 0;
          Swift::Int v49 = v47 + v48;
          if (__OFADD__(v47, v48))
          {
            __break(1u);
LABEL_23:
            KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)();
            __break(1u);
            return;
          }
          unint64_t v50 = v45;
          char v51 = v46;
          __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, [URL]>);
          Swift::Bool v52 = _NativeDictionary.ensureUnique(isUnique:capacity:)(isUniquelyReferenced_nonNull_native, v49);
          uint64_t v7 = v38;
          unint64_t v14 = v64;
          if (v52)
          {
            unint64_t v53 = specialized __RawDictionaryStorage.find<A>(_:)(v42, v44);
            if ((v51 & 1) != (v54 & 1)) {
              goto LABEL_23;
            }
            unint64_t v50 = v53;
          }
          swift_bridgeObjectRelease();
          swift_bridgeObjectRetain();
          if ((v51 & 1) == 0)
          {
            specialized _NativeDictionary._insert(at:key:value:)(v50, v42, v44, MEMORY[0x263F8EE78], v40);
            swift_bridgeObjectRetain();
          }
          uint64_t v55 = *(void *)(v40 + 56);
          uint64_t v72 = v76;
          swift_bridgeObjectRelease();
          uint64_t v56 = v55 + 8 * v50;
          specialized Array._makeUniqueAndReserveCapacityIfNotUnique()();
          uint64_t v57 = *(void *)(*(void *)v56 + 16);
          specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(v57);
          *(void *)(*(void *)v56 + 16) = v57 + 1;
          uint64_t v58 = v69;
          uint64_t v1 = v66;
          OUTLINED_FUNCTION_3();
          v59();
          swift_bridgeObjectRelease();
          OUTLINED_FUNCTION_25_0();
          v60();
          uint64_t v71 = specialized thunk for @callee_guaranteed () -> (@owned [URL]);
          uint64_t v16 = v67;
        }
        v19 += v58;
        if (!--v16) {
          goto LABEL_19;
        }
      }
    }
    else
    {
      uint64_t v71 = 0;
      uint64_t v72 = MEMORY[0x263F8EE80];
LABEL_19:
      __swift_storeEnumTagSinglePayload((uint64_t)v14, 1, 1, v1);
    }
    swift_bridgeObjectRelease();
    outlined consume of (@escaping @callee_guaranteed @Sendable (@in_guaranteed Event) -> ())?((uint64_t)v71);
  }
  OUTLINED_FUNCTION_8_1();
}

void *static _FileUtilities.getNonHiddenFilesInDirectory(at:)()
{
  v9[1] = *(id *)MEMORY[0x263EF8340];
  id v0 = objc_msgSend(self, sel_defaultManager);
  URL._bridgeToObjectiveC()(v1);
  uint64_t v3 = v2;
  v9[0] = 0;
  id v4 = objc_msgSend(v0, sel_contentsOfDirectoryAtURL_includingPropertiesForKeys_options_error_, v2, 0, 4, v9);

  id v5 = v9[0];
  if (v4)
  {
    type metadata accessor for URL();
    uint64_t v3 = (void *)static Array._unconditionallyBridgeFromObjectiveC(_:)();
    id v6 = v5;
  }
  else
  {
    id v7 = v9[0];
    _convertNSErrorToError(_:)();

    swift_willThrow();
  }
  return v3;
}

id outlined bridged method (mnbnnnn) of @objc NSFileManager.contentsOfDirectory(at:includingPropertiesForKeys:options:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, void *a5)
{
  type metadata accessor for NSURLResourceKey(0);
  Class isa = Array._bridgeToObjectiveC()().super.isa;
  swift_bridgeObjectRelease();
  id v10 = objc_msgSend(a5, sel_contentsOfDirectoryAtURL_includingPropertiesForKeys_options_error_, a1, isa, a3, a4);

  return v10;
}

unint64_t lazy protocol witness table accessor for type NSURLResourceKey and conformance NSURLResourceKey()
{
  unint64_t result = lazy protocol witness table cache variable for type NSURLResourceKey and conformance NSURLResourceKey;
  if (!lazy protocol witness table cache variable for type NSURLResourceKey and conformance NSURLResourceKey)
  {
    type metadata accessor for NSURLResourceKey(255);
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type NSURLResourceKey and conformance NSURLResourceKey);
  }
  return result;
}

uint64_t outlined init with copy of URLResourceValues?(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URLResourceValues?);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 16))(a2, a1, v4);
  return a2;
}

uint64_t outlined destroy of UTType?(uint64_t a1, uint64_t *a2)
{
  __swift_instantiateConcreteTypeFromMangledName(a2);
  OUTLINED_FUNCTION_25_0();
  v3();
  return a1;
}

unint64_t partial apply for closure #2 in static _FileUtilities.readableFiles(at:type:)()
{
  return (unint64_t)static _FileUtilities.isReadableFile(at:of:)() & 1;
}

uint64_t OUTLINED_FUNCTION_3_26(uint64_t a1, uint64_t a2)
{
  return __swift_storeEnumTagSinglePayload(a1, a2, 1, v2);
}

unint64_t OUTLINED_FUNCTION_12_9()
{
  uint64_t v3 = *(void *)(v1 - 96);
  return specialized __RawDictionaryStorage.find<A>(_:)(v3, v0);
}

void OUTLINED_FUNCTION_14_9(uint64_t a1@<X8>)
{
  *(void *)(a1 + 64) |= v1;
}

uint64_t OUTLINED_FUNCTION_15_11()
{
  return v0;
}

BOOL OUTLINED_FUNCTION_16_11()
{
  return _NativeDictionary.ensureUnique(isUnique:capacity:)(v0, v1);
}

uint64_t OUTLINED_FUNCTION_18_9()
{
  return *(void *)(v0 - 224);
}

uint64_t OUTLINED_FUNCTION_19_10()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_21_10()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_22_10(uint64_t a1)
{
  return __swift_getEnumTagSinglePayload(a1, 1, v1);
}

void *initializeBufferWithCopyOfBuffer for AnyTreeClassifierModel(void *a1, void *a2, uint64_t a3)
{
  int v5 = *(_DWORD *)(*(void *)(a3 - 8) + 80);
  if ((v5 & 0x20000) != 0)
  {
    uint64_t v12 = *a2;
    *a1 = *a2;
    a1 = (void *)(v12 + ((v5 + 16) & ~(unint64_t)v5));
    swift_retain();
  }
  else
  {
    uint64_t v7 = a2[1];
    *a1 = *a2;
    a1[1] = v7;
    uint64_t v9 = a2 + 2;
    uint64_t v8 = a2[2];
    swift_bridgeObjectRetain();
    if (v8)
    {
      uint64_t v10 = a2[3];
      uint64_t v11 = a2[4];
      a1[2] = v8;
      a1[3] = v10;
      a1[4] = v11;
      swift_bridgeObjectRetain();
      swift_bridgeObjectRetain();
    }
    else
    {
      *((_OWORD *)a1 + 1) = *v9;
      a1[4] = a2[4];
    }
    uint64_t v13 = *(int *)(a3 + 24);
    unint64_t v14 = (char *)a1 + v13;
    uint64_t v15 = (char *)a2 + v13;
    uint64_t v16 = type metadata accessor for BaseTreeClassifierModel();
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v16 - 8) + 16))(v14, v15, v16);
    uint64_t v17 = *(int *)(a3 + 28);
    uint64_t v18 = (char *)a1 + v17;
    uint64_t v19 = (char *)a2 + v17;
    uint64_t v20 = *(void *)v19;
    LOBYTE(v19) = v19[8];
    *(void *)uint64_t v18 = v20;
    v18[8] = (char)v19;
    swift_bridgeObjectRetain();
  }
  return a1;
}

uint64_t destroy for AnyTreeClassifierModel(uint64_t a1, uint64_t a2)
{
  swift_bridgeObjectRelease();
  if (*(void *)(a1 + 16))
  {
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
  }
  uint64_t v4 = a1 + *(int *)(a2 + 24);
  uint64_t v5 = type metadata accessor for BaseTreeClassifierModel();
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v5 - 8) + 8))(v4, v5);

  return swift_bridgeObjectRelease();
}

void *initializeWithCopy for AnyTreeClassifierModel(void *a1, void *a2, uint64_t a3)
{
  uint64_t v6 = a2[1];
  *a1 = *a2;
  a1[1] = v6;
  uint64_t v8 = a2 + 2;
  uint64_t v7 = a2[2];
  swift_bridgeObjectRetain();
  if (v7)
  {
    uint64_t v9 = a2[3];
    uint64_t v10 = a2[4];
    a1[2] = v7;
    a1[3] = v9;
    a1[4] = v10;
    swift_bridgeObjectRetain();
    swift_bridgeObjectRetain();
  }
  else
  {
    *((_OWORD *)a1 + 1) = *(_OWORD *)v8;
    a1[4] = v8[2];
  }
  uint64_t v11 = *(int *)(a3 + 24);
  uint64_t v12 = (char *)a1 + v11;
  uint64_t v13 = (char *)a2 + v11;
  uint64_t v14 = type metadata accessor for BaseTreeClassifierModel();
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v14 - 8) + 16))(v12, v13, v14);
  uint64_t v15 = *(int *)(a3 + 28);
  uint64_t v16 = (char *)a1 + v15;
  uint64_t v17 = (char *)a2 + v15;
  uint64_t v18 = *(void *)v17;
  LOBYTE(v17) = v17[8];
  *(void *)uint64_t v16 = v18;
  v16[8] = (char)v17;
  swift_bridgeObjectRetain();
  return a1;
}

void *assignWithCopy for AnyTreeClassifierModel(void *a1, void *a2, uint64_t a3)
{
  *a1 = *a2;
  a1[1] = a2[1];
  swift_bridgeObjectRetain();
  swift_bridgeObjectRelease();
  uint64_t v6 = a1 + 2;
  uint64_t v8 = a2 + 2;
  uint64_t v7 = a2[2];
  if (a1[2])
  {
    if (v7)
    {
      a1[2] = v7;
      swift_bridgeObjectRetain();
      swift_bridgeObjectRelease();
      a1[3] = a2[3];
      a1[4] = a2[4];
      swift_bridgeObjectRetain();
      swift_bridgeObjectRelease();
    }
    else
    {
      outlined destroy of FeatureVectorizer<Float>.Transformer((uint64_t)(a1 + 2));
      uint64_t v9 = a2[4];
      *uint64_t v6 = *v8;
      a1[4] = v9;
    }
  }
  else if (v7)
  {
    a1[2] = v7;
    a1[3] = a2[3];
    a1[4] = a2[4];
    swift_bridgeObjectRetain();
    swift_bridgeObjectRetain();
  }
  else
  {
    long long v10 = *v8;
    a1[4] = a2[4];
    *uint64_t v6 = v10;
  }
  uint64_t v11 = *(int *)(a3 + 24);
  uint64_t v12 = (char *)a1 + v11;
  uint64_t v13 = (char *)a2 + v11;
  uint64_t v14 = type metadata accessor for BaseTreeClassifierModel();
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v14 - 8) + 24))(v12, v13, v14);
  uint64_t v15 = *(int *)(a3 + 28);
  uint64_t v16 = (char *)a1 + v15;
  uint64_t v17 = (char *)a2 + v15;
  uint64_t v18 = *(void *)v17;
  LOBYTE(v17) = v17[8];
  *(void *)uint64_t v16 = v18;
  v16[8] = (char)v17;
  swift_bridgeObjectRetain();
  swift_bridgeObjectRelease();
  return a1;
}

uint64_t initializeWithTake for AnyTreeClassifierModel(uint64_t a1, uint64_t a2, uint64_t a3)
{
  long long v6 = *(_OWORD *)(a2 + 16);
  *(_OWORD *)a1 = *(_OWORD *)a2;
  *(_OWORD *)(a1 + 16) = v6;
  *(void *)(a1 + 32) = *(void *)(a2 + 32);
  uint64_t v7 = *(int *)(a3 + 24);
  uint64_t v8 = a1 + v7;
  uint64_t v9 = a2 + v7;
  uint64_t v10 = type metadata accessor for BaseTreeClassifierModel();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v10 - 8) + 32))(v8, v9, v10);
  uint64_t v11 = *(int *)(a3 + 28);
  uint64_t v12 = a1 + v11;
  uint64_t v13 = a2 + v11;
  *(void *)uint64_t v12 = *(void *)v13;
  *(unsigned char *)(v12 + 8) = *(unsigned char *)(v13 + 8);
  return a1;
}

void *assignWithTake for AnyTreeClassifierModel(void *a1, void *a2, uint64_t a3)
{
  uint64_t v6 = a2[1];
  *a1 = *a2;
  a1[1] = v6;
  swift_bridgeObjectRelease();
  uint64_t v7 = a2[2];
  if (!a1[2]) {
    goto LABEL_5;
  }
  if (!v7)
  {
    outlined destroy of FeatureVectorizer<Float>.Transformer((uint64_t)(a1 + 2));
LABEL_5:
    *((_OWORD *)a1 + 1) = *((_OWORD *)a2 + 1);
    a1[4] = a2[4];
    goto LABEL_6;
  }
  a1[2] = v7;
  swift_bridgeObjectRelease();
  uint64_t v8 = a2[4];
  a1[3] = a2[3];
  a1[4] = v8;
  swift_bridgeObjectRelease();
LABEL_6:
  uint64_t v9 = *(int *)(a3 + 24);
  uint64_t v10 = (char *)a1 + v9;
  uint64_t v11 = (char *)a2 + v9;
  uint64_t v12 = type metadata accessor for BaseTreeClassifierModel();
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 40))(v10, v11, v12);
  uint64_t v13 = *(int *)(a3 + 28);
  uint64_t v14 = (char *)a1 + v13;
  uint64_t v15 = (char *)a2 + v13;
  uint64_t v16 = *(void *)v15;
  LOBYTE(v15) = v15[8];
  *(void *)uint64_t v14 = v16;
  v14[8] = (char)v15;
  swift_bridgeObjectRelease();
  return a1;
}

uint64_t getEnumTagSinglePayload for AnyTreeClassifierModel(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return MEMORY[0x270FA0340](a1, a2, a3, sub_2270FDBB8);
}

uint64_t sub_2270FDBB8(uint64_t a1, uint64_t a2, uint64_t a3)
{
  if (a2 == 0x7FFFFFFF)
  {
    unint64_t v4 = *(void *)(a1 + 8);
    if (v4 >= 0xFFFFFFFF) {
      LODWORD(v4) = -1;
    }
    return (v4 + 1);
  }
  else
  {
    uint64_t v8 = type metadata accessor for BaseTreeClassifierModel();
    uint64_t v9 = a1 + *(int *)(a3 + 24);
    return __swift_getEnumTagSinglePayload(v9, a2, v8);
  }
}

uint64_t storeEnumTagSinglePayload for AnyTreeClassifierModel(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return MEMORY[0x270FA0580](a1, a2, a3, a4, sub_2270FDC54);
}

uint64_t sub_2270FDC54(uint64_t result, uint64_t a2, int a3, uint64_t a4)
{
  uint64_t v5 = result;
  if (a3 == 0x7FFFFFFF)
  {
    *(void *)(result + 8) = (a2 - 1);
  }
  else
  {
    uint64_t v7 = type metadata accessor for BaseTreeClassifierModel();
    uint64_t v8 = v5 + *(int *)(a4 + 24);
    return __swift_storeEnumTagSinglePayload(v8, a2, a2, v7);
  }
  return result;
}

uint64_t type metadata accessor for AnyTreeClassifierModel()
{
  uint64_t result = type metadata singleton initialization cache for AnyTreeClassifierModel;
  if (!type metadata singleton initialization cache for AnyTreeClassifierModel) {
    return swift_getSingletonMetadata();
  }
  return result;
}

uint64_t type metadata completion function for AnyTreeClassifierModel()
{
  uint64_t result = type metadata accessor for BaseTreeClassifierModel();
  if (v1 <= 0x3F)
  {
    swift_initStructMetadata();
    return 0;
  }
  return result;
}

uint64_t _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents26ClassificationDistributionVySSGG_SSSgs5NeverOTg503_s8d81ML22AnyTreeClassifierModelV14buildDataFramey07TabularH00hI0VSay0A12MLComponents26fG26VyxGGSHRzlFxSgAKcfu_SS_TG5s7KeyPathCyAiKGTf1cn_n(uint64_t a1)
{
  uint64_t v1 = *(void *)(a1 + 16);
  if (v1)
  {
    uint64_t v11 = MEMORY[0x263F8EE78];
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
    uint64_t v3 = v11;
    uint64_t v4 = *(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ClassificationDistribution<String>)
                   - 8);
    uint64_t v5 = a1 + ((*(unsigned __int8 *)(v4 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v4 + 80));
    uint64_t v6 = *(void *)(v4 + 72);
    do
    {
      swift_getAtKeyPath();
      long long v7 = v10;
      unint64_t v8 = *(void *)(v11 + 16);
      if (v8 >= *(void *)(v11 + 24) >> 1)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
        long long v7 = v10;
      }
      *(void *)(v11 + 16) = v8 + 1;
      *(_OWORD *)(v11 + 16 * v8 + 32) = v7;
      v5 += v6;
      --v1;
    }
    while (v1);
    swift_release();
  }
  else
  {
    swift_release();
    return MEMORY[0x263F8EE78];
  }
  return v3;
}

uint64_t _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents26ClassificationDistributionVySiGG_SiSgs5NeverOTg503_s8d81ML22AnyTreeClassifierModelV14buildDataFramey07TabularH00hI0VSay0A12MLComponents26fG26VyxGGSHRzlFxSgAKcfu_Si_TG5s7KeyPathCyAiKGTf1cn_n(uint64_t a1)
{
  uint64_t v1 = *(void *)(a1 + 16);
  if (v1)
  {
    uint64_t v13 = MEMORY[0x263F8EE78];
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v1, 0);
    uint64_t v3 = v13;
    uint64_t v4 = *(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ClassificationDistribution<Int>)
                   - 8);
    uint64_t v5 = a1 + ((*(unsigned __int8 *)(v4 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v4 + 80));
    uint64_t v6 = *(void *)(v4 + 72);
    do
    {
      swift_getAtKeyPath();
      unint64_t v8 = *(void *)(v13 + 16);
      unint64_t v7 = *(void *)(v13 + 24);
      if (v8 >= v7 >> 1) {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v7 > 1, v8 + 1, 1);
      }
      *(void *)(v13 + 16) = v8 + 1;
      uint64_t v9 = v13 + 16 * v8;
      *(void *)(v9 + 32) = v11;
      *(unsigned char *)(v9 + 40) = v12;
      v5 += v6;
      --v1;
    }
    while (v1);
    swift_release();
  }
  else
  {
    swift_release();
    return MEMORY[0x263F8EE78];
  }
  return v3;
}

void AnyTreeClassifierModel.applied(to:eventHandler:)(uint64_t a1@<X8>)
{
  uint64_t v3 = v1;
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DenseMatrix<Float>);
  OUTLINED_FUNCTION_0();
  uint64_t v7 = v6;
  MEMORY[0x270FA5388](v8);
  long long v10 = (char *)&v17 - ((v9 + 15) & 0xFFFFFFFFFFFFFFF0);
  if (*(void *)(v3 + 16))
  {
    specialized FeatureVectorizer.Transformer.vectorized(_:includingBias:)();
    if (!v2)
    {
      uint64_t v17 = a1;
      type metadata accessor for AnyTreeClassifierModel();
      uint64_t v11 = BaseTreeClassifierModel.applied(features:eventHandler:)();
      MEMORY[0x270FA5388](v11);
      if (v12)
      {
        _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents26ClassificationDistributionVySiGG_AHySSGs5NeverOTg5();
        swift_bridgeObjectRelease();
        uint64_t v13 = OUTLINED_FUNCTION_1_23();
        specialized AnyTreeClassifierModel.buildDataFrame<A>(_:)(v13, v14);
      }
      else
      {
        _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents26ClassificationDistributionVySiGG_AIs5NeverOTg5();
        swift_bridgeObjectRelease();
        uint64_t v15 = OUTLINED_FUNCTION_1_23();
        specialized AnyTreeClassifierModel.buildDataFrame<A>(_:)(v15, v16);
      }
      swift_bridgeObjectRelease();
      (*(void (**)(char *, uint64_t))(v7 + 8))(v10, v5);
    }
  }
  else
  {
    _assertionFailure(_:_:file:line:flags:)();
    __break(1u);
  }
}

uint64_t specialized AnyTreeClassifierModel.buildDataFrame<A>(_:)@<X0>(uint64_t a1@<X0>, uint64_t a2@<X8>)
{
  uint64_t v20 = a2;
  uint64_t v17 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Int>);
  uint64_t v19 = *(void *)(v17 - 8);
  MEMORY[0x270FA5388](v17);
  uint64_t v5 = (char *)&v15 - ((v4 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v16 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<ClassificationDistribution<Int>>);
  uint64_t v18 = *(void *)(v16 - 8);
  MEMORY[0x270FA5388](v16);
  uint64_t v7 = (char *)&v15 - ((v6 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v8 = v2[1];
  uint64_t v23 = *v2;
  uint64_t v24 = v8;
  swift_bridgeObjectRetain();
  v9._uint64_t countAndFlagsBits = 0x6C696261626F7250;
  v9._uint64_t object = (void *)0xEB00000000797469;
  String.append(_:)(v9);
  uint64_t v23 = a1;
  swift_bridgeObjectRetain();
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ClassificationDistribution<Int>);
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [ClassificationDistribution<Int>]);
  lazy protocol witness table accessor for type [ClassificationDistribution<Int>] and conformance [A](&lazy protocol witness table cache variable for type [ClassificationDistribution<Int>] and conformance [A], &demangling cache variable for type metadata for [ClassificationDistribution<Int>]);
  Column.init<A>(name:contents:)();
  uint64_t v21 = MEMORY[0x263F8D6C8];
  uint64_t v22 = MEMORY[0x263F8D6D8];
  swift_getKeyPath();
  swift_bridgeObjectRetain();
  swift_retain();
  uint64_t MLComponents26ClassificationDistributionVySiGG_SiSgs5NeverOTg503_s8d81ML22AnyTreeClassifierModelV14buildDataFramey07TabularH00hI0VSay0A12MLComponents26fG26VyxGGSHRzlFxSgAKcfu_Si_TG5s7KeyPathCyAiKGTf1cn_n = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents26ClassificationDistributionVySiGG_SiSgs5NeverOTg503_s8d81ML22AnyTreeClassifierModelV14buildDataFramey07TabularH00hI0VSay0A12MLComponents26fG26VyxGGSHRzlFxSgAKcfu_Si_TG5s7KeyPathCyAiKGTf1cn_n(a1);
  swift_release();
  uint64_t v23 = MLComponents26ClassificationDistributionVySiGG_SiSgs5NeverOTg503_s8d81ML22AnyTreeClassifierModelV14buildDataFramey07TabularH00hI0VSay0A12MLComponents26fG26VyxGGSHRzlFxSgAKcfu_Si_TG5s7KeyPathCyAiKGTf1cn_n;
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Int?]);
  lazy protocol witness table accessor for type [ClassificationDistribution<Int>] and conformance [A](&lazy protocol witness table cache variable for type [Int?] and conformance [A], &demangling cache variable for type metadata for [Int?]);
  Column.init<A>(name:contents:)();
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<AnyColumn>);
  type metadata accessor for AnyColumn();
  uint64_t v11 = swift_allocObject();
  *(_OWORD *)(v11 + 16) = xmmword_2272CB4D0;
  uint64_t v12 = v17;
  Column.eraseToAnyColumn()();
  uint64_t v13 = v16;
  Column.eraseToAnyColumn()();
  uint64_t v23 = v11;
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [AnyColumn]);
  lazy protocol witness table accessor for type [ClassificationDistribution<Int>] and conformance [A](&lazy protocol witness table cache variable for type [AnyColumn] and conformance [A], &demangling cache variable for type metadata for [AnyColumn]);
  DataFrame.init<A>(columns:)();
  (*(void (**)(char *, uint64_t))(v19 + 8))(v5, v12);
  return (*(uint64_t (**)(char *, uint64_t))(v18 + 8))(v7, v13);
}

{
  uint64_t *v2;
  uint64_t v4;
  char *v5;
  uint64_t v6;
  char *v7;
  uint64_t v8;
  Swift::String v9;
  uint64_t MLComponents26ClassificationDistributionVySSGG_SSSgs5NeverOTg503_s8d81ML22AnyTreeClassifierModelV14buildDataFramey07TabularH00hI0VSay0A12MLComponents26fG26VyxGGSHRzlFxSgAKcfu_SS_TG5s7KeyPathCyAiKGTf1cn_n;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t v24;

  uint64_t v20 = a2;
  uint64_t v17 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  uint64_t v19 = *(void *)(v17 - 8);
  MEMORY[0x270FA5388](v17);
  uint64_t v5 = (char *)&v15 - ((v4 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v16 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<ClassificationDistribution<String>>);
  uint64_t v18 = *(void *)(v16 - 8);
  MEMORY[0x270FA5388](v16);
  uint64_t v7 = (char *)&v15 - ((v6 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v8 = v2[1];
  uint64_t v23 = *v2;
  uint64_t v24 = v8;
  swift_bridgeObjectRetain();
  v9._uint64_t countAndFlagsBits = 0x6C696261626F7250;
  v9._uint64_t object = (void *)0xEB00000000797469;
  String.append(_:)(v9);
  uint64_t v23 = a1;
  swift_bridgeObjectRetain();
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ClassificationDistribution<String>);
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [ClassificationDistribution<String>]);
  lazy protocol witness table accessor for type [ClassificationDistribution<Int>] and conformance [A](&lazy protocol witness table cache variable for type [ClassificationDistribution<String>] and conformance [A], &demangling cache variable for type metadata for [ClassificationDistribution<String>]);
  Column.init<A>(name:contents:)();
  uint64_t v21 = MEMORY[0x263F8D310];
  uint64_t v22 = MEMORY[0x263F8D320];
  swift_getKeyPath();
  swift_bridgeObjectRetain();
  swift_retain();
  MLComponents26ClassificationDistributionVySSGG_SSSgs5NeverOTg503_s8d81ML22AnyTreeClassifierModelV14buildDataFramey07TabularH00hI0VSay0A12MLComponents26fG26VyxGGSHRzlFxSgAKcfu_SS_TG5s7KeyPathCyAiKGTf1cn_n = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents26ClassificationDistributionVySSGG_SSSgs5NeverOTg503_s8d81ML22AnyTreeClassifierModelV14buildDataFramey07TabularH00hI0VSay0A12MLComponents26fG26VyxGGSHRzlFxSgAKcfu_SS_TG5s7KeyPathCyAiKGTf1cn_n(a1);
  swift_release();
  uint64_t v23 = MLComponents26ClassificationDistributionVySSGG_SSSgs5NeverOTg503_s8d81ML22AnyTreeClassifierModelV14buildDataFramey07TabularH00hI0VSay0A12MLComponents26fG26VyxGGSHRzlFxSgAKcfu_SS_TG5s7KeyPathCyAiKGTf1cn_n;
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String?]);
  lazy protocol witness table accessor for type [ClassificationDistribution<Int>] and conformance [A](&lazy protocol witness table cache variable for type [String?] and conformance [A], &demangling cache variable for type metadata for [String?]);
  Column.init<A>(name:contents:)();
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<AnyColumn>);
  type metadata accessor for AnyColumn();
  uint64_t v11 = swift_allocObject();
  *(_OWORD *)(v11 + 16) = xmmword_2272CB4D0;
  uint64_t v12 = v17;
  Column.eraseToAnyColumn()();
  uint64_t v13 = v16;
  Column.eraseToAnyColumn()();
  uint64_t v23 = v11;
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [AnyColumn]);
  lazy protocol witness table accessor for type [ClassificationDistribution<Int>] and conformance [A](&lazy protocol witness table cache variable for type [AnyColumn] and conformance [A], &demangling cache variable for type metadata for [AnyColumn]);
  DataFrame.init<A>(columns:)();
  (*(void (**)(char *, uint64_t))(v19 + 8))(v5, v12);
  return (*(uint64_t (**)(char *, uint64_t))(v18 + 8))(v7, v13);
}

uint64_t closure #1 in AnyTreeClassifierModel.applied(to:eventHandler:)()
{
  return ClassificationDistribution.map<A>(_:)();
}

uint64_t closure #1 in AnyTreeClassifierModel.convertDistribution(_:labels:)(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = *(void *)(a2 + 16);
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Classification<Int>);
  Classification.label.getter();
  if ((v4 & 0x8000000000000000) == 0 && v4 < v2)
  {
    Classification.label.getter();
    if ((v4 & 0x8000000000000000) == 0 && v4 < v2)
    {
      Classification.probability.getter();
      return Classification.init(label:probability:)();
    }
    __break(1u);
  }
  uint64_t result = _assertionFailure(_:_:file:line:flags:)();
  __break(1u);
  return result;
}

{
  uint64_t v2;
  uint64_t result;
  uint64_t v4;

  uint64_t v2 = *(void *)(a2 + 16);
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Classification<Int>);
  Classification.label.getter();
  if ((v4 & 0x8000000000000000) == 0 && v4 < v2)
  {
    Classification.label.getter();
    if ((v4 & 0x8000000000000000) == 0 && v4 < v2)
    {
      swift_bridgeObjectRetain();
      Classification.probability.getter();
      return Classification.init(label:probability:)();
    }
    __break(1u);
  }
  uint64_t result = _assertionFailure(_:_:file:line:flags:)();
  __break(1u);
  return result;
}

uint64_t key path getter for ClassificationDistribution.mostLikelyLabel : <A>ClassificationDistribution<A>()
{
  return ClassificationDistribution.mostLikelyLabel.getter();
}

void AnyTreeClassifierModel.computeMetrics(on:)(uint64_t a1@<X0>, uint64_t a2@<X8>)
{
  uint64_t v6 = type metadata accessor for AnyColumn();
  uint64_t v7 = MEMORY[0x270FA5388](v6 - 8);
  MEMORY[0x270FA5388](v7);
  uint64_t v8 = type metadata accessor for DataFrame();
  OUTLINED_FUNCTION_0();
  uint64_t v10 = v9;
  MEMORY[0x270FA5388](v11);
  uint64_t v13 = (char *)v16 - ((v12 + 15) & 0xFFFFFFFFFFFFFFF0);
  AnyTreeClassifierModel.applied(to:eventHandler:)((uint64_t)v13);
  if (!v3)
  {
    v16[1] = a1;
    v16[3] = a2;
    uint64_t v15 = *v2;
    uint64_t v14 = v2[1];
    MEMORY[0x22A672220](*v2, v14);
    MEMORY[0x22A672220](v15, v14);
    AnyClassificationMetrics.init(_:_:)();
    (*(void (**)(char *, uint64_t))(v10 + 8))(v13, v8);
  }
}

uint64_t protocol witness for Transformer.applied(to:eventHandler:) in conformance AnyTreeClassifierModel(uint64_t a1)
{
  AnyTreeClassifierModel.applied(to:eventHandler:)(a1);
  uint64_t v2 = *(uint64_t (**)(void))(v1 + 8);
  return protocol witness for SupervisedTabularEstimator.fitted(to:validateOn:eventHandler:) in conformance TreeRegressor(v2);
}

unint64_t lazy protocol witness table accessor for type AnyTreeClassifierModel and conformance AnyTreeClassifierModel()
{
  unint64_t result = lazy protocol witness table cache variable for type AnyTreeClassifierModel and conformance AnyTreeClassifierModel;
  if (!lazy protocol witness table cache variable for type AnyTreeClassifierModel and conformance AnyTreeClassifierModel)
  {
    type metadata accessor for AnyTreeClassifierModel();
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type AnyTreeClassifierModel and conformance AnyTreeClassifierModel);
  }
  return result;
}

uint64_t partial apply for closure #2 in AnyTreeClassifierModel.applied(to:eventHandler:)()
{
  return closure #1 in AnyTreeClassifierModel.applied(to:eventHandler:)();
}

uint64_t partial apply for closure #1 in AnyTreeClassifierModel.applied(to:eventHandler:)()
{
  return closure #1 in AnyTreeClassifierModel.applied(to:eventHandler:)();
}

uint64_t sub_2270FEFFC(uint64_t a1)
{
  return *(void *)(a1 + 8);
}

uint64_t sub_2270FF008()
{
  return 16;
}

__n128 sub_2270FF014(__n128 *a1, __n128 *a2)
{
  __n128 result = *a1;
  *a2 = *a1;
  return result;
}

uint64_t partial apply for closure #1 in AnyTreeClassifierModel.convertDistribution(_:labels:)(uint64_t a1)
{
  return closure #1 in AnyTreeClassifierModel.convertDistribution(_:labels:)(a1, *(void *)(v1 + 16));
}

{
  uint64_t v1;

  return closure #1 in AnyTreeClassifierModel.convertDistribution(_:labels:)(a1, *(void *)(v1 + 16));
}

uint64_t lazy protocol witness table accessor for type [ClassificationDistribution<Int>] and conformance [A](unint64_t *a1, uint64_t *a2)
{
  uint64_t result = *a1;
  if (!result)
  {
    __swift_instantiateConcreteTypeFromMangledNameAbstract(a2);
    uint64_t result = swift_getWitnessTable();
    atomic_store(result, a1);
  }
  return result;
}

uint64_t OUTLINED_FUNCTION_1_23()
{
  return v0;
}

uint64_t _UntypedColumn.__allocating_init<A>(_:)(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = OUTLINED_FUNCTION_70();
  _UntypedColumn.init<A>(_:)(a1, a2);
  return v4;
}

uint64_t _UntypedColumn.init<A>(_:)(uint64_t a1, uint64_t a2)
{
  OUTLINED_FUNCTION_0_15();
  uint64_t v8 = v7;
  MEMORY[0x270FA5388](v9);
  OUTLINED_FUNCTION_15();
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness();
  OUTLINED_FUNCTION_0_15();
  uint64_t v54 = v11;
  OUTLINED_FUNCTION_8_13();
  MEMORY[0x270FA5388](v12);
  uint64_t v13 = OUTLINED_FUNCTION_13_12();
  uint64_t v14 = MEMORY[0x22A676370](v13);
  if (!v14) {
    goto LABEL_40;
  }
  uint64_t v15 = v14;
  type metadata accessor for CMLSequence();
  uint64_t inited = swift_initStackObject();
  *(void *)(inited + 16) = v15;
  uint64_t v65 = inited;
  *(unsigned char *)(inited + 24) = 1;
  uint64_t v51 = a1;
  uint64_t v52 = v8;
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v8 + 16))(v2, a1, a2);
  dispatch thunk of Sequence.makeIterator()();
  uint64_t v53 = a2;
  uint64_t AssociatedConformanceWitness = swift_getAssociatedConformanceWitness();
  int v17 = 6;
  while (2)
  {
    uint64_t v18 = v4;
    uint64_t v19 = AssociatedTypeWitness;
    uint64_t v20 = dispatch thunk of IteratorProtocol.next()();
    uint64_t v29 = v57;
    uint64_t v28 = v58;
    char v30 = v59;
    if (v17 == 6)
    {
      switch((char)v59)
      {
        case 0:
          goto LABEL_7;
        case 1:
          goto LABEL_21;
        case 2:
          goto LABEL_16;
        case 3:
          goto LABEL_19;
        case 4:
          goto LABEL_14;
        case 5:
          goto LABEL_26;
        default:
          goto LABEL_10;
      }
    }
    switch((char)v59)
    {
      case 0:
        if (v17) {
          goto LABEL_30;
        }
LABEL_7:
        specialized handling<A, B>(_:_:)((uint64_t)v57, v21, v22, v23, v24, v25, v26, v27, v50, v51, v52, v53, v54, v55, AssociatedConformanceWitness, (uint64_t)v57, (uint64_t)v58, v59, v60,
          v61,
          v62,
          v63,
          v64,
          v65,
          v66,
          v67,
          v68,
          v69,
          v70,
          v71);
        if (v3) {
          goto LABEL_42;
        }
        uint64_t v32 = v31;
        if (!v31) {
          goto LABEL_39;
        }
        type metadata accessor for CMLFeatureValue();
        swift_allocObject();
        CMLFeatureValue.init(rawValue:ownsValue:)(v32, 1);
        OUTLINED_FUNCTION_12_10();
        int v17 = 0;
        goto LABEL_27;
      case 1:
        if (v17 != 1) {
          goto LABEL_30;
        }
LABEL_21:
        specialized handling<A, B>(_:_:)(v20, v21, v22, v23, v24, v25, v26, v27, v50, v51, v52, v53, v54, v55, AssociatedConformanceWitness, (uint64_t)v57, (uint64_t)v58, v59, v60,
          v61,
          v62,
          v63,
          v64,
          v65,
          v66,
          v67,
          v68,
          v69,
          v70,
          v71);
        if (v3) {
          goto LABEL_42;
        }
        uint64_t v37 = v36;
        if (!v36)
        {
          __break(1u);
LABEL_39:
          __break(1u);
LABEL_40:
          __break(1u);
LABEL_41:
          __break(1u);
LABEL_42:
          OUTLINED_FUNCTION_9_14();
          swift_unexpectedError();
          __break(1u);
          JUMPOUT(0x2270FF66CLL);
        }
        type metadata accessor for CMLFeatureValue();
        swift_allocObject();
        int v17 = 1;
        uint64_t v8 = CMLFeatureValue.init(rawValue:ownsValue:)(v37, 1);
        uint64_t v33 = v29;
        uint64_t v34 = v28;
        char v35 = v30;
        goto LABEL_24;
      case 2:
        if (v17 != 2) {
          goto LABEL_30;
        }
LABEL_16:
        type metadata accessor for CMLFeatureValue();
        outlined copy of MLDataValue(v57, v58, v59);
        swift_bridgeObjectRetain();
        CMLFeatureValue.__allocating_init(_:)();
        if (v3) {
          goto LABEL_42;
        }
        OUTLINED_FUNCTION_12_10();
        int v17 = 2;
        goto LABEL_27;
      case 3:
        if (v17 != 3) {
          goto LABEL_30;
        }
LABEL_19:
        uint64_t v8 = MLDataValue.SequenceType.featureValue.getter(v20);
        int v17 = 3;
        goto LABEL_27;
      case 4:
        if (v17 != 4) {
          goto LABEL_30;
        }
LABEL_14:
        uint64_t v8 = MLDataValue.DictionaryType.featureValue.getter();
        int v17 = 4;
        goto LABEL_27;
      case 5:
        if (v17 != 5)
        {
LABEL_30:
          lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
          OUTLINED_FUNCTION_85();
          OUTLINED_FUNCTION_1_24(v38, 0xD000000000000027);
          goto LABEL_31;
        }
LABEL_26:
        uint64_t v8 = MLDataValue.MultiArrayType.featureValue.getter(v20);
        int v17 = 5;
        goto LABEL_27;
      default:
LABEL_10:
        if (v17 == 6)
        {
          type metadata accessor for CMLFeatureValue();
          uint64_t v8 = CMLFeatureValue.__allocating_init()();
          uint64_t v33 = v57;
          uint64_t v34 = v58;
          char v35 = 6;
LABEL_24:
          outlined consume of MLDataValue?(v33, v34, v35);
LABEL_27:
          CMLSequence.append(_:)(v8);
          if (v3)
          {
            swift_release();
LABEL_31:
            swift_release();
            outlined consume of MLDataValue?(v29, v28, v30);
            OUTLINED_FUNCTION_25_0();
            v39();
            (*(void (**)(uint64_t, uint64_t))(v54 + 8))(v18, v19);
            goto LABEL_32;
          }
          swift_release();
          outlined consume of MLDataValue?(v29, v28, v30);
          uint64_t AssociatedTypeWitness = v19;
          uint64_t v4 = v18;
          continue;
        }
        OUTLINED_FUNCTION_25_0();
        v42();
        uint64_t v43 = specialized handling<A, B>(_:_:)(*(void *)(v65 + 16));
        if (v3)
        {
          swift_setDeallocating();
          CMLFeatureValue.deinit();
          swift_deallocClassInstance();
          uint64_t v44 = OUTLINED_FUNCTION_11_12();
          v45(v44);
LABEL_32:
          uint64_t v40 = v55;
          type metadata accessor for _UntypedColumn();
          swift_deallocPartialClassInstance();
        }
        else
        {
          uint64_t v46 = v43;
          if (!v43) {
            goto LABEL_41;
          }
          swift_setDeallocating();
          CMLFeatureValue.deinit();
          swift_deallocClassInstance();
          type metadata accessor for CMLColumn();
          uint64_t v47 = OUTLINED_FUNCTION_70();
          *(void *)(v47 + 16) = v46;
          uint64_t v48 = OUTLINED_FUNCTION_11_12();
          v49(v48);
          uint64_t v40 = v55;
          *(void *)(v55 + 16) = v47;
        }
        return v40;
    }
  }
}

uint64_t _UntypedColumn.__allocating_init<A>(_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v8 = OUTLINED_FUNCTION_70();
  _UntypedColumn.init<A>(_:)(a1, a2, a3, a4);
  return v8;
}

uint64_t _UntypedColumn.init<A>(_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v43 = a4;
  uint64_t v40 = a1;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness();
  OUTLINED_FUNCTION_0_15();
  uint64_t v45 = v10;
  OUTLINED_FUNCTION_8_13();
  MEMORY[0x270FA5388](v11);
  OUTLINED_FUNCTION_13_12();
  type metadata accessor for Optional();
  OUTLINED_FUNCTION_8_13();
  MEMORY[0x270FA5388](v12);
  uint64_t v14 = (char *)v37 - v13;
  OUTLINED_FUNCTION_0_15();
  uint64_t v39 = v15;
  MEMORY[0x270FA5388](v16);
  OUTLINED_FUNCTION_15();
  uint64_t AssociatedConformanceWitness = a3;
  swift_getAssociatedTypeWitness();
  OUTLINED_FUNCTION_0_15();
  v37[1] = v17;
  OUTLINED_FUNCTION_8_13();
  MEMORY[0x270FA5388](v18);
  uint64_t result = MEMORY[0x22A676370](0);
  if (result)
  {
    uint64_t v20 = result;
    type metadata accessor for CMLSequence();
    uint64_t inited = swift_initStackObject();
    *(void *)(inited + 16) = v20;
    uint64_t v44 = inited;
    *(unsigned char *)(inited + 24) = 1;
    (*(void (**)(uint64_t, uint64_t, uint64_t))(v39 + 16))(v4, v40, a2);
    dispatch thunk of Sequence.makeIterator()();
    v37[0] = a2;
    uint64_t AssociatedConformanceWitness = swift_getAssociatedConformanceWitness();
    dispatch thunk of IteratorProtocol.next()();
    if (__swift_getEnumTagSinglePayload((uint64_t)v14, 1, AssociatedTypeWitness) == 1)
    {
LABEL_6:
      OUTLINED_FUNCTION_16_12();
      OUTLINED_FUNCTION_25_0();
      v25();
      (*(void (**)(uint64_t *__return_ptr, uint64_t))(v43 + 8))(&v46, AssociatedTypeWitness);
      OUTLINED_FUNCTION_8_15();
      unint64_t v28 = v27 >> v26;
      type metadata accessor for CMLColumn();
      uint64_t v29 = CMLColumn.__allocating_init(_:type:)(v44, v28);
      if (!v5)
      {
        uint64_t v30 = v29;
        OUTLINED_FUNCTION_25_0();
        v31();
        uint64_t v32 = v38;
        *(void *)(v38 + 16) = v30;
        return v32;
      }
    }
    else
    {
      uint64_t v41 = *(void (**)(uint64_t, char *, uint64_t))(v45 + 32);
      v45 += 32;
      while (1)
      {
        v41(v6, v14, AssociatedTypeWitness);
        uint64_t v22 = MLDataValueConvertible.featureValue.getter(AssociatedTypeWitness, v43);
        CMLSequence.append(_:)(v22);
        if (v5) {
          break;
        }
        uint64_t v23 = OUTLINED_FUNCTION_10_12();
        v24(v23);
        swift_release();
        dispatch thunk of IteratorProtocol.next()();
        if (__swift_getEnumTagSinglePayload((uint64_t)v14, 1, AssociatedTypeWitness) == 1) {
          goto LABEL_6;
        }
      }
      swift_release();
      swift_release();
      OUTLINED_FUNCTION_25_0();
      v33();
      uint64_t v34 = OUTLINED_FUNCTION_10_12();
      v35(v34);
      OUTLINED_FUNCTION_16_12();
    }
    OUTLINED_FUNCTION_25_0();
    v36();
    uint64_t v32 = v38;
    type metadata accessor for _UntypedColumn();
    swift_deallocPartialClassInstance();
    return v32;
  }
  __break(1u);
  return result;
}

uint64_t _UntypedColumn.init(repeating:count:)(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = v2;
  uint64_t v5 = *(void **)a1;
  uint64_t v6 = *(void **)(a1 + 8);
  char v7 = *(unsigned char *)(a1 + 16);
  uint64_t v8 = type metadata accessor for CMLColumn();
  uint64_t v10 = MLDataValue.featureValue.getter(v8, v9);
  outlined consume of MLDataValue(v5, v6, v7);
  *(void *)(v3 + 16) = CMLColumn.__allocating_init(repeating:count:)(v10, a2);
  return v3;
}

uint64_t _UntypedColumn.__allocating_init<A>(repeating:count:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v8 = swift_allocObject();
  _UntypedColumn.init<A>(repeating:count:)(a1, a2, a3, a4);
  return v8;
}

uint64_t _UntypedColumn.init<A>(repeating:count:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v5 = v4;
  type metadata accessor for CMLColumn();
  uint64_t v9 = MLDataValueConvertible.featureValue.getter(a3, a4);
  uint64_t v10 = CMLColumn.__allocating_init(repeating:count:)(v9, a2);
  OUTLINED_FUNCTION_25_0();
  v11();
  *(void *)(v5 + 16) = v10;
  return v5;
}

uint64_t _UntypedColumn.init(_:)(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = v2;
  type metadata accessor for CMLColumn();
  if (__OFADD__(a2, 1))
  {
    __break(1u);
    OUTLINED_FUNCTION_4_22();
    uint64_t result = swift_unexpectedError();
    __break(1u);
  }
  else
  {
    *(void *)(v3 + 16) = CMLColumn.__allocating_init(_:)(a1, a2 + 1);
    return v3;
  }
  return result;
}

uint64_t _UntypedColumn.appending(contentsOf:)(uint64_t a1)
{
  uint64_t v4 = *(void *)(v1 + 16);
  int v5 = CMLColumn.type.getter();
  uint64_t v6 = *(void *)(a1 + 16);
  if (v5 == CMLColumn.type.getter())
  {
    type metadata accessor for CMLColumn();
    swift_retain();
    swift_retain();
    uint64_t result = CMLColumn.__allocating_init(concatenating:and:)(v4, v6);
    if (!v2)
    {
      uint64_t v8 = result;
      type metadata accessor for _UntypedColumn();
      uint64_t result = OUTLINED_FUNCTION_70();
      *(void *)(result + 16) = v8;
    }
  }
  else
  {
    lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    OUTLINED_FUNCTION_85();
    return OUTLINED_FUNCTION_1_24(v9, 0xD000000000000034);
  }
  return result;
}

void _UntypedColumn.type.getter(unsigned char *a1@<X8>)
{
  CMLColumn.type.getter();
  OUTLINED_FUNCTION_8_15();
  *a1 = v3 >> v2;
}

uint64_t static _UntypedColumn.performRightScalar(op:a:b:)(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = v2;
  char v5 = a1;
  OUTLINED_FUNCTION_17_11(a1, a2);
  if (v3 > 9)
  {
LABEL_6:
    lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    OUTLINED_FUNCTION_85();
    OUTLINED_FUNCTION_1_24(v8, 0xD000000000000017);
    return swift_release();
  }
  else
  {
    switch(v5)
    {
      case 1:
        uint64_t v9 = OUTLINED_FUNCTION_3_27();
        uint64_t v10 = specialized handling<A, B, C, D>(_:_:_:_:)(v9, "-");
        if (v2) {
          return swift_release();
        }
        uint64_t v4 = v10;
        if (v10) {
          goto LABEL_34;
        }
        __break(1u);
        goto LABEL_10;
      case 2:
LABEL_10:
        uint64_t v11 = OUTLINED_FUNCTION_3_27();
        uint64_t v12 = specialized handling<A, B, C, D>(_:_:_:_:)(v11, "/");
        if (v4) {
          return swift_release();
        }
        uint64_t v4 = v12;
        if (v12) {
          goto LABEL_34;
        }
        __break(1u);
LABEL_13:
        uint64_t v13 = OUTLINED_FUNCTION_3_27();
        uint64_t v14 = specialized handling<A, B, C, D>(_:_:_:_:)(v13, "*");
        if (v4) {
          return swift_release();
        }
        uint64_t v4 = v14;
        if (v14) {
          goto LABEL_34;
        }
        __break(1u);
LABEL_16:
        uint64_t v15 = OUTLINED_FUNCTION_3_27();
        uint64_t v16 = specialized handling<A, B, C, D>(_:_:_:_:)(v15, "==");
        if (v4) {
          return swift_release();
        }
        uint64_t v4 = v16;
        if (v16) {
          goto LABEL_34;
        }
        __break(1u);
LABEL_19:
        uint64_t v17 = OUTLINED_FUNCTION_3_27();
        uint64_t v18 = specialized handling<A, B, C, D>(_:_:_:_:)(v17, "!=");
        if (v4) {
          return swift_release();
        }
        uint64_t v4 = v18;
        if (v18) {
          goto LABEL_34;
        }
        __break(1u);
LABEL_22:
        uint64_t v19 = OUTLINED_FUNCTION_3_27();
        uint64_t v20 = specialized handling<A, B, C, D>(_:_:_:_:)(v19, "<");
        if (v4) {
          return swift_release();
        }
        uint64_t v4 = v20;
        if (v20) {
          goto LABEL_34;
        }
        __break(1u);
LABEL_25:
        uint64_t v21 = OUTLINED_FUNCTION_3_27();
        uint64_t v22 = specialized handling<A, B, C, D>(_:_:_:_:)(v21, ">");
        if (v4) {
          return swift_release();
        }
        uint64_t v4 = v22;
        if (v22) {
          goto LABEL_34;
        }
        __break(1u);
LABEL_28:
        uint64_t v23 = OUTLINED_FUNCTION_3_27();
        uint64_t v24 = specialized handling<A, B, C, D>(_:_:_:_:)(v23, "<=");
        if (v4) {
          return swift_release();
        }
        uint64_t v4 = v24;
        if (v24) {
          goto LABEL_34;
        }
        __break(1u);
LABEL_31:
        uint64_t v25 = OUTLINED_FUNCTION_3_27();
        uint64_t v26 = specialized handling<A, B, C, D>(_:_:_:_:)(v25, ">=");
        if (v4) {
          return swift_release();
        }
        uint64_t v4 = v26;
        if (!v26)
        {
          __break(1u);
          JUMPOUT(0x2271000C0);
        }
LABEL_34:
        swift_release();
        type metadata accessor for CMLColumn();
        uint64_t v28 = OUTLINED_FUNCTION_70();
        *(void *)(v28 + 16) = v4;
        type metadata accessor for _UntypedColumn();
        uint64_t result = OUTLINED_FUNCTION_70();
        *(void *)(result + 16) = v28;
        break;
      case 3:
        goto LABEL_13;
      case 4:
        goto LABEL_16;
      case 5:
        goto LABEL_19;
      case 6:
        goto LABEL_22;
      case 7:
        goto LABEL_25;
      case 8:
        goto LABEL_28;
      case 9:
        goto LABEL_31;
      default:
        uint64_t v6 = OUTLINED_FUNCTION_3_27();
        uint64_t v7 = specialized handling<A, B, C, D>(_:_:_:_:)(v6, "+");
        if (v2) {
          return swift_release();
        }
        uint64_t v4 = v7;
        if (v7) {
          goto LABEL_34;
        }
        __break(1u);
        goto LABEL_6;
    }
  }
  return result;
}

uint64_t static _UntypedColumn.performLeftScalar(op:a:b:)(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = v2;
  char v5 = a1;
  OUTLINED_FUNCTION_17_11(a1, a2);
  if (v3 > 9)
  {
LABEL_6:
    lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    OUTLINED_FUNCTION_85();
    OUTLINED_FUNCTION_1_24(v8, 0xD000000000000017);
    return swift_release();
  }
  else
  {
    switch(v5)
    {
      case 1:
        uint64_t v9 = OUTLINED_FUNCTION_2_25();
        uint64_t v10 = specialized handling<A, B, C, D>(_:_:_:_:)(v9, "-");
        if (v2) {
          return swift_release();
        }
        uint64_t v4 = v10;
        if (v10) {
          goto LABEL_34;
        }
        __break(1u);
        goto LABEL_10;
      case 2:
LABEL_10:
        uint64_t v11 = OUTLINED_FUNCTION_2_25();
        uint64_t v12 = specialized handling<A, B, C, D>(_:_:_:_:)(v11, "/");
        if (v4) {
          return swift_release();
        }
        uint64_t v4 = v12;
        if (v12) {
          goto LABEL_34;
        }
        __break(1u);
LABEL_13:
        uint64_t v13 = OUTLINED_FUNCTION_2_25();
        uint64_t v14 = specialized handling<A, B, C, D>(_:_:_:_:)(v13, "*");
        if (v4) {
          return swift_release();
        }
        uint64_t v4 = v14;
        if (v14) {
          goto LABEL_34;
        }
        __break(1u);
LABEL_16:
        uint64_t v15 = OUTLINED_FUNCTION_2_25();
        uint64_t v16 = specialized handling<A, B, C, D>(_:_:_:_:)(v15, "==");
        if (v4) {
          return swift_release();
        }
        uint64_t v4 = v16;
        if (v16) {
          goto LABEL_34;
        }
        __break(1u);
LABEL_19:
        uint64_t v17 = OUTLINED_FUNCTION_2_25();
        uint64_t v18 = specialized handling<A, B, C, D>(_:_:_:_:)(v17, "!=");
        if (v4) {
          return swift_release();
        }
        uint64_t v4 = v18;
        if (v18) {
          goto LABEL_34;
        }
        __break(1u);
LABEL_22:
        uint64_t v19 = OUTLINED_FUNCTION_2_25();
        uint64_t v20 = specialized handling<A, B, C, D>(_:_:_:_:)(v19, "<");
        if (v4) {
          return swift_release();
        }
        uint64_t v4 = v20;
        if (v20) {
          goto LABEL_34;
        }
        __break(1u);
LABEL_25:
        uint64_t v21 = OUTLINED_FUNCTION_2_25();
        uint64_t v22 = specialized handling<A, B, C, D>(_:_:_:_:)(v21, ">");
        if (v4) {
          return swift_release();
        }
        uint64_t v4 = v22;
        if (v22) {
          goto LABEL_34;
        }
        __break(1u);
LABEL_28:
        uint64_t v23 = OUTLINED_FUNCTION_2_25();
        uint64_t v24 = specialized handling<A, B, C, D>(_:_:_:_:)(v23, "<=");
        if (v4) {
          return swift_release();
        }
        uint64_t v4 = v24;
        if (v24) {
          goto LABEL_34;
        }
        __break(1u);
LABEL_31:
        uint64_t v25 = OUTLINED_FUNCTION_2_25();
        uint64_t v26 = specialized handling<A, B, C, D>(_:_:_:_:)(v25, ">=");
        if (v4) {
          return swift_release();
        }
        uint64_t v4 = v26;
        if (!v26)
        {
          __break(1u);
          JUMPOUT(0x22710035CLL);
        }
LABEL_34:
        swift_release();
        type metadata accessor for CMLColumn();
        uint64_t v28 = OUTLINED_FUNCTION_70();
        *(void *)(v28 + 16) = v4;
        type metadata accessor for _UntypedColumn();
        uint64_t result = OUTLINED_FUNCTION_70();
        *(void *)(result + 16) = v28;
        break;
      case 3:
        goto LABEL_13;
      case 4:
        goto LABEL_16;
      case 5:
        goto LABEL_19;
      case 6:
        goto LABEL_22;
      case 7:
        goto LABEL_25;
      case 8:
        goto LABEL_28;
      case 9:
        goto LABEL_31;
      default:
        uint64_t v6 = OUTLINED_FUNCTION_2_25();
        uint64_t v7 = specialized handling<A, B, C, D>(_:_:_:_:)(v6, "+");
        if (v2) {
          return swift_release();
        }
        uint64_t v4 = v7;
        if (v7) {
          goto LABEL_34;
        }
        __break(1u);
        goto LABEL_6;
    }
  }
  return result;
}

uint64_t _UntypedColumn.valueAtIndex(index:)@<X0>(uint64_t result@<X0>, uint64_t a2@<X8>)
{
  if (result < 0 || (v3 = result, uint64_t result = CMLColumn.size.getter(), result <= v3))
  {
    *(void *)a2 = 0;
    *(void *)(a2 + 8) = 0;
    *(unsigned char *)(a2 + 16) = 6;
  }
  else
  {
    CMLColumn.value(at:)(v3);
    return MLDataValue.init(_:)(v4, a2);
  }
  return result;
}

uint64_t _UntypedColumn.description.getter()
{
  _UntypedColumn.type.getter(v38);
  unint64_t v0 = 0xE300000000000000;
  uint64_t v1 = 7630409;
  switch(LOBYTE(v38[0]))
  {
    case 1:
      unint64_t v0 = 0xE600000000000000;
      uint64_t v1 = 0x656C62756F44;
      break;
    case 2:
      unint64_t v0 = 0xE600000000000000;
      uint64_t v1 = 0x676E69727453;
      break;
    case 3:
      unint64_t v0 = 0xE800000000000000;
      uint64_t v1 = 0x65636E6575716553;
      break;
    case 4:
      unint64_t v0 = 0xEA00000000007972;
      uint64_t v1 = 0x616E6F6974636944;
      break;
    case 5:
      uint64_t v1 = 0x72724169746C754DLL;
      unint64_t v0 = 0xEA00000000007961;
      break;
    case 6:
      unint64_t v0 = 0xE700000000000000;
      uint64_t v1 = OUTLINED_FUNCTION_15_12();
      break;
    default:
      break;
  }
  v36._uint64_t countAndFlagsBits = 0x70795465756C6156;
  v36._uint64_t object = (void *)0xEB00000000203A65;
  unint64_t v2 = v0;
  String.append(_:)(*(Swift::String *)&v1);
  swift_bridgeObjectRelease();
  swift_bridgeObjectRetain();
  v3._uint64_t object = (void *)0x80000002272D6AE0;
  v3._uint64_t countAndFlagsBits = 0xD000000000000012;
  String.append(_:)(v3);
  swift_bridgeObjectRelease();
  v38[0] = 0x70795465756C6156;
  v38[1] = 0xEB00000000203A65;
  uint64_t v4 = CMLColumn.size.getter();
  if (v4 >= 10) {
    uint64_t v5 = 10;
  }
  else {
    uint64_t v5 = v4;
  }
  if (v5 < 0)
  {
    __break(1u);
    JUMPOUT(0x2271008CCLL);
  }
  uint64_t v6 = v4;
  if (v5)
  {
    uint64_t v7 = 0;
    do
    {
      uint64_t v8 = v7;
      if (v7)
      {
        v9._uint64_t countAndFlagsBits = 8236;
        v9._uint64_t object = (void *)0xE200000000000000;
        String.append(_:)(v9);
      }
      ++v7;
      _UntypedColumn.valueAtIndex(index:)(v8, (uint64_t)&v36);
      uint64_t countAndFlagsBits = (void *)v36._countAndFlagsBits;
      uint64_t object = v36._object;
      switch((char)v37)
      {
        case 1:
          uint64_t v12 = Double.description.getter();
          goto LABEL_19;
        case 2:
          swift_bridgeObjectRetain();
          v14._uint64_t countAndFlagsBits = (uint64_t)countAndFlagsBits;
          v14._uint64_t object = object;
          String.append(_:)(v14);
          outlined consume of MLDataValue(countAndFlagsBits, object, 2);
          uint64_t v15 = countAndFlagsBits;
          uint64_t v16 = object;
          char v17 = 2;
          goto LABEL_25;
        case 3:
          v36._uint64_t object = closure #1 in MLDataValue.SequenceType.description.getter;
          uint64_t v37 = 0;
          outlined copy of MLDataValue((id)v36._countAndFlagsBits, object, 3);
          swift_retain_n();
          __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LazyMapSequence<MLDataValue.SequenceType, String>);
          lazy protocol witness table accessor for type LazyMapSequence<MLDataValue.SequenceType, String> and conformance <> LazyMapSequence<A, B>();
          uint64_t v18 = BidirectionalCollection<>.joined(separator:)();
          uint64_t v20 = v19;
          swift_release();
          v36._uint64_t countAndFlagsBits = 91;
          v36._uint64_t object = (void *)0xE100000000000000;
          v21._uint64_t countAndFlagsBits = v18;
          v21._uint64_t object = v20;
          String.append(_:)(v21);
          swift_bridgeObjectRelease();
          swift_bridgeObjectRetain();
          v22._uint64_t countAndFlagsBits = 93;
          v22._uint64_t object = (void *)0xE100000000000000;
          String.append(_:)(v22);
          swift_bridgeObjectRelease();
          outlined consume of MLDataValue(countAndFlagsBits, object, 3);
          String.append(_:)(v36);
          outlined consume of MLDataValue(countAndFlagsBits, object, 3);
          swift_bridgeObjectRelease();
          uint64_t v15 = countAndFlagsBits;
          uint64_t v16 = object;
          char v17 = 3;
          goto LABEL_25;
        case 4:
          lazy protocol witness table accessor for type MLDataValue and conformance MLDataValue();
          swift_bridgeObjectRetain();
          uint64_t v23 = Dictionary.description.getter();
          uint64_t v25 = v24;
          outlined consume of MLDataValue(countAndFlagsBits, object, 4);
          v26._uint64_t countAndFlagsBits = v23;
          v26._uint64_t object = v25;
          String.append(_:)(v26);
          outlined consume of MLDataValue(countAndFlagsBits, object, 4);
          goto LABEL_23;
        case 5:
          id v27 = objc_msgSend((id)v36._countAndFlagsBits, sel_description);
          uint64_t v28 = static String._unconditionallyBridgeFromObjectiveC(_:)();
          uint64_t v30 = v29;

          outlined consume of MLDataValue(countAndFlagsBits, object, 5);
          v31._uint64_t countAndFlagsBits = v28;
          v31._uint64_t object = v30;
          String.append(_:)(v31);
          outlined consume of MLDataValue(countAndFlagsBits, object, 5);
          swift_bridgeObjectRelease();
          uint64_t v15 = countAndFlagsBits;
          uint64_t v16 = object;
          char v17 = 5;
LABEL_25:
          outlined consume of MLDataValue(v15, v16, v17);
          break;
        case 6:
          v32._uint64_t countAndFlagsBits = OUTLINED_FUNCTION_15_12();
          v32._uint64_t object = (void *)0xE700000000000000;
          String.append(_:)(v32);
          break;
        default:
          lazy protocol witness table accessor for type Int and conformance Int();
          uint64_t v12 = BinaryInteger.description.getter();
LABEL_19:
          String.append(_:)(*(Swift::String *)&v12);
LABEL_23:
          swift_bridgeObjectRelease();
          break;
      }
    }
    while (v5 != v7);
  }
  if (v6 >= 11)
  {
    v33._uint64_t countAndFlagsBits = 0x2E2E2E202CLL;
    v33._uint64_t object = (void *)0xE500000000000000;
    String.append(_:)(v33);
  }
  v34._uint64_t countAndFlagsBits = 93;
  v34._uint64_t object = (void *)0xE100000000000000;
  String.append(_:)(v34);
  return v38[0];
}

uint64_t _UntypedColumn.map(_:skipUndefined:outputType:)(uint64_t a1, uint64_t a2, uint64_t a3, unsigned char *a4)
{
  uint64_t v4 = CMLColumn.apply(transform:type:skipUndefined:)(a1, a2, 0x5060403020100uLL >> (8 * *a4), a3);
  type metadata accessor for _UntypedColumn();
  uint64_t result = swift_allocObject();
  *(void *)(result + 16) = v4;
  return result;
}

uint64_t _UntypedColumn.__deallocating_deinit()
{
  swift_release();

  return swift_deallocClassInstance();
}

uint64_t type metadata accessor for _UntypedColumn()
{
  return self;
}

void outlined consume of MLDataValue?(void *a1, id a2, char a3)
{
  if (a3 != -1) {
    outlined consume of MLDataValue(a1, a2, a3);
  }
}

unint64_t lazy protocol witness table accessor for type MLDataValue and conformance MLDataValue()
{
  unint64_t result = lazy protocol witness table cache variable for type MLDataValue and conformance MLDataValue;
  if (!lazy protocol witness table cache variable for type MLDataValue and conformance MLDataValue)
  {
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type MLDataValue and conformance MLDataValue);
  }
  return result;
}

{
  unint64_t result;

  unint64_t result = lazy protocol witness table cache variable for type MLDataValue and conformance MLDataValue;
  if (!lazy protocol witness table cache variable for type MLDataValue and conformance MLDataValue)
  {
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type MLDataValue and conformance MLDataValue);
  }
  return result;
}

unint64_t lazy protocol witness table accessor for type LazyMapSequence<MLDataValue.SequenceType, String> and conformance <> LazyMapSequence<A, B>()
{
  unint64_t result = lazy protocol witness table cache variable for type LazyMapSequence<MLDataValue.SequenceType, String> and conformance <> LazyMapSequence<A, B>;
  if (!lazy protocol witness table cache variable for type LazyMapSequence<MLDataValue.SequenceType, String> and conformance <> LazyMapSequence<A, B>)
  {
    __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for LazyMapSequence<MLDataValue.SequenceType, String>);
    lazy protocol witness table accessor for type MLDataValue.SequenceType and conformance MLDataValue.SequenceType();
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type LazyMapSequence<MLDataValue.SequenceType, String> and conformance <> LazyMapSequence<A, B>);
  }
  return result;
}

unint64_t lazy protocol witness table accessor for type MLDataValue.SequenceType and conformance MLDataValue.SequenceType()
{
  unint64_t result = lazy protocol witness table cache variable for type MLDataValue.SequenceType and conformance MLDataValue.SequenceType;
  if (!lazy protocol witness table cache variable for type MLDataValue.SequenceType and conformance MLDataValue.SequenceType)
  {
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type MLDataValue.SequenceType and conformance MLDataValue.SequenceType);
  }
  return result;
}

{
  unint64_t result;

  unint64_t result = lazy protocol witness table cache variable for type MLDataValue.SequenceType and conformance MLDataValue.SequenceType;
  if (!lazy protocol witness table cache variable for type MLDataValue.SequenceType and conformance MLDataValue.SequenceType)
  {
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type MLDataValue.SequenceType and conformance MLDataValue.SequenceType);
  }
  return result;
}

{
  unint64_t result;

  unint64_t result = lazy protocol witness table cache variable for type MLDataValue.SequenceType and conformance MLDataValue.SequenceType;
  if (!lazy protocol witness table cache variable for type MLDataValue.SequenceType and conformance MLDataValue.SequenceType)
  {
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type MLDataValue.SequenceType and conformance MLDataValue.SequenceType);
  }
  return result;
}

{
  unint64_t result;

  unint64_t result = lazy protocol witness table cache variable for type MLDataValue.SequenceType and conformance MLDataValue.SequenceType;
  if (!lazy protocol witness table cache variable for type MLDataValue.SequenceType and conformance MLDataValue.SequenceType)
  {
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type MLDataValue.SequenceType and conformance MLDataValue.SequenceType);
  }
  return result;
}

uint64_t OUTLINED_FUNCTION_1_24@<X0>(uint64_t a1@<X1>, uint64_t a2@<X8>)
{
  *(void *)a1 = a2;
  *(void *)(a1 + 8) = (v2 - 32) | 0x8000000000000000;
  *(_OWORD *)(a1 + 16) = 0u;
  *(_OWORD *)(a1 + 32) = 0u;
  *(unsigned char *)(a1 + 48) = 1;
  return swift_willThrow();
}

uint64_t OUTLINED_FUNCTION_2_25()
{
  return *(void *)(v0 + 16);
}

uint64_t OUTLINED_FUNCTION_3_27()
{
  return *(void *)(*(void *)(v0 + 16) + 16);
}

uint64_t OUTLINED_FUNCTION_4_22()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_9_14()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_10_12()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_11_12()
{
  return v0;
}

void OUTLINED_FUNCTION_12_10()
{
  outlined consume of MLDataValue?(v1, v0, v2);
}

uint64_t OUTLINED_FUNCTION_13_12()
{
  return 0;
}

uint64_t OUTLINED_FUNCTION_15_12()
{
  return 0x676E697373694DLL;
}

uint64_t OUTLINED_FUNCTION_16_12()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_17_11(uint64_t a1, uint64_t a2)
{
  return MLDataValue.featureValue.getter(a1, a2);
}

void **assignWithCopy for MLDecisionTreeRegressor.ModelParameters.ValidationData(void **a1, void **a2, uint64_t a3)
{
  if (a1 != a2)
  {
    outlined destroy of MLDecisionTreeRegressor.ModelParameters.ValidationData((uint64_t)a1);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload();
    if (EnumCaseMultiPayload == 2)
    {
      uint64_t v9 = type metadata accessor for DataFrame();
      (*(void (**)(void **, void **, uint64_t))(*(void *)(v9 - 8) + 16))(a1, a2, v9);
    }
    else
    {
      if (EnumCaseMultiPayload != 1)
      {
        memcpy(a1, a2, *(void *)(*(void *)(a3 - 8) + 64));
        return a1;
      }
      uint64_t v7 = *a2;
      char v8 = *((unsigned char *)a2 + 8);
      outlined copy of Result<_DataTable, Error>(v7, v8);
      *a1 = v7;
      *((unsigned char *)a1 + 8) = v8;
    }
    swift_storeEnumTagMultiPayload();
  }
  return a1;
}

uint64_t type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData()
{
  uint64_t result = type metadata singleton initialization cache for MLDecisionTreeRegressor.ModelParameters.ValidationData;
  if (!type metadata singleton initialization cache for MLDecisionTreeRegressor.ModelParameters.ValidationData) {
    return swift_getSingletonMetadata();
  }
  return result;
}

void *assignWithTake for MLDecisionTreeRegressor.ModelParameters.ValidationData(void *a1, const void *a2, uint64_t a3)
{
  if (a1 != a2)
  {
    outlined destroy of MLDecisionTreeRegressor.ModelParameters.ValidationData((uint64_t)a1);
    if (swift_getEnumCaseMultiPayload() == 2)
    {
      uint64_t v6 = type metadata accessor for DataFrame();
      (*(void (**)(void *, const void *, uint64_t))(*(void *)(v6 - 8) + 32))(a1, a2, v6);
      swift_storeEnumTagMultiPayload();
    }
    else
    {
      memcpy(a1, a2, *(void *)(*(void *)(a3 - 8) + 64));
    }
  }
  return a1;
}

uint64_t type metadata completion function for MLDecisionTreeRegressor.ModelParameters.ValidationData()
{
  uint64_t result = type metadata accessor for DataFrame();
  if (v1 <= 0x3F)
  {
    swift_initEnumMetadataMultiPayload();
    return 0;
  }
  return result;
}

uint64_t MLDecisionTreeRegressor.ModelParameters.ValidationData.table.getter@<X0>(uint64_t a1@<X8>)
{
  uint64_t v2 = v1;
  uint64_t v4 = type metadata accessor for DataFrame();
  OUTLINED_FUNCTION_0();
  uint64_t v6 = v5;
  MEMORY[0x270FA5388](v7);
  OUTLINED_FUNCTION_33();
  uint64_t v10 = v8 - v9;
  MEMORY[0x270FA5388](v11);
  uint64_t v13 = (char *)&v26 - v12;
  uint64_t v14 = type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData();
  MEMORY[0x270FA5388](v14);
  OUTLINED_FUNCTION_3_0();
  char v17 = (uint64_t *)(v16 - v15);
  outlined init with copy of MLDecisionTreeRegressor.ModelParameters.ValidationData(v2, v16 - v15);
  uint64_t result = swift_getEnumCaseMultiPayload();
  switch((int)result)
  {
    case 1:
      uint64_t v19 = *v17;
      char v20 = *((unsigned char *)v17 + 8);
      goto LABEL_7;
    case 2:
      (*(void (**)(char *, uint64_t *, uint64_t))(v6 + 32))(v13, v17, v4);
      (*(void (**)(uint64_t, char *, uint64_t))(v6 + 16))(v10, v13, v4);
      MLDataTable.init(_:convertArraysToShapedArrays:)(1, (uint64_t)&v27);
      uint64_t v24 = OUTLINED_FUNCTION_4_1();
      uint64_t result = v25(v24);
      uint64_t v19 = v27;
      char v20 = v28;
LABEL_7:
      *(void *)a1 = v19;
      *(unsigned char *)(a1 + 8) = v20;
      break;
    case 3:
      uint64_t v21 = MEMORY[0x22A6764B0](0);
      if (!v21)
      {
        __break(1u);
        JUMPOUT(0x227101118);
      }
      uint64_t v22 = v21;
      type metadata accessor for CMLTable();
      uint64_t v23 = swift_allocObject();
      *(void *)(v23 + 16) = v22;
      type metadata accessor for _DataTable();
      swift_allocObject();
      uint64_t result = (uint64_t)_DataTable.init(impl:)(v23);
      *(void *)a1 = result;
      *(unsigned char *)(a1 + 8) = 0;
      break;
    default:
      *(void *)a1 = 0;
      *(unsigned char *)(a1 + 8) = -1;
      break;
  }
  return result;
}

uint64_t MLDecisionTreeRegressor.ModelParameters.ValidationData.generateDataFrames(trainingData:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v62 = a3;
  uint64_t v4 = v3;
  uint64_t v60 = a2;
  uint64_t v66 = a1;
  uint64_t v61 = type metadata accessor for DataFrame();
  OUTLINED_FUNCTION_0();
  uint64_t v6 = v5;
  MEMORY[0x270FA5388](v7);
  OUTLINED_FUNCTION_3_0();
  uint64_t v10 = (uint64_t *)(v9 - v8);
  type metadata accessor for DataFrame.Slice();
  OUTLINED_FUNCTION_0();
  uint64_t v58 = v12;
  uint64_t v59 = v11;
  MEMORY[0x270FA5388](v11);
  OUTLINED_FUNCTION_33();
  uint64_t v57 = (char *)(v13 - v14);
  uint64_t v16 = MEMORY[0x270FA5388](v15);
  uint64_t v18 = (char *)&v56 - v17;
  MEMORY[0x270FA5388](v16);
  char v20 = (char *)&v56 - v19;
  uint64_t v21 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame.Slice?);
  MEMORY[0x270FA5388](v21 - 8);
  OUTLINED_FUNCTION_33();
  uint64_t v24 = v22 - v23;
  MEMORY[0x270FA5388](v25);
  uint64_t v27 = (char *)&v56 - v26;
  uint64_t v28 = type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData();
  MEMORY[0x270FA5388](v28);
  OUTLINED_FUNCTION_3_0();
  Swift::String v31 = (uint64_t *)(v30 - v29);
  outlined init with copy of MLDecisionTreeRegressor.ModelParameters.ValidationData(v4, v30 - v29);
  switch(swift_getEnumCaseMultiPayload())
  {
    case 1u:
      uint64_t v47 = *v31;
      char v48 = *((unsigned char *)v31 + 8);
      uint64_t v49 = v61;
      (*(void (**)(uint64_t, uint64_t, uint64_t))(v6 + 16))(v66, v62, v61);
      *(void *)&long long v63 = v47;
      BYTE8(v63) = v48;
      uint64_t v50 = v60;
      DataFrame.init(_:)((uint64_t)&v63, v60);
      uint64_t v43 = v50;
      uint64_t v44 = 0;
      uint64_t v46 = v49;
      goto LABEL_10;
    case 2u:
      uint64_t v38 = *(void (**)(uint64_t, uint64_t *, uint64_t))(v6 + 32);
      uint64_t v39 = v31;
      uint64_t v40 = v61;
      v38((uint64_t)v10, v39, v61);
      if (DataFrameProtocol.isEmpty.getter())
      {
        (*(void (**)(uint64_t *, uint64_t))(v6 + 8))(v10, v40);
        uint64_t v41 = OUTLINED_FUNCTION_1_3();
        v42(v41);
        uint64_t v43 = v60;
        uint64_t v44 = 1;
      }
      else
      {
        uint64_t v51 = OUTLINED_FUNCTION_1_3();
        v52(v51);
        uint64_t v53 = v60;
        v38(v60, v10, v40);
        uint64_t v43 = v53;
        uint64_t v44 = 0;
      }
      uint64_t v46 = v40;
      goto LABEL_10;
    case 3u:
      uint64_t v45 = v61;
      (*(void (**)(uint64_t, uint64_t, uint64_t))(v6 + 16))(v66, v62, v61);
      uint64_t v43 = v60;
      uint64_t v44 = 1;
      uint64_t v46 = v45;
LABEL_10:
      uint64_t result = __swift_storeEnumTagSinglePayload(v43, v44, 1, v46);
      break;
    default:
      char v32 = *((unsigned char *)v31 + 16);
      char v33 = *((unsigned char *)v31 + 17);
      long long v63 = *(_OWORD *)v31;
      char v64 = v32;
      char v65 = v33;
      DataFrame.randomSplit(strategy:)((uint64_t)v27, (uint64_t)v20, (uint64_t)&v63);
      uint64_t v35 = v58;
      uint64_t v34 = v59;
      Swift::String v36 = *(void (**)(char *, char *, uint64_t))(v58 + 16);
      v36(v18, v20, v59);
      DataFrame.init(_:)();
      outlined init with copy of DataFrame.Slice?((uint64_t)v27, v24);
      if (__swift_getEnumTagSinglePayload(v24, 1, v34) == 1)
      {
        __swift_storeEnumTagSinglePayload(v60, 1, 1, v61);
        uint64_t v37 = *(void (**)(char *, uint64_t))(v35 + 8);
      }
      else
      {
        (*(void (**)(char *, uint64_t, uint64_t))(v35 + 32))(v18, v24, v34);
        v36(v57, v18, v34);
        uint64_t v55 = v60;
        DataFrame.init(_:)();
        uint64_t v37 = *(void (**)(char *, uint64_t))(v35 + 8);
        v37(v18, v34);
        __swift_storeEnumTagSinglePayload(v55, 0, 1, v61);
      }
      v37(v20, v34);
      uint64_t result = outlined destroy of DataFrame.Slice?((uint64_t)v27);
      break;
  }
  return result;
}

uint64_t *initializeBufferWithCopyOfBuffer for MLFewShotSoundClassifier.DataSource(uint64_t *a1, uint64_t *a2, uint64_t a3)
{
  int v5 = *(_DWORD *)(*(void *)(a3 - 8) + 80);
  if ((v5 & 0x20000) != 0)
  {
    uint64_t v7 = *a2;
    *a1 = *a2;
    a1 = (uint64_t *)(v7 + ((v5 + 16) & ~(unint64_t)v5));
    swift_retain();
  }
  else
  {
    uint64_t v6 = type metadata accessor for URL();
    (*(void (**)(uint64_t *, uint64_t *, uint64_t))(*(void *)(v6 - 8) + 16))(a1, a2, v6);
  }
  return a1;
}

uint64_t destroy for MLFewShotSoundClassifier.DataSource(uint64_t a1)
{
  uint64_t v2 = type metadata accessor for URL();
  uint64_t v3 = *(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v2 - 8) + 8);

  return v3(a1, v2);
}

uint64_t initializeWithCopy for MLFewShotSoundClassifier.DataSource(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = type metadata accessor for URL();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 16))(a1, a2, v4);
  return a1;
}

uint64_t assignWithCopy for MLFewShotSoundClassifier.DataSource(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = type metadata accessor for URL();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 24))(a1, a2, v4);
  return a1;
}

uint64_t initializeWithTake for MLFewShotSoundClassifier.DataSource(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = type metadata accessor for URL();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 32))(a1, a2, v4);
  return a1;
}

uint64_t assignWithTake for MLFewShotSoundClassifier.DataSource(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = type metadata accessor for URL();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 40))(a1, a2, v4);
  return a1;
}

uint64_t getEnumTagSinglePayload for MLFewShotSoundClassifier.DataSource(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL));

  return __swift_getEnumTagSinglePayload(a1, a2, v4);
}

uint64_t storeEnumTagSinglePayload for MLFewShotSoundClassifier.DataSource(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL));

  return __swift_storeEnumTagSinglePayload(a1, a2, a3, v6);
}

uint64_t type metadata accessor for MLFewShotSoundClassifier.DataSource()
{
  uint64_t result = type metadata singleton initialization cache for MLFewShotSoundClassifier.DataSource;
  if (!type metadata singleton initialization cache for MLFewShotSoundClassifier.DataSource) {
    return swift_getSingletonMetadata();
  }
  return result;
}

uint64_t type metadata completion function for MLFewShotSoundClassifier.DataSource(uint64_t a1)
{
  uint64_t result = type metadata accessor for URL();
  if (v3 <= 0x3F)
  {
    uint64_t v4 = *(void *)(result - 8);
    swift_initEnumMetadataSingleCase();
    uint64_t result = 0;
    *(_DWORD *)(*(void *)(a1 - 8) + 84) = *(_DWORD *)(v4 + 84);
  }
  return result;
}

uint64_t MLFewShotSoundClassifier.DataSource.extractFeatures(with:)(void *a1)
{
  type metadata accessor for UTType();
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v3);
  OUTLINED_FUNCTION_3_0();
  uint64_t v4 = type metadata accessor for URL();
  OUTLINED_FUNCTION_0();
  uint64_t v6 = v5;
  MEMORY[0x270FA5388](v7);
  OUTLINED_FUNCTION_3_0();
  uint64_t v10 = v9 - v8;
  uint64_t v11 = type metadata accessor for MLFewShotSoundClassifier.DataSource();
  MEMORY[0x270FA5388](v11 - 8);
  OUTLINED_FUNCTION_3_0();
  uint64_t v14 = v13 - v12;
  outlined init with copy of MLFewShotSoundClassifier.DataSource(v1, v13 - v12);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v6 + 32))(v10, v14, v4);
  static UTType.audio.getter();
  static _FileUtilities.readableFiles(at:type:)();
  if (v2)
  {
    uint64_t v16 = OUTLINED_FUNCTION_3_28();
    v17(v16);
  }
  else
  {
    uint64_t v19 = v15;
    uint64_t v20 = OUTLINED_FUNCTION_3_28();
    v21(v20);
    if (*(void *)(v19 + 16))
    {
      uint64_t v1 = MLFewShotSoundClassifier.DataSource.extractFeatures(with:from:)(a1, v19);
      uint64_t v23 = OUTLINED_FUNCTION_2_26();
      v24(v23);
      swift_bridgeObjectRelease();
      return v1;
    }
    swift_bridgeObjectRelease();
    lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError();
    *(void *)uint64_t v22 = 0xD00000000000002ELL;
    *(void *)(v22 + 8) = 0x80000002272D6B70;
    *(_OWORD *)(v22 + 16) = 0u;
    *(_OWORD *)(v22 + 32) = 0u;
    *(unsigned char *)(v22 + 48) = 2;
    swift_willThrow();
  }
  (*(void (**)(uint64_t, uint64_t))(v6 + 8))(v10, v4);
  return v1;
}

uint64_t outlined init with copy of MLFewShotSoundClassifier.DataSource(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = type metadata accessor for MLFewShotSoundClassifier.DataSource();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 16))(a2, a1, v4);
  return a2;
}

uint64_t MLFewShotSoundClassifier.DataSource.extractFeatures(with:from:)(void *a1, uint64_t a2)
{
  uint64_t v63 = a2;
  id v64 = a1;
  uint64_t v72 = type metadata accessor for DispatchTimeInterval();
  uint64_t v68 = *(void *)(v72 - 8);
  MEMORY[0x270FA5388](v72);
  uint64_t v67 = (uint64_t *)((char *)&v59 - ((v2 + 15) & 0xFFFFFFFFFFFFFFF0));
  uint64_t v3 = type metadata accessor for DispatchTime();
  uint64_t v69 = *(void *)(v3 - 8);
  uint64_t v70 = v3;
  uint64_t v4 = MEMORY[0x270FA5388](v3);
  char v65 = (char *)&v59 - ((v5 + 15) & 0xFFFFFFFFFFFFFFF0);
  MEMORY[0x270FA5388](v4);
  uint64_t v66 = (char *)&v59 - v6;
  uint64_t v7 = type metadata accessor for OS_dispatch_queue.AutoreleaseFrequency();
  uint64_t v8 = *(void *)(v7 - 8);
  MEMORY[0x270FA5388](v7);
  uint64_t v10 = (char *)&v59 - ((v9 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v11 = type metadata accessor for OS_dispatch_queue.Attributes();
  MEMORY[0x270FA5388](v11);
  uint64_t v12 = type metadata accessor for DispatchQoS();
  MEMORY[0x270FA5388](v12 - 8);
  dispatch_semaphore_t v62 = dispatch_semaphore_create(0);
  type metadata accessor for NSAttributedString(0, &lazy cache variable for type metadata for OS_dispatch_queue);
  static DispatchQoS.default.getter();
  aBlock[0] = MEMORY[0x263F8EE78];
  lazy protocol witness table accessor for type OS_dispatch_queue.Attributes and conformance OS_dispatch_queue.Attributes();
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [OS_dispatch_queue.Attributes]);
  lazy protocol witness table accessor for type [OS_dispatch_queue.Attributes] and conformance [A]();
  dispatch thunk of SetAlgebra.init<A>(_:)();
  (*(void (**)(char *, void, uint64_t))(v8 + 104))(v10, *MEMORY[0x263F8F130], v7);
  uint64_t v13 = (void *)OS_dispatch_queue.init(label:qos:attributes:autoreleaseFrequency:target:)();
  uint64_t v14 = swift_allocObject();
  *(void *)(v14 + 16) = 0;
  uint64_t v61 = (id *)(v14 + 16);
  uint64_t v15 = swift_allocObject();
  *(void *)(v15 + 16) = 0;
  uint64_t v60 = (id *)(v15 + 16);
  uint64_t v16 = self;
  type metadata accessor for URL();
  Class isa = Array._bridgeToObjectiveC()().super.isa;
  URL._bridgeToObjectiveC()(v18);
  uint64_t v20 = v19;
  uint64_t v21 = (void *)swift_allocObject();
  v21[2] = v14;
  v21[3] = v15;
  dispatch_semaphore_t v22 = v62;
  uint64_t v21[4] = v62;
  aBlock[4] = partial apply for closure #1 in MLFewShotSoundClassifier.DataSource.extractFeatures(with:from:);
  aBlock[5] = v21;
  aBlock[0] = MEMORY[0x263EF8330];
  aBlock[1] = 1107296256;
  aBlock[2] = thunk for @escaping @callee_guaranteed (@guaranteed SNKShotFeaturizationResult?, @guaranteed Error?) -> ();
  aBlock[3] = &block_descriptor_4;
  uint64_t v23 = _Block_copy(aBlock);
  swift_retain();
  swift_retain();
  uint64_t v24 = v22;
  swift_release();
  id v64 = v13;
  id v25 = objc_msgSend(v16, sel_featurizeFiles_hallucinatorModelURL_queue_completionHandler_, isa, v20, v13, v23);
  _Block_release(v23);
  uint64_t v26 = v24;
  swift_unknownObjectRelease();

  uint64_t v27 = v65;
  static DispatchTime.now()();
  uint64_t v29 = v67;
  uint64_t v28 = v68;
  *uint64_t v67 = 600;
  uint64_t v30 = v72;
  (*(void (**)(void *, void, uint64_t))(v28 + 104))(v29, *MEMORY[0x263F8F018], v72);
  Swift::String v31 = v66;
  DispatchTime.advanced(by:)();
  (*(void (**)(void *, uint64_t))(v28 + 8))(v29, v30);
  uint64_t v32 = v70;
  char v33 = *(void (**)(char *, uint64_t))(v69 + 8);
  v33(v27, v70);
  uint64_t v34 = MEMORY[0x22A6750C0](v31);
  v33(v31, v32);
  if (v34)
  {
    lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError();
    *(void *)uint64_t v49 = 0xD00000000000001ELL;
    *(void *)(v49 + 8) = 0x80000002272D6C20;
    *(_OWORD *)(v49 + 16) = 0u;
    *(_OWORD *)(v49 + 32) = 0u;
    *(unsigned char *)(v49 + 48) = 2;
    swift_willThrow();
    swift_release();
LABEL_23:
    swift_release();
LABEL_24:
    id v56 = v64;
LABEL_27:

    return v34;
  }
  uint64_t v35 = v61;
  swift_beginAccess();
  if (!*v35)
  {
    uint64_t v50 = v60;
    swift_beginAccess();
    if (*v50)
    {
      id v51 = *v50;
    }
    else
    {
      lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
      swift_allocError();
      *(void *)uint64_t v55 = 0xD000000000000029;
      *(void *)(v55 + 8) = 0x80000002272D6C40;
      *(_OWORD *)(v55 + 16) = 0u;
      *(_OWORD *)(v55 + 32) = 0u;
      *(unsigned char *)(v55 + 48) = 2;
    }
    swift_willThrow();
    swift_release();
    goto LABEL_23;
  }
  Swift::String v36 = v26;
  uint64_t v34 = (uint64_t)*v35;
  id v37 = objc_msgSend((id)v34, sel_trainingDataEmbeddings);
  type metadata accessor for NSAttributedString(0, (unint64_t *)&lazy cache variable for type metadata for MLMultiArray);
  unint64_t v38 = static Array._unconditionallyBridgeFromObjectiveC(_:)();

  if (v38 >> 62)
  {
    swift_bridgeObjectRetain();
    uint64_t v39 = _CocoaArrayWrapper.endIndex.getter();
    swift_bridgeObjectRelease();
  }
  else
  {
    uint64_t v39 = *(void *)((v38 & 0xFFFFFFFFFFFFFF8) + 0x10);
  }
  swift_bridgeObjectRelease();
  if (!v39)
  {
    lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError();
    unint64_t v53 = 0xD000000000000036;
    uint64_t v54 = "Empty training sound embeddings in retrieved features.";
LABEL_26:
    *(void *)uint64_t v52 = v53;
    *(void *)(v52 + 8) = (unint64_t)(v54 - 32) | 0x8000000000000000;
    *(_OWORD *)(v52 + 16) = 0u;
    *(_OWORD *)(v52 + 32) = 0u;
    *(unsigned char *)(v52 + 48) = 2;
    swift_willThrow();
    swift_release();
    swift_release();

    id v56 = v64;
    uint64_t v26 = v36;
    goto LABEL_27;
  }
  id v40 = objc_msgSend((id)v34, sel_trainingDataLabels);
  type metadata accessor for NSAttributedString(0, (unint64_t *)&lazy cache variable for type metadata for NSNumber);
  unint64_t v41 = static Array._unconditionallyBridgeFromObjectiveC(_:)();

  if (v41 >> 62)
  {
    swift_bridgeObjectRetain();
    uint64_t v42 = _CocoaArrayWrapper.endIndex.getter();
    swift_bridgeObjectRelease();
  }
  else
  {
    uint64_t v42 = *(void *)((v41 & 0xFFFFFFFFFFFFFF8) + 0x10);
  }
  swift_bridgeObjectRelease();
  if (!v42)
  {
    lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError();
    unint64_t v53 = 0xD000000000000031;
    uint64_t v54 = "Empty training data labels in retrieved features.";
    goto LABEL_26;
  }
  id v43 = objc_msgSend((id)v34, sel_validationDataEmbeddings);
  unint64_t v44 = static Array._unconditionallyBridgeFromObjectiveC(_:)();

  if (v44 >> 62)
  {
    swift_bridgeObjectRetain();
    uint64_t v45 = _CocoaArrayWrapper.endIndex.getter();
    swift_bridgeObjectRelease();
  }
  else
  {
    uint64_t v45 = *(void *)((v44 & 0xFFFFFFFFFFFFFF8) + 0x10);
  }
  swift_bridgeObjectRelease();
  if (!v45)
  {
    lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError();
    unint64_t v53 = 0xD000000000000038;
    uint64_t v54 = "Empty validation sound embeddings in retrieved features.";
    goto LABEL_26;
  }
  id v46 = objc_msgSend((id)v34, sel_validationDataLabels);
  unint64_t v47 = static Array._unconditionallyBridgeFromObjectiveC(_:)();

  if (v47 >> 62)
  {
    swift_bridgeObjectRetain();
    uint64_t v48 = _CocoaArrayWrapper.endIndex.getter();
    swift_bridgeObjectRelease();
  }
  else
  {
    uint64_t v48 = *(void *)((v47 & 0xFFFFFFFFFFFFFF8) + 0x10);
  }
  uint64_t v26 = v36;
  swift_bridgeObjectRelease();
  if (!v48)
  {
    lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError();
    *(void *)uint64_t v58 = 0xD000000000000033;
    *(void *)(v58 + 8) = 0x80000002272D6C70;
    *(_OWORD *)(v58 + 16) = 0u;
    *(_OWORD *)(v58 + 32) = 0u;
    *(unsigned char *)(v58 + 48) = 2;
    swift_willThrow();
    swift_release();
    swift_release();

    goto LABEL_24;
  }

  swift_release();
  swift_release();
  return v34;
}

unint64_t lazy protocol witness table accessor for type OS_dispatch_queue.Attributes and conformance OS_dispatch_queue.Attributes()
{
  unint64_t result = lazy protocol witness table cache variable for type OS_dispatch_queue.Attributes and conformance OS_dispatch_queue.Attributes;
  if (!lazy protocol witness table cache variable for type OS_dispatch_queue.Attributes and conformance OS_dispatch_queue.Attributes)
  {
    type metadata accessor for OS_dispatch_queue.Attributes();
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type OS_dispatch_queue.Attributes and conformance OS_dispatch_queue.Attributes);
  }
  return result;
}

unint64_t lazy protocol witness table accessor for type [OS_dispatch_queue.Attributes] and conformance [A]()
{
  unint64_t result = lazy protocol witness table cache variable for type [OS_dispatch_queue.Attributes] and conformance [A];
  if (!lazy protocol witness table cache variable for type [OS_dispatch_queue.Attributes] and conformance [A])
  {
    __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for [OS_dispatch_queue.Attributes]);
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type [OS_dispatch_queue.Attributes] and conformance [A]);
  }
  return result;
}

uint64_t sub_227102768()
{
  return MEMORY[0x270FA0238](v0, 24, 7);
}

uint64_t sub_2271027A0()
{
  return MEMORY[0x270FA0238](v0, 24, 7);
}

Swift::Int closure #1 in MLFewShotSoundClassifier.DataSource.extractFeatures(with:from:)(void *a1, void *a2, uint64_t a3, uint64_t a4)
{
  swift_beginAccess();
  uint64_t v8 = *(void **)(a3 + 16);
  *(void *)(a3 + 16) = a1;
  id v9 = a1;

  swift_beginAccess();
  uint64_t v10 = *(void **)(a4 + 16);
  *(void *)(a4 + 16) = a2;
  id v11 = a2;

  return OS_dispatch_semaphore.signal()();
}

uint64_t sub_227102880()
{
  swift_release();
  swift_release();

  return MEMORY[0x270FA0238](v0, 40, 7);
}

Swift::Int partial apply for closure #1 in MLFewShotSoundClassifier.DataSource.extractFeatures(with:from:)(void *a1, void *a2)
{
  return closure #1 in MLFewShotSoundClassifier.DataSource.extractFeatures(with:from:)(a1, a2, *(void *)(v2 + 16), *(void *)(v2 + 24));
}

void thunk for @escaping @callee_guaranteed (@guaranteed SNKShotFeaturizationResult?, @guaranteed Error?) -> ()(uint64_t a1, void *a2, void *a3)
{
  uint64_t v5 = *(void (**)(void *, void *))(a1 + 32);
  swift_retain();
  id v7 = a2;
  id v6 = a3;
  v5(a2, a3);
  swift_release();
}

uint64_t block_copy_helper_2(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = *(void *)(a2 + 40);
  *(void *)(a1 + 32) = *(void *)(a2 + 32);
  *(void *)(a1 + 40) = v2;
  return swift_retain();
}

uint64_t block_destroy_helper_2()
{
  return swift_release();
}

uint64_t OUTLINED_FUNCTION_2_26()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_3_28()
{
  return v0;
}

uint64_t *initializeBufferWithCopyOfBuffer for MLImageClassifier.Model(uint64_t *a1, uint64_t *a2)
{
  int v4 = *(_DWORD *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>)
                             - 8)
                 + 80);
  if ((v4 & 0x20000) != 0)
  {
    uint64_t v6 = *a2;
    *a1 = *a2;
    a1 = (uint64_t *)(v6 + ((v4 + 16) & ~(unint64_t)v4));
    swift_retain();
  }
  else
  {
    if (swift_getEnumCaseMultiPayload() == 1) {
      uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>);
    }
    else {
      uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>);
    }
    (*(void (**)(uint64_t *, uint64_t *, uint64_t))(*(void *)(v5 - 8) + 16))(a1, a2, v5);
    swift_storeEnumTagMultiPayload();
  }
  return a1;
}

uint64_t destroy for MLImageClassifier.Model(uint64_t a1)
{
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  if (swift_getEnumCaseMultiPayload() == 1) {
    uint64_t v2 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>;
  }
  else {
    uint64_t v2 = &demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>;
  }
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(v2);
  int v4 = *(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v3 - 8) + 8);

  return v4(a1, v3);
}

uint64_t initializeWithCopy for MLImageClassifier.Model(uint64_t a1, uint64_t a2)
{
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  if (swift_getEnumCaseMultiPayload() == 1) {
    int v4 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>;
  }
  else {
    int v4 = &demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>;
  }
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(v4);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v5 - 8) + 16))(a1, a2, v5);
  swift_storeEnumTagMultiPayload();
  return a1;
}

uint64_t assignWithCopy for MLImageClassifier.Model(uint64_t a1, uint64_t a2)
{
  if (a1 != a2)
  {
    outlined destroy of Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>(a1);
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
    if (swift_getEnumCaseMultiPayload() == 1) {
      int v4 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>;
    }
    else {
      int v4 = &demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>;
    }
    uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(v4);
    (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v5 - 8) + 16))(a1, a2, v5);
    swift_storeEnumTagMultiPayload();
  }
  return a1;
}

uint64_t outlined destroy of Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>(uint64_t a1)
{
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v2 - 8) + 8))(a1, v2);
  return a1;
}

uint64_t initializeWithTake for MLImageClassifier.Model(uint64_t a1, uint64_t a2)
{
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  if (swift_getEnumCaseMultiPayload() == 1) {
    int v4 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>;
  }
  else {
    int v4 = &demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>;
  }
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(v4);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v5 - 8) + 32))(a1, a2, v5);
  swift_storeEnumTagMultiPayload();
  return a1;
}

uint64_t assignWithTake for MLImageClassifier.Model(uint64_t a1, uint64_t a2)
{
  if (a1 != a2)
  {
    outlined destroy of Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>(a1);
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
    if (swift_getEnumCaseMultiPayload() == 1) {
      int v4 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>;
    }
    else {
      int v4 = &demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>;
    }
    uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(v4);
    (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v5 - 8) + 32))(a1, a2, v5);
    swift_storeEnumTagMultiPayload();
  }
  return a1;
}

uint64_t getEnumTagSinglePayload for MLImageClassifier.Model(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return MEMORY[0x270FA0340](a1, a2, a3, sub_227102ECC);
}

uint64_t sub_227102ECC(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);

  return __swift_getEnumTagSinglePayload(a1, a2, v4);
}

uint64_t storeEnumTagSinglePayload for MLImageClassifier.Model(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return MEMORY[0x270FA0580](a1, a2, a3, a4, sub_227102F2C);
}

uint64_t sub_227102F2C(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);

  return __swift_storeEnumTagSinglePayload(a1, a2, a2, v4);
}

uint64_t type metadata accessor for MLImageClassifier.Model()
{
  uint64_t result = type metadata singleton initialization cache for MLImageClassifier.Model;
  if (!type metadata singleton initialization cache for MLImageClassifier.Model) {
    return swift_getSingletonMetadata();
  }
  return result;
}

void type metadata completion function for MLImageClassifier.Model()
{
  type metadata accessor for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>();
  if (v0 <= 0x3F) {
    swift_initStructMetadata();
  }
}

void type metadata accessor for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>()
{
  if (!lazy cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>)
  {
    __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>);
    __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>);
    unint64_t v0 = type metadata accessor for Either();
    if (!v1) {
      atomic_store(v0, (unint64_t *)&lazy cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
    }
  }
}

void MLImageClassifier.Model.export(metadata:featureExtractorType:)()
{
  OUTLINED_FUNCTION_9_0();
  uint64_t v3 = v2;
  uint64_t v5 = v4;
  uint64_t v6 = type metadata accessor for Model();
  OUTLINED_FUNCTION_0();
  uint64_t v14 = v7;
  MEMORY[0x270FA5388](v8);
  OUTLINED_FUNCTION_32();
  uint64_t v13 = *(void *)(v3 + 64);
  MLImageClassifier.Model.createPipelineModel(featureExtractorType:)();
  if (!v0)
  {
    swift_bridgeObjectRetain();
    Model.modelDescription.setter();
    swift_bridgeObjectRetain();
    Model.versionString.setter();
    swift_bridgeObjectRetain();
    Model.author.setter();
    swift_bridgeObjectRetain();
    Model.license.setter();
    if (!v13) {
      Dictionary.init(dictionaryLiteral:)();
    }
    swift_bridgeObjectRetain();
    Model.metadata.setter();
    getOSVersion()();
    id v9 = (void (*)(uint64_t *, void))Model.metadata.modify();
    specialized Dictionary._Variant.setValue(_:forKey:)();
    v9(&v15, 0);
    (*(void (**)(uint64_t, uint64_t, uint64_t))(v14 + 16))(v1, v5, v6);
    uint64_t v10 = Model.nestedModels.getter();
    OUTLINED_FUNCTION_21_4();
    v11();
    ML16CoreMLExportablePAAE6export8metadata20d14Specification5F75VAA0G8MetadataV_tKFSiAHcfu_32b63bdf5f6c975d31a36a8f37561ba444AHSiTf3nnnpk_nTf1cn_n = (void *)_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay20MLModelSpecification5ModelVG_Sis5NeverOTg5051_s8CreateML16CoreMLExportablePAAE6export8metadata20d14Specification5F75VAA0G8MetadataV_tKFSiAHcfu_32b63bdf5f6c975d31a36a8f37561ba444AHSiTf3nnnpk_nTf1cn_n(v10);
    swift_bridgeObjectRelease();
    specialized Sequence<>.max()(ML16CoreMLExportablePAAE6export8metadata20d14Specification5F75VAA0G8MetadataV_tKFSiAHcfu_32b63bdf5f6c975d31a36a8f37561ba444AHSiTf3nnnpk_nTf1cn_n);
    swift_bridgeObjectRelease();
    Model.specificationVersion.setter();
  }
  OUTLINED_FUNCTION_8_1();
}

uint64_t MLImageClassifier.Model.applied(to:eventHandler:)()
{
  OUTLINED_FUNCTION_11();
  v1[5] = v2;
  v1[6] = v0;
  v1[3] = v3;
  v1[4] = v4;
  v1[2] = v5;
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>);
  v1[7] = v6;
  OUTLINED_FUNCTION_1(v6);
  v1[8] = v7;
  v1[9] = OUTLINED_FUNCTION_5();
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>);
  v1[10] = v8;
  OUTLINED_FUNCTION_1(v8);
  v1[11] = v9;
  v1[12] = OUTLINED_FUNCTION_5();
  v1[13] = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  v1[14] = OUTLINED_FUNCTION_5();
  OUTLINED_FUNCTION_14();
  return MEMORY[0x270FA2498](v10, v11, v12);
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  void *v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v9;

  OUTLINED_FUNCTION_11();
  OUTLINED_FUNCTION_2();
  uint64_t v2 = *v1;
  OUTLINED_FUNCTION_6();
  *uint64_t v3 = v2;
  *(void *)(v4 + 128) = v0;
  swift_task_dealloc();
  OUTLINED_FUNCTION_14();
  return MEMORY[0x270FA2498](v5, v6, v7);
}

{
  uint64_t v0;
  uint64_t v1;
  void (*v2)(uint64_t);
  uint64_t (*v3)(void);
  uint64_t v5;

  OUTLINED_FUNCTION_60_0();
  uint64_t v1 = OUTLINED_FUNCTION_7_18();
  v2(v1);
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  uint64_t v3 = *(uint64_t (**)(void))(v0 + 8);
  return v3();
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  void *v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v9;

  OUTLINED_FUNCTION_11();
  OUTLINED_FUNCTION_2();
  uint64_t v2 = *v1;
  OUTLINED_FUNCTION_6();
  *uint64_t v3 = v2;
  *(void *)(v4 + 144) = v0;
  swift_task_dealloc();
  OUTLINED_FUNCTION_14();
  return MEMORY[0x270FA2498](v5, v6, v7);
}

{
  uint64_t v0;
  uint64_t v1;
  void (*v2)(uint64_t);
  uint64_t (*v3)(void);
  uint64_t v5;

  OUTLINED_FUNCTION_60_0();
  uint64_t v1 = OUTLINED_FUNCTION_7_18();
  v2(v1);
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  uint64_t v3 = *(uint64_t (**)(void))(v0 + 8);
  return v3();
}

{
  void (*v0)(void);
  uint64_t (*v1)(void);
  uint64_t v3;

  OUTLINED_FUNCTION_60_0();
  OUTLINED_FUNCTION_9();
  v0();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  OUTLINED_FUNCTION_30();
  return v1();
}

{
  void (*v0)(void);
  uint64_t (*v1)(void);
  uint64_t v3;

  OUTLINED_FUNCTION_60_0();
  OUTLINED_FUNCTION_9();
  v0();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  OUTLINED_FUNCTION_30();
  return v1();
}

uint64_t MLImageClassifier.Model.applied(to:eventHandler:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16)
{
  OUTLINED_FUNCTION_11();
  outlined init with copy of Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>(v16[6], v16[14]);
  if (swift_getEnumCaseMultiPayload() == 1)
  {
    OUTLINED_FUNCTION_3();
    v17();
    uint64_t v21 = (void *)swift_task_alloc();
    v16[17] = v21;
    *uint64_t v21 = v16;
    v21[1] = MLImageClassifier.Model.applied(to:eventHandler:);
    uint64_t v22 = v16[7];
    uint64_t v23 = v16[4];
    uint64_t v24 = v16[5];
    uint64_t v25 = v16[2];
    uint64_t v26 = v16[3];
    return MEMORY[0x270EEA930](v25, v26, v23, v24, v22, v18, v19, v20, a9, a10, a11, a12, a13, a14, a15, a16);
  }
  else
  {
    OUTLINED_FUNCTION_3();
    v27();
    Swift::String v31 = (void *)swift_task_alloc();
    v16[15] = v31;
    *Swift::String v31 = v16;
    v31[1] = MLImageClassifier.Model.applied(to:eventHandler:);
    uint64_t v32 = v16[10];
    uint64_t v33 = v16[4];
    uint64_t v34 = v16[5];
    uint64_t v35 = v16[2];
    uint64_t v36 = v16[3];
    return MEMORY[0x270EEA920](v35, v36, v33, v34, v32, v28, v29, v30, a9, a10, a11, a12, a13, a14, a15, a16);
  }
}

uint64_t protocol witness for Transformer.applied(to:eventHandler:) in conformance MLImageClassifier.Model()
{
  uint64_t v1 = (void *)swift_task_alloc();
  *(void *)(v0 + 16) = v1;
  void *v1 = v0;
  v1[1] = protocol witness for SupervisedEstimator.fitted<A, B>(to:validateOn:eventHandler:) in conformance MLImageClassifier.Classifier;
  return MLImageClassifier.Model.applied(to:eventHandler:)();
}

unint64_t lazy protocol witness table accessor for type MLImageClassifier.Model and conformance MLImageClassifier.Model()
{
  unint64_t result = lazy protocol witness table cache variable for type MLImageClassifier.Model and conformance MLImageClassifier.Model;
  if (!lazy protocol witness table cache variable for type MLImageClassifier.Model and conformance MLImageClassifier.Model)
  {
    type metadata accessor for MLImageClassifier.Model();
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type MLImageClassifier.Model and conformance MLImageClassifier.Model);
  }
  return result;
}

uint64_t associated type witness table accessor for Classifier.Label : Hashable in MLImageClassifier.Model()
{
  return MEMORY[0x263F8D320];
}

uint64_t outlined init with copy of Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 16))(a2, a1, v4);
  return a2;
}

uint64_t MLImageClassifier.Model.exportAsCompiledMLModel(featureExtractorType:)()
{
  OUTLINED_FUNCTION_11();
  v1[2] = v2;
  v1[3] = v0;
  uint64_t v3 = type metadata accessor for Model();
  v1[4] = v3;
  OUTLINED_FUNCTION_1(v3);
  v1[5] = v4;
  v1[6] = OUTLINED_FUNCTION_5();
  OUTLINED_FUNCTION_14();
  return MEMORY[0x270FA2498](v5, v6, v7);
}

{
  uint64_t v0;
  NSString *v1;
  void *v2;
  uint64_t v3;
  uint64_t v5;

  uint64_t v1 = NSFullUserName();
  static String._unconditionallyBridgeFromObjectiveC(_:)();

  MLImageClassifier.Model.export(metadata:featureExtractorType:)();
  swift_bridgeObjectRelease();
  swift_bridgeObjectRelease();
  swift_bridgeObjectRelease_n();
  swift_bridgeObjectRelease();
  type metadata accessor for MLModel();
  uint64_t v2 = (void *)swift_task_alloc();
  *(void *)(v0 + 56) = v2;
  *uint64_t v2 = v0;
  v2[1] = MLImageClassifier.Model.exportAsCompiledMLModel(featureExtractorType:);
  uint64_t v3 = *(void *)(v0 + 48);
  return static MLModel.compile(_:)(v3);
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  void *v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v12;

  OUTLINED_FUNCTION_60_0();
  uint64_t v3 = v2;
  OUTLINED_FUNCTION_2();
  uint64_t v5 = v4;
  uint64_t v6 = *v1;
  OUTLINED_FUNCTION_6();
  void *v7 = v6;
  *(void *)(v5 + 64) = v0;
  swift_task_dealloc();
  if (!v0) {
    *(void *)(v5 + 72) = v3;
  }
  OUTLINED_FUNCTION_14();
  return MEMORY[0x270FA2498](v8, v9, v10);
}

{
  uint64_t v0;
  uint64_t v1;
  void (*v2)(uint64_t);
  uint64_t (*v3)(uint64_t);
  uint64_t v4;
  uint64_t v6;

  OUTLINED_FUNCTION_11();
  uint64_t v1 = OUTLINED_FUNCTION_7_18();
  v2(v1);
  swift_task_dealloc();
  uint64_t v3 = *(uint64_t (**)(uint64_t))(v0 + 8);
  uint64_t v4 = *(void *)(v0 + 72);
  return v3(v4);
}

{
  void (*v0)(void);
  uint64_t (*v1)(void);
  uint64_t v3;

  OUTLINED_FUNCTION_11();
  OUTLINED_FUNCTION_9();
  v0();
  swift_task_dealloc();
  OUTLINED_FUNCTION_30();
  return v1();
}

void MLImageClassifier.Model.createPipelineModel(featureExtractorType:)()
{
  OUTLINED_FUNCTION_9_0();
  uint64_t v75 = v3;
  uint64_t v72 = v4;
  type metadata accessor for ModelKind();
  OUTLINED_FUNCTION_0();
  uint64_t v67 = v6;
  uint64_t v68 = v5;
  MEMORY[0x270FA5388](v5);
  OUTLINED_FUNCTION_33_0();
  uint64_t v66 = v7;
  uint64_t v73 = type metadata accessor for FeatureDescription();
  OUTLINED_FUNCTION_0();
  uint64_t v69 = v8;
  MEMORY[0x270FA5388](v9);
  OUTLINED_FUNCTION_6_18(v10, v59[0]);
  uint64_t v74 = type metadata accessor for FeatureType();
  OUTLINED_FUNCTION_0();
  uint64_t v70 = v11;
  MEMORY[0x270FA5388](v12);
  OUTLINED_FUNCTION_13_13();
  MEMORY[0x270FA5388](v13);
  uint64_t v15 = (char *)v59 - v14;
  uint64_t v16 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FeatureDescription?);
  uint64_t v17 = MEMORY[0x270FA5388](v16 - 8);
  uint64_t v19 = (char *)v59 - ((v18 + 15) & 0xFFFFFFFFFFFFFFF0);
  MEMORY[0x270FA5388](v17);
  uint64_t v21 = (char *)v59 - v20;
  uint64_t v22 = type metadata accessor for Model();
  OUTLINED_FUNCTION_0();
  uint64_t v24 = v23;
  MEMORY[0x270FA5388](v25);
  OUTLINED_FUNCTION_63();
  MEMORY[0x270FA5388](v26);
  uint64_t v28 = (char *)v59 - v27;
  MLImageClassifier.Model.createFeatureExtractorModel(_:)(v75, (uint64_t)v59 - v27);
  if (v1) {
    goto LABEL_5;
  }
  uint64_t v61 = v2;
  dispatch_semaphore_t v62 = v19;
  uint64_t v64 = v22;
  char v65 = v28;
  uint64_t v76 = v24;
  uint64_t v63 = v15;
  uint64_t v30 = v73;
  uint64_t v29 = v74;
  MLImageClassifier.Model.createClassifierModel()();
  uint64_t v75 = 0;
  Swift::String v31 = v0;
  uint64_t v32 = Model.outputs.getter();
  specialized Collection.first.getter(v32, (uint64_t)v21);
  swift_bridgeObjectRelease();
  if (__swift_getEnumTagSinglePayload((uint64_t)v21, 1, v30) == 1)
  {
    __break(1u);
  }
  else
  {
    uint64_t v33 = FeatureDescription.name.getter();
    v59[2] = v34;
    v59[3] = v33;
    uint64_t v35 = v69;
    uint64_t v36 = v69 + 8;
    uint64_t v60 = *(void (**)(uint64_t, uint64_t))(v69 + 8);
    OUTLINED_FUNCTION_9();
    v37();
    uint64_t v38 = Model.inputs.getter();
    uint64_t v39 = (uint64_t)v62;
    specialized Collection.first.getter(v38, (uint64_t)v62);
    swift_bridgeObjectRelease();
    uint64_t v40 = v30;
    int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v39, 1, v30);
    uint64_t v42 = v71;
    if (EnumTagSinglePayload != 1)
    {
      id v43 = v63;
      FeatureDescription.type.getter();
      v59[1] = v36;
      v60(v39, v40);
      (*(void (**)(uint64_t, char *, uint64_t))(v70 + 16))(v61, v43, v29);
      FeatureDescription.init(name:type:description:)();
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<FeatureDescription>);
      uint64_t v44 = v42;
      unint64_t v45 = (*(unsigned __int8 *)(v35 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v35 + 80);
      uint64_t v46 = swift_allocObject();
      *(_OWORD *)(v46 + 16) = xmmword_2272CB370;
      (*(void (**)(unint64_t, uint64_t, uint64_t))(v35 + 16))(v46 + v45, v44, v40);
      unint64_t v47 = v65;
      Model.outputs.setter();
      Model.outputs.getter();
      Model.inputs.setter();
      Model.init()();
      Model.specificationVersion.setter();
      Model.inputs.getter();
      Model.inputs.setter();
      Model.outputs.getter();
      Model.outputs.setter();
      Model.predictedFeatureName.getter();
      Model.predictedFeatureName.setter();
      Model.predictedProbabilitiesName.getter();
      Model.predictedProbabilitiesName.setter();
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Model>);
      uint64_t v48 = *(void *)(v76 + 72);
      unint64_t v49 = (*(unsigned __int8 *)(v76 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v76 + 80);
      uint64_t v50 = swift_allocObject();
      *(_OWORD *)(v50 + 16) = xmmword_2272CB4D0;
      unint64_t v51 = v50 + v49;
      uint64_t v52 = *(void (**)(unint64_t, char *, uint64_t))(v76 + 16);
      unint64_t v53 = v31;
      uint64_t v54 = v64;
      v52(v51, v47, v64);
      v52(v51 + v48, v53, v54);
      uint64_t v55 = v66;
      PipelineClassifierConfiguration.init(models:names:)();
      (*(void (**)(uint64_t, void, uint64_t))(v67 + 104))(v55, *MEMORY[0x263F53408], v68);
      Model.kind.setter();
      OUTLINED_FUNCTION_25_0();
      v56();
      OUTLINED_FUNCTION_25_0();
      v57();
      uint64_t v58 = *(void (**)(void))(v76 + 8);
      OUTLINED_FUNCTION_21_4();
      v58();
      ((void (*)(char *, uint64_t))v58)(v65, v54);
LABEL_5:
      OUTLINED_FUNCTION_8_1();
      return;
    }
  }
  __break(1u);
}

void MLImageClassifier.Model.createFeatureExtractorModel(_:)(uint64_t a1@<X0>, uint64_t a2@<X8>)
{
  uint64_t v4 = type metadata accessor for MLImageClassifier.CustomFeatureExtractor(0);
  MEMORY[0x270FA5388](v4 - 8);
  OUTLINED_FUNCTION_3_0();
  uint64_t v7 = v6 - v5;
  uint64_t v8 = type metadata accessor for MLImageClassifier.FeatureExtractorType(0);
  MEMORY[0x270FA5388](v8);
  OUTLINED_FUNCTION_3_0();
  uint64_t v11 = v10 - v9;
  outlined init with copy of MLImageClassifier.FeatureExtractorType(a1, v10 - v9);
  if (swift_getEnumCaseMultiPayload() == 1)
  {
    outlined init with take of MLImageClassifier.CustomFeatureExtractor(v11, v7);
    MLImageClassifier.CustomFeatureExtractor.buildModel()(a2);
    outlined destroy of MLImageClassifier.CustomFeatureExtractor(v7);
  }
  else
  {
    MLImageClassifier.Model.createScenePrintFeatureExtractorModel(revision:)();
  }
}

void MLImageClassifier.Model.createScenePrintFeatureExtractorModel(revision:)()
{
  OUTLINED_FUNCTION_9_0();
  uint64_t v49 = v2;
  v44[1] = v3;
  type metadata accessor for ImageFeaturePrint();
  OUTLINED_FUNCTION_0();
  uint64_t v51 = v4;
  MEMORY[0x270FA5388](v5);
  OUTLINED_FUNCTION_33_0();
  uint64_t v50 = v6;
  type metadata accessor for URL.DirectoryHint();
  OUTLINED_FUNCTION_0();
  uint64_t v45 = v8;
  uint64_t v46 = v7;
  MEMORY[0x270FA5388](v7);
  OUTLINED_FUNCTION_3_0();
  uint64_t v11 = v10 - v9;
  type metadata accessor for UUID();
  OUTLINED_FUNCTION_0();
  v44[2] = v13;
  v44[3] = v12;
  MEMORY[0x270FA5388](v12);
  OUTLINED_FUNCTION_3_0();
  type metadata accessor for URL();
  OUTLINED_FUNCTION_0();
  uint64_t v47 = v14;
  uint64_t v48 = v15;
  MEMORY[0x270FA5388](v14);
  OUTLINED_FUNCTION_13_13();
  MEMORY[0x270FA5388](v16);
  OUTLINED_FUNCTION_47_2();
  uint64_t v18 = MEMORY[0x270FA5388](v17);
  uint64_t v20 = (char *)v44 - v19;
  uint64_t v21 = MEMORY[0x270FA5388](v18);
  OUTLINED_FUNCTION_24_9(v21, v22, v23, v24, v25, v26, v27, v28, v44[0]);
  uint64_t v29 = self;
  id v30 = objc_msgSend(v29, sel_defaultManager);
  NSFileManager.createTemporaryModelDirectory()();

  if (!v31)
  {
    v44[0] = v0;
    id v32 = objc_msgSend(v29, sel_defaultManager);
    NSFileManager.temporaryModelDirectory.getter();

    UUID.init()();
    uint64_t v33 = UUID.uuidString.getter();
    uint64_t v35 = v34;
    OUTLINED_FUNCTION_25_0();
    v36();
    uint64_t v52 = v33;
    uint64_t v53 = v35;
    uint64_t v38 = v45;
    uint64_t v37 = v46;
    (*(void (**)(uint64_t, void, uint64_t))(v45 + 104))(v11, *MEMORY[0x263F06E50], v46);
    lazy protocol witness table accessor for type String and conformance String();
    URL.appending<A>(component:directoryHint:)();
    uint64_t v39 = *(void (**)(uint64_t, uint64_t))(v38 + 8);
    v38 += 8;
    v39(v11, v37);
    swift_bridgeObjectRelease();
    uint64_t v40 = v47;
    uint64_t v41 = v48;
    uint64_t v42 = *(void (**)(char *, uint64_t))(v48 + 8);
    v42(v1, v47);
    OUTLINED_FUNCTION_8_16();
    URL.appendingPathExtension(_:)();
    v42(v20, v40);
    objc_msgSend(objc_allocWithZone(MEMORY[0x263F00628]), sel_init);
    ImageFeaturePrint.init(revision:cropAndScale:context:)();
    Transformer.export(to:)();
    OUTLINED_FUNCTION_25_0();
    v43();
    (*(void (**)(uint64_t, uint64_t, uint64_t))(v41 + 16))(v44[0], v38, v40);
    Model.init(contentsOf:)();
    $defer #1 () in MLImageClassifier.Model.createScenePrintFeatureExtractorModel(revision:)();
    v42((char *)v38, v40);
  }
  OUTLINED_FUNCTION_8_1();
}

void MLImageClassifier.Model.createClassifierModel()()
{
  OUTLINED_FUNCTION_9_0();
  uint64_t v44 = v1;
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>);
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v2);
  OUTLINED_FUNCTION_33_0();
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>);
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v3);
  OUTLINED_FUNCTION_33_0();
  uint64_t v42 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  MEMORY[0x270FA5388](v42);
  OUTLINED_FUNCTION_6_18(v4, v37);
  type metadata accessor for URL.DirectoryHint();
  OUTLINED_FUNCTION_0();
  uint64_t v39 = v6;
  uint64_t v40 = v5;
  MEMORY[0x270FA5388](v5);
  OUTLINED_FUNCTION_3_0();
  uint64_t v9 = v8 - v7;
  type metadata accessor for UUID();
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v10);
  OUTLINED_FUNCTION_32();
  uint64_t v41 = type metadata accessor for URL();
  OUTLINED_FUNCTION_0();
  uint64_t v45 = v11;
  MEMORY[0x270FA5388](v12);
  OUTLINED_FUNCTION_63();
  uint64_t v14 = MEMORY[0x270FA5388](v13);
  MEMORY[0x270FA5388](v14);
  OUTLINED_FUNCTION_47_2();
  uint64_t v16 = MEMORY[0x270FA5388](v15);
  OUTLINED_FUNCTION_24_9(v16, v17, v18, v19, v20, v21, v22, v23, v38);
  uint64_t v24 = self;
  id v25 = objc_msgSend(v24, sel_defaultManager);
  NSFileManager.createTemporaryModelDirectory()();

  if (!v26)
  {
    id v27 = objc_msgSend(v24, sel_defaultManager);
    NSFileManager.temporaryModelDirectory.getter();

    UUID.init()();
    UUID.uuidString.getter();
    OUTLINED_FUNCTION_25_0();
    v28();
    (*(void (**)(uint64_t, void, uint64_t))(v39 + 104))(v9, *MEMORY[0x263F06E50], v40);
    lazy protocol witness table accessor for type String and conformance String();
    URL.appending<A>(component:directoryHint:)();
    OUTLINED_FUNCTION_21_4();
    v29();
    swift_bridgeObjectRelease();
    id v30 = *(void (**)(void))(v45 + 8);
    OUTLINED_FUNCTION_21_4();
    v30();
    OUTLINED_FUNCTION_8_16();
    URL.appendingPathExtension(_:)();
    OUTLINED_FUNCTION_21_4();
    v30();
    outlined init with copy of Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>(v44, v43);
    if (swift_getEnumCaseMultiPayload() == 1)
    {
      OUTLINED_FUNCTION_25_11();
      OUTLINED_FUNCTION_3();
      v31();
      id v32 = (unint64_t *)&lazy protocol witness table cache variable for type FullyConnectedNetworkClassifierModel<Float, String> and conformance FullyConnectedNetworkClassifierModel<A, B>;
      uint64_t v33 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>;
    }
    else
    {
      OUTLINED_FUNCTION_25_11();
      OUTLINED_FUNCTION_3();
      v34();
      id v32 = (unint64_t *)&lazy protocol witness table cache variable for type LogisticRegressionClassifierModel<Float, String> and conformance LogisticRegressionClassifierModel<A, B>;
      uint64_t v33 = &demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>;
    }
    lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(v32, v33);
    Transformer.export(to:)();
    uint64_t v35 = OUTLINED_FUNCTION_14_10();
    v36(v35);
    (*(void (**)(uint64_t, void, uint64_t))(v45 + 16))(v0, 0, v41);
    Model.init(contentsOf:)();
    $defer #1 () in MLImageClassifier.Model.createScenePrintFeatureExtractorModel(revision:)();
    ((void (*)(void, uint64_t))v30)(0, v41);
  }
  OUTLINED_FUNCTION_8_1();
}

void $defer #1 () in MLImageClassifier.Model.createScenePrintFeatureExtractorModel(revision:)()
{
  v9[1] = *(id *)MEMORY[0x263EF8340];
  id v0 = objc_msgSend(self, sel_defaultManager);
  URL._bridgeToObjectiveC()(v1);
  uint64_t v3 = v2;
  v9[0] = 0;
  unsigned int v4 = objc_msgSend(v0, sel_removeItemAtURL_error_, v2, v9);

  id v5 = v9[0];
  if (v4)
  {
    id v6 = v5;
  }
  else
  {
    id v7 = v9[0];
    uint64_t v8 = (void *)_convertNSErrorToError(_:)();

    swift_willThrow();
  }
}

uint64_t outlined destroy of MLImageClassifier.CustomFeatureExtractor(uint64_t a1)
{
  uint64_t v2 = type metadata accessor for MLImageClassifier.CustomFeatureExtractor(0);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v2 - 8) + 8))(a1, v2);
  return a1;
}

uint64_t OUTLINED_FUNCTION_6_18@<X0>(uint64_t a1@<X8>, uint64_t a2)
{
  *(void *)(v2 - 120) = (char *)&a2 - ((a1 + 15) & 0xFFFFFFFFFFFFFFF0);
  return 0;
}

uint64_t OUTLINED_FUNCTION_7_18()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_8_16()
{
  return 0x6C65646F6D6C6D2ELL;
}

uint64_t OUTLINED_FUNCTION_14_10()
{
  return v0;
}

void OUTLINED_FUNCTION_24_9(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
  *(void *)(v10 - 160) = (char *)&a9 - v9;
}

uint64_t OUTLINED_FUNCTION_25_11()
{
  return v0;
}

uint64_t instantiation function for generic protocol witness table for SGD<A>(uint64_t a1)
{
  uint64_t result = swift_getWitnessTable();
  *(void *)(a1 + 8) = result;
  return result;
}

void **assignWithCopy for MLRandomForestClassifier.ModelParameters.ValidationData(void **a1, void **a2, uint64_t a3)
{
  if (a1 != a2)
  {
    outlined destroy of MLRandomForestClassifier.ModelParameters.ValidationData((uint64_t)a1);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload();
    if (EnumCaseMultiPayload == 2)
    {
      uint64_t v9 = type metadata accessor for DataFrame();
      (*(void (**)(void **, void **, uint64_t))(*(void *)(v9 - 8) + 16))(a1, a2, v9);
    }
    else
    {
      if (EnumCaseMultiPayload != 1)
      {
        memcpy(a1, a2, *(void *)(*(void *)(a3 - 8) + 64));
        return a1;
      }
      id v7 = *a2;
      char v8 = *((unsigned char *)a2 + 8);
      outlined copy of Result<_DataTable, Error>(v7, v8);
      *a1 = v7;
      *((unsigned char *)a1 + 8) = v8;
    }
    swift_storeEnumTagMultiPayload();
  }
  return a1;
}

uint64_t outlined destroy of MLRandomForestClassifier.ModelParameters.ValidationData(uint64_t a1)
{
  uint64_t v2 = type metadata accessor for MLRandomForestClassifier.ModelParameters.ValidationData();
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v2 - 8) + 8))(a1, v2);
  return a1;
}

uint64_t type metadata accessor for MLRandomForestClassifier.ModelParameters.ValidationData()
{
  uint64_t result = type metadata singleton initialization cache for MLRandomForestClassifier.ModelParameters.ValidationData;
  if (!type metadata singleton initialization cache for MLRandomForestClassifier.ModelParameters.ValidationData) {
    return swift_getSingletonMetadata();
  }
  return result;
}

void *assignWithTake for MLRandomForestClassifier.ModelParameters.ValidationData(void *a1, const void *a2, uint64_t a3)
{
  if (a1 != a2)
  {
    outlined destroy of MLRandomForestClassifier.ModelParameters.ValidationData((uint64_t)a1);
    if (swift_getEnumCaseMultiPayload() == 2)
    {
      uint64_t v6 = type metadata accessor for DataFrame();
      (*(void (**)(void *, const void *, uint64_t))(*(void *)(v6 - 8) + 32))(a1, a2, v6);
      swift_storeEnumTagMultiPayload();
    }
    else
    {
      memcpy(a1, a2, *(void *)(*(void *)(a3 - 8) + 64));
    }
  }
  return a1;
}

uint64_t type metadata completion function for MLRandomForestClassifier.ModelParameters.ValidationData()
{
  uint64_t result = type metadata accessor for DataFrame();
  if (v1 <= 0x3F)
  {
    swift_initEnumMetadataMultiPayload();
    return 0;
  }
  return result;
}

uint64_t MLRandomForestClassifier.ModelParameters.ValidationData.asTable()@<X0>(uint64_t a1@<X8>)
{
  uint64_t v2 = v1;
  uint64_t v4 = type metadata accessor for DataFrame();
  OUTLINED_FUNCTION_0();
  uint64_t v6 = v5;
  MEMORY[0x270FA5388](v7);
  OUTLINED_FUNCTION_33();
  uint64_t v10 = v8 - v9;
  MEMORY[0x270FA5388](v11);
  uint64_t v13 = (char *)&v26 - v12;
  uint64_t v14 = type metadata accessor for MLRandomForestClassifier.ModelParameters.ValidationData();
  MEMORY[0x270FA5388](v14);
  OUTLINED_FUNCTION_3_0();
  uint64_t v17 = (uint64_t *)(v16 - v15);
  outlined init with copy of MLRandomForestClassifier.ModelParameters.ValidationData(v2, v16 - v15);
  uint64_t result = swift_getEnumCaseMultiPayload();
  switch((int)result)
  {
    case 1:
      uint64_t v19 = *v17;
      char v20 = *((unsigned char *)v17 + 8);
      goto LABEL_7;
    case 2:
      (*(void (**)(char *, uint64_t *, uint64_t))(v6 + 32))(v13, v17, v4);
      (*(void (**)(uint64_t, char *, uint64_t))(v6 + 16))(v10, v13, v4);
      MLDataTable.init(_:convertArraysToShapedArrays:)(1, (uint64_t)&v27);
      uint64_t v24 = OUTLINED_FUNCTION_4_1();
      uint64_t result = v25(v24);
      uint64_t v19 = v27;
      char v20 = v28;
LABEL_7:
      *(void *)a1 = v19;
      *(unsigned char *)(a1 + 8) = v20;
      break;
    case 3:
      uint64_t v21 = MEMORY[0x22A6764B0](0);
      if (!v21)
      {
        __break(1u);
        JUMPOUT(0x227105538);
      }
      uint64_t v22 = v21;
      type metadata accessor for CMLTable();
      uint64_t v23 = swift_allocObject();
      *(void *)(v23 + 16) = v22;
      type metadata accessor for _DataTable();
      swift_allocObject();
      uint64_t result = (uint64_t)_DataTable.init(impl:)(v23);
      *(void *)a1 = result;
      *(unsigned char *)(a1 + 8) = 0;
      break;
    default:
      *(void *)a1 = 0;
      *(unsigned char *)(a1 + 8) = -1;
      break;
  }
  return result;
}

uint64_t MLRandomForestClassifier.ModelParameters.ValidationData.generateDataFrames(trainingData:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v62 = a3;
  uint64_t v4 = v3;
  uint64_t v60 = a2;
  uint64_t v66 = a1;
  uint64_t v61 = type metadata accessor for DataFrame();
  OUTLINED_FUNCTION_0();
  uint64_t v6 = v5;
  MEMORY[0x270FA5388](v7);
  OUTLINED_FUNCTION_3_0();
  uint64_t v10 = (uint64_t *)(v9 - v8);
  type metadata accessor for DataFrame.Slice();
  OUTLINED_FUNCTION_0();
  uint64_t v58 = v12;
  uint64_t v59 = v11;
  MEMORY[0x270FA5388](v11);
  OUTLINED_FUNCTION_33();
  uint64_t v57 = (char *)(v13 - v14);
  uint64_t v16 = MEMORY[0x270FA5388](v15);
  uint64_t v18 = (char *)&v56 - v17;
  MEMORY[0x270FA5388](v16);
  char v20 = (char *)&v56 - v19;
  uint64_t v21 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame.Slice?);
  MEMORY[0x270FA5388](v21 - 8);
  OUTLINED_FUNCTION_33();
  uint64_t v24 = v22 - v23;
  MEMORY[0x270FA5388](v25);
  uint64_t v27 = (char *)&v56 - v26;
  uint64_t v28 = type metadata accessor for MLRandomForestClassifier.ModelParameters.ValidationData();
  MEMORY[0x270FA5388](v28);
  OUTLINED_FUNCTION_3_0();
  uint64_t v31 = (uint64_t *)(v30 - v29);
  outlined init with copy of MLRandomForestClassifier.ModelParameters.ValidationData(v4, v30 - v29);
  switch(swift_getEnumCaseMultiPayload())
  {
    case 1u:
      uint64_t v47 = *v31;
      char v48 = *((unsigned char *)v31 + 8);
      uint64_t v49 = v61;
      (*(void (**)(uint64_t, uint64_t, uint64_t))(v6 + 16))(v66, v62, v61);
      *(void *)&long long v63 = v47;
      BYTE8(v63) = v48;
      uint64_t v50 = v60;
      DataFrame.init(_:)((uint64_t)&v63, v60);
      uint64_t v43 = v50;
      uint64_t v44 = 0;
      uint64_t v46 = v49;
      goto LABEL_10;
    case 2u:
      uint64_t v38 = *(void (**)(uint64_t, uint64_t *, uint64_t))(v6 + 32);
      uint64_t v39 = v31;
      uint64_t v40 = v61;
      v38((uint64_t)v10, v39, v61);
      if (DataFrameProtocol.isEmpty.getter())
      {
        (*(void (**)(uint64_t *, uint64_t))(v6 + 8))(v10, v40);
        uint64_t v41 = OUTLINED_FUNCTION_1_3();
        v42(v41);
        uint64_t v43 = v60;
        uint64_t v44 = 1;
      }
      else
      {
        uint64_t v51 = OUTLINED_FUNCTION_1_3();
        v52(v51);
        uint64_t v53 = v60;
        v38(v60, v10, v40);
        uint64_t v43 = v53;
        uint64_t v44 = 0;
      }
      uint64_t v46 = v40;
      goto LABEL_10;
    case 3u:
      uint64_t v45 = v61;
      (*(void (**)(uint64_t, uint64_t, uint64_t))(v6 + 16))(v66, v62, v61);
      uint64_t v43 = v60;
      uint64_t v44 = 1;
      uint64_t v46 = v45;
LABEL_10:
      uint64_t result = __swift_storeEnumTagSinglePayload(v43, v44, 1, v46);
      break;
    default:
      char v32 = *((unsigned char *)v31 + 16);
      char v33 = *((unsigned char *)v31 + 17);
      long long v63 = *(_OWORD *)v31;
      char v64 = v32;
      char v65 = v33;
      DataFrame.randomSplit(strategy:)((uint64_t)v27, (uint64_t)v20, (uint64_t)&v63);
      uint64_t v35 = v58;
      uint64_t v34 = v59;
      uint64_t v36 = *(void (**)(char *, char *, uint64_t))(v58 + 16);
      v36(v18, v20, v59);
      DataFrame.init(_:)();
      outlined init with copy of DataFrame.Slice?((uint64_t)v27, v24);
      if (__swift_getEnumTagSinglePayload(v24, 1, v34) == 1)
      {
        __swift_storeEnumTagSinglePayload(v60, 1, 1, v61);
        uint64_t v37 = *(void (**)(char *, uint64_t))(v35 + 8);
      }
      else
      {
        (*(void (**)(char *, uint64_t, uint64_t))(v35 + 32))(v18, v24, v34);
        v36(v57, v18, v34);
        uint64_t v55 = v60;
        DataFrame.init(_:)();
        uint64_t v37 = *(void (**)(char *, uint64_t))(v35 + 8);
        v37(v18, v34);
        __swift_storeEnumTagSinglePayload(v55, 0, 1, v61);
      }
      v37(v20, v34);
      uint64_t result = outlined destroy of DataFrame.Slice?((uint64_t)v27);
      break;
  }
  return result;
}

uint64_t outlined init with copy of MLRandomForestClassifier.ModelParameters.ValidationData(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = type metadata accessor for MLRandomForestClassifier.ModelParameters.ValidationData();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 16))(a2, a1, v4);
  return a2;
}

uint64_t MLLinearRegressor.ModelParameters.validationData.getter@<X0>(uint64_t a1@<X8>)
{
  type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v3);
  OUTLINED_FUNCTION_3_0();
  uint64_t v6 = v5 - v4;
  uint64_t result = outlined init with copy of Any?(v1, (uint64_t)&v8);
  if (v9)
  {
    outlined init with take of Any(&v8, &v10);
    swift_dynamicCast();
    MLLinearRegressor.ModelParameters.ValidationData.asTable()(a1);
    return outlined destroy of MLLinearRegressor.ModelParameters.ValidationData(v6);
  }
  else
  {
    __break(1u);
  }
  return result;
}

uint64_t key path getter for MLLinearRegressor.ModelParameters.validationData : MLLinearRegressor.ModelParameters@<X0>(uint64_t a1@<X8>)
{
  uint64_t result = MLLinearRegressor.ModelParameters.validationData.getter((uint64_t)&v4);
  char v3 = v5;
  *(void *)a1 = v4;
  *(unsigned char *)(a1 + 8) = v3;
  return result;
}

uint64_t key path setter for MLLinearRegressor.ModelParameters.validationData : MLLinearRegressor.ModelParameters(uint64_t a1)
{
  unsigned __int8 v1 = *(unsigned char *)(a1 + 8);
  id v3 = *(id *)a1;
  unsigned __int8 v4 = v1;
  outlined copy of MLDataTable?(v3, v1);
  return MLLinearRegressor.ModelParameters.validationData.setter((uint64_t)&v3);
}

uint64_t MLLinearRegressor.ModelParameters.validationData.setter(uint64_t a1)
{
  uint64_t v2 = v1;
  type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v4);
  OUTLINED_FUNCTION_3_0();
  uint64_t v7 = v6 - v5;
  long long v8 = *(void **)a1;
  int v9 = *(unsigned __int8 *)(a1 + 8);
  v13[3] = v10;
  boxed_opaque_existential_0 = __swift_allocate_boxed_opaque_existential_0(v13);
  if (v9 == 255)
  {
    *(void *)uint64_t v7 = 0;
    *(void *)(v7 + 8) = 0;
    *(_WORD *)(v7 + 16) = 256;
  }
  else if (MLDataTable.size.getter())
  {
    *(void *)uint64_t v7 = v8;
    *(unsigned char *)(v7 + 8) = v9 & 1;
  }
  else
  {
    outlined consume of MLDataTable?(v8, v9);
  }
  swift_storeEnumTagMultiPayload();
  outlined init with take of MLLinearRegressor.ModelParameters.ValidationData(v7, (uint64_t)boxed_opaque_existential_0);
  return outlined assign with take of Any?((uint64_t)v13, v2);
}

uint64_t MLLinearRegressor.ModelParameters.validation.getter()
{
  uint64_t result = outlined init with copy of Any?(v0, (uint64_t)&v2);
  if (v3)
  {
    outlined init with take of Any(&v2, &v4);
    type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData();
    return swift_dynamicCast();
  }
  else
  {
    __break(1u);
  }
  return result;
}

uint64_t outlined destroy of MLLinearRegressor.ModelParameters.ValidationData(uint64_t a1)
{
  uint64_t v2 = type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData();
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v2 - 8) + 8))(a1, v2);
  return a1;
}

uint64_t outlined init with take of MLLinearRegressor.ModelParameters.ValidationData(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 32))(a2, a1, v4);
  return a2;
}

void (*MLLinearRegressor.ModelParameters.validationData.modify(uint64_t a1))(uint64_t a1, char a2)
{
  *(void *)(a1 + 16) = v1;
  MLLinearRegressor.ModelParameters.validationData.getter(a1);
  return MLLinearRegressor.ModelParameters.validationData.modify;
}

void MLLinearRegressor.ModelParameters.validationData.modify(uint64_t a1, char a2)
{
  uint64_t v2 = *(void **)a1;
  unsigned __int8 v3 = *(unsigned char *)(a1 + 8);
  if (a2)
  {
    uint64_t v4 = *(void **)a1;
    unsigned __int8 v5 = v3;
    outlined copy of MLDataTable?(v2, v3);
    MLLinearRegressor.ModelParameters.validationData.setter((uint64_t)&v4);
    outlined consume of MLDataTable?(v2, v3);
  }
  else
  {
    uint64_t v4 = *(void **)a1;
    unsigned __int8 v5 = v3;
    MLLinearRegressor.ModelParameters.validationData.setter((uint64_t)&v4);
  }
}

uint64_t key path setter for MLLinearRegressor.ModelParameters.validation : MLLinearRegressor.ModelParameters(uint64_t a1)
{
  uint64_t v2 = type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData();
  MEMORY[0x270FA5388](v2 - 8);
  uint64_t v4 = (char *)&v6 - ((v3 + 15) & 0xFFFFFFFFFFFFFFF0);
  outlined init with copy of MLLinearRegressor.ModelParameters.ValidationData(a1, (uint64_t)v4);
  return MLLinearRegressor.ModelParameters.validation.setter((uint64_t)v4);
}

uint64_t MLLinearRegressor.ModelParameters.validation.setter(uint64_t a1)
{
  v5[3] = type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData();
  boxed_opaque_existential_0 = __swift_allocate_boxed_opaque_existential_0(v5);
  outlined init with take of MLLinearRegressor.ModelParameters.ValidationData(a1, (uint64_t)boxed_opaque_existential_0);
  return outlined assign with take of Any?((uint64_t)v5, v1);
}

void (*MLLinearRegressor.ModelParameters.validation.modify(void *a1))(uint64_t **a1, char a2)
{
  uint64_t v2 = v1;
  uint64_t v4 = malloc(0xA0uLL);
  *a1 = v4;
  v4[16] = v2;
  v4[17] = type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData();
  OUTLINED_FUNCTION_8();
  size_t v6 = *(void *)(v5 + 64);
  v4[18] = malloc(v6);
  v4[19] = malloc(v6);
  uint64_t result = (void (*)(uint64_t **, char))outlined init with copy of Any?(v2, (uint64_t)(v4 + 4));
  if (v4[7])
  {
    outlined init with take of Any((_OWORD *)v4 + 2, v4);
    swift_dynamicCast();
    return MLLinearRegressor.ModelParameters.validation.modify;
  }
  else
  {
    __break(1u);
  }
  return result;
}

void MLLinearRegressor.ModelParameters.validation.modify(uint64_t **a1, char a2)
{
  uint64_t v2 = *a1;
  uint64_t v3 = (void *)(*a1)[18];
  uint64_t v4 = (void *)(*a1)[19];
  uint64_t v5 = (*a1)[16];
  uint64_t v6 = (*a1)[17];
  if (a2)
  {
    outlined init with copy of MLLinearRegressor.ModelParameters.ValidationData((*a1)[19], (uint64_t)v3);
    v2[11] = v6;
    boxed_opaque_existential_0 = __swift_allocate_boxed_opaque_existential_0(v2 + 8);
    outlined init with take of MLLinearRegressor.ModelParameters.ValidationData((uint64_t)v3, (uint64_t)boxed_opaque_existential_0);
    outlined assign with take of Any?((uint64_t)(v2 + 8), v5);
    outlined destroy of MLLinearRegressor.ModelParameters.ValidationData((uint64_t)v4);
  }
  else
  {
    v2[15] = v6;
    long long v8 = __swift_allocate_boxed_opaque_existential_0(v2 + 12);
    outlined init with take of MLLinearRegressor.ModelParameters.ValidationData((uint64_t)v4, (uint64_t)v8);
    outlined assign with take of Any?((uint64_t)(v2 + 12), v5);
  }
  free(v4);
  free(v3);

  free(v2);
}

uint64_t outlined init with copy of MLLinearRegressor.ModelParameters.ValidationData(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 16))(a2, a1, v4);
  return a2;
}

uint64_t MLLinearRegressor.ModelParameters.maxIterations.getter()
{
  return *(void *)(v0 + 32);
}

uint64_t MLLinearRegressor.ModelParameters.maxIterations.setter(uint64_t result)
{
  *(void *)(v1 + 32) = result;
  return result;
}

uint64_t (*MLLinearRegressor.ModelParameters.maxIterations.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

double MLLinearRegressor.ModelParameters.l1Penalty.getter()
{
  return *(double *)(v0 + 40);
}

void MLLinearRegressor.ModelParameters.l1Penalty.setter(double a1)
{
  *(double *)(v1 + 40) = a1;
}

uint64_t (*MLLinearRegressor.ModelParameters.l1Penalty.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

double MLLinearRegressor.ModelParameters.l2Penalty.getter()
{
  return *(double *)(v0 + 48);
}

void MLLinearRegressor.ModelParameters.l2Penalty.setter(double a1)
{
  *(double *)(v1 + 48) = a1;
}

uint64_t (*MLLinearRegressor.ModelParameters.l2Penalty.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

double MLLinearRegressor.ModelParameters.stepSize.getter()
{
  return *(double *)(v0 + 56);
}

void MLLinearRegressor.ModelParameters.stepSize.setter(double a1)
{
  *(double *)(v1 + 56) = a1;
}

uint64_t (*MLLinearRegressor.ModelParameters.stepSize.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

double MLLinearRegressor.ModelParameters.convergenceThreshold.getter()
{
  return *(double *)(v0 + 64);
}

void MLLinearRegressor.ModelParameters.convergenceThreshold.setter(double a1)
{
  *(double *)(v1 + 64) = a1;
}

uint64_t (*MLLinearRegressor.ModelParameters.convergenceThreshold.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLLinearRegressor.ModelParameters.featureRescaling.getter()
{
  return *(unsigned __int8 *)(v0 + 72);
}

uint64_t MLLinearRegressor.ModelParameters.featureRescaling.setter(uint64_t result)
{
  *(unsigned char *)(v1 + 72) = result;
  return result;
}

uint64_t (*MLLinearRegressor.ModelParameters.featureRescaling.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLLinearRegressor.ModelParameters.init(validation:maxIterations:l1Penalty:l2Penalty:stepSize:convergenceThreshold:featureRescaling:)@<X0>(uint64_t a1@<X0>, uint64_t a2@<X1>, char a3@<W2>, uint64_t a4@<X8>, double a5@<D0>, double a6@<D1>, double a7@<D2>, double a8@<D3>)
{
  uint64_t v16 = type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v17);
  OUTLINED_FUNCTION_3_0();
  uint64_t v20 = v19 - v18;
  *(_OWORD *)a4 = 0u;
  *(_OWORD *)(a4 + 16) = 0u;
  *(void *)(a4 + 32) = a2;
  *(double *)(a4 + 40) = a5;
  *(double *)(a4 + 48) = a6;
  *(double *)(a4 + 56) = a7;
  *(double *)(a4 + 64) = a8;
  *(unsigned char *)(a4 + 72) = a3;
  outlined init with copy of MLLinearRegressor.ModelParameters.ValidationData(a1, v19 - v18);
  v23[3] = v16;
  boxed_opaque_existential_0 = __swift_allocate_boxed_opaque_existential_0(v23);
  outlined init with take of MLLinearRegressor.ModelParameters.ValidationData(v20, (uint64_t)boxed_opaque_existential_0);
  outlined assign with take of Any?((uint64_t)v23, a4);
  return outlined destroy of MLLinearRegressor.ModelParameters.ValidationData(a1);
}

uint64_t MLLinearRegressor.ModelParameters.init(validationData:maxIterations:l1Penalty:l2Penalty:stepSize:convergenceThreshold:featureRescaling:)@<X0>(uint64_t *a1@<X0>, uint64_t a2@<X1>, char a3@<W2>, uint64_t a4@<X8>, double a5@<D0>, double a6@<D1>, double a7@<D2>, double a8@<D3>)
{
  uint64_t v8 = *a1;
  char v9 = *((unsigned char *)a1 + 8);
  *(_OWORD *)a4 = 0u;
  *(_OWORD *)(a4 + 16) = 0u;
  *(void *)(a4 + 32) = a2;
  *(double *)(a4 + 40) = a5;
  *(double *)(a4 + 48) = a6;
  *(double *)(a4 + 56) = a7;
  *(double *)(a4 + 64) = a8;
  *(unsigned char *)(a4 + 72) = a3;
  uint64_t v11 = v8;
  char v12 = v9;
  return MLLinearRegressor.ModelParameters.validationData.setter((uint64_t)&v11);
}

unint64_t MLLinearRegressor.ModelParameters.description.getter()
{
  _StringGuts.grow(_:)(19);
  swift_bridgeObjectRelease();
  v1._uint64_t countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter();
  String.append(_:)(v1);
  swift_bridgeObjectRelease();
  v2._uint64_t countAndFlagsBits = 10;
  v2._uint64_t object = (void *)0xE100000000000000;
  String.append(_:)(v2);
  v3._uint64_t countAndFlagsBits = 0x6C616E655020314CLL;
  v3._uint64_t object = (void *)0xEC000000203A7974;
  String.append(_:)(v3);
  OUTLINED_FUNCTION_1_16();
  OUTLINED_FUNCTION_0_10();
  OUTLINED_FUNCTION_3_15(v4, v5, v6, v7, v8, v9, v10, v11, 0, 0xE000000000000000);
  swift_bridgeObjectRelease();
  v12._uint64_t countAndFlagsBits = 0x6C616E655020324CLL;
  v12._uint64_t object = (void *)0xEC000000203A7974;
  String.append(_:)(v12);
  OUTLINED_FUNCTION_1_16();
  OUTLINED_FUNCTION_0_10();
  OUTLINED_FUNCTION_3_15(v13, v14, v15, v16, v17, v18, v19, v20, 0, 0xE000000000000000);
  swift_bridgeObjectRelease();
  v21._uint64_t countAndFlagsBits = 0x7A69532070657453;
  v21._uint64_t object = (void *)0xEB00000000203A65;
  String.append(_:)(v21);
  OUTLINED_FUNCTION_1_16();
  OUTLINED_FUNCTION_0_10();
  OUTLINED_FUNCTION_3_15(v22, v23, v24, v25, v26, v27, v28, v29, 0, 0xE000000000000000);
  swift_bridgeObjectRelease();
  _StringGuts.grow(_:)(26);
  v30._uint64_t countAndFlagsBits = 0xD000000000000017;
  v30._uint64_t object = (void *)0x80000002272D5EA0;
  String.append(_:)(v30);
  OUTLINED_FUNCTION_1_16();
  OUTLINED_FUNCTION_0_10();
  v31._uint64_t countAndFlagsBits = 0;
  v31._uint64_t object = (void *)0xE000000000000000;
  String.append(_:)(v31);
  swift_bridgeObjectRelease();
  _StringGuts.grow(_:)(22);
  swift_bridgeObjectRelease();
  if (*(unsigned char *)(v0 + 72)) {
    uint64_t v32 = 1702195828;
  }
  else {
    uint64_t v32 = 0x65736C6166;
  }
  if (*(unsigned char *)(v0 + 72)) {
    unint64_t v33 = 0xE400000000000000;
  }
  else {
    unint64_t v33 = 0xE500000000000000;
  }
  unint64_t v34 = v33;
  String.append(_:)(*(Swift::String *)&v32);
  swift_bridgeObjectRelease();
  OUTLINED_FUNCTION_0_10();
  v35._uint64_t countAndFlagsBits = 0xD000000000000013;
  v35._uint64_t object = (void *)0x80000002272D5EC0;
  String.append(_:)(v35);
  swift_bridgeObjectRelease();
  return 0xD000000000000010;
}

unint64_t MLLinearRegressor.ModelParameters.playgroundDescription.getter@<X0>(unint64_t *a1@<X8>)
{
  unint64_t result = MLLinearRegressor.ModelParameters.description.getter();
  a1[3] = MEMORY[0x263F8D310];
  *a1 = result;
  a1[1] = v3;
  return result;
}

uint64_t sub_2271066C4()
{
  return MLLinearRegressor.ModelParameters.validation.getter();
}

uint64_t initializeWithCopy for MLLinearRegressor.ModelParameters(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = *(void *)(a2 + 24);
  if (v4)
  {
    *(void *)(a1 + 24) = v4;
    (**(void (***)(uint64_t, uint64_t))(v4 - 8))(a1, a2);
  }
  else
  {
    long long v5 = *(_OWORD *)(a2 + 16);
    *(_OWORD *)a1 = *(_OWORD *)a2;
    *(_OWORD *)(a1 + 16) = v5;
  }
  long long v6 = *(_OWORD *)(a2 + 48);
  *(_OWORD *)(a1 + 32) = *(_OWORD *)(a2 + 32);
  *(_OWORD *)(a1 + 48) = v6;
  *(void *)(a1 + 64) = *(void *)(a2 + 64);
  *(unsigned char *)(a1 + 72) = *(unsigned char *)(a2 + 72);
  return a1;
}

uint64_t assignWithCopy for MLLinearRegressor.ModelParameters(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = *(void *)(a2 + 24);
  if (!*(void *)(a1 + 24))
  {
    if (v4)
    {
      *(void *)(a1 + 24) = v4;
      (**(void (***)(uint64_t, uint64_t))(v4 - 8))(a1, a2);
      goto LABEL_8;
    }
LABEL_7:
    long long v5 = *(_OWORD *)(a2 + 16);
    *(_OWORD *)a1 = *(_OWORD *)a2;
    *(_OWORD *)(a1 + 16) = v5;
    goto LABEL_8;
  }
  if (!v4)
  {
    __swift_destroy_boxed_opaque_existential_0(a1);
    goto LABEL_7;
  }
  __swift_assign_boxed_opaque_existential_0((uint64_t *)a1, (uint64_t *)a2);
LABEL_8:
  *(void *)(a1 + 32) = *(void *)(a2 + 32);
  *(void *)(a1 + 40) = *(void *)(a2 + 40);
  *(void *)(a1 + 48) = *(void *)(a2 + 48);
  *(void *)(a1 + 56) = *(void *)(a2 + 56);
  *(void *)(a1 + 64) = *(void *)(a2 + 64);
  *(unsigned char *)(a1 + 72) = *(unsigned char *)(a2 + 72);
  return a1;
}

uint64_t assignWithTake for MLLinearRegressor.ModelParameters(uint64_t a1, uint64_t a2)
{
  if (*(void *)(a1 + 24)) {
    __swift_destroy_boxed_opaque_existential_0(a1);
  }
  long long v4 = *(_OWORD *)(a2 + 16);
  *(_OWORD *)a1 = *(_OWORD *)a2;
  *(_OWORD *)(a1 + 16) = v4;
  *(void *)(a1 + 32) = *(void *)(a2 + 32);
  *(_OWORD *)(a1 + 40) = *(_OWORD *)(a2 + 40);
  *(_OWORD *)(a1 + 56) = *(_OWORD *)(a2 + 56);
  *(unsigned char *)(a1 + 72) = *(unsigned char *)(a2 + 72);
  return a1;
}

uint64_t getEnumTagSinglePayload for MLLinearRegressor.ModelParameters(uint64_t a1, unsigned int a2)
{
  if (a2)
  {
    if (a2 >= 0x7FFFFFFF && *(unsigned char *)(a1 + 73))
    {
      int v2 = *(_DWORD *)a1 + 2147483646;
    }
    else
    {
      unint64_t v3 = *(void *)(a1 + 24);
      if (v3 >= 0xFFFFFFFF) {
        LODWORD(v3) = -1;
      }
      int v2 = v3 - 1;
      if (v2 < 0) {
        int v2 = -1;
      }
    }
  }
  else
  {
    int v2 = -1;
  }
  return (v2 + 1);
}

uint64_t storeEnumTagSinglePayload for MLLinearRegressor.ModelParameters(uint64_t result, unsigned int a2, unsigned int a3)
{
  if (a2 > 0x7FFFFFFE)
  {
    *(_OWORD *)(result + 56) = 0u;
    *(_OWORD *)(result + 40) = 0u;
    *(_OWORD *)(result + 24) = 0u;
    *(_OWORD *)(result + 8) = 0u;
    *(unsigned char *)(result + 72) = 0;
    *(void *)unint64_t result = a2 - 0x7FFFFFFF;
    if (a3 >= 0x7FFFFFFF) {
      *(unsigned char *)(result + 73) = 1;
    }
  }
  else
  {
    if (a3 >= 0x7FFFFFFF) {
      *(unsigned char *)(result + 73) = 0;
    }
    if (a2) {
      *(void *)(result + 24) = a2;
    }
  }
  return result;
}

ValueMetadata *type metadata accessor for MLLinearRegressor.ModelParameters()
{
  return &type metadata for MLLinearRegressor.ModelParameters;
}

uint64_t static MLSoundClassifier.VGGishFeatureExtractor.buildSoundAnalysisPreprocessingSpec()@<X0>(uint64_t a1@<X8>)
{
  type metadata accessor for ModelKind();
  OUTLINED_FUNCTION_0();
  uint64_t v55 = v3;
  uint64_t v56 = v2;
  MEMORY[0x270FA5388](v2);
  OUTLINED_FUNCTION_33_0();
  uint64_t v54 = v4;
  uint64_t v58 = type metadata accessor for FeatureType.ShapedArrayParameters.DataType();
  OUTLINED_FUNCTION_0();
  uint64_t v6 = v5;
  MEMORY[0x270FA5388](v7);
  OUTLINED_FUNCTION_3_0();
  uint64_t v10 = v9 - v8;
  uint64_t v11 = type metadata accessor for FeatureType();
  MEMORY[0x270FA5388](v11 - 8);
  OUTLINED_FUNCTION_3_0();
  uint64_t v14 = v13 - v12;
  uint64_t v53 = type metadata accessor for FeatureDescription();
  uint64_t v57 = *(void *)(v53 - 8);
  uint64_t v15 = v57;
  MEMORY[0x270FA5388](v53);
  OUTLINED_FUNCTION_49();
  uint64_t v52 = v16;
  MEMORY[0x270FA5388](v17);
  uint64_t v19 = (char *)&v40 - v18;
  Model.init()();
  uint64_t v49 = a1;
  Model.specificationVersion.setter();
  OUTLINED_FUNCTION_20_1();
  uint64_t v51 = v20;
  Model.predictedFeatureName.setter();
  Model.modelDescription.setter();
  FeatureDescription.init()();
  FeatureDescription.name.setter();
  OUTLINED_FUNCTION_20_1();
  FeatureDescription.featureDescription.setter();
  unsigned int v48 = *MEMORY[0x263F531A0];
  uint64_t v47 = *(void (**)(uint64_t))(v6 + 104);
  uint64_t v21 = v58;
  v47(v10);
  uint64_t v44 = v14;
  static FeatureType.shapedArray(dataType:shape:optional:)();
  uint64_t v22 = *(void (**)(uint64_t, uint64_t))(v6 + 8);
  uint64_t v45 = v6 + 8;
  uint64_t v46 = v22;
  v22(v10, v21);
  uint64_t v23 = v19;
  uint64_t v50 = v19;
  FeatureDescription.type.setter();
  uint64_t v43 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<FeatureDescription>);
  uint64_t v24 = *(void *)(v15 + 72);
  uint64_t v25 = v57;
  uint64_t v26 = *(unsigned __int8 *)(v57 + 80);
  uint64_t v27 = (v26 + 32) & ~v26;
  uint64_t v41 = v26 | 7;
  uint64_t v42 = v27 + v24;
  uint64_t v28 = swift_allocObject();
  long long v40 = xmmword_2272CB370;
  *(_OWORD *)(v28 + 16) = xmmword_2272CB370;
  uint64_t v29 = *(void (**)(uint64_t, char *, uint64_t))(v25 + 16);
  Swift::String v30 = v23;
  uint64_t v31 = v53;
  v29(v28 + v27, v30, v53);
  Model.inputs.setter();
  uint64_t v32 = v52;
  FeatureDescription.init()();
  FeatureDescription.name.setter();
  uint64_t v33 = v58;
  ((void (*)(uint64_t, void, uint64_t))v47)(v10, v48, v58);
  static FeatureType.shapedArray(dataType:shape:optional:)();
  v46(v10, v33);
  FeatureDescription.type.setter();
  uint64_t v34 = swift_allocObject();
  *(_OWORD *)(v34 + 16) = v40;
  v29(v34 + v27, v32, v31);
  uint64_t v35 = Model.outputs.setter();
  MEMORY[0x22A674100](v35);
  type metadata accessor for SoundAnalysisPreprocessorKind();
  OUTLINED_FUNCTION_7_19();
  v36();
  OUTLINED_FUNCTION_7_19();
  v37();
  Model.kind.setter();
  uint64_t v38 = *(void (**)(uint64_t, uint64_t))(v57 + 8);
  v38((uint64_t)v32, v31);
  return ((uint64_t (*)(char *, uint64_t))v38)(v50, v31);
}

void static MLSoundClassifier.VGGishFeatureExtractor.buildFeatureEmbeddingNeuralNetworkSpec(outputName:)(uint64_t a1@<X0>, uint64_t a2@<X1>, uint64_t a3@<X8>)
{
  uint64_t v129 = a2;
  uint64_t v130 = a3;
  uint64_t v127 = a1;
  type metadata accessor for ModelKind();
  OUTLINED_FUNCTION_0();
  uint64_t v124 = v4;
  uint64_t v125 = v3;
  MEMORY[0x270FA5388](v3);
  OUTLINED_FUNCTION_49();
  uint64_t v121 = v5;
  MEMORY[0x270FA5388](v6);
  uint64_t v123 = (char *)&v101 - v7;
  type metadata accessor for NeuralNetwork();
  OUTLINED_FUNCTION_0();
  uint64_t v119 = v9;
  uint64_t v120 = v8;
  MEMORY[0x270FA5388](v8);
  OUTLINED_FUNCTION_33_0();
  uint64_t v118 = v10;
  uint64_t v128 = type metadata accessor for FeatureType.ShapedArrayParameters.DataType();
  OUTLINED_FUNCTION_0();
  uint64_t v122 = v11;
  MEMORY[0x270FA5388](v12);
  OUTLINED_FUNCTION_3_0();
  uint64_t v15 = v14 - v13;
  uint64_t v16 = type metadata accessor for FeatureType();
  MEMORY[0x270FA5388](v16 - 8);
  OUTLINED_FUNCTION_3_0();
  uint64_t v19 = v18 - v17;
  uint64_t v20 = type metadata accessor for FeatureDescription();
  OUTLINED_FUNCTION_0();
  uint64_t v126 = v21;
  uint64_t v23 = MEMORY[0x270FA5388](v22);
  uint64_t v25 = (char *)&v101 - ((v24 + 15) & 0xFFFFFFFFFFFFFFF0);
  MEMORY[0x270FA5388](v23);
  uint64_t v27 = (char *)&v101 - v26;
  uint64_t v28 = type metadata accessor for URL();
  OUTLINED_FUNCTION_0();
  uint64_t v30 = v29;
  uint64_t v32 = MEMORY[0x270FA5388](v31);
  uint64_t v34 = (char *)&v101 - ((v33 + 15) & 0xFFFFFFFFFFFFFFF0);
  MEMORY[0x270FA5388](v32);
  uint64_t v36 = (char *)&v101 - v35;
  OUTLINED_FUNCTION_20_1();
  uint64_t v37 = v133;
  static BundleUtilities.getMLModelURL(at:)(v38, v39, (uint64_t)v36);
  if (!v37)
  {
    uint64_t v114 = v19;
    uint64_t v40 = v128;
    uint64_t v115 = v25;
    uint64_t v117 = v27;
    uint64_t v116 = (void *)v20;
    (*(void (**)(char *, char *, uint64_t))(v30 + 16))(v34, v36, v28);
    Model.init(contentsOf:)();
    uint64_t v133 = 0;
    uint64_t v103 = v36;
    uint64_t v104 = v30;
    uint64_t v105 = v28;
    Model.specificationVersion.setter();
    swift_bridgeObjectRetain();
    Model.predictedFeatureName.setter();
    Model.modelDescription.setter();
    uint64_t v41 = v117;
    FeatureDescription.init()();
    unint64_t v102 = (unint64_t)"Feature embedding for VGGish";
    FeatureDescription.name.setter();
    unsigned int v113 = *MEMORY[0x263F531A0];
    uint64_t v42 = v122;
    uint64_t v112 = *(void (**)(uint64_t))(v122 + 104);
    uint64_t v43 = v15;
    uint64_t v44 = v15;
    uint64_t v45 = v40;
    v112(v44);
    static FeatureType.shapedArray(dataType:shape:optional:)();
    uint64_t v122 = *(void *)(v42 + 8);
    ((void (*)(uint64_t, uint64_t))v122)(v43, v40);
    FeatureDescription.type.setter();
    uint64_t v111 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<FeatureDescription>);
    uint64_t v46 = v126;
    uint64_t v47 = *(unsigned __int8 *)(v126 + 80);
    uint64_t v110 = ((v47 + 32) & ~v47) + *(void *)(v126 + 72);
    uint64_t v48 = (v47 + 32) & ~v47;
    uint64_t v108 = v48;
    uint64_t v109 = v47 | 7;
    uint64_t v49 = swift_allocObject();
    long long v107 = xmmword_2272CB370;
    *(_OWORD *)(v49 + 16) = xmmword_2272CB370;
    uint64_t v50 = v49 + v48;
    uint64_t v106 = *(void (**)(uint64_t, char *, void *))(v46 + 16);
    uint64_t v51 = v116;
    v106(v50, v41, v116);
    Model.inputs.setter();
    uint64_t v52 = v115;
    FeatureDescription.init()();
    swift_bridgeObjectRetain();
    FeatureDescription.name.setter();
    ((void (*)(uint64_t, void, uint64_t))v112)(v43, v113, v45);
    uint64_t v53 = v125;
    static FeatureType.shapedArray(dataType:shape:optional:)();
    uint64_t v54 = v43;
    uint64_t v55 = v52;
    ((void (*)(uint64_t, uint64_t))v122)(v54, v45);
    FeatureDescription.type.setter();
    uint64_t v56 = swift_allocObject();
    *(_OWORD *)(v56 + 16) = v107;
    v106(v56 + v108, v52, v51);
    uint64_t v57 = v130;
    Model.outputs.setter();
    uint64_t v58 = v123;
    Model.kind.getter();
    uint64_t v59 = v124;
    if ((*(unsigned int (**)(char *, uint64_t))(v124 + 88))(v58, v53) != *MEMORY[0x263F533B8])
    {
      uint64_t v86 = *(void (**)(uint64_t))(v59 + 8);
      uint64_t v87 = OUTLINED_FUNCTION_5_19();
      v86(v87);
      uint64_t v131 = 0;
      unint64_t v132 = 0xE000000000000000;
      _StringGuts.grow(_:)(52);
      OUTLINED_FUNCTION_20_1();
      String.append(_:)(v88);
      Model.kind.getter();
      _print_unlocked<A, B>(_:_:)();
      uint64_t v89 = OUTLINED_FUNCTION_5_19();
      v86(v89);
      v90._uint64_t countAndFlagsBits = 0x64616574736E6920;
      v90._uint64_t object = (void *)0xE90000000000002ELL;
      String.append(_:)(v90);
      uint64_t v91 = v131;
      unint64_t v92 = v132;
      lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
      uint64_t v93 = swift_allocError();
      *(void *)uint64_t v94 = v91;
      *(void *)(v94 + 8) = v92;
      *(_OWORD *)(v94 + 16) = 0u;
      *(_OWORD *)(v94 + 32) = 0u;
      *(unsigned char *)(v94 + 48) = 2;
      uint64_t v133 = v93;
      swift_willThrow();
      uint64_t v95 = *(void (**)(char *, void *))(v126 + 8);
      v95(v55, v51);
      v95(v117, v51);
      uint64_t v96 = type metadata accessor for Model();
      (*(void (**)(uint64_t, uint64_t))(*(void *)(v96 - 8) + 8))(v57, v96);
      (*(void (**)(char *, uint64_t))(v104 + 8))(v103, v105);
      return;
    }
    (*(void (**)(char *, uint64_t))(v59 + 96))(v58, v53);
    uint64_t v60 = v118;
    (*(void (**)(void (*)(void), char *, uint64_t))(v119 + 32))(v118, v58, v120);
    uint64_t v61 = (void (*)(void))NeuralNetwork.layers.modify();
    long long v63 = v62;
    uint64_t v64 = *v62;
    char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native();
    *long long v63 = v64;
    if ((isUniquelyReferenced_nonNull_native & 1) == 0)
    {
      specialized _ArrayBuffer._consumeAndCreateNew()();
      uint64_t v64 = v97;
      *long long v63 = v97;
    }
    if (*(void *)(v64 + 16))
    {
      type metadata accessor for NeuralNetwork.Layer();
      uint64_t v64 = NeuralNetwork.Layer.inputNames.modify();
      uint64_t v51 = v66;
      uint64_t v67 = *v66;
      char v68 = swift_isUniquelyReferenced_nonNull_native();
      *uint64_t v51 = v67;
      if (v68) {
        goto LABEL_7;
      }
    }
    else
    {
      __break(1u);
    }
    specialized _ArrayBuffer._consumeAndCreateNew()();
    uint64_t v67 = v98;
    *uint64_t v51 = v98;
LABEL_7:
    if (v67[2])
    {
      unint64_t v69 = v102 | 0x8000000000000000;
      v67[4] = 0xD000000000000011;
      v67[5] = v69;
      swift_bridgeObjectRelease();
      OUTLINED_FUNCTION_2_27();
      ((void (*)(void))v64)();
      OUTLINED_FUNCTION_2_27();
      v61();
      uint64_t v60 = *(void (**)(void))(NeuralNetwork.layers.getter() + 16);
      swift_bridgeObjectRelease();
      swift_bridgeObjectRetain();
      uint64_t v61 = (void (*)(void))NeuralNetwork.layers.modify();
      uint64_t v67 = v70;
      uint64_t v71 = *v70;
      char v72 = swift_isUniquelyReferenced_nonNull_native();
      *uint64_t v67 = v71;
      if (v72)
      {
        if (v60) {
          goto LABEL_10;
        }
        goto LABEL_20;
      }
    }
    else
    {
      __break(1u);
    }
    specialized _ArrayBuffer._consumeAndCreateNew()();
    uint64_t v71 = v99;
    *uint64_t v67 = v99;
    if (v60)
    {
LABEL_10:
      if ((unint64_t)v60 <= *(void *)(v71 + 16))
      {
        uint64_t v60 = (void (*)(void))NeuralNetwork.Layer.outputNames.modify();
        uint64_t v67 = v73;
        uint64_t v74 = (void *)*v73;
        char v75 = swift_isUniquelyReferenced_nonNull_native();
        *uint64_t v67 = v74;
        if (v75) {
          goto LABEL_12;
        }
        goto LABEL_22;
      }
LABEL_21:
      __break(1u);
LABEL_22:
      specialized _ArrayBuffer._consumeAndCreateNew()();
      uint64_t v74 = v100;
      *uint64_t v67 = v100;
LABEL_12:
      uint64_t v76 = v126;
      uint64_t v77 = v121;
      id v78 = v117;
      if (v74[2])
      {
        uint64_t v79 = v129;
        v74[4] = v127;
        v74[5] = v79;
        swift_bridgeObjectRelease();
        OUTLINED_FUNCTION_2_27();
        v60();
        OUTLINED_FUNCTION_2_27();
        v61();
        uint64_t v81 = v118;
        uint64_t v80 = v119;
        uint64_t v82 = v120;
        (*(void (**)(uint64_t, void (*)(void), uint64_t))(v119 + 16))(v77, v118, v120);
        OUTLINED_FUNCTION_7_19();
        v83();
        Model.kind.setter();
        (*(void (**)(void (*)(void), uint64_t))(v80 + 8))(v81, v82);
        uint64_t v84 = *(void (**)(char *, void *))(v76 + 8);
        id v85 = v116;
        v84(v115, v116);
        v84(v78, v85);
        (*(void (**)(char *, uint64_t))(v104 + 8))(v103, v105);
      }
      else
      {
        __break(1u);
      }
      return;
    }
LABEL_20:
    __break(1u);
    goto LABEL_21;
  }
}

uint64_t static MLSoundClassifier.VGGishFeatureExtractor.buildCoreMLSpec(outputName:)(uint64_t a1, uint64_t a2)
{
  type metadata accessor for ModelKind();
  OUTLINED_FUNCTION_0();
  uint64_t v30 = v4;
  uint64_t v31 = v5;
  MEMORY[0x270FA5388](v4);
  OUTLINED_FUNCTION_3_0();
  uint64_t v8 = v7 - v6;
  uint64_t v9 = type metadata accessor for Model();
  OUTLINED_FUNCTION_0();
  uint64_t v11 = v10;
  MEMORY[0x270FA5388](v12);
  OUTLINED_FUNCTION_49();
  uint64_t v32 = (char *)v13;
  MEMORY[0x270FA5388](v14);
  uint64_t v16 = (char *)v28 - v15;
  Model.init()();
  Model.specificationVersion.setter();
  swift_bridgeObjectRetain();
  Model.predictedFeatureName.setter();
  OUTLINED_FUNCTION_20_1();
  Model.modelDescription.setter();
  uint64_t v17 = v33;
  static MLSoundClassifier.VGGishFeatureExtractor.buildSoundAnalysisPreprocessingSpec()((uint64_t)v16);
  if (v17)
  {
    OUTLINED_FUNCTION_24_5();
    return v18();
  }
  else
  {
    v28[1] = v8;
    uint64_t v29 = v16;
    uint64_t v33 = v9;
    static MLSoundClassifier.VGGishFeatureExtractor.buildFeatureEmbeddingNeuralNetworkSpec(outputName:)(a1, a2, (uint64_t)v32);
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Model>);
    v28[0] = *(void *)(v11 + 72);
    unint64_t v20 = (*(unsigned __int8 *)(v11 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v11 + 80);
    uint64_t v21 = swift_allocObject();
    *(_OWORD *)(v21 + 16) = xmmword_2272CB4D0;
    unint64_t v22 = v21 + v20;
    uint64_t v23 = *(void (**)(unint64_t, char *, uint64_t))(v11 + 16);
    uint64_t v24 = v29;
    uint64_t v25 = v33;
    v23(v22, v29, v33);
    v23(v22 + v28[0], v32, v25);
    PipelineClassifierConfiguration.init(models:names:)();
    OUTLINED_FUNCTION_7_19();
    v26();
    Model.kind.setter();
    Model.inputs.getter();
    Model.inputs.setter();
    Model.outputs.getter();
    Model.outputs.setter();
    uint64_t v27 = *(void (**)(void))(v11 + 8);
    OUTLINED_FUNCTION_24_5();
    v27();
    return ((uint64_t (*)(char *, uint64_t))v27)(v24, v25);
  }
}

uint64_t OUTLINED_FUNCTION_5_19()
{
  return v0;
}

uint64_t *initializeBufferWithCopyOfBuffer for MLLinearRegressor.PersistentParameters(uint64_t *a1, uint64_t *a2, int *a3)
{
  int v5 = *(_DWORD *)(*((void *)a3 - 1) + 80);
  if ((v5 & 0x20000) != 0)
  {
    uint64_t v13 = *a2;
    *a1 = *a2;
    a1 = (uint64_t *)(v13 + ((v5 + 16) & ~(unint64_t)v5));
    swift_retain();
  }
  else
  {
    uint64_t v7 = type metadata accessor for DataFrame();
    uint64_t v8 = *(void (**)(uint64_t *, uint64_t *, uint64_t))(*(void *)(v7 - 8) + 16);
    v8(a1, a2, v7);
    uint64_t v9 = a3[5];
    uint64_t v10 = (char *)a1 + v9;
    uint64_t v11 = (char *)a2 + v9;
    if (__swift_getEnumTagSinglePayload((uint64_t)a2 + v9, 1, v7))
    {
      uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
      memcpy(v10, v11, *(void *)(*(void *)(v12 - 8) + 64));
    }
    else
    {
      v8((uint64_t *)v10, (uint64_t *)v11, v7);
      __swift_storeEnumTagSinglePayload((uint64_t)v10, 0, 1, v7);
    }
    uint64_t v14 = a3[6];
    uint64_t v15 = a3[7];
    uint64_t v16 = (uint64_t *)((char *)a1 + v14);
    uint64_t v17 = (uint64_t *)((char *)a2 + v14);
    uint64_t v18 = v17[1];
    *uint64_t v16 = *v17;
    v16[1] = v18;
    *(uint64_t *)((char *)a1 + v15) = *(uint64_t *)((char *)a2 + v15);
    uint64_t v19 = a3[8];
    unint64_t v20 = (char *)a1 + v19;
    uint64_t v21 = (char *)a2 + v19;
    uint64_t v22 = *((void *)v21 + 3);
    swift_bridgeObjectRetain();
    swift_bridgeObjectRetain();
    if (v22)
    {
      *((void *)v20 + 3) = v22;
      (**(void (***)(char *, char *, uint64_t))(v22 - 8))(v20, v21, v22);
    }
    else
    {
      long long v23 = *((_OWORD *)v21 + 1);
      *(_OWORD *)unint64_t v20 = *(_OWORD *)v21;
      *((_OWORD *)v20 + 1) = v23;
    }
    long long v24 = *((_OWORD *)v21 + 3);
    *((_OWORD *)v20 + 2) = *((_OWORD *)v21 + 2);
    *((_OWORD *)v20 + 3) = v24;
    *((void *)v20 + 8) = *((void *)v21 + 8);
    v20[72] = v21[72];
  }
  return a1;
}

uint64_t destroy for MLLinearRegressor.PersistentParameters(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = type metadata accessor for DataFrame();
  int v5 = *(void (**)(uint64_t, uint64_t))(*(void *)(v4 - 8) + 8);
  v5(a1, v4);
  uint64_t v6 = a1 + *(int *)(a2 + 20);
  if (!__swift_getEnumTagSinglePayload(v6, 1, v4)) {
    v5(v6, v4);
  }
  swift_bridgeObjectRelease();
  swift_bridgeObjectRelease();
  uint64_t result = a1 + *(int *)(a2 + 32);
  if (*(void *)(result + 24))
  {
    return __swift_destroy_boxed_opaque_existential_0(result);
  }
  return result;
}

char *initializeWithCopy for MLLinearRegressor.PersistentParameters(char *a1, char *a2, int *a3)
{
  uint64_t v6 = type metadata accessor for DataFrame();
  uint64_t v7 = *(void (**)(void *, const void *, uint64_t))(*(void *)(v6 - 8) + 16);
  v7(a1, a2, v6);
  uint64_t v8 = a3[5];
  uint64_t v9 = &a1[v8];
  uint64_t v10 = &a2[v8];
  if (__swift_getEnumTagSinglePayload((uint64_t)&a2[v8], 1, v6))
  {
    uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
    memcpy(v9, v10, *(void *)(*(void *)(v11 - 8) + 64));
  }
  else
  {
    v7(v9, v10, v6);
    __swift_storeEnumTagSinglePayload((uint64_t)v9, 0, 1, v6);
  }
  uint64_t v12 = a3[6];
  uint64_t v13 = a3[7];
  uint64_t v14 = &a1[v12];
  uint64_t v15 = &a2[v12];
  uint64_t v16 = *((void *)v15 + 1);
  *(void *)uint64_t v14 = *(void *)v15;
  *((void *)v14 + 1) = v16;
  *(void *)&a1[v13] = *(void *)&a2[v13];
  uint64_t v17 = a3[8];
  uint64_t v18 = &a1[v17];
  uint64_t v19 = &a2[v17];
  uint64_t v20 = *((void *)v19 + 3);
  swift_bridgeObjectRetain();
  swift_bridgeObjectRetain();
  if (v20)
  {
    *((void *)v18 + 3) = v20;
    (**(void (***)(uint64_t, uint64_t, uint64_t))(v20 - 8))((uint64_t)v18, (uint64_t)v19, v20);
  }
  else
  {
    long long v21 = *((_OWORD *)v19 + 1);
    *(_OWORD *)uint64_t v18 = *(_OWORD *)v19;
    *((_OWORD *)v18 + 1) = v21;
  }
  long long v22 = *((_OWORD *)v19 + 3);
  *((_OWORD *)v18 + 2) = *((_OWORD *)v19 + 2);
  *((_OWORD *)v18 + 3) = v22;
  *((void *)v18 + 8) = *((void *)v19 + 8);
  v18[72] = v19[72];
  return a1;
}

char *assignWithCopy for MLLinearRegressor.PersistentParameters(char *a1, char *a2, int *a3)
{
  uint64_t v6 = type metadata accessor for DataFrame();
  uint64_t v7 = *(void *)(v6 - 8);
  uint64_t v8 = *(void (**)(void *, const void *, uint64_t))(v7 + 24);
  v8(a1, a2, v6);
  uint64_t v9 = a3[5];
  uint64_t v10 = &a1[v9];
  uint64_t v11 = &a2[v9];
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)&a1[v9], 1, v6);
  int v13 = __swift_getEnumTagSinglePayload((uint64_t)v11, 1, v6);
  if (EnumTagSinglePayload)
  {
    if (!v13)
    {
      (*(void (**)(char *, char *, uint64_t))(v7 + 16))(v10, v11, v6);
      __swift_storeEnumTagSinglePayload((uint64_t)v10, 0, 1, v6);
      goto LABEL_7;
    }
    goto LABEL_6;
  }
  if (v13)
  {
    (*(void (**)(char *, uint64_t))(v7 + 8))(v10, v6);
LABEL_6:
    uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
    memcpy(v10, v11, *(void *)(*(void *)(v14 - 8) + 64));
    goto LABEL_7;
  }
  v8(v10, v11, v6);
LABEL_7:
  uint64_t v15 = a3[6];
  uint64_t v16 = &a1[v15];
  uint64_t v17 = &a2[v15];
  *(void *)uint64_t v16 = *(void *)v17;
  *((void *)v16 + 1) = *((void *)v17 + 1);
  swift_bridgeObjectRetain();
  swift_bridgeObjectRelease();
  *(void *)&a1[a3[7]] = *(void *)&a2[a3[7]];
  swift_bridgeObjectRetain();
  swift_bridgeObjectRelease();
  uint64_t v18 = a3[8];
  uint64_t v19 = (uint64_t)&a1[v18];
  uint64_t v20 = &a2[v18];
  uint64_t v21 = *((void *)v20 + 3);
  if (!*(void *)&a1[v18 + 24])
  {
    if (v21)
    {
      *(void *)(v19 + 24) = v21;
      (**(void (***)(uint64_t, uint64_t))(v21 - 8))(v19, (uint64_t)v20);
      goto LABEL_14;
    }
LABEL_13:
    long long v22 = *((_OWORD *)v20 + 1);
    *(_OWORD *)uint64_t v19 = *(_OWORD *)v20;
    *(_OWORD *)(v19 + 16) = v22;
    goto LABEL_14;
  }
  if (!v21)
  {
    __swift_destroy_boxed_opaque_existential_0(v19);
    goto LABEL_13;
  }
  __swift_assign_boxed_opaque_existential_0((uint64_t *)v19, (uint64_t *)v20);
LABEL_14:
  *(void *)(v19 + 32) = *((void *)v20 + 4);
  *(void *)(v19 + 40) = *((void *)v20 + 5);
  *(void *)(v19 + 48) = *((void *)v20 + 6);
  *(void *)(v19 + 56) = *((void *)v20 + 7);
  *(void *)(v19 + 64) = *((void *)v20 + 8);
  *(unsigned char *)(v19 + 72) = v20[72];
  return a1;
}

char *assignWithTake for MLLinearRegressor.PersistentParameters(char *a1, char *a2, int *a3)
{
  uint64_t v6 = type metadata accessor for DataFrame();
  uint64_t v7 = *(void *)(v6 - 8);
  uint64_t v8 = *(void (**)(void *, const void *, uint64_t))(v7 + 40);
  v8(a1, a2, v6);
  uint64_t v9 = a3[5];
  uint64_t v10 = &a1[v9];
  uint64_t v11 = &a2[v9];
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)&a1[v9], 1, v6);
  int v13 = __swift_getEnumTagSinglePayload((uint64_t)v11, 1, v6);
  if (EnumTagSinglePayload)
  {
    if (!v13)
    {
      (*(void (**)(char *, char *, uint64_t))(v7 + 32))(v10, v11, v6);
      __swift_storeEnumTagSinglePayload((uint64_t)v10, 0, 1, v6);
      goto LABEL_7;
    }
    goto LABEL_6;
  }
  if (v13)
  {
    (*(void (**)(char *, uint64_t))(v7 + 8))(v10, v6);
LABEL_6:
    uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
    memcpy(v10, v11, *(void *)(*(void *)(v14 - 8) + 64));
    goto LABEL_7;
  }
  v8(v10, v11, v6);
LABEL_7:
  uint64_t v15 = a3[6];
  uint64_t v16 = &a1[v15];
  uint64_t v17 = (uint64_t *)&a2[v15];
  uint64_t v19 = *v17;
  uint64_t v18 = v17[1];
  *(void *)uint64_t v16 = v19;
  *((void *)v16 + 1) = v18;
  swift_bridgeObjectRelease();
  *(void *)&a1[a3[7]] = *(void *)&a2[a3[7]];
  swift_bridgeObjectRelease();
  uint64_t v20 = a3[8];
  uint64_t v21 = &a1[v20];
  if (*(void *)&a1[v20 + 24]) {
    __swift_destroy_boxed_opaque_existential_0((uint64_t)&a1[v20]);
  }
  long long v22 = *(_OWORD *)&a2[v20 + 16];
  *(_OWORD *)uint64_t v21 = *(_OWORD *)&a2[v20];
  *((_OWORD *)v21 + 1) = v22;
  *((void *)v21 + 4) = *(void *)&a2[v20 + 32];
  *(_OWORD *)(v21 + 40) = *(_OWORD *)&a2[v20 + 40];
  *(_OWORD *)(v21 + 56) = *(_OWORD *)&a2[v20 + 56];
  v21[72] = a2[v20 + 72];
  return a1;
}

uint64_t getEnumTagSinglePayload for MLLinearRegressor.PersistentParameters(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return MEMORY[0x270FA0340](a1, a2, a3, sub_227108460);
}

uint64_t sub_227108460(uint64_t a1, uint64_t a2, uint64_t a3)
{
  type metadata accessor for DataFrame();
  OUTLINED_FUNCTION_6_1();
  if (*(_DWORD *)(v7 + 84) == a2)
  {
    uint64_t v8 = v6;
    uint64_t v9 = a1;
LABEL_5:
    return __swift_getEnumTagSinglePayload(v9, a2, v8);
  }
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
  OUTLINED_FUNCTION_6_1();
  if (*(_DWORD *)(v11 + 84) == a2)
  {
    uint64_t v8 = v10;
    uint64_t v9 = a1 + *(int *)(a3 + 20);
    goto LABEL_5;
  }
  unint64_t v13 = *(void *)(a1 + *(int *)(a3 + 24) + 8);
  if (v13 >= 0xFFFFFFFF) {
    LODWORD(v13) = -1;
  }
  return (v13 + 1);
}

uint64_t storeEnumTagSinglePayload for MLLinearRegressor.PersistentParameters(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return MEMORY[0x270FA0580](a1, a2, a3, a4, sub_227108530);
}

void sub_227108530(uint64_t a1, uint64_t a2, int a3, uint64_t a4)
{
  type metadata accessor for DataFrame();
  OUTLINED_FUNCTION_6_1();
  if (*(_DWORD *)(v9 + 84) == a3)
  {
    uint64_t v10 = v8;
    uint64_t v11 = a1;
  }
  else
  {
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
    OUTLINED_FUNCTION_6_1();
    if (*(_DWORD *)(v13 + 84) != a3)
    {
      *(void *)(a1 + *(int *)(a4 + 24) + 8) = (a2 - 1);
      return;
    }
    uint64_t v10 = v12;
    uint64_t v11 = a1 + *(int *)(a4 + 20);
  }

  __swift_storeEnumTagSinglePayload(v11, a2, a2, v10);
}

uint64_t type metadata accessor for MLLinearRegressor.PersistentParameters()
{
  uint64_t result = type metadata singleton initialization cache for MLLinearRegressor.PersistentParameters;
  if (!type metadata singleton initialization cache for MLLinearRegressor.PersistentParameters) {
    return swift_getSingletonMetadata();
  }
  return result;
}

void type metadata completion function for MLLinearRegressor.PersistentParameters()
{
  type metadata accessor for DataFrame();
  if (v0 <= 0x3F)
  {
    type metadata accessor for DataFrame?();
    if (v1 <= 0x3F) {
      swift_initStructMetadata();
    }
  }
}

uint64_t _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lF11TabularData0D5FrameV_s5NeverO8CreateML17MLLinearRegressorV15ModelParametersV010ValidationD0OTg503_s8g4ML17ij13V20Persistentl48V16sessionDirectoryAE10Foundation3URLV_tKcfcAC05k5F0V14md3O07c5M00M5E17VcAMmcfu_AmPcfu0_AOXMtTf1ncn_n@<X0>(uint64_t a1@<X0>, uint64_t a2@<X8>)
{
  uint64_t v4 = type metadata accessor for DataFrame();
  uint64_t v5 = *(void *)(v4 - 8);
  MEMORY[0x270FA5388](v4);
  uint64_t v7 = (char *)v16 - ((v6 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
  MEMORY[0x270FA5388](v8 - 8);
  uint64_t v10 = (char *)v16 - ((v9 + 15) & 0xFFFFFFFFFFFFFFF0);
  outlined init with copy of DataFrame?(a1, (uint64_t)v10);
  if (__swift_getEnumTagSinglePayload((uint64_t)v10, 1, v4) == 1)
  {
    uint64_t v11 = type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData();
    uint64_t v12 = a2;
    uint64_t v13 = 1;
  }
  else
  {
    (*(void (**)(char *, char *, uint64_t))(v5 + 32))(v7, v10, v4);
    (*(void (**)(uint64_t, char *, uint64_t))(v5 + 16))(a2, v7, v4);
    uint64_t v14 = type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData();
    swift_storeEnumTagMultiPayload();
    (*(void (**)(char *, uint64_t))(v5 + 8))(v7, v4);
    uint64_t v12 = a2;
    uint64_t v13 = 0;
    uint64_t v11 = v14;
  }
  return __swift_storeEnumTagSinglePayload(v12, v13, 1, v11);
}

uint64_t MLLinearRegressor.PersistentParameters.init(sessionDirectory:)@<X0>(uint64_t a1@<X0>, uint64_t a2@<X8>)
{
  uint64_t v133 = a1;
  uint64_t v139 = *MEMORY[0x263EF8340];
  uint64_t v118 = type metadata accessor for CSVType();
  OUTLINED_FUNCTION_0();
  uint64_t v126 = v3;
  MEMORY[0x270FA5388](v4);
  OUTLINED_FUNCTION_33_0();
  OUTLINED_FUNCTION_17_3(v5);
  uint64_t v6 = type metadata accessor for CSVReadingOptions();
  uint64_t v7 = OUTLINED_FUNCTION_17(v6);
  MEMORY[0x270FA5388](v7);
  OUTLINED_FUNCTION_49();
  OUTLINED_FUNCTION_16_2();
  MEMORY[0x270FA5388](v8);
  OUTLINED_FUNCTION_106();
  uint64_t v115 = v9;
  uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLLinearRegressor.ModelParameters.ValidationData?);
  uint64_t v11 = OUTLINED_FUNCTION_17(v10);
  MEMORY[0x270FA5388](v11);
  OUTLINED_FUNCTION_33_0();
  uint64_t v124 = v12;
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
  uint64_t v14 = OUTLINED_FUNCTION_17(v13);
  MEMORY[0x270FA5388](v14);
  OUTLINED_FUNCTION_49();
  OUTLINED_FUNCTION_16_2();
  MEMORY[0x270FA5388](v15);
  OUTLINED_FUNCTION_106();
  OUTLINED_FUNCTION_17_3(v16);
  uint64_t v17 = type metadata accessor for DataFrame();
  OUTLINED_FUNCTION_0();
  uint64_t v117 = v18;
  MEMORY[0x270FA5388](v19);
  OUTLINED_FUNCTION_49();
  OUTLINED_FUNCTION_16_2();
  MEMORY[0x270FA5388](v20);
  OUTLINED_FUNCTION_106();
  OUTLINED_FUNCTION_17_3(v21);
  uint64_t v128 = type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v22);
  OUTLINED_FUNCTION_49();
  OUTLINED_FUNCTION_16_2();
  MEMORY[0x270FA5388](v23);
  OUTLINED_FUNCTION_16_2();
  MEMORY[0x270FA5388](v24);
  OUTLINED_FUNCTION_106();
  OUTLINED_FUNCTION_17_3(v25);
  uint64_t v26 = type metadata accessor for URL();
  OUTLINED_FUNCTION_0();
  uint64_t v131 = v27;
  MEMORY[0x270FA5388](v28);
  OUTLINED_FUNCTION_49();
  OUTLINED_FUNCTION_16_2();
  MEMORY[0x270FA5388](v29);
  OUTLINED_FUNCTION_16_2();
  uint64_t v31 = MEMORY[0x270FA5388](v30);
  uint64_t v33 = (char *)&v103 - v32;
  uint64_t v34 = MEMORY[0x270FA5388](v31);
  uint64_t v36 = (char *)&v103 - v35;
  uint64_t v37 = MEMORY[0x270FA5388](v34);
  uint64_t v39 = (char *)&v103 - v38;
  uint64_t v40 = MEMORY[0x270FA5388](v37);
  uint64_t v42 = (char *)&v103 - v41;
  MEMORY[0x270FA5388](v40);
  uint64_t v44 = (char *)&v103 - v43;
  uint64_t v45 = type metadata accessor for MLLinearRegressor.PersistentParameters();
  uint64_t v46 = *(int *)(v45 + 20);
  uint64_t v132 = a2;
  uint64_t v129 = a2 + v46;
  uint64_t v122 = v17;
  __swift_storeEnumTagSinglePayload(a2 + v46, 1, 1, v17);
  uint64_t v47 = v133;
  URL.appendingPathComponent(_:)();
  id v48 = v130;
  uint64_t v49 = Data.init(contentsOf:options:)();
  id v130 = v48;
  if (v48)
  {
    uint64_t v51 = *(void (**)(uint64_t, uint64_t))(v131 + 8);
    v51(v47, v26);
    v51((uint64_t)v44, v26);
    uint64_t v52 = v129;
    return outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v52, &demangling cache variable for type metadata for DataFrame?);
  }
  long long v107 = v36;
  uint64_t v106 = v33;
  uint64_t v108 = v39;
  uint64_t v109 = v42;
  uint64_t v114 = v45;
  uint64_t v53 = v131;
  uint64_t v54 = *(void (**)(void))(v131 + 8);
  uint64_t v55 = v49;
  unint64_t v56 = v50;
  OUTLINED_FUNCTION_24_5();
  v54();
  uint64_t v57 = self;
  uint64_t v58 = v26;
  Class isa = Data._bridgeToObjectiveC()().super.isa;
  *(void *)&long long v136 = 0;
  id v60 = objc_msgSend(v57, sel_propertyListWithData_options_format_error_, isa, 0, 0, &v136);

  id v61 = (id)v136;
  if (!v60)
  {
    id v85 = v61;
    _convertNSErrorToError(_:)();

    swift_willThrow();
    outlined consume of Data._Representation(v55, v56);
    OUTLINED_FUNCTION_24_5();
    v54();
LABEL_25:
    uint64_t v52 = v129;
    return outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v52, &demangling cache variable for type metadata for DataFrame?);
  }
  uint64_t v110 = v55;
  unint64_t v111 = v56;
  uint64_t v112 = v54;
  uint64_t v113 = v58;
  _bridgeAnyObjectToAny(_:)();
  swift_unknownObjectRelease();
  outlined init with copy of Any((uint64_t)v138, (uint64_t)&v136);
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String : Any]);
  if ((OUTLINED_FUNCTION_2_12() & 1) == 0)
  {
    lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError();
    OUTLINED_FUNCTION_19_0(v86, 0xD000000000000037);
    OUTLINED_FUNCTION_8_7();
    OUTLINED_FUNCTION_18_5();
    OUTLINED_FUNCTION_24_5();
    v87();
    __swift_destroy_boxed_opaque_existential_0((uint64_t)v138);
    goto LABEL_25;
  }
  uint64_t v62 = v134;
  specialized Dictionary.subscript.getter(0x746567726174, 0xE600000000000000, v134, &v136);
  if (!v137)
  {
    swift_bridgeObjectRelease();
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v136, &demangling cache variable for type metadata for Any?);
LABEL_28:
    uint64_t v52 = v129;
LABEL_34:
    lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError();
    OUTLINED_FUNCTION_19_0(v88, 0xD000000000000034);
    OUTLINED_FUNCTION_8_7();
    uint64_t v89 = OUTLINED_FUNCTION_18_5();
    v90(v89);
    __swift_destroy_boxed_opaque_existential_0((uint64_t)v138);
    return outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v52, &demangling cache variable for type metadata for DataFrame?);
  }
  if ((OUTLINED_FUNCTION_2_12() & 1) == 0)
  {
    swift_bridgeObjectRelease();
    goto LABEL_28;
  }
  uint64_t v64 = v134;
  uint64_t v63 = v135;
  OUTLINED_FUNCTION_15_6((uint64_t)"selectedFeatures");
  if (!v137)
  {
LABEL_30:
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v136, &demangling cache variable for type metadata for Any?);
LABEL_33:
    uint64_t v52 = v129;
    goto LABEL_34;
  }
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String]);
  if ((OUTLINED_FUNCTION_2_12() & 1) == 0)
  {
LABEL_32:
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    goto LABEL_33;
  }
  uint64_t v104 = v64;
  uint64_t v65 = v134;
  specialized Dictionary.subscript.getter(0x617265744978616DLL, 0xED0000736E6F6974, v62, &v136);
  if (!v137) {
    goto LABEL_29;
  }
  uint64_t v105 = v65;
  if ((OUTLINED_FUNCTION_2_12() & 1) == 0) {
    goto LABEL_31;
  }
  uint64_t v66 = v134;
  specialized Dictionary.subscript.getter(0x746C616E6550316CLL, 0xE900000000000079, v62, &v136);
  if (!v137) {
    goto LABEL_36;
  }
  if ((OUTLINED_FUNCTION_2_12() & 1) == 0)
  {
    OUTLINED_FUNCTION_17_6();
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    goto LABEL_33;
  }
  uint64_t v67 = v134;
  specialized Dictionary.subscript.getter(0x746C616E6550326CLL, 0xE900000000000079, v62, &v136);
  if (!v137)
  {
LABEL_36:
    OUTLINED_FUNCTION_17_6();
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v136, &demangling cache variable for type metadata for Any?);
    goto LABEL_33;
  }
  if ((OUTLINED_FUNCTION_2_12() & 1) == 0) {
    goto LABEL_31;
  }
  uint64_t v68 = v134;
  specialized Dictionary.subscript.getter(0x657A695370657473, 0xE800000000000000, v62, &v136);
  if (!v137)
  {
LABEL_29:
    swift_bridgeObjectRelease();
    goto LABEL_30;
  }
  if ((OUTLINED_FUNCTION_2_12() & 1) == 0)
  {
LABEL_31:
    OUTLINED_FUNCTION_17_6();
    goto LABEL_32;
  }
  uint64_t v103 = v66;
  uint64_t v69 = v134;
  specialized Dictionary.subscript.getter(0xD000000000000014, 0x80000002272D5A40, v62, &v136);
  if (!v137) {
    goto LABEL_29;
  }
  uint64_t v70 = v63;
  if ((OUTLINED_FUNCTION_2_12() & 1) == 0)
  {
    OUTLINED_FUNCTION_17_6();
    swift_bridgeObjectRelease();
LABEL_42:
    swift_bridgeObjectRelease();
    goto LABEL_33;
  }
  uint64_t v71 = v134;
  OUTLINED_FUNCTION_15_6((uint64_t)"featureRescaling");
  swift_bridgeObjectRelease();
  if (!v137)
  {
    OUTLINED_FUNCTION_17_6();
    swift_bridgeObjectRelease();
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v136, &demangling cache variable for type metadata for Any?);
    goto LABEL_33;
  }
  if ((OUTLINED_FUNCTION_2_12() & 1) == 0)
  {
    OUTLINED_FUNCTION_17_6();
    goto LABEL_42;
  }
  char v72 = v134;
  uint64_t v73 = v114;
  uint64_t v74 = v132;
  char v75 = (uint64_t *)(v132 + *(int *)(v114 + 24));
  *char v75 = v104;
  v75[1] = v70;
  *(void *)(v74 + *(int *)(v73 + 28)) = v105;
  uint64_t v76 = v121;
  void *v121 = 0;
  v76[1] = 0;
  *((_WORD *)v76 + 8) = 256;
  uint64_t v77 = v128;
  swift_storeEnumTagMultiPayload();
  id v78 = (void *)(v74 + *(int *)(v73 + 32));
  *(_OWORD *)id v78 = 0u;
  *((_OWORD *)v78 + 1) = 0u;
  v78[4] = 10;
  *(_OWORD *)(v78 + 5) = xmmword_2272CC8C0;
  *(_OWORD *)(v78 + 7) = xmmword_2272CC8D0;
  *((unsigned char *)v78 + 72) = 1;
  uint64_t v79 = v120;
  outlined init with copy of MLLinearRegressor.ModelParameters.ValidationData((uint64_t)v76, v120);
  uint64_t v137 = v77;
  boxed_opaque_existential_0 = __swift_allocate_boxed_opaque_existential_0((uint64_t *)&v136);
  outlined init with take of MLLinearRegressor.ModelParameters.ValidationData(v79, (uint64_t)boxed_opaque_existential_0);
  outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata((uint64_t)&v136, (uint64_t)v78, &demangling cache variable for type metadata for Any?);
  outlined destroy of MLLinearRegressor.ModelParameters.ValidationData((uint64_t)v76);
  v78[4] = v103;
  v78[5] = v67;
  v78[6] = v68;
  v78[7] = v69;
  v78[8] = v71;
  uint64_t v121 = v78;
  *((unsigned char *)v78 + 72) = v72;
  uint64_t v81 = v109;
  URL.appendingPathComponent(_:)();
  OUTLINED_FUNCTION_11_2();
  URL.appendingPathComponent(_:)();
  uint64_t v82 = *(void (**)(void))(v53 + 16);
  uint64_t v131 = v53 + 16;
  ((void (*)(char *, char *, uint64_t))v82)(v107, v81, v113);
  OUTLINED_FUNCTION_16_7();
  id v83 = v130;
  DataFrame.init(contentsOfSFrameDirectory:columns:rows:)();
  id v130 = v83;
  if (v83)
  {
    OUTLINED_FUNCTION_6_9();
    v82();
    specialized Dictionary.init(dictionaryLiteral:)(MEMORY[0x263F8EE78]);
    default argument 1 of CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:)();
    specialized Set.init(_nonEmptyArrayLiteral:)((uint64_t)&outlined read-only object #0 of default argument 2 of CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:));
    specialized Set.init(_nonEmptyArrayLiteral:)((uint64_t)&outlined read-only object #0 of default argument 3 of CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:));
    uint64_t v84 = *(void (**)(void))(v126 + 104);
    LODWORD(v127) = *MEMORY[0x263F1BF38];
    v126 += 104;
    uint64_t v125 = (void (*)(uint64_t, void, uint64_t))v84;
    v84(v119);
    CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:)();
    DataFrame.init(contentsOfCSVFile:columns:rows:types:options:)();
    OUTLINED_FUNCTION_23_2();
    OUTLINED_FUNCTION_20_5();
    v95();
    OUTLINED_FUNCTION_6_9();
    v82();
    specialized Dictionary.init(dictionaryLiteral:)(MEMORY[0x263F8EE78]);
    default argument 1 of CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:)();
    specialized Set.init(_nonEmptyArrayLiteral:)((uint64_t)&outlined read-only object #0 of default argument 2 of CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:));
    specialized Set.init(_nonEmptyArrayLiteral:)((uint64_t)&outlined read-only object #0 of default argument 3 of CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:));
    v125(v119, v127, v118);
    CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:)();
    OUTLINED_FUNCTION_16_7();
    DataFrame.init(contentsOfCSVFile:columns:rows:types:options:)();

    uint64_t v96 = v116;
    __swift_storeEnumTagSinglePayload(v116, 0, 1, v122);
    uint64_t v127 = v96;
  }
  else
  {
    OUTLINED_FUNCTION_23_2();
    OUTLINED_FUNCTION_20_5();
    v92();
    OUTLINED_FUNCTION_6_9();
    v82();
    id v93 = v130;
    DataFrame.init(contentsOfSFrameDirectory:columns:rows:)();
    if (v93)
    {

      uint64_t v94 = 1;
    }
    else
    {
      uint64_t v94 = 0;
    }
    __swift_storeEnumTagSinglePayload(v127, v94, 1, v122);
  }
  uint64_t v97 = v129;
  outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v127, v129, &demangling cache variable for type metadata for DataFrame?);
  uint64_t v98 = v124;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lF11TabularData0D5FrameV_s5NeverO8CreateML17MLLinearRegressorV15ModelParametersV010ValidationD0OTg503_s8g4ML17ij13V20Persistentl48V16sessionDirectoryAE10Foundation3URLV_tKcfcAC05k5F0V14md3O07c5M00M5E17VcAMmcfu_AmPcfu0_AOXMtTf1ncn_n(v97, v124);
  if (__swift_getEnumTagSinglePayload(v98, 1, v128) == 1)
  {
    swift_storeEnumTagMultiPayload();
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v124, &demangling cache variable for type metadata for MLLinearRegressor.ModelParameters.ValidationData?);
  }
  else
  {
    outlined init with take of MLLinearRegressor.ModelParameters.ValidationData(v124, v123);
  }
  uint64_t v137 = v128;
  uint64_t v99 = __swift_allocate_boxed_opaque_existential_0((uint64_t *)&v136);
  outlined init with take of MLLinearRegressor.ModelParameters.ValidationData(v123, (uint64_t)v99);
  outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata((uint64_t)&v136, (uint64_t)v121, &demangling cache variable for type metadata for Any?);
  OUTLINED_FUNCTION_8_7();
  uint64_t v100 = v112;
  OUTLINED_FUNCTION_24_5();
  v100();
  uint64_t v101 = OUTLINED_FUNCTION_7_11((uint64_t)&v135);
  ((void (*)(uint64_t))v100)(v101);
  uint64_t v102 = OUTLINED_FUNCTION_7_11((uint64_t)&v136);
  ((void (*)(uint64_t))v100)(v102);
  return __swift_destroy_boxed_opaque_existential_0((uint64_t)v138);
}

uint64_t outlined destroy of MLLinearRegressor.ModelParameters(uint64_t a1)
{
  return a1;
}

uint64_t MLLinearRegressor.PersistentParameters.save(toSessionDirectory:)(uint64_t a1)
{
  uint64_t v2 = v1;
  uint64_t v57 = a1;
  v59[53] = *(id *)MEMORY[0x263EF8340];
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
  uint64_t v4 = OUTLINED_FUNCTION_17(v3);
  MEMORY[0x270FA5388](v4);
  OUTLINED_FUNCTION_33_0();
  uint64_t v50 = v5;
  type metadata accessor for CSVWritingOptions();
  OUTLINED_FUNCTION_0();
  uint64_t v53 = v6;
  uint64_t v54 = v7;
  MEMORY[0x270FA5388](v6);
  OUTLINED_FUNCTION_49();
  uint64_t v49 = v8;
  MEMORY[0x270FA5388](v9);
  OUTLINED_FUNCTION_106();
  uint64_t v52 = v10;
  uint64_t v58 = type metadata accessor for URL();
  OUTLINED_FUNCTION_0();
  uint64_t v56 = v11;
  MEMORY[0x270FA5388](v12);
  OUTLINED_FUNCTION_49();
  uint64_t v48 = v13;
  uint64_t v15 = MEMORY[0x270FA5388](v14);
  uint64_t v51 = (char *)&v46 - v16;
  MEMORY[0x270FA5388](v15);
  uint64_t v18 = (char *)&v46 - v17;
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, Any)>);
  uint64_t inited = swift_initStackObject();
  *(_OWORD *)(inited + 16) = xmmword_2272CB4C0;
  *(void *)(inited + 32) = 0x746567726174;
  *(void *)(inited + 40) = 0xE600000000000000;
  uint64_t v20 = (int *)type metadata accessor for MLLinearRegressor.PersistentParameters();
  uint64_t v21 = (void *)(v2 + v20[6]);
  uint64_t v22 = v21[1];
  uint64_t v23 = MEMORY[0x263F8D310];
  *(void *)(inited + 48) = *v21;
  *(void *)(inited + 56) = v22;
  *(void *)(inited + 72) = v23;
  *(void *)(inited + 80) = 0xD000000000000010;
  *(void *)(inited + 88) = 0x80000002272D4EF0;
  uint64_t v24 = *(void *)(v2 + v20[7]);
  uint64_t v25 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String]);
  *(void *)(inited + 96) = v24;
  *(void *)(inited + 120) = v25;
  strcpy((char *)(inited + 128), "maxIterations");
  *(_WORD *)(inited + 142) = -4864;
  uint64_t v26 = v2 + v20[8];
  uint64_t v27 = MEMORY[0x263F8D6C8];
  *(void *)(inited + 144) = *(void *)(v26 + 32);
  *(void *)(inited + 168) = v27;
  *(void *)(inited + 176) = 0x746C616E6550316CLL;
  *(void *)(inited + 184) = 0xE900000000000079;
  uint64_t v28 = MEMORY[0x263F8D538];
  *(void *)(inited + 192) = *(void *)(v26 + 40);
  *(void *)(inited + 216) = v28;
  *(void *)(inited + 224) = 0x746C616E6550326CLL;
  *(void *)(inited + 232) = 0xE900000000000079;
  *(void *)(inited + 240) = *(void *)(v26 + 48);
  *(void *)(inited + 264) = v28;
  *(void *)(inited + 272) = 0x657A695370657473;
  *(void *)(inited + 280) = 0xE800000000000000;
  *(void *)(inited + 288) = *(void *)(v26 + 56);
  *(void *)(inited + 312) = v28;
  *(void *)(inited + 320) = 0xD000000000000014;
  *(void *)(inited + 328) = 0x80000002272D5A40;
  *(void *)(inited + 336) = *(void *)(v26 + 64);
  *(void *)(inited + 360) = v28;
  *(void *)(inited + 368) = 0xD000000000000010;
  *(void *)(inited + 376) = 0x80000002272D5A60;
  LOBYTE(v26) = *(unsigned char *)(v26 + 72);
  *(void *)(inited + 408) = MEMORY[0x263F8D4F8];
  *(unsigned char *)(inited + 384) = v26;
  swift_bridgeObjectRetain();
  swift_bridgeObjectRetain();
  OUTLINED_FUNCTION_24_6();
  Dictionary.init(dictionaryLiteral:)();
  uint64_t v29 = self;
  OUTLINED_FUNCTION_24_6();
  Class isa = Dictionary._bridgeToObjectiveC()().super.isa;
  swift_bridgeObjectRelease();
  v59[0] = 0;
  id v31 = objc_msgSend(v29, sel_dataWithPropertyList_format_options_error_, isa, 200, 0, v59);

  id v32 = v59[0];
  if (v31)
  {
    uint64_t v33 = static Data._unconditionallyBridgeFromObjectiveC(_:)();
    unint64_t v35 = v34;

    URL.appendingPathComponent(_:)();
    unint64_t v36 = v55;
    Data.write(to:options:)();
    if (v36)
    {
      (*(void (**)(char *, uint64_t))(v56 + 8))(v18, v58);
      return outlined consume of Data._Representation(v33, v35);
    }
    else
    {
      unint64_t v55 = v35;
      uint64_t v56 = *(void *)(v56 + 8);
      OUTLINED_FUNCTION_21_4();
      v39();
      URL.appendingPathComponent(_:)();
      OUTLINED_FUNCTION_12_3();
      uint64_t v40 = v52;
      OUTLINED_FUNCTION_5_10();
      uint64_t v47 = type metadata accessor for DataFrame();
      DataFrameProtocol.writeCSV(to:options:)();
      uint64_t v41 = v54 + 8;
      uint64_t v52 = *(void (**)(void, void))(v54 + 8);
      v52(v40, v53);
      uint64_t v42 = (void (*)(void))v56;
      OUTLINED_FUNCTION_21_4();
      v42();
      uint64_t v43 = v2 + v20[5];
      uint64_t v44 = v50;
      outlined init with copy of DataFrame?(v43, v50);
      if (__swift_getEnumTagSinglePayload(v44, 1, v47) == 1)
      {
        outlined consume of Data._Representation(v33, v55);
        return outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v44, &demangling cache variable for type metadata for DataFrame?);
      }
      else
      {
        uint64_t v54 = v41;
        OUTLINED_FUNCTION_11_2();
        URL.appendingPathComponent(_:)();
        OUTLINED_FUNCTION_12_3();
        uint64_t v45 = v49;
        OUTLINED_FUNCTION_5_10();
        DataFrameProtocol.writeCSV(to:options:)();
        outlined consume of Data._Representation(v33, v55);
        v52(v45, v53);
        OUTLINED_FUNCTION_21_4();
        v42();
        return (*(uint64_t (**)(uint64_t))(*(void *)(v47 - 8) + 8))(v44);
      }
    }
  }
  else
  {
    uint64_t v38 = v32;
    _convertNSErrorToError(_:)();

    return swift_willThrow();
  }
}

void MLRegressorMetrics.init(maximumError:rootMeanSquaredError:)(uint64_t a1@<X8>, double a2@<D0>, double a3@<D1>)
{
  *(double *)a1 = a2;
  *(double *)(a1 + 8) = a3;
  *(unsigned char *)(a1 + 16) = 0;
}

unint64_t MLRegressorMetrics.description.getter()
{
  unint64_t v1 = 0xD000000000000038;
  if ((*(unsigned char *)(v0 + 16) & 1) == 0)
  {
    double v2 = *(double *)v0;
    if (*(double *)v0 >= 0.0)
    {
      double v3 = *(double *)(v0 + 8);
      if (v3 >= 0.0)
      {
        __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
        uint64_t v4 = OUTLINED_FUNCTION_9_8();
        *(_OWORD *)(v4 + 16) = xmmword_2272CB370;
        uint64_t v5 = MEMORY[0x263F8D538];
        uint64_t v6 = MEMORY[0x263F8D5B8];
        *(void *)(v4 + 56) = MEMORY[0x263F8D538];
        *(void *)(v4 + 64) = v6;
        *(double *)(v4 + 32) = v2;
        uint64_t v7 = String.init(format:_:)();
        uint64_t v8 = OUTLINED_FUNCTION_9_8();
        *(_OWORD *)(v8 + 16) = xmmword_2272CB370;
        *(void *)(v8 + 56) = v5;
        *(void *)(v8 + 64) = v6;
        *(double *)(v8 + 32) = v3;
        uint64_t v9 = String.init(format:_:)();
        uint64_t v11 = v10;
        swift_bridgeObjectRetain();
        v12._uint64_t countAndFlagsBits = v9;
        v12._uint64_t object = v11;
        String.append(_:)(v12);
        swift_bridgeObjectRelease();
        swift_bridgeObjectRelease();
        return v7;
      }
    }
  }
  return v1;
}

BOOL MLRegressorMetrics.isValid.getter()
{
  return (*(unsigned char *)(v0 + 16) & 1) == 0;
}

id MLRegressorMetrics.error.getter()
{
  if (*(unsigned char *)(v0 + 16) != 1) {
    return 0;
  }
  id v1 = *(id *)v0;
  id v2 = *(id *)v0;
  return v1;
}

double MLRegressorMetrics.maximumError.getter()
{
  double result = -1.0;
  if ((v0[16] & 1) == 0) {
    return *(double *)v0;
  }
  return result;
}

double MLRegressorMetrics.rootMeanSquaredError.getter()
{
  double result = -1.0;
  if ((*(unsigned char *)(v0 + 16) & 1) == 0) {
    return *(double *)(v0 + 8);
  }
  return result;
}

unint64_t MLRegressorMetrics.debugDescription.getter()
{
  double v2 = *(double *)v0;
  double v1 = *(double *)(v0 + 8);
  char v3 = *(unsigned char *)(v0 + 16);
  if (v3)
  {
    id v4 = *(id *)&v2;
  }
  else if (v2 >= 0.0 && v1 >= 0.0)
  {
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
    uint64_t v5 = OUTLINED_FUNCTION_9_8();
    uint64_t v6 = MEMORY[0x263F8D538];
    *(_OWORD *)(v5 + 16) = xmmword_2272CB370;
    uint64_t v7 = MEMORY[0x263F8D5B8];
    *(void *)(v5 + 56) = v6;
    *(void *)(v5 + 64) = v7;
    *(double *)(v5 + 32) = v2;
    uint64_t v8 = String.init(format:_:)();
    uint64_t v9 = OUTLINED_FUNCTION_9_8();
    *(_OWORD *)(v9 + 16) = xmmword_2272CB370;
    *(void *)(v9 + 56) = v6;
    *(void *)(v9 + 64) = v7;
    *(double *)(v9 + 32) = v1;
    uint64_t v10 = String.init(format:_:)();
    Swift::String v12 = v11;
    swift_bridgeObjectRetain();
    v13._uint64_t countAndFlagsBits = v10;
    v13._uint64_t object = v12;
    String.append(_:)(v13);
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    outlined consume of Result<_RegressorMetrics, Error>(*(id *)&v2, *(uint64_t *)&v1, 0);
    return v8;
  }
  outlined consume of Result<_RegressorMetrics, Error>(*(id *)&v2, *(uint64_t *)&v1, v3);
  return 0xD000000000000038;
}

unint64_t MLRegressorMetrics.playgroundDescription.getter@<X0>(void *a1@<X8>)
{
  unint64_t v2 = MLRegressorMetrics.description.getter();
  uint64_t v4 = v3;
  id v5 = objc_allocWithZone(MEMORY[0x263F086A0]);
  id v6 = @nonobjc NSAttributedString.init(string:attributes:)(v2, v4, 0);
  unint64_t result = type metadata accessor for NSAttributedString();
  a1[3] = result;
  *a1 = v6;
  return result;
}

void destroy for MLRegressorMetrics(uint64_t a1)
{
}

uint64_t initializeBufferWithCopyOfBuffer for MLRegressorMetrics(uint64_t a1, uint64_t a2)
{
  id v3 = *(id *)a2;
  uint64_t v4 = *(void *)(a2 + 8);
  char v5 = *(unsigned char *)(a2 + 16);
  outlined copy of Result<_RegressorMetrics, Error>(*(id *)a2, v4, v5);
  *(void *)a1 = v3;
  *(void *)(a1 + 8) = v4;
  *(unsigned char *)(a1 + 16) = v5;
  return a1;
}

uint64_t assignWithCopy for MLRegressorMetrics(uint64_t a1, uint64_t a2)
{
  id v3 = *(id *)a2;
  uint64_t v4 = *(void *)(a2 + 8);
  char v5 = *(unsigned char *)(a2 + 16);
  outlined copy of Result<_RegressorMetrics, Error>(*(id *)a2, v4, v5);
  id v6 = *(void **)a1;
  uint64_t v7 = *(void *)(a1 + 8);
  char v8 = *(unsigned char *)(a1 + 16);
  *(void *)a1 = v3;
  *(void *)(a1 + 8) = v4;
  *(unsigned char *)(a1 + 16) = v5;
  outlined consume of Result<_RegressorMetrics, Error>(v6, v7, v8);
  return a1;
}

__n128 __swift_memcpy17_8(__n128 *a1, __n128 *a2)
{
  __n128 result = *a2;
  a1[1].n128_u8[0] = a2[1].n128_u8[0];
  *a1 = result;
  return result;
}

uint64_t assignWithTake for MLRegressorMetrics(uint64_t a1, uint64_t a2)
{
  char v3 = *(unsigned char *)(a2 + 16);
  uint64_t v4 = *(void **)a1;
  uint64_t v5 = *(void *)(a1 + 8);
  char v6 = *(unsigned char *)(a1 + 16);
  *(_OWORD *)a1 = *(_OWORD *)a2;
  *(unsigned char *)(a1 + 16) = v3;
  outlined consume of Result<_RegressorMetrics, Error>(v4, v5, v6);
  return a1;
}

uint64_t getEnumTagSinglePayload for MLRegressorMetrics(uint64_t a1, unsigned int a2)
{
  if (a2)
  {
    if (a2 >= 0xFF && *(unsigned char *)(a1 + 17))
    {
      int v2 = *(_DWORD *)a1 + 254;
    }
    else
    {
      unsigned int v3 = *(unsigned __int8 *)(a1 + 16);
      if (v3 <= 1) {
        int v2 = -1;
      }
      else {
        int v2 = v3 ^ 0xFF;
      }
    }
  }
  else
  {
    int v2 = -1;
  }
  return (v2 + 1);
}

uint64_t storeEnumTagSinglePayload for MLRegressorMetrics(uint64_t result, unsigned int a2, unsigned int a3)
{
  if (a2 > 0xFE)
  {
    *(unsigned char *)(result + 16) = 0;
    *(void *)__n128 result = a2 - 255;
    *(void *)(result + 8) = 0;
    if (a3 >= 0xFF) {
      *(unsigned char *)(result + 17) = 1;
    }
  }
  else
  {
    if (a3 >= 0xFF) {
      *(unsigned char *)(result + 17) = 0;
    }
    if (a2) {
      *(unsigned char *)(result + 16) = -(char)a2;
    }
  }
  return result;
}

ValueMetadata *type metadata accessor for MLRegressorMetrics()
{
  return &type metadata for MLRegressorMetrics;
}

void *type metadata accessor for _RegressorMetrics()
{
  return &unk_26DB41F68;
}

uint64_t LabelEncoder<>.encode(to:)(void *a1, uint64_t a2)
{
  __swift_project_boxed_opaque_existential_1(a1, a1[3]);
  dispatch thunk of Encoder.singleValueContainer()();
  uint64_t v6 = a2;
  __swift_mutable_project_boxed_opaque_existential_1((uint64_t)v4, v5);
  type metadata accessor for Array();
  swift_getWitnessTable();
  dispatch thunk of SingleValueEncodingContainer.encode<A>(_:)();
  return __swift_destroy_boxed_opaque_existential_0((uint64_t)v4);
}

uint64_t protocol witness for Encodable.encode(to:) in conformance <> LabelEncoder<A>(void *a1)
{
  return LabelEncoder<>.encode(to:)(a1, *v1);
}

uint64_t LabelEncoder<>.init(from:)(void *a1)
{
  uint64_t v3 = (uint64_t)__swift_project_boxed_opaque_existential_1(a1, a1[3]);
  dispatch thunk of Decoder.singleValueContainer()();
  if (!v1)
  {
    __swift_project_boxed_opaque_existential_1(v5, v5[3]);
    type metadata accessor for Array();
    swift_getWitnessTable();
    dispatch thunk of SingleValueDecodingContainer.decode<A>(_:)();
    swift_getWitnessTable();
    Set.init<A>(_:)();
    uint64_t v3 = SortedSet.init(_:)();
    __swift_destroy_boxed_opaque_existential_0((uint64_t)v5);
  }
  __swift_destroy_boxed_opaque_existential_0((uint64_t)a1);
  return v3;
}

uint64_t protocol witness for Decodable.init(from:) in conformance <> LabelEncoder<A>@<X0>(void *a1@<X0>, uint64_t *a2@<X8>)
{
  uint64_t result = LabelEncoder<>.init(from:)(a1);
  if (!v2)
  {
    *a2 = result;
    a2[1] = v5;
  }
  return result;
}

uint64_t type metadata accessor for LabelEncoder()
{
  return __swift_instantiateGenericMetadata();
}

unint64_t MLSoundClassifier.ModelParameters.ClassifierType.description.getter()
{
  return 0xD000000000000012;
}

uint64_t static MLSoundClassifier.ModelParameters.ClassifierType.== infix(_:_:)()
{
  return 1;
}

void MLSoundClassifier.ModelParameters.ClassifierType.hash(into:)()
{
}

Swift::Int MLSoundClassifier.ModelParameters.ClassifierType.hashValue.getter()
{
  return Hasher._finalize()();
}

Swift::Int protocol witness for Hashable.hashValue.getter in conformance MLSoundClassifier.ModelParameters.ClassifierType()
{
  return MLSoundClassifier.ModelParameters.ClassifierType.hashValue.getter();
}

void protocol witness for Hashable.hash(into:) in conformance MLSoundClassifier.ModelParameters.ClassifierType()
{
}

unint64_t lazy protocol witness table accessor for type MLSoundClassifier.ModelParameters.ClassifierType and conformance MLSoundClassifier.ModelParameters.ClassifierType()
{
  unint64_t result = lazy protocol witness table cache variable for type MLSoundClassifier.ModelParameters.ClassifierType and conformance MLSoundClassifier.ModelParameters.ClassifierType;
  if (!lazy protocol witness table cache variable for type MLSoundClassifier.ModelParameters.ClassifierType and conformance MLSoundClassifier.ModelParameters.ClassifierType)
  {
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type MLSoundClassifier.ModelParameters.ClassifierType and conformance MLSoundClassifier.ModelParameters.ClassifierType);
  }
  return result;
}

unint64_t protocol witness for CustomStringConvertible.description.getter in conformance MLSoundClassifier.ModelParameters.ClassifierType()
{
  return 0xD000000000000012;
}

unsigned char *storeEnumTagSinglePayload for MLSoundClassifier.ModelParameters.ClassifierType(unsigned char *result, int a2, int a3)
{
  if ((a3 + 1) >= 0x10000) {
    int v3 = 4;
  }
  else {
    int v3 = 2;
  }
  if ((a3 + 1) < 0x100) {
    unsigned int v4 = 1;
  }
  else {
    unsigned int v4 = v3;
  }
  if (a3) {
    uint64_t v5 = v4;
  }
  else {
    uint64_t v5 = 0;
  }
  if (a2)
  {
    switch(v5)
    {
      case 1:
        *unint64_t result = a2;
        return result;
      case 2:
        *(_WORD *)unint64_t result = a2;
        return result;
      case 3:
        goto LABEL_19;
      case 4:
        *(_DWORD *)unint64_t result = a2;
        return result;
      default:
        return result;
    }
  }
  switch(v5)
  {
    case 1:
      *unint64_t result = 0;
      break;
    case 2:
      *(_WORD *)unint64_t result = 0;
      break;
    case 3:
LABEL_19:
      __break(1u);
      JUMPOUT(0x22710A970);
    case 4:
      *(_DWORD *)unint64_t result = 0;
      break;
    default:
      return result;
  }
  return result;
}

ValueMetadata *type metadata accessor for MLSoundClassifier.ModelParameters.ClassifierType()
{
  return &type metadata for MLSoundClassifier.ModelParameters.ClassifierType;
}

uint64_t _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay8CreateML16ColumnDescriptorVG_20MLModelSpecification18FeatureDescriptionVs5NeverOTg503_s8d50ML18TreeRegressorModelV6export16internalMetadata20h33Specification0E0VSDyS2SGz_tKFAF18jk5VAA16fG54Vcfu0_33_3fd57c9cf8bb5b882e179ce0f1f8c55eAmKTf3nnnpk_nTf1cn_n(uint64_t a1)
{
  uint64_t v17 = type metadata accessor for FeatureDescription();
  uint64_t v3 = *(void *)(v17 - 8);
  MEMORY[0x270FA5388](v17);
  uint64_t v5 = (char *)v16 - ((v4 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v6 = *(void *)(a1 + 16);
  uint64_t v7 = MEMORY[0x263F8EE78];
  if (v6)
  {
    v16[1] = v1;
    uint64_t v18 = MEMORY[0x263F8EE78];
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v6, 0);
    uint64_t v7 = v18;
    void v16[2] = v3 + 32;
    char v8 = (char *)(a1 + 56);
    do
    {
      uint64_t v9 = *((void *)v8 - 3);
      uint64_t v10 = *((void *)v8 - 2);
      uint64_t v11 = *((void *)v8 - 1);
      char v12 = *v8;
      swift_bridgeObjectRetain();
      outlined copy of ColumnDescriptor.ColumnTypeDescriptor(v11, v12);
      ColumnDescriptor.featureDescription.getter(v9, v10, v11, v12);
      swift_bridgeObjectRelease();
      outlined consume of ColumnDescriptor.ColumnTypeDescriptor(v11, v12);
      uint64_t v18 = v7;
      unint64_t v14 = *(void *)(v7 + 16);
      unint64_t v13 = *(void *)(v7 + 24);
      if (v14 >= v13 >> 1)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v13 > 1, v14 + 1, 1);
        uint64_t v7 = v18;
      }
      v8 += 32;
      *(void *)(v7 + 16) = v14 + 1;
      (*(void (**)(unint64_t, char *, uint64_t))(v3 + 32))(v7+ ((*(unsigned __int8 *)(v3 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v3 + 80))+ *(void *)(v3 + 72) * v14, v5, v17);
      --v6;
    }
    while (v6);
  }
  return v7;
}

void TreeRegressorModel.export(internalMetadata:)(uint64_t a1@<X8>)
{
  uint64_t v74 = a1;
  uint64_t v3 = type metadata accessor for ModelKind();
  OUTLINED_FUNCTION_0();
  uint64_t v73 = v4;
  MEMORY[0x270FA5388](v5);
  OUTLINED_FUNCTION_33_0();
  uint64_t v72 = v6;
  type metadata accessor for FeatureType();
  OUTLINED_FUNCTION_0();
  uint64_t v69 = v8;
  uint64_t v70 = v7;
  MEMORY[0x270FA5388](v7);
  OUTLINED_FUNCTION_33_0();
  uint64_t v68 = v9;
  uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Model?);
  MEMORY[0x270FA5388](v10 - 8);
  OUTLINED_FUNCTION_33_0();
  uint64_t v67 = v11;
  type metadata accessor for Model();
  OUTLINED_FUNCTION_0();
  uint64_t v75 = v13;
  uint64_t v76 = v12;
  MEMORY[0x270FA5388](v12);
  OUTLINED_FUNCTION_49();
  uint64_t v71 = v14;
  MEMORY[0x270FA5388](v15);
  id v78 = (char *)v63 - v16;
  uint64_t v81 = type metadata accessor for URL.DirectoryHint();
  OUTLINED_FUNCTION_0();
  *(void *)&long long v80 = v17;
  MEMORY[0x270FA5388](v18);
  uint64_t v20 = (char *)v63 - ((v19 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v21 = type metadata accessor for UUID();
  OUTLINED_FUNCTION_0();
  uint64_t v79 = v22;
  MEMORY[0x270FA5388](v23);
  uint64_t v25 = (char *)v63 - ((v24 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v84 = type metadata accessor for URL();
  OUTLINED_FUNCTION_0();
  uint64_t v82 = v26;
  MEMORY[0x270FA5388](v27);
  OUTLINED_FUNCTION_49();
  uint64_t v77 = v28;
  uint64_t v30 = MEMORY[0x270FA5388](v29);
  uint64_t v31 = MEMORY[0x270FA5388](v30);
  MEMORY[0x270FA5388](v31);
  id v83 = (char *)v63 - v32;
  uint64_t v33 = *(void *)(v1 + 16);
  if (!v33) {
    goto LABEL_9;
  }
  Swift::Int v34 = specialized FeatureVectorizer.Transformer.exportEncoders()(*(void *)(v1 + 16), *(void *)(v1 + 24), *(void (**)(void))(v1 + 32));
  if (v2) {
    return;
  }
  v63[1] = v33;
  Swift::Int v66 = v34;
  uint64_t v65 = v1;
  uint64_t v64 = v3;
  unint64_t v35 = self;
  id v36 = objc_msgSend(v35, sel_defaultManager);
  NSFileManager.createTemporaryModelDirectory()();
  if (v37)
  {
    swift_bridgeObjectRelease();

    return;
  }

  id v38 = objc_msgSend(v35, sel_defaultManager);
  NSFileManager.temporaryModelDirectory.getter();

  UUID.init()();
  uint64_t v39 = UUID.uuidString.getter();
  uint64_t v41 = v40;
  (*(void (**)(char *, uint64_t))(v79 + 8))(v25, v21);
  uint64_t v85 = v39;
  uint64_t v86 = v41;
  uint64_t v42 = v80;
  uint64_t v43 = v81;
  (*(void (**)(char *, void, uint64_t))(v80 + 104))(v20, *MEMORY[0x263F06E50], v81);
  lazy protocol witness table accessor for type String and conformance String();
  URL.appending<A>(component:directoryHint:)();
  (*(void (**)(char *, uint64_t))(v42 + 8))(v20, v43);
  swift_bridgeObjectRelease();
  uint64_t v44 = (void (**)(void, char *, uint64_t))v82;
  uint64_t v45 = (void (*)(void))*((void *)v82 + 1);
  uint64_t v46 = v84;
  OUTLINED_FUNCTION_2_28();
  v45();
  uint64_t v47 = v83;
  URL.appendingPathExtension(_:)();
  OUTLINED_FUNCTION_2_28();
  v45();
  type metadata accessor for TreeRegressorModel();
  BaseTreeRegressorModel.export(to:)();
  v44[2](v77, v47, v46);
  Model.init(contentsOf:)();
  uint64_t v48 = v67;
  specialized BidirectionalCollection.last.getter(v66);
  uint64_t v49 = v76;
  if (__swift_getEnumTagSinglePayload(v48, 1, v76) == 1)
  {
    __break(1u);
LABEL_9:
    _assertionFailure(_:_:file:line:flags:)();
    __break(1u);
    return;
  }
  Model.outputs.getter();
  uint64_t v50 = *(void (**)(void, void))(v75 + 8);
  uint64_t v81 = v75 + 8;
  uint64_t v82 = v50;
  v50(v48, v49);
  Model.inputs.setter();
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<FeatureDescription>);
  type metadata accessor for FeatureDescription();
  uint64_t v51 = swift_allocObject();
  long long v80 = xmmword_2272CB370;
  *(_OWORD *)(v51 + 16) = xmmword_2272CB370;
  swift_bridgeObjectRetain();
  uint64_t v52 = v68;
  FeatureType.DoubleParameters.init(optional:)();
  (*(void (**)(uint64_t, void, uint64_t))(v69 + 104))(v52, *MEMORY[0x263F531C8], v70);
  FeatureDescription.init(name:type:description:)();
  uint64_t v53 = v78;
  Model.outputs.setter();
  swift_bridgeObjectRetain();
  uint64_t v54 = v53;
  Model.predictedFeatureName.setter();
  Dictionary.init(dictionaryLiteral:)();
  Model.metadata.setter();
  uint64_t v55 = v71;
  Model.init()();
  Model.specificationVersion.setter();
  uint64_t v56 = swift_bridgeObjectRetain();
  _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay8CreateML16ColumnDescriptorVG_20MLModelSpecification18FeatureDescriptionVs5NeverOTg503_s8d50ML18TreeRegressorModelV6export16internalMetadata20h33Specification0E0VSDyS2SGz_tKFAF18jk5VAA16fG54Vcfu0_33_3fd57c9cf8bb5b882e179ce0f1f8c55eAmKTf3nnnpk_nTf1cn_n(v56);
  swift_bridgeObjectRelease();
  Model.inputs.setter();
  Model.outputs.getter();
  Model.outputs.setter();
  swift_bridgeObjectRetain();
  Model.predictedFeatureName.setter();
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Model>);
  uint64_t v57 = v75;
  unint64_t v58 = (*(unsigned __int8 *)(v75 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v75 + 80);
  uint64_t v59 = swift_allocObject();
  *(_OWORD *)(v59 + 16) = v80;
  uint64_t v60 = v76;
  (*(void (**)(unint64_t, char *, uint64_t))(v57 + 16))(v59 + v58, v54, v76);
  uint64_t v85 = v66;
  specialized Array.append<A>(contentsOf:)(v59);
  uint64_t v61 = v72;
  PipelineRegressorConfiguration.init(models:names:)();
  (*(void (**)(uint64_t, void, uint64_t))(v73 + 104))(v61, *MEMORY[0x263F533F0], v64);
  Model.kind.setter();
  v82(v54, v60);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v57 + 32))(v74, v55, v60);
  uint64_t v62 = v83;
  $defer #1 () in MLImageClassifier.Model.createScenePrintFeatureExtractorModel(revision:)();
  ((void (*)(char *, uint64_t))v45)(v62, v84);
}

uint64_t TreeClassifierTrainingSessionDelegate.init(sessionParameters:)(uint64_t a1)
{
  OUTLINED_FUNCTION_108_0();
  uint64_t v4 = type metadata accessor for PersistentParametersForTreeBasedMethods();
  OUTLINED_FUNCTION_42_5(v4);
  DataFrame.init()();
  OUTLINED_FUNCTION_108_0();
  uint64_t v5 = type metadata accessor for DataFrame();
  OUTLINED_FUNCTION_42_5(v5);
  OUTLINED_FUNCTION_108_0();
  uint64_t v6 = type metadata accessor for AnyTreeClassifier();
  OUTLINED_FUNCTION_42_5(v6);
  OUTLINED_FUNCTION_108_0();
  uint64_t v7 = type metadata accessor for AnyTreeClassifierModel();
  OUTLINED_FUNCTION_42_5(v7);
  OUTLINED_FUNCTION_108_0();
  type metadata accessor for AnyClassificationMetrics();
  OUTLINED_FUNCTION_67(v2);
  OUTLINED_FUNCTION_67(v1 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_validationMetrics);
  outlined init with take of AnyTreeClassifierModel(a1, v1 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_sessionParameters, (void (*)(void))type metadata accessor for MLTrainingSessionParameters);
  return v1;
}

void TreeClassifierTrainingSessionDelegate.init(trainingData:validationData:targetColumn:featureColumns:configuration:sessionParameters:)()
{
  OUTLINED_FUNCTION_9_0();
  long long v136 = v3;
  uint64_t v137 = v1;
  uint64_t v4 = v0;
  uint64_t v139 = v5;
  uint64_t v141 = v7;
  uint64_t v142 = v6;
  uint64_t v135 = v8;
  uint64_t v10 = v9;
  uint64_t v143 = v11;
  OUTLINED_FUNCTION_4_12();
  uint64_t v131 = v12;
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Int>);
  uint64_t v14 = OUTLINED_FUNCTION_17(v13);
  MEMORY[0x270FA5388](v14);
  OUTLINED_FUNCTION_33_0();
  uint64_t v121 = v15;
  uint64_t v16 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  uint64_t v17 = OUTLINED_FUNCTION_17(v16);
  MEMORY[0x270FA5388](v17);
  OUTLINED_FUNCTION_33_0();
  uint64_t v122 = v18;
  uint64_t v19 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyTreeClassifier?);
  uint64_t v20 = OUTLINED_FUNCTION_17(v19);
  MEMORY[0x270FA5388](v20);
  OUTLINED_FUNCTION_21_11(v21, v117[0]);
  uint64_t v128 = type metadata accessor for AnyColumn();
  OUTLINED_FUNCTION_0();
  uint64_t v130 = v22;
  MEMORY[0x270FA5388](v23);
  OUTLINED_FUNCTION_49();
  uint64_t v120 = v24;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v25);
  OUTLINED_FUNCTION_106();
  uint64_t v126 = v26;
  uint64_t v27 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?);
  uint64_t v28 = OUTLINED_FUNCTION_17(v27);
  MEMORY[0x270FA5388](v28);
  OUTLINED_FUNCTION_33_0();
  uint64_t v125 = v29;
  uint64_t v30 = type metadata accessor for BoostedTreeConfiguration();
  OUTLINED_FUNCTION_0();
  uint64_t v146 = v31;
  MEMORY[0x270FA5388](v32);
  OUTLINED_FUNCTION_33_0();
  uint64_t v138 = v33;
  uint64_t v34 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
  uint64_t v35 = OUTLINED_FUNCTION_17(v34);
  MEMORY[0x270FA5388](v35);
  OUTLINED_FUNCTION_33_0();
  uint64_t v132 = v36;
  uint64_t v37 = type metadata accessor for DataFrame();
  OUTLINED_FUNCTION_0();
  uint64_t v39 = v38;
  uint64_t v41 = MEMORY[0x270FA5388](v40);
  uint64_t v43 = (char *)v117 - ((v42 + 15) & 0xFFFFFFFFFFFFFFF0);
  MEMORY[0x270FA5388](v41);
  OUTLINED_FUNCTION_106();
  uint64_t v123 = v44;
  type metadata accessor for PersistentParametersForTreeBasedMethods();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v45);
  OUTLINED_FUNCTION_33_7();
  MEMORY[0x270FA5388](v46);
  OUTLINED_FUNCTION_106();
  uint64_t v134 = v47;
  uint64_t v124 = v4 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingParameters;
  uint64_t v133 = (int *)v48;
  __swift_storeEnumTagSinglePayload(v4 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingParameters, 1, 1, v48);
  DataFrame.init()();
  uint64_t v140 = v37;
  __swift_storeEnumTagSinglePayload(v4 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_validationData, 1, 1, v37);
  uint64_t v49 = v4 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_classifier;
  uint64_t v50 = type metadata accessor for AnyTreeClassifier();
  OUTLINED_FUNCTION_67(v49);
  uint64_t v51 = v4 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_model;
  uint64_t v52 = type metadata accessor for AnyTreeClassifierModel();
  __swift_storeEnumTagSinglePayload(v51, 1, 1, v52);
  uint64_t v53 = v4 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingMetrics;
  uint64_t v54 = type metadata accessor for AnyClassificationMetrics();
  uint64_t v55 = v53;
  uint64_t v56 = v135;
  __swift_storeEnumTagSinglePayload(v55, 1, 1, v54);
  uint64_t v57 = v54;
  uint64_t v58 = v143;
  __swift_storeEnumTagSinglePayload(v4 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_validationMetrics, 1, 1, v57);
  uint64_t v127 = v10;
  uint64_t v59 = v10;
  uint64_t v60 = v137;
  uint64_t v61 = (uint64_t)v136;
  static _FeatureUtilities.selectFeaturesFromTrainingData(trainingData:targetColumn:featureColumns:)(v58, v59, v136, v56);
  uint64_t v137 = v60;
  if (v60)
  {
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    outlined destroy of AnyTreeClassifierModel(v139, (void (*)(void))type metadata accessor for MLTrainingSessionParameters);
    OUTLINED_FUNCTION_25_0();
    v63();
    outlined destroy of URL?(v142, &demangling cache variable for type metadata for DataFrame?);
    uint64_t v64 = *(void (**)(void))(v39 + 8);
    OUTLINED_FUNCTION_2_28();
    v64();
    outlined destroy of URL?(v4 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingParameters, &demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?);
    OUTLINED_FUNCTION_2_28();
    v64();
    outlined destroy of URL?(v4 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_validationData, &demangling cache variable for type metadata for DataFrame?);
    outlined destroy of URL?(v4 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_classifier, &demangling cache variable for type metadata for AnyTreeClassifier?);
    outlined destroy of URL?(v4 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_model, &demangling cache variable for type metadata for AnyTreeClassifierModel?);
    outlined destroy of URL?(v4 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingMetrics, &demangling cache variable for type metadata for AnyClassificationMetrics?);
    outlined destroy of URL?(v4 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_validationMetrics, &demangling cache variable for type metadata for AnyClassificationMetrics?);
    swift_deallocPartialClassInstance();
LABEL_8:
    OUTLINED_FUNCTION_8_1();
    return;
  }
  uint64_t v118 = v43;
  uint64_t v131 = v50;
  uint64_t v119 = v62;
  swift_bridgeObjectRelease();
  uint64_t v65 = *(void (**)(uint64_t, uint64_t, uint64_t))(v39 + 16);
  uint64_t v66 = v123;
  uint64_t v67 = v30;
  uint64_t v68 = v140;
  v117[1] = v39 + 16;
  v117[0] = (uint64_t)v65;
  v65(v123, v58, v140);
  outlined init with copy of URL?(v142, v132, &demangling cache variable for type metadata for DataFrame?);
  uint64_t v69 = v39;
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v146 + 16))(v138, v141, v67);
  uint64_t v70 = v133;
  uint64_t v71 = v2 + v133[5];
  uint64_t v72 = OUTLINED_FUNCTION_65_2();
  __swift_storeEnumTagSinglePayload(v72, v73, v74, v75);
  uint64_t v135 = v69;
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v69 + 32))(v2, v66, v68);
  swift_bridgeObjectRetain();
  outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v132, v71, &demangling cache variable for type metadata for DataFrame?);
  uint64_t v76 = (uint64_t *)(v2 + v70[6]);
  uint64_t v77 = v127;
  *uint64_t v76 = v127;
  v76[1] = v61;
  *(void *)(v2 + v70[7]) = v119;
  uint64_t v78 = v2 + v70[8];
  uint64_t v79 = *(void (**)(uint64_t, uint64_t, uint64_t))(v146 + 32);
  uint64_t v132 = v67;
  v79(v78, v138, v67);
  uint64_t v80 = v134;
  outlined init with take of AnyTreeClassifierModel(v2, v134, (void (*)(void))type metadata accessor for PersistentParametersForTreeBasedMethods);
  uint64_t v81 = v80;
  uint64_t v82 = v125;
  outlined init with copy of PersistentParametersForTreeBasedMethods(v81, v125, (void (*)(void))type metadata accessor for PersistentParametersForTreeBasedMethods);
  OUTLINED_FUNCTION_82_1();
  __swift_storeEnumTagSinglePayload(v83, v84, v85, (uint64_t)v70);
  uint64_t v86 = v124;
  OUTLINED_FUNCTION_81_2();
  outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v82, v86, &demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?);
  swift_endAccess();
  uint64_t v87 = v139;
  outlined init with copy of PersistentParametersForTreeBasedMethods(v139, v4 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_sessionParameters, (void (*)(void))type metadata accessor for MLTrainingSessionParameters);
  uint64_t v88 = v126;
  MEMORY[0x22A672220](v77, v61);
  AnyColumn.wrappedElementType.getter();
  uint64_t v89 = v130 + 8;
  Swift::String v90 = *(void (**)(uint64_t, uint64_t))(v130 + 8);
  v90(v88, v128);
  if (swift_dynamicCastMetatype())
  {
    DataFrame.subscript.getter();
    specialized Set.init<A>(_:)();
    uint64_t v92 = v91;
    uint64_t v93 = v134;
    uint64_t v94 = v138;
    swift_bridgeObjectRetain();
    BoostedTreeConfiguration.init()();
    uint64_t v95 = v129;
    AnyTreeClassifier.init(labels:annotationColumnName:featureColumnNames:configuration:)(v92, v77, v61, v94, v129);
    outlined destroy of AnyTreeClassifierModel(v87, (void (*)(void))type metadata accessor for MLTrainingSessionParameters);
    OUTLINED_FUNCTION_25_0();
    v96();
    outlined destroy of URL?(v142, &demangling cache variable for type metadata for DataFrame?);
    OUTLINED_FUNCTION_25_0();
    v97();
    outlined destroy of AnyTreeClassifierModel(v93, (void (*)(void))type metadata accessor for PersistentParametersForTreeBasedMethods);
    __swift_storeEnumTagSinglePayload(v95, 0, 1, v131);
    uint64_t v98 = v4 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_classifier;
    OUTLINED_FUNCTION_81_2();
    uint64_t v99 = v95;
LABEL_7:
    outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v99, v98, &demangling cache variable for type metadata for AnyTreeClassifier?);
    swift_endAccess();
    goto LABEL_8;
  }
  uint64_t v101 = v133;
  uint64_t v100 = v134;
  uint64_t v130 = v89;
  uint64_t v102 = v77;
  uint64_t v103 = swift_dynamicCastMetatype();
  uint64_t v104 = v129;
  if (v103)
  {
    OUTLINED_FUNCTION_63_3();
    DataFrame.subscript.getter();
    specialized Set.init<A>(_:)();
    uint64_t v106 = v105;
    uint64_t v107 = v101[7];
    uint64_t v108 = v100;
    uint64_t v109 = *(void *)(v100 + v107);
    swift_bridgeObjectRetain();
    uint64_t v110 = v138;
    BoostedTreeConfiguration.init()();
    AnyTreeClassifier.init(labels:annotationColumnName:featureColumnNames:configuration:)(v106, v102, v61, v109, v110, v104);
    outlined destroy of AnyTreeClassifierModel(v139, (void (*)(void))type metadata accessor for MLTrainingSessionParameters);
    OUTLINED_FUNCTION_25_0();
    v111();
    outlined destroy of URL?(v142, &demangling cache variable for type metadata for DataFrame?);
    OUTLINED_FUNCTION_25_0();
    v112();
    outlined destroy of AnyTreeClassifierModel(v108, (void (*)(void))type metadata accessor for PersistentParametersForTreeBasedMethods);
    __swift_storeEnumTagSinglePayload(v104, 0, 1, v131);
    uint64_t v98 = v4 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_classifier;
    OUTLINED_FUNCTION_81_2();
    uint64_t v99 = v104;
    goto LABEL_7;
  }
  ((void (*)(char *, uint64_t, uint64_t))v117[0])(v118, v143, v140);
  unint64_t v144 = 0;
  unint64_t v145 = 0xE000000000000000;
  _StringGuts.grow(_:)(38);
  swift_bridgeObjectRelease();
  unint64_t v144 = 0xD000000000000023;
  unint64_t v145 = 0x80000002272D70E0;
  uint64_t v113 = v120;
  uint64_t v114 = OUTLINED_FUNCTION_63_3();
  MEMORY[0x22A672220](v114);
  swift_bridgeObjectRelease();
  AnyColumn.wrappedElementType.getter();
  v90(v113, v128);
  v115._uint64_t countAndFlagsBits = _typeName(_:qualified:)();
  String.append(_:)(v115);
  swift_bridgeObjectRelease();
  v116._uint64_t countAndFlagsBits = 46;
  v116._uint64_t object = (void *)0xE100000000000000;
  String.append(_:)(v116);
  OUTLINED_FUNCTION_56_7();
  __break(1u);
}

Swift::Void __swiftcall __spoils<CF,ZF,NF,VF,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13,X14,X15,X16,X17,X21,Q0,Q1,Q2,Q3,Q4,Q5,Q6,Q7,Q16,Q17,Q18,Q19,Q20,Q21,Q22,Q23,Q24,Q25,Q26,Q27,Q28,Q29,Q30,Q31> TreeClassifierTrainingSessionDelegate.setUp()()
{
  OUTLINED_FUNCTION_9_0();
  type metadata accessor for BaseTreeClassifierModel();
  OUTLINED_FUNCTION_0();
  uint64_t v83 = v5;
  uint64_t v84 = v4;
  MEMORY[0x270FA5388](v4);
  OUTLINED_FUNCTION_7_15(v6, v82[0]);
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyTreeClassifierModel?);
  uint64_t v8 = OUTLINED_FUNCTION_17(v7);
  MEMORY[0x270FA5388](v8);
  OUTLINED_FUNCTION_33_0();
  uint64_t v85 = v9;
  uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Int>);
  uint64_t v11 = OUTLINED_FUNCTION_17(v10);
  MEMORY[0x270FA5388](v11);
  OUTLINED_FUNCTION_21_11(v12, v82[0]);
  type metadata accessor for BoostedTreeConfiguration();
  OUTLINED_FUNCTION_0();
  uint64_t v90 = v14;
  uint64_t v91 = v13;
  MEMORY[0x270FA5388](v13);
  OUTLINED_FUNCTION_49();
  uint64_t v89 = v15;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v16);
  OUTLINED_FUNCTION_106();
  uint64_t v93 = v17;
  uint64_t v18 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  uint64_t v19 = OUTLINED_FUNCTION_17(v18);
  MEMORY[0x270FA5388](v19);
  OUTLINED_FUNCTION_33_0();
  v82[2] = v20;
  uint64_t v21 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyTreeClassifier?);
  uint64_t v22 = OUTLINED_FUNCTION_17(v21);
  MEMORY[0x270FA5388](v22);
  OUTLINED_FUNCTION_49();
  uint64_t v86 = v23;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v24);
  uint64_t v26 = (char *)v82 - v25;
  uint64_t v88 = type metadata accessor for AnyColumn();
  OUTLINED_FUNCTION_0();
  uint64_t v28 = v27;
  MEMORY[0x270FA5388](v29);
  OUTLINED_FUNCTION_22_0();
  uint64_t v30 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?);
  uint64_t v31 = OUTLINED_FUNCTION_17(v30);
  MEMORY[0x270FA5388](v31);
  uint64_t v32 = (int *)OUTLINED_FUNCTION_34_6();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v33);
  OUTLINED_FUNCTION_3_0();
  uint64_t v36 = v35 - v34;
  uint64_t v37 = v0 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingParameters;
  OUTLINED_FUNCTION_53();
  outlined init with copy of URL?(v37, v2, &demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?);
  OUTLINED_FUNCTION_57_4(v2, 1, (uint64_t)v32);
  if (v38)
  {
    outlined destroy of URL?(v2, &demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?);
    __break(1u);
    goto LABEL_11;
  }
  outlined init with take of AnyTreeClassifierModel(v2, v36, (void (*)(void))type metadata accessor for PersistentParametersForTreeBasedMethods);
  uint64_t v39 = v0 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingData;
  OUTLINED_FUNCTION_81_2();
  type metadata accessor for DataFrame();
  OUTLINED_FUNCTION_8();
  (*(void (**)(uint64_t, uint64_t))(v40 + 24))(v39, v36);
  swift_endAccess();
  uint64_t v41 = v36 + v32[5];
  uint64_t v42 = v0 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_validationData;
  OUTLINED_FUNCTION_81_2();
  outlined assign with copy of DataFrame?(v41, v42);
  swift_endAccess();
  uint64_t v43 = v32[6];
  uint64_t v92 = v0;
  uint64_t v44 = *(void *)(v36 + v43);
  uint64_t v45 = *(void *)(v36 + v43 + 8);
  OUTLINED_FUNCTION_18_10();
  swift_bridgeObjectRetain();
  MEMORY[0x22A672220](v44, v45);
  swift_endAccess();
  swift_bridgeObjectRelease();
  AnyColumn.wrappedElementType.getter();
  (*(void (**)(uint64_t, uint64_t))(v28 + 8))(v3, v88);
  if (swift_dynamicCastMetatype())
  {
    OUTLINED_FUNCTION_18_10();
    swift_bridgeObjectRetain();
    OUTLINED_FUNCTION_44_3();
    swift_endAccess();
    swift_bridgeObjectRelease();
    specialized Set.init<A>(_:)();
    OUTLINED_FUNCTION_53_7();
    swift_bridgeObjectRetain();
    BoostedTreeConfiguration.init()();
    uint64_t v46 = OUTLINED_FUNCTION_48_4();
    AnyTreeClassifier.init(labels:annotationColumnName:featureColumnNames:configuration:)(v46, v47, v48, v49, v50);
    uint64_t v51 = type metadata accessor for AnyTreeClassifier();
    OUTLINED_FUNCTION_20_10((uint64_t)v26);
    uint64_t v52 = v92;
    uint64_t v53 = v92 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_classifier;
    OUTLINED_FUNCTION_4_23();
    uint64_t v54 = (uint64_t)v26;
    goto LABEL_6;
  }
  uint64_t v55 = (uint64_t)v26;
  uint64_t v56 = v92;
  if (swift_dynamicCastMetatype())
  {
    OUTLINED_FUNCTION_18_10();
    swift_bridgeObjectRetain();
    OUTLINED_FUNCTION_44_3();
    swift_endAccess();
    swift_bridgeObjectRelease();
    specialized Set.init<A>(_:)();
    OUTLINED_FUNCTION_53_7();
    swift_bridgeObjectRetain();
    BoostedTreeConfiguration.init()();
    uint64_t v57 = OUTLINED_FUNCTION_48_4();
    AnyTreeClassifier.init(labels:annotationColumnName:featureColumnNames:configuration:)(v57, v58, v59, v60, v61, v62);
    uint64_t v51 = type metadata accessor for AnyTreeClassifier();
    OUTLINED_FUNCTION_20_10(v55);
    uint64_t v52 = v56;
    uint64_t v53 = v56 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_classifier;
    OUTLINED_FUNCTION_4_23();
    uint64_t v54 = v55;
LABEL_6:
    outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v54, v53, &demangling cache variable for type metadata for AnyTreeClassifier?);
    swift_endAccess();
    uint64_t v63 = v32[8];
    uint64_t v88 = v36;
    uint64_t v64 = v89;
    uint64_t v65 = *(void (**)(uint64_t, uint64_t, uint64_t))(v90 + 16);
    uint64_t v66 = v91;
    v65(v89, v36 + v63, v91);
    uint64_t v67 = v52 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_classifier;
    OUTLINED_FUNCTION_81_2();
    type metadata accessor for AnyTreeClassifier();
    OUTLINED_FUNCTION_57_4(v67, 1, v51);
    if (!v38)
    {
      v65(v93, v64, v66);
      BaseTreeClassifier.configuration.setter();
      OUTLINED_FUNCTION_63_3();
      OUTLINED_FUNCTION_38_0();
      v68();
      swift_endAccess();
      uint64_t v69 = v86;
      outlined init with copy of URL?(v67, v86, &demangling cache variable for type metadata for AnyTreeClassifier?);
      OUTLINED_FUNCTION_57_4(v69, 1, v51);
      uint64_t v70 = v87;
      if (!v38)
      {
        uint64_t v72 = *(void *)v69;
        uint64_t v71 = *(void *)(v69 + 8);
        uint64_t v73 = *(void *)(v69 + 24);
        char v74 = *(unsigned char *)(v69 + 32);
        swift_bridgeObjectRetain();
        BaseTreeClassifier.makeTransformer(classCount:featureCount:)();
        if (!v1)
        {
          uint64_t v75 = v85;
          *(void *)uint64_t v85 = v72;
          *((void *)v75 + 1) = v71;
          uint64_t v76 = type metadata accessor for AnyTreeClassifierModel();
          *((void *)v75 + 3) = 0;
          *((void *)v75 + 4) = 0;
          *((void *)v75 + 2) = 0;
          (*(void (**)(char *, uint64_t, uint64_t))(v83 + 32))(&v75[*(int *)(v76 + 24)], v70, v84);
          uint64_t v77 = &v75[*(int *)(v76 + 28)];
          *(void *)uint64_t v77 = v73;
          v77[8] = v74;
          swift_bridgeObjectRetain();
          outlined destroy of AnyTreeClassifierModel(v88, (void (*)(void))type metadata accessor for PersistentParametersForTreeBasedMethods);
          outlined destroy of AnyTreeClassifierModel(v69, (void (*)(void))type metadata accessor for AnyTreeClassifier);
          OUTLINED_FUNCTION_82_1();
          __swift_storeEnumTagSinglePayload(v78, v79, v80, v76);
          uint64_t v81 = v92 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_model;
          OUTLINED_FUNCTION_4_23();
          outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata((uint64_t)v75, v81, &demangling cache variable for type metadata for AnyTreeClassifierModel?);
          swift_endAccess();
          OUTLINED_FUNCTION_8_1();
          return;
        }
        goto LABEL_13;
      }
LABEL_12:
      __break(1u);
LABEL_13:
      swift_bridgeObjectRelease();
      swift_unexpectedError();
      __break(1u);
      goto LABEL_14;
    }
LABEL_11:
    __break(1u);
    goto LABEL_12;
  }
LABEL_14:
  _assertionFailure(_:_:file:line:flags:)();
  __break(1u);
}

Swift::Void __swiftcall __spoils<CF,ZF,NF,VF,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13,X14,X15,X16,X17,X21,Q0,Q1,Q2,Q3,Q4,Q5,Q6,Q7,Q16,Q17,Q18,Q19,Q20,Q21,Q22,Q23,Q24,Q25,Q26,Q27,Q28,Q29,Q30,Q31> TreeClassifierTrainingSessionDelegate.resume(from:)(Swift::OpaquePointer from)
{
  OUTLINED_FUNCTION_9_0();
  uint64_t v82 = v2;
  uint64_t v88 = v5;
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyTreeClassifierModel?);
  uint64_t v7 = OUTLINED_FUNCTION_17(v6);
  MEMORY[0x270FA5388](v7);
  OUTLINED_FUNCTION_49();
  uint64_t v78 = v8;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v9);
  OUTLINED_FUNCTION_106();
  uint64_t v80 = v10;
  uint64_t v11 = type metadata accessor for BoostedTreeConfiguration();
  uint64_t v12 = OUTLINED_FUNCTION_17(v11);
  MEMORY[0x270FA5388](v12);
  OUTLINED_FUNCTION_33_0();
  uint64_t v85 = v13;
  uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyTreeClassifier?);
  uint64_t v15 = OUTLINED_FUNCTION_17(v14);
  MEMORY[0x270FA5388](v15);
  OUTLINED_FUNCTION_49();
  uint64_t v79 = v16;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v17);
  uint64_t v81 = (uint64_t)&v77 - v18;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v19);
  OUTLINED_FUNCTION_106();
  uint64_t v86 = v20;
  type metadata accessor for AnyColumn();
  OUTLINED_FUNCTION_0();
  uint64_t v83 = v22;
  uint64_t v84 = v21;
  MEMORY[0x270FA5388](v21);
  OUTLINED_FUNCTION_7_15(v23, v77);
  uint64_t v24 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?);
  uint64_t v25 = OUTLINED_FUNCTION_17(v24);
  MEMORY[0x270FA5388](v25);
  uint64_t v27 = (char *)&v77 - ((v26 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v28 = type metadata accessor for MLCheckpoint();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v29);
  OUTLINED_FUNCTION_33_0();
  uint64_t v87 = v30;
  uint64_t v31 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?);
  uint64_t v32 = OUTLINED_FUNCTION_17(v31);
  MEMORY[0x270FA5388](v32);
  OUTLINED_FUNCTION_22_0();
  uint64_t v33 = type metadata accessor for PersistentParametersForTreeBasedMethods();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v34);
  OUTLINED_FUNCTION_27_7();
  uint64_t v35 = v1;
  uint64_t v36 = v1 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingParameters;
  OUTLINED_FUNCTION_53();
  outlined init with copy of URL?(v36, v4, &demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?);
  OUTLINED_FUNCTION_57_4(v4, 1, v33);
  if (v37)
  {
    outlined destroy of URL?(v4, &demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?);
    __break(1u);
LABEL_21:
    __break(1u);
    goto LABEL_22;
  }
  outlined init with take of AnyTreeClassifierModel(v4, v3, (void (*)(void))type metadata accessor for PersistentParametersForTreeBasedMethods);
  specialized BidirectionalCollection.last.getter(v88, (uint64_t)v27);
  OUTLINED_FUNCTION_57_4((uint64_t)v27, 1, v28);
  if (v37)
  {
    outlined destroy of URL?((uint64_t)v27, &demangling cache variable for type metadata for MLCheckpoint?);
    lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    OUTLINED_FUNCTION_85();
    OUTLINED_FUNCTION_19_0(v38, 0xD00000000000001DLL);
LABEL_13:
    outlined destroy of AnyTreeClassifierModel(v3, (void (*)(void))type metadata accessor for PersistentParametersForTreeBasedMethods);
    goto LABEL_19;
  }
  uint64_t v39 = v87;
  outlined init with take of AnyTreeClassifierModel((uint64_t)v27, v87, (void (*)(void))type metadata accessor for MLCheckpoint);
  uint64_t v40 = v1;
  switch(*(unsigned char *)(v39 + *(int *)(v28 + 20)))
  {
    case 2:
      swift_bridgeObjectRelease();
      goto LABEL_9;
    case 4:
      OUTLINED_FUNCTION_55_0();
      goto LABEL_8;
    default:
LABEL_8:
      char v41 = OUTLINED_FUNCTION_37_5();
      swift_bridgeObjectRelease();
      if ((v41 & 1) == 0)
      {
        lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
        OUTLINED_FUNCTION_85();
        OUTLINED_FUNCTION_19_0(v61, 0xD000000000000028);
        outlined destroy of AnyTreeClassifierModel(v39, (void (*)(void))type metadata accessor for MLCheckpoint);
        goto LABEL_13;
      }
LABEL_9:
      uint64_t v42 = v1 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingData;
      OUTLINED_FUNCTION_4_23();
      type metadata accessor for DataFrame();
      OUTLINED_FUNCTION_8();
      (*(void (**)(uint64_t))(v43 + 24))(v42);
      swift_endAccess();
      uint64_t v44 = v3 + *(int *)(v33 + 20);
      uint64_t v45 = v35 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_validationData;
      OUTLINED_FUNCTION_81_2();
      outlined assign with copy of DataFrame?(v44, v45);
      swift_endAccess();
      uint64_t v46 = v3;
      uint64_t v47 = (uint64_t *)(v3 + *(int *)(v33 + 24));
      uint64_t v48 = *v47;
      uint64_t v49 = v47[1];
      swift_beginAccess();
      swift_bridgeObjectRetain();
      MEMORY[0x22A672220](v48, v49);
      swift_endAccess();
      swift_bridgeObjectRelease();
      AnyColumn.wrappedElementType.getter();
      OUTLINED_FUNCTION_25_0();
      v50();
      if (swift_dynamicCastMetatype())
      {
        specialized _setUpCast<A, B>(_:)(MEMORY[0x263F8EE88]);
        OUTLINED_FUNCTION_45_4();
        swift_bridgeObjectRetain();
        BoostedTreeConfiguration.init()();
        uint64_t v51 = OUTLINED_FUNCTION_25_12();
        AnyTreeClassifier.init(labels:annotationColumnName:featureColumnNames:configuration:)(v51, v52, v53, v54, v55);
        uint64_t v56 = type metadata accessor for AnyTreeClassifier();
        OUTLINED_FUNCTION_20_10((uint64_t)v47);
        uint64_t v57 = v40 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_classifier;
        OUTLINED_FUNCTION_4_23();
        outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata((uint64_t)v47, v57, &demangling cache variable for type metadata for AnyTreeClassifier?);
        swift_endAccess();
        uint64_t v58 = v57;
        uint64_t v59 = v81;
        outlined init with copy of URL?(v58, v81, &demangling cache variable for type metadata for AnyTreeClassifier?);
        OUTLINED_FUNCTION_57_4(v59, 1, v56);
        if (!v37)
        {
          lazy protocol witness table accessor for type AnyTreeClassifier and conformance AnyTreeClassifier();
          uint64_t v60 = v80;
          goto LABEL_17;
        }
        goto LABEL_21;
      }
      if (!swift_dynamicCastMetatype())
      {
LABEL_23:
        OUTLINED_FUNCTION_56_7();
        __break(1u);
        JUMPOUT(0x22710CFD4);
      }
      specialized _setUpCast<A, B>(_:)(MEMORY[0x263F8EE88]);
      OUTLINED_FUNCTION_45_4();
      swift_bridgeObjectRetain();
      BoostedTreeConfiguration.init()();
      uint64_t v62 = OUTLINED_FUNCTION_25_12();
      AnyTreeClassifier.init(labels:annotationColumnName:featureColumnNames:configuration:)(v62, v63, v64, v65, v66, v67);
      uint64_t v68 = type metadata accessor for AnyTreeClassifier();
      OUTLINED_FUNCTION_20_10((uint64_t)v47);
      uint64_t v69 = v40 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_classifier;
      OUTLINED_FUNCTION_4_23();
      outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata((uint64_t)v47, v69, &demangling cache variable for type metadata for AnyTreeClassifier?);
      swift_endAccess();
      uint64_t v70 = v69;
      uint64_t v59 = v79;
      outlined init with copy of URL?(v70, v79, &demangling cache variable for type metadata for AnyTreeClassifier?);
      OUTLINED_FUNCTION_57_4(v59, 1, v68);
      if (v37)
      {
LABEL_22:
        __break(1u);
        goto LABEL_23;
      }
      lazy protocol witness table accessor for type AnyTreeClassifier and conformance AnyTreeClassifier();
      uint64_t v60 = v78;
LABEL_17:
      uint64_t v71 = v82;
      SupervisedTabularEstimator.read(from:)();
      outlined destroy of AnyTreeClassifierModel(v39, (void (*)(void))type metadata accessor for MLCheckpoint);
      outlined destroy of AnyTreeClassifierModel(v46, (void (*)(void))type metadata accessor for PersistentParametersForTreeBasedMethods);
      outlined destroy of AnyTreeClassifierModel(v59, (void (*)(void))type metadata accessor for AnyTreeClassifier);
      if (!v71)
      {
        type metadata accessor for AnyTreeClassifierModel();
        OUTLINED_FUNCTION_82_1();
        __swift_storeEnumTagSinglePayload(v72, v73, v74, v75);
        uint64_t v76 = v40 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_model;
        OUTLINED_FUNCTION_4_23();
        outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v60, v76, &demangling cache variable for type metadata for AnyTreeClassifierModel?);
        swift_endAccess();
      }
LABEL_19:
      OUTLINED_FUNCTION_8_1();
      return;
  }
}

Swift::Int_optional __swiftcall TreeClassifierTrainingSessionDelegate.itemCount(phase:)(CreateML::MLPhase phase)
{
  int v2 = *(unsigned __int8 *)phase;
  if (v2 == 2)
  {
    uint64_t v4 = v1 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_sessionParameters;
    Swift::Int v3 = *(void *)(v4 + *(int *)(type metadata accessor for MLTrainingSessionParameters() + 28));
  }
  else
  {
    Swift::Int v3 = 0;
  }
  Swift::Bool v5 = v2 != 2;
  result.value = v3;
  result.is_nil = v5;
  return result;
}

uint64_t TreeClassifierTrainingSessionDelegate.train(from:)(uint64_t a1)
{
  v2[19] = a1;
  v2[20] = v1;
  uint64_t v3 = type metadata accessor for MetricsKey();
  v2[21] = v3;
  OUTLINED_FUNCTION_1(v3);
  v2[22] = v4;
  v2[23] = OUTLINED_FUNCTION_5();
  uint64_t v5 = type metadata accessor for DataFrame();
  v2[24] = v5;
  OUTLINED_FUNCTION_1(v5);
  v2[25] = v6;
  v2[26] = OUTLINED_FUNCTION_5();
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyTreeClassifier?);
  OUTLINED_FUNCTION_17(v7);
  v2[27] = OUTLINED_FUNCTION_5();
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?);
  OUTLINED_FUNCTION_17(v8);
  v2[28] = OUTLINED_FUNCTION_5();
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyTreeClassifierModel?);
  OUTLINED_FUNCTION_17(v9);
  v2[29] = OUTLINED_FUNCTION_5();
  return MEMORY[0x270FA2498](TreeClassifierTrainingSessionDelegate.train(from:), 0, 0);
}

uint64_t TreeClassifierTrainingSessionDelegate.train(from:)()
{
  uint64_t v3 = *(void *)(v0 + 232);
  uint64_t v4 = *(void *)(v0 + 160);
  uint64_t v5 = OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_model;
  *(void *)(v0 + 240) = OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_model;
  uint64_t v6 = v4 + v5;
  OUTLINED_FUNCTION_53();
  outlined init with copy of URL?(v6, v3, &demangling cache variable for type metadata for AnyTreeClassifierModel?);
  uint64_t v7 = type metadata accessor for AnyTreeClassifierModel();
  *(void *)(v0 + 248) = v7;
  uint64_t result = OUTLINED_FUNCTION_61_4(v7, v8, v7);
  if (v6 == 1)
  {
    __break(1u);
    goto LABEL_27;
  }
  uint64_t v10 = *(void *)(v0 + 224);
  uint64_t v11 = *(void *)(v0 + 160) + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingParameters;
  OUTLINED_FUNCTION_53();
  outlined init with copy of URL?(v11, v10, &demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?);
  uint64_t v12 = type metadata accessor for PersistentParametersForTreeBasedMethods();
  uint64_t result = OUTLINED_FUNCTION_61_4(v12, v13, v12);
  if (v11 == 1)
  {
LABEL_27:
    __break(1u);
LABEL_28:
    __break(1u);
    goto LABEL_29;
  }
  uint64_t v14 = *(void *)(v0 + 152);
  uint64_t v15 = *(void *)(v0 + 160) + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_sessionParameters;
  uint64_t result = type metadata accessor for MLTrainingSessionParameters();
  uint64_t v16 = *(void *)(v15 + *(int *)(result + 20));
  BOOL v17 = __OFADD__(v14, v16);
  *(void *)(v0 + 136) = v14 + v16;
  *(unsigned char *)(v0 + 144) = v17;
  if (__OFADD__(v14, v16)) {
    goto LABEL_28;
  }
  uint64_t v18 = *(void *)(v15 + *(int *)(result + 28));
  *(void *)(v0 + 256) = v18;
  BOOL v19 = __OFSUB__(v18, v14);
  uint64_t v20 = v18 - v14;
  if (v19)
  {
LABEL_29:
    __break(1u);
LABEL_30:
    __break(1u);
LABEL_31:
    __break(1u);
    goto LABEL_32;
  }
  if (v16 >= v20) {
    uint64_t v21 = v20;
  }
  else {
    uint64_t v21 = v16;
  }
  *(void *)(v0 + 264) = v21;
  type metadata accessor for EventCollector();
  swift_allocObject();
  uint64_t result = EventCollector.init()();
  *(void *)(v0 + 272) = result;
  if (v21 < 0) {
    goto LABEL_30;
  }
  if (!v21)
  {
    static MetricsKey.trainingAccuracy.getter();
    specialized EventCollector.getLast<A>(metric:type:)();
    uint64_t v35 = OUTLINED_FUNCTION_19_11();
    ((void (*)(uint64_t))v2)(v35);
    if ((v1 & 1) == 0)
    {
      char v36 = OUTLINED_FUNCTION_141();
      OUTLINED_FUNCTION_46_5(v36);
      OUTLINED_FUNCTION_140();
    }
    OUTLINED_FUNCTION_57_6();
    specialized EventCollector.getLast<A>(metric:type:)();
    char v38 = v37;
    OUTLINED_FUNCTION_2_28();
    v2();
    if ((v38 & 1) == 0)
    {
      char v39 = OUTLINED_FUNCTION_141();
      OUTLINED_FUNCTION_47_5(v39);
      OUTLINED_FUNCTION_140();
    }
    OUTLINED_FUNCTION_13_14();
    swift_release();
    swift_bridgeObjectRelease();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    OUTLINED_FUNCTION_36_6();
    OUTLINED_FUNCTION_9_15();
    __asm { BRAA            X4, X16 }
  }
  uint64_t v22 = *(void *)(v0 + 160);
  uint64_t v23 = OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingData;
  *(void *)(v0 + 280) = OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_classifier;
  *(void *)(v0 + 288) = v23;
  uint64_t v24 = v22 + v23;
  OUTLINED_FUNCTION_53();
  uint64_t result = OUTLINED_FUNCTION_53();
  *(void *)(v0 + 296) = 0;
  if (!*(void *)(v0 + 264)) {
    goto LABEL_31;
  }
  uint64_t v25 = OUTLINED_FUNCTION_64_2();
  outlined init with copy of URL?(v25, v0 + 88, &demangling cache variable for type metadata for AnyTreeClassifier?);
  uint64_t v26 = type metadata accessor for AnyTreeClassifier();
  uint64_t result = __swift_getEnumTagSinglePayload(v0 + 88, 1, v26);
  if (result == 1)
  {
LABEL_32:
    __break(1u);
    goto LABEL_33;
  }
  uint64_t v27 = OUTLINED_FUNCTION_10_13();
  v28(v27);
  OUTLINED_FUNCTION_81_2();
  uint64_t result = __swift_getEnumTagSinglePayload((uint64_t)&demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?, 1, v24);
  if (result == 1)
  {
LABEL_33:
    __break(1u);
    return result;
  }
  swift_retain();
  uint64_t v29 = (void *)swift_task_alloc();
  *(void *)(v0 + 304) = v29;
  *uint64_t v29 = v0;
  v29[1] = TreeClassifierTrainingSessionDelegate.train(from:);
  OUTLINED_FUNCTION_9_15();
  return AnyTreeClassifier.update(_:with:eventHandler:)(v30, v31, v32, v33);
}

{
  uint64_t v0;
  uint64_t *v1;
  void *v2;
  void *v3;
  uint64_t v4;
  void *v5;
  uint64_t (*v6)();
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  uint64_t v13;

  OUTLINED_FUNCTION_2();
  uint64_t v3 = v2;
  uint64_t v4 = *v1;
  OUTLINED_FUNCTION_6();
  *uint64_t v5 = v4;
  v3[39] = v0;
  swift_task_dealloc();
  if (v0)
  {
    uint64_t v6 = TreeClassifierTrainingSessionDelegate.train(from:);
  }
  else
  {
    uint64_t v8 = v3[26];
    uint64_t v7 = v3[27];
    uint64_t v11 = v3 + 24;
    uint64_t v9 = v3[24];
    uint64_t v10 = v11[1];
    swift_endAccess();
    swift_release();
    (*(void (**)(uint64_t, uint64_t))(v10 + 8))(v8, v9);
    outlined destroy of AnyTreeClassifierModel(v7, (void (*)(void))type metadata accessor for AnyTreeClassifier);
    uint64_t v6 = TreeClassifierTrainingSessionDelegate.train(from:);
  }
  return MEMORY[0x270FA2498](v6, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  void *v3;
  char v4;
  void (*v5)(void);
  uint64_t v6;
  uint64_t v7;
  char v8;
  char v9;
  char v10;
  char v11;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t result;
  uint64_t v17;
  void (*v18)(uint64_t);
  void *v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t v24;

  uint64_t v6 = v3[37] + 1;
  if (v6 == v3[33])
  {
    static MetricsKey.trainingAccuracy.getter();
    specialized EventCollector.getLast<A>(metric:type:)();
    uint64_t v7 = OUTLINED_FUNCTION_19_11();
    ((void (*)(uint64_t))v5)(v7);
    if ((v4 & 1) == 0)
    {
      uint64_t v8 = OUTLINED_FUNCTION_141();
      OUTLINED_FUNCTION_46_5(v8);
      OUTLINED_FUNCTION_140();
    }
    OUTLINED_FUNCTION_57_6();
    specialized EventCollector.getLast<A>(metric:type:)();
    uint64_t v10 = v9;
    OUTLINED_FUNCTION_2_28();
    v5();
    if ((v10 & 1) == 0)
    {
      uint64_t v11 = OUTLINED_FUNCTION_141();
      OUTLINED_FUNCTION_47_5(v11);
      OUTLINED_FUNCTION_140();
    }
    OUTLINED_FUNCTION_13_14();
    swift_release();
    swift_bridgeObjectRelease();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    OUTLINED_FUNCTION_36_6();
    OUTLINED_FUNCTION_9_15();
    __asm { BRAA            X4, X16 }
  }
  v3[37] = v6;
  uint64_t v14 = OUTLINED_FUNCTION_64_2();
  outlined init with copy of URL?(v14, v1, &demangling cache variable for type metadata for AnyTreeClassifier?);
  uint64_t v15 = type metadata accessor for AnyTreeClassifier();
  uint64_t result = __swift_getEnumTagSinglePayload(v1, 1, v15);
  if (result == 1)
  {
    __break(1u);
    goto LABEL_15;
  }
  BOOL v17 = OUTLINED_FUNCTION_10_13();
  v18(v17);
  OUTLINED_FUNCTION_81_2();
  uint64_t result = __swift_getEnumTagSinglePayload(v2, 1, v0);
  if (result == 1)
  {
LABEL_15:
    __break(1u);
    return result;
  }
  swift_retain();
  BOOL v19 = (void *)swift_task_alloc();
  v3[38] = v19;
  *BOOL v19 = v3;
  v19[1] = TreeClassifierTrainingSessionDelegate.train(from:);
  OUTLINED_FUNCTION_9_15();
  return AnyTreeClassifier.update(_:with:eventHandler:)(v20, v21, v22, v23);
}

{
  uint64_t v0;
  uint64_t v1;
  void (*v2)(void);
  uint64_t (*v3)(void);
  uint64_t v5;

  char v1 = *(void *)(v0 + 216);
  swift_endAccess();
  swift_release_n();
  OUTLINED_FUNCTION_38_0();
  v2();
  outlined destroy of AnyTreeClassifierModel(v1, (void (*)(void))type metadata accessor for AnyTreeClassifier);
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  uint64_t v3 = *(uint64_t (**)(void))(v0 + 8);
  return v3();
}

uint64_t TreeClassifierTrainingSessionDelegate.evaluate(from:)()
{
  v1[26] = v0;
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
  OUTLINED_FUNCTION_17(v2);
  v1[27] = OUTLINED_FUNCTION_5();
  uint64_t v3 = type metadata accessor for AnyColumn();
  OUTLINED_FUNCTION_17(v3);
  v1[28] = swift_task_alloc();
  v1[29] = swift_task_alloc();
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyClassificationMetrics?);
  OUTLINED_FUNCTION_17(v4);
  v1[30] = OUTLINED_FUNCTION_5();
  uint64_t v5 = type metadata accessor for DataFrame();
  v1[31] = v5;
  OUTLINED_FUNCTION_1(v5);
  v1[32] = v6;
  v1[33] = swift_task_alloc();
  v1[34] = swift_task_alloc();
  v1[35] = swift_task_alloc();
  v1[36] = swift_task_alloc();
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyTreeClassifierModel?);
  OUTLINED_FUNCTION_17(v7);
  v1[37] = OUTLINED_FUNCTION_5();
  uint64_t v8 = type metadata accessor for AnyTreeClassifierModel();
  v1[38] = v8;
  OUTLINED_FUNCTION_17(v8);
  v1[39] = OUTLINED_FUNCTION_5();
  return MEMORY[0x270FA2498](TreeClassifierTrainingSessionDelegate.evaluate(from:), 0, 0);
}

{
  void *v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t (*v7)(uint64_t, uint64_t);
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t *v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  void (*v19)(void);
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  int EnumTagSinglePayload;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  void (*v30)(void);
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v34;
  uint64_t v35;
  uint64_t v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  uint64_t v42;
  uint64_t v43;
  uint64_t v44;
  uint64_t v45;
  uint64_t v46;
  void (*v47)(void);
  uint64_t v48;
  uint64_t v49;
  uint64_t v50;

  char v1 = v0[37];
  uint64_t v2 = v0[38];
  uint64_t v3 = v0[26] + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_model;
  OUTLINED_FUNCTION_53();
  outlined init with copy of URL?(v3, v1, &demangling cache variable for type metadata for AnyTreeClassifierModel?);
  if (__swift_getEnumTagSinglePayload(v1, 1, v2) == 1)
  {
    outlined destroy of URL?(v0[37], &demangling cache variable for type metadata for AnyTreeClassifierModel?);
  }
  else
  {
    uint64_t v4 = v0[26];
    outlined init with take of AnyTreeClassifierModel(v0[37], v0[39], (void (*)(void))type metadata accessor for AnyTreeClassifierModel);
    uint64_t v5 = v4 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingParameters;
    OUTLINED_FUNCTION_53();
    uint64_t v6 = type metadata accessor for PersistentParametersForTreeBasedMethods();
    if (!__swift_getEnumTagSinglePayload(v5, 1, v6))
    {
      uint64_t v10 = v0[35];
      uint64_t v9 = v0[36];
      uint64_t v12 = v0[31];
      uint64_t v11 = v0[32];
      uint64_t v13 = (uint64_t *)(v5 + *(int *)(v6 + 24));
      uint64_t v15 = *v13;
      uint64_t v14 = v13[1];
      uint64_t v16 = v0[26] + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingData;
      OUTLINED_FUNCTION_53();
      (*(void (**)(uint64_t, uint64_t, uint64_t))(v11 + 16))(v10, v16, v12);
      swift_bridgeObjectRetain();
      AnyTreeClassifierModel.applied(to:eventHandler:)(v9);
      uint64_t v43 = v0[31];
      BOOL v17 = v15;
      uint64_t v18 = v0[30];
      uint64_t v45 = v0[27];
      uint64_t v42 = v0[26];
      uint64_t v47 = *(void (**)(void))(v0[32] + 8);
      OUTLINED_FUNCTION_38_0();
      v19();
      MEMORY[0x22A672220](v17, v14);
      swift_beginAccess();
      MEMORY[0x22A672220](v17, v14);
      swift_endAccess();
      AnyClassificationMetrics.init(_:_:)();
      uint64_t v20 = type metadata accessor for AnyClassificationMetrics();
      OUTLINED_FUNCTION_82_1();
      __swift_storeEnumTagSinglePayload(v21, v22, v23, v20);
      uint64_t v24 = v42 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingMetrics;
      OUTLINED_FUNCTION_81_2();
      outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v18, v24, &demangling cache variable for type metadata for AnyClassificationMetrics?);
      swift_endAccess();
      uint64_t v25 = v42 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_validationData;
      OUTLINED_FUNCTION_53();
      outlined init with copy of URL?(v25, v45, &demangling cache variable for type metadata for DataFrame?);
      int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v45, 1, v43);
      uint64_t v27 = v0[39];
      if (EnumTagSinglePayload == 1)
      {
        uint64_t v28 = v0[30];
        uint64_t v29 = v0[27];
        uint64_t v46 = v0[26];
        swift_bridgeObjectRelease();
        OUTLINED_FUNCTION_63_3();
        OUTLINED_FUNCTION_38_0();
        v30();
        outlined destroy of AnyTreeClassifierModel(v27, (void (*)(void))type metadata accessor for AnyTreeClassifierModel);
        outlined destroy of URL?(v29, &demangling cache variable for type metadata for DataFrame?);
        uint64_t v48 = 1;
        uint64_t v31 = OUTLINED_FUNCTION_65_2();
        __swift_storeEnumTagSinglePayload(v31, v32, v33, v34);
        uint64_t v35 = v46 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_validationMetrics;
        OUTLINED_FUNCTION_81_2();
        outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v28, v35, &demangling cache variable for type metadata for AnyClassificationMetrics?);
      }
      else
      {
        char v36 = v0[33];
        (*(void (**)(void, void, void))(v0[32] + 32))(v0[34], v0[27], v0[31]);
        AnyTreeClassifierModel.applied(to:eventHandler:)(v36);
        uint64_t v49 = v0[39];
        uint64_t v41 = v0[30];
        uint64_t v44 = v0[26];
        MEMORY[0x22A672220](v17, v14);
        MEMORY[0x22A672220](v17, v14);
        swift_bridgeObjectRelease();
        AnyClassificationMetrics.init(_:_:)();
        OUTLINED_FUNCTION_7_7();
        v47();
        OUTLINED_FUNCTION_7_7();
        v47();
        OUTLINED_FUNCTION_7_7();
        v47();
        outlined destroy of AnyTreeClassifierModel(v49, (void (*)(void))type metadata accessor for AnyTreeClassifierModel);
        uint64_t v48 = 1;
        OUTLINED_FUNCTION_82_1();
        __swift_storeEnumTagSinglePayload(v37, v38, v39, v20);
        uint64_t v40 = v44 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_validationMetrics;
        OUTLINED_FUNCTION_81_2();
        outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v41, v40, &demangling cache variable for type metadata for AnyClassificationMetrics?);
      }
      swift_endAccess();
      goto LABEL_6;
    }
    outlined destroy of AnyTreeClassifierModel(v0[39], (void (*)(void))type metadata accessor for AnyTreeClassifierModel);
  }
  uint64_t v48 = 0;
LABEL_6:
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  uint64_t v7 = (uint64_t (*)(uint64_t, uint64_t))v0[1];
  return v7(v48, 1);
}

void TreeClassifierTrainingSessionDelegate.saveCheckpoint(to:phase:iteration:)()
{
  OUTLINED_FUNCTION_9_0();
  uint64_t v4 = v3;
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyTreeClassifier?);
  uint64_t v6 = OUTLINED_FUNCTION_17(v5);
  MEMORY[0x270FA5388](v6);
  OUTLINED_FUNCTION_3_0();
  uint64_t v9 = v8 - v7;
  uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyTreeClassifierModel?);
  uint64_t v11 = OUTLINED_FUNCTION_17(v10);
  MEMORY[0x270FA5388](v11);
  OUTLINED_FUNCTION_27_7();
  uint64_t v12 = type metadata accessor for AnyTreeClassifierModel();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v13);
  OUTLINED_FUNCTION_41_0();
  uint64_t v14 = *v4;
  uint64_t v15 = v0 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_model;
  OUTLINED_FUNCTION_53();
  outlined init with copy of URL?(v15, v2, &demangling cache variable for type metadata for AnyTreeClassifierModel?);
  OUTLINED_FUNCTION_57_4(v2, 1, v12);
  if (v16)
  {
    outlined destroy of URL?(v2, &demangling cache variable for type metadata for AnyTreeClassifierModel?);
  }
  else
  {
    outlined init with take of AnyTreeClassifierModel(v2, v1, (void (*)(void))type metadata accessor for AnyTreeClassifierModel);
    switch(v14)
    {
      case 2:
        swift_bridgeObjectRelease();
        goto LABEL_8;
      case 4:
        OUTLINED_FUNCTION_55_0();
        break;
      default:
        break;
    }
    char v17 = OUTLINED_FUNCTION_37_5();
    swift_bridgeObjectRelease();
    if (v17)
    {
LABEL_8:
      uint64_t v18 = v0 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_classifier;
      OUTLINED_FUNCTION_53();
      outlined init with copy of URL?(v18, v9, &demangling cache variable for type metadata for AnyTreeClassifier?);
      uint64_t v19 = type metadata accessor for AnyTreeClassifier();
      OUTLINED_FUNCTION_57_4(v9, 1, v19);
      if (v16)
      {
        __break(1u);
        JUMPOUT(0x22710E48CLL);
      }
      lazy protocol witness table accessor for type AnyTreeClassifier and conformance AnyTreeClassifier();
      SupervisedTabularEstimator.write(_:to:overwrite:)();
      outlined destroy of AnyTreeClassifierModel(v1, (void (*)(void))type metadata accessor for AnyTreeClassifierModel);
      outlined destroy of AnyTreeClassifierModel(v9, (void (*)(void))type metadata accessor for AnyTreeClassifier);
    }
    else
    {
      outlined destroy of AnyTreeClassifierModel(v1, (void (*)(void))type metadata accessor for AnyTreeClassifierModel);
    }
  }
  OUTLINED_FUNCTION_8_1();
}

uint64_t TreeClassifierTrainingSessionDelegate.save(to:)(uint64_t a1)
{
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?);
  uint64_t v6 = OUTLINED_FUNCTION_17(v5);
  MEMORY[0x270FA5388](v6);
  uint64_t v7 = OUTLINED_FUNCTION_34_6();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v8);
  OUTLINED_FUNCTION_41_0();
  uint64_t v9 = v1 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingParameters;
  OUTLINED_FUNCTION_53();
  outlined init with copy of URL?(v9, v2, &demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?);
  OUTLINED_FUNCTION_57_4(v2, 1, v7);
  if (v10)
  {
    outlined destroy of URL?(v2, &demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?);
    lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    OUTLINED_FUNCTION_85();
    *(void *)uint64_t v11 = 0xD000000000000031;
    *(void *)(v11 + 8) = 0x80000002272D70A0;
    *(_OWORD *)(v11 + 16) = 0u;
    *(_OWORD *)(v11 + 32) = 0u;
    *(unsigned char *)(v11 + 48) = 2;
    return swift_willThrow();
  }
  else
  {
    outlined init with take of AnyTreeClassifierModel(v2, v3, (void (*)(void))type metadata accessor for PersistentParametersForTreeBasedMethods);
    PersistentParametersForTreeBasedMethods.save(toSessionDirectory:)(a1);
    return outlined destroy of AnyTreeClassifierModel(v3, (void (*)(void))type metadata accessor for PersistentParametersForTreeBasedMethods);
  }
}

void TreeClassifierTrainingSessionDelegate.restore(from:phase:)()
{
  OUTLINED_FUNCTION_9_0();
  uint64_t v30 = v0;
  uint64_t v4 = v3;
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?);
  uint64_t v6 = OUTLINED_FUNCTION_17(v5);
  MEMORY[0x270FA5388](v6);
  OUTLINED_FUNCTION_33_7();
  MEMORY[0x270FA5388](v7);
  uint64_t v9 = (char *)&v29 - v8;
  uint64_t v10 = type metadata accessor for URL();
  OUTLINED_FUNCTION_0();
  uint64_t v12 = v11;
  MEMORY[0x270FA5388](v13);
  OUTLINED_FUNCTION_3_0();
  uint64_t v16 = v15 - v14;
  uint64_t v17 = type metadata accessor for PersistentParametersForTreeBasedMethods();
  OUTLINED_FUNCTION_8();
  uint64_t v19 = MEMORY[0x270FA5388](v18);
  uint64_t v21 = (char *)&v29 - ((v20 + 15) & 0xFFFFFFFFFFFFFFF0);
  MEMORY[0x270FA5388](v19);
  uint64_t v23 = (char *)&v29 - v22;
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v12 + 16))(v16, v4, v10);
  PersistentParametersForTreeBasedMethods.init(sessionDirectory:)(v16, (uint64_t)v23);
  if (!v1)
  {
    uint64_t v24 = v30 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingParameters;
    OUTLINED_FUNCTION_53();
    outlined init with copy of URL?(v24, (uint64_t)v9, &demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?);
    OUTLINED_FUNCTION_57_4((uint64_t)v9, 1, v17);
    if (v25)
    {
      outlined destroy of URL?((uint64_t)v9, &demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?);
      outlined init with take of AnyTreeClassifierModel((uint64_t)v23, v2, (void (*)(void))type metadata accessor for PersistentParametersForTreeBasedMethods);
      OUTLINED_FUNCTION_82_1();
      __swift_storeEnumTagSinglePayload(v26, v27, v28, v17);
      OUTLINED_FUNCTION_4_23();
      outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v2, v24, &demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?);
      swift_endAccess();
    }
    else
    {
      outlined init with take of AnyTreeClassifierModel((uint64_t)v9, (uint64_t)v21, (void (*)(void))type metadata accessor for PersistentParametersForTreeBasedMethods);
      TreeClassifierTrainingSessionDelegate.verifyThatParametersAreCompatible(_:_:)((uint64_t)v23, (uint64_t)v21);
      outlined destroy of AnyTreeClassifierModel((uint64_t)v21, (void (*)(void))type metadata accessor for PersistentParametersForTreeBasedMethods);
      outlined destroy of AnyTreeClassifierModel((uint64_t)v23, (void (*)(void))type metadata accessor for PersistentParametersForTreeBasedMethods);
    }
  }
  OUTLINED_FUNCTION_8_1();
}

uint64_t TreeClassifierTrainingSessionDelegate.verifyThatParametersAreCompatible(_:_:)(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = type metadata accessor for PersistentParametersForTreeBasedMethods();
  uint64_t v5 = *(int *)(v4 + 24);
  uint64_t v6 = *(void *)(a1 + v5);
  uint64_t v7 = *(void *)(a1 + v5 + 8);
  uint64_t v8 = (void *)(a2 + v5);
  BOOL v9 = v6 == *v8 && v7 == v8[1];
  if (v9 || (_stringCompareWithSmolCheck(_:_:expecting:)() & 1) != 0)
  {
    uint64_t v10 = swift_bridgeObjectRetain();
    uint64_t v11 = specialized Set.init<A>(_:)(v10);
    uint64_t v12 = swift_bridgeObjectRetain();
    uint64_t v13 = specialized Set.init<A>(_:)(v12);
    specialized static Set.== infix(_:_:)(v11, v13);
    char v15 = v14;
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    if (v15)
    {
      static BoostedTreeConfiguration.firstIncompatibility(_:_:)(a1 + *(int *)(v4 + 32), v25);
      uint64_t result = outlined init with take of (name: String, originalValue: String, newValue: String)?((uint64_t)v25, (uint64_t)&v26);
      unint64_t v17 = v27;
      if (!v27) {
        return result;
      }
      uint64_t v18 = v26;
      uint64_t v6 = v28;
      uint64_t v7 = v29;
      uint64_t v19 = v30;
      uint64_t v20 = v31;
      lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
      OUTLINED_FUNCTION_85();
      *(void *)uint64_t v21 = v18;
    }
    else
    {
      swift_bridgeObjectRetain();
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String]);
      lazy protocol witness table accessor for type [String] and conformance [A]();
      uint64_t v6 = OUTLINED_FUNCTION_51_5();
      uint64_t v7 = v22;
      swift_bridgeObjectRelease();
      swift_bridgeObjectRetain();
      OUTLINED_FUNCTION_51_5();
      swift_bridgeObjectRelease();
      uint64_t v19 = String.init<A>(_:)();
      uint64_t v20 = v23;
      lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
      OUTLINED_FUNCTION_85();
      *(void *)uint64_t v21 = 0xD000000000000011;
      unint64_t v17 = 0x80000002272D7080;
    }
  }
  else
  {
    swift_bridgeObjectRetain();
    swift_bridgeObjectRetain();
    uint64_t v19 = String.init<A>(_:)();
    uint64_t v20 = v24;
    lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    OUTLINED_FUNCTION_85();
    *(void *)uint64_t v21 = 0x6320746567726154;
    unint64_t v17 = 0xED00006E6D756C6FLL;
  }
  *(void *)(v21 + 8) = v17;
  *(void *)(v21 + 16) = v6;
  *(void *)(v21 + 24) = v7;
  *(void *)(v21 + 32) = v19;
  *(void *)(v21 + 40) = v20;
  *(unsigned char *)(v21 + 48) = 3;
  return swift_willThrow();
}

void specialized static Set.== infix(_:_:)(uint64_t a1, uint64_t a2)
{
  if (a1 == a2 || *(void *)(a1 + 16) != *(void *)(a2 + 16)) {
    return;
  }
  uint64_t v3 = 0;
  uint64_t v4 = *(void *)(a1 + 56);
  uint64_t v34 = a1 + 56;
  uint64_t v5 = 1 << *(unsigned char *)(a1 + 32);
  if (v5 < 64) {
    uint64_t v6 = ~(-1 << v5);
  }
  else {
    uint64_t v6 = -1;
  }
  unint64_t v7 = v6 & v4;
  int64_t v35 = (unint64_t)(v5 + 63) >> 6;
  uint64_t v8 = a2 + 56;
  if ((v6 & v4) == 0) {
    goto LABEL_8;
  }
LABEL_7:
  unint64_t v9 = __clz(__rbit64(v7));
  v7 &= v7 - 1;
  int64_t v36 = v3;
  for (unint64_t i = v9 | (v3 << 6); ; unint64_t i = __clz(__rbit64(v12)) + (v13 << 6))
  {
    uint64_t v19 = a1;
    uint64_t v20 = (uint64_t *)(*(void *)(a1 + 48) + 16 * i);
    uint64_t v22 = *v20;
    uint64_t v21 = v20[1];
    Hasher.init(_seed:)();
    swift_bridgeObjectRetain();
    String.hash(into:)();
    Swift::Int v23 = Hasher._finalize()();
    uint64_t v24 = -1 << *(unsigned char *)(a2 + 32);
    unint64_t v25 = v23 & ~v24;
    if (((*(void *)(v8 + ((v25 >> 3) & 0xFFFFFFFFFFFFFF8)) >> v25) & 1) == 0) {
      goto LABEL_45;
    }
    uint64_t v26 = *(void *)(a2 + 48);
    unint64_t v27 = (void *)(v26 + 16 * v25);
    BOOL v28 = *v27 == v22 && v27[1] == v21;
    if (!v28 && (_stringCompareWithSmolCheck(_:_:expecting:)() & 1) == 0)
    {
      uint64_t v29 = ~v24;
      for (unint64_t j = v25 + 1; ; unint64_t j = v31 + 1)
      {
        uint64_t v31 = j & v29;
        if (((*(void *)(v8 + (((j & v29) >> 3) & 0xFFFFFFFFFFFFFF8)) >> (j & v29)) & 1) == 0) {
          break;
        }
        uint64_t v32 = (void *)(v26 + 16 * v31);
        BOOL v33 = *v32 == v22 && v32[1] == v21;
        if (v33 || (_stringCompareWithSmolCheck(_:_:expecting:)() & 1) != 0) {
          goto LABEL_34;
        }
      }
LABEL_45:
      swift_bridgeObjectRelease();
      return;
    }
LABEL_34:
    swift_bridgeObjectRelease();
    a1 = v19;
    uint64_t v3 = v36;
    if (v7) {
      goto LABEL_7;
    }
LABEL_8:
    int64_t v11 = v3 + 1;
    if (__OFADD__(v3, 1))
    {
      __break(1u);
      goto LABEL_48;
    }
    if (v11 >= v35) {
      return;
    }
    unint64_t v12 = *(void *)(v34 + 8 * v11);
    int64_t v13 = v3 + 1;
    if (!v12)
    {
      OUTLINED_FUNCTION_55_6();
      if (v14 == v15) {
        return;
      }
      OUTLINED_FUNCTION_54_5();
      if (!v12)
      {
        OUTLINED_FUNCTION_55_6();
        if (v14 == v15) {
          return;
        }
        OUTLINED_FUNCTION_54_5();
        if (!v12)
        {
          OUTLINED_FUNCTION_55_6();
          if (v14 == v15) {
            return;
          }
          OUTLINED_FUNCTION_54_5();
          if (!v12) {
            break;
          }
        }
      }
    }
LABEL_27:
    unint64_t v7 = (v12 - 1) & v12;
    int64_t v36 = v13;
  }
  int64_t v17 = v16 + 4;
  if (v17 >= v35) {
    return;
  }
  unint64_t v12 = *(void *)(v34 + 8 * v17);
  if (v12)
  {
    int64_t v13 = v17;
    goto LABEL_27;
  }
  while (!__OFADD__(v17, 1))
  {
    OUTLINED_FUNCTION_55_6();
    if (v14 == v15) {
      return;
    }
    OUTLINED_FUNCTION_54_5();
    int64_t v17 = v18 + 1;
    if (v12) {
      goto LABEL_27;
    }
  }
LABEL_48:
  __break(1u);
}

uint64_t TreeClassifierTrainingSessionDelegate.deinit()
{
  outlined destroy of AnyTreeClassifierModel(v0 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_sessionParameters, (void (*)(void))type metadata accessor for MLTrainingSessionParameters);
  outlined destroy of URL?(v0 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingParameters, &demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?);
  type metadata accessor for DataFrame();
  OUTLINED_FUNCTION_8();
  OUTLINED_FUNCTION_25_0();
  v1();
  outlined destroy of URL?(v0 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_validationData, &demangling cache variable for type metadata for DataFrame?);
  outlined destroy of URL?(v0 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_classifier, &demangling cache variable for type metadata for AnyTreeClassifier?);
  outlined destroy of URL?(v0 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_model, &demangling cache variable for type metadata for AnyTreeClassifierModel?);
  outlined destroy of URL?(v0 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingMetrics, &demangling cache variable for type metadata for AnyClassificationMetrics?);
  outlined destroy of URL?(v0 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_validationMetrics, &demangling cache variable for type metadata for AnyClassificationMetrics?);
  return v0;
}

uint64_t TreeClassifierTrainingSessionDelegate.__deallocating_deinit()
{
  TreeClassifierTrainingSessionDelegate.deinit();
  OUTLINED_FUNCTION_4_12();

  return swift_deallocClassInstance();
}

uint64_t ObjC metadata update function for TreeClassifierTrainingSessionDelegate()
{
  return type metadata accessor for TreeClassifierTrainingSessionDelegate();
}

uint64_t type metadata accessor for TreeClassifierTrainingSessionDelegate()
{
  uint64_t result = type metadata singleton initialization cache for TreeClassifierTrainingSessionDelegate;
  if (!type metadata singleton initialization cache for TreeClassifierTrainingSessionDelegate) {
    return swift_getSingletonMetadata();
  }
  return result;
}

void type metadata completion function for TreeClassifierTrainingSessionDelegate()
{
  type metadata accessor for MLTrainingSessionParameters();
  if (v0 <= 0x3F)
  {
    type metadata accessor for PersistentParametersForTreeBasedMethods?(319, &lazy cache variable for type metadata for PersistentParametersForTreeBasedMethods?, (void (*)(uint64_t))type metadata accessor for PersistentParametersForTreeBasedMethods);
    if (v1 <= 0x3F)
    {
      type metadata accessor for DataFrame();
      if (v2 <= 0x3F)
      {
        type metadata accessor for PersistentParametersForTreeBasedMethods?(319, (unint64_t *)&lazy cache variable for type metadata for DataFrame?, MEMORY[0x263F1BEC8]);
        if (v3 <= 0x3F)
        {
          type metadata accessor for PersistentParametersForTreeBasedMethods?(319, &lazy cache variable for type metadata for AnyTreeClassifier?, (void (*)(uint64_t))type metadata accessor for AnyTreeClassifier);
          if (v4 <= 0x3F)
          {
            type metadata accessor for PersistentParametersForTreeBasedMethods?(319, &lazy cache variable for type metadata for AnyTreeClassifierModel?, (void (*)(uint64_t))type metadata accessor for AnyTreeClassifierModel);
            if (v5 <= 0x3F)
            {
              type metadata accessor for PersistentParametersForTreeBasedMethods?(319, &lazy cache variable for type metadata for AnyClassificationMetrics?, (void (*)(uint64_t))type metadata accessor for AnyClassificationMetrics);
              if (v6 <= 0x3F) {
                swift_updateClassMetadata2();
              }
            }
          }
        }
      }
    }
  }
}

void type metadata accessor for PersistentParametersForTreeBasedMethods?(uint64_t a1, unint64_t *a2, void (*a3)(uint64_t))
{
  if (!*a2)
  {
    a3(255);
    unint64_t v4 = type metadata accessor for Optional();
    if (!v5) {
      atomic_store(v4, a2);
    }
  }
}

void protocol witness for TrainingSessionDelegate.setUp() in conformance TreeClassifierTrainingSessionDelegate()
{
}

void protocol witness for TrainingSessionDelegate.resume(from:) in conformance TreeClassifierTrainingSessionDelegate(Swift::OpaquePointer a1)
{
}

unint64_t protocol witness for TrainingSessionDelegate.itemCount(phase:) in conformance TreeClassifierTrainingSessionDelegate(CreateML::MLPhase a1)
{
  return (unint64_t)TreeClassifierTrainingSessionDelegate.itemCount(phase:)(a1);
}

uint64_t protocol witness for TrainingSessionDelegate.train(from:) in conformance TreeClassifierTrainingSessionDelegate(uint64_t a1)
{
  unint64_t v3 = (void *)swift_task_alloc();
  *(void *)(v1 + 16) = v3;
  *unint64_t v3 = v1;
  v3[1] = protocol witness for TrainingSessionDelegate.train(from:) in conformance TreeClassifierTrainingSessionDelegate;
  return TreeClassifierTrainingSessionDelegate.train(from:)(a1);
}

uint64_t protocol witness for TrainingSessionDelegate.train(from:) in conformance TreeClassifierTrainingSessionDelegate(uint64_t a1, uint64_t a2, char a3)
{
  OUTLINED_FUNCTION_2();
  uint64_t v8 = *v4;
  OUTLINED_FUNCTION_6();
  *unint64_t v9 = v8;
  uint64_t v10 = swift_task_dealloc();
  unint64_t v12 = *(uint64_t (**)(uint64_t, uint64_t, uint64_t))(v8 + 8);
  if (v3)
  {
    uint64_t v13 = 0;
  }
  else
  {
    uint64_t v13 = a3 & 1;
    uint64_t v10 = a1;
    uint64_t v11 = a2;
  }
  return v12(v10, v11, v13);
}

uint64_t protocol witness for TrainingSessionDelegate.evaluate(from:) in conformance TreeClassifierTrainingSessionDelegate()
{
  uint64_t v1 = (void *)swift_task_alloc();
  *(void *)(v0 + 16) = v1;
  void *v1 = v0;
  v1[1] = protocol witness for TrainingSessionDelegate.evaluate(from:) in conformance TreeClassifierTrainingSessionDelegate;
  return TreeClassifierTrainingSessionDelegate.evaluate(from:)();
}

uint64_t protocol witness for TrainingSessionDelegate.evaluate(from:) in conformance TreeClassifierTrainingSessionDelegate(uint64_t a1, char a2)
{
  OUTLINED_FUNCTION_2();
  uint64_t v6 = *v3;
  OUTLINED_FUNCTION_6();
  void *v7 = v6;
  uint64_t v8 = swift_task_dealloc();
  unint64_t v9 = *(uint64_t (**)(uint64_t, uint64_t))(v6 + 8);
  if (v2)
  {
    uint64_t v10 = 0;
  }
  else
  {
    uint64_t v10 = a2 & 1;
    uint64_t v8 = a1;
  }
  return v9(v8, v10);
}

uint64_t protocol witness for TrainingSessionDelegate.saveCheckpoint(to:phase:iteration:) in conformance TreeClassifierTrainingSessionDelegate()
{
  TreeClassifierTrainingSessionDelegate.saveCheckpoint(to:phase:iteration:)();
  return v0 & 1;
}

uint64_t protocol witness for TrainingSessionCodable.save(to:) in conformance TreeClassifierTrainingSessionDelegate(uint64_t a1)
{
  return TreeClassifierTrainingSessionDelegate.save(to:)(a1);
}

void protocol witness for TrainingSessionCodable.restore(from:phase:) in conformance TreeClassifierTrainingSessionDelegate()
{
}

unint64_t lazy protocol witness table accessor for type AnyTreeClassifier and conformance AnyTreeClassifier()
{
  unint64_t result = lazy protocol witness table cache variable for type AnyTreeClassifier and conformance AnyTreeClassifier;
  if (!lazy protocol witness table cache variable for type AnyTreeClassifier and conformance AnyTreeClassifier)
  {
    type metadata accessor for AnyTreeClassifier();
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type AnyTreeClassifier and conformance AnyTreeClassifier);
  }
  return result;
}

{
  unint64_t result;

  unint64_t result = lazy protocol witness table cache variable for type AnyTreeClassifier and conformance AnyTreeClassifier;
  if (!lazy protocol witness table cache variable for type AnyTreeClassifier and conformance AnyTreeClassifier)
  {
    type metadata accessor for AnyTreeClassifier();
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type AnyTreeClassifier and conformance AnyTreeClassifier);
  }
  return result;
}

uint64_t outlined assign with copy of DataFrame?(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 24))(a2, a1, v4);
  return a2;
}

unint64_t lazy protocol witness table accessor for type [String] and conformance [A]()
{
  unint64_t result = lazy protocol witness table cache variable for type [String] and conformance [A];
  if (!lazy protocol witness table cache variable for type [String] and conformance [A])
  {
    __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for [String]);
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type [String] and conformance [A]);
  }
  return result;
}

{
  unint64_t result;

  unint64_t result = lazy protocol witness table cache variable for type [String] and conformance [A];
  if (!lazy protocol witness table cache variable for type [String] and conformance [A])
  {
    __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for [String]);
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type [String] and conformance [A]);
  }
  return result;
}

uint64_t outlined init with take of (name: String, originalValue: String, newValue: String)?(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (name: String, originalValue: String, newValue: String)?);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 32))(a2, a1, v4);
  return a2;
}

uint64_t outlined destroy of AnyTreeClassifierModel(uint64_t a1, void (*a2)(void))
{
  a2(0);
  OUTLINED_FUNCTION_8();
  OUTLINED_FUNCTION_25_0();
  v3();
  return a1;
}

uint64_t outlined init with take of AnyTreeClassifierModel(uint64_t a1, uint64_t a2, void (*a3)(void))
{
  a3(0);
  OUTLINED_FUNCTION_8();
  (*(void (**)(uint64_t, uint64_t))(v5 + 32))(a2, a1);
  return a2;
}

uint64_t outlined init with copy of PersistentParametersForTreeBasedMethods(uint64_t a1, uint64_t a2, void (*a3)(void))
{
  a3(0);
  OUTLINED_FUNCTION_8();
  uint64_t v4 = OUTLINED_FUNCTION_111();
  v5(v4);
  return a2;
}

uint64_t OUTLINED_FUNCTION_4_23()
{
  return swift_beginAccess();
}

uint64_t OUTLINED_FUNCTION_10_13()
{
  return *(void *)(v0 + 208);
}

void *OUTLINED_FUNCTION_13_14()
{
  return specialized _dictionaryUpCast<A, B, C, D>(_:)(v0);
}

uint64_t OUTLINED_FUNCTION_18_10()
{
  return swift_beginAccess();
}

uint64_t OUTLINED_FUNCTION_19_11()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_20_10(uint64_t a1)
{
  return __swift_storeEnumTagSinglePayload(a1, 0, 1, v1);
}

uint64_t OUTLINED_FUNCTION_21_11@<X0>(uint64_t a1@<X8>, uint64_t a2)
{
  *(void *)(v2 - 232) = (char *)&a2 - ((a1 + 15) & 0xFFFFFFFFFFFFFFF0);
  return 0;
}

uint64_t OUTLINED_FUNCTION_25_12()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_34_6()
{
  return type metadata accessor for PersistentParametersForTreeBasedMethods();
}

uint64_t OUTLINED_FUNCTION_36_6()
{
  return *(void *)(v0 + 264);
}

uint64_t OUTLINED_FUNCTION_37_5()
{
  return _stringCompareWithSmolCheck(_:_:expecting:)();
}

uint64_t OUTLINED_FUNCTION_44_3()
{
  return DataFrame.subscript.getter();
}

uint64_t OUTLINED_FUNCTION_45_4()
{
  return swift_bridgeObjectRetain();
}

unint64_t OUTLINED_FUNCTION_46_5(char a1)
{
  return specialized _NativeDictionary.setValue(_:forKey:isUnique:)(3, a1, v2);
}

unint64_t OUTLINED_FUNCTION_47_5(char a1)
{
  return specialized _NativeDictionary.setValue(_:forKey:isUnique:)(0, a1, v2);
}

uint64_t OUTLINED_FUNCTION_48_4()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_51_5()
{
  return BidirectionalCollection<>.joined(separator:)();
}

uint64_t OUTLINED_FUNCTION_53_7()
{
  return swift_bridgeObjectRetain();
}

uint64_t OUTLINED_FUNCTION_56_7()
{
  return _assertionFailure(_:_:file:line:flags:)();
}

uint64_t OUTLINED_FUNCTION_57_6()
{
  return static MetricsKey.trainingLoss.getter();
}

uint64_t OUTLINED_FUNCTION_61_4(uint64_t a1, uint64_t a2, uint64_t a3)
{
  __swift_getEnumTagSinglePayload(v3, 1, a3);
  return outlined destroy of URL?(v3, v4);
}

uint64_t OUTLINED_FUNCTION_63_3()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_64_2()
{
  return *(void *)(v0 + 160) + *(void *)(v0 + 280);
}

uint64_t OUTLINED_FUNCTION_65_2()
{
  return v0;
}

void CMLModel.initialize(options:)()
{
  OUTLINED_FUNCTION_4_24();
  if (v1)
  {
    uint64_t v2 = v1;
    type metadata accessor for CMLParameters();
    uint64_t inited = swift_initStackObject();
    *(void *)(inited + 16) = v2;
    type metadata accessor for CMLFeatureValue();
    uint64_t v4 = swift_retain();
    uint64_t v5 = CMLFeatureValue.__allocating_init(_:)(v4);
    if (v0)
    {
      swift_release();
    }
    else
    {
      CMLParameters.add(key:featureValue:)(33, v5);
      CMLModel.callFunction(name:arguments:)(14, inited);
      swift_release();
      swift_release();
      swift_setDeallocating();
      tc_v1_release();
    }
  }
  else
  {
    __break(1u);
  }
}

void CMLModel.addMetadata(_:)()
{
  OUTLINED_FUNCTION_4_24();
  if (v1)
  {
    uint64_t v2 = v1;
    type metadata accessor for CMLParameters();
    uint64_t inited = swift_initStackObject();
    *(void *)(inited + 16) = v2;
    type metadata accessor for CMLFeatureValue();
    uint64_t v4 = swift_retain();
    uint64_t v5 = CMLFeatureValue.__allocating_init(_:)(v4);
    if (v0)
    {
      swift_release();
    }
    else
    {
      CMLParameters.add(key:featureValue:)(32, v5);
      swift_release();
      CMLModel.callFunction(name:arguments:)(7, inited);
      swift_release();
      swift_setDeallocating();
      tc_v1_release();
    }
  }
  else
  {
    __break(1u);
  }
}

uint64_t CMLModel.save(to:)()
{
  uint64_t v1 = MEMORY[0x22A676420](0);
  if (v1)
  {
    uint64_t v2 = v1;
    type metadata accessor for CMLParameters();
    uint64_t inited = swift_initStackObject();
    *(void *)(inited + 16) = v2;
    URL.path.getter();
    type metadata accessor for CMLFeatureValue();
    swift_bridgeObjectRetain();
    uint64_t v4 = CMLFeatureValue.__allocating_init(_:)();
    if (!v0)
    {
      uint64_t v5 = v4;
      swift_bridgeObjectRelease();
      CMLParameters.add(key:featureValue:)(8, v5);
      swift_release();
      CMLModel.callFunction(name:arguments:)(6, inited);
      swift_release();
      swift_setDeallocating();
      return tc_v1_release();
    }
  }
  else
  {
    __break(1u);
  }
  uint64_t result = swift_unexpectedError();
  __break(1u);
  return result;
}

uint64_t CMLModel.export(to:)(uint64_t a1)
{
  v22[5] = *v1;
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  MEMORY[0x270FA5388](v4 - 8);
  uint64_t v6 = (char *)v22 - ((v5 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v7 = type metadata accessor for URL();
  uint64_t v8 = *(void *)(v7 - 8);
  MEMORY[0x270FA5388](v7);
  uint64_t v10 = (char *)v22 - ((v9 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v11 = MEMORY[0x22A676420](0);
  if (!v11)
  {
    __break(1u);
LABEL_10:
    __break(1u);
    goto LABEL_11;
  }
  uint64_t v12 = v11;
  type metadata accessor for CMLParameters();
  uint64_t inited = swift_initStackObject();
  *(void *)(inited + 16) = v12;
  outlined init with copy of URL?(a1, (uint64_t)v6);
  if (__swift_getEnumTagSinglePayload((uint64_t)v6, 1, v7) == 1)
  {
    outlined destroy of URL?((uint64_t)v6);
    type metadata accessor for CMLFeatureValue();
    uint64_t v14 = CMLFeatureValue.__allocating_init(_:)();
    if (!v2)
    {
      CMLParameters.add(key:featureValue:)(27, v14);
      goto LABEL_7;
    }
  }
  else
  {
    (*(void (**)(char *, char *, uint64_t))(v8 + 32))(v10, v6, v7);
    URL.path.getter();
    type metadata accessor for CMLFeatureValue();
    swift_bridgeObjectRetain();
    uint64_t v15 = CMLFeatureValue.__allocating_init(_:)();
    if (!v2)
    {
      uint64_t v16 = v15;
      swift_bridgeObjectRelease();
      CMLParameters.add(key:featureValue:)(27, v16);
      uint64_t v17 = OUTLINED_FUNCTION_3_29();
      v18(v17);
LABEL_7:
      swift_release();
      uint64_t v19 = CMLModel.callFunction(name:arguments:)(8, inited);
      uint64_t v20 = specialized handling<A, B>(_:_:)(v19[2]);
      if (v20)
      {
        swift_release();
        swift_setDeallocating();
        tc_v1_release();
        uint64_t result = swift_allocObject();
        *(void *)(result + 16) = v20;
        return result;
      }
      goto LABEL_10;
    }
  }
LABEL_11:
  uint64_t result = swift_unexpectedError();
  __break(1u);
  return result;
}

uint64_t outlined init with copy of URL?(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 16))(a2, a1, v4);
  return a2;
}

uint64_t outlined destroy of URL?(uint64_t a1)
{
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v2 - 8) + 8))(a1, v2);
  return a1;
}

uint64_t CMLModel.compile()()
{
  v1[16] = v0;
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  v1[17] = swift_task_alloc();
  uint64_t v2 = type metadata accessor for UUID();
  v1[18] = v2;
  OUTLINED_FUNCTION_1(v2);
  v1[19] = v3;
  v1[20] = swift_task_alloc();
  uint64_t v4 = type metadata accessor for URL();
  v1[21] = v4;
  OUTLINED_FUNCTION_1(v4);
  v1[22] = v5;
  v1[23] = swift_task_alloc();
  v1[24] = swift_task_alloc();
  v1[25] = swift_task_alloc();
  return MEMORY[0x270FA2498](CMLModel.compile(), 0, 0);
}

{
  void *v0;
  id v1;
  uint64_t v2;
  uint64_t v3;
  void (*v4)(void);
  void (*v5)(void);
  uint64_t v6;
  void (*v7)(uint64_t);
  uint64_t v8;
  uint64_t v9;
  uint64_t (*v10)(void);
  uint64_t v12;
  unint64_t v13;
  uint64_t v14;
  unint64_t v15;
  id v16;
  id v17;
  void *v18;
  id v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;

  uint64_t v1 = objc_msgSend(self, sel_defaultManager);
  v0[26] = v1;
  NSFileManager.createTemporaryModelDirectory()();
  if (v2)
  {

    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    uint64_t v10 = (uint64_t (*)(void))v0[1];
    return v10();
  }
  else
  {
    uint64_t v3 = v0[22];
    uint64_t v21 = v0[21];
    uint64_t v22 = v0[17];
    NSFileManager.temporaryModelDirectory.getter();
    UUID.init()();
    UUID.uuidString.getter();
    OUTLINED_FUNCTION_24_5();
    v4();
    URL.appendingPathComponent(_:)();
    swift_bridgeObjectRelease();
    URL.appendingPathExtension(_:)();
    v0[27] = *(void *)(v3 + 8);
    v0[28] = (v3 + 8) & 0xFFFFFFFFFFFFLL | 0x4F8000000000000;
    OUTLINED_FUNCTION_24_5();
    v5();
    uint64_t v6 = OUTLINED_FUNCTION_2_29();
    v7(v6);
    __swift_storeEnumTagSinglePayload(v22, 0, 1, v21);
    CMLModel.export(to:)(v22);
    uint64_t v8 = v0[17];
    swift_release();
    outlined destroy of URL?(v8);
    v0[29] = Data.init(contentsOf:options:)();
    v0[30] = v9;
    type metadata accessor for MLModelAsset();
    uint64_t v12 = OUTLINED_FUNCTION_2_29();
    outlined copy of Data._Representation(v12, v13);
    uint64_t v14 = OUTLINED_FUNCTION_2_29();
    uint64_t v16 = @nonobjc MLModelAsset.__allocating_init(specification:)(v14, v15);
    v0[31] = v16;
    uint64_t v17 = v16;
    uint64_t v18 = self;
    uint64_t v19 = objc_msgSend(objc_allocWithZone(MEMORY[0x263F00D98]), sel_init);
    v0[32] = v19;
    v0[2] = v0;
    v0[7] = v0 + 15;
    v0[3] = CMLModel.compile();
    uint64_t v20 = swift_continuation_init();
    v0[10] = MEMORY[0x263EF8330];
    v0[11] = 0x40000000;
    v0[12] = @objc completion handler block implementation for @escaping @callee_unowned @convention(block) (@unowned MLModel?, @unowned NSError?) -> () with result type MLModel;
    v0[13] = &block_descriptor_0;
    v0[14] = v20;
    objc_msgSend(v18, sel_loadModelAsset_configuration_completionHandler_, v17, v19, v0 + 10);
    return MEMORY[0x270FA23F0](v0 + 2);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t (*v2)();
  uint64_t v4;

  uint64_t v1 = *(void *)(*(void *)v0 + 48);
  *(void *)(*(void *)v0 + 264) = v1;
  if (v1) {
    uint64_t v2 = CMLModel.compile();
  }
  else {
    uint64_t v2 = CMLModel.compile();
  }
  return MEMORY[0x270FA2498](v2, 0, 0);
}

{
  void *v0;
  void *v1;
  void *v2;
  void (*v3)(uint64_t, uint64_t);
  uint64_t v4;
  void *v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t (*v9)(uint64_t);
  uint64_t v11;

  uint64_t v1 = (void *)v0[31];
  uint64_t v2 = (void *)v0[32];
  uint64_t v3 = (void (*)(uint64_t, uint64_t))v0[27];
  uint64_t v4 = v0[25];
  uint64_t v5 = (void *)v0[26];
  uint64_t v6 = v0[24];
  uint64_t v7 = v0[21];
  outlined consume of Data._Representation(v0[29], v0[30]);

  uint64_t v8 = v0[15];
  $defer #1 () in CMLModel.compile()(v5);

  v3(v6, v7);
  v3(v4, v7);
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  uint64_t v9 = (uint64_t (*)(uint64_t))v0[1];
  return v9(v8);
}

{
  void *v0;
  unint64_t v1;
  void *v2;
  uint64_t v3;
  void *v4;
  void (*v5)(uint64_t, uint64_t);
  uint64_t v6;
  uint64_t v7;
  uint64_t (*v8)(void);
  void *v10;
  uint64_t v11;
  uint64_t v12;

  uint64_t v1 = v0[30];
  uint64_t v2 = (void *)v0[31];
  uint64_t v3 = v0[29];
  uint64_t v4 = (void *)v0[26];
  uint64_t v5 = (void (*)(uint64_t, uint64_t))v0[27];
  uint64_t v6 = v0[24];
  uint64_t v10 = (void *)v0[32];
  uint64_t v11 = v0[25];
  uint64_t v7 = v0[21];
  swift_willThrow();
  outlined consume of Data._Representation(v3, v1);

  $defer #1 () in CMLModel.compile()(v4);
  v5(v6, v7);
  v5(v11, v7);
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  uint64_t v8 = (uint64_t (*)(void))v0[1];
  return v8();
}

void $defer #1 () in CMLModel.compile()(void *a1)
{
  uint64_t v9 = (NSURL *)*MEMORY[0x263EF8340];
  URL._bridgeToObjectiveC()(v9);
  uint64_t v3 = v2;
  id v8 = 0;
  LODWORD(a1) = objc_msgSend(a1, sel_removeItemAtURL_error_, v2, &v8);

  id v4 = v8;
  if (a1)
  {
    id v5 = v4;
  }
  else
  {
    id v6 = v8;
    uint64_t v7 = (void *)_convertNSErrorToError(_:)();

    swift_willThrow();
  }
}

uint64_t OUTLINED_FUNCTION_2_29()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_3_29()
{
  return v0;
}

void OUTLINED_FUNCTION_4_24()
{
  JUMPOUT(0x22A676420);
}

uint64_t _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSDySSypG_8CreateML11MLDataValueO_AItsAE_pTg5020_sSS3key_x5valuetSg8d4ML11fg5OAFs5c136_pIgnrrzo_SSAA_xABtAF_AFtsAG_pIegnrzr_lTRyp_TG503_s8c39ML15MLUntypedColumnVyAC11TabularData0D0l18SDySSxGGKclufcAA11ef34OAGSgKXEfU_AJ_AJti1_J22SgV8U_yp_Tg5Tf3nnnpf_nTf1cn_n(uint64_t a1)
{
  int64_t v1 = *(void *)(a1 + 16);
  uint64_t v2 = (uint64_t *)MEMORY[0x263F8EE78];
  if (!v1) {
    return (uint64_t)v2;
  }
  uint64_t v3 = a1;
  uint64_t v52 = (uint64_t *)MEMORY[0x263F8EE78];
  specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v1, 0);
  uint64_t result = specialized Dictionary.startIndex.getter(v3);
  if ((result & 0x8000000000000000) == 0)
  {
    unint64_t v6 = result;
    if (result < 1 << *(unsigned char *)(v3 + 32))
    {
      int v7 = v5;
      uint64_t v8 = v3 + 64;
      uint64_t v20 = v3;
      uint64_t v21 = MEMORY[0x263F8EE58] + 8;
      uint64_t v22 = v3 + 64;
      while ((*(void *)(v8 + 8 * (v6 >> 6)) & (1 << v6)) != 0)
      {
        if (v7 != *(_DWORD *)(v3 + 36)) {
          goto LABEL_25;
        }
        unint64_t v53 = v6 >> 6;
        uint64_t v9 = (uint64_t *)(*(void *)(v3 + 48) + 16 * v6);
        uint64_t v11 = *v9;
        uint64_t v10 = v9[1];
        outlined init with copy of Any(*(void *)(v3 + 56) + 32 * v6, (uint64_t)v45);
        v44[0] = v11;
        v44[1] = v10;
        *(void *)&long long v42 = v11;
        *((void *)&v42 + 1) = v10;
        outlined init with copy of Any((uint64_t)v45, (uint64_t)v43);
        long long v40 = v42;
        v41[0] = v43[0];
        v41[1] = v43[1];
        swift_bridgeObjectRetain_n();
        outlined destroy of DefaultIndices<DataFrame.Rows>((uint64_t)v44, &demangling cache variable for type metadata for (key: String, value: Any));
        long long v12 = v40;
        outlined init with copy of Any((uint64_t)v41, (uint64_t)v37);
        long long v38 = v12;
        outlined init with take of Any(v37, &v39);
        outlined init with copy of MLShapedArray<Int32>?((uint64_t)&v38, (uint64_t)&v32, &demangling cache variable for type metadata for (key: String, value: Any)?);
        uint64_t v13 = v33;
        int64_t v28 = v1;
        int v29 = v7;
        if (v33)
        {
          uint64_t v14 = v32;
          v35[0] = v32;
          v35[1] = v33;
          outlined init with take of Any(v34, v36);
          uint64_t v32 = v14;
          uint64_t v33 = v13;
          outlined init with copy of Any((uint64_t)v36, (uint64_t)v34);
          uint64_t v46 = v14;
          uint64_t v47 = v13;
          char v48 = 2;
          outlined init with copy of Any((uint64_t)v36, (uint64_t)v30);
          v31[3] = v21;
          v31[0] = swift_allocObject();
          outlined init with take of Any(v30, (_OWORD *)(v31[0] + 16));
          swift_bridgeObjectRetain();
          swift_bridgeObjectRetain();
          MLDataValue.init(fromAny:)((uint64_t)v31, (uint64_t)&v49);
          if (v23)
          {
            swift_bridgeObjectRelease();
            uint64_t v2 = &demangling cache variable for type metadata for (key: String, value: Any);
            outlined destroy of DefaultIndices<DataFrame.Rows>((uint64_t)v35, &demangling cache variable for type metadata for (key: String, value: Any));
            __swift_destroy_boxed_opaque_existential_0((uint64_t)v34);
            outlined destroy of DefaultIndices<DataFrame.Rows>((uint64_t)&v38, &demangling cache variable for type metadata for (key: String, value: Any)?);
            outlined destroy of DefaultIndices<DataFrame.Rows>((uint64_t)&v40, &demangling cache variable for type metadata for (key: String, value: Any));
            swift_release();
            return (uint64_t)v2;
          }
          outlined destroy of DefaultIndices<DataFrame.Rows>((uint64_t)v35, &demangling cache variable for type metadata for (key: String, value: Any));
          __swift_destroy_boxed_opaque_existential_0((uint64_t)v34);
          uint64_t v26 = v47;
          uint64_t v27 = v46;
          char v15 = v48;
          uint64_t v24 = v50;
          uint64_t v25 = v49;
          char v16 = v51;
          uint64_t v3 = v20;
        }
        else
        {
          swift_bridgeObjectRetain();
          outlined destroy of DefaultIndices<DataFrame.Rows>((uint64_t)&v32, &demangling cache variable for type metadata for (key: String, value: Any)?);
          uint64_t v24 = 0;
          uint64_t v25 = 0;
          uint64_t v26 = 0;
          uint64_t v27 = 0;
          uint64_t v46 = 0;
          uint64_t v47 = 0;
          char v16 = 6;
          char v48 = 6;
          uint64_t v49 = 0;
          uint64_t v50 = 0;
          char v15 = 6;
          char v51 = 6;
        }
        outlined destroy of DefaultIndices<DataFrame.Rows>((uint64_t)&v38, &demangling cache variable for type metadata for (key: String, value: Any)?);
        outlined destroy of DefaultIndices<DataFrame.Rows>((uint64_t)&v40, &demangling cache variable for type metadata for (key: String, value: Any));
        uint64_t v2 = v52;
        uint64_t result = swift_isUniquelyReferenced_nonNull_native();
        if ((result & 1) == 0)
        {
          uint64_t result = (uint64_t)specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v2[2] + 1, 1);
          uint64_t v2 = v52;
        }
        unint64_t v18 = v2[2];
        unint64_t v17 = v2[3];
        if (v18 >= v17 >> 1)
        {
          uint64_t result = (uint64_t)specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)((char *)(v17 > 1), v18 + 1, 1);
          uint64_t v2 = v52;
        }
        v2[2] = v18 + 1;
        uint64_t v19 = (char *)&v2[6 * v18];
        *((void *)v19 + 4) = v27;
        *((void *)v19 + 5) = v26;
        v19[48] = v15;
        *((void *)v19 + 7) = v25;
        *((void *)v19 + 8) = v24;
        v19[72] = v16;
        if ((uint64_t)v6 >= -(-1 << *(unsigned char *)(v3 + 32))) {
          goto LABEL_26;
        }
        uint64_t v8 = v22;
        if ((*(void *)(v22 + 8 * v53) & (1 << v6)) == 0) {
          goto LABEL_27;
        }
        if (v29 != *(_DWORD *)(v3 + 36)) {
          goto LABEL_28;
        }
        uint64_t result = _HashTable.occupiedBucket(after:)();
        int64_t v1 = v28 - 1;
        if (v28 == 1) {
          return (uint64_t)v2;
        }
        unint64_t v6 = result;
        if ((result & 0x8000000000000000) == 0)
        {
          int v7 = *(_DWORD *)(v3 + 36);
          if (result < 1 << *(unsigned char *)(v3 + 32)) {
            continue;
          }
        }
        goto LABEL_29;
      }
      __break(1u);
LABEL_25:
      __break(1u);
LABEL_26:
      __break(1u);
LABEL_27:
      __break(1u);
LABEL_28:
      __break(1u);
    }
  }
LABEL_29:
  __break(1u);
  return result;
}

uint64_t _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSDySSypSgG_8CreateML11MLDataValueO_AJtsAE_pTg5022_sSS3key_xSg5valuetSg8d4ML11fg5OAGs5c138_pIgnrrzo_SSAA_AbCtAG_AGtsAH_pIegnrzr_lTRyp_TG503_s8c39ML15MLUntypedColumnVyAC11TabularData0D0l20SDySSxSgGGKclufcAA11ef33OAHSgKXEfU_AK_AKtI31_AG5valuetsW8U_yp_Tg5Tf3nnnpf_nTf1cn_n(uint64_t a1)
{
  uint64_t v2 = v1;
  int64_t v3 = *(void *)(a1 + 16);
  uint64_t v4 = MEMORY[0x263F8EE78];
  if (!v3) {
    return v4;
  }
  uint64_t v5 = a1;
  uint64_t v41 = MEMORY[0x263F8EE78];
  specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v3, 0);
  uint64_t result = specialized Dictionary.startIndex.getter(v5);
  if ((result & 0x8000000000000000) == 0)
  {
    unint64_t v8 = result;
    if (result < 1 << *(unsigned char *)(v5 + 32))
    {
      uint64_t v9 = v5 + 64;
      uint64_t v22 = v5 + 64;
      uint64_t v23 = v5;
      while ((*(void *)(v9 + 8 * (v8 >> 6)) & (1 << v8)) != 0)
      {
        if (v7 != *(_DWORD *)(v5 + 36)) {
          goto LABEL_22;
        }
        unint64_t v42 = v8 >> 6;
        int v27 = v7;
        uint64_t v10 = *(void *)(v5 + 56);
        uint64_t v11 = (uint64_t *)(*(void *)(v5 + 48) + 16 * v8);
        uint64_t v12 = *v11;
        uint64_t v13 = v11[1];
        outlined init with copy of MLShapedArray<Int32>?(v10 + 32 * v8, (uint64_t)v36, &demangling cache variable for type metadata for Any?);
        v35[0] = v12;
        v35[1] = v13;
        *(void *)&long long v33 = v12;
        *((void *)&v33 + 1) = v13;
        outlined init with copy of MLShapedArray<Int32>?((uint64_t)v36, (uint64_t)v34, &demangling cache variable for type metadata for Any?);
        long long v31 = v33;
        v32[0] = v34[0];
        v32[1] = v34[1];
        swift_bridgeObjectRetain_n();
        outlined destroy of DefaultIndices<DataFrame.Rows>((uint64_t)v35, &demangling cache variable for type metadata for (key: String, value: Any?));
        uint64_t v4 = *((void *)&v31 + 1);
        uint64_t v14 = v31;
        outlined init with copy of MLShapedArray<Int32>?((uint64_t)v32, (uint64_t)v28, &demangling cache variable for type metadata for Any?);
        v29[0] = v14;
        v29[1] = v4;
        outlined init with take of Any?((uint64_t)v28, (uint64_t)&v30);
        swift_bridgeObjectRetain();
        specialized closure #1 in closure #1 in MLUntypedColumn.init<A>(_:)((uint64_t)v37, (uint64_t)v39, (uint64_t)v29);
        outlined destroy of DefaultIndices<DataFrame.Rows>((uint64_t)v29, &demangling cache variable for type metadata for (key: String, value: Any?)?);
        outlined destroy of DefaultIndices<DataFrame.Rows>((uint64_t)&v31, &demangling cache variable for type metadata for (key: String, value: Any?));
        if (v2)
        {
          swift_release();
          return v4;
        }
        uint64_t v15 = v37[0];
        uint64_t v16 = v37[1];
        char v17 = v38;
        uint64_t v18 = v39[0];
        uint64_t v26 = v39[1];
        char v25 = v40;
        uint64_t v4 = v41;
        uint64_t result = swift_isUniquelyReferenced_nonNull_native();
        int64_t v24 = v3;
        if ((result & 1) == 0)
        {
          uint64_t result = (uint64_t)specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, *(void *)(v4 + 16) + 1, 1);
          uint64_t v4 = v41;
        }
        unint64_t v20 = *(void *)(v4 + 16);
        unint64_t v19 = *(void *)(v4 + 24);
        if (v20 >= v19 >> 1)
        {
          uint64_t result = (uint64_t)specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)((char *)(v19 > 1), v20 + 1, 1);
          uint64_t v4 = v41;
        }
        *(void *)(v4 + 16) = v20 + 1;
        uint64_t v21 = v4 + 48 * v20;
        *(void *)(v21 + 32) = v15;
        *(void *)(v21 + 40) = v16;
        *(unsigned char *)(v21 + 48) = v17;
        *(void *)(v21 + 56) = v18;
        *(void *)(v21 + 64) = v26;
        *(unsigned char *)(v21 + 72) = v25;
        uint64_t v5 = v23;
        if ((uint64_t)v8 >= -(-1 << *(unsigned char *)(v23 + 32))) {
          goto LABEL_23;
        }
        uint64_t v9 = v22;
        if ((*(void *)(v22 + 8 * v42) & (1 << v8)) == 0) {
          goto LABEL_24;
        }
        if (v27 != *(_DWORD *)(v23 + 36)) {
          goto LABEL_25;
        }
        uint64_t result = _HashTable.occupiedBucket(after:)();
        --v3;
        if (v24 == 1) {
          return v4;
        }
        unint64_t v8 = result;
        uint64_t v2 = 0;
        if ((result & 0x8000000000000000) == 0)
        {
          int v7 = *(_DWORD *)(v23 + 36);
          if (result < 1 << *(unsigned char *)(v23 + 32)) {
            continue;
          }
        }
        goto LABEL_26;
      }
      __break(1u);
LABEL_22:
      __break(1u);
LABEL_23:
      __break(1u);
LABEL_24:
      __break(1u);
LABEL_25:
      __break(1u);
    }
  }
LABEL_26:
  __break(1u);
  return result;
}

uint64_t _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSDyS2SG_8CreateML11MLDataValueO_AItsAE_pTg5020_sSS3key_x5valuetSg8d4ML11fg5OAFs5c136_pIgnrrzo_SSAA_xABtAF_AFtsAG_pIegnrzr_lTRSS_TG503_s8c39ML15MLUntypedColumnVyAC11TabularData0D0l18SDySSxGGKclufcAA11ef34OAGSgKXEfU_AJ_AJti1_J22SgV8U_SS_TG5Tf3nnnpf_nTf1cn_n(uint64_t a1)
{
  uint64_t v2 = v1;
  int64_t v3 = *(void *)(a1 + 16);
  uint64_t v4 = MEMORY[0x263F8EE78];
  if (!v3) {
    return v4;
  }
  uint64_t v5 = a1;
  uint64_t v34 = MEMORY[0x263F8EE78];
  specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v3, 0);
  uint64_t v4 = v34;
  uint64_t result = specialized Dictionary.startIndex.getter(v5);
  if ((result & 0x8000000000000000) == 0)
  {
    unint64_t v8 = result;
    if (result < 1 << *(unsigned char *)(v5 + 32))
    {
      uint64_t v9 = v5 + 64;
      uint64_t v26 = v5 + 64;
      while ((*(void *)(v9 + 8 * (v8 >> 6)) & (1 << v8)) != 0)
      {
        if (v7 != *(_DWORD *)(v5 + 36)) {
          goto LABEL_20;
        }
        int v28 = v7;
        uint64_t v10 = v5;
        uint64_t v11 = (uint64_t *)(*(void *)(v5 + 48) + 16 * v8);
        uint64_t v12 = *v11;
        uint64_t v13 = v11[1];
        uint64_t v14 = (uint64_t *)(*(void *)(v5 + 56) + 16 * v8);
        uint64_t v15 = *v14;
        uint64_t v16 = v14[1];
        *(void *)&long long v30 = v12;
        *((void *)&v30 + 1) = v13;
        char v31 = 2;
        v29[3] = MEMORY[0x263F8D310];
        v29[0] = v15;
        v29[1] = v16;
        swift_bridgeObjectRetain_n();
        swift_bridgeObjectRetain_n();
        MLDataValue.init(fromAny:)((uint64_t)v29, (uint64_t)&v32);
        if (v2)
        {
          swift_bridgeObjectRelease_n();
          swift_bridgeObjectRelease_n();
          swift_release();
          swift_bridgeObjectRelease();
          return v4;
        }
        int64_t v27 = v3;
        swift_bridgeObjectRelease_n();
        swift_bridgeObjectRelease_n();
        uint64_t result = swift_bridgeObjectRelease();
        long long v17 = v30;
        char v18 = v31;
        long long v19 = v32;
        char v20 = v33;
        uint64_t v34 = v4;
        unint64_t v22 = *(void *)(v4 + 16);
        unint64_t v21 = *(void *)(v4 + 24);
        if (v22 >= v21 >> 1)
        {
          long long v24 = v32;
          long long v25 = v30;
          uint64_t result = (uint64_t)specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)((char *)(v21 > 1), v22 + 1, 1);
          long long v19 = v24;
          long long v17 = v25;
          uint64_t v4 = v34;
        }
        *(void *)(v4 + 16) = v22 + 1;
        uint64_t v23 = v4 + 48 * v22;
        *(_OWORD *)(v23 + 32) = v17;
        *(unsigned char *)(v23 + 48) = v18;
        *(_OWORD *)(v23 + 56) = v19;
        *(unsigned char *)(v23 + 72) = v20;
        if ((uint64_t)v8 >= -(-1 << *(unsigned char *)(v10 + 32))) {
          goto LABEL_21;
        }
        uint64_t v9 = v26;
        if ((*(void *)(v26 + 8 * (v8 >> 6)) & (1 << v8)) == 0) {
          goto LABEL_22;
        }
        uint64_t v5 = v10;
        if (v28 != *(_DWORD *)(v10 + 36)) {
          goto LABEL_23;
        }
        uint64_t result = _HashTable.occupiedBucket(after:)();
        int64_t v3 = v27 - 1;
        if (v27 == 1) {
          return v4;
        }
        unint64_t v8 = result;
        uint64_t v2 = 0;
        if ((result & 0x8000000000000000) == 0)
        {
          int v7 = *(_DWORD *)(v10 + 36);
          if (result < 1 << *(unsigned char *)(v10 + 32)) {
            continue;
          }
        }
        goto LABEL_24;
      }
      __break(1u);
LABEL_20:
      __break(1u);
LABEL_21:
      __break(1u);
LABEL_22:
      __break(1u);
LABEL_23:
      __break(1u);
    }
  }
LABEL_24:
  __break(1u);
  return result;
}

uint64_t _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSDySSSfG_8CreateML11MLDataValueO_AItsAE_pTg5020_sSS3key_x5valuetSg8d4ML11fg5OAFs5c136_pIgnrrzo_SSAA_xABtAF_AFtsAG_pIegnrzr_lTRSf_TG503_s8c39ML15MLUntypedColumnVyAC11TabularData0D0l18SDySSxGGKclufcAA11ef34OAGSgKXEfU_AJ_AJti1_J22SgV8U_Sf_TG5Tf3nnnpf_nTf1cn_n(uint64_t a1)
{
  uint64_t v2 = v1;
  int64_t v3 = *(void *)(a1 + 16);
  uint64_t v4 = MEMORY[0x263F8EE78];
  if (!v3) {
    return v4;
  }
  uint64_t v5 = a1;
  uint64_t v32 = MEMORY[0x263F8EE78];
  specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v3, 0);
  uint64_t v4 = v32;
  uint64_t result = specialized Dictionary.startIndex.getter(v5);
  if ((result & 0x8000000000000000) == 0)
  {
    unint64_t v8 = result;
    if (result < 1 << *(unsigned char *)(v5 + 32))
    {
      uint64_t v9 = v5 + 64;
      uint64_t v23 = v5 + 64;
      while ((*(void *)(v9 + 8 * (v8 >> 6)) & (1 << v8)) != 0)
      {
        if (v7 != *(_DWORD *)(v5 + 36)) {
          goto LABEL_20;
        }
        int v25 = v7;
        uint64_t v10 = v5;
        uint64_t v11 = (void *)(*(void *)(v5 + 48) + 16 * v8);
        int v12 = *(_DWORD *)(*(void *)(v5 + 56) + 4 * v8);
        uint64_t v13 = v11[1];
        *(void *)&long long v28 = *v11;
        *((void *)&v28 + 1) = v13;
        char v29 = 2;
        uint64_t v27 = MEMORY[0x263F8D5C8];
        v26[0] = v12;
        swift_bridgeObjectRetain_n();
        MLDataValue.init(fromAny:)((uint64_t)v26, (uint64_t)&v30);
        if (v2)
        {
          swift_release();
          swift_bridgeObjectRelease_n();
          return v4;
        }
        int64_t v24 = v3;
        uint64_t result = swift_bridgeObjectRelease_n();
        long long v14 = v28;
        char v15 = v29;
        long long v16 = v30;
        char v17 = v31;
        uint64_t v32 = v4;
        unint64_t v19 = *(void *)(v4 + 16);
        unint64_t v18 = *(void *)(v4 + 24);
        if (v19 >= v18 >> 1)
        {
          long long v21 = v30;
          long long v22 = v28;
          uint64_t result = (uint64_t)specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)((char *)(v18 > 1), v19 + 1, 1);
          long long v16 = v21;
          long long v14 = v22;
          uint64_t v4 = v32;
        }
        *(void *)(v4 + 16) = v19 + 1;
        uint64_t v20 = v4 + 48 * v19;
        *(_OWORD *)(v20 + 32) = v14;
        *(unsigned char *)(v20 + 48) = v15;
        *(_OWORD *)(v20 + 56) = v16;
        *(unsigned char *)(v20 + 72) = v17;
        if ((uint64_t)v8 >= -(-1 << *(unsigned char *)(v10 + 32))) {
          goto LABEL_21;
        }
        uint64_t v9 = v23;
        if ((*(void *)(v23 + 8 * (v8 >> 6)) & (1 << v8)) == 0) {
          goto LABEL_22;
        }
        uint64_t v5 = v10;
        if (v25 != *(_DWORD *)(v10 + 36)) {
          goto LABEL_23;
        }
        uint64_t result = _HashTable.occupiedBucket(after:)();
        int64_t v3 = v24 - 1;
        if (v24 == 1) {
          return v4;
        }
        unint64_t v8 = result;
        uint64_t v2 = 0;
        if ((result & 0x8000000000000000) == 0)
        {
          int v7 = *(_DWORD *)(v10 + 36);
          if (result < 1 << *(unsigned char *)(v10 + 32)) {
            continue;
          }
        }
        goto LABEL_24;
      }
      __break(1u);
LABEL_20:
      __break(1u);
LABEL_21:
      __break(1u);
LABEL_22:
      __break(1u);
LABEL_23:
      __break(1u);
    }
  }
LABEL_24:
  __break(1u);
  return result;
}

uint64_t _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSDySSSdG_8CreateML11MLDataValueO_AItsAE_pTg5020_sSS3key_x5valuetSg8d4ML11fg5OAFs5c136_pIgnrrzo_SSAA_xABtAF_AFtsAG_pIegnrzr_lTRSd_TG503_s8c39ML15MLUntypedColumnVyAC11TabularData0D0l18SDySSxGGKclufcAA11ef34OAGSgKXEfU_AJ_AJti1_J22SgV8U_Sd_TG5Tf3nnnpf_nTf1cn_n(uint64_t a1)
{
  uint64_t v2 = v1;
  int64_t v3 = *(void *)(a1 + 16);
  uint64_t v4 = MEMORY[0x263F8EE78];
  if (!v3) {
    return v4;
  }
  uint64_t v5 = a1;
  uint64_t v31 = MEMORY[0x263F8EE78];
  specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v3, 0);
  uint64_t v4 = v31;
  uint64_t result = specialized Dictionary.startIndex.getter(v5);
  if ((result & 0x8000000000000000) == 0)
  {
    unint64_t v8 = result;
    if (result < 1 << *(unsigned char *)(v5 + 32))
    {
      uint64_t v9 = v5 + 64;
      uint64_t v23 = v5 + 64;
      while ((*(void *)(v9 + 8 * (v8 >> 6)) & (1 << v8)) != 0)
      {
        if (v7 != *(_DWORD *)(v5 + 36)) {
          goto LABEL_20;
        }
        int v25 = v7;
        uint64_t v10 = v5;
        uint64_t v11 = (void *)(*(void *)(v5 + 48) + 16 * v8);
        uint64_t v12 = *(void *)(*(void *)(v5 + 56) + 8 * v8);
        uint64_t v13 = v11[1];
        *(void *)&long long v27 = *v11;
        *((void *)&v27 + 1) = v13;
        char v28 = 2;
        v26[3] = MEMORY[0x263F8D538];
        v26[0] = v12;
        swift_bridgeObjectRetain_n();
        MLDataValue.init(fromAny:)((uint64_t)v26, (uint64_t)&v29);
        if (v2)
        {
          swift_release();
          swift_bridgeObjectRelease_n();
          return v4;
        }
        int64_t v24 = v3;
        uint64_t result = swift_bridgeObjectRelease_n();
        long long v14 = v27;
        char v15 = v28;
        long long v16 = v29;
        char v17 = v30;
        uint64_t v31 = v4;
        unint64_t v19 = *(void *)(v4 + 16);
        unint64_t v18 = *(void *)(v4 + 24);
        if (v19 >= v18 >> 1)
        {
          long long v21 = v29;
          long long v22 = v27;
          uint64_t result = (uint64_t)specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)((char *)(v18 > 1), v19 + 1, 1);
          long long v16 = v21;
          long long v14 = v22;
          uint64_t v4 = v31;
        }
        *(void *)(v4 + 16) = v19 + 1;
        uint64_t v20 = v4 + 48 * v19;
        *(_OWORD *)(v20 + 32) = v14;
        *(unsigned char *)(v20 + 48) = v15;
        *(_OWORD *)(v20 + 56) = v16;
        *(unsigned char *)(v20 + 72) = v17;
        if ((uint64_t)v8 >= -(-1 << *(unsigned char *)(v10 + 32))) {
          goto LABEL_21;
        }
        uint64_t v9 = v23;
        if ((*(void *)(v23 + 8 * (v8 >> 6)) & (1 << v8)) == 0) {
          goto LABEL_22;
        }
        uint64_t v5 = v10;
        if (v25 != *(_DWORD *)(v10 + 36)) {
          goto LABEL_23;
        }
        uint64_t result = _HashTable.occupiedBucket(after:)();
        int64_t v3 = v24 - 1;
        if (v24 == 1) {
          return v4;
        }
        unint64_t v8 = result;
        uint64_t v2 = 0;
        if ((result & 0x8000000000000000) == 0)
        {
          int v7 = *(_DWORD *)(v10 + 36);
          if (result < 1 << *(unsigned char *)(v10 + 32)) {
            continue;
          }
        }
        goto LABEL_24;
      }
      __break(1u);
LABEL_20:
      __break(1u);
LABEL_21:
      __break(1u);
LABEL_22:
      __break(1u);
LABEL_23:
      __break(1u);
    }
  }
LABEL_24:
  __break(1u);
  return result;
}

uint64_t _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSDySSSiG_8CreateML11MLDataValueO_AItsAE_pTg5020_sSS3key_x5valuetSg8d4ML11fg5OAFs5c136_pIgnrrzo_SSAA_xABtAF_AFtsAG_pIegnrzr_lTRSi_TG503_s8c39ML15MLUntypedColumnVyAC11TabularData0D0l18SDySSxGGKclufcAA11ef34OAGSgKXEfU_AJ_AJti1_J22SgV8U_Si_TG5Tf3nnnpf_nTf1cn_n(uint64_t a1)
{
  uint64_t v2 = v1;
  int64_t v3 = *(void *)(a1 + 16);
  uint64_t v4 = MEMORY[0x263F8EE78];
  if (!v3) {
    return v4;
  }
  uint64_t v5 = a1;
  uint64_t v31 = MEMORY[0x263F8EE78];
  specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v3, 0);
  uint64_t v4 = v31;
  uint64_t result = specialized Dictionary.startIndex.getter(v5);
  if ((result & 0x8000000000000000) == 0)
  {
    unint64_t v8 = result;
    if (result < 1 << *(unsigned char *)(v5 + 32))
    {
      uint64_t v9 = v5 + 64;
      uint64_t v23 = v5 + 64;
      while ((*(void *)(v9 + 8 * (v8 >> 6)) & (1 << v8)) != 0)
      {
        if (v7 != *(_DWORD *)(v5 + 36)) {
          goto LABEL_20;
        }
        int v25 = v7;
        uint64_t v10 = v5;
        uint64_t v11 = (void *)(*(void *)(v5 + 48) + 16 * v8);
        uint64_t v12 = *(void *)(*(void *)(v5 + 56) + 8 * v8);
        uint64_t v13 = v11[1];
        *(void *)&long long v27 = *v11;
        *((void *)&v27 + 1) = v13;
        char v28 = 2;
        v26[3] = MEMORY[0x263F8D6C8];
        v26[0] = v12;
        swift_bridgeObjectRetain_n();
        MLDataValue.init(fromAny:)((uint64_t)v26, (uint64_t)&v29);
        if (v2)
        {
          swift_release();
          swift_bridgeObjectRelease_n();
          return v4;
        }
        int64_t v24 = v3;
        uint64_t result = swift_bridgeObjectRelease_n();
        long long v14 = v27;
        char v15 = v28;
        long long v16 = v29;
        char v17 = v30;
        uint64_t v31 = v4;
        unint64_t v19 = *(void *)(v4 + 16);
        unint64_t v18 = *(void *)(v4 + 24);
        if (v19 >= v18 >> 1)
        {
          long long v21 = v29;
          long long v22 = v27;
          uint64_t result = (uint64_t)specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)((char *)(v18 > 1), v19 + 1, 1);
          long long v16 = v21;
          long long v14 = v22;
          uint64_t v4 = v31;
        }
        *(void *)(v4 + 16) = v19 + 1;
        uint64_t v20 = v4 + 48 * v19;
        *(_OWORD *)(v20 + 32) = v14;
        *(unsigned char *)(v20 + 48) = v15;
        *(_OWORD *)(v20 + 56) = v16;
        *(unsigned char *)(v20 + 72) = v17;
        if ((uint64_t)v8 >= -(-1 << *(unsigned char *)(v10 + 32))) {
          goto LABEL_21;
        }
        uint64_t v9 = v23;
        if ((*(void *)(v23 + 8 * (v8 >> 6)) & (1 << v8)) == 0) {
          goto LABEL_22;
        }
        uint64_t v5 = v10;
        if (v25 != *(_DWORD *)(v10 + 36)) {
          goto LABEL_23;
        }
        uint64_t result = _HashTable.occupiedBucket(after:)();
        int64_t v3 = v24 - 1;
        if (v24 == 1) {
          return v4;
        }
        unint64_t v8 = result;
        uint64_t v2 = 0;
        if ((result & 0x8000000000000000) == 0)
        {
          int v7 = *(_DWORD *)(v10 + 36);
          if (result < 1 << *(unsigned char *)(v10 + 32)) {
            continue;
          }
        }
        goto LABEL_24;
      }
      __break(1u);
LABEL_20:
      __break(1u);
LABEL_21:
      __break(1u);
LABEL_22:
      __break(1u);
LABEL_23:
      __break(1u);
    }
  }
LABEL_24:
  __break(1u);
  return result;
}

void _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSnySiG_SiSgs5NeverOTg5059_s11TabularData0B5FrameV8CreateMLEyAcD11MLDataTableVcfcSiSgR5XEfU_0K2ML0O6ColumnVySiGTf1cn_n(uint64_t a1, uint64_t a2, void *a3, char a4)
{
  uint64_t v4 = a2 - a1;
  if (__OFSUB__(a2, a1))
  {
LABEL_19:
    __break(1u);
    goto LABEL_20;
  }
  if (!v4)
  {
    outlined consume of Result<_DataTable, Error>(a3, a4 & 1);
    return;
  }
  uint64_t v7 = a1;
  uint64_t v19 = MEMORY[0x263F8EE78];
  specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v4 & ~(v4 >> 63), 0);
  if (a2 >= v7 && (v4 & 0x8000000000000000) == 0)
  {
    uint64_t v8 = v19;
    char v9 = a4;
    while (a2 != v7)
    {
      if (v9)
      {
        uint64_t v10 = 0;
        char v11 = 1;
      }
      else
      {
        outlined copy of Result<_DataTable, Error>(a3, 0);
        _UntypedColumn.valueAtIndex(index:)(v7, (uint64_t)v16);
        outlined consume of Result<_DataTable, Error>(a3, 0);
        uint64_t v10 = *(void **)v16;
        if (v18)
        {
          outlined consume of MLDataValue(*(void **)v16, v17, v18);
          uint64_t v10 = 0;
          char v11 = 1;
        }
        else
        {
          char v11 = 0;
        }
        char v9 = a4;
      }
      uint64_t v19 = v8;
      unint64_t v13 = *(void *)(v8 + 16);
      unint64_t v12 = *(void *)(v8 + 24);
      if (v13 >= v12 >> 1)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v12 > 1, v13 + 1, 1);
        char v9 = a4;
        uint64_t v8 = v19;
      }
      *(void *)(v8 + 16) = v13 + 1;
      uint64_t v14 = v8 + 16 * v13;
      *(void *)(v14 + 32) = v10;
      *(unsigned char *)(v14 + 40) = v11;
      if (a2 == ++v7)
      {
        outlined consume of Result<_DataTable, Error>(a3, v9 & 1);
        return;
      }
    }
    __break(1u);
    goto LABEL_19;
  }
LABEL_20:
  __break(1u);
}

void _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSnySiG_SdSgs5NeverOTg567_s11TabularData0B5FrameV8CreateMLEyAcD11MLDataTableVcfcSdSgSiXEfU0_0K2ML0O6ColumnVySdGTf1cn_n(uint64_t a1, uint64_t a2, void *a3, char a4)
{
  uint64_t v4 = a2 - a1;
  if (__OFSUB__(a2, a1))
  {
LABEL_19:
    __break(1u);
    goto LABEL_20;
  }
  if (!v4)
  {
    outlined consume of Result<_DataTable, Error>(a3, a4 & 1);
    return;
  }
  uint64_t v7 = a1;
  uint64_t v19 = MEMORY[0x263F8EE78];
  specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v4 & ~(v4 >> 63), 0);
  if (a2 >= v7 && (v4 & 0x8000000000000000) == 0)
  {
    uint64_t v8 = v19;
    char v9 = a4;
    while (a2 != v7)
    {
      if (v9)
      {
        uint64_t v10 = 0;
        char v11 = 1;
      }
      else
      {
        outlined copy of Result<_DataTable, Error>(a3, 0);
        _UntypedColumn.valueAtIndex(index:)(v7, (uint64_t)v16);
        outlined consume of Result<_DataTable, Error>(a3, 0);
        uint64_t v10 = *(void **)v16;
        if (v18 == 1)
        {
          char v11 = 0;
        }
        else
        {
          outlined consume of MLDataValue(*(void **)v16, v17, v18);
          uint64_t v10 = 0;
          char v11 = 1;
        }
        char v9 = a4;
      }
      uint64_t v19 = v8;
      unint64_t v13 = *(void *)(v8 + 16);
      unint64_t v12 = *(void *)(v8 + 24);
      if (v13 >= v12 >> 1)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v12 > 1, v13 + 1, 1);
        char v9 = a4;
        uint64_t v8 = v19;
      }
      *(void *)(v8 + 16) = v13 + 1;
      uint64_t v14 = v8 + 16 * v13;
      *(void *)(v14 + 32) = v10;
      *(unsigned char *)(v14 + 40) = v11;
      if (a2 == ++v7)
      {
        outlined consume of Result<_DataTable, Error>(a3, v9 & 1);
        return;
      }
    }
    __break(1u);
    goto LABEL_19;
  }
LABEL_20:
  __break(1u);
}

void _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSnySiG_SSSgs5NeverOTg567_s11TabularData0B5FrameV8CreateMLEyAcD11MLDataTableVcfcSSSgSiXEfU1_0K2ML0O6ColumnVySSGTf1cn_n(uint64_t a1, uint64_t a2, void *a3, char a4)
{
  uint64_t v4 = a2 - a1;
  if (__OFSUB__(a2, a1))
  {
LABEL_18:
    __break(1u);
    goto LABEL_19;
  }
  if (!v4)
  {
    outlined consume of Result<_DataTable, Error>(a3, a4 & 1);
    return;
  }
  uint64_t v7 = a1;
  uint64_t v18 = MEMORY[0x263F8EE78];
  specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
  if (a2 >= v7 && (v4 & 0x8000000000000000) == 0)
  {
    uint64_t v8 = v18;
    char v9 = a4;
    while (a2 != v7)
    {
      if (v9)
      {
        uint64_t v10 = 0;
        id v11 = 0;
      }
      else
      {
        outlined copy of Result<_DataTable, Error>(a3, 0);
        _UntypedColumn.valueAtIndex(index:)(v7, (uint64_t)&v15);
        outlined consume of Result<_DataTable, Error>(a3, 0);
        uint64_t v10 = v15;
        id v11 = v16;
        if (v17 != 2)
        {
          outlined consume of MLDataValue(v15, v16, v17);
          uint64_t v10 = 0;
          id v11 = 0;
        }
        char v9 = a4;
      }
      uint64_t v18 = v8;
      unint64_t v12 = *(void *)(v8 + 16);
      if (v12 >= *(void *)(v8 + 24) >> 1)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
        char v9 = a4;
        uint64_t v8 = v18;
      }
      *(void *)(v8 + 16) = v12 + 1;
      uint64_t v13 = v8 + 16 * v12;
      *(void *)(v13 + 32) = v10;
      *(void *)(v13 + 40) = v11;
      if (a2 == ++v7)
      {
        outlined consume of Result<_DataTable, Error>(a3, v9 & 1);
        return;
      }
    }
    __break(1u);
    goto LABEL_18;
  }
LABEL_19:
  __break(1u);
}

uint64_t _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSnySiG_Say8CreateML11MLDataValueOGSgs5NeverOTg5025_s11TabularData0B5FrameV8d9MLEyAcD11f17TableVcfcSayAD0F5G12OGSgSiXEfU2_AG0F6ColumnVyAI12SequenceTypeVGTf1cn_n(uint64_t a1, uint64_t a2, void *a3, char a4)
{
  uint64_t v9 = a2 - a1;
  if (__OFSUB__(a2, a1))
  {
LABEL_66:
    __break(1u);
    goto LABEL_67;
  }
  unint64_t v6 = v4;
  uint64_t v10 = a3;
  if (!v9)
  {
    outlined consume of Result<_DataTable, Error>(a3, a4 & 1);
    return MEMORY[0x263F8EE78];
  }
  uint64_t v84 = MEMORY[0x263F8EE78];
  uint64_t v69 = a2 - a1;
  specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v9 & ~(v9 >> 63), 0);
  id v11 = (char *)v69;
  if (v69 < 0)
  {
LABEL_67:
    __break(1u);
    goto LABEL_68;
  }
  unint64_t v12 = 0;
  uint64_t v13 = v84;
  uint64_t v7 = (void *)MEMORY[0x263F8EE80];
  uint64_t v15 = a1;
  uint64_t v14 = a2;
  uint64_t v16 = a1;
  char v17 = a4;
  uint64_t v65 = v10;
  do
  {
    if (v12 == v11) {
      goto LABEL_59;
    }
    if (v17)
    {
      uint64_t countAndFlagsBits = 0;
    }
    else
    {
      uint64_t v75 = v12;
      uint64_t v76 = v13;
      outlined copy of Result<_DataTable, Error>(v10, 0);
      _UntypedColumn.valueAtIndex(index:)(v16, (uint64_t)&v82);
      outlined consume of Result<_DataTable, Error>(v10, 0);
      uint64_t countAndFlagsBits = (void *)v82._countAndFlagsBits;
      uint64_t object = (char *)v82._object;
      if (v83 == 3)
      {
        outlined copy of MLDataValue((id)v82._countAndFlagsBits, v82._object, 3);
        uint64_t v18 = CMLSequence.size.getter();
        if (CMLSequence.size.getter() < 0) {
          goto LABEL_64;
        }
        uint64_t v19 = CMLSequence.size.getter();
        if (v18 < 0 || v19 < v18)
        {
LABEL_65:
          __break(1u);
          goto LABEL_66;
        }
        if (v18)
        {
          __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<MLDataValue>);
          uint64_t v20 = (uint64_t *)swift_allocObject();
          size_t v21 = _swift_stdlib_malloc_size(v20);
          v20[2] = v18;
          v20[3] = 2 * ((uint64_t)(v21 - 32) / 24);
          uint64_t v70 = v20;
          outlined copy of MLDataValue(countAndFlagsBits, object, 3);
          if (CMLSequence.size.getter())
          {
            swift_retain();
            CMLSequence.value(at:)(0);
            uint64_t v71 = countAndFlagsBits;
            uint64_t v72 = object;
            if (!v6)
            {
              uint64_t v80 = 0;
              uint64_t v23 = v20 + 4;
              uint64_t v24 = 1;
              uint64_t v77 = v18;
              uint64_t v25 = v22;
              uint64_t v73 = v16;
              while (1)
              {
                outlined consume of MLDataValue(countAndFlagsBits, object, 3);
                uint64_t v78 = v24;
                switch(CMLFeatureValue.type.getter())
                {
                  case 1u:
                    specialized handling<A, B>(_:_:)();
                    uint64_t v52 = v51;
                    swift_release();
                    uint64_t v26 = 0;
                    uint64_t v79 = v52;
                    char v27 = 1;
                    goto LABEL_41;
                  case 2u:
                    swift_retain();
                    Swift::String v46 = CMLFeatureValue.stringValue()();
                    uint64_t v79 = v46._countAndFlagsBits;
                    unint64_t v6 = v47;
                    if (v47) {
                      goto LABEL_72;
                    }
                    uint64_t v26 = v46._object;
                    char v27 = 2;
                    swift_release_n();
                    goto LABEL_41;
                  case 3u:
                    uint64_t v48 = *(void *)(v25 + 16);
                    swift_retain();
                    uint64_t v49 = specialized handling<A, B>(_:_:)(v48);
                    if (!v49) {
                      goto LABEL_70;
                    }
                    type metadata accessor for CMLSequence();
                    uint64_t v50 = swift_allocObject();
                    *(void *)(v50 + 16) = v49;
                    uint64_t v79 = v50;
                    *(unsigned char *)(v50 + 24) = 1;
                    swift_release_n();
                    uint64_t v26 = 0;
                    char v27 = 3;
                    goto LABEL_41;
                  case 4u:
                    uint64_t v28 = *(void *)(v25 + 16);
                    swift_retain();
                    uint64_t v29 = specialized handling<A, B>(_:_:)(v28);
                    if (!v29) {
                      goto LABEL_69;
                    }
                    type metadata accessor for CMLDictionary();
                    *(void *)(swift_initStackObject() + 16) = v29;
                    uint64_t v81 = v7;
                    swift_retain_n();
                    if (CMLDictionary.size.getter())
                    {
                      uint64_t v30 = 0;
                      uint64_t v79 = (uint64_t)v7;
                      do
                      {
                        while (1)
                        {
                          CMLDictionary.keyAndValue(at:)(v30);
                          uint64_t object = v31;
                          swift_retain();
                          uint64_t v30 = specialized RandomAccessCollection<>.index(after:)(v30);
                          swift_release();
                          Swift::String v33 = CMLFeatureValue.stringValue()();
                          unint64_t v6 = v32;
                          if (v32) {
                            break;
                          }
                          uint64_t countAndFlagsBits = v33._object;
                          uint64_t v34 = swift_retain();
                          MLDataValue.init(_:)(v34, (uint64_t)&v82);
                          swift_release();
                          swift_release();
                          Swift::String v74 = v82;
                          LOBYTE(v7) = v83;
                          Swift::String v82 = v33;
                          char v83 = 2;
                          unint64_t v35 = specialized __RawDictionaryStorage.find<A>(_:)(v33._countAndFlagsBits, (unint64_t)v33._object, 2);
                          uint64_t v37 = *(void *)(v79 + 16);
                          BOOL v38 = (v36 & 1) == 0;
                          BOOL v39 = __OFADD__(v37, v38);
                          uint64_t v40 = v37 + v38;
                          if (v39) {
                            goto LABEL_62;
                          }
                          uint64_t object = v36;
                          if (*(void *)(v79 + 24) < v40)
                          {
                            specialized _NativeDictionary._copyOrMoveAndResize(capacity:moveElements:)();
                            unint64_t v35 = specialized __RawDictionaryStorage.find<A>(_:)(v33._countAndFlagsBits, (unint64_t)v33._object, 2);
                            if ((object & 1) != (v41 & 1)) {
                              goto LABEL_75;
                            }
                          }
                          if (object) {
                            goto LABEL_76;
                          }
                          v81[(v35 >> 6) + 8] |= 1 << v35;
                          uint64_t v42 = v81[6] + 24 * v35;
                          *(Swift::String *)uint64_t v42 = v33;
                          *(unsigned char *)(v42 + 16) = 2;
                          uint64_t v43 = v81[7] + 24 * v35;
                          *(Swift::String *)uint64_t v43 = v74;
                          *(unsigned char *)(v43 + 16) = (_BYTE)v7;
                          uint64_t v44 = v81[2];
                          BOOL v39 = __OFADD__(v44, 1);
                          uint64_t v45 = v44 + 1;
                          if (v39) {
                            goto LABEL_63;
                          }
                          uint64_t v79 = (uint64_t)v81;
                          v81[2] = v45;
                          if (v30 == CMLDictionary.size.getter()) {
                            goto LABEL_40;
                          }
                        }

                        swift_release();
                        swift_release();
                      }
                      while (v30 != CMLDictionary.size.getter());
                      unint64_t v6 = 0;
                    }
                    else
                    {
                      uint64_t v79 = (uint64_t)v7;
                    }
LABEL_40:
                    swift_release();
                    char v27 = 4;
                    swift_release_n();
                    swift_release();
                    uint64_t v26 = 0;
                    uint64_t v7 = (void *)MEMORY[0x263F8EE80];
                    uint64_t object = v72;
                    uint64_t v16 = v73;
                    uint64_t countAndFlagsBits = v71;
LABEL_41:
                    swift_retain();
                    uint64_t v54 = CMLSequence.size.getter();
                    outlined consume of MLDataValue(countAndFlagsBits, object, 3);
                    uint64_t v55 = v80;
                    if (v80 >= v54)
                    {
                      __break(1u);
LABEL_59:
                      __break(1u);
LABEL_60:
                      __break(1u);
LABEL_61:
                      __break(1u);
LABEL_62:
                      __break(1u);
LABEL_63:
                      __break(1u);
LABEL_64:
                      __break(1u);
                      goto LABEL_65;
                    }
                    *uint64_t v23 = v79;
                    v23[1] = (uint64_t)v26;
                    *((unsigned char *)v23 + 16) = v27;
                    if (v78 == v77)
                    {
                      outlined consume of MLDataValue(countAndFlagsBits, object, 3);
                      uint64_t v10 = v65;
                      goto LABEL_48;
                    }
                    ++v80;
                    uint64_t v56 = v55 + 1;
                    if (v55 + 1 == CMLSequence.size.getter()) {
                      goto LABEL_68;
                    }
                    v23 += 3;
                    uint64_t v24 = v78 + 1;
                    swift_retain();
                    CMLSequence.value(at:)(v56);
                    uint64_t v25 = v57;
                    break;
                  case 5u:
                    swift_release();
                    uint64_t v79 = 0;
                    uint64_t v26 = 0;
                    char v27 = 6;
                    goto LABEL_41;
                  case 6u:
                    uint64_t v53 = swift_retain();
                    MLDataValue.MultiArrayType.init(from:)(v53, &v82._countAndFlagsBits);
                    uint64_t v79 = v82._countAndFlagsBits;
                    if (!v82._countAndFlagsBits) {
                      goto LABEL_71;
                    }
                    swift_release();
                    uint64_t v26 = 0;
                    char v27 = 5;
                    goto LABEL_41;
                  default:
                    uint64_t v79 = specialized handling<A, B>(_:_:)(*(void *)(v25 + 16));
                    swift_release();
                    uint64_t v26 = 0;
                    char v27 = 0;
                    goto LABEL_41;
                }
              }
            }
            outlined consume of MLDataValue(countAndFlagsBits, object, 3);
            while (1)
            {
LABEL_74:
              swift_unexpectedError();
              __break(1u);
LABEL_75:
              KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)();
              __break(1u);
LABEL_76:
              uint64_t v61 = (void *)swift_allocError();
              swift_willThrow();
              id v62 = v61;
              __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
              if (swift_dynamicCast())
              {
                _StringGuts.grow(_:)(30);
                v63._uint64_t object = (void *)0x80000002272D7190;
                v63._uint64_t countAndFlagsBits = 0xD00000000000001BLL;
                String.append(_:)(v63);
                _print_unlocked<A, B>(_:_:)();
                v64._uint64_t countAndFlagsBits = 39;
                v64._uint64_t object = (void *)0xE100000000000000;
                String.append(_:)(v64);
                _assertionFailure(_:_:file:line:flags:)();
                __break(1u);
              }
              swift_release();
              outlined consume of MLDataValue((void *)v74._countAndFlagsBits, v74._object, (char)v7);
              outlined consume of MLDataValue((void *)v82._countAndFlagsBits, v82._object, v83);
              swift_release();
            }
          }
LABEL_68:
          outlined consume of MLDataValue(countAndFlagsBits, object, 3);
          __break(1u);
LABEL_69:
          __break(1u);
          swift_release();

          __break(1u);
LABEL_70:
          __break(1u);
LABEL_71:
          __break(1u);

          __break(1u);
          swift_release();

          __break(1u);
LABEL_72:
          swift_release();

          __break(1u);
          __break(1u);
          goto LABEL_74;
        }
        uint64_t v70 = (uint64_t *)MEMORY[0x263F8EE78];
LABEL_48:
        outlined consume of MLDataValue(countAndFlagsBits, object, 3);
        outlined consume of MLDataValue(countAndFlagsBits, object, 3);
        char v17 = a4;
        uint64_t v15 = a1;
        uint64_t v14 = a2;
        id v11 = (char *)v69;
        uint64_t countAndFlagsBits = v70;
      }
      else
      {
        outlined consume of MLDataValue((void *)v82._countAndFlagsBits, v82._object, v83);
        uint64_t countAndFlagsBits = 0;
        char v17 = a4;
        uint64_t v15 = a1;
        uint64_t v14 = a2;
        id v11 = (char *)v69;
      }
      unint64_t v12 = v75;
      uint64_t v13 = v76;
    }
    uint64_t v84 = v13;
    unint64_t v59 = *(void *)(v13 + 16);
    unint64_t v58 = *(void *)(v13 + 24);
    if (v59 >= v58 >> 1)
    {
      uint64_t object = v12;
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v58 > 1, v59 + 1, 1);
      unint64_t v12 = object;
      id v11 = (char *)v69;
      uint64_t v15 = a1;
      uint64_t v14 = a2;
      char v17 = a4;
      uint64_t v13 = v84;
    }
    *(void *)(v13 + 16) = v59 + 1;
    *(void *)(v13 + 8 * v59 + 32) = countAndFlagsBits;
    if (v14 < v15) {
      goto LABEL_60;
    }
    if (v16 >= v14) {
      goto LABEL_61;
    }
    ++v12;
    ++v16;
  }
  while (v12 != v11);
  outlined consume of Result<_DataTable, Error>(v10, v17 & 1);
  return v13;
}

void _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSnySiG_Say8CreateML11MLDataValueO3key_AI5valuetGSgs5NeverOTg5025_s11TabularData0B5FrameV8d9MLEyAcD11f17TableVcfcSayAD0F5G26O3key_AH5valuetGSgSiXEfU3_AG0F6ColumnVyAI14DictionaryTypeVGTf1cn_n(uint64_t a1, uint64_t a2, void *a3, char a4)
{
  uint64_t v4 = a2 - a1;
  if (__OFSUB__(a2, a1)) {
    goto LABEL_23;
  }
  char v5 = a4;
  unint64_t v6 = a3;
  if (!v4)
  {
    outlined consume of Result<_DataTable, Error>(a3, a4 & 1);
    return;
  }
  uint64_t v7 = a2;
  uint64_t v8 = a1;
  uint64_t v29 = MEMORY[0x263F8EE78];
  specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v4 & ~(v4 >> 63), 0);
  if (v7 < v8 || v4 < 0) {
    goto LABEL_24;
  }
  uint64_t v9 = v29;
  uint64_t v22 = v6;
  char v21 = v5;
  uint64_t v23 = v7;
  while (v7 != v8)
  {
    if (v5) {
      goto LABEL_13;
    }
    outlined copy of Result<_DataTable, Error>(v6, 0);
    _UntypedColumn.valueAtIndex(index:)(v8, (uint64_t)&v25);
    outlined consume of Result<_DataTable, Error>(v6, 0);
    uint64_t v10 = v25;
    id v11 = v26;
    if (v27 != 4)
    {
      outlined consume of MLDataValue(v25, v26, v27);
LABEL_13:
      uint64_t v13 = 0;
      goto LABEL_16;
    }
    uint64_t v12 = v25[2];
    if (v12)
    {
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(key: MLDataValue, value: MLDataValue)>);
      uint64_t v13 = (void *)swift_allocObject();
      size_t v14 = _swift_stdlib_malloc_size(v13);
      v13[2] = v12;
      v13[3] = 2 * ((uint64_t)(v14 - 32) / 48);
      outlined copy of MLDataValue(v10, v11, 4);
      swift_bridgeObjectRetain();
      specialized Sequence._copySequenceContents(initializing:)((uint64_t)&v25, (uint64_t)(v13 + 4), v12, (uint64_t)v10);
      uint64_t v24 = v15;
      uint64_t v16 = (uint64_t)v26;
      uint64_t v17 = v27;
      char v18 = v28;
      swift_bridgeObjectRelease();
      outlined consume of [MLDataValue : MLDataValue].Index._Variant(v16, v17, v18);
      if (v24 != v12) {
        goto LABEL_22;
      }
      outlined consume of MLDataValue(v10, v11, 4);
      outlined consume of MLDataValue(v10, v11, 4);
      unint64_t v6 = v22;
      char v5 = v21;
    }
    else
    {
      outlined consume of MLDataValue(v25, v26, 4);
      uint64_t v13 = (void *)MEMORY[0x263F8EE78];
    }
    uint64_t v7 = v23;
LABEL_16:
    uint64_t v29 = v9;
    unint64_t v20 = *(void *)(v9 + 16);
    unint64_t v19 = *(void *)(v9 + 24);
    if (v20 >= v19 >> 1)
    {
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v19 > 1, v20 + 1, 1);
      uint64_t v9 = v29;
    }
    *(void *)(v9 + 16) = v20 + 1;
    *(void *)(v9 + 8 * v20 + 32) = v13;
    if (v7 == ++v8)
    {
      outlined consume of Result<_DataTable, Error>(v6, v5 & 1);
      return;
    }
  }
  __break(1u);
LABEL_22:
  __break(1u);
LABEL_23:
  __break(1u);
LABEL_24:
  __break(1u);
}

uint64_t _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSnySiG_So12MLMultiArrayCSgs5NeverOTg5059_s11TabularData0B5FrameV8CreateMLEyAcD11MLDataTableVcfcSo12dE11CSgSiXEfU4_0M2ML0Q6ColumnVyAM0Q5ValueO05MultiE4TypeVGTf1cn_n(uint64_t result, uint64_t a2, void *a3, char a4)
{
  uint64_t v4 = a2 - result;
  if (__OFSUB__(a2, result)) {
    goto LABEL_14;
  }
  if (v4)
  {
    uint64_t v8 = result;
    uint64_t v13 = MEMORY[0x263F8EE78];
    uint64_t result = specialized ContiguousArray.reserveCapacity(_:)();
    if (a2 < v8 || v4 < 0) {
      goto LABEL_15;
    }
    while (a2 != v8)
    {
      if ((a4 & 1) == 0)
      {
        outlined copy of Result<_DataTable, Error>(a3, 0);
        _UntypedColumn.valueAtIndex(index:)(v8, (uint64_t)v10);
        outlined consume of Result<_DataTable, Error>(a3, 0);
        if (v12 != 5) {
          outlined consume of MLDataValue(*(void **)v10, v11, v12);
        }
      }
      specialized ContiguousArray._makeUniqueAndReserveCapacityIfNotUnique()();
      specialized ContiguousArray._reserveCapacityAssumingUniqueBuffer(oldCount:)();
      specialized ContiguousArray._appendElementAssumeUniqueAndCapacity(_:newElement:)();
      uint64_t result = specialized ContiguousArray._endMutation()();
      if (a2 == ++v8)
      {
        uint64_t v9 = v13;
        outlined consume of Result<_DataTable, Error>(a3, a4 & 1);
        return v9;
      }
    }
    __break(1u);
LABEL_14:
    __break(1u);
LABEL_15:
    __break(1u);
    return result;
  }
  outlined consume of Result<_DataTable, Error>(a3, a4 & 1);
  return MEMORY[0x263F8EE78];
}

void MLDataTable.init(_:convertArraysToShapedArrays:)(char a1@<W1>, uint64_t a2@<X8>)
{
  uint64_t v4 = type metadata accessor for AnyColumn();
  OUTLINED_FUNCTION_0();
  uint64_t v6 = v5;
  MEMORY[0x270FA5388](v7);
  OUTLINED_FUNCTION_49();
  uint64_t v52 = v8;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v9);
  OUTLINED_FUNCTION_106();
  uint64_t v53 = v10;
  uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyColumn?);
  uint64_t v12 = OUTLINED_FUNCTION_17(v11);
  MEMORY[0x270FA5388](v12);
  OUTLINED_FUNCTION_32();
  uint64_t v13 = MEMORY[0x22A6764B0](0);
  if (v13)
  {
    uint64_t v14 = v13;
    type metadata accessor for CMLTable();
    uint64_t v15 = swift_allocObject();
    *(void *)(v15 + 16) = v14;
    type metadata accessor for _DataTable();
    OUTLINED_FUNCTION_55_7();
    uint64_t v60 = _DataTable.init(impl:)(v15);
    char v61 = 0;
    uint64_t v16 = DataFrame.columns.getter();
    uint64_t v17 = *(void *)(v16 + 16);
    if (v17)
    {
      unint64_t v20 = *(void (**)(uint64_t, unint64_t, uint64_t))(v6 + 16);
      uint64_t v18 = v6 + 16;
      unint64_t v19 = v20;
      unint64_t v21 = v16 + ((*(unsigned __int8 *)(v18 + 64) + 32) & ~(unint64_t)*(unsigned __int8 *)(v18 + 64));
      uint64_t v51 = (void (**)(uint64_t, uint64_t, uint64_t))(v18 + 16);
      uint64_t v50 = *(void *)(v18 + 56);
      uint64_t v48 = v2;
      uint64_t v22 = v53;
      uint64_t v49 = v20;
      do
      {
        v19(v2, v21, v4);
        __swift_storeEnumTagSinglePayload(v2, 0, 1, v4);
        if (__swift_getEnumTagSinglePayload(v2, 1, v4) == 1) {
          goto LABEL_23;
        }
        (*v51)(v22, v2, v4);
        v19(v52, v22, v4);
        uint64_t v23 = v62;
        MLUntypedColumn.init(_:convertArraysToShapedArrays:)(v52, a1 & 1, (uint64_t)&v58);
        id v62 = v23;
        if (v23)
        {
          type metadata accessor for DataFrame();
          OUTLINED_FUNCTION_6_19();
          OUTLINED_FUNCTION_25_0();
          v45();
          OUTLINED_FUNCTION_25_0();
          v46();
          swift_bridgeObjectRelease();
          outlined consume of Result<_DataTable, Error>(v60, v61);
          return;
        }
        uint64_t v54 = v17;
        uint64_t v24 = v58;
        char v25 = v59;
        uint64_t v26 = AnyColumn.name.getter();
        uint64_t v57 = v27;
        MLDataTable.willMutate()();
        id v28 = v60;
        uint64_t v56 = v24;
        char v55 = v25;
        if (v61)
        {
          unint64_t v58 = v60;
          outlined copy of Result<_DataTable, Error>(v60, 1);
          id v29 = v28;
          __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
          uint64_t v30 = _getErrorEmbeddedNSError<A>(_:)();
          if (v30)
          {
            uint64_t v31 = (void *)v30;
            outlined consume of Result<_DataTable, Error>(v28, 1);
          }
          else
          {
            uint64_t v31 = (void *)OUTLINED_FUNCTION_85();
            *uint64_t v40 = v58;
          }
          unint64_t v19 = v49;
          uint64_t v39 = v54;
          outlined consume of Result<_DataTable, Error>(v28, 1);
          uint64_t v2 = v48;
          uint64_t v22 = v53;
        }
        else
        {
          if (v25)
          {
            unint64_t v58 = 0;
            unint64_t v59 = 0xE000000000000000;
            swift_retain();
            _StringGuts.grow(_:)(36);
            swift_bridgeObjectRelease();
            unint64_t v58 = (void *)0xD000000000000021;
            unint64_t v59 = 0x80000002272D71D0;
            v32._uint64_t countAndFlagsBits = v26;
            v32._uint64_t object = v57;
            String.append(_:)(v32);
            v33._uint64_t countAndFlagsBits = 39;
            v33._uint64_t object = (void *)0xE100000000000000;
            String.append(_:)(v33);
            uint64_t v34 = v58;
            unint64_t v35 = v59;
            lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
            uint64_t v31 = (void *)OUTLINED_FUNCTION_85();
            *int64_t v36 = v34;
            v36[1] = v35;
            OUTLINED_FUNCTION_2_3((uint64_t)v31, (uint64_t)v36);
            outlined consume of Result<_DataTable, Error>(v28, 0);
            id v62 = 0;
            unint64_t v19 = v49;
            uint64_t v22 = v53;
          }
          else
          {
            uint64_t v37 = v24[2];
            outlined copy of Result<_DataTable, Error>(v60, 0);
            outlined copy of Result<_DataTable, Error>(v24, 0);
            swift_retain();
            BOOL v38 = v62;
            CMLTable.addColumn(name:_:)(v26, (uint64_t)v57, v37);
            uint64_t v31 = v38;
            if (!v38)
            {
              id v62 = 0;
              outlined consume of Result<_DataTable, Error>(v24, 0);
              swift_release();
              outlined consume of Result<_DataTable, Error>(v28, 0);
              unint64_t v19 = v49;
              uint64_t v39 = v54;
              if ((v61 & 1) == 0)
              {
                id v42 = v60;
                outlined copy of Result<_DataTable, Error>(v60, 0);
                _DataTable.columnNamesDidChange()();
                outlined consume of Result<_DataTable, Error>(v42, 0);
              }
              uint64_t v22 = v53;
              uint64_t v2 = v48;
              goto LABEL_17;
            }
            swift_release();
            outlined consume of Result<_DataTable, Error>(v24, 0);
            outlined consume of Result<_DataTable, Error>(v28, 0);
            id v62 = 0;
            uint64_t v22 = v53;
            uint64_t v2 = v48;
            unint64_t v19 = v49;
          }
          uint64_t v39 = v54;
        }
        outlined consume of Result<_DataTable, Error>(v60, v61);
        uint64_t v60 = v31;
        char v61 = 1;
LABEL_17:
        swift_bridgeObjectRelease();
        OUTLINED_FUNCTION_25_0();
        v41();
        outlined consume of Result<_DataTable, Error>(v56, v55);
        v21 += v50;
        uint64_t v17 = v39 - 1;
      }
      while (v17);
    }
    __swift_storeEnumTagSinglePayload(v2, 1, 1, v4);
LABEL_23:
    type metadata accessor for DataFrame();
    OUTLINED_FUNCTION_6_19();
    OUTLINED_FUNCTION_25_0();
    v43();
    swift_bridgeObjectRelease();
    char v44 = v61;
    *(void *)a2 = v60;
    *(unsigned char *)(a2 + 8) = v44;
  }
  else
  {
    __break(1u);
  }
}

uint64_t DataFrame.randomSplit(strategy:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v36 = a1;
  uint64_t v37 = a2;
  uint64_t v34 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame.Slice, DataFrame.Slice));
  OUTLINED_FUNCTION_17_12();
  MEMORY[0x270FA5388](v4);
  OUTLINED_FUNCTION_49();
  uint64_t v35 = v5;
  OUTLINED_FUNCTION_20_3();
  uint64_t v7 = MEMORY[0x270FA5388](v6);
  uint64_t v9 = (char *)&v34 - v8;
  MEMORY[0x270FA5388](v7);
  uint64_t v11 = (char *)&v34 - v10;
  uint64_t v12 = type metadata accessor for DataFrame.Rows();
  OUTLINED_FUNCTION_0();
  uint64_t v14 = v13;
  MEMORY[0x270FA5388](v15);
  OUTLINED_FUNCTION_3_0();
  uint64_t v18 = v17 - v16;
  double v19 = *(double *)a3;
  int v20 = *(unsigned __int8 *)(a3 + 17);
  DataFrame.rows.getter();
  uint64_t v21 = DataFrame.Rows.count.getter();
  (*(void (**)(uint64_t, uint64_t))(v14 + 8))(v18, v12);
  if (v20 == 1)
  {
    if (v21 >= 50) {
      goto LABEL_6;
    }
LABEL_5:
    uint64_t v22 = type metadata accessor for DataFrame.Slice();
    __swift_storeEnumTagSinglePayload(v36, 1, 1, v22);
    return specialized DataFrameProtocol.subscript.getter(0, v37);
  }
  if (v19 == 0.0) {
    goto LABEL_5;
  }
LABEL_6:
  uint64_t v24 = v34;
  char v25 = &v11[*(int *)(v34 + 48)];
  type metadata accessor for DataFrame();
  DataFrameProtocol.randomSplit(by:seed:)();
  uint64_t v26 = &v9[*(int *)(v24 + 48)];
  uint64_t v27 = type metadata accessor for DataFrame.Slice();
  id v28 = *(void **)(v27 - 8);
  id v29 = (void (*)(char *, char *, uint64_t))v28[2];
  v29(v9, v11, v27);
  v29(v26, v25, v27);
  uint64_t v30 = (void (*)(void))v28[4];
  uint64_t v31 = v36;
  OUTLINED_FUNCTION_38_7();
  v30();
  __swift_storeEnumTagSinglePayload(v31, 0, 1, v27);
  uint64_t v32 = v35;
  OUTLINED_FUNCTION_63_3();
  OUTLINED_FUNCTION_38_7();
  v30();
  OUTLINED_FUNCTION_38_7();
  v30();
  OUTLINED_FUNCTION_38_7();
  v30();
  Swift::String v33 = (void (*)(uint64_t, uint64_t))v28[1];
  v33(v32, v27);
  return ((uint64_t (*)(char *, uint64_t))v33)(v26, v27);
}

uint64_t DataFrame.init(_:)@<X0>(uint64_t a1@<X0>, uint64_t a2@<X8>)
{
  uint64_t v132 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<MLMultiArray>);
  OUTLINED_FUNCTION_0();
  uint64_t v5 = v4;
  MEMORY[0x270FA5388](v6);
  OUTLINED_FUNCTION_33_0();
  uint64_t v131 = v7;
  uint64_t v130 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[(MLDataValue, MLDataValue)]>);
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v8);
  OUTLINED_FUNCTION_33_0();
  uint64_t v129 = v9;
  uint64_t v128 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[MLDataValue]>);
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v10);
  OUTLINED_FUNCTION_33_0();
  uint64_t v127 = v11;
  uint64_t v126 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v12);
  OUTLINED_FUNCTION_33_0();
  uint64_t v125 = v13;
  uint64_t v124 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Double>);
  OUTLINED_FUNCTION_0();
  uint64_t v15 = v14;
  MEMORY[0x270FA5388](v16);
  OUTLINED_FUNCTION_33_0();
  uint64_t v123 = v17;
  uint64_t v122 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Int>);
  OUTLINED_FUNCTION_0();
  uint64_t v19 = v18;
  MEMORY[0x270FA5388](v20);
  OUTLINED_FUNCTION_33_0();
  uint64_t v121 = v21;
  uint64_t v22 = *(void **)a1;
  uint64_t v23 = *(unsigned __int8 *)(a1 + 8);
  uint64_t v134 = a2;
  DataFrame.init()();
  uint64_t v133 = v15;
  uint64_t v119 = v19;
  if (v23)
  {
    uint64_t v24 = 1;
    outlined copy of Result<_DataTable, Error>(v22, 1);
    uint64_t v25 = MEMORY[0x22A676370](0);
    if (!v25) {
      goto LABEL_70;
    }
    uint64_t v26 = v25;
    uint64_t v27 = v5;
    outlined consume of Result<_DataTable, Error>(v22, 1);
    type metadata accessor for CMLSequence();
    uint64_t v28 = swift_allocObject();
    *(void *)(v28 + 16) = v26;
    *(unsigned char *)(v28 + 24) = 1;
  }
  else
  {
    uint64_t v27 = v5;
    outlined copy of Result<_DataTable, Error>(v22, 0);
    _DataTable.columnNames.getter(&ML11MLDataValueOGSgs5NeverOTg5025_s11TabularData0B5FrameV8d9MLEyAcD11f17TableVcfcSayAD0F5G12OGSgSiXEfU2_AG0F6ColumnVyAI12SequenceTypeVGTf1cn_n);
    outlined consume of Result<_DataTable, Error>(v22, 0);
  }
  uint64_t ML11MLDataValueOGSgs5NeverOTg5025_s11TabularData0B5FrameV8d9MLEyAcD11f17TableVcfcSayAD0F5G12OGSgSiXEfU2_AG0F6ColumnVyAI12SequenceTypeVGTf1cn_n = (uint64_t)v22;
  LOBYTE(v138) = v23;
  MLDataTable.columnTypes.getter();
  uint64_t v30 = v29;
  swift_retain_n();
  uint64_t v31 = CMLSequence.size.getter();
  uint64_t v32 = specialized RandomAccessCollection<>.distance(from:to:)(0, v31);
  swift_release();
  if (!v32)
  {
    swift_release();
    uint64_t v94 = v22;
    char v95 = v23;
    goto LABEL_43;
  }
  int v135 = v23;
  uint64_t v23 = 0;
  uint64_t v118 = (void (**)(uint64_t, uint64_t))(v119 + 8);
  uint64_t v120 = v22;
  uint64_t v133 = v30;
  while (2)
  {
    CMLSequence.value(at:)(v23);
    CMLFeatureValue.stringValue()();
    if (v24) {
      goto LABEL_71;
    }
    swift_release();
    swift_retain();
    uint64_t v33 = CMLSequence.size.getter();
    uint64_t v34 = specialized RandomAccessCollection<>.distance(from:to:)(0, v33);
    swift_release();
    if (v23 >= v34)
    {
      __break(1u);
LABEL_45:
      __break(1u);
LABEL_46:
      __break(1u);
LABEL_47:
      __break(1u);
LABEL_48:
      __break(1u);
LABEL_49:
      __break(1u);
LABEL_50:
      __break(1u);
LABEL_51:
      OUTLINED_FUNCTION_11_13();
      OUTLINED_FUNCTION_21_12();
      swift_bridgeObjectRelease();
      OUTLINED_FUNCTION_39_7();
      OUTLINED_FUNCTION_16_13(v97);
      OUTLINED_FUNCTION_47_6();
      lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
      uint64_t v98 = OUTLINED_FUNCTION_85();
      OUTLINED_FUNCTION_4_25(v98, v99);
LABEL_53:
      OUTLINED_FUNCTION_13_15();
      __break(1u);
LABEL_54:
      OUTLINED_FUNCTION_11_13();
      goto LABEL_61;
    }
    if (!v30[2])
    {
LABEL_16:
      swift_bridgeObjectRelease();
      goto LABEL_40;
    }
    swift_bridgeObjectRetain();
    uint64_t v35 = OUTLINED_FUNCTION_57_7();
    unint64_t v37 = specialized __RawDictionaryStorage.find<A>(_:)(v35, v36);
    if ((v38 & 1) == 0)
    {
      swift_bridgeObjectRelease_n();
      goto LABEL_40;
    }
    uint64_t v39 = *(unsigned __int8 *)(v30[7] + v37);
    swift_bridgeObjectRelease();
    switch(v39)
    {
      case 1:
        if (v135)
        {
          OUTLINED_FUNCTION_11_13();
          OUTLINED_FUNCTION_21_12();
          swift_bridgeObjectRelease();
          OUTLINED_FUNCTION_39_7();
          OUTLINED_FUNCTION_16_13(v100);
          OUTLINED_FUNCTION_47_6();
          lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
          uint64_t v101 = OUTLINED_FUNCTION_85();
          OUTLINED_FUNCTION_4_25(v101, v102);
LABEL_57:
          OUTLINED_FUNCTION_13_15();
          __break(1u);
LABEL_58:
          OUTLINED_FUNCTION_11_13();
          OUTLINED_FUNCTION_21_12();
          swift_bridgeObjectRelease();
          OUTLINED_FUNCTION_39_7();
          OUTLINED_FUNCTION_16_13(v103);
          OUTLINED_FUNCTION_47_6();
          uint64_t v24 = v138;
          lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
          uint64_t v104 = OUTLINED_FUNCTION_85();
          OUTLINED_FUNCTION_4_25(v104, v105);
LABEL_60:
          OUTLINED_FUNCTION_13_15();
          __break(1u);

          swift_release();
LABEL_61:
          OUTLINED_FUNCTION_21_12();
          swift_bridgeObjectRelease();
          OUTLINED_FUNCTION_39_7();
          OUTLINED_FUNCTION_16_13(v106);
          OUTLINED_FUNCTION_47_6();
          lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
          uint64_t v107 = OUTLINED_FUNCTION_85();
          OUTLINED_FUNCTION_4_25(v107, v108);
          goto LABEL_63;
        }
        OUTLINED_FUNCTION_8_17();
        OUTLINED_FUNCTION_27_8((void *(*)(uint64_t *__return_ptr, void *))partial apply for closure #1 in CMLTable.column(name:));
        OUTLINED_FUNCTION_44_4();
        type metadata accessor for _UntypedColumn();
        unint64_t v59 = (void *)OUTLINED_FUNCTION_70();
        OUTLINED_FUNCTION_3_30(v59);
        OUTLINED_FUNCTION_24_10();
        if (v60 != 1)
        {
          OUTLINED_FUNCTION_46_6();
          goto LABEL_57;
        }
        uint64_t v61 = OUTLINED_FUNCTION_12_11();
        OUTLINED_FUNCTION_26_8();
        if (v61 < 0) {
          goto LABEL_47;
        }
        OUTLINED_FUNCTION_42_6();
        uint64_t v62 = OUTLINED_FUNCTION_19_12();
        _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSnySiG_SdSgs5NeverOTg567_s11TabularData0B5FrameV8CreateMLEyAcD11MLDataTableVcfcSdSgSiXEfU0_0K2ML0O6ColumnVySdGTf1cn_n(v62, v63, v64, v65);
        uint64_t ML11MLDataValueOGSgs5NeverOTg5025_s11TabularData0B5FrameV8d9MLEyAcD11f17TableVcfcSayAD0F5G12OGSgSiXEfU2_AG0F6ColumnVyAI12SequenceTypeVGTf1cn_n = v66;
        __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Double?]);
        lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [Double?] and conformance [A], &demangling cache variable for type metadata for [Double?]);
        uint64_t v22 = v123;
        OUTLINED_FUNCTION_57_7();
        Column.init<A>(name:contents:)();
        DataFrame.append<A>(column:)();
        OUTLINED_FUNCTION_26_8();
        uint64_t v49 = OUTLINED_FUNCTION_74_1();
        uint64_t v50 = &v140;
LABEL_26:
        uint64_t v58 = *(v50 - 32);
LABEL_39:
        v48(v49, v58);
LABEL_40:
        ++v23;
        swift_retain();
        uint64_t v92 = CMLSequence.size.getter();
        uint64_t v93 = specialized RandomAccessCollection<>.distance(from:to:)(0, v92);
        swift_release();
        if (v23 != v93) {
          continue;
        }
        swift_release();
        uint64_t v94 = v22;
        char v95 = v135;
LABEL_43:
        outlined consume of Result<_DataTable, Error>(v94, v95);
        swift_release();
        return swift_bridgeObjectRelease();
      case 2:
        if (v135) {
          goto LABEL_58;
        }
        OUTLINED_FUNCTION_8_17();
        OUTLINED_FUNCTION_27_8((void *(*)(uint64_t *__return_ptr, void *))partial apply for closure #1 in CMLTable.column(name:));
        OUTLINED_FUNCTION_44_4();
        type metadata accessor for _UntypedColumn();
        uint64_t v67 = (void *)OUTLINED_FUNCTION_70();
        OUTLINED_FUNCTION_3_30(v67);
        OUTLINED_FUNCTION_24_10();
        if (v68 != 2)
        {
          OUTLINED_FUNCTION_46_6();
          goto LABEL_60;
        }
        uint64_t v69 = OUTLINED_FUNCTION_12_11();
        OUTLINED_FUNCTION_26_8();
        if (v69 < 0) {
          goto LABEL_48;
        }
        OUTLINED_FUNCTION_42_6();
        uint64_t v70 = OUTLINED_FUNCTION_19_12();
        _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSnySiG_SSSgs5NeverOTg567_s11TabularData0B5FrameV8CreateMLEyAcD11MLDataTableVcfcSSSgSiXEfU1_0K2ML0O6ColumnVySSGTf1cn_n(v70, v71, v72, v73);
        uint64_t ML11MLDataValueOGSgs5NeverOTg5025_s11TabularData0B5FrameV8d9MLEyAcD11f17TableVcfcSayAD0F5G12OGSgSiXEfU2_AG0F6ColumnVyAI12SequenceTypeVGTf1cn_n = v74;
        __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String?]);
        lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [String?] and conformance [A], &demangling cache variable for type metadata for [String?]);
        uint64_t v22 = v125;
        OUTLINED_FUNCTION_57_7();
        Column.init<A>(name:contents:)();
        DataFrame.append<A>(column:)();
        OUTLINED_FUNCTION_26_8();
        uint64_t v49 = OUTLINED_FUNCTION_74_1();
        uint64_t v58 = v126;
        goto LABEL_39;
      case 3:
        if (v135) {
          goto LABEL_54;
        }
        OUTLINED_FUNCTION_8_17();
        OUTLINED_FUNCTION_27_8((void *(*)(uint64_t *__return_ptr, void *))partial apply for closure #1 in CMLTable.column(name:));
        OUTLINED_FUNCTION_44_4();
        type metadata accessor for _UntypedColumn();
        uint64_t v51 = (void *)OUTLINED_FUNCTION_70();
        OUTLINED_FUNCTION_3_30(v51);
        OUTLINED_FUNCTION_24_10();
        if (v52 != 3)
        {
          OUTLINED_FUNCTION_46_6();
LABEL_63:
          OUTLINED_FUNCTION_13_15();
          __break(1u);
LABEL_64:
          OUTLINED_FUNCTION_11_13();
          OUTLINED_FUNCTION_21_12();
          swift_bridgeObjectRelease();
          OUTLINED_FUNCTION_39_7();
          OUTLINED_FUNCTION_16_13(v109);
          OUTLINED_FUNCTION_47_6();
          lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
          uint64_t v110 = OUTLINED_FUNCTION_85();
          OUTLINED_FUNCTION_4_25(v110, v111);
          goto LABEL_66;
        }
        uint64_t v53 = OUTLINED_FUNCTION_12_11();
        OUTLINED_FUNCTION_26_8();
        if (v53 < 0) {
          goto LABEL_46;
        }
        OUTLINED_FUNCTION_42_6();
        uint64_t v54 = OUTLINED_FUNCTION_19_12();
        uint64_t ML11MLDataValueOGSgs5NeverOTg5025_s11TabularData0B5FrameV8d9MLEyAcD11f17TableVcfcSayAD0F5G12OGSgSiXEfU2_AG0F6ColumnVyAI12SequenceTypeVGTf1cn_n = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSnySiG_Say8CreateML11MLDataValueOGSgs5NeverOTg5025_s11TabularData0B5FrameV8d9MLEyAcD11f17TableVcfcSayAD0F5G12OGSgSiXEfU2_AG0F6ColumnVyAI12SequenceTypeVGTf1cn_n(v54, v55, v56, v57);
        __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [MLDataValue]);
        __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [[MLDataValue]?]);
        lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [[MLDataValue]?] and conformance [A], &demangling cache variable for type metadata for [[MLDataValue]?]);
        uint64_t v30 = v22;
        uint64_t v22 = v127;
        OUTLINED_FUNCTION_31_6();
        OUTLINED_FUNCTION_48_5();
        OUTLINED_FUNCTION_26_8();
        uint64_t v49 = OUTLINED_FUNCTION_53_8();
        uint64_t v58 = v128;
        goto LABEL_39;
      case 4:
        if (v135) {
          goto LABEL_64;
        }
        OUTLINED_FUNCTION_8_17();
        OUTLINED_FUNCTION_27_8((void *(*)(uint64_t *__return_ptr, void *))partial apply for closure #1 in CMLTable.column(name:));
        OUTLINED_FUNCTION_44_4();
        type metadata accessor for _UntypedColumn();
        uint64_t v75 = (void *)OUTLINED_FUNCTION_70();
        OUTLINED_FUNCTION_3_30(v75);
        OUTLINED_FUNCTION_24_10();
        if (v76 != 4)
        {
          OUTLINED_FUNCTION_46_6();
LABEL_66:
          OUTLINED_FUNCTION_13_15();
          __break(1u);
LABEL_67:
          OUTLINED_FUNCTION_11_13();
          OUTLINED_FUNCTION_21_12();
          swift_bridgeObjectRelease();
          OUTLINED_FUNCTION_39_7();
          OUTLINED_FUNCTION_16_13(v112);
          OUTLINED_FUNCTION_47_6();
          uint64_t v24 = v138;
          lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
          uint64_t v113 = OUTLINED_FUNCTION_85();
          OUTLINED_FUNCTION_4_25(v113, v114);
LABEL_69:
          OUTLINED_FUNCTION_13_15();
          __break(1u);
LABEL_70:
          __break(1u);
          swift_unexpectedError();
          __break(1u);
LABEL_71:

          swift_release();
          uint64_t ML11MLDataValueOGSgs5NeverOTg5025_s11TabularData0B5FrameV8d9MLEyAcD11f17TableVcfcSayAD0F5G12OGSgSiXEfU2_AG0F6ColumnVyAI12SequenceTypeVGTf1cn_n = 0;
          unint64_t v138 = 0xE000000000000000;
          _StringGuts.grow(_:)(37);
          swift_bridgeObjectRelease();
          OUTLINED_FUNCTION_39_7();
          uint64_t ML11MLDataValueOGSgs5NeverOTg5025_s11TabularData0B5FrameV8d9MLEyAcD11f17TableVcfcSayAD0F5G12OGSgSiXEfU2_AG0F6ColumnVyAI12SequenceTypeVGTf1cn_n = v115 + 3;
          unint64_t v138 = 0x80000002272D40C0;
          uint64_t v136 = v23;
          v116._uint64_t countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter();
          String.append(_:)(v116);
          swift_bridgeObjectRelease();
          v117._uint64_t countAndFlagsBits = 46;
          v117._uint64_t object = (void *)0xE100000000000000;
          String.append(_:)(v117);
          _assertionFailure(_:_:file:line:flags:)();
          __break(1u);
          JUMPOUT(0x2271146F8);
        }
        uint64_t v77 = OUTLINED_FUNCTION_12_11();
        OUTLINED_FUNCTION_26_8();
        if (v77 < 0) {
          goto LABEL_49;
        }
        OUTLINED_FUNCTION_42_6();
        uint64_t v78 = OUTLINED_FUNCTION_19_12();
        _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSnySiG_Say8CreateML11MLDataValueO3key_AI5valuetGSgs5NeverOTg5025_s11TabularData0B5FrameV8d9MLEyAcD11f17TableVcfcSayAD0F5G26O3key_AH5valuetGSgSiXEfU3_AG0F6ColumnVyAI14DictionaryTypeVGTf1cn_n(v78, v79, v80, v81);
        uint64_t v83 = specialized _arrayForceCast<A, B>(_:)(v82);
        swift_bridgeObjectRelease();
        uint64_t ML11MLDataValueOGSgs5NeverOTg5025_s11TabularData0B5FrameV8d9MLEyAcD11f17TableVcfcSayAD0F5G12OGSgSiXEfU2_AG0F6ColumnVyAI12SequenceTypeVGTf1cn_n = v83;
        __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [(MLDataValue, MLDataValue)]);
        __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [[(MLDataValue, MLDataValue)]?]);
        lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [[(MLDataValue, MLDataValue)]?] and conformance [A], &demangling cache variable for type metadata for [[(MLDataValue, MLDataValue)]?]);
        uint64_t v30 = v22;
        uint64_t v22 = v129;
        OUTLINED_FUNCTION_31_6();
        OUTLINED_FUNCTION_48_5();
        OUTLINED_FUNCTION_26_8();
        uint64_t v49 = OUTLINED_FUNCTION_53_8();
        uint64_t v58 = v130;
        goto LABEL_39;
      case 5:
        if (v135) {
          goto LABEL_67;
        }
        OUTLINED_FUNCTION_8_17();
        OUTLINED_FUNCTION_27_8((void *(*)(uint64_t *__return_ptr, void *))partial apply for closure #1 in CMLTable.column(name:));
        OUTLINED_FUNCTION_44_4();
        type metadata accessor for _UntypedColumn();
        uint64_t v84 = (void *)OUTLINED_FUNCTION_70();
        OUTLINED_FUNCTION_3_30(v84);
        OUTLINED_FUNCTION_24_10();
        if (v85 != 5)
        {
          OUTLINED_FUNCTION_46_6();
          goto LABEL_69;
        }
        uint64_t v86 = OUTLINED_FUNCTION_12_11();
        OUTLINED_FUNCTION_26_8();
        if (v86 < 0) {
          goto LABEL_50;
        }
        OUTLINED_FUNCTION_42_6();
        uint64_t v87 = OUTLINED_FUNCTION_19_12();
        uint64_t ML11MLDataValueOGSgs5NeverOTg5025_s11TabularData0B5FrameV8d9MLEyAcD11f17TableVcfcSayAD0F5G12OGSgSiXEfU2_AG0F6ColumnVyAI12SequenceTypeVGTf1cn_n = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSnySiG_So12MLMultiArrayCSgs5NeverOTg5059_s11TabularData0B5FrameV8CreateMLEyAcD11MLDataTableVcfcSo12dE11CSgSiXEfU4_0M2ML0Q6ColumnVyAM0Q5ValueO05MultiE4TypeVGTf1cn_n(v87, v88, v89, v90);
        type metadata accessor for MLMultiArray();
        __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [MLMultiArray?]);
        lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [MLMultiArray?] and conformance [A], &demangling cache variable for type metadata for [MLMultiArray?]);
        uint64_t v91 = v131;
        OUTLINED_FUNCTION_31_6();
        OUTLINED_FUNCTION_48_5();
        OUTLINED_FUNCTION_26_8();
        uint64_t v48 = *(void (**)(uint64_t, uint64_t))(v27 + 8);
        uint64_t v49 = v91;
        uint64_t v22 = v120;
        uint64_t v58 = v132;
        goto LABEL_39;
      case 6:
        goto LABEL_16;
      default:
        if (v135) {
          goto LABEL_51;
        }
        OUTLINED_FUNCTION_8_17();
        OUTLINED_FUNCTION_27_8((void *(*)(uint64_t *__return_ptr, void *))partial apply for closure #1 in CMLTable.column(name:));
        OUTLINED_FUNCTION_44_4();
        type metadata accessor for _UntypedColumn();
        uint64_t v40 = (void *)OUTLINED_FUNCTION_70();
        OUTLINED_FUNCTION_3_30(v40);
        OUTLINED_FUNCTION_24_10();
        if (v41)
        {
          OUTLINED_FUNCTION_46_6();
          goto LABEL_53;
        }
        uint64_t v42 = OUTLINED_FUNCTION_12_11();
        OUTLINED_FUNCTION_26_8();
        if (v42 < 0) {
          goto LABEL_45;
        }
        OUTLINED_FUNCTION_42_6();
        uint64_t v43 = OUTLINED_FUNCTION_19_12();
        _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSnySiG_SiSgs5NeverOTg5059_s11TabularData0B5FrameV8CreateMLEyAcD11MLDataTableVcfcSiSgR5XEfU_0K2ML0O6ColumnVySiGTf1cn_n(v43, v44, v45, v46);
        uint64_t ML11MLDataValueOGSgs5NeverOTg5025_s11TabularData0B5FrameV8d9MLEyAcD11f17TableVcfcSayAD0F5G12OGSgSiXEfU2_AG0F6ColumnVyAI12SequenceTypeVGTf1cn_n = v47;
        __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Int?]);
        lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [Int?] and conformance [A], &demangling cache variable for type metadata for [Int?]);
        OUTLINED_FUNCTION_57_7();
        Column.init<A>(name:contents:)();
        DataFrame.append<A>(column:)();
        OUTLINED_FUNCTION_26_8();
        uint64_t v48 = *v118;
        uint64_t v49 = v121;
        uint64_t v50 = &v139;
        goto LABEL_26;
    }
  }
}

uint64_t MLUntypedColumn.init(_:convertArraysToShapedArrays:)@<X0>(uint64_t a1@<X0>, char a2@<W1>, uint64_t a3@<X8>)
{
  void (*v272)(long long *__return_ptr, uint64_t);
  uint64_t v273;
  uint64_t (*v274)(void);
  uint64_t v275;
  uint64_t *v276;
  unint64_t *v277;
  uint64_t (*v278)(uint64_t);
  void (*v279)(uint64_t);
  uint64_t *v280;
  uint64_t v281;
  uint64_t v282;
  int64_t v283;
  uint64_t v284;
  int v285;
  unint64_t v286;
  uint64_t v287;
  char *v288;
  uint64_t v289;
  uint64_t v290;
  char v291;
  uint64_t v292;
  uint64_t v293;
  uint64_t v294;
  unint64_t v295;
  unint64_t v296;
  uint64_t v297;
  uint64_t v298;
  void (*v299)(uint64_t);
  id *v300;
  id v301;
  id v302;
  uint64_t v303;
  unint64_t v304;
  uint64_t v305;
  void (*v306)(void);
  uint64_t v307;
  uint64_t (*v308)(uint64_t);
  uint64_t v309;
  uint64_t (*v310)(uint64_t);
  uint64_t v311;
  void (*v312)(uint64_t *__return_ptr, uint64_t *);
  uint64_t (*v313)(void);
  uint64_t v314;
  uint64_t v315;
  uint64_t v316;
  uint64_t v317;
  uint64_t v318;
  uint64_t v319;
  uint64_t v320;
  uint64_t v321;
  uint64_t v322;
  uint64_t v323;
  void (*v324)(void);
  void (*v325)(void);
  uint64_t v326;
  void (*v327)(void);
  void (*v328)(void);
  uint64_t v329;
  uint64_t v330;
  uint64_t v331;
  uint64_t v332;
  uint64_t v333;
  uint64_t v334;
  uint64_t v335;
  uint64_t v336;
  uint64_t v337;
  uint64_t v338;
  void (*v339)(void);
  void (*v340)(void);
  uint64_t v341;
  void (*v342)(void);
  uint64_t v343;
  uint64_t v344;
  uint64_t v345;
  uint64_t v346;
  uint64_t v347;
  uint64_t v348;
  uint64_t v349;
  uint64_t v350;
  char v351;
  void (*v352)(void);
  void (*v353)(void);
  uint64_t v354;
  void (*v355)(void);
  uint64_t v356;
  unint64_t v357;
  uint64_t v358;
  uint64_t (*v359)(void);
  uint64_t v360;
  Swift::String v361;
  Swift::String v362;
  uint64_t v363;
  void *v364;
  uint64_t v365;
  void (*v366)(uint64_t);
  uint64_t v367;
  uint64_t v368;
  void (*v369)(uint64_t);
  uint64_t v370;
  uint64_t v371;
  void (*v372)(uint64_t);
  uint64_t v373;
  uint64_t v374;
  void (*v375)(uint64_t);
  uint64_t v376;
  uint64_t v377;
  void (*v378)(uint64_t);
  uint64_t v379;
  uint64_t v380;
  uint64_t v381;
  uint64_t v382;
  uint64_t v383;
  uint64_t v384;
  uint64_t v385;
  uint64_t v386;
  uint64_t v387;
  void (*v388)(uint64_t);
  char v389;
  uint64_t v390;
  uint64_t v391;
  uint64_t v392;
  void (*v393)(uint64_t);
  char v395;
  uint64_t v396;
  uint64_t v397;
  uint64_t v398;
  uint64_t v399;
  uint64_t v400;
  void (*v401)(uint64_t);
  void (*v402)(uint64_t);
  uint64_t v403;
  char v404;
  uint64_t v405;
  uint64_t v406;
  uint64_t v407;
  void (*v408)(uint64_t);
  char v409;
  uint64_t v410;
  uint64_t v411;
  void (*v413)(uint64_t);
  void (*v414)(uint64_t);
  uint64_t v415;
  int v416;
  unint64_t v417;
  void (*v418)(uint64_t);
  unint64_t v419;
  unint64_t v420;
  char v421;
  unint64_t v422;
  double v423;
  uint64_t v424;
  uint64_t v425;
  uint64_t v426;
  char v427;
  uint64_t v428;
  uint64_t v429;
  void v430[2];
  char v431;
  uint64_t v432;
  uint64_t v433;
  char v434;
  _OWORD v435[2];
  uint64_t v436;
  unsigned char v437[32];
  _OWORD v438[2];
  uint64_t v439;
  uint64_t v440;
  unsigned char v441[72];
  void v442[9];
  unint64_t v443;
  unint64_t v444;
  unsigned char v445[32];
  void v446[2];
  char v447;
  void v448[2];
  char v449;
  uint64_t v450;
  unint64_t v451;

  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Int32>?);
  uint64_t v7 = OUTLINED_FUNCTION_17(v6);
  MEMORY[0x270FA5388](v7);
  OUTLINED_FUNCTION_49();
  v374 = v8;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v9);
  OUTLINED_FUNCTION_106();
  v373 = v10;
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<MLShapedArray<Int32>>);
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v11);
  OUTLINED_FUNCTION_33_0();
  v372 = v12;
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Double>?);
  uint64_t v14 = OUTLINED_FUNCTION_17(v13);
  MEMORY[0x270FA5388](v14);
  OUTLINED_FUNCTION_49();
  v371 = v15;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v16);
  OUTLINED_FUNCTION_106();
  v370 = v17;
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<MLShapedArray<Double>>);
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v18);
  OUTLINED_FUNCTION_33_0();
  v369 = v19;
  uint64_t v20 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Float>?);
  uint64_t v21 = OUTLINED_FUNCTION_17(v20);
  MEMORY[0x270FA5388](v21);
  OUTLINED_FUNCTION_49();
  v368 = v22;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v23);
  OUTLINED_FUNCTION_106();
  v367 = v24;
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<MLShapedArray<Float>>);
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v25);
  OUTLINED_FUNCTION_33_0();
  v366 = v26;
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<MLMultiArray>);
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v27);
  OUTLINED_FUNCTION_33_0();
  v378 = v28;
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[AnyHashable : Any?]>);
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v29);
  OUTLINED_FUNCTION_33_0();
  v375 = v30;
  uint64_t v31 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[String : Any]>);
  uint64_t v32 = OUTLINED_FUNCTION_17(v31);
  MEMORY[0x270FA5388](v32);
  OUTLINED_FUNCTION_33_0();
  v365 = v33;
  uint64_t v34 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[String : Any?]>);
  uint64_t v35 = OUTLINED_FUNCTION_17(v34);
  MEMORY[0x270FA5388](v35);
  OUTLINED_FUNCTION_33_0();
  v376 = v36;
  uint64_t v37 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[String : String]>);
  uint64_t v38 = OUTLINED_FUNCTION_17(v37);
  MEMORY[0x270FA5388](v38);
  OUTLINED_FUNCTION_33_0();
  v377 = v39;
  uint64_t v40 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[String : Float]>);
  uint64_t v41 = OUTLINED_FUNCTION_17(v40);
  MEMORY[0x270FA5388](v41);
  OUTLINED_FUNCTION_33_0();
  v379 = v42;
  uint64_t v43 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[String : Double]>);
  uint64_t v44 = OUTLINED_FUNCTION_17(v43);
  MEMORY[0x270FA5388](v44);
  OUTLINED_FUNCTION_33_0();
  v380 = v45;
  uint64_t v46 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[String : Int]>);
  uint64_t v47 = OUTLINED_FUNCTION_17(v46);
  MEMORY[0x270FA5388](v47);
  OUTLINED_FUNCTION_33_0();
  v381 = v48;
  uint64_t v49 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Any]>);
  uint64_t v50 = OUTLINED_FUNCTION_17(v49);
  MEMORY[0x270FA5388](v50);
  OUTLINED_FUNCTION_33_0();
  v382 = v51;
  uint64_t v52 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Any?]>);
  uint64_t v53 = OUTLINED_FUNCTION_17(v52);
  MEMORY[0x270FA5388](v53);
  OUTLINED_FUNCTION_33_0();
  v383 = v54;
  uint64_t v55 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[String]>);
  uint64_t v56 = OUTLINED_FUNCTION_17(v55);
  MEMORY[0x270FA5388](v56);
  OUTLINED_FUNCTION_33_0();
  v385 = v57;
  v387 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Double>);
  OUTLINED_FUNCTION_0();
  v384 = v58;
  MEMORY[0x270FA5388](v59);
  OUTLINED_FUNCTION_49();
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v60);
  OUTLINED_FUNCTION_45_3();
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v61);
  OUTLINED_FUNCTION_106();
  v389 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Double]>);
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v62);
  OUTLINED_FUNCTION_49();
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v63);
  OUTLINED_FUNCTION_106();
  v388 = v64;
  v392 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Float>);
  OUTLINED_FUNCTION_0();
  v386 = v65;
  MEMORY[0x270FA5388](v66);
  OUTLINED_FUNCTION_49();
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v67);
  OUTLINED_FUNCTION_45_3();
  v390 = v68;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v69);
  OUTLINED_FUNCTION_106();
  v391 = v70;
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Float]>);
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v71);
  OUTLINED_FUNCTION_49();
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v72);
  OUTLINED_FUNCTION_106();
  v393 = v73;
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Int32]>);
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v74);
  OUTLINED_FUNCTION_33_0();
  v401 = v75;
  v396 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Int32>);
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v76);
  OUTLINED_FUNCTION_49();
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v77);
  OUTLINED_FUNCTION_45_3();
  v397 = v78;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v79);
  OUTLINED_FUNCTION_106();
  v399 = v80;
  v395 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Int]>);
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v81);
  OUTLINED_FUNCTION_49();
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v82);
  OUTLINED_FUNCTION_45_3();
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v83);
  OUTLINED_FUNCTION_106();
  v402 = v84;
  uint64_t v85 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Date?);
  uint64_t v86 = OUTLINED_FUNCTION_17(v85);
  MEMORY[0x270FA5388](v86);
  OUTLINED_FUNCTION_49();
  v405 = v87;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v88);
  OUTLINED_FUNCTION_106();
  v403 = v89;
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Date>);
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v90);
  OUTLINED_FUNCTION_33_0();
  v408 = v91;
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v92);
  OUTLINED_FUNCTION_33_0();
  v414 = v93;
  uint64_t v94 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Double>);
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v95);
  OUTLINED_FUNCTION_3_0();
  unint64_t v98 = v97 - v96;
  char v99 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Float>);
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v100);
  OUTLINED_FUNCTION_32();
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Int>);
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v101);
  OUTLINED_FUNCTION_3_0();
  uint64_t v104 = (void (*)(void))(v103 - v102);
  uint64_t v105 = a1;
  AnyColumn.wrappedElementType.getter();
  if (swift_dynamicCastMetatype())
  {
    AnyColumn.assumingType<A>(_:)();
    LOBYTE(v98) = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<Int> and conformance Column<A>, &demangling cache variable for type metadata for Column<Int>);
    uint64_t v106 = v104;
    uint64_t v107 = dispatch thunk of Collection.count.getter();
    v418 = v104;
    if (!v107) {
      goto LABEL_35;
    }
    uint64_t v108 = v107;
    v442[0] = MEMORY[0x263F8EE78];
    OUTLINED_FUNCTION_10_14();
    uint64_t v109 = v442[0];
    dispatch thunk of Collection.startIndex.getter();
    if ((v108 & 0x8000000000000000) == 0)
    {
      do
      {
        OUTLINED_FUNCTION_36_7();
        dispatch thunk of Collection.subscript.read();
        uint64_t v111 = *v110;
        int v112 = *((unsigned __int8 *)v110 + 8);
        uint64_t v113 = OUTLINED_FUNCTION_34_7();
        v114(v113);
        BOOL v115 = v112 == 0;
        if (v112) {
          uint64_t v116 = 0;
        }
        else {
          uint64_t v116 = v111;
        }
        if (v115) {
          char v117 = 0;
        }
        else {
          char v117 = 6;
        }
        v442[0] = v109;
        unint64_t v118 = *(void *)(v109 + 16);
        if (v118 >= *(void *)(v109 + 24) >> 1)
        {
          OUTLINED_FUNCTION_25_13();
          uint64_t v109 = v442[0];
        }
        *(void *)(v109 + 16) = v118 + 1;
        uint64_t v119 = v109 + 24 * v118;
        *(void *)(v119 + 32) = v116;
        *(void *)(v119 + 40) = 0;
        *(unsigned char *)(v119 + 48) = v117;
        uint64_t v106 = v418;
        dispatch thunk of Collection.formIndex(after:)();
        --v108;
      }
      while (v108);
LABEL_23:
      OUTLINED_FUNCTION_59_5();
      goto LABEL_35;
    }
    __break(1u);
LABEL_147:
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String]);
    if (OUTLINED_FUNCTION_58_3())
    {
      AnyColumn.assumingType<A>(_:)();
      int64_t v3 = v413;
      specialized MLUntypedColumn.init<A>(_:)(v385, (uint64_t)&v443);
      goto LABEL_151;
    }
LABEL_155:
    uint64_t v136 = (uint64_t)v413;
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Any?]);
    if (OUTLINED_FUNCTION_58_3())
    {
      uint64_t v269 = v383;
      OUTLINED_FUNCTION_14_11();
      v270 = &demangling cache variable for type metadata for Column<[Any?]>;
      v271 = (unint64_t *)&lazy protocol witness table cache variable for type Column<[Any?]> and conformance Column<A>;
      v272 = (void (*)(long long *__return_ptr, uint64_t))specialized closure #1 in MLUntypedColumn.init<A>(_:);
LABEL_160:
      v273 = v136;
      specialized MLUntypedColumn.init<A>(_:)(v269, v270, v271, (uint64_t)closure #1 in MLUntypedColumn.init<A>(_:)specialized partial apply, v272, (uint64_t)&v443);
      goto LABEL_161;
    }
LABEL_158:
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Any]);
    if (!OUTLINED_FUNCTION_22_11()) {
      goto LABEL_165;
    }
    uint64_t v269 = v382;
    OUTLINED_FUNCTION_14_11();
    v270 = &demangling cache variable for type metadata for Column<[Any]>;
    v271 = (unint64_t *)&lazy protocol witness table cache variable for type Column<[Any]> and conformance Column<A>;
    v272 = (void (*)(long long *__return_ptr, uint64_t))specialized closure #1 in MLUntypedColumn.init<A>(_:);
    goto LABEL_160;
  }
  uint64_t v106 = v4;
  if (swift_dynamicCastMetatype())
  {
    uint64_t v120 = v4;
    AnyColumn.assumingType<A>(_:)();
    uint64_t v121 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<Float> and conformance Column<A>, &demangling cache variable for type metadata for Column<Float>);
    LOBYTE(v98) = v99;
    uint64_t v122 = dispatch thunk of Collection.count.getter();
    if (!v122)
    {
LABEL_35:
      uint64_t v152 = a3;
      OUTLINED_FUNCTION_25_0();
      v153();
      OUTLINED_FUNCTION_50_5();
      MEMORY[0x270FA5388](v154);
      OUTLINED_FUNCTION_2_30();
LABEL_36:
      _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTgm5((void (*)(uint64_t *__return_ptr, uint64_t *))closure #1 in MLUntypedColumn.init<A>(_:)specialized partial apply);
      OUTLINED_FUNCTION_29_7();
      type metadata accessor for AnyColumn();
      OUTLINED_FUNCTION_6_19();
      OUTLINED_FUNCTION_25_0();
      uint64_t result = v155();
      goto LABEL_37;
    }
    uint64_t v123 = v122;
    v442[0] = MEMORY[0x263F8EE78];
    OUTLINED_FUNCTION_10_14();
    uint64_t v124 = v442[0];
    dispatch thunk of Collection.startIndex.getter();
    if ((v123 & 0x8000000000000000) == 0)
    {
      do
      {
        OUTLINED_FUNCTION_36_7();
        dispatch thunk of Collection.subscript.read();
        float v126 = *(float *)v125;
        int v127 = *(unsigned __int8 *)(v125 + 4);
        uint64_t v128 = OUTLINED_FUNCTION_34_7();
        v129(v128);
        if (v127) {
          double v130 = 0.0;
        }
        else {
          double v130 = v126;
        }
        v442[0] = v124;
        uint64_t v131 = v121;
        unint64_t v133 = *(void *)(v124 + 16);
        unint64_t v132 = *(void *)(v124 + 24);
        if (v133 >= v132 >> 1)
        {
          OUTLINED_FUNCTION_63_4(v132);
          v423 = v135;
          specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
          double v130 = v423;
          uint64_t v124 = v442[0];
        }
        *(void *)(v124 + 16) = v133 + 1;
        uint64_t v134 = v124 + 24 * v133;
        *(double *)(v134 + 32) = v130;
        *(void *)(v134 + 40) = 0;
        OUTLINED_FUNCTION_40_5(v134);
        uint64_t v106 = v120;
        dispatch thunk of Collection.formIndex(after:)();
        --v123;
        uint64_t v121 = v131;
      }
      while (v123);
      goto LABEL_23;
    }
    __break(1u);
    goto LABEL_155;
  }
  uint64_t v136 = v105;
  if (swift_dynamicCastMetatype())
  {
    uint64_t v137 = (void (*)(void))v98;
    AnyColumn.assumingType<A>(_:)();
    LOBYTE(v98) = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<Double> and conformance Column<A>, &demangling cache variable for type metadata for Column<Double>);
    uint64_t v106 = v137;
    uint64_t v138 = dispatch thunk of Collection.count.getter();
    if (!v138) {
      goto LABEL_91;
    }
    uint64_t v139 = v138;
    v442[0] = MEMORY[0x263F8EE78];
    OUTLINED_FUNCTION_10_14();
    uint64_t v140 = v442[0];
    OUTLINED_FUNCTION_81_3();
    if (v139 < 0)
    {
      __break(1u);
      goto LABEL_158;
    }
    do
    {
      OUTLINED_FUNCTION_79_3();
      dispatch thunk of Collection.subscript.read();
      uint64_t v142 = *v141;
      unint64_t v98 = v94;
      int v143 = *((unsigned __int8 *)v141 + 8);
      uint64_t v144 = OUTLINED_FUNCTION_34_7();
      v145(v144);
      if (v143) {
        uint64_t v146 = 0;
      }
      else {
        uint64_t v146 = v142;
      }
      v442[0] = v140;
      uint64_t v147 = v137;
      unint64_t v149 = *(void *)(v140 + 16);
      unint64_t v148 = *(void *)(v140 + 24);
      if (v149 >= v148 >> 1)
      {
        OUTLINED_FUNCTION_61_5(v148);
        v424 = v151;
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
        uint64_t v146 = v424;
        uint64_t v140 = v442[0];
      }
      *(void *)(v140 + 16) = v149 + 1;
      uint64_t v150 = v140 + 24 * v149;
      *(void *)(v150 + 32) = v146;
      *(void *)(v150 + 40) = 0;
      OUTLINED_FUNCTION_40_5(v150);
      uint64_t v106 = v147;
      dispatch thunk of Collection.formIndex(after:)();
      --v139;
      uint64_t v94 = v98;
      uint64_t v137 = v147;
    }
    while (v139);
    goto LABEL_60;
  }
  if (swift_dynamicCastMetatype())
  {
    AnyColumn.assumingType<A>(_:)();
    uint64_t v136 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<String> and conformance Column<A>, &demangling cache variable for type metadata for Column<String>);
    uint64_t v106 = v414;
    uint64_t v157 = dispatch thunk of Collection.count.getter();
    if (v157)
    {
      uint64_t v158 = v157;
      v442[0] = MEMORY[0x263F8EE78];
      OUTLINED_FUNCTION_10_14();
      uint64_t v159 = v442[0];
      dispatch thunk of Collection.startIndex.getter();
      if (v158 < 0) {
        goto LABEL_164;
      }
      do
      {
        OUTLINED_FUNCTION_36_7();
        uint64_t v160 = (void (*)(uint64_t))dispatch thunk of Collection.subscript.read();
        uint64_t v162 = *v161;
        uint64_t v163 = v161[1];
        swift_bridgeObjectRetain();
        uint64_t v164 = OUTLINED_FUNCTION_5_20();
        v160(v164);
        if (v163) {
          uint64_t v165 = v162;
        }
        else {
          uint64_t v165 = 0;
        }
        v442[0] = v159;
        unint64_t v98 = *(void *)(v159 + 16);
        unint64_t v166 = *(void *)(v159 + 24);
        if (v98 >= v166 >> 1)
        {
          OUTLINED_FUNCTION_60_3(v166);
          v425 = v168;
          specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
          uint64_t v165 = v425;
          uint64_t v159 = v442[0];
        }
        *(void *)(v159 + 16) = v98 + 1;
        uint64_t v167 = v159 + 24 * v98;
        *(void *)(v167 + 32) = v165;
        *(void *)(v167 + 40) = v163;
        OUTLINED_FUNCTION_40_5(v167);
        uint64_t v106 = v414;
        dispatch thunk of Collection.formIndex(after:)();
        --v158;
      }
      while (v158);
      OUTLINED_FUNCTION_59_5();
    }
    OUTLINED_FUNCTION_57_7();
    OUTLINED_FUNCTION_25_0();
    v185();
    OUTLINED_FUNCTION_51_6();
    MEMORY[0x270FA5388](v186);
    OUTLINED_FUNCTION_2_30();
    goto LABEL_92;
  }
  type metadata accessor for Date();
  if (OUTLINED_FUNCTION_58_3())
  {
    v426 = v98;
    AnyColumn.assumingType<A>(_:)();
    LOBYTE(v98) = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<Date> and conformance Column<A>, &demangling cache variable for type metadata for Column<Date>);
    uint64_t v106 = v408;
    uint64_t v169 = dispatch thunk of Collection.count.getter();
    if (!v169)
    {
LABEL_91:
      OUTLINED_FUNCTION_25_0();
      v215();
      OUTLINED_FUNCTION_51_6();
      MEMORY[0x270FA5388](v216);
      OUTLINED_FUNCTION_2_30();
LABEL_92:
      _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTgm5((void (*)(uint64_t *__return_ptr, uint64_t *))closure #1 in MLUntypedColumn.init<A>(_:)specialized partial apply);
      OUTLINED_FUNCTION_29_7();
      type metadata accessor for AnyColumn();
      OUTLINED_FUNCTION_6_19();
LABEL_93:
      OUTLINED_FUNCTION_25_0();
      uint64_t result = v217();
      goto LABEL_94;
    }
    uint64_t v170 = v169;
    v442[0] = MEMORY[0x263F8EE78];
    OUTLINED_FUNCTION_10_14();
    OUTLINED_FUNCTION_81_3();
    if (v170 < 0)
    {
LABEL_168:
      __break(1u);
      goto LABEL_169;
    }
    do
    {
      OUTLINED_FUNCTION_79_3();
      uint64_t v171 = dispatch thunk of Collection.subscript.read();
      uint64_t v173 = OUTLINED_FUNCTION_76_2(v171, v172);
      outlined init with copy of MLShapedArray<Int32>?(v173, v403, &demangling cache variable for type metadata for Date?);
      uint64_t v174 = OUTLINED_FUNCTION_5_20();
      v106(v174);
      outlined init with copy of MLShapedArray<Int32>?(v403, v405, &demangling cache variable for type metadata for Date?);
      uint64_t v175 = OUTLINED_FUNCTION_133();
      if (__swift_getEnumTagSinglePayload(v175, v176, v426) == 1)
      {
        outlined destroy of DefaultIndices<DataFrame.Rows>(v405, &demangling cache variable for type metadata for Date?);
        char v177 = 6;
        uint64_t v178 = 0;
      }
      else
      {
        Date.timeIntervalSince1970.getter();
        uint64_t v178 = v179;
        OUTLINED_FUNCTION_25_0();
        v180();
        char v177 = 1;
      }
      outlined destroy of DefaultIndices<DataFrame.Rows>(v403, &demangling cache variable for type metadata for Date?);
      uint64_t v181 = v442[0];
      if ((swift_isUniquelyReferenced_nonNull_native() & 1) == 0)
      {
        OUTLINED_FUNCTION_15_13();
        uint64_t v181 = v442[0];
      }
      unint64_t v183 = *(void *)(v181 + 16);
      unint64_t v182 = *(void *)(v181 + 24);
      if (v183 >= v182 >> 1)
      {
        OUTLINED_FUNCTION_60_3(v182);
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
        uint64_t v181 = v442[0];
      }
      *(void *)(v181 + 16) = v183 + 1;
      uint64_t v184 = v181 + 24 * v183;
      *(void *)(v184 + 32) = v178;
      *(void *)(v184 + 40) = 0;
      *(unsigned char *)(v184 + 48) = v177;
      uint64_t v106 = v408;
      dispatch thunk of Collection.formIndex(after:)();
      --v170;
    }
    while (v170);
LABEL_60:
    OUTLINED_FUNCTION_59_5();
    goto LABEL_91;
  }
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Int]);
  if (!swift_dynamicCastMetatype())
  {
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Int32]);
    if (swift_dynamicCastMetatype())
    {
      if ((a2 & 1) == 0)
      {
LABEL_126:
        AnyColumn.assumingType<A>(_:)();
        uint64_t v246 = OUTLINED_FUNCTION_70_3();
        specialized MLUntypedColumn.init<A>(_:)(v246, v247);
        goto LABEL_127;
      }
      OUTLINED_FUNCTION_67_3();
      LOBYTE(v98) = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<[Int32]> and conformance Column<A>, &demangling cache variable for type metadata for Column<[Int32]>);
      uint64_t v106 = v401;
      uint64_t v218 = dispatch thunk of Collection.count.getter();
      unint64_t v219 = MEMORY[0x263F8EE78];
      uint64_t v152 = a3;
      if (v218)
      {
        uint64_t v220 = v218;
        v442[0] = MEMORY[0x263F8EE78];
        OUTLINED_FUNCTION_10_14();
        dispatch thunk of Collection.startIndex.getter();
        if (v220 < 0)
        {
          __break(1u);
          goto LABEL_177;
        }
        v427 = v98;
        do
        {
          OUTLINED_FUNCTION_80_3();
          dispatch thunk of Collection.subscript.read();
          OUTLINED_FUNCTION_64_3();
          uint64_t v221 = OUTLINED_FUNCTION_5_20();
          v3(v221);
          if (v219)
          {
            v443 = v219;
            __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
            v222 = (__n128 *)OUTLINED_FUNCTION_55_7();
            OUTLINED_FUNCTION_49_1(v222, (__n128)xmmword_2272CB370);
            int64_t v3 = (void (*)(uint64_t))lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [Int32] and conformance [A], &demangling cache variable for type metadata for [Int32]);
            swift_bridgeObjectRetain();
            MLShapedArray.init<A>(scalars:shape:)();
            type metadata accessor for MLMultiArray();
            OUTLINED_FUNCTION_32_8();
            v223();
            lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type MLShapedArray<Int32> and conformance MLShapedArray<A>, &demangling cache variable for type metadata for MLShapedArray<Int32>);
            uint64_t v224 = MLMultiArray.init<A>(_:)();
            MLDataValue.MultiArrayType.init(_:)((MLMultiArray)v224);
            OUTLINED_FUNCTION_73_0();
            OUTLINED_FUNCTION_25_0();
            v225();
            swift_bridgeObjectRelease();
            unint64_t v226 = v219;
            char v227 = 5;
          }
          else
          {
            unint64_t v226 = 0;
            char v227 = 6;
          }
          if ((OUTLINED_FUNCTION_65_3() & 1) == 0)
          {
            OUTLINED_FUNCTION_15_13();
            unint64_t v219 = v442[0];
          }
          unint64_t v228 = *(void *)(v219 + 16);
          if (v228 >= *(void *)(v219 + 24) >> 1)
          {
            OUTLINED_FUNCTION_62_3();
            unint64_t v219 = v442[0];
          }
          *(void *)(v219 + 16) = v228 + 1;
          unint64_t v229 = v219 + 24 * v228;
          *(void *)(v229 + 32) = v226;
          *(void *)(v229 + 40) = 0;
          *(unsigned char *)(v229 + 48) = v227;
          uint64_t v106 = v401;
          LOBYTE(v98) = v427;
          dispatch thunk of Collection.formIndex(after:)();
          --v220;
        }
        while (v220);
        uint64_t v152 = a3;
      }
    }
    else
    {
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Float]);
      if (swift_dynamicCastMetatype())
      {
        LOBYTE(v98) = v386;
        if ((a2 & 1) == 0)
        {
          AnyColumn.assumingType<A>(_:)();
          uint64_t v263 = OUTLINED_FUNCTION_70_3();
          specialized MLUntypedColumn.init<A>(_:)(v263, v264);
LABEL_127:
          uint64_t v152 = a3;
          if (!v3)
          {
            type metadata accessor for AnyColumn();
            OUTLINED_FUNCTION_6_19();
            OUTLINED_FUNCTION_25_0();
            uint64_t result = v249();
            uint64_t v106 = (void (*)(uint64_t))v443;
            LOBYTE(v98) = v444;
            goto LABEL_37;
          }
          goto LABEL_128;
        }
        OUTLINED_FUNCTION_67_3();
        uint64_t v136 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<[Float]> and conformance Column<A>, &demangling cache variable for type metadata for Column<[Float]>);
        uint64_t v106 = v393;
        OUTLINED_FUNCTION_63_3();
        uint64_t v235 = dispatch thunk of Collection.count.getter();
        unint64_t v236 = MEMORY[0x263F8EE78];
        uint64_t v152 = a3;
        if (v235)
        {
          uint64_t v237 = v235;
          v442[0] = MEMORY[0x263F8EE78];
          OUTLINED_FUNCTION_10_14();
          OUTLINED_FUNCTION_63_3();
          dispatch thunk of Collection.startIndex.getter();
          if (v237 < 0)
          {
            __break(1u);
            goto LABEL_180;
          }
          unint64_t v98 = v386 + 16;
          do
          {
            OUTLINED_FUNCTION_80_3();
            dispatch thunk of Collection.subscript.read();
            OUTLINED_FUNCTION_64_3();
            uint64_t v238 = OUTLINED_FUNCTION_5_20();
            v3(v238);
            if (v236)
            {
              v443 = v236;
              __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
              v239 = (__n128 *)OUTLINED_FUNCTION_55_7();
              OUTLINED_FUNCTION_49_1(v239, (__n128)xmmword_2272CB370);
              int64_t v3 = (void (*)(uint64_t))lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>((unint64_t *)&lazy protocol witness table cache variable for type [Float] and conformance [A], &demangling cache variable for type metadata for [Float]);
              swift_bridgeObjectRetain();
              MLShapedArray.init<A>(scalars:shape:)();
              type metadata accessor for MLMultiArray();
              (*(void (**)(uint64_t, uint64_t, uint64_t))v98)(v390, v391, v392);
              lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type MLShapedArray<Float> and conformance MLShapedArray<A>, &demangling cache variable for type metadata for MLShapedArray<Float>);
              uint64_t v240 = MLMultiArray.init<A>(_:)();
              MLDataValue.MultiArrayType.init(_:)((MLMultiArray)v240);
              OUTLINED_FUNCTION_63_3();
              OUTLINED_FUNCTION_25_0();
              v241();
              swift_bridgeObjectRelease();
              unint64_t v242 = v236;
              char v243 = 5;
            }
            else
            {
              unint64_t v242 = 0;
              char v243 = 6;
            }
            if ((OUTLINED_FUNCTION_65_3() & 1) == 0)
            {
              OUTLINED_FUNCTION_15_13();
              unint64_t v236 = v442[0];
            }
            unint64_t v244 = *(void *)(v236 + 16);
            if (v244 >= *(void *)(v236 + 24) >> 1)
            {
              OUTLINED_FUNCTION_62_3();
              unint64_t v236 = v442[0];
            }
            *(void *)(v236 + 16) = v244 + 1;
            unint64_t v245 = v236 + 24 * v244;
            *(void *)(v245 + 32) = v242;
            *(void *)(v245 + 40) = 0;
            *(unsigned char *)(v245 + 48) = v243;
            uint64_t v106 = v393;
            dispatch thunk of Collection.formIndex(after:)();
            --v237;
          }
          while (v237);
          uint64_t v152 = a3;
        }
      }
      else
      {
        __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Double]);
        if (!swift_dynamicCastMetatype()) {
          goto LABEL_147;
        }
        if ((a2 & 1) == 0)
        {
          AnyColumn.assumingType<A>(_:)();
          uint64_t v265 = OUTLINED_FUNCTION_70_3();
          specialized MLUntypedColumn.init<A>(_:)(v265, v266);
LABEL_151:
          if (!v3) {
            goto LABEL_162;
          }
          goto LABEL_128;
        }
        OUTLINED_FUNCTION_67_3();
        lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<[Double]> and conformance Column<A>, &demangling cache variable for type metadata for Column<[Double]>);
        uint64_t v106 = v388;
        LOBYTE(v98) = v389;
        uint64_t v250 = dispatch thunk of Collection.count.getter();
        unint64_t v251 = MEMORY[0x263F8EE78];
        uint64_t v152 = a3;
        if (v250)
        {
          uint64_t v252 = v250;
          v442[0] = MEMORY[0x263F8EE78];
          OUTLINED_FUNCTION_10_14();
          dispatch thunk of Collection.startIndex.getter();
          if (v252 < 0)
          {
            __break(1u);
            goto LABEL_184;
          }
          do
          {
            dispatch thunk of Collection.subscript.read();
            OUTLINED_FUNCTION_64_3();
            uint64_t v253 = OUTLINED_FUNCTION_5_20();
            v3(v253);
            if (v251)
            {
              v443 = v251;
              __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
              v254 = (__n128 *)OUTLINED_FUNCTION_55_7();
              OUTLINED_FUNCTION_49_1(v254, (__n128)xmmword_2272CB370);
              int64_t v3 = (void (*)(uint64_t))lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [Double] and conformance [A], &demangling cache variable for type metadata for [Double]);
              swift_bridgeObjectRetain();
              MLShapedArray.init<A>(scalars:shape:)();
              type metadata accessor for MLMultiArray();
              OUTLINED_FUNCTION_32_8();
              v255();
              lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type MLShapedArray<Double> and conformance MLShapedArray<A>, &demangling cache variable for type metadata for MLShapedArray<Double>);
              uint64_t v256 = MLMultiArray.init<A>(_:)();
              MLDataValue.MultiArrayType.init(_:)((MLMultiArray)v256);
              OUTLINED_FUNCTION_25_0();
              v257();
              swift_bridgeObjectRelease();
              unint64_t v258 = v251;
              char v259 = 5;
            }
            else
            {
              unint64_t v258 = 0;
              char v259 = 6;
            }
            if ((OUTLINED_FUNCTION_65_3() & 1) == 0)
            {
              OUTLINED_FUNCTION_15_13();
              unint64_t v251 = v442[0];
            }
            unint64_t v261 = *(void *)(v251 + 16);
            unint64_t v260 = *(void *)(v251 + 24);
            if (v261 >= v260 >> 1)
            {
              OUTLINED_FUNCTION_63_4(v260);
              specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
              unint64_t v251 = v442[0];
            }
            *(void *)(v251 + 16) = v261 + 1;
            unint64_t v262 = v251 + 24 * v261;
            *(void *)(v262 + 32) = v258;
            *(void *)(v262 + 40) = 0;
            *(unsigned char *)(v262 + 48) = v259;
            LOBYTE(v98) = v389;
            uint64_t v106 = v388;
            dispatch thunk of Collection.formIndex(after:)();
            --v252;
          }
          while (v252);
          uint64_t v152 = a3;
        }
      }
    }
    OUTLINED_FUNCTION_25_0();
    v267();
    OUTLINED_FUNCTION_30_8();
    MEMORY[0x270FA5388](v268);
    OUTLINED_FUNCTION_2_30();
    goto LABEL_36;
  }
  if ((a2 & 1) == 0) {
    goto LABEL_126;
  }
  AnyColumn.assumingType<A>(_:)();
  lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<[Int]> and conformance Column<A>, &demangling cache variable for type metadata for Column<[Int]>);
  uint64_t v106 = v402;
  LOBYTE(v98) = v395;
  uint64_t v187 = dispatch thunk of Collection.count.getter();
  uint64_t v136 = (uint64_t)v413;
  uint64_t v152 = a3;
  if (!v187)
  {
LABEL_110:
    OUTLINED_FUNCTION_25_0();
    v230();
    OUTLINED_FUNCTION_50_5();
    MEMORY[0x270FA5388](v231);
    OUTLINED_FUNCTION_2_30();
    goto LABEL_36;
  }
  v442[0] = MEMORY[0x263F8EE78];
  v415 = v187;
  OUTLINED_FUNCTION_20_11();
  dispatch thunk of Collection.startIndex.getter();
  uint64_t v188 = v415;
  if (v415 < 0)
  {
    __break(1u);
    goto LABEL_174;
  }
  unint64_t v189 = 0;
  uint64_t v190 = v396;
  while (1)
  {
    v419 = v189;
    if (v189 == v188)
    {
      __break(1u);
      goto LABEL_168;
    }
    OUTLINED_FUNCTION_36_7();
    uint64_t v191 = (void (*)(uint64_t))dispatch thunk of Collection.subscript.read();
    uint64_t v193 = *v192;
    swift_bridgeObjectRetain();
    uint64_t v194 = OUTLINED_FUNCTION_5_20();
    v191(v194);
    if (v193) {
      break;
    }
    unint64_t v200 = 0;
    char v201 = 6;
LABEL_78:
    uint64_t v206 = v442[0];
    if ((swift_isUniquelyReferenced_nonNull_native() & 1) == 0)
    {
      OUTLINED_FUNCTION_15_13();
      uint64_t v206 = v442[0];
    }
    unint64_t v207 = v419;
    unint64_t v98 = *(void *)(v206 + 16);
    unint64_t v208 = *(void *)(v206 + 24);
    if (v98 >= v208 >> 1)
    {
      OUTLINED_FUNCTION_61_5(v208);
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
      unint64_t v207 = v419;
      uint64_t v206 = v442[0];
    }
    *(void *)(v206 + 16) = v98 + 1;
    uint64_t v209 = v206 + 24 * v98;
    *(void *)(v209 + 32) = v200;
    *(void *)(v209 + 40) = 0;
    *(unsigned char *)(v209 + 48) = v201;
    uint64_t v106 = v402;
    LOBYTE(v98) = v395;
    unint64_t v210 = v207 + 1;
    dispatch thunk of Collection.formIndex(after:)();
    unint64_t v189 = v210;
    uint64_t v188 = v415;
    uint64_t v136 = (uint64_t)v413;
    if (v210 == v415) {
      goto LABEL_110;
    }
  }
  unint64_t v195 = *(void *)(v193 + 16);
  if (!v195)
  {
    unint64_t v197 = MEMORY[0x263F8EE78];
    uint64_t v199 = v397;
    goto LABEL_77;
  }
  v443 = MEMORY[0x263F8EE78];
  specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
  uint64_t v196 = *(void *)(v193 + 32);
  if (v196 != (int)v196)
  {
LABEL_111:
    lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    uint64_t v232 = OUTLINED_FUNCTION_85();
    void *v233 = 0xD00000000000001FLL;
    v233[1] = 0x80000002272D7150;
    OUTLINED_FUNCTION_2_3(v232, (uint64_t)v233);
    swift_bridgeObjectRelease();
    swift_release();
    swift_release();
    type metadata accessor for AnyColumn();
    OUTLINED_FUNCTION_6_19();
    OUTLINED_FUNCTION_25_0();
    v234();
    goto LABEL_129;
  }
  unint64_t v197 = v443;
  unint64_t v198 = *(void *)(v443 + 16);
  if (v198 >= *(void *)(v443 + 24) >> 1)
  {
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
    unint64_t v197 = v443;
  }
  *(void *)(v197 + 16) = v198 + 1;
  *(_DWORD *)(v197 + 4 * v198 + 32) = v196;
  uint64_t v136 = v195 - 1;
  if (v195 == 1)
  {
LABEL_74:
    uint64_t v152 = a3;
    uint64_t v190 = v396;
    uint64_t v199 = v397;
LABEL_77:
    v443 = v197;
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
    uint64_t v202 = OUTLINED_FUNCTION_55_7();
    *(_OWORD *)(v202 + 16) = xmmword_2272CB370;
    *(void *)(v202 + 32) = v195;
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Int32]);
    lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [Int32] and conformance [A], &demangling cache variable for type metadata for [Int32]);
    MLShapedArray.init<A>(scalars:shape:)();
    type metadata accessor for MLMultiArray();
    OUTLINED_FUNCTION_72_2();
    v203(v199, v399, v190);
    lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type MLShapedArray<Int32> and conformance MLShapedArray<A>, &demangling cache variable for type metadata for MLShapedArray<Int32>);
    uint64_t v204 = MLMultiArray.init<A>(_:)();
    MLDataValue.MultiArrayType.init(_:)((MLMultiArray)v204);
    OUTLINED_FUNCTION_25_0();
    v205();
    swift_bridgeObjectRelease();
    unint64_t v200 = v443;
    char v201 = 5;
    goto LABEL_78;
  }
  uint64_t v211 = 0;
  unint64_t v212 = v198 + 9;
  uint64_t v213 = v193 + 40;
  while (v211 + 1 < v195)
  {
    uint64_t v214 = *(void *)(v213 + 8 * v211);
    if (v214 != (int)v214) {
      goto LABEL_111;
    }
    v443 = v197;
    if (v212 - 8 >= *(void *)(v197 + 24) >> 1)
    {
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
      unint64_t v197 = v443;
    }
    *(void *)(v197 + 16) = v212 - 7;
    *(_DWORD *)(v197 + 4 * v212++) = v214;
    if (v136 == ++v211) {
      goto LABEL_74;
    }
  }
  __break(1u);
LABEL_164:
  __break(1u);
LABEL_165:
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String : Int]);
  if (OUTLINED_FUNCTION_22_11())
  {
    v275 = v381;
    OUTLINED_FUNCTION_14_11();
    v276 = &demangling cache variable for type metadata for Column<[String : Int]>;
    v277 = (unint64_t *)&lazy protocol witness table cache variable for type Column<[String : Int]> and conformance Column<A>;
    v278 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSDySSSiG_8CreateML11MLDataValueO_AItsAE_pTg5020_sSS3key_x5valuetSg8d4ML11fg5OAFs5c136_pIgnrrzo_SSAA_xABtAF_AFtsAG_pIegnrzr_lTRSi_TG503_s8c39ML15MLUntypedColumnVyAC11TabularData0D0l18SDySSxGGKclufcAA11ef34OAGSgKXEfU_AJ_AJti1_J22SgV8U_Si_TG5Tf3nnnpf_nTf1cn_n;
    goto LABEL_182;
  }
LABEL_169:
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String : Double]);
  if (OUTLINED_FUNCTION_22_11())
  {
    v275 = v380;
    OUTLINED_FUNCTION_14_11();
    v276 = &demangling cache variable for type metadata for Column<[String : Double]>;
    v277 = (unint64_t *)&lazy protocol witness table cache variable for type Column<[String : Double]> and conformance Column<A>;
    v278 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSDySSSdG_8CreateML11MLDataValueO_AItsAE_pTg5020_sSS3key_x5valuetSg8d4ML11fg5OAFs5c136_pIgnrrzo_SSAA_xABtAF_AFtsAG_pIegnrzr_lTRSd_TG503_s8c39ML15MLUntypedColumnVyAC11TabularData0D0l18SDySSxGGKclufcAA11ef34OAGSgKXEfU_AJ_AJti1_J22SgV8U_Sd_TG5Tf3nnnpf_nTf1cn_n;
    goto LABEL_182;
  }
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String : Float]);
  if (OUTLINED_FUNCTION_22_11())
  {
    v275 = v379;
    OUTLINED_FUNCTION_14_11();
    v276 = &demangling cache variable for type metadata for Column<[String : Float]>;
    v277 = (unint64_t *)&lazy protocol witness table cache variable for type Column<[String : Float]> and conformance Column<A>;
    v278 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSDySSSfG_8CreateML11MLDataValueO_AItsAE_pTg5020_sSS3key_x5valuetSg8d4ML11fg5OAFs5c136_pIgnrrzo_SSAA_xABtAF_AFtsAG_pIegnrzr_lTRSf_TG503_s8c39ML15MLUntypedColumnVyAC11TabularData0D0l18SDySSxGGKclufcAA11ef34OAGSgKXEfU_AJ_AJti1_J22SgV8U_Sf_TG5Tf3nnnpf_nTf1cn_n;
    goto LABEL_182;
  }
LABEL_174:
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String : String]);
  if (OUTLINED_FUNCTION_22_11())
  {
    v275 = v377;
    OUTLINED_FUNCTION_14_11();
    v276 = &demangling cache variable for type metadata for Column<[String : String]>;
    v277 = (unint64_t *)&lazy protocol witness table cache variable for type Column<[String : String]> and conformance Column<A>;
    v278 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSDyS2SG_8CreateML11MLDataValueO_AItsAE_pTg5020_sSS3key_x5valuetSg8d4ML11fg5OAFs5c136_pIgnrrzo_SSAA_xABtAF_AFtsAG_pIegnrzr_lTRSS_TG503_s8c39ML15MLUntypedColumnVyAC11TabularData0D0l18SDySSxGGKclufcAA11ef34OAGSgKXEfU_AJ_AJti1_J22SgV8U_SS_TG5Tf3nnnpf_nTf1cn_n;
    goto LABEL_182;
  }
LABEL_177:
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String : Any?]);
  if (OUTLINED_FUNCTION_22_11())
  {
    v275 = v376;
    OUTLINED_FUNCTION_14_11();
    v276 = &demangling cache variable for type metadata for Column<[String : Any?]>;
    v277 = (unint64_t *)&lazy protocol witness table cache variable for type Column<[String : Any?]> and conformance Column<A>;
    v278 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSDySSypSgG_8CreateML11MLDataValueO_AJtsAE_pTg5022_sSS3key_xSg5valuetSg8d4ML11fg5OAGs5c138_pIgnrrzo_SSAA_AbCtAG_AGtsAH_pIegnrzr_lTRyp_TG503_s8c39ML15MLUntypedColumnVyAC11TabularData0D0l20SDySSxSgGGKclufcAA11ef33OAHSgKXEfU_AK_AKtI31_AG5valuetsW8U_yp_Tg5Tf3nnnpf_nTf1cn_n;
    goto LABEL_182;
  }
LABEL_180:
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String : Any]);
  if (!OUTLINED_FUNCTION_22_11())
  {
LABEL_184:
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [AnyHashable : Any?]);
    if (OUTLINED_FUNCTION_22_11())
    {
      AnyColumn.assumingType<A>(_:)();
      uint64_t v106 = v375;
      lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<[AnyHashable : Any?]> and conformance Column<A>, &demangling cache variable for type metadata for Column<[AnyHashable : Any?]>);
      v398 = dispatch thunk of Collection.count.getter();
      if (v398)
      {
        v451 = MEMORY[0x263F8EE78];
        OUTLINED_FUNCTION_20_11();
        dispatch thunk of Collection.startIndex.getter();
        if ((v398 & 0x8000000000000000) == 0)
        {
          v400 = 0;
          while (v400 != v398)
          {
            v279 = (void (*)(uint64_t))dispatch thunk of Collection.subscript.read();
            v281 = *v280;
            swift_bridgeObjectRetain();
            v282 = OUTLINED_FUNCTION_5_20();
            v279(v282);
            v428 = v281;
            if (v281)
            {
              if (*(void *)(v281 + 16))
              {
                v283 = *(void *)(v281 + 16);
                v450 = MEMORY[0x263F8EE78];
                specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v283, 0);
                v284 = specialized Dictionary.startIndex.getter(v281);
                v416 = v285;
                if (v284 < 0 || (v286 = v284, v284 >= 1 << *(unsigned char *)(v281 + 32)))
                {
LABEL_275:
                  __break(1u);
                }
                else
                {
                  v420 = v281 + 64;
                  while ((*(void *)(v420 + 8 * (v286 >> 6)) & (1 << v286)) != 0)
                  {
                    if (*(_DWORD *)(v428 + 36) != v416) {
                      goto LABEL_277;
                    }
                    outlined init with copy of AnyHashable(*(void *)(v428 + 48) + 40 * v286, (uint64_t)&v443);
                    outlined init with copy of MLShapedArray<Int32>?(*(void *)(v428 + 56) + 32 * v286, (uint64_t)v445, &demangling cache variable for type metadata for Any?);
                    outlined init with copy of AnyHashable((uint64_t)&v443, (uint64_t)v442);
                    outlined init with copy of MLShapedArray<Int32>?((uint64_t)v445, (uint64_t)&v442[5], &demangling cache variable for type metadata for Any?);
                    memcpy(v441, v442, sizeof(v441));
                    outlined destroy of DefaultIndices<DataFrame.Rows>((uint64_t)&v443, &demangling cache variable for type metadata for (key: AnyHashable, value: Any?));
                    outlined init with copy of AnyHashable((uint64_t)v441, (uint64_t)v435);
                    outlined init with copy of MLShapedArray<Int32>?((uint64_t)&v441[40], (uint64_t)v437, &demangling cache variable for type metadata for Any?);
                    v438[0] = v435[0];
                    v438[1] = v435[1];
                    v439 = v436;
                    outlined init with take of Any?((uint64_t)v437, (uint64_t)&v440);
                    closure #1 in closure #10 in MLUntypedColumn.init(_:convertArraysToShapedArrays:)((uint64_t)v446, (uint64_t)v448, (uint64_t)v438);
                    if (v136)
                    {
                      outlined destroy of DefaultIndices<DataFrame.Rows>((uint64_t)v438, &demangling cache variable for type metadata for (key: AnyHashable, value: Any?)?);
                      outlined destroy of DefaultIndices<DataFrame.Rows>((uint64_t)v441, &demangling cache variable for type metadata for (key: AnyHashable, value: Any?));
                      swift_bridgeObjectRelease();
                      swift_release();
                      swift_release();
                      type metadata accessor for AnyColumn();
                      OUTLINED_FUNCTION_6_19();
                      OUTLINED_FUNCTION_25_0();
                      v306();
                      v307 = OUTLINED_FUNCTION_54_6();
                      return v308(v307);
                    }
                    outlined destroy of DefaultIndices<DataFrame.Rows>((uint64_t)v438, &demangling cache variable for type metadata for (key: AnyHashable, value: Any?)?);
                    outlined destroy of DefaultIndices<DataFrame.Rows>((uint64_t)v441, &demangling cache variable for type metadata for (key: AnyHashable, value: Any?));
                    v411 = v446[0];
                    v410 = v446[1];
                    v409 = v447;
                    v407 = v448[0];
                    v406 = v448[1];
                    v404 = v449;
                    v287 = v450;
                    if ((swift_isUniquelyReferenced_nonNull_native() & 1) == 0)
                    {
                      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, *(void *)(v287 + 16) + 1, 1);
                      v287 = v450;
                    }
                    v288 = *(char **)(v287 + 16);
                    specialized ContiguousArray._reserveCapacityAssumingUniqueBuffer(oldCount:)(v288);
                    v430[0] = v411;
                    v430[1] = v410;
                    v431 = v409;
                    v432 = v407;
                    v433 = v406;
                    v434 = v404;
                    specialized ContiguousArray._appendElementAssumeUniqueAndCapacity(_:newElement:)((uint64_t)v288, (uint64_t)v430);
                    MLBoostedTreeRegressor.ModelParameters.maxDepth.modify(v289);
                    if ((uint64_t)v286 >= -(-1 << *(unsigned char *)(v428 + 32))) {
                      goto LABEL_278;
                    }
                    if ((*(void *)(v420 + 8 * (v286 >> 6)) & (1 << v286)) == 0) {
                      goto LABEL_279;
                    }
                    if (*(_DWORD *)(v428 + 36) != v416) {
                      goto LABEL_280;
                    }
                    v290 = _HashTable.occupiedBucket(after:)();
                    if (!--v283)
                    {
                      v292 = v450;
                      goto LABEL_209;
                    }
                    v286 = v290;
                    if ((v290 & 0x8000000000000000) == 0)
                    {
                      v416 = *(_DWORD *)(v428 + 36);
                      if (v290 < 1 << *(unsigned char *)(v428 + 32)) {
                        continue;
                      }
                    }
                    goto LABEL_275;
                  }
                }
                __break(1u);
LABEL_277:
                __break(1u);
LABEL_278:
                __break(1u);
LABEL_279:
                __break(1u);
LABEL_280:
                __break(1u);
                break;
              }
              v292 = MEMORY[0x263F8EE78];
LABEL_209:
              if (*(void *)(v292 + 16))
              {
                __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _DictionaryStorage<MLDataValue, MLDataValue>);
                v293 = static _DictionaryStorage.allocate(capacity:)();
              }
              else
              {
                v293 = MEMORY[0x263F8EE80];
              }
              v443 = v293;
              v294 = swift_bridgeObjectRetain();
              specialized _NativeDictionary.merge<A>(_:isUnique:uniquingKeysWith:)(v294, 1, &v443);
              if (v136) {
                goto LABEL_287;
              }
              swift_bridgeObjectRelease();
              swift_bridgeObjectRelease();
              v417 = v443;
              v291 = 4;
            }
            else
            {
              v417 = 0;
              v291 = 6;
            }
            v421 = v291;
            unint64_t v98 = v451;
            if ((swift_isUniquelyReferenced_nonNull_native() & 1) == 0)
            {
              specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
              unint64_t v98 = v451;
            }
            v295 = *(void *)(v98 + 16);
            if (v295 >= *(void *)(v98 + 24) >> 1)
            {
              specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
              unint64_t v98 = v451;
            }
            *(void *)(v98 + 16) = v295 + 1;
            v296 = v98 + 24 * v295;
            *(void *)(v296 + 32) = v417;
            *(void *)(v296 + 40) = 0;
            *(unsigned char *)(v296 + 48) = v421;
            uint64_t v106 = v375;
            dispatch thunk of Collection.formIndex(after:)();
            if (++v400 == v398) {
              goto LABEL_232;
            }
          }
          __break(1u);
        }
        __break(1u);
        goto LABEL_283;
      }
      unint64_t v98 = MEMORY[0x263F8EE78];
LABEL_232:
      v309 = OUTLINED_FUNCTION_54_6();
      v311 = v310(v309);
      v443 = v98;
      MEMORY[0x270FA5388](v311);
      OUTLINED_FUNCTION_2_30();
      v312 = (void (*)(uint64_t *__return_ptr, uint64_t *))closure #1 in MLUntypedColumn.init<A>(_:)specialized partial apply;
    }
    else
    {
      type metadata accessor for MLMultiArray();
      if (!swift_dynamicCastMetatype())
      {
        if (swift_dynamicCastMetatype())
        {
          LOBYTE(v98) = (_BYTE)v366;
          OUTLINED_FUNCTION_77_3();
          lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<MLShapedArray<Float>> and conformance Column<A>, &demangling cache variable for type metadata for Column<MLShapedArray<Float>>);
          uint64_t v106 = v366;
          v315 = dispatch thunk of Collection.count.getter();
          v316 = MEMORY[0x263F8EE78];
          if (v315)
          {
            v317 = v315;
            v442[0] = MEMORY[0x263F8EE78];
            OUTLINED_FUNCTION_10_14();
            dispatch thunk of Collection.startIndex.getter();
            if (v317 < 0)
            {
LABEL_284:
              __break(1u);
              goto LABEL_285;
            }
            OUTLINED_FUNCTION_41_5(v386);
            do
            {
              OUTLINED_FUNCTION_36_7();
              v318 = dispatch thunk of Collection.subscript.read();
              v320 = OUTLINED_FUNCTION_76_2(v318, v319);
              outlined init with copy of MLShapedArray<Int32>?(v320, v367, &demangling cache variable for type metadata for MLShapedArray<Float>?);
              v321 = OUTLINED_FUNCTION_5_20();
              v366(v321);
              outlined init with copy of MLShapedArray<Int32>?(v367, v368, &demangling cache variable for type metadata for MLShapedArray<Float>?);
              v322 = OUTLINED_FUNCTION_133();
              if (__swift_getEnumTagSinglePayload(v322, v323, v392) == 1)
              {
                outlined destroy of DefaultIndices<DataFrame.Rows>(v368, &demangling cache variable for type metadata for MLShapedArray<Float>?);
              }
              else
              {
                OUTLINED_FUNCTION_73_0();
                OUTLINED_FUNCTION_56_8();
                v324();
                OUTLINED_FUNCTION_72_2();
                OUTLINED_FUNCTION_32_8();
                v325();
                lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type MLShapedArray<Float> and conformance MLShapedArray<A>, &demangling cache variable for type metadata for MLShapedArray<Float>);
                v326 = OUTLINED_FUNCTION_37_6();
                MLDataValue.MultiArrayType.init(_:)((MLMultiArray)v326);
                OUTLINED_FUNCTION_25_0();
                v327();
              }
              outlined destroy of DefaultIndices<DataFrame.Rows>(v367, &demangling cache variable for type metadata for MLShapedArray<Float>?);
              if ((OUTLINED_FUNCTION_65_3() & 1) == 0)
              {
                OUTLINED_FUNCTION_15_13();
                v316 = v442[0];
              }
              unint64_t v98 = *(void *)(v316 + 16);
              if (v98 >= *(void *)(v316 + 24) >> 1)
              {
                OUTLINED_FUNCTION_25_13();
                v316 = v442[0];
              }
              OUTLINED_FUNCTION_35_7();
              uint64_t v106 = v366;
              dispatch thunk of Collection.formIndex(after:)();
              --v317;
            }
            while (v317);
          }
        }
        else
        {
          if (!swift_dynamicCastMetatype())
          {
            if (!swift_dynamicCastMetatype())
            {
              static String._createEmpty(withInitialCapacity:)(25);
              swift_bridgeObjectRelease();
              v443 = 0xD000000000000016;
              v444 = 0x80000002272D7110;
              AnyColumn.wrappedElementType.getter();
              v361._uint64_t countAndFlagsBits = _typeName(_:qualified:)();
              String.append(_:)(v361);
              swift_bridgeObjectRelease();
              v362._uint64_t countAndFlagsBits = 46;
              v362._uint64_t object = (void *)0xE100000000000000;
              String.append(_:)(v362);
              lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
              v363 = OUTLINED_FUNCTION_85();
              *v364 = 0xD000000000000016;
              v364[1] = 0x80000002272D7110;
              OUTLINED_FUNCTION_2_3(v363, (uint64_t)v364);
LABEL_128:
              type metadata accessor for AnyColumn();
              OUTLINED_FUNCTION_6_19();
LABEL_129:
              OUTLINED_FUNCTION_25_0();
              return v248();
            }
            LOBYTE(v98) = (_BYTE)v372;
            OUTLINED_FUNCTION_77_3();
            lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<MLShapedArray<Int32>> and conformance Column<A>, &demangling cache variable for type metadata for Column<MLShapedArray<Int32>>);
            v343 = dispatch thunk of Collection.count.getter();
            uint64_t v106 = (void (*)(uint64_t))MEMORY[0x263F8EE78];
            if (v343)
            {
              v344 = v343;
              v442[0] = MEMORY[0x263F8EE78];
              OUTLINED_FUNCTION_10_14();
              dispatch thunk of Collection.startIndex.getter();
              if (v344 < 0) {
                goto LABEL_286;
              }
              do
              {
                OUTLINED_FUNCTION_36_7();
                v345 = dispatch thunk of Collection.subscript.read();
                v347 = OUTLINED_FUNCTION_76_2(v345, v346);
                outlined init with copy of MLShapedArray<Int32>?(v347, v373, &demangling cache variable for type metadata for MLShapedArray<Int32>?);
                v348 = OUTLINED_FUNCTION_5_20();
                v372(v348);
                outlined init with copy of MLShapedArray<Int32>?(v373, v374, &demangling cache variable for type metadata for MLShapedArray<Int32>?);
                v349 = OUTLINED_FUNCTION_133();
                if (__swift_getEnumTagSinglePayload(v349, v350, v396) == 1)
                {
                  outlined destroy of DefaultIndices<DataFrame.Rows>(v374, &demangling cache variable for type metadata for MLShapedArray<Int32>?);
                  v429 = 0;
                  v351 = 6;
                }
                else
                {
                  OUTLINED_FUNCTION_56_8();
                  v352();
                  OUTLINED_FUNCTION_73_0();
                  OUTLINED_FUNCTION_32_8();
                  v353();
                  lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type MLShapedArray<Int32> and conformance MLShapedArray<A>, &demangling cache variable for type metadata for MLShapedArray<Int32>);
                  v354 = OUTLINED_FUNCTION_37_6();
                  MLDataValue.MultiArrayType.init(_:)((MLMultiArray)v354);
                  v429 = v443;
                  OUTLINED_FUNCTION_72_2();
                  OUTLINED_FUNCTION_25_0();
                  v355();
                  v351 = 5;
                }
                outlined destroy of DefaultIndices<DataFrame.Rows>(v373, &demangling cache variable for type metadata for MLShapedArray<Int32>?);
                v356 = v442[0];
                if ((swift_isUniquelyReferenced_nonNull_native() & 1) == 0)
                {
                  OUTLINED_FUNCTION_15_13();
                  v356 = v442[0];
                }
                unint64_t v98 = *(void *)(v356 + 16);
                v357 = *(void *)(v356 + 24);
                if (v98 >= v357 >> 1)
                {
                  OUTLINED_FUNCTION_60_3(v357);
                  specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
                }
                v358 = specialized ContiguousArray._appendElementAssumeUniqueAndCapacity(_:newElement:)(v98, v429, 0, v351);
                MLBoostedTreeRegressor.ModelParameters.maxDepth.modify(v358);
                dispatch thunk of Collection.formIndex(after:)();
                --v344;
              }
              while (v344);
              uint64_t v106 = (void (*)(uint64_t))v442[0];
            }
            OUTLINED_FUNCTION_25_0();
            v360 = v359();
            v443 = (unint64_t)v106;
            MEMORY[0x270FA5388](v360);
            OUTLINED_FUNCTION_2_30();
            v312 = (void (*)(uint64_t *__return_ptr, uint64_t *))partial apply for specialized closure #1 in MLUntypedColumn.init<A>(_:);
            goto LABEL_273;
          }
          LOBYTE(v98) = (_BYTE)v369;
          OUTLINED_FUNCTION_77_3();
          lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<MLShapedArray<Double>> and conformance Column<A>, &demangling cache variable for type metadata for Column<MLShapedArray<Double>>);
          uint64_t v106 = v369;
          v330 = dispatch thunk of Collection.count.getter();
          v331 = MEMORY[0x263F8EE78];
          if (v330)
          {
            v332 = v330;
            v442[0] = MEMORY[0x263F8EE78];
            OUTLINED_FUNCTION_10_14();
            dispatch thunk of Collection.startIndex.getter();
            if (v332 < 0)
            {
LABEL_285:
              __break(1u);
LABEL_286:
              __break(1u);
LABEL_287:
              uint64_t result = swift_unexpectedError();
              __break(1u);
              return result;
            }
            OUTLINED_FUNCTION_41_5(v384);
            do
            {
              OUTLINED_FUNCTION_36_7();
              v333 = dispatch thunk of Collection.subscript.read();
              v335 = OUTLINED_FUNCTION_76_2(v333, v334);
              outlined init with copy of MLShapedArray<Int32>?(v335, v370, &demangling cache variable for type metadata for MLShapedArray<Double>?);
              v336 = OUTLINED_FUNCTION_5_20();
              v369(v336);
              outlined init with copy of MLShapedArray<Int32>?(v370, v371, &demangling cache variable for type metadata for MLShapedArray<Double>?);
              v337 = OUTLINED_FUNCTION_133();
              if (__swift_getEnumTagSinglePayload(v337, v338, v387) == 1)
              {
                outlined destroy of DefaultIndices<DataFrame.Rows>(v371, &demangling cache variable for type metadata for MLShapedArray<Double>?);
              }
              else
              {
                OUTLINED_FUNCTION_73_0();
                OUTLINED_FUNCTION_56_8();
                v339();
                OUTLINED_FUNCTION_72_2();
                OUTLINED_FUNCTION_32_8();
                v340();
                lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type MLShapedArray<Double> and conformance MLShapedArray<A>, &demangling cache variable for type metadata for MLShapedArray<Double>);
                v341 = OUTLINED_FUNCTION_37_6();
                MLDataValue.MultiArrayType.init(_:)((MLMultiArray)v341);
                OUTLINED_FUNCTION_25_0();
                v342();
              }
              outlined destroy of DefaultIndices<DataFrame.Rows>(v370, &demangling cache variable for type metadata for MLShapedArray<Double>?);
              if ((OUTLINED_FUNCTION_65_3() & 1) == 0)
              {
                OUTLINED_FUNCTION_15_13();
                v331 = v442[0];
              }
              unint64_t v98 = *(void *)(v331 + 16);
              if (v98 >= *(void *)(v331 + 24) >> 1)
              {
                OUTLINED_FUNCTION_25_13();
                v331 = v442[0];
              }
              OUTLINED_FUNCTION_35_7();
              uint64_t v106 = v369;
              dispatch thunk of Collection.formIndex(after:)();
              --v332;
            }
            while (v332);
          }
        }
        OUTLINED_FUNCTION_25_0();
        v328();
        OUTLINED_FUNCTION_30_8();
        MEMORY[0x270FA5388](v329);
        OUTLINED_FUNCTION_2_30();
        v312 = (void (*)(uint64_t *__return_ptr, uint64_t *))closure #1 in MLUntypedColumn.init<A>(_:)specialized partial apply;
        goto LABEL_273;
      }
      OUTLINED_FUNCTION_77_3();
      lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<MLMultiArray> and conformance Column<A>, &demangling cache variable for type metadata for Column<MLMultiArray>);
      uint64_t v106 = v378;
      v297 = dispatch thunk of Collection.count.getter();
      unint64_t v98 = MEMORY[0x263F8EE78];
      if (v297)
      {
        v298 = v297;
        v442[0] = MEMORY[0x263F8EE78];
        OUTLINED_FUNCTION_10_14();
        unint64_t v98 = v442[0];
        dispatch thunk of Collection.startIndex.getter();
        if (v298 < 0)
        {
LABEL_283:
          __break(1u);
          goto LABEL_284;
        }
        do
        {
          OUTLINED_FUNCTION_36_7();
          v299 = (void (*)(uint64_t))dispatch thunk of Collection.subscript.read();
          v301 = *v300;
          v302 = *v300;
          v303 = OUTLINED_FUNCTION_5_20();
          v299(v303);
          if (v301)
          {
            MLDataValue.MultiArrayType.init(_:)((MLMultiArray)v302);
            v422 = v443;
          }
          else
          {
            v422 = 0;
          }
          v442[0] = v98;
          v304 = *(void *)(v98 + 16);
          if (v304 >= *(void *)(v98 + 24) >> 1)
          {
            OUTLINED_FUNCTION_25_13();
            unint64_t v98 = v442[0];
          }
          *(void *)(v98 + 16) = v304 + 1;
          v305 = v98 + 24 * v304;
          *(void *)(v305 + 32) = v422;
          *(void *)(v305 + 40) = 0;
          OUTLINED_FUNCTION_40_5(v305);
          uint64_t v106 = v378;
          dispatch thunk of Collection.formIndex(after:)();
          --v298;
        }
        while (v298);
      }
      OUTLINED_FUNCTION_25_0();
      v314 = v313();
      v443 = v98;
      MEMORY[0x270FA5388](v314);
      OUTLINED_FUNCTION_2_30();
      v312 = (void (*)(uint64_t *__return_ptr, uint64_t *))closure #1 in MLUntypedColumn.init<A>(_:)specialized partial apply;
    }
LABEL_273:
    _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTgm5(v312);
    OUTLINED_FUNCTION_29_7();
    type metadata accessor for AnyColumn();
    OUTLINED_FUNCTION_6_19();
    goto LABEL_93;
  }
  v275 = v365;
  OUTLINED_FUNCTION_14_11();
  v276 = &demangling cache variable for type metadata for Column<[String : Any]>;
  v277 = (unint64_t *)&lazy protocol witness table cache variable for type Column<[String : Any]> and conformance Column<A>;
  v278 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSDySSypG_8CreateML11MLDataValueO_AItsAE_pTg5020_sSS3key_x5valuetSg8d4ML11fg5OAFs5c136_pIgnrrzo_SSAA_xABtAF_AFtsAG_pIegnrzr_lTRyp_TG503_s8c39ML15MLUntypedColumnVyAC11TabularData0D0l18SDySSxGGKclufcAA11ef34OAGSgKXEfU_AJ_AJti1_J22SgV8U_yp_Tg5Tf3nnnpf_nTf1cn_n;
LABEL_182:
  v273 = v136;
  specialized MLUntypedColumn.init<A>(_:)(v275, v276, v277, (uint64_t)closure #1 in MLUntypedColumn.init<A>(_:)specialized partial apply, v278, (uint64_t)&v443);
LABEL_161:
  if (v273) {
    goto LABEL_128;
  }
LABEL_162:
  type metadata accessor for AnyColumn();
  OUTLINED_FUNCTION_6_19();
  OUTLINED_FUNCTION_25_0();
  uint64_t result = v274();
  uint64_t v106 = (void (*)(uint64_t))v443;
  LOBYTE(v98) = v444;
LABEL_94:
  uint64_t v152 = a3;
LABEL_37:
  *(void *)uint64_t v152 = v106;
  *(unsigned char *)(v152 + 8) = v98;
  return result;
}

uint64_t specialized DataFrameProtocol.subscript.getter@<X0>(uint64_t a1@<X0>, uint64_t a2@<X8>)
{
  v13[1] = a2;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DefaultIndices<DataFrame.Rows>);
  uint64_t v4 = v3 - 8;
  MEMORY[0x270FA5388](v3);
  uint64_t v6 = (char *)v13 - ((v5 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v7 = type metadata accessor for DataFrame.Rows();
  uint64_t v8 = *(void *)(v7 - 8);
  MEMORY[0x270FA5388](v7);
  uint64_t v10 = (char *)v13 - ((v9 + 15) & 0xFFFFFFFFFFFFFFF0);
  type metadata accessor for DataFrame();
  dispatch thunk of DataFrameProtocol.rows.getter();
  (*(void (**)(char *, char *, uint64_t))(v8 + 16))(v6, v10, v7);
  lazy protocol witness table accessor for type DataFrame.Rows and conformance DataFrame.Rows();
  dispatch thunk of Collection.startIndex.getter();
  uint64_t v11 = &v6[*(int *)(v4 + 48)];
  dispatch thunk of Collection.endIndex.getter();
  uint64_t result = (*(uint64_t (**)(char *, uint64_t))(v8 + 8))(v10, v7);
  if (*(void *)v11 < a1)
  {
    __break(1u);
  }
  else
  {
    outlined destroy of DefaultIndices<DataFrame.Rows>((uint64_t)v6, &demangling cache variable for type metadata for DefaultIndices<DataFrame.Rows>);
    return dispatch thunk of DataFrameProtocol.subscript.getter();
  }
  return result;
}

unint64_t lazy protocol witness table accessor for type DataFrame.Rows and conformance DataFrame.Rows()
{
  unint64_t result = lazy protocol witness table cache variable for type DataFrame.Rows and conformance DataFrame.Rows;
  if (!lazy protocol witness table cache variable for type DataFrame.Rows and conformance DataFrame.Rows)
  {
    type metadata accessor for DataFrame.Rows();
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type DataFrame.Rows and conformance DataFrame.Rows);
  }
  return result;
}

uint64_t specialized MLUntypedColumn.init<A>(_:)@<X0>(uint64_t a1@<X0>, uint64_t a2@<X8>)
{
  uint64_t v3 = v2;
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Int]>);
  lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<[Int]> and conformance Column<A>, &demangling cache variable for type metadata for Column<[Int]>);
  uint64_t result = dispatch thunk of Collection.count.getter();
  uint64_t v30 = a2;
  if (result)
  {
    uint64_t v8 = result;
    uint64_t v39 = MEMORY[0x263F8EE78];
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
    uint64_t v9 = v39;
    uint64_t result = dispatch thunk of Collection.startIndex.getter();
    if (v8 < 0)
    {
LABEL_24:
      __break(1u);
      return result;
    }
    uint64_t v10 = 0;
    uint64_t v32 = v6;
    uint64_t v33 = a1;
    uint64_t v31 = v8;
    while (1)
    {
      if (v10 == v8)
      {
        __break(1u);
        goto LABEL_24;
      }
      uint64_t v34 = v9;
      uint64_t v11 = (void (*)(void *, void))dispatch thunk of Collection.subscript.read();
      uint64_t v13 = *v12;
      swift_bridgeObjectRetain();
      v11(v38, 0);
      if (v13)
      {
        uint64_t v14 = *(void *)(v13 + 16);
        if (v14)
        {
          uint64_t v37 = MEMORY[0x263F8EE78];
          specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
          uint64_t v15 = 0;
          uint64_t v16 = v37;
          while (1)
          {
            uint64_t v17 = *(void *)(v13 + 8 * v15 + 32);
            v38[3] = MEMORY[0x263F8D6C8];
            v38[0] = v17;
            MLDataValue.init(fromAny:)((uint64_t)v38, (uint64_t)&v35);
            if (v3) {
              break;
            }
            long long v18 = v35;
            char v19 = v36;
            uint64_t v37 = v16;
            unint64_t v20 = *(void *)(v16 + 16);
            if (v20 >= *(void *)(v16 + 24) >> 1)
            {
              long long v29 = v35;
              specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
              long long v18 = v29;
              uint64_t v16 = v37;
            }
            ++v15;
            *(void *)(v16 + 16) = v20 + 1;
            uint64_t v21 = v16 + 24 * v20;
            *(_OWORD *)(v21 + 32) = v18;
            *(unsigned char *)(v21 + 48) = v19;
            if (v14 == v15) {
              goto LABEL_15;
            }
          }
          swift_release();
          swift_bridgeObjectRelease();
          swift_release();
          return (*(uint64_t (**)(uint64_t))(*(void *)(v32 - 8) + 8))(v33);
        }
        uint64_t v16 = MEMORY[0x263F8EE78];
LABEL_15:
        specialized MLDataValue.SequenceType.init<A>(_:)(v38, v16);
        swift_bridgeObjectRelease();
        uint64_t v22 = v38[0];
        char v23 = 3;
      }
      else
      {
        uint64_t v22 = 0;
        char v23 = 6;
      }
      uint64_t v9 = v34;
      uint64_t v39 = v34;
      unint64_t v24 = *(void *)(v34 + 16);
      uint64_t v8 = v31;
      if (v24 >= *(void *)(v34 + 24) >> 1)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
        uint64_t v9 = v39;
      }
      ++v10;
      *(void *)(v9 + 16) = v24 + 1;
      uint64_t v25 = v9 + 24 * v24;
      *(void *)(v25 + 32) = v22;
      *(void *)(v25 + 40) = 0;
      *(unsigned char *)(v25 + 48) = v23;
      uint64_t v6 = v32;
      a1 = v33;
      uint64_t result = dispatch thunk of Collection.formIndex(after:)();
      if (v10 == v31) {
        goto LABEL_22;
      }
    }
  }
  uint64_t v9 = MEMORY[0x263F8EE78];
LABEL_22:
  v38[0] = v9;
  MEMORY[0x270FA5388](result);
  uint64_t ML14_UntypedColumnC_s5Error_pTgm5 = _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTgm5((void (*)(uint64_t *__return_ptr, uint64_t *))closure #1 in MLUntypedColumn.init<A>(_:)specialized partial apply);
  char v28 = v27;
  swift_bridgeObjectRelease();
  uint64_t result = (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v6 - 8) + 8))(a1, v6);
  *(void *)uint64_t v30 = ML14_UntypedColumnC_s5Error_pTgm5;
  *(unsigned char *)(v30 + 8) = v28 & 1;
  return result;
}

{
  uint64_t v2;
  uint64_t v3;
  uint64_t v6;
  uint64_t result;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void (*v11)(void *, void);
  uint64_t *v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  int v17;
  long long v18;
  char v19;
  unint64_t v20;
  uint64_t v21;
  uint64_t v22;
  char v23;
  unint64_t v24;
  uint64_t v25;
  uint64_t ML14_UntypedColumnC_s5Error_pTgm5;
  char v27;
  char v28;
  long long v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v34;
  long long v35;
  char v36;
  uint64_t v37;
  void v38[4];
  uint64_t v39;

  uint64_t v3 = v2;
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Float]>);
  lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<[Float]> and conformance Column<A>, &demangling cache variable for type metadata for Column<[Float]>);
  uint64_t result = dispatch thunk of Collection.count.getter();
  uint64_t v30 = a2;
  if (result)
  {
    uint64_t v8 = result;
    uint64_t v39 = MEMORY[0x263F8EE78];
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
    uint64_t v9 = v39;
    uint64_t result = dispatch thunk of Collection.startIndex.getter();
    if (v8 < 0)
    {
LABEL_24:
      __break(1u);
      return result;
    }
    uint64_t v10 = 0;
    uint64_t v32 = v6;
    uint64_t v33 = a1;
    uint64_t v31 = v8;
    while (1)
    {
      if (v10 == v8)
      {
        __break(1u);
        goto LABEL_24;
      }
      uint64_t v34 = v9;
      uint64_t v11 = (void (*)(void *, void))dispatch thunk of Collection.subscript.read();
      uint64_t v13 = *v12;
      swift_bridgeObjectRetain();
      v11(v38, 0);
      if (v13)
      {
        uint64_t v14 = *(void *)(v13 + 16);
        if (v14)
        {
          uint64_t v37 = MEMORY[0x263F8EE78];
          specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
          uint64_t v15 = 0;
          uint64_t v16 = v37;
          while (1)
          {
            uint64_t v17 = *(_DWORD *)(v13 + 4 * v15 + 32);
            v38[3] = MEMORY[0x263F8D5C8];
            LODWORD(v38[0]) = v17;
            MLDataValue.init(fromAny:)((uint64_t)v38, (uint64_t)&v35);
            if (v3) {
              break;
            }
            long long v18 = v35;
            char v19 = v36;
            uint64_t v37 = v16;
            unint64_t v20 = *(void *)(v16 + 16);
            if (v20 >= *(void *)(v16 + 24) >> 1)
            {
              long long v29 = v35;
              specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
              long long v18 = v29;
              uint64_t v16 = v37;
            }
            ++v15;
            *(void *)(v16 + 16) = v20 + 1;
            uint64_t v21 = v16 + 24 * v20;
            *(_OWORD *)(v21 + 32) = v18;
            *(unsigned char *)(v21 + 48) = v19;
            if (v14 == v15) {
              goto LABEL_15;
            }
          }
          swift_release();
          swift_bridgeObjectRelease();
          swift_release();
          return (*(uint64_t (**)(uint64_t))(*(void *)(v32 - 8) + 8))(v33);
        }
        uint64_t v16 = MEMORY[0x263F8EE78];
LABEL_15:
        specialized MLDataValue.SequenceType.init<A>(_:)(v38, v16);
        swift_bridgeObjectRelease();
        uint64_t v22 = v38[0];
        char v23 = 3;
      }
      else
      {
        uint64_t v22 = 0;
        char v23 = 6;
      }
      uint64_t v9 = v34;
      uint64_t v39 = v34;
      unint64_t v24 = *(void *)(v34 + 16);
      uint64_t v8 = v31;
      if (v24 >= *(void *)(v34 + 24) >> 1)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
        uint64_t v9 = v39;
      }
      ++v10;
      *(void *)(v9 + 16) = v24 + 1;
      uint64_t v25 = v9 + 24 * v24;
      *(void *)(v25 + 32) = v22;
      *(void *)(v25 + 40) = 0;
      *(unsigned char *)(v25 + 48) = v23;
      uint64_t v6 = v32;
      a1 = v33;
      uint64_t result = dispatch thunk of Collection.formIndex(after:)();
      if (v10 == v31) {
        goto LABEL_22;
      }
    }
  }
  uint64_t v9 = MEMORY[0x263F8EE78];
LABEL_22:
  v38[0] = v9;
  MEMORY[0x270FA5388](result);
  uint64_t ML14_UntypedColumnC_s5Error_pTgm5 = _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTgm5((void (*)(uint64_t *__return_ptr, uint64_t *))closure #1 in MLUntypedColumn.init<A>(_:)specialized partial apply);
  char v28 = v27;
  swift_bridgeObjectRelease();
  uint64_t result = (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v6 - 8) + 8))(a1, v6);
  *(void *)uint64_t v30 = ML14_UntypedColumnC_s5Error_pTgm5;
  *(unsigned char *)(v30 + 8) = v28 & 1;
  return result;
}

{
  uint64_t v2;
  uint64_t v3;
  uint64_t v6;
  uint64_t result;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void (*v11)(void *, void);
  uint64_t *v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  long long v18;
  char v19;
  unint64_t v20;
  uint64_t v21;
  uint64_t v22;
  char v23;
  unint64_t v24;
  uint64_t v25;
  uint64_t ML14_UntypedColumnC_s5Error_pTgm5;
  char v27;
  char v28;
  long long v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v34;
  long long v35;
  char v36;
  uint64_t v37;
  void v38[4];
  uint64_t v39;

  uint64_t v3 = v2;
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Double]>);
  lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<[Double]> and conformance Column<A>, &demangling cache variable for type metadata for Column<[Double]>);
  uint64_t result = dispatch thunk of Collection.count.getter();
  uint64_t v30 = a2;
  if (result)
  {
    uint64_t v8 = result;
    uint64_t v39 = MEMORY[0x263F8EE78];
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
    uint64_t v9 = v39;
    uint64_t result = dispatch thunk of Collection.startIndex.getter();
    if (v8 < 0)
    {
LABEL_24:
      __break(1u);
      return result;
    }
    uint64_t v10 = 0;
    uint64_t v32 = v6;
    uint64_t v33 = a1;
    uint64_t v31 = v8;
    while (1)
    {
      if (v10 == v8)
      {
        __break(1u);
        goto LABEL_24;
      }
      uint64_t v34 = v9;
      uint64_t v11 = (void (*)(void *, void))dispatch thunk of Collection.subscript.read();
      uint64_t v13 = *v12;
      swift_bridgeObjectRetain();
      v11(v38, 0);
      if (v13)
      {
        uint64_t v14 = *(void *)(v13 + 16);
        if (v14)
        {
          uint64_t v37 = MEMORY[0x263F8EE78];
          specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
          uint64_t v15 = 0;
          uint64_t v16 = v37;
          while (1)
          {
            uint64_t v17 = *(void *)(v13 + 8 * v15 + 32);
            v38[3] = MEMORY[0x263F8D538];
            v38[0] = v17;
            MLDataValue.init(fromAny:)((uint64_t)v38, (uint64_t)&v35);
            if (v3) {
              break;
            }
            long long v18 = v35;
            char v19 = v36;
            uint64_t v37 = v16;
            unint64_t v20 = *(void *)(v16 + 16);
            if (v20 >= *(void *)(v16 + 24) >> 1)
            {
              long long v29 = v35;
              specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
              long long v18 = v29;
              uint64_t v16 = v37;
            }
            ++v15;
            *(void *)(v16 + 16) = v20 + 1;
            uint64_t v21 = v16 + 24 * v20;
            *(_OWORD *)(v21 + 32) = v18;
            *(unsigned char *)(v21 + 48) = v19;
            if (v14 == v15) {
              goto LABEL_15;
            }
          }
          swift_release();
          swift_bridgeObjectRelease();
          swift_release();
          return (*(uint64_t (**)(uint64_t))(*(void *)(v32 - 8) + 8))(v33);
        }
        uint64_t v16 = MEMORY[0x263F8EE78];
LABEL_15:
        specialized MLDataValue.SequenceType.init<A>(_:)(v38, v16);
        swift_bridgeObjectRelease();
        uint64_t v22 = v38[0];
        char v23 = 3;
      }
      else
      {
        uint64_t v22 = 0;
        char v23 = 6;
      }
      uint64_t v9 = v34;
      uint64_t v39 = v34;
      unint64_t v24 = *(void *)(v34 + 16);
      uint64_t v8 = v31;
      if (v24 >= *(void *)(v34 + 24) >> 1)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
        uint64_t v9 = v39;
      }
      ++v10;
      *(void *)(v9 + 16) = v24 + 1;
      uint64_t v25 = v9 + 24 * v24;
      *(void *)(v25 + 32) = v22;
      *(void *)(v25 + 40) = 0;
      *(unsigned char *)(v25 + 48) = v23;
      uint64_t v6 = v32;
      a1 = v33;
      uint64_t result = dispatch thunk of Collection.formIndex(after:)();
      if (v10 == v31) {
        goto LABEL_22;
      }
    }
  }
  uint64_t v9 = MEMORY[0x263F8EE78];
LABEL_22:
  v38[0] = v9;
  MEMORY[0x270FA5388](result);
  uint64_t ML14_UntypedColumnC_s5Error_pTgm5 = _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTgm5((void (*)(uint64_t *__return_ptr, uint64_t *))closure #1 in MLUntypedColumn.init<A>(_:)specialized partial apply);
  char v28 = v27;
  swift_bridgeObjectRelease();
  uint64_t result = (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v6 - 8) + 8))(a1, v6);
  *(void *)uint64_t v30 = ML14_UntypedColumnC_s5Error_pTgm5;
  *(unsigned char *)(v30 + 8) = v28 & 1;
  return result;
}

{
  uint64_t v2;
  uint64_t v3;
  uint64_t v6;
  uint64_t result;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void (*v11)(void *, void);
  uint64_t *v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t *v16;
  uint64_t v17;
  uint64_t v18;
  long long v19;
  char v20;
  unint64_t v21;
  uint64_t v22;
  uint64_t v23;
  char v24;
  unint64_t v25;
  uint64_t v26;
  uint64_t ML14_UntypedColumnC_s5Error_pTgm5;
  char v28;
  char v29;
  long long v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v34;
  uint64_t v35;
  long long v36;
  char v37;
  uint64_t v38;
  void v39[4];
  uint64_t v40;

  uint64_t v3 = v2;
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[String]>);
  lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<[String]> and conformance Column<A>, &demangling cache variable for type metadata for Column<[String]>);
  uint64_t result = dispatch thunk of Collection.count.getter();
  uint64_t v31 = a2;
  if (result)
  {
    uint64_t v8 = result;
    uint64_t v40 = MEMORY[0x263F8EE78];
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
    uint64_t v9 = v40;
    uint64_t result = dispatch thunk of Collection.startIndex.getter();
    if (v8 < 0)
    {
LABEL_24:
      __break(1u);
      return result;
    }
    uint64_t v10 = 0;
    uint64_t v33 = v6;
    uint64_t v34 = a1;
    uint64_t v32 = v8;
    while (1)
    {
      if (v10 == v8)
      {
        __break(1u);
        goto LABEL_24;
      }
      long long v35 = v9;
      uint64_t v11 = (void (*)(void *, void))dispatch thunk of Collection.subscript.read();
      uint64_t v13 = *v12;
      swift_bridgeObjectRetain();
      v11(v39, 0);
      if (v13)
      {
        uint64_t v14 = *(void *)(v13 + 16);
        if (v14)
        {
          uint64_t v38 = MEMORY[0x263F8EE78];
          specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
          uint64_t v15 = v38;
          uint64_t v16 = (uint64_t *)(v13 + 40);
          while (1)
          {
            uint64_t v17 = *(v16 - 1);
            long long v18 = *v16;
            v39[3] = MEMORY[0x263F8D310];
            v39[0] = v17;
            v39[1] = v18;
            swift_bridgeObjectRetain_n();
            MLDataValue.init(fromAny:)((uint64_t)v39, (uint64_t)&v36);
            if (v3) {
              break;
            }
            swift_bridgeObjectRelease();
            char v19 = v36;
            unint64_t v20 = v37;
            uint64_t v38 = v15;
            uint64_t v21 = *(void *)(v15 + 16);
            if (v21 >= *(void *)(v15 + 24) >> 1)
            {
              uint64_t v30 = v36;
              specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
              char v19 = v30;
              uint64_t v15 = v38;
            }
            v16 += 2;
            *(void *)(v15 + 16) = v21 + 1;
            uint64_t v22 = v15 + 24 * v21;
            *(_OWORD *)(v22 + 32) = v19;
            *(unsigned char *)(v22 + 48) = v20;
            if (!--v14) {
              goto LABEL_15;
            }
          }
          swift_release();
          swift_bridgeObjectRelease();
          swift_release();
          swift_bridgeObjectRelease();
          return (*(uint64_t (**)(uint64_t))(*(void *)(v33 - 8) + 8))(v34);
        }
        uint64_t v15 = MEMORY[0x263F8EE78];
LABEL_15:
        specialized MLDataValue.SequenceType.init<A>(_:)(v39, v15);
        swift_bridgeObjectRelease();
        char v23 = v39[0];
        unint64_t v24 = 3;
      }
      else
      {
        char v23 = 0;
        unint64_t v24 = 6;
      }
      uint64_t v9 = v35;
      uint64_t v40 = v35;
      uint64_t v25 = *(void *)(v35 + 16);
      uint64_t v8 = v32;
      if (v25 >= *(void *)(v35 + 24) >> 1)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
        uint64_t v9 = v40;
      }
      ++v10;
      *(void *)(v9 + 16) = v25 + 1;
      uint64_t v26 = v9 + 24 * v25;
      *(void *)(v26 + 32) = v23;
      *(void *)(v26 + 40) = 0;
      *(unsigned char *)(v26 + 48) = v24;
      uint64_t v6 = v33;
      a1 = v34;
      uint64_t result = dispatch thunk of Collection.formIndex(after:)();
      if (v10 == v32) {
        goto LABEL_22;
      }
    }
  }
  uint64_t v9 = MEMORY[0x263F8EE78];
LABEL_22:
  v39[0] = v9;
  MEMORY[0x270FA5388](result);
  uint64_t ML14_UntypedColumnC_s5Error_pTgm5 = _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTgm5((void (*)(uint64_t *__return_ptr, uint64_t *))closure #1 in MLUntypedColumn.init<A>(_:)specialized partial apply);
  long long v29 = v28;
  swift_bridgeObjectRelease();
  uint64_t result = (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v6 - 8) + 8))(a1, v6);
  *(void *)uint64_t v31 = ML14_UntypedColumnC_s5Error_pTgm5;
  *(unsigned char *)(v31 + 8) = v29 & 1;
  return result;
}

uint64_t specialized MLUntypedColumn.init<A>(_:)@<X0>(uint64_t a1@<X0>, uint64_t *a2@<X1>, unint64_t *a3@<X2>, uint64_t a4@<X3>, void (*a5)(long long *__return_ptr, uint64_t)@<X4>, uint64_t a6@<X8>)
{
  void (*v26)(uint64_t *__return_ptr, uint64_t *);
  uint64_t ML14_UntypedColumnC_s5Error_pTgm5;
  char v28;
  char v29;
  uint64_t (*v30)(void);
  uint64_t v31;
  long long v32;
  void v36[4];
  long long v37;
  char v38;
  uint64_t v39;

  uint64_t v9 = v6;
  uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(a2);
  uint64_t v12 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(a3, a2);
  uint64_t v13 = dispatch thunk of Collection.count.getter();
  uint64_t v14 = MEMORY[0x263F8EE78];
  if (v13)
  {
    uint64_t v15 = v13;
    uint64_t v39 = MEMORY[0x263F8EE78];
    OUTLINED_FUNCTION_20_11();
    uint64_t v14 = v39;
    uint64_t result = dispatch thunk of Collection.startIndex.getter();
    if (v15 < 0)
    {
      __break(1u);
    }
    else
    {
      while (1)
      {
        uint64_t v17 = (void (*)(void *, void))dispatch thunk of Collection.subscript.read();
        uint64_t v19 = *v18;
        swift_bridgeObjectRetain();
        v17(v36, 0);
        a5(&v37, v19);
        if (v9) {
          break;
        }
        uint64_t v20 = v12;
        uint64_t v21 = a1;
        swift_bridgeObjectRelease();
        long long v22 = v37;
        char v23 = v38;
        uint64_t v39 = v14;
        unint64_t v24 = *(void *)(v14 + 16);
        if (v24 >= *(void *)(v14 + 24) >> 1)
        {
          uint64_t v32 = v37;
          specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
          long long v22 = v32;
          uint64_t v14 = v39;
        }
        *(void *)(v14 + 16) = v24 + 1;
        uint64_t v25 = v14 + 24 * v24;
        *(_OWORD *)(v25 + 32) = v22;
        *(unsigned char *)(v25 + 48) = v23;
        a1 = v21;
        uint64_t v12 = v20;
        dispatch thunk of Collection.formIndex(after:)();
        --v15;
        uint64_t v9 = 0;
        if (!v15) {
          goto LABEL_7;
        }
      }
      swift_release();
      swift_bridgeObjectRelease();
      OUTLINED_FUNCTION_17_12();
      return (*(uint64_t (**)(uint64_t, uint64_t))(v31 + 8))(a1, v11);
    }
  }
  else
  {
LABEL_7:
    v36[0] = v14;
    uint64_t v26 = (void (*)(uint64_t *__return_ptr, uint64_t *))MEMORY[0x270FA5388](a4);
    uint64_t ML14_UntypedColumnC_s5Error_pTgm5 = _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTgm5(v26);
    long long v29 = v28;
    swift_bridgeObjectRelease();
    OUTLINED_FUNCTION_17_12();
    OUTLINED_FUNCTION_25_0();
    uint64_t result = v30();
    *(void *)a6 = ML14_UntypedColumnC_s5Error_pTgm5;
    *(unsigned char *)(a6 + 8) = v29 & 1;
  }
  return result;
}

uint64_t specialized MLUntypedColumn.init<A>(_:)@<X0>(uint64_t a1@<X0>, uint64_t *a2@<X1>, unint64_t *a3@<X2>, uint64_t a4@<X3>, uint64_t (*a5)(uint64_t)@<X4>, uint64_t a6@<X8>)
{
  void (*v26)(uint64_t *__return_ptr, uint64_t *);
  uint64_t ML14_UntypedColumnC_s5Error_pTgm5;
  char v28;
  char v29;
  uint64_t (*v30)(void);
  uint64_t result;
  uint64_t v32;
  uint64_t v36;
  void v37[4];
  uint64_t v38;

  uint64_t v9 = v6;
  uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(a2);
  lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(a3, a2);
  uint64_t v12 = dispatch thunk of Collection.count.getter();
  uint64_t v13 = MEMORY[0x263F8EE78];
  if (!v12)
  {
LABEL_14:
    v37[0] = v13;
    uint64_t v26 = (void (*)(uint64_t *__return_ptr, uint64_t *))MEMORY[0x270FA5388](a4);
    uint64_t ML14_UntypedColumnC_s5Error_pTgm5 = _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTgm5(v26);
    long long v29 = v28;
    swift_bridgeObjectRelease();
    OUTLINED_FUNCTION_17_12();
    OUTLINED_FUNCTION_25_0();
    uint64_t result = v30();
    *(void *)a6 = ML14_UntypedColumnC_s5Error_pTgm5;
    *(unsigned char *)(a6 + 8) = v29 & 1;
    return result;
  }
  uint64_t v14 = v12;
  uint64_t v38 = MEMORY[0x263F8EE78];
  OUTLINED_FUNCTION_20_11();
  uint64_t v13 = v38;
  dispatch thunk of Collection.startIndex.getter();
  if ((v14 & 0x8000000000000000) == 0)
  {
    char v36 = a1;
    while (1)
    {
      uint64_t v15 = v11;
      uint64_t v16 = (void (*)(void *, void))dispatch thunk of Collection.subscript.read();
      uint64_t v18 = *v17;
      swift_bridgeObjectRetain();
      v16(v37, 0);
      if (v18)
      {
        uint64_t v19 = a5(v18);
        if (v9)
        {
          swift_release();
          swift_bridgeObjectRelease();
          OUTLINED_FUNCTION_17_12();
          return (*(uint64_t (**)(uint64_t, uint64_t))(v32 + 8))(a1, v11);
        }
        if (*(void *)(v19 + 16))
        {
          __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _DictionaryStorage<MLDataValue, MLDataValue>);
          uint64_t v20 = static _DictionaryStorage.allocate(capacity:)();
        }
        else
        {
          uint64_t v20 = MEMORY[0x263F8EE80];
        }
        v37[0] = v20;
        uint64_t v23 = swift_bridgeObjectRetain();
        specialized _NativeDictionary.merge<A>(_:isUnique:uniquingKeysWith:)(v23, 1, v37);
        swift_bridgeObjectRelease();
        swift_bridgeObjectRelease();
        uint64_t v21 = v37[0];
        char v22 = 4;
      }
      else
      {
        uint64_t v21 = 0;
        char v22 = 6;
      }
      uint64_t v38 = v13;
      unint64_t v24 = *(void *)(v13 + 16);
      if (v24 >= *(void *)(v13 + 24) >> 1)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
        uint64_t v13 = v38;
      }
      *(void *)(v13 + 16) = v24 + 1;
      uint64_t v25 = v13 + 24 * v24;
      *(void *)(v25 + 32) = v21;
      *(void *)(v25 + 40) = 0;
      *(unsigned char *)(v25 + 48) = v22;
      a1 = v36;
      uint64_t v11 = v15;
      dispatch thunk of Collection.formIndex(after:)();
      if (!--v14) {
        goto LABEL_14;
      }
    }
  }
  __break(1u);
  uint64_t result = swift_unexpectedError();
  __break(1u);
  return result;
}

uint64_t closure #1 in closure #10 in MLUntypedColumn.init(_:convertArraysToShapedArrays:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  outlined init with copy of MLShapedArray<Int32>?(a3, (uint64_t)&v11, &demangling cache variable for type metadata for (key: AnyHashable, value: Any?)?);
  if (!*((void *)&v12 + 1))
  {
    uint64_t result = outlined destroy of DefaultIndices<DataFrame.Rows>((uint64_t)&v11, &demangling cache variable for type metadata for (key: AnyHashable, value: Any?)?);
    *(void *)a1 = 0;
    *(void *)(a1 + 8) = 0;
    *(unsigned char *)(a1 + 16) = 6;
    *(void *)a2 = 0;
    *(void *)(a2 + 8) = 0;
LABEL_8:
    *(unsigned char *)(a2 + 16) = 6;
    return result;
  }
  v16[0] = v11;
  v16[1] = v12;
  uint64_t v17 = v13;
  outlined init with take of Any?((uint64_t)&v14, (uint64_t)v18);
  outlined init with copy of AnyHashable((uint64_t)v16, (uint64_t)&v11);
  outlined init with copy of MLShapedArray<Int32>?((uint64_t)v18, (uint64_t)&v14, &demangling cache variable for type metadata for Any?);
  if (!v15)
  {
    outlined destroy of DefaultIndices<DataFrame.Rows>((uint64_t)&v14, &demangling cache variable for type metadata for Any?);
    outlined destroy of AnyHashable((uint64_t)&v11);
    outlined init with copy of AnyHashable((uint64_t)v16, (uint64_t)&v11);
    outlined init with copy of MLShapedArray<Int32>?((uint64_t)v18, (uint64_t)&v14, &demangling cache variable for type metadata for Any?);
    AnyHashable.base.getter();
    outlined destroy of AnyHashable((uint64_t)&v11);
    MLDataValue.init(fromAny:)((uint64_t)v10, a1);
    outlined destroy of DefaultIndices<DataFrame.Rows>((uint64_t)v16, &demangling cache variable for type metadata for (key: AnyHashable, value: Any?));
    uint64_t result = outlined destroy of DefaultIndices<DataFrame.Rows>((uint64_t)&v14, &demangling cache variable for type metadata for Any?);
    if (v3) {
      return result;
    }
    *(void *)a2 = 0;
    *(void *)(a2 + 8) = 0;
    goto LABEL_8;
  }
  outlined init with take of Any(&v14, v10);
  outlined destroy of AnyHashable((uint64_t)&v11);
  outlined init with copy of AnyHashable((uint64_t)v16, (uint64_t)&v11);
  outlined init with copy of MLShapedArray<Int32>?((uint64_t)v18, (uint64_t)&v14, &demangling cache variable for type metadata for Any?);
  AnyHashable.base.getter();
  outlined destroy of AnyHashable((uint64_t)&v11);
  MLDataValue.init(fromAny:)((uint64_t)v9, a1);
  if (v3)
  {
    __swift_destroy_boxed_opaque_existential_0((uint64_t)v10);
    outlined destroy of DefaultIndices<DataFrame.Rows>((uint64_t)v16, &demangling cache variable for type metadata for (key: AnyHashable, value: Any?));
    uint64_t v6 = &demangling cache variable for type metadata for Any?;
    uint64_t v7 = &v14;
  }
  else
  {
    outlined destroy of DefaultIndices<DataFrame.Rows>((uint64_t)&v14, &demangling cache variable for type metadata for Any?);
    outlined init with copy of Any((uint64_t)v10, (uint64_t)&v11);
    MLDataValue.init(fromAny:)((uint64_t)&v11, a2);
    __swift_destroy_boxed_opaque_existential_0((uint64_t)v10);
    uint64_t v6 = &demangling cache variable for type metadata for (key: AnyHashable, value: Any?);
    uint64_t v7 = v16;
  }
  return outlined destroy of DefaultIndices<DataFrame.Rows>((uint64_t)v7, v6);
}

void *specialized closure #1 in MLUntypedColumn.init<A>(_:)@<X0>(void *result@<X0>, uint64_t a2@<X8>)
{
  if (result)
  {
    uint64_t v3 = result;
    uint64_t v4 = result[2];
    uint64_t v5 = MEMORY[0x263F8EE78];
    if (v4)
    {
      uint64_t v18 = MEMORY[0x263F8EE78];
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
      uint64_t v6 = (uint64_t)(v3 + 4);
      uint64_t v13 = MEMORY[0x263F8EE58] + 8;
      while (1)
      {
        outlined init with copy of Any(v6, (uint64_t)v15);
        void v14[3] = v13;
        v14[0] = swift_allocObject();
        outlined init with copy of Any((uint64_t)v15, v14[0] + 16);
        MLDataValue.init(fromAny:)((uint64_t)v14, (uint64_t)v16);
        __swift_destroy_boxed_opaque_existential_0((uint64_t)v15);
        if (v2) {
          return (void *)swift_release();
        }
        uint64_t v7 = v16[0];
        uint64_t v8 = v16[1];
        char v9 = v17;
        uint64_t v5 = v18;
        if ((swift_isUniquelyReferenced_nonNull_native() & 1) == 0)
        {
          specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
          uint64_t v5 = v18;
        }
        unint64_t v10 = *(void *)(v5 + 16);
        if (v10 >= *(void *)(v5 + 24) >> 1)
        {
          specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
          uint64_t v5 = v18;
        }
        *(void *)(v5 + 16) = v10 + 1;
        uint64_t v11 = v5 + 24 * v10;
        *(void *)(v11 + 32) = v7;
        *(void *)(v11 + 40) = v8;
        *(unsigned char *)(v11 + 48) = v9;
        v6 += 32;
        if (!--v4) {
          goto LABEL_10;
        }
      }
    }
    else
    {
LABEL_10:
      uint64_t result = specialized MLDataValue.SequenceType.init<A>(_:)(v15, v5);
      *(void *)a2 = v15[0];
      *(void *)(a2 + 8) = 0;
      *(unsigned char *)(a2 + 16) = 3;
    }
  }
  else
  {
    *(void *)a2 = 0;
    *(void *)(a2 + 8) = 0;
    *(unsigned char *)(a2 + 16) = 6;
  }
  return result;
}

{
  uint64_t v2;
  void *v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  char v9;
  unint64_t v10;
  uint64_t v11;
  uint64_t v13;
  long long v14;
  uint64_t v15;
  _OWORD v16[2];
  void v17[4];
  uint64_t v18;
  uint64_t v19;
  char v20;
  uint64_t v21;

  if (!result)
  {
    *(void *)a2 = 0;
    *(void *)(a2 + 8) = 0;
    *(unsigned char *)(a2 + 16) = 6;
    return result;
  }
  uint64_t v3 = result;
  uint64_t v4 = result[2];
  uint64_t v5 = MEMORY[0x263F8EE78];
  if (!v4)
  {
LABEL_13:
    uint64_t result = specialized MLDataValue.SequenceType.init<A>(_:)(v17, v5);
    *(void *)a2 = v17[0];
    *(void *)(a2 + 8) = 0;
    *(unsigned char *)(a2 + 16) = 3;
    return result;
  }
  uint64_t v21 = MEMORY[0x263F8EE78];
  specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
  uint64_t v6 = (uint64_t)(v3 + 4);
  uint64_t v13 = MEMORY[0x263F8EE58] + 8;
  while (1)
  {
    outlined init with copy of MLShapedArray<Int32>?(v6, (uint64_t)v17, &demangling cache variable for type metadata for Any?);
    outlined init with copy of MLShapedArray<Int32>?((uint64_t)v17, (uint64_t)&v14, &demangling cache variable for type metadata for Any?);
    if (!v15)
    {
      outlined destroy of DefaultIndices<DataFrame.Rows>((uint64_t)&v14, &demangling cache variable for type metadata for Any?);
      uint64_t v8 = 0;
      uint64_t v7 = 0;
      uint64_t v18 = 0;
      uint64_t v19 = 0;
      char v9 = 6;
      goto LABEL_8;
    }
    outlined init with take of Any(&v14, v16);
    uint64_t v15 = v13;
    *(void *)&long long v14 = swift_allocObject();
    outlined init with copy of Any((uint64_t)v16, v14 + 16);
    MLDataValue.init(fromAny:)((uint64_t)&v14, (uint64_t)&v18);
    __swift_destroy_boxed_opaque_existential_0((uint64_t)v16);
    if (v2) {
      break;
    }
    uint64_t v7 = v18;
    uint64_t v8 = v19;
    char v9 = v20;
LABEL_8:
    outlined destroy of DefaultIndices<DataFrame.Rows>((uint64_t)v17, &demangling cache variable for type metadata for Any?);
    uint64_t v5 = v21;
    if ((swift_isUniquelyReferenced_nonNull_native() & 1) == 0)
    {
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
      uint64_t v5 = v21;
    }
    unint64_t v10 = *(void *)(v5 + 16);
    if (v10 >= *(void *)(v5 + 24) >> 1)
    {
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
      uint64_t v5 = v21;
    }
    *(void *)(v5 + 16) = v10 + 1;
    uint64_t v11 = v5 + 24 * v10;
    *(void *)(v11 + 32) = v7;
    *(void *)(v11 + 40) = v8;
    *(unsigned char *)(v11 + 48) = v9;
    v6 += 32;
    if (!--v4) {
      goto LABEL_13;
    }
  }
  outlined destroy of DefaultIndices<DataFrame.Rows>((uint64_t)v17, &demangling cache variable for type metadata for Any?);
  return (void *)swift_release();
}

#error "2271197C8: call analysis failed (funcsize=150)"

uint64_t specialized closure #1 in closure #1 in MLUntypedColumn.init<A>(_:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  outlined init with copy of MLShapedArray<Int32>?(a3, (uint64_t)&v12, &demangling cache variable for type metadata for (key: String, value: Any?)?);
  uint64_t v6 = v13;
  if (v13)
  {
    uint64_t v7 = v12;
    v16[0] = v12;
    v16[1] = v13;
    outlined init with take of Any?((uint64_t)&v14, (uint64_t)v17);
    uint64_t v12 = v7;
    uint64_t v13 = v6;
    outlined init with copy of MLShapedArray<Int32>?((uint64_t)v17, (uint64_t)&v14, &demangling cache variable for type metadata for Any?);
    if (v15)
    {
      outlined init with take of Any(&v14, v11);
      uint64_t v12 = v7;
      uint64_t v13 = v6;
      outlined init with copy of MLShapedArray<Int32>?((uint64_t)v17, (uint64_t)&v14, &demangling cache variable for type metadata for Any?);
      *(void *)a1 = v7;
      *(void *)(a1 + 8) = v6;
      *(unsigned char *)(a1 + 16) = 2;
      v10[3] = MEMORY[0x263F8EE58] + 8;
      v10[0] = swift_allocObject();
      outlined init with copy of Any((uint64_t)v11, v10[0] + 16);
      swift_bridgeObjectRetain();
      MLDataValue.init(fromAny:)((uint64_t)v10, a2);
      if (v3) {
        swift_bridgeObjectRelease();
      }
      __swift_destroy_boxed_opaque_existential_0((uint64_t)v11);
      outlined destroy of DefaultIndices<DataFrame.Rows>((uint64_t)v16, &demangling cache variable for type metadata for (key: String, value: Any?));
    }
    else
    {
      swift_bridgeObjectRetain();
      outlined destroy of DefaultIndices<DataFrame.Rows>((uint64_t)&v14, &demangling cache variable for type metadata for Any?);
      uint64_t v12 = v7;
      uint64_t v13 = v6;
      outlined init with copy of MLShapedArray<Int32>?((uint64_t)v17, (uint64_t)&v14, &demangling cache variable for type metadata for Any?);
      outlined destroy of DefaultIndices<DataFrame.Rows>((uint64_t)v16, &demangling cache variable for type metadata for (key: String, value: Any?));
      uint64_t v9 = v13;
      *(void *)a1 = v12;
      *(void *)(a1 + 8) = v9;
      *(unsigned char *)(a1 + 16) = 2;
      *(void *)a2 = 0;
      *(void *)(a2 + 8) = 0;
      *(unsigned char *)(a2 + 16) = 6;
    }
    return outlined destroy of DefaultIndices<DataFrame.Rows>((uint64_t)&v14, &demangling cache variable for type metadata for Any?);
  }
  else
  {
    uint64_t result = outlined destroy of DefaultIndices<DataFrame.Rows>((uint64_t)&v12, &demangling cache variable for type metadata for (key: String, value: Any?)?);
    *(void *)a1 = 0;
    *(void *)(a1 + 8) = 0;
    *(unsigned char *)(a1 + 16) = 6;
    *(void *)a2 = 0;
    *(void *)(a2 + 8) = 0;
    *(unsigned char *)(a2 + 16) = 6;
  }
  return result;
}

char *specialized ContiguousArray._reserveCapacityAssumingUniqueBuffer(oldCount:)(char *result)
{
  unint64_t v2 = *(void *)(*(void *)v1 + 24);
  if ((uint64_t)(result + 1) > (uint64_t)(v2 >> 1)) {
    return specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)((char *)(v2 > 1), (int64_t)(result + 1), 1);
  }
  return result;
}

void specialized _NativeDictionary.merge<A>(_:isUnique:uniquingKeysWith:)(uint64_t a1, char a2, void *a3)
{
  uint64_t v4 = *(void *)(a1 + 16);
  swift_bridgeObjectRetain();
  if (!v4)
  {
LABEL_18:
    swift_bridgeObjectRelease_n();
    return;
  }
  unint64_t v5 = 0;
  uint64_t v6 = (char *)(a1 + 72);
  while (1)
  {
    if (v5 >= *(void *)(a1 + 16))
    {
      __break(1u);
LABEL_21:
      __break(1u);
LABEL_22:
      __break(1u);
LABEL_23:
      KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)();
      __break(1u);
      goto LABEL_24;
    }
    int v7 = *(v6 - 24);
    char v8 = *v6;
    unint64_t v10 = (void *)*((void *)v6 - 2);
    uint64_t v9 = (void *)*((void *)v6 - 1);
    uint64_t v11 = (void *)*((void *)v6 - 5);
    uint64_t v12 = (void *)*((void *)v6 - 4);
    outlined copy of MLDataValue(v11, v12, *(v6 - 24));
    outlined copy of MLDataValue(v10, v9, v8);
    if (v7 == 255) {
      goto LABEL_18;
    }
    uint64_t v32 = v10;
    uint64_t v33 = v9;
    char v34 = v8;
    uint64_t v13 = (void *)*a3;
    unint64_t v15 = specialized __RawDictionaryStorage.find<A>(_:)((uint64_t)v11, (unint64_t)v12, v7);
    uint64_t v16 = v13[2];
    BOOL v17 = (v14 & 1) == 0;
    if (__OFADD__(v16, v17)) {
      goto LABEL_21;
    }
    char v18 = v14;
    if (v13[3] < v16 + v17) {
      break;
    }
    if (a2)
    {
      if (v14) {
        goto LABEL_16;
      }
    }
    else
    {
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<MLDataValue, MLDataValue>);
      _NativeDictionary.copy()();
      if (v18) {
        goto LABEL_16;
      }
    }
LABEL_12:
    uint64_t v21 = (void *)*a3;
    *(void *)(*a3 + 8 * (v15 >> 6) + 64) |= 1 << v15;
    uint64_t v22 = v21[6] + 24 * v15;
    *(void *)uint64_t v22 = v11;
    *(void *)(v22 + 8) = v12;
    *(unsigned char *)(v22 + 16) = v7;
    uint64_t v23 = v21[7] + 24 * v15;
    *(void *)uint64_t v23 = v32;
    *(void *)(v23 + 8) = v33;
    *(unsigned char *)(v23 + 16) = v34;
    uint64_t v24 = v21[2];
    BOOL v25 = __OFADD__(v24, 1);
    uint64_t v26 = v24 + 1;
    if (v25) {
      goto LABEL_22;
    }
    ++v5;
    v21[2] = v26;
    v6 += 48;
    a2 = 1;
    if (v4 == v5) {
      goto LABEL_18;
    }
  }
  specialized _NativeDictionary._copyOrMoveAndResize(capacity:moveElements:)();
  unint64_t v19 = specialized __RawDictionaryStorage.find<A>(_:)((uint64_t)v11, (unint64_t)v12, v7);
  if ((v18 & 1) != (v20 & 1)) {
    goto LABEL_23;
  }
  unint64_t v15 = v19;
  if ((v18 & 1) == 0) {
    goto LABEL_12;
  }
LABEL_16:
  char v27 = (void *)OUTLINED_FUNCTION_85();
  swift_willThrow();
  id v28 = v27;
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
  if ((swift_dynamicCast() & 1) == 0)
  {
    swift_bridgeObjectRelease();
    outlined consume of MLDataValue(v32, v33, v34);
    outlined consume of MLDataValue(v11, v12, v7);
    swift_bridgeObjectRelease();

    return;
  }
LABEL_24:
  _StringGuts.grow(_:)(30);
  v29._uint64_t object = (void *)0x80000002272D7190;
  v29._uint64_t countAndFlagsBits = 0xD00000000000001BLL;
  String.append(_:)(v29);
  _print_unlocked<A, B>(_:_:)();
  v30._uint64_t countAndFlagsBits = 39;
  v30._uint64_t object = (void *)0xE100000000000000;
  String.append(_:)(v30);
  _assertionFailure(_:_:file:line:flags:)();
  __break(1u);
}

uint64_t sub_22711A0C8()
{
  __swift_destroy_boxed_opaque_existential_0(v0 + 16);

  return MEMORY[0x270FA0238](v0, 48, 7);
}

uint64_t outlined destroy of DefaultIndices<DataFrame.Rows>(uint64_t a1, uint64_t *a2)
{
  __swift_instantiateConcreteTypeFromMangledName(a2);
  OUTLINED_FUNCTION_6_19();
  OUTLINED_FUNCTION_25_0();
  v3();
  return a1;
}

uint64_t outlined init with copy of MLShapedArray<Int32>?(uint64_t a1, uint64_t a2, uint64_t *a3)
{
  __swift_instantiateConcreteTypeFromMangledName(a3);
  OUTLINED_FUNCTION_17_12();
  (*(void (**)(uint64_t, uint64_t))(v5 + 16))(a2, a1);
  return a2;
}

void OUTLINED_FUNCTION_3_30(void *a1)
{
  a1[2] = v2;
  outlined consume of Result<_DataTable, Error>(v1, 0);
  outlined copy of Result<_DataTable, Error>(a1, 0);
  _UntypedColumn.type.getter((unsigned char *)(v3 - 112));
}

void OUTLINED_FUNCTION_4_25(uint64_t a1, uint64_t a2)
{
  *(void *)a2 = v2;
  *(void *)(a2 + 8) = v3;
  *(_OWORD *)(a2 + 16) = 0u;
  *(_OWORD *)(a2 + 32) = 0u;
  *(unsigned char *)(a2 + 48) = 1;
  uint64_t v6 = *(void **)(v4 - 296);
  int v7 = *(_DWORD *)(v4 - 172);
  outlined consume of Result<_DataTable, Error>(v6, v7);
}

uint64_t OUTLINED_FUNCTION_5_20()
{
  return v0 - 232;
}

uint64_t OUTLINED_FUNCTION_8_17()
{
  outlined copy of Result<_DataTable, Error>(v0, 0);
  outlined copy of Result<_DataTable, Error>(v0, 0);
  return swift_retain();
}

void OUTLINED_FUNCTION_10_14()
{
  specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
}

uint64_t OUTLINED_FUNCTION_11_13()
{
  outlined copy of Result<_DataTable, Error>(v0, 1);
  outlined copy of Result<_DataTable, Error>(v0, 1);
  return swift_willThrow();
}

uint64_t OUTLINED_FUNCTION_12_11()
{
  outlined consume of Result<_DataTable, Error>(v0, 0);
  outlined copy of Result<_DataTable, Error>(v1, 0);
  return CMLColumn.size.getter();
}

void OUTLINED_FUNCTION_13_15()
{
  outlined consume of Result<_DataTable, Error>(v1, v0);
  uint64_t v3 = *(void **)(v2 - 296);
  int v4 = *(_DWORD *)(v2 - 172);
  outlined consume of Result<_DataTable, Error>(v3, v4);
}

uint64_t OUTLINED_FUNCTION_14_11()
{
  return AnyColumn.assumingType<A>(_:)();
}

void OUTLINED_FUNCTION_15_13()
{
  specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
}

void OUTLINED_FUNCTION_16_13(uint64_t a1@<X8>)
{
  *(void *)(v4 - 112) = a1;
  *(void *)(v4 - 104) = (v1 - 32) | 0x8000000000000000;
  uint64_t v6 = v2;
  uint64_t v7 = v3;
  String.append(_:)(*(Swift::String *)&v6);
}

uint64_t OUTLINED_FUNCTION_19_12()
{
  return 0;
}

void OUTLINED_FUNCTION_20_11()
{
  specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
}

void OUTLINED_FUNCTION_21_12()
{
  *(void *)(v0 - 112) = 0;
  *(void *)(v0 - 104) = 0xE000000000000000;
  _StringGuts.grow(_:)(34);
}

uint64_t OUTLINED_FUNCTION_22_11()
{
  return swift_dynamicCastMetatype();
}

void OUTLINED_FUNCTION_24_10()
{
  outlined consume of Result<_DataTable, Error>(v0, 0);
}

void OUTLINED_FUNCTION_25_13()
{
  specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
}

void OUTLINED_FUNCTION_26_8()
{
  outlined consume of Result<_DataTable, Error>(v0, 0);
}

void *OUTLINED_FUNCTION_27_8(void *(*a1)(uint64_t *__return_ptr, void *))
{
  return specialized String.withCString<A>(_:)(a1, v1, v2, v3);
}

uint64_t OUTLINED_FUNCTION_29_7()
{
  return swift_bridgeObjectRelease();
}

void OUTLINED_FUNCTION_30_8()
{
  *(void *)(v1 - 232) = v0;
}

uint64_t OUTLINED_FUNCTION_31_6()
{
  return Column.init<A>(name:contents:)();
}

uint64_t OUTLINED_FUNCTION_34_7()
{
  return v0 - 232;
}

uint64_t OUTLINED_FUNCTION_35_7()
{
  *(void *)(v3 + 16) = v2;
  uint64_t v4 = v3 + 24 * v1;
  *(void *)(v4 + 32) = *(void *)(v0 + 656);
  *(void *)(v4 + 40) = 0;
  *(unsigned char *)(v4 + 48) = *(_DWORD *)(v0 + 648);
  return v0 + 856;
}

uint64_t OUTLINED_FUNCTION_36_7()
{
  return v0 - 232;
}

uint64_t OUTLINED_FUNCTION_37_6()
{
  return MLMultiArray.init<A>(_:)();
}

uint64_t OUTLINED_FUNCTION_40_5@<X0>(uint64_t a1@<X8>)
{
  *(unsigned char *)(a1 + 48) = v1;
  return v2 + 856;
}

void OUTLINED_FUNCTION_41_5(uint64_t a1@<X8>)
{
  v1[76] = a1 + 32;
  v1[74] = a1 + 16;
  v1[73] = a1 + 8;
}

id OUTLINED_FUNCTION_42_6()
{
  return outlined copy of Result<_DataTable, Error>(v0, 0);
}

uint64_t OUTLINED_FUNCTION_44_4()
{
  return swift_release();
}

void OUTLINED_FUNCTION_46_6()
{
  *(_DWORD *)(v0 - 172) = 0;
}

void OUTLINED_FUNCTION_47_6()
{
  uint64_t v1 = 34;
  unint64_t v2 = 0xE100000000000000;
  String.append(_:)(*(Swift::String *)&v1);
}

uint64_t OUTLINED_FUNCTION_48_5()
{
  return DataFrame.append<A>(column:)();
}

__n128 *OUTLINED_FUNCTION_49_1(__n128 *result, __n128 a2)
{
  result[1] = a2;
  result[2].n128_u64[0] = *(void *)(v2 + 16);
  return result;
}

void OUTLINED_FUNCTION_50_5()
{
  *(void *)(v1 - 232) = v0;
}

void OUTLINED_FUNCTION_51_6()
{
  *(void *)(v1 - 232) = v0;
}

uint64_t OUTLINED_FUNCTION_53_8()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_54_6()
{
  return *(void *)(v0 + 168);
}

uint64_t OUTLINED_FUNCTION_55_7()
{
  return swift_allocObject();
}

uint64_t OUTLINED_FUNCTION_57_7()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_58_3()
{
  return swift_dynamicCastMetatype();
}

BOOL OUTLINED_FUNCTION_60_3@<W0>(unint64_t a1@<X8>)
{
  return a1 > 1;
}

BOOL OUTLINED_FUNCTION_61_5@<W0>(unint64_t a1@<X8>)
{
  return a1 > 1;
}

void OUTLINED_FUNCTION_62_3()
{
  specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
}

BOOL OUTLINED_FUNCTION_63_4@<W0>(unint64_t a1@<X8>)
{
  return a1 > 1;
}

uint64_t OUTLINED_FUNCTION_64_3()
{
  return swift_bridgeObjectRetain();
}

uint64_t OUTLINED_FUNCTION_65_3()
{
  return swift_isUniquelyReferenced_nonNull_native();
}

uint64_t OUTLINED_FUNCTION_67_3()
{
  *(void *)(v0 + 552) = v1;
  return AnyColumn.assumingType<A>(_:)();
}

uint64_t OUTLINED_FUNCTION_70_3()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_71_3()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_74_1()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_76_2(uint64_t a1, uint64_t a2)
{
  return a2;
}

uint64_t OUTLINED_FUNCTION_77_3()
{
  return AnyColumn.assumingType<A>(_:)();
}

uint64_t OUTLINED_FUNCTION_79_3()
{
  return v0 - 232;
}

uint64_t OUTLINED_FUNCTION_80_3()
{
  return v0 - 232;
}

uint64_t OUTLINED_FUNCTION_81_3()
{
  return dispatch thunk of Collection.startIndex.getter();
}

uint64_t MLDataColumn.dropDuplicates()(uint64_t a1)
{
  return MLDataColumn.dropDuplicates()(a1, specialized handling<A, B>(_:_:));
}

uint64_t Array<A>.init(_:)()
{
  OUTLINED_FUNCTION_17_12();
  uint64_t v1 = MEMORY[0x270FA5388](v0);
  uint64_t v3 = (char *)&v11 - ((v2 + 15) & 0xFFFFFFFFFFFFFFF0);
  id v4 = *(id *)v1;
  if (*(unsigned char *)(v1 + 8))
  {
    outlined consume of Result<_DataTable, Error>(*(id *)v1, 1);
    OUTLINED_FUNCTION_24_11();
    return static Array._allocateUninitialized(_:)();
  }
  uint64_t v5 = Array.init()();
  uint64_t v14 = v5;
  id v12 = v4;
  char v13 = 0;
  OUTLINED_FUNCTION_24_11();
  uint64_t v6 = type metadata accessor for MLDataColumn();
  uint64_t result = MLDataColumn.count.getter();
  if ((result & 0x8000000000000000) == 0)
  {
    uint64_t v8 = result;
    if (result)
    {
      uint64_t v9 = 0;
      do
      {
        uint64_t v10 = v9 + 1;
        id v12 = v4;
        char v13 = 0;
        MLDataColumn.subscript.getter(v9, v6, (uint64_t)v3);
        OUTLINED_FUNCTION_24_11();
        type metadata accessor for Array();
        Array.append(_:)();
        uint64_t v9 = v10;
      }
      while (v8 != v10);
      outlined consume of Result<_DataTable, Error>(v4, 0);
      return v14;
    }
    else
    {
      outlined consume of Result<_DataTable, Error>(v4, 0);
    }
    return v5;
  }
  __break(1u);
  return result;
}

uint64_t MLDataColumn.dropMissing()(uint64_t a1)
{
  return MLDataColumn.dropDuplicates()(a1, specialized handling<A, B>(_:_:));
}

uint64_t MLDataColumn.count.getter()
{
  if (*(unsigned char *)(v0 + 8)) {
    return -1;
  }
  id v2 = *(id *)v0;
  outlined copy of Result<_DataTable, Error>(*(id *)v0, 0);
  uint64_t v3 = CMLColumn.size.getter();
  outlined consume of Result<_DataTable, Error>(v2, 0);
  return v3;
}

void MLDataColumn.init(repeating:count:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  OUTLINED_FUNCTION_0_15();
  uint64_t v10 = v9;
  MEMORY[0x270FA5388](v11);
  char v13 = OUTLINED_FUNCTION_2_31(v12, v15);
  v14(v13);
  MLUntypedColumn.init<A>(repeating:count:)(v4, a2, a3, a4, (uint64_t)&v15);
  (*(void (**)(uint64_t, uint64_t))(v10 + 8))(a1, a3);
  OUTLINED_FUNCTION_10_15();
}

uint64_t MLDataColumn.init(from:)@<X0>(uint64_t result@<X0>, uint64_t a2@<X8>)
{
  char v2 = *(unsigned char *)(result + 8);
  *(void *)a2 = *(void *)result;
  *(unsigned char *)(a2 + 8) = v2;
  return result;
}

uint64_t MLDataColumn.element(at:)(uint64_t a1, uint64_t a2)
{
  if (*(unsigned char *)(v2 + 8))
  {
    long long v4 = 0uLL;
    char v5 = 6;
  }
  else
  {
    outlined copy of Result<_DataTable, Error>(*(id *)v2, 0);
    _UntypedColumn.valueAtIndex(index:)(a1, (uint64_t)&v8);
    OUTLINED_FUNCTION_26_9();
    long long v4 = v8;
    char v5 = v9;
  }
  long long v8 = v4;
  char v9 = v5;
  return (*(uint64_t (**)(long long *))(*(void *)(a2 + 24) + 16))(&v8);
}

void MLDataColumn.init<A>(column:type:)(uint64_t a1@<X0>, uint64_t a2@<X8>)
{
  uint64_t v3 = *(void **)a1;
  char v4 = *(unsigned char *)(a1 + 8);
  MLDataColumn.map<A>(to:)();
  outlined consume of Result<_DataTable, Error>(v3, v4);
  *(void *)a2 = v5;
  *(unsigned char *)(a2 + 8) = v6;
}

void MLDataColumn.map<A>(to:)()
{
  OUTLINED_FUNCTION_14_12();
  MLUntypedColumn.map<A>(to:)(v0, v1, v2);
}

BOOL MLDataColumn.isEmpty.getter()
{
  return MLDataColumn.count.getter() < 1;
}

id MLDataColumn.error.getter()
{
  if (*(unsigned char *)(v0 + 8) != 1) {
    return 0;
  }
  id v1 = *(id *)v0;
  outlined copy of Result<_DataTable, Error>(*(id *)v0, 1);
  return v1;
}

BOOL MLDataColumn.isValid.getter()
{
  return (*(unsigned char *)(v0 + 8) & 1) == 0;
}

void MLDataColumn.init<A>(_:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  OUTLINED_FUNCTION_0_15();
  uint64_t v6 = v5;
  MEMORY[0x270FA5388](v7);
  char v9 = OUTLINED_FUNCTION_2_31(v8, v11);
  v10(v9);
  MLUntypedColumn.init<A>(_:)();
  (*(void (**)(uint64_t, uint64_t))(v6 + 8))(a1, a3);
  OUTLINED_FUNCTION_10_15();
}

uint64_t MLDataColumn.init(repeating:count:)@<X0>(long long *a1@<X0>, uint64_t a2@<X1>, uint64_t a3@<X8>)
{
  char v5 = *((unsigned char *)a1 + 16);
  long long v7 = *a1;
  char v8 = v5;
  type metadata accessor for _UntypedColumn();
  OUTLINED_FUNCTION_70();
  uint64_t result = _UntypedColumn.init(repeating:count:)((uint64_t)&v7, a2);
  *(void *)a3 = result;
  *(unsigned char *)(a3 + 8) = 0;
  return result;
}

double MLDataColumn.init()@<D0>(uint64_t a1@<X8>)
{
  lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  uint64_t v2 = swift_allocError();
  *(void *)uint64_t v3 = 0xD00000000000001DLL;
  *(void *)(v3 + 8) = 0x80000002272D7200;
  double result = 0.0;
  *(_OWORD *)(v3 + 16) = 0u;
  *(_OWORD *)(v3 + 32) = 0u;
  *(unsigned char *)(v3 + 48) = 1;
  *(void *)a1 = v2;
  *(unsigned char *)(a1 + 8) = 1;
  return result;
}

void MLDataColumn.append(contentsOf:)()
{
  OUTLINED_FUNCTION_29_8();
  uint64_t v2 = v0;
  uint64_t v3 = *v0;
  if ((_BYTE)v2[1])
  {
    char v4 = 1;
  }
  else
  {
    id v5 = *(id *)v1;
    if (*(unsigned char *)(v1 + 8))
    {
      char v4 = 1;
      outlined copy of Result<_DataTable, Error>(*(id *)v1, 1);
      OUTLINED_FUNCTION_26_9();
      uint64_t v3 = v5;
    }
    else
    {
      outlined copy of Result<_DataTable, Error>(*(id *)v1, 0);
      outlined copy of Result<_DataTable, Error>(v3, 0);
      uint64_t v6 = _UntypedColumn.appending(contentsOf:)((uint64_t)v5);
      outlined consume of Result<_DataTable, Error>(v5, 0);
      OUTLINED_FUNCTION_26_9();
      OUTLINED_FUNCTION_26_9();
      uint64_t v3 = (void *)v6;
      char v4 = 0;
    }
  }
  *uint64_t v2 = v3;
  *((unsigned char *)v2 + 8) = v4;
  OUTLINED_FUNCTION_28_8();
}

void MLDataColumn.subscript.getter()
{
  OUTLINED_FUNCTION_1_25();
  OUTLINED_FUNCTION_6_16(v0, v1, v2, v3, v4, v5, v6, v7, v8, v9, v10, v11, v12, v13);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  char v13;

  OUTLINED_FUNCTION_1_25();
  OUTLINED_FUNCTION_6_16(v0, v1, v2, v3, v4, v5, v6, v7, v8, v9, v10, v11, v12, v13);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  char v13;

  OUTLINED_FUNCTION_25_14();
  MLUntypedColumn.subscript.getter(v0, v1, (uint64_t)&v12);
  OUTLINED_FUNCTION_20_12(v2, v3, v4, v5, v6, v7, v8, v9, v10, v11, v12, v13);
}

{
  if (MLDataColumn.count.getter() < 0)
  {
    __break(1u);
  }
  else
  {
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Range<Int>);
    lazy protocol witness table accessor for type Range<Int> and conformance <> Range<A>();
    dispatch thunk of RangeExpression.relative<A>(to:)();
    MLDataColumn.subscript.getter();
  }
}

uint64_t MLDataColumn.map<A>(skipUndefined:_:)@<X0>(uint64_t a1@<X1>, uint64_t a2@<X2>, uint64_t a3@<X3>, uint64_t a4@<X4>, uint64_t a5@<X5>, uint64_t a6@<X8>)
{
  char v13 = *(void **)v6;
  char v14 = *(unsigned char *)(v6 + 8);
  uint64_t v15 = (void *)swift_allocObject();
  uint64_t v16 = *(void *)(a3 + 16);
  uint64_t v17 = *(void *)(a3 + 24);
  v15[2] = v16;
  v15[3] = a4;
  void v15[4] = v17;
  v15[5] = a5;
  v15[6] = a1;
  v15[7] = a2;
  if (v14)
  {
    uint64_t v23 = (uint64_t)v13;
    outlined copy of Result<_DataTable, Error>(v13, 1);
    swift_retain();
    outlined copy of Result<_DataTable, Error>(v13, 1);
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    uint64_t v18 = _getErrorEmbeddedNSError<A>(_:)();
    if (v18)
    {
      uint64_t v19 = v18;
      outlined consume of Result<_DataTable, Error>(v13, 1);
    }
    else
    {
      uint64_t v19 = swift_allocError();
      *uint64_t v21 = v23;
    }
    char v22 = 1;
    outlined consume of Result<_DataTable, Error>(v13, 1);
    uint64_t result = swift_release();
  }
  else
  {
    swift_retain();
    outlined copy of Result<_DataTable, Error>(v13, 0);
    closure #2 in MLDataColumn.map<A>(skipUndefined:_:)((uint64_t)partial apply for closure #1 in MLDataColumn.map<A>(skipUndefined:_:), (uint64_t)v15, a4, a5, &v23);
    outlined consume of Result<_DataTable, Error>(v13, 0);
    uint64_t result = swift_release();
    char v22 = 0;
    uint64_t v19 = v23;
  }
  *(void *)a6 = v19;
  *(unsigned char *)(a6 + 8) = v22;
  return result;
}

uint64_t closure #1 in MLDataColumn.map<A>(skipUndefined:_:)(uint64_t a1, void (*a2)(char *), uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  uint64_t v25 = a7;
  uint64_t v26 = a3;
  uint64_t v23 = a6;
  char v27 = a2;
  uint64_t v24 = type metadata accessor for Optional();
  uint64_t v9 = *(void *)(v24 - 8);
  uint64_t v10 = MEMORY[0x270FA5388](v24);
  uint64_t v12 = (char *)&v22 - v11;
  uint64_t v13 = *(void *)(a5 - 8);
  MEMORY[0x270FA5388](v10);
  uint64_t v15 = (char *)&v22 - ((v14 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v16 = type metadata accessor for Optional();
  uint64_t v17 = *(void *)(v16 - 8);
  MEMORY[0x270FA5388](v16);
  uint64_t v19 = (char *)&v22 - v18;
  if (CMLFeatureValue.isUndefined.getter()) {
    __swift_storeEnumTagSinglePayload((uint64_t)v19, 1, 1, a4);
  }
  else {
    static MLDataValueConvertible.makeInstance(featureValue:)(a4, v23, (uint64_t)v19);
  }
  v27(v19);
  if (__swift_getEnumTagSinglePayload((uint64_t)v12, 1, a5) == 1)
  {
    (*(void (**)(char *, uint64_t))(v9 + 8))(v12, v24);
    type metadata accessor for CMLFeatureValue();
    uint64_t v20 = CMLFeatureValue.__allocating_init()();
  }
  else
  {
    (*(void (**)(char *, char *, uint64_t))(v13 + 32))(v15, v12, a5);
    uint64_t v20 = MLDataValueConvertible.featureValue.getter(a5, v25);
    (*(void (**)(char *, uint64_t))(v13 + 8))(v15, a5);
  }
  (*(void (**)(char *, uint64_t))(v17 + 8))(v19, v16);
  return v20;
}

uint64_t closure #2 in MLDataColumn.map<A>(skipUndefined:_:)@<X0>(uint64_t a1@<X1>, uint64_t a2@<X2>, uint64_t a3@<X4>, uint64_t a4@<X6>, uint64_t *a5@<X8>)
{
  (*(void (**)(uint64_t *__return_ptr, uint64_t, uint64_t))(a4 + 8))(&v9, a3, a4);
  uint64_t result = _UntypedColumn.map(_:skipUndefined:outputType:)(a1, a2, 0, &v9);
  *a5 = result;
  return result;
}

uint64_t MLDataColumn.map<A>(_:)@<X0>(uint64_t a1@<X0>, uint64_t a2@<X1>, uint64_t a3@<X2>, uint64_t a4@<X3>, uint64_t a5@<X4>, uint64_t a6@<X8>)
{
  return MLDataColumn.map<A>(_:)(a1, a2, a3, a4, a5, (uint64_t)partial apply for closure #1 in MLDataColumn.map<A>(_:), a6);
}

{
  return MLDataColumn.map<A>(_:)(a1, a2, a3, a4, a5, (uint64_t)partial apply for closure #1 in MLDataColumn.map<A>(_:), a6);
}

uint64_t closure #1 in MLDataColumn.map<A>(_:)(uint64_t a1, void (*a2)(char *), uint64_t a3, uint64_t a4)
{
  uint64_t v7 = type metadata accessor for Optional();
  MEMORY[0x270FA5388](v7);
  uint64_t v9 = (char *)&v12 - v8;
  (*(void (**)(char *, uint64_t))(v10 + 16))((char *)&v12 - v8, a1);
  uint64_t result = __swift_getEnumTagSinglePayload((uint64_t)v9, 1, a4);
  if (result == 1)
  {
    __break(1u);
  }
  else
  {
    a2(v9);
    return (*(uint64_t (**)(char *, uint64_t))(*(void *)(a4 - 8) + 8))(v9, a4);
  }
  return result;
}

uint64_t MLDataColumn.map<A>(_:)@<X0>(uint64_t a1@<X0>, uint64_t a2@<X1>, uint64_t a3@<X2>, uint64_t a4@<X3>, uint64_t a5@<X4>, uint64_t a6@<X6>, uint64_t a7@<X8>)
{
  OUTLINED_FUNCTION_25_14();
  uint64_t v14 = (void *)swift_allocObject();
  uint64_t v15 = *(void *)(a3 + 24);
  v14[2] = *(void *)(a3 + 16);
  void v14[3] = a4;
  void v14[4] = v15;
  v14[5] = a5;
  v14[6] = a1;
  v14[7] = a2;
  swift_retain();
  MLDataColumn.map<A>(skipUndefined:_:)(a6, (uint64_t)v14, a3, a4, a5, a7);

  return swift_release();
}

uint64_t closure #1 in MLDataColumn.map<A>(_:)@<X0>(uint64_t a1@<X0>, void (*a2)(char *)@<X1>, uint64_t a3@<X3>, uint64_t a4@<X4>, uint64_t a5@<X8>)
{
  uint64_t v10 = type metadata accessor for Optional();
  MEMORY[0x270FA5388](v10);
  uint64_t v12 = (char *)&v15 - v11;
  (*(void (**)(char *, uint64_t))(v13 + 16))((char *)&v15 - v11, a1);
  uint64_t result = __swift_getEnumTagSinglePayload((uint64_t)v12, 1, a3);
  if (result == 1)
  {
    __break(1u);
  }
  else
  {
    a2(v12);
    (*(void (**)(char *, uint64_t))(*(void *)(a3 - 8) + 8))(v12, a3);
    return __swift_storeEnumTagSinglePayload(a5, 0, 1, a4);
  }
  return result;
}

uint64_t MLDataColumn.mapMissing<A>(_:)()
{
  OUTLINED_FUNCTION_14_12();
  return MLDataColumn.map<A>(skipUndefined:_:)(v0, v1, v2, v3, v4, v5);
}

void MLDataColumn.fillMissing(with:)()
{
  OUTLINED_FUNCTION_17_13();
  if (v2)
  {
    uint64_t v7 = v0;
    id v3 = v0;
    OUTLINED_FUNCTION_23_4();
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    if (_getErrorEmbeddedNSError<A>(_:)())
    {
      OUTLINED_FUNCTION_4_26();
    }
    else
    {
      OUTLINED_FUNCTION_5_21();
      *uint64_t v5 = v7;
    }
    OUTLINED_FUNCTION_4_26();
  }
  else
  {
    uint64_t v4 = v1;
    uint64_t v6 = v0;
    outlined copy of Result<_DataTable, Error>(v0, 0);
    closure #1 in MLDataColumn.fillMissing(with:)((uint64_t *)&v6, *(void *)(v4 + 16), *(void *)(v4 + 24), (uint64_t *)&v7);
    OUTLINED_FUNCTION_12_12();
  }
  OUTLINED_FUNCTION_19_13();
}

uint64_t closure #1 in MLDataColumn.fillMissing(with:)@<X0>(uint64_t *a1@<X0>, uint64_t a2@<X2>, uint64_t a3@<X3>, uint64_t *a4@<X8>)
{
  uint64_t v6 = *a1;
  uint64_t v7 = MLDataValueConvertible.featureValue.getter(a2, a3);
  uint64_t result = specialized handling<A, B, C>(_:_:_:)(*(void *)(*(void *)(v6 + 16) + 16), *(void *)(v7 + 16));
  if (v4) {
    return swift_release();
  }
  uint64_t v9 = result;
  if (result)
  {
    type metadata accessor for CMLColumn();
    uint64_t v10 = swift_allocObject();
    *(void *)(v10 + 16) = v9;
    type metadata accessor for _UntypedColumn();
    uint64_t v11 = swift_allocObject();
    *(void *)(v11 + 16) = v10;
    uint64_t result = swift_release();
    *a4 = v11;
  }
  else
  {
    __break(1u);
  }
  return result;
}

uint64_t MLDataColumn.prefix(_:)(uint64_t a1, uint64_t a2)
{
  return MLDataColumn.prefix(_:)(a1, a2, specialized handling<A, B, C>(_:_:_:));
}

uint64_t MLDataColumn.suffix(_:)(uint64_t a1, uint64_t a2)
{
  return MLDataColumn.prefix(_:)(a1, a2, specialized handling<A, B, C>(_:_:_:));
}

#error "22711BB6C: call analysis failed (funcsize=82)"

#error "22711BC40: call analysis failed (funcsize=62)"

uint64_t MLDataColumn.copy()(uint64_t a1)
{
  return MLDataColumn.dropDuplicates()(a1, specialized handling<A, B>(_:_:));
}

#error "22711BD7C: call analysis failed (funcsize=62)"

void MLDataColumn.materialize()(uint64_t a1@<X8>)
{
  id v3 = *(id *)v1;
  if (*(unsigned char *)(v1 + 8))
  {
    outlined copy of Result<_DataTable, Error>(*(id *)v1, 1);
    swift_willThrow();
  }
  else
  {
    outlined copy of Result<_DataTable, Error>(v3, 0);
    CMLColumn.materialize()();
    outlined consume of Result<_DataTable, Error>(v3, 0);
    if (!v4)
    {
      *(void *)a1 = v3;
      *(unsigned char *)(a1 + 8) = 0;
      outlined copy of Result<_DataTable, Error>(v3, 0);
    }
  }
}

uint64_t MLDataColumn.subscript.getter@<X0>(uint64_t a1@<X0>, uint64_t a2@<X1>, uint64_t a3@<X8>)
{
  uint64_t v7 = *(void *)(a2 + 16);
  OUTLINED_FUNCTION_24_11();
  uint64_t v8 = type metadata accessor for Optional();
  OUTLINED_FUNCTION_0_15();
  uint64_t v10 = v9;
  MEMORY[0x270FA5388](v11);
  uint64_t v13 = (char *)&v17 - v12;
  char v14 = *((unsigned char *)v3 + 8);
  uint64_t v17 = *v3;
  char v18 = v14;
  MLDataColumn.element(at:)(a1, a2);
  if (__swift_getEnumTagSinglePayload((uint64_t)v13, 1, v7) == 1)
  {
    (*(void (**)(uint64_t))(*(void *)(a2 + 24) + 24))(v7);
    return (*(uint64_t (**)(char *, uint64_t))(v10 + 8))(v13, v8);
  }
  else
  {
    OUTLINED_FUNCTION_17_12();
    return (*(uint64_t (**)(uint64_t, char *, uint64_t))(v16 + 32))(a3, v13, v7);
  }
}

void MLDataColumn<>.init<A>(column:)(uint64_t a1)
{
}

{
  MLDataColumn<>.init<A>(column:)(a1);
}

{
  MLDataColumn<>.init<A>(column:)(a1);
}

{
  MLDataColumn<>.init<A>(column:)(a1);
}

{
  MLDataColumn<>.init<A>(column:)(a1);
}

{
  char v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  char v13;

  uint64_t v1 = *(unsigned char *)(a1 + 8);
  uint64_t v10 = *(void *)a1;
  LOBYTE(v11) = v1;
  MLDataColumn.init<A>(column:type:)((uint64_t)&v10, (uint64_t)&v12);
  OUTLINED_FUNCTION_20_12(v2, v3, v4, v5, v6, v7, v8, v9, v10, v11, v12, v13);
}

void MLDataColumn<>.sum()()
{
  OUTLINED_FUNCTION_29_8();
  if ((*(unsigned char *)(v0 + 8) & 1) == 0)
  {
    id v1 = *(id *)v0;
    outlined copy of Result<_DataTable, Error>(*(id *)v0, 0);
    CMLColumn.sum()();
    uint64_t v3 = v2;
    if (CMLFeatureValue.isInt64.getter())
    {
      specialized handling<A, B>(_:_:)(*(void *)(v3 + 16));
      swift_release();
      OUTLINED_FUNCTION_26_8();
    }
    else
    {
      outlined consume of Result<_DataTable, Error>(v1, 0);
      swift_release();
    }
  }
  OUTLINED_FUNCTION_28_8();
}

void MLDataColumn<>.min()()
{
}

{
  void *v0;
  uint64_t v1;
  void *v2;
  uint64_t (*v3)(id);
  id v4;
  uint64_t v5;
  uint64_t v6;

  OUTLINED_FUNCTION_29_8();
  if ((*(unsigned char *)(v1 + 8) & 1) == 0)
  {
    uint64_t v4 = OUTLINED_FUNCTION_8_18();
    uint64_t v5 = v3(v4);
    if (v2)
    {

      OUTLINED_FUNCTION_21_13();
    }
    else
    {
      uint64_t v6 = v5;
      if (CMLFeatureValue.isInt64.getter())
      {
        specialized handling<A, B>(_:_:)(*(void *)(v6 + 16));
        swift_release();
        outlined consume of Result<_DataTable, Error>(v0, 0);
      }
      else
      {
        OUTLINED_FUNCTION_21_13();
        swift_release();
      }
    }
  }
  OUTLINED_FUNCTION_28_8();
}

void MLDataColumn<>.max()()
{
}

uint64_t MLDataColumn<>.std()()
{
  return MLDataColumn<>.std()((void (*)(id))CMLColumn.stdev());
}

{
  return MLDataColumn<>.std()((void (*)(id))CMLColumn.stdev());
}

uint64_t MLDataColumn<>.mean()()
{
  return MLDataColumn<>.std()((void (*)(id))CMLColumn.mean());
}

{
  return MLDataColumn<>.std()((void (*)(id))CMLColumn.mean());
}

uint64_t MLDataColumn<>.sum()()
{
  return MLDataColumn<>.std()((void (*)(id))CMLColumn.sum());
}

uint64_t MLDataColumn<>.min()()
{
  return MLDataColumn<>.min()();
}

{
  void *v0;
  uint64_t v1;
  void *v2;
  void (*v3)(id);
  id v4;
  uint64_t v5;
  uint64_t v6;

  if ((*(unsigned char *)(v1 + 8) & 1) == 0)
  {
    uint64_t v4 = OUTLINED_FUNCTION_8_18();
    v3(v4);
    if (v2)
    {

      OUTLINED_FUNCTION_21_13();
    }
    else
    {
      if (CMLFeatureValue.isDouble.getter())
      {
        specialized handling<A, B>(_:_:)();
        uint64_t v6 = v5;
        swift_release();
        outlined consume of Result<_DataTable, Error>(v0, 0);
        return v6;
      }
      outlined consume of Result<_DataTable, Error>(v0, 0);
      swift_release();
    }
  }
  return 0;
}

uint64_t MLDataColumn<>.max()()
{
  return MLDataColumn<>.min()();
}

uint64_t MLDataColumn<>.std()(void (*a1)(id))
{
  uint64_t result = 0;
  if ((*(unsigned char *)(v1 + 8) & 1) == 0)
  {
    id v4 = outlined copy of Result<_DataTable, Error>(*(id *)v1, 0);
    a1(v4);
    if (CMLFeatureValue.isDouble.getter())
    {
      specialized handling<A, B>(_:_:)();
      uint64_t v6 = v5;
      swift_release();
      OUTLINED_FUNCTION_12_12();
      return v6;
    }
    else
    {
      OUTLINED_FUNCTION_12_12();
      swift_release();
      return 0;
    }
  }
  return result;
}

uint64_t MLDataColumn<>.stdev()()
{
  uint64_t result = 0;
  if ((*(unsigned char *)(v0 + 8) & 1) == 0)
  {
    id v2 = *(id *)v0;
    outlined copy of Result<_DataTable, Error>(*(id *)v0, 0);
    CMLColumn.stdev()();
    if (CMLFeatureValue.isDouble.getter())
    {
      specialized handling<A, B>(_:_:)();
      uint64_t v4 = v3;
      swift_release();
      OUTLINED_FUNCTION_26_8();
      return v4;
    }
    else
    {
      outlined consume of Result<_DataTable, Error>(v2, 0);
      swift_release();
      return 0;
    }
  }
  return result;
}

void MLDataColumn<>.init<A>(column:)(uint64_t *a1@<X0>, uint64_t a2@<X8>)
{
}

{
  MLDataColumn<>.init<A>(column:)(a1, &demangling cache variable for type metadata for [Double], &lazy protocol witness table cache variable for type [Double] and conformance <A> [A], a2);
}

{
  MLDataColumn<>.init<A>(column:)(a1, &demangling cache variable for type metadata for [String], (unint64_t *)&lazy protocol witness table cache variable for type [String] and conformance <A> [A], a2);
}

void MLDataColumn<>.init<A>(column:)(uint64_t *a1@<X0>, uint64_t *a2@<X3>, unint64_t *a3@<X4>, uint64_t a4@<X8>)
{
  char v7 = *((unsigned char *)a1 + 8);
  uint64_t v9 = *a1;
  char v10 = v7;
  __swift_instantiateConcreteTypeFromMangledName(a2);
  lazy protocol witness table accessor for type [String] and conformance <A> [A](a3, a2);
  MLDataColumn.init<A>(column:type:)((uint64_t)&v9, (uint64_t)&v11);
  char v8 = v12;
  *(void *)a4 = v11;
  *(unsigned char *)(a4 + 8) = v8;
}

uint64_t MLDataColumn.customMirror.getter(uint64_t a1)
{
  uint64_t v4 = type metadata accessor for Mirror.AncestorRepresentation();
  OUTLINED_FUNCTION_0_15();
  uint64_t v6 = v5;
  MEMORY[0x270FA5388](v7);
  OUTLINED_FUNCTION_41_0();
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Mirror.DisplayStyle?);
  MEMORY[0x270FA5388](v8 - 8);
  char v10 = (char *)&v21 - ((v9 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v11 = *v1;
  char v12 = *((unsigned char *)v1 + 8);
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, Any)>);
  uint64_t v13 = swift_allocObject();
  *(_OWORD *)(v13 + 16) = xmmword_2272CB4D0;
  *(void *)(v13 + 32) = 0x746E756F63;
  *(void *)(v13 + 40) = 0xE500000000000000;
  uint64_t v21 = v11;
  char v22 = v12;
  uint64_t v14 = MLDataColumn.count.getter();
  uint64_t v15 = MEMORY[0x263F8D6C8];
  *(void *)(v13 + 48) = v14;
  *(void *)(v13 + 72) = v15;
  *(void *)(v13 + 80) = 1701869940;
  *(void *)(v13 + 88) = 0xE400000000000000;
  uint64_t v16 = *(void *)(a1 + 16);
  *(void *)(v13 + 120) = swift_getMetatypeMetadata();
  *(void *)(v13 + 96) = v16;
  uint64_t v21 = a1;
  uint64_t v17 = *MEMORY[0x263F8E7F0];
  uint64_t v18 = type metadata accessor for Mirror.DisplayStyle();
  OUTLINED_FUNCTION_17_12();
  (*(void (**)(char *, uint64_t, uint64_t))(v19 + 104))(v10, v17, v18);
  __swift_storeEnumTagSinglePayload((uint64_t)v10, 0, 1, v18);
  (*(void (**)(uint64_t, void, uint64_t))(v6 + 104))(v2, *MEMORY[0x263F8E828], v4);
  swift_getMetatypeMetadata();
  return Mirror.init<A>(_:children:displayStyle:ancestorRepresentation:)();
}

uint64_t MLDataColumn.description.getter()
{
  OUTLINED_FUNCTION_17_12();
  MEMORY[0x270FA5388](v1);
  OUTLINED_FUNCTION_41_0();
  uint64_t v2 = *(void **)v0;
  if (*(unsigned char *)(v0 + 8))
  {
    uint64_t v16 = 0;
    unint64_t v17 = 0xE000000000000000;
    uint64_t v14 = (uint64_t)v2;
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    _print_unlocked<A, B>(_:_:)();
    return v16;
  }
  uint64_t v16 = 91;
  unint64_t v17 = 0xE100000000000000;
  uint64_t v14 = (uint64_t)v2;
  LOBYTE(v15) = 0;
  outlined copy of Result<_DataTable, Error>(v2, 0);
  uint64_t result = MLDataColumn.count.getter();
  if (result >= 10) {
    uint64_t v4 = 10;
  }
  else {
    uint64_t v4 = result;
  }
  if ((v4 & 0x8000000000000000) == 0)
  {
    uint64_t v13 = result;
    if (v4)
    {
      for (uint64_t i = 0; i != v4; ++i)
      {
        if (i)
        {
          v6._uint64_t countAndFlagsBits = 8236;
          v6._uint64_t object = (void *)0xE200000000000000;
          String.append(_:)(v6);
        }
        _UntypedColumn.type.getter(&v14);
        if (v14 == 2)
        {
          OUTLINED_FUNCTION_9_16();
          v7._uint64_t countAndFlagsBits = String.init<A>(describing:)();
          uint64_t v14 = 34;
          unint64_t v15 = 0xE100000000000000;
          String.append(_:)(v7);
          swift_bridgeObjectRelease();
          swift_bridgeObjectRetain();
          v8._uint64_t countAndFlagsBits = 34;
          v8._uint64_t object = (void *)0xE100000000000000;
          String.append(_:)(v8);
          swift_bridgeObjectRelease();
          uint64_t v9 = v14;
          unint64_t v10 = v15;
        }
        else
        {
          OUTLINED_FUNCTION_9_16();
          uint64_t v9 = String.init<A>(describing:)();
        }
        String.append(_:)(*(Swift::String *)&v9);
        swift_bridgeObjectRelease();
      }
    }
    if (v13 >= 11)
    {
      v11._uint64_t countAndFlagsBits = 0x2E2E2E202CLL;
      v11._uint64_t object = (void *)0xE500000000000000;
      String.append(_:)(v11);
    }
    v12._uint64_t countAndFlagsBits = 93;
    v12._uint64_t object = (void *)0xE100000000000000;
    String.append(_:)(v12);
    OUTLINED_FUNCTION_21_13();
    return v16;
  }
  __break(1u);
  return result;
}

uint64_t MLDataColumn.debugDescription.getter()
{
  return OUTLINED_FUNCTION_13_16();
}

unint64_t MLDataColumn.playgroundDescription.getter@<X0>(void *a1@<X8>)
{
  uint64_t v2 = OUTLINED_FUNCTION_13_16();
  uint64_t v4 = v3;
  id v5 = objc_allocWithZone(MEMORY[0x263F086A0]);
  id v6 = @nonobjc NSAttributedString.init(string:attributes:)(v2, v4, 0);
  unint64_t result = type metadata accessor for NSAttributedString();
  a1[3] = result;
  *a1 = v6;
  return result;
}

uint64_t type metadata accessor for MLDataColumn()
{
  return __swift_instantiateGenericMetadata();
}

uint64_t sub_22711CC38()
{
  swift_release();

  return MEMORY[0x270FA0238](v0, 64, 7);
}

uint64_t partial apply for closure #1 in MLDataColumn.map<A>(_:)(uint64_t a1)
{
  return partial apply for closure #1 in MLDataColumn.map<A>(_:)(a1, (uint64_t (*)(uint64_t, void, void, void, void, void, void))closure #1 in MLDataColumn.map<A>(_:));
}

{
  return partial apply for closure #1 in MLDataColumn.map<A>(_:)(a1, (uint64_t (*)(uint64_t, void, void, void, void, void, void))closure #1 in MLDataColumn.map<A>(_:));
}

uint64_t partial apply for closure #1 in MLDataColumn.map<A>(_:)(uint64_t a1, uint64_t (*a2)(uint64_t, void, void, void, void, void, void))
{
  return a2(a1, v2[6], v2[7], v2[2], v2[3], v2[4], v2[5]);
}

uint64_t type metadata instantiation function for MLDataColumn(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return MEMORY[0x270FA01A8](a1, a2, a3, 24);
}

uint64_t partial apply for closure #1 in MLDataColumn.map<A>(skipUndefined:_:)(uint64_t a1)
{
  return closure #1 in MLDataColumn.map<A>(skipUndefined:_:)(a1, *(void (**)(char *))(v1 + 48), *(void *)(v1 + 56), *(void *)(v1 + 16), *(void *)(v1 + 24), *(void *)(v1 + 32), *(void *)(v1 + 40));
}

void OUTLINED_FUNCTION_1_25()
{
  MLUntypedColumn.subscript.getter();
}

char *OUTLINED_FUNCTION_2_31@<X0>(uint64_t a1@<X8>, uint64_t a2)
{
  return (char *)&a2 - ((a1 + 15) & 0xFFFFFFFFFFFFFFF0);
}

void OUTLINED_FUNCTION_3_31(uint64_t a1)
{
  *(void *)(a1 + 16) = v1;
  outlined consume of Result<_DataTable, Error>(v2, 0);
}

void OUTLINED_FUNCTION_4_26()
{
  outlined consume of Result<_DataTable, Error>(v0, 1);
}

uint64_t OUTLINED_FUNCTION_5_21()
{
  return swift_allocError();
}

uint64_t OUTLINED_FUNCTION_7_20()
{
  return swift_unexpectedError();
}

id OUTLINED_FUNCTION_8_18()
{
  return outlined copy of Result<_DataTable, Error>(*v0, 0);
}

uint64_t OUTLINED_FUNCTION_9_16()
{
  *(void *)(v4 - 112) = v0;
  *(unsigned char *)(v4 - 104) = 0;
  return MLDataColumn.subscript.getter(v3, v1, v2);
}

void OUTLINED_FUNCTION_10_15()
{
  char v2 = *(unsigned char *)(v1 - 72);
  *(void *)uint64_t v0 = *(void *)(v1 - 80);
  *(unsigned char *)(v0 + 8) = v2;
}

void OUTLINED_FUNCTION_11_14(uint64_t a1, void *a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10)
{
  *a2 = a10;
}

void OUTLINED_FUNCTION_12_12()
{
  outlined consume of Result<_DataTable, Error>(v0, 0);
}

uint64_t OUTLINED_FUNCTION_13_16()
{
  return MLDataColumn.description.getter();
}

uint64_t OUTLINED_FUNCTION_16_14(uint64_t a1)
{
  *(void *)(a1 + 16) = v1;
  return type metadata accessor for _UntypedColumn();
}

void OUTLINED_FUNCTION_19_13()
{
  *(void *)uint64_t v0 = v2;
  *(unsigned char *)(v0 + 8) = v1;
}

void OUTLINED_FUNCTION_20_12(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, char a12)
{
  *(void *)uint64_t v12 = a11;
  *(unsigned char *)(v12 + 8) = a12;
}

void OUTLINED_FUNCTION_21_13()
{
  outlined consume of Result<_DataTable, Error>(v0, 0);
}

id OUTLINED_FUNCTION_23_4()
{
  return outlined copy of Result<_DataTable, Error>(v0, 1);
}

uint64_t OUTLINED_FUNCTION_24_11()
{
  return 0;
}

void OUTLINED_FUNCTION_26_9()
{
  outlined consume of Result<_DataTable, Error>(v0, 0);
}

void specialized Sequence.allSatisfy(_:)()
{
  OUTLINED_FUNCTION_9_0();
  uint64_t v4 = v3;
  uint64_t v5 = type metadata accessor for AnyColumn();
  OUTLINED_FUNCTION_0();
  uint64_t v7 = v6;
  MEMORY[0x270FA5388](v8);
  OUTLINED_FUNCTION_41_0();
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Zip2Sequence<AnyColumn, AnyColumn>);
  uint64_t v10 = v9 - 8;
  MEMORY[0x270FA5388](v9);
  OUTLINED_FUNCTION_40_0();
  uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Zip2Sequence<AnyColumn, AnyColumn>.Iterator);
  uint64_t v12 = v11 - 8;
  MEMORY[0x270FA5388](v11);
  OUTLINED_FUNCTION_24_4();
  outlined init with copy of URL?(v4, v2, &demangling cache variable for type metadata for Zip2Sequence<AnyColumn, AnyColumn>);
  uint64_t v13 = v7 + 32;
  uint64_t v14 = *(void (**)(uint64_t, uint64_t, uint64_t))(v7 + 32);
  uint64_t v29 = v13;
  v14(v0, v2, v5);
  lazy protocol witness table accessor for type AnyColumn and conformance AnyColumn(&lazy protocol witness table cache variable for type AnyColumn and conformance AnyColumn);
  dispatch thunk of Sequence.makeIterator()();
  v14(v0, v2 + *(int *)(v10 + 60), v5);
  uint64_t v40 = v1 + *(int *)(v12 + 60);
  uint64_t v32 = v0;
  dispatch thunk of Sequence.makeIterator()();
  uint64_t v31 = *(int *)(v12 + 64);
  *(unsigned char *)(v1 + v31) = 0;
  uint64_t v33 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for IndexingIterator<AnyColumn>);
  unint64_t v15 = (void *)(v1 + *(int *)(v33 + 36));
  lazy protocol witness table accessor for type AnyColumn and conformance AnyColumn((unint64_t *)&lazy protocol witness table cache variable for type AnyColumn and conformance AnyColumn);
  uint64_t v16 = (void (**)(uint64_t, uint64_t, uint64_t))(v29 - 16);
  unint64_t v17 = (void (**)(void))(v29 - 24);
  uint64_t v30 = v1;
  id v28 = v15;
  while (1)
  {
    uint64_t v18 = *v15;
    dispatch thunk of Collection.endIndex.getter();
    if (v18 == v35[0]) {
      goto LABEL_8;
    }
    uint64_t v19 = (void (*)(void *, void))dispatch thunk of Collection.subscript.read();
    outlined init with copy of URL?(v20, (uint64_t)v36, &demangling cache variable for type metadata for Any?);
    v19(v35, 0);
    uint64_t v21 = *v16;
    v21(v32, v1, v5);
    dispatch thunk of Collection.formIndex(after:)();
    char v22 = *v17;
    uint64_t v23 = OUTLINED_FUNCTION_30_9();
    ((void (*)(uint64_t))v22)(v23);
    outlined init with take of DataFrame?((uint64_t)v36, (uint64_t)v37, &demangling cache variable for type metadata for Any?);
    uint64_t v24 = *(void *)(v40 + *(int *)(v33 + 36));
    dispatch thunk of Collection.endIndex.getter();
    if (v24 == v34)
    {
      outlined destroy of URL?((uint64_t)v37, &demangling cache variable for type metadata for Any?);
      uint64_t v1 = v30;
LABEL_8:
      *(unsigned char *)(v1 + v31) = 1;
      goto LABEL_10;
    }
    uint64_t v25 = (void (*)(uint64_t *, void))dispatch thunk of Collection.subscript.read();
    outlined init with copy of URL?(v26, (uint64_t)v35, &demangling cache variable for type metadata for Any?);
    v25(&v34, 0);
    v21(v32, v40, v5);
    dispatch thunk of Collection.formIndex(after:)();
    OUTLINED_FUNCTION_30_9();
    OUTLINED_FUNCTION_5_4();
    v22();
    outlined init with take of DataFrame?((uint64_t)v35, (uint64_t)v36, &demangling cache variable for type metadata for Any?);
    outlined init with take of DataFrame?((uint64_t)v37, (uint64_t)v38, &demangling cache variable for type metadata for Any?);
    outlined init with take of DataFrame?((uint64_t)v36, (uint64_t)v39, &demangling cache variable for type metadata for Any?);
    char v27 = closure #1 in HandPoseClassifierTrainingSessionDelegate.verifyThatParametersAreCompatible(_:_:)((uint64_t)v38, (uint64_t)v39);
    outlined destroy of URL?((uint64_t)v38, &demangling cache variable for type metadata for (Any?, Any?));
    if ((v27 & 1) == 0) {
      break;
    }
    uint64_t v16 = (void (**)(uint64_t, uint64_t, uint64_t))(v29 - 16);
    unint64_t v17 = (void (**)(void))(v29 - 24);
    uint64_t v1 = v30;
    unint64_t v15 = v28;
    if (*(unsigned char *)(v30 + v31)) {
      goto LABEL_10;
    }
  }
  uint64_t v1 = v30;
LABEL_10:
  outlined destroy of URL?(v1, &demangling cache variable for type metadata for Zip2Sequence<AnyColumn, AnyColumn>.Iterator);
  OUTLINED_FUNCTION_8_1();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  char *v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  void (*v15)(uint64_t, char *, uint64_t);
  uint64_t v16;
  uint64_t v17;
  char *v18;
  uint64_t v19;
  void *v20;
  void (**v21)(void, void, void);
  void (**v22)(void, void);
  uint64_t *v23;
  uint64_t v24;
  void (*v25)(void *, void);
  uint64_t v26;
  void (*v27)(uint64_t, uint64_t, uint64_t);
  void (**v28)(uint64_t, uint64_t);
  uint64_t *v29;
  uint64_t v30;
  uint64_t v31;
  void (*v32)(uint64_t, uint64_t);
  uint64_t v33;
  uint64_t v34;
  void (*v35)(uint64_t *, void);
  uint64_t v36;
  void (**v37)(void, void, void);
  uint64_t v38;
  void (**v39)(void, void);
  uint64_t v40;
  uint64_t *v41;
  uint64_t v42;
  void *v43;
  void (**v44)(void, void);
  void (**v45)(void, void, void);
  uint64_t *v46;
  uint64_t v47;
  uint64_t v48;
  uint64_t v49;
  uint64_t v50;
  uint64_t v51;
  void v52[4];
  unsigned char v53[32];
  unsigned char v54[32];
  unsigned char v55[32];
  uint64_t v56;
  uint64_t v57;

  OUTLINED_FUNCTION_9_0();
  uint64_t v3 = v2;
  uint64_t v4 = type metadata accessor for AnyColumn();
  OUTLINED_FUNCTION_0();
  uint64_t v6 = v5;
  MEMORY[0x270FA5388](v7);
  OUTLINED_FUNCTION_41_0();
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Zip2Sequence<AnyColumn, AnyColumn>);
  uint64_t v9 = v8 - 8;
  MEMORY[0x270FA5388](v8);
  uint64_t v11 = (char *)&v42 - ((v10 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Zip2Sequence<AnyColumn, AnyColumn>.Iterator);
  uint64_t v13 = v12 - 8;
  MEMORY[0x270FA5388](v12);
  OUTLINED_FUNCTION_24_4();
  outlined init with copy of URL?(v3, (uint64_t)v11, &demangling cache variable for type metadata for Zip2Sequence<AnyColumn, AnyColumn>);
  uint64_t v14 = v6 + 32;
  unint64_t v15 = *(void (**)(uint64_t, char *, uint64_t))(v6 + 32);
  uint64_t v46 = (uint64_t *)v14;
  v15(v0, v11, v4);
  lazy protocol witness table accessor for type AnyColumn and conformance AnyColumn(&lazy protocol witness table cache variable for type AnyColumn and conformance AnyColumn);
  dispatch thunk of Sequence.makeIterator()();
  uint64_t v16 = *(int *)(v9 + 60);
  unint64_t v17 = v4;
  uint64_t v18 = &v11[v16];
  uint64_t v19 = (uint64_t)v46;
  v15(v0, v18, v4);
  uint64_t v57 = v1 + *(int *)(v13 + 60);
  uint64_t v49 = v0;
  dispatch thunk of Sequence.makeIterator()();
  uint64_t v48 = *(int *)(v13 + 64);
  *(unsigned char *)(v1 + v48) = 0;
  uint64_t v50 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for IndexingIterator<AnyColumn>);
  uint64_t v20 = (void *)(v1 + *(int *)(v50 + 36));
  lazy protocol witness table accessor for type AnyColumn and conformance AnyColumn((unint64_t *)&lazy protocol witness table cache variable for type AnyColumn and conformance AnyColumn);
  uint64_t v21 = (void (**)(void, void, void))(v19 - 16);
  char v22 = (void (**)(void, void))(v19 - 24);
  uint64_t v46 = &v56;
  uint64_t v23 = &demangling cache variable for type metadata for Any?;
  uint64_t v47 = v1;
  uint64_t v43 = v20;
  uint64_t v45 = v21;
  uint64_t v44 = v22;
  while (1)
  {
    uint64_t v24 = *v20;
    dispatch thunk of Collection.endIndex.getter();
    if (v24 == v52[0]) {
      goto LABEL_8;
    }
    uint64_t v25 = (void (*)(void *, void))dispatch thunk of Collection.subscript.read();
    outlined init with copy of URL?(v26, (uint64_t)v53, v23);
    v25(v52, 0);
    char v27 = *v21;
    id v28 = v22;
    uint64_t v29 = v23;
    uint64_t v30 = v17;
    uint64_t v31 = v49;
    v27(v49, v1, v30);
    dispatch thunk of Collection.formIndex(after:)();
    uint64_t v32 = *v28;
    (*v28)(v31, v30);
    outlined init with take of DataFrame?((uint64_t)v53, (uint64_t)v54, v29);
    OUTLINED_FUNCTION_39_18();
    uint64_t v34 = *(void *)(v57 + *(int *)(v33 + 36));
    dispatch thunk of Collection.endIndex.getter();
    if (v34 == v51)
    {
      outlined destroy of URL?((uint64_t)v54, &demangling cache variable for type metadata for Any?);
      uint64_t v1 = v47;
LABEL_8:
      *(unsigned char *)(v1 + v48) = 1;
      goto LABEL_10;
    }
    long long v35 = (void (*)(uint64_t *, void))dispatch thunk of Collection.subscript.read();
    outlined init with copy of URL?(v36, (uint64_t)v52, v29);
    v35(&v51, 0);
    uint64_t v37 = v45;
    v27(v31, v57, v30);
    dispatch thunk of Collection.formIndex(after:)();
    uint64_t v38 = v31;
    uint64_t v39 = v44;
    v32(v38, v30);
    outlined init with take of DataFrame?((uint64_t)v52, (uint64_t)v53, v29);
    outlined init with take of DataFrame?((uint64_t)v54, (uint64_t)v55, v29);
    uint64_t v40 = (uint64_t)v46;
    uint64_t v41 = v29;
    outlined init with take of DataFrame?((uint64_t)v53, (uint64_t)v46, v29);
    LOBYTE(v40) = closure #1 in HandPoseClassifierTrainingSessionDelegate.verifyThatParametersAreCompatible(_:_:)((uint64_t)v55, v40);
    outlined destroy of URL?((uint64_t)v55, &demangling cache variable for type metadata for (Any?, Any?));
    if ((v40 & 1) == 0) {
      break;
    }
    uint64_t v21 = v37;
    char v22 = v39;
    unint64_t v17 = v30;
    uint64_t v1 = v47;
    uint64_t v20 = v43;
    uint64_t v23 = v41;
    if (*(unsigned char *)(v47 + v48)) {
      goto LABEL_10;
    }
  }
  uint64_t v1 = v47;
LABEL_10:
  outlined destroy of URL?(v1, &demangling cache variable for type metadata for Zip2Sequence<AnyColumn, AnyColumn>.Iterator);
  OUTLINED_FUNCTION_8_1();
}

uint64_t (*HandPoseClassifierTrainingSessionDelegate.sourceTable.modify())()
{
  return HandPoseClassifierTrainingSessionDelegate.sourceTable.modify;
}

uint64_t HandPoseClassifierTrainingSessionDelegate.init(sessionParameters:)(uint64_t a1)
{
  uint64_t v3 = v1 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingParameters;
  uint64_t v4 = type metadata accessor for MLHandPoseClassifier.PersistentParameters();
  __swift_storeEnumTagSinglePayload(v3, 1, 1, v4);
  OUTLINED_FUNCTION_48_6(OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTable);
  *(void *)(v1 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTrainingRowCount) = 0;
  *(void *)(v1 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceValidationRowCount) = 0;
  OUTLINED_FUNCTION_49_2(v1 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingFeatures);
  OUTLINED_FUNCTION_49_2(v1 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_validationFeatures);
  *(void *)(v1 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_model) = 0;
  *(void *)(v1 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_classLabels) = 0;
  *(void *)(v1 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_metricsAttributesDictionary) = MEMORY[0x263F8EE80];
  outlined init with take of MLHandPoseClassifier.PersistentParameters(a1, v1 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sessionParameters, (void (*)(void))type metadata accessor for MLTrainingSessionParameters);
  return v1;
}

void HandPoseClassifierTrainingSessionDelegate.init(trainingData:modelParameters:sessionParameters:)()
{
  OUTLINED_FUNCTION_9_0();
  uint64_t v143 = v1;
  uint64_t v144 = v5;
  uint64_t v152 = v6;
  uint64_t v8 = v7;
  uint64_t v123 = type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData(0);
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v9);
  OUTLINED_FUNCTION_33_0();
  uint64_t v124 = v10;
  uint64_t v128 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  OUTLINED_FUNCTION_0();
  uint64_t v127 = v11;
  MEMORY[0x270FA5388](v12);
  OUTLINED_FUNCTION_33_0();
  uint64_t v126 = v13;
  uint64_t v135 = type metadata accessor for AnyColumn();
  OUTLINED_FUNCTION_0();
  uint64_t v134 = v14;
  MEMORY[0x270FA5388](v15);
  OUTLINED_FUNCTION_49();
  uint64_t v125 = v16;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v17);
  OUTLINED_FUNCTION_106();
  uint64_t v133 = v18;
  uint64_t v139 = type metadata accessor for DataFrame();
  OUTLINED_FUNCTION_0();
  uint64_t v136 = v19;
  MEMORY[0x270FA5388](v20);
  OUTLINED_FUNCTION_49();
  uint64_t v132 = v21;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v22);
  OUTLINED_FUNCTION_106();
  uint64_t v138 = v23;
  uint64_t v24 = (int *)type metadata accessor for MLHandPoseClassifier.PersistentParameters();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v25);
  OUTLINED_FUNCTION_40_0();
  uint64_t v26 = type metadata accessor for MLHandPoseClassifier.ModelParameters(0);
  char v27 = (int *)(v26 - 8);
  MEMORY[0x270FA5388](v26);
  OUTLINED_FUNCTION_27_7();
  uint64_t v146 = type metadata accessor for MLHandPoseClassifier.DataSource();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v28);
  OUTLINED_FUNCTION_49();
  uint64_t v137 = v29;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v30);
  OUTLINED_FUNCTION_59_6();
  MEMORY[0x270FA5388](v31);
  uint64_t v33 = (char *)&v120 - v32;
  uint64_t v34 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
  uint64_t v35 = OUTLINED_FUNCTION_17(v34);
  MEMORY[0x270FA5388](v35);
  OUTLINED_FUNCTION_33_0();
  uint64_t v142 = v36;
  uint64_t v147 = v0 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingParameters;
  __swift_storeEnumTagSinglePayload(v0 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingParameters, 1, 1, (uint64_t)v24);
  OUTLINED_FUNCTION_48_6(OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTable);
  *(void *)(v0 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTrainingRowCount) = 0;
  *(void *)(v0 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceValidationRowCount) = 0;
  uint64_t v140 = v0 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingFeatures;
  OUTLINED_FUNCTION_53_9(v0 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingFeatures);
  uint64_t v129 = v0 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_validationFeatures;
  OUTLINED_FUNCTION_53_9(v0 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_validationFeatures);
  *(void *)(v0 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_model) = 0;
  uint64_t v131 = OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_classLabels;
  *(void *)(v0 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_classLabels) = 0;
  uint64_t v145 = v0;
  *(void *)(v0 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_metricsAttributesDictionary) = MEMORY[0x263F8EE80];
  uint64_t v141 = type metadata accessor for MLHandPoseClassifier.DataSource;
  outlined init with copy of MLHandPoseClassifier.DataSource(v8, (uint64_t)v33, (void (*)(void))type metadata accessor for MLHandPoseClassifier.DataSource);
  outlined init with copy of MLHandPoseClassifier.DataSource(v152, v2, (void (*)(void))type metadata accessor for MLHandPoseClassifier.ModelParameters);
  uint64_t v37 = v24[6];
  uint64_t v38 = v24[7];
  outlined init with take of MLHandPoseClassifier.PersistentParameters((uint64_t)v33, v4, (void (*)(void))type metadata accessor for MLHandPoseClassifier.DataSource);
  outlined init with copy of MLHandPoseClassifier.DataSource(v2, v4 + v24[5], (void (*)(void))type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData);
  *(void *)(v4 + v37) = *(void *)(v2 + v27[7]);
  *(void *)(v4 + v38) = *(void *)(v2 + v27[8]);
  *(void *)(v4 + v24[8]) = *(void *)(v2 + v27[9]);
  _s8CreateML20MLHandPoseClassifierV10DataSourceOWOhTm_0(v2, (void (*)(void))type metadata accessor for MLHandPoseClassifier.ModelParameters);
  uint64_t v39 = v142;
  outlined init with take of MLHandPoseClassifier.PersistentParameters(v4, v142, (void (*)(void))type metadata accessor for MLHandPoseClassifier.PersistentParameters);
  double v130 = v24;
  __swift_storeEnumTagSinglePayload(v39, 0, 1, (uint64_t)v24);
  uint64_t v40 = v147;
  OUTLINED_FUNCTION_81_2();
  outlined assign with take of MLHandPoseClassifier.PersistentParameters?(v39, v40);
  swift_endAccess();
  outlined init with copy of MLHandPoseClassifier.DataSource(v8, v3, (void (*)(void))v141);
  if (swift_getEnumCaseMultiPayload() != 3)
  {
    uint64_t v53 = v143;
    _s8CreateML20MLHandPoseClassifierV10DataSourceOWOhTm_0(v3, (void (*)(void))type metadata accessor for MLHandPoseClassifier.DataSource);
    uint64_t v54 = v137;
    outlined init with copy of MLHandPoseClassifier.DataSource(v8, v137, (void (*)(void))type metadata accessor for MLHandPoseClassifier.DataSource);
    if (swift_getEnumCaseMultiPayload() == 5)
    {
      uint64_t v55 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
      uint64_t v56 = (uint64_t *)(v54 + v55[12]);
      uint64_t v58 = *v56;
      uint64_t v57 = v56[1];
      uint64_t v122 = v58;
      uint64_t v142 = v57;
      uint64_t v59 = (uint64_t *)(v54 + v55[16]);
      uint64_t v61 = *v59;
      uint64_t v60 = (uint64_t (*)())v59[1];
      uint64_t v121 = v61;
      uint64_t v141 = v60;
      uint64_t v62 = (uint64_t *)(v54 + v55[20]);
      uint64_t v64 = *v62;
      uint64_t v63 = (void *)v62[1];
      (*(void (**)(uint64_t, uint64_t, uint64_t))(v136 + 32))(v138, v54, v139);
      MEMORY[0x22A672220](v64, v63);
      uint64_t v65 = AnyColumn.wrappedElementType.getter();
      OUTLINED_FUNCTION_3_25();
      OUTLINED_FUNCTION_25_0();
      v66();
      if (v65 == MEMORY[0x263F8D310])
      {
        DataFrame.subscript.getter();
        uint64_t v73 = v125;
        Column<A>.parseAsJSONArrays()(v125);
        if (v53)
        {
          swift_bridgeObjectRelease();
          swift_bridgeObjectRelease();
          swift_bridgeObjectRelease();
          _s8CreateML20MLHandPoseClassifierV10DataSourceOWOhTm_0(v144, (void (*)(void))type metadata accessor for MLTrainingSessionParameters);
          _s8CreateML20MLHandPoseClassifierV10DataSourceOWOhTm_0(v152, (void (*)(void))type metadata accessor for MLHandPoseClassifier.ModelParameters);
          _s8CreateML20MLHandPoseClassifierV10DataSourceOWOhTm_0(v8, (void (*)(void))type metadata accessor for MLHandPoseClassifier.DataSource);
          OUTLINED_FUNCTION_25_0();
          v74();
          OUTLINED_FUNCTION_25_0();
          v75();
          goto LABEL_26;
        }
        OUTLINED_FUNCTION_25_0();
        v109();
        swift_bridgeObjectRetain();
        uint64_t v110 = v73;
        uint64_t v67 = v63;
        MEMORY[0x22A672230](v110, v64, v63);
      }
      else
      {
        uint64_t v67 = v63;
      }
      uint64_t v69 = v138;
      uint64_t v68 = v139;
      uint64_t v70 = v136;
      (*(void (**)(uint64_t, uint64_t, uint64_t))(v136 + 16))(v132, v138, v139);
      MLDataTable.init(_:convertArraysToShapedArrays:)(0, (uint64_t)&v150);
      if (v53)
      {
        swift_bridgeObjectRelease();
        swift_bridgeObjectRelease();
        swift_bridgeObjectRelease();
        _s8CreateML20MLHandPoseClassifierV10DataSourceOWOhTm_0(v144, (void (*)(void))type metadata accessor for MLTrainingSessionParameters);
        _s8CreateML20MLHandPoseClassifierV10DataSourceOWOhTm_0(v152, (void (*)(void))type metadata accessor for MLHandPoseClassifier.ModelParameters);
        _s8CreateML20MLHandPoseClassifierV10DataSourceOWOhTm_0(v8, (void (*)(void))type metadata accessor for MLHandPoseClassifier.DataSource);
        (*(void (**)(uint64_t, uint64_t))(v70 + 8))(v69, v68);
LABEL_26:
        uint64_t v88 = v145;
        goto LABEL_27;
      }
      uint64_t v77 = v150;
      char v78 = v151;
      uint64_t v79 = v140;
      OUTLINED_FUNCTION_13_17();
      uint64_t v80 = *(void **)v79;
      char v81 = *(unsigned char *)(v79 + 8);
      *(void *)uint64_t v79 = v77;
      *(unsigned char *)(v79 + 8) = v78;
      outlined consume of Result<_DataTable, Error>(v80, v81);
      OUTLINED_FUNCTION_81_2();
      static MLHandPoseClassifier.reformatKeypointsDataTable(table:featureColumn:)(v79, v64, v67);
      swift_endAccess();
      OUTLINED_FUNCTION_81_2();
      static _VideoUtilities.renameFeatureTableColumns(table:sessionIdColumn:featureColumn:labelColumn:)(v79, v122, v142, v64, (uint64_t)v67, v121, (uint64_t)v141);
      swift_endAccess();
      swift_bridgeObjectRelease();
      swift_bridgeObjectRelease();
      swift_bridgeObjectRelease();
      uint64_t v115 = swift_beginAccess();
      OUTLINED_FUNCTION_39_8(v115, v116, *(void *)v79, *(unsigned char *)(v79 + 8));
      char v117 = v148;
      char v118 = v149;
      swift_endAccess();
      specialized MLDataColumn.dropDuplicates()(v117, v118, (uint64_t)&v150);
      outlined consume of Result<_DataTable, Error>(v117, v118);
      uint64_t v87 = specialized Array<A>.init(_:)(v150, v151);
      OUTLINED_FUNCTION_5_4();
      v119();
    }
    else
    {
      _s8CreateML20MLHandPoseClassifierV10DataSourceOWOhTm_0(v54, (void (*)(void))type metadata accessor for MLHandPoseClassifier.DataSource);
      static _ImageUtilities.getDataSourceSynopsisForHandPoseClassifier(from:)(v8);
      if (v53)
      {
        int v52 = 0;
        uint64_t v88 = v145;
        goto LABEL_12;
      }
      uint64_t v76 = v71;
      swift_bridgeObjectRelease();
      swift_bridgeObjectRelease();
      uint64_t v87 = specialized _copyCollectionToContiguousArray<A>(_:)(v76);
      swift_bridgeObjectRelease();
    }
    uint64_t v88 = v145;
LABEL_20:
    uint64_t v72 = v144;
    uint64_t v89 = v131;
    uint64_t v90 = (uint64_t)v130;
    *(void *)(v88 + v131) = v87;
    swift_bridgeObjectRelease();
    uint64_t v91 = v147;
    if (!__swift_getEnumTagSinglePayload(v147, 1, v90))
    {
      uint64_t v92 = v91 + *(int *)(v90 + 20);
      uint64_t v93 = v124;
      outlined init with copy of MLHandPoseClassifier.DataSource(v92, v124, (void (*)(void))type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData);
      if (swift_getEnumCaseMultiPayload() == 1)
      {
        if (swift_getEnumCaseMultiPayload() == 3)
        {
          uint64_t v142 = v8;
          uint64_t v94 = *(void **)v93;
          char v95 = *(unsigned char *)(v93 + 8);
          uint64_t v96 = *(void *)(v93 + 24);
          uint64_t v97 = *(void *)(v93 + 32);
          uint64_t v98 = *(void *)(v93 + 40);
          uint64_t v146 = *(void *)(v93 + 16);
          uint64_t v147 = v97;
          uint64_t v100 = *(void *)(v93 + 48);
          char v99 = *(void **)(v93 + 56);
          OUTLINED_FUNCTION_13_17();
          OUTLINED_FUNCTION_47_7();
          uint64_t v102 = *v101;
          OUTLINED_FUNCTION_47_7();
          char v104 = *(unsigned char *)(v103 + 8);
          OUTLINED_FUNCTION_47_7();
          *uint64_t v105 = v94;
          OUTLINED_FUNCTION_47_7();
          *(unsigned char *)(v106 + 8) = v95;
          outlined copy of Result<_DataTable, Error>(v94, v95);
          uint64_t v107 = v102;
          uint64_t v108 = v129;
          outlined consume of Result<_DataTable, Error>(v107, v104);
          OUTLINED_FUNCTION_81_2();
          static MLHandPoseClassifier.reformatKeypointsDataTable(table:featureColumn:)(v108, v100, v99);
          swift_endAccess();
          OUTLINED_FUNCTION_81_2();
          static _VideoUtilities.renameFeatureTableColumns(table:sessionIdColumn:featureColumn:labelColumn:)(v108, v146, v96, v100, (uint64_t)v99, v147, v98);
          swift_endAccess();
          swift_bridgeObjectRelease();
          swift_bridgeObjectRelease();
          swift_bridgeObjectRelease();
          OUTLINED_FUNCTION_32_9();
          uint64_t v72 = v144;
          uint64_t v88 = v145;
          uint64_t v8 = v142;
          uint64_t v89 = v131;
          goto LABEL_30;
        }
        uint64_t v111 = (void (*)(void))type metadata accessor for MLHandPoseClassifier.DataSource;
      }
      else
      {
        uint64_t v111 = (void (*)(void))type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData;
      }
      _s8CreateML20MLHandPoseClassifierV10DataSourceOWOhTm_0(v93, v111);
    }
LABEL_30:
    outlined init with copy of MLHandPoseClassifier.DataSource(v72, v88 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sessionParameters, (void (*)(void))type metadata accessor for MLTrainingSessionParameters);
    if (*(void *)(v88 + v89))
    {
      type metadata accessor for MLHandActionClassifier.GraphCNN(0);
      swift_allocObject();
      swift_bridgeObjectRetain();
      OUTLINED_FUNCTION_64_4();
      uint64_t v113 = v112;
      _s8CreateML20MLHandPoseClassifierV10DataSourceOWOhTm_0(v72, (void (*)(void))type metadata accessor for MLTrainingSessionParameters);
      _s8CreateML20MLHandPoseClassifierV10DataSourceOWOhTm_0(v152, (void (*)(void))type metadata accessor for MLHandPoseClassifier.ModelParameters);
      _s8CreateML20MLHandPoseClassifierV10DataSourceOWOhTm_0(v8, (void (*)(void))type metadata accessor for MLHandPoseClassifier.DataSource);
      *(void *)(v88 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_model) = v113;
LABEL_32:
      swift_release();
      goto LABEL_33;
    }
    lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    OUTLINED_FUNCTION_85();
    OUTLINED_FUNCTION_19_0(v114, 0xD00000000000003DLL);
    int v52 = 1;
    goto LABEL_13;
  }
  uint64_t v142 = v8;
  uint64_t v41 = *(void **)v3;
  char v42 = *(unsigned char *)(v3 + 8);
  uint64_t v43 = *(void *)(v3 + 24);
  uint64_t v139 = *(void *)(v3 + 16);
  uint64_t v44 = *(void *)(v3 + 40);
  uint64_t v141 = *(uint64_t (**)())(v3 + 32);
  uint64_t v46 = *(void *)(v3 + 48);
  uint64_t v45 = *(void **)(v3 + 56);
  uint64_t v47 = v140;
  OUTLINED_FUNCTION_13_17();
  uint64_t v48 = *(void **)v47;
  char v49 = *(unsigned char *)(v47 + 8);
  *(void *)uint64_t v47 = v41;
  *(unsigned char *)(v47 + 8) = v42;
  outlined copy of Result<_DataTable, Error>(v41, v42);
  outlined consume of Result<_DataTable, Error>(v48, v49);
  OUTLINED_FUNCTION_81_2();
  uint64_t v50 = v143;
  static MLHandPoseClassifier.reformatKeypointsDataTable(table:featureColumn:)(v47, v46, v45);
  if (!v50)
  {
    swift_endAccess();
    uint64_t v51 = v140;
    OUTLINED_FUNCTION_81_2();
    static _VideoUtilities.renameFeatureTableColumns(table:sessionIdColumn:featureColumn:labelColumn:)(v51, v139, v43, v46, (uint64_t)v45, (uint64_t)v141, v44);
    swift_endAccess();
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    uint64_t v82 = v140;
    uint64_t v83 = swift_beginAccess();
    OUTLINED_FUNCTION_39_8(v83, v84, *(void *)v82, *(unsigned char *)(v82 + 8));
    uint64_t v85 = v148;
    char v86 = v149;
    swift_endAccess();
    specialized MLDataColumn.dropDuplicates()(v85, v86, (uint64_t)&v150);
    outlined consume of Result<_DataTable, Error>(v85, v86);
    uint64_t v87 = specialized Array<A>.init(_:)(v150, v151);
    OUTLINED_FUNCTION_32_9();
    uint64_t v88 = v145;
    uint64_t v8 = v142;
    goto LABEL_20;
  }
  swift_endAccess();
  swift_bridgeObjectRelease();
  swift_bridgeObjectRelease();
  swift_bridgeObjectRelease();
  OUTLINED_FUNCTION_32_9();
  int v52 = 0;
  uint64_t v88 = v145;
  uint64_t v8 = v142;
LABEL_12:
  uint64_t v72 = v144;
LABEL_13:
  _s8CreateML20MLHandPoseClassifierV10DataSourceOWOhTm_0(v72, (void (*)(void))type metadata accessor for MLTrainingSessionParameters);
  _s8CreateML20MLHandPoseClassifierV10DataSourceOWOhTm_0(v152, (void (*)(void))type metadata accessor for MLHandPoseClassifier.ModelParameters);
  _s8CreateML20MLHandPoseClassifierV10DataSourceOWOhTm_0(v8, (void (*)(void))type metadata accessor for MLHandPoseClassifier.DataSource);
  if (v52) {
    goto LABEL_32;
  }
LABEL_27:
  outlined destroy of URL?(v88 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingParameters, &demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
  outlined consume of MLDataTable?(*(void **)(v88 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTable), *(unsigned char *)(v88 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTable + 8));
  outlined consume of Result<_DataTable, Error>(*(id *)(v88 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingFeatures), *(unsigned char *)(v88 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingFeatures + 8));
  outlined consume of Result<_DataTable, Error>(*(id *)(v88 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_validationFeatures), *(unsigned char *)(v88 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_validationFeatures + 8));
  swift_release();
  swift_bridgeObjectRelease();
  swift_bridgeObjectRelease();
  type metadata accessor for HandPoseClassifierTrainingSessionDelegate();
  swift_deallocPartialClassInstance();
LABEL_33:
  OUTLINED_FUNCTION_8_1();
}

void HandPoseClassifierTrainingSessionDelegate.populateSourceTable(parameters:)()
{
  uint64_t v2 = v0;
  type metadata accessor for MLHandPoseClassifier.PersistentParameters();
  MLHandPoseClassifier.ModelParameters.ValidationData.extractAnnotations(trainingData:)(&v21, &v23);
  if (!v1)
  {
    uint64_t v3 = v21;
    unsigned __int8 v4 = v22;
    uint64_t v5 = v23;
    int v6 = v24;
    if (v22 == 255)
    {
      if (v24 != 255)
      {
        uint64_t v14 = v0 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTable;
        OUTLINED_FUNCTION_13_17();
        char v27 = *(void **)v14;
        *(void *)uint64_t v14 = v5;
        unsigned __int8 v15 = *(unsigned char *)(v14 + 8);
        int v16 = v6 & 1;
        *(unsigned char *)(v14 + 8) = v6;
        outlined copy of Result<_DataTable, Error>(v5, v6 & 1);
        outlined consume of MLDataTable?(v27, v15);
        *(void *)(v2 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTrainingRowCount) = 0;
LABEL_12:
        uint64_t v25 = v5;
        char v26 = v16 != 0;
        uint64_t v20 = MLDataTable.size.getter();
        OUTLINED_FUNCTION_50_6();
        outlined consume of MLDataTable?(v5, v6);
LABEL_15:
        *(void *)(v2 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceValidationRowCount) = v20;
        return;
      }
      *(void *)(v0 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTrainingRowCount) = 0;
    }
    else
    {
      LODWORD(v27) = v22 & 1;
      uint64_t v7 = v0 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTable;
      if (v24 == 255)
      {
        OUTLINED_FUNCTION_13_17();
        uint64_t v17 = *(void **)v7;
        *(void *)uint64_t v7 = v3;
        unsigned __int8 v18 = *(unsigned char *)(v7 + 8);
        *(unsigned char *)(v7 + 8) = v4;
        outlined copy of MLDataTable?(v3, v4);
        int v13 = (int)v27;
        outlined copy of Result<_DataTable, Error>(v3, (char)v27);
        outlined consume of MLDataTable?(v17, v18);
      }
      else
      {
        OUTLINED_FUNCTION_13_17();
        uint64_t v8 = *(void **)v7;
        *(void *)uint64_t v7 = v3;
        unsigned __int8 v9 = *(unsigned char *)(v7 + 8);
        char v10 = (char)v27;
        *(unsigned char *)(v7 + 8) = (_BYTE)v27;
        outlined copy of Result<_DataTable, Error>(v3, v10);
        outlined copy of MLDataTable?(v3, v4);
        outlined copy of MLDataTable?(v5, v6);
        outlined consume of MLDataTable?(v8, v9);
        uint64_t v11 = HandPoseClassifierTrainingSessionDelegate.sourceTable.modify();
        if (*(unsigned __int8 *)(v12 + 8) != 255)
        {
          uint64_t v25 = v5;
          char v26 = v6 & 1;
          MLDataTable.append(contentsOf:)();
        }
        ((void (*)(void **, void))v11)(&v21, 0);
        OUTLINED_FUNCTION_50_6();
        outlined consume of MLDataTable?(v5, v6);
        int v13 = (int)v27;
        outlined copy of Result<_DataTable, Error>(v3, (char)v27);
      }
      uint64_t v25 = v3;
      char v26 = v13 != 0;
      uint64_t v19 = MLDataTable.size.getter();
      OUTLINED_FUNCTION_50_6();
      *(void *)(v2 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTrainingRowCount) = v19;
      if (v6 != 255)
      {
        int v16 = v6 & 1;
        goto LABEL_12;
      }
    }
    OUTLINED_FUNCTION_50_6();
    uint64_t v20 = 0;
    goto LABEL_15;
  }
}

Swift::Void __swiftcall __spoils<CF,ZF,NF,VF,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13,X14,X15,X16,X17,X21,Q0,Q1,Q2,Q3,Q4,Q5,Q6,Q7,Q16,Q17,Q18,Q19,Q20,Q21,Q22,Q23,Q24,Q25,Q26,Q27,Q28,Q29,Q30,Q31> HandPoseClassifierTrainingSessionDelegate.setUp()()
{
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
  uint64_t v4 = OUTLINED_FUNCTION_17(v3);
  MEMORY[0x270FA5388](v4);
  uint64_t v5 = OUTLINED_FUNCTION_36_8();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v6);
  OUTLINED_FUNCTION_41_0();
  uint64_t v7 = v0 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingParameters;
  OUTLINED_FUNCTION_53();
  outlined init with copy of URL?(v7, v1, &demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
  if (__swift_getEnumTagSinglePayload(v1, 1, v5) == 1)
  {
    outlined destroy of URL?(v1, &demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
    __break(1u);
  }
  else
  {
    outlined init with take of MLHandPoseClassifier.PersistentParameters(v1, v2, (void (*)(void))type metadata accessor for MLHandPoseClassifier.PersistentParameters);
    HandPoseClassifierTrainingSessionDelegate.populateSourceTable(parameters:)();
    _s8CreateML20MLHandPoseClassifierV10DataSourceOWOhTm_0(v2, (void (*)(void))type metadata accessor for MLHandPoseClassifier.PersistentParameters);
  }
}

Swift::Void __swiftcall __spoils<CF,ZF,NF,VF,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13,X14,X15,X16,X17,X21,Q0,Q1,Q2,Q3,Q4,Q5,Q6,Q7,Q16,Q17,Q18,Q19,Q20,Q21,Q22,Q23,Q24,Q25,Q26,Q27,Q28,Q29,Q30,Q31> HandPoseClassifierTrainingSessionDelegate.resume(from:)(Swift::OpaquePointer from)
{
  OUTLINED_FUNCTION_9_0();
  uint64_t v111 = v2;
  uint64_t v115 = v5;
  uint64_t v6 = type metadata accessor for URL();
  uint64_t v7 = OUTLINED_FUNCTION_17(v6);
  MEMORY[0x270FA5388](v7);
  OUTLINED_FUNCTION_49();
  char v104 = v8;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v9);
  OUTLINED_FUNCTION_45_3();
  uint64_t v105 = v10;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v11);
  OUTLINED_FUNCTION_45_3();
  uint64_t v107 = v12;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v13);
  OUTLINED_FUNCTION_106();
  uint64_t v110 = v14;
  uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?);
  uint64_t v16 = OUTLINED_FUNCTION_17(v15);
  MEMORY[0x270FA5388](v16);
  OUTLINED_FUNCTION_49();
  uint64_t v109 = v17;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v18);
  uint64_t v20 = (char *)&v103 - v19;
  uint64_t v21 = type metadata accessor for MLCheckpoint();
  OUTLINED_FUNCTION_0();
  uint64_t v108 = v22;
  MEMORY[0x270FA5388](v23);
  OUTLINED_FUNCTION_49();
  uint64_t v116 = v24;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v25);
  OUTLINED_FUNCTION_45_3();
  uint64_t v106 = v26;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v27);
  OUTLINED_FUNCTION_45_3();
  uint64_t v112 = v28;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v29);
  OUTLINED_FUNCTION_106();
  uint64_t v113 = v30;
  uint64_t v31 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
  uint64_t v32 = OUTLINED_FUNCTION_17(v31);
  MEMORY[0x270FA5388](v32);
  OUTLINED_FUNCTION_24_4();
  uint64_t v33 = type metadata accessor for MLHandPoseClassifier.PersistentParameters();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v34);
  OUTLINED_FUNCTION_40_0();
  uint64_t v114 = v1;
  uint64_t v35 = v1 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingParameters;
  OUTLINED_FUNCTION_53();
  outlined init with copy of URL?(v35, v3, &demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
  if (__swift_getEnumTagSinglePayload(v3, 1, v33) == 1)
  {
    outlined destroy of URL?(v3, &demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
    __break(1u);
    JUMPOUT(0x22711F79CLL);
  }
  outlined init with take of MLHandPoseClassifier.PersistentParameters(v3, v4, (void (*)(void))type metadata accessor for MLHandPoseClassifier.PersistentParameters);
  uint64_t v36 = v115;
  specialized BidirectionalCollection.last.getter(v115, (uint64_t)v20);
  if (__swift_getEnumTagSinglePayload((uint64_t)v20, 1, v21) != 1)
  {
    uint64_t v39 = v21;
    uint64_t v40 = v113;
    outlined init with take of MLHandPoseClassifier.PersistentParameters((uint64_t)v20, v113, (void (*)(void))type metadata accessor for MLCheckpoint);
    uint64_t v41 = *(int *)(v21 + 20);
    uint64_t v103 = v41;
    uint64_t v42 = v112;
    switch(*(unsigned char *)(v40 + v41))
    {
      case 1:
        swift_bridgeObjectRelease();
        outlined init with copy of MLHandPoseClassifier.DataSource(v40, v42, (void (*)(void))type metadata accessor for MLCheckpoint);
        goto LABEL_10;
      case 2:
        OUTLINED_FUNCTION_155();
        break;
      case 3:
        OUTLINED_FUNCTION_154();
        break;
      case 4:
        OUTLINED_FUNCTION_35_8();
        break;
      default:
        break;
    }
    char v43 = OUTLINED_FUNCTION_87_0();
    swift_bridgeObjectRelease();
    outlined init with copy of MLHandPoseClassifier.DataSource(v40, v42, (void (*)(void))type metadata accessor for MLCheckpoint);
    if (v43)
    {
LABEL_10:
      _s8CreateML20MLHandPoseClassifierV10DataSourceOWOhTm_0(v42, (void (*)(void))type metadata accessor for MLCheckpoint);
    }
    else
    {
      switch(*(unsigned char *)(v42 + *(int *)(v39 + 20)))
      {
        case 1:
          break;
        case 2:
          swift_bridgeObjectRelease();
          goto LABEL_10;
        case 3:
          OUTLINED_FUNCTION_154();
          break;
        case 4:
          OUTLINED_FUNCTION_35_8();
          break;
        default:
          OUTLINED_FUNCTION_56_9();
          break;
      }
      char v45 = OUTLINED_FUNCTION_37_5();
      swift_bridgeObjectRelease();
      _s8CreateML20MLHandPoseClassifierV10DataSourceOWOhTm_0(v42, (void (*)(void))type metadata accessor for MLCheckpoint);
      if ((v45 & 1) == 0)
      {
        lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
        OUTLINED_FUNCTION_85();
        OUTLINED_FUNCTION_19_0(v46, 0xD00000000000003FLL);
        goto LABEL_27;
      }
    }
    uint64_t v44 = v111;
    HandPoseClassifierTrainingSessionDelegate.populateSourceTable(parameters:)();
    if (!v44)
    {
      switch(*(unsigned char *)(v40 + v103))
      {
        case 1:
          swift_bridgeObjectRelease();
          goto LABEL_26;
        case 2:
          OUTLINED_FUNCTION_155();
          break;
        case 3:
          OUTLINED_FUNCTION_154();
          break;
        case 4:
          OUTLINED_FUNCTION_34_8();
          break;
        default:
          break;
      }
      char v47 = OUTLINED_FUNCTION_87_0();
      uint64_t ML20MLHandPoseClassifierV10DataSourceOWOhTm_0 = swift_bridgeObjectRelease();
      if (v47)
      {
LABEL_26:
        char v49 = v110;
        OUTLINED_FUNCTION_123();
        URL.appendingPathComponent(_:)();
        char v152 = 1;
        LOBYTE(v136) = 1;
        uint64_t v137 = 44;
        unint64_t v138 = 0xE100000000000000;
        uint64_t v139 = 0;
        unint64_t v140 = 0xE000000000000000;
        uint64_t v141 = 92;
        unint64_t v142 = 0xE100000000000000;
        char v143 = 1;
        uint64_t v144 = 34;
        unint64_t v145 = 0xE100000000000000;
        char v146 = 1;
        uint64_t v147 = &outlined read-only object #0 of default argument 1 of MLDataTable.init(contentsOf:options:);
        uint64_t v148 = 10;
        uint64_t v150 = 0;
        uint64_t v151 = 0;
        unint64_t v149 = 0xE100000000000000;
        OUTLINED_FUNCTION_45_5();
        MLDataTable.init(contentsOf:options:)(v49, v50, v51);
        uint64_t v112 = v4;
        uint64_t v61 = v155;
        uint64_t v116 = 0;
        char v62 = v156;
        uint64_t v63 = v114;
        uint64_t v64 = v114 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingFeatures;
        OUTLINED_FUNCTION_13_17();
        uint64_t v65 = *(void **)v64;
        char v66 = *(unsigned char *)(v64 + 8);
        *(void *)uint64_t v64 = v61;
        *(unsigned char *)(v64 + 8) = v62;
        outlined consume of Result<_DataTable, Error>(v65, v66);
        uint64_t v67 = v107;
        OUTLINED_FUNCTION_172();
        URL.appendingPathComponent(_:)();
        char v135 = 1;
        LOBYTE(v117) = 1;
        uint64_t v118 = 44;
        unint64_t v119 = 0xE100000000000000;
        uint64_t v120 = 0;
        unint64_t v121 = 0xE000000000000000;
        uint64_t v122 = 92;
        unint64_t v123 = 0xE100000000000000;
        char v124 = 1;
        uint64_t v125 = 34;
        unint64_t v126 = 0xE100000000000000;
        char v127 = 1;
        uint64_t v128 = &outlined read-only object #0 of default argument 1 of MLDataTable.init(contentsOf:options:);
        uint64_t v129 = 10;
        uint64_t v131 = 0;
        uint64_t v132 = 0;
        unint64_t v130 = 0xE100000000000000;
        char v133 = 1;
        uint64_t v134 = 0;
        uint64_t v68 = v116;
        MLDataTable.init(contentsOf:options:)(v67, &v117, (uint64_t)&v153);
        if (v68)
        {
          uint64_t v69 = v40;
LABEL_50:
          _s8CreateML20MLHandPoseClassifierV10DataSourceOWOhTm_0(v69, (void (*)(void))type metadata accessor for MLCheckpoint);
          uint64_t v53 = v112;
          goto LABEL_30;
        }
        OUTLINED_FUNCTION_13_17();
        OUTLINED_FUNCTION_57_8();
        uint64_t v4 = v112;
        uint64_t v75 = v40;
      }
      else
      {
        uint64_t v136 = v36;
        uint64_t v54 = *(void *)(v36 + 16);
        if (v54)
        {
          uint64_t v112 = v4;
          uint64_t v55 = *(void *)(v108 + 72);
          uint64_t v56 = v54 - 1;
          uint64_t v57 = v36
              + ((*(unsigned __int8 *)(v108 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v108 + 80))
              + v55 * (v54 - 1);
          uint64_t v58 = -v55;
          while (2)
          {
            uint64_t v59 = v116;
            outlined init with copy of MLHandPoseClassifier.DataSource(v57, v116, (void (*)(void))type metadata accessor for MLCheckpoint);
            switch(*(unsigned char *)(v59 + *(int *)(v39 + 20)))
            {
              case 1:
                swift_bridgeObjectRelease();
                uint64_t ML20MLHandPoseClassifierV10DataSourceOWOhTm_0 = _s8CreateML20MLHandPoseClassifierV10DataSourceOWOhTm_0(v116, (void (*)(void))type metadata accessor for MLCheckpoint);
                uint64_t v4 = v112;
                break;
              case 2:
                OUTLINED_FUNCTION_155();
                goto LABEL_36;
              case 3:
                OUTLINED_FUNCTION_154();
                goto LABEL_36;
              default:
LABEL_36:
                char v60 = OUTLINED_FUNCTION_87_0();
                swift_bridgeObjectRelease();
                uint64_t ML20MLHandPoseClassifierV10DataSourceOWOhTm_0 = _s8CreateML20MLHandPoseClassifierV10DataSourceOWOhTm_0(v116, (void (*)(void))type metadata accessor for MLCheckpoint);
                if (v60) {
                  goto LABEL_39;
                }
                --v56;
                v57 += v58;
                if (v56 != -1) {
                  continue;
                }
                uint64_t v56 = 0;
LABEL_39:
                uint64_t v4 = v112;
                break;
            }
            break;
          }
        }
        else
        {
          uint64_t v56 = 0;
        }
        uint64_t v70 = v109;
        MEMORY[0x270FA5388](ML20MLHandPoseClassifierV10DataSourceOWOhTm_0);
        *(&v103 - 2) = (uint64_t)&v136;
        _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5((void *(*)(void *__return_ptr, uint64_t *))partial apply for specialized closure #1 in BidirectionalCollection.last(where:), v56, v71 & 1, v70);
        if (__swift_getEnumTagSinglePayload((uint64_t)v70, 1, v39) == 1)
        {
          outlined destroy of URL?((uint64_t)v70, &demangling cache variable for type metadata for MLCheckpoint?);
          uint64_t v63 = v114;
          uint64_t v72 = (uint64_t *)(v114 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingFeatures);
          OUTLINED_FUNCTION_53();
          char v73 = *((unsigned char *)v72 + 8);
          uint64_t v117 = *v72;
          LOBYTE(v118) = v73;
          uint64_t v74 = MLDataTable.size.getter();
          uint64_t v75 = v113;
          if (!v74)
          {
            lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
            OUTLINED_FUNCTION_85();
            OUTLINED_FUNCTION_29_9();
            uint64_t v78 = v77 + 11;
LABEL_64:
            OUTLINED_FUNCTION_19_0(v76, v78);
LABEL_65:
            uint64_t v52 = v75;
            goto LABEL_28;
          }
        }
        else
        {
          uint64_t v79 = (uint64_t)v70;
          uint64_t v80 = v106;
          outlined init with take of MLHandPoseClassifier.PersistentParameters(v79, v106, (void (*)(void))type metadata accessor for MLCheckpoint);
          char v81 = v105;
          OUTLINED_FUNCTION_123();
          URL.appendingPathComponent(_:)();
          char v152 = 1;
          LOBYTE(v136) = 1;
          uint64_t v137 = 44;
          unint64_t v138 = 0xE100000000000000;
          uint64_t v139 = 0;
          unint64_t v140 = 0xE000000000000000;
          uint64_t v141 = 92;
          unint64_t v142 = 0xE100000000000000;
          char v143 = 1;
          uint64_t v144 = 34;
          unint64_t v145 = 0xE100000000000000;
          char v146 = 1;
          uint64_t v147 = &outlined read-only object #0 of default argument 1 of MLDataTable.init(contentsOf:options:);
          uint64_t v148 = 10;
          uint64_t v150 = 0;
          uint64_t v151 = 0;
          unint64_t v149 = 0xE100000000000000;
          OUTLINED_FUNCTION_45_5();
          MLDataTable.init(contentsOf:options:)(v81, v82, v83);
          uint64_t v112 = v4;
          uint64_t v84 = v155;
          char v85 = v156;
          uint64_t v86 = v114;
          uint64_t v87 = v114 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingFeatures;
          uint64_t v116 = 0;
          OUTLINED_FUNCTION_13_17();
          uint64_t v88 = *(void **)v87;
          char v89 = *(unsigned char *)(v87 + 8);
          *(void *)uint64_t v87 = v84;
          *(unsigned char *)(v87 + 8) = v85;
          outlined consume of Result<_DataTable, Error>(v88, v89);
          uint64_t v90 = v104;
          OUTLINED_FUNCTION_172();
          URL.appendingPathComponent(_:)();
          char v135 = 1;
          LOBYTE(v117) = 1;
          uint64_t v118 = 44;
          unint64_t v119 = 0xE100000000000000;
          uint64_t v120 = 0;
          unint64_t v121 = 0xE000000000000000;
          uint64_t v122 = 92;
          unint64_t v123 = 0xE100000000000000;
          char v124 = 1;
          uint64_t v125 = 34;
          unint64_t v126 = 0xE100000000000000;
          char v127 = 1;
          uint64_t v128 = &outlined read-only object #0 of default argument 1 of MLDataTable.init(contentsOf:options:);
          uint64_t v129 = 10;
          uint64_t v131 = 0;
          uint64_t v132 = 0;
          unint64_t v130 = 0xE100000000000000;
          char v133 = 1;
          uint64_t v134 = 0;
          uint64_t v91 = v116;
          MLDataTable.init(contentsOf:options:)(v90, &v117, (uint64_t)&v153);
          if (v91)
          {
            _s8CreateML20MLHandPoseClassifierV10DataSourceOWOhTm_0(v80, (void (*)(void))type metadata accessor for MLCheckpoint);
            uint64_t v69 = v113;
            goto LABEL_50;
          }
          _s8CreateML20MLHandPoseClassifierV10DataSourceOWOhTm_0(v80, (void (*)(void))type metadata accessor for MLCheckpoint);
          OUTLINED_FUNCTION_13_17();
          OUTLINED_FUNCTION_57_8();
          uint64_t v4 = v112;
          uint64_t v75 = v113;
          uint64_t v63 = v86;
        }
      }
      switch(*(unsigned char *)(v75 + v103))
      {
        case 1:
          goto LABEL_58;
        case 2:
          swift_bridgeObjectRelease();
          goto LABEL_59;
        case 3:
          OUTLINED_FUNCTION_154();
          goto LABEL_58;
        case 4:
          OUTLINED_FUNCTION_34_8();
          goto LABEL_58;
        default:
          OUTLINED_FUNCTION_56_9();
LABEL_58:
          char v92 = OUTLINED_FUNCTION_37_5();
          swift_bridgeObjectRelease();
          if ((v92 & 1) == 0) {
            goto LABEL_65;
          }
LABEL_59:
          uint64_t v93 = v63 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingFeatures;
          OUTLINED_FUNCTION_53();
          uint64_t v94 = *(void **)v93;
          LOBYTE(v93) = *(unsigned char *)(v93 + 8);
          outlined copy of Result<_DataTable, Error>(v94, v93);
          OUTLINED_FUNCTION_25_15();
          specialized MLDataTable.subscript.getter(v93, v95);
          OUTLINED_FUNCTION_32_9();
          id v96 = v153;
          LOBYTE(v94) = v154;
          specialized MLDataColumn.dropDuplicates()(v153, v154, (uint64_t)&v155);
          outlined consume of Result<_DataTable, Error>(v96, (char)v94);
          uint64_t v97 = specialized Array<A>.init(_:)(v155, v156);
          uint64_t v98 = OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_classLabels;
          *(void *)(v63 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_classLabels) = v97;
          swift_bridgeObjectRelease();
          if (*(void *)(v63 + v98))
          {
            type metadata accessor for MLHandActionClassifier.GraphCNN(0);
            swift_allocObject();
            swift_bridgeObjectRetain();
            MLHandActionClassifier.GraphCNN.init(classLabels:export:numOfKeypoints:numOfKeypointsChannels:windowSize:)();
            uint64_t v99 = OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_model;
            *(void *)(v63 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_model) = v100;
            swift_release();
            if (*(void *)(v63 + v99))
            {
              swift_retain();
              MLHandActionClassifier.GraphCNN.updateGraphCNN(from:)(v75);
              MLHandActionClassifier.GraphCNN.initDevice()();
              swift_release();
              goto LABEL_65;
            }
            lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
            OUTLINED_FUNCTION_85();
            OUTLINED_FUNCTION_29_9();
            uint64_t v78 = v102 + 20;
          }
          else
          {
            lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
            OUTLINED_FUNCTION_85();
            OUTLINED_FUNCTION_29_9();
            uint64_t v78 = v101 + 17;
          }
          break;
      }
      goto LABEL_64;
    }
LABEL_27:
    uint64_t v52 = v40;
LABEL_28:
    _s8CreateML20MLHandPoseClassifierV10DataSourceOWOhTm_0(v52, (void (*)(void))type metadata accessor for MLCheckpoint);
    goto LABEL_29;
  }
  outlined destroy of URL?((uint64_t)v20, &demangling cache variable for type metadata for MLCheckpoint?);
  lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  OUTLINED_FUNCTION_85();
  OUTLINED_FUNCTION_29_9();
  OUTLINED_FUNCTION_19_0(v37, v38);
LABEL_29:
  uint64_t v53 = v4;
LABEL_30:
  _s8CreateML20MLHandPoseClassifierV10DataSourceOWOhTm_0(v53, (void (*)(void))type metadata accessor for MLHandPoseClassifier.PersistentParameters);
  OUTLINED_FUNCTION_8_1();
}

Swift::Int_optional __swiftcall HandPoseClassifierTrainingSessionDelegate.itemCount(phase:)(CreateML::MLPhase phase)
{
  uint64_t v2 = *(unsigned __int8 *)phase;
  Swift::Bool v3 = 1;
  Swift::Int v4 = 0;
  switch(v2)
  {
    case 1:
      uint64_t v5 = v1 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTable;
      swift_beginAccess();
      if (*(unsigned __int8 *)(v5 + 8) == 255) {
        Swift::Int v4 = 0;
      }
      else {
        Swift::Int v4 = MLDataTable.size.getter();
      }
      Swift::Bool v3 = 0;
      break;
    case 2:
      uint64_t v6 = v1 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sessionParameters;
      uint64_t v7 = type metadata accessor for MLTrainingSessionParameters();
      Swift::Bool v3 = 0;
      Swift::Int v4 = *(void *)(v6 + *(int *)(v7 + 28));
      break;
    default:
      break;
  }
  result.value = v4;
  result.is_nil = v3;
  return result;
}

Swift::tuple_Int_finished_Bool __swiftcall __spoils<CF,ZF,NF,VF,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13,X14,X15,X16,X17,X21,Q0,Q1,Q2,Q3,Q4,Q5,Q6,Q7,Q16,Q17,Q18,Q19,Q20,Q21,Q22,Q23,Q24,Q25,Q26,Q27,Q28,Q29,Q30,Q31> HandPoseClassifierTrainingSessionDelegate.extractFeatures(from:)(Swift::Int from)
{
  OUTLINED_FUNCTION_9_0();
  uint64_t v4 = v1;
  uint64_t v6 = v5;
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
  uint64_t v8 = OUTLINED_FUNCTION_17(v7);
  MEMORY[0x270FA5388](v8);
  OUTLINED_FUNCTION_24_4();
  uint64_t v9 = v1 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingParameters;
  OUTLINED_FUNCTION_53();
  outlined init with copy of URL?(v9, v3, &demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
  uint64_t v10 = type metadata accessor for MLHandPoseClassifier.PersistentParameters();
  LODWORD(v9) = __swift_getEnumTagSinglePayload(v3, 1, v10);
  Swift::Int v11 = outlined destroy of URL?(v3, &demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
  if (v9 == 1)
  {
    __break(1u);
LABEL_27:
    __break(1u);
    goto LABEL_28;
  }
  uint64_t v13 = v1 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTable;
  OUTLINED_FUNCTION_53();
  int v14 = *(unsigned __int8 *)(v13 + 8);
  if (v14 == 255) {
    goto LABEL_15;
  }
  id v33 = *(id *)v13;
  char v34 = v14 & 1;
  outlined copy of Result<_DataTable, Error>(v33, v14 & 1);
  Swift::Int v11 = MLDataTable.size.getter();
  if (v12 < 1)
  {
LABEL_12:
    OUTLINED_FUNCTION_46_7();
    goto LABEL_15;
  }
  uint64_t v15 = OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTrainingRowCount;
  uint64_t v16 = *(void *)(v4 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTrainingRowCount);
  uint64_t v17 = *(void *)(v4 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceValidationRowCount);
  uint64_t v18 = v16 + v17;
  if (__OFADD__(v16, v17)) {
    goto LABEL_27;
  }
  if (v18 > v6)
  {
    uint64_t v32 = OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceValidationRowCount;
    uint64_t v19 = v4 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sessionParameters;
    Swift::Int v11 = type metadata accessor for MLTrainingSessionParameters();
    uint64_t v20 = *(void *)(v19 + *(int *)(v11 + 20));
    BOOL v21 = __OFADD__(v6, v20);
    uint64_t v22 = v6 + v20;
    char v23 = v21;
    if (v16 <= v6)
    {
      if (v23)
      {
LABEL_29:
        __break(1u);
        goto LABEL_30;
      }
    }
    else
    {
      uint64_t v18 = v16;
      if (v23)
      {
        __break(1u);
        goto LABEL_12;
      }
    }
    uint64_t v31 = v15;
    if (v18 >= v22) {
      uint64_t v24 = v22;
    }
    else {
      uint64_t v24 = v18;
    }
    if (v24 >= v6)
    {
      id v35 = v33;
      char v36 = v14 & 1;
      MLDataTable.subscript.getter(&v33, v6, v24);
      id v25 = v33;
      char v26 = v34;
      type metadata accessor for MLHandPoseClassifier.FeatureExtractor();
      id v35 = v25;
      char v36 = v26;
      static MLHandPoseClassifier.FeatureExtractor.extractFeatures(from:startingSessionId:)((uint64_t)&v35, v6, &v33);
      if (v2)
      {
        OUTLINED_FUNCTION_46_7();
        outlined consume of Result<_DataTable, Error>(v25, v26);
        goto LABEL_15;
      }
      uint64_t v29 = v25;
      char v30 = v26;
      id v27 = v33;
      char v28 = v34;
      id v35 = v33;
      char v36 = v34;
      OUTLINED_FUNCTION_81_2();
      MLDataTable.append(contentsOf:)();
      swift_endAccess();
      OUTLINED_FUNCTION_46_7();
      outlined consume of Result<_DataTable, Error>(v29, v30);
      outlined consume of Result<_DataTable, Error>(v27, v28);
      Swift::Int v11 = v24 - v6;
      if (!__OFSUB__(v24, v6))
      {
        if (!__OFADD__(*(void *)(v4 + v31), *(void *)(v4 + v32))) {
          goto LABEL_15;
        }
LABEL_31:
        __break(1u);
        goto LABEL_32;
      }
LABEL_30:
      __break(1u);
      goto LABEL_31;
    }
LABEL_28:
    __break(1u);
    goto LABEL_29;
  }
  OUTLINED_FUNCTION_46_7();
LABEL_15:
  OUTLINED_FUNCTION_8_1();
LABEL_32:
  result.BOOL finished = v12;
  result._0 = v11;
  return result;
}

Swift::Void __swiftcall __spoils<CF,ZF,NF,VF,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13,X14,X15,X16,X17,X21,Q0,Q1,Q2,Q3,Q4,Q5,Q6,Q7,Q16,Q17,Q18,Q19,Q20,Q21,Q22,Q23,Q24,Q25,Q26,Q27,Q28,Q29,Q30,Q31> HandPoseClassifierTrainingSessionDelegate.transitionTo(phase:)(CreateML::MLPhase phase)
{
  uint64_t v2 = v1;
  uint64_t v3 = (unsigned char *)phase;
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
  uint64_t v5 = OUTLINED_FUNCTION_17(v4);
  MEMORY[0x270FA5388](v5);
  OUTLINED_FUNCTION_15();
  if (*v3 != 2) {
    return;
  }
  uint64_t v6 = v1 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingParameters;
  OUTLINED_FUNCTION_53();
  outlined init with copy of URL?(v6, v1, &demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
  uint64_t v7 = type metadata accessor for MLHandPoseClassifier.PersistentParameters();
  LODWORD(v6) = __swift_getEnumTagSinglePayload(v1, 1, v7);
  outlined destroy of URL?(v1, &demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
  if (v6 == 1)
  {
    __break(1u);
    return;
  }
  uint64_t v8 = v1 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingFeatures;
  OUTLINED_FUNCTION_53();
  uint64_t v9 = *(void **)v8;
  LOBYTE(v8) = *(unsigned char *)(v8 + 8);
  outlined copy of Result<_DataTable, Error>(v9, v8);
  OUTLINED_FUNCTION_25_15();
  specialized MLDataTable.subscript.getter(v8, v10);
  outlined consume of Result<_DataTable, Error>(v9, v8);
  specialized MLDataColumn.dropDuplicates()(v18, v19, (uint64_t)&v20);
  outlined consume of Result<_DataTable, Error>(v18, v19);
  uint64_t v11 = specialized Array<A>.init(_:)(v20, v21);
  uint64_t v12 = OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_classLabels;
  *(void *)(v2 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_classLabels) = v11;
  swift_bridgeObjectRelease();
  if (!*(void *)(v2 + v12))
  {
    lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    OUTLINED_FUNCTION_85();
    uint64_t v17 = 0xD00000000000002ELL;
LABEL_10:
    OUTLINED_FUNCTION_19_0(v16, v17);
    return;
  }
  type metadata accessor for MLHandActionClassifier.GraphCNN(0);
  swift_allocObject();
  swift_bridgeObjectRetain_n();
  OUTLINED_FUNCTION_64_4();
  uint64_t v13 = OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_model;
  *(void *)(v2 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_model) = v14;
  swift_release();
  if (!*(void *)(v2 + v13))
  {
    swift_bridgeObjectRelease();
    lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    OUTLINED_FUNCTION_85();
    uint64_t v17 = 0xD00000000000003CLL;
    goto LABEL_10;
  }
  swift_retain();
  MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel()();
  if (!v15) {
    MLHandActionClassifier.GraphCNN.initDevice()();
  }
  swift_bridgeObjectRelease();
  swift_release();
}

Swift::tuple_Int_metrics_OpaquePointer_finished_Bool __swiftcall __spoils<CF,ZF,NF,VF,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13,X14,X15,X16,X17,X21,Q0,Q1,Q2,Q3,Q4,Q5,Q6,Q7,Q16,Q17,Q18,Q19,Q20,Q21,Q22,Q23,Q24,Q25,Q26,Q27,Q28,Q29,Q30,Q31> HandPoseClassifierTrainingSessionDelegate.train(from:)(Swift::Int from)
{
  uint64_t v86 = type metadata accessor for Tensor();
  OUTLINED_FUNCTION_0();
  uint64_t v85 = v4;
  MEMORY[0x270FA5388](v5);
  OUTLINED_FUNCTION_33_0();
  uint64_t v84 = v6;
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Dataset<[(label: Int, keypoints: MLMultiArray)], DataSample<Tensor, Tensor>>?);
  uint64_t v8 = OUTLINED_FUNCTION_17(v7);
  MEMORY[0x270FA5388](v8);
  OUTLINED_FUNCTION_33_0();
  uint64_t v93 = v9;
  uint64_t v91 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Dataset<[(label: Int, keypoints: MLMultiArray)], DataSample<Tensor, Tensor>>);
  OUTLINED_FUNCTION_0();
  uint64_t v90 = v10;
  MEMORY[0x270FA5388](v11);
  OUTLINED_FUNCTION_33_0();
  uint64_t v96 = v12;
  uint64_t v13 = (int *)type metadata accessor for MLHandActionClassifier.ModelParameters(0);
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v14);
  OUTLINED_FUNCTION_33_0();
  uint64_t v94 = v15;
  uint64_t v16 = (int *)type metadata accessor for MLHandPoseClassifier.PersistentParameters();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v17);
  OUTLINED_FUNCTION_27_7();
  uint64_t v18 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
  uint64_t v19 = OUTLINED_FUNCTION_17(v18);
  MEMORY[0x270FA5388](v19);
  char v21 = (char *)v82 - ((v20 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v22 = (int *)type metadata accessor for MLHandPoseClassifier.ModelParameters(0);
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v23);
  OUTLINED_FUNCTION_33();
  char v26 = (void *)(v24 - v25);
  MEMORY[0x270FA5388](v27);
  OUTLINED_FUNCTION_106();
  uint64_t v95 = v28;
  uint64_t v29 = v1 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sessionParameters;
  Swift::Int ML20MLHandPoseClassifierV10DataSourceOWOhTm_0 = type metadata accessor for MLTrainingSessionParameters();
  Swift::Int v33 = *(void *)(v29 + *(int *)(ML20MLHandPoseClassifierV10DataSourceOWOhTm_0 + 20));
  if (__OFADD__(from, v33))
  {
    __break(1u);
    goto LABEL_40;
  }
  Swift::Int v34 = *(void *)(v29 + *(int *)(ML20MLHandPoseClassifierV10DataSourceOWOhTm_0 + 28));
  if (__OFSUB__(v34, from))
  {
LABEL_40:
    __break(1u);
LABEL_41:
    __break(1u);
LABEL_42:
    __break(1u);
    goto LABEL_43;
  }
  Swift::Int v89 = from;
  Swift::Int v87 = v34;
  Swift::Int v88 = from + v33;
  if (v33 >= v34 - from) {
    Swift::Int v35 = v34 - from;
  }
  else {
    Swift::Int v35 = v33;
  }
  uint64_t v36 = v1 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingParameters;
  OUTLINED_FUNCTION_53();
  outlined init with copy of URL?(v36, (uint64_t)v21, &demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
  if (!__swift_getEnumTagSinglePayload((uint64_t)v21, 1, (uint64_t)v16))
  {
    Swift::Int v83 = v35;
    outlined init with copy of MLHandPoseClassifier.DataSource((uint64_t)v21, v2, (void (*)(void))type metadata accessor for MLHandPoseClassifier.PersistentParameters);
    outlined destroy of URL?((uint64_t)v21, &demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
    outlined init with copy of MLHandPoseClassifier.DataSource(v2 + v16[5], (uint64_t)v26, (void (*)(void))type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData);
    uint64_t v39 = *(void *)(v2 + v16[7]);
    uint64_t v40 = *(void *)(v2 + v16[8]);
    *(void *)((char *)v26 + v22[5]) = *(void *)(v2 + v16[6]);
    *(void *)((char *)v26 + v22[6]) = v39;
    *(void *)((char *)v26 + v22[7]) = v40;
    _s8CreateML20MLHandPoseClassifierV10DataSourceOWOhTm_0(v2, (void (*)(void))type metadata accessor for MLHandPoseClassifier.PersistentParameters);
    uint64_t v41 = v95;
    outlined init with take of MLHandPoseClassifier.PersistentParameters((uint64_t)v26, v95, (void (*)(void))type metadata accessor for MLHandPoseClassifier.ModelParameters);
    uint64_t v42 = *(void *)(v1 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_model);
    if (!v42
      || (uint64_t v43 = v1,
          (uint64_t v44 = *(void **)(v1 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_classLabels)) == 0))
    {
      swift_bridgeObjectRelease();
      lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
      OUTLINED_FUNCTION_85();
      OUTLINED_FUNCTION_26_10();
      OUTLINED_FUNCTION_19_0(v57, v56 + 42);
      Swift::Int ML20MLHandPoseClassifierV10DataSourceOWOhTm_0 = _s8CreateML20MLHandPoseClassifierV10DataSourceOWOhTm_0(v41, (void (*)(void))type metadata accessor for MLHandPoseClassifier.ModelParameters);
      goto LABEL_13;
    }
    uint64_t v45 = *(void *)(v41 + v22[7]);
    uint64_t v46 = *(void *)(v41 + v22[5]);
    uint64_t v47 = *(void *)(v41 + v22[6]);
    uint64_t v48 = (uint64_t)v94;
    void *v94 = 0;
    *(void *)(v48 + 8) = 0;
    *(_WORD *)(v48 + 16) = 256;
    uint64_t v49 = v42;
    uint64_t v50 = v44;
    type metadata accessor for MLHandActionClassifier.ModelParameters.ValidationData(0);
    swift_storeEnumTagMultiPayload();
    *(void *)(v48 + v13[5]) = v46;
    *(void *)(v48 + v13[6]) = v47;
    *(void *)(v48 + v13[7]) = 1;
    *(void *)(v48 + v13[8]) = v45;
    *(void *)(v48 + v13[10]) = 0x403E000000000000;
    v1 += OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingFeatures;
    OUTLINED_FUNCTION_53();
    char v26 = *(void **)v1;
    LOBYTE(v1) = *(unsigned char *)(v1 + 8);
    *(void *)&long long v97 = v26;
    BYTE8(v97) = v1;
    uint64_t v51 = v43 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_validationFeatures;
    OUTLINED_FUNCTION_53();
    uint64_t v52 = *(void **)v51;
    char v53 = *(unsigned char *)(v51 + 8);
    uint64_t v99 = v52;
    char v100 = v53;
    v82[1] = v49;
    swift_retain();
    swift_bridgeObjectRetain();
    outlined copy of Result<_DataTable, Error>(v26, v1);
    outlined copy of Result<_DataTable, Error>(v52, v53);
    uint64_t v54 = v92;
    uint64_t v55 = v93;
    static MLHandActionClassifier.prepareDataset(classLabels:trainingFeatures:validationFeatures:parameters:)(v96, v93, v50, (uint64_t)&v97, (uint64_t)&v99, v48);
    if (v54)
    {
      swift_bridgeObjectRelease();
      swift_release();
      outlined consume of Result<_DataTable, Error>(v52, v53);
      outlined consume of Result<_DataTable, Error>(v26, v1);
      _s8CreateML20MLHandPoseClassifierV10DataSourceOWOhTm_0(v48, (void (*)(void))type metadata accessor for MLHandActionClassifier.ModelParameters);
      _s8CreateML20MLHandPoseClassifierV10DataSourceOWOhTm_0(v95, (void (*)(void))type metadata accessor for MLHandPoseClassifier.ModelParameters);
      Swift::Int ML20MLHandPoseClassifierV10DataSourceOWOhTm_0 = swift_bridgeObjectRelease();
      goto LABEL_13;
    }
    char v92 = v50;
    outlined consume of Result<_DataTable, Error>(v52, v53);
    outlined consume of Result<_DataTable, Error>(v26, v1);
    Swift::Int v58 = v83;
    if (v83 < 0)
    {
LABEL_43:
      __break(1u);
      goto LABEL_44;
    }
    uint64_t v59 = &unk_268176000;
    Swift::Int v60 = v89;
    if (v83)
    {
      uint64_t v61 = 0;
      uint64_t v62 = OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_metricsAttributesDictionary;
      while (v58 != v61)
      {
        Swift::Int v32 = v60 + v61;
        if (__OFADD__(v60, v61)) {
          goto LABEL_42;
        }
        ++v61;
        *(void *)(v43 + v62) = MLHandActionClassifier.GraphCNN.iterateTraining(trainingData:validationData:epochCount:)(v96, v55, v32);
        Swift::Int ML20MLHandPoseClassifierV10DataSourceOWOhTm_0 = swift_bridgeObjectRelease();
        Swift::Int v58 = v83;
        if (v83 == v61) {
          goto LABEL_20;
        }
      }
      goto LABEL_41;
    }
LABEL_20:
    OUTLINED_FUNCTION_62_4();
    uint64_t v63 = OUTLINED_FUNCTION_155();
    specialized Dictionary.subscript.getter(v63, 0xED000073736F6C5FLL, (uint64_t)&unk_268176000, v64);
    swift_bridgeObjectRelease();
    if (v98)
    {
      if (OUTLINED_FUNCTION_18_11())
      {
        double v65 = *(double *)&v99;
        uint64_t v59 = (void *)MEMORY[0x263F8EE80];
        char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native();
        *(void *)&long long v97 = v59;
        specialized _NativeDictionary.setValue(_:forKey:isUnique:)(0, isUniquelyReferenced_nonNull_native, v65);
        uint64_t v67 = (void *)v97;
        swift_bridgeObjectRelease();
LABEL_25:
        OUTLINED_FUNCTION_62_4();
        specialized Dictionary.subscript.getter(0x69746164696C6176, 0xEF73736F6C5F6E6FLL, (uint64_t)v59, &v97);
        swift_bridgeObjectRelease();
        if (v98)
        {
          if (OUTLINED_FUNCTION_18_11())
          {
            swift_isUniquelyReferenced_nonNull_native();
            double v68 = OUTLINED_FUNCTION_27_9();
            specialized _NativeDictionary.setValue(_:forKey:isUnique:)(4, v69, v68);
            uint64_t v67 = (void *)v97;
            swift_bridgeObjectRelease();
          }
        }
        else
        {
          outlined destroy of URL?((uint64_t)&v97, &demangling cache variable for type metadata for Any?);
        }
        OUTLINED_FUNCTION_62_4();
        specialized Dictionary.subscript.getter(0xD000000000000012, 0x80000002272D4230, (uint64_t)v59, &v97);
        swift_bridgeObjectRelease();
        if (v98)
        {
          type metadata accessor for _MetricUtilities.ConfusionMatrixMeter();
          if (OUTLINED_FUNCTION_18_11())
          {
            uint64_t v59 = v99;
            uint64_t v70 = v84;
            _MetricUtilities.ConfusionMatrixMeter.value(normalized:)();
            static _MetricUtilities.top1Accuracy(confusionMatrix:classCount:)(v70, v92[2]);
            (*(void (**)(uint64_t, uint64_t))(v85 + 8))(v70, v86);
            swift_isUniquelyReferenced_nonNull_native();
            double v71 = OUTLINED_FUNCTION_27_9();
            specialized _NativeDictionary.setValue(_:forKey:isUnique:)(3, v72, v71);
            uint64_t v67 = (void *)v97;
            swift_release();
            swift_bridgeObjectRelease();
          }
        }
        else
        {
          outlined destroy of URL?((uint64_t)&v97, &demangling cache variable for type metadata for Any?);
        }
        OUTLINED_FUNCTION_62_4();
        specialized Dictionary.subscript.getter(0xD000000000000014, 0x80000002272D4280, (uint64_t)v59, &v97);
        swift_bridgeObjectRelease();
        if (v98)
        {
          type metadata accessor for _MetricUtilities.ConfusionMatrixMeter();
          char v73 = OUTLINED_FUNCTION_18_11();
          uint64_t v74 = v93;
          if (v73)
          {
            uint64_t v75 = v84;
            _MetricUtilities.ConfusionMatrixMeter.value(normalized:)();
            uint64_t v76 = v92[2];
            swift_bridgeObjectRelease();
            static _MetricUtilities.top1Accuracy(confusionMatrix:classCount:)(v75, v76);
            OUTLINED_FUNCTION_3_25();
            OUTLINED_FUNCTION_25_0();
            v77();
            swift_isUniquelyReferenced_nonNull_native();
            double v78 = OUTLINED_FUNCTION_27_9();
            specialized _NativeDictionary.setValue(_:forKey:isUnique:)(5, v79, v78);
            uint64_t v67 = (void *)v97;
            swift_release();
          }
          swift_bridgeObjectRelease();
        }
        else
        {
          swift_bridgeObjectRelease();
          outlined destroy of URL?((uint64_t)&v97, &demangling cache variable for type metadata for Any?);
          uint64_t v74 = v93;
        }
        uint64_t v80 = (uint64_t)v94;
        LOBYTE(v1) = v88 >= v87;
        char v26 = specialized _dictionaryUpCast<A, B, C, D>(_:)(v67);
        swift_bridgeObjectRelease();
        swift_release();
        outlined destroy of URL?(v74, &demangling cache variable for type metadata for Dataset<[(label: Int, keypoints: MLMultiArray)], DataSample<Tensor, Tensor>>?);
        OUTLINED_FUNCTION_3_25();
        OUTLINED_FUNCTION_25_0();
        v81();
        _s8CreateML20MLHandPoseClassifierV10DataSourceOWOhTm_0(v80, (void (*)(void))type metadata accessor for MLHandActionClassifier.ModelParameters);
        _s8CreateML20MLHandPoseClassifierV10DataSourceOWOhTm_0(v95, (void (*)(void))type metadata accessor for MLHandPoseClassifier.ModelParameters);
        Swift::Int ML20MLHandPoseClassifierV10DataSourceOWOhTm_0 = v83;
        goto LABEL_13;
      }
    }
    else
    {
      outlined destroy of URL?((uint64_t)&v97, &demangling cache variable for type metadata for Any?);
    }
    uint64_t v67 = (void *)MEMORY[0x263F8EE80];
    goto LABEL_25;
  }
  outlined destroy of URL?((uint64_t)v21, &demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
  swift_bridgeObjectRelease();
  lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  OUTLINED_FUNCTION_85();
  OUTLINED_FUNCTION_26_10();
  Swift::Int ML20MLHandPoseClassifierV10DataSourceOWOhTm_0 = OUTLINED_FUNCTION_19_0(v38, v37 + 20);
LABEL_13:
  LOBYTE(v32) = v1 & 1;
  uint64_t v31 = v26;
LABEL_44:
  result.BOOL finished = v32;
  result.metrics._rawValue = v31;
  result._0 = ML20MLHandPoseClassifierV10DataSourceOWOhTm_0;
  return result;
}

Swift::tuple_Int_finished_Bool __swiftcall __spoils<CF,ZF,NF,VF,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13,X14,X15,X16,X17,X21,Q0,Q1,Q2,Q3,Q4,Q5,Q6,Q7,Q16,Q17,Q18,Q19,Q20,Q21,Q22,Q23,Q24,Q25,Q26,Q27,Q28,Q29,Q30,Q31> HandPoseClassifierTrainingSessionDelegate.evaluate(from:)(Swift::Int from)
{
  Swift::Int v1 = 1;
  Swift::Bool v2 = 1;
  result._0 = v1;
  result.BOOL finished = v2;
  return result;
}

void HandPoseClassifierTrainingSessionDelegate.saveCheckpoint(to:phase:iteration:)()
{
  OUTLINED_FUNCTION_9_0();
  uint64_t v3 = v0;
  uint64_t v5 = v4;
  uint64_t v7 = v6;
  uint64_t v8 = type metadata accessor for URL();
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v9);
  OUTLINED_FUNCTION_33();
  uint64_t v11 = MEMORY[0x270FA5388](v10);
  MEMORY[0x270FA5388](v11);
  OUTLINED_FUNCTION_65_0();
  MEMORY[0x270FA5388](v12);
  uint64_t v17 = (char *)&v36 - v16;
  int v18 = *v5;
  if (v18 == 2)
  {
    if (*(void *)(v3 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_model))
    {
      swift_retain();
      specialized _ModelCheckpoint<>.save(to:)();
      swift_release();
    }
  }
  else if (v18 == 1)
  {
    uint64_t v92 = v15;
    uint64_t v38 = v13;
    uint64_t v39 = v14;
    uint64_t v19 = v3 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingFeatures;
    OUTLINED_FUNCTION_13_17();
    char v20 = *(unsigned char *)(v19 + 8);
    id v62 = *(id *)v19;
    LOBYTE(v63) = v20;
    outlined copy of Result<_DataTable, Error>(v62, v20);
    OUTLINED_FUNCTION_123();
    uint64_t v40 = v7;
    URL.appendingPathComponent(_:)();
    MLDataTable.write(to:)((uint64_t)v17);
    if (v1)
    {
      OUTLINED_FUNCTION_25_0();
      v21();
      outlined consume of Result<_DataTable, Error>(v62, v63);
    }
    else
    {
      uint64_t v37 = v19;
      (*(void (**)(char *, uint64_t))(v92 + 8))(v17, v8);
      outlined consume of Result<_DataTable, Error>(v62, v63);
      uint64_t v22 = v3 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_validationFeatures;
      OUTLINED_FUNCTION_13_17();
      char v23 = *(unsigned char *)(v22 + 8);
      id v90 = *(id *)v22;
      char v91 = v23;
      outlined copy of Result<_DataTable, Error>(v90, v23);
      OUTLINED_FUNCTION_33_8();
      URL.appendingPathComponent(_:)();
      MLDataTable.write(to:)(v2);
      uint64_t v36 = v22;
      uint64_t v24 = OUTLINED_FUNCTION_42_7();
      v25(v24);
      outlined consume of Result<_DataTable, Error>(v90, v91);
      char v26 = v39;
      OUTLINED_FUNCTION_123();
      URL.appendingPathComponent(_:)();
      char v86 = 1;
      LOBYTE(v62) = 1;
      *(_DWORD *)((char *)&v62 + 1) = *(_DWORD *)v89;
      HIDWORD(v62) = *(_DWORD *)&v89[3];
      uint64_t v63 = 44;
      unint64_t v64 = 0xE100000000000000;
      uint64_t v65 = 0;
      unint64_t v66 = 0xE000000000000000;
      uint64_t v67 = 92;
      unint64_t v68 = 0xE100000000000000;
      char v69 = 1;
      *(_DWORD *)uint64_t v70 = *(_DWORD *)v88;
      *(_DWORD *)&v70[3] = *(_DWORD *)&v88[3];
      uint64_t v71 = 34;
      unint64_t v72 = 0xE100000000000000;
      char v73 = 1;
      *(_DWORD *)uint64_t v74 = *(_DWORD *)v87;
      *(_DWORD *)&v74[3] = *(_DWORD *)&v87[3];
      uint64_t v75 = &outlined read-only object #0 of default argument 1 of MLDataTable.init(contentsOf:options:);
      uint64_t v76 = 10;
      unint64_t v77 = 0xE100000000000000;
      uint64_t v78 = 0;
      uint64_t v79 = 0;
      char v80 = 1;
      *(_DWORD *)char v81 = *(_DWORD *)v85;
      *(_DWORD *)&v81[3] = *(_DWORD *)&v85[3];
      uint64_t v82 = 0;
      MLDataTable.init(contentsOf:options:)(v26, &v62, (uint64_t)&v83);
      char v27 = v84;
      uint64_t v28 = v37;
      uint64_t v29 = *(void **)v37;
      char v30 = *(unsigned char *)(v37 + 8);
      *(void *)uint64_t v37 = v83;
      *(unsigned char *)(v28 + 8) = v27;
      outlined consume of Result<_DataTable, Error>(v29, v30);
      uint64_t v31 = v38;
      OUTLINED_FUNCTION_33_8();
      URL.appendingPathComponent(_:)();
      char v61 = 1;
      char v41 = 1;
      uint64_t v42 = 44;
      unint64_t v43 = 0xE100000000000000;
      uint64_t v44 = 0;
      unint64_t v45 = 0xE000000000000000;
      uint64_t v46 = 92;
      unint64_t v47 = 0xE100000000000000;
      char v48 = 1;
      uint64_t v49 = 34;
      unint64_t v50 = 0xE100000000000000;
      char v51 = 1;
      uint64_t v52 = &outlined read-only object #0 of default argument 1 of MLDataTable.init(contentsOf:options:);
      uint64_t v53 = 10;
      uint64_t v55 = 0;
      uint64_t v56 = 0;
      unint64_t v54 = 0xE100000000000000;
      char v57 = 1;
      uint64_t v58 = 0;
      MLDataTable.init(contentsOf:options:)(v31, &v41, (uint64_t)&v59);
      char v32 = v60;
      uint64_t v33 = v36;
      Swift::Int v34 = *(void **)v36;
      char v35 = *(unsigned char *)(v36 + 8);
      *(void *)uint64_t v36 = v59;
      *(unsigned char *)(v33 + 8) = v32;
      outlined consume of Result<_DataTable, Error>(v34, v35);
    }
  }
  OUTLINED_FUNCTION_8_1();
}

uint64_t HandPoseClassifierTrainingSessionDelegate.save(to:)(uint64_t a1)
{
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
  uint64_t v6 = OUTLINED_FUNCTION_17(v5);
  MEMORY[0x270FA5388](v6);
  uint64_t v7 = OUTLINED_FUNCTION_36_8();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v8);
  OUTLINED_FUNCTION_41_0();
  uint64_t v9 = v1 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingParameters;
  OUTLINED_FUNCTION_53();
  outlined init with copy of URL?(v9, v2, &demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
  if (__swift_getEnumTagSinglePayload(v2, 1, v7) == 1)
  {
    outlined destroy of URL?(v2, &demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
    lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    OUTLINED_FUNCTION_85();
    *(void *)uint64_t v10 = 0xD000000000000030;
    *(void *)(v10 + 8) = 0x80000002272D69A0;
    *(_OWORD *)(v10 + 16) = 0u;
    *(_OWORD *)(v10 + 32) = 0u;
    *(unsigned char *)(v10 + 48) = 2;
    return swift_willThrow();
  }
  else
  {
    outlined init with take of MLHandPoseClassifier.PersistentParameters(v2, v3, (void (*)(void))type metadata accessor for MLHandPoseClassifier.PersistentParameters);
    MLHandPoseClassifier.PersistentParameters.save(toSessionDirectory:)(a1);
    return _s8CreateML20MLHandPoseClassifierV10DataSourceOWOhTm_0(v3, (void (*)(void))type metadata accessor for MLHandPoseClassifier.PersistentParameters);
  }
}

void HandPoseClassifierTrainingSessionDelegate.restore(from:phase:)()
{
  OUTLINED_FUNCTION_9_0();
  uint64_t v25 = v0;
  uint64_t v5 = v4;
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
  uint64_t v7 = OUTLINED_FUNCTION_17(v6);
  MEMORY[0x270FA5388](v7);
  OUTLINED_FUNCTION_33();
  uint64_t v10 = v8 - v9;
  MEMORY[0x270FA5388](v11);
  OUTLINED_FUNCTION_59_6();
  MEMORY[0x270FA5388](v12);
  uint64_t v14 = (char *)&v25 - v13;
  uint64_t v15 = type metadata accessor for URL();
  OUTLINED_FUNCTION_0();
  uint64_t v17 = v16;
  MEMORY[0x270FA5388](v18);
  OUTLINED_FUNCTION_15();
  uint64_t v26 = type metadata accessor for MLHandPoseClassifier.PersistentParameters();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v19);
  OUTLINED_FUNCTION_33();
  OUTLINED_FUNCTION_65_0();
  MEMORY[0x270FA5388](v20);
  uint64_t v22 = (uint64_t *)((char *)&v25 - v21);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v17 + 16))(v0, v5, v15);
  MLHandPoseClassifier.PersistentParameters.init(sessionDirectory:)(v0, v22);
  if (!v1)
  {
    uint64_t v23 = v10;
    uint64_t v24 = v25 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingParameters;
    OUTLINED_FUNCTION_53();
    outlined init with copy of URL?(v24, (uint64_t)v14, &demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
    if (__swift_getEnumTagSinglePayload((uint64_t)v14, 1, v26) == 1)
    {
      outlined destroy of URL?((uint64_t)v14, &demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
      outlined init with take of MLHandPoseClassifier.PersistentParameters((uint64_t)v22, v2, (void (*)(void))type metadata accessor for MLHandPoseClassifier.PersistentParameters);
      __swift_storeEnumTagSinglePayload(v2, 0, 1, v26);
      outlined init with take of DataFrame?(v2, v23, &demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
      OUTLINED_FUNCTION_81_2();
      outlined assign with take of MLHandPoseClassifier.PersistentParameters?(v23, v24);
      swift_endAccess();
    }
    else
    {
      outlined init with take of MLHandPoseClassifier.PersistentParameters((uint64_t)v14, v3, (void (*)(void))type metadata accessor for MLHandPoseClassifier.PersistentParameters);
      OUTLINED_FUNCTION_30_9();
      HandPoseClassifierTrainingSessionDelegate.verifyThatParametersAreCompatible(_:_:)();
      _s8CreateML20MLHandPoseClassifierV10DataSourceOWOhTm_0(v3, (void (*)(void))type metadata accessor for MLHandPoseClassifier.PersistentParameters);
      _s8CreateML20MLHandPoseClassifierV10DataSourceOWOhTm_0((uint64_t)v22, (void (*)(void))type metadata accessor for MLHandPoseClassifier.PersistentParameters);
    }
  }
  OUTLINED_FUNCTION_8_1();
}

void HandPoseClassifierTrainingSessionDelegate.verifyThatParametersAreCompatible(_:_:)()
{
  OUTLINED_FUNCTION_9_0();
  uint64_t v3 = v2;
  uint64_t v5 = v4;
  uint64_t v141 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Zip2Sequence<AnyColumn, AnyColumn>);
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v6);
  OUTLINED_FUNCTION_33_0();
  uint64_t v142 = v7;
  uint64_t v8 = type metadata accessor for DataFrame();
  OUTLINED_FUNCTION_0();
  v150[0] = v9;
  MEMORY[0x270FA5388](v10);
  OUTLINED_FUNCTION_49();
  uint64_t v143 = v11;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v12);
  OUTLINED_FUNCTION_106();
  unint64_t v145 = v13;
  type metadata accessor for MLHandPoseClassifier.DataSource();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v14);
  OUTLINED_FUNCTION_49();
  uint64_t v144 = v15;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v16);
  OUTLINED_FUNCTION_65_0();
  uint64_t v18 = MEMORY[0x270FA5388](v17);
  uint64_t v20 = (char *)&v129 - v19;
  MEMORY[0x270FA5388](v18);
  uint64_t v22 = (char *)&v129 - v21;
  type metadata accessor for MLHandPoseClassifier.PersistentParameters();
  OUTLINED_FUNCTION_44_5();
  if (!v24)
  {
    id v148 = v23;
    lazy protocol witness table accessor for type Int and conformance Int();
    OUTLINED_FUNCTION_43_6();
    uint64_t v28 = OUTLINED_FUNCTION_24_12();
    uint64_t v30 = v29;
    lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    OUTLINED_FUNCTION_85();
    *(_OWORD *)uint64_t v31 = xmmword_2272CDF80;
LABEL_11:
    *(void *)(v31 + 16) = v3;
    *(void *)(v31 + 24) = v0;
    *(void *)(v31 + 32) = v28;
    *(void *)(v31 + 40) = v30;
    *(unsigned char *)(v31 + 48) = 3;
    swift_willThrow();
    goto LABEL_12;
  }
  OUTLINED_FUNCTION_44_5();
  if (!v24)
  {
    id v148 = v25;
    lazy protocol witness table accessor for type Int and conformance Int();
    OUTLINED_FUNCTION_43_6();
    uint64_t v28 = OUTLINED_FUNCTION_24_12();
    uint64_t v30 = v32;
    lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    OUTLINED_FUNCTION_85();
    OUTLINED_FUNCTION_26_10();
    Swift::Int v34 = "Maximum Iterations";
LABEL_10:
    *(void *)uint64_t v31 = v33;
    *(void *)(v31 + 8) = (unint64_t)(v34 - 32) | 0x8000000000000000;
    goto LABEL_11;
  }
  OUTLINED_FUNCTION_44_5();
  if (!v24)
  {
    id v148 = v26;
    lazy protocol witness table accessor for type Int and conformance Int();
    OUTLINED_FUNCTION_43_6();
    uint64_t v28 = OUTLINED_FUNCTION_24_12();
    uint64_t v30 = v35;
    lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    OUTLINED_FUNCTION_85();
    OUTLINED_FUNCTION_26_10();
    uint64_t v33 = v36 + 2;
    Swift::Int v34 = "Augmentation options";
    goto LABEL_10;
  }
  uint64_t v140 = v8;
  MLHandPoseClassifier.DataSource.imagesWithAnnotations()();
  if (!v0)
  {
    char v27 = v148;
    HIDWORD(v139) = v149;
    MLHandPoseClassifier.DataSource.imagesWithAnnotations()();
    id v137 = v27;
    id v138 = v148;
    id v148 = v27;
    int v37 = v149;
    unsigned __int8 v149 = BYTE4(v139);
    if (MLDataTable.size.getter() >= 1)
    {
      id v148 = v138;
      unsigned __int8 v149 = v37;
      if (MLDataTable.size.getter() >= 1)
      {
        id v38 = v137;
        id v148 = v137;
        char v39 = BYTE4(v139);
        unsigned __int8 v149 = BYTE4(v139);
        uint64_t v40 = HandPoseClassifierTrainingSessionDelegate.pathsByLabel(for:)((uint64_t)&v148);
        id v41 = v138;
        id v148 = v138;
        unsigned __int8 v149 = v37;
        uint64_t v42 = HandPoseClassifierTrainingSessionDelegate.pathsByLabel(for:)((uint64_t)&v148);
        specialized static Dictionary<>.== infix(_:_:)(v40, v42);
        char v44 = v43;
        swift_bridgeObjectRelease();
        swift_bridgeObjectRelease();
        if (v44)
        {
          outlined consume of Result<_DataTable, Error>(v38, v39);
          id v45 = v41;
          char v46 = v37;
        }
        else
        {
          lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
          uint64_t v89 = OUTLINED_FUNCTION_85();
          OUTLINED_FUNCTION_3_32(v89, v90);
          outlined consume of Result<_DataTable, Error>(v41, v37);
          id v45 = v38;
          char v46 = v39;
        }
LABEL_9:
        outlined consume of Result<_DataTable, Error>(v45, v46);
        goto LABEL_12;
      }
    }
    outlined init with copy of MLHandPoseClassifier.DataSource(v5, (uint64_t)v22, (void (*)(void))type metadata accessor for MLHandPoseClassifier.DataSource);
    if (swift_getEnumCaseMultiPayload() == 3)
    {
      HIDWORD(v136) = v37;
      unint64_t v47 = *(void **)v22;
      unsigned int v48 = v22[8];
      uint64_t v49 = (void *)*((void *)v22 + 3);
      uint64_t v131 = *((void *)v22 + 2);
      uint64_t v133 = *((void *)v22 + 4);
      uint64_t v134 = (void *)*((void *)v22 + 5);
      id v135 = v47;
      swift_bridgeObjectRelease();
      outlined init with copy of MLHandPoseClassifier.DataSource(v3, (uint64_t)v20, (void (*)(void))type metadata accessor for MLHandPoseClassifier.DataSource);
      if (swift_getEnumCaseMultiPayload() == 3)
      {
        uint64_t v132 = 0;
        unint64_t v50 = *(void **)v20;
        char v51 = v20[8];
        uint64_t v52 = (void *)*((void *)v20 + 3);
        uint64_t v144 = *((void *)v20 + 2);
        unint64_t v145 = v49;
        uint64_t v53 = *((void *)v20 + 4);
        unint64_t v54 = (void *)*((void *)v20 + 5);
        swift_bridgeObjectRelease();
        id v55 = v135;
        id v146 = v135;
        char v147 = v48;
        outlined copy of Result<_DataTable, Error>(v135, v48);
        uint64_t v56 = (uint64_t)v134;
        MLDataTable.subscript.getter(v133, v134, (uint64_t)&v148);
        swift_bridgeObjectRelease();
        char v151 = v48;
        OUTLINED_FUNCTION_7_21(v55, v48, v57, v58, v59, v60, v61, v62, v129, v130, v131, v132, v133, (uint64_t)v134, (uint64_t)v135, v136, (uint64_t)v137, (uint64_t)v138, v139,
          v140,
          v141,
          v142,
          v143,
          v144);
        OUTLINED_FUNCTION_58_4();
        MLDataTable.subscript.getter(v53, v54, v63);
        swift_bridgeObjectRelease();
        OUTLINED_FUNCTION_7_21(v50, v51, v64, v65, v66, v67, v68, v69, v129, v130, v131, v132, v133, (uint64_t)v134, (uint64_t)v135, v136, (uint64_t)v137, (uint64_t)v138, v139,
          v140,
          v141,
          v142,
          v143,
          v144);
        char v71 = specialized static Array<A>.== infix(_:_:)(v56, v70);
        swift_bridgeObjectRelease();
        swift_bridgeObjectRelease();
        if (v71)
        {
          id v72 = v135;
          id v146 = v135;
          char v147 = v48;
          outlined copy of Result<_DataTable, Error>(v135, v48);
          MLDataTable.subscript.getter(v131, v145, (uint64_t)&v148);
          swift_bridgeObjectRelease();
          OUTLINED_FUNCTION_7_21(v72, v48, v73, v74, v75, v76, v77, v78, v129, v130, v131, v132, v133, (uint64_t)v134, (uint64_t)v135, v136, (uint64_t)v137, (uint64_t)v138, v139,
            v140,
            v141,
            v142,
            v143,
            v144);
          OUTLINED_FUNCTION_58_4();
          MLDataTable.subscript.getter(v144, v52, v79);
          swift_bridgeObjectRelease();
          OUTLINED_FUNCTION_7_21(v50, v51, v80, v81, v82, v83, v84, v85, v129, v130, v131, v132, v133, (uint64_t)v134, (uint64_t)v135, v136, (uint64_t)v137, (uint64_t)v138, v139,
            v140,
            v141,
            v142,
            v143,
            v144);
          char v87 = specialized static Array<A>.== infix(_:_:)(v48, v86);
          swift_bridgeObjectRelease();
          swift_bridgeObjectRelease();
          if (v87)
          {
            outlined consume of Result<_DataTable, Error>(v137, SBYTE4(v139));
            outlined consume of Result<_DataTable, Error>(v138, SBYTE4(v136));
            outlined consume of Result<_DataTable, Error>(v50, v51);
            outlined consume of Result<_DataTable, Error>(v135, v151);
            goto LABEL_12;
          }
        }
        else
        {
          swift_bridgeObjectRelease();
          swift_bridgeObjectRelease();
        }
        lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
        uint64_t v123 = OUTLINED_FUNCTION_85();
        OUTLINED_FUNCTION_3_32(v123, v124);
        outlined consume of Result<_DataTable, Error>(v50, v51);
        outlined consume of Result<_DataTable, Error>(v135, v151);
        outlined consume of Result<_DataTable, Error>(v138, SBYTE4(v136));
        id v45 = v137;
        char v46 = BYTE4(v139);
        goto LABEL_9;
      }
      outlined consume of Result<_DataTable, Error>(v135, v48);
      swift_bridgeObjectRelease();
      swift_bridgeObjectRelease();
      char v88 = BYTE4(v139);
      int v37 = HIDWORD(v136);
    }
    else
    {
      uint64_t v20 = v22;
      char v88 = BYTE4(v139);
    }
    _s8CreateML20MLHandPoseClassifierV10DataSourceOWOhTm_0((uint64_t)v20, (void (*)(void))type metadata accessor for MLHandPoseClassifier.DataSource);
    outlined init with copy of MLHandPoseClassifier.DataSource(v5, v1, (void (*)(void))type metadata accessor for MLHandPoseClassifier.DataSource);
    if (swift_getEnumCaseMultiPayload() == 5)
    {
      HIDWORD(v136) = v37;
      uint64_t v91 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
      uint64_t v92 = (uint64_t *)(v1 + *(int *)(v91 + 48));
      uint64_t v93 = (void *)v92[1];
      uint64_t v131 = *v92;
      uint64_t v94 = (uint64_t *)(v1 + *(int *)(v91 + 64));
      uint64_t v96 = *v94;
      uint64_t v95 = (void *)v94[1];
      uint64_t v133 = v96;
      uint64_t v134 = v93;
      id v135 = v95;
      swift_bridgeObjectRelease();
      long long v97 = *(void (**)(uint64_t))(v150[0] + 32);
      uint64_t v98 = OUTLINED_FUNCTION_30_9();
      uint64_t v99 = v140;
      v97(v98);
      uint64_t v100 = v3;
      uint64_t v101 = v144;
      outlined init with copy of MLHandPoseClassifier.DataSource(v100, v144, (void (*)(void))type metadata accessor for MLHandPoseClassifier.DataSource);
      if (swift_getEnumCaseMultiPayload() == 5)
      {
        uint64_t v102 = (uint64_t *)(v101 + *(int *)(v91 + 48));
        uint64_t v104 = *v102;
        uint64_t v103 = v102[1];
        uint64_t v129 = v104;
        uint64_t v130 = v103;
        uint64_t v105 = (uint64_t *)(v101 + *(int *)(v91 + 64));
        uint64_t v132 = 0;
        uint64_t v106 = *v105;
        uint64_t v107 = v105[1];
        swift_bridgeObjectRelease();
        uint64_t v108 = v143;
        ((void (*)(uint64_t, uint64_t, uint64_t))v97)(v143, v101, v99);
        uint64_t v109 = v142;
        MEMORY[0x22A672220](v133, v135);
        swift_bridgeObjectRelease();
        MEMORY[0x22A672220](v106, v107);
        swift_bridgeObjectRelease();
        specialized Sequence.allSatisfy(_:)();
        char v111 = v110;
        outlined destroy of URL?(v109, &demangling cache variable for type metadata for Zip2Sequence<AnyColumn, AnyColumn>);
        if (v111)
        {
          MEMORY[0x22A672220](v131, v134);
          swift_bridgeObjectRelease();
          MEMORY[0x22A672220](v129, v130);
          swift_bridgeObjectRelease();
          specialized Sequence.allSatisfy(_:)();
          uint64_t v112 = v109;
          char v114 = v113;
          outlined destroy of URL?(v112, &demangling cache variable for type metadata for Zip2Sequence<AnyColumn, AnyColumn>);
          char v115 = BYTE4(v136);
          id v116 = v138;
          if ((v114 & 1) == 0)
          {
            lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
            uint64_t v117 = OUTLINED_FUNCTION_85();
            OUTLINED_FUNCTION_3_32(v117, v118);
          }
          outlined consume of Result<_DataTable, Error>(v116, v115);
          OUTLINED_FUNCTION_32_9();
          unint64_t v119 = *(void (**)(void))(v150[0] + 8);
          OUTLINED_FUNCTION_5_4();
          v119();
          OUTLINED_FUNCTION_5_4();
          v119();
        }
        else
        {
          swift_bridgeObjectRelease();
          swift_bridgeObjectRelease();
          lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
          uint64_t v125 = OUTLINED_FUNCTION_85();
          OUTLINED_FUNCTION_3_32(v125, v126);
          outlined consume of Result<_DataTable, Error>(v138, SBYTE4(v136));
          outlined consume of Result<_DataTable, Error>(v137, SBYTE4(v139));
          char v127 = *(void (**)(uint64_t, uint64_t))(v150[0] + 8);
          v127(v108, v99);
          uint64_t v128 = OUTLINED_FUNCTION_30_9();
          ((void (*)(uint64_t))v127)(v128);
        }
        goto LABEL_12;
      }
      uint64_t v121 = OUTLINED_FUNCTION_30_9();
      v122(v121);
      outlined consume of Result<_DataTable, Error>(v137, SBYTE4(v139));
      outlined consume of Result<_DataTable, Error>(v138, SBYTE4(v136));
      swift_bridgeObjectRelease();
      swift_bridgeObjectRelease();
      uint64_t v120 = v101;
    }
    else
    {
      outlined consume of Result<_DataTable, Error>(v137, v88);
      outlined consume of Result<_DataTable, Error>(v138, v37);
      uint64_t v120 = v1;
    }
    _s8CreateML20MLHandPoseClassifierV10DataSourceOWOhTm_0(v120, (void (*)(void))type metadata accessor for MLHandPoseClassifier.DataSource);
  }
LABEL_12:
  OUTLINED_FUNCTION_8_1();
}

uint64_t closure #1 in HandPoseClassifierTrainingSessionDelegate.verifyThatParametersAreCompatible(_:_:)(uint64_t a1, uint64_t a2)
{
  outlined init with copy of URL?(a1, (uint64_t)v9, &demangling cache variable for type metadata for Any?);
  if (v10)
  {
    if ((swift_dynamicCast() & 1) == 0)
    {
      uint64_t v19 = 0;
      long long v17 = 0u;
      long long v18 = 0u;
    }
  }
  else
  {
    outlined destroy of URL?((uint64_t)v9, &demangling cache variable for type metadata for Any?);
    long long v17 = 0u;
    long long v18 = 0u;
    uint64_t v19 = 0;
  }
  outlined init with copy of URL?(a2, (uint64_t)v9, &demangling cache variable for type metadata for Any?);
  if (v10)
  {
    if ((swift_dynamicCast() & 1) == 0)
    {
      uint64_t v16 = 0;
      long long v14 = 0u;
      long long v15 = 0u;
    }
  }
  else
  {
    outlined destroy of URL?((uint64_t)v9, &demangling cache variable for type metadata for Any?);
    long long v14 = 0u;
    long long v15 = 0u;
    uint64_t v16 = 0;
  }
  outlined init with copy of URL?((uint64_t)&v17, (uint64_t)v9, &demangling cache variable for type metadata for AnyHashable?);
  outlined init with copy of URL?((uint64_t)&v14, (uint64_t)&v11, &demangling cache variable for type metadata for AnyHashable?);
  if (v10)
  {
    outlined init with copy of URL?((uint64_t)v9, (uint64_t)v8, &demangling cache variable for type metadata for AnyHashable?);
    if (*((void *)&v12 + 1))
    {
      v6[0] = v11;
      v6[1] = v12;
      uint64_t v7 = v13;
      char v3 = MEMORY[0x22A6752B0](v8, v6);
      outlined destroy of AnyHashable((uint64_t)v6);
      outlined destroy of AnyHashable((uint64_t)v8);
      uint64_t v4 = &demangling cache variable for type metadata for AnyHashable?;
    }
    else
    {
      outlined destroy of AnyHashable((uint64_t)v8);
      char v3 = 0;
      uint64_t v4 = (uint64_t *)&demangling cache variable for type metadata for (AnyHashable?, AnyHashable?);
    }
  }
  else
  {
    if (*((void *)&v12 + 1)) {
      uint64_t v4 = (uint64_t *)&demangling cache variable for type metadata for (AnyHashable?, AnyHashable?);
    }
    else {
      uint64_t v4 = &demangling cache variable for type metadata for AnyHashable?;
    }
    if (*((void *)&v12 + 1)) {
      char v3 = 0;
    }
    else {
      char v3 = -1;
    }
  }
  outlined destroy of URL?((uint64_t)v9, v4);
  outlined destroy of URL?((uint64_t)&v14, &demangling cache variable for type metadata for AnyHashable?);
  outlined destroy of URL?((uint64_t)&v17, &demangling cache variable for type metadata for AnyHashable?);
  return v3 & 1;
}

uint64_t HandPoseClassifierTrainingSessionDelegate.pathsByLabel(for:)(uint64_t a1)
{
  uint64_t v1 = *(void **)a1;
  char v2 = *(unsigned char *)(a1 + 8);
  unsigned int v48 = v1;
  char v49 = v2;
  outlined copy of Result<_DataTable, Error>(v1, v2);
  MLDataTable.subscript.getter(0x7461506F65646976, (void *)0xE900000000000068, (uint64_t)&v45);
  char v3 = v45;
  char v4 = (char)v46;
  if ((v46 & 1) != 0
    || (outlined copy of Result<_DataTable, Error>(v45, 0),
        _UntypedColumn.type.getter(&v48),
        OUTLINED_FUNCTION_61_6(),
        v48 != 2))
  {
    outlined consume of Result<_DataTable, Error>(v3, v4);
    char v39 = v1;
    char v40 = v2;
LABEL_31:
    outlined consume of Result<_DataTable, Error>(v39, v40);
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String]);
    return Dictionary.init(dictionaryLiteral:)();
  }
  outlined consume of Result<_DataTable, Error>(v1, v2);
  unsigned int v48 = v1;
  char v49 = v2;
  outlined copy of Result<_DataTable, Error>(v1, v2);
  uint64_t v5 = OUTLINED_FUNCTION_25_15();
  MLDataTable.subscript.getter(v5, v6, v7);
  uint64_t v8 = v45;
  char v9 = (char)v46;
  if ((v46 & 1) != 0
    || (outlined copy of Result<_DataTable, Error>(v45, 0),
        _UntypedColumn.type.getter(&v48),
        outlined consume of Result<_DataTable, Error>(v8, 0),
        v48 != 2))
  {
    outlined consume of Result<_DataTable, Error>(v8, v9);
    outlined consume of Result<_DataTable, Error>(v1, v2);
    char v39 = v3;
    char v40 = 0;
    goto LABEL_31;
  }
  char v43 = v8;
  outlined consume of Result<_DataTable, Error>(v1, v2);
  outlined copy of Result<_DataTable, Error>(v3, 0);
  uint64_t v10 = CMLColumn.size.getter();
  OUTLINED_FUNCTION_61_6();
  if (v10 < 0)
  {
LABEL_38:
    __break(1u);
LABEL_39:
    uint64_t result = KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)();
    __break(1u);
    return result;
  }
  long long v11 = 0;
  if (v10)
  {
    uint64_t v12 = 0;
    uint64_t v13 = (void *)MEMORY[0x263F8EE80];
    uint64_t v42 = v10;
    while (v10 != v12)
    {
      outlined copy of Result<_DataTable, Error>(v8, 0);
      _UntypedColumn.valueAtIndex(index:)(v12, (uint64_t)&v45);
      uint64_t v14 = (uint64_t)v45;
      uint64_t v15 = (uint64_t)v46;
      if (v47 != 2)
      {
        outlined consume of MLDataValue(v45, v46, v47);
        uint64_t v14 = 0;
        uint64_t v15 = 0xE000000000000000;
      }
      outlined consume of Result<_DataTable, Error>(v8, 0);
      outlined copy of Result<_DataTable, Error>(v3, 0);
      _UntypedColumn.valueAtIndex(index:)(v12, (uint64_t)&v45);
      if (v47 == 2)
      {
        unint64_t v44 = (unint64_t)v46;
        unint64_t v50 = v45;
      }
      else
      {
        outlined consume of MLDataValue(v45, v46, v47);
        unint64_t v50 = 0;
        unint64_t v44 = 0xE000000000000000;
      }
      uint64_t v16 = v3;
      OUTLINED_FUNCTION_61_6();
      outlined consume of (@escaping @callee_guaranteed @Sendable (@in_guaranteed Event) -> ())?((uint64_t)v11);
      char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native();
      id v45 = v13;
      unint64_t v18 = specialized __RawDictionaryStorage.find<A>(_:)(v14, v15);
      uint64_t v20 = v13[2];
      BOOL v21 = (v19 & 1) == 0;
      Swift::Int v22 = v20 + v21;
      if (__OFADD__(v20, v21)) {
        goto LABEL_36;
      }
      unint64_t v23 = v18;
      char v24 = v19;
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, [String]>);
      Swift::Bool v25 = _NativeDictionary.ensureUnique(isUnique:capacity:)(isUniquelyReferenced_nonNull_native, v22);
      uint64_t v13 = v45;
      if (v25)
      {
        unint64_t v26 = specialized __RawDictionaryStorage.find<A>(_:)(v14, v15);
        if ((v24 & 1) != (v27 & 1)) {
          goto LABEL_39;
        }
        unint64_t v23 = v26;
      }
      swift_bridgeObjectRelease();
      if ((v24 & 1) == 0)
      {
        v13[(v23 >> 6) + 8] |= 1 << v23;
        uint64_t v28 = (uint64_t *)(v13[6] + 16 * v23);
        *uint64_t v28 = v14;
        v28[1] = v15;
        *(void *)(v13[7] + 8 * v23) = MEMORY[0x263F8EE78];
        uint64_t v29 = v13[2];
        uint64_t v30 = v29 + 1;
        BOOL v31 = __OFADD__(v29, 1);
        swift_bridgeObjectRetain();
        if (v31) {
          goto LABEL_37;
        }
        void v13[2] = v30;
      }
      swift_bridgeObjectRetain();
      uint64_t v32 = v13[7];
      swift_bridgeObjectRelease();
      uint64_t v33 = *(void *)(v32 + 8 * v23);
      char v34 = swift_isUniquelyReferenced_nonNull_native();
      *(void *)(v32 + 8 * v23) = v33;
      if ((v34 & 1) == 0)
      {
        specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
        uint64_t v33 = v37;
        *(void *)(v32 + 8 * v23) = v37;
      }
      unint64_t v35 = *(void *)(v33 + 16);
      if (v35 >= *(void *)(v33 + 24) >> 1)
      {
        specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
        uint64_t v33 = v38;
        *(void *)(v32 + 8 * v23) = v38;
      }
      ++v12;
      *(void *)(v33 + 16) = v35 + 1;
      uint64_t v36 = v33 + 16 * v35;
      *(void *)(v36 + 32) = v50;
      *(void *)(v36 + 40) = v44;
      swift_bridgeObjectRelease();
      long long v11 = specialized thunk for @callee_guaranteed () -> (@owned [URL]);
      uint64_t v10 = v42;
      uint64_t v8 = v43;
      char v3 = v16;
      if (v42 == v12) {
        goto LABEL_34;
      }
    }
    __break(1u);
LABEL_36:
    __break(1u);
LABEL_37:
    __break(1u);
    goto LABEL_38;
  }
  uint64_t v13 = (void *)MEMORY[0x263F8EE80];
LABEL_34:
  OUTLINED_FUNCTION_61_6();
  outlined consume of Result<_DataTable, Error>(v8, 0);
  outlined consume of (@escaping @callee_guaranteed @Sendable (@in_guaranteed Event) -> ())?((uint64_t)v11);
  return (uint64_t)v13;
}

uint64_t HandPoseClassifierTrainingSessionDelegate.deinit()
{
  _s8CreateML20MLHandPoseClassifierV10DataSourceOWOhTm_0(v0 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sessionParameters, (void (*)(void))type metadata accessor for MLTrainingSessionParameters);
  outlined destroy of URL?(v0 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingParameters, &demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
  outlined consume of MLDataTable?(*(void **)(v0 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTable), *(unsigned char *)(v0 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTable + 8));
  outlined consume of Result<_DataTable, Error>(*(id *)(v0 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingFeatures), *(unsigned char *)(v0 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingFeatures + 8));
  outlined consume of Result<_DataTable, Error>(*(id *)(v0 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_validationFeatures), *(unsigned char *)(v0 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_validationFeatures + 8));
  swift_release();
  swift_bridgeObjectRelease();
  swift_bridgeObjectRelease();
  return v0;
}

uint64_t HandPoseClassifierTrainingSessionDelegate.__deallocating_deinit()
{
  HandPoseClassifierTrainingSessionDelegate.deinit();

  return swift_deallocClassInstance();
}

uint64_t ObjC metadata update function for HandPoseClassifierTrainingSessionDelegate()
{
  return type metadata accessor for HandPoseClassifierTrainingSessionDelegate();
}

uint64_t type metadata accessor for HandPoseClassifierTrainingSessionDelegate()
{
  uint64_t result = type metadata singleton initialization cache for HandPoseClassifierTrainingSessionDelegate;
  if (!type metadata singleton initialization cache for HandPoseClassifierTrainingSessionDelegate) {
    return swift_getSingletonMetadata();
  }
  return result;
}

void type metadata completion function for HandPoseClassifierTrainingSessionDelegate()
{
  type metadata accessor for MLTrainingSessionParameters();
  if (v0 <= 0x3F)
  {
    type metadata accessor for MLHandPoseClassifier.PersistentParameters?();
    if (v1 <= 0x3F) {
      swift_updateClassMetadata2();
    }
  }
}

void type metadata accessor for MLHandPoseClassifier.PersistentParameters?()
{
  if (!lazy cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?)
  {
    type metadata accessor for MLHandPoseClassifier.PersistentParameters();
    unint64_t v0 = type metadata accessor for Optional();
    if (!v1) {
      atomic_store(v0, (unint64_t *)&lazy cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
    }
  }
}

void protocol witness for TrainingSessionDelegate.setUp() in conformance HandPoseClassifierTrainingSessionDelegate()
{
}

void protocol witness for TrainingSessionDelegate.resume(from:) in conformance HandPoseClassifierTrainingSessionDelegate(Swift::OpaquePointer a1)
{
}

unint64_t protocol witness for TrainingSessionDelegate.itemCount(phase:) in conformance HandPoseClassifierTrainingSessionDelegate(CreateML::MLPhase a1)
{
  return (unint64_t)HandPoseClassifierTrainingSessionDelegate.itemCount(phase:)(a1);
}

void protocol witness for TrainingSessionDelegate.transitionTo(phase:) in conformance HandPoseClassifierTrainingSessionDelegate(CreateML::MLPhase a1)
{
}

uint64_t protocol witness for TrainingSessionDelegate.extractFeatures(from:) in conformance HandPoseClassifierTrainingSessionDelegate(Swift::Int a1)
{
  Swift::tuple_Int_finished_Bool v9 = HandPoseClassifierTrainingSessionDelegate.extractFeatures(from:)(a1);
  if (v3)
  {
    char v4 = *(uint64_t (**)(uint64_t, uint64_t))(v1 + 8);
    uint64_t v5 = v1;
    BOOL finished = 0;
  }
  else
  {
    Swift::Int v2 = v9._0;
    v9._0 = *(void *)(v1 + 8);
    BOOL finished = v9.finished;
    uint64_t v5 = v1;
  }
  return protocol witness for TrainingSessionDelegate.extractFeatures(from:) in conformance SoundClassifierTrainingSessionDelegate(v4, v5, v2, finished);
}

uint64_t protocol witness for TrainingSessionDelegate.train(from:) in conformance HandPoseClassifierTrainingSessionDelegate(Swift::Int a1)
{
  Swift::tuple_Int_metrics_OpaquePointer_finished_Bool v10 = HandPoseClassifierTrainingSessionDelegate.train(from:)(a1);
  if (v4)
  {
    v10._0 = v1[1];
    v10.metrics._rawValue = v1;
    BOOL finished = 0;
  }
  else
  {
    Swift::Int v6 = v10._0;
    rawValue = v10.metrics._rawValue;
    v10._0 = v1[1];
    BOOL finished = v10.finished;
    v10.metrics._rawValue = v1;
    *(void *)&v10.BOOL finished = v6;
    uint64_t v3 = (uint64_t)rawValue;
  }
  return protocol witness for TrainingSessionDelegate.train(from:) in conformance HandPoseClassifierTrainingSessionDelegate((uint64_t (*)(uint64_t, uint64_t, uint64_t))v10._0, (uint64_t)v10.metrics._rawValue, *(uint64_t *)&v10.finished, v3, finished);
}

uint64_t protocol witness for TrainingSessionDelegate.evaluate(from:) in conformance HandPoseClassifierTrainingSessionDelegate()
{
  return protocol witness for TrainingSessionDelegate.extractFeatures(from:) in conformance SoundClassifierTrainingSessionDelegate(*(uint64_t (**)(uint64_t, uint64_t))(v0 + 8), v0, 1, 1);
}

uint64_t protocol witness for TrainingSessionDelegate.saveCheckpoint(to:phase:iteration:) in conformance HandPoseClassifierTrainingSessionDelegate()
{
  HandPoseClassifierTrainingSessionDelegate.saveCheckpoint(to:phase:iteration:)();
  return v0 & 1;
}

uint64_t protocol witness for TrainingSessionCodable.save(to:) in conformance HandPoseClassifierTrainingSessionDelegate(uint64_t a1)
{
  return HandPoseClassifierTrainingSessionDelegate.save(to:)(a1);
}

void protocol witness for TrainingSessionCodable.restore(from:phase:) in conformance HandPoseClassifierTrainingSessionDelegate()
{
}

uint64_t protocol witness for TrainingSessionDelegate.train(from:) in conformance HandPoseClassifierTrainingSessionDelegate(uint64_t (*a1)(uint64_t, uint64_t, uint64_t), uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  return a1(a3, a4, a5);
}

uint64_t lazy protocol witness table accessor for type AnyColumn and conformance AnyColumn(unint64_t *a1)
{
  uint64_t result = *a1;
  if (!result)
  {
    type metadata accessor for AnyColumn();
    uint64_t result = swift_getWitnessTable();
    atomic_store(result, a1);
  }
  return result;
}

uint64_t outlined assign with take of MLHandPoseClassifier.PersistentParameters?(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 40))(a2, a1, v4);
  return a2;
}

uint64_t outlined init with take of MLHandPoseClassifier.PersistentParameters(uint64_t a1, uint64_t a2, void (*a3)(void))
{
  a3(0);
  OUTLINED_FUNCTION_8();
  uint64_t v4 = OUTLINED_FUNCTION_52_3();
  v5(v4);
  return a2;
}

uint64_t outlined init with copy of MLHandPoseClassifier.DataSource(uint64_t a1, uint64_t a2, void (*a3)(void))
{
  a3(0);
  OUTLINED_FUNCTION_8();
  uint64_t v4 = OUTLINED_FUNCTION_111();
  v5(v4);
  return a2;
}

uint64_t _s8CreateML20MLHandPoseClassifierV10DataSourceOWOhTm_0(uint64_t a1, void (*a2)(void))
{
  a2(0);
  OUTLINED_FUNCTION_8();
  OUTLINED_FUNCTION_25_0();
  v3();
  return a1;
}

uint64_t OUTLINED_FUNCTION_3_32(uint64_t a1, uint64_t a2)
{
  *(void *)a2 = 1;
  *(_OWORD *)(a2 + 8) = 0u;
  *(_OWORD *)(a2 + 24) = 0u;
  *(void *)(a2 + 40) = 0;
  *(unsigned char *)(a2 + 48) = 4;
  return swift_willThrow();
}

void OUTLINED_FUNCTION_7_21(void *a1, char a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, char a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24)
{
  outlined consume of Result<_DataTable, Error>(a1, a2);
  char v32 = *(unsigned char *)(v24 - 96);
  *(void *)(v24 - 120) = *(void *)(v24 - 104);
  *(unsigned char *)(v24 - 112) = v32;
  Array<A>.init(_:)(v24 - 120, v25, v26, v27, v28, v29, v30, v31, a9, a10, a11, a12, a13, a14, a15, a16, a17, a18, a19,
    a20,
    a21,
    a22,
    a23,
    a24);
}

uint64_t OUTLINED_FUNCTION_13_17()
{
  return swift_beginAccess();
}

uint64_t OUTLINED_FUNCTION_18_11()
{
  return swift_dynamicCast();
}

uint64_t OUTLINED_FUNCTION_24_12()
{
  *(void *)(v1 - 104) = v0;
  return BinaryInteger.description.getter();
}

uint64_t OUTLINED_FUNCTION_25_15()
{
  return 0x6C6562616CLL;
}

double OUTLINED_FUNCTION_27_9()
{
  *(void *)(v1 - 208) = v0;
  return v2;
}

uint64_t OUTLINED_FUNCTION_30_9()
{
  return v0;
}

void OUTLINED_FUNCTION_32_9()
{
  outlined consume of Result<_DataTable, Error>(v1, v0);
}

uint64_t OUTLINED_FUNCTION_33_8()
{
  return 0x69746164696C6176;
}

uint64_t OUTLINED_FUNCTION_34_8()
{
  return 0x636E657265666E69;
}

uint64_t OUTLINED_FUNCTION_35_8()
{
  return 0x636E657265666E69;
}

uint64_t OUTLINED_FUNCTION_36_8()
{
  return type metadata accessor for MLHandPoseClassifier.PersistentParameters();
}

void OUTLINED_FUNCTION_39_8(uint64_t a1, uint64_t a2, uint64_t a3, char a4)
{
  specialized MLDataTable.subscript.getter(a4, v4 - 136);
}

uint64_t OUTLINED_FUNCTION_42_7()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_43_6()
{
  return BinaryInteger.description.getter();
}

void OUTLINED_FUNCTION_45_5()
{
  *(unsigned char *)(v0 + 440) = v1;
  *(void *)(v0 + 448) = 0;
}

void OUTLINED_FUNCTION_46_7()
{
  outlined consume of MLDataTable?(v1, v0);
}

void OUTLINED_FUNCTION_48_6(uint64_t a1@<X8>)
{
  uint64_t v2 = v1 + a1;
  *(void *)uint64_t v2 = 0;
  *(unsigned char *)(v2 + 8) = -1;
}

uint64_t OUTLINED_FUNCTION_49_2@<X0>(uint64_t a1@<X8>)
{
  return static MLHandPoseClassifier.buildFeatureTable(features:labels:sessionIds:imageFiles:)(v1, v1, v1, v1, a1);
}

void OUTLINED_FUNCTION_50_6()
{
  outlined consume of MLDataTable?(v1, v0);
}

uint64_t OUTLINED_FUNCTION_53_9@<X0>(uint64_t a1@<X8>)
{
  return static MLHandPoseClassifier.buildFeatureTable(features:labels:sessionIds:imageFiles:)(v1, v1, v1, v1, a1);
}

uint64_t OUTLINED_FUNCTION_56_9()
{
  return 0x696C616974696E69;
}

void OUTLINED_FUNCTION_57_8()
{
  uint64_t v4 = *(void **)v0;
  char v5 = *(unsigned char *)(v0 + 8);
  *(void *)uint64_t v0 = v1;
  *(unsigned char *)(v0 + 8) = v2;
  outlined consume of Result<_DataTable, Error>(v4, v5);
}

id OUTLINED_FUNCTION_58_4()
{
  *(void *)(v2 - 120) = v1;
  *(unsigned char *)(v2 - 112) = v0;
  return outlined copy of Result<_DataTable, Error>(v1, v0);
}

void OUTLINED_FUNCTION_61_6()
{
  outlined consume of Result<_DataTable, Error>(v0, 0);
}

uint64_t OUTLINED_FUNCTION_62_4()
{
  return swift_bridgeObjectRetain();
}

void OUTLINED_FUNCTION_64_4()
{
  MLHandActionClassifier.GraphCNN.init(classLabels:export:numOfKeypoints:numOfKeypointsChannels:windowSize:)();
}

void static _TextUtilities.getTextLabels(from:)(uint64_t a1, uint64_t a2)
{
  uint64_t v126 = a1;
  uint64_t v3 = type metadata accessor for String.Encoding();
  MEMORY[0x270FA5388](v3 - 8);
  OUTLINED_FUNCTION_33_0();
  uint64_t v134 = v4;
  uint64_t v132 = type metadata accessor for UTType();
  OUTLINED_FUNCTION_0();
  *(void *)&long long v144 = v5;
  MEMORY[0x270FA5388](v6);
  OUTLINED_FUNCTION_33_0();
  uint64_t v125 = v7;
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  uint64_t v9 = MEMORY[0x270FA5388](v8 - 8);
  id v135 = (char *)&v110 - ((v10 + 15) & 0xFFFFFFFFFFFFFFF0);
  MEMORY[0x270FA5388](v9);
  uint64_t v127 = (uint64_t)&v110 - v11;
  uint64_t v12 = type metadata accessor for URL();
  OUTLINED_FUNCTION_0();
  uint64_t v14 = v13;
  uint64_t v16 = MEMORY[0x270FA5388](v15);
  unint64_t v18 = (char *)&v110 - ((v17 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v19 = MEMORY[0x270FA5388](v16);
  BOOL v21 = (char *)&v110 - v20;
  MEMORY[0x270FA5388](v19);
  unint64_t v23 = (char *)&v110 - v22;
  uint64_t v24 = type metadata accessor for MLTextClassifier.DataSource();
  MEMORY[0x270FA5388](v24 - 8);
  uint64_t v26 = (char *)&v110 - ((v25 + 15) & 0xFFFFFFFFFFFFFFF0);
  outlined init with copy of MLTextClassifier.DataSource(a2, (uint64_t)v26);
  uint64_t v27 = *(void (**)(char *, char *, uint64_t))(v14 + 32);
  v27(v23, v26, v12);
  uint64_t v28 = v147;
  static _FileUtilities.getReadableSubdirectoriesOfDirectory(at:)();
  uint64_t v30 = v28;
  if (v28)
  {
    (*(void (**)(char *, uint64_t))(v14 + 8))(v23, v12);
    return;
  }
  uint64_t v139 = (char *)v27;
  uint64_t v138 = v14 + 32;
  uint64_t v31 = v126;
  uint64_t v136 = v18;
  uint64_t v120 = v21;
  char v111 = v23;
  uint64_t v32 = *(void *)(v29 + 16);
  uint64_t v123 = v14;
  uint64_t v118 = v32;
  if (v32)
  {
    char v33 = v132;
    OUTLINED_FUNCTION_10_16();
    uint64_t v35 = (uint64_t)v135;
  }
  else
  {
    swift_bridgeObjectRelease();
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<URL>);
    uint64_t v36 = (void (*)(char *, uint64_t, uint64_t))((*(unsigned __int8 *)(v14 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v14 + 80));
    uint64_t v37 = swift_allocObject();
    *(_OWORD *)(v37 + 16) = xmmword_2272CB370;
    uint64_t v14 = v123;
    (*(void (**)(char *, char *, uint64_t))(v123 + 16))((char *)v36 + v37, v111, v12);
    uint64_t v34 = v37;
    uint64_t v38 = *(void *)(v37 + 16);
    char v33 = v132;
    uint64_t v35 = (uint64_t)v135;
    uint64_t v118 = v38;
    if (!v38)
    {
      uint64_t v122 = v34;
      unint64_t v121 = MEMORY[0x263F8EE78];
      unint64_t v114 = MEMORY[0x263F8EE78];
LABEL_40:
      OUTLINED_FUNCTION_8_19(v127, 1);
LABEL_41:
      swift_bridgeObjectRelease();
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, MLUntypedColumn)>);
      uint64_t inited = swift_initStackObject();
      *(_OWORD *)(inited + 16) = xmmword_2272CB4D0;
      *(void *)(inited + 32) = 1954047348;
      *(void *)(inited + 40) = 0xE400000000000000;
      unint64_t v145 = v121;
      MEMORY[0x270FA5388](inited);
      *(&v110 - 2) = (uint64_t)&v145;
      _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTgm5((void (*)(uint64_t *__return_ptr, uint64_t *))partial apply for specialized closure #1 in MLUntypedColumn.init<A>(_:));
      uint64_t v107 = OUTLINED_FUNCTION_13_18();
      *(void *)(inited + 48) = v36;
      *(unsigned char *)(inited + 56) = v33 & 1;
      *(void *)(inited + 64) = 0x6C6562616CLL;
      *(void *)(inited + 72) = 0xE500000000000000;
      unint64_t v145 = v114;
      MEMORY[0x270FA5388](v107);
      *(&v110 - 2) = (uint64_t)&v145;
      _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTgm5((void (*)(uint64_t *__return_ptr, uint64_t *))closure #1 in MLUntypedColumn.init<A>(_:)specialized partial apply);
      OUTLINED_FUNCTION_13_18();
      *(void *)(inited + 80) = v36;
      *(unsigned char *)(inited + 88) = v33 & 1;
      uint64_t v108 = Dictionary.init(dictionaryLiteral:)();
      specialized MLDataTable.init<A>(uniqueKeysWithValues:)(v108, (uint64_t)&v145);
      if (!v30)
      {
        char v109 = v146;
        *(void *)uint64_t v31 = v145;
        *(unsigned char *)(v31 + 8) = v109;
      }
      (*(void (**)(char *, uint64_t))(v123 + 8))(v111, v12);
      return;
    }
  }
  unint64_t v39 = 0;
  unint64_t v113 = (*(unsigned __int8 *)(v14 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v14 + 80);
  unint64_t v119 = v34 + v113;
  uint64_t v141 = v14 + 16;
  uint64_t v117 = v144 + 8;
  id v137 = (void (**)(char *, uint64_t))(v14 + 8);
  unint64_t v131 = 0x80000002272D7510;
  long long v144 = xmmword_2272CB370;
  unint64_t v121 = MEMORY[0x263F8EE78];
  unint64_t v114 = MEMORY[0x263F8EE78];
  char v40 = v120;
  uint64_t v36 = (void (*)(char *, uint64_t, uint64_t))v139;
  uint64_t v122 = v34;
  while (v39 < *(void *)(v34 + 16))
  {
    uint64_t v41 = *(void *)(v14 + 72);
    unint64_t v128 = v39;
    uint64_t v142 = v41;
    unint64_t v42 = v119 + v41 * v39;
    char v43 = *(void (**)(uint64_t, uint64_t, uint64_t))(v14 + 16);
    uint64_t v44 = v127;
    uint64_t v140 = v43;
    v43(v127, v42, v12);
    OUTLINED_FUNCTION_8_19(v44, 0);
    if (__swift_getEnumTagSinglePayload(v44, 1, v12) == 1) {
      goto LABEL_41;
    }
    v36(v40, v44, v12);
    uint64_t v124 = URL.lastPathComponent.getter();
    uint64_t v130 = v45;
    static UTType.text.getter();
    static _FileUtilities.readableFiles(at:type:)();
    char v47 = v30;
    if (v30)
    {
      uint64_t v88 = OUTLINED_FUNCTION_2_32();
      v89(v88);
      swift_bridgeObjectRelease();
      uint64_t v90 = v40;
      uint64_t v91 = *v137;
      (*v137)(v90, v12);
      swift_bridgeObjectRelease();
      swift_bridgeObjectRelease();
      swift_bridgeObjectRelease();
LABEL_38:
      v91(v111, v12);
      return;
    }
    uint64_t v48 = v46;
    uint64_t v49 = OUTLINED_FUNCTION_2_32();
    v50(v49);
    uint64_t v51 = *(void *)(v48 + 16);
    if (v51)
    {
      int v129 = 0;
      unint64_t v52 = 0;
      uint64_t v133 = v51;
      uint64_t v116 = v51 - 1;
      uint64_t v53 = v48 + v113;
      uint64_t v115 = v48 + v113;
      do
      {
        uint64_t v54 = v53 + v142 * v52;
        unint64_t v55 = v52;
        char v147 = 0;
        uint64_t v56 = v136;
        while (1)
        {
          if (v55 >= *(void *)(v48 + 16))
          {
            __break(1u);
            goto LABEL_45;
          }
          v140(v35, v54, v12);
          OUTLINED_FUNCTION_8_19(v35, 0);
          if (__swift_getEnumTagSinglePayload(v35, 1, v12) == 1)
          {
            swift_bridgeObjectRelease();
            uint64_t v31 = v126;
            uint64_t v14 = v123;
            char v40 = v120;
            OUTLINED_FUNCTION_10_16();
            uint64_t v30 = v147;
            goto LABEL_32;
          }
          ((void (*)(char *, uint64_t, uint64_t))v139)(v56, v35, v12);
          static String.Encoding.utf8.getter();
          uint64_t v57 = v147;
          uint64_t v58 = String.init(contentsOf:encoding:)();
          char v47 = v57;
          if (!v57) {
            break;
          }
          char v147 = 0;
          ++v55;

          unint64_t v145 = 0;
          unint64_t v146 = 0xE000000000000000;
          _StringGuts.grow(_:)(34);
          swift_bridgeObjectRelease();
          unint64_t v145 = 0xD00000000000001FLL;
          unint64_t v146 = v131;
          v60._uint64_t countAndFlagsBits = URL.path.getter();
          String.append(_:)(v60);
          swift_bridgeObjectRelease();
          v61._uint64_t countAndFlagsBits = 46;
          v61._uint64_t object = (void *)0xE100000000000000;
          String.append(_:)(v61);
          unint64_t v62 = v145;
          unint64_t v63 = v146;
          int v143 = static os_log_type_t.info.getter();
          __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Any>);
          uint64_t v64 = swift_allocObject();
          *(_OWORD *)(v64 + 16) = v144;
          uint64_t v65 = MEMORY[0x263F8D310];
          *(void *)(v64 + 56) = MEMORY[0x263F8D310];
          *(void *)(v64 + 32) = v62;
          *(void *)(v64 + 40) = v63;
          swift_bridgeObjectRetain();
          print(_:separator:terminator:)();
          swift_bridgeObjectRelease();
          type metadata accessor for OS_os_log();
          uint64_t v66 = (void *)static OS_os_log.default.getter();
          __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
          uint64_t v67 = v12;
          uint64_t v68 = swift_allocObject();
          *(_OWORD *)(v68 + 16) = v144;
          *(void *)(v68 + 56) = v65;
          *(void *)(v68 + 64) = lazy protocol witness table accessor for type String and conformance String();
          *(void *)(v68 + 32) = v62;
          *(void *)(v68 + 40) = v63;
          uint64_t v56 = v136;
          swift_bridgeObjectRetain();
          os_log(_:dso:log:type:_:)();
          swift_bridgeObjectRelease();

          uint64_t v12 = v67;
          char v33 = v132;
          swift_bridgeObjectRelease();
          OUTLINED_FUNCTION_7_22();
          OUTLINED_FUNCTION_6_20();
          v69();
          v54 += v142;
          uint64_t v35 = (uint64_t)v135;
          if (v133 == v55)
          {
            char v47 = v147;
            uint64_t v31 = v126;
            char v40 = v120;
            OUTLINED_FUNCTION_10_16();
            goto LABEL_31;
          }
        }
        uint64_t v70 = v58;
        uint64_t v71 = v59;
        char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native();
        uint64_t v112 = v48;
        if ((isUniquelyReferenced_nonNull_native & 1) == 0)
        {
          specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
          unint64_t v121 = v82;
        }
        OUTLINED_FUNCTION_10_16();
        unint64_t v73 = *(void *)(v121 + 16);
        if (v73 >= *(void *)(v121 + 24) >> 1)
        {
          specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
          unint64_t v121 = v83;
        }
        unint64_t v74 = v121;
        *(void *)(v121 + 16) = v73 + 1;
        unint64_t v75 = v74 + 16 * v73;
        *(void *)(v75 + 32) = v70;
        *(void *)(v75 + 40) = v71;
        swift_bridgeObjectRetain();
        unint64_t v76 = v114;
        if ((swift_isUniquelyReferenced_nonNull_native() & 1) == 0)
        {
          OUTLINED_FUNCTION_4_27();
          unint64_t v76 = v84;
        }
        unint64_t v77 = *(void *)(v76 + 16);
        if (v77 >= *(void *)(v76 + 24) >> 1)
        {
          specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
          unint64_t v76 = v85;
        }
        unint64_t v52 = v55 + 1;
        *(void *)(v76 + 16) = v77 + 1;
        unint64_t v114 = v76;
        unint64_t v78 = v76 + 16 * v77;
        uint64_t v79 = v130;
        *(void *)(v78 + 32) = v124;
        *(void *)(v78 + 40) = v79;
        OUTLINED_FUNCTION_7_22();
        OUTLINED_FUNCTION_6_20();
        v80();
        int v129 = 1;
        BOOL v81 = v116 == v55;
        char v40 = v120;
        uint64_t v35 = (uint64_t)v135;
        uint64_t v31 = v126;
        uint64_t v48 = v112;
        uint64_t v53 = v115;
      }
      while (!v81);
    }
    else
    {
      int v129 = 0;
    }
LABEL_31:
    OUTLINED_FUNCTION_8_19(v35, 1);
    swift_bridgeObjectRelease();
    uint64_t v30 = v47;
    uint64_t v14 = v123;
LABEL_32:
    if ((v129 & 1) == 0)
    {
      swift_bridgeObjectRelease();
      swift_bridgeObjectRelease();
      swift_bridgeObjectRelease();
      uint64_t v92 = v40;
      unint64_t v145 = 0;
      unint64_t v146 = 0xE000000000000000;
      _StringGuts.grow(_:)(29);
      swift_bridgeObjectRelease();
      unint64_t v145 = 0xD000000000000019;
      unint64_t v146 = 0x80000002272D74F0;
      uint64_t v93 = v124;
      v94._uint64_t countAndFlagsBits = v124;
      uint64_t v95 = v130;
      v94._uint64_t object = v130;
      String.append(_:)(v94);
      v96._uint64_t countAndFlagsBits = 11815;
      v96._uint64_t object = (void *)0xE200000000000000;
      String.append(_:)(v96);
      uint64_t v97 = v145;
      uint64_t v98 = (void *)v146;
      os_log_type_t v99 = static os_log_type_t.error.getter();
      v100._uint64_t countAndFlagsBits = v97;
      v100._uint64_t object = v98;
      log(_:type:)(v100, v99);
      swift_bridgeObjectRelease();
      unint64_t v145 = 0;
      unint64_t v146 = 0xE000000000000000;
      _StringGuts.grow(_:)(29);
      swift_bridgeObjectRelease();
      unint64_t v145 = 0xD000000000000019;
      unint64_t v146 = 0x80000002272D74F0;
      v101._uint64_t countAndFlagsBits = v93;
      v101._uint64_t object = v95;
      String.append(_:)(v101);
      swift_bridgeObjectRelease();
      v102._uint64_t countAndFlagsBits = 11815;
      v102._uint64_t object = (void *)0xE200000000000000;
      String.append(_:)(v102);
      unint64_t v103 = v145;
      unint64_t v104 = v146;
      lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
      swift_allocError();
      *(void *)uint64_t v105 = v103;
      *(void *)(v105 + 8) = v104;
      *(_OWORD *)(v105 + 16) = 0u;
      *(_OWORD *)(v105 + 32) = 0u;
      *(unsigned char *)(v105 + 48) = 0;
      swift_willThrow();
      uint64_t v91 = *v137;
      (*v137)(v92, v12);
      goto LABEL_38;
    }
    unint64_t v86 = v128 + 1;
    OUTLINED_FUNCTION_7_22();
    OUTLINED_FUNCTION_6_20();
    v87();
    swift_bridgeObjectRelease();
    unint64_t v39 = v86;
    BOOL v81 = v86 == v118;
    uint64_t v34 = v122;
    uint64_t v36 = (void (*)(char *, uint64_t, uint64_t))v139;
    if (v81) {
      goto LABEL_40;
    }
  }
LABEL_45:
  __break(1u);
}

uint64_t static _TextUtilities.getTextLabeledDictionary(from:)(uint64_t a1)
{
  static _TextUtilities.getTextLabels(from:)((uint64_t)&v84, a1);
  uint64_t v7 = v1;
  if (v1) {
    return (uint64_t)v2;
  }
  uint64_t v8 = v3;
  uint64_t v9 = v4;
  id isUniquelyReferenced_nonNull_native = v5;
  uint64_t v11 = v6;
  uint64_t v12 = v84;
  unint64_t v13 = v85;
  unint64_t v86 = v84;
  char v87 = (char)v85;
  outlined copy of Result<_DataTable, Error>(v84, (char)v85);
  MLDataTable.subscript.getter(v8, v9, (uint64_t)&v84);
  swift_bridgeObjectRelease();
  outlined consume of Result<_DataTable, Error>(v12, v13);
  uint64_t v14 = v84;
  LOBYTE(v9) = (_BYTE)v85;
  unint64_t v86 = v12;
  char v87 = v13;
  outlined copy of Result<_DataTable, Error>(v12, v13);
  MLDataTable.subscript.getter((uint64_t)isUniquelyReferenced_nonNull_native, v11, (uint64_t)&v84);
  swift_bridgeObjectRelease();
  outlined consume of Result<_DataTable, Error>(v12, v13);
  if ((v9 & 1) == 0)
  {
    unint64_t v83 = v84;
    int v89 = v85;
    uint64_t v15 = v14[2];
    outlined copy of Result<_DataTable, Error>(v14, 0);
    uint64_t v16 = CMLColumn.size.getter();
    outlined consume of Result<_DataTable, Error>(v14, 0);
    if ((v16 & 0x8000000000000000) == 0)
    {
      int v88 = v13;
      unint64_t v78 = v12;
      if (v16)
      {
        uint64_t v18 = 0;
        uint64_t v2 = (id **)MEMORY[0x263F8EE80];
        uint64_t v81 = v16;
        unint64_t v82 = v14;
        while (v16 != v18)
        {
          id v19 = outlined copy of Result<_DataTable, Error>(v14, 0);
          OUTLINED_FUNCTION_3_33((uint64_t)v19, v20, v21, v22, v23, v24, v25, v26, (uint64_t)v78);
          outlined consume of Result<_DataTable, Error>(v14, 0);
          id isUniquelyReferenced_nonNull_native = v84;
          uint64_t v16 = (uint64_t)v85;
          OUTLINED_FUNCTION_5_22();
          if (!v27) {
            goto LABEL_53;
          }
          if (v2[2]
            && (uint64_t v15 = (id *)v2,
                unint64_t v28 = specialized __RawDictionaryStorage.find<A>(_:)((uint64_t)isUniquelyReferenced_nonNull_native, v16),
                (v29 & 1) != 0))
          {
            uint64_t v30 = v2[7][v28];
            swift_bridgeObjectRetain();
            outlined consume of MLDataValue(isUniquelyReferenced_nonNull_native, (id)v16, 2);
            uint64_t v31 = swift_retain();
            OUTLINED_FUNCTION_3_33(v31, v32, v33, v34, v35, v36, v37, v38, v79);
            outlined consume of Result<_DataTable, Error>(v14, 0);
            uint64_t v7 = (uint64_t)v84;
            uint64_t v16 = (uint64_t)v85;
            OUTLINED_FUNCTION_5_22();
            if (!v27) {
              goto LABEL_59;
            }
            if (v89) {
              goto LABEL_58;
            }
            outlined copy of Result<_DataTable, Error>(v83, 0);
            _UntypedColumn.valueAtIndex(index:)(v18, (uint64_t)&v84);
            outlined consume of Result<_DataTable, Error>(v83, 0);
            unint64_t v13 = (unint64_t)v84;
            uint64_t v15 = v85;
            OUTLINED_FUNCTION_5_22();
            if (!v27) {
              goto LABEL_57;
            }
            swift_bridgeObjectRetain();
            uint64_t v80 = v16;
            if ((swift_isUniquelyReferenced_nonNull_native() & 1) == 0)
            {
              OUTLINED_FUNCTION_4_27();
              uint64_t v30 = v75;
            }
            unint64_t v41 = v30[2];
            if (v41 >= v30[3] >> 1)
            {
              specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
              uint64_t v30 = v76;
            }
            _OWORD v30[2] = v41 + 1;
            unint64_t v42 = &v30[2 * v41];
            v42[4] = v13;
            v42[5] = v15;
            outlined consume of MLDataValue((void *)v13, v15, 2);
            id isUniquelyReferenced_nonNull_native = (id)swift_isUniquelyReferenced_nonNull_native();
            unint64_t v84 = v2;
            uint64_t v16 = v7;
            uint64_t v15 = (id *)v2;
            specialized __RawDictionaryStorage.find<A>(_:)(v7, v80);
            OUTLINED_FUNCTION_11_15();
            if (v45) {
              goto LABEL_51;
            }
            unint64_t v13 = v43;
            uint64_t v7 = v44;
            __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, [String]>);
            uint64_t v15 = (id *)&v84;
            Swift::Bool v46 = _NativeDictionary.ensureUnique(isUnique:capacity:)((Swift::Bool)isUniquelyReferenced_nonNull_native, (Swift::Int)v2);
            uint64_t v14 = v82;
            id isUniquelyReferenced_nonNull_native = (id)v80;
            if (v46)
            {
              uint64_t v15 = (id *)v84;
              unint64_t v47 = specialized __RawDictionaryStorage.find<A>(_:)(v16, v80);
              if ((v7 & 1) != (v48 & 1)) {
                goto LABEL_61;
              }
              unint64_t v13 = v47;
            }
            uint64_t v2 = v84;
            if (v7)
            {
              uint64_t v15 = v84[7];
              swift_bridgeObjectRelease();
              v15[v13] = v30;
            }
            else
            {
              OUTLINED_FUNCTION_1_26();
              *unint64_t v73 = v16;
              v73[1] = v80;
              OUTLINED_FUNCTION_9_17();
              if (v45) {
                goto LABEL_52;
              }
              v2[2] = v74;
              swift_bridgeObjectRetain();
            }
            swift_bridgeObjectRelease();
            uint64_t v71 = (void *)v16;
            id v72 = (void *)v80;
          }
          else
          {
            outlined consume of MLDataValue(isUniquelyReferenced_nonNull_native, (id)v16, 2);
            uint64_t v49 = swift_retain();
            OUTLINED_FUNCTION_3_33(v49, v50, v51, v52, v53, v54, v55, v56, v79);
            outlined consume of Result<_DataTable, Error>(v14, 0);
            id isUniquelyReferenced_nonNull_native = v84;
            uint64_t v16 = (uint64_t)v85;
            OUTLINED_FUNCTION_5_22();
            if (!v27) {
              goto LABEL_54;
            }
            __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<String>);
            uint64_t v58 = swift_allocObject();
            *(_OWORD *)(v58 + 16) = xmmword_2272CB370;
            if (v89) {
              goto LABEL_56;
            }
            uint64_t v59 = (void *)v58;
            uint64_t v15 = (id *)v83;
            outlined copy of Result<_DataTable, Error>(v83, 0);
            _UntypedColumn.valueAtIndex(index:)(v18, (uint64_t)&v84);
            outlined consume of Result<_DataTable, Error>(v83, 0);
            OUTLINED_FUNCTION_5_22();
            if (!v27) {
              goto LABEL_55;
            }
            uint64_t v59[4] = v60;
            v59[5] = v61;
            char v63 = swift_isUniquelyReferenced_nonNull_native();
            unint64_t v84 = v2;
            uint64_t v15 = (id *)v2;
            specialized __RawDictionaryStorage.find<A>(_:)((uint64_t)isUniquelyReferenced_nonNull_native, v16);
            OUTLINED_FUNCTION_11_15();
            if (v45) {
              goto LABEL_49;
            }
            unint64_t v13 = v64;
            uint64_t v7 = v65;
            __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, [String]>);
            uint64_t v15 = (id *)&v84;
            Swift::Bool v66 = _NativeDictionary.ensureUnique(isUnique:capacity:)(v63, (Swift::Int)v2);
            uint64_t v14 = v82;
            if (v66)
            {
              uint64_t v15 = (id *)v84;
              unint64_t v67 = specialized __RawDictionaryStorage.find<A>(_:)((uint64_t)isUniquelyReferenced_nonNull_native, v16);
              if ((v7 & 1) != (v68 & 1)) {
                goto LABEL_61;
              }
              unint64_t v13 = v67;
            }
            uint64_t v2 = v84;
            if (v7)
            {
              uint64_t v15 = v84[7];
              swift_bridgeObjectRelease();
              v15[v13] = v59;
            }
            else
            {
              OUTLINED_FUNCTION_1_26();
              *uint64_t v69 = isUniquelyReferenced_nonNull_native;
              v69[1] = v16;
              OUTLINED_FUNCTION_9_17();
              if (v45) {
                goto LABEL_50;
              }
              v2[2] = v70;
              swift_bridgeObjectRetain();
            }
            swift_bridgeObjectRelease();
            uint64_t v71 = isUniquelyReferenced_nonNull_native;
            id v72 = (void *)v16;
          }
          outlined consume of MLDataValue(v71, v72, 2);
          ++v18;
          uint64_t v16 = v81;
          if (v81 == v18) {
            goto LABEL_46;
          }
        }
        __break(1u);
LABEL_49:
        __break(1u);
LABEL_50:
        __break(1u);
LABEL_51:
        __break(1u);
LABEL_52:
        __break(1u);
LABEL_53:
        outlined consume of MLDataValue(isUniquelyReferenced_nonNull_native, (id)v16, v17);
        __break(1u);
LABEL_54:
        outlined consume of MLDataValue(isUniquelyReferenced_nonNull_native, (id)v16, v57);
        __break(1u);
LABEL_55:
        outlined consume of MLDataValue(v60, v61, v62);
LABEL_56:
        __break(1u);
LABEL_57:
        outlined consume of MLDataValue((void *)v13, v15, v40);
LABEL_58:
        __break(1u);
LABEL_59:
        outlined consume of MLDataValue((void *)v7, (id)v16, v39);
        __break(1u);
        goto LABEL_60;
      }
      uint64_t v2 = (id **)MEMORY[0x263F8EE80];
LABEL_46:
      outlined consume of Result<_DataTable, Error>(v78, v88);
      outlined consume of Result<_DataTable, Error>(v14, 0);
      outlined consume of Result<_DataTable, Error>(v83, v89);
      return (uint64_t)v2;
    }
  }
LABEL_60:
  __break(1u);
LABEL_61:
  uint64_t result = KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)();
  __break(1u);
  return result;
}

uint64_t outlined init with copy of MLTextClassifier.DataSource(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = type metadata accessor for MLTextClassifier.DataSource();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 16))(a2, a1, v4);
  return a2;
}

void OUTLINED_FUNCTION_1_26()
{
  *(void *)(v0 + 8 * (v1 >> 6) + 64) |= 1 << v1;
}

uint64_t OUTLINED_FUNCTION_2_32()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_3_33(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, ...)
{
  va_start(va, a9);
  return _UntypedColumn.valueAtIndex(index:)(v9, (uint64_t)va);
}

void OUTLINED_FUNCTION_4_27()
{
  specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
}

uint64_t OUTLINED_FUNCTION_8_19(uint64_t a1, uint64_t a2)
{
  return __swift_storeEnumTagSinglePayload(a1, a2, 1, v2);
}

void OUTLINED_FUNCTION_9_17()
{
  *(void *)(*(void *)(v0 + 56) + 8 * v2) = v1;
}

uint64_t OUTLINED_FUNCTION_13_18()
{
  return swift_bridgeObjectRelease();
}

uint64_t _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lF11TabularData0D5FrameV_s5NeverO8CreateML23MLBoostedTreeClassifierV15ModelParametersV010ValidationD0OTg503_s8g4ML23ijk3V15lm75V13configuration10validationAE0A12MLComponents07BoostedD13ConfigurationV_11c7Data0N5e12VSgtcfcAE010N21N0OAMcAPmcfu_ApMcfu0_AOXMtTf1ncn_n@<X0>(uint64_t a1@<X0>, uint64_t a2@<X8>)
{
  uint64_t v4 = type metadata accessor for DataFrame();
  uint64_t v5 = *(void *)(v4 - 8);
  MEMORY[0x270FA5388](v4);
  uint64_t v7 = (char *)&v16 - ((v6 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
  MEMORY[0x270FA5388](v8 - 8);
  uint64_t v10 = (char *)&v16 - ((v9 + 15) & 0xFFFFFFFFFFFFFFF0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(a1, (uint64_t)v10, &demangling cache variable for type metadata for DataFrame?);
  if (__swift_getEnumTagSinglePayload((uint64_t)v10, 1, v4) == 1)
  {
    uint64_t v11 = type metadata accessor for MLBoostedTreeClassifier.ModelParameters.ValidationData();
    uint64_t v12 = a2;
    uint64_t v13 = 1;
  }
  else
  {
    (*(void (**)(char *, char *, uint64_t))(v5 + 32))(v7, v10, v4);
    (*(void (**)(uint64_t, char *, uint64_t))(v5 + 16))(a2, v7, v4);
    uint64_t v14 = type metadata accessor for MLBoostedTreeClassifier.ModelParameters.ValidationData();
    swift_storeEnumTagMultiPayload();
    (*(void (**)(char *, uint64_t))(v5 + 8))(v7, v4);
    uint64_t v12 = a2;
    uint64_t v13 = 0;
    uint64_t v11 = v14;
  }
  return __swift_storeEnumTagSinglePayload(v12, v13, 1, v11);
}

uint64_t MLBoostedTreeClassifier.ModelParameters.validationData.getter@<X0>(uint64_t a1@<X8>)
{
  type metadata accessor for MLBoostedTreeClassifier.ModelParameters.ValidationData();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v3);
  OUTLINED_FUNCTION_3_0();
  uint64_t v6 = v5 - v4;
  uint64_t result = outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v1, (uint64_t)&v8, &demangling cache variable for type metadata for Any?);
  if (v9)
  {
    outlined init with take of Any(&v8, &v10);
    swift_dynamicCast();
    MLBoostedTreeClassifier.ModelParameters.ValidationData.asTable()(a1);
    return outlined destroy of MLBoostedTreeClassifier.ModelParameters.ValidationData(v6);
  }
  else
  {
    __break(1u);
  }
  return result;
}

uint64_t key path getter for MLBoostedTreeClassifier.ModelParameters.validationData : MLBoostedTreeClassifier.ModelParameters@<X0>(uint64_t a1@<X8>)
{
  uint64_t result = MLBoostedTreeClassifier.ModelParameters.validationData.getter((uint64_t)&v4);
  char v3 = v5;
  *(void *)a1 = v4;
  *(unsigned char *)(a1 + 8) = v3;
  return result;
}

uint64_t key path setter for MLBoostedTreeClassifier.ModelParameters.validationData : MLBoostedTreeClassifier.ModelParameters(uint64_t a1)
{
  unsigned __int8 v1 = *(unsigned char *)(a1 + 8);
  id v3 = *(id *)a1;
  unsigned __int8 v4 = v1;
  outlined copy of MLDataTable?(v3, v1);
  return MLBoostedTreeClassifier.ModelParameters.validationData.setter((uint64_t)&v3);
}

uint64_t MLBoostedTreeClassifier.ModelParameters.validationData.setter(uint64_t a1)
{
  uint64_t v2 = v1;
  type metadata accessor for MLBoostedTreeClassifier.ModelParameters.ValidationData();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v4);
  OUTLINED_FUNCTION_3_0();
  uint64_t v7 = v6 - v5;
  long long v8 = *(void **)a1;
  int v9 = *(unsigned __int8 *)(a1 + 8);
  v13[3] = v10;
  boxed_opaque_existential_0 = __swift_allocate_boxed_opaque_existential_0(v13);
  if (v9 == 255)
  {
    *(void *)uint64_t v7 = 0;
    *(void *)(v7 + 8) = 0;
    *(_WORD *)(v7 + 16) = 256;
  }
  else if (MLDataTable.size.getter())
  {
    *(void *)uint64_t v7 = v8;
    *(unsigned char *)(v7 + 8) = v9 & 1;
  }
  else
  {
    outlined consume of MLDataTable?(v8, v9);
  }
  swift_storeEnumTagMultiPayload();
  outlined init with take of MLBoostedTreeClassifier.ModelParameters.ValidationData(v7, (uint64_t)boxed_opaque_existential_0);
  return outlined assign with take of Any?((uint64_t)v13, v2);
}

uint64_t MLBoostedTreeClassifier.ModelParameters.validation.getter()
{
  uint64_t result = outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v0, (uint64_t)&v2, &demangling cache variable for type metadata for Any?);
  if (v3)
  {
    outlined init with take of Any(&v2, &v4);
    type metadata accessor for MLBoostedTreeClassifier.ModelParameters.ValidationData();
    return swift_dynamicCast();
  }
  else
  {
    __break(1u);
  }
  return result;
}

uint64_t outlined init with take of MLBoostedTreeClassifier.ModelParameters.ValidationData(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = type metadata accessor for MLBoostedTreeClassifier.ModelParameters.ValidationData();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 32))(a2, a1, v4);
  return a2;
}

void (*MLBoostedTreeClassifier.ModelParameters.validationData.modify(uint64_t a1))(uint64_t a1, char a2)
{
  *(void *)(a1 + 16) = v1;
  MLBoostedTreeClassifier.ModelParameters.validationData.getter(a1);
  return MLBoostedTreeClassifier.ModelParameters.validationData.modify;
}

void MLBoostedTreeClassifier.ModelParameters.validationData.modify(uint64_t a1, char a2)
{
  long long v2 = *(void **)a1;
  unsigned __int8 v3 = *(unsigned char *)(a1 + 8);
  if (a2)
  {
    uint64_t v4 = *(void **)a1;
    unsigned __int8 v5 = v3;
    outlined copy of MLDataTable?(v2, v3);
    MLBoostedTreeClassifier.ModelParameters.validationData.setter((uint64_t)&v4);
    outlined consume of MLDataTable?(v2, v3);
  }
  else
  {
    uint64_t v4 = *(void **)a1;
    unsigned __int8 v5 = v3;
    MLBoostedTreeClassifier.ModelParameters.validationData.setter((uint64_t)&v4);
  }
}

uint64_t key path setter for MLBoostedTreeClassifier.ModelParameters.validation : MLBoostedTreeClassifier.ModelParameters(uint64_t a1)
{
  uint64_t v2 = type metadata accessor for MLBoostedTreeClassifier.ModelParameters.ValidationData();
  MEMORY[0x270FA5388](v2 - 8);
  uint64_t v4 = (char *)&v6 - ((v3 + 15) & 0xFFFFFFFFFFFFFFF0);
  outlined init with copy of MLBoostedTreeClassifier.ModelParameters.ValidationData(a1, (uint64_t)v4);
  return MLBoostedTreeClassifier.ModelParameters.validation.setter((uint64_t)v4);
}

uint64_t MLBoostedTreeClassifier.ModelParameters.validation.setter(uint64_t a1)
{
  v5[3] = type metadata accessor for MLBoostedTreeClassifier.ModelParameters.ValidationData();
  boxed_opaque_existential_0 = __swift_allocate_boxed_opaque_existential_0(v5);
  outlined init with take of MLBoostedTreeClassifier.ModelParameters.ValidationData(a1, (uint64_t)boxed_opaque_existential_0);
  return outlined assign with take of Any?((uint64_t)v5, v1);
}

void (*MLBoostedTreeClassifier.ModelParameters.validation.modify(void *a1))(uint64_t **a1, char a2)
{
  uint64_t v2 = v1;
  uint64_t v4 = malloc(0xA0uLL);
  *a1 = v4;
  v4[16] = v2;
  v4[17] = type metadata accessor for MLBoostedTreeClassifier.ModelParameters.ValidationData();
  OUTLINED_FUNCTION_8();
  size_t v6 = *(void *)(v5 + 64);
  v4[18] = malloc(v6);
  v4[19] = malloc(v6);
  uint64_t result = (void (*)(uint64_t **, char))outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v2, (uint64_t)(v4 + 4), &demangling cache variable for type metadata for Any?);
  if (v4[7])
  {
    outlined init with take of Any((_OWORD *)v4 + 2, v4);
    swift_dynamicCast();
    return MLBoostedTreeClassifier.ModelParameters.validation.modify;
  }
  else
  {
    __break(1u);
  }
  return result;
}

void MLBoostedTreeClassifier.ModelParameters.validation.modify(uint64_t **a1, char a2)
{
  uint64_t v2 = *a1;
  uint64_t v3 = (void *)(*a1)[18];
  uint64_t v4 = (void *)(*a1)[19];
  uint64_t v5 = (*a1)[16];
  uint64_t v6 = (*a1)[17];
  if (a2)
  {
    outlined init with copy of MLBoostedTreeClassifier.ModelParameters.ValidationData((*a1)[19], (uint64_t)v3);
    v2[11] = v6;
    boxed_opaque_existential_0 = __swift_allocate_boxed_opaque_existential_0(v2 + 8);
    outlined init with take of MLBoostedTreeClassifier.ModelParameters.ValidationData((uint64_t)v3, (uint64_t)boxed_opaque_existential_0);
    outlined assign with take of Any?((uint64_t)(v2 + 8), v5);
    outlined destroy of MLBoostedTreeClassifier.ModelParameters.ValidationData((uint64_t)v4);
  }
  else
  {
    v2[15] = v6;
    long long v8 = __swift_allocate_boxed_opaque_existential_0(v2 + 12);
    outlined init with take of MLBoostedTreeClassifier.ModelParameters.ValidationData((uint64_t)v4, (uint64_t)v8);
    outlined assign with take of Any?((uint64_t)(v2 + 12), v5);
  }
  free(v4);
  free(v3);

  free(v2);
}

uint64_t MLBoostedTreeClassifier.ModelParameters.maxDepth.getter()
{
  return *(void *)(v0 + 32);
}

uint64_t MLBoostedTreeClassifier.ModelParameters.maxDepth.setter(uint64_t result)
{
  *(void *)(v1 + 32) = result;
  return result;
}

uint64_t (*MLBoostedTreeClassifier.ModelParameters.maxDepth.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLBoostedTreeClassifier.ModelParameters.maxIterations.getter()
{
  return *(void *)(v0 + 40);
}

uint64_t MLBoostedTreeClassifier.ModelParameters.maxIterations.setter(uint64_t result)
{
  *(void *)(v1 + 40) = result;
  return result;
}

uint64_t (*MLBoostedTreeClassifier.ModelParameters.maxIterations.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

double MLBoostedTreeClassifier.ModelParameters.minLossReduction.getter()
{
  return *(double *)(v0 + 48);
}

void MLBoostedTreeClassifier.ModelParameters.minLossReduction.setter(double a1)
{
  *(double *)(v1 + 48) = a1;
}

uint64_t (*MLBoostedTreeClassifier.ModelParameters.minLossReduction.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

double MLBoostedTreeClassifier.ModelParameters.minChildWeight.getter()
{
  return *(double *)(v0 + 56);
}

void MLBoostedTreeClassifier.ModelParameters.minChildWeight.setter(double a1)
{
  *(double *)(v1 + 56) = a1;
}

uint64_t (*MLBoostedTreeClassifier.ModelParameters.minChildWeight.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLBoostedTreeClassifier.ModelParameters.randomSeed.getter()
{
  return *(void *)(v0 + 64);
}

uint64_t MLBoostedTreeClassifier.ModelParameters.randomSeed.setter(uint64_t result)
{
  *(void *)(v1 + 64) = result;
  return result;
}

uint64_t (*MLBoostedTreeClassifier.ModelParameters.randomSeed.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

double MLBoostedTreeClassifier.ModelParameters.stepSize.getter()
{
  return *(double *)(v0 + 72);
}

void MLBoostedTreeClassifier.ModelParameters.stepSize.setter(double a1)
{
  *(double *)(v1 + 72) = a1;
}

uint64_t (*MLBoostedTreeClassifier.ModelParameters.stepSize.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLBoostedTreeClassifier.ModelParameters.earlyStoppingRounds.getter()
{
  return *(void *)(v0 + 80);
}

uint64_t MLBoostedTreeClassifier.ModelParameters.earlyStoppingRounds.setter(uint64_t result, char a2)
{
  *(void *)(v2 + 80) = result;
  *(unsigned char *)(v2 + 88) = a2 & 1;
  return result;
}

uint64_t (*MLBoostedTreeClassifier.ModelParameters.earlyStoppingRounds.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

double MLBoostedTreeClassifier.ModelParameters.rowSubsample.getter()
{
  return *(double *)(v0 + 96);
}

void MLBoostedTreeClassifier.ModelParameters.rowSubsample.setter(double a1)
{
  *(double *)(v1 + 96) = a1;
}

uint64_t (*MLBoostedTreeClassifier.ModelParameters.rowSubsample.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

double MLBoostedTreeClassifier.ModelParameters.columnSubsample.getter()
{
  return *(double *)(v0 + 104);
}

void MLBoostedTreeClassifier.ModelParameters.columnSubsample.setter(double a1)
{
  *(double *)(v1 + 104) = a1;
}

uint64_t (*MLBoostedTreeClassifier.ModelParameters.columnSubsample.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLBoostedTreeClassifier.ModelParameters.init(validation:maxDepth:maxIterations:minLossReduction:minChildWeight:randomSeed:stepSize:earlyStoppingRounds:rowSubsample:columnSubsample:)@<X0>(uint64_t a1@<X0>, uint64_t a2@<X1>, uint64_t a3@<X2>, uint64_t a4@<X3>, uint64_t a5@<X4>, char a6@<W5>, uint64_t a7@<X8>, double a8@<D0>, double a9@<D1>, double a10@<D2>, double a11@<D3>, double a12@<D4>)
{
  uint64_t v24 = type metadata accessor for MLBoostedTreeClassifier.ModelParameters.ValidationData();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v25);
  OUTLINED_FUNCTION_3_0();
  uint64_t v28 = v27 - v26;
  *(_OWORD *)a7 = 0u;
  *(_OWORD *)(a7 + 16) = 0u;
  *(void *)(a7 + 32) = a2;
  *(void *)(a7 + 40) = a3;
  *(double *)(a7 + 48) = a8;
  *(double *)(a7 + 56) = a9;
  *(void *)(a7 + 64) = a4;
  *(double *)(a7 + 72) = a10;
  *(void *)(a7 + 80) = a5;
  *(unsigned char *)(a7 + 88) = a6 & 1;
  *(double *)(a7 + 96) = a11;
  *(double *)(a7 + 104) = a12;
  outlined init with copy of MLBoostedTreeClassifier.ModelParameters.ValidationData(a1, v27 - v26);
  v31[3] = v24;
  boxed_opaque_existential_0 = __swift_allocate_boxed_opaque_existential_0(v31);
  outlined init with take of MLBoostedTreeClassifier.ModelParameters.ValidationData(v28, (uint64_t)boxed_opaque_existential_0);
  outlined assign with take of Any?((uint64_t)v31, a7);
  return outlined destroy of MLBoostedTreeClassifier.ModelParameters.ValidationData(a1);
}

uint64_t MLBoostedTreeClassifier.ModelParameters.init(validationData:maxDepth:maxIterations:minLossReduction:minChildWeight:randomSeed:stepSize:earlyStoppingRounds:rowSubsample:columnSubsample:)@<X0>(uint64_t *a1@<X0>, uint64_t a2@<X1>, uint64_t a3@<X2>, uint64_t a4@<X3>, uint64_t a5@<X4>, char a6@<W5>, uint64_t a7@<X8>, double a8@<D0>, double a9@<D1>, double a10@<D2>, double a11@<D3>, double a12@<D4>)
{
  uint64_t v12 = *a1;
  char v13 = *((unsigned char *)a1 + 8);
  *(_OWORD *)a7 = 0u;
  *(_OWORD *)(a7 + 16) = 0u;
  *(void *)(a7 + 32) = a2;
  *(void *)(a7 + 40) = a3;
  *(double *)(a7 + 48) = a8;
  *(double *)(a7 + 56) = a9;
  *(void *)(a7 + 64) = a4;
  *(double *)(a7 + 72) = a10;
  *(void *)(a7 + 80) = a5;
  *(unsigned char *)(a7 + 88) = a6 & 1;
  *(double *)(a7 + 96) = a11;
  *(double *)(a7 + 104) = a12;
  uint64_t v15 = v12;
  char v16 = v13;
  return MLBoostedTreeClassifier.ModelParameters.validationData.setter((uint64_t)&v15);
}

uint64_t MLBoostedTreeClassifier.ModelParameters.init(configuration:validation:)@<X0>(uint64_t a1@<X0>, uint64_t a2@<X1>, uint64_t a3@<X8>)
{
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLBoostedTreeClassifier.ModelParameters.ValidationData?);
  MEMORY[0x270FA5388](v6 - 8);
  OUTLINED_FUNCTION_3_0();
  uint64_t v9 = v8 - v7;
  uint64_t v10 = type metadata accessor for MLBoostedTreeClassifier.ModelParameters.ValidationData();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v11);
  OUTLINED_FUNCTION_3_0();
  uint64_t v14 = v13 - v12;
  *(_OWORD *)a3 = 0u;
  *(_OWORD *)(a3 + 16) = 0u;
  *(void *)(a3 + 32) = BoostedTreeConfiguration.maximumDepth.getter();
  *(void *)(a3 + 40) = BoostedTreeConfiguration.maximumIterations.getter();
  BoostedTreeConfiguration.minimumLossReduction.getter();
  *(void *)(a3 + 48) = v15;
  BoostedTreeConfiguration.minimumChildWeight.getter();
  *(void *)(a3 + 56) = v16;
  *(void *)(a3 + 64) = BoostedTreeConfiguration.randomSeed.getter();
  BoostedTreeConfiguration.learningRate.getter();
  *(void *)(a3 + 72) = v17;
  *(void *)(a3 + 80) = BoostedTreeConfiguration.earlyStoppingIterationCount.getter();
  *(unsigned char *)(a3 + 88) = v18 & 1;
  BoostedTreeConfiguration.rowSubsample.getter();
  *(void *)(a3 + 96) = v19;
  BoostedTreeConfiguration.columnSubsample.getter();
  *(void *)(a3 + 104) = v20;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lF11TabularData0D5FrameV_s5NeverO8CreateML23MLBoostedTreeClassifierV15ModelParametersV010ValidationD0OTg503_s8g4ML23ijk3V15lm75V13configuration10validationAE0A12MLComponents07BoostedD13ConfigurationV_11c7Data0N5e12VSgtcfcAE010N21N0OAMcAPmcfu_ApMcfu0_AOXMtTf1ncn_n(a2, v9);
  if (__swift_getEnumTagSinglePayload(v9, 1, v10) == 1)
  {
    swift_storeEnumTagMultiPayload();
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v9, &demangling cache variable for type metadata for MLBoostedTreeClassifier.ModelParameters.ValidationData?);
  }
  else
  {
    outlined init with take of MLBoostedTreeClassifier.ModelParameters.ValidationData(v9, v14);
  }
  v24[3] = v10;
  boxed_opaque_existential_0 = __swift_allocate_boxed_opaque_existential_0(v24);
  outlined init with take of MLBoostedTreeClassifier.ModelParameters.ValidationData(v14, (uint64_t)boxed_opaque_existential_0);
  outlined assign with take of Any?((uint64_t)v24, a3);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(a2, &demangling cache variable for type metadata for DataFrame?);
  type metadata accessor for BoostedTreeConfiguration();
  OUTLINED_FUNCTION_8();
  return (*(uint64_t (**)(uint64_t))(v22 + 8))(a1);
}

uint64_t MLBoostedTreeClassifier.ModelParameters.description.getter()
{
  v0._uint64_t countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter();
  String.append(_:)(v0);
  swift_bridgeObjectRelease();
  v1._uint64_t countAndFlagsBits = 10;
  v1._uint64_t object = (void *)0xE100000000000000;
  String.append(_:)(v1);
  OUTLINED_FUNCTION_4_0();
  _StringGuts.grow(_:)(19);
  swift_bridgeObjectRelease();
  v2._uint64_t countAndFlagsBits = OUTLINED_FUNCTION_8_0();
  String.append(_:)(v2);
  swift_bridgeObjectRelease();
  OUTLINED_FUNCTION_1_1();
  v3._uint64_t countAndFlagsBits = 0xD000000000000010;
  v3._uint64_t object = (void *)0x80000002272D3F00;
  String.append(_:)(v3);
  swift_bridgeObjectRelease();
  OUTLINED_FUNCTION_4_0();
  _StringGuts.grow(_:)(23);
  OUTLINED_FUNCTION_7_0();
  v4._uint64_t countAndFlagsBits = 0xD000000000000014;
  v4._uint64_t object = (void *)0x80000002272D3F20;
  String.append(_:)(v4);
  OUTLINED_FUNCTION_3_1();
  OUTLINED_FUNCTION_1_1();
  v5._uint64_t countAndFlagsBits = 0xD000000000000010;
  v5._uint64_t object = (void *)0x80000002272D3F00;
  String.append(_:)(v5);
  swift_bridgeObjectRelease();
  _StringGuts.grow(_:)(21);
  OUTLINED_FUNCTION_7_0();
  OUTLINED_FUNCTION_5_0((uint64_t)"Min Child Weight: ");
  OUTLINED_FUNCTION_3_1();
  OUTLINED_FUNCTION_1_1();
  v6._uint64_t countAndFlagsBits = 0;
  v6._uint64_t object = (void *)0xE000000000000000;
  String.append(_:)(v6);
  swift_bridgeObjectRelease();
  OUTLINED_FUNCTION_4_0();
  _StringGuts.grow(_:)(16);
  swift_bridgeObjectRelease();
  strcpy((char *)v42, "Random Seed: ");
  HIWORD(v42[1]) = -4864;
  v7._uint64_t countAndFlagsBits = OUTLINED_FUNCTION_8_0();
  String.append(_:)(v7);
  swift_bridgeObjectRelease();
  OUTLINED_FUNCTION_1_1();
  OUTLINED_FUNCTION_6_0(v8, v9, v10, v11, v12, v13, v14, v15, v36, v39, v42[0], v42[1]);
  swift_bridgeObjectRelease();
  OUTLINED_FUNCTION_4_0();
  v16._uint64_t countAndFlagsBits = 0x7A69532070657453;
  v16._uint64_t object = (void *)0xEB00000000203A65;
  String.append(_:)(v16);
  OUTLINED_FUNCTION_3_1();
  OUTLINED_FUNCTION_1_1();
  OUTLINED_FUNCTION_6_0(v17, v18, v19, v20, v21, v22, v23, v24, v37, v40, v42[0], v42[1]);
  swift_bridgeObjectRelease();
  OUTLINED_FUNCTION_4_0();
  _StringGuts.grow(_:)(18);
  OUTLINED_FUNCTION_7_0();
  v25._uint64_t countAndFlagsBits = 0x7362755320776F52;
  v25._uint64_t object = (void *)0xEF203A656C706D61;
  String.append(_:)(v25);
  OUTLINED_FUNCTION_3_1();
  OUTLINED_FUNCTION_1_1();
  OUTLINED_FUNCTION_6_0(v26, v27, v28, v29, v30, v31, v32, v33, v38, v41, v42[0], v42[1]);
  swift_bridgeObjectRelease();
  _StringGuts.grow(_:)(21);
  OUTLINED_FUNCTION_7_0();
  OUTLINED_FUNCTION_5_0((uint64_t)"Column Subsample: ");
  OUTLINED_FUNCTION_3_1();
  OUTLINED_FUNCTION_1_1();
  v34._uint64_t countAndFlagsBits = 0;
  v34._uint64_t object = (void *)0xE000000000000000;
  String.append(_:)(v34);
  swift_bridgeObjectRelease();
  return 0x747065442078614DLL;
}

uint64_t MLBoostedTreeClassifier.ModelParameters.playgroundDescription.getter@<X0>(uint64_t *a1@<X8>)
{
  uint64_t result = MLBoostedTreeClassifier.ModelParameters.description.getter();
  a1[3] = MEMORY[0x263F8D310];
  *a1 = result;
  a1[1] = v3;
  return result;
}

uint64_t sub_2271252C8()
{
  return MLBoostedTreeClassifier.ModelParameters.validation.getter();
}

ValueMetadata *type metadata accessor for MLBoostedTreeClassifier.ModelParameters()
{
  return &type metadata for MLBoostedTreeClassifier.ModelParameters;
}

uint64_t specialized RandomAccessCollection<>.indices.getter()
{
  return specialized RandomAccessCollection<>.indices.getter(CMLDictionary.size.getter);
}

{
  uint64_t result;

  uint64_t result = CMLSequence.size.getter();
  if ((result & 0x8000000000000000) == 0) {
    return 0;
  }
  __break(1u);
  return result;
}

{
  uint64_t result;

  uint64_t result = OUTLINED_FUNCTION_19_14();
  if ((result & 0x8000000000000000) == 0) {
    return OUTLINED_FUNCTION_29_10();
  }
  __break(1u);
  return result;
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t result;

  swift_retain();
  Swift::String v0 = CMLSequence.size.getter();
  Swift::String v1 = OUTLINED_FUNCTION_12_0(v0);
  uint64_t result = swift_release();
  if ((v1 & 0x8000000000000000) == 0) {
    return 0;
  }
  __break(1u);
  return result;
}

uint64_t specialized RandomAccessCollection<>.indices.getter(uint64_t (*a1)(void))
{
  uint64_t result = a1();
  if ((result & 0x8000000000000000) == 0) {
    return OUTLINED_FUNCTION_29_10();
  }
  __break(1u);
  return result;
}

void CMLSequence.subscript.getter(uint64_t a1)
{
}

uint64_t specialized RandomAccessCollection<>.index(_:offsetBy:)(uint64_t a1, uint64_t a2)
{
  return specialized RandomAccessCollection<>.index(_:offsetBy:)(a1, a2, CMLDictionary.size.getter);
}

uint64_t specialized RandomAccessCollection<>.index(_:offsetBy:)(uint64_t result, uint64_t a2)
{
  uint64_t v2 = result + a2;
  if (__OFADD__(result, a2))
  {
    __break(1u);
  }
  else
  {
    uint64_t result = CMLSequence.size.getter();
    if ((v2 & 0x8000000000000000) == 0 && result >= v2) {
      return v2;
    }
  }
  __break(1u);
  return result;
}

{
  uint64_t v2;

  uint64_t v2 = result + a2;
  if (__OFADD__(result, a2))
  {
    __break(1u);
  }
  else
  {
    uint64_t result = OUTLINED_FUNCTION_19_14();
    if ((v2 & 0x8000000000000000) == 0 && result >= v2) {
      return v2;
    }
  }
  __break(1u);
  return result;
}

{
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;

  uint64_t v3 = result + a2;
  if (__OFADD__(result, a2))
  {
    __break(1u);
  }
  else
  {
    swift_retain();
    Swift::String v4 = CMLSequence.size.getter();
    OUTLINED_FUNCTION_12_0(v4);
    uint64_t result = OUTLINED_FUNCTION_74();
    if ((v3 & 0x8000000000000000) == 0 && v2 >= v3) {
      return v3;
    }
  }
  __break(1u);
  return result;
}

uint64_t specialized RandomAccessCollection<>.index(_:offsetBy:)(uint64_t result, uint64_t a2, uint64_t (*a3)(void))
{
  uint64_t v3 = result + a2;
  if (__OFADD__(result, a2))
  {
    __break(1u);
  }
  else
  {
    uint64_t result = a3();
    if ((v3 & 0x8000000000000000) == 0 && result >= v3) {
      return v3;
    }
  }
  __break(1u);
  return result;
}

uint64_t specialized RandomAccessCollection.index(_:offsetBy:limitedBy:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return specialized RandomAccessCollection.index(_:offsetBy:limitedBy:)(a1, a2, a3, specialized RandomAccessCollection<>.distance(from:to:), CMLDictionary.size.getter);
}

{
  uint64_t v6;
  uint64_t v7;
  uint64_t result;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  BOOL v14;
  uint64_t v15;

  swift_retain();
  Swift::String v6 = CMLSequence.size.getter();
  Swift::String v7 = OUTLINED_FUNCTION_12_0(v6);
  uint64_t result = swift_release();
  if (a1 < 0 || v7 < a1)
  {
    __break(1u);
LABEL_19:
    __break(1u);
LABEL_20:
    __break(1u);
    goto LABEL_21;
  }
  swift_retain();
  uint64_t v9 = CMLSequence.size.getter();
  uint64_t v10 = OUTLINED_FUNCTION_12_0(v9);
  uint64_t result = swift_release();
  if (a3 < 0 || v10 < a3) {
    goto LABEL_19;
  }
  uint64_t v11 = a3 - a1;
  if (a2 < 1)
  {
    if (v11 <= 0 && v11 > a2) {
      return 0;
    }
  }
  else if ((v11 & 0x8000000000000000) == 0 && v11 < a2)
  {
    return 0;
  }
  uint64_t v14 = __OFADD__(a1, a2);
  uint64_t v12 = a1 + a2;
  if (v14) {
    goto LABEL_20;
  }
  swift_retain();
  uint64_t v15 = CMLSequence.size.getter();
  OUTLINED_FUNCTION_12_0(v15);
  uint64_t result = OUTLINED_FUNCTION_74();
  if ((v12 & 0x8000000000000000) == 0 && a1 >= v12) {
    return v12;
  }
LABEL_21:
  __break(1u);
  return result;
}

uint64_t specialized RandomAccessCollection.index(_:offsetBy:limitedBy:)(uint64_t a1, uint64_t a2)
{
  uint64_t result = specialized RandomAccessCollection<>.distance(from:to:)();
  if (a2 < 1)
  {
    if (result <= 0 && result > a2) {
      return 0;
    }
  }
  else if ((result & 0x8000000000000000) == 0 && result < a2)
  {
    return 0;
  }
  BOOL v7 = __OFADD__(a1, a2);
  uint64_t v5 = a1 + a2;
  if (v7)
  {
    __break(1u);
  }
  else
  {
    uint64_t result = CMLSequence.size.getter();
    if ((v5 & 0x8000000000000000) == 0 && result >= v5) {
      return v5;
    }
  }
  __break(1u);
  return result;
}

{
  uint64_t result;
  uint64_t v5;
  BOOL v7;

  uint64_t result = specialized RandomAccessCollection<>.distance(from:to:)();
  if (a2 < 1)
  {
    if (result <= 0 && result > a2) {
      return 0;
    }
  }
  else if ((result & 0x8000000000000000) == 0 && result < a2)
  {
    return 0;
  }
  BOOL v7 = __OFADD__(a1, a2);
  uint64_t v5 = a1 + a2;
  if (v7)
  {
    __break(1u);
  }
  else
  {
    uint64_t result = OUTLINED_FUNCTION_19_14();
    if ((v5 & 0x8000000000000000) == 0 && result >= v5) {
      return v5;
    }
  }
  __break(1u);
  return result;
}

uint64_t specialized RandomAccessCollection.index(_:offsetBy:limitedBy:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t (*a4)(uint64_t, uint64_t), uint64_t (*a5)(void))
{
  uint64_t v8 = a4(a1, a3);
  if (a2 < 1)
  {
    if (v8 <= 0 && v8 > a2) {
      return 0;
    }
  }
  else if ((v8 & 0x8000000000000000) == 0 && v8 < (unint64_t)a2)
  {
    return 0;
  }
  return specialized RandomAccessCollection<>.index(_:offsetBy:)(a1, a2, a5);
}

uint64_t specialized RandomAccessCollection<>.index(before:)(uint64_t result)
{
  uint64_t v2 = result - 1;
  if (__OFSUB__(result, 1))
  {
    __break(1u);
  }
  else
  {
    swift_retain();
    uint64_t v3 = CMLSequence.size.getter();
    OUTLINED_FUNCTION_12_0(v3);
    uint64_t result = OUTLINED_FUNCTION_74();
    if ((v2 & 0x8000000000000000) == 0 && v2 < v1) {
      return v2;
    }
  }
  __break(1u);
  return result;
}

{
  uint64_t v1;

  uint64_t v1 = result - 1;
  if (__OFSUB__(result, 1))
  {
    __break(1u);
  }
  else
  {
    uint64_t result = OUTLINED_FUNCTION_19_14();
    if ((v1 & 0x8000000000000000) == 0 && v1 < result) {
      return v1;
    }
  }
  __break(1u);
  return result;
}

{
  uint64_t v1;

  uint64_t v1 = result - 1;
  if (__OFSUB__(result, 1))
  {
    __break(1u);
  }
  else
  {
    uint64_t result = CMLSequence.size.getter();
    if ((v1 & 0x8000000000000000) == 0 && v1 < result) {
      return v1;
    }
  }
  __break(1u);
  return result;
}

uint64_t specialized RandomAccessCollection<>.index(before:)(uint64_t a1)
{
  return specialized RandomAccessCollection<>.index(before:)(a1, CMLDictionary.size.getter);
}

uint64_t specialized RandomAccessCollection<>.index(before:)(uint64_t result, uint64_t (*a2)(void))
{
  uint64_t v2 = result - 1;
  if (__OFSUB__(result, 1))
  {
    __break(1u);
  }
  else
  {
    uint64_t result = a2();
    if ((v2 & 0x8000000000000000) == 0 && v2 < result) {
      return v2;
    }
  }
  __break(1u);
  return result;
}

uint64_t specialized Collection<>.subscript.getter(uint64_t a1, uint64_t a2)
{
  return specialized Collection<>.subscript.getter(a1, a2, CMLDictionary.size.getter);
}

uint64_t specialized Collection<>.subscript.getter@<X0>(uint64_t a1@<X0>, uint64_t a2@<X1>, uint64_t a3@<X8>)
{
  uint64_t result = specialized Dictionary.startIndex.getter(a2);
  if (v8) {
    goto LABEL_17;
  }
  uint64_t v9 = v7;
  uint64_t v10 = *(unsigned int *)(a2 + 36);
  if (v10 != v7)
  {
    __break(1u);
    goto LABEL_12;
  }
  uint64_t v11 = result;
  uint64_t v12 = 1 << *(unsigned char *)(a2 + 32);
  if (v12 < result)
  {
LABEL_12:
    __break(1u);
LABEL_13:
    __break(1u);
    goto LABEL_14;
  }
  long long v21 = *(_OWORD *)a1;
  char v22 = *(unsigned char *)(a1 + 16);
  long long v23 = v21;
  char v24 = v22;
  outlined init with take of [MLDataValue : MLDataValue].Index._Variant((uint64_t)&v23, (uint64_t)v25);
  uint64_t result = outlined init with take of [MLDataValue : MLDataValue].Index._Variant((uint64_t)v25, (uint64_t)&v26);
  if (v28)
  {
LABEL_18:
    __break(1u);
    goto LABEL_19;
  }
  if (v27 != v10) {
    goto LABEL_13;
  }
  if (v26 < v11)
  {
LABEL_14:
    __break(1u);
    goto LABEL_15;
  }
  __n128 v18 = OUTLINED_FUNCTION_27_10();
  char v19 = v13;
  outlined init with take of [MLDataValue : MLDataValue].Index._Variant((uint64_t)&v18, (uint64_t)v20);
  uint64_t result = outlined init with take of [MLDataValue : MLDataValue].Index._Variant((uint64_t)v20, (uint64_t)&v29);
  if ((v31 & 1) == 0)
  {
    uint64_t v14 = v29;
    int v15 = v30;
    outlined consume of [MLDataValue : MLDataValue].Index._Variant(v11, v9, 0);
    uint64_t result = outlined consume of [MLDataValue : MLDataValue].Index._Variant(v12, v10, 0);
    if (v10 == v15)
    {
      if (v12 >= v14)
      {
        *(void *)(a3 + 48) = a2;
        *(_OWORD *)a3 = v21;
        *(unsigned char *)(a3 + 16) = v22;
        *(_OWORD *)(a3 + 24) = v16;
        *(unsigned char *)(a3 + 40) = v17;
        swift_bridgeObjectRetain();
        return outlined retain of Range<MLDataValue.DictionaryType.Index>(a1);
      }
      goto LABEL_16;
    }
LABEL_15:
    __break(1u);
LABEL_16:
    __break(1u);
LABEL_17:
    __break(1u);
    goto LABEL_18;
  }
LABEL_19:
  __break(1u);
  return result;
}

uint64_t specialized Collection<>.subscript.getter@<X0>(uint64_t a1@<X0>, uint64_t a2@<X1>, uint64_t a3@<X2>, void *a4@<X8>)
{
  uint64_t result = CMLSequence.size.getter();
  if (result < 0)
  {
    __break(1u);
    goto LABEL_8;
  }
  if (a1 < 0)
  {
LABEL_8:
    __break(1u);
    goto LABEL_9;
  }
  if (result < a2)
  {
LABEL_9:
    __break(1u);
    return result;
  }
  a4[1] = a2;
  a4[2] = a3;
  *a4 = a1;

  return swift_retain();
}

{
  uint64_t v8;
  uint64_t v9;
  uint64_t result;
  uint64_t vars8;

  swift_retain();
  char v8 = CMLSequence.size.getter();
  uint64_t v9 = OUTLINED_FUNCTION_12_0(v8);
  uint64_t result = swift_release();
  if (v9 < 0)
  {
    __break(1u);
    goto LABEL_8;
  }
  if (a1 < 0)
  {
LABEL_8:
    __break(1u);
    goto LABEL_9;
  }
  if (v9 < a2)
  {
LABEL_9:
    __break(1u);
    return result;
  }
  a4[1] = a2;
  a4[2] = a3;
  *a4 = a1;

  return swift_retain();
}

uint64_t specialized Collection<>.subscript.getter@<X0>(uint64_t a1@<X0>, uint64_t a2@<X1>, void *a3@<X2>, char a4@<W3>, uint64_t a5@<X8>)
{
  uint64_t result = OUTLINED_FUNCTION_19_14();
  if (result < 0)
  {
    __break(1u);
    goto LABEL_8;
  }
  if (a1 < 0)
  {
LABEL_8:
    __break(1u);
    goto LABEL_9;
  }
  if (result < a2)
  {
LABEL_9:
    __break(1u);
    return result;
  }
  *(void *)(a5 + 8) = a2;
  *(void *)(a5 + 16) = a3;
  *(unsigned char *)(a5 + 24) = a4 & 1;
  *(void *)a5 = a1;

  return (uint64_t)outlined copy of Result<_DataTable, Error>(a3, a4 & 1);
}

uint64_t specialized Collection<>.subscript.getter@<X0>(uint64_t a1@<X0>, uint64_t a2@<X1>, uint64_t a3@<X2>, uint64_t a4@<X3>, uint64_t a5@<X4>, void *a6@<X8>)
{
  swift_retain();
  swift_bridgeObjectRetain();
  swift_retain_n();
  uint64_t v12 = CMLSequence.size.getter();
  uint64_t v13 = OUTLINED_FUNCTION_12_0(v12);
  swift_retain();
  uint64_t v14 = CMLSequence.size.getter();
  uint64_t v15 = OUTLINED_FUNCTION_12_0(v14);
  uint64_t result = swift_release();
  if (v15 < 0)
  {
    __break(1u);
LABEL_10:
    __break(1u);
    goto LABEL_11;
  }
  swift_retain();
  uint64_t v17 = CMLSequence.size.getter();
  uint64_t v18 = OUTLINED_FUNCTION_12_0(v17);
  swift_bridgeObjectRelease();
  swift_release();
  uint64_t result = swift_release_n();
  if (v13 < 0 || v18 < v13) {
    goto LABEL_10;
  }
  if (a1 < 0)
  {
LABEL_11:
    __break(1u);
    goto LABEL_12;
  }
  if (v13 < a2)
  {
LABEL_12:
    __break(1u);
    return result;
  }
  a6[2] = a3;
  a6[3] = a4;
  a6[4] = a5;
  *a6 = a1;
  a6[1] = a2;
  swift_retain();
  swift_bridgeObjectRetain();

  return swift_retain();
}

uint64_t specialized Collection<>.subscript.getter(uint64_t a1, uint64_t a2, uint64_t (*a3)(void))
{
  uint64_t result = a3();
  if (result < 0)
  {
    __break(1u);
    goto LABEL_6;
  }
  if (a1 < 0)
  {
LABEL_6:
    __break(1u);
    goto LABEL_7;
  }
  if (result >= a2)
  {
    swift_retain();
    return a1;
  }
LABEL_7:
  __break(1u);
  return result;
}

uint64_t specialized Collection._failEarlyRangeCheck(_:bounds:)(uint64_t result, uint64_t a2, uint64_t a3, uint64_t a4)
{
  if (result < a3 || a4 < a2) {
    __break(1u);
  }
  return result;
}

uint64_t specialized Collection._failEarlyRangeCheck(_:bounds:)(long long *a1, long long *a2)
{
  long long v16 = *a1;
  char v17 = *((unsigned char *)a1 + 16);
  outlined init with take of [MLDataValue : MLDataValue].Index._Variant((uint64_t)&v16, (uint64_t)v18);
  uint64_t result = outlined init with take of [MLDataValue : MLDataValue].Index._Variant((uint64_t)v18, (uint64_t)&v19);
  if (v21) {
    goto LABEL_14;
  }
  uint64_t v4 = v19;
  int v5 = v20;
  long long v13 = *a2;
  char v14 = *((unsigned char *)a2 + 16);
  outlined init with take of [MLDataValue : MLDataValue].Index._Variant((uint64_t)&v13, (uint64_t)v15);
  uint64_t result = outlined init with take of [MLDataValue : MLDataValue].Index._Variant((uint64_t)v15, (uint64_t)&v22);
  if (v24) {
    goto LABEL_14;
  }
  if (v5 != v23)
  {
    __break(1u);
    goto LABEL_11;
  }
  if (v4 < v22)
  {
LABEL_11:
    __break(1u);
LABEL_12:
    __break(1u);
    goto LABEL_13;
  }
  long long v10 = *(long long *)((char *)a2 + 24);
  char v11 = *((unsigned char *)a2 + 40);
  outlined init with take of [MLDataValue : MLDataValue].Index._Variant((uint64_t)&v10, (uint64_t)v12);
  uint64_t result = outlined init with take of [MLDataValue : MLDataValue].Index._Variant((uint64_t)v12, (uint64_t)&v25);
  if (v27) {
    goto LABEL_15;
  }
  uint64_t v6 = v25;
  int v7 = v26;
  OUTLINED_FUNCTION_27_10();
  outlined init with take of [MLDataValue : MLDataValue].Index._Variant((uint64_t)&v8, (uint64_t)v9);
  uint64_t result = outlined init with take of [MLDataValue : MLDataValue].Index._Variant((uint64_t)v9, (uint64_t)&v28);
  if (v30) {
    goto LABEL_15;
  }
  if (v7 != v29) {
    goto LABEL_12;
  }
  if (v6 < v28)
  {
LABEL_13:
    __break(1u);
LABEL_14:
    __break(1u);
LABEL_15:
    __break(1u);
  }
  return result;
}

uint64_t specialized Collection.underestimatedCount.getter()
{
  CMLDictionary.size.getter();
  uint64_t v0 = OUTLINED_FUNCTION_29_10();

  return specialized RandomAccessCollection<>.distance(from:to:)(v0, v1);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t result;
  uint64_t v5;
  uint64_t v6;

  swift_retain();
  uint64_t v1 = CMLSequence.size.getter();
  uint64_t v2 = OUTLINED_FUNCTION_12_0(v1);
  swift_retain();
  uint64_t v3 = CMLSequence.size.getter();
  OUTLINED_FUNCTION_12_0(v3);
  uint64_t result = OUTLINED_FUNCTION_74();
  if (v0 < 0)
  {
    __break(1u);
  }
  else
  {
    swift_retain();
    int v5 = CMLSequence.size.getter();
    uint64_t v6 = OUTLINED_FUNCTION_12_0(v5);
    uint64_t result = swift_release_n();
    if ((v2 & 0x8000000000000000) == 0 && v6 >= v2) {
      return v2;
    }
  }
  __break(1u);
  return result;
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t result;
  uint64_t v5;

  swift_retain();
  uint64_t v1 = CMLSequence.size.getter();
  uint64_t v2 = OUTLINED_FUNCTION_12_0(v1);
  swift_release();
  swift_retain();
  uint64_t v3 = CMLSequence.size.getter();
  OUTLINED_FUNCTION_12_0(v3);
  uint64_t result = OUTLINED_FUNCTION_74();
  if (v0 < 0)
  {
    __break(1u);
  }
  else
  {
    swift_retain();
    int v5 = CMLSequence.size.getter();
    OUTLINED_FUNCTION_12_0(v5);
    uint64_t result = OUTLINED_FUNCTION_74();
    if ((v2 & 0x8000000000000000) == 0 && v0 >= v2) {
      return v2;
    }
  }
  __break(1u);
  return result;
}

{
  uint64_t v0;
  uint64_t vars8;

  uint64_t v0 = CMLSequence.size.getter();

  return specialized RandomAccessCollection<>.distance(from:to:)(0, v0);
}

uint64_t specialized Collection._copyToContiguousArray()()
{
  uint64_t v1 = specialized _copyCollectionToContiguousArray<A>(_:)(v0);
  swift_release();
  return v1;
}

{
  uint64_t v0;

  specialized _copyCollectionToContiguousArray<A>(_:)();
  OUTLINED_FUNCTION_105();
  return v0;
}

{
  uint64_t v0;

  specialized _copyCollectionToContiguousArray<A>(_:)();
  OUTLINED_FUNCTION_105();
  return v0;
}

{
  uint64_t v0;
  uint64_t v1;

  uint64_t v1 = specialized _copyCollectionToContiguousArray<A>(_:)(v0);
  swift_release();
  return v1;
}

void *specialized Collection._copyToContiguousArray()(uint64_t a1)
{
  uint64_t v1 = specialized _copyCollectionToContiguousArray<A>(_:)(a1);
  swift_bridgeObjectRelease();
  return v1;
}

uint64_t specialized Collection._copyToContiguousArray()(void *a1, char a2)
{
  char v3 = a2 & 1;
  specialized _copyCollectionToContiguousArray<A>(_:)(a1, a2 & 1);
  uint64_t v5 = v4;
  outlined consume of Result<_DataTable, Error>(a1, v3);
  return v5;
}

uint64_t specialized Collection._copyToContiguousArray()(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v3 = specialized _copyCollectionToContiguousArray<A>(_:)(a1, a2, a3);
  swift_release();
  swift_bridgeObjectRelease();
  swift_release();
  return v3;
}

uint64_t specialized Collection._copyToContiguousArray()(uint64_t a1)
{
  specialized _copyCollectionToContiguousArray<A>(_:)(a1);
  OUTLINED_FUNCTION_105();
  return v1;
}

uint64_t specialized Sequence._copyContents(initializing:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, char a5)
{
  return specialized Sequence._copySequenceContents(initializing:)(a1, a2, a3, a4, a5 & 1);
}

uint64_t Array<A>.featureValue.getter()
{
  type metadata accessor for CMLFeatureValue();
  Array<A>.featureSequence.getter();
  return CMLFeatureValue.__allocating_init(_:)(v0);
}

uint64_t MLDataValue.SequenceType.description.getter()
{
  return MLDataValue.SequenceType.description.getter();
}

{
  uint64_t v0;
  void *v1;
  void *v2;
  Swift::String v3;
  Swift::String v4;

  swift_retain();
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LazyMapSequence<MLDataValue.SequenceType, String>);
  lazy protocol witness table accessor for type LazyMapSequence<MLDataValue.SequenceType, String> and conformance <> LazyMapSequence<A, B>((uint64_t)&lazy protocol witness table cache variable for type LazyMapSequence<MLDataValue.SequenceType, String> and conformance <> LazyMapSequence<A, B>);
  uint64_t v0 = BidirectionalCollection<>.joined(separator:)();
  uint64_t v2 = v1;
  swift_release();
  v3._uint64_t countAndFlagsBits = v0;
  v3._uint64_t object = v2;
  String.append(_:)(v3);
  swift_bridgeObjectRelease();
  swift_bridgeObjectRetain();
  v4._uint64_t countAndFlagsBits = 93;
  v4._uint64_t object = (void *)0xE100000000000000;
  String.append(_:)(v4);
  swift_bridgeObjectRelease();
  return 91;
}

#error "2271265F0: call analysis failed (funcsize=208)"

uint64_t MLDataValue.SequenceType.init()@<X0>(uint64_t *a1@<X8>)
{
  uint64_t result = MEMORY[0x22A676370](0);
  if (result)
  {
    OUTLINED_FUNCTION_26_11();
    uint64_t v3 = OUTLINED_FUNCTION_6_3();
    uint64_t result = OUTLINED_FUNCTION_0_9(v3);
    *a1 = result;
  }
  else
  {
    __break(1u);
  }
  return result;
}

void MLDataValue.SequenceType.init<A>(_:)()
{
  OUTLINED_FUNCTION_19_4();
  uint64_t v38 = v1;
  uint64_t v3 = v2;
  uint64_t v35 = v5;
  uint64_t v36 = v4;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness();
  OUTLINED_FUNCTION_0_15();
  uint64_t v31 = v7;
  OUTLINED_FUNCTION_8_13();
  MEMORY[0x270FA5388](v8);
  long long v10 = (char *)&v30 - v9;
  type metadata accessor for Optional();
  OUTLINED_FUNCTION_8_13();
  MEMORY[0x270FA5388](v11);
  long long v13 = (char *)&v30 - v12;
  OUTLINED_FUNCTION_0_15();
  uint64_t v15 = v14;
  MEMORY[0x270FA5388](v16);
  OUTLINED_FUNCTION_15();
  uint64_t v17 = swift_getAssociatedTypeWitness();
  OUTLINED_FUNCTION_0_15();
  uint64_t v34 = v18;
  OUTLINED_FUNCTION_8_13();
  MEMORY[0x270FA5388](v19);
  uint64_t v20 = MEMORY[0x22A676370](0);
  if (v20)
  {
    uint64_t v21 = v20;
    type metadata accessor for CMLSequence();
    uint64_t v22 = OUTLINED_FUNCTION_6_3();
    *(void *)(v22 + 16) = v21;
    uint64_t v39 = v22;
    *(unsigned char *)(v22 + 24) = 1;
    uint64_t v32 = v15;
    (*(void (**)(uint64_t, uint64_t, uint64_t))(v15 + 16))(v0, v36, v3);
    dispatch thunk of Sequence.makeIterator()();
    uint64_t v33 = v3;
    uint64_t AssociatedConformanceWitness = swift_getAssociatedConformanceWitness();
    uint64_t v40 = v17;
    uint64_t v37 = AssociatedConformanceWitness;
    dispatch thunk of IteratorProtocol.next()();
    OUTLINED_FUNCTION_21_14((uint64_t)v13);
    if (!v24)
    {
      uint64_t v25 = *(void (**)(char *, char *, uint64_t))(v31 + 32);
      int v26 = (void (**)(char *, uint64_t))(v31 + 8);
      do
      {
        v25(v10, v13, AssociatedTypeWitness);
        uint64_t v27 = MLDataValueConvertible.featureValue.getter(AssociatedTypeWitness, v38);
        CMLSequence.append(_:)(v27);
        (*v26)(v10, AssociatedTypeWitness);
        swift_release();
        dispatch thunk of IteratorProtocol.next()();
        OUTLINED_FUNCTION_21_14((uint64_t)v13);
      }
      while (!v24);
    }
    OUTLINED_FUNCTION_25_0();
    v28();
    OUTLINED_FUNCTION_25_0();
    v29();
    *uint64_t v35 = v39;
    OUTLINED_FUNCTION_12_4();
  }
  else
  {
    __break(1u);
    swift_release();
    OUTLINED_FUNCTION_2_33();
    swift_unexpectedError();
    __break(1u);
  }
}

uint64_t MLDataValue.SequenceType.startIndex.getter()
{
  return 0;
}

uint64_t MLDataValue.SequenceType.endIndex.getter()
{
  return CMLSequence.size.getter();
}

uint64_t MLDataValue.SequenceType.subscript.getter@<X0>(uint64_t a1@<X0>, uint64_t a2@<X8>)
{
  uint64_t v5 = *v2;
  swift_retain();
  CMLSequence.value(at:)(a1);
  OUTLINED_FUNCTION_18_12();

  return MLDataValue.init(_:)(v5, a2);
}

uint64_t protocol witness for BidirectionalCollection.index(before:) in conformance MLDataValue.SequenceType@<X0>(uint64_t *a1@<X0>, uint64_t *a2@<X8>)
{
  uint64_t result = specialized RandomAccessCollection<>.index(before:)(*a1);
  *a2 = result;
  return result;
}

uint64_t *protocol witness for BidirectionalCollection.formIndex(before:) in conformance MLDataValue.SequenceType(uint64_t *result)
{
  uint64_t v1 = *result - 1;
  if (__OFSUB__(*result, 1))
  {
    __break(1u);
  }
  else
  {
    uint64_t v2 = result;
    uint64_t result = (uint64_t *)CMLSequence.size.getter();
    if ((v1 & 0x8000000000000000) == 0 && v1 < (uint64_t)result)
    {
      *uint64_t v2 = v1;
      return result;
    }
  }
  __break(1u);
  return result;
}

uint64_t protocol witness for BidirectionalCollection.index(_:offsetBy:) in conformance MLDataValue.SequenceType@<X0>(uint64_t *a1@<X0>, uint64_t a2@<X1>, uint64_t *a3@<X8>)
{
  uint64_t result = specialized RandomAccessCollection<>.index(_:offsetBy:)(*a1, a2);
  *a3 = result;
  return result;
}

uint64_t protocol witness for BidirectionalCollection.distance(from:to:) in conformance MLDataValue.SequenceType()
{
  return specialized RandomAccessCollection<>.distance(from:to:)();
}

uint64_t protocol witness for Collection.endIndex.getter in conformance MLDataValue.SequenceType@<X0>(uint64_t *a1@<X8>)
{
  uint64_t result = MLDataValue.SequenceType.endIndex.getter();
  *a1 = result;
  return result;
}

void (*protocol witness for Collection.subscript.read in conformance MLDataValue.SequenceType(uint64_t a1, uint64_t *a2))(uint64_t a1)
{
  return protocol witness for Collection.subscript.read in conformance MLDataValue.SequenceType;
}

void protocol witness for Collection.subscript.read in conformance MLDataValue.SequenceType(uint64_t a1)
{
}

uint64_t protocol witness for Collection.subscript.getter in conformance MLDataValue.SequenceType@<X0>(uint64_t *a1@<X0>, void *a2@<X8>)
{
  return specialized Collection<>.subscript.getter(*a1, a1[1], *v2, a2);
}

uint64_t protocol witness for Collection.indices.getter in conformance MLDataValue.SequenceType@<X0>(uint64_t *a1@<X8>)
{
  uint64_t result = specialized RandomAccessCollection<>.indices.getter();
  *a1 = result;
  a1[1] = v3;
  return result;
}

BOOL protocol witness for Collection.isEmpty.getter in conformance MLDataValue.SequenceType()
{
  return specialized Collection.isEmpty.getter();
}

uint64_t protocol witness for Collection.count.getter in conformance MLDataValue.SequenceType()
{
  return specialized Collection.count.getter();
}

uint64_t protocol witness for RandomAccessCollection.index(_:offsetBy:limitedBy:) in conformance MLDataValue.SequenceType@<X0>(uint64_t *a1@<X0>, uint64_t a2@<X1>, uint64_t a3@<X8>)
{
  uint64_t result = specialized RandomAccessCollection.index(_:offsetBy:limitedBy:)(*a1, a2);
  *(void *)a3 = result;
  *(unsigned char *)(a3 + 8) = v5 & 1;
  return result;
}

uint64_t protocol witness for Collection._failEarlyRangeCheck(_:bounds:) in conformance MLDataValue.SequenceType(void *a1, void *a2)
{
  return specialized Collection._failEarlyRangeCheck(_:bounds:)(*a1, *a2, a2[1], *v2);
}

{
  void *v2;

  return specialized Collection._failEarlyRangeCheck(_:bounds:)(*a1, *a2, a2[1], *v2);
}

uint64_t protocol witness for Collection.index(after:) in conformance MLDataValue.SequenceType@<X0>(uint64_t *a1@<X0>, uint64_t *a2@<X8>)
{
  uint64_t result = specialized RandomAccessCollection<>.index(after:)(*a1);
  *a2 = result;
  return result;
}

uint64_t protocol witness for Collection.formIndex(after:) in conformance MLDataValue.SequenceType(uint64_t *a1)
{
  uint64_t v2 = *a1;
  uint64_t result = CMLSequence.size.getter();
  if (v2 < 0 || v2 >= result) {
    __break(1u);
  }
  else {
    *a1 = v2 + 1;
  }
  return result;
}

uint64_t protocol witness for Sequence._copyToContiguousArray() in conformance MLDataValue.SequenceType()
{
  return specialized Collection._copyToContiguousArray()();
}

uint64_t protocol witness for Sequence._copyContents(initializing:) in conformance MLDataValue.SequenceType(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return specialized Sequence._copyContents(initializing:)(a1, a2, a3, *v3);
}

#error "227126EE4: call analysis failed (funcsize=131)"

uint64_t static MLDataValue.SequenceType.== infix(_:_:)(uint64_t *a1, uint64_t *a2)
{
  uint64_t v2 = *a1;
  uint64_t v3 = *a2;
  swift_retain();
  CMLSequence.size.getter();
  uint64_t v4 = specialized RandomAccessCollection<>.distance(from:to:)();
  swift_release();
  swift_retain();
  CMLSequence.size.getter();
  OUTLINED_FUNCTION_29_10();
  specialized RandomAccessCollection<>.distance(from:to:)();
  OUTLINED_FUNCTION_18_12();
  if (v4 != v3)
  {
    char v14 = 0;
    return v14 & 1;
  }
  swift_retain();
  CMLSequence.size.getter();
  uint64_t v5 = specialized RandomAccessCollection<>.distance(from:to:)();
  swift_release();
  if ((v5 & 0x8000000000000000) == 0)
  {
    if (v5)
    {
      uint64_t v6 = 0;
      uint64_t v17 = v5 - 1;
      uint64_t v18 = v5;
      uint64_t v19 = v2;
      while (v5 != v6)
      {
        swift_retain_n();
        CMLSequence.value(at:)(v6);
        OUTLINED_FUNCTION_105();
        MLDataValue.init(_:)(&v27, v2);
        swift_release();
        uint64_t v7 = v27;
        uint64_t v8 = v28;
        char v9 = v29;
        v25[0] = v27;
        v25[1] = v28;
        char v26 = v29;
        swift_retain_n();
        CMLSequence.value(at:)(v6);
        OUTLINED_FUNCTION_18_12();
        MLDataValue.init(_:)(&v22, v3);
        uint64_t v10 = v3;
        swift_release();
        uint64_t v12 = v22;
        uint64_t v11 = v23;
        char v13 = v24;
        v20[0] = v22;
        v20[1] = v23;
        char v21 = v24;
        char v14 = static MLDataValue.== infix(_:_:)((uint64_t)v25, (uint64_t)v20);
        outlined consume of MLDataValue(v12, v11, v13);
        outlined consume of MLDataValue(v7, v8, v9);
        if (v14)
        {
          uint64_t v5 = v18;
          BOOL v15 = v17 == v6++;
          uint64_t v3 = v10;
          uint64_t v2 = v19;
          if (!v15) {
            continue;
          }
        }
        return v14 & 1;
      }
      __break(1u);
      goto LABEL_14;
    }
    char v14 = 1;
    return v14 & 1;
  }
LABEL_14:
  __break(1u);
  uint64_t result = OUTLINED_FUNCTION_109();
  __break(1u);
  return result;
}

uint64_t closure #1 in MLDataValue.SequenceType.description.getter@<X0>(uint64_t a1@<X0>, uint64_t a2@<X1>, uint64_t a3@<X2>, uint64_t *a4@<X8>)
{
  uint64_t result = MLDataValue.description.getter(a1, a2, a3);
  *a4 = result;
  a4[1] = v6;
  return result;
}

uint64_t MLDataValue.SequenceType.debugDescription.getter()
{
  return MLDataValue.SequenceType.description.getter();
}

uint64_t closure #1 in MLDataValue.SequenceType.debugDescription.getter@<X0>(uint64_t a1@<X0>, uint64_t *a2@<X8>)
{
  outlined copy of MLDataValue(*(id *)a1, *(id *)(a1 + 8), *(unsigned char *)(a1 + 16));
  uint64_t result = String.init<A>(reflecting:)();
  *a2 = result;
  a2[1] = v4;
  return result;
}

uint64_t protocol witness for BidirectionalCollection.index(before:) in conformance CMLSequence@<X0>(uint64_t *a1@<X0>, uint64_t *a2@<X8>)
{
  uint64_t result = specialized RandomAccessCollection<>.index(before:)(*a1, CMLSequence.size.getter);
  *a2 = result;
  return result;
}

uint64_t protocol witness for BidirectionalCollection.formIndex(before:) in conformance CMLSequence(uint64_t *a1)
{
  uint64_t result = specialized RandomAccessCollection<>.index(before:)(*a1, CMLSequence.size.getter);
  *a1 = result;
  return result;
}

uint64_t protocol witness for BidirectionalCollection.index(_:offsetBy:) in conformance CMLSequence@<X0>(uint64_t *a1@<X0>, uint64_t a2@<X1>, uint64_t *a3@<X8>)
{
  uint64_t result = specialized RandomAccessCollection<>.index(_:offsetBy:)(*a1, a2, CMLSequence.size.getter);
  *a3 = result;
  return result;
}

uint64_t protocol witness for BidirectionalCollection.distance(from:to:) in conformance CMLSequence(uint64_t *a1, uint64_t *a2)
{
  return specialized RandomAccessCollection<>.distance(from:to:)(*a1, *a2);
}

uint64_t protocol witness for Collection.endIndex.getter in conformance CMLSequence@<X0>(uint64_t *a1@<X8>)
{
  uint64_t result = CMLSequence.endIndex.getter();
  *a1 = result;
  return result;
}

uint64_t (*protocol witness for Collection.subscript.read in conformance CMLSequence(void *a1, uint64_t *a2))()
{
  CMLSequence.subscript.getter(*a2);
  *a1 = v3;
  a1[1] = v3;
  return protocol witness for Collection.subscript.read in conformance CMLSequence;
}

uint64_t protocol witness for Collection.subscript.read in conformance CMLSequence()
{
  return swift_release();
}

uint64_t protocol witness for Collection.subscript.getter in conformance CMLSequence@<X0>(uint64_t *a1@<X0>, uint64_t *a2@<X8>)
{
  uint64_t result = specialized Collection<>.subscript.getter(*a1, a1[1], CMLSequence.size.getter);
  *a2 = result;
  a2[1] = v4;
  a2[2] = v5;
  return result;
}

uint64_t protocol witness for Collection.indices.getter in conformance CMLSequence@<X0>(uint64_t *a1@<X8>)
{
  uint64_t result = specialized RandomAccessCollection<>.indices.getter(CMLSequence.size.getter);
  *a1 = result;
  a1[1] = v3;
  return result;
}

BOOL protocol witness for Collection.isEmpty.getter in conformance CMLSequence()
{
  return specialized Collection.isEmpty.getter();
}

uint64_t protocol witness for Collection.count.getter in conformance CMLSequence()
{
  return specialized Collection.count.getter();
}

uint64_t protocol witness for RandomAccessCollection.index(_:offsetBy:limitedBy:) in conformance CMLSequence@<X0>(uint64_t *a1@<X0>, uint64_t a2@<X1>, uint64_t *a3@<X2>, uint64_t a4@<X8>)
{
  uint64_t result = specialized RandomAccessCollection.index(_:offsetBy:limitedBy:)(*a1, a2, *a3, specialized RandomAccessCollection<>.distance(from:to:), CMLSequence.size.getter);
  *(void *)a4 = result;
  *(unsigned char *)(a4 + 8) = v6 & 1;
  return result;
}

uint64_t protocol witness for Collection._failEarlyRangeCheck(_:bounds:) in conformance CMLSequence(uint64_t a1)
{
  uint64_t v1 = OUTLINED_FUNCTION_20_13(a1);
  return specialized Collection._failEarlyRangeCheck(_:bounds:)(v1, v2, v3);
}

{
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;

  uint64_t v1 = OUTLINED_FUNCTION_20_13(a1);
  return specialized Collection._failEarlyRangeCheck(_:bounds:)(v1, v2, v3);
}

uint64_t protocol witness for Collection._failEarlyRangeCheck(_:bounds:) in conformance CMLSequence(uint64_t *a1, uint64_t *a2)
{
  return specialized Collection._failEarlyRangeCheck(_:bounds:)(*a1, a1[1], *a2, a2[1]);
}

uint64_t protocol witness for Collection.index(after:) in conformance CMLSequence@<X0>(uint64_t *a1@<X0>, uint64_t *a2@<X8>)
{
  uint64_t result = specialized RandomAccessCollection<>.index(after:)(*a1);
  *a2 = result;
  return result;
}

uint64_t protocol witness for Collection.formIndex(after:) in conformance CMLSequence(uint64_t *a1)
{
  uint64_t result = specialized RandomAccessCollection<>.index(after:)(*a1);
  *a1 = result;
  return result;
}

uint64_t protocol witness for Sequence.underestimatedCount.getter in conformance CMLSequence()
{
  return specialized Collection.underestimatedCount.getter();
}

uint64_t protocol witness for Sequence._copyToContiguousArray() in conformance CMLSequence()
{
  return specialized Collection._copyToContiguousArray()();
}

uint64_t protocol witness for Sequence._copyContents(initializing:) in conformance CMLSequence()
{
  return specialized Sequence._copyContents(initializing:)();
}

void *MLDataValue.SequenceType.init(from:)@<X0>(uint64_t a1@<X0>, void *a2@<X8>)
{
  uint64_t result = *(void **)a1;
  int v5 = *(unsigned __int8 *)(a1 + 16);
  if (v5 != 3)
  {
    outlined consume of MLDataValue(result, *(id *)(a1 + 8), v5);
    uint64_t result = 0;
  }
  *a2 = result;
  return result;
}

uint64_t MLDataValue.SequenceType.dataValue.getter@<X0>(uint64_t a1@<X8>)
{
  *(void *)a1 = *v1;
  *(void *)(a1 + 8) = 0;
  *(unsigned char *)(a1 + 16) = 3;
  return swift_retain();
}

uint64_t MLDataValue.SequenceType.init(from:)@<X0>(uint64_t a1@<X0>, uint64_t *a2@<X8>)
{
  uint64_t result = specialized handling<A, B>(_:_:)(*(void *)(a1 + 16));
  uint64_t v4 = result;
  if (result)
  {
    type metadata accessor for CMLSequence();
    uint64_t v5 = OUTLINED_FUNCTION_6_3();
    *(void *)(v5 + 16) = v4;
    *(unsigned char *)(v5 + 24) = 1;
    uint64_t result = swift_release();
    *a2 = v5;
  }
  else
  {
    __break(1u);
  }
  return result;
}

#error "2271279F4: call analysis failed (funcsize=169)"

void Array<A>.init(from:)()
{
  OUTLINED_FUNCTION_19_4();
  uint64_t v40 = v0;
  uint64_t v2 = v1;
  uint64_t v4 = v3;
  uint64_t v5 = type metadata accessor for Optional();
  OUTLINED_FUNCTION_0_15();
  uint64_t v7 = v6;
  OUTLINED_FUNCTION_8_13();
  MEMORY[0x270FA5388](v8);
  uint64_t v41 = (uint64_t)&v31 - v9;
  OUTLINED_FUNCTION_0_15();
  uint64_t v11 = v10;
  uint64_t v13 = MEMORY[0x270FA5388](v12);
  uint64_t v39 = (char *)&v31 - ((v14 + 15) & 0xFFFFFFFFFFFFFFF0);
  MEMORY[0x270FA5388](v13);
  uint64_t v38 = (char *)&v31 - v15;
  uint64_t v16 = *(void **)v4;
  uint64_t v17 = *(void **)(v4 + 8);
  int v18 = *(unsigned __int8 *)(v4 + 16);
  if (v18 != 3)
  {
    outlined consume of MLDataValue(*(void **)v4, *(id *)(v4 + 8), v18);
LABEL_11:
    OUTLINED_FUNCTION_12_4();
    return;
  }
  uint64_t v45 = Array.init()();
  swift_retain();
  if (!CMLSequence.size.getter())
  {
    outlined consume of MLDataValue(v16, v17, 3);
    outlined consume of MLDataValue(v16, v17, 3);
    goto LABEL_11;
  }
  uint64_t v32 = v5;
  id v33 = v17;
  uint64_t v31 = v7;
  uint64_t v19 = 0;
  uint64_t v36 = (void (**)(char *, uint64_t, uint64_t))(v11 + 32);
  uint64_t v37 = v40 + 16;
  uint64_t v34 = v11 + 8;
  uint64_t v35 = (void (**)(char *, char *, uint64_t))(v11 + 16);
  while (1)
  {
    swift_retain();
    CMLSequence.value(at:)(v19);
    uint64_t v21 = v20;
    swift_release();
    MLDataValue.init(_:)(v21, (uint64_t)&v42);
    int v23 = v42;
    uint64_t v22 = v43;
    char v24 = v44;
    swift_retain();
    uint64_t v25 = CMLSequence.size.getter();
    swift_release();
    if (v19 >= v25) {
      break;
    }
    unint64_t v42 = v23;
    unint64_t v43 = v22;
    char v44 = v24;
    uint64_t v26 = v40;
    uint64_t v27 = *(void (**)(void **, uint64_t, uint64_t))(v40 + 16);
    outlined copy of MLDataValue(v23, v22, v24);
    v27(&v42, v2, v26);
    uint64_t v28 = v41;
    if (__swift_getEnumTagSinglePayload(v41, 1, v2) == 1)
    {
      outlined consume of MLDataValue(v23, v22, v24);
      outlined consume of MLDataValue(v16, v33, 3);
      swift_release();
      swift_bridgeObjectRelease();
      (*(void (**)(uint64_t, uint64_t))(v31 + 8))(v28, v32);
      goto LABEL_11;
    }
    ++v19;
    char v29 = v38;
    (*v36)(v38, v28, v2);
    (*v35)(v39, v29, v2);
    type metadata accessor for Array();
    Array.append(_:)();
    outlined consume of MLDataValue(v23, v22, v24);
    OUTLINED_FUNCTION_25_0();
    v30();
    if (v19 == CMLSequence.size.getter())
    {
      swift_release();
      outlined consume of MLDataValue(v16, v33, 3);
      goto LABEL_11;
    }
  }
  __break(1u);
  OUTLINED_FUNCTION_109();
  __break(1u);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  char *v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  char *v16;
  uint64_t v17;
  char *v18;
  uint64_t v19;
  uint64_t inited;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  char v24;
  void (*v25)(void);
  void v26[4];
  void (**v27)(char *, uint64_t, uint64_t);
  char *v28;
  char *v29;
  uint64_t v30;
  uint64_t v31;

  OUTLINED_FUNCTION_19_4();
  uint64_t v30 = v0;
  uint64_t v2 = v1;
  uint64_t v4 = v3;
  uint64_t v5 = type metadata accessor for Optional();
  OUTLINED_FUNCTION_0_15();
  uint64_t v7 = v6;
  OUTLINED_FUNCTION_8_13();
  MEMORY[0x270FA5388](v8);
  uint64_t v10 = (char *)v26 - v9;
  OUTLINED_FUNCTION_0_15();
  uint64_t v12 = v11;
  uint64_t v14 = MEMORY[0x270FA5388](v13);
  uint64_t v16 = (char *)v26 - ((v15 + 15) & 0xFFFFFFFFFFFFFFF0);
  MEMORY[0x270FA5388](v14);
  int v18 = (char *)v26 - v17;
  uint64_t v19 = specialized handling<A, B>(_:_:)(*(void *)(v4 + 16));
  uint64_t v28 = v16;
  char v29 = v10;
  v26[3] = v7;
  if (v19)
  {
    type metadata accessor for CMLSequence();
    uint64_t inited = swift_initStackObject();
    OUTLINED_FUNCTION_0_9(inited);
    uint64_t v31 = Array.init()();
    swift_retain();
    uint64_t v21 = CMLSequence.size.getter();
    uint64_t v22 = (uint64_t)v29;
    if (v21)
    {
      v26[1] = v5;
      v26[2] = v4;
      int v23 = 0;
      uint64_t v27 = (void (**)(char *, uint64_t, uint64_t))(v12 + 32);
      while (1)
      {
        CMLSequence.value(at:)(v23);
        swift_retain();
        int v23 = specialized RandomAccessCollection<>.index(after:)(v23);
        swift_release();
        static MLDataValueConvertible.makeInstance(featureValue:)(v2, v30, v22);
        OUTLINED_FUNCTION_21_14(v22);
        if (v24) {
          break;
        }
        (*v27)(v18, v22, v2);
        (*(void (**)(char *, char *, uint64_t))(v12 + 16))(v28, v18, v2);
        type metadata accessor for Array();
        uint64_t v22 = (uint64_t)v29;
        Array.append(_:)();
        swift_release();
        (*(void (**)(char *, uint64_t))(v12 + 8))(v18, v2);
        if (v23 == CMLSequence.size.getter()) {
          goto LABEL_6;
        }
      }
      swift_release_n();
      swift_release();
      swift_release();
      swift_bridgeObjectRelease();
      OUTLINED_FUNCTION_25_0();
      v25();
    }
    else
    {
LABEL_6:
      swift_release();
      swift_release();
      swift_release();
    }
    OUTLINED_FUNCTION_12_4();
  }
  else
  {
    __break(1u);
    OUTLINED_FUNCTION_108();
    __break(1u);
  }
}

void *Array<A>.dataValue.getter@<X0>(uint64_t a1@<X0>, uint64_t a2@<X1>, uint64_t a3@<X2>, uint64_t a4@<X8>)
{
  *(void *)&long long v15 = a1;
  uint64_t v7 = type metadata accessor for Array();
  uint64_t WitnessTable = swift_getWitnessTable();
  MEMORY[0x22A674CB0](&v13, v7, WitnessTable);
  uint64_t v17 = v13;
  uint64_t v9 = swift_allocObject();
  *(void *)(v9 + 16) = a2;
  *(void *)(v9 + 24) = a3;
  type metadata accessor for LazySequence();
  swift_getWitnessTable();
  LazySequenceProtocol.map<A>(_:)();
  swift_release();
  swift_bridgeObjectRelease();
  long long v13 = v15;
  uint64_t v14 = v16;
  uint64_t v10 = type metadata accessor for LazyMapSequence();
  uint64_t v11 = swift_getWitnessTable();
  uint64_t result = MLDataValue.SequenceType.init<A>(_:)(&v17, &v13, v10, v11);
  *(void *)a4 = v17;
  *(void *)(a4 + 8) = 0;
  *(unsigned char *)(a4 + 16) = 3;
  return result;
}

void Array<A>.featureSequence.getter()
{
  OUTLINED_FUNCTION_19_4();
  uint64_t v23 = v1;
  uint64_t v3 = v2;
  uint64_t v5 = v4;
  OUTLINED_FUNCTION_0_15();
  uint64_t v7 = v6;
  uint64_t v9 = *(void *)(v8 + 64);
  uint64_t v11 = MEMORY[0x270FA5388](v10);
  uint64_t v12 = (char *)&v20 - ((v9 + 15) & 0xFFFFFFFFFFFFFFF0);
  MEMORY[0x270FA5388](v11);
  uint64_t v14 = (char *)&v20 - v13;
  if (MEMORY[0x22A676370](0))
  {
    OUTLINED_FUNCTION_26_11();
    uint64_t v15 = OUTLINED_FUNCTION_6_3();
    *(void *)(v15 + 16) = v0;
    uint64_t v24 = v15;
    *(unsigned char *)(v15 + 24) = 1;
    swift_bridgeObjectRetain();
    uint64_t v16 = Array.startIndex.getter();
    uint64_t v26 = v16;
    if (v16 != MEMORY[0x22A674E10](v5, v3))
    {
      uint64_t v21 = v9;
      uint64_t v22 = (void (**)(char *, uint64_t *, uint64_t))(v7 + 16);
      do
      {
        Swift::Bool IsNativeType = Array._hoistableIsNativeTypeChecked()();
        Array._checkSubscript(_:wasNativeTypeChecked:)();
        if (IsNativeType)
        {
          (*(void (**)(char *, unint64_t, uint64_t))(v7 + 16))(v14, v5+ ((*(unsigned __int8 *)(v7 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v7 + 80))+ *(void *)(v7 + 72) * v16, v3);
        }
        else
        {
          uint64_t v19 = _ArrayBuffer._getElementSlowPath(_:)();
          if (v21 != 8)
          {
            __break(1u);
            goto LABEL_12;
          }
          uint64_t v25 = v19;
          (*v22)(v14, &v25, v3);
          swift_unknownObjectRelease();
        }
        swift_bridgeObjectRetain();
        MEMORY[0x22A674E20](&v26, v5, v3);
        swift_bridgeObjectRelease();
        (*(void (**)(char *, char *, uint64_t))(v7 + 32))(v12, v14, v3);
        uint64_t v18 = MLDataValueConvertible.featureValue.getter(v3, v23);
        CMLSequence.append(_:)(v18);
        (*(void (**)(char *, uint64_t))(v7 + 8))(v12, v3);
        swift_release();
        uint64_t v16 = v26;
      }
      while (v16 != MEMORY[0x22A674E10](v5, v3));
    }
    swift_bridgeObjectRelease();
    OUTLINED_FUNCTION_12_4();
  }
  else
  {
LABEL_12:
    __break(1u);
    swift_release();
    OUTLINED_FUNCTION_2_33();
    swift_unexpectedError();
    __break(1u);
  }
}

uint64_t Array<A>.featureColumn.getter(uint64_t a1, uint64_t a2, uint64_t a3)
{
  Array<A>.featureSequence.getter();
  uint64_t v6 = v5;
  (*(void (**)(uint64_t *__return_ptr, uint64_t, uint64_t))(a3 + 8))(&v9, a2, a3);
  unint64_t v7 = 0x5060403020100uLL >> (8 * v9);
  type metadata accessor for CMLColumn();
  return CMLColumn.__allocating_init(_:type:)(v6, v7);
}

void protocol witness for MLDataValueConvertible.init(from:) in conformance <A> [A](void *a1@<X8>)
{
  Array<A>.init(from:)();
  *a1 = v2;
}

uint64_t protocol witness for MLDataValueConvertible.init() in conformance <A> [A]@<X0>(uint64_t *a1@<X8>)
{
  uint64_t result = Array.init()();
  *a1 = result;
  return result;
}

void *protocol witness for MLDataValueConvertible.dataValue.getter in conformance <A> [A]@<X0>(uint64_t a1@<X0>, uint64_t a2@<X1>, uint64_t a3@<X8>)
{
  return Array<A>.dataValue.getter(*v3, *(void *)(a1 + 16), *(void *)(a2 - 8), a3);
}

void protocol witness for FeatureValueConvertible.init(from:) in conformance <A> [A](void *a1@<X8>)
{
  Array<A>.init(from:)();
  *a1 = v2;
}

uint64_t protocol witness for FeatureValueConvertible.featureValue.getter in conformance <A> [A]()
{
  return Array<A>.featureValue.getter();
}

uint64_t protocol witness for CMLColumnConvertible.featureColumn.getter in conformance <A> [A](uint64_t a1, uint64_t a2)
{
  return Array<A>.featureColumn.getter(*v2, *(void *)(a1 + 16), *(void *)(a2 - 8));
}

uint64_t sub_22712879C()
{
  return MEMORY[0x270FA0238](v0, 32, 7);
}

uint64_t partial apply for closure #1 in Array<A>.dataValue.getter()
{
  return (*(uint64_t (**)(void))(*(void *)(v0 + 24) + 32))(*(void *)(v0 + 16));
}

unint64_t associated type witness table accessor for Collection.Indices : RandomAccessCollection in MLDataValue.SequenceType()
{
  return _sSnySiGSnyxGSksSxRzSZ6StrideRpzrlWlTm_0((uint64_t)&lazy protocol witness table cache variable for type Range<Int> and conformance <> Range<A>);
}

unint64_t associated type witness table accessor for Collection.SubSequence : RandomAccessCollection in MLDataValue.SequenceType()
{
  return lazy protocol witness table accessor for type LazyMapSequence<MLDataValue.SequenceType, String> and conformance <> LazyMapSequence<A, B>((uint64_t)&lazy protocol witness table cache variable for type Slice<MLDataValue.SequenceType> and conformance <> Slice<A>);
}

unint64_t lazy protocol witness table accessor for type LazyMapSequence<MLDataValue.SequenceType, String> and conformance <> LazyMapSequence<A, B>(uint64_t a1)
{
  unint64_t result = OUTLINED_FUNCTION_17_14(a1);
  if (!result)
  {
    uint64_t v5 = v4;
    __swift_instantiateConcreteTypeFromMangledNameAbstract(v3);
    v5();
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, v1);
  }
  return result;
}

unint64_t associated type witness table accessor for Collection.Indices : BidirectionalCollection in MLDataValue.SequenceType()
{
  return _sSnySiGSnyxGSksSxRzSZ6StrideRpzrlWlTm_0((uint64_t)&lazy protocol witness table cache variable for type Range<Int> and conformance <> Range<A>);
}

unint64_t associated type witness table accessor for Collection.SubSequence : BidirectionalCollection in MLDataValue.SequenceType()
{
  return lazy protocol witness table accessor for type LazyMapSequence<MLDataValue.SequenceType, String> and conformance <> LazyMapSequence<A, B>((uint64_t)&lazy protocol witness table cache variable for type Slice<MLDataValue.SequenceType> and conformance <> Slice<A>);
}

unint64_t associated type witness table accessor for Collection.Indices : Collection in MLDataValue.SequenceType()
{
  return _sSnySiGSnyxGSksSxRzSZ6StrideRpzrlWlTm_0((uint64_t)&lazy protocol witness table cache variable for type Range<Int> and conformance <> Range<A>);
}

unint64_t _sSnySiGSnyxGSksSxRzSZ6StrideRpzrlWlTm_0(uint64_t a1)
{
  unint64_t result = OUTLINED_FUNCTION_17_14(a1);
  if (!result)
  {
    __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for Range<Int>);
    lazy protocol witness table accessor for type Int and conformance Int();
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, v1);
  }
  return result;
}

unint64_t associated type witness table accessor for Collection.SubSequence : Collection in MLDataValue.SequenceType()
{
  return lazy protocol witness table accessor for type Slice<MLDataValue.SequenceType> and conformance Slice<A>((uint64_t)&lazy protocol witness table cache variable for type Slice<MLDataValue.SequenceType> and conformance Slice<A>);
}

unint64_t associated type witness table accessor for Sequence.Iterator : IteratorProtocol in MLDataValue.SequenceType()
{
  return lazy protocol witness table accessor for type Slice<MLDataValue.SequenceType> and conformance Slice<A>((uint64_t)&lazy protocol witness table cache variable for type IndexingIterator<MLDataValue.SequenceType> and conformance IndexingIterator<A>);
}

uint64_t instantiation function for generic protocol witness table for <A> [A](uint64_t a1)
{
  uint64_t result = swift_getWitnessTable();
  *(void *)(a1 + 8) = result;
  return result;
}

unint64_t associated type witness table accessor for Sequence.Iterator : IteratorProtocol in CMLSequence()
{
  return lazy protocol witness table accessor for type Slice<MLDataValue.SequenceType> and conformance Slice<A>((uint64_t)&lazy protocol witness table cache variable for type IndexingIterator<CMLSequence> and conformance IndexingIterator<A>);
}

unint64_t base witness table accessor for Sequence in CMLSequence()
{
  return lazy protocol witness table accessor for type CMLSequence and conformance CMLSequence((uint64_t)&lazy protocol witness table cache variable for type CMLSequence and conformance CMLSequence);
}

unint64_t associated type witness table accessor for Collection.SubSequence : Collection in CMLSequence()
{
  return lazy protocol witness table accessor for type Slice<MLDataValue.SequenceType> and conformance Slice<A>((uint64_t)&lazy protocol witness table cache variable for type Slice<CMLSequence> and conformance Slice<A>);
}

unint64_t lazy protocol witness table accessor for type Slice<MLDataValue.SequenceType> and conformance Slice<A>(uint64_t a1)
{
  unint64_t result = OUTLINED_FUNCTION_17_14(a1);
  if (!result)
  {
    __swift_instantiateConcreteTypeFromMangledNameAbstract(v3);
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, v1);
  }
  return result;
}

unint64_t base witness table accessor for Collection in CMLSequence()
{
  return lazy protocol witness table accessor for type CMLSequence and conformance CMLSequence((uint64_t)&lazy protocol witness table cache variable for type CMLSequence and conformance CMLSequence);
}

unint64_t associated type witness table accessor for Collection.SubSequence : BidirectionalCollection in CMLSequence()
{
  return lazy protocol witness table accessor for type Slice<CMLSequence> and conformance <> Slice<A>((uint64_t)&lazy protocol witness table cache variable for type Slice<CMLSequence> and conformance <> Slice<A>);
}

unint64_t lazy protocol witness table accessor for type Slice<CMLSequence> and conformance <> Slice<A>(uint64_t a1)
{
  unint64_t result = OUTLINED_FUNCTION_17_14(a1);
  if (!result)
  {
    uint64_t v4 = v3;
    __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for Slice<CMLSequence>);
    lazy protocol witness table accessor for type CMLSequence and conformance CMLSequence(v4);
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, v1);
  }
  return result;
}

unint64_t base witness table accessor for BidirectionalCollection in CMLSequence()
{
  return lazy protocol witness table accessor for type CMLSequence and conformance CMLSequence((uint64_t)&lazy protocol witness table cache variable for type CMLSequence and conformance CMLSequence);
}

unint64_t associated type witness table accessor for Collection.SubSequence : RandomAccessCollection in CMLSequence()
{
  return lazy protocol witness table accessor for type Slice<CMLSequence> and conformance <> Slice<A>((uint64_t)&lazy protocol witness table cache variable for type Slice<CMLSequence> and conformance <> Slice<A>);
}

unint64_t lazy protocol witness table accessor for type CMLSequence and conformance CMLSequence(uint64_t a1)
{
  unint64_t result = OUTLINED_FUNCTION_17_14(a1);
  if (!result)
  {
    type metadata accessor for CMLSequence();
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, v1);
  }
  return result;
}

uint64_t outlined retain of Range<MLDataValue.DictionaryType.Index>(uint64_t a1)
{
  uint64_t v2 = *(void *)(a1 + 24);
  uint64_t v3 = *(void *)(a1 + 32);
  char v4 = *(unsigned char *)(a1 + 40);
  outlined copy of [A : B].Index._Variant<A, B>(*(void *)a1, *(void *)(a1 + 8), *(unsigned char *)(a1 + 16));
  outlined copy of [A : B].Index._Variant<A, B>(v2, v3, v4);
  return a1;
}

uint64_t OUTLINED_FUNCTION_2_33()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_4_28()
{
  return CMLFeatureValue.init(rawValue:ownsValue:)(v0, 1);
}

uint64_t OUTLINED_FUNCTION_6_21()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_9_18()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_10_17()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_11_16()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_17_14(uint64_t a1)
{
  return *(void *)a1;
}

uint64_t OUTLINED_FUNCTION_18_12()
{
  return swift_release();
}

uint64_t OUTLINED_FUNCTION_19_14()
{
  return MLDataTable.size.getter();
}

uint64_t OUTLINED_FUNCTION_20_13(uint64_t a1)
{
  return *(void *)a1;
}

uint64_t OUTLINED_FUNCTION_21_14(uint64_t a1)
{
  return __swift_getEnumTagSinglePayload(a1, 1, v1);
}

void OUTLINED_FUNCTION_24_13(unsigned char *a1@<X8>)
{
  *a1 = 3;
}

uint64_t OUTLINED_FUNCTION_26_11()
{
  return type metadata accessor for CMLSequence();
}

__n128 OUTLINED_FUNCTION_27_10()
{
  return *(__n128 *)(v0 + 24);
}

uint64_t OUTLINED_FUNCTION_29_10()
{
  return 0;
}

void *initializeBufferWithCopyOfBuffer for MLLogisticRegressionClassifier.Model(void *a1, void *a2, uint64_t a3)
{
  int v5 = *(_DWORD *)(*(void *)(a3 - 8) + 80);
  if ((v5 & 0x20000) != 0)
  {
    uint64_t v12 = *a2;
    *a1 = *a2;
    a1 = (void *)(v12 + ((v5 + 16) & ~(unint64_t)v5));
    swift_retain();
  }
  else
  {
    uint64_t v7 = a2[1];
    *a1 = *a2;
    a1[1] = v7;
    uint64_t v9 = a2 + 2;
    uint64_t v8 = a2[2];
    swift_bridgeObjectRetain();
    if (v8)
    {
      uint64_t v10 = a2[3];
      uint64_t v11 = a2[4];
      a1[2] = v8;
      a1[3] = v10;
      a1[4] = v11;
      swift_bridgeObjectRetain();
      swift_bridgeObjectRetain();
    }
    else
    {
      *((_OWORD *)a1 + 1) = *v9;
      a1[4] = a2[4];
    }
    uint64_t v13 = *(int *)(a3 + 24);
    uint64_t v14 = (char *)a1 + v13;
    uint64_t v15 = (char *)a2 + v13;
    uint64_t v16 = type metadata accessor for BaseLogisticRegressionClassifierModel();
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v16 - 8) + 16))(v14, v15, v16);
    uint64_t v17 = *(int *)(a3 + 28);
    uint64_t v18 = (char *)a1 + v17;
    uint64_t v19 = (char *)a2 + v17;
    uint64_t v20 = *(void *)v19;
    LOBYTE(v19) = v19[8];
    *(void *)uint64_t v18 = v20;
    v18[8] = (char)v19;
    swift_bridgeObjectRetain();
  }
  return a1;
}

uint64_t destroy for MLLogisticRegressionClassifier.Model(uint64_t a1, uint64_t a2)
{
  swift_bridgeObjectRelease();
  if (*(void *)(a1 + 16))
  {
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
  }
  uint64_t v4 = a1 + *(int *)(a2 + 24);
  uint64_t v5 = type metadata accessor for BaseLogisticRegressionClassifierModel();
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v5 - 8) + 8))(v4, v5);

  return swift_bridgeObjectRelease();
}

void *initializeWithCopy for MLLogisticRegressionClassifier.Model(void *a1, void *a2, uint64_t a3)
{
  uint64_t v6 = a2[1];
  *a1 = *a2;
  a1[1] = v6;
  uint64_t v8 = a2 + 2;
  uint64_t v7 = a2[2];
  swift_bridgeObjectRetain();
  if (v7)
  {
    uint64_t v9 = a2[3];
    uint64_t v10 = a2[4];
    a1[2] = v7;
    a1[3] = v9;
    a1[4] = v10;
    swift_bridgeObjectRetain();
    swift_bridgeObjectRetain();
  }
  else
  {
    *((_OWORD *)a1 + 1) = *(_OWORD *)v8;
    a1[4] = v8[2];
  }
  uint64_t v11 = *(int *)(a3 + 24);
  uint64_t v12 = (char *)a1 + v11;
  uint64_t v13 = (char *)a2 + v11;
  uint64_t v14 = type metadata accessor for BaseLogisticRegressionClassifierModel();
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v14 - 8) + 16))(v12, v13, v14);
  uint64_t v15 = *(int *)(a3 + 28);
  uint64_t v16 = (char *)a1 + v15;
  uint64_t v17 = (char *)a2 + v15;
  uint64_t v18 = *(void *)v17;
  LOBYTE(v17) = v17[8];
  *(void *)uint64_t v16 = v18;
  v16[8] = (char)v17;
  swift_bridgeObjectRetain();
  return a1;
}

void *assignWithCopy for MLLogisticRegressionClassifier.Model(void *a1, void *a2, uint64_t a3)
{
  *a1 = *a2;
  a1[1] = a2[1];
  swift_bridgeObjectRetain();
  swift_bridgeObjectRelease();
  uint64_t v6 = a1 + 2;
  uint64_t v8 = a2 + 2;
  uint64_t v7 = a2[2];
  if (a1[2])
  {
    if (v7)
    {
      a1[2] = v7;
      swift_bridgeObjectRetain();
      swift_bridgeObjectRelease();
      a1[3] = a2[3];
      a1[4] = a2[4];
      swift_bridgeObjectRetain();
      swift_bridgeObjectRelease();
    }
    else
    {
      outlined destroy of FeatureVectorizer<Double>.Transformer((uint64_t)(a1 + 2));
      uint64_t v9 = a2[4];
      *uint64_t v6 = *v8;
      a1[4] = v9;
    }
  }
  else if (v7)
  {
    a1[2] = v7;
    a1[3] = a2[3];
    a1[4] = a2[4];
    swift_bridgeObjectRetain();
    swift_bridgeObjectRetain();
  }
  else
  {
    long long v10 = *v8;
    a1[4] = a2[4];
    *uint64_t v6 = v10;
  }
  uint64_t v11 = *(int *)(a3 + 24);
  uint64_t v12 = (char *)a1 + v11;
  uint64_t v13 = (char *)a2 + v11;
  uint64_t v14 = type metadata accessor for BaseLogisticRegressionClassifierModel();
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v14 - 8) + 24))(v12, v13, v14);
  uint64_t v15 = *(int *)(a3 + 28);
  uint64_t v16 = (char *)a1 + v15;
  uint64_t v17 = (char *)a2 + v15;
  uint64_t v18 = *(void *)v17;
  LOBYTE(v17) = v17[8];
  *(void *)uint64_t v16 = v18;
  v16[8] = (char)v17;
  swift_bridgeObjectRetain();
  swift_bridgeObjectRelease();
  return a1;
}

uint64_t outlined destroy of FeatureVectorizer<Double>.Transformer(uint64_t a1)
{
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FeatureVectorizer<Double>.Transformer);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v2 - 8) + 8))(a1, v2);
  return a1;
}

uint64_t initializeWithTake for MLLogisticRegressionClassifier.Model(uint64_t a1, uint64_t a2, uint64_t a3)
{
  long long v6 = *(_OWORD *)(a2 + 16);
  *(_OWORD *)a1 = *(_OWORD *)a2;
  *(_OWORD *)(a1 + 16) = v6;
  *(void *)(a1 + 32) = *(void *)(a2 + 32);
  uint64_t v7 = *(int *)(a3 + 24);
  uint64_t v8 = a1 + v7;
  uint64_t v9 = a2 + v7;
  uint64_t v10 = type metadata accessor for BaseLogisticRegressionClassifierModel();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v10 - 8) + 32))(v8, v9, v10);
  uint64_t v11 = *(int *)(a3 + 28);
  uint64_t v12 = a1 + v11;
  uint64_t v13 = a2 + v11;
  *(void *)uint64_t v12 = *(void *)v13;
  *(unsigned char *)(v12 + 8) = *(unsigned char *)(v13 + 8);
  return a1;
}

void *assignWithTake for MLLogisticRegressionClassifier.Model(void *a1, void *a2, uint64_t a3)
{
  uint64_t v6 = a2[1];
  *a1 = *a2;
  a1[1] = v6;
  swift_bridgeObjectRelease();
  uint64_t v7 = a2[2];
  if (!a1[2]) {
    goto LABEL_5;
  }
  if (!v7)
  {
    outlined destroy of FeatureVectorizer<Double>.Transformer((uint64_t)(a1 + 2));
LABEL_5:
    *((_OWORD *)a1 + 1) = *((_OWORD *)a2 + 1);
    a1[4] = a2[4];
    goto LABEL_6;
  }
  a1[2] = v7;
  swift_bridgeObjectRelease();
  uint64_t v8 = a2[4];
  a1[3] = a2[3];
  a1[4] = v8;
  swift_bridgeObjectRelease();
LABEL_6:
  uint64_t v9 = *(int *)(a3 + 24);
  uint64_t v10 = (char *)a1 + v9;
  uint64_t v11 = (char *)a2 + v9;
  uint64_t v12 = type metadata accessor for BaseLogisticRegressionClassifierModel();
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 40))(v10, v11, v12);
  uint64_t v13 = *(int *)(a3 + 28);
  uint64_t v14 = (char *)a1 + v13;
  uint64_t v15 = (char *)a2 + v13;
  uint64_t v16 = *(void *)v15;
  LOBYTE(v15) = v15[8];
  *(void *)uint64_t v14 = v16;
  v14[8] = (char)v15;
  swift_bridgeObjectRelease();
  return a1;
}

uint64_t getEnumTagSinglePayload for MLLogisticRegressionClassifier.Model(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return MEMORY[0x270FA0340](a1, a2, a3, sub_22712966C);
}

uint64_t sub_22712966C(uint64_t a1, uint64_t a2, uint64_t a3)
{
  if (a2 == 0x7FFFFFFF)
  {
    unint64_t v4 = *(void *)(a1 + 8);
    if (v4 >= 0xFFFFFFFF) {
      LODWORD(v4) = -1;
    }
    return (v4 + 1);
  }
  else
  {
    uint64_t v8 = type metadata accessor for BaseLogisticRegressionClassifierModel();
    uint64_t v9 = a1 + *(int *)(a3 + 24);
    return __swift_getEnumTagSinglePayload(v9, a2, v8);
  }
}

uint64_t storeEnumTagSinglePayload for MLLogisticRegressionClassifier.Model(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return MEMORY[0x270FA0580](a1, a2, a3, a4, sub_227129708);
}

uint64_t sub_227129708(uint64_t result, uint64_t a2, int a3, uint64_t a4)
{
  uint64_t v5 = result;
  if (a3 == 0x7FFFFFFF)
  {
    *(void *)(result + 8) = (a2 - 1);
  }
  else
  {
    uint64_t v7 = type metadata accessor for BaseLogisticRegressionClassifierModel();
    uint64_t v8 = v5 + *(int *)(a4 + 24);
    return __swift_storeEnumTagSinglePayload(v8, a2, a2, v7);
  }
  return result;
}

uint64_t type metadata accessor for MLLogisticRegressionClassifier.Model()
{
  uint64_t result = type metadata singleton initialization cache for MLLogisticRegressionClassifier.Model;
  if (!type metadata singleton initialization cache for MLLogisticRegressionClassifier.Model) {
    return swift_getSingletonMetadata();
  }
  return result;
}

uint64_t type metadata completion function for MLLogisticRegressionClassifier.Model()
{
  uint64_t result = type metadata accessor for BaseLogisticRegressionClassifierModel();
  if (v1 <= 0x3F)
  {
    swift_initStructMetadata();
    return 0;
  }
  return result;
}

void MLLogisticRegressionClassifier.Model.computeMetrics(on:)(uint64_t a1@<X0>, uint64_t a2@<X8>)
{
  uint64_t v6 = type metadata accessor for AnyColumn();
  uint64_t v7 = MEMORY[0x270FA5388](v6 - 8);
  MEMORY[0x270FA5388](v7);
  uint64_t v8 = type metadata accessor for DataFrame();
  OUTLINED_FUNCTION_0();
  uint64_t v10 = v9;
  MEMORY[0x270FA5388](v11);
  uint64_t v13 = (char *)v16 - ((v12 + 15) & 0xFFFFFFFFFFFFFFF0);
  MLLogisticRegressionClassifier.Model.applied(to:eventHandler:)((uint64_t)v13);
  if (!v3)
  {
    v16[1] = a1;
    void v16[3] = a2;
    uint64_t v15 = *v2;
    uint64_t v14 = v2[1];
    MEMORY[0x22A672220](*v2, v14);
    MEMORY[0x22A672220](v15, v14);
    AnyClassificationMetrics.init(_:_:)();
    (*(void (**)(char *, uint64_t))(v10 + 8))(v13, v8);
  }
}

void MLLogisticRegressionClassifier.Model.applied(to:eventHandler:)(uint64_t a1@<X8>)
{
  uint64_t v3 = v1;
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DenseMatrix<Double>);
  OUTLINED_FUNCTION_0();
  uint64_t v7 = v6;
  MEMORY[0x270FA5388](v8);
  uint64_t v10 = (char *)&v17 - ((v9 + 15) & 0xFFFFFFFFFFFFFFF0);
  if (*(void *)(v3 + 16))
  {
    specialized FeatureVectorizer.Transformer.vectorized(_:includingBias:)();
    if (!v2)
    {
      uint64_t v17 = a1;
      type metadata accessor for MLLogisticRegressionClassifier.Model();
      uint64_t v11 = BaseLogisticRegressionClassifierModel.applied(features:eventHandler:)();
      MEMORY[0x270FA5388](v11);
      if (v12)
      {
        _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents26ClassificationDistributionVySiGG_AHySSGs5NeverOTg5();
        swift_bridgeObjectRelease();
        uint64_t v13 = OUTLINED_FUNCTION_1_27();
        specialized MLLogisticRegressionClassifier.Model.buildDataFrame<A>(_:)(v13, v14);
      }
      else
      {
        _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents26ClassificationDistributionVySiGG_AIs5NeverOTg5();
        swift_bridgeObjectRelease();
        uint64_t v15 = OUTLINED_FUNCTION_1_27();
        specialized MLLogisticRegressionClassifier.Model.buildDataFrame<A>(_:)(v15, v16);
      }
      swift_bridgeObjectRelease();
      (*(void (**)(char *, uint64_t))(v7 + 8))(v10, v5);
    }
  }
  else
  {
    _assertionFailure(_:_:file:line:flags:)();
    __break(1u);
  }
}

uint64_t specialized MLLogisticRegressionClassifier.Model.buildDataFrame<A>(_:)@<X0>(uint64_t a1@<X0>, uint64_t a2@<X8>)
{
  uint64_t v20 = a2;
  uint64_t v17 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Int>);
  uint64_t v19 = *(void *)(v17 - 8);
  MEMORY[0x270FA5388](v17);
  uint64_t v5 = (char *)&v15 - ((v4 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v16 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<ClassificationDistribution<Int>>);
  uint64_t v18 = *(void *)(v16 - 8);
  MEMORY[0x270FA5388](v16);
  uint64_t v7 = (char *)&v15 - ((v6 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v8 = v2[1];
  uint64_t v23 = *v2;
  uint64_t v24 = v8;
  swift_bridgeObjectRetain();
  v9._uint64_t countAndFlagsBits = 0x6C696261626F7250;
  v9._uint64_t object = (void *)0xEB00000000797469;
  String.append(_:)(v9);
  uint64_t v23 = a1;
  swift_bridgeObjectRetain();
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ClassificationDistribution<Int>);
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [ClassificationDistribution<Int>]);
  lazy protocol witness table accessor for type [ClassificationDistribution<Int>] and conformance [A](&lazy protocol witness table cache variable for type [ClassificationDistribution<Int>] and conformance [A], &demangling cache variable for type metadata for [ClassificationDistribution<Int>]);
  Column.init<A>(name:contents:)();
  uint64_t v21 = MEMORY[0x263F8D6C8];
  uint64_t v22 = MEMORY[0x263F8D6D8];
  swift_getKeyPath();
  swift_bridgeObjectRetain();
  swift_retain();
  uint64_t MLComponents26ClassificationDistributionVySiGG_SiSgs5NeverOTg503_s8d81ML22AnyTreeClassifierModelV14buildDataFramey07TabularH00hI0VSay0A12MLComponents26fG26VyxGGSHRzlFxSgAKcfu_Si_TG5s7KeyPathCyAiKGTf1cn_n = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents26ClassificationDistributionVySiGG_SiSgs5NeverOTg503_s8d81ML22AnyTreeClassifierModelV14buildDataFramey07TabularH00hI0VSay0A12MLComponents26fG26VyxGGSHRzlFxSgAKcfu_Si_TG5s7KeyPathCyAiKGTf1cn_n(a1);
  swift_release();
  uint64_t v23 = MLComponents26ClassificationDistributionVySiGG_SiSgs5NeverOTg503_s8d81ML22AnyTreeClassifierModelV14buildDataFramey07TabularH00hI0VSay0A12MLComponents26fG26VyxGGSHRzlFxSgAKcfu_Si_TG5s7KeyPathCyAiKGTf1cn_n;
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Int?]);
  lazy protocol witness table accessor for type [ClassificationDistribution<Int>] and conformance [A](&lazy protocol witness table cache variable for type [Int?] and conformance [A], &demangling cache variable for type metadata for [Int?]);
  Column.init<A>(name:contents:)();
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<AnyColumn>);
  type metadata accessor for AnyColumn();
  uint64_t v11 = swift_allocObject();
  *(_OWORD *)(v11 + 16) = xmmword_2272CB4D0;
  uint64_t v12 = v17;
  Column.eraseToAnyColumn()();
  uint64_t v13 = v16;
  Column.eraseToAnyColumn()();
  uint64_t v23 = v11;
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [AnyColumn]);
  lazy protocol witness table accessor for type [ClassificationDistribution<Int>] and conformance [A](&lazy protocol witness table cache variable for type [AnyColumn] and conformance [A], &demangling cache variable for type metadata for [AnyColumn]);
  DataFrame.init<A>(columns:)();
  (*(void (**)(char *, uint64_t))(v19 + 8))(v5, v12);
  return (*(uint64_t (**)(char *, uint64_t))(v18 + 8))(v7, v13);
}

{
  uint64_t *v2;
  uint64_t v4;
  char *v5;
  uint64_t v6;
  char *v7;
  uint64_t v8;
  Swift::String v9;
  uint64_t MLComponents26ClassificationDistributionVySSGG_SSSgs5NeverOTg503_s8d81ML22AnyTreeClassifierModelV14buildDataFramey07TabularH00hI0VSay0A12MLComponents26fG26VyxGGSHRzlFxSgAKcfu_SS_TG5s7KeyPathCyAiKGTf1cn_n;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t v24;

  uint64_t v20 = a2;
  uint64_t v17 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  uint64_t v19 = *(void *)(v17 - 8);
  MEMORY[0x270FA5388](v17);
  uint64_t v5 = (char *)&v15 - ((v4 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v16 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<ClassificationDistribution<String>>);
  uint64_t v18 = *(void *)(v16 - 8);
  MEMORY[0x270FA5388](v16);
  uint64_t v7 = (char *)&v15 - ((v6 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v8 = v2[1];
  uint64_t v23 = *v2;
  uint64_t v24 = v8;
  swift_bridgeObjectRetain();
  v9._uint64_t countAndFlagsBits = 0x6C696261626F7250;
  v9._uint64_t object = (void *)0xEB00000000797469;
  String.append(_:)(v9);
  uint64_t v23 = a1;
  swift_bridgeObjectRetain();
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ClassificationDistribution<String>);
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [ClassificationDistribution<String>]);
  lazy protocol witness table accessor for type [ClassificationDistribution<Int>] and conformance [A](&lazy protocol witness table cache variable for type [ClassificationDistribution<String>] and conformance [A], &demangling cache variable for type metadata for [ClassificationDistribution<String>]);
  Column.init<A>(name:contents:)();
  uint64_t v21 = MEMORY[0x263F8D310];
  uint64_t v22 = MEMORY[0x263F8D320];
  swift_getKeyPath();
  swift_bridgeObjectRetain();
  swift_retain();
  MLComponents26ClassificationDistributionVySSGG_SSSgs5NeverOTg503_s8d81ML22AnyTreeClassifierModelV14buildDataFramey07TabularH00hI0VSay0A12MLComponents26fG26VyxGGSHRzlFxSgAKcfu_SS_TG5s7KeyPathCyAiKGTf1cn_n = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents26ClassificationDistributionVySSGG_SSSgs5NeverOTg503_s8d81ML22AnyTreeClassifierModelV14buildDataFramey07TabularH00hI0VSay0A12MLComponents26fG26VyxGGSHRzlFxSgAKcfu_SS_TG5s7KeyPathCyAiKGTf1cn_n(a1);
  swift_release();
  uint64_t v23 = MLComponents26ClassificationDistributionVySSGG_SSSgs5NeverOTg503_s8d81ML22AnyTreeClassifierModelV14buildDataFramey07TabularH00hI0VSay0A12MLComponents26fG26VyxGGSHRzlFxSgAKcfu_SS_TG5s7KeyPathCyAiKGTf1cn_n;
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String?]);
  lazy protocol witness table accessor for type [ClassificationDistribution<Int>] and conformance [A](&lazy protocol witness table cache variable for type [String?] and conformance [A], &demangling cache variable for type metadata for [String?]);
  Column.init<A>(name:contents:)();
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<AnyColumn>);
  type metadata accessor for AnyColumn();
  uint64_t v11 = swift_allocObject();
  *(_OWORD *)(v11 + 16) = xmmword_2272CB4D0;
  uint64_t v12 = v17;
  Column.eraseToAnyColumn()();
  uint64_t v13 = v16;
  Column.eraseToAnyColumn()();
  uint64_t v23 = v11;
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [AnyColumn]);
  lazy protocol witness table accessor for type [ClassificationDistribution<Int>] and conformance [A](&lazy protocol witness table cache variable for type [AnyColumn] and conformance [A], &demangling cache variable for type metadata for [AnyColumn]);
  DataFrame.init<A>(columns:)();
  (*(void (**)(char *, uint64_t))(v19 + 8))(v5, v12);
  return (*(uint64_t (**)(char *, uint64_t))(v18 + 8))(v7, v13);
}

uint64_t closure #1 in MLLogisticRegressionClassifier.Model.convertDistribution(_:labels:)(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = *(void *)(a2 + 16);
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Classification<Int>);
  Classification.label.getter();
  if ((v4 & 0x8000000000000000) == 0 && v4 < v2)
  {
    Classification.label.getter();
    if ((v4 & 0x8000000000000000) == 0 && v4 < v2)
    {
      Classification.probability.getter();
      return Classification.init(label:probability:)();
    }
    __break(1u);
  }
  uint64_t result = _assertionFailure(_:_:file:line:flags:)();
  __break(1u);
  return result;
}

{
  uint64_t v2;
  uint64_t result;
  uint64_t v4;

  uint64_t v2 = *(void *)(a2 + 16);
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Classification<Int>);
  Classification.label.getter();
  if ((v4 & 0x8000000000000000) == 0 && v4 < v2)
  {
    Classification.label.getter();
    if ((v4 & 0x8000000000000000) == 0 && v4 < v2)
    {
      swift_bridgeObjectRetain();
      Classification.probability.getter();
      return Classification.init(label:probability:)();
    }
    __break(1u);
  }
  uint64_t result = _assertionFailure(_:_:file:line:flags:)();
  __break(1u);
  return result;
}

uint64_t protocol witness for Transformer.applied(to:eventHandler:) in conformance MLLogisticRegressionClassifier.Model(uint64_t a1)
{
  MLLogisticRegressionClassifier.Model.applied(to:eventHandler:)(a1);
  uint64_t v2 = *(uint64_t (**)(void))(v1 + 8);
  return protocol witness for SupervisedTabularEstimator.fitted(to:validateOn:eventHandler:) in conformance TreeRegressor(v2);
}

unint64_t lazy protocol witness table accessor for type MLLogisticRegressionClassifier.Model and conformance MLLogisticRegressionClassifier.Model()
{
  unint64_t result = lazy protocol witness table cache variable for type MLLogisticRegressionClassifier.Model and conformance MLLogisticRegressionClassifier.Model;
  if (!lazy protocol witness table cache variable for type MLLogisticRegressionClassifier.Model and conformance MLLogisticRegressionClassifier.Model)
  {
    type metadata accessor for MLLogisticRegressionClassifier.Model();
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type MLLogisticRegressionClassifier.Model and conformance MLLogisticRegressionClassifier.Model);
  }
  return result;
}

uint64_t partial apply for closure #2 in MLLogisticRegressionClassifier.Model.applied(to:eventHandler:)()
{
  return closure #1 in AnyTreeClassifierModel.applied(to:eventHandler:)();
}

uint64_t partial apply for closure #1 in MLLogisticRegressionClassifier.Model.applied(to:eventHandler:)()
{
  return closure #1 in AnyTreeClassifierModel.applied(to:eventHandler:)();
}

uint64_t sub_22712A71C()
{
  return 16;
}

__n128 sub_22712A728(__n128 *a1, __n128 *a2)
{
  __n128 result = *a1;
  *a2 = *a1;
  return result;
}

uint64_t partial apply for closure #1 in MLLogisticRegressionClassifier.Model.convertDistribution(_:labels:)(uint64_t a1)
{
  return closure #1 in MLLogisticRegressionClassifier.Model.convertDistribution(_:labels:)(a1, *(void *)(v1 + 16));
}

{
  uint64_t v1;

  return closure #1 in MLLogisticRegressionClassifier.Model.convertDistribution(_:labels:)(a1, *(void *)(v1 + 16));
}

uint64_t OUTLINED_FUNCTION_1_27()
{
  return v0;
}

uint64_t destroy for ClassificationMetricsContainer()
{
  swift_release();
  swift_release();

  return swift_bridgeObjectRelease();
}

void *initializeBufferWithCopyOfBuffer for ClassificationMetricsContainer(void *a1, void *a2)
{
  uint64_t v3 = a2[1];
  *a1 = *a2;
  a1[1] = v3;
  a1[2] = a2[2];
  swift_retain();
  swift_retain();
  swift_bridgeObjectRetain();
  return a1;
}

void *assignWithCopy for ClassificationMetricsContainer(void *a1, void *a2)
{
  *a1 = *a2;
  swift_retain();
  swift_release();
  a1[1] = a2[1];
  swift_retain();
  swift_release();
  a1[2] = a2[2];
  swift_bridgeObjectRetain();
  swift_bridgeObjectRelease();
  return a1;
}

uint64_t assignWithTake for ClassificationMetricsContainer(uint64_t a1, uint64_t a2)
{
  *(_OWORD *)a1 = *(_OWORD *)a2;
  swift_release();
  *(void *)(a1 + 16) = *(void *)(a2 + 16);
  swift_bridgeObjectRelease();
  return a1;
}

ValueMetadata *type metadata accessor for ClassificationMetricsContainer()
{
  return &type metadata for ClassificationMetricsContainer;
}

uint64_t initializeBufferWithCopyOfBuffer for MLLogisticRegressionClassifier.Classifier(uint64_t a1, uint64_t *a2, uint64_t a3)
{
  int v5 = *(_DWORD *)(*(void *)(a3 - 8) + 80);
  if ((v5 & 0x20000) != 0)
  {
    uint64_t v11 = *a2;
    *(void *)a1 = *a2;
    a1 = v11 + ((v5 + 16) & ~(unint64_t)v5);
    swift_retain();
  }
  else
  {
    uint64_t v7 = a2[1];
    *(void *)a1 = *a2;
    *(void *)(a1 + 8) = v7;
    uint64_t v8 = a2[3];
    *(void *)(a1 + 16) = a2[2];
    *(void *)(a1 + 24) = v8;
    Swift::String v9 = a2 + 4;
    uint64_t v10 = a2[7];
    swift_bridgeObjectRetain();
    swift_bridgeObjectRetain();
    if (v10)
    {
      *(void *)(a1 + 56) = v10;
      (**(void (***)(uint64_t, uint64_t, uint64_t))(v10 - 8))(a1 + 32, (uint64_t)(a2 + 4), v10);
    }
    else
    {
      long long v12 = *((_OWORD *)a2 + 3);
      *(_OWORD *)(a1 + 32) = *v9;
      *(_OWORD *)(a1 + 48) = v12;
    }
    long long v13 = *((_OWORD *)a2 + 5);
    *(_OWORD *)(a1 + 64) = *((_OWORD *)a2 + 4);
    *(_OWORD *)(a1 + 80) = v13;
    *(unsigned char *)(a1 + 96) = *((unsigned char *)a2 + 96);
    char v14 = *((unsigned char *)a2 + 112);
    *(void *)(a1 + 104) = a2[13];
    *(unsigned char *)(a1 + 112) = v14;
    uint64_t v15 = a2[16];
    *(void *)(a1 + 120) = a2[15];
    *(void *)(a1 + 128) = v15;
    uint64_t v16 = a2[17];
    uint64_t v17 = *(int *)(a3 + 36);
    uint64_t v18 = a1 + v17;
    uint64_t v19 = (uint64_t)a2 + v17;
    *(void *)(a1 + 136) = v16;
    uint64_t v20 = type metadata accessor for BaseLogisticRegressionClassifier();
    uint64_t v21 = *(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v20 - 8) + 16);
    swift_bridgeObjectRetain();
    swift_bridgeObjectRetain();
    swift_bridgeObjectRetain();
    v21(v18, v19, v20);
  }
  return a1;
}

uint64_t destroy for MLLogisticRegressionClassifier.Classifier(uint64_t a1, uint64_t a2)
{
  swift_bridgeObjectRelease();
  swift_bridgeObjectRelease();
  if (*(void *)(a1 + 56)) {
    __swift_destroy_boxed_opaque_existential_0(a1 + 32);
  }
  swift_bridgeObjectRelease();
  swift_bridgeObjectRelease();
  swift_bridgeObjectRelease();
  uint64_t v4 = a1 + *(int *)(a2 + 36);
  uint64_t v5 = type metadata accessor for BaseLogisticRegressionClassifier();
  uint64_t v6 = *(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v5 - 8) + 8);

  return v6(v4, v5);
}

uint64_t initializeWithCopy for MLLogisticRegressionClassifier.Classifier(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v6 = *(void *)(a2 + 8);
  *(void *)a1 = *(void *)a2;
  *(void *)(a1 + 8) = v6;
  uint64_t v7 = *(void *)(a2 + 24);
  *(void *)(a1 + 16) = *(void *)(a2 + 16);
  *(void *)(a1 + 24) = v7;
  uint64_t v8 = (_OWORD *)(a2 + 32);
  uint64_t v9 = *(void *)(a2 + 56);
  swift_bridgeObjectRetain();
  swift_bridgeObjectRetain();
  if (v9)
  {
    *(void *)(a1 + 56) = v9;
    (**(void (***)(uint64_t, _OWORD *, uint64_t))(v9 - 8))(a1 + 32, v8, v9);
  }
  else
  {
    long long v10 = v8[1];
    *(_OWORD *)(a1 + 32) = *v8;
    *(_OWORD *)(a1 + 48) = v10;
  }
  long long v11 = *(_OWORD *)(a2 + 80);
  *(_OWORD *)(a1 + 64) = *(_OWORD *)(a2 + 64);
  *(_OWORD *)(a1 + 80) = v11;
  *(unsigned char *)(a1 + 96) = *(unsigned char *)(a2 + 96);
  char v12 = *(unsigned char *)(a2 + 112);
  *(void *)(a1 + 104) = *(void *)(a2 + 104);
  *(unsigned char *)(a1 + 112) = v12;
  uint64_t v13 = *(void *)(a2 + 128);
  *(void *)(a1 + 120) = *(void *)(a2 + 120);
  *(void *)(a1 + 128) = v13;
  uint64_t v14 = *(void *)(a2 + 136);
  uint64_t v15 = *(int *)(a3 + 36);
  uint64_t v16 = a1 + v15;
  uint64_t v17 = a2 + v15;
  *(void *)(a1 + 136) = v14;
  uint64_t v18 = type metadata accessor for BaseLogisticRegressionClassifier();
  uint64_t v19 = *(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v18 - 8) + 16);
  swift_bridgeObjectRetain();
  swift_bridgeObjectRetain();
  swift_bridgeObjectRetain();
  v19(v16, v17, v18);
  return a1;
}

uint64_t assignWithCopy for MLLogisticRegressionClassifier.Classifier(uint64_t a1, uint64_t a2, uint64_t a3)
{
  *(void *)a1 = *(void *)a2;
  *(void *)(a1 + 8) = *(void *)(a2 + 8);
  swift_bridgeObjectRetain();
  swift_bridgeObjectRelease();
  *(void *)(a1 + 16) = *(void *)(a2 + 16);
  swift_bridgeObjectRetain();
  swift_bridgeObjectRelease();
  *(void *)(a1 + 24) = *(void *)(a2 + 24);
  uint64_t v6 = *(void *)(a2 + 56);
  if (!*(void *)(a1 + 56))
  {
    if (v6)
    {
      *(void *)(a1 + 56) = v6;
      (**(void (***)(uint64_t, uint64_t))(v6 - 8))(a1 + 32, a2 + 32);
      goto LABEL_8;
    }
LABEL_7:
    long long v7 = *(_OWORD *)(a2 + 48);
    *(_OWORD *)(a1 + 32) = *(_OWORD *)(a2 + 32);
    *(_OWORD *)(a1 + 48) = v7;
    goto LABEL_8;
  }
  if (!v6)
  {
    __swift_destroy_boxed_opaque_existential_0(a1 + 32);
    goto LABEL_7;
  }
  __swift_assign_boxed_opaque_existential_0((uint64_t *)(a1 + 32), (uint64_t *)(a2 + 32));
LABEL_8:
  *(void *)(a1 + 64) = *(void *)(a2 + 64);
  *(void *)(a1 + 72) = *(void *)(a2 + 72);
  *(void *)(a1 + 80) = *(void *)(a2 + 80);
  *(void *)(a1 + 88) = *(void *)(a2 + 88);
  *(unsigned char *)(a1 + 96) = *(unsigned char *)(a2 + 96);
  char v8 = *(unsigned char *)(a2 + 112);
  *(void *)(a1 + 104) = *(void *)(a2 + 104);
  *(unsigned char *)(a1 + 112) = v8;
  swift_bridgeObjectRetain();
  swift_bridgeObjectRelease();
  *(void *)(a1 + 120) = *(void *)(a2 + 120);
  swift_bridgeObjectRetain();
  swift_bridgeObjectRelease();
  *(void *)(a1 + 128) = *(void *)(a2 + 128);
  *(void *)(a1 + 136) = *(void *)(a2 + 136);
  swift_bridgeObjectRetain();
  swift_bridgeObjectRelease();
  uint64_t v9 = *(int *)(a3 + 36);
  uint64_t v10 = a1 + v9;
  uint64_t v11 = a2 + v9;
  uint64_t v12 = type metadata accessor for BaseLogisticRegressionClassifier();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v12 - 8) + 24))(v10, v11, v12);
  return a1;
}

uint64_t initializeWithTake for MLLogisticRegressionClassifier.Classifier(uint64_t a1, uint64_t a2, uint64_t a3)
{
  *(_OWORD *)a1 = *(_OWORD *)a2;
  *(void *)(a1 + 16) = *(void *)(a2 + 16);
  memcpy((void *)(a1 + 24), (const void *)(a2 + 24), 0x49uLL);
  *(void *)(a1 + 104) = *(void *)(a2 + 104);
  *(unsigned char *)(a1 + 112) = *(unsigned char *)(a2 + 112);
  *(_OWORD *)(a1 + 120) = *(_OWORD *)(a2 + 120);
  *(void *)(a1 + 136) = *(void *)(a2 + 136);
  uint64_t v6 = *(int *)(a3 + 36);
  uint64_t v7 = a1 + v6;
  uint64_t v8 = a2 + v6;
  uint64_t v9 = type metadata accessor for BaseLogisticRegressionClassifier();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v9 - 8) + 32))(v7, v8, v9);
  return a1;
}

uint64_t assignWithTake for MLLogisticRegressionClassifier.Classifier(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v6 = *(void *)(a2 + 8);
  *(void *)a1 = *(void *)a2;
  *(void *)(a1 + 8) = v6;
  swift_bridgeObjectRelease();
  *(void *)(a1 + 16) = *(void *)(a2 + 16);
  swift_bridgeObjectRelease();
  *(void *)(a1 + 24) = *(void *)(a2 + 24);
  if (*(void *)(a1 + 56)) {
    __swift_destroy_boxed_opaque_existential_0(a1 + 32);
  }
  long long v7 = *(_OWORD *)(a2 + 48);
  *(_OWORD *)(a1 + 32) = *(_OWORD *)(a2 + 32);
  *(_OWORD *)(a1 + 48) = v7;
  long long v8 = *(_OWORD *)(a2 + 80);
  *(_OWORD *)(a1 + 64) = *(_OWORD *)(a2 + 64);
  *(_OWORD *)(a1 + 80) = v8;
  *(unsigned char *)(a1 + 96) = *(unsigned char *)(a2 + 96);
  char v9 = *(unsigned char *)(a2 + 112);
  *(void *)(a1 + 104) = *(void *)(a2 + 104);
  *(unsigned char *)(a1 + 112) = v9;
  swift_bridgeObjectRelease();
  *(void *)(a1 + 120) = *(void *)(a2 + 120);
  swift_bridgeObjectRelease();
  uint64_t v10 = *(void *)(a2 + 136);
  *(void *)(a1 + 128) = *(void *)(a2 + 128);
  *(void *)(a1 + 136) = v10;
  swift_bridgeObjectRelease();
  uint64_t v11 = *(int *)(a3 + 36);
  uint64_t v12 = a1 + v11;
  uint64_t v13 = a2 + v11;
  uint64_t v14 = type metadata accessor for BaseLogisticRegressionClassifier();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v14 - 8) + 40))(v12, v13, v14);
  return a1;
}

uint64_t getEnumTagSinglePayload for MLLogisticRegressionClassifier.Classifier(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return MEMORY[0x270FA0340](a1, a2, a3, sub_22712B018);
}

uint64_t sub_22712B018(uint64_t a1, uint64_t a2, uint64_t a3)
{
  if (a2 == 0x7FFFFFFF)
  {
    unint64_t v4 = *(void *)(a1 + 8);
    if (v4 >= 0xFFFFFFFF) {
      LODWORD(v4) = -1;
    }
    return (v4 + 1);
  }
  else
  {
    uint64_t v8 = type metadata accessor for BaseLogisticRegressionClassifier();
    uint64_t v9 = a1 + *(int *)(a3 + 36);
    return __swift_getEnumTagSinglePayload(v9, a2, v8);
  }
}

uint64_t storeEnumTagSinglePayload for MLLogisticRegressionClassifier.Classifier(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return MEMORY[0x270FA0580](a1, a2, a3, a4, sub_22712B0B4);
}

uint64_t sub_22712B0B4(uint64_t result, uint64_t a2, int a3, uint64_t a4)
{
  uint64_t v5 = result;
  if (a3 == 0x7FFFFFFF)
  {
    *(void *)(result + 8) = (a2 - 1);
  }
  else
  {
    uint64_t v7 = type metadata accessor for BaseLogisticRegressionClassifier();
    uint64_t v8 = v5 + *(int *)(a4 + 36);
    return __swift_storeEnumTagSinglePayload(v8, a2, a2, v7);
  }
  return result;
}

uint64_t type metadata accessor for MLLogisticRegressionClassifier.Classifier()
{
  uint64_t result = type metadata singleton initialization cache for MLLogisticRegressionClassifier.Classifier;
  if (!type metadata singleton initialization cache for MLLogisticRegressionClassifier.Classifier) {
    return swift_getSingletonMetadata();
  }
  return result;
}

uint64_t type metadata completion function for MLLogisticRegressionClassifier.Classifier()
{
  uint64_t result = type metadata accessor for BaseLogisticRegressionClassifier();
  if (v1 <= 0x3F)
  {
    swift_initStructMetadata();
    return 0;
  }
  return result;
}

uint64_t associated type witness table accessor for SupervisedTabularEstimator.Transformer : TabularTransformer in MLLogisticRegressionClassifier.Classifier()
{
  return lazy protocol witness table accessor for type MLLogisticRegressionClassifier.Model and conformance MLLogisticRegressionClassifier.Model(&lazy protocol witness table cache variable for type MLLogisticRegressionClassifier.Model and conformance MLLogisticRegressionClassifier.Model, (void (*)(uint64_t))type metadata accessor for MLLogisticRegressionClassifier.Model);
}

void MLLogisticRegressionClassifier.Classifier.init(trainingLabelsColumn:validationLabelsColumn:annotationColumnName:featureColumnNames:parameters:)()
{
  OUTLINED_FUNCTION_9_0();
  uint64_t v36 = v2;
  uint64_t v37 = v0;
  uint64_t v4 = v3;
  uint64_t v6 = v5;
  uint64_t v8 = v7;
  uint64_t v10 = v9;
  uint64_t v35 = v11;
  uint64_t v13 = v12;
  uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifier<Double, Int>.Configuration);
  OUTLINED_FUNCTION_0();
  uint64_t v16 = v15;
  MEMORY[0x270FA5388](v17);
  OUTLINED_FUNCTION_5_23();
  MEMORY[0x270FA5388](v18);
  uint64_t v20 = (char *)&v34 - v19;
  *(void *)uint64_t v13 = v10;
  *(void *)(v13 + 8) = v8;
  *(void *)(v13 + 16) = v6;
  uint64_t v34 = v13 + 24;
  outlined init with copy of MLLogisticRegressionClassifier.ModelParameters(v4, v13 + 24);
  *(void *)(v13 + 120) = v6;
  *(void *)(v13 + 128) = 0xD000000000000013;
  *(void *)(v13 + 136) = 0x80000002272D4D10;
  uint64_t v39 = v4;
  outlined init with copy of MLLogisticRegressionClassifier.ModelParameters(v4, (uint64_t)v38);
  lazy protocol witness table accessor for type Double and conformance Double();
  swift_bridgeObjectRetain();
  LogisticRegressionClassifier.Configuration.init()();
  LogisticRegressionClassifier.Configuration.maximumIterations.setter();
  LogisticRegressionClassifier.Configuration.l1Penalty.setter();
  LogisticRegressionClassifier.Configuration.l2Penalty.setter();
  LogisticRegressionClassifier.Configuration.stepSize.setter();
  LogisticRegressionClassifier.Configuration.convergenceThreshold.setter();
  outlined destroy of MLLogisticRegressionClassifier.ModelParameters((uint64_t)v38);
  (*(void (**)(uint64_t, char *, uint64_t))(v16 + 16))(v1, v20, v14);
  type metadata accessor for MLLogisticRegressionClassifier.Classifier();
  BaseLogisticRegressionClassifier.init(configuration:)();
  uint64_t v21 = v36;
  uint64_t v22 = v37;
  uint64_t v23 = static Labels.collected(from:_:)(v35, v36);
  uint64_t v37 = v22;
  if (v22)
  {
    outlined destroy of MLLogisticRegressionClassifier.ModelParameters(v39);
    outlined destroy of DefaultIndices<DataFrame.Rows>((uint64_t)v21, &demangling cache variable for type metadata for AnyColumn?);
    type metadata accessor for AnyColumn();
    OUTLINED_FUNCTION_6_19();
    OUTLINED_FUNCTION_25_0();
    v25();
    uint64_t v26 = OUTLINED_FUNCTION_9_19();
    v27(v26);
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    outlined destroy of MLLogisticRegressionClassifier.ModelParameters(v34);
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    type metadata accessor for BaseLogisticRegressionClassifier();
    OUTLINED_FUNCTION_6_19();
    OUTLINED_FUNCTION_25_0();
    v28();
  }
  else
  {
    uint64_t v29 = v23;
    char v30 = v24;
    outlined destroy of MLLogisticRegressionClassifier.ModelParameters(v39);
    outlined destroy of DefaultIndices<DataFrame.Rows>((uint64_t)v21, &demangling cache variable for type metadata for AnyColumn?);
    type metadata accessor for AnyColumn();
    OUTLINED_FUNCTION_6_19();
    OUTLINED_FUNCTION_25_0();
    v31();
    uint64_t v32 = OUTLINED_FUNCTION_9_19();
    v33(v32);
    *(void *)(v13 + 104) = v29;
    *(unsigned char *)(v13 + 112) = v30 & 1;
  }
  OUTLINED_FUNCTION_8_1();
}

void MLLogisticRegressionClassifier.Classifier.fitted(to:validateOn:eventHandler:)()
{
  OUTLINED_FUNCTION_9_0();
  uint64_t v77 = v3;
  uint64_t v78 = v4;
  uint64_t v81 = v5;
  uint64_t v7 = v6;
  uint64_t v74 = v8;
  type metadata accessor for BaseLogisticRegressionClassifierModel();
  OUTLINED_FUNCTION_0();
  uint64_t v72 = v10;
  uint64_t v73 = v9;
  MEMORY[0x270FA5388](v9);
  OUTLINED_FUNCTION_49();
  uint64_t v75 = v11;
  MEMORY[0x270FA5388](v12);
  uint64_t v71 = (char *)v66 - v13;
  uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
  MEMORY[0x270FA5388](v14 - 8);
  OUTLINED_FUNCTION_33_0();
  uint64_t v80 = v15;
  uint64_t v84 = type metadata accessor for DataFrame();
  OUTLINED_FUNCTION_0();
  uint64_t v76 = v16;
  MEMORY[0x270FA5388](v17);
  OUTLINED_FUNCTION_27_7();
  uint64_t v18 = type metadata accessor for AnyColumn();
  OUTLINED_FUNCTION_0();
  unint64_t v82 = v19;
  MEMORY[0x270FA5388](v20);
  OUTLINED_FUNCTION_3_0();
  uint64_t v23 = v22 - v21;
  uint64_t v24 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DenseMatrix<Double>);
  OUTLINED_FUNCTION_0();
  uint64_t v79 = v25;
  uint64_t v27 = MEMORY[0x270FA5388](v26);
  uint64_t v29 = (char *)v66 - ((v28 + 15) & 0xFFFFFFFFFFFFFFF0);
  MEMORY[0x270FA5388](v27);
  uint64_t v31 = (char *)v66 - v30;
  uint64_t v32 = v0[2];
  uint64_t v83 = v7;
  v85[2] = v7;
  swift_bridgeObjectRetain();
  uint64_t ML16ColumnDescriptorVsAE_pTg5 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSaySSG_8CreateML16ColumnDescriptorVsAE_pTg5((uint64_t)closure #1 in FeatureVectorizer.fitted(to:)partial apply, (uint64_t)v85, v32);
  swift_bridgeObjectRelease();
  if (!v1)
  {
    uint64_t v69 = v23;
    uint64_t v70 = v18;
    v66[1] = v29;
    uint64_t v67 = v2;
    uint64_t v68 = v24;
    unint64_t v86 = v0;
    uint64_t v34 = v84;
    OUTLINED_FUNCTION_8_20();
    specialized FeatureVectorizer.Transformer.vectorized(_:includingBias:)();
    v66[0] = 0;
    uint64_t v35 = v0[13];
    char v36 = *((unsigned char *)v0 + 112);
    uint64_t v37 = v69;
    MEMORY[0x22A672220](*v0, v0[1]);
    uint64_t v38 = Labels.encodeAnnotations(_:)(v37, v35, v36);
    uint64_t v39 = v82 + 8;
    uint64_t v40 = (void (*)(uint64_t, uint64_t))*((void *)v82 + 1);
    v40(v37, v70);
    uint64_t v41 = v80;
    outlined init with copy of DataFrame?(v81, v80);
    if (__swift_getEnumTagSinglePayload(v41, 1, v34) == 1)
    {
      uint64_t v81 = (uint64_t)"raining samples.";
      outlined destroy of DefaultIndices<DataFrame.Rows>(v41, &demangling cache variable for type metadata for DataFrame?);
      type metadata accessor for MLLogisticRegressionClassifier.Classifier();
      uint64_t v42 = v75;
      unint64_t v43 = (void *)v66[0];
      BaseLogisticRegressionClassifier.fitted(features:annotations:classCount:eventHandler:)();
      OUTLINED_FUNCTION_25_0();
      v44();
      swift_bridgeObjectRelease();
      uint64_t v45 = v86;
      Swift::Bool v46 = v43;
      if (!v43)
      {
        v66[0] = 0;
        uint64_t v47 = *v86;
        uint64_t v48 = v86[1];
        uint64_t v49 = type metadata accessor for MLLogisticRegressionClassifier.Model();
        uint64_t v50 = OUTLINED_FUNCTION_13_19(v49);
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v72 + 32))(v50, v42, v73);
LABEL_11:
        uint64_t v63 = v45[13];
        char v64 = *((unsigned char *)v45 + 112);
        *Swift::Bool v46 = v47;
        v46[1] = v48;
        v46[2] = ML16ColumnDescriptorVsAE_pTg5;
        v46[3] = 0xD000000000000013;
        v46[4] = v81 | 0x8000000000000000;
        uint64_t v65 = (char *)v46 + *((int *)v31 + 7);
        *(void *)uint64_t v65 = v63;
        v65[8] = v64;
        swift_bridgeObjectRetain();
        swift_bridgeObjectRetain();
        goto LABEL_4;
      }
      swift_bridgeObjectRelease();
    }
    else
    {
      unint64_t v82 = v39;
      uint64_t v83 = v38;
      uint64_t v51 = v76;
      uint64_t v52 = v67;
      (*(void (**)(uint64_t, uint64_t, uint64_t))(v76 + 32))(v67, v41, v34);
      OUTLINED_FUNCTION_8_20();
      uint64_t v53 = v66[0];
      specialized FeatureVectorizer.Transformer.vectorized(_:includingBias:)();
      if (!v53)
      {
        uint64_t v81 = (uint64_t)"raining samples.";
        uint64_t v55 = v86[13];
        LODWORD(v80) = *((unsigned __int8 *)v86 + 112);
        uint64_t v56 = v69;
        MEMORY[0x22A672220](*v86, v86[1]);
        Swift::Bool v46 = (void *)Labels.encodeAnnotations(_:)(v56, v55, v80);
        uint64_t v57 = v56;
        uint64_t v45 = v86;
        v40(v57, v70);
        type metadata accessor for MLLogisticRegressionClassifier.Classifier();
        unint64_t v82 = v31;
        BaseLogisticRegressionClassifier.fitted(trainingFeatures:trainingAnnotations:validationFeatures:validationAnnotations:classCount:eventHandler:)();
        uint64_t v58 = v79;
        v66[0] = 0;
        swift_bridgeObjectRelease();
        swift_bridgeObjectRelease();
        uint64_t v59 = *(void (**)(void))(v58 + 8);
        uint64_t v31 = (char *)(v58 + 8);
        OUTLINED_FUNCTION_4_29();
        v59();
        OUTLINED_FUNCTION_25_0();
        v60();
        OUTLINED_FUNCTION_4_29();
        v59();
        uint64_t v47 = *v86;
        uint64_t v48 = v86[1];
        uint64_t v61 = type metadata accessor for MLLogisticRegressionClassifier.Model();
        uint64_t v62 = OUTLINED_FUNCTION_13_19(v61);
        (*(void (**)(uint64_t, char *, uint64_t))(v72 + 32))(v62, v71, v73);
        goto LABEL_11;
      }
      swift_bridgeObjectRelease();
      swift_bridgeObjectRelease();
      (*(void (**)(uint64_t, uint64_t))(v51 + 8))(v52, v34);
      OUTLINED_FUNCTION_25_0();
      v54();
    }
  }
LABEL_4:
  OUTLINED_FUNCTION_8_1();
}

uint64_t MLLogisticRegressionClassifier.Classifier.init(labels:annotationColumnName:featureColumnNames:)@<X0>(uint64_t a1@<X0>, int a2@<W1>, uint64_t a3@<X2>, uint64_t a4@<X3>, uint64_t a5@<X4>, uint64_t a6@<X8>)
{
  uint64_t v31 = a4;
  uint64_t v32 = a1;
  int v33 = a2;
  type metadata accessor for BaseLogisticRegressionClassifier();
  OUTLINED_FUNCTION_0();
  uint64_t v35 = v11;
  uint64_t v36 = v10;
  MEMORY[0x270FA5388](v10);
  OUTLINED_FUNCTION_33_0();
  uint64_t v34 = v12;
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifier<Double, Int>.Configuration);
  OUTLINED_FUNCTION_0();
  uint64_t v15 = v14;
  uint64_t v17 = MEMORY[0x270FA5388](v16);
  uint64_t v19 = (char *)&v31 - ((v18 + 15) & 0xFFFFFFFFFFFFFFF0);
  MEMORY[0x270FA5388](v17);
  uint64_t v21 = (char *)&v31 - v20;
  uint64_t v22 = type metadata accessor for MLLogisticRegressionClassifier.ModelParameters.ValidationData();
  MEMORY[0x270FA5388](v22);
  OUTLINED_FUNCTION_5_23();
  MEMORY[0x270FA5388](v23);
  uint64_t v25 = (char *)&v31 - v24;
  uint64_t v26 = v31;
  *(void *)a6 = a3;
  *(void *)(a6 + 8) = v26;
  *(void *)(a6 + 16) = a5;
  *(void *)uint64_t v25 = 0;
  *((void *)v25 + 1) = 0;
  *((_WORD *)v25 + 8) = 256;
  swift_storeEnumTagMultiPayload();
  *(_OWORD *)(a6 + 32) = 0u;
  *(void *)(a6 + 24) = 10;
  *(_OWORD *)(a6 + 48) = 0u;
  *(_OWORD *)(a6 + 64) = xmmword_2272CC8C0;
  *(_OWORD *)(a6 + 80) = xmmword_2272CC8D0;
  *(unsigned char *)(a6 + 96) = 1;
  outlined init with copy of MLLogisticRegressionClassifier.ModelParameters.ValidationData((uint64_t)v25, v6);
  v37[3] = v22;
  boxed_opaque_existential_0 = __swift_allocate_boxed_opaque_existential_0(v37);
  outlined init with take of MLLogisticRegressionClassifier.ModelParameters.ValidationData(v6, (uint64_t)boxed_opaque_existential_0);
  swift_bridgeObjectRetain();
  outlined assign with take of Any?((uint64_t)v37, a6 + 32);
  outlined destroy of MLLogisticRegressionClassifier.ModelParameters.ValidationData((uint64_t)v25);
  *(void *)(a6 + 104) = v32;
  *(unsigned char *)(a6 + 112) = v33 & 1;
  *(void *)(a6 + 120) = a5;
  *(void *)(a6 + 128) = 0xD000000000000013;
  *(void *)(a6 + 136) = 0x80000002272D4D10;
  lazy protocol witness table accessor for type Double and conformance Double();
  LogisticRegressionClassifier.Configuration.init()();
  (*(void (**)(char *, char *, uint64_t))(v15 + 16))(v19, v21, v13);
  uint64_t v28 = v34;
  BaseLogisticRegressionClassifier.init(configuration:)();
  (*(void (**)(char *, uint64_t))(v15 + 8))(v21, v13);
  uint64_t v29 = type metadata accessor for MLLogisticRegressionClassifier.Classifier();
  return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t))(v35 + 32))(a6 + *(int *)(v29 + 36), v28, v36);
}

uint64_t MLLogisticRegressionClassifier.Classifier.annotationColumnID.getter()
{
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<String, Int>);
  swift_bridgeObjectRetain();

  return ColumnID.init(_:_:)();
}

uint64_t MLLogisticRegressionClassifier.Classifier.annotationColumnID.setter()
{
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ColumnID<Either<String, Int>>);
  uint64_t v1 = ColumnID.name.getter();
  uint64_t v3 = v2;
  OUTLINED_FUNCTION_25_0();
  v4();
  uint64_t result = swift_bridgeObjectRelease();
  *uint64_t v0 = v1;
  v0[1] = v3;
  return result;
}

void (*protocol witness for SupervisedTabularEstimator.annotationColumnID.modify in conformance MLLogisticRegressionClassifier.Classifier(void *a1))(uint64_t a1, char a2)
{
  uint64_t v3 = malloc(0x28uLL);
  *a1 = v3;
  *uint64_t v3 = v1;
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ColumnID<Either<String, Int>>);
  v3[1] = v4;
  uint64_t v5 = *(void *)(v4 - 8);
  v3[2] = v5;
  size_t v6 = *(void *)(v5 + 64);
  v3[3] = malloc(v6);
  v3[4] = malloc(v6);
  MLLogisticRegressionClassifier.Classifier.annotationColumnID.getter();
  return protocol witness for SupervisedTabularEstimator.annotationColumnID.modify in conformance MLLogisticRegressionClassifier.Classifier;
}

void protocol witness for SupervisedTabularEstimator.annotationColumnID.modify in conformance MLLogisticRegressionClassifier.Classifier(uint64_t a1, char a2)
{
  uint64_t v2 = *(void **)a1;
  uint64_t v3 = *(void **)(*(void *)a1 + 24);
  uint64_t v4 = *(void **)(*(void *)a1 + 32);
  if (a2)
  {
    uint64_t v5 = v2[1];
    uint64_t v6 = v2[2];
    (*(void (**)(void, void *, uint64_t))(v6 + 16))(*(void *)(*(void *)a1 + 24), v4, v5);
    MLLogisticRegressionClassifier.Classifier.annotationColumnID.setter();
    (*(void (**)(void *, uint64_t))(v6 + 8))(v4, v5);
  }
  else
  {
    MLLogisticRegressionClassifier.Classifier.annotationColumnID.setter();
  }
  free(v4);
  free(v3);

  free(v2);
}

uint64_t protocol witness for SupervisedTabularEstimator.fitted(to:validateOn:eventHandler:) in conformance MLLogisticRegressionClassifier.Classifier()
{
  MLLogisticRegressionClassifier.Classifier.fitted(to:validateOn:eventHandler:)();
  uint64_t v1 = *(uint64_t (**)(void))(v0 + 8);
  return protocol witness for SupervisedTabularEstimator.fitted(to:validateOn:eventHandler:) in conformance TreeRegressor(v1);
}

uint64_t protocol witness for SupervisedTabularEstimator.encode(_:to:) in conformance MLLogisticRegressionClassifier.Classifier(uint64_t a1, uint64_t a2)
{
  return MLLogisticRegressionClassifier.Classifier.encode(_:to:)(a1, a2);
}

uint64_t MLLogisticRegressionClassifier.Classifier.encode(_:to:)(uint64_t a1, uint64_t a2)
{
  __swift_mutable_project_boxed_opaque_existential_1(a2, *(void *)(a2 + 24));
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FeatureVectorizer<Double>.Transformer?);
  lazy protocol witness table accessor for type FeatureVectorizer<Double>.Transformer? and conformance <A> A?();
  uint64_t result = dispatch thunk of EstimatorEncoder.encode<A>(_:)();
  if (!v2)
  {
    type metadata accessor for MLLogisticRegressionClassifier.Model();
    __swift_mutable_project_boxed_opaque_existential_1(a2, *(void *)(a2 + 24));
    type metadata accessor for BaseLogisticRegressionClassifierModel();
    lazy protocol witness table accessor for type MLLogisticRegressionClassifier.Model and conformance MLLogisticRegressionClassifier.Model(&lazy protocol witness table cache variable for type BaseLogisticRegressionClassifierModel and conformance BaseLogisticRegressionClassifierModel, MEMORY[0x263F044D8]);
    return dispatch thunk of EstimatorEncoder.encode<A>(_:)();
  }
  return result;
}

void protocol witness for SupervisedTabularEstimator.decode(from:) in conformance MLLogisticRegressionClassifier.Classifier()
{
}

uint64_t base witness table accessor for SupervisedTabularEstimator in MLLogisticRegressionClassifier.Classifier()
{
  return lazy protocol witness table accessor for type MLLogisticRegressionClassifier.Model and conformance MLLogisticRegressionClassifier.Model((unint64_t *)&lazy protocol witness table cache variable for type MLLogisticRegressionClassifier.Classifier and conformance MLLogisticRegressionClassifier.Classifier, (void (*)(uint64_t))type metadata accessor for MLLogisticRegressionClassifier.Classifier);
}

void MLLogisticRegressionClassifier.Classifier.decode(from:)()
{
  OUTLINED_FUNCTION_9_0();
  uint64_t v20 = v0;
  uint64_t v4 = v3;
  uint64_t v16 = v5;
  uint64_t v6 = type metadata accessor for BaseLogisticRegressionClassifierModel();
  OUTLINED_FUNCTION_0();
  uint64_t v8 = v7;
  MEMORY[0x270FA5388](v9);
  OUTLINED_FUNCTION_27_7();
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FeatureVectorizer<Double>.Transformer);
  __swift_mutable_project_boxed_opaque_existential_1(v4, *(void *)(v4 + 24));
  lazy protocol witness table accessor for type FeatureVectorizer<Double>.Transformer and conformance FeatureVectorizer<A>.Transformer(&lazy protocol witness table cache variable for type FeatureVectorizer<Double>.Transformer and conformance FeatureVectorizer<A>.Transformer);
  dispatch thunk of EstimatorDecoder.decode<A>(_:)();
  if (!v1)
  {
    __swift_mutable_project_boxed_opaque_existential_1(v4, *(void *)(v4 + 24));
    lazy protocol witness table accessor for type MLLogisticRegressionClassifier.Model and conformance MLLogisticRegressionClassifier.Model(&lazy protocol witness table cache variable for type BaseLogisticRegressionClassifierModel and conformance BaseLogisticRegressionClassifierModel, MEMORY[0x263F044D8]);
    dispatch thunk of EstimatorDecoder.decode<A>(_:)();
    uint64_t v11 = *v0;
    uint64_t v10 = v0[1];
    uint64_t v12 = type metadata accessor for MLLogisticRegressionClassifier.Model();
    (*(void (**)(char *, uint64_t, uint64_t))(v8 + 32))(&v16[*(int *)(v12 + 24)], v2, v6);
    uint64_t v13 = v20[13];
    char v14 = *((unsigned char *)v20 + 112);
    *(void *)uint64_t v16 = v11;
    *((void *)v16 + 1) = v10;
    *((void *)v16 + 2) = v17;
    *((void *)v16 + 3) = v18;
    *((void *)v16 + 4) = v19;
    uint64_t v15 = &v16[*(int *)(v12 + 28)];
    *(void *)uint64_t v15 = v13;
    v15[8] = v14;
    swift_bridgeObjectRetain();
    swift_bridgeObjectRetain();
  }
  OUTLINED_FUNCTION_8_1();
}

uint64_t MLLogisticRegressionClassifier.Classifier.makeTransformer()@<X0>(char *a1@<X8>)
{
  uint64_t v3 = type metadata accessor for BaseLogisticRegressionClassifierModel();
  OUTLINED_FUNCTION_0();
  uint64_t v5 = v4;
  MEMORY[0x270FA5388](v6);
  OUTLINED_FUNCTION_3_0();
  uint64_t v9 = v8 - v7;
  uint64_t v11 = *v1;
  uint64_t v10 = v1[1];
  uint64_t v12 = v1[13];
  char v13 = *((unsigned char *)v1 + 112);
  type metadata accessor for MLLogisticRegressionClassifier.Classifier();
  swift_bridgeObjectRetain();
  BaseLogisticRegressionClassifier.makeTransformer(classCount:)();
  *(void *)a1 = v11;
  *((void *)a1 + 1) = v10;
  uint64_t v14 = type metadata accessor for MLLogisticRegressionClassifier.Model();
  *((void *)a1 + 3) = 0;
  *((void *)a1 + 4) = 0;
  *((void *)a1 + 2) = 0;
  (*(void (**)(char *, uint64_t, uint64_t))(v5 + 32))(&a1[*(int *)(v14 + 24)], v9, v3);
  uint64_t v15 = &a1[*(int *)(v14 + 28)];
  *(void *)uint64_t v15 = v12;
  v15[8] = v13;
  return swift_bridgeObjectRetain();
}

void MLLogisticRegressionClassifier.Classifier.update(_:with:eventHandler:)()
{
  OUTLINED_FUNCTION_9_0();
  uint64_t v38 = v2;
  uint64_t v36 = v3;
  uint64_t v5 = v4;
  uint64_t v7 = v6;
  uint64_t v39 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DenseMatrix<Double>);
  OUTLINED_FUNCTION_0();
  uint64_t v37 = v8;
  MEMORY[0x270FA5388](v9);
  OUTLINED_FUNCTION_33_0();
  uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyColumn?);
  MEMORY[0x270FA5388](v10 - 8);
  OUTLINED_FUNCTION_3_0();
  char v13 = (void (*)(uint64_t, uint64_t))(v12 - v11);
  type metadata accessor for AnyColumn();
  OUTLINED_FUNCTION_0();
  uint64_t v40 = v15;
  uint64_t v41 = v14;
  MEMORY[0x270FA5388](v14);
  OUTLINED_FUNCTION_49();
  uint64_t v35 = v16;
  uint64_t v18 = MEMORY[0x270FA5388](v17);
  uint64_t v20 = (char *)v34 - v19;
  uint64_t ML16ColumnDescriptorVsAE_pTg5 = v7[2];
  uint64_t v42 = v0;
  if (!ML16ColumnDescriptorVsAE_pTg5)
  {
    uint64_t v29 = v0[2];
    MEMORY[0x270FA5388](v18);
    v34[-2] = v5;
    swift_bridgeObjectRetain();
    uint64_t ML16ColumnDescriptorVsAE_pTg5 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSaySSG_8CreateML16ColumnDescriptorVsAE_pTg5((uint64_t)partial apply for closure #1 in FeatureVectorizer.fitted(to:), (uint64_t)&v34[-4], v29);
    swift_bridgeObjectRelease();
    if (v1)
    {
LABEL_10:
      OUTLINED_FUNCTION_8_1();
      return;
    }
    outlined consume of FeatureVectorizer<Float>.Transformer?(v7[2]);
    v7[2] = ML16ColumnDescriptorVsAE_pTg5;
    v7[3] = 0xD000000000000013;
    v7[4] = 0x80000002272D4D10;
  }
  uint64_t v22 = type metadata accessor for MLLogisticRegressionClassifier.Model();
  uint64_t v23 = (char *)v7 + *(int *)(v22 + 28);
  uint64_t v24 = *(void *)v23;
  if (*(void *)(*(void *)v23 + 16))
  {
    char v25 = v23[8];
    if (ML16ColumnDescriptorVsAE_pTg5) {
      goto LABEL_4;
    }
    goto LABEL_12;
  }
  v34[1] = v22;
  MEMORY[0x22A672220](*v42, v42[1]);
  uint64_t v30 = v41;
  __swift_storeEnumTagSinglePayload((uint64_t)v13, 1, 1, v41);
  uint64_t v31 = static Labels.collected(from:_:)((uint64_t)v20, v13);
  if (v1)
  {
    outlined destroy of DefaultIndices<DataFrame.Rows>((uint64_t)v13, &demangling cache variable for type metadata for AnyColumn?);
    (*(void (**)(char *, uint64_t))(v40 + 8))(v20, v30);
    goto LABEL_10;
  }
  uint64_t v24 = v31;
  char v33 = v32;
  outlined destroy of DefaultIndices<DataFrame.Rows>((uint64_t)v13, &demangling cache variable for type metadata for AnyColumn?);
  (*(void (**)(char *, uint64_t))(v40 + 8))(v20, v30);
  swift_bridgeObjectRelease();
  *(void *)uint64_t v23 = v24;
  v23[8] = v33 & 1;
  char v25 = v33;
  if (v7[2])
  {
LABEL_4:
    specialized FeatureVectorizer.Transformer.vectorized(_:includingBias:)();
    if (!v1)
    {
      uint64_t v26 = v35;
      MEMORY[0x22A672220](*v42, v42[1]);
      Labels.encodeAnnotations(_:)(v26, v24, v25 & 1);
      OUTLINED_FUNCTION_25_0();
      v27();
      type metadata accessor for MLLogisticRegressionClassifier.Classifier();
      BaseLogisticRegressionClassifier.update(_:features:annotations:eventHandler:)();
      OUTLINED_FUNCTION_25_0();
      v28();
      swift_bridgeObjectRelease();
    }
    goto LABEL_10;
  }
LABEL_12:
  __break(1u);
}

uint64_t protocol witness for UpdatableSupervisedTabularEstimator.update(_:with:eventHandler:) in conformance MLLogisticRegressionClassifier.Classifier()
{
  MLLogisticRegressionClassifier.Classifier.update(_:with:eventHandler:)();
  uint64_t v1 = *(uint64_t (**)(void))(v0 + 8);
  return protocol witness for SupervisedTabularEstimator.fitted(to:validateOn:eventHandler:) in conformance TreeRegressor(v1);
}

uint64_t protocol witness for UpdatableSupervisedTabularEstimator.encodeWithOptimizer(_:to:) in conformance MLLogisticRegressionClassifier.Classifier(uint64_t a1, uint64_t a2)
{
  return protocol witness for SupervisedTabularEstimator.encode(_:to:) in conformance MLLogisticRegressionClassifier.Classifier(a1, a2);
}

void protocol witness for UpdatableSupervisedTabularEstimator.decodeWithOptimizer(from:) in conformance MLLogisticRegressionClassifier.Classifier()
{
}

unint64_t lazy protocol witness table accessor for type FeatureVectorizer<Double>.Transformer? and conformance <A> A?()
{
  unint64_t result = lazy protocol witness table cache variable for type FeatureVectorizer<Double>.Transformer? and conformance <A> A?;
  if (!lazy protocol witness table cache variable for type FeatureVectorizer<Double>.Transformer? and conformance <A> A?)
  {
    __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for FeatureVectorizer<Double>.Transformer?);
    lazy protocol witness table accessor for type FeatureVectorizer<Double>.Transformer and conformance FeatureVectorizer<A>.Transformer(&lazy protocol witness table cache variable for type FeatureVectorizer<Double>.Transformer and conformance FeatureVectorizer<A>.Transformer);
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type FeatureVectorizer<Double>.Transformer? and conformance <A> A?);
  }
  return result;
}

uint64_t lazy protocol witness table accessor for type FeatureVectorizer<Double>.Transformer and conformance FeatureVectorizer<A>.Transformer(unint64_t *a1)
{
  uint64_t result = *a1;
  if (!result)
  {
    __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for FeatureVectorizer<Double>.Transformer);
    uint64_t result = swift_getWitnessTable();
    atomic_store(result, a1);
  }
  return result;
}

uint64_t lazy protocol witness table accessor for type MLLogisticRegressionClassifier.Model and conformance MLLogisticRegressionClassifier.Model(unint64_t *a1, void (*a2)(uint64_t))
{
  uint64_t result = *a1;
  if (!result)
  {
    a2(255);
    uint64_t result = swift_getWitnessTable();
    atomic_store(result, a1);
  }
  return result;
}

uint64_t OUTLINED_FUNCTION_8_20()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_9_19()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_13_19(uint64_t a1)
{
  return *(void *)(v1 - 200) + *(int *)(a1 + 24);
}

uint64_t _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay10Foundation3URLVG_18CreateMLComponents16AnnotatedFeatureVyAHSSGs5NeverOTg503_s8f24ML17MLSoundClassifierV16i143ExtractorC12filesByLabel7optionsAESDySSSay10Foundation3URLVGG_AE13ConfigurationVtKc33_EF88DE97863F019753745A6AAFDAF1B0LlfcSay0A12MLComponents09H29E0VyAJSSGGSS_AKtXEfU_AsJXEfU_SSTf1cn_n(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v26 = a2;
  uint64_t v25 = type metadata accessor for URL();
  uint64_t v6 = *(void *)(v25 - 8);
  MEMORY[0x270FA5388](v25);
  uint64_t v24 = (char *)v19 - ((v7 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v23 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
  uint64_t v8 = *(void *)(v23 - 8);
  MEMORY[0x270FA5388](v23);
  uint64_t v10 = (char *)v19 - ((v9 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v11 = *(void *)(a1 + 16);
  if (v11)
  {
    v19[1] = v3;
    uint64_t v29 = MEMORY[0x263F8EE78];
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
    uint64_t v12 = v29;
    uint64_t v14 = *(void (**)(char *, uint64_t, uint64_t))(v6 + 16);
    uint64_t v13 = v6 + 16;
    uint64_t v15 = a1 + ((*(unsigned __int8 *)(v13 + 64) + 32) & ~(unint64_t)*(unsigned __int8 *)(v13 + 64));
    uint64_t v20 = *(void *)(v13 + 56);
    uint64_t v21 = v14;
    v19[2] = v8 + 32;
    uint64_t v22 = v13;
    uint64_t v16 = v24;
    do
    {
      v21(v16, v15, v25);
      uint64_t v27 = v26;
      uint64_t v28 = a3;
      swift_bridgeObjectRetain();
      AnnotatedFeature.init(feature:annotation:)();
      uint64_t v29 = v12;
      unint64_t v17 = *(void *)(v12 + 16);
      if (v17 >= *(void *)(v12 + 24) >> 1)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
        uint64_t v12 = v29;
      }
      *(void *)(v12 + 16) = v17 + 1;
      (*(void (**)(unint64_t, char *, uint64_t))(v8 + 32))(v12+ ((*(unsigned __int8 *)(v8 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v8 + 80))+ *(void *)(v8 + 72) * v17, v10, v23);
      v15 += v20;
      --v11;
    }
    while (v11);
    swift_bridgeObjectRelease();
  }
  else
  {
    swift_bridgeObjectRelease();
    return MEMORY[0x263F8EE78];
  }
  return v12;
}

void specialized Array.append<A>(contentsOf:)()
{
  OUTLINED_FUNCTION_14_13();
  if (v5)
  {
    __break(1u);
LABEL_13:
    __break(1u);
    goto LABEL_14;
  }
  if (!OUTLINED_FUNCTION_13_20() || v4 > *(void *)(v2 + 24) >> 1)
  {
    OUTLINED_FUNCTION_11_17();
    specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
    uint64_t v2 = v6;
  }
  if (!*(void *)(v0 + 16))
  {
    if (!v3) {
      goto LABEL_11;
    }
    goto LABEL_13;
  }
  OUTLINED_FUNCTION_10_18();
  if (v7 != v5)
  {
LABEL_14:
    __break(1u);
    goto LABEL_15;
  }
  specialized UnsafeMutablePointer.initialize(from:count:)();
  if (!v3)
  {
LABEL_11:
    swift_bridgeObjectRelease();
    void *v1 = v2;
    return;
  }
  OUTLINED_FUNCTION_9_20();
  if (!v5)
  {
    *(void *)(v2 + 16) = v8;
    goto LABEL_11;
  }
LABEL_15:
  __break(1u);
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  char v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;

  OUTLINED_FUNCTION_14_13();
  if (v5)
  {
    __break(1u);
LABEL_13:
    __break(1u);
    goto LABEL_14;
  }
  if (!OUTLINED_FUNCTION_13_20() || v4 > *(void *)(v2 + 24) >> 1)
  {
    OUTLINED_FUNCTION_11_17();
    specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
    uint64_t v2 = v6;
  }
  if (!*(void *)(v0 + 16))
  {
    if (!v3) {
      goto LABEL_11;
    }
    goto LABEL_13;
  }
  char v7 = (*(void *)(v2 + 24) >> 1) - *(void *)(v2 + 16);
  uint64_t v8 = *(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<MLShapedArray<Float>, String>)
                 - 8);
  if (v7 < v3)
  {
LABEL_14:
    __break(1u);
    goto LABEL_15;
  }
  specialized UnsafeMutablePointer.initialize(from:count:)(v0 + ((*(unsigned __int8 *)(v8 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v8 + 80)), v3);
  if (!v3)
  {
LABEL_11:
    swift_bridgeObjectRelease();
    void *v1 = v2;
    return;
  }
  OUTLINED_FUNCTION_9_20();
  if (!v5)
  {
    *(void *)(v2 + 16) = v9;
    goto LABEL_11;
  }
LABEL_15:
  __break(1u);
}

void specialized Array.append<A>(contentsOf:)(uint64_t a1)
{
}

{
  specialized Array.append<A>(contentsOf:)(a1, (uint64_t (*)(void))specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:), (void (*)(uint64_t, uint64_t, uint64_t))specialized UnsafeMutablePointer.initialize(from:count:));
}

{
  specialized Array.append<A>(contentsOf:)(a1, (uint64_t (*)(void))specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:), (void (*)(unint64_t, uint64_t, unint64_t))specialized UnsafeMutablePointer.initialize(from:count:), MEMORY[0x263F53300]);
}

{
  specialized Array.append<A>(contentsOf:)(a1, (uint64_t (*)(void))specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:), (void (*)(unint64_t, uint64_t, unint64_t))specialized UnsafeMutablePointer.initialize(from:count:), MEMORY[0x263F53260]);
}

void specialized Array.append<A>(contentsOf:)(uint64_t a1, uint64_t (*a2)(void), void (*a3)(uint64_t, uint64_t, uint64_t))
{
  uint64_t v5 = *(void *)(a1 + 16);
  uint64_t v6 = *v4;
  uint64_t v7 = *(void *)(*v4 + 16);
  if (__OFADD__(v7, v5))
  {
    __break(1u);
LABEL_13:
    __break(1u);
    goto LABEL_14;
  }
  if (!OUTLINED_FUNCTION_13_20() || v7 + v5 > *(void *)(v6 + 24) >> 1)
  {
    OUTLINED_FUNCTION_11_17();
    uint64_t v6 = a2();
  }
  if (!*(void *)(v3 + 16))
  {
    if (!v5) {
      goto LABEL_11;
    }
    goto LABEL_13;
  }
  OUTLINED_FUNCTION_10_18();
  if (v11 != v12)
  {
LABEL_14:
    __break(1u);
    goto LABEL_15;
  }
  a3(v3 + 32, v5, v6 + 8 * v10 + 32);
  if (!v5)
  {
LABEL_11:
    swift_bridgeObjectRelease();
    *uint64_t v4 = v6;
    return;
  }
  OUTLINED_FUNCTION_9_20();
  if (!v12)
  {
    *(void *)(v6 + 16) = v13;
    goto LABEL_11;
  }
LABEL_15:
  __break(1u);
}

void specialized Array.append<A>(contentsOf:)(uint64_t a1, uint64_t (*a2)(void), void (*a3)(unint64_t, uint64_t, unint64_t), uint64_t (*a4)(void))
{
  uint64_t v6 = *(void *)(a1 + 16);
  uint64_t v7 = *v5;
  uint64_t v8 = *(void *)(*v5 + 16);
  if (__OFADD__(v8, v6))
  {
    __break(1u);
LABEL_13:
    __break(1u);
    goto LABEL_14;
  }
  if (!OUTLINED_FUNCTION_13_20() || v8 + v6 > *(void *)(v7 + 24) >> 1)
  {
    OUTLINED_FUNCTION_11_17();
    uint64_t v7 = a2();
  }
  if (!*(void *)(v4 + 16))
  {
    if (!v6) {
      goto LABEL_11;
    }
    goto LABEL_13;
  }
  uint64_t v12 = *(void *)(v7 + 16);
  uint64_t v13 = (*(void *)(v7 + 24) >> 1) - v12;
  uint64_t v14 = *(void *)(a4(0) - 8);
  if (v13 < v6)
  {
LABEL_14:
    __break(1u);
    goto LABEL_15;
  }
  unint64_t v15 = (*(unsigned __int8 *)(v14 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v14 + 80);
  a3(v4 + v15, v6, v7 + v15 + *(void *)(v14 + 72) * v12);
  if (!v6)
  {
LABEL_11:
    swift_bridgeObjectRelease();
    *uint64_t v5 = v7;
    return;
  }
  OUTLINED_FUNCTION_9_20();
  if (!v17)
  {
    *(void *)(v7 + 16) = v16;
    goto LABEL_11;
  }
LABEL_15:
  __break(1u);
}

uint64_t static MLSoundClassifier.FeatureExtractor.extractFeatures(from:options:)(uint64_t a1, long long *a2)
{
  long long v3 = a2[1];
  long long v8 = *a2;
  v9[0] = v3;
  *(_OWORD *)((char *)v9 + 9) = *(long long *)((char *)a2 + 25);
  uint64_t v4 = swift_bridgeObjectRetain();
  uint64_t v5 = specialized Sequence.flatMap<A>(_:)(v4);
  swift_bridgeObjectRelease();
  uint64_t v6 = swift_allocObject();
  specialized MLSoundClassifier.FeatureExtractor.init<A>(files:options:)(v5, &v8);
  if (!v2)
  {
    uint64_t v6 = MLSoundClassifier.FeatureExtractor.extractFeatures()();
    swift_release();
  }
  return v6;
}

{
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  char *v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  char *v16;
  uint64_t v17;
  uint64_t v18;
  char *v19;
  uint64_t v20;
  char v21;
  long long v22;
  id v23;
  double v24;
  uint64_t v25;
  uint64_t v26;
  void (*v27)(char *, uint64_t, uint64_t);
  void (*v28)(char *, uint64_t, uint64_t);
  uint64_t v29;
  uint64_t v30;
  id v31;
  id v32;
  void *v33;
  id v34;
  id v35;
  id v36;
  char *v37;
  uint64_t v38;
  void (*v39)(uint64_t, char *, uint64_t);
  uint64_t v40;
  uint64_t v41;
  uint64_t v42;
  char isUniquelyReferenced_nonNull_native;
  unint64_t v44;
  char v45;
  uint64_t v46;
  BOOL v47;
  Swift::Int v48;
  unint64_t v49;
  char v50;
  unint64_t v51;
  char v52;
  void *v53;
  uint64_t v54;
  uint64_t v55;
  BOOL v56;
  uint64_t v57;
  uint64_t (*v58)(char *, uint64_t);
  uint64_t result;
  uint64_t v60;
  void (*v61)(uint64_t);
  void *v62;
  id v63;
  uint64_t v64;
  char *v65;
  char *v66;
  uint64_t (**v67)(char *, uint64_t);
  void (**v68)(char *, char *, uint64_t);
  uint64_t v69;
  char *v70;
  id v71;
  uint64_t v72;
  void (*v73)(unint64_t, uint64_t, uint64_t);
  id v74;
  uint64_t v75;
  uint64_t v76;
  uint64_t v77;
  long long v78;
  char *v79;
  _OWORD v80[2];
  uint64_t v81;
  char v82;
  uint64_t v83;

  uint64_t v4 = v3;
  uint64_t v83 = *MEMORY[0x263EF8340];
  uint64_t v7 = type metadata accessor for URL();
  OUTLINED_FUNCTION_0();
  uint64_t v9 = v8;
  MEMORY[0x270FA5388](v10);
  OUTLINED_FUNCTION_49();
  uint64_t v79 = v11;
  uint64_t v13 = MEMORY[0x270FA5388](v12);
  uint64_t v70 = (char *)&v64 - v14;
  MEMORY[0x270FA5388](v13);
  uint64_t v16 = (char *)&v64 - v15;
  char v17 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  MEMORY[0x270FA5388](v17 - 8);
  uint64_t v19 = (char *)&v64 - ((v18 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v20 = *((void *)a2 + 4);
  uint64_t v21 = *((unsigned char *)a2 + 40);
  uint64_t v22 = a2[1];
  uint64_t v78 = *a2;
  v80[0] = v78;
  v80[1] = v22;
  uint64_t v81 = v20;
  unint64_t v82 = v21;
  uint64_t v69 = v2;
  uint64_t v23 = static MLSoundClassifier.FeatureExtractor.getFeaturePrintRequest(options:)((uint64_t)v80);
  HIDWORD(v24) = DWORD1(v78);
  *(float *)&uint64_t v24 = *(double *)&v78;
  uint64_t v71 = v23;
  objc_msgSend(v23, sel_setOverlapFactor_, v24);
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [MLShapedArray<Float>]);
  lazy protocol witness table accessor for type URL and conformance URL();
  *(void *)&uint64_t v78 = Dictionary.init(dictionaryLiteral:)();
  uint64_t v25 = *(void *)(a1 + 16);
  char v64 = a1;
  if (v25)
  {
    uint64_t v28 = *(void (**)(char *, uint64_t, uint64_t))(v9 + 16);
    uint64_t v26 = v9 + 16;
    uint64_t v27 = v28;
    uint64_t v29 = a1 + ((*(unsigned __int8 *)(v26 + 64) + 32) & ~(unint64_t)*(unsigned __int8 *)(v26 + 64));
    uint64_t v72 = *(void *)(v26 + 56);
    uint64_t v68 = (void (**)(char *, char *, uint64_t))(v26 + 16);
    uint64_t v67 = (uint64_t (**)(char *, uint64_t))(v26 - 8);
    swift_bridgeObjectRetain();
    Swift::Bool v66 = v16;
    uint64_t v65 = v19;
    uint64_t v73 = (void (*)(unint64_t, uint64_t, uint64_t))v28;
    while (1)
    {
      v27(v19, v29, v7);
      __swift_storeEnumTagSinglePayload((uint64_t)v19, 0, 1, v7);
      if (__swift_getEnumTagSinglePayload((uint64_t)v19, 1, v7) == 1) {
        break;
      }
      uint64_t v76 = v29;
      uint64_t v77 = v25;
      (*v68)(v16, v19, v7);
      uint64_t v30 = (uint64_t)v70;
      v27(v70, (uint64_t)v16, v7);
      uint64_t v31 = objc_allocWithZone(MEMORY[0x263F179A0]);
      char v32 = @nonobjc SNAudioFileAnalyzer.init(url:)(v30);
      if (v4)
      {

        OUTLINED_FUNCTION_25_0();
        v61(v60);
        swift_bridgeObjectRelease();
        return swift_bridgeObjectRelease();
      }
      char v33 = v32;
      uint64_t v34 = objc_allocWithZone(MEMORY[0x263F17A40]);
      uint64_t v35 = objc_msgSend(v34, sel_init, v64);
      *(void *)&v80[0] = 0;
      if ((objc_msgSend(v33, sel_addRequest_withObserver_error_, v71, v35, v80) & 1) == 0)
      {
        uint64_t v62 = v33;
        uint64_t v63 = *(id *)&v80[0];
        swift_bridgeObjectRelease();
        swift_bridgeObjectRelease();
        _convertNSErrorToError(_:)();

        swift_willThrow();
        return (*v67)(v16, v7);
      }
      uint64_t v75 = 0;
      uint64_t v36 = *(id *)&v80[0];
      uint64_t v74 = v33;
      objc_msgSend(v33, sel_analyze);
      uint64_t v37 = v16;
      uint64_t v38 = v7;
      uint64_t v39 = (void (*)(uint64_t, char *, uint64_t))v27;
      uint64_t v40 = v26;
      v39((uint64_t)v79, v37, v7);
      uint64_t v41 = static MLSoundClassifier.FeatureExtractor.convertResultsToShapedArrays(resultsCollector:options:)(v35);
      uint64_t v42 = v78;
      id isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native();
      *(void *)&v80[0] = v42;
      char v44 = specialized __RawDictionaryStorage.find<A>(_:)();
      Swift::Bool v46 = *(void *)(v42 + 16);
      uint64_t v47 = (v45 & 1) == 0;
      uint64_t v48 = v46 + v47;
      if (__OFADD__(v46, v47))
      {
        __break(1u);
LABEL_22:
        __break(1u);
      }
      uint64_t v49 = v44;
      uint64_t v50 = v45;
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<URL, [MLShapedArray<Float>]>);
      if (_NativeDictionary.ensureUnique(isUnique:capacity:)(isUniquelyReferenced_nonNull_native, v48))
      {
        uint64_t v51 = specialized __RawDictionaryStorage.find<A>(_:)();
        if ((v50 & 1) != (v52 & 1))
        {
          uint64_t result = KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)();
          __break(1u);
          return result;
        }
        uint64_t v49 = v51;
      }
      uint64_t v53 = *(void **)&v80[0];
      *(void *)&uint64_t v78 = *(void *)&v80[0];
      if (v50)
      {
        uint64_t v54 = *(void *)(*(void *)&v80[0] + 56);
        swift_bridgeObjectRelease();
        *(void *)(v54 + 8 * v49) = v41;
        uint64_t v7 = v38;
      }
      else
      {
        *(void *)(*(void *)&v80[0] + 8 * (v49 >> 6) + 64) |= 1 << v49;
        uint64_t v7 = v38;
        v73(v53[6] + v49 * v72, (uint64_t)v79, v38);
        *(void *)(v53[7] + 8 * v49) = v41;
        uint64_t v55 = v53[2];
        uint64_t v56 = __OFADD__(v55, 1);
        uint64_t v57 = v55 + 1;
        if (v56) {
          goto LABEL_22;
        }
        v53[2] = v57;
      }
      swift_bridgeObjectRelease();
      uint64_t v58 = *v67;
      (*v67)(v79, v7);

      uint64_t v16 = v66;
      v58(v66, v7);
      uint64_t v29 = v76 + v72;
      uint64_t v25 = v77 - 1;
      uint64_t v4 = v75;
      uint64_t v26 = v40;
      uint64_t v19 = v65;
      uint64_t v27 = (void (*)(char *, uint64_t, uint64_t))v73;
      if (v77 == 1) {
        goto LABEL_17;
      }
    }
  }
  else
  {
    swift_bridgeObjectRetain();
LABEL_17:
    __swift_storeEnumTagSinglePayload((uint64_t)v19, 1, 1, v7);
  }

  swift_bridgeObjectRelease();
  return v78;
}

uint64_t MLSoundClassifier.FeatureExtractor.extractFeatures()()
{
  uint64_t v1 = v0;
  uint64_t v2 = *(void *)v0;
  uint64_t v131 = type metadata accessor for URL();
  OUTLINED_FUNCTION_0();
  uint64_t v126 = v3;
  MEMORY[0x270FA5388](v4);
  OUTLINED_FUNCTION_33_0();
  uint64_t v130 = v5;
  uint64_t v119 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
  OUTLINED_FUNCTION_0();
  uint64_t v121 = v6;
  MEMORY[0x270FA5388](v7);
  OUTLINED_FUNCTION_50_0();
  uint64_t v129 = v8;
  uint64_t v124 = v9;
  MEMORY[0x270FA5388](v10);
  uint64_t v132 = (char *)v108 - v11;
  uint64_t v137 = type metadata accessor for Date();
  OUTLINED_FUNCTION_0();
  uint64_t v133 = v12;
  MEMORY[0x270FA5388](v13);
  OUTLINED_FUNCTION_33_0();
  uint64_t v128 = v14;
  uint64_t v127 = type metadata accessor for _TablePrinter(0);
  OUTLINED_FUNCTION_0();
  uint64_t v118 = v15;
  MEMORY[0x270FA5388](v16);
  OUTLINED_FUNCTION_50_0();
  uint64_t v117 = v17;
  uint64_t v123 = v18;
  MEMORY[0x270FA5388](v19);
  uint64_t v122 = (void *)((char *)v108 - v20);
  uint64_t v21 = *((void *)v0 + 8);
  id v135 = objc_msgSend(self, sel_progressWithTotalUnitCount_, *(void *)(v21 + 16));
  uint64_t aBlock = 0;
  unint64_t v142 = 0xE000000000000000;
  _StringGuts.grow(_:)(19);
  swift_bridgeObjectRelease();
  uint64_t aBlock = 0x69737365636F7250;
  unint64_t v142 = 0xEB0000000020676ELL;
  uint64_t v109 = v21;
  unint64_t v144 = *(void *)(v21 + 16);
  v22._uint64_t countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter();
  String.append(_:)(v22);
  swift_bridgeObjectRelease();
  v23._uint64_t countAndFlagsBits = 0x73656C696620;
  v23._uint64_t object = (void *)0xE600000000000000;
  String.append(_:)(v23);
  uint64_t v24 = aBlock;
  uint64_t v25 = (void *)v142;
  os_log_type_t v26 = static os_log_type_t.info.getter();
  v27._uint64_t countAndFlagsBits = v24;
  v27._uint64_t object = v25;
  log(_:type:)(v27, v26);
  swift_bridgeObjectRelease();
  uint64_t v134 = swift_allocObject();
  *(void *)(v134 + 16) = 0;
  id v28 = objc_msgSend(objc_allocWithZone(MEMORY[0x263F08A48]), sel_init);
  type metadata accessor for NSAttributedString(0, &lazy cache variable for type metadata for NSOperationQueue);
  uint64_t v29 = static Array._allocateBufferUninitialized(minimumCapacity:)();
  uint64_t v30 = (void *)(v29 & 0xFFFFFFFFFFFFFF8);
  _OWORD v30[2] = 8;
  uint64_t aBlock = v29;
  v30[4] = v28;
  v30[5] = v28;
  v30[6] = v28;
  v30[7] = v28;
  v30[8] = v28;
  v30[9] = v28;
  v30[10] = v28;
  v30[11] = v28;
  id v31 = v28;
  specialized Array._endMutation()();
  unint64_t v144 = aBlock;
  uint64_t v32 = swift_allocObject();
  double v33 = v1[2];
  unint64_t v34 = *((void *)v1 + 3);
  uint64_t v35 = *((void *)v1 + 5);
  uint64_t v138 = *((void *)v1 + 4);
  uint64_t v139 = v1;
  uint64_t aBlock = *(void *)&v33;
  unint64_t v142 = v34;
  uint64_t v36 = OUTLINED_FUNCTION_12_13(v138);
  uint64_t v140 = v2;
  id v37 = static MLSoundClassifier.FeatureExtractor.getFeaturePrintRequest(options:)(v36);
  type metadata accessor for NSAttributedString(0, &lazy cache variable for type metadata for SNCreateFeaturePrintRequest);
  uint64_t v38 = static Array._allocateBufferUninitialized(minimumCapacity:)();
  uint64_t v39 = (void *)(v38 & 0xFFFFFFFFFFFFFF8);
  void v39[2] = 8;
  uint64_t aBlock = v38;
  v39[4] = v37;
  v39[5] = v37;
  v39[6] = v37;
  v39[7] = v37;
  v39[8] = v37;
  v39[9] = v37;
  v39[10] = v37;
  v39[11] = v37;
  id v40 = v37;
  specialized Array._endMutation()();
  unint64_t v41 = aBlock;
  uint64_t v120 = v32;
  *(void *)(v32 + 16) = aBlock;
  unint64_t v42 = v32 + 16;
  uint64_t v43 = 4;
  unint64_t v44 = v144;
  do
  {
    id v45 = objc_msgSend(objc_allocWithZone(MEMORY[0x263F08A48]), sel_init);
    if (!swift_isUniquelyReferenced_nonNull_bridgeObject()
      || (v44 & 0x8000000000000000) != 0
      || (v44 & 0x4000000000000000) != 0)
    {
      specialized _ArrayBuffer._consumeAndCreateNew()(v44);
      unint64_t v44 = v46;
      unint64_t v144 = v46;
    }
    unint64_t v47 = v43 - 4;
    uint64_t v48 = v44 & 0xFFFFFFFFFFFFFF8;
    if ((unint64_t)(v43 - 4) >= *(void *)((v44 & 0xFFFFFFFFFFFFFF8) + 0x10))
    {
      __break(1u);
LABEL_45:
      __break(1u);
LABEL_46:
      __break(1u);
LABEL_47:
      __break(1u);
LABEL_48:
      __break(1u);
LABEL_49:
      __break(1u);
LABEL_50:
      __break(1u);
      goto LABEL_51;
    }
    uint64_t v49 = *(void **)(v48 + 8 * v43);
    *(void *)(v48 + 8 * v43) = v45;

    specialized Array._endMutation()();
    unint64_t v44 = v144;
    if ((v144 & 0xC000000000000001) != 0)
    {
      id v50 = (id)MEMORY[0x22A6753B0](v43 - 4, v144);
    }
    else
    {
      if (v47 >= *(void *)((v144 & 0xFFFFFFFFFFFFFF8) + 0x10)) {
        goto LABEL_45;
      }
      id v50 = *(id *)(v144 + 8 * v43);
    }
    uint64_t v51 = v50;
    objc_msgSend(v50, sel_setMaxConcurrentOperationCount_, 1);

    uint64_t aBlock = *(void *)&v33;
    unint64_t v142 = v34;
    uint64_t v52 = OUTLINED_FUNCTION_12_13(v138);
    id v53 = static MLSoundClassifier.FeatureExtractor.getFeaturePrintRequest(options:)(v52);
    int isUniquelyReferenced_nonNull_bridgeObject = swift_isUniquelyReferenced_nonNull_bridgeObject();
    *(void *)unint64_t v42 = v41;
    if (!isUniquelyReferenced_nonNull_bridgeObject
      || (v41 & 0x8000000000000000) != 0
      || (v41 & 0x4000000000000000) != 0)
    {
      specialized _ArrayBuffer._consumeAndCreateNew()(v41);
      unint64_t v41 = v55;
      *(void *)unint64_t v42 = v55;
    }
    uint64_t v56 = v41 & 0xFFFFFFFFFFFFFF8;
    if (v47 >= *(void *)((v41 & 0xFFFFFFFFFFFFFF8) + 0x10)) {
      goto LABEL_46;
    }
    uint64_t v57 = *(void **)(v56 + 8 * v43);
    *(void *)(v56 + 8 * v43) = v53;

    specialized Array._endMutation()();
    unint64_t v41 = *(void *)v42;
    if ((*(void *)v42 & 0xC000000000000001) != 0)
    {
      id v58 = (id)MEMORY[0x22A6753B0](v43 - 4, *(void *)v42);
    }
    else
    {
      if (v47 >= *(void *)((v41 & 0xFFFFFFFFFFFFFF8) + 0x10)) {
        goto LABEL_47;
      }
      id v58 = *(id *)(v41 + 8 * v43);
    }
    Swift::String v60 = v58;
    *(float *)&double v59 = v33;
    objc_msgSend(v58, sel_setOverlapFactor_, v59);

    ++v43;
  }
  while (v43 != 12);
  uint64_t v61 = v127;
  uint64_t v62 = v122;
  uint64_t v63 = (char *)v122 + *(int *)(v127 + 20);
  Date.init()();
  *uint64_t v62 = v35;
  type metadata accessor for NSAttributedString(0, (unint64_t *)&lazy cache variable for type metadata for OS_os_log);
  uint64_t v64 = OS_os_log.init(subsystem:category:)();
  uint64_t v65 = *(int *)(v61 + 24);
  *(void *)((char *)v62 + v65) = v64;
  Swift::Bool v66 = (void *)((char *)v62 + *(int *)(v61 + 28));
  *Swift::Bool v66 = 0x73656C6946;
  v66[1] = 0xE500000000000000;
  uint64_t v67 = v128;
  Date.init()();
  (*(void (**)(char *, uint64_t, uint64_t))(v133 + 40))(v63, v67, v137);
  _TablePrinter.beginTable()();
  _TablePrinter.printRow(currentFileIndex:)(0);
  uint64_t v68 = swift_allocObject();
  uint64_t v133 = v68;
  *(void *)(v68 + 16) = MEMORY[0x263F8EE78];
  uint64_t v69 = *(void *)(v109 + 16);
  if (v69)
  {
    v108[0] = v65;
    v108[1] = v68 + 16;
    uint64_t v128 = *((void *)v139 + 10);
    uint64_t v70 = v121 + 16;
    uint64_t v138 = *(void *)(v121 + 16);
    uint64_t v71 = *(unsigned __int8 *)(v121 + 80);
    uint64_t v115 = ~v71;
    unint64_t v42 = v109 + ((v71 + 32) & ~v71);
    uint64_t v125 = *(void *)(v121 + 72);
    uint64_t v127 = v126 + 8;
    unint64_t v114 = v123 + 7;
    uint64_t v116 = v71;
    uint64_t v113 = v71 + 8;
    uint64_t v112 = v124 + 7;
    char v111 = (void (**)(char *, uint64_t, uint64_t))(v121 + 32);
    uint64_t v110 = v143;
    uint64_t v126 = v121 + 8;
    swift_bridgeObjectRetain();
    uint64_t v137 = 0;
    uint64_t v72 = v136;
    uint64_t v121 = v70;
    do
    {
      OUTLINED_FUNCTION_5_24();
      v73();
      uint64_t v74 = v130;
      uint64_t v75 = AnnotatedFeature.feature.getter();
      MEMORY[0x270FA5388](v75);
      v108[-2] = v139;
      v108[-1] = v74;
      char v76 = specialized NSLocking.withLock<A>(_:)((void (*)(uint64_t *__return_ptr, id))partial apply for closure #1 in MLSoundClassifier.FeatureExtractor.isProcessed(url:));
      OUTLINED_FUNCTION_25_0();
      v77();
      if (v76)
      {
        uint64_t v78 = OUTLINED_FUNCTION_2_34();
        v79(v78);
      }
      else
      {
        uint64_t v124 = v69;
        unint64_t v80 = v137 % 8;
        uint64_t v136 = v72;
        if ((v144 & 0xC000000000000001) != 0)
        {
          uint64_t v81 = (char *)MEMORY[0x22A6753B0](v137 % 8);
        }
        else
        {
          if ((v80 & 0x8000000000000000) != 0) {
            goto LABEL_48;
          }
          if (v80 >= *(void *)((v144 & 0xFFFFFFFFFFFFFF8) + 0x10)) {
            goto LABEL_49;
          }
          uint64_t v81 = (char *)*(id *)(v144 + 8 * v80 + 32);
        }
        uint64_t v123 = v81;
        uint64_t v82 = v117;
        outlined init with copy of _TablePrinter((uint64_t)v122, v117);
        OUTLINED_FUNCTION_5_24();
        v83();
        unint64_t v84 = (*(unsigned __int8 *)(v118 + 80) + 48) & ~(unint64_t)*(unsigned __int8 *)(v118 + 80);
        unint64_t v85 = (unint64_t)&v114[v84] & 0xFFFFFFFFFFFFFFF8;
        unint64_t v86 = (v85 + 15) & 0xFFFFFFFFFFFFFFF8;
        unint64_t v87 = (v113 + v86) & v115;
        unint64_t v88 = (v112 + v87) & 0xFFFFFFFFFFFFFFF8;
        int v89 = (char *)swift_allocObject();
        uint64_t v90 = v133;
        *((void *)v89 + 2) = v139;
        *((void *)v89 + 3) = v90;
        id v91 = v135;
        *((void *)v89 + 4) = v134;
        *((void *)v89 + 5) = v91;
        outlined init with take of _TablePrinter(v82, (uint64_t)&v89[v84]);
        *(void *)&v89[v85] = v120;
        uint64_t v92 = v119;
        *(void *)&v89[v86] = v80;
        (*v111)(&v89[v87], v129, v92);
        *(void *)&v89[v88] = v140;
        v143[2] = partial apply for closure #1 in MLSoundClassifier.FeatureExtractor.extractFeatures();
        v143[3] = v89;
        uint64_t aBlock = MEMORY[0x263EF8330];
        unint64_t v142 = 1107296256;
        v143[0] = thunk for @escaping @callee_guaranteed @Sendable () -> ();
        v143[1] = &block_descriptor_5;
        uint64_t v93 = _Block_copy(&aBlock);
        swift_retain();
        swift_retain();
        swift_retain();
        id v94 = v135;
        swift_retain();
        swift_release();
        uint64_t v95 = v123;
        objc_msgSend(v123, sel_addOperationWithBlock_, v93);
        _Block_release(v93);

        uint64_t v96 = OUTLINED_FUNCTION_2_34();
        v97(v96);
        if (__OFADD__(v137++, 1)) {
          goto LABEL_50;
        }
        uint64_t v72 = v136;
        uint64_t v69 = v124;
      }
      v42 += v125;
      --v69;
    }
    while (v69);
    swift_bridgeObjectRelease();
  }
  unint64_t v42 = v144;
  if (!(v144 >> 62))
  {
    uint64_t v99 = *(void *)((v144 & 0xFFFFFFFFFFFFFF8) + 0x10);
    uint64_t result = swift_bridgeObjectRetain();
    if (v99) {
      goto LABEL_37;
    }
LABEL_43:
    swift_bridgeObjectRelease();
    uint64_t v104 = (uint64_t)v122;
    static os_log_type_t.info.getter();
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
    uint64_t v105 = swift_allocObject();
    *(_OWORD *)(v105 + 16) = xmmword_2272CB370;
    uint64_t v106 = MEMORY[0x263F8D750];
    *(void *)(v105 + 56) = MEMORY[0x263F8D6C8];
    *(void *)(v105 + 64) = v106;
    *(void *)(v105 + 32) = 3;
    os_log(_:dso:log:type:_:)();

    swift_bridgeObjectRelease();
    outlined destroy of _TablePrinter(v104);
    swift_beginAccess();
    uint64_t v107 = *(void *)(v133 + 16);
    swift_bridgeObjectRetain();
    swift_release();
    swift_bridgeObjectRelease();
    swift_release();
    swift_release();
    return v107;
  }
LABEL_51:
  swift_bridgeObjectRetain();
  uint64_t result = _CocoaArrayWrapper.endIndex.getter();
  uint64_t v99 = result;
  if (!result) {
    goto LABEL_43;
  }
LABEL_37:
  if (v99 >= 1)
  {
    for (uint64_t i = 0; i != v99; ++i)
    {
      if ((v42 & 0xC000000000000001) != 0) {
        id v102 = (id)MEMORY[0x22A6753B0](i, v42);
      }
      else {
        id v102 = *(id *)(v42 + 8 * i + 32);
      }
      unint64_t v103 = v102;
      objc_msgSend(v102, sel_waitUntilAllOperationsAreFinished);
    }
    goto LABEL_43;
  }
  __break(1u);
  return result;
}

uint64_t specialized Sequence.flatMap<A>(_:)(uint64_t a1)
{
  specialized _NativeDictionary.makeIterator()(v36, a1);
  uint64_t v1 = v36[0];
  int64_t v2 = v36[3];
  unint64_t v3 = v36[4];
  uint64_t v34 = v36[1];
  int64_t v35 = (unint64_t)(v36[2] + 64) >> 6;
  swift_bridgeObjectRetain();
  uint64_t v4 = MEMORY[0x263F8EE78];
  if (!v3) {
    goto LABEL_3;
  }
LABEL_2:
  unint64_t v5 = __clz(__rbit64(v3));
  v3 &= v3 - 1;
  unint64_t v6 = v5 | (v2 << 6);
  while (1)
  {
    uint64_t v10 = (uint64_t *)(*(void *)(v1 + 48) + 16 * v6);
    uint64_t v11 = *v10;
    uint64_t v12 = v10[1];
    swift_bridgeObjectRetain_n();
    uint64_t v13 = swift_bridgeObjectRetain();
    uint64_t MLComponents16AnnotatedFeatureVyAHSSGs5NeverOTg503_s8f24ML17MLSoundClassifierV16i143ExtractorC12filesByLabel7optionsAESDySSSay10Foundation3URLVGG_AE13ConfigurationVtKc33_EF88DE97863F019753745A6AAFDAF1B0LlfcSay0A12MLComponents09H29E0VyAJSSGGSS_AKtXEfU_AsJXEfU_SSTf1cn_n = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay10Foundation3URLVG_18CreateMLComponents16AnnotatedFeatureVyAHSSGs5NeverOTg503_s8f24ML17MLSoundClassifierV16i143ExtractorC12filesByLabel7optionsAESDySSSay10Foundation3URLVGG_AE13ConfigurationVtKc33_EF88DE97863F019753745A6AAFDAF1B0LlfcSay0A12MLComponents09H29E0VyAJSSGGSS_AKtXEfU_AsJXEfU_SSTf1cn_n(v13, v11, v12);
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    uint64_t v15 = *(void *)(MLComponents16AnnotatedFeatureVyAHSSGs5NeverOTg503_s8f24ML17MLSoundClassifierV16i143ExtractorC12filesByLabel7optionsAESDySSSay10Foundation3URLVGG_AE13ConfigurationVtKc33_EF88DE97863F019753745A6AAFDAF1B0LlfcSay0A12MLComponents09H29E0VyAJSSGGSS_AKtXEfU_AsJXEfU_SSTf1cn_n
                    + 16);
    uint64_t v16 = *(void *)(v4 + 16);
    if (__OFADD__(v16, v15)) {
      break;
    }
    if (!swift_isUniquelyReferenced_nonNull_native() || v16 + v15 > *(void *)(v4 + 24) >> 1)
    {
      specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
      uint64_t v4 = v17;
    }
    if (*(void *)(MLComponents16AnnotatedFeatureVyAHSSGs5NeverOTg503_s8f24ML17MLSoundClassifierV16i143ExtractorC12filesByLabel7optionsAESDySSSay10Foundation3URLVGG_AE13ConfigurationVtKc33_EF88DE97863F019753745A6AAFDAF1B0LlfcSay0A12MLComponents09H29E0VyAJSSGGSS_AKtXEfU_AsJXEfU_SSTf1cn_n
                   + 16))
    {
      uint64_t v18 = *(void *)(v4 + 16);
      uint64_t v19 = (*(void *)(v4 + 24) >> 1) - v18;
      uint64_t v20 = *(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>)
                      - 8);
      uint64_t v21 = *(void *)(v20 + 72);
      if (v19 < v15) {
        goto LABEL_40;
      }
      unint64_t v22 = (*(unsigned __int8 *)(v20 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v20 + 80);
      unint64_t v23 = v4 + v22 + v21 * v18;
      unint64_t v24 = MLComponents16AnnotatedFeatureVyAHSSGs5NeverOTg503_s8f24ML17MLSoundClassifierV16i143ExtractorC12filesByLabel7optionsAESDySSSay10Foundation3URLVGG_AE13ConfigurationVtKc33_EF88DE97863F019753745A6AAFDAF1B0LlfcSay0A12MLComponents09H29E0VyAJSSGGSS_AKtXEfU_AsJXEfU_SSTf1cn_n
          + v22;
      uint64_t v25 = v21 * v15;
      unint64_t v26 = v23 + v25;
      unint64_t v27 = v24 + v25;
      if (v24 < v26 && v23 < v27) {
        goto LABEL_43;
      }
      swift_arrayInitWithCopy();
      if (v15)
      {
        uint64_t v29 = *(void *)(v4 + 16);
        BOOL v30 = __OFADD__(v29, v15);
        uint64_t v31 = v29 + v15;
        if (v30) {
          goto LABEL_41;
        }
        *(void *)(v4 + 16) = v31;
      }
    }
    else if (v15)
    {
      goto LABEL_39;
    }
    swift_bridgeObjectRelease();
    if (v3) {
      goto LABEL_2;
    }
LABEL_3:
    int64_t v7 = v2 + 1;
    if (__OFADD__(v2, 1)) {
      goto LABEL_42;
    }
    if (v7 >= v35) {
      goto LABEL_37;
    }
    unint64_t v8 = *(void *)(v34 + 8 * v7);
    if (!v8)
    {
      int64_t v9 = v2 + 2;
      if (v2 + 2 >= v35) {
        goto LABEL_37;
      }
      unint64_t v8 = *(void *)(v34 + 8 * v9);
      if (v8) {
        goto LABEL_12;
      }
      int64_t v9 = v2 + 3;
      if (v2 + 3 >= v35) {
        goto LABEL_37;
      }
      unint64_t v8 = *(void *)(v34 + 8 * v9);
      if (v8) {
        goto LABEL_12;
      }
      int64_t v9 = v2 + 4;
      if (v2 + 4 >= v35) {
        goto LABEL_37;
      }
      unint64_t v8 = *(void *)(v34 + 8 * v9);
      if (v8)
      {
LABEL_12:
        int64_t v7 = v9;
      }
      else
      {
        int64_t v7 = v2 + 5;
        if (v2 + 5 >= v35) {
          goto LABEL_37;
        }
        unint64_t v8 = *(void *)(v34 + 8 * v7);
        if (!v8)
        {
          int64_t v32 = v2 + 6;
          while (v32 < v35)
          {
            unint64_t v8 = *(void *)(v34 + 8 * v32++);
            if (v8)
            {
              int64_t v7 = v32 - 1;
              goto LABEL_13;
            }
          }
LABEL_37:
          swift_release();
          return v4;
        }
      }
    }
LABEL_13:
    unint64_t v3 = (v8 - 1) & v8;
    unint64_t v6 = __clz(__rbit64(v8)) + (v7 << 6);
    int64_t v2 = v7;
  }
  __break(1u);
LABEL_39:
  __break(1u);
LABEL_40:
  __break(1u);
LABEL_41:
  __break(1u);
LABEL_42:
  __break(1u);
LABEL_43:
  uint64_t result = _fatalErrorMessage(_:_:file:line:flags:)();
  __break(1u);
  return result;
}

{
  uint64_t v1;
  int64_t v2;
  unint64_t v3;
  uint64_t v4;
  unint64_t v5;
  uint64_t v6;
  unint64_t v7;
  int64_t v8;
  unint64_t v9;
  int64_t v10;
  int64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t *v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t *v18;
  uint64_t v19;
  uint64_t v20;
  unint64_t v21;
  unint64_t v22;
  void *v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  unint64_t v28;
  uint64_t v30;
  BOOL v31;
  uint64_t v32;
  uint64_t result;
  uint64_t v34;
  uint64_t v35;
  int64_t v36;
  uint64_t v37;
  uint64_t v38;
  unint64_t v39;
  void v40[5];
  uint64_t v41;

  specialized _NativeDictionary.makeIterator()(v40, a1);
  uint64_t v1 = v40[0];
  uint64_t v34 = v40[1];
  int64_t v2 = v40[3];
  unint64_t v3 = v40[4];
  uint64_t v36 = (unint64_t)(v40[2] + 64) >> 6;
  swift_bridgeObjectRetain();
  uint64_t v4 = MEMORY[0x263F8EE78];
  int64_t v35 = v1;
  if (!v3) {
    goto LABEL_3;
  }
LABEL_2:
  unint64_t v5 = __clz(__rbit64(v3));
  unint64_t v6 = (v3 - 1) & v3;
  int64_t v7 = v5 | (v2 << 6);
  while (1)
  {
    uint64_t v39 = v6;
    uint64_t v12 = *(void *)(*(void *)(v1 + 56) + 8 * v7);
    uint64_t v13 = *(void *)(v12 + 16);
    if (v13)
    {
      id v37 = v2;
      uint64_t v38 = v4;
      uint64_t v14 = (uint64_t *)(*(void *)(v1 + 48) + 16 * v7);
      uint64_t v15 = *v14;
      uint64_t v16 = v14[1];
      unint64_t v41 = MEMORY[0x263F8EE78];
      swift_bridgeObjectRetain_n();
      swift_bridgeObjectRetain();
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
      uint64_t v17 = v41;
      uint64_t v18 = (uint64_t *)(v12 + 40);
      do
      {
        uint64_t v19 = *(v18 - 1);
        uint64_t v20 = *v18;
        unint64_t v41 = v17;
        unint64_t v22 = *(void *)(v17 + 16);
        uint64_t v21 = *(void *)(v17 + 24);
        swift_bridgeObjectRetain();
        swift_bridgeObjectRetain();
        if (v22 >= v21 >> 1)
        {
          specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
          uint64_t v17 = v41;
        }
        v18 += 2;
        *(void *)(v17 + 16) = v22 + 1;
        unint64_t v23 = (void *)(v17 + 32 * v22);
        uint64_t v23[4] = v19;
        v23[5] = v20;
        uint64_t v23[6] = v15;
        v23[7] = v16;
        --v13;
      }
      while (v13);
      swift_bridgeObjectRelease();
      swift_bridgeObjectRelease_n();
      uint64_t v1 = v35;
      int64_t v2 = v37;
      uint64_t v4 = v38;
    }
    else
    {
      uint64_t v17 = MEMORY[0x263F8EE78];
    }
    unint64_t v24 = *(void *)(v17 + 16);
    uint64_t v25 = *(void *)(v4 + 16);
    if (__OFADD__(v25, v24)) {
      break;
    }
    if ((swift_isUniquelyReferenced_nonNull_native() & 1) == 0 || v25 + v24 > *(void *)(v4 + 24) >> 1)
    {
      specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
      uint64_t v4 = v26;
    }
    if (*(void *)(v17 + 16))
    {
      unint64_t v27 = *(void *)(v4 + 16);
      if ((*(void *)(v4 + 24) >> 1) - v27 < v24) {
        goto LABEL_46;
      }
      id v28 = v4 + 32 * v27 + 32;
      if (v17 + 32 < v28 + 32 * v24 && v28 < v17 + 32 + 32 * v24) {
        goto LABEL_49;
      }
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (predicted: String, label: String));
      swift_arrayInitWithCopy();
      if (v24)
      {
        BOOL v30 = *(void *)(v4 + 16);
        uint64_t v31 = __OFADD__(v30, v24);
        int64_t v32 = v30 + v24;
        if (v31) {
          goto LABEL_47;
        }
        *(void *)(v4 + 16) = v32;
      }
    }
    else if (v24)
    {
      goto LABEL_45;
    }
    swift_bridgeObjectRelease();
    unint64_t v3 = v39;
    if (v39) {
      goto LABEL_2;
    }
LABEL_3:
    unint64_t v8 = v2 + 1;
    if (__OFADD__(v2, 1)) {
      goto LABEL_48;
    }
    if (v8 >= v36) {
      goto LABEL_43;
    }
    int64_t v9 = *(void *)(v34 + 8 * v8);
    uint64_t v10 = v2 + 1;
    if (!v9)
    {
      uint64_t v10 = v2 + 2;
      if (v2 + 2 >= v36) {
        goto LABEL_43;
      }
      int64_t v9 = *(void *)(v34 + 8 * v10);
      if (!v9)
      {
        uint64_t v10 = v2 + 3;
        if (v2 + 3 >= v36) {
          goto LABEL_43;
        }
        int64_t v9 = *(void *)(v34 + 8 * v10);
        if (!v9)
        {
          uint64_t v10 = v2 + 4;
          if (v2 + 4 >= v36) {
            goto LABEL_43;
          }
          int64_t v9 = *(void *)(v34 + 8 * v10);
          if (!v9)
          {
            uint64_t v10 = v2 + 5;
            if (v2 + 5 >= v36) {
              goto LABEL_43;
            }
            int64_t v9 = *(void *)(v34 + 8 * v10);
            if (!v9)
            {
              uint64_t v11 = v2 + 6;
              while (v11 < v36)
              {
                int64_t v9 = *(void *)(v34 + 8 * v11++);
                if (v9)
                {
                  uint64_t v10 = v11 - 1;
                  goto LABEL_18;
                }
              }
LABEL_43:
              swift_release();
              return v4;
            }
          }
        }
      }
    }
LABEL_18:
    unint64_t v6 = (v9 - 1) & v9;
    int64_t v7 = __clz(__rbit64(v9)) + (v10 << 6);
    int64_t v2 = v10;
  }
  __break(1u);
LABEL_45:
  __break(1u);
LABEL_46:
  __break(1u);
LABEL_47:
  __break(1u);
LABEL_48:
  __break(1u);
LABEL_49:
  uint64_t result = _fatalErrorMessage(_:_:file:line:flags:)();
  __break(1u);
  return result;
}

{
  uint64_t v1;
  int64_t v2;
  unint64_t v3;
  uint64_t v4;
  unint64_t v5;
  unint64_t v6;
  int64_t v7;
  unint64_t v8;
  int64_t v9;
  uint64_t *v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t MLComponents16AnnotatedFeatureVyAHSSGs5NeverOTg503_s8f71ML17MLSoundClassifierV10DataSourceO13annotatedURLsSay0A12MLComponents16hI51Vy10Foundation3URLVSSGGyKFANSS_SayALGtXEfU_AmLXEfU_SSTf1cn_n;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  unint64_t v23;
  unint64_t v24;
  unint64_t v25;
  uint64_t v26;
  unint64_t v27;
  unint64_t v28;
  uint64_t v30;
  BOOL v31;
  uint64_t v32;
  int64_t v33;
  uint64_t result;
  uint64_t v35;
  int64_t v36;
  void v37[5];

  specialized _NativeDictionary.makeIterator()(v37, a1);
  uint64_t v1 = v37[0];
  int64_t v2 = v37[3];
  unint64_t v3 = v37[4];
  int64_t v35 = v37[1];
  uint64_t v36 = (unint64_t)(v37[2] + 64) >> 6;
  swift_bridgeObjectRetain();
  uint64_t v4 = MEMORY[0x263F8EE78];
  if (!v3) {
    goto LABEL_3;
  }
LABEL_2:
  unint64_t v5 = __clz(__rbit64(v3));
  v3 &= v3 - 1;
  unint64_t v6 = v5 | (v2 << 6);
  while (1)
  {
    uint64_t v10 = (uint64_t *)(*(void *)(v1 + 48) + 16 * v6);
    uint64_t v11 = *v10;
    uint64_t v12 = v10[1];
    swift_bridgeObjectRetain_n();
    uint64_t v13 = swift_bridgeObjectRetain();
    MLComponents16AnnotatedFeatureVyAHSSGs5NeverOTg503_s8f71ML17MLSoundClassifierV10DataSourceO13annotatedURLsSay0A12MLComponents16hI51Vy10Foundation3URLVSSGGyKFANSS_SayALGtXEfU_AmLXEfU_SSTf1cn_n = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay10Foundation3URLVG_18CreateMLComponents16AnnotatedFeatureVyAHSSGs5NeverOTg503_s8f71ML17MLSoundClassifierV10DataSourceO13annotatedURLsSay0A12MLComponents16hI51Vy10Foundation3URLVSSGGyKFANSS_SayALGtXEfU_AmLXEfU_SSTf1cn_n(v13, v11, v12);
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    uint64_t v15 = *(void *)(MLComponents16AnnotatedFeatureVyAHSSGs5NeverOTg503_s8f71ML17MLSoundClassifierV10DataSourceO13annotatedURLsSay0A12MLComponents16hI51Vy10Foundation3URLVSSGGyKFANSS_SayALGtXEfU_AmLXEfU_SSTf1cn_n
                    + 16);
    uint64_t v16 = *(void *)(v4 + 16);
    if (__OFADD__(v16, v15)) {
      break;
    }
    if (!swift_isUniquelyReferenced_nonNull_native() || v16 + v15 > *(void *)(v4 + 24) >> 1)
    {
      specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
      uint64_t v4 = v17;
    }
    if (*(void *)(MLComponents16AnnotatedFeatureVyAHSSGs5NeverOTg503_s8f71ML17MLSoundClassifierV10DataSourceO13annotatedURLsSay0A12MLComponents16hI51Vy10Foundation3URLVSSGGyKFANSS_SayALGtXEfU_AmLXEfU_SSTf1cn_n
                   + 16))
    {
      uint64_t v18 = *(void *)(v4 + 16);
      uint64_t v19 = (*(void *)(v4 + 24) >> 1) - v18;
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
      OUTLINED_FUNCTION_57_5();
      unint64_t v22 = *(void *)(v21 + 72);
      if (v19 < v15) {
        goto LABEL_40;
      }
      unint64_t v23 = (*(unsigned __int8 *)(v20 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v20 + 80);
      unint64_t v24 = v4 + v23 + v22 * v18;
      uint64_t v25 = MLComponents16AnnotatedFeatureVyAHSSGs5NeverOTg503_s8f71ML17MLSoundClassifierV10DataSourceO13annotatedURLsSay0A12MLComponents16hI51Vy10Foundation3URLVSSGGyKFANSS_SayALGtXEfU_AmLXEfU_SSTf1cn_n
          + v23;
      unint64_t v26 = v22 * v15;
      unint64_t v27 = v24 + v26;
      id v28 = v25 + v26;
      if (v25 < v27 && v24 < v28) {
        goto LABEL_43;
      }
      swift_arrayInitWithCopy();
      if (v15)
      {
        BOOL v30 = *(void *)(v4 + 16);
        uint64_t v31 = __OFADD__(v30, v15);
        int64_t v32 = v30 + v15;
        if (v31) {
          goto LABEL_41;
        }
        *(void *)(v4 + 16) = v32;
      }
    }
    else if (v15)
    {
      goto LABEL_39;
    }
    swift_bridgeObjectRelease();
    if (v3) {
      goto LABEL_2;
    }
LABEL_3:
    int64_t v7 = v2 + 1;
    if (__OFADD__(v2, 1)) {
      goto LABEL_42;
    }
    if (v7 >= v36) {
      goto LABEL_37;
    }
    unint64_t v8 = *(void *)(v35 + 8 * v7);
    if (!v8)
    {
      int64_t v9 = v2 + 2;
      if (v2 + 2 >= v36) {
        goto LABEL_37;
      }
      unint64_t v8 = *(void *)(v35 + 8 * v9);
      if (v8) {
        goto LABEL_12;
      }
      int64_t v9 = v2 + 3;
      if (v2 + 3 >= v36) {
        goto LABEL_37;
      }
      unint64_t v8 = *(void *)(v35 + 8 * v9);
      if (v8) {
        goto LABEL_12;
      }
      int64_t v9 = v2 + 4;
      if (v2 + 4 >= v36) {
        goto LABEL_37;
      }
      unint64_t v8 = *(void *)(v35 + 8 * v9);
      if (v8)
      {
LABEL_12:
        int64_t v7 = v9;
      }
      else
      {
        int64_t v7 = v2 + 5;
        if (v2 + 5 >= v36) {
          goto LABEL_37;
        }
        unint64_t v8 = *(void *)(v35 + 8 * v7);
        if (!v8)
        {
          double v33 = v2 + 6;
          while (v33 < v36)
          {
            unint64_t v8 = *(void *)(v35 + 8 * v33++);
            if (v8)
            {
              int64_t v7 = v33 - 1;
              goto LABEL_13;
            }
          }
LABEL_37:
          swift_release();
          return v4;
        }
      }
    }
LABEL_13:
    unint64_t v3 = (v8 - 1) & v8;
    unint64_t v6 = __clz(__rbit64(v8)) + (v7 << 6);
    int64_t v2 = v7;
  }
  __break(1u);
LABEL_39:
  __break(1u);
LABEL_40:
  __break(1u);
LABEL_41:
  __break(1u);
LABEL_42:
  __break(1u);
LABEL_43:
  uint64_t result = _fatalErrorMessage(_:_:file:line:flags:)();
  __break(1u);
  return result;
}

{
  uint64_t v1;
  int64_t v2;
  unint64_t v3;
  int64_t v4;
  uint64_t v5;
  unint64_t v6;
  unint64_t v7;
  int64_t v8;
  unint64_t v9;
  int64_t v10;
  int64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  unint64_t v20;
  unint64_t v21;
  unint64_t v22;
  uint64_t v23;
  unint64_t v24;
  unint64_t v25;
  uint64_t v27;
  BOOL v28;
  uint64_t v29;
  uint64_t result;
  void v31[5];
  uint64_t v32;

  specialized _NativeDictionary.makeIterator()(v31, a1);
  uint64_t v1 = v31[0];
  int64_t v32 = v31[1];
  int64_t v2 = v31[3];
  unint64_t v3 = v31[4];
  uint64_t v4 = (unint64_t)(v31[2] + 64) >> 6;
  swift_bridgeObjectRetain();
  unint64_t v5 = MEMORY[0x263F8EE78];
  if (!v3) {
    goto LABEL_3;
  }
LABEL_2:
  unint64_t v6 = __clz(__rbit64(v3));
  v3 &= v3 - 1;
  int64_t v7 = v6 | (v2 << 6);
  while (1)
  {
    uint64_t v12 = *(void *)(*(void *)(v1 + 56) + 8 * v7);
    uint64_t v13 = *(void *)(v12 + 16);
    uint64_t v14 = *(void *)(v5 + 16);
    if (__OFADD__(v14, v13)) {
      break;
    }
    swift_bridgeObjectRetain();
    if (!swift_isUniquelyReferenced_nonNull_native() || v14 + v13 > *(void *)(v5 + 24) >> 1)
    {
      specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
      unint64_t v5 = v15;
    }
    if (*(void *)(v12 + 16))
    {
      uint64_t v16 = *(void *)(v5 + 16);
      uint64_t v17 = (*(void *)(v5 + 24) >> 1) - v16;
      uint64_t v18 = *(void *)(type metadata accessor for URL() - 8);
      uint64_t v19 = *(void *)(v18 + 72);
      if (v17 < v13) {
        goto LABEL_39;
      }
      uint64_t v20 = (*(unsigned __int8 *)(v18 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v18 + 80);
      uint64_t v21 = v5 + v20 + v19 * v16;
      unint64_t v22 = v12 + v20;
      unint64_t v23 = v19 * v13;
      unint64_t v24 = v21 + v23;
      uint64_t v25 = v22 + v23;
      if (v22 < v24 && v21 < v25) {
        goto LABEL_42;
      }
      swift_arrayInitWithCopy();
      if (v13)
      {
        unint64_t v27 = *(void *)(v5 + 16);
        id v28 = __OFADD__(v27, v13);
        uint64_t v29 = v27 + v13;
        if (v28) {
          goto LABEL_40;
        }
        *(void *)(v5 + 16) = v29;
      }
    }
    else if (v13)
    {
      goto LABEL_38;
    }
    swift_bridgeObjectRelease();
    if (v3) {
      goto LABEL_2;
    }
LABEL_3:
    unint64_t v8 = v2 + 1;
    if (__OFADD__(v2, 1)) {
      goto LABEL_41;
    }
    if (v8 >= v4) {
      goto LABEL_36;
    }
    int64_t v9 = *(void *)(v32 + 8 * v8);
    uint64_t v10 = v2 + 1;
    if (!v9)
    {
      uint64_t v10 = v2 + 2;
      if (v2 + 2 >= v4) {
        goto LABEL_36;
      }
      int64_t v9 = *(void *)(v32 + 8 * v10);
      if (!v9)
      {
        uint64_t v10 = v2 + 3;
        if (v2 + 3 >= v4) {
          goto LABEL_36;
        }
        int64_t v9 = *(void *)(v32 + 8 * v10);
        if (!v9)
        {
          uint64_t v10 = v2 + 4;
          if (v2 + 4 >= v4) {
            goto LABEL_36;
          }
          int64_t v9 = *(void *)(v32 + 8 * v10);
          if (!v9)
          {
            uint64_t v10 = v2 + 5;
            if (v2 + 5 >= v4) {
              goto LABEL_36;
            }
            int64_t v9 = *(void *)(v32 + 8 * v10);
            if (!v9)
            {
              uint64_t v11 = v2 + 6;
              while (v11 < v4)
              {
                int64_t v9 = *(void *)(v32 + 8 * v11++);
                if (v9)
                {
                  uint64_t v10 = v11 - 1;
                  goto LABEL_18;
                }
              }
LABEL_36:
              swift_release();
              return v5;
            }
          }
        }
      }
    }
LABEL_18:
    unint64_t v3 = (v9 - 1) & v9;
    int64_t v7 = __clz(__rbit64(v9)) + (v10 << 6);
    int64_t v2 = v10;
  }
  __break(1u);
LABEL_38:
  __break(1u);
LABEL_39:
  __break(1u);
LABEL_40:
  __break(1u);
LABEL_41:
  __break(1u);
LABEL_42:
  uint64_t result = _fatalErrorMessage(_:_:file:line:flags:)();
  __break(1u);
  return result;
}

{
  uint64_t v1;
  int64_t v2;
  unint64_t v3;
  uint64_t v4;
  unint64_t v5;
  unint64_t v6;
  int64_t v7;
  unint64_t v8;
  int64_t v9;
  uint64_t *v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t MLComponents16AnnotatedFeatureVyAHSSGs5NeverOTg503_s8f80ML17MLImageClassifierV10DataSourceO17annotatedFeatures4fromSay0A12MLComponents16hI60Vy10Foundation3URLVSSGGSDySSSayAMGG_tFZAOSS_APtXEfU_AnMXEfU_SSTf1cn_n;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  unint64_t v23;
  unint64_t v24;
  unint64_t v25;
  uint64_t v26;
  unint64_t v27;
  unint64_t v28;
  uint64_t v30;
  BOOL v31;
  uint64_t v32;
  int64_t v33;
  uint64_t result;
  uint64_t v35;
  int64_t v36;
  void v37[5];

  specialized _NativeDictionary.makeIterator()(v37, a1);
  uint64_t v1 = v37[0];
  int64_t v2 = v37[3];
  unint64_t v3 = v37[4];
  int64_t v35 = v37[1];
  uint64_t v36 = (unint64_t)(v37[2] + 64) >> 6;
  swift_bridgeObjectRetain();
  uint64_t v4 = MEMORY[0x263F8EE78];
  if (!v3) {
    goto LABEL_3;
  }
LABEL_2:
  unint64_t v5 = __clz(__rbit64(v3));
  v3 &= v3 - 1;
  unint64_t v6 = v5 | (v2 << 6);
  while (1)
  {
    uint64_t v10 = (uint64_t *)(*(void *)(v1 + 48) + 16 * v6);
    uint64_t v11 = *v10;
    uint64_t v12 = v10[1];
    swift_bridgeObjectRetain_n();
    uint64_t v13 = swift_bridgeObjectRetain();
    MLComponents16AnnotatedFeatureVyAHSSGs5NeverOTg503_s8f80ML17MLImageClassifierV10DataSourceO17annotatedFeatures4fromSay0A12MLComponents16hI60Vy10Foundation3URLVSSGGSDySSSayAMGG_tFZAOSS_APtXEfU_AnMXEfU_SSTf1cn_n = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay10Foundation3URLVG_18CreateMLComponents16AnnotatedFeatureVyAHSSGs5NeverOTg503_s8f80ML17MLImageClassifierV10DataSourceO17annotatedFeatures4fromSay0A12MLComponents16hI60Vy10Foundation3URLVSSGGSDySSSayAMGG_tFZAOSS_APtXEfU_AnMXEfU_SSTf1cn_n(v13, v11, v12);
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    uint64_t v15 = *(void *)(MLComponents16AnnotatedFeatureVyAHSSGs5NeverOTg503_s8f80ML17MLImageClassifierV10DataSourceO17annotatedFeatures4fromSay0A12MLComponents16hI60Vy10Foundation3URLVSSGGSDySSSayAMGG_tFZAOSS_APtXEfU_AnMXEfU_SSTf1cn_n
                    + 16);
    uint64_t v16 = *(void *)(v4 + 16);
    if (__OFADD__(v16, v15)) {
      break;
    }
    if (!swift_isUniquelyReferenced_nonNull_native() || v16 + v15 > *(void *)(v4 + 24) >> 1)
    {
      specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
      uint64_t v4 = v17;
    }
    if (*(void *)(MLComponents16AnnotatedFeatureVyAHSSGs5NeverOTg503_s8f80ML17MLImageClassifierV10DataSourceO17annotatedFeatures4fromSay0A12MLComponents16hI60Vy10Foundation3URLVSSGGSDySSSayAMGG_tFZAOSS_APtXEfU_AnMXEfU_SSTf1cn_n
                   + 16))
    {
      uint64_t v18 = *(void *)(v4 + 16);
      uint64_t v19 = (*(void *)(v4 + 24) >> 1) - v18;
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
      OUTLINED_FUNCTION_57_5();
      unint64_t v22 = *(void *)(v21 + 72);
      if (v19 < v15) {
        goto LABEL_40;
      }
      unint64_t v23 = (*(unsigned __int8 *)(v20 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v20 + 80);
      unint64_t v24 = v4 + v23 + v22 * v18;
      uint64_t v25 = MLComponents16AnnotatedFeatureVyAHSSGs5NeverOTg503_s8f80ML17MLImageClassifierV10DataSourceO17annotatedFeatures4fromSay0A12MLComponents16hI60Vy10Foundation3URLVSSGGSDySSSayAMGG_tFZAOSS_APtXEfU_AnMXEfU_SSTf1cn_n
          + v23;
      unint64_t v26 = v22 * v15;
      unint64_t v27 = v24 + v26;
      id v28 = v25 + v26;
      if (v25 < v27 && v24 < v28) {
        goto LABEL_43;
      }
      swift_arrayInitWithCopy();
      if (v15)
      {
        BOOL v30 = *(void *)(v4 + 16);
        uint64_t v31 = __OFADD__(v30, v15);
        int64_t v32 = v30 + v15;
        if (v31) {
          goto LABEL_41;
        }
        *(void *)(v4 + 16) = v32;
      }
    }
    else if (v15)
    {
      goto LABEL_39;
    }
    swift_bridgeObjectRelease();
    if (v3) {
      goto LABEL_2;
    }
LABEL_3:
    int64_t v7 = v2 + 1;
    if (__OFADD__(v2, 1)) {
      goto LABEL_42;
    }
    if (v7 >= v36) {
      goto LABEL_37;
    }
    unint64_t v8 = *(void *)(v35 + 8 * v7);
    if (!v8)
    {
      int64_t v9 = v2 + 2;
      if (v2 + 2 >= v36) {
        goto LABEL_37;
      }
      unint64_t v8 = *(void *)(v35 + 8 * v9);
      if (v8) {
        goto LABEL_12;
      }
      int64_t v9 = v2 + 3;
      if (v2 + 3 >= v36) {
        goto LABEL_37;
      }
      unint64_t v8 = *(void *)(v35 + 8 * v9);
      if (v8) {
        goto LABEL_12;
      }
      int64_t v9 = v2 + 4;
      if (v2 + 4 >= v36) {
        goto LABEL_37;
      }
      unint64_t v8 = *(void *)(v35 + 8 * v9);
      if (v8)
      {
LABEL_12:
        int64_t v7 = v9;
      }
      else
      {
        int64_t v7 = v2 + 5;
        if (v2 + 5 >= v36) {
          goto LABEL_37;
        }
        unint64_t v8 = *(void *)(v35 + 8 * v7);
        if (!v8)
        {
          double v33 = v2 + 6;
          while (v33 < v36)
          {
            unint64_t v8 = *(void *)(v35 + 8 * v33++);
            if (v8)
            {
              int64_t v7 = v33 - 1;
              goto LABEL_13;
            }
          }
LABEL_37:
          swift_release();
          return v4;
        }
      }
    }
LABEL_13:
    unint64_t v3 = (v8 - 1) & v8;
    unint64_t v6 = __clz(__rbit64(v8)) + (v7 << 6);
    int64_t v2 = v7;
  }
  __break(1u);
LABEL_39:
  __break(1u);
LABEL_40:
  __break(1u);
LABEL_41:
  __break(1u);
LABEL_42:
  __break(1u);
LABEL_43:
  uint64_t result = _fatalErrorMessage(_:_:file:line:flags:)();
  __break(1u);
  return result;
}

id static MLSoundClassifier.FeatureExtractor.getFeaturePrintRequest(options:)(uint64_t a1)
{
  int v1 = *(unsigned __int8 *)(a1 + 40);
  if (v1 == 255)
  {
    id v2 = objc_allocWithZone(MEMORY[0x263F179E0]);
  }
  else
  {
    Swift::Double v3 = *(double *)(a1 + 8);
    id v2 = objc_allocWithZone(MEMORY[0x263F179E0]);
    if (v1)
    {
      id v5 = objc_msgSend(v2, sel_initWithFeaturePrintType_, 3);
      CMTime v6 = CMTime.init(seconds:preferredTimescale:)(v3, 16000);
      objc_msgSend(v5, sel_setWindowDuration_, &v6);
      return v5;
    }
  }

  return objc_msgSend(v2, sel_init);
}

void trainWork #1 (_:annotatedFeature:) in MLSoundClassifier.FeatureExtractor.extractFeatures()(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, void *a6, uint64_t a7, void *a8)
{
}

void closure #1 in trainWork #1 (_:annotatedFeature:) in MLSoundClassifier.FeatureExtractor.extractFeatures()(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, void *a5, void *a6, uint64_t a7, void *a8)
{
  id v34 = a8;
  uint64_t v35 = a4;
  uint64_t v31 = a7;
  id v32 = a6;
  uint64_t v33 = a2;
  v38[3] = *(id *)MEMORY[0x263EF8340];
  uint64_t v12 = type metadata accessor for URL();
  uint64_t v36 = *(void *)(v12 - 8);
  uint64_t v37 = v12;
  uint64_t v13 = MEMORY[0x270FA5388](v12);
  uint64_t v14 = MEMORY[0x270FA5388](v13);
  uint64_t v16 = (char *)&v28 - v15;
  MEMORY[0x270FA5388](v14);
  uint64_t v18 = (char *)&v28 - v17;
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
  AnnotatedFeature.feature.getter();
  id v19 = objc_allocWithZone(MEMORY[0x263F179A0]);
  id v20 = @nonobjc SNAudioFileAnalyzer.init(url:)((uint64_t)v18);
  if (!v8)
  {
    uint64_t v21 = v20;
    id v22 = objc_msgSend(objc_allocWithZone(MEMORY[0x263F17A40]), sel_init);
    v38[0] = 0;
    if (objc_msgSend(v21, sel_addRequest_withObserver_error_, v33, v22, v38))
    {
      id v23 = v38[0];
      id v30 = v21;
      objc_msgSend(v21, sel_analyze);
      uint64_t v33 = *(void *)(a3 + 32);
      id v29 = v22;
      static MLSoundClassifier.FeatureExtractor.convertResultsToShapedArrays(resultsCollector:options:)(v22);
      id v34 = *(id *)(a3 + 80);
      id v24 = objc_msgSend(v34, sel_lock);
      MEMORY[0x270FA5388](v24);
      *(&v28 - 2) = a1;
      _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay6CoreML13MLShapedArrayVySfGG_18CreateMLComponents16AnnotatedFeatureVyAISSGs5NeverOTg5();
      uint64_t v28 = 0;
      swift_bridgeObjectRelease();
      swift_beginAccess();
      specialized Array.append<A>(contentsOf:)();
      swift_endAccess();
      AnnotatedFeature.feature.getter();
      swift_beginAccess();
      specialized Set._Variant.insert(_:)();
      swift_endAccess();
      (*(void (**)(char *, uint64_t))(v36 + 8))(v16, v37);
      swift_beginAccess();
      if (__OFADD__(*a5, 1))
      {
        __break(1u);
      }
      else
      {
        ++*a5;
        id v25 = v32;
        unint64_t v26 = (char *)objc_msgSend(v32, sel_completedUnitCount);
        if (!__OFADD__(v26, 1))
        {
          objc_msgSend(v25, sel_setCompletedUnitCount_, v26 + 1);
          swift_beginAccess();
          if (!__OFADD__(*a5, v33))
          {
            _TablePrinter.printRow(currentFileIndex:)(*a5 + v33);
            objc_msgSend(v34, sel_unlock);

            return;
          }
LABEL_9:
          __break(1u);
        }
      }
      __break(1u);
      goto LABEL_9;
    }
    id v27 = v38[0];
    _convertNSErrorToError(_:)();

    swift_willThrow();
  }
  swift_unexpectedError();
  __break(1u);
}

uint64_t static MLSoundClassifier.FeatureExtractor.convertResultsToShapedArrays(resultsCollector:options:)(void *a1)
{
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Float>);
  OUTLINED_FUNCTION_0();
  uint64_t v4 = v3;
  MEMORY[0x270FA5388](v5);
  OUTLINED_FUNCTION_49();
  uint64_t v30 = v6;
  MEMORY[0x270FA5388](v7);
  int64_t v9 = (char *)&v26 - v8;
  id v10 = objc_msgSend(a1, sel_results);
  uint64_t v11 = MEMORY[0x263F8EE58] + 8;
  static Array._unconditionallyBridgeFromObjectiveC(_:)();

  swift_bridgeObjectRelease();
  specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
  uint64_t v13 = v12;
  id v14 = objc_msgSend(a1, sel_results);
  uint64_t v29 = v11;
  uint64_t v15 = static Array._unconditionallyBridgeFromObjectiveC(_:)();

  uint64_t v16 = *(void *)(v15 + 16);
  if (v16)
  {
    uint64_t v17 = v15 + 32;
    uint64_t v28 = v4 + 32;
    uint64_t v26 = v15;
    uint64_t v27 = v4 + 8;
    uint64_t v18 = v30;
    do
    {
      outlined init with copy of Any(v17, (uint64_t)v32);
      type metadata accessor for NSAttributedString(0, &lazy cache variable for type metadata for SNFeaturePrint);
      swift_dynamicCast();
      id v19 = v31;
      id v20 = objc_msgSend(v31, sel_featureVector, v26, v27, v28);
      static MLSoundClassifier.FeatureExtractor.convertVector(_:)(v20, (uint64_t)v9);

      (*(void (**)(uint64_t, char *, uint64_t))(v4 + 16))(v18, v9, v2);
      unint64_t v21 = *(void *)(v13 + 16);
      if (v21 >= *(void *)(v13 + 24) >> 1)
      {
        specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
        uint64_t v13 = v24;
      }
      *(void *)(v13 + 16) = v21 + 1;
      unint64_t v22 = v13
          + ((*(unsigned __int8 *)(v4 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v4 + 80))
          + *(void *)(v4 + 72) * v21;
      uint64_t v18 = v30;
      (*(void (**)(unint64_t, uint64_t, uint64_t))(v4 + 32))(v22, v30, v2);

      OUTLINED_FUNCTION_25_0();
      v23();
      v17 += 32;
      --v16;
    }
    while (v16);
  }
  swift_bridgeObjectRelease();
  return v13;
}

uint64_t closure #1 in closure #1 in trainWork #1 (_:annotatedFeature:) in MLSoundClassifier.FeatureExtractor.extractFeatures()(uint64_t a1)
{
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Float>);
  MEMORY[0x270FA5388](v2);
  (*(void (**)(char *, uint64_t, uint64_t))(v4 + 16))((char *)v6 - ((v3 + 15) & 0xFFFFFFFFFFFFFFF0), a1, v2);
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
  AnnotatedFeature.annotation.getter();
  v6[0] = v6[2];
  v6[1] = v6[3];
  return AnnotatedFeature.init(feature:annotation:)();
}

void closure #1 in MLSoundClassifier.FeatureExtractor.extractFeatures()(uint64_t a1, uint64_t a2, uint64_t a3, void *a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, void *a9)
{
  swift_beginAccess();
  uint64_t v17 = *(void *)(a6 + 16);
  specialized Array._checkSubscript(_:wasNativeTypeChecked:)(a7, (v17 & 0xC000000000000001) == 0, v17);
  if ((v17 & 0xC000000000000001) != 0) {
    id v18 = (id)MEMORY[0x22A6753B0](a7, v17);
  }
  else {
    id v18 = *(id *)(v17 + 8 * a7 + 32);
  }
  id v19 = v18;
  swift_endAccess();
  trainWork #1 (_:annotatedFeature:) in MLSoundClassifier.FeatureExtractor.extractFeatures()((uint64_t)v19, a8, a1, a2, a3, a4, a5, a9);
}

uint64_t thunk for @escaping @callee_guaranteed @Sendable () -> ()(uint64_t a1)
{
  int v1 = *(void (**)(uint64_t))(a1 + 32);
  uint64_t v2 = swift_retain();
  v1(v2);

  return swift_release();
}

uint64_t closure #1 in MLSoundClassifier.FeatureExtractor.isProcessed(url:)@<X0>(uint64_t a1@<X0>, uint64_t a2@<X1>, unsigned char *a3@<X8>)
{
  swift_beginAccess();
  uint64_t v6 = *(void *)(a1 + 72);
  swift_bridgeObjectRetain();
  LOBYTE(a2) = specialized Set.contains(_:)(a2, v6);
  uint64_t result = swift_bridgeObjectRelease();
  *a3 = a2 & 1;
  return result;
}

void *static MLSoundClassifier.FeatureExtractor.convertVector(_:)@<X0>(void *a1@<X0>, uint64_t a2@<X8>)
{
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Float>);
  OUTLINED_FUNCTION_0();
  uint64_t v6 = v5;
  MEMORY[0x270FA5388](v7);
  int64_t v9 = (char *)v16 - ((v8 + 15) & 0xFFFFFFFFFFFFFFF0);
  id v10 = a1;
  MLShapedArray.init(_:)();
  uint64_t v11 = *(void *)(MLShapedArray.shape.getter() + 16);
  uint64_t result = (void *)swift_bridgeObjectRelease();
  if (v11 == 2)
  {
    uint64_t result = (void *)MLShapedArray.shape.getter();
    if (result[2])
    {
      uint64_t v13 = result[4];
      uint64_t result = (void *)swift_bridgeObjectRelease();
      if (v13 != 1) {
        return result;
      }
      lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type MLShapedArray<Float> and conformance MLShapedArray<A>, &demangling cache variable for type metadata for MLShapedArray<Float>);
      v16[1] = MLShapedArrayProtocol.scalars.getter();
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
      uint64_t v14 = swift_allocObject();
      *(_OWORD *)(v14 + 16) = xmmword_2272CB370;
      uint64_t result = (void *)MLShapedArray.shape.getter();
      if (result[2] >= 2uLL)
      {
        uint64_t v15 = result[5];
        swift_bridgeObjectRelease();
        *(void *)(v14 + 32) = v15;
        __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Float]);
        lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>((unint64_t *)&lazy protocol witness table cache variable for type [Float] and conformance [A], &demangling cache variable for type metadata for [Float]);
        MLShapedArray.init<A>(scalars:shape:)();
        (*(void (**)(uint64_t, uint64_t))(v6 + 8))(a2, v4);
        return (void *)(*(uint64_t (**)(uint64_t, char *, uint64_t))(v6 + 32))(a2, v9, v4);
      }
    }
    else
    {
      __break(1u);
    }
    __break(1u);
  }
  return result;
}

uint64_t MLSoundClassifier.FeatureExtractor.deinit()
{
  swift_bridgeObjectRelease();
  swift_bridgeObjectRelease();

  return v0;
}

uint64_t MLSoundClassifier.FeatureExtractor.__deallocating_deinit()
{
  MLSoundClassifier.FeatureExtractor.deinit();

  return swift_deallocClassInstance();
}

uint64_t type metadata accessor for MLSoundClassifier.FeatureExtractor()
{
  return self;
}

__n128 __swift_memcpy41_8(uint64_t a1, uint64_t a2)
{
  __n128 result = *(__n128 *)a2;
  long long v3 = *(_OWORD *)(a2 + 16);
  *(_OWORD *)(a1 + 25) = *(_OWORD *)(a2 + 25);
  *(__n128 *)a1 = result;
  *(_OWORD *)(a1 + 16) = v3;
  return result;
}

uint64_t getEnumTagSinglePayload for MLSoundClassifier.FeatureExtractor.Configuration(uint64_t a1, unsigned int a2)
{
  if (a2)
  {
    if (a2 >= 0xFE && *(unsigned char *)(a1 + 41))
    {
      int v2 = *(_DWORD *)a1 + 253;
    }
    else
    {
      unsigned int v3 = *(unsigned __int8 *)(a1 + 40);
      if (v3 <= 1) {
        int v2 = -1;
      }
      else {
        int v2 = (v3 ^ 0xFF) - 1;
      }
    }
  }
  else
  {
    int v2 = -1;
  }
  return (v2 + 1);
}

uint64_t storeEnumTagSinglePayload for MLSoundClassifier.FeatureExtractor.Configuration(uint64_t result, unsigned int a2, unsigned int a3)
{
  if (a2 > 0xFD)
  {
    *(_OWORD *)(result + 24) = 0u;
    *(_OWORD *)(result + 8) = 0u;
    *(unsigned char *)(result + 40) = 0;
    *(void *)__n128 result = a2 - 254;
    if (a3 >= 0xFE) {
      *(unsigned char *)(result + 41) = 1;
    }
  }
  else
  {
    if (a3 >= 0xFE) {
      *(unsigned char *)(result + 41) = 0;
    }
    if (a2) {
      *(unsigned char *)(result + 40) = ~(_BYTE)a2;
    }
  }
  return result;
}

ValueMetadata *type metadata accessor for MLSoundClassifier.FeatureExtractor.Configuration()
{
  return &type metadata for MLSoundClassifier.FeatureExtractor.Configuration;
}

id @nonobjc SNAudioFileAnalyzer.init(url:)(uint64_t a1)
{
  int v2 = v1;
  uint64_t v15 = (NSURL *)*MEMORY[0x263EF8340];
  URL._bridgeToObjectiveC()(v15);
  uint64_t v5 = v4;
  id v14 = 0;
  id v6 = objc_msgSend(v2, sel_initWithURL_error_, v4, &v14);

  id v7 = v14;
  if (v6)
  {
    uint64_t v8 = type metadata accessor for URL();
    int64_t v9 = *(void (**)(uint64_t, uint64_t))(*(void *)(v8 - 8) + 8);
    id v10 = v7;
    v9(a1, v8);
  }
  else
  {
    id v11 = v14;
    _convertNSErrorToError(_:)();

    swift_willThrow();
    uint64_t v12 = type metadata accessor for URL();
    (*(void (**)(uint64_t, uint64_t))(*(void *)(v12 - 8) + 8))(a1, v12);
  }
  return v6;
}

uint64_t sub_22712F938()
{
  return MEMORY[0x270FA0238](v0, 24, 7);
}

uint64_t sub_22712F948()
{
  swift_bridgeObjectRelease();

  return MEMORY[0x270FA0238](v0, 24, 7);
}

void specialized _ArrayBuffer._consumeAndCreateNew()()
{
  char v0 = OUTLINED_FUNCTION_4_30();
  specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v0, v1, v2, v3);
}

{
  char v0;
  uint64_t v1;
  char v2;
  uint64_t v3;

  char v0 = OUTLINED_FUNCTION_4_30();
  specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v0, v1, v2, v3);
}

{
  OUTLINED_FUNCTION_4_30();
  specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
}

{
  OUTLINED_FUNCTION_4_30();
  specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
}

{
  OUTLINED_FUNCTION_4_30();
  specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
}

{
  OUTLINED_FUNCTION_4_30();
  specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
}

{
  OUTLINED_FUNCTION_4_30();
  specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
}

uint64_t partial apply for closure #1 in MLSoundClassifier.FeatureExtractor.isProcessed(url:)@<X0>(unsigned char *a1@<X8>)
{
  return closure #1 in MLSoundClassifier.FeatureExtractor.isProcessed(url:)(*(void *)(v1 + 16), *(void *)(v1 + 24), a1);
}

uint64_t outlined init with copy of _TablePrinter(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = type metadata accessor for _TablePrinter(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 16))(a2, a1, v4);
  return a2;
}

uint64_t sub_22712FA64()
{
  uint64_t v1 = (int *)(type metadata accessor for _TablePrinter(0) - 8);
  uint64_t v2 = *(unsigned __int8 *)(*(void *)v1 + 80);
  uint64_t v3 = (v2 + 48) & ~v2;
  unint64_t v4 = (*(void *)(*(void *)v1 + 64) + v3 + 7) & 0xFFFFFFFFFFFFFFF8;
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
  OUTLINED_FUNCTION_0();
  uint64_t v7 = v6;
  uint64_t v9 = v8;
  uint64_t v10 = *(unsigned __int8 *)(v7 + 80);
  unint64_t v11 = (((v4 + 15) & 0xFFFFFFFFFFFFFFF8) + v10 + 8) & ~v10;
  uint64_t v12 = v2 | v10 | 7;
  unint64_t v13 = ((*(void *)(v9 + 64) + v11 + 7) & 0xFFFFFFFFFFFFFFF8) + 8;
  swift_release();
  swift_release();
  swift_release();

  type metadata accessor for Date();
  OUTLINED_FUNCTION_25_0();
  v14();

  swift_bridgeObjectRelease();
  swift_release();
  (*(void (**)(unint64_t, uint64_t))(v7 + 8))(v0 + v11, v5);

  return MEMORY[0x270FA0238](v0, v13, v12);
}

uint64_t outlined init with take of _TablePrinter(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = type metadata accessor for _TablePrinter(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 32))(a2, a1, v4);
  return a2;
}

void partial apply for closure #1 in MLSoundClassifier.FeatureExtractor.extractFeatures()()
{
  uint64_t v1 = type metadata accessor for _TablePrinter(0);
  OUTLINED_FUNCTION_1(v1);
  unint64_t v3 = (*(unsigned __int8 *)(v2 + 80) + 48) & ~(unint64_t)*(unsigned __int8 *)(v2 + 80);
  unint64_t v5 = (*(void *)(v4 + 64) + v3 + 7) & 0xFFFFFFFFFFFFFFF8;
  unint64_t v6 = (v5 + 15) & 0xFFFFFFFFFFFFFFF8;
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
  OUTLINED_FUNCTION_1(v7);
  uint64_t v9 = v8;
  uint64_t v11 = v10;
  unint64_t v12 = (v6 + *(unsigned __int8 *)(v9 + 80) + 8) & ~(unint64_t)*(unsigned __int8 *)(v9 + 80);
  closure #1 in MLSoundClassifier.FeatureExtractor.extractFeatures()(*(void *)(v0 + 16), *(void *)(v0 + 24), *(void *)(v0 + 32), *(void **)(v0 + 40), v0 + v3, *(void *)(v0 + v5), *(void *)(v0 + v6), v0 + v12, *(void **)(v0 + ((*(void *)(v11 + 64) + v12 + 7) & 0xFFFFFFFFFFFFFFF8)));
}

uint64_t block_copy_helper_3(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = *(void *)(a2 + 40);
  *(void *)(a1 + 32) = *(void *)(a2 + 32);
  *(void *)(a1 + 40) = v2;
  return swift_retain();
}

uint64_t block_destroy_helper_3()
{
  return swift_release();
}

uint64_t outlined destroy of _TablePrinter(uint64_t a1)
{
  uint64_t v2 = type metadata accessor for _TablePrinter(0);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v2 - 8) + 8))(a1, v2);
  return a1;
}

void specialized _ArrayBuffer._consumeAndCreateNew()(unint64_t a1)
{
  if (a1 >> 62)
  {
    swift_bridgeObjectRetain();
    _CocoaArrayWrapper.endIndex.getter();
    swift_bridgeObjectRelease();
  }

  JUMPOUT(0x22A6753C0);
}

void specialized trainWork #1 (_:annotatedFeature:) in MLSoundClassifier.FeatureExtractor.extractFeatures()(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, void *a6, uint64_t a7, void *a8)
{
  uint64_t v14 = a4 + 16;
  uint64_t v15 = (void *)(a5 + 16);
  uint64_t v16 = (void *)MEMORY[0x22A675AA0]();
  closure #1 in trainWork #1 (_:annotatedFeature:) in MLSoundClassifier.FeatureExtractor.extractFeatures()(a2, a1, a3, v14, v15, a6, a7, a8);
}

uint64_t partial apply for closure #1 in closure #1 in trainWork #1 (_:annotatedFeature:) in MLSoundClassifier.FeatureExtractor.extractFeatures()(uint64_t a1)
{
  return closure #1 in closure #1 in trainWork #1 (_:annotatedFeature:) in MLSoundClassifier.FeatureExtractor.extractFeatures()(a1);
}

uint64_t OUTLINED_FUNCTION_2_34()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_4_30()
{
  return 0;
}

uint64_t OUTLINED_FUNCTION_12_13@<X0>(uint64_t a1@<X8>)
{
  *(void *)(v4 - 144) = a1;
  *(void *)(v4 - 136) = v1;
  *(void *)(v4 - 128) = v2;
  *(unsigned char *)(v4 - 120) = v3;
  return v4 - 160;
}

uint64_t OUTLINED_FUNCTION_13_20()
{
  return swift_isUniquelyReferenced_nonNull_native();
}

uint64_t MLHandPoseClassifier.ModelParameters.init(validation:batchSize:maximumIterations:augmentationOptions:algorithm:)@<X0>(uint64_t a1@<X0>, uint64_t a2@<X1>, uint64_t a3@<X2>, uint64_t *a4@<X3>, uint64_t a5@<X8>)
{
  uint64_t v8 = *a4;
  outlined init with take of MLHandPoseClassifier.ModelParameters.ValidationData(a1, a5, (void (*)(void))type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData);
  uint64_t result = OUTLINED_FUNCTION_2_35();
  *(void *)(a5 + v10) = a2;
  *(void *)(a5 + *(int *)(result + 24)) = a3;
  *(void *)(a5 + *(int *)(result + 28)) = v8;
  return result;
}

uint64_t type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData(uint64_t a1)
{
  return type metadata accessor for MLImageClassifier.CustomFeatureExtractor(a1, (uint64_t *)&type metadata singleton initialization cache for MLHandPoseClassifier.ModelParameters.ValidationData);
}

uint64_t type metadata accessor for MLHandPoseClassifier.ModelParameters(uint64_t a1)
{
  return type metadata accessor for MLImageClassifier.CustomFeatureExtractor(a1, (uint64_t *)&type metadata singleton initialization cache for MLHandPoseClassifier.ModelParameters);
}

void MLHandPoseClassifier.ModelParameters.ValidationData.extractAnnotations(trainingData:)(void *a1, void *a2)
{
  type metadata accessor for MLHandPoseClassifier.DataSource();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v6);
  uint64_t v8 = (char *)&v31 - ((v7 + 15) & 0xFFFFFFFFFFFFFFF0);
  type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData(0);
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v9);
  uint64_t v11 = (char *)&v31 - ((v10 + 15) & 0xFFFFFFFFFFFFFFF0);
  MLHandPoseClassifier.DataSource.imagesWithAnnotations()();
  if (!v3)
  {
    id v31 = a1;
    unint64_t v42 = a2;
    id v12 = v32;
    char v13 = v33;
    outlined init with copy of MLHandPoseClassifier.ModelParameters.ValidationData(v2, (uint64_t)v11);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload();
    if (EnumCaseMultiPayload)
    {
      if (EnumCaseMultiPayload == 1)
      {
        int v15 = swift_getEnumCaseMultiPayload();
        if (v15 == 5)
        {
          OUTLINED_FUNCTION_2_10();
          __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
          swift_bridgeObjectRelease();
          swift_bridgeObjectRelease();
          swift_bridgeObjectRelease();
          type metadata accessor for DataFrame();
          OUTLINED_FUNCTION_8();
          (*(void (**)(char *))(v28 + 8))(v11);
          goto LABEL_14;
        }
        if (v15 == 3)
        {
          OUTLINED_FUNCTION_2_10();
          outlined consume of Result<_DataTable, Error>(*(id *)v11, v11[8]);
          swift_bridgeObjectRelease();
          swift_bridgeObjectRelease();
          swift_bridgeObjectRelease();
LABEL_14:
          uint64_t v29 = v31;
          *id v31 = 0;
          *((unsigned char *)v29 + 8) = -1;
          uint64_t v27 = v42;
          *unint64_t v42 = 0;
          goto LABEL_15;
        }
        outlined init with take of MLHandPoseClassifier.ModelParameters.ValidationData((uint64_t)v11, (uint64_t)v8, (void (*)(void))type metadata accessor for MLHandPoseClassifier.DataSource);
        MLHandPoseClassifier.DataSource.imagesWithAnnotations()();
        outlined destroy of MLHandPoseClassifier.ModelParameters.ValidationData((uint64_t)v8, (void (*)(void))type metadata accessor for MLHandPoseClassifier.DataSource);
        uint64_t v30 = v31;
        id v20 = v32;
        char v21 = v33;
        *id v31 = v12;
        *((unsigned char *)v30 + 8) = v13;
LABEL_9:
        uint64_t v24 = v42;
        *unint64_t v42 = v20;
        *((unsigned char *)v24 + 8) = v21;
        return;
      }
      id v32 = v12;
      LOBYTE(v33) = v13;
      MLDataTable.size.getter();
      if (v25)
      {
        uint64_t v26 = v31;
        *id v31 = v12;
        *((unsigned char *)v26 + 8) = v13;
        uint64_t v27 = v42;
        *unint64_t v42 = 0;
LABEL_15:
        *((unsigned char *)v27 + 8) = -1;
        return;
      }
    }
    else
    {
      id v16 = *(id *)v11;
      uint64_t v17 = *((void *)v11 + 1);
      char v18 = v11[16];
      char v19 = v11[17];
      id v32 = v12;
      LOBYTE(v33) = v13;
      if (MLDataTable.size.getter() >= 1)
      {
        id v36 = v12;
        char v37 = v13;
        id v32 = v16;
        uint64_t v33 = v17;
        char v34 = v18;
        char v35 = v19;
        MLDataTable.randomSplitBySequence(strategy:by:on:)((uint64_t)&v40, (uint64_t)&v38, (uint64_t)&v32, (void *)0x7461506567616D69, (void *)0xE900000000000068, (void *)0x6C6562616CLL, (void *)0xE500000000000000);
        OUTLINED_FUNCTION_2_10();
        id v20 = v40;
        char v21 = v41;
        char v22 = v39;
        id v23 = v31;
        *id v31 = v38;
        *((unsigned char *)v23 + 8) = v22;
        goto LABEL_9;
      }
    }
    OUTLINED_FUNCTION_2_10();
    goto LABEL_14;
  }
}

uint64_t MLHandPoseClassifier.ModelParameters.validation.getter@<X0>(uint64_t a1@<X8>)
{
  return outlined init with copy of MLHandPoseClassifier.ModelParameters.ValidationData(v1, a1);
}

uint64_t MLHandPoseClassifier.ModelParameters.validation.setter(uint64_t a1)
{
  return outlined assign with take of MLHandPoseClassifier.ModelParameters.ValidationData(a1, v1);
}

uint64_t (*MLHandPoseClassifier.ModelParameters.validation.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLHandPoseClassifier.ModelParameters.batchSize.getter()
{
  OUTLINED_FUNCTION_2_35();
  return *(void *)(v0 + v1);
}

uint64_t MLHandPoseClassifier.ModelParameters.batchSize.setter(uint64_t a1)
{
  uint64_t result = OUTLINED_FUNCTION_2_35();
  *(void *)(v1 + v4) = a1;
  return result;
}

uint64_t (*MLHandPoseClassifier.ModelParameters.batchSize.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLHandPoseClassifier.ModelParameters.maximumIterations.getter()
{
  return *(void *)(v0 + *(int *)(type metadata accessor for MLHandPoseClassifier.ModelParameters(0) + 24));
}

uint64_t MLHandPoseClassifier.ModelParameters.maximumIterations.setter(uint64_t a1)
{
  uint64_t result = type metadata accessor for MLHandPoseClassifier.ModelParameters(0);
  *(void *)(v1 + *(int *)(result + 24)) = a1;
  return result;
}

uint64_t (*MLHandPoseClassifier.ModelParameters.maximumIterations.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLHandPoseClassifier.ModelParameters.augmentationOptions.getter@<X0>(void *a1@<X8>)
{
  uint64_t result = type metadata accessor for MLHandPoseClassifier.ModelParameters(0);
  *a1 = *(void *)(v1 + *(int *)(result + 28));
  return result;
}

uint64_t MLHandPoseClassifier.ModelParameters.augmentationOptions.setter(uint64_t *a1)
{
  uint64_t v2 = *a1;
  uint64_t result = type metadata accessor for MLHandPoseClassifier.ModelParameters(0);
  *(void *)(v1 + *(int *)(result + 28)) = v2;
  return result;
}

uint64_t (*MLHandPoseClassifier.ModelParameters.augmentationOptions.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t (*MLHandPoseClassifier.ModelParameters.algorithm.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

void MLHandPoseClassifier.ModelParameters.ModelAlgorithmType.hash(into:)()
{
}

uint64_t static MLHandPoseClassifier.ModelParameters.ModelAlgorithmType.== infix(_:_:)()
{
  return 1;
}

Swift::Int MLHandPoseClassifier.ModelParameters.ModelAlgorithmType.hashValue.getter()
{
  return Hasher._finalize()();
}

Swift::Int protocol witness for Hashable.hashValue.getter in conformance MLHandPoseClassifier.ModelParameters.ModelAlgorithmType()
{
  return MLHandPoseClassifier.ModelParameters.ModelAlgorithmType.hashValue.getter();
}

void protocol witness for Hashable.hash(into:) in conformance MLHandPoseClassifier.ModelParameters.ModelAlgorithmType()
{
}

unint64_t MLHandPoseClassifier.ModelParameters.description.getter()
{
  _StringGuts.grow(_:)(23);
  swift_bridgeObjectRelease();
  unint64_t v14 = 0xD000000000000014;
  unint64_t v15 = 0x80000002272D5920;
  uint64_t v1 = type metadata accessor for MLHandPoseClassifier.ModelParameters(0);
  v2._uint64_t countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter();
  String.append(_:)(v2);
  swift_bridgeObjectRelease();
  v3._uint64_t countAndFlagsBits = 10;
  v3._uint64_t object = (void *)0xE100000000000000;
  String.append(_:)(v3);
  strcpy((char *)&v13, "Batch Size: ");
  BYTE5(v13._object) = 0;
  HIWORD(v13._object) = -5120;
  v4._uint64_t countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter();
  String.append(_:)(v4);
  swift_bridgeObjectRelease();
  v5._uint64_t countAndFlagsBits = 10;
  v5._uint64_t object = (void *)0xE100000000000000;
  String.append(_:)(v5);
  String.append(_:)(v13);
  swift_bridgeObjectRelease();
  v13._uint64_t countAndFlagsBits = 0;
  v13._uint64_t object = (void *)0xE000000000000000;
  _StringGuts.grow(_:)(25);
  swift_bridgeObjectRelease();
  uint64_t v6 = *(void *)(v0 + *(int *)(v1 + 28));
  v13._uint64_t countAndFlagsBits = 0xD000000000000016;
  v13._uint64_t object = (void *)0x80000002272D5980;
  if (v6 == 1) {
    unint64_t v7 = 0xD000000000000011;
  }
  else {
    unint64_t v7 = 0;
  }
  if (v6 == 1) {
    unint64_t v8 = 0x80000002272D59C0;
  }
  else {
    unint64_t v8 = 0xE000000000000000;
  }
  unint64_t v9 = v8;
  String.append(_:)(*(Swift::String *)&v7);
  swift_bridgeObjectRelease();
  v10._uint64_t countAndFlagsBits = 10;
  v10._uint64_t object = (void *)0xE100000000000000;
  String.append(_:)(v10);
  String.append(_:)(v13);
  swift_bridgeObjectRelease();
  _StringGuts.grow(_:)(20);
  swift_bridgeObjectRelease();
  v11._uint64_t countAndFlagsBits = 0xD000000000000015;
  v11._uint64_t object = (void *)0x80000002272D59A0;
  String.append(_:)(v11);
  return v14;
}

uint64_t outlined init with copy of MLHandPoseClassifier.ModelParameters.ValidationData(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 16))(a2, a1, v4);
  return a2;
}

uint64_t outlined assign with take of MLHandPoseClassifier.ModelParameters.ValidationData(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 40))(a2, a1, v4);
  return a2;
}

unint64_t MLHandPoseClassifier.ModelParameters.playgroundDescription.getter@<X0>(unint64_t *a1@<X8>)
{
  unint64_t result = MLHandPoseClassifier.ModelParameters.description.getter();
  a1[3] = MEMORY[0x263F8D310];
  *a1 = result;
  a1[1] = v3;
  return result;
}

unint64_t lazy protocol witness table accessor for type MLHandPoseClassifier.ModelParameters.ModelAlgorithmType and conformance MLHandPoseClassifier.ModelParameters.ModelAlgorithmType()
{
  unint64_t result = lazy protocol witness table cache variable for type MLHandPoseClassifier.ModelParameters.ModelAlgorithmType and conformance MLHandPoseClassifier.ModelParameters.ModelAlgorithmType;
  if (!lazy protocol witness table cache variable for type MLHandPoseClassifier.ModelParameters.ModelAlgorithmType and conformance MLHandPoseClassifier.ModelParameters.ModelAlgorithmType)
  {
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type MLHandPoseClassifier.ModelParameters.ModelAlgorithmType and conformance MLHandPoseClassifier.ModelParameters.ModelAlgorithmType);
  }
  return result;
}

char *initializeBufferWithCopyOfBuffer for MLHandPoseClassifier.ModelParameters(char *a1, char **a2, int *a3)
{
  int v5 = *(_DWORD *)(*((void *)a3 - 1) + 80);
  if ((v5 & 0x20000) != 0)
  {
    char v19 = *a2;
    *(void *)a1 = *a2;
    a1 = &v19[(v5 + 16) & ~(unint64_t)v5];
    swift_retain();
  }
  else
  {
    uint64_t v7 = type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData(0);
    if (swift_getEnumCaseMultiPayload() == 1)
    {
      type metadata accessor for MLHandPoseClassifier.DataSource();
      switch(swift_getEnumCaseMultiPayload())
      {
        case 1u:
        case 2u:
          uint64_t v20 = type metadata accessor for URL();
          (*(void (**)(char *, char **, uint64_t))(*(void *)(v20 - 8) + 16))(a1, a2, v20);
          break;
        case 3u:
          char v21 = *a2;
          char v22 = *((unsigned char *)a2 + 8);
          outlined copy of Result<_DataTable, Error>(*a2, v22);
          *(void *)a1 = v21;
          a1[8] = v22;
          id v23 = a2[3];
          *((void *)a1 + 2) = a2[2];
          *((void *)a1 + 3) = v23;
          uint64_t v24 = a2[5];
          *((void *)a1 + 4) = a2[4];
          *((void *)a1 + 5) = v24;
          uint64_t v25 = a2[7];
          *((void *)a1 + 6) = a2[6];
          *((void *)a1 + 7) = v25;
          swift_bridgeObjectRetain();
          swift_bridgeObjectRetain();
          swift_bridgeObjectRetain();
          break;
        case 4u:
          uint64_t v26 = *a2;
          char v27 = *((unsigned char *)a2 + 8);
          outlined copy of Result<_DataTable, Error>(*a2, v27);
          *(void *)a1 = v26;
          a1[8] = v27;
          uint64_t v28 = a2[3];
          *((void *)a1 + 2) = a2[2];
          *((void *)a1 + 3) = v28;
          uint64_t v29 = a2[5];
          *((void *)a1 + 4) = a2[4];
          *((void *)a1 + 5) = v29;
          swift_bridgeObjectRetain();
          swift_bridgeObjectRetain();
          break;
        case 5u:
          uint64_t v30 = type metadata accessor for DataFrame();
          (*(void (**)(char *, char **, uint64_t))(*(void *)(v30 - 8) + 16))(a1, a2, v30);
          id v31 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
          uint64_t v32 = v31[12];
          uint64_t v33 = &a1[v32];
          char v34 = (uint64_t *)((char *)a2 + v32);
          uint64_t v36 = *v34;
          uint64_t v35 = v34[1];
          *(void *)uint64_t v33 = v36;
          *((void *)v33 + 1) = v35;
          uint64_t v37 = v31[16];
          uint64_t v38 = &a1[v37];
          char v39 = (char **)((char *)a2 + v37);
          uint64_t v40 = v39[1];
          *(void *)uint64_t v38 = *v39;
          *((void *)v38 + 1) = v40;
          uint64_t v41 = v31[20];
          unint64_t v42 = &a1[v41];
          uint64_t v43 = (char **)((char *)a2 + v41);
          uint64_t v44 = v43[1];
          *(void *)unint64_t v42 = *v43;
          *((void *)v42 + 1) = v44;
          swift_bridgeObjectRetain();
          swift_bridgeObjectRetain();
          swift_bridgeObjectRetain();
          break;
        case 6u:
          uint64_t v45 = type metadata accessor for DataFrame();
          (*(void (**)(char *, char **, uint64_t))(*(void *)(v45 - 8) + 16))(a1, a2, v45);
          uint64_t v46 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, labelColumn: String));
          uint64_t v47 = *(int *)(v46 + 48);
          uint64_t v48 = &a1[v47];
          uint64_t v49 = (uint64_t *)((char *)a2 + v47);
          uint64_t v51 = *v49;
          uint64_t v50 = v49[1];
          *(void *)uint64_t v48 = v51;
          *((void *)v48 + 1) = v50;
          uint64_t v52 = *(int *)(v46 + 64);
          id v53 = &a1[v52];
          uint64_t v54 = (char **)((char *)a2 + v52);
          uint64_t v55 = v54[1];
          *(void *)id v53 = *v54;
          *((void *)v53 + 1) = v55;
          swift_bridgeObjectRetain();
          swift_bridgeObjectRetain();
          break;
        default:
          uint64_t v8 = type metadata accessor for URL();
          unint64_t v9 = *(void (**)(char *, char **, uint64_t))(*(void *)(v8 - 8) + 16);
          v9(a1, a2, v8);
          Swift::String v10 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, imageColumn: String, labelColumn: String));
          v9(&a1[v10[12]], (char **)((char *)a2 + v10[12]), v8);
          uint64_t v11 = v10[16];
          id v12 = &a1[v11];
          Swift::String v13 = (char **)((char *)a2 + v11);
          uint64_t v14 = v13[1];
          *(void *)id v12 = *v13;
          *((void *)v12 + 1) = v14;
          uint64_t v15 = v10[20];
          id v16 = &a1[v15];
          uint64_t v17 = (char **)((char *)a2 + v15);
          uint64_t v18 = v17[1];
          *(void *)id v16 = *v17;
          *((void *)v16 + 1) = v18;
          swift_bridgeObjectRetain();
          swift_bridgeObjectRetain();
          break;
      }
      swift_storeEnumTagMultiPayload();
      swift_storeEnumTagMultiPayload();
    }
    else
    {
      memcpy(a1, a2, *(void *)(*(void *)(v7 - 8) + 64));
    }
    uint64_t v56 = a3[6];
    *(void *)&a1[a3[5]] = *(char **)((char *)a2 + a3[5]);
    *(void *)&a1[v56] = *(char **)((char *)a2 + v56);
    *(void *)&a1[a3[7]] = *(char **)((char *)a2 + a3[7]);
  }
  return a1;
}

uint64_t destroy for MLHandPoseClassifier.ModelParameters(uint64_t a1)
{
  type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData(0);
  uint64_t result = swift_getEnumCaseMultiPayload();
  if (result == 1)
  {
    type metadata accessor for MLHandPoseClassifier.DataSource();
    uint64_t result = swift_getEnumCaseMultiPayload();
    switch((int)result)
    {
      case 0:
        uint64_t v5 = type metadata accessor for URL();
        uint64_t v6 = *(void (**)(uint64_t, uint64_t))(*(void *)(v5 - 8) + 8);
        v6(a1, v5);
        uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, imageColumn: String, labelColumn: String));
        v6(a1 + *(int *)(v7 + 48), v5);
        swift_bridgeObjectRelease();
        goto LABEL_12;
      case 1:
      case 2:
        uint64_t v3 = type metadata accessor for URL();
        uint64_t v4 = *(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v3 - 8) + 8);
        return v4(a1, v3);
      case 3:
        outlined consume of Result<_DataTable, Error>(*(id *)a1, *(unsigned char *)(a1 + 8));
        swift_bridgeObjectRelease();
        swift_bridgeObjectRelease();
        goto LABEL_12;
      case 4:
        outlined consume of Result<_DataTable, Error>(*(id *)a1, *(unsigned char *)(a1 + 8));
        swift_bridgeObjectRelease();
        goto LABEL_12;
      case 5:
        uint64_t v8 = type metadata accessor for DataFrame();
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v8 - 8) + 8))(a1, v8);
        __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
        swift_bridgeObjectRelease();
        swift_bridgeObjectRelease();
        goto LABEL_12;
      case 6:
        uint64_t v9 = type metadata accessor for DataFrame();
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v9 - 8) + 8))(a1, v9);
        __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, labelColumn: String));
        swift_bridgeObjectRelease();
LABEL_12:
        uint64_t result = swift_bridgeObjectRelease();
        break;
      default:
        return result;
    }
  }
  return result;
}

char *initializeWithCopy for MLHandPoseClassifier.ModelParameters(char *a1, uint64_t a2, int *a3)
{
  uint64_t v6 = type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData(0);
  if (swift_getEnumCaseMultiPayload() == 1)
  {
    type metadata accessor for MLHandPoseClassifier.DataSource();
    switch(swift_getEnumCaseMultiPayload())
    {
      case 1u:
      case 2u:
        uint64_t v18 = type metadata accessor for URL();
        (*(void (**)(char *, uint64_t, uint64_t))(*(void *)(v18 - 8) + 16))(a1, a2, v18);
        break;
      case 3u:
        id v19 = *(id *)a2;
        char v20 = *(unsigned char *)(a2 + 8);
        outlined copy of Result<_DataTable, Error>(*(id *)a2, v20);
        *(void *)a1 = v19;
        a1[8] = v20;
        uint64_t v21 = *(void *)(a2 + 24);
        *((void *)a1 + 2) = *(void *)(a2 + 16);
        *((void *)a1 + 3) = v21;
        uint64_t v22 = *(void *)(a2 + 40);
        *((void *)a1 + 4) = *(void *)(a2 + 32);
        *((void *)a1 + 5) = v22;
        uint64_t v23 = *(void *)(a2 + 56);
        *((void *)a1 + 6) = *(void *)(a2 + 48);
        *((void *)a1 + 7) = v23;
        swift_bridgeObjectRetain();
        swift_bridgeObjectRetain();
        swift_bridgeObjectRetain();
        break;
      case 4u:
        id v24 = *(id *)a2;
        char v25 = *(unsigned char *)(a2 + 8);
        outlined copy of Result<_DataTable, Error>(*(id *)a2, v25);
        *(void *)a1 = v24;
        a1[8] = v25;
        uint64_t v26 = *(void *)(a2 + 24);
        *((void *)a1 + 2) = *(void *)(a2 + 16);
        *((void *)a1 + 3) = v26;
        uint64_t v27 = *(void *)(a2 + 40);
        *((void *)a1 + 4) = *(void *)(a2 + 32);
        *((void *)a1 + 5) = v27;
        swift_bridgeObjectRetain();
        swift_bridgeObjectRetain();
        break;
      case 5u:
        uint64_t v28 = type metadata accessor for DataFrame();
        (*(void (**)(char *, uint64_t, uint64_t))(*(void *)(v28 - 8) + 16))(a1, a2, v28);
        uint64_t v29 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
        uint64_t v30 = v29[12];
        id v31 = &a1[v30];
        uint64_t v32 = (uint64_t *)(a2 + v30);
        uint64_t v34 = *v32;
        uint64_t v33 = v32[1];
        *(void *)id v31 = v34;
        *((void *)v31 + 1) = v33;
        uint64_t v35 = v29[16];
        uint64_t v36 = &a1[v35];
        uint64_t v37 = (void *)(a2 + v35);
        uint64_t v38 = v37[1];
        *(void *)uint64_t v36 = *v37;
        *((void *)v36 + 1) = v38;
        uint64_t v39 = v29[20];
        uint64_t v40 = &a1[v39];
        uint64_t v41 = (void *)(a2 + v39);
        uint64_t v42 = v41[1];
        *(void *)uint64_t v40 = *v41;
        *((void *)v40 + 1) = v42;
        swift_bridgeObjectRetain();
        swift_bridgeObjectRetain();
        swift_bridgeObjectRetain();
        break;
      case 6u:
        uint64_t v43 = type metadata accessor for DataFrame();
        (*(void (**)(char *, uint64_t, uint64_t))(*(void *)(v43 - 8) + 16))(a1, a2, v43);
        uint64_t v44 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, labelColumn: String));
        uint64_t v45 = *(int *)(v44 + 48);
        uint64_t v46 = &a1[v45];
        uint64_t v47 = (uint64_t *)(a2 + v45);
        uint64_t v49 = *v47;
        uint64_t v48 = v47[1];
        *(void *)uint64_t v46 = v49;
        *((void *)v46 + 1) = v48;
        uint64_t v50 = *(int *)(v44 + 64);
        uint64_t v51 = &a1[v50];
        uint64_t v52 = (void *)(a2 + v50);
        uint64_t v53 = v52[1];
        *(void *)uint64_t v51 = *v52;
        *((void *)v51 + 1) = v53;
        swift_bridgeObjectRetain();
        swift_bridgeObjectRetain();
        break;
      default:
        uint64_t v7 = type metadata accessor for URL();
        uint64_t v8 = *(void (**)(char *, uint64_t, uint64_t))(*(void *)(v7 - 8) + 16);
        v8(a1, a2, v7);
        uint64_t v9 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, imageColumn: String, labelColumn: String));
        v8(&a1[v9[12]], a2 + v9[12], v7);
        uint64_t v10 = v9[16];
        uint64_t v11 = &a1[v10];
        id v12 = (void *)(a2 + v10);
        uint64_t v13 = v12[1];
        *(void *)uint64_t v11 = *v12;
        *((void *)v11 + 1) = v13;
        uint64_t v14 = v9[20];
        uint64_t v15 = &a1[v14];
        id v16 = (void *)(a2 + v14);
        uint64_t v17 = v16[1];
        *(void *)uint64_t v15 = *v16;
        *((void *)v15 + 1) = v17;
        swift_bridgeObjectRetain();
        swift_bridgeObjectRetain();
        break;
    }
    swift_storeEnumTagMultiPayload();
    swift_storeEnumTagMultiPayload();
  }
  else
  {
    memcpy(a1, (const void *)a2, *(void *)(*(void *)(v6 - 8) + 64));
  }
  uint64_t v54 = a3[6];
  *(void *)&a1[a3[5]] = *(void *)(a2 + a3[5]);
  *(void *)&a1[v54] = *(void *)(a2 + v54);
  *(void *)&a1[a3[7]] = *(void *)(a2 + a3[7]);
  return a1;
}

char *assignWithCopy for MLHandPoseClassifier.ModelParameters(char *a1, uint64_t a2, int *a3)
{
  if (a1 != (char *)a2)
  {
    outlined destroy of MLHandPoseClassifier.ModelParameters.ValidationData((uint64_t)a1, (void (*)(void))type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData);
    uint64_t v6 = type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData(0);
    if (swift_getEnumCaseMultiPayload() == 1)
    {
      type metadata accessor for MLHandPoseClassifier.DataSource();
      switch(swift_getEnumCaseMultiPayload())
      {
        case 1u:
        case 2u:
          uint64_t v16 = type metadata accessor for URL();
          (*(void (**)(char *, uint64_t, uint64_t))(*(void *)(v16 - 8) + 16))(a1, a2, v16);
          break;
        case 3u:
          id v17 = *(id *)a2;
          char v18 = *(unsigned char *)(a2 + 8);
          outlined copy of Result<_DataTable, Error>(*(id *)a2, v18);
          *(void *)a1 = v17;
          a1[8] = v18;
          *((void *)a1 + 2) = *(void *)(a2 + 16);
          *((void *)a1 + 3) = *(void *)(a2 + 24);
          *((void *)a1 + 4) = *(void *)(a2 + 32);
          *((void *)a1 + 5) = *(void *)(a2 + 40);
          *((void *)a1 + 6) = *(void *)(a2 + 48);
          *((void *)a1 + 7) = *(void *)(a2 + 56);
          swift_bridgeObjectRetain();
          swift_bridgeObjectRetain();
          swift_bridgeObjectRetain();
          break;
        case 4u:
          id v19 = *(id *)a2;
          char v20 = *(unsigned char *)(a2 + 8);
          outlined copy of Result<_DataTable, Error>(*(id *)a2, v20);
          *(void *)a1 = v19;
          a1[8] = v20;
          *((void *)a1 + 2) = *(void *)(a2 + 16);
          *((void *)a1 + 3) = *(void *)(a2 + 24);
          *((void *)a1 + 4) = *(void *)(a2 + 32);
          *((void *)a1 + 5) = *(void *)(a2 + 40);
          swift_bridgeObjectRetain();
          swift_bridgeObjectRetain();
          break;
        case 5u:
          uint64_t v21 = type metadata accessor for DataFrame();
          (*(void (**)(char *, uint64_t, uint64_t))(*(void *)(v21 - 8) + 16))(a1, a2, v21);
          uint64_t v22 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
          uint64_t v23 = v22[12];
          id v24 = &a1[v23];
          char v25 = (void *)(a2 + v23);
          *(void *)id v24 = *v25;
          *((void *)v24 + 1) = v25[1];
          uint64_t v26 = v22[16];
          uint64_t v27 = &a1[v26];
          uint64_t v28 = (void *)(a2 + v26);
          *(void *)uint64_t v27 = *v28;
          *((void *)v27 + 1) = v28[1];
          uint64_t v29 = v22[20];
          uint64_t v30 = &a1[v29];
          id v31 = (void *)(a2 + v29);
          *(void *)uint64_t v30 = *v31;
          *((void *)v30 + 1) = v31[1];
          swift_bridgeObjectRetain();
          swift_bridgeObjectRetain();
          swift_bridgeObjectRetain();
          break;
        case 6u:
          uint64_t v32 = type metadata accessor for DataFrame();
          (*(void (**)(char *, uint64_t, uint64_t))(*(void *)(v32 - 8) + 16))(a1, a2, v32);
          uint64_t v33 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, labelColumn: String));
          uint64_t v34 = *(int *)(v33 + 48);
          uint64_t v35 = &a1[v34];
          uint64_t v36 = (void *)(a2 + v34);
          *(void *)uint64_t v35 = *v36;
          *((void *)v35 + 1) = v36[1];
          uint64_t v37 = *(int *)(v33 + 64);
          uint64_t v38 = &a1[v37];
          uint64_t v39 = (void *)(a2 + v37);
          *(void *)uint64_t v38 = *v39;
          *((void *)v38 + 1) = v39[1];
          swift_bridgeObjectRetain();
          swift_bridgeObjectRetain();
          break;
        default:
          uint64_t v7 = type metadata accessor for URL();
          uint64_t v8 = *(void (**)(char *, uint64_t, uint64_t))(*(void *)(v7 - 8) + 16);
          v8(a1, a2, v7);
          uint64_t v9 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, imageColumn: String, labelColumn: String));
          v8(&a1[v9[12]], a2 + v9[12], v7);
          uint64_t v10 = v9[16];
          uint64_t v11 = &a1[v10];
          id v12 = (void *)(a2 + v10);
          *(void *)uint64_t v11 = *v12;
          *((void *)v11 + 1) = v12[1];
          uint64_t v13 = v9[20];
          uint64_t v14 = &a1[v13];
          uint64_t v15 = (void *)(a2 + v13);
          *(void *)uint64_t v14 = *v15;
          *((void *)v14 + 1) = v15[1];
          swift_bridgeObjectRetain();
          swift_bridgeObjectRetain();
          break;
      }
      swift_storeEnumTagMultiPayload();
      swift_storeEnumTagMultiPayload();
    }
    else
    {
      memcpy(a1, (const void *)a2, *(void *)(*(void *)(v6 - 8) + 64));
    }
  }
  *(void *)&a1[a3[5]] = *(void *)(a2 + a3[5]);
  *(void *)&a1[a3[6]] = *(void *)(a2 + a3[6]);
  *(void *)&a1[a3[7]] = *(void *)(a2 + a3[7]);
  return a1;
}

char *initializeWithTake for MLHandPoseClassifier.ModelParameters(char *a1, char *a2, int *a3)
{
  uint64_t v6 = type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData(0);
  if (swift_getEnumCaseMultiPayload() == 1)
  {
    uint64_t v7 = type metadata accessor for MLHandPoseClassifier.DataSource();
    switch(swift_getEnumCaseMultiPayload())
    {
      case 0u:
        uint64_t v8 = type metadata accessor for URL();
        uint64_t v9 = *(void (**)(char *, char *, uint64_t))(*(void *)(v8 - 8) + 32);
        v9(a1, a2, v8);
        uint64_t v10 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, imageColumn: String, labelColumn: String));
        v9(&a1[v10[12]], &a2[v10[12]], v8);
        *(_OWORD *)&a1[v10[16]] = *(_OWORD *)&a2[v10[16]];
        *(_OWORD *)&a1[v10[20]] = *(_OWORD *)&a2[v10[20]];
        goto LABEL_9;
      case 1u:
      case 2u:
        uint64_t v11 = type metadata accessor for URL();
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v11 - 8) + 32))(a1, a2, v11);
        goto LABEL_9;
      case 5u:
        uint64_t v12 = type metadata accessor for DataFrame();
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 32))(a1, a2, v12);
        uint64_t v13 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
        *(_OWORD *)&a1[v13[12]] = *(_OWORD *)&a2[v13[12]];
        *(_OWORD *)&a1[v13[16]] = *(_OWORD *)&a2[v13[16]];
        *(_OWORD *)&a1[v13[20]] = *(_OWORD *)&a2[v13[20]];
        goto LABEL_9;
      case 6u:
        uint64_t v14 = type metadata accessor for DataFrame();
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v14 - 8) + 32))(a1, a2, v14);
        uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, labelColumn: String));
        *(_OWORD *)&a1[*(int *)(v15 + 48)] = *(_OWORD *)&a2[*(int *)(v15 + 48)];
        *(_OWORD *)&a1[*(int *)(v15 + 64)] = *(_OWORD *)&a2[*(int *)(v15 + 64)];
LABEL_9:
        swift_storeEnumTagMultiPayload();
        break;
      default:
        memcpy(a1, a2, *(void *)(*(void *)(v7 - 8) + 64));
        break;
    }
    swift_storeEnumTagMultiPayload();
  }
  else
  {
    memcpy(a1, a2, *(void *)(*(void *)(v6 - 8) + 64));
  }
  uint64_t v16 = a3[6];
  *(void *)&a1[a3[5]] = *(void *)&a2[a3[5]];
  *(void *)&a1[v16] = *(void *)&a2[v16];
  *(void *)&a1[a3[7]] = *(void *)&a2[a3[7]];
  return a1;
}

char *assignWithTake for MLHandPoseClassifier.ModelParameters(char *a1, char *a2, int *a3)
{
  if (a1 != a2)
  {
    outlined destroy of MLHandPoseClassifier.ModelParameters.ValidationData((uint64_t)a1, (void (*)(void))type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData);
    uint64_t v6 = type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData(0);
    if (swift_getEnumCaseMultiPayload() == 1)
    {
      uint64_t v7 = type metadata accessor for MLHandPoseClassifier.DataSource();
      switch(swift_getEnumCaseMultiPayload())
      {
        case 0u:
          uint64_t v8 = type metadata accessor for URL();
          uint64_t v9 = *(void (**)(char *, char *, uint64_t))(*(void *)(v8 - 8) + 32);
          v9(a1, a2, v8);
          uint64_t v10 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, imageColumn: String, labelColumn: String));
          v9(&a1[v10[12]], &a2[v10[12]], v8);
          *(_OWORD *)&a1[v10[16]] = *(_OWORD *)&a2[v10[16]];
          *(_OWORD *)&a1[v10[20]] = *(_OWORD *)&a2[v10[20]];
          goto LABEL_10;
        case 1u:
        case 2u:
          uint64_t v11 = type metadata accessor for URL();
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v11 - 8) + 32))(a1, a2, v11);
          goto LABEL_10;
        case 5u:
          uint64_t v12 = type metadata accessor for DataFrame();
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 32))(a1, a2, v12);
          uint64_t v13 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
          *(_OWORD *)&a1[v13[12]] = *(_OWORD *)&a2[v13[12]];
          *(_OWORD *)&a1[v13[16]] = *(_OWORD *)&a2[v13[16]];
          *(_OWORD *)&a1[v13[20]] = *(_OWORD *)&a2[v13[20]];
          goto LABEL_10;
        case 6u:
          uint64_t v14 = type metadata accessor for DataFrame();
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v14 - 8) + 32))(a1, a2, v14);
          uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, labelColumn: String));
          *(_OWORD *)&a1[*(int *)(v15 + 48)] = *(_OWORD *)&a2[*(int *)(v15 + 48)];
          *(_OWORD *)&a1[*(int *)(v15 + 64)] = *(_OWORD *)&a2[*(int *)(v15 + 64)];
LABEL_10:
          swift_storeEnumTagMultiPayload();
          break;
        default:
          memcpy(a1, a2, *(void *)(*(void *)(v7 - 8) + 64));
          break;
      }
      swift_storeEnumTagMultiPayload();
    }
    else
    {
      memcpy(a1, a2, *(void *)(*(void *)(v6 - 8) + 64));
    }
  }
  uint64_t v16 = a3[6];
  *(void *)&a1[a3[5]] = *(void *)&a2[a3[5]];
  *(void *)&a1[v16] = *(void *)&a2[v16];
  *(void *)&a1[a3[7]] = *(void *)&a2[a3[7]];
  return a1;
}

uint64_t getEnumTagSinglePayload for MLHandPoseClassifier.ModelParameters(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return MEMORY[0x270FA0340](a1, a2, a3, sub_227132194);
}

uint64_t sub_227132194(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData(0);

  return __swift_getEnumTagSinglePayload(a1, a2, v4);
}

uint64_t storeEnumTagSinglePayload for MLHandPoseClassifier.ModelParameters(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return MEMORY[0x270FA0580](a1, a2, a3, a4, sub_2271321F0);
}

uint64_t sub_2271321F0(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData(0);

  return __swift_storeEnumTagSinglePayload(a1, a2, a2, v4);
}

uint64_t type metadata completion function for MLHandPoseClassifier.ModelParameters()
{
  uint64_t result = type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData(319);
  if (v1 <= 0x3F)
  {
    swift_initStructMetadata();
    return 0;
  }
  return result;
}

unsigned char *storeEnumTagSinglePayload for MLHandPoseClassifier.ModelParameters.ModelAlgorithmType(unsigned char *result, int a2, int a3)
{
  if ((a3 + 1) >= 0x10000) {
    int v3 = 4;
  }
  else {
    int v3 = 2;
  }
  if ((a3 + 1) < 0x100) {
    unsigned int v4 = 1;
  }
  else {
    unsigned int v4 = v3;
  }
  if (a3) {
    uint64_t v5 = v4;
  }
  else {
    uint64_t v5 = 0;
  }
  if (a2)
  {
    switch(v5)
    {
      case 1:
        *uint64_t result = a2;
        return result;
      case 2:
        *(_WORD *)uint64_t result = a2;
        return result;
      case 3:
        goto LABEL_19;
      case 4:
        *(_DWORD *)uint64_t result = a2;
        return result;
      default:
        return result;
    }
  }
  switch(v5)
  {
    case 1:
      *uint64_t result = 0;
      break;
    case 2:
      *(_WORD *)uint64_t result = 0;
      break;
    case 3:
LABEL_19:
      __break(1u);
      JUMPOUT(0x227132384);
    case 4:
      *(_DWORD *)uint64_t result = 0;
      break;
    default:
      return result;
  }
  return result;
}

ValueMetadata *type metadata accessor for MLHandPoseClassifier.ModelParameters.ModelAlgorithmType()
{
  return &type metadata for MLHandPoseClassifier.ModelParameters.ModelAlgorithmType;
}

char *initializeBufferWithCopyOfBuffer for MLHandPoseClassifier.ModelParameters.ValidationData(char *a1, char **a2, uint64_t a3)
{
  int v5 = *(_DWORD *)(*(void *)(a3 - 8) + 80);
  if ((v5 & 0x20000) != 0)
  {
    char v18 = *a2;
    *(void *)a1 = *a2;
    a1 = &v18[(v5 + 16) & ~(unint64_t)v5];
    swift_retain();
  }
  else
  {
    uint64_t v6 = *(void *)(a3 - 8);
    if (swift_getEnumCaseMultiPayload() == 1)
    {
      type metadata accessor for MLHandPoseClassifier.DataSource();
      switch(swift_getEnumCaseMultiPayload())
      {
        case 1u:
        case 2u:
          uint64_t v19 = type metadata accessor for URL();
          (*(void (**)(char *, char **, uint64_t))(*(void *)(v19 - 8) + 16))(a1, a2, v19);
          break;
        case 3u:
          char v20 = *a2;
          char v21 = *((unsigned char *)a2 + 8);
          outlined copy of Result<_DataTable, Error>(*a2, v21);
          *(void *)a1 = v20;
          a1[8] = v21;
          uint64_t v22 = a2[3];
          *((void *)a1 + 2) = a2[2];
          *((void *)a1 + 3) = v22;
          uint64_t v23 = a2[5];
          *((void *)a1 + 4) = a2[4];
          *((void *)a1 + 5) = v23;
          id v24 = a2[6];
          char v25 = a2[7];
          *((void *)a1 + 6) = v24;
          *((void *)a1 + 7) = v25;
          swift_bridgeObjectRetain();
          swift_bridgeObjectRetain();
          swift_bridgeObjectRetain();
          break;
        case 4u:
          uint64_t v26 = *a2;
          char v27 = *((unsigned char *)a2 + 8);
          outlined copy of Result<_DataTable, Error>(*a2, v27);
          *(void *)a1 = v26;
          a1[8] = v27;
          uint64_t v28 = a2[3];
          *((void *)a1 + 2) = a2[2];
          *((void *)a1 + 3) = v28;
          uint64_t v29 = a2[4];
          uint64_t v30 = a2[5];
          *((void *)a1 + 4) = v29;
          *((void *)a1 + 5) = v30;
          swift_bridgeObjectRetain();
          swift_bridgeObjectRetain();
          break;
        case 5u:
          uint64_t v31 = type metadata accessor for DataFrame();
          (*(void (**)(char *, char **, uint64_t))(*(void *)(v31 - 8) + 16))(a1, a2, v31);
          uint64_t v32 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
          uint64_t v33 = v32[12];
          uint64_t v34 = &a1[v33];
          uint64_t v35 = (uint64_t *)((char *)a2 + v33);
          uint64_t v37 = *v35;
          uint64_t v36 = v35[1];
          *(void *)uint64_t v34 = v37;
          *((void *)v34 + 1) = v36;
          uint64_t v38 = v32[16];
          uint64_t v39 = &a1[v38];
          uint64_t v40 = (char **)((char *)a2 + v38);
          uint64_t v41 = v40[1];
          *(void *)uint64_t v39 = *v40;
          *((void *)v39 + 1) = v41;
          uint64_t v42 = v32[20];
          uint64_t v43 = &a1[v42];
          uint64_t v44 = (char **)((char *)a2 + v42);
          uint64_t v45 = v44[1];
          *(void *)uint64_t v43 = *v44;
          *((void *)v43 + 1) = v45;
          swift_bridgeObjectRetain();
          swift_bridgeObjectRetain();
          swift_bridgeObjectRetain();
          break;
        case 6u:
          uint64_t v46 = type metadata accessor for DataFrame();
          (*(void (**)(char *, char **, uint64_t))(*(void *)(v46 - 8) + 16))(a1, a2, v46);
          uint64_t v47 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, labelColumn: String));
          uint64_t v48 = *(int *)(v47 + 48);
          uint64_t v49 = &a1[v48];
          uint64_t v50 = (uint64_t *)((char *)a2 + v48);
          uint64_t v52 = *v50;
          uint64_t v51 = v50[1];
          *(void *)uint64_t v49 = v52;
          *((void *)v49 + 1) = v51;
          uint64_t v53 = *(int *)(v47 + 64);
          uint64_t v54 = &a1[v53];
          uint64_t v55 = (char **)((char *)a2 + v53);
          uint64_t v56 = v55[1];
          *(void *)uint64_t v54 = *v55;
          *((void *)v54 + 1) = v56;
          swift_bridgeObjectRetain();
          swift_bridgeObjectRetain();
          break;
        default:
          uint64_t v7 = type metadata accessor for URL();
          uint64_t v8 = *(void (**)(char *, char **, uint64_t))(*(void *)(v7 - 8) + 16);
          v8(a1, a2, v7);
          uint64_t v9 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, imageColumn: String, labelColumn: String));
          v8(&a1[v9[12]], (char **)((char *)a2 + v9[12]), v7);
          uint64_t v10 = v9[16];
          uint64_t v11 = &a1[v10];
          uint64_t v12 = (char **)((char *)a2 + v10);
          uint64_t v13 = v12[1];
          *(void *)uint64_t v11 = *v12;
          *((void *)v11 + 1) = v13;
          uint64_t v14 = v9[20];
          uint64_t v15 = &a1[v14];
          uint64_t v16 = (char **)((char *)a2 + v14);
          uint64_t v17 = v16[1];
          *(void *)uint64_t v15 = *v16;
          *((void *)v15 + 1) = v17;
          swift_bridgeObjectRetain();
          swift_bridgeObjectRetain();
          break;
      }
      swift_storeEnumTagMultiPayload();
      swift_storeEnumTagMultiPayload();
    }
    else
    {
      memcpy(a1, a2, *(void *)(v6 + 64));
    }
  }
  return a1;
}

uint64_t destroy for MLHandPoseClassifier.ModelParameters.ValidationData(uint64_t a1)
{
  uint64_t result = swift_getEnumCaseMultiPayload();
  if (result == 1)
  {
    type metadata accessor for MLHandPoseClassifier.DataSource();
    uint64_t result = swift_getEnumCaseMultiPayload();
    switch((int)result)
    {
      case 0:
        uint64_t v5 = type metadata accessor for URL();
        uint64_t v6 = *(void (**)(uint64_t, uint64_t))(*(void *)(v5 - 8) + 8);
        v6(a1, v5);
        uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, imageColumn: String, labelColumn: String));
        v6(a1 + *(int *)(v7 + 48), v5);
        swift_bridgeObjectRelease();
        goto LABEL_12;
      case 1:
      case 2:
        uint64_t v3 = type metadata accessor for URL();
        unsigned int v4 = *(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v3 - 8) + 8);
        return v4(a1, v3);
      case 3:
        outlined consume of Result<_DataTable, Error>(*(id *)a1, *(unsigned char *)(a1 + 8));
        swift_bridgeObjectRelease();
        swift_bridgeObjectRelease();
        goto LABEL_12;
      case 4:
        outlined consume of Result<_DataTable, Error>(*(id *)a1, *(unsigned char *)(a1 + 8));
        swift_bridgeObjectRelease();
        goto LABEL_12;
      case 5:
        uint64_t v8 = type metadata accessor for DataFrame();
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v8 - 8) + 8))(a1, v8);
        __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
        swift_bridgeObjectRelease();
        swift_bridgeObjectRelease();
        goto LABEL_12;
      case 6:
        uint64_t v9 = type metadata accessor for DataFrame();
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v9 - 8) + 8))(a1, v9);
        __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, labelColumn: String));
        swift_bridgeObjectRelease();
LABEL_12:
        uint64_t result = swift_bridgeObjectRelease();
        break;
      default:
        return result;
    }
  }
  return result;
}

char *initializeWithCopy for MLHandPoseClassifier.ModelParameters.ValidationData(char *a1, uint64_t a2, uint64_t a3)
{
  if (swift_getEnumCaseMultiPayload() == 1)
  {
    type metadata accessor for MLHandPoseClassifier.DataSource();
    switch(swift_getEnumCaseMultiPayload())
    {
      case 1u:
      case 2u:
        uint64_t v17 = type metadata accessor for URL();
        (*(void (**)(char *, uint64_t, uint64_t))(*(void *)(v17 - 8) + 16))(a1, a2, v17);
        break;
      case 3u:
        id v18 = *(id *)a2;
        char v19 = *(unsigned char *)(a2 + 8);
        outlined copy of Result<_DataTable, Error>(*(id *)a2, v19);
        *(void *)a1 = v18;
        a1[8] = v19;
        uint64_t v20 = *(void *)(a2 + 24);
        *((void *)a1 + 2) = *(void *)(a2 + 16);
        *((void *)a1 + 3) = v20;
        uint64_t v21 = *(void *)(a2 + 40);
        *((void *)a1 + 4) = *(void *)(a2 + 32);
        *((void *)a1 + 5) = v21;
        uint64_t v22 = *(void *)(a2 + 48);
        uint64_t v23 = *(void *)(a2 + 56);
        *((void *)a1 + 6) = v22;
        *((void *)a1 + 7) = v23;
        swift_bridgeObjectRetain();
        swift_bridgeObjectRetain();
        swift_bridgeObjectRetain();
        break;
      case 4u:
        id v24 = *(id *)a2;
        char v25 = *(unsigned char *)(a2 + 8);
        outlined copy of Result<_DataTable, Error>(*(id *)a2, v25);
        *(void *)a1 = v24;
        a1[8] = v25;
        uint64_t v26 = *(void *)(a2 + 24);
        *((void *)a1 + 2) = *(void *)(a2 + 16);
        *((void *)a1 + 3) = v26;
        uint64_t v27 = *(void *)(a2 + 32);
        uint64_t v28 = *(void *)(a2 + 40);
        *((void *)a1 + 4) = v27;
        *((void *)a1 + 5) = v28;
        swift_bridgeObjectRetain();
        swift_bridgeObjectRetain();
        break;
      case 5u:
        uint64_t v29 = type metadata accessor for DataFrame();
        (*(void (**)(char *, uint64_t, uint64_t))(*(void *)(v29 - 8) + 16))(a1, a2, v29);
        uint64_t v30 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
        uint64_t v31 = v30[12];
        uint64_t v32 = &a1[v31];
        uint64_t v33 = (uint64_t *)(a2 + v31);
        uint64_t v35 = *v33;
        uint64_t v34 = v33[1];
        *(void *)uint64_t v32 = v35;
        *((void *)v32 + 1) = v34;
        uint64_t v36 = v30[16];
        uint64_t v37 = &a1[v36];
        uint64_t v38 = (void *)(a2 + v36);
        uint64_t v39 = v38[1];
        *(void *)uint64_t v37 = *v38;
        *((void *)v37 + 1) = v39;
        uint64_t v40 = v30[20];
        uint64_t v41 = &a1[v40];
        uint64_t v42 = (void *)(a2 + v40);
        uint64_t v43 = v42[1];
        *(void *)uint64_t v41 = *v42;
        *((void *)v41 + 1) = v43;
        swift_bridgeObjectRetain();
        swift_bridgeObjectRetain();
        swift_bridgeObjectRetain();
        break;
      case 6u:
        uint64_t v44 = type metadata accessor for DataFrame();
        (*(void (**)(char *, uint64_t, uint64_t))(*(void *)(v44 - 8) + 16))(a1, a2, v44);
        uint64_t v45 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, labelColumn: String));
        uint64_t v46 = *(int *)(v45 + 48);
        uint64_t v47 = &a1[v46];
        uint64_t v48 = (uint64_t *)(a2 + v46);
        uint64_t v50 = *v48;
        uint64_t v49 = v48[1];
        *(void *)uint64_t v47 = v50;
        *((void *)v47 + 1) = v49;
        uint64_t v51 = *(int *)(v45 + 64);
        uint64_t v52 = &a1[v51];
        uint64_t v53 = (void *)(a2 + v51);
        uint64_t v54 = v53[1];
        *(void *)uint64_t v52 = *v53;
        *((void *)v52 + 1) = v54;
        swift_bridgeObjectRetain();
        swift_bridgeObjectRetain();
        break;
      default:
        uint64_t v6 = type metadata accessor for URL();
        uint64_t v7 = *(void (**)(char *, uint64_t, uint64_t))(*(void *)(v6 - 8) + 16);
        v7(a1, a2, v6);
        uint64_t v8 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, imageColumn: String, labelColumn: String));
        v7(&a1[v8[12]], a2 + v8[12], v6);
        uint64_t v9 = v8[16];
        uint64_t v10 = &a1[v9];
        uint64_t v11 = (void *)(a2 + v9);
        uint64_t v12 = v11[1];
        *(void *)uint64_t v10 = *v11;
        *((void *)v10 + 1) = v12;
        uint64_t v13 = v8[20];
        uint64_t v14 = &a1[v13];
        uint64_t v15 = (void *)(a2 + v13);
        uint64_t v16 = v15[1];
        *(void *)uint64_t v14 = *v15;
        *((void *)v14 + 1) = v16;
        swift_bridgeObjectRetain();
        swift_bridgeObjectRetain();
        break;
    }
    swift_storeEnumTagMultiPayload();
    swift_storeEnumTagMultiPayload();
  }
  else
  {
    memcpy(a1, (const void *)a2, *(void *)(*(void *)(a3 - 8) + 64));
  }
  return a1;
}

char *assignWithCopy for MLHandPoseClassifier.ModelParameters.ValidationData(char *a1, uint64_t a2, uint64_t a3)
{
  if (a1 != (char *)a2)
  {
    outlined destroy of MLHandPoseClassifier.ModelParameters.ValidationData((uint64_t)a1, (void (*)(void))type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData);
    if (swift_getEnumCaseMultiPayload() == 1)
    {
      type metadata accessor for MLHandPoseClassifier.DataSource();
      switch(swift_getEnumCaseMultiPayload())
      {
        case 1u:
        case 2u:
          uint64_t v15 = type metadata accessor for URL();
          (*(void (**)(char *, uint64_t, uint64_t))(*(void *)(v15 - 8) + 16))(a1, a2, v15);
          break;
        case 3u:
          id v16 = *(id *)a2;
          char v17 = *(unsigned char *)(a2 + 8);
          outlined copy of Result<_DataTable, Error>(*(id *)a2, v17);
          *(void *)a1 = v16;
          a1[8] = v17;
          *((void *)a1 + 2) = *(void *)(a2 + 16);
          *((void *)a1 + 3) = *(void *)(a2 + 24);
          *((void *)a1 + 4) = *(void *)(a2 + 32);
          *((void *)a1 + 5) = *(void *)(a2 + 40);
          *((void *)a1 + 6) = *(void *)(a2 + 48);
          *((void *)a1 + 7) = *(void *)(a2 + 56);
          swift_bridgeObjectRetain();
          swift_bridgeObjectRetain();
          swift_bridgeObjectRetain();
          break;
        case 4u:
          id v18 = *(id *)a2;
          char v19 = *(unsigned char *)(a2 + 8);
          outlined copy of Result<_DataTable, Error>(*(id *)a2, v19);
          *(void *)a1 = v18;
          a1[8] = v19;
          *((void *)a1 + 2) = *(void *)(a2 + 16);
          *((void *)a1 + 3) = *(void *)(a2 + 24);
          *((void *)a1 + 4) = *(void *)(a2 + 32);
          *((void *)a1 + 5) = *(void *)(a2 + 40);
          swift_bridgeObjectRetain();
          swift_bridgeObjectRetain();
          break;
        case 5u:
          uint64_t v20 = type metadata accessor for DataFrame();
          (*(void (**)(char *, uint64_t, uint64_t))(*(void *)(v20 - 8) + 16))(a1, a2, v20);
          uint64_t v21 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
          uint64_t v22 = v21[12];
          uint64_t v23 = &a1[v22];
          id v24 = (void *)(a2 + v22);
          *(void *)uint64_t v23 = *v24;
          *((void *)v23 + 1) = v24[1];
          uint64_t v25 = v21[16];
          uint64_t v26 = &a1[v25];
          uint64_t v27 = (void *)(a2 + v25);
          *(void *)uint64_t v26 = *v27;
          *((void *)v26 + 1) = v27[1];
          uint64_t v28 = v21[20];
          uint64_t v29 = &a1[v28];
          uint64_t v30 = (void *)(a2 + v28);
          *(void *)uint64_t v29 = *v30;
          *((void *)v29 + 1) = v30[1];
          swift_bridgeObjectRetain();
          swift_bridgeObjectRetain();
          swift_bridgeObjectRetain();
          break;
        case 6u:
          uint64_t v31 = type metadata accessor for DataFrame();
          (*(void (**)(char *, uint64_t, uint64_t))(*(void *)(v31 - 8) + 16))(a1, a2, v31);
          uint64_t v32 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, labelColumn: String));
          uint64_t v33 = *(int *)(v32 + 48);
          uint64_t v34 = &a1[v33];
          uint64_t v35 = (void *)(a2 + v33);
          *(void *)uint64_t v34 = *v35;
          *((void *)v34 + 1) = v35[1];
          uint64_t v36 = *(int *)(v32 + 64);
          uint64_t v37 = &a1[v36];
          uint64_t v38 = (void *)(a2 + v36);
          *(void *)uint64_t v37 = *v38;
          *((void *)v37 + 1) = v38[1];
          swift_bridgeObjectRetain();
          swift_bridgeObjectRetain();
          break;
        default:
          uint64_t v6 = type metadata accessor for URL();
          uint64_t v7 = *(void (**)(char *, uint64_t, uint64_t))(*(void *)(v6 - 8) + 16);
          v7(a1, a2, v6);
          uint64_t v8 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, imageColumn: String, labelColumn: String));
          v7(&a1[v8[12]], a2 + v8[12], v6);
          uint64_t v9 = v8[16];
          uint64_t v10 = &a1[v9];
          uint64_t v11 = (void *)(a2 + v9);
          *(void *)uint64_t v10 = *v11;
          *((void *)v10 + 1) = v11[1];
          uint64_t v12 = v8[20];
          uint64_t v13 = &a1[v12];
          uint64_t v14 = (void *)(a2 + v12);
          *(void *)uint64_t v13 = *v14;
          *((void *)v13 + 1) = v14[1];
          swift_bridgeObjectRetain();
          swift_bridgeObjectRetain();
          break;
      }
      swift_storeEnumTagMultiPayload();
      swift_storeEnumTagMultiPayload();
    }
    else
    {
      memcpy(a1, (const void *)a2, *(void *)(*(void *)(a3 - 8) + 64));
    }
  }
  return a1;
}

char *initializeWithTake for MLHandPoseClassifier.ModelParameters.ValidationData(char *a1, char *a2, uint64_t a3)
{
  if (swift_getEnumCaseMultiPayload() == 1)
  {
    uint64_t v6 = type metadata accessor for MLHandPoseClassifier.DataSource();
    switch(swift_getEnumCaseMultiPayload())
    {
      case 0u:
        uint64_t v7 = type metadata accessor for URL();
        uint64_t v8 = *(void (**)(char *, char *, uint64_t))(*(void *)(v7 - 8) + 32);
        v8(a1, a2, v7);
        uint64_t v9 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, imageColumn: String, labelColumn: String));
        v8(&a1[v9[12]], &a2[v9[12]], v7);
        *(_OWORD *)&a1[v9[16]] = *(_OWORD *)&a2[v9[16]];
        *(_OWORD *)&a1[v9[20]] = *(_OWORD *)&a2[v9[20]];
        goto LABEL_9;
      case 1u:
      case 2u:
        uint64_t v10 = type metadata accessor for URL();
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v10 - 8) + 32))(a1, a2, v10);
        goto LABEL_9;
      case 5u:
        uint64_t v11 = type metadata accessor for DataFrame();
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v11 - 8) + 32))(a1, a2, v11);
        uint64_t v12 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
        *(_OWORD *)&a1[v12[12]] = *(_OWORD *)&a2[v12[12]];
        *(_OWORD *)&a1[v12[16]] = *(_OWORD *)&a2[v12[16]];
        *(_OWORD *)&a1[v12[20]] = *(_OWORD *)&a2[v12[20]];
        goto LABEL_9;
      case 6u:
        uint64_t v13 = type metadata accessor for DataFrame();
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v13 - 8) + 32))(a1, a2, v13);
        uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, labelColumn: String));
        *(_OWORD *)&a1[*(int *)(v14 + 48)] = *(_OWORD *)&a2[*(int *)(v14 + 48)];
        *(_OWORD *)&a1[*(int *)(v14 + 64)] = *(_OWORD *)&a2[*(int *)(v14 + 64)];
LABEL_9:
        swift_storeEnumTagMultiPayload();
        break;
      default:
        memcpy(a1, a2, *(void *)(*(void *)(v6 - 8) + 64));
        break;
    }
    swift_storeEnumTagMultiPayload();
  }
  else
  {
    memcpy(a1, a2, *(void *)(*(void *)(a3 - 8) + 64));
  }
  return a1;
}

char *assignWithTake for MLHandPoseClassifier.ModelParameters.ValidationData(char *a1, char *a2, uint64_t a3)
{
  if (a1 != a2)
  {
    outlined destroy of MLHandPoseClassifier.ModelParameters.ValidationData((uint64_t)a1, (void (*)(void))type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData);
    if (swift_getEnumCaseMultiPayload() == 1)
    {
      uint64_t v6 = type metadata accessor for MLHandPoseClassifier.DataSource();
      switch(swift_getEnumCaseMultiPayload())
      {
        case 0u:
          uint64_t v7 = type metadata accessor for URL();
          uint64_t v8 = *(void (**)(char *, char *, uint64_t))(*(void *)(v7 - 8) + 32);
          v8(a1, a2, v7);
          uint64_t v9 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, imageColumn: String, labelColumn: String));
          v8(&a1[v9[12]], &a2[v9[12]], v7);
          *(_OWORD *)&a1[v9[16]] = *(_OWORD *)&a2[v9[16]];
          *(_OWORD *)&a1[v9[20]] = *(_OWORD *)&a2[v9[20]];
          goto LABEL_10;
        case 1u:
        case 2u:
          uint64_t v10 = type metadata accessor for URL();
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v10 - 8) + 32))(a1, a2, v10);
          goto LABEL_10;
        case 5u:
          uint64_t v11 = type metadata accessor for DataFrame();
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v11 - 8) + 32))(a1, a2, v11);
          uint64_t v12 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
          *(_OWORD *)&a1[v12[12]] = *(_OWORD *)&a2[v12[12]];
          *(_OWORD *)&a1[v12[16]] = *(_OWORD *)&a2[v12[16]];
          *(_OWORD *)&a1[v12[20]] = *(_OWORD *)&a2[v12[20]];
          goto LABEL_10;
        case 6u:
          uint64_t v13 = type metadata accessor for DataFrame();
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v13 - 8) + 32))(a1, a2, v13);
          uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, labelColumn: String));
          *(_OWORD *)&a1[*(int *)(v14 + 48)] = *(_OWORD *)&a2[*(int *)(v14 + 48)];
          *(_OWORD *)&a1[*(int *)(v14 + 64)] = *(_OWORD *)&a2[*(int *)(v14 + 64)];
LABEL_10:
          swift_storeEnumTagMultiPayload();
          break;
        default:
          memcpy(a1, a2, *(void *)(*(void *)(v6 - 8) + 64));
          break;
      }
      swift_storeEnumTagMultiPayload();
    }
    else
    {
      memcpy(a1, a2, *(void *)(*(void *)(a3 - 8) + 64));
    }
  }
  return a1;
}

uint64_t type metadata completion function for MLHandPoseClassifier.ModelParameters.ValidationData()
{
  uint64_t result = type metadata accessor for MLHandPoseClassifier.DataSource();
  if (v1 <= 0x3F)
  {
    swift_initEnumMetadataMultiPayload();
    return 0;
  }
  return result;
}

uint64_t outlined init with take of MLHandPoseClassifier.ModelParameters.ValidationData(uint64_t a1, uint64_t a2, void (*a3)(void))
{
  a3(0);
  OUTLINED_FUNCTION_8();
  (*(void (**)(uint64_t, uint64_t))(v5 + 32))(a2, a1);
  return a2;
}

uint64_t outlined destroy of MLHandPoseClassifier.ModelParameters.ValidationData(uint64_t a1, void (*a2)(void))
{
  a2(0);
  OUTLINED_FUNCTION_8();
  (*(void (**)(uint64_t))(v3 + 8))(a1);
  return a1;
}

uint64_t OUTLINED_FUNCTION_2_35()
{
  return type metadata accessor for MLHandPoseClassifier.ModelParameters(0);
}

uint64_t MLTrainingSessionParameters.init(sessionDirectory:reportInterval:checkpointInterval:iterations:)@<X0>(uint64_t a1@<X0>, uint64_t a2@<X1>, uint64_t a3@<X2>, uint64_t a4@<X3>, uint64_t a5@<X8>)
{
  uint64_t v10 = (int *)type metadata accessor for MLTrainingSessionParameters();
  uint64_t v11 = v10[5];
  *(void *)(a5 + v11) = 5;
  uint64_t v12 = v10[6];
  *(void *)(a5 + v12) = 10;
  uint64_t v13 = v10[7];
  *(void *)(a5 + v13) = 1000;
  outlined init with copy of URL?(a1, a5);
  if (a3 < a2) {
    a2 = a3;
  }
  uint64_t result = _s10Foundation3URLVSgWOhTm_0(a1, &demangling cache variable for type metadata for URL?);
  *(void *)(a5 + v11) = a2;
  *(void *)(a5 + v12) = a3;
  *(void *)(a5 + v13) = a4;
  return result;
}

uint64_t type metadata accessor for MLTrainingSessionParameters()
{
  uint64_t result = type metadata singleton initialization cache for MLTrainingSessionParameters;
  if (!type metadata singleton initialization cache for MLTrainingSessionParameters) {
    return swift_getSingletonMetadata();
  }
  return result;
}

uint64_t specialized BidirectionalCollection.last.getter@<X0>(uint64_t a1@<X0>, uint64_t a2@<X8>)
{
  uint64_t v3 = *(void *)(a1 + 16);
  if (v3)
  {
    uint64_t v5 = v3 - 1;
    uint64_t v6 = *(void *)(type metadata accessor for MLCheckpoint() - 8);
    _s8CreateML27MLTrainingSessionParametersVWOcTm_2(a1+ ((*(unsigned __int8 *)(v6 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v6 + 80))+ *(void *)(v6 + 72) * v5, a2, (void (*)(void))type metadata accessor for MLCheckpoint);
    uint64_t v7 = OUTLINED_FUNCTION_23_5();
  }
  else
  {
    type metadata accessor for MLCheckpoint();
    uint64_t v7 = OUTLINED_FUNCTION_9_21();
  }

  return __swift_storeEnumTagSinglePayload(v7, v8, v9, v10);
}

uint64_t specialized BidirectionalCollection.last.getter(uint64_t a1)
{
  return specialized BidirectionalCollection.last.getter(a1, MEMORY[0x263F53260]);
}

{
  return specialized BidirectionalCollection.last.getter(a1, MEMORY[0x263F53300]);
}

{
  uint64_t v1;

  unint64_t v1 = *(void *)(a1 + 16);
  if (v1) {
    return *(void *)(a1 + 8 * v1 + 24);
  }
  else {
    return 0;
  }
}

uint64_t specialized BidirectionalCollection.last.getter(uint64_t a1, unint64_t a2)
{
  uint64_t v2 = HIBYTE(a2) & 0xF;
  if ((a2 & 0x2000000000000000) == 0) {
    uint64_t v2 = a1 & 0xFFFFFFFFFFFFLL;
  }
  if (!v2) {
    return 0;
  }
  String.index(before:)();
  return String.subscript.getter();
}

uint64_t specialized BidirectionalCollection.last.getter(uint64_t a1, void (*a2)(void))
{
  if (*(void *)(a1 + 16))
  {
    a2(0);
    OUTLINED_FUNCTION_8();
    OUTLINED_FUNCTION_46_4();
    v2();
    uint64_t v3 = OUTLINED_FUNCTION_23_5();
  }
  else
  {
    a2(0);
    uint64_t v3 = OUTLINED_FUNCTION_9_21();
  }

  return __swift_storeEnumTagSinglePayload(v3, v4, v5, v6);
}

uint64_t MLTrainingSessionParameters.sessionDirectory.getter@<X0>(uint64_t a1@<X8>)
{
  return outlined init with copy of URL?(v1, a1);
}

uint64_t MLTrainingSessionParameters.reportInterval.getter()
{
  return *(void *)(v0 + *(int *)(type metadata accessor for MLTrainingSessionParameters() + 20));
}

uint64_t MLTrainingSessionParameters.reportInterval.setter()
{
  uint64_t result = OUTLINED_FUNCTION_11_18();
  *(void *)(v1 + *(int *)(result + 20)) = v0;
  return result;
}

uint64_t (*MLTrainingSessionParameters.reportInterval.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLTrainingSessionParameters.checkpointInterval.getter()
{
  return *(void *)(v0 + *(int *)(type metadata accessor for MLTrainingSessionParameters() + 24));
}

uint64_t MLTrainingSessionParameters.checkpointInterval.setter()
{
  uint64_t result = OUTLINED_FUNCTION_11_18();
  *(void *)(v1 + *(int *)(result + 24)) = v0;
  return result;
}

uint64_t (*MLTrainingSessionParameters.checkpointInterval.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLTrainingSessionParameters.iterations.getter()
{
  return *(void *)(v0 + *(int *)(type metadata accessor for MLTrainingSessionParameters() + 28));
}

uint64_t MLTrainingSessionParameters.iterations.setter()
{
  uint64_t result = OUTLINED_FUNCTION_11_18();
  *(void *)(v1 + *(int *)(result + 28)) = v0;
  return result;
}

uint64_t (*MLTrainingSessionParameters.iterations.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLTrainingSession.parameters.getter@<X0>(uint64_t a1@<X8>)
{
  return _s8CreateML27MLTrainingSessionParametersVWOcTm_2(v1 + direct field offset for MLTrainingSession.parameters, a1, (void (*)(void))type metadata accessor for MLTrainingSessionParameters);
}

uint64_t MLTrainingSession.date.getter()
{
  OUTLINED_FUNCTION_24_14();
  swift_beginAccess();
  type metadata accessor for Date();
  OUTLINED_FUNCTION_8();
  OUTLINED_FUNCTION_46_4();
  return v0();
}

uint64_t MLTrainingSession.phase.getter@<X0>(unsigned char *a1@<X8>)
{
  OUTLINED_FUNCTION_21_15();
  uint64_t v4 = v1 + *(void *)(v3 + 112);
  swift_beginAccess();
  OUTLINED_FUNCTION_21_15();
  uint64_t result = type metadata accessor for MLTrainingSession.Metadata();
  *a1 = *(unsigned char *)(v4 + *(int *)(result + 28));
  return result;
}

uint64_t type metadata accessor for MLTrainingSession.Metadata()
{
  return __swift_instantiateGenericMetadata();
}

uint64_t key path setter for MLTrainingSession.phase : <A>MLTrainingSession<A>(char *a1)
{
  char v2 = *a1;
  return MLTrainingSession.phase.setter(&v2);
}

uint64_t MLTrainingSession.phase.setter(char *a1)
{
  char v2 = *a1;
  OUTLINED_FUNCTION_8_21();
  uint64_t v4 = v1 + *(void *)(v3 + 112);
  swift_beginAccess();
  OUTLINED_FUNCTION_8_21();
  uint64_t result = type metadata accessor for MLTrainingSession.Metadata();
  *(unsigned char *)(v4 + *(int *)(result + 28)) = v2;
  return result;
}

uint64_t MLTrainingSession.iteration.getter()
{
  OUTLINED_FUNCTION_8_21();
  OUTLINED_FUNCTION_14_14();
  OUTLINED_FUNCTION_8_21();
  return *(void *)(v0 + *(int *)(type metadata accessor for MLTrainingSession.Metadata() + 32));
}

uint64_t MLTrainingSession.iteration.setter(uint64_t a1)
{
  OUTLINED_FUNCTION_21_15();
  uint64_t v4 = v1 + *(void *)(v3 + 112);
  swift_beginAccess();
  OUTLINED_FUNCTION_21_15();
  uint64_t result = type metadata accessor for MLTrainingSession.Metadata();
  *(void *)(v4 + *(int *)(result + 32)) = a1;
  return result;
}

uint64_t MLTrainingSession.checkpoints.getter()
{
  return swift_bridgeObjectRetain();
}

Swift::Void __swiftcall __spoils<CF,ZF,NF,VF,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13,X14,X15,X16,X17,X21,Q0,Q1,Q2,Q3,Q4,Q5,Q6,Q7,Q16,Q17,Q18,Q19,Q20,Q21,Q22,Q23,Q24,Q25,Q26,Q27,Q28,Q29,Q30,Q31> MLTrainingSession.save()()
{
  OUTLINED_FUNCTION_9_0();
  uint64_t v2 = v0;
  OUTLINED_FUNCTION_24_14();
  type metadata accessor for MLTrainingSession.Metadata();
  OUTLINED_FUNCTION_0();
  uint64_t v56 = v3;
  uint64_t v57 = v4;
  OUTLINED_FUNCTION_8_13();
  MEMORY[0x270FA5388](v5);
  uint64_t v55 = (char *)v53 - v6;
  OUTLINED_FUNCTION_65();
  uint64_t v7 = type metadata accessor for CodingUserInfoKey();
  OUTLINED_FUNCTION_0();
  uint64_t v54 = v8;
  MEMORY[0x270FA5388](v9);
  OUTLINED_FUNCTION_3_0();
  uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  uint64_t v11 = OUTLINED_FUNCTION_17(v10);
  MEMORY[0x270FA5388](v11);
  OUTLINED_FUNCTION_3_0();
  uint64_t v14 = v13 - v12;
  uint64_t v15 = type metadata accessor for MLTrainingSessionParameters();
  uint64_t v16 = OUTLINED_FUNCTION_17(v15);
  MEMORY[0x270FA5388](v16);
  OUTLINED_FUNCTION_3_0();
  uint64_t v19 = v18 - v17;
  uint64_t v20 = type metadata accessor for URL();
  OUTLINED_FUNCTION_0();
  uint64_t v22 = v21;
  uint64_t v24 = MEMORY[0x270FA5388](v23);
  uint64_t v26 = (char *)v53 - ((v25 + 15) & 0xFFFFFFFFFFFFFFF0);
  MEMORY[0x270FA5388](v24);
  uint64_t v28 = (char *)v53 - v27;
  _s8CreateML27MLTrainingSessionParametersVWOcTm_2(v2 + direct field offset for MLTrainingSession.parameters, v19, (void (*)(void))type metadata accessor for MLTrainingSessionParameters);
  uint64_t v29 = v19;
  uint64_t v30 = v20;
  outlined init with take of URL?(v29, v14);
  if (__swift_getEnumTagSinglePayload(v14, 1, v20) == 1)
  {
    _s10Foundation3URLVSgWOhTm_0(v14, &demangling cache variable for type metadata for URL?);
  }
  else
  {
    (*(void (**)(char *, uint64_t, uint64_t))(v22 + 32))(v28, v14, v20);
    v53[1] = v26;
    URL.appendingPathComponent(_:)();
    type metadata accessor for PropertyListEncoder();
    swift_allocObject();
    uint64_t v31 = PropertyListEncoder.init()();
    if (one-time initialization token for sessionDirectory != -1) {
      swift_once();
    }
    __swift_project_value_buffer(v7, (uint64_t)static CodingUserInfoKey.sessionDirectory);
    OUTLINED_FUNCTION_46_4();
    v32();
    v59[3] = v30;
    boxed_opaque_existential_0 = __swift_allocate_boxed_opaque_existential_0(v59);
    (*(void (**)(uint64_t *, char *, uint64_t))(v22 + 16))(boxed_opaque_existential_0, v28, v30);
    v53[0] = v30;
    uint64_t v34 = (void (*)(uint64_t *, void))dispatch thunk of PropertyListEncoder.userInfo.modify();
    specialized Dictionary.subscript.setter((uint64_t)v59);
    v34(&v58, 0);
    uint64_t v35 = v2 + *(void *)(*(void *)v2 + 112);
    swift_beginAccess();
    uint64_t v36 = *(void (**)(char *, uint64_t, uint64_t))(v57 + 16);
    uint64_t v54 = v28;
    v36(v55, v35, v56);
    swift_getWitnessTable();
    uint64_t v37 = dispatch thunk of PropertyListEncoder.encode<A>(_:)();
    if (v1)
    {
      swift_release();
      uint64_t v39 = OUTLINED_FUNCTION_13_21();
      v40(v39);
      uint64_t v41 = *(void (**)(void))(v22 + 8);
      OUTLINED_FUNCTION_18_13();
      v41();
      ((void (*)(char *, uint64_t))v41)(v54, v31);
    }
    else
    {
      uint64_t v42 = v37;
      unint64_t v43 = v38;
      uint64_t v44 = OUTLINED_FUNCTION_13_21();
      v45(v44);
      Data.write(to:options:)();
      unint64_t v46 = v43;
      uint64_t v47 = (void *)(v2 + direct field offset for MLTrainingSession.delegate);
      uint64_t v48 = *(void *)(v2 + direct field offset for MLTrainingSession.delegate + 24);
      uint64_t v49 = v47[4];
      uint64_t v50 = __swift_project_boxed_opaque_existential_1(v47, v48);
      uint64_t v51 = v54;
      (*(void (**)(char *, uint64_t))(*(void *)(v49 + 8) + 8))(v54, v48);
      outlined consume of Data._Representation(v42, v46);
      swift_release();
      uint64_t v52 = *(void (**)(void))(v22 + 8);
      OUTLINED_FUNCTION_18_13();
      v52();
      ((void (*)(char *, void *))v52)(v51, v50);
    }
  }
  OUTLINED_FUNCTION_8_1();
}

uint64_t MLTrainingSession.Metadata.CodingKeys.init(stringValue:)(uint64_t a1, uint64_t a2)
{
  BOOL v2 = a1 == 1702125924 && a2 == 0xE400000000000000;
  if (v2 || (_stringCompareWithSmolCheck(_:_:expecting:)() & 1) != 0)
  {
    swift_bridgeObjectRelease();
    return 0;
  }
  else
  {
    BOOL v6 = a1 == 0x6573616870 && a2 == 0xE500000000000000;
    if (v6 || (_stringCompareWithSmolCheck(_:_:expecting:)() & 1) != 0)
    {
      swift_bridgeObjectRelease();
      return 1;
    }
    else
    {
      BOOL v7 = a1 == 0x6F69746172657469 && a2 == 0xE90000000000006ELL;
      if (v7 || (_stringCompareWithSmolCheck(_:_:expecting:)() & 1) != 0)
      {
        swift_bridgeObjectRelease();
        return 2;
      }
      else
      {
        BOOL v8 = a1 == 0x4C52556C65646F6DLL && a2 == 0xE800000000000000;
        if (v8 || (_stringCompareWithSmolCheck(_:_:expecting:)() & 1) != 0)
        {
          swift_bridgeObjectRelease();
          return 3;
        }
        else
        {
          BOOL v9 = a1 == 0x7461447475706E69 && a2 == 0xEC0000004C525561;
          if (v9 || (_stringCompareWithSmolCheck(_:_:expecting:)() & 1) != 0)
          {
            swift_bridgeObjectRelease();
            return 4;
          }
          else if (a1 == 0x696F706B63656863 && a2 == 0xEB0000000073746ELL)
          {
            swift_bridgeObjectRelease();
            return 5;
          }
          else
          {
            char v11 = _stringCompareWithSmolCheck(_:_:expecting:)();
            swift_bridgeObjectRelease();
            if (v11) {
              return 5;
            }
            else {
              return 6;
            }
          }
        }
      }
    }
  }
}

uint64_t MLTrainingSession.Metadata.CodingKeys.init(intValue:)()
{
  return 6;
}

uint64_t MLTrainingSession.Metadata.CodingKeys.stringValue.getter(char a1)
{
  uint64_t result = 1702125924;
  switch(a1)
  {
    case 1:
      uint64_t result = 0x6573616870;
      break;
    case 2:
      uint64_t result = 0x6F69746172657469;
      break;
    case 3:
      uint64_t result = 0x4C52556C65646F6DLL;
      break;
    case 4:
      uint64_t result = 0x7461447475706E69;
      break;
    case 5:
      uint64_t result = 0x696F706B63656863;
      break;
    default:
      return result;
  }
  return result;
}

void MLTrainingSession.Metadata.encode(to:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, __int16 a10, char a11, char a12, char a13, char a14, char a15, char a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26)
{
  OUTLINED_FUNCTION_9_0();
  a25 = v28;
  a26 = v29;
  uint64_t v45 = v30;
  uint64_t v46 = v27;
  uint64_t v31 = v26;
  uint64_t v33 = v32;
  type metadata accessor for MLTrainingSession.Metadata.CodingKeys();
  swift_getWitnessTable();
  uint64_t v34 = type metadata accessor for KeyedEncodingContainer();
  OUTLINED_FUNCTION_0();
  uint64_t v36 = v35;
  OUTLINED_FUNCTION_8_13();
  MEMORY[0x270FA5388](v37);
  uint64_t v39 = (char *)&v44 - v38;
  __swift_project_boxed_opaque_existential_1(v33, v33[3]);
  dispatch thunk of Encoder.container<A>(keyedBy:)();
  a16 = 0;
  type metadata accessor for Date();
  lazy protocol witness table accessor for type Date and conformance Date(&lazy protocol witness table cache variable for type Date and conformance Date, MEMORY[0x263F07490]);
  uint64_t v40 = v46;
  KeyedEncodingContainer.encode<A>(_:forKey:)();
  if (!v40)
  {
    uint64_t v41 = v45;
    a15 = *(unsigned char *)(v31 + v45[7]);
    a14 = 1;
    lazy protocol witness table accessor for type MLPhase and conformance MLPhase();
    KeyedEncodingContainer.encode<A>(_:forKey:)();
    a13 = 2;
    KeyedEncodingContainer.encode(_:forKey:)();
    uint64_t v42 = v31 + v41[9];
    a12 = 3;
    type metadata accessor for URL();
    lazy protocol witness table accessor for type Date and conformance Date(&lazy protocol witness table cache variable for type URL and conformance URL, MEMORY[0x263F06EA8]);
    OUTLINED_FUNCTION_12_14(v42, (uint64_t)&a12);
    uint64_t v43 = v31 + v45[10];
    a11 = 4;
    OUTLINED_FUNCTION_12_14(v43, (uint64_t)&a11);
    uint64_t v47 = *(void *)(v31 + v45[11]);
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [MLCheckpoint]);
    lazy protocol witness table accessor for type [MLCheckpoint] and conformance <A> [A](&lazy protocol witness table cache variable for type [MLCheckpoint] and conformance <A> [A], &lazy protocol witness table cache variable for type MLCheckpoint and conformance MLCheckpoint);
    KeyedEncodingContainer.encode<A>(_:forKey:)();
  }
  (*(void (**)(char *, uint64_t))(v36 + 8))(v39, v34);
  OUTLINED_FUNCTION_8_1();
}

void MLTrainingSession.Metadata.init(from:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, int a10, __int16 a11, char a12)
{
  OUTLINED_FUNCTION_9_0();
  uint64_t v70 = v12;
  uint64_t v14 = v13;
  uint64_t v55 = v15;
  uint64_t v16 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  uint64_t v17 = OUTLINED_FUNCTION_17(v16);
  MEMORY[0x270FA5388](v17);
  OUTLINED_FUNCTION_49();
  uint64_t v56 = v18;
  MEMORY[0x270FA5388](v19);
  uint64_t v57 = (char *)&v53 - v20;
  OUTLINED_FUNCTION_65();
  type metadata accessor for Date();
  OUTLINED_FUNCTION_0();
  uint64_t v60 = v22;
  uint64_t v61 = v21;
  MEMORY[0x270FA5388](v21);
  OUTLINED_FUNCTION_33_0();
  uint64_t v63 = v23;
  type metadata accessor for MLTrainingSession.Metadata.CodingKeys();
  uint64_t WitnessTable = swift_getWitnessTable();
  uint64_t v62 = type metadata accessor for KeyedDecodingContainer();
  OUTLINED_FUNCTION_0();
  uint64_t v59 = v24;
  OUTLINED_FUNCTION_8_13();
  MEMORY[0x270FA5388](v25);
  uint64_t v27 = (char *)&v53 - v26;
  uint64_t v28 = (int *)type metadata accessor for MLTrainingSession.Metadata();
  OUTLINED_FUNCTION_0();
  uint64_t v66 = v29;
  OUTLINED_FUNCTION_8_13();
  MEMORY[0x270FA5388](v30);
  uint64_t v32 = (char *)&v53 - v31;
  Date.init()();
  uint64_t v58 = v28[7];
  v32[v58] = 0;
  uint64_t v33 = v28[8];
  *(void *)&v32[v33] = 0;
  uint64_t v34 = (uint64_t)&v32[v28[9]];
  uint64_t v35 = type metadata accessor for URL();
  __swift_storeEnumTagSinglePayload(v34, 1, 1, v35);
  uint64_t v36 = (uint64_t)&v32[v28[10]];
  __swift_storeEnumTagSinglePayload(v36, 1, 1, v35);
  uint64_t v65 = v28;
  uint64_t v37 = v28[11];
  uint64_t v68 = v32;
  *(void *)&v32[v37] = MEMORY[0x263F8EE78];
  uint64_t v38 = v14;
  uint64_t v39 = v14[3];
  uint64_t v67 = v38;
  __swift_project_boxed_opaque_existential_1(v38, v39);
  uint64_t v64 = v27;
  uint64_t v40 = v70;
  dispatch thunk of Decoder.container<A>(keyedBy:)();
  if (v40)
  {
    uint64_t v50 = v66;
    uint64_t v52 = (uint64_t)v67;
    uint64_t v51 = v65;
    uint64_t v45 = v68;
  }
  else
  {
    uint64_t v41 = v60;
    uint64_t WitnessTable = v34;
    uint64_t v70 = v35;
    uint64_t v53 = v37;
    uint64_t v54 = v36;
    uint64_t v43 = v58;
    uint64_t v42 = v59;
    lazy protocol witness table accessor for type Date and conformance Date(&lazy protocol witness table cache variable for type Date and conformance Date, MEMORY[0x263F07490]);
    uint64_t v44 = v61;
    KeyedDecodingContainer.decode<A>(_:forKey:)();
    uint64_t v45 = v68;
    (*(void (**)(char *, uint64_t, uint64_t))(v41 + 40))(v68, v63, v44);
    lazy protocol witness table accessor for type MLPhase and conformance MLPhase();
    KeyedDecodingContainer.decode<A>(_:forKey:)();
    v45[v43] = a12;
    *(void *)&v45[v33] = KeyedDecodingContainer.decode(_:forKey:)();
    lazy protocol witness table accessor for type Date and conformance Date(&lazy protocol witness table cache variable for type URL and conformance URL, MEMORY[0x263F06EA8]);
    uint64_t v46 = (uint64_t)v57;
    OUTLINED_FUNCTION_22_12();
    outlined assign with take of URL?(v46, WitnessTable);
    uint64_t v47 = v56;
    OUTLINED_FUNCTION_22_12();
    outlined assign with take of URL?(v47, v54);
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [MLCheckpoint]);
    lazy protocol witness table accessor for type [MLCheckpoint] and conformance <A> [A](&lazy protocol witness table cache variable for type [MLCheckpoint] and conformance <A> [A], &lazy protocol witness table cache variable for type MLCheckpoint and conformance MLCheckpoint);
    KeyedDecodingContainer.decode<A>(_:forKey:)();
    (*(void (**)(char *, uint64_t))(v42 + 8))(v64, v62);
    uint64_t v48 = v71;
    uint64_t v49 = v53;
    swift_bridgeObjectRelease();
    *(void *)&v45[v49] = v48;
    uint64_t v51 = v65;
    uint64_t v50 = v66;
    (*(void (**)(uint64_t, char *, int *))(v66 + 16))(v55, v45, v65);
    uint64_t v52 = (uint64_t)v67;
  }
  __swift_destroy_boxed_opaque_existential_0(v52);
  (*(void (**)(char *, int *))(v50 + 8))(v45, v51);
  OUTLINED_FUNCTION_8_1();
}

BOOL protocol witness for static Equatable.== infix(_:_:) in conformance MLTrainingSession<A>.Metadata.CodingKeys(char *a1, char *a2)
{
  return static MLCheckpoint.CodingKeys.== infix(_:_:)(*a1, *a2);
}

Swift::Int protocol witness for Hashable.hashValue.getter in conformance MLTrainingSession<A>.Metadata.CodingKeys()
{
  return MLCheckpoint.CodingKeys.hashValue.getter(*v0);
}

void protocol witness for Hashable.hash(into:) in conformance MLTrainingSession<A>.Metadata.CodingKeys(uint64_t a1)
{
  MLCheckpoint.CodingKeys.hash(into:)(a1, *v1);
}

Swift::Int protocol witness for Hashable._rawHashValue(seed:) in conformance MLTrainingSession<A>.Metadata.CodingKeys()
{
  Hasher.init(_seed:)();
  MLCheckpoint.CodingKeys.hash(into:)((uint64_t)v2, *v0);
  return Hasher._finalize()();
}

uint64_t protocol witness for CodingKey.stringValue.getter in conformance MLTrainingSession<A>.Metadata.CodingKeys()
{
  return MLTrainingSession.Metadata.CodingKeys.stringValue.getter(*v0);
}

uint64_t protocol witness for CodingKey.init(stringValue:) in conformance MLTrainingSession<A>.Metadata.CodingKeys@<X0>(uint64_t a1@<X0>, uint64_t a2@<X1>, unsigned char *a3@<X8>)
{
  uint64_t result = MLTrainingSession.Metadata.CodingKeys.init(stringValue:)(a1, a2);
  *a3 = result;
  return result;
}

uint64_t protocol witness for CodingKey.intValue.getter in conformance MLTrainingSession<A>.Metadata.CodingKeys()
{
  return Metadata.CodingKeys.intValue.getter();
}

uint64_t protocol witness for CodingKey.init(intValue:) in conformance MLTrainingSession<A>.Metadata.CodingKeys@<X0>(unsigned char *a1@<X8>)
{
  uint64_t result = MLTrainingSession.Metadata.CodingKeys.init(intValue:)();
  *a1 = result;
  return result;
}

uint64_t protocol witness for CustomStringConvertible.description.getter in conformance MLTrainingSession<A>.Metadata.CodingKeys(uint64_t a1)
{
  uint64_t WitnessTable = swift_getWitnessTable();

  return MEMORY[0x270FA00B0](a1, WitnessTable);
}

uint64_t protocol witness for CustomDebugStringConvertible.debugDescription.getter in conformance MLTrainingSession<A>.Metadata.CodingKeys(uint64_t a1)
{
  uint64_t WitnessTable = swift_getWitnessTable();

  return MEMORY[0x270FA00B8](a1, WitnessTable);
}

void protocol witness for Decodable.init(from:) in conformance MLTrainingSession<A>.Metadata(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
  MLTrainingSession.Metadata.init(from:)(a1, *(void *)(a2 + 16), a3, a4, a5, a6, a7, a8, vars0, *(int *)vars8, *(__int16 *)&vars8[4], vars8[6]);
}

#error "2271355F8: call analysis failed (funcsize=6)"

void MLTrainingSession.removeCheckpoints(_:)()
{
  OUTLINED_FUNCTION_9_0();
  uint64_t v51 = v2;
  uint64_t v52 = v3;
  v54[4] = *(id *)MEMORY[0x263EF8340];
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?);
  uint64_t v5 = OUTLINED_FUNCTION_17(v4);
  MEMORY[0x270FA5388](v5);
  OUTLINED_FUNCTION_49();
  uint64_t v46 = v6;
  MEMORY[0x270FA5388](v7);
  uint64_t v44 = (uint64_t)&v43 - v8;
  OUTLINED_FUNCTION_65();
  uint64_t v45 = type metadata accessor for MLCheckpoint();
  OUTLINED_FUNCTION_0();
  uint64_t v10 = v9;
  MEMORY[0x270FA5388](v11);
  OUTLINED_FUNCTION_49();
  uint64_t v50 = v12;
  MEMORY[0x270FA5388](v13);
  uint64_t v15 = (char *)&v43 - v14;
  id v49 = objc_msgSend(objc_allocWithZone(MEMORY[0x263F08850]), sel_init);
  OUTLINED_FUNCTION_24_14();
  uint64_t v17 = v0 + *(void *)(v16 + 112);
  swift_beginAccess();
  OUTLINED_FUNCTION_8_21();
  uint64_t v53 = type metadata accessor for MLTrainingSession.Metadata();
  uint64_t v18 = *(int *)(v53 + 44);
  uint64_t v19 = *(void *)(*(void *)(v17 + v18) + 16);
  uint64_t v48 = v17;
  if (v19)
  {
    uint64_t v47 = v1;
    uint64_t v43 = v0;
    unint64_t v20 = 0;
    uint64_t v21 = MEMORY[0x263F8EE78];
    do
    {
      uint64_t v22 = *(void *)(v17 + *(int *)(v53 + 44));
      if (v20 >= *(void *)(v22 + 16)) {
        __break(1u);
      }
      unint64_t v23 = (*(unsigned __int8 *)(v10 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v10 + 80);
      uint64_t v24 = *(void *)(v10 + 72);
      _s8CreateML27MLTrainingSessionParametersVWOcTm_2(v22 + v23 + v24 * v20, (uint64_t)v15, (void (*)(void))type metadata accessor for MLCheckpoint);
      if (v51(v15))
      {
        URL._bridgeToObjectiveC()(v25);
        uint64_t v27 = v26;
        v54[0] = 0;
        unsigned int v28 = objc_msgSend(v49, sel_removeItemAtURL_error_, v26, v54);

        if (v28)
        {
          id v29 = v54[0];
        }
        else
        {
          id v31 = v54[0];
          uint64_t v32 = (void *)_convertNSErrorToError(_:)();

          swift_willThrow();
          uint64_t v47 = 0;
        }
      }
      else
      {
        _s8CreateML27MLTrainingSessionParametersVWOcTm_2((uint64_t)v15, v50, (void (*)(void))type metadata accessor for MLCheckpoint);
        if ((swift_isUniquelyReferenced_nonNull_native() & 1) == 0)
        {
          specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
          uint64_t v21 = v33;
        }
        unint64_t v30 = *(void *)(v21 + 16);
        if (v30 >= *(void *)(v21 + 24) >> 1)
        {
          specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
          uint64_t v21 = v34;
        }
        *(void *)(v21 + 16) = v30 + 1;
        outlined init with take of MLCheckpoint(v50, v21 + v23 + v30 * v24);
        uint64_t v17 = v48;
      }
      ++v20;
      outlined destroy of MLCheckpoint((uint64_t)v15, (void (*)(void))type metadata accessor for MLCheckpoint);
    }
    while (v19 != v20);
    uint64_t v18 = *(int *)(v53 + 44);
  }
  else
  {
    uint64_t v21 = MEMORY[0x263F8EE78];
  }
  *(void *)(v17 + v18) = v21;
  swift_bridgeObjectRetain();
  swift_bridgeObjectRelease();
  uint64_t v35 = v44;
  specialized BidirectionalCollection.last.getter(v21, v44);
  uint64_t v36 = v45;
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v35, 1, v45);
  uint64_t v38 = v46;
  if (EnumTagSinglePayload == 1)
  {
    _s10Foundation3URLVSgWOhTm_0(v35, &demangling cache variable for type metadata for MLCheckpoint?);
    swift_bridgeObjectRelease();
  }
  else
  {
    char v39 = *(unsigned char *)(v35 + *(int *)(v36 + 20));
    outlined destroy of MLCheckpoint(v35, (void (*)(void))type metadata accessor for MLCheckpoint);
    specialized BidirectionalCollection.last.getter(v21, v38);
    swift_bridgeObjectRelease();
    if (__swift_getEnumTagSinglePayload(v38, 1, v36) == 1)
    {
      _s10Foundation3URLVSgWOhTm_0(v38, &demangling cache variable for type metadata for MLCheckpoint?);
    }
    else
    {
      uint64_t v40 = *(void *)(v38 + *(int *)(v36 + 24));
      outlined destroy of MLCheckpoint(v38, (void (*)(void))type metadata accessor for MLCheckpoint);
      uint64_t v41 = v53;
      uint64_t v42 = v48;
      *(unsigned char *)(v48 + *(int *)(v53 + 28)) = v39;
      *(void *)(v42 + *(int *)(v41 + 32)) = v40;
    }
  }
  MLTrainingSession.save()();

  OUTLINED_FUNCTION_8_1();
}

void MLTrainingSession.reuseExtractedFeatures(from:)()
{
  OUTLINED_FUNCTION_9_0();
  uint64_t v90 = v1;
  BOOL v2 = v0;
  uint64_t v92 = v3;
  v93[7] = *(id *)MEMORY[0x263EF8340];
  uint64_t v4 = *v0;
  type metadata accessor for Date();
  OUTLINED_FUNCTION_0();
  uint64_t v86 = v6;
  uint64_t v87 = v5;
  MEMORY[0x270FA5388](v5);
  OUTLINED_FUNCTION_33_0();
  uint64_t v85 = v7;
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  uint64_t v9 = OUTLINED_FUNCTION_17(v8);
  MEMORY[0x270FA5388](v9);
  OUTLINED_FUNCTION_33_0();
  uint64_t v91 = v10;
  OUTLINED_FUNCTION_65();
  uint64_t v11 = type metadata accessor for MLTrainingSessionParameters();
  uint64_t v12 = OUTLINED_FUNCTION_17(v11);
  MEMORY[0x270FA5388](v12);
  OUTLINED_FUNCTION_33_0();
  uint64_t v89 = v13;
  uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?);
  uint64_t v15 = OUTLINED_FUNCTION_17(v14);
  MEMORY[0x270FA5388](v15);
  OUTLINED_FUNCTION_3_0();
  uint64_t v18 = (void *)(v17 - v16);
  uint64_t v19 = type metadata accessor for MLCheckpoint();
  OUTLINED_FUNCTION_0();
  uint64_t v88 = v20;
  uint64_t v22 = MEMORY[0x270FA5388](v21);
  uint64_t v24 = (char *)&v79 - ((v23 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v25 = MEMORY[0x270FA5388](v22);
  uint64_t v27 = (char *)&v79 - v26;
  uint64_t v28 = MEMORY[0x270FA5388](v25);
  unint64_t v30 = (char *)&v79 - v29;
  MEMORY[0x270FA5388](v28);
  uint64_t v32 = (char *)&v79 - v31;
  uint64_t v33 = (char *)v2 + *(void *)(v4 + 112);
  swift_beginAccess();
  uint64_t v34 = type metadata accessor for MLTrainingSession.Metadata();
  if (*(void *)(*(void *)&v33[*(int *)(v34 + 44)] + 16))
  {
    lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError();
    unint64_t v36 = 0xD000000000000047;
    uint64_t v37 = "This session already contains checkpoints. Please create a new session.";
LABEL_14:
    *(void *)uint64_t v35 = v36;
    *(void *)(v35 + 8) = (unint64_t)(v37 - 32) | 0x8000000000000000;
    *(_OWORD *)(v35 + 16) = 0u;
    *(_OWORD *)(v35 + 32) = 0u;
    *(unsigned char *)(v35 + 48) = 0;
    swift_willThrow();
    goto LABEL_15;
  }
  uint64_t v38 = (int *)v34;
  uint64_t v81 = v27;
  uint64_t v82 = v32;
  uint64_t v83 = v18;
  unint64_t v84 = v2;
  unint64_t v80 = v24;
  uint64_t v79 = v33;
  char v39 = (char *)v92 + *(void *)(*(void *)v92 + 112);
  swift_beginAccess();
  uint64_t v92 = v38;
  uint64_t v40 = *(void **)&v39[v38[11]];
  v93[0] = v40;
  uint64_t v41 = v40[2];
  if (v41)
  {
    uint64_t v42 = v88;
    uint64_t v43 = (char *)v40 + ((*(unsigned __int8 *)(v88 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v88 + 80));
    swift_bridgeObjectRetain();
    uint64_t v44 = (int *)v19;
    while (2)
    {
      if (v41 > v40[2]) {
        __break(1u);
      }
      --v41;
      _s8CreateML27MLTrainingSessionParametersVWOcTm_2((uint64_t)&v43[*(void *)(v42 + 72) * v41], (uint64_t)v30, (void (*)(void))type metadata accessor for MLCheckpoint);
      switch(v30[v44[5]])
      {
        case 1:
          swift_bridgeObjectRelease();
          uint64_t v46 = outlined destroy of MLCheckpoint((uint64_t)v30, (void (*)(void))type metadata accessor for MLCheckpoint);
          uint64_t v50 = (uint64_t)v82;
          uint64_t v48 = v83;
          uint64_t v47 = v84;
          uint64_t v49 = v89;
          goto LABEL_12;
        default:
          char v45 = _stringCompareWithSmolCheck(_:_:expecting:)();
          swift_bridgeObjectRelease();
          uint64_t v46 = outlined destroy of MLCheckpoint((uint64_t)v30, (void (*)(void))type metadata accessor for MLCheckpoint);
          if ((v45 & 1) == 0 && v41) {
            continue;
          }
          uint64_t v48 = v83;
          uint64_t v47 = v84;
          uint64_t v49 = v89;
          break;
      }
      break;
    }
  }
  else
  {
    uint64_t v46 = swift_bridgeObjectRetain();
    uint64_t v44 = (int *)v19;
    uint64_t v48 = v83;
    uint64_t v47 = v84;
    uint64_t v49 = v89;
  }
  uint64_t v50 = (uint64_t)v82;
LABEL_12:
  MEMORY[0x270FA5388](v46);
  *(&v79 - 2) = (char *)v93;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5Tm((void *(*)(void *__return_ptr, uint64_t *))partial apply for specialized closure #1 in BidirectionalCollection.last(where:), v41, v51 & 1, (void (*)(void))type metadata accessor for MLCheckpoint, v48);
  swift_bridgeObjectRelease();
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)v48, 1, (uint64_t)v44);
  uint64_t v53 = v91;
  if (EnumTagSinglePayload == 1)
  {
    _s10Foundation3URLVSgWOhTm_0((uint64_t)v48, &demangling cache variable for type metadata for MLCheckpoint?);
    lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError();
    unint64_t v36 = 0xD000000000000029;
    uint64_t v37 = "Session is missing a features checkpoint.";
    goto LABEL_14;
  }
  outlined init with take of MLCheckpoint((uint64_t)v48, v50);
  _s8CreateML27MLTrainingSessionParametersVWOcTm_2((uint64_t)v47 + direct field offset for MLTrainingSession.parameters, v49, (void (*)(void))type metadata accessor for MLTrainingSessionParameters);
  outlined init with take of URL?(v49, v53);
  uint64_t v54 = type metadata accessor for URL();
  if (__swift_getEnumTagSinglePayload(v53, 1, v54) == 1)
  {
    __break(1u);
    JUMPOUT(0x227136380);
  }
  uint64_t v55 = *(void *)(v50 + v44[6]);
  uint64_t v90 = *(void *)(v50 + v44[8]);
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  uint64_t v56 = swift_allocObject();
  *(_OWORD *)(v56 + 16) = xmmword_2272CB4D0;
  *(void *)(v56 + 56) = MEMORY[0x263F8D310];
  unint64_t v57 = lazy protocol witness table accessor for type String and conformance String();
  *(void *)(v56 + 32) = 0x6974636172747865;
  *(void *)(v56 + 40) = 0xEA0000000000676ELL;
  uint64_t v58 = MEMORY[0x263F8D750];
  *(void *)(v56 + 96) = MEMORY[0x263F8D6C8];
  *(void *)(v56 + 104) = v58;
  *(void *)(v56 + 64) = v57;
  *(void *)(v56 + 72) = v55;
  swift_bridgeObjectRetain();
  String.init(format:_:)();
  uint64_t v59 = v50;
  uint64_t v60 = (uint64_t)v80;
  URL.appendingPathComponent(_:)();
  swift_bridgeObjectRelease();
  *(unsigned char *)(v60 + v44[5]) = 1;
  *(void *)(v60 + v44[6]) = v55;
  uint64_t v61 = v85;
  Date.init()();
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v54 - 8) + 8))(v53, v54);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v86 + 32))(v60 + v44[7], v61, v87);
  *(void *)(v60 + v44[8]) = v90;
  uint64_t v62 = (uint64_t)v81;
  outlined init with take of MLCheckpoint(v60, (uint64_t)v81);
  id v63 = objc_msgSend(self, sel_defaultManager);
  URL._bridgeToObjectiveC()(v64);
  uint64_t v66 = v65;
  URL._bridgeToObjectiveC()(v67);
  uint64_t v69 = v68;
  v93[0] = 0;
  unsigned __int8 v70 = objc_msgSend(v63, sel_copyItemAtURL_toURL_error_, v66, v68, v93);

  id v71 = v93[0];
  if (v70)
  {
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<MLCheckpoint>);
    unint64_t v72 = (*(unsigned __int8 *)(v88 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v88 + 80);
    uint64_t v73 = swift_allocObject();
    *(_OWORD *)(v73 + 16) = xmmword_2272CB370;
    _s8CreateML27MLTrainingSessionParametersVWOcTm_2(v62, v73 + v72, (void (*)(void))type metadata accessor for MLCheckpoint);
    id v74 = v71;
    outlined destroy of MLCheckpoint(v59, (void (*)(void))type metadata accessor for MLCheckpoint);
    uint64_t v75 = v92;
    char v76 = v79;
    *(void *)&v79[v92[11]] = v73;
    swift_bridgeObjectRelease();
    v76[v75[7]] = 1;
    uint64_t v77 = *(void *)(v62 + v44[6]);
    outlined destroy of MLCheckpoint(v62, (void (*)(void))type metadata accessor for MLCheckpoint);
    *(void *)&v76[v75[8]] = v77;
  }
  else
  {
    id v78 = v93[0];
    _convertNSErrorToError(_:)();

    swift_willThrow();
    outlined destroy of MLCheckpoint(v62, (void (*)(void))type metadata accessor for MLCheckpoint);
    outlined destroy of MLCheckpoint(v59, (void (*)(void))type metadata accessor for MLCheckpoint);
  }
LABEL_15:
  OUTLINED_FUNCTION_8_1();
}

uint64_t MLTrainingSession.deinit()
{
  outlined destroy of MLCheckpoint(v0 + direct field offset for MLTrainingSession.parameters, (void (*)(void))type metadata accessor for MLTrainingSessionParameters);
  __swift_destroy_boxed_opaque_existential_0(v0 + direct field offset for MLTrainingSession.delegate);
  OUTLINED_FUNCTION_24_14();
  type metadata accessor for MLTrainingSession.Metadata();
  OUTLINED_FUNCTION_8();
  uint64_t v1 = OUTLINED_FUNCTION_22_1();
  v2(v1);
  return v0;
}

uint64_t MLTrainingSession.__deallocating_deinit()
{
  MLTrainingSession.deinit();

  return swift_deallocClassInstance();
}

uint64_t specialized Array._makeUniqueAndReserveCapacityIfNotUnique()()
{
  return specialized Array._makeUniqueAndReserveCapacityIfNotUnique()((uint64_t (*)(uint64_t, uint64_t, uint64_t, uint64_t))specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:));
}

{
  return specialized Array._makeUniqueAndReserveCapacityIfNotUnique()((uint64_t (*)(uint64_t, uint64_t, uint64_t, uint64_t))specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:));
}

{
  return specialized Array._makeUniqueAndReserveCapacityIfNotUnique()((uint64_t (*)(uint64_t, uint64_t, uint64_t, uint64_t))specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:));
}

{
  return specialized Array._makeUniqueAndReserveCapacityIfNotUnique()((uint64_t (*)(uint64_t, uint64_t, uint64_t, uint64_t))specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:));
}

{
  return specialized Array._makeUniqueAndReserveCapacityIfNotUnique()((uint64_t (*)(uint64_t, uint64_t, uint64_t, uint64_t))specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:));
}

{
  return specialized Array._makeUniqueAndReserveCapacityIfNotUnique()((uint64_t (*)(uint64_t, uint64_t, uint64_t, uint64_t))specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:));
}

{
  return specialized Array._makeUniqueAndReserveCapacityIfNotUnique()((uint64_t (*)(uint64_t, uint64_t, uint64_t, uint64_t))specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:));
}

{
  return specialized Array._makeUniqueAndReserveCapacityIfNotUnique()((uint64_t (*)(uint64_t, uint64_t, uint64_t, uint64_t))specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:));
}

{
  return specialized Array._makeUniqueAndReserveCapacityIfNotUnique()((uint64_t (*)(uint64_t, uint64_t, uint64_t, uint64_t))specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:));
}

{
  return MEMORY[0x270F9DBA0]();
}

uint64_t specialized Array._makeUniqueAndReserveCapacityIfNotUnique()(uint64_t (*a1)(uint64_t, uint64_t, uint64_t, uint64_t))
{
  uint64_t v3 = *v1;
  uint64_t result = swift_isUniquelyReferenced_nonNull_native();
  uint64_t *v1 = v3;
  if (!result)
  {
    uint64_t result = a1(result, *(void *)(v3 + 16) + 1, 1, v3);
    uint64_t *v1 = result;
  }
  return result;
}

uint64_t specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(uint64_t a1)
{
  return specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(a1, (uint64_t (*)(BOOL))specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:));
}

{
  return specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(a1, (uint64_t (*)(BOOL))specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:));
}

{
  return specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(a1, (uint64_t (*)(BOOL))specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:));
}

{
  return specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(a1, (uint64_t (*)(BOOL))specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:));
}

{
  return specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(a1, (uint64_t (*)(BOOL))specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:));
}

{
  return specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(a1, (uint64_t (*)(BOOL))specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:));
}

{
  return specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(a1, (uint64_t (*)(BOOL))specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:));
}

{
  return specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(a1, (uint64_t (*)(BOOL))specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:));
}

{
  return specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(a1, (uint64_t (*)(BOOL))specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:));
}

uint64_t _s8CreateML27MLTrainingSessionParametersVWOcTm_2(uint64_t a1, uint64_t a2, void (*a3)(void))
{
  a3(0);
  OUTLINED_FUNCTION_8();
  OUTLINED_FUNCTION_46_4();
  v4();
  return a2;
}

uint64_t specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(uint64_t result, uint64_t (*a2)(BOOL))
{
  unint64_t v3 = *(void *)(*(void *)v2 + 24);
  if (result + 1 > (uint64_t)(v3 >> 1))
  {
    uint64_t result = a2(v3 > 1);
    *(void *)uint64_t v2 = result;
  }
  return result;
}

uint64_t outlined init with take of MLCheckpoint(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = type metadata accessor for MLCheckpoint();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 32))(a2, a1, v4);
  return a2;
}

uint64_t _s10Foundation3URLVSgWOhTm_0(uint64_t a1, uint64_t *a2)
{
  __swift_instantiateConcreteTypeFromMangledName(a2);
  OUTLINED_FUNCTION_8();
  uint64_t v3 = OUTLINED_FUNCTION_22_1();
  v4(v3);
  return a1;
}

void *_sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5@<X0>(void *(*a1)(void *__return_ptr, uint64_t *)@<X0>, uint64_t a2@<X2>, char a3@<W3>, void *a4@<X8>)
{
  return _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5Tm(a1, a2, a3, (void (*)(void))type metadata accessor for MLCheckpoint, a4);
}

void *_sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_18CreateMLComponents5EventVTg5@<X0>(void *(*a1)(void *__return_ptr, uint64_t *)@<X0>, uint64_t a2@<X2>, char a3@<W3>, void *a4@<X8>)
{
  return _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5Tm(a1, a2, a3, MEMORY[0x263F044F0], a4);
}

void *_sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5Tm@<X0>(void *(*a1)(void *__return_ptr, uint64_t *)@<X0>, uint64_t a2@<X2>, char a3@<W3>, void (*a4)(void)@<X5>, void *a5@<X8>)
{
  if (a3)
  {
    a4(0);
    uint64_t v9 = OUTLINED_FUNCTION_9_21();
    return (void *)__swift_storeEnumTagSinglePayload(v9, v10, v11, v12);
  }
  else
  {
    uint64_t v14 = a2;
    uint64_t result = a1(a5, &v14);
    if (!v5)
    {
      uint64_t v13 = ((uint64_t (*)(void))a4)(0);
      return (void *)__swift_storeEnumTagSinglePayload((uint64_t)a5, 0, 1, v13);
    }
  }
  return result;
}

unint64_t specialized closure #1 in BidirectionalCollection.last(where:)@<X0>(unint64_t *a1@<X0>, uint64_t *a2@<X1>, uint64_t a3@<X8>)
{
  return specialized closure #1 in BidirectionalCollection.last(where:)(*a1, *a2, a3);
}

{
  return specialized closure #1 in BidirectionalCollection.last(where:)(*a1, *a2, a3);
}

uint64_t outlined destroy of MLCheckpoint(uint64_t a1, void (*a2)(void))
{
  a2(0);
  OUTLINED_FUNCTION_8();
  uint64_t v3 = OUTLINED_FUNCTION_22_1();
  v4(v3);
  return a1;
}

uint64_t sub_227136980@<X0>(unsigned char *a1@<X8>)
{
  return MLTrainingSession.phase.getter(a1);
}

void *sub_2271369AC(void *result, void *a2)
{
  *a2 = *result;
  return result;
}

uint64_t sub_2271369B8@<X0>(uint64_t *a1@<X8>)
{
  uint64_t result = MLTrainingSession.iteration.getter();
  *a1 = result;
  return result;
}

uint64_t sub_2271369E4(uint64_t *a1)
{
  return MLTrainingSession.iteration.setter(*a1);
}

uint64_t *initializeBufferWithCopyOfBuffer for MLTrainingSessionParameters(uint64_t *a1, uint64_t *a2, int *a3)
{
  int v5 = *(_DWORD *)(*((void *)a3 - 1) + 80);
  if ((v5 & 0x20000) != 0)
  {
    uint64_t v9 = *a2;
    *a1 = *a2;
    a1 = (uint64_t *)(v9 + ((v5 + 16) & ~(unint64_t)v5));
    swift_retain();
  }
  else
  {
    uint64_t v7 = type metadata accessor for URL();
    if (__swift_getEnumTagSinglePayload((uint64_t)a2, 1, v7))
    {
      uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
      memcpy(a1, a2, *(void *)(*(void *)(v8 - 8) + 64));
    }
    else
    {
      (*(void (**)(uint64_t *, uint64_t *, uint64_t))(*(void *)(v7 - 8) + 16))(a1, a2, v7);
      __swift_storeEnumTagSinglePayload((uint64_t)a1, 0, 1, v7);
    }
    uint64_t v10 = a3[6];
    *(uint64_t *)((char *)a1 + a3[5]) = *(uint64_t *)((char *)a2 + a3[5]);
    *(uint64_t *)((char *)a1 + v10) = *(uint64_t *)((char *)a2 + v10);
    *(uint64_t *)((char *)a1 + a3[7]) = *(uint64_t *)((char *)a2 + a3[7]);
  }
  return a1;
}

char *initializeWithCopy for MLTrainingSessionParameters(char *a1, char *a2, int *a3)
{
  uint64_t v6 = type metadata accessor for URL();
  if (__swift_getEnumTagSinglePayload((uint64_t)a2, 1, v6))
  {
    uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
    memcpy(a1, a2, *(void *)(*(void *)(v7 - 8) + 64));
  }
  else
  {
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v6 - 8) + 16))(a1, a2, v6);
    __swift_storeEnumTagSinglePayload((uint64_t)a1, 0, 1, v6);
  }
  uint64_t v8 = a3[6];
  *(void *)&a1[a3[5]] = *(void *)&a2[a3[5]];
  *(void *)&a1[v8] = *(void *)&a2[v8];
  *(void *)&a1[a3[7]] = *(void *)&a2[a3[7]];
  return a1;
}

char *assignWithCopy for MLTrainingSessionParameters(char *a1, char *a2, int *a3)
{
  uint64_t v6 = type metadata accessor for URL();
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)a1, 1, v6);
  int v8 = __swift_getEnumTagSinglePayload((uint64_t)a2, 1, v6);
  if (!EnumTagSinglePayload)
  {
    uint64_t v9 = *(void *)(v6 - 8);
    if (!v8)
    {
      (*(void (**)(char *, char *, uint64_t))(v9 + 24))(a1, a2, v6);
      goto LABEL_7;
    }
    (*(void (**)(char *, uint64_t))(v9 + 8))(a1, v6);
    goto LABEL_6;
  }
  if (v8)
  {
LABEL_6:
    uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
    memcpy(a1, a2, *(void *)(*(void *)(v10 - 8) + 64));
    goto LABEL_7;
  }
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v6 - 8) + 16))(a1, a2, v6);
  __swift_storeEnumTagSinglePayload((uint64_t)a1, 0, 1, v6);
LABEL_7:
  *(void *)&a1[a3[5]] = *(void *)&a2[a3[5]];
  *(void *)&a1[a3[6]] = *(void *)&a2[a3[6]];
  *(void *)&a1[a3[7]] = *(void *)&a2[a3[7]];
  return a1;
}

char *initializeWithTake for MLTrainingSessionParameters(char *a1, char *a2, int *a3)
{
  uint64_t v6 = type metadata accessor for URL();
  if (__swift_getEnumTagSinglePayload((uint64_t)a2, 1, v6))
  {
    uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
    memcpy(a1, a2, *(void *)(*(void *)(v7 - 8) + 64));
  }
  else
  {
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v6 - 8) + 32))(a1, a2, v6);
    __swift_storeEnumTagSinglePayload((uint64_t)a1, 0, 1, v6);
  }
  uint64_t v8 = a3[6];
  *(void *)&a1[a3[5]] = *(void *)&a2[a3[5]];
  *(void *)&a1[v8] = *(void *)&a2[v8];
  *(void *)&a1[a3[7]] = *(void *)&a2[a3[7]];
  return a1;
}

char *assignWithTake for MLTrainingSessionParameters(char *a1, char *a2, int *a3)
{
  uint64_t v6 = type metadata accessor for URL();
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)a1, 1, v6);
  int v8 = __swift_getEnumTagSinglePayload((uint64_t)a2, 1, v6);
  if (!EnumTagSinglePayload)
  {
    uint64_t v9 = *(void *)(v6 - 8);
    if (!v8)
    {
      (*(void (**)(char *, char *, uint64_t))(v9 + 40))(a1, a2, v6);
      goto LABEL_7;
    }
    (*(void (**)(char *, uint64_t))(v9 + 8))(a1, v6);
    goto LABEL_6;
  }
  if (v8)
  {
LABEL_6:
    uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
    memcpy(a1, a2, *(void *)(*(void *)(v10 - 8) + 64));
    goto LABEL_7;
  }
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v6 - 8) + 32))(a1, a2, v6);
  __swift_storeEnumTagSinglePayload((uint64_t)a1, 0, 1, v6);
LABEL_7:
  uint64_t v11 = a3[6];
  *(void *)&a1[a3[5]] = *(void *)&a2[a3[5]];
  *(void *)&a1[v11] = *(void *)&a2[v11];
  *(void *)&a1[a3[7]] = *(void *)&a2[a3[7]];
  return a1;
}

uint64_t getEnumTagSinglePayload for MLTrainingSessionParameters(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return MEMORY[0x270FA0340](a1, a2, a3, sub_227137024);
}

uint64_t sub_227137024(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);

  return __swift_getEnumTagSinglePayload(a1, a2, v4);
}

uint64_t storeEnumTagSinglePayload for MLTrainingSessionParameters(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return MEMORY[0x270FA0580](a1, a2, a3, a4, sub_227137084);
}

uint64_t sub_227137084(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);

  return __swift_storeEnumTagSinglePayload(a1, a2, a2, v4);
}

void type metadata completion function for MLTrainingSessionParameters()
{
  type metadata accessor for URL?();
  if (v0 <= 0x3F) {
    swift_initStructMetadata();
  }
}

void type metadata accessor for URL?()
{
  if (!lazy cache variable for type metadata for URL?)
  {
    type metadata accessor for URL();
    unint64_t v0 = type metadata accessor for Optional();
    if (!v1) {
      atomic_store(v0, (unint64_t *)&lazy cache variable for type metadata for URL?);
    }
  }
}

uint64_t type metadata instantiation function for MLTrainingSession()
{
  return MEMORY[0x270FA01A0]();
}

uint64_t type metadata completion function for MLTrainingSession()
{
  uint64_t result = type metadata accessor for MLTrainingSessionParameters();
  if (v1 <= 0x3F)
  {
    uint64_t result = type metadata accessor for MLTrainingSession.Metadata();
    if (v2 <= 0x3F)
    {
      uint64_t result = swift_initClassMetadata2();
      if (!result) {
        return 0;
      }
    }
  }
  return result;
}

uint64_t type metadata accessor for MLTrainingSession()
{
  return __swift_instantiateGenericMetadata();
}

uint64_t method lookup function for MLTrainingSession(uint64_t a1, uint64_t a2)
{
  return MEMORY[0x270FA04D0](a1, a2, &nominal type descriptor for MLTrainingSession);
}

void type metadata completion function for MLTrainingSession.Metadata()
{
  type metadata accessor for Date();
  if (v0 <= 0x3F)
  {
    type metadata accessor for URL?();
    if (v1 <= 0x3F) {
      swift_initStructMetadata();
    }
  }
}

void *initializeBufferWithCopyOfBuffer for MLTrainingSession.Metadata(void *a1, void *a2, int *a3)
{
  int v5 = *(_DWORD *)(*((void *)a3 - 1) + 80);
  if ((v5 & 0x20000) != 0)
  {
    uint64_t v14 = *a2;
    *a1 = *a2;
    a1 = (void *)(v14 + ((v5 + 16) & ~(unint64_t)v5));
    swift_retain();
  }
  else
  {
    uint64_t v7 = type metadata accessor for Date();
    (*(void (**)(void *, void *, uint64_t))(*(void *)(v7 - 8) + 16))(a1, a2, v7);
    uint64_t v8 = a3[8];
    *((unsigned char *)a1 + a3[7]) = *((unsigned char *)a2 + a3[7]);
    *(void *)((char *)a1 + v8) = *(void *)((char *)a2 + v8);
    uint64_t v9 = a3[9];
    uint64_t v10 = (char *)a1 + v9;
    uint64_t v11 = (char *)a2 + v9;
    uint64_t v12 = type metadata accessor for URL();
    if (__swift_getEnumTagSinglePayload((uint64_t)v11, 1, v12))
    {
      uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
      memcpy(v10, v11, *(void *)(*(void *)(v13 - 8) + 64));
    }
    else
    {
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 16))(v10, v11, v12);
      __swift_storeEnumTagSinglePayload((uint64_t)v10, 0, 1, v12);
    }
    uint64_t v15 = a3[10];
    uint64_t v16 = (char *)a1 + v15;
    uint64_t v17 = (char *)a2 + v15;
    if (__swift_getEnumTagSinglePayload((uint64_t)a2 + v15, 1, v12))
    {
      uint64_t v18 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
      memcpy(v16, v17, *(void *)(*(void *)(v18 - 8) + 64));
    }
    else
    {
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 16))(v16, v17, v12);
      __swift_storeEnumTagSinglePayload((uint64_t)v16, 0, 1, v12);
    }
    *(void *)((char *)a1 + a3[11]) = *(void *)((char *)a2 + a3[11]);
    swift_bridgeObjectRetain();
  }
  return a1;
}

uint64_t destroy for MLTrainingSession.Metadata(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = type metadata accessor for Date();
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v4 - 8) + 8))(a1, v4);
  uint64_t v5 = a1 + *(int *)(a2 + 36);
  uint64_t v6 = type metadata accessor for URL();
  if (!__swift_getEnumTagSinglePayload(v5, 1, v6)) {
    (*(void (**)(uint64_t, uint64_t))(*(void *)(v6 - 8) + 8))(v5, v6);
  }
  uint64_t v7 = a1 + *(int *)(a2 + 40);
  if (!__swift_getEnumTagSinglePayload(v7, 1, v6)) {
    (*(void (**)(uint64_t, uint64_t))(*(void *)(v6 - 8) + 8))(v7, v6);
  }

  return swift_bridgeObjectRelease();
}

uint64_t initializeWithCopy for MLTrainingSession.Metadata(uint64_t a1, uint64_t a2, int *a3)
{
  uint64_t v6 = type metadata accessor for Date();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v6 - 8) + 16))(a1, a2, v6);
  uint64_t v7 = a3[8];
  *(unsigned char *)(a1 + a3[7]) = *(unsigned char *)(a2 + a3[7]);
  *(void *)(a1 + v7) = *(void *)(a2 + v7);
  uint64_t v8 = a3[9];
  uint64_t v9 = (void *)(a1 + v8);
  uint64_t v10 = (const void *)(a2 + v8);
  uint64_t v11 = type metadata accessor for URL();
  if (__swift_getEnumTagSinglePayload((uint64_t)v10, 1, v11))
  {
    uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
    memcpy(v9, v10, *(void *)(*(void *)(v12 - 8) + 64));
  }
  else
  {
    (*(void (**)(void *, const void *, uint64_t))(*(void *)(v11 - 8) + 16))(v9, v10, v11);
    __swift_storeEnumTagSinglePayload((uint64_t)v9, 0, 1, v11);
  }
  uint64_t v13 = a3[10];
  uint64_t v14 = (void *)(a1 + v13);
  uint64_t v15 = (const void *)(a2 + v13);
  if (__swift_getEnumTagSinglePayload(a2 + v13, 1, v11))
  {
    uint64_t v16 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
    memcpy(v14, v15, *(void *)(*(void *)(v16 - 8) + 64));
  }
  else
  {
    (*(void (**)(void *, const void *, uint64_t))(*(void *)(v11 - 8) + 16))(v14, v15, v11);
    __swift_storeEnumTagSinglePayload((uint64_t)v14, 0, 1, v11);
  }
  *(void *)(a1 + a3[11]) = *(void *)(a2 + a3[11]);
  swift_bridgeObjectRetain();
  return a1;
}

uint64_t assignWithCopy for MLTrainingSession.Metadata(uint64_t a1, uint64_t a2, int *a3)
{
  uint64_t v6 = type metadata accessor for Date();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v6 - 8) + 24))(a1, a2, v6);
  *(unsigned char *)(a1 + a3[7]) = *(unsigned char *)(a2 + a3[7]);
  *(void *)(a1 + a3[8]) = *(void *)(a2 + a3[8]);
  uint64_t v7 = a3[9];
  uint64_t v8 = (void *)(a1 + v7);
  uint64_t v9 = (const void *)(a2 + v7);
  uint64_t v10 = type metadata accessor for URL();
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)v8, 1, v10);
  int v12 = __swift_getEnumTagSinglePayload((uint64_t)v9, 1, v10);
  if (EnumTagSinglePayload)
  {
    if (!v12)
    {
      (*(void (**)(void *, const void *, uint64_t))(*(void *)(v10 - 8) + 16))(v8, v9, v10);
      __swift_storeEnumTagSinglePayload((uint64_t)v8, 0, 1, v10);
      goto LABEL_7;
    }
    goto LABEL_6;
  }
  uint64_t v13 = *(void *)(v10 - 8);
  if (v12)
  {
    (*(void (**)(void *, uint64_t))(v13 + 8))(v8, v10);
LABEL_6:
    uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
    memcpy(v8, v9, *(void *)(*(void *)(v14 - 8) + 64));
    goto LABEL_7;
  }
  (*(void (**)(void *, const void *, uint64_t))(v13 + 24))(v8, v9, v10);
LABEL_7:
  uint64_t v15 = a3[10];
  uint64_t v16 = (void *)(a1 + v15);
  uint64_t v17 = (const void *)(a2 + v15);
  int v18 = __swift_getEnumTagSinglePayload(a1 + v15, 1, v10);
  int v19 = __swift_getEnumTagSinglePayload((uint64_t)v17, 1, v10);
  if (!v18)
  {
    uint64_t v20 = *(void *)(v10 - 8);
    if (!v19)
    {
      (*(void (**)(void *, const void *, uint64_t))(v20 + 24))(v16, v17, v10);
      goto LABEL_13;
    }
    (*(void (**)(void *, uint64_t))(v20 + 8))(v16, v10);
    goto LABEL_12;
  }
  if (v19)
  {
LABEL_12:
    uint64_t v21 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
    memcpy(v16, v17, *(void *)(*(void *)(v21 - 8) + 64));
    goto LABEL_13;
  }
  (*(void (**)(void *, const void *, uint64_t))(*(void *)(v10 - 8) + 16))(v16, v17, v10);
  __swift_storeEnumTagSinglePayload((uint64_t)v16, 0, 1, v10);
LABEL_13:
  *(void *)(a1 + a3[11]) = *(void *)(a2 + a3[11]);
  swift_bridgeObjectRetain();
  swift_bridgeObjectRelease();
  return a1;
}

uint64_t initializeWithTake for MLTrainingSession.Metadata(uint64_t a1, uint64_t a2, int *a3)
{
  uint64_t v6 = type metadata accessor for Date();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v6 - 8) + 32))(a1, a2, v6);
  uint64_t v7 = a3[8];
  *(unsigned char *)(a1 + a3[7]) = *(unsigned char *)(a2 + a3[7]);
  *(void *)(a1 + v7) = *(void *)(a2 + v7);
  uint64_t v8 = a3[9];
  uint64_t v9 = (void *)(a1 + v8);
  uint64_t v10 = (const void *)(a2 + v8);
  uint64_t v11 = type metadata accessor for URL();
  if (__swift_getEnumTagSinglePayload((uint64_t)v10, 1, v11))
  {
    uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
    memcpy(v9, v10, *(void *)(*(void *)(v12 - 8) + 64));
  }
  else
  {
    (*(void (**)(void *, const void *, uint64_t))(*(void *)(v11 - 8) + 32))(v9, v10, v11);
    __swift_storeEnumTagSinglePayload((uint64_t)v9, 0, 1, v11);
  }
  uint64_t v13 = a3[10];
  uint64_t v14 = (void *)(a1 + v13);
  uint64_t v15 = (const void *)(a2 + v13);
  if (__swift_getEnumTagSinglePayload(a2 + v13, 1, v11))
  {
    uint64_t v16 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
    memcpy(v14, v15, *(void *)(*(void *)(v16 - 8) + 64));
  }
  else
  {
    (*(void (**)(void *, const void *, uint64_t))(*(void *)(v11 - 8) + 32))(v14, v15, v11);
    __swift_storeEnumTagSinglePayload((uint64_t)v14, 0, 1, v11);
  }
  *(void *)(a1 + a3[11]) = *(void *)(a2 + a3[11]);
  return a1;
}

uint64_t assignWithTake for MLTrainingSession.Metadata(uint64_t a1, uint64_t a2, int *a3)
{
  uint64_t v6 = type metadata accessor for Date();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v6 - 8) + 40))(a1, a2, v6);
  uint64_t v7 = a3[8];
  *(unsigned char *)(a1 + a3[7]) = *(unsigned char *)(a2 + a3[7]);
  *(void *)(a1 + v7) = *(void *)(a2 + v7);
  uint64_t v8 = a3[9];
  uint64_t v9 = (void *)(a1 + v8);
  uint64_t v10 = (const void *)(a2 + v8);
  uint64_t v11 = type metadata accessor for URL();
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)v9, 1, v11);
  int v13 = __swift_getEnumTagSinglePayload((uint64_t)v10, 1, v11);
  if (EnumTagSinglePayload)
  {
    if (!v13)
    {
      (*(void (**)(void *, const void *, uint64_t))(*(void *)(v11 - 8) + 32))(v9, v10, v11);
      __swift_storeEnumTagSinglePayload((uint64_t)v9, 0, 1, v11);
      goto LABEL_7;
    }
    goto LABEL_6;
  }
  uint64_t v14 = *(void *)(v11 - 8);
  if (v13)
  {
    (*(void (**)(void *, uint64_t))(v14 + 8))(v9, v11);
LABEL_6:
    uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
    memcpy(v9, v10, *(void *)(*(void *)(v15 - 8) + 64));
    goto LABEL_7;
  }
  (*(void (**)(void *, const void *, uint64_t))(v14 + 40))(v9, v10, v11);
LABEL_7:
  uint64_t v16 = a3[10];
  uint64_t v17 = (void *)(a1 + v16);
  int v18 = (const void *)(a2 + v16);
  int v19 = __swift_getEnumTagSinglePayload(a1 + v16, 1, v11);
  int v20 = __swift_getEnumTagSinglePayload((uint64_t)v18, 1, v11);
  if (!v19)
  {
    uint64_t v21 = *(void *)(v11 - 8);
    if (!v20)
    {
      (*(void (**)(void *, const void *, uint64_t))(v21 + 40))(v17, v18, v11);
      goto LABEL_13;
    }
    (*(void (**)(void *, uint64_t))(v21 + 8))(v17, v11);
    goto LABEL_12;
  }
  if (v20)
  {
LABEL_12:
    uint64_t v22 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
    memcpy(v17, v18, *(void *)(*(void *)(v22 - 8) + 64));
    goto LABEL_13;
  }
  (*(void (**)(void *, const void *, uint64_t))(*(void *)(v11 - 8) + 32))(v17, v18, v11);
  __swift_storeEnumTagSinglePayload((uint64_t)v17, 0, 1, v11);
LABEL_13:
  *(void *)(a1 + a3[11]) = *(void *)(a2 + a3[11]);
  swift_bridgeObjectRelease();
  return a1;
}

uint64_t getEnumTagSinglePayload for MLTrainingSession.Metadata(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return MEMORY[0x270FA0340](a1, a2, a3, sub_2271380AC);
}

uint64_t sub_2271380AC(uint64_t a1, uint64_t a2, uint64_t a3)
{
  type metadata accessor for Date();
  OUTLINED_FUNCTION_6_1();
  if (*(_DWORD *)(v7 + 84) == a2)
  {
    uint64_t v8 = v6;
    uint64_t v9 = a1;
LABEL_5:
    return __swift_getEnumTagSinglePayload(v9, a2, v8);
  }
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  OUTLINED_FUNCTION_6_1();
  if (*(_DWORD *)(v11 + 84) == a2)
  {
    uint64_t v8 = v10;
    uint64_t v9 = a1 + *(int *)(a3 + 36);
    goto LABEL_5;
  }
  unint64_t v13 = *(void *)(a1 + *(int *)(a3 + 44));
  if (v13 >= 0xFFFFFFFF) {
    LODWORD(v13) = -1;
  }
  return (v13 + 1);
}

uint64_t storeEnumTagSinglePayload for MLTrainingSession.Metadata(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return MEMORY[0x270FA0580](a1, a2, a3, a4, sub_227138178);
}

void sub_227138178(uint64_t a1, uint64_t a2, int a3, uint64_t a4)
{
  type metadata accessor for Date();
  OUTLINED_FUNCTION_6_1();
  if (*(_DWORD *)(v9 + 84) == a3)
  {
    uint64_t v10 = v8;
    uint64_t v11 = a1;
  }
  else
  {
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
    OUTLINED_FUNCTION_6_1();
    if (*(_DWORD *)(v13 + 84) != a3)
    {
      *(void *)(a1 + *(int *)(a4 + 44)) = (a2 - 1);
      return;
    }
    uint64_t v10 = v12;
    uint64_t v11 = a1 + *(int *)(a4 + 36);
  }

  __swift_storeEnumTagSinglePayload(v11, a2, a2, v10);
}

uint64_t type metadata accessor for MLTrainingSession.Metadata.CodingKeys()
{
  return __swift_instantiateGenericMetadata();
}

uint64_t outlined assign with take of URL?(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 40))(a2, a1, v4);
  return a2;
}

uint64_t lazy protocol witness table accessor for type [MLCheckpoint] and conformance <A> [A](unint64_t *a1, unint64_t *a2)
{
  uint64_t result = *a1;
  if (!result)
  {
    __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for [MLCheckpoint]);
    lazy protocol witness table accessor for type Date and conformance Date(a2, (void (*)(uint64_t))type metadata accessor for MLCheckpoint);
    uint64_t result = swift_getWitnessTable();
    atomic_store(result, a1);
  }
  return result;
}

uint64_t lazy protocol witness table accessor for type Date and conformance Date(unint64_t *a1, void (*a2)(uint64_t))
{
  uint64_t result = *a1;
  if (!result)
  {
    a2(255);
    uint64_t result = swift_getWitnessTable();
    atomic_store(result, a1);
  }
  return result;
}

uint64_t type metadata instantiation function for MLTrainingSession.Metadata.CodingKeys(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return MEMORY[0x270FA01A8](a1, a2, a3, 8);
}

unsigned char *storeEnumTagSinglePayload for MLTrainingSession.Metadata.CodingKeys(unsigned char *result, unsigned int a2, unsigned int a3)
{
  if (a3 + 5 >= 0xFFFF00) {
    int v3 = 4;
  }
  else {
    int v3 = 2;
  }
  if ((a3 + 5) >> 8 < 0xFF) {
    unsigned int v4 = 1;
  }
  else {
    unsigned int v4 = v3;
  }
  if (a3 >= 0xFB) {
    uint64_t v5 = v4;
  }
  else {
    uint64_t v5 = 0;
  }
  if (a2 > 0xFA)
  {
    unsigned int v6 = ((a2 - 251) >> 8) + 1;
    *uint64_t result = a2 + 5;
    switch(v5)
    {
      case 1:
        result[1] = v6;
        break;
      case 2:
        *(_WORD *)(result + 1) = v6;
        break;
      case 3:
LABEL_23:
        __break(1u);
        JUMPOUT(0x22713845CLL);
      case 4:
        *(_DWORD *)(result + 1) = v6;
        break;
      default:
        return result;
    }
  }
  else
  {
    switch(v5)
    {
      case 1:
        result[1] = 0;
        if (!a2) {
          return result;
        }
        goto LABEL_18;
      case 2:
        *(_WORD *)(result + 1) = 0;
        goto LABEL_17;
      case 3:
        goto LABEL_23;
      case 4:
        *(_DWORD *)(result + 1) = 0;
        if (!a2) {
          return result;
        }
        goto LABEL_18;
      default:
LABEL_17:
        if (a2) {
LABEL_18:
        }
          *uint64_t result = a2 + 5;
        break;
    }
  }
  return result;
}

uint64_t base witness table accessor for Equatable in MLTrainingSession<A>.Metadata.CodingKeys()
{
  return swift_getWitnessTable();
}

uint64_t base witness table accessor for CustomDebugStringConvertible in MLTrainingSession<A>.Metadata.CodingKeys()
{
  return swift_getWitnessTable();
}

uint64_t base witness table accessor for CustomStringConvertible in MLTrainingSession<A>.Metadata.CodingKeys()
{
  return swift_getWitnessTable();
}

uint64_t OUTLINED_FUNCTION_9_21()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_11_18()
{
  return type metadata accessor for MLTrainingSessionParameters();
}

uint64_t OUTLINED_FUNCTION_12_14(uint64_t a1, uint64_t a2)
{
  return MEMORY[0x270F9F3E0](a1, a2, v4, v2, v3);
}

uint64_t OUTLINED_FUNCTION_13_21()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_14_14()
{
  return swift_beginAccess();
}

uint64_t OUTLINED_FUNCTION_20_14()
{
  return 8;
}

uint64_t OUTLINED_FUNCTION_22_12()
{
  return KeyedDecodingContainer.decodeIfPresent<A>(_:forKey:)();
}

uint64_t OUTLINED_FUNCTION_23_5()
{
  return v0;
}

uint64_t MLTextClassifier.write(to:metadata:)(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = *(void *)(a2 + 64);
  long long v3 = *(_OWORD *)(a2 + 16);
  v6[0] = *(_OWORD *)a2;
  v6[1] = v3;
  long long v4 = *(_OWORD *)(a2 + 48);
  _OWORD v6[2] = *(_OWORD *)(a2 + 32);
  v6[3] = v4;
  uint64_t v7 = v2;
  return NLModel.write(to:defaultName:metadata:)(a1, 0x73616C4374786554, (void *)0xEE00726569666973, (uint64_t *)v6);
}

uint64_t MLTextClassifier.write(toFile:metadata:)(uint64_t a1, void *a2, uint64_t a3)
{
  uint64_t v3 = *(void *)(a3 + 64);
  long long v4 = *(_OWORD *)(a3 + 16);
  v7[0] = *(_OWORD *)a3;
  v7[1] = v4;
  long long v5 = *(_OWORD *)(a3 + 48);
  v7[2] = *(_OWORD *)(a3 + 32);
  v7[3] = v5;
  uint64_t v8 = v3;
  return NLModel.write(toFile:defaultName:metadata:)(a1, a2, 0x73616C4374786554, (void *)0xEE00726569666973, (uint64_t *)v7);
}

uint64_t _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents16AnnotatedFeatureVySo7CIImageCSSGG_AJs5NeverOTg503_s8d87ML17MLImageClassifierV10evaluation2onAA19MLClassifierMetricsVx_tKSlRz0A12MLComponents16fg5VySo7h5CSSG7B59RtzlFAlMcfu_32ebed8ba5c9417264c39088de476e42ecAmLTf3nnnpk_nTf1cn_n(uint64_t a1)
{
  uint64_t v2 = *(void *)(a1 + 16);
  uint64_t result = MEMORY[0x263F8EE78];
  if (v2)
  {
    uint64_t v7 = MEMORY[0x263F8EE78];
    specialized ContiguousArray.reserveCapacity(_:)();
    uint64_t v4 = *(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<CIImage, String>)
                   - 8);
    uint64_t v5 = a1 + ((*(unsigned __int8 *)(v4 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v4 + 80));
    uint64_t v6 = *(void *)(v4 + 72);
    do
    {
      swift_getKeyPath();
      swift_getAtKeyPath();
      swift_release();
      specialized ContiguousArray._makeUniqueAndReserveCapacityIfNotUnique()();
      specialized ContiguousArray._reserveCapacityAssumingUniqueBuffer(oldCount:)();
      specialized ContiguousArray._appendElementAssumeUniqueAndCapacity(_:newElement:)();
      specialized ContiguousArray._endMutation()();
      v5 += v6;
      --v2;
    }
    while (v2);
    return v7;
  }
  return result;
}

uint64_t _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents16AnnotatedFeatureVySo7CIImageCSSGG_SSs5NeverOTg503_s8d87ML17MLImageClassifierV10evaluation2onAA19MLClassifierMetricsVx_tKSlRz0A12MLComponents16fg5VySo7h5CSSG7B63RtzlFSSAMcfu0_33_7eec49b2e7313abe927b434220475ef8AMSSTf3nnnpk_nTf1cn_n(uint64_t a1)
{
  uint64_t v1 = *(void *)(a1 + 16);
  uint64_t v2 = MEMORY[0x263F8EE78];
  if (v1)
  {
    uint64_t v12 = MEMORY[0x263F8EE78];
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
    uint64_t v4 = *(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<CIImage, String>)
                   - 8);
    uint64_t v5 = a1 + ((*(unsigned __int8 *)(v4 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v4 + 80));
    uint64_t v6 = *(void *)(v4 + 72);
    do
    {
      swift_getKeyPath();
      swift_getAtKeyPath();
      swift_release();
      uint64_t v2 = v12;
      if ((swift_isUniquelyReferenced_nonNull_native() & 1) == 0)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
        uint64_t v2 = v12;
      }
      unint64_t v7 = *(void *)(v2 + 16);
      if (v7 >= *(void *)(v2 + 24) >> 1)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
        uint64_t v2 = v12;
      }
      *(void *)(v2 + 16) = v7 + 1;
      uint64_t v8 = v2 + 16 * v7;
      *(void *)(v8 + 32) = v10;
      *(void *)(v8 + 40) = v11;
      v5 += v6;
      --v1;
    }
    while (v1);
  }
  return v2;
}

uint64_t static MLImageClassifier._defaultSessionParameters.getter@<X0>(uint64_t a1@<X8>)
{
  if (one-time initialization token for _defaultSessionParameters != -1) {
    swift_once();
  }
  uint64_t v2 = type metadata accessor for MLTrainingSessionParameters();
  uint64_t v3 = __swift_project_value_buffer(v2, (uint64_t)static MLImageClassifier._defaultSessionParameters);
  return _s8CreateML27MLTrainingSessionParametersVWOcTm_3(v3, a1, (void (*)(void))type metadata accessor for MLTrainingSessionParameters);
}

id MLImageClassifier.model.getter()
{
  return *v0;
}

void key path setter for MLImageClassifier.model : MLImageClassifier(id *a1)
{
}

void MLImageClassifier.model.setter(void *a1)
{
  id *v1 = a1;
}

uint64_t MLImageClassifier.model.modify(void **a1)
{
  uint64_t v2 = *v1;
  *a1 = *v1;
  a1[1] = v1;
  id v3 = v2;
  return OUTLINED_FUNCTION_27_11();
}

void MLImageClassifier.model.modify(uint64_t a1, char a2)
{
  id v3 = *(void **)a1;
  uint64_t v2 = *(void ***)(a1 + 8);
  uint64_t v4 = *v2;
  if (a2)
  {
    id v5 = v3;

    *uint64_t v2 = v5;
  }
  else
  {

    *uint64_t v2 = v3;
  }
}

uint64_t MLImageClassifier.modelParameters.getter@<X0>(uint64_t a1@<X8>)
{
  return outlined init with copy of MLImageClassifier.ModelParameters((long long *)(v1 + 8), a1);
}

uint64_t MLImageClassifier.trainingMetrics.getter@<X0>(uint64_t a1@<X8>)
{
  uint64_t v3 = type metadata accessor for MLImageClassifier();
  return _s8CreateML27MLTrainingSessionParametersVWOcTm_3(v1 + *(int *)(v3 + 24), a1, (void (*)(void))type metadata accessor for MLClassifierMetrics);
}

uint64_t type metadata accessor for MLImageClassifier()
{
  uint64_t result = type metadata singleton initialization cache for MLImageClassifier;
  if (!type metadata singleton initialization cache for MLImageClassifier) {
    return swift_getSingletonMetadata();
  }
  return result;
}

uint64_t MLImageClassifier.validationMetrics.getter@<X0>(uint64_t a1@<X8>)
{
  uint64_t v3 = type metadata accessor for MLImageClassifier();
  return _s8CreateML27MLTrainingSessionParametersVWOcTm_3(v1 + *(int *)(v3 + 28), a1, (void (*)(void))type metadata accessor for MLClassifierMetrics);
}

uint64_t MLImageClassifier.init(trainingData:parameters:)@<X0>(uint64_t a1@<X0>, long long *a2@<X1>, uint64_t a3@<X8>)
{
  uint64_t v7 = type metadata accessor for MLImageClassifier();
  uint64_t v8 = v7 - 8;
  MEMORY[0x270FA5388](v7);
  OUTLINED_FUNCTION_3_0();
  uint64_t v11 = v10 - v9;
  uint64_t v12 = a3 + *(int *)(v8 + 32);
  MLClassifierMetrics.init()(v13, v14, v15, v16, v17, v18, v19, v20, __src[0], __src[1], __src[2], __src[3], __src[4], __src[5], __src[6], __src[7], __src[8], __src[9], __src[10],
    __src[11]);
  uint64_t v21 = (void *)(a3 + *(int *)(v8 + 36));
  lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  swift_allocError();
  OUTLINED_FUNCTION_32_2(v22, 0xD0000000000000C0);
  *uint64_t v21 = v23;
  type metadata accessor for MLClassifierMetrics.Contents(0);
  swift_storeEnumTagMultiPayload();
  uint64_t v24 = static _ImageUtilities.getImageURLsAndLabels(from:)(a1);
  if (v3)
  {
    outlined destroy of MLImageClassifier.ModelParameters((uint64_t)a2);
    outlined destroy of MLImageClassifier.DataSource(a1, (void (*)(void))type metadata accessor for MLImageClassifier.DataSource);
    outlined destroy of MLImageClassifier.DataSource(v12, (void (*)(void))type metadata accessor for MLClassifierMetrics);
    uint64_t v27 = OUTLINED_FUNCTION_27_11();
    return outlined destroy of MLImageClassifier.DataSource(v27, v28);
  }
  else
  {
    uint64_t v25 = v24;
    outlined init with copy of MLImageClassifier.ModelParameters(a2, (uint64_t)__src);
    uint64_t v26 = swift_allocObject();
    *(void *)(v26 + 16) = v25;
    memcpy((void *)(v26 + 24), __src, 0x50uLL);
    specialized blockAwait<A>(_:)();
    swift_release();
    outlined destroy of MLImageClassifier.ModelParameters((uint64_t)a2);
    outlined destroy of MLImageClassifier.DataSource(a1, (void (*)(void))type metadata accessor for MLImageClassifier.DataSource);
    outlined destroy of MLImageClassifier.DataSource(v12, (void (*)(void))type metadata accessor for MLClassifierMetrics);
    outlined destroy of MLImageClassifier.DataSource((uint64_t)v21, (void (*)(void))type metadata accessor for MLClassifierMetrics);
    return outlined init with take of MLImageClassifier(v11, a3, (void (*)(void))type metadata accessor for MLImageClassifier);
  }
}

{
  uint64_t v3;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  void *v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t result;
  uint64_t v23;
  uint64_t v24;
  void (*v25)(void);
  uint64_t __src[12];

  uint64_t v7 = type metadata accessor for MLImageClassifier();
  uint64_t v8 = v7 - 8;
  MEMORY[0x270FA5388](v7);
  OUTLINED_FUNCTION_3_0();
  uint64_t v9 = a3 + *(int *)(v8 + 32);
  MLClassifierMetrics.init()(v10, v11, v12, v13, v14, v15, v16, v17, __src[0], __src[1], __src[2], __src[3], __src[4], __src[5], __src[6], __src[7], __src[8], __src[9], __src[10],
    __src[11]);
  uint64_t v18 = (void *)(a3 + *(int *)(v8 + 36));
  lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  swift_allocError();
  OUTLINED_FUNCTION_32_2(v19, 0xD0000000000000C0);
  *uint64_t v18 = v20;
  type metadata accessor for MLClassifierMetrics.Contents(0);
  swift_storeEnumTagMultiPayload();
  outlined init with copy of MLImageClassifier.ModelParameters(a2, (uint64_t)__src);
  uint64_t v21 = swift_allocObject();
  *(void *)(v21 + 16) = a1;
  memcpy((void *)(v21 + 24), __src, 0x50uLL);
  specialized blockAwait<A>(_:)();
  outlined destroy of MLImageClassifier.ModelParameters((uint64_t)a2);
  swift_release();
  outlined destroy of MLImageClassifier.DataSource(v9, (void (*)(void))type metadata accessor for MLClassifierMetrics);
  uint64_t result = outlined destroy of MLImageClassifier.DataSource((uint64_t)v18, (void (*)(void))type metadata accessor for MLClassifierMetrics);
  if (!v3)
  {
    uint64_t v23 = OUTLINED_FUNCTION_27_11();
    return outlined init with take of MLImageClassifier(v23, v24, v25);
  }
  return result;
}

uint64_t closure #1 in MLImageClassifier.init(trainingData:parameters:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  v3[13] = a2;
  v3[14] = a3;
  v3[12] = a1;
  return MEMORY[0x270FA2498](closure #1 in MLImageClassifier.init(trainingData:parameters:), 0, 0);
}

{
  void *v3;

  v3[13] = a2;
  v3[14] = a3;
  v3[12] = a1;
  return MEMORY[0x270FA2498](closure #1 in MLImageClassifier.init(trainingData:parameters:), 0, 0);
}

uint64_t closure #1 in MLImageClassifier.init(trainingData:parameters:)()
{
  OUTLINED_FUNCTION_25();
  OUTLINED_FUNCTION_38_8();
  outlined init with copy of MLImageClassifier.ModelParameters(v0, v1);
  uint64_t v3 = swift_bridgeObjectRetain();
  specialized Set.init<A>(_:)(v3);
  uint64_t v4 = (void *)swift_task_alloc();
  *(void *)(v2 + 120) = v4;
  *uint64_t v4 = v2;
  v4[1] = closure #1 in MLImageClassifier.init(trainingData:parameters:);
  OUTLINED_FUNCTION_31_7();
  return MLImageClassifier.init(trainingData:parameters:classNames:)();
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  void *v3;
  uint64_t v4;
  void *v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t (*v10)(void);
  uint64_t v12;

  OUTLINED_FUNCTION_11();
  OUTLINED_FUNCTION_2();
  OUTLINED_FUNCTION_7();
  *uint64_t v3 = v2;
  uint64_t v4 = *v1;
  OUTLINED_FUNCTION_7();
  *id v5 = v4;
  *(void *)(v6 + 128) = v0;
  swift_task_dealloc();
  if (v0)
  {
    OUTLINED_FUNCTION_14();
    return MEMORY[0x270FA2498](v7, v8, v9);
  }
  else
  {
    OUTLINED_FUNCTION_30();
    return v10();
  }
}

{
  uint64_t (*v0)(void);

  OUTLINED_FUNCTION_30();
  return v0();
}

{
  long long *v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  void *v4;
  uint64_t v6;

  OUTLINED_FUNCTION_25();
  OUTLINED_FUNCTION_38_8();
  outlined init with copy of MLImageClassifier.ModelParameters(v0, v1);
  uint64_t v3 = swift_bridgeObjectRetain();
  specialized Set.init<A>(_:)(v3);
  uint64_t v4 = (void *)swift_task_alloc();
  *(void *)(v2 + 120) = v4;
  *uint64_t v4 = v2;
  v4[1] = closure #1 in MLImageClassifier.init(trainingData:parameters:);
  OUTLINED_FUNCTION_31_7();
  return MLImageClassifier.init(trainingData:parameters:classNames:)();
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  void *v3;
  uint64_t v4;
  void *v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t (*v10)(void);
  uint64_t v12;

  OUTLINED_FUNCTION_11();
  OUTLINED_FUNCTION_2();
  OUTLINED_FUNCTION_7();
  *uint64_t v3 = v2;
  uint64_t v4 = *v1;
  OUTLINED_FUNCTION_7();
  *id v5 = v4;
  *(void *)(v6 + 128) = v0;
  swift_task_dealloc();
  if (v0)
  {
    OUTLINED_FUNCTION_14();
    return MEMORY[0x270FA2498](v7, v8, v9);
  }
  else
  {
    OUTLINED_FUNCTION_30();
    return v10();
  }
}

uint64_t MLImageClassifier.init(trainingData:parameters:classNames:)()
{
  OUTLINED_FUNCTION_11();
  v0[27] = v1;
  v0[28] = v2;
  v0[25] = v3;
  v0[26] = v4;
  uint64_t v5 = type metadata accessor for MLClassifierMetrics(0);
  OUTLINED_FUNCTION_17(v5);
  v0[29] = OUTLINED_FUNCTION_24();
  v0[30] = swift_task_alloc();
  uint64_t v6 = type metadata accessor for MLImageClassifier.Model();
  OUTLINED_FUNCTION_17(v6);
  v0[31] = OUTLINED_FUNCTION_24();
  v0[32] = swift_task_alloc();
  uint64_t v7 = type metadata accessor for MLImageClassifier.ModelParameters.ValidationData();
  v0[33] = v7;
  OUTLINED_FUNCTION_1(v7);
  v0[34] = v8;
  v0[35] = *(void *)(v9 + 64);
  v0[36] = OUTLINED_FUNCTION_24();
  v0[37] = swift_task_alloc();
  uint64_t v10 = type metadata accessor for MLImageClassifier.FeatureExtractorType(0);
  OUTLINED_FUNCTION_17(v10);
  v0[38] = OUTLINED_FUNCTION_24();
  v0[39] = swift_task_alloc();
  uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifier<Float, String>);
  v0[40] = v11;
  OUTLINED_FUNCTION_1(v11);
  v0[41] = v12;
  v0[42] = OUTLINED_FUNCTION_5();
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifier<Float, String>.Configuration);
  v0[43] = v13;
  OUTLINED_FUNCTION_1(v13);
  v0[44] = v14;
  v0[45] = OUTLINED_FUNCTION_24();
  v0[46] = swift_task_alloc();
  uint64_t v15 = type metadata accessor for MLImageClassifier.ModelParameters.ModelAlgorithmType();
  OUTLINED_FUNCTION_17(v15);
  v0[47] = OUTLINED_FUNCTION_24();
  v0[48] = swift_task_alloc();
  uint64_t v16 = type metadata accessor for MLImageClassifier.Classifier();
  OUTLINED_FUNCTION_17(v16);
  v0[49] = OUTLINED_FUNCTION_24();
  v0[50] = swift_task_alloc();
  OUTLINED_FUNCTION_14();
  return MEMORY[0x270FA2498](v17, v18, v19);
}

{
  uint64_t v0;
  long long *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  void *v12;
  uint64_t v13;
  uint64_t v14;
  long long *v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t (*v19)(void);
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  void *v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v34;
  uint64_t v35;
  uint64_t v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  uint64_t v42;
  uint64_t v43;
  uint64_t v44;
  uint64_t v45;
  uint64_t v46;

  uint64_t v1 = *(long long **)(v0 + 216);
  uint64_t v2 = *(void *)(v0 + 200);
  uint64_t v3 = type metadata accessor for MLImageClassifier();
  *(void *)(v0 + 408) = v3;
  *(_DWORD *)(v0 + 584) = *(_DWORD *)(v3 + 24);
  MLClassifierMetrics.init()(v3, v4, v5, v6, v7, v8, v9, v10, v28, v29, v30, v32, v34, v36, v37, v39, v41, v43, v44,
    v45);
  uint64_t v11 = *(int *)(v3 + 28);
  *(_DWORD *)(v0 + 588) = v11;
  uint64_t v12 = (void *)(v2 + v11);
  lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  swift_allocError();
  OUTLINED_FUNCTION_32_2(v13, 0xD0000000000000C0);
  *uint64_t v12 = v14;
  type metadata accessor for MLClassifierMetrics.Contents(0);
  swift_storeEnumTagMultiPayload();
  uint64_t v15 = (long long *)(v2 + 8);
  outlined init with copy of MLImageClassifier.ModelParameters(v1, v2 + 8);
  MLImageClassifier.ModelParameters.validate()();
  if (v16)
  {
    uint64_t v17 = *(void *)(v0 + 224);
    uint64_t v18 = *(void *)(v0 + 208);
    outlined destroy of MLImageClassifier.ModelParameters(*(void *)(v0 + 216));
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    OUTLINED_FUNCTION_15_14();
    outlined destroy of MLImageClassifier.DataSource(v18, (void (*)(void))type metadata accessor for MLClassifierMetrics);
    outlined destroy of MLImageClassifier.DataSource(v17, (void (*)(void))type metadata accessor for MLClassifierMetrics);
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    OUTLINED_FUNCTION_30();
    return v19();
  }
  else
  {
    uint64_t v21 = *(void *)(v0 + 384);
    uint64_t v38 = *(void *)(v0 + 392);
    uint64_t v40 = *(void *)(v0 + 400);
    uint64_t v23 = *(void *)(v0 + 360);
    uint64_t v22 = *(void *)(v0 + 368);
    uint64_t v24 = *(void *)(v0 + 344);
    uint64_t v25 = *(void *)(v0 + 352);
    uint64_t v31 = *(void *)(v0 + 336);
    uint64_t v33 = *(void *)(v0 + 328);
    uint64_t v35 = *(void *)(v0 + 320);
    uint64_t v42 = *(void *)(v0 + 312);
    outlined init with copy of MLImageClassifier.ModelParameters(v15, v0 + 16);
    swift_bridgeObjectRetain();
    MLImageClassifier.ModelParameters.algorithm.getter(v21);
    lazy protocol witness table accessor for type Float and conformance Float();
    LogisticRegressionClassifier.Configuration.init()();
    LogisticRegressionClassifier.Configuration.maximumIterations.setter();
    (*(void (**)(uint64_t, uint64_t, uint64_t))(v25 + 16))(v23, v22, v24);
    LogisticRegressionClassifier.init(labels:configuration:)();
    outlined destroy of MLImageClassifier.ModelParameters(v0 + 16);
    (*(void (**)(uint64_t, uint64_t))(v25 + 8))(v22, v24);
    (*(void (**)(uint64_t, uint64_t, uint64_t))(v33 + 32))(v38, v31, v35);
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
    swift_storeEnumTagMultiPayload();
    outlined destroy of MLImageClassifier.DataSource(v21, (void (*)(void))type metadata accessor for MLImageClassifier.FeatureExtractorType);
    outlined init with take of MLImageClassifier(v38, v40, (void (*)(void))type metadata accessor for MLImageClassifier.Classifier);
    MLImageClassifier.ModelParameters.algorithm.getter(v21);
    outlined init with take of MLImageClassifier(v21, v42, (void (*)(void))type metadata accessor for MLImageClassifier.FeatureExtractorType);
    uint64_t v26 = (void *)swift_task_alloc();
    *(void *)(v0 + 416) = v26;
    *uint64_t v26 = v0;
    v26[1] = MLImageClassifier.init(trainingData:parameters:classNames:);
    uint64_t v27 = *(void *)(v0 + 312);
    return MLImageClassifier.FeatureExtractor.init(type:)(v0 + 96, v27);
  }
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  uint64_t v3;
  void *v4;
  uint64_t v5;
  void *v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v11;

  OUTLINED_FUNCTION_11();
  OUTLINED_FUNCTION_2();
  uint64_t v3 = v2;
  OUTLINED_FUNCTION_7();
  *uint64_t v4 = v3;
  uint64_t v5 = *v1;
  OUTLINED_FUNCTION_7();
  *uint64_t v6 = v5;
  *(void *)(v3 + 424) = v0;
  swift_task_dealloc();
  if (v0)
  {
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
  }
  OUTLINED_FUNCTION_14();
  return MEMORY[0x270FA2498](v7, v8, v9);
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  void *v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v10;

  OUTLINED_FUNCTION_11();
  OUTLINED_FUNCTION_2();
  uint64_t v3 = v2;
  OUTLINED_FUNCTION_7();
  *uint64_t v4 = v3;
  *uint64_t v4 = *v1;
  *(void *)(v3 + 456) = v5;
  *(void *)(v3 + 464) = v0;
  swift_task_dealloc();
  if (v0)
  {
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
  }
  OUTLINED_FUNCTION_14();
  return MEMORY[0x270FA2498](v6, v7, v8);
}

{
  void *v0;
  uint64_t *v1;
  uint64_t v2;
  uint64_t v3;
  void *v4;
  uint64_t v5;
  uint64_t (*v7)(uint64_t);
  uint64_t v8;

  OUTLINED_FUNCTION_25();
  uint64_t v1 = (uint64_t *)v0[27];
  uint64_t v2 = *(void *)(v0[57] + 16);
  uint64_t v3 = *(void *)(v0[28] + 16);
  swift_bridgeObjectRelease();
  static MLImageClassifier.reportAnalytics(trainingExampleCount:classCount:parameters:)(v2, v3, v1);
  uint64_t v4 = (void *)OUTLINED_FUNCTION_35_9();
  v0[59] = v4;
  *uint64_t v4 = v0;
  v4[1] = MLImageClassifier.init(trainingData:parameters:classNames:);
  uint64_t v5 = OUTLINED_FUNCTION_29_11(v0[57]);
  return v7(v5);
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  void *v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v10;

  OUTLINED_FUNCTION_11();
  OUTLINED_FUNCTION_2();
  uint64_t v3 = v2;
  OUTLINED_FUNCTION_7();
  *uint64_t v4 = v3;
  *uint64_t v4 = *v1;
  *(void *)(v3 + 480) = v5;
  *(void *)(v3 + 488) = v0;
  swift_task_dealloc();
  if (v0) {
    swift_bridgeObjectRelease();
  }
  swift_bridgeObjectRelease();
  OUTLINED_FUNCTION_14();
  return MEMORY[0x270FA2498](v6, v7, v8);
}

{
  void *v0;
  uint64_t v1;
  void *v2;
  uint64_t v3;
  void *v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t (*v8)(uint64_t);
  uint64_t v9;

  OUTLINED_FUNCTION_11();
  uint64_t v1 = *(void *)(v0[55] + 16);
  v0[62] = v1;
  if (v1)
  {
    uint64_t v2 = (void *)OUTLINED_FUNCTION_16_15();
    v0[65] = v2;
    *uint64_t v2 = v0;
    v2[1] = MLImageClassifier.init(trainingData:parameters:classNames:);
    uint64_t v3 = OUTLINED_FUNCTION_29_11(v0[55]);
    return v8(v3);
  }
  else
  {
    uint64_t v5 = (void *)OUTLINED_FUNCTION_16_15();
    v0[63] = v5;
    *uint64_t v5 = v0;
    v5[1] = MLImageClassifier.init(trainingData:parameters:classNames:);
    uint64_t v6 = v0[60];
    uint64_t v7 = v0[32];
    return ((uint64_t (*)(uint64_t, uint64_t, void, void))v8)(v7, v6, 0, 0);
  }
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  uint64_t v3;
  void *v4;
  uint64_t v5;
  void *v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v11;

  OUTLINED_FUNCTION_11();
  OUTLINED_FUNCTION_2();
  uint64_t v3 = v2;
  OUTLINED_FUNCTION_7();
  *uint64_t v4 = v3;
  uint64_t v5 = *v1;
  OUTLINED_FUNCTION_7();
  *uint64_t v6 = v5;
  *(void *)(v3 + 512) = v0;
  swift_task_dealloc();
  if (v0) {
    swift_bridgeObjectRelease();
  }
  swift_bridgeObjectRelease();
  OUTLINED_FUNCTION_14();
  return MEMORY[0x270FA2498](v7, v8, v9);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  void *v5;
  uint64_t v7;

  OUTLINED_FUNCTION_25();
  OUTLINED_FUNCTION_22_13();
  outlined init with take of MLImageClassifier(v3, v4, (void (*)(void))type metadata accessor for MLImageClassifier.Model);
  MLImageClassifier.ModelParameters.algorithm.getter(v0);
  outlined init with take of MLImageClassifier(v0, v1, (void (*)(void))type metadata accessor for MLImageClassifier.FeatureExtractorType);
  uint64_t v5 = (void *)swift_task_alloc();
  *(void *)(v2 + 560) = v5;
  *uint64_t v5 = v2;
  v5[1] = MLImageClassifier.init(trainingData:parameters:classNames:);
  OUTLINED_FUNCTION_29_11(*(void *)(v2 + 304));
  return MLImageClassifier.Model.exportAsCompiledMLModel(featureExtractorType:)();
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  uint64_t v3;
  void *v4;
  void *v5;
  void *v6;
  uint64_t v7;
  void *v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  void *v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t (*v16)(uint64_t, uint64_t, uint64_t, void, void);
  uint64_t v17;

  OUTLINED_FUNCTION_25();
  uint64_t v3 = v2;
  OUTLINED_FUNCTION_2();
  uint64_t v5 = v4;
  OUTLINED_FUNCTION_7();
  *uint64_t v6 = v5;
  uint64_t v7 = *v1;
  OUTLINED_FUNCTION_7();
  *uint64_t v8 = v7;
  v5[66] = v3;
  v5[67] = v0;
  swift_task_dealloc();
  if (v0)
  {
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    OUTLINED_FUNCTION_14();
    return MEMORY[0x270FA2498](v9, v10, v11);
  }
  else
  {
    uint64_t v12 = (void *)OUTLINED_FUNCTION_35_9();
    v5[68] = v12;
    *uint64_t v12 = v7;
    v12[1] = MLImageClassifier.init(trainingData:parameters:classNames:);
    uint64_t v13 = v5[60];
    uint64_t v14 = v5[31];
    return v16(v14, v13, v3, 0, 0);
  }
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  uint64_t v3;
  void *v4;
  uint64_t v5;
  void *v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v11;

  OUTLINED_FUNCTION_11();
  OUTLINED_FUNCTION_2();
  uint64_t v3 = v2;
  OUTLINED_FUNCTION_7();
  *uint64_t v4 = v3;
  uint64_t v5 = *v1;
  OUTLINED_FUNCTION_7();
  *uint64_t v6 = v5;
  *(void *)(v3 + 552) = v0;
  swift_task_dealloc();
  swift_bridgeObjectRelease();
  swift_bridgeObjectRelease();
  OUTLINED_FUNCTION_14();
  return MEMORY[0x270FA2498](v7, v8, v9);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  void *v5;
  uint64_t v7;

  OUTLINED_FUNCTION_25();
  OUTLINED_FUNCTION_22_13();
  outlined init with take of MLImageClassifier(v3, v4, (void (*)(void))type metadata accessor for MLImageClassifier.Model);
  MLImageClassifier.ModelParameters.algorithm.getter(v0);
  outlined init with take of MLImageClassifier(v0, v1, (void (*)(void))type metadata accessor for MLImageClassifier.FeatureExtractorType);
  uint64_t v5 = (void *)swift_task_alloc();
  *(void *)(v2 + 560) = v5;
  *uint64_t v5 = v2;
  v5[1] = MLImageClassifier.init(trainingData:parameters:classNames:);
  OUTLINED_FUNCTION_29_11(*(void *)(v2 + 304));
  return MLImageClassifier.Model.exportAsCompiledMLModel(featureExtractorType:)();
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  void *v6;
  uint64_t v7;
  void *v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v13;

  OUTLINED_FUNCTION_60_0();
  uint64_t v3 = v2;
  OUTLINED_FUNCTION_2();
  uint64_t v5 = v4;
  OUTLINED_FUNCTION_7();
  *uint64_t v6 = v5;
  uint64_t v7 = *v1;
  OUTLINED_FUNCTION_7();
  *uint64_t v8 = v7;
  *(void *)(v5 + 568) = v0;
  swift_task_dealloc();
  if (v0)
  {
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
  }
  else
  {
    *(void *)(v5 + 576) = v3;
  }
  OUTLINED_FUNCTION_14();
  return MEMORY[0x270FA2498](v9, v10, v11);
}

uint64_t MLImageClassifier.init(trainingData:parameters:classNames:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18)
{
  OUTLINED_FUNCTION_6_22();
  OUTLINED_FUNCTION_18_14();
  uint64_t result = outlined init with copy of URL?(v18[27] + 16, (uint64_t)(v18 + 21), &demangling cache variable for type metadata for Any?);
  if (v18[24])
  {
    uint64_t v55 = v18[53];
    uint64_t v21 = v18[36];
    uint64_t v20 = v18[37];
    uint64_t v22 = v18[34];
    uint64_t v23 = v18[26];
    uint64_t v24 = (_OWORD *)OUTLINED_FUNCTION_27_11();
    outlined init with take of Any(v24, v25);
    swift_dynamicCast();
    _s8CreateML27MLTrainingSessionParametersVWOcTm_3(v20, v21, (void (*)(void))type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
    unint64_t v26 = (*(unsigned __int8 *)(v22 + 80) + 24) & ~(unint64_t)*(unsigned __int8 *)(v22 + 80);
    uint64_t v27 = swift_allocObject();
    *(void *)(v27 + 16) = v23;
    outlined init with take of MLImageClassifier(v21, v27 + v26, (void (*)(void))type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
    specialized blockAwait<A>(_:)();
    v18[54] = v28;
    v18[55] = v29;
    if (v55)
    {
      uint64_t v30 = v18[50];
      uint64_t v31 = v18[37];
      uint64_t v32 = v18[27];
      swift_release();
      swift_bridgeObjectRelease();
      outlined destroy of MLImageClassifier.ModelParameters(v32);
      outlined destroy of MLImageClassifier.DataSource(v31, (void (*)(void))type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
      outlined destroy of MLImageClassifier.FeatureExtractor((uint64_t)(v18 + 12));
      outlined destroy of MLImageClassifier.DataSource(v30, (void (*)(void))type metadata accessor for MLImageClassifier.Classifier);
      OUTLINED_FUNCTION_15_14();
      outlined destroy of MLImageClassifier.DataSource(v27, (void (*)(void))type metadata accessor for MLClassifierMetrics);
      outlined destroy of MLImageClassifier.DataSource((uint64_t)(v18 + 12), (void (*)(void))type metadata accessor for MLClassifierMetrics);
      uint64_t v50 = v18[36];
      uint64_t v51 = v18[32];
      uint64_t v52 = v18[31];
      uint64_t v53 = v18[30];
      uint64_t v54 = v18[29];
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      swift_task_dealloc();
      OUTLINED_FUNCTION_30();
      OUTLINED_FUNCTION_4_31();
      return v34(v33, v34, v35, v36, v37, v38, v39, v40, v50, v51, v52, v53, v54, v55, a15, a16, a17, a18);
    }
    else
    {
      swift_release();
      uint64_t v56 = (char *)&async function pointer to specialized static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)
          + async function pointer to specialized static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:);
      uint64_t v41 = (void *)swift_task_alloc();
      v18[56] = v41;
      *uint64_t v41 = v18;
      v41[1] = MLImageClassifier.init(trainingData:parameters:classNames:);
      OUTLINED_FUNCTION_4_31();
      return v45(v42, v43, v44, v45, v46, v47, v48, v49, a9, a10, a11, a12, a13, v56, a15, a16, a17, a18);
    }
  }
  else
  {
    __break(1u);
  }
  return result;
}

{
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  void *v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v34;
  uint64_t v35;
  uint64_t v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t (*v40)(uint64_t, void, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t);
  uint64_t v41;
  uint64_t v42;
  uint64_t v43;
  uint64_t v44;
  uint64_t v45;
  uint64_t v46;

  OUTLINED_FUNCTION_6_22();
  OUTLINED_FUNCTION_18_14();
  uint64_t v19 = *(void *)(v18 + 576);
  uint64_t v20 = *(void *)(v18 + 568);
  uint64_t v21 = *(void *)(v18 + 432);
  uint64_t v22 = *(void **)(v18 + 200);
  outlined destroy of MLImageClassifier.DataSource(*(void *)(v18 + 304), (void (*)(void))type metadata accessor for MLImageClassifier.FeatureExtractorType);
  *uint64_t v22 = v19;
  specialized MLImageClassifier.evaluation<A>(on:)(v21);
  uint64_t v23 = *(void *)(v18 + 432);
  if (v20)
  {
    a9 = v20;
    uint64_t v24 = *(void *)(v18 + 400);
    uint64_t v25 = *(void *)(v18 + 296);
    unint64_t v26 = *(void *)(v18 + 216);
    swift_bridgeObjectRelease();
    outlined destroy of MLImageClassifier.ModelParameters(v26);
    outlined destroy of MLImageClassifier.DataSource(v25, (void (*)(void))type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
    outlined destroy of MLImageClassifier.FeatureExtractor(v18 + 96);
    outlined destroy of MLImageClassifier.DataSource(v24, (void (*)(void))type metadata accessor for MLImageClassifier.Classifier);
    swift_bridgeObjectRelease();

    OUTLINED_FUNCTION_15_14();
    outlined destroy of MLImageClassifier.DataSource(v18 + 96, (void (*)(void))type metadata accessor for MLClassifierMetrics);
    outlined destroy of MLImageClassifier.DataSource(v23, (void (*)(void))type metadata accessor for MLClassifierMetrics);
    uint64_t v27 = OUTLINED_FUNCTION_36_9();
    outlined destroy of MLImageClassifier.DataSource(v27, (void (*)(void))type metadata accessor for MLImageClassifier.Model);
    OUTLINED_FUNCTION_2_36();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    OUTLINED_FUNCTION_30();
  }
  else
  {
    uint64_t v28 = *(void *)(v18 + 496);
    uint64_t v29 = *(int *)(v18 + 584);
    uint64_t v30 = *(void *)(v18 + 240);
    uint64_t v31 = *(void *)(v18 + 200);
    swift_bridgeObjectRelease();
    outlined assign with take of MLClassifierMetrics(v30, v31 + v29);
    if (v28)
    {
      specialized MLImageClassifier.evaluation<A>(on:)(*(void *)(v18 + 440));
      uint64_t v35 = *(void *)(v18 + 400);
      uint64_t v36 = *(void *)(v18 + 296);
      uint64_t v37 = *(void *)(v18 + 232);
      uint64_t v38 = *(void *)(v18 + 200) + *(int *)(v18 + 588);
      outlined destroy of MLImageClassifier.ModelParameters(*(void *)(v18 + 216));
      outlined destroy of MLImageClassifier.DataSource(v36, (void (*)(void))type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
      outlined destroy of MLImageClassifier.FeatureExtractor(v18 + 96);
      outlined destroy of MLImageClassifier.DataSource(v35, (void (*)(void))type metadata accessor for MLImageClassifier.Classifier);
      swift_bridgeObjectRelease();
      outlined assign with take of MLClassifierMetrics(v37, v38);
    }
    else
    {
      uint64_t v32 = *(void *)(v18 + 400);
      uint64_t v33 = *(void *)(v18 + 296);
      uint64_t v34 = *(void *)(v18 + 216);
      swift_bridgeObjectRelease();
      outlined destroy of MLImageClassifier.ModelParameters(v34);
      outlined destroy of MLImageClassifier.DataSource(v33, (void (*)(void))type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
      outlined destroy of MLImageClassifier.FeatureExtractor(v18 + 96);
      outlined destroy of MLImageClassifier.DataSource(v32, (void (*)(void))type metadata accessor for MLImageClassifier.Classifier);
    }
    OUTLINED_FUNCTION_2_36();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
  }
  OUTLINED_FUNCTION_4_31();
  return v40(v39, v40, v41, v42, v43, v44, v45, v46, a9, a10, a11, a12, a13, a14, a15, a16, a17, a18);
}

{
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t (*v22)(uint64_t, void, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t);
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;

  OUTLINED_FUNCTION_6_22();
  OUTLINED_FUNCTION_18_14();
  uint64_t v20 = *(void *)(v19 + 400);
  outlined destroy of MLImageClassifier.ModelParameters(*(void *)(v19 + 216));
  outlined destroy of MLImageClassifier.DataSource(v20, (void (*)(void))type metadata accessor for MLImageClassifier.Classifier);
  OUTLINED_FUNCTION_3_34();
  outlined destroy of MLImageClassifier.DataSource(v18, (void (*)(void))type metadata accessor for MLClassifierMetrics);
  OUTLINED_FUNCTION_24_15();
  OUTLINED_FUNCTION_1_28();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  OUTLINED_FUNCTION_11_19();
  OUTLINED_FUNCTION_4_31();
  return v22(v21, v22, v23, v24, v25, v26, v27, v28, a9, a10, a11, a12, a13, a14, a15, a16, a17, a18);
}

{
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t (*v22)(uint64_t, void, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t);
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;

  OUTLINED_FUNCTION_6_22();
  OUTLINED_FUNCTION_18_14();
  OUTLINED_FUNCTION_23_6();
  outlined destroy of MLImageClassifier.DataSource(v20, (void (*)(void))type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
  outlined destroy of MLImageClassifier.FeatureExtractor(v19 + 96);
  outlined destroy of MLImageClassifier.DataSource(v18, (void (*)(void))type metadata accessor for MLImageClassifier.Classifier);
  swift_bridgeObjectRelease();
  OUTLINED_FUNCTION_3_34();
  outlined destroy of MLImageClassifier.DataSource(v18, (void (*)(void))type metadata accessor for MLClassifierMetrics);
  OUTLINED_FUNCTION_24_15();
  OUTLINED_FUNCTION_1_28();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  OUTLINED_FUNCTION_11_19();
  OUTLINED_FUNCTION_4_31();
  return v22(v21, v22, v23, v24, v25, v26, v27, v28, a9, a10, a11, a12, a13, a14, a15, a16, a17, a18);
}

{
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t (*v22)(uint64_t, void, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t);
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;

  OUTLINED_FUNCTION_6_22();
  OUTLINED_FUNCTION_18_14();
  OUTLINED_FUNCTION_23_6();
  outlined destroy of MLImageClassifier.DataSource(v20, (void (*)(void))type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
  outlined destroy of MLImageClassifier.FeatureExtractor(v19 + 96);
  outlined destroy of MLImageClassifier.DataSource(v18, (void (*)(void))type metadata accessor for MLImageClassifier.Classifier);
  swift_bridgeObjectRelease();
  OUTLINED_FUNCTION_3_34();
  outlined destroy of MLImageClassifier.DataSource(v18, (void (*)(void))type metadata accessor for MLClassifierMetrics);
  OUTLINED_FUNCTION_24_15();
  OUTLINED_FUNCTION_1_28();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  OUTLINED_FUNCTION_11_19();
  OUTLINED_FUNCTION_4_31();
  return v22(v21, v22, v23, v24, v25, v26, v27, v28, a9, a10, a11, a12, a13, a14, a15, a16, a17, a18);
}

{
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t (*v22)(uint64_t, void, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t);
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;

  OUTLINED_FUNCTION_6_22();
  OUTLINED_FUNCTION_18_14();
  OUTLINED_FUNCTION_23_6();
  outlined destroy of MLImageClassifier.DataSource(v20, (void (*)(void))type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
  outlined destroy of MLImageClassifier.FeatureExtractor(v19 + 96);
  outlined destroy of MLImageClassifier.DataSource(v18, (void (*)(void))type metadata accessor for MLImageClassifier.Classifier);
  swift_bridgeObjectRelease();
  OUTLINED_FUNCTION_3_34();
  outlined destroy of MLImageClassifier.DataSource(v18, (void (*)(void))type metadata accessor for MLClassifierMetrics);
  OUTLINED_FUNCTION_24_15();
  OUTLINED_FUNCTION_1_28();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  OUTLINED_FUNCTION_11_19();
  OUTLINED_FUNCTION_4_31();
  return v22(v21, v22, v23, v24, v25, v26, v27, v28, a9, a10, a11, a12, a13, a14, a15, a16, a17, a18);
}

{
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t (*v22)(uint64_t, void, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t);
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;

  OUTLINED_FUNCTION_6_22();
  OUTLINED_FUNCTION_18_14();
  OUTLINED_FUNCTION_23_6();
  outlined destroy of MLImageClassifier.DataSource(v20, (void (*)(void))type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
  outlined destroy of MLImageClassifier.FeatureExtractor(v19 + 96);
  outlined destroy of MLImageClassifier.DataSource(v18, (void (*)(void))type metadata accessor for MLImageClassifier.Classifier);
  swift_bridgeObjectRelease();
  OUTLINED_FUNCTION_3_34();
  outlined destroy of MLImageClassifier.DataSource(v18, (void (*)(void))type metadata accessor for MLClassifierMetrics);
  OUTLINED_FUNCTION_24_15();
  OUTLINED_FUNCTION_1_28();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  OUTLINED_FUNCTION_11_19();
  OUTLINED_FUNCTION_4_31();
  return v22(v21, v22, v23, v24, v25, v26, v27, v28, a9, a10, a11, a12, a13, a14, a15, a16, a17, a18);
}

{
  uint64_t *v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t (*v23)(uint64_t, void, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t);
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;

  OUTLINED_FUNCTION_6_22();
  OUTLINED_FUNCTION_18_14();
  uint64_t v19 = v18[60];
  uint64_t v20 = v18[50];
  uint64_t v21 = v18[37];
  outlined destroy of MLImageClassifier.ModelParameters(v18[27]);
  outlined destroy of MLImageClassifier.DataSource(v21, (void (*)(void))type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
  outlined destroy of MLImageClassifier.FeatureExtractor((uint64_t)(v18 + 12));
  outlined destroy of MLImageClassifier.DataSource(v20, (void (*)(void))type metadata accessor for MLImageClassifier.Classifier);
  swift_bridgeObjectRelease();
  swift_bridgeObjectRelease();
  OUTLINED_FUNCTION_3_34();
  outlined destroy of MLImageClassifier.DataSource(v19, (void (*)(void))type metadata accessor for MLClassifierMetrics);
  OUTLINED_FUNCTION_24_15();
  OUTLINED_FUNCTION_1_28();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  OUTLINED_FUNCTION_11_19();
  OUTLINED_FUNCTION_4_31();
  return v23(v22, v23, v24, v25, v26, v27, v28, v29, a9, a10, a11, a12, a13, a14, a15, a16, a17, a18);
}

{
  uint64_t *v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t (*v24)(uint64_t, void, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t);
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t v30;

  OUTLINED_FUNCTION_6_22();
  OUTLINED_FUNCTION_18_14();
  uint64_t v19 = v18[50];
  uint64_t v21 = v18[37];
  uint64_t v20 = v18[38];
  outlined destroy of MLImageClassifier.ModelParameters(v18[27]);
  outlined destroy of MLImageClassifier.DataSource(v20, (void (*)(void))type metadata accessor for MLImageClassifier.FeatureExtractorType);
  outlined destroy of MLImageClassifier.DataSource(v21, (void (*)(void))type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
  outlined destroy of MLImageClassifier.FeatureExtractor((uint64_t)(v18 + 12));
  outlined destroy of MLImageClassifier.DataSource(v19, (void (*)(void))type metadata accessor for MLImageClassifier.Classifier);
  OUTLINED_FUNCTION_3_34();
  outlined destroy of MLImageClassifier.DataSource(v20, (void (*)(void))type metadata accessor for MLClassifierMetrics);
  OUTLINED_FUNCTION_24_15();
  uint64_t v22 = OUTLINED_FUNCTION_36_9();
  outlined destroy of MLImageClassifier.DataSource(v22, (void (*)(void))type metadata accessor for MLImageClassifier.Model);
  OUTLINED_FUNCTION_1_28();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  OUTLINED_FUNCTION_11_19();
  OUTLINED_FUNCTION_4_31();
  return v24(v23, v24, v25, v26, v27, v28, v29, v30, a9, a10, a11, a12, a13, a14, a15, a16, a17, a18);
}

uint64_t closure #1 in MLImageClassifier.init(trainingData:parameters:classNames:)(uint64_t a1)
{
  *(void *)(v1 + 16) = a1;
  uint64_t v2 = (void *)swift_task_alloc();
  *(void *)(v1 + 24) = v2;
  *uint64_t v2 = v1;
  v2[1] = closure #1 in MLImageClassifier.init(trainingData:parameters:classNames:);
  return static MLImageClassifier.collectImages(trainingData:validationData:)();
}

uint64_t closure #1 in MLImageClassifier.init(trainingData:parameters:classNames:)()
{
  OUTLINED_FUNCTION_25();
  uint64_t v3 = v2;
  uint64_t v5 = v4;
  OUTLINED_FUNCTION_2();
  uint64_t v7 = v6;
  OUTLINED_FUNCTION_7();
  *uint64_t v8 = v7;
  uint64_t v9 = *v1;
  OUTLINED_FUNCTION_7();
  void *v10 = v9;
  swift_task_dealloc();
  if (v0)
  {
    uint64_t v11 = *(uint64_t (**)(void))(v9 + 8);
    return v11();
  }
  else
  {
    *(void *)(v7 + 32) = v3;
    *(void *)(v7 + 40) = v5;
    OUTLINED_FUNCTION_14();
    return MEMORY[0x270FA2498](v13, v14, v15);
  }
}

{
  uint64_t v0;

  *(int8x16_t *)*(void *)(v0 + 16) = vextq_s8(*(int8x16_t *)(v0 + 32), *(int8x16_t *)(v0 + 32), 8uLL);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t static MLImageClassifier.collectImages(trainingData:validationData:)()
{
  OUTLINED_FUNCTION_11();
  v0[2] = v1;
  v0[3] = v2;
  uint64_t v3 = type metadata accessor for MLImageClassifier.DataSource();
  OUTLINED_FUNCTION_17(v3);
  v0[4] = OUTLINED_FUNCTION_5();
  uint64_t v4 = type metadata accessor for MLImageClassifier.ModelParameters.ValidationData();
  v0[5] = v4;
  OUTLINED_FUNCTION_17(v4);
  v0[6] = OUTLINED_FUNCTION_5();
  uint64_t v5 = type metadata accessor for ImageReader();
  v0[7] = v5;
  OUTLINED_FUNCTION_1(v5);
  v0[8] = v6;
  v0[9] = OUTLINED_FUNCTION_5();
  OUTLINED_FUNCTION_14();
  return MEMORY[0x270FA2498](v7, v8, v9);
}

{
  void *v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  __int16 v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  void *v14;
  uint64_t (*v16)(uint64_t, void, void);
  uint64_t v17;

  uint64_t v1 = v0[6];
  uint64_t v2 = v0[3];
  ImageReader.init()();
  _s8CreateML27MLTrainingSessionParametersVWOcTm_3(v2, v1, (void (*)(void))type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
  OUTLINED_FUNCTION_27_11();
  switch(swift_getEnumCaseMultiPayload())
  {
    case 1u:
      uint64_t v10 = v0[4];
      outlined init with take of MLImageClassifier(v0[6], v10, (void (*)(void))type metadata accessor for MLImageClassifier.DataSource);
      swift_bridgeObjectRetain();
      uint64_t v11 = static _ImageUtilities.getImageURLsAndLabels(from:)(v10);
      uint64_t v13 = v0[4];
      uint64_t v7 = specialized Sequence.flatMap<A>(_:)(v11);
      swift_bridgeObjectRelease();
      outlined destroy of MLImageClassifier.DataSource(v13, (void (*)(void))type metadata accessor for MLImageClassifier.DataSource);
      goto LABEL_6;
    case 2u:
      uint64_t v12 = *(void *)v0[6];
      swift_bridgeObjectRetain();
      uint64_t v7 = specialized Sequence.flatMap<A>(_:)(v12);
      swift_bridgeObjectRelease();
LABEL_6:
      uint64_t v9 = v0[2];
      break;
    case 3u:
      uint64_t v9 = v0[2];
      swift_bridgeObjectRetain();
      uint64_t v7 = MEMORY[0x263F8EE78];
      break;
    default:
      uint64_t v3 = v0[2];
      swift_bridgeObjectRetain();
      uint64_t v4 = OUTLINED_FUNCTION_27_11();
      uint64_t v7 = specialized Collection.randomSplit<A, B>(strategy:)(v4, v5, v6, v3);
      uint64_t v9 = v8;
      swift_bridgeObjectRelease();
      break;
  }
  v0[10] = v7;
  v0[11] = v9;
  uint64_t v14 = (void *)OUTLINED_FUNCTION_16_15();
  v0[12] = v14;
  *uint64_t v14 = v0;
  v14[1] = static MLImageClassifier.collectImages(trainingData:validationData:);
  return v16(v9, 0, 0);
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t *v2;
  uint64_t *v3;
  uint64_t **v4;
  uint64_t v5;
  void *v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  uint64_t v12;
  uint64_t (*v14)(uint64_t, void, void);
  uint64_t v15;

  OUTLINED_FUNCTION_60_0();
  OUTLINED_FUNCTION_2();
  uint64_t v3 = v2;
  OUTLINED_FUNCTION_7();
  *uint64_t v4 = v3;
  uint64_t v5 = *v1;
  OUTLINED_FUNCTION_7();
  *uint64_t v6 = v5;
  v3[13] = v7;
  v3[14] = v0;
  swift_task_dealloc();
  swift_bridgeObjectRelease();
  if (v0)
  {
    swift_bridgeObjectRelease();
    OUTLINED_FUNCTION_14();
    return MEMORY[0x270FA2498](v8, v9, v10);
  }
  else
  {
    uint64_t v11 = (void *)OUTLINED_FUNCTION_16_15();
    v3[15] = (uint64_t)v11;
    *uint64_t v11 = v5;
    v11[1] = static MLImageClassifier.collectImages(trainingData:validationData:);
    uint64_t v12 = OUTLINED_FUNCTION_29_11(v3[10]);
    return v14(v12, 0, 0);
  }
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  void *v6;
  uint64_t v7;
  void *v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v13;

  OUTLINED_FUNCTION_60_0();
  uint64_t v3 = v2;
  OUTLINED_FUNCTION_2();
  uint64_t v5 = v4;
  OUTLINED_FUNCTION_7();
  *uint64_t v6 = v5;
  uint64_t v7 = *v1;
  OUTLINED_FUNCTION_7();
  *uint64_t v8 = v7;
  *(void *)(v5 + 128) = v0;
  swift_task_dealloc();
  swift_bridgeObjectRelease();
  if (!v0) {
    *(void *)(v5 + 136) = v3;
  }
  OUTLINED_FUNCTION_14();
  return MEMORY[0x270FA2498](v9, v10, v11);
}

{
  void *v0;
  uint64_t (*v1)(uint64_t, uint64_t);
  uint64_t v2;
  uint64_t v3;
  uint64_t v5;

  OUTLINED_FUNCTION_60_0();
  (*(void (**)(void, void))(v0[8] + 8))(v0[9], v0[7]);
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  uint64_t v1 = (uint64_t (*)(uint64_t, uint64_t))v0[1];
  uint64_t v2 = v0[17];
  uint64_t v3 = v0[13];
  return v1(v3, v2);
}

{
  void *v0;
  uint64_t (*v1)(void);
  uint64_t v3;

  OUTLINED_FUNCTION_60_0();
  (*(void (**)(void, void))(v0[8] + 8))(v0[9], v0[7]);
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  OUTLINED_FUNCTION_30();
  return v1();
}

{
  void *v0;
  uint64_t (*v1)(void);
  uint64_t v3;

  OUTLINED_FUNCTION_60_0();
  (*(void (**)(void, void))(v0[8] + 8))(v0[9], v0[7]);
  swift_bridgeObjectRelease();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  OUTLINED_FUNCTION_30();
  return v1();
}

uint64_t static MLImageClassifier.reportAnalytics(trainingExampleCount:classCount:parameters:)(uint64_t a1, uint64_t a2, uint64_t *a3)
{
  uint64_t v6 = type metadata accessor for MLImageClassifier.ModelParameters.ModelAlgorithmType();
  MEMORY[0x270FA5388](v6 - 8);
  uint64_t v8 = (char *)&v19 - ((v7 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t result = (uint64_t)AnalyticsReporter.init()();
  if ((result & 1) == 0)
  {
    v10._uint64_t object = (void *)0x80000002272D7770;
    v10._uint64_t countAndFlagsBits = 0xD000000000000010;
    AnalyticsReporter.reportDataMetrics(model:metricName:quantity:)(CreateML_ModelType_imageClassifier, v10, (float)a1);
    v11._uint64_t countAndFlagsBits = 0xD000000000000011;
    v11._uint64_t object = (void *)0x80000002272D7790;
    AnalyticsReporter.reportDataMetrics(model:metricName:quantity:)(CreateML_ModelType_imageClassifier, v11, (float)a2);
    v12._uint64_t countAndFlagsBits = 0x726574492078614DLL;
    v12._uint64_t object = (void *)0xEE00736E6F697461;
    AnalyticsReporter.reportDataMetrics(model:metricName:quantity:)(CreateML_ModelType_imageClassifier, v12, (float)*a3);
    v13._uint64_t countAndFlagsBits = 0xD000000000000014;
    v13._uint64_t object = (void *)0x80000002272D77B0;
    AnalyticsReporter.reportDataMetrics(model:metricName:quantity:)(CreateML_ModelType_imageClassifier, v13, a3[1]);
    MLImageClassifier.ModelParameters.algorithm.getter((uint64_t)v8);
    uint64_t v14 = MLImageClassifier.ModelParameters.ModelAlgorithmType.description.getter();
    uint64_t v16 = v15;
    outlined destroy of MLImageClassifier.DataSource((uint64_t)v8, (void (*)(void))type metadata accessor for MLImageClassifier.ModelParameters.ModelAlgorithmType);
    v17._uint64_t countAndFlagsBits = 0x687469726F676C41;
    v17._uint64_t object = (void *)0xE90000000000006DLL;
    v18._uint64_t countAndFlagsBits = v14;
    v18._uint64_t object = v16;
    AnalyticsReporter.reportParameterSettings(model:parameterName:parameterValue:)(CreateML_ModelType_imageClassifier, v17, v18);
    return swift_bridgeObjectRelease();
  }
  return result;
}

uint64_t specialized MLImageClassifier.evaluation<A>(on:)(uint64_t a1)
{
  MLComponents16AnnotatedFeatureVySo7CIImageCSSGG_AJs5NeverOTg503_s8d87ML17MLImageClassifierV10evaluation2onAA19MLClassifierMetricsVx_tKSlRz0A12MLComponents16fg5VySo7h5CSSG7B59RtzlFAlMcfu_32ebed8ba5c9417264c39088de476e42ecAmLTf3nnnpk_nTf1cn_n = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents16AnnotatedFeatureVySo7CIImageCSSGG_AJs5NeverOTg503_s8d87ML17MLImageClassifierV10evaluation2onAA19MLClassifierMetricsVx_tKSlRz0A12MLComponents16fg5VySo7h5CSSG7B59RtzlFAlMcfu_32ebed8ba5c9417264c39088de476e42ecAmLTf3nnnpk_nTf1cn_n(a1);
  MLImageClassifier.performRequests(_:)(MLComponents16AnnotatedFeatureVySo7CIImageCSSGG_AJs5NeverOTg503_s8d87ML17MLImageClassifierV10evaluation2onAA19MLClassifierMetricsVx_tKSlRz0A12MLComponents16fg5VySo7h5CSSG7B59RtzlFAlMcfu_32ebed8ba5c9417264c39088de476e42ecAmLTf3nnnpk_nTf1cn_n);
  uint64_t result = swift_bridgeObjectRelease();
  if (!v1)
  {
    _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents16AnnotatedFeatureVySo7CIImageCSSGG_SSs5NeverOTg503_s8d87ML17MLImageClassifierV10evaluation2onAA19MLClassifierMetricsVx_tKSlRz0A12MLComponents16fg5VySo7h5CSSG7B63RtzlFSSAMcfu0_33_7eec49b2e7313abe927b434220475ef8AMSSTf3nnnpk_nTf1cn_n(a1);
    uint64_t v5 = swift_bridgeObjectRetain();
    specialized Set.init<A>(_:)(v5);
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String]);
    lazy protocol witness table accessor for type [String] and conformance [A]();
    ClassificationMetrics.init<A, B>(predicted:groundTruth:labels:)();
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
    swift_storeEnumTagMultiPayload();
    type metadata accessor for MLClassifierMetrics.Contents(0);
    return swift_storeEnumTagMultiPayload();
  }
  return result;
}

uint64_t MLImageClassifier.init(delegate:)()
{
  OUTLINED_FUNCTION_11();
  v0[42] = v1;
  v0[43] = v2;
  uint64_t v3 = type metadata accessor for MLClassifierMetrics(0);
  v0[44] = v3;
  OUTLINED_FUNCTION_17(v3);
  v0[45] = OUTLINED_FUNCTION_5();
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLClassifierMetrics?);
  OUTLINED_FUNCTION_17(v4);
  v0[46] = OUTLINED_FUNCTION_24();
  v0[47] = swift_task_alloc();
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLImageClassifier.Model?);
  OUTLINED_FUNCTION_17(v5);
  v0[48] = OUTLINED_FUNCTION_5();
  uint64_t v6 = type metadata accessor for MLImageClassifier();
  v0[49] = v6;
  OUTLINED_FUNCTION_17(v6);
  v0[50] = OUTLINED_FUNCTION_5();
  uint64_t v7 = type metadata accessor for MLImageClassifier.ModelParameters.ModelAlgorithmType();
  v0[51] = v7;
  OUTLINED_FUNCTION_17(v7);
  v0[52] = OUTLINED_FUNCTION_24();
  v0[53] = swift_task_alloc();
  uint64_t v8 = type metadata accessor for MLImageClassifier.ModelParameters.ValidationData();
  v0[54] = v8;
  OUTLINED_FUNCTION_17(v8);
  v0[55] = OUTLINED_FUNCTION_24();
  v0[56] = swift_task_alloc();
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLImageClassifier.PersistentParameters?);
  OUTLINED_FUNCTION_17(v9);
  v0[57] = OUTLINED_FUNCTION_5();
  uint64_t v10 = type metadata accessor for MLImageClassifier.PersistentParameters();
  v0[58] = v10;
  OUTLINED_FUNCTION_17(v10);
  v0[59] = OUTLINED_FUNCTION_5();
  OUTLINED_FUNCTION_14();
  return MEMORY[0x270FA2498](v11, v12, v13);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t result;
  int *v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t *boxed_opaque_existential_0;
  uint64_t *v13;
  uint64_t v14;
  uint64_t v15;
  void *v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;

  OUTLINED_FUNCTION_6_22();
  OUTLINED_FUNCTION_18_14();
  uint64_t v1 = *(void *)(v0 + 456);
  uint64_t v2 = *(void *)(v0 + 464);
  uint64_t v3 = *(void *)(v0 + 344) + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingParameters;
  OUTLINED_FUNCTION_53();
  outlined init with copy of URL?(v3, v1, &demangling cache variable for type metadata for MLImageClassifier.PersistentParameters?);
  uint64_t result = __swift_getEnumTagSinglePayload(v1, 1, v2);
  if (result == 1)
  {
    __break(1u);
    goto LABEL_7;
  }
  uint64_t v5 = *(int **)(v0 + 464);
  uint64_t v6 = *(void *)(v0 + 472);
  uint64_t v7 = *(void *)(v0 + 448);
  uint64_t v8 = *(void *)(v0 + 440);
  uint64_t v9 = *(void *)(v0 + 424);
  Swift::String v18 = *(void *)(v0 + 432);
  uint64_t v19 = *(void *)(v0 + 416);
  uint64_t v20 = *(void *)(v0 + 408);
  uint64_t v21 = *(void *)(v0 + 344);
  uint64_t v22 = *(void *)(v0 + 384);
  outlined init with take of MLImageClassifier(*(void *)(v0 + 456), v6, (void (*)(void))type metadata accessor for MLImageClassifier.PersistentParameters);
  _s8CreateML27MLTrainingSessionParametersVWOcTm_3(v6 + v5[5], v7, (void (*)(void))type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
  uint64_t v10 = *(void *)(v6 + v5[8]);
  uint64_t v11 = *(void *)(v6 + v5[9]);
  _s8CreateML27MLTrainingSessionParametersVWOcTm_3(v6 + v5[6], v9, (void (*)(void))type metadata accessor for MLImageClassifier.FeatureExtractorType);
  *(_OWORD *)(v0 + 144) = 0u;
  *(_OWORD *)(v0 + 128) = 0u;
  *(_OWORD *)(v0 + 160) = 0u;
  *(_OWORD *)(v0 + 112) = 0u;
  *(void *)(v0 + 96) = v10;
  *(void *)(v0 + 104) = v11;
  _s8CreateML27MLTrainingSessionParametersVWOcTm_3(v7, v8, (void (*)(void))type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
  *(void *)(v0 + 200) = v18;
  boxed_opaque_existential_0 = __swift_allocate_boxed_opaque_existential_0((uint64_t *)(v0 + 176));
  outlined init with take of MLImageClassifier(v8, (uint64_t)boxed_opaque_existential_0, (void (*)(void))type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
  outlined assign with take of Any?(v0 + 176, v0 + 112);
  _s8CreateML27MLTrainingSessionParametersVWOcTm_3(v9, v19, (void (*)(void))type metadata accessor for MLImageClassifier.ModelParameters.ModelAlgorithmType);
  *(void *)(v0 + 232) = v20;
  uint64_t v13 = __swift_allocate_boxed_opaque_existential_0((uint64_t *)(v0 + 208));
  outlined init with take of MLImageClassifier(v19, (uint64_t)v13, (void (*)(void))type metadata accessor for MLImageClassifier.ModelParameters.ModelAlgorithmType);
  outlined assign with take of Any?(v0 + 208, v0 + 144);
  outlined destroy of MLImageClassifier.DataSource(v9, (void (*)(void))type metadata accessor for MLImageClassifier.ModelParameters.ModelAlgorithmType);
  outlined destroy of MLImageClassifier.DataSource(v7, (void (*)(void))type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
  uint64_t v14 = v21 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_model;
  OUTLINED_FUNCTION_53();
  outlined init with copy of URL?(v14, v22, &demangling cache variable for type metadata for MLImageClassifier.Model?);
  uint64_t v15 = type metadata accessor for MLImageClassifier.Model();
  uint64_t result = __swift_getEnumTagSinglePayload(v22, 1, v15);
  if (result == 1)
  {
LABEL_7:
    __break(1u);
    return result;
  }
  outlined init with copy of MLImageClassifier.ModelParameters((long long *)(v0 + 96), v0 + 16);
  uint64_t v16 = (void *)swift_task_alloc();
  *(void *)(v0 + 480) = v16;
  *uint64_t v16 = v0;
  v16[1] = MLImageClassifier.init(delegate:);
  OUTLINED_FUNCTION_4_31();
  return MLImageClassifier.init(_:parameters:)();
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  void *v3;
  uint64_t v4;
  void *v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v11;

  OUTLINED_FUNCTION_11();
  OUTLINED_FUNCTION_2();
  OUTLINED_FUNCTION_7();
  *uint64_t v3 = v2;
  uint64_t v4 = *v1;
  OUTLINED_FUNCTION_7();
  *uint64_t v5 = v4;
  *(void *)(v6 + 488) = v0;
  swift_task_dealloc();
  OUTLINED_FUNCTION_14();
  return MEMORY[0x270FA2498](v7, v8, v9);
}

{
  void *v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t result;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t (*v17)(void);
  uint64_t v18;

  uint64_t v1 = v0[47];
  uint64_t v3 = v0[43];
  uint64_t v2 = v0[44];
  outlined init with take of MLImageClassifier(v0[50], v0[42], (void (*)(void))type metadata accessor for MLImageClassifier);
  uint64_t v4 = v3 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingMetrics;
  OUTLINED_FUNCTION_53();
  outlined init with copy of URL?(v4, v1, &demangling cache variable for type metadata for MLClassifierMetrics?);
  uint64_t result = __swift_getEnumTagSinglePayload(v1, 1, v2);
  if (result == 1)
  {
    __break(1u);
  }
  else
  {
    uint64_t v6 = v0[59];
    uint64_t v7 = v0[49];
    uint64_t v9 = v0[46];
    uint64_t v8 = v0[47];
    uint64_t v11 = v0[43];
    uint64_t v10 = v0[44];
    uint64_t v12 = v0[42];
    outlined destroy of MLImageClassifier.ModelParameters((uint64_t)(v0 + 12));
    outlined destroy of MLImageClassifier.DataSource(v6, (void (*)(void))type metadata accessor for MLImageClassifier.PersistentParameters);
    outlined assign with take of MLClassifierMetrics(v8, v12 + *(int *)(v7 + 24));
    uint64_t v13 = v11 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationMetrics;
    OUTLINED_FUNCTION_53();
    outlined init with copy of URL?(v13, v9, &demangling cache variable for type metadata for MLClassifierMetrics?);
    swift_release();
    if (__swift_getEnumTagSinglePayload(v9, 1, v10) == 1)
    {
      _s10Foundation3URLVSgWOhTm_0(v0[46], &demangling cache variable for type metadata for MLClassifierMetrics?);
    }
    else
    {
      uint64_t v14 = v0[49];
      uint64_t v15 = v0[45];
      uint64_t v16 = v0[42];
      outlined init with take of MLImageClassifier(v0[46], v15, (void (*)(void))type metadata accessor for MLClassifierMetrics);
      outlined assign with take of MLClassifierMetrics(v15, v16 + *(int *)(v14 + 28));
    }
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    swift_task_dealloc();
    Swift::String v17 = (uint64_t (*)(void))v0[1];
    return v17();
  }
  return result;
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t (*v2)(void);
  uint64_t v4;

  uint64_t v1 = *(void *)(v0 + 472);
  swift_release();
  outlined destroy of MLImageClassifier.ModelParameters(v0 + 96);
  outlined destroy of MLImageClassifier.DataSource(v1, (void (*)(void))type metadata accessor for MLImageClassifier.PersistentParameters);
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  OUTLINED_FUNCTION_30();
  return v2();
}

unint64_t MLImageClassifier.debugDescription.getter()
{
  type metadata accessor for MLClassifierMetrics.Contents(0);
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v1);
  OUTLINED_FUNCTION_3_0();
  uint64_t v4 = v3 - v2;
  unint64_t v5 = MLImageClassifier.ModelParameters.description.getter();
  uint64_t v7 = v6;
  uint64_t v8 = type metadata accessor for MLImageClassifier();
  unint64_t v9 = MLClassifierMetrics.description.getter();
  uint64_t v11 = v10;
  _s8CreateML27MLTrainingSessionParametersVWOcTm_3(v0 + *(int *)(v8 + 28), v4, (void (*)(void))type metadata accessor for MLClassifierMetrics.Contents);
  LODWORD(v8) = swift_getEnumCaseMultiPayload();
  outlined destroy of MLImageClassifier.DataSource(v4, (void (*)(void))type metadata accessor for MLClassifierMetrics.Contents);
  unint64_t v12 = MLClassifierMetrics.description.getter();
  uint64_t v14 = v13;
  v15._uint64_t countAndFlagsBits = v5;
  v15._uint64_t object = v7;
  String.append(_:)(v15);
  OUTLINED_FUNCTION_33_9(0xD00000000000001ELL);
  v16._uint64_t countAndFlagsBits = v9;
  v16._uint64_t object = v11;
  String.append(_:)(v16);
  String.append(_:)(v19);
  swift_bridgeObjectRelease();
  if (v8 <= 1)
  {
    OUTLINED_FUNCTION_33_9(0xD000000000000020);
    v17._uint64_t countAndFlagsBits = v12;
    v17._uint64_t object = v14;
    String.append(_:)(v17);
    String.append(_:)(v19);
    swift_bridgeObjectRelease();
  }
  swift_bridgeObjectRelease();
  swift_bridgeObjectRelease();
  swift_bridgeObjectRelease();
  return 0xD00000000000001CLL;
}

NSAttributedString MLImageClassifier.playgroundDescription.getter@<X0>(NSAttributedString *a1@<X8>)
{
  unint64_t v2 = type metadata accessor for NSAttributedString();
  v3._uint64_t countAndFlagsBits = MLImageClassifier.debugDescription.getter();
  result.super.Class isa = NSAttributedString.__allocating_init(string:)(v3).super.isa;
  a1[3].super.Class isa = (Class)v2;
  a1->super.Class isa = result.super.isa;
  return result;
}

uint64_t key path getter for AnnotatedFeature.feature : AnnotatedFeature<CIImage, String>@<X0>(void *a1@<X8>)
{
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<CIImage, String>);
  uint64_t result = AnnotatedFeature.feature.getter();
  *a1 = v3;
  return result;
}

uint64_t key path setter for AnnotatedFeature.feature : AnnotatedFeature<CIImage, String>(id *a1)
{
  id v1 = *a1;
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<CIImage, String>);
  return AnnotatedFeature.feature.setter();
}

uint64_t key path getter for AnnotatedFeature.annotation : AnnotatedFeature<CIImage, String>@<X0>(void *a1@<X8>)
{
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<CIImage, String>);
  uint64_t result = AnnotatedFeature.annotation.getter();
  *a1 = v3;
  a1[1] = v4;
  return result;
}

uint64_t key path setter for AnnotatedFeature.annotation : AnnotatedFeature<CIImage, String>()
{
  return AnnotatedFeature.annotation.setter();
}

uint64_t partial apply for closure #1 in MLImageClassifier.init(trainingData:parameters:)()
{
  OUTLINED_FUNCTION_60_0();
  uint64_t v0 = swift_task_alloc();
  id v1 = (void *)OUTLINED_FUNCTION_7_1(v0);
  void *v1 = v2;
  v1[1] = partial apply for closure #1 in MLImageClassifier.init(trainingData:parameters:);
  uint64_t v3 = OUTLINED_FUNCTION_25_16();
  return closure #1 in MLImageClassifier.init(trainingData:parameters:)(v3, v4, v5);
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v7;

  OUTLINED_FUNCTION_60_0();
  uint64_t v0 = swift_task_alloc();
  id v1 = (void *)OUTLINED_FUNCTION_7_1(v0);
  void *v1 = v2;
  v1[1] = partial apply for closure #1 in MLImageClassifier.init(trainingData:parameters:);
  uint64_t v3 = OUTLINED_FUNCTION_25_16();
  return closure #1 in MLImageClassifier.init(trainingData:parameters:)(v3, v4, v5);
}

uint64_t objectdestroyTm_2()
{
  swift_bridgeObjectRelease();
  if (*(void *)(v0 + 64)) {
    __swift_destroy_boxed_opaque_existential_0(v0 + 40);
  }
  if (*(void *)(v0 + 96)) {
    __swift_destroy_boxed_opaque_existential_0(v0 + 72);
  }

  return MEMORY[0x270FA0238](v0, 104, 7);
}

id sub_22713D054@<X0>(void *a1@<X8>)
{
  id result = MLImageClassifier.model.getter();
  *a1 = result;
  return result;
}

char *initializeBufferWithCopyOfBuffer for MLImageClassifier(char *a1, char **a2, int *a3)
{
  int v4 = *(_DWORD *)(*((void *)a3 - 1) + 80);
  uint64_t v5 = *a2;
  *(void *)a1 = *a2;
  if ((v4 & 0x20000) != 0)
  {
    a1 = &v5[(v4 + 16) & ~(unint64_t)v4];
    swift_retain();
  }
  else
  {
    *(_OWORD *)(a1 + 8) = *(_OWORD *)(a2 + 1);
    uint64_t v8 = a2 + 3;
    unint64_t v9 = a2[6];
    uint64_t v10 = v5;
    if (v9)
    {
      *((void *)a1 + 6) = v9;
      (**((void (***)(uint64_t, _OWORD *, char *))v9 - 1))((uint64_t)(a1 + 24), v8, v9);
    }
    else
    {
      long long v11 = v8[1];
      *(_OWORD *)(a1 + 24) = *v8;
      *(_OWORD *)(a1 + 40) = v11;
    }
    unint64_t v12 = a1 + 56;
    uint64_t v13 = a2 + 7;
    uint64_t v14 = a2[10];
    if (v14)
    {
      *((void *)a1 + 10) = v14;
      (**((void (***)(_OWORD *, _OWORD *))v14 - 1))(v12, v13);
    }
    else
    {
      long long v15 = *(_OWORD *)(a2 + 9);
      *unint64_t v12 = *v13;
      *(_OWORD *)(a1 + 72) = v15;
    }
    uint64_t v16 = a3[6];
    Swift::String v17 = (void **)&a1[v16];
    Swift::String v18 = (void **)((char *)a2 + v16);
    type metadata accessor for MLClassifierMetrics.Contents(0);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload();
    if (EnumCaseMultiPayload == 2)
    {
      uint64_t v24 = *v18;
      id v25 = v24;
      *Swift::String v17 = v24;
    }
    else if (EnumCaseMultiPayload == 1)
    {
      *Swift::String v17 = *v18;
      uint64_t v20 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
      uint64_t v21 = *(int *)(v20 + 20);
      char v45 = (char *)v18 + v21;
      uint64_t v47 = (char *)v17 + v21;
      uint64_t v22 = type metadata accessor for DataFrame();
      uint64_t v23 = *(void (**)(char *, char *, uint64_t))(*(void *)(v22 - 8) + 16);
      v23(v47, v45, v22);
      v23((char *)v17 + *(int *)(v20 + 24), (char *)v18 + *(int *)(v20 + 24), v22);
    }
    else
    {
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
      if (swift_getEnumCaseMultiPayload() == 1) {
        unint64_t v26 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
      }
      else {
        unint64_t v26 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
      }
      uint64_t v27 = __swift_instantiateConcreteTypeFromMangledName(v26);
      (*(void (**)(void **, void **, uint64_t))(*(void *)(v27 - 8) + 16))(v17, v18, v27);
      swift_storeEnumTagMultiPayload();
    }
    swift_storeEnumTagMultiPayload();
    uint64_t v28 = a3[7];
    uint64_t v29 = (void **)&a1[v28];
    uint64_t v30 = (void **)((char *)a2 + v28);
    int v31 = swift_getEnumCaseMultiPayload();
    if (v31 == 2)
    {
      uint64_t v36 = *v30;
      id v37 = v36;
      *uint64_t v29 = v36;
    }
    else if (v31 == 1)
    {
      *uint64_t v29 = *v30;
      uint64_t v32 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
      uint64_t v33 = *(int *)(v32 + 20);
      uint64_t v46 = (char *)v30 + v33;
      uint64_t v48 = (char *)v29 + v33;
      uint64_t v34 = type metadata accessor for DataFrame();
      uint64_t v35 = *(void (**)(char *, char *, uint64_t))(*(void *)(v34 - 8) + 16);
      v35(v48, v46, v34);
      v35((char *)v29 + *(int *)(v32 + 24), (char *)v30 + *(int *)(v32 + 24), v34);
    }
    else
    {
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
      if (swift_getEnumCaseMultiPayload() == 1) {
        uint64_t v38 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
      }
      else {
        uint64_t v38 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
      }
      uint64_t v39 = __swift_instantiateConcreteTypeFromMangledName(v38);
      (*(void (**)(void **, void **, uint64_t))(*(void *)(v39 - 8) + 16))(v29, v30, v39);
      swift_storeEnumTagMultiPayload();
    }
    swift_storeEnumTagMultiPayload();
    uint64_t v40 = a3[8];
    uint64_t v41 = &a1[v40];
    uint64_t v42 = (uint64_t)a2 + v40;
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
    if (swift_getEnumCaseMultiPayload() == 1) {
      uint64_t v43 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>);
    }
    else {
      uint64_t v43 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>);
    }
    (*(void (**)(char *, uint64_t, uint64_t))(*(void *)(v43 - 8) + 16))(v41, v42, v43);
    swift_storeEnumTagMultiPayload();
  }
  return a1;
}

uint64_t destroy for MLImageClassifier(uint64_t a1, int *a2)
{
  if (*(void *)(a1 + 48)) {
    __swift_destroy_boxed_opaque_existential_0(a1 + 24);
  }
  if (*(void *)(a1 + 80)) {
    __swift_destroy_boxed_opaque_existential_0(a1 + 56);
  }
  int v4 = (id *)(a1 + a2[6]);
  type metadata accessor for MLClassifierMetrics.Contents(0);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload();
  switch(EnumCaseMultiPayload)
  {
    case 2:

      break;
    case 1:
      uint64_t v7 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
      uint64_t v8 = (char *)v4 + *(int *)(v7 + 20);
      uint64_t v9 = type metadata accessor for DataFrame();
      uint64_t v10 = *(void (**)(char *, uint64_t))(*(void *)(v9 - 8) + 8);
      v10(v8, v9);
      v10((char *)v4 + *(int *)(v7 + 24), v9);
      break;
    case 0:
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
      if (swift_getEnumCaseMultiPayload() == 1) {
        uint64_t v6 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
      }
      else {
        uint64_t v6 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
      }
      uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(v6);
      (*(void (**)(id *, uint64_t))(*(void *)(v11 - 8) + 8))(v4, v11);
      break;
  }
  unint64_t v12 = (id *)(a1 + a2[7]);
  int v13 = swift_getEnumCaseMultiPayload();
  switch(v13)
  {
    case 2:

      break;
    case 1:
      uint64_t v15 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
      uint64_t v16 = (char *)v12 + *(int *)(v15 + 20);
      uint64_t v17 = type metadata accessor for DataFrame();
      Swift::String v18 = *(void (**)(char *, uint64_t))(*(void *)(v17 - 8) + 8);
      v18(v16, v17);
      v18((char *)v12 + *(int *)(v15 + 24), v17);
      break;
    case 0:
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
      if (swift_getEnumCaseMultiPayload() == 1) {
        uint64_t v14 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
      }
      else {
        uint64_t v14 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
      }
      uint64_t v19 = __swift_instantiateConcreteTypeFromMangledName(v14);
      (*(void (**)(id *, uint64_t))(*(void *)(v19 - 8) + 8))(v12, v19);
      break;
  }
  uint64_t v20 = a1 + a2[8];
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  if (swift_getEnumCaseMultiPayload() == 1) {
    uint64_t v21 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>;
  }
  else {
    uint64_t v21 = &demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>;
  }
  uint64_t v22 = __swift_instantiateConcreteTypeFromMangledName(v21);
  uint64_t v23 = *(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v22 - 8) + 8);

  return v23(v20, v22);
}

uint64_t initializeWithCopy for MLImageClassifier(uint64_t a1, uint64_t a2, int *a3)
{
  uint64_t v6 = *(void **)a2;
  *(void *)a1 = *(void *)a2;
  *(_OWORD *)(a1 + 8) = *(_OWORD *)(a2 + 8);
  uint64_t v7 = (_OWORD *)(a1 + 24);
  uint64_t v8 = (_OWORD *)(a2 + 24);
  uint64_t v9 = *(void *)(a2 + 48);
  id v10 = v6;
  if (v9)
  {
    *(void *)(a1 + 48) = v9;
    (**(void (***)(_OWORD *, _OWORD *, uint64_t))(v9 - 8))(v7, v8, v9);
  }
  else
  {
    long long v11 = v8[1];
    _OWORD *v7 = *v8;
    v7[1] = v11;
  }
  unint64_t v12 = (_OWORD *)(a1 + 56);
  int v13 = (_OWORD *)(a2 + 56);
  uint64_t v14 = *(void *)(a2 + 80);
  if (v14)
  {
    *(void *)(a1 + 80) = v14;
    (**(void (***)(_OWORD *, _OWORD *))(v14 - 8))(v12, v13);
  }
  else
  {
    long long v15 = *(_OWORD *)(a2 + 72);
    *unint64_t v12 = *v13;
    *(_OWORD *)(a1 + 72) = v15;
  }
  uint64_t v16 = a3[6];
  uint64_t v17 = (id *)(a1 + v16);
  Swift::String v18 = (id *)(a2 + v16);
  type metadata accessor for MLClassifierMetrics.Contents(0);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload();
  if (EnumCaseMultiPayload == 2)
  {
    id v24 = *v18;
    id v25 = *v18;
    *uint64_t v17 = v24;
  }
  else if (EnumCaseMultiPayload == 1)
  {
    *uint64_t v17 = *v18;
    uint64_t v20 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
    uint64_t v21 = *(int *)(v20 + 20);
    uint64_t v47 = (char *)v18 + v21;
    uint64_t v49 = (char *)v17 + v21;
    uint64_t v22 = type metadata accessor for DataFrame();
    uint64_t v23 = *(void (**)(char *, char *, uint64_t))(*(void *)(v22 - 8) + 16);
    v23(v49, v47, v22);
    v23((char *)v17 + *(int *)(v20 + 24), (char *)v18 + *(int *)(v20 + 24), v22);
  }
  else
  {
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
    if (swift_getEnumCaseMultiPayload() == 1) {
      unint64_t v26 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
    }
    else {
      unint64_t v26 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
    }
    uint64_t v27 = __swift_instantiateConcreteTypeFromMangledName(v26);
    (*(void (**)(id *, id *, uint64_t))(*(void *)(v27 - 8) + 16))(v17, v18, v27);
    swift_storeEnumTagMultiPayload();
  }
  swift_storeEnumTagMultiPayload();
  uint64_t v28 = a3[7];
  uint64_t v29 = (id *)(a1 + v28);
  uint64_t v30 = (id *)(a2 + v28);
  int v31 = swift_getEnumCaseMultiPayload();
  if (v31 == 2)
  {
    id v37 = *v30;
    id v38 = *v30;
    *uint64_t v29 = v37;
  }
  else if (v31 == 1)
  {
    *uint64_t v29 = *v30;
    uint64_t v32 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
    uint64_t v33 = *(int *)(v32 + 20);
    uint64_t v48 = (char *)v30 + v33;
    uint64_t v50 = (char *)v29 + v33;
    uint64_t v51 = a3;
    uint64_t v34 = type metadata accessor for DataFrame();
    uint64_t v35 = *(void (**)(char *, char *, uint64_t))(*(void *)(v34 - 8) + 16);
    v35(v50, v48, v34);
    uint64_t v36 = v34;
    a3 = v51;
    v35((char *)v29 + *(int *)(v32 + 24), (char *)v30 + *(int *)(v32 + 24), v36);
  }
  else
  {
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
    if (swift_getEnumCaseMultiPayload() == 1) {
      uint64_t v39 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
    }
    else {
      uint64_t v39 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
    }
    uint64_t v40 = __swift_instantiateConcreteTypeFromMangledName(v39);
    (*(void (**)(id *, id *, uint64_t))(*(void *)(v40 - 8) + 16))(v29, v30, v40);
    swift_storeEnumTagMultiPayload();
  }
  swift_storeEnumTagMultiPayload();
  uint64_t v41 = a3[8];
  uint64_t v42 = a1 + v41;
  uint64_t v43 = a2 + v41;
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  if (swift_getEnumCaseMultiPayload() == 1) {
    uint64_t v44 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>;
  }
  else {
    uint64_t v44 = &demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>;
  }
  uint64_t v45 = __swift_instantiateConcreteTypeFromMangledName(v44);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v45 - 8) + 16))(v42, v43, v45);
  swift_storeEnumTagMultiPayload();
  return a1;
}

uint64_t assignWithCopy for MLImageClassifier(uint64_t a1, uint64_t a2, int *a3)
{
  uint64_t v6 = *(void **)a2;
  uint64_t v7 = *(void **)a1;
  *(void *)a1 = *(void *)a2;
  id v8 = v6;

  *(void *)(a1 + 8) = *(void *)(a2 + 8);
  *(void *)(a1 + 16) = *(void *)(a2 + 16);
  uint64_t v9 = *(void *)(a2 + 48);
  if (*(void *)(a1 + 48))
  {
    if (v9)
    {
      __swift_assign_boxed_opaque_existential_0((uint64_t *)(a1 + 24), (uint64_t *)(a2 + 24));
      goto LABEL_8;
    }
    __swift_destroy_boxed_opaque_existential_0(a1 + 24);
  }
  else if (v9)
  {
    *(void *)(a1 + 48) = v9;
    (**(void (***)(uint64_t, uint64_t))(v9 - 8))(a1 + 24, a2 + 24);
    goto LABEL_8;
  }
  long long v10 = *(_OWORD *)(a2 + 40);
  *(_OWORD *)(a1 + 24) = *(_OWORD *)(a2 + 24);
  *(_OWORD *)(a1 + 40) = v10;
LABEL_8:
  uint64_t v11 = *(void *)(a2 + 80);
  if (*(void *)(a1 + 80))
  {
    if (v11)
    {
      __swift_assign_boxed_opaque_existential_0((uint64_t *)(a1 + 56), (uint64_t *)(a2 + 56));
      goto LABEL_15;
    }
    __swift_destroy_boxed_opaque_existential_0(a1 + 56);
  }
  else if (v11)
  {
    *(void *)(a1 + 80) = v11;
    (**(void (***)(uint64_t, uint64_t))(v11 - 8))(a1 + 56, a2 + 56);
    goto LABEL_15;
  }
  long long v12 = *(_OWORD *)(a2 + 72);
  *(_OWORD *)(a1 + 56) = *(_OWORD *)(a2 + 56);
  *(_OWORD *)(a1 + 72) = v12;
LABEL_15:
  if (a1 != a2)
  {
    uint64_t v13 = a3[6];
    uint64_t v14 = (id *)(a1 + v13);
    long long v15 = (id *)(a2 + v13);
    outlined destroy of MLImageClassifier.DataSource(a1 + v13, (void (*)(void))type metadata accessor for MLClassifierMetrics.Contents);
    type metadata accessor for MLClassifierMetrics.Contents(0);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload();
    if (EnumCaseMultiPayload == 2)
    {
      id v21 = *v15;
      id v22 = *v15;
      *uint64_t v14 = v21;
    }
    else if (EnumCaseMultiPayload == 1)
    {
      *uint64_t v14 = *v15;
      uint64_t v17 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
      uint64_t v18 = *(int *)(v17 + 20);
      uint64_t v44 = (char *)v15 + v18;
      uint64_t v46 = (char *)v14 + v18;
      uint64_t v19 = type metadata accessor for DataFrame();
      uint64_t v20 = *(void (**)(char *, char *, uint64_t))(*(void *)(v19 - 8) + 16);
      v20(v46, v44, v19);
      v20((char *)v14 + *(int *)(v17 + 24), (char *)v15 + *(int *)(v17 + 24), v19);
    }
    else
    {
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
      if (swift_getEnumCaseMultiPayload() == 1) {
        uint64_t v23 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
      }
      else {
        uint64_t v23 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
      }
      uint64_t v24 = __swift_instantiateConcreteTypeFromMangledName(v23);
      (*(void (**)(id *, id *, uint64_t))(*(void *)(v24 - 8) + 16))(v14, v15, v24);
      swift_storeEnumTagMultiPayload();
    }
    swift_storeEnumTagMultiPayload();
    uint64_t v25 = a3[7];
    unint64_t v26 = (id *)(a1 + v25);
    uint64_t v27 = (id *)(a2 + v25);
    outlined destroy of MLImageClassifier.DataSource(a1 + v25, (void (*)(void))type metadata accessor for MLClassifierMetrics.Contents);
    int v28 = swift_getEnumCaseMultiPayload();
    if (v28 == 2)
    {
      id v34 = *v27;
      id v35 = *v27;
      *unint64_t v26 = v34;
    }
    else if (v28 == 1)
    {
      *unint64_t v26 = *v27;
      uint64_t v29 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
      uint64_t v30 = *(int *)(v29 + 20);
      uint64_t v45 = (char *)v27 + v30;
      uint64_t v47 = (char *)v26 + v30;
      uint64_t v48 = a3;
      uint64_t v31 = type metadata accessor for DataFrame();
      uint64_t v32 = *(void (**)(char *, char *, uint64_t))(*(void *)(v31 - 8) + 16);
      v32(v47, v45, v31);
      uint64_t v33 = v31;
      a3 = v48;
      v32((char *)v26 + *(int *)(v29 + 24), (char *)v27 + *(int *)(v29 + 24), v33);
    }
    else
    {
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
      if (swift_getEnumCaseMultiPayload() == 1) {
        uint64_t v36 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
      }
      else {
        uint64_t v36 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
      }
      uint64_t v37 = __swift_instantiateConcreteTypeFromMangledName(v36);
      (*(void (**)(id *, id *, uint64_t))(*(void *)(v37 - 8) + 16))(v26, v27, v37);
      swift_storeEnumTagMultiPayload();
    }
    swift_storeEnumTagMultiPayload();
    uint64_t v38 = a3[8];
    uint64_t v39 = a1 + v38;
    uint64_t v40 = a2 + v38;
    _s10Foundation3URLVSgWOhTm_0(a1 + v38, &demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
    if (swift_getEnumCaseMultiPayload() == 1) {
      uint64_t v41 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>;
    }
    else {
      uint64_t v41 = &demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>;
    }
    uint64_t v42 = __swift_instantiateConcreteTypeFromMangledName(v41);
    (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v42 - 8) + 16))(v39, v40, v42);
    swift_storeEnumTagMultiPayload();
  }
  return a1;
}

void *initializeWithTake for MLImageClassifier(void *a1, void *a2, int *a3)
{
  int v4 = a2;
  *a1 = *a2;
  memcpy(a1 + 1, a2 + 1, 0x50uLL);
  uint64_t v6 = a3[6];
  uint64_t v7 = (char *)a1 + v6;
  id v8 = (char *)v4 + v6;
  uint64_t v9 = type metadata accessor for MLClassifierMetrics.Contents(0);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload();
  if (EnumCaseMultiPayload == 1)
  {
    *(void *)uint64_t v7 = *(void *)v8;
    uint64_t v13 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
    uint64_t v14 = *(int *)(v13 + 20);
    long long v15 = &v7[v14];
    uint64_t v16 = &v8[v14];
    uint64_t v17 = type metadata accessor for DataFrame();
    uint64_t v37 = a3;
    uint64_t v18 = *(void (**)(char *, char *, uint64_t))(*(void *)(v17 - 8) + 32);
    v18(v15, v16, v17);
    v18(&v7[*(int *)(v13 + 24)], &v8[*(int *)(v13 + 24)], v17);
    a3 = v37;
LABEL_8:
    swift_storeEnumTagMultiPayload();
    goto LABEL_10;
  }
  if (!EnumCaseMultiPayload)
  {
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
    if (swift_getEnumCaseMultiPayload() == 1) {
      uint64_t v11 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
    }
    else {
      uint64_t v11 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
    }
    uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(v11);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 32))(v7, v8, v12);
    swift_storeEnumTagMultiPayload();
    goto LABEL_8;
  }
  memcpy(v7, v8, *(void *)(*(void *)(v9 - 8) + 64));
LABEL_10:
  uint64_t v19 = a3[7];
  uint64_t v20 = (char *)a1 + v19;
  id v21 = (char *)v4 + v19;
  int v22 = swift_getEnumCaseMultiPayload();
  if (v22 == 1)
  {
    *(void *)uint64_t v20 = *(void *)v21;
    uint64_t v25 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
    uint64_t v26 = *(int *)(v25 + 20);
    uint64_t v27 = &v20[v26];
    int v28 = &v21[v26];
    uint64_t v29 = type metadata accessor for DataFrame();
    uint64_t v38 = v4;
    uint64_t v30 = *(void (**)(char *, char *, uint64_t))(*(void *)(v29 - 8) + 32);
    v30(v27, v28, v29);
    v30(&v20[*(int *)(v25 + 24)], &v21[*(int *)(v25 + 24)], v29);
    int v4 = v38;
LABEL_17:
    swift_storeEnumTagMultiPayload();
    goto LABEL_19;
  }
  if (!v22)
  {
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
    if (swift_getEnumCaseMultiPayload() == 1) {
      uint64_t v23 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
    }
    else {
      uint64_t v23 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
    }
    uint64_t v24 = __swift_instantiateConcreteTypeFromMangledName(v23);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v24 - 8) + 32))(v20, v21, v24);
    swift_storeEnumTagMultiPayload();
    goto LABEL_17;
  }
  memcpy(v20, v21, *(void *)(*(void *)(v9 - 8) + 64));
LABEL_19:
  uint64_t v31 = a3[8];
  uint64_t v32 = (char *)a1 + v31;
  uint64_t v33 = (char *)v4 + v31;
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  if (swift_getEnumCaseMultiPayload() == 1) {
    id v34 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>;
  }
  else {
    id v34 = &demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>;
  }
  uint64_t v35 = __swift_instantiateConcreteTypeFromMangledName(v34);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v35 - 8) + 32))(v32, v33, v35);
  swift_storeEnumTagMultiPayload();
  return a1;
}

uint64_t assignWithTake for MLImageClassifier(uint64_t a1, uint64_t a2, int *a3)
{
  uint64_t v6 = *(void **)a1;
  *(void *)a1 = *(void *)a2;

  *(_OWORD *)(a1 + 8) = *(_OWORD *)(a2 + 8);
  if (*(void *)(a1 + 48)) {
    __swift_destroy_boxed_opaque_existential_0(a1 + 24);
  }
  long long v7 = *(_OWORD *)(a2 + 40);
  *(_OWORD *)(a1 + 24) = *(_OWORD *)(a2 + 24);
  *(_OWORD *)(a1 + 40) = v7;
  if (*(void *)(a1 + 80)) {
    __swift_destroy_boxed_opaque_existential_0(a1 + 56);
  }
  long long v8 = *(_OWORD *)(a2 + 72);
  *(_OWORD *)(a1 + 56) = *(_OWORD *)(a2 + 56);
  *(_OWORD *)(a1 + 72) = v8;
  if (a1 != a2)
  {
    uint64_t v9 = a3[6];
    long long v10 = (char *)(a1 + v9);
    uint64_t v11 = (char *)(a2 + v9);
    outlined destroy of MLImageClassifier.DataSource(a1 + v9, (void (*)(void))type metadata accessor for MLClassifierMetrics.Contents);
    uint64_t v12 = type metadata accessor for MLClassifierMetrics.Contents(0);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload();
    if (EnumCaseMultiPayload == 1)
    {
      *(void *)long long v10 = *(void *)v11;
      uint64_t v16 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
      uint64_t v17 = *(int *)(v16 + 20);
      uint64_t v38 = &v10[v17];
      uint64_t v18 = &v11[v17];
      uint64_t v19 = type metadata accessor for DataFrame();
      uint64_t v40 = a3;
      uint64_t v20 = *(void (**)(char *, char *, uint64_t))(*(void *)(v19 - 8) + 32);
      v20(v38, v18, v19);
      v20(&v10[*(int *)(v16 + 24)], &v11[*(int *)(v16 + 24)], v19);
      a3 = v40;
    }
    else
    {
      if (EnumCaseMultiPayload)
      {
        memcpy(v10, v11, *(void *)(*(void *)(v12 - 8) + 64));
LABEL_15:
        uint64_t v21 = a3[7];
        int v22 = (char *)(a1 + v21);
        uint64_t v23 = (char *)(a2 + v21);
        outlined destroy of MLImageClassifier.DataSource(a1 + v21, (void (*)(void))type metadata accessor for MLClassifierMetrics.Contents);
        int v24 = swift_getEnumCaseMultiPayload();
        if (v24 == 1)
        {
          *(void *)int v22 = *(void *)v23;
          uint64_t v27 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
          uint64_t v28 = *(int *)(v27 + 20);
          uint64_t v39 = &v22[v28];
          uint64_t v29 = &v23[v28];
          uint64_t v30 = type metadata accessor for DataFrame();
          uint64_t v41 = a3;
          uint64_t v31 = *(void (**)(char *, char *, uint64_t))(*(void *)(v30 - 8) + 32);
          v31(v39, v29, v30);
          v31(&v22[*(int *)(v27 + 24)], &v23[*(int *)(v27 + 24)], v30);
          a3 = v41;
        }
        else
        {
          if (v24)
          {
            memcpy(v22, v23, *(void *)(*(void *)(v12 - 8) + 64));
            goto LABEL_24;
          }
          __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
          if (swift_getEnumCaseMultiPayload() == 1) {
            uint64_t v25 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
          }
          else {
            uint64_t v25 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
          }
          uint64_t v26 = __swift_instantiateConcreteTypeFromMangledName(v25);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v26 - 8) + 32))(v22, v23, v26);
          swift_storeEnumTagMultiPayload();
        }
        swift_storeEnumTagMultiPayload();
LABEL_24:
        uint64_t v32 = a3[8];
        uint64_t v33 = a1 + v32;
        uint64_t v34 = a2 + v32;
        _s10Foundation3URLVSgWOhTm_0(a1 + v32, &demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
        __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
        if (swift_getEnumCaseMultiPayload() == 1) {
          uint64_t v35 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>;
        }
        else {
          uint64_t v35 = &demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>;
        }
        uint64_t v36 = __swift_instantiateConcreteTypeFromMangledName(v35);
        (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v36 - 8) + 32))(v33, v34, v36);
        swift_storeEnumTagMultiPayload();
        return a1;
      }
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
      if (swift_getEnumCaseMultiPayload() == 1) {
        uint64_t v14 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
      }
      else {
        uint64_t v14 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
      }
      uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(v14);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v15 - 8) + 32))(v10, v11, v15);
      swift_storeEnumTagMultiPayload();
    }
    swift_storeEnumTagMultiPayload();
    goto LABEL_15;
  }
  return a1;
}

uint64_t getEnumTagSinglePayload for MLImageClassifier(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return MEMORY[0x270FA0340](a1, a2, a3, sub_22713EA0C);
}

uint64_t sub_22713EA0C(uint64_t *a1, uint64_t a2, uint64_t a3)
{
  if (a2 == 0x7FFFFFFF)
  {
    uint64_t v4 = *a1;
    if ((unint64_t)*a1 >= 0xFFFFFFFF) {
      LODWORD(v4) = -1;
    }
    return (v4 + 1);
  }
  else
  {
    type metadata accessor for MLClassifierMetrics(0);
    OUTLINED_FUNCTION_6_1();
    if (*(_DWORD *)(v9 + 84) == a2)
    {
      uint64_t v10 = v8;
      uint64_t v11 = *(int *)(a3 + 24);
    }
    else
    {
      uint64_t v10 = type metadata accessor for MLImageClassifier.Model();
      uint64_t v11 = *(int *)(a3 + 32);
    }
    return __swift_getEnumTagSinglePayload((uint64_t)a1 + v11, a2, v10);
  }
}

uint64_t storeEnumTagSinglePayload for MLImageClassifier(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return MEMORY[0x270FA0580](a1, a2, a3, a4, sub_22713EACC);
}

void *sub_22713EACC(void *result, uint64_t a2, int a3, uint64_t a4)
{
  uint64_t v5 = result;
  if (a3 == 0x7FFFFFFF)
  {
    *id result = (a2 - 1);
  }
  else
  {
    type metadata accessor for MLClassifierMetrics(0);
    OUTLINED_FUNCTION_6_1();
    if (*(_DWORD *)(v9 + 84) == a3)
    {
      uint64_t v10 = v8;
      uint64_t v11 = *(int *)(a4 + 24);
    }
    else
    {
      uint64_t v10 = type metadata accessor for MLImageClassifier.Model();
      uint64_t v11 = *(int *)(a4 + 32);
    }
    return (void *)__swift_storeEnumTagSinglePayload((uint64_t)v5 + v11, a2, a2, v10);
  }
  return result;
}

void type metadata completion function for MLImageClassifier()
{
  type metadata accessor for MLClassifierMetrics.Contents(319);
  if (v0 <= 0x3F)
  {
    type metadata accessor for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>();
    if (v1 <= 0x3F) {
      swift_initStructMetadata();
    }
  }
}

uint64_t _s8CreateML27MLTrainingSessionParametersVWOcTm_3(uint64_t a1, uint64_t a2, void (*a3)(void))
{
  a3(0);
  OUTLINED_FUNCTION_8();
  uint64_t v4 = OUTLINED_FUNCTION_111();
  v5(v4);
  return a2;
}

uint64_t outlined destroy of MLImageClassifier.DataSource(uint64_t a1, void (*a2)(void))
{
  a2(0);
  OUTLINED_FUNCTION_8();
  uint64_t v3 = OUTLINED_FUNCTION_22_1();
  v4(v3);
  return a1;
}

uint64_t sub_22713ECF8()
{
  uint64_t v1 = *(void *)(type metadata accessor for MLImageClassifier.ModelParameters.ValidationData() - 8);
  uint64_t v2 = *(unsigned __int8 *)(v1 + 80);
  uint64_t v3 = *(void *)(v1 + 64);
  swift_bridgeObjectRelease();
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload();
  if (EnumCaseMultiPayload == 2) {
    goto LABEL_6;
  }
  if (EnumCaseMultiPayload != 1) {
    goto LABEL_7;
  }
  type metadata accessor for MLImageClassifier.DataSource();
  unsigned int v5 = swift_getEnumCaseMultiPayload();
  if (v5 == 2)
  {
LABEL_6:
    swift_bridgeObjectRelease();
  }
  else if (v5 <= 1)
  {
    type metadata accessor for URL();
    OUTLINED_FUNCTION_8();
    uint64_t v6 = OUTLINED_FUNCTION_22_1();
    v7(v6);
  }
LABEL_7:

  return MEMORY[0x270FA0238](v0, ((v2 + 24) & ~v2) + v3, v2 | 7);
}

uint64_t partial apply for closure #1 in MLImageClassifier.init(trainingData:parameters:classNames:)()
{
  OUTLINED_FUNCTION_60_0();
  type metadata accessor for MLImageClassifier.ModelParameters.ValidationData();
  uint64_t v0 = swift_task_alloc();
  uint64_t v1 = (void *)OUTLINED_FUNCTION_7_1(v0);
  void *v1 = v2;
  v1[1] = partial apply for closure #1 in MLImageClassifier.init(trainingData:parameters:classNames:);
  uint64_t v3 = OUTLINED_FUNCTION_25_16();
  return closure #1 in MLImageClassifier.init(trainingData:parameters:classNames:)(v3);
}

{
  uint64_t *v0;
  uint64_t v1;
  void *v2;
  uint64_t (*v3)(void);
  uint64_t v5;

  OUTLINED_FUNCTION_11();
  OUTLINED_FUNCTION_2();
  uint64_t v1 = *v0;
  OUTLINED_FUNCTION_7();
  *uint64_t v2 = v1;
  swift_task_dealloc();
  OUTLINED_FUNCTION_30();
  return v3();
}

uint64_t outlined destroy of MLImageClassifier.FeatureExtractor(uint64_t a1)
{
  return a1;
}

uint64_t outlined init with take of MLImageClassifier(uint64_t a1, uint64_t a2, void (*a3)(void))
{
  a3(0);
  OUTLINED_FUNCTION_8();
  (*(void (**)(uint64_t, uint64_t))(v5 + 32))(a2, a1);
  return a2;
}

uint64_t OUTLINED_FUNCTION_1_28()
{
  return swift_task_dealloc();
}

uint64_t OUTLINED_FUNCTION_2_36()
{
  return swift_task_dealloc();
}

uint64_t OUTLINED_FUNCTION_3_34()
{
  uint64_t v2 = *(void *)(v0 + 200);
  return outlined destroy of MLImageClassifier.ModelParameters(v2 + 8);
}

uint64_t OUTLINED_FUNCTION_11_19()
{
  return v0 + 8;
}

uint64_t OUTLINED_FUNCTION_15_14()
{
  uint64_t v2 = *(void *)(v0 + 200);
  return outlined destroy of MLImageClassifier.ModelParameters(v2 + 8);
}

uint64_t OUTLINED_FUNCTION_16_15()
{
  return swift_task_alloc();
}

uint64_t OUTLINED_FUNCTION_23_6()
{
  uint64_t v2 = *(void *)(v0 + 216);
  return outlined destroy of MLImageClassifier.ModelParameters(v2);
}

uint64_t OUTLINED_FUNCTION_24_15()
{
  return outlined destroy of MLImageClassifier.DataSource(v0, v1);
}

uint64_t OUTLINED_FUNCTION_25_16()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_27_11()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_29_11@<X0>(uint64_t a1@<X8>)
{
  return a1;
}

uint64_t OUTLINED_FUNCTION_31_7()
{
  return *(void *)(v0 + 96);
}

void OUTLINED_FUNCTION_33_9(uint64_t a1@<X8>)
{
  *(void *)(v2 - 112) = a1;
  *(void *)(v2 - 104) = (v1 - 32) | 0x8000000000000000;
}

uint64_t OUTLINED_FUNCTION_35_9()
{
  return swift_task_alloc();
}

uint64_t OUTLINED_FUNCTION_36_9()
{
  return *(void *)(v0 + 200) + *(int *)(*(void *)(v0 + 408) + 32);
}

uint64_t OUTLINED_FUNCTION_38_8()
{
  uint64_t v2 = *(void *)(v0 + 104);
  return specialized Sequence.flatMap<A>(_:)(v2);
}

uint64_t specialized Dictionary.subscript.setter()
{
  OUTLINED_FUNCTION_14_15();
  uint64_t v0 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MetricsKey?);
  uint64_t v1 = OUTLINED_FUNCTION_17(v0);
  MEMORY[0x270FA5388](v1);
  OUTLINED_FUNCTION_2_37();
  type metadata accessor for MetricsKey();
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v2);
  OUTLINED_FUNCTION_4_32();
  if (v3)
  {
    uint64_t v4 = OUTLINED_FUNCTION_25_17();
    OUTLINED_FUNCTION_11_20(v4, v5, &demangling cache variable for type metadata for _NativeDictionary<String, MetricsKey>, MEMORY[0x263F042E0]);
    swift_bridgeObjectRelease();
    return OUTLINED_FUNCTION_22_14();
  }
  else
  {
    uint64_t v6 = OUTLINED_FUNCTION_1_29();
    uint64_t v8 = v7(v6);
    OUTLINED_FUNCTION_10_19(v8, v9, v10, (void (*)(uint64_t))specialized _NativeDictionary.setValue(_:forKey:isUnique:));
    return swift_bridgeObjectRelease();
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  char v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t (*v7)(uint64_t);
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;

  OUTLINED_FUNCTION_14_15();
  uint64_t v0 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for JSONType?);
  uint64_t v1 = OUTLINED_FUNCTION_17(v0);
  MEMORY[0x270FA5388](v1);
  OUTLINED_FUNCTION_2_37();
  type metadata accessor for JSONType();
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v2);
  OUTLINED_FUNCTION_4_32();
  if (v3)
  {
    uint64_t v4 = OUTLINED_FUNCTION_25_17();
    OUTLINED_FUNCTION_11_20(v4, v5, &demangling cache variable for type metadata for _NativeDictionary<String, JSONType>, MEMORY[0x263F1BF60]);
    swift_bridgeObjectRelease();
    return OUTLINED_FUNCTION_22_14();
  }
  else
  {
    uint64_t v6 = OUTLINED_FUNCTION_1_29();
    uint64_t v8 = v7(v6);
    OUTLINED_FUNCTION_10_19(v8, v9, v10, (void (*)(uint64_t))specialized _NativeDictionary.setValue(_:forKey:isUnique:));
    return swift_bridgeObjectRelease();
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  char v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t (*v7)(uint64_t);
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;

  OUTLINED_FUNCTION_14_15();
  uint64_t v0 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for CSVType?);
  uint64_t v1 = OUTLINED_FUNCTION_17(v0);
  MEMORY[0x270FA5388](v1);
  OUTLINED_FUNCTION_2_37();
  type metadata accessor for CSVType();
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v2);
  OUTLINED_FUNCTION_4_32();
  if (v3)
  {
    uint64_t v4 = OUTLINED_FUNCTION_25_17();
    OUTLINED_FUNCTION_11_20(v4, v5, &demangling cache variable for type metadata for _NativeDictionary<String, CSVType>, MEMORY[0x263F1BF48]);
    swift_bridgeObjectRelease();
    return OUTLINED_FUNCTION_22_14();
  }
  else
  {
    uint64_t v6 = OUTLINED_FUNCTION_1_29();
    uint64_t v8 = v7(v6);
    OUTLINED_FUNCTION_10_19(v8, v9, v10, (void (*)(uint64_t))specialized _NativeDictionary.setValue(_:forKey:isUnique:));
    return swift_bridgeObjectRelease();
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  char v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t (*v7)(uint64_t);
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;

  OUTLINED_FUNCTION_14_15();
  uint64_t v0 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLProgram.Block?);
  uint64_t v1 = OUTLINED_FUNCTION_17(v0);
  MEMORY[0x270FA5388](v1);
  OUTLINED_FUNCTION_2_37();
  type metadata accessor for MLProgram.Block();
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v2);
  OUTLINED_FUNCTION_4_32();
  if (v3)
  {
    uint64_t v4 = OUTLINED_FUNCTION_25_17();
    OUTLINED_FUNCTION_11_20(v4, v5, &demangling cache variable for type metadata for _NativeDictionary<String, MLProgram.Block>, MEMORY[0x263F53328]);
    swift_bridgeObjectRelease();
    return OUTLINED_FUNCTION_22_14();
  }
  else
  {
    uint64_t v6 = OUTLINED_FUNCTION_1_29();
    uint64_t v8 = v7(v6);
    OUTLINED_FUNCTION_10_19(v8, v9, v10, (void (*)(uint64_t))specialized _NativeDictionary.setValue(_:forKey:isUnique:));
    return swift_bridgeObjectRelease();
  }
}

uint64_t specialized Dictionary.subscript.setter(uint64_t a1, uint64_t a2, uint64_t a3)
{
  if (*(void *)(a1 + 24))
  {
    outlined init with take of Any((_OWORD *)a1, v6);
    specialized Dictionary._Variant.setValue(_:forKey:)((uint64_t)v6, a2, a3);
    return swift_bridgeObjectRelease();
  }
  else
  {
    _s10Foundation3URLVSgWOhTm_0(a1, &demangling cache variable for type metadata for Any?);
    specialized Dictionary._Variant.removeValue(forKey:)(a2, a3, v6);
    swift_bridgeObjectRelease();
    return _s10Foundation3URLVSgWOhTm_0((uint64_t)v6, &demangling cache variable for type metadata for Any?);
  }
}

uint64_t specialized Dictionary.subscript.setter(uint64_t a1)
{
  if (*(void *)(a1 + 24))
  {
    outlined init with take of Any((_OWORD *)a1, v6);
    specialized Dictionary._Variant.setValue(_:forKey:)();
    type metadata accessor for CodingUserInfoKey();
    OUTLINED_FUNCTION_8();
    uint64_t v1 = OUTLINED_FUNCTION_22_1();
    return v2(v1);
  }
  else
  {
    _s10Foundation3URLVSgWOhTm_0(a1, &demangling cache variable for type metadata for Any?);
    specialized Dictionary._Variant.removeValue(forKey:)(v6);
    type metadata accessor for CodingUserInfoKey();
    OUTLINED_FUNCTION_8();
    uint64_t v4 = OUTLINED_FUNCTION_22_1();
    v5(v4);
    return _s10Foundation3URLVSgWOhTm_0((uint64_t)v6, &demangling cache variable for type metadata for Any?);
  }
}

uint64_t specialized Dictionary.subscript.setter(uint64_t a1, char a2)
{
  if (*(void *)(a1 + 24))
  {
    outlined init with take of Any((_OWORD *)a1, v4);
    return specialized Dictionary._Variant.setValue(_:forKey:)((uint64_t)v4, a2);
  }
  else
  {
    _s10Foundation3URLVSgWOhTm_0(a1, &demangling cache variable for type metadata for Any?);
    specialized Dictionary._Variant.removeValue(forKey:)(a2, v4);
    return _s10Foundation3URLVSgWOhTm_0((uint64_t)v4, &demangling cache variable for type metadata for Any?);
  }
}

uint64_t specialized Dictionary.subscript.setter(uint64_t a1, uint64_t a2)
{
  if (*(void *)(a1 + 24))
  {
    outlined init with take of Any((_OWORD *)a1, v4);
    specialized Dictionary._Variant.setValue(_:forKey:)(v4, a2);
    return outlined destroy of AnyHashable(a2);
  }
  else
  {
    _s10Foundation3URLVSgWOhTm_0(a1, &demangling cache variable for type metadata for Any?);
    specialized Dictionary._Variant.removeValue(forKey:)(a2, v4);
    outlined destroy of AnyHashable(a2);
    return _s10Foundation3URLVSgWOhTm_0((uint64_t)v4, &demangling cache variable for type metadata for Any?);
  }
}

void specialized _dictionaryUpCast<A, B, C, D>(_:)(uint64_t a1)
{
  uint64_t v67 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (key: MetricsKey, value: Sendable));
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v2);
  OUTLINED_FUNCTION_33_0();
  uint64_t v66 = v3;
  uint64_t v65 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (MetricsKey, Sendable));
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v4);
  OUTLINED_FUNCTION_33_0();
  uint64_t v64 = v5;
  uint64_t v6 = type metadata accessor for MetricsKey();
  OUTLINED_FUNCTION_0();
  uint64_t v68 = v7;
  uint64_t v9 = MEMORY[0x270FA5388](v8);
  uint64_t v11 = (char *)&v54 - ((v10 + 15) & 0xFFFFFFFFFFFFFFF0);
  MEMORY[0x270FA5388](v9);
  uint64_t v62 = (char *)&v54 - v12;
  uint64_t v61 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (key: MetricsKey, value: Double));
  OUTLINED_FUNCTION_8();
  uint64_t v14 = MEMORY[0x270FA5388](v13);
  uint64_t v60 = (char *)&v54 - ((v15 + 15) & 0xFFFFFFFFFFFFFFF0);
  MEMORY[0x270FA5388](v14);
  uint64_t v59 = (char *)&v54 - v16;
  uint64_t v69 = a1;
  if (*(void *)(a1 + 16))
  {
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _DictionaryStorage<MetricsKey, Sendable>);
    uint64_t v17 = static _DictionaryStorage.allocate(capacity:)();
  }
  else
  {
    uint64_t v17 = MEMORY[0x263F8EE80];
  }
  uint64_t v56 = v69 + 64;
  OUTLINED_FUNCTION_16_16();
  unint64_t v20 = v19 & v18;
  uint64_t v54 = v21;
  int64_t v55 = (unint64_t)(63 - v21) >> 6;
  uint64_t v58 = v68 + 16;
  uint64_t v72 = v68 + 32;
  uint64_t v22 = v17 + 64;
  swift_bridgeObjectRetain();
  swift_retain();
  int64_t v70 = 0;
  id v63 = v11;
  unint64_t v57 = (void *)v17;
  uint64_t v23 = (uint64_t)v60;
  if (!v20) {
    goto LABEL_6;
  }
LABEL_5:
  uint64_t v71 = (v20 - 1) & v20;
  for (unint64_t i = __clz(__rbit64(v20)) | (v70 << 6); ; unint64_t i = __clz(__rbit64(v26)) + (v27 << 6))
  {
    uint64_t v34 = v68;
    uint64_t v33 = v69;
    uint64_t v35 = *(void *)(v68 + 72);
    uint64_t v36 = (uint64_t)v59;
    (*(void (**)(char *, unint64_t, uint64_t))(v68 + 16))(v59, *(void *)(v69 + 48) + v35 * i, v6);
    uint64_t v37 = v61;
    *(void *)(v36 + *(int *)(v61 + 48)) = *(void *)(*(void *)(v33 + 56) + 8 * i);
    outlined init with take of (key: MetricsKey, value: Double)(v36, v23);
    uint64_t v38 = *(int *)(v37 + 48);
    uint64_t v39 = (_OWORD *)(v66 + *(int *)(v67 + 48));
    uint64_t v40 = *(void (**)(void))(v34 + 32);
    OUTLINED_FUNCTION_12_15();
    v40();
    *(void *)&v74[0] = *(void *)(v23 + v38);
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Sendable);
    swift_dynamicCast();
    uint64_t v41 = (_OWORD *)(v64 + *(int *)(v65 + 48));
    OUTLINED_FUNCTION_12_15();
    v40();
    outlined init with take of Any(v39, v41);
    OUTLINED_FUNCTION_12_15();
    v40();
    outlined init with take of Any(v41, v74);
    uint64_t v42 = v63;
    OUTLINED_FUNCTION_12_15();
    v40();
    outlined init with take of Any(v74, v73);
    uint64_t v43 = v57;
    lazy protocol witness table accessor for type NSProgressUserInfoKey and conformance NSProgressUserInfoKey(&lazy protocol witness table cache variable for type MetricsKey and conformance MetricsKey, MEMORY[0x263F042E0]);
    dispatch thunk of Hashable._rawHashValue(seed:)();
    OUTLINED_FUNCTION_20_15();
    unint64_t v47 = (v46 << v44) & ~*(void *)(v22 + 8 * v45);
    if (!v47)
    {
      OUTLINED_FUNCTION_30_10();
      while (++v50 != v51 || (v49 & 1) == 0)
      {
        BOOL v52 = v50 == v51;
        if (v50 == v51) {
          uint64_t v50 = 0;
        }
        v49 |= v52;
        uint64_t v53 = *(void *)(v22 + 8 * v50);
        if (v53 != -1)
        {
          unint64_t v48 = __clz(__rbit64(~v53)) + (v50 << 6);
          goto LABEL_35;
        }
      }
      __break(1u);
LABEL_39:
      __break(1u);
      goto LABEL_40;
    }
    unint64_t v48 = __clz(__rbit64(v47)) | v44 & 0x7FFFFFFFFFFFFFC0;
LABEL_35:
    *(void *)(v22 + ((v48 >> 3) & 0x1FFFFFFFFFFFFFF8)) |= 1 << v48;
    ((void (*)(unint64_t, char *, uint64_t))v40)(v43[6] + v48 * v35, v42, v6);
    outlined init with take of Any(v73, (_OWORD *)(v43[7] + 32 * v48));
    ++v43[2];
    unint64_t v20 = v71;
    if (v71) {
      goto LABEL_5;
    }
LABEL_6:
    int64_t v25 = v70 + 1;
    if (__OFADD__(v70, 1)) {
      goto LABEL_39;
    }
    if (v25 >= v55) {
      goto LABEL_37;
    }
    unint64_t v26 = *(void *)(v56 + 8 * v25);
    int64_t v27 = v70 + 1;
    if (!v26)
    {
      OUTLINED_FUNCTION_15_15();
      if (v28 == v29) {
        goto LABEL_37;
      }
      OUTLINED_FUNCTION_13_22();
      if (!v26)
      {
        OUTLINED_FUNCTION_15_15();
        if (v28 == v29) {
          goto LABEL_37;
        }
        OUTLINED_FUNCTION_13_22();
        if (!v26)
        {
          OUTLINED_FUNCTION_15_15();
          if (v28 == v29) {
            goto LABEL_37;
          }
          OUTLINED_FUNCTION_13_22();
          if (!v26) {
            break;
          }
        }
      }
    }
LABEL_25:
    int64_t v70 = v27;
    uint64_t v71 = (v26 - 1) & v26;
  }
  int64_t v31 = v30 + 4;
  if (v31 >= v55)
  {
LABEL_37:
    swift_release();
    outlined consume of [String : [Int]].Iterator._Variant();
    return;
  }
  unint64_t v26 = *(void *)(v56 + 8 * v31);
  if (v26)
  {
    int64_t v27 = v31;
    goto LABEL_25;
  }
  while (!__OFADD__(v31, 1))
  {
    OUTLINED_FUNCTION_15_15();
    if (v28 == v29) {
      goto LABEL_37;
    }
    OUTLINED_FUNCTION_13_22();
    int64_t v31 = v32 + 1;
    if (v26) {
      goto LABEL_25;
    }
  }
LABEL_40:
  __break(1u);
}

void *specialized _dictionaryUpCast<A, B, C, D>(_:)(void *a1)
{
  if (a1[2])
  {
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _DictionaryStorage<MLProgress.Metric, Any>);
    uint64_t v2 = (void *)static _DictionaryStorage.allocate(capacity:)();
  }
  else
  {
    uint64_t v2 = (void *)MEMORY[0x263F8EE80];
  }
  uint64_t v33 = a1 + 8;
  OUTLINED_FUNCTION_16_16();
  unint64_t v5 = v4 & v3;
  int64_t v32 = (unint64_t)(63 - v6) >> 6;
  uint64_t v7 = v2 + 8;
  swift_bridgeObjectRetain();
  swift_retain();
  int64_t v8 = 0;
  if (!v5) {
    goto LABEL_6;
  }
LABEL_5:
  unint64_t v9 = __clz(__rbit64(v5));
  v5 &= v5 - 1;
  unint64_t v10 = v9 | (v8 << 6);
  while (1)
  {
    uint64_t v19 = *(void *)(a1[7] + 8 * v10);
    LOBYTE(v36[0]) = *(unsigned char *)(a1[6] + v10);
    *(void *)&v35[0] = v19;
    swift_dynamicCast();
    char v20 = v36[0];
    outlined init with take of Any((_OWORD *)((char *)v36 + 8), v34);
    outlined init with take of Any(v34, v36);
    outlined init with take of Any(v36, v35);
    Hasher.init(_seed:)();
    String.hash(into:)();
    swift_bridgeObjectRelease();
    Hasher._finalize()();
    OUTLINED_FUNCTION_20_15();
    unint64_t v24 = (v23 << v21) & ~v7[v22];
    if (v24)
    {
      unint64_t v25 = __clz(__rbit64(v24)) | v21 & 0x7FFFFFFFFFFFFFC0;
      goto LABEL_35;
    }
    OUTLINED_FUNCTION_30_10();
    do
    {
      if (++v27 == v28 && (v26 & 1) != 0)
      {
        __break(1u);
LABEL_39:
        __break(1u);
        goto LABEL_40;
      }
      BOOL v29 = v27 == v28;
      if (v27 == v28) {
        uint64_t v27 = 0;
      }
      v26 |= v29;
      uint64_t v30 = v7[v27];
    }
    while (v30 == -1);
    unint64_t v25 = __clz(__rbit64(~v30)) + (v27 << 6);
LABEL_35:
    *(void *)((char *)v7 + ((v25 >> 3) & 0x1FFFFFFFFFFFFFF8)) |= 1 << v25;
    *(unsigned char *)(v2[6] + v25) = v20;
    outlined init with take of Any(v35, (_OWORD *)(v2[7] + 32 * v25));
    ++v2[2];
    if (v5) {
      goto LABEL_5;
    }
LABEL_6:
    int64_t v11 = v8 + 1;
    if (__OFADD__(v8, 1)) {
      goto LABEL_39;
    }
    if (v11 >= v32) {
      goto LABEL_37;
    }
    unint64_t v12 = v33[v11];
    int64_t v13 = v8 + 1;
    if (!v12)
    {
      OUTLINED_FUNCTION_24_16();
      if (v14 == v15) {
        goto LABEL_37;
      }
      OUTLINED_FUNCTION_23_7();
      if (!v12)
      {
        OUTLINED_FUNCTION_24_16();
        if (v14 == v15) {
          goto LABEL_37;
        }
        OUTLINED_FUNCTION_23_7();
        if (!v12)
        {
          OUTLINED_FUNCTION_24_16();
          if (v14 == v15) {
            goto LABEL_37;
          }
          OUTLINED_FUNCTION_23_7();
          if (!v12) {
            break;
          }
        }
      }
    }
LABEL_25:
    unint64_t v5 = (v12 - 1) & v12;
    unint64_t v10 = __clz(__rbit64(v12)) + (v13 << 6);
    int64_t v8 = v13;
  }
  int64_t v17 = v16 + 4;
  if (v17 < v32)
  {
    unint64_t v12 = v33[v17];
    if (v12)
    {
      int64_t v13 = v17;
      goto LABEL_25;
    }
    while (!__OFADD__(v17, 1))
    {
      OUTLINED_FUNCTION_24_16();
      if (v14 == v15) {
        goto LABEL_37;
      }
      OUTLINED_FUNCTION_23_7();
      int64_t v17 = v18 + 1;
      if (v12) {
        goto LABEL_25;
      }
    }
LABEL_40:
    __break(1u);
    JUMPOUT(0x227140964);
  }
LABEL_37:
  swift_release();
  outlined consume of [String : [Int]].Iterator._Variant();
  return v2;
}

double MLProgress.elapsedTime.getter()
{
  return *(double *)v0;
}

void MLProgress.elapsedTime.setter(double a1)
{
  double *v1 = a1;
}

uint64_t (*MLProgress.elapsedTime.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

void MLProgress.phase.getter(unsigned char *a1@<X8>)
{
  *a1 = *(unsigned char *)(v1 + 8);
}

unsigned char *MLProgress.phase.setter(unsigned char *result)
{
  *(unsigned char *)(v1 + 8) = *result;
  return result;
}

uint64_t (*MLProgress.phase.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLProgress.itemCount.getter()
{
  return *(void *)(v0 + 16);
}

uint64_t MLProgress.itemCount.setter(uint64_t result)
{
  *(void *)(v1 + 16) = result;
  return result;
}

uint64_t (*MLProgress.itemCount.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLProgress.totalItemCount.getter()
{
  return *(void *)(v0 + 24);
}

uint64_t MLProgress.totalItemCount.setter(uint64_t result, char a2)
{
  *(void *)(v2 + 24) = result;
  *(unsigned char *)(v2 + 32) = a2 & 1;
  return result;
}

uint64_t (*MLProgress.totalItemCount.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLProgress.metrics.getter()
{
  return swift_bridgeObjectRetain();
}

uint64_t MLProgress.metrics.setter(uint64_t a1)
{
  uint64_t result = swift_bridgeObjectRelease();
  *(void *)(v1 + 40) = a1;
  return result;
}

uint64_t (*MLProgress.metrics.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLProgress.init(phase:)@<X0>(char *a1@<X0>, uint64_t a2@<X8>)
{
  char v3 = *a1;
  lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  uint64_t result = Dictionary.init(dictionaryLiteral:)();
  *(void *)a2 = 0;
  *(unsigned char *)(a2 + 8) = v3;
  *(void *)(a2 + 16) = 0;
  *(void *)(a2 + 24) = 0;
  *(unsigned char *)(a2 + 32) = 1;
  *(void *)(a2 + 40) = result;
  return result;
}

void MLProgress.init(progress:)(void *a1@<X0>, uint64_t a2@<X8>)
{
  unsigned __int8 v103 = 1;
  lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  unint64_t v4 = MEMORY[0x263F8EE58];
  Swift::Int v5 = Dictionary.init(dictionaryLiteral:)();
  id isUniquelyReferenced_nonNull_native = OUTLINED_FUNCTION_19_15();
  type metadata accessor for NSProgressUserInfoKey(0);
  int64_t v8 = v7;
  uint64_t v9 = lazy protocol witness table accessor for type NSProgressUserInfoKey and conformance NSProgressUserInfoKey(&lazy protocol witness table cache variable for type NSProgressUserInfoKey and conformance NSProgressUserInfoKey, type metadata accessor for NSProgressUserInfoKey);
  static Dictionary._unconditionallyBridgeFromObjectiveC(_:)();

  if (one-time initialization token for elapsedTimeKey != -1) {
    swift_once();
  }
  id v10 = (id)static MLProgress.elapsedTimeKey;
  OUTLINED_FUNCTION_7_23((uint64_t)v10, v11, v12, v13, v14, v15, v16, v17, v69, v72, v75, v78, v81, v83, v86, v89, v92, v95, v98,
    *((uint64_t *)&v98 + 1),
    v99,
    v100,
    v101);

  swift_bridgeObjectRelease();
  if (!*((void *)&v102 + 1)) {
    goto LABEL_16;
  }
  if ((OUTLINED_FUNCTION_5_25() & 1) == 0) {
    goto LABEL_17;
  }
  id v18 = OUTLINED_FUNCTION_19_15();
  OUTLINED_FUNCTION_8_22();

  if (one-time initialization token for phaseKey != -1) {
    swift_once();
  }
  id v19 = (id)static MLProgress.phaseKey;
  OUTLINED_FUNCTION_7_23((uint64_t)v19, v20, v21, v22, v23, v24, v25, v26, v70, v73, v76, v79, v98, v84, v87, v90, v93, v96, v98,
    *((uint64_t *)&v98 + 1),
    v99,
    v100,
    v101);

  swift_bridgeObjectRelease();
  if ((OUTLINED_FUNCTION_5_25() & 1) == 0) {
    goto LABEL_17;
  }
  uint64_t v80 = v98;
  id v27 = OUTLINED_FUNCTION_19_15();
  OUTLINED_FUNCTION_8_22();

  if (one-time initialization token for itemCountKey != -1) {
LABEL_69:
  }
    swift_once();
  id v28 = (id)static MLProgress.itemCountKey;
  OUTLINED_FUNCTION_7_23((uint64_t)v28, v29, v30, v31, v32, v33, v34, v35, v71, v74, v77, v80, v82, v85, v88, v91, v94, (uint64_t)v97, v98,
    *((uint64_t *)&v98 + 1),
    v99,
    v100,
    v101);

  swift_bridgeObjectRelease();
  if (!*((void *)&v102 + 1))
  {
LABEL_16:

    _s10Foundation3URLVSgWOhTm_0((uint64_t)&v101, &demangling cache variable for type metadata for Any?);
LABEL_18:
    swift_bridgeObjectRelease();
    *(_OWORD *)(a2 + 16) = 0u;
    *(_OWORD *)(a2 + 32) = 0u;
    *(_OWORD *)a2 = 0u;
    return;
  }
  if ((OUTLINED_FUNCTION_5_25() & 1) == 0)
  {
LABEL_17:

    goto LABEL_18;
  }
  uint64_t v77 = v98;
  id v36 = OUTLINED_FUNCTION_19_15();
  OUTLINED_FUNCTION_8_22();

  if (one-time initialization token for totalItemCountKey != -1) {
    goto LABEL_71;
  }
  while (1)
  {
    id v37 = (id)static MLProgress.totalItemCountKey;
    OUTLINED_FUNCTION_7_23((uint64_t)v37, v38, v39, v40, v41, v42, v43, v44, v71, v74, v77, v80, v82, v85, v88, v91, v94, (uint64_t)v97, v98,
      *((uint64_t *)&v98 + 1),
      v99,
      v100,
      v101);

    swift_bridgeObjectRelease();
    uint64_t v91 = v9;
    if (*((void *)&v102 + 1))
    {
      int v45 = swift_dynamicCast();
      uint64_t v46 = v98;
      if (!v45) {
        uint64_t v46 = 0;
      }
      uint64_t v74 = v46;
      unsigned int v47 = v45 ^ 1;
    }
    else
    {
      _s10Foundation3URLVSgWOhTm_0((uint64_t)&v101, &demangling cache variable for type metadata for Any?);
      uint64_t v74 = 0;
      unsigned int v47 = 1;
    }
    id isUniquelyReferenced_nonNull_native = (id)MEMORY[0x263F8D538];
    unsigned __int8 v103 = v47;
    uint64_t v9 = qword_26DB3FD48;
    if (!qword_26DB3FD48) {
      break;
    }
    unint64_t v48 = &byte_26DB3FD58;
    uint64_t v85 = (uint64_t)v8;
    uint64_t v88 = v4 + 8;
    while (1)
    {
      unsigned int v50 = *v48++;
      uint64_t v49 = v50;
      if (v50 == 6 && (id)type metadata accessor for URL() != isUniquelyReferenced_nonNull_native) {
        goto LABEL_64;
      }
      uint64_t v94 = (uint64_t)v48;
      id v51 = OUTLINED_FUNCTION_19_15();
      uint64_t v52 = static Dictionary._unconditionallyBridgeFromObjectiveC(_:)();

      switch(v49)
      {
        case 1:
          uint64_t v53 = &static MLProgress.contentLossKey;
          id isUniquelyReferenced_nonNull_native = (id)MEMORY[0x263F8D538];
          if (one-time initialization token for contentLossKey != -1)
          {
            swift_once();
            uint64_t v53 = &static MLProgress.contentLossKey;
          }
          break;
        case 2:
          uint64_t v53 = &static MLProgress.styleLossKey;
          id isUniquelyReferenced_nonNull_native = (id)MEMORY[0x263F8D538];
          if (one-time initialization token for styleLossKey != -1)
          {
            swift_once();
            uint64_t v53 = &static MLProgress.styleLossKey;
          }
          break;
        case 3:
          uint64_t v53 = &static MLProgress.accuracyKey;
          id isUniquelyReferenced_nonNull_native = (id)MEMORY[0x263F8D538];
          if (one-time initialization token for accuracyKey != -1)
          {
            swift_once();
            uint64_t v53 = &static MLProgress.accuracyKey;
          }
          break;
        case 4:
          uint64_t v53 = &static MLProgress.validationLossKey;
          id isUniquelyReferenced_nonNull_native = (id)MEMORY[0x263F8D538];
          if (one-time initialization token for validationLossKey != -1)
          {
            swift_once();
            uint64_t v53 = &static MLProgress.validationLossKey;
          }
          break;
        case 5:
          uint64_t v53 = &static MLProgress.validationAccuracyKey;
          id isUniquelyReferenced_nonNull_native = (id)MEMORY[0x263F8D538];
          if (one-time initialization token for validationAccuracyKey != -1)
          {
            swift_once();
            uint64_t v53 = &static MLProgress.validationAccuracyKey;
          }
          break;
        case 6:
          uint64_t v53 = &static MLProgress.stylizedImageKey;
          id isUniquelyReferenced_nonNull_native = (id)MEMORY[0x263F8D538];
          if (one-time initialization token for stylizedImageKey != -1)
          {
            swift_once();
            uint64_t v53 = &static MLProgress.stylizedImageKey;
          }
          break;
        case 7:
          uint64_t v53 = &static MLProgress.rootMeanSquaredErrorKey;
          id isUniquelyReferenced_nonNull_native = (id)MEMORY[0x263F8D538];
          if (one-time initialization token for rootMeanSquaredErrorKey != -1)
          {
            swift_once();
            uint64_t v53 = &static MLProgress.rootMeanSquaredErrorKey;
          }
          break;
        case 8:
          uint64_t v53 = &static MLProgress.maximumErrorKey;
          id isUniquelyReferenced_nonNull_native = (id)MEMORY[0x263F8D538];
          if (one-time initialization token for maximumErrorKey != -1)
          {
            swift_once();
            uint64_t v53 = &static MLProgress.maximumErrorKey;
          }
          break;
        case 9:
          uint64_t v53 = &static MLProgress.validationRootMeanSquaredErrorKey;
          id isUniquelyReferenced_nonNull_native = (id)MEMORY[0x263F8D538];
          if (one-time initialization token for validationRootMeanSquaredErrorKey != -1)
          {
            swift_once();
            uint64_t v53 = &static MLProgress.validationRootMeanSquaredErrorKey;
          }
          break;
        case 10:
          uint64_t v53 = &static MLProgress.validationMaximumErrorKey;
          id isUniquelyReferenced_nonNull_native = (id)MEMORY[0x263F8D538];
          if (one-time initialization token for validationMaximumErrorKey != -1)
          {
            swift_once();
            uint64_t v53 = &static MLProgress.validationMaximumErrorKey;
          }
          break;
        default:
          uint64_t v53 = &static MLProgress.lossKey;
          id isUniquelyReferenced_nonNull_native = (id)MEMORY[0x263F8D538];
          if (one-time initialization token for lossKey != -1)
          {
            swift_once();
            uint64_t v53 = &static MLProgress.lossKey;
          }
          break;
      }
      id v54 = (id)*v53;
      int64_t v8 = v54;
      if (*(void *)(v52 + 16) && (unint64_t v55 = specialized __RawDictionaryStorage.find<A>(_:)((uint64_t)v54), (v56 & 1) != 0))
      {
        outlined init with copy of Any(*(void *)(v52 + 56) + 32 * v55, (uint64_t)&v101);
      }
      else
      {
        long long v101 = 0u;
        long long v102 = 0u;
      }

      swift_bridgeObjectRelease();
      if (!*((void *)&v102 + 1))
      {
        _s10Foundation3URLVSgWOhTm_0((uint64_t)&v101, &demangling cache variable for type metadata for Any?);
        goto LABEL_60;
      }
      if (swift_dynamicCast()) {
        break;
      }
LABEL_60:
      unint64_t v48 = (char *)v94;
LABEL_64:
      if (!--v9)
      {
        swift_bridgeObjectRelease();

        unsigned int v47 = v103;
        goto LABEL_67;
      }
    }
    unint64_t v57 = v4;
    *((void *)&v102 + 1) = isUniquelyReferenced_nonNull_native;
    *(void *)&long long v101 = v98;
    outlined init with take of Any(&v101, &v98);
    id isUniquelyReferenced_nonNull_native = (id)swift_isUniquelyReferenced_nonNull_native();
    uint64_t v97 = (void *)v5;
    unint64_t v58 = specialized __RawDictionaryStorage.find<A>(_:)(v49);
    uint64_t v60 = *(void *)(v5 + 16);
    BOOL v61 = (v59 & 1) == 0;
    Swift::Int v5 = v60 + v61;
    if (__OFADD__(v60, v61))
    {
      __break(1u);
      goto LABEL_69;
    }
    unint64_t v4 = v58;
    int64_t v8 = v59;
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<MLProgress.Metric, Any>);
    Swift::Bool v62 = _NativeDictionary.ensureUnique(isUnique:capacity:)((Swift::Bool)isUniquelyReferenced_nonNull_native, v5);
    id isUniquelyReferenced_nonNull_native = (id)MEMORY[0x263F8D538];
    if (v62)
    {
      unint64_t v63 = specialized __RawDictionaryStorage.find<A>(_:)(v49);
      if ((v8 & 1) != (v64 & 1))
      {
        KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)();
        __break(1u);
        JUMPOUT(0x227141438);
      }
      unint64_t v4 = v63;
    }
    Swift::Int v5 = (Swift::Int)v97;
    if (v8)
    {
      uint64_t v65 = (_OWORD *)(v97[7] + 32 * v4);
      __swift_destroy_boxed_opaque_existential_0((uint64_t)v65);
      outlined init with take of Any(&v98, v65);
LABEL_63:
      unint64_t v4 = v57;
      unint64_t v48 = (char *)v94;
      swift_bridgeObjectRelease();
      goto LABEL_64;
    }
    v97[(v4 >> 6) + 8] |= 1 << v4;
    *(unsigned char *)(v97[6] + v4) = v49;
    outlined init with take of Any(&v98, (_OWORD *)(v97[7] + 32 * v4));
    uint64_t v66 = v97[2];
    BOOL v67 = __OFADD__(v66, 1);
    uint64_t v68 = v66 + 1;
    if (!v67)
    {
      v97[2] = v68;
      goto LABEL_63;
    }
    __break(1u);
LABEL_71:
    swift_once();
  }
  swift_bridgeObjectRelease();

LABEL_67:
  *(void *)a2 = v82;
  *(void *)(a2 + 8) = v80;
  *(void *)(a2 + 16) = v77;
  *(void *)(a2 + 24) = v74;
  *(void *)(a2 + 32) = v47;
  *(void *)(a2 + 40) = v5;
}

void *static MLProgress.Metric.allCases.getter()
{
  return &outlined read-only object #0 of static MLProgress.Metric.allCases.getter;
}

CreateML::MLProgress::Metric_optional __swiftcall MLProgress.Metric.init(rawValue:)(Swift::String rawValue)
{
  uint64_t object = rawValue._object;
  v3._uint64_t countAndFlagsBits = rawValue._countAndFlagsBits;
  unint64_t v4 = v1;
  v3._uint64_t object = object;
  unint64_t v5 = _findStringSwitchCase(cases:string:)((Swift::OpaquePointer)&outlined read-only object #0 of MLProgress.Metric.init(rawValue:), v3);
  result.value = swift_bridgeObjectRelease();
  char v7 = 11;
  if (v5 < 0xB) {
    char v7 = v5;
  }
  *unint64_t v4 = v7;
  return result;
}

unint64_t MLProgress.Metric.rawValue.getter()
{
  unint64_t result = 1936945004;
  switch(*v0)
  {
    case 1:
      unint64_t result = 0x4C746E65746E6F63;
      break;
    case 2:
      unint64_t result = 0x736F4C656C797473;
      break;
    case 3:
      unint64_t result = 0x7963617275636361;
      break;
    case 4:
      unint64_t result = 0x69746164696C6176;
      break;
    case 5:
      unint64_t result = 0xD000000000000012;
      break;
    case 6:
      unint64_t result = 0xD000000000000010;
      break;
    case 7:
      unint64_t result = 0xD000000000000014;
      break;
    case 8:
      unint64_t result = 0x456D756D6978616DLL;
      break;
    case 9:
      unint64_t result = 0xD00000000000001ELL;
      break;
    case 0xA:
      unint64_t result = 0xD000000000000016;
      break;
    default:
      return result;
  }
  return result;
}

uint64_t protocol witness for static Equatable.== infix(_:_:) in conformance MLProgress.Metric(unsigned __int8 *a1, char *a2)
{
  return specialized == infix<A>(_:_:)(*a1, *a2);
}

CreateML::MLProgress::Metric_optional protocol witness for RawRepresentable.init(rawValue:) in conformance MLProgress.Metric(Swift::String *a1)
{
  return MLProgress.Metric.init(rawValue:)(*a1);
}

unint64_t protocol witness for RawRepresentable.rawValue.getter in conformance MLProgress.Metric@<X0>(unint64_t *a1@<X8>)
{
  unint64_t result = MLProgress.Metric.rawValue.getter();
  *a1 = result;
  a1[1] = v3;
  return result;
}

uint64_t protocol witness for Decodable.init(from:) in conformance MLProgress.Metric()
{
  return RawRepresentable<>.init(from:)();
}

uint64_t protocol witness for Encodable.encode(to:) in conformance MLProgress.Metric()
{
  return RawRepresentable<>.encode(to:)();
}

CreateML::MLProgress::CodingKeys_optional __swiftcall MLProgress.CodingKeys.init(stringValue:)(Swift::String stringValue)
{
  BOOL v1 = stringValue._countAndFlagsBits == 0x5464657370616C65 && stringValue._object == (void *)0xEB00000000656D69;
  if (v1
    || (uint64_t object = stringValue._object,
        uint64_t countAndFlagsBits = stringValue._countAndFlagsBits,
        (OUTLINED_FUNCTION_4_7() & 1) != 0))
  {
    swift_bridgeObjectRelease();
    return 0;
  }
  else
  {
    BOOL v5 = countAndFlagsBits == 0x6573616870 && object == (void *)0xE500000000000000;
    if (v5 || (OUTLINED_FUNCTION_21_16(), (OUTLINED_FUNCTION_4_7() & 1) != 0))
    {
      swift_bridgeObjectRelease();
      return (CreateML::MLProgress::CodingKeys_optional)1;
    }
    else
    {
      BOOL v6 = countAndFlagsBits == 0x6F72506573616870 && object == (void *)0xED00007373657267;
      if (v6 || (OUTLINED_FUNCTION_4_7() & 1) != 0)
      {
        swift_bridgeObjectRelease();
        return (CreateML::MLProgress::CodingKeys_optional)2;
      }
      else if (countAndFlagsBits == 0x7363697274656DLL && object == (void *)0xE700000000000000)
      {
        swift_bridgeObjectRelease();
        return (CreateML::MLProgress::CodingKeys_optional)3;
      }
      else
      {
        char v8 = OUTLINED_FUNCTION_4_7();
        swift_bridgeObjectRelease();
        if (v8) {
          return (CreateML::MLProgress::CodingKeys_optional)3;
        }
        else {
          return (CreateML::MLProgress::CodingKeys_optional)4;
        }
      }
    }
  }
}

uint64_t MLProgress.CodingKeys.stringValue.getter(char a1)
{
  uint64_t result = 0x5464657370616C65;
  switch(a1)
  {
    case 1:
      uint64_t result = 0x6573616870;
      break;
    case 2:
      uint64_t result = 0x6F72506573616870;
      break;
    case 3:
      uint64_t result = 0x7363697274656DLL;
      break;
    default:
      return result;
  }
  return result;
}

Swift::Int protocol witness for Hashable.hashValue.getter in conformance MLProgress.Metric()
{
  return specialized RawRepresentable<>.hashValue.getter(*v0);
}

uint64_t protocol witness for Hashable.hash(into:) in conformance MLProgress.Metric(uint64_t a1)
{
  return specialized RawRepresentable<>.hash(into:)(a1, *v1);
}

Swift::Int protocol witness for Hashable._rawHashValue(seed:) in conformance MLProgress.Metric(uint64_t a1)
{
  return specialized RawRepresentable<>._rawHashValue(seed:)(a1, *v1);
}

void protocol witness for static CaseIterable.allCases.getter in conformance MLProgress.Metric(void *a1@<X8>)
{
  *a1 = &outlined read-only object #0 of static MLProgress.Metric.allCases.getter;
}

uint64_t protocol witness for CodingKey.stringValue.getter in conformance MLProgress.CodingKeys()
{
  return MLProgress.CodingKeys.stringValue.getter(*v0);
}

CreateML::MLProgress::CodingKeys_optional protocol witness for CodingKey.init(stringValue:) in conformance MLProgress.CodingKeys@<W0>(uint64_t a1@<X0>, CreateML::MLProgress::CodingKeys_optional *a2@<X8>)
{
  result.value = MLProgress.CodingKeys.init(stringValue:)(*(Swift::String *)&a1).value;
  a2->value = result.value;
  return result;
}

void protocol witness for CodingKey.init(intValue:) in conformance MLProgress.CodingKeys(unsigned char *a1@<X8>)
{
  *a1 = 4;
}

uint64_t protocol witness for CustomStringConvertible.description.getter in conformance MLProgress.CodingKeys(uint64_t a1)
{
  unint64_t v2 = lazy protocol witness table accessor for type MLProgress.CodingKeys and conformance MLProgress.CodingKeys();

  return MEMORY[0x270FA00B0](a1, v2);
}

uint64_t protocol witness for CustomDebugStringConvertible.debugDescription.getter in conformance MLProgress.CodingKeys(uint64_t a1)
{
  unint64_t v2 = lazy protocol witness table accessor for type MLProgress.CodingKeys and conformance MLProgress.CodingKeys();

  return MEMORY[0x270FA00B8](a1, v2);
}

uint64_t MLProgress.init(from:)@<X0>(void *a1@<X0>, uint64_t a2@<X8>)
{
  uint64_t v22 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for KeyedDecodingContainer<MLProgress.CodingKeys>);
  OUTLINED_FUNCTION_0();
  uint64_t v6 = v5;
  MEMORY[0x270FA5388](v7);
  uint64_t v9 = (char *)&v20 - ((v8 + 15) & 0xFFFFFFFFFFFFFFF0);
  lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  Dictionary.init(dictionaryLiteral:)();
  __swift_project_boxed_opaque_existential_1(a1, a1[3]);
  lazy protocol witness table accessor for type MLProgress.CodingKeys and conformance MLProgress.CodingKeys();
  dispatch thunk of Decoder.container<A>(keyedBy:)();
  if (!v2)
  {
    uint64_t v10 = v6;
    char v27 = 0;
    uint64_t v11 = v22;
    KeyedDecodingContainer.decode(_:forKey:)();
    uint64_t v13 = v12;
    char v25 = 1;
    lazy protocol witness table accessor for type MLPhase and conformance MLPhase();
    KeyedDecodingContainer.decode<A>(_:forKey:)();
    int v14 = v26;
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [MLProgress.Metric : Double]);
    char v23 = 3;
    lazy protocol witness table accessor for type [MLProgress.Metric : Double] and conformance <> [A : B](&lazy protocol witness table cache variable for type [MLProgress.Metric : Double] and conformance <> [A : B], (void (*)(void))lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric);
    KeyedDecodingContainer.decode<A>(_:forKey:)();
    uint64_t v16 = specialized _dictionaryUpCast<A, B, C, D>(_:)(v24);
    int v21 = v14;
    uint64_t v17 = v11;
    uint64_t v18 = v10;
    id v19 = v16;
    swift_bridgeObjectRelease();
    (*(void (**)(char *, uint64_t))(v18 + 8))(v9, v17);
    swift_bridgeObjectRetain();
    swift_bridgeObjectRelease();
    *(void *)a2 = v13;
    *(unsigned char *)(a2 + 8) = v21;
    *(void *)(a2 + 16) = 0;
    *(void *)(a2 + 24) = 0;
    *(unsigned char *)(a2 + 32) = 1;
    *(void *)(a2 + 40) = v19;
  }
  __swift_destroy_boxed_opaque_existential_0((uint64_t)a1);
  return swift_bridgeObjectRelease();
}

uint64_t MLProgress.encode(to:)(void *a1)
{
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for KeyedEncodingContainer<MLProgress.CodingKeys>);
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v4);
  uint64_t v5 = *(void *)(v1 + 40);
  __swift_project_boxed_opaque_existential_1(a1, a1[3]);
  lazy protocol witness table accessor for type MLProgress.CodingKeys and conformance MLProgress.CodingKeys();
  dispatch thunk of Encoder.container<A>(keyedBy:)();
  KeyedEncodingContainer.encode(_:forKey:)();
  if (v2)
  {
    uint64_t v6 = OUTLINED_FUNCTION_26_12();
    return v7(v6);
  }
  else
  {
    lazy protocol witness table accessor for type MLPhase and conformance MLPhase();
    KeyedEncodingContainer.encode<A>(_:forKey:)();
    specialized Dictionary.compactMapValues<A>(_:)(v5);
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [MLProgress.Metric : Double]);
    lazy protocol witness table accessor for type [MLProgress.Metric : Double] and conformance <> [A : B](&lazy protocol witness table cache variable for type [MLProgress.Metric : Double] and conformance <> [A : B], (void (*)(void))lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric);
    KeyedEncodingContainer.encode<A>(_:forKey:)();
    uint64_t v8 = OUTLINED_FUNCTION_26_12();
    v9(v8);
    return swift_bridgeObjectRelease();
  }
}

uint64_t protocol witness for Decodable.init(from:) in conformance MLProgress@<X0>(void *a1@<X0>, uint64_t a2@<X8>)
{
  return MLProgress.init(from:)(a1, a2);
}

uint64_t protocol witness for Encodable.encode(to:) in conformance MLProgress(void *a1)
{
  return MLProgress.encode(to:)(a1);
}

uint64_t one-time initialization function for elapsedTimeKey()
{
  uint64_t result = MEMORY[0x22A674AE0](0x5F64657370616C65, 0xEC000000656D6974);
  static MLProgress.elapsedTimeKey = result;
  return result;
}

id static MLProgress.elapsedTimeKey.getter()
{
  return static MLProgress.elapsedTimeKey.getter(&one-time initialization token for elapsedTimeKey, (void **)&static MLProgress.elapsedTimeKey);
}

uint64_t one-time initialization function for phaseKey()
{
  uint64_t v0 = OUTLINED_FUNCTION_21_16();
  uint64_t result = MEMORY[0x22A674AE0](v0);
  static MLProgress.phaseKey = result;
  return result;
}

id static MLProgress.phaseKey.getter()
{
  return static MLProgress.elapsedTimeKey.getter(&one-time initialization token for phaseKey, (void **)&static MLProgress.phaseKey);
}

uint64_t one-time initialization function for itemCountKey()
{
  uint64_t result = MEMORY[0x22A674AE0](0x756F635F6D657469, 0xEA0000000000746ELL);
  static MLProgress.itemCountKey = result;
  return result;
}

id static MLProgress.itemCountKey.getter()
{
  return static MLProgress.elapsedTimeKey.getter(&one-time initialization token for itemCountKey, (void **)&static MLProgress.itemCountKey);
}

void one-time initialization function for totalItemCountKey()
{
  OUTLINED_FUNCTION_27_12();
  static MLProgress.totalItemCountKey = v0;
}

id static MLProgress.totalItemCountKey.getter()
{
  return static MLProgress.elapsedTimeKey.getter(&one-time initialization token for totalItemCountKey, (void **)&static MLProgress.totalItemCountKey);
}

uint64_t one-time initialization function for lossKey()
{
  uint64_t result = MEMORY[0x22A674AE0](1936945004, 0xE400000000000000);
  static MLProgress.lossKey = result;
  return result;
}

id static MLProgress.lossKey.getter()
{
  return static MLProgress.elapsedTimeKey.getter(&one-time initialization token for lossKey, (void **)&static MLProgress.lossKey);
}

uint64_t one-time initialization function for contentLossKey()
{
  uint64_t result = MEMORY[0x22A674AE0](0x5F746E65746E6F63, 0xEC00000073736F6CLL);
  static MLProgress.contentLossKey = result;
  return result;
}

id static MLProgress.contentLossKey.getter()
{
  return static MLProgress.elapsedTimeKey.getter(&one-time initialization token for contentLossKey, (void **)&static MLProgress.contentLossKey);
}

uint64_t one-time initialization function for styleLossKey()
{
  uint64_t result = MEMORY[0x22A674AE0](0x6F6C5F656C797473, 0xEA00000000007373);
  static MLProgress.styleLossKey = result;
  return result;
}

id static MLProgress.styleLossKey.getter()
{
  return static MLProgress.elapsedTimeKey.getter(&one-time initialization token for styleLossKey, (void **)&static MLProgress.styleLossKey);
}

uint64_t one-time initialization function for accuracyKey()
{
  uint64_t result = MEMORY[0x22A674AE0](0x7963617275636361, 0xE800000000000000);
  static MLProgress.accuracyKey = result;
  return result;
}

id static MLProgress.accuracyKey.getter()
{
  return static MLProgress.elapsedTimeKey.getter(&one-time initialization token for accuracyKey, (void **)&static MLProgress.accuracyKey);
}

uint64_t one-time initialization function for validationLossKey()
{
  uint64_t v0 = OUTLINED_FUNCTION_17_15();
  uint64_t result = MEMORY[0x22A674AE0](v0, v1 | 0xEF73736F6C5F0000);
  static MLProgress.validationLossKey = result;
  return result;
}

id static MLProgress.validationLossKey.getter()
{
  return static MLProgress.elapsedTimeKey.getter(&one-time initialization token for validationLossKey, (void **)&static MLProgress.validationLossKey);
}

uint64_t one-time initialization function for validationAccuracyKey()
{
  uint64_t result = MEMORY[0x22A674AE0](0xD000000000000013, 0x80000002272D77D0);
  static MLProgress.validationAccuracyKey = result;
  return result;
}

id static MLProgress.validationAccuracyKey.getter()
{
  return static MLProgress.elapsedTimeKey.getter(&one-time initialization token for validationAccuracyKey, (void **)&static MLProgress.validationAccuracyKey);
}

uint64_t one-time initialization function for stylizedImageKey()
{
  uint64_t result = MEMORY[0x22A674AE0](0x64657A696C797473, 0xEE006567616D695FLL);
  static MLProgress.stylizedImageKey = result;
  return result;
}

id static MLProgress.stylizedImageKey.getter()
{
  return static MLProgress.elapsedTimeKey.getter(&one-time initialization token for stylizedImageKey, (void **)&static MLProgress.stylizedImageKey);
}

uint64_t one-time initialization function for rootMeanSquaredErrorKey()
{
  uint64_t result = MEMORY[0x22A674AE0](1702063474, 0xE400000000000000);
  static MLProgress.rootMeanSquaredErrorKey = result;
  return result;
}

id static MLProgress.rootMeanSquaredErrorKey.getter()
{
  return static MLProgress.elapsedTimeKey.getter(&one-time initialization token for rootMeanSquaredErrorKey, (void **)&static MLProgress.rootMeanSquaredErrorKey);
}

uint64_t one-time initialization function for maximumErrorKey()
{
  uint64_t result = MEMORY[0x22A674AE0](0x726F727265, 0xE500000000000000);
  static MLProgress.maximumErrorKey = result;
  return result;
}

id static MLProgress.maximumErrorKey.getter()
{
  return static MLProgress.elapsedTimeKey.getter(&one-time initialization token for maximumErrorKey, (void **)&static MLProgress.maximumErrorKey);
}

uint64_t one-time initialization function for validationRootMeanSquaredErrorKey()
{
  uint64_t v0 = OUTLINED_FUNCTION_17_15();
  uint64_t result = MEMORY[0x22A674AE0](v0, v1 | 0xEF65736D725F0000);
  static MLProgress.validationRootMeanSquaredErrorKey = result;
  return result;
}

id static MLProgress.validationRootMeanSquaredErrorKey.getter()
{
  return static MLProgress.elapsedTimeKey.getter(&one-time initialization token for validationRootMeanSquaredErrorKey, (void **)&static MLProgress.validationRootMeanSquaredErrorKey);
}

void one-time initialization function for validationMaximumErrorKey()
{
  OUTLINED_FUNCTION_27_12();
  static MLProgress.validationMaximumErrorKey = v0;
}

id static MLProgress.validationMaximumErrorKey.getter()
{
  return static MLProgress.elapsedTimeKey.getter(&one-time initialization token for validationMaximumErrorKey, (void **)&static MLProgress.validationMaximumErrorKey);
}

id static MLProgress.elapsedTimeKey.getter(void *a1, void **a2)
{
  if (*a1 != -1) {
    swift_once();
  }
  unint64_t v3 = *a2;

  return v3;
}

double specialized Dictionary._Variant.removeValue(forKey:)@<D0>(uint64_t a1@<X0>, uint64_t a2@<X1>, _OWORD *a3@<X8>)
{
  uint64_t v4 = v3;
  swift_bridgeObjectRetain();
  unint64_t v8 = specialized __RawDictionaryStorage.find<A>(_:)(a1, a2);
  LOBYTE(a2) = v9;
  swift_bridgeObjectRelease();
  if (a2)
  {
    char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native();
    uint64_t v14 = *v4;
    uint64_t v11 = *v4;
    *uint64_t v4 = 0x8000000000000000;
    Swift::Int v12 = *(void *)(v11 + 24);
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, Any>);
    _NativeDictionary.ensureUnique(isUnique:capacity:)(isUniquelyReferenced_nonNull_native, v12);
    swift_bridgeObjectRelease();
    outlined init with take of Any((_OWORD *)(*(void *)(v14 + 56) + 32 * v8), a3);
    _NativeDictionary._delete(at:)();
    *uint64_t v4 = v14;
    swift_bridgeObjectRelease();
  }
  else
  {
    double result = 0.0;
    *a3 = 0u;
    a3[1] = 0u;
  }
  return result;
}

double specialized Dictionary._Variant.removeValue(forKey:)@<D0>(_OWORD *a1@<X8>)
{
  uint64_t v2 = v1;
  swift_bridgeObjectRetain();
  unint64_t v4 = specialized __RawDictionaryStorage.find<A>(_:)();
  char v6 = v5;
  swift_bridgeObjectRelease();
  if (v6)
  {
    char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native();
    uint64_t v13 = *v2;
    uint64_t v8 = *v2;
    *uint64_t v2 = 0x8000000000000000;
    Swift::Int v9 = *(void *)(v8 + 24);
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<CodingUserInfoKey, Any>);
    _NativeDictionary.ensureUnique(isUnique:capacity:)(isUniquelyReferenced_nonNull_native, v9);
    uint64_t v10 = *(void *)(v13 + 48);
    uint64_t v11 = type metadata accessor for CodingUserInfoKey();
    (*(void (**)(unint64_t, uint64_t))(*(void *)(v11 - 8) + 8))(v10 + *(void *)(*(void *)(v11 - 8) + 72) * v4, v11);
    outlined init with take of Any((_OWORD *)(*(void *)(v13 + 56) + 32 * v4), a1);
    _NativeDictionary._delete(at:)();
    *uint64_t v2 = v13;
    swift_bridgeObjectRelease();
  }
  else
  {
    double result = 0.0;
    *a1 = 0u;
    a1[1] = 0u;
  }
  return result;
}

uint64_t specialized Dictionary._Variant.removeValue(forKey:)@<X0>(uint64_t a1@<X0>, uint64_t a2@<X1>, uint64_t *a3@<X2>, uint64_t (*a4)(void)@<X3>, uint64_t a5@<X8>)
{
  uint64_t v8 = v5;
  swift_bridgeObjectRetain();
  unint64_t v12 = specialized __RawDictionaryStorage.find<A>(_:)(a1, a2);
  LOBYTE(a2) = v13;
  swift_bridgeObjectRelease();
  if (a2)
  {
    char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native();
    uint64_t v24 = *v8;
    uint64_t v15 = *v8;
    *uint64_t v8 = 0x8000000000000000;
    Swift::Int v16 = *(void *)(v15 + 24);
    __swift_instantiateConcreteTypeFromMangledName(a3);
    _NativeDictionary.ensureUnique(isUnique:capacity:)(isUniquelyReferenced_nonNull_native, v16);
    swift_bridgeObjectRelease();
    uint64_t v17 = *(void *)(v24 + 56);
    uint64_t v18 = a4(0);
    OUTLINED_FUNCTION_8();
    (*(void (**)(uint64_t, unint64_t, uint64_t))(v19 + 32))(a5, v17 + *(void *)(v19 + 72) * v12, v18);
    _NativeDictionary._delete(at:)();
    *uint64_t v8 = v24;
    swift_bridgeObjectRelease();
    uint64_t v20 = a5;
    uint64_t v21 = 0;
    uint64_t v22 = v18;
  }
  else
  {
    uint64_t v22 = a4(0);
    uint64_t v20 = a5;
    uint64_t v21 = 1;
  }

  return __swift_storeEnumTagSinglePayload(v20, v21, 1, v22);
}

double specialized Dictionary._Variant.removeValue(forKey:)@<D0>(char a1@<W0>, _OWORD *a2@<X8>)
{
  unint64_t v3 = v2;
  swift_bridgeObjectRetain();
  unint64_t v6 = specialized __RawDictionaryStorage.find<A>(_:)(a1);
  char v8 = v7;
  swift_bridgeObjectRelease();
  if (v8)
  {
    char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native();
    uint64_t v13 = *v3;
    uint64_t v10 = *v3;
    *unint64_t v3 = 0x8000000000000000;
    Swift::Int v11 = *(void *)(v10 + 24);
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<MLProgress.Metric, Any>);
    _NativeDictionary.ensureUnique(isUnique:capacity:)(isUniquelyReferenced_nonNull_native, v11);
    outlined init with take of Any((_OWORD *)(*(void *)(v13 + 56) + 32 * v6), a2);
    lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
    _NativeDictionary._delete(at:)();
    *unint64_t v3 = v13;
    swift_bridgeObjectRelease();
  }
  else
  {
    double result = 0.0;
    *a2 = 0u;
    a2[1] = 0u;
  }
  return result;
}

double specialized Dictionary._Variant.removeValue(forKey:)@<D0>(uint64_t a1@<X0>, _OWORD *a2@<X8>)
{
  unint64_t v3 = v2;
  swift_bridgeObjectRetain();
  unint64_t v6 = specialized __RawDictionaryStorage.find<A>(_:)(a1);
  LOBYTE(a1) = v7;
  swift_bridgeObjectRelease();
  if (a1)
  {
    char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native();
    uint64_t v12 = *v3;
    uint64_t v9 = *v3;
    *unint64_t v3 = 0x8000000000000000;
    Swift::Int v10 = *(void *)(v9 + 24);
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<AnyHashable, Any>);
    _NativeDictionary.ensureUnique(isUnique:capacity:)(isUniquelyReferenced_nonNull_native, v10);
    outlined destroy of AnyHashable(*(void *)(v12 + 48) + 40 * v6);
    outlined init with take of Any((_OWORD *)(*(void *)(v12 + 56) + 32 * v6), a2);
    _NativeDictionary._delete(at:)();
    *unint64_t v3 = v12;
    swift_bridgeObjectRelease();
  }
  else
  {
    double result = 0.0;
    *a2 = 0u;
    a2[1] = 0u;
  }
  return result;
}

uint64_t specialized Dictionary._Variant.setValue(_:forKey:)()
{
  OUTLINED_FUNCTION_28_9();
  OUTLINED_FUNCTION_6_23();
  specialized _NativeDictionary.setValue(_:forKey:isUnique:)();
  *uint64_t v0 = v2;

  return swift_bridgeObjectRelease();
}

{
  uint64_t *v0;
  uint64_t v2;
  uint64_t vars8;

  swift_isUniquelyReferenced_nonNull_native();
  uint64_t v2 = *v0;
  *uint64_t v0 = 0x8000000000000000;
  specialized _NativeDictionary.setValue(_:forKey:isUnique:)();
  *uint64_t v0 = v2;

  return swift_bridgeObjectRelease();
}

{
  uint64_t *v0;
  uint64_t v2;
  uint64_t vars8;

  swift_isUniquelyReferenced_nonNull_native();
  uint64_t v2 = *v0;
  *uint64_t v0 = 0x8000000000000000;
  specialized _NativeDictionary.setValue(_:forKey:isUnique:)();
  *uint64_t v0 = v2;

  return swift_bridgeObjectRelease();
}

uint64_t specialized Dictionary._Variant.setValue(_:forKey:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  swift_isUniquelyReferenced_nonNull_native();
  uint64_t v8 = *v3;
  *unint64_t v3 = 0x8000000000000000;
  specialized _NativeDictionary.setValue(_:forKey:isUnique:)(a1, a2, a3);
  *unint64_t v3 = v8;

  return swift_bridgeObjectRelease();
}

uint64_t specialized Dictionary._Variant.setValue(_:forKey:)(uint64_t a1, uint64_t a2, uint64_t a3, void (*a4)(uint64_t))
{
  OUTLINED_FUNCTION_28_9();
  uint64_t v6 = OUTLINED_FUNCTION_6_23();
  a4(v6);
  *unint64_t v4 = v8;

  return swift_bridgeObjectRelease();
}

uint64_t specialized Dictionary._Variant.setValue(_:forKey:)(uint64_t a1, char a2)
{
  swift_isUniquelyReferenced_nonNull_native();
  uint64_t v6 = *v2;
  *uint64_t v2 = 0x8000000000000000;
  specialized _NativeDictionary.setValue(_:forKey:isUnique:)(a1, a2);
  *uint64_t v2 = v6;

  return swift_bridgeObjectRelease();
}

uint64_t specialized Dictionary._Variant.setValue(_:forKey:)(_OWORD *a1, uint64_t a2)
{
  swift_isUniquelyReferenced_nonNull_native();
  uint64_t v6 = *v2;
  *uint64_t v2 = 0x8000000000000000;
  specialized _NativeDictionary.setValue(_:forKey:isUnique:)(a1, a2);
  *uint64_t v2 = v6;

  return swift_bridgeObjectRelease();
}

unint64_t lazy protocol witness table accessor for type MLProgress.CodingKeys and conformance MLProgress.CodingKeys()
{
  unint64_t result = lazy protocol witness table cache variable for type MLProgress.CodingKeys and conformance MLProgress.CodingKeys;
  if (!lazy protocol witness table cache variable for type MLProgress.CodingKeys and conformance MLProgress.CodingKeys)
  {
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type MLProgress.CodingKeys and conformance MLProgress.CodingKeys);
  }
  return result;
}

{
  unint64_t result;

  unint64_t result = lazy protocol witness table cache variable for type MLProgress.CodingKeys and conformance MLProgress.CodingKeys;
  if (!lazy protocol witness table cache variable for type MLProgress.CodingKeys and conformance MLProgress.CodingKeys)
  {
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type MLProgress.CodingKeys and conformance MLProgress.CodingKeys);
  }
  return result;
}

{
  unint64_t result;

  unint64_t result = lazy protocol witness table cache variable for type MLProgress.CodingKeys and conformance MLProgress.CodingKeys;
  if (!lazy protocol witness table cache variable for type MLProgress.CodingKeys and conformance MLProgress.CodingKeys)
  {
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type MLProgress.CodingKeys and conformance MLProgress.CodingKeys);
  }
  return result;
}

{
  unint64_t result;

  unint64_t result = lazy protocol witness table cache variable for type MLProgress.CodingKeys and conformance MLProgress.CodingKeys;
  if (!lazy protocol witness table cache variable for type MLProgress.CodingKeys and conformance MLProgress.CodingKeys)
  {
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type MLProgress.CodingKeys and conformance MLProgress.CodingKeys);
  }
  return result;
}

unint64_t lazy protocol witness table accessor for type [MLProgress.Metric] and conformance [A]()
{
  unint64_t result = lazy protocol witness table cache variable for type [MLProgress.Metric] and conformance [A];
  if (!lazy protocol witness table cache variable for type [MLProgress.Metric] and conformance [A])
  {
    __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for [MLProgress.Metric]);
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type [MLProgress.Metric] and conformance [A]);
  }
  return result;
}

uint64_t destroy for MLProgress()
{
  return swift_bridgeObjectRelease();
}

uint64_t initializeWithCopy for MLProgress(uint64_t a1, uint64_t a2)
{
  *(void *)a1 = *(void *)a2;
  *(unsigned char *)(a1 + 8) = *(unsigned char *)(a2 + 8);
  uint64_t v3 = *(void *)(a2 + 24);
  *(void *)(a1 + 16) = *(void *)(a2 + 16);
  *(void *)(a1 + 24) = v3;
  *(unsigned char *)(a1 + 32) = *(unsigned char *)(a2 + 32);
  *(void *)(a1 + 40) = *(void *)(a2 + 40);
  swift_bridgeObjectRetain();
  return a1;
}

uint64_t assignWithCopy for MLProgress(uint64_t a1, uint64_t a2)
{
  *(void *)a1 = *(void *)a2;
  *(unsigned char *)(a1 + 8) = *(unsigned char *)(a2 + 8);
  *(void *)(a1 + 16) = *(void *)(a2 + 16);
  uint64_t v3 = *(void *)(a2 + 24);
  *(unsigned char *)(a1 + 32) = *(unsigned char *)(a2 + 32);
  *(void *)(a1 + 24) = v3;
  *(void *)(a1 + 40) = *(void *)(a2 + 40);
  swift_bridgeObjectRetain();
  swift_bridgeObjectRelease();
  return a1;
}

__n128 __swift_memcpy48_8(uint64_t a1, uint64_t a2)
{
  __n128 result = *(__n128 *)a2;
  long long v3 = *(_OWORD *)(a2 + 32);
  *(_OWORD *)(a1 + 16) = *(_OWORD *)(a2 + 16);
  *(_OWORD *)(a1 + 32) = v3;
  *(__n128 *)a1 = result;
  return result;
}

uint64_t assignWithTake for MLProgress(uint64_t a1, uint64_t a2)
{
  *(void *)a1 = *(void *)a2;
  *(unsigned char *)(a1 + 8) = *(unsigned char *)(a2 + 8);
  uint64_t v3 = *(void *)(a2 + 24);
  *(void *)(a1 + 16) = *(void *)(a2 + 16);
  *(void *)(a1 + 24) = v3;
  *(unsigned char *)(a1 + 32) = *(unsigned char *)(a2 + 32);
  *(void *)(a1 + 40) = *(void *)(a2 + 40);
  swift_bridgeObjectRelease();
  return a1;
}

uint64_t getEnumTagSinglePayload for MLProgress(uint64_t a1, int a2)
{
  if (a2)
  {
    if (a2 < 0 && *(unsigned char *)(a1 + 48))
    {
      LODWORD(v2) = *(_DWORD *)a1 + 0x7FFFFFFF;
    }
    else
    {
      unint64_t v2 = *(void *)(a1 + 40);
      if (v2 >= 0xFFFFFFFF) {
        LODWORD(v2) = -1;
      }
    }
  }
  else
  {
    LODWORD(v2) = -1;
  }
  return (v2 + 1);
}

uint64_t storeEnumTagSinglePayload for MLProgress(uint64_t result, int a2, int a3)
{
  if (a2 < 0)
  {
    *(void *)(result + 40) = 0;
    *(_OWORD *)(result + 24) = 0u;
    *(_OWORD *)(result + 8) = 0u;
    *(void *)__n128 result = a2 ^ 0x80000000;
    if (a3 < 0) {
      *(unsigned char *)(result + 48) = 1;
    }
  }
  else
  {
    if ((a3 & 0x80000000) == 0)
    {
      if (!a2) {
        return result;
      }
LABEL_8:
      *(void *)(result + 40) = (a2 - 1);
      return result;
    }
    *(unsigned char *)(result + 48) = 0;
    if (a2) {
      goto LABEL_8;
    }
  }
  return result;
}

void type metadata accessor for MLProgress()
{
}

uint64_t getEnumTagSinglePayload for MLProgress.Metric(unsigned __int8 *a1, unsigned int a2)
{
  if (!a2)
  {
    int v5 = -1;
    return (v5 + 1);
  }
  if (a2 >= 0xF6)
  {
    if (a2 + 10 >= 0xFFFF00) {
      int v2 = 4;
    }
    else {
      int v2 = 2;
    }
    if ((a2 + 10) >> 8 < 0xFF) {
      int v3 = 1;
    }
    else {
      int v3 = v2;
    }
    if (v3 == 4)
    {
      int v4 = *(_DWORD *)(a1 + 1);
      if (!v4) {
        goto LABEL_17;
      }
    }
    else if (v3 == 2)
    {
      int v4 = *(unsigned __int16 *)(a1 + 1);
      if (!*(_WORD *)(a1 + 1)) {
        goto LABEL_17;
      }
    }
    else
    {
      int v4 = a1[1];
      if (!a1[1]) {
        goto LABEL_17;
      }
    }
    int v5 = (*a1 | (v4 << 8)) - 11;
    return (v5 + 1);
  }
LABEL_17:
  unsigned int v6 = *a1;
  BOOL v7 = v6 >= 0xB;
  int v5 = v6 - 11;
  if (!v7) {
    int v5 = -1;
  }
  return (v5 + 1);
}

unsigned char *storeEnumTagSinglePayload for MLProgress.Metric(unsigned char *result, unsigned int a2, unsigned int a3)
{
  if (a3 + 10 >= 0xFFFF00) {
    int v3 = 4;
  }
  else {
    int v3 = 2;
  }
  if ((a3 + 10) >> 8 < 0xFF) {
    unsigned int v4 = 1;
  }
  else {
    unsigned int v4 = v3;
  }
  if (a3 >= 0xF6) {
    uint64_t v5 = v4;
  }
  else {
    uint64_t v5 = 0;
  }
  if (a2 > 0xF5)
  {
    unsigned int v6 = ((a2 - 246) >> 8) + 1;
    *__n128 result = a2 + 10;
    switch(v5)
    {
      case 1:
        result[1] = v6;
        break;
      case 2:
        *(_WORD *)(result + 1) = v6;
        break;
      case 3:
LABEL_23:
        __break(1u);
        JUMPOUT(0x22714328CLL);
      case 4:
        *(_DWORD *)(result + 1) = v6;
        break;
      default:
        return result;
    }
  }
  else
  {
    switch(v5)
    {
      case 1:
        result[1] = 0;
        if (!a2) {
          return result;
        }
        goto LABEL_18;
      case 2:
        *(_WORD *)(result + 1) = 0;
        goto LABEL_17;
      case 3:
        goto LABEL_23;
      case 4:
        *(_DWORD *)(result + 1) = 0;
        if (!a2) {
          return result;
        }
        goto LABEL_18;
      default:
LABEL_17:
        if (a2) {
LABEL_18:
        }
          *__n128 result = a2 + 10;
        break;
    }
  }
  return result;
}

void type metadata accessor for MLProgress.Metric()
{
}

uint64_t getEnumTagSinglePayload for MLProgress.CodingKeys(unsigned __int8 *a1, unsigned int a2)
{
  if (!a2)
  {
    int v5 = -1;
    return (v5 + 1);
  }
  if (a2 >= 0xFD)
  {
    if (a2 + 3 >= 0xFFFF00) {
      int v2 = 4;
    }
    else {
      int v2 = 2;
    }
    if ((a2 + 3) >> 8 < 0xFF) {
      int v3 = 1;
    }
    else {
      int v3 = v2;
    }
    if (v3 == 4)
    {
      int v4 = *(_DWORD *)(a1 + 1);
      if (!v4) {
        goto LABEL_17;
      }
    }
    else if (v3 == 2)
    {
      int v4 = *(unsigned __int16 *)(a1 + 1);
      if (!*(_WORD *)(a1 + 1)) {
        goto LABEL_17;
      }
    }
    else
    {
      int v4 = a1[1];
      if (!a1[1]) {
        goto LABEL_17;
      }
    }
    int v5 = (*a1 | (v4 << 8)) - 4;
    return (v5 + 1);
  }
LABEL_17:
  unsigned int v6 = *a1;
  BOOL v7 = v6 >= 4;
  int v5 = v6 - 4;
  if (!v7) {
    int v5 = -1;
  }
  return (v5 + 1);
}

unsigned char *storeEnumTagSinglePayload for MLProgress.CodingKeys(unsigned char *result, unsigned int a2, unsigned int a3)
{
  if (a3 + 3 >= 0xFFFF00) {
    int v3 = 4;
  }
  else {
    int v3 = 2;
  }
  if ((a3 + 3) >> 8 < 0xFF) {
    unsigned int v4 = 1;
  }
  else {
    unsigned int v4 = v3;
  }
  if (a3 >= 0xFD) {
    uint64_t v5 = v4;
  }
  else {
    uint64_t v5 = 0;
  }
  if (a2 > 0xFC)
  {
    unsigned int v6 = ((a2 - 253) >> 8) + 1;
    *__n128 result = a2 + 3;
    switch(v5)
    {
      case 1:
        result[1] = v6;
        break;
      case 2:
        *(_WORD *)(result + 1) = v6;
        break;
      case 3:
LABEL_23:
        __break(1u);
        JUMPOUT(0x227143414);
      case 4:
        *(_DWORD *)(result + 1) = v6;
        break;
      default:
        return result;
    }
  }
  else
  {
    switch(v5)
    {
      case 1:
        result[1] = 0;
        if (!a2) {
          return result;
        }
        goto LABEL_18;
      case 2:
        *(_WORD *)(result + 1) = 0;
        goto LABEL_17;
      case 3:
        goto LABEL_23;
      case 4:
        *(_DWORD *)(result + 1) = 0;
        if (!a2) {
          return result;
        }
        goto LABEL_18;
      default:
LABEL_17:
        if (a2) {
LABEL_18:
        }
          *__n128 result = a2 + 3;
        break;
    }
  }
  return result;
}

void type metadata accessor for MLProgress.CodingKeys()
{
}

uint64_t outlined init with take of (key: MetricsKey, value: Double)(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (key: MetricsKey, value: Double));
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 32))(a2, a1, v4);
  return a2;
}

uint64_t lazy protocol witness table accessor for type NSProgressUserInfoKey and conformance NSProgressUserInfoKey(unint64_t *a1, void (*a2)(uint64_t))
{
  uint64_t result = *a1;
  if (!result)
  {
    a2(255);
    uint64_t result = swift_getWitnessTable();
    atomic_store(result, a1);
  }
  return result;
}

uint64_t OUTLINED_FUNCTION_1_29()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_2_37()
{
  return 0;
}

uint64_t OUTLINED_FUNCTION_4_32()
{
  return __swift_getEnumTagSinglePayload(v0, 1, v1);
}

uint64_t OUTLINED_FUNCTION_5_25()
{
  return swift_dynamicCast();
}

uint64_t OUTLINED_FUNCTION_6_23()
{
  *uint64_t v0 = 0x8000000000000000;
  return v1;
}

double OUTLINED_FUNCTION_7_23(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,long long a23)
{
  return specialized Dictionary.subscript.getter(a1, v23, &a23);
}

uint64_t OUTLINED_FUNCTION_8_22()
{
  return static Dictionary._unconditionallyBridgeFromObjectiveC(_:)();
}

uint64_t OUTLINED_FUNCTION_10_19(uint64_t a1, uint64_t a2, uint64_t a3, void (*a4)(uint64_t))
{
  return specialized Dictionary._Variant.setValue(_:forKey:)(v6, v5, v4, a4);
}

uint64_t OUTLINED_FUNCTION_11_20(uint64_t a1, uint64_t a2, uint64_t *a3, uint64_t (*a4)(void))
{
  return specialized Dictionary._Variant.removeValue(forKey:)(v5, v4, a3, a4, v6);
}

uint64_t OUTLINED_FUNCTION_17_15()
{
  return 0x69746164696C6176;
}

id OUTLINED_FUNCTION_19_15()
{
  return [v0 (SEL)(v1 + 1816)];
}

uint64_t OUTLINED_FUNCTION_21_16()
{
  return 0x6573616870;
}

uint64_t OUTLINED_FUNCTION_22_14()
{
  return _s10Foundation3URLVSgWOhTm_0(v0, v1);
}

uint64_t OUTLINED_FUNCTION_25_17()
{
  return _s10Foundation3URLVSgWOhTm_0(v0, v1);
}

uint64_t OUTLINED_FUNCTION_26_12()
{
  return v0;
}

void OUTLINED_FUNCTION_27_12()
{
  JUMPOUT(0x22A674AE0);
}

uint64_t OUTLINED_FUNCTION_28_9()
{
  return swift_isUniquelyReferenced_nonNull_native();
}

uint64_t static MLHandPoseClassifier.__Defaults.batchSize.getter()
{
  return 32;
}

uint64_t static MLHandPoseClassifier.__Defaults.maximumIterations.getter()
{
  return 80;
}

uint64_t static MLHandPoseClassifier.__Defaults.sessionIdColumnName.getter()
{
  return 0x5F6E6F6973736573;
}

uint64_t static MLHandPoseClassifier.__Defaults.featureColumnName.getter()
{
  return 0x746E696F7079656BLL;
}

uint64_t static MLHandPoseClassifier.__Defaults.labelColumnName.getter()
{
  return 0x6C6562616CLL;
}

uint64_t static MLHandPoseClassifier.__Defaults.imageColumnName.getter()
{
  return 0x7461506567616D69;
}

ValueMetadata *type metadata accessor for MLHandPoseClassifier.__Defaults()
{
  return &type metadata for MLHandPoseClassifier.__Defaults;
}

uint64_t MLFewShotSoundClassifier.TemporalClassifier.makeConvBlock(name:input:output:layer:)(void (*a1)(char *, char *, uint64_t), void (*a2)(void, void, void), void (*a3)(void, void, void), uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  uint64_t v71 = a3;
  uint64_t v72 = a7;
  uint64_t v66 = a5;
  uint64_t v67 = a6;
  uint64_t v10 = type metadata accessor for NeuralNetwork.Border();
  MEMORY[0x270FA5388](v10 - 8);
  uint64_t v69 = (char *)&v59 - ((v11 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v12 = type metadata accessor for NeuralNetwork.Layer.PadParameters.Kind();
  MEMORY[0x270FA5388](v12 - 8);
  uint64_t v68 = (char *)&v59 - ((v13 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v65 = type metadata accessor for MLFewShotSoundClassifier.CausalConv1D(0);
  MEMORY[0x270FA5388](v65);
  uint64_t v15 = (char *)&v59 - ((v14 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v70 = type metadata accessor for NeuralNetwork.Layer.Kind();
  uint64_t v16 = *(void *)(v70 - 8);
  MEMORY[0x270FA5388](v70);
  uint64_t v18 = (char *)&v59 - ((v17 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v19 = type metadata accessor for NeuralNetwork.Layer();
  uint64_t v74 = *(void *)(v19 - 8);
  uint64_t v75 = v19;
  uint64_t v20 = MEMORY[0x270FA5388](v19);
  char v64 = (char *)&v59 - ((v21 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v22 = MEMORY[0x270FA5388](v20);
  unint64_t v63 = (char *)&v59 - v23;
  MEMORY[0x270FA5388](v22);
  char v25 = (char *)&v59 - v24;
  uint64_t v76 = a1;
  uint64_t v77 = a2;
  swift_bridgeObjectRetain();
  v26._uint64_t countAndFlagsBits = 1684107359;
  v26._uint64_t object = (void *)0xE400000000000000;
  String.append(_:)(v26);
  uint64_t v59 = (void (*)(char *, char *, uint64_t))v77;
  uint64_t v60 = v76;
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<String>);
  uint64_t v27 = swift_allocObject();
  long long v73 = xmmword_2272CB370;
  *(_OWORD *)(v27 + 16) = xmmword_2272CB370;
  *(void *)(v27 + 32) = v71;
  *(void *)(v27 + 40) = a4;
  uint64_t v28 = swift_allocObject();
  *(_OWORD *)(v28 + 16) = v73;
  uint64_t v71 = (void (*)(void, void, void))a1;
  uint64_t v76 = a1;
  uint64_t v77 = a2;
  swift_bridgeObjectRetain();
  swift_bridgeObjectRetain();
  v29._uint64_t countAndFlagsBits = 0x74756F5F6461705FLL;
  v29._uint64_t object = (void *)0xE800000000000000;
  String.append(_:)(v29);
  uint64_t v30 = v77;
  *(void *)(v28 + 32) = v76;
  *(void *)(v28 + 40) = v30;
  outlined init with copy of MLFewShotSoundClassifier.TemporalClassifier(v72, (uint64_t)v15, type metadata accessor for MLFewShotSoundClassifier.CausalConv1D);
  static NeuralNetwork.Layer.PadParameters.Kind.constant(value:)();
  NeuralNetwork.Border.init(leadingHeight:trailingHeight:leadingWidth:trailingWidth:)();
  NeuralNetwork.Layer.PadParameters.init(kind:amount:)();
  BOOL v61 = v15;
  outlined destroy of MLFewShotSoundClassifier.TemporalClassifier((uint64_t)v15, (void (*)(void))type metadata accessor for MLFewShotSoundClassifier.CausalConv1D);
  uint64_t v31 = *MEMORY[0x263F53250];
  uint64_t v32 = *(void (**)(char *, uint64_t, uint64_t))(v16 + 104);
  uint64_t v62 = v16 + 104;
  v32(v18, v31, v70);
  uint64_t v33 = v32;
  NeuralNetwork.Layer.init(name:inputNames:outputNames:kind:)();
  specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
  uint64_t v35 = v34;
  unint64_t v36 = *(void *)(v34 + 16);
  if (v36 >= *(void *)(v34 + 24) >> 1)
  {
    specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
    uint64_t v35 = v56;
  }
  *(void *)(v35 + 16) = v36 + 1;
  id v37 = *(void (**)(char *, char *, uint64_t))(v74 + 32);
  uint64_t v69 = (char *)((*(unsigned __int8 *)(v74 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v74 + 80));
  uint64_t v68 = *(char **)(v74 + 72);
  v74 += 32;
  uint64_t v60 = v37;
  v37(&v69[v35 + (void)v68 * v36], v25, v75);
  uint64_t v38 = (void (*)(char *, char *, uint64_t))v71;
  uint64_t v76 = (void (*)(char *, char *, uint64_t))v71;
  uint64_t v77 = a2;
  swift_bridgeObjectRetain();
  v39._uint64_t countAndFlagsBits = 0x6431766E6F635FLL;
  v39._uint64_t object = (void *)0xE700000000000000;
  String.append(_:)(v39);
  uint64_t v59 = v76;
  uint64_t v40 = swift_allocObject();
  *(_OWORD *)(v40 + 16) = v73;
  uint64_t v76 = v38;
  uint64_t v77 = a2;
  swift_bridgeObjectRetain();
  v41._uint64_t countAndFlagsBits = 0x74756F5F6461705FLL;
  v41._uint64_t object = (void *)0xE800000000000000;
  String.append(_:)(v41);
  uint64_t v42 = v77;
  *(void *)(v40 + 32) = v76;
  *(void *)(v40 + 40) = v42;
  uint64_t v43 = swift_allocObject();
  *(_OWORD *)(v43 + 16) = v73;
  uint64_t v76 = v38;
  uint64_t v77 = a2;
  swift_bridgeObjectRetain();
  v44._uint64_t countAndFlagsBits = 0x756F5F766E6F635FLL;
  v44._uint64_t object = (void *)0xE900000000000074;
  String.append(_:)(v44);
  int v45 = v77;
  *(void *)(v43 + 32) = v76;
  *(void *)(v43 + 40) = v45;
  uint64_t v46 = (uint64_t)v61;
  outlined init with copy of MLFewShotSoundClassifier.TemporalClassifier(v72, (uint64_t)v61, type metadata accessor for MLFewShotSoundClassifier.CausalConv1D);
  NeuralNetwork.Layer.ConvolutionParameters.init(from:)(v46);
  v33(v18, *MEMORY[0x263F53238], v70);
  unsigned int v47 = v63;
  NeuralNetwork.Layer.init(name:inputNames:outputNames:kind:)();
  unint64_t v48 = *(void *)(v35 + 16);
  if (v48 >= *(void *)(v35 + 24) >> 1)
  {
    specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
    uint64_t v35 = v57;
  }
  *(void *)(v35 + 16) = v48 + 1;
  uint64_t v49 = v60;
  v60(&v69[v35 + v48 * (void)v68], v47, v75);
  unsigned int v50 = (void (*)(char *, char *, uint64_t))v71;
  uint64_t v76 = (void (*)(char *, char *, uint64_t))v71;
  uint64_t v77 = a2;
  swift_bridgeObjectRetain();
  v51._uint64_t countAndFlagsBits = 0x746176697463615FLL;
  v51._uint64_t object = (void *)0xEB000000006E6F69;
  String.append(_:)(v51);
  uint64_t v76 = v50;
  uint64_t v77 = a2;
  swift_bridgeObjectRetain();
  v52._uint64_t countAndFlagsBits = 0x756F5F766E6F635FLL;
  v52._uint64_t object = (void *)0xE900000000000074;
  String.append(_:)(v52);
  uint64_t v53 = v64;
  static NeuralNetwork.Layer.leakyRelu(name:inputName:outputName:negativeSlope:)();
  swift_bridgeObjectRelease();
  swift_bridgeObjectRelease();
  unint64_t v54 = *(void *)(v35 + 16);
  if (v54 >= *(void *)(v35 + 24) >> 1)
  {
    specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
    uint64_t v35 = v58;
  }
  *(void *)(v35 + 16) = v54 + 1;
  v49(&v69[v35 + v54 * (void)v68], v53, v75);
  return v35;
}

char *MLFewShotSoundClassifier.TemporalClassifier.largeMarginClassifierLayers(framewiseEmbeddingShape:)(uint64_t a1)
{
  uint64_t v3 = type metadata accessor for Dense();
  uint64_t v102 = *(void *)(v3 - 8);
  MEMORY[0x270FA5388](v3);
  uint64_t v110 = (char *)v94 - ((v4 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v5 = type metadata accessor for NeuralNetwork.Layer.SliceParameters.Axis();
  uint64_t v99 = *(void *)(v5 - 8);
  uint64_t v100 = v5;
  MEMORY[0x270FA5388](v5);
  long long v98 = (char *)v94 - ((v6 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v104 = type metadata accessor for MLFewShotSoundClassifier.LeakyConv2D(0);
  MEMORY[0x270FA5388](v104);
  uint64_t v8 = (char *)v94 - ((v7 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v9 = type metadata accessor for NeuralNetwork.Layer.Kind();
  uint64_t v10 = *(void *)(v9 - 8);
  uint64_t v114 = v9;
  uint64_t v115 = v10;
  MEMORY[0x270FA5388](v9);
  uint64_t v113 = (uint64_t)v94 - ((v11 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v12 = type metadata accessor for NeuralNetwork.Layer();
  unint64_t v13 = *(void *)(v12 - 8);
  uint64_t v14 = MEMORY[0x270FA5388](v12);
  unsigned __int8 v103 = (char *)v94 - ((v15 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v16 = MEMORY[0x270FA5388](v14);
  long long v101 = (char *)v94 - v17;
  uint64_t v18 = MEMORY[0x270FA5388](v16);
  uint64_t v109 = (char *)v94 - v19;
  uint64_t v20 = MEMORY[0x270FA5388](v18);
  uint64_t v108 = (char *)v94 - v21;
  uint64_t v22 = MEMORY[0x270FA5388](v20);
  uint64_t v107 = (char *)v94 - v23;
  uint64_t v24 = MEMORY[0x270FA5388](v22);
  uint64_t v105 = (char *)v94 - v25;
  uint64_t v26 = MEMORY[0x270FA5388](v24);
  char v111 = (char *)v94 - v27;
  uint64_t v28 = MEMORY[0x270FA5388](v26);
  uint64_t v30 = (char *)v94 - v29;
  uint64_t v31 = MEMORY[0x270FA5388](v28);
  uint64_t v33 = (char *)v94 - v32;
  MEMORY[0x270FA5388](v31);
  uint64_t v35 = (char *)v94 - v34;
  uint64_t v36 = specialized BidirectionalCollection.last.getter(a1);
  if (v37)
  {
    lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError();
    *(void *)uint64_t v81 = 0xD00000000000002CLL;
    *(void *)(v81 + 8) = 0x80000002272D78D0;
    *(_OWORD *)(v81 + 16) = 0u;
    *(_OWORD *)(v81 + 32) = 0u;
    *(unsigned char *)(v81 + 48) = 2;
    swift_willThrow();
    return v30;
  }
  uint64_t v95 = v36;
  uint64_t v97 = v3;
  unint64_t v116 = v13;
  uint64_t v117 = v12;
  v94[1] = v1;
  static NeuralNetwork.Layer.expandDimensions(name:inputName:outputName:axes:)();
  specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
  Swift::String v39 = v38;
  unint64_t v40 = *((void *)v38 + 2);
  if (v40 >= *((void *)v38 + 3) >> 1)
  {
    specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
    Swift::String v39 = v83;
  }
  *((void *)v39 + 2) = v40 + 1;
  unint64_t v42 = v116 + 32;
  Swift::String v41 = *(void (**)(char *, char *, uint64_t))(v116 + 32);
  unint64_t v116 = (*(unsigned __int8 *)(v116 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v116 + 80);
  uint64_t v112 = *(void *)(v42 + 40);
  unint64_t v43 = (unint64_t)&v39[v116 + v112 * v40];
  Swift::String v44 = v41;
  v41((char *)v43, v35, v117);
  static NeuralNetwork.Layer.transpose(name:inputName:outputName:axes:)();
  unint64_t v45 = *((void *)v39 + 2);
  if (v45 >= *((void *)v39 + 3) >> 1)
  {
    specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
    Swift::String v39 = v84;
  }
  *((void *)v39 + 2) = v45 + 1;
  v44(&v39[v116 + v45 * v112], v33, v117);
  uint64_t v46 = v106;
  outlined init with copy of MLFewShotSoundClassifier.TemporalClassifier(v106, (uint64_t)v8, type metadata accessor for MLFewShotSoundClassifier.LeakyConv2D);
  uint64_t v47 = v113;
  NeuralNetwork.Layer.ConvolutionParameters.init(from:)((uint64_t)v8);
  uint64_t v48 = *MEMORY[0x263F53238];
  uint64_t v49 = *(void (**)(uint64_t, uint64_t, uint64_t))(v115 + 104);
  v115 += 104;
  uint64_t v96 = v49;
  v49(v47, v48, v114);
  NeuralNetwork.Layer.init(name:inputNames:outputNames:kind:)();
  unint64_t v50 = *((void *)v39 + 2);
  if (v50 >= *((void *)v39 + 3) >> 1)
  {
    specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
    Swift::String v39 = v85;
  }
  *((void *)v39 + 2) = v50 + 1;
  uint64_t v51 = v112;
  v44(&v39[v116 + v50 * v112], v30, v117);
  static NeuralNetwork.Layer.leakyRelu(name:inputName:outputName:negativeSlope:)();
  unint64_t v52 = *((void *)v39 + 2);
  if (v52 >= *((void *)v39 + 3) >> 1)
  {
    specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
    Swift::String v39 = v86;
  }
  uint64_t v53 = v105;
  *((void *)v39 + 2) = v52 + 1;
  v44(&v39[v116 + v52 * v51], v111, v117);
  static NeuralNetwork.Layer.transpose(name:inputName:outputName:axes:)();
  unint64_t v54 = *((void *)v39 + 2);
  if (v54 >= *((void *)v39 + 3) >> 1)
  {
    specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
    Swift::String v39 = v87;
  }
  *((void *)v39 + 2) = v54 + 1;
  v44(&v39[v116 + v54 * v51], v53, v117);
  uint64_t v118 = v39;
  unint64_t v55 = (int *)type metadata accessor for MLFewShotSoundClassifier.ConvolutionalNetwork(0);
  uint64_t v56 = MLFewShotSoundClassifier.TemporalClassifier.makeConvBlock(name:input:output:layer:)((void (*)(char *, char *, uint64_t))0x3163, (void (*)(void, void, void))0xE200000000000000, (void (*)(void, void, void))0x6E69646465626D65, 0xE900000000000067, 12643, 0xE200000000000000, v46 + v55[5]);
  specialized Array.append<A>(contentsOf:)(v56);
  uint64_t v57 = MLFewShotSoundClassifier.TemporalClassifier.makeConvBlock(name:input:output:layer:)((void (*)(char *, char *, uint64_t))0x3263, (void (*)(void, void, void))0xE200000000000000, (void (*)(void, void, void))0x3163, 0xE200000000000000, 12899, 0xE200000000000000, v46 + v55[6]);
  specialized Array.append<A>(contentsOf:)(v57);
  uint64_t v58 = MLFewShotSoundClassifier.TemporalClassifier.makeConvBlock(name:input:output:layer:)((void (*)(char *, char *, uint64_t))0x3363, (void (*)(void, void, void))0xE200000000000000, (void (*)(void, void, void))0x3263, 0xE200000000000000, 13155, 0xE200000000000000, v46 + v55[7]);
  specialized Array.append<A>(contentsOf:)(v58);
  uint64_t v59 = MLFewShotSoundClassifier.TemporalClassifier.makeConvBlock(name:input:output:layer:)((void (*)(char *, char *, uint64_t))0x3463, (void (*)(void, void, void))0xE200000000000000, (void (*)(void, void, void))0x3363, 0xE200000000000000, 13411, 0xE200000000000000, v46 + v55[8]);
  specialized Array.append<A>(contentsOf:)(v59);
  if (__OFSUB__(v95, 1))
  {
    __break(1u);
    goto LABEL_28;
  }
  BOOL v61 = v98;
  uint64_t v60 = v99;
  uint64_t v62 = v100;
  (*(void (**)(char *, void, uint64_t))(v99 + 104))(v98, *MEMORY[0x263F53220], v100);
  static NeuralNetwork.Layer.slice(name:inputName:outputName:startIndex:endIndex:stride:axis:)();
  (*(void (**)(char *, uint64_t))(v60 + 8))(v61, v62);
  uint64_t v30 = v118;
  if ((swift_isUniquelyReferenced_nonNull_native() & 1) == 0)
  {
LABEL_28:
    specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
    uint64_t v30 = v88;
  }
  unint64_t v63 = *((void *)v30 + 2);
  if (v63 >= *((void *)v30 + 3) >> 1)
  {
    specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
    uint64_t v30 = v89;
  }
  *((void *)v30 + 2) = v63 + 1;
  char v64 = v44;
  v44(&v30[v116 + v63 * v51], v107, v117);
  uint64_t v65 = v46 + *(int *)(type metadata accessor for MLFewShotSoundClassifier.TemporalClassifier(0) + 20);
  uint64_t v66 = *(void (**)(char *, uint64_t, uint64_t))(v102 + 16);
  uint64_t v67 = (uint64_t)v110;
  v66(v110, v65, v97);
  uint64_t v68 = v113;
  NeuralNetwork.Layer.InnerProductParameters.init(from:)(v67, v113);
  uint64_t v69 = *MEMORY[0x263F53240];
  v96(v68, v69, v114);
  NeuralNetwork.Layer.init(name:inputNames:outputNames:kind:)();
  unint64_t v70 = *((void *)v30 + 2);
  if (v70 >= *((void *)v30 + 3) >> 1)
  {
    specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
    uint64_t v30 = v90;
  }
  *((void *)v30 + 2) = v70 + 1;
  v64(&v30[v116 + v70 * v112], v108, v117);
  static NeuralNetwork.Layer.relu(name:inputName:outputName:)();
  unint64_t v71 = *((void *)v30 + 2);
  if (v71 >= *((void *)v30 + 3) >> 1)
  {
    specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
    uint64_t v30 = v91;
  }
  *((void *)v30 + 2) = v71 + 1;
  uint64_t v72 = &v30[v116 + v71 * v112];
  uint64_t v73 = v112;
  v64(v72, v109, v117);
  uint64_t v74 = v65 + *(int *)(type metadata accessor for MLFewShotSoundClassifier.MLP(0) + 20);
  uint64_t v75 = (uint64_t)v110;
  v66(v110, v74, v97);
  uint64_t v76 = v113;
  NeuralNetwork.Layer.InnerProductParameters.init(from:)(v75, v113);
  v96(v76, v69, v114);
  uint64_t v77 = v101;
  NeuralNetwork.Layer.init(name:inputNames:outputNames:kind:)();
  unint64_t v78 = *((void *)v30 + 2);
  if (v78 >= *((void *)v30 + 3) >> 1)
  {
    specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
    uint64_t v30 = v92;
  }
  uint64_t v79 = v103;
  *((void *)v30 + 2) = v78 + 1;
  v64(&v30[v116 + v78 * v73], v77, v117);
  static NeuralNetwork.Layer.softmax(name:inputName:outputName:)();
  unint64_t v80 = *((void *)v30 + 2);
  if (v80 >= *((void *)v30 + 3) >> 1)
  {
    specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
    uint64_t v30 = v93;
  }
  *((void *)v30 + 2) = v80 + 1;
  v64(&v30[v116 + v80 * v73], v79, v117);
  return v30;
}

uint64_t MLFewShotSoundClassifier.TemporalClassifier.branchClassifier(input:classLabels:framewiseEmbeddingShape:exemplar:)@<X0>(uint64_t a1@<X0>, uint64_t a2@<X1>, void (*a3)(char *, uint64_t)@<X2>, uint64_t a4@<X3>, uint64_t a5@<X8>)
{
  uint64_t v102 = a4;
  uint64_t v104 = a3;
  uint64_t v95 = a2;
  uint64_t v97 = a5;
  uint64_t v6 = type metadata accessor for ModelKind();
  uint64_t v98 = *(void *)(v6 - 8);
  uint64_t v99 = v6;
  MEMORY[0x270FA5388](v6);
  uint64_t v96 = (char *)&v71 - ((v7 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v94 = type metadata accessor for NeuralNetworkClassifier.ClassLabels();
  uint64_t v92 = *(void *)(v94 - 8);
  MEMORY[0x270FA5388](v94);
  uint64_t v91 = (uint64_t *)((char *)&v71 - ((v8 + 15) & 0xFFFFFFFFFFFFFFF0));
  uint64_t v9 = type metadata accessor for NeuralNetwork.ArrayShapeMapping();
  uint64_t v87 = *(void *)(v9 - 8);
  uint64_t v88 = v9;
  MEMORY[0x270FA5388](v9);
  uint64_t v86 = (char *)&v71 - ((v10 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v93 = type metadata accessor for NeuralNetworkClassifier();
  uint64_t v90 = *(void *)(v93 - 8);
  MEMORY[0x270FA5388](v93);
  uint64_t v89 = (char *)&v71 - ((v11 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v84 = type metadata accessor for FeatureType.ShapedArrayParameters.DataType();
  uint64_t v83 = *(void *)(v84 - 8);
  MEMORY[0x270FA5388](v84);
  uint64_t v82 = (char *)&v71 - ((v12 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v13 = type metadata accessor for FeatureType();
  uint64_t v85 = *(void *)(v13 - 8);
  MEMORY[0x270FA5388](v13);
  uint64_t v15 = (char *)&v71 - ((v14 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v16 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for NeuralNetwork?);
  MEMORY[0x270FA5388](v16 - 8);
  uint64_t v81 = (char *)&v71 - ((v17 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v18 = type metadata accessor for NeuralNetwork.Layer();
  uint64_t v19 = *(void *)(v18 - 8);
  MEMORY[0x270FA5388](v18);
  unint64_t v80 = (char *)&v71 - ((v20 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v21 = type metadata accessor for NeuralNetwork();
  uint64_t v100 = *(void *)(v21 - 8);
  uint64_t v101 = v21;
  uint64_t v22 = MEMORY[0x270FA5388](v21);
  uint64_t v24 = (char *)&v71 - ((v23 + 15) & 0xFFFFFFFFFFFFFFF0);
  MEMORY[0x270FA5388](v22);
  uint64_t v26 = (char *)&v71 - v25;
  uint64_t v27 = a1;
  uint64_t v28 = MLFewShotSoundClassifier.TemporalClassifier.cosineSimilarity(input:exemplar:)(a1, v102);
  uint64_t v29 = v103;
  MLFewShotSoundClassifier.TemporalClassifier.largeMarginClassifierLayers(framewiseEmbeddingShape:)((uint64_t)v104);
  if (v29) {
    return swift_bridgeObjectRelease();
  }
  uint64_t v74 = v18;
  uint64_t v75 = v27;
  uint64_t v76 = v15;
  uint64_t v77 = v13;
  uint64_t v102 = 0;
  NeuralNetwork.init(layers:preprocessors:)();
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<NeuralNetwork.Layer>);
  uint64_t v31 = *(void *)(v19 + 72);
  uint64_t v73 = (void (**)(void, char *, uint64_t))v19;
  unint64_t v32 = (*(unsigned __int8 *)(v19 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v19 + 80);
  uint64_t v33 = swift_allocObject();
  long long v103 = xmmword_2272CB4D0;
  *(_OWORD *)(v33 + 16) = xmmword_2272CB4D0;
  unint64_t v72 = v32;
  static NeuralNetwork.Layer.constant(name:outputName:shape:values:)();
  static NeuralNetwork.Layer.squeezeAll(name:inputName:outputName:)();
  NeuralNetwork.init(layers:preprocessors:)();
  uint64_t v34 = v101;
  uint64_t v35 = (uint64_t)v81;
  (*(void (**)(char *, char *, uint64_t))(v100 + 16))(v81, v24, v101);
  __swift_storeEnumTagSinglePayload(v35, 0, 1, v34);
  uint64_t v36 = v28;
  char v37 = v80;
  static NeuralNetwork.Layer.branch(name:inputName:ifBranch:elseBranch:)();
  outlined destroy of NeuralNetwork?(v35);
  char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native();
  uint64_t v39 = v36;
  uint64_t v79 = v24;
  if ((isUniquelyReferenced_nonNull_native & 1) == 0)
  {
    specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
    uint64_t v39 = v69;
  }
  uint64_t v40 = v83;
  uint64_t v41 = v75;
  uint64_t v42 = v74;
  unint64_t v44 = *(void *)(v39 + 16);
  unint64_t v43 = *(void *)(v39 + 24);
  unint64_t v45 = v73;
  unint64_t v78 = v26;
  if (v44 >= v43 >> 1)
  {
    specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
    uint64_t v39 = v70;
  }
  uint64_t v83 = v39;
  *(void *)(v39 + 16) = v44 + 1;
  v45[4](v39 + v72 + v44 * v31, v37, v42);
  Model.init()();
  Model.specificationVersion.setter();
  unint64_t v80 = (char *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<FeatureDescription>);
  uint64_t v46 = type metadata accessor for FeatureDescription();
  uint64_t v47 = *(void *)(v46 - 8);
  uint64_t v48 = *(char **)(v47 + 72);
  uint64_t v49 = *(unsigned __int8 *)(v47 + 80);
  uint64_t v50 = (v49 + 32) & ~v49;
  uint64_t v75 = v50 + 2 * (void)v48;
  uint64_t v51 = v48;
  uint64_t v81 = v48;
  uint64_t v74 = v49 | 7;
  uint64_t v52 = swift_allocObject();
  *(_OWORD *)(v52 + 16) = v103;
  uint64_t v53 = v52 + v50;
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v47 + 16))(v52 + v50, v41, v46);
  unint64_t v72 = (unint64_t)&v51[v53];
  uint64_t v54 = *MEMORY[0x263F531A0];
  uint64_t v73 = *(void (***)(void, char *, uint64_t))(v40 + 104);
  unint64_t v55 = v82;
  uint64_t v56 = v40;
  uint64_t v57 = v84;
  ((void (*)(char *, uint64_t, uint64_t))v73)(v82, v54, v84);
  uint64_t v58 = v76;
  static FeatureType.shapedArray(dataType:shape:optional:)();
  uint64_t v104 = *(void (**)(char *, uint64_t))(v56 + 8);
  v104(v55, v57);
  FeatureDescription.init(name:type:description:)();
  Model.inputs.setter();
  *(_OWORD *)(swift_allocObject() + 16) = v103;
  ((void (*)(char *, uint64_t, uint64_t))v73)(v55, v54, v57);
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
  uint64_t v59 = swift_allocObject();
  *(_OWORD *)(v59 + 16) = xmmword_2272CB4A0;
  *(int64x2_t *)(v59 + 32) = vdupq_n_s64(1uLL);
  uint64_t v60 = v95;
  *(void *)(v59 + 48) = *(void *)(v95 + 16);
  static FeatureType.shapedArray(dataType:shape:optional:)();
  swift_bridgeObjectRelease();
  v104(v55, v57);
  FeatureDescription.init(name:type:description:)();
  FeatureType.StringParameters.init(optional:)();
  (*(void (**)(char *, void, uint64_t))(v85 + 104))(v58, *MEMORY[0x263F531D0], v77);
  FeatureDescription.init(name:type:description:)();
  Model.outputs.setter();
  Model.predictedFeatureName.setter();
  Model.predictedProbabilitiesName.setter();
  BOOL v61 = v89;
  NeuralNetworkClassifier.init(layers:preprocessors:)();
  (*(void (**)(char *, void, uint64_t))(v87 + 104))(v86, *MEMORY[0x263F53208], v88);
  NeuralNetworkClassifier.arrayInputShapeMapping.setter();
  NeuralNetworkClassifier.labelProbabilityLayerName.setter();
  unint64_t v63 = v91;
  uint64_t v62 = v92;
  *uint64_t v91 = v60;
  (*(void (**)(void *, void, uint64_t))(v62 + 104))(v63, *MEMORY[0x263F53288], v94);
  swift_bridgeObjectRetain();
  NeuralNetworkClassifier.classLabels.setter();
  uint64_t v64 = v90;
  uint64_t v65 = v96;
  uint64_t v66 = v93;
  (*(void (**)(char *, char *, uint64_t))(v90 + 16))(v96, v61, v93);
  (*(void (**)(char *, void, uint64_t))(v98 + 104))(v65, *MEMORY[0x263F53438], v99);
  Model.kind.setter();
  (*(void (**)(char *, uint64_t))(v64 + 8))(v61, v66);
  uint64_t v67 = v101;
  uint64_t v68 = *(void (**)(char *, uint64_t))(v100 + 8);
  v68(v79, v101);
  return ((uint64_t (*)(char *, uint64_t))v68)(v78, v67);
}

uint64_t MLFewShotSoundClassifier.TemporalClassifier.cosineSimilarity(input:exemplar:)(uint64_t a1, uint64_t a2)
{
  v38[1] = a2;
  uint64_t v2 = type metadata accessor for NeuralNetwork.Layer();
  uint64_t v3 = *(void *)(v2 - 8);
  uint64_t v4 = MEMORY[0x270FA5388](v2);
  uint64_t v40 = (char *)v38 - ((v5 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v6 = MEMORY[0x270FA5388](v4);
  uint64_t v39 = (char *)v38 - v7;
  uint64_t v8 = MEMORY[0x270FA5388](v6);
  uint64_t v10 = (char *)v38 - v9;
  uint64_t v11 = MEMORY[0x270FA5388](v8);
  uint64_t v13 = (char *)v38 - v12;
  MEMORY[0x270FA5388](v11);
  uint64_t v15 = (char *)v38 - v14;
  FeatureDescription.name.getter();
  static NeuralNetwork.Layer.expandDimensions(name:inputName:outputName:axes:)();
  swift_bridgeObjectRelease();
  specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
  uint64_t v17 = v16;
  unint64_t v18 = *(void *)(v16 + 16);
  if (v18 >= *(void *)(v16 + 24) >> 1)
  {
    specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
    uint64_t v17 = v33;
  }
  *(void *)(v17 + 16) = v18 + 1;
  uint64_t v21 = *(void (**)(unint64_t, char *, uint64_t))(v3 + 32);
  uint64_t v20 = v3 + 32;
  uint64_t v19 = v21;
  unint64_t v22 = (*(unsigned __int8 *)(v20 + 48) + 32) & ~(unint64_t)*(unsigned __int8 *)(v20 + 48);
  uint64_t v23 = *(void *)(v20 + 40);
  v21(v17 + v22 + v23 * v18, v15, v2);
  static NeuralNetwork.Layer.constant(name:outputName:shape:values:)();
  unint64_t v24 = *(void *)(v17 + 16);
  if (v24 >= *(void *)(v17 + 24) >> 1)
  {
    specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
    uint64_t v17 = v34;
  }
  *(void *)(v17 + 16) = v24 + 1;
  unint64_t v25 = v17 + v22 + v24 * v23;
  uint64_t v26 = v2;
  v19(v25, v13, v2);
  static NeuralNetwork.Layer.constant(name:outputName:shape:values:)();
  unint64_t v27 = *(void *)(v17 + 16);
  if (v27 >= *(void *)(v17 + 24) >> 1)
  {
    specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
    uint64_t v17 = v35;
  }
  uint64_t v28 = v39;
  *(void *)(v17 + 16) = v27 + 1;
  v19(v17 + v22 + v27 * v23, v10, v26);
  static NeuralNetwork.Layer.cosineSimilarity(name:inputNames:outputName:)();
  unint64_t v29 = *(void *)(v17 + 16);
  if (v29 >= *(void *)(v17 + 24) >> 1)
  {
    specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
    uint64_t v17 = v36;
  }
  *(void *)(v17 + 16) = v29 + 1;
  v19(v17 + v22 + v29 * v23, v28, v26);
  uint64_t v30 = v40;
  static NeuralNetwork.Layer.broadcastableSubtract(name:inputNames:outputName:)();
  unint64_t v31 = *(void *)(v17 + 16);
  if (v31 >= *(void *)(v17 + 24) >> 1)
  {
    specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
    uint64_t v17 = v37;
  }
  *(void *)(v17 + 16) = v31 + 1;
  v19(v17 + v22 + v31 * v23, v30, v26);
  return v17;
}

uint64_t MLFewShotSoundClassifier.TemporalClassifier.soundPrintKCustomModel(input:fixedOutput:framewiseEmbeddingShape:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v23 = a2;
  uint64_t v24 = a3;
  uint64_t v21 = a1;
  uint64_t v3 = type metadata accessor for ModelKind();
  uint64_t v26 = *(void *)(v3 - 8);
  uint64_t v27 = v3;
  MEMORY[0x270FA5388](v3);
  unint64_t v25 = (char *)v19 - ((v4 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v22 = type metadata accessor for FeatureType.ShapedArrayParameters.DataType();
  uint64_t v20 = *(void *)(v22 - 8);
  MEMORY[0x270FA5388](v22);
  uint64_t v6 = (char *)v19 - ((v5 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v7 = type metadata accessor for FeatureType();
  MEMORY[0x270FA5388](v7 - 8);
  v19[1] = (char *)v19 - ((v8 + 15) & 0xFFFFFFFFFFFFFFF0);
  Model.init()();
  Model.specificationVersion.setter();
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<FeatureDescription>);
  uint64_t v9 = type metadata accessor for FeatureDescription();
  uint64_t v10 = *(void *)(v9 - 8);
  unint64_t v11 = (*(unsigned __int8 *)(v10 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v10 + 80);
  uint64_t v12 = swift_allocObject();
  *(_OWORD *)(v12 + 16) = xmmword_2272CB370;
  uint64_t v13 = *(void (**)(unint64_t, uint64_t, uint64_t))(v10 + 16);
  v13(v12 + v11, v21, v9);
  Model.inputs.setter();
  uint64_t v14 = swift_allocObject();
  *(_OWORD *)(v14 + 16) = xmmword_2272CB4D0;
  v13(v14 + v11, v23, v9);
  uint64_t v15 = v20;
  uint64_t v16 = v22;
  (*(void (**)(char *, void, uint64_t))(v20 + 104))(v6, *MEMORY[0x263F531A0], v22);
  static FeatureType.shapedArray(dataType:shape:optional:)();
  (*(void (**)(char *, uint64_t))(v15 + 8))(v6, v16);
  FeatureDescription.init(name:type:description:)();
  Model.outputs.setter();
  type metadata accessor for CustomModelConfiguration.ParameterValue();
  Dictionary.init(dictionaryLiteral:)();
  uint64_t v17 = v25;
  CustomModelConfiguration.init(className:parameters:)();
  (*(void (**)(char *, void, uint64_t))(v26 + 104))(v17, *MEMORY[0x263F53448], v27);
  return Model.kind.setter();
}

uint64_t MLFewShotSoundClassifier.TemporalClassifier.pipeline(classLabels:inferenceWindowSize:framewiseEmbeddingShape:exemplar:)@<X0>(uint64_t a1@<X0>, uint64_t a2@<X1>, uint64_t a3@<X2>, uint64_t a4@<X3>, uint64_t a5@<X8>)
{
  uint64_t v67 = a4;
  uint64_t v65 = (void (*)(char *, uint64_t))a3;
  uint64_t v66 = a1;
  uint64_t v64 = a5;
  type metadata accessor for ModelKind();
  OUTLINED_FUNCTION_0();
  uint64_t v62 = v8;
  uint64_t v63 = v7;
  MEMORY[0x270FA5388](v7);
  OUTLINED_FUNCTION_3_0();
  uint64_t v61 = v10 - v9;
  type metadata accessor for Model();
  OUTLINED_FUNCTION_0();
  uint64_t v69 = v12;
  uint64_t v70 = v11;
  MEMORY[0x270FA5388](v11);
  OUTLINED_FUNCTION_49();
  uint64_t v73 = (char *)v13;
  MEMORY[0x270FA5388](v14);
  unint64_t v72 = (char *)&v60 - v15;
  uint64_t v16 = type metadata accessor for FeatureType.ShapedArrayParameters.DataType();
  OUTLINED_FUNCTION_0();
  uint64_t v18 = v17;
  MEMORY[0x270FA5388](v19);
  OUTLINED_FUNCTION_60();
  uint64_t v20 = type metadata accessor for FeatureType();
  MEMORY[0x270FA5388](v20 - 8);
  OUTLINED_FUNCTION_3_0();
  uint64_t v75 = type metadata accessor for FeatureDescription();
  OUTLINED_FUNCTION_0();
  uint64_t v74 = v21;
  MEMORY[0x270FA5388](v22);
  OUTLINED_FUNCTION_49();
  uint64_t v71 = v23;
  MEMORY[0x270FA5388](v24);
  uint64_t v26 = (char *)&v60 - v25;
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
  uint64_t v27 = swift_allocObject();
  *(_OWORD *)(v27 + 16) = xmmword_2272CB4A0;
  *(int64x2_t *)(v27 + 32) = vdupq_n_s64(1uLL);
  *(void *)(v27 + 48) = a2;
  uint64_t v28 = *MEMORY[0x263F531A0];
  unint64_t v29 = *(void (**)(uint64_t, uint64_t, uint64_t))(v18 + 104);
  v29(v5, v28, v16);
  static FeatureType.shapedArray(dataType:shape:optional:)();
  swift_bridgeObjectRelease();
  uint64_t v30 = *(void (**)(uint64_t))(v18 + 8);
  uint64_t v31 = OUTLINED_FUNCTION_4_5();
  v30(v31);
  FeatureDescription.init(name:type:description:)();
  uint64_t v32 = v28;
  uint64_t v33 = (uint64_t)v26;
  uint64_t v34 = v71;
  v29(v5, v32, v16);
  static FeatureType.shapedArray(dataType:shape:optional:)();
  uint64_t v35 = OUTLINED_FUNCTION_4_5();
  v30(v35);
  uint64_t v36 = v72;
  FeatureDescription.init(name:type:description:)();
  uint64_t v37 = v65;
  MLFewShotSoundClassifier.TemporalClassifier.soundPrintKCustomModel(input:fixedOutput:framewiseEmbeddingShape:)(v33, v34, (uint64_t)v65);
  uint64_t v38 = v68;
  MLFewShotSoundClassifier.TemporalClassifier.branchClassifier(input:classLabels:framewiseEmbeddingShape:exemplar:)(v34, v66, v37, v67, (uint64_t)v73);
  if (v38)
  {
    OUTLINED_FUNCTION_25_0();
    v39();
    uint64_t v40 = *(void (**)(uint64_t, uint64_t))(v74 + 8);
    uint64_t v41 = v75;
    v40(v34, v75);
    return ((uint64_t (*)(uint64_t, uint64_t))v40)(v33, v41);
  }
  else
  {
    Model.init()();
    Model.specificationVersion.setter();
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<FeatureDescription>);
    uint64_t v43 = v74;
    unint64_t v44 = (*(unsigned __int8 *)(v74 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v74 + 80);
    uint64_t v45 = swift_allocObject();
    *(_OWORD *)(v45 + 16) = xmmword_2272CB370;
    (*(void (**)(unint64_t, uint64_t, uint64_t))(v43 + 16))(v45 + v44, v33, v75);
    Model.inputs.setter();
    Model.outputs.getter();
    Model.outputs.setter();
    OUTLINED_FUNCTION_3_35();
    Model.predictedFeatureName.setter();
    OUTLINED_FUNCTION_3_35();
    Model.predictedProbabilitiesName.setter();
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Model>);
    uint64_t v68 = v33;
    uint64_t v46 = v69;
    uint64_t v47 = *(void *)(v69 + 72);
    unint64_t v48 = (*(unsigned __int8 *)(v69 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v69 + 80);
    uint64_t v49 = swift_allocObject();
    *(_OWORD *)(v49 + 16) = xmmword_2272CB4D0;
    unint64_t v50 = v49 + v48;
    uint64_t v51 = *(void (**)(unint64_t, char *, uint64_t))(v46 + 16);
    uint64_t v52 = v36;
    uint64_t v53 = v70;
    v51(v50, v52, v70);
    unint64_t v54 = v50 + v47;
    uint64_t v55 = (uint64_t)v73;
    v51(v54, v73, v53);
    uint64_t v56 = v61;
    PipelineConfiguration.init(models:names:)();
    (*(void (**)(uint64_t, void, uint64_t))(v62 + 104))(v56, *MEMORY[0x263F53470], v63);
    Model.kind.setter();
    uint64_t v57 = *(void (**)(uint64_t, uint64_t))(v46 + 8);
    v57(v55, v53);
    v57((uint64_t)v72, v53);
    uint64_t v58 = *(void (**)(uint64_t, uint64_t))(v74 + 8);
    uint64_t v59 = v75;
    v58(v71, v75);
    return ((uint64_t (*)(uint64_t, uint64_t))v58)(v68, v59);
  }
}

uint64_t MLFewShotSoundClassifier.write(to:)(uint64_t a1)
{
  uint64_t v4 = type metadata accessor for MLFewShotSoundClassifier.TemporalClassifier(0);
  MEMORY[0x270FA5388](v4 - 8);
  OUTLINED_FUNCTION_3_0();
  uint64_t v7 = v6 - v5;
  type metadata accessor for Model();
  OUTLINED_FUNCTION_0();
  MEMORY[0x270FA5388](v8);
  OUTLINED_FUNCTION_60();
  uint64_t v9 = type metadata accessor for URL();
  OUTLINED_FUNCTION_0();
  uint64_t v11 = v10;
  MEMORY[0x270FA5388](v12);
  OUTLINED_FUNCTION_3_0();
  uint64_t v15 = v14 - v13;
  uint64_t result = static _ValidationUtilities.validateWriteLocation(atURL:defaultName:fileExtension:)(a1, 0xD000000000000016, (void *)0x80000002272D7830, 0x6C65646F6D6C6DLL, (void *)0xE700000000000000, v14 - v13);
  if (!v1)
  {
    uint64_t v38 = v15;
    uint64_t v35 = v7;
    uint64_t v36 = v2;
    uint64_t v37 = v11;
    uint64_t v17 = (int *)type metadata accessor for MLFewShotSoundClassifier();
    uint64_t v18 = *(void **)(v39 + v17[12]);
    id v19 = objc_msgSend(v18, sel_trainingDataEmbeddings);
    type metadata accessor for NSAttributedString(0, (unint64_t *)&lazy cache variable for type metadata for MLMultiArray);
    unint64_t v20 = static Array._unconditionallyBridgeFromObjectiveC(_:)();

    if (v20 >> 62)
    {
      swift_bridgeObjectRetain();
      uint64_t v21 = _CocoaArrayWrapper.endIndex.getter();
      swift_bridgeObjectRelease();
    }
    else
    {
      uint64_t v21 = *(void *)((v20 & 0xFFFFFFFFFFFFFF8) + 0x10);
    }
    if (v21)
    {
      specialized Array._checkSubscript(_:wasNativeTypeChecked:)(0, (v20 & 0xC000000000000001) == 0, v20);
      if ((v20 & 0xC000000000000001) != 0) {
        id v22 = (id)MEMORY[0x22A6753B0](0, v20);
      }
      else {
        id v22 = *(id *)(v20 + 32);
      }
      uint64_t v23 = v22;
      swift_bridgeObjectRelease();
      id v24 = objc_msgSend(v23, sel_shape);

      type metadata accessor for NSAttributedString(0, (unint64_t *)&lazy cache variable for type metadata for NSNumber);
      unint64_t v25 = static Array._unconditionallyBridgeFromObjectiveC(_:)();

      id v26 = objc_msgSend(v18, sel_exemplar);
      uint64_t v27 = UnsafeBufferPointer.init(_:)();
      uint64_t v30 = specialized _copyCollectionToContiguousArray<A>(_:)(v27, v29);
      outlined init with copy of MLFewShotSoundClassifier.TemporalClassifier(v39 + v17[10], v35, type metadata accessor for MLFewShotSoundClassifier.TemporalClassifier);
      uint64_t v31 = *(void *)(v39 + v17[8]);
      objc_msgSend(v18, sel_inferenceWindowSize);
      _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSaySo8NSNumberCG_Sis5NeverOTg50125_s8CreateML20MLHandPoseClassifierV15modelPrediction2on5usingSaySS5label_Sd10confidencetGSo12MLMultiArrayC_So7MLModelCtKFSiSo8D54Ccfu_33_5bdac5b40c7411f20a64c1277f8fd44fAOSiTf3nnnpk_nTf1cn_n(v25);
      uint64_t v33 = v32;
      swift_bridgeObjectRelease();
      MLFewShotSoundClassifier.TemporalClassifier.pipeline(classLabels:inferenceWindowSize:framewiseEmbeddingShape:exemplar:)(v31, v40, v33, (uint64_t)v30, v36);
      outlined destroy of MLFewShotSoundClassifier.TemporalClassifier(v35, (void (*)(void))type metadata accessor for MLFewShotSoundClassifier.TemporalClassifier);
      swift_release();
      swift_bridgeObjectRelease();
      Model.write(to:)();
      OUTLINED_FUNCTION_25_0();
      v34();
      return (*(uint64_t (**)(uint64_t, uint64_t))(v37 + 8))(v38, v9);
    }
    else
    {
      swift_bridgeObjectRelease();
      lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
      swift_allocError();
      *(void *)uint64_t v28 = 0xD000000000000037;
      *(void *)(v28 + 8) = 0x80000002272D7850;
      *(_OWORD *)(v28 + 16) = 0u;
      *(_OWORD *)(v28 + 32) = 0u;
      *(unsigned char *)(v28 + 48) = 2;
      swift_willThrow();
      return (*(uint64_t (**)(uint64_t, uint64_t))(v37 + 8))(v15, v9);
    }
  }
  return result;
}

uint64_t outlined destroy of NeuralNetwork?(uint64_t a1)
{
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for NeuralNetwork?);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v2 - 8) + 8))(a1, v2);
  return a1;
}

uint64_t outlined init with copy of MLFewShotSoundClassifier.TemporalClassifier(uint64_t a1, uint64_t a2, uint64_t (*a3)(void))
{
  uint64_t v5 = a3(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v5 - 8) + 16))(a2, a1, v5);
  return a2;
}

uint64_t outlined destroy of MLFewShotSoundClassifier.TemporalClassifier(uint64_t a1, void (*a2)(void))
{
  a2(0);
  OUTLINED_FUNCTION_25_0();
  v3();
  return a1;
}

uint64_t OUTLINED_FUNCTION_3_35()
{
  return 0x62614C7373616C63;
}

uint64_t MLImageClassifier.evaluation(on:)()
{
  uint64_t v0 = type metadata accessor for MLImageClassifier();
  uint64_t v1 = OUTLINED_FUNCTION_1(v0);
  MEMORY[0x270FA5388](v1);
  uint64_t v2 = type metadata accessor for MLImageClassifier.DataSource();
  uint64_t v3 = OUTLINED_FUNCTION_1(v2);
  MEMORY[0x270FA5388](v3);
  outlined init with copy of MLImageClassifier.DataSource();
  outlined init with copy of MLImageClassifier.DataSource();
  swift_allocObject();
  outlined init with take of MLImageClassifier.DataSource();
  outlined init with take of MLImageClassifier.DataSource();
  specialized blockAwait<A>(_:)();
  swift_release();
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [(predicted: String, label: String)]);
  lazy protocol witness table accessor for type [(predicted: String, label: String)] and conformance [A]();
  ClassificationMetrics.init<A>(_:)();
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
  swift_storeEnumTagMultiPayload();
  type metadata accessor for MLClassifierMetrics.Contents(0);
  return swift_storeEnumTagMultiPayload();
}

uint64_t closure #1 in MLImageClassifier.evaluation(on:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  v3[3] = a2;
  v3[4] = a3;
  v3[2] = a1;
  uint64_t v4 = *(void *)(type metadata accessor for MLImageClassifier() - 8);
  v3[5] = v4;
  v3[6] = *(void *)(v4 + 64);
  v3[7] = swift_task_alloc();
  return MEMORY[0x270FA2498](closure #1 in MLImageClassifier.evaluation(on:), 0, 0);
}

uint64_t closure #1 in MLImageClassifier.evaluation(on:)()
{
  uint64_t v1 = static _ImageUtilities.getImageURLsAndLabels(from:)(v0[3]);
  uint64_t v2 = specialized _NativeDictionary.mapValues<A>(_:)(v1);
  swift_bridgeObjectRelease();
  outlined init with copy of MLImageClassifier.DataSource();
  swift_allocObject();
  outlined init with take of MLImageClassifier.DataSource();
  uint64_t v3 = specialized _NativeDictionary.mapValues<A>(_:)(v2, (uint64_t (*)(uint64_t))partial apply for implicit closure #2 in implicit closure #1 in closure #1 in MLImageClassifier.evaluation(on:));
  swift_release();
  swift_release();
  uint64_t v5 = (uint64_t *)v0[2];
  uint64_t v6 = specialized Sequence.flatMap<A>(_:)(v3);
  swift_release();
  *uint64_t v5 = v6;
  swift_task_dealloc();
  uint64_t v7 = (uint64_t (*)(void))v0[1];
  return v7();
}

uint64_t outlined init with copy of MLImageClassifier.DataSource()
{
  uint64_t v2 = OUTLINED_FUNCTION_7_24();
  v3(v2);
  OUTLINED_FUNCTION_8();
  (*(void (**)(uint64_t, uint64_t))(v4 + 16))(v0, v1);
  return v0;
}

uint64_t sub_227147598()
{
  type metadata accessor for MLImageClassifier.DataSource();
  OUTLINED_FUNCTION_57_5();
  uint64_t v32 = *(unsigned __int8 *)(v2 + 80);
  uint64_t v3 = (v32 + 16) & ~v32;
  uint64_t v5 = *(void *)(v4 + 64);
  uint64_t v6 = type metadata accessor for MLImageClassifier();
  OUTLINED_FUNCTION_57_5();
  uint64_t v8 = *(unsigned __int8 *)(v7 + 80);
  uint64_t v33 = (v3 + v5 + v8) & ~v8;
  uint64_t v10 = *(void *)(v9 + 64);
  uint64_t v34 = v0;
  uint64_t v11 = v0 + v3;
  unsigned int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload();
  if (EnumCaseMultiPayload == 2)
  {
    swift_bridgeObjectRelease();
  }
  else if (EnumCaseMultiPayload <= 1)
  {
    type metadata accessor for URL();
    OUTLINED_FUNCTION_8();
    (*(void (**)(uint64_t))(v13 + 8))(v11);
  }
  uint64_t v14 = v0 + v33;

  if (*(void *)(v0 + v33 + 48)) {
    __swift_destroy_boxed_opaque_existential_0(v14 + 24);
  }
  if (*(void *)(v14 + 80)) {
    __swift_destroy_boxed_opaque_existential_0(v14 + 56);
  }
  uint64_t v15 = (id *)(v14 + *(int *)(v6 + 24));
  type metadata accessor for MLClassifierMetrics.Contents(0);
  int v16 = swift_getEnumCaseMultiPayload();
  switch(v16)
  {
    case 2:

      break;
    case 1:
      type metadata accessor for MLClassifierMetrics.Precomputed(0);
      uint64_t v18 = OUTLINED_FUNCTION_5_26();
      id v19 = *(void (**)(uint64_t, uint64_t))(*(void *)(v18 - 8) + 8);
      v19(v1, v18);
      v19((uint64_t)v15 + *(int *)(v10 + 24), v18);
      break;
    case 0:
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
      if (OUTLINED_FUNCTION_43() == 1) {
        uint64_t v17 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
      }
      else {
        uint64_t v17 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
      }
      __swift_instantiateConcreteTypeFromMangledName(v17);
      OUTLINED_FUNCTION_8();
      uint64_t v20 = OUTLINED_FUNCTION_9_22();
      v21(v20);
      break;
  }
  int v22 = OUTLINED_FUNCTION_6_24();
  switch(v22)
  {
    case 2:

      break;
    case 1:
      type metadata accessor for MLClassifierMetrics.Precomputed(0);
      type metadata accessor for DataFrame();
      OUTLINED_FUNCTION_8();
      unint64_t v25 = *(void (**)(void))(v24 + 8);
      OUTLINED_FUNCTION_35_6();
      v25();
      OUTLINED_FUNCTION_35_6();
      v25();
      break;
    case 0:
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
      if (OUTLINED_FUNCTION_43() == 1) {
        uint64_t v23 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
      }
      else {
        uint64_t v23 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
      }
      __swift_instantiateConcreteTypeFromMangledName(v23);
      OUTLINED_FUNCTION_8();
      uint64_t v26 = OUTLINED_FUNCTION_9_22();
      v27(v26);
      break;
  }
  uint64_t v28 = v14 + *(int *)(v6 + 32);
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  if (swift_getEnumCaseMultiPayload() == 1) {
    uint64_t v29 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>;
  }
  else {
    uint64_t v29 = &demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>;
  }
  __swift_instantiateConcreteTypeFromMangledName(v29);
  OUTLINED_FUNCTION_8();
  (*(void (**)(uint64_t))(v30 + 8))(v28);

  return MEMORY[0x270FA0238](v34, v33 + v10, v32 | v8 | 7);
}

uint64_t outlined init with take of MLImageClassifier.DataSource()
{
  uint64_t v2 = OUTLINED_FUNCTION_7_24();
  v3(v2);
  OUTLINED_FUNCTION_8();
  (*(void (**)(uint64_t, uint64_t))(v4 + 32))(v0, v1);
  return v0;
}

uint64_t partial apply for closure #1 in MLImageClassifier.evaluation(on:)(uint64_t a1)
{
  uint64_t v4 = type metadata accessor for MLImageClassifier.DataSource();
  OUTLINED_FUNCTION_1(v4);
  unint64_t v6 = (*(unsigned __int8 *)(v5 + 80) + 16) & ~(unint64_t)*(unsigned __int8 *)(v5 + 80);
  uint64_t v8 = *(void *)(v7 + 64);
  uint64_t v9 = type metadata accessor for MLImageClassifier();
  OUTLINED_FUNCTION_39_0(v9);
  uint64_t v11 = *(unsigned __int8 *)(v10 + 80);
  unint64_t v12 = v6 + v8 + v11;
  uint64_t v13 = v1 + v6;
  uint64_t v14 = v1 + (v12 & ~v11);
  uint64_t v15 = (void *)swift_task_alloc();
  *(void *)(v2 + 16) = v15;
  *uint64_t v15 = v2;
  v15[1] = partial apply for closure #1 in MLImageClassifier.evaluation(on:);
  return closure #1 in MLImageClassifier.evaluation(on:)(a1, v13, v14);
}

uint64_t partial apply for closure #1 in MLImageClassifier.evaluation(on:)()
{
  uint64_t v3 = *v0;
  swift_task_dealloc();
  uint64_t v1 = *(uint64_t (**)(void))(v3 + 8);
  return v1();
}

uint64_t MLImageClassifier.evaluation(on:)(uint64_t a1)
{
  type metadata accessor for MLImageClassifier.DataSource();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v2);
  uint64_t v4 = (uint64_t *)((char *)&v6 - ((v3 + 15) & 0xFFFFFFFFFFFFFFF0));
  *uint64_t v4 = a1;
  swift_storeEnumTagMultiPayload();
  swift_bridgeObjectRetain();
  MLImageClassifier.evaluation(on:)();
  return outlined destroy of MLImageClassifier.DataSource((uint64_t)v4);
}

uint64_t outlined destroy of MLImageClassifier.DataSource(uint64_t a1)
{
  uint64_t v2 = type metadata accessor for MLImageClassifier.DataSource();
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v2 - 8) + 8))(a1, v2);
  return a1;
}

uint64_t sub_227148098()
{
  uint64_t v2 = type metadata accessor for MLImageClassifier();
  OUTLINED_FUNCTION_57_5();
  uint64_t v4 = *(unsigned __int8 *)(v3 + 80);
  uint64_t v5 = (v4 + 16) & ~v4;
  uint64_t v7 = *(void *)(v6 + 64);
  uint64_t v26 = v0;
  uint64_t v8 = v0 + v5;

  if (*(void *)(v0 + v5 + 48)) {
    __swift_destroy_boxed_opaque_existential_0(v8 + 24);
  }
  if (*(void *)(v8 + 80)) {
    __swift_destroy_boxed_opaque_existential_0(v8 + 56);
  }
  uint64_t v9 = (id *)(v8 + *(int *)(v2 + 24));
  type metadata accessor for MLClassifierMetrics.Contents(0);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload();
  switch(EnumCaseMultiPayload)
  {
    case 2:

      break;
    case 1:
      type metadata accessor for MLClassifierMetrics.Precomputed(0);
      uint64_t v12 = OUTLINED_FUNCTION_5_26();
      uint64_t v13 = *(void (**)(char *, uint64_t))(*(void *)(v12 - 8) + 8);
      v13(v1, v12);
      v13((char *)v9 + *(int *)(v7 + 24), v12);
      uint64_t v5 = (v4 + 16) & ~v4;
      break;
    case 0:
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
      if (OUTLINED_FUNCTION_43() == 1) {
        uint64_t v11 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
      }
      else {
        uint64_t v11 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
      }
      __swift_instantiateConcreteTypeFromMangledName(v11);
      OUTLINED_FUNCTION_8();
      uint64_t v14 = OUTLINED_FUNCTION_9_22();
      v15(v14);
      break;
  }
  int v16 = OUTLINED_FUNCTION_6_24();
  switch(v16)
  {
    case 2:

      break;
    case 1:
      type metadata accessor for MLClassifierMetrics.Precomputed(0);
      type metadata accessor for DataFrame();
      OUTLINED_FUNCTION_8();
      id v19 = *(void (**)(void))(v18 + 8);
      OUTLINED_FUNCTION_35_6();
      v19();
      OUTLINED_FUNCTION_35_6();
      v19();
      break;
    case 0:
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
      if (OUTLINED_FUNCTION_43() == 1) {
        uint64_t v17 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
      }
      else {
        uint64_t v17 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
      }
      __swift_instantiateConcreteTypeFromMangledName(v17);
      OUTLINED_FUNCTION_8();
      uint64_t v20 = OUTLINED_FUNCTION_9_22();
      v21(v20);
      break;
  }
  uint64_t v22 = v8 + *(int *)(v2 + 32);
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  if (swift_getEnumCaseMultiPayload() == 1) {
    uint64_t v23 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>;
  }
  else {
    uint64_t v23 = &demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>;
  }
  __swift_instantiateConcreteTypeFromMangledName(v23);
  OUTLINED_FUNCTION_8();
  (*(void (**)(uint64_t))(v24 + 8))(v22);

  return MEMORY[0x270FA0238](v26, v5 + v7, v4 | 7);
}

id partial apply for implicit closure #2 in implicit closure #1 in closure #1 in MLImageClassifier.evaluation(on:)(unint64_t a1)
{
  uint64_t v2 = type metadata accessor for MLImageClassifier();
  OUTLINED_FUNCTION_39_0(v2);
  return MLImageClassifier.performRequests(_:)(a1);
}

uint64_t specialized _NativeDictionary.mapValues<A>(_:)(uint64_t a1, uint64_t (*a2)(uint64_t))
{
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _DictionaryStorage<String, [String]>);
  uint64_t result = static _DictionaryStorage.copy(original:)();
  uint64_t v5 = (void *)result;
  int64_t v6 = 0;
  uint64_t v29 = a1;
  uint64_t v9 = *(void *)(a1 + 64);
  uint64_t v8 = a1 + 64;
  uint64_t v7 = v9;
  uint64_t v10 = 1 << *(unsigned char *)(v8 - 32);
  uint64_t v11 = -1;
  if (v10 < 64) {
    uint64_t v11 = ~(-1 << v10);
  }
  unint64_t v12 = v11 & v7;
  uint64_t v26 = v8;
  int64_t v27 = (unint64_t)(v10 + 63) >> 6;
  uint64_t v28 = result + 64;
  if ((v11 & v7) == 0) {
    goto LABEL_5;
  }
LABEL_4:
  unint64_t v13 = __clz(__rbit64(v12));
  v12 &= v12 - 1;
  for (unint64_t i = v13 | (v6 << 6); ; unint64_t i = __clz(__rbit64(v16)) + (v6 << 6))
  {
    uint64_t v18 = (uint64_t *)(*(void *)(v29 + 48) + 16 * i);
    uint64_t v19 = *v18;
    uint64_t v20 = v18[1];
    swift_bridgeObjectRetain();
    uint64_t v21 = swift_bridgeObjectRetain();
    uint64_t v22 = a2(v21);
    uint64_t result = swift_bridgeObjectRelease();
    if (v2)
    {
      swift_bridgeObjectRelease();
      swift_release();
      return (uint64_t)v5;
    }
    *(void *)(v28 + ((i >> 3) & 0x1FFFFFFFFFFFFFF8)) |= 1 << i;
    uint64_t v23 = (void *)(v5[6] + 16 * i);
    *uint64_t v23 = v19;
    v23[1] = v20;
    *(void *)(v5[7] + 8 * i) = v22;
    uint64_t v24 = v5[2];
    BOOL v15 = __OFADD__(v24, 1);
    uint64_t v25 = v24 + 1;
    if (v15)
    {
      __break(1u);
LABEL_27:
      __break(1u);
      goto LABEL_28;
    }
    v5[2] = v25;
    if (v12) {
      goto LABEL_4;
    }
LABEL_5:
    BOOL v15 = __OFADD__(v6++, 1);
    if (v15) {
      goto LABEL_27;
    }
    if (v6 >= v27) {
      return (uint64_t)v5;
    }
    unint64_t v16 = *(void *)(v26 + 8 * v6);
    if (!v16) {
      break;
    }
LABEL_15:
    unint64_t v12 = (v16 - 1) & v16;
  }
  int64_t v17 = v6 + 1;
  if (v6 + 1 >= v27) {
    return (uint64_t)v5;
  }
  unint64_t v16 = *(void *)(v26 + 8 * v17);
  if (v16) {
    goto LABEL_14;
  }
  int64_t v17 = v6 + 2;
  if (v6 + 2 >= v27) {
    return (uint64_t)v5;
  }
  unint64_t v16 = *(void *)(v26 + 8 * v17);
  if (v16) {
    goto LABEL_14;
  }
  int64_t v17 = v6 + 3;
  if (v6 + 3 >= v27) {
    return (uint64_t)v5;
  }
  unint64_t v16 = *(void *)(v26 + 8 * v17);
  if (v16)
  {
LABEL_14:
    int64_t v6 = v17;
    goto LABEL_15;
  }
  while (1)
  {
    int64_t v6 = v17 + 1;
    if (__OFADD__(v17, 1)) {
      break;
    }
    if (v6 >= v27) {
      return (uint64_t)v5;
    }
    unint64_t v16 = *(void *)(v26 + 8 * v6);
    ++v17;
    if (v16) {
      goto LABEL_15;
    }
  }
LABEL_28:
  __break(1u);
  return result;
}

uint64_t OUTLINED_FUNCTION_5_26()
{
  return type metadata accessor for DataFrame();
}

uint64_t OUTLINED_FUNCTION_6_24()
{
  return swift_getEnumCaseMultiPayload();
}

uint64_t OUTLINED_FUNCTION_7_24()
{
  return 0;
}

uint64_t OUTLINED_FUNCTION_9_22()
{
  return v0;
}

void *initializeBufferWithCopyOfBuffer for MLLinearRegressor.Model(void *a1, void *a2, uint64_t a3)
{
  int v5 = *(_DWORD *)(*(void *)(a3 - 8) + 80);
  if ((v5 & 0x20000) != 0)
  {
    uint64_t v12 = *a2;
    *a1 = *a2;
    a1 = (void *)(v12 + ((v5 + 16) & ~(unint64_t)v5));
    swift_retain();
  }
  else
  {
    uint64_t v7 = a2[1];
    *a1 = *a2;
    a1[1] = v7;
    uint64_t v9 = a2 + 2;
    uint64_t v8 = a2[2];
    swift_bridgeObjectRetain();
    if (v8)
    {
      uint64_t v10 = a2[3];
      uint64_t v11 = a2[4];
      a1[2] = v8;
      a1[3] = v10;
      a1[4] = v11;
      swift_bridgeObjectRetain();
      swift_bridgeObjectRetain();
    }
    else
    {
      *((_OWORD *)a1 + 1) = *v9;
      a1[4] = a2[4];
    }
    uint64_t v13 = *(int *)(a3 + 24);
    uint64_t v14 = (char *)a1 + v13;
    BOOL v15 = (char *)a2 + v13;
    uint64_t v16 = type metadata accessor for BaseLinearRegressorModel();
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v16 - 8) + 16))(v14, v15, v16);
  }
  return a1;
}

uint64_t destroy for MLLinearRegressor.Model(uint64_t a1, uint64_t a2)
{
  swift_bridgeObjectRelease();
  if (*(void *)(a1 + 16))
  {
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
  }
  uint64_t v4 = a1 + *(int *)(a2 + 24);
  uint64_t v5 = type metadata accessor for BaseLinearRegressorModel();
  int64_t v6 = *(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v5 - 8) + 8);

  return v6(v4, v5);
}

void *initializeWithCopy for MLLinearRegressor.Model(void *a1, void *a2, uint64_t a3)
{
  uint64_t v6 = a2[1];
  *a1 = *a2;
  a1[1] = v6;
  uint64_t v8 = a2 + 2;
  uint64_t v7 = a2[2];
  swift_bridgeObjectRetain();
  if (v7)
  {
    uint64_t v9 = a2[3];
    uint64_t v10 = a2[4];
    a1[2] = v7;
    a1[3] = v9;
    a1[4] = v10;
    swift_bridgeObjectRetain();
    swift_bridgeObjectRetain();
  }
  else
  {
    *((_OWORD *)a1 + 1) = *(_OWORD *)v8;
    a1[4] = v8[2];
  }
  uint64_t v11 = *(int *)(a3 + 24);
  uint64_t v12 = (char *)a1 + v11;
  uint64_t v13 = (char *)a2 + v11;
  uint64_t v14 = type metadata accessor for BaseLinearRegressorModel();
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v14 - 8) + 16))(v12, v13, v14);
  return a1;
}

void *assignWithCopy for MLLinearRegressor.Model(void *a1, void *a2, uint64_t a3)
{
  *a1 = *a2;
  a1[1] = a2[1];
  swift_bridgeObjectRetain();
  swift_bridgeObjectRelease();
  uint64_t v6 = a1 + 2;
  uint64_t v8 = a2 + 2;
  uint64_t v7 = a2[2];
  if (a1[2])
  {
    if (v7)
    {
      a1[2] = v7;
      swift_bridgeObjectRetain();
      swift_bridgeObjectRelease();
      a1[3] = a2[3];
      a1[4] = a2[4];
      swift_bridgeObjectRetain();
      swift_bridgeObjectRelease();
    }
    else
    {
      outlined destroy of FeatureVectorizer<Double>.Transformer((uint64_t)(a1 + 2));
      uint64_t v9 = a2[4];
      *uint64_t v6 = *v8;
      a1[4] = v9;
    }
  }
  else if (v7)
  {
    a1[2] = v7;
    a1[3] = a2[3];
    a1[4] = a2[4];
    swift_bridgeObjectRetain();
    swift_bridgeObjectRetain();
  }
  else
  {
    long long v10 = *v8;
    a1[4] = a2[4];
    *uint64_t v6 = v10;
  }
  uint64_t v11 = *(int *)(a3 + 24);
  uint64_t v12 = (char *)a1 + v11;
  uint64_t v13 = (char *)a2 + v11;
  uint64_t v14 = type metadata accessor for BaseLinearRegressorModel();
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v14 - 8) + 24))(v12, v13, v14);
  return a1;
}

uint64_t initializeWithTake for MLLinearRegressor.Model(uint64_t a1, uint64_t a2, uint64_t a3)
{
  long long v4 = *(_OWORD *)(a2 + 16);
  *(_OWORD *)a1 = *(_OWORD *)a2;
  *(_OWORD *)(a1 + 16) = v4;
  *(void *)(a1 + 32) = *(void *)(a2 + 32);
  uint64_t v5 = *(int *)(a3 + 24);
  uint64_t v6 = a1 + v5;
  uint64_t v7 = a2 + v5;
  uint64_t v8 = type metadata accessor for BaseLinearRegressorModel();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v8 - 8) + 32))(v6, v7, v8);
  return a1;
}

void *assignWithTake for MLLinearRegressor.Model(void *a1, void *a2, uint64_t a3)
{
  uint64_t v6 = a2[1];
  *a1 = *a2;
  a1[1] = v6;
  swift_bridgeObjectRelease();
  uint64_t v7 = a2[2];
  if (!a1[2]) {
    goto LABEL_5;
  }
  if (!v7)
  {
    outlined destroy of FeatureVectorizer<Double>.Transformer((uint64_t)(a1 + 2));
LABEL_5:
    *((_OWORD *)a1 + 1) = *((_OWORD *)a2 + 1);
    a1[4] = a2[4];
    goto LABEL_6;
  }
  a1[2] = v7;
  swift_bridgeObjectRelease();
  uint64_t v8 = a2[4];
  a1[3] = a2[3];
  a1[4] = v8;
  swift_bridgeObjectRelease();
LABEL_6:
  uint64_t v9 = *(int *)(a3 + 24);
  long long v10 = (char *)a1 + v9;
  uint64_t v11 = (char *)a2 + v9;
  uint64_t v12 = type metadata accessor for BaseLinearRegressorModel();
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 40))(v10, v11, v12);
  return a1;
}

uint64_t getEnumTagSinglePayload for MLLinearRegressor.Model(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return MEMORY[0x270FA0340](a1, a2, a3, sub_227148BBC);
}

uint64_t sub_227148BBC(uint64_t a1, uint64_t a2, uint64_t a3)
{
  if (a2 == 0x7FFFFFFF)
  {
    unint64_t v4 = *(void *)(a1 + 8);
    if (v4 >= 0xFFFFFFFF) {
      LODWORD(v4) = -1;
    }
    return (v4 + 1);
  }
  else
  {
    uint64_t v8 = type metadata accessor for BaseLinearRegressorModel();
    uint64_t v9 = a1 + *(int *)(a3 + 24);
    return __swift_getEnumTagSinglePayload(v9, a2, v8);
  }
}

uint64_t storeEnumTagSinglePayload for MLLinearRegressor.Model(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return MEMORY[0x270FA0580](a1, a2, a3, a4, sub_227148C58);
}

uint64_t sub_227148C58(uint64_t result, uint64_t a2, int a3, uint64_t a4)
{
  uint64_t v5 = result;
  if (a3 == 0x7FFFFFFF)
  {
    *(void *)(result + 8) = (a2 - 1);
  }
  else
  {
    uint64_t v7 = type metadata accessor for BaseLinearRegressorModel();
    uint64_t v8 = v5 + *(int *)(a4 + 24);
    return __swift_storeEnumTagSinglePayload(v8, a2, a2, v7);
  }
  return result;
}

uint64_t type metadata accessor for MLLinearRegressor.Model()
{
  uint64_t result = type metadata singleton initialization cache for MLLinearRegressor.Model;
  if (!type metadata singleton initialization cache for MLLinearRegressor.Model) {
    return swift_getSingletonMetadata();
  }
  return result;
}

uint64_t type metadata completion function for MLLinearRegressor.Model()
{
  uint64_t result = type metadata accessor for BaseLinearRegressorModel();
  if (v1 <= 0x3F)
  {
    swift_initStructMetadata();
    return 0;
  }
  return result;
}

void MLLinearRegressor.Model.applied(to:eventHandler:)(uint64_t a1@<X8>)
{
  uint64_t v3 = v1;
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Double>);
  OUTLINED_FUNCTION_0();
  uint64_t v18 = v6;
  MEMORY[0x270FA5388](v7);
  uint64_t v9 = (char *)&v15 - ((v8 + 15) & 0xFFFFFFFFFFFFFFF0);
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DenseMatrix<Double>);
  OUTLINED_FUNCTION_0();
  uint64_t v16 = v11;
  uint64_t v17 = v10;
  MEMORY[0x270FA5388](v10);
  uint64_t v13 = (char *)&v15 - ((v12 + 15) & 0xFFFFFFFFFFFFFFF0);
  if (*(void *)(v3 + 16))
  {
    specialized FeatureVectorizer.Transformer.vectorized(_:includingBias:)();
    if (!v2)
    {
      type metadata accessor for MLLinearRegressor.Model();
      uint64_t v15 = a1;
      uint64_t v19 = BaseLinearRegressorModel.applied(features:eventHandler:)();
      swift_bridgeObjectRetain();
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ContiguousArray<Double>);
      lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type ContiguousArray<Double> and conformance ContiguousArray<A>, &demangling cache variable for type metadata for ContiguousArray<Double>);
      Column.init<A>(name:contents:)();
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<AnyColumn>);
      type metadata accessor for AnyColumn();
      uint64_t v14 = swift_allocObject();
      *(_OWORD *)(v14 + 16) = xmmword_2272CB370;
      Column.eraseToAnyColumn()();
      uint64_t v19 = v14;
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [AnyColumn]);
      lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [AnyColumn] and conformance [A], &demangling cache variable for type metadata for [AnyColumn]);
      DataFrame.init<A>(columns:)();
      (*(void (**)(char *, uint64_t))(v18 + 8))(v9, v5);
      (*(void (**)(char *, uint64_t))(v16 + 8))(v13, v17);
    }
  }
  else
  {
    _assertionFailure(_:_:file:line:flags:)();
    __break(1u);
  }
}

uint64_t protocol witness for Transformer.applied(to:eventHandler:) in conformance MLLinearRegressor.Model(uint64_t a1)
{
  MLLinearRegressor.Model.applied(to:eventHandler:)(a1);
  uint64_t v2 = *(uint64_t (**)(void))(v1 + 8);
  return protocol witness for SupervisedTabularEstimator.fitted(to:validateOn:eventHandler:) in conformance TreeRegressor(v2);
}

unint64_t lazy protocol witness table accessor for type MLLinearRegressor.Model and conformance MLLinearRegressor.Model()
{
  unint64_t result = lazy protocol witness table cache variable for type MLLinearRegressor.Model and conformance MLLinearRegressor.Model;
  if (!lazy protocol witness table cache variable for type MLLinearRegressor.Model and conformance MLLinearRegressor.Model)
  {
    type metadata accessor for MLLinearRegressor.Model();
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type MLLinearRegressor.Model and conformance MLLinearRegressor.Model);
  }
  return result;
}

uint64_t type metadata completion function for Either()
{
  uint64_t result = swift_checkMetadataState();
  if (v1 <= 0x3F)
  {
    uint64_t result = swift_checkMetadataState();
    if (v2 <= 0x3F)
    {
      swift_initEnumMetadataMultiPayload();
      return 0;
    }
  }
  return result;
}

void *initializeBufferWithCopyOfBuffer for Either(void *a1, unsigned __int8 *a2, uint64_t a3)
{
  uint64_t v3 = a1;
  uint64_t v4 = *(void *)(*(void *)(a3 + 16) - 8);
  uint64_t v5 = *(void *)(*(void *)(a3 + 24) - 8);
  if (*(void *)(v5 + 64) <= *(void *)(v4 + 64)) {
    uint64_t v6 = *(void *)(*(void *)(*(void *)(a3 + 16) - 8) + 64);
  }
  else {
    uint64_t v6 = *(void *)(v5 + 64);
  }
  uint64_t v7 = (*(unsigned char *)(v5 + 80) | *(unsigned char *)(v4 + 80));
  if (v7 <= 7
    && (unint64_t)(v6 + 1) <= 0x18
    && ((*(_DWORD *)(v5 + 80) | *(_DWORD *)(v4 + 80)) & 0x100000) == 0)
  {
    unsigned int v11 = a2[v6];
    unsigned int v12 = v11 - 2;
    if (v11 >= 2)
    {
      if (v6 <= 3) {
        uint64_t v13 = v6;
      }
      else {
        uint64_t v13 = 4;
      }
      switch(v13)
      {
        case 1:
          int v14 = *a2;
          goto LABEL_21;
        case 2:
          int v14 = *(unsigned __int16 *)a2;
          goto LABEL_21;
        case 3:
          int v14 = *(unsigned __int16 *)a2 | (a2[2] << 16);
          goto LABEL_21;
        case 4:
          int v14 = *(_DWORD *)a2;
LABEL_21:
          int v15 = (v14 | (v12 << (8 * v6))) + 2;
          unsigned int v11 = v14 + 2;
          if (v6 < 4) {
            unsigned int v11 = v15;
          }
          break;
        default:
          break;
      }
    }
    if (v11 == 1)
    {
      (*(void (**)(void *))(v5 + 16))(a1);
      *((unsigned char *)v3 + v6) = 1;
    }
    else
    {
      (*(void (**)(void *))(v4 + 16))(a1);
      *((unsigned char *)v3 + v6) = 0;
    }
  }
  else
  {
    uint64_t v10 = *(void *)a2;
    *uint64_t v3 = *(void *)a2;
    uint64_t v3 = (void *)(v10 + ((v7 + 16) & ~v7));
    swift_retain();
  }
  return v3;
}

uint64_t destroy for Either(unsigned __int8 *a1, uint64_t a2)
{
  uint64_t v2 = *(void *)(a2 + 24) - 8;
  uint64_t v3 = *(void *)v2;
  unint64_t v4 = *(void *)(*(void *)v2 + 64);
  if (v4 <= *(void *)(*(void *)(*(void *)(a2 + 16) - 8) + 64)) {
    unint64_t v4 = *(void *)(*(void *)(*(void *)(a2 + 16) - 8) + 64);
  }
  unsigned int v5 = a1[v4];
  unsigned int v6 = v5 - 2;
  if (v5 >= 2)
  {
    if (v4 <= 3) {
      uint64_t v7 = v4;
    }
    else {
      uint64_t v7 = 4;
    }
    switch(v7)
    {
      case 1:
        int v8 = *a1;
        goto LABEL_12;
      case 2:
        int v8 = *(unsigned __int16 *)a1;
        goto LABEL_12;
      case 3:
        int v8 = *(unsigned __int16 *)a1 | (a1[2] << 16);
        goto LABEL_12;
      case 4:
        int v8 = *(_DWORD *)a1;
LABEL_12:
        int v9 = (v8 | (v6 << (8 * v4))) + 2;
        unsigned int v5 = v8 + 2;
        if (v4 < 4) {
          unsigned int v5 = v9;
        }
        break;
      default:
        break;
    }
  }
  if (v5 == 1) {
    uint64_t v10 = v3;
  }
  else {
    uint64_t v10 = *(void *)(*(void *)(a2 + 16) - 8);
  }
  return (*(uint64_t (**)(void))(v10 + 8))();
}

uint64_t initializeWithCopy for Either(uint64_t a1, unsigned __int8 *a2, uint64_t a3)
{
  uint64_t v4 = *(void *)(a3 + 24);
  uint64_t v5 = *(void *)(*(void *)(a3 + 16) - 8);
  if (*(void *)(*(void *)(v4 - 8) + 64) <= *(void *)(v5 + 64)) {
    uint64_t v6 = *(void *)(*(void *)(*(void *)(a3 + 16) - 8) + 64);
  }
  else {
    uint64_t v6 = *(void *)(*(void *)(v4 - 8) + 64);
  }
  unsigned int v7 = a2[v6];
  unsigned int v8 = v7 - 2;
  if (v7 >= 2)
  {
    if (v6 <= 3) {
      uint64_t v9 = v6;
    }
    else {
      uint64_t v9 = 4;
    }
    switch(v9)
    {
      case 1:
        int v10 = *a2;
        goto LABEL_13;
      case 2:
        int v10 = *(unsigned __int16 *)a2;
        goto LABEL_13;
      case 3:
        int v10 = *(unsigned __int16 *)a2 | (a2[2] << 16);
        goto LABEL_13;
      case 4:
        int v10 = *(_DWORD *)a2;
LABEL_13:
        int v11 = (v10 | (v8 << (8 * v6))) + 2;
        unsigned int v7 = v10 + 2;
        if (v6 < 4) {
          unsigned int v7 = v11;
        }
        break;
      default:
        break;
    }
  }
  BOOL v12 = v7 == 1;
  if (v7 == 1) {
    uint64_t v5 = *(void *)(v4 - 8);
  }
  (*(void (**)(uint64_t))(v5 + 16))(a1);
  *(unsigned char *)(a1 + v6) = v12;
  return a1;
}

unsigned __int8 *assignWithCopy for Either(unsigned __int8 *a1, unsigned __int8 *a2, uint64_t a3)
{
  if (a1 != a2)
  {
    uint64_t v5 = *(void *)(a3 + 16);
    uint64_t v6 = *(void *)(a3 + 24);
    uint64_t v7 = *(void *)(v5 - 8);
    uint64_t v8 = *(void *)(v6 - 8);
    if (*(void *)(v8 + 64) <= *(void *)(v7 + 64)) {
      uint64_t v9 = *(void *)(*(void *)(*(void *)(a3 + 16) - 8) + 64);
    }
    else {
      uint64_t v9 = *(void *)(*(void *)(v6 - 8) + 64);
    }
    unsigned int v10 = a1[v9];
    unsigned int v11 = v10 - 2;
    if (v10 >= 2)
    {
      if (v9 <= 3) {
        uint64_t v12 = v9;
      }
      else {
        uint64_t v12 = 4;
      }
      switch(v12)
      {
        case 1:
          int v13 = *a1;
          goto LABEL_14;
        case 2:
          int v13 = *(unsigned __int16 *)a1;
          goto LABEL_14;
        case 3:
          int v13 = *(unsigned __int16 *)a1 | (a1[2] << 16);
          goto LABEL_14;
        case 4:
          int v13 = *(_DWORD *)a1;
LABEL_14:
          int v14 = (v13 | (v11 << (8 * v9))) + 2;
          unsigned int v10 = v13 + 2;
          if (v9 < 4) {
            unsigned int v10 = v14;
          }
          break;
        default:
          break;
      }
    }
    if (v10 == 1) {
      uint64_t v15 = *(void *)(v6 - 8);
    }
    else {
      uint64_t v15 = *(void *)(*(void *)(a3 + 16) - 8);
    }
    if (v10 == 1) {
      uint64_t v16 = *(void *)(a3 + 24);
    }
    else {
      uint64_t v16 = *(void *)(a3 + 16);
    }
    (*(void (**)(unsigned __int8 *, uint64_t))(v15 + 8))(a1, v16);
    unsigned int v17 = a2[v9];
    unsigned int v18 = v17 - 2;
    if (v17 >= 2)
    {
      if (v9 <= 3) {
        uint64_t v19 = v9;
      }
      else {
        uint64_t v19 = 4;
      }
      switch(v19)
      {
        case 1:
          int v20 = *a2;
          goto LABEL_31;
        case 2:
          int v20 = *(unsigned __int16 *)a2;
          goto LABEL_31;
        case 3:
          int v20 = *(unsigned __int16 *)a2 | (a2[2] << 16);
          goto LABEL_31;
        case 4:
          int v20 = *(_DWORD *)a2;
LABEL_31:
          int v21 = (v20 | (v18 << (8 * v9))) + 2;
          unsigned int v17 = v20 + 2;
          if (v9 < 4) {
            unsigned int v17 = v21;
          }
          break;
        default:
          break;
      }
    }
    BOOL v22 = v17 == 1;
    if (v17 == 1) {
      uint64_t v23 = v8;
    }
    else {
      uint64_t v23 = v7;
    }
    if (v17 == 1) {
      uint64_t v24 = v6;
    }
    else {
      uint64_t v24 = v5;
    }
    (*(void (**)(unsigned __int8 *, unsigned __int8 *, uint64_t))(v23 + 16))(a1, a2, v24);
    a1[v9] = v22;
  }
  return a1;
}

uint64_t initializeWithTake for Either(uint64_t a1, unsigned __int8 *a2, uint64_t a3)
{
  uint64_t v4 = *(void *)(a3 + 24);
  uint64_t v5 = *(void *)(*(void *)(a3 + 16) - 8);
  if (*(void *)(*(void *)(v4 - 8) + 64) <= *(void *)(v5 + 64)) {
    uint64_t v6 = *(void *)(*(void *)(*(void *)(a3 + 16) - 8) + 64);
  }
  else {
    uint64_t v6 = *(void *)(*(void *)(v4 - 8) + 64);
  }
  unsigned int v7 = a2[v6];
  unsigned int v8 = v7 - 2;
  if (v7 >= 2)
  {
    if (v6 <= 3) {
      uint64_t v9 = v6;
    }
    else {
      uint64_t v9 = 4;
    }
    switch(v9)
    {
      case 1:
        int v10 = *a2;
        goto LABEL_13;
      case 2:
        int v10 = *(unsigned __int16 *)a2;
        goto LABEL_13;
      case 3:
        int v10 = *(unsigned __int16 *)a2 | (a2[2] << 16);
        goto LABEL_13;
      case 4:
        int v10 = *(_DWORD *)a2;
LABEL_13:
        int v11 = (v10 | (v8 << (8 * v6))) + 2;
        unsigned int v7 = v10 + 2;
        if (v6 < 4) {
          unsigned int v7 = v11;
        }
        break;
      default:
        break;
    }
  }
  BOOL v12 = v7 == 1;
  if (v7 == 1) {
    uint64_t v5 = *(void *)(v4 - 8);
  }
  (*(void (**)(uint64_t))(v5 + 32))(a1);
  *(unsigned char *)(a1 + v6) = v12;
  return a1;
}

unsigned __int8 *assignWithTake for Either(unsigned __int8 *a1, unsigned __int8 *a2, uint64_t a3)
{
  if (a1 != a2)
  {
    uint64_t v5 = *(void *)(a3 + 16);
    uint64_t v6 = *(void *)(a3 + 24);
    uint64_t v7 = *(void *)(v5 - 8);
    uint64_t v8 = *(void *)(v6 - 8);
    if (*(void *)(v8 + 64) <= *(void *)(v7 + 64)) {
      uint64_t v9 = *(void *)(*(void *)(*(void *)(a3 + 16) - 8) + 64);
    }
    else {
      uint64_t v9 = *(void *)(*(void *)(v6 - 8) + 64);
    }
    unsigned int v10 = a1[v9];
    unsigned int v11 = v10 - 2;
    if (v10 >= 2)
    {
      if (v9 <= 3) {
        uint64_t v12 = v9;
      }
      else {
        uint64_t v12 = 4;
      }
      switch(v12)
      {
        case 1:
          int v13 = *a1;
          goto LABEL_14;
        case 2:
          int v13 = *(unsigned __int16 *)a1;
          goto LABEL_14;
        case 3:
          int v13 = *(unsigned __int16 *)a1 | (a1[2] << 16);
          goto LABEL_14;
        case 4:
          int v13 = *(_DWORD *)a1;
LABEL_14:
          int v14 = (v13 | (v11 << (8 * v9))) + 2;
          unsigned int v10 = v13 + 2;
          if (v9 < 4) {
            unsigned int v10 = v14;
          }
          break;
        default:
          break;
      }
    }
    if (v10 == 1) {
      uint64_t v15 = *(void *)(v6 - 8);
    }
    else {
      uint64_t v15 = *(void *)(*(void *)(a3 + 16) - 8);
    }
    if (v10 == 1) {
      uint64_t v16 = *(void *)(a3 + 24);
    }
    else {
      uint64_t v16 = *(void *)(a3 + 16);
    }
    (*(void (**)(unsigned __int8 *, uint64_t))(v15 + 8))(a1, v16);
    unsigned int v17 = a2[v9];
    unsigned int v18 = v17 - 2;
    if (v17 >= 2)
    {
      if (v9 <= 3) {
        uint64_t v19 = v9;
      }
      else {
        uint64_t v19 = 4;
      }
      switch(v19)
      {
        case 1:
          int v20 = *a2;
          goto LABEL_31;
        case 2:
          int v20 = *(unsigned __int16 *)a2;
          goto LABEL_31;
        case 3:
          int v20 = *(unsigned __int16 *)a2 | (a2[2] << 16);
          goto LABEL_31;
        case 4:
          int v20 = *(_DWORD *)a2;
LABEL_31:
          int v21 = (v20 | (v18 << (8 * v9))) + 2;
          unsigned int v17 = v20 + 2;
          if (v9 < 4) {
            unsigned int v17 = v21;
          }
          break;
        default:
          break;
      }
    }
    BOOL v22 = v17 == 1;
    if (v17 == 1) {
      uint64_t v23 = v8;
    }
    else {
      uint64_t v23 = v7;
    }
    if (v17 == 1) {
      uint64_t v24 = v6;
    }
    else {
      uint64_t v24 = v5;
    }
    (*(void (**)(unsigned __int8 *, unsigned __int8 *, uint64_t))(v23 + 32))(a1, a2, v24);
    a1[v9] = v22;
  }
  return a1;
}

uint64_t getEnumTagSinglePayload for Either(unsigned __int16 *a1, unsigned int a2, uint64_t a3)
{
  unint64_t v3 = *(void *)(*(void *)(*(void *)(a3 + 24) - 8) + 64);
  if (v3 <= *(void *)(*(void *)(*(void *)(a3 + 16) - 8) + 64)) {
    unint64_t v3 = *(void *)(*(void *)(*(void *)(a3 + 16) - 8) + 64);
  }
  if (!a2) {
    return 0;
  }
  if (a2 < 0xFF) {
    goto LABEL_22;
  }
  unint64_t v4 = v3 + 1;
  char v5 = 8 * (v3 + 1);
  if ((v3 + 1) <= 3)
  {
    unsigned int v8 = ((a2 + ~(-1 << v5) - 254) >> v5) + 1;
    if (HIWORD(v8))
    {
      int v6 = *(_DWORD *)((char *)a1 + v4);
      if (!v6) {
        goto LABEL_22;
      }
      goto LABEL_14;
    }
    if (v8 > 0xFF)
    {
      int v6 = *(unsigned __int16 *)((char *)a1 + v4);
      if (!*(unsigned __int16 *)((char *)a1 + v4)) {
        goto LABEL_22;
      }
      goto LABEL_14;
    }
    if (v8 < 2)
    {
LABEL_22:
      unsigned int v10 = *((unsigned __int8 *)a1 + v3);
      if (v10 >= 2) {
        return (v10 ^ 0xFF) + 1;
      }
      else {
        return 0;
      }
    }
  }
  int v6 = *((unsigned __int8 *)a1 + v4);
  if (!*((unsigned char *)a1 + v4)) {
    goto LABEL_22;
  }
LABEL_14:
  int v9 = (v6 - 1) << v5;
  if (v4 > 3) {
    int v9 = 0;
  }
  if (v4)
  {
    if (v4 > 3) {
      LODWORD(v4) = 4;
    }
    switch((int)v4)
    {
      case 2:
        LODWORD(v4) = *a1;
        break;
      case 3:
        LODWORD(v4) = *a1 | (*((unsigned __int8 *)a1 + 2) << 16);
        break;
      case 4:
        LODWORD(v4) = *(_DWORD *)a1;
        break;
      default:
        LODWORD(v4) = *(unsigned __int8 *)a1;
        break;
    }
  }
  return (v4 | v9) + 255;
}

void storeEnumTagSinglePayload for Either(char *a1, unsigned int a2, unsigned int a3, uint64_t a4)
{
  unint64_t v5 = *(void *)(*(void *)(*(void *)(a4 + 16) - 8) + 64);
  if (*(void *)(*(void *)(*(void *)(a4 + 24) - 8) + 64) > v5) {
    unint64_t v5 = *(void *)(*(void *)(*(void *)(a4 + 24) - 8) + 64);
  }
  size_t v6 = v5 + 1;
  char v7 = 8 * (v5 + 1);
  if (a3 < 0xFF)
  {
    int v8 = 0;
  }
  else if (v6 <= 3)
  {
    unsigned int v11 = ((a3 + ~(-1 << v7) - 254) >> v7) + 1;
    if (HIWORD(v11))
    {
      int v8 = 4;
    }
    else if (v11 >= 0x100)
    {
      int v8 = 2;
    }
    else
    {
      int v8 = v11 > 1;
    }
  }
  else
  {
    int v8 = 1;
  }
  if (a2 > 0xFE)
  {
    unsigned int v9 = a2 - 255;
    if (v6 < 4)
    {
      int v10 = (v9 >> v7) + 1;
      if (v5 != -1)
      {
        int v12 = v9 & ~(-1 << v7);
        bzero(a1, v6);
        if (v6 == 3)
        {
          *(_WORD *)a1 = v12;
          a1[2] = BYTE2(v12);
        }
        else if (v6 == 2)
        {
          *(_WORD *)a1 = v12;
        }
        else
        {
          *a1 = v12;
        }
      }
    }
    else
    {
      bzero(a1, v5 + 1);
      *(_DWORD *)a1 = v9;
      int v10 = 1;
    }
    switch(v8)
    {
      case 1:
        a1[v6] = v10;
        break;
      case 2:
        *(_WORD *)&a1[v6] = v10;
        break;
      case 3:
LABEL_34:
        __break(1u);
        JUMPOUT(0x22714A040);
      case 4:
        *(_DWORD *)&a1[v6] = v10;
        break;
      default:
        return;
    }
  }
  else
  {
    switch(v8)
    {
      case 1:
        a1[v6] = 0;
        if (!a2) {
          return;
        }
        goto LABEL_23;
      case 2:
        *(_WORD *)&a1[v6] = 0;
        goto LABEL_22;
      case 3:
        goto LABEL_34;
      case 4:
        *(_DWORD *)&a1[v6] = 0;
        if (!a2) {
          return;
        }
        goto LABEL_23;
      default:
LABEL_22:
        if (a2) {
LABEL_23:
        }
          a1[v5] = -(char)a2;
        break;
    }
  }
}

uint64_t getEnumTag for Either(unsigned __int8 *a1, uint64_t a2)
{
  unint64_t v2 = *(void *)(*(void *)(*(void *)(a2 + 24) - 8) + 64);
  if (v2 <= *(void *)(*(void *)(*(void *)(a2 + 16) - 8) + 64)) {
    unint64_t v2 = *(void *)(*(void *)(*(void *)(a2 + 16) - 8) + 64);
  }
  uint64_t v3 = a1[v2];
  int v4 = v3 - 2;
  if (v3 >= 2)
  {
    if (v2 <= 3) {
      uint64_t v5 = v2;
    }
    else {
      uint64_t v5 = 4;
    }
    switch(v5)
    {
      case 1:
        int v6 = *a1;
        goto LABEL_12;
      case 2:
        int v6 = *(unsigned __int16 *)a1;
        goto LABEL_12;
      case 3:
        int v6 = *(unsigned __int16 *)a1 | (a1[2] << 16);
        goto LABEL_12;
      case 4:
        int v6 = *(_DWORD *)a1;
LABEL_12:
        unsigned int v7 = (v6 | (v4 << (8 * v2))) + 2;
        LODWORD(v3) = v6 + 2;
        if (v2 >= 4) {
          uint64_t v3 = v3;
        }
        else {
          uint64_t v3 = v7;
        }
        break;
      default:
        return v3;
    }
  }
  return v3;
}

void destructiveInjectEnumTag for Either(unsigned char *a1, unsigned int a2, uint64_t a3)
{
  if (a2 > 1)
  {
    uint64_t v6 = *(void *)(*(void *)(a3 + 24) - 8);
    if (*(void *)(v6 + 64) <= *(void *)(*(void *)(*(void *)(a3 + 16) - 8) + 64)) {
      size_t v7 = *(void *)(*(void *)(*(void *)(a3 + 16) - 8) + 64);
    }
    else {
      size_t v7 = *(void *)(v6 + 64);
    }
    unsigned int v8 = a2 - 2;
    if (v7 < 4)
    {
      unsigned int v9 = v8 >> (8 * v7);
      int v10 = v8 & ~(-1 << (8 * v7));
      a1[v7] = v9 + 2;
      bzero(a1, v7);
      if (v7 == 3)
      {
        *(_WORD *)a1 = v10;
        a1[2] = BYTE2(v10);
      }
      else if (v7 == 2)
      {
        *(_WORD *)a1 = v10;
      }
      else
      {
        *a1 = v10;
      }
    }
    else
    {
      a1[v7] = 2;
      bzero(a1, v7);
      *(_DWORD *)a1 = v8;
    }
  }
  else
  {
    uint64_t v4 = *(void *)(*(void *)(a3 + 24) - 8);
    unint64_t v5 = *(void *)(*(void *)(*(void *)(a3 + 16) - 8) + 64);
    if (*(void *)(v4 + 64) > v5) {
      unint64_t v5 = *(void *)(v4 + 64);
    }
    a1[v5] = a2;
  }
}

uint64_t type metadata accessor for Either()
{
  return __swift_instantiateGenericMetadata();
}

uint64_t NLModel.write(to:defaultName:metadata:)(uint64_t a1, uint64_t a2, void *a3, uint64_t *a4)
{
  uint64_t v9 = type metadata accessor for URL();
  OUTLINED_FUNCTION_0();
  uint64_t v27 = v10;
  MEMORY[0x270FA5388](v11);
  OUTLINED_FUNCTION_3_0();
  uint64_t v14 = v13 - v12;
  uint64_t v15 = *a4;
  uint64_t v16 = a4[2];
  uint64_t v25 = a4[3];
  uint64_t v26 = a4[1];
  uint64_t v23 = a4[5];
  uint64_t v24 = a4[4];
  uint64_t v17 = a4[6];
  uint64_t v18 = a4[7];
  uint64_t v19 = a4[8];
  uint64_t v21 = v18;
  uint64_t v22 = v17;
  uint64_t result = static _ValidationUtilities.validateWriteLocation(atURL:defaultName:fileExtension:)(a1, a2, a3, 0x6C65646F6D6C6DLL, (void *)0xE700000000000000, v14);
  if (!v4)
  {
    v28[0] = v15;
    v28[1] = v26;
    void v28[2] = v16;
    v28[3] = v25;
    v28[4] = v24;
    v28[5] = v23;
    v28[6] = v22;
    v28[7] = v21;
    v28[8] = v19;
    NLModel.writeModel(to:metadata:)(v14, (uint64_t)v28);
    return (*(uint64_t (**)(uint64_t, uint64_t))(v27 + 8))(v14, v9);
  }
  return result;
}

uint64_t NLModel.write(toFile:defaultName:metadata:)(uint64_t a1, void *a2, uint64_t a3, void *a4, uint64_t *a5)
{
  uint64_t v11 = type metadata accessor for URL();
  OUTLINED_FUNCTION_0();
  uint64_t v28 = v12;
  MEMORY[0x270FA5388](v13);
  OUTLINED_FUNCTION_3_0();
  uint64_t v16 = v15 - v14;
  uint64_t v17 = a5[1];
  uint64_t v26 = a5[2];
  uint64_t v27 = *a5;
  uint64_t v24 = a5[4];
  uint64_t v25 = a5[3];
  uint64_t v22 = a5[6];
  uint64_t v23 = a5[5];
  uint64_t v18 = a5[7];
  uint64_t v19 = a5[8];
  uint64_t v21 = v18;
  uint64_t result = static _ValidationUtilities.validateWriteLocation(atPath:defaultName:)(a1, a2, a3, a4);
  if (!v5)
  {
    v29[0] = v27;
    v29[1] = v17;
    void v29[2] = v26;
    v29[3] = v25;
    void v29[4] = v24;
    v29[5] = v23;
    v29[6] = v22;
    v29[7] = v21;
    v29[8] = v19;
    NLModel.write(to:defaultName:metadata:)(v16, a3, a4, v29);
    return (*(uint64_t (**)(uint64_t, uint64_t))(v28 + 8))(v16, v11);
  }
  return result;
}

MLModel __swiftcall __spoils<CF,ZF,NF,VF,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13,X14,X15,X16,X17,X21,Q0,Q1,Q2,Q3,Q4,Q5,Q6,Q7,Q16,Q17,Q18,Q19,Q20,Q21,Q22,Q23,Q24,Q25,Q26,Q27,Q28,Q29,Q30,Q31> NLModel.asCoreML()()
{
  v54[1] = *(id *)MEMORY[0x263EF8340];
  type metadata accessor for UUID();
  OUTLINED_FUNCTION_0();
  uint64_t v49 = v1;
  uint64_t v50 = v0;
  MEMORY[0x270FA5388](v0);
  OUTLINED_FUNCTION_3_0();
  uint64_t v4 = v3 - v2;
  uint64_t v5 = type metadata accessor for URL();
  OUTLINED_FUNCTION_0();
  uint64_t v52 = v6;
  uint64_t v8 = MEMORY[0x270FA5388](v7);
  uint64_t v10 = (char *)&v46 - ((v9 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v11 = MEMORY[0x270FA5388](v8);
  uint64_t v13 = (char *)&v46 - v12;
  uint64_t v14 = MEMORY[0x270FA5388](v11);
  uint64_t v15 = MEMORY[0x270FA5388](v14);
  uint64_t v17 = (char *)&v46 - v16;
  MEMORY[0x270FA5388](v15);
  uint64_t v19 = (char *)&v46 - v18;
  id v20 = objc_msgSend(self, sel_defaultManager);
  NSFileManager.createTemporaryModelDirectory()();
  if (v21)
  {
  }
  else
  {
    uint64_t v46 = 0;
    uint64_t v47 = v10;
    unint64_t v48 = v13;
    NSFileManager.temporaryModelDirectory.getter();
    UUID.init()();
    UUID.uuidString.getter();
    uint64_t v53 = v5;
    (*(void (**)(uint64_t, uint64_t))(v49 + 8))(v4, v50);
    URL.appendingPathComponent(_:)();
    swift_bridgeObjectRelease();
    URL.appendingPathExtension(_:)();
    uint64_t v22 = v52 + 8;
    uint64_t v23 = *(void (**)(void))(v52 + 8);
    OUTLINED_FUNCTION_2_38();
    v23();
    URL._bridgeToObjectiveC()(v24);
    uint64_t v26 = v25;
    uint64_t v27 = Dictionary.init(dictionaryLiteral:)();
    v54[0] = 0;
    unsigned __int8 v28 = outlined bridged method (mnbnnn) of @objc NLModel.writeMLModel(to:options:)((uint64_t)v26, v27, (uint64_t)v54, v51);

    id v29 = v54[0];
    if (v28)
    {
      uint64_t v50 = v22;
      uint64_t v51 = v23;
      uint64_t v30 = self;
      id v31 = v29;
      URL._bridgeToObjectiveC()(v32);
      uint64_t v34 = v33;
      v54[0] = 0;
      id v35 = objc_msgSend(v30, sel_compileModelAtURL_error_, v33, v54);

      id v36 = v54[0];
      if (v35)
      {
        uint64_t v37 = v48;
        static URL._unconditionallyBridgeFromObjectiveC(_:)();
        id v38 = v36;

        type metadata accessor for NSAttributedString(0, (unint64_t *)&lazy cache variable for type metadata for MLModel);
        uint64_t v4 = (uint64_t)v47;
        (*(void (**)(char *, char *, uint64_t))(v52 + 16))(v47, v37, v53);
        uint64_t v39 = v46;
        id v40 = @nonobjc MLModel.__allocating_init(contentsOf:)(v4);
        uint64_t v41 = v51;
        if (!v39) {
          uint64_t v4 = (uint64_t)v40;
        }
        OUTLINED_FUNCTION_1_30();
        v41();
        $defer #1 () in CMLModel.compile()(v20);

        OUTLINED_FUNCTION_1_30();
        v41();
        OUTLINED_FUNCTION_1_30();
        v41();
      }
      else
      {
        id v43 = v54[0];
        _convertNSErrorToError(_:)();

        swift_willThrow();
        $defer #1 () in CMLModel.compile()(v20);

        uint64_t v4 = v53;
        unint64_t v44 = v51;
        ((void (*)(char *, uint64_t))v51)(v17, v53);
        ((void (*)(char *, uint64_t))v44)(v19, v4);
      }
    }
    else
    {
      id v42 = v54[0];
      uint64_t v4 = _convertNSErrorToError(_:)();

      swift_willThrow();
      OUTLINED_FUNCTION_2_38();
      v23();
      OUTLINED_FUNCTION_2_38();
      v23();
    }
  }
  return (MLModel)v4;
}

id @nonobjc MLModel.__allocating_init(contentsOf:)(uint64_t a1)
{
  uint64_t v13 = (NSURL *)*MEMORY[0x263EF8340];
  URL._bridgeToObjectiveC()(v13);
  uint64_t v3 = v2;
  id v12 = 0;
  id v4 = objc_msgSend((id)swift_getObjCClassFromMetadata(), sel_modelWithContentsOfURL_error_, v2, &v12);

  id v5 = v12;
  if (v4)
  {
    uint64_t v6 = type metadata accessor for URL();
    uint64_t v7 = *(void (**)(uint64_t, uint64_t))(*(void *)(v6 - 8) + 8);
    id v8 = v5;
    v7(a1, v6);
  }
  else
  {
    id v9 = v12;
    _convertNSErrorToError(_:)();

    swift_willThrow();
    uint64_t v10 = type metadata accessor for URL();
    (*(void (**)(uint64_t, uint64_t))(*(void *)(v10 - 8) + 8))(a1, v10);
  }
  return v4;
}

id NLModel.writeModel(to:metadata:)(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = v2;
  id v4 = (NSURL *)*MEMORY[0x263EF8340];
  uint64_t v22 = *MEMORY[0x263EF8340];
  id v5 = *(void **)(a2 + 8);
  if (v5)
  {
    uint64_t v6 = *(void *)(a2 + 64);
    long long v15 = *(_OWORD *)(a2 + 32);
    long long v16 = *(_OWORD *)(a2 + 48);
    long long v14 = *(_OWORD *)(a2 + 16);
    uint64_t v7 = *(void **)a2;
    type metadata accessor for NSAttributedString(0, &lazy cache variable for type metadata for NLModel);
    v17[0] = v7;
    v17[1] = v5;
    long long v18 = v14;
    long long v19 = v15;
    long long v20 = v16;
    uint64_t v21 = v6;
    id v5 = (void *)static NLModel.buildMetadataOptions(_:)((uint64_t *)v17);
  }
  URL._bridgeToObjectiveC()(v4);
  id v9 = v8;
  if (v5)
  {
    v10.super.Class isa = Dictionary._bridgeToObjectiveC()().super.isa;
    swift_bridgeObjectRelease();
  }
  else
  {
    v10.super.Class isa = 0;
  }
  v17[0] = 0;
  unsigned int v11 = objc_msgSend(v3, sel_writeMLModelToURL_options_error_, v9, v10.super.isa, v17, v14, v15, v16);

  if (v11) {
    return v17[0];
  }
  id v13 = v17[0];
  _convertNSErrorToError(_:)();

  return (id)swift_willThrow();
}

uint64_t static NLModel.buildMetadataOptions(_:)(uint64_t *a1)
{
  uint64_t v2 = *a1;
  uint64_t v1 = a1[1];
  uint64_t v4 = a1[2];
  uint64_t v3 = a1[3];
  uint64_t v5 = a1[5];
  uint64_t v15 = a1[4];
  uint64_t v7 = a1[6];
  uint64_t v6 = a1[7];
  uint64_t v8 = a1[8];
  uint64_t v20 = MEMORY[0x263F8EE80];
  static String._unconditionallyBridgeFromObjectiveC(_:)();
  uint64_t v9 = MEMORY[0x263F8D310];
  AnyHashable.init<A>(_:)();
  uint64_t v18 = v9;
  uint64_t v16 = v4;
  uint64_t v17 = v3;
  swift_bridgeObjectRetain();
  specialized Dictionary.subscript.setter((uint64_t)&v16, (uint64_t)v19);
  uint64_t v16 = static String._unconditionallyBridgeFromObjectiveC(_:)();
  uint64_t v17 = v10;
  AnyHashable.init<A>(_:)();
  uint64_t v18 = v9;
  uint64_t v16 = v7;
  uint64_t v17 = v6;
  swift_bridgeObjectRetain();
  specialized Dictionary.subscript.setter((uint64_t)&v16, (uint64_t)v19);
  uint64_t v16 = static String._unconditionallyBridgeFromObjectiveC(_:)();
  uint64_t v17 = v11;
  AnyHashable.init<A>(_:)();
  uint64_t v18 = v9;
  uint64_t v16 = v2;
  uint64_t v17 = v1;
  swift_bridgeObjectRetain();
  specialized Dictionary.subscript.setter((uint64_t)&v16, (uint64_t)v19);
  if (v5)
  {
    uint64_t v16 = static String._unconditionallyBridgeFromObjectiveC(_:)();
    uint64_t v17 = v12;
    swift_bridgeObjectRetain();
    AnyHashable.init<A>(_:)();
    uint64_t v18 = v9;
    uint64_t v16 = v15;
    uint64_t v17 = v5;
    specialized Dictionary.subscript.setter((uint64_t)&v16, (uint64_t)v19);
  }
  if (v8)
  {
    uint64_t v16 = static String._unconditionallyBridgeFromObjectiveC(_:)();
    uint64_t v17 = v13;
    swift_bridgeObjectRetain();
    AnyHashable.init<A>(_:)();
    uint64_t v18 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String : String]);
    uint64_t v16 = v8;
    specialized Dictionary.subscript.setter((uint64_t)&v16, (uint64_t)v19);
  }
  return v20;
}

id outlined bridged method (mnbnnn) of @objc NLModel.writeMLModel(to:options:)(uint64_t a1, uint64_t a2, uint64_t a3, void *a4)
{
  Class isa = Dictionary._bridgeToObjectiveC()().super.isa;
  swift_bridgeObjectRelease();
  id v8 = objc_msgSend(a4, sel_writeMLModelToURL_options_error_, a1, isa, a3);

  return v8;
}

uint64_t _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lF11TabularData0D5FrameV_s5NeverO8CreateML24MLRandomForestClassifierV15ModelParametersV010ValidationD0OTg503_s8g4ML24ijk3V15lm76V13configuration10validationAE0A12MLComponents24BoostedTreeConfigurationV_11c7Data0O5e12VSgtcfcAE010N21O0OAMcAPmcfu_ApMcfu0_AOXMtTf1ncn_n@<X0>(uint64_t a1@<X0>, uint64_t a2@<X8>)
{
  uint64_t v4 = type metadata accessor for DataFrame();
  uint64_t v5 = *(void *)(v4 - 8);
  MEMORY[0x270FA5388](v4);
  uint64_t v7 = (char *)&v16 - ((v6 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
  MEMORY[0x270FA5388](v8 - 8);
  uint64_t v10 = (char *)&v16 - ((v9 + 15) & 0xFFFFFFFFFFFFFFF0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(a1, (uint64_t)v10, &demangling cache variable for type metadata for DataFrame?);
  if (__swift_getEnumTagSinglePayload((uint64_t)v10, 1, v4) == 1)
  {
    uint64_t v11 = type metadata accessor for MLRandomForestClassifier.ModelParameters.ValidationData();
    uint64_t v12 = a2;
    uint64_t v13 = 1;
  }
  else
  {
    (*(void (**)(char *, char *, uint64_t))(v5 + 32))(v7, v10, v4);
    (*(void (**)(uint64_t, char *, uint64_t))(v5 + 16))(a2, v7, v4);
    uint64_t v14 = type metadata accessor for MLRandomForestClassifier.ModelParameters.ValidationData();
    swift_storeEnumTagMultiPayload();
    (*(void (**)(char *, uint64_t))(v5 + 8))(v7, v4);
    uint64_t v12 = a2;
    uint64_t v13 = 0;
    uint64_t v11 = v14;
  }
  return __swift_storeEnumTagSinglePayload(v12, v13, 1, v11);
}

uint64_t MLRandomForestClassifier.ModelParameters.validationData.getter@<X0>(uint64_t a1@<X8>)
{
  type metadata accessor for MLRandomForestClassifier.ModelParameters.ValidationData();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v3);
  OUTLINED_FUNCTION_3_0();
  uint64_t v6 = v5 - v4;
  uint64_t result = outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v1, (uint64_t)&v8, &demangling cache variable for type metadata for Any?);
  if (v9)
  {
    outlined init with take of Any(&v8, &v10);
    swift_dynamicCast();
    MLRandomForestClassifier.ModelParameters.ValidationData.asTable()(a1);
    return outlined destroy of MLRandomForestClassifier.ModelParameters.ValidationData(v6);
  }
  else
  {
    __break(1u);
  }
  return result;
}

uint64_t key path getter for MLRandomForestClassifier.ModelParameters.validationData : MLRandomForestClassifier.ModelParameters@<X0>(uint64_t a1@<X8>)
{
  uint64_t result = MLRandomForestClassifier.ModelParameters.validationData.getter((uint64_t)&v4);
  char v3 = v5;
  *(void *)a1 = v4;
  *(unsigned char *)(a1 + 8) = v3;
  return result;
}

uint64_t key path setter for MLRandomForestClassifier.ModelParameters.validationData : MLRandomForestClassifier.ModelParameters(uint64_t a1)
{
  unsigned __int8 v1 = *(unsigned char *)(a1 + 8);
  id v3 = *(id *)a1;
  unsigned __int8 v4 = v1;
  outlined copy of MLDataTable?(v3, v1);
  return MLRandomForestClassifier.ModelParameters.validationData.setter((uint64_t)&v3);
}

uint64_t MLRandomForestClassifier.ModelParameters.validationData.setter(uint64_t a1)
{
  uint64_t v2 = v1;
  type metadata accessor for MLRandomForestClassifier.ModelParameters.ValidationData();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v4);
  OUTLINED_FUNCTION_3_0();
  uint64_t v7 = v6 - v5;
  long long v8 = *(void **)a1;
  int v9 = *(unsigned __int8 *)(a1 + 8);
  v13[3] = v10;
  boxed_opaque_existential_0 = __swift_allocate_boxed_opaque_existential_0(v13);
  if (v9 == 255)
  {
    *(void *)uint64_t v7 = 0;
    *(void *)(v7 + 8) = 0;
    *(_WORD *)(v7 + 16) = 256;
  }
  else if (MLDataTable.size.getter())
  {
    *(void *)uint64_t v7 = v8;
    *(unsigned char *)(v7 + 8) = v9 & 1;
  }
  else
  {
    outlined consume of MLDataTable?(v8, v9);
  }
  swift_storeEnumTagMultiPayload();
  outlined init with take of MLRandomForestClassifier.ModelParameters.ValidationData(v7, (uint64_t)boxed_opaque_existential_0);
  return outlined assign with take of Any?((uint64_t)v13, v2);
}

uint64_t MLRandomForestClassifier.ModelParameters.validation.getter()
{
  uint64_t result = outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v0, (uint64_t)&v2, &demangling cache variable for type metadata for Any?);
  if (v3)
  {
    outlined init with take of Any(&v2, &v4);
    type metadata accessor for MLRandomForestClassifier.ModelParameters.ValidationData();
    return swift_dynamicCast();
  }
  else
  {
    __break(1u);
  }
  return result;
}

uint64_t outlined init with take of MLRandomForestClassifier.ModelParameters.ValidationData(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = type metadata accessor for MLRandomForestClassifier.ModelParameters.ValidationData();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 32))(a2, a1, v4);
  return a2;
}

void (*MLRandomForestClassifier.ModelParameters.validationData.modify(uint64_t a1))(uint64_t a1, char a2)
{
  *(void *)(a1 + 16) = v1;
  MLRandomForestClassifier.ModelParameters.validationData.getter(a1);
  return MLRandomForestClassifier.ModelParameters.validationData.modify;
}

void MLRandomForestClassifier.ModelParameters.validationData.modify(uint64_t a1, char a2)
{
  long long v2 = *(void **)a1;
  unsigned __int8 v3 = *(unsigned char *)(a1 + 8);
  if (a2)
  {
    uint64_t v4 = *(void **)a1;
    unsigned __int8 v5 = v3;
    outlined copy of MLDataTable?(v2, v3);
    MLRandomForestClassifier.ModelParameters.validationData.setter((uint64_t)&v4);
    outlined consume of MLDataTable?(v2, v3);
  }
  else
  {
    uint64_t v4 = *(void **)a1;
    unsigned __int8 v5 = v3;
    MLRandomForestClassifier.ModelParameters.validationData.setter((uint64_t)&v4);
  }
}

uint64_t key path setter for MLRandomForestClassifier.ModelParameters.validation : MLRandomForestClassifier.ModelParameters(uint64_t a1)
{
  uint64_t v2 = type metadata accessor for MLRandomForestClassifier.ModelParameters.ValidationData();
  MEMORY[0x270FA5388](v2 - 8);
  uint64_t v4 = (char *)&v6 - ((v3 + 15) & 0xFFFFFFFFFFFFFFF0);
  outlined init with copy of MLRandomForestClassifier.ModelParameters.ValidationData(a1, (uint64_t)v4);
  return MLRandomForestClassifier.ModelParameters.validation.setter((uint64_t)v4);
}

uint64_t MLRandomForestClassifier.ModelParameters.validation.setter(uint64_t a1)
{
  v5[3] = type metadata accessor for MLRandomForestClassifier.ModelParameters.ValidationData();
  boxed_opaque_existential_0 = __swift_allocate_boxed_opaque_existential_0(v5);
  outlined init with take of MLRandomForestClassifier.ModelParameters.ValidationData(a1, (uint64_t)boxed_opaque_existential_0);
  return outlined assign with take of Any?((uint64_t)v5, v1);
}

void (*MLRandomForestClassifier.ModelParameters.validation.modify(void *a1))(uint64_t **a1, char a2)
{
  uint64_t v2 = v1;
  uint64_t v4 = malloc(0xA0uLL);
  *a1 = v4;
  v4[16] = v2;
  v4[17] = type metadata accessor for MLRandomForestClassifier.ModelParameters.ValidationData();
  OUTLINED_FUNCTION_8();
  size_t v6 = *(void *)(v5 + 64);
  v4[18] = malloc(v6);
  v4[19] = malloc(v6);
  uint64_t result = (void (*)(uint64_t **, char))outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v2, (uint64_t)(v4 + 4), &demangling cache variable for type metadata for Any?);
  if (v4[7])
  {
    outlined init with take of Any((_OWORD *)v4 + 2, v4);
    swift_dynamicCast();
    return MLRandomForestClassifier.ModelParameters.validation.modify;
  }
  else
  {
    __break(1u);
  }
  return result;
}

void MLRandomForestClassifier.ModelParameters.validation.modify(uint64_t **a1, char a2)
{
  uint64_t v2 = *a1;
  uint64_t v3 = (void *)(*a1)[18];
  uint64_t v4 = (void *)(*a1)[19];
  uint64_t v5 = (*a1)[16];
  uint64_t v6 = (*a1)[17];
  if (a2)
  {
    outlined init with copy of MLRandomForestClassifier.ModelParameters.ValidationData((*a1)[19], (uint64_t)v3);
    v2[11] = v6;
    boxed_opaque_existential_0 = __swift_allocate_boxed_opaque_existential_0(v2 + 8);
    outlined init with take of MLRandomForestClassifier.ModelParameters.ValidationData((uint64_t)v3, (uint64_t)boxed_opaque_existential_0);
    outlined assign with take of Any?((uint64_t)(v2 + 8), v5);
    outlined destroy of MLRandomForestClassifier.ModelParameters.ValidationData((uint64_t)v4);
  }
  else
  {
    v2[15] = v6;
    long long v8 = __swift_allocate_boxed_opaque_existential_0(v2 + 12);
    outlined init with take of MLRandomForestClassifier.ModelParameters.ValidationData((uint64_t)v4, (uint64_t)v8);
    outlined assign with take of Any?((uint64_t)(v2 + 12), v5);
  }
  free(v4);
  free(v3);

  free(v2);
}

uint64_t MLRandomForestClassifier.ModelParameters.maxDepth.getter()
{
  return *(void *)(v0 + 32);
}

uint64_t MLRandomForestClassifier.ModelParameters.maxDepth.setter(uint64_t result)
{
  *(void *)(v1 + 32) = result;
  return result;
}

uint64_t (*MLRandomForestClassifier.ModelParameters.maxDepth.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLRandomForestClassifier.ModelParameters.maxIterations.getter()
{
  return *(void *)(v0 + 40);
}

uint64_t MLRandomForestClassifier.ModelParameters.maxIterations.setter(uint64_t result)
{
  *(void *)(v1 + 40) = result;
  return result;
}

uint64_t (*MLRandomForestClassifier.ModelParameters.maxIterations.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

double MLRandomForestClassifier.ModelParameters.minLossReduction.getter()
{
  return *(double *)(v0 + 48);
}

void MLRandomForestClassifier.ModelParameters.minLossReduction.setter(double a1)
{
  *(double *)(v1 + 48) = a1;
}

uint64_t (*MLRandomForestClassifier.ModelParameters.minLossReduction.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

double MLRandomForestClassifier.ModelParameters.minChildWeight.getter()
{
  return *(double *)(v0 + 56);
}

void MLRandomForestClassifier.ModelParameters.minChildWeight.setter(double a1)
{
  *(double *)(v1 + 56) = a1;
}

uint64_t (*MLRandomForestClassifier.ModelParameters.minChildWeight.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLRandomForestClassifier.ModelParameters.randomSeed.getter()
{
  return *(void *)(v0 + 64);
}

uint64_t MLRandomForestClassifier.ModelParameters.randomSeed.setter(uint64_t result)
{
  *(void *)(v1 + 64) = result;
  return result;
}

uint64_t (*MLRandomForestClassifier.ModelParameters.randomSeed.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

double MLRandomForestClassifier.ModelParameters.rowSubsample.getter()
{
  return *(double *)(v0 + 72);
}

void MLRandomForestClassifier.ModelParameters.rowSubsample.setter(double a1)
{
  *(double *)(v1 + 72) = a1;
}

uint64_t (*MLRandomForestClassifier.ModelParameters.rowSubsample.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

double MLRandomForestClassifier.ModelParameters.columnSubsample.getter()
{
  return *(double *)(v0 + 80);
}

void MLRandomForestClassifier.ModelParameters.columnSubsample.setter(double a1)
{
  *(double *)(v1 + 80) = a1;
}

uint64_t (*MLRandomForestClassifier.ModelParameters.columnSubsample.modify())(void)
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLRandomForestClassifier.ModelParameters.init(validation:maxDepth:maxIterations:minLossReduction:minChildWeight:randomSeed:rowSubsample:columnSubsample:)@<X0>(uint64_t a1@<X0>, uint64_t a2@<X1>, uint64_t a3@<X2>, uint64_t a4@<X3>, uint64_t a5@<X8>, double a6@<D0>, double a7@<D1>, double a8@<D2>, double a9@<D3>)
{
  uint64_t v19 = type metadata accessor for MLRandomForestClassifier.ModelParameters.ValidationData();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v20);
  *(double *)&long long v21 = OUTLINED_FUNCTION_2_15();
  *(_OWORD *)a5 = v21;
  *(_OWORD *)(a5 + 16) = v21;
  *(void *)(a5 + 32) = a2;
  *(void *)(a5 + 40) = a3;
  *(double *)(a5 + 48) = a6;
  *(double *)(a5 + 56) = a7;
  *(void *)(a5 + 64) = a4;
  *(double *)(a5 + 72) = a8;
  *(double *)(a5 + 80) = a9;
  outlined init with copy of MLRandomForestClassifier.ModelParameters.ValidationData(a1, v9);
  v24[3] = v19;
  boxed_opaque_existential_0 = __swift_allocate_boxed_opaque_existential_0(v24);
  outlined init with take of MLRandomForestClassifier.ModelParameters.ValidationData(v9, (uint64_t)boxed_opaque_existential_0);
  outlined assign with take of Any?((uint64_t)v24, a5);
  return outlined destroy of MLRandomForestClassifier.ModelParameters.ValidationData(a1);
}

uint64_t MLRandomForestClassifier.ModelParameters.init(validationData:maxDepth:maxIterations:minLossReduction:minChildWeight:randomSeed:rowSubsample:columnSubsample:)@<X0>(uint64_t *a1@<X0>, uint64_t a2@<X1>, uint64_t a3@<X2>, uint64_t a4@<X3>, uint64_t a5@<X8>, double a6@<D0>, double a7@<D1>, double a8@<D2>, double a9@<D3>)
{
  uint64_t v9 = *a1;
  char v10 = *((unsigned char *)a1 + 8);
  *(_OWORD *)a5 = 0u;
  *(_OWORD *)(a5 + 16) = 0u;
  *(void *)(a5 + 32) = a2;
  *(void *)(a5 + 40) = a3;
  *(double *)(a5 + 48) = a6;
  *(double *)(a5 + 56) = a7;
  *(void *)(a5 + 64) = a4;
  *(double *)(a5 + 72) = a8;
  *(double *)(a5 + 80) = a9;
  uint64_t v12 = v9;
  char v13 = v10;
  return MLRandomForestClassifier.ModelParameters.validationData.setter((uint64_t)&v12);
}

uint64_t MLRandomForestClassifier.ModelParameters.init(configuration:validation:)@<X0>(uint64_t a1@<X0>, uint64_t a2@<X1>, uint64_t a3@<X8>)
{
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLRandomForestClassifier.ModelParameters.ValidationData?);
  MEMORY[0x270FA5388](v7 - 8);
  OUTLINED_FUNCTION_3_0();
  uint64_t v10 = v9 - v8;
  uint64_t v11 = type metadata accessor for MLRandomForestClassifier.ModelParameters.ValidationData();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v12);
  *(double *)&long long v13 = OUTLINED_FUNCTION_2_15();
  *(_OWORD *)a3 = v13;
  *(_OWORD *)(a3 + 16) = v13;
  *(void *)(a3 + 32) = BoostedTreeConfiguration.maximumDepth.getter();
  *(void *)(a3 + 40) = BoostedTreeConfiguration.maximumIterations.getter();
  BoostedTreeConfiguration.minimumLossReduction.getter();
  *(void *)(a3 + 48) = v14;
  BoostedTreeConfiguration.minimumChildWeight.getter();
  *(void *)(a3 + 56) = v15;
  *(void *)(a3 + 64) = BoostedTreeConfiguration.randomSeed.getter();
  BoostedTreeConfiguration.rowSubsample.getter();
  *(void *)(a3 + 72) = v16;
  BoostedTreeConfiguration.columnSubsample.getter();
  *(void *)(a3 + 80) = v17;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lF11TabularData0D5FrameV_s5NeverO8CreateML24MLRandomForestClassifierV15ModelParametersV010ValidationD0OTg503_s8g4ML24ijk3V15lm76V13configuration10validationAE0A12MLComponents24BoostedTreeConfigurationV_11c7Data0O5e12VSgtcfcAE010N21O0OAMcAPmcfu_ApMcfu0_AOXMtTf1ncn_n(a2, v10);
  if (__swift_getEnumTagSinglePayload(v10, 1, v11) == 1)
  {
    swift_storeEnumTagMultiPayload();
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v10, &demangling cache variable for type metadata for MLRandomForestClassifier.ModelParameters.ValidationData?);
  }
  else
  {
    outlined init with take of MLRandomForestClassifier.ModelParameters.ValidationData(v10, v3);
  }
  v21[3] = v11;
  boxed_opaque_existential_0 = __swift_allocate_boxed_opaque_existential_0(v21);
  outlined init with take of MLRandomForestClassifier.ModelParameters.ValidationData(v3, (uint64_t)boxed_opaque_existential_0);
  outlined assign with take of Any?((uint64_t)v21, a3);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(a2, &demangling cache variable for type metadata for DataFrame?);
  type metadata accessor for BoostedTreeConfiguration();
  OUTLINED_FUNCTION_8();
  return (*(uint64_t (**)(uint64_t))(v19 + 8))(a1);
}

uint64_t MLRandomForestClassifier.ModelParameters.description.getter()
{
  v0._uint64_t countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter();
  String.append(_:)(v0);
  swift_bridgeObjectRelease();
  v1._uint64_t countAndFlagsBits = 10;
  v1._uint64_t object = (void *)0xE100000000000000;
  String.append(_:)(v1);
  OUTLINED_FUNCTION_4_0();
  _StringGuts.grow(_:)(19);
  swift_bridgeObjectRelease();
  v2._uint64_t countAndFlagsBits = OUTLINED_FUNCTION_8_9();
  String.append(_:)(v2);
  swift_bridgeObjectRelease();
  OUTLINED_FUNCTION_1_1();
  v3._uint64_t countAndFlagsBits = 0xD000000000000010;
  v3._uint64_t object = (void *)0x80000002272D3F00;
  String.append(_:)(v3);
  swift_bridgeObjectRelease();
  OUTLINED_FUNCTION_4_0();
  _StringGuts.grow(_:)(23);
  OUTLINED_FUNCTION_7_0();
  v4._uint64_t countAndFlagsBits = 0xD000000000000014;
  v4._uint64_t object = (void *)0x80000002272D3F20;
  String.append(_:)(v4);
  OUTLINED_FUNCTION_5_27();
  OUTLINED_FUNCTION_1_1();
  v5._uint64_t countAndFlagsBits = 0xD000000000000010;
  v5._uint64_t object = (void *)0x80000002272D3F00;
  String.append(_:)(v5);
  swift_bridgeObjectRelease();
  _StringGuts.grow(_:)(21);
  OUTLINED_FUNCTION_7_0();
  OUTLINED_FUNCTION_5_0((uint64_t)"Min Child Weight: ");
  OUTLINED_FUNCTION_5_27();
  OUTLINED_FUNCTION_1_1();
  v6._uint64_t countAndFlagsBits = 0;
  v6._uint64_t object = (void *)0xE000000000000000;
  String.append(_:)(v6);
  swift_bridgeObjectRelease();
  OUTLINED_FUNCTION_4_0();
  _StringGuts.grow(_:)(16);
  swift_bridgeObjectRelease();
  strcpy((char *)&v11, "Random Seed: ");
  HIWORD(v11._object) = -4864;
  v7._uint64_t countAndFlagsBits = OUTLINED_FUNCTION_8_9();
  String.append(_:)(v7);
  swift_bridgeObjectRelease();
  OUTLINED_FUNCTION_1_1();
  String.append(_:)(v11);
  swift_bridgeObjectRelease();
  OUTLINED_FUNCTION_4_0();
  _StringGuts.grow(_:)(18);
  OUTLINED_FUNCTION_7_0();
  v8._uint64_t countAndFlagsBits = 0x7362755320776F52;
  v8._uint64_t object = (void *)0xEF203A656C706D61;
  String.append(_:)(v8);
  OUTLINED_FUNCTION_5_27();
  OUTLINED_FUNCTION_1_1();
  String.append(_:)(v11);
  swift_bridgeObjectRelease();
  _StringGuts.grow(_:)(21);
  OUTLINED_FUNCTION_7_0();
  OUTLINED_FUNCTION_5_0((uint64_t)"Column Subsample: ");
  OUTLINED_FUNCTION_5_27();
  OUTLINED_FUNCTION_1_1();
  v9._uint64_t countAndFlagsBits = 0;
  v9._uint64_t object = (void *)0xE000000000000000;
  String.append(_:)(v9);
  swift_bridgeObjectRelease();
  return 0x747065442078614DLL;
}

uint64_t MLRandomForestClassifier.ModelParameters.playgroundDescription.getter@<X0>(uint64_t *a1@<X8>)
{
  uint64_t result = MLRandomForestClassifier.ModelParameters.description.getter();
  a1[3] = MEMORY[0x263F8D310];
  *a1 = result;
  a1[1] = v3;
  return result;
}

uint64_t sub_22714BFB4()
{
  return MLRandomForestClassifier.ModelParameters.validation.getter();
}

uint64_t initializeWithCopy for MLRandomForestClassifier.ModelParameters(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = *(void *)(a2 + 24);
  if (v4)
  {
    *(void *)(a1 + 24) = v4;
    (**(void (***)(uint64_t, uint64_t))(v4 - 8))(a1, a2);
  }
  else
  {
    long long v5 = *(_OWORD *)(a2 + 16);
    *(_OWORD *)a1 = *(_OWORD *)a2;
    *(_OWORD *)(a1 + 16) = v5;
  }
  long long v6 = *(_OWORD *)(a2 + 48);
  *(_OWORD *)(a1 + 32) = *(_OWORD *)(a2 + 32);
  *(_OWORD *)(a1 + 48) = v6;
  *(_OWORD *)(a1 + 64) = *(_OWORD *)(a2 + 64);
  *(void *)(a1 + 80) = *(void *)(a2 + 80);
  return a1;
}

uint64_t assignWithCopy for MLRandomForestClassifier.ModelParameters(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = *(void *)(a2 + 24);
  if (!*(void *)(a1 + 24))
  {
    if (v4)
    {
      *(void *)(a1 + 24) = v4;
      (**(void (***)(uint64_t, uint64_t))(v4 - 8))(a1, a2);
      goto LABEL_8;
    }
LABEL_7:
    long long v5 = *(_OWORD *)(a2 + 16);
    *(_OWORD *)a1 = *(_OWORD *)a2;
    *(_OWORD *)(a1 + 16) = v5;
    goto LABEL_8;
  }
  if (!v4)
  {
    __swift_destroy_boxed_opaque_existential_0(a1);
    goto LABEL_7;
  }
  __swift_assign_boxed_opaque_existential_0((uint64_t *)a1, (uint64_t *)a2);
LABEL_8:
  *(void *)(a1 + 32) = *(void *)(a2 + 32);
  *(void *)(a1 + 40) = *(void *)(a2 + 40);
  *(void *)(a1 + 48) = *(void *)(a2 + 48);
  *(void *)(a1 + 56) = *(void *)(a2 + 56);
  *(void *)(a1 + 64) = *(void *)(a2 + 64);
  *(void *)(a1 + 72) = *(void *)(a2 + 72);
  *(void *)(a1 + 80) = *(void *)(a2 + 80);
  return a1;
}

void *__swift_memcpy88_8(void *a1, const void *a2)
{
  return memcpy(a1, a2, 0x58uLL);
}

uint64_t assignWithTake for MLRandomForestClassifier.ModelParameters(uint64_t a1, uint64_t a2)
{
  if (*(void *)(a1 + 24)) {
    __swift_destroy_boxed_opaque_existential_0(a1);
  }
  long long v4 = *(_OWORD *)(a2 + 16);
  *(_OWORD *)a1 = *(_OWORD *)a2;
  *(_OWORD *)(a1 + 16) = v4;
  long long v5 = *(_OWORD *)(a2 + 48);
  *(_OWORD *)(a1 + 32) = *(_OWORD *)(a2 + 32);
  *(_OWORD *)(a1 + 48) = v5;
  *(void *)(a1 + 64) = *(void *)(a2 + 64);
  *(_OWORD *)(a1 + 72) = *(_OWORD *)(a2 + 72);
  return a1;
}

uint64_t getEnumTagSinglePayload for MLRandomForestClassifier.ModelParameters(uint64_t a1, unsigned int a2)
{
  if (a2)
  {
    if (a2 >= 0x7FFFFFFF && *(unsigned char *)(a1 + 88))
    {
      int v2 = *(_DWORD *)a1 + 2147483646;
    }
    else
    {
      unint64_t v3 = *(void *)(a1 + 24);
      if (v3 >= 0xFFFFFFFF) {
        LODWORD(v3) = -1;
      }
      int v2 = v3 - 1;
      if (v2 < 0) {
        int v2 = -1;
      }
    }
  }
  else
  {
    int v2 = -1;
  }
  return (v2 + 1);
}

uint64_t storeEnumTagSinglePayload for MLRandomForestClassifier.ModelParameters(uint64_t result, unsigned int a2, unsigned int a3)
{
  if (a2 > 0x7FFFFFFE)
  {
    *(_OWORD *)(result + 72) = 0u;
    *(_OWORD *)(result + 56) = 0u;
    *(_OWORD *)(result + 40) = 0u;
    *(_OWORD *)(result + 24) = 0u;
    *(_OWORD *)(result + 8) = 0u;
    *(void *)uint64_t result = a2 - 0x7FFFFFFF;
    if (a3 >= 0x7FFFFFFF) {
      *(unsigned char *)(result + 88) = 1;
    }
  }
  else
  {
    if (a3 >= 0x7FFFFFFF) {
      *(unsigned char *)(result + 88) = 0;
    }
    if (a2) {
      *(void *)(result + 24) = a2;
    }
  }
  return result;
}

ValueMetadata *type metadata accessor for MLRandomForestClassifier.ModelParameters()
{
  return &type metadata for MLRandomForestClassifier.ModelParameters;
}

uint64_t OUTLINED_FUNCTION_5_27()
{
  return Double.write<A>(to:)();
}

uint64_t *initializeBufferWithCopyOfBuffer for MLFewShotSoundClassifier.MLP(uint64_t *a1, uint64_t *a2, uint64_t a3)
{
  int v5 = *(_DWORD *)(*(void *)(a3 - 8) + 80);
  if ((v5 & 0x20000) != 0)
  {
    uint64_t v9 = *a2;
    *a1 = *a2;
    a1 = (uint64_t *)(v9 + ((v5 + 16) & ~(unint64_t)v5));
    swift_retain();
  }
  else
  {
    uint64_t v7 = type metadata accessor for Dense();
    Swift::String v8 = *(void (**)(uint64_t *, uint64_t *, uint64_t))(*(void *)(v7 - 8) + 16);
    v8(a1, a2, v7);
    v8((uint64_t *)((char *)a1 + *(int *)(a3 + 20)), (uint64_t *)((char *)a2 + *(int *)(a3 + 20)), v7);
  }
  return a1;
}

uint64_t destroy for MLFewShotSoundClassifier.MLP(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = type metadata accessor for Dense();
  uint64_t v7 = *(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v4 - 8) + 8);
  ((void (*)(void *__return_ptr, uint64_t, uint64_t))v7)((void *)(v4 - 8), a1, v4);
  uint64_t v5 = a1 + *(int *)(a2 + 20);

  return v7(v5, v4);
}

uint64_t initializeWithCopy for MLFewShotSoundClassifier.MLP(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v6 = type metadata accessor for Dense();
  uint64_t v7 = *(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v6 - 8) + 16);
  v7(a1, a2, v6);
  v7(a1 + *(int *)(a3 + 20), a2 + *(int *)(a3 + 20), v6);
  return a1;
}

uint64_t assignWithCopy for MLFewShotSoundClassifier.MLP(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v6 = type metadata accessor for Dense();
  uint64_t v7 = *(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v6 - 8) + 24);
  v7(a1, a2, v6);
  v7(a1 + *(int *)(a3 + 20), a2 + *(int *)(a3 + 20), v6);
  return a1;
}

uint64_t initializeWithTake for MLFewShotSoundClassifier.MLP(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v6 = type metadata accessor for Dense();
  uint64_t v7 = *(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v6 - 8) + 32);
  v7(a1, a2, v6);
  v7(a1 + *(int *)(a3 + 20), a2 + *(int *)(a3 + 20), v6);
  return a1;
}

uint64_t assignWithTake for MLFewShotSoundClassifier.MLP(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v6 = type metadata accessor for Dense();
  uint64_t v7 = *(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v6 - 8) + 40);
  v7(a1, a2, v6);
  v7(a1 + *(int *)(a3 + 20), a2 + *(int *)(a3 + 20), v6);
  return a1;
}

uint64_t getEnumTagSinglePayload for MLFewShotSoundClassifier.MLP(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return MEMORY[0x270FA0340](a1, a2, a3, sub_22714C66C);
}

uint64_t sub_22714C66C()
{
  return __swift_get_extra_inhabitant_indexTm();
}

uint64_t storeEnumTagSinglePayload for MLFewShotSoundClassifier.MLP(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return MEMORY[0x270FA0580](a1, a2, a3, a4, sub_22714C698);
}

uint64_t sub_22714C698()
{
  return __swift_store_extra_inhabitant_indexTm();
}

uint64_t type metadata accessor for MLFewShotSoundClassifier.MLP(uint64_t a1)
{
  return type metadata accessor for MLImageClassifier.CustomFeatureExtractor(a1, (uint64_t *)&type metadata singleton initialization cache for MLFewShotSoundClassifier.MLP);
}

uint64_t type metadata completion function for MLFewShotSoundClassifier.MLP()
{
  uint64_t result = type metadata accessor for Dense();
  if (v1 <= 0x3F)
  {
    swift_initStructMetadata();
    return 0;
  }
  return result;
}

uint64_t *initializeBufferWithCopyOfBuffer for MLFewShotSoundClassifier.CausalConv1D(uint64_t *a1, uint64_t *a2, uint64_t a3)
{
  uint64_t v4 = a1;
  int v5 = *(_DWORD *)(*(void *)(a3 - 8) + 80);
  if ((v5 & 0x20000) != 0)
  {
    uint64_t v11 = *a2;
    *uint64_t v4 = *a2;
    uint64_t v4 = (uint64_t *)(v11 + ((v5 + 16) & ~(unint64_t)v5));
    swift_retain();
  }
  else
  {
    *(_OWORD *)a1 = *(_OWORD *)a2;
    uint64_t v7 = *(int *)(a3 + 20);
    Swift::String v8 = (char *)a1 + v7;
    uint64_t v9 = (char *)a2 + v7;
    uint64_t v10 = type metadata accessor for Conv1D();
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v10 - 8) + 16))(v8, v9, v10);
    *(_DWORD *)((char *)v4 + *(int *)(a3 + 24)) = *(_DWORD *)((char *)a2 + *(int *)(a3 + 24));
  }
  return v4;
}

uint64_t destroy for MLFewShotSoundClassifier.CausalConv1D(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = a1 + *(int *)(a2 + 20);
  uint64_t v3 = type metadata accessor for Conv1D();
  uint64_t v4 = *(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v3 - 8) + 8);

  return v4(v2, v3);
}

_OWORD *initializeWithCopy for MLFewShotSoundClassifier.CausalConv1D(_OWORD *a1, _OWORD *a2, uint64_t a3)
{
  *a1 = *a2;
  uint64_t v6 = *(int *)(a3 + 20);
  uint64_t v7 = (char *)a1 + v6;
  Swift::String v8 = (char *)a2 + v6;
  uint64_t v9 = type metadata accessor for Conv1D();
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v9 - 8) + 16))(v7, v8, v9);
  *(_DWORD *)((char *)a1 + *(int *)(a3 + 24)) = *(_DWORD *)((char *)a2 + *(int *)(a3 + 24));
  return a1;
}

void *assignWithCopy for MLFewShotSoundClassifier.CausalConv1D(void *a1, void *a2, uint64_t a3)
{
  *a1 = *a2;
  a1[1] = a2[1];
  uint64_t v6 = *(int *)(a3 + 20);
  uint64_t v7 = (char *)a1 + v6;
  Swift::String v8 = (char *)a2 + v6;
  uint64_t v9 = type metadata accessor for Conv1D();
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v9 - 8) + 24))(v7, v8, v9);
  *(_DWORD *)((char *)a1 + *(int *)(a3 + 24)) = *(_DWORD *)((char *)a2 + *(int *)(a3 + 24));
  return a1;
}

_OWORD *initializeWithTake for MLFewShotSoundClassifier.CausalConv1D(_OWORD *a1, _OWORD *a2, uint64_t a3)
{
  *a1 = *a2;
  uint64_t v6 = *(int *)(a3 + 20);
  uint64_t v7 = (char *)a1 + v6;
  Swift::String v8 = (char *)a2 + v6;
  uint64_t v9 = type metadata accessor for Conv1D();
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v9 - 8) + 32))(v7, v8, v9);
  *(_DWORD *)((char *)a1 + *(int *)(a3 + 24)) = *(_DWORD *)((char *)a2 + *(int *)(a3 + 24));
  return a1;
}

_OWORD *assignWithTake for MLFewShotSoundClassifier.CausalConv1D(_OWORD *a1, _OWORD *a2, uint64_t a3)
{
  *a1 = *a2;
  uint64_t v6 = *(int *)(a3 + 20);
  uint64_t v7 = (char *)a1 + v6;
  Swift::String v8 = (char *)a2 + v6;
  uint64_t v9 = type metadata accessor for Conv1D();
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v9 - 8) + 40))(v7, v8, v9);
  *(_DWORD *)((char *)a1 + *(int *)(a3 + 24)) = *(_DWORD *)((char *)a2 + *(int *)(a3 + 24));
  return a1;
}

uint64_t getEnumTagSinglePayload for MLFewShotSoundClassifier.CausalConv1D(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return MEMORY[0x270FA0340](a1, a2, a3, sub_22714CB28);
}

uint64_t sub_22714CB28()
{
  type metadata accessor for Conv1D();
  uint64_t v0 = OUTLINED_FUNCTION_37_7();

  return __swift_getEnumTagSinglePayload(v0, v1, v2);
}

uint64_t storeEnumTagSinglePayload for MLFewShotSoundClassifier.CausalConv1D(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return MEMORY[0x270FA0580](a1, a2, a3, a4, sub_22714CB80);
}

uint64_t sub_22714CB80()
{
  type metadata accessor for Conv1D();
  uint64_t v0 = OUTLINED_FUNCTION_21_17();

  return __swift_storeEnumTagSinglePayload(v0, v1, v2, v3);
}

uint64_t type metadata accessor for MLFewShotSoundClassifier.CausalConv1D(uint64_t a1)
{
  return type metadata accessor for MLImageClassifier.CustomFeatureExtractor(a1, (uint64_t *)&type metadata singleton initialization cache for MLFewShotSoundClassifier.CausalConv1D);
}

uint64_t type metadata completion function for MLFewShotSoundClassifier.CausalConv1D()
{
  uint64_t result = type metadata accessor for Conv1D();
  if (v1 <= 0x3F)
  {
    swift_initStructMetadata();
    return 0;
  }
  return result;
}

char *initializeBufferWithCopyOfBuffer for MLFewShotSoundClassifier.ConvolutionalNetwork(char *a1, uint64_t *a2, int *a3)
{
  int v5 = *(_DWORD *)(*((void *)a3 - 1) + 80);
  if ((v5 & 0x20000) != 0)
  {
    uint64_t v26 = *a2;
    *(void *)a1 = *a2;
    a1 = (char *)(v26 + ((v5 + 16) & ~(unint64_t)v5));
    swift_retain();
  }
  else
  {
    uint64_t v7 = type metadata accessor for Conv2D();
    (*(void (**)(char *, uint64_t *, uint64_t))(*(void *)(v7 - 8) + 16))(a1, a2, v7);
    uint64_t v8 = type metadata accessor for MLFewShotSoundClassifier.LeakyConv2D(0);
    *(_DWORD *)&a1[*(int *)(v8 + 20)] = *(_DWORD *)((char *)a2 + *(int *)(v8 + 20));
    uint64_t v9 = a3[5];
    uint64_t v10 = &a1[v9];
    uint64_t v11 = (char *)a2 + v9;
    *(_OWORD *)&a1[v9] = *(_OWORD *)((char *)a2 + v9);
    uint64_t v12 = type metadata accessor for MLFewShotSoundClassifier.CausalConv1D(0);
    uint64_t v13 = *(int *)(v12 + 20);
    unsigned __int8 v28 = &v10[v13];
    uint64_t v14 = &v11[v13];
    uint64_t v15 = type metadata accessor for Conv1D();
    uint64_t v16 = *(void (**)(char *, char *, uint64_t))(*(void *)(v15 - 8) + 16);
    v16(v28, v14, v15);
    *(_DWORD *)&v10[*(int *)(v12 + 24)] = *(_DWORD *)&v11[*(int *)(v12 + 24)];
    uint64_t v17 = a3[6];
    uint64_t v18 = &a1[v17];
    uint64_t v19 = (char *)a2 + v17;
    *(_OWORD *)&a1[v17] = *(_OWORD *)((char *)a2 + v17);
    v16(&a1[v17 + *(int *)(v12 + 20)], (char *)a2 + v17 + *(int *)(v12 + 20), v15);
    *(_DWORD *)&v18[*(int *)(v12 + 24)] = *(_DWORD *)&v19[*(int *)(v12 + 24)];
    uint64_t v20 = a3[7];
    long long v21 = &a1[v20];
    uint64_t v22 = (char *)a2 + v20;
    *(_OWORD *)&a1[v20] = *(_OWORD *)((char *)a2 + v20);
    v16(&a1[v20 + *(int *)(v12 + 20)], (char *)a2 + v20 + *(int *)(v12 + 20), v15);
    *(_DWORD *)&v21[*(int *)(v12 + 24)] = *(_DWORD *)&v22[*(int *)(v12 + 24)];
    uint64_t v23 = a3[8];
    uint64_t v24 = &a1[v23];
    uint64_t v25 = (char *)a2 + v23;
    *(_OWORD *)&a1[v23] = *(_OWORD *)v25;
    v16(&a1[v23 + *(int *)(v12 + 20)], &v25[*(int *)(v12 + 20)], v15);
    *(_DWORD *)&v24[*(int *)(v12 + 24)] = *(_DWORD *)&v25[*(int *)(v12 + 24)];
  }
  return a1;
}

uint64_t type metadata accessor for MLFewShotSoundClassifier.LeakyConv2D(uint64_t a1)
{
  return type metadata accessor for MLImageClassifier.CustomFeatureExtractor(a1, (uint64_t *)&type metadata singleton initialization cache for MLFewShotSoundClassifier.LeakyConv2D);
}

uint64_t destroy for MLFewShotSoundClassifier.ConvolutionalNetwork(uint64_t a1, int *a2)
{
  uint64_t v4 = type metadata accessor for Conv2D();
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v4 - 8) + 8))(a1, v4);
  uint64_t v5 = a1 + a2[5];
  uint64_t v6 = type metadata accessor for MLFewShotSoundClassifier.CausalConv1D(0);
  uint64_t v7 = v5 + *(int *)(v6 + 20);
  uint64_t v8 = type metadata accessor for Conv1D();
  uint64_t v11 = *(void (**)(uint64_t, uint64_t))(*(void *)(v8 - 8) + 8);
  ((void (*)(void *__return_ptr, uint64_t, uint64_t))v11)((void *)(v8 - 8), v7, v8);
  v11(a1 + a2[6] + *(int *)(v6 + 20), v8);
  v11(a1 + a2[7] + *(int *)(v6 + 20), v8);
  uint64_t v9 = a1 + a2[8] + *(int *)(v6 + 20);

  return ((uint64_t (*)(uint64_t, uint64_t))v11)(v9, v8);
}

uint64_t initializeWithCopy for MLFewShotSoundClassifier.ConvolutionalNetwork(uint64_t a1, uint64_t a2, int *a3)
{
  uint64_t v6 = type metadata accessor for Conv2D();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v6 - 8) + 16))(a1, a2, v6);
  uint64_t v7 = type metadata accessor for MLFewShotSoundClassifier.LeakyConv2D(0);
  *(_DWORD *)(a1 + *(int *)(v7 + 20)) = *(_DWORD *)(a2 + *(int *)(v7 + 20));
  uint64_t v8 = a3[5];
  uint64_t v9 = a1 + v8;
  uint64_t v10 = a2 + v8;
  *(_OWORD *)(a1 + v8) = *(_OWORD *)(a2 + v8);
  uint64_t v11 = type metadata accessor for MLFewShotSoundClassifier.CausalConv1D(0);
  uint64_t v12 = *(int *)(v11 + 20);
  uint64_t v13 = v9 + v12;
  uint64_t v14 = (char *)(v10 + v12);
  uint64_t v15 = type metadata accessor for Conv1D();
  uint64_t v16 = *(void (**)(uint64_t, char *, uint64_t))(*(void *)(v15 - 8) + 16);
  v16(v13, v14, v15);
  *(_DWORD *)(v9 + *(int *)(v11 + 24)) = *(_DWORD *)(v10 + *(int *)(v11 + 24));
  uint64_t v17 = a3[6];
  uint64_t v18 = a1 + v17;
  uint64_t v19 = a2 + v17;
  *(_OWORD *)(a1 + v17) = *(_OWORD *)(a2 + v17);
  v16(a1 + v17 + *(int *)(v11 + 20), (char *)(a2 + v17 + *(int *)(v11 + 20)), v15);
  *(_DWORD *)(v18 + *(int *)(v11 + 24)) = *(_DWORD *)(v19 + *(int *)(v11 + 24));
  uint64_t v20 = a3[7];
  uint64_t v21 = a1 + v20;
  uint64_t v22 = a2 + v20;
  *(_OWORD *)(a1 + v20) = *(_OWORD *)(a2 + v20);
  v16(a1 + v20 + *(int *)(v11 + 20), (char *)(a2 + v20 + *(int *)(v11 + 20)), v15);
  *(_DWORD *)(v21 + *(int *)(v11 + 24)) = *(_DWORD *)(v22 + *(int *)(v11 + 24));
  uint64_t v23 = a3[8];
  uint64_t v24 = a1 + v23;
  uint64_t v25 = (char *)(a2 + v23);
  *(_OWORD *)(a1 + v23) = *(_OWORD *)v25;
  v16(a1 + v23 + *(int *)(v11 + 20), &v25[*(int *)(v11 + 20)], v15);
  *(_DWORD *)(v24 + *(int *)(v11 + 24)) = *(_DWORD *)&v25[*(int *)(v11 + 24)];
  return a1;
}

uint64_t assignWithCopy for MLFewShotSoundClassifier.ConvolutionalNetwork(uint64_t a1, uint64_t a2, int *a3)
{
  uint64_t v6 = type metadata accessor for Conv2D();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v6 - 8) + 24))(a1, a2, v6);
  uint64_t v7 = type metadata accessor for MLFewShotSoundClassifier.LeakyConv2D(0);
  *(_DWORD *)(a1 + *(int *)(v7 + 20)) = *(_DWORD *)(a2 + *(int *)(v7 + 20));
  uint64_t v8 = a3[5];
  uint64_t v9 = (void *)(a1 + v8);
  uint64_t v10 = a2 + v8;
  *uint64_t v9 = *(void *)(a2 + v8);
  v9[1] = *(void *)(a2 + v8 + 8);
  uint64_t v11 = type metadata accessor for MLFewShotSoundClassifier.CausalConv1D(0);
  uint64_t v12 = *(int *)(v11 + 20);
  uint64_t v13 = (char *)v9 + v12;
  uint64_t v14 = v10 + v12;
  uint64_t v15 = type metadata accessor for Conv1D();
  uint64_t v16 = *(void (**)(char *, uint64_t, uint64_t))(*(void *)(v15 - 8) + 24);
  v16(v13, v14, v15);
  *(_DWORD *)((char *)v9 + *(int *)(v11 + 24)) = *(_DWORD *)(v10 + *(int *)(v11 + 24));
  uint64_t v17 = a3[6];
  uint64_t v18 = (void *)(a1 + v17);
  uint64_t v19 = a2 + v17;
  *uint64_t v18 = *(void *)(a2 + v17);
  v18[1] = *(void *)(a2 + v17 + 8);
  v16((char *)(a1 + v17 + *(int *)(v11 + 20)), a2 + v17 + *(int *)(v11 + 20), v15);
  *(_DWORD *)((char *)v18 + *(int *)(v11 + 24)) = *(_DWORD *)(v19 + *(int *)(v11 + 24));
  uint64_t v20 = a3[7];
  uint64_t v21 = (void *)(a1 + v20);
  uint64_t v22 = a2 + v20;
  *uint64_t v21 = *(void *)(a2 + v20);
  v21[1] = *(void *)(a2 + v20 + 8);
  v16((char *)(a1 + v20 + *(int *)(v11 + 20)), a2 + v20 + *(int *)(v11 + 20), v15);
  *(_DWORD *)((char *)v21 + *(int *)(v11 + 24)) = *(_DWORD *)(v22 + *(int *)(v11 + 24));
  uint64_t v23 = a3[8];
  uint64_t v24 = (void *)(a1 + v23);
  uint64_t v25 = (void *)(a2 + v23);
  *uint64_t v24 = *v25;
  v24[1] = v25[1];
  v16((char *)(a1 + v23 + *(int *)(v11 + 20)), (uint64_t)v25 + *(int *)(v11 + 20), v15);
  *(_DWORD *)((char *)v24 + *(int *)(v11 + 24)) = *(_DWORD *)((char *)v25 + *(int *)(v11 + 24));
  return a1;
}

uint64_t initializeWithTake for MLFewShotSoundClassifier.ConvolutionalNetwork(uint64_t a1, uint64_t a2, int *a3)
{
  uint64_t v6 = type metadata accessor for Conv2D();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v6 - 8) + 32))(a1, a2, v6);
  uint64_t v7 = type metadata accessor for MLFewShotSoundClassifier.LeakyConv2D(0);
  *(_DWORD *)(a1 + *(int *)(v7 + 20)) = *(_DWORD *)(a2 + *(int *)(v7 + 20));
  uint64_t v8 = a3[5];
  uint64_t v9 = a1 + v8;
  uint64_t v10 = a2 + v8;
  *(_OWORD *)(a1 + v8) = *(_OWORD *)(a2 + v8);
  uint64_t v11 = type metadata accessor for MLFewShotSoundClassifier.CausalConv1D(0);
  uint64_t v12 = *(int *)(v11 + 20);
  uint64_t v13 = v9 + v12;
  uint64_t v14 = (char *)(v10 + v12);
  uint64_t v15 = type metadata accessor for Conv1D();
  uint64_t v16 = *(void (**)(uint64_t, char *, uint64_t))(*(void *)(v15 - 8) + 32);
  v16(v13, v14, v15);
  *(_DWORD *)(v9 + *(int *)(v11 + 24)) = *(_DWORD *)(v10 + *(int *)(v11 + 24));
  uint64_t v17 = a3[6];
  uint64_t v18 = a1 + v17;
  uint64_t v19 = a2 + v17;
  *(_OWORD *)(a1 + v17) = *(_OWORD *)(a2 + v17);
  v16(a1 + v17 + *(int *)(v11 + 20), (char *)(a2 + v17 + *(int *)(v11 + 20)), v15);
  *(_DWORD *)(v18 + *(int *)(v11 + 24)) = *(_DWORD *)(v19 + *(int *)(v11 + 24));
  uint64_t v20 = a3[7];
  uint64_t v21 = a1 + v20;
  uint64_t v22 = a2 + v20;
  *(_OWORD *)(a1 + v20) = *(_OWORD *)(a2 + v20);
  v16(a1 + v20 + *(int *)(v11 + 20), (char *)(a2 + v20 + *(int *)(v11 + 20)), v15);
  *(_DWORD *)(v21 + *(int *)(v11 + 24)) = *(_DWORD *)(v22 + *(int *)(v11 + 24));
  uint64_t v23 = a3[8];
  uint64_t v24 = a1 + v23;
  uint64_t v25 = (char *)(a2 + v23);
  *(_OWORD *)(a1 + v23) = *(_OWORD *)v25;
  v16(a1 + v23 + *(int *)(v11 + 20), &v25[*(int *)(v11 + 20)], v15);
  *(_DWORD *)(v24 + *(int *)(v11 + 24)) = *(_DWORD *)&v25[*(int *)(v11 + 24)];
  return a1;
}

uint64_t assignWithTake for MLFewShotSoundClassifier.ConvolutionalNetwork(uint64_t a1, uint64_t a2, int *a3)
{
  uint64_t v6 = type metadata accessor for Conv2D();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v6 - 8) + 40))(a1, a2, v6);
  uint64_t v7 = type metadata accessor for MLFewShotSoundClassifier.LeakyConv2D(0);
  *(_DWORD *)(a1 + *(int *)(v7 + 20)) = *(_DWORD *)(a2 + *(int *)(v7 + 20));
  uint64_t v8 = a3[5];
  uint64_t v9 = a1 + v8;
  uint64_t v10 = a2 + v8;
  *(_OWORD *)(a1 + v8) = *(_OWORD *)(a2 + v8);
  uint64_t v11 = type metadata accessor for MLFewShotSoundClassifier.CausalConv1D(0);
  uint64_t v12 = *(int *)(v11 + 20);
  uint64_t v13 = v9 + v12;
  uint64_t v14 = (char *)(v10 + v12);
  uint64_t v15 = type metadata accessor for Conv1D();
  uint64_t v16 = *(void (**)(uint64_t, char *, uint64_t))(*(void *)(v15 - 8) + 40);
  v16(v13, v14, v15);
  *(_DWORD *)(v9 + *(int *)(v11 + 24)) = *(_DWORD *)(v10 + *(int *)(v11 + 24));
  uint64_t v17 = a3[6];
  uint64_t v18 = a1 + v17;
  uint64_t v19 = a2 + v17;
  *(_OWORD *)(a1 + v17) = *(_OWORD *)(a2 + v17);
  v16(a1 + v17 + *(int *)(v11 + 20), (char *)(a2 + v17 + *(int *)(v11 + 20)), v15);
  *(_DWORD *)(v18 + *(int *)(v11 + 24)) = *(_DWORD *)(v19 + *(int *)(v11 + 24));
  uint64_t v20 = a3[7];
  uint64_t v21 = a1 + v20;
  uint64_t v22 = a2 + v20;
  *(_OWORD *)(a1 + v20) = *(_OWORD *)(a2 + v20);
  v16(a1 + v20 + *(int *)(v11 + 20), (char *)(a2 + v20 + *(int *)(v11 + 20)), v15);
  *(_DWORD *)(v21 + *(int *)(v11 + 24)) = *(_DWORD *)(v22 + *(int *)(v11 + 24));
  uint64_t v23 = a3[8];
  uint64_t v24 = a1 + v23;
  uint64_t v25 = (char *)(a2 + v23);
  *(_OWORD *)(a1 + v23) = *(_OWORD *)v25;
  v16(a1 + v23 + *(int *)(v11 + 20), &v25[*(int *)(v11 + 20)], v15);
  *(_DWORD *)(v24 + *(int *)(v11 + 24)) = *(_DWORD *)&v25[*(int *)(v11 + 24)];
  return a1;
}

uint64_t getEnumTagSinglePayload for MLFewShotSoundClassifier.ConvolutionalNetwork(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return MEMORY[0x270FA0340](a1, a2, a3, sub_22714D7AC);
}

uint64_t sub_22714D7AC(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return __swift_get_extra_inhabitant_index_5Tm(a1, a2, a3, (uint64_t)type metadata accessor for MLFewShotSoundClassifier.LeakyConv2D, type metadata accessor for MLFewShotSoundClassifier.CausalConv1D);
}

uint64_t storeEnumTagSinglePayload for MLFewShotSoundClassifier.ConvolutionalNetwork(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return MEMORY[0x270FA0580](a1, a2, a3, a4, sub_22714D7EC);
}

uint64_t sub_22714D7EC(uint64_t a1, uint64_t a2, int a3, uint64_t a4)
{
  return __swift_store_extra_inhabitant_index_6Tm(a1, a2, a3, a4, (uint64_t)type metadata accessor for MLFewShotSoundClassifier.LeakyConv2D, type metadata accessor for MLFewShotSoundClassifier.CausalConv1D);
}

uint64_t type metadata accessor for MLFewShotSoundClassifier.ConvolutionalNetwork(uint64_t a1)
{
  return type metadata accessor for MLImageClassifier.CustomFeatureExtractor(a1, (uint64_t *)&type metadata singleton initialization cache for MLFewShotSoundClassifier.ConvolutionalNetwork);
}

uint64_t type metadata completion function for MLFewShotSoundClassifier.ConvolutionalNetwork()
{
  uint64_t result = type metadata accessor for MLFewShotSoundClassifier.LeakyConv2D(319);
  if (v1 <= 0x3F)
  {
    uint64_t result = type metadata accessor for MLFewShotSoundClassifier.CausalConv1D(319);
    if (v2 <= 0x3F)
    {
      swift_initStructMetadata();
      return 0;
    }
  }
  return result;
}

uint64_t *initializeBufferWithCopyOfBuffer for MLFewShotSoundClassifier.LeakyConv2D(uint64_t *a1, uint64_t *a2, uint64_t a3)
{
  int v5 = *(_DWORD *)(*(void *)(a3 - 8) + 80);
  if ((v5 & 0x20000) != 0)
  {
    uint64_t v8 = *a2;
    *a1 = *a2;
    a1 = (uint64_t *)(v8 + ((v5 + 16) & ~(unint64_t)v5));
    swift_retain();
  }
  else
  {
    uint64_t v7 = type metadata accessor for Conv2D();
    (*(void (**)(uint64_t *, uint64_t *, uint64_t))(*(void *)(v7 - 8) + 16))(a1, a2, v7);
    *(_DWORD *)((char *)a1 + *(int *)(a3 + 20)) = *(_DWORD *)((char *)a2 + *(int *)(a3 + 20));
  }
  return a1;
}

uint64_t destroy for MLFewShotSoundClassifier.LeakyConv2D(uint64_t a1)
{
  uint64_t v2 = type metadata accessor for Conv2D();
  uint64_t v3 = *(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v2 - 8) + 8);

  return v3(a1, v2);
}

uint64_t initializeWithCopy for MLFewShotSoundClassifier.LeakyConv2D(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v6 = type metadata accessor for Conv2D();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v6 - 8) + 16))(a1, a2, v6);
  *(_DWORD *)(a1 + *(int *)(a3 + 20)) = *(_DWORD *)(a2 + *(int *)(a3 + 20));
  return a1;
}

uint64_t assignWithCopy for MLFewShotSoundClassifier.LeakyConv2D(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v6 = type metadata accessor for Conv2D();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v6 - 8) + 24))(a1, a2, v6);
  *(_DWORD *)(a1 + *(int *)(a3 + 20)) = *(_DWORD *)(a2 + *(int *)(a3 + 20));
  return a1;
}

uint64_t initializeWithTake for MLFewShotSoundClassifier.LeakyConv2D(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v6 = type metadata accessor for Conv2D();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v6 - 8) + 32))(a1, a2, v6);
  *(_DWORD *)(a1 + *(int *)(a3 + 20)) = *(_DWORD *)(a2 + *(int *)(a3 + 20));
  return a1;
}

uint64_t assignWithTake for MLFewShotSoundClassifier.LeakyConv2D(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v6 = type metadata accessor for Conv2D();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v6 - 8) + 40))(a1, a2, v6);
  *(_DWORD *)(a1 + *(int *)(a3 + 20)) = *(_DWORD *)(a2 + *(int *)(a3 + 20));
  return a1;
}

uint64_t getEnumTagSinglePayload for MLFewShotSoundClassifier.LeakyConv2D(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return MEMORY[0x270FA0340](a1, a2, a3, sub_22714DC38);
}

uint64_t sub_22714DC38()
{
  type metadata accessor for Conv2D();
  uint64_t v0 = OUTLINED_FUNCTION_37_7();

  return __swift_getEnumTagSinglePayload(v0, v1, v2);
}

uint64_t storeEnumTagSinglePayload for MLFewShotSoundClassifier.LeakyConv2D(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return MEMORY[0x270FA0580](a1, a2, a3, a4, sub_22714DC8C);
}

uint64_t sub_22714DC8C()
{
  type metadata accessor for Conv2D();
  uint64_t v0 = OUTLINED_FUNCTION_21_17();

  return __swift_storeEnumTagSinglePayload(v0, v1, v2, v3);
}

uint64_t type metadata completion function for MLFewShotSoundClassifier.LeakyConv2D()
{
  uint64_t result = type metadata accessor for Conv2D();
  if (v1 <= 0x3F)
  {
    swift_initStructMetadata();
    return 0;
  }
  return result;
}

char *initializeBufferWithCopyOfBuffer for MLFewShotSoundClassifier.TemporalClassifier(char *a1, uint64_t *a2, uint64_t a3)
{
  int v5 = *(_DWORD *)(*(void *)(a3 - 8) + 80);
  if ((v5 & 0x20000) != 0)
  {
    uint64_t v32 = *a2;
    *(void *)a1 = *a2;
    a1 = (char *)(v32 + ((v5 + 16) & ~(unint64_t)v5));
    swift_retain();
  }
  else
  {
    uint64_t v6 = type metadata accessor for Conv2D();
    (*(void (**)(char *, uint64_t *, uint64_t))(*(void *)(v6 - 8) + 16))(a1, a2, v6);
    uint64_t v7 = type metadata accessor for MLFewShotSoundClassifier.LeakyConv2D(0);
    *(_DWORD *)&a1[*(int *)(v7 + 20)] = *(_DWORD *)((char *)a2 + *(int *)(v7 + 20));
    uint64_t v8 = (int *)type metadata accessor for MLFewShotSoundClassifier.ConvolutionalNetwork(0);
    uint64_t v9 = v8[5];
    uint64_t v10 = &a1[v9];
    uint64_t v11 = (char *)a2 + v9;
    *(_OWORD *)&a1[v9] = *(_OWORD *)((char *)a2 + v9);
    uint64_t v12 = type metadata accessor for MLFewShotSoundClassifier.CausalConv1D(0);
    uint64_t v13 = *(int *)(v12 + 20);
    uint64_t v34 = &v10[v13];
    uint64_t v14 = &v11[v13];
    uint64_t v15 = type metadata accessor for Conv1D();
    uint64_t v16 = *(void (**)(char *, char *, uint64_t))(*(void *)(v15 - 8) + 16);
    v16(v34, v14, v15);
    *(_DWORD *)&v10[*(int *)(v12 + 24)] = *(_DWORD *)&v11[*(int *)(v12 + 24)];
    uint64_t v17 = v8[6];
    uint64_t v18 = &a1[v17];
    uint64_t v19 = (char *)a2 + v17;
    *(_OWORD *)&a1[v17] = *(_OWORD *)((char *)a2 + v17);
    v16(&a1[v17 + *(int *)(v12 + 20)], (char *)a2 + v17 + *(int *)(v12 + 20), v15);
    *(_DWORD *)&v18[*(int *)(v12 + 24)] = *(_DWORD *)&v19[*(int *)(v12 + 24)];
    uint64_t v20 = v8[7];
    uint64_t v21 = &a1[v20];
    uint64_t v22 = (char *)a2 + v20;
    *(_OWORD *)&a1[v20] = *(_OWORD *)((char *)a2 + v20);
    v16(&a1[v20 + *(int *)(v12 + 20)], (char *)a2 + v20 + *(int *)(v12 + 20), v15);
    *(_DWORD *)&v21[*(int *)(v12 + 24)] = *(_DWORD *)&v22[*(int *)(v12 + 24)];
    uint64_t v23 = v8[8];
    uint64_t v24 = &a1[v23];
    uint64_t v25 = (char *)a2 + v23;
    *(_OWORD *)&a1[v23] = *(_OWORD *)((char *)a2 + v23);
    v16(&a1[v23 + *(int *)(v12 + 20)], (char *)a2 + v23 + *(int *)(v12 + 20), v15);
    *(_DWORD *)&v24[*(int *)(v12 + 24)] = *(_DWORD *)&v25[*(int *)(v12 + 24)];
    uint64_t v26 = *(int *)(a3 + 20);
    uint64_t v27 = &a1[v26];
    unsigned __int8 v28 = (char *)a2 + v26;
    uint64_t v29 = type metadata accessor for Dense();
    uint64_t v30 = *(void (**)(char *, char *, uint64_t))(*(void *)(v29 - 8) + 16);
    v30(v27, v28, v29);
    uint64_t v31 = type metadata accessor for MLFewShotSoundClassifier.MLP(0);
    v30(&v27[*(int *)(v31 + 20)], &v28[*(int *)(v31 + 20)], v29);
  }
  return a1;
}

uint64_t destroy for MLFewShotSoundClassifier.TemporalClassifier(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = type metadata accessor for Conv2D();
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v4 - 8) + 8))(a1, v4);
  int v5 = (int *)type metadata accessor for MLFewShotSoundClassifier.ConvolutionalNetwork(0);
  uint64_t v6 = a1 + v5[5];
  uint64_t v7 = type metadata accessor for MLFewShotSoundClassifier.CausalConv1D(0);
  uint64_t v8 = v6 + *(int *)(v7 + 20);
  uint64_t v9 = type metadata accessor for Conv1D();
  uint64_t v10 = *(void (**)(uint64_t, uint64_t))(*(void *)(v9 - 8) + 8);
  v10(v8, v9);
  v10(a1 + v5[6] + *(int *)(v7 + 20), v9);
  v10(a1 + v5[7] + *(int *)(v7 + 20), v9);
  v10(a1 + v5[8] + *(int *)(v7 + 20), v9);
  uint64_t v11 = a1 + *(int *)(a2 + 20);
  uint64_t v12 = type metadata accessor for Dense();
  uint64_t v15 = *(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v12 - 8) + 8);
  ((void (*)(void *__return_ptr, uint64_t, uint64_t))v15)((void *)(v12 - 8), v11, v12);
  uint64_t v13 = v11 + *(int *)(type metadata accessor for MLFewShotSoundClassifier.MLP(0) + 20);

  return v15(v13, v12);
}

uint64_t initializeWithCopy for MLFewShotSoundClassifier.TemporalClassifier(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v5 = type metadata accessor for Conv2D();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v5 - 8) + 16))(a1, a2, v5);
  uint64_t v6 = type metadata accessor for MLFewShotSoundClassifier.LeakyConv2D(0);
  *(_DWORD *)(a1 + *(int *)(v6 + 20)) = *(_DWORD *)(a2 + *(int *)(v6 + 20));
  uint64_t v7 = (int *)type metadata accessor for MLFewShotSoundClassifier.ConvolutionalNetwork(0);
  uint64_t v8 = v7[5];
  uint64_t v9 = (_OWORD *)(a1 + v8);
  uint64_t v10 = a2 + v8;
  *uint64_t v9 = *(_OWORD *)(a2 + v8);
  uint64_t v11 = type metadata accessor for MLFewShotSoundClassifier.CausalConv1D(0);
  uint64_t v12 = *(int *)(v11 + 20);
  uint64_t v13 = (char *)v9 + v12;
  uint64_t v14 = v10 + v12;
  uint64_t v15 = type metadata accessor for Conv1D();
  uint64_t v16 = *(void (**)(char *, uint64_t, uint64_t))(*(void *)(v15 - 8) + 16);
  v16(v13, v14, v15);
  *(_DWORD *)((char *)v9 + *(int *)(v11 + 24)) = *(_DWORD *)(v10 + *(int *)(v11 + 24));
  uint64_t v17 = v7[6];
  uint64_t v18 = a1 + v17;
  uint64_t v19 = a2 + v17;
  *(_OWORD *)(a1 + v17) = *(_OWORD *)(a2 + v17);
  v16((char *)(a1 + v17 + *(int *)(v11 + 20)), a2 + v17 + *(int *)(v11 + 20), v15);
  *(_DWORD *)(v18 + *(int *)(v11 + 24)) = *(_DWORD *)(v19 + *(int *)(v11 + 24));
  uint64_t v20 = v7[7];
  uint64_t v21 = a1 + v20;
  uint64_t v22 = a2 + v20;
  *(_OWORD *)(a1 + v20) = *(_OWORD *)(a2 + v20);
  v16((char *)(a1 + v20 + *(int *)(v11 + 20)), a2 + v20 + *(int *)(v11 + 20), v15);
  *(_DWORD *)(v21 + *(int *)(v11 + 24)) = *(_DWORD *)(v22 + *(int *)(v11 + 24));
  uint64_t v23 = v7[8];
  uint64_t v24 = a1 + v23;
  uint64_t v25 = a2 + v23;
  *(_OWORD *)(a1 + v23) = *(_OWORD *)(a2 + v23);
  v16((char *)(a1 + v23 + *(int *)(v11 + 20)), a2 + v23 + *(int *)(v11 + 20), v15);
  *(_DWORD *)(v24 + *(int *)(v11 + 24)) = *(_DWORD *)(v25 + *(int *)(v11 + 24));
  uint64_t v26 = *(int *)(a3 + 20);
  uint64_t v27 = a1 + v26;
  uint64_t v28 = a2 + v26;
  uint64_t v29 = type metadata accessor for Dense();
  uint64_t v30 = *(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v29 - 8) + 16);
  v30(v27, v28, v29);
  uint64_t v31 = type metadata accessor for MLFewShotSoundClassifier.MLP(0);
  v30(v27 + *(int *)(v31 + 20), v28 + *(int *)(v31 + 20), v29);
  return a1;
}

uint64_t assignWithCopy for MLFewShotSoundClassifier.TemporalClassifier(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v5 = type metadata accessor for Conv2D();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v5 - 8) + 24))(a1, a2, v5);
  uint64_t v6 = type metadata accessor for MLFewShotSoundClassifier.LeakyConv2D(0);
  *(_DWORD *)(a1 + *(int *)(v6 + 20)) = *(_DWORD *)(a2 + *(int *)(v6 + 20));
  uint64_t v7 = (int *)type metadata accessor for MLFewShotSoundClassifier.ConvolutionalNetwork(0);
  uint64_t v8 = v7[5];
  uint64_t v9 = (void *)(a1 + v8);
  uint64_t v10 = a2 + v8;
  *uint64_t v9 = *(void *)(a2 + v8);
  v9[1] = *(void *)(a2 + v8 + 8);
  uint64_t v11 = type metadata accessor for MLFewShotSoundClassifier.CausalConv1D(0);
  uint64_t v12 = *(int *)(v11 + 20);
  uint64_t v13 = (char *)v9 + v12;
  uint64_t v14 = v10 + v12;
  uint64_t v15 = type metadata accessor for Conv1D();
  uint64_t v16 = *(void (**)(char *, uint64_t, uint64_t))(*(void *)(v15 - 8) + 24);
  v16(v13, v14, v15);
  *(_DWORD *)((char *)v9 + *(int *)(v11 + 24)) = *(_DWORD *)(v10 + *(int *)(v11 + 24));
  uint64_t v17 = v7[6];
  uint64_t v18 = (void *)(a1 + v17);
  uint64_t v19 = a2 + v17;
  *uint64_t v18 = *(void *)(a2 + v17);
  v18[1] = *(void *)(a2 + v17 + 8);
  v16((char *)(a1 + v17 + *(int *)(v11 + 20)), a2 + v17 + *(int *)(v11 + 20), v15);
  *(_DWORD *)((char *)v18 + *(int *)(v11 + 24)) = *(_DWORD *)(v19 + *(int *)(v11 + 24));
  uint64_t v20 = v7[7];
  uint64_t v21 = (void *)(a1 + v20);
  uint64_t v22 = a2 + v20;
  *uint64_t v21 = *(void *)(a2 + v20);
  v21[1] = *(void *)(a2 + v20 + 8);
  v16((char *)(a1 + v20 + *(int *)(v11 + 20)), a2 + v20 + *(int *)(v11 + 20), v15);
  *(_DWORD *)((char *)v21 + *(int *)(v11 + 24)) = *(_DWORD *)(v22 + *(int *)(v11 + 24));
  uint64_t v23 = v7[8];
  uint64_t v24 = (void *)(a1 + v23);
  uint64_t v25 = a2 + v23;
  *uint64_t v24 = *(void *)(a2 + v23);
  v24[1] = *(void *)(a2 + v23 + 8);
  v16((char *)(a1 + v23 + *(int *)(v11 + 20)), a2 + v23 + *(int *)(v11 + 20), v15);
  *(_DWORD *)((char *)v24 + *(int *)(v11 + 24)) = *(_DWORD *)(v25 + *(int *)(v11 + 24));
  uint64_t v26 = *(int *)(a3 + 20);
  uint64_t v27 = a1 + v26;
  uint64_t v28 = a2 + v26;
  uint64_t v29 = type metadata accessor for Dense();
  uint64_t v30 = *(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v29 - 8) + 24);
  v30(v27, v28, v29);
  uint64_t v31 = type metadata accessor for MLFewShotSoundClassifier.MLP(0);
  v30(v27 + *(int *)(v31 + 20), v28 + *(int *)(v31 + 20), v29);
  return a1;
}

uint64_t initializeWithTake for MLFewShotSoundClassifier.TemporalClassifier(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v5 = type metadata accessor for Conv2D();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v5 - 8) + 32))(a1, a2, v5);
  uint64_t v6 = type metadata accessor for MLFewShotSoundClassifier.LeakyConv2D(0);
  *(_DWORD *)(a1 + *(int *)(v6 + 20)) = *(_DWORD *)(a2 + *(int *)(v6 + 20));
  uint64_t v7 = (int *)type metadata accessor for MLFewShotSoundClassifier.ConvolutionalNetwork(0);
  uint64_t v8 = v7[5];
  uint64_t v9 = (_OWORD *)(a1 + v8);
  uint64_t v10 = a2 + v8;
  *uint64_t v9 = *(_OWORD *)(a2 + v8);
  uint64_t v11 = type metadata accessor for MLFewShotSoundClassifier.CausalConv1D(0);
  uint64_t v12 = *(int *)(v11 + 20);
  uint64_t v13 = (char *)v9 + v12;
  uint64_t v14 = v10 + v12;
  uint64_t v15 = type metadata accessor for Conv1D();
  uint64_t v16 = *(void (**)(char *, uint64_t, uint64_t))(*(void *)(v15 - 8) + 32);
  v16(v13, v14, v15);
  *(_DWORD *)((char *)v9 + *(int *)(v11 + 24)) = *(_DWORD *)(v10 + *(int *)(v11 + 24));
  uint64_t v17 = v7[6];
  uint64_t v18 = a1 + v17;
  uint64_t v19 = a2 + v17;
  *(_OWORD *)(a1 + v17) = *(_OWORD *)(a2 + v17);
  v16((char *)(a1 + v17 + *(int *)(v11 + 20)), a2 + v17 + *(int *)(v11 + 20), v15);
  *(_DWORD *)(v18 + *(int *)(v11 + 24)) = *(_DWORD *)(v19 + *(int *)(v11 + 24));
  uint64_t v20 = v7[7];
  uint64_t v21 = a1 + v20;
  uint64_t v22 = a2 + v20;
  *(_OWORD *)(a1 + v20) = *(_OWORD *)(a2 + v20);
  v16((char *)(a1 + v20 + *(int *)(v11 + 20)), a2 + v20 + *(int *)(v11 + 20), v15);
  *(_DWORD *)(v21 + *(int *)(v11 + 24)) = *(_DWORD *)(v22 + *(int *)(v11 + 24));
  uint64_t v23 = v7[8];
  uint64_t v24 = a1 + v23;
  uint64_t v25 = a2 + v23;
  *(_OWORD *)(a1 + v23) = *(_OWORD *)(a2 + v23);
  v16((char *)(a1 + v23 + *(int *)(v11 + 20)), a2 + v23 + *(int *)(v11 + 20), v15);
  *(_DWORD *)(v24 + *(int *)(v11 + 24)) = *(_DWORD *)(v25 + *(int *)(v11 + 24));
  uint64_t v26 = *(int *)(a3 + 20);
  uint64_t v27 = a1 + v26;
  uint64_t v28 = a2 + v26;
  uint64_t v29 = type metadata accessor for Dense();
  uint64_t v30 = *(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v29 - 8) + 32);
  v30(v27, v28, v29);
  uint64_t v31 = type metadata accessor for MLFewShotSoundClassifier.MLP(0);
  v30(v27 + *(int *)(v31 + 20), v28 + *(int *)(v31 + 20), v29);
  return a1;
}

uint64_t assignWithTake for MLFewShotSoundClassifier.TemporalClassifier(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v5 = type metadata accessor for Conv2D();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v5 - 8) + 40))(a1, a2, v5);
  uint64_t v6 = type metadata accessor for MLFewShotSoundClassifier.LeakyConv2D(0);
  *(_DWORD *)(a1 + *(int *)(v6 + 20)) = *(_DWORD *)(a2 + *(int *)(v6 + 20));
  uint64_t v7 = (int *)type metadata accessor for MLFewShotSoundClassifier.ConvolutionalNetwork(0);
  uint64_t v8 = v7[5];
  uint64_t v9 = (_OWORD *)(a1 + v8);
  uint64_t v10 = a2 + v8;
  *uint64_t v9 = *(_OWORD *)(a2 + v8);
  uint64_t v11 = type metadata accessor for MLFewShotSoundClassifier.CausalConv1D(0);
  uint64_t v12 = *(int *)(v11 + 20);
  uint64_t v13 = (char *)v9 + v12;
  uint64_t v14 = v10 + v12;
  uint64_t v15 = type metadata accessor for Conv1D();
  uint64_t v16 = *(void (**)(char *, uint64_t, uint64_t))(*(void *)(v15 - 8) + 40);
  v16(v13, v14, v15);
  *(_DWORD *)((char *)v9 + *(int *)(v11 + 24)) = *(_DWORD *)(v10 + *(int *)(v11 + 24));
  uint64_t v17 = v7[6];
  uint64_t v18 = a1 + v17;
  uint64_t v19 = a2 + v17;
  *(_OWORD *)(a1 + v17) = *(_OWORD *)(a2 + v17);
  v16((char *)(a1 + v17 + *(int *)(v11 + 20)), a2 + v17 + *(int *)(v11 + 20), v15);
  *(_DWORD *)(v18 + *(int *)(v11 + 24)) = *(_DWORD *)(v19 + *(int *)(v11 + 24));
  uint64_t v20 = v7[7];
  uint64_t v21 = a1 + v20;
  uint64_t v22 = a2 + v20;
  *(_OWORD *)(a1 + v20) = *(_OWORD *)(a2 + v20);
  v16((char *)(a1 + v20 + *(int *)(v11 + 20)), a2 + v20 + *(int *)(v11 + 20), v15);
  *(_DWORD *)(v21 + *(int *)(v11 + 24)) = *(_DWORD *)(v22 + *(int *)(v11 + 24));
  uint64_t v23 = v7[8];
  uint64_t v24 = a1 + v23;
  uint64_t v25 = a2 + v23;
  *(_OWORD *)(a1 + v23) = *(_OWORD *)(a2 + v23);
  v16((char *)(a1 + v23 + *(int *)(v11 + 20)), a2 + v23 + *(int *)(v11 + 20), v15);
  *(_DWORD *)(v24 + *(int *)(v11 + 24)) = *(_DWORD *)(v25 + *(int *)(v11 + 24));
  uint64_t v26 = *(int *)(a3 + 20);
  uint64_t v27 = a1 + v26;
  uint64_t v28 = a2 + v26;
  uint64_t v29 = type metadata accessor for Dense();
  uint64_t v30 = *(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v29 - 8) + 40);
  v30(v27, v28, v29);
  uint64_t v31 = type metadata accessor for MLFewShotSoundClassifier.MLP(0);
  v30(v27 + *(int *)(v31 + 20), v28 + *(int *)(v31 + 20), v29);
  return a1;
}

uint64_t getEnumTagSinglePayload for MLFewShotSoundClassifier.TemporalClassifier(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return MEMORY[0x270FA0340](a1, a2, a3, sub_22714EB48);
}

uint64_t sub_22714EB48(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return __swift_get_extra_inhabitant_index_5Tm(a1, a2, a3, (uint64_t)type metadata accessor for MLFewShotSoundClassifier.ConvolutionalNetwork, type metadata accessor for MLFewShotSoundClassifier.MLP);
}

uint64_t __swift_get_extra_inhabitant_index_5Tm(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t (*a5)(void))
{
  uint64_t v9 = OUTLINED_FUNCTION_49_3();
  v10(v9);
  OUTLINED_FUNCTION_2_39();
  if (*(_DWORD *)(v12 + 84) == v5)
  {
    uint64_t v13 = v11;
    uint64_t v14 = v6;
  }
  else
  {
    uint64_t v13 = a5(0);
    uint64_t v14 = v6 + *(int *)(a3 + 20);
  }

  return __swift_getEnumTagSinglePayload(v14, v5, v13);
}

uint64_t storeEnumTagSinglePayload for MLFewShotSoundClassifier.TemporalClassifier(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return MEMORY[0x270FA0580](a1, a2, a3, a4, sub_22714EC08);
}

uint64_t sub_22714EC08(uint64_t a1, uint64_t a2, int a3, uint64_t a4)
{
  return __swift_store_extra_inhabitant_index_6Tm(a1, a2, a3, a4, (uint64_t)type metadata accessor for MLFewShotSoundClassifier.ConvolutionalNetwork, type metadata accessor for MLFewShotSoundClassifier.MLP);
}

uint64_t __swift_store_extra_inhabitant_index_6Tm(uint64_t a1, uint64_t a2, int a3, uint64_t a4, uint64_t a5, uint64_t (*a6)(void))
{
  uint64_t v11 = OUTLINED_FUNCTION_49_3();
  v12(v11);
  OUTLINED_FUNCTION_2_39();
  if (*(_DWORD *)(v14 + 84) == a3)
  {
    uint64_t v15 = v13;
    uint64_t v16 = v7;
  }
  else
  {
    uint64_t v15 = a6(0);
    uint64_t v16 = v7 + *(int *)(a4 + 20);
  }

  return __swift_storeEnumTagSinglePayload(v16, v6, v6, v15);
}

uint64_t type metadata accessor for MLFewShotSoundClassifier.TemporalClassifier(uint64_t a1)
{
  return type metadata accessor for MLImageClassifier.CustomFeatureExtractor(a1, (uint64_t *)&type metadata singleton initialization cache for MLFewShotSoundClassifier.TemporalClassifier);
}

uint64_t type metadata completion function for MLFewShotSoundClassifier.TemporalClassifier()
{
  uint64_t result = type metadata accessor for MLFewShotSoundClassifier.ConvolutionalNetwork(319);
  if (v1 <= 0x3F)
  {
    uint64_t result = type metadata accessor for MLFewShotSoundClassifier.MLP(319);
    if (v2 <= 0x3F)
    {
      swift_initStructMetadata();
      return 0;
    }
  }
  return result;
}

void MLFewShotSoundClassifier.TemporalClassifier.init(outputs:inputChannels:)()
{
  OUTLINED_FUNCTION_28_10();
  uint64_t v10 = v2;
  uint64_t v3 = type metadata accessor for MLFewShotSoundClassifier.LeakyConv2D(0);
  uint64_t v4 = v3 - 8;
  MEMORY[0x270FA5388](v3);
  OUTLINED_FUNCTION_24_4();
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ComputeDevice?);
  uint64_t v6 = OUTLINED_FUNCTION_17(v5);
  MEMORY[0x270FA5388](v6);
  OUTLINED_FUNCTION_2_37();
  type metadata accessor for ParameterInitializer();
  type metadata accessor for ComputeDevice();
  OUTLINED_FUNCTION_45_6();
  OUTLINED_FUNCTION_31_8();
  static ParameterInitializer.randomNormal(mean:standardDeviation:seed:scalarType:on:)();
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v0, &demangling cache variable for type metadata for ComputeDevice?);
  static ParameterInitializer.zeros.getter();
  OUTLINED_FUNCTION_45_6();
  OUTLINED_FUNCTION_31_8();
  static ParameterInitializer.glorotUniform(seed:scalarType:on:)();
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v0, &demangling cache variable for type metadata for ComputeDevice?);
  static ParameterInitializer.zeros.getter();
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<MLFewShotSoundClassifier.CausalConv1D>);
  uint64_t v7 = type metadata accessor for MLFewShotSoundClassifier.CausalConv1D(0);
  OUTLINED_FUNCTION_1(v7);
  uint64_t v8 = swift_allocObject();
  *(_OWORD *)(v8 + 16) = xmmword_2272CB360;
  swift_retain();
  swift_retain();
  MLFewShotSoundClassifier.CausalConv1D.init(alpha:filterCount:kernelSize:stride:dilation:weightInitializer:biasInitializer:)();
  swift_retain();
  swift_retain();
  OUTLINED_FUNCTION_8_23();
  MLFewShotSoundClassifier.CausalConv1D.init(alpha:filterCount:kernelSize:stride:dilation:weightInitializer:biasInitializer:)();
  swift_retain();
  swift_retain();
  OUTLINED_FUNCTION_8_23();
  MLFewShotSoundClassifier.CausalConv1D.init(alpha:filterCount:kernelSize:stride:dilation:weightInitializer:biasInitializer:)();
  swift_retain();
  swift_retain();
  OUTLINED_FUNCTION_8_23();
  MLFewShotSoundClassifier.CausalConv1D.init(alpha:filterCount:kernelSize:stride:dilation:weightInitializer:biasInitializer:)();
  swift_retain();
  static ParameterInitializer.zeros.getter();
  uint64_t v9 = Conv2D.init(filterCount:kernelSize:stride:padding:dilation:groupCount:weightInitializer:biasInitializer:)();
  *(float *)(v1 + *(int *)(v4 + 28)) = MEMORY[0x22A672DB0](v9, 0.1);
  MLFewShotSoundClassifier.ConvolutionalNetwork.init(causal:featureReduction:)(v8, v1, v10);
  type metadata accessor for MLFewShotSoundClassifier.TemporalClassifier(0);
  swift_retain();
  swift_retain();
  Dense.init(unitCount:weightInitializer:biasInitializer:)();
  type metadata accessor for MLFewShotSoundClassifier.MLP(0);
  swift_retain();
  Dense.init(unitCount:weightInitializer:biasInitializer:)();
  swift_release();
  swift_release();
  swift_release();
  OUTLINED_FUNCTION_41_6();
}

uint64_t MLFewShotSoundClassifier.CausalPadding.forward(_:)()
{
  return Layer.callAsFunction(_:)();
}

uint64_t protocol witness for Layer.isEveryParameterInitialized.getter in conformance MLFewShotSoundClassifier.CausalPadding()
{
  return MEMORY[0x270F4E038]();
}

uint64_t protocol witness for Layer.initializeParameters(for:) in conformance MLFewShotSoundClassifier.CausalPadding()
{
  return MEMORY[0x270F4E028]();
}

uint64_t protocol witness for Layer.forward(_:) in conformance MLFewShotSoundClassifier.CausalPadding()
{
  return MLFewShotSoundClassifier.CausalPadding.forward(_:)();
}

uint64_t protocol witness for _ComputeDevicePlaceable.place(on:) in conformance MLFewShotSoundClassifier.CausalPadding()
{
  lazy protocol witness table accessor for type MLFewShotSoundClassifier.CausalPadding and conformance MLFewShotSoundClassifier.CausalPadding();

  return Layer.place(on:)();
}

uint64_t protocol witness for _ComputeDevicePlaceable.placed(on:) in conformance MLFewShotSoundClassifier.CausalPadding()
{
  lazy protocol witness table accessor for type MLFewShotSoundClassifier.CausalPadding and conformance MLFewShotSoundClassifier.CausalPadding();

  return Layer.placed(on:)();
}

void MLFewShotSoundClassifier.CausalConv1D.init(alpha:kernelSize:stride:dilation:weight:bias:)()
{
  OUTLINED_FUNCTION_28_10();
  uint64_t v1 = v0;
  uint64_t v3 = v2;
  uint64_t v5 = v4;
  uint64_t v7 = v6;
  float v9 = v8;
  uint64_t v11 = v10;
  uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Tensor?);
  uint64_t v13 = OUTLINED_FUNCTION_17(v12);
  MEMORY[0x270FA5388](v13);
  OUTLINED_FUNCTION_3_0();
  uint64_t v16 = v15 - v14;
  uint64_t v17 = type metadata accessor for Tensor();
  OUTLINED_FUNCTION_0();
  uint64_t v19 = v18;
  MEMORY[0x270FA5388](v20);
  OUTLINED_FUNCTION_3_0();
  uint64_t v23 = v22 - v21;
  if (__OFSUB__(v7, 1))
  {
    __break(1u);
  }
  else if ((unsigned __int128)(v5 * (__int128)(v7 - 1)) >> 64 == (v5 * (v7 - 1)) >> 63)
  {
    *uint64_t v11 = ZeroPad1D.init(size:)();
    v11[1] = v24;
    (*(void (**)(uint64_t, uint64_t, uint64_t))(v19 + 16))(v23, v3, v17);
    outlined init with copy of Tensor?(v1, v16);
    uint64_t v25 = type metadata accessor for MLFewShotSoundClassifier.CausalConv1D(0);
    OUTLINED_FUNCTION_43_7();
    uint64_t v26 = Conv1D.init(weight:bias:stride:padding:dilation:groupCount:)();
    float v27 = MEMORY[0x22A672DB0](v26, v9);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v1, &demangling cache variable for type metadata for Tensor?);
    (*(void (**)(uint64_t, uint64_t))(v19 + 8))(v3, v17);
    *(float *)((char *)v11 + *(int *)(v25 + 24)) = v27;
    OUTLINED_FUNCTION_41_6();
    return;
  }
  __break(1u);
}

void MLFewShotSoundClassifier.CausalConv1D.init(alpha:filterCount:kernelSize:stride:dilation:weightInitializer:biasInitializer:)()
{
  OUTLINED_FUNCTION_28_10();
  uint64_t v4 = v2;
  if (__OFSUB__(v0, 1))
  {
    __break(1u);
  }
  else if ((unsigned __int128)(v1 * (__int128)(v0 - 1)) >> 64 == (v1 * (v0 - 1)) >> 63)
  {
    float v5 = v3;
    *uint64_t v2 = ZeroPad1D.init(size:)();
    v4[1] = v6;
    uint64_t v7 = type metadata accessor for MLFewShotSoundClassifier.CausalConv1D(0);
    swift_retain();
    swift_retain();
    OUTLINED_FUNCTION_43_7();
    uint64_t v8 = Conv1D.init(filterCount:kernelSize:stride:padding:dilation:groupCount:weightInitializer:biasInitializer:)();
    float v9 = MEMORY[0x22A672DB0](v8, v5);
    swift_release();
    swift_release();
    *(float *)((char *)v4 + *(int *)(v7 + 24)) = v9;
    OUTLINED_FUNCTION_41_6();
    return;
  }
  __break(1u);
}

uint64_t MLFewShotSoundClassifier.CausalConv1D.forward(_:)()
{
  uint64_t v1 = type metadata accessor for Tensor();
  OUTLINED_FUNCTION_0();
  uint64_t v3 = v2;
  uint64_t v5 = MEMORY[0x270FA5388](v4);
  uint64_t v7 = (char *)&v12 - ((v6 + 15) & 0xFFFFFFFFFFFFFFF0);
  MEMORY[0x270FA5388](v5);
  float v9 = (char *)&v12 - v8;
  int v13 = *(_DWORD *)((char *)v0 + *(int *)(type metadata accessor for MLFewShotSoundClassifier.CausalConv1D(0) + 24));
  long long v12 = *v0;
  lazy protocol witness table accessor for type MLFewShotSoundClassifier.CausalPadding and conformance MLFewShotSoundClassifier.CausalPadding();
  Layer.callAsFunction(_:)();
  type metadata accessor for Conv1D();
  Layer.callAsFunction(_:)();
  uint64_t v10 = *(void (**)(char *, uint64_t))(v3 + 8);
  v10(v7, v1);
  Layer.callAsFunction(_:)();
  return ((uint64_t (*)(char *, uint64_t))v10)(v9, v1);
}

uint64_t protocol witness for _ComputeDevicePlaceable.place(on:) in conformance MLFewShotSoundClassifier.CausalConv1D()
{
  lazy protocol witness table accessor for type MLFewShotSoundClassifier.LeakyConv2D and conformance MLFewShotSoundClassifier.LeakyConv2D(&lazy protocol witness table cache variable for type MLFewShotSoundClassifier.CausalConv1D and conformance MLFewShotSoundClassifier.CausalConv1D, (void (*)(uint64_t))type metadata accessor for MLFewShotSoundClassifier.CausalConv1D);

  return Layer.place(on:)();
}

uint64_t protocol witness for _ComputeDevicePlaceable.placed(on:) in conformance MLFewShotSoundClassifier.CausalConv1D()
{
  lazy protocol witness table accessor for type MLFewShotSoundClassifier.LeakyConv2D and conformance MLFewShotSoundClassifier.LeakyConv2D(&lazy protocol witness table cache variable for type MLFewShotSoundClassifier.CausalConv1D and conformance MLFewShotSoundClassifier.CausalConv1D, (void (*)(uint64_t))type metadata accessor for MLFewShotSoundClassifier.CausalConv1D);

  return Layer.placed(on:)();
}

void MLFewShotSoundClassifier.MLP.forward(_:)()
{
  OUTLINED_FUNCTION_19_4();
  type metadata accessor for Tensor();
  OUTLINED_FUNCTION_0();
  uint64_t v3 = v2;
  uint64_t v5 = MEMORY[0x270FA5388](v4);
  MEMORY[0x270FA5388](v5);
  OUTLINED_FUNCTION_47_8();
  MEMORY[0x270FA5388](v6);
  OUTLINED_FUNCTION_44_6();
  uint64_t v7 = type metadata accessor for Dense();
  OUTLINED_FUNCTION_0();
  uint64_t v9 = v8;
  MEMORY[0x270FA5388](v10);
  uint64_t v11 = OUTLINED_FUNCTION_9_23();
  uint64_t v12 = type metadata accessor for MLFewShotSoundClassifier.MLP(v11);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v9 + 16))(v1, v0 + *(int *)(v12 + 20), v7);
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<TensorRangeExpression?>);
  uint64_t v13 = swift_allocObject();
  *(_OWORD *)(v13 + 16) = xmmword_2272CB4A0;
  *(_OWORD *)(v13 + 32) = 0u;
  *(_OWORD *)(v13 + 48) = 0u;
  *(_OWORD *)(v13 + 64) = 0u;
  *(_OWORD *)(v13 + 80) = 0u;
  *(_OWORD *)(v13 + 96) = 0u;
  uint64_t v14 = MEMORY[0x263F585B8];
  *(void *)(v13 + 136) = MEMORY[0x263F8D6C8];
  *(void *)(v13 + 144) = v14;
  *(void *)(v13 + 112) = -1;
  Tensor.subscript.getter();
  swift_bridgeObjectRelease();
  Layer.callAsFunction(_:)();
  uint64_t v15 = *(void (**)(void))(v3 + 8);
  OUTLINED_FUNCTION_29_12();
  v15();
  relu(_:)();
  OUTLINED_FUNCTION_29_12();
  v15();
  Layer.callAsFunction(_:)();
  OUTLINED_FUNCTION_29_12();
  v15();
  (*(void (**)(uint64_t, uint64_t))(v9 + 8))(v1, v7);
  OUTLINED_FUNCTION_12_4();
}

uint64_t protocol witness for _ComputeDevicePlaceable.place(on:) in conformance MLFewShotSoundClassifier.MLP()
{
  lazy protocol witness table accessor for type MLFewShotSoundClassifier.LeakyConv2D and conformance MLFewShotSoundClassifier.LeakyConv2D(&lazy protocol witness table cache variable for type MLFewShotSoundClassifier.MLP and conformance MLFewShotSoundClassifier.MLP, (void (*)(uint64_t))type metadata accessor for MLFewShotSoundClassifier.MLP);

  return Layer.place(on:)();
}

uint64_t protocol witness for _ComputeDevicePlaceable.placed(on:) in conformance MLFewShotSoundClassifier.MLP()
{
  lazy protocol witness table accessor for type MLFewShotSoundClassifier.LeakyConv2D and conformance MLFewShotSoundClassifier.LeakyConv2D(&lazy protocol witness table cache variable for type MLFewShotSoundClassifier.MLP and conformance MLFewShotSoundClassifier.MLP, (void (*)(uint64_t))type metadata accessor for MLFewShotSoundClassifier.MLP);

  return Layer.placed(on:)();
}

void MLFewShotSoundClassifier.LeakyConv2D.forward(_:)()
{
  OUTLINED_FUNCTION_19_4();
  uint64_t v32 = v0;
  uint64_t v34 = v1;
  uint64_t v30 = type metadata accessor for Tensor();
  OUTLINED_FUNCTION_0();
  uint64_t v33 = v2;
  MEMORY[0x270FA5388](v3);
  OUTLINED_FUNCTION_49();
  uint64_t v31 = v4;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v5);
  uint64_t v29 = (char *)v25 - v6;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v7);
  id v36 = (char *)v25 - v8;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v9);
  uint64_t v11 = (char *)v25 - v10;
  uint64_t v12 = type metadata accessor for TensorShape();
  OUTLINED_FUNCTION_0();
  uint64_t v14 = v13;
  MEMORY[0x270FA5388](v15);
  OUTLINED_FUNCTION_22_0();
  Tensor.shape.getter();
  uint64_t v16 = TensorShape.subscript.getter();
  uint64_t v17 = *(void (**)(void))(v14 + 8);
  OUTLINED_FUNCTION_137();
  v17();
  Tensor.shape.getter();
  uint64_t v26 = TensorShape.subscript.getter();
  OUTLINED_FUNCTION_137();
  v17();
  Tensor.shape.getter();
  uint64_t v18 = TensorShape.subscript.getter();
  id v35 = v17;
  OUTLINED_FUNCTION_137();
  v17();
  Tensor.transposed(permutation:)();
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
  uint64_t v19 = swift_allocObject();
  *(_OWORD *)(v19 + 16) = xmmword_2272CB360;
  uint64_t v27 = v18;
  uint64_t v28 = v16;
  if ((unsigned __int128)(v16 * (__int128)v18) >> 64 == (v16 * v18) >> 63)
  {
    *(void *)(v19 + 32) = v16 * v18;
    *(void *)(v19 + 40) = 1;
    *(void *)(v19 + 48) = v26;
    *(void *)(v19 + 56) = 1;
    MEMORY[0x22A672540]();
    v25[1] = v11;
    Tensor.reshaped(to:)();
    v25[0] = v12;
    OUTLINED_FUNCTION_137();
    v20();
    int v37 = *(_DWORD *)(v32 + *(int *)(type metadata accessor for MLFewShotSoundClassifier.LeakyConv2D(0) + 20));
    type metadata accessor for Conv2D();
    Layer.callAsFunction(_:)();
    Layer.callAsFunction(_:)();
    uint64_t v21 = *(void (**)(void))(v33 + 8);
    OUTLINED_FUNCTION_14_16();
    v21();
    uint64_t v22 = swift_allocObject();
    *(_OWORD *)(v22 + 16) = xmmword_2272CB4A0;
    uint64_t v23 = v27;
    *(void *)(v22 + 32) = v28;
    *(void *)(v22 + 40) = v23;
    *(void *)(v22 + 48) = MEMORY[0x22A672960]();
    MEMORY[0x22A672540](v22);
    Tensor.reshaped(to:)();
    OUTLINED_FUNCTION_137();
    v24();
    Tensor.transposed(permutation:)();
    OUTLINED_FUNCTION_14_16();
    v21();
    OUTLINED_FUNCTION_14_16();
    v21();
    OUTLINED_FUNCTION_14_16();
    v21();
    OUTLINED_FUNCTION_14_16();
    v21();
    OUTLINED_FUNCTION_12_4();
  }
  else
  {
    __break(1u);
  }
}

uint64_t protocol witness for _ComputeDevicePlaceable.place(on:) in conformance MLFewShotSoundClassifier.LeakyConv2D()
{
  lazy protocol witness table accessor for type MLFewShotSoundClassifier.LeakyConv2D and conformance MLFewShotSoundClassifier.LeakyConv2D(&lazy protocol witness table cache variable for type MLFewShotSoundClassifier.LeakyConv2D and conformance MLFewShotSoundClassifier.LeakyConv2D, (void (*)(uint64_t))type metadata accessor for MLFewShotSoundClassifier.LeakyConv2D);

  return Layer.place(on:)();
}

uint64_t protocol witness for _ComputeDevicePlaceable.placed(on:) in conformance MLFewShotSoundClassifier.LeakyConv2D()
{
  lazy protocol witness table accessor for type MLFewShotSoundClassifier.LeakyConv2D and conformance MLFewShotSoundClassifier.LeakyConv2D(&lazy protocol witness table cache variable for type MLFewShotSoundClassifier.LeakyConv2D and conformance MLFewShotSoundClassifier.LeakyConv2D, (void (*)(uint64_t))type metadata accessor for MLFewShotSoundClassifier.LeakyConv2D);

  return Layer.placed(on:)();
}

uint64_t MLFewShotSoundClassifier.ConvolutionalNetwork.init(causal:featureReduction:)@<X0>(uint64_t a1@<X0>, uint64_t a2@<X1>, uint64_t a3@<X8>)
{
  uint64_t result = type metadata accessor for MLFewShotSoundClassifier.ConvolutionalNetwork(0);
  unint64_t v7 = *(void *)(a1 + 16);
  if (!v7)
  {
    __break(1u);
    goto LABEL_9;
  }
  uint64_t v8 = (int *)result;
  uint64_t v9 = a3 + *(int *)(result + 20);
  uint64_t v10 = *(void *)(type metadata accessor for MLFewShotSoundClassifier.CausalConv1D(0) - 8);
  uint64_t v11 = a1 + ((*(unsigned __int8 *)(v10 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v10 + 80));
  uint64_t result = outlined init with copy of MLFewShotSoundClassifier.CausalConv1D(v11, v9);
  if (v7 == 1)
  {
LABEL_9:
    __break(1u);
    goto LABEL_10;
  }
  uint64_t v12 = *(void *)(v10 + 72);
  uint64_t result = outlined init with copy of MLFewShotSoundClassifier.CausalConv1D(v11 + v12, a3 + v8[6]);
  if (v7 < 3)
  {
LABEL_10:
    __break(1u);
    goto LABEL_11;
  }
  uint64_t result = outlined init with copy of MLFewShotSoundClassifier.CausalConv1D(v11 + 2 * v12, a3 + v8[7]);
  if (v7 == 3)
  {
LABEL_11:
    __break(1u);
    return result;
  }
  outlined init with copy of MLFewShotSoundClassifier.CausalConv1D(v11 + 3 * v12, a3 + v8[8]);
  swift_bridgeObjectRelease();

  return outlined init with take of MLFewShotSoundClassifier.LeakyConv2D(a2, a3);
}

void MLFewShotSoundClassifier.ConvolutionalNetwork.forward(_:)()
{
  OUTLINED_FUNCTION_19_4();
  uint64_t v15 = v0;
  uint64_t v14 = type metadata accessor for Tensor();
  OUTLINED_FUNCTION_0();
  uint64_t v2 = v1;
  MEMORY[0x270FA5388](v3);
  OUTLINED_FUNCTION_49();
  v13[1] = v4;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v5);
  v13[0] = (char *)v13 - v6;
  OUTLINED_FUNCTION_20_3();
  uint64_t v8 = MEMORY[0x270FA5388](v7);
  uint64_t v9 = MEMORY[0x270FA5388](v8);
  MEMORY[0x270FA5388](v9);
  uint64_t v11 = (char *)v13 - v10;
  type metadata accessor for MLFewShotSoundClassifier.LeakyConv2D(0);
  lazy protocol witness table accessor for type MLFewShotSoundClassifier.LeakyConv2D and conformance MLFewShotSoundClassifier.LeakyConv2D(&lazy protocol witness table cache variable for type MLFewShotSoundClassifier.LeakyConv2D and conformance MLFewShotSoundClassifier.LeakyConv2D, (void (*)(uint64_t))type metadata accessor for MLFewShotSoundClassifier.LeakyConv2D);
  Layer.callAsFunction(_:)();
  type metadata accessor for MLFewShotSoundClassifier.ConvolutionalNetwork(0);
  type metadata accessor for MLFewShotSoundClassifier.CausalConv1D(0);
  lazy protocol witness table accessor for type MLFewShotSoundClassifier.LeakyConv2D and conformance MLFewShotSoundClassifier.LeakyConv2D(&lazy protocol witness table cache variable for type MLFewShotSoundClassifier.CausalConv1D and conformance MLFewShotSoundClassifier.CausalConv1D, (void (*)(uint64_t))type metadata accessor for MLFewShotSoundClassifier.CausalConv1D);
  OUTLINED_FUNCTION_46_8();
  OUTLINED_FUNCTION_46_8();
  OUTLINED_FUNCTION_46_8();
  OUTLINED_FUNCTION_46_8();
  (*(void (**)(char *, uint64_t))(v2 + 8))(v11, v14);
  uint64_t v12 = *(void (**)(void))(v2 + 32);
  OUTLINED_FUNCTION_16_17();
  v12();
  type metadata accessor for MLFewShotSoundClassifier.ConvolutionalNetwork.Output(0);
  OUTLINED_FUNCTION_16_17();
  v12();
  OUTLINED_FUNCTION_16_17();
  v12();
  OUTLINED_FUNCTION_16_17();
  v12();
  OUTLINED_FUNCTION_12_4();
}

uint64_t protocol witness for _ComputeDevicePlaceable.place(on:) in conformance MLFewShotSoundClassifier.ConvolutionalNetwork()
{
  lazy protocol witness table accessor for type MLFewShotSoundClassifier.LeakyConv2D and conformance MLFewShotSoundClassifier.LeakyConv2D(&lazy protocol witness table cache variable for type MLFewShotSoundClassifier.ConvolutionalNetwork and conformance MLFewShotSoundClassifier.ConvolutionalNetwork, (void (*)(uint64_t))type metadata accessor for MLFewShotSoundClassifier.ConvolutionalNetwork);

  return Layer.place(on:)();
}

uint64_t protocol witness for _ComputeDevicePlaceable.placed(on:) in conformance MLFewShotSoundClassifier.ConvolutionalNetwork()
{
  lazy protocol witness table accessor for type MLFewShotSoundClassifier.LeakyConv2D and conformance MLFewShotSoundClassifier.LeakyConv2D(&lazy protocol witness table cache variable for type MLFewShotSoundClassifier.ConvolutionalNetwork and conformance MLFewShotSoundClassifier.ConvolutionalNetwork, (void (*)(uint64_t))type metadata accessor for MLFewShotSoundClassifier.ConvolutionalNetwork);

  return Layer.placed(on:)();
}

uint64_t MLFewShotSoundClassifier.TemporalClassifier.init(inputChannels:blobsFile:)@<X0>(uint64_t a1@<X0>, uint64_t a2@<X1>, uint64_t a3@<X8>)
{
  uint64_t v77 = type metadata accessor for MLFewShotSoundClassifier.LeakyConv2D(0);
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v6);
  OUTLINED_FUNCTION_3_0();
  uint64_t v9 = v8 - v7;
  type metadata accessor for ScalarType();
  OUTLINED_FUNCTION_0();
  uint64_t v76 = v10;
  MEMORY[0x270FA5388](v11);
  OUTLINED_FUNCTION_22_0();
  uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Tensor?);
  uint64_t v13 = OUTLINED_FUNCTION_17(v12);
  MEMORY[0x270FA5388](v13);
  OUTLINED_FUNCTION_3_0();
  uint64_t v16 = v15 - v14;
  uint64_t v17 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ComputeDevice?);
  uint64_t v18 = OUTLINED_FUNCTION_17(v17);
  MEMORY[0x270FA5388](v18);
  OUTLINED_FUNCTION_2_37();
  uint64_t v19 = type metadata accessor for TensorShape();
  uint64_t v20 = OUTLINED_FUNCTION_17(v19);
  MEMORY[0x270FA5388](v20);
  OUTLINED_FUNCTION_9_23();
  uint64_t v21 = type metadata accessor for Tensor();
  OUTLINED_FUNCTION_8();
  MEMORY[0x270FA5388](v22);
  OUTLINED_FUNCTION_24_4();
  uint64_t v23 = BlobsFile.floatBlob(at:)(0);
  if (v79) {
    return outlined release of BlobsFile(a2);
  }
  uint64_t v80 = v23;
  uint64_t v73 = v16;
  uint64_t v74 = v4;
  uint64_t v25 = BlobsFile.floatBlob(at:)(1uLL);
  uint64_t v26 = BlobsFile.floatBlob(at:)(2uLL);
  BlobsFile.floatBlob(at:)(3uLL);
  BlobsFile.floatBlob(at:)(4uLL);
  BlobsFile.floatBlob(at:)(5uLL);
  BlobsFile.floatBlob(at:)(6uLL);
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<MLFewShotSoundClassifier.CausalConv1D>);
  uint64_t v27 = type metadata accessor for MLFewShotSoundClassifier.CausalConv1D(0);
  OUTLINED_FUNCTION_1(v27);
  uint64_t v28 = swift_allocObject();
  *(_OWORD *)(v28 + 16) = xmmword_2272CB360;
  uint64_t v71 = v28;
  MEMORY[0x22A672540](&outlined read-only object #0 of MLFewShotSoundClassifier.TemporalClassifier.init(inputChannels:blobsFile:));
  specialized Collection.prefix(_:)(200, v25);
  uint64_t v81 = v29;
  uint64_t v72 = type metadata accessor for ComputeDevice();
  uint64_t v30 = OUTLINED_FUNCTION_36_10();
  __swift_storeEnumTagSinglePayload(v30, v31, v32, v33);
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ArraySlice<Float>);
  lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type ArraySlice<Float> and conformance ArraySlice<A>, &demangling cache variable for type metadata for ArraySlice<Float>);
  Tensor.init<A>(shape:scalars:on:)();
  MEMORY[0x22A672540](&outlined read-only object #1 of MLFewShotSoundClassifier.TemporalClassifier.init(inputChannels:blobsFile:));
  (*(void (**)(uint64_t))(v76 + 104))(v74);
  uint64_t v34 = OUTLINED_FUNCTION_24_17();
  __swift_storeEnumTagSinglePayload(v34, v36, v37, *(void *)(v35 - 256));
  Tensor.init(zeros:scalarType:on:)();
  __swift_storeEnumTagSinglePayload(v73, 0, 1, v21);
  MLFewShotSoundClassifier.CausalConv1D.init(alpha:kernelSize:stride:dilation:weight:bias:)();
  MEMORY[0x22A672540](&outlined read-only object #2 of MLFewShotSoundClassifier.TemporalClassifier.init(inputChannels:blobsFile:));
  specialized Collection.prefix(_:)(160, v26);
  uint64_t v81 = v38;
  uint64_t v39 = OUTLINED_FUNCTION_24_17();
  uint64_t v41 = *(void *)(v40 - 256);
  __swift_storeEnumTagSinglePayload(v39, v42, v43, v41);
  OUTLINED_FUNCTION_38_9();
  MEMORY[0x22A672540](&outlined read-only object #3 of MLFewShotSoundClassifier.TemporalClassifier.init(inputChannels:blobsFile:));
  uint64_t v44 = OUTLINED_FUNCTION_1_31();
  v45(v44);
  uint64_t v46 = OUTLINED_FUNCTION_36_10();
  __swift_storeEnumTagSinglePayload(v46, v47, v48, v41);
  OUTLINED_FUNCTION_20_16();
  OUTLINED_FUNCTION_17_16();
  MLFewShotSoundClassifier.CausalConv1D.init(alpha:kernelSize:stride:dilation:weight:bias:)();
  MEMORY[0x22A672540](&outlined read-only object #4 of MLFewShotSoundClassifier.TemporalClassifier.init(inputChannels:blobsFile:));
  OUTLINED_FUNCTION_13_23();
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Float]);
  lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [Float] and conformance [A], &demangling cache variable for type metadata for [Float]);
  OUTLINED_FUNCTION_48_7();
  Tensor.init<A>(shape:scalars:on:)();
  MEMORY[0x22A672540](&outlined read-only object #5 of MLFewShotSoundClassifier.TemporalClassifier.init(inputChannels:blobsFile:));
  uint64_t v49 = OUTLINED_FUNCTION_1_31();
  v50(v49);
  OUTLINED_FUNCTION_26_13();
  OUTLINED_FUNCTION_20_16();
  OUTLINED_FUNCTION_17_16();
  MLFewShotSoundClassifier.CausalConv1D.init(alpha:kernelSize:stride:dilation:weight:bias:)();
  MEMORY[0x22A672540](&outlined read-only object #6 of MLFewShotSoundClassifier.TemporalClassifier.init(inputChannels:blobsFile:));
  OUTLINED_FUNCTION_13_23();
  OUTLINED_FUNCTION_48_7();
  Tensor.init<A>(shape:scalars:on:)();
  MEMORY[0x22A672540](&outlined read-only object #7 of MLFewShotSoundClassifier.TemporalClassifier.init(inputChannels:blobsFile:));
  uint64_t v51 = OUTLINED_FUNCTION_1_31();
  v52(v51);
  OUTLINED_FUNCTION_13_23();
  OUTLINED_FUNCTION_20_16();
  __swift_storeEnumTagSinglePayload(v73, 0, 1, v21);
  MLFewShotSoundClassifier.CausalConv1D.init(alpha:kernelSize:stride:dilation:weight:bias:)();
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
  uint64_t v53 = swift_allocObject();
  *(_OWORD *)(v53 + 16) = xmmword_2272CB360;
  *(_OWORD *)(v53 + 32) = xmmword_2272CF210;
  *(void *)(v53 + 48) = a1;
  *(void *)(v53 + 56) = 1;
  MEMORY[0x22A672540]();
  uint64_t result = 10 * a1;
  if ((unsigned __int128)(a1 * (__int128)10) >> 64 == (10 * a1) >> 63)
  {
    specialized Collection.prefix(_:)(result, v80);
    uint64_t v81 = v54;
    OUTLINED_FUNCTION_26_13();
    OUTLINED_FUNCTION_38_9();
    MEMORY[0x22A672540](&outlined read-only object #8 of MLFewShotSoundClassifier.TemporalClassifier.init(inputChannels:blobsFile:));
    uint64_t v55 = OUTLINED_FUNCTION_1_31();
    v56(v55);
    OUTLINED_FUNCTION_13_23();
    OUTLINED_FUNCTION_19_16();
    __swift_storeEnumTagSinglePayload(v73, 0, 1, v21);
    uint64_t v57 = Conv2D.init(weight:bias:stride:padding:dilation:groupCount:)();
    *(float *)(v9 + *(int *)(v77 + 20)) = MEMORY[0x22A672DB0](v57, 0.1);
    MLFewShotSoundClassifier.ConvolutionalNetwork.init(causal:featureReduction:)(v71, v9, a3);
    MEMORY[0x22A672540](&outlined read-only object #9 of MLFewShotSoundClassifier.TemporalClassifier.init(inputChannels:blobsFile:));
    uint64_t v58 = OUTLINED_FUNCTION_15_16((uint64_t)&v81);
    __swift_storeEnumTagSinglePayload(v58, v59, v60, v72);
    Tensor.init<A>(shape:scalars:on:)();
    MEMORY[0x22A672540](&outlined read-only object #10 of MLFewShotSoundClassifier.TemporalClassifier.init(inputChannels:blobsFile:));
    uint64_t v61 = OUTLINED_FUNCTION_1_31();
    v62(v61);
    uint64_t v63 = OUTLINED_FUNCTION_36_10();
    __swift_storeEnumTagSinglePayload(v63, v64, v65, v72);
    OUTLINED_FUNCTION_19_16();
    __swift_storeEnumTagSinglePayload(v73, 0, 1, v21);
    type metadata accessor for MLFewShotSoundClassifier.TemporalClassifier(0);
    Dense.init(weight:bias:)();
    MEMORY[0x22A672540](&outlined read-only object #11 of MLFewShotSoundClassifier.TemporalClassifier.init(inputChannels:blobsFile:));
    uint64_t v66 = OUTLINED_FUNCTION_15_16((uint64_t)v82);
    __swift_storeEnumTagSinglePayload(v66, v67, v68, v72);
    Tensor.init<A>(shape:scalars:on:)();
    MEMORY[0x22A672540](&outlined read-only object #12 of MLFewShotSoundClassifier.TemporalClassifier.init(inputChannels:blobsFile:));
    uint64_t v69 = OUTLINED_FUNCTION_1_31();
    v70(v69);
    __swift_storeEnumTagSinglePayload(v3, 1, 1, v72);
    OUTLINED_FUNCTION_19_16();
    __swift_storeEnumTagSinglePayload(v73, 0, 1, v21);
    type metadata accessor for MLFewShotSoundClassifier.MLP(0);
    Dense.init(weight:bias:)();
    return outlined release of BlobsFile(a2);
  }
  __break(1u);
  return result;
}

void MLFewShotSoundClassifier.TemporalClassifier.forward(_:)()
{
  OUTLINED_FUNCTION_19_4();
  type metadata accessor for Tensor();
  OUTLINED_FUNCTION_0();
  uint64_t v2 = v1;
  MEMORY[0x270FA5388](v3);
  OUTLINED_FUNCTION_49();
  v14[1] = v4;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v5);
  v14[0] = (char *)v14 - v6;
  OUTLINED_FUNCTION_20_3();
  MEMORY[0x270FA5388](v7);
  OUTLINED_FUNCTION_47_8();
  MEMORY[0x270FA5388](v8);
  uint64_t v9 = OUTLINED_FUNCTION_44_6();
  uint64_t v10 = type metadata accessor for MLFewShotSoundClassifier.ConvolutionalNetwork.Output(v9);
  MEMORY[0x270FA5388](v10);
  uint64_t v11 = OUTLINED_FUNCTION_9_23();
  type metadata accessor for MLFewShotSoundClassifier.ConvolutionalNetwork(v11);
  lazy protocol witness table accessor for type MLFewShotSoundClassifier.LeakyConv2D and conformance MLFewShotSoundClassifier.LeakyConv2D(&lazy protocol witness table cache variable for type MLFewShotSoundClassifier.ConvolutionalNetwork and conformance MLFewShotSoundClassifier.ConvolutionalNetwork, (void (*)(uint64_t))type metadata accessor for MLFewShotSoundClassifier.ConvolutionalNetwork);
  Layer.callAsFunction(_:)();
  type metadata accessor for MLFewShotSoundClassifier.TemporalClassifier(0);
  type metadata accessor for MLFewShotSoundClassifier.MLP(0);
  lazy protocol witness table accessor for type MLFewShotSoundClassifier.LeakyConv2D and conformance MLFewShotSoundClassifier.LeakyConv2D(&lazy protocol witness table cache variable for type MLFewShotSoundClassifier.MLP and conformance MLFewShotSoundClassifier.MLP, (void (*)(uint64_t))type metadata accessor for MLFewShotSoundClassifier.MLP);
  Layer.callAsFunction(_:)();
  uint64_t v12 = *(void (**)(void))(v2 + 16);
  OUTLINED_FUNCTION_27_13();
  v12();
  OUTLINED_FUNCTION_27_13();
  v12();
  OUTLINED_FUNCTION_27_13();
  v12();
  outlined destroy of MLFewShotSoundClassifier.ConvolutionalNetwork.Output(v0);
  uint64_t v13 = *(void (**)(void))(v2 + 32);
  OUTLINED_FUNCTION_16_17();
  v13();
  type metadata accessor for MLFewShotSoundClassifier.TemporalClassifier.Output(0);
  OUTLINED_FUNCTION_16_17();
  v13();
  OUTLINED_FUNCTION_16_17();
  v13();
  OUTLINED_FUNCTION_16_17();
  v13();
  OUTLINED_FUNCTION_12_4();
}

uint64_t protocol witness for _ComputeDevicePlaceable.place(on:) in conformance MLFewShotSoundClassifier.TemporalClassifier()
{
  lazy protocol witness table accessor for type MLFewShotSoundClassifier.LeakyConv2D and conformance MLFewShotSoundClassifier.LeakyConv2D((unint64_t *)&lazy protocol witness table cache variable for type MLFewShotSoundClassifier.TemporalClassifier and conformance MLFewShotSoundClassifier.TemporalClassifier, (void (*)(uint64_t))type metadata accessor for MLFewShotSoundClassifier.TemporalClassifier);

  return Layer.place(on:)();
}

uint64_t protocol witness for _ComputeDevicePlaceable.placed(on:) in conformance MLFewShotSoundClassifier.TemporalClassifier()
{
  lazy protocol witness table accessor for type MLFewShotSoundClassifier.LeakyConv2D and conformance MLFewShotSoundClassifier.LeakyConv2D((unint64_t *)&lazy protocol witness table cache variable for type MLFewShotSoundClassifier.TemporalClassifier and conformance MLFewShotSoundClassifier.TemporalClassifier, (void (*)(uint64_t))type metadata accessor for MLFewShotSoundClassifier.TemporalClassifier);

  return Layer.placed(on:)();
}

uint64_t base witness table accessor for _BaseLayer in MLFewShotSoundClassifier.LeakyConv2D()
{
  return lazy protocol witness table accessor for type MLFewShotSoundClassifier.LeakyConv2D and conformance MLFewShotSoundClassifier.LeakyConv2D(&lazy protocol witness table cache variable for type MLFewShotSoundClassifier.LeakyConv2D and conformance MLFewShotSoundClassifier.LeakyConv2D, (void (*)(uint64_t))type metadata accessor for MLFewShotSoundClassifier.LeakyConv2D);
}

uint64_t base witness table accessor for _ComputeDevicePlaceable in MLFewShotSoundClassifier.LeakyConv2D()
{
  return lazy protocol witness table accessor for type MLFewShotSoundClassifier.LeakyConv2D and conformance MLFewShotSoundClassifier.LeakyConv2D(&lazy protocol witness table cache variable for type MLFewShotSoundClassifier.LeakyConv2D and conformance MLFewShotSoundClassifier.LeakyConv2D, (void (*)(uint64_t))type metadata accessor for MLFewShotSoundClassifier.LeakyConv2D);
}

uint64_t lazy protocol witness table accessor for type MLFewShotSoundClassifier.LeakyConv2D and conformance MLFewShotSoundClassifier.LeakyConv2D(unint64_t *a1, void (*a2)(uint64_t))
{
  uint64_t result = *a1;
  if (!result)
  {
    a2(255);
    uint64_t result = swift_getWitnessTable();
    atomic_store(result, a1);
  }
  return result;
}

uint64_t base witness table accessor for _Differentiable in MLFewShotSoundClassifier.LeakyConv2D()
{
  return lazy protocol witness table accessor for type MLFewShotSoundClassifier.LeakyConv2D and conformance MLFewShotSoundClassifier.LeakyConv2D(&lazy protocol witness table cache variable for type MLFewShotSoundClassifier.LeakyConv2D and conformance MLFewShotSoundClassifier.LeakyConv2D, (void (*)(uint64_t))type metadata accessor for MLFewShotSoundClassifier.LeakyConv2D);
}

uint64_t base witness table accessor for _BaseLayer in MLFewShotSoundClassifier.ConvolutionalNetwork()
{
  return lazy protocol witness table accessor for type MLFewShotSoundClassifier.LeakyConv2D and conformance MLFewShotSoundClassifier.LeakyConv2D(&lazy protocol witness table cache variable for type MLFewShotSoundClassifier.ConvolutionalNetwork and conformance MLFewShotSoundClassifier.ConvolutionalNetwork, (void (*)(uint64_t))type metadata accessor for MLFewShotSoundClassifier.ConvolutionalNetwork);
}

uint64_t base witness table accessor for _ComputeDevicePlaceable in MLFewShotSoundClassifier.ConvolutionalNetwork()
{
  return lazy protocol witness table accessor for type MLFewShotSoundClassifier.LeakyConv2D and conformance MLFewShotSoundClassifier.LeakyConv2D(&lazy protocol witness table cache variable for type MLFewShotSoundClassifier.ConvolutionalNetwork and conformance MLFewShotSoundClassifier.ConvolutionalNetwork, (void (*)(uint64_t))type metadata accessor for MLFewShotSoundClassifier.ConvolutionalNetwork);
}

uint64_t base witness table accessor for _Differentiable in MLFewShotSoundClassifier.ConvolutionalNetwork()
{
  return lazy protocol witness table accessor for type MLFewShotSoundClassifier.LeakyConv2D and conformance MLFewShotSoundClassifier.LeakyConv2D(&lazy protocol witness table cache variable for type MLFewShotSoundClassifier.ConvolutionalNetwork and conformance MLFewShotSoundClassifier.ConvolutionalNetwork, (void (*)(uint64_t))type metadata accessor for MLFewShotSoundClassifier.ConvolutionalNetwork);
}

uint64_t base witness table accessor for _BaseLayer in MLFewShotSoundClassifier.CausalConv1D()
{
  return lazy protocol witness table accessor for type MLFewShotSoundClassifier.LeakyConv2D and conformance MLFewShotSoundClassifier.LeakyConv2D(&lazy protocol witness table cache variable for type MLFewShotSoundClassifier.CausalConv1D and conformance MLFewShotSoundClassifier.CausalConv1D, (void (*)(uint64_t))type metadata accessor for MLFewShotSoundClassifier.CausalConv1D);
}

uint64_t base witness table accessor for _ComputeDevicePlaceable in MLFewShotSoundClassifier.CausalConv1D()
{
  return lazy protocol witness table accessor for type MLFewShotSoundClassifier.LeakyConv2D and conformance MLFewShotSoundClassifier.LeakyConv2D(&lazy protocol witness table cache variable for type MLFewShotSoundClassifier.CausalConv1D and conformance MLFewShotSoundClassifier.CausalConv1D, (void (*)(uint64_t))type metadata accessor for MLFewShotSoundClassifier.CausalConv1D);
}

uint64_t base witness table accessor for _Differentiable in MLFewShotSoundClassifier.CausalConv1D()
{
  return lazy protocol witness table accessor for type MLFewShotSoundClassifier.LeakyConv2D and conformance MLFewShotSoundClassifier.LeakyConv2D(&lazy protocol witness table cache variable for type MLFewShotSoundClassifier.CausalConv1D and conformance MLFewShotSoundClassifier.CausalConv1D, (void (*)(uint64_t))type metadata accessor for MLFewShotSoundClassifier.CausalConv1D);
}

uint64_t base witness table accessor for _BaseLayer in MLFewShotSoundClassifier.MLP()
{
  return lazy protocol witness table accessor for type MLFewShotSoundClassifier.LeakyConv2D and conformance MLFewShotSoundClassifier.LeakyConv2D(&lazy protocol witness table cache variable for type MLFewShotSoundClassifier.MLP and conformance MLFewShotSoundClassifier.MLP, (void (*)(uint64_t))type metadata accessor for MLFewShotSoundClassifier.MLP);
}

uint64_t base witness table accessor for _ComputeDevicePlaceable in MLFewShotSoundClassifier.MLP()
{
  return lazy protocol witness table accessor for type MLFewShotSoundClassifier.LeakyConv2D and conformance MLFewShotSoundClassifier.LeakyConv2D(&lazy protocol witness table cache variable for type MLFewShotSoundClassifier.MLP and conformance MLFewShotSoundClassifier.MLP, (void (*)(uint64_t))type metadata accessor for MLFewShotSoundClassifier.MLP);
}

uint64_t base witness table accessor for _Differentiable in MLFewShotSoundClassifier.MLP()
{
  return lazy protocol witness table accessor for type MLFewShotSoundClassifier.LeakyConv2D and conformance MLFewShotSoundClassifier.LeakyConv2D(&lazy protocol witness table cache variable for type MLFewShotSoundClassifier.MLP and conformance MLFewShotSoundClassifier.MLP, (void (*)(uint64_t))type metadata accessor for MLFewShotSoundClassifier.MLP);
}

uint64_t base witness table accessor for _BaseLayer in MLFewShotSoundClassifier.TemporalClassifier()
{
  return lazy protocol witness table accessor for type MLFewShotSoundClassifier.LeakyConv2D and conformance MLFewShotSoundClassifier.LeakyConv2D(&lazy protocol witness table cache variable for type MLFewShotSoundClassifier.TemporalClassifier and conformance MLFewShotSoundClassifier.TemporalClassifier, (void (*)(uint64_t))type metadata accessor for MLFewShotSoundClassifier.TemporalClassifier);
}

uint64_t base witness table accessor for _ComputeDevicePlaceable in MLFewShotSoundClassifier.TemporalClassifier()
{
  return lazy protocol witness table accessor for type MLFewShotSoundClassifier.LeakyConv2D and conformance MLFewShotSoundClassifier.LeakyConv2D(&lazy protocol witness table cache variable for type MLFewShotSoundClassifier.TemporalClassifier and conformance MLFewShotSoundClassifier.TemporalClassifier, (void (*)(uint64_t))type metadata accessor for MLFewShotSoundClassifier.TemporalClassifier);
}

uint64_t base witness table accessor for _Differentiable in MLFewShotSoundClassifier.TemporalClassifier()
{
  return lazy protocol witness table accessor for type MLFewShotSoundClassifier.LeakyConv2D and conformance MLFewShotSoundClassifier.LeakyConv2D(&lazy protocol witness table cache variable for type MLFewShotSoundClassifier.TemporalClassifier and conformance MLFewShotSoundClassifier.TemporalClassifier, (void (*)(uint64_t))type metadata accessor for MLFewShotSoundClassifier.TemporalClassifier);
}

uint64_t type metadata accessor for MLFewShotSoundClassifier.ConvolutionalNetwork.Output(uint64_t a1)
{
  return type metadata accessor for MLImageClassifier.CustomFeatureExtractor(a1, (uint64_t *)&type metadata singleton initialization cache for MLFewShotSoundClassifier.ConvolutionalNetwork.Output);
}

uint64_t outlined destroy of MLFewShotSoundClassifier.ConvolutionalNetwork.Output(uint64_t a1)
{
  uint64_t v2 = type metadata accessor for MLFewShotSoundClassifier.ConvolutionalNetwork.Output(0);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v2 - 8) + 8))(a1, v2);
  return a1;
}

uint64_t type metadata accessor for MLFewShotSoundClassifier.TemporalClassifier.Output(uint64_t a1)
{
  return type metadata accessor for MLImageClassifier.CustomFeatureExtractor(a1, (uint64_t *)&type metadata singleton initialization cache for MLFewShotSoundClassifier.TemporalClassifier.Output);
}

unint64_t lazy protocol witness table accessor for type MLFewShotSoundClassifier.CausalPadding and conformance MLFewShotSoundClassifier.CausalPadding()
{
  unint64_t result = lazy protocol witness table cache variable for type MLFewShotSoundClassifier.CausalPadding and conformance MLFewShotSoundClassifier.CausalPadding;
  if (!lazy protocol witness table cache variable for type MLFewShotSoundClassifier.CausalPadding and conformance MLFewShotSoundClassifier.CausalPadding)
  {
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type MLFewShotSoundClassifier.CausalPadding and conformance MLFewShotSoundClassifier.CausalPadding);
  }
  return result;
}

{
  unint64_t result;

  unint64_t result = lazy protocol witness table cache variable for type MLFewShotSoundClassifier.CausalPadding and conformance MLFewShotSoundClassifier.CausalPadding;
  if (!lazy protocol witness table cache variable for type MLFewShotSoundClassifier.CausalPadding and conformance MLFewShotSoundClassifier.CausalPadding)
  {
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type MLFewShotSoundClassifier.CausalPadding and conformance MLFewShotSoundClassifier.CausalPadding);
  }
  return result;
}

{
  unint64_t result;

  unint64_t result = lazy protocol witness table cache variable for type MLFewShotSoundClassifier.CausalPadding and conformance MLFewShotSoundClassifier.CausalPadding;
  if (!lazy protocol witness table cache variable for type MLFewShotSoundClassifier.CausalPadding and conformance MLFewShotSoundClassifier.CausalPadding)
  {
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type MLFewShotSoundClassifier.CausalPadding and conformance MLFewShotSoundClassifier.CausalPadding);
  }
  return result;
}

{
  unint64_t result;

  unint64_t result = lazy protocol witness table cache variable for type MLFewShotSoundClassifier.CausalPadding and conformance MLFewShotSoundClassifier.CausalPadding;
  if (!lazy protocol witness table cache variable for type MLFewShotSoundClassifier.CausalPadding and conformance MLFewShotSoundClassifier.CausalPadding)
  {
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type MLFewShotSoundClassifier.CausalPadding and conformance MLFewShotSoundClassifier.CausalPadding);
  }
  return result;
}

uint64_t outlined init with copy of MLFewShotSoundClassifier.CausalConv1D(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = type metadata accessor for MLFewShotSoundClassifier.CausalConv1D(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 16))(a2, a1, v4);
  return a2;
}

uint64_t outlined init with take of MLFewShotSoundClassifier.LeakyConv2D(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = type metadata accessor for MLFewShotSoundClassifier.LeakyConv2D(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 32))(a2, a1, v4);
  return a2;
}

uint64_t getEnumTagSinglePayload for MLFewShotSoundClassifier.TemporalClassifier.Output(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return MEMORY[0x270FA0340](a1, a2, a3, sub_227151618);
}

uint64_t sub_227151618()
{
  return __swift_get_extra_inhabitant_indexTm();
}

uint64_t storeEnumTagSinglePayload for MLFewShotSoundClassifier.TemporalClassifier.Output(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return MEMORY[0x270FA0580](a1, a2, a3, a4, sub_227151644);
}

uint64_t sub_227151644()
{
  return __swift_store_extra_inhabitant_indexTm();
}

uint64_t *initializeBufferWithCopyOfBuffer for MLFewShotSoundClassifier.TemporalClassifier.Output(uint64_t *a1, uint64_t *a2)
{
  OUTLINED_FUNCTION_2_39();
  int v5 = *(_DWORD *)(v4 + 80);
  if ((v5 & 0x20000) != 0)
  {
    uint64_t v9 = *a2;
    *a1 = *a2;
    a1 = (uint64_t *)(v9 + ((v5 + 16) & ~(unint64_t)v5));
    swift_retain();
  }
  else
  {
    uint64_t v6 = type metadata accessor for Tensor();
    OUTLINED_FUNCTION_8();
    uint64_t v8 = *(void (**)(void))(v7 + 16);
    ((void (*)(uint64_t *, uint64_t *, uint64_t))v8)(a1, a2, v6);
    OUTLINED_FUNCTION_4_33();
    v8();
    OUTLINED_FUNCTION_4_33();
    v8();
    OUTLINED_FUNCTION_4_33();
    v8();
  }
  return a1;
}

uint64_t destroy for MLFewShotSoundClassifier.TemporalClassifier.Output(uint64_t a1, int *a2)
{
  uint64_t v4 = type metadata accessor for Tensor();
  OUTLINED_FUNCTION_8();
  uint64_t v12 = *(void (**)(uint64_t, uint64_t))(v5 + 8);
  v12(a1, v4);
  uint64_t v6 = OUTLINED_FUNCTION_32_11(a2[5]);
  v7(v6);
  uint64_t v8 = OUTLINED_FUNCTION_32_11(a2[6]);
  v9(v8);
  uint64_t v10 = a1 + a2[7];

  return ((uint64_t (*)(uint64_t, uint64_t))v12)(v10, v4);
}

uint64_t initializeWithCopy for MLFewShotSoundClassifier.TemporalClassifier.Output()
{
  OUTLINED_FUNCTION_12_16();
  OUTLINED_FUNCTION_8();
  uint64_t v2 = *(void (**)(void))(v1 + 16);
  uint64_t v3 = OUTLINED_FUNCTION_11_21();
  ((void (*)(uint64_t))v2)(v3);
  OUTLINED_FUNCTION_4_33();
  v2();
  OUTLINED_FUNCTION_4_33();
  v2();
  OUTLINED_FUNCTION_4_33();
  v2();
  return v0;
}

uint64_t assignWithCopy for MLFewShotSoundClassifier.TemporalClassifier.Output()
{
  OUTLINED_FUNCTION_12_16();
  OUTLINED_FUNCTION_8();
  uint64_t v2 = *(void (**)(uint64_t))(v1 + 24);
  uint64_t v3 = OUTLINED_FUNCTION_11_21();
  v2(v3);
  uint64_t v4 = OUTLINED_FUNCTION_7_25();
  v2(v4);
  uint64_t v5 = OUTLINED_FUNCTION_6_25();
  v2(v5);
  uint64_t v6 = OUTLINED_FUNCTION_5_28();
  v2(v6);
  return v0;
}

uint64_t initializeWithTake for MLFewShotSoundClassifier.TemporalClassifier.Output()
{
  OUTLINED_FUNCTION_12_16();
  OUTLINED_FUNCTION_8();
  uint64_t v2 = *(void (**)(uint64_t))(v1 + 32);
  uint64_t v3 = OUTLINED_FUNCTION_11_21();
  v2(v3);
  uint64_t v4 = OUTLINED_FUNCTION_7_25();
  v2(v4);
  uint64_t v5 = OUTLINED_FUNCTION_6_25();
  v2(v5);
  uint64_t v6 = OUTLINED_FUNCTION_5_28();
  v2(v6);
  return v0;
}

uint64_t assignWithTake for MLFewShotSoundClassifier.TemporalClassifier.Output()
{
  OUTLINED_FUNCTION_12_16();
  OUTLINED_FUNCTION_8();
  uint64_t v2 = *(void (**)(uint64_t))(v1 + 40);
  uint64_t v3 = OUTLINED_FUNCTION_11_21();
  v2(v3);
  uint64_t v4 = OUTLINED_FUNCTION_7_25();
  v2(v4);
  uint64_t v5 = OUTLINED_FUNCTION_6_25();
  v2(v5);
  uint64_t v6 = OUTLINED_FUNCTION_5_28();
  v2(v6);
  return v0;
}

uint64_t getEnumTagSinglePayload for MLFewShotSoundClassifier.ConvolutionalNetwork.Output(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return MEMORY[0x270FA0340](a1, a2, a3, sub_2271519F4);
}

uint64_t sub_2271519F4()
{
  return __swift_get_extra_inhabitant_indexTm();
}

uint64_t __swift_get_extra_inhabitant_indexTm()
{
  uint64_t v0 = OUTLINED_FUNCTION_50_7();
  v1(v0);
  uint64_t v2 = OUTLINED_FUNCTION_37_7();

  return __swift_getEnumTagSinglePayload(v2, v3, v4);
}

uint64_t storeEnumTagSinglePayload for MLFewShotSoundClassifier.ConvolutionalNetwork.Output(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return MEMORY[0x270FA0580](a1, a2, a3, a4, sub_227151A58);
}

uint64_t sub_227151A58()
{
  return __swift_store_extra_inhabitant_indexTm();
}

uint64_t __swift_store_extra_inhabitant_indexTm()
{
  uint64_t v0 = OUTLINED_FUNCTION_50_7();
  v1(v0);
  uint64_t v2 = OUTLINED_FUNCTION_21_17();

  return __swift_storeEnumTagSinglePayload(v2, v3, v4, v5);
}

uint64_t type metadata completion function for MLFewShotSoundClassifier.TemporalClassifier.Output()
{
  uint64_t result = type metadata accessor for Tensor();
  if (v1 <= 0x3F)
  {
    swift_initStructMetadata();
    return 0;
  }
  return result;
}

ValueMetadata *type metadata accessor for MLFewShotSoundClassifier.CausalPadding()
{
  return &type metadata for MLFewShotSoundClassifier.CausalPadding;
}

uint64_t OUTLINED_FUNCTION_1_31()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_5_28()
{
  return v1 + *(int *)(v0 + 28);
}

uint64_t OUTLINED_FUNCTION_6_25()
{
  return v1 + *(int *)(v0 + 24);
}

uint64_t OUTLINED_FUNCTION_7_25()
{
  return v1 + *(int *)(v0 + 20);
}

uint64_t OUTLINED_FUNCTION_8_23()
{
  return 8;
}

uint64_t OUTLINED_FUNCTION_9_23()
{
  return 0;
}

uint64_t OUTLINED_FUNCTION_11_21()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_12_16()
{
  return type metadata accessor for Tensor();
}

uint64_t OUTLINED_FUNCTION_13_23()
{
  return __swift_storeEnumTagSinglePayload(v1, 1, 1, v0);
}

uint64_t OUTLINED_FUNCTION_15_16@<X0>(uint64_t a1@<X8>)
{
  *(void *)(v2 - 120) = *(void *)(a1 - 256);
  return v1;
}

uint64_t OUTLINED_FUNCTION_17_16()
{
  __swift_storeEnumTagSinglePayload(v0, 0, 1, *(void *)(v1 - 256));
  return 5;
}

uint64_t OUTLINED_FUNCTION_19_16()
{
  return Tensor.init(zeros:scalarType:on:)();
}

uint64_t OUTLINED_FUNCTION_20_16()
{
  return Tensor.init(zeros:scalarType:on:)();
}

uint64_t OUTLINED_FUNCTION_21_17()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_24_17()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_26_13()
{
  uint64_t v3 = *(void *)(v1 - 264);
  return __swift_storeEnumTagSinglePayload(v0, 1, 1, v3);
}

uint64_t OUTLINED_FUNCTION_31_8()
{
  return 0xFFFFFFFLL;
}

uint64_t OUTLINED_FUNCTION_32_11@<X0>(uint64_t a1@<X8>)
{
  return v1 + a1;
}

uint64_t OUTLINED_FUNCTION_36_10()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_37_7()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_38_9()
{
  return Tensor.init<A>(shape:scalars:on:)();
}

uint64_t OUTLINED_FUNCTION_39_9()
{
  return outlined release of BlobsFile(v0);
}

uint64_t OUTLINED_FUNCTION_44_6()
{
  return 0;
}

uint64_t OUTLINED_FUNCTION_45_6()
{
  return __swift_storeEnumTagSinglePayload(v0, 1, 1, v1);
}

uint64_t OUTLINED_FUNCTION_46_8()
{
  return Layer.callAsFunction(_:)();
}

uint64_t OUTLINED_FUNCTION_48_7()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_49_3()
{
  return 0;
}

uint64_t OUTLINED_FUNCTION_50_7()
{
  return 0;
}

uint64_t static MLHandActionClassifier.__Defaults.batchSize.getter()
{
  return 32;
}

uint64_t static MLHandActionClassifier.__Defaults.maximumIterations.getter()
{
  return 80;
}

uint64_t static MLHandActionClassifier.__Defaults.predictionWindowSize.getter()
{
  return 30;
}

double static MLHandActionClassifier.__Defaults.targetFrameRate.getter()
{
  return 30.0;
}

uint64_t static MLHandActionClassifier.__Defaults.sessionIdColumnName.getter()
{
  return 0x5F6E6F6973736573;
}

uint64_t static MLHandActionClassifier.__Defaults.featureColumnName.getter()
{
  return 0x746E696F7079656BLL;
}

uint64_t static MLHandActionClassifier.__Defaults.labelColumnName.getter()
{
  return 0x6C6562616CLL;
}

uint64_t static MLHandActionClassifier.__Defaults.videoColumnName.getter()
{
  return 0x7461506F65646976;
}

uint64_t static MLHandActionClassifier.__Defaults.startTimeColumnName.getter()
{
  return 0x7472617473;
}

uint64_t static MLHandActionClassifier.__Defaults.endTimeColumnName.getter()
{
  return 6581861;
}

ValueMetadata *type metadata accessor for MLHandActionClassifier.__Defaults()
{
  return &type metadata for MLHandActionClassifier.__Defaults;
}

void specialized MLDataColumn.dropMissing()(id a1@<X0>, char a2@<W1>, uint64_t a3@<X8>)
{
  if (a2)
  {
    id v7 = a1;
    outlined copy of Result<_DataTable, Error>(a1, 1);
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    uint64_t v8 = _getErrorEmbeddedNSError<A>(_:)();
    if (v8)
    {
      uint64_t v9 = v8;
      outlined consume of Result<_DataTable, Error>(a1, 1);
    }
    else
    {
      uint64_t v9 = OUTLINED_FUNCTION_85();
      *uint64_t v13 = a1;
    }
    char v12 = 1;
    outlined consume of Result<_DataTable, Error>(a1, 1);
    goto LABEL_9;
  }
  uint64_t v5 = *(void *)(*((void *)a1 + 2) + 16);
  outlined copy of Result<_DataTable, Error>(a1, 0);
  uint64_t v6 = specialized handling<A, B>(_:_:)(v5);
  uint64_t v10 = v6;
  if (v6)
  {
    type metadata accessor for CMLColumn();
    uint64_t v11 = OUTLINED_FUNCTION_70();
    *(void *)(v11 + 16) = v10;
    type metadata accessor for _UntypedColumn();
    uint64_t v9 = OUTLINED_FUNCTION_70();
    *(void *)(v9 + 16) = v11;
    outlined consume of Result<_DataTable, Error>(a1, 0);
    char v12 = 0;
LABEL_9:
    *(void *)a3 = v9;
    *(unsigned char *)(a3 + 8) = v12;
    return;
  }
  __break(1u);
}

void specialized MLDataTable.subscript.setter(void *a1, char a2)
{
  MLDataTable.willMutate()();
  uint64_t v6 = a1;
  a2 &= 1u;
  char v7 = a2;
  MLDataTable.setColumnImpl(newColumn:named:)((uint64_t *)&v6);
  swift_bridgeObjectRelease();
  outlined consume of Result<_DataTable, Error>(a1, a2);
  if ((*(unsigned char *)(v2 + 8) & 1) == 0)
  {
    uint64_t v5 = *(void **)v2;
    outlined copy of Result<_DataTable, Error>(v5, 0);
    _DataTable.columnNamesDidChange()();
    outlined consume of Result<_DataTable, Error>(v5, 0);
  }
}

uint64_t _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay10Foundation3URLVG_SSs5NeverOTg5148_s8CreateML15_VideoUtilitiesV08generateC5TableyAA06MLDataF0VSDySSSay10Foundation3URLVGGKFZSSAIcfu0_33_43697e1f61f7e10b647d882195ad8775AISSTf3nnnpk_nTf1cn_n(uint64_t a1)
{
  uint64_t v1 = *(void *)(a1 + 16);
  uint64_t v2 = MEMORY[0x263F8EE78];
  if (v1)
  {
    uint64_t v13 = MEMORY[0x263F8EE78];
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
    uint64_t v2 = v13;
    uint64_t v4 = *(void *)(type metadata accessor for URL() - 8);
    uint64_t v5 = a1 + ((*(unsigned __int8 *)(v4 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v4 + 80));
    uint64_t v6 = *(void *)(v4 + 72);
    do
    {
      uint64_t v7 = URL.path.getter();
      uint64_t v9 = v8;
      unint64_t v10 = *(void *)(v13 + 16);
      if (v10 >= *(void *)(v13 + 24) >> 1) {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
      }
      *(void *)(v13 + 16) = v10 + 1;
      uint64_t v11 = v13 + 16 * v10;
      *(void *)(v11 + 32) = v7;
      *(void *)(v11 + 40) = v9;
      v5 += v6;
      --v1;
    }
    while (v1);
  }
  return v2;
}

id static _VideoUtilities.getHandKeyPointsFromImageUrl(url:)(uint64_t a1)
{
  v37[3] = *(id *)MEMORY[0x263EF8340];
  uint64_t v36 = type metadata accessor for URL();
  OUTLINED_FUNCTION_0_15();
  uint64_t v3 = v2;
  uint64_t v5 = *(void *)(v4 + 64);
  MEMORY[0x270FA5388](v6);
  uint64_t v7 = *(void (**)(char *, uint64_t))(v3 + 16);
  v7((char *)v32 - ((v5 + 15) & 0xFFFFFFFFFFFFFFF0), a1);
  type metadata accessor for VNImageOption(0);
  lazy protocol witness table accessor for type URL and conformance URL(&lazy protocol witness table cache variable for type VNImageOption and conformance VNImageOption, type metadata accessor for VNImageOption);
  uint64_t v8 = MEMORY[0x263F8EE78];
  Dictionary.init(dictionaryLiteral:)();
  id v9 = objc_allocWithZone(MEMORY[0x263F1EF40]);
  id v35 = @nonobjc VNImageRequestHandler.init(url:options:)((uint64_t)v32 - ((v5 + 15) & 0xFFFFFFFFFFFFFFF0), v10);
  uint64_t v11 = OUTLINED_FUNCTION_70();
  uint64_t v34 = v11;
  *(void *)(v11 + 16) = v8;
  v32[1] = v11 + 16;
  uint64_t v12 = OUTLINED_FUNCTION_70();
  *(void *)(v12 + 16) = 0;
  uint64_t v33 = (id *)(v12 + 16);
  uint64_t v13 = OUTLINED_FUNCTION_70();
  *(void *)(v13 + 16) = 0;
  uint64_t v14 = a1;
  uint64_t v15 = v36;
  ((void (*)(char *, uint64_t, uint64_t))v7)((char *)v32 - ((v5 + 15) & 0xFFFFFFFFFFFFFFF0), v14, v36);
  unint64_t v16 = (*(unsigned __int8 *)(v3 + 80) + 24) & ~(unint64_t)*(unsigned __int8 *)(v3 + 80);
  unint64_t v17 = (v5 + v16 + 7) & 0xFFFFFFFFFFFFFFF8;
  uint64_t v18 = swift_allocObject();
  *(void *)(v18 + 16) = v12;
  (*(void (**)(unint64_t, char *, uint64_t))(v3 + 32))(v18 + v16, (char *)v32 - ((v5 + 15) & 0xFFFFFFFFFFFFFFF0), v15);
  *(void *)(v18 + v17) = v13;
  uint64_t v20 = v34;
  uint64_t v19 = v35;
  *(void *)(v18 + ((v17 + 15) & 0xFFFFFFFFFFFFFFF8)) = v34;
  objc_allocWithZone(MEMORY[0x263F1EEA0]);
  swift_retain();
  swift_retain();
  swift_retain();
  id v21 = @nonobjc VNDetectHumanHandPoseRequest.init(completionHandler:)((uint64_t)partial apply for closure #1 in static _VideoUtilities.getHandKeyPointsFromVideoUrl(url:startTime:endTime:targetFrameRate:), v18);
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Swift.AnyObject>);
  uint64_t v22 = OUTLINED_FUNCTION_55_7();
  *(_OWORD *)(v22 + 16) = xmmword_2272CBA80;
  *(void *)(v22 + 32) = v21;
  v37[0] = (id)v22;
  specialized Array._endMutation()();
  type metadata accessor for NSAttributedString(0, &lazy cache variable for type metadata for VNRequest);
  id v23 = v21;
  Class isa = Array._bridgeToObjectiveC()().super.isa;
  swift_bridgeObjectRelease();
  v37[0] = 0;
  LODWORD(v5) = objc_msgSend(v19, sel_performRequests_error_, isa, v37);

  id v25 = v37[0];
  if (v5)
  {
    uint64_t v26 = v33;
    OUTLINED_FUNCTION_30_11();
    id v27 = *v26;
    if (!v27)
    {
      id v31 = v25;

      swift_beginAccess();
      id v27 = *(id *)(v20 + 16);
      swift_bridgeObjectRetain();
      swift_release();
      swift_release();
      swift_release();
      return v27;
    }
    id v28 = v25;
    id v29 = v27;
    swift_willThrow();

    swift_release();
    swift_release();
    swift_release();
  }
  else
  {
    id v27 = v37[0];
    _convertNSErrorToError(_:)();

    swift_willThrow();
    swift_release();
    swift_release();
    swift_release();
  }
  return v27;
}

uint64_t static _VideoUtilities.generatePredictionWindows(frameKeypoints:windowSize:numOfKeypoints:)(unint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v7 = a2;
  unint64_t v8 = a1;
  int64_t v9 = a1 & 0xFFFFFFFFFFFFFF8;
  unint64_t v10 = a1 >> 62;
  if (a1 >> 62) {
    goto LABEL_85;
  }
  uint64_t v3 = *(void *)((a1 & 0xFFFFFFFFFFFFFF8) + 0x10);
  if (a2)
  {
    do
    {
      int64_t v9 = 0x8000000000000000;
      if (v3 == 0x8000000000000000 && v7 == -1) {
        goto LABEL_90;
      }
      uint64_t v12 = v3 / v7;
      if (v3 / v7 < 0) {
        goto LABEL_87;
      }
      uint64_t v50 = a3;
      int64_t v51 = v3;
      uint64_t v5 = MEMORY[0x263F8EE78];
      unint64_t v55 = v10;
      if (!v12)
      {
LABEL_45:
        int64_t v9 = v51 - v12 * v7;
        if (v9 < 1) {
          return v5;
        }
        uint64_t v4 = v12 * v7;
        if ((unsigned __int128)(v12 * (__int128)v7) >> 64 != (v12 * v7) >> 63) {
          goto LABEL_88;
        }
        uint64_t v28 = v7 - v9;
        if (__OFSUB__(v7, v9)) {
          goto LABEL_89;
        }
        uint64_t v58 = MEMORY[0x263F8EE78];
        specialized ContiguousArray.reserveCapacity(_:)();
        objc_msgSend(objc_allocWithZone(NSNumber), sel_initWithInteger_, v28);
        specialized ContiguousArray._makeUniqueAndReserveCapacityIfNotUnique()();
        OUTLINED_FUNCTION_28_11();
        specialized ContiguousArray._appendElementAssumeUniqueAndCapacity(_:newElement:)();
        specialized ContiguousArray._endMutation()();
        objc_msgSend(objc_allocWithZone(NSNumber), sel_initWithInteger_, 3);
        specialized ContiguousArray._makeUniqueAndReserveCapacityIfNotUnique()();
        OUTLINED_FUNCTION_28_11();
        specialized ContiguousArray._appendElementAssumeUniqueAndCapacity(_:newElement:)();
        specialized ContiguousArray._endMutation()();
        objc_msgSend(objc_allocWithZone(NSNumber), sel_initWithInteger_, v50);
        specialized ContiguousArray._makeUniqueAndReserveCapacityIfNotUnique()();
        OUTLINED_FUNCTION_28_11();
        specialized ContiguousArray._appendElementAssumeUniqueAndCapacity(_:newElement:)();
        specialized ContiguousArray._endMutation()();
        uint64_t v29 = v58;
        id v30 = objc_allocWithZone(MEMORY[0x263F00DA8]);
        id v31 = @nonobjc MLMultiArray.init(shape:dataType:)(v58, 65600);
        if (v52)
        {
          swift_bridgeObjectRelease();
          return v5;
        }
        uint64_t v32 = v31;
        uint64_t result = (uint64_t)static _VideoUtilities.resetMultiArray(_:with:)(v31, 0.0);
        int64_t v9 = v51;
        if (v51 < v4) {
          goto LABEL_91;
        }
        if (v55)
        {
          OUTLINED_FUNCTION_17_17();
          _CocoaArrayWrapper.endIndex.getter();
          uint64_t result = OUTLINED_FUNCTION_23_8();
        }
        else
        {
          int64_t v9 = v8 & 0xFFFFFFFFFFFFFF8;
          uint64_t v29 = *(void *)((v8 & 0xFFFFFFFFFFFFFF8) + 0x10);
        }
        if (v29 < v4) {
          goto LABEL_92;
        }
        if (v4 < 0) {
          goto LABEL_93;
        }
        if (v55)
        {
          OUTLINED_FUNCTION_17_17();
          _CocoaArrayWrapper.endIndex.getter();
          uint64_t result = OUTLINED_FUNCTION_23_8();
        }
        else
        {
          uint64_t v29 = *(void *)((v8 & 0xFFFFFFFFFFFFFF8) + 0x10);
        }
        int64_t v9 = v51;
        if (v29 < v51) {
          goto LABEL_94;
        }
        if ((v8 & 0xC000000000000001) != 0 && v4 != v51)
        {
          if (v4 >= (unint64_t)v51)
          {
            __break(1u);
            return result;
          }
          type metadata accessor for NSAttributedString(0, (unint64_t *)&lazy cache variable for type metadata for MLMultiArray);
          Swift::Int v34 = v12 * v7;
          do
          {
            Swift::Int v35 = v34 + 1;
            _ArrayBuffer._typeCheckSlowPath(_:)(v34);
            Swift::Int v34 = v35;
          }
          while (v51 != v35);
        }
        if (v55)
        {
          OUTLINED_FUNCTION_17_17();
          uint64_t v36 = _CocoaArrayWrapper.subscript.getter();
          uint64_t v37 = v40;
          uint64_t v39 = v41;
          unint64_t v38 = v42;
          swift_bridgeObjectRelease();
        }
        else
        {
          uint64_t v36 = v8 & 0xFFFFFFFFFFFFFF8;
          uint64_t v37 = (v8 & 0xFFFFFFFFFFFFFF8) + 32;
          unint64_t v38 = (2 * v51) | 1;
          swift_bridgeObjectRetain();
          uint64_t v39 = v4;
        }
        uint64_t v58 = specialized Array.init<A>(_:)(v36, v37, v39, v38);
        unint64_t v8 = v32;
        uint64_t v43 = swift_bridgeObjectRetain();
        MEMORY[0x22A674D40](v43);
        int64_t v9 = *(void *)((v58 & 0xFFFFFFFFFFFFFF8) + 0x18);
        if (*(void *)((v58 & 0xFFFFFFFFFFFFFF8) + 0x10) >= (unint64_t)v9 >> 1) {
          goto LABEL_95;
        }
        goto LABEL_71;
      }
      a3 = type metadata accessor for NSAttributedString(0, (unint64_t *)&lazy cache variable for type metadata for MLMultiArray);
      uint64_t v4 = 0;
      uint64_t v54 = v3 / v7;
      uint64_t v56 = v7;
      while (v4 != v12)
      {
        uint64_t v13 = v4 * v7;
        if ((unsigned __int128)(v4 * (__int128)v7) >> 64 != (v4 * v7) >> 63) {
          goto LABEL_77;
        }
        uint64_t v14 = v13 + v7;
        if (__OFADD__(v13, v7)) {
          goto LABEL_78;
        }
        if (v14 < v13) {
          goto LABEL_79;
        }
        if (v10)
        {
          swift_bridgeObjectRetain();
          _CocoaArrayWrapper.endIndex.getter();
          OUTLINED_FUNCTION_23_8();
        }
        else
        {
          uint64_t v3 = *(void *)((v8 & 0xFFFFFFFFFFFFFF8) + 0x10);
        }
        if (v3 < v13) {
          goto LABEL_80;
        }
        if (v13 < 0) {
          goto LABEL_81;
        }
        if (v10)
        {
          swift_bridgeObjectRetain();
          _CocoaArrayWrapper.endIndex.getter();
          OUTLINED_FUNCTION_23_8();
        }
        else
        {
          uint64_t v3 = *(void *)((v8 & 0xFFFFFFFFFFFFFF8) + 0x10);
        }
        if (v3 < v14) {
          goto LABEL_82;
        }
        if ((v8 & 0xC000000000000001) != 0 && v13 != v14)
        {
          if (v13 >= (unint64_t)v14) {
            goto LABEL_83;
          }
          uint64_t v15 = v56;
          Swift::Int v16 = v4 * v7;
          do
          {
            Swift::Int v17 = v16 + 1;
            _ArrayBuffer._typeCheckSlowPath(_:)(v16);
            Swift::Int v16 = v17;
            --v15;
          }
          while (v15);
        }
        if (v10)
        {
          swift_bridgeObjectRetain();
          uint64_t v3 = _CocoaArrayWrapper.subscript.getter();
          uint64_t v57 = v18;
          uint64_t v7 = v19;
          swift_bridgeObjectRelease();
          if ((v7 & 1) == 0) {
            goto LABEL_31;
          }
        }
        else
        {
          uint64_t v7 = (2 * v14) | 1;
          swift_bridgeObjectRetain();
          uint64_t v3 = v8 & 0xFFFFFFFFFFFFFF8;
          uint64_t v57 = v13;
        }
        uint64_t v53 = v5;
        uint64_t v5 = type metadata accessor for __ContiguousArrayStorageBase();
        swift_unknownObjectRetain_n();
        uint64_t v22 = swift_dynamicCastClass();
        if (!v22)
        {
          swift_unknownObjectRelease();
          uint64_t v22 = MEMORY[0x263F8EE78];
        }
        unint64_t v10 = *(void *)(v22 + 16);
        swift_release();
        if (__OFSUB__((unint64_t)v7 >> 1, v57)) {
          goto LABEL_84;
        }
        if (v10 == ((unint64_t)v7 >> 1) - v57)
        {
          uint64_t v21 = swift_dynamicCastClass();
          uint64_t v5 = v53;
          if (!v21)
          {
            swift_unknownObjectRelease();
            uint64_t v21 = MEMORY[0x263F8EE78];
          }
          goto LABEL_38;
        }
        swift_unknownObjectRelease();
        uint64_t v5 = v53;
LABEL_31:
        specialized _copyCollectionToContiguousArray<A>(_:)();
        uint64_t v21 = v20;
LABEL_38:
        swift_unknownObjectRelease();
        uint64_t v3 = (uint64_t)@nonobjc MLMultiArray.__allocating_init(concatenating:axis:dataType:)(v21, 0, 65600);
        if ((swift_isUniquelyReferenced_nonNull_native() & 1) == 0)
        {
          OUTLINED_FUNCTION_29_13();
          uint64_t v5 = v26;
        }
        unint64_t v24 = *(void *)(v5 + 16);
        unint64_t v23 = *(void *)(v5 + 24);
        if (v24 >= v23 >> 1)
        {
          OUTLINED_FUNCTION_91(v23);
          specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
          uint64_t v5 = v27;
        }
        ++v4;
        *(void *)(v5 + 16) = v24 + 1;
        id v25 = (void *)(v5 + 24 * v24);
        v25[4] = v3;
        v25[5] = v13;
        unint64_t v25[6] = v14;

        uint64_t v12 = v54;
        unint64_t v10 = v55;
        uint64_t v7 = v56;
        if (v4 == v54) {
          goto LABEL_45;
        }
      }
      __break(1u);
LABEL_77:
      __break(1u);
LABEL_78:
      __break(1u);
LABEL_79:
      __break(1u);
LABEL_80:
      __break(1u);
LABEL_81:
      __break(1u);
LABEL_82:
      __break(1u);
LABEL_83:
      __break(1u);
LABEL_84:
      __break(1u);
LABEL_85:
      OUTLINED_FUNCTION_17_17();
      _CocoaArrayWrapper.endIndex.getter();
      OUTLINED_FUNCTION_23_8();
    }
    while (v7);
  }
  __break(1u);
LABEL_87:
  __break(1u);
LABEL_88:
  __break(1u);
LABEL_89:
  __break(1u);
LABEL_90:
  __break(1u);
LABEL_91:
  __break(1u);
LABEL_92:
  __break(1u);
LABEL_93:
  __break(1u);
LABEL_94:
  __break(1u);
LABEL_95:
  OUTLINED_FUNCTION_91(v9);
  specialized Array._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
LABEL_71:
  type metadata accessor for NSAttributedString(0, (unint64_t *)&lazy cache variable for type metadata for MLMultiArray);
  specialized Array._appendElementAssumeUniqueAndCapacity(_:newElement:)();
  specialized Array._endMutation()();
  swift_bridgeObjectRelease();
  id v44 = @nonobjc MLMultiArray.__allocating_init(concatenating:axis:dataType:)(v58, 0, 65600);
  if ((swift_isUniquelyReferenced_nonNull_native() & 1) == 0)
  {
    OUTLINED_FUNCTION_29_13();
    uint64_t v5 = v48;
  }
  unint64_t v46 = *(void *)(v5 + 16);
  unint64_t v45 = *(void *)(v5 + 24);
  if (v46 >= v45 >> 1)
  {
    OUTLINED_FUNCTION_91(v45);
    specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
    uint64_t v5 = v49;
  }
  *(void *)(v5 + 16) = v46 + 1;
  uint64_t v47 = (void *)(v5 + 24 * v46);
  v47[4] = v44;
  v47[5] = v4;
  v47[6] = v51;

  return v5;
}

void static _VideoUtilities.reformatKeypointsDataTable(table:featureColumn:keypointsShape:)(uint64_t a1, uint64_t a2, void *a3, uint64_t a4)
{
  unint64_t v5 = v4;
  id v10 = *(id *)a1;
  char v11 = *(unsigned char *)(a1 + 8);
  id v42 = *(id *)a1;
  char v43 = v11;
  MLDataTable.subscript.getter(a2, a3, (uint64_t)&v40);
  if (v41 == 1)
  {
    outlined consume of Result<_DataTable, Error>(v40, 1);
LABEL_17:
    char v29 = *(unsigned char *)(a1 + 8);
    id v40 = *(id *)a1;
    LOBYTE(v41) = v29;
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<String>);
    uint64_t inited = swift_initStackObject();
    *(_OWORD *)(inited + 16) = xmmword_2272CB370;
    *(void *)(inited + 32) = a2;
    *(void *)(inited + 40) = a3;
    LOBYTE(v42) = 5;
    swift_bridgeObjectRetain();
    static _ValidationUtilities.validateTableTypes(table:columns:type:)((uint64_t)&v40, inited, (unsigned __int8 *)&v42);
    swift_setDeallocating();
    specialized _ContiguousArrayStorage.__deallocating_deinit();
    return;
  }
  swift_retain();
  _UntypedColumn.type.getter(&v42);
  OUTLINED_FUNCTION_26_9();
  OUTLINED_FUNCTION_26_9();
  if (v42 != 3) {
    goto LABEL_17;
  }
  id v40 = v10;
  LOBYTE(v41) = v11;
  MLDataTable.subscript.getter(a2, a3, (uint64_t)&v42);
  id v12 = v42;
  char v13 = v43;
  uint64_t v14 = OUTLINED_FUNCTION_70();
  *(void *)(v14 + 16) = a4;
  swift_bridgeObjectRetain();
  specialized MLUntypedColumn.map<A>(skipUndefined:_:)(1, (uint64_t)partial apply for closure #1 in static _VideoUtilities.reformatKeypointsDataTable(table:featureColumn:keypointsShape:), v14, v12, v13, (uint64_t)&v40);
  swift_release();
  outlined consume of Result<_DataTable, Error>(v12, v13);
  id v44 = v40;
  char v39 = v41;
  char v15 = *(unsigned char *)(a1 + 8);
  id v42 = *(id *)a1;
  char v43 = v15;
  MLDataTable.subscript.getter(a2, a3, (uint64_t)&v40);
  id v16 = v40;
  char v17 = v41;
  if (v41)
  {
    uint64_t v18 = -1;
  }
  else
  {
    swift_retain();
    uint64_t v18 = CMLColumn.size.getter();
    outlined consume of Result<_DataTable, Error>(v16, 0);
  }
  outlined consume of Result<_DataTable, Error>(v16, v17);
  specialized MLDataColumn.dropMissing()(v44, v39, (uint64_t)&v42);
  id v19 = v42;
  char v20 = v43;
  if (v43)
  {
    uint64_t v21 = -1;
  }
  else
  {
    outlined copy of Result<_DataTable, Error>(v42, 0);
    uint64_t v21 = CMLColumn.size.getter();
    outlined consume of Result<_DataTable, Error>(v19, 0);
  }
  outlined consume of Result<_DataTable, Error>(v19, v20);
  if (__OFSUB__(v18, v21))
  {
    __break(1u);
LABEL_21:
    id v23 = (id)MEMORY[0x22A6753B0](1, a4);
    goto LABEL_14;
  }
  if (v18 == v21)
  {
    swift_bridgeObjectRetain();
    specialized MLDataTable.subscript.setter(v44, v39);
    goto LABEL_17;
  }
  id v40 = 0;
  unint64_t v41 = 0xE000000000000000;
  _StringGuts.grow(_:)(236);
  OUTLINED_FUNCTION_35_10(0xD00000000000003DLL, (uint64_t)"Failed to convert keypoints column into MLMultiArray format. ");
  id v42 = (id)(v18 - v21);
  v22._uint64_t countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter();
  String.append(_:)(v22);
  swift_bridgeObjectRelease();
  OUTLINED_FUNCTION_35_10(0xD00000000000006BLL, (uint64_t)" rows have issues. Please make sure that the keypoints sequence on each row should have a dimension of [1, ");
  unint64_t v5 = a4 & 0xC000000000000001;
  specialized Array._checkSubscript(_:wasNativeTypeChecked:)(1, (a4 & 0xC000000000000001) == 0, a4);
  if ((a4 & 0xC000000000000001) != 0) {
    goto LABEL_21;
  }
  id v23 = *(id *)(a4 + 40);
LABEL_14:
  unint64_t v24 = v23;
  id v25 = objc_msgSend(v23, sel_integerValue);

  id v42 = v25;
  v26._uint64_t countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter();
  String.append(_:)(v26);
  swift_bridgeObjectRelease();
  v27._uint64_t countAndFlagsBits = 8236;
  v27._uint64_t object = (void *)0xE200000000000000;
  String.append(_:)(v27);
  specialized Array._checkSubscript(_:wasNativeTypeChecked:)(2, v5 == 0, a4);
  if (v5) {
    id v28 = (id)MEMORY[0x22A6753B0](2, a4);
  }
  else {
    id v28 = *(id *)(a4 + 48);
  }
  id v31 = v28;
  id v32 = objc_msgSend(v28, sel_integerValue);

  id v42 = v32;
  v33._uint64_t countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter();
  String.append(_:)(v33);
  swift_bridgeObjectRelease();
  v34._uint64_t object = (void *)0x80000002272D4350;
  v34._uint64_t countAndFlagsBits = 0xD00000000000003CLL;
  String.append(_:)(v34);
  id v35 = v40;
  unint64_t v36 = v41;
  lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  uint64_t v37 = OUTLINED_FUNCTION_85();
  *unint64_t v38 = v35;
  v38[1] = v36;
  OUTLINED_FUNCTION_8_4(v37, (uint64_t)v38);
  outlined consume of Result<_DataTable, Error>(v44, v39);
}

uint64_t static _VideoUtilities.getSecondsFromTimeString(_:)(uint64_t a1, void *a2)
{
  lazy protocol witness table accessor for type String and conformance String();
  unint64_t v4 = (void *)StringProtocol.components<A>(separatedBy:)();
  unint64_t v5 = v4;
  uint64_t v6 = v4[2];
  if (v6 != 3)
  {
    if (v6 != 2)
    {
      if (v6 == 1)
      {
        uint64_t v7 = v4[4];
        uint64_t v8 = v4[5];
        swift_bridgeObjectRetain();
        swift_bridgeObjectRelease();
        uint64_t result = specialized Double.init<A>(_:)(v7, v8);
        if ((v10 & 1) == 0) {
          return result;
        }
LABEL_17:
        _StringGuts.grow(_:)(153);
        OUTLINED_FUNCTION_20_1();
        v26._uint64_t countAndFlagsBits = 0xD00000000000001FLL;
        String.append(_:)(v26);
        v27._uint64_t countAndFlagsBits = a1;
        v27._uint64_t object = a2;
        String.append(_:)(v27);
        OUTLINED_FUNCTION_35_10(0xD000000000000078, (uint64_t)". Please provide a String value in hours:minutes:seconds.fraction, minutes:seconds.fraction, or seconds.fraction format.");
        lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
        uint64_t v28 = OUTLINED_FUNCTION_85();
        *char v29 = 0;
        v29[1] = 0xE000000000000000;
        return OUTLINED_FUNCTION_8_4(v28, (uint64_t)v29);
      }
LABEL_16:
      swift_bridgeObjectRelease();
      goto LABEL_17;
    }
    uint64_t v20 = v4[4];
    uint64_t v21 = v4[5];
    swift_bridgeObjectRetain();
    uint64_t result = specialized Double.init<A>(_:)(v20, v21);
    if (v22) {
      goto LABEL_16;
    }
    if (v5[2] >= 2uLL)
    {
      uint64_t v23 = v5[6];
      uint64_t v24 = v5[7];
      swift_bridgeObjectRetain();
      swift_bridgeObjectRelease();
      uint64_t result = specialized Double.init<A>(_:)(v23, v24);
      if (v25) {
        goto LABEL_17;
      }
      return result;
    }
    goto LABEL_19;
  }
  uint64_t v11 = v4[4];
  uint64_t v12 = v4[5];
  swift_bridgeObjectRetain();
  uint64_t result = specialized Double.init<A>(_:)(v11, v12);
  if (v13) {
    goto LABEL_16;
  }
  if (v5[2] < 2uLL)
  {
    __break(1u);
LABEL_19:
    __break(1u);
    goto LABEL_20;
  }
  uint64_t v14 = v5[6];
  uint64_t v15 = v5[7];
  swift_bridgeObjectRetain();
  uint64_t result = specialized Double.init<A>(_:)(v14, v15);
  if (v16) {
    goto LABEL_16;
  }
  if (v5[2] < 3uLL)
  {
LABEL_20:
    __break(1u);
    return result;
  }
  uint64_t v17 = v5[8];
  uint64_t v18 = v5[9];
  swift_bridgeObjectRetain();
  swift_bridgeObjectRelease();
  uint64_t result = specialized Double.init<A>(_:)(v17, v18);
  if (v19) {
    goto LABEL_17;
  }
  return result;
}

void *static _VideoUtilities.getHandKeyPointsFromVideoUrl(url:startTime:endTime:targetFrameRate:)(uint64_t a1, CMTimeValue a2, uint64_t a3, CMTimeEpoch a4, CMTimeValue a5, uint64_t a6, CMTimeEpoch a7, double a8)
{
  v59.epoch = a7;
  *(void *)&v59.timescale = a6;
  v59.CMTimeValue value = a5;
  v58.epoch = a4;
  *(void *)&v58.timescale = a3;
  v58.CMTimeValue value = a2;
  uint64_t v63 = a1;
  uint64_t v69 = *MEMORY[0x263EF8340];
  uint64_t v10 = type metadata accessor for URL();
  OUTLINED_FUNCTION_0_15();
  uint64_t v12 = v11;
  uint64_t v14 = *(void *)(v13 + 64);
  MEMORY[0x270FA5388](v15);
  type metadata accessor for NSAttributedString(0, &lazy cache variable for type metadata for VNVideoProcessor);
  char v16 = *(void (**)(char *, uint64_t, uint64_t))(v12 + 16);
  v16((char *)v55 - ((v14 + 15) & 0xFFFFFFFFFFFFFFF0), a1, v10);
  id v62 = VNVideoProcessor.__allocating_init(url:)((uint64_t)v55 - ((v14 + 15) & 0xFFFFFFFFFFFFFFF0));
  uint64_t v17 = OUTLINED_FUNCTION_70();
  uint64_t v60 = v17;
  *(void *)(v17 + 16) = MEMORY[0x263F8EE78];
  v55[0] = v17 + 16;
  uint64_t v18 = OUTLINED_FUNCTION_70();
  *(void *)(v18 + 16) = 0;
  uint64_t v57 = (id *)(v18 + 16);
  uint64_t v19 = OUTLINED_FUNCTION_70();
  *(void *)(v19 + 16) = 0;
  uint64_t v56 = (uint64_t *)(v19 + 16);
  v16((char *)v55 - ((v14 + 15) & 0xFFFFFFFFFFFFFFF0), v63, v10);
  unint64_t v20 = (*(unsigned __int8 *)(v12 + 80) + 24) & ~(unint64_t)*(unsigned __int8 *)(v12 + 80);
  unint64_t v21 = (v14 + v20 + 7) & 0xFFFFFFFFFFFFFFF8;
  uint64_t v22 = swift_allocObject();
  *(void *)(v22 + 16) = v18;
  (*(void (**)(unint64_t, char *, uint64_t))(v12 + 32))(v22 + v20, (char *)v55 - ((v14 + 15) & 0xFFFFFFFFFFFFFFF0), v10);
  *(void *)(v22 + v21) = v19;
  uint64_t v23 = v60;
  *(void *)(v22 + ((v21 + 15) & 0xFFFFFFFFFFFFFFF8)) = v60;
  objc_allocWithZone(MEMORY[0x263F1EEA0]);
  swift_retain();
  uint64_t v61 = v19;
  swift_retain();
  swift_retain();
  id v24 = @nonobjc VNDetectHumanHandPoseRequest.init(completionHandler:)((uint64_t)partial apply for closure #1 in static _VideoUtilities.getHandKeyPointsFromVideoUrl(url:startTime:endTime:targetFrameRate:), v22);
  if (a8 < 0.01)
  {
    v68.start.CMTimeValue value = 0;
    *(void *)&v68.start.timescale = 0xE000000000000000;
    _StringGuts.grow(_:)(55);
    v25._uint64_t countAndFlagsBits = 0xD00000000000001ALL;
    v25._uint64_t object = (void *)0x80000002272D7A20;
    String.append(_:)(v25);
    Double.write<A>(to:)();
    OUTLINED_FUNCTION_20_1();
    v26._uint64_t countAndFlagsBits = 0xD000000000000010;
    String.append(_:)(v26);
    a8 = 30.0;
    Double.write<A>(to:)();
    v27._uint64_t countAndFlagsBits = 0x776F6E2073706620;
    v27._uint64_t object = (void *)0xE90000000000002ELL;
    String.append(_:)(v27);
    CMTimeValue value = v68.start.value;
    char v29 = *(void **)&v68.start.timescale;
    os_log_type_t v30 = static os_log_type_t.default.getter();
    v31._uint64_t countAndFlagsBits = value;
    v31._uint64_t object = v29;
    log(_:type:)(v31, v30);
    swift_bridgeObjectRelease();
  }
  id v32 = objc_msgSend(objc_allocWithZone(MEMORY[0x263F1F018]), sel_init);
  id v33 = objc_msgSend(objc_allocWithZone(MEMORY[0x263F1F020]), sel_initWithTimeInterval_, 1.0 / a8);
  objc_msgSend(v32, sel_setCadence_, v33);

  v68.start.CMTimeValue value = 0;
  id v34 = v62;
  unsigned int v35 = objc_msgSend(v62, sel_addRequest_processingOptions_error_, v24, v32, &v68);
  unint64_t v36 = (void *)v68.start.value;
  if (v35
    && (id v37 = (id)v68.start.value,
        CMTimeRange.init(start:end:)(&v64, v58, v59),
        uint64_t v66 = 0,
        CMTimeRange v68 = v64,
        unsigned int v38 = objc_msgSend(v34, sel_analyzeTimeRange_error_, &v68, &v66),
        unint64_t v36 = (void *)v66,
        v38))
  {
    char v39 = v56;
    OUTLINED_FUNCTION_30_11();
    if (*v39 < 1)
    {
      id v52 = v36;
    }
    else
    {
      uint64_t v66 = 0;
      unint64_t v67 = 0xE000000000000000;
      id v40 = v36;
      _StringGuts.grow(_:)(44);
      swift_bridgeObjectRelease();
      uint64_t v66 = 0x206F65646956;
      unint64_t v67 = 0xE600000000000000;
      v41._uint64_t countAndFlagsBits = URL.path.getter();
      String.append(_:)(v41);
      swift_bridgeObjectRelease();
      v42._uint64_t countAndFlagsBits = 0x2073616820;
      v42._uint64_t object = (void *)0xE500000000000000;
      String.append(_:)(v42);
      uint64_t v65 = *v39;
      v43._uint64_t countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter();
      String.append(_:)(v43);
      swift_bridgeObjectRelease();
      v44._uint64_t countAndFlagsBits = 0xD00000000000001DLL;
      v44._uint64_t object = (void *)0x80000002272D7A00;
      String.append(_:)(v44);
      uint64_t v45 = v66;
      unint64_t v46 = (void *)v67;
      os_log_type_t v47 = static os_log_type_t.info.getter();
      v48._uint64_t countAndFlagsBits = v45;
      v48._uint64_t object = v46;
      log(_:type:)(v48, v47);
      swift_bridgeObjectRelease();
    }
    uint64_t v53 = v57;
    OUTLINED_FUNCTION_30_11();
    if (!*v53)
    {

      swift_beginAccess();
      uint64_t v50 = *(void **)(v23 + 16);
      swift_bridgeObjectRetain();
      swift_release();
      swift_release();
      swift_release();
      return v50;
    }
    id v54 = *v53;
    swift_willThrow();
    uint64_t v50 = v32;
  }
  else
  {
    id v49 = v36;
    _convertNSErrorToError(_:)();

    swift_willThrow();
    uint64_t v50 = v24;
    id v24 = v34;
    id v34 = v32;
  }
  swift_release();
  swift_release();
  swift_release();

  return v50;
}

void static _VideoUtilities.renameFeatureTableColumns(table:sessionIdColumn:featureColumn:labelColumn:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  uint64_t v13 = *(void **)a1;
  char v14 = *(unsigned char *)(a1 + 8);
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<String>);
  uint64_t inited = swift_initStackObject();
  *(_OWORD *)(inited + 16) = xmmword_2272CB4A0;
  *(void *)(inited + 32) = a2;
  *(void *)(inited + 40) = a3;
  *(void *)(inited + 48) = a4;
  *(void *)(inited + 56) = a5;
  *(void *)(inited + 64) = a6;
  *(void *)(inited + 72) = a7;
  outlined copy of Result<_DataTable, Error>(v13, v14);
  swift_bridgeObjectRetain();
  swift_bridgeObjectRetain();
  swift_bridgeObjectRetain();
  OUTLINED_FUNCTION_14_17();
  static _ValidationUtilities.validateTableFormat(table:context:columns:)(v16, v17, v18, inited);
  if (v28)
  {
    outlined consume of Result<_DataTable, Error>(v13, v14);
    swift_setDeallocating();
    specialized _ContiguousArrayStorage.__deallocating_deinit();
  }
  else
  {
    outlined consume of Result<_DataTable, Error>(v13, v14);
    swift_setDeallocating();
    specialized _ContiguousArrayStorage.__deallocating_deinit();
    MLDataTable.willMutate()();
    OUTLINED_FUNCTION_19_17();
    MLDataTable.renameImpl(named:to:)(v19, v20, v21, v22);
    if ((*(unsigned char *)(a1 + 8) & 1) == 0)
    {
      OUTLINED_FUNCTION_1_32();
      OUTLINED_FUNCTION_26_9();
    }
    MLDataTable.willMutate()();
    OUTLINED_FUNCTION_15_17();
    MLDataTable.renameImpl(named:to:)(v23, v24, v25, v26);
    if ((*(unsigned char *)(a1 + 8) & 1) == 0)
    {
      OUTLINED_FUNCTION_1_32();
      OUTLINED_FUNCTION_26_9();
    }
    MLDataTable.willMutate()();
    MLDataTable.renameImpl(named:to:)(a6, a7, 0x6C6562616CLL, 0xE500000000000000);
    if ((*(unsigned char *)(a1 + 8) & 1) == 0)
    {
      OUTLINED_FUNCTION_1_32();
      OUTLINED_FUNCTION_26_9();
    }
  }
}

uint64_t static _VideoUtilities.generateVideoTable(_:)()
{
  OUTLINED_FUNCTION_47_9();
  uint64_t v3 = v2;
  uint64_t v4 = swift_bridgeObjectRetain();
  uint64_t v49 = specialized _copyCollectionToContiguousArray<A>(_:)(v4);
  specialized MutableCollection<>.sort(by:)(&v49);
  if (v0)
  {
LABEL_59:
    uint64_t result = swift_release();
    __break(1u);
    return result;
  }
  uint64_t v5 = 0;
  swift_bridgeObjectRelease();
  uint64_t v48 = *(void *)(v49 + 16);
  if (v48)
  {
    uint64_t v45 = v3;
    uint64_t v6 = 0;
    uint64_t v47 = v49 + 32;
    uint64_t v7 = MEMORY[0x263F8EE78];
    uint64_t v8 = MEMORY[0x263F8EE78];
    uint64_t v46 = v1;
    while (1)
    {
      int64_t v9 = (uint64_t *)(v47 + 16 * v6);
      uint64_t v11 = *v9;
      uint64_t v10 = v9[1];
      uint64_t v12 = *(void *)(v1 + 16);
      swift_bridgeObjectRetain();
      if (v12)
      {
        swift_bridgeObjectRetain();
        unint64_t v13 = specialized __RawDictionaryStorage.find<A>(_:)(v11, v10);
        uint64_t v14 = MEMORY[0x263F8EE78];
        if (v15)
        {
          uint64_t v14 = *(void *)(*(void *)(v1 + 56) + 8 * v13);
          swift_bridgeObjectRetain();
        }
        swift_bridgeObjectRelease();
      }
      else
      {
        uint64_t v14 = MEMORY[0x263F8EE78];
      }
      uint64_t ML15_VideoUtilitiesV08generateC5TableyAA06MLDataF0VSDySSSay10Foundation3URLVGGKFZSSAIcfu0_33_43697e1f61f7e10b647d882195ad8775AISSTf3nnnpk_nTf1cn_n = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay10Foundation3URLVG_SSs5NeverOTg5148_s8CreateML15_VideoUtilitiesV08generateC5TableyAA06MLDataF0VSDySSSay10Foundation3URLVGGKFZSSAIcfu0_33_43697e1f61f7e10b647d882195ad8775AISSTf3nnnpk_nTf1cn_n(v14);
      uint64_t v17 = v5;
      swift_bridgeObjectRelease();
      uint64_t v18 = *(void *)(ML15_VideoUtilitiesV08generateC5TableyAA06MLDataF0VSDySSSay10Foundation3URLVGGKFZSSAIcfu0_33_43697e1f61f7e10b647d882195ad8775AISSTf3nnnpk_nTf1cn_n
                      + 16);
      if (v18)
      {
        uint64_t v19 = (void *)static Array._allocateBufferUninitialized(minimumCapacity:)();
        uint64_t v20 = v19;
        void v19[2] = v18;
        v19[4] = v11;
        v19[5] = v10;
        if (v18 != 1)
        {
          v19[6] = v11;
          v19[7] = v10;
          uint64_t v21 = v18 - 2;
          if (v18 != 2)
          {
            uint64_t v22 = v19 + 9;
            do
            {
              *(v22 - 1) = v11;
              *uint64_t v22 = v10;
              swift_bridgeObjectRetain();
              v22 += 2;
              --v21;
            }
            while (v21);
          }
          swift_bridgeObjectRetain();
        }
      }
      else
      {
        swift_bridgeObjectRelease();
        uint64_t v20 = (void *)MEMORY[0x263F8EE78];
      }
      uint64_t v23 = v20[2];
      uint64_t v24 = *(void *)(v7 + 16);
      if (__OFADD__(v24, v23)) {
        break;
      }
      if (!swift_isUniquelyReferenced_nonNull_native() || v24 + v23 > *(void *)(v7 + 24) >> 1)
      {
        specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
        uint64_t v7 = v25;
      }
      if (v20[2])
      {
        uint64_t v26 = *(void *)(v7 + 16);
        if ((*(void *)(v7 + 24) >> 1) - v26 < v23) {
          goto LABEL_54;
        }
        unint64_t v27 = v7 + 16 * v26 + 32;
        if ((unint64_t)(v20 + 4) < v27 + 16 * v23 && v27 < (unint64_t)&v20[2 * v23 + 4]) {
          goto LABEL_58;
        }
        swift_arrayInitWithCopy();
        if (v23)
        {
          uint64_t v29 = *(void *)(v7 + 16);
          BOOL v30 = __OFADD__(v29, v23);
          uint64_t v31 = v29 + v23;
          if (v30) {
            goto LABEL_56;
          }
          *(void *)(v7 + 16) = v31;
        }
      }
      else if (v23)
      {
        goto LABEL_51;
      }
      swift_bridgeObjectRelease();
      uint64_t v32 = *(void *)(ML15_VideoUtilitiesV08generateC5TableyAA06MLDataF0VSDySSSay10Foundation3URLVGGKFZSSAIcfu0_33_43697e1f61f7e10b647d882195ad8775AISSTf3nnnpk_nTf1cn_n
                      + 16);
      uint64_t v33 = *(void *)(v8 + 16);
      if (__OFADD__(v33, v32)) {
        goto LABEL_52;
      }
      if (!swift_isUniquelyReferenced_nonNull_native() || v33 + v32 > *(void *)(v8 + 24) >> 1)
      {
        specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
        uint64_t v8 = v34;
      }
      if (*(void *)(ML15_VideoUtilitiesV08generateC5TableyAA06MLDataF0VSDySSSay10Foundation3URLVGGKFZSSAIcfu0_33_43697e1f61f7e10b647d882195ad8775AISSTf3nnnpk_nTf1cn_n
                     + 16))
      {
        uint64_t v35 = *(void *)(v8 + 16);
        if ((*(void *)(v8 + 24) >> 1) - v35 < v32) {
          goto LABEL_55;
        }
        unint64_t v36 = v8 + 16 * v35 + 32;
        if (ML15_VideoUtilitiesV08generateC5TableyAA06MLDataF0VSDySSSay10Foundation3URLVGGKFZSSAIcfu0_33_43697e1f61f7e10b647d882195ad8775AISSTf3nnnpk_nTf1cn_n
           + 32 < v36 + 16 * v32
          && v36 < ML15_VideoUtilitiesV08generateC5TableyAA06MLDataF0VSDySSSay10Foundation3URLVGGKFZSSAIcfu0_33_43697e1f61f7e10b647d882195ad8775AISSTf3nnnpk_nTf1cn_n
                 + 32
                 + 16 * v32)
        {
          goto LABEL_58;
        }
        swift_arrayInitWithCopy();
        if (v32)
        {
          uint64_t v38 = *(void *)(v8 + 16);
          BOOL v30 = __OFADD__(v38, v32);
          uint64_t v39 = v38 + v32;
          if (v30) {
            goto LABEL_57;
          }
          *(void *)(v8 + 16) = v39;
        }
      }
      else if (v32)
      {
        goto LABEL_53;
      }
      ++v6;
      swift_bridgeObjectRelease();
      uint64_t v5 = v17;
      uint64_t v1 = v46;
      if (v6 == v48)
      {
        swift_release();
        uint64_t v3 = v45;
        goto LABEL_49;
      }
    }
    __break(1u);
LABEL_51:
    __break(1u);
LABEL_52:
    __break(1u);
LABEL_53:
    __break(1u);
LABEL_54:
    __break(1u);
LABEL_55:
    __break(1u);
LABEL_56:
    __break(1u);
LABEL_57:
    __break(1u);
LABEL_58:
    _fatalErrorMessage(_:_:file:line:flags:)();
    __break(1u);
    goto LABEL_59;
  }
  swift_release();
  uint64_t v8 = MEMORY[0x263F8EE78];
  uint64_t v7 = MEMORY[0x263F8EE78];
LABEL_49:
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, MLDataValueConvertible)>);
  uint64_t inited = swift_initStackObject();
  *(_OWORD *)(inited + 16) = xmmword_2272CB4D0;
  *(void *)(inited + 32) = 0x6C6562616CLL;
  *(void *)(inited + 40) = 0xE500000000000000;
  uint64_t v41 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String]);
  *(void *)(inited + 72) = v41;
  unint64_t v42 = lazy protocol witness table accessor for type [String] and conformance <A> [A]();
  *(void *)(inited + 48) = v7;
  *(void *)(inited + 80) = v42;
  *(void *)(inited + 88) = 0x7461506F65646976;
  *(void *)(inited + 128) = v41;
  *(void *)(inited + 136) = v42;
  *(void *)(inited + 96) = 0xE900000000000068;
  *(void *)(inited + 104) = v8;
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLDataValueConvertible);
  uint64_t v43 = Dictionary.init(dictionaryLiteral:)();
  return MLDataTable.init(dictionary:)(v43, v3);
}

uint64_t static _VideoUtilities.validateVideoInput(dataFrame:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)(uint64_t a1, uint64_t a2, void *a3, uint64_t a4, void *a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Any.Type>);
  uint64_t v12 = OUTLINED_FUNCTION_55_7();
  *(_OWORD *)(v12 + 16) = xmmword_2272CB370;
  uint64_t v13 = MEMORY[0x263F8D310];
  *(void *)(v12 + 32) = MEMORY[0x263F8D310];
  v14._uint64_t object = (void *)0xEA00000000006874;
  v15._uint64_t countAndFlagsBits = a2;
  v15._uint64_t object = a3;
  v14._uint64_t countAndFlagsBits = 0x6170206F65646956;
  DataFrame.validateColumnTypes(_:_:context:)(v15, (Swift::OpaquePointer)v12, v14);
  uint64_t result = swift_bridgeObjectRelease();
  if (!v17)
  {
    uint64_t v18 = OUTLINED_FUNCTION_55_7();
    *(_OWORD *)(v18 + 16) = xmmword_2272CB370;
    *(void *)(v18 + 32) = v13;
    v19._uint64_t countAndFlagsBits = a4;
    v19._uint64_t object = a5;
    v20._uint64_t countAndFlagsBits = 0x6C6562614CLL;
    v20._uint64_t object = (void *)0xE500000000000000;
    DataFrame.validateColumnTypes(_:_:context:)(v19, (Swift::OpaquePointer)v18, v20);
    uint64_t result = swift_bridgeObjectRelease();
    if (!v21)
    {
      if (a7)
      {
        __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<String>);
        uint64_t inited = swift_initStackObject();
        *(_OWORD *)(inited + 16) = xmmword_2272CB370;
        *(void *)(inited + 32) = a6;
        *(void *)(inited + 40) = a7;
        swift_bridgeObjectRetain();
        v23._uint64_t countAndFlagsBits = 0x6974207472617453;
        v23._uint64_t object = (void *)0xEA0000000000656DLL;
        DataFrame.validateContainsColumns(_:context:)((Swift::OpaquePointer)inited, v23);
        if (v24)
        {
LABEL_8:
          swift_setDeallocating();
          return specialized _ContiguousArrayStorage.__deallocating_deinit();
        }
        swift_setDeallocating();
        uint64_t result = specialized _ContiguousArrayStorage.__deallocating_deinit();
      }
      if (!a9) {
        return result;
      }
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<String>);
      uint64_t v25 = swift_initStackObject();
      *(_OWORD *)(v25 + 16) = xmmword_2272CB370;
      *(void *)(v25 + 32) = a8;
      *(void *)(v25 + 40) = a9;
      swift_bridgeObjectRetain();
      v26._uint64_t countAndFlagsBits = 0x656D697420646E45;
      v26._uint64_t object = (void *)0xE800000000000000;
      DataFrame.validateContainsColumns(_:context:)((Swift::OpaquePointer)v25, v26);
      goto LABEL_8;
    }
  }
  return result;
}

uint64_t static _VideoUtilities.validateVideoInput(trainingData:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
  uint64_t v14 = *(void *)a1;
  char v15 = *(unsigned char *)(a1 + 8);
  uint64_t v16 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<String>);
  uint64_t inited = swift_initStackObject();
  *(_OWORD *)(inited + 16) = xmmword_2272CB370;
  *(void *)(inited + 32) = a2;
  *(void *)(inited + 40) = a3;
  uint64_t v79 = v14;
  char v80 = v15;
  swift_bridgeObjectRetain();
  static _ValidationUtilities.validateTableFormat(table:context:columns:)((uint64_t)&v79, 0x7461506F65646976, (void *)0xE900000000000068, inited);
  if (v9) {
    goto LABEL_3;
  }
  uint64_t v79 = v14;
  char v80 = v15;
  uint64_t v18 = (__n128 *)swift_initStackObject();
  OUTLINED_FUNCTION_16_18(v18, v19, v20, v21, v22, v23, v24, v25, v62, a6, a8, a5, v14, a4, v26);
  uint64_t v27 = v72;
  *(void *)(v28 + 32) = v77;
  *(void *)(v28 + 40) = v72;
  swift_bridgeObjectRetain();
  static _ValidationUtilities.validateTableFormat(table:context:columns:)((uint64_t)&v79, 0x6C6562616CLL, (void *)0xE500000000000000, v16);
  swift_setDeallocating();
  specialized _ContiguousArrayStorage.__deallocating_deinit();
  swift_setDeallocating();
  uint64_t v30 = inited;
  specialized _ContiguousArrayStorage.__deallocating_deinit();
  uint64_t v31 = v74;
  uint64_t v79 = v74;
  char v80 = v15;
  uint64_t v32 = (__n128 *)swift_initStackObject();
  OUTLINED_FUNCTION_16_18(v32, v33, v34, v35, v36, v37, v38, v39, v63, v65, v68, v72, v74, v77, v40);
  *(void *)(v41 + 32) = a2;
  *(void *)(v41 + 40) = a3;
  unsigned __int8 v82 = 2;
  unsigned __int8 v81 = 2;
  swift_bridgeObjectRetain();
  static _ValidationUtilities.validateTableTypes(table:featureColumns:featureType:labelColumn:labelType:)(&v79, v30, &v82, v78, v27, &v81);
  swift_setDeallocating();
  uint64_t result = specialized _ContiguousArrayStorage.__deallocating_deinit();
  if (a7)
  {
    uint64_t v79 = v31;
    char v80 = v15;
    unint64_t v42 = (__n128 *)swift_initStackObject();
    OUTLINED_FUNCTION_16_18(v42, v43, v44, v45, v46, v47, v48, v49, v64, v66, v69, v73, v75, v78, v50);
    *(void *)(v51 + 32) = v66;
    *(void *)(v51 + 40) = a7;
    swift_bridgeObjectRetain();
    static _ValidationUtilities.validateTableFormat(table:context:columns:)((uint64_t)&v79, 0xD000000000000011, (void *)0x80000002272D7CC0, v30);
    swift_setDeallocating();
    uint64_t result = specialized _ContiguousArrayStorage.__deallocating_deinit();
  }
  if (a9)
  {
    uint64_t v79 = v31;
    char v80 = v15;
    id v52 = (__n128 *)swift_initStackObject();
    OUTLINED_FUNCTION_16_18(v52, v53, v54, v55, v56, v57, v58, v59, v64, v66, v69, v73, v75, v78, v60);
    *(void *)(v61 + 32) = v70;
    *(void *)(v61 + 40) = a9;
    swift_bridgeObjectRetain();
    static _ValidationUtilities.validateTableFormat(table:context:columns:)((uint64_t)&v79, 0x656D697420646E65, (void *)0xEF6E6D756C6F6320, v30);
LABEL_3:
    swift_setDeallocating();
    return specialized _ContiguousArrayStorage.__deallocating_deinit();
  }
  return result;
}

void static _VideoUtilities.getVideoURLsAndAnnotations(from:)(uint64_t a1@<X0>, void (***a2)(void)@<X8>)
{
  char v147 = a2;
  id v148 = (void *)type metadata accessor for DataFrame();
  OUTLINED_FUNCTION_0_15();
  uint64_t v146 = v4;
  MEMORY[0x270FA5388](v5);
  OUTLINED_FUNCTION_33();
  uint64_t v8 = v6 - v7;
  MEMORY[0x270FA5388](v9);
  uint64_t v142 = (uint64_t)&v139 - v10;
  uint64_t v145 = type metadata accessor for UTType();
  OUTLINED_FUNCTION_0_15();
  uint64_t v144 = v11;
  MEMORY[0x270FA5388](v12);
  OUTLINED_FUNCTION_33();
  MEMORY[0x270FA5388](v13);
  uint64_t v149 = type metadata accessor for URL();
  OUTLINED_FUNCTION_0_15();
  uint64_t v150 = v14;
  MEMORY[0x270FA5388](v15);
  OUTLINED_FUNCTION_33();
  OUTLINED_FUNCTION_16_2();
  uint64_t v17 = MEMORY[0x270FA5388](v16);
  uint64_t v19 = (char *)&v139 - v18;
  MEMORY[0x270FA5388](v17);
  OUTLINED_FUNCTION_16_2();
  MEMORY[0x270FA5388](v20);
  OUTLINED_FUNCTION_16_2();
  uint64_t v22 = MEMORY[0x270FA5388](v21);
  MEMORY[0x270FA5388](v22);
  uint64_t v23 = type metadata accessor for MLHandActionClassifier.DataSource();
  MEMORY[0x270FA5388](v23);
  OUTLINED_FUNCTION_27_7();
  outlined init with copy of MLHandActionClassifier.DataSource(a1, v2);
  switch(swift_getEnumCaseMultiPayload())
  {
    case 1u:
      OUTLINED_FUNCTION_21_18();
      v44();
      static UTType.movie.getter();
      uint64_t v45 = v181;
      static _FileUtilities.collectFilesLabeledByDirectoryName(at:type:)();
      if (!v45)
      {
        OUTLINED_FUNCTION_2_24();
        v105();
        static _VideoUtilities.generateVideoTable(_:)();
        swift_bridgeObjectRelease();
        id v112 = (id)v151;
        char v113 = v152;
        uint64_t v179 = (void (**)(void))v151;
        char v180 = v152;
        OUTLINED_FUNCTION_27_14();
        *(unsigned char *)(v114 - 256) = v113;
        id v115 = outlined copy of Result<_DataTable, Error>(v112, v113);
        OUTLINED_FUNCTION_2_40((uint64_t)v115, v116, v117, v118, v119, v120, v121, v122, v139);
        OUTLINED_FUNCTION_33_10();
        outlined consume of Result<_DataTable, Error>(v112, v113);
        uint64_t v134 = OUTLINED_FUNCTION_5_29();
        v135(v134);
        goto LABEL_14;
      }
      OUTLINED_FUNCTION_2_24();
      v46();
      uint64_t v47 = OUTLINED_FUNCTION_5_29();
      v48(v47);
      return;
    case 2u:
      OUTLINED_FUNCTION_21_18();
      v49();
      static UTType.movie.getter();
      uint64_t v50 = v181;
      static _FileUtilities.collectFilesLabeledByFileName(at:type:)();
      if (!v50)
      {
        OUTLINED_FUNCTION_2_24();
        v106();
        static _VideoUtilities.generateVideoTable(_:)();
        swift_bridgeObjectRelease();
        id v123 = (id)v151;
        char v124 = v152;
        uint64_t v179 = (void (**)(void))v151;
        char v180 = v152;
        id v125 = outlined copy of Result<_DataTable, Error>((id)v151, v152);
        OUTLINED_FUNCTION_2_40((uint64_t)v125, v126, v127, v128, v129, v130, v131, v132, v139);
        OUTLINED_FUNCTION_33_10();
        outlined consume of Result<_DataTable, Error>(v123, v124);
        OUTLINED_FUNCTION_11_3();
        v136();
        goto LABEL_14;
      }
      OUTLINED_FUNCTION_2_24();
      v51();
      OUTLINED_FUNCTION_11_3();
      v52();
      return;
    case 3u:
      outlined consume of Result<_DataTable, Error>(*(id *)v2, *(unsigned char *)(v2 + 8));
      swift_bridgeObjectRelease();
      swift_bridgeObjectRelease();
      swift_bridgeObjectRelease();
      goto LABEL_12;
    case 4u:
      int v53 = *(unsigned __int8 *)(v2 + 8);
      uint64_t v55 = *(void *)(v2 + 16);
      uint64_t v54 = *(void *)(v2 + 24);
      uint64_t v57 = *(void *)(v2 + 32);
      uint64_t v56 = *(void *)(v2 + 40);
      uint64_t v58 = *(void *)(v2 + 48);
      uint64_t v59 = *(void *)(v2 + 56);
      uint64_t v60 = *(void *)(v2 + 64);
      uint64_t v61 = *(void *)(v2 + 72);
      uint64_t v179 = *(void (***)(void))v2;
      char v180 = v53;
      uint64_t v150 = v179;
      LODWORD(v149) = v53;
      outlined copy of Result<_DataTable, Error>(v179, v53);
      uint64_t v62 = v181;
      static _VideoUtilities.renameVideoTableColumns(table:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)((uint64_t)&v179, v55, v54, v57, v56, v58, v59, v60, v61);
      OUTLINED_FUNCTION_33_10();
      if (v62)
      {
        swift_bridgeObjectRelease();
        swift_bridgeObjectRelease();
        swift_bridgeObjectRelease();
        swift_bridgeObjectRelease();
        OUTLINED_FUNCTION_42_8();
        goto LABEL_30;
      }
      swift_bridgeObjectRelease();
      swift_bridgeObjectRelease();
      swift_bridgeObjectRelease();
      swift_bridgeObjectRelease();
      OUTLINED_FUNCTION_42_8();
      goto LABEL_14;
    case 5u:
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
      swift_bridgeObjectRelease();
      swift_bridgeObjectRelease();
      swift_bridgeObjectRelease();
      (*(void (**)(uint64_t, void *))(v146 + 8))(v2, v148);
LABEL_12:
      uint64_t v63 = MEMORY[0x22A6764B0](0);
      if (!v63)
      {
        __break(1u);
        JUMPOUT(0x2271556FCLL);
      }
      uint64_t v64 = v63;
      type metadata accessor for CMLTable();
      uint64_t v65 = OUTLINED_FUNCTION_70();
      *(void *)(v65 + 16) = v64;
      type metadata accessor for _DataTable();
      OUTLINED_FUNCTION_55_7();
      uint64_t v179 = (void (**)(void))_DataTable.init(impl:)(v65);
      char v180 = 0;
      static os_log_type_t.info.getter();
      OUTLINED_FUNCTION_20_1();
      log(_:type:)(v66, v67);
      goto LABEL_14;
    case 6u:
      uint64_t v70 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
      uint64_t v71 = v2 + v70[12];
      uint64_t v72 = *(void *)(v71 + 8);
      uint64_t v150 = *(void (***)(void))v71;
      uint64_t v73 = (uint64_t *)(v2 + v70[16]);
      uint64_t v74 = v73[1];
      uint64_t v149 = *v73;
      uint64_t v75 = (uint64_t *)(v2 + v70[20]);
      uint64_t v76 = v75[1];
      uint64_t v145 = *v75;
      uint64_t v77 = (uint64_t *)(v2 + v70[24]);
      uint64_t v78 = *v77;
      uint64_t v79 = v77[1];
      uint64_t v80 = v146;
      uint64_t v81 = v142;
      uint64_t v82 = v2;
      uint64_t v83 = v148;
      (*(void (**)(uint64_t, uint64_t, void *))(v146 + 32))(v142, v82, v148);
      (*(void (**)(uint64_t, uint64_t, void *))(v80 + 16))(v8, v81, v83);
      uint64_t v84 = v181;
      MLDataTable.init(_:convertArraysToShapedArrays:)(0, (uint64_t)&v151);
      if (v84)
      {
        (*(void (**)(uint64_t, void *))(v80 + 8))(v81, v148);
        swift_bridgeObjectRelease();
        swift_bridgeObjectRelease();
        swift_bridgeObjectRelease();
        swift_bridgeObjectRelease();
        return;
      }
      uint64_t v179 = (void (**)(void))v151;
      char v180 = v152;
      static _VideoUtilities.renameVideoTableColumns(table:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)((uint64_t)&v179, (uint64_t)v150, v72, v149, v74, v145, v76, v78, v79);
      OUTLINED_FUNCTION_33_10();
      OUTLINED_FUNCTION_2_24();
      v133();
      swift_bridgeObjectRelease();
      swift_bridgeObjectRelease();
      swift_bridgeObjectRelease();
      swift_bridgeObjectRelease();
      goto LABEL_14;
    default:
      uint64_t v24 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
      uint64_t v25 = v2 + v24[12];
      __n128 v26 = (uint64_t *)(v2 + v24[16]);
      uint64_t v28 = *v26;
      uint64_t v27 = (void *)v26[1];
      uint64_t v144 = v28;
      id v148 = v27;
      uint64_t v29 = (uint64_t *)(v2 + v24[20]);
      uint64_t v30 = v29[1];
      uint64_t v142 = *v29;
      uint64_t v31 = (uint64_t *)(v2 + v24[24]);
      uint64_t v33 = *v31;
      uint64_t v32 = v31[1];
      uint64_t v140 = v33;
      uint64_t v145 = v32;
      uint64_t v34 = (uint64_t *)(v2 + v24[28]);
      uint64_t v36 = *v34;
      uint64_t v35 = v34[1];
      uint64_t v139 = v36;
      uint64_t v146 = v35;
      uint64_t v37 = v150;
      uint64_t v38 = v150[4];
      uint64_t v39 = v143;
      uint64_t v40 = v149;
      ((void (*)(uint64_t, uint64_t, uint64_t))v38)(v143, v2, v149);
      uint64_t v41 = v141;
      ((void (*)(uint64_t, uint64_t, uint64_t))v38)(v141, v25, v40);
      ((void (*)(char *, uint64_t, uint64_t))v37[2])(v19, v41, v40);
      char v175 = 1;
      LOBYTE(v151) = 1;
      *(_DWORD *)((char *)&v151 + 1) = *(_DWORD *)v178;
      HIDWORD(v151) = *(_DWORD *)&v178[3];
      unint64_t v152 = 44;
      unint64_t v153 = 0xE100000000000000;
      uint64_t v154 = 0;
      unint64_t v155 = 0xE000000000000000;
      uint64_t v156 = 92;
      unint64_t v157 = 0xE100000000000000;
      char v158 = 1;
      *(_DWORD *)uint64_t v159 = *(_DWORD *)v177;
      *(_DWORD *)&v159[3] = *(_DWORD *)&v177[3];
      uint64_t v160 = 34;
      unint64_t v161 = 0xE100000000000000;
      char v162 = 1;
      *(_DWORD *)uint64_t v163 = *(_DWORD *)v176;
      *(_DWORD *)&v163[3] = *(_DWORD *)&v176[3];
      uint64_t v164 = &outlined read-only object #0 of default argument 1 of MLDataTable.init(contentsOf:options:);
      uint64_t v165 = 10;
      unint64_t v166 = 0xE100000000000000;
      uint64_t v167 = 0;
      uint64_t v168 = 0;
      char v169 = 1;
      *(_DWORD *)uint64_t v170 = *(_DWORD *)v174;
      *(_DWORD *)&v170[3] = *(_DWORD *)&v174[3];
      uint64_t v171 = 0;
      uint64_t v42 = v181;
      MLDataTable.init(contentsOf:options:)(v19, &v151, (uint64_t)&v172);
      if (v42)
      {
        uint64_t v43 = v37[1];
        ((void (*)(uint64_t, uint64_t))v43)(v41, v40);
        swift_bridgeObjectRelease();
        swift_bridgeObjectRelease();
        swift_bridgeObjectRelease();
        swift_bridgeObjectRelease();
        ((void (*)(uint64_t, uint64_t))v43)(v39, v40);
      }
      else
      {
        uint64_t v181 = v30;
        uint64_t v85 = v145;
        uint64_t v86 = v146;
        uint64_t v179 = v172;
        char v180 = v173;
        uint64_t v87 = v144;
        uint64_t v88 = v148;
        MLDataTable.subscript.getter(v144, v148, (uint64_t)&v151);
        id v89 = (id)v151;
        unint64_t v90 = v152;
        if ((v152 & 1) != 0
          || (outlined copy of Result<_DataTable, Error>((id)v151, 0),
              _UntypedColumn.type.getter(&v172),
              outlined consume of Result<_DataTable, Error>(v89, 0),
              v172 != 2))
        {
          outlined consume of Result<_DataTable, Error>(v89, v90);
          swift_bridgeObjectRelease();
          swift_bridgeObjectRelease();
          swift_bridgeObjectRelease();
          uint64_t v151 = 0;
          unint64_t v152 = 0xE000000000000000;
          _StringGuts.grow(_:)(26);
          swift_bridgeObjectRelease();
          uint64_t v151 = 0x206E6D756C6F43;
          unint64_t v152 = 0xE700000000000000;
          v107._uint64_t countAndFlagsBits = v87;
          v107._uint64_t object = v88;
          String.append(_:)(v107);
          swift_bridgeObjectRelease();
          OUTLINED_FUNCTION_20_1();
          v108._uint64_t countAndFlagsBits = 0xD000000000000011;
          String.append(_:)(v108);
          OUTLINED_FUNCTION_43_8();
          lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
          uint64_t v109 = OUTLINED_FUNCTION_85();
          *uint64_t v110 = v90;
          v110[1] = (unint64_t)&v151;
          OUTLINED_FUNCTION_8_4(v109, (uint64_t)v110);
          char v111 = v150[1];
          OUTLINED_FUNCTION_6_26();
          v111();
          OUTLINED_FUNCTION_6_26();
          v111();
LABEL_30:
          outlined consume of Result<_DataTable, Error>(v179, v180);
        }
        else
        {
          outlined copy of Result<_DataTable, Error>(v89, 0);
          unint64_t v91 = (unint64_t)v89;
          _UntypedColumn.valueAtIndex(index:)(0, (uint64_t)&v151);
          OUTLINED_FUNCTION_43_8();
          if (v153 != 2)
          {
            outlined consume of MLDataValue((void *)v90, v89, v153);
            unint64_t v91 = 0xE000000000000000;
          }
          outlined consume of Result<_DataTable, Error>(v89, 0);
          OUTLINED_FUNCTION_27_14();
          *(void *)(v92 - 256) = v91;
          String.init<A>(_:)();
          URL.init(fileURLWithPath:)();
          swift_bridgeObjectRelease();
          id v93 = objc_msgSend(self, sel_defaultManager);
          uint64_t v94 = URL.path.getter();
          uint64_t v95 = (void *)MEMORY[0x22A674AE0](v94);
          swift_bridgeObjectRelease();
          unsigned __int8 v96 = objc_msgSend(v93, sel_fileExistsAtPath_, v95);

          if ((v96 & 1) == 0)
          {
            outlined copy of Result<_DataTable, Error>(v89, 0);
            uint64_t v97 = specialized Array<A>.init(_:)(v89, 0);
            MEMORY[0x270FA5388](v97);
            uint64_t v98 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSaySSG_SSs5NeverOTg5((uint64_t)partial apply for closure #1 in static _VideoUtilities.getVideoURLsAndAnnotations(from:), (uint64_t)(&v139 - 4), v97);
            uint64_t v99 = swift_bridgeObjectRelease();
            uint64_t v151 = v98;
            MEMORY[0x270FA5388](v99);
            uint64_t v138 = &v151;
            uint64_t ML14_UntypedColumnC_s5Error_pTgm5 = (void *)_ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTgm5((void (*)(uint64_t *__return_ptr, uint64_t *))partial apply for specialized closure #1 in MLUntypedColumn.init<A>(_:));
            char v102 = v101 & 1;
            uint64_t v87 = v144;
            swift_bridgeObjectRelease();
            swift_bridgeObjectRetain();
            MLDataTable.willMutate()();
            OUTLINED_FUNCTION_27_14();
            *(unsigned char *)(v103 - 256) = v102;
            MLDataTable.setColumnImpl(newColumn:named:)(&v151);
            swift_bridgeObjectRelease();
            outlined consume of Result<_DataTable, Error>(ML14_UntypedColumnC_s5Error_pTgm5, v102);
            if ((v180 & 1) == 0)
            {
              outlined copy of Result<_DataTable, Error>(v179, 0);
              _DataTable.columnNamesDidChange()();
              OUTLINED_FUNCTION_26_9();
            }
          }
          static _VideoUtilities.renameVideoTableColumns(table:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)((uint64_t)&v179, v87, (uint64_t)v88, v142, v181, v140, v85, v139, v86);
          OUTLINED_FUNCTION_33_10();
          uint64_t v104 = v150;
          swift_bridgeObjectRelease();
          swift_bridgeObjectRelease();
          swift_bridgeObjectRelease();
          swift_bridgeObjectRelease();
          outlined consume of Result<_DataTable, Error>(v89, 0);
          uint64_t v137 = v104[1];
          OUTLINED_FUNCTION_6_26();
          v137();
          OUTLINED_FUNCTION_6_26();
          v137();
          OUTLINED_FUNCTION_6_26();
          v137();
LABEL_14:
          char v68 = v180;
          uint64_t v69 = v147;
          *char v147 = v179;
          *((unsigned char *)v69 + 8) = v68;
        }
      }
      return;
  }
}

uint64_t closure #1 in static _VideoUtilities.getVideoURLsAndAnnotations(from:)@<X0>(uint64_t *a1@<X8>)
{
  uint64_t v2 = type metadata accessor for URL();
  uint64_t v3 = *(void *)(v2 - 8);
  MEMORY[0x270FA5388](v2);
  uint64_t v5 = (char *)&v10 - ((v4 + 15) & 0xFFFFFFFFFFFFFFF0);
  URL.appendingPathComponent(_:)();
  uint64_t v6 = URL.path.getter();
  uint64_t v8 = v7;
  uint64_t result = (*(uint64_t (**)(char *, uint64_t))(v3 + 8))(v5, v2);
  *a1 = v6;
  a1[1] = v8;
  return result;
}

void static _VideoUtilities.renameVideoTableColumns(table:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
  uint64_t v34 = a8;
  uint64_t v15 = *(void **)a1;
  char v16 = *(unsigned char *)(a1 + 8);
  uint64_t v32 = v15;
  char v33 = v16;
  outlined copy of Result<_DataTable, Error>(v15, v16);
  static _VideoUtilities.validateVideoInput(trainingData:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)((uint64_t)&v32, a2, a3, a4, a5, a6, a7, v34, a9);
  outlined consume of Result<_DataTable, Error>(v15, v16);
  if (!v31)
  {
    if (a7)
    {
      MLDataTable.willMutate()();
      OUTLINED_FUNCTION_36_11();
      MLDataTable.renameImpl(named:to:)(v17, v18, v19, v20);
      if ((*(unsigned char *)(a1 + 8) & 1) == 0)
      {
        OUTLINED_FUNCTION_1_32();
        OUTLINED_FUNCTION_26_9();
      }
    }
    uint64_t v21 = v34;
    if (a9)
    {
      MLDataTable.willMutate()();
      MLDataTable.renameImpl(named:to:)(v21, a9, 6581861, 0xE300000000000000);
      if ((*(unsigned char *)(a1 + 8) & 1) == 0)
      {
        OUTLINED_FUNCTION_1_32();
        OUTLINED_FUNCTION_26_9();
      }
    }
    MLDataTable.willMutate()();
    OUTLINED_FUNCTION_18_15();
    MLDataTable.renameImpl(named:to:)(v22, v23, v24, v25);
    if ((*(unsigned char *)(a1 + 8) & 1) == 0)
    {
      OUTLINED_FUNCTION_1_32();
      OUTLINED_FUNCTION_26_9();
    }
    MLDataTable.willMutate()();
    uint64_t v26 = OUTLINED_FUNCTION_20_17();
    MLDataTable.renameImpl(named:to:)(v26, v27, v28, v29);
    if ((*(unsigned char *)(a1 + 8) & 1) == 0)
    {
      OUTLINED_FUNCTION_1_32();
      OUTLINED_FUNCTION_26_9();
    }
  }
}

void static _VideoUtilities.renameVideoColumns(dataFrame:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)(int a1, int a2, int a3, int a4, int a5, int a6, uint64_t a7, uint64_t _, void *_a)
{
  if (a7)
  {
    OUTLINED_FUNCTION_36_11();
    DataFrame.renameColumn(_:to:)(v10, v11);
  }
  if (_a)
  {
    v12._uint64_t countAndFlagsBits = _;
    v12._uint64_t object = _a;
    v13._uint64_t countAndFlagsBits = 6581861;
    v13._uint64_t object = (void *)0xE300000000000000;
    DataFrame.renameColumn(_:to:)(v12, v13);
  }
  OUTLINED_FUNCTION_18_15();
  DataFrame.renameColumn(_:to:)(v14, v15);
  v16._uint64_t countAndFlagsBits = OUTLINED_FUNCTION_20_17();
  DataFrame.renameColumn(_:to:)(v16, v17);
}

void static _VideoUtilities.renameFeatureColumns(dataFrame:sessionIdColumn:featureColumn:labelColumn:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, void *a7)
{
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<String>);
  uint64_t inited = swift_initStackObject();
  *(_OWORD *)(inited + 16) = xmmword_2272CB4A0;
  *(void *)(inited + 32) = a2;
  *(void *)(inited + 40) = a3;
  *(void *)(inited + 48) = a4;
  *(void *)(inited + 56) = a5;
  *(void *)(inited + 64) = a6;
  *(void *)(inited + 72) = a7;
  swift_bridgeObjectRetain();
  swift_bridgeObjectRetain();
  swift_bridgeObjectRetain();
  OUTLINED_FUNCTION_14_17();
  DataFrame.validateContainsColumns(_:context:)(v14, v15);
  swift_setDeallocating();
  specialized _ContiguousArrayStorage.__deallocating_deinit();
  if (!v16)
  {
    OUTLINED_FUNCTION_19_17();
    DataFrame.renameColumn(_:to:)(v17, v18);
    OUTLINED_FUNCTION_15_17();
    DataFrame.renameColumn(_:to:)(v19, v20);
    v21._uint64_t countAndFlagsBits = a6;
    v21._uint64_t object = a7;
    v22._uint64_t countAndFlagsBits = 0x6C6562616CLL;
    v22._uint64_t object = (void *)0xE500000000000000;
    DataFrame.renameColumn(_:to:)(v21, v22);
  }
}

uint64_t static _VideoUtilities.videoURLsPerClass(from:)(uint64_t a1)
{
  uint64_t v59 = type metadata accessor for URL();
  OUTLINED_FUNCTION_0_15();
  uint64_t v5 = v4;
  MEMORY[0x270FA5388](v6);
  OUTLINED_FUNCTION_27_7();
  uint64_t v7 = (void (**)(void))type metadata accessor for MLHandActionClassifier.DataSource();
  MEMORY[0x270FA5388](v7);
  uint64_t v9 = (id *)((char *)v36 - ((v8 + 15) & 0xFFFFFFFFFFFFFFF0));
  outlined init with copy of MLHandActionClassifier.DataSource(a1, (uint64_t)v9);
  if (swift_getEnumCaseMultiPayload() == 3)
  {
    outlined consume of Result<_DataTable, Error>(*v9, *((unsigned char *)v9 + 8));
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    return MEMORY[0x263F8EE80];
  }
  static _VideoUtilities.getVideoURLsAndAnnotations(from:)(a1, &v49);
  if (v1)
  {
    swift_bridgeObjectRelease();
    outlined destroy of MLHandActionClassifier.DataSource((uint64_t)v9);
    return (uint64_t)v7;
  }
  Swift::String v10 = v49;
  int v11 = v50;
  outlined copy of Result<_DataTable, Error>(v49, v50);
  OUTLINED_FUNCTION_25_15();
  specialized MLDataTable.subscript.getter(v11, v12);
  uint64_t v41 = v10;
  int v40 = v11;
  outlined consume of Result<_DataTable, Error>(v10, v11);
  OUTLINED_FUNCTION_31_9();
  outlined consume of Result<_DataTable, Error>(v10, v11);
  uint64_t result = specialized Array<A>.init(_:)(v49, v50);
  uint64_t v39 = *(void *)(result + 16);
  if (!v39)
  {
    swift_bridgeObjectRelease();
    uint64_t v7 = (void (**)(void))MEMORY[0x263F8EE80];
LABEL_18:
    outlined consume of Result<_DataTable, Error>(v41, v40);
    outlined destroy of MLHandActionClassifier.DataSource((uint64_t)v9);
    return (uint64_t)v7;
  }
  v36[0] = v9;
  v36[1] = 0;
  unint64_t v14 = 0;
  uint64_t v37 = result + 32;
  uint64_t v7 = (void (**)(void))MEMORY[0x263F8EE80];
  uint64_t v38 = result;
  while (v14 < *(void *)(result + 16))
  {
    unint64_t v47 = v14;
    uint64_t v48 = v7;
    uint64_t v15 = v37 + 16 * v14;
    Swift::String v17 = *(void (***)(void))v15;
    uint64_t v16 = *(void *)(v15 + 8);
    Swift::String v18 = v41;
    uint64_t v49 = v41;
    char v19 = v40;
    LOBYTE(v50) = v40;
    outlined copy of Result<_DataTable, Error>(v41, v40);
    swift_bridgeObjectRetain();
    uint64_t v20 = OUTLINED_FUNCTION_25_15();
    MLDataTable.subscript.getter(v20, v21, v22);
    outlined consume of Result<_DataTable, Error>(v18, v19);
    uint64_t v23 = v55;
    char v24 = v56;
    int v53 = v55;
    char v54 = v56;
    uint64_t v51 = MEMORY[0x263F8D310];
    id v52 = &protocol witness table for String;
    uint64_t v45 = v17;
    uint64_t v46 = v16;
    uint64_t v49 = v17;
    uint64_t v50 = v16;
    swift_bridgeObjectRetain();
    static MLUntypedColumn.== infix(_:_:)();
    outlined consume of Result<_DataTable, Error>(v23, v24);
    __swift_destroy_boxed_opaque_existential_0((uint64_t)&v49);
    uint64_t v25 = v57;
    LOBYTE(v16) = v58;
    uint64_t v55 = v18;
    char v56 = v19;
    int v53 = (void (**)(void))v57;
    char v54 = v58;
    outlined copy of Result<_DataTable, Error>(v18, v19);
    MLDataTable.subscript.getter((uint64_t)&v53, (uint64_t)&v49);
    outlined consume of Result<_DataTable, Error>(v25, v16);
    outlined consume of Result<_DataTable, Error>(v18, v19);
    uint64_t v26 = v49;
    int v27 = v50;
    outlined copy of Result<_DataTable, Error>(v49, v50);
    specialized MLDataTable.subscript.getter(v27, (uint64_t)&v57);
    outlined consume of Result<_DataTable, Error>(v26, v27);
    OUTLINED_FUNCTION_31_9();
    outlined consume of Result<_DataTable, Error>(v25, (char)&v55);
    uint64_t v28 = specialized Array<A>.init(_:)(v49, v50);
    uint64_t v29 = *(void *)(v28 + 16);
    if (v29)
    {
      int v43 = v27;
      uint64_t v44 = v26;
      uint64_t v49 = (void (**)(void))MEMORY[0x263F8EE78];
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v29, 0);
      uint64_t v30 = v49;
      uint64_t v42 = v28;
      uint64_t v31 = v28 + 40;
      do
      {
        swift_bridgeObjectRetain();
        URL.init(fileURLWithPath:)();
        swift_bridgeObjectRelease();
        uint64_t v49 = v30;
        unint64_t v33 = (unint64_t)v30[2];
        unint64_t v32 = (unint64_t)v30[3];
        if (v33 >= v32 >> 1)
        {
          char v34 = OUTLINED_FUNCTION_91(v32);
          specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v34, v33 + 1, 1);
          uint64_t v30 = v49;
        }
        v31 += 16;
        _OWORD v30[2] = (void (*)(void))(v33 + 1);
        (*(void (**)(unint64_t, uint64_t, uint64_t))(v5 + 32))((unint64_t)v30+ ((*(unsigned __int8 *)(v5 + 80) + 32) & ~(unint64_t)*(unsigned __int8 *)(v5 + 80))+ *(void *)(v5 + 72) * v33, v2, v59);
        --v29;
      }
      while (v29);
      swift_bridgeObjectRelease();
      uint64_t v35 = v48;
      uint64_t v26 = v44;
      LOBYTE(v27) = v43;
    }
    else
    {
      swift_bridgeObjectRelease();
      uint64_t v35 = v48;
    }
    unint64_t v14 = v47 + 1;
    swift_isUniquelyReferenced_nonNull_native();
    uint64_t v49 = v35;
    specialized _NativeDictionary.setValue(_:forKey:isUnique:)();
    uint64_t v7 = v49;
    swift_bridgeObjectRelease();
    swift_bridgeObjectRelease();
    outlined consume of Result<_DataTable, Error>(v26, v27);
    uint64_t result = v38;
    if (v14 == v39)
    {
      swift_bridgeObjectRelease();
      uint64_t v9 = (id *)v36[0];
      goto LABEL_18;
    }
  }
  __break(1u);
  return result;
}

double *specialized UnsafeMutableBufferPointer.initialize(repeating:)(double *result, uint64_t a2, double a3)
{
  if (result)
  {
    if (a2 < 0)
    {
      __break(1u);
    }
    else
    {
      for (; a2; --a2)
        *result++ = a3;
    }
  }
  return result;
}

unint64_t static _VideoUtilities.handKeypointsToMultiArray(_:)()
{
  OUTLINED_FUNCTION_47_9();
  v22[1] = *(id *)MEMORY[0x263EF8340];
  if (v2 >> 62)
  {
    OUTLINED_FUNCTION_10_5();
    uint64_t v3 = _CocoaArrayWrapper.endIndex.getter();
    swift_bridgeObjectRelease();
  }
  else
  {
    uint64_t v3 = *(void *)((v1 & 0xFFFFFFFFFFFFFF8) + 0x10);
  }
  if (v3 < 1)
  {
    v22[0] = (id)MEMORY[0x263F8EE78];
    specialized ContiguousArray.reserveCapacity(_:)();
    objc_msgSend(objc_allocWithZone(NSNumber), sel_initWithInteger_, 1);
    specialized ContiguousArray._makeUniqueAndReserveCapacityIfNotUnique()();
    OUTLINED_FUNCTION_13_24();
    OUTLINED_FUNCTION_22_15();
    specialized ContiguousArray._endMutation()();
    objc_msgSend(objc_allocWithZone(NSNumber), sel_initWithInteger_, 3);
    specialized ContiguousArray._makeUniqueAndReserveCapacityIfNotUnique()();
    OUTLINED_FUNCTION_13_24();
    OUTLINED_FUNCTION_22_15();
    specialized ContiguousArray._endMutation()();
    objc_msgSend(objc_allocWithZone(NSNumber), sel_initWithInteger_, 21);
    specialized ContiguousArray._makeUniqueAndReserveCapacityIfNotUnique()();
    OUTLINED_FUNCTION_13_24();
    OUTLINED_FUNCTION_22_15();
    specialized ContiguousArray._endMutation()();
    unint64_t v1 = (unint64_t)objc_allocWithZone(MEMORY[0x263F00DA8]);
    id v12 = @nonobjc MLMultiArray.init(shape:dataType:)((uint64_t)v22[0], 65600);
    if (!v0)
    {
      unint64_t v1 = (unint64_t)v12;
      Swift::String v13 = (double *)UnsafeMutableBufferPointer.init(_:)();
      specialized UnsafeMutableBufferPointer.initialize(repeating:)(v13, v14, 0.0);
    }
  }
  else
  {
    uint64_t v4 = static _VideoUtilities.pickSingleHand(_:)();
    if (!v0)
    {
      uint64_t v5 = v4;
      if (v4)
      {
        v22[0] = 0;
        id v6 = objc_msgSend(v4, sel_keypointsMultiArrayAndReturnError_, v22);
        if (v6)
        {
          unint64_t v1 = (unint64_t)v6;
          id v7 = v22[0];
          id v8 = objc_msgSend((id)v1, sel_shape);
          type metadata accessor for NSAttributedString(0, (unint64_t *)&lazy cache variable for type metadata for NSNumber);
          unint64_t v9 = static Array._unconditionallyBridgeFromObjectiveC(_:)();

          _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSaySo8NSNumberCG_Sis5NeverOTg50125_s8CreateML20MLHandPoseClassifierV15modelPrediction2on5usingSaySS5label_Sd10confidencetGSo12MLMultiArrayC_So7MLModelCtKFSiSo8D54Ccfu_33_5bdac5b40c7411f20a64c1277f8fd44fAOSiTf3nnnpk_nTf1cn_n(v9);
          int v11 = v10;
          swift_bridgeObjectRelease();
          LOBYTE(v9) = specialized static Array<A>.== infix(_:_:)(v11, outlined read-only object #0 of static _VideoUtilities.handKeypointsToMultiArray(_:));
          swift_bridgeObjectRelease();
          if (v9)
          {
          }
          else
          {
            lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
            OUTLINED_FUNCTION_85();
            OUTLINED_FUNCTION_40_6();
            *char v19 = v18 | 3;
            v19[1] = 0x80000002272D7B20;
            OUTLINED_FUNCTION_8_4(v20, (uint64_t)v19);
          }
        }
        else
        {
          unint64_t v1 = (unint64_t)v22[0];
          _convertNSErrorToError(_:)();

          swift_willThrow();
        }
      }
      else
      {
        lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
        OUTLINED_FUNCTION_85();
        OUTLINED_FUNCTION_40_6();
        *uint64_t v15 = v16;
        v15[1] = 0x80000002272D7AF0;
        OUTLINED_FUNCTION_8_4(v17, (uint64_t)v15);
      }
    }
  }
  return v1;
}

void *static _VideoUtilities.pickSingleHand(_:)()
{
  OUTLINED_FUNCTION_47_9();
  if (v2 >> 62) {
    goto LABEL_21;
  }
  uint64_t v3 = *(void *)((v1 & 0xFFFFFFFFFFFFFF8) + 0x10);
  swift_bridgeObjectRetain();
  if (v3)
  {
    while (1)
    {
      unint64_t v4 = v1 & 0xC000000000000001;
      specialized Array._checkSubscript(_:wasNativeTypeChecked:)(0, (v1 & 0xC000000000000001) == 0, v1);
      id v5 = (v1 & 0xC000000000000001) != 0 ? (id)MEMORY[0x22A6753B0](0, v1) : *(id *)(v1 + 32);
      id v6 = v5;
      if (v3 == 1) {
        break;
      }
      uint64_t v7 = 5;
      while (1)
      {
        specialized Array._checkSubscript(_:wasNativeTypeChecked:)(v7 - 4, v4 == 0, v1);
        id v8 = v4 ? (id)MEMORY[0x22A6753B0](v7 - 4, v1) : *(id *)(v1 + 8 * v7);
        unint64_t v9 = v8;
        uint64_t v10 = v7 - 3;
        if (__OFADD__(v7 - 4, 1)) {
          break;
        }
        static _VideoUtilities.measureHandSize(_:)();
        if (v0)
        {

          swift_bridgeObjectRelease();
          return v6;
        }
        double v12 = v11;
        static _VideoUtilities.measureHandSize(_:)();
        uint64_t v0 = 0;
        if (v12 >= v13) {
          uint64_t v14 = v9;
        }
        else {
          uint64_t v14 = v6;
        }
        if (v12 < v13) {
          id v6 = v9;
        }

        ++v7;
        if (v10 == v3) {
          goto LABEL_18;
        }
      }
      __break(1u);
LABEL_21:
      OUTLINED_FUNCTION_10_5();
      uint64_t v3 = _CocoaArrayWrapper.endIndex.getter();
      if (!v3) {
        goto LABEL_22;
      }
    }
LABEL_18:
    swift_bridgeObjectRelease();
  }
  else
  {
LABEL_22:
    swift_bridgeObjectRelease();
    return 0;
  }
  return v6;
}

double *static _VideoUtilities.resetMultiArray(_:with:)(void *a1, double a2)
{
  id v4 = a1;
  uint64_t result = (double *)UnsafeMutableBufferPointer.init(_:)();
  if (!v2 && result)
  {
    if (v6 < 0)
    {
      __break(1u);
    }
    else
    {
      for (; v6; --v6)
        *result++ = a2;
    }
  }
  return result;
}

id VNVideoProcessor.__allocating_init(url:)(uint64_t a1)
{
  id v2 = objc_allocWithZone((Class)swift_getObjCClassFromMetadata());
  URL._bridgeToObjectiveC()(v3);
  id v5 = v4;
  id v6 = objc_msgSend(v2, sel_initWithURL_, v4);

  uint64_t v7 = type metadata accessor for URL();
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v7 - 8) + 8))(a1, v7);
  return v6;
}

void closure #1 in static _VideoUtilities.getHandKeyPointsFromVideoUrl(url:startTime:endTime:targetFrameRate:)(void *a1, void *a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  id v6 = (uint64_t *)(a3 + 16);
  if (a2)
  {
    OUTLINED_FUNCTION_37_8();
    id v8 = (void *)*v6;
    *id v6 = (uint64_t)a2;
    id v9 = a2;
    uint64_t v10 = v8;
LABEL_11:

    return;
  }
  unint64_t v13 = outlined bridged method (pb) of @objc VNRequest.results.getter(a1);
  if (!v13 || (unint64_t v14 = specialized _arrayConditionalCast<A, B>(_:)(v13), swift_bridgeObjectRelease(), !v14))
  {
    _StringGuts.grow(_:)(62);
    OUTLINED_FUNCTION_40_6();
    OUTLINED_FUNCTION_20_1();
    String.append(_:)(v15);
    type metadata accessor for URL();
    lazy protocol witness table accessor for type URL and conformance URL((unint64_t *)&lazy protocol witness table cache variable for type URL and conformance URL, MEMORY[0x263F06EA8]);
    v16._uint64_t countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter();
    String.append(_:)(v16);
    swift_bridgeObjectRelease();
    v17._uint64_t countAndFlagsBits = 46;
    v17._uint64_t object = (void *)0xE100000000000000;
    String.append(_:)(v17);
    lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    uint64_t v18 = OUTLINED_FUNCTION_85();
    *(void *)uint64_t v19 = 0;
    *(void *)(v19 + 8) = 0xE000000000000000;
    *(_OWORD *)(v19 + 16) = 0u;
    *(_OWORD *)(v19 + 32) = 0u;
    *(unsigned char *)(v19 + 48) = 0;
    OUTLINED_FUNCTION_37_8();
    uint64_t v10 = (void *)*v6;
    *id v6 = v18;
    goto LABEL_11;
  }
  if (v14 >> 62)
  {
    swift_bridgeObjectRetain();
    uint64_t v25 = _CocoaArrayWrapper.endIndex.getter();
    swift_bridgeObjectRelease();
    if (v25) {
      goto LABEL_9;
    }
  }
  else if (*(void *)((v14 & 0xFFFFFFFFFFFFFF8) + 0x10))
  {
LABEL_9:
    uint64_t v20 = (void *)static _VideoUtilities.handKeypointsToMultiArray(_:)();
    Swift::String v21 = (uint64_t *)(a6 + 16);
    swift_bridgeObjectRelease();
    id v22 = v20;
    MLDataValue.MultiArrayType.init(_:)((MLMultiArray)v22);
    swift_beginAccess();
    specialized Array._makeUniqueAndReserveCapacityIfNotUnique()();
    uint64_t v23 = *(void *)(*v21 + 16);
    specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(v23);
    uint64_t v24 = *v21;
    *(void *)(v24 + 16) = v23 + 1;
    *(void *)(v24 + 8 * v23 + 32) = v26;
    swift_endAccess();

    return;
  }
  swift_beginAccess();
  if (!__OFADD__(*(void *)(a5 + 16), 1))
  {
    ++*(void *)(a5 + 16);
    goto LABEL_9;
  }
  __break(1u);
}

uint64_t static _VideoUtilities.measureHandSize(_:)()
{
  OUTLINED_FUNCTION_47_9();
  v30[1] = *(id *)MEMORY[0x263EF8340];
  uint64_t v1 = (void *)MEMORY[0x22A674AE0](0x6C6C414F50494E56, 0xE800000000000000);
  v30[0] = 0;
  id v2 = objc_msgSend(v0, sel_recognizedPointsForGroupKey_error_, v1, v30);

  id v3 = v30[0];
  if (v2)
  {
    type metadata accessor for VNRecognizedPointKey(0);
    type metadata accessor for NSAttributedString(0, &lazy cache variable for type metadata for VNRecognizedPoint);
    lazy protocol witness table accessor for type URL and conformance URL(&lazy protocol witness table cache variable for type VNRecognizedPointKey and conformance VNRecognizedPointKey, type metadata accessor for VNRecognizedPointKey);
    uint64_t v4 = static Dictionary._unconditionallyBridgeFromObjectiveC(_:)();
    id v5 = v3;

    int64_t v6 = 0;
    uint64_t v7 = v4 + 64;
    uint64_t v8 = 1 << *(unsigned char *)(v4 + 32);
    uint64_t v9 = -1;
    if (v8 < 64) {
      uint64_t v9 = ~(-1 << v8);
    }
    unint64_t v10 = v9 & *(void *)(v4 + 64);
    int64_t v11 = (unint64_t)(v8 + 63) >> 6;
    double v12 = -1.0;
    double v13 = 1000.0;
    double v14 = -1.0;
    double v15 = 1000.0;
    while (1)
    {
      if (v10)
      {
        unint64_t v16 = __clz(__rbit64(v10));
        v10 &= v10 - 1;
        unint64_t v17 = v16 | (v6 << 6);
      }
      else
      {
        int64_t v18 = v6 + 1;
        if (__OFADD__(v6, 1))
        {
          __break(1u);
          goto LABEL_35;
        }
        if (v18 >= v11) {
          return swift_release();
        }
        unint64_t v19 = *(void *)(v7 + 8 * v18);
        ++v6;
        if (!v19)
        {
          int64_t v6 = v18 + 1;
          if (v18 + 1 >= v11) {
            return swift_release();
          }
          unint64_t v19 = *(void *)(v7 + 8 * v6);
          if (!v19)
          {
            int64_t v6 = v18 + 2;
            if (v18 + 2 >= v11) {
              return swift_release();
            }
            unint64_t v19 = *(void *)(v7 + 8 * v6);
            if (!v19)
            {
              int64_t v20 = v18 + 3;
              if (v20 >= v11) {
                return swift_release();
              }
              unint64_t v19 = *(void *)(v7 + 8 * v20);
              if (!v19)
              {
                while (1)
                {
                  int64_t v6 = v20 + 1;
                  if (__OFADD__(v20, 1)) {
                    break;
                  }
                  if (v6 >= v11) {
                    return swift_release();
                  }
                  unint64_t v19 = *(void *)(v7 + 8 * v6);
                  ++v20;
                  if (v19) {
                    goto LABEL_20;
                  }
                }
LABEL_35:
                __break(1u);
              }
              int64_t v6 = v20;
            }
          }
        }
LABEL_20:
        unint64_t v10 = (v19 - 1) & v19;
        unint64_t v17 = __clz(__rbit64(v19)) + (v6 << 6);
      }
      id v21 = *(id *)(*(void *)(v4 + 56) + 8 * v17);
      objc_msgSend(v21, sel_confidence);
      if (v22 > 0.2)
      {
        OUTLINED_FUNCTION_45_7();
        if (v15 >= v23) {
          double v15 = v23;
        }
        OUTLINED_FUNCTION_45_7();
        if (v13 >= v24) {
          double v13 = v24;
        }
        OUTLINED_FUNCTION_45_7();
        if (v25 > v14) {
          double v14 = v25;
        }
        OUTLINED_FUNCTION_45_7();
        double v27 = v26;

        if (v27 > v12) {
          double v12 = v27;
        }
      }
      else
      {
      }
    }
  }
  id v29 = v30[0];
  _convertNSErrorToError(_:)();

  return swift_willThrow();
}

uint64_t specialized Double.init<A>(_:)(uint64_t a1, uint64_t a2)
{
  if ((a2 & 0x1000000000000000) != 0 || !(a2 & 0x2000000000000000 | a1 & 0x1000000000000000))
  {
    _StringGuts._slowWithCString<A>(_:)();
    swift_bridgeObjectRelease();
    char v6 = v9;
  }
  else
  {
    MEMORY[0x270FA5388](a1);
    if ((a2 & 0x2000000000000000) != 0)
    {
      char v6 = (v3 > 0x20u || ((0x100003E01uLL >> v3) & 1) == 0)
        && (uint64_t v7 = (unsigned char *)_swift_stdlib_strtod_clocale()) != 0
        && *v7 == 0;
      swift_bridgeObjectRelease();
    }
    else
    {
      if ((v3 & 0x1000000000000000) != 0)
      {
        uint64_t v4 = (a2 & 0xFFFFFFFFFFFFFFFLL) + 32;
        uint64_t v5 = v3 & 0xFFFFFFFFFFFFLL;
      }
      else
      {
        uint64_t v4 = _StringObject.sharedUTF8.getter();
      }
      char v6 = _sSRsRi_zrlE17withMemoryRebound2to_qd_1_qd__m_qd_1_SRyqd__Gqd_0_YKXEtqd_0_YKs5ErrorRd_0_Ri_d__Ri_d_1_r1_lFSRyxGq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lys4Int8VsAD_pqd_1_Isgyrzr_SRys5UInt8VGqd_1_sAD_pAIRszAGRsd__sAD_pRsd_0_Ri_d_1_r_1_lIetMgyrzo_Tpq5Sb_Tg507_sSRys4f5VGxs5E34_pIgyrzo_ACxsAD_pIegyrzr_lTRSb_TG5SRyAGGSbsAD_pIgyrzo_Tf1cn_n(v4, v5, (void (*)(uint64_t *__return_ptr))partial apply for specialized closure #1 in _StringGuts.withCString<A>(_:));
      swift_bridgeObjectRelease();
    }
  }
  if (v6) {
    return 0;
  }
  else {
    return 0;
  }
}

void closure #1 in static _VideoUtilities.reformatKeypointsDataTable(table:featureColumn:keypointsShape:)(uint64_t a1@<X0>, uint64_t a2@<X1>, void *a3@<X8>)
{
  if (*(unsigned char *)(a1 + 16) == 3)
  {
    uint64_t v5 = *(void **)(a1 + 8);
    uint64_t v7 = *(void **)a1;
    char v6 = v7;
    swift_retain();
    static _VideoUtilities.convertKeypointsSequenceToMultiArray(value:keypointsShape:)((uint64_t *)&v7, a2, a3);
    outlined consume of MLDataValue(v6, v5, 3);
  }
  else
  {
    *a3 = 0;
  }
}

void static _VideoUtilities.convertKeypointsSequenceToMultiArray(value:keypointsShape:)(uint64_t *a1@<X0>, uint64_t a2@<X1>, void *a3@<X8>)
{
  uint64_t v5 = *a1;
  id v6 = objc_allocWithZone(MEMORY[0x263F00DA8]);
  uint64_t v7 = swift_bridgeObjectRetain();
  uint64_t v8 = 0;
  id v9 = @nonobjc MLMultiArray.init(shape:dataType:)(v7, 65600);
  if (!v9) {
    goto LABEL_65;
  }
  id v10 = v9;
  uint64_t v11 = UnsafeMutableBufferPointer.init(_:)();
  swift_retain();
  CMLSequence.size.getter();
  uint64_t v12 = specialized RandomAccessCollection<>.distance(from:to:)();
  swift_release();
  if (v12 != 1)
  {

LABEL_65:
    *a3 = 0;
    return;
  }
  uint64_t v110 = 0;
  uint64_t v111 = 0;
  unint64_t v97 = a2 & 0xC000000000000001;
  uint64_t v93 = a2 & 0xFFFFFFFFFFFFFF8;
  uint64_t v109 = v5;
  swift_retain();
  uint64_t v100 = v11;
  uint64_t v98 = a2;
  while (1)
  {
    specialized EnumeratedSequence.Iterator.next()((uint64_t)&v105);
    int v14 = (int)v105;
    id v13 = v106;
    id v15 = v107;
    char v16 = v108;
    id v99 = v106;
    *(void *)uint64_t v103 = v105;
    if (v108 != 3)
    {
      if (v108 == 255)
      {
        swift_release();
        MLDataValue.MultiArrayType.init(_:)((MLMultiArray)v10);
        *a3 = v105;
        return;
      }

      swift_release();
      unint64_t v90 = v99;
      int v91 = v103[0];
      goto LABEL_75;
    }
    outlined copy of MLDataValue(v106, v107, 3);
    outlined copy of MLDataValue(v13, v15, 3);
    CMLSequence.size.getter();
    uint64_t v17 = specialized RandomAccessCollection<>.distance(from:to:)();
    OUTLINED_FUNCTION_12_17(v14);
    specialized Array._checkSubscript(_:wasNativeTypeChecked:)(1, v97 == 0, v98);
    if (v97) {
      id v18 = (id)MEMORY[0x22A6753B0](1, v98);
    }
    else {
      id v18 = *(id *)(v98 + 40);
    }
    unint64_t v19 = v18;
    id v20 = objc_msgSend(v18, sel_integerValue);

    if ((id)v17 != v20)
    {

      swift_release();
      char v16 = 3;
      int v91 = v103[0];
      unint64_t v90 = v99;
      OUTLINED_FUNCTION_12_17(v103[0]);
LABEL_75:
      outlined consume of (offset: Int, element: MLDataValue)?(v91, v90, v15, v16);
      goto LABEL_65;
    }
    outlined copy of MLDataValue(v99, v15, 3);
    if (CMLSequence.size.getter()) {
      break;
    }
    uint64_t v22 = (uint64_t)v99;
LABEL_62:
    outlined consume of (offset: Int, element: MLDataValue)?(v103[0], (void *)v22, v15, 3);
    outlined consume of (offset: Int, element: MLDataValue)?(v103[0], (void *)v22, v15, 3);
    OUTLINED_FUNCTION_12_17(v103[0]);
  }
  uint64_t v21 = 0;
  uint64_t v22 = (uint64_t)v99;
  id v94 = v15;
  uint64_t v95 = (uint64_t)a3;
  while (1)
  {
    swift_retain();
    CMLSequence.value(at:)(v21);
    uint64_t v24 = v23;
    OUTLINED_FUNCTION_12_17(v103[0]);
    double v25 = v15;
    MLDataValue.init(_:)(v24, (uint64_t)&v105);
    double v26 = v105;
    id v104 = v106;
    int v27 = v107;
    swift_retain();
    uint64_t v28 = CMLSequence.size.getter();
    outlined consume of (offset: Int, element: MLDataValue)?(v103[0], (void *)v22, v25, 3);
    uint64_t v102 = v21;
    if (v21 >= v28) {
      goto LABEL_85;
    }
    id v29 = (char *)v98;
    if (v27 != 3)
    {
      uint64_t v30 = v104;
      goto LABEL_71;
    }
    uint64_t v30 = v104;
    outlined copy of MLDataValue(v26, v104, 3);
    outlined copy of MLDataValue(v26, v104, 3);
    uint64_t v31 = CMLSequence.size.getter();
    if (CMLSequence.size.getter() < 0) {
      goto LABEL_86;
    }
    uint64_t v32 = CMLSequence.size.getter();
    OUTLINED_FUNCTION_3_36();
    if (v31 < 0 || v32 < v31) {
      goto LABEL_87;
    }
    if (v97)
    {
      id v33 = (id)MEMORY[0x22A6753B0](2, v98);
    }
    else
    {
      if (*(void *)(v93 + 16) < 3uLL) {
        goto LABEL_88;
      }
      id v33 = *(id *)(v98 + 48);
    }
    uint64_t v22 = (uint64_t)v33;
    id v34 = objc_msgSend(v33, sel_integerValue);

    if ((id)v31 != v34) {
      break;
    }
    swift_retain();
    if (CMLSequence.size.getter())
    {
      uint64_t v35 = 0;
      while (1)
      {
        swift_retain();
        CMLSequence.value(at:)(v35);
        OUTLINED_FUNCTION_3_36();
        switch(CMLFeatureValue.type.getter())
        {
          case 1u:
            OUTLINED_FUNCTION_99();
            specialized handling<A, B>(_:_:)();
            uint64_t v52 = v51;
            swift_release();
            swift_release();
            uint64_t object = 0;
            uint64_t countAndFlagsBits = v52;
            int v38 = 1;
            break;
          case 2u:
            swift_retain();
            Swift::String v49 = CMLFeatureValue.stringValue()();
            uint64_t countAndFlagsBits = v49._countAndFlagsBits;
            uint64_t object = v49._object;
            swift_release();
            if (v8) {
              goto LABEL_90;
            }
            swift_release();
            int v38 = 2;
            break;
          case 3u:
            OUTLINED_FUNCTION_99();
            uint64_t v50 = specialized handling<A, B>(_:_:)(v34);
            if (!v50) {
              goto LABEL_91;
            }
            swift_release_n();
            type metadata accessor for CMLSequence();
            uint64_t countAndFlagsBits = swift_allocObject();
            uint64_t object = 0;
            *(void *)(countAndFlagsBits + 16) = v50;
            *(unsigned char *)(countAndFlagsBits + 24) = 1;
            int v38 = 3;
            break;
          case 4u:
            OUTLINED_FUNCTION_99();
            uint64_t v39 = specialized handling<A, B>(_:_:)(v34);
            if (!v39) {
              goto LABEL_89;
            }
            type metadata accessor for CMLDictionary();
            uint64_t v40 = OUTLINED_FUNCTION_70();
            *(void *)(v40 + 16) = v39;
            v112[0] = v40;
            v112[1] = closure #1 in MLDataValue.DictionaryType.init(from:);
            v112[2] = 0;
            v112[3] = specialized closure #1 in LazySequenceProtocol.compactMap<A>(_:);
            v112[4] = 0;
            v112[5] = specialized closure #2 in LazySequenceProtocol.compactMap<A>(_:);
            v112[6] = 0;
            swift_retain();
            specialized Dictionary.init<A>(uniqueKeysWithValues:)((uint64_t)v112, v41, v42, v43, v44, v45, v46, v47, v92, v93, (uint64_t)v94, v95, v97, v98, (uint64_t)v99, v100, (uint64_t)v101, v102);
            uint64_t countAndFlagsBits = v48;
            swift_release();
            swift_release_n();
            uint64_t object = 0;
            int v38 = 4;
            break;
          case 5u:
            swift_release();
            uint64_t countAndFlagsBits = 0;
            uint64_t object = 0;
            int v38 = 6;
            break;
          case 6u:
            uint64_t v53 = swift_retain();
            MLDataValue.MultiArrayType.init(from:)(v53, (uint64_t *)&v105);
            uint64_t countAndFlagsBits = (uint64_t)v105;
            if (!v105) {
              goto LABEL_92;
            }
            swift_release();
            uint64_t object = 0;
            int v38 = 5;
            break;
          default:
            OUTLINED_FUNCTION_99();
            uint64_t countAndFlagsBits = specialized handling<A, B>(_:_:)(v34);
            swift_release();
            swift_release();
            uint64_t object = 0;
            int v38 = 0;
            break;
        }
        swift_retain();
        uint64_t v54 = CMLSequence.size.getter();
        OUTLINED_FUNCTION_3_36();
        if (v35 >= v54) {
          break;
        }
        uint64_t v55 = v10;
        id v56 = objc_msgSend(v10, sel_strides);
        type metadata accessor for NSAttributedString(0, (unint64_t *)&lazy cache variable for type metadata for NSNumber);
        uint64_t v57 = static Array._unconditionallyBridgeFromObjectiveC(_:)();

        id v101 = object;
        if ((v57 & 0xC000000000000001) != 0)
        {
          id v58 = (id)MEMORY[0x22A6753B0](0, v57);
        }
        else
        {
          if (!*(void *)((v57 & 0xFFFFFFFFFFFFFF8) + 0x10)) {
            goto LABEL_78;
          }
          id v58 = *(id *)(v57 + 32);
        }
        uint64_t v59 = v58;
        swift_bridgeObjectRelease();
        uint64_t v60 = (uint64_t)objc_msgSend(v59, sel_integerValue);

        uint64_t v61 = *(void *)v103 * v60;
        if ((unsigned __int128)(*(uint64_t *)v103 * (__int128)v60) >> 64 != (*(void *)v103 * v60) >> 63) {
          goto LABEL_77;
        }
        id v62 = objc_msgSend(v55, sel_strides);
        uint64_t v63 = static Array._unconditionallyBridgeFromObjectiveC(_:)();

        if ((v63 & 0xC000000000000001) != 0)
        {
          id v64 = (id)MEMORY[0x22A6753B0](1, v63);
        }
        else
        {
          if (*(void *)((v63 & 0xFFFFFFFFFFFFFF8) + 0x10) < 2uLL) {
            goto LABEL_80;
          }
          id v64 = *(id *)(v63 + 40);
        }
        uint64_t v65 = v64;
        swift_bridgeObjectRelease();
        uint64_t v66 = (uint64_t)objc_msgSend(v65, sel_integerValue);

        uint64_t v67 = v102 * v66;
        if ((unsigned __int128)(v102 * (__int128)v66) >> 64 != (v102 * v66) >> 63) {
          goto LABEL_79;
        }
        BOOL v68 = __OFADD__(v61, v67);
        id v29 = (char *)(v61 + v67);
        if (v68) {
          goto LABEL_81;
        }
        id v10 = v55;
        id v69 = objc_msgSend(v55, sel_strides);
        uint64_t v70 = static Array._unconditionallyBridgeFromObjectiveC(_:)();

        if ((v70 & 0xC000000000000001) != 0)
        {
          id v34 = (id)MEMORY[0x22A6753B0](2, v70);
          uint64_t v71 = v104;
        }
        else
        {
          uint64_t v71 = v104;
          if (*(void *)((v70 & 0xFFFFFFFFFFFFFF8) + 0x10) < 3uLL) {
            goto LABEL_83;
          }
          id v34 = *(id *)(v70 + 48);
        }
        swift_bridgeObjectRelease();
        uint64_t v22 = (uint64_t)objc_msgSend(v34, sel_integerValue);

        uint64_t v72 = v35 * v22;
        if ((unsigned __int128)(v35 * (__int128)v22) >> 64 != (v35 * v22) >> 63) {
          goto LABEL_82;
        }
        BOOL v68 = __OFADD__(v29, v72);
        uint64_t v73 = &v29[v72];
        if (v68) {
          goto LABEL_84;
        }
        if (v38)
        {
          if (v38 != 1)
          {
            outlined consume of MLDataValue((void *)countAndFlagsBits, v101, v38);
            outlined consume of MLDataValue(v26, v71, 3);
            OUTLINED_FUNCTION_3_36();
            OUTLINED_FUNCTION_7_26(v74, v75, v76, v77, v78, v79, v80, v81, v92, v93, v94, v95, v97, v98, v99, v100, (uint64_t)v101, v102, v103[0]);
            OUTLINED_FUNCTION_3_36();
            goto LABEL_72;
          }
          *(void *)(v100 + 8 * (void)v73) = countAndFlagsBits;
        }
        else
        {
          *(double *)(v100 + 8 * (void)v73) = (double)countAndFlagsBits;
        }
        if (++v35 == CMLSequence.size.getter())
        {
          outlined consume of MLDataValue(v26, v71, 3);
          outlined consume of MLDataValue(v26, v71, 3);
          OUTLINED_FUNCTION_3_36();
          goto LABEL_59;
        }
      }
      __break(1u);
LABEL_77:
      __break(1u);
LABEL_78:
      __break(1u);
LABEL_79:
      __break(1u);
LABEL_80:
      __break(1u);
LABEL_81:
      __break(1u);
LABEL_82:
      __break(1u);
LABEL_83:
      __break(1u);
LABEL_84:
      __break(1u);
LABEL_85:
      __break(1u);
LABEL_86:
      __break(1u);
LABEL_87:
      __break(1u);
LABEL_88:
      __break(1u);

      __break(1u);
      swift_release();

      __break(1u);
LABEL_89:
      __break(1u);
LABEL_90:

      __break(1u);
      swift_release();

      __break(1u);
LABEL_91:
      __break(1u);

      __break(1u);
LABEL_92:
      __break(1u);
      swift_unexpectedError();
      __break(1u);
      JUMPOUT(0x227157834);
    }
    outlined consume of MLDataValue(v26, v104, 3);
    outlined consume of MLDataValue(v26, v104, 3);
    swift_release();
LABEL_59:
    uint64_t v21 = v102 + 1;
    uint64_t v22 = (uint64_t)v99;
    id v15 = v94;
    a3 = (void *)v95;
    if (v102 + 1 == CMLSequence.size.getter()) {
      goto LABEL_62;
    }
  }
  LOBYTE(v27) = 3;
  OUTLINED_FUNCTION_3_36();
LABEL_71:
  outlined consume of MLDataValue(v26, v30, v27);
  OUTLINED_FUNCTION_7_26(v82, v83, v84, v85, v86, v87, v88, v89, v92, v93, v94, v95, v97, v98, v99, v100, (uint64_t)v101, v21, v103[0]);
LABEL_72:
  outlined consume of (offset: Int, element: MLDataValue)?(0, (void *)v22, v29, 3);
  swift_release();
  *unsigned __int8 v96 = 0;
}

uint64_t specialized MLUntypedColumn.map<A>(skipUndefined:_:)@<X0>(char a1@<W0>, uint64_t a2@<X1>, uint64_t a3@<X2>, void *a4@<X3>, char a5@<W4>, uint64_t a6@<X8>)
{
  uint64_t v12 = swift_allocObject();
  *(void *)(v12 + 16) = a2;
  *(void *)(v12 + 24) = a3;
  if (a5)
  {
    outlined copy of Result<_DataTable, Error>(a4, 1);
    swift_retain();
    outlined copy of Result<_DataTable, Error>(a4, 1);
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    uint64_t v13 = _getErrorEmbeddedNSError<A>(_:)();
    if (v13)
    {
      uint64_t v14 = v13;
      outlined consume of Result<_DataTable, Error>(a4, 1);
    }
    else
    {
      uint64_t v14 = OUTLINED_FUNCTION_85();
      *id v18 = a4;
    }
    char v16 = a4;
    char v17 = 1;
  }
  else
  {
    swift_retain();
    outlined copy of Result<_DataTable, Error>(a4, 0);
    uint64_t v15 = CMLColumn.apply(transform:type:skipUndefined:)(partial apply for specialized closure #1 in MLUntypedColumn.map<A>(skipUndefined:_:), v12, 6, a1 & 1);
    type metadata accessor for _UntypedColumn();
    uint64_t v14 = OUTLINED_FUNCTION_70();
    *(void *)(v14 + 16) = v15;
    char v16 = a4;
    char v17 = 0;
  }
  outlined consume of Result<_DataTable, Error>(v16, v17);
  uint64_t result = swift_release();
  *(void *)a6 = v14;
  *(unsigned char *)(a6 + 8) = a5 & 1;
  return result;
}

uint64_t specialized closure #1 in MLUntypedColumn.map<A>(skipUndefined:_:)(uint64_t a1, void (*a2)(void **__return_ptr, void *))
{
  uint64_t v3 = swift_retain();
  MLDataValue.init(_:)(v3, (uint64_t)v11);
  uint64_t v4 = (void *)v11[0];
  uint64_t v5 = (void *)v11[1];
  char v6 = v12;
  a2(&v15, v11);
  uint64_t v7 = v15;
  if (v15)
  {
    uint64_t v13 = &type metadata for MLDataValue.MultiArrayType;
    uint64_t v14 = &protocol witness table for MLDataValue.MultiArrayType;
    v11[0] = v15;
    __swift_project_boxed_opaque_existential_1(v11, (uint64_t)&type metadata for MLDataValue.MultiArrayType);
    id v8 = v7;
    uint64_t v9 = MLDataValue.MultiArrayType.featureValue.getter(v8);
    __swift_destroy_boxed_opaque_existential_0((uint64_t)v11);
    outlined consume of MLDataValue(v4, v5, v6);
  }
  else
  {
    type metadata accessor for CMLFeatureValue();
    uint64_t v9 = CMLFeatureValue.__allocating_init()();
    outlined consume of MLDataValue(v4, v5, v6);
  }
  return v9;
}

id @nonobjc VNDetectHumanHandPoseRequest.init(completionHandler:)(uint64_t a1, uint64_t a2)
{
  if (a1)
  {
    _OWORD v6[4] = a1;
    v6[5] = a2;
    v6[0] = MEMORY[0x263EF8330];
    v6[1] = 1107296256;
    _OWORD v6[2] = thunk for @escaping @callee_guaranteed (@guaranteed VNRequest, @guaranteed Error?) -> ();
    v6[3] = &block_descriptor_6;
    uint64_t v3 = _Block_copy(v6);
    swift_release();
  }
  else
  {
    uint64_t v3 = 0;
  }
  id v4 = objc_msgSend(v2, sel_initWithCompletionHandler_, v3);
  _Block_release(v3);
  return v4;
}

void thunk for @escaping @callee_guaranteed (@guaranteed VNRequest, @guaranteed Error?) -> ()(uint64_t a1, void *a2, void *a3)
{
  uint64_t v5 = *(void (**)(id, void *))(a1 + 32);
  swift_retain();
  id v7 = a2;
  id v6 = a3;
  v5(v7, a3);
  swift_release();
}

uint64_t sub_227157C10()
{
  swift_bridgeObjectRelease();

  return MEMORY[0x270FA0238](v0, 24, 7);
}

void partial apply for closure #1 in static _VideoUtilities.reformatKeypointsDataTable(table:featureColumn:keypointsShape:)(uint64_t a1@<X0>, void *a2@<X8>)
{
  closure #1 in static _VideoUtilities.reformatKeypointsDataTable(table:featureColumn:keypointsShape:)(a1, *(void *)(v2 + 16), a2);
}

uint64_t sub_227157C50()
{
  swift_release();

  return MEMORY[0x270FA0238](v0, 32, 7);
}

uint64_t partial apply for specialized closure #1 in MLUntypedColumn.map<A>(skipUndefined:_:)(uint64_t a1)
{
  return specialized closure #1 in MLUntypedColumn.map<A>(skipUndefined:_:)(a1, *(void (**)(void **__return_ptr, void *))(v1 + 16));
}

unsigned char *closure #1 in closure #1 in Double.init<A>(_:)@<X0>(unsigned char *result@<X0>, BOOL *a2@<X8>)
{
  unsigned int v3 = *result;
  BOOL v4 = v3 > 0x20;
  uint64_t v5 = (1 << v3) & 0x100003E01;
  BOOL v6 = v4 || v5 == 0;
  v7 = v6 && (uint64_t result = (unsigned char *)_swift_stdlib_strtod_clocale()) != 0 && *result == 0;
  *a2 = v7;
  return result;
}

BOOL specialized closure #1 in LazySequenceProtocol.compactMap<A>(_:)(uint64_t a1)
{
  outlined init with take of (MLDataValue, MLDataValue)?(a1, (uint64_t)v2);
  return v2[16] != 0xFF;
}

{
  unsigned char v2[48];

  outlined init with take of (MLDataValue, MLDataValue)?(a1, (uint64_t)v2);
  return specialized closure #1 in LazySequenceProtocol.compactMap<A>(_:)((uint64_t)v2);
}

id specialized closure #2 in LazySequenceProtocol.compactMap<A>(_:)@<X0>(uint64_t a1@<X0>, uint64_t a2@<X8>)
{
  outlined init with take of (MLDataValue, MLDataValue)?(a1, (uint64_t)v11);
  BOOL v4 = (void *)v11[0];
  uint64_t v5 = (void *)v11[1];
  char v7 = v12;
  BOOL v6 = v13;
  id v8 = v14;
  char v9 = v15;
  id result = (id)outlined init with take of (MLDataValue, MLDataValue)?(a1, (uint64_t)v16);
  if (v16[16] == 0xFF)
  {
    __break(1u);
  }
  else
  {
    *(void *)a2 = v4;
    *(void *)(a2 + 8) = v5;
    *(unsigned char *)(a2 + 16) = v7;
    *(void *)(a2 + 24) = v6;
    *(void *)(a2 + 32) = v8;
    *(unsigned char *)(a2 + 40) = v9;
    outlined copy of MLDataValue(v4, v5, v7);
    return outlined copy of MLDataValue(v6, v8, v9);
  }
  return result;
}

{
  unsigned char v4[48];

  outlined init with take of (MLDataValue, MLDataValue)?(a1, (uint64_t)v4);
  return specialized closure #2 in LazySequenceProtocol.compactMap<A>(_:)((uint64_t)v4, a2);
}

uint64_t outlined bridged method (pb) of @objc VNRequest.results.getter(void *a1)
{
  id v1 = objc_msgSend(a1, sel_results);
  if (!v1) {
    return 0;
  }
  uint64_t v2 = v1;
  type metadata accessor for NSAttributedString(0, &lazy cache variable for type metadata for VNObservation);
  uint64_t v3 = static Array._unconditionallyBridgeFromObjectiveC(_:)();

  return v3;
}

uint64_t outlined init with take of (MLDataValue, MLDataValue)?(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (MLDataValue, MLDataValue)?);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 32))(a2, a1, v4);
  return a2;
}

uint64_t sub_227157F20()
{
  return MEMORY[0x270FA0238](v0, 24, 7);
}

uint64_t sub_227157F58()
{
  return MEMORY[0x270FA0238](v0, 24, 7);
}

uint64_t block_copy_helper_4(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = *(void *)(a2 + 40);
  *(void *)(a1 + 32) = *(void *)(a2 + 32);
  *(void *)(a1 + 40) = v2;
  return swift_retain();
}

uint64_t block_destroy_helper_4()
{
  return swift_release();
}

uint64_t outlined init with copy of MLHandActionClassifier.DataSource(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = type metadata accessor for MLHandActionClassifier.DataSource();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 16))(a2, a1, v4);
  return a2;
}

uint64_t outlined destroy of MLHandActionClassifier.DataSource(uint64_t a1)
{
  uint64_t v2 = type metadata accessor for MLHandActionClassifier.DataSource();
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v2 - 8) + 8))(a1, v2);
  return a1;
}

uint64_t partial apply for closure #1 in static _VideoUtilities.getVideoURLsAndAnnotations(from:)@<X0>(uint64_t *a1@<X8>)
{
  return closure #1 in static _VideoUtilities.getVideoURLsAndAnnotations(from:)(a1);
}

unsigned char *partial apply for closure #1 in closure #1 in Double.init<A>(_:)@<X0>(unsigned char *a1@<X0>, BOOL *a2@<X8>)
{
  return closure #1 in closure #1 in Double.init<A>(_:)(a1, a2);
}

void *partial apply for specialized closure #1 in _StringGuts.withCString<A>(_:)@<X0>(unsigned char *a1@<X8>)
{
  return specialized closure #1 in _StringGuts.withCString<A>(_:)(*(void *(**)(uint64_t *__return_ptr))(v1 + 16), a1);
}

unint64_t lazy protocol witness table accessor for type [String] and conformance <A> [A]()
{
  unint64_t result = lazy protocol witness table cache variable for type [String] and conformance <A> [A];
  if (!lazy protocol witness table cache variable for type [String] and conformance <A> [A])
  {
    __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for [String]);
    unint64_t result = swift_getWitnessTable();
    atomic_store(result, (unint64_t *)&lazy protocol witness table cache variable for type [String] and conformance <A> [A]);
  }
  return result;
}

uint64_t objectdestroy_14Tm()
{
  type metadata accessor for URL();
  OUTLINED_FUNCTION_0_15();
  uint64_t v2 = v1;
  uint64_t v4 = v3;
  uint64_t v5 = *(unsigned __int8 *)(v2 + 80);
  uint64_t v6 = v5 | 7;
  unint64_t v7 = (((*(void *)(v4 + 64) + ((v5 + 24) & ~v5) + 7) & 0xFFFFFFFFFFFFFFF8) + 15) & 0xFFFFFFFFFFFFFFF8;
  swift_release();
  OUTLINED_FUNCTION_11_3();
  v8();
  swift_release();
  swift_release();

  return MEMORY[0x270FA0238](v0, v7 + 8, v6);
}

void partial apply for closure #1 in static _VideoUtilities.getHandKeyPointsFromVideoUrl(url:startTime:endTime:targetFrameRate:)(void *a1, void *a2)
{
  uint64_t v5 = *(void *)(type metadata accessor for URL() - 8);
  unint64_t v6 = (*(unsigned __int8 *)(v5 + 80) + 24) & ~(unint64_t)*(unsigned __int8 *)(v5 + 80);
  unint64_t v7 = (*(void *)(v5 + 64) + v6 + 7) & 0xFFFFFFFFFFFFFFF8;
  closure #1 in static _VideoUtilities.getHandKeyPointsFromVideoUrl(url:startTime:endTime:targetFrameRate:)(a1, a2, *(void *)(v2 + 16), v2 + v6, *(void *)(v2 + v7), *(void *)(v2 + ((v7 + 15) & 0xFFFFFFFFFFFFFFF8)));
}

void OUTLINED_FUNCTION_1_32()
{
  outlined copy of Result<_DataTable, Error>(*v0, 0);
  _DataTable.columnNamesDidChange()();
}

uint64_t OUTLINED_FUNCTION_2_40(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
  return static _VideoUtilities.validateVideoInput(trainingData:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)(v9 - 288, 0x7461506F65646976, 0xE900000000000068, 0x6C6562616CLL, 0xE500000000000000, 0, 0, 0, a9);
}

void OUTLINED_FUNCTION_3_36()
{
  outlined consume of MLDataValue(v0, v1, 3);
}

uint64_t OUTLINED_FUNCTION_5_29()
{
  return v0;
}

void OUTLINED_FUNCTION_7_26(int a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, id a11, uint64_t a12, uint64_t a13, uint64_t a14, void *a15, uint64_t a16, uint64_t a17, uint64_t a18, int a19)
{
  outlined consume of (offset: Int, element: MLDataValue)?(a19, a15, a11, 3);
  outlined consume of (offset: Int, element: MLDataValue)?(a19, a15, a11, 3);
}

void OUTLINED_FUNCTION_12_17(int a1)
{
  outlined consume of (offset: Int, element: MLDataValue)?(a1, v1, v2, 3);
}

uint64_t OUTLINED_FUNCTION_13_24()
{
  return specialized ContiguousArray._reserveCapacityAssumingUniqueBuffer(oldCount:)();
}

__n128 OUTLINED_FUNCTION_16_18(__n128 *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, __n128 a15)
{
  __n128 result = a15;
  a1[1] = a15;
  return result;
}

uint64_t OUTLINED_FUNCTION_17_17()
{
  return swift_bridgeObjectRetain();
}

uint64_t OUTLINED_FUNCTION_20_17()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_22_15()
{
  return specialized ContiguousArray._appendElementAssumeUniqueAndCapacity(_:newElement:)();
}

uint64_t OUTLINED_FUNCTION_23_8()
{
  return swift_bridgeObjectRelease();
}

void OUTLINED_FUNCTION_27_14()
{
  *(void *)(v1 - 288) = v0;
}

uint64_t OUTLINED_FUNCTION_28_11()
{
  return specialized ContiguousArray._reserveCapacityAssumingUniqueBuffer(oldCount:)();
}

void OUTLINED_FUNCTION_29_13()
{
  specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)();
}

uint64_t OUTLINED_FUNCTION_30_11()
{
  return swift_beginAccess();
}

void OUTLINED_FUNCTION_31_9()
{
  uint64_t v2 = *(void **)(v0 - 104);
  char v3 = *(unsigned char *)(v0 - 96);
  specialized MLDataColumn.dropDuplicates()(v2, v3, v0 - 176);
}

void OUTLINED_FUNCTION_35_10(uint64_t a1@<X0>, uint64_t a2@<X8>)
{
  unint64_t v3 = (a2 - 32) | 0x8000000000000000;
  String.append(_:)(*(Swift::String *)&a1);
}

uint64_t OUTLINED_FUNCTION_37_8()
{
  return swift_beginAccess();
}

void OUTLINED_FUNCTION_42_8()
{
  uint64_t v2 = *(void **)(v0 - 304);
  int v3 = *(_DWORD *)(v0 - 312);
  outlined consume of Result<_DataTable, Error>(v2, v3);
}

id OUTLINED_FUNCTION_45_7()
{
  return [v0 (SEL)(v1 + 2200)];
}

uint64_t MLFewShotSoundClassifier.validationData(features:labels:device:)()
{
  uint64_t v0 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ScalarType?);
  MEMORY[0x270FA5388](v0 - 8);
  uint64_t v1 = type metadata accessor for Tensor();
  uint64_t v2 = MEMORY[0x270FA5388](v1);
  MEMORY[0x270FA5388](v2);
  _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSaySo8NSNumberCG_14NeuralNetworks6TensorVs5NeverOTg5();
  _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSaySo8NSNumberCG_14NeuralNetworks6TensorVs5NeverOTg5();
  type metadata accessor for ScalarType();
  OUTLINED_FUNCTION_4_34();
  Tensor.init(concatenating:alongAxis:scalarType:)();
  OUTLINED_FUNCTION_4_34();
  Tensor.init(stacking:alongAxis:scalarType:)();
  return DataSample.init(features:labels:)();
}

uint64_t closure #1 in MLFewShotSoundClassifier.makeSoundDataset<A>(from:batchSize:device:)@<X0>(uint64_t a1@<X1>, uint64_t a2@<X2>, uint64_t a3@<X8>)
{
  uint64_t v40 = a3;
  uint64_t v41 = a2;
  v35[6] = a1;
  type metadata accessor for FloatingPointRoundingRule();
  OUTLINED_FUNCTION_0();
  void v35[4] = v4;
  v35[5] = v3;
  MEMORY[0x270FA5388](v3);
  OUTLINED_FUNCTION_33_0();
  _OWORD v35[2] = v5;
  v35[3] = type metadata accessor for ScalarType();
  OUTLINED_FUNCTION_0();
  v35[1] = v6;
  MEMORY[0x270FA5388](v7);
  OUTLINED_FUNCTION_33_0();
  v35[0] = v8;
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ComputeDevice?);
  MEMORY[0x270FA5388](v9 - 8);
  uint64_t v11 = (char *)v35 - ((v10 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v12 = type metadata accessor for Tensor();
  OUTLINED_FUNCTION_0();
  uint64_t v38 = v13;
  uint64_t v15 = MEMORY[0x270FA5388](v14);
  uint64_t v37 = (char *)v35 - ((v16 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v17 = MEMORY[0x270FA5388](v15);
  unint64_t v19 = (char *)v35 - v18;
  uint64_t v20 = MEMORY[0x270FA5388](v17);
  uint64_t v36 = (char *)v35 - v21;
  MEMORY[0x270FA5388](v20);
  uint64_t v23 = (char *)v35 - v22;
  uint64_t v24 = *(void (**)(uint64_t))(*(void *)(type metadata accessor for ComputeDevice() - 8) + 16);
  uint64_t v25 = OUTLINED_FUNCTION_1_33();
  v24(v25);
  OUTLINED_FUNCTION_3_37();
  uint64_t v39 = v23;
  Tensor.init(oneHotAtIndex:depth:onValue:offValue:on:)();
  id v26 = MLMultiArray.cast(to:)((id)0x10020);
  uint64_t v27 = OUTLINED_FUNCTION_1_33();
  v24(v27);
  OUTLINED_FUNCTION_3_37();
  id v28 = v26;
  Tensor.init(_:device:)(v28, (uint64_t)v11);
  id v29 = v36;
  Tensor.squeezingShape(at:)();
  uint64_t v30 = v38;
  uint64_t v31 = *(void (**)(char *, uint64_t))(v38 + 8);
  v31(v19, v12);
  uint64_t v32 = *(void (**)(char *, char *, uint64_t))(v30 + 16);
  v32(v19, v29, v12);
  id v33 = v39;
  v32(v37, v39, v12);
  DataSample.init(features:labels:)();

  v31(v29, v12);
  return ((uint64_t (*)(char *, uint64_t))v31)(v33, v12);
}

uint64_t closure #1 in MLFewShotSoundClassifier.validationData(features:labels:device:)(id *a1, uint64_t a2, uint64_t a3)
{
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ComputeDevice?);
  MEMORY[0x270FA5388](v5 - 8);
  uint64_t v7 = (char *)&v10 - ((v6 + 15) & 0xFFFFFFFFFFFFFFF0);
  objc_msgSend(*a1, sel_integerValue);
  type metadata accessor for MLFewShotSoundClassifier();
  uint64_t v8 = type metadata accessor for ComputeDevice();
  (*(void (**)(char *, uint64_t, uint64_t))(*(void *)(v8 - 8) + 16))(v7, a3, v8);
  __swift_storeEnumTagSinglePayload((uint64_t)v7, 0, 1, v8);
  return Tensor.init(oneHotAtIndex:depth:onValue:offValue:on:)();
}

uint64_t partial apply for closure #1 in MLFewShotSoundClassifier.validationData(features:labels:device:)(id *a1)
{
  return closure #1 in MLFewShotSoundClassifier.validationData(features:labels:device:)(a1, *(void *)(v1 + 16), *(void *)(v1 + 24));
}

void closure #2 in MLFewShotSoundClassifier.validationData(features:labels:device:)(void **a1@<X0>, uint64_t a2@<X1>, uint64_t a3@<X8>)
{
  uint64_t v30 = a2;
  uint64_t v31 = a3;
  uint64_t v5 = type metadata accessor for FloatingPointRoundingRule();
  uint64_t v28 = *(void *)(v5 - 8);
  uint64_t v29 = v5;
  MEMORY[0x270FA5388](v5);
  uint64_t v7 = (char *)&v25 - ((v6 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v27 = type metadata accessor for ScalarType();
  uint64_t v8 = *(void *)(v27 - 8);
  MEMORY[0x270FA5388](v27);
  uint64_t v10 = (char *)&v25 - ((v9 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ComputeDevice?);
  MEMORY[0x270FA5388](v11 - 8);
  uint64_t v13 = (char *)&v25 - ((v12 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v26 = type metadata accessor for Tensor();
  uint64_t v14 = *(void *)(v26 - 8);
  MEMORY[0x270FA5388](v26);
  uint64_t v16 = (char *)&v25 - ((v15 + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v17 = *a1;
  id v18 = MLMultiArray.cast(to:)((id)0x10020);
  if (v3)
  {

    uint64_t v19 = type metadata accessor for ComputeDevice();
    (*(void (**)(char *, uint64_t, uint64_t))(*(void *)(v19 - 8) + 16))(v13, v30, v19);
    __swift_storeEnumTagSinglePayload((uint64_t)v13, 0, 1, v19);
    Tensor.init(_:device:)(v17, (uint64_t)v13);
    uint64_t v20 = v27;
    (*(void (**)(char *, void, uint64_t))(v8 + 104))(v10, *MEMORY[0x263F58330], v27);
    uint64_t v22 = v28;
    uint64_t v21 = v29;
    (*(void (**)(char *, void, uint64_t))(v28 + 104))(v7, *MEMORY[0x263F8E1F8], v29);
    Tensor.cast(to:roundingRule:)();
    (*(void (**)(char *, uint64_t))(v22 + 8))(v7, v21);
    (*(void (**)(char *, uint64_t))(v8 + 8))(v10, v20);
    (*(void (**)(char *, uint64_t))(v14 + 8))(v16, v26);
  }
  else
  {
    uint64_t v23 = v18;
    uint64_t v24 = type metadata accessor for ComputeDevice();
    (*(void (**)(char *, uint64_t, uint64_t))(*(void *)(v24 - 8) + 16))(v13, v30, v24);
    __swift_storeEnumTagSinglePayload((uint64_t)v13, 0, 1, v24);
    Tensor.init(_:device:)(v23, (uint64_t)v13);
  }
}

void partial apply for closure #2 in MLFewShotSoundClassifier.validationData(features:labels:device:)(void **a1@<X0>, uint64_t a2@<X8>)
{
  closure #2 in MLFewShotSoundClassifier.validationData(features:labels:device:)(a1, *(void *)(v2 + 16), a2);
}

uint64_t OUTLINED_FUNCTION_1_33()
{
  return v0;
}

uint64_t OUTLINED_FUNCTION_3_37()
{
  return __swift_storeEnumTagSinglePayload(v1, 0, 1, v0);
}

uint64_t OUTLINED_FUNCTION_4_34()
{
  return __swift_storeEnumTagSinglePayload(v0, 1, 1, v1);
}

void *initializeBufferWithCopyOfBuffer for AnyTreeClassifier(uint64_t a1, uint64_t *a2, uint64_t a3)
{
  uint64_t v3 = (void *)a1;
  int v4 = *(_DWORD *)(*(void *)(a3 - 8) + 80);
  if ((v4 & 0x20000) != 0)
  {
    uint64_t v13 = *a2;
    *uint64_t v3 = *a2;
    uint64_t v3 = (void *)(v13 + ((v4 + 16) & ~(unint64_t)v4));
    swift_retain();
  }
  else
  {
    uint64_t v5 = a2[1];
    *(void *)a1 = *a2;
    *(void *)(a1 + 8) = v5;
    uint64_t v6 = a2[3];
    char v7 = *((unsigned char *)a2 + 32);
    *(void *)(a1 + 16) = a2[2];
    *(void *)(a1 + 24) = v6;
    *(unsigned char *)(a1 + 32) = v7;
    uint64_t v8 = a2[6];
    *(void *)(a1 + 40) = a2[5];
    *(void *)(a1 + 48) = v8;
    uint64_t v9 = *(int *)(a3 + 32);
    uint64_t v15 = a1 + v9;
    uint64_t v10 = (uint64_t)a2 + v9;
    *(void *)(a1 + 56) = a2[7];
    uint64_t v11 = type metadata accessor for BaseTreeClassifier();
    uint64_t v12 = *(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v11 - 8) + 16);
    swift_bridgeObjectRetain();
    swift_bridgeObjectRetain();
    swift_bridgeObjectRetain();
    swift_bridgeObjectRetain();
    swift_bridgeObjectRetain();
    v12(v15, v10, v11);
  }
  return v3;
}

uint64_t destroy for AnyTreeClassifier(uint64_t a1, uint64_t a2)
{
  swift_bridgeObjectRelease();
  swift_bridgeObjectRelease();
  swift_bridgeObjectRelease();
  swift_bridgeObjectRelease();
  swift_bridgeObjectRelease();
  uint64_t v4 = a1 + *(int *)(a2 + 32);
  uint64_t v5 = type metadata accessor for BaseTreeClassifier();
  uint64_t v6 = *(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v5 - 8) + 8);

  return v6(v4, v5);
}

uint64_t initializeWithCopy for AnyTreeClassifier(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = *(void *)(a2 + 8);
  *(void *)a1 = *(void *)a2;
  *(void *)(a1 + 8) = v4;
  uint64_t v5 = *(void *)(a2 + 24);
  char v6 = *(unsigned char *)(a2 + 32);
  *(void *)(a1 + 16) = *(void *)(a2 + 16);
  *(void *)(a1 + 24) = v5;
  *(unsigned char *)(a1 + 32) = v6;
  uint64_t v7 = *(void *)(a2 + 48);
  *(void *)(a1 + 40) = *(void *)(a2 + 40);
  *(void *)(a1 + 48) = v7;
  uint64_t v8 = *(int *)(a3 + 32);
  uint64_t v13 = a1 + v8;
  uint64_t v9 = a2 + v8;
  *(void *)(a1 + 56) = *(void *)(a2 + 56);
  uint64_t v10 = type metadata accessor for BaseTreeClassifier();
  uint64_t v11 = *(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v10 - 8) + 16);
  swift_bridgeObjectRetain();
  swift_bridgeObjectRetain();
  swift_bridgeObjectRetain();
  swift_bridgeObjectRetain();
  swift_bridgeObjectRetain();
  v11(v13, v9, v10);
  return a1;
}

uint64_t assignWithCopy for AnyTreeClassifier(uint64_t a1, uint64_t a2, uint64_t a3)
{
  *(void *)a1 = *(void *)a2;
  *(void *)(a1 + 8) = *(void *)(a2 + 8);
  swift_bridgeObjectRetain();
  swift_bridgeObjectRelease();
  *(void *)(a1 + 16) = *(void *)(a2 + 16);
  swift_bridgeObjectRetain();
  swift_bridgeObjectRelease();
  char v6 = *(unsigned char *)(a2 + 32);
  *(void *)(a1 + 24) = *(void *)(a2 + 24);
  *(unsigned char *)(a1 + 32) = v6;
  swift_bridgeObjectRetain();
  swift_bridgeObjectRelease();
  *(void *)(a1 + 40) = *(void *)(a2 + 40);
  swift_bridgeObjectRetain();
  swift_bridgeObjectRelease();
  *(void *)(a1 + 48) = *(void *)(a2 + 48);
  *(void *)(a1 + 56) = *(void *)(a2 + 56);
  swift_bridgeObjectRetain();
  swift_bridgeObjectRelease();
  uint64_t v7 = *(int *)(a3 + 32);
  uint64_t v8 = a1 + v7;
  uint64_t v9 = a2 + v7;
  uint64_t v10 = type metadata accessor for BaseTreeClassifier();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v10 - 8) + 24))(v8, v9, v10);
  return a1;
}

uint64_t initializeWithTake for AnyTreeClassifier(uint64_t a1, uint64_t a2, uint64_t a3)
{
  *(_OWORD *)a1 = *(_OWORD *)a2;
  uint64_t v4 = *(void *)(a2 + 24);
  *(void *)(a1 + 16) = *(void *)(a2 + 16);
  *(void *)(a1 + 24) = v4;
  *(unsigned char *)(a1 + 32) = *(unsigned char *)(a2 + 32);
  *(_OWORD *)(a1 + 40) = *(_OWORD *)(a2 + 40);
  uint64_t v5 = *(int *)(a3 + 32);
  uint64_t v6 = a2 + v5;
  uint64_t v7 = a1 + v5;
  *(void *)(a1 + 56) = *(void *)(a2 + 56);
  uint64_t v8 = type metadata accessor for BaseTreeClassifier();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v8 - 8) + 32))(v7, v6, v8);
  return a1;
}

uint64_t assignWithTake for AnyTreeClassifier(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v6 = *(void *)(a2 + 8);
  *(void *)a1 = *(void *)a2;
  *(void *)(a1 + 8) = v6;
  swift_bridgeObjectRelease();
  *(void *)(a1 + 16) = *(void *)(a2 + 16);
  swift_bridgeObjectRelease();
  char v7 = *(unsigned char *)(a2 + 32);
  *(void *)(a1 + 24) = *(void *)(a2 + 24);
  *(unsigned char *)(a1 + 32) = v7;
  swift_bridgeObjectRelease();
  *(void *)(a1 + 40) = *(void *)(a2 + 40);
  swift_bridgeObjectRelease();
  uint64_t v8 = *(void *)(a2 + 56);
  *(void *)(a1 + 48) = *(void *)(a2 + 48);
  *(void *)(a1 + 56) = v8;
  swift_bridgeObjectRelease();
  uint64_t v9 = *(int *)(a3 + 32);
  uint64_t v10 = a1 + v9;
  uint64_t v11 = a2 + v9;
  uint64_t v12 = type metadata accessor for BaseTreeClassifier();
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v12 - 8) + 40))(v10, v11, v12);
  return a1;
}

uint64_t getEnumTagSinglePayload for AnyTreeClassifier(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return MEMORY[0x270FA0340](a1, a2, a3, sub_2271597B8);
}

uint64_t sub_2271597B8(uint64_t a1, uint64_t a2, uint64_t a3)
{
  if (a2 == 0x7FFFFFFF)
  {
    unint64_t v4 = *(void *)(a1 + 8);
    if (v4 >= 0xFFFFFFFF) {
      LODWORD(v4) = -1;
    }
    return (v4 + 1);
  }
  else
  {
    uint64_t v8 = type metadata accessor for BaseTreeClassifier();
    uint64_t v9 = a1 + *(int *)(a3 + 32);
    return __swift_getEnumTagSinglePayload(v9, a2, v8);
  }
}

uint64_t storeEnumTagSinglePayload for AnyTreeClassifier(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return MEMORY[0x270FA0580](a1, a2, a3, a4, sub_227159854);
}

uint64_t sub_227159854(uint64_t result, uint64_t a2, int a3, uint64_t a4)
{
  uint64_t v5 = result;
  if (a3 == 0x7FFFFFFF)
  {
    *(void *)(result + 8) = (a2 - 1);
  }
  else
  {
    uint64_t v7 = type metadata accessor for BaseTreeClassifier();
    uint64_t v8 = v5 + *(int *)(a4 + 32);
    return __swift_storeEnumTagSinglePayload(v8, a2, a2, v7);
  }
  return result;
}

uint64_t type metadata accessor for AnyTreeClassifier()
{
  uint64_t result = type metadata singleton initialization cache for AnyTreeClassifier;
  if (!type metadata singleton initialization cache for AnyTreeClassifier) {
    return swift_getSingletonMetadata();
  }
  return result;
}

uint64_t type metadata completion function for AnyTreeClassifier()
{
  uint64_t result = type metadata accessor for BaseTreeClassifier();
  if (v1 <= 0x3F)
  {
    swift_initStructMetadata();
    return 0;
  }
  return result;
}

uint64_t associated type witness table accessor for SupervisedTabularEstimator.Transformer : TabularTransformer in AnyTreeClassifier()
{
  return lazy protocol witness table accessor for type AnyTreeClassifierModel and conformance AnyTreeClassifierModel(&lazy protocol witness table cache variable for type AnyTreeClassifierModel and conformance AnyTreeClassifierModel, (void (*)(uint64_t))type metadata accessor for AnyTreeClassifierModel);
}

uint64_t AnyTreeClassifier.init(labels:annotationColumnName:featureColumnNames:configuration:)@<X0>(uint64_t a1@<X0>, uint64_t a2@<X1>, uint64_t a3@<X2>, uint64_t a4@<X4>, uint64_t a5@<X8>)
{
  uint64_t v10 = type metadata accessor for BoostedTreeConfiguration();
  OUTLINED_FUNCTION_0();
  uint64_t v12 = v11;
  MEMORY[0x270FA5388](v13);
  OUTLINED_FUNCTION_33_0();
  uint64_t v14 = type metadata accessor for BaseTreeClassifier();
  OUTLINED_FUNCTION_0();
  uint64_t v45 = v15;
  MEMORY[0x270FA5388](v16);
  OUTLINED_FUNCTION_33_0();
  uint64_t v44 = v17;
  *(void *)a5 = a2;
  *(void *)(a5 + 8) = a3;
  OUTLINED_FUNCTION_14_18();
  OUTLINED_FUNCTION_5_30((uint64_t)"vectorized_features");
  uint64_t v18 = *(void *)(a1 + 16);
  if (v18)
  {
    uint64_t v39 = v14;
    uint64_t v40 = v12;
    uint64_t v41 = v10;
    uint64_t v42 = a4;
    uint64_t v43 = a5;
    uint64_t v48 = MEMORY[0x263F8EE78];
    swift_bridgeObjectRetain();
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
    uint64_t v19 = v48;
    int64_t v20 = specialized _NativeSet.startIndex.getter(a1);
    int v22 = v21;
    char v24 = v23 & 1;
    uint64_t v46 = a1 + 56;
    while ((v20 & 0x8000000000000000) == 0 && v20 < 1 << *(unsigned char *)(a1 + 32))
    {
      if (((*(void *)(v46 + (((unint64_t)v20 >> 3) & 0x1FFFFFFFFFFFFFF8)) >> v20) & 1) == 0) {
        goto LABEL_20;
      }
      if (*(_DWORD *)(a1 + 36) != v22) {
        goto LABEL_21;
      }
      char v47 = v24;
      uint64_t v25 = (uint64_t *)(*(void *)(a1 + 48) + 16 * v20);
      uint64_t v26 = v25[1];
      if (v26) {
        uint64_t v27 = *v25;
      }
      else {
        uint64_t v27 = 0;
      }
      if (v26) {
        unint64_t v28 = v25[1];
      }
      else {
        unint64_t v28 = 0xE000000000000000;
      }
      uint64_t v48 = v19;
      uint64_t v29 = a1;
      unint64_t v31 = *(void *)(v19 + 16);
      unint64_t v30 = *(void *)(v19 + 24);
      swift_bridgeObjectRetain();
      if (v31 >= v30 >> 1)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)();
        uint64_t v19 = v48;
      }
      *(void *)(v19 + 16) = v31 + 1;
      uint64_t v32 = v19 + 16 * v31;
      *(void *)(v32 + 32) = v27;
      *(void *)(v32 + 40) = v28;
      int64_t v33 = specialized _NativeSet.index(after:)(v20, v22, v47 & 1, v29);
      int64_t v20 = v33;
      int v22 = v34;
      char v24 = v35 & 1;
      --v18;
      a1 = v29;
      if (!v18)
      {
        outlined consume of [MLDataValue : MLDataValue].Index._Variant(v33, v34, v24);
        swift_bridgeObjectRelease();
        a4 = v42;
        a5 = v43;
        uint64_t v12 = v40;
        uint64_t v10 = v41;
        uint64_t v14 = v39;
        goto LABEL_18;
      }
    }
    __break(1u);
LABEL_20:
    __break(1u);
LABEL_21:
    __break(1u);
    uint64_t result = swift_release();
    __break(1u);
  }
  else
  {
    swift_bridgeObjectRetain();
    swift_bridgeObjectRelease();
    uint64_t v19 = MEMORY[0x263F8EE78];
LABEL_18:
    uint64_t v48 = v19;
    swift_bridgeObjectRetain();
    specialized MutableCollection<>.sort(by:)(&v48);
    swift_bridgeObjectRelease();
    *(void *)(a5 + 24) = v48;
    *(unsigned char *)(a5 + 32) = 1;
    OUTLINED_FUNCTION_18_3();
    v36();
    BaseTreeClassifier.init(configuration:)();
    (*(void (**)(uint64_t, uint64_t))(v12 + 8))(a4, v10);
    uint64_t v37 = type metadata accessor for AnyTreeClassifier();
    return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t))(v45 + 32))(a5 + *(int *)(v37 + 32), v44, v14);
  }
  return result;
}

uint64_t AnyTreeClassifier.init(labels:annotationColumnName:featureColumnNames:configuration:)@<X0>(uint64_t a1@<X0>, uint64_t a2@<X1>, uint64_t a3@<X2>, uint64_t a4@<X3>, uint64_t a5@<X4>, uint64_t a6@<X8>)
{
  uint64_t v12 = type metadata accessor for BoostedTreeConfiguration();
  OUTLINED_FUNCTION_0();
  uint64_t v14 = v13;
  MEMORY[0x270FA5388](v15);
  OUTLINED_FUNCTION_33_0();
  uint64_t v16 = type metadata accessor for BaseTreeClassifier();
  OUTLINED_FUNCTION_0();
  uint64_t v18 = v17;
  MEMORY[0x270FA5388](v19);
  OUTLINED_FUNCTION_33_0();
  uint64_t v44 = v20;
  *(void *)a6 = a2;
  *(void *)(a6 + 8) = a3;
  uint64_t v21 = a4;
  *(void *)(a6 + 16) = a4;
  uint64_t v22 = *(void *)(a1 + 16);
  if (v22)
  {
    uint64_t v40 = v16;
    uint64_t v41 = v12;
    uint64_t v42 = a5;
    uint64_t v43 = a6;
    uint64_t v45 = MEMORY[0x263F8EE78];
    uint64_t v39 = v21;
    swift_bridgeObjectRetain();
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v22, 0);
    uint64_t v23 = v45;
    int64_t v24 = specialized _NativeSet.startIndex.getter(a1);
    int v26 = v25;
    char v28 = v27 & 1;
    while ((v24 & 0x8000000000000000) == 0 && v24 < 1 << *(unsigned char *)(a1 + 32))
    {
      if (((*(void *)(a1 + 56 + (((unint64_t)v24 >> 3) & 0x1FFFFFFFFFFFFFF8)) >> v24) & 1) == 0) {
        goto LABEL_17;
      }
      if (*(_DWORD *)(a1 + 36) != v26) {
        goto LABEL_18;
      }
      uint64_t v29 = *(void *)(a1 + 48) + 16 * v24;
      if (*(unsigned char *)(v29 + 8)) {
        uint64_t v30 = 0;
      }
      else {
        uint64_t v30 = *(void *)v29;
      }
      uint64_t v45 = v23;
      unint64_t v32 = *(void *)(v23 + 16);
      unint64_t v31 = *(void *)(v23 + 24);
      if (v32 >= v31 >> 1)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v31 > 1, v32 + 1, 1);
        uint64_t v23 = v45;
      }
      *(void *)(v23 + 16) = v32 + 1;
      *(void *)(v23 + 8 * v32 + 32) = v30;
      int64_t v33 = specialized _NativeSet.index(after:)(v24, v26, v28 & 1, a1);
      int64_t v24 = v33;
      int v26 = v34;
      char v28 = v35 & 1;
      if (!--v22)
      {
        outlined consume of [MLDataValue : MLDataValue].Index._Variant(v33, v34, v35 & 1);
        swift_bridgeObjectRelease();
        a5 = v42;
        a6 = v43;
        uint64_t v12 = v41;
        uint64_t v16 = v40;
        uint64_t v21 = v39;
        goto LABEL_15;
      }
    }
    __break(1u);
LABEL_17:
    __break(1u);
LABEL_18:
    __break(1u);
    uint64_t result = swift_release();
    __break(1u);
  }
  else
  {
    swift_bridgeObjectRetain();
    swift_bridgeObjectRelease();
    uint64_t v23 = MEMORY[0x263F8EE78];
LABEL_15:
    uint64_t v45 = v23;
    swift_bridgeObjectRetain();
    specialized MutableCollection<>.sort(by:)(&v45);
    swift_bridgeObjectRelease();
    *(void *)(a6 + 24) = v45;
    *(unsigned char *)(a6 + 32) = 0;
    *(void *)(a6 + 40) = v21;
    *(void *)(a6 + 48) = 0xD000000000000013;
    OUTLINED_FUNCTION_5_30((uint64_t)"vectorized_features");
    OUTLINED_FUNCTION_18_3();
    v36();
    BaseTreeClassifier.init(configuration:)();
    (*(void (**)(uint64_t, uint64_t))(v14 + 8))(a5, v12);
    uint64_t v37 = type metadata accessor for AnyTreeClassifier();
    return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t))(v18 + 32))(a6 + *(int *)(v37 + 32), v44, v16);
  }
  return result;
}

uint64_t AnyTreeClassifier.makeTransformer()@<X0>(char *a1@<X8>)
{
  uint64_t v3 = type metadata accessor for BaseTreeClassifierModel();
  OUTLINED_FUNCTION_0();
  uint64_t v5 = v4;
  MEMORY[0x270FA5388](v6);
  OUTLINED_FUNCTION_3_0();
  uint64_t v9 = v8 - v7;
  uint64_t v11 = *v1;
  uint64_t v10 = v1[1];
  uint64_t v12 = v1[3];
  char v13 = *((unsigned char *)v1 + 32);
  type metadata accessor for AnyTreeClassifier();
  swift_bridgeObjectRetain();
  BaseTreeClassifier.makeTransformer(classCount:featureCount:)();
  *(void *)a1 = v11;
  *((void *)a1 + 1) = v10;
  uint64_t v14 = type metadata accessor for AnyTreeClassifierModel();
  *((void *)a1 + 3) = 0;
  *((void *)a1 + 4) = 0;
  *((void *)a1 + 2) = 0;
  (*(void (**)(char *, uint64_t, uint64_t))(v5 + 32))(&a1[*(int *)(v14 + 24)], v9, v3);
  uint64_t v15 = &a1[*(int *)(v14 + 28)];
  *(void *)uint64_t v15 = v12;
  v15[8] = v13;
  return swift_bridgeObjectRetain();
}

uint64_t AnyTreeClassifier.update(_:with:eventHandler:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  v5[5] = a4;
  v5[6] = v4;
  v5[3] = a2;
  uint64_t v5[4] = a3;
  v5[2] = a1;
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DenseMatrix<Float>);
  v5[7] = v6;
  OUTLINED_FUNCTION_1(v6);
  v5[8] = v7;
  v5[9] = swift_task_alloc();
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyColumn?);
  OUTLINED_FUNCTION_17(v8);
  v5[10] = swift_task_alloc();
  uint64_t v9 = type metadata accessor for AnyColumn();
  v5[11] = v9;
  OUTLINED_FUNCTION_1(v9);
  v5[12] = v10;
  v5[13] = swift_task_alloc();
  v5[14] = swift_task_alloc();
  return MEMORY[0x270FA2498](AnyTreeClassifier.update(_:with:eventHandler:), 0, 0);
}

uint64_t AnyTreeClassifier.update(_:with:eventHandler:)()
{
  unint64_t v1 = (uint64_t *)v0[2];
  uint64_t ML16ColumnDescriptorVsAE_pTg5 = v1[2];
  uint64_t v3 = v1;
  if (!ML16ColumnDescriptorVsAE_pTg5)
  {
    uint64_t v12 = v0[3];
    uint64_t v13 = *(void *)(v0[6] + 16);
    uint64_t v14 = swift_task_alloc();
    *(void *)(v14 + 16) = v12;
    swift_bridgeObjectRetain();
    uint64_t ML16ColumnDescriptorVsAE_pTg5 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSaySSG_8CreateML16ColumnDescriptorVsAE_pTg5((uint64_t)partial apply for closure #1 in FeatureVectorizer.fitted(to:), v14, v13);
    swift_bridgeObjectRelease();
    swift_task_dealloc();
    outlined consume of FeatureVectorizer<Float>.Transformer?(v1[2]);
    v1[2] = ML16ColumnDescriptorVsAE_pTg5;
    v1[3] = 0xD000000000000013;
    v1[4] = 0x80000002272D4D10;
    uint64_t v3 = (uint64_t *)v0[2];
  }
  uint64_t result = type metadata accessor for AnyTreeClassifierModel();
  uint64_t v5 = (char *)v3 + *(int *)(result + 28);
  uint64_t v6 = *(void *)v5;
  if (!*(void *)(*(void *)v5 + 16))
  {
    uint64_t v15 = v0[14];
    uint64_t v17 = (void (*)(uint64_t, uint64_t))v0[10];
    uint64_t v16 = v0[11];
    MEMORY[0x22A672220](*(void *)v0[6], *(void *)(v0[6] + 8));
    __swift_storeEnumTagSinglePayload((uint64_t)v17, 1, 1, v16);
    uint64_t v6 = static Labels.collected(from:_:)(v15, v17);
    char v7 = v18;
    outlined destroy of UTType?(v0[10], &demangling cache variable for type metadata for AnyColumn?);
    uint64_t v19 = OUTLINED_FUNCTION_16_19();
    v20(v19);
    uint64_t result = swift_bridgeObjectRelease();
    *(void *)uint64_t v5 = v6;
    v5[8] = v7 & 1;
    if (v1[2]) {
      goto LABEL_5;
    }
LABEL_11:
    __break(1u);
    return result;
  }
  char v7 = v5[8];
  if (!ML16ColumnDescriptorVsAE_pTg5) {
    goto LABEL_11;
  }
LABEL_5:
  specialized FeatureVectorizer.Transformer.vectorized(_:includingBias:)();
  uint64_t v9 = v0[12];
  uint64_t v8 = v0[13];
  uint64_t v10 = v0[8];
  uint64_t v22 = v0[9];
  uint64_t v23 = v0[7];
  uint64_t v21 = v0[11];
  MEMORY[0x22A672220](*(void *)v0[6], *(void *)(v0[6] + 8));
  Labels.encodeAnnotations(_:)(v8, v6, v7 & 1);
  (*(void (**)(uint64_t, uint64_t))(v9 + 8))(v8, v21);
  type metadata accessor for AnyTreeClassifier();
  BaseTreeClassifier.update(_:features:annotations:eventHandler:)();
  (*(void (**)(uint64_t, uint64_t))(v10 + 8))(v22, v23);
  swift_bridgeObjectRelease();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  swift_task_dealloc();
  uint64_t v11 = (uint64_t (*)(void))v0[1];
  return v11();
}

uint64_t AnyTreeClassifier.init(trainingLabelsColumn:validationLabelsColumn:annotationColumnName:featureColumnNames:configuration:)@<X0>(uint64_t a1@<X0>, uint64_t a2@<X1>, void *a3@<X2>, uint64_t a4@<X3>, uint64_t a5@<X5>, void *a6@<X8>)
{
  uint64_t v95 = a5;
  int v91 = a3;
  uint64_t v92 = a4;
  uint64_t v97 = a2;
  type metadata accessor for BoostedTreeConfiguration();
  OUTLINED_FUNCTION_0();
  uint64_t v93 = v10;
  uint64_t v94 = v9;
  MEMORY[0x270FA5388](v9);
  OUTLINED_FUNCTION_33_0();
  uint64_t v87 = v11;
  OUTLINED_FUNCTION_65();
  type metadata accessor for BaseTreeClassifier();
  OUTLINED_FUNCTION_0();
  uint64_t v89 = v13;
  uint64_t v90 = v12;
  MEMORY[0x270FA5388](v12);
  OUTLINED_FUNCTION_33_0();
  uint64_t v88 = v14;
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Int>);
  OUTLINED_FUNCTION_0();
  uint64_t v83 = v15;
  uint64_t v84 = v16;
  MEMORY[0x270FA5388](v15);
  OUTLINED_FUNCTION_33_0();
  uint64_t v82 = v17;
  uint64_t v18 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FilledColumn<Column<Int>>);
  uint64_t v19 = OUTLINED_FUNCTION_17(v18);
  MEMORY[0x270FA5388](v19);
  OUTLINED_FUNCTION_33_0();
  uint64_t v81 = v20;
  uint64_t v21 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyColumn?);
  uint64_t v22 = OUTLINED_FUNCTION_17(v21);
  MEMORY[0x270FA5388](v22);
  OUTLINED_FUNCTION_13_25();
  MEMORY[0x270FA5388](v23);
  int v25 = (char *)v78 - v24;
  uint64_t v26 = type metadata accessor for AnyColumn();
  OUTLINED_FUNCTION_0();
  uint64_t v100 = v27;
  uint64_t v29 = MEMORY[0x270FA5388](v28);
  unint64_t v31 = (char *)v78 - ((v30 + 15) & 0xFFFFFFFFFFFFFFF0);
  MEMORY[0x270FA5388](v29);
  int v80 = (char *)v78 - v32;
  uint64_t v33 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  OUTLINED_FUNCTION_0();
  int v85 = v34;
  MEMORY[0x270FA5388](v35);
  OUTLINED_FUNCTION_27_7();
  uint64_t v36 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FilledColumn<Column<String>>);
  uint64_t v37 = OUTLINED_FUNCTION_17(v36);
  MEMORY[0x270FA5388](v37);
  OUTLINED_FUNCTION_3_0();
  uint64_t v38 = v92;
  *a6 = v91;
  a6[1] = v38;
  OUTLINED_FUNCTION_14_18();
  OUTLINED_FUNCTION_5_30((uint64_t)"vectorized_features");
  swift_bridgeObjectRetain();
  AnyColumn.wrappedElementType.getter();
  uint64_t v92 = swift_dynamicCastMetatype();
  uint64_t v96 = v26;
  if (!v92)
  {
    int v85 = v31;
    uint64_t v43 = v82;
    uint64_t v44 = v83;
    uint64_t v45 = v84;
    if (!swift_dynamicCastMetatype())
    {
      lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
      swift_allocError();
      *(void *)uint64_t v61 = 0xD000000000000025;
      *(void *)(v61 + 8) = 0x80000002272D7CE0;
      *(_OWORD *)(v61 + 16) = 0u;
      *(_OWORD *)(v61 + 32) = 0u;
      *(unsigned char *)(v61 + 48) = 1;
      swift_willThrow();
      OUTLINED_FUNCTION_25_0();
      v62();
      outlined destroy of UTType?(v97, &demangling cache variable for type metadata for AnyColumn?);
      OUTLINED_FUNCTION_25_0();
      v63();
      swift_bridgeObjectRelease();
      swift_bridgeObjectRelease();
      swift_bridgeObjectRelease();
      return swift_bridgeObjectRelease();
    }
    int v91 = a6;
    AnyColumn.assumingType<A>(_:)();
    uint64_t v98 = 0;
    int v80 = (char *)lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<Int> and conformance Column<A>, &demangling cache variable for type metadata for Column<Int>);
    OptionalColumnProtocol.filled(with:)();
    char v47 = *(void (**)(uint64_t, uint64_t))(v45 + 8);
    uint64_t v46 = v45 + 8;
    v78[1] = v47;
    v47(v43, v44);
    specialized Set.init<A>(_:)();
    uint64_t v49 = v48;
    uint64_t v50 = v97;
    uint64_t v51 = v79;
    outlined init with copy of DataFrame?(v97, v79, &demangling cache variable for type metadata for AnyColumn?);
    uint64_t v52 = v96;
    if (__swift_getEnumTagSinglePayload(v51, 1, v96) == 1)
    {
      outlined destroy of UTType?(v51, &demangling cache variable for type metadata for AnyColumn?);
    }
    else
    {
      uint64_t v84 = v46;
      uint64_t v65 = v85;
      OUTLINED_FUNCTION_3();
      v66();
      AnyColumn.assumingType<A>(_:)();
      uint64_t v98 = 0;
      OptionalColumnProtocol.filled(with:)();
      OUTLINED_FUNCTION_25_0();
      v67();
      specialized Set.init<A>(_:)();
      specialized Set.union<A>(_:)(v68, v49);
      (*(void (**)(char *, uint64_t))(v100 + 8))(v65, v52);
    }
    swift_bridgeObjectRetain();
    specialized _copyCollectionToContiguousArray<A>(_:)();
    uint64_t v70 = v69;
    swift_bridgeObjectRelease();
    uint64_t v98 = v70;
    uint64_t v71 = v86;
    specialized MutableCollection<>.sort(by:)(&v98);
    uint64_t v59 = v91;
    if (!v71)
    {
      swift_bridgeObjectRelease();
      uint64_t v60 = v98;
      goto LABEL_14;
    }
LABEL_16:
    uint64_t result = swift_release();
    __break(1u);
    return result;
  }
  int v91 = a6;
  uint64_t v84 = a1;
  AnyColumn.assumingType<A>(_:)();
  uint64_t v98 = 0;
  unint64_t v99 = 0xE000000000000000;
  uint64_t v39 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>((unint64_t *)&lazy protocol witness table cache variable for type Column<String> and conformance Column<A>, &demangling cache variable for type metadata for Column<String>);
  OptionalColumnProtocol.filled(with:)();
  uint64_t v40 = (void (*)(uint64_t, uint64_t))*((void *)v85 + 1);
  v40(v6, v33);
  specialized Set.init<A>(_:)();
  Swift::Int v42 = v41;
  outlined init with copy of DataFrame?(v97, (uint64_t)v25, &demangling cache variable for type metadata for AnyColumn?);
  if (__swift_getEnumTagSinglePayload((uint64_t)v25, 1, v26) == 1)
  {
    outlined destroy of UTType?((uint64_t)v25, &demangling cache variable for type metadata for AnyColumn?);
  }
  else
  {
    int v85 = (char *)v39;
    uint64_t v53 = v80;
    OUTLINED_FUNCTION_3();
    v54();
    AnyColumn.assumingType<A>(_:)();
    uint64_t v98 = 0;
    unint64_t v99 = 0xE000000000000000;
    OptionalColumnProtocol.filled(with:)();
    v40(v6, v33);
    specialized Set.init<A>(_:)();
    specialized Set.union<A>(_:)(v55, v42);
    (*(void (**)(char *, uint64_t))(v100 + 8))(v53, v26);
  }
  swift_bridgeObjectRetain();
  specialized _copyCollectionToContiguousArray<A>(_:)();
  uint64_t v57 = v56;
  swift_bridgeObjectRelease();
  uint64_t v98 = v57;
  uint64_t v58 = v86;
  specialized MutableCollection<>.sort(by:)(&v98);
  uint64_t v59 = v91;
  if (v58) {
    goto LABEL_16;
  }
  swift_bridgeObjectRelease();
  uint64_t v50 = v97;
  uint64_t v60 = v98;
LABEL_14:
  BOOL v72 = v92 != 0;
  v59[3] = v60;
  *((unsigned char *)v59 + 32) = v72;
  OUTLINED_FUNCTION_18_3();
  v73();
  uint64_t v74 = v88;
  BaseTreeClassifier.init(configuration:)();
  OUTLINED_FUNCTION_137();
  v75();
  outlined destroy of UTType?(v50, &demangling cache variable for type metadata for AnyColumn?);
  OUTLINED_FUNCTION_25_0();
  v76();
  uint64_t v77 = type metadata accessor for AnyTreeClassifier();
  return (*(uint64_t (**)(char *, uint64_t, uint64_t))(v89 + 32))((char *)v59 + *(int *)(v77 + 32), v74, v90);
}

uint64_t AnyTreeClassifier.fitted(to:validateOn:eventHandler:)@<X0>(char *a1@<X0>, uint64_t a2@<X1>, uint64_t a3@<X2>, uint64_t a4@<X3>, void *a5@<X8>)
{
  uint64_t v82 = a3;
  uint64_t v83 = a4;
  uint64_t v86 = a2;
  uint64_t v79 = a5;
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
  uint64_t v8 = OUTLINED_FUNCTION_17(v7);
  MEMORY[0x270FA5388](v8);
  OUTLINED_FUNCTION_33_0();
  uint64_t v87 = v9;
  OUTLINED_FUNCTION_65();
  uint64_t v90 = type metadata accessor for DataFrame();
  OUTLINED_FUNCTION_0();
  uint64_t v84 = v10;
  MEMORY[0x270FA5388](v11);
  OUTLINED_FUNCTION_33_0();
  uint64_t v81 = v12;
  OUTLINED_FUNCTION_65();
  type metadata accessor for BaseTreeClassifierModel();
  OUTLINED_FUNCTION_0();
  uint64_t v76 = v13;
  uint64_t v77 = v14;
  uint64_t v15 = MEMORY[0x270FA5388](v13);
  int v80 = (char *)&v72 - ((v16 + 15) & 0xFFFFFFFFFFFFFFF0);
  MEMORY[0x270FA5388](v15);
  OUTLINED_FUNCTION_13_25();
  MEMORY[0x270FA5388](v17);
  int v78 = (char *)&v72 - v18;
  OUTLINED_FUNCTION_65();
  type metadata accessor for AnyColumn();
  OUTLINED_FUNCTION_0();
  uint64_t v88 = v19;
  uint64_t v89 = v20;
  MEMORY[0x270FA5388](v19);
  OUTLINED_FUNCTION_3_0();
  uint64_t v23 = v22 - v21;
  uint64_t v24 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DenseMatrix<Float>);
  OUTLINED_FUNCTION_0();
  uint64_t v85 = v25;
  uint64_t v27 = MEMORY[0x270FA5388](v26);
  uint64_t v29 = (char *)&v72 - ((v28 + 15) & 0xFFFFFFFFFFFFFFF0);
  MEMORY[0x270FA5388](v27);
  unint64_t v31 = (char *)&v72 - v30;
  uint64_t v33 = *(void *)(v5 + 40);
  uint64_t v32 = *(void *)(v5 + 48);
  int v91 = a1;
  uint64_t v92 = v32;
  uint64_t v34 = *(void *)(v5 + 56);
  uint64_t v94 = a1;
  swift_bridgeObjectRetain();
  uint64_t v35 = v95;
  uint64_t ML16ColumnDescriptorVsAE_pTg5 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSaySSG_8CreateML16ColumnDescriptorVsAE_pTg5((uint64_t)closure #1 in FeatureVectorizer.fitted(to:)partial apply, (uint64_t)v93, v33);
  uint64_t result = swift_bridgeObjectRelease();
  if (!v35)
  {
    uint64_t v95 = v23;
    uint64_t v74 = v29;
    uint64_t v75 = v24;
    uint64_t v38 = v90;
    swift_bridgeObjectRetain();
    specialized FeatureVectorizer.Transformer.vectorized(_:includingBias:)();
    uint64_t v72 = ML16ColumnDescriptorVsAE_pTg5;
    uint64_t v73 = 0;
    uint64_t v39 = (void *)v5;
    uint64_t v40 = *(void *)(v5 + 24);
    char v41 = *(unsigned char *)(v5 + 32);
    uint64_t v42 = v95;
    MEMORY[0x22A672220](*v39, v39[1]);
    uint64_t v43 = Labels.encodeAnnotations(_:)(v42, v40, v41);
    uint64_t v44 = v89 + 8;
    uint64_t v45 = *(void (**)(uint64_t, uint64_t))(v89 + 8);
    v45(v42, v88);
    uint64_t v46 = v87;
    outlined init with copy of DataFrame?(v86, v87, &demangling cache variable for type metadata for DataFrame?);
    if (__swift_getEnumTagSinglePayload(v46, 1, v38) == 1)
    {
      outlined destroy of UTType?(v46, &demangling cache variable for type metadata for DataFrame?);
      type metadata accessor for AnyTreeClassifier();
      uint64_t v47 = v73;
      BaseTreeClassifier.fitted(features:annotations:classCount:eventHandler:)();
      uint64_t v48 = v47;
      OUTLINED_FUNCTION_25_0();
      v49();
      if (v47)
      {
        swift_bridgeObjectRelease();
        swift_bridgeObjectRelease();
        return swift_bridgeObjectRelease();
      }
      uint64_t v73 = 0;
      uint64_t v95 = v34;
      swift_bridgeObjectRelease();
      OUTLINED_FUNCTION_6_27();
    }
    else
    {
      uint64_t v86 = v43;
      uint64_t v89 = v44;
      int v91 = v31;
      uint64_t v50 = v84;
      uint64_t v51 = v81;
      OUTLINED_FUNCTION_3();
      v52();
      uint64_t v53 = v73;
      specialized FeatureVectorizer.Transformer.vectorized(_:includingBias:)();
      if (v53)
      {
        swift_bridgeObjectRelease();
        swift_bridgeObjectRelease();
        swift_bridgeObjectRelease();
        (*(void (**)(uint64_t, uint64_t))(v50 + 8))(v51, v38);
        OUTLINED_FUNCTION_25_0();
        return v54();
      }
      uint64_t v56 = v39[3];
      char v57 = *((unsigned char *)v39 + 32);
      uint64_t v58 = v95;
      MEMORY[0x22A672220](*v39, v39[1]);
      Labels.encodeAnnotations(_:)(v58, v56, v57);
      v45(v58, v88);
      type metadata accessor for AnyTreeClassifier();
      BaseTreeClassifier.fitted(trainingFeatures:trainingAnnotations:validationFeatures:validationAnnotations:classCount:eventHandler:)();
      uint64_t v73 = 0;
      uint64_t v95 = v34;
      swift_bridgeObjectRelease();
      swift_bridgeObjectRelease();
      uint64_t v48 = v85 + 8;
      uint64_t v59 = *(void (**)(void))(v85 + 8);
      OUTLINED_FUNCTION_4_35();
      OUTLINED_FUNCTION_137();
      v59();
      OUTLINED_FUNCTION_25_0();
      v60();
      OUTLINED_FUNCTION_137();
      v59();
      OUTLINED_FUNCTION_6_27();
    }
    uint64_t v61 = v76;
    id v62 = v55;
    OUTLINED_FUNCTION_3();
    v63();
    uint64_t v65 = *v39;
    uint64_t v64 = v39[1];
    uint64_t v66 = type metadata accessor for AnyTreeClassifierModel();
    uint64_t v67 = v79;
    v62((char *)v79 + *(int *)(v66 + 24), v48, v61);
    uint64_t v68 = v39[3];
    char v69 = *((unsigned char *)v39 + 32);
    *uint64_t v67 = v65;
    v67[1] = v64;
    uint64_t v70 = v92;
    v67[2] = v72;
    v67[3] = v70;
    v67[4] = v95;
    uint64_t v71 = (char *)v67 + *(int *)(v66 + 28);
    *(void *)uint64_t v71 = v68;
    v71[8] = v69;
    swift_bridgeObjectRetain();
    return swift_bridgeObjectRetain();
  }
  return result;
}

uint64_t AnyTreeClassifier.encode(_:to:)(uint64_t a1, uint64_t a2)
{
  __swift_mutable_project_boxed_opaque_existential_1(a2, *(void *)(a2 + 24));
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FeatureVectorizer<Float>.Transformer?);
  lazy protocol witness table accessor for type FeatureVectorizer<Float>.Transformer? and conformance <A> A?();
  uint64_t result = dispatch thunk of EstimatorEncoder.encode<A>(_:)();
  if (!v2)
  {
    type metadata accessor for AnyTreeClassifierModel();
    __swift_mutable_project_boxed_opaque_existential_1(a2, *(void *)(a2 + 24));
    type metadata accessor for BaseTreeClassifierModel();
    lazy protocol witness table accessor for type AnyTreeClassifierModel and conformance AnyTreeClassifierModel(&lazy protocol witness table cache variable for type BaseTreeClassifierModel and conformance BaseTreeClassifierModel, MEMORY[0x263F043E0]);
    return dispatch thunk of EstimatorEncoder.encode<A>(_:)();
  }
  return result;
}

uint64_t AnyTreeClassifier.decode(from:)@<X0>(uint64_t a1@<X0>, char *a2@<X8>)
{
  uint64_t v5 = type metadata accessor for BaseTreeClassifierModel();
  OUTLINED_FUNCTION_0();
  uint64_t v15 = v6;
  MEMORY[0x270FA5388](v7);
  OUTLINED_FUNCTION_27_7();
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FeatureVectorizer<Float>.Transformer);
  __swift_mutable_project_boxed_opaque_existential_1(a1, *(void *)(a1 + 24));
  lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type FeatureVectorizer<Float>.Transformer and conformance FeatureVectorizer<A>.Transformer, &demangling cache variable for type metadata for FeatureVectorizer<Float>.Transformer);
  uint64_t result = dispatch thunk of EstimatorDecoder.decode<A>(_:)();
  if (!v2)
  {
    __swift_mutable_project_boxed_opaque_existential_1(a1, *(void *)(a1 + 24));
    lazy protocol witness table accessor for type AnyTreeClassifierModel and conformance AnyTreeClassifierModel(&lazy protocol witness table cache variable for type BaseTreeClassifierModel and conformance BaseTreeClassifierModel, MEMORY[0x263F043E0]);
    dispatch thunk of EstimatorDecoder.decode<A>(_:)();
    uint64_t v9 = v16[1];
    uint64_t v14 = *v16;
    uint64_t v10 = type metadata accessor for AnyTreeClassifierModel();
    (*(void (**)(char *, uint64_t, uint64_t))(v15 + 32))(&a2[*(int *)(v10 + 24)], v3, v5);
    uint64_t v11 = v16[3];
    char v12 = *((unsigned char *)v16 + 32);
    *(void *)a2 = v14;
    *((void *)a2 + 1) = v9;
    *((void *)a2 + 2) = v17;
    *((void *)a2 + 3) = v18;
    *((void *)a2 + 4) = v19;
    uint64_t v13 = &a2[*(int *)(v10 + 28)];
    *(void *)uint64_t v13 = v11;
    v13[8] = v12;
    swift_bridgeObjectRetain();
    return swift_bridgeObjectRetain();
  }
  return result;
}

void (*protocol witness for SupervisedTabularEstimator.annotationColumnID.modify in conformance AnyTreeClassifier(void *a1))(uint64_t a1, char a2)
{
  uint64_t v3 = malloc(0x28uLL);
  *a1 = v3;
  *uint64_t v3 = v1;
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ColumnID<Either<String, Int>>);
  v3[1] = v4;
  uint64_t v5 = *(void *)(v4 - 8);
  v3[2] = v5;
  size_t v6 = *(void *)(v5 + 64);
  v3[3] = malloc(v6);
  v3[4] = malloc(v6);
  MLLogisticRegressionClassifier.Classifier.annotationColumnID.getter();
  return protocol witness for SupervisedTabularEstimator.annotationColumnID.modify in conformance AnyTreeClassifier;
}

void protocol witness for SupervisedTabularEstimator.annotationColumnID.modify in conformance AnyTreeClassifier(uint64_t a1, char a2)
{
  uint64_t v2 = *(void **)a1;
  uint64_t v3 = *(void **)(*(void *)a1 + 24);
  uint64_t v4 = *(void **)(*(void *)a1 + 32);
  if (a2)
  {
    OUTLINED_FUNCTION_18_3();
    v5();
    MLLogisticRegressionClassifier.Classifier.annotationColumnID.setter();
    OUTLINED_FUNCTION_137();
    v6();
  }
  else
  {
    MLLogisticRegressionClassifier.Classifier.annotationColumnID.setter();
  }
  free(v4);
  free(v3);

  free(v2);
}

uint64_t protocol witness for SupervisedTabularEstimator.fitted(to:validateOn:eventHandler:) in conformance AnyTreeClassifier(void *a1, char *a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  AnyTreeClassifier.fitted(to:validateOn:eventHandler:)(a2, a3, a4, a5, a1);
  size_t v6 = *(uint64_t (**)(void))(v5 + 8);
  return protocol witness for SupervisedTabularEstimator.fitted(to:validateOn:eventHandler:) in conformance TreeRegressor(v6);
}

uint64_t protocol witness for SupervisedTabularEstimator.encode(_:to:) in conformance AnyTreeClassifier(uint64_t a1, uint64_t a2)
{
  return AnyTreeClassifier.encode(_:to:)(a1, a2);
}

uint64_t protocol witness for SupervisedTabularEstimator.decode(from:) in conformance AnyTreeClassifier@<X0>(uint64_t a1@<X0>, char *a2@<X8>)
{
  return AnyTreeClassifier.decode(from:)(a1, a2);
}

uint64_t base witness table accessor for SupervisedTabularEstimator in AnyTreeClassifier()
{
  return lazy protocol witness table accessor for type AnyTreeClassifierModel and conformance AnyTreeClassifierModel((unint64_t *)&lazy protocol witness table cache variable for type AnyTreeClassifier and conformance AnyTreeClassifier, (void (*)(uint64_t))type metadata accessor for AnyTreeClassifier);
}

uint64_t protocol witness for UpdatableSupervisedTabularEstimator.update(_:with:eventHandler:) in conformance AnyTreeClassifier(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v9 = (void *)swift_task_alloc();
  *(void *)(v4 + 16) = v9;
  *uint64_t v9 = v4;
  v9[1] = partial apply for closure #1 in MLImageClassifier.evaluation(on:);
  return AnyTreeClassifier.update(_:with:eventHandler:)(a1, a2, a3, a4);
}

uint64_t protocol witness for UpdatableSupervisedTabularEstimator.encodeWithOptimizer(_:to:) in conformance AnyTreeClassifier(uint64_t a1, uint64_t a2)
{
  return protocol witness for SupervisedTabularEstimator.encode(_:to:) in conformance AnyTreeClassifier(a1, a2);
}

uint64_t protocol witness for UpdatableSupervisedTabularEstimator.decodeWithOptimizer(from:) in conformance AnyTreeClassifier@<X0>(uint64_t a1@<X0>, char *a2@<X8>)
{
  return protocol witness for SupervisedTabularEstimator.decode(from:) in conformance AnyTreeClassifier(a1, a2);
}

uint64_t lazy protocol witness table accessor for type AnyTreeClassifierModel and conformance AnyTreeClassifierModel(unint64_t *a1, void (*a2)(uint64_t))
{
  uint64_t result = *a1;
  if (!result)
  {
    a2(255);
    uint64_t result = swift_getWitnessTable();
    atomic_store(result, a1);
  }
  return result;
}

uint64_t specialized MutableCollection<>.sort(by:)(uint64_t *a1)
{
  uint64_t v2 = *a1;
  if ((swift_isUniquelyReferenced_nonNull_native() & 1) == 0)
  {
    specialized _ContiguousArrayBuffer._consumeAndCreateNew()();
    uint64_t v2 = v3;
  }
  uint64_t v4 = *(void *)(v2 + 16);
  v6[0] = v2 + 32;
  v6[1] = v4;
  uint64_t result = specialized UnsafeMutableBufferPointer._stableSortImpl(by:)(v6);
  *a1 = v2;
  return result;
}

{
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t result;
  uint64_t v6[2];

  uint64_t v2 = *a1;
  if ((swift_isUniquelyReferenced_nonNull_native() & 1) == 0)
  {
    specialized _ContiguousArrayBuffer._consumeAndCreateNew()();
    uint64_t v2 = v3;
  }
  uint64_t v4 = *(void *)(v2 + 16);
  v6[0] = v2 + 32;
  v6[1] = v4;
  uint64_t result = specialized UnsafeMutableBufferPointer._stableSortImpl(by:)(v6);
  *a1 = v2;
  return result;
}

uint64_t specialized UnsafeMutableBufferPointer._stableSortImpl(by:)(uint64_t *a1)
{
  Swift::Int v3 = a1[1];
  uint64_t result = _minimumMergeRunLength(_:)(v3);
  if (result >= v3)
  {
    if ((v3 & 0x8000000000000000) == 0)
    {
      if (v3) {
        return specialized MutableCollection<>._insertionSort(within:sortedEnd:by:)(0, v3, 1, a1);
      }
      return result;
    }
    goto LABEL_124;
  }
  uint64_t v5 = result;
  uint64_t result = specialized static Array._allocateUninitialized(_:)(v3 / 2);
  uint64_t v83 = a1;
  uint64_t v84 = result;
  uint64_t v88 = v6;
  uint64_t v86 = v3;
  if (v3 <= 0)
  {
    uint64_t v9 = MEMORY[0x263F8EE78];
    unint64_t v26 = *(void *)(MEMORY[0x263F8EE78] + 16);
LABEL_90:
    if (v26 < 2)
    {
LABEL_101:
      uint64_t result = swift_bridgeObjectRelease();
      if (v86 >= -1)
      {
        *(void *)(v84 + 16) = 0;
        return swift_bridgeObjectRelease();
      }
      goto LABEL_129;
    }
    uint64_t v76 = *v83;
    while (1)
    {
      unint64_t v77 = v26 - 2;
      if (v26 < 2) {
        break;
      }
      if (!v76) {
        goto LABEL_133;
      }
      uint64_t v78 = *(void *)(v9 + 32 + 16 * v77);
      uint64_t v79 = *(void *)(v9 + 32 + 16 * (v26 - 1) + 8);
      uint64_t result = specialized _merge<A>(low:mid:high:buffer:by:)((uint64_t *)(v76 + 8 * v78), (uint64_t *)(v76 + 8 * *(void *)(v9 + 32 + 16 * (v26 - 1))), v76 + 8 * v79, v88);
      if (v1) {
        goto LABEL_86;
      }
      if (v79 < v78) {
        goto LABEL_119;
      }
      uint64_t result = swift_isUniquelyReferenced_nonNull_native();
      if ((result & 1) == 0)
      {
        uint64_t result = (uint64_t)specialized _ArrayBuffer._consumeAndCreateNew()();
        uint64_t v9 = result;
      }
      if (v77 >= *(void *)(v9 + 16)) {
        goto LABEL_120;
      }
      int v80 = (void *)(v9 + 32 + 16 * v77);
      *int v80 = v78;
      v80[1] = v79;
      unint64_t v81 = *(void *)(v9 + 16);
      if (v26 > v81) {
        goto LABEL_121;
      }
      uint64_t result = (uint64_t)memmove((void *)(v9 + 32 + 16 * (v26 - 1)), (const void *)(v9 + 32 + 16 * v26), 16 * (v81 - v26));
      *(void *)(v9 + 16) = v81 - 1;
      unint64_t v26 = v81 - 1;
      if (v81 <= 2) {
        goto LABEL_101;
      }
    }
LABEL_118:
    __break(1u);
LABEL_119:
    __break(1u);
LABEL_120:
    __break(1u);
LABEL_121:
    __break(1u);
LABEL_122:
    __break(1u);
LABEL_123:
    __break(1u);
LABEL_124:
    __break(1u);
LABEL_125:
    __break(1u);
LABEL_126:
    __break(1u);
LABEL_127:
    __break(1u);
LABEL_128:
    __break(1u);
LABEL_129:
    __break(1u);
LABEL_130:
    __break(1u);
LABEL_131:
    __break(1u);
LABEL_132:
    __break(1u);
LABEL_133:
    __break(1u);
    return result;
  }
  Swift::Int v7 = 0;
  uint64_t v8 = *a1;
  uint64_t v82 = *a1 - 8;
  uint64_t v9 = MEMORY[0x263F8EE78];
  uint64_t v85 = v5;
  uint64_t v87 = *a1;
  while (1)
  {
    Swift::Int v10 = v7++;
    if (v7 < v3)
    {
      uint64_t v11 = *(void *)(v8 + 8 * v7);
      uint64_t v12 = *(void *)(v8 + 8 * v10);
      Swift::Int v7 = v10 + 2;
      if (v10 + 2 < v3)
      {
        uint64_t v13 = v11;
        while (1)
        {
          uint64_t v14 = *(void *)(v8 + 8 * v7);
          if (v11 < v12 == v14 >= v13) {
            break;
          }
          ++v7;
          uint64_t v13 = v14;
          if (v7 >= v3)
          {
            Swift::Int v7 = v3;
            break;
          }
        }
      }
      if (v11 < v12)
      {
        if (v7 < v10) {
          goto LABEL_126;
        }
        if (v10 < v7)
        {
          Swift::Int v15 = v7 - 1;
          Swift::Int v16 = v10;
          do
          {
            if (v16 != v15)
            {
              if (!v8) {
                goto LABEL_132;
              }
              uint64_t v17 = *(void *)(v8 + 8 * v16);
              *(void *)(v8 + 8 * v16) = *(void *)(v8 + 8 * v15);
              *(void *)(v8 + 8 * v15) = v17;
            }
            BOOL v57 = ++v16 < v15--;
          }
          while (v57);
        }
      }
    }
    if (v7 < v3)
    {
      if (__OFSUB__(v7, v10)) {
        goto LABEL_123;
      }
      if (v7 - v10 < v5)
      {
        Swift::Int v18 = v10 + v5;
        if (__OFADD__(v10, v5)) {
          goto LABEL_127;
        }
        if (v18 >= v3) {
          Swift::Int v18 = v3;
        }
        if (v18 < v10) {
          goto LABEL_128;
        }
        if (v7 != v18)
        {
          uint64_t v19 = (uint64_t *)(v82 + 8 * v7);
          do
          {
            uint64_t v20 = *(void *)(v8 + 8 * v7);
            Swift::Int v21 = v10;
            uint64_t v22 = v19;
            do
            {
              uint64_t v23 = *v22;
              if (v20 >= *v22) {
                break;
              }
              if (!v8) {
                goto LABEL_130;
              }
              *uint64_t v22 = v20;
              v22[1] = v23;
              --v22;
              ++v21;
            }
            while (v7 != v21);
            ++v7;
            ++v19;
          }
          while (v7 != v18);
          Swift::Int v7 = v18;
        }
      }
    }
    if (v7 < v10) {
      goto LABEL_122;
    }
    uint64_t result = swift_isUniquelyReferenced_nonNull_native();
    if ((result & 1) == 0)
    {
      uint64_t result = (uint64_t)specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *(void *)(v9 + 16) + 1, 1, (char *)v9);
      uint64_t v9 = result;
    }
    unint64_t v25 = *(void *)(v9 + 16);
    unint64_t v24 = *(void *)(v9 + 24);
    unint64_t v26 = v25 + 1;
    uint64_t v8 = v87;
    if (v25 >= v24 >> 1)
    {
      uint64_t result = (uint64_t)specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)((char *)(v24 > 1), v25 + 1, 1, (char *)v9);
      uint64_t v8 = v87;
      uint64_t v9 = result;
    }
    *(void *)(v9 + 16) = v26;
    uint64_t v27 = v9 + 32;
    uint64_t v28 = (Swift::Int *)(v9 + 32 + 16 * v25);
    *uint64_t v28 = v10;
    v28[1] = v7;
    if (v25) {
      break;
    }
    unint64_t v26 = 1;
LABEL_81:
    uint64_t v5 = v85;
    Swift::Int v3 = v86;
    if (v7 >= v86) {
      goto LABEL_90;
    }
  }
  while (1)
  {
    unint64_t v29 = v26 - 1;
    if (v26 >= 4)
    {
      unint64_t v34 = v27 + 16 * v26;
      uint64_t v35 = *(void *)(v34 - 64);
      uint64_t v36 = *(void *)(v34 - 56);
      BOOL v40 = __OFSUB__(v36, v35);
      uint64_t v37 = v36 - v35;
      if (v40) {
        goto LABEL_107;
      }
      uint64_t v39 = *(void *)(v34 - 48);
      uint64_t v38 = *(void *)(v34 - 40);
      BOOL v40 = __OFSUB__(v38, v39);
      uint64_t v32 = v38 - v39;
      char v33 = v40;
      if (v40) {
        goto LABEL_108;
      }
      unint64_t v41 = v26 - 2;
      uint64_t v42 = (uint64_t *)(v27 + 16 * (v26 - 2));
      uint64_t v44 = *v42;
      uint64_t v43 = v42[1];
      BOOL v40 = __OFSUB__(v43, v44);
      uint64_t v45 = v43 - v44;
      if (v40) {
        goto LABEL_109;
      }
      BOOL v40 = __OFADD__(v32, v45);
      uint64_t v46 = v32 + v45;
      if (v40) {
        goto LABEL_111;
      }
      if (v46 >= v37)
      {
        uint64_t v64 = (uint64_t *)(v27 + 16 * v29);
        uint64_t v66 = *v64;
        uint64_t v65 = v64[1];
        BOOL v40 = __OFSUB__(v65, v66);
        uint64_t v67 = v65 - v66;
        if (v40) {
          goto LABEL_117;
        }
        BOOL v57 = v32 < v67;
        goto LABEL_70;
      }
    }
    else
    {
      if (v26 != 3)
      {
        uint64_t v58 = *(void *)(v9 + 32);
        uint64_t v59 = *(void *)(v9 + 40);
        BOOL v40 = __OFSUB__(v59, v58);
        uint64_t v51 = v59 - v58;
        char v52 = v40;
        goto LABEL_64;
      }
      uint64_t v31 = *(void *)(v9 + 32);
      uint64_t v30 = *(void *)(v9 + 40);
      BOOL v40 = __OFSUB__(v30, v31);
      uint64_t v32 = v30 - v31;
      char v33 = v40;
    }
    if (v33) {
      goto LABEL_110;
    }
    unint64_t v41 = v26 - 2;
    uint64_t v47 = (uint64_t *)(v27 + 16 * (v26 - 2));
    uint64_t v49 = *v47;
    uint64_t v48 = v47[1];
    BOOL v50 = __OFSUB__(v48, v49);
    uint64_t v51 = v48 - v49;
    char v52 = v50;
    if (v50) {
      goto LABEL_112;
    }
    uint64_t v53 = (uint64_t *)(v27 + 16 * v29);
    uint64_t v55 = *v53;
    uint64_t v54 = v53[1];
    BOOL v40 = __OFSUB__(v54, v55);
    uint64_t v56 = v54 - v55;
    if (v40) {
      goto LABEL_114;
    }
    if (__OFADD__(v51, v56)) {
      goto LABEL_116;
    }
    if (v51 + v56 >= v32)
    {
      BOOL v57 = v32 < v56;
LABEL_70:
      if (v57) {
        unint64_t v29 = v41;
      }
      goto LABEL_72;
    }
LABEL_64:
    if (v52) {
      goto LABEL_113;
    }
    uint64_t v60 = (uint64_t *)(v27 + 16 * v29);
    uint64_t v62 = *v60;
    uint64_t v61 = v60[1];
    BOOL v40 = __OFSUB__(v61, v62);
    uint64_t v63 = v61 - v62;
    if (v40) {
      goto LABEL_115;
    }
    if (v63 < v51) {
      goto LABEL_81;
    }
LABEL_72:
    uint64_t v68 = v9;
    unint64_t v69 = v29 - 1;
    if (v29 - 1 >= v26)
    {
      __break(1u);
LABEL_104:
      __break(1u);
LABEL_105:
      __break(1u);
LABEL_106:
      __break(1u);
LABEL_107:
      __break(1u);
LABEL_108:
      __break(1u);
LABEL_109:
      __break(1u);
LABEL_110:
      __break(1u);
LABEL_111:
      __break(1u);
LABEL_112:
      __break(1u);
LABEL_113:
      __break(1u);
LABEL_114:
      __break(1u);
LABEL_115:
      __break(1u);
LABEL_116:
      __break(1u);
LABEL_117:
      __break(1u);
      goto LABEL_118;
    }
    if (!v8) {
      goto LABEL_131;
    }
    uint64_t v70 = (uint64_t *)(v27 + 16 * v69);
    uint64_t v71 = *v70;
    uint64_t v72 = v27;
    uint64_t v73 = (void *)(v27 + 16 * v29);
    uint64_t v74 = v73[1];
    uint64_t result = specialized _merge<A>(low:mid:high:buffer:by:)((uint64_t *)(v8 + 8 * *v70), (uint64_t *)(v8 + 8 * *v73), v8 + 8 * v74, v88);
    if (v1) {
      break;
    }
    if (v74 < v71) {
      goto LABEL_104;
    }
    if (v29 > *(void *)(v68 + 16)) {
      goto LABEL_105;
    }
    *uint64_t v70 = v71;
    *(void *)(v72 + 16 * v69 + 8) = v74;
    unint64_t v75 = *(void *)(v68 + 16);
    if (v29 >= v75) {
      goto LABEL_106;
    }
    uint64_t v9 = v68;
    unint64_t v26 = v75 - 1;
    uint64_t result = (uint64_t)memmove(v73, v73 + 2, 16 * (v75 - 1 - v29));
    uint64_t v27 = v72;
    *(void *)(v68 + 16) = v75 - 1;
    uint64_t v8 = v87;
    if (v75 <= 2) {
      goto LABEL_81;
    }
  }
LABEL_86:
  uint64_t result = swift_bridgeObjectRelease();
  if (v86 < -1) {
    goto LABEL_125;
  }
  *(void *)(v84 + 16) = 0;
  return swift_bridgeObjectRelease();
}

{
  uint64_t v1;
  Swift::Int v3;
  uint64_t result;
  uint64_t v5;
  char *v6;
  Swift::Int v7;
  uint64_t v8;
  Swift::Int v9;
  uint64_t *v10;
  uint64_t v11;
  void *v12;
  int v14;
  Swift::Int v15;
  void *v16;
  void *v17;
  Swift::Int v19;
  uint64_t v20;
  uint64_t v21;
  Swift::Int v22;
  Swift::Int v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  Swift::Int v27;
  uint64_t v28;
  unint64_t v29;
  unint64_t v30;
  unint64_t v31;
  uint64_t v32;
  Swift::Int *v33;
  unint64_t v34;
  uint64_t v35;
  uint64_t v36;
  uint64_t v37;
  char v38;
  unint64_t v39;
  uint64_t v40;
  uint64_t v41;
  uint64_t v42;
  uint64_t v43;
  uint64_t v44;
  BOOL v45;
  unint64_t v46;
  uint64_t *v47;
  uint64_t v48;
  uint64_t v49;
  uint64_t v50;
  uint64_t v51;
  uint64_t *v52;
  uint64_t v53;
  uint64_t v54;
  BOOL v55;
  uint64_t v56;
  char v57;
  uint64_t *v58;
  uint64_t v59;
  uint64_t v60;
  uint64_t v61;
  BOOL v62;
  uint64_t v63;
  uint64_t v64;
  uint64_t *v65;
  uint64_t v66;
  uint64_t v67;
  uint64_t v68;
  uint64_t *v69;
  uint64_t v70;
  uint64_t v71;
  uint64_t v72;
  unint64_t v73;
  uint64_t *v74;
  uint64_t v75;
  void *v76;
  uint64_t v77;
  unint64_t v78;
  uint64_t *v79;
  uint64_t *v80;
  uint64_t v81;
  Swift::Int v82;
  uint64_t *v83;
  uint64_t v85;
  unint64_t v86;
  uint64_t v87;
  uint64_t v88;
  uint64_t v89;
  void *v90;
  unint64_t v91;
  uint64_t v92;
  uint64_t *v93;
  uint64_t v94;
  uint64_t v95;
  uint64_t v96;
  char *v97;
  uint64_t v98;

  Swift::Int v3 = a1[1];
  uint64_t result = _minimumMergeRunLength(_:)(v3);
  if (result >= v3)
  {
    if ((v3 & 0x8000000000000000) == 0)
    {
      if (v3) {
        return specialized MutableCollection<>._insertionSort(within:sortedEnd:by:)(0, v3, 1, a1);
      }
      return result;
    }
    goto LABEL_144;
  }
  uint64_t v5 = result;
  uint64_t result = specialized static Array._allocateUninitialized(_:)(v3 / 2);
  uint64_t v95 = result;
  uint64_t v96 = v3;
  uint64_t v97 = v6;
  uint64_t v93 = a1;
  if (v3 <= 0)
  {
    uint64_t v98 = MEMORY[0x263F8EE78];
    uint64_t v31 = *(void *)(MEMORY[0x263F8EE78] + 16);
LABEL_110:
    if (v31 < 2)
    {
LABEL_121:
      uint64_t result = swift_bridgeObjectRelease();
      if (v3 >= -1)
      {
        *(void *)(v95 + 16) = 0;
        return swift_bridgeObjectRelease();
      }
      goto LABEL_149;
    }
    uint64_t v85 = *v93;
    while (1)
    {
      uint64_t v86 = v31 - 2;
      if (v31 < 2) {
        break;
      }
      if (!v85) {
        goto LABEL_153;
      }
      uint64_t v87 = v98;
      uint64_t v88 = *(void *)(v98 + 32 + 16 * v86);
      uint64_t v89 = *(void *)(v98 + 32 + 16 * (v31 - 1) + 8);
      uint64_t result = specialized _merge<A>(low:mid:high:buffer:by:)((char *)(v85 + 16 * v88), (char *)(v85 + 16 * *(void *)(v98 + 32 + 16 * (v31 - 1))), v85 + 16 * v89, v97);
      if (v1) {
        goto LABEL_106;
      }
      if (v89 < v88) {
        goto LABEL_139;
      }
      uint64_t result = swift_isUniquelyReferenced_nonNull_native();
      if ((result & 1) == 0)
      {
        uint64_t result = (uint64_t)specialized _ArrayBuffer._consumeAndCreateNew()();
        uint64_t v87 = result;
      }
      if (v86 >= *(void *)(v87 + 16)) {
        goto LABEL_140;
      }
      uint64_t v90 = (void *)(v87 + 32 + 16 * v86);
      *uint64_t v90 = v88;
      v90[1] = v89;
      int v91 = *(void *)(v87 + 16);
      if (v31 > v91) {
        goto LABEL_141;
      }
      uint64_t result = (uint64_t)memmove((void *)(v87 + 32 + 16 * (v31 - 1)), (const void *)(v87 + 32 + 16 * v31), 16 * (v91 - v31));
      uint64_t v98 = v87;
      *(void *)(v87 + 16) = v91 - 1;
      uint64_t v31 = v91 - 1;
      Swift::Int v3 = v96;
      if (v91 <= 2) {
        goto LABEL_121;
      }
    }
LABEL_138:
    __break(1u);
LABEL_139:
    __break(1u);
LABEL_140:
    __break(1u);
LABEL_141:
    __break(1u);
LABEL_142:
    __break(1u);
LABEL_143:
    __break(1u);
LABEL_144:
    __break(1u);
LABEL_145:
    __break(1u);
LABEL_146:
    __break(1u);
LABEL_147:
    __break(1u);
LABEL_148:
    __break(1u);
LABEL_149:
    __break(1u);
LABEL_150:
    __break(1u);
LABEL_151:
    __break(1u);
LABEL_152:
    __break(1u);
LABEL_153:
    __break(1u);
    return result;
  }
  uint64_t v94 = v5;
  Swift::Int v7 = 0;
  uint64_t v8 = *a1;
  uint64_t v92 = *a1 + 8;
  uint64_t v98 = MEMORY[0x263F8EE78];
  while (1)
  {
    uint64_t v9 = v7++;
    if (v7 >= v3) {
      goto LABEL_32;
    }
    Swift::Int v10 = (uint64_t *)(v8 + 16 * v7);
    uint64_t result = *v10;
    uint64_t v11 = v10[1];
    uint64_t v12 = (void *)(v8 + 16 * v9);
    if (result == *v12 && v11 == v12[1])
    {
      Swift::Int v15 = v9 + 2;
      if (v9 + 2 >= v3) {
        goto LABEL_31;
      }
      uint64_t v14 = 0;
LABEL_13:
      Swift::Int v16 = (void *)(v92 + 16 * v15);
      do
      {
        uint64_t result = *(v16 - 1);
        uint64_t v17 = (void *)(v8 + 16 * v7);
        if (result == *v17 && *v16 == v17[1])
        {
          if (v14) {
            goto LABEL_24;
          }
        }
        else
        {
          uint64_t result = _stringCompareWithSmolCheck(_:_:expecting:)();
          if ((v14 ^ result)) {
            goto LABEL_23;
          }
        }
        v16 += 2;
        uint64_t v19 = v15 + 1;
        Swift::Int v7 = v15;
        Swift::Int v15 = v19;
      }
      while (v19 < v3);
      Swift::Int v15 = v19;
      goto LABEL_23;
    }
    uint64_t result = _stringCompareWithSmolCheck(_:_:expecting:)();
    uint64_t v14 = result;
    Swift::Int v15 = v9 + 2;
    if (v9 + 2 < v3) {
      goto LABEL_13;
    }
LABEL_23:
    Swift::Int v7 = v15;
    if ((v14 & 1) == 0) {
      goto LABEL_32;
    }
LABEL_24:
    if (v15 < v9) {
      goto LABEL_148;
    }
    if (v9 < v15)
    {
      uint64_t v20 = 16 * v15;
      Swift::Int v21 = 16 * v9;
      uint64_t v22 = v15;
      uint64_t v23 = v9;
      do
      {
        if (v23 != --v22)
        {
          if (!v8) {
            goto LABEL_152;
          }
          unint64_t v24 = v8 + v20;
          unint64_t v25 = *(void *)(v8 + v21);
          unint64_t v26 = *(void *)(v8 + v21 + 8);
          *(_OWORD *)(v8 + v21) = *(_OWORD *)(v8 + v20 - 16);
          *(void *)(v24 - 16) = v25;
          *(void *)(v24 - 8) = v26;
        }
        ++v23;
        v20 -= 16;
        v21 += 16;
      }
      while (v23 < v22);
    }
LABEL_31:
    Swift::Int v7 = v15;
LABEL_32:
    if (v7 >= v3) {
      goto LABEL_41;
    }
    if (__OFSUB__(v7, v9)) {
      goto LABEL_143;
    }
    if (v7 - v9 >= v94) {
      goto LABEL_41;
    }
    if (__OFADD__(v9, v94)) {
      goto LABEL_146;
    }
    if (v9 + v94 >= v3) {
      uint64_t v27 = v3;
    }
    else {
      uint64_t v27 = v9 + v94;
    }
    if (v27 < v9) {
      goto LABEL_147;
    }
    if (v7 == v27)
    {
LABEL_41:
      uint64_t v28 = v98;
    }
    else
    {
      uint64_t v79 = (uint64_t *)(v8 + 16 * v7);
      uint64_t v28 = v98;
      do
      {
        int v80 = (uint64_t *)(v8 + 16 * v7);
        uint64_t result = *v80;
        unint64_t v81 = v80[1];
        uint64_t v82 = v9;
        uint64_t v83 = v79;
        do
        {
          if (result == *(v83 - 2) && v81 == *(v83 - 1)) {
            break;
          }
          uint64_t result = _stringCompareWithSmolCheck(_:_:expecting:)();
          if ((result & 1) == 0) {
            break;
          }
          if (!v8) {
            goto LABEL_150;
          }
          uint64_t result = *v83;
          unint64_t v81 = v83[1];
          *(_OWORD *)uint64_t v83 = *((_OWORD *)v83 - 1);
          *(v83 - 1) = v81;
          *(v83 - 2) = result;
          v83 -= 2;
          ++v82;
        }
        while (v7 != v82);
        ++v7;
        v79 += 2;
      }
      while (v7 != v27);
      Swift::Int v7 = v27;
    }
    if (v7 < v9) {
      goto LABEL_142;
    }
    uint64_t result = swift_isUniquelyReferenced_nonNull_native();
    if ((result & 1) == 0)
    {
      uint64_t result = (uint64_t)specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *(void *)(v28 + 16) + 1, 1, (char *)v28);
      uint64_t v28 = result;
    }
    uint64_t v30 = *(void *)(v28 + 16);
    unint64_t v29 = *(void *)(v28 + 24);
    uint64_t v31 = v30 + 1;
    if (v30 >= v29 >> 1)
    {
      uint64_t result = (uint64_t)specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)((char *)(v29 > 1), v30 + 1, 1, (char *)v28);
      uint64_t v28 = result;
    }
    *(void *)(v28 + 16) = v31;
    uint64_t v32 = v28 + 32;
    char v33 = (Swift::Int *)(v28 + 32 + 16 * v30);
    *char v33 = v9;
    v33[1] = v7;
    uint64_t v98 = v28;
    if (v30) {
      break;
    }
    uint64_t v31 = 1;
LABEL_90:
    Swift::Int v3 = v96;
    if (v7 >= v96) {
      goto LABEL_110;
    }
  }
  while (1)
  {
    unint64_t v34 = v31 - 1;
    if (v31 >= 4)
    {
      uint64_t v39 = v32 + 16 * v31;
      BOOL v40 = *(void *)(v39 - 64);
      unint64_t v41 = *(void *)(v39 - 56);
      uint64_t v45 = __OFSUB__(v41, v40);
      uint64_t v42 = v41 - v40;
      if (v45) {
        goto LABEL_127;
      }
      uint64_t v44 = *(void *)(v39 - 48);
      uint64_t v43 = *(void *)(v39 - 40);
      uint64_t v45 = __OFSUB__(v43, v44);
      uint64_t v37 = v43 - v44;
      uint64_t v38 = v45;
      if (v45) {
        goto LABEL_128;
      }
      uint64_t v46 = v31 - 2;
      uint64_t v47 = (uint64_t *)(v32 + 16 * (v31 - 2));
      uint64_t v49 = *v47;
      uint64_t v48 = v47[1];
      uint64_t v45 = __OFSUB__(v48, v49);
      BOOL v50 = v48 - v49;
      if (v45) {
        goto LABEL_129;
      }
      uint64_t v45 = __OFADD__(v37, v50);
      uint64_t v51 = v37 + v50;
      if (v45) {
        goto LABEL_131;
      }
      if (v51 >= v42)
      {
        unint64_t v69 = (uint64_t *)(v32 + 16 * v34);
        uint64_t v71 = *v69;
        uint64_t v70 = v69[1];
        uint64_t v45 = __OFSUB__(v70, v71);
        uint64_t v72 = v70 - v71;
        if (v45) {
          goto LABEL_137;
        }
        uint64_t v62 = v37 < v72;
        goto LABEL_79;
      }
    }
    else
    {
      if (v31 != 3)
      {
        uint64_t v63 = *(void *)(v28 + 32);
        uint64_t v64 = *(void *)(v28 + 40);
        uint64_t v45 = __OFSUB__(v64, v63);
        uint64_t v56 = v64 - v63;
        BOOL v57 = v45;
        goto LABEL_73;
      }
      uint64_t v36 = *(void *)(v28 + 32);
      uint64_t v35 = *(void *)(v28 + 40);
      uint64_t v45 = __OFSUB__(v35, v36);
      uint64_t v37 = v35 - v36;
      uint64_t v38 = v45;
    }
    if (v38) {
      goto LABEL_130;
    }
    uint64_t v46 = v31 - 2;
    char v52 = (uint64_t *)(v32 + 16 * (v31 - 2));
    uint64_t v54 = *v52;
    uint64_t v53 = v52[1];
    uint64_t v55 = __OFSUB__(v53, v54);
    uint64_t v56 = v53 - v54;
    BOOL v57 = v55;
    if (v55) {
      goto LABEL_132;
    }
    uint64_t v58 = (uint64_t *)(v32 + 16 * v34);
    uint64_t v60 = *v58;
    uint64_t v59 = v58[1];
    uint64_t v45 = __OFSUB__(v59, v60);
    uint64_t v61 = v59 - v60;
    if (v45) {
      goto LABEL_134;
    }
    if (__OFADD__(v56, v61)) {
      goto LABEL_136;
    }
    if (v56 + v61 >= v37)
    {
      uint64_t v62 = v37 < v61;
LABEL_79:
      if (v62) {
        unint64_t v34 = v46;
      }
      goto LABEL_81;
    }
LABEL_73:
    if (v57) {
      goto LABEL_133;
    }
    uint64_t v65 = (uint64_t *)(v32 + 16 * v34);
    uint64_t v67 = *v65;
    uint64_t v66 = v65[1];
    uint64_t v45 = __OFSUB__(v66, v67);
    uint64_t v68 = v66 - v67;
    if (v45) {
      goto LABEL_135;
    }
    if (v68 < v56) {
      goto LABEL_90;
    }
LABEL_81:
    uint64_t v73 = v34 - 1;
    if (v34 - 1 >= v31)
    {
      __break(1u);
LABEL_124:
      __break(1u);
LABEL_125:
      __break(1u);
LABEL_126:
      __break(1u);
LABEL_127:
      __break(1u);
LABEL_128:
      __break(1u);
LABEL_129:
      __break(1u);
LABEL_130:
      __break(1u);
LABEL_131:
      __break(1u);
LABEL_132:
      __break(1u);
LABEL_133:
      __break(1u);
LABEL_134:
      __break(1u);
LABEL_135:
      __break(1u);
LABEL_136:
      __break(1u);
LABEL_137:
      __break(1u);
      goto LABEL_138;
    }
    if (!v8) {
      goto LABEL_151;
    }
    uint64_t v74 = (uint64_t *)(v32 + 16 * v73);
    unint64_t v75 = *v74;
    uint64_t v76 = (void *)(v32 + 16 * v34);
    unint64_t v77 = v76[1];
    uint64_t result = specialized _merge<A>(low:mid:high:buffer:by:)((char *)(v8 + 16 * *v74), (char *)(v8 + 16 * *v76), v8 + 16 * v77, v97);
    if (v1) {
      break;
    }
    if (v77 < v75) {
      goto LABEL_124;
    }
    if (v34 > *(void *)(v98 + 16)) {
      goto LABEL_125;
    }
    *uint64_t v74 = v75;
    *(void *)(v32 + 16 * v73 + 8) = v77;
    uint64_t v78 = *(void *)(v98 + 16);
    if (v34 >= v78) {
      goto LABEL_126;
    }
    uint64_t v28 = v98;
    uint64_t v31 = v78 - 1;
    uint64_t result = (uint64_t)memmove((void *)(v32 + 16 * v34), v76 + 2, 16 * (v78 - 1 - v34));
    *(void *)(v98 + 16) = v78 - 1;
    if (v78 <= 2) {
      goto LABEL_90;
    }
  }
LABEL_106:
  uint64_t result = swift_bridgeObjectRelease();
  if (v96 < -1) {
    goto LABEL_145;
  }
  *(void *)(v95 + 16) = 0;
  return swift_bridgeObjectRelease();
}