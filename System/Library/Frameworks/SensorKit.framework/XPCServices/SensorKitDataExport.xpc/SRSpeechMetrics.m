@interface SRSpeechMetrics
- (id)sr_dictionaryRepresentation;
@end

@implementation SRSpeechMetrics

- (id)sr_dictionaryRepresentation
{
  id v3 = [(SRAudioLevel *)[(SRSpeechMetrics *)self audioLevel] sr_dictionaryRepresentation];
  id v4 = [(SFSpeechRecognitionResult *)[(SRSpeechMetrics *)self speechRecognition] sr_dictionaryRepresentation];
  id v5 = [(SNClassificationResult *)[(SRSpeechMetrics *)self soundClassification] sr_dictionaryRepresentation];
  id v6 = [(SRSpeechExpression *)[(SRSpeechMetrics *)self speechExpression] sr_dictionaryRepresentation];
  v16[0] = @"sessionIdentifier";
  v17[0] = [(SRSpeechMetrics *)self sessionIdentifier];
  v16[1] = @"sessionFlags";
  v17[1] = +[NSNumber numberWithUnsignedInteger:[(SRSpeechMetrics *)self sessionFlags]];
  v16[2] = @"timestamp";
  [(NSDate *)[(SRSpeechMetrics *)self timestamp] timeIntervalSinceReferenceDate];
  if (fabs(v7) == INFINITY) {
    CFStringRef v8 = @"INF";
  }
  else {
    CFStringRef v8 = +[NSString stringWithFormat:@"%f", *(void *)&v7];
  }
  v17[2] = v8;
  v16[3] = @"timeSinceAudioStart";
  [(SRSpeechMetrics *)self timeSinceAudioStart];
  if (fabs(v9) == INFINITY) {
    CFStringRef v10 = @"INF";
  }
  else {
    CFStringRef v10 = +[NSString stringWithFormat:@"%f", *(void *)&v9];
  }
  if (v3) {
    v11 = v3;
  }
  else {
    v11 = &__NSDictionary0__struct;
  }
  v17[3] = v10;
  v17[4] = v11;
  v16[4] = @"audioLevel";
  v16[5] = @"speechRecognition";
  if (v4) {
    v12 = v4;
  }
  else {
    v12 = &__NSDictionary0__struct;
  }
  if (v5) {
    v13 = v5;
  }
  else {
    v13 = &__NSDictionary0__struct;
  }
  v17[5] = v12;
  v17[6] = v13;
  v16[6] = @"soundClassification";
  v16[7] = @"speechExpression";
  if (v6) {
    v14 = v6;
  }
  else {
    v14 = &__NSDictionary0__struct;
  }
  v17[7] = v14;
  return +[NSDictionary dictionaryWithObjects:v17 forKeys:v16 count:8];
}

@end