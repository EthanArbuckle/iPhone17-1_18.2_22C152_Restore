uint64_t ZinAddAneMultiPlaneUncompressedBindings(void *a1, uint64_t a2, void *a3, unsigned int a4, uint64_t a5, uint64_t a6)
{
  void *v6;
  uint64_t v8;
  void **v9;
  void **v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  unint64_t v14;
  uint64_t *v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  std::vector<std::string>::pointer begin;
  void **v22;
  std::string *v23;
  const char *v24;
  std::string *v25;
  BOOL v26;
  void *v27;
  void *v28;
  BOOL v29;
  void **v34;
  void *v35;
  std::vector<std::string> v37;
  std::string v38;
  int64x2_t v39;
  int v40;
  uint64_t v41;
  uint64_t v42;
  uint64_t v43;
  unsigned int v44[2];
  _DWORD v45[4];
  int32x2_t v46;
  unsigned int v47;
  uint64_t v48;
  _OWORD v49[16];
  uint64_t v50;

  v50 = *MEMORY[0x263EF8340];
  v6 = (void *)*a3;
  v35 = a3 + 1;
  if ((void *)*a3 == a3 + 1) {
    return 0;
  }
  v8 = a5;
  v9 = (void **)(a6 + 8);
  v34 = (void **)(a5 + 8);
  while (1)
  {
    bzero(v45, 0xD20uLL);
    v44[0] = 4;
    v44[1] = a4;
    v39 = *(int64x2_t *)(v6 + 7);
    v40 = *((_DWORD *)v6 + 18);
    v42 = 0;
    v43 = 0;
    v41 = 0;
    std::vector<ZinPlaneDescriptor>::__init_with_size[abi:ne180100]<ZinPlaneDescriptor*,ZinPlaneDescriptor*>(&v41, v6[10], v6[11], 0xEEEEEEEEEEEEEEEFLL * ((uint64_t)(v6[11] - v6[10]) >> 4));
    memset(&v38, 0, sizeof(v38));
    v10 = std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::find<std::string>(v8, (void **)v6 + 4);
    if (v34 == v10)
    {
      v26 = 1;
    }
    else
    {
      std::string::operator=(&v38, (const std::string *)(v10 + 7));
      v45[3] = v40;
      v46 = vmovn_s64(v39);
      v47 = -286331153 * ((v42 - v41) >> 4);
      memset(&v37, 0, sizeof(v37));
      std::vector<std::string>::resize(&v37, v47);
      memset(v49, 0, sizeof(v49));
      v12 = v41;
      v11 = v42;
      if (v42 != v41)
      {
        v13 = 0;
        v14 = 0;
        v15 = &v48;
        v16 = 232;
        do
        {
          v17 = *(void *)(v12 + v16 - 152);
          *(int32x4_t *)(v15 - 11) = vuzp1q_s32(*(int32x4_t *)(v12 + v16 - 184), *(int32x4_t *)(v12 + v16 - 168));
          *((_DWORD *)v15 - 18) = v17;
          v18 = *(void *)(v12 + v16 - 192);
          *(int32x4_t *)((char *)v15 - 68) = vuzp1q_s32(*(int32x4_t *)(v12 + v16 - 224), *(int32x4_t *)(v12 + v16 - 208));
          *((_DWORD *)v15 - 13) = v18;
          v19 = *(void *)(v12 + v16 - 112);
          *((_OWORD *)v15 - 3) = *(_OWORD *)(v12 + v16 - 144);
          *((_OWORD *)v15 - 2) = *(_OWORD *)(v12 + v16 - 128);
          *(v15 - 2) = v19;
          *((_DWORD *)v15 - 2) = *(void *)(v12 + v16 - 56);
          *v15 = *(void *)(v12 + v16);
          v20 = *(unsigned __int8 *)(v12 + v16 - 1);
          if ((v20 & 0x80u) != 0) {
            v20 = *(void *)(v12 + v16 - 16);
          }
          if (v20)
          {
            begin = v37.__begin_;
            v22 = std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::find<std::string>(a6, (void **)(v12 + v16 - 24));
            if (v9 == v22)
            {
              v26 = 1;
              goto LABEL_24;
            }
            std::string::operator=(&begin[v13], (const std::string *)(v22 + 7));
            v23 = &v37.__begin_[v13];
            if (SHIBYTE(v37.__begin_[v13].__r_.__value_.__r.__words[2]) < 0) {
              v23 = (std::string *)v23->__r_.__value_.__r.__words[0];
            }
            *((void *)v49 + v14) = v23;
            v12 = v41;
            v11 = v42;
          }
          else
          {
            *((void *)v49 + v14) = &byte_211F4AA5D;
          }
          ++v14;
          v16 += 240;
          ++v13;
          v15 += 13;
        }
        while (0xEEEEEEEEEEEEEEEFLL * ((v11 - v12) >> 4) > v14);
      }
      v24 = *(char *)(a2 + 23) >= 0 ? (const char *)a2 : *(const char **)a2;
      v25 = (v38.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0
          ? &v38
          : (std::string *)v38.__r_.__value_.__r.__words[0];
      v26 = ZinComputeMutableProgramAddAneMultiPlaneUncompressedBinding(a1, v44, v24, (const char *)v25, (const char **)v49, 0) != 0;
LABEL_24:
      v8 = a5;
      *(void *)&v49[0] = &v37;
      std::vector<std::string>::__destroy_vector::operator()[abi:ne180100]((void ***)v49);
    }
    if (SHIBYTE(v38.__r_.__value_.__r.__words[2]) < 0) {
      operator delete(v38.__r_.__value_.__l.__data_);
    }
    *(void *)&v49[0] = &v41;
    std::vector<ZinPlaneDescriptor>::__destroy_vector::operator()[abi:ne180100]((void ***)v49);
    if (v26) {
      return 1;
    }
    v27 = (void *)v6[1];
    if (v27)
    {
      do
      {
        v28 = v27;
        v27 = (void *)*v27;
      }
      while (v27);
    }
    else
    {
      do
      {
        v28 = (void *)v6[2];
        v29 = *v28 == (void)v6;
        v6 = v28;
      }
      while (!v29);
    }
    v6 = v28;
    if (v28 == v35) {
      return 0;
    }
  }
}

void sub_21125FBC0(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, char a17, uint64_t a18, uint64_t a19, void *__p,uint64_t a21,int a22,__int16 a23,char a24,char a25)
{
  STACK[0xDD0] = (unint64_t)&a17;
  std::vector<std::string>::__destroy_vector::operator()[abi:ne180100]((void ***)&STACK[0xDD0]);
  if (a25 < 0) {
    operator delete(__p);
  }
  STACK[0xDD0] = v25;
  std::vector<ZinPlaneDescriptor>::__destroy_vector::operator()[abi:ne180100]((void ***)&STACK[0xDD0]);
  _Unwind_Resume(a1);
}

uint64_t ZinAddAneCompressedBindings(void *a1, uint64_t a2, void *a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  uint64_t v106 = *MEMORY[0x263EF8340];
  v7 = a3 + 1;
  v6 = (void *)*a3;
  if ((void *)*a3 == a3 + 1) {
    return 0;
  }
  uint64_t v9 = a5;
  uint64_t v10 = a4;
  v11 = &v66;
  v60 = (void **)(a5 + 8);
  v12 = (void **)(a6 + 8);
  unsigned int v57 = a4;
  v56 = a3 + 1;
  while (v6[12] - v6[11] != 64)
  {
    v23 = v11;
    bzero(v11, 0xD20uLL);
    unsigned int v64 = 5;
    int v65 = v10;
    int v67 = *((_DWORD *)v6 + 20);
    int32x2_t v68 = vmovn_s64(*(int64x2_t *)(v6 + 7));
    unint64_t v24 = v6[12] - v6[11];
    unsigned int v69 = v24 >> 6;
    if (v69 >= 0x21) {
      return 3;
    }
    memset(&v63, 0, sizeof(v63));
    unint64_t v25 = std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::find<std::string>(v9, (void **)v6 + 4);
    if (v60 == v25)
    {
      BOOL v41 = 1;
    }
    else
    {
      std::string::operator=(&v63, (const std::string *)(v25 + 7));
      memset(&v62, 0, sizeof(v62));
      memset(&v61, 0, sizeof(v61));
      std::vector<std::string>::resize((std::vector<std::string> *)&v62, (v24 >> 6));
      std::vector<std::string>::resize(&v61, (v24 >> 6));
      long long v105 = 0u;
      long long v104 = 0u;
      long long v103 = 0u;
      long long v102 = 0u;
      long long v101 = 0u;
      long long v100 = 0u;
      long long v99 = 0u;
      long long v98 = 0u;
      long long v97 = 0u;
      long long v96 = 0u;
      long long v95 = 0u;
      long long v94 = 0u;
      long long v93 = 0u;
      long long v92 = 0u;
      *(_OWORD *)__p = 0u;
      long long v90 = 0u;
      long long v89 = 0u;
      long long v88 = 0u;
      long long v87 = 0u;
      long long v86 = 0u;
      long long v85 = 0u;
      long long v84 = 0u;
      long long v83 = 0u;
      long long v82 = 0u;
      long long v81 = 0u;
      long long v80 = 0u;
      long long v79 = 0u;
      long long v78 = 0u;
      long long v77 = 0u;
      long long v76 = 0u;
      memset(v75, 0, sizeof(v75));
      if ((v24 >> 6))
      {
        uint64_t v26 = 0;
        uint64_t v27 = 0;
        unint64_t v28 = 0;
        std::string::size_type v29 = v62.__r_.__value_.__r.__words[0];
        v30 = &v74;
        while (1)
        {
          uint64_t v31 = v6[11];
          *(v30 - 4) = 0;
          uint64_t v32 = *(void *)(v31 + v26 + 24);
          *(v30 - 3) = v32;
          *(v30 - 1) = v32;
          uint64_t *v30 = *(void *)(v31 + v26 + 56);
          v33 = std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::find<std::string>(a6, (void **)(v31 + v26));
          if (v12 == v33) {
            break;
          }
          std::string::operator=((std::string *)(v29 + v27 * 24), (const std::string *)(v33 + 7));
          v34 = (void **)(v31 + v26 + 32);
          std::vector<std::string>::pointer begin = v61.__begin_;
          v36 = std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::find<std::string>(a6, v34);
          if (v12 == v36) {
            break;
          }
          std::string::operator=(&begin[v27], (const std::string *)(v36 + 7));
          std::string::size_type v29 = v62.__r_.__value_.__r.__words[0];
          v37 = (void *)(v62.__r_.__value_.__r.__words[0] + v27 * 24);
          if (*(char *)(v62.__r_.__value_.__r.__words[0] + v27 * 24 + 23) < 0) {
            v37 = (void *)*v37;
          }
          __p[v28 - 2] = v37;
          v38 = &v61.__begin_[v27];
          if (SHIBYTE(v61.__begin_[v27].__r_.__value_.__r.__words[2]) < 0) {
            v38 = (std::string *)v38->__r_.__value_.__r.__words[0];
          }
          *(void *)&v75[8 * v28++] = v38;
          ++v27;
          v26 += 64;
          v30 += 6;
          if (v28 >= v69) {
            goto LABEL_32;
          }
        }
        BOOL v41 = 1;
      }
      else
      {
LABEL_32:
        v39 = *(char *)(a2 + 23) >= 0 ? (char *)a2 : *(char **)a2;
        v40 = (v63.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0
            ? &v63
            : (std::string *)v63.__r_.__value_.__r.__words[0];
        BOOL v41 = ZinComputeMutableProgramAddAneMultiPlaneCompressedBinding(a1, &v64, v39, (char *)v40, (const char **)&v90, (const char **)v75, 0) != 0;
      }
      uint64_t v9 = a5;
      v7 = v56;
      uint64_t v10 = v57;
      v11 = v23;
      *(void *)&long long v90 = &v61;
      std::vector<std::string>::__destroy_vector::operator()[abi:ne180100]((void ***)&v90);
      *(void *)&long long v90 = &v62;
      std::vector<std::string>::__destroy_vector::operator()[abi:ne180100]((void ***)&v90);
    }
    if (SHIBYTE(v63.__r_.__value_.__r.__words[2]) < 0) {
      operator delete(v63.__r_.__value_.__l.__data_);
    }
    if (v41) {
      return 3;
    }
LABEL_74:
    v51 = (void *)v6[1];
    if (v51)
    {
      do
      {
        v52 = v51;
        v51 = (void *)*v51;
      }
      while (v51);
    }
    else
    {
      do
      {
        v52 = (void *)v6[2];
        BOOL v53 = *v52 == (void)v6;
        v6 = v52;
      }
      while (!v53);
    }
    v6 = v52;
    if (v52 == v7) {
      return 0;
    }
  }
  ZinIr4CCInfo::ZinIr4CCInfo(&v90, *((unsigned int *)v6 + 20));
  if (ZinIr4CCInfo::IsMultiSlice((ZinIr4CCInfo *)&v90))
  {
    bzero(v11, 0xD20uLL);
    uint64_t v13 = v10;
    unsigned int v64 = 6;
    int v65 = v10;
    int v67 = *((_DWORD *)v6 + 20);
    int32x2_t v68 = vmovn_s64(*(int64x2_t *)(v6 + 7));
    unsigned int v69 = v6[9];
    uint64_t v14 = v6[11];
    uint64_t v71 = *(void *)(v14 + 24);
    uint64_t v73 = v71;
    uint64_t v74 = *(void *)(v14 + 56);
    memset(v75, 0, 24);
    memset(&v63, 0, sizeof(v63));
    memset(&v62, 0, sizeof(v62));
    v15 = std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::find<std::string>(v9, (void **)v6 + 4);
    if (v60 != v15)
    {
      std::string::operator=((std::string *)v75, (const std::string *)(v15 + 7));
      v16 = std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::find<std::string>(a6, (void **)v14);
      if (v12 != v16)
      {
        std::string::operator=(&v63, (const std::string *)(v16 + 7));
        v17 = std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::find<std::string>(a6, (void **)(v14 + 32));
        if (v12 != v17)
        {
          std::string::operator=(&v62, (const std::string *)(v17 + 7));
          if (*(char *)(a2 + 23) >= 0) {
            v18 = (const char *)a2;
          }
          else {
            v18 = *(const char **)a2;
          }
          if (v75[23] >= 0) {
            v19 = v75;
          }
          else {
            v19 = *(const char **)v75;
          }
          if ((v63.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
            v20 = &v63;
          }
          else {
            v20 = (std::string *)v63.__r_.__value_.__r.__words[0];
          }
          if ((v62.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
            v21 = &v62;
          }
          else {
            v21 = (std::string *)v62.__r_.__value_.__r.__words[0];
          }
          int v22 = ZinComputeMutableProgramAddAneSinglePlaneCompressedBinding(a1, &v64, v18, v19, (const char *)v20, (const char *)v21, 1, 0);
          goto LABEL_55;
        }
      }
    }
LABEL_60:
    int v50 = 3;
    goto LABEL_61;
  }
  bzero(v11, 0xD20uLL);
  uint64_t v13 = v10;
  unsigned int v64 = 1;
  int v65 = v10;
  int v67 = *((_DWORD *)v6 + 20);
  int32x2_t v68 = vmovn_s64(*(int64x2_t *)(v6 + 7));
  uint64_t v42 = v6[11];
  uint64_t v70 = *(void *)(v42 + 24);
  uint64_t v72 = v70;
  uint64_t v73 = *(void *)(v42 + 56);
  memset(v75, 0, 24);
  memset(&v63, 0, sizeof(v63));
  memset(&v62, 0, sizeof(v62));
  v43 = std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::find<std::string>(v9, (void **)v6 + 4);
  if (v60 == v43) {
    goto LABEL_60;
  }
  std::string::operator=((std::string *)v75, (const std::string *)(v43 + 7));
  v44 = std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::find<std::string>(a6, (void **)v42);
  if (v12 == v44) {
    goto LABEL_60;
  }
  std::string::operator=(&v63, (const std::string *)(v44 + 7));
  v45 = std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::find<std::string>(a6, (void **)(v42 + 32));
  if (v12 == v45) {
    goto LABEL_60;
  }
  std::string::operator=(&v62, (const std::string *)(v45 + 7));
  if (*(char *)(a2 + 23) >= 0) {
    v46 = (const char *)a2;
  }
  else {
    v46 = *(const char **)a2;
  }
  if (v75[23] >= 0) {
    v47 = v75;
  }
  else {
    v47 = *(const char **)v75;
  }
  if ((v63.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
    v48 = &v63;
  }
  else {
    v48 = (std::string *)v63.__r_.__value_.__r.__words[0];
  }
  if ((v62.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
    v49 = &v62;
  }
  else {
    v49 = (std::string *)v62.__r_.__value_.__r.__words[0];
  }
  int v22 = ZinComputeMutableProgramAddAneSinglePlaneCompressedBinding(a1, &v64, v46, v47, (const char *)v48, (const char *)v49, 0, 0);
LABEL_55:
  if (v22) {
    int v50 = 3;
  }
  else {
    int v50 = 0;
  }
  if (SHIBYTE(v62.__r_.__value_.__r.__words[2]) < 0) {
    operator delete(v62.__r_.__value_.__l.__data_);
  }
LABEL_61:
  uint64_t v10 = v13;
  if (SHIBYTE(v63.__r_.__value_.__r.__words[2]) < 0) {
    operator delete(v63.__r_.__value_.__l.__data_);
  }
  if ((v75[23] & 0x80000000) != 0) {
    operator delete(*(void **)v75);
  }
  if (!v50)
  {
    if (__p[0])
    {
      __p[1] = __p[0];
      operator delete(__p[0]);
    }
    goto LABEL_74;
  }
  if (__p[0])
  {
    __p[1] = __p[0];
    operator delete(__p[0]);
  }
  return 3;
}

void sub_211260290(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, char a17, uint64_t a18, uint64_t a19, void *a20,uint64_t a21,uint64_t a22,void *__p,uint64_t a24,int a25,__int16 a26,char a27,char a28)
{
  STACK[0xEB0] = (unint64_t)&a17;
  std::vector<std::string>::__destroy_vector::operator()[abi:ne180100]((void ***)&STACK[0xEB0]);
  STACK[0xEB0] = (unint64_t)&a20;
  std::vector<std::string>::__destroy_vector::operator()[abi:ne180100]((void ***)&STACK[0xEB0]);
  if (a28 < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(a1);
}

void *std::vector<ZinPlaneDescriptor>::__init_with_size[abi:ne180100]<ZinPlaneDescriptor*,ZinPlaneDescriptor*>(void *result, uint64_t a2, uint64_t a3, unint64_t a4)
{
  if (a4)
  {
    v6 = result;
    std::vector<ZinPlaneDescriptor>::__vallocate[abi:ne180100](result, a4);
    result = (void *)std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<ZinPlaneDescriptor>,ZinPlaneDescriptor*,ZinPlaneDescriptor*,ZinPlaneDescriptor*>((uint64_t)(v6 + 2), a2, a3, v6[1]);
    v6[1] = result;
  }
  return result;
}

void sub_21126039C(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, void **a9)
{
  *(void *)(v9 + 8) = v10;
  std::vector<ZinPlaneDescriptor>::__destroy_vector::operator()[abi:ne180100](&a9);
  _Unwind_Resume(a1);
}

char *std::vector<ZinPlaneDescriptor>::__vallocate[abi:ne180100](void *a1, unint64_t a2)
{
  if (a2 >= 0x111111111111112) {
    std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
  }
  result = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ZinPlaneDescriptor>>((uint64_t)(a1 + 2), a2);
  *a1 = result;
  a1[1] = result;
  a1[2] = &result[240 * v4];
  return result;
}

uint64_t std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<ZinPlaneDescriptor>,ZinPlaneDescriptor*,ZinPlaneDescriptor*,ZinPlaneDescriptor*>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v4 = a4;
  uint64_t v10 = a4;
  uint64_t v11 = a4;
  v8[0] = a1;
  v8[1] = &v10;
  v8[2] = &v11;
  char v9 = 0;
  if (a2 != a3)
  {
    uint64_t v6 = a2;
    do
    {
      std::construct_at[abi:ne180100]<ZinPlaneDescriptor,ZinPlaneDescriptor&,ZinPlaneDescriptor*>(v4, v6);
      v6 += 240;
      uint64_t v4 = v11 + 240;
      v11 += 240;
    }
    while (v6 != a3);
  }
  char v9 = 1;
  std::__exception_guard_exceptions<std::_AllocatorDestroyRangeReverse<std::allocator<ZinPlaneDescriptor>,ZinPlaneDescriptor*>>::~__exception_guard_exceptions[abi:ne180100]((uint64_t)v8);
  return v4;
}

void sub_2112604A0(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
}

uint64_t std::construct_at[abi:ne180100]<ZinPlaneDescriptor,ZinPlaneDescriptor&,ZinPlaneDescriptor*>(uint64_t a1, uint64_t a2)
{
  *(_OWORD *)a1 = *(_OWORD *)a2;
  long long v4 = *(_OWORD *)(a2 + 16);
  long long v5 = *(_OWORD *)(a2 + 32);
  long long v6 = *(_OWORD *)(a2 + 64);
  *(_OWORD *)(a1 + 48) = *(_OWORD *)(a2 + 48);
  *(_OWORD *)(a1 + 64) = v6;
  *(_OWORD *)(a1 + 16) = v4;
  *(_OWORD *)(a1 + 32) = v5;
  long long v7 = *(_OWORD *)(a2 + 80);
  long long v8 = *(_OWORD *)(a2 + 96);
  long long v9 = *(_OWORD *)(a2 + 128);
  *(_OWORD *)(a1 + 112) = *(_OWORD *)(a2 + 112);
  *(_OWORD *)(a1 + 128) = v9;
  *(_OWORD *)(a1 + 80) = v7;
  *(_OWORD *)(a1 + 96) = v8;
  long long v10 = *(_OWORD *)(a2 + 144);
  long long v11 = *(_OWORD *)(a2 + 160);
  long long v12 = *(_OWORD *)(a2 + 192);
  *(_OWORD *)(a1 + 176) = *(_OWORD *)(a2 + 176);
  *(_OWORD *)(a1 + 192) = v12;
  *(_OWORD *)(a1 + 144) = v10;
  *(_OWORD *)(a1 + 160) = v11;
  uint64_t v13 = (std::string *)(a1 + 208);
  if (*(char *)(a2 + 231) < 0)
  {
    std::string::__init_copy_ctor_external(v13, *(const std::string::value_type **)(a2 + 208), *(void *)(a2 + 216));
  }
  else
  {
    long long v14 = *(_OWORD *)(a2 + 208);
    v13->__r_.__value_.__r.__words[2] = *(void *)(a2 + 224);
    *(_OWORD *)&v13->__r_.__value_.__l.__data_ = v14;
  }
  *(void *)(a1 + 232) = *(void *)(a2 + 232);
  return a1;
}

uint64_t std::__exception_guard_exceptions<std::_AllocatorDestroyRangeReverse<std::allocator<ZinPlaneDescriptor>,ZinPlaneDescriptor*>>::~__exception_guard_exceptions[abi:ne180100](uint64_t a1)
{
  if (!*(unsigned char *)(a1 + 24)) {
    std::_AllocatorDestroyRangeReverse<std::allocator<ZinPlaneDescriptor>,ZinPlaneDescriptor*>::operator()[abi:ne180100](a1);
  }
  return a1;
}

void std::_AllocatorDestroyRangeReverse<std::allocator<ZinPlaneDescriptor>,ZinPlaneDescriptor*>::operator()[abi:ne180100](uint64_t a1)
{
  uint64_t v1 = **(void **)(a1 + 16);
  uint64_t v2 = **(void **)(a1 + 8);
  while (v1 != v2)
  {
    if (*(char *)(v1 - 9) < 0) {
      operator delete(*(void **)(v1 - 32));
    }
    v1 -= 240;
  }
}

uint64_t *std::map<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>::map[abi:ne180100](uint64_t *a1, uint64_t a2)
{
  a1[2] = 0;
  a1[1] = 0;
  *a1 = (uint64_t)(a1 + 1);
  std::map<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>::insert[abi:ne180100]<std::__map_const_iterator<std::__tree_const_iterator<std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>,std::__tree_node<std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>,void *> *,long>>>(a1, *(void ***)a2, (void **)(a2 + 8));
  return a1;
}

void sub_211260608(_Unwind_Exception *a1)
{
  std::__tree<std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>,std::__map_value_compare<std::string,std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>>>::destroy(v1, *(void **)(v1 + 8));
  _Unwind_Resume(a1);
}

uint64_t *std::map<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>::insert[abi:ne180100]<std::__map_const_iterator<std::__tree_const_iterator<std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>,std::__tree_node<std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>,void *> *,long>>>(uint64_t *result, void **a2, void **a3)
{
  if (a2 != a3)
  {
    long long v4 = a2;
    long long v5 = (uint64_t **)result;
    uint64_t v6 = (uint64_t)(result + 1);
    do
    {
      result = std::__tree<std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>,std::__map_value_compare<std::string,std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>>>::__emplace_hint_unique_key_args<std::string,std::pair<std::string const,std::pair<IOType,std::vector<ZinIrTensor *>>> const&>(v5, v6, v4 + 4, (long long *)v4 + 2);
      long long v7 = (void **)v4[1];
      if (v7)
      {
        do
        {
          long long v8 = v7;
          long long v7 = (void **)*v7;
        }
        while (v7);
      }
      else
      {
        do
        {
          long long v8 = (void **)v4[2];
          BOOL v9 = *v8 == v4;
          long long v4 = v8;
        }
        while (!v9);
      }
      long long v4 = v8;
    }
    while (v8 != a3);
  }
  return result;
}

uint64_t *std::__tree<std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>,std::__map_value_compare<std::string,std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>>>::__emplace_hint_unique_key_args<std::string,std::pair<std::string const,std::pair<IOType,std::vector<ZinIrTensor *>>> const&>(uint64_t **a1, uint64_t a2, void **a3, long long *a4)
{
  uint64_t v6 = std::__tree<std::__value_type<std::string,SpatialSplitMode>,std::__map_value_compare<std::string,std::__value_type<std::string,SpatialSplitMode>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,SpatialSplitMode>>>::__find_equal<std::string>(a1, a2, &v12, &v11, a3);
  long long v7 = (uint64_t *)*v6;
  if (!*v6)
  {
    long long v8 = (uint64_t **)v6;
    std::__tree<std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>,std::__map_value_compare<std::string,std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>>>::__construct_node<std::pair<std::string const,std::pair<IOType,std::vector<ZinIrTensor *>>> const&>((uint64_t)a1, a4, (uint64_t)v10);
    std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::__insert_node_at(a1, (uint64_t)v12, v8, v10[0]);
    long long v7 = v10[0];
    v10[0] = 0;
    std::unique_ptr<std::__tree_node<std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>,void *>,std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>,void *>>>>::reset[abi:ne180100]((uint64_t)v10, 0);
  }
  return v7;
}

std::string *std::__tree<std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>,std::__map_value_compare<std::string,std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>>>::__construct_node<std::pair<std::string const,std::pair<IOType,std::vector<ZinIrTensor *>>> const&>@<X0>(uint64_t a1@<X0>, long long *a2@<X1>, uint64_t a3@<X8>)
{
  uint64_t v5 = a1 + 8;
  uint64_t v6 = (char *)operator new(0x58uLL);
  *(void *)a3 = v6;
  *(void *)(a3 + 8) = v5;
  *(unsigned char *)(a3 + 16) = 0;
  result = std::pair<std::string const,std::pair<IOType,std::vector<ZinIrTensor *>>>::pair[abi:ne180100]((std::string *)(v6 + 32), a2);
  *(unsigned char *)(a3 + 16) = 1;
  return result;
}

void sub_211260798(_Unwind_Exception *a1)
{
  std::unique_ptr<std::__tree_node<std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>,void *>,std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>,void *>>>>::reset[abi:ne180100](v1, 0);
  _Unwind_Resume(a1);
}

void std::unique_ptr<std::__tree_node<std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>,void *>,std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>,void *>>>>::reset[abi:ne180100](uint64_t a1, uint64_t a2)
{
  uint64_t v2 = *(void **)a1;
  *(void *)a1 = a2;
  if (v2)
  {
    if (*(unsigned char *)(a1 + 16)) {
      std::__destroy_at[abi:ne180100]<std::pair<std::string const,ZinPattern::MapEntry>,0>((uint64_t)v2 + 32);
    }
    operator delete(v2);
  }
}

void ZinObjectGeneration::AddBaseTypes(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void ZinObjectGeneration::AddTensorDebugInfo(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void ZinObjectGenerationLegacy::CreateFVMLIB(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void ZinObjectGeneration::BuildComputeProgram(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "Failed in call to ZinComputeMutableProgramAddSectionSymbol\n", a5, a6, a7, a8, 0);
}

void ZinObjectGenerationLegacy::BuildComputeProgram(uint8_t *buf, unsigned char *a2)
{
  *buf = 0;
  *a2 = 0;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "AddLiveIOFVMLIB failed.", buf, 2u);
}

void ZinObjectGenerationRT::BuildComputeProgram(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "Error: Failed to add __RUNTIME segment", a5, a6, a7, a8, 0);
}

void ZinObjectGenerationLegacy::Generate(int a1)
{
  uint64_t v2 = *MEMORY[0x263EF8340];
  v1[0] = 67109120;
  v1[1] = a1;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "Error: Failed to write operation (%d) to compute program.\n", (uint8_t *)v1, 8u);
}

void ZinObjectGenHandleProgramToFile(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void ZinObjectGenWriteSymbolData(uint64_t a1)
{
  uint64_t v5 = *MEMORY[0x263EF8340];
  int v1 = 134218240;
  uint64_t v2 = a1;
  __int16 v3 = 2048;
  uint64_t v4 = 1;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "ZinObjectGenWriteSymbolData: wrote %zd items, expected %zd items", (uint8_t *)&v1, 0x16u);
}

uint64_t ZinMirSetKernelSize(ZinIrControlFlowGraph *a1, unsigned int a2, ZinIrNetworkStatus *a3)
{
  v6[4] = *MEMORY[0x263EF8340];
  uint64_t v5 = a3;
  v6[0] = &unk_26C32D078;
  v6[1] = a2;
  v6[2] = &v5;
  v6[3] = v6;
  uint64_t v3 = ZinIrControlFlowGraph::TraverseForward(a1, (uint64_t)v6, 1);
  std::__function::__value_func<ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::~__value_func[abi:ne180100](v6);
  return v3;
}

void sub_211260CA4(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::__function::__value_func<ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::~__value_func[abi:ne180100]((uint64_t *)va);
  _Unwind_Resume(a1);
}

void ZinMirGetCompressedKernelOcgSize(uint64_t a1, uint64_t a2, uint64_t a3, int a4)
{
  uint64_t v8 = *(unsigned int *)((*(uint64_t (**)(void, void, void))(***(void ***)(a1 + 88) + 32))(**(void **)(a1 + 88), 0, 0)+ 88);

  ZinMirGetCompressedKernelOcgSize((uint64_t **)a1, a2, a3, v8, a4);
}

void ZinMirGetCompressedKernelOcgSize(uint64_t **a1, uint64_t a2, uint64_t a3, uint64_t a4, int a5)
{
  Hal = ZinIrTarget::GetHal(a1[2], (ZinIrTarget *)a1[2][20]);
  (*(void (**)(uint64_t *))(*Hal + 16))(Hal);
  ((void (*)(ZinIrKernel **__return_ptr, uint64_t **, void))(*a1)[71])(&v8, a1, 0);
  ZinIrKernel::SetSmallSourceMode((uint64_t)v8, a5);
  operator new();
}

void sub_211260FCC(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, ...)
{
  va_start(va, a8);
  std::unique_ptr<ZinIrKernel>::reset[abi:ne180100]((ZinIrKernel **)va, 0);
  (*(void (**)(uint64_t))(*(void *)v8 + 8))(v8);
  _Unwind_Resume(a1);
}

void std::__function::__func<ZinMirSetKernelSize(ZinIrControlFlowGraph *,BOOL,ZinIrNetworkStatus *)::$_0,std::allocator<ZinMirSetKernelSize(ZinIrControlFlowGraph *,BOOL,ZinIrNetworkStatus *)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::~__func()
{
}

__n128 std::__function::__func<ZinMirSetKernelSize(ZinIrControlFlowGraph *,BOOL,ZinIrNetworkStatus *)::$_0,std::allocator<ZinMirSetKernelSize(ZinIrControlFlowGraph *,BOOL,ZinIrNetworkStatus *)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::__clone(uint64_t a1)
{
  uint64_t v2 = (char *)operator new(0x18uLL);
  *(void *)uint64_t v2 = &unk_26C32D078;
  __n128 result = *(__n128 *)(a1 + 8);
  *(__n128 *)(v2 + 8) = result;
  return result;
}

__n128 std::__function::__func<ZinMirSetKernelSize(ZinIrControlFlowGraph *,BOOL,ZinIrNetworkStatus *)::$_0,std::allocator<ZinMirSetKernelSize(ZinIrControlFlowGraph *,BOOL,ZinIrNetworkStatus *)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::__clone(uint64_t a1, uint64_t a2)
{
  *(void *)a2 = &unk_26C32D078;
  __n128 result = *(__n128 *)(a1 + 8);
  *(__n128 *)(a2 + 8) = result;
  return result;
}

uint64_t std::__function::__func<ZinMirSetKernelSize(ZinIrControlFlowGraph *,BOOL,ZinIrNetworkStatus *)::$_0,std::allocator<ZinMirSetKernelSize(ZinIrControlFlowGraph *,BOOL,ZinIrNetworkStatus *)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::operator()(uint64_t a1, uint64_t a2, ZinIrOpLayer **a3)
{
  uint64_t v4 = *a3;
  uint64_t result = ZinIrOpLayer::IsNELayer(*a3);
  if (result)
  {
    char v6 = *(unsigned char *)(a1 + 8);
    long long v7 = **(ZinIrNetworkStatus ***)(a1 + 16);
    return ZinNELayer::LowerKernel(v4, v6, v7);
  }
  return result;
}

uint64_t std::__function::__func<ZinMirSetKernelSize(ZinIrControlFlowGraph *,BOOL,ZinIrNetworkStatus *)::$_0,std::allocator<ZinMirSetKernelSize(ZinIrControlFlowGraph *,BOOL,ZinIrNetworkStatus *)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::target(uint64_t a1, uint64_t a2)
{
  {
    return a1 + 8;
  }
  else
  {
    return 0;
  }
}

void *std::__function::__func<ZinMirSetKernelSize(ZinIrControlFlowGraph *,BOOL,ZinIrNetworkStatus *)::$_0,std::allocator<ZinMirSetKernelSize(ZinIrControlFlowGraph *,BOOL,ZinIrNetworkStatus *)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::target_type()
{
}

ZinMirGraphSplitterBase *ZinMirSpatialSplitter::ZinMirSpatialSplitter(ZinMirGraphSplitterBase *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, int a7, uint64_t a8, uint64_t *a9, uint64_t *a10)
{
  uint64_t v55 = a6;
  int v56 = a7;
  uint64_t v14 = ZinMirGraphSplitterBase::ZinMirGraphSplitterBase((uint64_t)a1, a2, a3, &v55, a8);
  *(void *)uint64_t v14 = &unk_26C34EC30;
  *(unsigned char *)(v14 + 56) = 0;
  *(void *)(v14 + 64) = 0x3F947AE147AE147BLL;
  *(void *)(v14 + 72) = 3;
  *(_OWORD *)(v14 + 80) = xmmword_211EFF120;
  *(void *)(v14 + 96) = 0x3FD999999999999ALL;
  *(void *)(v14 + 104) = 0;
  *(unsigned char *)(v14 + 128) = 0;
  *(void *)(v14 + 112) = 0;
  *(void *)(v14 + 120) = a4;
  *(unsigned char *)(v14 + 168) = 0;
  *(void *)(v14 + 176) = a5;
  uint64_t v15 = *a9;
  *a9 = 0;
  *(void *)(v14 + 184) = v15;
  uint64_t v16 = *a10;
  *a10 = 0;
  *(void *)(v14 + 192) = v16;
  v17 = (uint64_t *)(v14 + 200);
  v18 = (uint64_t *)(v14 + 616);
  uint64_t v19 = MEMORY[0x263F8C310] + 64;
  *(void *)(v14 + 616) = MEMORY[0x263F8C310] + 64;
  uint64_t v20 = v14 + 208;
  uint64_t v21 = *(void *)(MEMORY[0x263F8C2B0] + 16);
  uint64_t v22 = *(void *)(MEMORY[0x263F8C2B0] + 8);
  *(void *)(v14 + 200) = v22;
  *(uint64_t *)((char *)v17 + *(void *)(v22 - 24)) = v21;
  v23 = (std::ios_base *)(v14 + 200 + *(void *)(*((void *)a1 + 25) - 24));
  std::ios_base::init(v23, (void *)(v14 + 208));
  uint64_t v24 = MEMORY[0x263F8C310] + 24;
  v23[1].__vftable = 0;
  v23[1].__fmtflags_ = -1;
  uint64_t *v17 = v24;
  uint64_t *v18 = v19;
  MEMORY[0x21667CDD0](v20);
  if (ZinMirGraphSplitterBase::SetNextTileId(a1)) {
    ZinAssertImpl("Spatial Split Internal Error");
  }
  ZinIrCompilerParameters::ZinIrCompilerParameters(&v52, *(const ZinIrCompilerParameters **)(a3 + 8));
  if (SHIBYTE(v53.__r_.__value_.__r.__words[2]) < 0) {
    std::string::__init_copy_ctor_external(&v51, v53.__r_.__value_.__l.__data_, v53.__r_.__value_.__l.__size_);
  }
  else {
    std::string v51 = v53;
  }
  uint64_t v25 = *((void *)a1 + 2);
  if (*(char *)(v25 + 39) < 0) {
    std::string::__init_copy_ctor_external(&v50, *(const std::string::value_type **)(v25 + 16), *(void *)(v25 + 24));
  }
  else {
    std::string v50 = *(std::string *)(v25 + 16);
  }
  if ((v54 & 4) != 0)
  {
    if ((v51.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
      std::string::size_type size = HIBYTE(v51.__r_.__value_.__r.__words[2]);
    }
    else {
      std::string::size_type size = v51.__r_.__value_.__l.__size_;
    }
    uint64_t v27 = &v44;
    std::string::basic_string[abi:ne180100]((uint64_t)&v44, size + 10);
    if ((v44.__r_.__value_.__r.__words[2] & 0x8000000000000000) != 0) {
      uint64_t v27 = (std::string *)v44.__r_.__value_.__r.__words[0];
    }
    if (size)
    {
      if ((v51.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
        unint64_t v28 = &v51;
      }
      else {
        unint64_t v28 = (std::string *)v51.__r_.__value_.__r.__words[0];
      }
      memmove(v27, v28, size);
    }
    strcpy((char *)v27 + size, ".SS_debug.");
    std::string::basic_string[abi:ne180100]<0>(__p, &byte_211F4AA5D);
    if ((v43 & 0x80u) == 0) {
      std::string::size_type v29 = __p;
    }
    else {
      std::string::size_type v29 = (void **)__p[0];
    }
    if ((v43 & 0x80u) == 0) {
      std::string::size_type v30 = v43;
    }
    else {
      std::string::size_type v30 = (std::string::size_type)__p[1];
    }
    uint64_t v31 = std::string::append(&v44, (const std::string::value_type *)v29, v30);
    long long v32 = *(_OWORD *)&v31->__r_.__value_.__l.__data_;
    v45.__r_.__value_.__r.__words[2] = v31->__r_.__value_.__r.__words[2];
    *(_OWORD *)&v45.__r_.__value_.__l.__data_ = v32;
    v31->__r_.__value_.__l.__size_ = 0;
    v31->__r_.__value_.__r.__words[2] = 0;
    v31->__r_.__value_.__r.__words[0] = 0;
    v33 = std::string::append(&v45, ".", 1uLL);
    long long v34 = *(_OWORD *)&v33->__r_.__value_.__l.__data_;
    v46.__r_.__value_.__r.__words[2] = v33->__r_.__value_.__r.__words[2];
    *(_OWORD *)&v46.__r_.__value_.__l.__data_ = v34;
    v33->__r_.__value_.__l.__size_ = 0;
    v33->__r_.__value_.__r.__words[2] = 0;
    v33->__r_.__value_.__r.__words[0] = 0;
    if ((v50.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
      v35 = &v50;
    }
    else {
      v35 = (std::string *)v50.__r_.__value_.__r.__words[0];
    }
    if ((v50.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
      std::string::size_type v36 = HIBYTE(v50.__r_.__value_.__r.__words[2]);
    }
    else {
      std::string::size_type v36 = v50.__r_.__value_.__l.__size_;
    }
    v37 = std::string::append(&v46, (const std::string::value_type *)v35, v36);
    long long v38 = *(_OWORD *)&v37->__r_.__value_.__l.__data_;
    v47.__r_.__value_.__r.__words[2] = v37->__r_.__value_.__r.__words[2];
    *(_OWORD *)&v47.__r_.__value_.__l.__data_ = v38;
    v37->__r_.__value_.__l.__size_ = 0;
    v37->__r_.__value_.__r.__words[2] = 0;
    v37->__r_.__value_.__r.__words[0] = 0;
    v39 = std::string::append(&v47, ".txt", 4uLL);
    long long v40 = *(_OWORD *)&v39->__r_.__value_.__l.__data_;
    std::string::size_type v49 = v39->__r_.__value_.__r.__words[2];
    *(_OWORD *)v48 = v40;
    v39->__r_.__value_.__l.__size_ = 0;
    v39->__r_.__value_.__r.__words[2] = 0;
    v39->__r_.__value_.__r.__words[0] = 0;
    if (SHIBYTE(v47.__r_.__value_.__r.__words[2]) < 0) {
      operator delete(v47.__r_.__value_.__l.__data_);
    }
    if (SHIBYTE(v46.__r_.__value_.__r.__words[2]) < 0) {
      operator delete(v46.__r_.__value_.__l.__data_);
    }
    if (SHIBYTE(v45.__r_.__value_.__r.__words[2]) < 0) {
      operator delete(v45.__r_.__value_.__l.__data_);
    }
    if ((char)v43 < 0) {
      operator delete(__p[0]);
    }
    if (SHIBYTE(v44.__r_.__value_.__r.__words[2]) < 0) {
      operator delete(v44.__r_.__value_.__l.__data_);
    }
    std::ofstream::open();
    if (SHIBYTE(v49) < 0) {
      operator delete(v48[0]);
    }
  }
  if (SHIBYTE(v50.__r_.__value_.__r.__words[2]) < 0) {
    operator delete(v50.__r_.__value_.__l.__data_);
  }
  if (SHIBYTE(v51.__r_.__value_.__r.__words[2]) < 0) {
    operator delete(v51.__r_.__value_.__l.__data_);
  }
  ZinIrCompilerParameters::~ZinIrCompilerParameters((ZinIrCompilerParameters *)&v52);
  return a1;
}

{
  return ZinMirSpatialSplitter::ZinMirSpatialSplitter(a1, a2, a3, a4, a5, a6, a7, a8, a9, a10);
}

void sub_211261600(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, void *a9, uint64_t a10, int a11, __int16 a12, char a13, char a14, uint64_t a15, uint64_t a16, int a17, __int16 a18, char a19, char a20,void *a21,uint64_t a22,int a23,__int16 a24,char a25,char a26,uint64_t a27,void *a28,uint64_t a29,int a30,__int16 a31,char a32,char a33,uint64_t a34,void *a35,uint64_t a36,int a37,__int16 a38,char a39,char a40,uint64_t a41,void *a42,uint64_t a43,int a44,__int16 a45,char a46,char a47,uint64_t a48,void *a49,uint64_t a50,int a51,__int16 a52,char a53,char a54,uint64_t a55,void *__p,uint64_t a57,int a58,__int16 a59,char a60,char a61,uint64_t a62,char a63)
{
  if (a61 < 0) {
    operator delete(__p);
  }
  ZinIrCompilerParameters::~ZinIrCompilerParameters((ZinIrCompilerParameters *)&a63);
  std::ofstream::~ofstream(v66);
  uint64_t v68 = *(void *)(v63 + 192);
  *(void *)(v63 + 192) = 0;
  if (v68) {
    (*(void (**)(uint64_t))(*(void *)v68 + 8))(v68);
  }
  std::unique_ptr<BatchOrChannelSplitPressureBasedSubgraphIdentification>::reset[abi:ne180100](v65, 0);
  if (*(unsigned char *)(v63 + 168)) {
    std::__hash_table<std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::__unordered_map_hasher<unsigned long,std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::hash<unsigned long>,std::equal_to<unsigned long>,true>,std::__unordered_map_equal<unsigned long,std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::equal_to<unsigned long>,std::hash<unsigned long>,true>,std::allocator<std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>>>::~__hash_table(v64);
  }
  ZinIrHalH13g::~ZinIrHalH13g((ZinIrHalH13g *)v63);
  _Unwind_Resume(a1);
}

void ZinMirSpatialSplitter::~ZinMirSpatialSplitter(ZinMirSpatialSplitter *this)
{
  *(void *)this = &unk_26C34EC30;
  ZinIrControlFlowGraph::UnsetScheduleMap(*((ZinIrControlFlowGraph **)this + 1));
  uint64_t v2 = (void *)((char *)this + 200);
  if (*((void *)this + 41) && !std::filebuf::close()) {
    std::ios_base::clear((std::ios_base *)((char *)v2 + *(void *)(*v2 - 24)), *(_DWORD *)((char *)v2 + *(void *)(*v2 - 24) + 32) | 4);
  }
  uint64_t v3 = MEMORY[0x263F8C2B0];
  uint64_t v4 = *MEMORY[0x263F8C2B0];
  *((void *)this + 25) = *MEMORY[0x263F8C2B0];
  *(void *)((char *)v2 + *(void *)(v4 - 24)) = *(void *)(v3 + 24);
  MEMORY[0x21667CDE0]((char *)this + 208);
  std::ostream::~ostream();
  MEMORY[0x21667D2B0]((char *)this + 616);
  uint64_t v5 = *((void *)this + 24);
  *((void *)this + 24) = 0;
  if (v5) {
    (*(void (**)(uint64_t))(*(void *)v5 + 8))(v5);
  }
  std::unique_ptr<BatchOrChannelSplitPressureBasedSubgraphIdentification>::reset[abi:ne180100]((ZinMirSpatialSplitLatencyCostModel ***)this + 23, 0);
  if (*((unsigned char *)this + 168)) {
    std::__hash_table<std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::__unordered_map_hasher<unsigned long,std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::hash<unsigned long>,std::equal_to<unsigned long>,true>,std::__unordered_map_equal<unsigned long,std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::equal_to<unsigned long>,std::hash<unsigned long>,true>,std::allocator<std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>>>::~__hash_table((uint64_t)this + 128);
  }

  ZinIrHalH13g::~ZinIrHalH13g(this);
}

{
  uint64_t vars8;

  ZinMirSpatialSplitter::~ZinMirSpatialSplitter(this);

  JUMPOUT(0x21667D3C0);
}

uint64_t SpatialDimensionToZinIrDimension(int a1)
{
  if (a1) {
    return 4;
  }
  else {
    return 3;
  }
}

uint64_t ZinIrDimensionToSpatialDimension(int a1, int *a2)
{
  if (a1 == 4)
  {
    int v2 = 1;
    goto LABEL_5;
  }
  if (a1 == 3)
  {
    int v2 = 0;
LABEL_5:
    uint64_t result = 0;
    *a2 = v2;
    return result;
  }
  return 3;
}

void SplitInfo::GetSplitDimensions(SplitInfo *this@<X0>, char **a2@<X8>)
{
  uint64_t v4 = 0;
  *a2 = 0;
  a2[1] = 0;
  a2[2] = 0;
  if (*((void *)this + 13) >= 2uLL)
  {
    uint64_t v5 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ZinIrPaddingMode>>((uint64_t)(a2 + 2), 1uLL);
    char v6 = *a2;
    long long v7 = a2[1];
    BOOL v9 = &v5[4 * v8];
    *(_DWORD *)uint64_t v5 = 3;
    uint64_t v4 = v5 + 4;
    while (v7 != v6)
    {
      int v10 = *((_DWORD *)v7 - 1);
      v7 -= 4;
      *((_DWORD *)v5 - 1) = v10;
      v5 -= 4;
    }
    *a2 = v5;
    a2[1] = v4;
    a2[2] = v9;
    if (v6) {
      operator delete(v6);
    }
    a2[1] = v4;
  }
  if (*((void *)this + 14) >= 2uLL)
  {
    unint64_t v11 = (unint64_t)a2[2];
    if ((unint64_t)v4 >= v11)
    {
      uint64_t v13 = *a2;
      uint64_t v14 = (v4 - *a2) >> 2;
      unint64_t v15 = v14 + 1;
      if ((unint64_t)(v14 + 1) >> 62) {
        std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
      }
      uint64_t v16 = v11 - (void)v13;
      if (v16 >> 1 > v15) {
        unint64_t v15 = v16 >> 1;
      }
      if ((unint64_t)v16 >= 0x7FFFFFFFFFFFFFFCLL) {
        unint64_t v17 = 0x3FFFFFFFFFFFFFFFLL;
      }
      else {
        unint64_t v17 = v15;
      }
      if (v17)
      {
        v18 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ZinIrPaddingMode>>((uint64_t)(a2 + 2), v17);
        uint64_t v13 = *a2;
        uint64_t v4 = a2[1];
      }
      else
      {
        v18 = 0;
      }
      uint64_t v19 = &v18[4 * v14];
      uint64_t v20 = &v18[4 * v17];
      *(_DWORD *)uint64_t v19 = 4;
      long long v12 = v19 + 4;
      while (v4 != v13)
      {
        int v21 = *((_DWORD *)v4 - 1);
        v4 -= 4;
        *((_DWORD *)v19 - 1) = v21;
        v19 -= 4;
      }
      *a2 = v19;
      a2[1] = v12;
      a2[2] = v20;
      if (v13) {
        operator delete(v13);
      }
    }
    else
    {
      *(_DWORD *)uint64_t v4 = 4;
      long long v12 = v4 + 4;
    }
    a2[1] = v12;
    uint64_t v4 = v12;
  }
  if (*((void *)this + 15) >= 2uLL)
  {
    unint64_t v22 = (unint64_t)a2[2];
    if ((unint64_t)v4 >= v22)
    {
      uint64_t v24 = *a2;
      uint64_t v25 = (v4 - *a2) >> 2;
      unint64_t v26 = v25 + 1;
      if ((unint64_t)(v25 + 1) >> 62) {
        std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
      }
      uint64_t v27 = v22 - (void)v24;
      if (v27 >> 1 > v26) {
        unint64_t v26 = v27 >> 1;
      }
      if ((unint64_t)v27 >= 0x7FFFFFFFFFFFFFFCLL) {
        unint64_t v28 = 0x3FFFFFFFFFFFFFFFLL;
      }
      else {
        unint64_t v28 = v26;
      }
      if (v28)
      {
        std::string::size_type v29 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ZinIrPaddingMode>>((uint64_t)(a2 + 2), v28);
        uint64_t v24 = *a2;
        uint64_t v4 = a2[1];
      }
      else
      {
        std::string::size_type v29 = 0;
      }
      std::string::size_type v30 = &v29[4 * v25];
      uint64_t v31 = &v29[4 * v28];
      *(_DWORD *)std::string::size_type v30 = 0;
      v23 = v30 + 4;
      while (v4 != v24)
      {
        int v32 = *((_DWORD *)v4 - 1);
        v4 -= 4;
        *((_DWORD *)v30 - 1) = v32;
        v30 -= 4;
      }
      *a2 = v30;
      a2[1] = v23;
      a2[2] = v31;
      if (v24) {
        operator delete(v24);
      }
    }
    else
    {
      *(_DWORD *)uint64_t v4 = 0;
      v23 = v4 + 4;
    }
    a2[1] = v23;
  }
}

void sub_211261B98(_Unwind_Exception *exception_object)
{
  uint64_t v3 = *(void **)v1;
  if (*(void *)v1)
  {
    *(void *)(v1 + 8) = v3;
    operator delete(v3);
  }
  _Unwind_Resume(exception_object);
}

void *SplitInfo::GetTileCount(void *result, int a2)
{
  switch(a2)
  {
    case 0:
      int v2 = result + 15;
      goto LABEL_5;
    case 1:
    case 2:
    case 5:
      ZinAssertImpl("Spatial Splitting Error");
    case 3:
      int v2 = result + 13;
      goto LABEL_5;
    case 4:
      int v2 = result + 14;
LABEL_5:
      uint64_t result = (void *)*v2;
      break;
    default:
      return result;
  }
  return result;
}

uint64_t *LatencyInfo::SetLatency(uint64_t *result, ZinIrOpLayer *a2, int a3, double a4)
{
  uint64_t v5 = a2;
  if ((*((void *)a2 + 6) & 0x8000000000000000) != 0) {
    ZinAssertImpl("Invalid call on unscheduled layer");
  }
  switch(a3)
  {
    case 0:
      goto LABEL_7;
    case 1:
      result += 3;
      goto LABEL_7;
    case 2:
      result += 6;
      goto LABEL_7;
    case 3:
      result += 9;
      goto LABEL_7;
    case 4:
      result += 12;
LABEL_7:
      char v6 = &v5;
      uint64_t result = std::__tree<std::__value_type<ZinIrOpLayer const*,double>,std::__map_value_compare<ZinIrOpLayer const*,std::__value_type<ZinIrOpLayer const*,double>,ScheduleComparator,true>,std::allocator<std::__value_type<ZinIrOpLayer const*,double>>>::__emplace_unique_key_args<ZinIrOpLayer const*,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer const* const&>,std::tuple<>>((uint64_t **)result, &v5, (uint64_t)&std::piecewise_construct, (uint64_t **)&v6);
      *((double *)result + 5) = a4;
      break;
    default:
      return result;
  }
  return result;
}

uint64_t std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at(uint64_t a1, ZinIrOpLayer **a2)
{
  uint64_t v2 = *std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__find_equal<ZinIrOpLayer *>(a1, &v4, a2);
  if (!v2) {
    std::__throw_out_of_range[abi:ne180100]("map::at:  key not found");
  }
  return v2 + 40;
}

uint64_t ZinMirSpatialSplitter::TensorDimsToString@<X0>(const ZinTensorDimensions *a1@<X1>, void *a2@<X8>)
{
  unsigned int v3 = a1;
  std::basic_stringstream<char,std::char_traits<char>,std::allocator<char>>::basic_stringstream[abi:ne180100]((uint64_t)v13);
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v14, (uint64_t)"(", 1);
  uint64_t v5 = (void *)std::ostream::operator<<();
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v5, (uint64_t)"x", 1);
  char v6 = (void *)std::ostream::operator<<();
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v6, (uint64_t)"x", 1);
  long long v7 = (void *)std::ostream::operator<<();
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v7, (uint64_t)"x", 1);
  uint64_t v8 = (void *)std::ostream::operator<<();
  if (v3) {
    BOOL v9 = "f";
  }
  else {
    BOOL v9 = &byte_211F4AA5D;
  }
  int v10 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v8, (uint64_t)v9, v3);
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v10, (uint64_t)")", 1);
  std::stringbuf::str[abi:ne180100]<std::allocator<char>>((uint64_t)v15, a2);
  v13[0] = *MEMORY[0x263F8C2B8];
  uint64_t v11 = *(void *)(MEMORY[0x263F8C2B8] + 72);
  *(void *)((char *)v13 + *(void *)(v13[0] - 24)) = *(void *)(MEMORY[0x263F8C2B8] + 64);
  uint64_t v14 = v11;
  v15[0] = MEMORY[0x263F8C318] + 16;
  if (v16 < 0) {
    operator delete((void *)v15[8]);
  }
  std::streambuf::~streambuf();
  std::iostream::~basic_iostream();
  return MEMORY[0x21667D2B0](&v17);
}

void sub_211261F44(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
}

__n128 Padding::From@<Q0>(Padding *this@<X0>, __n128 *a2@<X8>)
{
  switch(*(_DWORD *)(*((void *)this + 8) + 8))
  {
    case 'S':
    case 'Y':
      uint64_t v3 = *(void *)(*((void *)this + 54) + 64);
      uint64_t v5 = *(void *)(v3 + 64);
      uint64_t v4 = *(void *)(v3 + 72);
      goto LABEL_6;
    case 'U':
      uint64_t v7 = *((void *)this + 54);
      if (!v7) {
        goto LABEL_3;
      }
      uint64_t v8 = *(void *)(v7 + 136);
      uint64_t v5 = *(void *)(v8 + 352);
      uint64_t v4 = *(void *)(v8 + 360);
LABEL_6:
      v9.n128_u64[0] = (int)v4;
      v9.n128_u64[1] = SHIDWORD(v4);
      __n128 result = v9;
      v9.n128_u64[0] = (int)v5;
      v9.n128_u64[1] = SHIDWORD(v5);
      *a2 = result;
      a2[1] = v9;
      break;
    default:
LABEL_3:
      result.n128_u64[0] = 0;
      *a2 = 0u;
      a2[1] = 0u;
      break;
  }
  return result;
}

uint64_t Padding::ToString@<X0>(Padding *this@<X0>, void *a2@<X8>)
{
  std::basic_stringstream<char,std::char_traits<char>,std::allocator<char>>::basic_stringstream[abi:ne180100]((uint64_t)v16);
  if (*(void *)this == *((void *)this + 1)
    && ((uint64_t v4 = *((void *)this + 2), *(void *)this == v4) ? (v5 = v4 == *((void *)this + 3)) : (v5 = 0), v5))
  {
    std::ostream::operator<<();
  }
  else
  {
    std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v17, (uint64_t)"{", 1);
    if (*(void *)this)
    {
      char v6 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v17, (uint64_t)&byte_211F4AA5D, 0);
      std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v6, (uint64_t)"t=", 2);
      std::ostream::operator<<();
      uint64_t v7 = ",";
    }
    else
    {
      uint64_t v7 = &byte_211F4AA5D;
    }
    if (*((void *)this + 1))
    {
      size_t v8 = strlen(v7);
      __n128 v9 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v17, (uint64_t)v7, v8);
      std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v9, (uint64_t)"b=", 2);
      std::ostream::operator<<();
      uint64_t v7 = ",";
    }
    if (*((void *)this + 2))
    {
      size_t v10 = strlen(v7);
      uint64_t v11 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v17, (uint64_t)v7, v10);
      std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v11, (uint64_t)"l=", 2);
      std::ostream::operator<<();
      uint64_t v7 = ",";
    }
    if (*((void *)this + 3))
    {
      size_t v12 = strlen(v7);
      uint64_t v13 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v17, (uint64_t)v7, v12);
      std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v13, (uint64_t)"r=", 2);
      std::ostream::operator<<();
    }
    std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v17, (uint64_t)"}", 1);
  }
  std::stringbuf::str[abi:ne180100]<std::allocator<char>>((uint64_t)v18, a2);
  v16[0] = *MEMORY[0x263F8C2B8];
  uint64_t v14 = *(void *)(MEMORY[0x263F8C2B8] + 72);
  *(void *)((char *)v16 + *(void *)(v16[0] - 24)) = *(void *)(MEMORY[0x263F8C2B8] + 64);
  uint64_t v17 = v14;
  v18[0] = MEMORY[0x263F8C318] + 16;
  if (v19 < 0) {
    operator delete((void *)v18[8]);
  }
  std::streambuf::~streambuf();
  std::iostream::~basic_iostream();
  return MEMORY[0x21667D2B0](&v20);
}

void sub_2112622D4(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
}

uint64_t ProducerConsumerChain::Extract(ProducerConsumerChain *this, unint64_t a2, unint64_t a3, ProducerConsumerChain *a4)
{
  uint64_t result = 3;
  if (a3 >= 2)
  {
    unint64_t v6 = a3;
    unint64_t v8 = a3 + a2;
    if (a3 + a2 <= (uint64_t)(*((void *)this + 2) - *((void *)this + 1)) >> 3)
    {
      size_t v10 = (void **)((char *)a4 + 8);
      *((void *)a4 + 2) = *((void *)a4 + 1);
      std::vector<ZinIrOpLayer *>::reserve((void **)a4 + 1, a3);
      std::__unwrap_and_dispatch[abi:ne180100]<std::__overload<std::__copy_loop<std::_ClassicAlgPolicy>,std::__copy_trivial>,std::__wrap_iter<ZinIrOpLayer * const*>,std::__wrap_iter<ZinIrOpLayer * const*>,std::back_insert_iterator<std::vector<ZinIrOpLayer *>>,0>((void *)(*((void *)this + 1) + 8 * a2), (void *)(*((void *)this + 1) + 8 * a2 + 8 * v6), v10);
      if (v8 > a2)
      {
        uint64_t v11 = (char *)a4 + 32;
        uint64_t v12 = 8 * a2;
        do
        {
          std::__hash_table<ZinIrTensor const*,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const* const&>((uint64_t)v11, (void *)(*((void *)this + 1) + v12), (void *)(*((void *)this + 1) + v12));
          v12 += 8;
          --v6;
        }
        while (v6);
      }
      return 0;
    }
  }
  return result;
}

uint64_t ProducerConsumerChain::ExtractAllSubChains(ProducerConsumerChain *this, uint64_t *a2)
{
  unint64_t v3 = (uint64_t)(*((void *)this + 2) - *((void *)this + 1)) >> 3;
  if (v3 != 1)
  {
    unint64_t v6 = 0;
    uint64_t v7 = (uint64_t)(*((void *)this + 2) - *((void *)this + 1)) >> 3;
    do
    {
      unint64_t v16 = v6 + 1;
      if (v6 + 1 < v3)
      {
        unint64_t v8 = 1;
        while (1)
        {
          if (++v8 >= v3)
          {
            uint64_t v12 = v2;
          }
          else
          {
            int v9 = *(_DWORD *)this;
            long long __p = 0u;
            memset(v19, 0, sizeof(v19));
            uint64_t v20 = 0;
            int v17 = v9;
            int v21 = 1065353216;
            uint64_t v10 = ProducerConsumerChain::Extract(this, v6, v8, (ProducerConsumerChain *)&v17);
            int v11 = v10;
            uint64_t v12 = v10;
            if (!v10)
            {
              unint64_t v13 = a2[1];
              if (v13 >= a2[2])
              {
                uint64_t v14 = std::vector<ProducerConsumerChain>::__push_back_slow_path<ProducerConsumerChain const&>(a2, (uint64_t)&v17);
              }
              else
              {
                std::construct_at[abi:ne180100]<ProducerConsumerChain,ProducerConsumerChain const&,ProducerConsumerChain*>(a2[1], (uint64_t)&v17);
                uint64_t v14 = v13 + 72;
                a2[1] = v13 + 72;
              }
              a2[1] = v14;
              uint64_t v12 = v2;
            }
            std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&v19[8]);
            if ((void)__p)
            {
              *((void *)&__p + 1) = __p;
              operator delete((void *)__p);
            }
            if (v11) {
              return v12;
            }
          }
          uint64_t v2 = v12;
          if (v7 == v8) {
            goto LABEL_18;
          }
        }
      }
      uint64_t v12 = v2;
LABEL_18:
      --v7;
      uint64_t v2 = v12;
      ++v6;
    }
    while (v16 != v3 - 1);
  }
  return 0;
}

void sub_211262518(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, ...)
{
  va_start(va, a4);
  *(void *)(v4 + 8) = v5;
  ProducerConsumerChain::~ProducerConsumerChain((ProducerConsumerChain *)va);
  _Unwind_Resume(a1);
}

void ProducerConsumerChain::~ProducerConsumerChain(ProducerConsumerChain *this)
{
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)this + 32);
  uint64_t v2 = (void *)*((void *)this + 1);
  if (v2)
  {
    *((void *)this + 2) = v2;
    operator delete(v2);
  }
}

uint64_t ProducerConsumerChain::GetLayerDesc@<X0>(ProducerConsumerChain *this@<X0>, unint64_t a2@<X1>, void *a3@<X8>)
{
  uint64_t v4 = *((void *)this + 1);
  if (a2 >= (*((void *)this + 2) - v4) >> 3) {
    std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
  }
  uint64_t v5 = *(void *)(v4 + 8 * a2);
  std::basic_stringstream<char,std::char_traits<char>,std::allocator<char>>::basic_stringstream[abi:ne180100]((uint64_t)v62);
  unint64_t v6 = "?";
  uint64_t v7 = 1;
  switch(*(_DWORD *)(*(void *)(v5 + 64) + 8))
  {
    case 'S':
      unint64_t v8 = *(int **)(*(void *)(v5 + 432) + 64);
      uint64_t v9 = v8[18];
      uint64_t v10 = v8[19];
      uint64_t v58 = v9;
      uint64_t v59 = v10;
      uint64_t v11 = v8[16];
      uint64_t v12 = v8[17];
      uint64_t v60 = v11;
      uint64_t v61 = v12;
      std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v63, (uint64_t)"P(k=", 4);
      unint64_t v13 = (void *)std::ostream::operator<<();
      std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v13, (uint64_t)"x", 1);
      uint64_t v14 = (void *)std::ostream::operator<<();
      std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v14, (uint64_t)",s=", 3);
      unint64_t v15 = (void *)std::ostream::operator<<();
      std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v15, (uint64_t)"x", 1);
      unint64_t v16 = (void *)std::ostream::operator<<();
      std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v16, (uint64_t)",e=", 3);
      int v17 = (void *)std::ostream::operator<<();
      std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v17, (uint64_t)",f=", 3);
      v18 = (void *)std::ostream::operator<<();
      std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v18, (uint64_t)",p=", 3);
      std::ostream::operator<<();
      if (v10 + v9 > 0 || v12 + v11 >= 1)
      {
        uint64_t v20 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v63, (uint64_t)",p=", 3);
        Padding::ToString((Padding *)&v58, &__p);
        int v21 = (v57 & 0x80u) == 0 ? &__p : (void **)__p;
        uint64_t v22 = (v57 & 0x80u) == 0 ? v57 : v56;
        std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v20, (uint64_t)v21, v22);
        if ((char)v57 < 0) {
          operator delete(__p);
        }
      }
      goto LABEL_45;
    case 'U':
      uint64_t v23 = *(void *)(v5 + 432);
      if (v23)
      {
        uint64_t v24 = *(void *)(v23 + 136);
        uint64_t v25 = *(int *)(v24 + 360);
        uint64_t v26 = *(int *)(v24 + 364);
        uint64_t v58 = v25;
        uint64_t v59 = v26;
        uint64_t v27 = *(int *)(v24 + 352);
        uint64_t v28 = *(int *)(v24 + 356);
        uint64_t v60 = v27;
        uint64_t v61 = v28;
        if ((*(unsigned char *)(v24 + 448) & 0x40) != 0) {
          std::string::size_type v29 = "D";
        }
        else {
          std::string::size_type v29 = "C";
        }
        std::string::size_type v30 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v63, (uint64_t)v29, 1);
        std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v30, (uint64_t)"(k=", 3);
        uint64_t v31 = (void *)std::ostream::operator<<();
        std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v31, (uint64_t)"x", 1);
        int v32 = (void *)std::ostream::operator<<();
        std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v32, (uint64_t)",s=", 3);
        v33 = (void *)std::ostream::operator<<();
        std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v33, (uint64_t)"x", 1);
        std::ostream::operator<<();
        if (v26 + v25 > 0 || v28 + v27 >= 1)
        {
          v35 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v63, (uint64_t)",p=", 3);
          Padding::ToString((Padding *)&v58, &__p);
          std::string::size_type v36 = (v57 & 0x80u) == 0 ? &__p : (void **)__p;
          uint64_t v37 = (v57 & 0x80u) == 0 ? v57 : v56;
          std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v35, (uint64_t)v36, v37);
          if ((char)v57 < 0) {
            operator delete(__p);
          }
        }
LABEL_45:
        std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v63, (uint64_t)")", 1);
      }
      else
      {
        std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v63, (uint64_t)"S", 1);
      }
      goto LABEL_50;
    case 'Y':
      long long v38 = *(int **)(*(void *)(v5 + 432) + 64);
      uint64_t v39 = v38[18];
      uint64_t v40 = v38[19];
      uint64_t v58 = v39;
      uint64_t v59 = v40;
      uint64_t v41 = v38[16];
      uint64_t v42 = v38[17];
      uint64_t v60 = v41;
      uint64_t v61 = v42;
      std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v63, (uint64_t)"P(k=", 4);
      unsigned __int8 v43 = (void *)std::ostream::operator<<();
      std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v43, (uint64_t)"x", 1);
      std::string v44 = (void *)std::ostream::operator<<();
      std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v44, (uint64_t)",s=", 3);
      std::string v45 = (void *)std::ostream::operator<<();
      std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v45, (uint64_t)"x", 1);
      std::string v46 = (void *)std::ostream::operator<<();
      std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v46, (uint64_t)",e=", 3);
      std::string v47 = (void *)std::ostream::operator<<();
      std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v47, (uint64_t)",f=", 3);
      v48 = (void *)std::ostream::operator<<();
      std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v48, (uint64_t)",p=", 3);
      std::ostream::operator<<();
      if (v40 + v39 > 0 || v42 + v41 >= 1)
      {
        std::string v50 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v63, (uint64_t)",p=", 3);
        Padding::ToString((Padding *)&v58, &__p);
        std::string v51 = (v57 & 0x80u) == 0 ? &__p : (void **)__p;
        uint64_t v52 = (v57 & 0x80u) == 0 ? v57 : v56;
        std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v50, (uint64_t)v51, v52);
        if ((char)v57 < 0) {
          operator delete(__p);
        }
      }
      goto LABEL_45;
    case 'Z':
      unint64_t v6 = "EW";
      goto LABEL_48;
    case '\\':
      unint64_t v6 = "BP";
LABEL_48:
      uint64_t v7 = 2;
      goto LABEL_49;
    default:
LABEL_49:
      std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v63, (uint64_t)v6, v7);
LABEL_50:
      std::stringbuf::str[abi:ne180100]<std::allocator<char>>((uint64_t)v64, a3);
      v62[0] = *MEMORY[0x263F8C2B8];
      uint64_t v53 = *(void *)(MEMORY[0x263F8C2B8] + 72);
      *(void *)((char *)v62 + *(void *)(v62[0] - 24)) = *(void *)(MEMORY[0x263F8C2B8] + 64);
      uint64_t v63 = v53;
      v64[0] = MEMORY[0x263F8C318] + 16;
      if (v65 < 0) {
        operator delete((void *)v64[8]);
      }
      std::streambuf::~streambuf();
      std::iostream::~basic_iostream();
      return MEMORY[0x21667D2B0](&v66);
  }
}

void sub_211262B50(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, void *__p, uint64_t a10, int a11, __int16 a12, char a13, char a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, char a19)
{
  if (a14 < 0) {
    operator delete(__p);
  }
  std::basic_stringstream<char,std::char_traits<char>,std::allocator<char>>::~basic_stringstream((uint64_t)&a19);
  _Unwind_Resume(a1);
}

uint64_t ProducerConsumerChain::ToString@<X0>(ProducerConsumerChain *this@<X0>, void *a2@<X8>)
{
  std::basic_stringstream<char,std::char_traits<char>,std::allocator<char>>::basic_stringstream[abi:ne180100]((uint64_t)v42);
  uint64_t v4 = (char *)this + 8;
  uint64_t v5 = **(void **)(**((void **)this + 1) + 88);
  uint64_t v6 = (*(uint64_t (**)(uint64_t, void, void))(*(void *)v5 + 32))(v5, 0, 0);
  uint64_t v9 = *(void *)(v6 + 24);
  uint64_t v7 = v6 + 24;
  uint64_t v8 = v9;
  int v10 = *(char *)(v7 + 23);
  if (v10 >= 0) {
    uint64_t v11 = v7;
  }
  else {
    uint64_t v11 = v8;
  }
  if (v10 >= 0) {
    uint64_t v12 = *(unsigned __int8 *)(v7 + 23);
  }
  else {
    uint64_t v12 = *(void *)(v7 + 8);
  }
  unint64_t v13 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v43, v11, v12);
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v13, (uint64_t)"(l=", 3);
  uint64_t v14 = (void *)std::ostream::operator<<();
  unint64_t v15 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v14, (uint64_t)"): ", 3);
  uint64_t v16 = **(void **)(**(void **)v4 + 88);
  (*(void (**)(uint64_t, void, void))(*(void *)v16 + 32))(v16, 0, 0);
  uint64_t v17 = **(void **)(**(void **)v4 + 88);
  BOOL v18 = *(_DWORD *)((*(uint64_t (**)(uint64_t, void, void))(*(void *)v17 + 32))(v17, 0, 0) + 88) == 3;
  ZinMirSpatialSplitter::TensorDimsToString((const ZinTensorDimensions *)v18, &__p);
  if ((v41 & 0x80u) == 0) {
    p_p = &__p;
  }
  else {
    p_p = __p;
  }
  if ((v41 & 0x80u) == 0) {
    uint64_t v20 = v41;
  }
  else {
    uint64_t v20 = v40;
  }
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v15, (uint64_t)p_p, v20);
  if ((char)v41 < 0) {
    operator delete(__p);
  }
  unint64_t v21 = 0;
  do
  {
    uint64_t v22 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v43, (uint64_t)"-> ", 3);
    ProducerConsumerChain::GetLayerDesc(this, v21, &__p);
    if ((v41 & 0x80u) == 0) {
      uint64_t v23 = &__p;
    }
    else {
      uint64_t v23 = __p;
    }
    if ((v41 & 0x80u) == 0) {
      uint64_t v24 = v41;
    }
    else {
      uint64_t v24 = v40;
    }
    uint64_t v25 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v22, (uint64_t)v23, v24);
    uint64_t v26 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v25, (uint64_t)"-> ", 3);
    uint64_t v27 = *((void *)this + 1);
    if (v21 >= (*((void *)this + 2) - v27) >> 3
      || (uint64_t v28 = v26,
          (*(void (**)(void, void, void))(**(void **)(v27 + 8 * v21) + 32))(*(void *)(v27 + 8 * v21), 0, 0), uint64_t v29 = *((void *)this + 1), v21 >= (*((void *)this + 2) - v29) >> 3))
    {
      std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
    }
    BOOL v30 = *(_DWORD *)((*(uint64_t (**)(void, void, void))(**(void **)(v29 + 8 * v21) + 32))(*(void *)(v29 + 8 * v21), 0, 0)+ 88) == 3;
    ZinMirSpatialSplitter::TensorDimsToString((const ZinTensorDimensions *)v30, v37);
    if ((v38 & 0x80u) == 0) {
      uint64_t v31 = v37;
    }
    else {
      uint64_t v31 = (void **)v37[0];
    }
    if ((v38 & 0x80u) == 0) {
      uint64_t v32 = v38;
    }
    else {
      uint64_t v32 = (uint64_t)v37[1];
    }
    std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v28, (uint64_t)v31, v32);
    if ((char)v38 < 0) {
      operator delete(v37[0]);
    }
    if ((char)v41 < 0) {
      operator delete(__p);
    }
  }
  while (v21++ < ((uint64_t)(*((void *)this + 2) - *((void *)this + 1)) >> 3) - 1);
  std::ios_base::getloc((const std::ios_base *)((char *)&v44[-1] + *(void *)(v43 - 24)));
  long long v34 = std::locale::use_facet((const std::locale *)&__p, MEMORY[0x263F8C108]);
  ((void (*)(const std::locale::facet *, uint64_t))v34->__vftable[2].~facet_0)(v34, 10);
  std::locale::~locale((std::locale *)&__p);
  std::ostream::put();
  std::ostream::flush();
  std::stringbuf::str[abi:ne180100]<std::allocator<char>>((uint64_t)v44, a2);
  v42[0] = *MEMORY[0x263F8C2B8];
  uint64_t v35 = *(void *)(MEMORY[0x263F8C2B8] + 72);
  *(void *)((char *)v42 + *(void *)(v42[0] - 24)) = *(void *)(MEMORY[0x263F8C2B8] + 64);
  uint64_t v43 = v35;
  v44[0] = MEMORY[0x263F8C318] + 16;
  if (v45 < 0) {
    operator delete((void *)v44[8]);
  }
  std::streambuf::~streambuf();
  std::iostream::~basic_iostream();
  return MEMORY[0x21667D2B0](&v46);
}

void sub_211263098(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, void *a9, uint64_t a10, int a11, __int16 a12, char a13, char a14, void *__p, uint64_t a16, int a17, __int16 a18, char a19, char a20,char a21)
{
  if (a20 < 0) {
    operator delete(__p);
  }
  std::basic_stringstream<char,std::char_traits<char>,std::allocator<char>>::~basic_stringstream((uint64_t)&a21);
  _Unwind_Resume(a1);
}

void ProducerConsumerChain::IsLayerAdmissible(ProducerConsumerChain *this@<X0>, const ZinIrOpLayer *a2@<X1>, const ZinIrHalParameters *a3@<X2>, void *a4@<X8>)
{
  memset(__p, 0, sizeof(__p));
  IsLayerSplittable<ProducerConsumerChain>(a2, (uint64_t)a3, *((unsigned char *)this + 1), 0, *(unsigned __int8 *)this, 0, (uint64_t)__p, (uint64_t)this, a4, 0);
  if (__p[0]) {
    operator delete(__p[0]);
  }
}

void sub_211263168(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

void IsLayerSplittable<ProducerConsumerChain>(ZinIrOpLayer *a1@<X0>, uint64_t a2@<X1>, char a3@<W2>, char a4@<W3>, int a5@<W4>, int a6@<W5>, uint64_t a7@<X6>, uint64_t a8@<X7>, void *a9@<X8>, SplitPatternHandlerMgr *a10)
{
  uint64_t v67 = *MEMORY[0x263EF8340];
  unint64_t v18 = (uint64_t)(*((void *)a1 + 12) - *((void *)a1 + 11)) >> 3;
  LOBYTE(v64) = 0;
  std::vector<BOOL>::vector(&v59, v18, (unsigned __int8 *)&v64);
  if (*(void *)a7)
  {
    operator delete(*(void **)a7);
    *(void *)a7 = 0;
    *(void *)(a7 + 8) = 0;
    *(void *)(a7 + 16) = 0;
  }
  *(void *)a7 = v59;
  *(_OWORD *)(a7 + 8) = v60;
  uint64_t v64 = 0x100000000;
  std::set<SpatialDimension>::set[abi:ne180100]((uint64_t)&v59, (unsigned int *)&v64, 2);
  char v65 = 0;
  uint64_t v66 = 0;
  uint64_t v64 = (uint64_t)&v65;
  if (*(void *)((*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)a1 + 32))(a1, 0, 0) + 64) == 1)
  {
    LODWORD(__p) = 0;
    std::__tree<SpatialDimension>::__erase_unique<SpatialDimension>((uint64_t)&v59, (unsigned int *)&__p);
  }
  if (*(void *)((*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)a1 + 32))(a1, 0, 0) + 72) == 1)
  {
    LODWORD(__p) = 1;
    std::__tree<SpatialDimension>::__erase_unique<SpatialDimension>((uint64_t)&v59, (unsigned int *)&__p);
  }
  if ((a4 & 1) != 0 || (__p = 0, unsigned __int8 v57 = 0, v58 = 0, (ZinIrOpLayer::IsNoOp(a1, (uint64_t *)&__p) & 1) == 0))
  {
    int v20 = (*(uint64_t (**)(ZinIrOpLayer *))(*(void *)a1 + 112))(a1);
    char v19 = v20;
    if (a4)
    {
      if (v20) {
        goto LABEL_16;
      }
      goto LABEL_19;
    }
  }
  else
  {
    char v19 = 1;
  }
  if (__p)
  {
    unsigned __int8 v57 = __p;
    operator delete(__p);
  }
  if (v19) {
    goto LABEL_16;
  }
LABEL_19:
  if (!ZinIrOpLayer::IsANELayer(a1)) {
    goto LABEL_41;
  }
  if (a10 && SplitPatternHandlerMgr::IsLayerCreated(a10, a1))
  {
    SplitPatternHandlerMgr::GetSupportedSplitDimension((uint64_t)a10, (uint64_t)a1);
    uint64_t v24 = v60;
    *a9 = v59;
    a9[1] = v24;
    uint64_t v22 = a9 + 1;
    uint64_t v25 = *((void *)&v60 + 1);
    a9[2] = *((void *)&v60 + 1);
    if (v25)
    {
      *(void *)(v24 + 16) = v22;
      uint64_t v59 = (uint64_t *)&v60;
      long long v60 = 0uLL;
      goto LABEL_113;
    }
LABEL_112:
    *a9 = v22;
    goto LABEL_113;
  }
  if (!*((void *)a1 + 25) || *((void *)a1 + 24) > 1uLL)
  {
    if (ZinIrOpLayer::IsNELayer(a1))
    {
      if ((*(unsigned int (**)(ZinIrOpLayer *))(*(void *)a1 + 408))(a1))
      {
        *(_DWORD *)buf = 1;
        std::__tree<SpatialDimension>::__erase_unique<SpatialDimension>((uint64_t)&v59, (unsigned int *)buf);
      }
      uint64_t v26 = *((void *)a1 + 46);
      if (v26)
      {
        uint64_t v27 = *(void *)(v26 + 64);
        if (ZinIrBroadcastInfo::HasDimension(v27, 3)
          || ZinIrBroadcastInfo::HasDimension(v27, 4)
          || ZinIrBroadcastInfo::HasDimension(v27, 1))
        {
          if ((a6 & 1) == 0) {
            goto LABEL_16;
          }
          **(void **)a7 |= 1uLL;
        }
      }
    }
    else
    {
      if (!ZinIrOpLayer::IsPELayer(a1)) {
        ZinAssertImpl("Only NE and PE engine layers are supported for Splitting\n");
      }
      if ((*(unsigned int (**)(ZinIrOpLayer *))(*(void *)a1 + 408))(a1))
      {
        *(_DWORD *)buf = 1;
        std::__tree<SpatialDimension>::__erase_unique<SpatialDimension>((uint64_t)&v59, (unsigned int *)buf);
      }
      if (((*(uint64_t (**)(ZinIrOpLayer *))(*(void *)a1 + 640))(a1) & 1) != 0
        || (*(unsigned int (**)(ZinIrOpLayer *))(*(void *)a1 + 648))(a1)
        || !CheckBroadcastSupport<ProducerConsumerChain>(a1, a8))
      {
        goto LABEL_16;
      }
    }
LABEL_41:
    int v28 = *(_DWORD *)(*((void *)a1 + 8) + 8);
    switch(v28)
    {
      case 'Q':
        uint64_t v22 = a9 + 1;
        if (*((void *)a1 + 63))
        {
          unint64_t v21 = v65;
          *a9 = v64;
          a9[1] = v21;
          goto LABEL_17;
        }
        uint64_t v29 = v60;
        *a9 = v59;
        a9[1] = v29;
        goto LABEL_43;
      case 'R':
      case 'V':
      case 'W':
      case 'X':
      case '[':
LABEL_64:
        if (a5 && os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_INFO))
        {
          *(_DWORD *)buf = 67109120;
          *(_DWORD *)&buf[4] = v28;
          _os_log_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_INFO, "unsupported: %d", buf, 8u);
        }
        goto LABEL_16;
      case 'S':
        uint64_t v40 = *(void *)(*((void *)a1 + 54) + 64);
        if (*(uint64_t *)(v40 + 32) >= 2) {
          goto LABEL_16;
        }
        if (*(uint64_t *)(v40 + 16) >= 2 && !*(unsigned char *)(a2 + 1327))
        {
          *(_DWORD *)buf = 1;
          std::__tree<SpatialDimension>::__erase_unique<SpatialDimension>((uint64_t)&v59, (unsigned int *)buf);
        }
        if (ZinPEPoolLayer::GetPreOpsPreScaleIndex(a1) == -1) {
          goto LABEL_42;
        }
        if (a6)
        {
          unint64_t PreOpsPreScaleIndex = ZinPEPoolLayer::GetPreOpsPreScaleIndex(a1);
          *(void *)(*(void *)a7 + ((PreOpsPreScaleIndex >> 3) & 0x1FFFFFFFFFFFFFF8)) |= 1 << PreOpsPreScaleIndex;
          goto LABEL_42;
        }
        unint64_t v54 = ZinPEPoolLayer::GetPreOpsPreScaleIndex(a1);
        if (DetectIncomingConstIn(a1, v54)) {
          goto LABEL_42;
        }
        goto LABEL_16;
      case 'T':
      case 'Z':
      case '\\':
        goto LABEL_42;
      case 'U':
        uint64_t v43 = (void *)*((void *)a1 + 54);
        if (!v43) {
          goto LABEL_42;
        }
        uint64_t v44 = v43[17];
        if ((*(unsigned char *)(v44 + 448) & 0x40) != 0 && (a3 & 1) == 0) {
          goto LABEL_16;
        }
        if (*(uint64_t *)(v44 + 264) >= 2 && !*(unsigned char *)(a2 + 1327))
        {
          *(_DWORD *)buf = 1;
          std::__tree<SpatialDimension>::__erase_unique<SpatialDimension>((uint64_t)&v59, (unsigned int *)buf);
          uint64_t v43 = (void *)*((void *)a1 + 54);
        }
        if (!(*(unsigned int (**)(void *))(*v43 + 120))(v43)) {
          goto LABEL_42;
        }
        (*(void (**)(uint8_t *__return_ptr, ZinIrOpLayer *))(*(void *)a1 + 128))(buf, a1);
        uint64_t v45 = *(void *)buf;
        if (v62) {
          std::__shared_weak_count::__release_shared[abi:ne180100](v62);
        }
        if (a6)
        {
          if (*((void *)a1 + 12) != *((void *)a1 + 11))
          {
            unint64_t v46 = 0;
            do
            {
              if (v45 == ZinIrOpLayer::GetInputTensor(a1, v46)) {
                *(void *)(*(void *)a7 + ((v46 >> 3) & 0x1FFFFFFFFFFFFFF8)) |= 1 << v46;
              }
              ++v46;
            }
            while (v46 < (uint64_t)(*((void *)a1 + 12) - *((void *)a1 + 11)) >> 3);
          }
        }
        else
        {
          *(void *)buf = *(void *)(v45 + 96);
          if (std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)(a8 + 32), buf))
          {
            goto LABEL_16;
          }
        }
LABEL_42:
        uint64_t v29 = v60;
        *a9 = v59;
        a9[1] = v29;
        uint64_t v22 = a9 + 1;
LABEL_43:
        uint64_t v30 = *((void *)&v60 + 1);
        a9[2] = *((void *)&v60 + 1);
        if (v30)
        {
          *(void *)(v29 + 16) = v22;
          uint64_t v59 = (uint64_t *)&v60;
          long long v60 = 0uLL;
          goto LABEL_113;
        }
        break;
      case 'Y':
        uint64_t v42 = *(void *)(*((void *)a1 + 54) + 64);
        if (*(uint64_t *)(v42 + 32) >= 2) {
          goto LABEL_16;
        }
        if (*(uint64_t *)(v42 + 16) >= 2 && !*(unsigned char *)(a2 + 1327))
        {
          *(_DWORD *)buf = 1;
          std::__tree<SpatialDimension>::__erase_unique<SpatialDimension>((uint64_t)&v59, (unsigned int *)buf);
        }
        goto LABEL_42;
      default:
        switch(v28)
        {
          case '!':
          case '%':
            goto LABEL_16;
          case '""':
            goto LABEL_64;
          case '#':
            ZinMirSpatialSplitUtils::SpatialDimensionsInWhichReshapeCannotBeSplit(a1, (uint64_t **)buf);
            uint64_t v31 = a9 + 1;
            if (v63)
            {
              uint64_t v32 = v65;
              *a9 = v64;
              a9[1] = v32;
              uint64_t v33 = v66;
              a9[2] = v66;
              if (v33)
              {
                v32[2] = v31;
                uint64_t v64 = (uint64_t)&v65;
                char v65 = 0;
                uint64_t v66 = 0;
                goto LABEL_118;
              }
            }
            else
            {
              uint64_t v52 = v60;
              *a9 = v59;
              a9[1] = v52;
              uint64_t v53 = *((void *)&v60 + 1);
              a9[2] = *((void *)&v60 + 1);
              if (v53)
              {
                *(void *)(v52 + 16) = v31;
                uint64_t v59 = (uint64_t *)&v60;
                long long v60 = 0uLL;
                goto LABEL_118;
              }
            }
            *a9 = v31;
LABEL_118:
            std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)buf, v62);
            break;
          case '$':
            std::string v47 = v59;
            uint64_t v35 = (uint64_t *)&v60;
            if (v59 == (uint64_t *)&v60) {
              goto LABEL_110;
            }
            do
            {
              if (*((_DWORD *)v47 + 7)) {
                int v48 = 4;
              }
              else {
                int v48 = 3;
              }
              if (ZinViewLayer::IsSplittable((uint64_t)a1, v48))
              {
                std::string::size_type v49 = (uint64_t *)v47[1];
                if (v49)
                {
                  do
                  {
                    std::string v50 = v49;
                    std::string::size_type v49 = (uint64_t *)*v49;
                  }
                  while (v49);
                }
                else
                {
                  do
                  {
                    std::string v50 = (uint64_t *)v47[2];
                    BOOL v39 = *v50 == (void)v47;
                    std::string v47 = v50;
                  }
                  while (!v39);
                }
              }
              else
              {
                std::string v50 = std::__tree<std::__value_type<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,ZinIrHazardGraph::EdgeType>,std::__map_value_compare<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,std::__value_type<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,ZinIrHazardGraph::EdgeType>,HazardEdgeCompare,true>,std::allocator<std::__value_type<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,ZinIrHazardGraph::EdgeType>>>::__remove_node_pointer(&v59, v47);
                operator delete(v47);
              }
              std::string v47 = v50;
            }
            while (v50 != (uint64_t *)&v60);
            goto LABEL_109;
          default:
            if (v28 != 7) {
              goto LABEL_64;
            }
            long long v34 = v59;
            uint64_t v35 = (uint64_t *)&v60;
            if (v59 == (uint64_t *)&v60) {
              goto LABEL_110;
            }
            do
            {
              if (*((_DWORD *)v34 + 7)) {
                int v36 = 4;
              }
              else {
                int v36 = 3;
              }
              if (ZinConcatLayer::IsSplittable((uint64_t)a1, v36))
              {
                uint64_t v37 = (uint64_t *)v34[1];
                if (v37)
                {
                  do
                  {
                    unsigned __int8 v38 = v37;
                    uint64_t v37 = (uint64_t *)*v37;
                  }
                  while (v37);
                }
                else
                {
                  do
                  {
                    unsigned __int8 v38 = (uint64_t *)v34[2];
                    BOOL v39 = *v38 == (void)v34;
                    long long v34 = v38;
                  }
                  while (!v39);
                }
              }
              else
              {
                unsigned __int8 v38 = std::__tree<std::__value_type<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,ZinIrHazardGraph::EdgeType>,std::__map_value_compare<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,std::__value_type<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,ZinIrHazardGraph::EdgeType>,HazardEdgeCompare,true>,std::allocator<std::__value_type<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,ZinIrHazardGraph::EdgeType>>>::__remove_node_pointer(&v59, v34);
                operator delete(v34);
              }
              long long v34 = v38;
            }
            while (v38 != (uint64_t *)&v60);
LABEL_109:
            uint64_t v35 = v59;
LABEL_110:
            *a9 = v35;
            long long v51 = v60;
            a9[1] = v60;
            uint64_t v22 = a9 + 1;
            a9[2] = *((void *)&v51 + 1);
            if (!*((void *)&v51 + 1)) {
              goto LABEL_112;
            }
            *(void *)(v51 + 16) = v22;
            uint64_t v59 = (uint64_t *)&v60;
            long long v60 = 0uLL;
            goto LABEL_113;
        }
        goto LABEL_113;
    }
    goto LABEL_112;
  }
LABEL_16:
  unint64_t v21 = v65;
  *a9 = v64;
  a9[1] = v21;
  uint64_t v22 = a9 + 1;
LABEL_17:
  uint64_t v23 = v66;
  a9[2] = v66;
  if (!v23) {
    goto LABEL_112;
  }
  v21[2] = v22;
  uint64_t v64 = (uint64_t)&v65;
  char v65 = 0;
  uint64_t v66 = 0;
LABEL_113:
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v64, v65);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v59, (void *)v60);
}

void sub_211263AA8(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, void *__p, uint64_t a12, uint64_t a13, char a14, void *a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,char a21,void *a22)
{
}

uint64_t ProducerConsumerChain::Analyze@<X0>(ProducerConsumerChain *this@<X0>, ZinIrOpLayerGraph *a2@<X1>, ZinIrOpLayer *a3@<X2>, const ZinIrHalParameters *a4@<X3>, uint64_t a5@<X8>)
{
  v35[0] = 0;
  v35[72] = 0;
  int v30 = *(_DWORD *)this;
  *(_OWORD *)long long __p = 0u;
  memset(v32, 0, sizeof(v32));
  uint64_t v33 = 0;
  int v34 = 1065353216;
  UniqueConsumer = a3;
  uint64_t v9 = (void *)((char *)a2 + 24);
  int v10 = (char *)a2 + 104;
  uint64_t v11 = &_os_log_internal;
  uint64_t v12 = a3;
  do
  {
    if (ZinIrOpLayer::IsANELayer(v12)
      && ((*(uint64_t (**)(ZinANELayer *))(*(void *)UniqueConsumer + 408))(UniqueConsumer) & 1) != 0)
    {
      break;
    }
    ProducerConsumerChain::IsLayerAdmissible(this, UniqueConsumer, a4, &v27);
    unint64_t v13 = v28;
    if (!v28) {
      goto LABEL_17;
    }
    while (*((_DWORD *)v13 + 7))
    {
      unint64_t v13 = (void *)*v13;
      if (!v13) {
        goto LABEL_17;
      }
    }
    uint64_t v14 = (*(uint64_t (**)(void, void, void))(***((void ***)UniqueConsumer + 11) + 32))(**((void **)UniqueConsumer + 11), 0, 0);
    if (*(void *)(v14 + 48) != 1 && !*((unsigned char *)this + 2)) {
      goto LABEL_17;
    }
    unint64_t v15 = UniqueConsumer;
    if (UniqueConsumer != a3)
    {
      uint64_t v16 = *(void *)(v14 + 104);
      if (v16)
      {
        if (*(_DWORD *)(v16 + 96)) {
          goto LABEL_17;
        }
      }
    }
    if (!*((unsigned char *)this + 3))
    {
      for (uint64_t i = *((void *)UniqueConsumer + 14); i != *((void *)UniqueConsumer + 15); i += 8)
      {
        if (*(_DWORD *)(*(void *)(*(void *)i + 64) + 8) == 7)
        {
          if (*(unsigned char *)this && os_log_type_enabled(v11, OS_LOG_TYPE_INFO))
          {
            *(_WORD *)buf = 0;
            _os_log_impl(&dword_210C72000, v11, OS_LOG_TYPE_INFO, "chain output in concat", buf, 2u);
            unint64_t v15 = UniqueConsumer;
          }
          break;
        }
      }
    }
    ProducerConsumerChain::AppendLayer((ProducerConsumerChain *)&v30, v15);
    *(void *)buf = &UniqueConsumer;
    uint64_t v17 = std::__hash_table<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::__unordered_map_hasher<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::__unordered_map_equal<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>>>::find<std::reference_wrapper<ZinIrOpLayer * const>>(v9, (unint64_t **)buf);
    unint64_t v18 = v17 + 3;
    if (!v17) {
      unint64_t v18 = v10;
    }
    if (v18[1] - *v18 <= 8uLL)
    {
      int v20 = (ProducerConsumerChain *)(*(uint64_t (**)(ZinANELayer *, void, void))(*(void *)UniqueConsumer
                                                                                              + 32))(UniqueConsumer, 0, 0);
      char v19 = 0;
      UniqueConsumer = ProducerConsumerChain::GetUniqueConsumer(v20, v21);
    }
    else
    {
LABEL_17:
      char v19 = 1;
    }
    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v27, v28);
    if (v19) {
      break;
    }
    uint64_t v12 = UniqueConsumer;
  }
  while (UniqueConsumer);
  uint64_t v23 = (char *)__p[1];
  if (__p[0] == __p[1])
  {
    uint64_t v23 = (char *)__p[0];
  }
  else
  {
    uint64_t v24 = *((void *)__p[1] - 1);
    if (*(_DWORD *)(*(void *)(v24 + 64) + 8) == 85)
    {
      uint64_t v25 = *(void *)(v24 + 432);
      if (v25)
      {
        if ((*(unsigned char *)(*(void *)(v25 + 136) + 448) & 0x40) != 0)
        {
          __p[1] = (char *)__p[1] - 8;
          v23 -= 8;
        }
      }
    }
  }
  if ((unint64_t)(v23 - (char *)__p[0]) < 0x10)
  {
LABEL_38:
    std::__optional_move_base<ProducerConsumerChain,false>::__optional_move_base[abi:ne180100]((unsigned char *)a5, (uint64_t)v35);
  }
  else
  {
    while (*(void *)((*(uint64_t (**)(void, void, void))(**((void **)v23 - 1) + 32))(*((void *)v23 - 1), 0, 0)+ 64) == 1)
    {
      uint64_t v23 = (char *)__p[1] - 8;
      __p[1] = v23;
      if ((unint64_t)(v23 - (char *)__p[0]) <= 0xF) {
        goto LABEL_38;
      }
    }
    *(_DWORD *)a5 = v30;
    *(_OWORD *)(a5 + 8) = *(_OWORD *)__p;
    *(void *)(a5 + 24) = *(void *)&v32[0];
    __p[1] = 0;
    *(void *)&v32[0] = 0;
    __p[0] = 0;
    std::__hash_table<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::__unordered_map_hasher<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::hash<long>,std::equal_to<long>,true>,std::__unordered_map_equal<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::equal_to<long>,std::hash<long>,true>,std::allocator<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>>>::__hash_table(a5 + 32, (uint64_t *)v32 + 1);
    *(unsigned char *)(a5 + 72) = 1;
  }
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v32 + 8);
  if (__p[0])
  {
    __p[1] = __p[0];
    operator delete(__p[0]);
  }
  return std::__optional_destruct_base<ProducerConsumerChain,false>::~__optional_destruct_base[abi:ne180100]((uint64_t)v35);
}

void sub_211263F20(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va2, a2);
  va_start(va1, a2);
  va_start(va, a2);
  uint64_t v3 = va_arg(va1, void);
  uint64_t v5 = va_arg(va1, void *);
  uint64_t v6 = va_arg(va1, void);
  uint64_t v7 = va_arg(va1, void);
  va_copy(va2, va1);
  uint64_t v8 = va_arg(va2, void);
  uint64_t v10 = va_arg(va2, void);
  uint64_t v11 = va_arg(va2, void);
  uint64_t v12 = va_arg(va2, void);
  uint64_t v13 = va_arg(va2, void);
  uint64_t v14 = va_arg(va2, void);
  uint64_t v15 = va_arg(va2, void);
  uint64_t v16 = va_arg(va2, void);
  uint64_t v17 = va_arg(va2, void);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)va, v5);
  ProducerConsumerChain::~ProducerConsumerChain((ProducerConsumerChain *)va1);
  std::__optional_destruct_base<ProducerConsumerChain,false>::~__optional_destruct_base[abi:ne180100]((uint64_t)va2);
  _Unwind_Resume(a1);
}

void *ProducerConsumerChain::AppendLayer(ProducerConsumerChain *this, ZinANELayer *a2)
{
  uint64_t v22 = a2;
  unint64_t v6 = *((void *)this + 3);
  uint64_t v4 = (char *)this + 24;
  unint64_t v5 = v6;
  uint64_t v7 = (void *)*((void *)v4 - 1);
  if ((unint64_t)v7 >= v6)
  {
    uint64_t v9 = (void **)(v4 - 16);
    uint64_t v10 = *((void *)v4 - 2);
    uint64_t v11 = ((uint64_t)v7 - v10) >> 3;
    if ((unint64_t)(v11 + 1) >> 61) {
      std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
    }
    uint64_t v12 = v5 - v10;
    uint64_t v13 = v12 >> 2;
    if (v12 >> 2 <= (unint64_t)(v11 + 1)) {
      uint64_t v13 = v11 + 1;
    }
    if ((unint64_t)v12 >= 0x7FFFFFFFFFFFFFF8) {
      unint64_t v14 = 0x1FFFFFFFFFFFFFFFLL;
    }
    else {
      unint64_t v14 = v13;
    }
    if (v14) {
      uint64_t v15 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)v4, v14);
    }
    else {
      uint64_t v15 = 0;
    }
    uint64_t v16 = &v15[8 * v11];
    uint64_t v17 = &v15[8 * v14];
    *(void *)uint64_t v16 = a2;
    uint64_t v8 = v16 + 8;
    char v19 = (char *)*((void *)this + 1);
    unint64_t v18 = (char *)*((void *)this + 2);
    if (v18 != v19)
    {
      do
      {
        uint64_t v20 = *((void *)v18 - 1);
        v18 -= 8;
        *((void *)v16 - 1) = v20;
        v16 -= 8;
      }
      while (v18 != v19);
      unint64_t v18 = (char *)*v9;
    }
    *((void *)this + 1) = v16;
    *((void *)this + 2) = v8;
    *((void *)this + 3) = v17;
    if (v18) {
      operator delete(v18);
    }
  }
  else
  {
    void *v7 = a2;
    uint64_t v8 = v7 + 1;
  }
  *((void *)this + 2) = v8;
  return std::__hash_table<ZinIrTensor const*,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const* const&>((uint64_t)this + 32, &v22, &v22);
}

ZinIrOpLayer *ProducerConsumerChain::GetUniqueConsumer(ProducerConsumerChain *this, ZinIrTensor *a2)
{
  uint64_t v9 = 0;
  uint64_t v10 = 0;
  uint64_t v8 = (uint64_t *)&v9;
  uint64_t v2 = *((void *)this + 12);
  uint64_t v3 = *(uint64_t **)(v2 + 112);
  uint64_t v4 = *(uint64_t **)(v2 + 120);
  if (v3 == v4) {
    goto LABEL_7;
  }
  do
  {
    uint64_t v7 = *v3;
    std::__tree<ZinIrTensor *>::__emplace_unique_key_args<ZinIrTensor *,ZinIrTensor * const&>(&v8, (unint64_t *)&v7, &v7);
    ++v3;
  }
  while (v3 != v4);
  if (v10 != 1)
  {
LABEL_7:
    unint64_t v5 = 0;
  }
  else
  {
    unint64_t v5 = (ZinIrOpLayer *)v8[4];
    if (!ZinIrOpLayer::IsANELayer(v5)) {
      unint64_t v5 = 0;
    }
  }
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v8, v9);
  return v5;
}

void sub_2112640F8(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, char a10, void *a11)
{
}

unint64_t ProducerConsumerChain::GetIncomingLayerIndexInChain(ProducerConsumerChain *this, const ZinANELayer *a2)
{
  uint64_t v2 = *((void *)a2 + 11);
  if (*((void *)a2 + 12) == v2) {
    return 0;
  }
  unint64_t v4 = 0;
  unint64_t v5 = (void *)((char *)this + 32);
  while (1)
  {
    uint64_t v7 = *(void *)(v2 + 8 * v4);
    if (std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(v5, &v7))
    {
      break;
    }
    ++v4;
    uint64_t v2 = *((void *)a2 + 11);
    if (v4 >= (*((void *)a2 + 12) - v2) >> 3) {
      return 0;
    }
  }
  return v4;
}

__n128 LogicalDimensions::LogicalDimensions(uint64_t a1, uint64_t a2, void *a3)
{
  *(_OWORD *)a1 = *(_OWORD *)a2;
  uint64_t v3 = a3[2] + *(void *)(a2 + 24) + a3[3];
  *(void *)(a1 + 16) = *a3 + *(void *)(a2 + 16) + a3[1];
  *(void *)(a1 + 24) = v3;
  *(void *)(a1 + 32) = *(void *)(a2 + 32);
  __n128 result = *(__n128 *)a3;
  *(_OWORD *)(a1 + 56) = *((_OWORD *)a3 + 1);
  *(__n128 *)(a1 + 40) = result;
  return result;
}

unint64_t LayerTilingHelper::GetOutputCount(uint64_t a1, LayerTilingHelper::Requirement *this, int a3)
{
  BOOL v4 = a3 == 0;
  uint64_t v5 = 72;
  if (!a3) {
    uint64_t v5 = 64;
  }
  uint64_t v6 = *(void *)(a1 + v5);
  uint64_t v7 = 88;
  if (!a3) {
    uint64_t v7 = 80;
  }
  uint64_t v8 = *(void *)(a1 + v7);
  uint64_t v9 = 104;
  if (v4) {
    uint64_t v9 = 96;
  }
  return LayerTilingHelper::Requirement::GetOutputCount(this, v6, v8, *(void *)(a1 + v9));
}

unint64_t LayerTilingHelper::Requirement::GetOutputCount(LayerTilingHelper::Requirement *this, uint64_t a2, uint64_t a3, uint64_t a4)
{
  if (a3 == 2 && a4 == 1) {
    unint64_t v4 = (*(void *)this
  }
        - a2
        + (unint64_t)*((unsigned __int8 *)this + 24)
        + *((void *)this + 4)
        + *((void *)this + 2)) >> 1;
  else {
    unint64_t v4 = *(void *)this
  }
       - a2
       + *((unsigned __int8 *)this + 24)
       + (*((void *)this + 2) + *((unsigned __int8 *)this + 25)) * a4
       + *((void *)this + 4);
  return v4 + 1;
}

uint64_t LayerTilingHelper::CreateLayer(const ZinIrOpLayer **a1, uint64_t **a2, uint64_t *a3, TiledLayerTensorRegions *a4, SplitPatternHandlerMgr *this, void *a6, ZinIrOpLayer **a7)
{
  v36[1] = *MEMORY[0x263EF8340];
  if (this && SplitPatternHandlerMgr::IsLayerCreated(this, *a1))
  {
    uint64_t v14 = SplitPatternHandlerMgr::SpatialSplitCopy(this, *a1, a4);
LABEL_7:
    *a7 = (ZinIrOpLayer *)v14;
LABEL_8:
    BOOL IsANELayer = ZinIrOpLayer::IsANELayer(*a7);
    unint64_t v18 = *a7;
    if (IsANELayer && *((void *)v18 + 33))
    {
      uint64_t v20 = (_DWORD *)*a6;
      char v19 = (_DWORD *)a6[1];
      if ((_DWORD *)*a6 != v19)
      {
        while (*v20)
        {
          if (++v20 == v19)
          {
            uint64_t v20 = (_DWORD *)a6[1];
            break;
          }
        }
      }
      if (v20 != v19) {
        operator new();
      }
    }
    v36[0] = *a1;
    v30[0] = v36;
    v30[1] = 1;
    Layer2TDMapper::SourceLayer::SourceLayer(&v31, v30);
    BOOL v21 = ZinIrOpLayerGraph::AddNode(a2, v18, (ZinIrOpLayer ***)&v31);
    uint64_t v31 = (ZinEngineLayerMirInfo *)&unk_26C359A08;
    if (__p)
    {
      uint64_t v33 = __p;
      operator delete(__p);
    }
    if (!v21
      || (ZinIrOpLayerGraph::AddEdgesImplSrc<std::vector<ZinIrOpLayer *>>((uint64_t)a2, a3, (uint64_t)*a7) & 1) == 0)
    {
      ZinAssertImpl("Failed to update graph");
    }
    uint64_t result = ZinIrOpLayer::IsANELayer(*a7);
    if (result)
    {
      uint64_t v23 = *a7;
      uint64_t v24 = *((void *)v23 + 33);
      if (v24
        && *(unsigned char *)(v24 + 233)
        && (unint64_t v25 = (*(uint64_t (**)(ZinIrOpLayer *, uint64_t))(*(void *)v23 + 368))(v23, 3),
            *(void *)(v24 + 200) > v25))
      {
        if (*(void *)(v24 + 216)
          || *(_DWORD *)(*((void *)v23 + 8) + 8) != 85
          || !ZinNEConvLayer::IsKernelStreaming(v23))
        {
          ZinAssertImpl("Unsupported tile configuration in spatial split");
        }
        uint64_t result = 0;
        *(void *)(v24 + 200) = v25;
        *(unsigned char *)(v24 + 233) = 1;
      }
      else
      {
        return 0;
      }
    }
  }
  else
  {
    uint64_t v15 = *a1;
    int v16 = *(_DWORD *)(*((void *)*a1 + 8) + 8);
    if (v16 <= 80)
    {
      switch(v16)
      {
        case 7:
          ZinConcatLayer::SpatialSplitCopy((uint64_t)*a1, (uint64_t)a4, (uint64_t)a6);
        case 35:
          ZinReshapeLayer::SpatialSplitCopy(*a1, a4);
        case 36:
          ZinViewLayer::SpatialSplitCopy(*a1, a4);
      }
LABEL_45:
      if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
        LayerTilingHelper::CreateLayer(v16);
      }
    }
    else
    {
      switch(v16)
      {
        case 'Q':
        case 'S':
        case 'T':
        case 'Y':
        case 'Z':
        case '\\':
          uint64_t v14 = (*(uint64_t (**)(const ZinIrOpLayer *, TiledLayerTensorRegions *))(*(void *)v15 + 320))(*a1, a4);
          goto LABEL_7;
        case 'U':
          *a7 = (ZinIrOpLayer *)(*(uint64_t (**)(const ZinIrOpLayer *, TiledLayerTensorRegions *))(*(void *)v15 + 320))(*a1, a4);
          if (!(*(unsigned int (**)(const ZinIrOpLayer *))(*(void *)v15 + 120))(v15)) {
            goto LABEL_8;
          }
          (*(void (**)(ZinEngineLayerMirInfo **__return_ptr, const ZinIrOpLayer *))(*(void *)v15 + 128))(&v31, v15);
          if ((*(uint64_t (**)(const ZinIrOpLayer *, ZinEngineLayerMirInfo *))(*(void *)v15 + 152))(v15, v31) != 1)ZinAssertImpl("wrong kernel-tensor index"); {
          uint64_t v26 = *a7;
          }
          uint64_t v27 = (uint64_t *)(*(uint64_t (**)(void, void, void))(**(void **)(*a3 + 8) + 40))(*(void *)(*a3 + 8), 0, 0);
          int v28 = (std::__shared_weak_count *)v27[1];
          uint64_t v34 = *v27;
          uint64_t v35 = v28;
          if (v28) {
            atomic_fetch_add_explicit(&v28->__shared_owners_, 1uLL, memory_order_relaxed);
          }
          char v29 = (*(uint64_t (**)(ZinIrOpLayer *, uint64_t *))(*(void *)v26 + 240))(v26, &v34);
          if (v35) {
            std::__shared_weak_count::__release_shared[abi:ne180100](v35);
          }
          if (v29)
          {
            if (__p) {
              std::__shared_weak_count::__release_shared[abi:ne180100]((std::__shared_weak_count *)__p);
            }
            goto LABEL_8;
          }
          if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_INFO))
          {
            LOWORD(v30[0]) = 0;
            _os_log_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_INFO, "Could not split MatMul", (uint8_t *)v30, 2u);
          }
          if (__p) {
            std::__shared_weak_count::__release_shared[abi:ne180100]((std::__shared_weak_count *)__p);
          }
          break;
        default:
          goto LABEL_45;
      }
    }
    return 3;
  }
  return result;
}

void sub_2112647EC(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, std::__shared_weak_count *__p, uint64_t a13, uint64_t a14, uint64_t a15, std::__shared_weak_count *a16)
{
  if (a16) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a16);
  }
  if (__p) {
    std::__shared_weak_count::__release_shared[abi:ne180100](__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t LayerTilingHelper::Requirement::GetExtendedTo(LayerTilingHelper::Requirement *this, const LayerTilingHelper::Requirement *a2, LayerTilingHelper::Requirement *a3)
{
  unint64_t v3 = *((void *)this + 1);
  if (v3 > *((void *)a2 + 1)) {
    return 3;
  }
  uint64_t result = 0;
  *((void *)a3 + 1) = v3;
  uint64_t v6 = *((void *)this + 1);
  *(void *)a3 = *(void *)this;
  *((unsigned char *)a3 + 24) = *((unsigned char *)this + 24);
  *((void *)a3 + 2) = *((void *)a2 + 1) - v6 + *((void *)a2 + 2);
  *((unsigned char *)a3 + 25) = *((unsigned char *)a2 + 25);
  uint64_t v7 = *((void *)this + 5);
  *((void *)a3 + 4) = *((void *)a2 + 4);
  *((void *)a3 + 5) = v7;
  *((void *)a3 + 6) = *((void *)a2 + 6);
  return result;
}

uint64_t LayerTilingHelper::ComputeInputRequirement(ZinIrOpLayer **this, LayerTilingHelper *a2)
{
  unint64_t v3 = operator new(8uLL);
  uint64_t v4 = 0;
  *unint64_t v3 = 0x100000000;
  long long v95 = (char *)(this + 18);
  long long __p = v3;
  uint64_t v5 = *this;
  long long v94 = (char *)(this + 21);
  while (1)
  {
    int v102 = __p[v4];
    uint64_t v6 = 168;
    if (!v102) {
      uint64_t v6 = 144;
    }
    uint64_t v108 = v6;
    if (v102) {
      uint64_t v7 = v94;
    }
    else {
      uint64_t v7 = v95;
    }
    uint64_t v8 = (char *)(this + 8);
    if (v102) {
      uint64_t v8 = (char *)(this + 9);
    }
    unint64_t v110 = *(void *)v8;
    if (v102) {
      uint64_t v9 = 11;
    }
    else {
      uint64_t v9 = 10;
    }
    unint64_t v10 = (unint64_t)this[v9];
    uint64_t v11 = (char *)(this + 14);
    if (v102) {
      uint64_t v11 = (char *)(this + 16);
    }
    unint64_t v105 = *(void *)v11;
    uint64_t v12 = (char *)(this + 15);
    if (v102) {
      uint64_t v12 = (char *)(this + 17);
    }
    uint64_t v13 = *(void *)v12;
    uint64_t v14 = (*(uint64_t (**)(void, void, void))(***((void ***)v5 + 11) + 32))(**((void **)v5 + 11), 0, 0);
    uint64_t v16 = *(void *)(v14 + 64);
    uint64_t v15 = *(void *)(v14 + 72);
    uint64_t v17 = (*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)*this + 32))(*this, 0, 0);
    long long v18 = *(_OWORD *)(v17 + 64);
    long long v113 = *(_OWORD *)(v17 + 48);
    long long v114 = v18;
    uint64_t v115 = *(void *)(v17 + 80);
    BOOL IsANELayer = ZinIrOpLayer::IsANELayer(*this);
    uint64_t v20 = *this;
    if (IsANELayer)
    {
      uint64_t v15 = (*(uint64_t (**)(ZinIrOpLayer *, uint64_t))(*(void *)v20 + 360))(*this, 4);
      uint64_t v16 = (*(uint64_t (**)(ZinIrOpLayer *, uint64_t))(*(void *)v20 + 360))(v20, 3);
      if ((*(unsigned int (**)(ZinIrOpLayer *))(*(void *)v20 + 408))(v20))
      {
        v111[0] = v113;
        v111[1] = v114;
        uint64_t v112 = v115;
        BOOL v21 = (ZinReshapeLayer *)(*(uint64_t (**)(ZinIrOpLayer *))(*(void *)v20 + 416))(v20);
        uint64_t ReshapeInfo = ZinReshapeLayer::GetReshapeInfo(v21);
        uint64_t v23 = v7;
        ZinIrTransposeUnitInfo::TransposeDimensions<ZinTensorDimensions>(v111, ReshapeInfo + 16, &v113);
LABEL_23:
        unint64_t v100 = 0;
        goto LABEL_24;
      }
LABEL_22:
      uint64_t v23 = v7;
      goto LABEL_23;
    }
    uint64_t v24 = *((void *)v20 + 8);
    int v25 = *(_DWORD *)(v24 + 8);
    if (v25 != 36)
    {
      if (v25 == 7)
      {
        uint64_t v26 = (*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)v20 + 32))(*this, 0, 0);
        uint64_t v23 = v7;
        unint64_t v100 = 0;
        uint64_t v16 = *(void *)(v26 + 64);
        uint64_t v15 = *(void *)(v26 + 72);
LABEL_24:
        uint64_t v27 = -1;
        goto LABEL_25;
      }
      goto LABEL_22;
    }
    uint64_t v23 = v7;
    long long v80 = (unint64_t *)(v24 + 32);
    long long v81 = (unint64_t *)(v24 + 40);
    if (!v102) {
      long long v81 = v80;
    }
    unint64_t v82 = *v81;
    long long v83 = &v114;
    if (v102) {
      long long v83 = (long long *)((char *)&v114 + 8);
    }
    unint64_t v100 = v82;
    uint64_t v27 = *(void *)v83 + v82;
LABEL_25:
    unint64_t v109 = v27;
    if (v102) {
      uint64_t v28 = v15;
    }
    else {
      uint64_t v28 = v16;
    }
    char v29 = (char *)(this + 12);
    if (v102) {
      char v29 = (char *)(this + 13);
    }
    char v31 = this[v9] == (ZinIrOpLayer *)1 && *(void *)v29 == 2;
    char v107 = v31;
    unint64_t v32 = (v28 << v31) + v105;
    unint64_t v33 = v32 + v13 - v110;
    if (v32 + v13 < v110) {
      goto LABEL_108;
    }
    unint64_t v99 = v28;
    std::vector<ZinOcgKernelData>::reserve((void **)v23, v33 / v10 + 1);
    uint64_t v97 = v4;
    uint64_t v98 = v13;
    unint64_t v34 = v100;
    if (v100 <= v33 && v100 < v109) {
      break;
    }
    int v36 = (char *)*((void *)v23 + 1);
LABEL_43:
    uint64_t v37 = *(uint64_t *)((char *)this + v108);
    uint64_t v38 = 0x6DB6DB6DB6DB6DB7 * ((uint64_t)&v36[-v37] >> 3);
    BOOL v39 = &v114;
    if (v102) {
      BOOL v39 = (long long *)((char *)&v114 + 8);
    }
    if (v38 != *(void *)v39) {
      ZinAssertImpl("Each output unit must have a calculation");
    }
    uint64_t v5 = *this;
    if (*(_DWORD *)(*((void *)*this + 8) + 8) == 36)
    {
      *(void *)(v37 + 40) = v100;
      if (v99 < v38 + v100) {
        ZinAssertImpl("Illegal value in view layer for spatial splitting");
      }
      *((void *)v36 - 1) = v99 - (v38 + v100);
    }
    else
    {
      uint64_t v78 = *((void *)v36 - 5);
      unint64_t v79 = v99 - (*((void *)v36 - 6) + v78 + *(v36 - 31));
      if (v98 - *((void *)v36 - 3) + v79 > v10 - 1) {
        ZinAssertImpl("Extra padding would create extra row");
      }
      *((void *)v36 - 3) = v98;
      *((void *)v36 - 5) = v79 + v78;
    }
    uint64_t v4 = v97 + 1;
    if (v97 == 1)
    {
      uint64_t v93 = 0;
      goto LABEL_109;
    }
  }
  unint64_t v40 = v33;
  unint64_t v41 = v110 - 1;
  unint64_t v42 = v32 - 1;
  uint64_t v101 = (uint64_t)(v23 + 16);
  unint64_t v43 = v105;
  unint64_t v104 = v33;
  unint64_t v103 = v42;
  uint64_t v106 = v23;
  while (1)
  {
    unint64_t v44 = v43 >= v34 ? v43 - v34 : 0;
    unint64_t v45 = v34 <= v43 ? v43 : v34;
    unint64_t v46 = v110 - v44;
    if (v110 == v44) {
      break;
    }
    unint64_t v47 = v41 + v34;
    unint64_t v48 = v45 - v43;
    if (v107)
    {
      char v49 = v48 & 1;
      unint64_t v50 = v46 - (v48 & 1);
      unint64_t v51 = (v48 & 1) + v45;
      unint64_t v48 = (v51 - v43) >> 1;
      if (v42 < v47) {
        unint64_t v47 = v42;
      }
      unint64_t v52 = v47 - v51 + 1;
      unint64_t v53 = v52 >> 1;
      char v54 = v52 & 1;
      unint64_t v55 = v50 - v52;
      if (v51 <= v42) {
        char v56 = v54;
      }
      else {
        char v56 = 0;
      }
      if (v51 <= v42) {
        unint64_t v57 = v53;
      }
      else {
        unint64_t v57 = 0;
      }
      if (v51 > v42) {
        unint64_t v55 = v50;
      }
    }
    else
    {
      if (v42 < v47) {
        unint64_t v47 = v42;
      }
      unint64_t v58 = v47 - v45;
      char v56 = 0;
      char v49 = 0;
      if (v45 <= v42) {
        unint64_t v57 = v58 + 1;
      }
      else {
        unint64_t v57 = 0;
      }
      if (v45 <= v42) {
        unint64_t v55 = v46 - (v58 + 1);
      }
      else {
        unint64_t v55 = v110 - v44;
      }
    }
    unint64_t v59 = *((void *)v23 + 1);
    unint64_t v60 = *((void *)v23 + 2);
    if (v59 >= v60)
    {
      unint64_t v61 = v55;
      std::string v62 = (ZinIrOpLayer *)v10;
      uint64_t v63 = (LayerTilingHelper *)this;
      uint64_t v64 = *(uint64_t *)((char *)this + v108);
      uint64_t v65 = 0x6DB6DB6DB6DB6DB7 * ((uint64_t)(v59 - v64) >> 3);
      unint64_t v66 = v65 + 1;
      if ((unint64_t)(v65 + 1) > 0x492492492492492) {
        std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
      }
      unint64_t v67 = v57;
      unint64_t v68 = 0x6DB6DB6DB6DB6DB7 * ((uint64_t)(v60 - v64) >> 3);
      if (2 * v68 > v66) {
        unint64_t v66 = 2 * v68;
      }
      if (v68 >= 0x249249249249249) {
        unint64_t v69 = 0x492492492492492;
      }
      else {
        unint64_t v69 = v66;
      }
      if (v69) {
        uint64_t v70 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ZinNeKernelData>>(v101, v69);
      }
      else {
        uint64_t v70 = 0;
      }
      uint64_t v71 = &v70[56 * v65];
      *(void *)uint64_t v71 = v44;
      *((void *)v71 + 1) = v48;
      *((void *)v71 + 2) = v67;
      v71[24] = v49;
      v71[25] = v56;
      *((_WORD *)v71 + 15) = WORD2(v111[0]);
      *(_DWORD *)(v71 + 26) = v111[0];
      *((void *)v71 + 5) = 0;
      *((void *)v71 + 6) = 0;
      *((void *)v71 + 4) = v61;
      uint64_t v72 = (char *)*((void *)v106 + 1);
      this = (ZinIrOpLayer **)v63;
      uint64_t v73 = *(char **)((char *)v63 + v108);
      uint64_t v74 = (ZinIrOpLayer *)v71;
      unint64_t v10 = (unint64_t)v62;
      if (v72 != v73)
      {
        do
        {
          long long v75 = *(_OWORD *)(v72 - 56);
          long long v76 = *(_OWORD *)(v72 - 40);
          long long v77 = *(_OWORD *)(v72 - 24);
          *((void *)v74 - 1) = *((void *)v72 - 1);
          *(_OWORD *)((char *)v74 - 24) = v77;
          *(_OWORD *)((char *)v74 - 40) = v76;
          *(_OWORD *)((char *)v74 - 56) = v75;
          uint64_t v74 = (ZinIrOpLayer *)((char *)v74 - 56);
          v72 -= 56;
        }
        while (v72 != v73);
        uint64_t v72 = *(char **)((char *)this + v108);
      }
      unint64_t v43 = v105;
      uint64_t v23 = v106;
      *(ZinIrOpLayer **)((char *)this + v108) = v74;
      int v36 = v71 + 56;
      *((void *)v106 + 1) = v71 + 56;
      *((void *)v106 + 2) = &v70[56 * v69];
      if (v72) {
        operator delete(v72);
      }
      *((void *)v106 + 1) = v36;
      unint64_t v41 = v110 - 1;
      unint64_t v40 = v104;
      unint64_t v42 = v103;
    }
    else
    {
      *(void *)unint64_t v59 = v44;
      *(void *)(v59 + 8) = v48;
      *(void *)(v59 + 16) = v57;
      *(unsigned char *)(v59 + 24) = v49;
      *(unsigned char *)(v59 + 25) = v56;
      int v36 = (char *)(v59 + 56);
      *(void *)(v59 + 40) = 0;
      *(void *)(v59 + 48) = 0;
      *(void *)(v59 + 32) = v55;
      *((void *)v23 + 1) = v59 + 56;
    }
    v34 += v10;
    if (v34 > v40 || v34 >= v109) {
      goto LABEL_43;
    }
  }
  BOOL v84 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
  if (v84) {
    LayerTilingHelper::ComputeInputRequirement(v84, v85, v86, v87, v88, v89, v90, v91);
  }
LABEL_108:
  uint64_t v93 = 3;
LABEL_109:
  operator delete(__p);
  return v93;
}

void sub_211265060(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, void *__p)
{
}

uint64_t LayerTilingHelper::CreateHelper(LayerTilingHelper *this, const ZinIrOpLayer *a2, const SplitPatternHandlerMgr *a3, LayerTilingHelper *a4)
{
  __n128 v7 = Padding::From(this, &v67);
  unint64_t v61 = (void **)((char *)a3 + 16);
  std::string v62 = a3;
  *((void *)a3 + 3) = *((void *)a3 + 2);
  uint64_t v8 = (void *)*((void *)this + 11);
  uint64_t v9 = (void *)*((void *)this + 12);
  unint64_t v59 = this;
  unint64_t v10 = a3;
  if (v8 != v9)
  {
    unint64_t v65 = v67.n128_u64[1];
    unint64_t v66 = v67.n128_u64[0];
    unint64_t v11 = v67.n128_u64[1] + v67.n128_u64[0];
    uint64_t v63 = v69;
    uint64_t v64 = v68;
    uint64_t v12 = v69 + v68;
    uint64_t v60 = (uint64_t)v10 + 32;
    do
    {
      uint64_t v13 = (void *)(*(uint64_t (**)(void, void, void, __n128))(*(void *)*v8 + 32))(*v8, 0, 0, v7);
      uint64_t v14 = v13[6];
      uint64_t v15 = v13[7];
      unint64_t v16 = v11 + v13[8];
      uint64_t v17 = v12 + v13[9];
      uint64_t v18 = v13[10];
      uint64_t v20 = (char *)*((void *)v10 + 3);
      unint64_t v19 = *((void *)v10 + 4);
      if ((unint64_t)v20 >= v19)
      {
        uint64_t v22 = v9;
        uint64_t v23 = (char *)*v61;
        unint64_t v24 = 0x8E38E38E38E38E39 * ((v20 - (unsigned char *)*v61) >> 3);
        unint64_t v25 = v24 + 1;
        if (v24 + 1 > 0x38E38E38E38E38ELL) {
          std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
        }
        unint64_t v26 = 0x8E38E38E38E38E39 * ((uint64_t)(v19 - (void)v23) >> 3);
        if (2 * v26 > v25) {
          unint64_t v25 = 2 * v26;
        }
        if (v26 >= 0x1C71C71C71C71C7) {
          unint64_t v6 = 0x38E38E38E38E38ELL;
        }
        else {
          unint64_t v6 = v25;
        }
        if (v6)
        {
          uint64_t v27 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ANEDebugInfo::DebugInfoInMem::TD>>(v60, v6);
          uint64_t v23 = (char *)*((void *)v62 + 2);
          uint64_t v20 = (char *)*((void *)v62 + 3);
        }
        else
        {
          uint64_t v27 = 0;
        }
        uint64_t v28 = &v27[72 * v24];
        *(void *)uint64_t v28 = v14;
        *((void *)v28 + 1) = v15;
        *((void *)v28 + 2) = v16;
        *((void *)v28 + 3) = v17;
        *((void *)v28 + 4) = v18;
        *((void *)v28 + 5) = v66;
        *((void *)v28 + 6) = v65;
        *((void *)v28 + 7) = v64;
        *((void *)v28 + 8) = v63;
        char v29 = v28;
        uint64_t v9 = v22;
        if (v20 != v23)
        {
          do
          {
            *(_OWORD *)(v29 - 72) = *(_OWORD *)(v20 - 72);
            __n128 v7 = *(__n128 *)(v20 - 56);
            long long v30 = *(_OWORD *)(v20 - 40);
            long long v31 = *(_OWORD *)(v20 - 24);
            *((void *)v29 - 1) = *((void *)v20 - 1);
            *(_OWORD *)(v29 - 24) = v31;
            *(_OWORD *)(v29 - 40) = v30;
            *(__n128 *)(v29 - 56) = v7;
            v29 -= 72;
            v20 -= 72;
          }
          while (v20 != v23);
          uint64_t v23 = (char *)*v61;
        }
        unint64_t v10 = v62;
        BOOL v21 = v28 + 72;
        *((void *)v62 + 2) = v29;
        *((void *)v62 + 3) = v28 + 72;
        *((void *)v62 + 4) = &v27[72 * v6];
        if (v23) {
          operator delete(v23);
        }
      }
      else
      {
        *(void *)uint64_t v20 = v14;
        *((void *)v20 + 1) = v15;
        *((void *)v20 + 2) = v16;
        *((void *)v20 + 3) = v17;
        *((void *)v20 + 4) = v18;
        *((void *)v20 + 5) = v66;
        *((void *)v20 + 6) = v65;
        *((void *)v20 + 7) = v64;
        BOOL v21 = v20 + 72;
        *((void *)v20 + 8) = v63;
      }
      *((void *)v10 + 3) = v21;
      ++v8;
    }
    while (v8 != v9);
  }
  *(void *)unint64_t v10 = v59;
  *((void *)v10 + 1) = a2;
  unsigned int v32 = *(_DWORD *)(*((void *)v59 + 8) + 8);
  switch(v32)
  {
    case 'Q':
    case 'T':
    case 'Z':
    case '\\':
      goto LABEL_26;
    case 'R':
    case 'V':
    case 'W':
    case 'X':
    case '[':
      return 3;
    case 'S':
    case 'Y':
      uint64_t v33 = *(void *)(*((void *)v59 + 54) + 64);
      *((void *)v62 + 8) = LayerTilingHelper::GetKernelDimsFrom(v59, (const ZinIrOpLayer *)v6);
      *((void *)v62 + 9) = v34;
      uint64_t v35 = *(int *)(v33 + 40);
      *((void *)v62 + 10) = *(int *)(v33 + 44);
      *((void *)v62 + 11) = v35;
      *((int64x2_t *)v62 + 6) = vdupq_n_s64(1uLL);
      uint64_t v36 = *(void *)(v33 + 72);
      *(void *)&long long v37 = (int)v36;
      *((void *)&v37 + 1) = SHIDWORD(v36);
      *((_OWORD *)v62 + 7) = v37;
      uint64_t v38 = *(void *)(v33 + 64);
      goto LABEL_38;
    case 'U':
      uint64_t v46 = *((void *)v59 + 54);
      if (!v46) {
        goto LABEL_26;
      }
      uint64_t v47 = *(void *)(v46 + 136);
      *((void *)v62 + 8) = LayerTilingHelper::GetKernelDimsFrom(v59, (const ZinIrOpLayer *)v6);
      *((void *)v62 + 9) = v34;
      uint64_t v48 = *(int *)(v47 + 328);
      BOOL v49 = v48 == 2;
      uint64_t v50 = *(int *)(v47 + 332);
      uint64_t v51 = *(int *)(v47 + 340);
      BOOL v52 = v51 == 2;
      if (v50 == 2 && *(_DWORD *)(v47 + 344) == 2)
      {
        uint64_t v50 = 1;
        uint64_t v53 = 1;
      }
      else
      {
        uint64_t v53 = *(int *)(v47 + 344);
      }
      if (v49 && v52) {
        uint64_t v48 = 1;
      }
      *((void *)v62 + 10) = v50;
      *((void *)v62 + 11) = v48;
      if (v49 && v52) {
        uint64_t v54 = 1;
      }
      else {
        uint64_t v54 = v51;
      }
      *((void *)v62 + 12) = v53;
      *((void *)v62 + 13) = v54;
      uint64_t v55 = *(void *)(v47 + 360);
      *(void *)&long long v56 = (int)v55;
      *((void *)&v56 + 1) = SHIDWORD(v55);
      *((_OWORD *)v62 + 7) = v56;
      uint64_t v38 = *(void *)(v47 + 352);
LABEL_38:
      unint64_t v10 = v62;
      *(void *)&long long v57 = (int)v38;
      *((void *)&v57 + 1) = SHIDWORD(v38);
      long long v44 = v57;
      goto LABEL_39;
    default:
      BOOL v39 = v32 > 0x24;
      uint64_t v40 = (1 << v32) & 0x1800000080;
      if (v39 || v40 == 0) {
        return 3;
      }
LABEL_26:
      uint64_t KernelDimsFrom = LayerTilingHelper::GetKernelDimsFrom(v59, (const ZinIrOpLayer *)v6);
      int64x2_t v43 = vdupq_n_s64(1uLL);
      *((void *)v10 + 8) = KernelDimsFrom;
      *((void *)v10 + 9) = v34;
      *((int64x2_t *)v10 + 5) = v43;
      *((int64x2_t *)v10 + 6) = v43;
      long long v44 = 0uLL;
      *((_OWORD *)v10 + 7) = 0u;
LABEL_39:
      *((_OWORD *)v10 + 8) = v44;
      return LayerTilingHelper::ComputeInputRequirement((ZinIrOpLayer **)v10, v34);
  }
}

uint64_t LayerTilingHelper::GetKernelDimsFrom(LayerTilingHelper *this, const ZinIrOpLayer *a2)
{
  int v2 = *(_DWORD *)(*((void *)this + 8) + 8);
  if (v2 == 83 || v2 == 89)
  {
    uint64_t v4 = *(void *)(*((void *)this + 54) + 64) + 24;
    return *(void *)v4;
  }
  if (v2 == 85)
  {
    uint64_t v3 = *((void *)this + 54);
    if (v3)
    {
      uint64_t v4 = *(void *)(v3 + 136) + 264;
      return *(void *)v4;
    }
  }
  return 1;
}

uint64_t LayerTilingHelper::Create(void *a1, ZinIrOpLayer *a2, uint64_t *a3, LayerTilingHelper *a4)
{
  uint64_t v4 = (LayerTilingHelper **)a1[1];
  uint64_t v5 = (LayerTilingHelper **)a1[2];
  if (v4 == v5) {
    return 0;
  }
  uint64_t v8 = (uint64_t)(a3 + 2);
  uint64_t v9 = a1 + 4;
  while (1)
  {
    unint64_t v10 = *v4;
    unint64_t v11 = (_OWORD *)a3[1];
    unint64_t v12 = a3[2];
    if ((unint64_t)v11 >= v12)
    {
      unint64_t v14 = 0xAAAAAAAAAAAAAAABLL * (((uint64_t)v11 - *a3) >> 6);
      unint64_t v15 = v14 + 1;
      if (v14 + 1 > 0x155555555555555) {
        std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
      }
      unint64_t v16 = 0xAAAAAAAAAAAAAAABLL * ((uint64_t)(v12 - *a3) >> 6);
      if (2 * v16 > v15) {
        unint64_t v15 = 2 * v16;
      }
      unint64_t v17 = v16 >= 0xAAAAAAAAAAAAAALL ? 0x155555555555555 : v15;
      v26[4] = v8;
      uint64_t v18 = v17 ? (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<LayerTilingHelper>>(v8, v17) : 0;
      unint64_t v19 = &v18[192 * v14];
      v26[0] = v18;
      v26[1] = v19;
      v26[3] = &v18[192 * v17];
      *(_OWORD *)unint64_t v19 = 0u;
      *((_OWORD *)v19 + 1) = 0u;
      *((_OWORD *)v19 + 2) = 0u;
      *((_OWORD *)v19 + 3) = 0u;
      *((_OWORD *)v19 + 4) = 0u;
      *((_OWORD *)v19 + 5) = 0u;
      *((_OWORD *)v19 + 6) = 0u;
      *((_OWORD *)v19 + 7) = 0u;
      *((_OWORD *)v19 + 8) = 0u;
      *((_OWORD *)v19 + 9) = 0u;
      *((_OWORD *)v19 + 10) = 0u;
      *((_OWORD *)v19 + 11) = 0u;
      v26[2] = v19 + 192;
      std::vector<LayerTilingHelper>::__swap_out_circular_buffer(a3, v26);
      uint64_t v13 = (_OWORD *)a3[1];
      std::__split_buffer<LayerTilingHelper>::~__split_buffer((uint64_t)v26);
    }
    else
    {
      v11[10] = 0u;
      v11[11] = 0u;
      v11[8] = 0u;
      v11[9] = 0u;
      v11[6] = 0u;
      v11[7] = 0u;
      v11[4] = 0u;
      v11[5] = 0u;
      v11[2] = 0u;
      v11[3] = 0u;
      _OWORD *v11 = 0u;
      v11[1] = 0u;
      uint64_t v13 = v11 + 12;
      a3[1] = (uint64_t)(v11 + 12);
    }
    a3[1] = (uint64_t)v13;
    uint64_t Helper = LayerTilingHelper::CreateHelper(v10, a2, (const SplitPatternHandlerMgr *)(v13 - 12), a4);
    uint64_t v22 = (ZinIrOpLayer **)*((void *)v10 + 11);
    BOOL v21 = (ZinIrOpLayer **)*((void *)v10 + 12);
    while (v22 != v21)
    {
      uint64_t v23 = *v22;
      BOOL v25 = 0;
      if (ZinIrOpLayer::IsANELayer(v23))
      {
        v26[0] = v10;
        BOOL v25 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(v9, v26) != 0;
      }
      std::vector<BOOL>::push_back(a3[1] - 152, &v25);
      ++v22;
    }
    if (Helper) {
      break;
    }
    if (++v4 == v5) {
      return 0;
    }
  }
  return Helper;
}

void sub_211265728(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::__split_buffer<LayerTilingHelper>::~__split_buffer((uint64_t)va);
  _Unwind_Resume(a1);
}

uint64_t LayerTilingHelper::Create(void *a1, const ZinIrOpLayer *a2, uint64_t a3, LayerTilingHelper *a4)
{
  unint64_t v6 = a1 + 1;
  uint64_t v5 = (void *)*a1;
  if ((void *)*a1 == a1 + 1) {
    return 0;
  }
  while (1)
  {
    uint64_t v8 = (LayerTilingHelper *)v5[4];
    long long v33 = 0u;
    long long v34 = 0u;
    long long v32 = 0u;
    memset(v31, 0, sizeof(v31));
    long long v30 = 0u;
    uint64_t Helper = LayerTilingHelper::CreateHelper(v8, a2, (const SplitPatternHandlerMgr *)v29, a4);
    unint64_t v11 = (ZinIrOpLayer **)*((void *)v8 + 11);
    unint64_t v10 = (ZinIrOpLayer **)*((void *)v8 + 12);
    while (v11 != v10)
    {
      unint64_t v19 = 0;
      unint64_t v19 = *v11;
      BOOL v28 = std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)a1, &v19) != 0;
      std::vector<BOOL>::push_back((uint64_t)&v31[1], &v28);
      ++v11;
    }
    uint64_t v12 = Helper;
    if (!Helper)
    {
      unint64_t v19 = v8;
      LayerTilingHelper::LayerTilingHelper((LayerTilingHelper *)&v20, (const LayerTilingHelper *)v29);
      std::__hash_table<std::__hash_value_type<ZinIrOpLayer *,LayerTilingHelper>,std::__unordered_map_hasher<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,LayerTilingHelper>,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,true>,std::__unordered_map_equal<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,LayerTilingHelper>,std::equal_to<ZinIrOpLayer *>,std::hash<ZinIrOpLayer *>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer *,LayerTilingHelper>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::pair<ZinIrOpLayer *,LayerTilingHelper>>(a3, &v19, (uint64_t)&v19);
      if (__p)
      {
        uint64_t v27 = __p;
        operator delete(__p);
      }
      if (v24)
      {
        BOOL v25 = v24;
        operator delete(v24);
      }
      if (v23) {
        operator delete(v23);
      }
      if (v21)
      {
        uint64_t v22 = v21;
        operator delete(v21);
      }
      uint64_t v12 = v4;
    }
    if (*((void *)&v33 + 1))
    {
      *(void *)&long long v34 = *((void *)&v33 + 1);
      operator delete(*((void **)&v33 + 1));
    }
    if ((void)v32)
    {
      *((void *)&v32 + 1) = v32;
      operator delete((void *)v32);
    }
    if (v31[1]) {
      operator delete(v31[1]);
    }
    if ((void)v30)
    {
      *((void *)&v30 + 1) = v30;
      operator delete((void *)v30);
    }
    if (Helper) {
      break;
    }
    uint64_t v13 = (void *)v5[1];
    if (v13)
    {
      do
      {
        unint64_t v14 = v13;
        uint64_t v13 = (void *)*v13;
      }
      while (v13);
    }
    else
    {
      do
      {
        unint64_t v14 = (void *)v5[2];
        BOOL v15 = *v14 == (void)v5;
        uint64_t v5 = v14;
      }
      while (!v15);
    }
    uint64_t v4 = v12;
    uint64_t v5 = v14;
    if (v14 == v6) {
      return 0;
    }
  }
  return v12;
}

void sub_211265914(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33,uint64_t a34,uint64_t a35,uint64_t a36,uint64_t a37,char a38)
{
}

void *std::pair<ZinIrOpLayer *,LayerTilingHelper>::~pair(void *a1)
{
  int v2 = (void *)a1[22];
  if (v2)
  {
    a1[23] = v2;
    operator delete(v2);
  }
  uint64_t v3 = (void *)a1[19];
  if (v3)
  {
    a1[20] = v3;
    operator delete(v3);
  }
  uint64_t v4 = (void *)a1[6];
  if (v4) {
    operator delete(v4);
  }
  uint64_t v5 = (void *)a1[3];
  if (v5)
  {
    a1[4] = v5;
    operator delete(v5);
  }
  return a1;
}

void LayerTilingHelper::~LayerTilingHelper(LayerTilingHelper *this)
{
  int v2 = (void *)*((void *)this + 21);
  if (v2)
  {
    *((void *)this + 22) = v2;
    operator delete(v2);
  }
  uint64_t v3 = (void *)*((void *)this + 18);
  if (v3)
  {
    *((void *)this + 19) = v3;
    operator delete(v3);
  }
  uint64_t v4 = (void *)*((void *)this + 5);
  if (v4) {
    operator delete(v4);
  }
  uint64_t v5 = (void *)*((void *)this + 2);
  if (v5)
  {
    *((void *)this + 3) = v5;
    operator delete(v5);
  }
}

void LayerTilingHelper::ToProduce(ZinIrOpLayer **this@<X0>, const TiledLayerTensorRegions::Id *a2@<X1>, const ZinTensorRegion *a3@<X2>, uint64_t a4@<X8>)
{
  if (ZinTensorRegion::IsValid(a3))
  {
    long long v55 = 0u;
    long long v56 = 0u;
    *(int64x2_t *)&v57[8] = vdupq_n_s64(1uLL);
    *(_OWORD *)&v57[24] = *(_OWORD *)&v57[8];
    *(void *)long long v57 = 0;
    *(void *)&v57[40] = 1;
    long long v58 = 0u;
    long long v59 = 0u;
    v60[5] = 0u;
    long long v61 = 0u;
    long long v8 = *((_OWORD *)a3 + 3);
    v60[2] = *((_OWORD *)a3 + 2);
    v60[3] = v8;
    v60[4] = *((_OWORD *)a3 + 4);
    long long v9 = *((_OWORD *)a3 + 1);
    v60[0] = *(_OWORD *)a3;
    v60[1] = v9;
    LayerTilingHelper::CalculateOutputRegion(this, 0, a3, (uint64_t)&v55);
    LayerTilingHelper::CalculateOutputRegion(this, 1, a3, (uint64_t)&v55);
    std::vector<LogicalDimensions>::vector(v54, 0x8E38E38E38E38E39 * ((this[3] - this[2]) >> 3));
    std::vector<ZinTensorRegion>::vector(v53, 0x8E38E38E38E38E39 * ((this[3] - this[2]) >> 3));
    unint64_t v10 = this[2];
    if (this[3] == v10)
    {
      unint64_t v32 = 0;
    }
    else
    {
      BOOL v39 = a2;
      uint64_t v11 = 0;
      uint64_t v12 = 0;
      unint64_t v13 = 0;
      unint64_t v14 = a3;
      do
      {
        BOOL v15 = (char *)v10 + v12;
        long long v16 = *(_OWORD *)v15;
        long long v17 = *((_OWORD *)v15 + 1);
        *(void *)&v57[40] = *((void *)v15 + 4);
        *(_OWORD *)&v57[8] = v16;
        *(_OWORD *)&v57[24] = v17;
        LayerTilingHelper::CalculateInputRegion(this, 0, v14, &v55);
        LayerTilingHelper::CalculateInputRegion(this, 1, v14, &v55);
        long long v18 = v58;
        long long v19 = v59;
        uint64_t v20 = *((void *)v14 + 5);
        if (v20 == *(void *)((*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)*this + 32))(*this, 0, 0)+ 48))
        {
          BOOL v21 = this[2];
          uint64_t v22 = *(void *)((char *)v21 + v12);
          unint64_t v14 = a3;
        }
        else
        {
          unint64_t v14 = a3;
          uint64_t v22 = *((void *)a3 + 5);
          *(void *)&long long v55 = *(void *)a3;
          BOOL v21 = this[2];
        }
        *(void *)&v57[8] = v22;
        uint64_t v23 = *(void *)((char *)v21 + v12 + 8);
        *(void *)&v57[16] = v23;
        uint64_t v24 = v19 + v18 + *(void *)&v57[24];
        uint64_t v25 = *((void *)&v19 + 1) + *((void *)&v18 + 1) + *(void *)&v57[32];
        uint64_t v26 = *(void *)&v57[40];
        uint64_t v27 = (char *)v54[0] + v12;
        *uint64_t v27 = v22;
        v27[1] = v23;
        v27[2] = v24;
        v27[3] = v25;
        v27[4] = v26;
        v27[5] = v18;
        v27[6] = v19;
        v27[7] = *((void *)&v18 + 1);
        v27[8] = *((void *)&v19 + 1);
        BOOL v28 = (char *)v53[0] + v11;
        long long v30 = v56;
        long long v29 = *(_OWORD *)v57;
        long long v31 = *(_OWORD *)&v57[32];
        v28[3] = *(_OWORD *)&v57[16];
        v28[4] = v31;
        v28[1] = v30;
        v28[2] = v29;
        *BOOL v28 = v55;
        ++v13;
        unint64_t v10 = this[2];
        unint64_t v32 = 0x8E38E38E38E38E39 * ((this[3] - v10) >> 3);
        v12 += 72;
        v11 += 80;
      }
      while (v13 < v32);
      a2 = v39;
    }
    std::vector<ZinTensorPosition>::vector(__p, v32, (long long *)a3);
    TiledLayerTensorRegions::TiledLayerTensorRegions((uint64_t)v40, (long long *)a2, v60, (uint64_t)__p, (uint64_t)v54, (uint64_t)v53, v61, *((uint64_t *)&v61 + 1));
    *(void *)(a4 + 96) = v42;
    *(void *)(a4 + 120) = v44;
    uint64_t v33 = v50;
    *(void *)(a4 + 144) = v46;
    long long v34 = v40[3];
    *(_OWORD *)(a4 + 32) = v40[2];
    *(_OWORD *)(a4 + 48) = v34;
    long long v35 = v40[1];
    *(_OWORD *)a4 = v40[0];
    *(_OWORD *)(a4 + 16) = v35;
    long long v36 = v41;
    *(_OWORD *)(a4 + 64) = v40[4];
    *(_OWORD *)(a4 + 80) = v36;
    long long v41 = 0uLL;
    *(_OWORD *)(a4 + 104) = v43;
    uint64_t v42 = 0;
    long long v43 = 0uLL;
    uint64_t v44 = 0;
    *(_OWORD *)(a4 + 128) = v45;
    long long v45 = 0uLL;
    uint64_t v46 = 0;
    long long v37 = v47;
    long long v38 = v48;
    *(_OWORD *)(a4 + 184) = v49;
    *(_OWORD *)(a4 + 168) = v38;
    *(_OWORD *)(a4 + 152) = v37;
    *(void *)(a4 + 200) = v33;
    *(_OWORD *)(a4 + 208) = v51;
    *(unsigned char *)(a4 + 224) = 1;
    if (__p[0])
    {
      __p[1] = __p[0];
      operator delete(__p[0]);
    }
    if (v53[0])
    {
      v53[1] = v53[0];
      operator delete(v53[0]);
    }
    if (v54[0])
    {
      v54[1] = v54[0];
      operator delete(v54[0]);
    }
  }
  else
  {
    *(unsigned char *)a4 = 0;
    *(unsigned char *)(a4 + 224) = 0;
  }
}

void sub_211265D90(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33,uint64_t a34,uint64_t a35,uint64_t a36,uint64_t a37,uint64_t a38,uint64_t a39,void *__p,uint64_t a41,uint64_t a42,void *a43,uint64_t a44,uint64_t a45,void *a46,uint64_t a47)
{
  if (__p) {
    operator delete(__p);
  }
  if (a43) {
    operator delete(a43);
  }
  if (a46) {
    operator delete(a46);
  }
  _Unwind_Resume(exception_object);
}

uint64_t LayerTilingHelper::CalculateOutputRegion(ZinIrOpLayer **a1, int a2, const ZinTensorRegion *a3, uint64_t a4)
{
  if (ZinIrOpLayer::IsANELayer(*a1)) {
    int v8 = (*(uint64_t (**)(ZinIrOpLayer *))(*(void *)*a1 + 408))(*a1) ^ 1;
  }
  else {
    LOBYTE(v8) = 1;
  }
  LayerTilingHelper::GetProgrammedOutRegion(a1, a3, (uint64_t)&v43);
  long long v9 = &v47;
  if (!a2) {
    long long v9 = &v46;
  }
  unint64_t v10 = (unint64_t *)&v44;
  if (a2) {
    unint64_t v10 = (unint64_t *)&v45;
  }
  unint64_t v11 = *v10;
  uint64_t v12 = a1 + 18;
  uint64_t v13 = 21;
  if (a2) {
    uint64_t v12 = a1 + 21;
  }
  else {
    uint64_t v13 = 18;
  }
  unint64_t v14 = a1[v13];
  unint64_t v15 = 0x6DB6DB6DB6DB6DB7 * ((v12[1] - v14) >> 3);
  if (v11 >= v15 || (unint64_t v16 = *v9, v17 = v16 + v11 - 1, v17 >= v15)) {
    ZinAssertImpl("Something is wrong in the realm of spatial splitting");
  }
  unint64_t v18 = *((void *)v14 + 7 * v11 + 1);
  unint64_t v19 = *((void *)v14 + 7 * v17 + 1);
  BOOL v37 = v19 >= v18;
  unint64_t v20 = v19 - v18;
  if (!v37) {
    ZinAssertImpl("Invalid Spatial Split Calculation");
  }
  BOOL v21 = (char *)v14 + 56 * v17;
  unint64_t v22 = *((void *)v21 + 2) + v20;
  unint64_t v23 = v22 + v21[25];
  if (!v23) {
    goto LABEL_46;
  }
  uint64_t v24 = (char *)v14 + 56 * v11;
  uint64_t v25 = *(void *)v24;
  uint64_t v26 = v24[24];
  uint64_t v27 = 9;
  if (!a2) {
    uint64_t v27 = 8;
  }
  BOOL v28 = a1[v27];
  uint64_t v29 = *((void *)v21 + 4);
  uint64_t v30 = 11;
  if (!a2) {
    uint64_t v30 = 10;
  }
  long long v31 = a1[v30];
  uint64_t v32 = 13;
  uint64_t result = 96;
  if (!a2) {
    uint64_t v32 = 12;
  }
  long long v34 = a1[v32];
  if (v31 == (ZinIrOpLayer *)2 && v34 == (ZinIrOpLayer *)1) {
    unint64_t v35 = (v25 + v26 + v29 + v22 - (unint64_t)v28) >> 1;
  }
  else {
    unint64_t v35 = v25 + v26 + v29 - (void)v28 + (void)v34 * v23;
  }
  unint64_t v36 = v35 + 1;
  BOOL v37 = v36 < v16 || v36 - v16 >= 2;
  if (v37) {
LABEL_46:
  }
    ZinAssertImpl("Internal Spatial Split Error");
  if (a2 == 1) {
    char v38 = v8;
  }
  else {
    char v38 = 1;
  }
  if (v38)
  {
    BOOL v37 = v36 >= v16;
    unint64_t v39 = v36 - v16;
    if (!v37) {
      unint64_t v39 = 0;
    }
    uint64_t v40 = 136;
    if (!a2) {
      uint64_t v40 = 128;
    }
    *(void *)(a4 + v40) = v11;
    uint64_t v41 = 176;
    if (!a2) {
      uint64_t v41 = 168;
    }
    *(void *)(a4 + v41) = v36;
    uint64_t v42 = 216;
    if (!a2) {
      uint64_t v42 = 208;
    }
    *(void *)(a4 + v42) = v39;
  }
  else
  {
    *(void *)(a4 + 120) = v11;
    *(void *)(a4 + 160) = v36;
    if (v36 > v16) {
      ZinAssertImpl("Error in the realm of spatial splitting");
    }
  }
  return result;
}

SplitPatternHandlerMgr *LayerTilingHelper::CalculateInputRegion(ZinIrOpLayer **a1, int a2, ZinTensorRegion *a3, long long *a4)
{
  LayerTilingHelper::GetProgrammedOutRegion(a1, a3, (uint64_t)&v44);
  uint64_t v7 = *((void *)*a1 + 8);
  if (*(_DWORD *)(v7 + 8) == 7)
  {
    int ConcatAxis = ZinConcatLayerUtils::GetConcatAxis(*(_DWORD *)(v7 + 12));
    int v9 = a2 ? 4 : 3;
    if (v9 == ConcatAxis)
    {
      long long v10 = a4[3];
      v45[1] = a4[2];
      long long v46 = v10;
      long long v47 = a4[4];
      long long v11 = a4[1];
      long long v44 = *a4;
      v45[0] = v11;
    }
  }
  uint64_t v12 = (unint64_t *)v45;
  if (a2) {
    uint64_t v12 = (unint64_t *)v45 + 1;
  }
  unint64_t v13 = *v12;
  uint64_t v14 = 21;
  if (a2)
  {
    unint64_t v15 = a1 + 21;
  }
  else
  {
    uint64_t v14 = 18;
    unint64_t v15 = a1 + 18;
  }
  unint64_t v16 = a1[v14];
  unint64_t v17 = 0x6DB6DB6DB6DB6DB7 * ((v15[1] - v16) >> 3);
  if (v17 <= v13) {
    goto LABEL_32;
  }
  unint64_t v18 = &v47;
  if (!a2) {
    unint64_t v18 = (long long *)((char *)&v46 + 8);
  }
  unint64_t v19 = v13 + *(void *)v18 - 1;
  if (v17 <= v19) {
LABEL_32:
  }
    std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
  unint64_t v20 = *((void *)v16 + 7 * v13 + 1);
  unint64_t v21 = *((void *)v16 + 7 * v19 + 1);
  BOOL v22 = v21 >= v20;
  unint64_t v23 = v21 - v20;
  if (!v22) {
    ZinAssertImpl("Invalid Spatial Split Calculation");
  }
  uint64_t v24 = *((void *)v16 + 7 * v13);
  uint64_t v25 = (uint64_t)v16 + 56 * v13;
  uint64_t v26 = *(unsigned __int8 *)(v25 + 24);
  uint64_t v27 = (uint64_t)v16 + 56 * v19;
  uint64_t v28 = *(void *)(v27 + 16);
  uint64_t v29 = *(unsigned __int8 *)(v27 + 25);
  uint64_t v30 = *(void *)(v27 + 32);
  uint64_t v31 = *(void *)(v25 + 40);
  uint64_t v32 = *(void *)(v27 + 48);
  uint64_t v33 = v24 + v26;
  uint64_t v34 = v20 - v31;
  uint64_t v35 = 88;
  if (!a2) {
    uint64_t v35 = 80;
  }
  *(void *)((char *)a4 + v35) = v33;
  uint64_t v36 = 104;
  if (!a2) {
    uint64_t v36 = 96;
  }
  *(void *)((char *)a4 + v36) = v30 - v31;
  uint64_t v37 = 24;
  if (!a2) {
    uint64_t v37 = 16;
  }
  *(void *)((char *)a4 + v37) = v34;
  unint64_t v38 = v28 + v29 + v23;
  unint64_t v39 = v38 + v31 + v32;
  uint64_t v40 = 64;
  if (!a2) {
    uint64_t v40 = 56;
  }
  *(void *)((char *)a4 + v40) = v39;
  unint64_t v41 = v38 + v24 + v30;
  uint64_t v42 = 200;
  if (!a2) {
    uint64_t v42 = 192;
  }
  *(void *)((char *)a4 + v42) = v41;
  uint64_t result = a1[1];
  if (result)
  {
    uint64_t result = (SplitPatternHandlerMgr *)SplitPatternHandlerMgr::IsLayerCreated(result, *a1);
    if (result) {
      return (SplitPatternHandlerMgr *)SplitPatternHandlerMgr::AdjustInputRegionOfTiledCombinedLayer((uint64_t)a1[1], (uint64_t)*a1);
    }
  }
  return result;
}

void LayerTilingHelper::ProduceConcatRegionAfterOutputNode(long long *a1@<X0>, long long **a2@<X1>, int a3@<W2>, uint64_t a4@<X8>)
{
  uint64_t v5 = a1;
  uint64_t v91 = 0;
  long long v92 = 0;
  uint64_t v93 = 0;
  uint64_t v88 = 0;
  uint64_t v89 = 0;
  uint64_t v90 = 0;
  uint64_t v85 = 0;
  uint64_t v86 = 0;
  uint64_t v87 = 0;
  unint64_t v6 = *a2;
  uint64_t v7 = a2[1];
  if (*a2 == v7)
  {
    BOOL v52 = 0;
    uint64_t v53 = 0;
  }
  else
  {
    do
    {
      long long v82 = *v6;
      long long v83 = v6[1];
      uint64_t v8 = *((void *)v6 + 5);
      *(void *)BOOL v84 = *((void *)v6 + 4);
      uint64_t v9 = *((void *)v6 + 6);
      uint64_t v10 = *((void *)v6 + 9);
      int64x2_t v74 = *(int64x2_t *)((char *)v6 + 184);
      int64x2_t v75 = *(int64x2_t *)((char *)v6 + 56);
      long long v77 = *v6;
      long long v78 = v6[1];
      *(void *)&long long v79 = *((void *)v6 + 4);
      long long v11 = v92;
      if (v92 >= v93)
      {
        unint64_t v15 = v91;
        unint64_t v16 = 0xCCCCCCCCCCCCCCCDLL * ((v92 - v91) >> 3);
        unint64_t v17 = v16 + 1;
        if (v16 + 1 > 0x666666666666666) {
          std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
        }
        if (0x999999999999999ALL * ((v93 - v91) >> 3) > v17) {
          unint64_t v17 = 0x999999999999999ALL * ((v93 - v91) >> 3);
        }
        if (0xCCCCCCCCCCCCCCCDLL * ((v93 - v91) >> 3) >= 0x333333333333333) {
          unint64_t v18 = 0x666666666666666;
        }
        else {
          unint64_t v18 = v17;
        }
        if (v18)
        {
          unint64_t v19 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ZinMirInterchangeInfo>>((uint64_t)&v93, v18);
          unint64_t v15 = v91;
          long long v11 = v92;
        }
        else
        {
          unint64_t v19 = 0;
        }
        unint64_t v20 = &v19[40 * v16];
        *(_OWORD *)unint64_t v20 = v82;
        *((_OWORD *)v20 + 1) = v83;
        *((void *)v20 + 4) = *(void *)v84;
        if (v11 == v15)
        {
          uint64_t v24 = &v19[40 * v16];
        }
        else
        {
          unint64_t v21 = &v19[40 * v16];
          do
          {
            long long v22 = *(_OWORD *)(v11 - 40);
            long long v23 = *(_OWORD *)(v11 - 24);
            uint64_t v24 = v21 - 40;
            *((void *)v21 - 1) = *((void *)v11 - 1);
            *(_OWORD *)(v21 - 24) = v23;
            *(_OWORD *)(v21 - 40) = v22;
            v11 -= 40;
            v21 -= 40;
          }
          while (v11 != v15);
        }
        uint64_t v14 = v20 + 40;
        uint64_t v91 = v24;
        long long v92 = v20 + 40;
        uint64_t v93 = &v19[40 * v18];
        if (v15) {
          operator delete(v15);
        }
      }
      else
      {
        long long v12 = *v6;
        long long v13 = v6[1];
        *((void *)v92 + 4) = *((void *)v6 + 4);
        *(_OWORD *)long long v11 = v12;
        *((_OWORD *)v11 + 1) = v13;
        uint64_t v14 = v11 + 40;
      }
      int64x2_t v25 = vsubq_s64(v75, v74);
      long long v92 = v14;
      uint64_t v26 = v89;
      int64x2_t v76 = v25;
      if (v89 >= v90)
      {
        uint64_t v28 = v88;
        unint64_t v29 = 0xCCCCCCCCCCCCCCCDLL * ((v89 - v88) >> 4);
        unint64_t v30 = v29 + 1;
        if (v29 + 1 > 0x333333333333333) {
          std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
        }
        if (0x999999999999999ALL * ((v90 - v88) >> 4) > v30) {
          unint64_t v30 = 0x999999999999999ALL * ((v90 - v88) >> 4);
        }
        if (0xCCCCCCCCCCCCCCCDLL * ((v90 - v88) >> 4) >= 0x199999999999999) {
          unint64_t v31 = 0x333333333333333;
        }
        else {
          unint64_t v31 = v30;
        }
        if (v31)
        {
          uint64_t v32 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ZinIrCodegenTDPartitionStats>>((uint64_t)&v90, v31);
          uint64_t v28 = v88;
          uint64_t v26 = v89;
        }
        else
        {
          uint64_t v32 = 0;
        }
        uint64_t v33 = &v32[80 * v29];
        *(_OWORD *)uint64_t v33 = v77;
        *((_OWORD *)v33 + 1) = v78;
        *((void *)v33 + 4) = v79;
        *((void *)v33 + 5) = v8;
        *((void *)v33 + 6) = v9;
        *(int64x2_t *)(v33 + 56) = v76;
        *((void *)v33 + 9) = v10;
        if (v26 == v28)
        {
          unint64_t v38 = &v32[80 * v29];
        }
        else
        {
          uint64_t v34 = &v32[80 * v29];
          do
          {
            *((_OWORD *)v34 - 5) = *((_OWORD *)v26 - 5);
            long long v35 = *((_OWORD *)v26 - 4);
            long long v36 = *((_OWORD *)v26 - 3);
            long long v37 = *((_OWORD *)v26 - 1);
            unint64_t v38 = v34 - 80;
            *((_OWORD *)v34 - 2) = *((_OWORD *)v26 - 2);
            *((_OWORD *)v34 - 1) = v37;
            *((_OWORD *)v34 - 4) = v35;
            *((_OWORD *)v34 - 3) = v36;
            v26 -= 80;
            v34 -= 80;
          }
          while (v26 != v28);
        }
        uint64_t v27 = v33 + 80;
        uint64_t v88 = v38;
        uint64_t v89 = v33 + 80;
        uint64_t v90 = &v32[80 * v31];
        if (v28) {
          operator delete(v28);
        }
      }
      else
      {
        *(_OWORD *)uint64_t v89 = v77;
        *((_OWORD *)v26 + 1) = v78;
        *((void *)v26 + 4) = v79;
        *((void *)v26 + 5) = v8;
        *((void *)v26 + 6) = v9;
        *(int64x2_t *)(v26 + 56) = v25;
        *((void *)v26 + 9) = v10;
        uint64_t v27 = v26 + 80;
      }
      uint64_t v89 = v27;
      unint64_t v39 = v86;
      if (v86 >= v87)
      {
        unint64_t v41 = v85;
        unint64_t v42 = 0x8E38E38E38E38E39 * ((v86 - v85) >> 3);
        unint64_t v43 = v42 + 1;
        if (v42 + 1 > 0x38E38E38E38E38ELL) {
          std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
        }
        if (0x1C71C71C71C71C72 * ((v87 - v85) >> 3) > v43) {
          unint64_t v43 = 0x1C71C71C71C71C72 * ((v87 - v85) >> 3);
        }
        if (0x8E38E38E38E38E39 * ((v87 - v85) >> 3) >= 0x1C71C71C71C71C7) {
          unint64_t v44 = 0x38E38E38E38E38ELL;
        }
        else {
          unint64_t v44 = v43;
        }
        if (v44)
        {
          uint64_t v45 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ANEDebugInfo::DebugInfoInMem::TD>>((uint64_t)&v87, v44);
          unint64_t v41 = v85;
          unint64_t v39 = v86;
        }
        else
        {
          uint64_t v45 = 0;
        }
        long long v46 = &v45[8 * ((v86 - v85) >> 3)];
        *(void *)long long v46 = v8;
        *((void *)v46 + 1) = v9;
        *((int64x2_t *)v46 + 1) = v76;
        *((void *)v46 + 4) = v10;
        *(_OWORD *)(v46 + 40) = 0u;
        *(_OWORD *)(v46 + 56) = 0u;
        if (v39 == v41)
        {
          long long v51 = &v45[72 * v42];
        }
        else
        {
          long long v47 = &v45[72 * v42];
          do
          {
            *(_OWORD *)(v47 - 72) = *(_OWORD *)(v39 - 72);
            long long v48 = *(_OWORD *)(v39 - 56);
            long long v49 = *(_OWORD *)(v39 - 40);
            long long v50 = *(_OWORD *)(v39 - 24);
            long long v51 = v47 - 72;
            *((void *)v47 - 1) = *((void *)v39 - 1);
            *(_OWORD *)(v47 - 24) = v50;
            *(_OWORD *)(v47 - 40) = v49;
            *(_OWORD *)(v47 - 56) = v48;
            v39 -= 72;
            v47 -= 72;
          }
          while (v39 != v41);
        }
        uint64_t v40 = v46 + 72;
        uint64_t v85 = v51;
        uint64_t v86 = v46 + 72;
        uint64_t v87 = &v45[72 * v44];
        if (v41) {
          operator delete(v41);
        }
      }
      else
      {
        *(void *)uint64_t v86 = v8;
        *((void *)v39 + 1) = v9;
        *((int64x2_t *)v39 + 1) = v76;
        *((void *)v39 + 4) = v10;
        *(_OWORD *)(v39 + 40) = 0u;
        uint64_t v40 = v39 + 72;
        *(_OWORD *)(v39 + 56) = 0u;
      }
      uint64_t v86 = v40;
      v6 += 14;
    }
    while (v6 != v7);
    BOOL v52 = v88;
    uint64_t v53 = v89;
    uint64_t v5 = a1;
  }
  if (v53 - (char *)v52 != 80)
  {
    uint64_t v54 = 0;
    unint64_t v55 = 0;
    unint64_t v56 = 0xCCCCCCCCCCCCCCCDLL * ((v53 - (char *)v52) >> 4);
    do
    {
      if (v56 <= v55) {
        std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
      }
      long long v57 = &v52[v54];
      long long v82 = *v57;
      long long v58 = v57[1];
      long long v59 = v57[2];
      long long v60 = v57[4];
      *(_OWORD *)&v84[16] = v57[3];
      *(_OWORD *)&v84[32] = v60;
      long long v83 = v58;
      *(_OWORD *)BOOL v84 = v59;
      if (v56 <= ++v55) {
        std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
      }
      long long v77 = v57[5];
      long long v61 = v57[6];
      long long v62 = v57[7];
      long long v63 = v57[9];
      long long v80 = v57[8];
      long long v81 = v63;
      long long v78 = v61;
      long long v79 = v62;
      uint64_t ValueAt = GetValueAtDimension<ZinTensorPosition>((uint64_t *)&v82, a3);
      uint64_t v65 = GetValueAtDimension<ZinTensorDimensions>((uint64_t *)&v84[8], a3);
      if (v65 + ValueAt != GetValueAtDimension<ZinTensorPosition>((uint64_t *)&v77, a3)) {
        ZinAssertImpl("Spatial Split Internal Error");
      }
      BOOL v52 = v88;
      uint64_t v53 = v89;
      unint64_t v56 = 0xCCCCCCCCCCCCCCCDLL * ((v89 - v88) >> 4);
      v54 += 5;
    }
    while (v56 - 1 > v55);
  }
  *(void *)BOOL v84 = 0;
  long long v82 = 0u;
  long long v83 = 0u;
  *(int64x2_t *)&v84[8] = vdupq_n_s64(1uLL);
  *(_OWORD *)&v84[24] = *(_OWORD *)&v84[8];
  *(void *)&v84[40] = 1;
  long long v66 = *v52;
  long long v67 = v52[1];
  *(void *)BOOL v84 = *((void *)v52 + 4);
  long long v82 = v66;
  long long v83 = v67;
  uint64_t v68 = *((void *)v52 + 9);
  long long v69 = *(_OWORD *)((char *)v52 + 56);
  *(_OWORD *)&v84[8] = *(_OWORD *)((char *)v52 + 40);
  *(_OWORD *)&v84[24] = v69;
  *(void *)&v84[40] = v68;
  uint64_t v70 = GetValueAtDimension<ZinTensorPosition>((uint64_t *)v53 - 10, a3);
  uint64_t v71 = GetValueAtDimension<ZinTensorDimensions>((uint64_t *)v89 - 5, a3);
  if (SetValueAtDimension<ZinTensorDimensions>(&v84[8], a3, v71 + v70)) {
    ZinAssertImpl("Spatial Splitting Intenral Error");
  }
  TiledLayerTensorRegions::TiledLayerTensorRegions(a4, v5, &v82, (uint64_t)&v91, (uint64_t)&v85, (uint64_t)&v88, 0, 0);
  if (v85)
  {
    uint64_t v86 = v85;
    operator delete(v85);
  }
  if (v88)
  {
    uint64_t v89 = v88;
    operator delete(v88);
  }
  if (v91)
  {
    long long v92 = v91;
    operator delete(v91);
  }
}

void sub_21126694C(_Unwind_Exception *exception_object)
{
  uint64_t v3 = *(void **)(v1 - 168);
  if (v3)
  {
    *(void *)(v1 - 160) = v3;
    operator delete(v3);
  }
  uint64_t v4 = *(void **)(v1 - 144);
  if (v4)
  {
    *(void *)(v1 - 136) = v4;
    operator delete(v4);
  }
  uint64_t v5 = *(void **)(v1 - 120);
  if (v5)
  {
    *(void *)(v1 - 112) = v5;
    operator delete(v5);
  }
  _Unwind_Resume(exception_object);
}

uint64_t LayerTilingHelper::GetProgrammedOutRegion@<X0>(ZinIrOpLayer **this@<X0>, const ZinTensorRegion *a2@<X1>, uint64_t a3@<X8>)
{
  long long v6 = *((_OWORD *)a2 + 3);
  *(_OWORD *)(a3 + 32) = *((_OWORD *)a2 + 2);
  *(_OWORD *)(a3 + 48) = v6;
  *(_OWORD *)(a3 + 64) = *((_OWORD *)a2 + 4);
  long long v7 = *((_OWORD *)a2 + 1);
  *(_OWORD *)a3 = *(_OWORD *)a2;
  *(_OWORD *)(a3 + 16) = v7;
  uint64_t result = ZinIrOpLayer::IsANELayer(*this);
  if (result)
  {
    uint64_t v9 = *this;
    uint64_t result = (*(uint64_t (**)(ZinIrOpLayer *))(*(void *)v9 + 408))(v9);
    if (result)
    {
      uint64_t v10 = (ZinReshapeLayer *)(*(uint64_t (**)(ZinIrOpLayer *))(*(void *)v9 + 416))(v9);
      uint64_t v11 = ZinReshapeLayer::GetReshapeInfo(v10) + 16;
      ZinIrTransposeUnitInfo::InverseTransposeDimensions<ZinTensorDimensions>((void *)a2 + 5, v11, (void *)(a3 + 40));
      return ZinIrTransposeUnitInfo::InverseTransposeDimensions<ZinTensorPosition>(a2, v11, (void *)a3);
    }
  }
  return result;
}

uint64_t ZinIrTransposeUnitInfo::InverseTransposeDimensions<ZinTensorPosition>(void *a1, uint64_t a2, void *a3)
{
  uint64_t v3 = *(_DWORD **)a2;
  uint64_t v4 = *(_DWORD **)(a2 + 8);
  if (*(_DWORD **)a2 != v4)
  {
    while (2)
    {
      uint64_t v5 = a1;
      switch(v3[1])
      {
        case 0:
          goto LABEL_7;
        case 1:
          uint64_t v5 = a1 + 4;
          goto LABEL_7;
        case 2:
          uint64_t v5 = a1 + 1;
          goto LABEL_7;
        case 3:
          uint64_t v5 = a1 + 2;
          goto LABEL_7;
        case 4:
          uint64_t v5 = a1 + 3;
LABEL_7:
          long long v6 = a3 + 3;
          switch(*v3)
          {
            case 0:
              long long v6 = a3;
              break;
            case 1:
              long long v6 = a3 + 4;
              break;
            case 2:
              long long v6 = a3 + 1;
              break;
            case 3:
              long long v6 = a3 + 2;
              break;
            case 4:
              break;
            default:
              return 3;
          }
          void *v6 = *v5;
          v3 += 2;
          if (v3 == v4) {
            return 0;
          }
          continue;
        default:
          return 3;
      }
    }
  }
  return 0;
}

BOOL TiledLayerTensorRegions::IsPerformanceEquivalent(TiledLayerTensorRegions *this, const TiledLayerTensorRegions *a2)
{
  uint64_t v2 = *((void *)this + 16);
  uint64_t v3 = *((void *)this + 17);
  if (v3 - v2 != *((void *)a2 + 17) - *((void *)a2 + 16)
    || (long long v6 = (char *)*((void *)this + 13),
        long long v7 = (char *)*((void *)this + 14),
        int64_t v8 = v7 - v6,
        uint64_t v9 = (void *)*((void *)a2 + 13),
        uint64_t v10 = *((void *)a2 + 14) - (void)v9,
        v7 - v6 != v10))
  {
    ZinAssertImpl("Spatial Split Internal Error");
  }
  if (v3 == v2)
  {
LABEL_9:
    if (v8 == v10)
    {
      while (v6 != v7)
      {
        BOOL result = LogicalDimensions::operator==(v6, v9);
        if (!result) {
          return result;
        }
        v6 += 72;
        v9 += 9;
      }
      if (!ZinTensorDimensions::operator!=((void *)this + 5, (void *)a2 + 5)
        && *((void *)this + 23) == *((void *)a2 + 23)
        && *((void *)this + 24) == *((void *)a2 + 24))
      {
        return 1;
      }
    }
  }
  else
  {
    unint64_t v11 = 0;
    uint64_t v12 = 40;
    while (1)
    {
      uint64_t v13 = *((void *)a2 + 16);
      if (0xCCCCCCCCCCCCCCCDLL * ((*((void *)a2 + 17) - v13) >> 4) <= v11) {
        std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
      }
      if (ZinTensorDimensions::operator!=((void *)(v2 + v12), (void *)(v13 + v12))) {
        break;
      }
      ++v11;
      uint64_t v2 = *((void *)this + 16);
      v12 += 80;
      if (v11 >= 0xCCCCCCCCCCCCCCCDLL * ((*((void *)this + 17) - v2) >> 4))
      {
        long long v6 = (char *)*((void *)this + 13);
        long long v7 = (char *)*((void *)this + 14);
        uint64_t v9 = (void *)*((void *)a2 + 13);
        int64_t v8 = v7 - v6;
        uint64_t v10 = *((void *)a2 + 14) - (void)v9;
        goto LABEL_9;
      }
    }
  }
  return 0;
}

uint64_t SplitInfo::Construct(ProducerConsumerChain *a1, unint64_t a2, unint64_t a3, uint64_t a4, int a5, uint64_t a6, ZinIrOpLayer *a7)
{
  uint64_t v28 = *MEMORY[0x263EF8340];
  LOBYTE(v16) = 0;
  char v25 = 0;
  memset(v15, 0, sizeof(v15));
  uint64_t v12 = LayerTilingHelper::Create(a1, a7, v15, (LayerTilingHelper *)a4);
  if (!v12)
  {
    uint64_t v12 = SplitInfo::TryToConstruct(a1, a2, a3, (uint64_t)&v16, 0, a6, v15);
    if (!v12)
    {
      if (v25)
      {
        if (&v16 != (uint64_t **)a4)
        {
          std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__assign_with_size[abi:ne180100]<std::vector<std::optional<TiledLayerTensorRegions>>*,std::vector<std::optional<TiledLayerTensorRegions>>*>(a4, v16, v17, 0xAAAAAAAAAAAAAAABLL * (v17 - v16));
          *(_DWORD *)(a4 + 56) = v19;
          std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,void *> *>>((void *)(a4 + 24), v18, 0);
          *(_DWORD *)(a4 + 96) = v21;
          std::__hash_table<ZinIrOpLayer *,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,std::allocator<ZinIrOpLayer *>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<ZinIrOpLayer *,void *> *>>((void *)(a4 + 64), v20, 0);
        }
        uint64_t v12 = 0;
        *(_OWORD *)(a4 + 104) = v22;
        *(_OWORD *)(a4 + 120) = v23;
        *(unsigned char *)(a4 + 136) = v24;
      }
      else
      {
        if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR))
        {
          ProducerConsumerChain::ToString(a1, v14);
          SplitInfo::Construct(a3, a2, (char *)v14, buf);
        }
        uint64_t v12 = 3;
      }
    }
  }
  uint64_t v26 = (void **)v15;
  std::vector<LayerTilingHelper>::__destroy_vector::operator()[abi:ne180100](&v26);
  std::__optional_destruct_base<SplitInfo,false>::~__optional_destruct_base[abi:ne180100]((uint64_t)&v16);
  return v12;
}

void sub_211266EB4(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, char a12, uint64_t a13, uint64_t a14, char a15)
{
}

uint64_t SplitInfo::TryToConstruct(ProducerConsumerChain *a1, unint64_t a2, unint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t *a7)
{
  std::__optional_destruct_base<SplitInfo,false>::reset[abi:ne180100](a4);
  if (!a2
    || *(void *)(*(void *)(*(uint64_t (**)(void, void, void))(**(void **)(*((void *)a1 + 2) - 8)
                                                                                + 40))(*(void *)(*((void *)a1 + 2) - 8), 0, 0)+ 64) < a2)
  {
    BOOL v12 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (v12) {
      SplitInfo::TryToConstruct(v12, v13, v14, v15, v16, v17, v18, v19);
    }
    return 3;
  }
  if (!a3
    || *(void *)(*(void *)(*(uint64_t (**)(void, void, void))(**(void **)(*((void *)a1 + 2) - 8)
                                                                                + 40))(*(void *)(*((void *)a1 + 2) - 8), 0, 0)+ 72) < a3)
  {
    BOOL v20 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (v20) {
      SplitInfo::TryToConstruct(v20, v21, v22, v23, v24, v25, v26, v27);
    }
    return 3;
  }
  uint64_t v78 = a2;
  uint64_t v76 = a4;
  uint64_t v97 = 0;
  memset(v96, 0, sizeof(v96));
  long long v95 = 0u;
  int v98 = 1065353216;
  memset(v99, 0, sizeof(v99));
  int v100 = 1065353216;
  int64x2_t v101 = vdupq_n_s64(1uLL);
  int64x2_t v102 = v101;
  uint64_t v30 = (*(uint64_t (**)(void, void, void))(**(void **)(*((void *)a1 + 2) - 8) + 40))(*(void *)(*((void *)a1 + 2) - 8), 0, 0);
  uint64_t v31 = *(void *)v30;
  uint64_t v32 = *(void *)(*(void *)v30 + 64);
  if (v32 < 1)
  {
LABEL_43:
    std::optional<SplitInfo>::operator=[abi:ne180100]<SplitInfo&,void>(v76, (uint64_t)&v95);
    uint64_t v28 = 0;
  }
  else
  {
    uint64_t v33 = 0;
    uint64_t v34 = 0;
    uint64_t v35 = 0;
    long long v83 = *(_OWORD *)(v31 + 48);
    uint64_t v36 = *(void *)(v31 + 72);
    uint64_t v82 = *(void *)(v31 + 80);
    uint64_t v79 = v36;
    unint64_t v80 = a3;
    uint64_t v77 = *(void *)(*(void *)v30 + 64);
    while (1)
    {
      uint64_t v37 = v32 - v33;
      if (v32 - v33 >= v78) {
        uint64_t v37 = v78;
      }
      uint64_t v84 = v37;
      if (v36 >= 1) {
        break;
      }
LABEL_42:
      uint64_t v32 = v77;
      v33 += v78;
      ++v35;
      if (v33 >= v77) {
        goto LABEL_43;
      }
    }
    uint64_t v38 = 0;
    uint64_t v81 = v33;
    while (1)
    {
      uint64_t v39 = *((void *)&v95 + 1);
      uint64_t v85 = v38;
      if (*((void *)&v95 + 1) >= *(void *)&v96[0])
      {
        unint64_t v41 = 0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*((void *)&v95 + 1) - v95) >> 3);
        unint64_t v42 = v41 + 1;
        if (v41 + 1 > 0xAAAAAAAAAAAAAAALL) {
          std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
        }
        if (0x5555555555555556 * ((uint64_t)(*(void *)&v96[0] - v95) >> 3) > v42) {
          unint64_t v42 = 0x5555555555555556 * ((uint64_t)(*(void *)&v96[0] - v95) >> 3);
        }
        unint64_t v43 = 0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*(void *)&v96[0] - v95) >> 3) >= 0x555555555555555
            ? 0xAAAAAAAAAAAAAAALL
            : v42;
        v88[4] = v96;
        unint64_t v44 = v43 ? (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<std::string>>((uint64_t)v96, v43) : 0;
        uint64_t v45 = &v44[24 * v41];
        v88[0] = v44;
        v88[1] = v45;
        v88[3] = &v44[24 * v43];
        *(void *)uint64_t v45 = 0;
        *((void *)v45 + 1) = 0;
        *((void *)v45 + 2) = 0;
        v88[2] = v45 + 24;
        std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__swap_out_circular_buffer((uint64_t *)&v95, v88);
        uint64_t v40 = *((void *)&v95 + 1);
        std::__split_buffer<std::vector<std::optional<TiledLayerTensorRegions>>>::~__split_buffer(v88);
        uint64_t v38 = v85;
      }
      else
      {
        **((void **)&v95 + 1) = 0;
        *(void *)(v39 + 8) = 0;
        uint64_t v40 = v39 + 24;
        *(void *)(v39 + 16) = 0;
      }
      *((void *)&v95 + 1) = v40;
      unint64_t v46 = v36 - v38;
      if (v36 - v38 >= (uint64_t)a3) {
        unint64_t v46 = a3;
      }
      *(void *)&long long v92 = v33;
      *((void *)&v92 + 1) = v38;
      long long v91 = 0uLL;
      *(void *)uint64_t v93 = 0;
      *(void *)&v93[24] = v84;
      *(void *)&long long v94 = v46;
      *(_OWORD *)&v93[8] = v83;
      *((void *)&v94 + 1) = v82;
      uint64_t v47 = *((void *)a1 + 1);
      unint64_t v48 = (*((void *)a1 + 2) - v47) >> 3;
      unint64_t v49 = v48 - 1;
      uint64_t v90 = 0;
      uint64_t v50 = (*(uint64_t (**)(void, void, void))(**(void **)(v47 + 8 * (v48 - 1)) + 32))(*(void *)(v47 + 8 * (v48 - 1)), 0, 0);
      if (ZinTensorFormatGetSizeInBytes(*(_DWORD *)(v50 + 88), &v90)) {
        ZinAssertImpl("Error in getting tensor format size in bytes");
      }
      if ((unint64_t)(v90 * *((void *)&v92 + 1)) % *(void *)(a6 + 528)) {
        break;
      }
      long long v51 = (void *)(v40 - 24);
      std::vector<std::optional<TiledLayerTensorRegions>>::resize((uint64_t *)(v40 - 24), v48);
      uint64_t v52 = *a7;
      if (0xAAAAAAAAAAAAAAABLL * ((a7[1] - *a7) >> 6) <= v49) {
LABEL_53:
      }
        std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
      uint64_t v53 = 192 * v48 - 192;
      uint64_t v54 = 232 * v48;
      while (1)
      {
        v87[0] = v49;
        v87[1] = 0;
        v87[2] = v35;
        v87[3] = v34;
        LayerTilingHelper::ToProduce((ZinIrOpLayer **)(v52 + v53), (const TiledLayerTensorRegions::Id *)v87, (const ZinTensorRegion *)&v91, (uint64_t)v88);
        if (!v89) {
          ZinAssertImpl("Spatial Splitting Internal Error");
        }
        std::__optional_storage_base<TiledLayerTensorRegions,false>::__assign_from[abi:ne180100]<std::__optional_copy_assign_base<TiledLayerTensorRegions,false> const&>((TiledLayerTensorRegions *)(*v51 + v54 - 232), (TiledLayerTensorRegions *)v88);
        uint64_t v55 = *v51 + v54;
        if (!*(unsigned char *)(v55 - 8)) {
          std::__throw_bad_optional_access[abi:ne180100]();
        }
        unint64_t v56 = (long long *)(*(void *)(v55 - 104)
                         + 80
                         * ProducerConsumerChain::GetIncomingLayerIndexInChain(a1, *(const ZinANELayer **)(*((void *)a1 + 1) + 8 * v49)));
        long long v91 = *v56;
        long long v57 = v56[1];
        long long v58 = v56[2];
        long long v59 = v56[4];
        *(_OWORD *)&v93[16] = v56[3];
        long long v94 = v59;
        long long v92 = v57;
        *(_OWORD *)uint64_t v93 = v58;
        if (!v49) {
          break;
        }
        --v49;
        std::__optional_destruct_base<TiledLayerTensorRegions,false>::~__optional_destruct_base[abi:ne180100]((uint64_t)v88);
        uint64_t v52 = *a7;
        v53 -= 192;
        v54 -= 232;
        if (0xAAAAAAAAAAAAAAABLL * ((a7[1] - *a7) >> 6) <= v49) {
          goto LABEL_53;
        }
      }
      if ((unint64_t)(v90 * *((void *)&v92 + 1)) % *(void *)(a6 + 528))
      {
        BOOL v68 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
        if (v68) {
          SplitInfo::TryToConstruct(v68, v69, v70, v71, v72, v73, v74, v75);
        }
        std::__optional_destruct_base<TiledLayerTensorRegions,false>::~__optional_destruct_base[abi:ne180100]((uint64_t)v88);
        goto LABEL_49;
      }
      std::__optional_destruct_base<TiledLayerTensorRegions,false>::~__optional_destruct_base[abi:ne180100]((uint64_t)v88);
      uint64_t v36 = v79;
      a3 = v80;
      uint64_t v38 = v85 + v80;
      ++v34;
      uint64_t v33 = v81;
      if ((uint64_t)(v85 + v80) >= v79) {
        goto LABEL_42;
      }
    }
    BOOL v60 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (v60) {
      SplitInfo::TryToConstruct(v60, v61, v62, v63, v64, v65, v66, v67);
    }
LABEL_49:
    uint64_t v28 = 3;
  }
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v99);
  std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::~__hash_table((uint64_t)v96 + 8);
  v88[0] = &v95;
  std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__destroy_vector::operator()[abi:ne180100]((void ***)v88);
  return v28;
}

void sub_211267474(_Unwind_Exception *a1)
{
  SplitInfo::~SplitInfo((void **)(v1 - 240));
  _Unwind_Resume(a1);
}

void std::__optional_destruct_base<SplitInfo,false>::reset[abi:ne180100](uint64_t a1)
{
  if (*(unsigned char *)(a1 + 144))
  {
    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table(a1 + 64);
    std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::~__hash_table(a1 + 24);
    uint64_t v2 = (void **)a1;
    std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__destroy_vector::operator()[abi:ne180100](&v2);
    *(unsigned char *)(a1 + 144) = 0;
  }
}

uint64_t std::optional<SplitInfo>::operator=[abi:ne180100]<SplitInfo&,void>(uint64_t a1, uint64_t a2)
{
  if (*(unsigned char *)(a1 + 144))
  {
    if (a1 != a2)
    {
      std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__assign_with_size[abi:ne180100]<std::vector<std::optional<TiledLayerTensorRegions>>*,std::vector<std::optional<TiledLayerTensorRegions>>*>(a1, *(uint64_t **)a2, *(uint64_t **)(a2 + 8), 0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*(void *)(a2 + 8) - *(void *)a2) >> 3));
      *(_DWORD *)(a1 + 56) = *(_DWORD *)(a2 + 56);
      std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,void *> *>>((void *)(a1 + 24), *(void **)(a2 + 40), 0);
      *(_DWORD *)(a1 + 96) = *(_DWORD *)(a2 + 96);
      std::__hash_table<ZinIrOpLayer *,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,std::allocator<ZinIrOpLayer *>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<ZinIrOpLayer *,void *> *>>((void *)(a1 + 64), *(void **)(a2 + 80), 0);
    }
    long long v4 = *(_OWORD *)(a2 + 104);
    long long v5 = *(_OWORD *)(a2 + 120);
    *(unsigned char *)(a1 + 136) = *(unsigned char *)(a2 + 136);
    *(_OWORD *)(a1 + 120) = v5;
    *(_OWORD *)(a1 + 104) = v4;
  }
  else
  {
    std::construct_at[abi:ne180100]<SplitInfo,SplitInfo&,SplitInfo*>(a1, a2);
    *(unsigned char *)(a1 + 144) = 1;
  }
  return a1;
}

void *SplitInfoMetrics::SplitInfoMetrics(void *a1, uint64_t a2, uint64_t a3, int a4, uint64_t a5, void *a6)
{
  *a1 = a5;
  a1[1] = a6;
  a1[2] = a3;
  unint64_t v11 = (uint64_t)(*(void *)(a5 + 16) - *(void *)(a5 + 8)) >> 3;
  uint64_t v50 = (ZinIrKernel *)1;
  unint64_t v46 = (unint64_t **)(a1 + 7);
  std::vector<unsigned long>::vector(a1 + 7, v11, &v50);
  uint64_t v48 = a2;
  a1[10] = a2;
  *((_DWORD *)a1 + 22) = a4;
  uint64_t v12 = **(void **)(**(void **)(*a1 + 8) + 88);
  uint64_t v13 = (ZinIrTensor *)(*(uint64_t (**)(uint64_t, void, void))(*(void *)v12 + 32))(v12, 0, 0);
  RootTensor = ZinIrTensor::GetRootTensor(v13);
  a1[3] = SplitInfoMetrics::GetSize((SplitInfoMetrics *)a1, RootTensor, (ZinIrTensor *)((char *)RootTensor + 48));
  a1[4] = v15;
  uint64_t v16 = *(void *)(*(void *)(*a1 + 16) - 8);
  uint64_t v17 = (ZinIrTensor **)(*(uint64_t (**)(uint64_t, void, void))(*(void *)v16 + 40))(v16, 0, 0);
  uint64_t v18 = ZinIrTensor::GetRootTensor(*v17);
  a1[5] = SplitInfoMetrics::GetSize((SplitInfoMetrics *)a1, v18, (ZinIrTensor *)((char *)v18 + 48));
  a1[6] = v19;
  a1[12] = 0;
  BOOL v20 = *(ZinIrOpLayer ***)(*a1 + 8);
  uint64_t v21 = *(ZinIrOpLayer ***)(a5 + 16);
  if (v20 == v21)
  {
    unint64_t v22 = 0;
  }
  else
  {
    unint64_t v22 = 0;
    do
    {
      uint64_t v23 = *v20;
      if (!ZinIrOpLayer::IsPELayer(*v20))
      {
        (*(void (**)(ZinIrKernel **__return_ptr, ZinIrOpLayer *, uint64_t))(*(void *)v23 + 568))(&v50, v23, 1);
        uint64_t v24 = v50;
        if (v50)
        {
          if (*((void *)v50 + 73)) {
            BOOL v25 = 1;
          }
          else {
            BOOL v25 = *((void *)v50 + 77) != 0;
          }
          uint64_t v50 = 0;
          ZinIrKernel::~ZinIrKernel(v24);
          MEMORY[0x21667D3C0]();
          v22 += v25;
        }
      }
      ++v20;
    }
    while (v20 != v21);
    BOOL v20 = *(ZinIrOpLayer ***)(*a1 + 8);
  }
  uint64_t v28 = a6;
  uint64_t v26 = *a6;
  uint64_t v27 = v28[1];
  uint64_t v29 = (*(uint64_t (**)(void, void, void))(***((void ***)*v20 + 11) + 32))(**((void **)*v20 + 11), 0, 0);
  BOOL EnableKernelRewind = ZinIrCompilerParameters::getEnableKernelRewind((ZinIrCompilerParameters *)(*(void *)(v29 + 16)
                                                                                                + 176));
  uint64_t v31 = *(ZinIrOpLayer ***)(*a1 + 8);
  uint64_t v32 = *(ZinIrOpLayer ***)(*a1 + 16);
  if (v31 != v32)
  {
    unint64_t v33 = 0xAAAAAAAAAAAAAAABLL * ((v27 - v26) >> 3);
    uint64_t v34 = *v46;
    if (EnableKernelRewind && v22 < 2) {
      unint64_t v33 = 1;
    }
    unint64_t v47 = v33;
    do
    {
      uint64_t v35 = *v31;
      if (!ZinIrOpLayer::IsPELayer(*v31))
      {
        (*(void (**)(ZinIrKernel **__return_ptr, ZinIrOpLayer *, void))(*(void *)v35 + 568))(&v50, v35, 0);
        uint64_t v36 = v50;
        if (v50)
        {
          if (*((void *)v50 + 73) || *((void *)v50 + 77))
          {
            uint64_t v49 = 0;
            int WeightFormat = ZinIrKernel::GetWeightFormat(v50);
            ZinKernelFormatGetBitDepth(WeightFormat, &v49);
            uint64_t v38 = *(void *)((*(uint64_t (**)(void, void, void))(***((void ***)v35 + 11) + 32))(**((void **)v35 + 11), 0, 0)+ 56);
            uint64_t v39 = *(void *)((*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)v35 + 32))(v35, 0, 0)+ 56);
            uint64_t v40 = *((void *)v36 + 33);
            uint64_t v42 = v49;
            uint64_t v41 = *((void *)v36 + 34);
            unint64_t v43 = (unint64_t)(v39 * v38 * v40 * v41)
                / *(void *)((*(uint64_t (**)(void, void, void))(***((void ***)v35 + 11) + 32))(**((void **)v35 + 11), 0, 0)+ 48)* (v42/ 8);
            unint64_t v44 = v43 / (*(void *)(v48 + 480) * *(int *)(v48 + 8));
            if (v44 <= 1) {
              unint64_t v44 = 1;
            }
            *v34++ = v44;
            a1[12] += v43 * v47;
            uint64_t v36 = v50;
            uint64_t v50 = 0;
            if (!v36) {
              goto LABEL_26;
            }
          }
          else
          {
            uint64_t v50 = 0;
          }
          ZinIrKernel::~ZinIrKernel(v36);
          MEMORY[0x21667D3C0]();
        }
      }
LABEL_26:
      ++v31;
    }
    while (v31 != v32);
  }
  return a1;
}

void sub_211267A10(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void **a10, uint64_t a11, uint64_t a12, uint64_t a13, char a14)
{
  uint64_t v16 = *a10;
  if (*a10)
  {
    *(void *)(v14 + 64) = v16;
    operator delete(v16);
  }
  _Unwind_Resume(exception_object);
}

uint64_t SplitInfoMetrics::GetSize(uint64_t a1, int a2, void *a3)
{
  uint64_t v8 = 0;
  if (ZinTensorFormatGetSizeInBytes(a2, &v8)) {
    ZinAssertImpl("Error in getting tensor format size in bytes");
  }
  uint64_t v5 = *a3 * a3[2] * a3[1];
  uint64_t v6 = v5 * ZinAlignPower2(a3[3] * v8, *(void *)(*(void *)(a1 + 80) + 416));
  ZinAlignPower2(a3[3] * v8, *(void *)(*(void *)(a1 + 80) + 528));
  return v6;
}

uint64_t SplitInfoMetrics::GetSize(SplitInfoMetrics *this, const ZinIrTensor *a2, const ZinTensorDimensions *a3)
{
  long long v5 = *((_OWORD *)a3 + 1);
  long long v10 = *(_OWORD *)a3;
  long long v11 = v5;
  uint64_t v12 = *((void *)a3 + 4);
  uint64_t v6 = *((void *)a2 + 12);
  if (v6)
  {
    if (*(_DWORD *)(*(void *)(v6 + 64) + 8) == 85)
    {
      uint64_t v7 = *(void *)(v6 + 432);
      if (v7)
      {
        if ((*(unsigned char *)(*(void *)(v7 + 136) + 448) & 0x40) != 0)
        {
          *(void *)&long long v11 = ZinAlignPower2(*((void *)a3 + 2), 2);
          *((void *)&v11 + 1) = ZinAlignPower2(*((void *)a3 + 3), 2);
        }
      }
    }
  }
  return SplitInfoMetrics::GetSize((uint64_t)this, *((_DWORD *)a2 + 22), &v10);
}

uint64_t SplitInfoMetrics::GetNonResidentFootprintAtLayer(SplitInfoMetrics *this, unint64_t a2, unint64_t a3)
{
  long long v4 = (void *)*((void *)this + 1);
  if (0xAAAAAAAAAAAAAAABLL * ((uint64_t)(v4[1] - *v4) >> 3) <= a3) {
    std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
  }
  uint64_t v7 = (void *)(*v4 + 24 * a3);
  if (0x34F72C234F72C235 * ((uint64_t)(v7[1] - *v7) >> 3) <= a2) {
    std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
  }
  uint64_t v8 = *v7 + 232 * a2;
  if (!*(unsigned char *)(v8 + 224)) {
    ZinAssertImpl("Internal spatial splitting error");
  }
  uint64_t v9 = *(void *)(*(void *)this + 8);
  unint64_t v10 = (*(void *)(*(void *)this + 16) - v9) >> 3;
  if (v10 <= a2) {
    std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
  }
  long long v11 = *(const ZinANELayer **)(v9 + 8 * a2);
  unint64_t v12 = v10 - 1;
  unint64_t IncomingLayerIndexInChain = ProducerConsumerChain::GetIncomingLayerIndexInChain(*(ProducerConsumerChain **)this, v11);
  uint64_t v14 = (const ZinIrTensor *)(*(uint64_t (**)(void, void, void))(***((void ***)v11 + 11) + 32))(**((void **)v11 + 11), 0, 0);
  if (a2)
  {
    uint64_t v15 = (const ZinTensorDimensions *)(*(void *)(v8 + 128) + 80 * IncomingLayerIndexInChain + 40);
  }
  else
  {
    uint64_t v16 = **(void **)(**(void **)(*(void *)this + 8) + 88);
    uint64_t v15 = (const ZinTensorDimensions *)((*(uint64_t (**)(uint64_t, void, void))(*(void *)v16 + 32))(v16, 0, 0)+ 48);
  }
  uint64_t Size = SplitInfoMetrics::GetSize(this, v14, v15);
  uint64_t v19 = v18;
  BOOL v20 = (const ZinIrTensor *)(*(uint64_t (**)(const ZinANELayer *, void, void))(*(void *)v11 + 32))(v11, 0, 0);
  if (v12 == a2)
  {
    uint64_t v21 = *(void *)(*(void *)(*(void *)this + 16) - 8);
    unint64_t v22 = (const ZinTensorDimensions *)(*(void *)(*(uint64_t (**)(uint64_t, void, void))(*(void *)v21 + 40))(v21, 0, 0)+ 48);
  }
  else
  {
    unint64_t v22 = (const ZinTensorDimensions *)(v8 + 40);
  }
  uint64_t v23 = SplitInfoMetrics::GetSize(this, v20, v22);
  uint64_t v25 = v24;
  if (*((_DWORD *)this + 22) == 1)
  {
    BOOL v26 = 1;
  }
  else
  {
    uint64_t v27 = **(void **)(**(void **)(*(void *)this + 8) + 88);
    uint64_t v28 = (void *)(*(uint64_t (**)(uint64_t, void, void))(*(void *)v27 + 32))(v27, 0, 0);
    if ((unint64_t)SplitInfoMetrics::GetSize(this, (const ZinIrTensor *)v28, (const ZinTensorDimensions *)(v28 + 6)) <= *((void *)this + 2))
    {
      uint64_t v29 = v28[13];
      if (v29) {
        BOOL v26 = *(_DWORD *)(v29 + 96) == 2;
      }
      else {
        BOOL v26 = 0;
      }
    }
    else
    {
      BOOL v26 = 1;
    }
    if (*((_DWORD *)this + 22) != 1)
    {
      uint64_t v30 = *(void *)(*(void *)(*(void *)this + 16) - 8);
      uint64_t v31 = *(void **)(*(uint64_t (**)(uint64_t, void, void))(*(void *)v30 + 40))(v30, 0, 0);
      if ((unint64_t)SplitInfoMetrics::GetSize(this, (const ZinIrTensor *)v31, (const ZinTensorDimensions *)(v31 + 6)) <= *((void *)this + 2))
      {
        uint64_t v46 = v31[13];
        if (v46) {
          BOOL v32 = *(_DWORD *)(v46 + 96) == 2;
        }
        else {
          BOOL v32 = 0;
        }
        goto LABEL_21;
      }
    }
  }
  BOOL v32 = 1;
LABEL_21:
  uint64_t v33 = 0;
  BOOL v35 = a3 < 2 && a2 + 1 != (uint64_t)(*(void *)(*(void *)this + 16) - *(void *)(*(void *)this + 8)) >> 3;
  unint64_t v36 = 0;
  BOOL v37 = a3 + 1 < 0xAAAAAAAAAAAAAAABLL
               * ((uint64_t)(*(void *)(*((void *)this + 1) + 8) - **((void **)this + 1)) >> 3)
     || a2 == 0;
  if (v37 && !v26)
  {
    unint64_t v36 = *((void *)this + 3);
    if (v36 >= *((void *)this + 2))
    {
      uint64_t v33 = 0;
      unint64_t v36 = 0;
    }
    else
    {
      uint64_t v33 = *((void *)this + 4);
    }
  }
  if (v35 || v32)
  {
    unint64_t v38 = *((void *)this + 2);
  }
  else
  {
    unint64_t v39 = *((void *)this + 5);
    unint64_t v38 = *((void *)this + 2);
    if (v39 < v38)
    {
      v36 += v39;
      v33 += *((void *)this + 6);
    }
  }
  if (a2) {
    uint64_t v40 = v19;
  }
  else {
    uint64_t v40 = 0;
  }
  if (a2) {
    uint64_t v41 = Size;
  }
  else {
    uint64_t v41 = 0;
  }
  if (v12 == a2) {
    uint64_t v42 = 0;
  }
  else {
    uint64_t v42 = v25;
  }
  uint64_t v43 = v42 + v33 + v40;
  if (v12 == a2) {
    uint64_t v44 = 0;
  }
  else {
    uint64_t v44 = v23;
  }
  if (v44 + v36 + v41 <= v38) {
    return 0;
  }
  else {
    return v43;
  }
}

unint64_t SplitInfoMetrics::GetWorstNonResidentFootprintRequirement(SplitInfoMetrics *this)
{
  uint64_t v1 = (uint64_t *)*((void *)this + 1);
  uint64_t v3 = *v1;
  uint64_t v2 = v1[1];
  if (v2 == *v1) {
    return 0;
  }
  unint64_t v5 = 0;
  unint64_t v6 = 0;
  uint64_t v7 = *(void *)this;
  do
  {
    if (*(void *)(v7 + 16) - *(void *)(v7 + 8) != 8)
    {
      unint64_t v8 = 0;
      do
      {
        unint64_t NonResidentFootprintAtLayer = SplitInfoMetrics::GetNonResidentFootprintAtLayer(this, v8++, v5);
        unint64_t v10 = SplitInfoMetrics::GetNonResidentFootprintAtLayer(this, v8, v5);
        if (NonResidentFootprintAtLayer <= v10) {
          unint64_t v11 = v10;
        }
        else {
          unint64_t v11 = NonResidentFootprintAtLayer;
        }
        if (v6 <= v11) {
          unint64_t v6 = v11;
        }
        uint64_t v7 = *(void *)this;
      }
      while (v8 < ((uint64_t)(*(void *)(*(void *)this + 16) - *(void *)(*(void *)this + 8)) >> 3) - 1);
      uint64_t v3 = *v1;
      uint64_t v2 = v1[1];
    }
    ++v5;
  }
  while (v5 < 0xAAAAAAAAAAAAAAABLL * ((v2 - v3) >> 3));
  return v6;
}

uint64_t SplitInfoMetrics::GetKOpCount(SplitInfoMetrics *this)
{
  uint64_t v1 = (uint64_t *)*((void *)this + 1);
  uint64_t v2 = *v1;
  uint64_t v3 = v1[1] - *v1;
  if (!v3) {
    return 0;
  }
  uint64_t result = 0;
  uint64_t v6 = 0;
  unint64_t v7 = v3 / 24;
  uint64_t v8 = *(void *)this;
  uint64_t v9 = *(void *)(v8 + 8);
  uint64_t v10 = *(void *)(v8 + 16);
  unint64_t v11 = (v10 - v9) >> 3;
  if (v11 <= 1) {
    uint64_t v12 = 1;
  }
  else {
    uint64_t v12 = (v10 - v9) >> 3;
  }
  if (v7 <= 1) {
    uint64_t v13 = 1;
  }
  else {
    uint64_t v13 = v7;
  }
  do
  {
    if (v10 != v9)
    {
      unint64_t v14 = 0;
      uint64_t v15 = (void *)(v2 + 24 * v6);
      uint64_t v16 = *v15 + 128;
      do
      {
        if (0x34F72C234F72C235 * ((uint64_t)(*(void *)(v2 + 24 * v6 + 8) - *v15) >> 3) == v14) {
          std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
        }
        if (!*(unsigned char *)(v16 + 96)) {
          ZinAssertImpl("Internal spatial splitting error", v13, 24, 0x34F72C234F72C235, 232);
        }
        if (v11 <= v14) {
          std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
        }
        unint64_t v17 = 0;
        uint64_t v18 = *(void *)(v9 + 8 * v14);
        switch(*(_DWORD *)(*(void *)(v18 + 64) + 8))
        {
          case 'Q':
          case 'Z':
          case '\\':
            uint64_t v19 = *v15 + 232 * v14;
            uint64_t v20 = *(void *)(v16 - 72) * *(void *)(v16 - 64) * *(void *)(v16 - 88);
            goto LABEL_15;
          case 'S':
          case 'Y':
            uint64_t v22 = *(void *)(*(void *)(v18 + 432) + 64);
            uint64_t v20 = *(void *)(v16 - 72)
                * *(void *)(v16 - 64)
                * *(void *)(v16 - 88)
                * *(void *)(v16 - 80)
                * *(void *)(v22 + 16);
            uint64_t v21 = (void *)(v22 + 24);
            goto LABEL_17;
          case 'U':
            uint64_t v23 = *(void *)(v18 + 432);
            if (v23)
            {
              uint64_t v20 = *(void *)(v16 - 72)
                  * *(void *)(v16 - 64)
                  * *(void *)(v16 - 88)
                  * *(void *)(*(void *)(v23 + 136) + 272)
                  * *(void *)(*(void *)(v23 + 136) + 264)
                  * *(void *)(v16 - 80);
              uint64_t v19 = *(void *)v16;
LABEL_15:
              uint64_t v21 = (void *)(v19 + 48);
            }
            else
            {
              uint64_t v20 = *(void *)(v16 - 72) * *(void *)(v16 - 64) * *(void *)(v16 - 88);
              uint64_t v21 = (void *)(v16 - 80);
            }
LABEL_17:
            unint64_t v17 = v20 * *v21;
            break;
          default:
            break;
        }
        result += v17 >> 10;
        ++v14;
        v16 += 232;
      }
      while (v12 != v14);
    }
    ++v6;
  }
  while (v6 != v13);
  return result;
}

BOOL SplitInfoMetrics::IsInputCertainlyNonResident(SplitInfoMetrics *this)
{
  uint64_t v2 = **(void **)(**(void **)(*(void *)this + 8) + 88);
  uint64_t v3 = (*(uint64_t (**)(uint64_t, void, void))(*(void *)v2 + 32))(v2, 0, 0);
  return (unint64_t)SplitInfoMetrics::GetSize(this, (const ZinIrTensor *)v3, (const ZinTensorDimensions *)(v3 + 48)) > *((void *)this + 2);
}

BOOL SplitInfoMetrics::IsOutputCertainlyNonResident(SplitInfoMetrics *this)
{
  uint64_t v2 = *(void *)(*(void *)(*(void *)this + 16) - 8);
  uint64_t v3 = (const ZinIrTensor **)(*(uint64_t (**)(uint64_t, void, void))(*(void *)v2 + 40))(v2, 0, 0);
  return (unint64_t)SplitInfoMetrics::GetSize(this, *v3, (const ZinIrTensor *)((char *)*v3 + 48)) > *((void *)this + 2);
}

uint64_t SplitInfoMetrics::GetTempBytesAccessed(SplitInfoMetrics *this)
{
  uint64_t v1 = (uint64_t *)*((void *)this + 1);
  uint64_t v2 = *v1;
  if (v1[1] == *v1)
  {
    uint64_t v4 = 0;
  }
  else
  {
    uint64_t v4 = 0;
    uint64_t v5 = 0;
    unint64_t v6 = 0;
    uint64_t v7 = *(void *)this;
    do
    {
      uint64_t v8 = *(void *)(v7 + 8);
      uint64_t v9 = *(void *)(v7 + 16);
      if (v9 - v8 != 8)
      {
        unint64_t v10 = 0;
        uint64_t v11 = 224;
        do
        {
          uint64_t v12 = (void *)*((void *)this + 1);
          if (0xAAAAAAAAAAAAAAABLL * ((uint64_t)(v12[1] - *v12) >> 3) <= v6) {
            std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
          }
          uint64_t v13 = (uint64_t *)(*v12 + 24 * v6);
          uint64_t v14 = *v13;
          if (0x34F72C234F72C235 * ((v13[1] - *v13) >> 3) <= v10) {
            std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
          }
          if (!*(unsigned char *)(v14 + v11)) {
            ZinAssertImpl("Internal Spatial Split Error");
          }
          if (v10 >= (v9 - v8) >> 3) {
            std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
          }
          uint64_t v15 = (const ZinTensorDimensions *)(v14 + v11 - 184);
          uint64_t v16 = (const ZinIrTensor *)(*(uint64_t (**)(void, void, void))(**(void **)(v8 + 8 * v10)
                                                                                       + 32))(*(void *)(v8 + 8 * v10), 0, 0);
          uint64_t Size = SplitInfoMetrics::GetSize(this, v16, v15);
          uint64_t v19 = *((void *)this + 7);
          if (v10 >= (*((void *)this + 8) - v19) >> 3) {
            std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
          }
          uint64_t v20 = *(void *)(v19 + 8 * v10);
          v4 += v20 * Size;
          v5 += v20 * v18;
          ++v10;
          uint64_t v7 = *(void *)this;
          uint64_t v8 = *(void *)(*(void *)this + 8);
          uint64_t v9 = *(void *)(*(void *)this + 16);
          v11 += 232;
        }
        while (v10 < ((v9 - v8) >> 3) - 1);
        uint64_t v1 = (uint64_t *)*((void *)this + 1);
        uint64_t v2 = *v1;
      }
      ++v6;
    }
    while (v6 < 0xAAAAAAAAAAAAAAABLL * ((v1[1] - v2) >> 3));
  }
  return 2 * v4;
}

uint64_t SplitInfoMetrics::GetInputBytesAccessed(SplitInfoMetrics *this)
{
  uint64_t v2 = **(void **)(**(void **)(*(void *)this + 8) + 88);
  uint64_t v3 = (*(uint64_t (**)(uint64_t, void, void))(*(void *)v2 + 32))(v2, 0, 0);
  uint64_t v4 = **((void **)this + 1);
  if (*(void *)(*((void *)this + 1) + 8) == v4) {
    return 0;
  }
  uint64_t v5 = (const ZinIrTensor *)v3;
  uint64_t v6 = 0;
  uint64_t v7 = 0;
  uint64_t v8 = 0;
  unint64_t v9 = 0;
  do
  {
    uint64_t v10 = v4 + v6;
    uint64_t v11 = *(void *)(v4 + v6);
    if (*(void *)(v10 + 8) == v11) {
      std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
    }
    if (!*(unsigned char *)(v11 + 224)) {
      ZinAssertImpl("Internal Spatial Splitting Error");
    }
    uint64_t Size = SplitInfoMetrics::GetSize(this, v5, (const ZinTensorDimensions *)(*(void *)(v11 + 128) + 40));
    uint64_t v14 = (uint64_t *)*((void *)this + 7);
    if (*((uint64_t **)this + 8) == v14) {
      std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
    }
    uint64_t v15 = *v14;
    v7 += v15 * Size;
    v8 += v15 * v13;
    ++v9;
    uint64_t v4 = **((void **)this + 1);
    v6 += 24;
  }
  while (v9 < 0xAAAAAAAAAAAAAAABLL * ((*(void *)(*((void *)this + 1) + 8) - v4) >> 3));
  return v7;
}

uint64_t ZinMirSpatialSplitter::AddDeconvBypassIfNecessary(ZinMirSpatialSplitter *this, ZinIrOpLayerGraph *a2, const ProducerConsumerChain *a3, uint64_t a4, ZinIrOpLayer **a5)
{
  v30[6] = *MEMORY[0x263EF8340];
  uint64_t v5 = *a5;
  if (*(_DWORD *)(*((void *)*a5 + 8) + 8) == 85
    && (v5[17] || (uint64_t v24 = v5[54]) != 0 && *(void *)(v24 + 136))
    && (*(unsigned char *)(ZinNEConvLayer::GetKernelDescriptor(*a5) + 272) & 0x40) != 0
    && (*(unsigned char *)((*(uint64_t (**)(void *, void, void))(*v5 + 32))(v5, 0, 0) + 64) & 1) != 0)
  {
    uint64_t v9 = *((void *)a3 + 1);
    if (a4 + 1 < (unint64_t)((*((void *)a3 + 2) - v9) >> 3)
      && !ZinIrOpLayer::IsANELayer(*(ZinIrOpLayer **)(v9 + 8 * (a4 + 1))))
    {
      uint64_t v10 = a4;
      do
      {
        uint64_t v11 = *((void *)a3 + 1);
        uint64_t v12 = v11 + 8 * v10;
        int v13 = *(_DWORD *)(*(void *)(*(void *)(v12 + 8) + 64) + 8);
        if (v10 + 2 >= (unint64_t)((*((void *)a3 + 2) - v11) >> 3)) {
          break;
        }
        ++v10;
      }
      while (!ZinIrOpLayer::IsANELayer(*(ZinIrOpLayer **)(v12 + 16)));
      if (v13 == 7) {
        goto LABEL_12;
      }
    }
    if (((uint64_t)(*((void *)a3 + 2) - *((void *)a3 + 1)) >> 3) - 1 == a4)
    {
LABEL_12:
      uint64_t v14 = *a5;
      if (*((char *)*a5 + 47) >= 0) {
        size_t v15 = *((unsigned __int8 *)*a5 + 47);
      }
      else {
        size_t v15 = *((void *)*a5 + 4);
      }
      p_p = &__p;
      std::string::basic_string[abi:ne180100]((uint64_t)&__p, v15 + 7);
      if (v27 < 0) {
        p_p = __p;
      }
      if (v15)
      {
        uint64_t v19 = (char *)v14[3];
        uint64_t v18 = (char *)(v14 + 3);
        unint64_t v17 = v19;
        if (v18[23] >= 0) {
          uint64_t v20 = v18;
        }
        else {
          uint64_t v20 = v17;
        }
        memmove(p_p, v20, v15);
      }
      strcpy((char *)p_p + v15, "/bypass");
      ZinObjectNameFactory::ZinObjectNameFactory(v30, &__p);
      if (v27 < 0) {
        operator delete(__p);
      }
      uint64_t v21 = (uint64_t)*a5;
      uint64_t v22 = *((void *)*a5 + 2);
      uint64_t v23 = *(unsigned int *)((*(uint64_t (**)(void, void, void))(*(void *)*a5 + 32))(*a5, 0, 0)
                            + 88);
      uint64_t v29 = 0;
      v28[0] = 0;
      v28[168] = 0;
      ZinBuilder::CreateNEBypass(v22, (uint64_t)v30, v21, v23, &v29, 0, (uint64_t)v28, 1.0);
    }
  }
  return 0;
}

void sub_211268A40(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, void *__p, uint64_t a13)
{
  if (__p) {
    operator delete(__p);
  }
  *(void *)(v13 - 120) = &unk_26C34DA98;
  if (*(char *)(v13 - 89) < 0) {
    operator delete(*(void **)(v13 - 112));
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinMirSpatialSplitter::Split(ZinIrOpLayer **this, uint64_t **a2, const ZinMirSpatialSplitter::SplitPlan *a3, LayerTilingHelper *a4, char a5)
{
  uint64_t v126 = *MEMORY[0x263EF8340];
  uint64_t v121 = 0;
  uint64_t v122 = 0;
  uint64_t v123 = 0;
  uint64_t v88 = (const ZinMirSpatialSplitter::SplitPlan *)((char *)a3 + 160);
  uint64_t v5 = LayerTilingHelper::Create((void *)a3 + 20, this[6], &v121, a4);
  if (!v5)
  {
    v118 = 0;
    v119 = 0;
    v120 = 0;
    uint64_t v115 = 0;
    v116 = 0;
    v117 = 0;
    LOBYTE(v113[0]) = 0;
    char v114 = 0;
    if (*(unsigned char *)(*((void *)this[2] + 1) + 492))
    {
      *(_OWORD *)unint64_t v110 = 0u;
      long long v111 = 0u;
      LODWORD(v112) = 1065353216;
      std::optional<std::unordered_map<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>>::operator=[abi:ne180100]<std::unordered_map<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,void>((uint64_t)v113, (uint64_t *)v110);
      std::__hash_table<std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::__unordered_map_hasher<unsigned long,std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::hash<unsigned long>,std::equal_to<unsigned long>,true>,std::__unordered_map_equal<unsigned long,std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::equal_to<unsigned long>,std::hash<unsigned long>,true>,std::allocator<std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>>>::~__hash_table((uint64_t)v110);
    }
    uint64_t v6 = a3;
    uint64_t v87 = *(void *)a3;
    if (*((void *)a3 + 1) == *(void *)a3)
    {
LABEL_109:
      uint64_t v82 = *((void *)v6 + 21);
      if (*((void *)v6 + 22) != v82)
      {
        uint64_t v83 = *(void *)(*(void *)v82 + 16);
        if (v83) {
          ZinSpatialSplitTransform::TransferShapeDependentTransformsToContext((uint64_t)v113, v83);
        }
      }
      operator new();
    }
    char v7 = 0;
    uint64_t v8 = 0;
    int64x2_t v85 = vdupq_n_s64(1uLL);
    while (1)
    {
      uint64_t v86 = v8;
      unint64_t v109 = 0;
      uint64_t v9 = *((void *)v6 + 21);
      if (*((void *)v6 + 22) != v9) {
        break;
      }
LABEL_73:
      uint64_t v55 = *(void *)(v87 + 24 * v86 + 8);
      if (!*(unsigned char *)(v55 - 8)) {
        std::__throw_bad_optional_access[abi:ne180100]();
      }
      *(_OWORD *)unint64_t v110 = *(_OWORD *)(v55 - 232);
      long long v111 = *(_OWORD *)(v55 - 216);
      unint64_t v56 = v116;
      if (v116 >= v117)
      {
        BOOL v60 = v115;
        unint64_t v61 = 0xCCCCCCCCCCCCCCCDLL * ((v116 - v115) >> 4);
        unint64_t v62 = v61 + 1;
        if (v61 + 1 > 0x333333333333333) {
          std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
        }
        if (0x999999999999999ALL * ((v117 - v115) >> 4) > v62) {
          unint64_t v62 = 0x999999999999999ALL * ((v117 - v115) >> 4);
        }
        if (0xCCCCCCCCCCCCCCCDLL * ((v117 - v115) >> 4) >= 0x199999999999999) {
          unint64_t v63 = 0x333333333333333;
        }
        else {
          unint64_t v63 = v62;
        }
        if (v63)
        {
          uint64_t v64 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ZinIrCodegenTDPartitionStats>>((uint64_t)&v117, v63);
          BOOL v60 = v115;
          unint64_t v56 = v116;
        }
        else
        {
          uint64_t v64 = 0;
        }
        uint64_t v65 = &v64[80 * v61];
        *(_OWORD *)uint64_t v65 = *(_OWORD *)v110;
        *((_OWORD *)v65 + 1) = v111;
        *((_OWORD *)v65 + 2) = xmmword_211ED5A80;
        int64x2_t v66 = vdupq_n_s64(1uLL);
        *((int64x2_t *)v65 + 3) = v66;
        *((int64x2_t *)v65 + 4) = v66;
        if (v56 == v60)
        {
          uint64_t v71 = &v64[80 * v61];
        }
        else
        {
          uint64_t v67 = &v64[80 * v61];
          do
          {
            *((_OWORD *)v67 - 5) = *((_OWORD *)v56 - 5);
            long long v68 = *((_OWORD *)v56 - 4);
            long long v69 = *((_OWORD *)v56 - 3);
            long long v70 = *((_OWORD *)v56 - 1);
            uint64_t v71 = v67 - 80;
            *((_OWORD *)v67 - 2) = *((_OWORD *)v56 - 2);
            *((_OWORD *)v67 - 1) = v70;
            *((_OWORD *)v67 - 4) = v68;
            *((_OWORD *)v67 - 3) = v69;
            v56 -= 80;
            v67 -= 80;
          }
          while (v56 != v60);
        }
        long long v59 = v65 + 80;
        uint64_t v115 = v71;
        v116 = v65 + 80;
        v117 = &v64[80 * v63];
        if (v60) {
          operator delete(v60);
        }
      }
      else
      {
        long long v57 = (_OWORD *)(v55 - 232);
        long long v58 = v57[1];
        *(_OWORD *)v116 = *v57;
        *((_OWORD *)v56 + 1) = v58;
        *((_OWORD *)v56 + 2) = xmmword_211ED5A80;
        *((int64x2_t *)v56 + 3) = v85;
        *((int64x2_t *)v56 + 4) = v85;
        long long v59 = v56 + 80;
      }
      v116 = v59;
      uint64_t v72 = v119;
      if (v119 >= v120)
      {
        uint64_t v74 = (v119 - v118) >> 3;
        if ((unint64_t)(v74 + 1) >> 61) {
          std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
        }
        unint64_t v75 = (v120 - v118) >> 2;
        if (v75 <= v74 + 1) {
          unint64_t v75 = v74 + 1;
        }
        if ((unint64_t)(v120 - v118) >= 0x7FFFFFFFFFFFFFF8) {
          unint64_t v76 = 0x1FFFFFFFFFFFFFFFLL;
        }
        else {
          unint64_t v76 = v75;
        }
        if (v76) {
          uint64_t v77 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)&v120, v76);
        }
        else {
          uint64_t v77 = 0;
        }
        uint64_t v78 = (ZinIrOpLayer **)&v77[8 * v74];
        *uint64_t v78 = v109;
        uint64_t v73 = (char *)(v78 + 1);
        unint64_t v80 = v118;
        uint64_t v79 = v119;
        if (v119 != v118)
        {
          do
          {
            uint64_t v81 = (ZinIrOpLayer *)*((void *)v79 - 1);
            v79 -= 8;
            *--uint64_t v78 = v81;
          }
          while (v79 != v80);
          uint64_t v79 = v118;
        }
        v118 = (char *)v78;
        v119 = v73;
        v120 = &v77[8 * v76];
        if (v79) {
          operator delete(v79);
        }
      }
      else
      {
        *(void *)v119 = v109;
        uint64_t v73 = v72 + 8;
      }
      v119 = v73;
      ++*(_WORD *)a4;
      uint64_t v8 = v86 + 1;
      uint64_t v6 = a3;
      uint64_t v87 = *(void *)a3;
      if (v86 + 1 >= 0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*((void *)a3 + 1) - *(void *)a3) >> 3)) {
        goto LABEL_109;
      }
    }
    unint64_t v10 = 0;
    char v89 = (void *)(v87 + 24 * v8 + 8);
    uint64_t v90 = (void *)(v87 + 24 * v8);
    while (1)
    {
      if (0x34F72C234F72C235 * ((uint64_t)(*v89 - *v90) >> 3) <= v10) {
        std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
      }
      uint64_t v11 = *v90 + 232 * v10;
      if (!*(unsigned char *)(v11 + 224)) {
        ZinAssertImpl("Internal Spatial Split Error");
      }
      uint64_t v12 = *(ZinIrOpLayer **)(v9 + 8 * v10);
      std::vector<ZinIrOpLayer *>::vector(&v108, (uint64_t)(*((void *)v12 + 12) - *((void *)v12 + 11)) >> 3);
      unint64_t v92 = v10;
      uint64_t v13 = *((void *)v12 + 11);
      if (*((void *)v12 + 12) != v13)
      {
        uint64_t v14 = 0;
        unint64_t v15 = 0;
        do
        {
          uint64_t v16 = *(void *)(v13 + 8 * v15);
          uint64_t v17 = (*(uint64_t (**)(uint64_t, void, void))(*(void *)v16 + 32))(v16, 0, 0);
          int v18 = (*(uint64_t (**)(ZinIrOpLayer *, uint64_t))(*(void *)v12 + 200))(v12, v17);
          v110[0] = (void *)v16;
          uint64_t v19 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)a3 + 24, v110);
          if (v19) {
            int v20 = v18;
          }
          else {
            int v20 = 0;
          }
          if (v20 == 1) {
            ZinAssertImpl("kernel tensor can't not be the intermediate tensor in the chain.");
          }
          uint64_t v21 = v19;
          if (*((_DWORD *)a3 + 58)) {
            int v22 = 4;
          }
          else {
            int v22 = 3;
          }
          if (ZinMirSpatialSplitUtils::ShouldCreateView(v12, v15, v22))
          {
            if (!v21)
            {
              uint64_t v23 = *(void *)(v11 + 128) + v14;
              long long v24 = *(_OWORD *)(v23 + 40);
              long long v25 = *(_OWORD *)(v23 + 56);
              uint64_t v112 = *(void *)(v23 + 72);
              *(_OWORD *)unint64_t v110 = v24;
              long long v111 = v25;
              BOOL v26 = (long long *)(*(void *)(v11 + 128) + v14);
              long long v27 = *v26;
              long long v28 = v26[1];
              uint64_t v107 = *((void *)v26 + 4);
              v106[0] = v27;
              v106[1] = v28;
              int v29 = *((_DWORD *)a3 + 58);
              uint64_t v30 = operator new(4uLL);
              if (v29) {
                int v31 = 4;
              }
              else {
                int v31 = 3;
              }
              __p[0] = v30;
              _DWORD *v30 = v31;
              __p[1] = v30 + 1;
              int v98 = v30 + 1;
              ZinMirSpatialSplitUtils::AdjustDimensionsForBroadcast(v106, v110, v12, (uint64_t)__p, v15);
              if (__p[0])
              {
                __p[1] = __p[0];
                operator delete(__p[0]);
              }
              uint64_t v32 = *((void *)v12 + 2);
              TiledLayerTensorRegions::Id::ToStringForIr((TiledLayerTensorRegions::Id *)(v11 + 152), &v105);
              int v33 = *(char *)(v16 + 47);
              if (v33 >= 0) {
                uint64_t v34 = (const std::string::value_type *)(v16 + 24);
              }
              else {
                uint64_t v34 = *(const std::string::value_type **)(v16 + 24);
              }
              if (v33 >= 0) {
                std::string::size_type v35 = *(unsigned __int8 *)(v16 + 47);
              }
              else {
                std::string::size_type v35 = *(void *)(v16 + 32);
              }
              unint64_t v36 = std::string::insert(&v105, 0, v34, v35);
              long long v37 = *(_OWORD *)&v36->__r_.__value_.__l.__data_;
              int v98 = (_DWORD *)v36->__r_.__value_.__r.__words[2];
              *(_OWORD *)long long __p = v37;
              v36->__r_.__value_.__l.__size_ = 0;
              v36->__r_.__value_.__r.__words[2] = 0;
              v36->__r_.__value_.__r.__words[0] = 0;
              ZinIrContext::GetAlternativeNameForTensor(v32, (uint64_t)__p, (uint64_t)v124);
              if (SHIBYTE(v98) < 0) {
                operator delete(__p[0]);
              }
              if (SHIBYTE(v105.__r_.__value_.__r.__words[2]) < 0) {
                operator delete(v105.__r_.__value_.__l.__data_);
              }
              (*(void (**)(uint64_t, void, void))(*(void *)v16 + 32))(v16, 0, 0);
              long long v99 = v106[0];
              long long v100 = v106[1];
              int64x2_t v102 = vdupq_n_s64(1uLL);
              int64x2_t v103 = v102;
              uint64_t v101 = v107;
              uint64_t v104 = 1;
              ZinBuilder::CreateView();
            }
            *(void *)(v108.__r_.__value_.__r.__words[0] + 8 * v15) = v109;
          }
          else
          {
            *(void *)(v108.__r_.__value_.__r.__words[0] + 8 * v15) = v16;
          }
          ++v15;
          uint64_t v13 = *((void *)v12 + 11);
          v14 += 80;
        }
        while (v15 < (*((void *)v12 + 12) - v13) >> 3);
      }
      int v38 = *((_DWORD *)a3 + 58);
      unint64_t v39 = operator new(4uLL);
      if (v38) {
        int v40 = 4;
      }
      else {
        int v40 = 3;
      }
      __p[0] = v39;
      _DWORD *v39 = v40;
      __p[1] = v39 + 1;
      int v98 = v39 + 1;
      if (0xAAAAAAAAAAAAAAABLL * ((v122 - v121) >> 6) <= v92) {
        std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
      }
      int v41 = LayerTilingHelper::CreateLayer((const ZinIrOpLayer **)(v121 + 192 * v92), a2, (uint64_t *)&v108, (TiledLayerTensorRegions *)v11, this[6], __p, &v109);
      if (v41)
      {
        if (v7) {
          ZinAssertImpl("CreateLayer failed and graph is changed");
        }
      }
      else
      {
        if (a5)
        {
          uint64_t v42 = (*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)v12 + 32))(v12, 0, 0);
          if (*(unsigned char *)(v42 + 144))
          {
            uint64_t v43 = (*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)v12 + 32))(v12, 0, 0);
            uint64_t v44 = (const ZinIrTensor *)(*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)v109 + 32))(v109, 0, 0);
            uint64_t v42 = ZinMirSpatialSplitUtils::PropagateSpatialSplitInfo(v43, v44, v45);
          }
        }
        else
        {
          uint64_t v42 = (*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)v109 + 32))(v109, 0, 0);
          int v46 = *(unsigned __int8 *)(v42 + 144);
          *(_WORD *)(v42 + 128) = *(_WORD *)a4;
          *(_DWORD *)(v42 + 132) = 2;
          *(void *)(v42 + 136) = -1;
          if (!v46) {
            *(unsigned char *)(v42 + 144) = 1;
          }
        }
        if (*(void *)(v11 + 184) || *(void *)(v11 + 192))
        {
          long long v47 = *(_OWORD *)(v11 + 40);
          long long v48 = *(_OWORD *)(v11 + 56);
          uint64_t v112 = *(void *)(v11 + 72);
          *(_OWORD *)unint64_t v110 = v47;
          long long v111 = v48;
          *(void *)&long long v111 = v48 - *(void *)(v11 + 184);
          *((void *)&v111 + 1) = *((void *)&v48 + 1) - *(void *)(v11 + 192);
          uint64_t v49 = v109;
          uint64_t v50 = (*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)v109 + 32))(v109, 0, 0);
          uint64_t v51 = v50;
          if (*(char *)(v50 + 47) >= 0) {
            size_t v52 = *(unsigned __int8 *)(v50 + 47);
          }
          else {
            size_t v52 = *(void *)(v50 + 32);
          }
          std::string::basic_string[abi:ne180100]((uint64_t)v124, v52 + 8);
          if (v125 >= 0) {
            uint64_t v53 = v124;
          }
          else {
            uint64_t v53 = (void *)v124[0];
          }
          if (v52)
          {
            if (*(char *)(v51 + 47) >= 0) {
              uint64_t v54 = (const void *)(v51 + 24);
            }
            else {
              uint64_t v54 = *(const void **)(v51 + 24);
            }
            memmove(v53, v54, v52);
          }
          strcpy((char *)v53 + v52, "/trimmed");
          (*(void (**)(ZinIrOpLayer *, void, void))(*(void *)v49 + 32))(v49, 0, 0);
          ZinBuilder::CreateView();
        }
        ZinMirSpatialSplitter::AddDeconvBypassIfNecessary((ZinMirSpatialSplitter *)v42, (ZinIrOpLayerGraph *)a2, v88, v92, &v109);
      }
      if (__p[0])
      {
        __p[1] = __p[0];
        operator delete(__p[0]);
      }
      if (v108.__r_.__value_.__r.__words[0])
      {
        v108.__r_.__value_.__l.__size_ = v108.__r_.__value_.__r.__words[0];
        operator delete(v108.__r_.__value_.__l.__data_);
      }
      if (v41) {
        break;
      }
      unint64_t v10 = v92 + 1;
      uint64_t v9 = *((void *)a3 + 21);
      char v7 = 1;
      if (v92 + 1 >= (*((void *)a3 + 22) - v9) >> 3) {
        goto LABEL_73;
      }
    }
    uint64_t v5 = 3;
    if (v114) {
      std::__hash_table<std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::__unordered_map_hasher<unsigned long,std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::hash<unsigned long>,std::equal_to<unsigned long>,true>,std::__unordered_map_equal<unsigned long,std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::equal_to<unsigned long>,std::hash<unsigned long>,true>,std::allocator<std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>>>::~__hash_table((uint64_t)v113);
    }
    if (v115)
    {
      v116 = v115;
      operator delete(v115);
    }
    if (v118)
    {
      v119 = v118;
      operator delete(v118);
    }
  }
  v113[0] = (void **)&v121;
  std::vector<LayerTilingHelper>::__destroy_vector::operator()[abi:ne180100](v113);
  return v5;
}

void sub_211269D90(_Unwind_Exception *a1)
{
  if (*(unsigned char *)(v1 - 216)) {
    std::__hash_table<std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::__unordered_map_hasher<unsigned long,std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::hash<unsigned long>,std::equal_to<unsigned long>,true>,std::__unordered_map_equal<unsigned long,std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::equal_to<unsigned long>,std::hash<unsigned long>,true>,std::allocator<std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>>>::~__hash_table(v1 - 256);
  }
  uint64_t v3 = *(void **)(v1 - 208);
  if (v3)
  {
    *(void *)(v1 - 200) = v3;
    operator delete(v3);
  }
  uint64_t v4 = *(void **)(v1 - 184);
  if (v4)
  {
    *(void *)(v1 - 176) = v4;
    operator delete(v4);
  }
  *(void *)(v1 - 256) = v1 - 160;
  std::vector<LayerTilingHelper>::__destroy_vector::operator()[abi:ne180100]((void ***)(v1 - 256));
  _Unwind_Resume(a1);
}

uint64_t std::optional<std::unordered_map<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>>::operator=[abi:ne180100]<std::unordered_map<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,void>(uint64_t a1, uint64_t *a2)
{
  if (*(unsigned char *)(a1 + 40))
  {
    std::__hash_table<std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::__unordered_map_hasher<unsigned long,std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::hash<unsigned long>,std::equal_to<unsigned long>,true>,std::__unordered_map_equal<unsigned long,std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::equal_to<unsigned long>,std::hash<unsigned long>,true>,std::allocator<std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>>>::__move_assign(a1, a2);
  }
  else
  {
    std::__hash_table<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::__unordered_map_hasher<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::hash<long>,std::equal_to<long>,true>,std::__unordered_map_equal<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::equal_to<long>,std::hash<long>,true>,std::allocator<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>>>::__hash_table(a1, a2);
    *(unsigned char *)(a1 + 40) = 1;
  }
  return a1;
}

uint64_t ZinMirSpatialSplitter::DetermineTiling(uint64_t a1, ProducerConsumerChain *a2, int a3, uint64_t a4)
{
  uint64_t v75 = 0;
  memset(v74, 0, sizeof(v74));
  int v76 = 1065353216;
  memset(v77, 0, sizeof(v77));
  int v78 = 1065353216;
  int64x2_t v79 = vdupq_n_s64(1uLL);
  int64x2_t v80 = v79;
  unint64_t v8 = *(void *)(*(void *)(*(uint64_t (**)(void, void, void))(**(void **)(*((void *)a2 + 2) - 8)
                                                                                + 40))(*(void *)(*((void *)a2 + 2) - 8), 0, 0)+ 64);
  uint64_t v9 = (*(uint64_t (**)(void, void, void))(**(void **)(*((void *)a2 + 2) - 8) + 40))(*(void *)(*((void *)a2 + 2) - 8), 0, 0);
  uint64_t v10 = SplitInfo::Construct(a2, v8, *(void *)(*(void *)v9 + 72), (uint64_t)v74, 0, **(void **)(a1 + 16), *(ZinIrOpLayer **)(a1 + 48));
  if (v10) {
    goto LABEL_46;
  }
  uint64_t v11 = *(void *)(*(void *)(*(uint64_t (**)(void, void, void))(**(void **)(*((void *)a2 + 2)
                                                                                               - 8)
                                                                                 + 40))(*(void *)(*((void *)a2 + 2) - 8), 0, 0)+ 64);
  uint64_t v12 = *(uint64_t **)(a1 + 16);
  uint64_t v13 = *(void *)(*v12 + 408);
  SplitInfoMetrics::SplitInfoMetrics(v70, *v12, v13, 0, (uint64_t)a2, v74);
  SplitInfoMetrics::GetTempBytesAccessed((SplitInfoMetrics *)v70);
  unint64_t v15 = v14;
  unint64_t v16 = v73;
  unint64_t KOpCount = SplitInfoMetrics::GetKOpCount((SplitInfoMetrics *)v70);
  BOOL IsInputCertainlyNonResident = SplitInfoMetrics::IsInputCertainlyNonResident((SplitInfoMetrics *)v70);
  BOOL IsOutputCertainlyNonResident = SplitInfoMetrics::IsOutputCertainlyNonResident((SplitInfoMetrics *)v70);
  SplitInfoMetrics::GetInputBytesAccessed((SplitInfoMetrics *)v70);
  if ((unint64_t)v11 < 2)
  {
    uint64_t v10 = 0;
    goto LABEL_44;
  }
  uint64_t v37 = v18;
  unint64_t v38 = v16;
  memset(v69, 0, sizeof(v69));
  uint64_t v10 = LayerTilingHelper::Create(a2, *(ZinIrOpLayer **)(a1 + 48), v69, v19);
  if (v10) {
    goto LABEL_43;
  }
  if (v11 - 1 < 1) {
    goto LABEL_42;
  }
  int v20 = a3 != 1 || IsOutputCertainlyNonResident;
  int v36 = v20;
  while (1)
  {
    LOBYTE(v62) = 0;
    char v68 = 0;
    uint64_t v21 = (*(uint64_t (**)(void, void, void))(**(void **)(*((void *)a2 + 2) - 8) + 40))(*(void *)(*((void *)a2 + 2) - 8), 0, 0);
    uint64_t v10 = SplitInfo::TryToConstruct(a2, --v11, *(void *)(*(void *)v21 + 72), (uint64_t)&v62, 0, **(void **)(a1 + 16), v69);
    if (v10)
    {
      std::__optional_destruct_base<SplitInfo,false>::~__optional_destruct_base[abi:ne180100]((uint64_t)&v62);
      goto LABEL_43;
    }
    if (v68) {
      break;
    }
    std::__optional_destruct_base<SplitInfo,false>::~__optional_destruct_base[abi:ne180100]((uint64_t)&v62);
LABEL_38:
    if (v11 <= 1) {
      goto LABEL_42;
    }
  }
  uint64_t v54 = 0;
  uint64_t v55 = 0;
  uint64_t v56 = 0;
  std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__init_with_size[abi:ne180100]<std::vector<std::optional<TiledLayerTensorRegions>>*,std::vector<std::optional<TiledLayerTensorRegions>>*>(&v54, v62, v63, 0xAAAAAAAAAAAAAAABLL * (v63 - v62));
  std::unordered_map<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>::unordered_map((uint64_t)v57, (uint64_t)&v64);
  std::unordered_set<ZinIrOpLayer const*>::unordered_set((uint64_t)v58, (uint64_t)v65);
  long long v59 = *(_OWORD *)&v65[40];
  long long v60 = v66;
  char v61 = v67;
  SplitInfoMetrics::SplitInfoMetrics(v50, **(void **)(a1 + 16), v13, a3, (uint64_t)a2, &v54);
  if (SplitInfoMetrics::GetWorstNonResidentFootprintRequirement((SplitInfoMetrics *)v50) > *(void *)(**(void **)(a1 + 16) + 408)) {
    goto LABEL_13;
  }
  SplitInfoMetrics::GetInputBytesAccessed((SplitInfoMetrics *)v50);
  uint64_t v24 = v23;
  long long v25 = (const ZinIrTensor **)(*(uint64_t (**)(void, void, void))(**(void **)(*((void *)a2 + 2) - 8)
                                                                                + 40))(*(void *)(*((void *)a2 + 2) - 8), 0, 0);
  SplitInfoMetrics::GetSize((SplitInfoMetrics *)v50, *v25, (const ZinIrTensor *)((char *)*v25 + 48));
  if (v53 >= v38)
  {
    if (v36) {
      uint64_t v27 = 0;
    }
    else {
      uint64_t v27 = v26;
    }
    uint64_t v28 = v27 + v24;
    if (a3 != 1) {
      uint64_t v28 = 0;
    }
    if (IsInputCertainlyNonResident) {
      uint64_t v28 = v24 - v37;
    }
    unint64_t v29 = v53 - v38 + v28;
    unint64_t v35 = v15 - v29;
    if (v15 <= v29)
    {
LABEL_13:
      int v22 = 4;
      goto LABEL_34;
    }
    uint64_t v30 = SplitInfoMetrics::GetKOpCount((SplitInfoMetrics *)v50);
    unint64_t v31 = SplitInfoMetrics::GetKOpCount((SplitInfoMetrics *)v50);
    if (KOpCount >= v31) {
      unint64_t v32 = v31;
    }
    else {
      unint64_t v32 = KOpCount;
    }
    unint64_t v33 = 0xAAAAAAAAAAAAAAABLL * (v55 - v54);
    if (*(unsigned char *)(a4 + 160) && v33 > 0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*(void *)(a4 + 8) - *(void *)a4) >> 3))
    {
      int v22 = 2;
    }
    else
    {
      memset(v41, 0, sizeof(v41));
      std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__init_with_size[abi:ne180100]<std::vector<std::optional<TiledLayerTensorRegions>>*,std::vector<std::optional<TiledLayerTensorRegions>>*>(v41, v54, v55, v33);
      std::unordered_map<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>::unordered_map((uint64_t)v42, (uint64_t)v57);
      std::unordered_set<ZinIrOpLayer const*>::unordered_set((uint64_t)v43, (uint64_t)v58);
      *(_OWORD *)&v43[40] = v59;
      long long v44 = v60;
      char v45 = v61;
      unint64_t v46 = v35;
      unint64_t v47 = v30 - v32;
      std::optional<ZinMirSpatialSplitter::TilingResult>::operator=[abi:ne180100]<ZinMirSpatialSplitter::TilingResult,void>(a4, (uint64_t)v41);
      std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v43);
      std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::~__hash_table((uint64_t)v42);
      uint64_t v81 = v41;
      std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v81);
      int v22 = 0;
    }
  }
  else
  {
    if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
      ZinMirSpatialSplitter::DetermineTiling(&buf, v49);
    }
    int v22 = 1;
  }
LABEL_34:
  if (__p)
  {
    size_t v52 = __p;
    operator delete(__p);
  }
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v58);
  std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::~__hash_table((uint64_t)v57);
  v41[0] = (void **)&v54;
  std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__destroy_vector::operator()[abi:ne180100](v41);
  std::__optional_destruct_base<SplitInfo,false>::~__optional_destruct_base[abi:ne180100]((uint64_t)&v62);
  if (!v22 || v22 == 4) {
    goto LABEL_38;
  }
  if (v22 == 2) {
LABEL_42:
  }
    uint64_t v10 = 0;
  else {
    uint64_t v10 = 3;
  }
LABEL_43:
  v41[0] = (void **)v69;
  std::vector<LayerTilingHelper>::__destroy_vector::operator()[abi:ne180100](v41);
LABEL_44:
  if (v71)
  {
    uint64_t v72 = v71;
    operator delete(v71);
  }
LABEL_46:
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v77);
  std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::~__hash_table((uint64_t)&v74[1] + 8);
  v41[0] = (void **)v74;
  std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__destroy_vector::operator()[abi:ne180100](v41);
  return v10;
}

void sub_21126A76C(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33,uint64_t a34,uint64_t a35,uint64_t a36,uint64_t a37,uint64_t a38,uint64_t a39,uint64_t a40,uint64_t a41,uint64_t a42,uint64_t a43,uint64_t a44,uint64_t a45,uint64_t a46,uint64_t a47,uint64_t a48,uint64_t a49,uint64_t a50,uint64_t a51,uint64_t a52,uint64_t a53,void *__p,uint64_t a55,uint64_t a56,uint64_t a57,uint64_t a58,uint64_t a59,void *a60)
{
  SplitInfo::~SplitInfo((void **)&a25);
  if (__p)
  {
    a55 = (uint64_t)__p;
    operator delete(__p);
  }
  SplitInfo::~SplitInfo(&a60);
  std::__optional_destruct_base<SplitInfo,false>::~__optional_destruct_base[abi:ne180100]((uint64_t)&STACK[0x228]);
  a25 = (uint64_t)&STACK[0x2C0];
  std::vector<LayerTilingHelper>::__destroy_vector::operator()[abi:ne180100]((void ***)&a25);
  unint64_t v62 = (void *)STACK[0x310];
  if (STACK[0x310])
  {
    STACK[0x318] = (unint64_t)v62;
    operator delete(v62);
  }
  SplitInfo::~SplitInfo((void **)(v60 - 256));
  _Unwind_Resume(a1);
}

uint64_t std::optional<ZinMirSpatialSplitter::TilingResult>::operator=[abi:ne180100]<ZinMirSpatialSplitter::TilingResult,void>(uint64_t a1, uint64_t a2)
{
  if (*(unsigned char *)(a1 + 160))
  {
    std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__vdeallocate((void ***)a1);
    *(_OWORD *)a1 = *(_OWORD *)a2;
    *(void *)(a1 + 16) = *(void *)(a2 + 16);
    *(void *)a2 = 0;
    *(void *)(a2 + 8) = 0;
    *(void *)(a2 + 16) = 0;
    std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::__move_assign(a1 + 24, (uint64_t *)(a2 + 24));
    std::__hash_table<std::__hash_value_type<ZinDependencyOffsetDim,long>,std::__unordered_map_hasher<ZinDependencyOffsetDim,std::__hash_value_type<ZinDependencyOffsetDim,long>,std::hash<ZinDependencyOffsetDim>,std::equal_to<ZinDependencyOffsetDim>,true>,std::__unordered_map_equal<ZinDependencyOffsetDim,std::__hash_value_type<ZinDependencyOffsetDim,long>,std::equal_to<ZinDependencyOffsetDim>,std::hash<ZinDependencyOffsetDim>,true>,std::allocator<std::__hash_value_type<ZinDependencyOffsetDim,long>>>::__move_assign(a1 + 64, (uint64_t *)(a2 + 64));
    long long v4 = *(_OWORD *)(a2 + 104);
    long long v5 = *(_OWORD *)(a2 + 120);
    *(unsigned char *)(a1 + 136) = *(unsigned char *)(a2 + 136);
    *(_OWORD *)(a1 + 120) = v5;
    *(_OWORD *)(a1 + 104) = v4;
    *(_OWORD *)(a1 + 144) = *(_OWORD *)(a2 + 144);
  }
  else
  {
    std::construct_at[abi:ne180100]<ZinMirSpatialSplitter::TilingResult,ZinMirSpatialSplitter::TilingResult,ZinMirSpatialSplitter::TilingResult*>(a1, a2);
    *(unsigned char *)(a1 + 160) = 1;
  }
  return a1;
}

uint64_t ZinMirSpatialSplitter::PruneForPerformance(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  std::__optional_destruct_base<ProducerConsumerChain,false>::reset[abi:ne180100](a4);
  int v29 = *(_DWORD *)a3;
  unint64_t v31 = 0;
  uint64_t v32 = 0;
  long long __p = 0;
  std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(&__p, *(const void **)(a3 + 8), *(void *)(a3 + 16), (uint64_t)(*(void *)(a3 + 16) - *(void *)(a3 + 8)) >> 3);
  std::unordered_set<ZinANELayer const*>::unordered_set((uint64_t)v33, a3 + 32);
  char v7 = __p;
  unint64_t v8 = v31;
  if (__p == v31) {
    goto LABEL_21;
  }
  uint64_t v22 = a4;
  uint64_t v9 = -(uint64_t)__p;
  uint64_t v10 = v31;
  uint64_t v11 = v31;
  uint64_t v12 = v31;
  uint64_t v13 = (LayerTilingHelper **)__p;
  while (1)
  {
    uint64_t v14 = v9;
    unint64_t v15 = *v13;
    if ((unint64_t)LayerTilingHelper::GetKernelDimsFrom(*v13, v6) < 2)
    {
      if (v11 == v8) {
        uint64_t v17 = v13;
      }
      else {
        uint64_t v17 = v11;
      }
      goto LABEL_16;
    }
    int v16 = *(_DWORD *)(*((void *)v15 + 8) + 8);
    if (v11 == v8)
    {
      if (v16 == 85) {
        uint64_t v10 = v13;
      }
      uint64_t v17 = v13;
      goto LABEL_16;
    }
    if (v16 != 85)
    {
      uint64_t v17 = v11;
      goto LABEL_16;
    }
    if (v10 == v8) {
      break;
    }
    uint64_t v17 = v13;
    uint64_t v10 = v13;
    if (v12 != v11)
    {
      uint64_t v17 = v11 + 1;
      goto LABEL_17;
    }
LABEL_16:
    uint64_t v12 = v13;
    uint64_t v9 = v14 - 8;
    uint64_t v11 = v17;
    if (++v13 == v8) {
      goto LABEL_17;
    }
  }
  uint64_t v17 = v11;
LABEL_17:
  if (v17 == v8 || (uint64_t v18 = -((uint64_t)v17 + v14), v18 < 8))
  {
LABEL_21:
    uint64_t v20 = 0;
    goto LABEL_22;
  }
  unint64_t v19 = ((unint64_t)v18 >> 3) + 1;
  if (v19 == ((char *)v8 - v7) >> 3) {
    goto LABEL_20;
  }
  int v23 = 16843008;
  *(_OWORD *)uint64_t v24 = 0u;
  long long v25 = 0u;
  long long v26 = 0u;
  uint64_t v27 = 0;
  int v28 = 1065353216;
  uint64_t v20 = ProducerConsumerChain::Extract((ProducerConsumerChain *)&v29, ((char *)v17 - v7) >> 3, v19, (ProducerConsumerChain *)&v23);
  if (!v20)
  {
    int v29 = v23;
    std::vector<DimensionMapping>::__assign_with_size[abi:ne180100]<DimensionMapping const*,DimensionMapping const*>((char *)&__p, (char *)v24[0], (uint64_t)v24[1], ((char *)v24[1] - (char *)v24[0]) >> 3);
    int v34 = v28;
    std::__hash_table<ZinIrOpLayer *,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,std::allocator<ZinIrOpLayer *>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<ZinIrOpLayer *,void *> *>>(v33, *((void **)&v26 + 1), 0);
    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&v25 + 8);
    if (v24[0])
    {
      v24[1] = v24[0];
      operator delete(v24[0]);
    }
LABEL_20:
    std::optional<ProducerConsumerChain>::operator=[abi:ne180100]<ProducerConsumerChain&,void>(v22, (uint64_t)&v29);
    goto LABEL_21;
  }
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&v25 + 8);
  if (v24[0])
  {
    v24[1] = v24[0];
    operator delete(v24[0]);
  }
LABEL_22:
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v33);
  if (__p)
  {
    unint64_t v31 = (LayerTilingHelper **)__p;
    operator delete(__p);
  }
  return v20;
}

void sub_21126AB74(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, char a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, char a19, void *__p,uint64_t a21)
{
}

void std::__optional_destruct_base<ProducerConsumerChain,false>::reset[abi:ne180100](uint64_t a1)
{
  if (*(unsigned char *)(a1 + 72))
  {
    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table(a1 + 32);
    uint64_t v2 = *(void **)(a1 + 8);
    if (v2)
    {
      *(void *)(a1 + 16) = v2;
      operator delete(v2);
    }
    *(unsigned char *)(a1 + 72) = 0;
  }
}

uint64_t std::optional<ProducerConsumerChain>::operator=[abi:ne180100]<ProducerConsumerChain&,void>(uint64_t a1, uint64_t a2)
{
  if (*(unsigned char *)(a1 + 72))
  {
    *(_DWORD *)a1 = *(_DWORD *)a2;
    if (a1 != a2)
    {
      std::vector<DimensionMapping>::__assign_with_size[abi:ne180100]<DimensionMapping const*,DimensionMapping const*>((char *)(a1 + 8), *(char **)(a2 + 8), *(void *)(a2 + 16), (uint64_t)(*(void *)(a2 + 16) - *(void *)(a2 + 8)) >> 3);
      *(_DWORD *)(a1 + 64) = *(_DWORD *)(a2 + 64);
      std::__hash_table<ZinIrOpLayer *,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,std::allocator<ZinIrOpLayer *>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<ZinIrOpLayer *,void *> *>>((void *)(a1 + 32), *(void **)(a2 + 48), 0);
    }
  }
  else
  {
    std::construct_at[abi:ne180100]<ProducerConsumerChain,ProducerConsumerChain&,ProducerConsumerChain*>(a1, a2);
    *(unsigned char *)(a1 + 72) = 1;
  }
  return a1;
}

uint64_t ZinMirSpatialSplitter::PruneForMemory(uint64_t a1, ProducerConsumerChain *a2, uint64_t a3)
{
  uint64_t v37 = 0;
  memset(v36, 0, sizeof(v36));
  memset(v39, 0, sizeof(v39));
  int v38 = 1065353216;
  int v40 = 1065353216;
  int64x2_t v41 = vdupq_n_s64(1uLL);
  int64x2_t v42 = v41;
  unint64_t v6 = *(void *)(*(void *)(*(uint64_t (**)(void, void, void))(**(void **)(*((void *)a2 + 2) - 8)
                                                                                + 40))(*(void *)(*((void *)a2 + 2) - 8), 0, 0)+ 64);
  uint64_t v7 = (*(uint64_t (**)(void, void, void))(**(void **)(*((void *)a2 + 2) - 8) + 40))(*(void *)(*((void *)a2 + 2) - 8), 0, 0);
  uint64_t v8 = SplitInfo::Construct(a2, v6, *(void *)(*(void *)v7 + 72), (uint64_t)v36, 0, **(void **)(a1 + 16), *(ZinIrOpLayer **)(a1 + 48));
  if (v8) {
    goto LABEL_34;
  }
  uint64_t v9 = *(uint64_t **)(a1 + 16);
  unint64_t v10 = *(void *)(*v9 + 408);
  SplitInfoMetrics::SplitInfoMetrics(v33, *v9, v10, 0, (uint64_t)a2, v36);
  if (SplitInfoMetrics::GetWorstNonResidentFootprintRequirement((SplitInfoMetrics *)v33) > v10)
  {
    unint64_t v11 = ((uint64_t)(*((void *)a2 + 2) - *((void *)a2 + 1)) >> 3) - 1;
    LOBYTE(v26) = 0;
    std::vector<BOOL>::vector(&__p, v11, (unsigned __int8 *)&v26);
    if (*((void *)a2 + 2) - *((void *)a2 + 1) == 8)
    {
      unint64_t v12 = v32;
      if (!v32) {
        goto LABEL_29;
      }
      unint64_t v13 = 0;
    }
    else
    {
      unint64_t v14 = 0;
      do
      {
        uint64_t NonResidentFootprintAtLayer = SplitInfoMetrics::GetNonResidentFootprintAtLayer((SplitInfoMetrics *)v33, v14, 0);
        unint64_t v16 = v14 + 1;
        uint64_t v17 = SplitInfoMetrics::GetNonResidentFootprintAtLayer((SplitInfoMetrics *)v33, v14 + 1, 0);
        unint64_t v18 = v14 >> 6;
        uint64_t v19 = 1 << v14;
        if (v17 | NonResidentFootprintAtLayer) {
          uint64_t v20 = *((void *)__p + v18) & ~v19;
        }
        else {
          uint64_t v20 = *((void *)__p + v18) | v19;
        }
        *((void *)__p + v18) = v20;
        unint64_t v13 = ((uint64_t)(*((void *)a2 + 2) - *((void *)a2 + 1)) >> 3) - 1;
        ++v14;
      }
      while (v16 < v13);
      unint64_t v12 = v32;
      if (!v32)
      {
        if ((uint64_t)(*((void *)a2 + 2) - *((void *)a2 + 1)) >> 3 == 1) {
          goto LABEL_29;
        }
        unint64_t v21 = 0;
        goto LABEL_25;
      }
    }
    unint64_t v21 = 0;
    while (((*(void *)((char *)__p + ((v21 >> 3) & 0x1FFFFFFFFFFFFFF8)) >> v21) & 1) != 0)
    {
      if (v12 == ++v21)
      {
        unint64_t v21 = v12;
        break;
      }
    }
    if (v21 == v13) {
      goto LABEL_29;
    }
    unint64_t v22 = v12 - v21;
    if (v12 > v21)
    {
      unint64_t v23 = 0;
      unint64_t v24 = v21 - v12;
      while (((*(void *)((char *)__p + (((v21 + v23) >> 3) & 0x1FFFFFFFFFFFFFF8)) >> (v21
                                                                                         + v23)) & 1) == 0)
      {
        ++v23;
        if (!(v24 + v23))
        {
          unint64_t v23 = v22;
          goto LABEL_26;
        }
      }
      goto LABEL_26;
    }
LABEL_25:
    unint64_t v23 = 0;
LABEL_26:
    if (v21 || v23 != v13)
    {
      int v26 = 16843008;
      *(_OWORD *)uint64_t v27 = 0u;
      memset(v28, 0, sizeof(v28));
      uint64_t v29 = 0;
      int v30 = 1065353216;
      uint64_t v8 = ProducerConsumerChain::Extract(a2, v21, v23 + 1, (ProducerConsumerChain *)&v26);
      if (!v8) {
        uint64_t v8 = ZinMirSpatialSplitter::PruneForMemory(a1, &v26, a3);
      }
      std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v28 + 8);
      if (v27[0])
      {
        v27[1] = v27[0];
        operator delete(v27[0]);
      }
      goto LABEL_30;
    }
    std::optional<ProducerConsumerChain>::operator=[abi:ne180100]<ProducerConsumerChain const&,void>(a3, (uint64_t)a2);
LABEL_29:
    uint64_t v8 = 0;
LABEL_30:
    if (__p) {
      operator delete(__p);
    }
    goto LABEL_32;
  }
  uint64_t v8 = 0;
LABEL_32:
  if (v34)
  {
    unint64_t v35 = v34;
    operator delete(v34);
  }
LABEL_34:
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v39);
  std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::~__hash_table((uint64_t)&v36[3]);
  v33[0] = (void **)v36;
  std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__destroy_vector::operator()[abi:ne180100](v33);
  return v8;
}

void sub_21126AFE8(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, char a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, void *__p, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,void *a29,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33,uint64_t a34,void *a35)
{
  if (__p) {
    operator delete(__p);
  }
  if (a29) {
    operator delete(a29);
  }
  SplitInfo::~SplitInfo(&a35);
  _Unwind_Resume(a1);
}

uint64_t std::optional<ProducerConsumerChain>::operator=[abi:ne180100]<ProducerConsumerChain const&,void>(uint64_t a1, uint64_t a2)
{
  if (*(unsigned char *)(a1 + 72))
  {
    *(_DWORD *)a1 = *(_DWORD *)a2;
    if (a1 != a2)
    {
      std::vector<DimensionMapping>::__assign_with_size[abi:ne180100]<DimensionMapping const*,DimensionMapping const*>((char *)(a1 + 8), *(char **)(a2 + 8), *(void *)(a2 + 16), (uint64_t)(*(void *)(a2 + 16) - *(void *)(a2 + 8)) >> 3);
      *(_DWORD *)(a1 + 64) = *(_DWORD *)(a2 + 64);
      std::__hash_table<ZinIrOpLayer *,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,std::allocator<ZinIrOpLayer *>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<ZinIrOpLayer *,void *> *>>((void *)(a1 + 32), *(void **)(a2 + 48), 0);
    }
  }
  else
  {
    std::construct_at[abi:ne180100]<ProducerConsumerChain,ProducerConsumerChain const&,ProducerConsumerChain*>(a1, a2);
    *(unsigned char *)(a1 + 72) = 1;
  }
  return a1;
}

uint64_t ZinMirSpatialSplitter::DetermineOptimizedPlan(uint64_t a1, ZinIrOpLayerGraph *a2, int a3, ZinIrOpLayer *a4, uint64_t a5)
{
  uint64_t v65 = *MEMORY[0x263EF8340];
  std::__optional_destruct_base<ZinMirSpatialSplitter::SplitPlan,false>::reset[abi:ne180100](a5);
  int v45 = 16843008;
  long long v46 = 0u;
  memset(v47, 0, sizeof(v47));
  uint64_t v48 = 0;
  int v49 = 1065353216;
  ProducerConsumerChain::Analyze((ProducerConsumerChain *)&v45, a2, a4, **(const ZinIrHalParameters ***)(a1 + 16), (uint64_t)v44);
  if (!v44[72])
  {
    uint64_t AllSubChains = 0;
    goto LABEL_37;
  }
  v42[0] = 0;
  char v43 = 0;
  uint64_t AllSubChains = ZinMirSpatialSplitter::PruneForMemory(a1, (ProducerConsumerChain *)v44, (uint64_t)v42);
  if (!AllSubChains)
  {
    if (v43)
    {
      unint64_t v39 = 0;
      int v40 = 0;
      uint64_t v41 = 0;
      int v40 = (uint64_t *)std::vector<ProducerConsumerChain>::__push_back_slow_path<ProducerConsumerChain const&>((uint64_t *)&v39, (uint64_t)v42);
      v38[0] = 0;
      v38[1] = 0;
      uint64_t v37 = v38;
      __src[1] = 0;
      __src[0] = 0;
      *(void *)&v52[0] = 0;
      if (!v43) {
        std::__throw_bad_optional_access[abi:ne180100]();
      }
      uint64_t AllSubChains = ProducerConsumerChain::ExtractAllSubChains((ProducerConsumerChain *)v42, (uint64_t *)__src);
      if (AllSubChains)
      {
        unint64_t v24 = __src;
        std::vector<ProducerConsumerChain>::__destroy_vector::operator()[abi:ne180100](&v24);
LABEL_35:
        std::__tree<std::__value_type<std::string,SpatialSplitMode>,std::__map_value_compare<std::string,std::__value_type<std::string,SpatialSplitMode>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,SpatialSplitMode>>>::destroy((uint64_t)&v37, v38[0]);
        __src[0] = &v39;
        std::vector<ProducerConsumerChain>::__destroy_vector::operator()[abi:ne180100]((void ***)__src);
        goto LABEL_36;
      }
      std::vector<ProducerConsumerChain>::__insert_with_size[abi:ne180100]<std::__wrap_iter<ProducerConsumerChain*>,std::__wrap_iter<ProducerConsumerChain*>>((uint64_t *)&v39, v40, (uint64_t)__src[0], (uint64_t)__src[1], 0x8E38E38E38E38E39 * (((char *)__src[1] - (char *)__src[0]) >> 3));
      unint64_t v24 = __src;
      std::vector<ProducerConsumerChain>::__destroy_vector::operator()[abi:ne180100](&v24);
      __src[0] = (void *)0x100000000;
      uint64_t v11 = (uint64_t)std::vector<SplitInfoMetrics::ResInputOutputMode>::vector[abi:ne180100](&v35, __src, 2uLL);
      uint64_t v13 = (uint64_t)v39;
      uint64_t v20 = v40;
      if (v39 == v40)
      {
LABEL_31:
        uint64_t AllSubChains = 0;
LABEL_33:
        if (v35)
        {
          int v36 = (int *)v35;
          operator delete(v35);
        }
        goto LABEL_35;
      }
      unint64_t v21 = (ZinMirSpatialSplitter::SplitPlan *)a5;
      unint64_t v23 = 0;
      int64x2_t v22 = vdupq_n_s64(1uLL);
      int v19 = a3;
      while (1)
      {
        if (a3 != 2) {
          goto LABEL_17;
        }
        LOBYTE(__src[0]) = 0;
        LOBYTE(v55[1]) = 0;
        uint64_t AllSubChains = ZinMirSpatialSplitter::PruneForPerformance(v11, v12, v13, (uint64_t)__src);
        if (AllSubChains)
        {
          std::__optional_destruct_base<ProducerConsumerChain,false>::~__optional_destruct_base[abi:ne180100]((uint64_t)__src);
          goto LABEL_33;
        }
        if (LOBYTE(v55[1])) {
          break;
        }
        uint64_t v11 = std::__optional_destruct_base<ProducerConsumerChain,false>::~__optional_destruct_base[abi:ne180100]((uint64_t)__src);
LABEL_30:
        v13 += 72;
        a3 = v19;
        if ((uint64_t *)v13 == v20) {
          goto LABEL_31;
        }
      }
      *(_DWORD *)uint64_t v13 = __src[0];
      if ((void **)v13 != __src)
      {
        std::vector<DimensionMapping>::__assign_with_size[abi:ne180100]<DimensionMapping const*,DimensionMapping const*>((char *)(v13 + 8), (char *)__src[1], *(uint64_t *)&v52[0], (uint64_t)(*(void *)&v52[0] - (unint64_t)__src[1]) >> 3);
        *(_DWORD *)(v13 + 64) = v55[0];
        std::__hash_table<ZinIrOpLayer *,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,std::allocator<ZinIrOpLayer *>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<ZinIrOpLayer *,void *> *>>((void *)(v13 + 32), v53, 0);
      }
      uint64_t v11 = std::__optional_destruct_base<ProducerConsumerChain,false>::~__optional_destruct_base[abi:ne180100]((uint64_t)__src);
LABEL_17:
      unint64_t v15 = (int *)v35;
      unint64_t v14 = v36;
      while (v15 != v14)
      {
        int v16 = *v15;
        LOBYTE(v24) = 0;
        char v34 = 0;
        uint64_t AllSubChains = ZinMirSpatialSplitter::DetermineTiling(a1, (ProducerConsumerChain *)v13, v16, (uint64_t)&v24);
        if (AllSubChains)
        {
          std::__optional_destruct_base<ZinMirSpatialSplitter::TilingResult,false>::~__optional_destruct_base[abi:ne180100]((uint64_t)&v24);
          goto LABEL_33;
        }
        if (v34)
        {
          unint64_t v53 = 0;
          memset(v52, 0, sizeof(v52));
          *(_OWORD *)__src = 0u;
          memset(v55, 0, sizeof(v55));
          int v54 = 1065353216;
          int v56 = 1065353216;
          int64x2_t v57 = v22;
          int64x2_t v58 = v22;
          memset(__p, 0, sizeof(__p));
          int v61 = 0;
          int v63 = 1065353216;
          int v64 = 0;
          std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__assign_with_size[abi:ne180100]<std::vector<std::optional<TiledLayerTensorRegions>>*,std::vector<std::optional<TiledLayerTensorRegions>>*>((uint64_t)__src, (uint64_t *)v24, v25, 0xAAAAAAAAAAAAAAABLL * (((char *)v25 - (char *)v24) >> 3));
          int v54 = v27;
          std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,void *> *>>((void *)v52 + 1, v26, 0);
          int v56 = v29;
          std::__hash_table<ZinIrOpLayer *,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,std::allocator<ZinIrOpLayer *>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<ZinIrOpLayer *,void *> *>>(v55, v28, 0);
          int64x2_t v57 = v30;
          int64x2_t v58 = v31;
          char v59 = v32;
          long long v60 = v33;
          int v61 = *(_DWORD *)v13;
          if (&v61 != (int *)v13)
          {
            std::vector<DimensionMapping>::__assign_with_size[abi:ne180100]<DimensionMapping const*,DimensionMapping const*>((char *)__p, *(char **)(v13 + 8), *(void *)(v13 + 16), (uint64_t)(*(void *)(v13 + 16) - *(void *)(v13 + 8)) >> 3);
            int v63 = *(_DWORD *)(v13 + 64);
            std::__hash_table<ZinIrOpLayer *,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,std::allocator<ZinIrOpLayer *>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<ZinIrOpLayer *,void *> *>>(&__p[3], *(void **)(v13 + 48), 0);
          }
          unint64_t v17 = (0x5555555555555555 * (((char *)__src[1] - (char *)__src[0]) >> 3) + 0xFFFFFFFFLL) | ((void)v60 << 32);
          if (v17 > v23)
          {
            std::optional<ZinMirSpatialSplitter::SplitPlan>::operator=[abi:ne180100]<ZinMirSpatialSplitter::SplitPlan&,void>(v21, (const ZinMirSpatialSplitter::SplitPlan *)__src);
            unint64_t v23 = v17;
          }
          std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&__p[3]);
          if (__p[0])
          {
            __p[1] = __p[0];
            operator delete(__p[0]);
          }
          std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v55);
          std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::~__hash_table((uint64_t)v52 + 8);
          uint64_t v50 = __src;
          std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__destroy_vector::operator()[abi:ne180100](&v50);
        }
        uint64_t v11 = std::__optional_destruct_base<ZinMirSpatialSplitter::TilingResult,false>::~__optional_destruct_base[abi:ne180100]((uint64_t)&v24);
        ++v15;
      }
      goto LABEL_30;
    }
    uint64_t AllSubChains = 0;
  }
LABEL_36:
  std::__optional_destruct_base<ProducerConsumerChain,false>::~__optional_destruct_base[abi:ne180100]((uint64_t)v42);
LABEL_37:
  std::__optional_destruct_base<ProducerConsumerChain,false>::~__optional_destruct_base[abi:ne180100]((uint64_t)v44);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&v47[8]);
  if ((void)v46)
  {
    *((void *)&v46 + 1) = v46;
    operator delete((void *)v46);
  }
  return AllSubChains;
}

void sub_21126B5C0(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33,uint64_t a34,uint64_t a35,uint64_t a36,uint64_t a37,uint64_t a38,uint64_t a39,uint64_t a40,uint64_t a41,void *__p,uint64_t a43,uint64_t a44,char a45,uint64_t a46,uint64_t a47,char a48,uint64_t a49,uint64_t a50,char a51,uint64_t a52,uint64_t a53,uint64_t a54,uint64_t a55,uint64_t a56,uint64_t a57,uint64_t a58,uint64_t a59,uint64_t a60,char a61,uint64_t a62,uint64_t a63)
{
  std::__tree<std::__value_type<std::string,SpatialSplitMode>,std::__map_value_compare<std::string,std::__value_type<std::string,SpatialSplitMode>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,SpatialSplitMode>>>::destroy((uint64_t)&a45, (char *)a46);
  STACK[0x240] = (unint64_t)&a48;
  std::vector<ProducerConsumerChain>::__destroy_vector::operator()[abi:ne180100]((void ***)&STACK[0x240]);
  std::__optional_destruct_base<ProducerConsumerChain,false>::~__optional_destruct_base[abi:ne180100]((uint64_t)&a51);
  std::__optional_destruct_base<ProducerConsumerChain,false>::~__optional_destruct_base[abi:ne180100]((uint64_t)&a61);
  ProducerConsumerChain::~ProducerConsumerChain((ProducerConsumerChain *)&a71);
  _Unwind_Resume(a1);
}

void std::__optional_destruct_base<ZinMirSpatialSplitter::SplitPlan,false>::reset[abi:ne180100](uint64_t a1)
{
  if (*(unsigned char *)(a1 + 240))
  {
    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table(a1 + 192);
    uint64_t v2 = *(void **)(a1 + 168);
    if (v2)
    {
      *(void *)(a1 + 176) = v2;
      operator delete(v2);
    }
    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table(a1 + 64);
    std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::~__hash_table(a1 + 24);
    uint64_t v3 = (void **)a1;
    std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__destroy_vector::operator()[abi:ne180100](&v3);
    *(unsigned char *)(a1 + 240) = 0;
  }
}

void *std::vector<SplitInfoMetrics::ResInputOutputMode>::vector[abi:ne180100](void *a1, const void *a2, unint64_t a3)
{
  *a1 = 0;
  a1[1] = 0;
  a1[2] = 0;
  if (a3)
  {
    std::vector<ZinIrPaddingMode>::__vallocate[abi:ne180100](a1, a3);
    unint64_t v6 = (char *)a1[1];
    memmove(v6, a2, 4 * a3);
    a1[1] = &v6[4 * a3];
  }
  return a1;
}

void sub_21126B748(_Unwind_Exception *exception_object)
{
  uint64_t v3 = *(void **)v1;
  if (*(void *)v1)
  {
    *(void *)(v1 + 8) = v3;
    operator delete(v3);
  }
  _Unwind_Resume(exception_object);
}

ZinMirSpatialSplitter::SplitPlan *std::optional<ZinMirSpatialSplitter::SplitPlan>::operator=[abi:ne180100]<ZinMirSpatialSplitter::SplitPlan&,void>(ZinMirSpatialSplitter::SplitPlan *this, const ZinMirSpatialSplitter::SplitPlan *a2)
{
  if (*((unsigned char *)this + 240))
  {
    ZinMirSpatialSplitter::SplitPlan::operator=((uint64_t)this, (uint64_t)a2);
  }
  else
  {
    ZinMirSpatialSplitter::SplitPlan::SplitPlan(this, a2);
    *((unsigned char *)this + 240) = 1;
  }
  return this;
}

void ZinMirSpatialSplitter::SplitPlan::~SplitPlan(ZinMirSpatialSplitter::SplitPlan *this)
{
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)this + 192);
  uint64_t v2 = (void *)*((void *)this + 21);
  if (v2)
  {
    *((void *)this + 22) = v2;
    operator delete(v2);
  }
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)this + 64);
  std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::~__hash_table((uint64_t)this + 24);
  uint64_t v3 = (void **)this;
  std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__destroy_vector::operator()[abi:ne180100](&v3);
}

uint64_t ZinMirSpatialSplitter::DetermineStessTestingPlan(uint64_t a1, ZinIrOpLayerGraph *a2, ZinIrOpLayer *a3, uint64_t a4)
{
  std::__optional_destruct_base<ZinMirSpatialSplitter::SplitPlan,false>::reset[abi:ne180100](a4);
  int v38 = 16843008;
  long long v39 = 0u;
  memset(v40, 0, sizeof(v40));
  uint64_t v41 = 0;
  int v42 = 1065353216;
  ProducerConsumerChain::Analyze((ProducerConsumerChain *)&v38, a2, a3, **(const ZinIrHalParameters ***)(a1 + 16), (uint64_t)v35);
  if (v37)
  {
    uint64_t v8 = (*(uint64_t (**)(void, void, void))(**(void **)(v36 - 8) + 40))(*(void *)(v36 - 8), 0, 0);
    unint64_t v9 = *(void *)(*(void *)v8 + 64);
    if (v9 < 4)
    {
      unint64_t v11 = 1;
    }
    else
    {
      unint64_t v10 = ZinAlignPower2(*(void *)(*(void *)v8 + 64), 2);
      if (0xAAAAAAAAAAAAAAABLL * v9 <= 0x5555555555555555) {
        unint64_t v11 = v10 / 3;
      }
      else {
        unint64_t v11 = v10 / 3 + 1;
      }
    }
    uint64_t v28 = 0;
    memset(v27, 0, sizeof(v27));
    int v29 = 1065353216;
    memset(v30, 0, sizeof(v30));
    int v31 = 1065353216;
    int64x2_t v32 = vdupq_n_s64(1uLL);
    int64x2_t v33 = v32;
    uint64_t v13 = (*(uint64_t (**)(void, void, void))(**(void **)(v36 - 8) + 40))(*(void *)(v36 - 8), 0, 0);
    uint64_t v12 = SplitInfo::Construct((ProducerConsumerChain *)v35, v11, *(void *)(*(void *)v13 + 72), (uint64_t)v27, 0, **(void **)(a1 + 16), *(ZinIrOpLayer **)(a1 + 48));
    if (!v12)
    {
      memset(v15, 0, sizeof(v15));
      std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__init_with_size[abi:ne180100]<std::vector<std::optional<TiledLayerTensorRegions>>*,std::vector<std::optional<TiledLayerTensorRegions>>*>(v15, *(uint64_t **)&v27[0], *((uint64_t **)&v27[0] + 1), 0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*((void *)&v27[0] + 1) - *(void *)&v27[0]) >> 3));
      std::unordered_map<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>::unordered_map((uint64_t)v16, (uint64_t)&v27[1] + 8);
      std::unordered_set<ZinIrOpLayer const*>::unordered_set((uint64_t)v17, (uint64_t)v30);
      *(int64x2_t *)&v17[40] = v32;
      int64x2_t v18 = v33;
      char v19 = v34;
      uint64_t v20 = 0;
      uint64_t v21 = 0;
      int v22 = v38;
      unint64_t v24 = 0;
      uint64_t v25 = 0;
      long long __p = 0;
      std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(&__p, (const void *)v39, *((uint64_t *)&v39 + 1), (uint64_t)(*((void *)&v39 + 1) - v39) >> 3);
      std::unordered_set<ZinANELayer const*>::unordered_set((uint64_t)v26, (uint64_t)v40 + 8);
      v26[10] = 0;
      std::optional<ZinMirSpatialSplitter::SplitPlan>::operator=[abi:ne180100]<ZinMirSpatialSplitter::SplitPlan,void>(a4, (uint64_t)v15);
      std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v26);
      if (__p)
      {
        unint64_t v24 = __p;
        operator delete(__p);
      }
      std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v17);
      std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::~__hash_table((uint64_t)v16);
      char v43 = v15;
      std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v43);
    }
    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v30);
    std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::~__hash_table((uint64_t)&v27[1] + 8);
    v15[0] = (void **)v27;
    std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__destroy_vector::operator()[abi:ne180100](v15);
  }
  else
  {
    uint64_t v12 = 0;
  }
  std::__optional_destruct_base<ProducerConsumerChain,false>::~__optional_destruct_base[abi:ne180100]((uint64_t)v35);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v40 + 8);
  if ((void)v39)
  {
    *((void *)&v39 + 1) = v39;
    operator delete((void *)v39);
  }
  return v12;
}

void sub_21126BB08(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,void *__p,uint64_t a31,uint64_t a32,uint64_t a33,uint64_t a34,uint64_t a35,uint64_t a36,uint64_t a37,uint64_t a38,void *a39)
{
  ZinMirSpatialSplitter::SplitPlan::~SplitPlan((ZinMirSpatialSplitter::SplitPlan *)&a9);
  SplitInfo::~SplitInfo(&a39);
  std::__optional_destruct_base<ProducerConsumerChain,false>::~__optional_destruct_base[abi:ne180100](v39 - 224);
  ProducerConsumerChain::~ProducerConsumerChain((ProducerConsumerChain *)(v39 - 144));
  _Unwind_Resume(a1);
}

uint64_t std::optional<ZinMirSpatialSplitter::SplitPlan>::operator=[abi:ne180100]<ZinMirSpatialSplitter::SplitPlan,void>(uint64_t a1, uint64_t a2)
{
  if (*(unsigned char *)(a1 + 240))
  {
    std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__vdeallocate((void ***)a1);
    *(_OWORD *)a1 = *(_OWORD *)a2;
    *(void *)(a1 + 16) = *(void *)(a2 + 16);
    *(void *)a2 = 0;
    *(void *)(a2 + 8) = 0;
    *(void *)(a2 + 16) = 0;
    std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::__move_assign(a1 + 24, (uint64_t *)(a2 + 24));
    std::__hash_table<std::__hash_value_type<ZinDependencyOffsetDim,long>,std::__unordered_map_hasher<ZinDependencyOffsetDim,std::__hash_value_type<ZinDependencyOffsetDim,long>,std::hash<ZinDependencyOffsetDim>,std::equal_to<ZinDependencyOffsetDim>,true>,std::__unordered_map_equal<ZinDependencyOffsetDim,std::__hash_value_type<ZinDependencyOffsetDim,long>,std::equal_to<ZinDependencyOffsetDim>,std::hash<ZinDependencyOffsetDim>,true>,std::allocator<std::__hash_value_type<ZinDependencyOffsetDim,long>>>::__move_assign(a1 + 64, (uint64_t *)(a2 + 64));
    long long v4 = *(_OWORD *)(a2 + 104);
    long long v5 = *(_OWORD *)(a2 + 120);
    *(unsigned char *)(a1 + 136) = *(unsigned char *)(a2 + 136);
    *(_OWORD *)(a1 + 120) = v5;
    *(_OWORD *)(a1 + 104) = v4;
    *(_OWORD *)(a1 + 144) = *(_OWORD *)(a2 + 144);
    *(_DWORD *)(a1 + 160) = *(_DWORD *)(a2 + 160);
    std::vector<ANEDebugInfo::DebugInfoInMem::Layer>::__move_assign(a1 + 168, (__n128 *)(a2 + 168));
    std::__hash_table<std::__hash_value_type<ZinDependencyOffsetDim,long>,std::__unordered_map_hasher<ZinDependencyOffsetDim,std::__hash_value_type<ZinDependencyOffsetDim,long>,std::hash<ZinDependencyOffsetDim>,std::equal_to<ZinDependencyOffsetDim>,true>,std::__unordered_map_equal<ZinDependencyOffsetDim,std::__hash_value_type<ZinDependencyOffsetDim,long>,std::equal_to<ZinDependencyOffsetDim>,std::hash<ZinDependencyOffsetDim>,true>,std::allocator<std::__hash_value_type<ZinDependencyOffsetDim,long>>>::__move_assign(a1 + 192, (uint64_t *)(a2 + 192));
    *(_DWORD *)(a1 + 232) = *(_DWORD *)(a2 + 232);
  }
  else
  {
    std::construct_at[abi:ne180100]<ZinMirSpatialSplitter::SplitPlan,ZinMirSpatialSplitter::SplitPlan,ZinMirSpatialSplitter::SplitPlan*>(a1, a2);
    *(unsigned char *)(a1 + 240) = 1;
  }
  return a1;
}

uint64_t ZinMirSpatialSplitter::DetermineMinimalSplitPlan(uint64_t a1, ZinANELayer ***a2, unint64_t a3, uint64_t a4)
{
  uint64_t v53 = *MEMORY[0x263EF8340];
  std::__optional_destruct_base<ZinMirSpatialSplitter::SplitPlan,false>::reset[abi:ne180100](a4);
  int v34 = 16843008;
  long long v35 = 0u;
  memset(v36, 0, sizeof(v36));
  uint64_t v37 = 0;
  int v38 = 1065353216;
  *(void *)&long long v40 = 0x100000000;
  std::unordered_set<SpatialDimension>::unordered_set((uint64_t)v32, (unsigned int *)&v40, 2);
  unint64_t v9 = *a2;
  uint64_t v8 = a2[1];
  while (v9 != v8)
    ProducerConsumerChain::AppendLayer((ProducerConsumerChain *)&v34, *v9++);
  unint64_t v11 = (const ZinIrOpLayer **)*((void *)&v35 + 1);
  unint64_t v10 = (const ZinIrOpLayer **)v35;
  if ((void)v35 != *((void *)&v35 + 1))
  {
    while (1)
    {
      ProducerConsumerChain::IsLayerAdmissible((ProducerConsumerChain *)&v34, *v10, **(const ZinIrHalParameters ***)(a1 + 16), v24);
      long long v40 = 0u;
      long long v41 = 0u;
      int v42 = 1065353216;
      uint64_t v12 = *(_OWORD **)&v24[0];
      if (*(_OWORD **)&v24[0] == (_OWORD *)((char *)v24 + 8)) {
        break;
      }
      do
      {
        LODWORD(v39) = *((_DWORD *)v12 + 7);
        if (std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::find<unsigned int>(v32, (unsigned int *)&v39))
        {
          std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::__emplace_unique_key_args<unsigned int,unsigned int const&>((uint64_t)&v40, (unsigned int *)&v39, &v39);
        }
        uint64_t v13 = (void *)*((void *)v12 + 1);
        if (v13)
        {
          do
          {
            unint64_t v14 = v13;
            uint64_t v13 = (void *)*v13;
          }
          while (v13);
        }
        else
        {
          do
          {
            unint64_t v14 = (_OWORD *)*((void *)v12 + 2);
            BOOL v15 = *(void *)v14 == (void)v12;
            uint64_t v12 = v14;
          }
          while (!v15);
        }
        uint64_t v12 = v14;
      }
      while (v14 != (_OWORD *)((char *)v24 + 8));
      if (!*((void *)&v41 + 1)) {
        break;
      }
      int v33 = v42;
      std::__hash_table<SpatialDimension,std::hash<SpatialDimension>,std::equal_to<SpatialDimension>,std::allocator<SpatialDimension>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<SpatialDimension,void *> *>>(v32, (unsigned int *)v41, 0);
      std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&v40);
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v24, *((void **)&v24[0] + 1));
      if (++v10 == v11)
      {
        unint64_t v10 = (const ZinIrOpLayer **)*((void *)&v35 + 1);
        goto LABEL_17;
      }
    }
    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&v40);
    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v24, *((void **)&v24[0] + 1));
    goto LABEL_28;
  }
LABEL_17:
  unint64_t v16 = *(void *)(*(void *)(*(uint64_t (**)(void, void, void))(*(void *)*(v10 - 1) + 40))(*(v10 - 1), 0, 0)+ 64);
  unint64_t v17 = *(void *)(*(void *)(*(uint64_t (**)(void, void, void))(**(void **)(*((void *)&v35 + 1)
                                                                                               - 8)
                                                                                 + 40))(*(void *)(*((void *)&v35 + 1) - 8), 0, 0)+ 72);
  if (v16 >= a3
    && (LODWORD(v40) = 0,
        std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::find<unsigned int>(v32, (unsigned int *)&v40)))
  {
    unint64_t v16 = (a3 + v16 - 1) / a3;
    int64x2_t v18 = *(ZinNEConvLayer **)(*((void *)&v35 + 1) - 8);
    if (*(_DWORD *)(*((void *)v18 + 8) + 8) == 85 && *((void *)v18 + 54))
    {
      if ((*(unsigned char *)(ZinNEConvLayer::GetKernelDescriptor(v18) + 272) & 0x40) != 0) {
        v16 -= (v16 != 1) & v16;
      }
      int v19 = 0;
    }
    else
    {
      int v19 = 0;
    }
  }
  else
  {
    LODWORD(v40) = 1;
    if (!std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::find<unsigned int>(v32, (unsigned int *)&v40)|| ((*(uint64_t (**)(void))(**(void **)(*((void *)&v35 + 1) - 8) + 408))(*(void *)(*((void *)&v35 + 1) - 8)) & 1) != 0)
    {
LABEL_28:
      uint64_t v20 = 3;
      goto LABEL_37;
    }
    *(void *)&long long v40 = 0;
    uint64_t v21 = (*(uint64_t (**)(void, void, void))(**(void **)(*((void *)&v35 + 1) - 8) + 40))(*(void *)(*((void *)&v35 + 1) - 8), 0, 0);
    if (ZinTensorFormatGetSizeInBytes(*(_DWORD *)(*(void *)v21 + 88), (uint64_t *)&v40)) {
      ZinAssertImpl("Error in getting tensor format size in bytes");
    }
    unint64_t v22 = *(void *)(**(void **)(a1 + 16) + 528) / (unint64_t)v40;
    unint64_t v17 = ZinDivRoundUp(v17, v22) / a3 * v22;
    int v19 = 1;
  }
  uint64_t v25 = 0;
  memset(v24, 0, sizeof(v24));
  int v26 = 1065353216;
  memset(v27, 0, sizeof(v27));
  int v28 = 1065353216;
  int64x2_t v29 = vdupq_n_s64(1uLL);
  int64x2_t v30 = v29;
  uint64_t v20 = SplitInfo::Construct((ProducerConsumerChain *)&v34, v16, v17, (uint64_t)v24, 0, **(void **)(a1 + 16), *(ZinIrOpLayer **)(a1 + 48));
  if (!v20)
  {
    long long v40 = 0uLL;
    *(void *)&long long v41 = 0;
    std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__init_with_size[abi:ne180100]<std::vector<std::optional<TiledLayerTensorRegions>>*,std::vector<std::optional<TiledLayerTensorRegions>>*>(&v40, *(uint64_t **)&v24[0], *((uint64_t **)&v24[0] + 1), 0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*((void *)&v24[0] + 1) - *(void *)&v24[0]) >> 3));
    std::unordered_map<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>::unordered_map((uint64_t)&v41 + 8, (uint64_t)&v24[1] + 8);
    std::unordered_set<ZinIrOpLayer const*>::unordered_set((uint64_t)v43, (uint64_t)v27);
    *(int64x2_t *)&v43[40] = v29;
    int64x2_t v44 = v30;
    char v45 = v31;
    uint64_t v46 = 0;
    uint64_t v47 = 0;
    int v48 = v34;
    uint64_t v50 = 0;
    uint64_t v51 = 0;
    long long __p = 0;
    std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(&__p, (const void *)v35, *((uint64_t *)&v35 + 1), (uint64_t)(*((void *)&v35 + 1) - v35) >> 3);
    std::unordered_set<ZinANELayer const*>::unordered_set((uint64_t)v52, (uint64_t)&v36[8]);
    v52[10] = v19;
    std::optional<ZinMirSpatialSplitter::SplitPlan>::operator=[abi:ne180100]<ZinMirSpatialSplitter::SplitPlan,void>(a4, (uint64_t)&v40);
    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v52);
    if (__p)
    {
      uint64_t v50 = __p;
      operator delete(__p);
    }
    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v43);
    std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::~__hash_table((uint64_t)&v41 + 8);
    uint64_t v39 = (void **)&v40;
    std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__destroy_vector::operator()[abi:ne180100](&v39);
  }
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v27);
  std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::~__hash_table((uint64_t)&v24[1] + 8);
  *(void *)&long long v40 = v24;
  std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v40);
LABEL_37:
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v32);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&v36[8]);
  if ((void)v35)
  {
    *((void *)&v35 + 1) = v35;
    operator delete((void *)v35);
  }
  return v20;
}

void sub_21126C1CC(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,char a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,char a33)
{
}

uint64_t ZinMirSpatialSplitter::DeterminePlanStartingAt(uint64_t a1, ZinIrOpLayerGraph *a2, int a3, ZinIrOpLayer *a4, uint64_t a5)
{
  std::__optional_destruct_base<ZinMirSpatialSplitter::SplitPlan,false>::reset[abi:ne180100](a5);
  if ((a3 - 1) >= 2)
  {
    if (a3) {
      return 3;
    }
    uint64_t result = ZinMirSpatialSplitter::DetermineStessTestingPlan(a1, a2, a4, a5);
    if (result) {
      return result;
    }
  }
  else
  {
    uint64_t result = ZinMirSpatialSplitter::DetermineOptimizedPlan(a1, a2, a3, a4, a5);
    if (result) {
      return result;
    }
  }
  if (*(unsigned char *)(a5 + 240))
  {
    if (((uint64_t)(*(void *)(a5 + 176) - *(void *)(a5 + 168)) >> 3)
       * (0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*(void *)(a5 + 8) - *(void *)a5) >> 3) - 1) > (unint64_t)(float)((float)*(unint64_t *)(**(void **)(a1 + 16) + 32) * 0.8))
      std::__optional_destruct_base<ZinMirSpatialSplitter::SplitPlan,false>::reset[abi:ne180100](a5);
  }
  return 0;
}

uint64_t ZinMirSpatialSplitter::SplitLayers(ZinIrOpLayer **a1, uint64_t **a2, uint64_t a3, unint64_t a4)
{
  v13[0] = 0;
  char v14 = 0;
  unint64_t v11 = 0;
  uint64_t v12 = 0;
  long long __p = 0;
  std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(&__p, *(const void **)a3, *(void *)(a3 + 8), (uint64_t)(*(void *)(a3 + 8) - *(void *)a3) >> 3);
  uint64_t v7 = ZinMirSpatialSplitter::DetermineMinimalSplitPlan((uint64_t)a1, (ZinANELayer ***)&__p, a4, (uint64_t)v13);
  if (__p)
  {
    unint64_t v11 = __p;
    operator delete(__p);
  }
  if (!v7)
  {
    unsigned __int16 v9 = 0;
    if (v14) {
      uint64_t v7 = ZinMirSpatialSplitter::Split(a1, a2, (const ZinMirSpatialSplitter::SplitPlan *)v13, (LayerTilingHelper *)&v9, 1);
    }
    else {
      uint64_t v7 = 3;
    }
  }
  std::__optional_destruct_base<ZinMirSpatialSplitter::SplitPlan,false>::~__optional_destruct_base[abi:ne180100]((uint64_t)v13);
  return v7;
}

void sub_21126C464(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, void *__p, uint64_t a12, uint64_t a13, char a14)
{
}

void ZinMirSpatialSplitter::ResetTileRegion(uint64_t a1, ZinMirSpatialSplitUtils *a2, uint64_t a3, void **a4)
{
  uint64_t v8 = (*(uint64_t (**)(ZinMirSpatialSplitUtils *, void, void))(*(void *)a2 + 32))(a2, 0, 0);
  long long v29 = *(_OWORD *)(a3 + 104);
  int IsDeConv = ZinMirSpatialSplitUtils::IsDeConv(a2, v9);
  long long __p = 0;
  __src = 0;
  int v28 = 0;
  unint64_t v11 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)&v28, 1uLL);
  uint64_t v13 = &v11[8 * (void)v12];
  *(void *)unint64_t v11 = a2;
  char v14 = v11 + 8;
  unint64_t v16 = (char *)__p;
  BOOL v15 = (char *)__src;
  if (__src != __p)
  {
    do
    {
      uint64_t v17 = *((void *)v15 - 1);
      v15 -= 8;
      *((void *)v11 - 1) = v17;
      v11 -= 8;
    }
    while (v15 != v16);
    BOOL v15 = (char *)__p;
  }
  long long __p = v11;
  __src = v14;
  int v28 = v13;
  if (v15)
  {
    operator delete(v15);
    unint64_t v11 = (char *)__p;
  }
  __src = v14;
  if (v11 == v14)
  {
    int v19 = 0;
  }
  else
  {
    do
    {
      uint64_t v18 = *((void *)v14 - 1);
      __src = v14 - 8;
      int v19 = ZinMirSpatialSplitUtils::IsDeConv((ZinMirSpatialSplitUtils *)v18, v12);
      if (v19) {
        break;
      }
      if (*(_DWORD *)(*(void *)(v18 + 64) + 8) == 7) {
        std::vector<ZinIrOpLayer *>::__insert_with_size[abi:ne180100]<std::__wrap_iter<ZinTransposeLayer **>,std::__wrap_iter<ZinTransposeLayer **>>((uint64_t)&__p, (char *)__src, *(uint64_t **)(v18 + 88), *(uint64_t **)(v18 + 96), (uint64_t)(*(void *)(v18 + 96) - *(void *)(v18 + 88)) >> 3);
      }
      char v14 = (char *)__src;
    }
    while (__p != __src);
  }
  uint64_t v20 = **(void ***)(a1 + 16);
  uint64_t v21 = (ZinMirSpatialSplitUtils *)(*(uint64_t (**)(ZinMirSpatialSplitUtils *, void, void))(*(void *)a2 + 32))(a2, 0, 0);
  unint64_t v22 = PressureBasedSubgraphIdentification::MinimumSplitAlignmentConstraint(v20, v21, 3);
  unint64_t v23 = **(void ***)(a1 + 16);
  unint64_t v24 = (ZinMirSpatialSplitUtils *)(*(uint64_t (**)(ZinMirSpatialSplitUtils *, void, void))(*(void *)a2 + 32))(a2, 0, 0);
  unint64_t v25 = PressureBasedSubgraphIdentification::MinimumSplitAlignmentConstraint(v23, v24, 4);
  ZinMirSpatialSplitUtils::OptimizeOutputTensorTileRegions((int64_t *)(v8 + 48), (int64_t *)&v29, *(void *)(a3 + 120), IsDeConv | v19, v22, v25, a4);
  if (__p)
  {
    __src = __p;
    operator delete(__p);
  }
}

void sub_21126C6B0(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinMirSpatialSplitter::GatherLatencyInfoOnLayer(uint64_t a1, uint64_t a2, ZinMirSpatialSplitUtils *a3, SplitInfo *a4, ZinIrOpLayer *this, const TiledLayerTensorRegions **a6, uint64_t *a7)
{
  unsigned __int16 v9 = a3;
  if (!ZinIrOpLayer::IsANELayer(this))
  {
    uint64_t v20 = (void **)*((void *)this + 14);
    uint64_t v21 = (void **)*((void *)this + 15);
    int64x2_t v102 = this;
    double v22 = 0.0;
    double v23 = 0.0;
    if (v20 != v21)
    {
      uint64_t v24 = (uint64_t)a3 + 72;
      do
      {
        v145 = 0;
        v145 = *v20;
        if (std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>(v24, (ZinIrOpLayer **)&v145))
        {
          __src = (void **)v145;
          if (a7 + 1 != (uint64_t *)std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>((uint64_t)a7, (ZinIrOpLayer **)&__src))
          {
            __src = (void **)v145;
            if (a7 + 4 != (uint64_t *)std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>((uint64_t)(a7 + 3), (ZinIrOpLayer **)&__src))
            {
              unint64_t v25 = (void **)v145;
              int v26 = (void ***)*((void *)v145 + 11);
              int v27 = (void ***)*((void *)v145 + 12);
              double v28 = 0.0;
              if (v26 != v27)
              {
                do
                {
                  __src = 0;
                  long long v29 = *v26++;
                  __src = v29;
                  if (std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>(v24, (ZinIrOpLayer **)&__src))
                  {
                    double v28 = v28 + 1.0;
                  }
                }
                while (v26 != v27);
                unint64_t v25 = (void **)v145;
              }
              __src = v25;
              double v30 = *(double *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)a7, (ZinIrOpLayer **)&__src);
              __src = (void **)v145;
              double v23 = v23
                  + (v30
                   - *(double *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)(a7 + 3), (ZinIrOpLayer **)&__src))/ v28;
            }
          }
        }
        ++v20;
      }
      while (v20 != v21);
    }
    uint64_t v31 = a1;
    if (*(unsigned char *)(a1 + 32)) {
      double v32 = 0.0;
    }
    else {
      double v32 = v23;
    }
    LatencyInfo::SetLatency(a7, this, 0, v32);
    LatencyInfo::SetLatency(a7, this, 1, 0.0);
    LatencyInfo::SetLatency(a7, this, 3, 0.0);
    LatencyInfo::SetLatency(a7, this, 2, 0.0);
    if (*(_DWORD *)(*((void *)this + 8) + 8) != 7) {
      goto LABEL_62;
    }
    int v33 = (ZinIrOpLayer **)*((void *)this + 11);
    uint64_t v104 = (ZinIrOpLayer **)*((void *)v102 + 12);
    int v34 = a4;
    long long v35 = a3;
    if (v33 == v104) {
      goto LABEL_62;
    }
    double v22 = 0.0;
    while (1)
    {
      v129 = 0;
      v129 = *v33;
      if ((ZinMirSpatialSplitUtils *)((char *)a3 + 80) != (ZinMirSpatialSplitUtils *)std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>((uint64_t)a3 + 72, &v129))goto LABEL_61; {
      v143[1] = 0;
      }
      v143[0] = 0;
      WORD4(v144) = 0;
      *(void *)&long long v144 = 0;
      LOWORD(__src) = 256;
      std::vector<std::optional<BOOL>>::__assign_with_size[abi:ne180100]<std::optional<BOOL> const*,std::optional<BOOL> const*>((char *)v143, (char *)&__src, (uint64_t)&__src + 2, 1uLL);
      WORD4(v144) = !ZinMirSpatialSplitUtils::IsRootOutputOrOutsideSubgraph(v35, v102, v36) | 0x100;
      uint64_t v37 = *a6;
      int v38 = a6[1];
      while (v37 != v38)
      {
        std::__optional_copy_base<TiledLayerTensorRegions,false>::__optional_copy_base[abi:ne180100]((TiledLayerTensorRegions *)&__src, v37);
        LOBYTE(v145) = 0;
        char v148 = 0;
        if (!(_BYTE)v141) {
          goto LABEL_50;
        }
        *(_OWORD *)uint64_t v126 = 0u;
        long long v127 = 0u;
        *(int64x2_t *)&v128[8] = vdupq_n_s64(1uLL);
        *(_OWORD *)&v128[24] = *(_OWORD *)&v128[8];
        *(void *)v128 = 0;
        *(void *)&v128[40] = 1;
        uint64_t v39 = (*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)v129 + 32))(v129, 0, 0);
        long long v40 = *(_OWORD *)(v39 + 48);
        long long v41 = *(_OWORD *)(v39 + 64);
        *(void *)&v128[40] = *(void *)(v39 + 80);
        *(_OWORD *)&v128[8] = v40;
        *(_OWORD *)&v128[24] = v41;
        SplitInfo::GetSplitDimensions(v34, (char **)&__p);
        char v43 = (int *)__p;
        int v42 = v116;
        if (__p == v116)
        {
          int v48 = 14;
          int v49 = 1;
          if (*(double *)&__p != 0.0) {
            goto LABEL_34;
          }
        }
        else
        {
          while (1)
          {
            int v44 = *v43;
            uint64_t ValueAt = GetValueAtDimension<ZinTensorDimensions>(v132, *v43);
            unsigned int v46 = SetValueAtDimension<ZinTensorDimensions>(&v128[8], v44, ValueAt);
            if (v46) {
              break;
            }
            uint64_t v47 = GetValueAtDimension<ZinTensorPosition>((uint64_t *)&__src, v44);
            unsigned int v46 = SetValueAtDimension<ZinTensorPosition>(v126, v44, v47);
            if (v46) {
              break;
            }
            if (++v43 == v42)
            {
              int v48 = 14;
              int v49 = 1;
              goto LABEL_33;
            }
          }
          int v49 = 0;
          int v48 = 1;
          unsigned int v103 = v46;
LABEL_33:
          char v43 = (int *)__p;
          if (*(double *)&__p != 0.0)
          {
LABEL_34:
            v116 = v43;
            operator delete(v43);
          }
        }
        if (v49)
        {
          uint64_t v50 = operator new(0x28uLL);
          v150 = (TiledLayerTensorRegions *)((char *)v50 + 40);
          v151 = (char *)v50 + 40;
          long long v51 = v127;
          *uint64_t v50 = *(_OWORD *)v126;
          v50[1] = v51;
          uint64_t v52 = *(void *)&v128[8];
          *((void *)v50 + 4) = *(void *)v128;
          v149 = (char *)v50;
          uint64_t v53 = *(void *)&v128[24];
          uint64_t v54 = *(void *)&v128[16];
          long long v55 = *(_OWORD *)&v128[32];
          int v56 = (char *)operator new(0x48uLL);
          long long v113 = v56 + 72;
          char v114 = v56 + 72;
          *(void *)int v56 = v52;
          *((void *)v56 + 1) = v54;
          *((void *)v56 + 2) = v53;
          *(_OWORD *)(v56 + 24) = v55;
          *(_OWORD *)(v56 + 40) = 0u;
          *(_OWORD *)(v56 + 56) = 0u;
          uint64_t v112 = v56;
          int64x2_t v57 = operator new(0x50uLL);
          unint64_t v110 = v57 + 5;
          long long v111 = v57 + 5;
          long long v58 = *(_OWORD *)&v128[16];
          v57[2] = *(_OWORD *)v128;
          v57[3] = v58;
          v57[4] = *(_OWORD *)&v128[32];
          long long v59 = v127;
          *int64x2_t v57 = *(_OWORD *)v126;
          v57[1] = v59;
          unint64_t v109 = v57;
          TiledLayerTensorRegions::TiledLayerTensorRegions((uint64_t)&__p, v139, v126, (uint64_t)&v149, (uint64_t)&v112, (uint64_t)&v109, 0, 0);
          int v34 = a4;
          long long v35 = a3;
          uint64_t v31 = a1;
          std::optional<TiledLayerTensorRegions>::operator=[abi:ne180100]<TiledLayerTensorRegions,void>((uint64_t)&v145, (uint64_t)&__p);
          if (v125) {
            operator delete(v125);
          }
          if (v123)
          {
            v124 = v123;
            operator delete(v123);
          }
          if (v121)
          {
            uint64_t v122 = v121;
            operator delete(v121);
          }
          if (v119)
          {
            v120 = v119;
            operator delete(v119);
          }
          if (v109)
          {
            unint64_t v110 = v109;
            operator delete(v109);
          }
          if (v112)
          {
            long long v113 = v112;
            operator delete(v112);
          }
          if (v149)
          {
            v150 = (TiledLayerTensorRegions *)v149;
            operator delete(v149);
          }
LABEL_50:
          *(double *)&long long __p = 0.0;
          v116 = 0;
          char v118 = 0;
          uint64_t v117 = 0;
          (*(void (**)(void, uint64_t, ZinMirSpatialSplitUtils *, SplitInfo *, ZinIrOpLayer *, void **, ZinIrOpLayer **, void **))(**(void **)(v31 + 120) + 16))(*(void *)(v31 + 120), a2, v35, v34, v129, &v145, v143, &__p);
          int v48 = 0;
          double v22 = v22 + *(double *)&__p;
          goto LABEL_52;
        }
        uint64_t v31 = a1;
LABEL_52:
        std::__optional_destruct_base<TiledLayerTensorRegions,false>::~__optional_destruct_base[abi:ne180100]((uint64_t)&v145);
        std::__optional_destruct_base<TiledLayerTensorRegions,false>::~__optional_destruct_base[abi:ne180100]((uint64_t)&__src);
        if (v48) {
          goto LABEL_57;
        }
        uint64_t v37 = (const TiledLayerTensorRegions *)((char *)v37 + 232);
      }
      int v48 = 0;
LABEL_57:
      if (v143[0])
      {
        v143[1] = v143[0];
        operator delete(v143[0]);
      }
      if (v48) {
        return v103;
      }
LABEL_61:
      if (++v33 == v104)
      {
LABEL_62:
        LatencyInfo::SetLatency(a7, v102, 4, v22);
        return 0;
      }
    }
  }
  *(double *)&long long __p = 0.0;
  v116 = 0;
  char v118 = 0;
  uint64_t v117 = 0;
  unint64_t v11 = *(unsigned int (****)(void))(a1 + 120);
  long long v152 = 0u;
  long long v153 = 0u;
  if ((**v11)())
  {
    BOOL v12 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (v12) {
      ZinMirSpatialSplitter::GatherLatencyInfoOnLayer(v12, v13, v14, v15, v16, v17, v18, v19);
    }
    return 3;
  }
  v126[0] = 0;
  v126[1] = 0;
  WORD4(v127) = 0;
  *(void *)&long long v127 = 0;
  if (!*(unsigned char *)(a1 + 32)) {
    goto LABEL_99;
  }
  (*(void (**)(void ***__return_ptr, ZinIrOpLayer *))(*(void *)this + 512))(&__src, this);
  unint64_t v62 = __src;
  int v61 = v131;
  if (__src == v131) {
    goto LABEL_96;
  }
  long long v100 = a7;
  uint64_t v63 = (uint64_t)v9 + 72;
  int v64 = (char *)v9 + 80;
  do
  {
    uint64_t v65 = (ZinIrTensor *)*v62;
    v143[0] = *((ZinIrOpLayer **)*v62 + 12);
    if (v64 == (char *)std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>(v63, v143))
    {
      __int16 v67 = 0;
    }
    else
    {
      v146 = 0;
      v145 = 0;
      uint64_t v147 = 0;
      if (ZinIrOpLayer::IsNoOp(v143[0], (uint64_t *)&v145))
      {
        int v66 = *(_DWORD *)(*((void *)v143[0] + 8) + 8);
        if (v145)
        {
          v146 = v145;
          operator delete(v145);
        }
        if (v66 != 7)
        {
          v145 = 0;
          v145 = (void *)*((void *)ZinIrTensor::GetRootTensor(v65) + 12);
          __int16 v67 = v64 != (char *)std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>(v63, (ZinIrOpLayer **)&v145);
          goto LABEL_77;
        }
      }
      else if (v145)
      {
        v146 = v145;
        operator delete(v145);
      }
      __int16 v67 = 1;
    }
LABEL_77:
    char v68 = (char *)v126[1];
    if (v126[1] >= (void *)v127)
    {
      int64_t v70 = (char *)v126[1] - (char *)v126[0];
      if ((char *)v126[1] - (char *)v126[0] <= -3) {
        std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
      }
      uint64_t v71 = v70 >> 1;
      if ((unint64_t)v127 - (unint64_t)v126[0] <= (v70 >> 1) + 1) {
        uint64_t v72 = v71 + 1;
      }
      else {
        uint64_t v72 = v127 - (unint64_t)v126[0];
      }
      if ((unint64_t)v127 - (unint64_t)v126[0] >= 0x7FFFFFFFFFFFFFFELL) {
        uint64_t v73 = 0x7FFFFFFFFFFFFFFFLL;
      }
      else {
        uint64_t v73 = v72;
      }
      if (v73) {
        uint64_t v74 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<half>>((uint64_t)&v127, v73);
      }
      else {
        uint64_t v74 = 0;
      }
      uint64_t v75 = &v74[2 * v71];
      *(_WORD *)uint64_t v75 = v67 | 0x100;
      long long v69 = v75 + 2;
      uint64_t v77 = (char *)v126[0];
      int v76 = (char *)v126[1];
      if (v126[1] != v126[0])
      {
        do
        {
          __int16 v78 = *((_WORD *)v76 - 1);
          v76 -= 2;
          *((_WORD *)v75 - 1) = v78;
          v75 -= 2;
        }
        while (v76 != v77);
        int v76 = (char *)v126[0];
      }
      v126[0] = v75;
      v126[1] = v69;
      *(void *)&long long v127 = &v74[2 * v73];
      if (v76) {
        operator delete(v76);
      }
    }
    else
    {
      *(_WORD *)v126[1] = v67 | 0x100;
      long long v69 = v68 + 2;
    }
    v126[1] = v69;
    ++v62;
  }
  while (v62 != v61);
  unint64_t v62 = __src;
  a7 = v100;
  unsigned __int16 v9 = a3;
LABEL_96:
  if (v62)
  {
    v131 = v62;
    operator delete(v62);
  }
  WORD4(v127) = !ZinMirSpatialSplitUtils::IsRootOutputOrOutsideSubgraph(v9, this, v60) | 0x100;
LABEL_99:
  v149 = 0;
  v150 = 0;
  v151 = 0;
  int64x2_t v79 = *a6;
  int64x2_t v80 = a6[1];
  if (*a6 != v80)
  {
    BOOL v81 = 0;
    double v82 = 0.0;
    double v83 = 0.0;
    double v84 = 0.0;
    while (1)
    {
      std::__optional_copy_base<TiledLayerTensorRegions,false>::__optional_copy_base[abi:ne180100]((TiledLayerTensorRegions *)&v145, v79);
      if (v148)
      {
        uint64_t v86 = (TiledLayerTensorRegions *)v149;
        int64x2_t v85 = v150;
        if (v149 == (char *)v150) {
          goto LABEL_109;
        }
        while (1)
        {
          if (!v148) {
            std::__throw_bad_optional_access[abi:ne180100]();
          }
          if (TiledLayerTensorRegions::IsPerformanceEquivalent(v86, (const TiledLayerTensorRegions *)&v145)) {
            break;
          }
          uint64_t v86 = (TiledLayerTensorRegions *)((char *)v86 + 256);
          if (v86 == v85)
          {
            uint64_t v86 = v85;
            break;
          }
        }
        if (v86 == v150)
        {
LABEL_109:
          v143[1] = 0;
          v143[0] = 0;
          BYTE8(v144) = 0;
          *(void *)&long long v144 = 0;
          if ((*(unsigned int (**)(void, uint64_t, ZinMirSpatialSplitUtils *, SplitInfo *, ZinIrOpLayer *, void **, void **, ZinIrOpLayer **))(**(void **)(a1 + 120) + 8))(*(void *)(a1 + 120), a2, a3, a4, this, &v145, v126, v143))
          {
            BOOL v92 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
            if (v92) {
              ZinMirSpatialSplitter::GatherLatencyInfoOnLayer(v92, v93, v94, v95, v96, v97, v98, v99);
            }
            std::__optional_destruct_base<TiledLayerTensorRegions,false>::~__optional_destruct_base[abi:ne180100]((uint64_t)&v145);
            char v90 = 0;
            goto LABEL_124;
          }
          BOOL v81 = (BYTE8(v144) | v81) != 0;
          if (!v148) {
            std::__throw_bad_optional_access[abi:ne180100]();
          }
          double v87 = *(double *)&v144;
          uint64_t v88 = v143[0];
          char v89 = v143[1];
          TiledLayerTensorRegions::TiledLayerTensorRegions((TiledLayerTensorRegions *)&__src, (const TiledLayerTensorRegions *)&v145);
          long long v141 = *(_OWORD *)v143;
          long long v142 = v144;
          std::vector<std::pair<TiledLayerTensorRegions,LatencyData>>::push_back[abi:ne180100]((uint64_t *)&v149, (uint64_t)&__src);
          if (v140) {
            operator delete(v140);
          }
          if (v137)
          {
            v138 = v137;
            operator delete(v137);
          }
          if (v135)
          {
            v136 = v135;
            operator delete(v135);
          }
          if (v133)
          {
            v134 = v133;
            operator delete(v133);
          }
          double v82 = v82 + *(double *)&v88;
          double v83 = v83 + v87;
          double v84 = v84 + *(double *)&v89;
        }
        else
        {
          double v82 = v82 + *((double *)v86 + 28);
          double v83 = v83 + *((double *)v86 + 30);
          double v84 = v84 + *((double *)v86 + 29);
          BOOL v81 = (*((unsigned __int8 *)v86 + 248) | v81) != 0;
        }
      }
      std::__optional_destruct_base<TiledLayerTensorRegions,false>::~__optional_destruct_base[abi:ne180100]((uint64_t)&v145);
      int64x2_t v79 = (const TiledLayerTensorRegions *)((char *)v79 + 232);
      if (v79 == v80) {
        goto LABEL_123;
      }
    }
  }
  BOOL v81 = 0;
  double v84 = 0.0;
  double v83 = 0.0;
  double v82 = 0.0;
LABEL_123:
  LatencyInfo::SetLatency(a7, this, 0, *(double *)&__p);
  LatencyInfo::SetLatency(a7, this, 1, v82);
  LatencyInfo::SetLatency(a7, this, 2, v84);
  LatencyInfo::SetLatency(a7, this, 3, v83);
  LatencyInfo::SetLatency(a7, this, 4, 0.0);
  v143[0] = this;
  v145 = v143;
  *((unsigned char *)std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,BOOL>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,BOOL>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,BOOL>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,BOOL>>>::__emplace_unique_key_args<ZinIrOpLayer const*,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer const* const&>,std::tuple<>>((uint64_t)(a7 + 15), v143, (uint64_t)&std::piecewise_construct, (void **)&v145)+ 24) = v81;
  char v90 = 1;
LABEL_124:
  __src = (void **)&v149;
  std::vector<std::pair<TiledLayerTensorRegions,LatencyData>>::__destroy_vector::operator()[abi:ne180100](&__src);
  if (v126[0])
  {
    v126[1] = v126[0];
    operator delete(v126[0]);
  }
  if (v90) {
    return 0;
  }
  return 3;
}

void sub_21126D228(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,void *a23,uint64_t a24,uint64_t a25,void *a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33,uint64_t a34,uint64_t a35,uint64_t a36,uint64_t a37,uint64_t a38,uint64_t a39,uint64_t a40,uint64_t a41,uint64_t a42,uint64_t a43,uint64_t a44,uint64_t a45,uint64_t a46,uint64_t a47,uint64_t a48,uint64_t a49,uint64_t a50,uint64_t a51,uint64_t a52,uint64_t a53,uint64_t a54,uint64_t a55,uint64_t a56,void *__p)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(a1);
}

void std::vector<std::pair<TiledLayerTensorRegions,LatencyData>>::push_back[abi:ne180100](uint64_t *a1, uint64_t a2)
{
  unint64_t v6 = a1[2];
  uint64_t v4 = (uint64_t)(a1 + 2);
  unint64_t v5 = v6;
  unint64_t v7 = *(void *)(v4 - 8);
  if (v7 >= v6)
  {
    uint64_t v9 = (uint64_t)(v7 - *a1) >> 8;
    if ((unint64_t)(v9 + 1) >> 56) {
      std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
    }
    uint64_t v10 = v5 - *a1;
    uint64_t v11 = v10 >> 7;
    if (v10 >> 7 <= (unint64_t)(v9 + 1)) {
      uint64_t v11 = v9 + 1;
    }
    if ((unint64_t)v10 >= 0x7FFFFFFFFFFFFF00) {
      unint64_t v12 = 0xFFFFFFFFFFFFFFLL;
    }
    else {
      unint64_t v12 = v11;
    }
    uint64_t v18 = v4;
    if (v12) {
      uint64_t v13 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<std::pair<TiledLayerTensorRegions,LatencyData>>>(v4, v12);
    }
    else {
      uint64_t v13 = 0;
    }
    uint64_t v14 = v13;
    uint64_t v15 = &v13[256 * v9];
    uint64_t v17 = &v13[256 * v12];
    std::pair<TiledLayerTensorRegions,LatencyData>::pair[abi:ne180100]((uint64_t)v15, a2);
    uint64_t v16 = v15 + 256;
    std::vector<std::pair<TiledLayerTensorRegions,LatencyData>>::__swap_out_circular_buffer(a1, &v14);
    uint64_t v8 = a1[1];
    std::__split_buffer<std::pair<TiledLayerTensorRegions,LatencyData>>::~__split_buffer((uint64_t)&v14);
  }
  else
  {
    std::pair<TiledLayerTensorRegions,LatencyData>::pair[abi:ne180100](*(void *)(v4 - 8), a2);
    uint64_t v8 = v7 + 256;
    a1[1] = v7 + 256;
  }
  a1[1] = v8;
}

void sub_21126D488(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::__split_buffer<std::pair<TiledLayerTensorRegions,LatencyData>>::~__split_buffer((uint64_t)va);
  _Unwind_Resume(a1);
}

uint64_t std::optional<TiledLayerTensorRegions>::operator=[abi:ne180100]<TiledLayerTensorRegions,void>(uint64_t a1, uint64_t a2)
{
  if (*(unsigned char *)(a1 + 224))
  {
    *(_OWORD *)a1 = *(_OWORD *)a2;
    long long v4 = *(_OWORD *)(a2 + 16);
    long long v5 = *(_OWORD *)(a2 + 32);
    long long v6 = *(_OWORD *)(a2 + 64);
    *(_OWORD *)(a1 + 48) = *(_OWORD *)(a2 + 48);
    *(_OWORD *)(a1 + 64) = v6;
    *(_OWORD *)(a1 + 16) = v4;
    *(_OWORD *)(a1 + 32) = v5;
    std::vector<ANEDebugInfo::DebugInfoInMem::Layer>::__move_assign(a1 + 80, (__n128 *)(a2 + 80));
    std::vector<ANEDebugInfo::DebugInfoInMem::Layer>::__move_assign(a1 + 104, (__n128 *)(a2 + 104));
    std::vector<ANEDebugInfo::DebugInfoInMem::Layer>::__move_assign(a1 + 128, (__n128 *)(a2 + 128));
    long long v7 = *(_OWORD *)(a2 + 152);
    long long v8 = *(_OWORD *)(a2 + 168);
    *(_OWORD *)(a1 + 184) = *(_OWORD *)(a2 + 184);
    *(_OWORD *)(a1 + 168) = v8;
    *(_OWORD *)(a1 + 152) = v7;
    std::vector<BOOL>::__move_assign(a1 + 200, (void *)(a2 + 200));
  }
  else
  {
    std::construct_at[abi:ne180100]<TiledLayerTensorRegions,TiledLayerTensorRegions,TiledLayerTensorRegions*>(a1, a2);
    *(unsigned char *)(a1 + 224) = 1;
  }
  return a1;
}

uint64_t ZinMirSpatialSplitter::IsWorthTile(ZinMirSpatialSplitter *this, const Subgraph *a2, const SplitInfo *a3, ZinIrOpLayer ***a4, const LatencyInfo *a5, BOOL *a6)
{
  double v11 = 1.0;
  if (ZinIrOpLayer::IsANELayer((ZinIrOpLayer *)a4))
  {
    int v34 = (ZinIrOpLayer *)a4;
    double v11 = *(double *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)a5, &v34);
  }
  int v34 = (ZinIrOpLayer *)a4;
  double v12 = *(double *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)a5 + 24, &v34);
  int v34 = (ZinIrOpLayer *)a4;
  double v14 = *(double *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)a5 + 48, &v34);
  double v15 = 1.0 - *((double *)this + 8);
  if (vabdd_f64(v11, v12) >= 1.0e-10) {
    double v16 = v11 - v12;
  }
  else {
    double v16 = 0.0;
  }
  BOOL v19 = !ZinOpLayerUtils::IsCopy((ZinOpLayerUtils *)a4, v13)
     || (uint64_t v17 = *(void *)(ZinIrOpLayer::GetInputTensor((ZinIrOpLayer *)a4, 0) + 104)) == 0
     || !*(_DWORD *)(v17 + 96)
     || (uint64_t v18 = *(void *)(((uint64_t (*)(ZinIrOpLayer ***, void, void))(*a4)[4])(a4, 0, 0) + 104)) == 0
     || *(_DWORD *)(v18 + 96) == 0;
  if (ZinIrOpLayer::IsNELayer((ZinIrOpLayer *)a4) && v19) {
    double v20 = -(v12 - v11 * v15);
  }
  else {
    double v20 = v16;
  }
  if (v20 >= 0.0)
  {
    BOOL v30 = 1;
    if (*((unsigned char *)a2 + 144) && v11 / v12 < 1.5 && v12 != 0.0) {
      BOOL v30 = v14 < v12 * *((double *)this + 10);
    }
  }
  else if (v14 >= v12 * *((double *)this + 10))
  {
    BOOL v30 = 0;
  }
  else
  {
    double v22 = a4[14];
    uint64_t v21 = a4[15];
    if (v22 != v21)
    {
      double v23 = (char *)a2 + 72;
      do
      {
        int v33 = (ZinIrOpLayer ***)*v22;
        if (std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)v23, (ZinIrOpLayer **)&v33))
        {
          uint64_t v24 = (ZinIrOpLayer *)v33;
          unint64_t v25 = v33[11];
          int v26 = v33[12];
          double v27 = 0.0;
          if (v25 != v26)
          {
            do
            {
              int v34 = 0;
              double v28 = *v25++;
              int v34 = v28;
              if (std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)v23, &v34))
              {
                double v27 = v27 + 1.0;
              }
            }
            while (v25 != v26);
            uint64_t v24 = (ZinIrOpLayer *)v33;
          }
          int v34 = v24;
          double v29 = *(double *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)a5, &v34);
          int v34 = (ZinIrOpLayer *)v33;
          double v20 = v20
              + (v29
               - *(double *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)a5 + 24, &v34))/ v27;
        }
        ++v22;
      }
      while (v22 != v21);
    }
    BOOL v30 = v20 > 0.0;
  }
  BOOL v31 = v30;
  *a6 = v31;
  *a6 = *((unsigned char *)this + 26) | v31;
  return 0;
}

uint64_t ZinMirSpatialSplitter::RemoveChainPairFromSubgraph(ZinMirSpatialSplitter *this, Subgraph *a2, ZinIrOpLayer ***a3, const LatencyInfo *a4)
{
  uint64_t v21 = (ZinIrOpLayer *)a3;
  double v8 = *(double *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)a4, &v21);
  uint64_t v21 = (ZinIrOpLayer *)a3;
  double v9 = v8
     - *(double *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)a4 + 24, &v21);
  uint64_t v10 = a3[14];
  for (uint64_t i = a3[15]; v10 != i; ++v10)
  {
    double v20 = *v10;
    if (std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)a2 + 72, &v20)&& ZinIrOpLayer::IsANELayer(v20))
    {
      uint64_t v21 = v20;
      double v12 = *(double *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)a4, &v21);
      uint64_t v21 = v20;
      double v9 = v9
         + v12
         - *(double *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)a4 + 24, &v21);
    }
  }
  if (v9 > 0.0) {
    return 0;
  }
  uint64_t v13 = a3[14];
  double v14 = a3[15];
  if (v13 == v14) {
    return 0;
  }
  double v15 = (char *)a2 + 72;
  double v16 = (uint64_t **)((char *)a2 + 120);
  uint64_t v17 = (char *)a2 + 24;
  while (1)
  {
    double v20 = *v13;
    if (std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)v15, &v20))
    {
      if ((*(unsigned int (**)(void, ZinIrOpLayer *))(**((void **)this + 22) + 24))(*((void *)this + 22), v20))
      {
        uint64_t v18 = (ZinIrOpLayer *)**((void **)v20 + 14);
        uint64_t v21 = v20;
        if (std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)v16, &v21))
        {
          uint64_t v21 = v18;
          if (std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)v17, &v21))
          {
            break;
          }
        }
      }
    }
    if (++v13 == v14) {
      return 0;
    }
  }
  uint64_t v21 = (ZinIrOpLayer *)a3;
  std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>(v16, &v21, (uint64_t *)&v21);
  return 1;
}

void ZinMirSpatialSplitter::RemoveOutputNodeFromSubgraph(ZinMirSpatialSplitter *this, Subgraph *a2, ZinIrOpLayer ***a3, const LatencyInfo *a4)
{
  if (((unsigned int (*)(ZinIrOpLayer ***))(*a3)[14])(a3)) {
    ZinAssertImpl("Error: SNE layer should not be in subgraph.");
  }
  long long __p = 0;
  BOOL v19 = 0;
  uint64_t v20 = 0;
  char IsNoOp = ZinIrOpLayer::IsNoOp((ZinIrOpLayer *)a3, (uint64_t *)&__p);
  if (__p)
  {
    BOOL v19 = __p;
    operator delete(__p);
  }
  if ((IsNoOp & 1) == 0)
  {
    long long __p = a3;
    double v8 = *(double *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)a4, (ZinIrOpLayer **)&__p);
    long long __p = a3;
    double v9 = v8
       - *(double *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)a4 + 24, (ZinIrOpLayer **)&__p);
    uint64_t v10 = a3[14];
    for (uint64_t i = a3[15]; v10 != i; ++v10)
    {
      uint64_t v17 = *v10;
      if (std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)a2 + 72, &v17)&& ZinIrOpLayer::IsANELayer(v17))
      {
        long long __p = v17;
        double v12 = *(double *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)a4, (ZinIrOpLayer **)&__p);
        long long __p = v17;
        double v9 = v9
           + v12
           - *(double *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)a4 + 24, (ZinIrOpLayer **)&__p);
      }
    }
    if (v9 <= 0.0)
    {
      uint64_t v13 = a3[14];
      double v14 = a3[15];
      if (v13 != v14)
      {
        double v15 = (uint64_t **)((char *)a2 + 120);
        double v16 = (char *)a2 + 24;
        do
        {
          uint64_t v17 = *v13;
          long long __p = v17;
          if (std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)v15, (ZinIrOpLayer **)&__p))
          {
            if (std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)v16, &v17))
            {
              long long __p = a3;
              std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>(v15, (ZinIrOpLayer **)&__p, (uint64_t *)&__p);
            }
          }
          ++v13;
        }
        while (v13 != v14);
      }
    }
  }
}

void sub_21126DB68(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

double ZinMirSpatialSplitter::ComputeScaleFactorForChainedPairResetDecision(uint64_t a1, ZinIrOpLayer *a2, uint64_t a3)
{
  long long v6 = a2;
  if (std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>(a3, &v6))
  {
    return 1.0 - *(double *)(a1 + 64);
  }
  uint64_t v5 = *((void *)v6 + 11);
  if (*((void *)v6 + 12) - v5 == 8) {
    return dbl_211EFF130[*(void *)(*(void *)v5 + 120) - *(void *)(*(void *)v5 + 112) == 8];
  }
  else {
    return 1.3;
  }
}

uint64_t ZinMirSpatialSplitter::HandleL2DepSplit(ZinMirSpatialSplitter *this, uint64_t **a2, ZinIrOpLayer *a3, const LatencyInfo *a4)
{
  if (!*((unsigned char *)this + 24)) {
    return 0;
  }
  double v8 = (ZinIrOpLayer **)*((void *)a3 + 11);
  double v9 = (ZinIrOpLayer **)*((void *)a3 + 12);
  if (v8 == v9)
  {
    v29[0] = a3;
    uint64_t v20 = std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)(a2 + 3), v29);
    LOBYTE(v10) = 0;
    uint64_t result = 0;
    if (v20) {
      return result;
    }
LABEL_15:
    double v22 = (ZinIrTensor *)(*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)a3 + 32))(a3, 0, 0);
    double v23 = (const ZinIrTensor *)**((void **)this + 2);
    LOBYTE(v29[0]) = 0;
    char v30 = 0;
    char v24 = v10 | ZinIrRegAllocUtil::IsL2Dependentable(v22, v23, (ZinTensorFamilyUtil *)v29);
    std::__optional_destruct_base<ZinTensorFamilyUtil,false>::~__optional_destruct_base[abi:ne180100]((uint64_t)v29);
    if (v24) {
      goto LABEL_9;
    }
    return 0;
  }
  int v10 = 0;
  do
  {
    BOOL v31 = *v8;
    if (std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)(a2 + 9), &v31))
    {
      double v11 = (ZinIrTensor *)(*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)v31 + 32))(v31, 0, 0);
      double v12 = (const ZinIrTensor *)**((void **)this + 2);
      LOBYTE(v29[0]) = 0;
      char v30 = 0;
      v10 |= ZinIrRegAllocUtil::IsL2Dependentable(v11, v12, (ZinTensorFamilyUtil *)v29);
      std::__optional_destruct_base<ZinTensorFamilyUtil,false>::~__optional_destruct_base[abi:ne180100]((uint64_t)v29);
    }
    ++v8;
  }
  while (v8 != v9);
  v29[0] = a3;
  if (!std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)(a2 + 3), v29))goto LABEL_15; {
  if ((v10 & 1) == 0)
  }
    return 0;
LABEL_9:
  if (!ZinIrOpLayer::IsNELayer(a3)) {
    return 1;
  }
  v29[0] = a3;
  double v13 = *(double *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)a4 + 24, v29);
  v29[0] = a3;
  double v14 = (double *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)a4 + 48, v29);
  double v15 = *v14;
  if (*v14 < v13 * *((double *)this + 10)) {
    return 1;
  }
  double v16 = (ZinIrOpLayer *)**((void **)a3 + 11);
  BOOL v31 = v16;
  double v28 = (ZinIrOpLayer *)**((void **)a3 + 14);
  uint64_t v17 = (ZinIrRegAllocUtil *)(*(uint64_t (**)(ZinIrOpLayer *, void, void, double))(*(void *)a3 + 32))(a3, 0, 0, v15);
  if (ZinIrRegAllocUtil::IsChainable(v17, **((const ZinIrTensor ***)this + 2), v18)
    && std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)(a2 + 9), &v28))
  {
    v29[0] = a3;
    std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>(a2 + 15, v29, (uint64_t *)v29);
    v29[0] = v28;
    BOOL v19 = a2 + 15;
  }
  else
  {
    unint64_t v25 = (ZinIrRegAllocUtil *)(*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)v16 + 32))(v16, 0, 0);
    if (!ZinIrRegAllocUtil::IsChainable(v25, **((const ZinIrTensor ***)this + 2), v26)
      || !std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)(a2 + 9), &v31))
    {
      return 1;
    }
    v29[0] = v31;
    double v27 = a2 + 15;
    std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>(v27, v29, (uint64_t *)v29);
    v29[0] = a3;
    BOOL v19 = v27;
  }
  std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>(v19, v29, (uint64_t *)v29);
  return 1;
}

void sub_21126DEF0(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::__optional_destruct_base<ZinTensorFamilyUtil,false>::~__optional_destruct_base[abi:ne180100]((uint64_t)va);
  _Unwind_Resume(a1);
}

uint64_t ZinMirSpatialSplitter::HandleChainSplit(ZinMirSpatialSplitter *this, Subgraph *a2, ZinIrOpLayer *a3, LatencyInfo *a4)
{
  uint64_t v18 = a3;
  long long v7 = (char *)a2 + 72;
  if (!std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)a2 + 72, &v18))ZinAssertImpl("Error"); {
  if (ZinMirSpatialSplitter::RemoveChainPairFromSubgraph(this, a2, (ZinIrOpLayer ***)v18, a4))
  }
    return 0;
  uint64_t v17 = 0;
  if ((*(uint64_t (**)(void, ZinIrOpLayer *, ZinIrOpLayer **))(**((void **)this + 22) + 40))(*((void *)this + 22), v18, &v17))return 0; {
  if (!(*(unsigned int (**)(void, ZinIrOpLayer *))(**((void **)this + 22) + 24))(*((void *)this + 22), v18))return 0;
  }
  uint64_t v17 = v18;
  double v16 = (ZinIrOpLayer *)**((void **)v18 + 14);
  if (!std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)v7, &v16))return 0; {
  if (*((unsigned char *)this + 24))
  }
    return 1;
  BOOL v19 = v17;
  double v10 = *(double *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)a4, &v19);
  BOOL v19 = v16;
  double v11 = (double *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)a4, &v19);
  if (v10 <= *v11) {
    double v10 = *v11;
  }
  BOOL v19 = v17;
  double v12 = *(double *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)a4 + 24, &v19);
  BOOL v19 = v16;
  double v13 = (double *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)a4 + 24, &v19);
  if (v12 <= *v13) {
    double v12 = *v13;
  }
  double v14 = ZinMirSpatialSplitter::ComputeScaleFactorForChainedPairResetDecision((uint64_t)this, v17, (uint64_t)a2);
  uint64_t v8 = 1;
  LatencyInfo::SetLatency((uint64_t *)a4, v17, 1, v12);
  LatencyInfo::SetLatency((uint64_t *)a4, v16, 1, v12);
  LatencyInfo::SetLatency((uint64_t *)a4, v17, 0, v10);
  LatencyInfo::SetLatency((uint64_t *)a4, v16, 0, v10);
  if (v10 * v14 <= v12)
  {
    BOOL v19 = v17;
    double v15 = (uint64_t **)((char *)a2 + 120);
    std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>(v15, &v19, (uint64_t *)&v19);
    BOOL v19 = v16;
    std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>(v15, &v19, (uint64_t *)&v19);
  }
  return v8;
}

uint64_t ZinMirSpatialSplitter::DetermineCircularBufferInputTiling(uint64_t a1, ZinIrOpLayer *a2, uint64_t a3, void *a4, uint64_t a5, uint64_t a6, uint64_t *a7, uint64_t *a8)
{
  v88[0] = a2;
  uint64_t v15 = a3 + 24;
  if (std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>(a3 + 24, v88))
  {
    return 0;
  }
  char v68 = a4;
  *(void *)int v66 = a6;
  double v16 = v88[0];
  uint64_t v18 = *((void *)v88[0] + 14);
  uint64_t v17 = *((void *)v88[0] + 15);
  if (v18 == v17)
  {
    BOOL v21 = 0;
    int v67 = 0;
  }
  else
  {
    uint64_t v19 = v18 + 8;
    do
    {
      int v20 = *(_DWORD *)(*(void *)(*(void *)(v19 - 8) + 64) + 8);
      BOOL v21 = v20 == 7;
      BOOL v22 = v20 == 7 || v19 == v17;
      v19 += 8;
    }
    while (!v22);
    while (1)
    {
      if (*(_DWORD *)(*(void *)(*(void *)v18 + 64) + 8) == 7)
      {
        __p[0] = *(void **)v18;
        if (std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)(a5 + 64), __p))
        {
          break;
        }
      }
      v18 += 8;
      if (v18 == v17)
      {
        int v67 = 0;
        goto LABEL_15;
      }
    }
    int v67 = 1;
LABEL_15:
    double v16 = v88[0];
  }
  if (*(_DWORD *)(*((void *)v16 + 8) + 8) == 7) {
    int CanConcatBeCircularBufferProducer = ZinMirSpatialSplitUtils::CanConcatBeCircularBufferProducer(a3, a1 + 24, v16);
  }
  else {
    int CanConcatBeCircularBufferProducer = 0;
  }
  int v26 = a7;
  uint64_t v25 = *a7;
  uint64_t v24 = v26[1];
  if (0xAAAAAAAAAAAAAAABLL * ((v24 - v25) >> 3) < 2 || v25 + 24 == v24)
  {
    int v29 = 0;
  }
  else
  {
    do
    {
      BOOL v27 = std::__equal_to::operator()[abi:ne180100]<std::vector<ZinTensorRegion>,std::vector<ZinTensorRegion>>((uint64_t)__p, v25 + 24, v25);
      if (!v27) {
        break;
      }
      uint64_t v28 = v25 + 48;
      v25 += 24;
    }
    while (v28 != v24);
    int v29 = !v27;
  }
  if (*(unsigned char *)(a1 + 29)) {
    BOOL v30 = 1;
  }
  else {
    BOOL v30 = *(unsigned char *)(a1 + 32) != 0;
  }
  BOOL v31 = (*(unsigned char *)(a1 + 24) || *(unsigned char *)(a1 + 25))
     && std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>(v15, v88) == 0;
  __p[0] = 0;
  __p[1] = 0;
  *(void *)&long long v72 = 0;
  int v33 = v31 & (ZinIrOpLayer::IsNoOp(v88[0], (uint64_t *)__p) ^ 1 | CanConcatBeCircularBufferProducer);
  if (__p[0])
  {
    __p[1] = __p[0];
    operator delete(__p[0]);
  }
  int v34 = v29 & v30;
  int v35 = (v21 & v33) == 1 ? v67 & ZinMirSpatialSplitUtils::IsDeConv(v88[0], v32) : 0;
  uint64_t v36 = (ZinMirSpatialSplitUtils *)(*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)v88[0] + 32))(v88[0], 0, 0);
  if ((v33 & (!v21 | v35) & (v34 | ZinMirSpatialSplitUtils::HasConsumerWithKernelSupportOnHeight(v36, v37)) & 1) == 0)return 0; {
  uint64_t v39 = *a8;
  }
  for (uint64_t i = a8[1];
        i != v39;
  a8[1] = v39;
  uint64_t v42 = *(void *)(a3 + 64);
  char v43 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(v68, v88);
  if (!v43) {
    ZinAssertImpl("Helper for layer in Spatial Splitting not found");
  }
  LayerTilingHelper::LayerTilingHelper((LayerTilingHelper *)v80, (const LayerTilingHelper *)(v43 + 3));
  uint64_t v77 = 0;
  __int16 v78 = 0;
  uint64_t v79 = 0;
  std::vector<WorkUnit>::__init_with_size[abi:ne180100]<WorkUnit*,WorkUnit*>(&v77, **(const void ***)v66, *(void *)(*(void *)v66 + 8), 0xCCCCCCCCCCCCCCCDLL * ((uint64_t)(*(void *)(*(void *)v66 + 8) - **(void **)v66) >> 4));
  int v44 = (const ZinTensorRegion *)v77;
  char v45 = v78;
  if (v77 == v78)
  {
LABEL_70:
    if (&v77 != *(void ***)v66) {
      std::vector<WorkUnit>::__assign_with_size[abi:ne180100]<WorkUnit*,WorkUnit*>(*(char **)v66, (char *)v77, (uint64_t)v78, 0xCCCCCCCCCCCCCCCDLL * ((v78 - (const ZinTensorRegion *)v77) >> 4));
    }
    uint64_t v40 = 1;
    goto LABEL_78;
  }
  unint64_t v46 = 0;
  long long v69 = (void *)(a5 + 64);
  while (!(v46 % *(void *)(a5 + 104)))
  {
    if (*((void *)v44 + 2)) {
      ZinAssertImpl("Spatial Splitting branch mismatch");
    }
LABEL_61:
    uint64_t v63 = *(void *)(a1 + 112);
    *(void *)(a1 + 112) = v63 + 1;
    v70[0] = v42;
    v70[1] = v63;
    v70[2] = v46;
    v70[3] = 0;
    LayerTilingHelper::ToProduce(v80, (const TiledLayerTensorRegions::Id *)v70, v44, (uint64_t)__p);
    if (v35)
    {
      v70[0] = v88[0];
      std::__hash_table<std::__hash_value_type<ZinIrOpLayer *,long>,std::__unordered_map_hasher<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,long>,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,true>,std::__unordered_map_equal<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,long>,std::equal_to<ZinIrOpLayer *>,std::hash<ZinIrOpLayer *>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer *,long>>>::__erase_unique<ZinIrOpLayer *>(v69, v70);
    }
    unint64_t v64 = a8[1];
    if (v64 != *a8 && v76 && !*(unsigned char *)(v64 - 8))
    {
      v70[0] = v88[0];
      std::__hash_table<std::__hash_value_type<ZinIrOpLayer *,long>,std::__unordered_map_hasher<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,long>,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,true>,std::__unordered_map_equal<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,long>,std::equal_to<ZinIrOpLayer *>,std::hash<ZinIrOpLayer *>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer *,long>>>::__erase_unique<ZinIrOpLayer *>(v69, v70);
      std::__optional_destruct_base<TiledLayerTensorRegions,false>::~__optional_destruct_base[abi:ne180100]((uint64_t)__p);
      goto LABEL_77;
    }
    if (v64 >= a8[2])
    {
      uint64_t v65 = std::vector<std::optional<TiledLayerTensorRegions>>::__push_back_slow_path<std::optional<TiledLayerTensorRegions> const&>(a8, (const TiledLayerTensorRegions *)__p);
    }
    else
    {
      std::__optional_copy_base<TiledLayerTensorRegions,false>::__optional_copy_base[abi:ne180100]((TiledLayerTensorRegions *)a8[1], (const TiledLayerTensorRegions *)__p);
      uint64_t v65 = v64 + 232;
      a8[1] = v64 + 232;
    }
    a8[1] = v65;
    ++v46;
    std::__optional_destruct_base<TiledLayerTensorRegions,false>::~__optional_destruct_base[abi:ne180100]((uint64_t)__p);
    int v44 = (const ZinTensorRegion *)((char *)v44 + 80);
    if (v44 == v45) {
      goto LABEL_70;
    }
  }
  unint64_t v47 = (a8[1] - *a8) / 232;
  uint64_t v48 = 232 * v47 + 192;
  do
  {
    if (!v47) {
      ZinAssertImpl("Invalid spatial split circular buffer state");
    }
    --v47;
    int v49 = *(unsigned __int8 *)(*a8 + v48 - 200);
    v48 -= 232;
  }
  while (!v49);
  if (!ZinTensorRegion::IsValid(v44)) {
    goto LABEL_61;
  }
  uint64_t v50 = *a8;
  if (0x34F72C234F72C235 * ((a8[1] - *a8) >> 3) <= v47) {
    std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
  }
  if (!*(unsigned char *)(v50 + v48 + 32)) {
    std::__throw_bad_optional_access[abi:ne180100]();
  }
  long long v51 = v88[0];
  uint64_t v52 = *(void *)(v50 + v48 - 136) + *(void *)(v50 + v48 - 176);
  uint64_t v53 = *((void *)v44 + 2);
  BOOL v54 = __OFSUB__(v52, v53);
  uint64_t v55 = v52 - v53;
  if (v55 < 0 == v54)
  {
    int v56 = (void *)(v50 + v48);
    if (*(v56 - 21) == *((void *)v44 + 3) && *(v56 - 16) - *v56 == *((void *)v44 + 8))
    {
      uint64_t v57 = *((void *)v44 + 7);
      BOOL v58 = v57 <= v55;
      uint64_t v59 = v57 - v55;
      if (v58)
      {
        ZinTensorRegion::InvalidZinTensorRegion((uint64_t)__p);
        *(_OWORD *)int v44 = *(_OWORD *)__p;
        long long v60 = v72;
        long long v61 = v73;
        long long v62 = v75;
        *((_OWORD *)v44 + 3) = v74;
        *((_OWORD *)v44 + 4) = v62;
        *((_OWORD *)v44 + 1) = v60;
        *((_OWORD *)v44 + 2) = v61;
        __p[0] = v51;
        std::__hash_table<ZinIrTensor const*,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const* const&>((uint64_t)v69, __p, __p);
      }
      else if (v55 >= 1)
      {
        *((void *)v44 + 2) = v52;
        *((void *)v44 + 7) = v59;
        __p[0] = v51;
        std::__hash_table<ZinIrTensor const*,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const* const&>((uint64_t)v69, __p, __p);
      }
      goto LABEL_61;
    }
  }
  __p[0] = v88[0];
  std::__hash_table<std::__hash_value_type<ZinIrOpLayer *,long>,std::__unordered_map_hasher<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,long>,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,true>,std::__unordered_map_equal<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,long>,std::equal_to<ZinIrOpLayer *>,std::hash<ZinIrOpLayer *>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer *,long>>>::__erase_unique<ZinIrOpLayer *>(v69, __p);
LABEL_77:
  uint64_t v40 = 0;
LABEL_78:
  if (v77)
  {
    __int16 v78 = (const ZinTensorRegion *)v77;
    operator delete(v77);
  }
  if (v86)
  {
    double v87 = v86;
    operator delete(v86);
  }
  if (v84)
  {
    int64x2_t v85 = v84;
    operator delete(v84);
  }
  if (v83) {
    operator delete(v83);
  }
  if (v81)
  {
    double v82 = v81;
    operator delete(v81);
  }
  return v40;
}

void sub_21126E768(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, void *a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33,uint64_t a34,uint64_t a35,uint64_t a36,uint64_t a37,uint64_t a38,uint64_t a39,uint64_t a40,uint64_t a41,uint64_t a42,uint64_t a43,uint64_t a44,uint64_t a45,void *__p,uint64_t a47,uint64_t a48,char a49)
{
  if (__p)
  {
    a47 = (uint64_t)__p;
    operator delete(__p);
  }
  LayerTilingHelper::~LayerTilingHelper((LayerTilingHelper *)&a49);
  _Unwind_Resume(a1);
}

void ZinMirSpatialSplitter::DetermineStandardInputTiling(uint64_t a1, uint64_t a2, uint64_t a3, void *a4, const ZinTensorRegion **a5, uint64_t *a6)
{
  uint64_t v30 = a2;
  double v10 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(a4, &v30);
  if (!v10) {
    ZinAssertImpl("Helper for layer in Spatial Splitting not found");
  }
  LayerTilingHelper::LayerTilingHelper((LayerTilingHelper *)v22, (const LayerTilingHelper *)(v10 + 3));
  uint64_t v12 = *a6;
  for (uint64_t i = a6[1];
        i != v12;
  a6[1] = v12;
  double v13 = *a5;
  double v14 = a5[1];
  if (v13 != v14)
  {
    uint64_t v15 = 0;
    uint64_t v16 = *(void *)(a3 + 64);
    do
    {
      uint64_t v17 = *(void *)(a1 + 112);
      *(void *)(a1 + 112) = v17 + 1;
      v20[0] = v16;
      v20[1] = v17;
      v20[2] = v15;
      v20[3] = 0;
      LayerTilingHelper::ToProduce(v22, (const TiledLayerTensorRegions::Id *)v20, v13, (uint64_t)v21);
      unint64_t v18 = a6[1];
      if (v18 >= a6[2])
      {
        uint64_t v19 = std::vector<std::optional<TiledLayerTensorRegions>>::__push_back_slow_path<std::optional<TiledLayerTensorRegions> const&>(a6, (const TiledLayerTensorRegions *)v21);
      }
      else
      {
        std::__optional_copy_base<TiledLayerTensorRegions,false>::__optional_copy_base[abi:ne180100]((TiledLayerTensorRegions *)a6[1], (const TiledLayerTensorRegions *)v21);
        uint64_t v19 = v18 + 232;
        a6[1] = v18 + 232;
      }
      a6[1] = v19;
      ++v15;
      std::__optional_destruct_base<TiledLayerTensorRegions,false>::~__optional_destruct_base[abi:ne180100]((uint64_t)v21);
      double v13 = (const ZinTensorRegion *)((char *)v13 + 80);
    }
    while (v13 != v14);
  }
  if (__p)
  {
    int v29 = __p;
    operator delete(__p);
  }
  if (v26)
  {
    BOOL v27 = v26;
    operator delete(v26);
  }
  if (v25) {
    operator delete(v25);
  }
  if (v23)
  {
    uint64_t v24 = v23;
    operator delete(v23);
  }
}

void sub_21126E938(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, char a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33,uint64_t a34,uint64_t a35,uint64_t a36,uint64_t a37,uint64_t a38,uint64_t a39,uint64_t a40,uint64_t a41,char a42)
{
}

uint64_t ZinMirSpatialSplitter::DetermineInputTiling(uint64_t a1, ZinIrOpLayer *a2, uint64_t a3, void *a4, uint64_t a5, uint64_t a6, uint64_t *a7, uint64_t *a8)
{
  uint64_t result = ZinMirSpatialSplitter::DetermineCircularBufferInputTiling(a1, a2, a3, a4, a5, a6, a7, a8);
  if ((result & 1) == 0)
  {
    uint64_t v15 = *(uint64_t (**)(uint64_t, ZinIrOpLayer *, uint64_t, void *, uint64_t, uint64_t *))(*(void *)a1 + 32);
    return v15(a1, a2, a3, a4, a6, a8);
  }
  return result;
}

uint64_t ZinMirSpatialSplitter::ExploreResetCurrentLayer(uint64_t a1, ZinIrOpLayer ***a2, uint64_t **a3, uint64_t a4, const LatencyInfo *a5, void *a6)
{
  BOOL v20 = 1;
  if (*(unsigned char *)(a1 + 56)) {
    return 0;
  }
  ZinMirSpatialSplitter::IsWorthTile((ZinMirSpatialSplitter *)a1, (const Subgraph *)a3, (const SplitInfo *)a3, a2, a5, &v20);
  uint64_t v12 = (ZinMirSpatialSplitter *)((uint64_t (*)(ZinIrOpLayer ***, void, void))(*a2)[4])(a2, 0, 0);
  if (*(void *)(a4 + 104) <= *((void *)v12 + 8))
  {
    double v13 = (ZinMirSpatialSplitter *)((uint64_t (*)(ZinIrOpLayer ***, void, void))(*a2)[4])(a2, 0, 0);
    unint64_t v14 = *((void *)v13 + 9);
    unint64_t v15 = *(void *)(a4 + 112);
    if ((v20
       || ZinMirSpatialSplitter::ConcatenatedLayersBenefitFromSplit(v13, (const ZinIrOpLayer *)a2, (Subgraph *)a3, a5))&& v15 <= v14)
    {
      char v16 = 1;
      goto LABEL_10;
    }
  }
  else if (!v20)
  {
    ZinMirSpatialSplitter::ConcatenatedLayersBenefitFromSplit(v12, (const ZinIrOpLayer *)a2, (Subgraph *)a3, a5);
  }
  char v16 = (*(uint64_t (**)(void, ZinIrOpLayer ***))(**(void **)(a1 + 176) + 48))(*(void *)(a1 + 176), a2);
LABEL_10:
  char v17 = ZinMirSpatialSplitter::HandleChainSplit((ZinMirSpatialSplitter *)a1, (Subgraph *)a3, (ZinIrOpLayer *)a2, a5);
  uint64_t v18 = ZinMirSpatialSplitter::HandleL2DepSplit((ZinMirSpatialSplitter *)a1, a3, (ZinIrOpLayer *)a2, a5);
  if ((v18 & 1) == 0 && (v17 & 1) == 0 && (v16 & 1) == 0)
  {
    a6[1] = *a6;
    (*(void (**)(uint64_t, ZinIrOpLayer ***, uint64_t, void *))(*(void *)a1 + 120))(a1, a2, a4, a6);
    BOOL v21 = a2;
    uint64_t v18 = (uint64_t)std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>(a3 + 15, (ZinIrOpLayer **)&v21, (uint64_t *)&v21);
  }
  ZinMirSpatialSplitter::RemoveOutputNodeFromSubgraph((ZinMirSpatialSplitter *)v18, (Subgraph *)a3, a2, a5);
  return 0;
}

uint64_t ZinMirSpatialSplitter::ConcatenatedLayersBenefitFromSplit(ZinMirSpatialSplitter *this, const ZinIrOpLayer *a2, Subgraph *a3, const LatencyInfo *a4)
{
  uint64_t v4 = *((void *)a2 + 14);
  uint64_t v5 = *((void *)a2 + 15);
  if (v4 == v5) {
    return 0;
  }
  while (*(_DWORD *)(*(void *)(*(void *)v4 + 64) + 8) != 7)
  {
    v4 += 8;
    if (v4 == v5) {
      return 0;
    }
  }
  BOOL v20 = *(ZinIrOpLayer **)v4;
  double v9 = (char *)a3 + 72;
  uint64_t result = std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)a3 + 72, &v20);
  if (!result) {
    return result;
  }
  double v10 = (ZinIrOpLayer **)*((void *)v20 + 11);
  double v11 = (ZinIrOpLayer **)*((void *)v20 + 12);
  if (v10 == v11)
  {
    int v14 = 1;
    double v12 = 0.0;
    goto LABEL_16;
  }
  double v12 = 0.0;
  while (1)
  {
    uint64_t v19 = *v10;
    if (std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)a3 + 72, &v19))
    {
      break;
    }
LABEL_12:
    if (++v10 == v11)
    {
      int v14 = 1;
      goto LABEL_16;
    }
  }
  BOOL v21 = v19;
  if ((const LatencyInfo *)((char *)a4 + 32) != (const LatencyInfo *)std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>((uint64_t)a4 + 24, &v21))
  {
    BOOL v21 = v19;
    double v13 = *(double *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)a4, &v21);
    BOOL v21 = v19;
    double v12 = v12
        + v13
        - *(double *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)a4 + 24, &v21);
    goto LABEL_12;
  }
  int v14 = 0;
LABEL_16:
  if (v12 > 0.0) {
    char v15 = v14;
  }
  else {
    char v15 = 0;
  }
  uint64_t result = 1;
  if ((v15 & 1) == 0 && v14)
  {
    char v16 = (ZinIrOpLayer **)*((void *)v20 + 11);
    char v17 = (ZinIrOpLayer **)*((void *)v20 + 12);
    if (v16 != v17)
    {
      uint64_t v18 = (uint64_t **)((char *)a3 + 120);
      do
      {
        uint64_t v19 = *v16;
        if (std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)v9, &v19))
        {
          BOOL v21 = v19;
          std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>(v18, &v21, (uint64_t *)&v21);
        }
        ++v16;
      }
      while (v16 != v17);
    }
    return 0;
  }
  return result;
}

uint64_t ZinMirSpatialSplitter::ReEvaluateSubgraph(ZinMirSpatialSplitter *this, ZinIrOpLayerGraph *a2, Subgraph *a3, uint64_t **a4, LatencyInfo *a5, int a6)
{
  if (*((void *)a3 + 11) != *((void *)a5 + 5)) {
    ZinAssertImpl("Spatial Split Internal Error", a2);
  }
  if (a6 && !*((unsigned char *)this + 56) && ZinMirSpatialSplitter::ReEvaluateTiledLayers(this, a2, a3, a4, a5)) {
    return 3;
  }
  ZinMirSpatialSplitter::PickBestResetLayer(this, a3);
  uint64_t result = 0;
  if (*((unsigned char *)this + 56))
  {
    if (*((void *)a3 + 17)) {
      ZinAssertImpl("Resetting subgraph not allowed");
    }
  }
  return result;
}

uint64_t ZinMirSpatialSplitter::ReEvaluateTiledLayers(ZinMirSpatialSplitter *this, ZinIrOpLayerGraph *a2, Subgraph *a3, uint64_t **a4, LatencyInfo *a5)
{
  long long v6 = (Subgraph **)((char *)a3 + 8);
  long long v7 = *(Subgraph **)a3;
  if (*(Subgraph **)a3 != (Subgraph *)((char *)a3 + 8))
  {
    long long v51 = (uint64_t **)((char *)a3 + 120);
    do
    {
      uint64_t v8 = (void *)*((void *)v7 + 4);
      double v9 = (void **)v8[11];
      double v10 = (void **)v8[12];
      while (v9 != v10)
      {
        long long __p = 0;
        long long __p = *v9;
        if (std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)a3 + 72, (ZinIrOpLayer **)&__p))
        {
          goto LABEL_21;
        }
        ++v9;
      }
      double v11 = (ZinIrTensor *)(*(uint64_t (**)(void *, void, void))(*v8 + 32))(v8, 0, 0);
      RootTensor = ZinIrTensor::GetRootTensor(v11);
      ZinIrTensor::GetTensorFamily(RootTensor, (uint64_t)&__p);
      int v14 = (TiledLayerTensorRegions *)__p;
      double v13 = v57;
      if (__p == v57)
      {
        char v15 = 0;
        if (__p) {
          goto LABEL_17;
        }
      }
      else
      {
        char v15 = 0;
        do
        {
          uint64_t v16 = *(void *)(*(void *)v14 + 96);
          uint64_t v18 = *(void **)(v16 + 112);
          char v17 = *(void **)(v16 + 120);
          while (v18 != v17)
          {
            *(void *)uint64_t v52 = 0;
            *(void *)uint64_t v52 = *v18;
            if (ZinIrOpLayer::IsANELayer(*(ZinIrOpLayer **)v52)
              && std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)a3 + 72, (ZinIrOpLayer **)v52))
            {
              char v15 = 1;
              break;
            }
            ++v18;
          }
          int v14 = (TiledLayerTensorRegions *)((char *)v14 + 8);
        }
        while (v14 != v13);
        int v14 = (TiledLayerTensorRegions *)__p;
        if (__p)
        {
LABEL_17:
          uint64_t v57 = v14;
          operator delete(v14);
        }
      }
      if ((v15 & 1) == 0 && ZinIrOpLayer::IsANELayer((ZinIrOpLayer *)v8))
      {
        long long __p = v8;
        std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>(v51, (ZinIrOpLayer **)&__p, (uint64_t *)&__p);
      }
LABEL_21:
      uint64_t v19 = (Subgraph *)*((void *)v7 + 1);
      if (v19)
      {
        do
        {
          BOOL v20 = (Subgraph **)v19;
          uint64_t v19 = *(Subgraph **)v19;
        }
        while (v19);
      }
      else
      {
        do
        {
          BOOL v20 = (Subgraph **)*((void *)v7 + 2);
          BOOL v23 = *v20 == v7;
          long long v7 = (Subgraph *)v20;
        }
        while (!v23);
      }
      long long v7 = (Subgraph *)v20;
    }
    while (v20 != v6);
  }
  BOOL v21 = (char *)a3 + 48;
  if ((Subgraph *)((char *)a3 + 48) != *((Subgraph **)a3 + 7))
  {
    uint64_t v22 = *((void *)a3 + 8);
    do
    {
      --v22;
      uint64_t v55 = 0;
      uint64_t v55 = *(ZinIrOpLayer **)(*(void *)v21 + 16);
      long long __p = v55;
      if (!std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)a3 + 120, (ZinIrOpLayer **)&__p)&& !std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)a3 + 24, &v55)&& !std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)a3, &v55))
      {
        uint64_t v28 = (void **)*((void *)v55 + 11);
        int v29 = (void **)*((void *)v55 + 12);
        while (v28 != v29)
        {
          long long __p = *v28;
          if (std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)a3 + 120, (ZinIrOpLayer **)&__p))
          {
            long long __p = 0;
            uint64_t v57 = 0;
            unint64_t v58 = 0;
            BOOL v31 = *a4;
            uint64_t v30 = a4[1];
            while (v31 != v30)
            {
              *(void *)uint64_t v52 = 0;
              uint64_t v53 = 0;
              uint64_t v54 = 0;
              std::vector<std::optional<TiledLayerTensorRegions>>::__init_with_size[abi:ne180100]<std::optional<TiledLayerTensorRegions>*,std::optional<TiledLayerTensorRegions>*>(v52, *v31, v31[1], 0x34F72C234F72C235 * ((v31[1] - *v31) >> 3));
              double v32 = (const TiledLayerTensorRegions *)(*(void *)v52 + 232 * v22);
              int v33 = v57;
              if ((unint64_t)v57 >= v58)
              {
                int v34 = (TiledLayerTensorRegions *)std::vector<std::optional<TiledLayerTensorRegions>>::__push_back_slow_path<std::optional<TiledLayerTensorRegions> const&>((uint64_t *)&__p, v32);
              }
              else
              {
                std::__optional_copy_base<TiledLayerTensorRegions,false>::__optional_copy_base[abi:ne180100](v57, v32);
                int v34 = (TiledLayerTensorRegions *)((char *)v33 + 232);
              }
              uint64_t v57 = v34;
              uint64_t v59 = (void **)v52;
              std::vector<std::optional<TiledLayerTensorRegions>>::__destroy_vector::operator()[abi:ne180100](&v59);
              v31 += 3;
            }
            if (!(*(unsigned int (**)(ZinMirSpatialSplitter *, ZinIrOpLayerGraph *, Subgraph *, uint64_t **, ZinIrOpLayer *, void **, LatencyInfo *))(*(void *)this + 16))(this, a2, a3, a4, v55, &__p, a5))
            {
              v52[0] = 0;
              ZinMirSpatialSplitter::IsWorthTile(this, a3, v35, (ZinIrOpLayer ***)v55, a5, v52);
              uint64_t v36 = (ZinMirSpatialSplitter *)ZinMirSpatialSplitter::HandleChainSplit(this, a3, v55, a5);
              if (*((void *)v55 + 12) - *((void *)v55 + 11) == 8) {
                char v37 = (char)v36;
              }
              else {
                char v37 = 1;
              }
              if ((v37 & 1) == 0
                && !v52[0]
                && (ZinMirSpatialSplitter::ConcatenatedLayersBenefitFromSplit(v36, v55, a3, a5) & 1) == 0)
              {
                uint64_t v59 = (void **)v55;
                std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>((uint64_t **)a3 + 15, (ZinIrOpLayer **)&v59, (uint64_t *)&v59);
              }
              *(void *)uint64_t v52 = &__p;
              std::vector<std::optional<TiledLayerTensorRegions>>::__destroy_vector::operator()[abi:ne180100]((void ***)v52);
              break;
            }
            BOOL v39 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
            if (v39) {
              ZinMirSpatialSplitter::ReEvaluateTiledLayers(v39, v40, v41, v42, v43, v44, v45, v46);
            }
            *(void *)uint64_t v52 = &__p;
            std::vector<std::optional<TiledLayerTensorRegions>>::__destroy_vector::operator()[abi:ne180100]((void ***)v52);
            return 3;
          }
          ++v28;
        }
      }
      BOOL v23 = *(_DWORD *)(*((void *)v55 + 8) + 8) == 7 && *((void *)a3 + 17) == 0;
      if (v23)
      {
        uint64_t v24 = (void **)*((void *)v55 + 11);
        uint64_t v25 = (void **)*((void *)v55 + 12);
        if (v24 != v25)
        {
          int v26 = 0;
          int v27 = 0;
          do
          {
            long long __p = 0;
            long long __p = *v24;
            if (ZinIrOpLayer::IsANELayer((ZinIrOpLayer *)__p))
            {
              if (std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)a3 + 72, (ZinIrOpLayer **)&__p))
              {
                ++v27;
              }
              else
              {
                ++v26;
              }
            }
            ++v24;
          }
          while (v24 != v25);
          if (v26 > v27)
          {
            long long __p = v55;
            std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>((uint64_t **)a3 + 15, (ZinIrOpLayer **)&__p, (uint64_t *)&__p);
          }
        }
      }
      BOOL v21 = *(char **)v21;
    }
    while (v21 != *((char **)a3 + 7));
  }
  ZinMirSpatialSplitter::OptimizeTileCountByInsertingResetLayers(this, a2, a3, (const SplitInfo *)a4, a5);
  return 0;
}

void sub_21126F2DC(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, void **p_p, uint64_t a16, uint64_t a17, uint64_t a18, void *__p, uint64_t a20)
{
  p_p = &__p;
  std::vector<std::optional<TiledLayerTensorRegions>>::__destroy_vector::operator()[abi:ne180100](&p_p);
  _Unwind_Resume(a1);
}

void ZinMirSpatialSplitter::PickBestResetLayer(ZinMirSpatialSplitter *this, Subgraph *a2)
{
  if (*((unsigned char *)this + 24))
  {
    BOOL v23 = 0;
    unint64_t v24 = 0;
    uint64_t v22 = (uint64_t *)&v23;
    uint64_t v3 = (uint64_t **)((char *)a2 + 120);
    uint64_t v4 = (char *)*((void *)a2 + 15);
    uint64_t v5 = (char *)a2 + 128;
    if (v4 != (char *)a2 + 128)
    {
      do
      {
        uint64_t v25 = (ZinIrOpLayer *)*((void *)v4 + 4);
        long long __p = v25;
        if (!std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)a2 + 24, (ZinIrOpLayer **)&__p))std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>(&v22, &v25, (uint64_t *)&v25); {
        long long v6 = (char *)*((void *)v4 + 1);
        }
        if (v6)
        {
          do
          {
            long long v7 = v6;
            long long v6 = *(char **)v6;
          }
          while (v6);
        }
        else
        {
          do
          {
            long long v7 = (char *)*((void *)v4 + 2);
            BOOL v8 = *(void *)v7 == (void)v4;
            uint64_t v4 = v7;
          }
          while (!v8);
        }
        uint64_t v4 = v7;
      }
      while (v7 != v5);
      if (v24 >= 2)
      {
        ZinMirSpatialSplitUtils::GetSortedCluster((uint64_t)a2 + 72, 1, (ZinIrOpLayer ***)&__p);
        uint64_t v9 = *(void *)(*(void *)__p + 48);
        uint64_t v10 = *(void *)(*(v21 - 1) + 48);
        BOOL v11 = __OFADD__(v10, v9);
        uint64_t v12 = v10 + v9;
        if (v12 < 0 != v11) {
          ++v12;
        }
        double v13 = v22;
        if (v22 == (uint64_t *)&v23) {
          goto LABEL_31;
        }
        int v14 = 0;
        uint64_t v15 = v12 >> 1;
        int v16 = 0x7FFFFFFF;
        do
        {
          int v17 = v15 - *(_DWORD *)(v13[4] + 48);
          if (v17 < 0) {
            int v17 = *(_DWORD *)(v13[4] + 48) - v15;
          }
          if (v17 < v16)
          {
            int v16 = v17;
            int v14 = (ZinIrOpLayer *)v13[4];
          }
          uint64_t v18 = (uint64_t *)v13[1];
          if (v18)
          {
            do
            {
              uint64_t v19 = v18;
              uint64_t v18 = (uint64_t *)*v18;
            }
            while (v18);
          }
          else
          {
            do
            {
              uint64_t v19 = (uint64_t *)v13[2];
              BOOL v8 = *v19 == (void)v13;
              double v13 = v19;
            }
            while (!v8);
          }
          double v13 = v19;
        }
        while (v19 != (uint64_t *)&v23);
        if (!v14) {
LABEL_31:
        }
          ZinAssertImpl("We should find a reset layer");
        std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v3, *((void **)a2 + 16));
        *((void *)a2 + 16) = 0;
        *((void *)a2 + 17) = 0;
        *((void *)a2 + 15) = v5;
        uint64_t v25 = v14;
        std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>(v3, &v25, (uint64_t *)&v25);
        if (__p)
        {
          BOOL v21 = __p;
          operator delete(__p);
        }
      }
    }
    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v22, v23);
  }
}

void sub_21126F508(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11, uint64_t a12, char a13, void *a14)
{
}

uint64_t ZinMirSpatialSplitter::OptimizeTileCountByInsertingResetLayers(ZinMirSpatialSplitter *this, ZinIrOpLayerGraph *a2, Subgraph *a3, const SplitInfo *a4, const LatencyInfo *a5)
{
  if (!*((void *)a3 + 17) || Subgraph::AreAllResetLayersOutputNodes(a3))
  {
    if ((*(unsigned char *)(*(void *)(*((void *)this + 2) + 8) + 97) & 1) != 0
      && os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_INFO))
    {
      *(_WORD *)uint8_t buf = 0;
      _os_log_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_INFO, "INFO:: (SpatialSplit) ---OptimizeTileCountByInsertingResetLayers:BEGIN---\n", buf, 2u);
    }
    long long v6 = (const LatencyInfo *)*((void *)a5 + 3);
    double v7 = 0.0;
    if (v6 != (const LatencyInfo *)((char *)a5 + 32))
    {
      do
      {
        BOOL v8 = (const LatencyInfo *)*((void *)v6 + 1);
        uint64_t v9 = v6;
        if (v8)
        {
          do
          {
            uint64_t v10 = v8;
            BOOL v8 = *(const LatencyInfo **)v8;
          }
          while (v8);
        }
        else
        {
          do
          {
            uint64_t v10 = (const LatencyInfo *)*((void *)v9 + 2);
            BOOL v11 = *(void *)v10 == (void)v9;
            uint64_t v9 = v10;
          }
          while (!v11);
        }
        double v7 = v7 + *((double *)v6 + 5);
        long long v6 = v10;
      }
      while (v10 != (const LatencyInfo *)((char *)a5 + 32));
    }
    uint64_t v12 = (char *)*((void *)a3 + 7);
    int v49 = (char *)a3 + 48;
    uint64_t v48 = a3;
    if (v12 == (char *)a3 + 48)
    {
      uint64_t v46 = 0;
      double v13 = 1.79769313e308;
    }
    else
    {
      uint64_t v46 = 0;
      uint64_t v45 = (ZinIrOpLayer **)((char *)a3 + 80);
      double v13 = 1.79769313e308;
      int64x2_t v50 = vdupq_n_s64(1uLL);
      do
      {
        int v14 = (ZinIrOpLayer *)*((void *)v12 + 2);
        if (ZinIrOpLayer::IsANELayer(v14))
        {
          Subgraph::Subgraph((Subgraph *)v91, v48);
          *(void *)uint8_t buf = v14;
          std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>(v97, (ZinIrOpLayer **)buf, (uint64_t *)buf);
          char v89 = 0;
          uint64_t v88 = 0;
          uint64_t v90 = 0;
          uint64_t v15 = *((void *)this + 22);
          uint64_t v57 = 0;
          uint64_t v58 = 0;
          *(void *)uint8_t buf = &v57;
          (*(void (**)(uint64_t, ZinIrOpLayerGraph *, char *, uint8_t *, Subgraph **))(*(void *)v15 + 8))(v15, a2, v91, buf, &v88);
          std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)buf, v57);
          int v16 = v89;
          int v17 = v88;
          if (v89 - v88 != 152)
          {
            unint64_t v47 = v14;
            if (v88 == v89)
            {
LABEL_24:
              int v23 = 0;
LABEL_25:
              if (*((void *)v48 + 11) <= (unint64_t)v23)
              {
                v87[0] = 0;
                v87[1] = 0;
                uint64_t v86 = v87;
                unint64_t v24 = v88;
                long long v51 = v89;
                double v25 = 0.0;
                if (v88 == v89)
                {
                  char v37 = v87;
                }
                else
                {
                  do
                  {
                    Subgraph::Subgraph((Subgraph *)&v77, v24);
                    uint64_t v71 = 0;
                    memset(v70, 0, sizeof(v70));
                    memset(v73, 0, sizeof(v73));
                    int v72 = 1065353216;
                    int v74 = 1065353216;
                    int64x2_t v75 = v50;
                    int64x2_t v76 = v50;
                    uint64_t v57 = 0;
                    uint64_t v58 = 0;
                    v60[0] = 0;
                    v60[1] = 0;
                    *(void *)uint8_t buf = &v57;
                    uint64_t v59 = v60;
                    v62[0] = 0;
                    v62[1] = 0;
                    unint64_t v64 = 0;
                    uint64_t v65 = 0;
                    long long v61 = v62;
                    uint64_t v63 = &v64;
                    v67[0] = 0;
                    v67[1] = 0;
                    int v66 = v67;
                    memset(v68, 0, sizeof(v68));
                    int v69 = 1065353216;
                    LODWORD(v100) = 3;
                    v101[0] = &v100;
                    int v26 = std::__tree<std::__value_type<ZinIrDimension,unsigned long>,std::__map_value_compare<ZinIrDimension,std::__value_type<ZinIrDimension,unsigned long>,std::less<ZinIrDimension>,true>,std::allocator<std::__value_type<ZinIrDimension,unsigned long>>>::__emplace_unique_key_args<ZinIrDimension,std::piecewise_construct_t const&,std::tuple<ZinIrDimension&&>,std::tuple<>>((uint64_t **)(v84 - 24), (int *)&v100, (uint64_t)&std::piecewise_construct, v101)[5];
                    LODWORD(v99) = 4;
                    v101[0] = &v99;
                    int v27 = std::__tree<std::__value_type<ZinIrDimension,unsigned long>,std::__map_value_compare<ZinIrDimension,std::__value_type<ZinIrDimension,unsigned long>,std::less<ZinIrDimension>,true>,std::allocator<std::__value_type<ZinIrDimension,unsigned long>>>::__emplace_unique_key_args<ZinIrDimension,std::piecewise_construct_t const&,std::tuple<ZinIrDimension&&>,std::tuple<>>((uint64_t **)(v84 - 24), (int *)&v99, (uint64_t)&std::piecewise_construct, v101)[5];
                    v75.i64[0] = (uint64_t)v26;
                    v75.i64[1] = (uint64_t)v27;
                    LODWORD(v100) = 3;
                    v101[0] = &v100;
                    uint64_t v28 = std::__tree<std::__value_type<ZinIrDimension,unsigned long>,std::__map_value_compare<ZinIrDimension,std::__value_type<ZinIrDimension,unsigned long>,std::less<ZinIrDimension>,true>,std::allocator<std::__value_type<ZinIrDimension,unsigned long>>>::__emplace_unique_key_args<ZinIrDimension,std::piecewise_construct_t const&,std::tuple<ZinIrDimension&&>,std::tuple<>>((uint64_t **)(v84 - 24), (int *)&v100, (uint64_t)&std::piecewise_construct, v101)[5];
                    LODWORD(v99) = 4;
                    v101[0] = &v99;
                    int v29 = std::__tree<std::__value_type<ZinIrDimension,unsigned long>,std::__map_value_compare<ZinIrDimension,std::__value_type<ZinIrDimension,unsigned long>,std::less<ZinIrDimension>,true>,std::allocator<std::__value_type<ZinIrDimension,unsigned long>>>::__emplace_unique_key_args<ZinIrDimension,std::piecewise_construct_t const&,std::tuple<ZinIrDimension&&>,std::tuple<>>((uint64_t **)(v84 - 24), (int *)&v99, (uint64_t)&std::piecewise_construct, v101);
                    std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::resize((uint64_t *)v70, (void)v29[5] * (void)v28);
                    SplitInfo::ReserveBranch((uint64_t **)v70, (unint64_t)v82[1]);
                    LODWORD(v100) = 3;
                    v101[0] = &v100;
                    uint64_t v30 = std::__tree<std::__value_type<ZinIrDimension,unsigned long>,std::__map_value_compare<ZinIrDimension,std::__value_type<ZinIrDimension,unsigned long>,std::less<ZinIrDimension>,true>,std::allocator<std::__value_type<ZinIrDimension,unsigned long>>>::__emplace_unique_key_args<ZinIrDimension,std::piecewise_construct_t const&,std::tuple<ZinIrDimension&&>,std::tuple<>>((uint64_t **)(v84 - 24), (int *)&v100, (uint64_t)&std::piecewise_construct, v101)[5];
                    LODWORD(v99) = 4;
                    v101[0] = &v99;
                    BOOL v31 = std::__tree<std::__value_type<ZinIrDimension,unsigned long>,std::__map_value_compare<ZinIrDimension,std::__value_type<ZinIrDimension,unsigned long>,std::less<ZinIrDimension>,true>,std::allocator<std::__value_type<ZinIrDimension,unsigned long>>>::__emplace_unique_key_args<ZinIrDimension,std::piecewise_construct_t const&,std::tuple<ZinIrDimension&&>,std::tuple<>>((uint64_t **)(v84 - 24), (int *)&v99, (uint64_t)&std::piecewise_construct, v101);
                    SplitInfo::ReserveTiledLayerTensorRegions((uint64_t)v70, &v81, (void)v31[5] * (void)v30);
                    ZinMirGraphSplitterBase::TileSubgraph(this, a2, (Subgraph *)&v77, (SplitInfo *)v70, (LatencyInfo *)buf, 0);
                    double v32 = v59;
                    double v33 = 0.0;
                    if (v59 != v60)
                    {
                      do
                      {
                        int v34 = v32[1];
                        int v35 = v32;
                        if (v34)
                        {
                          do
                          {
                            uint64_t v36 = (void **)v34;
                            int v34 = (void *)*v34;
                          }
                          while (v34);
                        }
                        else
                        {
                          do
                          {
                            uint64_t v36 = (void **)v35[2];
                            BOOL v11 = *v36 == v35;
                            int v35 = v36;
                          }
                          while (!v11);
                        }
                        double v33 = v33 + *((double *)v32 + 5);
                        double v32 = v36;
                      }
                      while (v36 != v60);
                    }
                    std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::insert[abi:ne180100]<std::__tree_const_iterator<ZinIrOpLayer *,std::__tree_node<ZinIrOpLayer *,void *> *,long>>((uint64_t *)&v86, v81, v82);
                    double v25 = v25 + v33;
                    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v68);
                    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v66, v67[0]);
                    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v63, v64);
                    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v61, v62[0]);
                    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v59, v60[0]);
                    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)buf, v57);
                    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v73);
                    std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::~__hash_table((uint64_t)&v70[1] + 8);
                    *(void *)uint8_t buf = v70;
                    std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__destroy_vector::operator()[abi:ne180100]((void ***)buf);
                    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v85, v85[1]);
                    *(void *)uint8_t buf = &v83;
                    std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100]((void ***)buf);
                    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v81, v82[0]);
                    std::__list_imp<ZinIrSection *>::clear(v80);
                    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v79, v79[1]);
                    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v77, v78[0]);
                    unint64_t v24 = (Subgraph *)((char *)v24 + 152);
                  }
                  while (v24 != v51);
                  char v37 = v86;
                }
                v78[0] = 0;
                v78[1] = 0;
                uint64_t v77 = (void **)v78;
                int v38 = (_DWORD *)*((void *)v48 + 9);
                long long v100 = v45;
                v101[0] = v38;
                uint64_t v98 = v87;
                uint64_t v99 = v37;
                *(void *)&v70[0] = &v77;
                *((void *)&v70[0] + 1) = v78;
                std::__set_difference[abi:ne180100]<std::_ClassicAlgPolicy,std::__less<void,void>,std::__tree_const_iterator<ZinIrOpLayer *,std::__tree_node<ZinIrOpLayer *,void *> *,long> &,std::__tree_const_iterator<ZinIrOpLayer *,std::__tree_node<ZinIrOpLayer *,void *> *,long> &,std::__tree_const_iterator<ZinIrOpLayer *,std::__tree_node<ZinIrOpLayer *,void *> *,long> &,std::__tree_const_iterator<ZinIrOpLayer *,std::__tree_node<ZinIrOpLayer *,void *> *,long> &,std::insert_iterator<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>> &>((ZinIrOpLayer ***)v101, &v100, (uint64_t)&v99, &v98, (uint64_t *)v70, (uint64_t)buf);
                BOOL v39 = v77;
                if (v77 != (void **)v78)
                {
                  do
                  {
                    *(void *)uint8_t buf = v39[4];
                    uint64_t v40 = (double *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)a5, (ZinIrOpLayer **)buf);
                    uint64_t v41 = (void **)v39[1];
                    if (v41)
                    {
                      do
                      {
                        uint64_t v42 = v41;
                        uint64_t v41 = (void **)*v41;
                      }
                      while (v41);
                    }
                    else
                    {
                      do
                      {
                        uint64_t v42 = (void **)v39[2];
                        BOOL v11 = *v42 == v39;
                        BOOL v39 = v42;
                      }
                      while (!v11);
                    }
                    double v25 = v25 + *v40;
                    BOOL v39 = v42;
                  }
                  while (v42 != (void **)v78);
                }
                uint64_t v43 = v46;
                if (v25 < v13) {
                  uint64_t v43 = v47;
                }
                uint64_t v46 = v43;
                if (v25 < v13) {
                  double v13 = v25;
                }
                std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v77, v78[0]);
                std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v86, v87[0]);
              }
            }
            else
            {
              while (1)
              {
                uint64_t v18 = (uint64_t **)(*((void *)v17 + 13) - 24);
                LODWORD(v77) = 3;
                *(void *)uint8_t buf = &v77;
                uint64_t v19 = std::__tree<std::__value_type<ZinIrDimension,unsigned long>,std::__map_value_compare<ZinIrDimension,std::__value_type<ZinIrDimension,unsigned long>,std::less<ZinIrDimension>,true>,std::allocator<std::__value_type<ZinIrDimension,unsigned long>>>::__emplace_unique_key_args<ZinIrDimension,std::piecewise_construct_t const&,std::tuple<ZinIrDimension&&>,std::tuple<>>(v18, (int *)&v77, (uint64_t)&std::piecewise_construct, (_DWORD **)buf)[5];
                BOOL v20 = (uint64_t **)(*((void *)v17 + 13) - 24);
                LODWORD(v70[0]) = 4;
                *(void *)uint8_t buf = v70;
                if ((void)std::__tree<std::__value_type<ZinIrDimension,unsigned long>,std::__map_value_compare<ZinIrDimension,std::__value_type<ZinIrDimension,unsigned long>,std::less<ZinIrDimension>,true>,std::allocator<std::__value_type<ZinIrDimension,unsigned long>>>::__emplace_unique_key_args<ZinIrDimension,std::piecewise_construct_t const&,std::tuple<ZinIrDimension&&>,std::tuple<>>(v20, (int *)v70, (uint64_t)&std::piecewise_construct, (_DWORD **)buf)[5]* (void)v19 >= *((void *)a4 + 14) * *((void *)a4 + 13))break; {
                int v17 = (Subgraph *)((char *)v17 + 152);
                }
                if (v17 == v16)
                {
                  BOOL v21 = v88;
                  uint64_t v22 = v89;
                  if (v88 == v89) {
                    goto LABEL_24;
                  }
                  int v23 = 0;
                  do
                  {
                    Subgraph::Subgraph((Subgraph *)buf, v21);
                    v23 += v65;
                    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v68, v68[1]);
                    uint64_t v77 = (void **)&v66;
                    std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100](&v77);
                    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v63, v64);
                    std::__list_imp<ZinIrSection *>::clear(&v61);
                    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v59, v60[0]);
                    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)buf, v57);
                    BOOL v21 = (Subgraph *)((char *)v21 + 152);
                  }
                  while (v21 != v22);
                  goto LABEL_25;
                }
              }
            }
          }
          *(void *)uint8_t buf = &v88;
          std::vector<Subgraph>::__destroy_vector::operator()[abi:ne180100]((void ***)buf);
          std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v97, v97[1]);
          *(void *)uint8_t buf = &v96;
          std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100]((void ***)buf);
          std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v95, v95[1]);
          std::__list_imp<ZinIrSection *>::clear(v94);
          std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v93, v93[1]);
          std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v91, v92);
        }
        uint64_t v12 = (char *)*((void *)v12 + 1);
      }
      while (v12 != v49);
    }
    if (v7 * 0.95 > v13)
    {
      *(void *)uint8_t buf = v46;
      std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>((uint64_t **)v48 + 15, (ZinIrOpLayer **)buf, (uint64_t *)buf);
    }
    if ((*(unsigned char *)(*(void *)(*((void *)this + 2) + 8) + 97) & 1) != 0
      && os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_INFO))
    {
      *(_WORD *)uint8_t buf = 0;
      _os_log_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_INFO, "INFO:: (SpatialSplit) ---OptimizeTileCountByInsertingResetLayers:END---\n", buf, 2u);
    }
  }
  return 0;
}

void sub_21126FE0C(_Unwind_Exception *a1)
{
  STACK[0x238] = (unint64_t)&STACK[0x2E8];
  std::vector<Subgraph>::__destroy_vector::operator()[abi:ne180100]((void ***)&STACK[0x238]);
  Subgraph::~Subgraph((Subgraph *)&STACK[0x300]);
  _Unwind_Resume(a1);
}

BOOL Subgraph::AreAllResetLayersOutputNodes(Subgraph *this)
{
  uint64_t v1 = (void *)*((void *)this + 15);
  uint64_t v2 = (char *)this + 128;
  if (v1 == (void *)((char *)this + 128)) {
    return 1;
  }
  uint64_t v3 = (char *)this + 24;
  do
  {
    uint64_t v9 = (ZinIrOpLayer *)v1[4];
    uint64_t v4 = std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)v3, &v9);
    BOOL result = v4 != 0;
    if (!v4) {
      break;
    }
    long long v6 = (void *)v1[1];
    if (v6)
    {
      do
      {
        double v7 = v6;
        long long v6 = (void *)*v6;
      }
      while (v6);
    }
    else
    {
      do
      {
        double v7 = (void *)v1[2];
        BOOL v8 = *v7 == (void)v1;
        uint64_t v1 = v7;
      }
      while (!v8);
    }
    uint64_t v1 = v7;
  }
  while (v7 != (void *)v2);
  return result;
}

uint64_t ZinMirSpatialSplitter::BuildConcatsForOutputNodes(uint64_t a1, ZinIrOpLayerGraph *a2, uint64_t a3, SplitInfo *a4, void *a5, void *a6)
{
  uint64_t v117 = *MEMORY[0x263EF8340];
  long long v6 = *(void **)(a3 + 24);
  char v68 = (void *)(a3 + 32);
  if (v6 == (void *)(a3 + 32)) {
    return 0;
  }
  while (1)
  {
    char v114 = (uint64_t **)v6[4];
    v115[0] = v114;
    __p[0] = v115;
    __p[1] = (void *)1;
    Layer2TDMapper::SourceLayer::SourceLayer(&v111, __p);
    BOOL v8 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::find<ZinIrTensor *>(a5, &v114);
    if (!v8) {
      std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
    }
    memset(v110, 0, sizeof(v110));
    std::vector<TiledLayerTensorRegions>::__init_with_size[abi:ne180100]<TiledLayerTensorRegions*,TiledLayerTensorRegions*>(v110, v8[3], v8[4], 0x6DB6DB6DB6DB6DB7 * ((uint64_t)(v8[4] - v8[3]) >> 5));
    uint64_t v9 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::find<ZinIrTensor *>(a6, &v114);
    if (!v9) {
      std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
    }
    uint64_t v107 = 0;
    std::string v108 = 0;
    uint64_t v109 = 0;
    std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(&v107, (const void *)v9[3], v9[4], (uint64_t)(v9[4] - v9[3]) >> 3);
    uint64_t v71 = v6;
    uint64_t v10 = v114;
    if (*((char *)v114 + 47) >= 0) {
      size_t v11 = *((unsigned __int8 *)v114 + 47);
    }
    else {
      size_t v11 = (size_t)v114[4];
    }
    std::string::basic_string[abi:ne180100]((uint64_t)v79, v11 + 1);
    if (v79[23] >= 0) {
      uint64_t v12 = v79;
    }
    else {
      uint64_t v12 = *(unsigned char **)v79;
    }
    if (v11)
    {
      if (*((char *)v10 + 47) >= 0) {
        double v13 = (uint64_t *)(v10 + 3);
      }
      else {
        double v13 = v10[3];
      }
      memmove(v12, v13, v11);
    }
    *(_WORD *)&v12[v11] = 95;
    std::string::basic_string[abi:ne180100]<0>(&v104, "concat_sssg");
    int v14 = std::string::append(&v104, "_xfm", 4uLL);
    long long v15 = *(_OWORD *)&v14->__r_.__value_.__l.__data_;
    int64_t v106 = v14->__r_.__value_.__r.__words[2];
    long long v105 = v15;
    v14->__r_.__value_.__l.__size_ = 0;
    v14->__r_.__value_.__r.__words[2] = 0;
    v14->__r_.__value_.__r.__words[0] = 0;
    if (v106 >= 0) {
      int v16 = (const std::string::value_type *)&v105;
    }
    else {
      int v16 = (const std::string::value_type *)v105;
    }
    if (v106 >= 0) {
      std::string::size_type v17 = HIBYTE(v106);
    }
    else {
      std::string::size_type v17 = *((void *)&v105 + 1);
    }
    uint64_t v18 = std::string::append((std::string *)v79, v16, v17);
    long long v19 = *(_OWORD *)&v18->__r_.__value_.__l.__data_;
    std::string::size_type v86 = v18->__r_.__value_.__r.__words[2];
    *(_OWORD *)long long __p = v19;
    v18->__r_.__value_.__l.__size_ = 0;
    v18->__r_.__value_.__r.__words[2] = 0;
    v18->__r_.__value_.__r.__words[0] = 0;
    ZinObjectNameFactory::ZinObjectNameFactory(v115, __p);
    if (SHIBYTE(v86) < 0) {
      operator delete(__p[0]);
    }
    if (SHIBYTE(v106) < 0) {
      operator delete((void *)v105);
    }
    if (SHIBYTE(v104.__r_.__value_.__r.__words[2]) < 0) {
      operator delete(v104.__r_.__value_.__l.__data_);
    }
    if ((v79[23] & 0x80000000) != 0) {
      operator delete(*(void **)v79);
    }
    SplitInfo::GetSplitDimensions(a4, (char **)&v105);
    int v72 = (unsigned int *)*((void *)&v105 + 1);
    BOOL v20 = (unsigned int *)v105;
    if ((void)v105 == *((void *)&v105 + 1))
    {
      int v60 = 1;
      if (!(void)v105) {
        goto LABEL_90;
      }
LABEL_89:
      *((void *)&v105 + 1) = v20;
      operator delete(v20);
      goto LABEL_90;
    }
    do
    {
      long long v73 = v20;
      unsigned int v21 = *v20;
      SplitInfo::GetSplitDimensions(a4, &v104.__r_.__value_.__l.__data_);
      std::string::size_type size = v104.__r_.__value_.__l.__size_;
      uint64_t v23 = 1;
      do
      {
        if (size == v104.__r_.__value_.__r.__words[0]) {
          break;
        }
        v23 *= (void)SplitInfo::GetTileCount(a4, *(_DWORD *)(size - 4));
        int v24 = *(_DWORD *)(size - 4);
        size -= 4;
      }
      while (v24 != v21);
      int64x2_t v102 = 0;
      __src = 0;
      uint64_t v103 = 0;
      uint64_t v99 = 0;
      uint64_t v98 = 0;
      unint64_t v100 = 0;
      if (v23 < 1)
      {
        std::vector<TiledLayerTensorRegions>::__assign_with_size[abi:ne180100]<TiledLayerTensorRegions*,TiledLayerTensorRegions*>(v110, 0, 0, 0);
        std::vector<DimensionMapping>::__assign_with_size[abi:ne180100]<DimensionMapping const*,DimensionMapping const*>((char *)&v107, (char *)__src, (uint64_t)v102, ((unsigned char *)v102 - (unsigned char *)__src) >> 3);
        int v58 = 0;
      }
      else
      {
        if (v21 <= 5 && ((1 << v21) & 0x26) != 0) {
          ZinAssertImpl("Spatial Splitting Internal Error");
        }
        uint64_t v25 = v110[0];
        unint64_t TileCount = (unint64_t)SplitInfo::GetTileCount(a4, v21);
        memset(v97, 0, sizeof(v97));
        std::vector<TiledLayerTensorRegions>::__init_with_size[abi:ne180100]<TiledLayerTensorRegions*,TiledLayerTensorRegions*>(v97, v25, v25 + 224 * TileCount, TileCount);
        int v27 = v107;
        unint64_t v28 = (unint64_t)SplitInfo::GetTileCount(a4, v21);
        uint64_t v94 = 0;
        uint64_t v95 = 0;
        uint64_t v96 = 0;
        std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(&v94, v27, (uint64_t)&v27[v28], v28);
        unint64_t v29 = *(void *)(a1 + 112);
        *(void *)(a1 + 112) = v29 + 1;
        *(void *)uint64_t v79 = 0;
        *(_OWORD *)&v79[8] = v29;
        *(void *)&v79[24] = 0;
        LayerTilingHelper::ProduceConcatRegionAfterOutputNode((long long *)v79, v97, v21, (uint64_t)__p);
        uint64_t v30 = v99;
        if ((unint64_t)v99 >= v100)
        {
          BOOL v31 = (TiledLayerTensorRegions *)std::vector<TiledLayerTensorRegions>::__push_back_slow_path<TiledLayerTensorRegions const&>(&v98, (const TiledLayerTensorRegions *)__p);
        }
        else
        {
          TiledLayerTensorRegions::TiledLayerTensorRegions(v99, (const TiledLayerTensorRegions *)__p);
          BOOL v31 = (TiledLayerTensorRegions *)((char *)v30 + 224);
        }
        uint64_t v99 = v31;
        SplitInfo::GetSplitDimensions(a4, (char **)v79);
        if (*(_DWORD *)(*(void *)&v79[8] - 4) != v21) {
          ZinIrOpLayer::CreateSpatialSplitCopyTensor((ZinIrOpLayer *)v114, (const TiledLayerTensorRegions *)__p);
        }
        double v32 = (void *)((uint64_t (*)(uint64_t **, void, void))(*v114)[5])(v114, 0, 0);
        double v33 = (std::__shared_weak_count *)v32[1];
        v83[1] = *v32;
        uint64_t v84 = v33;
        if (v33) {
          atomic_fetch_add_explicit(&v33->__shared_owners_, 1uLL, memory_order_relaxed);
        }
        if (*(void *)v79)
        {
          *(void *)&v79[8] = *(void *)v79;
          operator delete(*(void **)v79);
        }
        BOOL v81 = 0;
        double v82 = 0;
        v83[0] = 0;
        int v34 = (uint64_t *)v91;
        int v35 = v92;
        while (1)
        {
          if (v34 == v35) {
            operator new();
          }
          uint64_t v80 = 0;
          memset(v79, 0, sizeof(v79));
          uint64_t ValueAt = GetValueAtDimension<ZinTensorPosition>(v34, v21);
          unsigned int v37 = SetValueAtDimension<ZinTensorPosition>(v79, v21, ValueAt);
          if (v37) {
            break;
          }
          int v38 = v82;
          if ((unint64_t)v82 >= v83[0])
          {
            unint64_t v42 = 0xCCCCCCCCCCCCCCCDLL * ((v82 - (unsigned char *)v81) >> 4);
            unint64_t v43 = v42 + 1;
            if (v42 + 1 > 0x333333333333333) {
              std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
            }
            if (0x999999999999999ALL * ((uint64_t)(v83[0] - (void)v81) >> 4) > v43) {
              unint64_t v43 = 0x999999999999999ALL * ((uint64_t)(v83[0] - (void)v81) >> 4);
            }
            if (0xCCCCCCCCCCCCCCCDLL * ((uint64_t)(v83[0] - (void)v81) >> 4) >= 0x199999999999999) {
              unint64_t v44 = 0x333333333333333;
            }
            else {
              unint64_t v44 = v43;
            }
            uint64_t v45 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ZinIrCodegenTDPartitionStats>>((uint64_t)v83, v44);
            unint64_t v47 = &v45[80 * v42];
            long long v49 = *(_OWORD *)v79;
            long long v48 = *(_OWORD *)&v79[16];
            *((void *)v47 + 4) = v80;
            *(_OWORD *)unint64_t v47 = v49;
            *((_OWORD *)v47 + 1) = v48;
            int64x2_t v50 = vdupq_n_s64(1uLL);
            *(int64x2_t *)(v47 + 40) = v50;
            *(int64x2_t *)(v47 + 56) = v50;
            *((void *)v47 + 9) = 1;
            uint64_t v52 = (char *)v81;
            long long v51 = v82;
            uint64_t v53 = v47;
            if (v82 != v81)
            {
              do
              {
                *((_OWORD *)v53 - 5) = *((_OWORD *)v51 - 5);
                long long v54 = *((_OWORD *)v51 - 4);
                long long v55 = *((_OWORD *)v51 - 3);
                long long v56 = *((_OWORD *)v51 - 1);
                *((_OWORD *)v53 - 2) = *((_OWORD *)v51 - 2);
                *((_OWORD *)v53 - 1) = v56;
                *((_OWORD *)v53 - 4) = v54;
                *((_OWORD *)v53 - 3) = v55;
                v53 -= 80;
                v51 -= 80;
              }
              while (v51 != v52);
              long long v51 = v52;
            }
            uint64_t v57 = v47 + 80;
            BOOL v81 = v53;
            double v82 = v47 + 80;
            v83[0] = &v45[80 * v46];
            if (v51) {
              operator delete(v51);
            }
            double v82 = v57;
          }
          else
          {
            long long v40 = *(_OWORD *)v79;
            long long v39 = *(_OWORD *)&v79[16];
            *((void *)v82 + 4) = v80;
            int64x2_t v41 = vdupq_n_s64(1uLL);
            *(_OWORD *)int v38 = v40;
            *((_OWORD *)v38 + 1) = v39;
            *(int64x2_t *)(v38 + 40) = v41;
            *(int64x2_t *)(v38 + 56) = v41;
            *((void *)v38 + 9) = 1;
            double v82 = v38 + 80;
          }
          v34 += 10;
        }
        unsigned int v74 = v37;
        if (v81)
        {
          double v82 = (char *)v81;
          operator delete(v81);
        }
        if (v84) {
          std::__shared_weak_count::__release_shared[abi:ne180100](v84);
        }
        if (v93) {
          operator delete(v93);
        }
        if (v91)
        {
          BOOL v92 = (uint64_t *)v91;
          operator delete(v91);
        }
        if (v89)
        {
          uint64_t v90 = v89;
          operator delete(v89);
        }
        if (v87)
        {
          uint64_t v88 = v87;
          operator delete(v87);
        }
        if (v94)
        {
          uint64_t v95 = v94;
          operator delete(v94);
        }
        __p[0] = v97;
        std::vector<TiledLayerTensorRegions>::__destroy_vector::operator()[abi:ne180100]((void ***)__p);
        int v58 = 1;
      }
      __p[0] = &v98;
      std::vector<TiledLayerTensorRegions>::__destroy_vector::operator()[abi:ne180100]((void ***)__p);
      if (__src)
      {
        int64x2_t v102 = __src;
        operator delete(__src);
      }
      if (v104.__r_.__value_.__r.__words[0])
      {
        v104.__r_.__value_.__l.__size_ = v104.__r_.__value_.__r.__words[0];
        operator delete(v104.__r_.__value_.__l.__data_);
      }
      BOOL v20 = v73 + 1;
      if (v73 + 1 == v72) {
        char v59 = 1;
      }
      else {
        char v59 = v58;
      }
    }
    while ((v59 & 1) == 0);
    int v60 = v58 ^ 1;
    BOOL v20 = (unsigned int *)v105;
    if ((void)v105) {
      goto LABEL_89;
    }
LABEL_90:
    if (v60)
    {
      if (v108 - (char *)v107 != 8
        || (long long v61 = (ZinIrOpLayer *)*v107,
            memset(v77, 0, sizeof(v77)),
            int v78 = 1065353216,
            char v62 = ZinIrOpLayerGraph::MoveOutgoingEdges(a2, v114, v61, v77),
            std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v77),
            (v62 & 1) == 0))
      {
        ZinAssertImpl("Spatial Splitting Internal Error");
      }
    }
    v115[0] = &unk_26C34DA98;
    if (v116 < 0) {
      operator delete((void *)v115[1]);
    }
    if (v107)
    {
      std::string v108 = (char *)v107;
      operator delete(v107);
    }
    __p[0] = v110;
    std::vector<TiledLayerTensorRegions>::__destroy_vector::operator()[abi:ne180100]((void ***)__p);
    long long v111 = &unk_26C359A08;
    if (v112)
    {
      long long v113 = v112;
      operator delete(v112);
    }
    if (!v60) {
      return v74;
    }
    uint64_t v63 = v71;
    unint64_t v64 = (void *)v71[1];
    if (v64)
    {
      do
      {
        uint64_t v65 = v64;
        unint64_t v64 = (void *)*v64;
      }
      while (v64);
    }
    else
    {
      do
      {
        uint64_t v65 = (void *)v63[2];
        BOOL v66 = *v65 == (void)v63;
        uint64_t v63 = v65;
      }
      while (!v66);
    }
    long long v6 = v65;
    if (v65 == v68) {
      return 0;
    }
  }
}

void sub_2112709B0(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,char a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,void *a29,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33,void *a34,uint64_t a35,uint64_t a36,uint64_t a37,uint64_t a38,void *a39)
{
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&a21);
  *(void *)(v39 - 136) = &unk_26C34DA98;
  if (*(char *)(v39 - 105) < 0) {
    operator delete(*(void **)(v39 - 128));
  }
  int64x2_t v41 = *(void **)(v39 - 224);
  if (v41)
  {
    *(void *)(v39 - 216) = v41;
    operator delete(v41);
  }
  a39 = (void *)(v39 - 200);
  std::vector<TiledLayerTensorRegions>::__destroy_vector::operator()[abi:ne180100]((void ***)&a39);
  *(void *)(v39 - 176) = &unk_26C359A08;
  unint64_t v42 = *(void **)(v39 - 168);
  if (v42)
  {
    *(void *)(v39 - 160) = v42;
    operator delete(v42);
  }
  _Unwind_Resume(a1);
}

uint64_t ZinMirSpatialSplitter::InitializeSubgraphForCostModel(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v3 = *(void *)(a1 + 120);
  long long v5 = *(_OWORD *)(a3 + 104);
  return (*(uint64_t (**)(uint64_t, uint64_t, long long *))(*(void *)v3 + 24))(v3, a2, &v5);
}

uint64_t ZinMirSpatialSplitter::DetermineSubgraphSplitInfo(ZinMirSpatialSplitter *this, ZinIrOpLayerGraph *a2, SubgraphSplitInfo *a3)
{
  long long v6 = (uint64_t *)((char *)a3 + 152);
  double v7 = (uint64_t **)(*((void *)a3 + 13) - 24);
  int v19 = 3;
  BOOL v20 = &v19;
  BOOL v8 = std::__tree<std::__value_type<ZinIrDimension,unsigned long>,std::__map_value_compare<ZinIrDimension,std::__value_type<ZinIrDimension,unsigned long>,std::less<ZinIrDimension>,true>,std::allocator<std::__value_type<ZinIrDimension,unsigned long>>>::__emplace_unique_key_args<ZinIrDimension,std::piecewise_construct_t const&,std::tuple<ZinIrDimension&&>,std::tuple<>>(v7, &v19, (uint64_t)&std::piecewise_construct, &v20)[5];
  uint64_t v9 = (uint64_t **)(*((void *)a3 + 13) - 24);
  int v18 = 4;
  BOOL v20 = &v18;
  uint64_t v10 = std::__tree<std::__value_type<ZinIrDimension,unsigned long>,std::__map_value_compare<ZinIrDimension,std::__value_type<ZinIrDimension,unsigned long>,std::less<ZinIrDimension>,true>,std::allocator<std::__value_type<ZinIrDimension,unsigned long>>>::__emplace_unique_key_args<ZinIrDimension,std::piecewise_construct_t const&,std::tuple<ZinIrDimension&&>,std::tuple<>>(v9, &v18, (uint64_t)&std::piecewise_construct, &v20)[5];
  *((void *)a3 + 32) = v8;
  *((void *)a3 + 33) = v10;
  size_t v11 = (uint64_t **)(*((void *)a3 + 13) - 24);
  int v19 = 0;
  BOOL v20 = &v19;
  uint64_t v12 = std::__tree<std::__value_type<ZinIrDimension,unsigned long>,std::__map_value_compare<ZinIrDimension,std::__value_type<ZinIrDimension,unsigned long>,std::less<ZinIrDimension>,true>,std::allocator<std::__value_type<ZinIrDimension,unsigned long>>>::__emplace_unique_key_args<ZinIrDimension,std::piecewise_construct_t const&,std::tuple<ZinIrDimension&&>,std::tuple<>>(v11, &v19, (uint64_t)&std::piecewise_construct, &v20)[5];
  *((void *)a3 + 34) = v12;
  std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::resize(v6, *((void *)a3 + 32) * (void)v12 * *((void *)a3 + 33));
  SplitInfo::ReserveBranch((uint64_t **)v6, *((void *)a3 + 11));
  SplitInfo::ReserveTiledLayerTensorRegions((uint64_t)v6, (void *)a3 + 9, *((void *)a3 + 33) * *((void *)a3 + 32) * *((void *)a3 + 34));
  v17[0] = 0;
  v17[1] = 0;
  int v16 = v17;
  unint64_t v13 = PressureBasedSubgraphIdentification::EstimateSizeOfKernelReads((uint64_t)a3, (uint64_t)&v16, **((void **)this + 2), 1);
  unint64_t v14 = *(void *)(**((void **)this + 2) + 480);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v16, v17[0]);
  if (v13 > v14) {
    *((unsigned char *)a3 + 144) = 1;
  }
  if (ZinMirGraphSplitterBase::TileSubgraph(this, a2, a3, (SplitInfo *)v6, (SubgraphSplitInfo *)((char *)a3 + 296), 1))return 3; {
  else
  }
    return 0;
}

void sub_211270EA0(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, void *a10)
{
}

uint64_t ZinMirSpatialSplitter::IsCurrentGraphMinLatency(uint64_t a1, uint64_t a2, void *a3)
{
  if (*(unsigned char *)(a1 + 29)) {
    return 1;
  }
  double v7 = *(void **)(a2 + 296);
  double v8 = 0.0;
  double v9 = 0.0;
  if (v7 != (void *)(a2 + 304))
  {
    do
    {
      uint64_t v10 = (void *)v7[1];
      size_t v11 = v7;
      if (v10)
      {
        do
        {
          uint64_t v12 = v10;
          uint64_t v10 = (void *)*v10;
        }
        while (v10);
      }
      else
      {
        do
        {
          uint64_t v12 = (void *)v11[2];
          BOOL v13 = *v12 == (void)v11;
          size_t v11 = v12;
        }
        while (!v13);
      }
      double v9 = v9 + *((double *)v7 + 5);
      double v7 = v12;
    }
    while (v12 != (void *)(a2 + 304));
  }
  unint64_t v14 = *(void **)(a2 + 320);
  if (v14 != (void *)(a2 + 328))
  {
    double v8 = 0.0;
    do
    {
      long long v15 = (void *)v14[1];
      int v16 = v14;
      if (v15)
      {
        do
        {
          std::string::size_type v17 = v15;
          long long v15 = (void *)*v15;
        }
        while (v15);
      }
      else
      {
        do
        {
          std::string::size_type v17 = (void *)v16[2];
          BOOL v13 = *v17 == (void)v16;
          int v16 = v17;
        }
        while (!v13);
      }
      double v8 = v8 + *((double *)v14 + 5);
      unint64_t v14 = v17;
    }
    while (v17 != (void *)(a2 + 328));
  }
  if (*(unsigned char *)(a1 + 35))
  {
    int v18 = *(void **)(a2 + 368);
    double v8 = 0.0;
    if (v18 != (void *)(a2 + 376))
    {
      do
      {
        int v19 = (void *)v18[1];
        BOOL v20 = v18;
        if (v19)
        {
          do
          {
            unsigned int v21 = v19;
            int v19 = (void *)*v19;
          }
          while (v19);
        }
        else
        {
          do
          {
            unsigned int v21 = (void *)v20[2];
            BOOL v13 = *v21 == (void)v20;
            BOOL v20 = v21;
          }
          while (!v13);
        }
        double v8 = v8 + *((double *)v18 + 5);
        int v18 = v21;
      }
      while (v21 != (void *)(a2 + 376));
    }
  }
  uint64_t v22 = *(void **)(a2 + 392);
  double v23 = 0.0;
  if (v22 != (void *)(a2 + 400))
  {
    do
    {
      int v24 = (void *)v22[1];
      uint64_t v25 = v22;
      if (v24)
      {
        do
        {
          int v26 = v24;
          int v24 = (void *)*v24;
        }
        while (v24);
      }
      else
      {
        do
        {
          int v26 = (void *)v25[2];
          BOOL v13 = *v26 == (void)v25;
          uint64_t v25 = v26;
        }
        while (!v13);
      }
      double v23 = v23 + *((double *)v22 + 5);
      uint64_t v22 = v26;
    }
    while (v26 != (void *)(a2 + 400));
  }
  double v27 = v8 + v23;
  if (v9 <= v8 + v23) {
    return 0;
  }
  std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::set[abi:ne180100]((uint64_t *)&v62, (ZinIrOpLayer ***)(a2 + 72));
  unint64_t v29 = (void *)*a3;
  unint64_t v28 = (void *)a3[1];
  if (v29 != v28)
  {
    double v30 = 0.0;
    while (1)
    {
      if (*(unsigned char *)(a1 + 35))
      {
        BOOL v31 = (void *)v29[46];
        if (v31 != v29 + 47)
        {
          double v32 = 0.0;
          do
          {
            double v33 = (void *)v31[1];
            int v34 = v31;
            if (v33)
            {
              do
              {
                int v35 = v33;
                double v33 = (void *)*v33;
              }
              while (v33);
            }
            else
            {
              do
              {
                int v35 = (void *)v34[2];
                BOOL v13 = *v35 == (void)v34;
                int v34 = v35;
              }
              while (!v13);
            }
            double v32 = v32 + *((double *)v31 + 5);
            BOOL v31 = v35;
          }
          while (v35 != v29 + 47);
          goto LABEL_56;
        }
      }
      else
      {
        uint64_t v36 = (void *)v29[40];
        if (v36 != v29 + 41)
        {
          double v32 = 0.0;
          do
          {
            unsigned int v37 = (void *)v36[1];
            int v38 = v36;
            if (v37)
            {
              do
              {
                uint64_t v39 = v37;
                unsigned int v37 = (void *)*v37;
              }
              while (v37);
            }
            else
            {
              do
              {
                uint64_t v39 = (void *)v38[2];
                BOOL v13 = *v39 == (void)v38;
                int v38 = v39;
              }
              while (!v13);
            }
            double v32 = v32 + *((double *)v36 + 5);
            uint64_t v36 = v39;
          }
          while (v39 != v29 + 41);
          goto LABEL_56;
        }
      }
      double v32 = 0.0;
LABEL_56:
      long long v40 = (void *)v29[49];
      double v41 = 0.0;
      if (v40 != v29 + 50)
      {
        do
        {
          unint64_t v42 = (void *)v40[1];
          unint64_t v43 = v40;
          if (v42)
          {
            do
            {
              unint64_t v44 = v42;
              unint64_t v42 = (void *)*v42;
            }
            while (v42);
          }
          else
          {
            do
            {
              unint64_t v44 = (void *)v43[2];
              BOOL v13 = *v44 == (void)v43;
              unint64_t v43 = v44;
            }
            while (!v13);
          }
          double v41 = v41 + *((double *)v40 + 5);
          long long v40 = v44;
        }
        while (v44 != v29 + 50);
      }
      int v60 = 0;
      uint64_t v61 = 0;
      char v59 = (ZinIrOpLayer **)&v60;
      uint64_t v45 = v29[9];
      uint64_t v71 = v62;
      uint64_t v69 = v45;
      int64_t v70 = (ZinIrOpLayer **)&v63;
      v67[1] = (uint64_t)&v60;
      char v68 = v29 + 10;
      v67[0] = (uint64_t)&v59;
      std::__set_difference[abi:ne180100]<std::_ClassicAlgPolicy,ScheduleComparator &,std::__tree_const_iterator<ZinIrOpLayer *,std::__tree_node<ZinIrOpLayer *,void *> *,long> &,std::__tree_const_iterator<ZinIrOpLayer *,std::__tree_node<ZinIrOpLayer *,void *> *,long> &,std::__tree_const_iterator<ZinIrOpLayer *,std::__tree_node<ZinIrOpLayer *,void *> *,long> &,std::__tree_const_iterator<ZinIrOpLayer *,std::__tree_node<ZinIrOpLayer *,void *> *,long> &,std::insert_iterator<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>> &>(&v71, &v70, (uint64_t)&v69, &v68, v67, (int)&v66, (uint64_t)v65);
      double v30 = v30 + v32 + v41;
      uint64_t v46 = v59;
      unint64_t v47 = v60;
      long long v48 = v63;
      char v59 = v62;
      int v60 = v63;
      char v62 = v46;
      uint64_t v63 = v47;
      uint64_t v49 = v61;
      uint64_t v61 = v64;
      uint64_t v64 = v49;
      if (v61) {
        int64x2_t v50 = (ZinIrOpLayer ***)(v60 + 2);
      }
      else {
        int64x2_t v50 = &v59;
      }
      *int64x2_t v50 = (ZinIrOpLayer **)&v60;
      long long v51 = (ZinIrOpLayer ***)(v47 + 2);
      if (v49) {
        uint64_t v52 = v51;
      }
      else {
        uint64_t v52 = &v62;
      }
      char *v52 = (ZinIrOpLayer **)&v63;
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v59, v48);
      v29 += 57;
      if (v29 == v28) {
        goto LABEL_73;
      }
    }
  }
  double v30 = 0.0;
LABEL_73:
  uint64_t v53 = v62;
  if (v62 != (ZinIrOpLayer **)&v63)
  {
    uint64_t v54 = a2 + 296;
    do
    {
      long long v55 = v53[4];
      if (ZinIrOpLayer::IsANELayer(v55))
      {
        v65[0] = v55;
        double v30 = v30
            + *(double *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at(v54, v65);
      }
      long long v56 = v53[1];
      if (v56)
      {
        do
        {
          uint64_t v57 = (ZinIrOpLayer ***)v56;
          long long v56 = *(ZinIrOpLayer **)v56;
        }
        while (v56);
      }
      else
      {
        do
        {
          uint64_t v57 = (ZinIrOpLayer ***)v53[2];
          BOOL v13 = *v57 == v53;
          uint64_t v53 = (ZinIrOpLayer **)v57;
        }
        while (!v13);
      }
      uint64_t v53 = (ZinIrOpLayer **)v57;
    }
    while (v57 != &v63);
  }
  BOOL v3 = v27 <= v30;
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v62, v63);
  return v3;
}

void sub_21127131C(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, void *a10, uint64_t a11, char a12, void *a13)
{
}

void ZinMirSpatialSplitter::ConstructSplitInfoOfRefinedClusters(ZinMirSpatialSplitter *a1@<X0>, ZinIrOpLayerGraph *a2@<X1>, const Subgraph **a3@<X2>, uint64_t *a4@<X8>)
{
  *a4 = 0;
  a4[1] = 0;
  a4[2] = 0;
  uint64_t v4 = *a3;
  long long v5 = a3[1];
  uint64_t v6 = v5 - *a3;
  if (0x86BCA1AF286BCA1BLL * (v6 >> 3) >= 2 && v6 != 152)
  {
    unint64_t v8 = 0;
    uint64_t v9 = 224;
    do
    {
      unint64_t v10 = v8++;
      unint64_t v11 = 0x86BCA1AF286BCA1BLL * ((v5 - v4) >> 3);
      if (v8 < v11)
      {
        uint64_t v12 = v9;
        unint64_t v22 = v8;
        do
        {
          char v59 = 0;
          uint64_t v60 = 0;
          int v58 = (void **)&v59;
          if (v11 <= v10) {
            std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
          }
          double v13 = std::__set_intersection[abi:ne180100]<std::_ClassicAlgPolicy,ScheduleComparator &,std::__tree_const_iterator<ZinIrOpLayer *,std::__tree_node<ZinIrOpLayer *,void *> *,long>,std::__tree_const_iterator<ZinIrOpLayer *,std::__tree_node<ZinIrOpLayer *,void *> *,long>,std::__tree_const_iterator<ZinIrOpLayer *,std::__tree_node<ZinIrOpLayer *,void *> *,long>,std::__tree_const_iterator<ZinIrOpLayer *,std::__tree_node<ZinIrOpLayer *,void *> *,long>,std::insert_iterator<std::set<ZinIrOpLayer *>>>(*((void **)v4 + 19 * v10 + 9), (void *)v4 + 19 * v10 + 10, *(void **)((char *)v4 + v12), (const Subgraph *)((char *)v4 + v12 + 8), (uint64_t)&v58, (uint64_t)&v59, (int)&v74, (uint64_t)&v23);
          if (v60) {
            ZinAssertImpl("Refined subgraphs should not intersect", v13);
          }
          std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v58, v59);
          ++v8;
          uint64_t v4 = *a3;
          long long v5 = a3[1];
          unint64_t v11 = 0x86BCA1AF286BCA1BLL * ((v5 - *a3) >> 3);
          v12 += 152;
        }
        while (v8 < v11);
        unint64_t v8 = v22;
      }
      v9 += 152;
    }
    while (v8 < v11 - 1);
  }
  unint64_t v14 = a4;
  if (v4 != v5)
  {
    int64x2_t v19 = vdupq_n_s64(1uLL);
    do
    {
      Subgraph::Subgraph((Subgraph *)&v58, v4);
      int v24 = 0;
      uint64_t v25 = 0;
      double v27 = 0;
      uint64_t v28 = 0;
      double v23 = (void **)&v24;
      int v26 = &v27;
      v29[0] = (uint64_t)v29;
      v29[1] = (uint64_t)v29;
      BOOL v31 = 0;
      uint64_t v32 = 0;
      v29[2] = 0;
      double v30 = &v31;
      uint64_t v34 = 0;
      long long v33 = 0uLL;
      uint64_t v36 = 0;
      uint64_t v37 = 0;
      int v35 = &v36;
      char v38 = 0;
      uint64_t v42 = 0;
      long long v40 = 0u;
      long long v41 = 0u;
      long long v39 = 0u;
      long long v44 = 0u;
      long long v45 = 0u;
      int v43 = 1065353216;
      int v46 = 1065353216;
      int64x2_t v47 = v19;
      int64x2_t v48 = v19;
      v50[0] = 0;
      v50[1] = 0;
      v51[0] = 0;
      v51[1] = 0;
      uint64_t v49 = v50;
      v50[2] = v51;
      v52[0] = 0;
      v52[1] = 0;
      v53[0] = 0;
      v53[1] = 0;
      v51[2] = v52;
      _OWORD v52[2] = v53;
      v54[0] = 0;
      v54[1] = 0;
      v53[2] = v54;
      long long v55 = 0u;
      long long v56 = 0u;
      int v57 = 1065353216;
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v23, 0);
      double v23 = v58;
      int v24 = v59;
      uint64_t v25 = v60;
      if (v60)
      {
        v59[2] = &v24;
        int v58 = (void **)&v59;
        char v59 = 0;
        uint64_t v60 = 0;
      }
      else
      {
        double v23 = (void **)&v24;
      }
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v26, v27);
      int v26 = v61;
      double v27 = v62;
      uint64_t v28 = v63;
      if (v63)
      {
        void v62[2] = &v27;
        uint64_t v61 = &v62;
        char v62 = 0;
        uint64_t v63 = 0;
      }
      else
      {
        int v26 = &v27;
      }
      std::list<ZinIrOpLayer *>::__move_assign(v29, v64);
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v30, v31);
      double v30 = v65;
      BOOL v31 = v66;
      uint64_t v32 = v67;
      if (v67)
      {
        int v66[2] = &v31;
        uint64_t v65 = &v66;
        char v66 = 0;
        uint64_t v67 = 0;
      }
      else
      {
        double v30 = &v31;
      }
      std::vector<std::map<ZinIrDimension,unsigned long>>::__vdeallocate((void **)&v33);
      long long v33 = v68;
      uint64_t v34 = v69;
      uint64_t v69 = 0;
      long long v68 = 0uLL;
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v35, v36);
      int v35 = v70;
      uint64_t v36 = v71;
      uint64_t v37 = v72;
      if (v72)
      {
        v71[2] = &v36;
        int64_t v70 = &v71;
        uint64_t v71 = 0;
        uint64_t v72 = 0;
      }
      else
      {
        int v35 = &v36;
      }
      char v38 = v73;
      if (ZinMirSpatialSplitter::DetermineSubgraphSplitInfo(a1, a2, (SubgraphSplitInfo *)&v23)) {
        ZinAssertImpl("Fail in determining sub-graph split info");
      }
      long long v15 = v14;
      int v16 = (SubgraphSplitInfo *)v14[1];
      if ((unint64_t)v16 >= v15[2])
      {
        unint64_t v14 = v15;
        uint64_t v17 = std::vector<SubgraphSplitInfo>::__emplace_back_slow_path<SubgraphSplitInfo&>(v15, (const SubgraphSplitInfo *)&v23);
      }
      else
      {
        SubgraphSplitInfo::SubgraphSplitInfo(v16, (const SubgraphSplitInfo *)&v23);
        uint64_t v17 = (uint64_t)v16 + 456;
        unint64_t v14 = a4;
        a4[1] = v17;
      }
      v14[1] = v17;
      SubgraphSplitInfo::~SubgraphSplitInfo((SubgraphSplitInfo *)&v23);
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v70, v71);
      double v23 = (void **)&v68;
      std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100](&v23);
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v65, v66);
      std::__list_imp<ZinIrSection *>::clear(v64);
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v61, v62);
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v58, v59);
      uint64_t v4 = (const Subgraph *)((char *)v4 + 152);
    }
    while (v4 != v5);
  }
}

void sub_2112717EC(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,char a33)
{
  *(void *)(a9 + 8) = v33;
  SubgraphSplitInfo::~SubgraphSplitInfo((SubgraphSplitInfo *)&a33);
  Subgraph::~Subgraph((Subgraph *)(v34 - 248));
  *(void *)(v34 - 248) = a9;
  std::vector<SubgraphSplitInfo>::__destroy_vector::operator()[abi:ne180100]((void ***)(v34 - 248));
  _Unwind_Resume(a1);
}

uint64_t ZinMirSpatialSplitter::IsSubgraphLikelyToKernelStall(const ZinNELayer ***this, const SubgraphSplitInfo *a2)
{
  long long v29 = 0u;
  memset(v28, 0, sizeof(v28));
  uint64_t v2 = (char *)*((void *)a2 + 9);
  BOOL v3 = (char *)a2 + 80;
  if (v2 != (char *)a2 + 80)
  {
    unint64_t v5 = 0;
    uint64_t v6 = (char *)a2 + 368;
    double v7 = (char *)a2 + 344;
    double v8 = 0.0;
    double v9 = 0.0;
    double v10 = 0.0;
    do
    {
      double v27 = (PressureBasedSubgraphIdentification *)*((void *)v2 + 4);
      if (ZinIrOpLayer::IsNELayer(v27))
      {
        uint64_t v12 = PressureBasedSubgraphIdentification::EstimateKernelReadsPerNE((ZinEngineLayerMirInfo **)v27, *this[2], v11);
        double v30 = v27;
        double v13 = *(double *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)v6, &v30);
        double v30 = v27;
        double v8 = v8 + v13;
        double v9 = v9
           + *(double *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)v7, &v30);
      }
      else
      {
        double v30 = v27;
        uint64_t v12 = 0;
        double v10 = v10
            + *(double *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)v6, &v30);
      }
      std::deque<ZinIrOpLayer *>::push_back(v28, &v27);
      v5 += v12;
      if (v5 <= *((void *)*this[2] + 60)) {
        goto LABEL_23;
      }
      unint64_t v14 = *((void *)&v29 + 1);
      double v15 = 0.0;
      if (*((void *)&v29 + 1) < 2uLL)
      {
LABEL_16:
        if (v14 < 2) {
          goto LABEL_23;
        }
      }
      else
      {
        uint64_t v16 = *((void *)&v29 + 1);
        while (1)
        {
          uint64_t v17 = *(ZinEngineLayerMirInfo ***)(*(void *)(*((void *)&v28[0] + 1)
                                                       + (((unint64_t)v29 >> 6) & 0x3FFFFFFFFFFFFF8))
                                           + 8 * (v29 & 0x1FF));
          *(void *)&long long v29 = v29 + 1;
          *((void *)&v29 + 1) = v16 - 1;
          if ((unint64_t)v29 >= 0x400)
          {
            operator delete(**((void ***)&v28[0] + 1));
            *((void *)&v28[0] + 1) += 8;
            *(void *)&long long v29 = v29 - 512;
          }
          if (ZinIrOpLayer::IsNELayer((ZinIrOpLayer *)v17))
          {
            uint64_t v19 = PressureBasedSubgraphIdentification::EstimateKernelReadsPerNE(v17, *this[2], v18);
            double v30 = (ZinIrOpLayer *)v17;
            double v15 = *(double *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)v6, &v30);
            double v30 = (ZinIrOpLayer *)v17;
            double v8 = v8 - v15;
            double v9 = v9
               - *(double *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)v7, &v30);
          }
          else
          {
            double v30 = (ZinIrOpLayer *)v17;
            uint64_t v19 = 0;
            double v10 = v10
                - *(double *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)v6, &v30);
          }
          v5 -= v19;
          if (v5 <= *((void *)*this[2] + 60)) {
            break;
          }
          uint64_t v16 = *((void *)&v29 + 1);
          if (*((void *)&v29 + 1) < 2uLL) {
            goto LABEL_16;
          }
        }
      }
      double v20 = v8 + v15;
      if (v8 + v15 >= v10) {
        double v21 = v8 + v15;
      }
      else {
        double v21 = v10;
      }
      if (v10 < v20) {
        double v20 = v10;
      }
      if (v21 + *((double *)this + 12) * v20 < v9)
      {
        uint64_t v25 = 1;
        goto LABEL_30;
      }
LABEL_23:
      unint64_t v22 = (char *)*((void *)v2 + 1);
      if (v22)
      {
        do
        {
          double v23 = v22;
          unint64_t v22 = *(char **)v22;
        }
        while (v22);
      }
      else
      {
        do
        {
          double v23 = (char *)*((void *)v2 + 2);
          BOOL v24 = *(void *)v23 == (void)v2;
          uint64_t v2 = v23;
        }
        while (!v24);
      }
      uint64_t v2 = v23;
    }
    while (v23 != v3);
  }
  uint64_t v25 = 0;
LABEL_30:
  std::deque<unsigned long>::~deque[abi:ne180100](v28);
  return v25;
}

void sub_211271AFC(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, ...)
{
  va_start(va, a3);
  std::deque<unsigned long>::~deque[abi:ne180100]((uint64_t *)va);
  _Unwind_Resume(a1);
}

unint64_t ZinMirSpatialSplitter::FindWorstKernelBoundLayer(uint64_t a1, uint64_t a2)
{
  v25[1] = 0;
  int v26 = 0;
  BOOL v24 = v25;
  v25[0] = 0;
  uint64_t v2 = *(void **)(a2 + 72);
  BOOL v3 = (void *)(a2 + 80);
  if (v2 == (void *)(a2 + 80))
  {
    double v21 = 0;
    unint64_t v20 = 0;
  }
  else
  {
    uint64_t v6 = a2 + 296;
    uint64_t v7 = a2 + 344;
    uint64_t v8 = a2 + 320;
    uint64_t v9 = a2 + 368;
    do
    {
      double v23 = (ZinIrOpLayer **)v2[4];
      if (ZinIrOpLayer::IsANELayer((ZinIrOpLayer *)v23))
      {
        double v27 = v23;
        double v10 = *(double *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at(v7, (ZinIrOpLayer **)&v27);
        double v27 = v23;
        double v11 = *(double *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at(v6, (ZinIrOpLayer **)&v27);
        double v27 = v23;
        double v12 = *(double *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at(v8, (ZinIrOpLayer **)&v27);
        double v27 = v23;
        double v13 = (double *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at(v9, (ZinIrOpLayer **)&v27);
        if (*(unsigned char *)(a1 + 35)) {
          double v14 = *v13;
        }
        else {
          double v14 = v12;
        }
        BOOL v15 = 0;
        if (v11 / v12 < 1.6 && *(unsigned char *)(a2 + 144) && v12 != 0.0) {
          BOOL v15 = v10 >= v14 * *(double *)(a1 + 80);
        }
        if (*(unsigned char *)(a1 + 35)) {
          double v16 = v11 / *v13;
        }
        else {
          double v16 = v11 / v12;
        }
        double v27 = (ZinIrOpLayer **)&v23;
        *((double *)std::__tree<std::__value_type<unsigned long,ZinIrOpLayer *>,std::__map_value_compare<unsigned long,std::__value_type<unsigned long,ZinIrOpLayer *>,std::less<unsigned long>,true>,std::allocator<std::__value_type<unsigned long,ZinIrOpLayer *>>>::__emplace_unique_key_args<unsigned long,std::piecewise_construct_t const&,std::tuple<unsigned long const&>,std::tuple<>>(&v24, (unint64_t *)&v23, (uint64_t)&std::piecewise_construct, (uint64_t **)&v27)+ 5) = v16;
        if (v15
          && (!v26
           || *(double *)std::map<ZinIrTensor const*,SpatialAmount>::at((uint64_t)&v24, (unint64_t *)&v26) > v16))
        {
          int v26 = (ZinIrOpLayer *)v23;
        }
      }
      uint64_t v17 = (void *)v2[1];
      if (v17)
      {
        do
        {
          int v18 = v17;
          uint64_t v17 = (void *)*v17;
        }
        while (v17);
      }
      else
      {
        do
        {
          int v18 = (void *)v2[2];
          BOOL v19 = *v18 == (void)v2;
          uint64_t v2 = v18;
        }
        while (!v19);
      }
      uint64_t v2 = v18;
    }
    while (v18 != v3);
    unint64_t v20 = (unint64_t)v26;
    double v21 = (void *)v25[0];
  }
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v24, v21);
  return v20;
}

void sub_211271D18(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, char a11, void *a12)
{
}

void ZinMirSpatialSplitter::RefineSubgraphByKernelOverhead(ZinMirSpatialSplitter *this@<X0>, ZinIrOpLayerGraph *a2@<X1>, const SubgraphSplitInfo *a3@<X2>, uint64_t a4@<X8>)
{
  uint64_t v23 = *MEMORY[0x263EF8340];
  long long v12 = 0uLL;
  uint64_t v13 = 0;
  if (*((unsigned char *)this + 35)
    && (ZinMirSpatialSplitter::IsSubgraphLikelyToKernelStall((const ZinNELayer ***)this, a3) & 1) == 0)
  {
    goto LABEL_13;
  }
  uint64_t v8 = (uint64_t *)*((void *)a3 + 54);
  if (!v8) {
    goto LABEL_10;
  }
  while (!*((unsigned char *)v8 + 24))
  {
    uint64_t v8 = (uint64_t *)*v8;
    if (!v8) {
      goto LABEL_10;
    }
  }
  if (!*((unsigned char *)this + 35))
  {
LABEL_10:
    WorstKernelBoundLayer = (void **)ZinMirSpatialSplitter::FindWorstKernelBoundLayer((uint64_t)this, (uint64_t)a3);
    if (WorstKernelBoundLayer)
    {
      uint64_t v10 = *((void *)this + 22);
      double v21 = WorstKernelBoundLayer;
      std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::set[abi:ne180100]((uint64_t)&v14, (ZinIrOpLayer **)&v21, 1);
      (*(void (**)(uint64_t, ZinIrOpLayerGraph *, const SubgraphSplitInfo *, void ***, long long *))(*(void *)v10 + 8))(v10, a2, a3, &v14, &v12);
      goto LABEL_12;
    }
LABEL_13:
    Subgraph::Subgraph((Subgraph *)&v14, a3);
    *(void *)a4 = 0;
    *(void *)(a4 + 8) = 0;
    *(void *)(a4 + 16) = 0;
    double v21 = (void **)a4;
    char v22 = 0;
    double v11 = (char *)operator new(0x98uLL);
    *(void *)a4 = v11;
    *(void *)(a4 + 8) = v11;
    *(void *)(a4 + 16) = v11 + 152;
    *(void *)(a4 + 8) = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<Subgraph>,Subgraph const*,Subgraph const*,Subgraph*>(a4 + 16, (uint64_t)&v14, (uint64_t)&v21, (uint64_t)v11);
    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v20, v20[1]);
    double v21 = (void **)&v19;
    std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100](&v21);
    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v18, v18[1]);
    std::__list_imp<ZinIrSection *>::clear(v17);
    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v16, v16[1]);
    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v14, v15[0]);
    goto LABEL_14;
  }
  v15[0] = 0;
  v15[1] = 0;
  double v14 = (void **)v15;
  (*(void (**)(void, ZinIrOpLayerGraph *, const SubgraphSplitInfo *, void ***, long long *))(**((void **)this + 22) + 8))(*((void *)this + 22), a2, a3, &v14, &v12);
LABEL_12:
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v14, v15[0]);
  *(_OWORD *)a4 = v12;
  *(void *)(a4 + 16) = v13;
  uint64_t v13 = 0;
  long long v12 = 0uLL;
LABEL_14:
  double v14 = (void **)&v12;
  std::vector<Subgraph>::__destroy_vector::operator()[abi:ne180100](&v14);
}

void sub_211271FCC(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, char a11, uint64_t a12, uint64_t a13, uint64_t a14, void **a15, void *a16)
{
  a15 = (void **)&a11;
  std::vector<Subgraph>::__destroy_vector::operator()[abi:ne180100](&a15);
  _Unwind_Resume(a1);
}

void ZinMirSpatialSplitter::RefineSplitInfoByKernelOverhead(ZinMirSpatialSplitter *this@<X0>, ZinIrOpLayerGraph *a2@<X1>, const SubgraphSplitInfo *a3@<X2>, char **a4@<X8>)
{
  v27[0] = *MEMORY[0x263EF8340];
  if (*((unsigned char *)this + 29))
  {
    SubgraphSplitInfo::SubgraphSplitInfo((SubgraphSplitInfo *)v26, a3);
    *a4 = 0;
    a4[1] = 0;
    a4[2] = 0;
    char v22 = a4;
    LOBYTE(v23) = 0;
    unint64_t v5 = (char *)operator new(0x1C8uLL);
    *a4 = v5;
    a4[1] = v5;
    a4[2] = v5 + 456;
    a4[1] = (char *)std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<SubgraphSplitInfo>,SubgraphSplitInfo const*,SubgraphSplitInfo const*,SubgraphSplitInfo*>((uint64_t)(a4 + 2), (uint64_t)v26, (uint64_t)v27, (uint64_t)v5);
    SubgraphSplitInfo::~SubgraphSplitInfo((SubgraphSplitInfo *)v26);
  }
  else
  {
    char v22 = 0;
    uint64_t v23 = 0;
    uint64_t v24 = 0;
    SubgraphSplitInfo::SubgraphSplitInfo((SubgraphSplitInfo *)v26, a3);
    unint64_t v20 = 0;
    long long v21 = 0uLL;
    int v18 = (void ***)&v20;
    LOBYTE(v19) = 0;
    unint64_t v20 = (const SubgraphSplitInfo *)operator new(0x1C8uLL);
    *(void *)&long long v21 = v20;
    *((void *)&v21 + 1) = (char *)v20 + 456;
    *(void *)&long long v21 = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<SubgraphSplitInfo>,SubgraphSplitInfo const*,SubgraphSplitInfo const*,SubgraphSplitInfo*>((uint64_t)&v21 + 8, (uint64_t)v26, (uint64_t)v27, (uint64_t)v20);
    SubgraphSplitInfo::~SubgraphSplitInfo((SubgraphSplitInfo *)v26);
    *a4 = 0;
    a4[1] = 0;
    a4[2] = 0;
    uint64_t v8 = v20;
    uint64_t v9 = (const SubgraphSplitInfo *)v21;
    if (v20 != (const SubgraphSplitInfo *)v21)
    {
      do
      {
        char v10 = 0;
        do
        {
          SubgraphSplitInfo::SubgraphSplitInfo((SubgraphSplitInfo *)v26, v8);
          ZinMirSpatialSplitter::RefineSubgraphByKernelOverhead(this, a2, (const SubgraphSplitInfo *)v26, (uint64_t)&v18);
          unint64_t v11 = 0x86BCA1AF286BCA1BLL * ((v19 - (uint64_t)v18) >> 3);
          if (v11)
          {
            if (v11 == 1 && v26[11] == v18[11])
            {
              long long v12 = a4[1];
              if (v12 >= a4[2])
              {
                uint64_t v13 = std::vector<SubgraphSplitInfo>::__emplace_back_slow_path<SubgraphSplitInfo&>((uint64_t *)a4, (const SubgraphSplitInfo *)v26);
              }
              else
              {
                SubgraphSplitInfo::SubgraphSplitInfo((SubgraphSplitInfo *)a4[1], (const SubgraphSplitInfo *)v26);
                uint64_t v13 = (uint64_t)(v12 + 456);
                a4[1] = v12 + 456;
              }
              a4[1] = (char *)v13;
            }
            else
            {
              ZinMirSpatialSplitter::ConstructSplitInfoOfRefinedClusters(this, a2, (const Subgraph **)&v18, (uint64_t *)v17);
              double v14 = v17[0];
              BOOL v15 = v17[1];
              while (v14 != v15)
              {
                std::vector<SubgraphSplitInfo>::push_back[abi:ne180100]((uint64_t *)a4, (uint64_t)v14);
                v14 += 57;
              }
              uint64_t v25 = v17;
              std::vector<SubgraphSplitInfo>::__destroy_vector::operator()[abi:ne180100]((void ***)&v25);
              char v10 = 1;
            }
          }
          v17[0] = (void **)&v18;
          std::vector<Subgraph>::__destroy_vector::operator()[abi:ne180100](v17);
          SubgraphSplitInfo::~SubgraphSplitInfo((SubgraphSplitInfo *)v26);
          uint64_t v8 = (const SubgraphSplitInfo *)((char *)v8 + 456);
        }
        while (v8 != v9);
        if ((v10 & 1) == 0) {
          break;
        }
        std::vector<SubgraphSplitInfo>::__vdeallocate((void **)&v20);
        unint64_t v20 = (const SubgraphSplitInfo *)*a4;
        uint64_t v8 = v20;
        long long v21 = *(_OWORD *)(a4 + 1);
        double v16 = (const SubgraphSplitInfo *)v21;
        a4[1] = 0;
        a4[2] = 0;
        *a4 = 0;
        uint64_t v9 = v16;
      }
      while (v8 != v16);
    }
    v26[0] = (void **)&v20;
    std::vector<SubgraphSplitInfo>::__destroy_vector::operator()[abi:ne180100](v26);
    v26[0] = (void **)&v22;
    std::vector<SubgraphSplitInfo>::__destroy_vector::operator()[abi:ne180100](v26);
  }
}

void sub_2112722E8(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, void **a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, char a18, uint64_t a19, uint64_t a20,uint64_t a21,void **a22)
{
  a22 = (void **)&a18;
  std::vector<SubgraphSplitInfo>::__destroy_vector::operator()[abi:ne180100](&a22);
  _Unwind_Resume(a1);
}

BOOL ZinMirSpatialSplitter::IsWorthCompileTimeIncrease(uint64_t a1, void *a2, uint64_t a3)
{
  BOOL v3 = (void *)a2[37];
  double v4 = 0.0;
  double v5 = 0.0;
  if (v3 != a2 + 38)
  {
    do
    {
      uint64_t v6 = (void *)v3[1];
      uint64_t v7 = v3;
      if (v6)
      {
        do
        {
          uint64_t v8 = v6;
          uint64_t v6 = (void *)*v6;
        }
        while (v6);
      }
      else
      {
        do
        {
          uint64_t v8 = (void *)v7[2];
          BOOL v9 = *v8 == (void)v7;
          uint64_t v7 = v8;
        }
        while (!v9);
      }
      double v5 = v5 + *((double *)v3 + 5);
      BOOL v3 = v8;
    }
    while (v8 != a2 + 38);
  }
  char v10 = (void *)a2[40];
  if (v10 != a2 + 41)
  {
    double v4 = 0.0;
    do
    {
      unint64_t v11 = (void *)v10[1];
      long long v12 = v10;
      if (v11)
      {
        do
        {
          uint64_t v13 = v11;
          unint64_t v11 = (void *)*v11;
        }
        while (v11);
      }
      else
      {
        do
        {
          uint64_t v13 = (void *)v12[2];
          BOOL v9 = *v13 == (void)v12;
          long long v12 = v13;
        }
        while (!v9);
      }
      double v4 = v4 + *((double *)v10 + 5);
      char v10 = v13;
    }
    while (v13 != a2 + 41);
  }
  double v14 = (void *)a2[49];
  double v15 = 0.0;
  if (v14 != a2 + 50)
  {
    do
    {
      double v16 = (void *)v14[1];
      uint64_t v17 = v14;
      if (v16)
      {
        do
        {
          int v18 = v16;
          double v16 = (void *)*v16;
        }
        while (v16);
      }
      else
      {
        do
        {
          int v18 = (void *)v17[2];
          BOOL v9 = *v18 == (void)v17;
          uint64_t v17 = v18;
        }
        while (!v9);
      }
      double v15 = v15 + *((double *)v14 + 5);
      double v14 = v18;
    }
    while (v18 != a2 + 50);
  }
  return (v5 - (v4 + v15)) / v5 >= *(double *)(a1 + 64)
      || a2[32] * a2[11] * a2[33] <= (unint64_t)(*(void *)(a1 + 72) * a3);
}

uint64_t ZinMirSpatialSplitter::TileWithGlobalRefinement(uint64_t a1, uint64_t a2, ZinEngineLayerMirInfo *a3, char a4)
{
  v65[4] = *MEMORY[0x263EF8340];
  char v53 = a4;
  v52[0] = 0;
  v52[1] = 0;
  uint64_t v50 = 0;
  long long v51 = v52;
  uint64_t v7 = *(void **)(a1 + 8);
  v65[0] = &unk_26C32F388;
  v65[1] = &v50;
  v65[3] = v65;
  int v8 = ZinIrControlFlowGraph::TraverseForward(v7, (uint64_t)v65);
  std::__function::__value_func<ZinIrStatus ()(ZinIrBasicBlock *)>::~__value_func[abi:ne180100](v65);
  if (!v8)
  {
    BOOL v9 = *(void **)(a1 + 8);
    uint64_t v64 = 0;
    char v10 = operator new(0x20uLL);
    *char v10 = &unk_26C32F3E0;
    v10[1] = &v51;
    v10[2] = a1;
    v10[3] = &v50;
    uint64_t v64 = v10;
    LODWORD(v9) = ZinIrControlFlowGraph::TraverseForward(v9, (uint64_t)v63);
    std::__function::__value_func<ZinIrStatus ()(ZinIrBasicBlock *)>::~__value_func[abi:ne180100](v63);
    if (!v9)
    {
      v49[0] = 0;
      v49[1] = 0;
      int64x2_t v48 = v49;
      if (!*(void *)(a1 + 184)) {
        goto LABEL_34;
      }
      if (!*(void *)(a1 + 192)) {
        ZinAssertImpl("Spatial Split Internal Error");
      }
      uint64_t v13 = *(void **)(a1 + 8);
      char v62 = 0;
      double v14 = operator new(0x20uLL);
      *double v14 = &unk_26C32F438;
      v14[1] = &v51;
      v14[2] = a1;
      void v14[3] = &v48;
      char v62 = v14;
      LODWORD(v13) = ZinIrControlFlowGraph::TraverseForward(v13, (uint64_t)v61);
      std::__function::__value_func<ZinIrStatus ()(ZinIrBasicBlock *)>::~__value_func[abi:ne180100](v61);
      if (!v13)
      {
LABEL_34:
        ZinMirSpatialSplitUtils::PostprocessForPressureBasedSubgraphIdentification(a3);
        uint64_t v47 = 0;
        double v15 = *(void **)(a1 + 8);
        uint64_t v60 = 0;
        double v16 = operator new(0x30uLL);
        *double v16 = &unk_26C322E30;
        v16[1] = &v51;
        void v16[2] = a1;
        v16[3] = a2;
        v16[4] = &v47;
        v16[5] = &v53;
        uint64_t v60 = v16;
        int v17 = ZinIrControlFlowGraph::TraverseForward(v15, (uint64_t)v59);
        std::__function::__value_func<ZinIrStatus ()(ZinIrBasicBlock *)>::~__value_func[abi:ne180100](v59);
        if (!v17)
        {
          if (!*(void *)(a1 + 184)) {
            goto LABEL_35;
          }
          int v18 = *(ZinMirGraphSplitterBase **)(a1 + 192);
          if (!v18) {
            goto LABEL_35;
          }
          if (!ZinMirGraphSplitterBase::SetNextTileId(v18))
          {
            if (!*(void *)(a1 + 192)) {
              ZinAssertImpl("Spatial Split Internal Error");
            }
            uint64_t v19 = *(void **)(a1 + 8);
            int v58 = 0;
            unint64_t v20 = operator new(0x20uLL);
            void *v20 = &unk_26C322E88;
            v20[1] = a1;
            v20[2] = &v48;
            v20[3] = &v47;
            int v58 = v20;
            LODWORD(v19) = ZinIrControlFlowGraph::TraverseForward(v19, (uint64_t)v57);
            std::__function::__value_func<ZinIrStatus ()(ZinIrBasicBlock *)>::~__value_func[abi:ne180100](v57);
            if (!v19)
            {
LABEL_35:
              long long v21 = *(void **)(a1 + 8);
              v56[0] = &unk_26C380F58;
              v56[1] = ZinViewLayerUtils::CascadeMultiDimensionalViews;
              v56[3] = v56;
              int v22 = ZinIrControlFlowGraph::TraverseForward(v21, (uint64_t)v56, 1);
              std::__function::__value_func<ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::~__value_func[abi:ne180100](v56);
              if (!v22)
              {
                uint64_t v23 = *(void **)(a1 + 8);
                v55[0] = &unk_26C380F58;
                v55[1] = ZinMirSpatialSplitUtils::UpdateMirInfoForSSM;
                v55[3] = v55;
                int v24 = ZinIrControlFlowGraph::TraverseForward(v23, (uint64_t)v55, 1);
                std::__function::__value_func<ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::~__value_func[abi:ne180100](v55);
                if (!v24)
                {
                  char v46 = 0;
                  if (!MirOpt::CSE(*(MirOpt **)(a1 + 8), **(ZinIrControlFlowGraph ***)(a1 + 16), (const ZinIrHalParameters *)&v46, v25))
                  {
                    MirOpt::MergeConvolutions(*(void **)(a1 + 8), *(void **)(a1 + 16), 1);
                    if (v26)
                    {
                      MirOpt::MergeFanoutConvolutions(*(void **)(a1 + 8), *(void *)(a1 + 16));
                      if (v27)
                      {
                        if (*(unsigned char *)(a1 + 35))
                        {
                          uint64_t v28 = *(void **)(a1 + 8);
                          v54[0] = &unk_26C380F58;
                          v54[1] = ZinMirSpatialSplitUtils::MoveChannelConcatFromOuterToInnerMost;
                          v54[3] = v54;
                          int v29 = ZinIrControlFlowGraph::TraverseForward(v28, (uint64_t)v54, 1);
                          std::__function::__value_func<ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::~__value_func[abi:ne180100](v54);
                          if (v29) {
                            uint64_t v11 = 3;
                          }
                          else {
                            uint64_t v11 = 0;
                          }
                        }
                        else
                        {
                          uint64_t v11 = 0;
                        }
                        goto LABEL_10;
                      }
                      BOOL v38 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
                      if (v38) {
                        ZinMirSpatialSplitter::TileWithGlobalRefinement(v38, v39, v40, v41, v42, v43, v44, v45);
                      }
                    }
                    else
                    {
                      BOOL v30 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
                      if (v30) {
                        ZinMirSpatialSplitter::TileWithGlobalRefinement(v30, v31, v32, v33, v34, v35, v36, v37);
                      }
                    }
                  }
                }
              }
            }
          }
        }
      }
      uint64_t v11 = 3;
LABEL_10:
      std::__tree<std::__value_type<ZinIrBasicBlock *,std::vector<std::pair<Subgraph,SplitInfo>>>,std::__map_value_compare<ZinIrBasicBlock *,std::__value_type<ZinIrBasicBlock *,std::vector<std::pair<Subgraph,SplitInfo>>>,std::less<ZinIrBasicBlock *>,true>,std::allocator<std::__value_type<ZinIrBasicBlock *,std::vector<std::pair<Subgraph,SplitInfo>>>>>::destroy((uint64_t)&v48, v49[0]);
      goto LABEL_4;
    }
  }
  uint64_t v11 = 3;
LABEL_4:
  std::__tree<std::__value_type<ZinIrBasicBlock *,std::vector<SubgraphSplitInfo>>,std::__map_value_compare<ZinIrBasicBlock *,std::__value_type<ZinIrBasicBlock *,std::vector<SubgraphSplitInfo>>,std::less<ZinIrBasicBlock *>,true>,std::allocator<std::__value_type<ZinIrBasicBlock *,std::vector<SubgraphSplitInfo>>>>::destroy((uint64_t)&v51, v52[0]);
  return v11;
}

void sub_21127296C(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, ...)
{
  va_start(va2, a4);
  va_start(va1, a4);
  va_start(va, a4);
  uint64_t v5 = va_arg(va1, void);
  uint64_t v7 = va_arg(va1, char *);
  uint64_t v8 = va_arg(va1, void);
  uint64_t v9 = va_arg(va1, void);
  va_copy(va2, va1);
  uint64_t v10 = va_arg(va2, void);
  long long v12 = va_arg(va2, char *);
  uint64_t v13 = va_arg(va2, void);
  uint64_t v14 = va_arg(va2, void);
  std::__function::__value_func<ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::~__value_func[abi:ne180100](va2);
  std::__tree<std::__value_type<ZinIrBasicBlock *,std::vector<std::pair<Subgraph,SplitInfo>>>,std::__map_value_compare<ZinIrBasicBlock *,std::__value_type<ZinIrBasicBlock *,std::vector<std::pair<Subgraph,SplitInfo>>>,std::less<ZinIrBasicBlock *>,true>,std::allocator<std::__value_type<ZinIrBasicBlock *,std::vector<std::pair<Subgraph,SplitInfo>>>>>::destroy((uint64_t)va, v7);
  std::__tree<std::__value_type<ZinIrBasicBlock *,std::vector<SubgraphSplitInfo>>,std::__map_value_compare<ZinIrBasicBlock *,std::__value_type<ZinIrBasicBlock *,std::vector<SubgraphSplitInfo>>,std::less<ZinIrBasicBlock *>,true>,std::allocator<std::__value_type<ZinIrBasicBlock *,std::vector<SubgraphSplitInfo>>>>::destroy((uint64_t)va1, v12);
  _Unwind_Resume(a1);
}

uint64_t ZinMirSpatialSplitter::Tile(uint64_t a1, uint64_t *a2, ZinEngineLayerMirInfo *a3, char a4)
{
  uint64_t v33 = *MEMORY[0x263EF8340];
  char v25 = a4;
  if (*(unsigned char *)(a1 + 32))
  {
    uint64_t v7 = (std::__shared_weak_count *)a2[1];
    uint64_t v23 = *a2;
    int v24 = v7;
    if (v7) {
      atomic_fetch_add_explicit(&v7->__shared_owners_, 1uLL, memory_order_relaxed);
    }
    uint64_t v8 = ZinMirSpatialSplitter::TileWithGlobalRefinement(a1, (uint64_t)&v23, a3, a4);
    if (v24) {
      std::__shared_weak_count::__release_shared[abi:ne180100](v24);
    }
  }
  else
  {
    v22[0] = 0;
    v22[1] = 0;
    long long v21 = v22;
    uint64_t v9 = *(void **)(a1 + 8);
    uint64_t v32 = 0;
    uint64_t v10 = operator new(0x20uLL);
    *uint64_t v10 = &unk_26C32F540;
    v10[1] = &v21;
    v10[2] = a1;
    v10[3] = a2;
    uint64_t v32 = v10;
    int v11 = ZinIrControlFlowGraph::TraverseForward(v9, (uint64_t)v31);
    std::__function::__value_func<ZinIrStatus ()(ZinIrBasicBlock *)>::~__value_func[abi:ne180100](v31);
    if (v11) {
      goto LABEL_10;
    }
    ZinMirSpatialSplitUtils::PostprocessForPressureBasedSubgraphIdentification(a3);
    long long v12 = *(void **)(a1 + 8);
    BOOL v30 = 0;
    uint64_t v13 = operator new(0x20uLL);
    *uint64_t v13 = &unk_26C32F598;
    v13[1] = &v21;
    void v13[2] = a1;
    v13[3] = &v25;
    BOOL v30 = v13;
    LODWORD(v12) = ZinIrControlFlowGraph::TraverseForward(v12, (uint64_t)v29);
    std::__function::__value_func<ZinIrStatus ()(ZinIrBasicBlock *)>::~__value_func[abi:ne180100](v29);
    if (v12) {
      goto LABEL_10;
    }
    uint64_t v14 = *(void **)(a1 + 8);
    v28[0] = &unk_26C380F58;
    v28[1] = ZinViewLayerUtils::CascadeMultiDimensionalViews;
    v28[3] = v28;
    int v15 = ZinIrControlFlowGraph::TraverseForward(v14, (uint64_t)v28, 1);
    std::__function::__value_func<ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::~__value_func[abi:ne180100](v28);
    if (v15
      || (double v16 = *(void **)(a1 + 8),
          v27[0] = &unk_26C380F58,
          v27[1] = ZinMirSpatialSplitUtils::UpdateMirInfoForSSM,
          _OWORD v27[3] = v27,
          int v17 = ZinIrControlFlowGraph::TraverseForward(v16, (uint64_t)v27, 1),
          std::__function::__value_func<ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::~__value_func[abi:ne180100](v27),
          v17))
    {
LABEL_10:
      uint64_t v8 = 3;
    }
    else if (*(unsigned char *)(a1 + 35))
    {
      uint64_t v19 = *(void **)(a1 + 8);
      v26[0] = &unk_26C380F58;
      v26[1] = ZinMirSpatialSplitUtils::MoveChannelConcatFromOuterToInnerMost;
      v26[3] = v26;
      int v20 = ZinIrControlFlowGraph::TraverseForward(v19, (uint64_t)v26, 1);
      std::__function::__value_func<ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::~__value_func[abi:ne180100](v26);
      if (v20) {
        uint64_t v8 = 3;
      }
      else {
        uint64_t v8 = 0;
      }
    }
    else
    {
      uint64_t v8 = 0;
    }
    std::__tree<std::__value_type<ZinIrBasicBlock *,std::vector<std::pair<Subgraph,SplitInfo>>>,std::__map_value_compare<ZinIrBasicBlock *,std::__value_type<ZinIrBasicBlock *,std::vector<std::pair<Subgraph,SplitInfo>>>,std::less<ZinIrBasicBlock *>,true>,std::allocator<std::__value_type<ZinIrBasicBlock *,std::vector<std::pair<Subgraph,SplitInfo>>>>>::destroy((uint64_t)&v21, v22[0]);
  }
  return v8;
}

void sub_211272CC0(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va1, a2);
  va_start(va, a2);
  uint64_t v3 = va_arg(va1, void);
  uint64_t v5 = va_arg(va1, char *);
  uint64_t v6 = va_arg(va1, void);
  uint64_t v7 = va_arg(va1, void);
  uint64_t v8 = va_arg(va1, void);
  uint64_t v9 = va_arg(va1, void);
  std::__function::__value_func<ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::~__value_func[abi:ne180100](va1);
  std::__tree<std::__value_type<ZinIrBasicBlock *,std::vector<std::pair<Subgraph,SplitInfo>>>,std::__map_value_compare<ZinIrBasicBlock *,std::__value_type<ZinIrBasicBlock *,std::vector<std::pair<Subgraph,SplitInfo>>>,std::less<ZinIrBasicBlock *>,true>,std::allocator<std::__value_type<ZinIrBasicBlock *,std::vector<std::pair<Subgraph,SplitInfo>>>>>::destroy((uint64_t)va, v5);
  _Unwind_Resume(a1);
}

void ZinMirSpatialSplitter::AdjustTiledRegionsForConcats(ZinMirSpatialSplitter *this, const Subgraph *a2, SplitInfo *a3)
{
  double v4 = (char *)a2 + 72;
  uint64_t v3 = (char *)*((void *)a2 + 9);
  uint64_t v98 = (char *)a2 + 80;
  if (v3 != (char *)a2 + 80)
  {
    uint64_t v5 = a3;
    uint64_t v6 = a2;
    int v7 = (int)this;
    uint64_t v8 = (char *)a2 + 48;
    int v90 = (int)this;
    uint64_t v93 = (char *)a2 + 72;
    while (1)
    {
      char v89 = v3;
      uint64_t v9 = (Subgraph *)*((void *)v3 + 4);
      if (*(_DWORD *)(*((void *)v9 + 8) + 8) == 7)
      {
        uint64_t v10 = *((void *)v6 + 7);
        if ((char *)v10 == v8) {
          goto LABEL_143;
        }
        uint64_t v11 = *((void *)v6 + 7);
        while (*(Subgraph **)(v11 + 16) != v9)
        {
          uint64_t v11 = *(void *)(v11 + 8);
          if ((char *)v11 == v8) {
            goto LABEL_143;
          }
        }
        if ((char *)v11 == v8) {
LABEL_143:
        }
          ZinAssertImpl("Subgraph in set has not been tiled", v3);
        if (v10 == v11)
        {
          unint64_t v12 = 0;
        }
        else
        {
          unint64_t v12 = 0;
          do
          {
            ++v12;
            uint64_t v10 = *(void *)(v10 + 8);
          }
          while (v10 != v11);
        }
        unint64_t v95 = v12;
        uint64_t v14 = *(void *)v5;
        uint64_t v13 = *((void *)v5 + 1);
        if (v13 != *(void *)v5) {
          break;
        }
      }
LABEL_130:
      int64x2_t v85 = v89;
      std::string::size_type v86 = (char *)*((void *)v89 + 1);
      if (v86)
      {
        do
        {
          double v87 = v86;
          std::string::size_type v86 = *(char **)v86;
        }
        while (v86);
      }
      else
      {
        do
        {
          double v87 = (char *)*((void *)v85 + 2);
          BOOL v88 = *(void *)v87 == (void)v85;
          int64x2_t v85 = v87;
        }
        while (!v88);
      }
      uint64_t v3 = v87;
      if (v87 == v98) {
        return;
      }
    }
    unint64_t v15 = 0;
    while (1)
    {
      unint64_t v99 = v15;
      double v16 = (void *)(v14 + 24 * v15);
      if (0x34F72C234F72C235 * ((uint64_t)(v16[1] - *v16) >> 3) <= v95) {
        std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
      }
      uint64_t v17 = *v16 + 232 * v95;
      if (!*(unsigned char *)(v17 + 224)) {
        goto LABEL_129;
      }
      v120 = 0;
      uint64_t v121 = 0;
      uint64_t v122 = 0;
      uint64_t v94 = (_OWORD *)v17;
      std::vector<WorkUnit>::__init_with_size[abi:ne180100]<WorkUnit*,WorkUnit*>(&v120, *(const void **)(v17 + 128), *(void *)(v17 + 136), 0xCCCCCCCCCCCCCCCDLL * ((uint64_t)(*(void *)(v17 + 136) - *(void *)(v17 + 128)) >> 4));
      LOBYTE(v123) = 0;
      std::vector<BOOL>::vector(&v118, 0xCCCCCCCCCCCCCCCDLL * (((char *)v121 - (unsigned char *)v120) >> 4), (unsigned __int8 *)&v123);
      unint64_t v18 = v119;
      uint64_t v20 = *((void *)v9 + 11);
      uint64_t v19 = *((void *)v9 + 12);
      if (v119 != (v19 - v20) >> 3) {
        ZinAssertImpl("Internal Spatial Splitting Error", v89);
      }
      if (v19 == v20)
      {
        uint64_t v29 = *((void *)v9 + 12);
      }
      else
      {
        unint64_t v21 = 0;
        uint64_t v19 = *((void *)v9 + 11);
        do
        {
          *(void *)&v116[0] = 0;
          *(void *)&v116[0] = *(void *)(v19 + 8 * v21);
          if (v98 == (char *)std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>((uint64_t)v4, (ZinIrOpLayer **)v116))
          {
            *(void *)((char *)v118 + ((v21 >> 3) & 0x1FFFFFFFFFFFFFF8)) &= ~(1 << v21);
          }
          else
          {
            uint64_t v22 = *((void *)v6 + 7);
            if ((char *)v22 == v8) {
              goto LABEL_137;
            }
            uint64_t v23 = *((void *)v6 + 7);
            while (*(void *)(v23 + 16) != *(void *)&v116[0])
            {
              uint64_t v23 = *(void *)(v23 + 8);
              if ((char *)v23 == v8) {
                goto LABEL_137;
              }
            }
            if ((char *)v23 == v8) {
LABEL_137:
            }
              ZinAssertImpl("Internal Spatial Split Error", v89);
            if (v22 == v23)
            {
              unint64_t v24 = 0;
            }
            else
            {
              unint64_t v24 = 0;
              do
              {
                ++v24;
                uint64_t v22 = *(void *)(v22 + 8);
              }
              while (v22 != v23);
            }
            uint64_t v25 = *(void *)v5;
            if (0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*((void *)v5 + 1) - *(void *)v5) >> 3) <= v99) {
              std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
            }
            unint64_t v100 = 0;
            uint64_t v101 = 0;
            uint64_t v102 = 0;
            std::vector<std::optional<TiledLayerTensorRegions>>::__init_with_size[abi:ne180100]<std::optional<TiledLayerTensorRegions>*,std::optional<TiledLayerTensorRegions>*>(&v100, *(void *)(v25 + 24 * v99), *(void *)(v25 + 24 * v99 + 8), 0x34F72C234F72C235 * ((uint64_t)(*(void *)(v25 + 24 * v99 + 8) - *(void *)(v25 + 24 * v99)) >> 3));
            if (0x34F72C234F72C235 * ((v101 - v100) >> 3) <= v24) {
              std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
            }
            std::__optional_copy_base<TiledLayerTensorRegions,false>::__optional_copy_base[abi:ne180100]((TiledLayerTensorRegions *)&v123, (const TiledLayerTensorRegions *)&v100[232 * v24]);
            unint64_t v26 = v21 >> 6;
            uint64_t v27 = 1 << v21;
            if (v126) {
              uint64_t v28 = *((void *)v118 + v26) & ~v27;
            }
            else {
              uint64_t v28 = *((void *)v118 + v26) | v27;
            }
            *((void *)v118 + v26) = v28;
            std::__optional_destruct_base<TiledLayerTensorRegions,false>::~__optional_destruct_base[abi:ne180100]((uint64_t)&v123);
            *(void *)&long long v123 = &v100;
            std::vector<std::optional<TiledLayerTensorRegions>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v123);
          }
          ++v21;
          uint64_t v19 = *((void *)v9 + 11);
          uint64_t v29 = *((void *)v9 + 12);
        }
        while (v21 < (v29 - v19) >> 3);
        unint64_t v18 = v119;
      }
      BOOL v30 = (char *)v118;
      int v31 = v18 & 0x3F;
      if (v18 > 0x3F || (v18 & 0x3F) != 0) {
        break;
      }
LABEL_53:
      if (v29 != v19)
      {
        unint64_t v34 = 0;
        int v35 = 0;
        do
          v35 |= ZinMirSpatialSplitter::ShouldConcatBeTrimmed(v7, v9, v6, v5, v99, v34++, &v120);
        while (v34 < (uint64_t)(*((void *)v9 + 12) - *((void *)v9 + 11)) >> 3);
        double v4 = v93;
        if (v35) {
          goto LABEL_57;
        }
      }
LABEL_124:
      if (v118) {
        operator delete(v118);
      }
      if (v120)
      {
        uint64_t v121 = (long long *)v120;
        operator delete(v120);
      }
      uint64_t v14 = *(void *)v5;
      uint64_t v13 = *((void *)v5 + 1);
LABEL_129:
      unint64_t v15 = v99 + 1;
      if (v99 + 1 >= 0xAAAAAAAAAAAAAAABLL * ((v13 - v14) >> 3)) {
        goto LABEL_130;
      }
    }
    int v32 = 0;
    uint64_t v33 = (char *)v118 + 8 * (v18 >> 6);
    while (((*(void *)v30 >> v32) & 1) == 0)
    {
      v30 += 8 * (v32 == 63);
      if (v32 == 63) {
        int v32 = 0;
      }
      else {
        ++v32;
      }
      if (v32 == v31 && v30 == v33) {
        goto LABEL_53;
      }
    }
LABEL_57:
    v116[0] = *v94;
    long long v36 = v94[1];
    long long v37 = v94[2];
    long long v38 = v94[4];
    v117[1] = v94[3];
    v117[2] = v38;
    v116[1] = v36;
    v117[0] = v37;
    SplitInfo::GetSplitDimensions(v5, &v100);
    uint64_t v39 = (int *)v100;
    uint64_t v96 = (int *)v101;
    if (v100 != v101)
    {
      do
      {
        int v40 = *v39;
        uint64_t v42 = (long long *)v120;
        uint64_t v41 = v121;
        if (v120 == v121)
        {
          uint64_t v44 = 0x7FFFFFFFFFFFFFFFLL;
          uint64_t v43 = -1;
        }
        else
        {
          uint64_t v43 = -1;
          uint64_t v44 = 0x7FFFFFFFFFFFFFFFLL;
          do
          {
            long long v123 = *v42;
            long long v45 = v42[1];
            long long v46 = v42[2];
            long long v47 = v42[4];
            v125[1] = v42[3];
            v125[2] = v47;
            long long v124 = v45;
            v125[0] = v46;
            uint64_t ValueAt = GetValueAtDimension<ZinTensorPosition>((uint64_t *)&v123, v40);
            if (v44 >= ValueAt) {
              uint64_t v44 = ValueAt;
            }
            uint64_t v49 = GetValueAtDimension<ZinTensorPosition>((uint64_t *)&v123, v40);
            uint64_t v50 = GetValueAtDimension<ZinTensorDimensions>((uint64_t *)v125 + 1, v40);
            if (v50 + v49 > v43) {
              uint64_t v43 = v50 + v49;
            }
            v42 += 5;
          }
          while (v42 != v41);
        }
        if (SetValueAtDimension<ZinTensorPosition>(v116, v40, v44)
          || SetValueAtDimension<ZinTensorDimensions>((void *)v117 + 1, v40, v43 - v44))
        {
          ZinAssertImpl("Spatial Split Internal Error", v89);
        }
        ++v39;
      }
      while (v39 != v96);
      uint64_t v39 = (int *)v100;
    }
    if (v39)
    {
      uint64_t v101 = (char *)v39;
      operator delete(v39);
    }
    long long __p = 0;
    char v114 = 0;
    uint64_t v115 = 0;
    unint64_t v110 = 0;
    long long v111 = 0;
    uint64_t v112 = 0;
    uint64_t v52 = (long long *)v120;
    long long v51 = v121;
    uint64_t v97 = v121;
    while (v52 != v51)
    {
      long long v123 = *v52;
      long long v124 = v52[1];
      uint64_t v53 = *((void *)v52 + 5);
      *(void *)&v125[0] = *((void *)v52 + 4);
      uint64_t v55 = *((void *)v52 + 6);
      uint64_t v54 = *((void *)v52 + 7);
      uint64_t v57 = *((void *)v52 + 8);
      uint64_t v56 = *((void *)v52 + 9);
      int v58 = v114;
      if (v114 >= v115)
      {
        char v62 = __p;
        unint64_t v63 = 0xCCCCCCCCCCCCCCCDLL * ((v114 - (unsigned char *)__p) >> 3);
        unint64_t v64 = v63 + 1;
        if (v63 + 1 > 0x666666666666666) {
          std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
        }
        if (0x999999999999999ALL * ((v115 - (unsigned char *)__p) >> 3) > v64) {
          unint64_t v64 = 0x999999999999999ALL * ((v115 - (unsigned char *)__p) >> 3);
        }
        if (0xCCCCCCCCCCCCCCCDLL * ((v115 - (unsigned char *)__p) >> 3) >= 0x333333333333333) {
          unint64_t v65 = 0x666666666666666;
        }
        else {
          unint64_t v65 = v64;
        }
        if (v65)
        {
          char v66 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ZinMirInterchangeInfo>>((uint64_t)&v115, v65);
          char v62 = __p;
          int v58 = v114;
        }
        else
        {
          char v66 = 0;
        }
        uint64_t v67 = &v66[40 * v63];
        *(_OWORD *)uint64_t v67 = v123;
        *((_OWORD *)v67 + 1) = v124;
        *((void *)v67 + 4) = *(void *)&v125[0];
        if (v58 == v62)
        {
          uint64_t v71 = &v66[40 * v63];
        }
        else
        {
          long long v68 = &v66[40 * v63];
          do
          {
            long long v69 = *(_OWORD *)((char *)v58 - 40);
            long long v70 = *(_OWORD *)((char *)v58 - 24);
            uint64_t v71 = v68 - 40;
            *((void *)v68 - 1) = *((void *)v58 - 1);
            *(_OWORD *)(v68 - 24) = v70;
            *(_OWORD *)(v68 - 40) = v69;
            int v58 = (_OWORD *)((char *)v58 - 40);
            v68 -= 40;
          }
          while (v58 != v62);
        }
        uint64_t v61 = v67 + 40;
        long long __p = v71;
        char v114 = v67 + 40;
        uint64_t v115 = &v66[40 * v65];
        if (v62) {
          operator delete(v62);
        }
      }
      else
      {
        long long v59 = *v52;
        long long v60 = v52[1];
        *((void *)v114 + 4) = *((void *)v52 + 4);
        *int v58 = v59;
        v58[1] = v60;
        uint64_t v61 = (char *)v58 + 40;
      }
      char v114 = v61;
      uint64_t v72 = v111;
      if (v111 >= v112)
      {
        char v74 = (char *)v110;
        unint64_t v75 = 0x8E38E38E38E38E39 * ((v111 - (unsigned char *)v110) >> 3);
        unint64_t v76 = v75 + 1;
        if (v75 + 1 > 0x38E38E38E38E38ELL) {
          std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
        }
        if (0x1C71C71C71C71C72 * ((v112 - (unsigned char *)v110) >> 3) > v76) {
          unint64_t v76 = 0x1C71C71C71C71C72 * ((v112 - (unsigned char *)v110) >> 3);
        }
        if (0x8E38E38E38E38E39 * ((v112 - (unsigned char *)v110) >> 3) >= 0x1C71C71C71C71C7) {
          unint64_t v77 = 0x38E38E38E38E38ELL;
        }
        else {
          unint64_t v77 = v76;
        }
        if (v77)
        {
          int v78 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ANEDebugInfo::DebugInfoInMem::TD>>((uint64_t)&v112, v77);
          char v74 = (char *)v110;
          uint64_t v72 = v111;
        }
        else
        {
          int v78 = 0;
        }
        uint64_t v79 = &v78[72 * v75];
        *(void *)uint64_t v79 = v53;
        *((void *)v79 + 1) = v55;
        *((void *)v79 + 2) = v54;
        *((void *)v79 + 3) = v57;
        *((void *)v79 + 4) = v56;
        *(_OWORD *)(v79 + 40) = 0u;
        *(_OWORD *)(v79 + 56) = 0u;
        if (v72 == v74)
        {
          uint64_t v84 = &v78[72 * v75];
        }
        else
        {
          uint64_t v80 = &v78[72 * v75];
          do
          {
            *(_OWORD *)(v80 - 72) = *(_OWORD *)(v72 - 72);
            long long v81 = *(_OWORD *)(v72 - 56);
            long long v82 = *(_OWORD *)(v72 - 40);
            long long v83 = *(_OWORD *)(v72 - 24);
            uint64_t v84 = v80 - 72;
            *((void *)v80 - 1) = *((void *)v72 - 1);
            *(_OWORD *)(v80 - 24) = v83;
            *(_OWORD *)(v80 - 40) = v82;
            *(_OWORD *)(v80 - 56) = v81;
            v72 -= 72;
            v80 -= 72;
          }
          while (v72 != v74);
        }
        char v73 = v79 + 72;
        unint64_t v110 = v84;
        long long v111 = v79 + 72;
        uint64_t v112 = &v78[72 * v77];
        if (v74) {
          operator delete(v74);
        }
      }
      else
      {
        *(void *)long long v111 = v53;
        *((void *)v72 + 1) = v55;
        *((void *)v72 + 2) = v54;
        *((void *)v72 + 3) = v57;
        *((void *)v72 + 4) = v56;
        char v73 = v72 + 72;
        *(_OWORD *)(v72 + 40) = 0u;
        *(_OWORD *)(v72 + 56) = 0u;
      }
      long long v111 = v73;
      v52 += 5;
      long long v51 = v97;
    }
    TiledLayerTensorRegions::TiledLayerTensorRegions((uint64_t)&v100, (_OWORD *)((char *)v94 + 152), v116, (uint64_t)&__p, (uint64_t)&v110, (uint64_t)&v120, 0, 0);
    std::vector<BOOL>::operator=(&v109, (uint64_t)&v118);
    uint64_t v6 = a2;
    uint64_t v5 = a3;
    int v7 = v90;
    double v4 = v93;
    TiledLayerTensorRegions::TiledLayerTensorRegions((TiledLayerTensorRegions *)&v123, (const TiledLayerTensorRegions *)&v100);
    char v126 = 1;
    SplitInfo::AddTiledLayerTensorRegions((uint64_t)a3, (uint64_t)v9, v99, (TiledLayerTensorRegions *)&v123);
    std::__optional_destruct_base<TiledLayerTensorRegions,false>::~__optional_destruct_base[abi:ne180100]((uint64_t)&v123);
    TiledLayerTensorRegions::TiledLayerTensorRegions((TiledLayerTensorRegions *)&v123, (const TiledLayerTensorRegions *)&v100);
    char v126 = 1;
    SplitInfo::ReplaceTiledLayerOnBranch(a3, v99, v95, (TiledLayerTensorRegions *)&v123);
    std::__optional_destruct_base<TiledLayerTensorRegions,false>::~__optional_destruct_base[abi:ne180100]((uint64_t)&v123);
    if (v109) {
      operator delete(v109);
    }
    if (v107)
    {
      std::string v108 = v107;
      operator delete(v107);
    }
    if (v105)
    {
      int64_t v106 = v105;
      operator delete(v105);
    }
    if (v103)
    {
      std::string v104 = v103;
      operator delete(v103);
    }
    if (v110)
    {
      long long v111 = (char *)v110;
      operator delete(v110);
    }
    if (__p)
    {
      char v114 = (char *)__p;
      operator delete(__p);
    }
    goto LABEL_124;
  }
}

void sub_2112736FC(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33,uint64_t a34,uint64_t a35,uint64_t a36,uint64_t a37,uint64_t a38,uint64_t a39,uint64_t a40,uint64_t a41,uint64_t a42,uint64_t a43,uint64_t a44,uint64_t a45,uint64_t a46,uint64_t a47,uint64_t a48,uint64_t a49,uint64_t a50,void *__p,uint64_t a52,uint64_t a53,void *a54,uint64_t a55,uint64_t a56,uint64_t a57,uint64_t a58,uint64_t a59,uint64_t a60,uint64_t a61,uint64_t a62,uint64_t a63)
{
  std::__optional_destruct_base<TiledLayerTensorRegions,false>::~__optional_destruct_base[abi:ne180100]((uint64_t)&STACK[0x200]);
  TiledLayerTensorRegions::~TiledLayerTensorRegions((TiledLayerTensorRegions *)&a23);
  if (__p)
  {
    a52 = (uint64_t)__p;
    operator delete(__p);
  }
  if (a54)
  {
    a55 = (uint64_t)a54;
    operator delete(a54);
  }
  if (a67) {
    operator delete(a67);
  }
  if (a70)
  {
    a71 = (uint64_t)a70;
    operator delete(a70);
  }
  _Unwind_Resume(a1);
}

uint64_t ZinMirSpatialSplitter::ShouldConcatBeTrimmed(int a1, Subgraph *a2, ZinMirSpatialSplitUtils *this, SplitInfo *a4, unint64_t a5, unint64_t a6, void *a7)
{
  uint64_t v8 = *(void *)a4;
  if (0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*((void *)a4 + 1) - *(void *)a4) >> 3) <= a5) {
    std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
  }
  uint64_t v10 = (char *)this + 48;
  uint64_t v11 = (void *)*((void *)this + 7);
  if (v11 == (void *)((char *)this + 48)) {
    return 0;
  }
  uint64_t v14 = (void *)(v8 + 24 * a5);
  uint64_t v15 = *((void *)this + 7);
  while (*(Subgraph **)(v15 + 16) != a2)
  {
    uint64_t v15 = *(void *)(v15 + 8);
    if ((char *)v15 == v10) {
      return 0;
    }
  }
  if ((char *)v15 == v10) {
    return 0;
  }
  if (v11 == (void *)v15)
  {
    unint64_t v16 = 0;
  }
  else
  {
    unint64_t v16 = 0;
    do
    {
      ++v16;
      uint64_t v11 = (void *)v11[1];
    }
    while (v11 != (void *)v15);
  }
  uint64_t v17 = v8 + 24 * a5;
  uint64_t v19 = *(void *)(v17 + 8);
  unint64_t v18 = (void *)(v17 + 8);
  if (0x34F72C234F72C235 * ((v19 - *v14) >> 3) <= v16) {
    std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
  }
  uint64_t v85 = *v14 + 232 * v16;
  if (!*(unsigned char *)(v85 + 224)) {
    std::__throw_bad_optional_access[abi:ne180100]();
  }
  if (ZinMirSpatialSplitUtils::IsRootOutputOrOutsideSubgraph(this, a2, this)) {
    return 0;
  }
  uint64_t v97 = a2;
  double v87 = 0;
  BOOL v88 = 0;
  long long __p = 0;
  long long v96 = 0u;
  memset(v95, 0, sizeof(v95));
  std::deque<ZinConcatLayer const*>::push_back(v95, &v97);
  uint64_t v22 = *((void *)&v96 + 1);
  long long v83 = a4;
  if (*((void *)&v96 + 1))
  {
    do
    {
      uint64_t v23 = *(Subgraph **)(*(void *)(*((void *)&v95[0] + 1) + (((unint64_t)v96 >> 6) & 0x3FFFFFFFFFFFFF8))
                         + 8 * (v96 & 0x1FF));
      *(void *)&long long v96 = v96 + 1;
      *((void *)&v96 + 1) = v22 - 1;
      if ((unint64_t)v96 >= 0x400)
      {
        operator delete(**((void ***)&v95[0] + 1));
        *((void *)&v95[0] + 1) += 8;
        *(void *)&long long v96 = v96 - 512;
      }
      uint64_t v24 = *((void *)v23 + 11);
      uint64_t v25 = *((void *)v23 + 12);
      if (v25 != v24)
      {
        unint64_t v26 = 0;
        do
        {
          if (v26 == a6 || (a6 & 0x8000000000000000) != 0 || v23 != v97)
          {
            v89[0] = 0;
            v89[0] = *(ZinMirSpatialSplitUtils **)(v24 + 8 * v26);
            if (*(_DWORD *)(*((void *)v89[0] + 8) + 8) == 7)
            {
              if (std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)this + 72, v89))
              {
                uint64_t v94 = v89[0];
                std::deque<ZinConcatLayer const*>::push_back(v95, &v94);
              }
            }
            else if (std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)this + 72, v89)&& ZinMirSpatialSplitUtils::IsDeConv(v89[0], v27))
            {
              uint64_t v28 = *((void *)this + 7);
              if ((char *)v28 == v10) {
                goto LABEL_134;
              }
              uint64_t v29 = *((void *)this + 7);
              while (*(ZinMirSpatialSplitUtils **)(v29 + 16) != v89[0])
              {
                uint64_t v29 = *(void *)(v29 + 8);
                if ((char *)v29 == v10) {
                  goto LABEL_134;
                }
              }
              if ((char *)v29 == v10) {
LABEL_134:
              }
                ZinAssertImpl("Spatial Splitting Internal Error", v83, a7);
              if (v28 == v29)
              {
                unint64_t v30 = 0;
              }
              else
              {
                unint64_t v30 = 0;
                do
                {
                  ++v30;
                  uint64_t v28 = *(void *)(v28 + 8);
                }
                while (v28 != v29);
              }
              if (0x34F72C234F72C235 * ((uint64_t)(*v18 - *v14) >> 3) <= v30) {
                std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
              }
              uint64_t v31 = *v14 + 232 * v30;
              if (!*(unsigned char *)(v31 + 224)) {
                std::__throw_bad_optional_access[abi:ne180100]();
              }
              int v32 = v87;
              if (v87 >= (uint64_t *)v88)
              {
                long long v37 = (uint64_t *)__p;
                unint64_t v38 = 0xCCCCCCCCCCCCCCCDLL * (((char *)v87 - (unsigned char *)__p) >> 4);
                unint64_t v39 = v38 + 1;
                if (v38 + 1 > 0x333333333333333) {
                  std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
                }
                if (0x999999999999999ALL * ((v88 - (unsigned char *)__p) >> 4) > v39) {
                  unint64_t v39 = 0x999999999999999ALL * ((v88 - (unsigned char *)__p) >> 4);
                }
                if (0xCCCCCCCCCCCCCCCDLL * ((v88 - (unsigned char *)__p) >> 4) >= 0x199999999999999) {
                  unint64_t v40 = 0x333333333333333;
                }
                else {
                  unint64_t v40 = v39;
                }
                if (v40)
                {
                  uint64_t v41 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ZinIrCodegenTDPartitionStats>>((uint64_t)&v88, v40);
                  long long v37 = (uint64_t *)__p;
                  int v32 = v87;
                }
                else
                {
                  uint64_t v41 = 0;
                }
                uint64_t v42 = &v41[16 * (((char *)v87 - (unsigned char *)__p) >> 4)];
                *(_OWORD *)uint64_t v42 = *(_OWORD *)v31;
                long long v43 = *(_OWORD *)(v31 + 16);
                long long v44 = *(_OWORD *)(v31 + 32);
                long long v45 = *(_OWORD *)(v31 + 64);
                *((_OWORD *)v42 + 3) = *(_OWORD *)(v31 + 48);
                *((_OWORD *)v42 + 4) = v45;
                *((_OWORD *)v42 + 1) = v43;
                *((_OWORD *)v42 + 2) = v44;
                if (v32 == v37)
                {
                  uint64_t v50 = &v41[80 * v38];
                }
                else
                {
                  long long v46 = &v41[80 * v38];
                  do
                  {
                    *((_OWORD *)v46 - 5) = *((_OWORD *)v32 - 5);
                    long long v47 = *((_OWORD *)v32 - 4);
                    long long v48 = *((_OWORD *)v32 - 3);
                    long long v49 = *((_OWORD *)v32 - 1);
                    uint64_t v50 = v46 - 80;
                    *((_OWORD *)v46 - 2) = *((_OWORD *)v32 - 2);
                    *((_OWORD *)v46 - 1) = v49;
                    *((_OWORD *)v46 - 4) = v47;
                    *((_OWORD *)v46 - 3) = v48;
                    v32 -= 10;
                    v46 -= 80;
                  }
                  while (v32 != v37);
                }
                long long v36 = (uint64_t *)(v42 + 80);
                long long __p = v50;
                double v87 = (uint64_t *)(v42 + 80);
                BOOL v88 = &v41[80 * v40];
                if (v37) {
                  operator delete(v37);
                }
              }
              else
              {
                *(_OWORD *)double v87 = *(_OWORD *)v31;
                long long v33 = *(_OWORD *)(v31 + 16);
                long long v34 = *(_OWORD *)(v31 + 32);
                long long v35 = *(_OWORD *)(v31 + 64);
                *((_OWORD *)v32 + 3) = *(_OWORD *)(v31 + 48);
                *((_OWORD *)v32 + 4) = v35;
                *((_OWORD *)v32 + 1) = v33;
                *((_OWORD *)v32 + 2) = v34;
                long long v36 = v32 + 10;
              }
              double v87 = v36;
            }
            uint64_t v24 = *((void *)v23 + 11);
            uint64_t v25 = *((void *)v23 + 12);
          }
          ++v26;
        }
        while (v26 < (v25 - v24) >> 3);
      }
      uint64_t v22 = *((void *)&v96 + 1);
    }
    while (*((void *)&v96 + 1));
    long long v51 = (char *)__p;
    if (__p != v87) {
      goto LABEL_102;
    }
  }
  else
  {
    long long v51 = 0;
  }
  uint64_t v52 = (char *)*((void *)this + 7);
  if (v52 == v10) {
    goto LABEL_142;
  }
  uint64_t v53 = (char *)*((void *)this + 7);
  while (*((Subgraph **)v53 + 2) != v97)
  {
    uint64_t v53 = (char *)*((void *)v53 + 1);
    if (v53 == v10)
    {
      uint64_t v53 = v10;
      break;
    }
  }
  if (v52 == v53)
  {
    unint64_t v54 = 0;
  }
  else
  {
    unint64_t v54 = 0;
    do
    {
      ++v54;
      uint64_t v52 = (char *)*((void *)v52 + 1);
    }
    while (v52 != v53);
    uint64_t v52 = v53;
  }
  if (v52 == v10) {
LABEL_142:
  }
    ZinAssertImpl("Spatial Splitting Internal Error", v83, a7);
  if (0x34F72C234F72C235 * ((uint64_t)(*v18 - *v14) >> 3) <= v54) {
    std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
  }
  uint64_t v55 = *v14 + 232 * v54;
  if (!*(unsigned char *)(v55 + 224)) {
    ZinAssertImpl("Spatial Splitting Internal Error");
  }
  uint64_t v57 = *(_OWORD **)(v55 + 128);
  for (uint64_t i = *(_OWORD **)(v55 + 136); v57 != i; v57 += 5)
  {
    long long v90 = v57[1];
    long long v91 = v57[2];
    long long v92 = v57[3];
    long long v93 = v57[4];
    *(_OWORD *)char v89 = *v57;
    if (v51 >= v88)
    {
      int v58 = (char *)__p;
      unint64_t v59 = 0xCCCCCCCCCCCCCCCDLL * ((v51 - (unsigned char *)__p) >> 4);
      unint64_t v60 = v59 + 1;
      if (v59 + 1 > 0x333333333333333) {
        std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
      }
      if (0x999999999999999ALL * ((v88 - (unsigned char *)__p) >> 4) > v60) {
        unint64_t v60 = 0x999999999999999ALL * ((v88 - (unsigned char *)__p) >> 4);
      }
      if (0xCCCCCCCCCCCCCCCDLL * ((v88 - (unsigned char *)__p) >> 4) >= 0x199999999999999) {
        unint64_t v61 = 0x333333333333333;
      }
      else {
        unint64_t v61 = v60;
      }
      if (v61)
      {
        char v62 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ZinIrCodegenTDPartitionStats>>((uint64_t)&v88, v61);
        int v58 = (char *)__p;
        long long v51 = (char *)v87;
      }
      else
      {
        char v62 = 0;
      }
      unint64_t v63 = &v62[80 * v59];
      *((_OWORD *)v63 + 1) = v90;
      *((_OWORD *)v63 + 2) = v91;
      *((_OWORD *)v63 + 3) = v92;
      *((_OWORD *)v63 + 4) = v93;
      *(_OWORD *)unint64_t v63 = *(_OWORD *)v89;
      if (v51 == v58)
      {
        long long v68 = &v62[80 * v59];
      }
      else
      {
        unint64_t v64 = &v62[80 * v59];
        do
        {
          *((_OWORD *)v64 - 5) = *((_OWORD *)v51 - 5);
          long long v65 = *((_OWORD *)v51 - 4);
          long long v66 = *((_OWORD *)v51 - 3);
          long long v67 = *((_OWORD *)v51 - 1);
          long long v68 = v64 - 80;
          *((_OWORD *)v64 - 2) = *((_OWORD *)v51 - 2);
          *((_OWORD *)v64 - 1) = v67;
          *((_OWORD *)v64 - 4) = v65;
          *((_OWORD *)v64 - 3) = v66;
          v51 -= 80;
          v64 -= 80;
        }
        while (v51 != v58);
      }
      long long v51 = v63 + 80;
      long long __p = v68;
      double v87 = (uint64_t *)(v63 + 80);
      BOOL v88 = &v62[80 * v61];
      if (v58) {
        operator delete(v58);
      }
    }
    else
    {
      memmove(v51, v57, 0x50uLL);
      v51 += 80;
    }
    double v87 = (uint64_t *)v51;
  }
LABEL_102:
  std::deque<unsigned long>::~deque[abi:ne180100](v95);
  long long v69 = (uint64_t *)__p;
  if (__p == v87)
  {
    uint64_t v20 = 0;
    goto LABEL_132;
  }
  char v70 = 1;
  uint64_t v71 = v83;
  do
  {
    SplitInfo::GetSplitDimensions(v71, (char **)v89);
    char v74 = (int *)v89[0];
    char v73 = v89[1];
    if (v89[0] == v89[1])
    {
      char v80 = 1;
      if (v89[0]) {
        goto LABEL_121;
      }
    }
    else
    {
      do
      {
        int v75 = *v74;
        uint64_t ValueAt = GetValueAtDimension<ZinTensorPosition>(v69, *v74);
        uint64_t v77 = GetValueAtDimension<ZinTensorDimensions>(v69 + 5, v75);
        uint64_t v78 = GetValueAtDimension<ZinTensorPosition>((uint64_t *)v85, v75);
        uint64_t v72 = GetValueAtDimension<ZinTensorDimensions>((uint64_t *)(v85 + 40), v75);
        BOOL v79 = v75 != 4 || ValueAt == v78;
        char v80 = v79;
        if (!v79) {
          break;
        }
        BOOL v81 = ValueAt == v78 && v77 == v72;
        BOOL v82 = v81;
        v70 &= v82;
        ++v74;
      }
      while (v74 != (int *)v73);
      char v74 = (int *)v89[0];
      uint64_t v71 = v83;
      if (v89[0])
      {
LABEL_121:
        v89[1] = (ZinMirSpatialSplitUtils *)v74;
        operator delete(v74);
      }
    }
    if ((v80 & 1) == 0) {
      goto LABEL_129;
    }
    v69 += 10;
  }
  while (v69 != v87);
  if (v70)
  {
LABEL_129:
    uint64_t v20 = 0;
    goto LABEL_131;
  }
  ZinMirSpatialSplitter::DetermineConcatTensorRegion(v72, (uint64_t **)&__p, v71, a6, a7);
  uint64_t v20 = 1;
LABEL_131:
  long long v69 = (uint64_t *)__p;
LABEL_132:
  if (v69)
  {
    double v87 = v69;
    operator delete(v69);
  }
  return v20;
}

void sub_211273FD0(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, void *__p, uint64_t a15, uint64_t a16, void *a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,char a29)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

void SplitInfo::ReplaceTiledLayerOnBranch(void *a1, unint64_t a2, unint64_t a3, TiledLayerTensorRegions *a4)
{
  if (0xAAAAAAAAAAAAAAABLL * ((uint64_t)(a1[1] - *a1) >> 3) <= a2
    || (v5 = (uint64_t *)(*a1 + 24 * a2), uint64_t v4 = *v5, 0x34F72C234F72C235 * ((v5[1] - *v5) >> 3) <= a3))
  {
    ZinAssertImpl("Invalid replace call");
  }

  std::__optional_storage_base<TiledLayerTensorRegions,false>::__assign_from[abi:ne180100]<std::__optional_copy_assign_base<TiledLayerTensorRegions,false> const&>((TiledLayerTensorRegions *)(v4 + 232 * a3), a4);
}

uint64_t GetConcatConsumer(const ZinIrOpLayer *a1)
{
  uint64_t v1 = *((void *)a1 + 14);
  uint64_t v2 = *((void *)a1 + 15);
  while (v1 != v2)
  {
    uint64_t result = *(void *)v1;
    if (*(_DWORD *)(*(void *)(*(void *)v1 + 64) + 8) == 7) {
      return result;
    }
    v1 += 8;
  }
  return 0;
}

void ZinMirSpatialSplitter::DetermineConcatTensorRegion(int a1, uint64_t **a2, SplitInfo *this, unint64_t a4, void *a5)
{
  if ((a4 & 0x8000000000000000) != 0 || (uint64_t v5 = a5, 0xCCCCCCCCCCCCCCCDLL * ((uint64_t)(a5[1] - *a5) >> 4) <= a4)) {
    ZinAssertImpl("Spatial Split Internal Error", a2, this);
  }
  SplitInfo::GetSplitDimensions(this, &v28);
  int v7 = (int *)v28;
  unint64_t v26 = (int *)v29;
  if (v28 != v29)
  {
    unint64_t v25 = a4;
    do
    {
      int v8 = *v7;
      uint64_t v10 = *a2;
      uint64_t v9 = a2[1];
      uint64_t v11 = *a2 + 10;
      if (*a2 == v9 || v11 == v9)
      {
        uint64_t v13 = *a2;
      }
      else
      {
        do
        {
          uint64_t ValueAt = GetValueAtDimension<ZinTensorPosition>(v11, v8);
          if (ValueAt < GetValueAtDimension<ZinTensorPosition>(v10, v8)) {
            uint64_t v10 = v11;
          }
          v11 += 10;
        }
        while (v11 != v9);
        uint64_t v13 = *a2;
        uint64_t v9 = a2[1];
      }
      uint64_t v15 = v5;
      unint64_t v16 = v13 + 10;
      if (v13 != v9 && v16 != v9)
      {
        do
        {
          uint64_t v18 = GetValueAtDimension<ZinTensorPosition>(v13, v8);
          uint64_t v19 = GetValueAtDimension<ZinTensorDimensions>(v13 + 5, v8);
          uint64_t v20 = GetValueAtDimension<ZinTensorPosition>(v16, v8);
          unint64_t v21 = v16 + 5;
          if (v19 + v18 < GetValueAtDimension<ZinTensorDimensions>(v21, v8) + v20) {
            uint64_t v13 = v21 - 5;
          }
          unint64_t v16 = v21 + 5;
        }
        while (v16 != v9);
      }
      uint64_t v22 = GetValueAtDimension<ZinTensorPosition>(v10, v8);
      uint64_t v5 = v15;
      uint64_t v23 = GetValueAtDimension<ZinTensorPosition>(v13, v8);
      uint64_t v24 = GetValueAtDimension<ZinTensorDimensions>(v13 + 5, v8);
      if (SetValueAtDimension<ZinTensorPosition>((void *)(*v15 + 80 * v25), v8, v22)
        || SetValueAtDimension<ZinTensorDimensions>((void *)(*v15 + 80 * v25 + 40), v8, v23 - v22 + v24))
      {
        ZinAssertImpl("Spatial Split Internal Error", v25);
      }
      ++v7;
    }
    while (v7 != v26);
    int v7 = (int *)v28;
  }
  if (v7)
  {
    uint64_t v29 = (char *)v7;
    operator delete(v7);
  }
}

void sub_21127431C(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, void *__p, uint64_t a13)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinMirSpatialSplitter::DetermineInputLayersForCurrentSplitLayer(uint64_t a1, uint64_t a2, uint64_t a3, SplitInfo *a4, unint64_t a5, void *a6, uint64_t a7, ZinIrOpLayer *a8, void *a9)
{
  uint64_t v140 = *MEMORY[0x263EF8340];
  uint64_t v9 = *(void *)a4;
  if (0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*((void *)a4 + 1) - *(void *)a4) >> 3) <= a5) {
    std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
  }
  memset(v136, 0, sizeof(v136));
  std::vector<std::optional<TiledLayerTensorRegions>>::__init_with_size[abi:ne180100]<std::optional<TiledLayerTensorRegions>*,std::optional<TiledLayerTensorRegions>*>(v136, *(void *)(v9 + 24 * a5), *(void *)(v9 + 24 * a5 + 8), 0x34F72C234F72C235 * ((uint64_t)(*(void *)(v9 + 24 * a5 + 8) - *(void *)(v9 + 24 * a5)) >> 3));
  *(void *)v139 = a8;
  __p[0] = v139;
  __p[1] = (void *)1;
  Layer2TDMapper::SourceLayer::SourceLayer(&v133, __p);
  if (0xCCCCCCCCCCCCCCCDLL * ((uint64_t)(a6[1] - *a6) >> 3) <= a5) {
    std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
  }
  uint64_t v13 = *((void *)a8 + 11);
  if (*((void *)a8 + 12) == v13)
  {
LABEL_146:
    uint64_t v91 = 0;
    goto LABEL_150;
  }
  unint64_t v14 = 0;
  int64_t v106 = (void *)(*a6 + 40 * a5);
  uint64_t v109 = a3 + 80;
  uint64_t v111 = a3 + 48;
  unint64_t v112 = a5;
  uint64_t v113 = a7;
  std::string v104 = (TiledLayerTensorRegions::Id *)(a7 + 152);
  unint64_t v102 = a5 + 1;
  uint64_t v103 = 24 * a5 + 32;
  uint64_t v101 = -40 - 40 * a5;
  while (1)
  {
    v132 = 0;
    v132 = *(ZinIrOpLayer **)(v13 + 8 * v14);
    uint64_t v15 = (*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)v132 + 32))(v132, 0, 0);
    int v16 = (*(uint64_t (**)(ZinIrOpLayer *, uint64_t))(*(void *)a8 + 200))(a8, v15);
    uint64_t v17 = std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>(a3 + 72, &v132);
    if (v109 == v17) {
      int v18 = 0;
    }
    else {
      int v18 = v16;
    }
    if (v18 == 1)
    {
      BOOL v92 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v92) {
        ZinMirSpatialSplitter::DetermineInputLayersForCurrentSplitLayer(v92, v93, v94, v95, v96, v97, v98, v99);
      }
      goto LABEL_149;
    }
    SplitInfo::GetSplitDimensions(a4, (char **)__p);
    uint64_t v19 = (int *)__p[0];
    uint64_t v20 = (int *)__p[1];
    if (__p[0] == __p[1])
    {
      char View = 0;
      if (__p[0]) {
        goto LABEL_16;
      }
    }
    else
    {
      char View = 0;
      do
      {
        if (View) {
          char View = 1;
        }
        else {
          char View = ZinMirSpatialSplitUtils::ShouldCreateView(a8, v14, *v19);
        }
        ++v19;
      }
      while (v19 != v20);
      uint64_t v19 = (int *)__p[0];
      if (__p[0])
      {
LABEL_16:
        __p[1] = v19;
        operator delete(v19);
      }
    }
    if (View) {
      break;
    }
    long long v34 = v132;
LABEL_37:
    *(void *)(*a9 + 8 * v14++) = v34;
    uint64_t v13 = *((void *)a8 + 11);
    if (v14 >= (*((void *)a8 + 12) - v13) >> 3) {
      goto LABEL_146;
    }
  }
  if (v109 != v17)
  {
    uint64_t v22 = (void *)(*(void *)(v113 + 128) + 80 * v14);
    uint64_t v23 = v22[5];
    uint64_t v24 = v22[6];
    uint64_t v26 = v22[7];
    uint64_t v25 = v22[8];
    uint64_t v27 = v22[9];
    if (std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(v106, &v132))
    {
      uint64_t v28 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(v106, &v132);
      if (!v28) {
        std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
      }
      uint64_t v29 = (void *)(*(uint64_t (**)(void, void, void))(*(void *)v28[3] + 32))(v28[3], 0, 0);
      BOOL v30 = v29[6] == v23 && v29[7] == v24;
      BOOL v31 = v30 && v29[10] == v27;
      BOOL v32 = v31 && v29[8] == v26;
      if (v32 && v29[9] == v25)
      {
        if (!std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(v106, &v132))ZinAssertImpl("Spatial Splitting Internal Error"); {
        long long v33 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(v106, &v132);
        }
        if (!v33) {
          std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
        }
        long long v34 = (ZinIrOpLayer *)v33[3];
        goto LABEL_37;
      }
    }
  }
  uint64_t v35 = *(void *)(v113 + 128) + 80 * v14;
  uint64_t v36 = *(void *)(v35 + 72);
  long long v37 = *(_OWORD *)(v35 + 56);
  *(_OWORD *)long long __p = *(_OWORD *)(v35 + 40);
  long long v130 = v37;
  uint64_t v131 = v36;
  memset(v139, 0, sizeof(v139));
  SplitInfo::GetSplitDimensions(a4, &v122.__r_.__value_.__l.__data_);
  std::string::size_type size = v122.__r_.__value_.__l.__size_;
  unint64_t v38 = (void *)v122.__r_.__value_.__r.__words[0];
  if (v122.__r_.__value_.__r.__words[0] == v122.__r_.__value_.__l.__size_)
  {
    BOOL v44 = 1;
    if (v122.__r_.__value_.__r.__words[0]) {
      goto LABEL_46;
    }
  }
  else
  {
    std::string::size_type v40 = v122.__r_.__value_.__r.__words[0] + 4;
    do
    {
      int v41 = *(_DWORD *)(v40 - 4);
      uint64_t ValueAt = GetValueAtDimension<ZinTensorPosition>((uint64_t *)(*(void *)(v113 + 128) + 80 * v14), v41);
      int v43 = SetValueAtDimension<ZinTensorPosition>(v139, v41, ValueAt);
      BOOL v44 = v43 == 0;
      if (v43) {
        BOOL v45 = 1;
      }
      else {
        BOOL v45 = v40 == size;
      }
      v40 += 4;
    }
    while (!v45);
    unint64_t v38 = (void *)v122.__r_.__value_.__r.__words[0];
    if (v122.__r_.__value_.__r.__words[0])
    {
LABEL_46:
      v122.__r_.__value_.__l.__size_ = (std::string::size_type)v38;
      operator delete(v38);
    }
  }
  if (v44)
  {
    if (v16)
    {
      *(void *)v139 = *(void *)(*(void *)(v113 + 128) + 80 * v14);
      memset(&v139[8], 0, 32);
      uint64_t v46 = (*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)v132 + 32))(v132, 0, 0);
      long long v47 = *(_OWORD *)(v46 + 64);
      *(_OWORD *)long long __p = *(_OWORD *)(v46 + 48);
      long long v130 = v47;
      uint64_t v131 = *(void *)(v46 + 80);
      __p[0] = *(void **)(*(void *)(v113 + 128) + 80 * v14 + 40);
    }
    long long v48 = v132;
    if (v109 == v17) {
      goto LABEL_97;
    }
    uint64_t v49 = *(void *)(a3 + 56);
    if (v49 == v111) {
      goto LABEL_64;
    }
    uint64_t v50 = *(void *)(a3 + 56);
    while (*(ZinIrOpLayer **)(v50 + 16) != v132)
    {
      uint64_t v50 = *(void *)(v50 + 8);
      if (v50 == v111)
      {
        uint64_t v50 = a3 + 48;
        break;
      }
    }
    if (v49 == v50)
    {
LABEL_64:
      unint64_t v51 = 0;
    }
    else
    {
      unint64_t v51 = 0;
      do
      {
        ++v51;
        uint64_t v49 = *(void *)(v49 + 8);
      }
      while (v49 != v50);
    }
    uint64_t v52 = *(void *)a4;
    uint64_t v53 = v101;
    unint64_t v54 = v102;
    uint64_t v55 = v103;
    do
    {
      if (!v54) {
        goto LABEL_153;
      }
      if ((*((void *)a4 + 1) - *(void *)a4) / 24 <= v112) {
        std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
      }
      uint64_t v56 = *(void *)(v52 + v55 - 32);
      if (0x34F72C234F72C235 * ((*(void *)(v52 + v55 - 24) - v56) >> 3) <= v51) {
        std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
      }
      v55 -= 24;
      --v54;
      v53 += 40;
    }
    while (!*(unsigned char *)(v56 + 232 * v51 + 224));
    if ((v54 & 0x8000000000000000) != 0) {
LABEL_153:
    }
      ZinAssertImpl("Spatial Splitting Internal Error");
    uint64_t v57 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)(*a6 - v53), &v132);
    if (!v57) {
      std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
    }
    uint64_t v58 = *(void *)(a3 + 56);
    if (v58 == v111) {
      goto LABEL_81;
    }
    uint64_t v59 = *(void *)(a3 + 56);
    while (*(ZinIrOpLayer **)(v59 + 16) != v132)
    {
      uint64_t v59 = *(void *)(v59 + 8);
      if (v59 == v111)
      {
        uint64_t v59 = a3 + 48;
        break;
      }
    }
    if (v58 == v59)
    {
LABEL_81:
      unint64_t v60 = 0;
    }
    else
    {
      unint64_t v60 = 0;
      do
      {
        ++v60;
        uint64_t v58 = *(void *)(v58 + 8);
      }
      while (v58 != v59);
    }
    if (0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*((void *)a4 + 1) - *(void *)a4) >> 3) <= v54) {
      std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
    }
    unint64_t v61 = (void *)(*(void *)a4 + v55);
    uint64_t v62 = *(v61 - 1);
    if (0x34F72C234F72C235 * ((*v61 - v62) >> 3) <= v60) {
      std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
    }
    uint64_t v63 = v62 + 232 * v60;
    if (!*(unsigned char *)(v63 + 224)) {
      std::__throw_bad_optional_access[abi:ne180100]();
    }
    long long v48 = (ZinIrOpLayer *)v57[3];
    SplitInfo::GetSplitDimensions(a4, &v122.__r_.__value_.__l.__data_);
    std::string::size_type v65 = v122.__r_.__value_.__l.__size_;
    unint64_t v64 = (int *)v122.__r_.__value_.__r.__words[0];
    if (v122.__r_.__value_.__r.__words[0] == v122.__r_.__value_.__l.__size_)
    {
      int v69 = 1;
      if (v122.__r_.__value_.__r.__words[0]) {
        goto LABEL_95;
      }
    }
    else
    {
      while (1)
      {
        int v66 = *v64;
        v115.__r_.__value_.__r.__words[0] = (std::string::size_type)v132;
        if (!std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)a4 + 8, &v115)|| v66 != 3)
        {
          uint64_t v67 = GetValueAtDimension<ZinTensorPosition>((uint64_t *)v63, v66);
          uint64_t v68 = GetValueAtDimension<ZinTensorPosition>((uint64_t *)v139, v66);
          if (SetValueAtDimension<ZinTensorPosition>(v139, v66, v68 - v67)) {
            break;
          }
        }
        if (++v64 == (int *)v65)
        {
          int v69 = 1;
          goto LABEL_94;
        }
      }
      int v69 = 0;
LABEL_94:
      unint64_t v64 = (int *)v122.__r_.__value_.__r.__words[0];
      if (v122.__r_.__value_.__r.__words[0])
      {
LABEL_95:
        v122.__r_.__value_.__l.__size_ = (std::string::size_type)v64;
        operator delete(v64);
      }
    }
    if (v69)
    {
LABEL_97:
      SplitInfo::GetSplitDimensions(a4, &v122.__r_.__value_.__l.__data_);
      ZinMirSpatialSplitUtils::AdjustDimensionsForBroadcast(v139, __p, a8, (uint64_t)&v122, v14);
      if (v122.__r_.__value_.__r.__words[0])
      {
        v122.__r_.__value_.__l.__size_ = v122.__r_.__value_.__r.__words[0];
        operator delete(v122.__r_.__value_.__l.__data_);
      }
      char v70 = v132;
      if (*((char *)v132 + 47) >= 0) {
        size_t v71 = *((unsigned __int8 *)v132 + 47);
      }
      else {
        size_t v71 = *((void *)v132 + 4);
      }
      std::string::basic_string[abi:ne180100]((uint64_t)&v126, v71 + 1);
      if ((v126.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
        uint64_t v72 = &v126;
      }
      else {
        uint64_t v72 = (std::string *)v126.__r_.__value_.__r.__words[0];
      }
      if (v71)
      {
        if (*((char *)v70 + 47) >= 0) {
          char v73 = (char *)v70 + 24;
        }
        else {
          char v73 = (const void *)*((void *)v70 + 3);
        }
        memmove(v72, v73, v71);
      }
      *(_WORD *)((char *)&v72->__r_.__value_.__l.__data_ + v71) = 95;
      TiledLayerTensorRegions::Id::ToStringForIr(v104, &v125);
      if ((v125.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
        char v74 = &v125;
      }
      else {
        char v74 = (std::string *)v125.__r_.__value_.__r.__words[0];
      }
      if ((v125.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
        std::string::size_type v75 = HIBYTE(v125.__r_.__value_.__r.__words[2]);
      }
      else {
        std::string::size_type v75 = v125.__r_.__value_.__l.__size_;
      }
      unint64_t v76 = std::string::append(&v126, (const std::string::value_type *)v74, v75);
      long long v77 = *(_OWORD *)&v76->__r_.__value_.__l.__data_;
      v114.__r_.__value_.__r.__words[2] = v76->__r_.__value_.__r.__words[2];
      *(_OWORD *)&v114.__r_.__value_.__l.__data_ = v77;
      v76->__r_.__value_.__l.__size_ = 0;
      v76->__r_.__value_.__r.__words[2] = 0;
      v76->__r_.__value_.__r.__words[0] = 0;
      uint64_t v78 = std::string::append(&v114, "_", 1uLL);
      long long v79 = *(_OWORD *)&v78->__r_.__value_.__l.__data_;
      v115.__r_.__value_.__r.__words[2] = v78->__r_.__value_.__r.__words[2];
      *(_OWORD *)&v115.__r_.__value_.__l.__data_ = v79;
      v78->__r_.__value_.__l.__size_ = 0;
      v78->__r_.__value_.__r.__words[2] = 0;
      v78->__r_.__value_.__r.__words[0] = 0;
      std::string::basic_string[abi:ne180100]<0>(&v124, "ss_view");
      char v80 = std::string::append(&v124, "_xfm", 4uLL);
      long long v81 = *(_OWORD *)&v80->__r_.__value_.__l.__data_;
      int64_t v138 = v80->__r_.__value_.__r.__words[2];
      long long v137 = v81;
      v80->__r_.__value_.__l.__size_ = 0;
      v80->__r_.__value_.__r.__words[2] = 0;
      v80->__r_.__value_.__r.__words[0] = 0;
      if (v138 >= 0) {
        BOOL v82 = (const std::string::value_type *)&v137;
      }
      else {
        BOOL v82 = (const std::string::value_type *)v137;
      }
      if (v138 >= 0) {
        std::string::size_type v83 = HIBYTE(v138);
      }
      else {
        std::string::size_type v83 = *((void *)&v137 + 1);
      }
      uint64_t v84 = std::string::append(&v115, v82, v83);
      long long v85 = *(_OWORD *)&v84->__r_.__value_.__l.__data_;
      v122.__r_.__value_.__r.__words[2] = v84->__r_.__value_.__r.__words[2];
      *(_OWORD *)&v122.__r_.__value_.__l.__data_ = v85;
      v84->__r_.__value_.__l.__size_ = 0;
      v84->__r_.__value_.__r.__words[2] = 0;
      v84->__r_.__value_.__r.__words[0] = 0;
      unint64_t v86 = *(void *)(a1 + 40);
      *(void *)(a1 + 40) = v86 + 1;
      std::to_string(&v123, v86);
      if ((v123.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
        double v87 = &v123;
      }
      else {
        double v87 = (std::string *)v123.__r_.__value_.__r.__words[0];
      }
      if ((v123.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
        std::string::size_type v88 = HIBYTE(v123.__r_.__value_.__r.__words[2]);
      }
      else {
        std::string::size_type v88 = v123.__r_.__value_.__l.__size_;
      }
      char v89 = std::string::append(&v122, (const std::string::value_type *)v87, v88);
      long long v90 = *(_OWORD *)&v89->__r_.__value_.__l.__data_;
      std::string::size_type v128 = v89->__r_.__value_.__r.__words[2];
      *(_OWORD *)long long v127 = v90;
      v89->__r_.__value_.__l.__size_ = 0;
      v89->__r_.__value_.__r.__words[2] = 0;
      v89->__r_.__value_.__r.__words[0] = 0;
      if (SHIBYTE(v123.__r_.__value_.__r.__words[2]) < 0) {
        operator delete(v123.__r_.__value_.__l.__data_);
      }
      if (SHIBYTE(v122.__r_.__value_.__r.__words[2]) < 0) {
        operator delete(v122.__r_.__value_.__l.__data_);
      }
      if (SHIBYTE(v138) < 0) {
        operator delete((void *)v137);
      }
      if (SHIBYTE(v124.__r_.__value_.__r.__words[2]) < 0) {
        operator delete(v124.__r_.__value_.__l.__data_);
      }
      if (SHIBYTE(v115.__r_.__value_.__r.__words[2]) < 0) {
        operator delete(v115.__r_.__value_.__l.__data_);
      }
      if (SHIBYTE(v114.__r_.__value_.__r.__words[2]) < 0) {
        operator delete(v114.__r_.__value_.__l.__data_);
      }
      if (SHIBYTE(v125.__r_.__value_.__r.__words[2]) < 0) {
        operator delete(v125.__r_.__value_.__l.__data_);
      }
      if (SHIBYTE(v126.__r_.__value_.__r.__words[2]) < 0) {
        operator delete(v126.__r_.__value_.__l.__data_);
      }
      ZinObjectNameFactory::ZinObjectNameFactory(&v122, v127);
      ZinObjectNameFactory::CreateName((uint64_t)&v122, 0, &v115);
      (*(void (**)(ZinIrOpLayer *, void, void))(*(void *)v48 + 32))(v48, 0, 0);
      long long v116 = *(_OWORD *)v139;
      long long v117 = *(_OWORD *)&v139[16];
      int64x2_t v119 = vdupq_n_s64(1uLL);
      int64x2_t v120 = v119;
      uint64_t v118 = *(void *)&v139[32];
      uint64_t v121 = 1;
      ZinBuilder::CreateView();
    }
  }
LABEL_149:
  uint64_t v91 = 3;
LABEL_150:
  v133 = &unk_26C359A08;
  if (v134)
  {
    v135 = v134;
    operator delete(v134);
  }
  __p[0] = v136;
  std::vector<std::optional<TiledLayerTensorRegions>>::__destroy_vector::operator()[abi:ne180100]((void ***)__p);
  return v91;
}

void sub_211275428(_Unwind_Exception *a1)
{
  *(void *)(v1 - 232) = &unk_26C359A08;
  uint64_t v3 = *(void **)(v1 - 224);
  if (v3)
  {
    *(void *)(v1 - 216) = v3;
    operator delete(v3);
  }
  *(void *)(v1 - 144) = v1 - 200;
  std::vector<std::optional<TiledLayerTensorRegions>>::__destroy_vector::operator()[abi:ne180100]((void ***)(v1 - 144));
  _Unwind_Resume(a1);
}

uint64_t ZinMirSpatialSplitter::DetermineOutputLayersForCurrentSplitLayer(uint64_t a1, uint64_t a2, uint64_t a3, void *a4, unint64_t a5, unint64_t a6, void *a7, uint64_t a8, ZinIrOpLayer *a9, ZinMirSpatialSplitUtils **a10)
{
  uint64_t v15 = a9;
  uint64_t v106 = *MEMORY[0x263EF8340];
  v105.__r_.__value_.__r.__words[0] = (std::string::size_type)a9;
  *(void *)&long long v95 = &v105;
  *((void *)&v95 + 1) = 1;
  Layer2TDMapper::SourceLayer::SourceLayer(&v91, &v95);
  BOOL v82 = a10;
  if (a5 % a4[13])
  {
    *(void *)&long long v95 = v15;
    if (std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(a4 + 8, &v95))
    {
      uint64_t v79 = *((void *)a9 + 2);
      int v16 = *v82;
      uint64_t v94 = a9;
      uint64_t v17 = 40 * a5;
      int v18 = (uint64_t *)(*a4 + 24 * a5 - 24);
      uint64_t v19 = "Spatial Splitting Internal Error";
      unint64_t v20 = a5;
      do
      {
        if ((--v20 & 0x8000000000000000) != 0) {
          goto LABEL_103;
        }
        if (0xAAAAAAAAAAAAAAABLL * ((uint64_t)(a4[1] - *a4) >> 3) <= v20) {
          std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
        }
        uint64_t v21 = *v18;
        if (0x34F72C234F72C235 * ((v18[1] - *v18) >> 3) <= a6) {
          std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
        }
        v17 -= 40;
        v18 -= 3;
        uint64_t v22 = v21 + 232 * a6;
      }
      while (!*(unsigned char *)(v22 + 224));
      uint64_t v23 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)(*a7 + v17), &v94);
      if (!v23) {
        std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
      }
      uint64_t v24 = v23[3];
      if (*(_DWORD *)(*(void *)(v24 + 64) + 8) == 36 && *(_OWORD *)(v22 + 184) != 0) {
        uint64_t v24 = **(void **)(v24 + 88);
      }
      for (uint64_t i = *(void *)(v24 + 112); i != *(void *)(v24 + 120); i += 8)
      {
        if (*(_DWORD *)(*(void *)(*(void *)i + 64) + 8) == 7)
        {
          std::string::basic_string[abi:ne180100]<0>(v89, "copy_for_cb");
          int v26 = *(char *)(v24 + 47);
          if (v26 >= 0) {
            uint64_t v27 = (const std::string::value_type *)(v24 + 24);
          }
          else {
            uint64_t v27 = *(const std::string::value_type **)(v24 + 24);
          }
          if (v26 >= 0) {
            std::string::size_type v28 = *(unsigned __int8 *)(v24 + 47);
          }
          else {
            std::string::size_type v28 = *(void *)(v24 + 32);
          }
          uint64_t v29 = std::string::insert((std::string *)v89, 0, v27, v28);
          long long v30 = *(_OWORD *)&v29->__r_.__value_.__l.__data_;
          *(void *)&long long v96 = *((void *)&v29->__r_.__value_.__l + 2);
          long long v95 = v30;
          v29->__r_.__value_.__l.__size_ = 0;
          v29->__r_.__value_.__r.__words[2] = 0;
          v29->__r_.__value_.__r.__words[0] = 0;
          __n128 v31 = ZinObjectNameFactory::ZinObjectNameFactory(&v105, &v95);
          if (SBYTE7(v96) < 0) {
            operator delete((void *)v95);
          }
          if ((v89[23] & 0x80000000) != 0) {
            operator delete(*(void **)v89);
          }
          uint64_t v32 = *(unsigned int *)((*(uint64_t (**)(uint64_t, void, void, __n128))(*(void *)v24 + 32))(v24, 0, 0, v31)+ 88);
          v104.__r_.__value_.__r.__words[0] = 0;
          LOBYTE(v95) = 0;
          char v101 = 0;
          ZinBuilder::CreateNEBypass(v79, (uint64_t)&v105, v24, v32, (uint64_t *)&v104, 0, (uint64_t)&v95, 1.0);
        }
      }
      int v33 = *(_DWORD *)(*((void *)v16 + 8) + 8);
      if (v33 != 36 && v33 == *(_DWORD *)(*((void *)v94 + 8) + 8))
      {
        uint64_t v34 = (*(uint64_t (**)(ZinMirSpatialSplitUtils *, void, void))(*(void *)v16 + 32))(v16, 0, 0);
        long long v35 = *(_OWORD *)(v34 + 64);
        long long v95 = *(_OWORD *)(v34 + 48);
        long long v96 = v35;
        uint64_t v97 = *(void *)(v34 + 80);
        uint64_t v36 = *(void *)((*(uint64_t (**)(uint64_t, void, void))(*(void *)v24 + 32))(v24, 0, 0)
                        + 64);
        if (*(_DWORD *)(*((void *)v94 + 8) + 8) == 7)
        {
          for (uint64_t j = *(void *)(v22 + 128); j != *(void *)(v22 + 136); j += 80)
          {
            uint64_t v38 = *(void *)(j + 56);
            if (v38 + *(void *)(j + 16) < v36) {
              uint64_t v36 = v38 + *(void *)(j + 16);
            }
          }
        }
        unint64_t v39 = (char *)operator new(0xA0uLL);
        *(void *)&v89[8] = v39 + 160;
        *(void *)&v89[16] = v39 + 160;
        *(_OWORD *)unint64_t v39 = 0u;
        *((_OWORD *)v39 + 1) = 0u;
        *((void *)v39 + 4) = 0;
        int64x2_t v40 = vdupq_n_s64(1uLL);
        *(int64x2_t *)(v39 + 40) = v40;
        *(int64x2_t *)(v39 + 56) = v40;
        *((void *)v39 + 9) = 1;
        *((void *)v39 + 10) = 0;
        *((void *)v39 + 11) = 0;
        *((void *)v39 + 12) = v36;
        *((void *)v39 + 13) = 0;
        *((void *)v39 + 14) = 0;
        *(int64x2_t *)(v39 + 120) = v40;
        *(int64x2_t *)(v39 + 136) = v40;
        *((void *)v39 + 19) = 1;
        *(void *)char v89 = v39;
        operator new();
      }
      uint64_t v19 = "The trimming view of the current tile happens in a different section";
LABEL_103:
      ZinAssertImpl(v19);
    }
  }
  else if (*(void *)(a8 + 16))
  {
    ZinAssertImpl("Spatial Split branch mismatch");
  }
  if (std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>(a3 + 24, &a9))
  {
    if (*(_OWORD *)(a8 + 184) != 0)
    {
      long long v42 = *(_OWORD *)(a8 + 56);
      *(_OWORD *)char v89 = *(_OWORD *)(a8 + 40);
      *(_OWORD *)&v89[16] = v42;
      uint64_t v90 = *(void *)(a8 + 72);
      *(void *)&long long v95 = a9;
      if (std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(a4 + 8, &v95))
      {
        uint64_t v43 = (*(uint64_t (**)(ZinMirSpatialSplitUtils *, void, void))(*(void *)*v82 + 32))(*v82, 0, 0);
        long long v44 = *(_OWORD *)(v43 + 64);
        *(_OWORD *)char v89 = *(_OWORD *)(v43 + 48);
        *(_OWORD *)&v89[16] = v44;
        uint64_t v90 = *(void *)(v43 + 80);
      }
      BOOL v45 = *v82;
      int64x2_t v87 = *(int64x2_t *)&v89[16];
      long long v86 = *(_OWORD *)v89;
      uint64_t v88 = v90;
      int64x2_t v87 = vsubq_s64(*(int64x2_t *)&v89[16], *(int64x2_t *)(a8 + 184));
      uint64_t v46 = (*(uint64_t (**)(ZinMirSpatialSplitUtils *, void, void))(*(void *)v45 + 32))(v45, 0, 0);
      uint64_t v47 = v46;
      if (*(char *)(v46 + 47) >= 0) {
        size_t v48 = *(unsigned __int8 *)(v46 + 47);
      }
      else {
        size_t v48 = *(void *)(v46 + 32);
      }
      uint64_t v49 = &v95;
      std::string::basic_string[abi:ne180100]((uint64_t)&v95, v48 + 8);
      if (SBYTE7(v96) < 0) {
        uint64_t v49 = (long long *)v95;
      }
      if (v48)
      {
        uint64_t v52 = *(char **)(v47 + 24);
        unint64_t v51 = (char *)(v47 + 24);
        uint64_t v50 = v52;
        if (v51[23] >= 0) {
          uint64_t v53 = v51;
        }
        else {
          uint64_t v53 = v50;
        }
        memmove(v49, v53, v48);
      }
      strcpy((char *)v49 + v48, "_trimmed");
      ZinObjectNameFactory::ZinObjectNameFactory(&v105, &v95);
      if (SBYTE7(v96) < 0) {
        operator delete((void *)v95);
      }
      ZinObjectNameFactory::CreateName((uint64_t)&v105, 0, &v102);
      (*(void (**)(ZinMirSpatialSplitUtils *, void, void))(*(void *)v45 + 32))(v45, 0, 0);
      uint64_t v97 = 0;
      long long v95 = 0u;
      long long v96 = 0u;
      int64x2_t v98 = vdupq_n_s64(1uLL);
      int64x2_t v99 = v98;
      uint64_t v100 = 1;
      ZinBuilder::CreateView();
    }
    if (ZinMirSpatialSplitUtils::IsDeConv(*v82, v41)
      && (*(void *)((*(uint64_t (**)(ZinMirSpatialSplitUtils *, void, void))(*(void *)*v82 + 32))(*v82, 0, 0)+ 64) & 0x8000000000000001) == 1)
    {
      unint64_t v54 = (ZinIrTensor *)(*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)a9 + 32))(a9, 0, 0);
      RootTensor = ZinIrTensor::GetRootTensor(v54);
      ZinIrTensor::GetTensorFamily(RootTensor, (uint64_t)v89);
      uint64_t v57 = *(ZinIrTensor ***)&v89[8];
      uint64_t v56 = *(ZinIrTensor ***)v89;
      if (*(void *)v89 != *(void *)&v89[8])
      {
        do
        {
          if (ZinIrTensor::IsLiveOut(*v56))
          {
            uint64_t v58 = *v82;
            if (*((char *)*v82 + 47) >= 0) {
              size_t v59 = *((unsigned __int8 *)*v82 + 47);
            }
            else {
              size_t v59 = *((void *)*v82 + 4);
            }
            unint64_t v60 = &v105;
            std::string::basic_string[abi:ne180100]((uint64_t)&v105, v59 + 1);
            if ((v105.__r_.__value_.__r.__words[2] & 0x8000000000000000) != 0) {
              unint64_t v60 = (std::string *)v105.__r_.__value_.__r.__words[0];
            }
            if (v59)
            {
              if (*((char *)v58 + 47) >= 0) {
                unint64_t v61 = (char *)v58 + 24;
              }
              else {
                unint64_t v61 = (const void *)*((void *)v58 + 3);
              }
              memmove(v60, v61, v59);
            }
            *(_WORD *)((char *)&v60->__r_.__value_.__l.__data_ + v59) = 95;
            uint64_t v62 = (std::string *)std::string::basic_string[abi:ne180100]<0>(&v103, "ss_copy");
            uint64_t v63 = std::string::append(v62, "_xfm", 4uLL);
            long long v64 = *(_OWORD *)&v63->__r_.__value_.__l.__data_;
            v104.__r_.__value_.__r.__words[2] = v63->__r_.__value_.__r.__words[2];
            *(_OWORD *)&v104.__r_.__value_.__l.__data_ = v64;
            v63->__r_.__value_.__l.__size_ = 0;
            v63->__r_.__value_.__r.__words[2] = 0;
            v63->__r_.__value_.__r.__words[0] = 0;
            if ((v104.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
              std::string::size_type v65 = &v104;
            }
            else {
              std::string::size_type v65 = (std::string *)v104.__r_.__value_.__r.__words[0];
            }
            if ((v104.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
              std::string::size_type size = HIBYTE(v104.__r_.__value_.__r.__words[2]);
            }
            else {
              std::string::size_type size = v104.__r_.__value_.__l.__size_;
            }
            uint64_t v67 = std::string::append(&v105, (const std::string::value_type *)v65, size);
            long long v68 = *(_OWORD *)&v67->__r_.__value_.__l.__data_;
            *(void *)&long long v96 = *((void *)&v67->__r_.__value_.__l + 2);
            long long v95 = v68;
            v67->__r_.__value_.__l.__size_ = 0;
            v67->__r_.__value_.__r.__words[2] = 0;
            v67->__r_.__value_.__r.__words[0] = 0;
            unint64_t v69 = *(void *)(a1 + 40);
            *(void *)(a1 + 40) = v69 + 1;
            std::to_string(&v85, v69);
            if ((v85.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
              char v70 = &v85;
            }
            else {
              char v70 = (std::string *)v85.__r_.__value_.__r.__words[0];
            }
            if ((v85.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
              std::string::size_type v71 = HIBYTE(v85.__r_.__value_.__r.__words[2]);
            }
            else {
              std::string::size_type v71 = v85.__r_.__value_.__l.__size_;
            }
            uint64_t v72 = std::string::append((std::string *)&v95, (const std::string::value_type *)v70, v71);
            long long v73 = *(_OWORD *)&v72->__r_.__value_.__l.__data_;
            v102.__r_.__value_.__r.__words[2] = v72->__r_.__value_.__r.__words[2];
            *(_OWORD *)&v102.__r_.__value_.__l.__data_ = v73;
            v72->__r_.__value_.__l.__size_ = 0;
            v72->__r_.__value_.__r.__words[2] = 0;
            v72->__r_.__value_.__r.__words[0] = 0;
            if (SHIBYTE(v85.__r_.__value_.__r.__words[2]) < 0) {
              operator delete(v85.__r_.__value_.__l.__data_);
            }
            if (SBYTE7(v96) < 0) {
              operator delete((void *)v95);
            }
            if (SHIBYTE(v104.__r_.__value_.__r.__words[2]) < 0) {
              operator delete(v104.__r_.__value_.__l.__data_);
            }
            if (SHIBYTE(v103.__r_.__value_.__r.__words[2]) < 0) {
              operator delete(v103.__r_.__value_.__l.__data_);
            }
            if (SHIBYTE(v105.__r_.__value_.__r.__words[2]) < 0) {
              operator delete(v105.__r_.__value_.__l.__data_);
            }
            __n128 v74 = ZinObjectNameFactory::ZinObjectNameFactory(&v95, &v102);
            uint64_t v75 = *((void *)a9 + 2);
            uint64_t v76 = (uint64_t)*v82;
            uint64_t v77 = *(unsigned int *)((*(uint64_t (**)(ZinMirSpatialSplitUtils *, void, void, __n128))(*(void *)*v82 + 32))(*v82, 0, 0, v74)+ 88);
            uint64_t v84 = 0;
            v83[0] = 0;
            v83[168] = 0;
            ZinBuilder::CreateNEBypass(v75, (uint64_t)&v95, v76, v77, &v84, 0, (uint64_t)v83, 1.0);
          }
          ++v56;
        }
        while (v56 != v57);
        uint64_t v56 = *(ZinIrTensor ***)v89;
      }
      if (v56)
      {
        *(void *)&v89[8] = v56;
        operator delete(v56);
      }
    }
  }
  uint64_t v91 = &unk_26C359A08;
  if (v92)
  {
    uint64_t v93 = v92;
    operator delete(v92);
  }
  return 0;
}

void sub_211276FEC(_Unwind_Exception *a1)
{
  *(void *)(v1 + 112) = &unk_26C34DA98;
  if (SLOBYTE(STACK[0x27F]) < 0) {
    operator delete(*(void **)(v1 + 120));
  }
  if (*(char *)(v2 - 217) < 0) {
    operator delete(*(void **)(v1 + 288));
  }
  uint64_t v4 = *(void **)v1;
  if (*(void *)v1)
  {
    *(void *)(v1 + 8) = v4;
    operator delete(v4);
  }
  *(void *)(v1 + 40) = &unk_26C359A08;
  uint64_t v5 = *(void **)(v1 + 48);
  if (v5)
  {
    *(void *)(v1 + 56) = v5;
    operator delete(v5);
  }
  _Unwind_Resume(a1);
}

uint64_t ZinMirSpatialSplitter::CreateTilingHelpers(uint64_t a1, uint64_t a2, uint64_t a3, LayerTilingHelper *a4)
{
  return LayerTilingHelper::Create((void *)(a2 + 72), *(const ZinIrOpLayer **)(a1 + 48), (uint64_t)a4, a4);
}

uint64_t ZinMirSpatialSplitter::InitializeShapeDependentTransforms(uint64_t this)
{
  if (*(unsigned char *)(*(void *)(*(void *)(this + 16) + 8) + 492))
  {
    memset(v1, 0, sizeof(v1));
    int v2 = 1065353216;
    std::optional<std::unordered_map<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>>::operator=[abi:ne180100]<std::unordered_map<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,void>(this + 128, (uint64_t *)v1);
    return std::__hash_table<std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::__unordered_map_hasher<unsigned long,std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::hash<unsigned long>,std::equal_to<unsigned long>,true>,std::__unordered_map_equal<unsigned long,std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::equal_to<unsigned long>,std::hash<unsigned long>,true>,std::allocator<std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>>>::~__hash_table((uint64_t)v1);
  }
  return this;
}

void sub_2112775FC(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
}

uint64_t ZinMirSpatialSplitter::TransferShapeDependentTransforms(ZinMirSpatialSplitter *this, ZinIrContext *a2)
{
  return ZinSpatialSplitTransform::TransferShapeDependentTransformsToContext((uint64_t)this + 128, (uint64_t)a2);
}

uint64_t ZinMirSpatialSplitter::CreateSplitLayer(uint64_t a1, uint64_t **a2, uint64_t a3, SplitInfo *a4, uint64_t a5, uint64_t *a6, TiledLayerTensorRegions *a7, uint64_t a8, uint64_t a9, ZinIrOpLayer **a10)
{
  uint64_t v15 = a10;
  __p[0] = &a9;
  int v16 = (const ZinIrOpLayer **)(std::__hash_table<std::__hash_value_type<ZinIrOpLayer *,LayerTilingHelper>,std::__unordered_map_hasher<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,LayerTilingHelper>,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,true>,std::__unordered_map_equal<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,LayerTilingHelper>,std::equal_to<ZinIrOpLayer *>,std::hash<ZinIrOpLayer *>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer *,LayerTilingHelper>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer * const&>,std::tuple<>>(a5, &a9, (uint64_t)&std::piecewise_construct, (void **)__p)+ 3);
  uint64_t v17 = *(SplitPatternHandlerMgr **)(a1 + 48);
  SplitInfo::GetSplitDimensions(a4, (char **)__p);
  uint64_t Layer = LayerTilingHelper::CreateLayer(v16, a2, a6, a7, v17, __p, v15);
  if (__p[0])
  {
    __p[1] = __p[0];
    operator delete(__p[0]);
  }
  if (!Layer && *(unsigned char *)(a1 + 168))
  {
    GroupId = (unint64_t *)ZinIrOpLayer::GetGroupId(*v15);
    if (!*(unsigned char *)(a1 + 168)) {
      std::__throw_bad_optional_access[abi:ne180100]();
    }
    uint64_t SpatialSplitTransform = ZinSpatialSplitTransform::GetOrCreateSpatialSplitTransform(*GroupId, (void *)(a1 + 128));
    (*(void (**)(void **__return_ptr))(*(void *)a9 + 136))(__p);
    if (v30)
    {
      (*(void (**)(void **__return_ptr))(*(void *)a9 + 136))(__p);
      long long v24 = v28;
      uint64_t v25 = v29;
      (*(void (**)(void *__return_ptr))(*(void *)a9 + 136))(v22);
      int v26 = v23;
      ZinSpatialSplitTransform::SetPaddingInfo(SpatialSplitTransform, &v24);
    }
  }
  return Layer;
}

void sub_2112777CC(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,void *__p,uint64_t a26)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinMirSpatialSplitter::Run(ZinMirSpatialSplitter *this)
{
  v29[4] = *MEMORY[0x263EF8340];
  int v27 = 0;
  int v2 = *(ZinIrCompilerParameters **)(*((void *)this + 2) + 8);
  ZinIrCompilerParameters::getSpatialSplitMode(v2, &__p);
  uint64_t v3 = v26;
  if ((v26 & 0x80u) != 0) {
    uint64_t v3 = v25;
  }
  if (v3 == 8)
  {
    p_p = __p;
    if ((v26 & 0x80u) == 0) {
      p_p = &__p;
    }
    BOOL v5 = *p_p == 0x64656C6261736964;
    if (((char)v26 & 0x80000000) == 0)
    {
LABEL_7:
      if (v5) {
        return 0;
      }
      goto LABEL_12;
    }
  }
  else
  {
    BOOL v5 = 0;
    if (((char)v26 & 0x80000000) == 0) {
      goto LABEL_7;
    }
  }
  operator delete(__p);
  if (v5) {
    return 0;
  }
LABEL_12:
  ZinIrCompilerParameters::getSpatialSplitMode(v2, &__p);
  uint64_t v7 = v26;
  if ((v26 & 0x80u) != 0) {
    uint64_t v7 = v25;
  }
  if (v7 == 4)
  {
    int v8 = __p;
    if ((v26 & 0x80u) == 0) {
      int v8 = &__p;
    }
    BOOL v9 = *v8 == 1953719668;
    if (((char)v26 & 0x80000000) == 0)
    {
LABEL_18:
      if (v9) {
        goto LABEL_19;
      }
      goto LABEL_23;
    }
  }
  else
  {
    BOOL v9 = 0;
    if (((char)v26 & 0x80000000) == 0) {
      goto LABEL_18;
    }
  }
  operator delete(__p);
  if (v9)
  {
LABEL_19:
    long long __p = 0;
    uint64_t v10 = (void *)*((void *)this + 1);
    v29[0] = &unk_26C32F490;
    v29[1] = &__p;
    void v29[3] = v29;
    int v11 = ZinIrControlFlowGraph::TraverseForward(v10, (uint64_t)v29);
    std::__function::__value_func<ZinIrStatus ()(ZinIrBasicBlock *)>::~__value_func[abi:ne180100](v29);
    if (v11) {
      return 3;
    }
    if ((unint64_t)__p < 0x801)
    {
      int v27 = 0;
      goto LABEL_53;
    }
    return 0;
  }
LABEL_23:
  ZinIrCompilerParameters::getSpatialSplitMode(v2, &__p);
  uint64_t v12 = v26;
  if ((v26 & 0x80u) != 0) {
    uint64_t v12 = v25;
  }
  if (v12 != 6)
  {
    BOOL v17 = 0;
    if (((char)v26 & 0x80000000) == 0) {
      goto LABEL_35;
    }
LABEL_38:
    operator delete(__p);
    if (v17) {
      goto LABEL_36;
    }
LABEL_39:
    ZinIrCompilerParameters::getSpatialSplitMode(v2, &__p);
    uint64_t v19 = v26;
    if ((v26 & 0x80u) != 0) {
      uint64_t v19 = v25;
    }
    if (v19 == 4)
    {
      unint64_t v20 = __p;
      if ((v26 & 0x80u) == 0) {
        unint64_t v20 = &__p;
      }
      BOOL v21 = *v20 == 1869903201;
      if (((char)v26 & 0x80000000) == 0) {
        goto LABEL_50;
      }
    }
    else
    {
      BOOL v21 = 0;
      if (((char)v26 & 0x80000000) == 0)
      {
LABEL_50:
        if (!v21)
        {
          if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
            ZinMirSpatialSplitter::Run(v2);
          }
          return 3;
        }
        int v18 = 2;
        goto LABEL_52;
      }
    }
    operator delete(__p);
    goto LABEL_50;
  }
  uint64_t v13 = (unsigned __int16 *)__p;
  if ((v26 & 0x80u) == 0) {
    uint64_t v13 = (unsigned __int16 *)&__p;
  }
  int v14 = *(_DWORD *)v13;
  int v15 = v13[2];
  BOOL v17 = v14 == 1869440365 && v15 == 31090;
  if ((char)v26 < 0) {
    goto LABEL_38;
  }
LABEL_35:
  if (!v17) {
    goto LABEL_39;
  }
LABEL_36:
  int v18 = 1;
LABEL_52:
  int v27 = v18;
LABEL_53:
  uint64_t v22 = (void *)*((void *)this + 1);
  v28[0] = &unk_26C32F4E8;
  v28[1] = this;
  _OWORD v28[2] = &v27;
  v28[3] = v28;
  int v23 = ZinIrControlFlowGraph::TraverseForward(v22, (uint64_t)v28);
  std::__function::__value_func<ZinIrStatus ()(ZinIrBasicBlock *)>::~__value_func[abi:ne180100](v28);
  if (v23) {
    return 3;
  }
  else {
    return 0;
  }
}

void sub_211277AF0(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, ...)
{
  va_start(va, a6);
  std::__function::__value_func<ZinIrStatus ()(ZinIrBasicBlock *)>::~__value_func[abi:ne180100](va);
  _Unwind_Resume(a1);
}

void IsLayerSplittable<Subgraph>(ZinIrOpLayer *a1@<X0>, uint64_t a2@<X1>, char a3@<W2>, char a4@<W3>, int a5@<W4>, int a6@<W5>, uint64_t a7@<X6>, uint64_t a8@<X7>, void *a9@<X8>, SplitPatternHandlerMgr *a10)
{
  uint64_t v73 = *MEMORY[0x263EF8340];
  unint64_t v18 = (uint64_t)(*((void *)a1 + 12) - *((void *)a1 + 11)) >> 3;
  LOBYTE(v70) = 0;
  std::vector<BOOL>::vector(&v65, v18, (unsigned __int8 *)&v70);
  if (*(void *)a7)
  {
    operator delete(*(void **)a7);
    *(void *)a7 = 0;
    *(void *)(a7 + 8) = 0;
    *(void *)(a7 + 16) = 0;
  }
  *(void *)a7 = v65;
  *(_OWORD *)(a7 + 8) = v66;
  uint64_t v70 = 0x100000000;
  std::set<SpatialDimension>::set[abi:ne180100]((uint64_t)&v65, (unsigned int *)&v70, 2);
  uint64_t v19 = (long long *)&v71;
  std::string::size_type v71 = 0;
  uint64_t v72 = 0;
  uint64_t v70 = (uint64_t)&v71;
  if (*(void *)((*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)a1 + 32))(a1, 0, 0) + 64) == 1)
  {
    LODWORD(__p) = 0;
    std::__tree<SpatialDimension>::__erase_unique<SpatialDimension>((uint64_t)&v65, (unsigned int *)&__p);
  }
  if (*(void *)((*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)a1 + 32))(a1, 0, 0) + 72) == 1)
  {
    LODWORD(__p) = 1;
    std::__tree<SpatialDimension>::__erase_unique<SpatialDimension>((uint64_t)&v65, (unsigned int *)&__p);
  }
  if ((a4 & 1) != 0 || (__p = 0, uint64_t v63 = 0, v64 = 0, (ZinIrOpLayer::IsNoOp(a1, (uint64_t *)&__p) & 1) == 0))
  {
    int v21 = (*(uint64_t (**)(ZinIrOpLayer *))(*(void *)a1 + 112))(a1);
    char v20 = v21;
    if (a4)
    {
      if (v21) {
        goto LABEL_16;
      }
      goto LABEL_20;
    }
  }
  else
  {
    char v20 = 1;
  }
  if (__p)
  {
    uint64_t v63 = __p;
    operator delete(__p);
  }
  if (v20) {
    goto LABEL_16;
  }
LABEL_20:
  if (!ZinIrOpLayer::IsANELayer(a1)) {
    goto LABEL_53;
  }
  if (a10 && SplitPatternHandlerMgr::IsLayerCreated(a10, a1))
  {
    SplitPatternHandlerMgr::GetSupportedSplitDimension((uint64_t)a10, (uint64_t)a1);
    uint64_t v25 = v66;
    *a9 = v65;
    a9[1] = v25;
    int v23 = a9 + 1;
    uint64_t v26 = *((void *)&v66 + 1);
    a9[2] = *((void *)&v66 + 1);
    if (v26)
    {
      *(void *)(v25 + 16) = v23;
      std::string::size_type v65 = (uint64_t *)&v66;
      long long v66 = 0uLL;
      goto LABEL_126;
    }
LABEL_125:
    *a9 = v23;
    goto LABEL_126;
  }
  if (!*((void *)a1 + 25) || *((void *)a1 + 24) > 1uLL)
  {
    if (ZinIrOpLayer::IsNELayer(a1))
    {
      if ((*(unsigned int (**)(ZinIrOpLayer *))(*(void *)a1 + 408))(a1))
      {
        *(_DWORD *)uint8_t buf = 1;
        std::__tree<SpatialDimension>::__erase_unique<SpatialDimension>((uint64_t)&v65, (unsigned int *)buf);
      }
      uint64_t v27 = *((void *)a1 + 46);
      if (!v27) {
        goto LABEL_53;
      }
      uint64_t v28 = *(void *)(v27 + 64);
      if (!ZinIrBroadcastInfo::HasDimension(v28, 3)
        && !ZinIrBroadcastInfo::HasDimension(v28, 4)
        && !ZinIrBroadcastInfo::HasDimension(v28, 1))
      {
        goto LABEL_53;
      }
      if ((a6 & 1) == 0) {
        goto LABEL_16;
      }
      goto LABEL_51;
    }
    if (!ZinIrOpLayer::IsPELayer(a1)) {
      ZinAssertImpl("Only NE and PE engine layers are supported for Splitting\n");
    }
    if ((*(unsigned int (**)(ZinIrOpLayer *))(*(void *)a1 + 408))(a1))
    {
      *(_DWORD *)uint8_t buf = 1;
      std::__tree<SpatialDimension>::__erase_unique<SpatialDimension>((uint64_t)&v65, (unsigned int *)buf);
    }
    if ((*(unsigned int (**)(ZinIrOpLayer *))(*(void *)a1 + 640))(a1))
    {
      if (a6)
      {
        **(void **)a7 |= 1uLL;
      }
      else if (!DetectIncomingConstIn(a1, 0))
      {
        goto LABEL_16;
      }
    }
    if ((*(unsigned int (**)(ZinIrOpLayer *))(*(void *)a1 + 648))(a1))
    {
      if ((a6 & 1) == 0)
      {
        if (!DetectIncomingConstIn(a1, 1uLL)) {
          goto LABEL_16;
        }
        goto LABEL_53;
      }
      **(void **)a7 |= 2uLL;
    }
    else if (!a6)
    {
      goto LABEL_53;
    }
    int v29 = (*(uint64_t (**)(ZinIrOpLayer *))(*(void *)a1 + 656))(a1);
    uint64_t v30 = *(void *)a1;
    if (v29)
    {
      uint64_t v31 = *(void *)((*(uint64_t (**)(ZinIrOpLayer *))(v30 + 696))(a1) + 64);
      if (ZinIrBroadcastInfo::HasDimension(v31, 3)
        || ZinIrBroadcastInfo::HasDimension(v31, 4)
        || ZinIrBroadcastInfo::HasDimension(v31, 1))
      {
LABEL_51:
        uint64_t v32 = 1;
LABEL_52:
        **(void **)a7 |= v32;
      }
    }
    else if ((*(unsigned int (**)(ZinIrOpLayer *))(v30 + 664))(a1))
    {
      uint64_t v57 = (*(uint64_t (**)(ZinIrOpLayer *))(*(void *)a1 + 832))(a1);
      if (ZinIrBroadcastInfo::HasDimension(v57, 3)
        || ZinIrBroadcastInfo::HasDimension(v57, 4)
        || ZinIrBroadcastInfo::HasDimension(v57, 1))
      {
        uint64_t v32 = 2;
        goto LABEL_52;
      }
    }
LABEL_53:
    int v33 = *(_DWORD *)(*((void *)a1 + 8) + 8);
    switch(v33)
    {
      case 'Q':
        int v23 = a9 + 1;
        if (*((void *)a1 + 63))
        {
          uint64_t v22 = v71;
          *a9 = v70;
          a9[1] = v22;
          goto LABEL_17;
        }
        uint64_t v34 = v66;
        *a9 = v65;
        a9[1] = v34;
        goto LABEL_55;
      case 'R':
      case 'V':
      case 'W':
      case 'X':
      case '[':
LABEL_76:
        if (a5 && os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_INFO))
        {
          *(_DWORD *)uint8_t buf = 67109120;
          *(_DWORD *)&buf[4] = v33;
          _os_log_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_INFO, "unsupported: %d", buf, 8u);
        }
        goto LABEL_16;
      case 'S':
        uint64_t v45 = *(void *)(*((void *)a1 + 54) + 64);
        if (*(uint64_t *)(v45 + 32) >= 2) {
          goto LABEL_16;
        }
        if (*(uint64_t *)(v45 + 16) >= 2 && !*(unsigned char *)(a2 + 1327))
        {
          *(_DWORD *)uint8_t buf = 1;
          std::__tree<SpatialDimension>::__erase_unique<SpatialDimension>((uint64_t)&v65, (unsigned int *)buf);
        }
        if (ZinPEPoolLayer::GetPreOpsPreScaleIndex(a1) == -1) {
          goto LABEL_54;
        }
        if (a6)
        {
          unint64_t PreOpsPreScaleIndex = ZinPEPoolLayer::GetPreOpsPreScaleIndex(a1);
          *(void *)(*(void *)a7 + ((PreOpsPreScaleIndex >> 3) & 0x1FFFFFFFFFFFFFF8)) |= 1 << PreOpsPreScaleIndex;
          goto LABEL_54;
        }
        unint64_t v60 = ZinPEPoolLayer::GetPreOpsPreScaleIndex(a1);
        if (DetectIncomingConstIn(a1, v60)) {
          goto LABEL_54;
        }
        goto LABEL_16;
      case 'T':
      case 'Z':
      case '\\':
        goto LABEL_54;
      case 'U':
        uint64_t v48 = *((void *)a1 + 54);
        if (!v48) {
          goto LABEL_54;
        }
        uint64_t v49 = *(void *)(v48 + 136);
        if ((*(unsigned char *)(v49 + 448) & 0x40) != 0 && (a3 & 1) == 0) {
          goto LABEL_16;
        }
        if (*(uint64_t *)(v49 + 264) >= 2 && !*(unsigned char *)(a2 + 1327))
        {
          *(_DWORD *)uint8_t buf = 1;
          std::__tree<SpatialDimension>::__erase_unique<SpatialDimension>((uint64_t)&v65, (unsigned int *)buf);
        }
        if (*(uint64_t *)(v49 + 280) >= 2) {
          goto LABEL_16;
        }
        if (!(*(unsigned int (**)(void))(**((void **)a1 + 54) + 120))(*((void *)a1 + 54))) {
          goto LABEL_54;
        }
        (*(void (**)(uint8_t *__return_ptr, ZinIrOpLayer *))(*(void *)a1 + 128))(buf, a1);
        uint64_t v50 = *(void *)buf;
        if (v68) {
          std::__shared_weak_count::__release_shared[abi:ne180100](v68);
        }
        if (a6)
        {
          if (*((void *)a1 + 12) != *((void *)a1 + 11))
          {
            unint64_t v51 = 0;
            do
            {
              if (v50 == ZinIrOpLayer::GetInputTensor(a1, v51)) {
                *(void *)(*(void *)a7 + ((v51 >> 3) & 0x1FFFFFFFFFFFFFF8)) |= 1 << v51;
              }
              ++v51;
            }
            while (v51 < (uint64_t)(*((void *)a1 + 12) - *((void *)a1 + 11)) >> 3);
          }
        }
        else
        {
          *(void *)uint8_t buf = *(void *)(v50 + 96);
          if (a8 + 80 != std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>(a8 + 72, (ZinIrOpLayer **)buf))goto LABEL_16; {
        }
          }
LABEL_54:
        uint64_t v34 = v66;
        *a9 = v65;
        a9[1] = v34;
        int v23 = a9 + 1;
LABEL_55:
        uint64_t v35 = *((void *)&v66 + 1);
        a9[2] = *((void *)&v66 + 1);
        if (v35)
        {
          *(void *)(v34 + 16) = v23;
          std::string::size_type v65 = (uint64_t *)&v66;
          long long v66 = 0uLL;
          goto LABEL_126;
        }
        break;
      case 'Y':
        uint64_t v47 = *(void *)(*((void *)a1 + 54) + 64);
        if (*(uint64_t *)(v47 + 32) >= 2) {
          goto LABEL_16;
        }
        if (*(uint64_t *)(v47 + 16) >= 2 && !*(unsigned char *)(a2 + 1327))
        {
          *(_DWORD *)uint8_t buf = 1;
          std::__tree<SpatialDimension>::__erase_unique<SpatialDimension>((uint64_t)&v65, (unsigned int *)buf);
        }
        goto LABEL_54;
      default:
        switch(v33)
        {
          case '!':
          case '%':
            goto LABEL_16;
          case '""':
            goto LABEL_76;
          case '#':
            ZinMirSpatialSplitUtils::SpatialDimensionsInWhichReshapeCannotBeSplit(a1, (uint64_t **)buf);
            uint64_t v36 = a9 + 1;
            if (v69)
            {
              long long v37 = v71;
              *a9 = v70;
              a9[1] = v37;
              uint64_t v38 = v72;
              a9[2] = v72;
              if (v38)
              {
                v37[2] = v36;
                uint64_t v70 = (uint64_t)&v71;
                std::string::size_type v71 = 0;
                uint64_t v72 = 0;
                goto LABEL_138;
              }
            }
            else
            {
              uint64_t v58 = v66;
              *a9 = v65;
              a9[1] = v58;
              uint64_t v59 = *((void *)&v66 + 1);
              a9[2] = *((void *)&v66 + 1);
              if (v59)
              {
                *(void *)(v58 + 16) = v36;
                std::string::size_type v65 = (uint64_t *)&v66;
                long long v66 = 0uLL;
                goto LABEL_138;
              }
            }
            *a9 = v36;
LABEL_138:
            std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)buf, v68);
            break;
          case '$':
            uint64_t v52 = v65;
            uint64_t v19 = &v66;
            int64x2_t v40 = (uint64_t *)&v66;
            if (v65 == (uint64_t *)&v66) {
              goto LABEL_123;
            }
            do
            {
              if (*((_DWORD *)v52 + 7)) {
                int v53 = 4;
              }
              else {
                int v53 = 3;
              }
              if (ZinViewLayer::IsSplittable((uint64_t)a1, v53))
              {
                unint64_t v54 = (uint64_t *)v52[1];
                if (v54)
                {
                  do
                  {
                    uint64_t v55 = v54;
                    unint64_t v54 = (uint64_t *)*v54;
                  }
                  while (v54);
                }
                else
                {
                  do
                  {
                    uint64_t v55 = (uint64_t *)v52[2];
                    BOOL v44 = *v55 == (void)v52;
                    uint64_t v52 = v55;
                  }
                  while (!v44);
                }
              }
              else
              {
                uint64_t v55 = std::__tree<std::__value_type<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,ZinIrHazardGraph::EdgeType>,std::__map_value_compare<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,std::__value_type<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,ZinIrHazardGraph::EdgeType>,HazardEdgeCompare,true>,std::allocator<std::__value_type<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,ZinIrHazardGraph::EdgeType>>>::__remove_node_pointer(&v65, v52);
                operator delete(v52);
              }
              uint64_t v52 = v55;
            }
            while (v55 != (uint64_t *)&v66);
            goto LABEL_122;
          default:
            if (v33 != 7) {
              goto LABEL_76;
            }
            unint64_t v39 = v65;
            uint64_t v19 = &v66;
            int64x2_t v40 = (uint64_t *)&v66;
            if (v65 == (uint64_t *)&v66) {
              goto LABEL_123;
            }
            do
            {
              if (*((_DWORD *)v39 + 7)) {
                int v41 = 4;
              }
              else {
                int v41 = 3;
              }
              if (ZinConcatLayer::IsSplittable((uint64_t)a1, v41))
              {
                long long v42 = (uint64_t *)v39[1];
                if (v42)
                {
                  do
                  {
                    uint64_t v43 = v42;
                    long long v42 = (uint64_t *)*v42;
                  }
                  while (v42);
                }
                else
                {
                  do
                  {
                    uint64_t v43 = (uint64_t *)v39[2];
                    BOOL v44 = *v43 == (void)v39;
                    unint64_t v39 = v43;
                  }
                  while (!v44);
                }
              }
              else
              {
                uint64_t v43 = std::__tree<std::__value_type<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,ZinIrHazardGraph::EdgeType>,std::__map_value_compare<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,std::__value_type<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,ZinIrHazardGraph::EdgeType>,HazardEdgeCompare,true>,std::allocator<std::__value_type<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,ZinIrHazardGraph::EdgeType>>>::__remove_node_pointer(&v65, v39);
                operator delete(v39);
              }
              unint64_t v39 = v43;
            }
            while (v43 != (uint64_t *)&v66);
LABEL_122:
            int64x2_t v40 = v65;
LABEL_123:
            *a9 = v40;
            long long v56 = v66;
            a9[1] = v66;
            int v23 = a9 + 1;
            a9[2] = *((void *)&v56 + 1);
            if (!*((void *)&v56 + 1)) {
              goto LABEL_125;
            }
            *(void *)(v56 + 16) = v23;
            std::string::size_type v65 = (uint64_t *)&v66;
            goto LABEL_19;
        }
        goto LABEL_126;
    }
    goto LABEL_125;
  }
LABEL_16:
  uint64_t v22 = v71;
  *a9 = v70;
  a9[1] = v22;
  int v23 = a9 + 1;
LABEL_17:
  uint64_t v24 = v72;
  a9[2] = v72;
  if (!v24) {
    goto LABEL_125;
  }
  v22[2] = v23;
  uint64_t v70 = (uint64_t)&v71;
LABEL_19:
  *(void *)uint64_t v19 = 0;
  *((void *)v19 + 1) = 0;
LABEL_126:
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v70, v71);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v65, (void *)v66);
}

void sub_2112785BC(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, void *__p, uint64_t a12, uint64_t a13, char a14, void *a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,char a21,void *a22)
{
}

BOOL DetectIncomingConstIn(const ZinPELayer *a1, unint64_t a2)
{
  uint64_t v2 = *((void *)a1 + 11);
  uint64_t v3 = *((void *)a1 + 12);
  if (v2 == v3) {
    return 0;
  }
  if (a2 >= (v3 - v2) >> 3) {
    std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
  }
  uint64_t v4 = *(void *)(v2 + 8 * a2);
  if ((*(_DWORD *)(*(void *)(v4 + 64) + 8) - 28) >= 3)
  {
    int v8 = 0;
    BOOL v9 = 0;
    uint64_t v10 = 0;
    std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(&v8, *(const void **)(v4 + 88), *(void *)(v4 + 96), (uint64_t)(*(void *)(v4 + 96) - *(void *)(v4 + 88)) >> 3);
    if (v9 == v8 || (unint64_t)(v9 - v8) > 8)
    {
      BOOL v6 = 0;
      uint64_t v5 = 0;
      if (!v8) {
        return v5;
      }
    }
    else
    {
      BOOL v6 = (*(_DWORD *)(*(void *)(*(void *)v8 + 64) + 8) - 28) < 3;
    }
    BOOL v9 = v8;
    operator delete(v8);
    return v6;
  }
  return 1;
}

uint64_t ZinMirSplitSpatially(const ZinIrControlFlowGraph *a1, uint64_t a2)
{
  ZinIrCompilerParameters::getSpatialSplitMode(*(ZinIrCompilerParameters **)(a2 + 8), v20);
  if (*(char *)(a2 + 39) < 0) {
    std::string::__init_copy_ctor_external(&v19, *(const std::string::value_type **)(a2 + 16), *(void *)(a2 + 24));
  }
  else {
    std::string v19 = *(std::string *)(a2 + 16);
  }
  std::string::basic_string[abi:ne180100]<0>(v17, "before_spatial_splitting");
  ZinIrCompilerParameters::ZinIrCompilerParameters(&v16, *(const ZinIrCompilerParameters **)(a2 + 8));
  ZinVisualization::CreateDotGraphAndLogConditionally((uint64_t)a1, (std::string::size_type)v17, (ZinIrCompilerParameters *)&v16, (uint64_t)&v19, 256);
  ZinIrCompilerParameters::~ZinIrCompilerParameters((ZinIrCompilerParameters *)&v16);
  if (v18 < 0) {
    operator delete(v17[0]);
  }
  if ((v21 & 0x80u) == 0) {
    int64_t v4 = v21;
  }
  else {
    int64_t v4 = (int64_t)v20[1];
  }
  if (v4 > 14)
  {
    if (v4 == 15)
    {
      if ((v21 & 0x80u) == 0) {
        BOOL v9 = v20;
      }
      else {
        BOOL v9 = (void **)v20[0];
      }
      uint64_t v10 = "generic-dag-exp";
    }
    else
    {
      if (v4 != 18) {
        goto LABEL_36;
      }
      if ((v21 & 0x80u) == 0) {
        BOOL v9 = v20;
      }
      else {
        BOOL v9 = (void **)v20[0];
      }
      uint64_t v10 = "generic-dag-memory";
    }
    if (memcmp(v9, v10, v4)) {
      goto LABEL_36;
    }
  }
  else
  {
    if (v4 == 6)
    {
      if ((v21 & 0x80u) == 0) {
        int v11 = v20;
      }
      else {
        int v11 = (void **)v20[0];
      }
      if (!memcmp(v11, "manual", 6uLL))
      {
        uint64_t v12 = ZinMirSpatialSplitUtils::ExecuteManualMode((uint64_t)a1, a2);
        goto LABEL_38;
      }
      goto LABEL_36;
    }
    if (v4 != 11) {
      goto LABEL_36;
    }
    uint64_t v5 = v20;
    if ((v21 & 0x80u) != 0) {
      uint64_t v5 = (void **)v20[0];
    }
    BOOL v6 = *v5;
    uint64_t v7 = *(uint64_t *)((char *)v5 + 3);
    if (v6 != (void *)0x2D636972656E6567 || v7 != 0x6761642D63697265)
    {
LABEL_36:
      uint64_t v12 = ZinMirSpatialSplitUtils::ExecuteLegacyMode((uint64_t)a1, a2);
      goto LABEL_38;
    }
  }
  uint64_t v12 = ZinMirSpatialSplitUtils::ExecuteGenericDAGMode(a1, (ZinIrCompilerParameters **)a2);
LABEL_38:
  uint64_t v13 = v12;
  std::string::basic_string[abi:ne180100]<0>(v17, "after_spatial_splitting");
  ZinIrCompilerParameters::ZinIrCompilerParameters(&v15, *(const ZinIrCompilerParameters **)(a2 + 8));
  ZinVisualization::CreateDotGraphAndLogConditionally((uint64_t)a1, (std::string::size_type)v17, (ZinIrCompilerParameters *)&v15, (uint64_t)&v19, 256);
  ZinIrCompilerParameters::~ZinIrCompilerParameters((ZinIrCompilerParameters *)&v15);
  if (v18 < 0) {
    operator delete(v17[0]);
  }
  if (SHIBYTE(v19.__r_.__value_.__r.__words[2]) < 0) {
    operator delete(v19.__r_.__value_.__l.__data_);
  }
  if ((char)v21 < 0) {
    operator delete(v20[0]);
  }
  return v13;
}

void sub_2112789B8(_Unwind_Exception *a1)
{
  if (*(char *)(v1 - 33) < 0) {
    operator delete(*(void **)(v1 - 56));
  }
  _Unwind_Resume(a1);
}

uint64_t std::vector<ProducerConsumerChain>::__push_back_slow_path<ProducerConsumerChain const&>(uint64_t *a1, uint64_t a2)
{
  uint64_t v3 = *a1;
  unint64_t v4 = 0x8E38E38E38E38E39 * ((a1[1] - *a1) >> 3);
  unint64_t v5 = v4 + 1;
  if (v4 + 1 > 0x38E38E38E38E38ELL) {
    std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
  }
  uint64_t v7 = (uint64_t)(a1 + 2);
  unint64_t v8 = 0x8E38E38E38E38E39 * ((a1[2] - v3) >> 3);
  if (2 * v8 > v5) {
    unint64_t v5 = 2 * v8;
  }
  if (v8 >= 0x1C71C71C71C71C7) {
    unint64_t v9 = 0x38E38E38E38E38ELL;
  }
  else {
    unint64_t v9 = v5;
  }
  BOOL v17 = a1 + 2;
  if (v9) {
    uint64_t v10 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ANEDebugInfo::DebugInfoInMem::TD>>(v7, v9);
  }
  else {
    uint64_t v10 = 0;
  }
  uint64_t v13 = v10;
  int v14 = &v10[72 * v4];
  std::string v16 = &v10[72 * v9];
  std::construct_at[abi:ne180100]<ProducerConsumerChain,ProducerConsumerChain const&,ProducerConsumerChain*>((uint64_t)v14, a2);
  std::string v15 = v14 + 72;
  std::vector<ProducerConsumerChain>::__swap_out_circular_buffer(a1, &v13);
  uint64_t v11 = a1[1];
  std::__split_buffer<ProducerConsumerChain>::~__split_buffer((uint64_t)&v13);
  return v11;
}

void sub_211278B38(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::__split_buffer<ProducerConsumerChain>::~__split_buffer((uint64_t)va);
  _Unwind_Resume(a1);
}

uint64_t std::construct_at[abi:ne180100]<ProducerConsumerChain,ProducerConsumerChain const&,ProducerConsumerChain*>(uint64_t a1, uint64_t a2)
{
  *(_DWORD *)a1 = *(_DWORD *)a2;
  *(void *)(a1 + 8) = 0;
  *(void *)(a1 + 16) = 0;
  *(void *)(a1 + 24) = 0;
  std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>((void *)(a1 + 8), *(const void **)(a2 + 8), *(void *)(a2 + 16), (uint64_t)(*(void *)(a2 + 16) - *(void *)(a2 + 8)) >> 3);
  std::unordered_set<ZinANELayer const*>::unordered_set(a1 + 32, a2 + 32);
  return a1;
}

void sub_211278BB4(_Unwind_Exception *exception_object)
{
  unint64_t v4 = *v2;
  if (*v2)
  {
    *(void *)(v1 + 16) = v4;
    operator delete(v4);
  }
  _Unwind_Resume(exception_object);
}

uint64_t std::vector<ProducerConsumerChain>::__swap_out_circular_buffer(uint64_t *a1, void *a2)
{
  uint64_t result = std::__uninitialized_allocator_move_if_noexcept[abi:ne180100]<std::allocator<ProducerConsumerChain>,std::reverse_iterator<ProducerConsumerChain*>,std::reverse_iterator<ProducerConsumerChain*>,std::reverse_iterator<ProducerConsumerChain*>>((uint64_t)(a1 + 2), a1[1], a1[1], *a1, *a1, a2[1], a2[1]);
  a2[1] = v5;
  uint64_t v6 = *a1;
  *a1 = v5;
  a2[1] = v6;
  uint64_t v7 = a1[1];
  a1[1] = a2[2];
  a2[2] = v7;
  uint64_t v8 = a1[2];
  a1[2] = a2[3];
  a2[3] = v8;
  *a2 = a2[1];
  return result;
}

uint64_t std::__uninitialized_allocator_move_if_noexcept[abi:ne180100]<std::allocator<ProducerConsumerChain>,std::reverse_iterator<ProducerConsumerChain*>,std::reverse_iterator<ProducerConsumerChain*>,std::reverse_iterator<ProducerConsumerChain*>>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  if (a3 != a5)
  {
    uint64_t v11 = 0;
    do
    {
      uint64_t v12 = a7 + v11;
      uint64_t v13 = a3 + v11;
      *(_DWORD *)(v12 - 72) = *(_DWORD *)(a3 + v11 - 72);
      *(void *)(v12 - 56) = 0;
      *(void *)(v12 - 48) = 0;
      *(void *)(v12 - 64) = 0;
      *(_OWORD *)(v12 - 64) = *(_OWORD *)(a3 + v11 - 64);
      *(void *)(v12 - 48) = *(void *)(a3 + v11 - 48);
      *(void *)(v13 - 64) = 0;
      *(void *)(v13 - 56) = 0;
      *(void *)(v13 - 48) = 0;
      std::__hash_table<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::__unordered_map_hasher<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::hash<long>,std::equal_to<long>,true>,std::__unordered_map_equal<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::equal_to<long>,std::hash<long>,true>,std::allocator<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>>>::__hash_table(a7 + v11 - 40, (uint64_t *)(a3 + v11 - 40));
      v11 -= 72;
    }
    while (a3 + v11 != a5);
  }
  return a6;
}

void std::__destroy_at[abi:ne180100]<ProducerConsumerChain,0>(uint64_t a1)
{
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table(a1 + 32);
  uint64_t v2 = *(void **)(a1 + 8);
  if (v2)
  {
    *(void *)(a1 + 16) = v2;
    operator delete(v2);
  }
}

uint64_t std::__split_buffer<ProducerConsumerChain>::~__split_buffer(uint64_t a1)
{
  uint64_t v3 = *(void *)(a1 + 8);
  for (uint64_t i = *(void *)(a1 + 16); i != v3; uint64_t i = *(void *)(a1 + 16))
  {
    *(void *)(a1 + 16) = i - 72;
    std::__destroy_at[abi:ne180100]<ProducerConsumerChain,0>(i - 72);
  }
  if (*(void *)a1) {
    operator delete(*(void **)a1);
  }
  return a1;
}

unsigned char *std::__optional_move_base<ProducerConsumerChain,false>::__optional_move_base[abi:ne180100](unsigned char *a1, uint64_t a2)
{
  *a1 = 0;
  a1[72] = 0;
  std::__optional_storage_base<ProducerConsumerChain,false>::__construct_from[abi:ne180100]<std::__optional_move_base<ProducerConsumerChain,false>>((uint64_t)a1, a2);
  return a1;
}

uint64_t std::__optional_storage_base<ProducerConsumerChain,false>::__construct_from[abi:ne180100]<std::__optional_move_base<ProducerConsumerChain,false>>(uint64_t result, uint64_t a2)
{
  if (*(unsigned char *)(a2 + 72))
  {
    uint64_t v2 = result;
    *(_DWORD *)uint64_t result = *(_DWORD *)a2;
    *(void *)(result + 16) = 0;
    *(void *)(result + 24) = 0;
    *(void *)(result + 8) = 0;
    *(_OWORD *)(result + 8) = *(_OWORD *)(a2 + 8);
    *(void *)(result + 24) = *(void *)(a2 + 24);
    *(void *)(a2 + 8) = 0;
    *(void *)(a2 + 16) = 0;
    *(void *)(a2 + 24) = 0;
    uint64_t result = std::__hash_table<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::__unordered_map_hasher<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::hash<long>,std::equal_to<long>,true>,std::__unordered_map_equal<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::equal_to<long>,std::hash<long>,true>,std::allocator<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>>>::__hash_table(result + 32, (uint64_t *)(a2 + 32));
    *(unsigned char *)(v2 + 72) = 1;
  }
  return result;
}

uint64_t std::__optional_destruct_base<ProducerConsumerChain,false>::~__optional_destruct_base[abi:ne180100](uint64_t a1)
{
  if (*(unsigned char *)(a1 + 72))
  {
    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table(a1 + 32);
    uint64_t v2 = *(void **)(a1 + 8);
    if (v2)
    {
      *(void *)(a1 + 16) = v2;
      operator delete(v2);
    }
  }
  return a1;
}

void std::vector<LayerTilingHelper>::__swap_out_circular_buffer(uint64_t *a1, void *a2)
{
  uint64_t v5 = *a1;
  uint64_t v4 = a1[1];
  uint64_t v6 = a2[1];
  while (v4 != v5)
  {
    v6 -= 192;
    v4 -= 192;
    std::construct_at[abi:ne180100]<LayerTilingHelper,LayerTilingHelper,LayerTilingHelper*>(v6, v4);
  }
  a2[1] = v6;
  uint64_t v7 = *a1;
  *a1 = v6;
  a2[1] = v7;
  uint64_t v8 = a1[1];
  a1[1] = a2[2];
  a2[2] = v8;
  uint64_t v9 = a1[2];
  a1[2] = a2[3];
  a2[3] = v9;
  *a2 = a2[1];
}

void *std::__allocate_at_least[abi:ne180100]<std::allocator<LayerTilingHelper>>(uint64_t a1, unint64_t a2)
{
  if (a2 >= 0x155555555555556) {
    std::__throw_bad_array_new_length[abi:ne180100]();
  }
  return operator new(192 * a2);
}

__n128 std::construct_at[abi:ne180100]<LayerTilingHelper,LayerTilingHelper,LayerTilingHelper*>(uint64_t a1, uint64_t a2)
{
  *(_OWORD *)a1 = *(_OWORD *)a2;
  *(void *)(a1 + 24) = 0;
  *(void *)(a1 + 32) = 0;
  *(void *)(a1 + 16) = 0;
  *(_OWORD *)(a1 + 16) = *(_OWORD *)(a2 + 16);
  *(void *)(a1 + 32) = *(void *)(a2 + 32);
  *(void *)(a2 + 24) = 0;
  *(void *)(a2 + 32) = 0;
  *(void *)(a2 + 16) = 0;
  uint64_t v2 = *(void *)(a2 + 48);
  *(void *)(a1 + 40) = *(void *)(a2 + 40);
  *(void *)(a1 + 48) = v2;
  *(void *)(a1 + 56) = *(void *)(a2 + 56);
  *(void *)(a2 + 48) = 0;
  *(void *)(a2 + 56) = 0;
  *(void *)(a2 + 40) = 0;
  long long v3 = *(_OWORD *)(a2 + 80);
  long long v4 = *(_OWORD *)(a2 + 96);
  long long v5 = *(_OWORD *)(a2 + 128);
  *(_OWORD *)(a1 + 112) = *(_OWORD *)(a2 + 112);
  *(_OWORD *)(a1 + 128) = v5;
  *(_OWORD *)(a1 + 80) = v3;
  *(_OWORD *)(a1 + 96) = v4;
  *(_OWORD *)(a1 + 64) = *(_OWORD *)(a2 + 64);
  *(void *)(a1 + 152) = 0;
  *(void *)(a1 + 160) = 0;
  *(void *)(a1 + 144) = 0;
  *(_OWORD *)(a1 + 144) = *(_OWORD *)(a2 + 144);
  *(void *)(a1 + 160) = *(void *)(a2 + 160);
  *(void *)(a2 + 144) = 0;
  *(void *)(a2 + 152) = 0;
  *(void *)(a2 + 160) = 0;
  *(void *)(a1 + 168) = 0;
  *(void *)(a1 + 176) = 0;
  *(void *)(a1 + 184) = 0;
  __n128 result = *(__n128 *)(a2 + 168);
  *(__n128 *)(a1 + 168) = result;
  *(void *)(a1 + 184) = *(void *)(a2 + 184);
  *(void *)(a2 + 168) = 0;
  *(void *)(a2 + 176) = 0;
  *(void *)(a2 + 184) = 0;
  return result;
}

void std::__destroy_at[abi:ne180100]<LayerTilingHelper,0>(void *a1)
{
  uint64_t v2 = (void *)a1[21];
  if (v2)
  {
    a1[22] = v2;
    operator delete(v2);
  }
  long long v3 = (void *)a1[18];
  if (v3)
  {
    a1[19] = v3;
    operator delete(v3);
  }
  long long v4 = (void *)a1[5];
  if (v4) {
    operator delete(v4);
  }
  long long v5 = (void *)a1[2];
  if (v5)
  {
    a1[3] = v5;
    operator delete(v5);
  }
}

uint64_t std::__split_buffer<LayerTilingHelper>::~__split_buffer(uint64_t a1)
{
  uint64_t v3 = *(void *)(a1 + 8);
  for (uint64_t i = *(void *)(a1 + 16); i != v3; uint64_t i = *(void *)(a1 + 16))
  {
    *(void *)(a1 + 16) = i - 192;
    std::__destroy_at[abi:ne180100]<LayerTilingHelper,0>((void *)(i - 192));
  }
  if (*(void *)a1) {
    operator delete(*(void **)a1);
  }
  return a1;
}

void *std::vector<LogicalDimensions>::vector(void *a1, unint64_t a2)
{
  *a1 = 0;
  a1[1] = 0;
  a1[2] = 0;
  if (a2)
  {
    std::vector<ANEDebugInfo::DebugInfoInMem::TD>::__vallocate[abi:ne180100](a1, a2);
    uint64_t v4 = a1[1];
    uint64_t v5 = v4 + 72 * a2;
    int64x2_t v6 = vdupq_n_s64(1uLL);
    do
    {
      *(int64x2_t *)uint64_t v4 = v6;
      *(int64x2_t *)(v4 + 16) = v6;
      *(void *)(v4 + 32) = 1;
      *(_OWORD *)(v4 + 40) = 0uLL;
      *(_OWORD *)(v4 + 56) = 0uLL;
      v4 += 72;
    }
    while (v4 != v5);
    a1[1] = v5;
  }
  return a1;
}

void sub_211279114(_Unwind_Exception *exception_object)
{
  uint64_t v3 = *(void **)v1;
  if (*(void *)v1)
  {
    *(void *)(v1 + 8) = v3;
    operator delete(v3);
  }
  _Unwind_Resume(exception_object);
}

void *std::vector<ZinTensorRegion>::vector(void *a1, unint64_t a2)
{
  *a1 = 0;
  a1[1] = 0;
  a1[2] = 0;
  if (a2)
  {
    std::vector<ZinDramDependentInfo>::__vallocate[abi:ne180100](a1, a2);
    uint64_t v4 = a1[1];
    uint64_t v5 = v4 + 80 * a2;
    int64x2_t v6 = vdupq_n_s64(1uLL);
    do
    {
      *(void *)(v4 + 32) = 0;
      *(_OWORD *)uint64_t v4 = 0uLL;
      *(_OWORD *)(v4 + 16) = 0uLL;
      *(int64x2_t *)(v4 + 40) = v6;
      *(int64x2_t *)(v4 + 56) = v6;
      *(void *)(v4 + 72) = 1;
      v4 += 80;
    }
    while (v4 != v5);
    a1[1] = v5;
  }
  return a1;
}

void sub_2112791A8(_Unwind_Exception *exception_object)
{
  uint64_t v3 = *(void **)v1;
  if (*(void *)v1)
  {
    *(void *)(v1 + 8) = v3;
    operator delete(v3);
  }
  _Unwind_Resume(exception_object);
}

void *std::vector<ZinTensorPosition>::vector(void *a1, unint64_t a2, long long *a3)
{
  *a1 = 0;
  a1[1] = 0;
  a1[2] = 0;
  if (a2)
  {
    std::vector<ZinMirInterchangeInfo>::__vallocate[abi:ne180100](a1, a2);
    uint64_t v6 = a1[1];
    uint64_t v7 = v6 + 40 * a2;
    uint64_t v8 = 40 * a2;
    do
    {
      long long v9 = *a3;
      long long v10 = a3[1];
      *(void *)(v6 + 32) = *((void *)a3 + 4);
      *(_OWORD *)uint64_t v6 = v9;
      *(_OWORD *)(v6 + 16) = v10;
      v6 += 40;
      v8 -= 40;
    }
    while (v8);
    a1[1] = v7;
  }
  return a1;
}

void sub_21127923C(_Unwind_Exception *exception_object)
{
  uint64_t v3 = *(void **)v1;
  if (*(void *)v1)
  {
    *(void *)(v1 + 8) = v3;
    operator delete(v3);
  }
  _Unwind_Resume(exception_object);
}

BOOL LogicalDimensions::operator==(void *a1, void *a2)
{
  BOOL result = ZinTensorPosition::operator==(a1, a2);
  if (result) {
    return a1[5] == a2[5] && a1[6] == a2[6] && a1[7] == a2[7] && a1[8] == a2[8];
  }
  return result;
}

void std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__assign_with_size[abi:ne180100]<std::vector<std::optional<TiledLayerTensorRegions>>*,std::vector<std::optional<TiledLayerTensorRegions>>*>(uint64_t a1, uint64_t *a2, uint64_t *a3, unint64_t a4)
{
  uint64_t v8 = a1 + 16;
  long long v9 = *(void ***)a1;
  if (0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*(void *)(a1 + 16) - *(void *)a1) >> 3) < a4)
  {
    std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__vdeallocate((void ***)a1);
    if (a4 > 0xAAAAAAAAAAAAAAALL) {
      std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
    }
    unint64_t v10 = 0x5555555555555556 * ((uint64_t)(*(void *)(a1 + 16) - *(void *)a1) >> 3);
    if (v10 <= a4) {
      unint64_t v10 = a4;
    }
    if (0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*(void *)(a1 + 16) - *(void *)a1) >> 3) >= 0x555555555555555) {
      unint64_t v11 = 0xAAAAAAAAAAAAAAALL;
    }
    else {
      unint64_t v11 = v10;
    }
    std::vector<std::string>::__vallocate[abi:ne180100]((void *)a1, v11);
    uint64_t v12 = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::vector<std::optional<TiledLayerTensorRegions>>>,std::vector<std::optional<TiledLayerTensorRegions>>*,std::vector<std::optional<TiledLayerTensorRegions>>*,std::vector<std::optional<TiledLayerTensorRegions>>*>(v8, a2, a3, *(void **)(a1 + 8));
    goto LABEL_11;
  }
  if (0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*(void *)(a1 + 8) - (void)v9) >> 3) < a4)
  {
    uint64_t v13 = (TiledLayerTensorRegions **)&a2[(uint64_t)(*(void *)(a1 + 8) - (void)v9) >> 3];
    std::__copy_loop<std::_ClassicAlgPolicy>::operator()[abi:ne180100]<std::vector<std::optional<TiledLayerTensorRegions>> *,std::vector<std::optional<TiledLayerTensorRegions>> *,std::vector<std::optional<TiledLayerTensorRegions>> *>((int)&v17, (TiledLayerTensorRegions **)a2, v13, (uint64_t)v9);
    uint64_t v12 = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::vector<std::optional<TiledLayerTensorRegions>>>,std::vector<std::optional<TiledLayerTensorRegions>>*,std::vector<std::optional<TiledLayerTensorRegions>>*,std::vector<std::optional<TiledLayerTensorRegions>>*>(v8, (uint64_t *)v13, a3, *(void **)(a1 + 8));
LABEL_11:
    *(void *)(a1 + 8) = v12;
    return;
  }
  std::__copy_loop<std::_ClassicAlgPolicy>::operator()[abi:ne180100]<std::vector<std::optional<TiledLayerTensorRegions>> *,std::vector<std::optional<TiledLayerTensorRegions>> *,std::vector<std::optional<TiledLayerTensorRegions>> *>((int)&v18, (TiledLayerTensorRegions **)a2, (TiledLayerTensorRegions **)a3, (uint64_t)v9);
  std::string v15 = v14;
  std::string v16 = *(void ***)(a1 + 8);
  if (v16 != v14)
  {
    do
    {
      v16 -= 3;
      std::string v19 = v16;
      std::vector<std::optional<TiledLayerTensorRegions>>::__destroy_vector::operator()[abi:ne180100](&v19);
    }
    while (v16 != v15);
  }
  *(void *)(a1 + 8) = v15;
}

void sub_211279440(_Unwind_Exception *a1)
{
  *(void *)(v1 + 8) = v2;
  _Unwind_Resume(a1);
}

void sub_211279448(_Unwind_Exception *a1)
{
  *(void *)(v1 + 8) = v2;
  _Unwind_Resume(a1);
}

void std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__vdeallocate(void ***a1)
{
  uint64_t v1 = *a1;
  if (*a1)
  {
    uint64_t v3 = a1[1];
    uint64_t v4 = *a1;
    if (v3 != v1)
    {
      do
      {
        v3 -= 3;
        uint64_t v5 = v3;
        std::vector<std::optional<TiledLayerTensorRegions>>::__destroy_vector::operator()[abi:ne180100](&v5);
      }
      while (v3 != v1);
      uint64_t v4 = *a1;
    }
    a1[1] = v1;
    operator delete(v4);
    *a1 = 0;
    a1[1] = 0;
    a1[2] = 0;
  }
}

void *std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::vector<std::optional<TiledLayerTensorRegions>>>,std::vector<std::optional<TiledLayerTensorRegions>>*,std::vector<std::optional<TiledLayerTensorRegions>>*,std::vector<std::optional<TiledLayerTensorRegions>>*>(uint64_t a1, uint64_t *a2, uint64_t *a3, void *a4)
{
  uint64_t v4 = a4;
  unint64_t v10 = a4;
  unint64_t v11 = a4;
  v8[0] = a1;
  v8[1] = &v10;
  v8[2] = &v11;
  char v9 = 0;
  if (a2 != a3)
  {
    uint64_t v6 = a2;
    do
    {
      *uint64_t v4 = 0;
      v4[1] = 0;
      v4[2] = 0;
      std::vector<std::optional<TiledLayerTensorRegions>>::__init_with_size[abi:ne180100]<std::optional<TiledLayerTensorRegions>*,std::optional<TiledLayerTensorRegions>*>(v4, *v6, v6[1], 0x34F72C234F72C235 * ((v6[1] - *v6) >> 3));
      uint64_t v4 = v11 + 3;
      v11 += 3;
      v6 += 3;
    }
    while (v6 != a3);
  }
  char v9 = 1;
  std::__exception_guard_exceptions<std::_AllocatorDestroyRangeReverse<std::allocator<std::vector<std::optional<TiledLayerTensorRegions>>>,std::vector<std::optional<TiledLayerTensorRegions>>*>>::~__exception_guard_exceptions[abi:ne180100]((uint64_t)v8);
  return v4;
}

void sub_211279578(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
}

uint64_t std::__exception_guard_exceptions<std::_AllocatorDestroyRangeReverse<std::allocator<std::vector<std::optional<TiledLayerTensorRegions>>>,std::vector<std::optional<TiledLayerTensorRegions>>*>>::~__exception_guard_exceptions[abi:ne180100](uint64_t a1)
{
  if (!*(unsigned char *)(a1 + 24)) {
    std::_AllocatorDestroyRangeReverse<std::allocator<std::vector<std::optional<TiledLayerTensorRegions>>>,std::vector<std::optional<TiledLayerTensorRegions>>*>::operator()[abi:ne180100](a1);
  }
  return a1;
}

void std::_AllocatorDestroyRangeReverse<std::allocator<std::vector<std::optional<TiledLayerTensorRegions>>>,std::vector<std::optional<TiledLayerTensorRegions>>*>::operator()[abi:ne180100](uint64_t a1)
{
  uint64_t v1 = **(void ****)(a1 + 16);
  uint64_t v2 = **(void ****)(a1 + 8);
  while (v1 != v2)
  {
    v1 -= 3;
    uint64_t v3 = v1;
    std::vector<std::optional<TiledLayerTensorRegions>>::__destroy_vector::operator()[abi:ne180100](&v3);
  }
}

TiledLayerTensorRegions **std::__copy_loop<std::_ClassicAlgPolicy>::operator()[abi:ne180100]<std::vector<std::optional<TiledLayerTensorRegions>> *,std::vector<std::optional<TiledLayerTensorRegions>> *,std::vector<std::optional<TiledLayerTensorRegions>> *>(int a1, TiledLayerTensorRegions **a2, TiledLayerTensorRegions **a3, uint64_t a4)
{
  uint64_t v5 = a2;
  if (a2 != a3)
  {
    do
    {
      if (v5 != (TiledLayerTensorRegions **)a4) {
        std::vector<std::optional<TiledLayerTensorRegions>>::__assign_with_size[abi:ne180100]<std::optional<TiledLayerTensorRegions>*,std::optional<TiledLayerTensorRegions>*>(a4, *v5, v5[1], 0x34F72C234F72C235 * ((v5[1] - *v5) >> 3));
      }
      v5 += 3;
      a4 += 24;
    }
    while (v5 != a3);
    return a3;
  }
  return v5;
}

uint64_t std::vector<std::optional<TiledLayerTensorRegions>>::__assign_with_size[abi:ne180100]<std::optional<TiledLayerTensorRegions>*,std::optional<TiledLayerTensorRegions>*>(uint64_t a1, TiledLayerTensorRegions *a2, TiledLayerTensorRegions *a3, unint64_t a4)
{
  uint64_t v8 = a1 + 16;
  char v9 = *(TiledLayerTensorRegions **)a1;
  if (0x34F72C234F72C235 * ((uint64_t)(*(void *)(a1 + 16) - *(void *)a1) >> 3) < a4)
  {
    std::vector<std::optional<TiledLayerTensorRegions>>::__vdeallocate((void **)a1);
    if (a4 > 0x11A7B9611A7B961) {
      std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
    }
    unint64_t v10 = 0x69EE58469EE5846ALL * ((uint64_t)(*(void *)(a1 + 16) - *(void *)a1) >> 3);
    if (v10 <= a4) {
      unint64_t v10 = a4;
    }
    if ((unint64_t)(0x34F72C234F72C235 * ((uint64_t)(*(void *)(a1 + 16) - *(void *)a1) >> 3)) >= 0x8D3DCB08D3DCB0) {
      unint64_t v11 = 0x11A7B9611A7B961;
    }
    else {
      unint64_t v11 = v10;
    }
    std::vector<std::optional<TiledLayerTensorRegions>>::__vallocate[abi:ne180100]((void *)a1, v11);
    uint64_t result = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::optional<TiledLayerTensorRegions>>,std::optional<TiledLayerTensorRegions>*,std::optional<TiledLayerTensorRegions>*,std::optional<TiledLayerTensorRegions>*>(v8, (uint64_t)a2, (uint64_t)a3, *(void *)(a1 + 8));
    goto LABEL_11;
  }
  if (0x34F72C234F72C235 * ((uint64_t)(*(void *)(a1 + 8) - (void)v9) >> 3) < a4)
  {
    uint64_t v13 = (TiledLayerTensorRegions *)((char *)a2 + 8 * ((uint64_t)(*(void *)(a1 + 8) - (void)v9) >> 3));
    std::__unwrap_and_dispatch[abi:ne180100]<std::__overload<std::__copy_loop<std::_ClassicAlgPolicy>,std::__copy_trivial>,std::optional<TiledLayerTensorRegions> *,std::optional<TiledLayerTensorRegions> *,std::optional<TiledLayerTensorRegions> *,0>(a2, v13, v9);
    uint64_t result = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::optional<TiledLayerTensorRegions>>,std::optional<TiledLayerTensorRegions>*,std::optional<TiledLayerTensorRegions>*,std::optional<TiledLayerTensorRegions>*>(v8, (uint64_t)v13, (uint64_t)a3, *(void *)(a1 + 8));
LABEL_11:
    *(void *)(a1 + 8) = result;
    return result;
  }
  std::__unwrap_and_dispatch[abi:ne180100]<std::__overload<std::__copy_loop<std::_ClassicAlgPolicy>,std::__copy_trivial>,std::optional<TiledLayerTensorRegions> *,std::optional<TiledLayerTensorRegions> *,std::optional<TiledLayerTensorRegions> *,0>(a2, a3, v9);
  uint64_t v15 = v14;
  uint64_t result = *(void *)(a1 + 8);
  if (result != v14)
  {
    do
      uint64_t result = std::__optional_destruct_base<TiledLayerTensorRegions,false>::~__optional_destruct_base[abi:ne180100](result - 232);
    while (result != v15);
  }
  *(void *)(a1 + 8) = v15;
  return result;
}

void sub_211279810(_Unwind_Exception *a1)
{
  *(void *)(v1 + 8) = v2;
  _Unwind_Resume(a1);
}

void sub_211279818(_Unwind_Exception *a1)
{
  *(void *)(v1 + 8) = v2;
  _Unwind_Resume(a1);
}

void std::vector<std::optional<TiledLayerTensorRegions>>::__vdeallocate(void **a1)
{
  uint64_t v1 = *a1;
  if (*a1)
  {
    uint64_t v3 = (uint64_t)a1[1];
    uint64_t v4 = v1;
    if ((void *)v3 != v1)
    {
      do
        uint64_t v3 = std::__optional_destruct_base<TiledLayerTensorRegions,false>::~__optional_destruct_base[abi:ne180100](v3 - 232);
      while ((void *)v3 != v1);
      uint64_t v4 = *a1;
    }
    a1[1] = v1;
    operator delete(v4);
    *a1 = 0;
    a1[1] = 0;
    a1[2] = 0;
  }
}

TiledLayerTensorRegions *std::__unwrap_and_dispatch[abi:ne180100]<std::__overload<std::__copy_loop<std::_ClassicAlgPolicy>,std::__copy_trivial>,std::optional<TiledLayerTensorRegions> *,std::optional<TiledLayerTensorRegions> *,std::optional<TiledLayerTensorRegions> *,0>(TiledLayerTensorRegions *a1, TiledLayerTensorRegions *a2, TiledLayerTensorRegions *this)
{
  uint64_t v4 = a1;
  if (a1 != a2)
  {
    do
    {
      std::__optional_storage_base<TiledLayerTensorRegions,false>::__assign_from[abi:ne180100]<std::__optional_copy_assign_base<TiledLayerTensorRegions,false> const&>(this, v4);
      uint64_t v4 = (TiledLayerTensorRegions *)((char *)v4 + 232);
      this = (TiledLayerTensorRegions *)((char *)this + 232);
    }
    while (v4 != a2);
    return a2;
  }
  return v4;
}

void std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,void *> *>>(void *a1, void *a2, void *a3)
{
  uint64_t v4 = a2;
  uint64_t v6 = a1[1];
  if (v6)
  {
    for (uint64_t i = 0; i != v6; ++i)
      *(void *)(*a1 + 8 * i) = 0;
    uint64_t v8 = (char *)a1[2];
    a1[2] = 0;
    a1[3] = 0;
    if (v8) {
      BOOL v9 = a2 == a3;
    }
    else {
      BOOL v9 = 1;
    }
    if (v9)
    {
      unint64_t v10 = v8;
    }
    else
    {
      do
      {
        v12[0] = v8 + 16;
        v12[1] = v8 + 24;
        std::pair<ZinIrOpLayer const*&,std::vector<std::optional<TiledLayerTensorRegions>> &>::operator=[abi:ne180100]<ZinIrOpLayer const* const,std::vector<std::optional<TiledLayerTensorRegions>>,(void *)0>((uint64_t)v12, (uint64_t)(v4 + 2));
        unint64_t v10 = *(char **)v8;
        std::__hash_table<ZinIrOpLayer *,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,std::allocator<ZinIrOpLayer *>>::__node_insert_multi(a1, v8);
        uint64_t v4 = (void *)*v4;
        if (v10) {
          BOOL v11 = v4 == a3;
        }
        else {
          BOOL v11 = 1;
        }
        uint64_t v8 = v10;
      }
      while (!v11);
    }
    std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::__deallocate_node((uint64_t)a1, v10);
  }
  while (v4 != a3)
  {
    std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::__emplace_multi<std::pair<ZinIrOpLayer const* const,std::vector<std::optional<TiledLayerTensorRegions>>> const&>(a1, v4 + 2);
    uint64_t v4 = (void *)*v4;
  }
}

void sub_2112799C0(void *a1)
{
  __cxa_begin_catch(a1);
  std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::__deallocate_node(v1, v2);
  __cxa_rethrow();
}

void sub_2112799DC(_Unwind_Exception *a1)
{
}

uint64_t std::pair<ZinIrOpLayer const*&,std::vector<std::optional<TiledLayerTensorRegions>> &>::operator=[abi:ne180100]<ZinIrOpLayer const* const,std::vector<std::optional<TiledLayerTensorRegions>>,(void *)0>(uint64_t a1, uint64_t a2)
{
  **(void **)a1 = *(void *)a2;
  uint64_t v3 = *(void *)(a1 + 8);
  if (v3 != a2 + 8) {
    std::vector<std::optional<TiledLayerTensorRegions>>::__assign_with_size[abi:ne180100]<std::optional<TiledLayerTensorRegions>*,std::optional<TiledLayerTensorRegions>*>(v3, *(TiledLayerTensorRegions **)(a2 + 8), *(TiledLayerTensorRegions **)(a2 + 16), 0x34F72C234F72C235 * ((uint64_t)(*(void *)(a2 + 16) - *(void *)(a2 + 8)) >> 3));
  }
  return a1;
}

void *std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::__emplace_multi<std::pair<ZinIrOpLayer const* const,std::vector<std::optional<TiledLayerTensorRegions>>> const&>(void *a1, void *a2)
{
  std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::__construct_node<std::pair<ZinIrOpLayer const* const,std::vector<std::optional<TiledLayerTensorRegions>>> const&>((uint64_t)a1, a2, (uint64_t)&v4);
  return std::__hash_table<ZinIrOpLayer *,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,std::allocator<ZinIrOpLayer *>>::__node_insert_multi(a1, v4);
}

void sub_211279A94(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void **__p, uint64_t a11)
{
  if (__p) {
    std::__hash_node_destructor<std::allocator<std::__hash_node<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,void *>>>::operator()[abi:ne180100]((uint64_t)&a11, __p);
  }
  _Unwind_Resume(exception_object);
}

void *std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::__construct_node<std::pair<ZinIrOpLayer const* const,std::vector<std::optional<TiledLayerTensorRegions>>> const&>@<X0>(uint64_t a1@<X0>, void *a2@<X1>, uint64_t a3@<X8>)
{
  uint64_t v5 = a1 + 16;
  uint64_t v6 = operator new(0x30uLL);
  *(void *)a3 = v6;
  *(void *)(a3 + 8) = v5;
  *(unsigned char *)(a3 + 16) = 0;
  void *v6 = 0;
  v6[1] = 0;
  uint64_t v7 = a2[1];
  v6[2] = *a2;
  v6[3] = 0;
  v6[4] = 0;
  void v6[5] = 0;
  uint64_t result = std::vector<std::optional<TiledLayerTensorRegions>>::__init_with_size[abi:ne180100]<std::optional<TiledLayerTensorRegions>*,std::optional<TiledLayerTensorRegions>*>(v6 + 3, v7, a2[2], 0x34F72C234F72C235 * ((a2[2] - v7) >> 3));
  *(unsigned char *)(a3 + 16) = 1;
  unint64_t v9 = v6[2];
  unint64_t v10 = HIDWORD(v9);
  unint64_t v11 = 0x9DDFEA08EB382D69 * (((8 * v9) + 8) ^ HIDWORD(v9));
  v6[1] = 0x9DDFEA08EB382D69
        * ((0x9DDFEA08EB382D69 * (v10 ^ (v11 >> 47) ^ v11)) ^ ((0x9DDFEA08EB382D69 * (v10 ^ (v11 >> 47) ^ v11)) >> 47));
  return result;
}

void sub_211279B8C(_Unwind_Exception *a1)
{
  *uint64_t v2 = 0;
  std::__hash_node_destructor<std::allocator<std::__hash_node<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,void *>>>::operator()[abi:ne180100](v3, v1);
  _Unwind_Resume(a1);
}

void std::vector<LayerTilingHelper>::__destroy_vector::operator()[abi:ne180100](void ***a1)
{
  uint64_t v1 = *a1;
  uint64_t v2 = **a1;
  if (v2)
  {
    uint64_t v4 = v1[1];
    uint64_t v5 = **a1;
    if (v4 != v2)
    {
      do
      {
        v4 -= 24;
        std::__destroy_at[abi:ne180100]<LayerTilingHelper,0>(v4);
      }
      while (v4 != v2);
      uint64_t v5 = **a1;
    }
    v1[1] = v2;
    operator delete(v5);
  }
}

uint64_t std::__optional_destruct_base<SplitInfo,false>::~__optional_destruct_base[abi:ne180100](uint64_t a1)
{
  if (*(unsigned char *)(a1 + 144))
  {
    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table(a1 + 64);
    std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::~__hash_table(a1 + 24);
    uint64_t v3 = (void **)a1;
    std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__destroy_vector::operator()[abi:ne180100](&v3);
  }
  return a1;
}

uint64_t std::construct_at[abi:ne180100]<SplitInfo,SplitInfo&,SplitInfo*>(uint64_t a1, uint64_t a2)
{
  *(void *)a1 = 0;
  *(void *)(a1 + 8) = 0;
  *(void *)(a1 + 16) = 0;
  std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__init_with_size[abi:ne180100]<std::vector<std::optional<TiledLayerTensorRegions>>*,std::vector<std::optional<TiledLayerTensorRegions>>*>((void *)a1, *(uint64_t **)a2, *(uint64_t **)(a2 + 8), 0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*(void *)(a2 + 8) - *(void *)a2) >> 3));
  std::unordered_map<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>::unordered_map(a1 + 24, a2 + 24);
  std::unordered_set<ZinIrOpLayer const*>::unordered_set(a1 + 64, a2 + 64);
  long long v4 = *(_OWORD *)(a2 + 104);
  long long v5 = *(_OWORD *)(a2 + 120);
  *(unsigned char *)(a1 + 136) = *(unsigned char *)(a2 + 136);
  *(_OWORD *)(a1 + 120) = v5;
  *(_OWORD *)(a1 + 104) = v4;
  return a1;
}

void sub_211279D10(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::~__hash_table(v2);
  std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__destroy_vector::operator()[abi:ne180100]((void ***)va);
  _Unwind_Resume(a1);
}

void std::__hash_table<std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::__unordered_map_hasher<unsigned long,std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::hash<unsigned long>,std::equal_to<unsigned long>,true>,std::__unordered_map_equal<unsigned long,std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::equal_to<unsigned long>,std::hash<unsigned long>,true>,std::allocator<std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>>>::__move_assign(uint64_t a1, uint64_t *a2)
{
  std::__hash_table<std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::__unordered_map_hasher<unsigned long,std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::hash<unsigned long>,std::equal_to<unsigned long>,true>,std::__unordered_map_equal<unsigned long,std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::equal_to<unsigned long>,std::hash<unsigned long>,true>,std::allocator<std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>>>::clear(a1);
  uint64_t v4 = *a2;
  *a2 = 0;
  long long v5 = *(void **)a1;
  *(void *)a1 = v4;
  if (v5) {
    operator delete(v5);
  }
  uint64_t v8 = a2[2];
  uint64_t v7 = a2 + 2;
  uint64_t v6 = v8;
  uint64_t v9 = *(v7 - 1);
  *(void *)(a1 + 16) = v8;
  *(void *)(a1 + 8) = v9;
  *(v7 - 1) = 0;
  uint64_t v10 = v7[1];
  *(void *)(a1 + 24) = v10;
  *(_DWORD *)(a1 + 32) = *((_DWORD *)v7 + 4);
  if (v10)
  {
    unint64_t v11 = *(void *)(v6 + 8);
    unint64_t v12 = *(void *)(a1 + 8);
    if ((v12 & (v12 - 1)) != 0)
    {
      if (v11 >= v12) {
        v11 %= v12;
      }
    }
    else
    {
      v11 &= v12 - 1;
    }
    *(void *)(*(void *)a1 + 8 * v11) = a1 + 16;
    void *v7 = 0;
    v7[1] = 0;
  }
}

void std::__hash_table<std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::__unordered_map_hasher<unsigned long,std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::hash<unsigned long>,std::equal_to<unsigned long>,true>,std::__unordered_map_equal<unsigned long,std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::equal_to<unsigned long>,std::hash<unsigned long>,true>,std::allocator<std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>>>::clear(uint64_t a1)
{
  if (*(void *)(a1 + 24))
  {
    std::__hash_table<std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::__unordered_map_hasher<unsigned long,std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::hash<unsigned long>,std::equal_to<unsigned long>,true>,std::__unordered_map_equal<unsigned long,std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::equal_to<unsigned long>,std::hash<unsigned long>,true>,std::allocator<std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>>>::__deallocate_node(a1, *(void **)(a1 + 16));
    *(void *)(a1 + 16) = 0;
    uint64_t v2 = *(void *)(a1 + 8);
    if (v2)
    {
      for (uint64_t i = 0; i != v2; ++i)
        *(void *)(*(void *)a1 + 8 * i) = 0;
    }
    *(void *)(a1 + 24) = 0;
  }
}

void std::__hash_table<std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::__unordered_map_hasher<unsigned long,std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::hash<unsigned long>,std::equal_to<unsigned long>,true>,std::__unordered_map_equal<unsigned long,std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::equal_to<unsigned long>,std::hash<unsigned long>,true>,std::allocator<std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>>>::__deallocate_node(int a1, void *__p)
{
  if (__p)
  {
    uint64_t v2 = __p;
    do
    {
      uint64_t v3 = (void *)*v2;
      uint64_t v4 = v2[3];
      v2[3] = 0;
      if (v4) {
        (*(void (**)(uint64_t))(*(void *)v4 + 8))(v4);
      }
      operator delete(v2);
      uint64_t v2 = v3;
    }
    while (v3);
  }
}

void *std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__init_with_size[abi:ne180100]<std::vector<std::optional<TiledLayerTensorRegions>>*,std::vector<std::optional<TiledLayerTensorRegions>>*>(void *result, uint64_t *a2, uint64_t *a3, unint64_t a4)
{
  if (a4)
  {
    uint64_t v6 = result;
    std::vector<std::string>::__vallocate[abi:ne180100](result, a4);
    uint64_t result = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::vector<std::optional<TiledLayerTensorRegions>>>,std::vector<std::optional<TiledLayerTensorRegions>>*,std::vector<std::optional<TiledLayerTensorRegions>>*,std::vector<std::optional<TiledLayerTensorRegions>>*>((uint64_t)(v6 + 2), a2, a3, (void *)v6[1]);
    v6[1] = result;
  }
  return result;
}

void sub_211279F08(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, void **a9)
{
  *(void *)(v9 + 8) = v10;
  std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__destroy_vector::operator()[abi:ne180100](&a9);
  _Unwind_Resume(a1);
}

uint64_t std::unordered_map<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>::unordered_map(uint64_t a1, uint64_t a2)
{
  *(_OWORD *)a1 = 0u;
  *(_OWORD *)(a1 + 16) = 0u;
  *(_DWORD *)(a1 + 32) = *(_DWORD *)(a2 + 32);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::__rehash<true>(a1, *(void *)(a2 + 8));
  for (uint64_t i = *(void **)(a2 + 16); i; uint64_t i = (void *)*i)
    std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::__emplace_unique_key_args<ZinIrOpLayer const*,std::pair<ZinIrOpLayer const* const,std::vector<std::optional<TiledLayerTensorRegions>>> const&>(a1, i + 2, i + 2);
  return a1;
}

void sub_211279F88(_Unwind_Exception *a1)
{
  std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::~__hash_table(v1);
  _Unwind_Resume(a1);
}

void *std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::__emplace_unique_key_args<ZinIrOpLayer const*,std::pair<ZinIrOpLayer const* const,std::vector<std::optional<TiledLayerTensorRegions>>> const&>(uint64_t a1, void *a2, void *a3)
{
  unint64_t v5 = 0x9DDFEA08EB382D69 * ((8 * *a2 + 8) ^ HIDWORD(*a2));
  unint64_t v6 = 0x9DDFEA08EB382D69 * (HIDWORD(*a2) ^ (v5 >> 47) ^ v5);
  unint64_t v7 = 0x9DDFEA08EB382D69 * (v6 ^ (v6 >> 47));
  unint64_t v8 = *(void *)(a1 + 8);
  if (v8)
  {
    uint8x8_t v9 = (uint8x8_t)vcnt_s8((int8x8_t)v8);
    v9.i16[0] = vaddlv_u8(v9);
    if (v9.u32[0] > 1uLL)
    {
      unint64_t v3 = 0x9DDFEA08EB382D69 * (v6 ^ (v6 >> 47));
      if (v7 >= v8) {
        unint64_t v3 = v7 % v8;
      }
    }
    else
    {
      unint64_t v3 = v7 & (v8 - 1);
    }
    uint64_t v10 = *(void **)(*(void *)a1 + 8 * v3);
    if (v10)
    {
      uint64_t result = (void *)*v10;
      if (*v10)
      {
        do
        {
          unint64_t v12 = result[1];
          if (v12 == v7)
          {
            if (result[2] == *a2) {
              return result;
            }
          }
          else
          {
            if (v9.u32[0] > 1uLL)
            {
              if (v12 >= v8) {
                v12 %= v8;
              }
            }
            else
            {
              v12 &= v8 - 1;
            }
            if (v12 != v3) {
              break;
            }
          }
          uint64_t result = (void *)*result;
        }
        while (result);
      }
    }
  }
  std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::__construct_node_hash<std::pair<ZinIrOpLayer const* const,std::vector<std::optional<TiledLayerTensorRegions>>> const&>(a1, v7, a3, (uint64_t)&v21);
  float v13 = (float)(unint64_t)(*(void *)(a1 + 24) + 1);
  float v14 = *(float *)(a1 + 32);
  if (!v8 || (float)(v14 * (float)v8) < v13)
  {
    BOOL v15 = 1;
    if (v8 >= 3) {
      BOOL v15 = (v8 & (v8 - 1)) != 0;
    }
    unint64_t v16 = v15 | (2 * v8);
    unint64_t v17 = vcvtps_u32_f32(v13 / v14);
    if (v16 <= v17) {
      size_t v18 = v17;
    }
    else {
      size_t v18 = v16;
    }
    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::__rehash<true>(a1, v18);
    unint64_t v8 = *(void *)(a1 + 8);
    if ((v8 & (v8 - 1)) != 0)
    {
      if (v7 >= v8) {
        unint64_t v3 = v7 % v8;
      }
      else {
        unint64_t v3 = v7;
      }
    }
    else
    {
      unint64_t v3 = (v8 - 1) & v7;
    }
  }
  std::string v19 = *(void **)(*(void *)a1 + 8 * v3);
  if (v19)
  {
    void *v21 = *v19;
    void *v19 = v21;
  }
  else
  {
    void *v21 = *(void *)(a1 + 16);
    *(void *)(a1 + 16) = v21;
    *(void *)(*(void *)a1 + 8 * v3) = a1 + 16;
    if (*v21)
    {
      unint64_t v20 = *(void *)(*v21 + 8);
      if ((v8 & (v8 - 1)) != 0)
      {
        if (v20 >= v8) {
          v20 %= v8;
        }
      }
      else
      {
        v20 &= v8 - 1;
      }
      *(void *)(*(void *)a1 + 8 * v20) = v21;
    }
  }
  uint64_t result = v21;
  ++*(void *)(a1 + 24);
  return result;
}

void sub_21127A1EC(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void **__p, uint64_t a11)
{
  if (__p) {
    std::__hash_node_destructor<std::allocator<std::__hash_node<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,void *>>>::operator()[abi:ne180100]((uint64_t)&a11, __p);
  }
  _Unwind_Resume(exception_object);
}

void *std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::__construct_node_hash<std::pair<ZinIrOpLayer const* const,std::vector<std::optional<TiledLayerTensorRegions>>> const&>@<X0>(uint64_t a1@<X0>, uint64_t a2@<X1>, void *a3@<X2>, uint64_t a4@<X8>)
{
  uint64_t v7 = a1 + 16;
  unint64_t v8 = operator new(0x30uLL);
  *(void *)a4 = v8;
  *(void *)(a4 + 8) = v7;
  *(unsigned char *)(a4 + 16) = 0;
  *unint64_t v8 = 0;
  v8[1] = a2;
  uint64_t v9 = a3[1];
  v8[2] = *a3;
  void v8[3] = 0;
  v8[4] = 0;
  v8[5] = 0;
  uint64_t result = std::vector<std::optional<TiledLayerTensorRegions>>::__init_with_size[abi:ne180100]<std::optional<TiledLayerTensorRegions>*,std::optional<TiledLayerTensorRegions>*>(v8 + 3, v9, a3[2], 0x34F72C234F72C235 * ((a3[2] - v9) >> 3));
  *(unsigned char *)(a4 + 16) = 1;
  return result;
}

void sub_21127A2A8(_Unwind_Exception *a1)
{
  *uint64_t v1 = 0;
  std::__hash_node_destructor<std::allocator<std::__hash_node<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,void *>>>::operator()[abi:ne180100](v3, v2);
  _Unwind_Resume(a1);
}

uint64_t std::unordered_set<ZinIrOpLayer const*>::unordered_set(uint64_t a1, uint64_t a2)
{
  *(_OWORD *)a1 = 0u;
  *(_OWORD *)(a1 + 16) = 0u;
  *(_DWORD *)(a1 + 32) = *(_DWORD *)(a2 + 32);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::__rehash<true>(a1, *(void *)(a2 + 8));
  for (uint64_t i = *(void **)(a2 + 16); i; uint64_t i = (void *)*i)
    std::__hash_table<ZinIrTensor const*,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const* const&>(a1, i + 2, i + 2);
  return a1;
}

void sub_21127A324(_Unwind_Exception *a1)
{
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table(v1);
  _Unwind_Resume(a1);
}

void std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::__move_assign(uint64_t a1, uint64_t *a2)
{
  std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::clear(a1);
  uint64_t v4 = *a2;
  *a2 = 0;
  unint64_t v5 = *(void **)a1;
  *(void *)a1 = v4;
  if (v5) {
    operator delete(v5);
  }
  uint64_t v8 = a2[2];
  uint64_t v7 = a2 + 2;
  uint64_t v6 = v8;
  uint64_t v9 = *(v7 - 1);
  *(void *)(a1 + 16) = v8;
  *(void *)(a1 + 8) = v9;
  *(v7 - 1) = 0;
  uint64_t v10 = v7[1];
  *(void *)(a1 + 24) = v10;
  *(_DWORD *)(a1 + 32) = *((_DWORD *)v7 + 4);
  if (v10)
  {
    unint64_t v11 = *(void *)(v6 + 8);
    unint64_t v12 = *(void *)(a1 + 8);
    if ((v12 & (v12 - 1)) != 0)
    {
      if (v11 >= v12) {
        v11 %= v12;
      }
    }
    else
    {
      v11 &= v12 - 1;
    }
    *(void *)(*(void *)a1 + 8 * v11) = a1 + 16;
    void *v7 = 0;
    v7[1] = 0;
  }
}

void std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::clear(uint64_t a1)
{
  if (*(void *)(a1 + 24))
  {
    std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::__deallocate_node(a1, *(char **)(a1 + 16));
    *(void *)(a1 + 16) = 0;
    uint64_t v2 = *(void *)(a1 + 8);
    if (v2)
    {
      for (uint64_t i = 0; i != v2; ++i)
        *(void *)(*(void *)a1 + 8 * i) = 0;
    }
    *(void *)(a1 + 24) = 0;
  }
}

uint64_t std::construct_at[abi:ne180100]<ZinMirSpatialSplitter::TilingResult,ZinMirSpatialSplitter::TilingResult,ZinMirSpatialSplitter::TilingResult*>(uint64_t a1, uint64_t a2)
{
  *(void *)a1 = 0;
  *(void *)(a1 + 8) = 0;
  *(void *)(a1 + 16) = 0;
  *(_OWORD *)a1 = *(_OWORD *)a2;
  *(void *)(a1 + 16) = *(void *)(a2 + 16);
  *(void *)a2 = 0;
  *(void *)(a2 + 8) = 0;
  *(void *)(a2 + 16) = 0;
  std::__hash_table<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::__unordered_map_hasher<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::hash<long>,std::equal_to<long>,true>,std::__unordered_map_equal<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::equal_to<long>,std::hash<long>,true>,std::allocator<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>>>::__hash_table(a1 + 24, (uint64_t *)(a2 + 24));
  std::__hash_table<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::__unordered_map_hasher<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::hash<long>,std::equal_to<long>,true>,std::__unordered_map_equal<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::equal_to<long>,std::hash<long>,true>,std::allocator<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>>>::__hash_table(a1 + 64, (uint64_t *)(a2 + 64));
  long long v4 = *(_OWORD *)(a2 + 104);
  long long v5 = *(_OWORD *)(a2 + 120);
  *(unsigned char *)(a1 + 136) = *(unsigned char *)(a2 + 136);
  *(_OWORD *)(a1 + 120) = v5;
  *(_OWORD *)(a1 + 104) = v4;
  *(_OWORD *)(a1 + 144) = *(_OWORD *)(a2 + 144);
  return a1;
}

uint64_t std::unordered_set<ZinANELayer const*>::unordered_set(uint64_t a1, uint64_t a2)
{
  *(_OWORD *)a1 = 0u;
  *(_OWORD *)(a1 + 16) = 0u;
  *(_DWORD *)(a1 + 32) = *(_DWORD *)(a2 + 32);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::__rehash<true>(a1, *(void *)(a2 + 8));
  for (uint64_t i = *(void **)(a2 + 16); i; uint64_t i = (void *)*i)
    std::__hash_table<ZinIrTensor const*,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const* const&>(a1, i + 2, i + 2);
  return a1;
}

void sub_21127A518(_Unwind_Exception *a1)
{
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table(v1);
  _Unwind_Resume(a1);
}

uint64_t std::construct_at[abi:ne180100]<ProducerConsumerChain,ProducerConsumerChain&,ProducerConsumerChain*>(uint64_t a1, uint64_t a2)
{
  *(_DWORD *)a1 = *(_DWORD *)a2;
  *(void *)(a1 + 8) = 0;
  *(void *)(a1 + 16) = 0;
  *(void *)(a1 + 24) = 0;
  std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>((void *)(a1 + 8), *(const void **)(a2 + 8), *(void *)(a2 + 16), (uint64_t)(*(void *)(a2 + 16) - *(void *)(a2 + 8)) >> 3);
  std::unordered_set<ZinANELayer const*>::unordered_set(a1 + 32, a2 + 32);
  return a1;
}

void sub_21127A598(_Unwind_Exception *exception_object)
{
  long long v4 = *v2;
  if (*v2)
  {
    *(void *)(v1 + 16) = v4;
    operator delete(v4);
  }
  _Unwind_Resume(exception_object);
}

uint64_t *std::vector<ProducerConsumerChain>::__insert_with_size[abi:ne180100]<std::__wrap_iter<ProducerConsumerChain*>,std::__wrap_iter<ProducerConsumerChain*>>(uint64_t *a1, uint64_t *a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  long long v5 = a2;
  if (a5 >= 1)
  {
    uint64_t v7 = a3;
    uint64_t v11 = a1[2];
    uint64_t v9 = (uint64_t)(a1 + 2);
    uint64_t v10 = v11;
    unint64_t v12 = *(void *)(v9 - 8);
    if ((uint64_t)(0x8E38E38E38E38E39 * ((uint64_t)(v11 - v12) >> 3)) >= a5)
    {
      uint64_t v20 = v12 - (void)a2;
      if ((uint64_t)(0x8E38E38E38E38E39 * ((uint64_t)(v12 - (void)a2) >> 3)) >= a5)
      {
        uint64_t v21 = a3 + 72 * a5;
      }
      else
      {
        uint64_t v21 = a3 + 8 * ((uint64_t)(v12 - (void)a2) >> 3);
        a1[1] = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<ProducerConsumerChain>,ProducerConsumerChain*,ProducerConsumerChain*,ProducerConsumerChain*>(v9, v21, a4, *(void *)(v9 - 8));
        if (v20 < 1) {
          return v5;
        }
      }
      std::vector<ProducerConsumerChain>::__move_range((uint64_t)a1, (uint64_t)v5, v12, (uint64_t)&v5[9 * a5]);
      std::__copy_loop<std::_ClassicAlgPolicy>::operator()[abi:ne180100]<ProducerConsumerChain *,ProducerConsumerChain *,ProducerConsumerChain *>((uint64_t)v27, v7, v21, (uint64_t)v5);
    }
    else
    {
      uint64_t v13 = *a1;
      unint64_t v14 = a5 - 0x71C71C71C71C71C7 * ((uint64_t)(v12 - *a1) >> 3);
      if (v14 > 0x38E38E38E38E38ELL) {
        std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
      }
      unint64_t v15 = 0x8E38E38E38E38E39 * (((uint64_t)a2 - v13) >> 3);
      unint64_t v16 = 0x8E38E38E38E38E39 * ((v10 - v13) >> 3);
      uint64_t v17 = 2 * v16;
      if (2 * v16 <= v14) {
        uint64_t v17 = v14;
      }
      if (v16 >= 0x1C71C71C71C71C7) {
        unint64_t v18 = 0x38E38E38E38E38ELL;
      }
      else {
        unint64_t v18 = v17;
      }
      uint64_t v30 = v9;
      if (v18) {
        std::string v19 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ANEDebugInfo::DebugInfoInMem::TD>>(v9, v18);
      }
      else {
        std::string v19 = 0;
      }
      uint64_t v22 = (uint64_t)&v19[72 * v15];
      v27[0] = v19;
      v27[1] = v22;
      uint64_t v28 = v22;
      int v29 = &v19[72 * v18];
      uint64_t v23 = 9 * a5;
      uint64_t v24 = v22 + 72 * a5;
      uint64_t v25 = 8 * v23;
      do
      {
        std::construct_at[abi:ne180100]<ProducerConsumerChain,ProducerConsumerChain&,ProducerConsumerChain*>(v22, v7);
        v22 += 72;
        v7 += 72;
        v25 -= 72;
      }
      while (v25);
      uint64_t v28 = v24;
      long long v5 = (uint64_t *)std::vector<ProducerConsumerChain>::__swap_out_circular_buffer((uint64_t)a1, v27, v5);
      std::__split_buffer<ProducerConsumerChain>::~__split_buffer((uint64_t)v27);
    }
  }
  return v5;
}

void sub_21127A798(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, char a10, uint64_t a11, uint64_t a12)
{
  *(void *)(v12 + 8) = v13;
  _Unwind_Resume(exception_object);
}

uint64_t std::vector<ProducerConsumerChain>::__move_range(uint64_t a1, uint64_t a2, unint64_t a3, uint64_t a4)
{
  uint64_t v6 = *(void *)(a1 + 8);
  unint64_t v7 = a2 + v6 - a4;
  uint64_t v8 = v6;
  if (v7 < a3)
  {
    uint64_t v10 = (uint64_t *)(a2 + 8 * ((v6 - a4) >> 3) + 32);
    uint64_t v8 = *(void *)(a1 + 8);
    do
    {
      *(_DWORD *)uint64_t v8 = *((_DWORD *)v10 - 8);
      *(void *)(v8 + 16) = 0;
      *(void *)(v8 + 24) = 0;
      *(void *)(v8 + 8) = 0;
      *(_OWORD *)(v8 + 8) = *(_OWORD *)(v10 - 3);
      *(void *)(v8 + 24) = *(v10 - 1);
      *(v10 - 3) = 0;
      *(v10 - 2) = 0;
      *(v10 - 1) = 0;
      std::__hash_table<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::__unordered_map_hasher<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::hash<long>,std::equal_to<long>,true>,std::__unordered_map_equal<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::equal_to<long>,std::hash<long>,true>,std::allocator<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>>>::__hash_table(v8 + 32, v10);
      v8 += 72;
      uint64_t v11 = v10 + 5;
      v10 += 9;
    }
    while ((unint64_t)v11 < a3);
  }
  *(void *)(a1 + 8) = v8;
  return std::__move_backward_loop<std::_ClassicAlgPolicy>::operator()[abi:ne180100]<ProducerConsumerChain *,ProducerConsumerChain *,ProducerConsumerChain *>((uint64_t)&v13, a2, v7, v6);
}

uint64_t std::vector<ProducerConsumerChain>::__swap_out_circular_buffer(uint64_t a1, void *a2, uint64_t *a3)
{
  uint64_t v6 = a2[1];
  uint64_t v7 = a1 + 16;
  std::__uninitialized_allocator_move_if_noexcept[abi:ne180100]<std::allocator<ProducerConsumerChain>,std::reverse_iterator<ProducerConsumerChain*>,std::reverse_iterator<ProducerConsumerChain*>,std::reverse_iterator<ProducerConsumerChain*>>(a1 + 16, (uint64_t)a3, (uint64_t)a3, *(void *)a1, *(void *)a1, v6, v6);
  a2[1] = v8;
  a2[2] = std::__uninitialized_allocator_move_if_noexcept[abi:ne180100]<std::allocator<ProducerConsumerChain>,ProducerConsumerChain*,ProducerConsumerChain*,ProducerConsumerChain*>(v7, a3, *(uint64_t **)(a1 + 8), a2[2]);
  uint64_t v9 = *(void *)a1;
  *(void *)a1 = a2[1];
  a2[1] = v9;
  uint64_t v10 = *(void *)(a1 + 8);
  *(void *)(a1 + 8) = a2[2];
  a2[2] = v10;
  uint64_t v11 = *(void *)(a1 + 16);
  *(void *)(a1 + 16) = a2[3];
  a2[3] = v11;
  *a2 = a2[1];
  return v6;
}

uint64_t std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<ProducerConsumerChain>,ProducerConsumerChain*,ProducerConsumerChain*,ProducerConsumerChain*>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  if (a2 != a3)
  {
    uint64_t v7 = 0;
    do
    {
      std::construct_at[abi:ne180100]<ProducerConsumerChain,ProducerConsumerChain&,ProducerConsumerChain*>(a4 + v7, a2 + v7);
      v7 += 72;
    }
    while (a2 + v7 != a3);
    a4 += v7;
  }
  return a4;
}

void sub_21127A9C0(_Unwind_Exception *exception_object)
{
  if (v2)
  {
    uint64_t v4 = v1 - 72;
    do
    {
      std::__destroy_at[abi:ne180100]<ProducerConsumerChain,0>(v4 + v2);
      v2 -= 72;
    }
    while (v2);
  }
  _Unwind_Resume(exception_object);
}

uint64_t std::__move_backward_loop<std::_ClassicAlgPolicy>::operator()[abi:ne180100]<ProducerConsumerChain *,ProducerConsumerChain *,ProducerConsumerChain *>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  if (a3 != a2)
  {
    uint64_t v7 = 0;
    do
    {
      *(_DWORD *)(a4 + v7 - 72) = *(_DWORD *)(a3 + v7 - 72);
      std::vector<ANEDebugInfo::DebugInfoInMem::Layer>::__move_assign(a4 + v7 - 64, (__n128 *)(a3 + v7 - 64));
      std::__hash_table<std::__hash_value_type<ZinDependencyOffsetDim,long>,std::__unordered_map_hasher<ZinDependencyOffsetDim,std::__hash_value_type<ZinDependencyOffsetDim,long>,std::hash<ZinDependencyOffsetDim>,std::equal_to<ZinDependencyOffsetDim>,true>,std::__unordered_map_equal<ZinDependencyOffsetDim,std::__hash_value_type<ZinDependencyOffsetDim,long>,std::equal_to<ZinDependencyOffsetDim>,std::hash<ZinDependencyOffsetDim>,true>,std::allocator<std::__hash_value_type<ZinDependencyOffsetDim,long>>>::__move_assign(a4 + v7 - 40, (uint64_t *)(a3 + v7 - 40));
      v7 -= 72;
    }
    while (a3 + v7 != a2);
  }
  return a3;
}

uint64_t std::__copy_loop<std::_ClassicAlgPolicy>::operator()[abi:ne180100]<ProducerConsumerChain *,ProducerConsumerChain *,ProducerConsumerChain *>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  if (a2 == a3) {
    return a2;
  }
  uint64_t v6 = a3;
  uint64_t v7 = 0;
  do
  {
    *(_DWORD *)(a4 + v7) = *(_DWORD *)(a2 + v7);
    if (a2 != a4)
    {
      std::vector<DimensionMapping>::__assign_with_size[abi:ne180100]<DimensionMapping const*,DimensionMapping const*>((char *)(a4 + v7 + 8), *(char **)(a2 + v7 + 8), *(void *)(a2 + v7 + 16), (uint64_t)(*(void *)(a2 + v7 + 16) - *(void *)(a2 + v7 + 8)) >> 3);
      *(_DWORD *)(a4 + v7 + 64) = *(_DWORD *)(a2 + v7 + 64);
      std::__hash_table<ZinIrOpLayer *,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,std::allocator<ZinIrOpLayer *>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<ZinIrOpLayer *,void *> *>>((void *)(a4 + v7 + 32), *(void **)(a2 + v7 + 48), 0);
    }
    v7 += 72;
  }
  while (a2 + v7 != v6);
  return v6;
}

uint64_t std::__uninitialized_allocator_move_if_noexcept[abi:ne180100]<std::allocator<ProducerConsumerChain>,ProducerConsumerChain*,ProducerConsumerChain*,ProducerConsumerChain*>(uint64_t a1, uint64_t *a2, uint64_t *a3, uint64_t a4)
{
  if (a2 != a3)
  {
    uint64_t v6 = a2 + 4;
    do
    {
      *(_DWORD *)a4 = *((_DWORD *)v6 - 8);
      *(void *)(a4 + 16) = 0;
      *(void *)(a4 + 24) = 0;
      *(void *)(a4 + 8) = 0;
      *(_OWORD *)(a4 + 8) = *(_OWORD *)(v6 - 3);
      *(void *)(a4 + 24) = *(v6 - 1);
      *(v6 - 3) = 0;
      *(v6 - 2) = 0;
      *(v6 - 1) = 0;
      std::__hash_table<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::__unordered_map_hasher<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::hash<long>,std::equal_to<long>,true>,std::__unordered_map_equal<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::equal_to<long>,std::hash<long>,true>,std::allocator<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>>>::__hash_table(a4 + 32, v6);
      a4 += 72;
      uint64_t v7 = v6 + 5;
      v6 += 9;
    }
    while (v7 != a3);
  }
  return a4;
}

void std::vector<ProducerConsumerChain>::__destroy_vector::operator()[abi:ne180100](void ***a1)
{
  uint64_t v1 = *a1;
  uint64_t v2 = **a1;
  if (v2)
  {
    uint64_t v4 = (uint64_t)v1[1];
    long long v5 = **a1;
    if ((void *)v4 != v2)
    {
      do
      {
        v4 -= 72;
        std::__destroy_at[abi:ne180100]<ProducerConsumerChain,0>(v4);
      }
      while ((void *)v4 != v2);
      long long v5 = **a1;
    }
    v1[1] = v2;
    operator delete(v5);
  }
}

uint64_t ZinMirSpatialSplitter::SplitPlan::operator=(uint64_t a1, uint64_t a2)
{
  if (a1 == a2)
  {
    long long v6 = *(_OWORD *)(a2 + 104);
    long long v7 = *(_OWORD *)(a2 + 120);
    *(unsigned char *)(a1 + 136) = *(unsigned char *)(a2 + 136);
    *(_OWORD *)(a1 + 120) = v7;
    *(_OWORD *)(a1 + 104) = v6;
    *(_OWORD *)(a1 + 144) = *(_OWORD *)(a2 + 144);
    *(_DWORD *)(a1 + 160) = *(_DWORD *)(a2 + 160);
  }
  else
  {
    std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__assign_with_size[abi:ne180100]<std::vector<std::optional<TiledLayerTensorRegions>>*,std::vector<std::optional<TiledLayerTensorRegions>>*>(a1, *(uint64_t **)a2, *(uint64_t **)(a2 + 8), 0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*(void *)(a2 + 8) - *(void *)a2) >> 3));
    *(_DWORD *)(a1 + 56) = *(_DWORD *)(a2 + 56);
    std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,void *> *>>((void *)(a1 + 24), *(void **)(a2 + 40), 0);
    *(_DWORD *)(a1 + 96) = *(_DWORD *)(a2 + 96);
    std::__hash_table<ZinIrOpLayer *,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,std::allocator<ZinIrOpLayer *>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<ZinIrOpLayer *,void *> *>>((void *)(a1 + 64), *(void **)(a2 + 80), 0);
    long long v4 = *(_OWORD *)(a2 + 104);
    long long v5 = *(_OWORD *)(a2 + 120);
    *(unsigned char *)(a1 + 136) = *(unsigned char *)(a2 + 136);
    *(_OWORD *)(a1 + 120) = v5;
    *(_OWORD *)(a1 + 104) = v4;
    *(_OWORD *)(a1 + 144) = *(_OWORD *)(a2 + 144);
    *(_DWORD *)(a1 + 160) = *(_DWORD *)(a2 + 160);
    std::vector<DimensionMapping>::__assign_with_size[abi:ne180100]<DimensionMapping const*,DimensionMapping const*>((char *)(a1 + 168), *(char **)(a2 + 168), *(void *)(a2 + 176), (uint64_t)(*(void *)(a2 + 176) - *(void *)(a2 + 168)) >> 3);
    *(_DWORD *)(a1 + 224) = *(_DWORD *)(a2 + 224);
    std::__hash_table<ZinIrOpLayer *,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,std::allocator<ZinIrOpLayer *>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<ZinIrOpLayer *,void *> *>>((void *)(a1 + 192), *(void **)(a2 + 208), 0);
  }
  *(_DWORD *)(a1 + 232) = *(_DWORD *)(a2 + 232);
  return a1;
}

ZinMirSpatialSplitter::SplitPlan *ZinMirSpatialSplitter::SplitPlan::SplitPlan(ZinMirSpatialSplitter::SplitPlan *this, const ZinMirSpatialSplitter::SplitPlan *a2)
{
  *(void *)this = 0;
  *((void *)this + 1) = 0;
  *((void *)this + 2) = 0;
  std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__init_with_size[abi:ne180100]<std::vector<std::optional<TiledLayerTensorRegions>>*,std::vector<std::optional<TiledLayerTensorRegions>>*>(this, *(uint64_t **)a2, *((uint64_t **)a2 + 1), 0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*((void *)a2 + 1) - *(void *)a2) >> 3));
  std::unordered_map<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>::unordered_map((uint64_t)this + 24, (uint64_t)a2 + 24);
  std::unordered_set<ZinIrOpLayer const*>::unordered_set((uint64_t)this + 64, (uint64_t)a2 + 64);
  long long v4 = *(_OWORD *)((char *)a2 + 104);
  long long v5 = *(_OWORD *)((char *)a2 + 120);
  *((unsigned char *)this + 136) = *((unsigned char *)a2 + 136);
  *(_OWORD *)((char *)this + 120) = v5;
  *(_OWORD *)((char *)this + 104) = v4;
  *((_OWORD *)this + 9) = *((_OWORD *)a2 + 9);
  int v6 = *((_DWORD *)a2 + 40);
  *((void *)this + 21) = 0;
  *((_DWORD *)this + 40) = v6;
  *((void *)this + 22) = 0;
  *((void *)this + 23) = 0;
  std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>((void *)this + 21, *((const void **)a2 + 21), *((void *)a2 + 22), (uint64_t)(*((void *)a2 + 22) - *((void *)a2 + 21)) >> 3);
  std::unordered_set<ZinANELayer const*>::unordered_set((uint64_t)this + 192, (uint64_t)a2 + 192);
  *((_DWORD *)this + 58) = *((_DWORD *)a2 + 58);
  return this;
}

void sub_21127AE00(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10)
{
  char v13 = *v11;
  if (*v11)
  {
    *(void *)(v10 + 176) = v13;
    operator delete(v13);
  }
  SplitInfo::~SplitInfo((void **)v10);
  _Unwind_Resume(a1);
}

uint64_t std::__optional_destruct_base<ZinMirSpatialSplitter::TilingResult,false>::~__optional_destruct_base[abi:ne180100](uint64_t a1)
{
  if (*(unsigned char *)(a1 + 160))
  {
    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table(a1 + 64);
    std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::~__hash_table(a1 + 24);
    uint64_t v3 = (void **)a1;
    std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__destroy_vector::operator()[abi:ne180100](&v3);
  }
  return a1;
}

uint64_t std::construct_at[abi:ne180100]<ZinMirSpatialSplitter::SplitPlan,ZinMirSpatialSplitter::SplitPlan,ZinMirSpatialSplitter::SplitPlan*>(uint64_t a1, uint64_t a2)
{
  *(void *)a1 = 0;
  *(void *)(a1 + 8) = 0;
  *(void *)(a1 + 16) = 0;
  *(_OWORD *)a1 = *(_OWORD *)a2;
  *(void *)(a1 + 16) = *(void *)(a2 + 16);
  *(void *)a2 = 0;
  *(void *)(a2 + 8) = 0;
  *(void *)(a2 + 16) = 0;
  std::__hash_table<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::__unordered_map_hasher<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::hash<long>,std::equal_to<long>,true>,std::__unordered_map_equal<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::equal_to<long>,std::hash<long>,true>,std::allocator<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>>>::__hash_table(a1 + 24, (uint64_t *)(a2 + 24));
  std::__hash_table<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::__unordered_map_hasher<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::hash<long>,std::equal_to<long>,true>,std::__unordered_map_equal<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::equal_to<long>,std::hash<long>,true>,std::allocator<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>>>::__hash_table(a1 + 64, (uint64_t *)(a2 + 64));
  long long v4 = *(_OWORD *)(a2 + 104);
  long long v5 = *(_OWORD *)(a2 + 120);
  *(unsigned char *)(a1 + 136) = *(unsigned char *)(a2 + 136);
  *(_OWORD *)(a1 + 120) = v5;
  *(_OWORD *)(a1 + 104) = v4;
  *(_OWORD *)(a1 + 144) = *(_OWORD *)(a2 + 144);
  *(_DWORD *)(a1 + 160) = *(_DWORD *)(a2 + 160);
  *(void *)(a1 + 176) = 0;
  *(void *)(a1 + 184) = 0;
  *(void *)(a1 + 168) = 0;
  *(_OWORD *)(a1 + 168) = *(_OWORD *)(a2 + 168);
  *(void *)(a1 + 184) = *(void *)(a2 + 184);
  *(void *)(a2 + 168) = 0;
  *(void *)(a2 + 176) = 0;
  *(void *)(a2 + 184) = 0;
  std::__hash_table<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::__unordered_map_hasher<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::hash<long>,std::equal_to<long>,true>,std::__unordered_map_equal<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::equal_to<long>,std::hash<long>,true>,std::allocator<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>>>::__hash_table(a1 + 192, (uint64_t *)(a2 + 192));
  *(_DWORD *)(a1 + 232) = *(_DWORD *)(a2 + 232);
  return a1;
}

uint64_t std::__optional_destruct_base<ZinMirSpatialSplitter::SplitPlan,false>::~__optional_destruct_base[abi:ne180100](uint64_t a1)
{
  if (*(unsigned char *)(a1 + 240))
  {
    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table(a1 + 192);
    uint64_t v2 = *(void **)(a1 + 168);
    if (v2)
    {
      *(void *)(a1 + 176) = v2;
      operator delete(v2);
    }
    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table(a1 + 64);
    std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::~__hash_table(a1 + 24);
    long long v4 = (void **)a1;
    std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__destroy_vector::operator()[abi:ne180100](&v4);
  }
  return a1;
}

__n128 std::pair<TiledLayerTensorRegions,LatencyData>::pair[abi:ne180100](uint64_t a1, uint64_t a2)
{
  *(_OWORD *)a1 = *(_OWORD *)a2;
  long long v2 = *(_OWORD *)(a2 + 16);
  long long v3 = *(_OWORD *)(a2 + 32);
  long long v4 = *(_OWORD *)(a2 + 64);
  *(_OWORD *)(a1 + 48) = *(_OWORD *)(a2 + 48);
  *(_OWORD *)(a1 + 64) = v4;
  *(_OWORD *)(a1 + 16) = v2;
  *(_OWORD *)(a1 + 32) = v3;
  *(void *)(a1 + 88) = 0;
  *(void *)(a1 + 96) = 0;
  *(void *)(a1 + 80) = 0;
  *(_OWORD *)(a1 + 80) = *(_OWORD *)(a2 + 80);
  *(void *)(a1 + 96) = *(void *)(a2 + 96);
  *(void *)(a2 + 80) = 0;
  *(void *)(a2 + 88) = 0;
  *(void *)(a2 + 96) = 0;
  *(void *)(a1 + 104) = 0;
  *(void *)(a1 + 112) = 0;
  *(void *)(a1 + 120) = 0;
  *(_OWORD *)(a1 + 104) = *(_OWORD *)(a2 + 104);
  *(void *)(a1 + 120) = *(void *)(a2 + 120);
  *(void *)(a2 + 104) = 0;
  *(void *)(a2 + 112) = 0;
  *(void *)(a2 + 120) = 0;
  *(void *)(a1 + 128) = 0;
  *(void *)(a1 + 136) = 0;
  *(void *)(a1 + 144) = 0;
  *(_OWORD *)(a1 + 128) = *(_OWORD *)(a2 + 128);
  *(void *)(a1 + 144) = *(void *)(a2 + 144);
  *(void *)(a2 + 128) = 0;
  *(void *)(a2 + 136) = 0;
  *(void *)(a2 + 144) = 0;
  long long v5 = *(_OWORD *)(a2 + 152);
  long long v6 = *(_OWORD *)(a2 + 168);
  *(_OWORD *)(a1 + 184) = *(_OWORD *)(a2 + 184);
  *(_OWORD *)(a1 + 168) = v6;
  *(_OWORD *)(a1 + 152) = v5;
  uint64_t v7 = *(void *)(a2 + 208);
  *(void *)(a1 + 200) = *(void *)(a2 + 200);
  *(void *)(a1 + 208) = v7;
  *(void *)(a1 + 216) = *(void *)(a2 + 216);
  *(void *)(a2 + 200) = 0;
  *(void *)(a2 + 208) = 0;
  *(void *)(a2 + 216) = 0;
  __n128 result = *(__n128 *)(a2 + 224);
  long long v9 = *(_OWORD *)(a2 + 240);
  *(__n128 *)(a1 + 224) = result;
  *(_OWORD *)(a1 + 240) = v9;
  return result;
}

void std::vector<std::pair<TiledLayerTensorRegions,LatencyData>>::__swap_out_circular_buffer(uint64_t *a1, void *a2)
{
  uint64_t v5 = *a1;
  uint64_t v4 = a1[1];
  uint64_t v6 = a2[1];
  while (v4 != v5)
  {
    v4 -= 256;
    std::pair<TiledLayerTensorRegions,LatencyData>::pair[abi:ne180100](v6 - 256, v4);
  }
  a2[1] = v6;
  uint64_t v7 = *a1;
  *a1 = v6;
  a2[1] = v7;
  uint64_t v8 = a1[1];
  a1[1] = a2[2];
  a2[2] = v8;
  uint64_t v9 = a1[2];
  a1[2] = a2[3];
  a2[3] = v9;
  *a2 = a2[1];
}

void *std::__allocate_at_least[abi:ne180100]<std::allocator<std::pair<TiledLayerTensorRegions,LatencyData>>>(uint64_t a1, unint64_t a2)
{
  if (HIBYTE(a2)) {
    std::__throw_bad_array_new_length[abi:ne180100]();
  }
  return operator new(a2 << 8);
}

uint64_t std::__split_buffer<std::pair<TiledLayerTensorRegions,LatencyData>>::~__split_buffer(uint64_t a1)
{
  uint64_t v3 = *(void *)(a1 + 8);
  for (uint64_t i = *(void *)(a1 + 16); i != v3; uint64_t i = *(void *)(a1 + 16))
  {
    *(void *)(a1 + 16) = i - 256;
    std::__destroy_at[abi:ne180100]<TiledLayerTensorRegions,0>((void *)(i - 256));
  }
  if (*(void *)a1) {
    operator delete(*(void **)a1);
  }
  return a1;
}

void std::vector<std::pair<TiledLayerTensorRegions,LatencyData>>::__destroy_vector::operator()[abi:ne180100](void ***a1)
{
  uint64_t v1 = *a1;
  long long v2 = **a1;
  if (v2)
  {
    uint64_t v4 = v1[1];
    uint64_t v5 = **a1;
    if (v4 != v2)
    {
      do
      {
        v4 -= 32;
        std::__destroy_at[abi:ne180100]<TiledLayerTensorRegions,0>(v4);
      }
      while (v4 != v2);
      uint64_t v5 = **a1;
    }
    v1[1] = v2;
    operator delete(v5);
  }
}

char *std::vector<std::optional<BOOL>>::__assign_with_size[abi:ne180100]<std::optional<BOOL> const*,std::optional<BOOL> const*>(char *result, char *__src, uint64_t a3, unint64_t a4)
{
  uint64_t v7 = result;
  unint64_t v8 = *((void *)result + 2);
  uint64_t v9 = *(char **)result;
  if (a4 > (uint64_t)(v8 - *(void *)result) >> 1)
  {
    if (v9)
    {
      *((void *)result + 1) = v9;
      operator delete(v9);
      unint64_t v8 = 0;
      void *v7 = 0;
      v7[1] = 0;
      v7[2] = 0;
    }
    if ((a4 & 0x8000000000000000) != 0) {
      std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
    }
    if (v8 <= a4) {
      unint64_t v10 = a4;
    }
    else {
      unint64_t v10 = v8;
    }
    if (v8 >= 0x7FFFFFFFFFFFFFFELL) {
      uint64_t v11 = 0x7FFFFFFFFFFFFFFFLL;
    }
    else {
      uint64_t v11 = v10;
    }
    __n128 result = std::vector<half>::__vallocate[abi:ne180100](v7, v11);
    char v13 = (char *)v7[1];
    uint64_t v12 = (void **)(v7 + 1);
    uint64_t v9 = v13;
LABEL_17:
    size_t v17 = a3 - (void)__src;
    if (v17)
    {
      unint64_t v18 = v9;
      std::string v19 = __src;
      goto LABEL_19;
    }
    goto LABEL_20;
  }
  uint64_t v12 = (void **)(result + 8);
  unint64_t v14 = (unsigned char *)*((void *)result + 1);
  unint64_t v15 = (v14 - v9) >> 1;
  if (v15 >= a4) {
    goto LABEL_17;
  }
  unint64_t v16 = &__src[2 * v15];
  if (v14 != v9)
  {
    __n128 result = (char *)memmove(*(void **)result, __src, v14 - v9);
    uint64_t v9 = (char *)*v12;
  }
  size_t v17 = a3 - (void)v16;
  if (v17)
  {
    unint64_t v18 = v9;
    std::string v19 = v16;
LABEL_19:
    __n128 result = (char *)memmove(v18, v19, v17);
  }
LABEL_20:
  *uint64_t v12 = &v9[v17];
  return result;
}

BOOL std::__equal_to::operator()[abi:ne180100]<std::vector<ZinTensorRegion>,std::vector<ZinTensorRegion>>(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v3 = *(void **)a2;
  uint64_t v4 = *(void **)(a2 + 8);
  uint64_t v5 = *(void **)a3;
  if ((void *)((char *)v4 - *(void *)a2) != (void *)(*(void *)(a3 + 8) - *(void *)a3)) {
    return 0;
  }
  if (v3 == v4) {
    return 1;
  }
  do
  {
    BOOL result = ZinTensorRegion::operator==(v3, v5);
    if (!result) {
      break;
    }
    v3 += 10;
    v5 += 10;
  }
  while (v3 != v4);
  return result;
}

void LayerTilingHelper::LayerTilingHelper(LayerTilingHelper *this, const LayerTilingHelper *a2)
{
  *(_OWORD *)this = *(_OWORD *)a2;
  *((void *)this + 2) = 0;
  *((void *)this + 3) = 0;
  *((void *)this + 4) = 0;
  std::vector<ANEDebugInfo::DebugInfoInMem::TD>::__init_with_size[abi:ne180100]<ANEDebugInfo::DebugInfoInMem::TD*,ANEDebugInfo::DebugInfoInMem::TD*>((void *)this + 2, *((const void **)a2 + 2), *((void *)a2 + 3), 0x8E38E38E38E38E39 * ((uint64_t)(*((void *)a2 + 3) - *((void *)a2 + 2)) >> 3));
  std::vector<BOOL>::vector((void *)this + 5, (uint64_t)a2 + 40);
  long long v4 = *((_OWORD *)a2 + 6);
  long long v5 = *((_OWORD *)a2 + 7);
  long long v6 = *((_OWORD *)a2 + 8);
  long long v8 = *((_OWORD *)a2 + 4);
  long long v7 = *((_OWORD *)a2 + 5);
  *((void *)this + 18) = 0;
  *((_OWORD *)this + 7) = v5;
  *((_OWORD *)this + 8) = v6;
  *((_OWORD *)this + 5) = v7;
  *((_OWORD *)this + 6) = v4;
  *((_OWORD *)this + 4) = v8;
  *((void *)this + 19) = 0;
  *((void *)this + 20) = 0;
  std::vector<ZinOcgKernelData>::__init_with_size[abi:ne180100]<ZinOcgKernelData*,ZinOcgKernelData*>((void *)this + 18, *((const void **)a2 + 18), *((void *)a2 + 19), 0x6DB6DB6DB6DB6DB7 * ((uint64_t)(*((void *)a2 + 19) - *((void *)a2 + 18)) >> 3));
  *((void *)this + 21) = 0;
  *((void *)this + 22) = 0;
  *((void *)this + 23) = 0;
  std::vector<ZinOcgKernelData>::__init_with_size[abi:ne180100]<ZinOcgKernelData*,ZinOcgKernelData*>((void *)this + 21, *((const void **)a2 + 21), *((void *)a2 + 22), 0x6DB6DB6DB6DB6DB7 * ((uint64_t)(*((void *)a2 + 22) - *((void *)a2 + 21)) >> 3));
}

void sub_21127B478(_Unwind_Exception *exception_object)
{
  long long v6 = *v4;
  if (*v4)
  {
    *(void *)(v1 + 152) = v6;
    operator delete(v6);
  }
  if (*v3) {
    operator delete(*v3);
  }
  long long v7 = *v2;
  if (*v2)
  {
    *(void *)(v1 + 24) = v7;
    operator delete(v7);
  }
  _Unwind_Resume(exception_object);
}

double std::__set_difference[abi:ne180100]<std::_ClassicAlgPolicy,std::__less<void,void>,std::__tree_const_iterator<ZinIrOpLayer *,std::__tree_node<ZinIrOpLayer *,void *> *,long> &,std::__tree_const_iterator<ZinIrOpLayer *,std::__tree_node<ZinIrOpLayer *,void *> *,long> &,std::__tree_const_iterator<ZinIrOpLayer *,std::__tree_node<ZinIrOpLayer *,void *> *,long> &,std::__tree_const_iterator<ZinIrOpLayer *,std::__tree_node<ZinIrOpLayer *,void *> *,long> &,std::insert_iterator<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>> &>@<D0>(ZinIrOpLayer ***a1@<X0>, ZinIrOpLayer ***a2@<X1>, uint64_t a3@<X2>, void *a4@<X3>, uint64_t *a5@<X4>, uint64_t a6@<X8>)
{
  unint64_t v10 = *a1;
  uint64_t v11 = *a2;
  if (*a1 == *a2)
  {
LABEL_31:
    uint64_t v11 = v10;
    goto LABEL_32;
  }
  for (uint64_t i = *(void **)a3; *(void *)a3 != *a4; uint64_t i = *(void **)a3)
  {
    unint64_t v15 = v10[4];
    unint64_t v16 = i[4];
    if ((unint64_t)v15 >= v16)
    {
      if (v16 >= (unint64_t)v15)
      {
        uint64_t v23 = v10[1];
        if (v23)
        {
          do
          {
            uint64_t v24 = (ZinIrOpLayer ***)v23;
            uint64_t v23 = *(ZinIrOpLayer **)v23;
          }
          while (v23);
        }
        else
        {
          do
          {
            uint64_t v24 = (ZinIrOpLayer ***)v10[2];
            BOOL v20 = *v24 == v10;
            unint64_t v10 = (ZinIrOpLayer **)v24;
          }
          while (!v20);
        }
        *a1 = (ZinIrOpLayer **)v24;
        uint64_t v25 = *(void **)a3;
        uint64_t v26 = *(void **)(*(void *)a3 + 8);
        if (v26)
        {
          do
          {
            uint64_t v27 = v26;
            uint64_t v26 = (void *)*v26;
          }
          while (v26);
        }
        else
        {
          do
          {
            uint64_t v27 = (void *)v25[2];
            BOOL v20 = *v27 == (void)v25;
            uint64_t v25 = v27;
          }
          while (!v20);
        }
        *(void *)a3 = v27;
      }
      else
      {
        uint64_t v21 = (void *)i[1];
        if (v21)
        {
          do
          {
            uint64_t v22 = v21;
            uint64_t v21 = (void *)*v21;
          }
          while (v21);
        }
        else
        {
          do
          {
            uint64_t v22 = (void *)i[2];
            BOOL v20 = *v22 == (void)i;
            uint64_t i = v22;
          }
          while (!v20);
        }
        *(void *)a3 = v22;
      }
    }
    else
    {
      std::insert_iterator<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::operator=[abi:ne180100]((uint64_t)a5, v10 + 4);
      size_t v17 = *a1;
      unint64_t v18 = (*a1)[1];
      if (v18)
      {
        do
        {
          std::string v19 = (ZinIrOpLayer ***)v18;
          unint64_t v18 = *(ZinIrOpLayer **)v18;
        }
        while (v18);
      }
      else
      {
        do
        {
          std::string v19 = (ZinIrOpLayer ***)v17[2];
          BOOL v20 = *v19 == v17;
          size_t v17 = (ZinIrOpLayer **)v19;
        }
        while (!v20);
      }
      *a1 = (ZinIrOpLayer **)v19;
    }
    unint64_t v10 = *a1;
    uint64_t v11 = *a2;
    if (*a1 == *a2) {
      goto LABEL_31;
    }
  }
LABEL_32:
  std::__copy_loop<std::_ClassicAlgPolicy>::operator()[abi:ne180100]<std::__tree_const_iterator<ZinIrOpLayer *,std::__tree_node<ZinIrOpLayer *,void *> *,long>,std::__tree_const_iterator<ZinIrOpLayer *,std::__tree_node<ZinIrOpLayer *,void *> *,long>,std::insert_iterator<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>>(v10, v11, *a5, a5[1], (uint64_t)&v29);
  *(void *)a6 = v29;
  double result = *(double *)&v30;
  *(_OWORD *)(a6 + 8) = v30;
  return result;
}

void std::vector<TiledLayerTensorRegions>::__assign_with_size[abi:ne180100]<TiledLayerTensorRegions*,TiledLayerTensorRegions*>(uint64_t *a1, uint64_t a2, uint64_t a3, unint64_t a4)
{
  uint64_t v8 = (uint64_t)(a1 + 2);
  uint64_t v9 = *a1;
  if (0x6DB6DB6DB6DB6DB7 * ((a1[2] - *a1) >> 5) < a4)
  {
    std::vector<TiledLayerTensorRegions>::__vdeallocate(a1);
    if (a4 > 0x124924924924924) {
      std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
    }
    unint64_t v10 = 0xDB6DB6DB6DB6DB6ELL * ((a1[2] - *a1) >> 5);
    if (v10 <= a4) {
      unint64_t v10 = a4;
    }
    if ((unint64_t)(0x6DB6DB6DB6DB6DB7 * ((a1[2] - *a1) >> 5)) >= 0x92492492492492) {
      unint64_t v11 = 0x124924924924924;
    }
    else {
      unint64_t v11 = v10;
    }
    std::vector<TiledLayerTensorRegions>::__vallocate[abi:ne180100](a1, v11);
    uint64_t v12 = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<TiledLayerTensorRegions>,TiledLayerTensorRegions*,TiledLayerTensorRegions*,TiledLayerTensorRegions*>(v8, a2, a3, a1[1]);
    goto LABEL_11;
  }
  if (0x6DB6DB6DB6DB6DB7 * ((a1[1] - v9) >> 5) < a4)
  {
    uint64_t v13 = a2 + 32 * ((a1[1] - v9) >> 5);
    std::__copy_loop<std::_ClassicAlgPolicy>::operator()[abi:ne180100]<TiledLayerTensorRegions *,TiledLayerTensorRegions *,TiledLayerTensorRegions *>((uint64_t)&v17, a2, v13, v9);
    uint64_t v12 = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<TiledLayerTensorRegions>,TiledLayerTensorRegions*,TiledLayerTensorRegions*,TiledLayerTensorRegions*>(v8, v13, a3, a1[1]);
LABEL_11:
    a1[1] = v12;
    return;
  }
  std::__copy_loop<std::_ClassicAlgPolicy>::operator()[abi:ne180100]<TiledLayerTensorRegions *,TiledLayerTensorRegions *,TiledLayerTensorRegions *>((uint64_t)&v18, a2, a3, v9);
  unint64_t v15 = v14;
  unint64_t v16 = (void *)a1[1];
  if (v16 != v14)
  {
    do
    {
      v16 -= 28;
      std::__destroy_at[abi:ne180100]<TiledLayerTensorRegions,0>(v16);
    }
    while (v16 != v15);
  }
  a1[1] = (uint64_t)v15;
}

void sub_21127B7FC(_Unwind_Exception *a1)
{
  *(void *)(v1 + 8) = v2;
  _Unwind_Resume(a1);
}

void sub_21127B804(_Unwind_Exception *a1)
{
  *(void *)(v1 + 8) = v2;
  _Unwind_Resume(a1);
}

void std::vector<TiledLayerTensorRegions>::__vdeallocate(void *a1)
{
  uint64_t v1 = (void *)*a1;
  if (*a1)
  {
    uint64_t v3 = (void *)a1[1];
    long long v4 = (void *)*a1;
    if (v3 != v1)
    {
      do
      {
        v3 -= 28;
        std::__destroy_at[abi:ne180100]<TiledLayerTensorRegions,0>(v3);
      }
      while (v3 != v1);
      long long v4 = (void *)*a1;
    }
    a1[1] = v1;
    operator delete(v4);
    *a1 = 0;
    a1[1] = 0;
    a1[2] = 0;
  }
}

uint64_t std::__copy_loop<std::_ClassicAlgPolicy>::operator()[abi:ne180100]<TiledLayerTensorRegions *,TiledLayerTensorRegions *,TiledLayerTensorRegions *>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  if (a2 == a3) {
    return a2;
  }
  uint64_t v5 = a3;
  uint64_t v6 = a2 + 136;
  do
  {
    uint64_t v7 = v6 - 136;
    *(_OWORD *)a4 = *(_OWORD *)(v6 - 136);
    long long v8 = *(_OWORD *)(v6 - 120);
    long long v9 = *(_OWORD *)(v6 - 104);
    long long v10 = *(_OWORD *)(v6 - 72);
    *(_OWORD *)(a4 + 48) = *(_OWORD *)(v6 - 88);
    *(_OWORD *)(a4 + 64) = v10;
    *(_OWORD *)(a4 + 16) = v8;
    *(_OWORD *)(a4 + 32) = v9;
    if (a4 != v6 - 136)
    {
      std::vector<ZinTensorDimensions>::__assign_with_size[abi:ne180100]<ZinTensorDimensions const*,ZinTensorDimensions const*>((char *)(a4 + 80), *(char **)(v6 - 56), *(void *)(v6 - 48), 0xCCCCCCCCCCCCCCCDLL * ((uint64_t)(*(void *)(v6 - 48) - *(void *)(v6 - 56)) >> 3));
      std::vector<LogicalDimensions>::__assign_with_size[abi:ne180100]<LogicalDimensions*,LogicalDimensions*>((char *)(a4 + 104), *(char **)(v6 - 32), *(void *)(v6 - 24), 0x8E38E38E38E38E39 * ((uint64_t)(*(void *)(v6 - 24) - *(void *)(v6 - 32)) >> 3));
      std::vector<WorkUnit>::__assign_with_size[abi:ne180100]<WorkUnit*,WorkUnit*>((char *)(a4 + 128), *(char **)(v6 - 8), *(void *)v6, 0xCCCCCCCCCCCCCCCDLL * ((uint64_t)(*(void *)v6 - *(void *)(v6 - 8)) >> 4));
    }
    long long v11 = *(_OWORD *)(v6 + 16);
    long long v12 = *(_OWORD *)(v6 + 32);
    *(_OWORD *)(a4 + 184) = *(_OWORD *)(v6 + 48);
    *(_OWORD *)(a4 + 168) = v12;
    *(_OWORD *)(a4 + 152) = v11;
    std::vector<BOOL>::operator=((void **)(a4 + 200), v6 + 64);
    a4 += 224;
    v6 += 224;
  }
  while (v7 + 224 != v5);
  return v5;
}

double std::__set_difference[abi:ne180100]<std::_ClassicAlgPolicy,ScheduleComparator &,std::__tree_const_iterator<ZinIrOpLayer *,std::__tree_node<ZinIrOpLayer *,void *> *,long> &,std::__tree_const_iterator<ZinIrOpLayer *,std::__tree_node<ZinIrOpLayer *,void *> *,long> &,std::__tree_const_iterator<ZinIrOpLayer *,std::__tree_node<ZinIrOpLayer *,void *> *,long> &,std::__tree_const_iterator<ZinIrOpLayer *,std::__tree_node<ZinIrOpLayer *,void *> *,long> &,std::insert_iterator<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>> &>@<D0>(ZinIrOpLayer ***a1@<X0>, ZinIrOpLayer ***a2@<X1>, uint64_t a3@<X2>, void *a4@<X3>, uint64_t *a5@<X4>, int a6@<W5>, uint64_t a7@<X8>)
{
  long long v11 = *a1;
  long long v12 = *a2;
  if (*a1 == *a2)
  {
LABEL_31:
    long long v12 = v11;
    goto LABEL_32;
  }
  for (uint64_t i = *(void **)a3; *(void *)a3 != *a4; uint64_t i = *(void **)a3)
  {
    if (ScheduleComparator::operator()(a6, v11[4], (ZinIrOpLayer *)i[4]))
    {
      std::insert_iterator<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::operator=[abi:ne180100]((uint64_t)a5, *a1 + 4);
      char v17 = *a1;
      char v18 = (*a1)[1];
      if (v18)
      {
        do
        {
          std::string v19 = (ZinIrOpLayer ***)v18;
          char v18 = *(ZinIrOpLayer **)v18;
        }
        while (v18);
      }
      else
      {
        do
        {
          std::string v19 = (ZinIrOpLayer ***)v17[2];
          BOOL v20 = *v19 == v17;
          char v17 = (ZinIrOpLayer **)v19;
        }
        while (!v20);
      }
      *a1 = (ZinIrOpLayer **)v19;
    }
    else
    {
      if (ScheduleComparator::operator()(a6, *(ZinIrOpLayer **)(*(void *)a3 + 32), (*a1)[4]))
      {
        uint64_t v21 = *(void **)a3;
        uint64_t v22 = *(void **)(*(void *)a3 + 8);
        if (v22)
        {
          do
          {
            uint64_t v23 = v22;
            uint64_t v22 = (void *)*v22;
          }
          while (v22);
        }
        else
        {
          do
          {
            uint64_t v23 = (void *)v21[2];
            BOOL v20 = *v23 == (void)v21;
            uint64_t v21 = v23;
          }
          while (!v20);
        }
      }
      else
      {
        uint64_t v24 = *a1;
        uint64_t v25 = (*a1)[1];
        if (v25)
        {
          do
          {
            uint64_t v26 = (ZinIrOpLayer ***)v25;
            uint64_t v25 = *(ZinIrOpLayer **)v25;
          }
          while (v25);
        }
        else
        {
          do
          {
            uint64_t v26 = (ZinIrOpLayer ***)v24[2];
            BOOL v20 = *v26 == v24;
            uint64_t v24 = (ZinIrOpLayer **)v26;
          }
          while (!v20);
        }
        *a1 = (ZinIrOpLayer **)v26;
        uint64_t v27 = *(void **)a3;
        uint64_t v28 = *(void **)(*(void *)a3 + 8);
        if (v28)
        {
          do
          {
            uint64_t v23 = v28;
            uint64_t v28 = (void *)*v28;
          }
          while (v28);
        }
        else
        {
          do
          {
            uint64_t v23 = (void *)v27[2];
            BOOL v20 = *v23 == (void)v27;
            uint64_t v27 = v23;
          }
          while (!v20);
        }
      }
      *(void *)a3 = v23;
    }
    long long v11 = *a1;
    long long v12 = *a2;
    if (*a1 == *a2) {
      goto LABEL_31;
    }
  }
LABEL_32:
  std::__copy_loop<std::_ClassicAlgPolicy>::operator()[abi:ne180100]<std::__tree_const_iterator<ZinIrOpLayer *,std::__tree_node<ZinIrOpLayer *,void *> *,long>,std::__tree_const_iterator<ZinIrOpLayer *,std::__tree_node<ZinIrOpLayer *,void *> *,long>,std::insert_iterator<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>>(v11, v12, *a5, a5[1], (uint64_t)&v30);
  *(void *)a7 = v30;
  double result = *(double *)&v31;
  *(_OWORD *)(a7 + 8) = v31;
  return result;
}

double std::__set_intersection[abi:ne180100]<std::_ClassicAlgPolicy,ScheduleComparator &,std::__tree_const_iterator<ZinIrOpLayer *,std::__tree_node<ZinIrOpLayer *,void *> *,long>,std::__tree_const_iterator<ZinIrOpLayer *,std::__tree_node<ZinIrOpLayer *,void *> *,long>,std::__tree_const_iterator<ZinIrOpLayer *,std::__tree_node<ZinIrOpLayer *,void *> *,long>,std::__tree_const_iterator<ZinIrOpLayer *,std::__tree_node<ZinIrOpLayer *,void *> *,long>,std::insert_iterator<std::set<ZinIrOpLayer *>>>@<D0>(void *a1@<X0>, void *a2@<X1>, void *a3@<X2>, void *a4@<X3>, uint64_t a5@<X4>, uint64_t a6@<X5>, int a7@<W6>, uint64_t a8@<X8>)
{
  *(void *)&long long v22 = a5;
  *((void *)&v22 + 1) = a6;
  if (a1 != a2)
  {
    long long v11 = a3;
    if (a3 != a4)
    {
      uint64_t v13 = a1;
      do
      {
        if (ScheduleComparator::operator()(a7, (ZinIrOpLayer *)v13[4], (ZinIrOpLayer *)v11[4]))
        {
          unint64_t v14 = (void *)v13[1];
          if (v14)
          {
            do
            {
              uint64_t v13 = v14;
              unint64_t v14 = (void *)*v14;
            }
            while (v14);
          }
          else
          {
            do
            {
              unint64_t v15 = v13;
              uint64_t v13 = (void *)v13[2];
            }
            while ((void *)*v13 != v15);
          }
        }
        else
        {
          if (ScheduleComparator::operator()(a7, (ZinIrOpLayer *)v11[4], (ZinIrOpLayer *)v13[4]))
          {
            unint64_t v16 = v13;
          }
          else
          {
            std::insert_iterator<std::set<unsigned long long>>::operator=[abi:ne180100]((uint64_t)&v22, v13 + 4);
            char v17 = (void *)v13[1];
            if (v17)
            {
              do
              {
                unint64_t v16 = v17;
                char v17 = (void *)*v17;
              }
              while (v17);
            }
            else
            {
              do
              {
                unint64_t v16 = (void *)v13[2];
                BOOL v18 = *v16 == (void)v13;
                uint64_t v13 = v16;
              }
              while (!v18);
            }
          }
          std::string v19 = (void *)v11[1];
          if (v19)
          {
            do
            {
              long long v11 = v19;
              std::string v19 = (void *)*v19;
            }
            while (v19);
          }
          else
          {
            do
            {
              BOOL v20 = v11;
              long long v11 = (void *)v11[2];
            }
            while ((void *)*v11 != v20);
          }
          uint64_t v13 = v16;
        }
      }
      while (v13 != a2 && v11 != a4);
    }
  }
  *(void *)a8 = a2;
  *(void *)(a8 + 8) = a4;
  double result = *(double *)&v22;
  *(_OWORD *)(a8 + 16) = v22;
  return result;
}

uint64_t std::list<ZinIrOpLayer *>::__move_assign(uint64_t *a1, void *a2)
{
  return std::list<ZinIrOpLayer *>::splice((uint64_t)a1, a1, a2);
}

void std::vector<std::map<ZinIrDimension,unsigned long>>::__vdeallocate(void **a1)
{
  uint64_t v1 = (char *)*a1;
  if (*a1)
  {
    uint64_t v3 = (char *)a1[1];
    long long v4 = *a1;
    if (v3 != v1)
    {
      do
      {
        uint64_t v5 = v3 - 24;
        std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)(v3 - 24), *((void **)v3 - 2));
        uint64_t v3 = v5;
      }
      while (v5 != v1);
      long long v4 = *a1;
    }
    a1[1] = v1;
    operator delete(v4);
    *a1 = 0;
    a1[1] = 0;
    a1[2] = 0;
  }
}

uint64_t std::vector<SubgraphSplitInfo>::__emplace_back_slow_path<SubgraphSplitInfo&>(uint64_t *a1, const SubgraphSplitInfo *a2)
{
  uint64_t v3 = *a1;
  unint64_t v4 = 0x823EE08FB823EE09 * ((a1[1] - *a1) >> 3);
  unint64_t v5 = v4 + 1;
  if (v4 + 1 > 0x8FB823EE08FB82) {
    std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
  }
  uint64_t v7 = (uint64_t)(a1 + 2);
  unint64_t v8 = 0x823EE08FB823EE09 * ((a1[2] - v3) >> 3);
  if (2 * v8 > v5) {
    unint64_t v5 = 2 * v8;
  }
  if (v8 >= 0x47DC11F7047DC1) {
    unint64_t v9 = 0x8FB823EE08FB82;
  }
  else {
    unint64_t v9 = v5;
  }
  char v17 = a1 + 2;
  if (v9) {
    long long v10 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<SubgraphSplitInfo>>(v7, v9);
  }
  else {
    long long v10 = 0;
  }
  uint64_t v13 = v10;
  unint64_t v14 = (SubgraphSplitInfo *)&v10[456 * v4];
  unint64_t v16 = &v10[456 * v9];
  SubgraphSplitInfo::SubgraphSplitInfo(v14, a2);
  unint64_t v15 = (char *)v14 + 456;
  std::vector<SubgraphSplitInfo>::__swap_out_circular_buffer(a1, &v13);
  uint64_t v11 = a1[1];
  std::__split_buffer<SubgraphSplitInfo>::~__split_buffer((uint64_t)&v13);
  return v11;
}

void sub_21127BE64(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::__split_buffer<SubgraphSplitInfo>::~__split_buffer((uint64_t)va);
  _Unwind_Resume(a1);
}

uint64_t std::vector<SubgraphSplitInfo>::__swap_out_circular_buffer(uint64_t *a1, void *a2)
{
  uint64_t v5 = *a1;
  uint64_t v4 = a1[1];
  uint64_t result = a2[1];
  while (v4 != v5)
  {
    v4 -= 456;
    uint64_t result = SubgraphSplitInfo::SubgraphSplitInfo(result - 456, v4);
  }
  a2[1] = result;
  uint64_t v7 = *a1;
  *a1 = result;
  a2[1] = v7;
  uint64_t v8 = a1[1];
  a1[1] = a2[2];
  a2[2] = v8;
  uint64_t v9 = a1[2];
  a1[2] = a2[3];
  a2[3] = v9;
  *a2 = a2[1];
  return result;
}

void *std::__allocate_at_least[abi:ne180100]<std::allocator<SubgraphSplitInfo>>(uint64_t a1, unint64_t a2)
{
  if (a2 >= 0x8FB823EE08FB83) {
    std::__throw_bad_array_new_length[abi:ne180100]();
  }
  return operator new(456 * a2);
}

uint64_t SubgraphSplitInfo::SubgraphSplitInfo(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = (void *)Subgraph::Subgraph(a1, a2);
  v4[19] = 0;
  v4[20] = 0;
  v4[21] = 0;
  *(_OWORD *)(v4 + 19) = *(_OWORD *)(a2 + 152);
  v4[21] = *(void *)(a2 + 168);
  *(void *)(a2 + 152) = 0;
  *(void *)(a2 + 160) = 0;
  *(void *)(a2 + 168) = 0;
  std::__hash_table<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::__unordered_map_hasher<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::hash<long>,std::equal_to<long>,true>,std::__unordered_map_equal<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::equal_to<long>,std::hash<long>,true>,std::allocator<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>>>::__hash_table((uint64_t)(v4 + 22), (uint64_t *)(a2 + 176));
  std::__hash_table<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::__unordered_map_hasher<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::hash<long>,std::equal_to<long>,true>,std::__unordered_map_equal<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::equal_to<long>,std::hash<long>,true>,std::allocator<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>>>::__hash_table(a1 + 216, (uint64_t *)(a2 + 216));
  long long v5 = *(_OWORD *)(a2 + 256);
  long long v6 = *(_OWORD *)(a2 + 272);
  *(unsigned char *)(a1 + 288) = *(unsigned char *)(a2 + 288);
  *(_OWORD *)(a1 + 256) = v5;
  *(_OWORD *)(a1 + 272) = v6;
  *(void *)(a1 + 296) = *(void *)(a2 + 296);
  uint64_t v7 = a1 + 304;
  uint64_t v8 = *(void *)(a2 + 304);
  *(void *)(a1 + 304) = v8;
  uint64_t v9 = *(void *)(a2 + 312);
  *(void *)(a1 + 312) = v9;
  if (v9)
  {
    *(void *)(v8 + 16) = v7;
    *(void *)(a2 + 296) = a2 + 304;
    *(void *)(a2 + 304) = 0;
    *(void *)(a2 + 312) = 0;
  }
  else
  {
    *(void *)(a1 + 296) = v7;
  }
  *(void *)(a1 + 320) = *(void *)(a2 + 320);
  uint64_t v10 = a1 + 328;
  uint64_t v11 = *(void *)(a2 + 328);
  *(void *)(a1 + 328) = v11;
  uint64_t v12 = *(void *)(a2 + 336);
  *(void *)(a1 + 336) = v12;
  if (v12)
  {
    *(void *)(v11 + 16) = v10;
    *(void *)(a2 + 320) = a2 + 328;
    *(void *)(a2 + 328) = 0;
    *(void *)(a2 + 336) = 0;
  }
  else
  {
    *(void *)(a1 + 320) = v10;
  }
  *(void *)(a1 + 344) = *(void *)(a2 + 344);
  uint64_t v13 = a1 + 352;
  uint64_t v14 = *(void *)(a2 + 352);
  *(void *)(a1 + 352) = v14;
  uint64_t v15 = *(void *)(a2 + 360);
  *(void *)(a1 + 360) = v15;
  if (v15)
  {
    *(void *)(v14 + 16) = v13;
    *(void *)(a2 + 344) = a2 + 352;
    *(void *)(a2 + 352) = 0;
    *(void *)(a2 + 360) = 0;
  }
  else
  {
    *(void *)(a1 + 344) = v13;
  }
  *(void *)(a1 + 368) = *(void *)(a2 + 368);
  uint64_t v16 = a1 + 376;
  uint64_t v17 = *(void *)(a2 + 376);
  *(void *)(a1 + 376) = v17;
  uint64_t v18 = *(void *)(a2 + 384);
  *(void *)(a1 + 384) = v18;
  if (v18)
  {
    *(void *)(v17 + 16) = v16;
    *(void *)(a2 + 368) = a2 + 376;
    *(void *)(a2 + 376) = 0;
    *(void *)(a2 + 384) = 0;
  }
  else
  {
    *(void *)(a1 + 368) = v16;
  }
  *(void *)(a1 + 392) = *(void *)(a2 + 392);
  uint64_t v19 = a1 + 400;
  uint64_t v20 = *(void *)(a2 + 400);
  *(void *)(a1 + 400) = v20;
  uint64_t v21 = *(void *)(a2 + 408);
  *(void *)(a1 + 408) = v21;
  if (v21)
  {
    *(void *)(v20 + 16) = v19;
    *(void *)(a2 + 392) = a2 + 400;
    *(void *)(a2 + 400) = 0;
    *(void *)(a2 + 408) = 0;
  }
  else
  {
    *(void *)(a1 + 392) = v19;
  }
  std::__hash_table<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::__unordered_map_hasher<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::hash<long>,std::equal_to<long>,true>,std::__unordered_map_equal<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::equal_to<long>,std::hash<long>,true>,std::allocator<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>>>::__hash_table(a1 + 416, (uint64_t *)(a2 + 416));
  return a1;
}

uint64_t std::__split_buffer<SubgraphSplitInfo>::~__split_buffer(uint64_t a1)
{
  uint64_t v3 = *(void *)(a1 + 8);
  for (uint64_t i = *(void *)(a1 + 16); i != v3; uint64_t i = *(void *)(a1 + 16))
  {
    *(void *)(a1 + 16) = i - 456;
    SubgraphSplitInfo::~SubgraphSplitInfo((SubgraphSplitInfo *)(i - 456));
  }
  if (*(void *)a1) {
    operator delete(*(void **)a1);
  }
  return a1;
}

void SubgraphSplitInfo::~SubgraphSplitInfo(SubgraphSplitInfo *this)
{
  uint64_t v2 = (char *)this + 296;
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)this + 416);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)this + 392, *((void **)this + 50));
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)this + 368, *((void **)this + 47));
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)this + 344, *((void **)this + 44));
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)this + 320, *((void **)this + 41));
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v2, *((void **)this + 38));
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)this + 216);
  std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::~__hash_table((uint64_t)this + 176);
  uint64_t v3 = (void **)((char *)this + 152);
  std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__destroy_vector::operator()[abi:ne180100](&v3);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)this + 120, *((void **)this + 16));
  uint64_t v3 = (void **)((char *)this + 96);
  std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100](&v3);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)this + 72, *((void **)this + 10));
  std::__list_imp<ZinIrSection *>::clear((void *)this + 6);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)this + 24, *((void **)this + 4));
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)this, *((void **)this + 1));
}

void std::vector<SubgraphSplitInfo>::__destroy_vector::operator()[abi:ne180100](void ***a1)
{
  uint64_t v1 = *a1;
  uint64_t v2 = (char *)**a1;
  if (v2)
  {
    uint64_t v4 = (char *)v1[1];
    long long v5 = v2;
    if (v4 != v2)
    {
      do
        SubgraphSplitInfo::~SubgraphSplitInfo((SubgraphSplitInfo *)(v4 - 456));
      while (v4 != v2);
      long long v5 = **a1;
    }
    v1[1] = v2;
    operator delete(v5);
  }
}

char *std::vector<Subgraph>::__vallocate[abi:ne180100](void *a1, unint64_t a2)
{
  if (a2 >= 0x1AF286BCA1AF287) {
    std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
  }
  uint64_t result = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<Subgraph>>((uint64_t)(a1 + 2), a2);
  *a1 = result;
  a1[1] = result;
  a1[2] = &result[152 * v4];
  return result;
}

uint64_t std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<Subgraph>,Subgraph const*,Subgraph const*,Subgraph*>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  if (a2 != a3)
  {
    uint64_t v7 = 0;
    do
    {
      Subgraph::Subgraph((Subgraph *)(a4 + v7), (const Subgraph *)(a2 + v7));
      v7 += 152;
    }
    while (a2 + v7 != a3);
    a4 += v7;
  }
  return a4;
}

void sub_21127C34C(_Unwind_Exception *exception_object)
{
  if (v2)
  {
    uint64_t v4 = v1 - 152;
    do
    {
      std::__destroy_at[abi:ne180100]<Subgraph,0>(v4 + v2);
      v2 -= 152;
    }
    while (v2);
  }
  _Unwind_Resume(exception_object);
}

void SubgraphSplitInfo::SubgraphSplitInfo(SubgraphSplitInfo *this, const SubgraphSplitInfo *a2)
{
  Subgraph::Subgraph(this, a2);
  v4[19] = 0;
  v4[20] = 0;
  v4[21] = 0;
  std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__init_with_size[abi:ne180100]<std::vector<std::optional<TiledLayerTensorRegions>>*,std::vector<std::optional<TiledLayerTensorRegions>>*>(v4 + 19, *((uint64_t **)a2 + 19), *((uint64_t **)a2 + 20), 0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*((void *)a2 + 20) - *((void *)a2 + 19)) >> 3));
  std::unordered_map<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>::unordered_map((uint64_t)this + 176, (uint64_t)a2 + 176);
  std::unordered_set<ZinIrOpLayer const*>::unordered_set((uint64_t)this + 216, (uint64_t)a2 + 216);
  long long v5 = *((_OWORD *)a2 + 16);
  long long v6 = *((_OWORD *)a2 + 17);
  *((unsigned char *)this + 288) = *((unsigned char *)a2 + 288);
  *((_OWORD *)this + 16) = v5;
  *((_OWORD *)this + 17) = v6;
  LatencyInfo::LatencyInfo((SubgraphSplitInfo *)((char *)this + 296), (ZinIrOpLayer ***)a2 + 37);
}

void sub_21127C410(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10)
{
  SplitInfo::~SplitInfo(v11);
  Subgraph::~Subgraph(v10);
  _Unwind_Resume(a1);
}

void LatencyInfo::LatencyInfo(LatencyInfo *this, ZinIrOpLayer ***a2)
{
  uint64_t v4 = std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::map[abi:ne180100]((uint64_t *)this, a2);
  std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::map[abi:ne180100](v4 + 3, a2 + 3);
  std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::map[abi:ne180100]((uint64_t *)this + 6, a2 + 6);
  std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::map[abi:ne180100]((uint64_t *)this + 9, a2 + 9);
  std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::map[abi:ne180100]((uint64_t *)this + 12, a2 + 12);
  std::unordered_map<ZinIrOpLayer const*,BOOL>::unordered_map((uint64_t)this + 120, (uint64_t)(a2 + 15));
}

void sub_21127C4E0(_Unwind_Exception *a1)
{
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy(v5, v1[13]);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy(v4, v1[10]);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy(v3, v1[7]);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy(v2, v1[4]);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v1, v1[1]);
  _Unwind_Resume(a1);
}

uint64_t *std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::map[abi:ne180100](uint64_t *a1, ZinIrOpLayer ***a2)
{
  a1[2] = 0;
  a1[1] = 0;
  *a1 = (uint64_t)(a1 + 1);
  std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::insert[abi:ne180100]<std::__map_const_iterator<std::__tree_const_iterator<std::__value_type<ZinIrOpLayer const*,double>,std::__tree_node<std::__value_type<ZinIrOpLayer const*,double>,void *> *,long>>>(a1, *a2, a2 + 1);
  return a1;
}

void sub_21127C588(_Unwind_Exception *a1)
{
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy(v1, *(void **)(v1 + 8));
  _Unwind_Resume(a1);
}

uint64_t *std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::insert[abi:ne180100]<std::__map_const_iterator<std::__tree_const_iterator<std::__value_type<ZinIrOpLayer const*,double>,std::__tree_node<std::__value_type<ZinIrOpLayer const*,double>,void *> *,long>>>(uint64_t *result, ZinIrOpLayer **a2, ZinIrOpLayer ***a3)
{
  if (a2 != (ZinIrOpLayer **)a3)
  {
    uint64_t v4 = a2;
    uint64_t v5 = (uint64_t **)result;
    long long v6 = result + 1;
    do
    {
      uint64_t result = std::__tree<std::__value_type<ZinIrOpLayer const*,double>,std::__map_value_compare<ZinIrOpLayer const*,std::__value_type<ZinIrOpLayer const*,double>,ScheduleComparator,true>,std::allocator<std::__value_type<ZinIrOpLayer const*,double>>>::__emplace_hint_unique_key_args<ZinIrOpLayer const*,std::pair<ZinIrOpLayer const* const,double> const&>(v5, v6, v4 + 4, (_OWORD *)v4 + 2);
      uint64_t v7 = v4[1];
      if (v7)
      {
        do
        {
          uint64_t v8 = (ZinIrOpLayer ***)v7;
          uint64_t v7 = *(ZinIrOpLayer **)v7;
        }
        while (v7);
      }
      else
      {
        do
        {
          uint64_t v8 = (ZinIrOpLayer ***)v4[2];
          BOOL v9 = *v8 == v4;
          uint64_t v4 = (ZinIrOpLayer **)v8;
        }
        while (!v9);
      }
      uint64_t v4 = (ZinIrOpLayer **)v8;
    }
    while (v8 != a3);
  }
  return result;
}

uint64_t *std::__tree<std::__value_type<ZinIrOpLayer const*,double>,std::__map_value_compare<ZinIrOpLayer const*,std::__value_type<ZinIrOpLayer const*,double>,ScheduleComparator,true>,std::allocator<std::__value_type<ZinIrOpLayer const*,double>>>::__emplace_hint_unique_key_args<ZinIrOpLayer const*,std::pair<ZinIrOpLayer const* const,double> const&>(uint64_t **a1, uint64_t *a2, ZinIrOpLayer **a3, _OWORD *a4)
{
  long long v6 = std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__find_equal<ZinIrOpLayer *>(a1, a2, &v11, &v10, a3);
  uint64_t v7 = (uint64_t *)*v6;
  if (!*v6)
  {
    uint64_t v8 = (uint64_t **)v6;
    uint64_t v7 = (uint64_t *)operator new(0x30uLL);
    *((_OWORD *)v7 + 2) = *a4;
    std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::__insert_node_at(a1, (uint64_t)v11, v8, v7);
  }
  return v7;
}

uint64_t std::unordered_map<ZinIrOpLayer const*,BOOL>::unordered_map(uint64_t a1, uint64_t a2)
{
  *(_OWORD *)a1 = 0u;
  *(_OWORD *)(a1 + 16) = 0u;
  *(_DWORD *)(a1 + 32) = *(_DWORD *)(a2 + 32);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::__rehash<true>(a1, *(void *)(a2 + 8));
  for (uint64_t i = *(void **)(a2 + 16); i; uint64_t i = (void *)*i)
    std::__hash_table<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::__unordered_map_hasher<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,true>,std::__unordered_map_equal<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::equal_to<ZinIrOpLayer *>,std::hash<ZinIrOpLayer *>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::pair<ZinIrOpLayer * const,ZinAneInstruction *> const&>(a1, i + 2, (_OWORD *)i + 1);
  return a1;
}

void sub_21127C714(_Unwind_Exception *a1)
{
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table(v1);
  _Unwind_Resume(a1);
}

uint64_t std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<SubgraphSplitInfo>,SubgraphSplitInfo const*,SubgraphSplitInfo const*,SubgraphSplitInfo*>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  if (a2 != a3)
  {
    uint64_t v7 = 0;
    do
    {
      SubgraphSplitInfo::SubgraphSplitInfo((SubgraphSplitInfo *)(a4 + v7), (const SubgraphSplitInfo *)(a2 + v7));
      v7 += 456;
    }
    while (a2 + v7 != a3);
    a4 += v7;
  }
  return a4;
}

void sub_21127C78C(_Unwind_Exception *exception_object)
{
  if (v2)
  {
    uint64_t v4 = v1 - 456;
    do
    {
      SubgraphSplitInfo::~SubgraphSplitInfo((SubgraphSplitInfo *)(v4 + v2));
      v2 -= 456;
    }
    while (v2);
  }
  _Unwind_Resume(exception_object);
}

uint64_t std::vector<SubgraphSplitInfo>::push_back[abi:ne180100](uint64_t *a1, uint64_t a2)
{
  unint64_t v6 = a1[2];
  uint64_t v4 = (uint64_t)(a1 + 2);
  unint64_t v5 = v6;
  unint64_t v7 = *(void *)(v4 - 8);
  if (v7 >= v6)
  {
    unint64_t v10 = 0x823EE08FB823EE09 * ((uint64_t)(v7 - *a1) >> 3);
    if (v10 + 1 > 0x8FB823EE08FB82) {
      std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
    }
    unint64_t v11 = 0x823EE08FB823EE09 * ((uint64_t)(v5 - *a1) >> 3);
    uint64_t v12 = 2 * v11;
    if (2 * v11 <= v10 + 1) {
      uint64_t v12 = v10 + 1;
    }
    if (v11 >= 0x47DC11F7047DC1) {
      unint64_t v13 = 0x8FB823EE08FB82;
    }
    else {
      unint64_t v13 = v12;
    }
    uint64_t v19 = v4;
    if (v13) {
      uint64_t v14 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<SubgraphSplitInfo>>(v4, v13);
    }
    else {
      uint64_t v14 = 0;
    }
    uint64_t v15 = v14;
    uint64_t v16 = &v14[456 * v10];
    uint64_t v18 = &v14[456 * v13];
    SubgraphSplitInfo::SubgraphSplitInfo((uint64_t)v16, a2);
    uint64_t v17 = v16 + 456;
    std::vector<SubgraphSplitInfo>::__swap_out_circular_buffer(a1, &v15);
    uint64_t v9 = a1[1];
    uint64_t result = std::__split_buffer<SubgraphSplitInfo>::~__split_buffer((uint64_t)&v15);
  }
  else
  {
    uint64_t result = SubgraphSplitInfo::SubgraphSplitInfo(*(void *)(v4 - 8), a2);
    uint64_t v9 = v7 + 456;
    a1[1] = v7 + 456;
  }
  a1[1] = v9;
  return result;
}

void sub_21127C8D8(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::__split_buffer<SubgraphSplitInfo>::~__split_buffer((uint64_t)va);
  _Unwind_Resume(a1);
}

void std::vector<SubgraphSplitInfo>::__vdeallocate(void **a1)
{
  uint64_t v1 = (char *)*a1;
  if (*a1)
  {
    uint64_t v3 = (char *)a1[1];
    uint64_t v4 = v1;
    if (v3 != v1)
    {
      do
        SubgraphSplitInfo::~SubgraphSplitInfo((SubgraphSplitInfo *)(v3 - 456));
      while (v3 != v1);
      uint64_t v4 = *a1;
    }
    a1[1] = v1;
    operator delete(v4);
    *a1 = 0;
    a1[1] = 0;
    a1[2] = 0;
  }
}

void std::deque<ZinConcatLayer const*>::push_back(void *a1, void *a2)
{
  uint64_t v4 = a1[2];
  uint64_t v5 = a1[1];
  if (v4 == v5) {
    uint64_t v6 = 0;
  }
  else {
    uint64_t v6 = ((v4 - v5) << 6) - 1;
  }
  uint64_t v7 = a1[5];
  unint64_t v8 = v7 + a1[4];
  if (v6 == v8)
  {
    std::deque<ZinConcatLayer const*>::__add_back_capacity(a1);
    uint64_t v5 = a1[1];
    uint64_t v7 = a1[5];
    unint64_t v8 = a1[4] + v7;
  }
  *(void *)(*(void *)(v5 + ((v8 >> 6) & 0x3FFFFFFFFFFFFF8)) + 8 * (v8 & 0x1FF)) = *a2;
  a1[5] = v7 + 1;
}

void std::deque<ZinConcatLayer const*>::__add_back_capacity(void *a1)
{
  unint64_t v2 = a1[4];
  BOOL v3 = v2 >= 0x200;
  unint64_t v4 = v2 - 512;
  if (v3)
  {
    uint64_t v5 = (uint64_t)(a1 + 3);
    uint64_t v6 = (char *)a1[3];
    a1[4] = v4;
    uint64_t v7 = (void *)a1[1];
    unint64_t v8 = (char *)a1[2];
    uint64_t v11 = *v7;
    uint64_t v9 = (char *)(v7 + 1);
    uint64_t v10 = v11;
    a1[1] = v9;
    if (v8 != v6)
    {
LABEL_33:
      *(void *)unint64_t v8 = v10;
      a1[2] += 8;
      return;
    }
    uint64_t v12 = (uint64_t)&v9[-*a1];
    if ((unint64_t)v9 <= *a1)
    {
      if (v8 == (char *)*a1) {
        unint64_t v33 = 1;
      }
      else {
        unint64_t v33 = (uint64_t)&v8[-*a1] >> 2;
      }
      uint64_t v34 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>(v5, v33);
      uint64_t v35 = &v34[8 * (v33 >> 2)];
      long long v37 = &v34[8 * v36];
      uint64_t v38 = (uint64_t *)a1[1];
      unint64_t v8 = v35;
      uint64_t v39 = a1[2] - (void)v38;
      if (v39)
      {
        unint64_t v8 = &v35[v39 & 0xFFFFFFFFFFFFFFF8];
        uint64_t v40 = 8 * (v39 >> 3);
        int v41 = &v34[8 * (v33 >> 2)];
        do
        {
          uint64_t v42 = *v38++;
          *(void *)int v41 = v42;
          v41 += 8;
          v40 -= 8;
        }
        while (v40);
      }
      goto LABEL_30;
    }
LABEL_5:
    uint64_t v13 = v12 >> 3;
    BOOL v14 = v12 >> 3 < -1;
    uint64_t v15 = (v12 >> 3) + 2;
    if (v14) {
      uint64_t v16 = v15;
    }
    else {
      uint64_t v16 = v13 + 1;
    }
    uint64_t v17 = -(v16 >> 1);
    uint64_t v18 = v16 >> 1;
    uint64_t v19 = &v9[-8 * v18];
    int64_t v20 = v8 - v9;
    if (v8 != v9)
    {
      memmove(&v9[-8 * v18], v9, v8 - v9);
      uint64_t v9 = (char *)a1[1];
    }
    unint64_t v8 = &v19[v20];
    a1[1] = &v9[8 * v17];
    a1[2] = &v19[v20];
    goto LABEL_33;
  }
  uint64_t v21 = a1[2];
  unint64_t v22 = (v21 - a1[1]) >> 3;
  uint64_t v23 = a1[3];
  uint64_t v24 = v23 - *a1;
  if (v22 < v24 >> 3)
  {
    if (v23 != v21)
    {
      *(void *)&long long v54 = operator new(0x1000uLL);
      std::__split_buffer<unsigned long *>::push_back(a1, &v54);
      return;
    }
    *(void *)&long long v54 = operator new(0x1000uLL);
    std::__split_buffer<unsigned long *>::push_front((uint64_t)a1, &v54);
    BOOL v44 = (void *)a1[1];
    unint64_t v8 = (char *)a1[2];
    uint64_t v45 = *v44;
    uint64_t v9 = (char *)(v44 + 1);
    uint64_t v10 = v45;
    a1[1] = v9;
    if (v8 != (char *)a1[3]) {
      goto LABEL_33;
    }
    uint64_t v12 = (uint64_t)&v9[-*a1];
    if ((unint64_t)v9 <= *a1)
    {
      if (v8 == (char *)*a1) {
        unint64_t v46 = 1;
      }
      else {
        unint64_t v46 = (uint64_t)&v8[-*a1] >> 2;
      }
      uint64_t v34 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)(a1 + 3), v46);
      uint64_t v35 = &v34[8 * (v46 >> 2)];
      long long v37 = &v34[8 * v47];
      uint64_t v48 = (uint64_t *)a1[1];
      unint64_t v8 = v35;
      uint64_t v49 = a1[2] - (void)v48;
      if (v49)
      {
        unint64_t v8 = &v35[v49 & 0xFFFFFFFFFFFFFFF8];
        uint64_t v50 = 8 * (v49 >> 3);
        unint64_t v51 = &v34[8 * (v46 >> 2)];
        do
        {
          uint64_t v52 = *v48++;
          *(void *)unint64_t v51 = v52;
          v51 += 8;
          v50 -= 8;
        }
        while (v50);
      }
LABEL_30:
      uint64_t v43 = (char *)*a1;
      *a1 = v34;
      a1[1] = v35;
      a1[2] = v8;
      a1[3] = v37;
      if (v43)
      {
        operator delete(v43);
        unint64_t v8 = (char *)a1[2];
      }
      goto LABEL_33;
    }
    goto LABEL_5;
  }
  if (v23 == *a1) {
    unint64_t v25 = 1;
  }
  else {
    unint64_t v25 = v24 >> 2;
  }
  long long v56 = a1 + 3;
  *(void *)&long long v54 = std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)(a1 + 3), v25);
  *((void *)&v54 + 1) = v54 + 8 * v22;
  *(void *)&long long v55 = *((void *)&v54 + 1);
  *((void *)&v55 + 1) = v54 + 8 * v26;
  int v53 = operator new(0x1000uLL);
  std::__split_buffer<unsigned long *>::push_back(&v54, &v53);
  uint64_t v27 = (void *)a1[2];
  uint64_t v28 = -7 - (void)v27;
  while (v27 != (void *)a1[1])
  {
    --v27;
    v28 += 8;
    std::__split_buffer<unsigned long *>::push_front((uint64_t)&v54, v27);
  }
  uint64_t v29 = (char *)*a1;
  long long v30 = v54;
  long long v31 = v55;
  *(void *)&long long v54 = *a1;
  *((void *)&v54 + 1) = v27;
  long long v32 = *((_OWORD *)a1 + 1);
  *(_OWORD *)a1 = v30;
  *((_OWORD *)a1 + 1) = v31;
  long long v55 = v32;
  if (v27 != (void *)v32) {
    *(void *)&long long v55 = v32 + (-(v32 + v28) & 0xFFFFFFFFFFFFFFF8);
  }
  if (v29) {
    operator delete(v29);
  }
}

void sub_21127CCA0(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, void *__p, uint64_t a12, uint64_t a13)
{
  operator delete(v13);
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(a1);
}

void std::vector<BOOL>::__move_assign(uint64_t a1, void *a2)
{
  unint64_t v4 = *(void **)a1;
  if (v4)
  {
    operator delete(v4);
    *(void *)a1 = 0;
    *(void *)(a1 + 8) = 0;
    *(void *)(a1 + 16) = 0;
  }
  uint64_t v5 = a2[1];
  *(void *)a1 = *a2;
  *(void *)(a1 + 8) = v5;
  *(void *)(a1 + 16) = a2[2];
  *a2 = 0;
  a2[1] = 0;
  a2[2] = 0;
}

uint64_t std::__hash_table<std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::__unordered_map_hasher<unsigned long,std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::hash<unsigned long>,std::equal_to<unsigned long>,true>,std::__unordered_map_equal<unsigned long,std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::equal_to<unsigned long>,std::hash<unsigned long>,true>,std::allocator<std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>>>::~__hash_table(uint64_t a1)
{
  std::__hash_table<std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::__unordered_map_hasher<unsigned long,std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::hash<unsigned long>,std::equal_to<unsigned long>,true>,std::__unordered_map_equal<unsigned long,std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>,std::equal_to<unsigned long>,std::hash<unsigned long>,true>,std::allocator<std::__hash_value_type<unsigned long,std::unique_ptr<ZinSpatialSplitTransform>>>>::__deallocate_node(a1, *(void **)(a1 + 16));
  unint64_t v2 = *(void **)a1;
  *(void *)a1 = 0;
  if (v2) {
    operator delete(v2);
  }
  return a1;
}

uint64_t *std::__tree<std::__value_type<ZinIrOpLayer const*,double>,std::__map_value_compare<ZinIrOpLayer const*,std::__value_type<ZinIrOpLayer const*,double>,ScheduleComparator,true>,std::allocator<std::__value_type<ZinIrOpLayer const*,double>>>::__emplace_unique_key_args<ZinIrOpLayer const*,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer const* const&>,std::tuple<>>(uint64_t **a1, ZinIrOpLayer **a2, uint64_t a3, uint64_t **a4)
{
  uint64_t v6 = std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__find_equal<ZinIrOpLayer *>((uint64_t)a1, &v10, a2);
  uint64_t v7 = (uint64_t *)*v6;
  if (!*v6)
  {
    unint64_t v8 = (uint64_t **)v6;
    uint64_t v7 = (uint64_t *)operator new(0x30uLL);
    v7[4] = **a4;
    v7[5] = 0;
    std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::__insert_node_at(a1, v10, v8, v7);
  }
  return v7;
}

void *std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,BOOL>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,BOOL>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,BOOL>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,BOOL>>>::__emplace_unique_key_args<ZinIrOpLayer const*,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer const* const&>,std::tuple<>>(uint64_t a1, void *a2, uint64_t a3, void **a4)
{
  unint64_t v7 = 0x9DDFEA08EB382D69 * ((8 * *a2 + 8) ^ HIDWORD(*a2));
  unint64_t v8 = 0x9DDFEA08EB382D69 * (HIDWORD(*a2) ^ (v7 >> 47) ^ v7);
  unint64_t v9 = 0x9DDFEA08EB382D69 * (v8 ^ (v8 >> 47));
  unint64_t v10 = *(void *)(a1 + 8);
  if (v10)
  {
    uint8x8_t v11 = (uint8x8_t)vcnt_s8((int8x8_t)v10);
    v11.i16[0] = vaddlv_u8(v11);
    if (v11.u32[0] > 1uLL)
    {
      unint64_t v4 = 0x9DDFEA08EB382D69 * (v8 ^ (v8 >> 47));
      if (v9 >= v10) {
        unint64_t v4 = v9 % v10;
      }
    }
    else
    {
      unint64_t v4 = v9 & (v10 - 1);
    }
    uint64_t v12 = *(void ***)(*(void *)a1 + 8 * v4);
    if (v12)
    {
      uint64_t v13 = *v12;
      if (*v12)
      {
        do
        {
          unint64_t v14 = v13[1];
          if (v14 == v9)
          {
            if (v13[2] == *a2) {
              return v13;
            }
          }
          else
          {
            if (v11.u32[0] > 1uLL)
            {
              if (v14 >= v10) {
                v14 %= v10;
              }
            }
            else
            {
              v14 &= v10 - 1;
            }
            if (v14 != v4) {
              break;
            }
          }
          uint64_t v13 = (void *)*v13;
        }
        while (v13);
      }
    }
  }
  uint64_t v13 = operator new(0x20uLL);
  *uint64_t v13 = 0;
  v13[1] = v9;
  void v13[2] = **a4;
  *((unsigned char *)v13 + 24) = 0;
  float v15 = (float)(unint64_t)(*(void *)(a1 + 24) + 1);
  float v16 = *(float *)(a1 + 32);
  if (!v10 || (float)(v16 * (float)v10) < v15)
  {
    BOOL v17 = 1;
    if (v10 >= 3) {
      BOOL v17 = (v10 & (v10 - 1)) != 0;
    }
    unint64_t v18 = v17 | (2 * v10);
    unint64_t v19 = vcvtps_u32_f32(v15 / v16);
    if (v18 <= v19) {
      size_t v20 = v19;
    }
    else {
      size_t v20 = v18;
    }
    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::__rehash<true>(a1, v20);
    unint64_t v10 = *(void *)(a1 + 8);
    if ((v10 & (v10 - 1)) != 0)
    {
      if (v9 >= v10) {
        unint64_t v4 = v9 % v10;
      }
      else {
        unint64_t v4 = v9;
      }
    }
    else
    {
      unint64_t v4 = (v10 - 1) & v9;
    }
  }
  uint64_t v21 = *(void *)a1;
  unint64_t v22 = *(void **)(*(void *)a1 + 8 * v4);
  if (v22)
  {
    *uint64_t v13 = *v22;
LABEL_38:
    *unint64_t v22 = v13;
    goto LABEL_39;
  }
  *uint64_t v13 = *(void *)(a1 + 16);
  *(void *)(a1 + 16) = v13;
  *(void *)(v21 + 8 * v4) = a1 + 16;
  if (*v13)
  {
    unint64_t v23 = *(void *)(*v13 + 8);
    if ((v10 & (v10 - 1)) != 0)
    {
      if (v23 >= v10) {
        v23 %= v10;
      }
    }
    else
    {
      v23 &= v10 - 1;
    }
    unint64_t v22 = (void *)(*(void *)a1 + 8 * v23);
    goto LABEL_38;
  }
LABEL_39:
  ++*(void *)(a1 + 24);
  return v13;
}

void sub_21127D048(_Unwind_Exception *a1)
{
  operator delete(v1);
  _Unwind_Resume(a1);
}

BOOL CheckBroadcastSupport<ProducerConsumerChain>(void *a1, uint64_t a2)
{
  uint64_t v3 = *(void *)(a2 + 8);
  BOOL result = 1;
  if (v3 == *(void *)(a2 + 16) || *(void *)(*(void *)v3 + 8) != a1[1])
  {
    if ((*(unsigned int (**)(void *))(*a1 + 656))(a1))
    {
      uint64_t v4 = *(void *)((*(uint64_t (**)(void *))(*a1 + 696))(a1) + 64);
      if (ZinIrBroadcastInfo::HasDimension(v4, 4)
        || ZinIrBroadcastInfo::HasDimension(v4, 3)
        || ZinIrBroadcastInfo::HasDimension(v4, 1))
      {
        return 0;
      }
    }
    if ((*(unsigned int (**)(void *))(*a1 + 664))(a1))
    {
      uint64_t v5 = (*(uint64_t (**)(void *))(*a1 + 832))(a1);
      if (ZinIrBroadcastInfo::HasDimension(v5, 4)
        || ZinIrBroadcastInfo::HasDimension(v5, 3)
        || ZinIrBroadcastInfo::HasDimension(v5, 1))
      {
        return 0;
      }
    }
  }
  return result;
}

void *std::__hash_table<std::__hash_value_type<ZinIrOpLayer *,LayerTilingHelper>,std::__unordered_map_hasher<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,LayerTilingHelper>,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,true>,std::__unordered_map_equal<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,LayerTilingHelper>,std::equal_to<ZinIrOpLayer *>,std::hash<ZinIrOpLayer *>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer *,LayerTilingHelper>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::pair<ZinIrOpLayer *,LayerTilingHelper>>(uint64_t a1, void *a2, uint64_t a3)
{
  unint64_t v6 = 0x9DDFEA08EB382D69 * ((8 * *a2 + 8) ^ HIDWORD(*a2));
  unint64_t v7 = 0x9DDFEA08EB382D69 * (HIDWORD(*a2) ^ (v6 >> 47) ^ v6);
  unint64_t v8 = 0x9DDFEA08EB382D69 * (v7 ^ (v7 >> 47));
  unint64_t v9 = *(void *)(a1 + 8);
  if (v9)
  {
    uint8x8_t v10 = (uint8x8_t)vcnt_s8((int8x8_t)v9);
    v10.i16[0] = vaddlv_u8(v10);
    if (v10.u32[0] > 1uLL)
    {
      unint64_t v3 = 0x9DDFEA08EB382D69 * (v7 ^ (v7 >> 47));
      if (v8 >= v9) {
        unint64_t v3 = v8 % v9;
      }
    }
    else
    {
      unint64_t v3 = v8 & (v9 - 1);
    }
    uint8x8_t v11 = *(void **)(*(void *)a1 + 8 * v3);
    if (v11)
    {
      uint64_t v12 = (void *)*v11;
      if (*v11)
      {
        do
        {
          unint64_t v13 = v12[1];
          if (v13 == v8)
          {
            if (v12[2] == *a2) {
              return v12;
            }
          }
          else
          {
            if (v10.u32[0] > 1uLL)
            {
              if (v13 >= v9) {
                v13 %= v9;
              }
            }
            else
            {
              v13 &= v9 - 1;
            }
            if (v13 != v3) {
              break;
            }
          }
          uint64_t v12 = (void *)*v12;
        }
        while (v12);
      }
    }
  }
  uint64_t v14 = a1 + 16;
  float v15 = operator new(0xD8uLL);
  v25[0] = v15;
  v25[1] = a1 + 16;
  *float v15 = 0;
  v15[1] = v8;
  std::pair<ZinIrOpLayer * const,LayerTilingHelper>::pair[abi:ne180100]<ZinIrOpLayer *,LayerTilingHelper,0>((uint64_t)(v15 + 2), a3);
  char v26 = 1;
  float v16 = (float)(unint64_t)(*(void *)(a1 + 24) + 1);
  float v17 = *(float *)(a1 + 32);
  if (!v9 || (float)(v17 * (float)v9) < v16)
  {
    BOOL v18 = 1;
    if (v9 >= 3) {
      BOOL v18 = (v9 & (v9 - 1)) != 0;
    }
    unint64_t v19 = v18 | (2 * v9);
    unint64_t v20 = vcvtps_u32_f32(v16 / v17);
    if (v19 <= v20) {
      size_t v21 = v20;
    }
    else {
      size_t v21 = v19;
    }
    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::__rehash<true>(a1, v21);
    unint64_t v9 = *(void *)(a1 + 8);
    if ((v9 & (v9 - 1)) != 0)
    {
      if (v8 >= v9) {
        unint64_t v3 = v8 % v9;
      }
      else {
        unint64_t v3 = v8;
      }
    }
    else
    {
      unint64_t v3 = (v9 - 1) & v8;
    }
  }
  unint64_t v22 = *(void **)(*(void *)a1 + 8 * v3);
  if (v22)
  {
    *(void *)v25[0] = *v22;
    *unint64_t v22 = v25[0];
  }
  else
  {
    *(void *)v25[0] = *(void *)(a1 + 16);
    *(void *)(a1 + 16) = v25[0];
    *(void *)(*(void *)a1 + 8 * v3) = v14;
    if (*(void *)v25[0])
    {
      unint64_t v23 = *(void *)(*(void *)v25[0] + 8);
      if ((v9 & (v9 - 1)) != 0)
      {
        if (v23 >= v9) {
          v23 %= v9;
        }
      }
      else
      {
        v23 &= v9 - 1;
      }
      *(void *)(*(void *)a1 + 8 * v23) = v25[0];
    }
  }
  uint64_t v12 = (void *)v25[0];
  v25[0] = 0;
  ++*(void *)(a1 + 24);
  std::unique_ptr<std::__hash_node<std::__hash_value_type<ZinIrOpLayer *,LayerTilingHelper>,void *>,std::__hash_node_destructor<std::allocator<std::__hash_node<std::__hash_value_type<ZinIrOpLayer *,LayerTilingHelper>,void *>>>>::reset[abi:ne180100]((uint64_t)v25, 0);
  return v12;
}

void sub_21127D44C(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::unique_ptr<std::__hash_node<std::__hash_value_type<ZinIrOpLayer *,LayerTilingHelper>,void *>,std::__hash_node_destructor<std::allocator<std::__hash_node<std::__hash_value_type<ZinIrOpLayer *,LayerTilingHelper>,void *>>>>::reset[abi:ne180100]((uint64_t)va, 0);
  _Unwind_Resume(a1);
}

__n128 std::pair<ZinIrOpLayer * const,LayerTilingHelper>::pair[abi:ne180100]<ZinIrOpLayer *,LayerTilingHelper,0>(uint64_t a1, uint64_t a2)
{
  *(void *)a1 = *(void *)a2;
  *(_OWORD *)(a1 + 8) = *(_OWORD *)(a2 + 8);
  *(void *)(a1 + 32) = 0;
  *(void *)(a1 + 40) = 0;
  *(void *)(a1 + 24) = 0;
  *(_OWORD *)(a1 + 24) = *(_OWORD *)(a2 + 24);
  *(void *)(a1 + 40) = *(void *)(a2 + 40);
  *(void *)(a2 + 32) = 0;
  *(void *)(a2 + 40) = 0;
  *(void *)(a2 + 24) = 0;
  uint64_t v2 = *(void *)(a2 + 56);
  *(void *)(a1 + 48) = *(void *)(a2 + 48);
  *(void *)(a1 + 56) = v2;
  *(void *)(a1 + 64) = *(void *)(a2 + 64);
  *(void *)(a2 + 56) = 0;
  *(void *)(a2 + 64) = 0;
  *(void *)(a2 + 48) = 0;
  long long v3 = *(_OWORD *)(a2 + 88);
  long long v4 = *(_OWORD *)(a2 + 104);
  long long v5 = *(_OWORD *)(a2 + 120);
  *(_OWORD *)(a1 + 136) = *(_OWORD *)(a2 + 136);
  *(_OWORD *)(a1 + 120) = v5;
  *(_OWORD *)(a1 + 104) = v4;
  *(_OWORD *)(a1 + 88) = v3;
  *(_OWORD *)(a1 + 72) = *(_OWORD *)(a2 + 72);
  *(void *)(a1 + 160) = 0;
  *(void *)(a1 + 168) = 0;
  *(void *)(a1 + 152) = 0;
  *(_OWORD *)(a1 + 152) = *(_OWORD *)(a2 + 152);
  *(void *)(a1 + 168) = *(void *)(a2 + 168);
  *(void *)(a2 + 152) = 0;
  *(void *)(a2 + 160) = 0;
  *(void *)(a2 + 168) = 0;
  *(void *)(a1 + 176) = 0;
  *(void *)(a1 + 184) = 0;
  *(void *)(a1 + 192) = 0;
  __n128 result = *(__n128 *)(a2 + 176);
  *(__n128 *)(a1 + 176) = result;
  *(void *)(a1 + 192) = *(void *)(a2 + 192);
  *(void *)(a2 + 176) = 0;
  *(void *)(a2 + 184) = 0;
  *(void *)(a2 + 192) = 0;
  return result;
}

void std::unique_ptr<std::__hash_node<std::__hash_value_type<ZinIrOpLayer *,LayerTilingHelper>,void *>,std::__hash_node_destructor<std::allocator<std::__hash_node<std::__hash_value_type<ZinIrOpLayer *,LayerTilingHelper>,void *>>>>::reset[abi:ne180100](uint64_t a1, uint64_t a2)
{
  uint64_t v2 = *(void **)a1;
  *(void *)a1 = a2;
  if (v2)
  {
    if (*(unsigned char *)(a1 + 16)) {
      std::__destroy_at[abi:ne180100]<std::pair<ZinIrOpLayer * const,LayerTilingHelper>,0>(v2 + 2);
    }
    operator delete(v2);
  }
}

uint64_t std::unordered_set<SpatialDimension>::unordered_set(uint64_t a1, unsigned int *a2, uint64_t a3)
{
  *(_OWORD *)a1 = 0u;
  *(_OWORD *)(a1 + 16) = 0u;
  *(_DWORD *)(a1 + 32) = 1065353216;
  if (a3)
  {
    uint64_t v5 = 4 * a3;
    do
    {
      std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::__emplace_unique_key_args<unsigned int,unsigned int const&>(a1, a2, a2);
      ++a2;
      v5 -= 4;
    }
    while (v5);
  }
  return a1;
}

void sub_21127D5D4(_Unwind_Exception *a1)
{
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table(v1);
  _Unwind_Resume(a1);
}

void std::__hash_table<SpatialDimension,std::hash<SpatialDimension>,std::equal_to<SpatialDimension>,std::allocator<SpatialDimension>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<SpatialDimension,void *> *>>(void *a1, unsigned int *a2, uint64_t *a3)
{
  uint64_t v6 = a1[1];
  if (!v6) {
    goto LABEL_9;
  }
  for (uint64_t i = 0; i != v6; *(void *)(*a1 + 8 * i++) = 0)
    ;
  unint64_t v8 = (uint64_t *)a1[2];
  a1[2] = 0;
  a1[3] = 0;
  if (v8)
  {
    while (a2 != (unsigned int *)a3)
    {
      unint64_t v9 = a2[4];
      *((_DWORD *)v8 + 4) = v9;
      uint8x8_t v10 = (uint64_t *)*v8;
      v8[1] = v9;
      inserted = (void *)std::__hash_table<std::__hash_value_type<ZinIrDimension,unsigned long>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,unsigned long>>>::__node_insert_multi_prepare((uint64_t)a1, v9, (_DWORD *)v8 + 4);
      std::__hash_table<std::__hash_value_type<ZinIrDimension,unsigned long>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,unsigned long>>>::__node_insert_multi_perform(a1, v8, inserted);
      a2 = *(unsigned int **)a2;
      unint64_t v8 = v10;
      if (!v10) {
        goto LABEL_9;
      }
    }
    do
    {
      uint64_t v12 = (uint64_t *)*v8;
      operator delete(v8);
      unint64_t v8 = v12;
    }
    while (v12);
  }
  else
  {
LABEL_9:
    while (a2 != (unsigned int *)a3)
    {
      std::__hash_table<SpatialDimension,std::hash<SpatialDimension>,std::equal_to<SpatialDimension>,std::allocator<SpatialDimension>>::__emplace_multi<SpatialDimension const&>(a1, a2 + 4);
      a2 = *(unsigned int **)a2;
    }
  }
}

void sub_21127D6C0(void *a1)
{
  __cxa_begin_catch(a1);
  do
  {
    uint64_t v2 = (void *)*v1;
    operator delete(v1);
    uint64_t v1 = v2;
  }
  while (v2);
  __cxa_rethrow();
}

void sub_21127D6E0(_Unwind_Exception *a1)
{
}

_DWORD *std::__hash_table<SpatialDimension,std::hash<SpatialDimension>,std::equal_to<SpatialDimension>,std::allocator<SpatialDimension>>::__emplace_multi<SpatialDimension const&>(void *a1, unsigned int *a2)
{
  long long v4 = operator new(0x18uLL);
  unint64_t v5 = *a2;
  v4[4] = v5;
  *(void *)long long v4 = 0;
  *((void *)v4 + 1) = v5;
  inserted = (void *)std::__hash_table<std::__hash_value_type<ZinIrDimension,unsigned long>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,unsigned long>>>::__node_insert_multi_prepare((uint64_t)a1, v5, v4 + 4);
  std::__hash_table<std::__hash_value_type<ZinIrDimension,unsigned long>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,unsigned long>>>::__node_insert_multi_perform(a1, v4, inserted);
  return v4;
}

void sub_21127D758(_Unwind_Exception *a1)
{
  operator delete(v1);
  _Unwind_Resume(a1);
}

uint64_t std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::set[abi:ne180100](uint64_t a1, ZinIrOpLayer **a2, uint64_t a3)
{
  *(void *)(a1 + 8) = 0;
  long long v4 = (uint64_t *)(a1 + 8);
  *(void *)(a1 + 16) = 0;
  *(void *)a1 = a1 + 8;
  if (a3)
  {
    uint64_t v6 = 8 * a3;
    do
    {
      std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_hint_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>((uint64_t **)a1, v4, a2, (uint64_t *)a2);
      ++a2;
      v6 -= 8;
    }
    while (v6);
  }
  return a1;
}

void sub_21127D7D4(_Unwind_Exception *a1)
{
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy(v1, *(void **)(v1 + 8));
  _Unwind_Resume(a1);
}

void std::__tree<std::__value_type<ZinIrBasicBlock *,std::vector<SubgraphSplitInfo>>,std::__map_value_compare<ZinIrBasicBlock *,std::__value_type<ZinIrBasicBlock *,std::vector<SubgraphSplitInfo>>,std::less<ZinIrBasicBlock *>,true>,std::allocator<std::__value_type<ZinIrBasicBlock *,std::vector<SubgraphSplitInfo>>>>::destroy(uint64_t a1, char *a2)
{
  if (a2)
  {
    std::__tree<std::__value_type<ZinIrBasicBlock *,std::vector<SubgraphSplitInfo>>,std::__map_value_compare<ZinIrBasicBlock *,std::__value_type<ZinIrBasicBlock *,std::vector<SubgraphSplitInfo>>,std::less<ZinIrBasicBlock *>,true>,std::allocator<std::__value_type<ZinIrBasicBlock *,std::vector<SubgraphSplitInfo>>>>::destroy(a1, *(void *)a2);
    std::__tree<std::__value_type<ZinIrBasicBlock *,std::vector<SubgraphSplitInfo>>,std::__map_value_compare<ZinIrBasicBlock *,std::__value_type<ZinIrBasicBlock *,std::vector<SubgraphSplitInfo>>,std::less<ZinIrBasicBlock *>,true>,std::allocator<std::__value_type<ZinIrBasicBlock *,std::vector<SubgraphSplitInfo>>>>::destroy(a1, *((void *)a2 + 1));
    long long v4 = (void **)(a2 + 40);
    std::vector<SubgraphSplitInfo>::__destroy_vector::operator()[abi:ne180100](&v4);
    operator delete(a2);
  }
}

void std::__function::__func<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_0,std::allocator<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_0>,ZinIrStatus ()(ZinIrBasicBlock *)>::~__func()
{
}

void *std::__function::__func<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_0,std::allocator<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_0>,ZinIrStatus ()(ZinIrBasicBlock *)>::__clone(uint64_t a1)
{
  __n128 result = operator new(0x10uLL);
  uint64_t v3 = *(void *)(a1 + 8);
  void *result = &unk_26C32F388;
  result[1] = v3;
  return result;
}

uint64_t std::__function::__func<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_0,std::allocator<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_0>,ZinIrStatus ()(ZinIrBasicBlock *)>::__clone(uint64_t result, void *a2)
{
  uint64_t v2 = *(void *)(result + 8);
  *a2 = &unk_26C32F388;
  a2[1] = v2;
  return result;
}

uint64_t std::__function::__func<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_0,std::allocator<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_0>,ZinIrStatus ()(ZinIrBasicBlock *)>::operator()@<X0>(uint64_t a1@<X0>, ZinIrTarget **a2@<X1>, uint64_t *a3@<X8>)
{
  **(void **)(a1 + 8) += ZinIrTarget::GetHal(a3, *a2)[2];
  return 0;
}

uint64_t std::__function::__func<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_0,std::allocator<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_0>,ZinIrStatus ()(ZinIrBasicBlock *)>::target(uint64_t a1, uint64_t a2)
{
  {
    return a1 + 8;
  }
  else
  {
    return 0;
  }
}

void *std::__function::__func<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_0,std::allocator<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_0>,ZinIrStatus ()(ZinIrBasicBlock *)>::target_type()
{
}

void std::__function::__func<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_1,std::allocator<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_1>,ZinIrStatus ()(ZinIrBasicBlock *)>::~__func()
{
}

__n128 std::__function::__func<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_1,std::allocator<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_1>,ZinIrStatus ()(ZinIrBasicBlock *)>::__clone(uint64_t a1)
{
  uint64_t v2 = (char *)operator new(0x20uLL);
  *(void *)uint64_t v2 = &unk_26C32F3E0;
  __n128 result = *(__n128 *)(a1 + 8);
  *(__n128 *)(v2 + 8) = result;
  *((void *)v2 + 3) = *(void *)(a1 + 24);
  return result;
}

__n128 std::__function::__func<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_1,std::allocator<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_1>,ZinIrStatus ()(ZinIrBasicBlock *)>::__clone(uint64_t a1, uint64_t a2)
{
  *(void *)a2 = &unk_26C32F3E0;
  __n128 result = *(__n128 *)(a1 + 8);
  *(void *)(a2 + 24) = *(void *)(a1 + 24);
  *(__n128 *)(a2 + 8) = result;
  return result;
}

uint64_t std::__function::__func<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_1,std::allocator<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_1>,ZinIrStatus ()(ZinIrBasicBlock *)>::operator()(uint64_t a1, ZinIrTarget **a2)
{
  uint64_t v94 = *a2;
  uint64_t v5 = a1 + 8;
  uint64_t v3 = *(uint64_t ***)(a1 + 8);
  uint64_t v4 = *(void *)(v5 + 8);
  uint64_t v53 = 0;
  uint64_t v52 = 0;
  uint64_t v54 = 0;
  std::__tree<std::__value_type<ZinIrBasicBlock *,std::vector<std::pair<Subgraph,SplitInfo>>>,std::__map_value_compare<ZinIrBasicBlock *,std::__value_type<ZinIrBasicBlock *,std::vector<std::pair<Subgraph,SplitInfo>>>,std::less<ZinIrBasicBlock *>,true>,std::allocator<std::__value_type<ZinIrBasicBlock *,std::vector<std::pair<Subgraph,SplitInfo>>>>>::__emplace_unique_key_args<ZinIrBasicBlock *,ZinIrBasicBlock *&,std::vector<std::pair<Subgraph,SplitInfo>>>(v3, (unint64_t *)&v94, &v94, (uint64_t)&v52);
  *(void *)&long long v36 = &v52;
  std::vector<SubgraphSplitInfo>::__destroy_vector::operator()[abi:ne180100]((void ***)&v36);
  uint64_t v91 = 0;
  uint64_t v92 = 0;
  uint64_t v93 = 0;
  uint64_t v6 = *(uint64_t (****)(void, uint64_t *, uint64_t *, void, void))(v4 + 176);
  Hal = ZinIrTarget::GetHal(v7, v94);
  int v9 = (**v6)(v6, Hal, &v91, 0, 0);
  std::string::basic_string[abi:ne180100]<0>(&v89, "[Initial Subgraphs]");
  ZinIrHalH13g::~ZinIrHalH13g((ZinIrHalH13g *)(v4 + 200));
  if (v90 < 0) {
    operator delete(v89);
  }
  if (v9 == 3)
  {
    uint64_t v10 = 3;
  }
  else
  {
    long long v86 = 0;
    int64x2_t v87 = 0;
    uint64_t v88 = 0;
    long long v85 = 0u;
    memset(&v84, 0, 32);
    uint64_t v11 = v91;
    uint64_t v35 = v92;
    if (v91 != v92)
    {
      int64x2_t v34 = vdupq_n_s64(1uLL);
      do
      {
        uint64_t v53 = 0;
        uint64_t v54 = 0;
        v56[0] = 0;
        v56[1] = 0;
        uint64_t v52 = (const SubgraphSplitInfo **)&v53;
        long long v55 = v56;
        v57[0] = (uint64_t)v57;
        v57[1] = (uint64_t)v57;
        v59[0] = 0;
        v59[1] = 0;
        v57[2] = 0;
        uint64_t v58 = v59;
        uint64_t v61 = 0;
        long long v60 = 0uLL;
        v63[0] = 0;
        v63[1] = 0;
        uint64_t v62 = v63;
        unsigned __int8 v64 = 0;
        uint64_t v68 = 0;
        long long v66 = 0u;
        long long v67 = 0u;
        long long v65 = 0u;
        long long v70 = 0u;
        long long v71 = 0u;
        int v69 = 1065353216;
        int v72 = 1065353216;
        int64x2_t v73 = v34;
        int64x2_t v74 = v34;
        v76[0] = 0;
        v76[1] = 0;
        v77[0] = 0;
        v77[1] = 0;
        uint64_t v75 = v76;
        v76[2] = v77;
        v78[0] = 0;
        v78[1] = 0;
        v79[0] = 0;
        v79[1] = 0;
        _OWORD v77[2] = v78;
        v78[2] = v79;
        v80[0] = 0;
        v80[1] = 0;
        v79[2] = v80;
        long long v81 = 0u;
        long long v82 = 0u;
        int v83 = 1065353216;
        std::__tree<ZinSpaceRange>::__move_assign((uint64_t)&v52, (void *)v11);
        std::__tree<ZinSpaceRange>::__move_assign((uint64_t)&v55, (void *)(v11 + 24));
        std::list<ZinIrOpLayer *>::__move_assign(v57, (void *)(v11 + 48));
        std::__tree<ZinSpaceRange>::__move_assign((uint64_t)&v58, (void *)(v11 + 72));
        std::vector<std::map<ZinIrDimension,unsigned long>>::__vdeallocate((void **)&v60);
        long long v60 = *(_OWORD *)(v11 + 96);
        uint64_t v61 = *(void *)(v11 + 112);
        *(void *)(v11 + 96) = 0;
        *(void *)(v11 + 104) = 0;
        *(void *)(v11 + 112) = 0;
        uint64_t v12 = v11 + 120;
        std::__tree<ZinSpaceRange>::__move_assign((uint64_t)&v62, (void *)(v11 + 120));
        unsigned __int8 v64 = *(unsigned char *)(v11 + 144);
        unint64_t v13 = (ZinIrOpLayerGraph *)ZinIrTarget::GetHal((uint64_t *)v64, v94);
        if (ZinMirSpatialSplitter::DetermineSubgraphSplitInfo((ZinMirSpatialSplitter *)v4, v13, (SubgraphSplitInfo *)&v52))
        {
          SubgraphSplitInfo::~SubgraphSplitInfo((SubgraphSplitInfo *)&v52);
          uint64_t v10 = 3;
          goto LABEL_35;
        }
        std::deque<SubgraphSplitInfo>::push_back(&v84, (SubgraphSplitInfo *)&v52);
        SubgraphSplitInfo::~SubgraphSplitInfo((SubgraphSplitInfo *)&v52);
        v11 += 152;
      }
      while (v12 + 32 != v35);
      uint64_t v14 = (ZinIrHalH13g *)(v4 + 200);
      while (*((void *)&v85 + 1))
      {
        float v15 = (const Subgraph *)(*(void *)(v84.i64[1] + (((unint64_t)v85 >> 1) & 0x7FFFFFFFFFFFFFF8))
                               + 456 * (v85 & 0xF));
        uint64_t v53 = 0;
        uint64_t v52 = 0;
        uint64_t v54 = 0;
        long long v36 = 0uLL;
        long long v37 = 0;
        PressureBasedSubgraphIdentification::ComputeTimeSpanOfCluster((void *)v15 + 9);
        uint64_t v16 = *(void *)(v4 + 176);
        BOOL v18 = ZinIrTarget::GetHal(v17, v94);
        v50[1] = 0;
        unint64_t v51 = 0;
        v50[0] = (Subgraph *)&v50[1];
        (*(void (**)(uint64_t, uint64_t *, const Subgraph *, Subgraph **, const SubgraphSplitInfo ***))(*(void *)v16 + 8))(v16, v18, v15, v50, &v52);
        std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v50, (void *)v50[1]);
        unint64_t v20 = (ZinIrOpLayerGraph *)ZinIrTarget::GetHal(v19, v94);
        ZinMirSpatialSplitter::ConstructSplitInfoOfRefinedClusters((ZinMirSpatialSplitter *)v4, v20, (const Subgraph **)&v52, (uint64_t *)v50);
        std::vector<SubgraphSplitInfo>::__vdeallocate((void **)&v36);
        long long v36 = *(_OWORD *)v50;
        long long v37 = v51;
        unint64_t v51 = 0;
        v50[1] = 0;
        v50[0] = 0;
        v95[0] = (uint64_t *)v50;
        std::vector<SubgraphSplitInfo>::__destroy_vector::operator()[abi:ne180100]((void ***)v95);
        std::string::basic_string[abi:ne180100]<0>(&__p, "[Visited Subgraph]");
        Subgraph::Subgraph((Subgraph *)v41, v15);
        ZinIrHalH13g::~ZinIrHalH13g(v14);
        std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v47, v47[1]);
        v50[0] = (Subgraph *)&v46;
        std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100]((void ***)v50);
        std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v45, v45[1]);
        std::__list_imp<ZinIrSection *>::clear(v44);
        std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v43, v43[1]);
        std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v41, v42);
        if (v49 < 0) {
          operator delete(__p);
        }
        if (*(unsigned char *)(v4 + 29)
          || ZinMirSpatialSplitter::IsCurrentGraphMinLatency(v4, (uint64_t)v15, &v36))
        {
          std::vector<SubgraphSplitInfo>::push_back[abi:ne180100]((uint64_t *)&v86, (uint64_t)v15);
        }
        else
        {
          v50[1] = 0;
          v50[0] = 0;
          unint64_t v51 = 0;
          size_t v21 = (const Subgraph *)*((void *)&v36 + 1);
          for (uint64_t i = (const Subgraph *)v36; i != v21; uint64_t i = (const Subgraph *)((char *)i + 456))
          {
            unint64_t v23 = v50[1];
            if (v50[1] >= v51)
            {
              uint64_t v24 = (Subgraph *)std::vector<Subgraph>::__push_back_slow_path<Subgraph const&>((uint64_t *)v50, i);
            }
            else
            {
              Subgraph::Subgraph(v50[1], i);
              uint64_t v24 = (Subgraph *)((char *)v23 + 152);
            }
            v50[1] = v24;
            std::deque<SubgraphSplitInfo>::push_back(&v84, (uint64_t)i);
          }
          std::string::basic_string[abi:ne180100]<0>(&v39, "[Refined Subgraphs]");
          uint64_t v14 = (ZinIrHalH13g *)(v4 + 200);
          ZinIrHalH13g::~ZinIrHalH13g((ZinIrHalH13g *)(v4 + 200));
          if (v40 < 0) {
            operator delete(v39);
          }
          v95[0] = (uint64_t *)v50;
          std::vector<Subgraph>::__destroy_vector::operator()[abi:ne180100]((void ***)v95);
        }
        std::deque<SubgraphSplitInfo>::pop_front(&v84);
        v50[0] = (Subgraph *)&v36;
        std::vector<SubgraphSplitInfo>::__destroy_vector::operator()[abi:ne180100]((void ***)v50);
        *(void *)&long long v36 = &v52;
        std::vector<Subgraph>::__destroy_vector::operator()[abi:ne180100]((void ***)&v36);
      }
    }
    unint64_t v25 = v86;
    for (j = v87; v25 != j; unint64_t v25 = (const SubgraphSplitInfo *)((char *)v25 + 456))
    {
      SubgraphSplitInfo::SubgraphSplitInfo((SubgraphSplitInfo *)&v52, v25);
      uint64_t v28 = (ZinIrOpLayerGraph *)ZinIrTarget::GetHal(v27, v94);
      ZinMirSpatialSplitter::RefineSplitInfoByKernelOverhead((ZinMirSpatialSplitter *)v4, v28, (const SubgraphSplitInfo *)&v52, (char **)v50);
      uint64_t v29 = v50[0];
      long long v30 = v50[1];
      while (v29 != v30)
      {
        SubgraphSplitInfo::SubgraphSplitInfo((SubgraphSplitInfo *)&v36, v29);
        PressureBasedSubgraphIdentification::ComputeTimeSpanOfCluster(v38);
        if (ZinMirSpatialSplitter::IsWorthCompileTimeIncrease(v4, &v36, **(void **)(a1 + 24)))
        {
          long long v31 = *(uint64_t ***)(a1 + 8);
          v95[0] = (uint64_t *)&v94;
          long long v32 = std::__tree<std::__value_type<ZinIrOpLayer const*,std::vector<std::unordered_map<ZinIrDimension,unsigned long>>>,std::__map_value_compare<ZinIrOpLayer const*,std::__value_type<ZinIrOpLayer const*,std::vector<std::unordered_map<ZinIrDimension,unsigned long>>>,std::less<ZinIrOpLayer const*>,true>,std::allocator<std::__value_type<ZinIrOpLayer const*,std::vector<std::unordered_map<ZinIrDimension,unsigned long>>>>>::__emplace_unique_key_args<ZinIrOpLayer const*,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer const* const&>,std::tuple<>>(v31, (unint64_t *)&v94, (uint64_t)&std::piecewise_construct, v95);
          std::vector<SubgraphSplitInfo>::push_back[abi:ne180100](v32 + 5, (uint64_t)&v36);
        }
        SubgraphSplitInfo::~SubgraphSplitInfo((SubgraphSplitInfo *)&v36);
        uint64_t v29 = (const SubgraphSplitInfo *)((char *)v29 + 456);
      }
      *(void *)&long long v36 = v50;
      std::vector<SubgraphSplitInfo>::__destroy_vector::operator()[abi:ne180100]((void ***)&v36);
      SubgraphSplitInfo::~SubgraphSplitInfo((SubgraphSplitInfo *)&v52);
    }
    uint64_t v10 = 0;
LABEL_35:
    std::deque<SubgraphSplitInfo>::~deque[abi:ne180100](&v84);
    uint64_t v52 = &v86;
    std::vector<SubgraphSplitInfo>::__destroy_vector::operator()[abi:ne180100]((void ***)&v52);
  }
  uint64_t v52 = (const SubgraphSplitInfo **)&v91;
  std::vector<Subgraph>::__destroy_vector::operator()[abi:ne180100]((void ***)&v52);
  return v10;
}

void sub_21127E0C4(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27)
{
  if (SLOBYTE(STACK[0x26F]) < 0) {
    operator delete((void *)STACK[0x258]);
  }
  *(void *)(v27 - 104) = &STACK[0x320];
  std::vector<Subgraph>::__destroy_vector::operator()[abi:ne180100]((void ***)(v27 - 104));
  STACK[0x320] = (unint64_t)&a27;
  std::vector<SubgraphSplitInfo>::__destroy_vector::operator()[abi:ne180100]((void ***)&STACK[0x320]);
  a27 = (uint64_t)&STACK[0x338];
  std::vector<Subgraph>::__destroy_vector::operator()[abi:ne180100]((void ***)&a27);
  std::deque<SubgraphSplitInfo>::~deque[abi:ne180100]((void *)(v27 - 240));
  STACK[0x338] = v27 - 192;
  std::vector<SubgraphSplitInfo>::__destroy_vector::operator()[abi:ne180100]((void ***)&STACK[0x338]);
  STACK[0x338] = v27 - 144;
  std::vector<Subgraph>::__destroy_vector::operator()[abi:ne180100]((void ***)&STACK[0x338]);
  _Unwind_Resume(a1);
}

uint64_t std::__function::__func<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_1,std::allocator<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_1>,ZinIrStatus ()(ZinIrBasicBlock *)>::target(uint64_t a1, uint64_t a2)
{
  {
    return a1 + 8;
  }
  else
  {
    return 0;
  }
}

void *std::__function::__func<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_1,std::allocator<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_1>,ZinIrStatus ()(ZinIrBasicBlock *)>::target_type()
{
}

void std::deque<SubgraphSplitInfo>::push_back(void *a1, SubgraphSplitInfo *a2)
{
  uint64_t v4 = a1[1];
  uint64_t v5 = a1[2];
  uint64_t v6 = 2 * (v5 - v4) - 1;
  if (v5 == v4) {
    uint64_t v6 = 0;
  }
  if (v6 == a1[5] + a1[4])
  {
    std::deque<SubgraphSplitInfo>::__add_back_capacity(a1);
    uint64_t v4 = a1[1];
    uint64_t v5 = a1[2];
  }
  if (v5 == v4)
  {
    unint64_t v8 = 0;
  }
  else
  {
    unint64_t v7 = a1[5] + a1[4];
    unint64_t v8 = (SubgraphSplitInfo *)(*(void *)(v4 + ((v7 >> 1) & 0x7FFFFFFFFFFFFFF8)) + 456 * (v7 & 0xF));
  }
  SubgraphSplitInfo::SubgraphSplitInfo(v8, a2);
  ++a1[5];
}

void std::deque<SubgraphSplitInfo>::__add_back_capacity(void *a1)
{
  unint64_t v2 = a1[4];
  BOOL v3 = v2 >= 0x10;
  unint64_t v4 = v2 - 16;
  if (v3)
  {
    uint64_t v5 = (uint64_t)(a1 + 3);
    uint64_t v6 = (char *)a1[3];
    a1[4] = v4;
    unint64_t v7 = (void *)a1[1];
    unint64_t v8 = (char *)a1[2];
    uint64_t v11 = *v7;
    int v9 = (char *)(v7 + 1);
    uint64_t v10 = v11;
    a1[1] = v9;
    if (v8 != v6)
    {
LABEL_33:
      *(void *)unint64_t v8 = v10;
      a1[2] += 8;
      return;
    }
    uint64_t v12 = (uint64_t)&v9[-*a1];
    if ((unint64_t)v9 <= *a1)
    {
      if (v8 == (char *)*a1) {
        unint64_t v33 = 1;
      }
      else {
        unint64_t v33 = (uint64_t)&v8[-*a1] >> 2;
      }
      int64x2_t v34 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>(v5, v33);
      uint64_t v35 = &v34[8 * (v33 >> 2)];
      long long v37 = &v34[8 * v36];
      uint64_t v38 = (uint64_t *)a1[1];
      unint64_t v8 = v35;
      uint64_t v39 = a1[2] - (void)v38;
      if (v39)
      {
        unint64_t v8 = &v35[v39 & 0xFFFFFFFFFFFFFFF8];
        uint64_t v40 = 8 * (v39 >> 3);
        int v41 = &v34[8 * (v33 >> 2)];
        do
        {
          uint64_t v42 = *v38++;
          *(void *)int v41 = v42;
          v41 += 8;
          v40 -= 8;
        }
        while (v40);
      }
      goto LABEL_30;
    }
LABEL_5:
    uint64_t v13 = v12 >> 3;
    BOOL v14 = v12 >> 3 < -1;
    uint64_t v15 = (v12 >> 3) + 2;
    if (v14) {
      uint64_t v16 = v15;
    }
    else {
      uint64_t v16 = v13 + 1;
    }
    uint64_t v17 = -(v16 >> 1);
    uint64_t v18 = v16 >> 1;
    unint64_t v19 = &v9[-8 * v18];
    int64_t v20 = v8 - v9;
    if (v8 != v9)
    {
      memmove(&v9[-8 * v18], v9, v8 - v9);
      int v9 = (char *)a1[1];
    }
    unint64_t v8 = &v19[v20];
    a1[1] = &v9[8 * v17];
    a1[2] = &v19[v20];
    goto LABEL_33;
  }
  uint64_t v21 = a1[2];
  unint64_t v22 = (v21 - a1[1]) >> 3;
  uint64_t v23 = a1[3];
  uint64_t v24 = v23 - *a1;
  if (v22 < v24 >> 3)
  {
    if (v23 != v21)
    {
      *(void *)&long long v54 = operator new(0x1C80uLL);
      std::__split_buffer<unsigned long *>::push_back(a1, &v54);
      return;
    }
    *(void *)&long long v54 = operator new(0x1C80uLL);
    std::__split_buffer<unsigned long *>::push_front((uint64_t)a1, &v54);
    BOOL v44 = (void *)a1[1];
    unint64_t v8 = (char *)a1[2];
    uint64_t v45 = *v44;
    int v9 = (char *)(v44 + 1);
    uint64_t v10 = v45;
    a1[1] = v9;
    if (v8 != (char *)a1[3]) {
      goto LABEL_33;
    }
    uint64_t v12 = (uint64_t)&v9[-*a1];
    if ((unint64_t)v9 <= *a1)
    {
      if (v8 == (char *)*a1) {
        unint64_t v46 = 1;
      }
      else {
        unint64_t v46 = (uint64_t)&v8[-*a1] >> 2;
      }
      int64x2_t v34 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)(a1 + 3), v46);
      uint64_t v35 = &v34[8 * (v46 >> 2)];
      long long v37 = &v34[8 * v47];
      uint64_t v48 = (uint64_t *)a1[1];
      unint64_t v8 = v35;
      uint64_t v49 = a1[2] - (void)v48;
      if (v49)
      {
        unint64_t v8 = &v35[v49 & 0xFFFFFFFFFFFFFFF8];
        uint64_t v50 = 8 * (v49 >> 3);
        unint64_t v51 = &v34[8 * (v46 >> 2)];
        do
        {
          uint64_t v52 = *v48++;
          *(void *)unint64_t v51 = v52;
          v51 += 8;
          v50 -= 8;
        }
        while (v50);
      }
LABEL_30:
      uint64_t v43 = (char *)*a1;
      *a1 = v34;
      a1[1] = v35;
      a1[2] = v8;
      a1[3] = v37;
      if (v43)
      {
        operator delete(v43);
        unint64_t v8 = (char *)a1[2];
      }
      goto LABEL_33;
    }
    goto LABEL_5;
  }
  if (v23 == *a1) {
    unint64_t v25 = 1;
  }
  else {
    unint64_t v25 = v24 >> 2;
  }
  long long v56 = a1 + 3;
  *(void *)&long long v54 = std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)(a1 + 3), v25);
  *((void *)&v54 + 1) = v54 + 8 * v22;
  *(void *)&long long v55 = *((void *)&v54 + 1);
  *((void *)&v55 + 1) = v54 + 8 * v26;
  uint64_t v53 = operator new(0x1C80uLL);
  std::__split_buffer<unsigned long *>::push_back(&v54, &v53);
  uint64_t v27 = (void *)a1[2];
  uint64_t v28 = -7 - (void)v27;
  while (v27 != (void *)a1[1])
  {
    --v27;
    v28 += 8;
    std::__split_buffer<unsigned long *>::push_front((uint64_t)&v54, v27);
  }
  uint64_t v29 = (char *)*a1;
  long long v30 = v54;
  long long v31 = v55;
  *(void *)&long long v54 = *a1;
  *((void *)&v54 + 1) = v27;
  long long v32 = *((_OWORD *)a1 + 1);
  *(_OWORD *)a1 = v30;
  *((_OWORD *)a1 + 1) = v31;
  long long v55 = v32;
  if (v27 != (void *)v32) {
    *(void *)&long long v55 = v32 + (-(v32 + v28) & 0xFFFFFFFFFFFFFFF8);
  }
  if (v29) {
    operator delete(v29);
  }
}

void sub_21127E600(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, void *__p, uint64_t a12, uint64_t a13)
{
  operator delete(v13);
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(a1);
}

uint64_t std::deque<SubgraphSplitInfo>::push_back(void *a1, uint64_t a2)
{
  uint64_t v4 = a1[1];
  uint64_t v5 = a1[2];
  uint64_t v6 = 2 * (v5 - v4) - 1;
  if (v5 == v4) {
    uint64_t v6 = 0;
  }
  if (v6 == a1[5] + a1[4])
  {
    std::deque<SubgraphSplitInfo>::__add_back_capacity(a1);
    uint64_t v4 = a1[1];
    uint64_t v5 = a1[2];
  }
  if (v5 == v4)
  {
    uint64_t v8 = 0;
  }
  else
  {
    unint64_t v7 = a1[5] + a1[4];
    uint64_t v8 = *(void *)(v4 + ((v7 >> 1) & 0x7FFFFFFFFFFFFFF8)) + 456 * (v7 & 0xF);
  }
  uint64_t result = SubgraphSplitInfo::SubgraphSplitInfo(v8, a2);
  ++a1[5];
  return result;
}

uint64_t std::deque<SubgraphSplitInfo>::pop_front(int64x2_t *a1)
{
  SubgraphSplitInfo::~SubgraphSplitInfo((SubgraphSplitInfo *)(*(void *)(a1->i64[1]
                                                                        + (((unint64_t)a1[2].i64[0] >> 1) & 0x7FFFFFFFFFFFFFF8))
                                                            + 456 * (a1[2].i64[0] & 0xF)));
  a1[2] = vaddq_s64(a1[2], (int64x2_t)xmmword_211EE1AE0);

  return std::deque<SubgraphSplitInfo>::__maybe_remove_front_spare[abi:ne180100]((uint64_t)a1, 1);
}

uint64_t std::deque<SubgraphSplitInfo>::__maybe_remove_front_spare[abi:ne180100](uint64_t a1, int a2)
{
  unint64_t v2 = *(void *)(a1 + 32);
  if (v2 < 0x10) {
    a2 = 1;
  }
  if (v2 < 0x20) {
    int v4 = a2;
  }
  else {
    int v4 = 0;
  }
  if ((v4 & 1) == 0)
  {
    operator delete(**(void ***)(a1 + 8));
    *(void *)(a1 + 8) += 8;
    *(void *)(a1 + 32) -= 16;
  }
  return v4 ^ 1u;
}

uint64_t std::deque<SubgraphSplitInfo>::~deque[abi:ne180100](void *a1)
{
  unint64_t v2 = (void **)a1[1];
  BOOL v3 = (void **)a1[2];
  if (v3 == v2)
  {
    int v4 = a1 + 5;
    BOOL v3 = (void **)a1[1];
  }
  else
  {
    int v4 = a1 + 5;
    unint64_t v5 = a1[4];
    uint64_t v6 = &v2[v5 >> 4];
    unint64_t v7 = (SubgraphSplitInfo *)((char *)*v6 + 456 * (v5 & 0xF));
    uint64_t v8 = *(uint64_t *)((char *)v2 + (((a1[5] + v5) >> 1) & 0x7FFFFFFFFFFFFFF8))
       + 456 * ((*((_DWORD *)a1 + 10) + (int)v5) & 0xF);
    if (v7 != (SubgraphSplitInfo *)v8)
    {
      do
      {
        SubgraphSplitInfo::~SubgraphSplitInfo(v7);
        unint64_t v7 = (SubgraphSplitInfo *)(v9 + 456);
        if (v7 - (SubgraphSplitInfo *)*v6 == 7296)
        {
          uint64_t v10 = (SubgraphSplitInfo *)v6[1];
          ++v6;
          unint64_t v7 = v10;
        }
      }
      while (v7 != (SubgraphSplitInfo *)v8);
      unint64_t v2 = (void **)a1[1];
      BOOL v3 = (void **)a1[2];
    }
  }
  *int v4 = 0;
  unint64_t v11 = (char *)v3 - (char *)v2;
  if ((unint64_t)((char *)v3 - (char *)v2) >= 0x11)
  {
    do
    {
      operator delete(*v2);
      BOOL v3 = (void **)a1[2];
      unint64_t v2 = (void **)(a1[1] + 8);
      a1[1] = v2;
      unint64_t v11 = (char *)v3 - (char *)v2;
    }
    while ((unint64_t)((char *)v3 - (char *)v2) > 0x10);
  }
  unint64_t v12 = v11 >> 3;
  if (v12 == 1)
  {
    uint64_t v13 = 8;
  }
  else
  {
    if (v12 != 2) {
      goto LABEL_16;
    }
    uint64_t v13 = 16;
  }
  a1[4] = v13;
LABEL_16:
  while (v2 != v3)
  {
    BOOL v14 = *v2++;
    operator delete(v14);
  }

  return std::__split_buffer<unsigned long *>::~__split_buffer((uint64_t)a1);
}

void std::__function::__func<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_2,std::allocator<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_2>,ZinIrStatus ()(ZinIrBasicBlock *)>::~__func()
{
}

__n128 std::__function::__func<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_2,std::allocator<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_2>,ZinIrStatus ()(ZinIrBasicBlock *)>::__clone(uint64_t a1)
{
  unint64_t v2 = (char *)operator new(0x20uLL);
  *(void *)unint64_t v2 = &unk_26C32F438;
  __n128 result = *(__n128 *)(a1 + 8);
  *(__n128 *)(v2 + 8) = result;
  *((void *)v2 + 3) = *(void *)(a1 + 24);
  return result;
}

__n128 std::__function::__func<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_2,std::allocator<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_2>,ZinIrStatus ()(ZinIrBasicBlock *)>::__clone(uint64_t a1, uint64_t a2)
{
  *(void *)a2 = &unk_26C32F438;
  __n128 result = *(__n128 *)(a1 + 8);
  *(void *)(a2 + 24) = *(void *)(a1 + 24);
  *(__n128 *)(a2 + 8) = result;
  return result;
}

uint64_t std::__function::__func<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_2,std::allocator<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_2>,ZinIrStatus ()(ZinIrBasicBlock *)>::operator()(uint64_t a1, ZinIrTarget **a2)
{
  unint64_t v12 = *a2;
  uint64_t v3 = *(void *)(a1 + 16);
  int v4 = std::map<ZinIrTensor const*,SpatialAmount>::at(*(void *)(a1 + 8), (unint64_t *)&v12);
  v11[0] = 0;
  v11[1] = 0;
  uint64_t v10 = v11;
  uint64_t v5 = *v4;
  uint64_t v6 = v4[1];
  if (*v4 != v6)
  {
    unint64_t v7 = (ZinIrOpLayer ***)(v5 + 80);
    do
    {
      std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::insert[abi:ne180100]<std::__tree_const_iterator<ZinIrOpLayer *,std::__tree_node<ZinIrOpLayer *,void *> *,long>>((uint64_t *)&v10, *(ZinIrOpLayer ***)(v5 + 72), v7);
      v5 += 456;
      v7 += 57;
    }
    while (v5 != v6);
  }
  uint64_t v8 = ZinMirBatchOrChannelSplitter::AnalysisPerBasicBlock(*(ZinMirGraphSplitterBase **)(v3 + 192), v12, *(unsigned int (****)(void, uint64_t *, uint64_t *, uint64_t, uint64_t))(v3 + 184), *(uint64_t ***)(a1 + 24), (uint64_t)&v10, 1);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v10, v11[0]);
  return v8;
}

void sub_21127EA48(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, void *a10)
{
}

uint64_t std::__function::__func<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_2,std::allocator<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_2>,ZinIrStatus ()(ZinIrBasicBlock *)>::target(uint64_t a1, uint64_t a2)
{
  {
    return a1 + 8;
  }
  else
  {
    return 0;
  }
}

void *std::__function::__func<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_2,std::allocator<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_2>,ZinIrStatus ()(ZinIrBasicBlock *)>::target_type()
{
}

void std::__function::__func<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_3,std::allocator<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_3>,ZinIrStatus ()(ZinIrBasicBlock *)>::~__func()
{
}

__n128 std::__function::__func<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_3,std::allocator<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_3>,ZinIrStatus ()(ZinIrBasicBlock *)>::__clone(uint64_t a1)
{
  unint64_t v2 = (char *)operator new(0x30uLL);
  *(void *)unint64_t v2 = &unk_26C322E30;
  *(_OWORD *)(v2 + 8) = *(_OWORD *)(a1 + 8);
  __n128 result = *(__n128 *)(a1 + 24);
  *(__n128 *)(v2 + 24) = result;
  *((void *)v2 + 5) = *(void *)(a1 + 40);
  return result;
}

__n128 std::__function::__func<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_3,std::allocator<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_3>,ZinIrStatus ()(ZinIrBasicBlock *)>::__clone(uint64_t a1, uint64_t a2)
{
  *(void *)a2 = &unk_26C322E30;
  __n128 result = *(__n128 *)(a1 + 8);
  long long v3 = *(_OWORD *)(a1 + 24);
  *(void *)(a2 + 40) = *(void *)(a1 + 40);
  *(_OWORD *)(a2 + 24) = v3;
  *(__n128 *)(a2 + 8) = result;
  return result;
}

uint64_t std::__function::__func<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_3,std::allocator<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_3>,ZinIrStatus ()(ZinIrBasicBlock *)>::operator()(uint64_t a1, ZinIrTarget **a2)
{
  uint64_t v29 = *a2;
  uint64_t v3 = *(void *)(a1 + 16);
  int v4 = std::map<ZinIrTensor const*,SpatialAmount>::at(*(void *)(a1 + 8), (unint64_t *)&v29);
  uint64_t v5 = *v4;
  if (v4[1] != *v4)
  {
    uint64_t v6 = v4;
    unint64_t v7 = 0;
    uint64_t v8 = 152;
    do
    {
      ZinMirSpatialSplitter::AdjustTiledRegionsForConcats((ZinMirSpatialSplitter *)v3, (const Subgraph *)(v5 + v8 - 152), (SplitInfo *)(v5 + v8));
      uint64_t v9 = **(uint64_t ***)(a1 + 24);
      if (v9)
      {
        std::pair<std::list<ZinIrOpLayer *>,SplitInfo>::pair[abi:ne180100]<std::list<ZinIrOpLayer *>&,SplitInfo&,0>((uint64_t)v25, *v6 + v8 - 104, *v6 + v8);
        std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>::push_back[abi:ne180100](v9, (uint64_t)v25);
        std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&v28);
        std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::~__hash_table((uint64_t)&v27);
        long long v30 = (void **)&v26;
        std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__destroy_vector::operator()[abi:ne180100](&v30);
        std::__list_imp<ZinIrSection *>::clear(v25);
      }
      std::string::basic_string[abi:ne180100]<0>(&__p, "[Finalized Subgraph]");
      Subgraph::Subgraph((Subgraph *)v16, (const Subgraph *)(*v6 + v8 - 152));
      ZinIrHalH13g::~ZinIrHalH13g((ZinIrHalH13g *)(v3 + 200));
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v22, v22[1]);
      v25[0] = (void **)&v21;
      std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100](v25);
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v20, v20[1]);
      std::__list_imp<ZinIrSection *>::clear(v19);
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v18, v18[1]);
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v16, v17);
      uint64_t v10 = (uint64_t *)v24;
      if ((v10 & 0x80000000) != 0) {
        operator delete(__p);
      }
      Hal = (ZinIrOpLayerGraph *)ZinIrTarget::GetHal(v10, v29);
      unint64_t v12 = (const SplitInfo *)(*v6 + v8);
      uint64_t v13 = *(void **)(a1 + 32);
      uint64_t v14 = (*v13)++;
      ZinMirGraphSplitterBase::SplitSubgraph((ZinMirGraphSplitterBase *)v3, Hal, (const SplitInfo *)((char *)v12 - 152), v12, (unsigned __int16)v14, **(unsigned char **)(a1 + 40));
      ++v7;
      uint64_t v5 = *v6;
      v8 += 456;
    }
    while (v7 < 0x823EE08FB823EE09 * ((v6[1] - *v6) >> 3));
  }
  return 0;
}

void sub_21127ED6C(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, char a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33,void *__p,uint64_t a35,int a36,__int16 a37,char a38,char a39,uint64_t a40)
{
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table(a10);
  std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::~__hash_table(a11);
  *(void *)(v40 - 96) = a12;
  std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__destroy_vector::operator()[abi:ne180100]((void ***)(v40 - 96));
  std::__list_imp<ZinIrSection *>::clear(&a40);
  _Unwind_Resume(a1);
}

uint64_t std::__function::__func<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_3,std::allocator<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_3>,ZinIrStatus ()(ZinIrBasicBlock *)>::target(uint64_t a1, uint64_t a2)
{
  {
    return a1 + 8;
  }
  else
  {
    return 0;
  }
}

void *std::__function::__func<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_3,std::allocator<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_3>,ZinIrStatus ()(ZinIrBasicBlock *)>::target_type()
{
}

uint64_t std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>::push_back[abi:ne180100](uint64_t *a1, uint64_t a2)
{
  unint64_t v6 = a1[2];
  uint64_t v4 = (uint64_t)(a1 + 2);
  unint64_t v5 = v6;
  unint64_t v7 = *(void *)(v4 - 8);
  if (v7 >= v6)
  {
    unint64_t v10 = 0xCF3CF3CF3CF3CF3DLL * ((uint64_t)(v7 - *a1) >> 3);
    if (v10 + 1 > 0x186186186186186) {
      std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
    }
    unint64_t v11 = 0xCF3CF3CF3CF3CF3DLL * ((uint64_t)(v5 - *a1) >> 3);
    uint64_t v12 = 2 * v11;
    if (2 * v11 <= v10 + 1) {
      uint64_t v12 = v10 + 1;
    }
    if (v11 >= 0xC30C30C30C30C3) {
      unint64_t v13 = 0x186186186186186;
    }
    else {
      unint64_t v13 = v12;
    }
    uint64_t v19 = v4;
    if (v13) {
      uint64_t v14 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ANEDebugInfo::DebugInfoInMem>>(v4, v13);
    }
    else {
      uint64_t v14 = 0;
    }
    uint64_t v15 = v14;
    uint64_t v16 = &v14[168 * v10];
    uint64_t v18 = &v14[168 * v13];
    std::pair<std::list<ZinIrOpLayer *>,SplitInfo>::pair[abi:ne180100]((uint64_t)v16, a2);
    uint64_t v17 = v16 + 168;
    std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>::__swap_out_circular_buffer(a1, &v15);
    uint64_t v9 = a1[1];
    uint64_t result = std::__split_buffer<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>::~__split_buffer((uint64_t)&v15);
  }
  else
  {
    uint64_t result = std::pair<std::list<ZinIrOpLayer *>,SplitInfo>::pair[abi:ne180100](*(void *)(v4 - 8), a2);
    uint64_t v9 = v7 + 168;
    a1[1] = v7 + 168;
  }
  a1[1] = v9;
  return result;
}

void sub_21127EF78(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::__split_buffer<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>::~__split_buffer((uint64_t)va);
  _Unwind_Resume(a1);
}

uint64_t std::pair<std::list<ZinIrOpLayer *>,SplitInfo>::pair[abi:ne180100](uint64_t a1, uint64_t a2)
{
  *(void *)a1 = a1;
  *(void *)(a1 + 8) = a1;
  *(void *)(a1 + 16) = 0;
  std::list<ZinIrOpLayer *>::splice(a1, (uint64_t *)a1, (void *)a2);
  *(void *)(a1 + 24) = 0;
  *(void *)(a1 + 32) = 0;
  *(void *)(a1 + 40) = 0;
  *(_OWORD *)(a1 + 24) = *(_OWORD *)(a2 + 24);
  *(void *)(a1 + 40) = *(void *)(a2 + 40);
  *(void *)(a2 + 24) = 0;
  *(void *)(a2 + 32) = 0;
  *(void *)(a2 + 40) = 0;
  std::__hash_table<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::__unordered_map_hasher<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::hash<long>,std::equal_to<long>,true>,std::__unordered_map_equal<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::equal_to<long>,std::hash<long>,true>,std::allocator<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>>>::__hash_table(a1 + 48, (uint64_t *)(a2 + 48));
  std::__hash_table<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::__unordered_map_hasher<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::hash<long>,std::equal_to<long>,true>,std::__unordered_map_equal<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::equal_to<long>,std::hash<long>,true>,std::allocator<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>>>::__hash_table(a1 + 88, (uint64_t *)(a2 + 88));
  long long v4 = *(_OWORD *)(a2 + 128);
  long long v5 = *(_OWORD *)(a2 + 144);
  *(unsigned char *)(a1 + 160) = *(unsigned char *)(a2 + 160);
  *(_OWORD *)(a1 + 128) = v4;
  *(_OWORD *)(a1 + 144) = v5;
  return a1;
}

uint64_t std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>::__swap_out_circular_buffer(uint64_t *a1, void *a2)
{
  uint64_t v5 = *a1;
  uint64_t v4 = a1[1];
  uint64_t result = a2[1];
  while (v4 != v5)
  {
    v4 -= 168;
    uint64_t result = std::pair<std::list<ZinIrOpLayer *>,SplitInfo>::pair[abi:ne180100](result - 168, v4);
  }
  a2[1] = result;
  uint64_t v7 = *a1;
  *a1 = result;
  a2[1] = v7;
  uint64_t v8 = a1[1];
  a1[1] = a2[2];
  a2[2] = v8;
  uint64_t v9 = a1[2];
  a1[2] = a2[3];
  a2[3] = v9;
  *a2 = a2[1];
  return result;
}

uint64_t std::__split_buffer<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>::~__split_buffer(uint64_t a1)
{
  uint64_t v3 = *(void *)(a1 + 8);
  for (uint64_t i = *(void *)(a1 + 16); i != v3; uint64_t i = *(void *)(a1 + 16))
  {
    *(void *)(a1 + 16) = i - 168;
    std::__destroy_at[abi:ne180100]<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>,0>((void *)(i - 168));
  }
  if (*(void *)a1) {
    operator delete(*(void **)a1);
  }
  return a1;
}

uint64_t std::pair<std::list<ZinIrOpLayer *>,SplitInfo>::pair[abi:ne180100]<std::list<ZinIrOpLayer *>&,SplitInfo&,0>(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v5 = std::list<ZinIrOpLayer *>::list((void *)a1, a2);
  v5[3] = 0;
  v5[4] = 0;
  v5[5] = 0;
  std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__init_with_size[abi:ne180100]<std::vector<std::optional<TiledLayerTensorRegions>>*,std::vector<std::optional<TiledLayerTensorRegions>>*>(v5 + 3, *(uint64_t **)a3, *(uint64_t **)(a3 + 8), 0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*(void *)(a3 + 8) - *(void *)a3) >> 3));
  std::unordered_map<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>::unordered_map(a1 + 48, a3 + 24);
  std::unordered_set<ZinIrOpLayer const*>::unordered_set(a1 + 88, a3 + 64);
  long long v6 = *(_OWORD *)(a3 + 104);
  long long v7 = *(_OWORD *)(a3 + 120);
  *(unsigned char *)(a1 + 160) = *(unsigned char *)(a3 + 136);
  *(_OWORD *)(a1 + 128) = v6;
  *(_OWORD *)(a1 + 144) = v7;
  return a1;
}

void sub_21127F184(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::~__hash_table(v3);
  std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__destroy_vector::operator()[abi:ne180100]((void ***)va);
  std::__list_imp<ZinIrSection *>::clear(v2);
  _Unwind_Resume(a1);
}

void std::__function::__func<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_4,std::allocator<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_4>,ZinIrStatus ()(ZinIrBasicBlock *)>::~__func()
{
}

__n128 std::__function::__func<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_4,std::allocator<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_4>,ZinIrStatus ()(ZinIrBasicBlock *)>::__clone(uint64_t a1)
{
  unint64_t v2 = (char *)operator new(0x20uLL);
  *(void *)unint64_t v2 = &unk_26C322E88;
  __n128 result = *(__n128 *)(a1 + 8);
  *(__n128 *)(v2 + 8) = result;
  *((void *)v2 + 3) = *(void *)(a1 + 24);
  return result;
}

__n128 std::__function::__func<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_4,std::allocator<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_4>,ZinIrStatus ()(ZinIrBasicBlock *)>::__clone(uint64_t a1, uint64_t a2)
{
  *(void *)a2 = &unk_26C322E88;
  __n128 result = *(__n128 *)(a1 + 8);
  *(void *)(a2 + 24) = *(void *)(a1 + 24);
  *(__n128 *)(a2 + 8) = result;
  return result;
}

uint64_t std::__function::__func<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_4,std::allocator<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_4>,ZinIrStatus ()(ZinIrBasicBlock *)>::operator()(uint64_t a1, ZinIrTarget **a2)
{
  return ZinMirBatchOrChannelSplitter::UpdatePerBasicBlock(*(ZinMirGraphSplitterBase **)(*(void *)(a1 + 8) + 192), *a2, *(void *)(a1 + 16), *(void **)(a1 + 24));
}

uint64_t std::__function::__func<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_4,std::allocator<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_4>,ZinIrStatus ()(ZinIrBasicBlock *)>::target(uint64_t a1, uint64_t a2)
{
  {
    return a1 + 8;
  }
  else
  {
    return 0;
  }
}

void *std::__function::__func<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_4,std::allocator<ZinMirSpatialSplitter::TileWithGlobalRefinement(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_4>,ZinIrStatus ()(ZinIrBasicBlock *)>::target_type()
{
}

void std::__function::__func<ZinMirSpatialSplitter::Tile(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_0,std::allocator<ZinMirSpatialSplitter::Tile(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_0>,ZinIrStatus ()(ZinIrBasicBlock *)>::~__func()
{
}

__n128 std::__function::__func<ZinMirSpatialSplitter::Tile(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_0,std::allocator<ZinMirSpatialSplitter::Tile(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_0>,ZinIrStatus ()(ZinIrBasicBlock *)>::__clone(uint64_t a1)
{
  unint64_t v2 = (char *)operator new(0x20uLL);
  *(void *)unint64_t v2 = &unk_26C32F540;
  __n128 result = *(__n128 *)(a1 + 8);
  *(__n128 *)(v2 + 8) = result;
  *((void *)v2 + 3) = *(void *)(a1 + 24);
  return result;
}

__n128 std::__function::__func<ZinMirSpatialSplitter::Tile(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_0,std::allocator<ZinMirSpatialSplitter::Tile(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_0>,ZinIrStatus ()(ZinIrBasicBlock *)>::__clone(uint64_t a1, uint64_t a2)
{
  *(void *)a2 = &unk_26C32F540;
  __n128 result = *(__n128 *)(a1 + 8);
  *(void *)(a2 + 24) = *(void *)(a1 + 24);
  *(__n128 *)(a2 + 8) = result;
  return result;
}

uint64_t std::__function::__func<ZinMirSpatialSplitter::Tile(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_0,std::allocator<ZinMirSpatialSplitter::Tile(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_0>,ZinIrStatus ()(ZinIrBasicBlock *)>::operator()(uint64_t a1, ZinIrTarget **a2)
{
  std::string v103 = *a2;
  uint64_t v4 = a1 + 8;
  unint64_t v2 = *(uint64_t ***)(a1 + 8);
  uint64_t v3 = *(void *)(v4 + 8);
  uint64_t v36 = 0;
  long long v37 = 0;
  uint64_t v38 = 0;
  std::__tree<std::__value_type<ZinIrBasicBlock *,std::vector<std::pair<Subgraph,SplitInfo>>>,std::__map_value_compare<ZinIrBasicBlock *,std::__value_type<ZinIrBasicBlock *,std::vector<std::pair<Subgraph,SplitInfo>>>,std::less<ZinIrBasicBlock *>,true>,std::allocator<std::__value_type<ZinIrBasicBlock *,std::vector<std::pair<Subgraph,SplitInfo>>>>>::__emplace_unique_key_args<ZinIrBasicBlock *,ZinIrBasicBlock *&,std::vector<std::pair<Subgraph,SplitInfo>>>(v2, (unint64_t *)&v103, &v103, (uint64_t)&v36);
  long long v70 = &v36;
  std::vector<std::pair<Subgraph,SplitInfo>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v70);
  uint64_t v100 = 0;
  uint64_t v101 = 0;
  uint64_t v102 = 0;
  uint64_t v5 = *(uint64_t (****)(void, uint64_t *, uint64_t *, void, void))(v3 + 176);
  Hal = ZinIrTarget::GetHal(v6, v103);
  int v8 = (**v5)(v5, Hal, &v100, 0, 0);
  std::string::basic_string[abi:ne180100]<0>(&v98, "[Initial Subgraphs]");
  unint64_t v33 = (ZinIrHalH13g *)(v3 + 200);
  ZinIrHalH13g::~ZinIrHalH13g((ZinIrHalH13g *)(v3 + 200));
  if (v99 < 0) {
    operator delete(v98);
  }
  uint64_t v9 = 3;
  if (v8 != 3)
  {
    uint64_t v10 = 0;
    int64x2_t v35 = vdupq_n_s64(1uLL);
    unint64_t v11 = &std::piecewise_construct;
    while (0x86BCA1AF286BCA1BLL * ((v101 - v100) >> 3) > (unsigned __int16)v10)
    {
      uint64_t v12 = v10;
      Subgraph::Subgraph((Subgraph *)v89, (const Subgraph *)(v100 + 152 * (unsigned __int16)v10));
      uint64_t v83 = 0;
      memset(v82, 0, sizeof(v82));
      memset(v85, 0, sizeof(v85));
      int v84 = 1065353216;
      int v86 = 1065353216;
      int64x2_t v87 = v35;
      int64x2_t v88 = v35;
      v71[0] = 0;
      v71[1] = 0;
      v73[0] = 0;
      v73[1] = 0;
      long long v70 = (void ***)v71;
      int v72 = v73;
      v75[0] = 0;
      v75[1] = 0;
      v77[0] = 0;
      v77[1] = 0;
      int64x2_t v74 = v75;
      uint64_t v76 = v77;
      v79[0] = 0;
      v79[1] = 0;
      uint64_t v78 = v79;
      memset(v80, 0, sizeof(v80));
      int v81 = 1065353216;
      LODWORD(v36) = 3;
      v105[0] = &v36;
      unint64_t v13 = std::__tree<std::__value_type<ZinIrDimension,unsigned long>,std::__map_value_compare<ZinIrDimension,std::__value_type<ZinIrDimension,unsigned long>,std::less<ZinIrDimension>,true>,std::allocator<std::__value_type<ZinIrDimension,unsigned long>>>::__emplace_unique_key_args<ZinIrDimension,std::piecewise_construct_t const&,std::tuple<ZinIrDimension&&>,std::tuple<>>((uint64_t **)(v95 - 24), (int *)&v36, (uint64_t)v11, v105)[5];
      LODWORD(v104) = 4;
      v105[0] = &v104;
      uint64_t v14 = std::__tree<std::__value_type<ZinIrDimension,unsigned long>,std::__map_value_compare<ZinIrDimension,std::__value_type<ZinIrDimension,unsigned long>,std::less<ZinIrDimension>,true>,std::allocator<std::__value_type<ZinIrDimension,unsigned long>>>::__emplace_unique_key_args<ZinIrDimension,std::piecewise_construct_t const&,std::tuple<ZinIrDimension&&>,std::tuple<>>((uint64_t **)(v95 - 24), (int *)&v104, (uint64_t)v11, v105)[5];
      v87.i64[0] = (uint64_t)v13;
      v87.i64[1] = (uint64_t)v14;
      LODWORD(v36) = 0;
      v105[0] = &v36;
      v88.i64[0] = (uint64_t)std::__tree<std::__value_type<ZinIrDimension,unsigned long>,std::__map_value_compare<ZinIrDimension,std::__value_type<ZinIrDimension,unsigned long>,std::less<ZinIrDimension>,true>,std::allocator<std::__value_type<ZinIrDimension,unsigned long>>>::__emplace_unique_key_args<ZinIrDimension,std::piecewise_construct_t const&,std::tuple<ZinIrDimension&&>,std::tuple<>>((uint64_t **)(v95 - 24), (int *)&v36, (uint64_t)v11, v105)[5];
      std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::resize((uint64_t *)v82, v87.i64[0] * v88.i64[0] * v87.i64[1]);
      SplitInfo::ReserveBranch((uint64_t **)v82, v93[2]);
      uint64_t v15 = v11;
      SplitInfo::ReserveTiledLayerTensorRegions((uint64_t)v82, v93, v87.i64[1] * v87.i64[0] * v88.i64[0]);
      v69[0] = 0;
      v69[1] = 0;
      uint64_t v68 = v69;
      unint64_t v16 = PressureBasedSubgraphIdentification::EstimateSizeOfKernelReads((uint64_t)v89, (uint64_t)&v68, **(void **)(v3 + 16), 1);
      unint64_t v17 = *(void *)(**(void **)(v3 + 16) + 480);
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v68, v69[0]);
      if (v16 > v17)
      {
        uint64_t v18 = 1;
        char v97 = 1;
      }
      uint64_t v19 = (ZinIrOpLayerGraph *)ZinIrTarget::GetHal((uint64_t *)v18, v103);
      unint64_t v11 = v15;
      int v20 = ZinMirGraphSplitterBase::TileSubgraph((ZinMirGraphSplitterBase *)v3, v19, (Subgraph *)v89, (SplitInfo *)v82, (LatencyInfo *)&v70, 1);
      if (!v20)
      {
        uint64_t v21 = **(uint64_t ***)(a1 + 24);
        if (v21)
        {
          std::pair<std::list<ZinIrOpLayer *>,SplitInfo>::pair[abi:ne180100]<std::list<ZinIrOpLayer *>&,SplitInfo&,0>((uint64_t)&v36, (uint64_t)v92, (uint64_t)v82);
          std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>::push_back[abi:ne180100](v21, (uint64_t)&v36);
          std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&v42);
          std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::~__hash_table((uint64_t)v40);
          v105[0] = v39;
          std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__destroy_vector::operator()[abi:ne180100]((void ***)v105);
          std::__list_imp<ZinIrSection *>::clear(&v36);
        }
        std::string::basic_string[abi:ne180100]<0>(&__p, "[Visited Subgraph]");
        uint64_t v22 = (uint64_t)v15;
        Subgraph::Subgraph((Subgraph *)v59, (const Subgraph *)v89);
        ZinIrHalH13g::~ZinIrHalH13g(v33);
        std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v65, v65[1]);
        uint64_t v36 = (void **)&v64;
        std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100](&v36);
        std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v63, v63[1]);
        std::__list_imp<ZinIrSection *>::clear(v62);
        std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v61, v61[1]);
        std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v59, v60);
        if (v67 < 0) {
          operator delete(__p);
        }
        if ((*(unsigned int (**)(void, unsigned char *, _OWORD *))(**(void **)(v3 + 176) + 16))(*(void *)(v3 + 176), v89, v82))
        {
          int64x2_t v87 = vdupq_n_s64(1uLL);
          v88.i64[0] = 1;
          uint64_t v23 = v100;
          uint64_t v24 = v101;
          uint64_t v25 = *(void *)(v3 + 176);
          uint64_t v26 = ZinIrTarget::GetHal((uint64_t *)1, v103);
          long long v37 = 0;
          uint64_t v38 = 0;
          uint64_t v36 = (void **)&v37;
          (*(void (**)(uint64_t, uint64_t *, unsigned char *, void ***, uint64_t *))(*(void *)v25 + 8))(v25, v26, v89, &v36, &v100);
          std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v36, v37);
          uint64_t v36 = 0;
          long long v37 = 0;
          uint64_t v38 = 0;
          std::vector<Subgraph>::__init_with_size[abi:ne180100]<std::__wrap_iter<Subgraph const*>,std::__wrap_iter<Subgraph const*>>(&v36, v100 + 8 * ((v24 - v23) >> 3), v101, 0x86BCA1AF286BCA1BLL * ((v101 - v100 - (v24 - v23)) >> 3));
          std::string::basic_string[abi:ne180100]<0>(&v57, "[Refined Subgraphs]");
          uint64_t v22 = (uint64_t)v15;
          ZinIrHalH13g::~ZinIrHalH13g(v33);
          if (v58 < 0) {
            operator delete(v57);
          }
          v105[0] = &v36;
          std::vector<Subgraph>::__destroy_vector::operator()[abi:ne180100]((void ***)v105);
        }
        else
        {
          std::string::basic_string[abi:ne180100]<0>(&v55, "[Finalized Subgraph]");
          Subgraph::Subgraph((Subgraph *)v48, (const Subgraph *)v89);
          ZinIrHalH13g::~ZinIrHalH13g(v33);
          std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v54, v54[1]);
          uint64_t v36 = (void **)&v53;
          std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100](&v36);
          std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v52, v52[1]);
          std::__list_imp<ZinIrSection *>::clear(v51);
          std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v50, v50[1]);
          std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v48, v49);
          if (v56 < 0) {
            operator delete(v55);
          }
        }
        std::pair<Subgraph,SplitInfo>::pair[abi:ne180100]<Subgraph,SplitInfo,0>((uint64_t)&v36, (uint64_t)v89, (uint64_t)v82);
        uint64_t v27 = *(uint64_t ***)(a1 + 8);
        std::string v104 = &v103;
        uint64_t v28 = std::__tree<std::__value_type<ZinIrOpLayer const*,std::vector<std::unordered_map<ZinIrDimension,unsigned long>>>,std::__map_value_compare<ZinIrOpLayer const*,std::__value_type<ZinIrOpLayer const*,std::vector<std::unordered_map<ZinIrDimension,unsigned long>>>,std::less<ZinIrOpLayer const*>,true>,std::allocator<std::__value_type<ZinIrOpLayer const*,std::vector<std::unordered_map<ZinIrDimension,unsigned long>>>>>::__emplace_unique_key_args<ZinIrOpLayer const*,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer const* const&>,std::tuple<>>(v27, (unint64_t *)&v103, v22, (uint64_t **)&v104);
        uint64_t v29 = v28;
        unint64_t v30 = v28[6];
        if (v30 >= v28[7])
        {
          uint64_t v31 = std::vector<std::pair<Subgraph,SplitInfo>>::__push_back_slow_path<std::pair<Subgraph,SplitInfo> const&>(v28 + 5, (uint64_t)&v36);
        }
        else
        {
          std::pair<Subgraph,SplitInfo>::pair[abi:ne180100](v28[6], (uint64_t)&v36);
          uint64_t v31 = v30 + 296;
          v29[6] = v30 + 296;
        }
        v29[6] = v31;
        uint64_t v12 = (v12 + 1);
        std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&v47);
        std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::~__hash_table((uint64_t)&v46);
        v105[0] = &v45;
        std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__destroy_vector::operator()[abi:ne180100]((void ***)v105);
        std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v44, v44[1]);
        v105[0] = &v43;
        std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100]((void ***)v105);
        std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v41, v41[1]);
        std::__list_imp<ZinIrSection *>::clear(v40);
        std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v39, v39[1]);
        std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v36, v37);
        unint64_t v11 = v15;
      }
      std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v80);
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v78, v79[0]);
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v76, v77[0]);
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v74, v75[0]);
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v72, v73[0]);
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v70, v71[0]);
      std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v85);
      std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::~__hash_table((uint64_t)&v82[1] + 8);
      uint64_t v36 = (void **)v82;
      std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__destroy_vector::operator()[abi:ne180100](&v36);
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v96, v96[1]);
      uint64_t v36 = (void **)&v94;
      std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100](&v36);
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v93, (void *)v93[1]);
      std::__list_imp<ZinIrSection *>::clear(v92);
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v91, v91[1]);
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v89, v90);
      uint64_t v10 = v12;
      if (v20)
      {
        uint64_t v9 = 3;
        goto LABEL_26;
      }
    }
    uint64_t v9 = 0;
  }
LABEL_26:
  uint64_t v36 = (void **)&v100;
  std::vector<Subgraph>::__destroy_vector::operator()[abi:ne180100](&v36);
  return v9;
}

void sub_21127FC18(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33,uint64_t a34,uint64_t a35,uint64_t a36,uint64_t a37,uint64_t a38,uint64_t a39,uint64_t a40,uint64_t a41,uint64_t a42,uint64_t a43,uint64_t a44,uint64_t a45,uint64_t a46,uint64_t a47,uint64_t a48,uint64_t a49,uint64_t a50)
{
  if (*(char *)(v50 - 153) < 0) {
    operator delete(*(void **)(v50 - 176));
  }
  a50 = v50 - 152;
  std::vector<Subgraph>::__destroy_vector::operator()[abi:ne180100]((void ***)&a50);
  _Unwind_Resume(a1);
}

uint64_t std::__function::__func<ZinMirSpatialSplitter::Tile(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_0,std::allocator<ZinMirSpatialSplitter::Tile(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_0>,ZinIrStatus ()(ZinIrBasicBlock *)>::target(uint64_t a1, uint64_t a2)
{
  {
    return a1 + 8;
  }
  else
  {
    return 0;
  }
}

void *std::__function::__func<ZinMirSpatialSplitter::Tile(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_0,std::allocator<ZinMirSpatialSplitter::Tile(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_0>,ZinIrStatus ()(ZinIrBasicBlock *)>::target_type()
{
}

void *std::vector<Subgraph>::__init_with_size[abi:ne180100]<std::__wrap_iter<Subgraph const*>,std::__wrap_iter<Subgraph const*>>(void *result, uint64_t a2, uint64_t a3, unint64_t a4)
{
  if (a4)
  {
    long long v6 = result;
    std::vector<Subgraph>::__vallocate[abi:ne180100](result, a4);
    __n128 result = (void *)std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<Subgraph>,Subgraph const*,Subgraph const*,Subgraph*>((uint64_t)(v6 + 2), a2, a3, v6[1]);
    v6[1] = result;
  }
  return result;
}

void sub_21127FFB8(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, void **a9)
{
  *(void *)(v9 + 8) = v10;
  std::vector<Subgraph>::__destroy_vector::operator()[abi:ne180100](&a9);
  _Unwind_Resume(a1);
}

uint64_t std::vector<std::pair<Subgraph,SplitInfo>>::__push_back_slow_path<std::pair<Subgraph,SplitInfo> const&>(uint64_t *a1, uint64_t a2)
{
  uint64_t v3 = *a1;
  uint64_t v4 = 0x14C1BACF914C1BADLL * ((a1[1] - *a1) >> 3);
  unint64_t v5 = v4 + 1;
  if ((unint64_t)(v4 + 1) > 0xDD67C8A60DD67CLL) {
    std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
  }
  uint64_t v7 = (uint64_t)(a1 + 2);
  unint64_t v8 = 0x14C1BACF914C1BADLL * ((a1[2] - v3) >> 3);
  if (2 * v8 > v5) {
    unint64_t v5 = 2 * v8;
  }
  if (v8 >= 0x6EB3E45306EB3ELL) {
    unint64_t v9 = 0xDD67C8A60DD67CLL;
  }
  else {
    unint64_t v9 = v5;
  }
  unint64_t v17 = a1 + 2;
  if (v9) {
    uint64_t v10 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<std::pair<Subgraph,SplitInfo>>>(v7, v9);
  }
  else {
    uint64_t v10 = 0;
  }
  unint64_t v13 = v10;
  uint64_t v14 = &v10[296 * v4];
  unint64_t v16 = &v10[296 * v9];
  std::pair<Subgraph,SplitInfo>::pair[abi:ne180100]((uint64_t)v14, a2);
  uint64_t v15 = v14 + 296;
  std::vector<std::pair<Subgraph,SplitInfo>>::__swap_out_circular_buffer(a1, &v13);
  uint64_t v11 = a1[1];
  std::__split_buffer<std::pair<Subgraph,SplitInfo>>::~__split_buffer((uint64_t)&v13);
  return v11;
}

void sub_2112800E4(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::__split_buffer<std::pair<Subgraph,SplitInfo>>::~__split_buffer((uint64_t)va);
  _Unwind_Resume(a1);
}

void sub_21128018C(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,std::vector<std::optional<TiledLayerTensorRegions>>>>>::~__hash_table(v3);
  std::vector<std::vector<std::optional<TiledLayerTensorRegions>>>::__destroy_vector::operator()[abi:ne180100]((void ***)va);
  Subgraph::~Subgraph(v2);
  _Unwind_Resume(a1);
}

void std::__function::__func<ZinMirSpatialSplitter::Tile(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_1,std::allocator<ZinMirSpatialSplitter::Tile(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_1>,ZinIrStatus ()(ZinIrBasicBlock *)>::~__func()
{
}

__n128 std::__function::__func<ZinMirSpatialSplitter::Tile(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_1,std::allocator<ZinMirSpatialSplitter::Tile(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_1>,ZinIrStatus ()(ZinIrBasicBlock *)>::__clone(uint64_t a1)
{
  unint64_t v2 = (char *)operator new(0x20uLL);
  *(void *)unint64_t v2 = &unk_26C32F598;
  __n128 result = *(__n128 *)(a1 + 8);
  *(__n128 *)(v2 + 8) = result;
  *((void *)v2 + 3) = *(void *)(a1 + 24);
  return result;
}

__n128 std::__function::__func<ZinMirSpatialSplitter::Tile(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_1,std::allocator<ZinMirSpatialSplitter::Tile(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_1>,ZinIrStatus ()(ZinIrBasicBlock *)>::__clone(uint64_t a1, uint64_t a2)
{
  *(void *)a2 = &unk_26C32F598;
  __n128 result = *(__n128 *)(a1 + 8);
  *(void *)(a2 + 24) = *(void *)(a1 + 24);
  *(__n128 *)(a2 + 8) = result;
  return result;
}

uint64_t std::__function::__func<ZinMirSpatialSplitter::Tile(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_1,std::allocator<ZinMirSpatialSplitter::Tile(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_1>,ZinIrStatus ()(ZinIrBasicBlock *)>::operator()(uint64_t a1, ZinIrTarget **a2)
{
  uint64_t v15 = *a2;
  uint64_t v3 = *(ZinMirSpatialSplitter **)(a1 + 16);
  uint64_t v4 = std::map<ZinIrTensor const*,SpatialAmount>::at(*(void *)(a1 + 8), (unint64_t *)&v15);
  if (v4[1] != *v4)
  {
    uint64_t v5 = 0;
    unint64_t v6 = 0;
    do
    {
      uint64_t v7 = *std::map<ZinIrTensor const*,SpatialAmount>::at(*(void *)(a1 + 8), (unint64_t *)&v15);
      unint64_t v8 = (void *)(*std::map<ZinIrTensor const*,SpatialAmount>::at(*(void *)(a1 + 8), (unint64_t *)&v15) + v5);
      if (v8[33] * v8[32] * v8[34] >= 2uLL)
      {
        unint64_t v9 = (const SplitInfo *)(v8 + 19);
        uint64_t v10 = (const Subgraph *)(v7 + v5);
        ZinMirSpatialSplitter::AdjustTiledRegionsForConcats(v3, v10, (SplitInfo *)(v8 + 19));
        Hal = (ZinIrOpLayerGraph *)ZinIrTarget::GetHal(v11, v15);
        ZinMirGraphSplitterBase::SplitSubgraph(v3, Hal, v10, v9, (unsigned __int16)v6, **(unsigned char **)(a1 + 24));
      }
      ++v6;
      unint64_t v13 = std::map<ZinIrTensor const*,SpatialAmount>::at(*(void *)(a1 + 8), (unint64_t *)&v15);
      v5 += 296;
    }
    while (v6 < 0x14C1BACF914C1BADLL * ((uint64_t)(v13[1] - *v13) >> 3));
  }
  return 0;
}

uint64_t std::__function::__func<ZinMirSpatialSplitter::Tile(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_1,std::allocator<ZinMirSpatialSplitter::Tile(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_1>,ZinIrStatus ()(ZinIrBasicBlock *)>::target(uint64_t a1, uint64_t a2)
{
  {
    return a1 + 8;
  }
  else
  {
    return 0;
  }
}

void *std::__function::__func<ZinMirSpatialSplitter::Tile(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_1,std::allocator<ZinMirSpatialSplitter::Tile(std::shared_ptr<std::vector<std::pair<std::list<ZinIrOpLayer *>,SplitInfo>>>,std::set<ZinANELayer *> const&,BOOL)::$_1>,ZinIrStatus ()(ZinIrBasicBlock *)>::target_type()
{
}

void *std::__hash_table<std::__hash_value_type<ZinIrOpLayer *,LayerTilingHelper>,std::__unordered_map_hasher<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,LayerTilingHelper>,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,true>,std::__unordered_map_equal<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,LayerTilingHelper>,std::equal_to<ZinIrOpLayer *>,std::hash<ZinIrOpLayer *>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer *,LayerTilingHelper>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer * const&>,std::tuple<>>(uint64_t a1, void *a2, uint64_t a3, void **a4)
{
  unint64_t v7 = 0x9DDFEA08EB382D69 * ((8 * *a2 + 8) ^ HIDWORD(*a2));
  unint64_t v8 = 0x9DDFEA08EB382D69 * (HIDWORD(*a2) ^ (v7 >> 47) ^ v7);
  unint64_t v9 = 0x9DDFEA08EB382D69 * (v8 ^ (v8 >> 47));
  unint64_t v10 = *(void *)(a1 + 8);
  if (v10)
  {
    uint8x8_t v11 = (uint8x8_t)vcnt_s8((int8x8_t)v10);
    v11.i16[0] = vaddlv_u8(v11);
    if (v11.u32[0] > 1uLL)
    {
      unint64_t v4 = 0x9DDFEA08EB382D69 * (v8 ^ (v8 >> 47));
      if (v9 >= v10) {
        unint64_t v4 = v9 % v10;
      }
    }
    else
    {
      unint64_t v4 = v9 & (v10 - 1);
    }
    uint64_t v12 = *(void **)(*(void *)a1 + 8 * v4);
    if (v12)
    {
      unint64_t v13 = (void *)*v12;
      if (*v12)
      {
        do
        {
          unint64_t v14 = v13[1];
          if (v14 == v9)
          {
            if (v13[2] == *a2) {
              return v13;
            }
          }
          else
          {
            if (v11.u32[0] > 1uLL)
            {
              if (v14 >= v10) {
                v14 %= v10;
              }
            }
            else
            {
              v14 &= v10 - 1;
            }
            if (v14 != v4) {
              break;
            }
          }
          unint64_t v13 = (void *)*v13;
        }
        while (v13);
      }
    }
  }
  uint64_t v15 = a1 + 16;
  unint64_t v16 = (char *)operator new(0xD8uLL);
  v26[0] = v16;
  v26[1] = a1 + 16;
  *(void *)unint64_t v16 = 0;
  *((void *)v16 + 1) = v9;
  *((void *)v16 + 2) = **a4;
  *(_OWORD *)(v16 + 24) = 0u;
  *(_OWORD *)(v16 + 40) = 0u;
  *(_OWORD *)(v16 + 56) = 0u;
  *(_OWORD *)(v16 + 72) = 0u;
  *(_OWORD *)(v16 + 88) = 0u;
  *(_OWORD *)(v16 + 104) = 0u;
  *(_OWORD *)(v16 + 120) = 0u;
  *(_OWORD *)(v16 + 136) = 0u;
  *(_OWORD *)(v16 + 152) = 0u;
  *(_OWORD *)(v16 + 168) = 0u;
  *(_OWORD *)(v16 + 184) = 0u;
  *(_OWORD *)(v16 + 200) = 0u;
  char v27 = 1;
  float v17 = (float)(unint64_t)(*(void *)(a1 + 24) + 1);
  float v18 = *(float *)(a1 + 32);
  if (!v10 || (float)(v18 * (float)v10) < v17)
  {
    BOOL v19 = 1;
    if (v10 >= 3) {
      BOOL v19 = (v10 & (v10 - 1)) != 0;
    }
    unint64_t v20 = v19 | (2 * v10);
    unint64_t v21 = vcvtps_u32_f32(v17 / v18);
    if (v20 <= v21) {
      size_t v22 = v21;
    }
    else {
      size_t v22 = v20;
    }
    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::__rehash<true>(a1, v22);
    unint64_t v10 = *(void *)(a1 + 8);
    if ((v10 & (v10 - 1)) != 0)
    {
      if (v9 >= v10) {
        unint64_t v4 = v9 % v10;
      }
      else {
        unint64_t v4 = v9;
      }
    }
    else
    {
      unint64_t v4 = (v10 - 1) & v9;
    }
  }
  uint64_t v23 = *(void **)(*(void *)a1 + 8 * v4);
  if (v23)
  {
    *(void *)v26[0] = *v23;
    void *v23 = v26[0];
  }
  else
  {
    *(void *)v26[0] = *(void *)(a1 + 16);
    *(void *)(a1 + 16) = v26[0];
    *(void *)(*(void *)a1 + 8 * v4) = v15;
    if (*(void *)v26[0])
    {
      unint64_t v24 = *(void *)(*(void *)v26[0] + 8);
      if ((v10 & (v10 - 1)) != 0)
      {
        if (v24 >= v10) {
          v24 %= v10;
        }
      }
      else
      {
        v24 &= v10 - 1;
      }
      *(void *)(*(void *)a1 + 8 * v24) = v26[0];
    }
  }
  unint64_t v13 = (void *)v26[0];
  v26[0] = 0;
  ++*(void *)(a1 + 24);
  std::unique_ptr<std::__hash_node<std::__hash_value_type<ZinIrOpLayer *,LayerTilingHelper>,void *>,std::__hash_node_destructor<std::allocator<std::__hash_node<std::__hash_value_type<ZinIrOpLayer *,LayerTilingHelper>,void *>>>>::reset[abi:ne180100]((uint64_t)v26, 0);
  return v13;
}

void sub_211280688(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::unique_ptr<std::__hash_node<std::__hash_value_type<ZinIrOpLayer *,LayerTilingHelper>,void *>,std::__hash_node_destructor<std::allocator<std::__hash_node<std::__hash_value_type<ZinIrOpLayer *,LayerTilingHelper>,void *>>>>::reset[abi:ne180100]((uint64_t)va, 0);
  _Unwind_Resume(a1);
}

void std::__function::__func<ZinMirSpatialSplitter::Run(void)::$_0,std::allocator<ZinMirSpatialSplitter::Run(void)::$_0>,ZinIrStatus ()(ZinIrBasicBlock *)>::~__func()
{
}

void *std::__function::__func<ZinMirSpatialSplitter::Run(void)::$_0,std::allocator<ZinMirSpatialSplitter::Run(void)::$_0>,ZinIrStatus ()(ZinIrBasicBlock *)>::__clone(uint64_t a1)
{
  __n128 result = operator new(0x10uLL);
  uint64_t v3 = *(void *)(a1 + 8);
  void *result = &unk_26C32F490;
  result[1] = v3;
  return result;
}

uint64_t std::__function::__func<ZinMirSpatialSplitter::Run(void)::$_0,std::allocator<ZinMirSpatialSplitter::Run(void)::$_0>,ZinIrStatus ()(ZinIrBasicBlock *)>::__clone(uint64_t result, void *a2)
{
  uint64_t v2 = *(void *)(result + 8);
  *a2 = &unk_26C32F490;
  a2[1] = v2;
  return result;
}

uint64_t std::__function::__func<ZinMirSpatialSplitter::Run(void)::$_0,std::allocator<ZinMirSpatialSplitter::Run(void)::$_0>,ZinIrStatus ()(ZinIrBasicBlock *)>::operator()@<X0>(uint64_t a1@<X0>, ZinIrTarget **a2@<X1>, uint64_t *a3@<X8>)
{
  **(void **)(a1 + 8) += ZinIrTarget::GetHal(a3, *a2)[2];
  return 0;
}

uint64_t std::__function::__func<ZinMirSpatialSplitter::Run(void)::$_0,std::allocator<ZinMirSpatialSplitter::Run(void)::$_0>,ZinIrStatus ()(ZinIrBasicBlock *)>::target(uint64_t a1, uint64_t a2)
{
    return a1 + 8;
  else {
    return 0;
  }
}

void *std::__function::__func<ZinMirSpatialSplitter::Run(void)::$_0,std::allocator<ZinMirSpatialSplitter::Run(void)::$_0>,ZinIrStatus ()(ZinIrBasicBlock *)>::target_type()
{
}

void std::__function::__func<ZinMirSpatialSplitter::Run(void)::$_1,std::allocator<ZinMirSpatialSplitter::Run(void)::$_1>,ZinIrStatus ()(ZinIrBasicBlock *)>::~__func()
{
}

__n128 std::__function::__func<ZinMirSpatialSplitter::Run(void)::$_1,std::allocator<ZinMirSpatialSplitter::Run(void)::$_1>,ZinIrStatus ()(ZinIrBasicBlock *)>::__clone(uint64_t a1)
{
  uint64_t v2 = (char *)operator new(0x18uLL);
  *(void *)uint64_t v2 = &unk_26C32F4E8;
  __n128 result = *(__n128 *)(a1 + 8);
  *(__n128 *)(v2 + 8) = result;
  return result;
}

__n128 std::__function::__func<ZinMirSpatialSplitter::Run(void)::$_1,std::allocator<ZinMirSpatialSplitter::Run(void)::$_1>,ZinIrStatus ()(ZinIrBasicBlock *)>::__clone(uint64_t a1, uint64_t a2)
{
  *(void *)a2 = &unk_26C32F4E8;
  __n128 result = *(__n128 *)(a1 + 8);
  *(__n128 *)(a2 + 8) = result;
  return result;
}

uint64_t std::__function::__func<ZinMirSpatialSplitter::Run(void)::$_1,std::allocator<ZinMirSpatialSplitter::Run(void)::$_1>,ZinIrStatus ()(ZinIrBasicBlock *)>::operator()(uint64_t a1, ZinIrTarget **a2)
{
  uint64_t v3 = *a2;
  unint64_t v4 = *(ZinIrOpLayer ***)(a1 + 8);
  uint64_t v20 = (uint64_t)&v20;
  unint64_t v21 = &v20;
  uint64_t v22 = 0;
  Hal = ZinIrTarget::GetHal(&v20, v3);
  if ((ZinIrNgraph<ZinIrOpLayer *,ZinIrIdComparator<ZinIrOpLayer *>>::TopologicalSortImpl<std::list<ZinIrOpLayer *>>(Hal, &v20) & 1) == 0)ZinAssertImpl("Couldn't do Topological Sort"); {
  unsigned __int16 v19 = 0;
  }
  while (1)
  {
    do
    {
      uint64_t v6 = v22;
      if (!v22) {
        goto LABEL_11;
      }
      unint64_t v7 = v21;
      float v18 = (ZinIrOpLayer *)v21[2];
      uint64_t v8 = *v21;
      *(void *)(v8 + 8) = v21[1];
      *(void *)v7[1] = v8;
      uint64_t v22 = v6 - 1;
      operator delete(v7);
      uint64_t v9 = (*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)v18 + 32))(v18, 0, 0);
      if (*(unsigned char *)(v9 + 164))
      {
LABEL_11:
        uint64_t v13 = 0;
        goto LABEL_13;
      }
      unint64_t v10 = ZinIrTarget::GetHal((uint64_t *)*(unsigned __int8 *)(v9 + 164), v3);
    }
    while (!std::__tree<ZinIrOpLayer *,ZinIrIdComparator<ZinIrOpLayer *>,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)v10, (uint64_t *)&v18));
    v16[0] = 0;
    unsigned __int8 v17 = 0;
    uint64_t v12 = (ZinIrOpLayerGraph *)ZinIrTarget::GetHal(v11, v3);
    uint64_t v13 = ZinMirSpatialSplitter::DeterminePlanStartingAt((uint64_t)v4, v12, **(_DWORD **)(a1 + 16), v18, (uint64_t)v16);
    if (v13) {
      break;
    }
    if (v17)
    {
      unint64_t v14 = (uint64_t **)ZinIrTarget::GetHal((uint64_t *)v17, v3);
      if (!v17) {
        std::__throw_bad_optional_access[abi:ne180100]();
      }
      uint64_t v13 = ZinMirSpatialSplitter::Split(v4, v14, (const ZinMirSpatialSplitter::SplitPlan *)v16, (LayerTilingHelper *)&v19, 0);
      if (v13) {
        break;
      }
    }
    std::__optional_destruct_base<ZinMirSpatialSplitter::SplitPlan,false>::~__optional_destruct_base[abi:ne180100]((uint64_t)v16);
  }
  std::__optional_destruct_base<ZinMirSpatialSplitter::SplitPlan,false>::~__optional_destruct_base[abi:ne180100]((uint64_t)v16);
LABEL_13:
  std::__list_imp<ZinIrSection *>::clear(&v20);
  return v13;
}

void sub_2112809D8(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
  std::__optional_destruct_base<ZinMirSpatialSplitter::SplitPlan,false>::~__optional_destruct_base[abi:ne180100]((uint64_t)&a9);
  std::__list_imp<ZinIrSection *>::clear((void *)(v9 - 72));
  _Unwind_Resume(a1);
}

uint64_t std::__function::__func<ZinMirSpatialSplitter::Run(void)::$_1,std::allocator<ZinMirSpatialSplitter::Run(void)::$_1>,ZinIrStatus ()(ZinIrBasicBlock *)>::target(uint64_t a1, uint64_t a2)
{
    return a1 + 8;
  else {
    return 0;
  }
}

void *std::__function::__func<ZinMirSpatialSplitter::Run(void)::$_1,std::allocator<ZinMirSpatialSplitter::Run(void)::$_1>,ZinIrStatus ()(ZinIrBasicBlock *)>::target_type()
{
}

void LayerTilingHelper::CreateLayer(int a1)
{
  uint64_t v2 = *MEMORY[0x263EF8340];
  v1[0] = 67109120;
  v1[1] = a1;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "unsupported opcode: %d", (uint8_t *)v1, 8u);
}

void LayerTilingHelper::ComputeInputRequirement(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void SplitInfo::Construct(int a1, int a2, char *a3, uint8_t *buf)
{
  if (a3[23] >= 0) {
    uint64_t v5 = a3;
  }
  else {
    uint64_t v5 = *(char **)a3;
  }
  *(_DWORD *)uint8_t buf = 67109634;
  *((_DWORD *)buf + 1) = a2;
  *((_WORD *)buf + 4) = 1024;
  *(_DWORD *)(buf + 10) = a1;
  *((_WORD *)buf + 7) = 2080;
  *((void *)buf + 2) = v5;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "expected to split (th=%d, tw=%d): %s", buf, 0x18u);
  if (a3[23] < 0) {
    operator delete(*(void **)a3);
  }
}

void SplitInfo::TryToConstruct(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "Illegal tile width factor", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "input tile width is not aligned.", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "output tile width is not aligned.", a5, a6, a7, a8, 0);
}

void ZinMirSpatialSplitter::DetermineTiling(uint8_t *buf, unsigned char *a2)
{
  *uint8_t buf = 0;
  *a2 = 0;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "kernel accesses accounting bug", buf, 2u);
}

void ZinMirSpatialSplitter::GatherLatencyInfoOnLayer(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "ERROR: ZinMirSpatialSplitter::ComputeLayerCostOrgLayer.\n", a5, a6, a7, a8, 0);
}

void ZinMirSpatialSplitter::ReEvaluateTiledLayers(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void ZinMirSpatialSplitter::TileWithGlobalRefinement(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "Error: MirOpt::MergeFanoutConvolutions in spatial splitter", a5, a6, a7, a8, 0);
}

void ZinMirSpatialSplitter::DetermineInputLayersForCurrentSplitLayer(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void ZinMirSpatialSplitter::DetermineOutputLayersForCurrentSplitLayer(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void ZinMirSpatialSplitter::Run(ZinIrCompilerParameters *a1)
{
  uint64_t v6 = *MEMORY[0x263EF8340];
  ZinIrCompilerParameters::getSpatialSplitMode(a1, __p);
  if (v3 >= 0) {
    uint64_t v1 = __p;
  }
  else {
    uint64_t v1 = (void **)__p[0];
  }
  *(_DWORD *)uint8_t buf = 136315138;
  uint64_t v5 = v1;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "unexpected split mode: %s", buf, 0xCu);
  if (v3 < 0) {
    operator delete(__p[0]);
  }
}

uint64_t ZinIrDimensionGetTypeno(int a1)
{
  if ((a1 - 1) > 4) {
    return 1;
  }
  else {
    return dword_211F0008C[a1 - 1];
  }
}

uint64_t ZinIrDimensionGetWithTypeno(int a1)
{
  if ((a1 - 1) >= 5) {
    return 5;
  }
  else {
    return (a1 - 1);
  }
}

uint64_t MinDMABufferMapKey::operator<(uint64_t a1, uint64_t a2)
{
  BOOL v4 = ScheduleComparator::operator()((int)&v10, *(ZinIrOpLayer **)a1, *(ZinIrOpLayer **)a2);
  BOOL v5 = ScheduleComparator::operator()((int)&v10, *(ZinIrOpLayer **)a2, *(ZinIrOpLayer **)a1);
  if (v4 && !v5) {
    return 1;
  }
  if (v5 && !v4) {
    return 0;
  }
  unsigned int v7 = *(unsigned __int8 *)(a1 + 8);
  unsigned int v8 = *(unsigned __int8 *)(a2 + 8);
  if (v7 == v8) {
    return *(void *)(a1 + 16) < *(void *)(a2 + 16);
  }
  else {
    return v7 < v8;
  }
}

void PressureBasedSubgraphIdentification::~PressureBasedSubgraphIdentification(ZinMirSpatialSplitLatencyCostModel **this)
{
  *this = (ZinMirSpatialSplitLatencyCostModel *)&unk_26C353CA0;
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)(this + 31));
  std::unique_ptr<ZinMirSpatialSplitLatencyCostModel>::reset[abi:ne180100](this + 30, 0);
  std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)(this + 20));
  std::__tree<std::unique_ptr<ZinIrMemoryPressureAnalyzer::Allocation const>,ZinIrMemoryPressureAnalyzer::PointerComparator,std::allocator<std::unique_ptr<ZinIrMemoryPressureAnalyzer::Allocation const>>>::destroy((uint64_t)(this + 16), this[17]);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)(this + 10), this[11]);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)(this + 3));
}

void ZinIrMemoryPressureAnalyzer::~ZinIrMemoryPressureAnalyzer(ZinIrMemoryPressureAnalyzer *this)
{
}

void PressureBasedSubgraphIdentification::PressureBasedSubgraphIdentification(uint64_t a1, uint64_t a2, void *a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
  *(void *)(a1 + 8) = a2;
  *(void *)(a1 + 16) = a3;
  *(void *)a1 = &unk_26C353CA0;
  *(_OWORD *)(a1 + 24) = 0u;
  *(_OWORD *)(a1 + 40) = 0u;
  *(_DWORD *)(a1 + 56) = 1065353216;
  *(void *)(a1 + 64) = a5;
  *(_DWORD *)(a1 + 72) = 1;
  *(void *)(a1 + 88) = 0;
  *(void *)(a1 + 80) = a1 + 88;
  *(void *)(a1 + 96) = 0;
  *(void *)(a1 + 112) = a4;
  *(_DWORD *)(a1 + 120) = 1065017672;
  *(void *)(a1 + 136) = 0;
  *(void *)(a1 + 128) = a1 + 136;
  *(void *)(a1 + 144) = 0;
  *(unsigned char *)(a1 + 152) = 0;
  *(_OWORD *)(a1 + 240) = 0u;
  *(_OWORD *)(a1 + 160) = 0u;
  *(_OWORD *)(a1 + 176) = 0u;
  *(_DWORD *)(a1 + 192) = 1065353216;
  *(void *)(a1 + 200) = a8;
  *(_OWORD *)(a1 + 208) = xmmword_211F000A0;
  *(void *)(a1 + 224) = a6;
  *(void *)(a1 + 2std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = a7;
  *(_OWORD *)(a1 + 256) = 0u;
  *(void *)(a1 + 272) = 0;
  *(_DWORD *)(a1 + 280) = 1065353216;
  if (*(unsigned char *)(a5 + 2))
  {
    unint64_t v8 = *(void *)(a3[1] + 392);
    if ((v8 & 0x8000000000000000) != 0) {
      unint64_t v8 = *(void *)(*a3 + 624);
    }
    float v9 = (float)v8;
  }
  else
  {
    float v9 = (float)*(unint64_t *)(*a3 + 408) * 0.98;
  }
  *(void *)(a1 + 104) = (unint64_t)v9;
  if (*(void *)(a2 + 360) != *(void *)(a2 + 352))
  {
    ZinLiveRangeUtils<ZinIrOpLayer,ZinIrTensor>::ZinIrComputeLiveRanges((ZinIrOpLayer ***)(a2 + 352), (void *)(a1 + 24));
    operator new();
  }
  ZinAssertImpl("Must run scheduler first");
}

void sub_211281638(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, void *a11, uint64_t a12, int a13, __int16 a14, char a15, char a16, uint64_t a17, uint64_t a18, int a19, __int16 a20,char a21,char a22,void *__p,uint64_t a24,int a25,__int16 a26,char a27,char a28,uint64_t a29,void *a30,uint64_t a31,int a32,__int16 a33,char a34,char a35,uint64_t a36)
{
  if (a28 < 0) {
    operator delete(__p);
  }
  if (a35 < 0) {
    operator delete(a30);
  }
  std::ofstream::~ofstream(&a36);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table(v36 + 248);
  std::unique_ptr<ZinMirSpatialSplitLatencyCostModel>::reset[abi:ne180100](v39, 0);
  ZinIrMemoryPressureAnalyzer::~ZinIrMemoryPressureAnalyzer(v38);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy(a10, *(void **)(v36 + 88));
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table(v37);
  _Unwind_Resume(a1);
}

void PressureBasedSubgraphIdentification::ConstructMemoryPressureMap(PressureBasedSubgraphIdentification *this)
{
  uint64_t v29 = *MEMORY[0x263EF8340];
  v25[0] = 0;
  v25[1] = 0;
  unint64_t v24 = v25;
  memset(v22, 0, sizeof(v22));
  int v23 = 1065353216;
  unint64_t v21 = 0;
  uint64_t v2 = (void *)*((void *)this + 1);
  uint64_t v28 = 0;
  char v3 = operator new(0x28uLL);
  *char v3 = &unk_26C32FB18;
  v3[1] = &v24;
  v3[2] = v22;
  v3[3] = this;
  v3[4] = &v21;
  uint64_t v28 = v3;
  ZinIrControlFlowGraph::TraverseForward(v2, (uint64_t)v27, 1);
  std::__function::__value_func<ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::~__value_func[abi:ne180100](v27);
  if (*(unsigned char *)(*((void *)this + 8) + 2))
  {
    unint64_t v4 = *((void *)this + 13);
    BOOL v5 = v4 >= v21;
    unint64_t v6 = v4 - v21;
    if (!v5) {
      unint64_t v6 = 0;
    }
    *((void *)this + 13) = (unint64_t)((double)*(int *)(*(void *)(*((void *)this + 2) + 8) + 208)
                                              / 100.0
                                              * (double)v6);
  }
  unsigned int v7 = v24;
  if (v24 != v25)
  {
    while (1)
    {
      uint64_t v20 = (ZinIrTensor *)v7[4];
      unint64_t v8 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(*((void **)this + 14), &v20);
      float v9 = v8;
      if (v8
        && ((BOOL IsChain = CpAllocUtils::IsChain(*((_DWORD *)v8 + 6)), !CpAllocUtils::IsL2Inplace(*((_DWORD *)v9 + 6)))
          ? (LODWORD(v9) = CpAllocUtils::IsDRAMInplace(*((_DWORD *)v9 + 6)))
          : (LODWORD(v9) = 1),
            (uint8x8_t v11 = (unsigned char *)*((void *)this + 8), !v11[2]) ? (v12 = IsChain) : (v12 = 0),
            v12))
      {
        if (*v11) {
          ZinAssertImpl("The chaining should be disabled in spatial split analysis with L2-circular buffer. This is because we can't enable chaining in L2-circular buffer.");
        }
        ChainBufferuint64_t Size = ZinL2FootprintCalculator::GetChainBufferSize(*((const ZinIrTensor ***)this + 28), (ZinIrRegAllocUtil **)v20);
      }
      else
      {
        PressureBasedSubgraphIdentification::GetTensorSize(this, v20);
      }
      unint64_t v14 = ChainBufferSize;
      uint64_t v26 = &v20;
      long long v19 = *(_OWORD *)(std::__hash_table<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>>>::__emplace_unique_key_args<ZinIrTensor *,std::piecewise_construct_t const&,std::tuple<ZinIrTensor * const&>,std::tuple<>>((uint64_t)this + 24, &v20, (uint64_t)&std::piecewise_construct, &v26)+ 3);
      if (*(unsigned char *)(*((void *)this + 8) + 2)) {
        int v15 = 0;
      }
      else {
        int v15 = (int)v9;
      }
      if (v15 == 1) {
        --*((void *)&v19 + 1);
      }
      if (!std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(v22, &v20))goto LABEL_25; {
      if (!*(unsigned char *)(*((void *)this + 8) + 2))
      }
        break;
      unint64_t v16 = v7[1];
      if (v16)
      {
        do
        {
          unsigned __int8 v17 = (void **)v16;
          unint64_t v16 = (void *)*v16;
        }
        while (v16);
      }
      else
      {
        do
        {
          unsigned __int8 v17 = (void **)v7[2];
          BOOL v18 = *v17 == v7;
          unsigned int v7 = v17;
        }
        while (!v18);
      }
      unsigned int v7 = v17;
      if (v17 == v25) {
        goto LABEL_32;
      }
    }
    unint64_t v14 = 0;
LABEL_25:
    ZinIrMemoryPressureAnalyzer::AddTensorAllocation((PressureBasedSubgraphIdentification *)((char *)this + 128), v14, (const ZinLiveRange *)&v19, v20);
  }
LABEL_32:
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v22);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v24, v25[0]);
}

void sub_211281A04(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, ...)
{
  va_start(va2, a5);
  va_start(va1, a5);
  va_start(va, a5);
  uint64_t v6 = va_arg(va1, void);
  uint64_t v8 = va_arg(va1, void);
  uint64_t v9 = va_arg(va1, void);
  uint64_t v10 = va_arg(va1, void);
  uint64_t v11 = va_arg(va1, void);
  uint64_t v12 = va_arg(va1, void);
  va_copy(va2, va1);
  uint64_t v13 = va_arg(va2, void);
  int v15 = va_arg(va2, void *);
  uint64_t v16 = va_arg(va2, void);
  uint64_t v17 = va_arg(va2, void);
  uint64_t v18 = va_arg(va2, void);
  std::__function::__value_func<ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::~__value_func[abi:ne180100]((uint64_t *)va2);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)va);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)va1, v15);
  _Unwind_Resume(a1);
}

uint64_t PressureBasedSubgraphIdentification::IsolateLiveRangeForConcatInputs(PressureBasedSubgraphIdentification *this, BOOL *a2)
{
  v5[4] = *MEMORY[0x263EF8340];
  uint64_t v2 = (void *)*((void *)this + 1);
  v5[0] = &unk_26C32FB70;
  v5[1] = this;
  v5[2] = a2;
  v5[3] = v5;
  uint64_t v3 = ZinIrControlFlowGraph::TraverseForward(v2, (uint64_t)v5);
  std::__function::__value_func<ZinIrStatus ()(ZinIrBasicBlock *)>::~__value_func[abi:ne180100](v5);
  return v3;
}

void sub_211281AD8(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::__function::__value_func<ZinIrStatus ()(ZinIrBasicBlock *)>::~__value_func[abi:ne180100]((uint64_t *)va);
  _Unwind_Resume(a1);
}

uint64_t PressureBasedSubgraphIdentification::AddCopyForLiveOutWithMultiFanOutParent(PressureBasedSubgraphIdentification *this, BOOL *a2)
{
  v5[4] = *MEMORY[0x263EF8340];
  uint64_t v2 = (void *)*((void *)this + 1);
  v5[0] = &unk_26C32FBC8;
  v5[1] = this;
  v5[2] = a2;
  v5[3] = v5;
  uint64_t v3 = ZinIrControlFlowGraph::TraverseForward(v2, (uint64_t)v5);
  std::__function::__value_func<ZinIrStatus ()(ZinIrBasicBlock *)>::~__value_func[abi:ne180100](v5);
  return v3;
}

void sub_211281B80(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::__function::__value_func<ZinIrStatus ()(ZinIrBasicBlock *)>::~__value_func[abi:ne180100]((uint64_t *)va);
  _Unwind_Resume(a1);
}

void PressureBasedSubgraphIdentification::GetTensorSize(PressureBasedSubgraphIdentification *this, const ZinIrTensor *a2)
{
  uint64_t v3 = *((void *)this + 8);
  if (*(unsigned char *)(v3 + 2))
  {
    BOOL v4 = *(unsigned char *)(*(void *)(*((void *)this + 2) + 8) + 529) == 0;
    DimensionOrderHint::DimensionOrderHint(__p, 0);
    ZinIrTensor::GetTensorSizeInBytesFromResidency(a2, 2, (uint64_t)__p, v4);
    if (__p[0])
    {
      __p[1] = __p[0];
      operator delete(__p[0]);
    }
  }
  else if (*(unsigned char *)(v3 + 6))
  {
    ZinIrTensor::InferDescriptorForMACITensor(a2, (uint64_t)__p);
    ZinIrTensor::GetTensorSizeInBytesForMACILayout((uint64_t)a2, __p);
  }
  else
  {
    BOOL v5 = (ZinL2FootprintCalculator *)*((void *)this + 28);
    ZinL2FootprintCalculator::GetResidentBufferSize(v5, a2);
  }
}

void sub_211281C64(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, void *__p, uint64_t a10)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

BOOL PressureBasedSubgraphIdentification::HasWorkUnitUtilizationLossAfterSplit(uint64_t a1, uint64_t a2, uint64_t a3, unint64_t a4, unint64_t a5)
{
  BOOL v5 = *(unsigned char **)(a1 + 64);
  if (v5[5] || v5[2] || v5[3]) {
    return 0;
  }
  uint64_t v9 = (*(uint64_t (**)(uint64_t, void, void))(*(void *)a2 + 32))(a2, 0, 0);
  unint64_t v10 = *(void *)(v9 + 64);
  unint64_t v11 = *(void *)(v9 + 72);
  uint64_t v13 = 0;
  if (ZinTensorFormatGetSizeInBytes(*(_DWORD *)(v9 + 88), &v13)) {
    ZinAssertImpl("Error in getting tensor format size in bytes");
  }
  if (v11 / a5 * (v10 / a4) * v13 >= *(void *)(**(void **)(a1 + 16) + 592)
    || *(unsigned char *)(*(void *)(a1 + 64) + 10))
  {
    return 0;
  }
  if (a4 > 1) {
    return v10 != 1;
  }
  BOOL result = 0;
  if (a4 == 1 && a5 == 1) {
    return v10 != 1;
  }
  return result;
}

uint64_t PressureBasedSubgraphIdentification::IdentifySubgraphs(uint64_t a1, ZinIrOpLayerGraph *a2, uint64_t *a3, uint64_t a4, uint64_t a5)
{
  uint64_t v77 = *MEMORY[0x263EF8340];
  uint64_t v6 = *(void *)(a1 + 8);
  unsigned int v7 = *(const void **)(v6 + 352);
  uint64_t v8 = *(void *)(v6 + 360);
  if ((const void *)v8 == v7) {
    ZinAssertImpl("Must run scheduler first");
  }
  long long v70 = 0;
  long long v71 = 0;
  uint64_t v72 = 0;
  std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(&v70, v7, v8, (v8 - (uint64_t)v7) >> 3);
  if ((*(unsigned char *)(*(void *)(*(void *)(a1 + 16) + 8) + 97) & 1) != 0
    && os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_INFO))
  {
    *(_WORD *)uint8_t buf = 0;
    _os_log_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_INFO, "INFO:: (SpatialSplit) --mem pressure--\n", buf, 2u);
  }
  if (*(unsigned char *)(*(void *)(a1 + 64) + 2)) {
    BOOL v10 = a5 == 0;
  }
  else {
    BOOL v10 = 1;
  }
  if (!v10) {
    ZinAssertImpl("DRAM Legalizer Error");
  }
  uint64_t v67 = 0;
  uint64_t v68 = 0;
  unint64_t v69 = 0;
  uint64_t v11 = *(void *)(*(void *)v70 + 48);
  uint64_t v12 = *(void *)(*((void *)v71 - 1) + 48);
  buf[0] = 0;
  uint64_t PeakPressure = (uint64_t)std::vector<BOOL>::vector(&__p, (v71 - (unsigned char *)v70) >> 3, buf);
  if (v11 <= v12)
  {
    uint64_t v59 = (ZinIrMemoryPressureAnalyzer *)(a1 + 128);
    uint64_t v19 = -1;
    uint64_t v20 = -1;
    uint64_t v58 = v12;
    do
    {
      v65[0] = v11;
      v65[1] = v11;
      uint64_t PeakPressure = ZinIrMemoryPressureAnalyzer::GetPeakPressure(v59, (const ZinLiveRange *)v65);
      unint64_t v22 = PeakPressure;
      if (*(unsigned char *)(*(void *)(*(void *)(a1 + 16) + 8) + 97))
      {
        uint64_t PeakPressure = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_INFO);
        if (PeakPressure)
        {
          uint64_t v23 = *((void *)v70 + v11);
          unint64_t v24 = (void *)(v23 + 24);
          if (*(char *)(v23 + 47) < 0) {
            unint64_t v24 = (void *)*v24;
          }
          *(_DWORD *)uint8_t buf = 134218498;
          *(void *)&uint8_t buf[4] = v11;
          *(_WORD *)&buf[12] = 2048;
          *(void *)&buf[14] = v22;
          *(_WORD *)&buf[22] = 2080;
          *(void *)&uint8_t buf[24] = v24;
          _os_log_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_INFO, "%zd, %llu, %s\n", buf, 0x20u);
        }
      }
      unint64_t v25 = *(void *)(a1 + 104);
      uint64_t v26 = *(unsigned char **)(a1 + 64);
      if (*v26 || v26[1] || v26[3] && !v26[2])
      {
        char v27 = (ZinIrRegAllocUtil *)(*(uint64_t (**)(void, void, void))(**((void **)v70 + v11) + 32))(*((void *)v70 + v11), 0, 0);
        uint64_t PeakPressure = ZinIrRegAllocUtil::IsChainable(v27, **(const ZinIrTensor ***)(a1 + 16), v28);
        if (PeakPressure)
        {
          uint64_t v29 = **(void **)(*((void *)v70 + v11) + 112);
          unint64_t v30 = (ZinIrTensor *)(*(uint64_t (**)(uint64_t, void, void))(*(void *)v29 + 32))(v29, 0, 0);
          RootTensor = ZinIrTensor::GetRootTensor(v30);
          ZinIrTensor::GetTensorSizeInBytes(v27);
          uint64_t v33 = v32;
          ZinIrTensor::GetTensorSizeInBytes(RootTensor);
          BOOL v34 = v33 >= PeakPressure;
        }
        else
        {
          BOOL v34 = 0;
        }
        uint64_t v12 = v58;
        if (v22 > v25 || v34)
        {
LABEL_57:
          if (v19 != -1) {
            goto LABEL_68;
          }
          uint64_t v46 = *((void *)v70 + v11);
          uint64_t v47 = *(void *)(v46 + 88);
          uint64_t v48 = *(void *)(v46 + 96);
          if (v47 == v48) {
            goto LABEL_66;
          }
          uint64_t v19 = v11 - 1;
          while (1)
          {
            if ((*(_DWORD *)(*(void *)(*(void *)v47 + 64) + 8) - 28) >= 3)
            {
              unint64_t v49 = *(void *)(*(void *)v47 + 48);
              uint64_t v50 = *((void *)__p + (v49 >> 6));
              if ((v50 & (1 << v49)) == 0 && v49 == v19) {
                break;
              }
            }
            v47 += 8;
            if (v47 == v48) {
              goto LABEL_66;
            }
          }
          *((void *)__p + (v49 >> 6)) = v50 | (1 << v49);
          goto LABEL_67;
        }
      }
      else if (v22 > v25)
      {
        goto LABEL_57;
      }
      uint64_t v35 = *(void *)(*(void *)(a1 + 8) + 352);
      if (*(void *)(*(void *)(a1 + 8) + 360) == v35) {
        ZinAssertImpl("Must run scheduler first");
      }
      unsigned int v36 = *(_DWORD *)(*(void *)(*(void *)(v35 + 8 * v11) + 64) + 8);
      BOOL v37 = v36 > 0x24;
      uint64_t v38 = (1 << v36) & 0x1870000080;
      if (v37 || v38 == 0)
      {
        uint64_t v40 = *((void *)v70 + v11);
        uint64_t v41 = *(void *)(v40 + 112);
        uint64_t v42 = *(void *)(v40 + 120);
        while (1)
        {
          if (v41 == v42)
          {
            if (v19 != -1) {
              uint64_t v20 = v11;
            }
            uint64_t v12 = v58;
            goto LABEL_67;
          }
          uint64_t v43 = *(void **)v41;
          uint64_t v44 = v11 + ((uint64_t)(*(void *)(*(void *)v41 + 96) - *(void *)(*(void *)v41 + 88)) >> 3);
          if (*(void *)(*(void *)v41 + 48) <= v44)
          {
            *(void *)uint8_t buf = v11
                           + ((uint64_t)(*(void *)(*(void *)v41 + 96) - *(void *)(*(void *)v41 + 88)) >> 3);
            *(void *)&uint8_t buf[8] = v44;
            uint64_t PeakPressure = ZinIrMemoryPressureAnalyzer::GetPeakPressure(v59, (const ZinLiveRange *)buf);
            if (*(_DWORD *)(v43[8] + 8) == 7)
            {
              for (uint64_t i = v43[11]; i != v43[12]; i += 8)
              {
                if (*(void *)(*(void *)i + 48) < v19) {
                  goto LABEL_88;
                }
              }
            }
            if ((unint64_t)PeakPressure >= *(void *)(a1 + 104)) {
              break;
            }
          }
          v41 += 8;
        }
LABEL_88:
        if (v19 != -1)
        {
          uint64_t v12 = v58;
          goto LABEL_68;
        }
        uint64_t v12 = v58;
        if (!*(unsigned char *)(*(void *)(a1 + 64) + 2))
        {
          uint64_t PeakPressure = (*(uint64_t (**)(uint64_t, void))(*(void *)a1 + 32))(a1, *((void *)v70 + v11));
          if (PeakPressure) {
            goto LABEL_80;
          }
        }
LABEL_66:
        uint64_t v19 = v11;
      }
LABEL_67:
      if (v19 != -1)
      {
LABEL_68:
        *(void *)((char *)__p + (((unint64_t)v11 >> 3) & 0x1FFFFFFFFFFFFFF8)) |= 1 << v11;
        uint64_t v52 = *(void *)(a1 + 64);
        if (!*(unsigned char *)(v52 + 10) && !*(unsigned char *)(v52 + 5))
        {
          uint64_t PeakPressure = PressureBasedSubgraphIdentification::HasWorkUnitUtilizationLossAfterSplit(a1, *((void *)v70 + v11), v21, 1uLL, 1uLL);
          if (PeakPressure) {
            uint64_t v20 = v11;
          }
        }
        if (v20 == -1) {
          goto LABEL_81;
        }
        *(void *)&long long v64 = v19;
        *((void *)&v64 + 1) = v20;
        uint64_t v60 = 0;
        uint64_t v61 = 0;
        uint64_t v62 = 0;
        if (*(unsigned char *)(a1 + 73) && os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_INFO))
        {
          *(_DWORD *)uint8_t buf = 134218240;
          *(void *)&uint8_t buf[4] = v19;
          *(_WORD *)&buf[12] = 2048;
          *(void *)&buf[14] = v20;
          _os_log_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_INFO, "Extracting cluster at High Pressure Region [%zu,%zu]", buf, 0x16u);
        }
        PressureBasedSubgraphIdentification::ExtractSubgraphsInHighPressureRegion(a1, a2, (uint64_t *)&v64, a4, a5, (uint64_t)&v60);
        *(_OWORD *)uint8_t buf = v64;
        *(void *)&uint8_t buf[24] = 0;
        uint64_t v75 = 0;
        *(void *)&buf[16] = 0;
        std::vector<Subgraph>::__init_with_size[abi:ne180100]<Subgraph*,Subgraph*>(&buf[16], v60, v61, 0x86BCA1AF286BCA1BLL * ((v61 - v60) >> 3));
        int v76 = v63;
        uint64_t v53 = v68;
        if ((unint64_t)v68 >= v69)
        {
          uint64_t v54 = std::vector<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::__push_back_slow_path<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>(&v67, (uint64_t)buf);
        }
        else
        {
          *uint64_t v68 = *(_OWORD *)buf;
          *((void *)v53 + 3) = 0;
          *((void *)v53 + 4) = 0;
          *((void *)v53 + 2) = 0;
          v53[1] = *(_OWORD *)&buf[16];
          *((void *)v53 + 4) = v75;
          *(void *)&buf[16] = 0;
          *(void *)&uint8_t buf[24] = 0;
          uint64_t v75 = 0;
          *((_DWORD *)v53 + 10) = v76;
          uint64_t v54 = (uint64_t)(v53 + 3);
        }
        uint64_t v68 = (_OWORD *)v54;
        int64x2_t v73 = (void **)&buf[16];
        std::vector<Subgraph>::__destroy_vector::operator()[abi:ne180100](&v73);
        *(void *)uint8_t buf = &v60;
        std::vector<Subgraph>::__destroy_vector::operator()[abi:ne180100]((void ***)buf);
        uint64_t v20 = -1;
LABEL_80:
        uint64_t v19 = -1;
      }
LABEL_81:
      BOOL v10 = v11++ == v12;
    }
    while (!v10);
  }
  if (*(unsigned char *)(*(void *)(a1 + 64) + 2))
  {
    uint64_t v14 = *a3;
    for (uint64_t j = a3[1]; j != v14; std::__destroy_at[abi:ne180100]<Subgraph,0>(j))
      j -= 152;
    a3[1] = v14;
    *(_DWORD *)uint8_t buf = 0;
    PressureBasedSubgraphIdentification::MergeContiguousHighPressureRegions(PeakPressure, &v67);
    PressureBasedSubgraphIdentification::TryExpandHighPressureRegions(a1, a2, &v67, buf);
    if (*(_DWORD *)buf)
    {
      if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_DEBUG)) {
        PressureBasedSubgraphIdentification::IdentifySubgraphs();
      }
    }
  }
  uint64_t v16 = v67;
  for (k = v68; (_OWORD *)v16 != k; v16 += 48)
    std::vector<Subgraph>::__insert_with_size[abi:ne180100]<std::__wrap_iter<Subgraph*>,std::__wrap_iter<Subgraph*>>(a3, a3[1], *(const Subgraph **)(v16 + 16), *(void *)(v16 + 24), 0x86BCA1AF286BCA1BLL * ((uint64_t)(*(void *)(v16 + 24) - *(void *)(v16 + 16)) >> 3));
  if (__p) {
    operator delete(__p);
  }
  *(void *)uint8_t buf = &v67;
  std::vector<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::__destroy_vector::operator()[abi:ne180100]((void ***)buf);
  if (v70)
  {
    long long v71 = (char *)v70;
    operator delete(v70);
  }
  return 0;
}

void sub_211282510(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, char a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,void *__p,uint64_t a28,uint64_t a29,char a30,uint64_t a31,uint64_t a32,void *a33,uint64_t a34)
{
  if (__p) {
    operator delete(__p);
  }
  *(void *)(v34 - 160) = &a30;
  std::vector<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::__destroy_vector::operator()[abi:ne180100]((void ***)(v34 - 160));
  if (a33)
  {
    a34 = (uint64_t)a33;
    operator delete(a33);
  }
  _Unwind_Resume(a1);
}

void PressureBasedSubgraphIdentification::ExtractSubgraphsInHighPressureRegion(uint64_t a1, ZinIrOpLayerGraph *a2, uint64_t *a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  uint64_t v24 = *MEMORY[0x263EF8340];
  long long v19 = 0uLL;
  uint64_t v20 = 0;
  PressureBasedSubgraphIdentification::ClusterLayersInHighPressureRegion((void *)a1, a3, (uint64_t *)&v19);
  if (*(unsigned char *)(a1 + 73) && os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_INFO))
  {
    *(_DWORD *)uint8_t buf = 134217984;
    *(void *)&uint8_t buf[4] = 0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*((void *)&v19 + 1) - v19) >> 3);
    _os_log_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_INFO, "  Initial number of clusters : %zu", buf, 0xCu);
  }
  uint64_t v10 = *((void *)&v19 + 1);
  uint64_t v9 = v19;
  do
  {
    unint64_t v11 = 0;
    for (uint64_t i = v10 - v9; v9 != v10; v9 += 24)
      v11 += *(void *)(v9 + 16);
    PressureBasedSubgraphIdentification::CutClustersAtConcatWithPartialInputs(a1, (uint64_t)&v19);
    memset(v18, 0, sizeof(v18));
    std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::__init_with_size[abi:ne180100]<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>((uint64_t *)v18, (ZinIrOpLayer ***)v19, *((ZinIrOpLayer ****)&v19 + 1), 0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*((void *)&v19 + 1) - v19) >> 3));
    PressureBasedSubgraphIdentification::CutClustersAtPartialOutputs(a1, v18, (uint64_t)&v19);
    *(void *)uint8_t buf = v18;
    std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100]((void ***)buf);
    PressureBasedSubgraphIdentification::RemoveInputAndOutputNoopsOfClusters((void *)a1, (ZinIrOpLayer ****)&v19, (uint64_t *)buf);
    std::vector<std::map<ZinIrDimension,unsigned long>>::__vdeallocate((void **)&v19);
    long long v19 = *(_OWORD *)buf;
    uint64_t v20 = v23;
    uint64_t v21 = buf;
    uint64_t v23 = 0;
    memset(buf, 0, sizeof(buf));
    std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v21);
    PressureBasedSubgraphIdentification::CutClustersForRingBufferWriters(a1, (ZinIrOpLayer ****)&v19, (uint64_t *)buf);
    std::vector<std::map<ZinIrDimension,unsigned long>>::__vdeallocate((void **)&v19);
    long long v19 = *(_OWORD *)buf;
    uint64_t v20 = v23;
    uint64_t v21 = buf;
    uint64_t v23 = 0;
    memset(buf, 0, sizeof(buf));
    std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v21);
    uint64_t v10 = *((void *)&v19 + 1);
    uint64_t v9 = v19;
    if ((void)v19 == *((void *)&v19 + 1))
    {
      unint64_t v13 = 0;
    }
    else
    {
      unint64_t v13 = 0;
      uint64_t v14 = v19;
      do
      {
        v13 += *(void *)(v14 + 16);
        v14 += 24;
      }
      while (v14 != *((void *)&v19 + 1));
    }
    unint64_t v15 = 0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*((void *)&v19 + 1) - v19) >> 3);
  }
  while (0xAAAAAAAAAAAAAAABLL * (i >> 3) < v15 || v13 < v11);
  memset(v17, 0, sizeof(v17));
  std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::__init_with_size[abi:ne180100]<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>((uint64_t *)v17, (ZinIrOpLayer ***)v19, *((ZinIrOpLayer ****)&v19 + 1), v15);
  PressureBasedSubgraphIdentification::RemoveClusterOnlyHasChainPair(a1, v17, (ZinIrOpLayer ****)&v19);
  *(void *)uint8_t buf = v17;
  std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100]((void ***)buf);
  PressureBasedSubgraphIdentification::ConstructSubGraphs(a1, a2, (uint64_t *)&v19, (uint64_t *)a6, (_DWORD *)(a6 + 24));
  *(void *)uint8_t buf = &v19;
  std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100]((void ***)buf);
}

void sub_211282840(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, char a15, uint64_t a16, uint64_t a17, uint64_t a18, void **a19)
{
  a19 = v19;
  std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100](&a19);
  a19 = (void **)&a15;
  std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100](&a19);
  _Unwind_Resume(a1);
}

void PressureBasedSubgraphIdentification::MergeContiguousHighPressureRegions(uint64_t a1, uint64_t *a2)
{
  uint64_t v15 = 0;
  uint64_t v16 = 0;
  uint64_t v17 = 0;
  std::vector<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::__init_with_size[abi:ne180100]<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>*,std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>*>(&v15, *a2, a2[1], 0xAAAAAAAAAAAAAAABLL * ((a2[1] - *a2) >> 4));
  unint64_t v4 = *a2;
  uint64_t v3 = a2[1];
  if (v3 != *a2)
  {
    do
    {
      uint64_t v5 = v3 - 48;
      uint64_t v18 = (void **)(v3 - 32);
      std::vector<Subgraph>::__destroy_vector::operator()[abi:ne180100](&v18);
      uint64_t v3 = v5;
    }
    while (v5 != v4);
  }
  a2[1] = v4;
  if (v16 != v15)
  {
    if (v4 >= a2[2])
    {
      uint64_t v6 = std::vector<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::__push_back_slow_path<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult> const&>(a2, v15);
    }
    else
    {
      std::vector<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::__construct_one_at_end[abi:ne180100]<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult> const&>((uint64_t)a2, v15);
      uint64_t v6 = v4 + 48;
    }
    a2[1] = v6;
    uint64_t v7 = v15;
    if (0xAAAAAAAAAAAAAAABLL * ((v16 - v15) >> 4) >= 2)
    {
      unint64_t v8 = 1;
      do
      {
        uint64_t v9 = (void *)(v7 + 48 * v8);
        if (*v9 == *(v9 - 5) + 1)
        {
          uint64_t v10 = a2[1];
          *(void *)(v10 - 40) = v9[1];
          *(_DWORD *)(v10 - 8) = 1;
          uint64_t v12 = *(void *)(v10 - 32);
          for (uint64_t i = *(void *)(v10 - 24); i != v12; std::__destroy_at[abi:ne180100]<Subgraph,0>(i))
            i -= 152;
          *(void *)(v10 - 24) = v12;
        }
        else
        {
          unint64_t v13 = a2[1];
          if (v13 >= a2[2])
          {
            uint64_t v14 = std::vector<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::__push_back_slow_path<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult> const&>(a2, (uint64_t)v9);
          }
          else
          {
            std::vector<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::__construct_one_at_end[abi:ne180100]<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult> const&>((uint64_t)a2, (uint64_t)v9);
            uint64_t v14 = v13 + 48;
          }
          a2[1] = v14;
        }
        ++v8;
        uint64_t v7 = v15;
      }
      while (v8 < 0xAAAAAAAAAAAAAAABLL * ((v16 - v15) >> 4));
    }
  }
  uint64_t v18 = (void **)&v15;
  std::vector<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::__destroy_vector::operator()[abi:ne180100](&v18);
}

void sub_211282A2C(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, void **a12)
{
  a12 = (void **)&a9;
  std::vector<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::__destroy_vector::operator()[abi:ne180100](&a12);
  _Unwind_Resume(a1);
}

void PressureBasedSubgraphIdentification::TryExpandHighPressureRegions(uint64_t a1, ZinIrOpLayerGraph *a2, uint64_t *a3, _DWORD *a4)
{
  std::list<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::list<std::__wrap_iter<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>*>>(&v41, *a3, a3[1]);
  uint64_t v31 = a4;
  *a4 = 0;
  uint64_t v8 = *(void *)(*(void *)(a1 + 8) + 352);
  uint64_t v7 = *(void *)(*(void *)(a1 + 8) + 360);
  if (v7 == v8) {
    ZinAssertImpl("Must run scheduler first");
  }
  uint64_t v9 = (uint64_t)v42;
  if (v42 == &v41) {
    goto LABEL_34;
  }
  uint64_t v10 = *(void *)(*(void *)v8 + 48);
  uint64_t v11 = *(void *)(*(void *)(v7 - 8) + 48);
  while (!*(_DWORD *)(v9 + 56))
  {
    uint64_t v9 = *(void *)(v9 + 8);
LABEL_31:
    if ((uint64_t *)v9 == &v41) {
      goto LABEL_34;
    }
  }
  uint64_t v12 = v10;
  if ((uint64_t *)v9 != v42) {
    uint64_t v12 = *(void *)(*(void *)v9 + 24) + 1;
  }
  uint64_t v13 = v11;
  if (v9 != v41) {
    uint64_t v13 = *(void *)(*(void *)(v9 + 8) + 16) - 1;
  }
  uint64_t v37 = 0;
  uint64_t v38 = 0;
  uint64_t v39 = 0;
  long long v36 = *(_OWORD *)(v9 + 16);
  PressureBasedSubgraphIdentification::TryExpandHighPressureRegion(a1, a2, &v36, v12, v13, (uint64_t)&v37);
  if (!v40)
  {
    long long v32 = v36;
    uint64_t v34 = 0;
    long long v33 = 0uLL;
    std::vector<Subgraph>::__init_with_size[abi:ne180100]<Subgraph*,Subgraph*>(&v33, v37, v38, 0x86BCA1AF286BCA1BLL * ((v38 - v37) >> 3));
    int v35 = v40;
    *(_OWORD *)(v9 + 16) = v32;
    std::vector<Subgraph>::__vdeallocate((void **)(v9 + 32));
    *(_OWORD *)(v9 + std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = v33;
    *(void *)(v9 + 48) = v34;
    long long v33 = 0uLL;
    uint64_t v34 = 0;
    *(_DWORD *)(v9 + 56) = v35;
    uint64_t v44 = (void **)&v33;
    std::vector<Subgraph>::__destroy_vector::operator()[abi:ne180100](&v44);
    char v27 = (uint64_t *)(v9 + 8);
LABEL_30:
    uint64_t v9 = *v27;
    *(void *)&long long v32 = &v37;
    std::vector<Subgraph>::__destroy_vector::operator()[abi:ne180100]((void ***)&v32);
    goto LABEL_31;
  }
  uint64_t v14 = v9;
  while (1)
  {
    uint64_t v15 = v42;
    if ((uint64_t *)v9 == v42 && v14 == v41) {
      break;
    }
    uint64_t v17 = v37;
    uint64_t v18 = v38;
    if (v38 != v37)
    {
      do
      {
        v18 -= 152;
        std::__destroy_at[abi:ne180100]<Subgraph,0>(v18);
      }
      while (v18 != v17);
      uint64_t v15 = v42;
    }
    uint64_t v38 = v17;
    int v40 = 1;
    if ((uint64_t *)v9 != v15) {
      uint64_t v9 = *(void *)v9;
    }
    if (v14 != v41) {
      uint64_t v14 = *(void *)(v14 + 8);
    }
    uint64_t v19 = *(void *)(v14 + 24);
    uint64_t v20 = v10;
    if ((uint64_t *)v9 != v15) {
      uint64_t v20 = *(void *)(*(void *)v9 + 24);
    }
    uint64_t v21 = v11;
    if (v14 != v41) {
      uint64_t v21 = *(void *)(*(void *)(v14 + 8) + 16);
    }
    *(void *)&long long v36 = *(void *)(v9 + 16);
    *((void *)&v36 + 1) = v19;
    PressureBasedSubgraphIdentification::TryExpandHighPressureRegion(a1, a2, &v36, v20 + 1, v21 - 1, (uint64_t)&v37);
    if (!v40)
    {
      unint64_t v22 = std::list<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::erase((uint64_t)&v41, (void **)v9, *(void ***)(v14 + 8));
      long long v32 = v36;
      uint64_t v34 = 0;
      long long v33 = 0uLL;
      std::vector<Subgraph>::__init_with_size[abi:ne180100]<Subgraph*,Subgraph*>(&v33, v37, v38, 0x86BCA1AF286BCA1BLL * ((v38 - v37) >> 3));
      int v23 = v40;
      int v35 = v40;
      uint64_t v24 = (char *)operator new(0x40uLL);
      long long v25 = v33;
      *((_OWORD *)v24 + 1) = v32;
      *((_OWORD *)v24 + 2) = v25;
      *((void *)v24 + 6) = v34;
      uint64_t v34 = 0;
      long long v33 = 0uLL;
      uint64_t v26 = *v22;
      v26[1] = v24;
      *((void *)v24 + 1) = v22;
      char v27 = (uint64_t *)(v24 + 8);
      *((_DWORD *)v24 + 14) = v23;
      *(void *)uint64_t v24 = v26;
      *unint64_t v22 = v24;
      ++v43;
      uint64_t v44 = (void **)&v33;
      std::vector<Subgraph>::__destroy_vector::operator()[abi:ne180100](&v44);
      goto LABEL_30;
    }
  }
  *uint64_t v31 = 1;
  *(void *)&long long v32 = &v37;
  std::vector<Subgraph>::__destroy_vector::operator()[abi:ne180100]((void ***)&v32);
LABEL_34:
  if (!*v31)
  {
    std::vector<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::resize(a3, v43);
    uint64_t v28 = v42;
    if (v42 != &v41)
    {
      uint64_t v29 = *a3;
      do
      {
        std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>::operator=[abi:ne180100](v29, (uint64_t)(v28 + 2));
        uint64_t v28 = (uint64_t *)v28[1];
        v29 += 48;
      }
      while (v28 != &v41);
    }
  }
  std::__list_imp<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::clear((char *)&v41);
}

void sub_211282DF0(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, ...)
{
  va_start(va, a15);
  std::__list_imp<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::clear(va);
  _Unwind_Resume(a1);
}

double PressureBasedSubgraphIdentification::TryExpandHighPressureRegion(uint64_t a1, ZinIrOpLayerGraph *a2, void *a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  uint64_t v9 = a3[1];
  if (*(unsigned char *)(*(void *)(a1 + 64) + 3)) {
    uint64_t v10 = a4;
  }
  else {
    uint64_t v10 = *a3 - 1;
  }
  if (*(unsigned char *)(*(void *)(a1 + 64) + 3)) {
    uint64_t v11 = a5;
  }
  else {
    uint64_t v11 = v9 + 1;
  }
  if (v10 < a4 || v10 < 1)
  {
LABEL_12:
    if (v11 > a5)
    {
LABEL_13:
      *(_DWORD *)(a6 + 24) = 1;
      return result;
    }
    unint64_t v19 = 0;
    uint64_t v20 = 1;
    while (1)
    {
      *(void *)&long long v26 = a4;
      *((void *)&v26 + 1) = v11;
      PressureBasedSubgraphIdentification::ExtractSubgraphsInHighPressureRegion(a1, a2, (uint64_t *)&v26, 0, 0, a6);
      if (!*(_DWORD *)(a6 + 24)) {
        break;
      }
      uint64_t v21 = *(void *)a6;
      for (uint64_t i = *(void *)(a6 + 8); i != v21; std::__destroy_at[abi:ne180100]<Subgraph,0>(i))
        i -= 152;
      *(void *)(a6 + 8) = v21;
      *(_DWORD *)(a6 + 24) = 1;
      v11 += v20;
      if (v11 <= a5)
      {
        v20 *= 2;
        BOOL v18 = v19++ >= 4;
        if (!v18) {
          continue;
        }
      }
      goto LABEL_13;
    }
  }
  else
  {
    unint64_t v13 = 0;
    uint64_t v14 = 1;
    while (1)
    {
      *(void *)&long long v26 = v10;
      *((void *)&v26 + 1) = v9;
      PressureBasedSubgraphIdentification::ExtractSubgraphsInHighPressureRegion(a1, a2, (uint64_t *)&v26, 0, 0, a6);
      if (!*(_DWORD *)(a6 + 24)) {
        break;
      }
      uint64_t v16 = *(void *)a6;
      for (uint64_t j = *(void *)(a6 + 8); j != v16; std::__destroy_at[abi:ne180100]<Subgraph,0>(j))
        j -= 152;
      *(void *)(a6 + 8) = v16;
      *(_DWORD *)(a6 + 24) = 1;
      v10 -= v14;
      if (v10 >= a4 && v10 >= 1)
      {
        v14 *= 2;
        BOOL v18 = v13++ >= 4;
        if (!v18) {
          continue;
        }
      }
      goto LABEL_12;
    }
  }
  double result = *(double *)&v26;
  *(_OWORD *)a3 = v26;
  return result;
}

void **std::list<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::erase(uint64_t a1, void **a2, void **a3)
{
  if (a2 != a3)
  {
    unint64_t v4 = a2;
    uint64_t v6 = (void **)*a3;
    uint64_t v7 = *a2;
    v7[1] = *((void *)*a3 + 1);
    *v6[1] = v7;
    do
    {
      uint64_t v8 = (void **)v4[1];
      --*(void *)(a1 + 16);
      uint64_t v10 = v4 + 4;
      std::vector<Subgraph>::__destroy_vector::operator()[abi:ne180100](&v10);
      operator delete(v4);
      unint64_t v4 = v8;
    }
    while (v8 != a3);
  }
  return a3;
}

void std::vector<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::resize(uint64_t *a1, unint64_t a2)
{
  uint64_t v3 = a1[1];
  unint64_t v4 = 0xAAAAAAAAAAAAAAABLL * ((v3 - *a1) >> 4);
  BOOL v5 = a2 >= v4;
  unint64_t v6 = a2 - v4;
  if (v6 != 0 && v5)
  {
    std::vector<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::__append(a1, v6);
  }
  else if (!v5)
  {
    uint64_t v7 = *a1 + 48 * a2;
    if (v3 != v7)
    {
      do
      {
        uint64_t v8 = v3 - 48;
        uint64_t v9 = (void **)(v3 - 32);
        std::vector<Subgraph>::__destroy_vector::operator()[abi:ne180100](&v9);
        uint64_t v3 = v8;
      }
      while (v8 != v7);
    }
    a1[1] = v7;
  }
}

uint64_t PressureBasedSubgraphIdentification::ClusterLayersInHighPressureRegion(void *a1, uint64_t *a2, uint64_t *a3)
{
  uint64_t v3 = a3;
  if (!*(unsigned char *)(a1[8] + 8))
  {
    uint64_t v8 = a1[1];
    if (*(void *)(v8 + 360) == *(void *)(v8 + 352)) {
      ZinAssertImpl("Must run scheduler first");
    }
    memset(v89, 0, sizeof(v89));
    int v90 = 1065353216;
    uint64_t v10 = *a2;
    uint64_t v9 = a2[1];
    if (*a2 >= v9) {
      return std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v89);
    }
    while (1)
    {
      v79[0] = 0;
      v79[1] = 0;
      v81[0] = 0;
      v81[1] = 0;
      uint64_t v78 = v79;
      char v80 = v81;
      v82[0] = v82;
      v82[1] = v82;
      v84[0] = 0;
      v84[1] = 0;
      v82[2] = 0;
      uint64_t v83 = v84;
      memset(v85, 0, sizeof(v85));
      v87[0] = 0;
      v87[1] = 0;
      int v86 = v87;
      char v88 = 0;
      v77[0] = 0;
      v77[1] = 0;
      int v76 = (uint64_t *)v77;
      int64x2_t v74 = 0;
      uint64_t v75 = 0;
      int64x2_t v73 = (uint64_t *)&v74;
      v72[0] = 0;
      v72[1] = 0;
      long long v71 = (uint64_t *)v72;
      if (v10 > v9) {
        goto LABEL_96;
      }
      uint64_t v62 = v10;
      while (2)
      {
        long long v70 = 0;
        uint64_t v11 = *(ZinIrOpLayer **)(*(void *)(v8 + 352) + 8 * v10);
        long long v70 = v11;
        if (*(_DWORD *)(*((void *)v11 + 8) + 8) != 7) {
          goto LABEL_21;
        }
        uint64_t v12 = *(void *)a1[8];
        if ((v12 & 0x1000000) != 0)
        {
          if (!ZinConcatLayer::IsSplittable((uint64_t)v11, 0)) {
            goto LABEL_95;
          }
          if ((v12 & 0x10000) != 0) {
            goto LABEL_21;
          }
        }
        else
        {
          BOOL IsSplittable = ZinConcatLayer::IsSplittable((uint64_t)v11, 3);
          if ((v12 & 0x10000) != 0)
          {
            if (((IsSplittable | ZinConcatLayer::IsSplittable((uint64_t)v11, 4)) & 1) == 0)
            {
LABEL_95:
              ++v10;
              break;
            }
            goto LABEL_21;
          }
          if (!IsSplittable) {
            goto LABEL_95;
          }
        }
        uint64_t v15 = (void **)*((void *)v11 + 11);
        uint64_t v14 = (void **)*((void *)v11 + 12);
        while (v15 != v14)
        {
          __p[0] = *v15;
          if (!std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)&v76, (ZinIrOpLayer **)__p))goto LABEL_95; {
          ++v15;
          }
        }
LABEL_21:
        if ((*(_DWORD *)(*((void *)v70 + 8) + 8) & 0xFFFFFFFC) == 0x1C
          || ((*(uint64_t (**)(ZinIrOpLayer *))(*(void *)v70 + 112))(v70) & 1) != 0)
        {
          goto LABEL_92;
        }
        uint64_t v16 = v3;
        memset(__p, 0, sizeof(__p));
        (*(void (**)(void *__return_ptr, void *, ZinIrOpLayer *, uint64_t, void, void **, void ***))(*a1 + 112))(v67, a1, v70, 1, 0, __p, &v78);
        uint64_t v64 = v68;
        BOOL v17 = v68 != 0;
        BOOL v18 = (void *)*((void *)v70 + 11);
        unint64_t v19 = (void *)*((void *)v70 + 12);
        while (v18 != v19)
        {
          *(void *)&long long v65 = *v18;
          if (std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)&v76, (ZinIrOpLayer **)&v65))
          {
            goto LABEL_28;
          }
          ++v18;
        }
        if (!v64)
        {
          char v41 = 0;
          uint64_t v3 = v16;
          goto LABEL_89;
        }
LABEL_28:
        if (*(unsigned char *)(a1[8] + 2)) {
          unsigned int v63 = 0;
        }
        else {
          unsigned int v63 = (*(uint64_t (**)(void *, ZinIrOpLayer *))(*a1 + 104))(a1, v70);
        }
        uint64_t v20 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(v89, &v70);
        uint64_t v21 = *(void *)((*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)v70 + 32))(v70, 0, 0)+ 104);
        if (v21) {
          LODWORD(v21) = *(_DWORD *)(v21 + 96);
        }
        int v22 = v21;
        LOBYTE(v60) = v17;
        int v23 = (*(uint64_t (**)(void *, uint64_t **, uint64_t, uint64_t, void, BOOL, ZinIrOpLayer *, uint64_t, int, void ***))(*a1 + 96))(a1, &v76, v62, v10, v63, v21 == 1, v70, 1, v60, &v78);
        uint64_t v24 = (unint64_t *)*((void *)v70 + 11);
        long long v25 = (unint64_t *)*((void *)v70 + 12);
        if (v24 == v25)
        {
LABEL_41:
          if (!std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(v89, &v70))
          {
            std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>(&v76, &v70, (uint64_t *)&v70);
            std::__hash_table<ZinIrTensor const*,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const* const&>((uint64_t)v89, &v70, &v70);
            if (v64) {
              std::__tree<ZinIrTensor *>::__emplace_unique_key_args<ZinIrTensor *,ZinIrTensor * const&>(&v71, (unint64_t *)&v70, (uint64_t *)&v70);
            }
          }
          if (v23)
          {
            BOOL v29 = 0;
            long long v66 = 0;
            char v30 = v63;
            if (!v64) {
              char v30 = 1;
            }
            if ((v30 & 1) != 0 || v20)
            {
              uint64_t v3 = a3;
            }
            else
            {
              BOOL v31 = v22 == 1;
              uint64_t v3 = a3;
              if (!v31)
              {
                if ((*(uint64_t (**)(void *, ZinIrOpLayer *))(*a1 + 24))(a1, v70)) {
                  BOOL v29 = 0;
                }
                else {
                  BOOL v29 = !(*(unsigned int (**)(void *, ZinIrOpLayer *, ZinIrOpLayer **))(*a1 + 40))(a1, v70, &v66)|| (v46 = (PressureBasedSubgraphIdentification *)std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>((uint64_t)&v76, &v66), v77 != (void **)v46)|| PressureBasedSubgraphIdentification::NeedKernelSplitting(v46, v66);
                }
              }
            }
            *(void *)&long long v65 = v70;
            BYTE8(v65) = v29;
            std::__tree<std::__value_type<ZinConcatLayer *,ZinConcatLayer *>,std::__map_value_compare<ZinConcatLayer *,std::__value_type<ZinConcatLayer *,ZinConcatLayer *>,std::less<ZinConcatLayer *>,true>,std::allocator<std::__value_type<ZinConcatLayer *,ZinConcatLayer *>>>::__emplace_unique_key_args<ZinConcatLayer *,std::pair<ZinConcatLayer * const,ZinConcatLayer *>>(&v73, (unint64_t *)&v65, &v65);
            char v41 = 0;
          }
          else
          {
            char v41 = 0;
            uint64_t v3 = a3;
          }
          goto LABEL_89;
        }
        while (!v74)
        {
LABEL_40:
          if (++v24 == v25) {
            goto LABEL_41;
          }
        }
        unint64_t v26 = *v24;
        char v27 = v74;
        while (1)
        {
          unint64_t v28 = v27[4];
          if (v28 <= v26) {
            break;
          }
LABEL_39:
          char v27 = (void *)*v27;
          if (!v27) {
            goto LABEL_40;
          }
        }
        if (v28 < v26)
        {
          ++v27;
          goto LABEL_39;
        }
        long long v32 = v73;
        if (v73 == (uint64_t *)&v74)
        {
          uint64_t v33 = 0;
          uint64_t v3 = a3;
        }
        else
        {
          uint64_t v33 = 0;
          uint64_t v3 = a3;
          do
          {
            uint64_t v34 = (ZinIrOpLayer **)(v32 + 4);
            int v35 = *(ZinIrOpLayer ***)(v8 + 352);
            long long v36 = *(ZinIrOpLayer ***)(v8 + 360);
            if (v35 == v36)
            {
              uint64_t v37 = *(ZinIrOpLayer ***)(v8 + 352);
            }
            else
            {
              uint64_t v37 = *(ZinIrOpLayer ***)(v8 + 352);
              while (*v37 != *v34)
              {
                if (++v37 == v36)
                {
                  uint64_t v37 = *(ZinIrOpLayer ***)(v8 + 360);
                  break;
                }
              }
            }
            uint64_t v38 = v37 - v35;
            if (v33 <= v38) {
              uint64_t v33 = v38;
            }
            if (!*((unsigned char *)v32 + 40))
            {
              std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__erase_unique<ZinIrOpLayer *>(&v76, v34);
              std::__hash_table<std::__hash_value_type<ZinIrOpLayer *,long>,std::__unordered_map_hasher<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,long>,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,true>,std::__unordered_map_equal<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,long>,std::equal_to<ZinIrOpLayer *>,std::hash<ZinIrOpLayer *>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer *,long>>>::__erase_unique<ZinIrOpLayer *>(v89, &v70);
            }
            uint64_t v39 = (uint64_t *)v32[1];
            if (v39)
            {
              do
              {
                int v40 = v39;
                uint64_t v39 = (uint64_t *)*v39;
              }
              while (v39);
            }
            else
            {
              do
              {
                int v40 = (uint64_t *)v32[2];
                BOOL v31 = *v40 == (void)v32;
                long long v32 = v40;
              }
              while (!v31);
            }
            long long v32 = v40;
          }
          while (v40 != (uint64_t *)&v74);
        }
        uint64_t v10 = v33 + 1;
        uint64_t v42 = v76;
        if (v76 != (uint64_t *)v77)
        {
          do
          {
            uint64_t v43 = *(void *)(v42[4] + 48);
            if (v43 > v33) {
              uint64_t v10 = v43 + 1;
            }
            uint64_t v44 = (uint64_t *)v42[1];
            if (v44)
            {
              do
              {
                uint64_t v45 = v44;
                uint64_t v44 = (uint64_t *)*v44;
              }
              while (v44);
            }
            else
            {
              do
              {
                uint64_t v45 = (uint64_t *)v42[2];
                BOOL v31 = *v45 == (void)v42;
                uint64_t v42 = v45;
              }
              while (!v31);
            }
            uint64_t v42 = v45;
          }
          while (v45 != (uint64_t *)v77);
        }
        std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v73, v74);
        int64x2_t v74 = 0;
        uint64_t v75 = 0;
        char v41 = 1;
        int64x2_t v73 = (uint64_t *)&v74;
LABEL_89:
        std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v67, (void *)v67[1]);
        if (__p[0]) {
          operator delete(__p[0]);
        }
        if ((v41 & 1) == 0)
        {
LABEL_92:
          if (v10++ >= a2[1]) {
            break;
          }
          continue;
        }
        break;
      }
LABEL_96:
      uint64_t v48 = v71;
      if (v71 != (uint64_t *)v72)
      {
        do
        {
          PressureBasedSubgraphIdentification::IncludeConsumersOfL2TensorInCluster((uint64_t)a1, (uint64_t)a2, v48[4], v89, (ZinIrOpLayer ***)&v76, (SplitPatternHandlerMgr *)a1[25]);
          unint64_t v49 = (uint64_t *)v48[1];
          if (v49)
          {
            do
            {
              uint64_t v50 = v49;
              unint64_t v49 = (uint64_t *)*v49;
            }
            while (v49);
          }
          else
          {
            do
            {
              uint64_t v50 = (uint64_t *)v48[2];
              BOOL v31 = *v50 == (void)v48;
              uint64_t v48 = v50;
            }
            while (!v31);
          }
          uint64_t v48 = v50;
        }
        while (v50 != (uint64_t *)v72);
      }
      if (v75)
      {
        unint64_t v51 = v73;
        if (v73 == (uint64_t *)&v74)
        {
          uint64_t v52 = 0;
        }
        else
        {
          uint64_t v52 = 0;
          do
          {
            uint64_t v53 = (ZinIrOpLayer **)(v51 + 4);
            uint64_t v54 = *(ZinIrOpLayer ***)(v8 + 352);
            long long v55 = *(ZinIrOpLayer ***)(v8 + 360);
            if (v54 == v55)
            {
              char v56 = *(ZinIrOpLayer ***)(v8 + 352);
            }
            else
            {
              char v56 = *(ZinIrOpLayer ***)(v8 + 352);
              while (*v56 != *v53)
              {
                if (++v56 == v55)
                {
                  char v56 = *(ZinIrOpLayer ***)(v8 + 360);
                  break;
                }
              }
            }
            uint64_t v57 = v56 - v54;
            if (v52 <= v57) {
              uint64_t v52 = v57;
            }
            if (!*((unsigned char *)v51 + 40)) {
              std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__erase_unique<ZinIrOpLayer *>(&v76, v53);
            }
            uint64_t v58 = (uint64_t *)v51[1];
            if (v58)
            {
              do
              {
                uint64_t v59 = v58;
                uint64_t v58 = (uint64_t *)*v58;
              }
              while (v58);
            }
            else
            {
              do
              {
                uint64_t v59 = (uint64_t *)v51[2];
                BOOL v31 = *v59 == (void)v51;
                unint64_t v51 = v59;
              }
              while (!v31);
            }
            unint64_t v51 = v59;
          }
          while (v59 != (uint64_t *)&v74);
        }
        uint64_t v10 = v52 + 1;
        std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v73, v74);
        int64x2_t v74 = 0;
        uint64_t v75 = 0;
        int64x2_t v73 = (uint64_t *)&v74;
      }
      IdentifyConnectedComponents(&v76, v3);
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v71, v72[0]);
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v73, v74);
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v76, v77[0]);
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v86, v87[0]);
      int v76 = (uint64_t *)v85;
      std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v76);
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v83, v84[0]);
      std::__list_imp<ZinIrSection *>::clear(v82);
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v80, v81[0]);
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v78, v79[0]);
      uint64_t v9 = a2[1];
      if (v10 >= v9) {
        return std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v89);
      }
    }
  }
  unint64_t v6 = *(uint64_t (**)(void))(*a1 + 72);

  return v6();
}

void sub_211283A00(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,char a28,void *a29,uint64_t a30,void *__p,uint64_t a32,uint64_t a33,uint64_t a34,char a35,void *a36,uint64_t a37,char a38,void *a39,uint64_t a40,char a41,void *a42,uint64_t a43,char a44)
{
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&a28, a29);
  if (__p) {
    operator delete(__p);
  }
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&a35, a36);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&a38, a39);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&a41, a42);
  Subgraph::~Subgraph((Subgraph *)&a44);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table(v44 - 128);
  _Unwind_Resume(a1);
}

void PressureBasedSubgraphIdentification::CutClustersAtConcatWithPartialInputs(uint64_t a1, uint64_t a2)
{
  if (!*(unsigned char *)(*(void *)(a1 + 64) + 2))
  {
    uint64_t v10 = 0;
    uint64_t v11 = 0;
    uint64_t v12 = 0;
    uint64_t v3 = *(ZinIrOpLayer ****)a2;
    unint64_t v4 = *(ZinIrOpLayer ****)(a2 + 8);
    if (*(ZinIrOpLayer ****)a2 != v4)
    {
      do
      {
        std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::set[abi:ne180100]((uint64_t *)v9, v3);
        unint64_t v6 = 0;
        uint64_t v7 = 0;
        uint64_t v8 = 0;
        PressureBasedSubgraphIdentification::CutClusterAtConcatWithPartialInputs(a1, v9, (uint64_t)&v6);
        std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::__insert_with_size[abi:ne180100]<std::__wrap_iter<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>,std::__wrap_iter<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>>((uint64_t *)&v10, v11, v6, v7, 0xAAAAAAAAAAAAAAABLL * (v7 - v6));
        unint64_t v13 = &v6;
        std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v13);
        std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v9, v9[1]);
        v3 += 3;
      }
      while (v3 != v4);
    }
    if (&v10 != (ZinIrOpLayer ****)a2) {
      std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::__assign_with_size[abi:ne180100]<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>(a2, v10, (ZinIrOpLayer ***)v11, 0xAAAAAAAAAAAAAAABLL * (((char *)v11 - (char *)v10) >> 3));
    }
    v9[0] = (void **)&v10;
    std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100](v9);
  }
}

void sub_211283B9C(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, void **a12, uint64_t a13, uint64_t a14, char a15)
{
  a12 = (void **)&a15;
  std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100](&a12);
  _Unwind_Resume(a1);
}

void PressureBasedSubgraphIdentification::CutClustersAtPartialOutputs(uint64_t a1, ZinIrOpLayer ****a2, uint64_t a3)
{
  uint64_t v7 = *(void *)a3;
  uint64_t v6 = *(void *)(a3 + 8);
  if (v6 != *(void *)a3)
  {
    do
    {
      uint64_t v8 = v6 - 24;
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy(v6 - 24, *(void **)(v6 - 16));
      uint64_t v6 = v8;
    }
    while (v8 != v7);
  }
  *(void *)(a3 + 8) = v7;
  uint64_t v9 = *a2;
  for (uint64_t i = a2[1]; v9 != i; v9 += 3)
  {
    std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::set[abi:ne180100]((uint64_t *)v15, v9);
    long long v13 = 0uLL;
    uint64_t v14 = 0;
    PressureBasedSubgraphIdentification::CutClusterAtPartialOutputs(a1, v15, (uint64_t)&v13);
    PressureBasedSubgraphIdentification::CutDisconnectedClusters((ZinIrOpLayer ****)&v13, (uint64_t)&v11);
    std::vector<std::map<ZinIrDimension,unsigned long>>::__vdeallocate((void **)&v13);
    long long v13 = v11;
    uint64_t v14 = v12;
    uint64_t v12 = 0;
    long long v11 = 0uLL;
    uint64_t v16 = (void **)&v11;
    std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100](&v16);
    std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::__insert_with_size[abi:ne180100]<std::__wrap_iter<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>,std::__wrap_iter<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>>((uint64_t *)a3, *(uint64_t ***)(a3 + 8), (ZinIrOpLayer ***)v13, *((ZinIrOpLayer ****)&v13 + 1), 0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*((void *)&v13 + 1) - v13) >> 3));
    *(void *)&long long v11 = &v13;
    std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v11);
    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v15, v15[1]);
  }
}

void sub_211283D10(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, void **a9, uint64_t a10, uint64_t a11, uint64_t a12, char a13, uint64_t a14, uint64_t a15, uint64_t a16, char a17, void *a18)
{
  a9 = (void **)&a13;
  std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100](&a9);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&a17, a18);
  _Unwind_Resume(a1);
}

void PressureBasedSubgraphIdentification::RemoveInputAndOutputNoopsOfClusters(void *a1@<X0>, ZinIrOpLayer ****a2@<X1>, uint64_t *a3@<X8>)
{
  *a3 = 0;
  a3[1] = 0;
  a3[2] = 0;
  uint64_t v3 = *a2;
  unint64_t v4 = a2[1];
  if (*a2 != v4)
  {
    do
    {
      std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::set[abi:ne180100]((uint64_t *)v8, v3);
      PressureBasedSubgraphIdentification::RemoveInputAndOutputNoopsOfCluster(a1, v8, (uint64_t *)v7);
      std::__unwrap_and_dispatch[abi:ne180100]<std::__overload<std::__move_loop<std::_ClassicAlgPolicy>,std::__move_trivial>,std::__wrap_iter<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> *>,std::__wrap_iter<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> *>,std::back_insert_iterator<std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>>,0>(v7[0], v7[1], a3);
      uint64_t v9 = (void **)v7;
      std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100](&v9);
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v8, v8[1]);
      v3 += 3;
    }
    while (v3 != v4);
  }
}

void sub_211283DE0(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, char a10, uint64_t a11, uint64_t a12, void **a13, void *a14, uint64_t a15, void **a16)
{
  a16 = (void **)&a10;
  std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100](&a16);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&a13, a14);
  std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100](&a13);
  _Unwind_Resume(a1);
}

void PressureBasedSubgraphIdentification::CutClustersForRingBufferWriters(uint64_t a1@<X0>, ZinIrOpLayer ****a2@<X1>, uint64_t *a3@<X8>)
{
  *a3 = 0;
  a3[1] = 0;
  a3[2] = 0;
  uint64_t v3 = *a2;
  unint64_t v4 = a2[1];
  if (*a2 != v4)
  {
    do
    {
      std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::set[abi:ne180100](v8, v3);
      (*(void (**)(void **__return_ptr, uint64_t, uint64_t *))(*(void *)a1 + 80))(v7, a1, v8);
      std::__unwrap_and_dispatch[abi:ne180100]<std::__overload<std::__move_loop<std::_ClassicAlgPolicy>,std::__move_trivial>,std::__wrap_iter<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> *>,std::__wrap_iter<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> *>,std::back_insert_iterator<std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>>,0>(v7[0], v7[1], a3);
      uint64_t v9 = (void **)v7;
      std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100](&v9);
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v8, (void *)v8[1]);
      v3 += 3;
    }
    while (v3 != v4);
  }
}

void sub_211283EE4(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, char a10, uint64_t a11, uint64_t a12, void **a13, void *a14, uint64_t a15, void **a16)
{
  a16 = (void **)&a10;
  std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100](&a16);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&a13, a14);
  std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100](&a13);
  _Unwind_Resume(a1);
}

void PressureBasedSubgraphIdentification::RemoveClusterOnlyHasChainPair(uint64_t a1, ZinIrOpLayer ****a2, ZinIrOpLayer ****a3)
{
  if (!*(unsigned char *)(*(void *)(a1 + 64) + 2))
  {
    BOOL v29 = 0;
    char v30 = 0;
    unint64_t v31 = 0;
    uint64_t v3 = *a2;
    unint64_t v4 = a2[1];
    if (*a2 != v4)
    {
      uint64_t v24 = a2[1];
      do
      {
        std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::set[abi:ne180100]((uint64_t *)&v27, v3);
        uint64_t v6 = v27;
        BOOL v7 = v28[1] > (void *)3 || v27 == (ZinIrOpLayer **)v28;
        if (v7) {
          goto LABEL_25;
        }
        long long v25 = v3;
        char v8 = 0;
        unint64_t v9 = 0;
        do
        {
          uint64_t v10 = v6[4];
          long long v11 = (ZinIrTensor *)(*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)v10 + 32))(v10, 0, 0);
          uint64_t v12 = (void **)*((void *)v10 + 14);
          long long v13 = (void **)*((void *)v10 + 15);
          if (v12 == v13) {
            goto LABEL_13;
          }
          char v14 = 1;
          do
          {
            __p[0] = 0;
            __p[0] = *v12;
            v14 &= std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)&v27, (ZinIrOpLayer **)__p) != 0;
            ++v12;
          }
          while (v12 != v13);
          if (v14)
          {
LABEL_13:
            uint64_t v15 = (ZinIrRegAllocUtil *)(*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)v10 + 32))(v10, 0, 0);
            if (v8 & 1 | ((ZinIrRegAllocUtil::IsChainable(v15, **(const ZinIrTensor ***)(a1 + 16), v16) & 1) == 0))
            {
              DimensionOrderHint::DimensionOrderHint(__p, 0);
              ZinIrTensor::GetTensorSizeInBytesFromResidency(v11, 1, (uint64_t)__p, 0);
              ChainBufferuint64_t Size = v17;
              if (__p[0])
              {
                __p[1] = __p[0];
                operator delete(__p[0]);
              }
            }
            else
            {
              ChainBufferuint64_t Size = ZinL2FootprintCalculator::GetChainBufferSize(*(const ZinIrTensor ***)(a1 + 224), (ZinIrRegAllocUtil **)v11);
              char v8 = 1;
            }
            v9 += ChainBufferSize;
          }
          unint64_t v19 = v6[1];
          if (v19)
          {
            do
            {
              uint64_t v20 = (ZinIrOpLayer ***)v19;
              unint64_t v19 = *(ZinIrOpLayer **)v19;
            }
            while (v19);
          }
          else
          {
            do
            {
              uint64_t v20 = (ZinIrOpLayer ***)v6[2];
              BOOL v7 = *v20 == v6;
              uint64_t v6 = (ZinIrOpLayer **)v20;
            }
            while (!v7);
          }
          uint64_t v6 = (ZinIrOpLayer **)v20;
        }
        while (v20 != v28);
        unint64_t v4 = v24;
        uint64_t v3 = v25;
        if (((v9 <= *(void *)(**(void **)(a1 + 16) + 408)) & v8) == 0)
        {
LABEL_25:
          uint64_t v21 = v30;
          if ((unint64_t)v30 >= v31)
          {
            int v22 = (uint64_t *)std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::__push_back_slow_path<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const&>((uint64_t *)&v29, &v27);
          }
          else
          {
            std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::set[abi:ne180100](v30, &v27);
            int v22 = v21 + 3;
          }
          char v30 = v22;
        }
        std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v27, v28[0]);
        v3 += 3;
      }
      while (v3 != v4);
    }
    if (&v29 != a3) {
      std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::__assign_with_size[abi:ne180100]<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>((uint64_t)a3, v29, (ZinIrOpLayer ***)v30, 0xAAAAAAAAAAAAAAABLL * (((char *)v30 - (char *)v29) >> 3));
    }
    __p[0] = &v29;
    std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100]((void ***)__p);
  }
}

void sub_2112841B4(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, char *__p, uint64_t a14, uint64_t a15, uint64_t a16, char a17, uint64_t a18, uint64_t a19, char a20,uint64_t a21)
{
  long long __p = &a20;
  std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100]((void ***)&__p);
  _Unwind_Resume(a1);
}

uint64_t PressureBasedSubgraphIdentification::ConstructSubGraphs(uint64_t result, ZinIrOpLayerGraph *a2, uint64_t *a3, uint64_t *a4, _DWORD *a5)
{
  *a5 = 0;
  uint64_t v5 = *a3;
  if (a3[1] != *a3)
  {
    uint64_t v10 = result;
    uint64_t v11 = 0;
    unint64_t v12 = 0;
    while (1)
    {
      double result = PressureBasedSubgraphIdentification::ConstructValidSubgraphsFromCluster(v10, a2, (void *)(v5 + v11), a4, 0);
      if (result) {
        break;
      }
      ++v12;
      uint64_t v5 = *a3;
      v11 += 24;
      if (v12 >= 0xAAAAAAAAAAAAAAABLL * ((a3[1] - *a3) >> 3)) {
        return result;
      }
    }
    *a5 = 1;
  }
  return result;
}

BOOL PressureBasedSubgraphIdentification::IsHighPressureLongLiverangeNode(PressureBasedSubgraphIdentification *this, uint64_t **a2)
{
  BOOL result = ZinIrOpLayer::IsANELayer((ZinIrOpLayer *)a2);
  if (!result) {
    return result;
  }
  uint64_t v5 = a2[11];
  uint64_t v6 = (char *)a2[12] - (char *)v5;
  if ((unint64_t)v6 < 9)
  {
    BOOL v13 = 0;
  }
  else
  {
    unint64_t v7 = v6 >> 3;
    uint64_t v10 = *v5;
    char v8 = v5 + 1;
    uint64_t v9 = v10;
    if (v7 <= 2) {
      unint64_t v7 = 2;
    }
    unint64_t v11 = v7 - 2;
    do
    {
      uint64_t v12 = *v8++;
      BOOL v13 = v9 != v12;
    }
    while (v9 == v12 && v11-- != 0);
  }
  ZinIrCompilerParameters::getSpatialSplitMode(*(ZinIrCompilerParameters **)(*((void *)this + 2) + 8), __p);
  unint64_t v15 = v35;
  if ((v35 & 0x80u) != 0) {
    unint64_t v15 = (unint64_t)__p[1];
  }
  if (v15 != 15
    || ((v35 & 0x80u) == 0 ? (uint64_t v16 = __p) : (uint64_t v16 = (void **)__p[0]),
        (uint64_t v17 = *v16, v18 = *(uint64_t *)((char *)v16 + 7), v17 == (void *)0x2D636972656E6567)
      ? (BOOL v19 = v18 == 0x7078652D6761642DLL)
      : (BOOL v19 = 0),
        !v19))
  {
    if ((char)v35 < 0) {
      operator delete(__p[0]);
    }
LABEL_28:
    uint64_t v21 = (unsigned char *)*((void *)this + 8);
    if (*v21 || v21[1]) {
      return 0;
    }
    if (v13)
    {
      BOOL v22 = 1;
    }
    else
    {
      BOOL v29 = a2[11];
      char v30 = a2[12];
      if (v29 == v30)
      {
        BOOL v22 = 0;
      }
      else
      {
        unint64_t v31 = v29 + 1;
        do
        {
          BOOL v22 = *(_DWORD *)(*(void *)(*(v31 - 1) + 64) + 8) == 7;
          BOOL v32 = *(_DWORD *)(*(void *)(*(v31 - 1) + 64) + 8) == 7 || v31 == v30;
          ++v31;
        }
        while (!v32);
      }
    }
    return (unint64_t)((char *)a2[15] - (char *)a2[14]) > 8 && v22;
  }
  int v20 = *(unsigned __int8 *)(*((void *)this + 8) + 8);
  if ((char)v35 < 0) {
    operator delete(__p[0]);
  }
  if (v20) {
    goto LABEL_28;
  }
  int v23 = (ZinIrTensor *)((uint64_t (*)(uint64_t **, void, void))(*a2)[4])(a2, 0, 0);
  RootTensor = ZinIrTensor::GetRootTensor(v23);
  __p[0] = &RootTensor;
  uint64_t v24 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>>>::__emplace_unique_key_args<ZinIrTensor *,std::piecewise_construct_t const&,std::tuple<ZinIrTensor * const&>,std::tuple<>>((uint64_t)this + 24, &RootTensor, (uint64_t)&std::piecewise_construct, (void **)__p);
  uint64_t v25 = *((void *)this + 1);
  if (*(void *)(v25 + 360) == *(void *)(v25 + 352)) {
    ZinAssertImpl("Must run scheduler first");
  }
  unint64_t v26 = v24;
  char v27 = a2[6];
  if ((uint64_t)v27 >= v24[4])
  {
    uint64_t v28 = 0;
  }
  else
  {
    LODWORD(v28) = 0;
    do
    {
      uint64_t v28 = (v28 + ZinIrOpLayer::IsANELayer(*(ZinIrOpLayer **)(*(void *)(v25 + 352) + 8 * (void)v27)));
      char v27 = (uint64_t *)((char *)v27 + 1);
    }
    while ((uint64_t)v27 < v26[4]);
  }
  return *((void *)this + 26) < v28;
}

uint64_t PressureBasedSubgraphIdentification::IsStillHighPressureAfterRemovingDRAMSIP(PressureBasedSubgraphIdentification *this, unint64_t a2, unint64_t a3)
{
  v23[0] = a3;
  v23[1] = a3;
  v21[0] = 0;
  v21[1] = 0;
  char v22 = 0;
  int v20 = v21;
  unint64_t PeakPressure = ZinIrMemoryPressureAnalyzer::GetPeakPressure((uint64_t)this + 128, v23, (uint64_t)&v20);
  unint64_t v7 = v20;
  if (v20 == v21)
  {
    char v18 = 0;
  }
  else
  {
    char v18 = 0;
    do
    {
      char v8 = (ZinIrTensor **)v7[4];
      if (!(*((unsigned int (**)(ZinIrTensor **))*v8 + 3))(v8))
      {
        BOOL v19 = v8[4];
        uint64_t v24 = &v19;
        if (std::__hash_table<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>>>::__emplace_unique_key_args<ZinIrTensor *,std::piecewise_construct_t const&,std::tuple<ZinIrTensor * const&>,std::tuple<>>((uint64_t)this + 24, &v19, (uint64_t)&std::piecewise_construct, &v24)[3] < a2)
        {
          uint64_t v9 = *((void *)v19 + 12);
          if ((*(void *)(v9 + 48) > a3 || *(_DWORD *)(*(void *)(v9 + 64) + 8) != 7)
            && ZinMirSpatialSplitUtils::IsNonResident(v19, *((void **)this + 14)))
          {
            if ((*(_DWORD *)(*(void *)(v9 + 64) + 8) & 0xFFFFFFFC) == 0x1C) {
              uint64_t v10 = 0;
            }
            else {
              PressureBasedSubgraphIdentification::GetTensorSize(this, v19);
            }
            PeakPressure -= v10;
            char v18 = 1;
          }
        }
      }
      unint64_t v11 = (void *)v7[1];
      if (v11)
      {
        do
        {
          uint64_t v12 = (void **)v11;
          unint64_t v11 = (void *)*v11;
        }
        while (v11);
      }
      else
      {
        do
        {
          uint64_t v12 = (void **)v7[2];
          BOOL v13 = *v12 == v7;
          unint64_t v7 = v12;
        }
        while (!v13);
      }
      unint64_t v7 = v12;
    }
    while (v12 != v21);
  }
  BOOL v15 = a3 == a2 || PeakPressure > *((void *)this + 13);
  char v16 = v15 | ~v18;
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v20, v21[0]);
  return v16 & 1;
}

void sub_2112846F0(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, char a11, void *a12)
{
}

BOOL PressureBasedSubgraphIdentification::NeedKernelSplitting(PressureBasedSubgraphIdentification *this, const ZinIrOpLayer *a2)
{
  if (!ZinIrOpLayer::IsNELayer(a2)) {
    return 0;
  }
  BOOL v19 = (uint64_t *)*((void *)a2 + 2);
  v20[0] = v20;
  v20[1] = v20;
  v20[2] = 0;
  v10[40] = 0;
  v10[48] = 0;
  __int16 v11 = 0;
  char v12 = 0;
  v18[0] = 0;
  v18[1] = 0;
  char v14 = 0;
  uint64_t v15 = 0;
  long long __p = 0;
  __int16 v16 = 0;
  uint64_t v17 = v18;
  unsigned int v3 = *(_DWORD *)(ZinIrOpLayer::GetInputTensor(a2, 0) + 88);
  (*(void (**)(void *__return_ptr, const ZinIrOpLayer *))(*(void *)a2 + 392))(v9, a2);
  int v4 = ZinMirKernelSizeSplitterEngine::Analyze(&v19, (uint64_t)a2, v3, (uint64_t)v9, (uint64_t)v10);
  BOOL v5 = v4 == 0;
  if (v4)
  {
    BOOL v6 = 0;
  }
  else
  {
    BOOL v7 = v12 || HIBYTE(v11) == 0;
    BOOL v6 = v7;
  }
  std::__tree<std::__value_type<std::shared_ptr<ZinIrConstData>,std::vector<unsigned long>>,std::__map_value_compare<std::shared_ptr<ZinIrConstData>,std::__value_type<std::shared_ptr<ZinIrConstData>,std::vector<unsigned long>>,std::less<std::shared_ptr<ZinIrConstData>>,true>,std::allocator<std::__value_type<std::shared_ptr<ZinIrConstData>,std::vector<unsigned long>>>>::destroy((uint64_t)&v17, v18[0]);
  if (__p)
  {
    char v14 = __p;
    operator delete(__p);
  }
  std::__list_imp<ZinIrSection *>::clear(v20);
  if (v6) {
    return 0;
  }
  return v5;
}

void sub_211284850(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, ...)
{
  va_start(va, a7);
  ZinMirKernelSizeSplitterEngine::Analysis::~Analysis((ZinMirKernelSizeSplitterEngine::Analysis *)va);
  std::__list_imp<ZinIrSection *>::clear(v7);
  _Unwind_Resume(a1);
}

BOOL PressureBasedSubgraphIdentification::IsKernelDominant(PressureBasedSubgraphIdentification *this, const ZinIrOpLayer *a2)
{
  IsNEuint64_t Layer = ZinIrOpLayer::IsNELayer(a2);
  if (!IsNELayer) {
    return 0;
  }
  if (!PressureBasedSubgraphIdentification::NeedKernelSplitting((PressureBasedSubgraphIdentification *)IsNELayer, a2)) {
    return 0;
  }
  (*(void (**)(ZinIrKernel **__return_ptr, const ZinIrOpLayer *, uint64_t))(*(void *)a2 + 568))(&v31, a2, 1);
  if (!v31) {
    return 0;
  }
  uint64_t v4 = (*(uint64_t (**)(const ZinIrOpLayer *, void, void))(*(void *)a2 + 32))(a2, 0, 0);
  uint64_t v30 = 0;
  if (ZinTensorFormatGetSizeInBytes(*(_DWORD *)(v4 + 88), &v30)) {
    ZinAssertImpl("Error in getting tensor format size in bytes");
  }
  uint64_t v5 = *(void *)(v4 + 72);
  uint64_t v6 = *(void *)(v4 + 80);
  uint64_t v8 = *(void *)(v4 + 48);
  uint64_t v7 = *(void *)(v4 + 56);
  uint64_t v9 = *(void *)(v4 + 64);
  uint64_t v10 = v30;
  uint64_t v11 = (*(uint64_t (**)(void, void, void))(***((void ***)a2 + 11) + 32))(**((void **)a2 + 11), 0, 0);
  uint64_t v29 = 0;
  uint64_t v27 = v5;
  if (ZinTensorFormatGetSizeInBytes(*(_DWORD *)(v11 + 88), &v29)) {
    ZinAssertImpl("Error in getting tensor format size in bytes");
  }
  uint64_t v13 = *(void *)(v11 + 72);
  uint64_t v12 = *(void *)(v11 + 80);
  uint64_t v14 = *(void *)(v11 + 48);
  uint64_t v15 = *(void *)(v11 + 56);
  uint64_t v16 = *(void *)(v11 + 64);
  uint64_t v17 = v29;
  int WeightFormat = ZinIrKernel::GetWeightFormat(v31);
  ZinIrKernel::GetWeightDimensions(v31, (uint64_t)v28);
  unint64_t SerializedWeightElementCount = GetSerializedWeightElementCount(WeightFormat, v28, *((void *)v31 + 52));
  double v20 = (double)(v6 * v8 * v7 * v9 * v27) * (double)v10;
  double v21 = (double)(v12 * v14 * v15 * v16 * v13) * (double)v17;
  double v22 = ZinIrKernel::GetWeightElementSizeInBytes(v31) * (double)SerializedWeightElementCount;
  int v23 = v31;
  uint64_t v24 = *((void *)v31 + 73);
  if (!v24)
  {
    BOOL v25 = v22 >= (v20 + v21) * 0.5;
    unint64_t v31 = 0;
LABEL_14:
    ZinIrKernel::~ZinIrKernel(v23);
    MEMORY[0x21667D3C0]();
    return v25;
  }
  if ((*(unsigned int (**)(void))(**(void **)(v24 + 136) + 184))(*(void *)(v24 + 136))) {
    double v22 = v22 * (1.0 - ZinIrKernel::CalculateSparsityFromWeightScan(v31, 0.14286));
  }
  int v23 = v31;
  BOOL v25 = v22 >= (v20 + v21) * 0.5;
  unint64_t v31 = 0;
  if (v23) {
    goto LABEL_14;
  }
  return v25;
}

void sub_211284B2C(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, ...)
{
  va_start(va, a10);
  std::unique_ptr<ZinIrKernel>::reset[abi:ne180100]((ZinIrKernel **)va, 0);
  _Unwind_Resume(a1);
}

uint64_t PressureBasedSubgraphIdentification::IncludeConsumersOfL2TensorInClusterHelper(uint64_t a1, uint64_t a2, ZinIrOpLayer *a3, void *a4, uint64_t **a5, SplitPatternHandlerMgr *a6)
{
  uint64_t v53 = a3;
  uint64_t v12 = (void *)(a1 + 24);
  uint64_t v13 = (ZinIrTensor *)(*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)a3 + 32))(a3, 0, 0);
  RootTensor = ZinIrTensor::GetRootTensor(v13);
  uint64_t v14 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(v12, &RootTensor);
  if (v14) {
    unint64_t v15 = v14[4] - v14[3] + 1;
  }
  else {
    unint64_t v15 = 0;
  }
  uint64_t v16 = *(void *)((*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)a3 + 32))(a3, 0, 0)
                  + 104);
  if (v16) {
    LODWORD(v16) = *(_DWORD *)(v16 + 96) == 1;
  }
  uint64_t v17 = 0;
  RootTensor = (ZinIrTensor *)v43;
  v43[0] = 0;
  v45[0] = 0;
  v45[1] = 0;
  v43[1] = 0;
  uint64_t v44 = v45;
  v46[2] = 0;
  uint64_t v47 = v48;
  uint64_t v50 = v51;
  v46[0] = v46;
  v46[1] = v46;
  v48[0] = 0;
  v48[1] = 0;
  memset(v49, 0, sizeof(v49));
  v51[0] = 0;
  v51[1] = 0;
  char v52 = 0;
  if (v16 && v15 <= 0x1F3)
  {
    uint64_t v38 = a4;
    char v18 = (ZinIrOpLayer **)*((void *)a3 + 14);
    BOOL v19 = (ZinIrOpLayer **)*((void *)a3 + 15);
    if (v18 == v19)
    {
LABEL_52:
      uint64_t v17 = 0;
    }
    else
    {
      do
      {
        double v20 = *v18;
        memset(__p, 0, sizeof(__p));
        IsLayerSplittable<Subgraph>(v20, **(void **)(a1 + 16), 1, 1, 1, 0, (uint64_t)__p, (uint64_t)&RootTensor, &v39, a6);
        if (!v40[0]) {
          goto LABEL_14;
        }
        double v21 = v40[0];
        do
        {
          double v22 = (void **)v21;
          double v21 = (void *)*v21;
        }
        while (v21);
        if (v22 == v40 || *((_DWORD *)v22 + 7)) {
LABEL_14:
        }
          double v22 = v40;
        BOOL v23 = v22 != v40;
        if (*(unsigned char *)(*(void *)(a1 + 64) + 9))
        {
          if (!v40[0]) {
            goto LABEL_26;
          }
          uint64_t v24 = v40;
          BOOL v25 = v40[0];
          do
          {
            unint64_t v26 = v25;
            uint64_t v27 = v24;
            int v28 = *((_DWORD *)v25 + 7);
            if (v28) {
              uint64_t v24 = (void **)v25;
            }
            else {
              ++v25;
            }
            BOOL v25 = (void *)*v25;
          }
          while (v25);
          if (v24 == v40) {
            goto LABEL_26;
          }
          if (!v28) {
            unint64_t v26 = v27;
          }
          if (*((_DWORD *)v26 + 7) >= 2u) {
LABEL_26:
          }
            uint64_t v24 = v40;
          BOOL v23 = v22 != v40 || v24 != v40;
        }
        std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v39, v40[0]);
        if (__p[0]) {
          operator delete(__p[0]);
        }
        if (!v23)
        {
          std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__erase_unique<ZinIrOpLayer *>(a5, &v53);
          unsigned __int8 v35 = (void **)*((void *)v53 + 14);
          long long v36 = (void **)*((void *)v53 + 15);
          while (v35 != v36)
          {
            __p[0] = *v35;
            std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__erase_unique<ZinIrOpLayer *>(a5, (ZinIrOpLayer **)__p);
            ++v35;
          }
          goto LABEL_52;
        }
        ++v18;
      }
      while (v18 != v19);
      uint64_t v30 = (void **)*((void *)a3 + 14);
      unint64_t v31 = (void **)*((void *)a3 + 15);
      if (v30 == v31) {
        goto LABEL_52;
      }
      uint64_t v17 = 0;
      do
      {
        __p[0] = *v30;
        if (*((void *)__p[0] + 6) <= *(void *)(a2 + 8)
          && !std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(v38, __p))
        {
          std::__hash_table<ZinIrTensor const*,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const* const&>((uint64_t)v38, __p, __p);
          std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>(a5, (ZinIrOpLayer **)__p, (uint64_t *)__p);
          uint64_t v32 = *((void *)__p[0] + 6);
          uint64_t v33 = PressureBasedSubgraphIdentification::IncludeConsumersOfL2TensorInClusterHelper(a1, a2);
          if (v17 <= v32) {
            uint64_t v34 = v32;
          }
          else {
            uint64_t v34 = v17;
          }
          if (v34 <= v33) {
            uint64_t v17 = v33;
          }
          else {
            uint64_t v17 = v34;
          }
        }
        ++v30;
      }
      while (v30 != v31);
    }
  }
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v50, v51[0]);
  __p[0] = v49;
  std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100]((void ***)__p);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v47, v48[0]);
  std::__list_imp<ZinIrSection *>::clear(v46);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v44, v45[0]);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&RootTensor, v43[0]);
  return v17;
}

void sub_211284EF0(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, void *__p, uint64_t a16, uint64_t a17, char a18)
{
}

uint64_t PressureBasedSubgraphIdentification::IsReachable(uint64_t a1, uint64_t a2, ZinIrOpLayer *a3)
{
  uint64_t v16 = a2;
  long long v15 = 0u;
  memset(v14, 0, sizeof(v14));
  v13[0] = 0;
  v13[1] = 0;
  uint64_t v12 = (uint64_t *)v13;
  std::deque<ZinIrOpLayer *>::push_back(v14, &v16);
  for (uint64_t i = *((void *)&v15 + 1); *((void *)&v15 + 1); uint64_t i = *((void *)&v15 + 1))
  {
    uint64_t v11 = 0;
    uint64_t v11 = *(ZinIrOpLayer **)(*(void *)(*((void *)&v14[0] + 1) + (((unint64_t)v15 >> 6) & 0x3FFFFFFFFFFFFF8))
                           + 8 * (v15 & 0x1FF));
    *(void *)&long long v15 = v15 + 1;
    *((void *)&v15 + 1) = i - 1;
    if ((unint64_t)v15 >= 0x400)
    {
      operator delete(**((void ***)&v14[0] + 1));
      *((void *)&v14[0] + 1) += 8;
      *(void *)&long long v15 = v15 - 512;
    }
    if (v13 == (void **)std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>((uint64_t)&v12, &v11))
    {
      std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>(&v12, &v11, (uint64_t *)&v11);
      if (v11 == a3)
      {
        uint64_t v8 = 1;
        goto LABEL_14;
      }
      uint64_t v6 = (ZinIrOpLayer **)*((void *)v11 + 14);
      uint64_t v7 = (ZinIrOpLayer **)*((void *)v11 + 15);
      while (v6 != v7)
      {
        uint64_t v10 = 0;
        uint64_t v10 = *v6;
        if (a1 + 8 != std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>(a1, &v10))std::deque<ZinIrOpLayer *>::push_back(v14, &v10); {
        ++v6;
        }
      }
    }
  }
  uint64_t v8 = 0;
LABEL_14:
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v12, v13[0]);
  std::deque<unsigned long>::~deque[abi:ne180100](v14);
  return v8;
}

void sub_211285090(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, ...)
{
  va_start(va1, a4);
  va_start(va, a4);
  uint64_t v5 = va_arg(va1, void);
  uint64_t v7 = va_arg(va1, void *);
  uint64_t v8 = va_arg(va1, void);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)va, v7);
  std::deque<unsigned long>::~deque[abi:ne180100]((uint64_t *)va1);
  _Unwind_Resume(a1);
}

void PressureBasedSubgraphIdentification::IncludeConsumersOfL2TensorInCluster(uint64_t a1, uint64_t a2, uint64_t a3, void *a4, ZinIrOpLayer ***a5, SplitPatternHandlerMgr *a6)
{
  long long __p = 0;
  unint64_t v49 = 0;
  uint64_t v50 = 0;
  std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(&__p, *(const void **)(a3 + 112), *(void *)(a3 + 120), (uint64_t)(*(void *)(a3 + 120) - *(void *)(a3 + 112)) >> 3);
  uint64_t v12 = (uint64_t **)__p;
  uint64_t v13 = v49;
  std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::set[abi:ne180100](&v46, a5);
  if (v12 == v13)
  {
LABEL_4:
    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v46, v47);
  }
  else
  {
    while (1)
    {
      uint64_t v44 = *v12;
      if (&v47 == (void **)std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>((uint64_t)&v46, (ZinIrOpLayer **)&v44))break; {
      if (++v12 == v13)
      }
        goto LABEL_4;
    }
    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v46, v47);
    uint64_t v14 = PressureBasedSubgraphIdentification::IncludeConsumersOfL2TensorInClusterHelper(a1, a2, (ZinIrOpLayer *)a3, a4, (uint64_t **)a5, a6);
    uint64_t v15 = *(void *)(a3 + 48);
    v45[0] = 0;
    v45[1] = 0;
    uint64_t v44 = (uint64_t *)v45;
    uint64_t v16 = a5 + 1;
    uint64_t v17 = *a5;
    if (*a5 != (ZinIrOpLayer **)(a5 + 1))
    {
      uint64_t v18 = v14;
      do
      {
        BOOL v19 = v17[4];
        double v20 = (ZinIrOpLayer **)*((void *)v19 + 14);
        double v21 = (ZinIrOpLayer **)*((void *)v19 + 15);
        while (v20 != v21)
        {
          uint64_t v43 = 0;
          uint64_t v43 = *v20;
          if (v16 == (ZinIrOpLayer ***)std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>((uint64_t)a5, &v43))
          {
            uint64_t v22 = *((void *)v43 + 6);
            if (v15 < v22 && v22 < v18) {
              std::__tree<ZinIrTensor *>::__emplace_unique_key_args<ZinIrTensor *,ZinIrTensor * const&>(&v44, (unint64_t *)&v43, (uint64_t *)&v43);
            }
          }
          ++v20;
        }
        uint64_t v24 = v17[1];
        if (v24)
        {
          do
          {
            BOOL v25 = (ZinIrOpLayer ***)v24;
            uint64_t v24 = *(ZinIrOpLayer **)v24;
          }
          while (v24);
        }
        else
        {
          do
          {
            BOOL v25 = (ZinIrOpLayer ***)v17[2];
            BOOL v26 = *v25 == v17;
            uint64_t v17 = (ZinIrOpLayer **)v25;
          }
          while (!v26);
        }
        uint64_t v17 = (ZinIrOpLayer **)v25;
      }
      while (v25 != v16);
      uint64_t v27 = v44;
      if (v44 != (uint64_t *)v45)
      {
        do
        {
          int v28 = (ZinIrOpLayer *)v27[4];
          ReacheableToCluster = FindReacheableToCluster(v28, (uint64_t)a5, v18);
          if (ReacheableToCluster)
          {
            uint64_t v30 = *((void *)ReacheableToCluster + 11);
            uint64_t v31 = *((void *)ReacheableToCluster + 12);
            while (v30 != v31)
            {
              uint64_t v32 = *(ZinIrOpLayer ***)(*(void *)v30 + 112);
              uint64_t v33 = *(ZinIrOpLayer ***)(*(void *)v30 + 120);
              while (v32 != v33)
              {
                uint64_t v43 = 0;
                uint64_t v43 = *v32;
                std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__erase_unique<ZinIrOpLayer *>((uint64_t **)a5, &v43);
                ++v32;
              }
              v30 += 8;
            }
            unsigned __int8 v35 = (ZinIrOpLayer **)*((void *)v28 + 11);
            uint64_t v34 = (ZinIrOpLayer **)*((void *)v28 + 12);
            while (v35 != v34)
            {
              uint64_t v43 = 0;
              uint64_t v43 = *v35;
              if (v16 != (ZinIrOpLayer ***)std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>((uint64_t)a5, &v43))
              {
                uint64_t v36 = *((void *)v43 + 11);
                uint64_t v37 = *((void *)v43 + 12);
                while (v36 != v37)
                {
                  uint64_t v39 = *(ZinIrOpLayer ***)(*(void *)v36 + 112);
                  uint64_t v38 = *(ZinIrOpLayer ***)(*(void *)v36 + 120);
                  while (v39 != v38)
                  {
                    uint64_t v42 = 0;
                    uint64_t v42 = *v39;
                    std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__erase_unique<ZinIrOpLayer *>((uint64_t **)a5, &v42);
                    ++v39;
                  }
                  v36 += 8;
                }
              }
              ++v35;
            }
          }
          int v40 = (uint64_t *)v27[1];
          if (v40)
          {
            do
            {
              char v41 = v40;
              int v40 = (uint64_t *)*v40;
            }
            while (v40);
          }
          else
          {
            do
            {
              char v41 = (uint64_t *)v27[2];
              BOOL v26 = *v41 == (void)v27;
              uint64_t v27 = v41;
            }
            while (!v26);
          }
          uint64_t v27 = v41;
        }
        while (v41 != (uint64_t *)v45);
      }
    }
    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v44, v45[0]);
  }
  if (__p)
  {
    unint64_t v49 = (uint64_t **)__p;
    operator delete(__p);
  }
}

void sub_2112853B0(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, char a12, uint64_t a13, uint64_t a14, char a15, uint64_t a16, uint64_t a17, void *__p, uint64_t a19)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

ZinIrOpLayer *FindReacheableToCluster(ZinIrOpLayer *a1, uint64_t a2, uint64_t a3)
{
  uint64_t v9 = a1;
  if (*((void *)a1 + 6) > a3) {
    return 0;
  }
  uint64_t v6 = std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>(a2, &v9);
  BOOL result = v9;
  if (a2 + 8 == v6)
  {
    uint64_t v7 = (void *)*((void *)v9 + 14);
    uint64_t v8 = (void *)*((void *)v9 + 15);
    while (v7 != v8)
    {
      BOOL result = (ZinIrOpLayer *)FindReacheableToCluster(*v7, a2, a3);
      if (result) {
        return result;
      }
      ++v7;
    }
    return 0;
  }
  return result;
}

uint64_t IdentifyConnectedComponents(void *a1, uint64_t *a2)
{
  memset(v53, 0, sizeof(v53));
  int v54 = 1065353216;
  memset(v51, 0, sizeof(v51));
  int v52 = 1065353216;
  unsigned int v3 = a1 + 1;
  uint64_t v2 = (void *)*a1;
  if ((void *)*a1 != a1 + 1)
  {
    uint64_t v6 = 0xAAAAAAAAAAAAAAABLL * ((a2[1] - *a2) >> 3);
    uint64_t v39 = a1 + 1;
    do
    {
      uint64_t v50 = (ZinIrOpLayer *)v2[4];
      if (!std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(v53, &v50))
      {
        int v40 = v2;
        uint64_t v7 = v50;
        uint64_t v8 = (char *)operator new(8uLL);
        *(void *)uint64_t v8 = v7;
        uint64_t v47 = v7;
        uint64_t v48 = (ZinIrOpLayer *)v6;
        std::__hash_table<std::__hash_value_type<ZinIrOpLayer *,unsigned long>,std::__unordered_map_hasher<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,unsigned long>,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,true>,std::__unordered_map_equal<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,unsigned long>,std::equal_to<ZinIrOpLayer *>,std::hash<ZinIrOpLayer *>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer *,unsigned long>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::pair<ZinIrOpLayer *,unsigned long>>((uint64_t)v53, &v47, &v47);
        IdentifyConnectedComponents(std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const&,std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>> &)::$_0::operator()(v6, v50, a2);
        uint64_t v9 = v8 + 8;
        uint64_t v43 = v8 + 8;
        do
        {
          char v41 = v9;
          uint64_t v42 = (ZinIrOpLayer *)v8;
          uint64_t v47 = 0;
          uint64_t v48 = 0;
          unint64_t v49 = 0;
          do
          {
            uint64_t v10 = *(void *)v8;
            uint64_t v11 = *(ZinIrOpLayer ***)(*(void *)v8 + 88);
            uint64_t v12 = *(ZinIrOpLayer ***)(*(void *)v8 + 96);
            while (v11 != v12)
            {
              uint64_t v46 = 0;
              uint64_t v46 = *v11;
              if (std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)a1, &v46)&& !std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(v53, &v46))
              {
                uint64_t v13 = v48;
                if (v48 >= (ZinIrOpLayer *)v49)
                {
                  uint64_t v15 = (v48 - v47) >> 3;
                  if ((unint64_t)(v15 + 1) >> 61) {
                    std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
                  }
                  unint64_t v16 = (v49 - (char *)v47) >> 2;
                  if (v16 <= v15 + 1) {
                    unint64_t v16 = v15 + 1;
                  }
                  if ((unint64_t)(v49 - (char *)v47) >= 0x7FFFFFFFFFFFFFF8) {
                    unint64_t v17 = 0x1FFFFFFFFFFFFFFFLL;
                  }
                  else {
                    unint64_t v17 = v16;
                  }
                  if (v17) {
                    uint64_t v18 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)&v49, v17);
                  }
                  else {
                    uint64_t v18 = 0;
                  }
                  BOOL v19 = &v18[8 * v15];
                  *(void *)BOOL v19 = v46;
                  uint64_t v14 = (ZinIrOpLayer *)(v19 + 8);
                  double v21 = v47;
                  double v20 = v48;
                  if (v48 != v47)
                  {
                    do
                    {
                      uint64_t v22 = *((void *)v20 - 1);
                      double v20 = (ZinIrOpLayer *)((char *)v20 - 8);
                      *((void *)v19 - 1) = v22;
                      v19 -= 8;
                    }
                    while (v20 != v21);
                    double v20 = v47;
                  }
                  uint64_t v47 = (ZinIrOpLayer *)v19;
                  uint64_t v48 = v14;
                  unint64_t v49 = &v18[8 * v17];
                  if (v20) {
                    operator delete(v20);
                  }
                }
                else
                {
                  *(void *)uint64_t v48 = v46;
                  uint64_t v14 = (ZinIrOpLayer *)((char *)v13 + 8);
                }
                uint64_t v48 = v14;
                uint64_t v44 = v46;
                uint64_t v45 = v6;
                std::__hash_table<std::__hash_value_type<ZinIrOpLayer *,unsigned long>,std::__unordered_map_hasher<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,unsigned long>,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,true>,std::__unordered_map_equal<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,unsigned long>,std::equal_to<ZinIrOpLayer *>,std::hash<ZinIrOpLayer *>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer *,unsigned long>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::pair<ZinIrOpLayer *,unsigned long>>((uint64_t)v53, &v44, &v44);
                IdentifyConnectedComponents(std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const&,std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>> &)::$_0::operator()(v6, v46, a2);
              }
              ++v11;
            }
            BOOL v23 = *(ZinIrOpLayer ***)(v10 + 112);
            uint64_t v24 = *(ZinIrOpLayer ***)(v10 + 120);
            while (v23 != v24)
            {
              uint64_t v46 = 0;
              uint64_t v46 = *v23;
              if (std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)a1, &v46)&& !std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(v53, &v46))
              {
                BOOL v25 = v48;
                if (v48 >= (ZinIrOpLayer *)v49)
                {
                  uint64_t v27 = (v48 - v47) >> 3;
                  if ((unint64_t)(v27 + 1) >> 61) {
                    std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
                  }
                  unint64_t v28 = (v49 - (char *)v47) >> 2;
                  if (v28 <= v27 + 1) {
                    unint64_t v28 = v27 + 1;
                  }
                  if ((unint64_t)(v49 - (char *)v47) >= 0x7FFFFFFFFFFFFFF8) {
                    unint64_t v29 = 0x1FFFFFFFFFFFFFFFLL;
                  }
                  else {
                    unint64_t v29 = v28;
                  }
                  if (v29) {
                    uint64_t v30 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)&v49, v29);
                  }
                  else {
                    uint64_t v30 = 0;
                  }
                  uint64_t v31 = &v30[8 * v27];
                  *(void *)uint64_t v31 = v46;
                  BOOL v26 = (ZinIrOpLayer *)(v31 + 8);
                  uint64_t v33 = v47;
                  uint64_t v32 = v48;
                  if (v48 != v47)
                  {
                    do
                    {
                      uint64_t v34 = *((void *)v32 - 1);
                      uint64_t v32 = (ZinIrOpLayer *)((char *)v32 - 8);
                      *((void *)v31 - 1) = v34;
                      v31 -= 8;
                    }
                    while (v32 != v33);
                    uint64_t v32 = v47;
                  }
                  uint64_t v47 = (ZinIrOpLayer *)v31;
                  uint64_t v48 = v26;
                  unint64_t v49 = &v30[8 * v29];
                  if (v32) {
                    operator delete(v32);
                  }
                }
                else
                {
                  *(void *)uint64_t v48 = v46;
                  BOOL v26 = (ZinIrOpLayer *)((char *)v25 + 8);
                }
                uint64_t v48 = v26;
                uint64_t v44 = v46;
                uint64_t v45 = v6;
                std::__hash_table<std::__hash_value_type<ZinIrOpLayer *,unsigned long>,std::__unordered_map_hasher<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,unsigned long>,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,true>,std::__unordered_map_equal<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,unsigned long>,std::equal_to<ZinIrOpLayer *>,std::hash<ZinIrOpLayer *>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer *,unsigned long>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::pair<ZinIrOpLayer *,unsigned long>>((uint64_t)v53, &v44, &v44);
                IdentifyConnectedComponents(std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const&,std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>> &)::$_0::operator()(v6, v46, a2);
              }
              ++v23;
            }
            v8 += 8;
          }
          while (v8 != v43);
          uint64_t v8 = (char *)v47;
          uint64_t v43 = (char *)v48;
          uint64_t v9 = v49;
          uint64_t v47 = v42;
          unint64_t v49 = v41;
          if (v42)
          {
            uint64_t v48 = v42;
            operator delete(v42);
          }
        }
        while (v43 != v8);
        ++v6;
        if (v8) {
          operator delete(v8);
        }
        unsigned int v3 = v39;
        uint64_t v2 = v40;
      }
      unsigned __int8 v35 = (void *)v2[1];
      if (v35)
      {
        do
        {
          uint64_t v36 = v35;
          unsigned __int8 v35 = (void *)*v35;
        }
        while (v35);
      }
      else
      {
        do
        {
          uint64_t v36 = (void *)v2[2];
          BOOL v37 = *v36 == (void)v2;
          uint64_t v2 = v36;
        }
        while (!v37);
      }
      uint64_t v2 = v36;
    }
    while (v36 != v3);
  }
  std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)v51);
  return std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v53);
}

void sub_211285884(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, void *__p, uint64_t a18, uint64_t a19, uint64_t a20,char a21)
{
  operator delete(v21);
  std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)&a21);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table(v22 - 128);
  _Unwind_Resume(a1);
}

void PressureBasedSubgraphIdentification::ClusterLayersInHighPressureRegionWithBoundaries(void *a1, unint64_t *a2, uint64_t *a3, uint64_t a4, unsigned __int8 a5)
{
  v39[0] = 0;
  v39[1] = 0;
  v37[1] = 0;
  uint64_t v38 = (uint64_t *)v39;
  uint64_t v36 = (uint64_t *)v37;
  v37[0] = 0;
  uint64_t v5 = a1[1];
  if (*(void *)(v5 + 360) == *(void *)(v5 + 352)) {
    ZinAssertImpl("Must run scheduler first");
  }
  unint64_t v7 = *a2;
  if (*a2 <= a2[1])
  {
    uint64_t v17 = a5;
    do
    {
      unsigned __int8 v35 = 0;
      uint64_t v8 = *(void *)(v5 + 352);
      if (v7 >= (*(void *)(v5 + 360) - v8) >> 3) {
        std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
      }
      uint64_t v9 = *(ZinIrOpLayer **)(v8 + 8 * v7);
      unsigned __int8 v35 = v9;
      v25[0] = 0;
      v25[1] = 0;
      v27[0] = 0;
      v27[1] = 0;
      uint64_t v24 = v25;
      BOOL v26 = v27;
      v28[0] = v28;
      v28[1] = v28;
      v30[0] = 0;
      v30[1] = 0;
      _OWORD v28[2] = 0;
      unint64_t v29 = v30;
      memset(v31, 0, sizeof(v31));
      v33[0] = 0;
      v33[1] = 0;
      uint64_t v32 = v33;
      char v34 = 0;
      if ((*(_DWORD *)(*((void *)v9 + 8) + 8) & 0xFFFFFFFC) != 0x1C
        && ((*(uint64_t (**)(ZinIrOpLayer *))(*(void *)v9 + 112))(v9) & 1) == 0)
      {
        long long __p = 0;
        unint64_t v22 = 0;
        uint64_t v23 = 0;
        (*(void (**)(void **__return_ptr))(*a1 + 112))(v20);
        uint64_t v10 = v20[2];
        if ((!v17
           || a4 + 8 == std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>(a4, &v35))&& v10)
        {
          uint64_t v11 = v35;
          uint64_t v13 = *((void *)v35 + 11);
          uint64_t v12 = *((void *)v35 + 12);
          if (v22 != (v12 - v13) >> 3) {
            ZinAssertImpl("Invalid boundary constraint in Spatial Splitting");
          }
          if (v12 != v13)
          {
            unint64_t v14 = 0;
            do
            {
              if (v22 <= v14) {
                std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
              }
              if ((*(void *)((char *)__p + ((v14 >> 3) & 0x1FFFFFFFFFFFFFF8)) >> v14))
              {
                uint64_t InputTensor = ZinIrOpLayer::GetInputTensor(v11, v14);
                std::__tree<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const*>(&v36, &InputTensor, &InputTensor);
                uint64_t v11 = v35;
              }
              ++v14;
            }
            while (v14 < (uint64_t)(*((void *)v11 + 12) - *((void *)v11 + 11)) >> 3);
          }
          std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>(&v38, &v35, (uint64_t *)&v35);
        }
        std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v20, (void *)v20[1]);
        if (__p) {
          operator delete(__p);
        }
      }
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v32, v33[0]);
      long long __p = v31;
      std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100]((void ***)&__p);
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v29, v30[0]);
      std::__list_imp<ZinIrSection *>::clear(v28);
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v26, v27[0]);
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v24, v25[0]);
      ++v7;
    }
    while (v7 <= a2[1]);
  }
  PressureBasedSubgraphIdentification::FindConnectedAcyclicClusters(a1, (ZinIrOpLayer ***)&v38, &v36, a3);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v36, v37[0]);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v38, v39[0]);
}

void sub_211285C20(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, char a20,uint64_t a21,uint64_t a22,void *__p,uint64_t a24,uint64_t a25,char a26)
{
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy(v26 - 136, *(void **)(v26 - 128));
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy(v26 - 112, *(void **)(v26 - 104));
  _Unwind_Resume(a1);
}

void PressureBasedSubgraphIdentification::FindConnectedAcyclicClusters(unsigned char *a1, ZinIrOpLayer ***a2, uint64_t **a3, uint64_t *a4)
{
  unint64_t v28 = (ZinIrOpLayer **)*MEMORY[0x263EF8340];
  std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::set[abi:ne180100]((uint64_t *)&v25, a2);
  unint64_t v22 = 0;
  uint64_t v23 = 0;
  uint64_t v24 = 0;
  BOOL v19 = (void **)&v22;
  LOBYTE(v20) = 0;
  unint64_t v22 = (uint64_t *)operator new(0x18uLL);
  uint64_t v23 = v22;
  uint64_t v24 = v22 + 3;
  uint64_t v23 = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const*,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const*,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>((uint64_t)&v24, (ZinIrOpLayer ***)&v25, &v28, v22);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v25, v26);
  BOOL v25 = 0;
  uint64_t v26 = 0;
  uint64_t v27 = 0;
  unint64_t v7 = (ZinIrOpLayer ***)v22;
  uint64_t v8 = v23;
  if (v22 == v23)
  {
    uint64_t v17 = 0;
    unint64_t v16 = 0;
  }
  else
  {
    do
    {
      BOOL v19 = 0;
      double v20 = 0;
      uint64_t v21 = 0;
      do
      {
        std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::set[abi:ne180100]((uint64_t *)v18, v7);
        PressureBasedSubgraphIdentification::IdentifyConnectedClusters((uint64_t)a1, v18, (uint64_t)a3, (uint64_t *)&v19);
        std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v18, v18[1]);
        v7 += 3;
      }
      while (v7 != (ZinIrOpLayer ***)v8);
      uint64_t v10 = v22;
      uint64_t v9 = v23;
      if (v23 != v22)
      {
        do
        {
          uint64_t v11 = v9 - 3;
          std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)(v9 - 3), (void *)*(v9 - 2));
          uint64_t v9 = v11;
        }
        while (v11 != v10);
      }
      uint64_t v23 = v10;
      uint64_t v12 = (ZinIrOpLayer ***)v19;
      uint64_t v13 = v20;
      if (v19 != v20)
      {
        do
        {
          if (PressureBasedSubgraphIdentification::AddBoundaryTensorsForAcyclicCluster(a1, v12, a3)) {
            std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::emplace<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const>((uint64_t *)&v22, v23, v12);
          }
          else {
            std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::emplace<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const>((uint64_t *)&v25, v26, v12);
          }
          v12 += 3;
        }
        while (v12 != (ZinIrOpLayer ***)v13);
        uint64_t v12 = (ZinIrOpLayer ***)v19;
        unint64_t v14 = v20;
        if (v20 != v19)
        {
          do
          {
            uint64_t v15 = (ZinIrOpLayer ***)(v14 - 3);
            std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)(v14 - 3), *(v14 - 2));
            unint64_t v14 = (void **)v15;
          }
          while (v15 != v12);
        }
      }
      double v20 = (void **)v12;
      v18[0] = (void **)&v19;
      std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100](v18);
      unint64_t v7 = (ZinIrOpLayer ***)v22;
      uint64_t v8 = v23;
    }
    while (v22 != v23);
    unint64_t v16 = v25;
    uint64_t v17 = v26;
  }
  std::__unwrap_and_dispatch[abi:ne180100]<std::__overload<std::__move_loop<std::_ClassicAlgPolicy>,std::__move_trivial>,std::__wrap_iter<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> *>,std::__wrap_iter<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> *>,std::back_insert_iterator<std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>>,0>(v16, v17, a4);
  BOOL v19 = (void **)&v25;
  std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100](&v19);
  BOOL v25 = (void **)&v22;
  std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100](&v25);
}

void sub_211285EA4(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, void ***a13, uint64_t a14, uint64_t a15, char a16, uint64_t a17, uint64_t a18, void **a19)
{
  a13 = &a19;
  std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100]((void ***)&a13);
  a19 = (void **)&a16;
  std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100](&a19);
  _Unwind_Resume(a1);
}

uint64_t PressureBasedSubgraphIdentification::IdentifyConnectedClusters(uint64_t a1, void *a2, uint64_t a3, uint64_t *a4)
{
  uint64_t v38 = *MEMORY[0x263EF8340];
  memset(v33, 0, sizeof(v33));
  int v34 = 1065353216;
  if (*(unsigned char *)(a1 + 73))
  {
    uint64_t v8 = PressureBasedSubgraphIdentification::ComputeTimeSpanOfCluster(a2);
    uint64_t v10 = v9;
    if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_INFO))
    {
      LODWORD(buf[0]) = 134218240;
      *(void *)((char *)buf + 4) = v8;
      WORD2(buf[1]) = 2048;
      *(void *)((char *)&buf[1] + 6) = v10;
      _os_log_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_INFO, "IdentifyConnectedCluster [%zu:%zu]", (uint8_t *)buf, 0x16u);
    }
  }
  uint64_t v11 = a2 + 1;
  uint64_t v12 = (void *)*a2;
  if ((void *)*a2 != a2 + 1)
  {
    uint64_t v13 = (void *)(a3 + 8);
    do
    {
      uint64_t v32 = v12[4];
      if (!std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(v33, &v32))
      {
        std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::emplace_back<>(a4);
        if (*(unsigned char *)(a1 + 74) && os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_INFO))
        {
          LOWORD(buf[0]) = 0;
          _os_log_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_INFO, "    Initializing cluster", (uint8_t *)buf, 2u);
        }
        long long v37 = 0u;
        memset(buf, 0, sizeof(buf));
        *(void *)unsigned __int8 v35 = v32;
        *(void *)&v35[8] = 0;
        std::deque<std::pair<ZinIrOpLayer *,ZinIrOpLayer *>>::push_back(buf, (__n128 *)v35);
        while (*((void *)&v37 + 1))
        {
          uint64_t v14 = *(void *)(buf[1] + (((unint64_t)v37 >> 5) & 0x7FFFFFFFFFFFFF8)) + 16 * v37;
          uint64_t v15 = *(void *)(v14 + 8);
          uint64_t v31 = *(ZinIrOpLayer **)v14;
          *(void *)&long long v37 = v37 + 1;
          --*((void *)&v37 + 1);
          if ((unint64_t)v37 >= 0x200)
          {
            operator delete(*(void **)buf[1]);
            buf[1] += 8;
            *(void *)&long long v37 = v37 - 256;
          }
          if (!std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(v33, &v31))
          {
            std::__hash_table<ZinIrTensor const*,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const* const&>((uint64_t)v33, &v31, &v31);
            if (v11 != (void *)std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>((uint64_t)a2, &v31))
            {
              std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>((uint64_t **)(a4[1] - 24), &v31, (uint64_t *)&v31);
              if (*(unsigned char *)(a1 + 74))
              {
                if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_INFO))
                {
                  uint64_t v17 = (void *)((char *)v31 + 24);
                  if (*((char *)v31 + 47) < 0) {
                    uint64_t v17 = (void *)*v17;
                  }
                  uint64_t v18 = *((void *)v31 + 6);
                  *(_DWORD *)unsigned __int8 v35 = 136315394;
                  *(void *)&v35[4] = v17;
                  *(_WORD *)&v35[12] = 2048;
                  *(void *)&v35[14] = v18;
                  _os_log_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_INFO, "\tAdding %s : %zu to connected cluster", v35, 0x16u);
                }
                if (v15 && os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_INFO))
                {
                  BOOL v19 = (void *)(v15 + 24);
                  if (*(char *)(v15 + 47) < 0) {
                    BOOL v19 = (void *)*v19;
                  }
                  uint64_t v20 = *(void *)(v15 + 48);
                  *(_DWORD *)unsigned __int8 v35 = 136315394;
                  *(void *)&v35[4] = v19;
                  *(_WORD *)&v35[12] = 2048;
                  *(void *)&v35[14] = v20;
                  _os_log_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_INFO, "\t    Connection from %s : %zu", v35, 0x16u);
                }
              }
              uint64_t v21 = v31;
              uint64_t v23 = (void *)*((void *)v31 + 11);
              unint64_t v22 = (void *)*((void *)v31 + 12);
              if (v23 != v22)
              {
                do
                {
                  uint64_t v24 = *v23;
                  *(void *)unsigned __int8 v35 = (*(uint64_t (**)(void, void, void))(*(void *)*v23 + 32))(*v23, 0, 0);
                  if (v13 == std::__tree<ZinIrOpLayer *,ZinIrIdComparator<ZinIrOpLayer *>,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>(a3, (uint64_t *)v35))
                  {
                    *(void *)unsigned __int8 v35 = v24;
                    *(void *)&v35[8] = v31;
                    __n128 v16 = std::deque<std::pair<ZinIrOpLayer *,ZinIrOpLayer *>>::push_back(buf, (__n128 *)v35);
                  }
                  ++v23;
                }
                while (v23 != v22);
                uint64_t v21 = v31;
              }
              *(void *)unsigned __int8 v35 = (*(uint64_t (**)(ZinIrOpLayer *, void, void, __n128))(*(void *)v21 + 32))(v21, 0, 0, v16);
              if (v13 == std::__tree<ZinIrOpLayer *,ZinIrIdComparator<ZinIrOpLayer *>,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>(a3, (uint64_t *)v35))
              {
                BOOL v25 = (void *)*((void *)v31 + 14);
                uint64_t v26 = (void *)*((void *)v31 + 15);
                while (v25 != v26)
                {
                  *(void *)unsigned __int8 v35 = *v25;
                  *(void *)&v35[8] = v31;
                  std::deque<std::pair<ZinIrOpLayer *,ZinIrOpLayer *>>::push_back(buf, (__n128 *)v35);
                  ++v25;
                }
              }
            }
          }
        }
        std::deque<std::pair<ZinIrOpLayer *,ZinIrOpLayer *>>::~deque[abi:ne180100](buf);
      }
      uint64_t v27 = (void *)v12[1];
      if (v27)
      {
        do
        {
          unint64_t v28 = v27;
          uint64_t v27 = (void *)*v27;
        }
        while (v27);
      }
      else
      {
        do
        {
          unint64_t v28 = (void *)v12[2];
          BOOL v29 = *v28 == (void)v12;
          uint64_t v12 = v28;
        }
        while (!v29);
      }
      uint64_t v12 = v28;
    }
    while (v28 != v11);
  }
  return std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v33);
}

void sub_2112863A0(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, ...)
{
  va_start(va1, a5);
  va_start(va, a5);
  uint64_t v6 = va_arg(va1, void);
  uint64_t v8 = va_arg(va1, void);
  uint64_t v9 = va_arg(va1, void);
  uint64_t v10 = va_arg(va1, void);
  uint64_t v11 = va_arg(va1, void);
  uint64_t v12 = va_arg(va1, void);
  uint64_t v13 = va_arg(va1, void);
  uint64_t v14 = va_arg(va1, void);
  uint64_t v15 = va_arg(va1, void);
  uint64_t v16 = va_arg(va1, void);
  std::deque<std::pair<ZinIrOpLayer *,ZinIrOpLayer *>>::~deque[abi:ne180100]((uint64_t *)va1);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)va);
  _Unwind_Resume(a1);
}

uint64_t PressureBasedSubgraphIdentification::ComputeTimeSpanOfCluster(void *a1)
{
  uint64_t v1 = a1 + 1;
  uint64_t v2 = (void *)*a1;
  if ((void *)*a1 == a1 + 1) {
    return 0x7FFFFFFFFFFFFFFFLL;
  }
  int64_t v3 = 0x8000000000000000;
  uint64_t result = 0x7FFFFFFFFFFFFFFFLL;
  do
  {
    int64_t v5 = *(void *)(v2[4] + 48);
    if (v5 < result) {
      uint64_t result = *(void *)(v2[4] + 48);
    }
    if (v3 <= v5) {
      int64_t v3 = *(void *)(v2[4] + 48);
    }
    uint64_t v6 = (void *)v2[1];
    if (v6)
    {
      do
      {
        unint64_t v7 = v6;
        uint64_t v6 = (void *)*v6;
      }
      while (v6);
    }
    else
    {
      do
      {
        unint64_t v7 = (void *)v2[2];
        BOOL v8 = *v7 == (void)v2;
        uint64_t v2 = v7;
      }
      while (!v8);
    }
    uint64_t v2 = v7;
  }
  while (v7 != v1);
  return result;
}

void *std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::emplace_back<>(uint64_t *a1)
{
  unint64_t v4 = a1[2];
  uint64_t v2 = a1 + 2;
  unint64_t v3 = v4;
  int64_t v5 = (void *)*(v2 - 1);
  if ((unint64_t)v5 >= v4)
  {
    unint64_t v7 = 0xAAAAAAAAAAAAAAABLL * (((uint64_t)v5 - *a1) >> 3);
    unint64_t v8 = v7 + 1;
    if (v7 + 1 > 0xAAAAAAAAAAAAAAALL) {
      std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
    }
    unint64_t v9 = 0xAAAAAAAAAAAAAAABLL * ((uint64_t)(v3 - *a1) >> 3);
    if (2 * v9 > v8) {
      unint64_t v8 = 2 * v9;
    }
    if (v9 >= 0x555555555555555) {
      unint64_t v10 = 0xAAAAAAAAAAAAAAALL;
    }
    else {
      unint64_t v10 = v8;
    }
    v14[4] = v2;
    if (v10) {
      uint64_t v11 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<std::string>>((uint64_t)v2, v10);
    }
    else {
      uint64_t v11 = 0;
    }
    uint64_t v12 = &v11[24 * v7];
    v14[0] = v11;
    v14[1] = v12;
    void v14[3] = &v11[24 * v10];
    *((void *)v12 + 2) = 0;
    *((void *)v12 + 1) = 0;
    *(void *)uint64_t v12 = v12 + 8;
    _OWORD v14[2] = v12 + 24;
    std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::__swap_out_circular_buffer(a1, v14);
    uint64_t v6 = (void *)a1[1];
    std::__split_buffer<std::map<ZinIrDimension,unsigned long>>::~__split_buffer(v14);
  }
  else
  {
    v5[2] = 0;
    v5[1] = 0;
    *int64_t v5 = v5 + 1;
    uint64_t v6 = v5 + 3;
    a1[1] = (uint64_t)(v5 + 3);
  }
  a1[1] = (uint64_t)v6;
  return v6 - 3;
}

void sub_211286560(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::__split_buffer<std::map<ZinIrDimension,unsigned long>>::~__split_buffer((void **)va);
  _Unwind_Resume(a1);
}

void *PressureBasedSubgraphIdentification::ComputeInputAndOutputNodes(void *result, void *a2, uint64_t a3, uint64_t **a4, uint64_t **a5)
{
  uint64_t v33 = *MEMORY[0x263EF8340];
  uint64_t v6 = a2 + 1;
  int64_t v5 = (void *)*a2;
  if ((void *)*a2 != a2 + 1)
  {
    unint64_t v9 = result;
    unint64_t v10 = (void *)(a3 + 8);
    do
    {
      uint64_t v30 = (ZinIrOpLayer *)v5[4];
      uint64_t v11 = *((void *)v30 + 11);
      uint64_t v12 = *((void *)v30 + 12);
      if (v11 == v12)
      {
        BOOL v15 = 0;
      }
      else
      {
        uint64_t v13 = v11 + 8;
        while (1)
        {
          *(void *)uint8_t buf = *(void *)(v13 - 8);
          if (v6 == (void *)std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>((uint64_t)a2, (ZinIrOpLayer **)buf))break; {
          uint64_t v31 = (*(uint64_t (**)(void, void, void))(**(void **)buf + 32))(*(void *)buf, 0, 0);
          }
          uint64_t v14 = std::__tree<ZinIrOpLayer *,ZinIrIdComparator<ZinIrOpLayer *>,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>(a3, &v31);
          BOOL v15 = v10 != v14;
          if (v10 == v14)
          {
            BOOL v22 = v13 == v12;
            v13 += 8;
            if (!v22) {
              continue;
            }
          }
          goto LABEL_12;
        }
        BOOL v15 = 1;
      }
LABEL_12:
      uint64_t v16 = v30;
      uint64_t v17 = *((void *)v30 + 14);
      uint64_t v18 = *((void *)v30 + 15);
      if (v17 == v18)
      {
        BOOL v21 = 0;
      }
      else
      {
        uint64_t v19 = v17 + 8;
        do
        {
          *(void *)uint8_t buf = *(void *)(v19 - 8);
          uint64_t v20 = std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>((uint64_t)a2, (ZinIrOpLayer **)buf);
          BOOL v21 = v6 == (void *)v20;
          BOOL v22 = v6 == (void *)v20 || v19 == v18;
          v19 += 8;
        }
        while (!v22);
        uint64_t v16 = v30;
      }
      *(void *)uint8_t buf = (*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)v16 + 32))(v16, 0, 0);
      uint64_t result = std::__tree<ZinIrOpLayer *,ZinIrIdComparator<ZinIrOpLayer *>,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>(a3, (uint64_t *)buf);
      int v23 = v10 != result || v21;
      if (v15)
      {
        if (*((unsigned char *)v9 + 74) && os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_INFO))
        {
          uint64_t v24 = (void *)((char *)v30 + 24);
          if (*((char *)v30 + 47) < 0) {
            uint64_t v24 = (void *)*v24;
          }
          *(_DWORD *)uint8_t buf = 136315138;
          *(void *)&void buf[4] = v24;
          _os_log_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_INFO, "\tInput node : %s", buf, 0xCu);
        }
        uint64_t result = std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>(a4, &v30, (uint64_t *)&v30);
      }
      if (v23)
      {
        if (*((unsigned char *)v9 + 74) && os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_INFO))
        {
          BOOL v25 = (void *)((char *)v30 + 24);
          if (*((char *)v30 + 47) < 0) {
            BOOL v25 = (void *)*v25;
          }
          *(_DWORD *)uint8_t buf = 136315138;
          *(void *)&void buf[4] = v25;
          _os_log_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_INFO, "\tOutput node : %s", buf, 0xCu);
        }
        uint64_t result = std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>(a5, &v30, (uint64_t *)&v30);
      }
      uint64_t v26 = (void *)v5[1];
      if (v26)
      {
        do
        {
          uint64_t v27 = v26;
          uint64_t v26 = (void *)*v26;
        }
        while (v26);
      }
      else
      {
        do
        {
          uint64_t v27 = (void *)v5[2];
          BOOL v22 = *v27 == (void)v5;
          int64_t v5 = v27;
        }
        while (!v22);
      }
      int64_t v5 = v27;
    }
    while (v27 != v6);
  }
  return result;
}

void PressureBasedSubgraphIdentification::BuildIdMaps(uint64_t a1, void *a2, uint64_t a3, uint64_t a4)
{
  unint64_t v7 = a2[2];
  uint64_t v16 = 0;
  std::vector<ZinIrOpLayer *>::vector(&v17, v7, &v16);
  unint64_t v8 = *(void **)a4;
  if (*(void *)a4)
  {
    *(void *)(a4 + 8) = v8;
    operator delete(v8);
  }
  *(_OWORD *)a4 = v17;
  *(void *)(a4 + 16) = v18;
  uint64_t v11 = (void *)*a2;
  unint64_t v9 = a2 + 1;
  unint64_t v10 = v11;
  if (v11 != v9)
  {
    uint64_t v12 = 0;
    do
    {
      uint64_t v16 = v10[4];
      *(void *)&long long v17 = &v16;
      std::__hash_table<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::__unordered_map_hasher<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,true>,std::__unordered_map_equal<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::equal_to<ZinIrOpLayer *>,std::hash<ZinIrOpLayer *>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer * const&>,std::tuple<>>(a3, &v16, (uint64_t)&std::piecewise_construct, (void **)&v17)[3] = v12;
      *(void *)(*(void *)a4 + 8 * v12) = v16;
      uint64_t v13 = (void *)v10[1];
      if (v13)
      {
        do
        {
          uint64_t v14 = v13;
          uint64_t v13 = (void *)*v13;
        }
        while (v13);
      }
      else
      {
        do
        {
          uint64_t v14 = (void *)v10[2];
          BOOL v15 = *v14 == (void)v10;
          unint64_t v10 = v14;
        }
        while (!v15);
      }
      ++v12;
      unint64_t v10 = v14;
    }
    while (v14 != v9);
  }
}

void PressureBasedSubgraphIdentification::ComputeReachabilityMaps(uint64_t a1, void *a2, uint64_t a3, void *a4, uint64_t a5, uint64_t *a6, uint64_t *a7)
{
  v53[0] = 0;
  v53[1] = 0;
  v51[1] = 0;
  int v52 = v53;
  uint64_t v50 = v51;
  v51[0] = 0;
  (*(void (**)(uint64_t, void *, uint64_t, void ***, void ***))(*(void *)a1 + 200))(a1, a2, a3, &v52, &v50);
  memset(v48, 0, sizeof(v48));
  int v49 = 1065353216;
  std::vector<std::vector<BOOL>>::vector(&v46, a2[2]);
  std::vector<std::vector<BOOL>>::__vdeallocate(a6);
  *(_OWORD *)a6 = v46;
  a6[2] = v47;
  uint64_t v47 = 0;
  long long v46 = 0uLL;
  int v54 = (void **)&v46;
  std::vector<std::vector<BOOL>>::__destroy_vector::operator()[abi:ne180100](&v54);
  std::vector<std::vector<BOOL>>::vector(&v46, a2[2]);
  std::vector<std::vector<BOOL>>::__vdeallocate(a7);
  *(_OWORD *)a7 = v46;
  a7[2] = v47;
  uint64_t v47 = 0;
  long long v46 = 0uLL;
  int v54 = (void **)&v46;
  std::vector<std::vector<BOOL>>::__destroy_vector::operator()[abi:ne180100](&v54);
  uint64_t v13 = v50;
  if (v50 != v51)
  {
    do
    {
      PressureBasedSubgraphIdentification::ComputeReachableMap(a1, (uint64_t)a2, a3, (uint64_t)&v50, (ZinIrOpLayer *)v13[4], v48, a4, a6);
      uint64_t v14 = v13[1];
      if (v14)
      {
        do
        {
          BOOL v15 = (void **)v14;
          uint64_t v14 = (void *)*v14;
        }
        while (v14);
      }
      else
      {
        do
        {
          BOOL v15 = (void **)v13[2];
          BOOL v16 = *v15 == v13;
          uint64_t v13 = v15;
        }
        while (!v16);
      }
      uint64_t v13 = v15;
    }
    while (v15 != v51);
  }
  long long v17 = (void *)*a2;
  if ((void *)*a2 != a2 + 1)
  {
    do
    {
      int v54 = (void **)v17[4];
      unint64_t v18 = a2[2];
      unsigned __int8 v45 = 0;
      std::vector<BOOL>::vector(&v46, v18, &v45);
      uint64_t v19 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(a4, &v54);
      if (!v19) {
        std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
      }
      uint64_t v20 = v19[3];
      uint64_t v21 = *a7;
      uint64_t v22 = *a7 + 24 * v20;
      if (*(void *)v22)
      {
        operator delete(*(void **)v22);
        *(void *)uint64_t v22 = 0;
        *(void *)(v22 + 8) = 0;
        *(void *)(v22 + 16) = 0;
      }
      *(void *)uint64_t v22 = v46;
      uint64_t v23 = v21 + 24 * v20;
      *(void *)(v23 + 8) = *((void *)&v46 + 1);
      *(void *)(v23 + 16) = v47;
      uint64_t v24 = (void *)v17[1];
      if (v24)
      {
        do
        {
          BOOL v25 = v24;
          uint64_t v24 = (void *)*v24;
        }
        while (v24);
      }
      else
      {
        do
        {
          BOOL v25 = (void *)v17[2];
          BOOL v16 = *v25 == (void)v17;
          long long v17 = v25;
        }
        while (!v16);
      }
      long long v17 = v25;
    }
    while (v25 != a2 + 1);
  }
  uint64_t v26 = *a6;
  uint64_t v27 = a6[1];
  uint64_t v28 = v27 - *a6;
  if (v27 != *a6)
  {
    unint64_t v29 = 0;
    unint64_t v30 = v28 / 24;
    uint64_t v31 = *a7;
    if (v30 <= 1) {
      unint64_t v30 = 1;
    }
    do
    {
      uint64_t v32 = v26 + 24 * v29;
      uint64_t v34 = *(void *)(v32 + 8);
      uint64_t v33 = (unint64_t *)(v32 + 8);
      if (v34)
      {
        unint64_t v35 = 0;
        uint64_t v36 = *(void *)(v26 + 24 * v29);
        unint64_t v37 = v29 >> 6;
        uint64_t v38 = (uint64_t *)v31;
        do
        {
          uint64_t v40 = *v38;
          v38 += 3;
          uint64_t v39 = v40;
          uint64_t v41 = *(void *)(v40 + 8 * v37);
          uint64_t v42 = v41 | (1 << v29);
          uint64_t v43 = v41 & ~(1 << v29);
          if ((*(void *)(v36 + ((v35 >> 3) & 0x1FFFFFFFFFFFFFF8)) >> v35)) {
            uint64_t v44 = v42;
          }
          else {
            uint64_t v44 = v43;
          }
          *(void *)(v39 + 8 * v37) = v44;
          ++v35;
        }
        while (v35 < *v33);
      }
      ++v29;
    }
    while (v29 != v30);
  }
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v48);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v50, v51[0]);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v52, v53[0]);
}

void sub_211286C90(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, void *__p, uint64_t a12, uint64_t a13, uint64_t a14, char a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, char a20,void *a21,uint64_t a22,char a23,void *a24)
{
}

void PressureBasedSubgraphIdentification::ComputeReachableMap(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, ZinIrOpLayer *a5, void *a6, void *a7, uint64_t *a8)
{
  uint64_t v55 = *MEMORY[0x263EF8340];
  int v52 = a5;
  uint64_t v12 = (void *)*((void *)a5 + 14);
  uint64_t v13 = (void *)*((void *)a5 + 15);
  if (v12 == v13)
  {
    uint64_t v14 = 0;
  }
  else
  {
    uint64_t v14 = 0;
    uint64_t v15 = a2 + 8;
    do
    {
      *(void *)&long long buf = *v12;
      if (v15 != std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>(a2, (ZinIrOpLayer **)&buf))++v14; {
      ++v12;
      }
    }
    while (v12 != v13);
  }
  unint64_t v16 = std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>(a4, &v52)+ v14;
  *(void *)&long long buf = (*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)v52 + 32))(v52, 0, 0);
  if (std::__tree<ZinIrOpLayer *,ZinIrIdComparator<ZinIrOpLayer *>,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>(a3, (uint64_t *)&buf))
  {
    unint64_t v16 = 1;
  }
  *(void *)&long long buf = &v52;
  long long v17 = std::__hash_table<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::__unordered_map_hasher<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,true>,std::__unordered_map_equal<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::equal_to<ZinIrOpLayer *>,std::hash<ZinIrOpLayer *>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer * const&>,std::tuple<>>((uint64_t)a6, &v52, (uint64_t)&std::piecewise_construct, (void **)&buf);
  ++v17[3];
  unint64_t v18 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::find<ZinIrTensor *>(a6, &v52);
  if (!v18) {
    std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
  }
  if (v18[3] >= v16)
  {
    uint64_t v19 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::find<ZinIrTensor *>(a6, &v52);
    if (!v19) {
      std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
    }
    if (v19[3] > v16) {
      ZinAssertImpl("Invalid visiting of cluster");
    }
    uint64_t v20 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(a7, &v52);
    if (!v20) {
      std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
    }
    uint64_t v21 = v20[3];
    unint64_t v22 = *(void *)(a2 + 16);
    LOBYTE(v51) = 0;
    std::vector<BOOL>::vector(&buf, v22, (unsigned __int8 *)&v51);
    uint64_t v23 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(a7, &v52);
    if (!v23) {
      std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
    }
    uint64_t v24 = v23[3];
    uint64_t v25 = *a8;
    uint64_t v26 = *a8 + 24 * v24;
    if (*(void *)v26)
    {
      operator delete(*(void **)v26);
      *(void *)uint64_t v26 = 0;
      *(void *)(v26 + 8) = 0;
      *(void *)(v26 + 16) = 0;
    }
    *(void *)uint64_t v26 = buf;
    uint64_t v27 = v25 + 24 * v24;
    *(void *)(v27 + 8) = *((void *)&buf + 1);
    *(void *)(v27 + 16) = v54;
    uint64_t v28 = (void *)*((void *)v52 + 14);
    for (uint64_t i = (void *)*((void *)v52 + 15); v28 != i; ++v28)
    {
      *(void *)&long long buf = *v28;
      uint64_t v51 = (*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)v52 + 32))(v52, 0, 0);
      if (std::__tree<ZinIrOpLayer *,ZinIrIdComparator<ZinIrOpLayer *>,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>(a3, &v51))
      {
        break;
      }
      if (a2 + 8 != std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>(a2, (ZinIrOpLayer **)&buf))
      {
        unint64_t v30 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(a7, &buf);
        if (!v30) {
          std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
        }
        unint64_t v31 = v30[3];
        uint64_t v32 = *a8;
        if (0xAAAAAAAAAAAAAAABLL * ((a8[1] - *a8) >> 3) <= v31) {
          std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
        }
        uint64_t v33 = (void *)(v32 + 24 * v31);
        if (v33[1])
        {
          unint64_t v34 = 0;
          uint64_t v35 = *(void *)(v32 + 24 * v21);
          do
          {
            unint64_t v36 = v34 >> 6;
            uint64_t v37 = 1 << v34;
            uint64_t v38 = *(void *)(v35 + 8 * (v34 >> 6));
            if ((v38 & (1 << v34)) != 0 || (*(void *)(*v33 + 8 * v36) & v37) != 0) {
              uint64_t v39 = v38 | v37;
            }
            else {
              uint64_t v39 = v38 & ~v37;
            }
            *(void *)(v35 + 8 * v36) = v39;
            ++v34;
          }
          while (v34 < v33[1]);
        }
      }
    }
    uint64_t v40 = *a8;
    uint64_t v41 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(a7, &v52);
    if (!v41) {
      std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
    }
    *(void *)(*(void *)(v40 + 24 * v21) + ((v41[3] >> 3) & 0x1FFFFFFFFFFFFFF8)) |= 1 << v41[3];
    uint64_t v42 = *a8;
    uint64_t v43 = a8[1];
    if (*a8 == v43) {
      goto LABEL_58;
    }
    uint64_t v44 = 0;
    uint64_t v45 = *a8;
    do
    {
      if (*(void *)(v45 + 8)) {
        ++v44;
      }
      v45 += 24;
    }
    while (v45 != v43);
    if (__ROR8__(0x8F5C28F5C28F5C29 * v44, 2) <= 0x28F5C28F5C28F5CuLL)
    {
LABEL_58:
      if (*(unsigned char *)(a1 + 74) && os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_INFO))
      {
        LODWORD(buf) = 134217984;
        *(void *)((char *)&buf + 4) = 0xAAAAAAAAAAAAAAABLL * ((v43 - v42) >> 3);
        _os_log_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_INFO, "Forward Reachable map size %zu", (uint8_t *)&buf, 0xCu);
      }
    }
    long long v46 = (void *)*((void *)v52 + 11);
    for (uint64_t j = (void *)*((void *)v52 + 12); v46 != j; ++v46)
    {
      *(void *)&long long buf = *v46;
      if (a2 + 8 != std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>(a2, (ZinIrOpLayer **)&buf))
      {
        uint64_t v51 = (*(uint64_t (**)(void, void, void))(*(void *)buf + 32))(buf, 0, 0);
        if ((void *)(a3 + 8) == std::__tree<ZinIrOpLayer *,ZinIrIdComparator<ZinIrOpLayer *>,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>(a3, &v51))PressureBasedSubgraphIdentification::ComputeReachableMap(a1, a2, a3, a4, buf, a6, a7, a8); {
      }
        }
    }
  }
}

void sub_211287244(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, void *__p)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

void PressureBasedSubgraphIdentification::FindCyclicPaths(uint64_t a1@<X1>, uint64_t a2@<X2>, void *a3@<X3>, void **a4@<X8>)
{
  *a4 = 0;
  a4[1] = 0;
  a4[2] = 0;
  unint64_t v7 = (void *)(a2 + 8);
  unint64_t v8 = *(void **)(a2 + 8);
  if (v8)
  {
    do
    {
      unint64_t v9 = v8;
      unint64_t v8 = (void *)v8[1];
    }
    while (v8);
  }
  else
  {
    do
    {
      unint64_t v9 = (void *)v7[2];
      BOOL v10 = *v9 == (void)v7;
      unint64_t v7 = v9;
    }
    while (v10);
  }
  uint64_t v11 = a3 + 1;
  uint64_t v12 = (void *)*a3;
  if ((void *)*a3 != a3 + 1)
  {
    unint64_t v13 = *(void *)(v9[4] + 48);
    uint64_t v14 = a1 + 8;
    do
    {
      uint64_t v40 = (ZinIrOpLayer *)v12[4];
      long long v39 = 0u;
      memset(v38, 0, sizeof(v38));
      std::deque<ZinIrOpLayer *>::push_back(v38, &v40);
      memset(v36, 0, sizeof(v36));
      int v37 = 1065353216;
      while (*((void *)&v39 + 1))
      {
        uint64_t v35 = 0;
        uint64_t v35 = *(ZinIrOpLayer **)(*(void *)(*((void *)&v38[0] + 1)
                                           + (((unint64_t)v39 >> 6) & 0x3FFFFFFFFFFFFF8))
                               + 8 * (v39 & 0x1FF));
        *(void *)&long long v39 = v39 + 1;
        --*((void *)&v39 + 1);
        if ((unint64_t)v39 >= 0x400)
        {
          operator delete(**((void ***)&v38[0] + 1));
          *((void *)&v38[0] + 1) += 8;
          *(void *)&long long v39 = v39 - 512;
        }
        if (!std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(v36, &v35))
        {
          std::__hash_table<ZinIrTensor const*,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const* const&>((uint64_t)v36, &v35, &v35);
          if (*((void *)v35 + 6) <= v13)
          {
            if (!std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>(a2, &v35)|| (uint64_t v15 = v35, v35 == v40))
            {
              if (v14 == std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>(a1, &v35)|| v35 == v40)
              {
                uint64_t v20 = (uint64_t *)*((void *)v35 + 14);
                uint64_t v19 = (uint64_t *)*((void *)v35 + 15);
                while (v20 != v19)
                {
                  uint64_t v34 = 0;
                  uint64_t v34 = *v20;
                  std::deque<ZinIrOpLayer *>::push_back(v38, &v34);
                  ++v20;
                }
              }
            }
            else
            {
              unint64_t v16 = (ZinIrOpLayer **)a4[1];
              unint64_t v17 = (unint64_t)a4[2];
              if ((unint64_t)v16 >= v17)
              {
                uint64_t v21 = ((char *)v16 - (unsigned char *)*a4) >> 4;
                unint64_t v22 = v21 + 1;
                if ((unint64_t)(v21 + 1) >> 60) {
                  std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
                }
                uint64_t v23 = v17 - (void)*a4;
                if (v23 >> 3 > v22) {
                  unint64_t v22 = v23 >> 3;
                }
                if ((unint64_t)v23 >= 0x7FFFFFFFFFFFFFF0) {
                  unint64_t v24 = 0xFFFFFFFFFFFFFFFLL;
                }
                else {
                  unint64_t v24 = v22;
                }
                uint64_t v25 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<std::pair<unsigned long,unsigned long>>>((uint64_t)(a4 + 2), v24);
                uint64_t v27 = (ZinIrOpLayer **)&v25[16 * v21];
                uint64_t v28 = v35;
                *uint64_t v27 = v40;
                v27[1] = v28;
                unint64_t v30 = (char *)*a4;
                unint64_t v29 = (char *)a4[1];
                unint64_t v31 = v27;
                if (v29 != *a4)
                {
                  do
                  {
                    *((_OWORD *)v31 - 1) = *((_OWORD *)v29 - 1);
                    v31 -= 2;
                    v29 -= 16;
                  }
                  while (v29 != v30);
                  unint64_t v29 = (char *)*a4;
                }
                unint64_t v18 = v27 + 2;
                *a4 = v31;
                a4[1] = v27 + 2;
                a4[2] = &v25[16 * v26];
                if (v29) {
                  operator delete(v29);
                }
              }
              else
              {
                *unint64_t v16 = v40;
                v16[1] = v15;
                unint64_t v18 = v16 + 2;
              }
              a4[1] = v18;
            }
          }
        }
      }
      std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v36);
      std::deque<unsigned long>::~deque[abi:ne180100](v38);
      uint64_t v32 = (void *)v12[1];
      if (v32)
      {
        do
        {
          uint64_t v33 = v32;
          uint64_t v32 = (void *)*v32;
        }
        while (v32);
      }
      else
      {
        do
        {
          uint64_t v33 = (void *)v12[2];
          BOOL v10 = *v33 == (void)v12;
          uint64_t v12 = v33;
        }
        while (!v10);
      }
      uint64_t v12 = v33;
    }
    while (v33 != v11);
  }
}

void sub_21128754C(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, ...)
{
  va_start(va1, a3);
  va_start(va, a3);
  uint64_t v6 = va_arg(va1, void);
  uint64_t v8 = va_arg(va1, void);
  uint64_t v9 = va_arg(va1, void);
  uint64_t v10 = va_arg(va1, void);
  uint64_t v11 = va_arg(va1, void);
  uint64_t v12 = va_arg(va1, void);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)va);
  std::deque<unsigned long>::~deque[abi:ne180100]((uint64_t *)va1);
  int64_t v5 = *(void **)v3;
  if (*(void *)v3)
  {
    *(void *)(v3 + 8) = v5;
    operator delete(v5);
  }
  _Unwind_Resume(a1);
}

uint64_t PressureBasedSubgraphIdentification::FindForkJoinPairForCyclicPath(uint64_t a1, void *a2, void *a3, uint64_t *a4, uint64_t *a5, uint64_t *a6)
{
  uint64_t v91 = *MEMORY[0x263EF8340];
  uint64_t v12 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(a3, a2);
  if (!v12) {
    goto LABEL_93;
  }
  unint64_t v13 = v12[3];
  uint64_t v14 = *a6;
  if (0xAAAAAAAAAAAAAAABLL * ((a6[1] - *a6) >> 3) <= v13) {
LABEL_95:
  }
    std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
  uint64_t v15 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(a3, a2 + 1);
  if (!v15) {
LABEL_93:
  }
    std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
  unint64_t v16 = v15[3];
  if (0xAAAAAAAAAAAAAAABLL * ((a5[1] - *a5) >> 3) <= v16) {
LABEL_94:
  }
    std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
  uint64_t v81 = v14;
  unint64_t v82 = v13;
  int v84 = (void *)(v14 + 24 * v13);
  uint64_t v79 = *a5;
  uint64_t v80 = v15[3];
  int v86 = (void *)(*a5 + 24 * v16);
  uint64_t v78 = a1;
  if (*(unsigned char *)(a1 + 74))
  {
    uint64_t v17 = v14 + 24 * v13;
    unint64_t v20 = *(void *)(v17 + 8);
    uint64_t v19 = (unint64_t *)(v17 + 8);
    unint64_t v18 = v20;
    if (v20)
    {
      unint64_t v21 = 0;
      unint64_t v22 = &_os_log_internal;
      do
      {
        if ((*(void *)(*v84 + ((v21 >> 3) & 0x1FFFFFFFFFFFFFF8)) >> v21))
        {
          uint64_t v23 = *a4;
          if (v21 >= (a4[1] - *a4) >> 3) {
LABEL_96:
          }
            std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
          if (os_log_type_enabled(v22, OS_LOG_TYPE_INFO))
          {
            uint64_t v24 = *(void *)(v23 + 8 * v21);
            uint64_t v25 = (void *)(v24 + 24);
            if (*(char *)(v24 + 47) < 0) {
              uint64_t v25 = (void *)*v25;
            }
            uint64_t v26 = *(void *)(v24 + 48);
            *(_DWORD *)long long buf = 136315394;
            *(void *)&void buf[4] = v25;
            __int16 v89 = 2048;
            uint64_t v90 = v26;
            _os_log_impl(&dword_210C72000, v22, OS_LOG_TYPE_INFO, "    Can Reach Output %s : %zu", buf, 0x16u);
            unint64_t v18 = *v19;
          }
        }
        ++v21;
      }
      while (v21 < v18);
    }
    uint64_t v27 = v79 + 24 * v80;
    unint64_t v30 = *(void *)(v27 + 8);
    unint64_t v29 = (unint64_t *)(v27 + 8);
    unint64_t v28 = v30;
    if (v30)
    {
      unint64_t v31 = 0;
      uint64_t v32 = &_os_log_internal;
      do
      {
        if ((*(void *)(*v86 + ((v31 >> 3) & 0x1FFFFFFFFFFFFFF8)) >> v31))
        {
          uint64_t v33 = *a4;
          if (v31 >= (a4[1] - *a4) >> 3) {
            goto LABEL_96;
          }
          if (os_log_type_enabled(v32, OS_LOG_TYPE_INFO))
          {
            uint64_t v34 = *(void *)(v33 + 8 * v31);
            uint64_t v35 = (void *)(v34 + 24);
            if (*(char *)(v34 + 47) < 0) {
              uint64_t v35 = (void *)*v35;
            }
            uint64_t v36 = *(void *)(v34 + 48);
            *(_DWORD *)long long buf = 136315394;
            *(void *)&void buf[4] = v35;
            __int16 v89 = 2048;
            uint64_t v90 = v36;
            _os_log_impl(&dword_210C72000, v32, OS_LOG_TYPE_INFO, "    Input Can Reach %s : %zu", buf, 0x16u);
            unint64_t v28 = *v29;
          }
        }
        ++v31;
      }
      while (v31 < v28);
    }
  }
  uint64_t v83 = (unint64_t *)(v81 + 24 * v82 + 8);
  uint64_t v37 = *v83 - 1;
  if (v37 >= 0)
  {
    uint64_t v38 = (unint64_t *)(v79 + 24 * v80 + 8);
    do
    {
      if (*v83 <= v37) {
        std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
      }
      if ((*(void *)(*v84 + (((unint64_t)v37 >> 3) & 0x1FFFFFFFFFFFFFF8)) >> v37))
      {
        *(void *)long long buf = 0;
        if (v37 >= (unint64_t)((a4[1] - *a4) >> 3)) {
          goto LABEL_96;
        }
        *(void *)long long buf = *(void *)(*a4 + 8 * v37);
        unint64_t v39 = *v38;
        if (*v38)
        {
          for (unint64_t i = 0; v39 > i; ++i)
          {
            if ((*(void *)(*v86 + 8 * (i >> 6)) & (1 << i)) != 0)
            {
              if (i >= (a4[1] - *a4) >> 3) {
                goto LABEL_96;
              }
              uint64_t v41 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(a3, buf);
              if (!v41) {
                goto LABEL_93;
              }
              unint64_t v42 = v41[3];
              if (0xAAAAAAAAAAAAAAABLL * ((a5[1] - *a5) >> 3) <= v42) {
                goto LABEL_94;
              }
              uint64_t v43 = (void *)(*a5 + 24 * v42);
              if (v43[1] <= i) {
LABEL_97:
              }
                std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
              if ((*(void *)(*v43 + 8 * (i >> 6)) & (1 << i)) != 0) {
                return *(void *)buf;
              }
              unint64_t v39 = *v38;
            }
          }
        }
      }
    }
    while (v37-- >= 1);
  }
  if (*(unsigned char *)(v78 + 74))
  {
    unint64_t v45 = *v83;
    if (*v83)
    {
      unint64_t v46 = 0;
      uint64_t v47 = &_os_log_internal;
      do
      {
        if ((*(void *)(*v84 + ((v46 >> 3) & 0x1FFFFFFFFFFFFFF8)) >> v46))
        {
          uint64_t v87 = 0;
          if (v46 >= (a4[1] - *a4) >> 3) {
            goto LABEL_96;
          }
          uint64_t v48 = *(void *)(*a4 + 8 * v46);
          uint64_t v87 = v48;
          if (os_log_type_enabled(v47, OS_LOG_TYPE_INFO))
          {
            int v49 = (void *)(v48 + 24);
            if (*(char *)(v48 + 47) < 0) {
              int v49 = (void *)*v49;
            }
            uint64_t v50 = *(void *)(v48 + 48);
            *(_DWORD *)long long buf = 136315394;
            *(void *)&void buf[4] = v49;
            __int16 v89 = 2048;
            uint64_t v90 = v50;
            _os_log_impl(&dword_210C72000, v47, OS_LOG_TYPE_INFO, "\tNode that can reach output %s : %zu", buf, 0x16u);
          }
          uint64_t v51 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(a3, &v87);
          if (!v51) {
            goto LABEL_93;
          }
          unint64_t v52 = 0;
          while (1)
          {
            unint64_t v53 = v51[3];
            if (0xAAAAAAAAAAAAAAABLL * ((a5[1] - *a5) >> 3) <= v53) {
              goto LABEL_94;
            }
            if (v52 >= *(void *)(*a5 + 24 * v53 + 8)) {
              break;
            }
            uint64_t v54 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(a3, &v87);
            if (!v54) {
              goto LABEL_93;
            }
            unint64_t v55 = v54[3];
            if (0xAAAAAAAAAAAAAAABLL * ((a5[1] - *a5) >> 3) <= v55) {
              goto LABEL_94;
            }
            if ((*(void *)(*(void *)(*a5 + 24 * v55) + ((v52 >> 3) & 0x1FFFFFFFFFFFFFF8)) >> v52))
            {
              uint64_t v56 = *a4;
              if (v52 >= (a4[1] - *a4) >> 3) {
                goto LABEL_96;
              }
              if (os_log_type_enabled(v47, OS_LOG_TYPE_INFO))
              {
                uint64_t v57 = *(void *)(v56 + 8 * v52);
                uint64_t v58 = (void *)(v57 + 24);
                if (*(char *)(v57 + 47) < 0) {
                  uint64_t v58 = (void *)*v58;
                }
                uint64_t v59 = *(void *)(v57 + 48);
                *(_DWORD *)long long buf = 136315394;
                *(void *)&void buf[4] = v58;
                __int16 v89 = 2048;
                uint64_t v90 = v59;
                _os_log_impl(&dword_210C72000, v47, OS_LOG_TYPE_INFO, "\t    Can be reached %s : %zu", buf, 0x16u);
              }
            }
            ++v52;
            uint64_t v51 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(a3, &v87);
            if (!v51) {
              goto LABEL_93;
            }
          }
          unint64_t v45 = *v83;
        }
        ++v46;
      }
      while (v46 < v45);
    }
    uint64_t v60 = v79 + 24 * v80;
    unint64_t v61 = *(void *)(v60 + 8);
    long long v85 = (unint64_t *)(v60 + 8);
    if (v61)
    {
      unint64_t v62 = 0;
      unsigned int v63 = &_os_log_internal;
      do
      {
        if ((*(void *)(*v86 + ((v62 >> 3) & 0x1FFFFFFFFFFFFFF8)) >> v62))
        {
          uint64_t v87 = 0;
          if (v62 >= (a4[1] - *a4) >> 3) {
            goto LABEL_96;
          }
          uint64_t v64 = *(void *)(*a4 + 8 * v62);
          uint64_t v87 = v64;
          if (os_log_type_enabled(v63, OS_LOG_TYPE_INFO))
          {
            long long v65 = (void *)(v64 + 24);
            if (*(char *)(v64 + 47) < 0) {
              long long v65 = (void *)*v65;
            }
            uint64_t v66 = *(void *)(v64 + 48);
            *(_DWORD *)long long buf = 136315394;
            *(void *)&void buf[4] = v65;
            __int16 v89 = 2048;
            uint64_t v90 = v66;
            _os_log_impl(&dword_210C72000, v63, OS_LOG_TYPE_INFO, "\tNode reachable from input %s : %zu", buf, 0x16u);
          }
          uint64_t v67 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(a3, &v87);
          if (!v67) {
            goto LABEL_93;
          }
          unint64_t v68 = 0;
          while (1)
          {
            unint64_t v69 = v67[3];
            if (0xAAAAAAAAAAAAAAABLL * ((a6[1] - *a6) >> 3) <= v69) {
              goto LABEL_95;
            }
            if (v68 >= *(void *)(*a6 + 24 * v69 + 8)) {
              break;
            }
            long long v70 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(a3, &v87);
            if (!v70) {
              goto LABEL_93;
            }
            unint64_t v71 = v70[3];
            if (0xAAAAAAAAAAAAAAABLL * ((a6[1] - *a6) >> 3) <= v71) {
              goto LABEL_95;
            }
            uint64_t v72 = (void *)(*a6 + 24 * v71);
            if (v72[1] <= v68) {
              goto LABEL_97;
            }
            if ((*(void *)(*v72 + ((v68 >> 3) & 0x1FFFFFFFFFFFFFF8)) >> v68))
            {
              uint64_t v73 = *a4;
              if (v68 >= (a4[1] - *a4) >> 3) {
                goto LABEL_96;
              }
              if (os_log_type_enabled(v63, OS_LOG_TYPE_INFO))
              {
                uint64_t v74 = *(void *)(v73 + 8 * v68);
                uint64_t v75 = (void *)(v74 + 24);
                if (*(char *)(v74 + 47) < 0) {
                  uint64_t v75 = (void *)*v75;
                }
                uint64_t v76 = *(void *)(v74 + 48);
                *(_DWORD *)long long buf = 136315394;
                *(void *)&void buf[4] = v75;
                __int16 v89 = 2048;
                uint64_t v90 = v76;
                _os_log_impl(&dword_210C72000, v63, OS_LOG_TYPE_INFO, "\t    Can reach %s : %zu", buf, 0x16u);
              }
            }
            ++v68;
            uint64_t v67 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(a3, &v87);
            if (!v67) {
              goto LABEL_93;
            }
          }
          unint64_t v61 = *v85;
        }
        ++v62;
      }
      while (v62 < v61);
    }
  }
  return 0;
}

uint64_t PressureBasedSubgraphIdentification::AddBoundaryTensorsByForkJoinPairs(unsigned char *a1, long long **a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t **a7)
{
  uint64_t v59 = *MEMORY[0x263EF8340];
  int v49 = 0;
  uint64_t v50 = 0;
  uint64_t v51 = 0;
  uint64_t v8 = *a2;
  unint64_t v7 = a2[1];
  if (*a2 == v7) {
    return 1;
  }
  unint64_t v13 = &_os_log_internal;
  do
  {
    long long v48 = *v8;
    if (a1[73] && os_log_type_enabled(v13, OS_LOG_TYPE_INFO))
    {
      uint64_t v14 = (void *)(v48 + 24);
      if (*(char *)(v48 + 47) < 0) {
        uint64_t v14 = (void *)*v14;
      }
      uint64_t v15 = (void *)(*((void *)&v48 + 1) + 24);
      if (*(char *)(*((void *)&v48 + 1) + 47) < 0) {
        uint64_t v15 = (void *)*v15;
      }
      uint64_t v16 = *(void *)(v48 + 48);
      uint64_t v17 = *(void *)(*((void *)&v48 + 1) + 48);
      *(_DWORD *)long long buf = 136315906;
      *(void *)&void buf[4] = v14;
      __int16 v53 = 2048;
      uint64_t v54 = v16;
      __int16 v55 = 2080;
      uint64_t v56 = v15;
      __int16 v57 = 2048;
      uint64_t v58 = v17;
      _os_log_impl(&dword_210C72000, v13, OS_LOG_TYPE_INFO, "  Cyclic Path [%s %zu] [%s %zu]", buf, 0x2Au);
    }
    uint64_t v18 = (*(uint64_t (**)(unsigned char *, long long *, uint64_t, uint64_t, uint64_t, uint64_t))(*(void *)a1 + 232))(a1, &v48, a3, a4, a5, a6);
    uint64_t v20 = v18;
    uint64_t v21 = v19;
    unint64_t v22 = v50;
    if (v50 >= v51)
    {
      uint64_t v24 = ((char *)v50 - (char *)v49) >> 4;
      unint64_t v25 = v24 + 1;
      if ((unint64_t)(v24 + 1) >> 60) {
        std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
      }
      uint64_t v26 = (char *)v51 - (char *)v49;
      if (v51 - v49 > v25) {
        unint64_t v25 = v26 >> 3;
      }
      if ((unint64_t)v26 >= 0x7FFFFFFFFFFFFFF0) {
        unint64_t v27 = 0xFFFFFFFFFFFFFFFLL;
      }
      else {
        unint64_t v27 = v25;
      }
      if (v27) {
        unint64_t v28 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<std::pair<unsigned long,unsigned long>>>((uint64_t)&v51, v27);
      }
      else {
        unint64_t v28 = 0;
      }
      unint64_t v29 = (uint64_t *)&v28[16 * v24];
      *unint64_t v29 = v20;
      v29[1] = v21;
      unint64_t v31 = v49;
      unint64_t v30 = v50;
      uint64_t v32 = v29;
      if (v50 != v49)
      {
        do
        {
          *((_OWORD *)v32 - 1) = *((_OWORD *)v30 - 1);
          v32 -= 2;
          v30 -= 2;
        }
        while (v30 != v31);
        unint64_t v30 = v49;
      }
      uint64_t v23 = v29 + 2;
      int v49 = v32;
      uint64_t v50 = v29 + 2;
      uint64_t v51 = (uint64_t *)&v28[16 * v27];
      if (v30) {
        operator delete(v30);
      }
    }
    else
    {
      *uint64_t v50 = v18;
      v22[1] = v19;
      uint64_t v23 = v22 + 2;
    }
    uint64_t v50 = v23;
    if (a1[73])
    {
      uint64_t v33 = *(v23 - 2);
      if (v33)
      {
        if (*(v23 - 1))
        {
          if (os_log_type_enabled(v13, OS_LOG_TYPE_INFO))
          {
            uint64_t v34 = (void *)(v33 + 24);
            if (*(char *)(v33 + 47) < 0) {
              uint64_t v34 = (void *)*v34;
            }
            uint64_t v35 = *(void *)(v33 + 48);
            *(_DWORD *)long long buf = 136315394;
            *(void *)&void buf[4] = v34;
            __int16 v53 = 2048;
            uint64_t v54 = v35;
            _os_log_impl(&dword_210C72000, v13, OS_LOG_TYPE_INFO, "    Fork Point %s %zu", buf, 0x16u);
          }
          if (os_log_type_enabled(v13, OS_LOG_TYPE_INFO))
          {
            uint64_t v36 = *(v50 - 1);
            uint64_t v37 = (void *)(v36 + 24);
            if (*(char *)(v36 + 47) < 0) {
              uint64_t v37 = (void *)*v37;
            }
            uint64_t v38 = *(void *)(v36 + 48);
            *(_DWORD *)long long buf = 136315394;
            *(void *)&void buf[4] = v37;
            __int16 v53 = 2048;
            uint64_t v54 = v38;
            _os_log_impl(&dword_210C72000, v13, OS_LOG_TYPE_INFO, "    Join Point %s %zu", buf, 0x16u);
          }
        }
      }
    }
    ++v8;
  }
  while (v8 != v7);
  uint64_t v40 = v49;
  unint64_t v39 = v50;
  if (v49 == v50) {
    goto LABEL_55;
  }
  uint64_t v41 = v49;
  while (!*v41 || v41[1] == 0)
  {
    v41 += 2;
    if (v41 == v50)
    {
      uint64_t v43 = 0;
      unint64_t v39 = v49;
      goto LABEL_56;
    }
  }
  if (v49 == v50)
  {
LABEL_55:
    uint64_t v43 = 1;
  }
  else
  {
    do
    {
      uint64_t v44 = v40[1];
      if (*v40)
      {
        if (!v44) {
          goto LABEL_60;
        }
        *(void *)long long buf = (*(uint64_t (**)(uint64_t, void, void))(*(void *)*v40 + 32))(*v40, 0, 0);
        std::__tree<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const*>(a7, (uint64_t *)buf, (uint64_t *)buf);
      }
      else if (v44)
      {
LABEL_60:
        ZinAssertImpl("Both fork and join point must be found");
      }
      v40 += 2;
    }
    while (v40 != v39);
    uint64_t v43 = 1;
    unint64_t v39 = v49;
  }
LABEL_56:
  if (v39)
  {
    uint64_t v50 = v39;
    operator delete(v39);
  }
  return v43;
}

void sub_2112881EC(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,void *__p,uint64_t a23)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t PressureBasedSubgraphIdentification::AddBoundaryTensorBySchedule(uint64_t a1, void *a2, uint64_t **a3, uint64_t a4)
{
  uint64_t v7 = PressureBasedSubgraphIdentification::ComputeTimeSpanOfCluster(a2);
  unint64_t v9 = v7 + v8;
  if (v7 + v8 < 0 != __OFADD__(v7, v8)) {
    ++v9;
  }
  v36[0] = 0;
  v36[1] = 0;
  uint64_t v35 = (uint64_t *)v36;
  uint64_t v10 = *a3;
  uint64_t v11 = a3[1];
  if (*a3 == v11) {
    goto LABEL_46;
  }
  unint64_t v12 = v9 >> 1;
  do
  {
    uint64_t v32 = v10;
    unint64_t v13 = std::__tree<std::__value_type<ZinIrOpLayer const*,double>,std::__map_value_compare<ZinIrOpLayer const*,std::__value_type<ZinIrOpLayer const*,double>,ScheduleComparator,true>,std::allocator<std::__value_type<ZinIrOpLayer const*,double>>>::__emplace_unique_key_args<ZinIrOpLayer const*,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer const* const&>,std::tuple<>>(&v35, (ZinIrOpLayer **)v10, (uint64_t)&std::piecewise_construct, &v32);
    ++v13[5];
    uint64_t v14 = v10 + 1;
    uint64_t v32 = v14;
    uint64_t v15 = std::__tree<std::__value_type<ZinIrOpLayer const*,double>,std::__map_value_compare<ZinIrOpLayer const*,std::__value_type<ZinIrOpLayer const*,double>,ScheduleComparator,true>,std::allocator<std::__value_type<ZinIrOpLayer const*,double>>>::__emplace_unique_key_args<ZinIrOpLayer const*,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer const* const&>,std::tuple<>>(&v35, (ZinIrOpLayer **)v14, (uint64_t)&std::piecewise_construct, &v32);
    ++v15[5];
    uint64_t v10 = v14 + 1;
  }
  while (v10 != v11);
  uint64_t v16 = v35;
  if (v35 == (uint64_t *)v36) {
    goto LABEL_46;
  }
  uint64_t v17 = 0;
  do
  {
    if (v16[5])
    {
      uint64_t v17 = v16[4];
    }
    else
    {
      if (!v17) {
        ZinAssertImpl("Boundary Tensor Internal Error");
      }
      int v18 = *(_DWORD *)(v17 + 48) - v12;
      if (v18 < 0) {
        int v18 = v12 - *(_DWORD *)(v17 + 48);
      }
      int v19 = *(_DWORD *)(v16[4] + 48) - v12;
      if (v19 < 0) {
        int v19 = v12 - *(_DWORD *)(v16[4] + 48);
      }
      if (v19 < v18) {
        uint64_t v17 = v16[4];
      }
    }
    uint64_t v20 = (uint64_t *)v16[1];
    if (v20)
    {
      do
      {
        uint64_t v21 = v20;
        uint64_t v20 = (uint64_t *)*v20;
      }
      while (v20);
    }
    else
    {
      do
      {
        uint64_t v21 = (uint64_t *)v16[2];
        BOOL v22 = *v21 == (void)v16;
        uint64_t v16 = v21;
      }
      while (!v22);
    }
    uint64_t v16 = v21;
  }
  while (v21 != (uint64_t *)v36);
  if (!v17) {
LABEL_46:
  }
    ZinAssertImpl("Could not find cut-point");
  uint64_t v23 = a2 + 1;
  uint64_t v24 = (void *)*a2;
  if ((void *)*a2 == a2 + 1) {
    goto LABEL_47;
  }
  char v25 = 0;
  do
  {
    uint64_t v26 = (void *)v24[4];
    if (v26[6] <= *(void *)(v17 + 48))
    {
      uint64_t v32 = (uint64_t *)(*(uint64_t (**)(void, void, void))(*v26 + 32))(v24[4], 0, 0);
      if ((void *)(a4 + 8) == std::__tree<ZinIrOpLayer *,ZinIrIdComparator<ZinIrOpLayer *>,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>(a4, (uint64_t *)&v32))
      {
        uint64_t v32 = 0;
        uint64_t v33 = 0;
        uint64_t v34 = 0;
        std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(&v32, (const void *)v26[14], v26[15], (uint64_t)(v26[15] - v26[14]) >> 3);
        unint64_t v27 = (ZinIrOpLayer **)v32;
        unint64_t v28 = v33;
        if (v32 != v33)
        {
          while (1)
          {
            uint64_t v37 = *v27;
            if (v23 != (void *)std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>((uint64_t)a2, &v37)&& *((void *)v37 + 6) > *(void *)(v17 + 48))
            {
              break;
            }
            if (++v27 == (ZinIrOpLayer **)v28) {
              goto LABEL_34;
            }
          }
          uint64_t v37 = (ZinIrOpLayer *)(*(uint64_t (**)(void *, void, void))(*v26 + 32))(v26, 0, 0);
          std::__tree<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const*>((uint64_t **)a4, (uint64_t *)&v37, (uint64_t *)&v37);
          char v25 = 1;
LABEL_34:
          unint64_t v27 = (ZinIrOpLayer **)v32;
        }
        if (v27)
        {
          uint64_t v33 = (uint64_t *)v27;
          operator delete(v27);
        }
      }
    }
    unint64_t v29 = (void *)v24[1];
    if (v29)
    {
      do
      {
        unint64_t v30 = v29;
        unint64_t v29 = (void *)*v29;
      }
      while (v29);
    }
    else
    {
      do
      {
        unint64_t v30 = (void *)v24[2];
        BOOL v22 = *v30 == (void)v24;
        uint64_t v24 = v30;
      }
      while (!v22);
    }
    uint64_t v24 = v30;
  }
  while (v30 != v23);
  if ((v25 & 1) == 0) {
LABEL_47:
  }
    ZinAssertImpl("Cluster subdividing algorithm failure");
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v35, v36[0]);
  return 1;
}

void sub_211288534(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11, uint64_t a12, char a13, void *a14)
{
}

BOOL PressureBasedSubgraphIdentification::AddBoundaryTensorsForAcyclicCluster(unsigned char *a1, void *a2, uint64_t **a3)
{
  uint64_t v38 = *MEMORY[0x263EF8340];
  if (!a2[2]) {
    return 0;
  }
  if (a1[73])
  {
    uint64_t v6 = PressureBasedSubgraphIdentification::ComputeTimeSpanOfCluster(a2);
    uint64_t v8 = v7;
    if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_INFO))
    {
      *(_DWORD *)long long buf = 134218240;
      *(void *)&void buf[4] = v6;
      *(_WORD *)&unsigned char buf[12] = 2048;
      *(void *)&buf[14] = v8;
      _os_log_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_INFO, "AddBoundaryTensorForLegalSchedule [%zu:%zu]", buf, 0x16u);
    }
    if (a1[74])
    {
      uint64_t v10 = (void *)*a2;
      if ((void *)*a2 != a2 + 1)
      {
        uint64_t v11 = &_os_log_internal;
        *(void *)&long long v9 = 136315394;
        long long v24 = v9;
        do
        {
          if (os_log_type_enabled(v11, OS_LOG_TYPE_INFO))
          {
            uint64_t v12 = v10[4];
            unint64_t v13 = (void *)(v12 + 24);
            if (*(char *)(v12 + 47) < 0) {
              unint64_t v13 = (void *)*v13;
            }
            uint64_t v14 = *(void *)(v12 + 48);
            *(_DWORD *)long long buf = v24;
            *(void *)&void buf[4] = v13;
            *(_WORD *)&unsigned char buf[12] = 2048;
            *(void *)&buf[14] = v14;
            _os_log_impl(&dword_210C72000, v11, OS_LOG_TYPE_INFO, "    Layer %s : %zu", buf, 0x16u);
          }
          uint64_t v15 = (void *)v10[1];
          if (v15)
          {
            do
            {
              uint64_t v16 = v15;
              uint64_t v15 = (void *)*v15;
            }
            while (v15);
          }
          else
          {
            do
            {
              uint64_t v16 = (void *)v10[2];
              BOOL v17 = *v16 == (void)v10;
              uint64_t v10 = v16;
            }
            while (!v17);
          }
          uint64_t v10 = v16;
        }
        while (v16 != a2 + 1);
      }
    }
  }
  uint64_t v34 = 0;
  uint64_t v35 = 0;
  uint64_t v32 = 0;
  uint64_t v33 = &v34;
  unint64_t v30 = &v31;
  unint64_t v31 = 0;
  (*(void (**)(unsigned char *, void *, uint64_t **, void ***, void ***))(*(void *)a1 + 200))(a1, a2, a3, &v33, &v30);
  if (!v35 || !v32) {
    ZinAssertImpl("Cannot have a cluster without input nodes and output nodes", v24);
  }
  memset(v29, 0, sizeof(v29));
  memset(v28, 0, sizeof(v28));
  memset(buf, 0, sizeof(buf));
  int v37 = 1065353216;
  unint64_t v18 = a2[2];
  long long __p = 0;
  std::vector<ZinIrOpLayer *>::vector(v27, v18, &__p);
  (*(void (**)(unsigned char *, void *, uint8_t *, void **))(*(void *)a1 + 208))(a1, a2, buf, v27);
  (*(void (**)(unsigned char *, void *, uint64_t **, uint8_t *, void **, void *, void *))(*(void *)a1 + 216))(a1, a2, a3, buf, v27, v29, v28);
  (*(void (**)(void **__return_ptr, unsigned char *, void *, void ***, void ***))(*(void *)a1 + 224))(&__p, a1, a2, &v33, &v30);
  int v19 = __p;
  BOOL v20 = __p != v26;
  if (__p != v26)
  {
    uint64_t v21 = PressureBasedSubgraphIdentification::AddBoundaryTensorsByForkJoinPairs(a1, (long long **)&__p, (uint64_t)buf, (uint64_t)v27, (uint64_t)v29, (uint64_t)v28, a3);
    if ((v21 & 1) == 0) {
      PressureBasedSubgraphIdentification::AddBoundaryTensorBySchedule(v21, a2, (uint64_t **)&__p, (uint64_t)a3);
    }
    int v19 = __p;
  }
  if (v19)
  {
    uint64_t v26 = v19;
    operator delete(v19);
  }
  if (v27[0])
  {
    v27[1] = v27[0];
    operator delete(v27[0]);
  }
  BOOL v22 = (void ***)std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)buf);
  *(void *)long long buf = v28;
  std::vector<std::vector<BOOL>>::__destroy_vector::operator()[abi:ne180100](v22);
  *(void *)long long buf = v29;
  std::vector<std::vector<BOOL>>::__destroy_vector::operator()[abi:ne180100]((void ***)buf);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v30, v31);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v33, v34);
  return v20;
}

void sub_211288944(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, void *__p, uint64_t a12, uint64_t a13, void *a14, uint64_t a15, uint64_t a16, char a17, uint64_t a18, uint64_t a19, char a20,uint64_t a21,uint64_t a22,char a23,void *a24,uint64_t a25,char a26,void *a27)
{
  if (__p) {
    operator delete(__p);
  }
  if (a14) {
    operator delete(a14);
  }
  unint64_t v29 = (void ***)std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table(v27 - 144);
  *(void *)(v27 - 144) = &a17;
  std::vector<std::vector<BOOL>>::__destroy_vector::operator()[abi:ne180100](v29);
  *(void *)(v27 - 144) = &a20;
  std::vector<std::vector<BOOL>>::__destroy_vector::operator()[abi:ne180100]((void ***)(v27 - 144));
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&a23, a24);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&a26, a27);
  _Unwind_Resume(a1);
}

uint64_t std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::emplace<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const>(uint64_t *a1, uint64_t *a2, ZinIrOpLayer ***a3)
{
  uint64_t v4 = (uint64_t)a2;
  uint64_t v6 = (uint64_t *)a1[1];
  unint64_t v9 = a1[2];
  uint64_t v7 = (uint64_t)(a1 + 2);
  unint64_t v8 = v9;
  if ((unint64_t)v6 >= v9)
  {
    uint64_t v13 = *a1;
    unint64_t v14 = 0xAAAAAAAAAAAAAAABLL * (((uint64_t)v6 - *a1) >> 3) + 1;
    if (v14 > 0xAAAAAAAAAAAAAAALL) {
      std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
    }
    unint64_t v15 = 0xAAAAAAAAAAAAAAABLL * (((uint64_t)a2 - v13) >> 3);
    unint64_t v16 = 0xAAAAAAAAAAAAAAABLL * ((uint64_t)(v8 - v13) >> 3);
    uint64_t v17 = 2 * v16;
    if (2 * v16 <= v14) {
      uint64_t v17 = v14;
    }
    if (v16 >= 0x555555555555555) {
      unint64_t v18 = 0xAAAAAAAAAAAAAAALL;
    }
    else {
      unint64_t v18 = v17;
    }
    uint64_t v25 = v7;
    if (v18) {
      int v19 = std::__allocate_at_least[abi:ne180100]<std::allocator<std::string>>(v7, v18);
    }
    else {
      int v19 = 0;
    }
    uint64_t v21 = v19;
    BOOL v22 = &v19[3 * v15];
    uint64_t v23 = v22;
    long long v24 = (char *)&v19[3 * v18];
    std::__split_buffer<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::emplace_back<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const>(&v21, a3);
    uint64_t v4 = std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::__swap_out_circular_buffer(a1, &v21, v4);
    std::__split_buffer<std::map<ZinIrDimension,unsigned long>>::~__split_buffer((void **)&v21);
  }
  else if (a2 == v6)
  {
    std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::set[abi:ne180100](a2, a3);
    a1[1] = v4 + 24;
  }
  else
  {
    long long v24 = (char *)v7;
    std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::set[abi:ne180100]((uint64_t *)&v21, a3);
    std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::__move_range((uint64_t)a1, (void *)v4, a1[1], v4 + 24);
    uint64_t v10 = v4 + 8;
    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy(v4, *(void **)(v4 + 8));
    *(void *)uint64_t v4 = v21;
    uint64_t v11 = v22;
    *(void *)(v4 + 8) = v22;
    uint64_t v12 = v23;
    *(void *)(v4 + 16) = v23;
    if (v12)
    {
      v11[2] = v10;
      uint64_t v21 = &v22;
      BOOL v22 = 0;
      uint64_t v23 = 0;
      uint64_t v11 = 0;
    }
    else
    {
      *(void *)uint64_t v4 = v10;
    }
    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v21, v11);
  }
  return v4;
}

void sub_211288B70(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, char a10, uint64_t a11)
{
  *(void *)(v12 + 8) = v11;
  _Unwind_Resume(exception_object);
}

uint64_t PressureBasedSubgraphIdentification::RemoveInputAndOutputNoopsOfCluster@<X0>(void *a1@<X0>, ZinIrOpLayer ***a2@<X1>, uint64_t *a3@<X8>)
{
  *a3 = 0;
  a3[1] = 0;
  a3[2] = 0;
  long long v35 = 0u;
  memset(&v34, 0, 32);
  std::deque<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::push_back(&v34, a2);
  while (*((void *)&v35 + 1))
  {
    std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::set[abi:ne180100]((uint64_t *)v33, (ZinIrOpLayer ***)(*(void *)(v34.i64[1] + 8 * ((unint64_t)v35 / 0xAA))+ 24 * ((unint64_t)v35 % 0xAA)));
    uint64_t v6 = v33[2];
    std::deque<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::pop_front(&v34);
    v32[0] = 0;
    v32[1] = 0;
    unint64_t v31 = v32;
    v30[0] = 0;
    v30[1] = 0;
    unint64_t v29 = v30;
    v28[0] = 0;
    v28[1] = 0;
    uint64_t v27 = v28;
    (*(void (**)(void *, uint64_t **, void ***, void ***, void ***))(*a1 + 200))(a1, v33, &v31, &v29, &v27);
    uint64_t v7 = v29;
    if (v29 != v30)
    {
      do
      {
        v36[0] = (void **)v7[4];
        long long __p = 0;
        uint64_t v25 = 0;
        uint64_t v26 = 0;
        char IsNoOp = ZinIrOpLayer::IsNoOp((ZinIrOpLayer *)v36[0], (uint64_t *)&__p);
        if (__p)
        {
          uint64_t v25 = (ZinIrOpLayer ***)__p;
          operator delete(__p);
        }
        if ((IsNoOp & 1) != 0
          && (*(unsigned char *)(a1[8] + 8) || *((_DWORD *)v36[0][8] + 2) != 35)
          && (PressureBasedSubgraphIdentification::IsPartialInput((uint64_t)a2, (uint64_t)v36[0]) & 1) == 0)
        {
          std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__erase_unique<ZinIrOpLayer *>(v33, (ZinIrOpLayer **)v36);
        }
        unint64_t v9 = v7[1];
        if (v9)
        {
          do
          {
            uint64_t v10 = (void **)v9;
            unint64_t v9 = (void *)*v9;
          }
          while (v9);
        }
        else
        {
          do
          {
            uint64_t v10 = (void **)v7[2];
            BOOL v11 = *v10 == v7;
            uint64_t v7 = v10;
          }
          while (!v11);
        }
        uint64_t v7 = v10;
      }
      while (v10 != v30);
    }
    uint64_t v12 = v27;
    if (v27 != v28)
    {
      do
      {
        v36[0] = (void **)v12[4];
        long long __p = 0;
        uint64_t v25 = 0;
        uint64_t v26 = 0;
        int v13 = ZinIrOpLayer::IsNoOp((ZinIrOpLayer *)v36[0], (uint64_t *)&__p);
        if (__p)
        {
          uint64_t v25 = (ZinIrOpLayer ***)__p;
          operator delete(__p);
        }
        if (v13) {
          std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__erase_unique<ZinIrOpLayer *>(v33, (ZinIrOpLayer **)v36);
        }
        unint64_t v14 = v12[1];
        if (v14)
        {
          do
          {
            unint64_t v15 = (void **)v14;
            unint64_t v14 = (void *)*v14;
          }
          while (v14);
        }
        else
        {
          do
          {
            unint64_t v15 = (void **)v12[2];
            BOOL v11 = *v15 == v12;
            uint64_t v12 = v15;
          }
          while (!v11);
        }
        uint64_t v12 = v15;
      }
      while (v15 != v28);
    }
    long long __p = 0;
    uint64_t v25 = 0;
    uint64_t v26 = 0;
    PressureBasedSubgraphIdentification::IdentifyConnectedClusters((uint64_t)a1, v33, (uint64_t)&v31, (uint64_t *)&__p);
    unint64_t v16 = (ZinIrOpLayer ***)__p;
    uint64_t v17 = v25;
    if ((char *)v25 - (unsigned char *)__p == 24 && *((uint64_t **)__p + 2) == v6)
    {
      unint64_t v18 = a3[1];
      if (v18 >= a3[2])
      {
        uint64_t v19 = std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::__push_back_slow_path<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const&>(a3, (ZinIrOpLayer ***)v33);
      }
      else
      {
        std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::set[abi:ne180100]((uint64_t *)a3[1], (ZinIrOpLayer ***)v33);
        uint64_t v19 = v18 + 24;
        a3[1] = v18 + 24;
      }
      a3[1] = v19;
    }
    else
    {
      while (v16 != v17)
      {
        std::deque<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::push_back(&v34, v16);
        v16 += 3;
      }
    }
    uint64_t v21 = (ZinIrOpLayer ***)__p;
    BOOL v20 = v25;
    if (v25 != __p)
    {
      do
      {
        BOOL v22 = v20 - 3;
        std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)(v20 - 3), *(v20 - 2));
        BOOL v20 = v22;
      }
      while (v22 != v21);
    }
    uint64_t v25 = v21;
    v36[0] = &__p;
    std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100](v36);
    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v27, v28[0]);
    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v29, v30[0]);
    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v31, v32[0]);
    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v33, v33[1]);
  }
  return std::deque<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::~deque[abi:ne180100](&v34);
}

void sub_211288EF4(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11, uint64_t a12, char a13, uint64_t a14, uint64_t a15, char a16, uint64_t a17, uint64_t a18, char a19, uint64_t a20,uint64_t a21,char a22,uint64_t a23,uint64_t a24,uint64_t a25)
{
}

uint64_t PressureBasedSubgraphIdentification::IsPartialInput(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = *(ZinIrOpLayer ***)(a2 + 88);
  uint64_t v3 = *(ZinIrOpLayer ***)(a2 + 96);
  if (v2 == v3)
  {
    char v9 = 0;
  }
  else
  {
    char v5 = 0;
    char v6 = 0;
    do
    {
      uint64_t v7 = *v2++;
      BOOL v11 = v7;
      uint64_t v8 = std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>(a1, &v11);
      v6 |= v8 == 0;
      v5 |= v8 != 0;
    }
    while (v2 != v3);
    char v9 = v5 & v6;
  }
  return v9 & 1;
}

void PressureBasedSubgraphIdentification::CutClusterForRingBufferWriter(void *a1@<X0>, ZinIrOpLayer ****a2@<X1>, uint64_t *a3@<X8>)
{
  unint64_t v68 = (ZinIrOpLayer **)*MEMORY[0x263EF8340];
  v63[0] = 0;
  v63[1] = 0;
  unint64_t v62 = (uint64_t *)v63;
  v61[0] = 0;
  v61[1] = 0;
  v59[1] = 0;
  uint64_t v60 = (uint64_t *)v61;
  uint64_t v58 = (uint64_t *)v59;
  v59[0] = 0;
  v57[0] = 0;
  v57[1] = 0;
  v55[1] = 0;
  uint64_t v56 = (uint64_t *)v57;
  uint64_t v54 = v55;
  v55[0] = 0;
  v53[0] = 0;
  v53[1] = 0;
  v51[1] = 0;
  unint64_t v52 = v53;
  uint64_t v50 = v51;
  v51[0] = 0;
  (*(void (**)(void *, ZinIrOpLayer ****, void ***, void ***, void ***))(*a1 + 200))(a1, a2, &v54, &v52, &v50);
  uint64_t v4 = v52;
  if (v52 != v53)
  {
    do
    {
      uint64_t v64 = (ZinIrOpLayer *)v4[4];
      char v5 = (void *)*((void *)v64 + 11);
      char v6 = (void *)*((void *)v64 + 12);
      while (v5 != v6)
      {
        uint64_t v7 = (uint64_t *)(*(uint64_t (**)(void, void, void))(*(void *)*v5 + 32))(*v5, 0, 0);
        if (v7)
        {
          while (*(_DWORD *)(*(void *)(v7[12] + 64) + 8) != 75)
          {
            ZinIrTensor::GetParentTensor((ZinIrTensor *)v7, &p_RootTensor);
            uint64_t v7 = (uint64_t *)p_RootTensor;
            if (v67) {
              std::__shared_weak_count::__release_shared[abi:ne180100](v67);
            }
            if (v7)
            {
              p_RootTensor = (ZinIrTensor **)v7[12];
              if (a2 + 1 == (ZinIrOpLayer ****)std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>((uint64_t)a2, (ZinIrOpLayer **)&p_RootTensor))continue; {
            }
              }
            goto LABEL_12;
          }
          int v49 = (ZinIrOpLayer *)v7[12];
          p_RootTensor = &v49;
          uint64_t v8 = std::__tree<std::__value_type<ZinIrOpLayer *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>,std::__map_value_compare<ZinIrOpLayer *,std::__value_type<ZinIrOpLayer *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>,ScheduleComparator,true>,std::allocator<std::__value_type<ZinIrOpLayer *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer * const&>,std::tuple<>>(&v60, &v49, (uint64_t)&std::piecewise_construct, (uint64_t **)&p_RootTensor);
          std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>((uint64_t **)v8 + 5, &v64, (uint64_t *)&v64);
          RootTensor = 0;
          RootTensor = ZinIrTensor::GetRootTensor((ZinIrTensor *)v7);
          p_RootTensor = &RootTensor;
          char v9 = std::__tree<std::__value_type<ZinIrTensor *,std::set<ZinRingBufferWriterLayer *,ScheduleComparator,std::allocator<ZinRingBufferWriterLayer *>>>,std::__map_value_compare<ZinIrTensor *,std::__value_type<ZinIrTensor *,std::set<ZinRingBufferWriterLayer *,ScheduleComparator,std::allocator<ZinRingBufferWriterLayer *>>>,ZinIrIdComparator<ZinIrTensor *>,true>,std::allocator<std::__value_type<ZinIrTensor *,std::set<ZinRingBufferWriterLayer *,ScheduleComparator,std::allocator<ZinRingBufferWriterLayer *>>>>>::__emplace_unique_key_args<ZinIrTensor *,std::piecewise_construct_t const&,std::tuple<ZinIrTensor * const&>,std::tuple<>>(&v56, (uint64_t *)&RootTensor, (uint64_t)&std::piecewise_construct, (uint64_t **)&p_RootTensor);
          std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>((uint64_t **)v9 + 5, &v49, (uint64_t *)&v49);
        }
LABEL_12:
        ++v5;
      }
      uint64_t v10 = (void *)v4[1];
      if (v10)
      {
        do
        {
          BOOL v11 = (void **)v10;
          uint64_t v10 = (void *)*v10;
        }
        while (v10);
      }
      else
      {
        do
        {
          BOOL v11 = (void **)v4[2];
          BOOL v12 = *v11 == v4;
          uint64_t v4 = v11;
        }
        while (!v12);
      }
      uint64_t v4 = v11;
    }
    while (v11 != v53);
  }
  int v13 = v50;
  if (v50 != v51)
  {
    do
    {
      uint64_t v64 = (ZinIrOpLayer *)v13[4];
      unint64_t v14 = (uint64_t *)(*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)v64 + 32))(v64, 0, 0);
      if (v14)
      {
        while (*(_DWORD *)(*(void *)(v14[12] + 64) + 8) != 75)
        {
          ZinIrTensor::GetParentTensor((ZinIrTensor *)v14, &p_RootTensor);
          unint64_t v14 = (uint64_t *)p_RootTensor;
          if (v67) {
            std::__shared_weak_count::__release_shared[abi:ne180100](v67);
          }
          if (!v14) {
            goto LABEL_27;
          }
        }
        int v49 = (ZinIrOpLayer *)v14[12];
        p_RootTensor = &v49;
        unint64_t v15 = std::__tree<std::__value_type<ZinIrOpLayer *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>,std::__map_value_compare<ZinIrOpLayer *,std::__value_type<ZinIrOpLayer *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>,ScheduleComparator,true>,std::allocator<std::__value_type<ZinIrOpLayer *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer * const&>,std::tuple<>>(&v62, &v49, (uint64_t)&std::piecewise_construct, (uint64_t **)&p_RootTensor);
        std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>((uint64_t **)v15 + 5, &v64, (uint64_t *)&v64);
        RootTensor = 0;
        RootTensor = ZinIrTensor::GetRootTensor((ZinIrTensor *)v14);
        p_RootTensor = &RootTensor;
        unint64_t v16 = std::__tree<std::__value_type<ZinIrTensor *,std::set<ZinRingBufferWriterLayer *,ScheduleComparator,std::allocator<ZinRingBufferWriterLayer *>>>,std::__map_value_compare<ZinIrTensor *,std::__value_type<ZinIrTensor *,std::set<ZinRingBufferWriterLayer *,ScheduleComparator,std::allocator<ZinRingBufferWriterLayer *>>>,ZinIrIdComparator<ZinIrTensor *>,true>,std::allocator<std::__value_type<ZinIrTensor *,std::set<ZinRingBufferWriterLayer *,ScheduleComparator,std::allocator<ZinRingBufferWriterLayer *>>>>>::__emplace_unique_key_args<ZinIrTensor *,std::piecewise_construct_t const&,std::tuple<ZinIrTensor * const&>,std::tuple<>>(&v58, (uint64_t *)&RootTensor, (uint64_t)&std::piecewise_construct, (uint64_t **)&p_RootTensor);
        std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>((uint64_t **)v16 + 5, &v49, (uint64_t *)&v49);
      }
LABEL_27:
      uint64_t v17 = (void *)v13[1];
      if (v17)
      {
        do
        {
          unint64_t v18 = (void **)v17;
          uint64_t v17 = (void *)*v17;
        }
        while (v17);
      }
      else
      {
        do
        {
          unint64_t v18 = (void **)v13[2];
          BOOL v12 = *v18 == v13;
          int v13 = v18;
        }
        while (!v12);
      }
      int v13 = v18;
    }
    while (v18 != v51);
  }
  uint64_t v19 = v56;
  if (v56 == (uint64_t *)v57) {
    goto LABEL_49;
  }
  while ((unint64_t)v19[7] <= 1)
  {
    BOOL v20 = (uint64_t *)v19[1];
    if (v20)
    {
      do
      {
        uint64_t v21 = v20;
        BOOL v20 = (uint64_t *)*v20;
      }
      while (v20);
    }
    else
    {
      do
      {
        uint64_t v21 = (uint64_t *)v19[2];
        BOOL v12 = *v21 == (void)v19;
        uint64_t v19 = v21;
      }
      while (!v12);
    }
    uint64_t v19 = v21;
    if (v21 == (uint64_t *)v57) {
      goto LABEL_49;
    }
  }
  if (v19 == (uint64_t *)v57)
  {
LABEL_49:
    unint64_t v28 = v58;
    if (v58 != (uint64_t *)v59)
    {
      unint64_t v29 = v58;
      while ((unint64_t)v29[7] <= 1)
      {
        unint64_t v30 = (uint64_t *)v29[1];
        if (v30)
        {
          do
          {
            unint64_t v31 = v30;
            unint64_t v30 = (uint64_t *)*v30;
          }
          while (v30);
        }
        else
        {
          do
          {
            unint64_t v31 = (uint64_t *)v29[2];
            BOOL v12 = *v31 == (void)v29;
            unint64_t v29 = v31;
          }
          while (!v12);
        }
        unint64_t v29 = v31;
        if (v31 == (uint64_t *)v59) {
          goto LABEL_67;
        }
      }
      if (v29 != (uint64_t *)v59)
      {
        std::set<ZinRingBufferWriterLayer *,ScheduleComparator,std::allocator<ZinRingBufferWriterLayer *>>::set[abi:ne180100]((uint64_t *)&p_RootTensor, (ZinIrOpLayer ***)v29 + 5);
        uint64_t v32 = (uint64_t *)p_RootTensor;
        uint64_t v64 = p_RootTensor[4];
        uint64_t v33 = p_RootTensor[1];
        if (v33)
        {
          do
          {
            int64x2_t v34 = (uint64_t *)v33;
            uint64_t v33 = *(ZinIrTensor **)v33;
          }
          while (v33);
        }
        else
        {
          do
          {
            int64x2_t v34 = (uint64_t *)v32[2];
            BOOL v12 = *v34 == (void)v32;
            uint64_t v32 = v34;
          }
          while (!v12);
        }
        int v49 = (ZinIrOpLayer *)v34[4];
        long long v35 = (void *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)&v62, &v64);
        uint64_t v36 = (void *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)&v62, &v49);
        int v37 = (ZinIrOpLayer **)PressureBasedSubgraphIdentification::CutClusterForRingBufferWriter(std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const&)const::$_3::operator()(v35, v36);
        PressureBasedSubgraphIdentification::CutClusterAtLayer(a1, a2, v37, a3);
        goto LABEL_66;
      }
LABEL_67:
      if (v58 != (uint64_t *)v59)
      {
        while (v57 == std::__tree<ZinIrOpLayer *,ZinIrIdComparator<ZinIrOpLayer *>,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>((uint64_t)&v56, v28 + 4))
        {
          uint64_t v38 = (uint64_t *)v28[1];
          if (v38)
          {
            do
            {
              unint64_t v39 = v38;
              uint64_t v38 = (uint64_t *)*v38;
            }
            while (v38);
          }
          else
          {
            do
            {
              unint64_t v39 = (uint64_t *)v28[2];
              BOOL v12 = *v39 == (void)v28;
              unint64_t v28 = v39;
            }
            while (!v12);
          }
          unint64_t v28 = v39;
          if (v39 == (uint64_t *)v59) {
            goto LABEL_78;
          }
        }
        if (v28 != (uint64_t *)v59)
        {
          p_RootTensor = (ZinIrTensor **)v28[4];
          uint64_t v40 = std::map<ZinIrOpLayer *,long,ZinIrIdComparator<ZinIrOpLayer *>,std::allocator<std::pair<ZinIrOpLayer * const,long>>>::at((uint64_t)&v58, (uint64_t *)&p_RootTensor);
          uint64_t v41 = (void *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)&v62, (ZinIrOpLayer **)(*(void *)v40 + 32));
          uint64_t v42 = std::map<ZinIrOpLayer *,long,ZinIrIdComparator<ZinIrOpLayer *>,std::allocator<std::pair<ZinIrOpLayer * const,long>>>::at((uint64_t)&v56, (uint64_t *)&p_RootTensor);
          uint64_t v43 = (void *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)&v60, (ZinIrOpLayer **)(*(void *)v42 + 32));
          uint64_t v44 = (ZinIrOpLayer **)PressureBasedSubgraphIdentification::CutClusterForRingBufferWriter(std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const&)const::$_3::operator()(v41, v43);
          PressureBasedSubgraphIdentification::CutClusterAtLayer(a1, a2, v44, a3);
          goto LABEL_79;
        }
      }
    }
LABEL_78:
    std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::set[abi:ne180100]((uint64_t *)&p_RootTensor, (ZinIrOpLayer ***)a2);
    *a3 = 0;
    a3[1] = 0;
    a3[2] = 0;
    uint64_t v64 = (ZinIrOpLayer *)a3;
    char v65 = 0;
    unint64_t v45 = (uint64_t *)operator new(0x18uLL);
    *a3 = (uint64_t)v45;
    a3[1] = (uint64_t)v45;
    a3[2] = (uint64_t)(v45 + 3);
    a3[1] = (uint64_t)std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const*,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const*,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>((uint64_t)(a3 + 2), &p_RootTensor, &v68, v45);
    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&p_RootTensor, v67);
  }
  else
  {
    std::set<ZinRingBufferWriterLayer *,ScheduleComparator,std::allocator<ZinRingBufferWriterLayer *>>::set[abi:ne180100]((uint64_t *)&p_RootTensor, (ZinIrOpLayer ***)v19 + 5);
    BOOL v22 = (uint64_t *)p_RootTensor;
    uint64_t v64 = p_RootTensor[4];
    uint64_t v23 = p_RootTensor[1];
    if (v23)
    {
      do
      {
        long long v24 = (uint64_t *)v23;
        uint64_t v23 = *(ZinIrTensor **)v23;
      }
      while (v23);
    }
    else
    {
      do
      {
        long long v24 = (uint64_t *)v22[2];
        BOOL v12 = *v24 == (void)v22;
        BOOL v22 = v24;
      }
      while (!v12);
    }
    int v49 = (ZinIrOpLayer *)v24[4];
    uint64_t v25 = (void *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)&v60, &v64);
    uint64_t v26 = (void *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)&v60, &v49);
    uint64_t v27 = (ZinIrOpLayer **)PressureBasedSubgraphIdentification::CutClusterForRingBufferWriter(std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const&)const::$_3::operator()(v25, v26);
    PressureBasedSubgraphIdentification::CutClusterAtLayer(a1, a2, v27, a3);
LABEL_66:
    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&p_RootTensor, v67);
  }
LABEL_79:
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v50, v51[0]);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v52, v53[0]);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v54, v55[0]);
  std::__tree<std::__value_type<int,std::set<ZinIrInitInfo const*>>,std::__map_value_compare<int,std::__value_type<int,std::set<ZinIrInitInfo const*>>,std::less<int>,true>,std::allocator<std::__value_type<int,std::set<ZinIrInitInfo const*>>>>::destroy((uint64_t)&v56, v57[0]);
  std::__tree<std::__value_type<int,std::set<ZinIrInitInfo const*>>,std::__map_value_compare<int,std::__value_type<int,std::set<ZinIrInitInfo const*>>,std::less<int>,true>,std::allocator<std::__value_type<int,std::set<ZinIrInitInfo const*>>>>::destroy((uint64_t)&v58, v59[0]);
  std::__tree<std::__value_type<int,std::set<ZinIrInitInfo const*>>,std::__map_value_compare<int,std::__value_type<int,std::set<ZinIrInitInfo const*>>,std::less<int>,true>,std::allocator<std::__value_type<int,std::set<ZinIrInitInfo const*>>>>::destroy((uint64_t)&v60, v61[0]);
  std::__tree<std::__value_type<int,std::set<ZinIrInitInfo const*>>,std::__map_value_compare<int,std::__value_type<int,std::set<ZinIrInitInfo const*>>,std::less<int>,true>,std::allocator<std::__value_type<int,std::set<ZinIrInitInfo const*>>>>::destroy((uint64_t)&v62, v63[0]);
}

void sub_211289758(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, char a16, void *a17, uint64_t a18, char a19, void *a20,uint64_t a21,char a22,void *a23,uint64_t a24,char a25,void *a26,uint64_t a27,char a28,void *a29,uint64_t a30,char a31,void *a32)
{
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&a16, a17);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&a19, a20);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&a22, a23);
  std::__tree<std::__value_type<int,std::set<ZinIrInitInfo const*>>,std::__map_value_compare<int,std::__value_type<int,std::set<ZinIrInitInfo const*>>,std::less<int>,true>,std::allocator<std::__value_type<int,std::set<ZinIrInitInfo const*>>>>::destroy((uint64_t)&a25, a26);
  std::__tree<std::__value_type<int,std::set<ZinIrInitInfo const*>>,std::__map_value_compare<int,std::__value_type<int,std::set<ZinIrInitInfo const*>>,std::less<int>,true>,std::allocator<std::__value_type<int,std::set<ZinIrInitInfo const*>>>>::destroy((uint64_t)&a28, a29);
  std::__tree<std::__value_type<int,std::set<ZinIrInitInfo const*>>,std::__map_value_compare<int,std::__value_type<int,std::set<ZinIrInitInfo const*>>,std::less<int>,true>,std::allocator<std::__value_type<int,std::set<ZinIrInitInfo const*>>>>::destroy((uint64_t)&a31, a32);
  std::__tree<std::__value_type<int,std::set<ZinIrInitInfo const*>>,std::__map_value_compare<int,std::__value_type<int,std::set<ZinIrInitInfo const*>>,std::less<int>,true>,std::allocator<std::__value_type<int,std::set<ZinIrInitInfo const*>>>>::destroy(v32 - 168, *(void **)(v32 - 160));
  _Unwind_Resume(a1);
}

void PressureBasedSubgraphIdentification::CutClusterAtLayer(void *a1@<X0>, ZinIrOpLayer ****a2@<X1>, ZinIrOpLayer **a3@<X2>, uint64_t *a4@<X8>)
{
  uint64_t v26 = (ZinIrOpLayer **)*MEMORY[0x263EF8340];
  if (a3)
  {
    v21[0] = 0;
    v21[1] = 0;
    v19[1] = 0;
    BOOL v20 = (ZinIrOpLayer **)v21;
    unint64_t v18 = (ZinIrOpLayer **)v19;
    v19[0] = 0;
    char v6 = a2 + 1;
    uint64_t v7 = *a2;
    if (*a2 != (ZinIrOpLayer ***)(a2 + 1))
    {
      char v9 = 1;
      do
      {
        v24[0] = v7[4];
        if (v9) {
          uint64_t v10 = &v20;
        }
        else {
          uint64_t v10 = &v18;
        }
        std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>((uint64_t **)v10, (ZinIrOpLayer **)v24, (uint64_t *)v24);
        BOOL v11 = v7[1];
        if (v11)
        {
          do
          {
            BOOL v12 = (ZinIrOpLayer ****)v11;
            BOOL v11 = (ZinIrOpLayer **)*v11;
          }
          while (v11);
        }
        else
        {
          do
          {
            BOOL v12 = (ZinIrOpLayer ****)v7[2];
            BOOL v13 = *v12 == v7;
            uint64_t v7 = (ZinIrOpLayer ***)v12;
          }
          while (!v13);
        }
        v9 &= v24[0] != a3;
        uint64_t v7 = (ZinIrOpLayer ***)v12;
      }
      while (v12 != v6);
    }
    std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::set[abi:ne180100]((uint64_t *)v24, &v20);
    std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::set[abi:ne180100](v25, &v18);
    unint64_t v15 = 0;
    unint64_t v16 = 0;
    uint64_t v17 = 0;
    BOOL v22 = &v15;
    char v23 = 0;
    unint64_t v15 = (ZinIrOpLayer ***)operator new(0x30uLL);
    unint64_t v16 = (uint64_t *)v15;
    uint64_t v17 = v15 + 6;
    unint64_t v16 = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const*,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const*,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>((uint64_t)&v17, v24, &v26, (uint64_t *)v15);
    PressureBasedSubgraphIdentification::RemoveInputAndOutputNoopsOfClusters(a1, &v15, a4);
    BOOL v22 = &v15;
    std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v22);
    for (uint64_t i = 0; i != -6; i -= 3)
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v24[i + 3], (void *)v25[i + 1]);
    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v18, v19[0]);
    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v20, v21[0]);
  }
  else
  {
    *a4 = 0;
    a4[1] = 0;
    a4[2] = 0;
  }
}

void sub_211289A1C(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, char a12, void *a13, uint64_t a14, char a15, void *a16, uint64_t a17, void **a18, uint64_t a19, char a20)
{
  std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100](&a18);
  for (uint64_t i = 0; i != -48; i -= 24)
    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)(&a20 + i + 24), *(void **)(&a20 + i + 32));
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&a12, a13);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&a15, a16);
  _Unwind_Resume(a1);
}

uint64_t PressureBasedSubgraphIdentification::CutClusterForRingBufferWriter(std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const&)const::$_3::operator()(void *a1, void *a2)
{
  if (a1[2]) {
    BOOL v2 = a2[2] == 0;
  }
  else {
    BOOL v2 = 1;
  }
  if (v2
    || (!ScheduleComparator::operator()((int)&v17, *(ZinIrOpLayer **)(*a1 + 32), *(ZinIrOpLayer **)(*a2 + 32))
      ? (char v5 = a2)
      : (char v5 = a1),
        char v6 = v5 + 1,
        v5 + 1 == (void *)*v5))
  {
LABEL_22:
    ZinAssertImpl("Internal Pressure Analysis Error");
  }
  while (1)
  {
    uint64_t v7 = (void *)*v6;
    uint64_t v8 = v6;
    if (*v6)
    {
      do
      {
        char v9 = v7;
        uint64_t v7 = (void *)v7[1];
      }
      while (v7);
    }
    else
    {
      do
      {
        char v9 = (void *)v8[2];
        BOOL v2 = *v9 == (void)v8;
        uint64_t v8 = v9;
      }
      while (v2);
    }
    uint64_t v10 = (ZinIrOpLayer *)v9[4];
    BOOL v11 = v5 == a1 ? a2 : a1;
    BOOL v12 = ScheduleComparator::operator()((int)&v17, v10, *(ZinIrOpLayer **)(*v11 + 32));
    BOOL v13 = (void *)*v6;
    if (v12) {
      break;
    }
    if (v13)
    {
      do
      {
        unint64_t v14 = v13;
        BOOL v13 = (void *)v13[1];
      }
      while (v13);
    }
    else
    {
      do
      {
        unint64_t v14 = (void *)v6[2];
        BOOL v2 = *v14 == (void)v6;
        char v6 = v14;
      }
      while (v2);
    }
    char v6 = v14;
    if (v14 == (void *)*v5) {
      goto LABEL_22;
    }
  }
  if (v13)
  {
    do
    {
      unint64_t v15 = v13;
      BOOL v13 = (void *)v13[1];
    }
    while (v13);
  }
  else
  {
    do
    {
      unint64_t v15 = (void *)v6[2];
      BOOL v2 = *v15 == (void)v6;
      char v6 = v15;
    }
    while (v2);
  }
  return v15[4];
}

void PressureBasedSubgraphIdentification::CutClusterAtConcatWithPartialInputs(uint64_t a1, void *a2, uint64_t a3)
{
  uint64_t v37 = *MEMORY[0x263EF8340];
  unint64_t v29 = 0;
  unint64_t v30 = 0;
  uint64_t v31 = 0;
  uint64_t v27 = 0;
  uint64_t v28 = 0;
  uint64_t v26 = (ZinIrOpLayer ****)&v27;
  uint64_t v7 = a2 + 1;
  char v6 = (void *)*a2;
  if ((void *)*a2 == a2 + 1)
  {
    uint64_t v10 = (unsigned char *)(a1 + 73);
  }
  else
  {
    do
    {
      *(void *)long long buf = v6[4];
      if (PressureBasedSubgraphIdentification::IsPartialInput((uint64_t)a2, *(uint64_t *)buf)
        && *(_DWORD *)(*(void *)(*(void *)buf + 64) + 8) == 7)
      {
        std::__tree<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const*>((uint64_t **)&v26, (uint64_t *)buf, (uint64_t *)buf);
      }
      uint64_t v8 = (void *)v6[1];
      if (v8)
      {
        do
        {
          char v9 = v8;
          uint64_t v8 = (void *)*v8;
        }
        while (v8);
      }
      else
      {
        do
        {
          char v9 = (void *)v6[2];
          BOOL v12 = *v9 == (void)v6;
          char v6 = v9;
        }
        while (!v12);
      }
      char v6 = v9;
    }
    while (v9 != v7);
    int v11 = *(unsigned __int8 *)(a1 + 73);
    uint64_t v10 = (unsigned char *)(a1 + 73);
    if (v11) {
      BOOL v12 = v28 == 0;
    }
    else {
      BOOL v12 = 1;
    }
    if (!v12)
    {
      uint64_t v13 = PressureBasedSubgraphIdentification::ComputeTimeSpanOfCluster(a2);
      uint64_t v15 = v14;
      if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_INFO))
      {
        *(_DWORD *)long long buf = 134218240;
        *(void *)&void buf[4] = v13;
        *(_WORD *)&unsigned char buf[12] = 2048;
        *(void *)&buf[14] = v15;
        _os_log_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_INFO, "\tCutting Cluster [%zu,%zu] at Concat With Partial Input", buf, 0x16u);
      }
    }
  }
  *(_OWORD *)&uint8_t buf[8] = 0uLL;
  *(void *)long long buf = &buf[8];
  std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::emplace_back<>((uint64_t *)&v29);
  unint64_t v16 = (void *)*a2;
  if ((void *)*a2 != v7)
  {
    char v17 = &_os_log_internal;
    do
    {
      uint64_t v25 = (ZinIrOpLayer *)v16[4];
      if (&v27 == std::__tree<ZinIrOpLayer *,ZinIrIdComparator<ZinIrOpLayer *>,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>((uint64_t)&v26, (uint64_t *)&v25))
      {
        std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>((uint64_t **)v30 - 3, &v25, (uint64_t *)&v25);
      }
      else
      {
        if (*v10 && os_log_type_enabled(v17, OS_LOG_TYPE_INFO))
        {
          unint64_t v18 = (void *)((char *)v25 + 24);
          if (*((char *)v25 + 47) < 0) {
            unint64_t v18 = (void *)*v18;
          }
          uint64_t v19 = *((void *)v25 + 6);
          *(_DWORD *)uint64_t v32 = 136315394;
          uint64_t v33 = v18;
          __int16 v34 = 2048;
          uint64_t v35 = v19;
          _os_log_impl(&dword_210C72000, v17, OS_LOG_TYPE_INFO, "\t\tCutting Cluster at Partial Input %s : %zu", v32, 0x16u);
        }
        std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::emplace_back<>((uint64_t *)&v29);
      }
      BOOL v20 = (void *)v16[1];
      if (v20)
      {
        do
        {
          uint64_t v21 = v20;
          BOOL v20 = (void *)*v20;
        }
        while (v20);
      }
      else
      {
        do
        {
          uint64_t v21 = (void *)v16[2];
          BOOL v12 = *v21 == (void)v16;
          unint64_t v16 = v21;
        }
        while (!v12);
      }
      unint64_t v16 = v21;
    }
    while (v21 != v7);
  }
  BOOL v22 = v30;
  if (v29 == v30)
  {
LABEL_39:
    long long v24 = v30;
  }
  else
  {
    char v23 = v29 + 3;
    while (*(v23 - 1))
    {
      BOOL v12 = v23 == v30;
      v23 += 3;
      if (v12) {
        goto LABEL_39;
      }
    }
    long long v24 = v23 - 3;
    if (v23 - 3 != v30 && v23 != v30)
    {
      do
      {
        if (v23[2])
        {
          std::__tree<ZinSpaceRange>::__move_assign((uint64_t)v24, v23);
          v24 += 3;
        }
        v23 += 3;
      }
      while (v23 != v22);
      BOOL v22 = v30;
    }
  }
  std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::erase((uint64_t)&v29, (uint64_t)v24, v22);
  std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::__insert_with_size[abi:ne180100]<std::__wrap_iter<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>,std::__wrap_iter<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>>((uint64_t *)a3, *(uint64_t ***)(a3 + 8), v29, v30, 0xAAAAAAAAAAAAAAABLL * (v30 - v29));
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)buf, *(void **)&buf[8]);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v26, v27);
  uint64_t v26 = &v29;
  std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v26);
}

void sub_211289F60(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, void **a13, void *a14, uint64_t a15, char a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,char a23,void *a24)
{
  a13 = (void **)&a16;
  std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100](&a13);
  _Unwind_Resume(a1);
}

void PressureBasedSubgraphIdentification::CutClusterAtPartialOutputs(uint64_t a1, ZinIrOpLayer ***a2, uint64_t a3)
{
  uint64_t v41 = *MEMORY[0x263EF8340];
  std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::set[abi:ne180100](v35, a2);
  uint64_t v32 = 0;
  uint64_t v33 = 0;
  uint64_t v34 = 0;
  unint64_t v30 = 0;
  uint64_t v31 = 0;
  unint64_t v29 = (ZinIrOpLayer ****)&v30;
  char v6 = *a2;
  if (*a2 == (ZinIrOpLayer **)(a2 + 1))
  {
    char v9 = (unsigned char *)(a1 + 73);
  }
  else
  {
    do
    {
      *(void *)long long buf = v6[4];
      if (PressureBasedSubgraphIdentification::IsPartialOutput((uint64_t)a2, *(uint64_t *)buf)) {
        std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>((uint64_t **)&v29, (ZinIrOpLayer **)buf, (uint64_t *)buf);
      }
      uint64_t v7 = v6[1];
      if (v7)
      {
        do
        {
          uint64_t v8 = (ZinIrOpLayer ***)v7;
          uint64_t v7 = *(ZinIrOpLayer **)v7;
        }
        while (v7);
      }
      else
      {
        do
        {
          uint64_t v8 = (ZinIrOpLayer ***)v6[2];
          BOOL v11 = *v8 == v6;
          char v6 = (ZinIrOpLayer **)v8;
        }
        while (!v11);
      }
      char v6 = (ZinIrOpLayer **)v8;
    }
    while (v8 != a2 + 1);
    int v10 = *(unsigned __int8 *)(a1 + 73);
    char v9 = (unsigned char *)(a1 + 73);
    if (v10) {
      BOOL v11 = v31 == 0;
    }
    else {
      BOOL v11 = 1;
    }
    if (!v11)
    {
      uint64_t v12 = PressureBasedSubgraphIdentification::ComputeTimeSpanOfCluster(a2);
      uint64_t v14 = v13;
      if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_INFO))
      {
        *(_DWORD *)long long buf = 134218240;
        *(void *)&void buf[4] = v12;
        *(_WORD *)&unsigned char buf[12] = 2048;
        *(void *)&buf[14] = v14;
        _os_log_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_INFO, "\tCutting Cluster [%zu,%zu] at Partial Outputs", buf, 0x16u);
      }
    }
  }
  ZinMirSpatialSplitUtils::GetSortedCluster((uint64_t)a2, 1, (ZinIrOpLayer ***)buf);
  uint64_t v15 = (void **)std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::emplace_back<>((uint64_t *)&v32);
  unint64_t v16 = *(ZinIrOpLayer ***)buf;
  char v17 = *(ZinIrOpLayer ***)&buf[8];
  if (*(void *)buf != *(void *)&buf[8])
  {
    unint64_t v18 = &_os_log_internal;
    do
    {
      uint64_t v28 = *v16;
      std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>((uint64_t **)v33 - 3, &v28, (uint64_t *)&v28);
      uint64_t v15 = (void **)std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>((uint64_t)&v29, &v28);
      if (&v30 != v15)
      {
        if (*v9 && os_log_type_enabled(v18, OS_LOG_TYPE_INFO))
        {
          uint64_t v19 = (void *)((char *)v28 + 24);
          if (*((char *)v28 + 47) < 0) {
            uint64_t v19 = (void *)*v19;
          }
          uint64_t v20 = *((void *)v28 + 6);
          *(_DWORD *)uint64_t v36 = 136315394;
          uint64_t v37 = v19;
          __int16 v38 = 2048;
          uint64_t v39 = v20;
          _os_log_impl(&dword_210C72000, v18, OS_LOG_TYPE_INFO, "\t\tCutting Cluster at Partial Output %s : %zu", v36, 0x16u);
        }
        uint64_t v15 = (void **)std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::emplace_back<>((uint64_t *)&v32);
      }
      ++v16;
    }
    while (v16 != v17);
  }
  uint64_t v21 = 0;
  uint64_t v22 = -1;
  while (1)
  {
    char v23 = v33;
    if (++v22 >= (unint64_t)(-1 - 0x5555555555555555 * (v33 - v32))) {
      break;
    }
    uint64_t v24 = v21 + 24;
    uint64_t v15 = (void **)PressureBasedSubgraphIdentification::MinimizeNewPartialOutputs((uint64_t)v15, (uint64_t **)((char *)v32 + v21), (uint64_t **)((char *)v32 + v21 + 24), (uint64_t)&v29);
    uint64_t v21 = v24;
  }
  if (v32 == v33)
  {
LABEL_35:
    uint64_t v26 = v33;
  }
  else
  {
    uint64_t v25 = v32 + 3;
    while (*(v25 - 1))
    {
      BOOL v11 = v25 == v33;
      v25 += 3;
      if (v11) {
        goto LABEL_35;
      }
    }
    uint64_t v27 = (uint64_t)(v25 - 3);
    if (v25 - 3 == v33 || v25 == v33)
    {
      uint64_t v26 = v33;
    }
    else
    {
      do
      {
        if (v25[2])
        {
          std::__tree<ZinSpaceRange>::__move_assign(v27, v25);
          v27 += 24;
        }
        v25 += 3;
      }
      while (v25 != v23);
      uint64_t v26 = v33;
    }
    char v23 = (ZinIrOpLayer ***)v27;
  }
  std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::erase((uint64_t)&v32, (uint64_t)v23, v26);
  std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::__insert_with_size[abi:ne180100]<std::__wrap_iter<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>,std::__wrap_iter<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>>((uint64_t *)a3, *(uint64_t ***)(a3 + 8), v32, v33, 0xAAAAAAAAAAAAAAABLL * (v33 - v32));
  if (*(void *)buf)
  {
    *(void *)&uint8_t buf[8] = *(void *)buf;
    operator delete(*(void **)buf);
  }
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v29, v30);
  unint64_t v29 = &v32;
  std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v29);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v35, (void *)v35[1]);
}

void sub_21128A348(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, void **a12, void *a13, uint64_t a14, char a15, uint64_t a16, uint64_t a17, char a18, void *a19)
{
  uint64_t v21 = *(void **)(v19 - 112);
  if (v21)
  {
    *(void *)(v19 - 104) = v21;
    operator delete(v21);
  }
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&a12, a13);
  a12 = (void **)&a15;
  std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100](&a12);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&a18, a19);
  _Unwind_Resume(a1);
}

uint64_t PressureBasedSubgraphIdentification::CutDisconnectedClusters@<X0>(ZinIrOpLayer ****a1@<X1>, uint64_t a2@<X8>)
{
  *(void *)a2 = 0;
  *(void *)(a2 + 8) = 0;
  *(void *)(a2 + 16) = 0;
  uint64_t v3 = *a1;
  uint64_t v4 = a1[1];
  if (*a1 == v4)
  {
    char v5 = 0;
    uint64_t v6 = 0;
  }
  else
  {
    do
    {
      std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::set[abi:ne180100](v13, v3);
      int v10 = 0;
      BOOL v11 = 0;
      uint64_t v12 = 0;
      IdentifyConnectedComponents(v13, (uint64_t *)&v10);
      std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::__insert_with_size[abi:ne180100]<std::__wrap_iter<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>,std::__wrap_iter<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>>((uint64_t *)a2, *(uint64_t ***)(a2 + 8), v10, v11, 0xAAAAAAAAAAAAAAABLL * (v11 - v10));
      uint64_t v14 = &v10;
      std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v14);
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v13, (void *)v13[1]);
      v3 += 3;
    }
    while (v3 != v4);
    uint64_t v6 = *(void *)a2;
    char v5 = *(void **)(a2 + 8);
    if (*(void **)a2 == v5)
    {
      char v5 = *(void **)a2;
    }
    else
    {
      for (uint64_t i = (void *)(v6 + 24); *(i - 1); i += 3)
      {
        if (i == v5)
        {
          uint64_t v6 = *(void *)(a2 + 8);
          return std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::erase(a2, v6, v5);
        }
      }
      uint64_t v6 = (uint64_t)(i - 3);
      if (i - 3 != v5 && i != v5)
      {
        do
        {
          if (i[2])
          {
            std::__tree<ZinSpaceRange>::__move_assign(v6, i);
            v6 += 24;
          }
          i += 3;
        }
        while (i != v5);
        char v5 = *(void **)(a2 + 8);
      }
    }
  }
  return std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::erase(a2, v6, v5);
}

void sub_21128A4F4(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, ...)
{
  va_start(va, a5);
  std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100]((void ***)va);
  _Unwind_Resume(a1);
}

unint64_t PressureBasedSubgraphIdentification::CountOverComputedSpaceForLayer(uint64_t a1, uint64_t a2, ZinIrOpLayer *this, unint64_t a4, uint64_t a5)
{
  if (ZinIrOpLayer::IsNELayer(this))
  {
    (*(void (**)(ZinIrKernel **__return_ptr, ZinIrOpLayer *, uint64_t))(*(void *)this + 568))(&v25, this, 1);
    if (v25)
    {
      int v10 = (ZinMirSpatialSplitUtils *)*((void *)v25 + 33);
      unint64_t v23 = *((int *)v25 + 82);
      uint64_t v24 = (ZinMirSpatialSplitUtils *)*((void *)v25 + 34);
      unint64_t v11 = *((int *)v25 + 83);
      unint64_t v12 = *((int *)v25 + 85);
      unint64_t v13 = *((int *)v25 + 86);
      uint64_t v14 = *((int *)v25 + 90);
      uint64_t v15 = *(unsigned char **)(a1 + 64);
      if (*v15) {
        BOOL IsCircularBufferConsumerCandidate = ZinIrCircularBufferUtil::IsCircularBufferConsumerCandidate(a2, (uint64_t)v15, this);
      }
      else {
        BOOL IsCircularBufferConsumerCandidate = 0;
      }
      a4 = ZinMirSpatialSplitUtils::OverComputedSpaceInDimension(v10, v11, v13, a4, v14, IsCircularBufferConsumerCandidate);
      ZinMirSpatialSplitUtils::OverComputedSpaceInDimension(v24, v23, v12, a5, 0, 0);
      uint64_t v21 = v25;
      uint64_t v25 = 0;
      if (v21)
      {
        ZinIrKernel::~ZinIrKernel(v21);
        MEMORY[0x21667D3C0]();
      }
    }
  }
  else if (ZinIrOpLayer::IsPELayer(this) && *(_DWORD *)(*((void *)this + 8) + 8) == 83)
  {
    uint64_t v17 = *(void *)(*((void *)this + 54) + 64);
    unint64_t v18 = *(ZinMirSpatialSplitUtils **)(v17 + 16);
    unint64_t v19 = *(int *)(v17 + 40);
    unint64_t v20 = *(int *)(v17 + 52);
    a4 = ZinMirSpatialSplitUtils::OverComputedSpaceInDimension(*(ZinMirSpatialSplitUtils **)(v17 + 24), *(int *)(v17 + 44), *(int *)(v17 + 56), a4, 0, 0);
    ZinMirSpatialSplitUtils::OverComputedSpaceInDimension(v18, v19, v20, a5, 0, 0);
  }
  return a4;
}

void sub_21128A6E8(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, ...)
{
  va_start(va, a4);
  std::unique_ptr<ZinIrKernel>::reset[abi:ne180100]((ZinIrKernel **)va, 0);
  _Unwind_Resume(a1);
}

uint64_t PressureBasedSubgraphIdentification::ComputeOverComputation(uint64_t result, ZinIrOpLayer *a2, uint64_t a3, void *a4)
{
  uint64_t v25 = result;
  unint64_t v29 = a2;
  uint64_t v5 = *((void *)a2 + 15) - *((void *)a2 + 14);
  if ((unint64_t)v5 < 9
    || (uint64_t result = std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>(a3 + 24, &v29), a3 + 32 != result))
  {
LABEL_3:
    uint64_t v6 = *((void *)v29 + 11);
    if (*((void *)v29 + 12) != v6)
    {
      unint64_t v7 = 0;
      uint64_t v8 = (uint64_t **)(v25 + 80);
      do
      {
        uint64_t v28 = 0;
        uint64_t v28 = *(ZinMirSpatialSplitUtils **)(v6 + 8 * v7);
        uint64_t result = std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>(a3 + 72, &v28);
        if (a3 + 80 != result)
        {
          char v9 = v29;
          unint64_t v30 = (uint64_t *)(*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)v29 + 32))(v29, 0, 0);
          int v10 = std::map<ZinIrTensor const*,SpatialAmount>::at((uint64_t)v8, (unint64_t *)&v30);
          unint64_t v11 = PressureBasedSubgraphIdentification::CountOverComputedSpaceForLayer(v25, a3, v9, *v10, v10[1]);
          unint64_t v13 = v12;
          uint64_t v27 = (*(uint64_t (**)(ZinMirSpatialSplitUtils *, void, void))(*(void *)v28 + 32))(v28, 0, 0);
          unint64_t v30 = &v27;
          uint64_t v14 = std::__tree<std::__value_type<ZinIrTensor const*,SpatialAmount>,std::__map_value_compare<ZinIrTensor const*,std::__value_type<ZinIrTensor const*,SpatialAmount>,std::less<ZinIrTensor const*>,true>,std::allocator<std::__value_type<ZinIrTensor const*,SpatialAmount>>>::__emplace_unique_key_args<ZinIrTensor const*,std::piecewise_construct_t const&,std::tuple<ZinIrTensor const*&&>,std::tuple<>>(v8, (unint64_t *)&v27, (uint64_t)&std::piecewise_construct, &v30);
          unint64_t v15 = v14[5];
          unint64_t v16 = v14[6];
          unsigned int IsDeConv = ZinMirSpatialSplitUtils::IsDeConv(v28, v17);
          if (v15 <= v11) {
            unint64_t v19 = v11;
          }
          else {
            unint64_t v19 = v15;
          }
          if (v16 <= v13) {
            unint64_t v20 = v13;
          }
          else {
            unint64_t v20 = v16;
          }
          uint64_t v21 = v19 + IsDeConv;
          uint64_t v22 = v20 + IsDeConv;
          uint64_t v27 = (*(uint64_t (**)(ZinMirSpatialSplitUtils *, void, void))(*(void *)v28 + 32))(v28, 0, 0);
          unint64_t v30 = &v27;
          unint64_t v23 = std::__tree<std::__value_type<ZinIrTensor const*,SpatialAmount>,std::__map_value_compare<ZinIrTensor const*,std::__value_type<ZinIrTensor const*,SpatialAmount>,std::less<ZinIrTensor const*>,true>,std::allocator<std::__value_type<ZinIrTensor const*,SpatialAmount>>>::__emplace_unique_key_args<ZinIrTensor const*,std::piecewise_construct_t const&,std::tuple<ZinIrTensor const*&&>,std::tuple<>>(v8, (unint64_t *)&v27, (uint64_t)&std::piecewise_construct, &v30);
          v23[5] = v21;
          v23[6] = v22;
          uint64_t result = PressureBasedSubgraphIdentification::ComputeOverComputation(v25, v28, a3, a4);
        }
        ++v7;
        uint64_t v6 = *((void *)v29 + 11);
      }
      while (v7 < (*((void *)v29 + 12) - v6) >> 3);
    }
    return result;
  }
  if (!std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(a4, &v29))
  {
    unint64_t v30 = (uint64_t *)&v29;
    uint64_t result = (uint64_t)std::__hash_table<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::__unordered_map_hasher<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,true>,std::__unordered_map_equal<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::equal_to<ZinIrOpLayer *>,std::hash<ZinIrOpLayer *>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer * const&>,std::tuple<>>((uint64_t)a4, &v29, (uint64_t)&std::piecewise_construct, &v30);
    *(void *)(result + 24) = 1;
    return result;
  }
  unint64_t v30 = (uint64_t *)&v29;
  uint64_t v24 = std::__hash_table<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::__unordered_map_hasher<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,true>,std::__unordered_map_equal<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::equal_to<ZinIrOpLayer *>,std::hash<ZinIrOpLayer *>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer * const&>,std::tuple<>>((uint64_t)a4, &v29, (uint64_t)&std::piecewise_construct, &v30);
  ++v24[3];
  unint64_t v30 = (uint64_t *)&v29;
  uint64_t result = (uint64_t)std::__hash_table<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::__unordered_map_hasher<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,true>,std::__unordered_map_equal<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::equal_to<ZinIrOpLayer *>,std::hash<ZinIrOpLayer *>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer * const&>,std::tuple<>>((uint64_t)a4, &v29, (uint64_t)&std::piecewise_construct, &v30);
  if (*(void *)(result + 24) == v5 >> 3)
  {
    uint64_t result = (uint64_t)std::__hash_table<std::__hash_value_type<ZinIrOpLayer *,long>,std::__unordered_map_hasher<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,long>,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,true>,std::__unordered_map_equal<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,long>,std::equal_to<ZinIrOpLayer *>,std::hash<ZinIrOpLayer *>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer *,long>>>::__erase_unique<ZinIrOpLayer *>(a4, &v29);
    goto LABEL_3;
  }
  return result;
}

uint64_t PressureBasedSubgraphIdentification::GetMinDMABufferSize(PressureBasedSubgraphIdentification *this, const ZinANELayer *a2, uint64_t a3, int a4)
{
  if (*(unsigned char *)(*((void *)this + 8) + 2)) {
    return 0;
  }
  if (!a4) {
    a3 = -1;
  }
  uint64_t v8 = a2;
  char v9 = a4;
  uint64_t v10 = a3;
  uint64_t v7 = *((void *)this + 29);
  if ((void *)(v7 + 8) == std::__tree<std::__value_type<MinDMABufferMapKey,long>,std::__map_value_compare<MinDMABufferMapKey,std::__value_type<MinDMABufferMapKey,long>,std::less<MinDMABufferMapKey>,true>,std::allocator<std::__value_type<MinDMABufferMapKey,long>>>::find<MinDMABufferMapKey>(v7, (uint64_t)&v8))ZinAssertImpl("Spatial Splitting DMA Buffer error"); {
  return *(void *)std::map<MinDMABufferMapKey,long>::at(*((void *)this + 29), (uint64_t)&v8);
  }
}

uint64_t std::map<MinDMABufferMapKey,long>::at(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = *std::__tree<std::__value_type<MinDMABufferMapKey,long>,std::__map_value_compare<MinDMABufferMapKey,std::__value_type<MinDMABufferMapKey,long>,std::less<MinDMABufferMapKey>,true>,std::allocator<std::__value_type<MinDMABufferMapKey,long>>>::__find_equal<MinDMABufferMapKey>(a1, &v4, a2);
  if (!v2) {
    std::__throw_out_of_range[abi:ne180100]("map::at:  key not found");
  }
  return v2 + 56;
}

uint64_t PressureBasedSubgraphIdentification::IsIndirectlyReachable(uint64_t a1, uint64_t a2, uint64_t a3)
{
  long long v19 = 0u;
  long long v20 = 0u;
  int v21 = 1065353216;
  uint64_t v3 = *(void **)(a1 + 112);
  uint64_t v4 = *(void **)(a1 + 120);
  if (v3 == v4)
  {
    uint64_t v10 = 0;
    long long v16 = 0uLL;
    long long v17 = 0uLL;
    int v18 = 1065353216;
  }
  else
  {
    do
    {
      *(void *)&long long v16 = *v3;
      if (std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>(a3, (ZinIrOpLayer **)&v16)&& (void)v16 != a2)
      {
        std::__hash_table<ZinIrTensor const*,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const* const&>((uint64_t)&v19, &v16, &v16);
      }
      ++v3;
    }
    while (v3 != v4);
    long long v16 = 0u;
    long long v17 = 0u;
    int v18 = 1065353216;
    if (*((void *)&v20 + 1))
    {
      do
      {
        memset(v14, 0, sizeof(v14));
        int v15 = 1065353216;
        for (uint64_t i = (void *)v20; i; uint64_t i = (void *)*i)
        {
          unint64_t v13 = (ZinIrOpLayer *)i[2];
          if (!std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(&v16, &v13)&& std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>(a3, &v13))
          {
            uint64_t v8 = (uint64_t *)*((void *)v13 + 14);
            char v9 = (uint64_t *)*((void *)v13 + 15);
            while (v8 != v9)
            {
              uint64_t v12 = 0;
              uint64_t v12 = *v8;
              if (v12 == a2)
              {
                std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v14);
                uint64_t v10 = 1;
                goto LABEL_21;
              }
              std::__hash_table<ZinIrTensor const*,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const* const&>((uint64_t)v14, &v12, &v12);
              ++v8;
            }
          }
        }
        std::__hash_table<ZinIrOpLayer *,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,std::allocator<ZinIrOpLayer *>>::swap((uint64_t)&v19, (uint64_t)v14);
        std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v14);
        uint64_t v10 = 0;
      }
      while (*((void *)&v20 + 1));
    }
    else
    {
      uint64_t v10 = 0;
    }
  }
LABEL_21:
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&v16);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&v19);
  return v10;
}

void sub_21128AC44(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, ...)
{
  va_start(va1, a3);
  va_start(va, a3);
  uint64_t v5 = va_arg(va1, void);
  uint64_t v7 = va_arg(va1, void);
  uint64_t v8 = va_arg(va1, void);
  uint64_t v9 = va_arg(va1, void);
  uint64_t v10 = va_arg(va1, void);
  uint64_t v11 = va_arg(va1, void);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)va);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)va1);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table(v3 - 96);
  _Unwind_Resume(a1);
}

void PressureBasedSubgraphIdentification::OldCopyPressureForConcatMetric(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v3 = a2 + 72;
  uint64_t v4 = *(void **)(a2 + 72);
  uint64_t v5 = (void *)(a2 + 80);
  if (v4 != (void *)(a2 + 80))
  {
    long long v20 = (void *)(a2 + 80);
    while (1)
    {
      uint64_t v7 = (void *)v4[4];
      if (*(_DWORD *)(v7[8] + 8) == 7) {
        break;
      }
LABEL_18:
      long long v17 = (void *)v4[1];
      if (v17)
      {
        do
        {
          int v18 = v17;
          long long v17 = (void *)*v17;
        }
        while (v17);
      }
      else
      {
        do
        {
          int v18 = (void *)v4[2];
          BOOL v19 = *v18 == (void)v4;
          uint64_t v4 = v18;
        }
        while (!v19);
      }
      uint64_t v4 = v18;
      if (v18 == v5) {
        return;
      }
    }
    uint64_t v9 = (ZinIrOpLayer **)v7[11];
    uint64_t v8 = (ZinIrOpLayer **)v7[12];
    while (1)
    {
      if (v9 == v8) {
        goto LABEL_18;
      }
      unint64_t v23 = 0;
      unint64_t v23 = *v9;
      if (v5 != (void *)std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>(v3, &v23))
      {
        if (PressureBasedSubgraphIdentification::IsIndirectlyReachable((uint64_t)v23, (uint64_t)v7, v3)) {
          break;
        }
      }
LABEL_17:
      ++v9;
    }
    int64_t v10 = *((void *)v23 + 6);
    int64_t v22 = v10;
    uint64_t v11 = *((void *)v23 + 14);
    uint64_t v12 = *((void *)v23 + 15);
    int64_t v13 = v10;
    if (v11 == v12)
    {
      int64_t v21 = v10;
      int64_t v13 = v10;
    }
    else
    {
      do
      {
        if (*(void **)v11 != v7) {
          int64_t v13 = *(void *)(*(void *)v11 + 48);
        }
        v11 += 8;
      }
      while (v11 != v12);
      int64_t v21 = v10;
      if (v10 > v13) {
        goto LABEL_16;
      }
    }
    do
    {
      uint64_t v24 = (unint64_t *)&v21;
      uint64_t v14 = (uint64_t **)(std::__hash_table<std::__hash_value_type<long,PressureBasedSubgraphIdentification::CopyPressure>,std::__unordered_map_hasher<long,std::__hash_value_type<long,PressureBasedSubgraphIdentification::CopyPressure>,std::hash<long>,std::equal_to<long>,true>,std::__unordered_map_equal<long,std::__hash_value_type<long,PressureBasedSubgraphIdentification::CopyPressure>,std::equal_to<long>,std::hash<long>,true>,std::allocator<std::__hash_value_type<long,PressureBasedSubgraphIdentification::CopyPressure>>>::__emplace_unique_key_args<long,std::piecewise_construct_t const&,std::tuple<long &&>,std::tuple<>>(a3, (unint64_t *)&v21, (uint64_t)&std::piecewise_construct, (uint64_t **)&v24)+ 3);
      uint64_t v24 = (unint64_t *)(*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)v23 + 32))(v23, 0, 0);
      std::__tree<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const*>(v14, (uint64_t *)&v24, (uint64_t *)&v24);
      int64_t v15 = v21++;
    }
    while (v15 < v13);
LABEL_16:
    uint64_t v24 = (unint64_t *)&v22;
    long long v16 = (uint64_t **)(std::__hash_table<std::__hash_value_type<long,PressureBasedSubgraphIdentification::CopyPressure>,std::__unordered_map_hasher<long,std::__hash_value_type<long,PressureBasedSubgraphIdentification::CopyPressure>,std::hash<long>,std::equal_to<long>,true>,std::__unordered_map_equal<long,std::__hash_value_type<long,PressureBasedSubgraphIdentification::CopyPressure>,std::equal_to<long>,std::hash<long>,true>,std::allocator<std::__hash_value_type<long,PressureBasedSubgraphIdentification::CopyPressure>>>::__emplace_unique_key_args<long,std::piecewise_construct_t const&,std::tuple<long &&>,std::tuple<>>(a3, (unint64_t *)&v22, (uint64_t)&std::piecewise_construct, (uint64_t **)&v24)+ 6);
    uint64_t v24 = (unint64_t *)(*(uint64_t (**)(void *, void, void))(*v7 + 32))(v7, 0, 0);
    std::__tree<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const*>(v16, (uint64_t *)&v24, (uint64_t *)&v24);
    uint64_t v5 = v20;
    goto LABEL_17;
  }
}

uint64_t PressureBasedSubgraphIdentification::DoesDeconvRequireCopy(uint64_t a1, ZinMirSpatialSplitUtils *this, Subgraph *a3, uint64_t a4)
{
  if (!ZinMirSpatialSplitUtils::IsRootOutputOrOutsideSubgraph(this, a3, a3)) {
    return 0;
  }
  long long v76 = 0u;
  long long v75 = 0u;
  long long v74 = 0u;
  memset(v73, 0, sizeof(v73));
  long long v72 = 0u;
  long long v71 = 0u;
  long long v70 = 0u;
  long long v69 = 0u;
  *(_OWORD *)unint64_t v68 = 0u;
  LayerTilingHelper::CreateHelper(a3, *(const ZinIrOpLayer **)(a1 + 200), (const SplitPatternHandlerMgr *)v67, v7);
  uint64_t v8 = (char *)operator new(4uLL);
  *(_DWORD *)uint64_t v8 = 0;
  uint64_t v9 = v8 + 4;
  char v65 = v8 + 4;
  uint64_t v66 = v8 + 4;
  long long __p = v8;
  if (*(_DWORD *)(a4 + 24) != 4)
  {
    uint64_t v18 = *(void *)(a4 + 8);
    uint64_t v17 = a4 + 8;
    uint64_t v16 = v18;
    if (!v18) {
      goto LABEL_22;
    }
    uint64_t v19 = v17;
    do
    {
      int v20 = *(_DWORD *)(v16 + 32);
      BOOL v21 = v20 < 4;
      if (v20 >= 4) {
        int64_t v22 = (uint64_t *)v16;
      }
      else {
        int64_t v22 = (uint64_t *)(v16 + 8);
      }
      if (!v21) {
        uint64_t v19 = v16;
      }
      uint64_t v16 = *v22;
    }
    while (*v22);
    if (v19 == v17 || *(int *)(v19 + 32) > 4 || *(void *)(v19 + 40) < 2uLL) {
      goto LABEL_22;
    }
  }
  uint64_t v11 = std::__allocate_at_least[abi:ne180100]<std::allocator<ZinIrPaddingMode>>((uint64_t)&v66, 2uLL);
  uint64_t v12 = (char *)__p;
  int64_t v13 = v65;
  v11[1] = 1;
  uint64_t v8 = (char *)(v11 + 1);
  uint64_t v9 = (char *)(v11 + 2);
  while (v13 != v12)
  {
    int v14 = *((_DWORD *)v13 - 1);
    v13 -= 4;
    *((_DWORD *)v8 - 1) = v14;
    v8 -= 4;
  }
  long long __p = v8;
  char v65 = (char *)(v11 + 2);
  uint64_t v66 = &v11[v10];
  if (v12)
  {
    operator delete(v12);
    uint64_t v8 = (char *)__p;
  }
  char v65 = v9;
  if (v8 == v9)
  {
LABEL_10:
    uint64_t v15 = 0;
  }
  else
  {
LABEL_22:
    unint64_t v52 = v9;
    while (1)
    {
      int v23 = *(_DWORD *)v8;
      uint64_t v24 = v73;
      if (*(_DWORD *)v8) {
        uint64_t v24 = &v73[8];
      }
      if (*(void *)v24 != 1) {
        break;
      }
LABEL_48:
      v8 += 4;
      if (v8 == v9) {
        goto LABEL_10;
      }
    }
    if (v23) {
      uint64_t v25 = 168;
    }
    else {
      uint64_t v25 = 144;
    }
    if (v23) {
      uint64_t v26 = 176;
    }
    else {
      uint64_t v26 = 152;
    }
    if ((unint64_t)(0x6DB6DB6DB6DB6DB7 * ((uint64_t)(*(void *)&v67[v26] - *(void *)&v67[v25]) >> 3)) <= 1) {
      ZinAssertImpl("Splitting a layer with a dimension size of 1");
    }
    uint64_t v27 = 0;
    unint64_t v28 = -2;
    while (1)
    {
      uint64_t v29 = *(void *)&v67[v25];
      unint64_t v30 = 0x6DB6DB6DB6DB6DB7 * ((*(void *)&v67[v26] - v29) >> 3);
      if (v28 + 3 >= v30) {
        break;
      }
      v28 += 2;
      if (v30 <= v28) {
        std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
      }
      uint64_t v31 = (long long *)(v29 + v27);
      long long v32 = *v31;
      long long v33 = v31[1];
      long long v34 = v31[2];
      uint64_t v60 = *((void *)v31 + 6);
      long long v58 = v33;
      long long v59 = v34;
      long long v57 = v32;
      long long v35 = *(long long *)((char *)v31 + 56);
      long long v36 = *(long long *)((char *)v31 + 72);
      long long v37 = *(long long *)((char *)v31 + 88);
      uint64_t v56 = *((void *)v31 + 13);
      long long v54 = v36;
      long long v55 = v37;
      long long v53 = v35;
      if (LayerTilingHelper::Requirement::GetExtendedTo((LayerTilingHelper::Requirement *)&v57, (const LayerTilingHelper::Requirement *)&v53, (LayerTilingHelper::Requirement *)v61))ZinAssertImpl("Invalid deconv in spatial split"); {
      if (LayerTilingHelper::GetOutputCount((uint64_t)v67, (LayerTilingHelper::Requirement *)v61, v23) != 2)
      }
        goto LABEL_50;
      v27 += 112;
      if (!(v61[0] + v62))
      {
        unint64_t v30 = 0x6DB6DB6DB6DB6DB7 * ((uint64_t)(*(void *)&v67[v26] - *(void *)&v67[v25]) >> 3);
        break;
      }
    }
    unint64_t v38 = 2 - (v30 & 0xFFFFFFFFFFFFFFFELL);
    unint64_t v39 = (v30 & 0xFFFFFFFFFFFFFFFELL) - 2;
    uint64_t v40 = 112 * (v30 >> 1) - 112;
    while (1)
    {
      unint64_t v41 = v39;
      uint64_t v42 = *(void *)&v67[v25];
      unint64_t v43 = 0x6DB6DB6DB6DB6DB7 * ((*(void *)&v67[v26] - v42) >> 3);
      if (v43 <= v41) {
        std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
      }
      long long v44 = *(_OWORD *)(v42 + v40);
      long long v45 = *(_OWORD *)(v42 + v40 + 16);
      long long v46 = *(_OWORD *)(v42 + v40 + 32);
      uint64_t v60 = *(void *)(v42 + v40 + 48);
      long long v58 = v45;
      long long v59 = v46;
      long long v57 = v44;
      if (v43 <= v30 - 1) {
        std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
      }
      uint64_t v47 = (long long *)(v42 + 56 * (v30 - 1));
      long long v48 = *v47;
      long long v49 = v47[1];
      long long v50 = v47[2];
      uint64_t v56 = *((void *)v47 + 6);
      long long v54 = v49;
      long long v55 = v50;
      long long v53 = v48;
      if (LayerTilingHelper::Requirement::GetExtendedTo((LayerTilingHelper::Requirement *)&v57, (const LayerTilingHelper::Requirement *)&v53, (LayerTilingHelper::Requirement *)v61))ZinAssertImpl("Invalid deconv in spatial split"); {
      if (v30 + v38 != LayerTilingHelper::GetOutputCount((uint64_t)v67, (LayerTilingHelper::Requirement *)v61, v23))
      }
        break;
      if (v38)
      {
        v38 += 2;
        unint64_t v39 = v41 - 2;
        v40 -= 112;
        unint64_t v30 = v41;
        if (v63) {
          continue;
        }
      }
      uint64_t v9 = v52;
      goto LABEL_48;
    }
LABEL_50:
    uint64_t v15 = 1;
  }
  if (__p)
  {
    char v65 = (char *)__p;
    operator delete(__p);
  }
  if (*((void *)&v75 + 1))
  {
    *(void *)&long long v76 = *((void *)&v75 + 1);
    operator delete(*((void **)&v75 + 1));
  }
  if ((void)v74)
  {
    *((void *)&v74 + 1) = v74;
    operator delete((void *)v74);
  }
  if (*((void *)&v69 + 1)) {
    operator delete(*((void **)&v69 + 1));
  }
  if (v68[0])
  {
    v68[1] = v68[0];
    operator delete(v68[0]);
  }
  return v15;
}

void sub_21128B338(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33,uint64_t a34,void *__p,uint64_t a36,uint64_t a37,char a38)
{
  if (__p) {
    operator delete(__p);
  }
  LayerTilingHelper::~LayerTilingHelper((LayerTilingHelper *)&a38);
  _Unwind_Resume(a1);
}

uint64_t PressureBasedSubgraphIdentification::IsMultiFanoutCBCandidate(PressureBasedSubgraphIdentification *this, const Subgraph *a2, ZinIrOpLayer *a3)
{
  uint64_t v6 = *((void *)this + 8);
  if (!*(unsigned char *)(v6 + 5) && !*(unsigned char *)(v6 + 8)) {
    return 0;
  }
  uint64_t v25 = 0;
  uint64_t v26 = 0;
  uint64_t v27 = 0;
  std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(&v25, *((const void **)a3 + 14), *((void *)a3 + 15), (uint64_t)(*((void *)a3 + 15) - *((void *)a3 + 14)) >> 3);
  long long __p = 0;
  int v23 = 0;
  uint64_t v24 = 0;
  if (ZinIrOpLayer::IsNoOp(a3, (uint64_t *)&__p))
  {
    int v7 = *(_DWORD *)(*((void *)a3 + 8) + 8);
    if (__p)
    {
      int v23 = __p;
      operator delete(__p);
    }
    if (v7 != 7) {
      goto LABEL_21;
    }
  }
  else if (__p)
  {
    int v23 = __p;
    operator delete(__p);
  }
  uint64_t v8 = (char *)v25;
  uint64_t v9 = v26;
  if ((unint64_t)(v26 - (unsigned char *)v25) < 9)
  {
LABEL_38:
    uint64_t v13 = 0;
    if (!v8) {
      return v13;
    }
LABEL_39:
    uint64_t v26 = v8;
    operator delete(v8);
    return v13;
  }
  if (v25 != v26)
  {
    uint64_t v10 = (char *)v25 + 8;
    do
    {
      int v11 = *(_DWORD *)(*(void *)(*((void *)v10 - 1) + 64) + 8);
      BOOL v12 = v11 == 7 || v10 == v26;
      v10 += 8;
    }
    while (!v12);
    while (1)
    {
      long long __p = *(void **)v8;
      if ((const Subgraph *)((char *)a2 + 80) == (const Subgraph *)std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>((uint64_t)a2 + 72, (ZinIrOpLayer **)&__p))break; {
      v8 += 8;
      }
      if (v8 == v9)
      {
        if (v11 == 7) {
          break;
        }
        uint64_t v8 = (char *)v25;
        int v14 = v26;
        if (v25 != v26)
        {
          uint64_t v15 = (char *)v25 + 8;
          uint64_t v16 = -1;
          do
          {
            uint64_t v17 = (ZinIrOpLayer *)*((void *)v15 - 1);
            long long __p = (void *)(*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)v17 + 32))(v17, 0, 0);
            uint64_t v18 = std::map<ZinIrTensor const*,SpatialAmount>::at((uint64_t)this + 80, (unint64_t *)&__p);
            unint64_t v19 = PressureBasedSubgraphIdentification::CountOverComputedSpaceForLayer((uint64_t)this, (uint64_t)a2, v17, *v18, v18[1]);
            BOOL v20 = v16 == -1 || v19 == v16;
            uint64_t v13 = !v20;
            if (!v20) {
              break;
            }
            uint64_t v16 = v19;
            BOOL v12 = v15 == v14;
            v15 += 8;
          }
          while (!v12);
          goto LABEL_22;
        }
        goto LABEL_38;
      }
    }
  }
LABEL_21:
  uint64_t v13 = 0;
LABEL_22:
  uint64_t v8 = (char *)v25;
  if (v25) {
    goto LABEL_39;
  }
  return v13;
}

void sub_21128B588(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, void *__p, uint64_t a10, uint64_t a11, void *a12, uint64_t a13)
{
  if (__p) {
    operator delete(__p);
  }
  if (a12) {
    operator delete(a12);
  }
  _Unwind_Resume(exception_object);
}

void PressureBasedSubgraphIdentification::ExternalTensorSetPerResetLayer(uint64_t a1, void *a2, uint64_t **a3, uint64_t **a4)
{
  uint64_t v48 = PressureBasedSubgraphIdentification::ComputeTimeSpanOfCluster(a2);
  unint64_t v49 = v6;
  unint64_t v71 = v48;
  int64_t v72 = v6;
  ZinIrMemoryPressureAnalyzer::GetTimeConflictAllocations((void *)(a1 + 128), (const ZinLiveRange *)&v71, (uint64_t)&v69);
  v65[0] = 0;
  v65[1] = 0;
  char v66 = 0;
  v63[1] = 0;
  uint64_t v64 = v65;
  memset(v67, 0, sizeof(v67));
  int v68 = 1065353216;
  unsigned __int8 v62 = (uint64_t *)v63;
  v63[0] = 0;
  uint64_t v7 = *(void *)(a1 + 8);
  if (*(void *)(v7 + 360) == *(void *)(v7 + 352)) {
    ZinAssertImpl("Must run scheduler first");
  }
  uint64_t v8 = v69;
  if (v69 != v70)
  {
    long long v50 = a2 + 1;
    while (1)
    {
      uint64_t v9 = (unint64_t *)v8[4];
      BOOL v10 = ZinLiveRange::Contains(&v71, v9 + 2);
      uint64_t v47 = (ZinIrTensor *)v9[4];
      unint64_t v61 = (ZinIrOpLayer *)*((void *)v47 + 12);
      int v11 = *(_DWORD *)(*((void *)v61 + 8) + 8);
      if (v10) {
        break;
      }
      if (v11 == 7) {
        goto LABEL_8;
      }
LABEL_28:
      uint64_t v29 = (void *)v8[1];
      if (v29)
      {
        do
        {
          unint64_t v30 = (void **)v29;
          uint64_t v29 = (void *)*v29;
        }
        while (v29);
      }
      else
      {
        do
        {
          unint64_t v30 = (void **)v8[2];
          BOOL v31 = *v30 == v8;
          uint64_t v8 = v30;
        }
        while (!v31);
      }
      uint64_t v8 = v30;
      if (v30 == v70) {
        goto LABEL_34;
      }
    }
    if (v11 != 7) {
      ZinIrMemoryPressureAnalyzer::AddTensorAllocation((ZinIrMemoryPressureAnalyzer *)&v64, v9[1], (const ZinLiveRange *)(v9 + 2), v47);
    }
LABEL_8:
    if (v50 != (void *)std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>((uint64_t)a2, &v61))
    {
      long long v53 = 0;
      uint64_t v54 = 0;
      long long __p = 0;
      std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(&__p, *((const void **)v61 + 11), *((void *)v61 + 12), (uint64_t)(*((void *)v61 + 12) - *((void *)v61 + 11)) >> 3);
      unint64_t v12 = 126 - 2 * __clz((v53 - (unsigned char *)__p) >> 3);
      if (v53 == __p) {
        uint64_t v13 = 0;
      }
      else {
        uint64_t v13 = v12;
      }
      std::__introsort<std::_ClassicAlgPolicy,PressureBasedSubgraphIdentification::ExternalTensorSetPerResetLayer(std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const&,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &)::$_0 &,ZinIrOpLayer **,false>((uint64_t)__p, (ZinIrOpLayer **)v53, v13, 1);
      int v14 = __p;
      unint64_t v15 = v9[3];
      long long v59 = *(uint64_t ***)(*((void *)v53 - 1) + 48);
      unint64_t v60 = v15;
      if (v53 - (unsigned char *)__p != 8)
      {
        unint64_t v16 = 0;
        unint64_t v17 = (v53 - (unsigned char *)__p) >> 3;
        do
        {
          long long v58 = 0;
          if (v17 <= v16) {
            std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
          }
          uint64_t v18 = (ZinIrOpLayer *)v14[v16];
          uint64_t v57 = 0;
          long long v58 = v18;
          uint64_t v57 = (*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)v18 + 32))(v18, 0, 0);
          if (v50 == (void *)std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>((uint64_t)a2, &v58))
          {
            for (unint64_t i = v48; i < (unint64_t)v59; ++i)
            {
              uint64_t v56 = 0;
              uint64_t v24 = *(void *)(v7 + 352);
              if (i >= (*(void *)(v7 + 360) - v24) >> 3) {
                std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
              }
              uint64_t v56 = *(ZinIrOpLayer **)(v24 + 8 * i);
              v73[0] = (uint64_t *)&v56;
              uint64_t v25 = std::__tree<std::__value_type<ZinIrOpLayer *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>,std::__map_value_compare<ZinIrOpLayer *,std::__value_type<ZinIrOpLayer *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>,ScheduleComparator,true>,std::allocator<std::__value_type<ZinIrOpLayer *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer * const&>,std::tuple<>>(&v62, &v56, (uint64_t)&std::piecewise_construct, v73);
              std::__tree<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const*>((uint64_t **)v25 + 5, &v57, &v57);
            }
            unint64_t v26 = v60;
            if (v60 <= v49)
            {
              do
              {
                uint64_t v56 = 0;
                uint64_t v27 = *(void *)(v7 + 352);
                if (v26 >= (*(void *)(v7 + 360) - v27) >> 3) {
                  std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
                }
                uint64_t v56 = *(ZinIrOpLayer **)(v27 + 8 * v26);
                v73[0] = (uint64_t *)&v56;
                unint64_t v28 = std::__tree<std::__value_type<ZinIrOpLayer *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>,std::__map_value_compare<ZinIrOpLayer *,std::__value_type<ZinIrOpLayer *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>,ScheduleComparator,true>,std::allocator<std::__value_type<ZinIrOpLayer *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer * const&>,std::tuple<>>(&v62, &v56, (uint64_t)&std::piecewise_construct, v73);
                std::__tree<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const*>((uint64_t **)v28 + 5, &v57, &v57);
                ++v26;
              }
              while (v49 + 1 != v26);
            }
          }
          else
          {
            unint64_t v19 = (uint64_t *)v59;
            unint64_t v20 = *((void *)v58 + 6);
            if (v20 <= (unint64_t)v59 - 1)
            {
              do
              {
                uint64_t v56 = 0;
                uint64_t v21 = *(void *)(v7 + 352);
                if (v20 >= (*(void *)(v7 + 360) - v21) >> 3) {
                  std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
                }
                uint64_t v56 = *(ZinIrOpLayer **)(v21 + 8 * v20);
                v73[0] = (uint64_t *)&v56;
                int64_t v22 = std::__tree<std::__value_type<ZinIrOpLayer *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>,std::__map_value_compare<ZinIrOpLayer *,std::__value_type<ZinIrOpLayer *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>,ScheduleComparator,true>,std::allocator<std::__value_type<ZinIrOpLayer *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer * const&>,std::tuple<>>(&v62, &v56, (uint64_t)&std::piecewise_construct, v73);
                std::__tree<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const*>((uint64_t **)v22 + 5, &v57, &v57);
                ++v20;
              }
              while (v19 != (uint64_t *)v20);
            }
          }
          ++v16;
          int v14 = __p;
          unint64_t v17 = (v53 - (unsigned char *)__p) >> 3;
        }
        while (v16 < v17 - 1);
      }
      ZinIrMemoryPressureAnalyzer::AddTensorAllocation((ZinIrMemoryPressureAnalyzer *)&v64, v9[1], (const ZinLiveRange *)&v59, v47);
    }
    goto LABEL_28;
  }
LABEL_34:
  unint64_t v32 = v71;
  for (uint64_t j = a3; (uint64_t)v32 < v72; ++v32)
  {
    v73[0] = 0;
    uint64_t v34 = *(void *)(v7 + 352);
    if (v32 >= (*(void *)(v7 + 360) - v34) >> 3) {
      std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
    }
    v73[0] = *(uint64_t **)(v34 + 8 * v32);
    if (a2 + 1 != (void *)std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>((uint64_t)a2, (ZinIrOpLayer **)v73))
    {
      long long v53 = 0;
      uint64_t v54 = 0;
      long long __p = &v53;
      std::__tree<std::__value_type<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>,std::__map_value_compare<ZinIrOpLayer *,std::__value_type<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>,ScheduleComparator,true>,std::allocator<std::__value_type<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer *&,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>(j, (ZinIrOpLayer **)v73, v73, (uint64_t *)&__p);
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&__p, v53);
      long long v53 = 0;
      uint64_t v54 = 0;
      long long __p = &v53;
      std::__tree<std::__value_type<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>,std::__map_value_compare<ZinIrOpLayer *,std::__value_type<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>,ScheduleComparator,true>,std::allocator<std::__value_type<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer *&,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>(a4, (ZinIrOpLayer **)v73, v73, (uint64_t *)&__p);
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&__p, v53);
      long long v53 = 0;
      uint64_t v54 = 0;
      char v55 = 0;
      long long __p = &v53;
      long long v59 = (uint64_t **)v32;
      unint64_t v60 = v32;
      ZinIrMemoryPressureAnalyzer::GetPeakPressure((uint64_t)&v64, (unint64_t *)&v59, (uint64_t)&__p);
      long long v35 = (char *)__p;
      if (__p != &v53)
      {
        do
        {
          uint64_t v36 = *((void *)v35 + 4);
          if (*(void *)(v36 + 24) != v32)
          {
            long long v59 = v73;
            long long v37 = std::__tree<std::__value_type<ZinIrOpLayer *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>,std::__map_value_compare<ZinIrOpLayer *,std::__value_type<ZinIrOpLayer *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>,ScheduleComparator,true>,std::allocator<std::__value_type<ZinIrOpLayer *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer * const&>,std::tuple<>>(j, (ZinIrOpLayer **)v73, (uint64_t)&std::piecewise_construct, (uint64_t **)&v59);
            std::__tree<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const*>((uint64_t **)v37 + 5, (uint64_t *)(v36 + 32), (uint64_t *)(v36 + 32));
          }
          unint64_t v38 = (char *)*((void *)v35 + 1);
          if (v38)
          {
            do
            {
              unint64_t v39 = (char **)v38;
              unint64_t v38 = *(char **)v38;
            }
            while (v38);
          }
          else
          {
            do
            {
              unint64_t v39 = (char **)*((void *)v35 + 2);
              BOOL v31 = *v39 == v35;
              long long v35 = (char *)v39;
            }
            while (!v31);
          }
          long long v35 = (char *)v39;
        }
        while (v39 != &v53);
      }
      long long v59 = v73;
      uint64_t v40 = std::__tree<std::__value_type<ZinIrOpLayer *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>,std::__map_value_compare<ZinIrOpLayer *,std::__value_type<ZinIrOpLayer *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>,ScheduleComparator,true>,std::allocator<std::__value_type<ZinIrOpLayer *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer * const&>,std::tuple<>>(&v62, (ZinIrOpLayer **)v73, (uint64_t)&std::piecewise_construct, (uint64_t **)&v59);
      unint64_t v41 = (uint64_t *)v40[5];
      uint64_t v42 = v40 + 6;
      if (v41 != v40 + 6)
      {
        do
        {
          unint64_t v61 = (ZinIrOpLayer *)v41[4];
          long long v59 = v73;
          unint64_t v43 = std::__tree<std::__value_type<ZinIrOpLayer *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>,std::__map_value_compare<ZinIrOpLayer *,std::__value_type<ZinIrOpLayer *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>,ScheduleComparator,true>,std::allocator<std::__value_type<ZinIrOpLayer *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer * const&>,std::tuple<>>(a4, (ZinIrOpLayer **)v73, (uint64_t)&std::piecewise_construct, (uint64_t **)&v59);
          std::__tree<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const*>((uint64_t **)v43 + 5, (uint64_t *)&v61, (uint64_t *)&v61);
          long long v44 = (uint64_t *)v41[1];
          if (v44)
          {
            do
            {
              long long v45 = v44;
              long long v44 = (uint64_t *)*v44;
            }
            while (v44);
          }
          else
          {
            do
            {
              long long v45 = (uint64_t *)v41[2];
              BOOL v31 = *v45 == (void)v41;
              unint64_t v41 = v45;
            }
            while (!v31);
          }
          unint64_t v41 = v45;
        }
        while (v45 != v42);
      }
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&__p, v53);
      uint64_t j = a3;
    }
  }
  std::__tree<std::__value_type<int,std::set<ZinIrInitInfo const*>>,std::__map_value_compare<int,std::__value_type<int,std::set<ZinIrInitInfo const*>>,std::less<int>,true>,std::allocator<std::__value_type<int,std::set<ZinIrInitInfo const*>>>>::destroy((uint64_t)&v62, v63[0]);
  std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)v67);
  std::__tree<std::unique_ptr<ZinIrMemoryPressureAnalyzer::Allocation const>,ZinIrMemoryPressureAnalyzer::PointerComparator,std::allocator<std::unique_ptr<ZinIrMemoryPressureAnalyzer::Allocation const>>>::destroy((uint64_t)&v64, v65[0]);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v69, v70[0]);
}

void sub_21128BC28(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, void *__p, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,char a28,void *a29,uint64_t a30,char a31,void *a32)
{
  std::__tree<std::__value_type<int,std::set<ZinIrInitInfo const*>>,std::__map_value_compare<int,std::__value_type<int,std::set<ZinIrInitInfo const*>>,std::less<int>,true>,std::allocator<std::__value_type<int,std::set<ZinIrInitInfo const*>>>>::destroy((uint64_t)&a28, a29);
  std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table(a10);
  std::__tree<std::unique_ptr<ZinIrMemoryPressureAnalyzer::Allocation const>,ZinIrMemoryPressureAnalyzer::PointerComparator,std::allocator<std::unique_ptr<ZinIrMemoryPressureAnalyzer::Allocation const>>>::destroy((uint64_t)&a31, a32);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy(v32 - 152, *(void **)(v32 - 144));
  _Unwind_Resume(a1);
}

void PressureBasedSubgraphIdentification::TensorToProducersAndConsumers(uint64_t a1, void *a2, uint64_t **a3, uint64_t **a4)
{
  uint64_t v4 = a2 + 1;
  uint64_t v5 = (void *)*a2;
  if ((void *)*a2 != a2 + 1)
  {
    do
    {
      uint64_t v8 = (ZinIrOpLayer *)v5[4];
      if (ZinIrOpLayer::IsANELayer(v8))
      {
        RootTensor = 0;
        uint64_t v21 = v8;
        uint64_t v9 = (ZinIrTensor *)(*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)v8 + 32))(v8, 0, 0);
        RootTensor = ZinIrTensor::GetRootTensor(v9);
        p_RootTensor = &RootTensor;
        BOOL v10 = std::__tree<std::__value_type<ZinIrTensor *,std::set<ZinRingBufferWriterLayer *,ScheduleComparator,std::allocator<ZinRingBufferWriterLayer *>>>,std::__map_value_compare<ZinIrTensor *,std::__value_type<ZinIrTensor *,std::set<ZinRingBufferWriterLayer *,ScheduleComparator,std::allocator<ZinRingBufferWriterLayer *>>>,ZinIrIdComparator<ZinIrTensor *>,true>,std::allocator<std::__value_type<ZinIrTensor *,std::set<ZinRingBufferWriterLayer *,ScheduleComparator,std::allocator<ZinRingBufferWriterLayer *>>>>>::__emplace_unique_key_args<ZinIrTensor *,std::piecewise_construct_t const&,std::tuple<ZinIrTensor * const&>,std::tuple<>>(a3, (uint64_t *)&RootTensor, (uint64_t)&std::piecewise_construct, (uint64_t **)&p_RootTensor);
        std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>((uint64_t **)v10 + 5, &v21, (uint64_t *)&v21);
        unint64_t v12 = (uint64_t *)*((void *)v8 + 11);
        int v11 = (uint64_t *)*((void *)v8 + 12);
        while (v12 != v11)
        {
          uint64_t v13 = *v12++;
          unint64_t v19 = 0;
          int v14 = (ZinIrTensor *)(*(uint64_t (**)(uint64_t, void, void))(*(void *)v13 + 32))(v13, 0, 0);
          unint64_t v19 = ZinIrTensor::GetRootTensor(v14);
          p_RootTensor = &v19;
          unint64_t v15 = std::__tree<std::__value_type<ZinIrTensor *,std::set<ZinRingBufferWriterLayer *,ScheduleComparator,std::allocator<ZinRingBufferWriterLayer *>>>,std::__map_value_compare<ZinIrTensor *,std::__value_type<ZinIrTensor *,std::set<ZinRingBufferWriterLayer *,ScheduleComparator,std::allocator<ZinRingBufferWriterLayer *>>>,ZinIrIdComparator<ZinIrTensor *>,true>,std::allocator<std::__value_type<ZinIrTensor *,std::set<ZinRingBufferWriterLayer *,ScheduleComparator,std::allocator<ZinRingBufferWriterLayer *>>>>>::__emplace_unique_key_args<ZinIrTensor *,std::piecewise_construct_t const&,std::tuple<ZinIrTensor * const&>,std::tuple<>>(a4, (uint64_t *)&v19, (uint64_t)&std::piecewise_construct, (uint64_t **)&p_RootTensor);
          std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>((uint64_t **)v15 + 5, &v21, (uint64_t *)&v21);
        }
      }
      unint64_t v16 = (void *)v5[1];
      if (v16)
      {
        do
        {
          unint64_t v17 = v16;
          unint64_t v16 = (void *)*v16;
        }
        while (v16);
      }
      else
      {
        do
        {
          unint64_t v17 = (void *)v5[2];
          BOOL v18 = *v17 == (void)v5;
          uint64_t v5 = v17;
        }
        while (!v18);
      }
      uint64_t v5 = v17;
    }
    while (v17 != v4);
  }
}

uint64_t PressureBasedSubgraphIdentification::DeterminePreResetCostModelParameters(uint64_t a1, void *a2, uint64_t **a3)
{
  uint64_t v74 = *MEMORY[0x263EF8340];
  memset(v69, 0, sizeof(v69));
  int v70 = 1065353216;
  memset(v67, 0, sizeof(v67));
  int v68 = 1065353216;
  uint64_t v56 = (uint64_t *)v57;
  v57[0] = 0;
  v59[0] = 0;
  v59[1] = 0;
  v57[1] = 0;
  long long v58 = v59;
  v60[0] = v60;
  v60[1] = v60;
  v62[0] = 0;
  v62[1] = 0;
  v60[2] = 0;
  unint64_t v61 = v62;
  memset(v63, 0, sizeof(v63));
  v65[0] = 0;
  v65[1] = 0;
  uint64_t v64 = v65;
  char v66 = 0;
  PressureBasedSubgraphIdentification::IdentifyInputOutputNodes(a1, a2, &v56);
  uint64_t v5 = v56;
  if (v56 != (uint64_t *)v57)
  {
    int64_t v6 = a2 + 1;
    uint64_t v7 = &_os_log_internal;
    do
    {
      uint64_t v8 = v5[4];
      if (*(_DWORD *)(*(void *)(v8 + 64) + 8) == 7)
      {
        BOOL v10 = *(void **)(v8 + 88);
        uint64_t v9 = *(void **)(v8 + 96);
        while (1)
        {
          if (v10 == v9) {
            ZinAssertImpl("A concat cannot be a full input to a subgraph", v60);
          }
          *(void *)&long long buf = *v10;
          if (v6 != (void *)std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>((uint64_t)a2, (ZinIrOpLayer **)&buf))break; {
          ++v10;
          }
        }
      }
      else
      {
        if (*(unsigned char *)(a1 + 73) && os_log_type_enabled(v7, OS_LOG_TYPE_INFO))
        {
          int v11 = (void *)(v8 + 24);
          if (*(char *)(v8 + 47) < 0) {
            int v11 = (void *)*v11;
          }
          LODWORD(buf) = 136315138;
          *(void *)((char *)&buf + 4) = v11;
          _os_log_impl(&dword_210C72000, v7, OS_LOG_TYPE_INFO, "\tInput Node : %s", (uint8_t *)&buf, 0xCu);
        }
        uint64_t v13 = *(void **)(v8 + 88);
        unint64_t v12 = *(void **)(v8 + 96);
        while (v13 != v12)
        {
          *(void *)&long long buf = 0;
          *(void *)&long long buf = *v13;
          if (v6 == (void *)std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>((uint64_t)a2, (ZinIrOpLayer **)&buf))
          {
            int v14 = (ZinIrTensor *)(*(uint64_t (**)(void, void, void))(*(void *)buf + 32))(buf, 0, 0);
            RootTensor = ZinIrTensor::GetRootTensor(v14);
            std::__hash_table<ZinIrTensor const*,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const* const&>((uint64_t)v69, &RootTensor, &RootTensor);
          }
          ++v13;
        }
      }
      unint64_t v15 = (uint64_t *)v5[1];
      if (v15)
      {
        do
        {
          unint64_t v16 = v15;
          unint64_t v15 = (uint64_t *)*v15;
        }
        while (v15);
      }
      else
      {
        do
        {
          unint64_t v16 = (uint64_t *)v5[2];
          BOOL v17 = *v16 == (void)v5;
          uint64_t v5 = v16;
        }
        while (!v17);
      }
      uint64_t v5 = v16;
    }
    while (v16 != (uint64_t *)v57);
  }
  BOOL v18 = v58;
  if (v58 != v59)
  {
    unint64_t v19 = &_os_log_internal;
    do
    {
      unint64_t v20 = (char *)v18[4];
      if (*(unsigned char *)(a1 + 73) && os_log_type_enabled(v19, OS_LOG_TYPE_INFO))
      {
        uint64_t v21 = v20 + 24;
        if (v20[47] < 0) {
          uint64_t v21 = (void *)*v21;
        }
        LODWORD(buf) = 136315138;
        *(void *)((char *)&buf + 4) = v21;
        _os_log_impl(&dword_210C72000, v19, OS_LOG_TYPE_INFO, "\tOutput Node : %s", (uint8_t *)&buf, 0xCu);
      }
      int64_t v22 = (ZinIrTensor *)(*(uint64_t (**)(char *, void, void))(*(void *)v20 + 32))(v20, 0, 0);
      *(void *)&long long buf = ZinIrTensor::GetRootTensor(v22);
      std::__hash_table<ZinIrTensor const*,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const* const&>((uint64_t)v67, &buf, &buf);
      int v23 = (void *)v18[1];
      if (v23)
      {
        do
        {
          uint64_t v24 = (void **)v23;
          int v23 = (void *)*v23;
        }
        while (v23);
      }
      else
      {
        do
        {
          uint64_t v24 = (void **)v18[2];
          BOOL v17 = *v24 == v18;
          BOOL v18 = v24;
        }
        while (!v17);
      }
      BOOL v18 = v24;
    }
    while (v24 != v59);
  }
  uint64_t v27 = (void *)*a2;
  unint64_t v26 = a2 + 1;
  uint64_t v25 = v27;
  if (v27 != v26)
  {
    do
    {
      unint64_t v28 = (ZinIrOpLayer *)v25[4];
      if (ZinIrOpLayer::IsANELayer(v28))
      {
        char v55 = v28;
        long long buf = 0uLL;
        __int16 v73 = 0;
        int64_t v72 = 0;
        (*(void (**)(ZinIrTensor **__return_ptr, ZinIrOpLayer *))(*(void *)v28 + 512))(&RootTensor, v28);
        uint64_t v29 = (ZinIrTensor **)RootTensor;
        unint64_t v30 = (ZinIrTensor **)v54;
        if (RootTensor != v54)
        {
          do
          {
            BOOL v31 = *v29;
            if (!(*(unsigned int (**)(ZinIrOpLayer *))(*(void *)v55 + 120))(v55)) {
              goto LABEL_44;
            }
            (*(void (**)(ZinIrTensor **__return_ptr))(*(void *)v55 + 128))(&v51);
            uint64_t v32 = v51;
            if (v52) {
              std::__shared_weak_count::__release_shared[abi:ne180100](v52);
            }
            if (v31 != v32)
            {
LABEL_44:
              uint64_t v51 = ZinIrTensor::GetRootTensor(v31);
              long long v33 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(v69, &v51);
              uint64_t v34 = v33;
              uint64_t v35 = *((void *)&buf + 1);
              if (*((void *)&buf + 1) >= (unint64_t)v72)
              {
                uint64_t v37 = *((void *)&buf + 1) - buf;
                if ((uint64_t)(*((void *)&buf + 1) - buf) <= -3) {
                  std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
                }
                uint64_t v38 = v37 >> 1;
                if ((unint64_t)&v72[-buf] <= (v37 >> 1) + 1) {
                  uint64_t v39 = v38 + 1;
                }
                else {
                  uint64_t v39 = (uint64_t)&v72[-buf];
                }
                if ((unint64_t)&v72[-buf] >= 0x7FFFFFFFFFFFFFFELL) {
                  uint64_t v40 = 0x7FFFFFFFFFFFFFFFLL;
                }
                else {
                  uint64_t v40 = v39;
                }
                if (v40) {
                  unint64_t v41 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<half>>((uint64_t)&v72, v40);
                }
                else {
                  unint64_t v41 = 0;
                }
                uint64_t v42 = &v41[2 * v38];
                *(_WORD *)uint64_t v42 = (v34 == 0) | 0x100;
                uint64_t v36 = v42 + 2;
                unint64_t v43 = (char *)*((void *)&buf + 1);
                long long v44 = (char *)buf;
                if (*((void *)&buf + 1) != (void)buf)
                {
                  do
                  {
                    __int16 v45 = *((_WORD *)v43 - 1);
                    v43 -= 2;
                    *((_WORD *)v42 - 1) = v45;
                    v42 -= 2;
                  }
                  while (v43 != v44);
                  unint64_t v43 = (char *)buf;
                }
                *(void *)&long long buf = v42;
                *((void *)&buf + 1) = v36;
                int64_t v72 = &v41[2 * v40];
                if (v43) {
                  operator delete(v43);
                }
              }
              else
              {
                **((_WORD **)&buf + 1) = (v33 == 0) | 0x100;
                uint64_t v36 = (_WORD *)(v35 + 2);
              }
              *((void *)&buf + 1) = v36;
            }
            ++v29;
          }
          while (v29 != v30);
          uint64_t v29 = (ZinIrTensor **)RootTensor;
        }
        if (v29)
        {
          uint64_t v54 = (ZinIrTensor *)v29;
          operator delete(v29);
        }
        long long v46 = (ZinIrTensor *)(*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)v55 + 32))(v55, 0, 0);
        RootTensor = ZinIrTensor::GetRootTensor(v46);
        __int16 v73 = (std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(v67, &RootTensor) == 0) | 0x100;
        std::__tree<std::__value_type<ZinANELayer *,CostModelParameters>,std::__map_value_compare<ZinANELayer *,std::__value_type<ZinANELayer *,CostModelParameters>,ScheduleComparator,true>,std::allocator<std::__value_type<ZinANELayer *,CostModelParameters>>>::__emplace_unique_key_args<ZinANELayer *,ZinANELayer *&,CostModelParameters&>(a3, &v55, &v55, (uint64_t)&buf);
        if ((void)buf)
        {
          *((void *)&buf + 1) = buf;
          operator delete((void *)buf);
        }
      }
      uint64_t v47 = (void *)v25[1];
      if (v47)
      {
        do
        {
          uint64_t v48 = v47;
          uint64_t v47 = (void *)*v47;
        }
        while (v47);
      }
      else
      {
        do
        {
          uint64_t v48 = (void *)v25[2];
          BOOL v17 = *v48 == (void)v25;
          uint64_t v25 = v48;
        }
        while (!v17);
      }
      uint64_t v25 = v48;
    }
    while (v48 != v26);
  }
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v64, v65[0]);
  *(void *)&long long buf = v63;
  std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100]((void ***)&buf);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v61, v62[0]);
  std::__list_imp<ZinIrSection *>::clear(v60);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v58, v59[0]);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v56, v57[0]);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v67);
  return std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v69);
}

void sub_21128C4F4(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, void *__p, uint64_t a17, uint64_t a18, uint64_t a19, char a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33,uint64_t a34,uint64_t a35,uint64_t a36,uint64_t a37,uint64_t a38,char a39)
{
  Subgraph::~Subgraph((Subgraph *)&a20);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&a39);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table(v39 - 192);
  _Unwind_Resume(a1);
}

void PressureBasedSubgraphIdentification::IdentifyInputOutputNodes(uint64_t a1, void *a2, uint64_t **a3)
{
  uint64_t v3 = a2 + 1;
  uint64_t v4 = (void *)*a2;
  if ((void *)*a2 != a2 + 1)
  {
    uint64_t v7 = a3 + 3;
    do
    {
      unint64_t v16 = (ZinIrOpLayer *)v4[4];
      uint64_t v8 = (ZinIrOpLayer **)*((void *)v16 + 11);
      uint64_t v9 = (ZinIrOpLayer **)*((void *)v16 + 12);
      while (v8 != v9)
      {
        unint64_t v15 = 0;
        unint64_t v15 = *v8;
        if (!std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)a2, &v15))
        {
          std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>(a3, &v16, (uint64_t *)&v16);
          break;
        }
        ++v8;
      }
      BOOL v10 = (ZinIrOpLayer **)*((void *)v16 + 14);
      int v11 = (ZinIrOpLayer **)*((void *)v16 + 15);
      while (v10 != v11)
      {
        unint64_t v15 = 0;
        unint64_t v15 = *v10;
        if (!std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)a2, &v15))
        {
          std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>(v7, &v16, (uint64_t *)&v16);
          break;
        }
        ++v10;
      }
      unint64_t v12 = (void *)v4[1];
      if (v12)
      {
        do
        {
          uint64_t v13 = v12;
          unint64_t v12 = (void *)*v12;
        }
        while (v12);
      }
      else
      {
        do
        {
          uint64_t v13 = (void *)v4[2];
          BOOL v14 = *v13 == (void)v4;
          uint64_t v4 = v13;
        }
        while (!v14);
      }
      uint64_t v4 = v13;
    }
    while (v13 != v3);
  }
}

void PressureBasedSubgraphIdentification::DeterminePostResetCostModelParameters(uint64_t a1, uint64_t a2, void *a3, void *a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t **a8)
{
  uint64_t v8 = (void *)*a3;
  uint64_t v48 = a3 + 1;
  if ((void *)*a3 != a3 + 1)
  {
    uint64_t v9 = a8;
    BOOL v10 = a8 + 1;
    long long v46 = (void *)(a6 + 8);
    uint64_t v47 = (void *)(a5 + 8);
    while (1)
    {
      unint64_t v61 = (ZinIrOpLayer *)v8[4];
      if (v47 != std::__tree<ZinIrOpLayer *,ZinIrIdComparator<ZinIrOpLayer *>,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>(a5, (uint64_t *)&v61))
      {
        int v11 = (void *)std::map<ZinIrOpLayer *,long,ZinIrIdComparator<ZinIrOpLayer *>,std::allocator<std::pair<ZinIrOpLayer * const,long>>>::at(a5, (uint64_t *)&v61);
        uint64_t v13 = v11 + 1;
        unint64_t v12 = (void *)*v11;
        if ((void *)*v11 != v11 + 1)
        {
          do
          {
            unint64_t v60 = (ZinIrOpLayer *)v12[4];
            long long __p = 0;
            uint64_t v57 = 0;
            __int16 v59 = 0;
            uint64_t v58 = 0;
            if (v10 == (uint64_t **)std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>((uint64_t)v9, &v60))uint64_t v14 = std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at(a7, &v60); {
            else
            }
              uint64_t v14 = std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)v9, &v60);
            if (&__p != (void **)v14) {
              std::vector<std::optional<BOOL>>::__assign_with_size[abi:ne180100]<std::optional<BOOL> const*,std::optional<BOOL> const*>((char *)&__p, *(char **)v14, *(void *)(v14 + 8), (uint64_t)(*(void *)(v14 + 8) - *(void *)v14) >> 1);
            }
            __int16 v59 = 256;
            uint64_t v54 = &v60;
            unint64_t v15 = std::__tree<std::__value_type<ZinANELayer *,CostModelParameters>,std::__map_value_compare<ZinANELayer *,std::__value_type<ZinANELayer *,CostModelParameters>,ScheduleComparator,true>,std::allocator<std::__value_type<ZinANELayer *,CostModelParameters>>>::__emplace_unique_key_args<ZinANELayer *,std::piecewise_construct_t const&,std::tuple<ZinANELayer * const&>,std::tuple<>>(v9, &v60, (uint64_t)&std::piecewise_construct, &v54);
            if (v15 + 40 != (char *)&__p) {
              std::vector<std::optional<BOOL>>::__assign_with_size[abi:ne180100]<std::optional<BOOL> const*,std::optional<BOOL> const*>(v15 + 40, (char *)__p, (uint64_t)v57, (v57 - (unsigned char *)__p) >> 1);
            }
            *((_WORD *)v15 + std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = v59;
            if (__p)
            {
              uint64_t v57 = __p;
              operator delete(__p);
            }
            unint64_t v16 = (void *)v12[1];
            if (v16)
            {
              do
              {
                BOOL v17 = v16;
                unint64_t v16 = (void *)*v16;
              }
              while (v16);
            }
            else
            {
              do
              {
                BOOL v17 = (void *)v12[2];
                BOOL v18 = *v17 == (void)v12;
                unint64_t v12 = v17;
              }
              while (!v18);
            }
            unint64_t v12 = v17;
          }
          while (v17 != v13);
        }
      }
      if (v46 != std::__tree<ZinIrOpLayer *,ZinIrIdComparator<ZinIrOpLayer *>,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>(a6, (uint64_t *)&v61))
      {
        unint64_t v19 = (void *)std::map<ZinIrOpLayer *,long,ZinIrIdComparator<ZinIrOpLayer *>,std::allocator<std::pair<ZinIrOpLayer * const,long>>>::at(a6, (uint64_t *)&v61);
        unint64_t v20 = (void *)*v19;
        unint64_t v52 = v19 + 1;
        if ((void *)*v19 != v19 + 1) {
          break;
        }
      }
LABEL_48:
      uint64_t v36 = (void *)v8[1];
      if (v36)
      {
        do
        {
          uint64_t v37 = v36;
          uint64_t v36 = (void *)*v36;
        }
        while (v36);
      }
      else
      {
        do
        {
          uint64_t v37 = (void *)v8[2];
          BOOL v18 = *v37 == (void)v8;
          uint64_t v8 = v37;
        }
        while (!v18);
      }
      uint64_t v8 = v37;
      if (v37 == v48) {
        goto LABEL_54;
      }
    }
    while (1)
    {
      unint64_t v60 = (ZinIrOpLayer *)v20[4];
      long long __p = 0;
      uint64_t v57 = 0;
      __int16 v59 = 0;
      uint64_t v58 = 0;
      if (v10 == (uint64_t **)std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>((uint64_t)v9, &v60))
      {
        uint64_t v21 = std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at(a7, &v60);
        uint64_t v22 = v21;
        if (&__p != (void **)v21) {
LABEL_26:
        }
          std::vector<std::optional<BOOL>>::__assign_with_size[abi:ne180100]<std::optional<BOOL> const*,std::optional<BOOL> const*>((char *)&__p, *(char **)v21, *(void *)(v21 + 8), (uint64_t)(*(void *)(v21 + 8) - *(void *)v21) >> 1);
      }
      else
      {
        uint64_t v21 = std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)v9, &v60);
        uint64_t v22 = v21;
        if (&__p != (void **)v21) {
          goto LABEL_26;
        }
      }
      int v23 = v10;
      __int16 v59 = *(_WORD *)(v22 + 24);
      uint64_t v24 = v60;
      uint64_t v25 = *((void *)v60 + 11);
      if (*((void *)v60 + 12) != v25)
      {
        unint64_t v26 = 0;
        unint64_t v27 = 0;
        do
        {
          uint64_t v28 = *(void *)(v25 + 8 * v26);
          if (((*(uint64_t (**)(ZinIrOpLayer *))(*(void *)v24 + 120))(v24) & 1) == 0) {
            goto LABEL_33;
          }
          uint64_t v29 = *(ZinIrOpLayer ***)(*(uint64_t (**)(uint64_t, void, void))(*(void *)v28 + 40))(v28, 0, 0);
          (*(void (**)(ZinIrOpLayer ***__return_ptr))(*(void *)v60 + 128))(&v54);
          unint64_t v30 = v54;
          if (v55) {
            std::__shared_weak_count::__release_shared[abi:ne180100](v55);
          }
          if (v29 == v30)
          {
            --v27;
          }
          else
          {
LABEL_33:
            BOOL v31 = (ZinIrTensor *)(*(uint64_t (**)(uint64_t, void, void))(*(void *)v28 + 32))(v28, 0, 0);
            RootTensor = ZinIrTensor::GetRootTensor(v31);
            if (RootTensor == v61)
            {
              if (v27 >= (v57 - (unsigned char *)__p) >> 1) {
                std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
              }
              *((_WORD *)__p + v27) = 256;
            }
          }
          ++v26;
          ++v27;
          uint64_t v24 = v60;
          uint64_t v25 = *((void *)v60 + 11);
        }
        while (v26 < (*((void *)v60 + 12) - v25) >> 3);
      }
      uint64_t v54 = &v60;
      long long v33 = std::__tree<std::__value_type<ZinANELayer *,CostModelParameters>,std::__map_value_compare<ZinANELayer *,std::__value_type<ZinANELayer *,CostModelParameters>,ScheduleComparator,true>,std::allocator<std::__value_type<ZinANELayer *,CostModelParameters>>>::__emplace_unique_key_args<ZinANELayer *,std::piecewise_construct_t const&,std::tuple<ZinANELayer * const&>,std::tuple<>>(a8, &v60, (uint64_t)&std::piecewise_construct, &v54);
      if (v33 + 40 != (char *)&__p) {
        std::vector<std::optional<BOOL>>::__assign_with_size[abi:ne180100]<std::optional<BOOL> const*,std::optional<BOOL> const*>(v33 + 40, (char *)__p, (uint64_t)v57, (v57 - (unsigned char *)__p) >> 1);
      }
      *((_WORD *)v33 + std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = v59;
      if (__p)
      {
        uint64_t v57 = __p;
        operator delete(__p);
      }
      uint64_t v34 = (void *)v20[1];
      BOOL v10 = v23;
      if (v34)
      {
        do
        {
          uint64_t v35 = v34;
          uint64_t v34 = (void *)*v34;
        }
        while (v34);
      }
      else
      {
        do
        {
          uint64_t v35 = (void *)v20[2];
          BOOL v18 = *v35 == (void)v20;
          unint64_t v20 = v35;
        }
        while (!v18);
      }
      unint64_t v20 = v35;
      uint64_t v9 = a8;
      if (v35 == v52) {
        goto LABEL_48;
      }
    }
  }
LABEL_54:
  uint64_t v38 = a2;
  uint64_t v39 = (void *)*a4;
  if ((void *)*a4 != a4 + 1)
  {
    do
    {
      unint64_t v61 = *(ZinIrOpLayer **)(v39[4] + 96);
      if (a2 + 8 != std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>(v38, &v61)&& ZinIrOpLayer::IsANELayer(v61))
      {
        unint64_t v60 = v61;
        long long __p = 0;
        uint64_t v57 = 0;
        __int16 v59 = 0;
        uint64_t v58 = 0;
        if (a8 + 1 == (uint64_t **)std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>((uint64_t)a8, &v60))uint64_t v40 = std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at(a7, &v60); {
        else
        }
          uint64_t v40 = std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)a8, &v60);
        if (&__p != (void **)v40) {
          std::vector<std::optional<BOOL>>::__assign_with_size[abi:ne180100]<std::optional<BOOL> const*,std::optional<BOOL> const*>((char *)&__p, *(char **)v40, *(void *)(v40 + 8), (uint64_t)(*(void *)(v40 + 8) - *(void *)v40) >> 1);
        }
        __int16 v59 = 256;
        uint64_t v54 = &v60;
        unint64_t v41 = std::__tree<std::__value_type<ZinANELayer *,CostModelParameters>,std::__map_value_compare<ZinANELayer *,std::__value_type<ZinANELayer *,CostModelParameters>,ScheduleComparator,true>,std::allocator<std::__value_type<ZinANELayer *,CostModelParameters>>>::__emplace_unique_key_args<ZinANELayer *,std::piecewise_construct_t const&,std::tuple<ZinANELayer * const&>,std::tuple<>>(a8, &v60, (uint64_t)&std::piecewise_construct, &v54);
        if (v41 + 40 != (char *)&__p) {
          std::vector<std::optional<BOOL>>::__assign_with_size[abi:ne180100]<std::optional<BOOL> const*,std::optional<BOOL> const*>(v41 + 40, (char *)__p, (uint64_t)v57, (v57 - (unsigned char *)__p) >> 1);
        }
        *((_WORD *)v41 + std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = v59;
        if (__p)
        {
          uint64_t v57 = __p;
          operator delete(__p);
        }
        uint64_t v38 = a2;
      }
      uint64_t v42 = (void *)v39[1];
      if (v42)
      {
        do
        {
          unint64_t v43 = v42;
          uint64_t v42 = (void *)*v42;
        }
        while (v42);
      }
      else
      {
        do
        {
          unint64_t v43 = (void *)v39[2];
          BOOL v18 = *v43 == (void)v39;
          uint64_t v39 = v43;
        }
        while (!v18);
      }
      uint64_t v39 = v43;
    }
    while (v43 != a4 + 1);
  }
}

void sub_21128CC7C(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,void *__p,uint64_t a22)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

double PressureBasedSubgraphIdentification::CalculateInputCopyCost(PressureBasedSubgraphIdentification *this, ZinIrOpLayerGraph *a2, const ZinIrTensor *a3)
{
  uint64_t v36 = *MEMORY[0x263EF8340];
  uint64_t v34 = a3;
  uint64_t v4 = (void *)((char *)this + 248);
  if (!std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)this + 31, &v34))
  {
    int64_t v6 = v34;
    uint64_t v7 = (void *)*((void *)v34 + 12);
    uint64_t v8 = v7[14];
    uint64_t v9 = v7[15];
    if (v8 != v9)
    {
      while (*(_DWORD *)(*(void *)(*(void *)v8 + 64) + 8) != 7)
      {
        v8 += 8;
        if (v8 == v9) {
          goto LABEL_7;
        }
      }
    }
    if (v8 != v9)
    {
      if (*((char *)v34 + 47) >= 0) {
        size_t v10 = *((unsigned __int8 *)v34 + 47);
      }
      else {
        size_t v10 = *((void *)v34 + 4);
      }
      int v11 = &v35;
      std::string::basic_string[abi:ne180100]((uint64_t)&v35, v10 + 1);
      if ((v35.__r_.__value_.__r.__words[2] & 0x8000000000000000) != 0) {
        int v11 = (std::string *)v35.__r_.__value_.__r.__words[0];
      }
      if (v10)
      {
        uint64_t v14 = (char *)*((void *)v6 + 3);
        uint64_t v13 = (char *)v6 + 24;
        unint64_t v12 = v14;
        if (v13[23] >= 0) {
          unint64_t v15 = v13;
        }
        else {
          unint64_t v15 = v12;
        }
        memmove(v11, v15, v10);
      }
      *(_WORD *)((char *)&v11->__r_.__value_.__l.__data_ + v10) = 95;
      (*(void (**)(void **__return_ptr, PressureBasedSubgraphIdentification *))(*(void *)this + 120))(v31, this);
      if ((v32 & 0x80u) == 0) {
        unint64_t v16 = (const std::string::value_type *)v31;
      }
      else {
        unint64_t v16 = (const std::string::value_type *)v31[0];
      }
      if ((v32 & 0x80u) == 0) {
        std::string::size_type v17 = v32;
      }
      else {
        std::string::size_type v17 = (std::string::size_type)v31[1];
      }
      BOOL v18 = std::string::append(&v35, v16, v17);
      long long v19 = *(_OWORD *)&v18->__r_.__value_.__l.__data_;
      v26.__r_.__value_.__r.__words[2] = v18->__r_.__value_.__r.__words[2];
      *(_OWORD *)&v26.__r_.__value_.__l.__data_ = v19;
      v18->__r_.__value_.__l.__size_ = 0;
      v18->__r_.__value_.__r.__words[2] = 0;
      v18->__r_.__value_.__r.__words[0] = 0;
      unint64_t v20 = std::string::append(&v26, "bypass_for_cm", 0xDuLL);
      long long v21 = *(_OWORD *)&v20->__r_.__value_.__l.__data_;
      std::string::size_type v28 = v20->__r_.__value_.__r.__words[2];
      *(_OWORD *)long long __p = v21;
      v20->__r_.__value_.__l.__size_ = 0;
      v20->__r_.__value_.__r.__words[2] = 0;
      v20->__r_.__value_.__r.__words[0] = 0;
      ZinObjectNameFactory::ZinObjectNameFactory(&v33, __p);
      if (SHIBYTE(v28) < 0) {
        operator delete(__p[0]);
      }
      if (SHIBYTE(v26.__r_.__value_.__r.__words[2]) < 0) {
        operator delete(v26.__r_.__value_.__l.__data_);
      }
      if ((char)v32 < 0) {
        operator delete(v31[0]);
      }
      if (SHIBYTE(v35.__r_.__value_.__r.__words[2]) < 0) {
        operator delete(v35.__r_.__value_.__l.__data_);
      }
      uint64_t v22 = v7[2];
      uint64_t v23 = *((void *)v34 + 12);
      uint64_t v24 = *((unsigned int *)v34 + 22);
      uint64_t v30 = 0;
      v29[0] = 0;
      v29[168] = 0;
      ZinBuilder::CreateNEBypass(v22, (uint64_t)&v33, v23, v24, &v30, 0, (uint64_t)v29, 1.0);
    }
LABEL_7:
    ZinAssertImpl("Invalid and unnecessary copy analyzed");
  }
  uint64_t v5 = (double *)std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::find<ZinIrTensor *>(v4, &v34);
  if (!v5) {
    std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
  }
  return v5[3];
}

void sub_21128D1B4(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, void *a9, uint64_t a10, uint64_t a11, uint64_t a12, void *__p, uint64_t a14, int a15, __int16 a16, char a17, char a18, uint64_t a19, void *a20,void *a21,uint64_t a22)
{
  if (__p) {
    operator delete(__p);
  }
  ZinIrNetworkStatus::~ZinIrNetworkStatus((ZinIrNetworkStatus *)&a20);
  *(void *)(v22 - 192) = &unk_26C34DA98;
  if (*(char *)(v22 - 161) < 0) {
    operator delete(*(void **)(v22 - 184));
  }
  _Unwind_Resume(a1);
}

void PressureBasedSubgraphIdentification::FindMinimumCostDescriptor(uint64_t *a1@<X1>, void *a2@<X2>, uint64_t a3@<X3>, unsigned char *a4@<X8>)
{
  long long __p = 0;
  uint64_t v40 = 0;
  unint64_t v41 = 0;
  uint64_t v5 = *a1;
  if (a1[1] == *a1) {
    goto LABEL_43;
  }
  uint64_t v36 = a4;
  unint64_t v7 = 0;
  do
  {
    uint64_t v8 = v5 + 16 * v7;
    uint64_t v9 = std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at(a3, (ZinIrOpLayer **)(v8 + 8));
    uint64_t v11 = *a1;
    uint64_t v10 = a1[1];
    if (v10 != *a1)
    {
      unint64_t v12 = (void **)v9;
      uint64_t v13 = 0;
      unint64_t v14 = 0;
      unint64_t v15 = (void *)(v9 + 8);
      do
      {
        if (v7 != v14 && *(double *)v8 == *(double *)(v11 + v13))
        {
          unint64_t v16 = (void **)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at(a3, (ZinIrOpLayer **)(v11 + v13 + 8));
          BOOL v17 = std::__includes[abi:ne180100]<std::__tree_const_iterator<ZinIrTensor const*,std::__tree_node<ZinIrTensor const*,void *> *,long>,std::__tree_const_iterator<ZinIrTensor const*,std::__tree_node<ZinIrTensor const*,void *> *,long>,std::__tree_const_iterator<ZinIrTensor const*,std::__tree_node<ZinIrTensor const*,void *> *,long>,std::__tree_const_iterator<ZinIrTensor const*,std::__tree_node<ZinIrTensor const*,void *> *,long>,ZinIrIdComparator<ZinIrTensor const*> &,std::__identity,std::__identity>(*v16, v16 + 1, *v12, v15);
          if (std::__includes[abi:ne180100]<std::__tree_const_iterator<ZinIrTensor const*,std::__tree_node<ZinIrTensor const*,void *> *,long>,std::__tree_const_iterator<ZinIrTensor const*,std::__tree_node<ZinIrTensor const*,void *> *,long>,std::__tree_const_iterator<ZinIrTensor const*,std::__tree_node<ZinIrTensor const*,void *> *,long>,std::__tree_const_iterator<ZinIrTensor const*,std::__tree_node<ZinIrTensor const*,void *> *,long>,ZinIrIdComparator<ZinIrTensor const*> &,std::__identity,std::__identity>(*v12, v15, *v16, v16 + 1)&& !v17)
          {
            goto LABEL_27;
          }
          uint64_t v11 = *a1;
          uint64_t v10 = a1[1];
        }
        ++v14;
        v13 += 16;
      }
      while (v14 < (v10 - v11) >> 4);
    }
    if (v40 >= v41)
    {
      uint64_t v19 = (v40 - __p) >> 4;
      unint64_t v20 = v19 + 1;
      if ((unint64_t)(v19 + 1) >> 60) {
        std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
      }
      uint64_t v21 = v41 - __p;
      if ((v41 - __p) >> 3 > v20) {
        unint64_t v20 = v21 >> 3;
      }
      if ((unint64_t)v21 >= 0x7FFFFFFFFFFFFFF0) {
        unint64_t v22 = 0xFFFFFFFFFFFFFFFLL;
      }
      else {
        unint64_t v22 = v20;
      }
      if (v22) {
        uint64_t v23 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<std::pair<unsigned long,unsigned long>>>((uint64_t)&v41, v22);
      }
      else {
        uint64_t v23 = 0;
      }
      uint64_t v24 = &v23[16 * v19];
      *(_OWORD *)uint64_t v24 = *(_OWORD *)v8;
      uint64_t v25 = v40;
      std::string v26 = v24;
      if (v40 != __p)
      {
        do
        {
          *((_OWORD *)v26 - 1) = *((_OWORD *)v25 - 1);
          v26 -= 16;
          v25 -= 16;
        }
        while (v25 != __p);
        uint64_t v25 = __p;
      }
      BOOL v18 = v24 + 16;
      long long __p = v26;
      unint64_t v41 = &v23[16 * v22];
      if (v25) {
        operator delete(v25);
      }
    }
    else
    {
      *(_OWORD *)uint64_t v40 = *(_OWORD *)v8;
      BOOL v18 = v40 + 16;
    }
    uint64_t v40 = v18;
LABEL_27:
    ++v7;
    uint64_t v5 = *a1;
  }
  while (v7 < (a1[1] - *a1) >> 4);
  unint64_t v27 = __p;
  a4 = v36;
  if (__p == v40) {
    goto LABEL_43;
  }
  for (unint64_t i = __p + 16; i != v40; i += 16)
  {
    uint64_t v29 = (uint64_t *)*((void *)i + 1);
    if (v29)
    {
      uint64_t v30 = (uint64_t *)*((void *)v27 + 1);
      if (!v30
        || *(double *)i < *(double *)v27
        || *(double *)v27 >= *(double *)i
        && ((uint64_t v31 = PressureBasedSubgraphIdentification::ComputeTimeSpanOfCluster(a2),
             double v33 = ((double)v31 + (double)v32) * 0.5,
             double v34 = vabdd_f64((double)v29[6], v33),
             double v35 = vabdd_f64((double)v30[6], v33),
             v34 < v35)
         || v35 >= v34 && ScheduleComparator::operator()((int)&v42, (ZinIrOpLayer *)v29, (ZinIrOpLayer *)v30)))
      {
        unint64_t v27 = i;
      }
    }
  }
  if (v27 == v40)
  {
LABEL_43:
    *a4 = 0;
    a4[16] = 0;
  }
  else
  {
    *(_OWORD *)uint64_t v36 = *(_OWORD *)v27;
    v36[16] = 1;
  }
  if (__p) {
    operator delete(__p);
  }
}

void sub_21128D610(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, void *__p, uint64_t a14)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

ZinIrOpLayer **PressureBasedSubgraphIdentification::DetermineBestLayerFromCostModel(unsigned char *a1, ZinIrOpLayerGraph *a2, void *a3, void *a4)
{
  v116[19] = *MEMORY[0x263EF8340];
  if (a1[73] && os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_INFO))
  {
    *(_WORD *)long long buf = 0;
    _os_log_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_INFO, "\tDetermineBestLayerFromCostModel", buf, 2u);
  }
  v106[0] = 0;
  v106[1] = 0;
  v104[1] = 0;
  std::string v105 = (ZinIrOpLayer **)v106;
  std::string v103 = v104;
  v104[0] = 0;
  (*(void (**)(unsigned char *, void *, ZinIrOpLayer ***, void ***))(*(void *)a1 + 168))(a1, a3, &v105, &v103);
  v102[0] = 0;
  v102[1] = 0;
  v100[1] = 0;
  uint64_t v101 = v102;
  char v99 = v100;
  v100[0] = 0;
  (*(void (**)(unsigned char *, void *, void ***, void ***))(*(void *)a1 + 184))(a1, a3, &v101, &v99);
  v98[0] = 0;
  v98[1] = 0;
  char v97 = v98;
  (*(void (**)(unsigned char *, void *, void ***))(*(void *)a1 + 176))(a1, a3, &v97);
  uint64_t v74 = a4;
  uint64_t v94 = 0;
  uint64_t v95 = 0;
  long long v96 = 0;
  uint64_t v8 = v105;
  if (v105 == (ZinIrOpLayer **)v106) {
    goto LABEL_115;
  }
  uint64_t v77 = *MEMORY[0x263F8C2B8];
  uint64_t v75 = *(void *)(MEMORY[0x263F8C2B8] + 72);
  uint64_t v76 = *(void *)(MEMORY[0x263F8C2B8] + 64);
  uint64_t v9 = &_os_log_internal;
  uint64_t v78 = a3;
  do
  {
    v93[0] = 0;
    v93[1] = 0;
    uint64_t v92 = v93;
    uint64_t v79 = v8 + 4;
    if (v104 == (void **)std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>((uint64_t)&v103, v8 + 4))ZinAssertImpl("Invalid cost model internal state"); {
    uint64_t v10 = std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)&v103, v79);
    }
    (*(void (**)(unsigned char *, void *, void **, uint64_t, void ***, void ***, void ***, void ***))(*(void *)a1 + 192))(a1, a3, (void **)v8 + 5, v10, &v101, &v99, &v97, &v92);
    if (a1[75] && os_log_type_enabled(v9, OS_LOG_TYPE_INFO))
    {
      uint64_t v11 = (void *)((char *)*v79 + 24);
      if (*((char *)*v79 + 47) < 0) {
        uint64_t v11 = (void *)*v11;
      }
      *(_DWORD *)long long buf = 136315138;
      *(void *)&void buf[4] = v11;
      _os_log_impl(&dword_210C72000, v9, OS_LOG_TYPE_INFO, "\t\t\tChecking Potential Reset Layer %s", buf, 0xCu);
    }
    unint64_t v12 = v92;
    double v13 = 0.0;
    if (v92 != v93)
    {
      do
      {
        memset(buf, 0, sizeof(buf));
        LOBYTE(v114[0]) = 0;
        unint64_t v16 = v12[4];
        unint64_t v14 = v12[5];
        unint64_t v15 = v12 + 4;
        *(double *)&char v88 = 0.0;
        uint64_t v89 = 0;
        char v91 = 0;
        uint64_t v90 = 0;
        BOOL v17 = (void (***)(void, void *, uint8_t *, void **))*((void *)a1 + 30);
        long long v85 = 0;
        uint64_t v86 = 0;
        long long __p = 0;
        std::vector<unsigned short>::__init_with_size[abi:ne180100]<unsigned short const*,unsigned short const*>(&__p, v14, (uint64_t)v12[6], ((char *)v12[6] - (char *)v14) >> 1);
        __int16 v87 = *((_WORD *)v12 + 32);
        (**v17)(v17, v16, buf, &__p);
        if (__p)
        {
          long long v85 = __p;
          operator delete(__p);
        }
        BOOL v18 = (void (***)(void, char *, void **, void **))*((void *)a1 + 30);
        uint64_t v19 = (char *)*v15;
        uint64_t v20 = std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)&v97, (ZinIrOpLayer **)v12 + 4);
        uint64_t v80 = 0;
        uint64_t v81 = 0;
        uint64_t v82 = 0;
        std::vector<unsigned short>::__init_with_size[abi:ne180100]<unsigned short const*,unsigned short const*>(&v80, *(const void **)v20, *(void *)(v20 + 8), (uint64_t)(*(void *)(v20 + 8) - *(void *)v20) >> 1);
        __int16 v83 = *(_WORD *)(v20 + 24);
        (**v18)(v18, v19, &v88, &v80);
        if (v80)
        {
          uint64_t v81 = v80;
          operator delete(v80);
        }
        double v21 = *(double *)buf;
        unint64_t v22 = v88;
        if (*(double *)buf < *(double *)&v88) {
          ZinAssertImpl("Incorrect DRAM cost");
        }
        if (a1[75] && os_log_type_enabled(v9, OS_LOG_TYPE_INFO))
        {
          uint64_t v23 = *v15 + 3;
          if (*((char *)*v15 + 47) < 0) {
            uint64_t v23 = (void *)*v23;
          }
          *(_DWORD *)uint64_t v107 = 136315394;
          *(void *)&v107[4] = v23;
          __int16 v108 = 2048;
          double v109 = v21 - *(double *)&v22;
          _os_log_impl(&dword_210C72000, v9, OS_LOG_TYPE_INFO, "\t\t\t\t Engine Layer %s, Cost %f", v107, 0x16u);
        }
        uint64_t v24 = v12[1];
        if (v24)
        {
          do
          {
            uint64_t v25 = (void **)v24;
            uint64_t v24 = (void *)*v24;
          }
          while (v24);
        }
        else
        {
          do
          {
            uint64_t v25 = (void **)v12[2];
            BOOL v26 = *v25 == v12;
            unint64_t v12 = v25;
          }
          while (!v26);
        }
        double v13 = v13 + v21 - *(double *)&v22;
        unint64_t v12 = v25;
      }
      while (v25 != v93);
    }
    unint64_t v27 = (void *)std::map<ZinIrOpLayer const*,double,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer const* const,double>>>::at((uint64_t)&v103, v79);
    std::string::size_type v28 = v27 + 1;
    uint64_t v29 = (void *)*v27;
    if ((void *)*v27 != v27 + 1)
    {
      do
      {
        uint64_t v30 = (char *)v29[4];
        double v31 = PressureBasedSubgraphIdentification::CalculateInputCopyCost((PressureBasedSubgraphIdentification *)a1, a2, (const ZinIrTensor *)v30);
        if (a1[75] && os_log_type_enabled(v9, OS_LOG_TYPE_INFO))
        {
          uint64_t v32 = v30 + 24;
          if (v30[47] < 0) {
            uint64_t v32 = (void *)*v32;
          }
          *(_DWORD *)long long buf = 136315394;
          *(void *)&void buf[4] = v32;
          *(_WORD *)&unsigned char buf[12] = 2048;
          *(double *)&buf[14] = v31;
          _os_log_impl(&dword_210C72000, v9, OS_LOG_TYPE_INFO, "\t\t\t\t Copy Tensor %s, Cost %f", buf, 0x16u);
        }
        double v33 = (void *)v29[1];
        if (v33)
        {
          do
          {
            double v34 = v33;
            double v33 = (void *)*v33;
          }
          while (v33);
        }
        else
        {
          do
          {
            double v34 = (void *)v29[2];
            BOOL v26 = *v34 == (void)v29;
            uint64_t v29 = v34;
          }
          while (!v26);
        }
        double v13 = v13 + v31;
        uint64_t v29 = v34;
      }
      while (v34 != v28);
    }
    if (a1[73])
    {
      std::basic_stringstream<char,std::char_traits<char>,std::allocator<char>>::basic_stringstream[abi:ne180100]((uint64_t)buf);
      double v35 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&buf[16], (uint64_t)"\t\tReset Layer : ", 16);
      int v36 = *((char *)*v79 + 47);
      if (v36 >= 0) {
        uint64_t v37 = (uint64_t)*v79 + 24;
      }
      else {
        uint64_t v37 = *((void *)*v79 + 3);
      }
      if (v36 >= 0) {
        uint64_t v38 = *((unsigned __int8 *)*v79 + 47);
      }
      else {
        uint64_t v38 = *((void *)*v79 + 4);
      }
      uint64_t v39 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v35, v37, v38);
      std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v39, (uint64_t)" { ", 3);
      std::string::basic_string[abi:ne180100]<0>(&v88, &byte_211F4AA5D);
      uint64_t v40 = (ZinIrOpLayer **)v8[5];
      if (v40 != v8 + 6)
      {
        do
        {
          unint64_t v41 = v40[4];
          if (v90 >= 0) {
            char v42 = &v88;
          }
          else {
            char v42 = v88;
          }
          if (v90 >= 0) {
            uint64_t v43 = HIBYTE(v90);
          }
          else {
            uint64_t v43 = v89;
          }
          long long v44 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&buf[16], (uint64_t)v42, v43);
          uint64_t v47 = *((void *)v41 + 3);
          uint64_t v46 = (uint64_t)v41 + 24;
          uint64_t v45 = v47;
          int v48 = *(char *)(v46 + 23);
          if (v48 >= 0) {
            uint64_t v49 = v46;
          }
          else {
            uint64_t v49 = v45;
          }
          if (v48 >= 0) {
            uint64_t v50 = *(unsigned __int8 *)(v46 + 23);
          }
          else {
            uint64_t v50 = *(void *)(v46 + 8);
          }
          std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v44, v49, v50);
          if (SHIBYTE(v90) < 0)
          {
            uint64_t v89 = 2;
            uint64_t v51 = (char *)v88;
          }
          else
          {
            HIBYTE(v90) = 2;
            uint64_t v51 = (char *)&v88;
          }
          strcpy(v51, ", ");
          unint64_t v52 = v40[1];
          if (v52)
          {
            do
            {
              long long v53 = (ZinIrOpLayer **)v52;
              unint64_t v52 = *(ZinIrOpLayer **)v52;
            }
            while (v52);
          }
          else
          {
            do
            {
              long long v53 = (ZinIrOpLayer **)v40[2];
              BOOL v26 = *v53 == (ZinIrOpLayer *)v40;
              uint64_t v40 = v53;
            }
            while (!v26);
          }
          uint64_t v40 = v53;
        }
        while (v53 != v8 + 6);
      }
      std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&buf[16], (uint64_t)" } Cost : ", 10);
      std::ostream::operator<<();
      if (os_log_type_enabled(v9, OS_LOG_TYPE_INFO))
      {
        std::stringbuf::str[abi:ne180100]<std::allocator<char>>((uint64_t)v114, v107);
        uint64_t v54 = v107;
        if (v110 < 0) {
          uint64_t v54 = *(unsigned char **)v107;
        }
        *(_DWORD *)uint64_t v111 = 136315138;
        unint64_t v112 = v54;
        _os_log_impl(&dword_210C72000, v9, OS_LOG_TYPE_INFO, "%s", v111, 0xCu);
        if (v110 < 0) {
          operator delete(*(void **)v107);
        }
      }
      if (SHIBYTE(v90) < 0) {
        operator delete(v88);
      }
      *(void *)long long buf = v77;
      *(void *)&buf[*(void *)(v77 - 24)] = v76;
      *(void *)&uint8_t buf[16] = v75;
      v114[0] = MEMORY[0x263F8C318] + 16;
      if (v115 < 0) {
        operator delete((void *)v114[8]);
      }
      std::streambuf::~streambuf();
      std::iostream::~basic_iostream();
      MEMORY[0x21667D2B0](v116);
    }
    char v55 = *v79;
    uint64_t v56 = v95;
    if (v95 >= v96)
    {
      uint64_t v58 = ((char *)v95 - (unsigned char *)v94) >> 4;
      unint64_t v59 = v58 + 1;
      if ((unint64_t)(v58 + 1) >> 60) {
        std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
      }
      uint64_t v60 = (char *)v96 - (unsigned char *)v94;
      if (((char *)v96 - (unsigned char *)v94) >> 3 > v59) {
        unint64_t v59 = v60 >> 3;
      }
      if ((unint64_t)v60 >= 0x7FFFFFFFFFFFFFF0) {
        unint64_t v61 = 0xFFFFFFFFFFFFFFFLL;
      }
      else {
        unint64_t v61 = v59;
      }
      if (v61) {
        unsigned __int8 v62 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<std::pair<unsigned long,unsigned long>>>((uint64_t)&v96, v61);
      }
      else {
        unsigned __int8 v62 = 0;
      }
      uint64_t v63 = (double *)&v62[16 * v58];
      *uint64_t v63 = v13;
      *((void *)v63 + 1) = v55;
      char v65 = (char *)v94;
      uint64_t v64 = (char *)v95;
      char v66 = v63;
      if (v95 != v94)
      {
        do
        {
          *((_OWORD *)v66 - 1) = *((_OWORD *)v64 - 1);
          v66 -= 2;
          v64 -= 16;
        }
        while (v64 != v65);
        uint64_t v64 = (char *)v94;
      }
      uint64_t v57 = v63 + 2;
      uint64_t v94 = v66;
      uint64_t v95 = v63 + 2;
      long long v96 = (double *)&v62[16 * v61];
      if (v64) {
        operator delete(v64);
      }
    }
    else
    {
      *uint64_t v95 = v13;
      *((void *)v56 + 1) = v55;
      uint64_t v57 = v56 + 2;
    }
    uint64_t v95 = v57;
    std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::destroy((uint64_t)&v92, v93[0]);
    uint64_t v67 = v8[1];
    if (v67)
    {
      do
      {
        int v68 = (ZinIrOpLayer ***)v67;
        uint64_t v67 = *(ZinIrOpLayer **)v67;
      }
      while (v67);
    }
    else
    {
      do
      {
        int v68 = (ZinIrOpLayer ***)v8[2];
        BOOL v26 = *v68 == v8;
        uint64_t v8 = (ZinIrOpLayer **)v68;
      }
      while (!v26);
    }
    uint64_t v8 = (ZinIrOpLayer **)v68;
    a3 = v78;
  }
  while (v68 != v106);
  if (v94 == v95) {
LABEL_115:
  }
    ZinAssertImpl("Internal error: empty reset layer candidates in SS cost model");
  BestResetuint64_t Layer = PressureBasedSubgraphIdentification::FindBestResetLayer((uint64_t)a1, v78, (uint64_t *)&v94, (uint64_t)a2, v74, (uint64_t)&v105);
  int v70 = BestResetLayer;
  if (a1[73] && BestResetLayer && os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_INFO))
  {
    unint64_t v71 = v70 + 3;
    if (*((char *)v70 + 47) < 0) {
      unint64_t v71 = (void *)*v71;
    }
    int64_t v72 = v70[6];
    *(_DWORD *)long long buf = 136315394;
    *(void *)&void buf[4] = v71;
    *(_WORD *)&unsigned char buf[12] = 2048;
    *(void *)&buf[14] = v72;
    _os_log_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_INFO, "\tBest Reset Layer %s : %zu", buf, 0x16u);
  }
  if (v94)
  {
    uint64_t v95 = (double *)v94;
    operator delete(v94);
  }
  std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::destroy((uint64_t)&v97, v98[0]);
  std::__tree<std::__value_type<int,std::set<ZinIrInitInfo const*>>,std::__map_value_compare<int,std::__value_type<int,std::set<ZinIrInitInfo const*>>,std::less<int>,true>,std::allocator<std::__value_type<int,std::set<ZinIrInitInfo const*>>>>::destroy((uint64_t)&v99, v100[0]);
  std::__tree<std::__value_type<int,std::set<ZinIrInitInfo const*>>,std::__map_value_compare<int,std::__value_type<int,std::set<ZinIrInitInfo const*>>,std::less<int>,true>,std::allocator<std::__value_type<int,std::set<ZinIrInitInfo const*>>>>::destroy((uint64_t)&v101, v102[0]);
  std::__tree<std::__value_type<int,std::set<ZinIrInitInfo const*>>,std::__map_value_compare<int,std::__value_type<int,std::set<ZinIrInitInfo const*>>,std::less<int>,true>,std::allocator<std::__value_type<int,std::set<ZinIrInitInfo const*>>>>::destroy((uint64_t)&v103, v104[0]);
  std::__tree<std::__value_type<int,std::set<ZinIrInitInfo const*>>,std::__map_value_compare<int,std::__value_type<int,std::set<ZinIrInitInfo const*>>,std::less<int>,true>,std::allocator<std::__value_type<int,std::set<ZinIrInitInfo const*>>>>::destroy((uint64_t)&v105, v106[0]);
  return v70;
}

void sub_21128E13C(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,void *a27,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33,uint64_t a34,void *a35,uint64_t a36,uint64_t a37,uint64_t a38,uint64_t a39,uint64_t a40,uint64_t a41,void *__p,uint64_t a43,uint64_t a44,char a45,uint64_t a46,uint64_t a47,char a48,uint64_t a49,uint64_t a50,char a51,uint64_t a52,uint64_t a53,char a54,uint64_t a55,uint64_t a56,char a57,uint64_t a58)
{
  if (__p) {
    operator delete(__p);
  }
  std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::destroy((uint64_t)&a45, (void *)a46);
  std::__tree<std::__value_type<int,std::set<ZinIrInitInfo const*>>,std::__map_value_compare<int,std::__value_type<int,std::set<ZinIrInitInfo const*>>,std::less<int>,true>,std::allocator<std::__value_type<int,std::set<ZinIrInitInfo const*>>>>::destroy((uint64_t)&a48, (void *)a49);
  std::__tree<std::__value_type<int,std::set<ZinIrInitInfo const*>>,std::__map_value_compare<int,std::__value_type<int,std::set<ZinIrInitInfo const*>>,std::less<int>,true>,std::allocator<std::__value_type<int,std::set<ZinIrInitInfo const*>>>>::destroy((uint64_t)&a51, (void *)a52);
  std::__tree<std::__value_type<int,std::set<ZinIrInitInfo const*>>,std::__map_value_compare<int,std::__value_type<int,std::set<ZinIrInitInfo const*>>,std::less<int>,true>,std::allocator<std::__value_type<int,std::set<ZinIrInitInfo const*>>>>::destroy((uint64_t)&a54, (void *)a55);
  std::__tree<std::__value_type<int,std::set<ZinIrInitInfo const*>>,std::__map_value_compare<int,std::__value_type<int,std::set<ZinIrInitInfo const*>>,std::less<int>,true>,std::allocator<std::__value_type<int,std::set<ZinIrInitInfo const*>>>>::destroy((uint64_t)&a57, (void *)a58);
  _Unwind_Resume(a1);
}

ZinIrOpLayer **PressureBasedSubgraphIdentification::FindBestResetLayer(uint64_t a1, void *a2, uint64_t *a3, uint64_t a4, void *a5, uint64_t a6)
{
  uint64_t v10 = a2;
  PressureBasedSubgraphIdentification::FindMinimumCostDescriptor(a3, a2, a6, &v60);
  if (!v61) {
    return 0;
  }
  unint64_t v12 = (ZinIrOpLayer **)*((void *)&v60 + 1);
  if (**(unsigned char **)(a1 + 64))
  {
    uint64_t v45 = a6;
    uint64_t v46 = a3;
    uint64_t v47 = a5;
    uint64_t v43 = a4;
    long long v44 = v10;
    do
    {
      uint64_t v13 = a5[1];
      if (*a5 == v13) {
        break;
      }
      LODWORD(v50) = 3;
      if ((unint64_t)*std::map<ZinIrDimension,unsigned long>::at(v13 - 24, (int *)&v50) < 3) {
        break;
      }
      PressureBasedSubgraphIdentification::CutClusterAtLayer((void *)a1, (ZinIrOpLayer ****)v10, v12, (uint64_t *)&v58);
      unint64_t v14 = v58;
      unint64_t v15 = v59;
      do
      {
        unint64_t v16 = v10[2];
        memset(v57, 0, sizeof(v57));
        std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::__init_with_size[abi:ne180100]<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>((uint64_t *)v57, v14, v15, 0xAAAAAAAAAAAAAAABLL * (v15 - v14));
        PressureBasedSubgraphIdentification::CutClustersAtPartialOutputs(a1, v57, (uint64_t)&v58);
        *(void *)&long long v50 = v57;
        std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v50);
        unint64_t v14 = v58;
        unint64_t v15 = v59;
      }
      while (v16 < 0xAAAAAAAAAAAAAAABLL * (v59 - v58));
      long long v53 = 0;
      uint64_t v54 = 0;
      uint64_t v55 = 0;
      PressureBasedSubgraphIdentification::ConstructSubGraphs(a1, a4, &v58, &v53, v56);
      BOOL v17 = v53;
      int v48 = v54;
      if (v53 == v54) {
        goto LABEL_39;
      }
      double v18 = 1.79769313e308;
      do
      {
        uint64_t v19 = (void *)v17[9];
        if (v19 != v17 + 10)
        {
          do
          {
            if (ZinIrOpLayer::IsNELayer((ZinIrOpLayer *)v19[4]))
            {
              uint64_t v20 = (ZinIrOpLayer *)v19[4];
              (*(void (**)(long long *__return_ptr, ZinIrOpLayer *))(*(void *)v20 + 384))(&v50, v20);
              uint64_t v21 = v51;
              uint64_t v22 = v17[13] - 24;
              int v49 = 3;
              unint64_t v23 = *std::map<ZinIrDimension,unsigned long>::at(v22, &v49);
              uint64_t v24 = **(void **)(a1 + 16);
              uint64_t v25 = v52;
              uint64_t InputTensor = ZinIrOpLayer::GetInputTensor(v20, 0);
              char v27 = IsFloatFormat(*(_DWORD *)(InputTensor + 88));
              unint64_t v28 = (v21 + v23 - 1) / v23;
              unint64_t v29 = *(void *)(*((void *)v20 + 33) + 136);
              double v30 = (double)((v28 + v29 - 1)
                           / v29
                           * v29
                           * ((*(void *)(v24 + 592) / v29) >> v27)
                           * ((v25 + ((*(void *)(v24 + 592) / v29) >> v27) - 1)
                            / ((*(void *)(v24 + 592) / v29) >> v27)));
              if (v18 >= (double)(v25 * v28) / v30) {
                double v18 = (double)(v25 * v28) / v30;
              }
            }
            double v31 = (void *)v19[1];
            if (v31)
            {
              do
              {
                uint64_t v32 = v31;
                double v31 = (void *)*v31;
              }
              while (v31);
            }
            else
            {
              do
              {
                uint64_t v32 = (void *)v19[2];
                BOOL v33 = *v32 == (void)v19;
                uint64_t v19 = v32;
              }
              while (!v33);
            }
            uint64_t v19 = v32;
          }
          while (v32 != v17 + 10);
        }
        v17 += 19;
      }
      while (v17 != v48);
      if (v18 > 0.65) {
        goto LABEL_39;
      }
      double v34 = v53;
      double v35 = v54;
      if (v53 == v54) {
        goto LABEL_39;
      }
      while (1)
      {
        uint64_t v36 = v34[13] - 24;
        LODWORD(v50) = 3;
        uint64_t v37 = *std::map<ZinIrDimension,unsigned long>::at(v36, (int *)&v50);
        uint64_t v38 = v47[1] - 24;
        int v49 = 3;
        if (v37 == *std::map<ZinIrDimension,unsigned long>::at(v38, &v49)) {
          break;
        }
        v34 += 19;
        if (v34 == v35) {
          goto LABEL_39;
        }
      }
      uint64_t v40 = *v46;
      uint64_t v39 = v46[1];
      if (*v46 == v39)
      {
        unint64_t v12 = 0;
LABEL_39:
        *(void *)&long long v50 = &v53;
        std::vector<Subgraph>::__destroy_vector::operator()[abi:ne180100]((void ***)&v50);
        *(void *)&long long v50 = &v58;
        std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v50);
        return v12;
      }
      while (*(double *)v40 != *(double *)&v60 || *(ZinIrOpLayer ***)(v40 + 8) != v12)
      {
        v40 += 16;
        if (v40 == v39)
        {
          uint64_t v40 = v46[1];
          break;
        }
      }
      if (v40 == v39) {
        ZinAssertImpl("Pressure Analysis Internal Error");
      }
      uint64_t v41 = v39 - (v40 + 16);
      if (v39 != v40 + 16) {
        memmove((void *)v40, (const void *)(v40 + 16), v39 - (v40 + 16));
      }
      v46[1] = v40 + v41;
      uint64_t v10 = v44;
      PressureBasedSubgraphIdentification::FindMinimumCostDescriptor(v46, v44, v45, &v50);
      char v61 = v51;
      long long v60 = v50;
      a5 = v47;
      a4 = v43;
      if (!(_BYTE)v51)
      {
        *(void *)&long long v50 = &v53;
        std::vector<Subgraph>::__destroy_vector::operator()[abi:ne180100]((void ***)&v50);
        *(void *)&long long v50 = &v58;
        std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v50);
        return 0;
      }
      unint64_t v12 = (ZinIrOpLayer **)*((void *)&v60 + 1);
      *(void *)&long long v50 = &v53;
      std::vector<Subgraph>::__destroy_vector::operator()[abi:ne180100]((void ***)&v50);
      *(void *)&long long v50 = &v58;
      std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v50);
    }
    while (**(unsigned char **)(a1 + 64));
  }
  return v12;
}

void sub_21128E69C(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, void **a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,char a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,char a30)
{
  a18 = (void **)&a23;
  std::vector<Subgraph>::__destroy_vector::operator()[abi:ne180100](&a18);
  a18 = (void **)&a30;
  std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100](&a18);
  _Unwind_Resume(a1);
}

void PressureBasedSubgraphIdentification::ComputeCircularBufferPressure(uint64_t *a1, const Subgraph *a2, uint64_t a3, void *a4, void *a5, void *a6)
{
  std::__hash_table<std::__hash_value_type<ZinIrDimension,unsigned long>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,unsigned long>>>::clear(a4);
  *a5 = 0;
  *a6 = 0;
  unint64_t v12 = (unsigned char *)a1[8];
  if (!v12[1])
  {
    if (*v12)
    {
      int v13 = *(_DWORD *)(a3 + 24);
      if (v13 || *(void *)(a3 + 16))
      {
        uint64_t v76 = a5;
        v97[0] = 0;
        int v14 = ZinIrDimensionToSpatialDimension(v13, v97);
        if (!(v14 | v97[0]))
        {
          uint64_t v16 = (uint64_t)a2 + 72;
          unint64_t v15 = (void *)*((void *)a2 + 9);
          BOOL v17 = (void *)((char *)a2 + 80);
          if (v15 != (void *)((char *)a2 + 80))
          {
            double v18 = (int *)(a3 + 8);
            uint64_t v19 = (uint64_t)a2 + 24;
            uint64_t v77 = a1 + 11;
            uint64_t v20 = v18;
            uint64_t v74 = (void *)((char *)a2 + 24);
            uint64_t v75 = a2;
            do
            {
              long long v96 = (ZinIrOpLayer *)v15[4];
              if (!std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>(v19, &v96))
              {
                RootTensor = 0;
                uint64_t v21 = (ZinIrTensor *)(*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)v96 + 32))(v96, 0, 0);
                RootTensor = ZinIrTensor::GetRootTensor(v21);
                char IsCircularBufferProducerCandidate = ZinIrCircularBufferUtil::IsCircularBufferProducerCandidate((uint64_t)a2, a1[8], v96);
                int IsMultiFanoutCBCandidate = PressureBasedSubgraphIdentification::IsMultiFanoutCBCandidate((PressureBasedSubgraphIdentification *)a1, a2, v96);
                if ((IsCircularBufferProducerCandidate & 1) != 0 || IsMultiFanoutCBCandidate)
                {
                  v94[0] = *((void *)v96 + 6);
                  v94[1] = v94[0];
                  v92[0] = 0;
                  v92[1] = 0;
                  char v93 = 0;
                  char v91 = v92;
                  ZinIrMemoryPressureAnalyzer::GetPeakPressure((uint64_t)(a1 + 16), v94, (uint64_t)&v91);
                  uint64_t v24 = v91;
                  if (v91 != v92)
                  {
                    while (1)
                    {
                      uint64_t v25 = (void *)v24[4];
                      if (!(*(unsigned int (**)(void *))(*v25 + 24))(v25))
                      {
                        *(void *)&v86[0] = *((void *)RootTensor + 12);
                        if (v17 == (void *)std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>(v16, (ZinIrOpLayer **)v86))ZinAssertImpl("Adding over-compute on a tensornot in the subgraph"); {
                        if ((ZinIrTensor *)v25[4] == RootTensor)
                        }
                        {
                          *(void *)&v86[0] = v25;
                          if (!std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(a4, v86))break; {
                        }
                          }
                      }
                      long long v69 = (void *)v24[1];
                      if (v69)
                      {
                        do
                        {
                          int v70 = (void **)v69;
                          long long v69 = (void *)*v69;
                        }
                        while (v69);
                      }
                      else
                      {
                        do
                        {
                          int v70 = (void **)v24[2];
                          BOOL v71 = *v70 == v24;
                          uint64_t v24 = v70;
                        }
                        while (!v71);
                      }
                      uint64_t v24 = v70;
                      if (v70 == v92) {
                        goto LABEL_114;
                      }
                    }
                    *(void *)&v86[0] = v25;
                    std::__hash_table<ZinIrTensor const*,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const* const&>((uint64_t)a4, v86, v86);
                    uint64_t v26 = *(void *)v20;
                    if (!*(void *)v20) {
                      goto LABEL_27;
                    }
                    char v27 = v20;
                    uint64_t v28 = *(void *)v20;
                    do
                    {
                      int v29 = *(_DWORD *)(v28 + 32);
                      BOOL v30 = v29 < 0;
                      if (v29 >= 0) {
                        double v31 = (uint64_t *)v28;
                      }
                      else {
                        double v31 = (uint64_t *)(v28 + 8);
                      }
                      if (!v30) {
                        char v27 = (int *)v28;
                      }
                      uint64_t v28 = *v31;
                    }
                    while (*v31);
                    if (v27 != v20 && v27[8] <= 0) {
                      unint64_t v32 = *((void *)v27 + 5);
                    }
                    else {
LABEL_27:
                    }
                      unint64_t v32 = 1;
                    *v76 += v25[1] / v32;
                    long long v33 = *((_OWORD *)RootTensor + 4);
                    long long v88 = *((_OWORD *)RootTensor + 3);
                    long long v89 = v33;
                    uint64_t v90 = *((void *)RootTensor + 10);
                    if (!v26) {
                      goto LABEL_38;
                    }
                    double v34 = v20;
                    do
                    {
                      int v35 = *(_DWORD *)(v26 + 32);
                      BOOL v36 = v35 < 0;
                      if (v35 >= 0) {
                        uint64_t v37 = (uint64_t *)v26;
                      }
                      else {
                        uint64_t v37 = (uint64_t *)(v26 + 8);
                      }
                      if (!v36) {
                        double v34 = (int *)v26;
                      }
                      uint64_t v26 = *v37;
                    }
                    while (*v37);
                    if (v34 != v20 && v34[8] <= 0) {
                      unint64_t v38 = *((void *)v34 + 5);
                    }
                    else {
LABEL_38:
                    }
                      unint64_t v38 = 1;
                    *(void *)&long long v88 = (unint64_t)v88 / v38;
                    *(void *)&long long v89 = 0;
                    long long v87 = 0u;
                    memset(v86, 0, sizeof(v86));
                    uint64_t v39 = *((void *)RootTensor + 12);
                    uint64_t v40 = *(std::string::size_type **)(v39 + 112);
                    uint64_t v41 = *(std::string::size_type **)(v39 + 120);
                    if (v40 == v41)
                    {
LABEL_75:
                      uint64_t v56 = RootTensor;
                      if (*((char *)RootTensor + 47) >= 0) {
                        size_t v57 = *((unsigned __int8 *)RootTensor + 47);
                      }
                      else {
                        size_t v57 = *((void *)RootTensor + 4);
                      }
                      std::string::basic_string[abi:ne180100]((uint64_t)&v83, v57 + 19);
                      if ((v83.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
                        uint64_t v58 = &v83;
                      }
                      else {
                        uint64_t v58 = (std::string *)v83.__r_.__value_.__r.__words[0];
                      }
                      if (v57)
                      {
                        if (*((char *)v56 + 47) >= 0) {
                          unint64_t v59 = (char *)v56 + 24;
                        }
                        else {
                          unint64_t v59 = (const void *)*((void *)v56 + 3);
                        }
                        memmove(v58, v59, v57);
                      }
                      strcpy((char *)v58 + v57, "__GetPeakPressure__");
                      if (*(unsigned char *)(a1[8] + 2)) {
                        long long v60 = "DRAM_Legalizer_";
                      }
                      else {
                        long long v60 = "SpatialSplit_";
                      }
                      if (*(unsigned char *)(a1[8] + 2)) {
                        std::string::size_type v61 = 15;
                      }
                      else {
                        std::string::size_type v61 = 13;
                      }
                      unsigned __int8 v62 = std::string::append(&v83, v60, v61);
                      long long v63 = *(_OWORD *)&v62->__r_.__value_.__l.__data_;
                      __p.__r_.__value_.__r.__words[2] = v62->__r_.__value_.__r.__words[2];
                      *(_OWORD *)&__p.__r_.__value_.__l.__data_ = v63;
                      v62->__r_.__value_.__l.__size_ = 0;
                      v62->__r_.__value_.__r.__words[2] = 0;
                      v62->__r_.__value_.__r.__words[0] = 0;
                      unint64_t v64 = a1[27];
                      a1[27] = v64 + 1;
                      std::to_string(&v82, v64);
                      if ((v82.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
                        char v65 = &v82;
                      }
                      else {
                        char v65 = (std::string *)v82.__r_.__value_.__r.__words[0];
                      }
                      if ((v82.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
                        std::string::size_type size = HIBYTE(v82.__r_.__value_.__r.__words[2]);
                      }
                      else {
                        std::string::size_type size = v82.__r_.__value_.__l.__size_;
                      }
                      uint64_t v67 = std::string::append(&__p, (const std::string::value_type *)v65, size);
                      long long v68 = *(_OWORD *)&v67->__r_.__value_.__l.__data_;
                      std::string::size_type v85 = v67->__r_.__value_.__r.__words[2];
                      *(_OWORD *)int v84 = v68;
                      v67->__r_.__value_.__l.__size_ = 0;
                      v67->__r_.__value_.__r.__words[2] = 0;
                      v67->__r_.__value_.__r.__words[0] = 0;
                      if (SHIBYTE(v82.__r_.__value_.__r.__words[2]) < 0) {
                        operator delete(v82.__r_.__value_.__l.__data_);
                      }
                      if (SHIBYTE(__p.__r_.__value_.__r.__words[2]) < 0) {
                        operator delete(__p.__r_.__value_.__l.__data_);
                      }
                      if (SHIBYTE(v83.__r_.__value_.__r.__words[2]) < 0) {
                        operator delete(v83.__r_.__value_.__l.__data_);
                      }
                      ZinIrTensor::CopyTensorMirInfo((uint64_t)RootTensor, &v81);
                      *(_OWORD *)&v83.__r_.__value_.__l.__data_ = 0uLL;
                      LODWORD(__p.__r_.__value_.__l.__data_) = 0;
                      uint64_t v79 = 0;
                      *(_OWORD *)&__p.__r_.__value_.__r.__words[1] = 0uLL;
                      int v80 = 0;
                      ZinIrTensor::CreateTensor();
                    }
                    do
                    {
                      __p.__r_.__value_.__r.__words[0] = 0;
                      __p.__r_.__value_.__r.__words[0] = *v40;
                      std::deque<ZinIrOpLayer *>::push_back(v86, &__p);
                      ++v40;
                    }
                    while (v40 != v41);
                    while (1)
                    {
                      if (!*((void *)&v87 + 1)) {
                        goto LABEL_75;
                      }
                      v84[0] = 0;
                      char v42 = *(ZinIrOpLayer **)(*(void *)(*((void *)&v86[0] + 1)
                                                         + (((unint64_t)v87 >> 6) & 0x3FFFFFFFFFFFFF8))
                                             + 8 * (v87 & 0x1FF));
                      v84[0] = v42;
                      *(void *)&long long v87 = v87 + 1;
                      --*((void *)&v87 + 1);
                      if ((unint64_t)v87 >= 0x400)
                      {
                        operator delete(**((void ***)&v86[0] + 1));
                        *((void *)&v86[0] + 1) += 8;
                        *(void *)&long long v87 = v87 - 512;
                        char v42 = v84[0];
                      }
                      memset(&__p, 0, sizeof(__p));
                      if (ZinIrOpLayer::IsNoOp(v42, (uint64_t *)&__p))
                      {
                        uint64_t v43 = v84[0];
                        int v44 = *(_DWORD *)(*((void *)v84[0] + 8) + 8);
                        if (__p.__r_.__value_.__r.__words[0])
                        {
                          __p.__r_.__value_.__l.__size_ = __p.__r_.__value_.__r.__words[0];
                          operator delete(__p.__r_.__value_.__l.__data_);
                          uint64_t v43 = v84[0];
                        }
                        if (v44 != 7)
                        {
                          uint64_t v45 = (std::string::size_type *)*((void *)v43 + 14);
                          uint64_t v46 = (std::string::size_type *)*((void *)v43 + 15);
                          while (v45 != v46)
                          {
                            __p.__r_.__value_.__r.__words[0] = 0;
                            __p.__r_.__value_.__r.__words[0] = *v45;
                            std::deque<ZinIrOpLayer *>::push_back(v86, &__p);
                            ++v45;
                          }
                          continue;
                        }
                      }
                      else
                      {
                        if (__p.__r_.__value_.__r.__words[0])
                        {
                          __p.__r_.__value_.__l.__size_ = __p.__r_.__value_.__r.__words[0];
                          operator delete(__p.__r_.__value_.__l.__data_);
                        }
                        uint64_t v43 = v84[0];
                      }
                      if (ZinIrOpLayer::IsNELayer(v43)
                        && v17 != (void *)std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>(v16, v84))
                      {
                        (*(void (**)(std::string *__return_ptr))(*(void *)v84[0] + 568))(&__p);
                        if (__p.__r_.__value_.__r.__words[0])
                        {
                          unint64_t v47 = ZinMirSpatialSplitUtils::OverComputedSpaceInDimension(*(ZinMirSpatialSplitUtils **)(__p.__r_.__value_.__r.__words[0] + 264), *(int *)(__p.__r_.__value_.__r.__words[0] + 332), *(int *)(__p.__r_.__value_.__r.__words[0] + 344), 0, 0, 0);
                          uint64_t v48 = *v77;
                          if (!*v77) {
                            goto LABEL_123;
                          }
                          unint64_t v49 = v47;
                          long long v50 = a1 + 11;
                          do
                          {
                            uint64_t v51 = *(ZinIrTensor **)(v48 + 32);
                            BOOL v52 = v51 >= RootTensor;
                            if (v51 >= RootTensor) {
                              long long v53 = (uint64_t *)v48;
                            }
                            else {
                              long long v53 = (uint64_t *)(v48 + 8);
                            }
                            if (v52) {
                              long long v50 = (uint64_t *)v48;
                            }
                            uint64_t v48 = *v53;
                          }
                          while (*v53);
                          if (v50 == v77 || (unint64_t)RootTensor < v50[4]) {
LABEL_123:
                          }
                            ZinAssertImpl("Spatial Split Internal Error");
                          uint64_t v54 = *std::map<ZinIrTensor const*,SpatialAmount>::at((uint64_t)(a1 + 10), (unint64_t *)&RootTensor);
                          if (v49 > v54) {
                            uint64_t v54 = v49;
                          }
                          if ((uint64_t)v89 > v54) {
                            uint64_t v54 = v89;
                          }
                          *(void *)&long long v89 = v54;
                          uint64_t v55 = (ZinIrKernel *)__p.__r_.__value_.__r.__words[0];
                          __p.__r_.__value_.__r.__words[0] = 0;
                          if (v55)
                          {
                            ZinIrKernel::~ZinIrKernel(v55);
                            MEMORY[0x21667D3C0]();
                          }
                        }
                      }
                    }
                  }
LABEL_114:
                  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v91, v92[0]);
                  uint64_t v19 = (uint64_t)v74;
                  a2 = v75;
                }
              }
              int64_t v72 = (void *)v15[1];
              if (v72)
              {
                do
                {
                  __int16 v73 = v72;
                  int64_t v72 = (void *)*v72;
                }
                while (v72);
              }
              else
              {
                do
                {
                  __int16 v73 = (void *)v15[2];
                  BOOL v71 = *v73 == (void)v15;
                  unint64_t v15 = v73;
                }
                while (!v71);
              }
              unint64_t v15 = v73;
            }
            while (v73 != v17);
          }
        }
      }
    }
  }
}

void sub_21128EF60(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, void *a19, uint64_t a20,int a21,__int16 a22,char a23,char a24,uint64_t a25,uint64_t a26,uint64_t a27,void *a28,uint64_t a29,int a30,__int16 a31,char a32,char a33,void *a34,uint64_t a35,int a36,__int16 a37,char a38,char a39,void *__p,uint64_t a41,int a42,__int16 a43,char a44,char a45,uint64_t a46,char a47)
{
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy(v47 - 160, *(void **)(v47 - 152));
  _Unwind_Resume(a1);
}

uint64_t PressureBasedSubgraphIdentification::GetPeakPressure(PressureBasedSubgraphIdentification *a1, const ZinIrOpLayer *a2, uint64_t a3, uint64_t a4, unint64_t *a5)
{
  uint64_t v5 = a5;
  unint64_t v7 = *(void **)(a3 + 72);
  uint64_t v169 = a3 + 72;
  uint64_t v8 = (void *)(a3 + 80);
  if (v7 == (void *)(a3 + 80))
  {
    char v163 = 0;
  }
  else
  {
    char v163 = 0;
    while (1)
    {
      BOOL HasKernelSupportOnHeight = ZinMirSpatialSplitUtils::HasKernelSupportOnHeight((ZinMirSpatialSplitUtils *)v7[4], a2, a3, a4, a5);
      if (HasKernelSupportOnHeight) {
        break;
      }
      uint64_t v11 = (void *)v7[1];
      if (v11)
      {
        do
        {
          unint64_t v12 = v11;
          uint64_t v11 = (void *)*v11;
        }
        while (v11);
      }
      else
      {
        do
        {
          unint64_t v12 = (void *)v7[2];
          BOOL v33 = *v12 == (void)v7;
          unint64_t v7 = v12;
        }
        while (!v33);
      }
      v163 |= HasKernelSupportOnHeight;
      unint64_t v7 = v12;
      if (v12 == v8) {
        goto LABEL_13;
      }
    }
    char v163 = 1;
  }
LABEL_13:
  uint64_t v203 = 0;
  uint64_t v204 = 0;
  memset(v201, 0, sizeof(v201));
  int v202 = 1065353216;
  (*(void (**)(PressureBasedSubgraphIdentification *, uint64_t, uint64_t, _OWORD *, uint64_t *, uint64_t *))(*(void *)a1 + 160))(a1, a3, a4, v201, &v204, &v203);
  memset(v199, 0, sizeof(v199));
  int v200 = 1065353216;
  v170 = (const Subgraph *)a3;
  (*(void (**)(PressureBasedSubgraphIdentification *, uint64_t, uint64_t, _OWORD *))(*(void *)a1 + 152))(a1, a3, a4, v199);
  int64_t v14 = *((void *)a2 + 1);
  int64_t v198 = *(void *)a2;
  unint64_t v13 = v198;
  if (v198 > v14) {
    goto LABEL_312;
  }
  unint64_t v15 = (int *)(a4 + 8);
  v174 = (void *)((char *)a1 + 88);
  uint64_t v162 = (uint64_t)a1 + 80;
  v164 = v5;
  uint64_t v165 = a3 + 24;
  uint64_t v161 = (uint64_t)(v5 + 2);
  v175 = (uint64_t *)(a4 + 8);
  do
  {
    v197[0] = 0;
    v197[1] = 0;
    v195[1] = v13;
    v196 = v197;
    v195[0] = v13;
    v193[0] = 0;
    v193[1] = 0;
    char v194 = 0;
    v192 = (uint64_t *)v193;
    ZinIrMemoryPressureAnalyzer::GetPeakPressure((uint64_t)a1 + 128, v195, (uint64_t)&v192);
    if (std::__hash_table<std::__hash_value_type<unsigned long long,CpAllocUtils::AllocationType>,std::__unordered_map_hasher<unsigned long long,std::__hash_value_type<unsigned long long,CpAllocUtils::AllocationType>,std::hash<unsigned long long>,std::equal_to<unsigned long long>,true>,std::__unordered_map_equal<unsigned long long,std::__hash_value_type<unsigned long long,CpAllocUtils::AllocationType>,std::equal_to<unsigned long long>,std::hash<unsigned long long>,true>,std::allocator<std::__hash_value_type<unsigned long long,CpAllocUtils::AllocationType>>>::find<unsigned long long>(v199, (unint64_t *)&v198))
    {
      uint64_t v16 = std::__hash_table<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::__unordered_map_hasher<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::hash<long>,std::equal_to<long>,true>,std::__unordered_map_equal<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::equal_to<long>,std::hash<long>,true>,std::allocator<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>>>::find<long>(v199, (unint64_t *)&v198);
      if (!v16) {
        std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
      }
      BOOL v17 = (void *)v16[3];
      double v18 = v16 + 4;
      if (v17 == v16 + 4)
      {
        uint64_t v19 = 0;
      }
      else
      {
        uint64_t v19 = 0;
        do
        {
          unint64_t v20 = v17[4];
          uint64_t v21 = operator new(0x14uLL);
          v180[1] = v21 + 5;
          v181 = (char *)(v21 + 5);
          v21[4] = 4;
          *(_OWORD *)uint64_t v21 = xmmword_211F000C0;
          v180[0] = v21;
          DimensionOrderHint::DimensionOrderHint(__p, v180);
          ZinIrTensor::GetTensorSizeInBytesFromResidency((ZinIrTensor *)v20, 1, (uint64_t)__p, 0);
          unint64_t v23 = v22;
          uint64_t v24 = a4 + 8;
          uint64_t v25 = *v175;
          if (!*v175) {
            goto LABEL_28;
          }
          do
          {
            int v26 = *(_DWORD *)(v25 + 32);
            BOOL v27 = v26 < 0;
            if (v26 >= 0) {
              uint64_t v28 = (uint64_t *)v25;
            }
            else {
              uint64_t v28 = (uint64_t *)(v25 + 8);
            }
            if (!v27) {
              uint64_t v24 = v25;
            }
            uint64_t v25 = *v28;
          }
          while (*v28);
          if ((uint64_t *)v24 != v175 && *(int *)(v24 + 32) <= 0) {
            unint64_t v29 = *(void *)(v24 + 40);
          }
          else {
LABEL_28:
          }
            unint64_t v29 = 1;
          if (__p[0])
          {
            __p[1] = __p[0];
            operator delete(__p[0]);
          }
          if (v180[0])
          {
            v180[1] = v180[0];
            operator delete(v180[0]);
          }
          BOOL v30 = (unsigned __int8 *)*((void *)a1 + 8);
          BOOL v31 = v30[10] || v30[5] || v30[2] || *v30 != 0;
          int v32 = *(_DWORD *)(a4 + 24);
          if (v32) {
            BOOL v33 = 0;
          }
          else {
            BOOL v33 = *(void *)(a4 + 16) == 0;
          }
          BOOL v34 = !v33 && v31;
          int v35 = (void *)*v174;
          if (*v174)
          {
            BOOL v36 = (void *)*v174;
            do
            {
              unint64_t v37 = v36[4];
              if (v20 >= v37)
              {
                if (v37 >= v20)
                {
                  if (v34)
                  {
                    long long v38 = *(_OWORD *)(v20 + 64);
                    *(_OWORD *)std::string __p = *(_OWORD *)(v20 + 48);
                    long long v190 = v38;
                    uint64_t v191 = *(void *)(v20 + 80);
                    uint64_t v39 = a4 + 8;
                    uint64_t v40 = *v175;
                    if (!*v175) {
                      goto LABEL_60;
                    }
                    do
                    {
                      int v41 = *(_DWORD *)(v40 + 32);
                      BOOL v42 = v41 < 0;
                      if (v41 >= 0) {
                        uint64_t v43 = (uint64_t *)v40;
                      }
                      else {
                        uint64_t v43 = (uint64_t *)(v40 + 8);
                      }
                      if (!v42) {
                        uint64_t v39 = v40;
                      }
                      uint64_t v40 = *v43;
                    }
                    while (*v43);
                    if ((uint64_t *)v39 != v175 && *(int *)(v39 + 32) <= 0) {
                      unint64_t v44 = *(void *)(v39 + 40);
                    }
                    else {
LABEL_60:
                    }
                      unint64_t v44 = 1;
                    v188 = (void *)v20;
                    __p[0] = (void *)((unint64_t)__p[0] / v44);
                    uint64_t v45 = (void *)((char *)a1 + 88);
                    do
                    {
                      unint64_t v46 = v35[4];
                      BOOL v47 = v46 >= v20;
                      if (v46 >= v20) {
                        uint64_t v48 = v35;
                      }
                      else {
                        uint64_t v48 = v35 + 1;
                      }
                      if (v47) {
                        uint64_t v45 = v35;
                      }
                      int v35 = (void *)*v48;
                    }
                    while (*v48);
                    if (v45 != v174 && v20 >= v45[4])
                    {
                      LODWORD(v179) = 0;
                      if (ZinIrDimensionToSpatialDimension(v32, (int *)&v179)) {
                        ZinAssertImpl("Over-Compute on spatial dimensions only");
                      }
                      unint64_t v49 = std::map<ZinIrTensor const*,SpatialAmount>::at(v162, (unint64_t *)&v188);
                      if (v179) {
                        long long v50 = v49 + 1;
                      }
                      else {
                        long long v50 = v49;
                      }
                      if (*v50)
                      {
                        if (!SetValueAtDimension<ZinTensorDimensions>(__p, *(_DWORD *)(a4 + 24), *v50))
                        {
                          if (*(char *)(v20 + 47) >= 0) {
                            size_t v51 = *(unsigned __int8 *)(v20 + 47);
                          }
                          else {
                            size_t v51 = *(void *)(v20 + 32);
                          }
                          std::string::basic_string[abi:ne180100]((uint64_t)&v187, v51 + 19);
                          if ((v187.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
                            BOOL v52 = &v187;
                          }
                          else {
                            BOOL v52 = (std::string *)v187.__r_.__value_.__r.__words[0];
                          }
                          if (v51)
                          {
                            if (*(char *)(v20 + 47) >= 0) {
                              long long v53 = (const void *)(v20 + 24);
                            }
                            else {
                              long long v53 = *(const void **)(v20 + 24);
                            }
                            memmove(v52, v53, v51);
                          }
                          strcpy((char *)v52 + v51, "__GetPeakPressure__");
                          (*(void (**)(std::string *__return_ptr, PressureBasedSubgraphIdentification *))(*(void *)a1 + 120))(&v186, a1);
                          unint64_t v54 = *((void *)a1 + 27);
                          *((void *)a1 + 27) = v54 + 1;
                          std::to_string(&v185, v54);
                          if ((v185.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
                            uint64_t v55 = &v185;
                          }
                          else {
                            uint64_t v55 = (std::string *)v185.__r_.__value_.__r.__words[0];
                          }
                          if ((v185.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
                            std::string::size_type size = HIBYTE(v185.__r_.__value_.__r.__words[2]);
                          }
                          else {
                            std::string::size_type size = v185.__r_.__value_.__l.__size_;
                          }
                          size_t v57 = std::string::append(&v186, (const std::string::value_type *)v55, size);
                          long long v58 = *(_OWORD *)&v57->__r_.__value_.__l.__data_;
                          v181 = (char *)v57->__r_.__value_.__r.__words[2];
                          *(_OWORD *)v180 = v58;
                          v57->__r_.__value_.__l.__size_ = 0;
                          v57->__r_.__value_.__r.__words[2] = 0;
                          v57->__r_.__value_.__r.__words[0] = 0;
                          if (SHIBYTE(v181) >= 0) {
                            unint64_t v59 = v180;
                          }
                          else {
                            unint64_t v59 = (void **)v180[0];
                          }
                          if (SHIBYTE(v181) >= 0) {
                            std::string::size_type v60 = HIBYTE(v181);
                          }
                          else {
                            std::string::size_type v60 = (std::string::size_type)v180[1];
                          }
                          std::string::append(&v187, (const std::string::value_type *)v59, v60);
                          if (SHIBYTE(v181) < 0) {
                            operator delete(v180[0]);
                          }
                          if (SHIBYTE(v185.__r_.__value_.__r.__words[2]) < 0) {
                            operator delete(v185.__r_.__value_.__l.__data_);
                          }
                          if (SHIBYTE(v186.__r_.__value_.__r.__words[2]) < 0) {
                            operator delete(v186.__r_.__value_.__l.__data_);
                          }
                          ZinIrTensor::CopyTensorMirInfo(v20, &v184);
                          *(_OWORD *)&v186.__r_.__value_.__l.__data_ = 0uLL;
                          LODWORD(v180[0]) = 0;
                          v181 = 0;
                          uint64_t v182 = 0;
                          v180[1] = 0;
                          int v183 = 0;
                          ZinIrTensor::CreateTensor();
                        }
                        ZinAssertImpl("Invalid Tile Calculation");
                      }
                    }
                  }
                  break;
                }
                ++v36;
              }
              BOOL v36 = (void *)*v36;
            }
            while (v36);
          }
          unint64_t v15 = (int *)(a4 + 8);
          std::string::size_type v61 = (void *)v17[1];
          if (v61)
          {
            do
            {
              unsigned __int8 v62 = v61;
              std::string::size_type v61 = (void *)*v61;
            }
            while (v61);
          }
          else
          {
            do
            {
              unsigned __int8 v62 = (void *)v17[2];
              BOOL v33 = *v62 == (void)v17;
              BOOL v17 = v62;
            }
            while (!v33);
          }
          v19 += v23 / v29;
          BOOL v17 = v62;
        }
        while (v62 != v18);
      }
      long long v63 = v192;
      if (v192 != (uint64_t *)v193)
      {
        do
        {
          __p[0] = *(void **)(v63[4] + 32);
          unint64_t v64 = std::__hash_table<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::__unordered_map_hasher<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::hash<long>,std::equal_to<long>,true>,std::__unordered_map_equal<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::equal_to<long>,std::hash<long>,true>,std::allocator<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>>>::find<long>(v199, (unint64_t *)&v198);
          if (!v64) {
            std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
          }
          if (std::__tree<ZinIrOpLayer *,ZinIrIdComparator<ZinIrOpLayer *>,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)(v64 + 6), (uint64_t *)__p))
          {
            char v65 = std::__tree<std::__value_type<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,ZinIrHazardGraph::EdgeType>,std::__map_value_compare<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,std::__value_type<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,ZinIrHazardGraph::EdgeType>,HazardEdgeCompare,true>,std::allocator<std::__value_type<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,ZinIrHazardGraph::EdgeType>>>::__remove_node_pointer(&v192, v63);
            operator delete(v63);
          }
          else
          {
            char v66 = (uint64_t *)v63[1];
            if (v66)
            {
              do
              {
                char v65 = v66;
                char v66 = (uint64_t *)*v66;
              }
              while (v66);
            }
            else
            {
              do
              {
                char v65 = (uint64_t *)v63[2];
                BOOL v33 = *v65 == (void)v63;
                long long v63 = v65;
              }
              while (!v33);
            }
          }
          long long v63 = v65;
          BOOL v33 = v65 == (uint64_t *)v193;
          unint64_t v15 = (int *)(a4 + 8);
        }
        while (!v33);
      }
    }
    else
    {
      uint64_t v19 = 0;
    }
    uint64_t v67 = v192;
    if (v192 == (uint64_t *)v193)
    {
      uint64_t v68 = 0;
      ChainBufferuint64_t Size = 0;
      goto LABEL_289;
    }
    ChainBufferuint64_t Size = 0;
    uint64_t v68 = 0;
    do
    {
      v188 = (void *)v67[4];
      if (std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(v201, &v188))
      {
        goto LABEL_179;
      }
      uint64_t v69 = *(void *)v15;
      if (!*(void *)v15) {
        goto LABEL_143;
      }
      int v70 = v15;
      do
      {
        int v71 = *(_DWORD *)(v69 + 32);
        BOOL v72 = v71 < 0;
        if (v71 >= 0) {
          __int16 v73 = (uint64_t *)v69;
        }
        else {
          __int16 v73 = (uint64_t *)(v69 + 8);
        }
        if (!v72) {
          int v70 = (int *)v69;
        }
        uint64_t v69 = *v73;
      }
      while (*v73);
      if (v70 != v15 && v70[8] <= 0) {
        unint64_t v74 = *((void *)v70 + 5);
      }
      else {
LABEL_143:
      }
        unint64_t v74 = 1;
      v19 += v188[1] / v74;
      if ((*(unsigned int (**)(void *))(*v188 + 24))(v188)) {
        goto LABEL_179;
      }
      uint64_t v75 = (ZinIrTensor *)v188[4];
      v178 = (ZinIrOpLayer *)*((void *)v75 + 12);
      v179 = v75;
      RootTensor = ZinIrTensor::GetRootTensor(v75);
      unsigned int v77 = ZinMirSpatialSplitUtils::IsChained((uint64_t)RootTensor, *((void **)a1 + 14));
      if (!std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>(v169, &v178)|| std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>(v165, &v178))
      {
        goto LABEL_147;
      }
      char v97 = (unsigned char *)*((void *)a1 + 8);
      if (v97[2]) {
        unsigned int v98 = 0;
      }
      else {
        unsigned int v98 = v77;
      }
      if (v98 == 1)
      {
        ChainBufferuint64_t Size = ZinL2FootprintCalculator::GetChainBufferSize(*((const ZinIrTensor ***)a1 + 28), (ZinIrRegAllocUtil **)v179);
        v19 -= ChainBufferSize;
        if ((v163 & 1) == 0)
        {
          PressureBasedSubgraphIdentification::GetTensorSize(a1, v179);
          uint64_t v100 = *(void *)v15;
          if (!*(void *)v15) {
            goto LABEL_201;
          }
          uint64_t v101 = v15;
          do
          {
            int v102 = *(_DWORD *)(v100 + 32);
            BOOL v103 = v102 < 0;
            if (v102 >= 0) {
              std::string v104 = (uint64_t *)v100;
            }
            else {
              std::string v104 = (uint64_t *)(v100 + 8);
            }
            if (!v103) {
              uint64_t v101 = (int *)v100;
            }
            uint64_t v100 = *v104;
          }
          while (*v104);
          if (v101 != v15 && v101[8] <= 0) {
            unint64_t v105 = *((void *)v101 + 5);
          }
          else {
LABEL_201:
          }
            unint64_t v105 = 1;
          ChainBufferuint64_t Size = 0;
          v19 += v99 / v105;
        }
        goto LABEL_147;
      }
      uint64_t v106 = (void *)*v174;
      if (!*v174)
      {
LABEL_220:
        int v111 = 0;
        goto LABEL_221;
      }
      while (1)
      {
        unint64_t v107 = v106[4];
        if ((unint64_t)v179 >= v107) {
          break;
        }
LABEL_207:
        uint64_t v106 = (void *)*v106;
        if (!v106) {
          goto LABEL_220;
        }
      }
      if (v107 < (unint64_t)v179)
      {
        ++v106;
        goto LABEL_207;
      }
      int v108 = *(_DWORD *)(a4 + 24);
      if (*v97) {
        BOOL v109 = v108 == 3;
      }
      else {
        BOOL v109 = 0;
      }
      if (v109) {
        goto LABEL_220;
      }
      if (v108) {
        BOOL v110 = 0;
      }
      else {
        BOOL v110 = *(void *)(a4 + 16) == 0;
      }
      int v111 = !v110;
LABEL_221:
      if (*(_DWORD *)(a4 + 24)) {
        BOOL v112 = 0;
      }
      else {
        BOOL v112 = *(void *)(a4 + 16) == 0;
      }
      if (v112
        || !*v97
        || std::__hash_table<std::__hash_value_type<unsigned long long,CpAllocUtils::AllocationType>,std::__unordered_map_hasher<unsigned long long,std::__hash_value_type<unsigned long long,CpAllocUtils::AllocationType>,std::hash<unsigned long long>,std::equal_to<unsigned long long>,true>,std::__unordered_map_equal<unsigned long long,std::__hash_value_type<unsigned long long,CpAllocUtils::AllocationType>,std::equal_to<unsigned long long>,std::hash<unsigned long long>,true>,std::allocator<std::__hash_value_type<unsigned long long,CpAllocUtils::AllocationType>>>::find<unsigned long long>(v199, (unint64_t *)&v198)|| *(_DWORD *)(*(void *)(*((void *)ZinIrTensor::GetRootTensor(v179) + 12) + 64) + 8) != 7)
      {
        if (v111)
        {
LABEL_234:
          long long v120 = *((_OWORD *)v179 + 4);
          *(_OWORD *)std::string __p = *((_OWORD *)v179 + 3);
          long long v190 = v120;
          uint64_t v191 = *((void *)v179 + 10);
          uint64_t v121 = *(void *)v15;
          if (!*(void *)v15) {
            goto LABEL_244;
          }
          std::string v122 = v15;
          do
          {
            int v123 = *(_DWORD *)(v121 + 32);
            BOOL v124 = v123 < 0;
            if (v123 >= 0) {
              std::string v125 = (uint64_t *)v121;
            }
            else {
              std::string v125 = (uint64_t *)(v121 + 8);
            }
            if (!v124) {
              std::string v122 = (int *)v121;
            }
            uint64_t v121 = *v125;
          }
          while (*v125);
          if (v122 != v15 && v122[8] <= 0) {
            unint64_t v126 = *((void *)v122 + 5);
          }
          else {
LABEL_244:
          }
            unint64_t v126 = 1;
          __p[0] = (void *)((unint64_t)__p[0] / v126);
          int v177 = 0;
          if (ZinIrDimensionToSpatialDimension(*(_DWORD *)(a4 + 24), &v177)) {
            ZinAssertImpl("Over-Compute on spatial dimensions only");
          }
          long long v127 = std::map<ZinIrTensor const*,SpatialAmount>::at(v162, (unint64_t *)&v179);
          if (v177) {
            std::string::size_type v128 = v127 + 1;
          }
          else {
            std::string::size_type v128 = v127;
          }
          if (*v128)
          {
            int v129 = *(_DWORD *)(a4 + 24);
            long long v130 = std::map<ZinIrTensor const*,SpatialAmount>::at(v162, (unint64_t *)&v179);
            if (v177) {
              uint64_t v131 = v130 + 1;
            }
            else {
              uint64_t v131 = v130;
            }
            if (!SetValueAtDimension<ZinTensorDimensions>(__p, v129, *v131))
            {
              v132 = v179;
              if (*((char *)v179 + 47) >= 0) {
                size_t v133 = *((unsigned __int8 *)v179 + 47);
              }
              else {
                size_t v133 = *((void *)v179 + 4);
              }
              std::string::basic_string[abi:ne180100]((uint64_t)&v187, v133 + 19);
              if ((v187.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
                v134 = &v187;
              }
              else {
                v134 = (std::string *)v187.__r_.__value_.__r.__words[0];
              }
              if (v133)
              {
                if (*((char *)v132 + 47) >= 0) {
                  v135 = (char *)v132 + 24;
                }
                else {
                  v135 = (const void *)*((void *)v132 + 3);
                }
                memmove(v134, v135, v133);
              }
              strcpy((char *)v134 + v133, "__GetPeakPressure__");
              (*(void (**)(std::string *__return_ptr, PressureBasedSubgraphIdentification *))(*(void *)a1 + 120))(&v186, a1);
              unint64_t v136 = *((void *)a1 + 27);
              *((void *)a1 + 27) = v136 + 1;
              std::to_string(&v185, v136);
              if ((v185.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
                long long v137 = &v185;
              }
              else {
                long long v137 = (std::string *)v185.__r_.__value_.__r.__words[0];
              }
              if ((v185.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
                std::string::size_type v138 = HIBYTE(v185.__r_.__value_.__r.__words[2]);
              }
              else {
                std::string::size_type v138 = v185.__r_.__value_.__l.__size_;
              }
              v139 = std::string::append(&v186, (const std::string::value_type *)v137, v138);
              long long v140 = *(_OWORD *)&v139->__r_.__value_.__l.__data_;
              v181 = (char *)v139->__r_.__value_.__r.__words[2];
              *(_OWORD *)v180 = v140;
              v139->__r_.__value_.__l.__size_ = 0;
              v139->__r_.__value_.__r.__words[2] = 0;
              v139->__r_.__value_.__r.__words[0] = 0;
              if (SHIBYTE(v181) >= 0) {
                long long v141 = v180;
              }
              else {
                long long v141 = (void **)v180[0];
              }
              if (SHIBYTE(v181) >= 0) {
                std::string::size_type v142 = HIBYTE(v181);
              }
              else {
                std::string::size_type v142 = (std::string::size_type)v180[1];
              }
              std::string::append(&v187, (const std::string::value_type *)v141, v142);
              if (SHIBYTE(v181) < 0) {
                operator delete(v180[0]);
              }
              if (SHIBYTE(v185.__r_.__value_.__r.__words[2]) < 0) {
                operator delete(v185.__r_.__value_.__l.__data_);
              }
              if (SHIBYTE(v186.__r_.__value_.__r.__words[2]) < 0) {
                operator delete(v186.__r_.__value_.__l.__data_);
              }
              ZinIrTensor::CopyTensorMirInfo((uint64_t)v179, &v176);
              *(_OWORD *)&v186.__r_.__value_.__l.__data_ = 0uLL;
              LODWORD(v180[0]) = 0;
              v181 = 0;
              uint64_t v182 = 0;
              v180[1] = 0;
              int v183 = 0;
              ZinIrTensor::CreateTensor();
            }
            ZinAssertImpl("Invalid Tile Calculation");
          }
        }
      }
      else
      {
        uint64_t v117 = *((void *)v179 + 12);
        uint64_t v118 = *(ZinMirSpatialSplitUtils ***)(v117 + 112);
        int64x2_t v119 = *(ZinMirSpatialSplitUtils ***)(v117 + 120);
        while (v118 != v119)
        {
          if (ZinMirSpatialSplitUtils::HasKernelSupportOnHeight(*v118, v113, v114, v115, v116)) {
            LOBYTE(v111) = 1;
          }
          ++v118;
        }
        if (v111) {
          goto LABEL_234;
        }
      }
LABEL_147:
      uint64_t v78 = ZinIrTensor::GetRootTensor(v179);
      if (PressureBasedSubgraphIdentification::IsSIPContributor(a1, a2, v170, v78))
      {
        uint64_t v79 = a4 + 8;
        uint64_t v80 = *v175;
        if (!*v175) {
          goto LABEL_157;
        }
        do
        {
          int v81 = *(_DWORD *)(v80 + 32);
          BOOL v82 = v81 < 0;
          if (v81 >= 0) {
            std::string v83 = (uint64_t *)v80;
          }
          else {
            std::string v83 = (uint64_t *)(v80 + 8);
          }
          if (!v82) {
            uint64_t v79 = v80;
          }
          uint64_t v80 = *v83;
        }
        while (*v83);
        if ((uint64_t *)v79 != v175 && *(int *)(v79 + 32) <= 0) {
          uint64_t v84 = *(void *)(v79 + 40);
        }
        else {
LABEL_157:
        }
          uint64_t v84 = 1;
        unint64_t v166 = v84;
        unint64_t v167 = v188[1];
        uint64_t v168 = v19;
        ZinIrTensor::GetTensorFamily(v78, (uint64_t)__p);
        std::string::size_type v85 = (char *)__p[0];
        uint64_t v86 = (char *)__p[1];
        while (v85 != v86)
        {
          uint64_t v87 = *(void *)v85;
          uint64_t v88 = *(void *)(*(void *)v85 + 96);
          uint64_t v90 = *(const ZinANELayer ***)(v88 + 112);
          long long v89 = *(const ZinANELayer ***)(v88 + 120);
          while (v90 != v89)
          {
            char v91 = *v90;
            if (*((void *)*v90 + 6) == v198
              && ZinMirSpatialSplitUtils::IsNonResident(v78, *((void **)a1 + 14))
              && ZinIrOpLayer::IsANELayer(v91))
            {
              uint64_t v92 = (*(uint64_t (**)(const ZinANELayer *, uint64_t))(*(void *)v91 + 152))(v91, v87);
              if (v92 == -1)
              {
                if (!*((void *)v91 + 25)) {
                  ZinAssertImpl("DMA Buffer pressure incorrectly modeled");
                }
              }
              else
              {
                v68 += PressureBasedSubgraphIdentification::GetMinDMABufferSize(a1, v91, v92, 1);
              }
            }
            ++v90;
          }
          v85 += 8;
        }
        char v93 = (ZinIrOpLayer *)*((void *)v179 + 12);
        if (*((void *)v93 + 6) == v198)
        {
          uint64_t v5 = v164;
          unint64_t v15 = (int *)(a4 + 8);
          uint64_t v94 = v168;
          if (ZinIrOpLayer::IsANELayer(v93)) {
            v68 += PressureBasedSubgraphIdentification::GetMinDMABufferSize(a1, *((const ZinANELayer **)v179 + 12), 0, 0);
          }
        }
        else
        {
          uint64_t v5 = v164;
          unint64_t v15 = (int *)(a4 + 8);
          uint64_t v94 = v168;
        }
        if (__p[0])
        {
          __p[1] = __p[0];
          operator delete(__p[0]);
        }
        uint64_t v19 = v94 - v167 / v166;
      }
      else
      {
        unint64_t v15 = (int *)(a4 + 8);
      }
LABEL_179:
      uint64_t v95 = (uint64_t *)v67[1];
      if (v95)
      {
        do
        {
          long long v96 = v95;
          uint64_t v95 = (uint64_t *)*v95;
        }
        while (v95);
      }
      else
      {
        do
        {
          long long v96 = (uint64_t *)v67[2];
          BOOL v33 = *v96 == (void)v67;
          uint64_t v67 = v96;
        }
        while (!v33);
      }
      uint64_t v67 = v96;
    }
    while (v96 != (uint64_t *)v193);
LABEL_289:
    uint64_t v143 = v204 + (v19 & ~(v19 >> 63));
    uint64_t v144 = v203;
    if (*(unsigned char *)(*((void *)a1 + 8) + 2)) {
      uint64_t v145 = 0;
    }
    else {
      uint64_t v145 = v68;
    }
    if (*(unsigned char *)(*((void *)a1 + 8) + 2)) {
      uint64_t v146 = 0;
    }
    else {
      uint64_t v146 = ChainBufferSize;
    }
    char v148 = (void *)v5[1];
    unint64_t v147 = v5[2];
    if ((unint64_t)v148 >= v147)
    {
      v150 = (void *)*v5;
      uint64_t v151 = (uint64_t)((uint64_t)v148 - *v5) >> 5;
      unint64_t v152 = v151 + 1;
      if ((unint64_t)(v151 + 1) >> 59) {
        std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
      }
      uint64_t v153 = v147 - (void)v150;
      if (v153 >> 4 > v152) {
        unint64_t v152 = v153 >> 4;
      }
      if ((unint64_t)v153 >= 0x7FFFFFFFFFFFFFE0) {
        unint64_t v154 = 0x7FFFFFFFFFFFFFFLL;
      }
      else {
        unint64_t v154 = v152;
      }
      if (v154)
      {
        v155 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ControlEdgeInfo>>(v161, v154);
        v150 = (void *)*v5;
        char v148 = (void *)v5[1];
      }
      else
      {
        v155 = 0;
      }
      v156 = &v155[32 * v151];
      *(void *)v156 = v143;
      *((void *)v156 + 1) = v144;
      *((void *)v156 + 2) = v146;
      *((void *)v156 + 3) = v145;
      v157 = v156;
      if (v148 != v150)
      {
        do
        {
          long long v158 = *((_OWORD *)v148 - 1);
          *((_OWORD *)v157 - 2) = *((_OWORD *)v148 - 2);
          *((_OWORD *)v157 - 1) = v158;
          v157 -= 32;
          v148 -= 4;
        }
        while (v148 != v150);
        v150 = (void *)*v5;
      }
      v149 = v156 + 32;
      *uint64_t v5 = (unint64_t)v157;
      v5[1] = (unint64_t)(v156 + 32);
      v5[2] = (unint64_t)&v155[32 * v154];
      if (v150) {
        operator delete(v150);
      }
    }
    else
    {
      *char v148 = v143;
      v148[1] = v144;
      v149 = v148 + 4;
      v148[2] = v146;
      v148[3] = v145;
    }
    v5[1] = (unint64_t)v149;
    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v192, v193[0]);
    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v196, v197[0]);
    int64_t v159 = v198;
    unint64_t v13 = ++v198;
  }
  while (v159 < *((void *)a2 + 1));
LABEL_312:
  std::__hash_table<std::__hash_value_type<long,PressureBasedSubgraphIdentification::CopyPressure>,std::__unordered_map_hasher<long,std::__hash_value_type<long,PressureBasedSubgraphIdentification::CopyPressure>,std::hash<long>,std::equal_to<long>,true>,std::__unordered_map_equal<long,std::__hash_value_type<long,PressureBasedSubgraphIdentification::CopyPressure>,std::equal_to<long>,std::hash<long>,true>,std::allocator<std::__hash_value_type<long,PressureBasedSubgraphIdentification::CopyPressure>>>::~__hash_table((uint64_t)v199);
  return std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v201);
}

void sub_2112901C8(_Unwind_Exception *a1)
{
  std::__hash_table<std::__hash_value_type<long,PressureBasedSubgraphIdentification::CopyPressure>,std::__unordered_map_hasher<long,std::__hash_value_type<long,PressureBasedSubgraphIdentification::CopyPressure>,std::hash<long>,std::equal_to<long>,true>,std::__unordered_map_equal<long,std::__hash_value_type<long,PressureBasedSubgraphIdentification::CopyPressure>,std::equal_to<long>,std::hash<long>,true>,std::allocator<std::__hash_value_type<long,PressureBasedSubgraphIdentification::CopyPressure>>>::~__hash_table(v1 - 192);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table(v1 - 144);
  _Unwind_Resume(a1);
}

BOOL PressureBasedSubgraphIdentification::IsSIPContributor(PressureBasedSubgraphIdentification *this, const ZinLiveRange *a2, const Subgraph *a3, const ZinIrTensor *a4)
{
  RootTensor = ZinIrTensor::GetRootTensor(a4);
  p_RootTensor = &RootTensor;
  unint64_t v7 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>>>::__emplace_unique_key_args<ZinIrTensor *,std::piecewise_construct_t const&,std::tuple<ZinIrTensor * const&>,std::tuple<>>((uint64_t)this + 24, &RootTensor, (uint64_t)&std::piecewise_construct, &p_RootTensor);
  uint64_t v8 = v7[3];
  uint64_t v9 = v7[4];
  uint64_t v10 = (ZinIrOpLayer *)*((void *)RootTensor + 12);
  unint64_t v23 = v10;
  for (uint64_t i = *((void *)v10 + 14); i != *((void *)v10 + 15); i += 8)
  {
    if (*(_DWORD *)(*(void *)(*(void *)i + 64) + 8) == 31) {
      return 0;
    }
  }
  if (*(_DWORD *)(*((void *)v10 + 8) + 8) == 7)
  {
    BOOL v12 = std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)a3 + 72, &v23) == 0;
    uint64_t v10 = v23;
  }
  else
  {
    BOOL v12 = 1;
  }
  uint64_t v13 = *((void *)v10 + 11);
  uint64_t v14 = *((void *)v10 + 12);
  if (v13 == v14)
  {
    BOOL v17 = 1;
  }
  else
  {
    uint64_t v15 = v13 + 8;
    do
    {
      p_RootTensor = *(ZinIrTensor ***)(v15 - 8);
      uint64_t v16 = std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)a3 + 72, (ZinIrOpLayer **)&p_RootTensor);
      BOOL v17 = v16 == 0;
      if (v16) {
        break;
      }
      BOOL v18 = v15 == v14;
      v15 += 8;
    }
    while (!v18);
    uint64_t v10 = v23;
  }
  uint64_t v19 = (ZinIrTensor ***)*((void *)v10 + 14);
  unint64_t v20 = (ZinIrTensor ***)*((void *)v10 + 15);
  if (v19 == v20)
  {
LABEL_18:
    if (!v12 && !v17) {
      return 0;
    }
  }
  else
  {
    while (1)
    {
      p_RootTensor = *v19;
      if (!std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)a3 + 72, (ZinIrOpLayer **)&p_RootTensor))break; {
      if (++v19 == v20)
      }
        goto LABEL_18;
    }
  }
  return v8 < *(void *)a2
      || v9 > *((void *)a2 + 1)
      || std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)a3 + 72, &v23) == 0;
}

uint64_t PressureBasedSubgraphIdentification::ComputeSplitInvariantPressure(const ZinIrTensor ***this, const ZinLiveRange *a2, const Subgraph *a3, unint64_t a4)
{
  memset(v47, 0, sizeof(v47));
  int v48 = 1065353216;
  memset(v45, 0, sizeof(v45));
  int v46 = 1065353216;
  unint64_t v4 = *(void *)a2;
  if (*(void *)a2 <= *((void *)a2 + 1))
  {
    uint64_t v7 = 0;
    uint64_t v5 = 0;
    BOOL v30 = (char *)(this + 16);
    BOOL v34 = (char *)a3 + 72;
    do
    {
      v44[0] = v4;
      v44[1] = v4;
      int64_t v31 = v4;
      v42[0] = 0;
      v42[1] = 0;
      char v43 = 0;
      int v41 = v42;
      ZinIrMemoryPressureAnalyzer::GetPeakPressure((uint64_t)v30, v44, (uint64_t)&v41);
      uint64_t v8 = v41;
      if (v41 != v42)
      {
        do
        {
          uint64_t v9 = (ZinIrTensor **)v8[4];
          if (!(*((unsigned int (**)(ZinIrTensor **))*v9 + 3))(v9))
          {
            RootTensor = 0;
            RootTensor = ZinIrTensor::GetRootTensor(v9[4]);
            if (!std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(v45, &RootTensor))
            {
              std::__hash_table<ZinIrTensor const*,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const* const&>((uint64_t)v45, &RootTensor, &RootTensor);
              v39[0] = 0;
              v39[1] = 0;
              long long v38 = (uint64_t *)v39;
              if (PressureBasedSubgraphIdentification::IsSIPContributor((PressureBasedSubgraphIdentification *)this, a2, a3, RootTensor))
              {
                std::__tree<ZinIrTensor *>::__emplace_unique_key_args<ZinIrTensor *,ZinIrTensor * const&>(&v38, (unint64_t *)&RootTensor, (uint64_t *)&RootTensor);
              }
              else
              {
                unint64_t v37 = (ZinIrOpLayer *)*((void *)RootTensor + 12);
                if (*(_DWORD *)(*((void *)v37 + 8) + 8) == 7
                  && std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)v34, &v37)&& PressureBasedSubgraphIdentification::IsPartialInput((uint64_t)v34, (uint64_t)v37))
                {
                  uint64_t v11 = (ZinIrOpLayer **)*((void *)v37 + 11);
                  uint64_t v10 = (ZinIrOpLayer **)*((void *)v37 + 12);
                  while (v11 != v10)
                  {
                    if (!std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)v34, v11))
                    {
                      uint64_t v36 = (*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)*v11 + 32))(*v11, 0, 0);
                      std::__tree<ZinIrTensor *>::__emplace_unique_key_args<ZinIrTensor *,ZinIrTensor * const&>(&v38, (unint64_t *)&v36, &v36);
                    }
                    ++v11;
                  }
                }
              }
              BOOL v12 = v38;
              if (v38 != (uint64_t *)v39)
              {
                do
                {
                  uint64_t v13 = v12 + 4;
                  if (!std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(v47, v12 + 4))
                  {
                    unsigned int v14 = ZinMirSpatialSplitUtils::IsChained(*v13, this[14]);
                    unsigned int v15 = v14;
                    uint64_t v16 = *((void *)RootTensor + 13);
                    if (v16) {
                      LODWORD(v16) = *(_DWORD *)(v16 + 96);
                    }
                    if (v16 == 1) {
                      char v17 = 1;
                    }
                    else {
                      char v17 = v14;
                    }
                    BOOL v18 = (const ZinIrTensor *)*v13;
                    if (*((unsigned char *)this[8] + 2)
                      || (*(_DWORD *)(*(void *)(*((void *)v18 + 12) + 64) + 8) & 0xFFFFFFFC) != 0x1C)
                    {
                      PressureBasedSubgraphIdentification::GetTensorSize((PressureBasedSubgraphIdentification *)this, v18);
                      ChainBufferuint64_t Size = v21;
                      int v19 = *((unsigned __int8 *)this[8] + 2);
                    }
                    else
                    {
                      int v19 = 0;
                      ChainBufferuint64_t Size = 0;
                    }
                    if (v19) {
                      unsigned int v22 = 0;
                    }
                    else {
                      unsigned int v22 = v15;
                    }
                    if (v22 == 1) {
                      ChainBufferuint64_t Size = ZinL2FootprintCalculator::GetChainBufferSize(this[28], (ZinIrRegAllocUtil **)*v13);
                    }
                    std::__hash_table<ZinIrTensor const*,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const* const&>((uint64_t)v47, v12 + 4, v12 + 4);
                    if (((ChainBufferSize < a4) & v17) != 0) {
                      unint64_t v23 = ChainBufferSize;
                    }
                    else {
                      unint64_t v23 = 0;
                    }
                    v7 += v23;
                    v5 += ChainBufferSize;
                  }
                  uint64_t v24 = (uint64_t *)v12[1];
                  if (v24)
                  {
                    do
                    {
                      uint64_t v25 = v24;
                      uint64_t v24 = (uint64_t *)*v24;
                    }
                    while (v24);
                  }
                  else
                  {
                    do
                    {
                      uint64_t v25 = (uint64_t *)v12[2];
                      BOOL v26 = *v25 == (void)v12;
                      BOOL v12 = v25;
                    }
                    while (!v26);
                  }
                  BOOL v12 = v25;
                }
                while (v25 != (uint64_t *)v39);
              }
              std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v38, v39[0]);
            }
          }
          BOOL v27 = (void *)v8[1];
          if (v27)
          {
            do
            {
              uint64_t v28 = (void **)v27;
              BOOL v27 = (void *)*v27;
            }
            while (v27);
          }
          else
          {
            do
            {
              uint64_t v28 = (void **)v8[2];
              BOOL v26 = *v28 == v8;
              uint64_t v8 = v28;
            }
            while (!v26);
          }
          uint64_t v8 = v28;
        }
        while (v28 != v42);
      }
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v41, v42[0]);
      unint64_t v4 = v31 + 1;
    }
    while (v31 < *((void *)a2 + 1));
  }
  else
  {
    uint64_t v5 = 0;
  }
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v45);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v47);
  return v5;
}

void sub_211290928(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,char a23,void *a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,char a29)
{
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&a23, a24);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&a29);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table(v29 - 128);
  _Unwind_Resume(a1);
}

uint64_t PressureBasedSubgraphIdentification::ComputeTileSize(uint64_t a1, void *a2, unint64_t a3, uint64_t a4, void **a5, void *a6)
{
  uint64_t v9 = a2;
  (*(void (**)(uint64_t, void *, uint64_t))(*(void *)a1 + 88))(a1, a2, a4);
  uint64_t v38 = (uint64_t)(v9 + 9);
  uint64_t v11 = PressureBasedSubgraphIdentification::ComputeTimeSpanOfCluster(v9 + 9);
  v47[0] = v11;
  v47[1] = v12;
  unint64_t v44 = 0;
  uint64_t v45 = 0;
  uint64_t v46 = 0;
  PressureBasedSubgraphIdentification::GetPeakPressure((PressureBasedSubgraphIdentification *)a1, (const ZinIrOpLayer *)v47, (uint64_t)v9, a4, (unint64_t *)&v44);
  uint64_t v13 = PressureBasedSubgraphIdentification::ComputeSplitInvariantPressure((const ZinIrTensor ***)a1, (const ZinLiveRange *)v47, (const Subgraph *)v9, a3);
  unint64_t v43 = 1;
  if (*(unsigned char *)(*(void *)(a1 + 64) + 2)) {
    unint64_t v15 = v13 - v14;
  }
  else {
    unint64_t v15 = v14;
  }
  unint64_t v41 = a3 - v15;
  if (a3 < v15)
  {
    if (*(unsigned char *)(a1 + 73))
    {
      uint64_t v16 = 1;
      if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_INFO))
      {
        *(_WORD *)long long buf = 0;
        _os_log_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_INFO, "INFO:: (SpatialSplit) Can't tile subgraph b/c SIP > budget\n", buf, 2u);
      }
    }
    else
    {
      uint64_t v16 = 1;
    }
    goto LABEL_32;
  }
  uint64_t v37 = *(void *)(a1 + 8);
  if (*(void *)(v37 + 360) == *(void *)(v37 + 352)) {
    ZinAssertImpl("Must run scheduler first");
  }
  int v35 = v9;
  uint64_t v36 = a6;
  char v17 = v44;
  BOOL v18 = v45;
  if (v44 != v45)
  {
    uint64_t v40 = v9 + 3;
    int v19 = v9 + 4;
    unint64_t v20 = 1;
    while (1)
    {
      unint64_t v21 = v17[2] + v17[1] + v17[3];
      BOOL v22 = v41 >= v21;
      unint64_t v23 = v41 - v21;
      if (v23 == 0 || !v22) {
        goto LABEL_12;
      }
      if (*v17) {
        break;
      }
LABEL_26:
      v17 += 4;
      if (v17 == v18) {
        goto LABEL_31;
      }
    }
    uint64_t v24 = (void *)*v40;
    if ((void *)*v40 != v19)
    {
      float v25 = (float)*v17 / (float)v23;
      while (1)
      {
        uint64_t v26 = v24[4];
        unint64_t v27 = (*(uint64_t (**)(uint64_t, uint64_t, uint64_t, float))(*(void *)a1 + 128))(a1, v26, a4, v25);
        if (!v27) {
          break;
        }
        uint64_t v28 = (*(uint64_t (**)(uint64_t, void, void))(*(void *)v26 + 32))(v26, 0, 0);
        float v29 = (float)((float)((float)v27
                            + (float)(unint64_t)GetValueAtDimension<ZinTensorDimensions>((uint64_t *)(v28 + 48), *(_DWORD *)(a4 + 24)))+ -1.0)/ (float)v27;
        if (v20 <= (unint64_t)v29) {
          unint64_t v20 = (unint64_t)v29;
        }
        BOOL v30 = (void *)v24[1];
        if (v30)
        {
          do
          {
            int64_t v31 = v30;
            BOOL v30 = (void *)*v30;
          }
          while (v30);
        }
        else
        {
          do
          {
            int64_t v31 = (void *)v24[2];
            BOOL v32 = *v31 == (void)v24;
            uint64_t v24 = v31;
          }
          while (!v32);
        }
        uint64_t v24 = v31;
        if (v31 == v19) {
          goto LABEL_25;
        }
      }
LABEL_12:
      ResetLayerCausingTooMuchPressure(*(ZinIrOpLayer **)(*(void *)(v37 + 352) + 8 * v11), v38, (uint64_t)v40, a5);
    }
LABEL_25:
    ++v11;
    goto LABEL_26;
  }
  unint64_t v20 = 1;
LABEL_31:
  uint64_t v16 = 0;
  unint64_t v43 = v20;
  uint64_t v9 = v35;
  a6 = v36;
LABEL_32:
  PressureBasedSubgraphIdentification::UpdateTileCountToMinimizeUtilizationLoss(a1, (uint64_t)v9, a4, &v43);
  BOOL v33 = v44;
  *a6 = v43;
  if (v33)
  {
    uint64_t v45 = v33;
    operator delete(v33);
  }
  return v16;
}

void sub_211290CB4(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, void *__p,uint64_t a21)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

void ResetLayerCausingTooMuchPressure(ZinIrOpLayer *a1, uint64_t a2, uint64_t a3, void **a4)
{
  int v35 = a1;
  if (ZinIrOpLayer::IsANELayer(a1)
    && std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>(a2, &v35))
  {
    unint64_t v7 = (unint64_t)a4[2];
    uint64_t v8 = a4[1];
    if ((unint64_t)v8 >= v7)
    {
      uint64_t v10 = ((char *)v8 - (unsigned char *)*a4) >> 3;
      if ((unint64_t)(v10 + 1) >> 61) {
LABEL_41:
      }
        std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
      uint64_t v11 = v7 - (void)*a4;
      uint64_t v12 = v11 >> 2;
      if (v11 >> 2 <= (unint64_t)(v10 + 1)) {
        uint64_t v12 = v10 + 1;
      }
      if ((unint64_t)v11 >= 0x7FFFFFFFFFFFFFF8) {
        unint64_t v13 = 0x1FFFFFFFFFFFFFFFLL;
      }
      else {
        unint64_t v13 = v12;
      }
      if (v13) {
        unint64_t v14 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)(a4 + 2), v13);
      }
      else {
        unint64_t v14 = 0;
      }
      unint64_t v15 = &v14[8 * v10];
      uint64_t v16 = &v14[8 * v13];
      *(void *)unint64_t v15 = v35;
      uint64_t v9 = v15 + 8;
      BOOL v18 = (char *)*a4;
      char v17 = (char *)a4[1];
      if (v17 != *a4)
      {
        do
        {
          uint64_t v19 = *((void *)v17 - 1);
          v17 -= 8;
          *((void *)v15 - 1) = v19;
          v15 -= 8;
        }
        while (v17 != v18);
        char v17 = (char *)*a4;
      }
      *a4 = v15;
      a4[1] = v9;
      a4[2] = v16;
      if (v17) {
        operator delete(v17);
      }
    }
    else
    {
      *uint64_t v8 = v35;
      uint64_t v9 = v8 + 1;
    }
    a4[1] = v9;
    if (std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>(a3, &v35))
    {
      unint64_t v20 = (ZinIrOpLayer **)*((void *)v35 + 11);
      for (uint64_t i = (ZinIrOpLayer **)*((void *)v35 + 12); v20 != i; ++v20)
      {
        BOOL v34 = *v20;
        if (std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>(a2, &v34))
        {
          unint64_t v23 = a4[1];
          unint64_t v22 = (unint64_t)a4[2];
          if ((unint64_t)v23 >= v22)
          {
            uint64_t v25 = ((char *)v23 - (unsigned char *)*a4) >> 3;
            if ((unint64_t)(v25 + 1) >> 61) {
              goto LABEL_41;
            }
            uint64_t v26 = v22 - (void)*a4;
            uint64_t v27 = v26 >> 2;
            if (v26 >> 2 <= (unint64_t)(v25 + 1)) {
              uint64_t v27 = v25 + 1;
            }
            if ((unint64_t)v26 >= 0x7FFFFFFFFFFFFFF8) {
              unint64_t v28 = 0x1FFFFFFFFFFFFFFFLL;
            }
            else {
              unint64_t v28 = v27;
            }
            if (v28) {
              float v29 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)(a4 + 2), v28);
            }
            else {
              float v29 = 0;
            }
            BOOL v30 = &v29[8 * v25];
            *(void *)BOOL v30 = v34;
            uint64_t v24 = v30 + 8;
            BOOL v32 = (char *)*a4;
            int64_t v31 = (char *)a4[1];
            if (v31 != *a4)
            {
              do
              {
                uint64_t v33 = *((void *)v31 - 1);
                v31 -= 8;
                *((void *)v30 - 1) = v33;
                v30 -= 8;
              }
              while (v31 != v32);
              int64_t v31 = (char *)*a4;
            }
            *a4 = v30;
            a4[1] = v24;
            a4[2] = &v29[8 * v28];
            if (v31) {
              operator delete(v31);
            }
          }
          else
          {
            void *v23 = v34;
            uint64_t v24 = v23 + 1;
          }
          a4[1] = v24;
        }
      }
    }
  }
}

void PressureBasedSubgraphIdentification::UpdateTileCountToMinimizeUtilizationLoss(uint64_t a1, uint64_t a2, uint64_t a3, unint64_t *a4)
{
  if (*(_DWORD *)(a3 + 24) == 4)
  {
    BOOL v32 = 0;
    uint64_t v33 = 0;
    BOOL v34 = 0;
    unint64_t v4 = *(void **)(a2 + 72);
    uint64_t v5 = (void *)(a2 + 80);
    if (v4 != (void *)(a2 + 80))
    {
      do
      {
        uint64_t v8 = (ZinIrOpLayer *)v4[4];
        if (*(_DWORD *)(*((void *)v8 + 8) + 8) == 85
          && *(void *)((*(uint64_t (**)(void, void, void))(*(void *)v8 + 32))(v4[4], 0, 0) + 64) == 1)
        {
          if (v33 >= (ZinIrOpLayer **)v34)
          {
            uint64_t v10 = ((char *)v33 - v32) >> 3;
            if ((unint64_t)(v10 + 1) >> 61) {
              std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
            }
            unint64_t v11 = (v34 - v32) >> 2;
            if (v11 <= v10 + 1) {
              unint64_t v11 = v10 + 1;
            }
            if ((unint64_t)(v34 - v32) >= 0x7FFFFFFFFFFFFFF8) {
              unint64_t v12 = 0x1FFFFFFFFFFFFFFFLL;
            }
            else {
              unint64_t v12 = v11;
            }
            if (v12) {
              unint64_t v13 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)&v34, v12);
            }
            else {
              unint64_t v13 = 0;
            }
            unint64_t v14 = &v13[8 * v10];
            *(void *)unint64_t v14 = v8;
            uint64_t v9 = (ZinIrOpLayer **)(v14 + 8);
            unint64_t v15 = (char *)v33;
            if (v33 != (ZinIrOpLayer **)v32)
            {
              do
              {
                uint64_t v16 = *((void *)v15 - 1);
                v15 -= 8;
                *((void *)v14 - 1) = v16;
                v14 -= 8;
              }
              while (v15 != v32);
              unint64_t v15 = v32;
            }
            BOOL v32 = v14;
            BOOL v34 = &v13[8 * v12];
            if (v15) {
              operator delete(v15);
            }
          }
          else
          {
            unint64_t *v33 = v8;
            uint64_t v9 = v33 + 1;
          }
          uint64_t v33 = v9;
        }
        char v17 = (void *)v4[1];
        if (v17)
        {
          do
          {
            BOOL v18 = v17;
            char v17 = (void *)*v17;
          }
          while (v17);
        }
        else
        {
          do
          {
            BOOL v18 = (void *)v4[2];
            BOOL v19 = *v18 == (void)v4;
            unint64_t v4 = v18;
          }
          while (!v19);
        }
        unint64_t v4 = v18;
      }
      while (v18 != v5);
      unint64_t v20 = (ZinIrOpLayer **)v32;
      if (v33 == (ZinIrOpLayer **)v32) {
        goto LABEL_43;
      }
      unint64_t v21 = *a4;
      unint64_t v22 = *(void *)(**(void **)(a1 + 16) + 784);
      do
      {
        unint64_t v23 = *v20;
        uint64_t v24 = (*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)*v20 + 32))(*v20, 0, 0);
        unint64_t v25 = *(void *)(**(void **)(a1 + 16) + 592) >> (*(_DWORD *)(ZinIrOpLayer::GetInputTensor(v23, 0) + 88) == 3);
        unint64_t v26 = *(void *)(v24 + 72);
        while (v26 / v21 % v25 && v26 / v21 % v22)
        {
          if (++v21 > v26) {
            goto LABEL_42;
          }
        }
        ++v20;
      }
      while (v20 != v33);
      for (uint64_t i = (ZinIrOpLayer **)v32; i != v33; ++i)
      {
        unint64_t v28 = *i;
        uint64_t v29 = (*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)*i + 32))(*i, 0, 0);
        unint64_t v30 = *(void *)(**(void **)(a1 + 16) + 592) >> (*(_DWORD *)(ZinIrOpLayer::GetInputTensor(v28, 0) + 88) == 3);
        unint64_t v31 = *(void *)(v29 + 72) / v21;
        if (v31 % v30 && v31 % v22) {
          goto LABEL_42;
        }
      }
      *a4 = v21;
    }
LABEL_42:
    unint64_t v20 = (ZinIrOpLayer **)v32;
LABEL_43:
    if (v20) {
      operator delete(v20);
    }
  }
}

void sub_211291218(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

void PressureBasedSubgraphIdentification::RemoveIllegalInternalNodes(uint64_t a1, uint64_t **a2)
{
  uint64_t v45 = 0;
  uint64_t v46 = 0;
  v43[1] = 0;
  unint64_t v44 = (uint64_t *)&v45;
  BOOL v42 = (uint64_t *)v43;
  v43[0] = 0;
  v41[0] = 0;
  v41[1] = 0;
  v39[1] = 0;
  uint64_t v40 = (uint64_t *)v41;
  uint64_t v38 = (ZinIrOpLayer **)v39;
  v39[0] = 0;
  PressureBasedSubgraphIdentification::FindOutputNoOps(a1, a2, (uint64_t **)&v38);
  PressureBasedSubgraphIdentification::FindUnsupportedConcats(v3, a2, (uint64_t **)&v38);
  std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::insert[abi:ne180100]<std::__tree_const_iterator<ZinIrOpLayer *,std::__tree_node<ZinIrOpLayer *,void *> *,long>>((uint64_t *)&v40, v38, v39);
  std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::insert[abi:ne180100]<std::__tree_const_iterator<ZinIrOpLayer *,std::__tree_node<ZinIrOpLayer *,void *> *,long>>((uint64_t *)&v44, v38, v39);
  std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::insert[abi:ne180100]<std::__tree_const_iterator<ZinIrOpLayer *,std::__tree_node<ZinIrOpLayer *,void *> *,long>>((uint64_t *)&v42, v38, v39);
  unint64_t v4 = *a2;
  if (*a2 != (uint64_t *)(a2 + 1))
  {
    do
    {
      BOOL v34 = (uint64_t *)v4[4];
      uint64_t v5 = (ZinIrOpLayer **)v34[14];
      uint64_t v6 = v34[15];
      while (v5 != (ZinIrOpLayer **)v6)
      {
        uint64_t v37 = 0;
        uint64_t v37 = *v5;
        if (!std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)a2, &v37))
        {
          std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>(&v40, (ZinIrOpLayer **)&v34, (uint64_t *)&v34);
          break;
        }
        ++v5;
      }
      unint64_t v7 = (uint64_t *)v4[1];
      if (v7)
      {
        do
        {
          uint64_t v8 = (uint64_t **)v7;
          unint64_t v7 = (uint64_t *)*v7;
        }
        while (v7);
      }
      else
      {
        do
        {
          uint64_t v8 = (uint64_t **)v4[2];
          BOOL v9 = *v8 == v4;
          unint64_t v4 = (uint64_t *)v8;
        }
        while (!v9);
      }
      unint64_t v4 = (uint64_t *)v8;
    }
    while (v8 != a2 + 1);
  }
  uint64_t v10 = v40;
  if (v40 != (uint64_t *)v41)
  {
    do
    {
      uint64_t v11 = v10[4];
      unint64_t v12 = *(uint64_t ***)(v11 + 112);
      unint64_t v13 = *(uint64_t ***)(v11 + 120);
      while (v12 != v13)
      {
        BOOL v34 = 0;
        BOOL v34 = *v12;
        if (!std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)&v44, (ZinIrOpLayer **)&v34))
        {
          if (std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)a2, (ZinIrOpLayer **)&v34))
          {
            std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>(&v44, (ZinIrOpLayer **)&v34, (uint64_t *)&v34);
            std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>(&v42, (ZinIrOpLayer **)&v34, (uint64_t *)&v34);
          }
        }
        ++v12;
      }
      unint64_t v14 = (uint64_t *)v10[1];
      if (v14)
      {
        do
        {
          unint64_t v15 = v14;
          unint64_t v14 = (uint64_t *)*v14;
        }
        while (v14);
      }
      else
      {
        do
        {
          unint64_t v15 = (uint64_t *)v10[2];
          BOOL v9 = *v15 == (void)v10;
          uint64_t v10 = v15;
        }
        while (!v9);
      }
      uint64_t v10 = v15;
    }
    while (v15 != (uint64_t *)v41);
  }
  int v35 = 0;
  uint64_t v36 = 0;
  BOOL v34 = (uint64_t *)&v35;
  for (uint64_t i = v46; v46; uint64_t i = v46)
  {
    char v17 = v44;
    if (v44 == (uint64_t *)&v45)
    {
      uint64_t v26 = 0;
      unint64_t v23 = 0;
      uint64_t v24 = (uint64_t *)&v35;
      unint64_t v25 = (uint64_t *)&v45;
    }
    else
    {
      do
      {
        uint64_t v18 = v17[4];
        BOOL v19 = *(ZinIrOpLayer ***)(v18 + 112);
        unint64_t v20 = *(ZinIrOpLayer ***)(v18 + 120);
        while (v19 != v20)
        {
          uint64_t v37 = 0;
          uint64_t v37 = *v19;
          if (!std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)&v34, &v37)&& std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)a2, &v37))
          {
            std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>(&v34, &v37, (uint64_t *)&v37);
            std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>(&v42, &v37, (uint64_t *)&v37);
          }
          ++v19;
        }
        unint64_t v21 = (uint64_t *)v17[1];
        if (v21)
        {
          do
          {
            unint64_t v22 = v21;
            unint64_t v21 = (uint64_t *)*v21;
          }
          while (v21);
        }
        else
        {
          do
          {
            unint64_t v22 = (uint64_t *)v17[2];
            BOOL v9 = *v22 == (void)v17;
            char v17 = v22;
          }
          while (!v9);
        }
        char v17 = v22;
      }
      while (v22 != (uint64_t *)&v45);
      uint64_t v24 = v34;
      unint64_t v23 = v35;
      unint64_t v25 = v44;
      uint64_t i = v46;
      uint64_t v26 = v36;
    }
    uint64_t v27 = v45;
    unint64_t v44 = v24;
    uint64_t v45 = v23;
    BOOL v34 = v25;
    int v35 = v27;
    uint64_t v46 = v26;
    uint64_t v36 = i;
    unint64_t v28 = (uint64_t **)(v23 + 2);
    if (!v26) {
      unint64_t v28 = &v44;
    }
    *unint64_t v28 = (uint64_t *)&v45;
    if (i) {
      uint64_t v29 = (uint64_t **)(v27 + 2);
    }
    else {
      uint64_t v29 = &v34;
    }
    *uint64_t v29 = (uint64_t *)&v35;
    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v34, v27);
    int v35 = 0;
    uint64_t v36 = 0;
    BOOL v34 = (uint64_t *)&v35;
  }
  unint64_t v30 = v42;
  if (v42 == (uint64_t *)v43)
  {
    uint64_t v33 = 0;
  }
  else
  {
    do
    {
      uint64_t v37 = (ZinIrOpLayer *)v30[4];
      std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__erase_unique<ZinIrOpLayer *>(a2, &v37);
      unint64_t v31 = (uint64_t *)v30[1];
      if (v31)
      {
        do
        {
          BOOL v32 = v31;
          unint64_t v31 = (uint64_t *)*v31;
        }
        while (v31);
      }
      else
      {
        do
        {
          BOOL v32 = (uint64_t *)v30[2];
          BOOL v9 = *v32 == (void)v30;
          unint64_t v30 = v32;
        }
        while (!v9);
      }
      unint64_t v30 = v32;
    }
    while (v32 != (uint64_t *)v43);
    uint64_t v33 = v35;
  }
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v34, v33);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v38, v39[0]);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v40, v41[0]);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v42, v43[0]);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v44, v45);
}

void sub_211291618(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, char a13, void *a14, uint64_t a15, char a16, void *a17, uint64_t a18, char a19, void *a20,uint64_t a21,char a22,void *a23)
{
}

void PressureBasedSubgraphIdentification::FindOutputNoOps(uint64_t a1, void *a2, uint64_t **a3)
{
  uint64_t v3 = a2 + 1;
  unint64_t v4 = (void *)*a2;
  if ((void *)*a2 != a2 + 1)
  {
    do
    {
      unint64_t v7 = (ZinIrOpLayer *)v4[4];
      uint64_t v16 = 0;
      char v17 = v7;
      std::string __p = 0;
      unint64_t v15 = 0;
      if (ZinIrOpLayer::IsNoOp(v7, (uint64_t *)&__p))
      {
        int v8 = *(_DWORD *)(*((void *)v17 + 8) + 8);
        if (__p)
        {
          unint64_t v15 = __p;
          operator delete(__p);
        }
        if (v8 != 7)
        {
          BOOL v9 = (void **)*((void *)v17 + 14);
          uint64_t v10 = (void **)*((void *)v17 + 15);
          while (v9 != v10)
          {
            std::string __p = 0;
            std::string __p = *v9;
            if (!std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)a2, (ZinIrOpLayer **)&__p))
            {
              std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>(a3, &v17, (uint64_t *)&v17);
              break;
            }
            ++v9;
          }
        }
      }
      else if (__p)
      {
        unint64_t v15 = __p;
        operator delete(__p);
      }
      uint64_t v11 = (void *)v4[1];
      if (v11)
      {
        do
        {
          unint64_t v12 = v11;
          uint64_t v11 = (void *)*v11;
        }
        while (v11);
      }
      else
      {
        do
        {
          unint64_t v12 = (void *)v4[2];
          BOOL v13 = *v12 == (void)v4;
          unint64_t v4 = v12;
        }
        while (!v13);
      }
      unint64_t v4 = v12;
    }
    while (v12 != v3);
  }
}

void sub_211291790(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, void *__p, uint64_t a10)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

void PressureBasedSubgraphIdentification::FindUnsupportedConcats(uint64_t a1, void *a2, uint64_t **a3)
{
  uint64_t v3 = a2 + 1;
  unint64_t v4 = (void *)*a2;
  if ((void *)*a2 != a2 + 1)
  {
    do
    {
      unint64_t v7 = (void *)v4[4];
      if (*(_DWORD *)(v7[8] + 8) == 7)
      {
        long long v20 = 0u;
        memset(v19, 0, sizeof(v19));
        int v8 = (ZinIrOpLayer **)v7[14];
        BOOL v9 = (ZinIrOpLayer **)v7[15];
        if (v8 != v9)
        {
          int v10 = 0;
          int v11 = 0;
          do
          {
            uint64_t v18 = 0;
            uint64_t v18 = *v8;
            if (std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)a2, &v18))
            {
              std::deque<ZinIrOpLayer *>::push_back(v19, &v18);
              int v11 = 1;
            }
            else
            {
              int v10 = 1;
            }
            ++v8;
          }
          while (v8 != v9);
          if (v11 & v10)
          {
            while (*((void *)&v20 + 1))
            {
              uint64_t v18 = 0;
              uint64_t v18 = *(ZinIrOpLayer **)(*(void *)(*((void *)&v19[0] + 1)
                                                 + (((unint64_t)v20 >> 6) & 0x3FFFFFFFFFFFFF8))
                                     + 8 * (v20 & 0x1FF));
              *(void *)&long long v20 = v20 + 1;
              --*((void *)&v20 + 1);
              if ((unint64_t)v20 >= 0x400)
              {
                operator delete(**((void ***)&v19[0] + 1));
                *((void *)&v19[0] + 1) += 8;
                *(void *)&long long v20 = v20 - 512;
              }
              std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>(a3, &v18, (uint64_t *)&v18);
              unint64_t v12 = (ZinIrOpLayer **)*((void *)v18 + 14);
              BOOL v13 = (ZinIrOpLayer **)*((void *)v18 + 15);
              while (v12 != v13)
              {
                char v17 = 0;
                char v17 = *v12;
                if (std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)a2, &v17))
                {
                  std::deque<ZinIrOpLayer *>::push_back(v19, &v17);
                }
                ++v12;
              }
            }
          }
        }
        std::deque<unsigned long>::~deque[abi:ne180100](v19);
      }
      unint64_t v14 = (void *)v4[1];
      if (v14)
      {
        do
        {
          unint64_t v15 = v14;
          unint64_t v14 = (void *)*v14;
        }
        while (v14);
      }
      else
      {
        do
        {
          unint64_t v15 = (void *)v4[2];
          BOOL v16 = *v15 == (void)v4;
          unint64_t v4 = v15;
        }
        while (!v16);
      }
      unint64_t v4 = v15;
    }
    while (v15 != v3);
  }
}

void sub_21129196C(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, ...)
{
  va_start(va, a3);
  std::deque<unsigned long>::~deque[abi:ne180100]((uint64_t *)va);
  _Unwind_Resume(a1);
}

uint64_t PressureBasedSubgraphIdentification::IsPartialOutput(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = *(ZinIrOpLayer ***)(a2 + 112);
  uint64_t v3 = *(ZinIrOpLayer ***)(a2 + 120);
  if (v2 == v3)
  {
    char v9 = 0;
  }
  else
  {
    char v5 = 0;
    char v6 = 0;
    do
    {
      unint64_t v7 = *v2++;
      int v11 = v7;
      uint64_t v8 = std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>(a1, &v11);
      v6 |= v8 == 0;
      v5 |= v8 != 0;
    }
    while (v2 != v3);
    char v9 = v5 & v6;
  }
  return v9 & 1;
}

uint64_t PressureBasedSubgraphIdentification::MinimumSplitAlignmentConstraint(void *a1, ZinMirSpatialSplitUtils *this, int a3)
{
  uint64_t result = 1;
  switch(a3)
  {
    case 1:
    case 5:
      ZinAssertImpl("Unsupported dimension");
    case 3:
      uint64_t result = ZinMirSpatialSplitUtils::CalculateSplitAlignmentConstraintInHOnCompressedTensor(this, this);
      break;
    case 4:
      unint64_t v8 = 0;
      if (ZinTensorFormatGetSizeInBytes(*((_DWORD *)this + 22), (uint64_t *)&v8)) {
        ZinAssertImpl("Error in getting tensor format size in bytes");
      }
      unint64_t v6 = a1[66];
      if (v6 <= a1[52]) {
        unint64_t v6 = a1[52];
      }
      int64_t v7 = v6 / v8;
      if (*((void *)this + 8) == 1) {
        int64_t v7 = a1[98];
      }
      if (v7 <= 1) {
        uint64_t result = 1;
      }
      else {
        uint64_t result = v7;
      }
      break;
    default:
      return result;
  }
  return result;
}

uint64_t PressureBasedSubgraphIdentification::MinimizeNewPartialOutputs(uint64_t a1, uint64_t **a2, uint64_t **a3, uint64_t a4)
{
  long long v25 = 0u;
  memset(v24, 0, sizeof(v24));
  unint64_t v4 = a2 + 1;
  char v5 = *a2;
  if (*a2 != (uint64_t *)(a2 + 1))
  {
    do
    {
      unint64_t v22 = (uint64_t *)v5[4];
      if (PressureBasedSubgraphIdentification::IsPartialOutput((uint64_t)a2, (uint64_t)v22)
        && !std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>(a4, (ZinIrOpLayer **)&v22))
      {
        std::deque<ZinIrOpLayer *>::push_back(v24, &v22);
      }
      char v9 = (uint64_t *)v5[1];
      if (v9)
      {
        do
        {
          int v10 = v9;
          char v9 = (uint64_t *)*v9;
        }
        while (v9);
      }
      else
      {
        do
        {
          int v10 = (uint64_t *)v5[2];
          BOOL v11 = *v10 == (void)v5;
          char v5 = v10;
        }
        while (!v11);
      }
      char v5 = v10;
    }
    while (v10 != (uint64_t *)v4);
    for (uint64_t i = *((void *)&v25 + 1); *((void *)&v25 + 1); uint64_t i = *((void *)&v25 + 1))
    {
      uint64_t v13 = *(void *)(*(void *)(*((void *)&v24[0] + 1) + (((unint64_t)v25 >> 6) & 0x3FFFFFFFFFFFFF8))
                      + 8 * (v25 & 0x1FF));
      *(void *)&long long v25 = v25 + 1;
      *((void *)&v25 + 1) = i - 1;
      if ((unint64_t)v25 >= 0x400)
      {
        operator delete(**((void ***)&v24[0] + 1));
        *((void *)&v24[0] + 1) += 8;
        *(void *)&long long v25 = v25 - 512;
      }
      v23[0] = 0;
      v23[1] = 0;
      unint64_t v22 = (uint64_t *)v23;
      unint64_t v14 = *(ZinIrOpLayer ***)(v13 + 112);
      unint64_t v15 = *(ZinIrOpLayer ***)(v13 + 120);
      if (v14 != v15)
      {
        char v16 = 1;
        do
        {
          unint64_t v21 = 0;
          unint64_t v21 = *v14;
          if (!std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)a2, &v21))
          {
            if (std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)a3, &v21)&& *((void *)v21 + 12) - *((void *)v21 + 11) == 8)
            {
              std::__tree<ZinIrTensor *>::__emplace_unique_key_args<ZinIrTensor *,ZinIrTensor * const&>(&v22, (unint64_t *)&v21, (uint64_t *)&v21);
            }
            else
            {
              char v16 = 0;
            }
          }
          ++v14;
        }
        while (v14 != v15);
        char v17 = v22;
        if ((v16 & (v22 != (uint64_t *)v23)) == 1)
        {
          do
          {
            unint64_t v21 = (ZinIrOpLayer *)v17[4];
            std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>(a2, &v21, (uint64_t *)&v21);
            std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__erase_unique<ZinIrOpLayer *>(a3, &v21);
            if (PressureBasedSubgraphIdentification::IsPartialOutput((uint64_t)a2, (uint64_t)v21)
              && !std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>(a4, &v21))
            {
              std::deque<ZinIrOpLayer *>::push_back(v24, &v21);
            }
            uint64_t v18 = (uint64_t *)v17[1];
            if (v18)
            {
              do
              {
                BOOL v19 = v18;
                uint64_t v18 = (uint64_t *)*v18;
              }
              while (v18);
            }
            else
            {
              do
              {
                BOOL v19 = (uint64_t *)v17[2];
                BOOL v11 = *v19 == (void)v17;
                char v17 = v19;
              }
              while (!v11);
            }
            char v17 = v19;
          }
          while (v19 != (uint64_t *)v23);
        }
      }
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v22, v23[0]);
    }
  }
  return std::deque<unsigned long>::~deque[abi:ne180100](v24);
}

void sub_211291D68(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, ...)
{
  va_start(va, a5);
  std::deque<unsigned long>::~deque[abi:ne180100]((uint64_t *)va);
  _Unwind_Resume(a1);
}

void PressureBasedSubgraphIdentification::RemoveInputNodeDrivingBothExternalAndInternalNodes(uint64_t a1, uint64_t a2, uint64_t **a3)
{
  v37[1] = *(ZinIrOpLayer **)MEMORY[0x263EF8340];
  v35[0] = 0;
  v35[1] = 0;
  BOOL v34 = (uint64_t *)v35;
  uint64_t v3 = a3 + 1;
  unint64_t v4 = *a3;
  if (*a3 != (uint64_t *)(a3 + 1))
  {
    do
    {
      int64_t v7 = (ZinIrOpLayer *)v4[4];
      uint64_t v33 = (ZinIrOpLayer ***)v7;
      uint64_t v8 = *((void *)v7 + 11);
      uint64_t v9 = *((void *)v7 + 12);
      if (v8 == v9)
      {
        BOOL v12 = 0;
      }
      else
      {
        uint64_t v10 = v8 + 8;
        do
        {
          v31[0] = 0;
          v31[0] = *(ZinIrOpLayer **)(v10 - 8);
          uint64_t v11 = std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)a3, v31);
          BOOL v12 = v11 != 0;
          if (v11) {
            break;
          }
          BOOL v21 = v10 == v9;
          v10 += 8;
        }
        while (!v21);
        int64_t v7 = (ZinIrOpLayer *)v33;
      }
      uint64_t v13 = (ZinIrOpLayer **)*((void *)v7 + 14);
      unint64_t v14 = (ZinIrOpLayer **)*((void *)v7 + 15);
      if (v13 != v14)
      {
        int v15 = 0;
        char v16 = 0;
        do
        {
          v31[0] = 0;
          v31[0] = *v13;
          uint64_t v17 = std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)a3, v31);
          v16 |= v17 != 0;
          v15 |= v17 == 0;
          ++v13;
        }
        while (v13 != v14);
        if (!v12 && (v16 & 1) != 0 && ((v15 ^ 1) & 1) == 0)
        {
          std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>(&v34, (ZinIrOpLayer **)&v33, (uint64_t *)&v33);
          uint64_t v18 = v33[14];
          BOOL v19 = v33[15];
          while (v18 != v19)
          {
            BOOL v32 = 0;
            BOOL v32 = *v18;
            if (std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)a3, &v32))
            {
              long long v20 = *a3;
              BOOL v21 = *(_DWORD *)(*((void *)v32 + 8) + 8) != 7 || v20 == (uint64_t *)v3;
              if (!v21)
              {
                do
                {
                  v37[0] = (ZinIrOpLayer *)v20[4];
                  std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::set[abi:ne180100]((uint64_t)v31, v37, 1);
                  uint64_t v36 = v32;
                  std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::set[abi:ne180100]((uint64_t)v30, &v36, 1);
                  BOOL v22 = ZinIrNgraph<ZinIrOpLayer *,ZinIrIdComparator<ZinIrOpLayer *>>::IsDominanceRelationship<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>(a2, v31, v30);
                  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v30, (void *)v30[1]);
                  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v31, (void *)v31[1]);
                  if (v22) {
                    std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>(&v34, (ZinIrOpLayer **)&v33, (uint64_t *)&v33);
                  }
                  unint64_t v23 = (uint64_t *)v20[1];
                  if (v23)
                  {
                    do
                    {
                      uint64_t v24 = v23;
                      unint64_t v23 = (uint64_t *)*v23;
                    }
                    while (v23);
                  }
                  else
                  {
                    do
                    {
                      uint64_t v24 = (uint64_t *)v20[2];
                      BOOL v21 = *v24 == (void)v20;
                      long long v20 = v24;
                    }
                    while (!v21);
                  }
                  long long v20 = v24;
                }
                while (v24 != (uint64_t *)v3);
              }
            }
            ++v18;
          }
        }
      }
      long long v25 = (uint64_t *)v4[1];
      if (v25)
      {
        do
        {
          uint64_t v26 = v25;
          long long v25 = (uint64_t *)*v25;
        }
        while (v25);
      }
      else
      {
        do
        {
          uint64_t v26 = (uint64_t *)v4[2];
          BOOL v21 = *v26 == (void)v4;
          unint64_t v4 = v26;
        }
        while (!v21);
      }
      unint64_t v4 = v26;
    }
    while (v26 != (uint64_t *)v3);
    uint64_t v27 = v34;
    if (v34 != (uint64_t *)v35)
    {
      do
      {
        v31[0] = (ZinIrOpLayer *)v27[4];
        std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__erase_unique<ZinIrOpLayer *>(a3, v31);
        unint64_t v28 = (uint64_t *)v27[1];
        if (v28)
        {
          do
          {
            uint64_t v29 = v28;
            unint64_t v28 = (uint64_t *)*v28;
          }
          while (v28);
        }
        else
        {
          do
          {
            uint64_t v29 = (uint64_t *)v27[2];
            BOOL v21 = *v29 == (void)v27;
            uint64_t v27 = v29;
          }
          while (!v21);
        }
        uint64_t v27 = v29;
      }
      while (v29 != (uint64_t *)v35);
    }
  }
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v34, v35[0]);
}

void sub_211292090(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, char a19, void *a20)
{
}

BOOL ZinIrNgraph<ZinIrOpLayer *,ZinIrIdComparator<ZinIrOpLayer *>>::IsDominanceRelationship<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>(uint64_t a1, void *a2, void *a3)
{
  memset(v45, 0, sizeof(v45));
  int v46 = 1065353216;
  unint64_t v43 = 0;
  uint64_t v44 = 0;
  BOOL v42 = (uint64_t *)&v43;
  unint64_t v4 = a2 + 1;
  char v5 = (void *)*a2;
  if ((void *)*a2 != a2 + 1)
  {
    do
    {
      uint64_t v39 = v5 + 4;
      std::__tree<std::reference_wrapper<ZinIrOpLayer * const>,ZinIrIdComparator<ZinIrOpLayer *>,std::allocator<std::reference_wrapper<ZinIrOpLayer * const>>>::__emplace_unique_key_args<std::reference_wrapper<ZinIrOpLayer * const>,std::reference_wrapper<ZinIrOpLayer * const>>(&v42, &v39, (uint64_t *)&v39);
      int64_t v7 = (void *)v5[1];
      if (v7)
      {
        do
        {
          uint64_t v8 = v7;
          int64_t v7 = (void *)*v7;
        }
        while (v7);
      }
      else
      {
        do
        {
          uint64_t v8 = (void *)v5[2];
          BOOL v9 = *v8 == (void)v5;
          char v5 = v8;
        }
        while (!v9);
      }
      char v5 = v8;
    }
    while (v8 != v4);
    if (v44)
    {
      uint64_t v10 = (void *)(a1 + 24);
      uint64_t v11 = (void *)(a1 + 104);
      do
      {
        uint64_t v40 = 0;
        uint64_t v41 = 0;
        uint64_t v39 = (uint64_t *)&v40;
        BOOL v12 = v42;
        if (v42 != (uint64_t *)&v43)
        {
          while (1)
          {
            uint64_t v38 = (unint64_t *)v12[4];
            if (!std::__hash_table<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::__unordered_map_hasher<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::__unordered_map_equal<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>>>::find<std::reference_wrapper<ZinIrOpLayer * const>>(v45, &v38))
            {
              if (a3 + 1 == (void *)std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>((uint64_t)a3, (ZinIrOpLayer **)v38))
              {
                BOOL v47 = (uint64_t *)v38;
                int v15 = std::__hash_table<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::__unordered_map_hasher<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::__unordered_map_equal<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>>>::find<std::reference_wrapper<ZinIrOpLayer * const>>(v10, (unint64_t **)&v47);
                char v16 = v15 + 3;
                if (!v15) {
                  char v16 = v11;
                }
                if (v16[1] == *v16)
                {
                  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v39, v40);
                  BOOL v34 = 0;
                  goto LABEL_48;
                }
                BOOL v47 = (uint64_t *)v38;
                uint64_t v17 = std::__hash_table<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::__unordered_map_hasher<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::__unordered_map_equal<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>>>::find<std::reference_wrapper<ZinIrOpLayer * const>>(v10, (unint64_t **)&v47);
                uint64_t v18 = (uint64_t ***)(v17 + 3);
                if (!v17) {
                  uint64_t v18 = (uint64_t ***)v11;
                }
                long long v20 = *v18;
                BOOL v19 = v18[1];
                while (v20 != v19)
                {
                  BOOL v47 = *v20;
                  if (!std::__hash_table<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::__unordered_map_hasher<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::__unordered_map_equal<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>>>::find<std::reference_wrapper<ZinIrOpLayer * const>>(v45, (unint64_t **)&v47))std::__tree<std::reference_wrapper<ZinIrOpLayer * const>,ZinIrIdComparator<ZinIrOpLayer *>,std::allocator<std::reference_wrapper<ZinIrOpLayer * const>>>::__emplace_unique_key_args<std::reference_wrapper<ZinIrOpLayer * const>,std::reference_wrapper<ZinIrOpLayer * const>>(&v39, &v47, (uint64_t *)&v47); {
                  ++v20;
                  }
                }
              }
              std::__hash_table<std::reference_wrapper<ZinIrOpLayer * const>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,std::allocator<std::reference_wrapper<ZinIrOpLayer * const>>>::__emplace_unique_key_args<std::reference_wrapper<ZinIrOpLayer * const>,std::reference_wrapper<ZinIrOpLayer * const> const&>((uint64_t)v45, &v38, &v38);
            }
            uint64_t v13 = (uint64_t *)v12[1];
            if (v13)
            {
              do
              {
                unint64_t v14 = v13;
                uint64_t v13 = (uint64_t *)*v13;
              }
              while (v13);
            }
            else
            {
              do
              {
                unint64_t v14 = (uint64_t *)v12[2];
                BOOL v9 = *v14 == (void)v12;
                BOOL v12 = v14;
              }
              while (!v9);
            }
            BOOL v12 = v14;
            if (v14 == (uint64_t *)&v43)
            {
              uint64_t v21 = v41;
              BOOL v22 = v42;
              uint64_t v24 = v39;
              unint64_t v23 = v40;
              goto LABEL_32;
            }
          }
        }
        uint64_t v21 = 0;
        unint64_t v23 = 0;
        uint64_t v24 = (uint64_t *)&v40;
        BOOL v22 = (uint64_t *)&v43;
LABEL_32:
        long long v25 = v43;
        uint64_t v26 = v44;
        BOOL v42 = v24;
        unint64_t v43 = v23;
        uint64_t v39 = v22;
        uint64_t v40 = v25;
        uint64_t v44 = v21;
        uint64_t v41 = v26;
        uint64_t v27 = (uint64_t **)(v23 + 2);
        BOOL v9 = v21 == 0;
        unint64_t v28 = &v42;
        if (!v9) {
          unint64_t v28 = v27;
        }
        *unint64_t v28 = (uint64_t *)&v43;
        uint64_t v29 = (uint64_t **)(v25 + 2);
        if (!v26) {
          uint64_t v29 = &v39;
        }
        *uint64_t v29 = (uint64_t *)&v40;
        std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v39, v25);
      }
      while (v44);
    }
  }
  BOOL v32 = (void *)*a3;
  unint64_t v30 = a3 + 1;
  unint64_t v31 = v32;
  if (v32 == v30)
  {
    BOOL v34 = 1;
  }
  else
  {
    do
    {
      uint64_t v39 = v31 + 4;
      uint64_t v33 = std::__hash_table<std::__hash_value_type<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::vector<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>,std::__unordered_map_hasher<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::__hash_value_type<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::vector<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>,std::hash<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,std::equal_to<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,true>,std::__unordered_map_equal<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::__hash_value_type<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::vector<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>,std::equal_to<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,std::hash<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::vector<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>>>::find<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>(v45, (unint64_t **)&v39);
      BOOL v34 = v33 != 0;
      if (!v33) {
        break;
      }
      int v35 = (void *)v31[1];
      if (v35)
      {
        do
        {
          uint64_t v36 = v35;
          int v35 = (void *)*v35;
        }
        while (v35);
      }
      else
      {
        do
        {
          uint64_t v36 = (void *)v31[2];
          BOOL v9 = *v36 == (void)v31;
          unint64_t v31 = v36;
        }
        while (!v9);
      }
      unint64_t v31 = v36;
    }
    while (v36 != v30);
  }
LABEL_48:
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v42, v43);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v45);
  return v34;
}

void sub_2112923E0(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, ...)
{
  va_start(va2, a3);
  va_start(va1, a3);
  va_start(va, a3);
  uint64_t v4 = va_arg(va1, void);
  unint64_t v6 = va_arg(va1, void *);
  uint64_t v7 = va_arg(va1, void);
  va_copy(va2, va1);
  uint64_t v8 = va_arg(va2, void);
  uint64_t v10 = va_arg(va2, void *);
  uint64_t v11 = va_arg(va2, void);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)va, v6);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)va1, v10);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)va2);
  _Unwind_Resume(a1);
}

void PressureBasedSubgraphIdentification::RemovePureInOutNodes(PressureBasedSubgraphIdentification *this, uint64_t **a2)
{
  uint64_t v29 = 0;
  unint64_t v30 = 0;
  unint64_t v31 = 0;
  uint64_t v2 = (uint64_t *)(a2 + 1);
  uint64_t v3 = *a2;
  if (*a2 != (uint64_t *)(a2 + 1))
  {
    char v5 = a2 + 3;
    unint64_t v6 = a2 + 9;
    do
    {
      unint64_t v28 = (ZinIrOpLayer ***)v3[4];
      if (std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)v5, (ZinIrOpLayer **)&v28))
      {
        uint64_t v7 = (ZinIrOpLayer *)v28;
        uint64_t v8 = v28[14];
        BOOL v9 = v28[15];
        if (v8 == v9)
        {
LABEL_8:
          uint64_t v10 = (ZinIrOpLayer **)*((void *)v7 + 11);
          uint64_t v11 = (ZinIrOpLayer **)*((void *)v7 + 12);
          while (v10 != v11)
          {
            uint64_t v27 = 0;
            uint64_t v27 = *v10;
            if (std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)v6, &v27))
            {
              goto LABEL_29;
            }
            ++v10;
          }
          BOOL v12 = v30;
          if (v30 >= v31)
          {
            uint64_t v14 = (v30 - v29) >> 3;
            if ((unint64_t)(v14 + 1) >> 61) {
              std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
            }
            unint64_t v15 = (v31 - v29) >> 2;
            if (v15 <= v14 + 1) {
              unint64_t v15 = v14 + 1;
            }
            if ((unint64_t)(v31 - v29) >= 0x7FFFFFFFFFFFFFF8) {
              unint64_t v16 = 0x1FFFFFFFFFFFFFFFLL;
            }
            else {
              unint64_t v16 = v15;
            }
            if (v16) {
              uint64_t v17 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)&v31, v16);
            }
            else {
              uint64_t v17 = 0;
            }
            uint64_t v18 = (ZinIrOpLayer ****)&v17[8 * v14];
            uint64_t *v18 = v28;
            uint64_t v13 = (char *)(v18 + 1);
            long long v20 = v29;
            BOOL v19 = v30;
            if (v30 != v29)
            {
              do
              {
                uint64_t v21 = (ZinIrOpLayer ***)*((void *)v19 - 1);
                v19 -= 8;
                *--uint64_t v18 = v21;
              }
              while (v19 != v20);
              BOOL v19 = v29;
            }
            uint64_t v29 = (char *)v18;
            unint64_t v30 = v13;
            unint64_t v31 = &v17[8 * v16];
            if (v19) {
              operator delete(v19);
            }
          }
          else
          {
            *(void *)unint64_t v30 = v28;
            uint64_t v13 = v12 + 8;
          }
          unint64_t v30 = v13;
        }
        else
        {
          while (1)
          {
            uint64_t v27 = 0;
            uint64_t v27 = *v8;
            if (std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)v6, &v27))
            {
              break;
            }
            if (++v8 == v9)
            {
              uint64_t v7 = (ZinIrOpLayer *)v28;
              goto LABEL_8;
            }
          }
        }
      }
LABEL_29:
      BOOL v22 = (uint64_t *)v3[1];
      if (v22)
      {
        do
        {
          unint64_t v23 = v22;
          BOOL v22 = (uint64_t *)*v22;
        }
        while (v22);
      }
      else
      {
        do
        {
          unint64_t v23 = (uint64_t *)v3[2];
          BOOL v24 = *v23 == (void)v3;
          uint64_t v3 = v23;
        }
        while (!v24);
      }
      uint64_t v3 = v23;
    }
    while (v23 != v2);
    uint64_t v26 = (ZinIrOpLayer **)v29;
    long long v25 = (ZinIrOpLayer **)v30;
    if (v29 != v30)
    {
      do
      {
        unint64_t v28 = (ZinIrOpLayer ***)*v26;
        std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__erase_unique<ZinIrOpLayer *>(v6, (ZinIrOpLayer **)&v28);
        std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__erase_unique<ZinIrOpLayer *>(a2, (ZinIrOpLayer **)&v28);
        std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__erase_unique<ZinIrOpLayer *>(v5, (ZinIrOpLayer **)&v28);
        ++v26;
      }
      while (v26 != v25);
      long long v25 = (ZinIrOpLayer **)v29;
    }
    if (v25)
    {
      unint64_t v30 = (char *)v25;
      operator delete(v25);
    }
  }
}

void sub_21129265C(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, void *__p, uint64_t a13)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

void PressureBasedSubgraphIdentification::DropPureInputConcats(PressureBasedSubgraphIdentification *this, uint64_t **a2)
{
  v23[0] = 0;
  v23[1] = 0;
  BOOL v22 = (uint64_t *)v23;
  uint64_t v2 = (uint64_t *)(a2 + 1);
  uint64_t v3 = *a2;
  if (*a2 != (uint64_t *)(a2 + 1))
  {
    char v5 = a2 + 9;
    unint64_t v6 = (char *)(a2 + 10);
    do
    {
      uint64_t v7 = v3[4];
      uint64_t v21 = (ZinIrOpLayer *)v7;
      if (*(_DWORD *)(*(void *)(v7 + 64) + 8) == 7)
      {
        std::string __p = 0;
        BOOL v19 = 0;
        uint64_t v20 = 0;
        std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(&__p, *(const void **)(v7 + 88), *(void *)(v7 + 96), (uint64_t)(*(void *)(v7 + 96) - *(void *)(v7 + 88)) >> 3);
        uint64_t v8 = (ZinIrOpLayer **)__p;
        BOOL v9 = v19;
        while (v8 != v9)
        {
          BOOL v24 = *v8;
          if (v6 != (char *)std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>((uint64_t)v5, &v24))goto LABEL_9; {
          ++v8;
          }
        }
        std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>(&v22, &v21, (uint64_t *)&v21);
LABEL_9:
        if (__p)
        {
          BOOL v19 = (ZinIrOpLayer **)__p;
          operator delete(__p);
        }
      }
      uint64_t v10 = (uint64_t *)v3[1];
      if (v10)
      {
        do
        {
          uint64_t v11 = v10;
          uint64_t v10 = (uint64_t *)*v10;
        }
        while (v10);
      }
      else
      {
        do
        {
          uint64_t v11 = (uint64_t *)v3[2];
          BOOL v12 = *v11 == (void)v3;
          uint64_t v3 = v11;
        }
        while (!v12);
      }
      uint64_t v3 = v11;
    }
    while (v11 != v2);
    uint64_t v13 = v22;
    if (v22 != (uint64_t *)v23)
    {
      do
      {
        std::string __p = (void *)v13[4];
        std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__erase_unique<ZinIrOpLayer *>(a2, (ZinIrOpLayer **)&__p);
        std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__erase_unique<ZinIrOpLayer *>(v5, (ZinIrOpLayer **)&__p);
        std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__erase_unique<ZinIrOpLayer *>(a2 + 3, (ZinIrOpLayer **)&__p);
        uint64_t v14 = (ZinIrOpLayer **)*((void *)__p + 14);
        unint64_t v15 = (ZinIrOpLayer **)*((void *)__p + 15);
        while (v14 != v15)
        {
          BOOL v24 = 0;
          BOOL v24 = *v14;
          if (std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)v5, &v24))
          {
            std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>(a2, &v24, (uint64_t *)&v24);
          }
          ++v14;
        }
        unint64_t v16 = (uint64_t *)v13[1];
        if (v16)
        {
          do
          {
            uint64_t v17 = v16;
            unint64_t v16 = (uint64_t *)*v16;
          }
          while (v16);
        }
        else
        {
          do
          {
            uint64_t v17 = (uint64_t *)v13[2];
            BOOL v12 = *v17 == (void)v13;
            uint64_t v13 = v17;
          }
          while (!v12);
        }
        uint64_t v13 = v17;
      }
      while (v17 != (uint64_t *)v23);
    }
  }
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v22, v23[0]);
}

void sub_211292874(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, void *__p, uint64_t a10, uint64_t a11, uint64_t a12, char a13, void *a14)
{
  if (__p) {
    operator delete(__p);
  }
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&a13, a14);
  _Unwind_Resume(a1);
}

void PressureBasedSubgraphIdentification::ConstructSubGraph(SubgraphIdentification *a1, uint64_t a2, uint64_t a3, uint64_t **a4)
{
  uint64_t v8 = *(void *)(a3 + 16);
  do
  {
    PressureBasedSubgraphIdentification::RemoveInputNodeDrivingBothExternalAndInternalNodes((uint64_t)a1, a2, (uint64_t **)a3);
    PressureBasedSubgraphIdentification::RemoveIllegalInternalNodes((uint64_t)a1, (uint64_t **)a3);
    BOOL v9 = *(void *)(a3 + 16) == v8;
    uint64_t v8 = *(void *)(a3 + 16);
  }
  while (!v9);
  PressureBasedSubgraphIdentification::IdentifyInputOutputNodes((uint64_t)a1, (void *)a3, a4);
  Subgraph = (PressureBasedSubgraphIdentification *)SubgraphIdentification::ExtractSubgraph(a1, (Subgraph *)a4);
  PressureBasedSubgraphIdentification::DropPureInputConcats(Subgraph, a4);

  PressureBasedSubgraphIdentification::RemovePureInOutNodes(v11, a4);
}

uint64_t PressureBasedSubgraphIdentification::EstimateKernelReadsPerNE(ZinEngineLayerMirInfo **this, const ZinNELayer *a2, const ZinIrHalParameters *a3)
{
  (*((void (**)(ZinIrKernel **__return_ptr))*this + 71))(&v25);
  unint64_t v6 = v25;
  if (!v25) {
    return 0;
  }
  uint64_t v7 = (_DWORD *)((char *)v25 + 176);
  unint64_t v8 = ZinKernelSizeEstimateUtil::EstimateKMEMFootprintPerCoutElement((ZinIrKernel *)((char *)v25 + 176), v5);
  BOOL v9 = this[33];
  if (v9)
  {
    ChannelAssignment = (MirInfoChannelAssignment *)ZinEngineLayerMirInfo::GetChannelAssignment(v9);
    OCGuint64_t Size = MirInfoChannelAssignment::GetOCGSize(ChannelAssignment);
    BOOL v12 = (MirInfoChannelAssignment *)ZinEngineLayerMirInfo::GetChannelAssignment(this[33]);
    unint64_t NumNeededNEs = MirInfoChannelAssignment::GetNumNeededNEs(v12);
    if ((*v7 - 7) > 0x14)
    {
      unint64_t v14 = 1;
    }
    else
    {
      unint64_t v14 = *((void *)v6 + 52);
      if (OCGSize % v14) {
        ZinAssertImpl("OCG size must be a multiple of palette_vector_size.");
      }
    }
    unint64_t v16 = (*((uint64_t (**)(ZinEngineLayerMirInfo **, uint64_t))*this + 46))(this, 2);
    ZinChannelAssignment::ZinChannelAssignment((ZinChannelAssignment *)v22, NumNeededNEs, OCGSize, v16, 1uLL);
    if (v24 == 0) {
      uint64_t v17 = v23;
    }
    else {
      uint64_t v17 = v23 + 1;
    }
    uint64_t v18 = this[49];
    if (v18) {
      BOOL v19 = *((_DWORD *)v18 + 48) > 1u;
    }
    else {
      BOOL v19 = 0;
    }
    uint64_t v15 = ZinKernelGetLUTSize(a2, v19) + OCGSize / v14 * v8 * v17;
  }
  else
  {
    uint64_t v15 = 0;
  }
  uint64_t v20 = v25;
  long long v25 = 0;
  if (v20)
  {
    ZinIrKernel::~ZinIrKernel(v20);
    MEMORY[0x21667D3C0]();
  }
  return v15;
}

void sub_211292B00(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, ...)
{
  va_start(va, a10);
  std::unique_ptr<ZinIrKernel>::reset[abi:ne180100]((ZinIrKernel **)va, 0);
  _Unwind_Resume(a1);
}

uint64_t PressureBasedSubgraphIdentification::EstimateSizeOfKernelReads(uint64_t a1, uint64_t a2, uint64_t a3, char a4)
{
  uint64_t v7 = *(void **)(a1 + 72);
  unint64_t v8 = (void *)(a1 + 80);
  if (v7 == (void *)(a1 + 80))
  {
    unint64_t v9 = 0;
    if (a4) {
      return v9;
    }
    goto LABEL_14;
  }
  unint64_t v9 = 0;
  do
  {
    uint64_t v10 = (ZinEngineLayerMirInfo **)v7[4];
    if (ZinIrOpLayer::IsNELayer((ZinIrOpLayer *)v10)) {
      v9 += PressureBasedSubgraphIdentification::EstimateKernelReadsPerNE(v10, (const ZinNELayer *)a3, v11);
    }
    BOOL v12 = (void *)v7[1];
    if (v12)
    {
      do
      {
        uint64_t v13 = v12;
        BOOL v12 = (void *)*v12;
      }
      while (v12);
    }
    else
    {
      do
      {
        uint64_t v13 = (void *)v7[2];
        BOOL v14 = *v13 == (void)v7;
        uint64_t v7 = v13;
      }
      while (!v14);
    }
    uint64_t v7 = v13;
  }
  while (v13 != v8);
  if ((a4 & 1) == 0)
  {
LABEL_14:
    unint64_t v15 = *(void *)(a3 + 480);
    uint64_t v16 = v9 * *(int *)(a3 + 8);
    BOOL v17 = v9 >= v15;
    unint64_t v9 = v16;
    if (v17)
    {
      int v21 = 3;
      uint64_t v18 = v16 * *std::map<ZinIrDimension,unsigned long>::at(a2, &v21);
      int v20 = 4;
      return v18 * *std::map<ZinIrDimension,unsigned long>::at(a2, &v20);
    }
  }
  return v9;
}

BOOL PressureBasedSubgraphIdentification::IsMemoryFootprintReduced(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v3 = a3;
  uint64_t v5 = a1;
  uint64_t v45 = *MEMORY[0x263EF8340];
  memset(v38, 0, sizeof(v38));
  int v39 = 1065353216;
  uint64_t v7 = a2 + 72;
  unint64_t v6 = *(void **)(a2 + 72);
  unint64_t v8 = (void *)(a2 + 80);
  if (v6 == (void *)(a2 + 80))
  {
    unint64_t v9 = 0;
  }
  else
  {
    unint64_t v9 = 0;
    uint64_t v10 = a2 + 32;
    uint64_t v28 = a2 + 8;
    do
    {
      uint64_t v11 = v6[4];
      uint64_t v37 = 0;
      BOOL v12 = (ZinIrTensor *)(*(uint64_t (**)(uint64_t, void, void))(*(void *)v11 + 32))(v11, 0, 0);
      RootTensor = ZinIrTensor::GetRootTensor(v12);
      uint64_t v36 = (ZinIrOpLayer *)*((void *)RootTensor + 12);
      uint64_t v37 = RootTensor;
      if (v8 != (void *)std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>(v7, &v36)&& v10 == std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>(a2 + 24, &v36)&& !std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(v38, &v37)&& ZinMirSpatialSplitUtils::IsNonResident(v37, *(void **)(v5 + 112)))
      {
        BOOL v14 = v37;
        DimensionOrderHint::DimensionOrderHint(__p, 0);
        ZinIrTensor::GetTensorSizeInBytesFromResidency(v14, 2, (uint64_t)__p, 0);
        unint64_t v16 = v15;
        if (__p[0])
        {
          __p[1] = __p[0];
          operator delete(__p[0]);
        }
        unint64_t v31 = v9;
        if (*(_DWORD *)(*((void *)v36 + 8) + 8) == 7
          && v28 != std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>(a2, &v36))
        {
          uint64_t v18 = (ZinIrOpLayer **)*((void *)v36 + 11);
          BOOL v17 = (ZinIrOpLayer **)*((void *)v36 + 12);
          while (v18 != v17)
          {
            int v35 = 0;
            int v35 = *v18;
            if (v8 == (void *)std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>(v7, &v35))
            {
              BOOL v19 = (ZinIrTensor *)(*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)v35 + 32))(v35, 0, 0);
              DimensionOrderHint::DimensionOrderHint(__p, 0);
              ZinIrTensor::GetTensorSizeInBytesFromResidency(v19, 2, (uint64_t)__p, 0);
              unint64_t v21 = v20;
              if (__p[0])
              {
                __p[1] = __p[0];
                operator delete(__p[0]);
              }
              if (v16 >= v21) {
                v16 -= v21;
              }
              else {
                unint64_t v16 = 0;
              }
            }
            ++v18;
          }
        }
        std::__hash_table<ZinIrTensor const*,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const* const&>((uint64_t)v38, &v37, &v37);
        uint64_t v5 = a1;
        uint64_t v3 = a3;
        unint64_t v9 = v31 + 2 * v16;
      }
      BOOL v22 = (void *)v6[1];
      if (v22)
      {
        do
        {
          uint64_t v23 = v22;
          BOOL v22 = (void *)*v22;
        }
        while (v22);
      }
      else
      {
        do
        {
          uint64_t v23 = (void *)v6[2];
          BOOL v24 = *v23 == (void)v6;
          unint64_t v6 = v23;
        }
        while (!v24);
      }
      unint64_t v6 = v23;
    }
    while (v23 != v8);
  }
  std::map<ZinIrDimension,unsigned long>::map[abi:ne180100](v34, v3);
  uint64_t v25 = PressureBasedSubgraphIdentification::EstimateSizeOfKernelReads(a2, (uint64_t)v34, **(void **)(v5 + 16), 0);
  long long v41 = unk_211F000E8;
  long long v42 = xmmword_211F000F8;
  long long v43 = unk_211F00108;
  long long v44 = xmmword_211F00118;
  *(_OWORD *)std::string __p = xmmword_211F000D8;
  std::map<ZinIrDimension,unsigned long>::map[abi:ne180100]((uint64_t)v32, (int *)__p, 5);
  unint64_t v26 = v25
      - PressureBasedSubgraphIdentification::EstimateSizeOfKernelReads(a2, (uint64_t)v32, **(void **)(v5 + 16), 0);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v32, v33);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v34, (void *)v34[1]);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v38);
  return v26 < v9;
}

void sub_211292F98(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, char a14, uint64_t a15, uint64_t a16, char a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,char a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,void *__p,uint64_t a30)
{
  if (__p)
  {
    a30 = (uint64_t)__p;
    operator delete(__p);
  }
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&a23);
  _Unwind_Resume(a1);
}

uint64_t PressureBasedSubgraphIdentification::ConstructValidSubgraphsFromCluster(uint64_t a1, ZinIrOpLayerGraph *a2, void *a3, uint64_t *a4, char a5)
{
  uint64_t v66 = *MEMORY[0x263EF8340];
  uint64_t v10 = a3 + 1;
  uint64_t v11 = (void *)*a3;
  if ((void *)*a3 == a3 + 1) {
    goto LABEL_77;
  }
  uint64_t v12 = 0;
  do
  {
    BOOL IsANELayer = ZinIrOpLayer::IsANELayer((ZinIrOpLayer *)v11[4]);
    BOOL v14 = (void *)v11[1];
    if (v14)
    {
      do
      {
        unint64_t v15 = v14;
        BOOL v14 = (void *)*v14;
      }
      while (v14);
    }
    else
    {
      do
      {
        unint64_t v15 = (void *)v11[2];
        BOOL v16 = *v15 == (void)v11;
        uint64_t v11 = v15;
      }
      while (!v16);
    }
    v12 += IsANELayer;
    uint64_t v11 = v15;
  }
  while (v15 != v10);
  if (v12 != 1)
  {
LABEL_77:
    if (*(unsigned char *)(a1 + 73))
    {
      uint64_t v18 = PressureBasedSubgraphIdentification::ComputeTimeSpanOfCluster(a3);
      uint64_t v20 = v19;
      if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_INFO))
      {
        *(_DWORD *)long long buf = 134218240;
        *(void *)&void buf[4] = v18;
        *(_WORD *)&unsigned char buf[12] = 2048;
        *(void *)&buf[14] = v20;
        _os_log_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_INFO, "\tConstructing Subgraph for Cluster [%zu,%zu]", buf, 0x16u);
      }
    }
    *(void *)long long buf = &buf[8];
    *(_OWORD *)&uint8_t buf[8] = 0uLL;
    v57[0] = 0;
    v57[1] = 0;
    uint64_t v56 = v57;
    v58[0] = v58;
    v58[1] = v58;
    std::string::size_type v60 = 0;
    unint64_t v61 = 0;
    v58[2] = 0;
    unint64_t v59 = &v60;
    memset(v62, 0, sizeof(v62));
    v64[0] = 0;
    v64[1] = 0;
    long long v63 = (uint64_t *)v64;
    char v65 = 0;
    PressureBasedSubgraphIdentification::ConstructSubGraph((SubgraphIdentification *)a1, (uint64_t)a2, (uint64_t)a3, (uint64_t **)buf);
    if (v61 <= 1)
    {
      if (!*(unsigned char *)(a1 + 73) || !os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_INFO)) {
        goto LABEL_35;
      }
      *(_WORD *)unint64_t v49 = 0;
      unint64_t v21 = &_os_log_internal;
      BOOL v22 = "\t\tToo small of subgraph found";
      goto LABEL_34;
    }
    if (!ZinIrNgraph<ZinIrOpLayer *,ZinIrIdComparator<ZinIrOpLayer *>>::IsDominanceRelationship<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>((uint64_t)a2, buf, &v56))
    {
      if (!*(unsigned char *)(a1 + 73) || !os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_INFO)) {
        goto LABEL_35;
      }
      *(_WORD *)unint64_t v49 = 0;
      unint64_t v21 = &_os_log_internal;
      BOOL v22 = "\t\tIllegal Dominance Relationship";
LABEL_34:
      _os_log_impl(&dword_210C72000, v21, OS_LOG_TYPE_INFO, v22, v49, 2u);
      goto LABEL_35;
    }
    uint64_t v23 = v59;
    if (v59 != &v60)
    {
      while (!*(unsigned char *)((*(uint64_t (**)(void *, void, void))(*v23[4] + 32))(v23[4], 0, 0) + 144))
      {
        BOOL v24 = v23[1];
        if (v24)
        {
          do
          {
            uint64_t v25 = (void **)v24;
            BOOL v24 = (void *)*v24;
          }
          while (v24);
        }
        else
        {
          do
          {
            uint64_t v25 = (void **)v23[2];
            BOOL v16 = *v25 == v23;
            uint64_t v23 = v25;
          }
          while (!v16);
        }
        uint64_t v23 = v25;
        if (v25 == &v60) {
          goto LABEL_27;
        }
      }
      goto LABEL_35;
    }
LABEL_27:
    if (!(*(unsigned int (**)(uint64_t, unsigned char *))(*(void *)a1 + 64))(a1, buf))
    {
LABEL_35:
      uint64_t v17 = 0;
LABEL_36:
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v63, v64[0]);
      *(void *)unint64_t v49 = v62;
      std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100]((void ***)v49);
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v59, v60);
      std::__list_imp<ZinIrSection *>::clear(v58);
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v56, v57[0]);
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)buf, *(void **)&buf[8]);
      return v17;
    }
    v50[0] = 0;
    v50[1] = 0;
    uint64_t v48 = 0;
    *(void *)unint64_t v49 = v50;
    int v51 = 5;
    std::string __p = 0;
    BOOL v47 = 0;
    unint64_t v45 = 0;
    if (((*(uint64_t (**)(uint64_t, unsigned char *, uint8_t *))(*(void *)a1 + 240))(a1, buf, v49) & 1) == 0)
    {
      if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_INFO))
      {
        *(_WORD *)BOOL v52 = 0;
        _os_log_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_INFO, "\t\tLegalizing Cluster Due to no legal split dimension found", v52, 2u);
      }
      uint64_t v27 = PressureBasedSubgraphIdentification::LegalizeCluster((void *)a1, a2, (uint64_t)&v59, (uint64_t)a4);
      goto LABEL_41;
    }
    if ((*(uint64_t (**)(uint64_t, unsigned char *, uint8_t *, uint64_t *))(*(void *)a1 + 56))(a1, buf, v49, a4))
    {
LABEL_30:
      uint64_t v17 = 0;
      goto LABEL_44;
    }
    if (PressureBasedSubgraphIdentification::ComputeTileSize(a1, buf, *(void *)(a1 + 104), (uint64_t)v49, &__p, &v45))
    {
      uint64_t v17 = 1;
LABEL_44:
      uint64_t v28 = __p;
      if (!__p)
      {
LABEL_46:
        std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v49, v50[0]);
        goto LABEL_36;
      }
LABEL_45:
      BOOL v47 = v28;
      operator delete(v28);
      goto LABEL_46;
    }
    unint64_t v29 = v45;
    if (v45 <= 1 && __p == v47)
    {
      if (*(unsigned char *)(a1 + 73) && os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_INFO))
      {
        *(_WORD *)BOOL v52 = 0;
        _os_log_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_INFO, "\t\tUnnecessary to tile subgraph", v52, 2u);
      }
      goto LABEL_30;
    }
    if (*(unsigned char *)(*(void *)(a1 + 64) + 2))
    {
      uint64_t v28 = __p;
      if (__p != v47)
      {
        uint64_t v17 = 1;
        if (!__p) {
          goto LABEL_46;
        }
        goto LABEL_45;
      }
    }
    (*(void (**)(uint64_t, unsigned char *, unint64_t, uint8_t *))(*(void *)a1 + 136))(a1, buf, v45, v49);
    unint64_t v30 = *(unsigned char **)(a1 + 64);
    BOOL v31 = *v30 || v30[1] || v30[5] != 0;
    BOOL v42 = v31;
    char v43 = (*(uint64_t (**)(uint64_t, unsigned char *, unint64_t))(*(void *)a1 + 144))(a1, buf, v29);
    unsigned __int8 v32 = (*(uint64_t (**)(uint64_t, unsigned char *))(*(void *)a1 + 64))(a1, buf);
    BOOL v34 = __p;
    uint64_t v33 = v47;
    if (((__p == v47) & ~(v43 & a5) & v32) == 0 && v42)
    {
      if (*(unsigned char *)(a1 + 73))
      {
        uint64_t v35 = PressureBasedSubgraphIdentification::ComputeTimeSpanOfCluster(a3);
        uint64_t v37 = v36;
        if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_INFO))
        {
          *(_DWORD *)BOOL v52 = 134218240;
          *(void *)&v52[4] = v35;
          __int16 v53 = 2048;
          uint64_t v54 = v37;
          _os_log_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_INFO, "\tLegalizing Cluster [%zu,%zu] due to high pressure", v52, 0x16u);
        }
      }
      goto LABEL_70;
    }
    if (*(unsigned char *)(*(void *)(a1 + 64) + 5))
    {
      std::map<ZinIrDimension,unsigned long>::map[abi:ne180100](v44, v62[0]);
      BOOL IsMemoryFootprintReduced = PressureBasedSubgraphIdentification::IsMemoryFootprintReduced(a1, (uint64_t)buf, (uint64_t)v44);
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v44, (void *)v44[1]);
      if (!IsMemoryFootprintReduced)
      {
LABEL_70:
        uint64_t v27 = PressureBasedSubgraphIdentification::LegalizeCluster((void *)a1, a2, (uint64_t)&v59, (uint64_t)a4);
LABEL_41:
        uint64_t v17 = v27;
        goto LABEL_44;
      }
      BOOL v34 = __p;
      uint64_t v33 = v47;
    }
    while (v34 != v33)
    {
      *(void *)BOOL v52 = *v34;
      std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>(&v63, (ZinIrOpLayer **)v52, (uint64_t *)v52);
      ++v34;
    }
    if (*(unsigned char *)(a1 + 73))
    {
      uint64_t v39 = PressureBasedSubgraphIdentification::ComputeTimeSpanOfCluster(a3);
      uint64_t v41 = v40;
      if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_INFO))
      {
        *(_DWORD *)BOOL v52 = 134218240;
        *(void *)&v52[4] = v39;
        __int16 v53 = 2048;
        uint64_t v54 = v41;
        _os_log_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_INFO, "\tTile Count Found for Cluster [%zu,%zu]", v52, 0x16u);
      }
    }
    std::__list_imp<ZinIrSection *>::clear(v58);
    std::vector<Subgraph>::push_back[abi:ne180100](a4, (const Subgraph *)buf);
    goto LABEL_30;
  }
  return 0;
}

void sub_21129378C(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, char a12, void *a13, uint64_t a14, uint64_t a15, void *__p, uint64_t a17, uint64_t a18, char a19, void *a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,char a27)
{
  if (__p)
  {
    a17 = (uint64_t)__p;
    operator delete(__p);
  }
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&a19, a20);
  Subgraph::~Subgraph((Subgraph *)&a27);
  _Unwind_Resume(a1);
}

uint64_t PressureBasedSubgraphIdentification::LegalizeCluster(void *a1, ZinIrOpLayerGraph *a2, uint64_t a3, uint64_t a4)
{
  if (*(void *)(a3 + 16) == 1) {
    return 0;
  }
  long long v25 = 0uLL;
  unint64_t v26 = 0;
  if ((*(unsigned int (**)(void *, uint64_t))(*a1 + 248))(a1, a3))
  {
    (*(void (**)(long long *__return_ptr, void *, uint64_t))(*a1 + 256))(&v23, a1, a3);
    std::vector<std::map<ZinIrDimension,unsigned long>>::__vdeallocate((void **)&v25);
    long long v25 = v23;
    unint64_t v26 = v24;
    unint64_t v24 = 0;
    long long v23 = 0uLL;
    v22[0] = (void **)&v23;
    std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100](v22);
  }
  else
  {
    memset(v22, 0, sizeof(v22));
    PressureBasedSubgraphIdentification::SplitClusterViaCostModel(a1, a2, a3, v22, (uint64_t *)&v23);
    std::vector<std::map<ZinIrDimension,unsigned long>>::__vdeallocate((void **)&v25);
    long long v25 = v23;
    unint64_t v26 = v24;
    unint64_t v24 = 0;
    long long v23 = 0uLL;
    uint64_t v27 = (void ***)&v23;
    std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v27);
    uint64_t v27 = v22;
    std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v27);
  }
  unint64_t v9 = (ZinIrOpLayer ***)*((void *)&v25 + 1);
  uint64_t v10 = (ZinIrOpLayer ***)v25;
  if (*((void *)&v25 + 1) == (void)v25) {
    goto LABEL_27;
  }
  do
  {
    std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::set[abi:ne180100]((uint64_t *)&v23, v10);
    if (v24 >= *(void *)(a3 + 16)) {
      ZinAssertImpl("Splitted cluster must be smaller than the original cluster.");
    }
    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v23, *((void **)&v23 + 1));
    v10 += 3;
  }
  while (v10 != v9);
  uint64_t v12 = (ZinIrOpLayer ***)*((void *)&v25 + 1);
  uint64_t v11 = (ZinIrOpLayer ***)v25;
  do
  {
    unint64_t v13 = 0;
    uint64_t v14 = (char *)v12 - (char *)v11;
    if (v12 == v11)
    {
      unint64_t v15 = v11;
    }
    else
    {
      do
      {
        std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::set[abi:ne180100]((uint64_t *)&v23, v11);
        v13 += v24;
        std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v23, *((void **)&v23 + 1));
        v11 += 3;
      }
      while (v11 != v12);
      uint64_t v11 = (ZinIrOpLayer ***)*((void *)&v25 + 1);
      unint64_t v15 = (ZinIrOpLayer ***)v25;
    }
    memset(v21, 0, sizeof(v21));
    std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::__init_with_size[abi:ne180100]<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>((uint64_t *)v21, v15, v11, 0xAAAAAAAAAAAAAAABLL * (v11 - v15));
    PressureBasedSubgraphIdentification::CutClustersAtPartialOutputs((uint64_t)a1, v21, (uint64_t)&v25);
    *(void *)&long long v23 = v21;
    std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v23);
    PressureBasedSubgraphIdentification::RemoveInputAndOutputNoopsOfClusters(a1, (ZinIrOpLayer ****)&v25, (uint64_t *)&v23);
    std::vector<std::map<ZinIrDimension,unsigned long>>::__vdeallocate((void **)&v25);
    long long v25 = v23;
    unint64_t v26 = v24;
    unint64_t v24 = 0;
    long long v23 = 0uLL;
    v22[0] = (void **)&v23;
    std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100](v22);
    BOOL v16 = (ZinIrOpLayer ***)*((void *)&v25 + 1);
    uint64_t v11 = (ZinIrOpLayer ***)v25;
    if ((void)v25 == *((void *)&v25 + 1))
    {
      unint64_t v17 = 0;
      uint64_t v12 = (ZinIrOpLayer ***)v25;
    }
    else
    {
      unint64_t v17 = 0;
      do
      {
        std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::set[abi:ne180100]((uint64_t *)&v23, v11);
        v17 += v24;
        std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v23, *((void **)&v23 + 1));
        v11 += 3;
      }
      while (v11 != v16);
      uint64_t v12 = (ZinIrOpLayer ***)*((void *)&v25 + 1);
      uint64_t v11 = (ZinIrOpLayer ***)v25;
    }
  }
  while (0xAAAAAAAAAAAAAAABLL * (v14 >> 3) < 0xAAAAAAAAAAAAAAABLL * (v12 - v11) || v17 < v13);
  if (v11 == v12)
  {
LABEL_27:
    uint64_t v4 = 0;
  }
  else
  {
    while (1)
    {
      std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::set[abi:ne180100]((uint64_t *)&v23, v11);
      int valid = PressureBasedSubgraphIdentification::ConstructValidSubgraphsFromCluster(a1, a2, &v23, a4, 1);
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v23, *((void **)&v23 + 1));
      if (valid) {
        break;
      }
      v11 += 3;
      if (v11 == v12) {
        goto LABEL_27;
      }
    }
    uint64_t v4 = 1;
  }
  *(void *)&long long v23 = &v25;
  std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v23);
  return v4;
}

void sub_211293B48(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, void **a17, uint64_t a18, uint64_t a19, uint64_t a20,char a21)
{
  *(void *)(v22 - 88) = v21;
  std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100]((void ***)(v22 - 88));
  a17 = (void **)&a21;
  std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100](&a17);
  _Unwind_Resume(a1);
}

void PressureBasedSubgraphIdentification::SplitClusterByConcatWithCopyCost(uint64_t a1@<X0>, uint64_t a2@<X1>, uint64_t *a3@<X8>)
{
  uint64_t v4 = *(void *)(a1 + 64);
  if (*(unsigned char *)(v4 + 5) || *(unsigned char *)(v4 + 2))
  {
    *a3 = 0;
    a3[1] = 0;
    a3[2] = 0;
    return;
  }
  ZinMirSpatialSplitUtils::GetSortedCluster(a2, 1, (ZinIrOpLayer ***)&__p);
  unint64_t v6 = v33;
  if (v33 == __p) {
    goto LABEL_35;
  }
  uint64_t v7 = 0;
  unint64_t v6 = (void **)__p;
  while (1)
  {
    int HaveSameOrigin = PressureBasedSubgraphIdentification::ConcatTensorsHaveSameOrigin((uint64_t)v6, a2, v6[v7]);
    unint64_t v6 = (void **)__p;
    if (HaveSameOrigin)
    {
      uint64_t v13 = *((void *)__p + v7);
      uint64_t v14 = *(ZinMirSpatialSplitUtils ***)(v13 + 88);
      unint64_t v15 = *(ZinMirSpatialSplitUtils ***)(v13 + 96);
      if (v14 != v15) {
        break;
      }
    }
LABEL_12:
    if (++v7 >= (unint64_t)(v33 - v6)) {
      goto LABEL_35;
    }
  }
  while (!ZinMirSpatialSplitUtils::HasKernelSupportOnHeight(*v14, v8, v9, v10, v11))
  {
    if (++v14 == v15)
    {
      unint64_t v6 = (void **)__p;
      goto LABEL_12;
    }
  }
  unint64_t v6 = (void **)__p;
  uint64_t v16 = *((void *)__p + v7);
  if (!v16)
  {
LABEL_35:
    *a3 = 0;
    a3[1] = 0;
    a3[2] = 0;
    if (v6)
    {
LABEL_40:
      uint64_t v33 = v6;
      operator delete(v6);
    }
  }
  else
  {
    memset(v30, 0, sizeof(v30));
    int v31 = 1065353216;
    unint64_t v17 = (ZinIrTensor *)(*(uint64_t (**)(uint64_t, void, void))(*(void *)v16 + 32))(v16, 0, 0);
    ZinIrTensor::GetTensorFamily(v17, (uint64_t)&v27);
    uint64_t v18 = (uint64_t *)v27;
    uint64_t v19 = v28;
    if (v27 != (uint64_t **)v28)
    {
      do
      {
        if (*(_DWORD *)(*(void *)(*(void *)(*v18 + 96) + 64) + 8) == 7)
        {
          unint64_t v26 = *(ZinIrOpLayer **)(*v18 + 96);
          std::__hash_table<ZinIrTensor const*,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const* const&>((uint64_t)v30, &v26, &v26);
        }
        ++v18;
      }
      while (v18 != v19);
      uint64_t v18 = (uint64_t *)v27;
    }
    if (v18)
    {
      uint64_t v28 = v18;
      operator delete(v18);
    }
    *a3 = 0;
    a3[1] = 0;
    a3[2] = 0;
    uint64_t v28 = 0;
    uint64_t v29 = 0;
    uint64_t v27 = &v28;
    uint64_t v20 = (ZinIrOpLayer **)__p;
    uint64_t v21 = (ZinIrOpLayer **)v33;
    if (__p != v33)
    {
      do
      {
        unint64_t v26 = *v20;
        if (std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(v30, &v26))
        {
          if (v29)
          {
            unint64_t v22 = a3[1];
            if (v22 >= a3[2])
            {
              uint64_t v23 = std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::__push_back_slow_path<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const&>(a3, (ZinIrOpLayer ***)&v27);
            }
            else
            {
              std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::set[abi:ne180100]((uint64_t *)a3[1], (ZinIrOpLayer ***)&v27);
              uint64_t v23 = v22 + 24;
              a3[1] = v22 + 24;
            }
            a3[1] = v23;
          }
          std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v27, v28);
          uint64_t v28 = 0;
          uint64_t v29 = 0;
          uint64_t v27 = &v28;
        }
        else
        {
          std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>((uint64_t **)&v27, &v26, (uint64_t *)&v26);
        }
        ++v20;
      }
      while (v20 != v21);
      if (v29)
      {
        unint64_t v24 = a3[1];
        if (v24 >= a3[2])
        {
          uint64_t v25 = std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::__push_back_slow_path<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const&>(a3, (ZinIrOpLayer ***)&v27);
        }
        else
        {
          std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::set[abi:ne180100]((uint64_t *)a3[1], (ZinIrOpLayer ***)&v27);
          uint64_t v25 = v24 + 24;
          a3[1] = v24 + 24;
        }
        a3[1] = v25;
      }
    }
    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v27, v28);
    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v30);
    unint64_t v6 = (void **)__p;
    if (__p) {
      goto LABEL_40;
    }
  }
}

void sub_211293E68(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *a10, void *a11, uint64_t a12, char a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, void *__p, uint64_t a19)
{
  if (__p)
  {
    a19 = (uint64_t)__p;
    operator delete(__p);
  }
  _Unwind_Resume(a1);
}

uint64_t PressureBasedSubgraphIdentification::ConcatTensorsHaveSameOrigin(uint64_t a1, uint64_t a2, void *a3)
{
  if (*(_DWORD *)(a3[8] + 8) != 7) {
    return 0;
  }
  uint64_t v4 = a3[11];
  uint64_t v3 = a3[12];
  if (v4 == v3) {
    return 0;
  }
  uint64_t v38 = a3[12];
  while (1)
  {
    uint64_t v7 = *(char **)(*(void *)v4 + 112);
    unint64_t v6 = *(char **)(*(void *)v4 + 120);
    if ((unint64_t)(v6 - v7) >= 9)
    {
      long long v47 = 0uLL;
      uint64_t v48 = 0;
      while (v7 != v6)
      {
        *(void *)&v45[0] = 0;
        *(void *)&v45[0] = *(void *)v7;
        if (*(void **)&v45[0] != a3
          && std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>(a2, (ZinIrOpLayer **)v45))
        {
          uint64_t v8 = *((void *)&v47 + 1);
          if (*((void *)&v47 + 1) >= (unint64_t)v48)
          {
            uint64_t v10 = (uint64_t)(*((void *)&v47 + 1) - v47) >> 3;
            if ((unint64_t)(v10 + 1) >> 61) {
              std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
            }
            unint64_t v11 = (uint64_t)&v48[-v47] >> 2;
            if (v11 <= v10 + 1) {
              unint64_t v11 = v10 + 1;
            }
            if ((unint64_t)&v48[-v47] >= 0x7FFFFFFFFFFFFFF8) {
              unint64_t v12 = 0x1FFFFFFFFFFFFFFFLL;
            }
            else {
              unint64_t v12 = v11;
            }
            if (v12) {
              uint64_t v13 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)&v48, v12);
            }
            else {
              uint64_t v13 = 0;
            }
            uint64_t v14 = &v13[8 * v10];
            *(void *)uint64_t v14 = *(void *)&v45[0];
            uint64_t v9 = v14 + 8;
            unint64_t v15 = (char *)*((void *)&v47 + 1);
            uint64_t v16 = (char *)v47;
            if (*((void *)&v47 + 1) != (void)v47)
            {
              do
              {
                uint64_t v17 = *((void *)v15 - 1);
                v15 -= 8;
                *((void *)v14 - 1) = v17;
                v14 -= 8;
              }
              while (v15 != v16);
              unint64_t v15 = (char *)v47;
            }
            *(void *)&long long v47 = v14;
            *((void *)&v47 + 1) = v9;
            uint64_t v48 = &v13[8 * v12];
            if (v15) {
              operator delete(v15);
            }
          }
          else
          {
            **((void **)&v47 + 1) = *(void *)&v45[0];
            uint64_t v9 = (void *)(v8 + 8);
          }
          *((void *)&v47 + 1) = v9;
        }
        v7 += 8;
      }
      uint64_t v39 = v4;
      memset(v45, 0, sizeof(v45));
      int v46 = 1065353216;
      uint64_t v18 = a3;
      do
      {
        uint64_t v19 = (void *)*((void *)&v47 + 1);
        uint64_t v20 = (void *)v47;
        if ((void)v47 == *((void *)&v47 + 1)) {
          break;
        }
        __p[0] = 0;
        __p[1] = 0;
        uint64_t v40 = (void *)v47;
        long long v44 = 0;
        while (1)
        {
          uint64_t v21 = (void *)*v20;
          if ((void *)*v20 == v18) {
            break;
          }
          uint64_t v23 = (ZinIrOpLayer **)v21[14];
          unint64_t v22 = (ZinIrOpLayer **)v21[15];
          while (v23 != v22)
          {
            BOOL v42 = 0;
            BOOL v42 = *v23;
            if (!std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(v45, &v42)&& std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>(a2, &v42))
            {
              unint64_t v24 = (char *)__p[1];
              if (__p[1] >= v44)
              {
                int64_t v26 = ((char *)__p[1] - (char *)__p[0]) >> 3;
                if ((unint64_t)(v26 + 1) >> 61) {
                  std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
                }
                unint64_t v27 = (v44 - (char *)__p[0]) >> 2;
                if (v27 <= v26 + 1) {
                  unint64_t v27 = v26 + 1;
                }
                if ((unint64_t)(v44 - (char *)__p[0]) >= 0x7FFFFFFFFFFFFFF8) {
                  unint64_t v28 = 0x1FFFFFFFFFFFFFFFLL;
                }
                else {
                  unint64_t v28 = v27;
                }
                if (v28) {
                  uint64_t v29 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)&v44, v28);
                }
                else {
                  uint64_t v29 = 0;
                }
                unint64_t v30 = &v29[8 * v26];
                *(void *)unint64_t v30 = v42;
                uint64_t v25 = v30 + 8;
                unsigned __int8 v32 = (char *)__p[0];
                int v31 = (char *)__p[1];
                if (__p[1] != __p[0])
                {
                  do
                  {
                    uint64_t v33 = *((void *)v31 - 1);
                    v31 -= 8;
                    *((void *)v30 - 1) = v33;
                    v30 -= 8;
                  }
                  while (v31 != v32);
                  int v31 = (char *)__p[0];
                }
                __p[0] = v30;
                __p[1] = v25;
                long long v44 = &v29[8 * v28];
                if (v31) {
                  operator delete(v31);
                }
              }
              else
              {
                *(void *)__p[1] = v42;
                uint64_t v25 = v24 + 8;
              }
              __p[1] = v25;
              std::__hash_table<ZinIrTensor const*,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const* const&>((uint64_t)v45, &v42, &v42);
            }
            ++v23;
          }
          ++v20;
          uint64_t v18 = a3;
          if (v20 == v19)
          {
            BOOL v34 = (void *)v47;
            uint64_t v35 = v48;
            long long v47 = *(_OWORD *)__p;
            uint64_t v48 = v44;
            __p[0] = v34;
            long long v44 = v35;
            goto LABEL_56;
          }
        }
        BOOL v34 = __p[0];
LABEL_56:
        uint64_t v20 = v40;
        if (v34)
        {
          __p[1] = v34;
          operator delete(v34);
        }
      }
      while (v21 != v18);
      std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v45);
      if ((void)v47)
      {
        *((void *)&v47 + 1) = v47;
        operator delete((void *)v47);
      }
      BOOL v36 = v20 == v19;
      uint64_t v3 = v38;
      uint64_t v4 = v39;
      if (!v36) {
        return 1;
      }
    }
    v4 += 8;
    if (v4 == v3) {
      return 0;
    }
  }
}

void sub_211294244(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, void *__p, uint64_t a16, uint64_t a17, uint64_t a18, char a19)
{
  uint64_t v21 = *(void **)(v19 - 112);
  if (v21)
  {
    *(void *)(v19 - 104) = v21;
    operator delete(v21);
  }
  _Unwind_Resume(exception_object);
}

void PressureBasedSubgraphIdentification::SplitClusterViaGuidance(void *a1@<X0>, void *a2@<X1>, uint64_t a3@<X2>, uint64_t a4@<X8>)
{
  unint64_t v5 = a2[2];
  *(void *)(a4 + 8) = 0;
  *(void *)(a4 + 16) = 0;
  *(void *)a4 = 0;
  if (v5 >= 2)
  {
    uint64_t v17 = 0;
    uint64_t v18 = 0;
    uint64_t v16 = (uint64_t *)&v17;
    unint64_t v6 = a2 + 1;
    uint64_t v7 = (void *)*a2;
    if ((void *)*a2 != a2 + 1)
    {
      do
      {
        unint64_t v15 = (ZinIrOpLayer *)v7[4];
        if (std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>(a3, &v15))
        {
          if (v18)
          {
            PressureBasedSubgraphIdentification::RemoveInputAndOutputNoopsOfCluster(a1, (ZinIrOpLayer ***)&v16, (uint64_t *)&v13);
            std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::__insert_with_size[abi:ne180100]<std::__wrap_iter<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>,std::__wrap_iter<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>>((uint64_t *)a4, *(uint64_t ***)(a4 + 8), v13, v14, 0xAAAAAAAAAAAAAAABLL * (v14 - v13));
            uint64_t v19 = &v13;
            std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v19);
          }
          std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v16, v17);
          uint64_t v17 = 0;
          uint64_t v18 = 0;
          uint64_t v16 = (uint64_t *)&v17;
        }
        else
        {
          std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>(&v16, &v15, (uint64_t *)&v15);
        }
        uint64_t v10 = (void *)v7[1];
        if (v10)
        {
          do
          {
            unint64_t v11 = v10;
            uint64_t v10 = (void *)*v10;
          }
          while (v10);
        }
        else
        {
          do
          {
            unint64_t v11 = (void *)v7[2];
            BOOL v12 = *v11 == (void)v7;
            uint64_t v7 = v11;
          }
          while (!v12);
        }
        uint64_t v7 = v11;
      }
      while (v11 != v6);
      if (v18)
      {
        PressureBasedSubgraphIdentification::RemoveInputAndOutputNoopsOfCluster(a1, (ZinIrOpLayer ***)&v16, (uint64_t *)&v13);
        std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::__insert_with_size[abi:ne180100]<std::__wrap_iter<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>,std::__wrap_iter<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>>((uint64_t *)a4, *(uint64_t ***)(a4 + 8), v13, v14, 0xAAAAAAAAAAAAAAABLL * (v14 - v13));
        uint64_t v19 = &v13;
        std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v19);
      }
    }
    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v16, v17);
  }
}

void sub_211294420(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, void **a13, void *a14, uint64_t a15, void **a16)
{
  a16 = (void **)&a9;
  std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100](&a16);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&a13, a14);
  std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100](&a13);
  _Unwind_Resume(a1);
}

void PressureBasedSubgraphIdentification::SplitClusterViaCostModel(void *a1@<X0>, ZinIrOpLayerGraph *a2@<X1>, uint64_t a3@<X2>, void *a4@<X3>, uint64_t *a5@<X8>)
{
  PressureBasedSubgraphIdentification::RemoveInputAndOutputNoopsOfCluster(a1, (ZinIrOpLayer ***)a3, &v17);
  uint64_t v10 = v18;
  if (v18 - v17 == 24 && (unint64_t v11 = *(void *)(v17 + 16), v11 == *(void *)(a3 + 16)))
  {
    if (v11 > 1)
    {
      PressureBasedSubgraphIdentification::SplitClusterByConcatWithCopyCost((uint64_t)a1, a3, (uint64_t *)&v14);
      BOOL v12 = v15;
      if (v15 == v14)
      {
        uint64_t v13 = PressureBasedSubgraphIdentification::DetermineBestLayerFromCostModel(a1, a2, (void *)a3, a4);
        PressureBasedSubgraphIdentification::CutClusterAtLayer(a1, (ZinIrOpLayer ****)a3, v13, a5);
      }
      else
      {
        *a5 = (uint64_t)v14;
        a5[1] = (uint64_t)v12;
        a5[2] = v16;
        unint64_t v15 = 0;
        uint64_t v16 = 0;
        uint64_t v14 = 0;
      }
      uint64_t v20 = &v14;
      std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v20);
    }
    else
    {
      *a5 = 0;
      a5[1] = 0;
      a5[2] = 0;
    }
  }
  else
  {
    *a5 = v17;
    a5[1] = v10;
    a5[2] = v19;
    uint64_t v18 = 0;
    uint64_t v19 = 0;
    uint64_t v17 = 0;
  }
  uint64_t v14 = (void **)&v17;
  std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100](&v14);
}

void sub_211294584(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, void **a10, uint64_t a11, uint64_t a12, char a13, uint64_t a14, uint64_t a15, void ***a16)
{
  a16 = &a10;
  std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100]((void ***)&a16);
  a10 = (void **)&a13;
  std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100](&a10);
  _Unwind_Resume(a1);
}

uint64_t PressureBasedSubgraphIdentification::IsReClusteringNecessary(PressureBasedSubgraphIdentification *this, const Subgraph *a2, const SplitInfo *a3)
{
  if (!*((void *)a2 + 17) || Subgraph::AreAllResetLayersOutputNodes(a2)) {
    return 0;
  }
  if (*(unsigned char *)(*(void *)(*((void *)this + 2) + 8) + 97)) {
    SubgraphIdentification::PrintSubgraphInfo((uint64_t)this, a2);
  }
  return 1;
}

uint64_t PressureBasedSubgraphIdentification::RefineSubgraph(void *a1, ZinIrOpLayerGraph *a2, uint64_t a3, uint64_t a4, uint64_t *a5)
{
  long long v16 = 0uLL;
  uint64_t v17 = 0;
  if (*(void *)(a4 + 16))
  {
    PressureBasedSubgraphIdentification::SplitClusterViaGuidance(a1, (void *)(a3 + 72), a4, (uint64_t)&v14);
  }
  else
  {
    if (!*(unsigned char *)(a1[8] + 8))
    {
      PressureBasedSubgraphIdentification::CutSubgraphAtResetLayers(a1, a3, (uint64_t)&v16);
      goto LABEL_6;
    }
    PressureBasedSubgraphIdentification::SplitClusterViaCostModel(a1, a2, a3 + 72, (void *)(a3 + 96), (uint64_t *)&v14);
  }
  std::vector<std::map<ZinIrDimension,unsigned long>>::__vdeallocate((void **)&v16);
  long long v16 = v14;
  uint64_t v17 = v15;
  uint64_t v15 = 0;
  long long v14 = 0uLL;
  uint64_t v18 = (void **)&v14;
  std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100](&v18);
LABEL_6:
  uint64_t v9 = (ZinIrOpLayer ***)*((void *)&v16 + 1);
  uint64_t v8 = (ZinIrOpLayer ***)v16;
  do
  {
    unint64_t v10 = 0xAAAAAAAAAAAAAAABLL * (v9 - v8);
    unint64_t v11 = v10;
    if (!*(unsigned char *)(a1[8] + 8))
    {
      PressureBasedSubgraphIdentification::CutClustersAtConcatWithPartialInputs((uint64_t)a1, (uint64_t)&v16);
      uint64_t v9 = (ZinIrOpLayer ***)*((void *)&v16 + 1);
      uint64_t v8 = (ZinIrOpLayer ***)v16;
      unint64_t v11 = 0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*((void *)&v16 + 1) - v16) >> 3);
    }
    memset(v13, 0, sizeof(v13));
    std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::__init_with_size[abi:ne180100]<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>((uint64_t *)v13, v8, v9, v11);
    PressureBasedSubgraphIdentification::CutClustersAtPartialOutputs((uint64_t)a1, v13, (uint64_t)&v16);
    *(void *)&long long v14 = v13;
    std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v14);
    uint64_t v9 = (ZinIrOpLayer ***)*((void *)&v16 + 1);
    uint64_t v8 = (ZinIrOpLayer ***)v16;
  }
  while (v10 < 0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*((void *)&v16 + 1) - v16) >> 3));
  PressureBasedSubgraphIdentification::ConstructSubGraphs((uint64_t)a1, a2, (uint64_t *)&v16, a5, &v14);
  *(void *)&long long v14 = &v16;
  std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v14);
  return 0;
}

void sub_2112947C8(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, void **a13, uint64_t a14, uint64_t a15, uint64_t a16, char a17)
{
  a13 = (void **)&a17;
  std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100](&a13);
  _Unwind_Resume(a1);
}

void PressureBasedSubgraphIdentification::CutSubgraphAtResetLayers(void *a1, uint64_t a2, uint64_t a3)
{
  uint64_t v42 = *MEMORY[0x263EF8340];
  uint64_t v38 = 0;
  uint64_t v39 = 0;
  uint64_t v37 = (uint64_t *)&v38;
  uint64_t v4 = a2 + 72;
  ZinMirSpatialSplitUtils::GetSortedCluster(a2 + 72, 0, &v35);
  unint64_t v6 = v35;
  unint64_t v5 = v36;
  if ((unint64_t)((char *)v36 - (char *)v35) >= 9)
  {
    if ((*(unsigned char *)(*(void *)(a1[2] + 8) + 97) & 1) != 0
      && os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_INFO))
    {
      LOWORD(buf) = 0;
      _os_log_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_INFO, "INFO:: (SpatialSplit) ---CutSubgraphAtResetLayers---\n", (uint8_t *)&buf, 2u);
      unint64_t v6 = v35;
      unint64_t v5 = v36;
    }
    if (v5 != v6)
    {
      char v7 = 0;
      unint64_t v8 = 0;
      uint64_t v9 = a2 + 120;
      while (1)
      {
        BOOL v34 = 0;
        BOOL v34 = v6[v8];
        *(void *)&long long buf = v34;
        uint64_t v10 = std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>(v9, (ZinIrOpLayer **)&buf);
        if (v10) {
          goto LABEL_8;
        }
        if (*(_DWORD *)(*((void *)v34 + 8) + 8) == 7) {
          break;
        }
LABEL_14:
        BOOL v11 = 0;
LABEL_15:
        long long v14 = v34;
        if (*(_DWORD *)(*((void *)v34 + 8) + 8) == 7)
        {
          uint64_t v10 = std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>(a2, &v34);
          uint64_t v15 = v10;
          long long v14 = v34;
          if (*(_DWORD *)(*((void *)v34 + 8) + 8) == 7)
          {
            uint64_t v17 = (void *)*((void *)v34 + 11);
            long long v16 = (void *)*((void *)v34 + 12);
            while (v17 != v16)
            {
              *(void *)&long long buf = *v17;
              uint64_t v10 = std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>(v9, (ZinIrOpLayer **)&buf);
              if (v10) {
                goto LABEL_37;
              }
              ++v17;
            }
            if (v15) {
              goto LABEL_37;
            }
            long long v14 = v34;
          }
          else if (v10)
          {
            goto LABEL_37;
          }
        }
        if (!PressureBasedSubgraphIdentification::ConcatTensorsHaveSameOrigin(v10, v4, v14)) {
          goto LABEL_41;
        }
        ZinIrCompilerParameters::getSpatialSplitMode(*(ZinIrCompilerParameters **)(a1[2] + 8), &buf);
        uint64_t v18 = HIBYTE(v41);
        if (v41 < 0) {
          uint64_t v18 = *((void *)&buf + 1);
        }
        if (v18 != 15) {
          goto LABEL_35;
        }
        p_long long buf = (long long *)buf;
        if (v41 >= 0) {
          p_long long buf = &buf;
        }
        uint64_t v20 = *(void *)p_buf;
        uint64_t v21 = *(void *)((char *)p_buf + 7);
        if (v20 == 0x2D636972656E6567 && v21 == 0x7078652D6761642DLL)
        {
          BOOL v23 = *(unsigned char *)(a1[8] + 8) != 0;
          if ((SHIBYTE(v41) & 0x80000000) == 0)
          {
LABEL_36:
            if (!v23) {
              goto LABEL_41;
            }
            goto LABEL_37;
          }
        }
        else
        {
LABEL_35:
          BOOL v23 = 1;
          if ((SHIBYTE(v41) & 0x80000000) == 0) {
            goto LABEL_36;
          }
        }
        operator delete((void *)buf);
        if (!v23)
        {
LABEL_41:
          if (v7 & 1 | !v11)
          {
            unint64_t v24 = &_os_log_internal;
            if ((*(unsigned char *)(*(void *)(a1[2] + 8) + 97) & 1) != 0
              && os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_INFO))
            {
              uint64_t v25 = (void *)((char *)v34 + 24);
              if (*((char *)v34 + 47) < 0) {
                uint64_t v25 = (void *)*v25;
              }
              LODWORD(buf) = 136315138;
              *(void *)((char *)&buf + 4) = v25;
              _os_log_impl(&dword_210C72000, v24, OS_LOG_TYPE_INFO, "%s\n", (uint8_t *)&buf, 0xCu);
            }
            long long buf = 0uLL;
            uint64_t v41 = 0;
            if (ZinIrOpLayer::IsNoOp(v34, (uint64_t *)&buf))
            {
              int v26 = *(_DWORD *)(*((void *)v34 + 8) + 8);
              if ((void)buf)
              {
                *((void *)&buf + 1) = buf;
                operator delete((void *)buf);
              }
              if (v26 != 7)
              {
                unint64_t v27 = (void *)*((void *)v34 + 14);
                unint64_t v28 = (void *)*((void *)v34 + 15);
                while (v27 != v28)
                {
                  *(void *)&long long buf = 0;
                  *(void *)&long long buf = *v27;
                  if (!std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)&v37, (ZinIrOpLayer **)&buf))goto LABEL_67; {
                  ++v27;
                  }
                }
              }
            }
            else if ((void)buf)
            {
              *((void *)&buf + 1) = buf;
              operator delete((void *)buf);
            }
            std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>(&v37, &v34, (uint64_t *)&v34);
LABEL_67:
            if (v8 == v36 - v35 - 1) {
              PressureBasedSubgraphIdentification::CutClusterAtPartialOutputs((uint64_t)a1, (ZinIrOpLayer ***)&v37, a3);
            }
          }
          else
          {
            PressureBasedSubgraphIdentification::CutClusterAtPartialOutputs((uint64_t)a1, (ZinIrOpLayer ***)&v37, a3);
            std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v37, v38);
            uint64_t v38 = 0;
            uint64_t v39 = 0;
            uint64_t v37 = (uint64_t *)&v38;
            char v29 = (*(uint64_t (**)(void *, ZinIrOpLayer *))(*a1 + 24))(a1, v34);
            if ((v29 & 1) == 0) {
              std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>(&v37, &v34, (uint64_t *)&v34);
            }
            char v7 = v29 ^ 1;
            if (*(unsigned char *)(*(void *)(a1[2] + 8) + 97))
            {
              unint64_t v30 = &_os_log_internal;
              if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_INFO))
              {
                LOWORD(buf) = 0;
                _os_log_impl(&dword_210C72000, v30, OS_LOG_TYPE_INFO, "----------------\n", (uint8_t *)&buf, 2u);
              }
              if (os_log_type_enabled(v30, OS_LOG_TYPE_INFO))
              {
                int v31 = (void *)((char *)v34 + 24);
                if (*((char *)v34 + 47) < 0) {
                  int v31 = (void *)*v31;
                }
                LODWORD(buf) = 136315138;
                *(void *)((char *)&buf + 4) = v31;
                _os_log_impl(&dword_210C72000, v30, OS_LOG_TYPE_INFO, "%s (reset)\n", (uint8_t *)&buf, 0xCu);
              }
            }
          }
          goto LABEL_69;
        }
LABEL_37:
        if (v39)
        {
          PressureBasedSubgraphIdentification::CutClusterAtPartialOutputs((uint64_t)a1, (ZinIrOpLayer ***)&v37, a3);
          std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v37, v38);
          uint64_t v38 = 0;
          uint64_t v39 = 0;
          uint64_t v37 = (uint64_t *)&v38;
        }
LABEL_69:
        ++v8;
        unint64_t v6 = v35;
        if (v8 >= v36 - v35) {
          goto LABEL_70;
        }
      }
      uint64_t v13 = (void *)*((void *)v34 + 11);
      BOOL v12 = (void *)*((void *)v34 + 12);
      while (v13 != v12)
      {
        *(void *)&long long buf = *v13;
        uint64_t v10 = std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>(v9, (ZinIrOpLayer **)&buf);
        if (!v10) {
          goto LABEL_14;
        }
        ++v13;
      }
LABEL_8:
      uint64_t v10 = std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>(a2 + 24, &v34);
      BOOL v11 = v10 == 0;
      goto LABEL_15;
    }
  }
LABEL_70:
  if (v6)
  {
    BOOL v36 = v6;
    operator delete(v6);
  }
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v37, v38);
}

void sub_211294D78(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, void *a15, uint64_t a16, uint64_t a17, char a18, void *a19, uint64_t a20,void *__p,uint64_t a22)
{
}

void *PressureBasedSubgraphIdentification::IsChainedProducer(PressureBasedSubgraphIdentification *this, const ZinIrOpLayer *a2)
{
  uint64_t v3 = (ZinIrTensor *)(*(uint64_t (**)(const ZinIrOpLayer *, void, void))(*(void *)a2 + 32))(a2, 0, 0);
  RootTensor = ZinIrTensor::GetRootTensor(v3);
  unint64_t v5 = (void *)*((void *)this + 14);

  return ZinMirSpatialSplitUtils::IsChained((uint64_t)RootTensor, v5);
}

void *PressureBasedSubgraphIdentification::IsChainedConsumer(PressureBasedSubgraphIdentification *this, const ZinIrOpLayer *a2, ZinIrOpLayer **a3)
{
  BOOL v11 = 0;
  BOOL v12 = 0;
  uint64_t v13 = 0;
  std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(&v11, *((const void **)a2 + 11), *((void *)a2 + 12), (uint64_t)(*((void *)a2 + 12) - *((void *)a2 + 11)) >> 3);
  unint64_t v5 = v11;
  unint64_t v6 = v12;
  if (v11 == v12)
  {
    uint64_t v9 = 0;
    if (!v11) {
      return v9;
    }
    goto LABEL_9;
  }
  while (1)
  {
    char v7 = *v5;
    uint64_t v8 = (*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)*v5 + 32))(*v5, 0, 0);
    uint64_t v9 = ZinMirSpatialSplitUtils::IsChained(v8, *((void **)this + 14));
    if (v9) {
      break;
    }
    if (++v5 == v6) {
      goto LABEL_8;
    }
  }
  *a3 = v7;
LABEL_8:
  unint64_t v5 = v11;
  if (v11)
  {
LABEL_9:
    BOOL v12 = v5;
    operator delete(v5);
  }
  return v9;
}

void sub_211294F28(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t PressureBasedSubgraphIdentification::IsChainedConsumer(PressureBasedSubgraphIdentification *this, const ZinIrOpLayer *a2)
{
  uint64_t v3 = 0;
  return (*(uint64_t (**)(PressureBasedSubgraphIdentification *, const ZinIrOpLayer *, uint64_t *))(*(void *)this + 40))(this, a2, &v3);
}

void std::__tree<std::unique_ptr<ZinIrMemoryPressureAnalyzer::Allocation const>,ZinIrMemoryPressureAnalyzer::PointerComparator,std::allocator<std::unique_ptr<ZinIrMemoryPressureAnalyzer::Allocation const>>>::destroy(uint64_t a1, void *a2)
{
  if (a2)
  {
    std::__tree<std::unique_ptr<ZinIrMemoryPressureAnalyzer::Allocation const>,ZinIrMemoryPressureAnalyzer::PointerComparator,std::allocator<std::unique_ptr<ZinIrMemoryPressureAnalyzer::Allocation const>>>::destroy(a1, *a2);
    std::__tree<std::unique_ptr<ZinIrMemoryPressureAnalyzer::Allocation const>,ZinIrMemoryPressureAnalyzer::PointerComparator,std::allocator<std::unique_ptr<ZinIrMemoryPressureAnalyzer::Allocation const>>>::destroy(a1, a2[1]);
    uint64_t v4 = a2[4];
    a2[4] = 0;
    if (v4) {
      (*(void (**)(uint64_t))(*(void *)v4 + 8))(v4);
    }
    operator delete(a2);
  }
}

uint64_t std::vector<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::__push_back_slow_path<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>(uint64_t *a1, uint64_t a2)
{
  uint64_t v3 = *a1;
  unint64_t v4 = 0xAAAAAAAAAAAAAAABLL * ((a1[1] - *a1) >> 4);
  unint64_t v5 = v4 + 1;
  if (v4 + 1 > 0x555555555555555) {
    std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
  }
  uint64_t v7 = (uint64_t)(a1 + 2);
  unint64_t v8 = 0xAAAAAAAAAAAAAAABLL * ((a1[2] - v3) >> 4);
  if (2 * v8 > v5) {
    unint64_t v5 = 2 * v8;
  }
  if (v8 >= 0x2AAAAAAAAAAAAAALL) {
    unint64_t v9 = 0x555555555555555;
  }
  else {
    unint64_t v9 = v5;
  }
  v15[4] = a1 + 2;
  uint64_t v10 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ANEDebugInfo::DebugInfoInMem::Group>>(v7, v9);
  BOOL v11 = &v10[48 * v4];
  v15[0] = v10;
  v15[1] = v11;
  uint64_t v15[3] = &v10[48 * v12];
  *(_OWORD *)BOOL v11 = *(_OWORD *)a2;
  *((void *)v11 + 3) = 0;
  *((void *)v11 + 4) = 0;
  *((void *)v11 + 2) = 0;
  *((_OWORD *)v11 + 1) = *(_OWORD *)(a2 + 16);
  *((void *)v11 + 4) = *(void *)(a2 + 32);
  *(void *)(a2 + 16) = 0;
  *(void *)(a2 + 24) = 0;
  *(void *)(a2 + std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = 0;
  *((_DWORD *)v11 + 10) = *(_DWORD *)(a2 + 40);
  v15[2] = v11 + 48;
  std::vector<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::__swap_out_circular_buffer(a1, v15);
  uint64_t v13 = a1[1];
  std::__split_buffer<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::~__split_buffer(v15);
  return v13;
}

void sub_211295118(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::__split_buffer<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::~__split_buffer((void **)va);
  _Unwind_Resume(a1);
}

uint64_t std::vector<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::__swap_out_circular_buffer(uint64_t *a1, void *a2)
{
  uint64_t result = std::__uninitialized_allocator_move_if_noexcept[abi:ne180100]<std::allocator<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>,std::reverse_iterator<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>*>,std::reverse_iterator<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>*>,std::reverse_iterator<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>*>>((uint64_t)(a1 + 2), a1[1], a1[1], *a1, *a1, a2[1], a2[1]);
  a2[1] = v5;
  uint64_t v6 = *a1;
  *a1 = v5;
  a2[1] = v6;
  uint64_t v7 = a1[1];
  a1[1] = a2[2];
  a2[2] = v7;
  uint64_t v8 = a1[2];
  a1[2] = a2[3];
  a2[3] = v8;
  *a2 = a2[1];
  return result;
}

uint64_t std::__uninitialized_allocator_move_if_noexcept[abi:ne180100]<std::allocator<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>,std::reverse_iterator<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>*>,std::reverse_iterator<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>*>,std::reverse_iterator<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>*>>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  uint64_t v7 = a7;
  *(void *)&long long v13 = a6;
  *((void *)&v13 + 1) = a7;
  long long v12 = v13;
  v10[0] = a1;
  v10[1] = &v12;
  v10[2] = &v13;
  if (a3 == a5)
  {
    uint64_t v8 = a6;
  }
  else
  {
    do
    {
      *(_OWORD *)(v7 - 48) = *(_OWORD *)(a3 - 48);
      *(void *)(v7 - 24) = 0;
      *(void *)(v7 - 16) = 0;
      *(void *)(v7 - std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = 0;
      *(_OWORD *)(v7 - std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_OWORD *)(a3 - 32);
      *(void *)(v7 - 16) = *(void *)(a3 - 16);
      *(void *)(a3 - 24) = 0;
      *(void *)(a3 - 16) = 0;
      *(void *)(a3 - std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = 0;
      *(_DWORD *)(v7 - 8) = *(_DWORD *)(a3 - 8);
      uint64_t v7 = *((void *)&v13 + 1) - 48;
      *((void *)&v13 + 1) -= 48;
      a3 -= 48;
    }
    while (a3 != a5);
    uint64_t v8 = v13;
  }
  char v11 = 1;
  std::__exception_guard_exceptions<std::_AllocatorDestroyRangeReverse<std::allocator<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>,std::reverse_iterator<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>*>>>::~__exception_guard_exceptions[abi:ne180100]((uint64_t)v10);
  return v8;
}

uint64_t std::__exception_guard_exceptions<std::_AllocatorDestroyRangeReverse<std::allocator<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>,std::reverse_iterator<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>*>>>::~__exception_guard_exceptions[abi:ne180100](uint64_t a1)
{
  if (!*(unsigned char *)(a1 + 24)) {
    std::_AllocatorDestroyRangeReverse<std::allocator<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>,std::reverse_iterator<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>*>>::operator()[abi:ne180100](a1);
  }
  return a1;
}

void std::_AllocatorDestroyRangeReverse<std::allocator<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>,std::reverse_iterator<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>*>>::operator()[abi:ne180100](uint64_t a1)
{
  uint64_t v1 = *(void *)(*(void *)(a1 + 16) + 8);
  uint64_t v2 = *(void *)(*(void *)(a1 + 8) + 8);
  while (v1 != v2)
  {
    uint64_t v3 = (void **)(v1 + 16);
    std::vector<Subgraph>::__destroy_vector::operator()[abi:ne180100](&v3);
    v1 += 48;
  }
}

void **std::__split_buffer<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::~__split_buffer(void **a1)
{
  if (*a1) {
    operator delete(*a1);
  }
  return a1;
}

void std::__split_buffer<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::clear[abi:ne180100](uint64_t a1)
{
  uint64_t v2 = *(void *)(a1 + 8);
  for (uint64_t i = *(void *)(a1 + 16); i != v2; uint64_t i = *(void *)(a1 + 16))
  {
    *(void *)(a1 + 16) = i - 48;
    unint64_t v4 = (void **)(i - 32);
    std::vector<Subgraph>::__destroy_vector::operator()[abi:ne180100](&v4);
  }
}

void *std::vector<Subgraph>::__init_with_size[abi:ne180100]<Subgraph*,Subgraph*>(void *result, uint64_t a2, uint64_t a3, unint64_t a4)
{
  if (a4)
  {
    uint64_t v6 = result;
    std::vector<Subgraph>::__vallocate[abi:ne180100](result, a4);
    uint64_t result = (void *)std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<Subgraph>,Subgraph*,Subgraph*,Subgraph*>((uint64_t)(v6 + 2), a2, a3, v6[1]);
    v6[1] = result;
  }
  return result;
}

void sub_2112953DC(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, void **a9)
{
  *(void *)(v9 + 8) = v10;
  std::vector<Subgraph>::__destroy_vector::operator()[abi:ne180100](&a9);
  _Unwind_Resume(a1);
}

uint64_t std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<Subgraph>,Subgraph*,Subgraph*,Subgraph*>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  if (a2 != a3)
  {
    uint64_t v7 = 0;
    do
    {
      Subgraph::Subgraph((Subgraph *)(a4 + v7), (const Subgraph *)(a2 + v7));
      v7 += 152;
    }
    while (a2 + v7 != a3);
    a4 += v7;
  }
  return a4;
}

void sub_21129545C(_Unwind_Exception *exception_object)
{
  if (v2)
  {
    uint64_t v4 = v1 - 152;
    do
    {
      std::__destroy_at[abi:ne180100]<Subgraph,0>(v4 + v2);
      v2 -= 152;
    }
    while (v2);
  }
  _Unwind_Resume(exception_object);
}

uint64_t std::vector<Subgraph>::__insert_with_size[abi:ne180100]<std::__wrap_iter<Subgraph*>,std::__wrap_iter<Subgraph*>>(uint64_t *a1, uint64_t a2, const Subgraph *a3, uint64_t a4, uint64_t a5)
{
  uint64_t v5 = a2;
  if (a5 >= 1)
  {
    uint64_t v7 = a3;
    uint64_t v11 = a1[2];
    uint64_t v9 = (uint64_t)(a1 + 2);
    uint64_t v10 = v11;
    unint64_t v12 = *(void *)(v9 - 8);
    if ((uint64_t)(0x86BCA1AF286BCA1BLL * ((uint64_t)(v11 - v12) >> 3)) >= a5)
    {
      uint64_t v20 = v12 - a2;
      if ((uint64_t)(0x86BCA1AF286BCA1BLL * ((uint64_t)(v12 - a2) >> 3)) >= a5)
      {
        uint64_t v21 = (uint64_t)a3 + 152 * a5;
      }
      else
      {
        uint64_t v21 = (uint64_t)a3 + 8 * ((uint64_t)(v12 - a2) >> 3);
        a1[1] = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<Subgraph>,Subgraph*,Subgraph*,Subgraph*>(v9, v21, a4, *(void *)(v9 - 8));
        if (v20 < 1) {
          return v5;
        }
      }
      std::vector<Subgraph>::__move_range((uint64_t)a1, v5, v12, v5 + 152 * a5);
      std::__copy_loop<std::_ClassicAlgPolicy>::operator()[abi:ne180100]<Subgraph *,Subgraph *,Subgraph *>((uint64_t)v26, (uint64_t)v7, v21, v5);
    }
    else
    {
      uint64_t v13 = *a1;
      unint64_t v14 = a5 - 0x79435E50D79435E5 * ((uint64_t)(v12 - *a1) >> 3);
      if (v14 > 0x1AF286BCA1AF286) {
        std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
      }
      unint64_t v15 = 0x86BCA1AF286BCA1BLL * ((a2 - v13) >> 3);
      unint64_t v16 = 0x86BCA1AF286BCA1BLL * ((v10 - v13) >> 3);
      uint64_t v17 = 2 * v16;
      if (2 * v16 <= v14) {
        uint64_t v17 = v14;
      }
      if (v16 >= 0xD79435E50D7943) {
        unint64_t v18 = 0x1AF286BCA1AF286;
      }
      else {
        unint64_t v18 = v17;
      }
      uint64_t v29 = v9;
      if (v18) {
        uint64_t v19 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<Subgraph>>(v9, v18);
      }
      else {
        uint64_t v19 = 0;
      }
      unint64_t v22 = (Subgraph *)&v19[152 * v15];
      v26[0] = v19;
      v26[1] = v22;
      unint64_t v27 = v22;
      unint64_t v28 = &v19[152 * v18];
      uint64_t v23 = 152 * a5;
      unint64_t v24 = (Subgraph *)((char *)v22 + 152 * a5);
      do
      {
        Subgraph::Subgraph(v22, v7);
        unint64_t v22 = (Subgraph *)((char *)v22 + 152);
        uint64_t v7 = (const Subgraph *)((char *)v7 + 152);
        v23 -= 152;
      }
      while (v23);
      unint64_t v27 = v24;
      uint64_t v5 = std::vector<Subgraph>::__swap_out_circular_buffer(a1, v26, v5);
      std::__split_buffer<Subgraph>::~__split_buffer((uint64_t)v26);
    }
  }
  return v5;
}

void sub_211295660(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, char a10, uint64_t a11, uint64_t a12)
{
  *(void *)(v12 + 8) = v13;
  _Unwind_Resume(exception_object);
}

uint64_t std::vector<Subgraph>::__move_range(uint64_t a1, uint64_t a2, unint64_t a3, uint64_t a4)
{
  uint64_t v6 = *(void *)(a1 + 8);
  unint64_t v7 = a2 + v6 - a4;
  uint64_t v8 = v6;
  if (v7 < a3)
  {
    unint64_t v10 = a2 + v6 - a4;
    uint64_t v8 = v6;
    do
    {
      uint64_t v11 = Subgraph::Subgraph(v8, v10);
      v10 += 152;
      uint64_t v8 = v11 + 152;
    }
    while (v10 < a3);
  }
  *(void *)(a1 + 8) = v8;
  return std::__move_backward_loop<std::_ClassicAlgPolicy>::operator()[abi:ne180100]<Subgraph *,Subgraph *,Subgraph *>((uint64_t)&v13, a2, v7, v6);
}

uint64_t std::vector<Subgraph>::__swap_out_circular_buffer(uint64_t *a1, void *a2, uint64_t a3)
{
  uint64_t v3 = a3;
  uint64_t v6 = a2[1];
  uint64_t v7 = *a1;
  uint64_t v8 = v6;
  if (v7 != a3)
  {
    uint64_t v9 = a3;
    uint64_t v8 = a2[1];
    do
    {
      v9 -= 152;
      uint64_t v8 = Subgraph::Subgraph(v8 - 152, v9);
    }
    while (v9 != v7);
  }
  a2[1] = v8;
  uint64_t v10 = a1[1];
  uint64_t v11 = a2[2];
  if (v10 != v3)
  {
    do
    {
      Subgraph::Subgraph(v11, v3);
      v3 += 152;
      v11 += 152;
    }
    while (v3 != v10);
    uint64_t v8 = a2[1];
  }
  a2[2] = v11;
  uint64_t v12 = *a1;
  *a1 = v8;
  a2[1] = v12;
  uint64_t v13 = a1[1];
  a1[1] = a2[2];
  a2[2] = v13;
  uint64_t v14 = a1[2];
  a1[2] = a2[3];
  a2[3] = v14;
  *a2 = a2[1];
  return v6;
}

uint64_t std::__move_backward_loop<std::_ClassicAlgPolicy>::operator()[abi:ne180100]<Subgraph *,Subgraph *,Subgraph *>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  if (a3 != a2)
  {
    uint64_t v7 = 0;
    do
    {
      uint64_t v8 = a3 + v7;
      uint64_t v9 = a4 + v7;
      std::__tree<ZinSpaceRange>::__move_assign(a4 + v7 - 152, (void *)(a3 + v7 - 152));
      std::__tree<ZinSpaceRange>::__move_assign(a4 + v7 - 128, (void *)(a3 + v7 - 128));
      std::list<ZinIrOpLayer *>::__move_assign((uint64_t *)(a4 + v7 - 104), (void *)(a3 + v7 - 104));
      std::__tree<ZinSpaceRange>::__move_assign(a4 + v7 - 80, (void *)(a3 + v7 - 80));
      std::vector<std::map<ZinIrDimension,unsigned long>>::__vdeallocate((void **)(a4 + v7 - 56));
      *(_OWORD *)(v9 - 56) = *(_OWORD *)(a3 + v7 - 56);
      *(void *)(v9 - 40) = *(void *)(a3 + v7 - 40);
      *(void *)(v8 - 56) = 0;
      *(void *)(v8 - 48) = 0;
      *(void *)(v8 - 40) = 0;
      std::__tree<ZinSpaceRange>::__move_assign(a4 + v7 - 32, (void *)(a3 + v7 - 32));
      *(unsigned char *)(v9 - 8) = *(unsigned char *)(a3 + v7 - 8);
      v7 -= 152;
    }
    while (a3 + v7 != a2);
  }
  return a3;
}

uint64_t std::__copy_loop<std::_ClassicAlgPolicy>::operator()[abi:ne180100]<Subgraph *,Subgraph *,Subgraph *>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  if (a2 == a3) {
    return a2;
  }
  uint64_t v6 = a3;
  uint64_t v7 = 0;
  do
  {
    uint64_t v8 = a4 + v7;
    if (a2 != a4)
    {
      uint64_t v9 = a2 + v7;
      std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__assign_multi<std::__tree_const_iterator<ZinIrOpLayer *,std::__tree_node<ZinIrOpLayer *,void *> *,long>>((uint64_t **)(a4 + v7), *(void **)(a2 + v7), (void *)(a2 + v7 + 8));
      std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__assign_multi<std::__tree_const_iterator<ZinIrOpLayer *,std::__tree_node<ZinIrOpLayer *,void *> *,long>>((uint64_t **)(v8 + 24), *(void **)(v9 + 24), (void *)(v9 + 32));
      std::list<ZinIrOpLayer *>::__assign_with_sentinel[abi:ne180100]<std::__list_const_iterator<ZinIrOpLayer *,void *>,std::__list_const_iterator<ZinIrOpLayer *,void *>>((uint64_t *)(v8 + 48), *(void *)(v9 + 56), v9 + 48);
      std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__assign_multi<std::__tree_const_iterator<ZinIrOpLayer *,std::__tree_node<ZinIrOpLayer *,void *> *,long>>((uint64_t **)(v8 + 72), *(void **)(v9 + 72), (void *)(v9 + 80));
      std::vector<std::map<ZinIrDimension,unsigned long>>::__assign_with_size[abi:ne180100]<std::map<ZinIrDimension,unsigned long>*,std::map<ZinIrDimension,unsigned long>*>(v8 + 96, *(void *)(v9 + 96), *(uint64_t ***)(v9 + 104), 0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*(void *)(v9 + 104) - *(void *)(v9 + 96)) >> 3));
      std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__assign_multi<std::__tree_const_iterator<ZinIrOpLayer *,std::__tree_node<ZinIrOpLayer *,void *> *,long>>((uint64_t **)(v8 + 120), *(void **)(v9 + 120), (void *)(v9 + 128));
    }
    *(unsigned char *)(v8 + 144) = *(unsigned char *)(a2 + v7 + 144);
    v7 += 152;
  }
  while (a2 + v7 != v6);
  return v6;
}

uint64_t **std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__assign_multi<std::__tree_const_iterator<ZinIrOpLayer *,std::__tree_node<ZinIrOpLayer *,void *> *,long>>(uint64_t **result, void *a2, void *a3)
{
  uint64_t v5 = result;
  if (result[2])
  {
    uint64_t v6 = *result;
    uint64_t v7 = result[1];
    ZinIrOpLayer *result = (uint64_t *)(result + 1);
    v7[2] = 0;
    result[1] = 0;
    result[2] = 0;
    if (v6[1]) {
      uint64_t v8 = (uint64_t *)v6[1];
    }
    else {
      uint64_t v8 = v6;
    }
    unint64_t v15 = result;
    unint64_t v16 = v8;
    uint64_t v17 = v8;
    if (v8)
    {
      unint64_t v16 = std::__tree<ZinIrTensor *,ZinIrIdComparator<ZinIrTensor *>,std::allocator<ZinIrTensor *>>::_DetachedTreeCache::__detach_next((uint64_t)v8);
      if (a2 != a3)
      {
        uint64_t v9 = a2;
        do
        {
          v8[4] = v9[4];
          leaf_high = (uint64_t **)std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__find_leaf_high((uint64_t)v5, &v18, (ZinIrOpLayer **)v8 + 4);
          std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::__insert_node_at(v5, v18, leaf_high, v8);
          uint64_t v17 = v16;
          if (v16) {
            unint64_t v16 = std::__tree<ZinIrTensor *,ZinIrIdComparator<ZinIrTensor *>,std::allocator<ZinIrTensor *>>::_DetachedTreeCache::__detach_next((uint64_t)v16);
          }
          uint64_t v11 = (void *)v9[1];
          if (v11)
          {
            do
            {
              a2 = v11;
              uint64_t v11 = (void *)*v11;
            }
            while (v11);
          }
          else
          {
            do
            {
              a2 = (void *)v9[2];
              BOOL v12 = *a2 == (void)v9;
              uint64_t v9 = a2;
            }
            while (!v12);
          }
          uint64_t v8 = v17;
          if (v17) {
            BOOL v12 = a2 == a3;
          }
          else {
            BOOL v12 = 1;
          }
          uint64_t v9 = a2;
        }
        while (!v12);
      }
    }
    uint64_t result = (uint64_t **)std::__tree<ZinIrTensor *,ZinIrIdComparator<ZinIrTensor *>,std::allocator<ZinIrTensor *>>::_DetachedTreeCache::~_DetachedTreeCache[abi:ne180100]((uint64_t)&v15);
  }
  if (a2 != a3)
  {
    do
    {
      uint64_t result = (uint64_t **)std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_multi<ZinIrOpLayer * const&>(v5, a2 + 4);
      uint64_t v13 = (void *)a2[1];
      if (v13)
      {
        do
        {
          uint64_t v14 = v13;
          uint64_t v13 = (void *)*v13;
        }
        while (v13);
      }
      else
      {
        do
        {
          uint64_t v14 = (void *)a2[2];
          BOOL v12 = *v14 == (void)a2;
          a2 = v14;
        }
        while (!v12);
      }
      a2 = v14;
    }
    while (v14 != a3);
  }
  return result;
}

void sub_211295B28(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
}

void *std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__find_leaf_high(uint64_t a1, void *a2, ZinIrOpLayer **a3)
{
  uint64_t v5 = (void *)(a1 + 8);
  uint64_t v4 = *(void *)(a1 + 8);
  if (v4)
  {
    int v7 = a1 + 16;
    do
    {
      while (1)
      {
        uint64_t v5 = (void *)v4;
        if (!ScheduleComparator::operator()(v7, *a3, *(ZinIrOpLayer **)(v4 + 32))) {
          break;
        }
        uint64_t v4 = *v5;
        uint64_t result = v5;
        if (!*v5) {
          goto LABEL_9;
        }
      }
      uint64_t v4 = v5[1];
    }
    while (v4);
    uint64_t result = v5 + 1;
  }
  else
  {
    uint64_t result = (void *)(a1 + 8);
  }
LABEL_9:
  *a2 = v5;
  return result;
}

void *std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_multi<ZinIrOpLayer * const&>(uint64_t **a1, void *a2)
{
  uint64_t v4 = operator new(0x28uLL);
  *((void *)v4 + 4) = *a2;
  leaf_high = (uint64_t **)std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__find_leaf_high((uint64_t)a1, &v7, (ZinIrOpLayer **)v4 + 4);
  std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::__insert_node_at(a1, v7, leaf_high, (uint64_t *)v4);
  return v4;
}

void sub_211295C28(_Unwind_Exception *a1)
{
  operator delete(v1);
  _Unwind_Resume(a1);
}

void std::vector<std::map<ZinIrDimension,unsigned long>>::__assign_with_size[abi:ne180100]<std::map<ZinIrDimension,unsigned long>*,std::map<ZinIrDimension,unsigned long>*>(uint64_t a1, uint64_t a2, uint64_t **a3, unint64_t a4)
{
  uint64_t v8 = a1 + 16;
  uint64_t v9 = *(uint64_t ***)a1;
  if (0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*(void *)(a1 + 16) - *(void *)a1) >> 3) < a4)
  {
    std::vector<std::map<ZinIrDimension,unsigned long>>::__vdeallocate((void **)a1);
    if (a4 > 0xAAAAAAAAAAAAAAALL) {
      std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
    }
    unint64_t v10 = 0x5555555555555556 * ((uint64_t)(*(void *)(a1 + 16) - *(void *)a1) >> 3);
    if (v10 <= a4) {
      unint64_t v10 = a4;
    }
    if (0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*(void *)(a1 + 16) - *(void *)a1) >> 3) >= 0x555555555555555) {
      unint64_t v11 = 0xAAAAAAAAAAAAAAALL;
    }
    else {
      unint64_t v11 = v10;
    }
    std::vector<std::string>::__vallocate[abi:ne180100]((void *)a1, v11);
    BOOL v12 = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::map<ZinIrDimension,unsigned long>>,std::map<ZinIrDimension,unsigned long>*,std::map<ZinIrDimension,unsigned long>*,std::map<ZinIrDimension,unsigned long>*>(v8, a2, (uint64_t)a3, *(uint64_t **)(a1 + 8));
    goto LABEL_11;
  }
  if (0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*(void *)(a1 + 8) - (void)v9) >> 3) < a4)
  {
    uint64_t v13 = (uint64_t **)(a2 + 8 * ((uint64_t)(*(void *)(a1 + 8) - (void)v9) >> 3));
    std::__unwrap_and_dispatch[abi:ne180100]<std::__overload<std::__copy_loop<std::_ClassicAlgPolicy>,std::__copy_trivial>,std::map<ZinIrDimension,unsigned long> *,std::map<ZinIrDimension,unsigned long> *,std::map<ZinIrDimension,unsigned long> *,0>(a2, v13, v9);
    BOOL v12 = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::map<ZinIrDimension,unsigned long>>,std::map<ZinIrDimension,unsigned long>*,std::map<ZinIrDimension,unsigned long>*,std::map<ZinIrDimension,unsigned long>*>(v8, (uint64_t)v13, (uint64_t)a3, *(uint64_t **)(a1 + 8));
LABEL_11:
    *(void *)(a1 + 8) = v12;
    return;
  }
  std::__unwrap_and_dispatch[abi:ne180100]<std::__overload<std::__copy_loop<std::_ClassicAlgPolicy>,std::__copy_trivial>,std::map<ZinIrDimension,unsigned long> *,std::map<ZinIrDimension,unsigned long> *,std::map<ZinIrDimension,unsigned long> *,0>(a2, a3, v9);
  uint64_t v15 = v14;
  uint64_t v16 = *(void *)(a1 + 8);
  if (v16 != v14)
  {
    do
    {
      uint64_t v17 = v16 - 24;
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy(v16 - 24, *(void **)(v16 - 16));
      uint64_t v16 = v17;
    }
    while (v17 != v15);
  }
  *(void *)(a1 + 8) = v15;
}

void sub_211295DA4(_Unwind_Exception *a1)
{
  *(void *)(v1 + 8) = v2;
  _Unwind_Resume(a1);
}

void sub_211295DAC(_Unwind_Exception *a1)
{
  *(void *)(v1 + 8) = v2;
  _Unwind_Resume(a1);
}

uint64_t **std::__unwrap_and_dispatch[abi:ne180100]<std::__overload<std::__copy_loop<std::_ClassicAlgPolicy>,std::__copy_trivial>,std::map<ZinIrDimension,unsigned long> *,std::map<ZinIrDimension,unsigned long> *,std::map<ZinIrDimension,unsigned long> *,0>(uint64_t a1, uint64_t **a2, uint64_t **a3)
{
  uint64_t v4 = (uint64_t **)a1;
  if ((uint64_t **)a1 != a2)
  {
    uint64_t v6 = (void *)(a1 + 8);
    do
    {
      if (v4 != a3) {
        std::__tree<std::__value_type<ZinIrDimension,unsigned long>,std::__map_value_compare<ZinIrDimension,std::__value_type<ZinIrDimension,unsigned long>,std::less<ZinIrDimension>,true>,std::allocator<std::__value_type<ZinIrDimension,unsigned long>>>::__assign_multi<std::__tree_const_iterator<std::__value_type<ZinIrDimension,unsigned long>,std::__tree_node<std::__value_type<ZinIrDimension,unsigned long>,void *> *,long>>(a3, *v4, v6);
      }
      v4 += 3;
      a3 += 3;
      v6 += 3;
    }
    while (v4 != a2);
    return a2;
  }
  return v4;
}

uint64_t **std::__tree<std::__value_type<ZinIrDimension,unsigned long>,std::__map_value_compare<ZinIrDimension,std::__value_type<ZinIrDimension,unsigned long>,std::less<ZinIrDimension>,true>,std::allocator<std::__value_type<ZinIrDimension,unsigned long>>>::__assign_multi<std::__tree_const_iterator<std::__value_type<ZinIrDimension,unsigned long>,std::__tree_node<std::__value_type<ZinIrDimension,unsigned long>,void *> *,long>>(uint64_t **result, void *a2, void *a3)
{
  uint64_t v5 = result;
  if (result[2])
  {
    uint64_t v6 = *result;
    uint64_t v7 = result[1];
    void *result = (uint64_t *)(result + 1);
    v7[2] = 0;
    result[1] = 0;
    result[2] = 0;
    if (v6[1]) {
      uint64_t v8 = (uint64_t *)v6[1];
    }
    else {
      uint64_t v8 = v6;
    }
    uint64_t v14 = result;
    uint64_t v15 = v8;
    uint64_t v16 = v8;
    if (v8)
    {
      uint64_t v15 = std::__tree<ZinIrTensor *,ZinIrIdComparator<ZinIrTensor *>,std::allocator<ZinIrTensor *>>::_DetachedTreeCache::__detach_next((uint64_t)v8);
      if (a2 != a3)
      {
        uint64_t v9 = a2;
        do
        {
          *((_DWORD *)v8 + 8) = *((_DWORD *)v9 + 8);
          v8[5] = v9[5];
          std::__tree<std::__value_type<ZinIrDimension,unsigned long>,std::__map_value_compare<ZinIrDimension,std::__value_type<ZinIrDimension,unsigned long>,std::less<ZinIrDimension>,true>,std::allocator<std::__value_type<ZinIrDimension,unsigned long>>>::__node_insert_multi(v5, (uint64_t)v8);
          uint64_t v8 = v15;
          uint64_t v16 = v15;
          if (v15) {
            uint64_t v15 = std::__tree<ZinIrTensor *,ZinIrIdComparator<ZinIrTensor *>,std::allocator<ZinIrTensor *>>::_DetachedTreeCache::__detach_next((uint64_t)v15);
          }
          unint64_t v10 = (void *)v9[1];
          if (v10)
          {
            do
            {
              a2 = v10;
              unint64_t v10 = (void *)*v10;
            }
            while (v10);
          }
          else
          {
            do
            {
              a2 = (void *)v9[2];
              BOOL v11 = *a2 == (void)v9;
              uint64_t v9 = a2;
            }
            while (!v11);
          }
          if (!v8) {
            break;
          }
          uint64_t v9 = a2;
        }
        while (a2 != a3);
      }
    }
    uint64_t result = (uint64_t **)std::__tree<ZinIrTensor *,ZinIrIdComparator<ZinIrTensor *>,std::allocator<ZinIrTensor *>>::_DetachedTreeCache::~_DetachedTreeCache[abi:ne180100]((uint64_t)&v14);
  }
  if (a2 != a3)
  {
    do
    {
      uint64_t result = (uint64_t **)std::__tree<std::__value_type<ZinIrSection::SectType,ZinIrSection*>,std::__map_value_compare<ZinIrSection::SectType,std::__value_type<ZinIrSection::SectType,ZinIrSection*>,std::less<ZinIrSection::SectType>,true>,std::allocator<std::__value_type<ZinIrSection::SectType,ZinIrSection*>>>::__emplace_multi<std::pair<ZinIrSection::SectType const,ZinIrSection*>>(v5, (_OWORD *)a2 + 2);
      BOOL v12 = (void *)a2[1];
      if (v12)
      {
        do
        {
          uint64_t v13 = v12;
          BOOL v12 = (void *)*v12;
        }
        while (v12);
      }
      else
      {
        do
        {
          uint64_t v13 = (void *)a2[2];
          BOOL v11 = *v13 == (void)a2;
          a2 = v13;
        }
        while (!v11);
      }
      a2 = v13;
    }
    while (v13 != a3);
  }
  return result;
}

void sub_211295F80(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::__tree<ZinIrTensor *,ZinIrIdComparator<ZinIrTensor *>,std::allocator<ZinIrTensor *>>::_DetachedTreeCache::~_DetachedTreeCache[abi:ne180100]((uint64_t)va);
  _Unwind_Resume(a1);
}

uint64_t std::__tree<std::__value_type<ZinIrDimension,unsigned long>,std::__map_value_compare<ZinIrDimension,std::__value_type<ZinIrDimension,unsigned long>,std::less<ZinIrDimension>,true>,std::allocator<std::__value_type<ZinIrDimension,unsigned long>>>::__node_insert_multi(uint64_t **a1, uint64_t a2)
{
  uint64_t v3 = a1 + 1;
  uint64_t v4 = a1[1];
  if (v4)
  {
    do
    {
      while (1)
      {
        uint64_t v3 = (uint64_t **)v4;
        if (*(_DWORD *)(a2 + 32) >= *((_DWORD *)v4 + 8)) {
          break;
        }
        uint64_t v4 = (uint64_t *)*v4;
        uint64_t v5 = v3;
        if (!*v3) {
          goto LABEL_8;
        }
      }
      uint64_t v4 = (uint64_t *)v4[1];
    }
    while (v4);
    uint64_t v5 = v3 + 1;
  }
  else
  {
    uint64_t v5 = a1 + 1;
  }
LABEL_8:
  std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::__insert_node_at(a1, (uint64_t)v3, v5, (uint64_t *)a2);
  return a2;
}

void std::vector<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::__destroy_vector::operator()[abi:ne180100](void ***a1)
{
  uint64_t v1 = *a1;
  uint64_t v2 = (char *)**a1;
  if (v2)
  {
    uint64_t v4 = (char *)v1[1];
    uint64_t v5 = **a1;
    if (v4 != v2)
    {
      do
      {
        uint64_t v6 = v4 - 48;
        uint64_t v7 = (void **)(v4 - 32);
        std::vector<Subgraph>::__destroy_vector::operator()[abi:ne180100](&v7);
        uint64_t v4 = v6;
      }
      while (v6 != v2);
      uint64_t v5 = **a1;
    }
    v1[1] = v2;
    operator delete(v5);
  }
}

void *std::vector<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::__init_with_size[abi:ne180100]<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>*,std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>*>(void *result, uint64_t a2, uint64_t a3, unint64_t a4)
{
  if (a4)
  {
    uint64_t v6 = result;
    std::vector<std::deque<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>>>::__vallocate[abi:ne180100](result, a4);
    uint64_t result = (void *)std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>,std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>*,std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>*,std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>*>((uint64_t)(v6 + 2), a2, a3, v6[1]);
    v6[1] = result;
  }
  return result;
}

void sub_2112960E8(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, void **a9)
{
  *(void *)(v9 + 8) = v10;
  std::vector<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::__destroy_vector::operator()[abi:ne180100](&a9);
  _Unwind_Resume(a1);
}

uint64_t std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>,std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>*,std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>*,std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>*>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v4 = a4;
  uint64_t v10 = a4;
  uint64_t v11 = a4;
  v8[0] = a1;
  v8[1] = &v10;
  v8[2] = &v11;
  char v9 = 0;
  if (a2 != a3)
  {
    uint64_t v6 = a2;
    do
    {
      *(_OWORD *)uint64_t v4 = *(_OWORD *)v6;
      *(void *)(v4 + 16) = 0;
      *(void *)(v4 + 24) = 0;
      *(void *)(v4 + std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = 0;
      std::vector<Subgraph>::__init_with_size[abi:ne180100]<Subgraph*,Subgraph*>((void *)(v4 + 16), *(void *)(v6 + 16), *(void *)(v6 + 24), 0x86BCA1AF286BCA1BLL * ((uint64_t)(*(void *)(v6 + 24) - *(void *)(v6 + 16)) >> 3));
      *(_DWORD *)(v4 + 40) = *(_DWORD *)(v6 + 40);
      uint64_t v4 = v11 + 48;
      v11 += 48;
      v6 += 48;
    }
    while (v6 != a3);
  }
  char v9 = 1;
  std::__exception_guard_exceptions<std::_AllocatorDestroyRangeReverse<std::allocator<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>,std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>*>>::~__exception_guard_exceptions[abi:ne180100]((uint64_t)v8);
  return v4;
}

void sub_2112961CC(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
}

uint64_t std::__exception_guard_exceptions<std::_AllocatorDestroyRangeReverse<std::allocator<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>,std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>*>>::~__exception_guard_exceptions[abi:ne180100](uint64_t a1)
{
  if (!*(unsigned char *)(a1 + 24)) {
    std::_AllocatorDestroyRangeReverse<std::allocator<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>,std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>*>::operator()[abi:ne180100](a1);
  }
  return a1;
}

void std::_AllocatorDestroyRangeReverse<std::allocator<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>,std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>*>::operator()[abi:ne180100](uint64_t a1)
{
  uint64_t v1 = **(void **)(a1 + 16);
  uint64_t v2 = **(void **)(a1 + 8);
  if (v1 != v2)
  {
    do
    {
      uint64_t v3 = v1 - 48;
      uint64_t v4 = (void **)(v1 - 32);
      std::vector<Subgraph>::__destroy_vector::operator()[abi:ne180100](&v4);
      uint64_t v1 = v3;
    }
    while (v3 != v2);
  }
}

void *std::vector<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::__construct_one_at_end[abi:ne180100]<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult> const&>(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = *(void *)(a1 + 8);
  *(_OWORD *)uint64_t v4 = *(_OWORD *)a2;
  *(void *)(v4 + 24) = 0;
  *(void *)(v4 + std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = 0;
  *(void *)(v4 + 16) = 0;
  uint64_t result = std::vector<Subgraph>::__init_with_size[abi:ne180100]<Subgraph*,Subgraph*>((void *)(v4 + 16), *(void *)(a2 + 16), *(void *)(a2 + 24), 0x86BCA1AF286BCA1BLL * ((uint64_t)(*(void *)(a2 + 24) - *(void *)(a2 + 16)) >> 3));
  *(_DWORD *)(v4 + 40) = *(_DWORD *)(a2 + 40);
  *(void *)(a1 + 8) = v4 + 48;
  return result;
}

void sub_2112962EC(_Unwind_Exception *a1)
{
  *(void *)(v1 + 8) = v2;
  _Unwind_Resume(a1);
}

uint64_t std::vector<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::__push_back_slow_path<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult> const&>(uint64_t *a1, uint64_t a2)
{
  uint64_t v3 = *a1;
  unint64_t v4 = 0xAAAAAAAAAAAAAAABLL * ((a1[1] - *a1) >> 4);
  unint64_t v5 = v4 + 1;
  if (v4 + 1 > 0x555555555555555) {
    std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
  }
  uint64_t v7 = (uint64_t)(a1 + 2);
  unint64_t v8 = 0xAAAAAAAAAAAAAAABLL * ((a1[2] - v3) >> 4);
  if (2 * v8 > v5) {
    unint64_t v5 = 2 * v8;
  }
  if (v8 >= 0x2AAAAAAAAAAAAAALL) {
    unint64_t v9 = 0x555555555555555;
  }
  else {
    unint64_t v9 = v5;
  }
  uint64_t v17 = a1 + 2;
  if (v9) {
    uint64_t v10 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ANEDebugInfo::DebugInfoInMem::Group>>(v7, v9);
  }
  else {
    uint64_t v10 = 0;
  }
  uint64_t v11 = &v10[48 * v4];
  v14[0] = v10;
  v14[1] = v11;
  uint64_t v15 = v11;
  uint64_t v16 = &v10[48 * v9];
  *(_OWORD *)uint64_t v11 = *(_OWORD *)a2;
  *((void *)v11 + 3) = 0;
  *((void *)v11 + 4) = 0;
  *((void *)v11 + 2) = 0;
  std::vector<Subgraph>::__init_with_size[abi:ne180100]<Subgraph*,Subgraph*>((void *)v11 + 2, *(void *)(a2 + 16), *(void *)(a2 + 24), 0x86BCA1AF286BCA1BLL * ((uint64_t)(*(void *)(a2 + 24) - *(void *)(a2 + 16)) >> 3));
  *(_DWORD *)&v10[48 * v4 + 40] = *(_DWORD *)(a2 + 40);
  v15 += 48;
  std::vector<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::__swap_out_circular_buffer(a1, v14);
  uint64_t v12 = a1[1];
  std::__split_buffer<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::~__split_buffer(v14);
  return v12;
}

void sub_211296424(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::__split_buffer<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::~__split_buffer((void **)va);
  _Unwind_Resume(a1);
}

void std::vector<Subgraph>::__vdeallocate(void **a1)
{
  uint64_t v1 = *a1;
  if (*a1)
  {
    uint64_t v3 = (uint64_t)a1[1];
    unint64_t v4 = *a1;
    if ((void *)v3 != v1)
    {
      do
      {
        v3 -= 152;
        std::__destroy_at[abi:ne180100]<Subgraph,0>(v3);
      }
      while ((void *)v3 != v1);
      unint64_t v4 = *a1;
    }
    a1[1] = v1;
    operator delete(v4);
    *a1 = 0;
    a1[1] = 0;
    a1[2] = 0;
  }
}

void **std::vector<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::__append(uint64_t *a1, unint64_t a2)
{
  uint64_t v6 = a1[2];
  uint64_t result = (void **)(a1 + 2);
  uint64_t v5 = v6;
  uint64_t v7 = (uint64_t)*(result - 1);
  if (0xAAAAAAAAAAAAAAABLL * ((v6 - v7) >> 4) >= a2)
  {
    if (a2)
    {
      uint64_t v13 = v7 + 48 * a2;
      do
      {
        *(void *)uint64_t v7 = -1;
        *(void *)(v7 + 8) = -1;
        *(_OWORD *)(v7 + 16) = 0uLL;
        *(_OWORD *)(v7 + std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = 0uLL;
        v7 += 48;
      }
      while (v7 != v13);
      uint64_t v7 = v13;
    }
    a1[1] = v7;
  }
  else
  {
    unint64_t v8 = 0xAAAAAAAAAAAAAAABLL * ((v7 - *a1) >> 4);
    unint64_t v9 = v8 + a2;
    if (v8 + a2 > 0x555555555555555) {
      std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
    }
    unint64_t v10 = 0xAAAAAAAAAAAAAAABLL * ((v5 - *a1) >> 4);
    if (2 * v10 > v9) {
      unint64_t v9 = 2 * v10;
    }
    if (v10 >= 0x2AAAAAAAAAAAAAALL) {
      unint64_t v11 = 0x555555555555555;
    }
    else {
      unint64_t v11 = v9;
    }
    v16[4] = result;
    if (v11) {
      uint64_t v12 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ANEDebugInfo::DebugInfoInMem::Group>>((uint64_t)result, v11);
    }
    else {
      uint64_t v12 = 0;
    }
    uint64_t v14 = &v12[48 * v8];
    v16[0] = v12;
    v16[1] = v14;
    v16[3] = &v12[48 * v11];
    uint64_t v15 = &v14[48 * a2];
    do
    {
      *(void *)uint64_t v14 = -1;
      *((void *)v14 + 1) = -1;
      *((_OWORD *)v14 + 1) = 0uLL;
      *((_OWORD *)v14 + 2) = 0uLL;
      v14 += 48;
    }
    while (v14 != v15);
    void v16[2] = v15;
    std::vector<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::__swap_out_circular_buffer(a1, v16);
    return std::__split_buffer<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::~__split_buffer(v16);
  }
  return result;
}

void sub_2112965E0(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::__split_buffer<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::~__split_buffer((void **)va);
  _Unwind_Resume(a1);
}

uint64_t std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>::operator=[abi:ne180100](uint64_t a1, uint64_t a2)
{
  *(_OWORD *)a1 = *(_OWORD *)a2;
  if (a1 != a2) {
    std::vector<Subgraph>::__assign_with_size[abi:ne180100]<Subgraph*,Subgraph*>(a1 + 16, *(void *)(a2 + 16), *(void *)(a2 + 24), 0x86BCA1AF286BCA1BLL * ((uint64_t)(*(void *)(a2 + 24) - *(void *)(a2 + 16)) >> 3));
  }
  *(_DWORD *)(a1 + 40) = *(_DWORD *)(a2 + 40);
  return a1;
}

void std::vector<Subgraph>::__assign_with_size[abi:ne180100]<Subgraph*,Subgraph*>(uint64_t a1, uint64_t a2, uint64_t a3, unint64_t a4)
{
  uint64_t v8 = a1 + 16;
  unint64_t v9 = *(void **)a1;
  if (0x86BCA1AF286BCA1BLL * ((uint64_t)(*(void *)(a1 + 16) - *(void *)a1) >> 3) < a4)
  {
    std::vector<Subgraph>::__vdeallocate((void **)a1);
    if (a4 > 0x1AF286BCA1AF286) {
      std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
    }
    unint64_t v10 = 0xD79435E50D79436 * ((uint64_t)(*(void *)(a1 + 16) - *(void *)a1) >> 3);
    if (v10 <= a4) {
      unint64_t v10 = a4;
    }
    if (0x86BCA1AF286BCA1BLL * ((uint64_t)(*(void *)(a1 + 16) - *(void *)a1) >> 3) >= 0xD79435E50D7943) {
      unint64_t v11 = 0x1AF286BCA1AF286;
    }
    else {
      unint64_t v11 = v10;
    }
    std::vector<Subgraph>::__vallocate[abi:ne180100]((void *)a1, v11);
    uint64_t v12 = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<Subgraph>,Subgraph*,Subgraph*,Subgraph*>(v8, a2, a3, *(void *)(a1 + 8));
    goto LABEL_11;
  }
  if (0x86BCA1AF286BCA1BLL * ((uint64_t)(*(void *)(a1 + 8) - (void)v9) >> 3) < a4)
  {
    uint64_t v13 = a2 + 8 * ((uint64_t)(*(void *)(a1 + 8) - (void)v9) >> 3);
    std::__copy_loop<std::_ClassicAlgPolicy>::operator()[abi:ne180100]<Subgraph *,Subgraph *,Subgraph *>((uint64_t)&v17, a2, v13, (uint64_t)v9);
    uint64_t v12 = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<Subgraph>,Subgraph*,Subgraph*,Subgraph*>(v8, v13, a3, *(void *)(a1 + 8));
LABEL_11:
    *(void *)(a1 + 8) = v12;
    return;
  }
  std::__copy_loop<std::_ClassicAlgPolicy>::operator()[abi:ne180100]<Subgraph *,Subgraph *,Subgraph *>((uint64_t)&v18, a2, a3, (uint64_t)v9);
  uint64_t v15 = v14;
  uint64_t v16 = *(void *)(a1 + 8);
  if (v16 != v14)
  {
    do
    {
      v16 -= 152;
      std::__destroy_at[abi:ne180100]<Subgraph,0>(v16);
    }
    while (v16 != v15);
  }
  *(void *)(a1 + 8) = v15;
}

void sub_2112967EC(_Unwind_Exception *a1)
{
  *(void *)(v1 + 8) = v2;
  _Unwind_Resume(a1);
}

void sub_2112967F4(_Unwind_Exception *a1)
{
  *(void *)(v1 + 8) = v2;
  _Unwind_Resume(a1);
}

void std::__list_imp<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::clear(char *a1)
{
  if (*((void *)a1 + 2))
  {
    uint64_t v2 = *(void *)a1;
    uint64_t v3 = (char *)*((void *)a1 + 1);
    uint64_t v4 = *(void *)v3;
    *(void *)(v4 + 8) = *(void *)(*(void *)a1 + 8);
    **(void **)(v2 + 8) = v4;
    *((void *)a1 + 2) = 0;
    if (v3 != a1)
    {
      do
      {
        uint64_t v5 = (char *)*((void *)v3 + 1);
        uint64_t v6 = (void **)(v3 + 32);
        std::vector<Subgraph>::__destroy_vector::operator()[abi:ne180100](&v6);
        operator delete(v3);
        uint64_t v3 = v5;
      }
      while (v5 != a1);
    }
  }
}

uint64_t *std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::__init_with_size[abi:ne180100]<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>(uint64_t *result, ZinIrOpLayer ***a2, ZinIrOpLayer ***a3, unint64_t a4)
{
  if (a4)
  {
    uint64_t v6 = result;
    std::vector<std::string>::__vallocate[abi:ne180100](result, a4);
    uint64_t result = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>((uint64_t)(v6 + 2), a2, a3, (uint64_t *)v6[1]);
    v6[1] = (uint64_t)result;
  }
  return result;
}

void sub_2112968E8(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, void **a9)
{
  *(void *)(v9 + 8) = v10;
  std::vector<std::map<ZinIrDimension,unsigned long>>::__destroy_vector::operator()[abi:ne180100](&a9);
  _Unwind_Resume(a1);
}

uint64_t *std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>(uint64_t a1, ZinIrOpLayer ***a2, ZinIrOpLayer ***a3, uint64_t *a4)
{
  uint64_t v4 = a4;
  uint64_t v10 = a4;
  unint64_t v11 = a4;
  v8[0] = a1;
  v8[1] = &v10;
  v8[2] = &v11;
  char v9 = 0;
  if (a2 != a3)
  {
    uint64_t v6 = a2;
    do
    {
      std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::set[abi:ne180100](v4, v6);
      v6 += 3;
      uint64_t v4 = v11 + 3;
      v11 += 3;
    }
    while (v6 != a3);
  }
  char v9 = 1;
  std::__exception_guard_exceptions<std::_AllocatorDestroyRangeReverse<std::allocator<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>>::~__exception_guard_exceptions[abi:ne180100]((uint64_t)v8);
  return v4;
}

void sub_211296998(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
}

uint64_t std::__exception_guard_exceptions<std::_AllocatorDestroyRangeReverse<std::allocator<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>>::~__exception_guard_exceptions[abi:ne180100](uint64_t a1)
{
  if (!*(unsigned char *)(a1 + 24)) {
    std::_AllocatorDestroyRangeReverse<std::allocator<std::map<ZinIrDimension,unsigned long>>,std::map<ZinIrDimension,unsigned long>*>::operator()[abi:ne180100](a1);
  }
  return a1;
}

void IdentifyConnectedComponents(std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const&,std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>> &)::$_0::operator()(uint64_t a1, ZinIrOpLayer *a2, uint64_t *a3)
{
  uint64_t v8 = a2;
  if (0xAAAAAAAAAAAAAAABLL * ((a3[1] - *a3) >> 3) >= a1 + 1)
  {
    std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>((uint64_t **)(*a3 + 24 * a1), &v8, (uint64_t *)&v8);
  }
  else
  {
    v7[0] = 0;
    v7[1] = 0;
    uint64_t v6 = (uint64_t *)v7;
    std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>(&v6, &v8, (uint64_t *)&v8);
    unint64_t v4 = a3[1];
    if (v4 >= a3[2])
    {
      uint64_t v5 = std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::__push_back_slow_path<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const&>(a3, (ZinIrOpLayer ***)&v6);
    }
    else
    {
      std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::set[abi:ne180100]((uint64_t *)a3[1], (ZinIrOpLayer ***)&v6);
      uint64_t v5 = v4 + 24;
      a3[1] = v4 + 24;
    }
    a3[1] = v5;
    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v6, v7[0]);
  }
}

void sub_211296AB4(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, void *a10)
{
  *(void *)(v10 + 8) = v11;
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&a9, a10);
  _Unwind_Resume(a1);
}

void *std::__hash_table<std::__hash_value_type<ZinIrOpLayer *,unsigned long>,std::__unordered_map_hasher<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,unsigned long>,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,true>,std::__unordered_map_equal<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,unsigned long>,std::equal_to<ZinIrOpLayer *>,std::hash<ZinIrOpLayer *>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer *,unsigned long>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::pair<ZinIrOpLayer *,unsigned long>>(uint64_t a1, void *a2, void *a3)
{
  unint64_t v6 = 0x9DDFEA08EB382D69 * ((8 * *a2 + 8) ^ HIDWORD(*a2));
  unint64_t v7 = 0x9DDFEA08EB382D69 * (HIDWORD(*a2) ^ (v6 >> 47) ^ v6);
  unint64_t v8 = 0x9DDFEA08EB382D69 * (v7 ^ (v7 >> 47));
  unint64_t v9 = *(void *)(a1 + 8);
  if (v9)
  {
    uint8x8_t v10 = (uint8x8_t)vcnt_s8((int8x8_t)v9);
    v10.i16[0] = vaddlv_u8(v10);
    if (v10.u32[0] > 1uLL)
    {
      unint64_t v3 = 0x9DDFEA08EB382D69 * (v7 ^ (v7 >> 47));
      if (v8 >= v9) {
        unint64_t v3 = v8 % v9;
      }
    }
    else
    {
      unint64_t v3 = v8 & (v9 - 1);
    }
    uint64_t v11 = *(void ***)(*(void *)a1 + 8 * v3);
    if (v11)
    {
      for (uint64_t i = *v11; i; uint64_t i = (void *)*i)
      {
        unint64_t v13 = i[1];
        if (v13 == v8)
        {
          if (i[2] == *a2) {
            return i;
          }
        }
        else
        {
          if (v10.u32[0] > 1uLL)
          {
            if (v13 >= v9) {
              v13 %= v9;
            }
          }
          else
          {
            v13 &= v9 - 1;
          }
          if (v13 != v3) {
            break;
          }
        }
      }
    }
  }
  uint64_t i = operator new(0x20uLL);
  *uint64_t i = 0;
  i[1] = v8;
  uint64_t v14 = a3[1];
  i[2] = *a3;
  i[3] = v14;
  float v15 = (float)(unint64_t)(*(void *)(a1 + 24) + 1);
  float v16 = *(float *)(a1 + 32);
  if (!v9 || (float)(v16 * (float)v9) < v15)
  {
    BOOL v17 = 1;
    if (v9 >= 3) {
      BOOL v17 = (v9 & (v9 - 1)) != 0;
    }
    unint64_t v18 = v17 | (2 * v9);
    unint64_t v19 = vcvtps_u32_f32(v15 / v16);
    if (v18 <= v19) {
      size_t v20 = v19;
    }
    else {
      size_t v20 = v18;
    }
    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::__rehash<true>(a1, v20);
    unint64_t v9 = *(void *)(a1 + 8);
    if ((v9 & (v9 - 1)) != 0)
    {
      if (v8 >= v9) {
        unint64_t v3 = v8 % v9;
      }
      else {
        unint64_t v3 = v8;
      }
    }
    else
    {
      unint64_t v3 = (v9 - 1) & v8;
    }
  }
  uint64_t v21 = *(void *)a1;
  unint64_t v22 = *(void **)(*(void *)a1 + 8 * v3);
  if (v22)
  {
    *uint64_t i = *v22;
LABEL_38:
    *unint64_t v22 = i;
    goto LABEL_39;
  }
  *uint64_t i = *(void *)(a1 + 16);
  *(void *)(a1 + 16) = i;
  *(void *)(v21 + 8 * v3) = a1 + 16;
  if (*i)
  {
    unint64_t v23 = *(void *)(*i + 8);
    if ((v9 & (v9 - 1)) != 0)
    {
      if (v23 >= v9) {
        v23 %= v9;
      }
    }
    else
    {
      v23 &= v9 - 1;
    }
    unint64_t v22 = (void *)(*(void *)a1 + 8 * v23);
    goto LABEL_38;
  }
LABEL_39:
  ++*(void *)(a1 + 24);
  return i;
}

void sub_211296D18(_Unwind_Exception *a1)
{
  operator delete(v1);
  _Unwind_Resume(a1);
}

uint64_t std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::__swap_out_circular_buffer(uint64_t *a1, void *a2)
{
  uint64_t result = std::__uninitialized_allocator_move_if_noexcept[abi:ne180100]<std::allocator<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>,std::reverse_iterator<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>,std::reverse_iterator<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>,std::reverse_iterator<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>>((uint64_t)(a1 + 2), a1[1], a1[1], *a1, *a1, a2[1], a2[1]);
  a2[1] = v5;
  uint64_t v6 = *a1;
  *a1 = v5;
  a2[1] = v6;
  uint64_t v7 = a1[1];
  a1[1] = a2[2];
  a2[2] = v7;
  uint64_t v8 = a1[2];
  a1[2] = a2[3];
  a2[3] = v8;
  *a2 = a2[1];
  return result;
}

uint64_t std::__uninitialized_allocator_move_if_noexcept[abi:ne180100]<std::allocator<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>,std::reverse_iterator<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>,std::reverse_iterator<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>,std::reverse_iterator<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  uint64_t v7 = a7;
  *(void *)&long long v19 = a6;
  *((void *)&v19 + 1) = a7;
  long long v18 = v19;
  v16[0] = a1;
  v16[1] = &v18;
  void v16[2] = &v19;
  if (a3 == a5)
  {
    uint64_t v14 = a6;
  }
  else
  {
    uint64_t v8 = a3;
    do
    {
      uint64_t v9 = *(void *)(v8 - 24);
      v8 -= 24;
      *(void *)(v7 - 24) = v9;
      uint8x8_t v10 = (void *)(a3 - 16);
      uint64_t v11 = *(void *)(a3 - 16);
      *(void *)(v7 - 16) = v11;
      uint64_t v12 = v7 - 16;
      uint64_t v13 = *(void *)(a3 - 8);
      *(void *)(v7 - 8) = v13;
      if (v13)
      {
        *(void *)(v11 + 16) = v12;
        *(void *)(a3 - 24) = v10;
        *uint8x8_t v10 = 0;
        *(void *)(a3 - 8) = 0;
      }
      else
      {
        *(void *)(v7 - 24) = v12;
      }
      uint64_t v7 = *((void *)&v19 + 1) - 24;
      *((void *)&v19 + 1) -= 24;
      a3 = v8;
    }
    while (v8 != a5);
    uint64_t v14 = v19;
  }
  char v17 = 1;
  std::__exception_guard_exceptions<std::_AllocatorDestroyRangeReverse<std::allocator<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>,std::reverse_iterator<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>>>::~__exception_guard_exceptions[abi:ne180100]((uint64_t)v16);
  return v14;
}

uint64_t std::__exception_guard_exceptions<std::_AllocatorDestroyRangeReverse<std::allocator<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>,std::reverse_iterator<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>>>::~__exception_guard_exceptions[abi:ne180100](uint64_t a1)
{
  if (!*(unsigned char *)(a1 + 24)) {
    std::_AllocatorDestroyRangeReverse<std::allocator<std::map<ZinIrDimension,unsigned long>>,std::reverse_iterator<std::map<ZinIrDimension,unsigned long>*>>::operator()[abi:ne180100](a1);
  }
  return a1;
}

uint64_t std::deque<std::pair<ZinIrOpLayer *,ZinIrOpLayer *>>::~deque[abi:ne180100](void *a1)
{
  uint64_t v2 = (void **)a1[1];
  unint64_t v3 = (void **)a1[2];
  a1[5] = 0;
  unint64_t v4 = (char *)v3 - (char *)v2;
  if ((unint64_t)((char *)v3 - (char *)v2) >= 0x11)
  {
    do
    {
      operator delete(*v2);
      unint64_t v3 = (void **)a1[2];
      uint64_t v2 = (void **)(a1[1] + 8);
      a1[1] = v2;
      unint64_t v4 = (char *)v3 - (char *)v2;
    }
    while ((unint64_t)((char *)v3 - (char *)v2) > 0x10);
  }
  unint64_t v5 = v4 >> 3;
  if (v5 == 1)
  {
    uint64_t v6 = 128;
  }
  else
  {
    if (v5 != 2) {
      goto LABEL_9;
    }
    uint64_t v6 = 256;
  }
  a1[4] = v6;
LABEL_9:
  while (v2 != v3)
  {
    uint64_t v7 = *v2++;
    operator delete(v7);
  }

  return std::__split_buffer<unsigned long *>::~__split_buffer((uint64_t)a1);
}

void *std::vector<std::vector<BOOL>>::vector(void *a1, unint64_t a2)
{
  *a1 = 0;
  a1[1] = 0;
  a1[2] = 0;
  if (a2)
  {
    std::vector<std::string>::__vallocate[abi:ne180100](a1, a2);
    unint64_t v4 = (char *)a1[1];
    size_t v5 = 24 * ((24 * a2 - 24) / 0x18) + 24;
    bzero(v4, v5);
    a1[1] = &v4[v5];
  }
  return a1;
}

void sub_211296FD8(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, void **a9)
{
}

void std::vector<std::vector<BOOL>>::__destroy_vector::operator()[abi:ne180100](void ***a1)
{
  uint64_t v2 = *a1;
  if (*v2)
  {
    std::vector<std::vector<BOOL>>::__clear[abi:ne180100]((uint64_t *)v2);
    unint64_t v3 = **a1;
    operator delete(v3);
  }
}

void std::vector<std::vector<BOOL>>::__clear[abi:ne180100](uint64_t *a1)
{
  uint64_t v2 = *a1;
  for (uint64_t i = a1[1]; i != v2; i -= 24)
  {
    size_t v5 = *(void **)(i - 24);
    unint64_t v4 = v5;
    if (v5) {
      operator delete(v4);
    }
  }
  a1[1] = v2;
}

void std::vector<std::vector<BOOL>>::__vdeallocate(uint64_t *a1)
{
  if (*a1)
  {
    std::vector<std::vector<BOOL>>::__clear[abi:ne180100](a1);
    operator delete((void *)*a1);
    *a1 = 0;
    a1[1] = 0;
    a1[2] = 0;
  }
}

uint64_t *std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const*,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const*,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>(uint64_t a1, ZinIrOpLayer ***a2, ZinIrOpLayer ***a3, uint64_t *a4)
{
  unint64_t v4 = a4;
  uint8x8_t v10 = a4;
  uint64_t v11 = a4;
  v8[0] = a1;
  v8[1] = &v10;
  v8[2] = &v11;
  char v9 = 0;
  if (a2 != a3)
  {
    uint64_t v6 = a2;
    do
    {
      std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::set[abi:ne180100](v4, v6);
      v6 += 3;
      unint64_t v4 = v11 + 3;
      v11 += 3;
    }
    while (v6 != a3);
  }
  char v9 = 1;
  std::__exception_guard_exceptions<std::_AllocatorDestroyRangeReverse<std::allocator<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>>::~__exception_guard_exceptions[abi:ne180100]((uint64_t)v8);
  return v4;
}

void sub_211297154(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
}

void *std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::__move_range(uint64_t a1, void *a2, unint64_t a3, uint64_t a4)
{
  uint64_t v6 = *(void *)(a1 + 8);
  uint64_t v7 = (void *)((char *)a2 + v6 - a4);
  uint64_t v8 = v6;
  if ((unint64_t)v7 < a3)
  {
    uint64_t v9 = 0;
    do
    {
      uint8x8_t v10 = (uint64_t *)(v6 + v9 * 8);
      *uint8x8_t v10 = v7[v9];
      uint64_t v11 = &v7[v9 + 1];
      uint64_t v12 = *v11;
      *(void *)(v6 + v9 * 8 + 8) = *v11;
      uint64_t v13 = v6 + v9 * 8 + 8;
      uint64_t v14 = v7[v9 + 2];
      v10[2] = v14;
      if (v14)
      {
        *(void *)(v12 + 16) = v13;
        v7[v9] = v11;
        uint64_t *v11 = 0;
        v7[v9 + 2] = 0;
      }
      else
      {
        *uint8x8_t v10 = v13;
      }
      v9 += 3;
    }
    while ((unint64_t)&v7[v9] < a3);
    uint64_t v8 = v6 + v9 * 8;
  }
  *(void *)(a1 + 8) = v8;
  return std::__unwrap_and_dispatch[abi:ne180100]<std::__overload<std::__move_backward_loop<std::_ClassicAlgPolicy>,std::__move_backward_trivial>,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> *,0>(a2, v7, v6);
}

uint64_t *std::__split_buffer<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::emplace_back<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const>(void *a1, ZinIrOpLayer ***a2)
{
  unint64_t v4 = (char *)a1[2];
  if (v4 == (char *)a1[3])
  {
    uint64_t v6 = (unsigned char *)*a1;
    size_t v5 = (void *)a1[1];
    if ((unint64_t)v5 <= *a1)
    {
      uint64_t v11 = v4 - v6;
      BOOL v10 = v11 == 0;
      uint64_t v12 = 0x5555555555555556 * (v11 >> 3);
      if (v10) {
        unint64_t v13 = 1;
      }
      else {
        unint64_t v13 = v12;
      }
      unint64_t v14 = v13 >> 2;
      uint64_t v37 = a1[4];
      float v15 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<std::string>>(v37, v13);
      float v16 = &v15[24 * v14];
      long long v18 = &v15[24 * v17];
      unint64_t v19 = a1[1];
      uint64_t v20 = a1[2];
      uint64_t v21 = v20 - v19;
      if (v20 == v19)
      {
        int64x2_t v31 = vdupq_n_s64(v19);
        unint64_t v24 = &v15[24 * v14];
      }
      else
      {
        uint64_t v22 = 0;
        uint64_t v23 = v21 / 24;
        unint64_t v24 = &v16[24 * v23];
        uint64_t v25 = 24 * v23;
        do
        {
          int v26 = (uint64_t *)&v16[v22];
          *int v26 = *(void *)(v19 + v22);
          unint64_t v27 = (uint64_t *)(v19 + v22 + 8);
          uint64_t v28 = *v27;
          *(void *)&v16[v22 + 8] = *v27;
          uint64_t v29 = (uint64_t)&v16[v22 + 8];
          uint64_t v30 = *(void *)(v19 + v22 + 16);
          void v26[2] = v30;
          if (v30)
          {
            *(void *)(v28 + 16) = v29;
            *(void *)(v19 + v22) = v27;
            *unint64_t v27 = 0;
            *(void *)(v19 + v22 + 16) = 0;
          }
          else
          {
            *int v26 = v29;
          }
          v22 += 24;
        }
        while (v25 != v22);
        int64x2_t v31 = *(int64x2_t *)(a1 + 1);
      }
      BOOL v34 = (unsigned char *)*a1;
      *a1 = v15;
      a1[1] = v16;
      int64x2_t v35 = v31;
      uint64_t v32 = a1[3];
      a1[2] = v24;
      a1[3] = v18;
      uint64_t v36 = v32;
      std::__split_buffer<std::map<ZinIrDimension,unsigned long>>::~__split_buffer((void **)&v34);
      unint64_t v4 = (char *)a1[2];
    }
    else
    {
      int64_t v7 = 0xAAAAAAAAAAAAAAABLL * (((uint64_t)v5 - *a1) >> 3);
      if (v7 >= -1) {
        uint64_t v8 = v7 + 1;
      }
      else {
        uint64_t v8 = v7 + 2;
      }
      uint64_t v9 = -3 * (v8 >> 1);
      std::__unwrap_and_dispatch[abi:ne180100]<std::__overload<std::__move_loop<std::_ClassicAlgPolicy>,std::__move_trivial>,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> *,0>(v5, v4, (uint64_t)&v5[-3 * (v8 >> 1)]);
      a1[1] += 8 * v9;
      a1[2] = v4;
    }
  }
  uint64_t result = std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::set[abi:ne180100]((uint64_t *)v4, a2);
  a1[2] += 24;
  return result;
}

uint64_t std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::__swap_out_circular_buffer(uint64_t *a1, void *a2, uint64_t a3)
{
  uint64_t v6 = a2[1];
  uint64_t v7 = (uint64_t)(a1 + 2);
  std::__uninitialized_allocator_move_if_noexcept[abi:ne180100]<std::allocator<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>,std::reverse_iterator<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>,std::reverse_iterator<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>,std::reverse_iterator<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>>((uint64_t)(a1 + 2), a3, a3, *a1, *a1, v6, v6);
  a2[1] = v8;
  a2[2] = std::__uninitialized_allocator_move_if_noexcept[abi:ne180100]<std::allocator<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>(v7, a3, a1[1], a2[2]);
  uint64_t v9 = *a1;
  *a1 = a2[1];
  a2[1] = v9;
  uint64_t v10 = a1[1];
  a1[1] = a2[2];
  a2[2] = v10;
  uint64_t v11 = a1[2];
  a1[2] = a2[3];
  a2[3] = v11;
  *a2 = a2[1];
  return v6;
}

void *std::__unwrap_and_dispatch[abi:ne180100]<std::__overload<std::__move_backward_loop<std::_ClassicAlgPolicy>,std::__move_backward_trivial>,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> *,0>(void *a1, void *a2, uint64_t a3)
{
  if (a2 != a1)
  {
    uint64_t v6 = a2;
    do
    {
      v6 -= 3;
      a3 -= 24;
      std::__tree<ZinSpaceRange>::__move_assign(a3, v6);
    }
    while (v6 != a1);
  }
  return a2;
}

void *std::__unwrap_and_dispatch[abi:ne180100]<std::__overload<std::__move_loop<std::_ClassicAlgPolicy>,std::__move_trivial>,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> *,0>(void *a1, void *a2, uint64_t a3)
{
  unint64_t v4 = a1;
  if (a1 != a2)
  {
    do
    {
      std::__tree<ZinSpaceRange>::__move_assign(a3, v4);
      v4 += 3;
      a3 += 24;
    }
    while (v4 != a2);
    return a2;
  }
  return v4;
}

uint64_t std::__uninitialized_allocator_move_if_noexcept[abi:ne180100]<std::allocator<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v4 = a4;
  uint64_t v15 = a4;
  uint64_t v14 = a4;
  v12[0] = a1;
  v12[1] = &v14;
  void v12[2] = &v15;
  if (a2 != a3)
  {
    uint64_t v5 = 0;
    do
    {
      uint64_t v6 = (uint64_t *)(a4 + v5);
      uint64_t *v6 = *(void *)(a2 + v5);
      uint64_t v7 = (uint64_t *)(a2 + v5 + 8);
      uint64_t v8 = *v7;
      *(void *)(a4 + v5 + 8) = *v7;
      uint64_t v9 = a4 + v5 + 8;
      uint64_t v10 = *(void *)(a2 + v5 + 16);
      v6[2] = v10;
      if (v10)
      {
        *(void *)(v8 + 16) = v9;
        *(void *)(a2 + v5) = v7;
        uint64_t *v7 = 0;
        *(void *)(a2 + v5 + 16) = 0;
      }
      else
      {
        uint64_t *v6 = v9;
      }
      v5 += 24;
    }
    while (a2 + v5 != a3);
    uint64_t v4 = a4 + v5;
    uint64_t v15 = a4 + v5;
  }
  char v13 = 1;
  std::__exception_guard_exceptions<std::_AllocatorDestroyRangeReverse<std::allocator<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>>::~__exception_guard_exceptions[abi:ne180100]((uint64_t)v12);
  return v4;
}

void *std::__unwrap_and_dispatch[abi:ne180100]<std::__overload<std::__move_loop<std::_ClassicAlgPolicy>,std::__move_trivial>,std::__wrap_iter<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> *>,std::__wrap_iter<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> *>,std::back_insert_iterator<std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>>,0>(void *a1, void *a2, uint64_t *a3)
{
  unint64_t v3 = a1;
  uint64_t v6 = a3;
  if (a1 == a2) {
    return a1;
  }
  uint64_t v4 = a2;
  do
  {
    std::back_insert_iterator<std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>>::operator=[abi:ne180100](&v6, v3);
    v3 += 3;
  }
  while (v3 != v4);
  return v4;
}

uint64_t **std::back_insert_iterator<std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>>::operator=[abi:ne180100](uint64_t **a1, void *a2)
{
  unint64_t v3 = *a1;
  uint64_t v4 = (void *)(*a1)[1];
  if ((unint64_t)v4 >= (*a1)[2])
  {
    uint64_t v9 = std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::__push_back_slow_path<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>(*a1, a2);
  }
  else
  {
    *uint64_t v4 = *a2;
    uint64_t v5 = a2 + 1;
    uint64_t v6 = a2[1];
    v4[1] = v6;
    uint64_t v7 = v4 + 1;
    uint64_t v8 = a2[2];
    v4[2] = v8;
    if (v8)
    {
      *(void *)(v6 + 16) = v7;
      *a2 = v5;
      *uint64_t v5 = 0;
      a2[2] = 0;
    }
    else
    {
      *uint64_t v4 = v7;
    }
    uint64_t v9 = (uint64_t)(v4 + 3);
  }
  v3[1] = v9;
  return a1;
}

uint64_t std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::__push_back_slow_path<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>(uint64_t *a1, void *a2)
{
  uint64_t v3 = *a1;
  unint64_t v4 = 0xAAAAAAAAAAAAAAABLL * ((a1[1] - *a1) >> 3);
  unint64_t v5 = v4 + 1;
  if (v4 + 1 > 0xAAAAAAAAAAAAAAALL) {
    std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
  }
  uint64_t v7 = (uint64_t)(a1 + 2);
  unint64_t v8 = 0xAAAAAAAAAAAAAAABLL * ((a1[2] - v3) >> 3);
  if (2 * v8 > v5) {
    unint64_t v5 = 2 * v8;
  }
  if (v8 >= 0x555555555555555) {
    unint64_t v9 = 0xAAAAAAAAAAAAAAALL;
  }
  else {
    unint64_t v9 = v5;
  }
  v18[4] = a1 + 2;
  if (v9) {
    uint64_t v10 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<std::string>>(v7, v9);
  }
  else {
    uint64_t v10 = 0;
  }
  uint64_t v11 = &v10[24 * v4];
  v18[0] = v10;
  v18[1] = v11;
  v18[3] = &v10[24 * v9];
  *(void *)uint64_t v11 = *a2;
  uint64_t v12 = a2 + 1;
  uint64_t v13 = a2[1];
  *((void *)v11 + 1) = v13;
  uint64_t v14 = v11 + 8;
  uint64_t v15 = a2[2];
  *((void *)v11 + 2) = v15;
  if (v15)
  {
    *(void *)(v13 + 16) = v14;
    *a2 = v12;
    *uint64_t v12 = 0;
    a2[2] = 0;
  }
  else
  {
    *(void *)uint64_t v11 = v14;
  }
  v18[2] = v11 + 24;
  std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::__swap_out_circular_buffer(a1, v18);
  uint64_t v16 = a1[1];
  std::__split_buffer<std::map<ZinIrDimension,unsigned long>>::~__split_buffer(v18);
  return v16;
}

void sub_2112977A4(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::__split_buffer<std::map<ZinIrDimension,unsigned long>>::~__split_buffer((void **)va);
  _Unwind_Resume(a1);
}

uint64_t std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::__push_back_slow_path<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const&>(uint64_t *a1, ZinIrOpLayer ***a2)
{
  uint64_t v3 = *a1;
  unint64_t v4 = 0xAAAAAAAAAAAAAAABLL * ((a1[1] - *a1) >> 3);
  unint64_t v5 = v4 + 1;
  if (v4 + 1 > 0xAAAAAAAAAAAAAAALL) {
    std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
  }
  uint64_t v7 = (uint64_t)(a1 + 2);
  unint64_t v8 = 0xAAAAAAAAAAAAAAABLL * ((a1[2] - v3) >> 3);
  if (2 * v8 > v5) {
    unint64_t v5 = 2 * v8;
  }
  if (v8 >= 0x555555555555555) {
    unint64_t v9 = 0xAAAAAAAAAAAAAAALL;
  }
  else {
    unint64_t v9 = v5;
  }
  uint64_t v17 = a1 + 2;
  if (v9) {
    uint64_t v10 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<std::string>>(v7, v9);
  }
  else {
    uint64_t v10 = 0;
  }
  uint64_t v13 = v10;
  uint64_t v14 = (uint64_t *)&v10[24 * v4];
  uint64_t v16 = &v10[24 * v9];
  std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::set[abi:ne180100](v14, a2);
  uint64_t v15 = v14 + 3;
  std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::__swap_out_circular_buffer(a1, &v13);
  uint64_t v11 = a1[1];
  std::__split_buffer<std::map<ZinIrDimension,unsigned long>>::~__split_buffer(&v13);
  return v11;
}

void sub_2112978AC(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::__split_buffer<std::map<ZinIrDimension,unsigned long>>::~__split_buffer((void **)va);
  _Unwind_Resume(a1);
}

uint64_t std::deque<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::~deque[abi:ne180100](void *a1)
{
  uint64_t v2 = (void **)a1[1];
  uint64_t v3 = (void **)a1[2];
  if (v3 == v2)
  {
    unint64_t v4 = a1 + 5;
    uint64_t v3 = (void **)a1[1];
  }
  else
  {
    unint64_t v4 = a1 + 5;
    unint64_t v5 = a1[4];
    uint64_t v6 = &v2[v5 / 0xAA];
    uint64_t v7 = (uint64_t)*v6 + 24 * (v5 % 0xAA);
    unint64_t v8 = (unint64_t)v2[(a1[5] + v5) / 0xAA] + 24 * ((a1[5] + v5) % 0xAA);
    if (v7 != v8)
    {
      do
      {
        std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy(v7, *(void **)(v7 + 8));
        v7 += 24;
        if (v7 - (void)*v6 == 4080)
        {
          uint64_t v9 = (uint64_t)v6[1];
          ++v6;
          uint64_t v7 = v9;
        }
      }
      while (v7 != v8);
      uint64_t v2 = (void **)a1[1];
      uint64_t v3 = (void **)a1[2];
    }
  }
  *unint64_t v4 = 0;
  unint64_t v10 = (char *)v3 - (char *)v2;
  if ((unint64_t)((char *)v3 - (char *)v2) >= 0x11)
  {
    do
    {
      operator delete(*v2);
      uint64_t v3 = (void **)a1[2];
      uint64_t v2 = (void **)(a1[1] + 8);
      a1[1] = v2;
      unint64_t v10 = (char *)v3 - (char *)v2;
    }
    while ((unint64_t)((char *)v3 - (char *)v2) > 0x10);
  }
  unint64_t v11 = v10 >> 3;
  if (v11 == 1)
  {
    uint64_t v12 = 85;
  }
  else
  {
    if (v11 != 2) {
      goto LABEL_16;
    }
    uint64_t v12 = 170;
  }
  a1[4] = v12;
LABEL_16:
  while (v2 != v3)
  {
    uint64_t v13 = *v2++;
    operator delete(v13);
  }

  return std::__split_buffer<unsigned long *>::~__split_buffer((uint64_t)a1);
}

void std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::__assign_with_size[abi:ne180100]<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>(uint64_t a1, ZinIrOpLayer ***a2, ZinIrOpLayer ***a3, unint64_t a4)
{
  uint64_t v8 = a1 + 16;
  uint64_t v9 = *(uint64_t ***)a1;
  if (0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*(void *)(a1 + 16) - *(void *)a1) >> 3) < a4)
  {
    std::vector<std::map<ZinIrDimension,unsigned long>>::__vdeallocate((void **)a1);
    if (a4 > 0xAAAAAAAAAAAAAAALL) {
      std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
    }
    unint64_t v10 = 0x5555555555555556 * ((uint64_t)(*(void *)(a1 + 16) - *(void *)a1) >> 3);
    if (v10 <= a4) {
      unint64_t v10 = a4;
    }
    if (0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*(void *)(a1 + 16) - *(void *)a1) >> 3) >= 0x555555555555555) {
      unint64_t v11 = 0xAAAAAAAAAAAAAAALL;
    }
    else {
      unint64_t v11 = v10;
    }
    std::vector<std::string>::__vallocate[abi:ne180100]((void *)a1, v11);
    uint64_t v12 = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>(v8, a2, a3, *(uint64_t **)(a1 + 8));
    goto LABEL_11;
  }
  if (0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*(void *)(a1 + 8) - (void)v9) >> 3) < a4)
  {
    uint64_t v13 = (uint64_t **)&a2[(uint64_t)(*(void *)(a1 + 8) - (void)v9) >> 3];
    std::__unwrap_and_dispatch[abi:ne180100]<std::__overload<std::__copy_loop<std::_ClassicAlgPolicy>,std::__copy_trivial>,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> *,0>((uint64_t)a2, v13, v9);
    uint64_t v12 = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>(v8, (ZinIrOpLayer ***)v13, a3, *(uint64_t **)(a1 + 8));
LABEL_11:
    *(void *)(a1 + 8) = v12;
    return;
  }
  std::__unwrap_and_dispatch[abi:ne180100]<std::__overload<std::__copy_loop<std::_ClassicAlgPolicy>,std::__copy_trivial>,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> *,0>((uint64_t)a2, (uint64_t **)a3, v9);
  uint64_t v15 = v14;
  uint64_t v16 = *(void *)(a1 + 8);
  if (v16 != v14)
  {
    do
    {
      uint64_t v17 = v16 - 24;
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy(v16 - 24, *(void **)(v16 - 16));
      uint64_t v16 = v17;
    }
    while (v17 != v15);
  }
  *(void *)(a1 + 8) = v15;
}

void sub_211297B78(_Unwind_Exception *a1)
{
  *(void *)(v1 + 8) = v2;
  _Unwind_Resume(a1);
}

void sub_211297B80(_Unwind_Exception *a1)
{
  *(void *)(v1 + 8) = v2;
  _Unwind_Resume(a1);
}

uint64_t **std::__unwrap_and_dispatch[abi:ne180100]<std::__overload<std::__copy_loop<std::_ClassicAlgPolicy>,std::__copy_trivial>,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> *,0>(uint64_t a1, uint64_t **a2, uint64_t **a3)
{
  unint64_t v4 = (uint64_t **)a1;
  if ((uint64_t **)a1 != a2)
  {
    uint64_t v6 = (void *)(a1 + 8);
    do
    {
      if (v4 != a3) {
        std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__assign_multi<std::__tree_const_iterator<ZinIrOpLayer *,std::__tree_node<ZinIrOpLayer *,void *> *,long>>(a3, *v4, v6);
      }
      v4 += 3;
      a3 += 3;
      v6 += 3;
    }
    while (v4 != a2);
    return a2;
  }
  return v4;
}

uint64_t **std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::__insert_with_size[abi:ne180100]<std::__wrap_iter<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>,std::__wrap_iter<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>>(uint64_t *a1, uint64_t **a2, ZinIrOpLayer ***a3, ZinIrOpLayer ***a4, uint64_t a5)
{
  unint64_t v5 = a2;
  if (a5 >= 1)
  {
    uint64_t v7 = a3;
    uint64_t v11 = a1[2];
    uint64_t v9 = (uint64_t)(a1 + 2);
    uint64_t v10 = v11;
    unint64_t v12 = *(void *)(v9 - 8);
    if ((uint64_t)(0xAAAAAAAAAAAAAAABLL * ((uint64_t)(v11 - v12) >> 3)) >= a5)
    {
      uint64_t v20 = v12 - (void)a2;
      if ((uint64_t)(0xAAAAAAAAAAAAAAABLL * ((uint64_t)(v12 - (void)a2) >> 3)) >= a5)
      {
        uint64_t v21 = &a3[3 * a5];
      }
      else
      {
        uint64_t v21 = &a3[(uint64_t)(v12 - (void)a2) >> 3];
        a1[1] = (uint64_t)std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>*>(v9, v21, a4, *(uint64_t **)(v9 - 8));
        if (v20 < 1) {
          return v5;
        }
      }
      std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::__move_range((uint64_t)a1, v5, v12, (uint64_t)&v5[3 * a5]);
      std::__unwrap_and_dispatch[abi:ne180100]<std::__overload<std::__copy_loop<std::_ClassicAlgPolicy>,std::__copy_trivial>,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> *,0>((uint64_t)v7, (uint64_t **)v21, v5);
    }
    else
    {
      uint64_t v13 = *a1;
      unint64_t v14 = a5 - 0x5555555555555555 * ((uint64_t)(v12 - *a1) >> 3);
      if (v14 > 0xAAAAAAAAAAAAAAALL) {
        std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
      }
      unint64_t v15 = 0xAAAAAAAAAAAAAAABLL * (((uint64_t)a2 - v13) >> 3);
      unint64_t v16 = 0xAAAAAAAAAAAAAAABLL * ((v10 - v13) >> 3);
      uint64_t v17 = 2 * v16;
      if (2 * v16 <= v14) {
        uint64_t v17 = v14;
      }
      if (v16 >= 0x555555555555555) {
        unint64_t v18 = 0xAAAAAAAAAAAAAAALL;
      }
      else {
        unint64_t v18 = v17;
      }
      uint64_t v30 = v9;
      if (v18) {
        unint64_t v19 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<std::string>>(v9, v18);
      }
      else {
        unint64_t v19 = 0;
      }
      uint64_t v22 = &v19[24 * v15];
      v27[0] = v19;
      v27[1] = v22;
      uint64_t v28 = v22;
      uint64_t v29 = &v19[24 * v18];
      uint64_t v23 = 3 * a5;
      unint64_t v24 = &v22[24 * a5];
      uint64_t v25 = 8 * v23;
      do
      {
        std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::set[abi:ne180100]((uint64_t *)v22, v7);
        v22 += 24;
        v7 += 3;
        v25 -= 24;
      }
      while (v25);
      uint64_t v28 = v24;
      unint64_t v5 = (uint64_t **)std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::__swap_out_circular_buffer(a1, v27, (uint64_t)v5);
      std::__split_buffer<std::map<ZinIrDimension,unsigned long>>::~__split_buffer(v27);
    }
  }
  return v5;
}

void sub_211297DBC(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, char a10, uint64_t a11, uint64_t a12)
{
  *(void *)(v12 + 8) = v13;
  _Unwind_Resume(exception_object);
}

uint64_t std::__introsort<std::_ClassicAlgPolicy,PressureBasedSubgraphIdentification::ExternalTensorSetPerResetLayer(std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const&,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &)::$_0 &,ZinIrOpLayer **,false>(uint64_t result, ZinIrOpLayer **a2, uint64_t a3, char a4)
{
  uint64_t v9 = (ZinIrOpLayer **)result;
  while (2)
  {
    uint64_t v10 = a2 - 1;
    std::string v83 = a2 - 3;
    uint64_t v84 = a2 - 2;
    uint64_t v11 = v9;
    while (1)
    {
      while (1)
      {
        while (1)
        {
          uint64_t v9 = v11;
          uint64_t v12 = (char *)a2 - (char *)v11;
          uint64_t v13 = a2 - v11;
          if (v5 || !v4)
          {
            switch(v13)
            {
              case 0:
              case 1:
                return result;
              case 2:
                uint64_t result = ScheduleComparator::operator()((int)&v86, *(a2 - 1), *v9);
                if (result)
                {
                  uint64_t v40 = *v9;
                  *uint64_t v9 = *(a2 - 1);
                  *(a2 - 1) = v40;
                }
                break;
              case 3:
                uint64_t result = std::__sort3[abi:ne180100]<std::_ClassicAlgPolicy,PressureBasedSubgraphIdentification::ExternalTensorSetPerResetLayer(std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const&,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &)::$_0 &,ZinIrOpLayer **>(v9, v9 + 1, v10);
                break;
              case 4:
                uint64_t result = std::__sort4[abi:ne180100]<std::_ClassicAlgPolicy,PressureBasedSubgraphIdentification::ExternalTensorSetPerResetLayer(std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const&,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &)::$_0 &,ZinIrOpLayer **>(v9, v9 + 1, v9 + 2, v10);
                break;
              case 5:
                uint64_t result = std::__sort5_maybe_branchless[abi:ne180100]<std::_ClassicAlgPolicy,PressureBasedSubgraphIdentification::ExternalTensorSetPerResetLayer(std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const&,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &)::$_0 &,ZinIrOpLayer **,0>(v9, v9 + 1, v9 + 2, v9 + 3, v10);
                break;
              default:
                JUMPOUT(0);
            }
            return result;
          }
          if (v12 <= 191)
          {
            uint64_t v41 = v9 + 1;
            BOOL v43 = v9 == a2 || v41 == a2;
            if (a4)
            {
              if (!v43)
              {
                uint64_t v44 = 0;
                unint64_t v45 = v9;
                do
                {
                  long long v47 = *v45;
                  int v46 = v45[1];
                  unint64_t v45 = v41;
                  uint64_t result = ScheduleComparator::operator()((int)&v86, v46, v47);
                  if (result)
                  {
                    uint64_t v48 = *v45;
                    uint64_t v49 = v44;
                    while (1)
                    {
                      *(ZinIrOpLayer **)((char *)v9 + v49 + 8) = *(ZinIrOpLayer **)((char *)v9 + v49);
                      if (!v49) {
                        break;
                      }
                      uint64_t result = ScheduleComparator::operator()((int)&v86, v48, *(ZinIrOpLayer **)((char *)v9 + v49 - 8));
                      v49 -= 8;
                      if ((result & 1) == 0)
                      {
                        long long v50 = (ZinIrOpLayer **)((char *)v9 + v49 + 8);
                        goto LABEL_75;
                      }
                    }
                    long long v50 = v9;
LABEL_75:
                    *long long v50 = v48;
                  }
                  uint64_t v41 = v45 + 1;
                  v44 += 8;
                }
                while (v45 + 1 != a2);
              }
            }
            else if (!v43)
            {
              do
              {
                unsigned int v77 = *v9;
                uint64_t v76 = v9[1];
                uint64_t v9 = v41;
                uint64_t result = ScheduleComparator::operator()((int)&v86, v76, v77);
                if (result)
                {
                  uint64_t v78 = *v9;
                  uint64_t v79 = v9;
                  do
                  {
                    uint64_t v80 = v79;
                    int v81 = *--v79;
                    *uint64_t v80 = v81;
                    uint64_t result = ScheduleComparator::operator()((int)&v86, v78, *(v80 - 2));
                  }
                  while ((result & 1) != 0);
                  *uint64_t v79 = v78;
                }
                uint64_t v41 = v9 + 1;
              }
              while (v9 + 1 != a2);
            }
            return result;
          }
          if (!a3)
          {
            if (v9 != a2)
            {
              int64_t v51 = (unint64_t)(v13 - 2) >> 1;
              int64_t v85 = v51;
              BOOL v82 = a2;
              do
              {
                int64_t v52 = v51;
                if (v85 >= v51)
                {
                  uint64_t v53 = (2 * v51) | 1;
                  uint64_t v54 = &v9[v53];
                  if (2 * v51 + 2 < v13 && ScheduleComparator::operator()((int)&v86, *v54, v54[1]))
                  {
                    ++v54;
                    uint64_t v53 = 2 * v52 + 2;
                  }
                  uint64_t v55 = &v9[v52];
                  uint64_t result = ScheduleComparator::operator()((int)&v86, *v54, *v55);
                  if ((result & 1) == 0)
                  {
                    uint64_t v56 = *v55;
                    do
                    {
                      size_t v57 = v54;
                      *uint64_t v55 = *v54;
                      if (v85 < v53) {
                        break;
                      }
                      uint64_t v58 = (2 * v53) | 1;
                      uint64_t v54 = &v9[v58];
                      uint64_t v59 = 2 * v53 + 2;
                      if (v59 < v13 && ScheduleComparator::operator()((int)&v86, *v54, v54[1]))
                      {
                        ++v54;
                        uint64_t v58 = v59;
                      }
                      uint64_t result = ScheduleComparator::operator()((int)&v86, *v54, v56);
                      uint64_t v55 = v57;
                      uint64_t v53 = v58;
                    }
                    while (!result);
                    *size_t v57 = v56;
                    a2 = v82;
                  }
                }
                int64_t v51 = v52 - 1;
              }
              while (v52);
              uint64_t v60 = (unint64_t)v12 >> 3;
              do
              {
                unint64_t v61 = a2;
                uint64_t v62 = 0;
                long long v63 = *v9;
                unint64_t v64 = v9;
                do
                {
                  char v65 = &v64[v62 + 1];
                  uint64_t v66 = (2 * v62) | 1;
                  uint64_t v67 = 2 * v62 + 2;
                  if (v67 < v60)
                  {
                    uint64_t result = ScheduleComparator::operator()((int)&v86, *v65, v64[v62 + 2]);
                    if (result)
                    {
                      ++v65;
                      uint64_t v66 = v67;
                    }
                  }
                  *unint64_t v64 = *v65;
                  unint64_t v64 = v65;
                  uint64_t v62 = v66;
                }
                while (v66 <= (uint64_t)((unint64_t)(v60 - 2) >> 1));
                uint64_t v68 = v61 - 1;
                if (v65 == v68)
                {
                  uint64_t v69 = v68;
                  *char v65 = v63;
                }
                else
                {
                  *char v65 = *v68;
                  uint64_t v69 = v68;
                  *uint64_t v68 = v63;
                  uint64_t v70 = (char *)v65 - (char *)v9 + 8;
                  if (v70 >= 9)
                  {
                    unint64_t v71 = (((unint64_t)v70 >> 3) - 2) >> 1;
                    BOOL v72 = &v9[v71];
                    uint64_t result = ScheduleComparator::operator()((int)&v86, *v72, *v65);
                    if (result)
                    {
                      __int16 v73 = *v65;
                      do
                      {
                        unint64_t v74 = v72;
                        *char v65 = *v72;
                        if (!v71) {
                          break;
                        }
                        unint64_t v71 = (v71 - 1) >> 1;
                        BOOL v72 = &v9[v71];
                        uint64_t result = ScheduleComparator::operator()((int)&v86, *v72, v73);
                        char v65 = v74;
                      }
                      while ((result & 1) != 0);
                      *unint64_t v74 = v73;
                    }
                  }
                }
                BOOL v75 = v60-- <= 2;
                a2 = v69;
              }
              while (!v75);
            }
            return result;
          }
          unint64_t v14 = (unint64_t)v13 >> 1;
          unint64_t v15 = &v9[(unint64_t)v13 >> 1];
          if ((unint64_t)v12 < 0x401)
          {
            std::__sort3[abi:ne180100]<std::_ClassicAlgPolicy,PressureBasedSubgraphIdentification::ExternalTensorSetPerResetLayer(std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const&,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &)::$_0 &,ZinIrOpLayer **>(v15, v9, v10);
          }
          else
          {
            std::__sort3[abi:ne180100]<std::_ClassicAlgPolicy,PressureBasedSubgraphIdentification::ExternalTensorSetPerResetLayer(std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const&,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &)::$_0 &,ZinIrOpLayer **>(v9, v15, v10);
            std::__sort3[abi:ne180100]<std::_ClassicAlgPolicy,PressureBasedSubgraphIdentification::ExternalTensorSetPerResetLayer(std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const&,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &)::$_0 &,ZinIrOpLayer **>(v9 + 1, v15 - 1, v84);
            std::__sort3[abi:ne180100]<std::_ClassicAlgPolicy,PressureBasedSubgraphIdentification::ExternalTensorSetPerResetLayer(std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const&,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &)::$_0 &,ZinIrOpLayer **>(v9 + 2, &v9[v14 + 1], v83);
            std::__sort3[abi:ne180100]<std::_ClassicAlgPolicy,PressureBasedSubgraphIdentification::ExternalTensorSetPerResetLayer(std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const&,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &)::$_0 &,ZinIrOpLayer **>(v15 - 1, v15, &v9[v14 + 1]);
            unint64_t v16 = *v9;
            *uint64_t v9 = *v15;
            *unint64_t v15 = v16;
          }
          --a3;
          if ((a4 & 1) != 0 || ScheduleComparator::operator()((int)&v86, *(v9 - 1), *v9)) {
            break;
          }
          int64x2_t v31 = *v9;
          uint64_t result = ScheduleComparator::operator()((int)&v86, *v9, *v10);
          if (result)
          {
            uint64_t v11 = v9;
            do
            {
              uint64_t v32 = v11[1];
              ++v11;
              uint64_t result = ScheduleComparator::operator()((int)&v86, v31, v32);
            }
            while ((result & 1) == 0);
          }
          else
          {
            uint64_t v33 = v9 + 1;
            do
            {
              uint64_t v11 = v33;
              if (v33 >= a2) {
                break;
              }
              ++v33;
              uint64_t result = ScheduleComparator::operator()((int)&v86, v31, *v11);
            }
            while (!result);
          }
          BOOL v34 = a2;
          if (v11 < a2)
          {
            BOOL v34 = a2;
            do
            {
              int64x2_t v35 = *--v34;
              uint64_t result = ScheduleComparator::operator()((int)&v86, v31, v35);
            }
            while ((result & 1) != 0);
          }
          while (v11 < v34)
          {
            uint64_t v36 = *v11;
            char *v11 = *v34;
            *BOOL v34 = v36;
            do
            {
              uint64_t v37 = v11[1];
              ++v11;
            }
            while (!ScheduleComparator::operator()((int)&v86, v31, v37));
            do
            {
              uint64_t v38 = *--v34;
              uint64_t result = ScheduleComparator::operator()((int)&v86, v31, v38);
            }
            while ((result & 1) != 0);
          }
          uint64_t v39 = v11 - 1;
          BOOL v4 = v11 - 1 >= v9;
          BOOL v5 = v11 - 1 == v9;
          if (v11 - 1 != v9) {
            *uint64_t v9 = *v39;
          }
          a4 = 0;
          uint64_t *v39 = v31;
        }
        uint64_t v17 = 0;
        unint64_t v18 = *v9;
        while (ScheduleComparator::operator()((int)&v86, v9[++v17], v18))
          ;
        uint64_t v20 = &v9[v17];
        uint64_t v21 = a2;
        if (v17 == 1)
        {
          do
          {
            if (v20 >= a2) {
              break;
            }
            uint64_t v23 = *--a2;
          }
          while (!ScheduleComparator::operator()((int)&v86, v23, v18));
        }
        else
        {
          do
            uint64_t v22 = *--a2;
          while (!ScheduleComparator::operator()((int)&v86, v22, v18));
        }
        if (v20 >= a2)
        {
          uint64_t v29 = v20 - 1;
        }
        else
        {
          unint64_t v24 = &v9[v17];
          uint64_t v25 = a2;
          do
          {
            int v26 = *v24;
            *unint64_t v24 = *v25;
            *uint64_t v25 = v26;
            do
            {
              unint64_t v27 = v24[1];
              ++v24;
            }
            while (ScheduleComparator::operator()((int)&v86, v27, v18));
            do
              uint64_t v28 = *--v25;
            while (!ScheduleComparator::operator()((int)&v86, v28, v18));
          }
          while (v24 < v25);
          uint64_t v29 = v24 - 1;
        }
        if (v29 != v9) {
          *uint64_t v9 = *v29;
        }
        *uint64_t v29 = v18;
        BOOL v4 = v20 >= a2;
        a2 = v21;
        if (v4) {
          break;
        }
LABEL_33:
        uint64_t result = std::__introsort<std::_ClassicAlgPolicy,PressureBasedSubgraphIdentification::ExternalTensorSetPerResetLayer(std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const&,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &)::$_0 &,ZinIrOpLayer **,false>(v9, v29, a3, a4 & 1);
        a4 = 0;
        uint64_t v11 = v29 + 1;
      }
      BOOL v30 = std::__insertion_sort_incomplete[abi:ne180100]<std::_ClassicAlgPolicy,PressureBasedSubgraphIdentification::ExternalTensorSetPerResetLayer(std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const&,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &)::$_0 &,ZinIrOpLayer **>(v9, v29);
      uint64_t v11 = v29 + 1;
      uint64_t result = std::__insertion_sort_incomplete[abi:ne180100]<std::_ClassicAlgPolicy,PressureBasedSubgraphIdentification::ExternalTensorSetPerResetLayer(std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const&,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &)::$_0 &,ZinIrOpLayer **>(v29 + 1, v21);
      if (result) {
        break;
      }
      if (!v30) {
        goto LABEL_33;
      }
    }
    a2 = v29;
    if (!v30) {
      continue;
    }
    return result;
  }
}

BOOL std::__sort5_maybe_branchless[abi:ne180100]<std::_ClassicAlgPolicy,PressureBasedSubgraphIdentification::ExternalTensorSetPerResetLayer(std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const&,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &)::$_0 &,ZinIrOpLayer **,0>(ZinIrOpLayer **a1, ZinIrOpLayer **a2, ZinIrOpLayer **a3, ZinIrOpLayer **a4, ZinIrOpLayer **a5)
{
  std::__sort4[abi:ne180100]<std::_ClassicAlgPolicy,PressureBasedSubgraphIdentification::ExternalTensorSetPerResetLayer(std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const&,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &)::$_0 &,ZinIrOpLayer **>(a1, a2, a3, a4);
  BOOL result = ScheduleComparator::operator()((int)&v15, *a5, *a4);
  if (result)
  {
    uint64_t v11 = *a4;
    *a4 = *a5;
    *a5 = v11;
    BOOL result = ScheduleComparator::operator()((int)&v16, *a4, *a3);
    if (result)
    {
      uint64_t v12 = *a3;
      *a3 = *a4;
      *a4 = v12;
      BOOL result = ScheduleComparator::operator()((int)&v17, *a3, *a2);
      if (result)
      {
        uint64_t v13 = *a2;
        *a2 = *a3;
        *a3 = v13;
        BOOL result = ScheduleComparator::operator()((int)&v18, *a2, *a1);
        if (result)
        {
          unint64_t v14 = *a1;
          *a1 = *a2;
          *a2 = v14;
        }
      }
    }
  }
  return result;
}

BOOL std::__sort3[abi:ne180100]<std::_ClassicAlgPolicy,PressureBasedSubgraphIdentification::ExternalTensorSetPerResetLayer(std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const&,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &)::$_0 &,ZinIrOpLayer **>(ZinIrOpLayer **a1, ZinIrOpLayer **a2, ZinIrOpLayer **a3)
{
  BOOL v6 = ScheduleComparator::operator()((int)&v14, *a2, *a1);
  uint64_t v7 = *a3;
  uint64_t v8 = *a2;
  if (v6)
  {
    BOOL result = ScheduleComparator::operator()((int)&v17, v7, v8);
    uint64_t v10 = *a1;
    if (result)
    {
      *a1 = *a3;
      *a3 = v10;
    }
    else
    {
      *a1 = *a2;
      *a2 = v10;
      BOOL result = ScheduleComparator::operator()((int)&v18, *a3, v10);
      if (result)
      {
        uint64_t v13 = *a2;
        *a2 = *a3;
        *a3 = v13;
      }
    }
  }
  else
  {
    BOOL result = ScheduleComparator::operator()((int)&v15, v7, v8);
    if (result)
    {
      uint64_t v11 = *a2;
      *a2 = *a3;
      *a3 = v11;
      BOOL result = ScheduleComparator::operator()((int)&v16, *a2, *a1);
      if (result)
      {
        uint64_t v12 = *a1;
        *a1 = *a2;
        *a2 = v12;
      }
    }
  }
  return result;
}

BOOL std::__insertion_sort_incomplete[abi:ne180100]<std::_ClassicAlgPolicy,PressureBasedSubgraphIdentification::ExternalTensorSetPerResetLayer(std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const&,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &)::$_0 &,ZinIrOpLayer **>(ZinIrOpLayer **a1, ZinIrOpLayer **a2)
{
  uint64_t v4 = a2 - a1;
  BOOL result = 1;
  switch(v4)
  {
    case 0:
    case 1:
      return result;
    case 2:
      if (ScheduleComparator::operator()((int)&v15, *(a2 - 1), *a1))
      {
        BOOL v6 = *a1;
        *a1 = *(a2 - 1);
        *(a2 - 1) = v6;
      }
      return 1;
    case 3:
      std::__sort3[abi:ne180100]<std::_ClassicAlgPolicy,PressureBasedSubgraphIdentification::ExternalTensorSetPerResetLayer(std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const&,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &)::$_0 &,ZinIrOpLayer **>(a1, a1 + 1, a2 - 1);
      return 1;
    case 4:
      std::__sort4[abi:ne180100]<std::_ClassicAlgPolicy,PressureBasedSubgraphIdentification::ExternalTensorSetPerResetLayer(std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const&,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &)::$_0 &,ZinIrOpLayer **>(a1, a1 + 1, a1 + 2, a2 - 1);
      return 1;
    case 5:
      std::__sort5_maybe_branchless[abi:ne180100]<std::_ClassicAlgPolicy,PressureBasedSubgraphIdentification::ExternalTensorSetPerResetLayer(std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const&,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &)::$_0 &,ZinIrOpLayer **,0>(a1, a1 + 1, a1 + 2, a1 + 3, a2 - 1);
      return 1;
    default:
      uint64_t v7 = a1 + 2;
      std::__sort3[abi:ne180100]<std::_ClassicAlgPolicy,PressureBasedSubgraphIdentification::ExternalTensorSetPerResetLayer(std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const&,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &)::$_0 &,ZinIrOpLayer **>(a1, a1 + 1, a1 + 2);
      uint64_t v8 = a1 + 3;
      if (a1 + 3 == a2) {
        return 1;
      }
      uint64_t v9 = 0;
      int v10 = 0;
      break;
  }
  while (1)
  {
    if (ScheduleComparator::operator()((int)&v16, *v8, *v7))
    {
      uint64_t v11 = *v8;
      uint64_t v12 = v9;
      while (1)
      {
        uint64_t v13 = (ZinIrOpLayer **)((char *)a1 + v12);
        *(ZinIrOpLayer **)((char *)a1 + v12 + 24) = *(ZinIrOpLayer **)((char *)a1 + v12 + 16);
        if (v12 == -16) {
          break;
        }
        v12 -= 8;
        if (!ScheduleComparator::operator()((int)&v17, v11, v13[1]))
        {
          char v14 = (ZinIrOpLayer **)((char *)a1 + v12 + 24);
          goto LABEL_12;
        }
      }
      char v14 = a1;
LABEL_12:
      *char v14 = v11;
      if (++v10 == 8) {
        return v8 + 1 == a2;
      }
    }
    uint64_t v7 = v8;
    v9 += 8;
    if (++v8 == a2) {
      return 1;
    }
  }
}

BOOL std::__sort4[abi:ne180100]<std::_ClassicAlgPolicy,PressureBasedSubgraphIdentification::ExternalTensorSetPerResetLayer(std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const&,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &)::$_0 &,ZinIrOpLayer **>(ZinIrOpLayer **a1, ZinIrOpLayer **a2, ZinIrOpLayer **a3, ZinIrOpLayer **a4)
{
  std::__sort3[abi:ne180100]<std::_ClassicAlgPolicy,PressureBasedSubgraphIdentification::ExternalTensorSetPerResetLayer(std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> const&,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &,std::map<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>,ScheduleComparator,std::allocator<std::pair<ZinIrOpLayer * const,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>> &)::$_0 &,ZinIrOpLayer **>(a1, a2, a3);
  BOOL result = ScheduleComparator::operator()((int)&v12, *a4, *a3);
  if (result)
  {
    uint64_t v9 = *a3;
    *a3 = *a4;
    *a4 = v9;
    BOOL result = ScheduleComparator::operator()((int)&v13, *a3, *a2);
    if (result)
    {
      int v10 = *a2;
      *a2 = *a3;
      *a3 = v10;
      BOOL result = ScheduleComparator::operator()((int)&v14, *a2, *a1);
      if (result)
      {
        uint64_t v11 = *a1;
        *a1 = *a2;
        *a2 = v11;
      }
    }
  }
  return result;
}

BOOL std::__includes[abi:ne180100]<std::__tree_const_iterator<ZinIrTensor const*,std::__tree_node<ZinIrTensor const*,void *> *,long>,std::__tree_const_iterator<ZinIrTensor const*,std::__tree_node<ZinIrTensor const*,void *> *,long>,std::__tree_const_iterator<ZinIrTensor const*,std::__tree_node<ZinIrTensor const*,void *> *,long>,std::__tree_const_iterator<ZinIrTensor const*,std::__tree_node<ZinIrTensor const*,void *> *,long>,ZinIrIdComparator<ZinIrTensor const*> &,std::__identity,std::__identity>(void *a1, void *a2, void *a3, void *a4)
{
  BOOL v4 = a3 == a4;
  if (a3 != a4 && a1 != a2)
  {
    while (1)
    {
      uint64_t v5 = a3[4];
      uint64_t v6 = a1[4];
      if (v5) {
        BOOL v7 = v6 == 0;
      }
      else {
        BOOL v7 = 1;
      }
      if (v7)
      {
        if (v5) {
          BOOL v8 = v6 == 0;
        }
        else {
          BOOL v8 = 0;
        }
        if (v8) {
          return 0;
        }
      }
      else if (*(void *)(v5 + 8) < *(void *)(v6 + 8))
      {
        return 0;
      }
      if (v5) {
        BOOL v9 = v6 == 0;
      }
      else {
        BOOL v9 = 1;
      }
      if (v9)
      {
        if (!v5 && v6)
        {
LABEL_22:
          int v10 = a3;
          goto LABEL_29;
        }
      }
      else if (*(void *)(v6 + 8) < *(void *)(v5 + 8))
      {
        goto LABEL_22;
      }
      uint64_t v11 = (void *)a3[1];
      if (v11)
      {
        do
        {
          int v10 = v11;
          uint64_t v11 = (void *)*v11;
        }
        while (v11);
      }
      else
      {
        do
        {
          int v10 = (void *)a3[2];
          BOOL v7 = *v10 == (void)a3;
          a3 = v10;
        }
        while (!v7);
      }
LABEL_29:
      char v12 = (void *)a1[1];
      if (v12)
      {
        do
        {
          char v13 = v12;
          char v12 = (void *)*v12;
        }
        while (v12);
      }
      else
      {
        do
        {
          char v13 = (void *)a1[2];
          BOOL v7 = *v13 == (void)a1;
          a1 = v13;
        }
        while (!v7);
      }
      BOOL v4 = v10 == a4;
      if (v10 != a4)
      {
        a1 = v13;
        a3 = v10;
        if (v13 != a2) {
          continue;
        }
      }
      return v4;
    }
  }
  return v4;
}

uint64_t std::vector<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::erase(uint64_t a1, uint64_t a2, void *a3)
{
  if ((void *)a2 != a3)
  {
    std::__unwrap_and_dispatch[abi:ne180100]<std::__overload<std::__move_loop<std::_ClassicAlgPolicy>,std::__move_trivial>,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>> *,0>(a3, *(void **)(a1 + 8), a2);
    uint64_t v6 = v5;
    uint64_t v7 = *(void *)(a1 + 8);
    if (v7 != v5)
    {
      do
      {
        uint64_t v8 = v7 - 24;
        std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy(v7 - 24, *(void **)(v7 - 16));
        uint64_t v7 = v8;
      }
      while (v8 != v6);
    }
    *(void *)(a1 + 8) = v6;
  }
  return a2;
}

uint64_t std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__erase_unique<ZinIrOpLayer *>(uint64_t **a1, ZinIrOpLayer **a2)
{
  uint64_t v3 = (uint64_t *)std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::find<ZinIrOpLayer *>((uint64_t)a1, a2);
  if (a1 + 1 == (uint64_t **)v3) {
    return 0;
  }
  BOOL v4 = v3;
  std::__tree<std::__value_type<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,ZinIrHazardGraph::EdgeType>,std::__map_value_compare<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,std::__value_type<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,ZinIrHazardGraph::EdgeType>,HazardEdgeCompare,true>,std::allocator<std::__value_type<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,ZinIrHazardGraph::EdgeType>>>::__remove_node_pointer(a1, v3);
  operator delete(v4);
  return 1;
}

ZinMirSpatialSplitLatencyCostModel *std::unique_ptr<ZinMirSpatialSplitLatencyCostModel>::reset[abi:ne180100](ZinMirSpatialSplitLatencyCostModel **a1, ZinMirSpatialSplitLatencyCostModel *a2)
{
  BOOL result = *a1;
  *a1 = a2;
  if (result)
  {
    ZinMirSpatialSplitLatencyCostModel::~ZinMirSpatialSplitLatencyCostModel(result);
    JUMPOUT(0x21667D3C0);
  }
  return result;
}

void std::__function::__func<PressureBasedSubgraphIdentification::IsolateLiveRangeForConcatInputs(BOOL &)::$_0,std::allocator<PressureBasedSubgraphIdentification::IsolateLiveRangeForConcatInputs(BOOL &)::$_0>,ZinIrStatus ()(ZinIrBasicBlock *)>::~__func()
{
}

__n128 std::__function::__func<PressureBasedSubgraphIdentification::IsolateLiveRangeForConcatInputs(BOOL &)::$_0,std::allocator<PressureBasedSubgraphIdentification::IsolateLiveRangeForConcatInputs(BOOL &)::$_0>,ZinIrStatus ()(ZinIrBasicBlock *)>::__clone(uint64_t a1)
{
  uint64_t v2 = (char *)operator new(0x18uLL);
  *(void *)uint64_t v2 = &unk_26C32FB70;
  __n128 result = *(__n128 *)(a1 + 8);
  *(__n128 *)(v2 + 8) = result;
  return result;
}

__n128 std::__function::__func<PressureBasedSubgraphIdentification::IsolateLiveRangeForConcatInputs(BOOL &)::$_0,std::allocator<PressureBasedSubgraphIdentification::IsolateLiveRangeForConcatInputs(BOOL &)::$_0>,ZinIrStatus ()(ZinIrBasicBlock *)>::__clone(uint64_t a1, uint64_t a2)
{
  *(void *)a2 = &unk_26C32FB70;
  __n128 result = *(__n128 *)(a1 + 8);
  *(__n128 *)(a2 + 8) = result;
  return result;
}

uint64_t std::__function::__func<PressureBasedSubgraphIdentification::IsolateLiveRangeForConcatInputs(BOOL &)::$_0,std::allocator<PressureBasedSubgraphIdentification::IsolateLiveRangeForConcatInputs(BOOL &)::$_0>,ZinIrStatus ()(ZinIrBasicBlock *)>::operator()(uint64_t a1, ZinIrTarget **a2)
{
  int64_t v52 = (uint64_t *)*MEMORY[0x263EF8340];
  uint64_t v2 = *(void **)(a1 + 8);
  Hal = ZinIrTarget::GetHal(v52, *a2);
  uint64_t v4 = v2[1];
  uint64_t v6 = *(void *)(v4 + 352);
  uint64_t v5 = *(void *)(v4 + 360);
  if (v5 == v6) {
    ZinAssertImpl("Must run scheduler first");
  }
  uint64_t v7 = (uint64_t)Hal;
  uint64_t v8 = *(void *)(*(void *)v6 + 48);
  uint64_t v9 = *(void *)(*(void *)(v5 - 8) + 48);
  ZinIrNgraph<ZinIrOpLayer *,ZinIrIdComparator<ZinIrOpLayer *>>::GetTopologicalOrderMap(Hal, (uint64_t)v47);
  v46[0] = 0;
  v46[1] = 0;
  unint64_t v45 = (uint64_t *)v46;
  if (v8 <= v9)
  {
    do
    {
      *(void *)&long long __p = 0;
      uint64_t v10 = *(void *)(*(void *)(v4 + 352) + 8 * v8);
      *(void *)&long long __p = v10;
      if ((*(_DWORD *)(*(void *)(v10 + 64) + 8) - 28) >= 3)
      {
        uint64_t v13 = v10 + 112;
        uint64_t v12 = *(void *)(v10 + 112);
        uint64_t v11 = *(void *)(v13 + 8);
        if ((unint64_t)(v11 - v12) >= 9)
        {
          v44[0] = 0;
          while (v12 != v11)
          {
            char v14 = *(void **)v12;
            if (*(_DWORD *)(*(void *)(*(void *)v12 + 64) + 8) == 7)
            {
              v44[0] = *(void **)v12;
              std::string::size_type v15 = v14[6];
              v49.__r_.__value_.__r.__words[0] = v8 + 1;
              v49.__r_.__value_.__l.__size_ = v15;
              if (ZinIrMemoryPressureAnalyzer::GetPeakPressure((ZinIrMemoryPressureAnalyzer *)(v2 + 16), (const ZinLiveRange *)&v49) >= v2[13])
              {
                char v18 = *(uint64_t **)(__p + 112);
                char v17 = *(uint64_t **)(__p + 120);
                while (v18 != v17)
                {
                  if ((void *)*v18 != v44[0]
                    && ZinIrNgraph<ZinIrOpLayer *,ZinIrIdComparator<ZinIrOpLayer *>>::FindPath(v7, v18, (uint64_t *)v44, (uint64_t)v47))
                  {
                    v39[0] = (uint64_t *)&__p;
                    unint64_t v19 = std::__tree<std::__value_type<ZinIrOpLayer *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>,std::__map_value_compare<ZinIrOpLayer *,std::__value_type<ZinIrOpLayer *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>,ScheduleComparator,true>,std::allocator<std::__value_type<ZinIrOpLayer *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer * const&>,std::tuple<>>(&v45, (ZinIrOpLayer **)&__p, (uint64_t)&std::piecewise_construct, v39);
                    std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer * const&>((uint64_t **)v19 + 5, (ZinIrOpLayer **)v44, (uint64_t *)v44);
                  }
                  ++v18;
                }
              }
              break;
            }
            v12 += 8;
          }
        }
      }
      BOOL v16 = v8++ == v9;
    }
    while (!v16);
    uint64_t v20 = v45;
    if (v45 != (uint64_t *)v46)
    {
      do
      {
        if ((uint64_t *)v20[5] != v20 + 6)
        {
          uint64_t v21 = v20[4];
          if (*(char *)(v21 + 47) >= 0) {
            size_t v22 = *(unsigned __int8 *)(v21 + 47);
          }
          else {
            size_t v22 = *(void *)(v21 + 32);
          }
          std::string::basic_string[abi:ne180100]((uint64_t)&v49, v22 + 1);
          if ((v49.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
            uint64_t v23 = &v49;
          }
          else {
            uint64_t v23 = (std::string *)v49.__r_.__value_.__r.__words[0];
          }
          if (v22)
          {
            if (*(char *)(v21 + 47) >= 0) {
              unint64_t v24 = (const void *)(v21 + 24);
            }
            else {
              unint64_t v24 = *(const void **)(v21 + 24);
            }
            memmove(v23, v24, v22);
          }
          *(_WORD *)((char *)&v23->__r_.__value_.__l.__data_ + v22) = 95;
          uint64_t v25 = (std::string *)std::string::basic_string[abi:ne180100]<0>(buf, "split_live_range");
          int v26 = std::string::append(v25, "_xfm", 4uLL);
          long long v27 = *(_OWORD *)&v26->__r_.__value_.__l.__data_;
          int64_t v43 = v26->__r_.__value_.__r.__words[2];
          long long __p = v27;
          v26->__r_.__value_.__l.__size_ = 0;
          v26->__r_.__value_.__r.__words[2] = 0;
          v26->__r_.__value_.__r.__words[0] = 0;
          if (v43 >= 0) {
            p_p = (const std::string::value_type *)&__p;
          }
          else {
            p_p = (const std::string::value_type *)__p;
          }
          if (v43 >= 0) {
            std::string::size_type v29 = HIBYTE(v43);
          }
          else {
            std::string::size_type v29 = *((void *)&__p + 1);
          }
          BOOL v30 = std::string::append(&v49, p_p, v29);
          long long v31 = *(_OWORD *)&v30->__r_.__value_.__l.__data_;
          unint64_t v44[2] = (void *)v30->__r_.__value_.__r.__words[2];
          *(_OWORD *)uint64_t v44 = v31;
          v30->__r_.__value_.__l.__size_ = 0;
          v30->__r_.__value_.__r.__words[2] = 0;
          v30->__r_.__value_.__r.__words[0] = 0;
          if (SHIBYTE(v43) < 0) {
            operator delete((void *)__p);
          }
          if (v51 < 0) {
            operator delete(*(void **)buf);
          }
          if (SHIBYTE(v49.__r_.__value_.__r.__words[2]) < 0) {
            operator delete(v49.__r_.__value_.__l.__data_);
          }
          __n128 v32 = ZinObjectNameFactory::ZinObjectNameFactory(&__p, v44);
          uint64_t v33 = (void *)v20[4];
          uint64_t v34 = v33[2];
          uint64_t v35 = *(unsigned int *)((*(uint64_t (**)(void *, void, void, __n128))(*v33 + 32))(v33, 0, 0, v32)+ 88);
          uint64_t v41 = 0;
          LOBYTE(v39[0]) = 0;
          char v40 = 0;
          ZinBuilder::CreateNEBypass(v34, (uint64_t)&__p, (uint64_t)v33, v35, &v41, 0, (uint64_t)v39, 1.0);
        }
        uint64_t v36 = (uint64_t *)v20[1];
        if (v36)
        {
          do
          {
            uint64_t v37 = v36;
            uint64_t v36 = (uint64_t *)*v36;
          }
          while (v36);
        }
        else
        {
          do
          {
            uint64_t v37 = (uint64_t *)v20[2];
            BOOL v16 = *v37 == (void)v20;
            uint64_t v20 = v37;
          }
          while (!v16);
        }
        uint64_t v20 = v37;
      }
      while (v37 != (uint64_t *)v46);
    }
  }
  std::__tree<std::__value_type<int,std::set<ZinIrInitInfo const*>>,std::__map_value_compare<int,std::__value_type<int,std::set<ZinIrInitInfo const*>>,std::less<int>,true>,std::allocator<std::__value_type<int,std::set<ZinIrInitInfo const*>>>>::destroy((uint64_t)&v45, v46[0]);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v47, v48);
  return 0;
}

void sub_211299208(_Unwind_Exception *a1)
{
}

uint64_t std::__function::__func<PressureBasedSubgraphIdentification::IsolateLiveRangeForConcatInputs(BOOL &)::$_0,std::allocator<PressureBasedSubgraphIdentification::IsolateLiveRangeForConcatInputs(BOOL &)::$_0>,ZinIrStatus ()(ZinIrBasicBlock *)>::target(uint64_t a1, uint64_t a2)
{
  {
    return a1 + 8;
  }
  else
  {
    return 0;
  }
}

void *std::__function::__func<PressureBasedSubgraphIdentification::IsolateLiveRangeForConcatInputs(BOOL &)::$_0,std::allocator<PressureBasedSubgraphIdentification::IsolateLiveRangeForConcatInputs(BOOL &)::$_0>,ZinIrStatus ()(ZinIrBasicBlock *)>::target_type()
{
}

uint64_t ZinIrNgraph<ZinIrOpLayer *,ZinIrIdComparator<ZinIrOpLayer *>>::FindPath(uint64_t a1, uint64_t *a2, uint64_t *a3, uint64_t a4)
{
  long long __p = 0;
  uint64_t v7 = 0;
  uint64_t v8 = 0;
  uint64_t Path = ZinIrNgraph<ZinIrOpLayer *,ZinIrIdComparator<ZinIrOpLayer *>>::FindPath(a1, a2, a3, a4, &__p);
  if (__p)
  {
    uint64_t v7 = __p;
    operator delete(__p);
  }
  return Path;
}

void sub_2112993D4(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t *std::__tree<std::__value_type<ZinIrOpLayer *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>,std::__map_value_compare<ZinIrOpLayer *,std::__value_type<ZinIrOpLayer *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>,ScheduleComparator,true>,std::allocator<std::__value_type<ZinIrOpLayer *,std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer * const&>,std::tuple<>>(uint64_t **a1, ZinIrOpLayer **a2, uint64_t a3, uint64_t **a4)
{
  uint64_t v6 = std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__find_equal<ZinIrOpLayer *>((uint64_t)a1, &v11, a2);
  uint64_t v7 = (uint64_t *)*v6;
  if (!*v6)
  {
    uint64_t v8 = (uint64_t **)v6;
    uint64_t v7 = (uint64_t *)operator new(0x40uLL);
    uint64_t v9 = **a4;
    v7[7] = 0;
    v7[6] = 0;
    v7[4] = v9;
    v7[5] = (uint64_t)(v7 + 6);
    std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::__insert_node_at(a1, v11, v8, v7);
  }
  return v7;
}

void std::__function::__func<PressureBasedSubgraphIdentification::AddCopyForLiveOutWithMultiFanOutParent(BOOL &)::$_0,std::allocator<PressureBasedSubgraphIdentification::AddCopyForLiveOutWithMultiFanOutParent(BOOL &)::$_0>,ZinIrStatus ()(ZinIrBasicBlock *)>::~__func()
{
}

__n128 std::__function::__func<PressureBasedSubgraphIdentification::AddCopyForLiveOutWithMultiFanOutParent(BOOL &)::$_0,std::allocator<PressureBasedSubgraphIdentification::AddCopyForLiveOutWithMultiFanOutParent(BOOL &)::$_0>,ZinIrStatus ()(ZinIrBasicBlock *)>::__clone(uint64_t a1)
{
  uint64_t v2 = (char *)operator new(0x18uLL);
  *(void *)uint64_t v2 = &unk_26C32FBC8;
  __n128 result = *(__n128 *)(a1 + 8);
  *(__n128 *)(v2 + 8) = result;
  return result;
}

__n128 std::__function::__func<PressureBasedSubgraphIdentification::AddCopyForLiveOutWithMultiFanOutParent(BOOL &)::$_0,std::allocator<PressureBasedSubgraphIdentification::AddCopyForLiveOutWithMultiFanOutParent(BOOL &)::$_0>,ZinIrStatus ()(ZinIrBasicBlock *)>::__clone(uint64_t a1, uint64_t a2)
{
  *(void *)a2 = &unk_26C32FBC8;
  __n128 result = *(__n128 *)(a1 + 8);
  *(__n128 *)(a2 + 8) = result;
  return result;
}

uint64_t std::__function::__func<PressureBasedSubgraphIdentification::AddCopyForLiveOutWithMultiFanOutParent(BOOL &)::$_0,std::allocator<PressureBasedSubgraphIdentification::AddCopyForLiveOutWithMultiFanOutParent(BOOL &)::$_0>,ZinIrStatus ()(ZinIrBasicBlock *)>::operator()(uint64_t a1, ZinIrTarget **a2)
{
  unint64_t v24 = (uint64_t *)*MEMORY[0x263EF8340];
  uint64_t v2 = *(void *)(a1 + 8);
  Hal = ZinIrTarget::GetHal(v24, *a2);
  uint64_t v4 = (uint64_t *)Hal[55];
  uint64_t v5 = Hal + 56;
  if (v4 != Hal + 56)
  {
    do
    {
      uint64_t v6 = v4[4];
      uint64_t v7 = **(void ***)(v6 + 88);
      if (v7[15] - v7[14] >= 9uLL)
      {
        v23[0] = v7[6];
        v23[1] = v23[0];
        if (ZinIrMemoryPressureAnalyzer::GetPeakPressure((ZinIrMemoryPressureAnalyzer *)(v2 + 128), (const ZinLiveRange *)v23) >= *(void *)(v2 + 104))
        {
          if (*(char *)(v6 + 47) >= 0) {
            size_t v8 = *(unsigned __int8 *)(v6 + 47);
          }
          else {
            size_t v8 = *(void *)(v6 + 32);
          }
          std::string::basic_string[abi:ne180100]((uint64_t)v21, v8 + 30);
          if (v22 >= 0) {
            uint64_t v9 = v21;
          }
          else {
            uint64_t v9 = (void *)v21[0];
          }
          if (v8)
          {
            if (*(char *)(v6 + 47) >= 0) {
              uint64_t v10 = (const void *)(v6 + 24);
            }
            else {
              uint64_t v10 = *(const void **)(v6 + 24);
            }
            memmove(v9, v10, v8);
          }
          strcpy((char *)v9 + v8, "_LiveOutCopy_MultiFanOutParent");
          __n128 v11 = ZinObjectNameFactory::ZinObjectNameFactory(v20, v21);
          uint64_t v12 = v7[2];
          uint64_t v13 = *(unsigned int *)((*(uint64_t (**)(uint64_t, void, void, __n128))(*(void *)v6 + 32))(v6, 0, 0, v11)+ 88);
          uint64_t v19 = 0;
          v18[0] = 0;
          v18[168] = 0;
          ZinBuilder::CreateNEBypass(v12, (uint64_t)v20, (uint64_t)v7, v13, &v19, 0, (uint64_t)v18, 1.0);
        }
      }
      char v14 = (uint64_t *)v4[1];
      if (v14)
      {
        do
        {
          std::string::size_type v15 = v14;
          char v14 = (uint64_t *)*v14;
        }
        while (v14);
      }
      else
      {
        do
        {
          std::string::size_type v15 = (uint64_t *)v4[2];
          BOOL v16 = *v15 == (void)v4;
          uint64_t v4 = v15;
        }
        while (!v16);
      }
      uint64_t v4 = v15;
    }
    while (v15 != v5);
  }
  return 0;
}

void sub_211299944(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33,uint64_t a34,uint64_t a35,uint64_t a36,uint64_t a37,uint64_t a38,uint64_t a39,uint64_t a40,uint64_t a41,int a42,__int16 a43,char a44,char a45,uint64_t a46,uint64_t a47,uint64_t a48,int a49,__int16 a50,char a51,char a52,uint64_t a53,uint64_t a54,uint64_t a55,uint64_t a56,uint64_t a57,uint64_t a58,char a59)
{
  ZinIrNetworkStatus::~ZinIrNetworkStatus((ZinIrNetworkStatus *)&a59);
  *(void *)(v59 + 8) = &unk_26C34DA98;
  if (a45 < 0) {
    operator delete(*(void **)(v59 + 16));
  }
  if (a52 < 0) {
    operator delete(*(void **)(v59 + 48));
  }
  _Unwind_Resume(a1);
}

uint64_t std::__function::__func<PressureBasedSubgraphIdentification::AddCopyForLiveOutWithMultiFanOutParent(BOOL &)::$_0,std::allocator<PressureBasedSubgraphIdentification::AddCopyForLiveOutWithMultiFanOutParent(BOOL &)::$_0>,ZinIrStatus ()(ZinIrBasicBlock *)>::target(uint64_t a1, uint64_t a2)
{
  {
    return a1 + 8;
  }
  else
  {
    return 0;
  }
}

void *std::__function::__func<PressureBasedSubgraphIdentification::AddCopyForLiveOutWithMultiFanOutParent(BOOL &)::$_0,std::allocator<PressureBasedSubgraphIdentification::AddCopyForLiveOutWithMultiFanOutParent(BOOL &)::$_0>,ZinIrStatus ()(ZinIrBasicBlock *)>::target_type()
{
}

void std::__function::__func<PressureBasedSubgraphIdentification::ConstructMemoryPressureMap(void)::$_0,std::allocator<PressureBasedSubgraphIdentification::ConstructMemoryPressureMap(void)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::~__func()
{
}

__n128 std::__function::__func<PressureBasedSubgraphIdentification::ConstructMemoryPressureMap(void)::$_0,std::allocator<PressureBasedSubgraphIdentification::ConstructMemoryPressureMap(void)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::__clone(uint64_t a1)
{
  uint64_t v2 = (char *)operator new(0x28uLL);
  *(void *)uint64_t v2 = &unk_26C32FB18;
  *(_OWORD *)(v2 + 8) = *(_OWORD *)(a1 + 8);
  __n128 result = *(__n128 *)(a1 + 24);
  *(__n128 *)(v2 + 24) = result;
  return result;
}

__n128 std::__function::__func<PressureBasedSubgraphIdentification::ConstructMemoryPressureMap(void)::$_0,std::allocator<PressureBasedSubgraphIdentification::ConstructMemoryPressureMap(void)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::__clone(uint64_t a1, uint64_t a2)
{
  *(void *)a2 = &unk_26C32FB18;
  __n128 result = *(__n128 *)(a1 + 8);
  *(_OWORD *)(a2 + 24) = *(_OWORD *)(a1 + 24);
  *(__n128 *)(a2 + 8) = result;
  return result;
}

uint64_t std::__function::__func<PressureBasedSubgraphIdentification::ConstructMemoryPressureMap(void)::$_0,std::allocator<PressureBasedSubgraphIdentification::ConstructMemoryPressureMap(void)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::operator()(uint64_t a1, uint64_t a2, void *a3)
{
  uint64_t v4 = *a3;
  uint64_t v5 = *(void *)(a1 + 24);
  uint64_t v6 = (ZinIrTensor *)(*(uint64_t (**)(void, void, void))(*(void *)*a3 + 32))(*a3, 0, 0);
  RootTensor = ZinIrTensor::GetRootTensor(v6);
  std::__tree<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const*>(*(uint64_t ***)(a1 + 8), (uint64_t *)&RootTensor, (uint64_t *)&RootTensor);
  if (!std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(*(void **)(a1 + 16), &RootTensor))
  {
    int v7 = *(_DWORD *)(*(void *)(v4 + 64) + 8);
    if ((v7 & 0xFFFFFFFC) == 0x1C
      || !*(unsigned char *)(*(void *)(v5 + 64) + 2)
      && (uint64_t v11 = *((void *)RootTensor + 13)) != 0
      && *(_DWORD *)(v11 + 96) == 2)
    {
      std::__hash_table<ZinIrTensor const*,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const* const&>(*(void *)(a1 + 16), &RootTensor, &RootTensor);
      int v7 = *(_DWORD *)(*(void *)(v4 + 64) + 8);
    }
    if ((v7 & 0xFFFFFFFC) == 0x1C)
    {
      size_t v8 = RootTensor;
      DimensionOrderHint::DimensionOrderHint(__p, 0);
      ZinIrTensor::GetTensorSizeInBytesFromResidency(v8, 2, (uint64_t)__p, 0);
      **(void **)(a1 + 32) += v9;
      if (__p[0])
      {
        __p[1] = __p[0];
        operator delete(__p[0]);
      }
    }
  }
  return 0;
}

void sub_211299C38(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t std::__function::__func<PressureBasedSubgraphIdentification::ConstructMemoryPressureMap(void)::$_0,std::allocator<PressureBasedSubgraphIdentification::ConstructMemoryPressureMap(void)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::target(uint64_t a1, uint64_t a2)
{
  {
    return a1 + 8;
  }
  else
  {
    return 0;
  }
}

void *std::__function::__func<PressureBasedSubgraphIdentification::ConstructMemoryPressureMap(void)::$_0,std::allocator<PressureBasedSubgraphIdentification::ConstructMemoryPressureMap(void)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::target_type()
{
}

uint64_t *std::list<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::list<std::__wrap_iter<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>*>>(uint64_t *a1, uint64_t a2, uint64_t a3)
{
  *a1 = (uint64_t)a1;
  a1[1] = (uint64_t)a1;
  a1[2] = 0;
  if (a2 != a3)
  {
    uint64_t v5 = a2;
    do
    {
      uint64_t v6 = std::__list_imp<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::__create_node[abi:ne180100]<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>&>((uint64_t)a1, 0, 0, v5);
      uint64_t v7 = *a1;
      void *v6 = *a1;
      v6[1] = a1;
      *(void *)(v7 + 8) = v6;
      *a1 = (uint64_t)v6;
      ++a1[2];
      v5 += 48;
    }
    while (v5 != a3);
  }
  return a1;
}

void sub_211299D20(_Unwind_Exception *a1)
{
  std::__list_imp<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::clear(v1);
  _Unwind_Resume(a1);
}

void *std::__list_imp<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>>::__create_node[abi:ne180100]<std::pair<ZinLiveRange,SubgraphIdentification::SubgraphIdentificationResult>&>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v7 = operator new(0x40uLL);
  void *v7 = a2;
  v7[1] = a3;
  *((_OWORD *)v7 + 1) = *(_OWORD *)a4;
  v7[5] = 0;
  v7[6] = 0;
  v7[4] = 0;
  std::vector<Subgraph>::__init_with_size[abi:ne180100]<Subgraph*,Subgraph*>(v7 + 4, *(void *)(a4 + 16), *(void *)(a4 + 24), 0x86BCA1AF286BCA1BLL * ((uint64_t)(*(void *)(a4 + 24) - *(void *)(a4 + 16)) >> 3));
  *((_DWORD *)v7 + 14) = *(_DWORD *)(a4 + 40);
  return v7;
}

void sub_211299DB4(_Unwind_Exception *a1)
{
  operator delete(v1);
  _Unwind_Resume(a1);
}

__n128 std::deque<std::pair<ZinIrOpLayer *,ZinIrOpLayer *>>::push_back(void *a1, __n128 *a2)
{
  uint64_t v4 = a1[2];
  uint64_t v5 = a1[1];
  uint64_t v6 = 32 * (v4 - v5) - 1;
  if (v4 == v5) {
    uint64_t v6 = 0;
  }
  unint64_t v7 = a1[5] + a1[4];
  if (v6 == v7)
  {
    std::deque<std::pair<ZinIrOpLayer *,ZinIrOpLayer *>>::__add_back_capacity(a1);
    uint64_t v5 = a1[1];
    unint64_t v7 = a1[5] + a1[4];
  }
  __n128 result = *a2;
  *(__n128 *)(*(void *)(v5 + ((v7 >> 5) & 0x7FFFFFFFFFFFFF8)) + 16 * v7) = *a2;
  ++a1[5];
  return result;
}

void std::deque<std::pair<ZinIrOpLayer *,ZinIrOpLayer *>>::__add_back_capacity(void *a1)
{
  unint64_t v2 = a1[4];
  BOOL v3 = v2 >= 0x100;
  unint64_t v4 = v2 - 256;
  if (v3)
  {
    uint64_t v5 = (uint64_t)(a1 + 3);
    uint64_t v6 = (char *)a1[3];
    a1[4] = v4;
    unint64_t v7 = (void *)a1[1];
    size_t v8 = (char *)a1[2];
    uint64_t v11 = *v7;
    uint64_t v9 = (char *)(v7 + 1);
    uint64_t v10 = v11;
    a1[1] = v9;
    if (v8 != v6)
    {
LABEL_33:
      *(void *)size_t v8 = v10;
      a1[2] += 8;
      return;
    }
    uint64_t v12 = (uint64_t)&v9[-*a1];
    if ((unint64_t)v9 <= *a1)
    {
      if (v8 == (char *)*a1) {
        unint64_t v33 = 1;
      }
      else {
        unint64_t v33 = (uint64_t)&v8[-*a1] >> 2;
      }
      uint64_t v34 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>(v5, v33);
      uint64_t v35 = &v34[8 * (v33 >> 2)];
      uint64_t v37 = &v34[8 * v36];
      uint64_t v38 = (uint64_t *)a1[1];
      size_t v8 = v35;
      uint64_t v39 = a1[2] - (void)v38;
      if (v39)
      {
        size_t v8 = &v35[v39 & 0xFFFFFFFFFFFFFFF8];
        uint64_t v40 = 8 * (v39 >> 3);
        uint64_t v41 = &v34[8 * (v33 >> 2)];
        do
        {
          uint64_t v42 = *v38++;
          *(void *)uint64_t v41 = v42;
          v41 += 8;
          v40 -= 8;
        }
        while (v40);
      }
      goto LABEL_30;
    }
LABEL_5:
    uint64_t v13 = v12 >> 3;
    BOOL v14 = v12 >> 3 < -1;
    uint64_t v15 = (v12 >> 3) + 2;
    if (v14) {
      uint64_t v16 = v15;
    }
    else {
      uint64_t v16 = v13 + 1;
    }
    uint64_t v17 = -(v16 >> 1);
    uint64_t v18 = v16 >> 1;
    uint64_t v19 = &v9[-8 * v18];
    int64_t v20 = v8 - v9;
    if (v8 != v9)
    {
      memmove(&v9[-8 * v18], v9, v8 - v9);
      uint64_t v9 = (char *)a1[1];
    }
    size_t v8 = &v19[v20];
    a1[1] = &v9[8 * v17];
    a1[2] = &v19[v20];
    goto LABEL_33;
  }
  uint64_t v21 = a1[2];
  unint64_t v22 = (v21 - a1[1]) >> 3;
  uint64_t v23 = a1[3];
  uint64_t v24 = v23 - *a1;
  if (v22 < v24 >> 3)
  {
    if (v23 != v21)
    {
      *(void *)&long long v54 = operator new(0x1000uLL);
      std::__split_buffer<unsigned long *>::push_back(a1, &v54);
      return;
    }
    *(void *)&long long v54 = operator new(0x1000uLL);
    std::__split_buffer<unsigned long *>::push_front((uint64_t)a1, &v54);
    uint64_t v44 = (void *)a1[1];
    size_t v8 = (char *)a1[2];
    uint64_t v45 = *v44;
    uint64_t v9 = (char *)(v44 + 1);
    uint64_t v10 = v45;
    a1[1] = v9;
    if (v8 != (char *)a1[3]) {
      goto LABEL_33;
    }
    uint64_t v12 = (uint64_t)&v9[-*a1];
    if ((unint64_t)v9 <= *a1)
    {
      if (v8 == (char *)*a1) {
        unint64_t v46 = 1;
      }
      else {
        unint64_t v46 = (uint64_t)&v8[-*a1] >> 2;
      }
      uint64_t v34 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)(a1 + 3), v46);
      uint64_t v35 = &v34[8 * (v46 >> 2)];
      uint64_t v37 = &v34[8 * v47];
      uint64_t v48 = (uint64_t *)a1[1];
      size_t v8 = v35;
      uint64_t v49 = a1[2] - (void)v48;
      if (v49)
      {
        size_t v8 = &v35[v49 & 0xFFFFFFFFFFFFFFF8];
        uint64_t v50 = 8 * (v49 >> 3);
        char v51 = &v34[8 * (v46 >> 2)];
        do
        {
          uint64_t v52 = *v48++;
          *(void *)char v51 = v52;
          v51 += 8;
          v50 -= 8;
        }
        while (v50);
      }
LABEL_30:
      int64_t v43 = (char *)*a1;
      *a1 = v34;
      a1[1] = v35;
      a1[2] = v8;
      a1[3] = v37;
      if (v43)
      {
        operator delete(v43);
        size_t v8 = (char *)a1[2];
      }
      goto LABEL_33;
    }
    goto LABEL_5;
  }
  if (v23 == *a1) {
    unint64_t v25 = 1;
  }
  else {
    unint64_t v25 = v24 >> 2;
  }
  uint64_t v56 = a1 + 3;
  *(void *)&long long v54 = std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)(a1 + 3), v25);
  *((void *)&v54 + 1) = v54 + 8 * v22;
  *(void *)&long long v55 = *((void *)&v54 + 1);
  *((void *)&v55 + 1) = v54 + 8 * v26;
  uint64_t v53 = operator new(0x1000uLL);
  std::__split_buffer<unsigned long *>::push_back(&v54, &v53);
  long long v27 = (void *)a1[2];
  uint64_t v28 = -7 - (void)v27;
  while (v27 != (void *)a1[1])
  {
    --v27;
    v28 += 8;
    std::__split_buffer<unsigned long *>::push_front((uint64_t)&v54, v27);
  }
  std::string::size_type v29 = (char *)*a1;
  long long v30 = v54;
  long long v31 = v55;
  *(void *)&long long v54 = *a1;
  *((void *)&v54 + 1) = v27;
  long long v32 = *((_OWORD *)a1 + 1);
  *(_OWORD *)a1 = v30;
  *((_OWORD *)a1 + 1) = v31;
  long long v55 = v32;
  if (v27 != (void *)v32) {
    *(void *)&long long v55 = v32 + (-(v32 + v28) & 0xFFFFFFFFFFFFFFF8);
  }
  if (v29) {
    operator delete(v29);
  }
}

void sub_21129A120(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, void *__p, uint64_t a12, uint64_t a13)
{
  operator delete(v13);
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(a1);
}

uint64_t *std::deque<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::push_back(void *a1, ZinIrOpLayer ***a2)
{
  uint64_t v4 = a1[1];
  uint64_t v5 = a1[2];
  uint64_t v6 = 170 * ((v5 - v4) >> 3) - 1;
  if (v5 == v4) {
    uint64_t v6 = 0;
  }
  if (v6 == a1[5] + a1[4])
  {
    std::deque<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::__add_back_capacity(a1);
    uint64_t v4 = a1[1];
    uint64_t v5 = a1[2];
  }
  if (v5 == v4)
  {
    size_t v8 = 0;
  }
  else
  {
    unint64_t v7 = a1[5] + a1[4];
    size_t v8 = (uint64_t *)(*(void *)(v4 + 8 * (v7 / 0xAA)) + 24 * (v7 % 0xAA));
  }
  __n128 result = std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::set[abi:ne180100](v8, a2);
  ++a1[5];
  return result;
}

void std::deque<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::__add_back_capacity(void *a1)
{
  unint64_t v2 = a1[4];
  BOOL v3 = v2 >= 0xAA;
  unint64_t v4 = v2 - 170;
  if (v3)
  {
    uint64_t v5 = (uint64_t)(a1 + 3);
    uint64_t v6 = (char *)a1[3];
    a1[4] = v4;
    unint64_t v7 = (void *)a1[1];
    size_t v8 = (char *)a1[2];
    uint64_t v11 = *v7;
    uint64_t v9 = (char *)(v7 + 1);
    uint64_t v10 = v11;
    a1[1] = v9;
    if (v8 != v6)
    {
LABEL_33:
      *(void *)size_t v8 = v10;
      a1[2] += 8;
      return;
    }
    uint64_t v12 = (uint64_t)&v9[-*a1];
    if ((unint64_t)v9 <= *a1)
    {
      if (v8 == (char *)*a1) {
        unint64_t v33 = 1;
      }
      else {
        unint64_t v33 = (uint64_t)&v8[-*a1] >> 2;
      }
      uint64_t v34 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>(v5, v33);
      uint64_t v35 = &v34[8 * (v33 >> 2)];
      uint64_t v37 = &v34[8 * v36];
      uint64_t v38 = (uint64_t *)a1[1];
      size_t v8 = v35;
      uint64_t v39 = a1[2] - (void)v38;
      if (v39)
      {
        size_t v8 = &v35[v39 & 0xFFFFFFFFFFFFFFF8];
        uint64_t v40 = 8 * (v39 >> 3);
        uint64_t v41 = &v34[8 * (v33 >> 2)];
        do
        {
          uint64_t v42 = *v38++;
          *(void *)uint64_t v41 = v42;
          v41 += 8;
          v40 -= 8;
        }
        while (v40);
      }
      goto LABEL_30;
    }
LABEL_5:
    uint64_t v13 = v12 >> 3;
    BOOL v14 = v12 >> 3 < -1;
    uint64_t v15 = (v12 >> 3) + 2;
    if (v14) {
      uint64_t v16 = v15;
    }
    else {
      uint64_t v16 = v13 + 1;
    }
    uint64_t v17 = -(v16 >> 1);
    uint64_t v18 = v16 >> 1;
    uint64_t v19 = &v9[-8 * v18];
    int64_t v20 = v8 - v9;
    if (v8 != v9)
    {
      memmove(&v9[-8 * v18], v9, v8 - v9);
      uint64_t v9 = (char *)a1[1];
    }
    size_t v8 = &v19[v20];
    a1[1] = &v9[8 * v17];
    a1[2] = &v19[v20];
    goto LABEL_33;
  }
  uint64_t v21 = a1[2];
  unint64_t v22 = (v21 - a1[1]) >> 3;
  uint64_t v23 = a1[3];
  uint64_t v24 = v23 - *a1;
  if (v22 < v24 >> 3)
  {
    if (v23 != v21)
    {
      *(void *)&long long v54 = operator new(0xFF0uLL);
      std::__split_buffer<unsigned long *>::push_back(a1, &v54);
      return;
    }
    *(void *)&long long v54 = operator new(0xFF0uLL);
    std::__split_buffer<unsigned long *>::push_front((uint64_t)a1, &v54);
    uint64_t v44 = (void *)a1[1];
    size_t v8 = (char *)a1[2];
    uint64_t v45 = *v44;
    uint64_t v9 = (char *)(v44 + 1);
    uint64_t v10 = v45;
    a1[1] = v9;
    if (v8 != (char *)a1[3]) {
      goto LABEL_33;
    }
    uint64_t v12 = (uint64_t)&v9[-*a1];
    if ((unint64_t)v9 <= *a1)
    {
      if (v8 == (char *)*a1) {
        unint64_t v46 = 1;
      }
      else {
        unint64_t v46 = (uint64_t)&v8[-*a1] >> 2;
      }
      uint64_t v34 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)(a1 + 3), v46);
      uint64_t v35 = &v34[8 * (v46 >> 2)];
      uint64_t v37 = &v34[8 * v47];
      uint64_t v48 = (uint64_t *)a1[1];
      size_t v8 = v35;
      uint64_t v49 = a1[2] - (void)v48;
      if (v49)
      {
        size_t v8 = &v35[v49 & 0xFFFFFFFFFFFFFFF8];
        uint64_t v50 = 8 * (v49 >> 3);
        char v51 = &v34[8 * (v46 >> 2)];
        do
        {
          uint64_t v52 = *v48++;
          *(void *)char v51 = v52;
          v51 += 8;
          v50 -= 8;
        }
        while (v50);
      }
LABEL_30:
      int64_t v43 = (char *)*a1;
      *a1 = v34;
      a1[1] = v35;
      a1[2] = v8;
      a1[3] = v37;
      if (v43)
      {
        operator delete(v43);
        size_t v8 = (char *)a1[2];
      }
      goto LABEL_33;
    }
    goto LABEL_5;
  }
  if (v23 == *a1) {
    unint64_t v25 = 1;
  }
  else {
    unint64_t v25 = v24 >> 2;
  }
  uint64_t v56 = a1 + 3;
  *(void *)&long long v54 = std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)(a1 + 3), v25);
  *((void *)&v54 + 1) = v54 + 8 * v22;
  *(void *)&long long v55 = *((void *)&v54 + 1);
  *((void *)&v55 + 1) = v54 + 8 * v26;
  uint64_t v53 = operator new(0xFF0uLL);
  std::__split_buffer<unsigned long *>::push_back(&v54, &v53);
  long long v27 = (void *)a1[2];
  uint64_t v28 = -7 - (void)v27;
  while (v27 != (void *)a1[1])
  {
    --v27;
    v28 += 8;
    std::__split_buffer<unsigned long *>::push_front((uint64_t)&v54, v27);
  }
  std::string::size_type v29 = (char *)*a1;
  long long v30 = v54;
  long long v31 = v55;
  *(void *)&long long v54 = *a1;
  *((void *)&v54 + 1) = v27;
  long long v32 = *((_OWORD *)a1 + 1);
  *(_OWORD *)a1 = v30;
  *((_OWORD *)a1 + 1) = v31;
  long long v55 = v32;
  if (v27 != (void *)v32) {
    *(void *)&long long v55 = v32 + (-(v32 + v28) & 0xFFFFFFFFFFFFFFF8);
  }
  if (v29) {
    operator delete(v29);
  }
}

void sub_21129A4E8(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, void *__p, uint64_t a12, uint64_t a13)
{
  operator delete(v13);
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(a1);
}

uint64_t std::deque<std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>>::pop_front(int64x2_t *a1)
{
  uint64_t v2 = *(void *)(a1->i64[1] + 8 * (a1[2].i64[0] / 0xAAuLL)) + 24 * (a1[2].i64[0] % 0xAAuLL);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy(v2, *(void **)(v2 + 8));
  a1[2] = vaddq_s64(a1[2], (int64x2_t)xmmword_211EE1AE0);

  return std::deque<std::string>::__maybe_remove_front_spare[abi:ne180100]((uint64_t)a1, 1);
}

uint64_t *std::__tree<std::__value_type<ZinIrTensor *,std::set<ZinRingBufferWriterLayer *,ScheduleComparator,std::allocator<ZinRingBufferWriterLayer *>>>,std::__map_value_compare<ZinIrTensor *,std::__value_type<ZinIrTensor *,std::set<ZinRingBufferWriterLayer *,ScheduleComparator,std::allocator<ZinRingBufferWriterLayer *>>>,ZinIrIdComparator<ZinIrTensor *>,true>,std::allocator<std::__value_type<ZinIrTensor *,std::set<ZinRingBufferWriterLayer *,ScheduleComparator,std::allocator<ZinRingBufferWriterLayer *>>>>>::__emplace_unique_key_args<ZinIrTensor *,std::piecewise_construct_t const&,std::tuple<ZinIrTensor * const&>,std::tuple<>>(uint64_t **a1, uint64_t *a2, uint64_t a3, uint64_t **a4)
{
  uint64_t v6 = (uint64_t **)std::__tree<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__find_equal<ZinIrTensor const*>((uint64_t)a1, &v11, a2);
  unint64_t v7 = *v6;
  if (!*v6)
  {
    size_t v8 = v6;
    unint64_t v7 = (uint64_t *)operator new(0x40uLL);
    uint64_t v9 = **a4;
    v7[7] = 0;
    v7[6] = 0;
    v7[4] = v9;
    v7[5] = (uint64_t)(v7 + 6);
    std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::__insert_node_at(a1, v11, v8, v7);
  }
  return v7;
}

uint64_t *std::set<ZinRingBufferWriterLayer *,ScheduleComparator,std::allocator<ZinRingBufferWriterLayer *>>::set[abi:ne180100](uint64_t *a1, ZinIrOpLayer ***a2)
{
  a1[2] = 0;
  a1[1] = 0;
  *a1 = (uint64_t)(a1 + 1);
  std::set<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::insert[abi:ne180100]<std::__tree_const_iterator<ZinIrOpLayer *,std::__tree_node<ZinIrOpLayer *,void *> *,long>>(a1, *a2, a2 + 1);
  return a1;
}

void sub_21129A688(_Unwind_Exception *a1)
{
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy(v1, *(void **)(v1 + 8));
  _Unwind_Resume(a1);
}

void *std::__tree<std::__value_type<MinDMABufferMapKey,long>,std::__map_value_compare<MinDMABufferMapKey,std::__value_type<MinDMABufferMapKey,long>,std::less<MinDMABufferMapKey>,true>,std::allocator<std::__value_type<MinDMABufferMapKey,long>>>::find<MinDMABufferMapKey>(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = (void *)(a1 + 8);
  BOOL v3 = *(void **)(a1 + 8);
  if (!v3) {
    return v2;
  }
  uint64_t v5 = (void *)(a1 + 8);
  do
  {
    int v6 = MinDMABufferMapKey::operator<((uint64_t)(v3 + 4), a2);
    unint64_t v7 = v3 + 1;
    if (!v6)
    {
      unint64_t v7 = v3;
      uint64_t v5 = v3;
    }
    BOOL v3 = (void *)*v7;
  }
  while (*v7);
  if (v5 == v2 || MinDMABufferMapKey::operator<(a2, (uint64_t)(v5 + 4))) {
    return v2;
  }
  return v5;
}

void std::__hash_table<ZinIrOpLayer *,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,std::allocator<ZinIrOpLayer *>>::swap(uint64_t a1, uint64_t a2)
{
  unint64_t v4 = *(void **)a1;
  *(void *)a1 = 0;
  uint64_t v5 = *(void **)a2;
  *(void *)a2 = 0;
  int v6 = *(void **)a1;
  *(void *)a1 = v5;
  if (v6) {
    operator delete(v6);
  }
  unint64_t v7 = *(void **)a2;
  *(void *)a2 = v4;
  if (v7) {
    operator delete(v7);
  }
  uint64_t v8 = *(void *)(a1 + 16);
  uint64_t v9 = *(void *)(a1 + 8);
  uint64_t v10 = *(void *)(a2 + 16);
  *(void *)(a1 + 8) = *(void *)(a2 + 8);
  *(void *)(a2 + 8) = v9;
  uint64_t v11 = *(void *)(a1 + 24);
  uint64_t v12 = *(void *)(a2 + 24);
  *(void *)(a1 + 16) = v10;
  *(void *)(a1 + 24) = v12;
  *(void *)(a2 + 16) = v8;
  *(void *)(a2 + 24) = v11;
  int v13 = *(_DWORD *)(a1 + 32);
  *(_DWORD *)(a1 + std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_DWORD *)(a2 + 32);
  *(_DWORD *)(a2 + std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = v13;
  if (*(void *)(a1 + 24))
  {
    unint64_t v14 = *(void *)(a1 + 8);
    unint64_t v15 = *(void *)(*(void *)(a1 + 16) + 8);
    if ((v14 & (v14 - 1)) != 0)
    {
      if (v15 >= v14) {
        v15 %= v14;
      }
    }
    else
    {
      v15 &= v14 - 1;
    }
    *(void *)(*(void *)a1 + 8 * v15) = a1 + 16;
  }
  if (v11)
  {
    unint64_t v16 = *(void *)(a2 + 8);
    unint64_t v17 = *(void *)(*(void *)(a2 + 16) + 8);
    if ((v16 & (v16 - 1)) != 0)
    {
      if (v17 >= v16) {
        v17 %= v16;
      }
    }
    else
    {
      v17 &= v16 - 1;
    }
    *(void *)(*(void *)a2 + 8 * v17) = a2 + 16;
  }
}

uint64_t *std::__tree<std::__value_type<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>,std::__map_value_compare<ZinIrOpLayer *,std::__value_type<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>,ScheduleComparator,true>,std::allocator<std::__value_type<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>>::__emplace_unique_key_args<ZinIrOpLayer *,ZinIrOpLayer *&,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>(uint64_t **a1, ZinIrOpLayer **a2, void *a3, uint64_t *a4)
{
  unint64_t v7 = (uint64_t **)std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__find_equal<ZinIrOpLayer *>((uint64_t)a1, &v10, a2);
  __n128 result = *v7;
  if (!*v7)
  {
    std::__tree<std::__value_type<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>,std::__map_value_compare<ZinIrOpLayer *,std::__value_type<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>,ScheduleComparator,true>,std::allocator<std::__value_type<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>>::__construct_node<ZinIrOpLayer *&,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>((uint64_t)a1, a3, a4, (uint64_t)&v9);
    std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::__insert_node_at(a1, v10, v7, v9);
    return v9;
  }
  return result;
}

void *std::__tree<std::__value_type<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>,std::__map_value_compare<ZinIrOpLayer *,std::__value_type<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>,ScheduleComparator,true>,std::allocator<std::__value_type<ZinIrOpLayer *,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>>>::__construct_node<ZinIrOpLayer *&,std::set<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>>@<X0>(uint64_t a1@<X0>, void *a2@<X1>, uint64_t *a3@<X2>, uint64_t a4@<X8>)
{
  uint64_t v7 = a1 + 8;
  __n128 result = operator new(0x40uLL);
  *(void *)a4 = result;
  *(void *)(a4 + 8) = v7;
  uint64_t v9 = *a3;
  uint64_t v10 = a3 + 1;
  uint64_t v11 = a3[1];
  result[4] = *a2;
  result[5] = v9;
  result[6] = v11;
  uint64_t v12 = result + 6;
  uint64_t v13 = a3[2];
  result[7] = v13;
  if (v13)
  {
    *(void *)(v11 + 16) = v12;
    *a3 = (uint64_t)v10;
    *uint64_t v10 = 0;
    a3[2] = 0;
  }
  else
  {
    result[5] = v12;
  }
  *(unsigned char *)(a4 + 16) = 1;
  return result;
}

uint64_t *std::__tree<std::__value_type<ZinANELayer *,CostModelParameters>,std::__map_value_compare<ZinANELayer *,std::__value_type<ZinANELayer *,CostModelParameters>,ScheduleComparator,true>,std::allocator<std::__value_type<ZinANELayer *,CostModelParameters>>>::__emplace_unique_key_args<ZinANELayer *,ZinANELayer *&,CostModelParameters&>(uint64_t **a1, ZinIrOpLayer **a2, void *a3, uint64_t a4)
{
  uint64_t v7 = (uint64_t **)std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__find_equal<ZinIrOpLayer *>((uint64_t)a1, &v10, a2);
  __n128 result = *v7;
  if (!*v7)
  {
    std::__tree<std::__value_type<ZinANELayer *,CostModelParameters>,std::__map_value_compare<ZinANELayer *,std::__value_type<ZinANELayer *,CostModelParameters>,ScheduleComparator,true>,std::allocator<std::__value_type<ZinANELayer *,CostModelParameters>>>::__construct_node<ZinANELayer *&,CostModelParameters&>((uint64_t)a1, a3, a4, (uint64_t)&v9);
    std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::__insert_node_at(a1, v10, v7, v9);
    return v9;
  }
  return result;
}

void *std::__tree<std::__value_type<ZinANELayer *,CostModelParameters>,std::__map_value_compare<ZinANELayer *,std::__value_type<ZinANELayer *,CostModelParameters>,ScheduleComparator,true>,std::allocator<std::__value_type<ZinANELayer *,CostModelParameters>>>::__construct_node<ZinANELayer *&,CostModelParameters&>@<X0>(uint64_t a1@<X0>, void *a2@<X1>, uint64_t a3@<X2>, uint64_t a4@<X8>)
{
  uint64_t v7 = a1 + 8;
  uint64_t v8 = operator new(0x48uLL);
  *(void *)a4 = v8;
  *(void *)(a4 + 8) = v7;
  *(unsigned char *)(a4 + 16) = 0;
  v8[4] = *a2;
  v8[6] = 0;
  v8[7] = 0;
  v8[5] = 0;
  __n128 result = std::vector<unsigned short>::__init_with_size[abi:ne180100]<unsigned short const*,unsigned short const*>(v8 + 5, *(const void **)a3, *(void *)(a3 + 8), (uint64_t)(*(void *)(a3 + 8) - *(void *)a3) >> 1);
  *((_WORD *)v8 + std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_WORD *)(a3 + 24);
  *(unsigned char *)(a4 + 16) = 1;
  return result;
}

void sub_21129AA48(_Unwind_Exception *a1)
{
  *uint64_t v1 = 0;
  std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,void *>>>::operator()[abi:ne180100](v3, v2);
  _Unwind_Resume(a1);
}

char *std::__tree<std::__value_type<ZinANELayer *,CostModelParameters>,std::__map_value_compare<ZinANELayer *,std::__value_type<ZinANELayer *,CostModelParameters>,ScheduleComparator,true>,std::allocator<std::__value_type<ZinANELayer *,CostModelParameters>>>::__emplace_unique_key_args<ZinANELayer *,std::piecewise_construct_t const&,std::tuple<ZinANELayer * const&>,std::tuple<>>(uint64_t **a1, ZinIrOpLayer **a2, uint64_t a3, void **a4)
{
  int v6 = std::__tree<ZinIrOpLayer *,ScheduleComparator,std::allocator<ZinIrOpLayer *>>::__find_equal<ZinIrOpLayer *>((uint64_t)a1, &v10, a2);
  uint64_t v7 = (char *)*v6;
  if (!*v6)
  {
    uint64_t v8 = (uint64_t **)v6;
    uint64_t v7 = (char *)operator new(0x48uLL);
    *((void *)v7 + 4) = **a4;
    *(_OWORD *)(v7 + 56) = 0u;
    *(_OWORD *)(v7 + 40) = 0u;
    std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::__insert_node_at(a1, v10, v8, (uint64_t *)v7);
  }
  return v7;
}

uint64_t std::__hash_table<std::__hash_value_type<long,PressureBasedSubgraphIdentification::CopyPressure>,std::__unordered_map_hasher<long,std::__hash_value_type<long,PressureBasedSubgraphIdentification::CopyPressure>,std::hash<long>,std::equal_to<long>,true>,std::__unordered_map_equal<long,std::__hash_value_type<long,PressureBasedSubgraphIdentification::CopyPressure>,std::equal_to<long>,std::hash<long>,true>,std::allocator<std::__hash_value_type<long,PressureBasedSubgraphIdentification::CopyPressure>>>::~__hash_table(uint64_t a1)
{
  std::__hash_table<std::__hash_value_type<long,PressureBasedSubgraphIdentification::CopyPressure>,std::__unordered_map_hasher<long,std::__hash_value_type<long,PressureBasedSubgraphIdentification::CopyPressure>,std::hash<long>,std::equal_to<long>,true>,std::__unordered_map_equal<long,std::__hash_value_type<long,PressureBasedSubgraphIdentification::CopyPressure>,std::equal_to<long>,std::hash<long>,true>,std::allocator<std::__hash_value_type<long,PressureBasedSubgraphIdentification::CopyPressure>>>::__deallocate_node(a1, *(void ***)(a1 + 16));
  uint64_t v2 = *(void **)a1;
  *(void *)a1 = 0;
  if (v2) {
    operator delete(v2);
  }
  return a1;
}

void std::__hash_table<std::__hash_value_type<long,PressureBasedSubgraphIdentification::CopyPressure>,std::__unordered_map_hasher<long,std::__hash_value_type<long,PressureBasedSubgraphIdentification::CopyPressure>,std::hash<long>,std::equal_to<long>,true>,std::__unordered_map_equal<long,std::__hash_value_type<long,PressureBasedSubgraphIdentification::CopyPressure>,std::equal_to<long>,std::hash<long>,true>,std::allocator<std::__hash_value_type<long,PressureBasedSubgraphIdentification::CopyPressure>>>::__deallocate_node(uint64_t a1, void **a2)
{
  if (a2)
  {
    uint64_t v2 = a2;
    do
    {
      uint64_t v3 = *v2;
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)(v2 + 6), v2[7]);
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)(v2 + 3), v2[4]);
      operator delete(v2);
      uint64_t v2 = (void **)v3;
    }
    while (v3);
  }
}

void PressureBasedSubgraphIdentification::IdentifySubgraphs()
{
  *(_WORD *)v0 = 0;
  _os_log_debug_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_DEBUG, "DEBUG: DRAM legalizer failed. Memory allocation may fail later.\n", v0, 2u);
}

uint64_t ZinParseLinearUnit(const __CFDictionary *a1, ZinIrLinearUnitInfo *a2, CFArrayRef *a3)
{
  CFDictionaryRef Value = (const __CFDictionary *)CFDictionaryGetValue(a1, @"Params");
  if (!Value || (CFDictionaryRef v6 = Value, v7 = CFGetTypeID(Value), v7 != CFDictionaryGetTypeID()))
  {
    ZinIrUnitStatus::SetError(a3, @"InvalidParamSyntax");
    return 3;
  }
  *((_DWORD *)a2 + 60) = 5;
  uint64_t v8 = CFDictionaryGetValue(v6, @"GroupDimension");
  if (v8)
  {
    uint64_t v9 = v8;
    CFTypeID v10 = CFGetTypeID(v8);
    if (v10 == CFStringGetTypeID() && !CFStringToZinIrDimension(v9, (char *)a2 + 240)) {
      return 3;
    }
  }

  return ZinParseKernelAndFileInfo<ZinIrConvUnitInfo>(v6, (uint64_t)a2, a3);
}

uint64_t ZinMirOptFullyConnectedLayer(void *a1, uint64_t a2)
{
  v6[4] = *MEMORY[0x263EF8340];
  if (!*(unsigned char *)(*(void *)a2 + 1880)) {
    return 0;
  }
  v4[1] = 0;
  uint64_t v5 = 0;
  v4[0] = a2;
  v6[0] = &unk_26C32D128;
  v6[1] = v4;
  v6[3] = v6;
  uint64_t v2 = ZinIrControlFlowGraph::TraverseForward(a1, (uint64_t)v6, 1);
  std::__function::__value_func<ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::~__value_func[abi:ne180100](v6);
  if (v5) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v5);
  }
  return v2;
}

void sub_21129AD80(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, std::__shared_weak_count *a4, ...)
{
  va_start(va, a4);
  std::__function::__value_func<ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::~__value_func[abi:ne180100]((uint64_t *)va);
  if (a4) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a4);
  }
  _Unwind_Resume(a1);
}

void std::__function::__func<ZinMirOptFullyConnectedLayer(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0,std::allocator<ZinMirOptFullyConnectedLayer(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::~__func()
{
}

void *std::__function::__func<ZinMirOptFullyConnectedLayer(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0,std::allocator<ZinMirOptFullyConnectedLayer(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::__clone(uint64_t a1)
{
  __n128 result = operator new(0x10uLL);
  uint64_t v3 = *(void *)(a1 + 8);
  void *result = &unk_26C32D128;
  result[1] = v3;
  return result;
}

uint64_t std::__function::__func<ZinMirOptFullyConnectedLayer(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0,std::allocator<ZinMirOptFullyConnectedLayer(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::__clone(uint64_t result, void *a2)
{
  uint64_t v2 = *(void *)(result + 8);
  *a2 = &unk_26C32D128;
  a2[1] = v2;
  return result;
}

uint64_t std::__function::__func<ZinMirOptFullyConnectedLayer(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0,std::allocator<ZinMirOptFullyConnectedLayer(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::operator()(uint64_t a1, ZinIrOpLayerGraph **a2, const void ***a3)
{
  uint64_t v78 = *MEMORY[0x263EF8340];
  unint64_t v4 = *a3;
  uint64_t v5 = (char *)*a3 + 47;
  CFDictionaryRef v6 = *a2;
  if (*v5 >= 0) {
    size_t v7 = *((unsigned __int8 *)*a3 + 47);
  }
  else {
    size_t v7 = (size_t)(*a3)[4];
  }
  std::string::basic_string[abi:ne180100]((uint64_t)__p, v7 + 15);
  uint64_t v8 = v4 + 3;
  if (v63 >= 0) {
    uint64_t v9 = __p;
  }
  else {
    uint64_t v9 = (void **)__p[0];
  }
  if (v7)
  {
    if (*v5 >= 0) {
      CFTypeID v10 = v4 + 3;
    }
    else {
      CFTypeID v10 = *v8;
    }
    memmove(v9, v10, v7);
  }
  strcpy((char *)v9 + v7, "fc_optimization");
  ZinObjectNameFactory::ZinObjectNameFactory(v60, __p);
  if (v63 < 0) {
    operator delete(__p[0]);
  }
  if (*((_DWORD *)v4[8] + 2) != 85)
  {
    uint64_t inserted = 0;
    goto LABEL_77;
  }
  uint64_t v11 = *(uint64_t **)(a1 + 8);
  uint64_t v68 = 0;
  uint64_t v69 = 0;
  uint64_t v70 = 0;
  int v67 = 0;
  if (v4[54])
  {
    buf[0] = 0;
    if (IsInefficientFullyConnectedLayer((ZinNEConvLayer *)v4, v11, (uint64_t)v60, &v67, buf))
    {
      BOOL v12 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (!v12)
      {
LABEL_19:
        BOOL v20 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
        if (v20) {
          std::__function::__func<ZinMirOptFullyConnectedLayer(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0,std::allocator<ZinMirOptFullyConnectedLayer(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::operator()(v20, v21, v22, v23, v24, v25, v26, v27);
        }
        uint64_t inserted = 3;
        goto LABEL_72;
      }
LABEL_18:
      std::__function::__func<ZinMirOptFullyConnectedLayer(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0,std::allocator<ZinMirOptFullyConnectedLayer(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::operator()(v12, v13, v14, v15, v16, v17, v18, v19);
      goto LABEL_19;
    }
    if (buf[0])
    {
      *(void *)&long long __src = v4;
      std::vector<DimensionMapping>::__assign_with_size[abi:ne180100]<DimensionMapping const*,DimensionMapping const*>((char *)&v68, (char *)&__src, (uint64_t)&__src + 8, 1uLL);
      std::string::size_type v29 = (ZinNEConvLayer **)*((void *)*(v69 - 1) + 14);
      if (*((void *)*(v69 - 1) + 15) - (void)v29 == 8)
      {
        int v30 = v67;
        while (1)
        {
          long long v31 = *v29;
          if (*(_DWORD *)(*((void *)*v29 + 8) + 8) != 85) {
            goto LABEL_47;
          }
          LODWORD(__src) = 0;
          if (IsInefficientFullyConnectedLayer(v31, v11, (uint64_t)v60, (int *)&__src, buf)) {
            break;
          }
          if (buf[0] && v30 == __src)
          {
            long long v32 = v69;
            if (v69 >= v70)
            {
              uint64_t v34 = v69 - v68;
              if ((unint64_t)(v34 + 1) >> 61) {
                std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
              }
              unint64_t v35 = ((char *)v70 - (char *)v68) >> 2;
              if (v35 <= v34 + 1) {
                unint64_t v35 = v34 + 1;
              }
              if ((unint64_t)((char *)v70 - (char *)v68) >= 0x7FFFFFFFFFFFFFF8) {
                unint64_t v36 = 0x1FFFFFFFFFFFFFFFLL;
              }
              else {
                unint64_t v36 = v35;
              }
              if (v36) {
                uint64_t v37 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)&v70, v36);
              }
              else {
                uint64_t v37 = 0;
              }
              uint64_t v38 = (ZinNEConvLayer **)&v37[8 * v34];
              uint64_t *v38 = v31;
              unint64_t v33 = v38 + 1;
              uint64_t v40 = v68;
              uint64_t v39 = v69;
              if (v69 != v68)
              {
                do
                {
                  uint64_t v41 = *--v39;
                  *--uint64_t v38 = v41;
                }
                while (v39 != v40);
                uint64_t v39 = v68;
              }
              uint64_t v68 = v38;
              uint64_t v69 = v33;
              uint64_t v70 = (ZinNEConvLayer **)&v37[8 * v36];
              if (v39) {
                operator delete(v39);
              }
            }
            else
            {
              *uint64_t v69 = v31;
              unint64_t v33 = v32 + 1;
            }
            uint64_t v69 = v33;
            std::string::size_type v29 = (ZinNEConvLayer **)*((void *)*(v33 - 1) + 14);
            if (*((void *)*(v33 - 1) + 15) - (void)v29 == 8) {
              continue;
            }
          }
          goto LABEL_47;
        }
        BOOL v12 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
        if (!v12) {
          goto LABEL_19;
        }
        goto LABEL_18;
      }
LABEL_47:
      if (*(_DWORD *)(*(void *)(*v11 + 8) + 96) && os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_INFO))
      {
        uint64_t v42 = (void *)((char *)*v68 + 24);
        if (*((char *)*v68 + 47) < 0) {
          uint64_t v42 = (void *)*v42;
        }
        std::to_string((std::string *)&__src, v69 - v68);
        if ((SBYTE7(__src_16) & 0x80u) == 0) {
          p_src = &__src;
        }
        else {
          p_src = (long long *)__src;
        }
        *(_DWORD *)long long buf = 136315394;
        *(void *)&void buf[4] = v42;
        *(_WORD *)&unsigned char buf[12] = 2080;
        *(void *)&buf[14] = p_src;
        _os_log_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_INFO, "Batched FC layer chain is optimized: <Seed layer = %s, Chain length= %s> \n", buf, 0x16u);
        if (SBYTE7(__src_16) < 0) {
          operator delete((void *)__src);
        }
      }
      int v44 = v67;
      uint64_t v45 = (uint64_t **)*v68;
      CreatePreTransposeMap(v67, &__src);
      uint64_t inserted = InsertTransposes(&__src, v6, v45, 1);
      *(void *)long long buf = &__src;
      std::vector<std::vector<ZinIrOpLayer *>>::__destroy_vector::operator()[abi:ne180100]((void ***)buf);
      if (inserted) {
        goto LABEL_72;
      }
      unint64_t v46 = (void **)*(v69 - 1);
      uint64_t v59 = *v46[14];
      uint64_t v47 = (ZinIrTensor *)((uint64_t (*)(void **, void, void))(*v46)[4])(v46, 0, 0);
      ZinIrTensor::GetDimensionOrderHint(v47, (uint64_t)v66);
      if (v68 == v69)
      {
        uint64_t v52 = (uint64_t **)*(v68 - 1);
        CreatePostTransposeMap(v44, &__src);
        uint64_t inserted = InsertTransposes(&__src, v6, v52, 0);
        *(void *)long long buf = &__src;
        std::vector<std::vector<ZinIrOpLayer *>>::__destroy_vector::operator()[abi:ne180100]((void ***)buf);
        if (!inserted)
        {
          uint64_t v53 = **(ZinIrOpLayer ***)(v59 + 88);
          BOOL IsANELayer = ZinIrOpLayer::IsANELayer(v53);
          if (!DimensionOrderHint::IsSet((DimensionOrderHint *)v66)) {
            goto LABEL_83;
          }
          if (!IsANELayer)
          {
            uint64_t v57 = *((void *)v53 + 2);
            uint64_t v58 = *(unsigned int *)((*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)v53 + 32))(v53, 0, 0)+ 88);
            v65[0] = 0;
            LOBYTE(__p[0]) = 0;
            char v64 = 0;
            ZinBuilder::CreateNEBypass(v57, (uint64_t)v60, (uint64_t)v53, v58, v65, 0, (uint64_t)__p, 1.0);
          }
          long long v55 = (ZinIrTensor *)(*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)v53 + 32))(v53, 0, 0);
          if (ZinMirTensorTransform::FixDimensionOrder(v55, (uint64_t **)v6, (DimensionOrderHint *)v66, 0)) {
            uint64_t inserted = 3;
          }
          else {
LABEL_83:
          }
            uint64_t inserted = 0;
        }
        if (v66[0])
        {
          v66[1] = v66[0];
          operator delete(v66[0]);
        }
        goto LABEL_72;
      }
      uint64_t v48 = (*(uint64_t (**)(ZinNEConvLayer *, void, void))(*(void *)*v68 + 32))(*v68, 0, 0);
      uint64_t v49 = *(void *)(v48 + 80);
      long long v50 = *(_OWORD *)(v48 + 48);
      long long v51 = *(_OWORD *)(v48 + 64);
      long long __src = v50;
      long long __src_16 = v51;
      uint64_t v77 = v49;
      if (v44 == 3)
      {
        *(void *)&long long __src_16 = 1;
        uint64_t v49 = v51;
      }
      else if (v44 == 1)
      {
        uint64_t v77 = 1;
      }
      else
      {
        if (v44) {
          goto LABEL_65;
        }
        *(void *)&long long __src = 1;
        uint64_t v49 = v50;
      }
      *((void *)&__src_16 + 1) = v49;
LABEL_65:
      (*(void (**)(uint64_t *__return_ptr, void *, void))(v60[0] + 16))(&v74, v60, 0);
      memset(&v65[3], 0, 24);
      *(_DWORD *)long long buf = 0;
      *(void *)&uint8_t buf[16] = 0;
      uint64_t v72 = 0;
      *(void *)&uint8_t buf[8] = 0;
      int v73 = 0;
      ZinIrTensor::CreateTensor();
    }
  }
  uint64_t inserted = 0;
LABEL_72:
  if (v68)
  {
    uint64_t v69 = v68;
    operator delete(v68);
  }
  if (inserted && os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
    std::__function::__func<ZinMirOptFullyConnectedLayer(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0,std::allocator<ZinMirOptFullyConnectedLayer(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::operator()(v5, v8);
  }
LABEL_77:
  v60[0] = &unk_26C34DA98;
  if (v61 < 0) {
    operator delete((void *)v60[1]);
  }
  return inserted;
}

void sub_21129B6A8(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, void *a13, uint64_t a14, int a15, __int16 a16, char a17, char a18, uint64_t a19, char a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,int a28,__int16 a29,char a30,char a31,uint64_t a32,uint64_t a33,uint64_t a34,uint64_t a35,uint64_t a36,uint64_t a37,uint64_t a38,uint64_t a39,uint64_t a40,uint64_t a41,uint64_t a42,uint64_t a43,uint64_t a44,uint64_t a45,uint64_t a46,uint64_t a47,uint64_t a48,uint64_t a49,uint64_t a50,uint64_t a51,uint64_t a52,uint64_t a53,uint64_t a54,uint64_t a55,uint64_t a56,uint64_t a57,uint64_t a58,void *__p,uint64_t a60)
{
  if (__p) {
    operator delete(__p);
  }
  uint64_t v62 = *(void **)(v60 - 232);
  if (v62)
  {
    *(void *)(v60 - 224) = v62;
    operator delete(v62);
  }
  if (a18 < 0) {
    operator delete(a13);
  }
  _Unwind_Resume(exception_object);
}

uint64_t std::__function::__func<ZinMirOptFullyConnectedLayer(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0,std::allocator<ZinMirOptFullyConnectedLayer(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::target(uint64_t a1, uint64_t a2)
{
  {
    return a1 + 8;
  }
  else
  {
    return 0;
  }
}

void *std::__function::__func<ZinMirOptFullyConnectedLayer(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0,std::allocator<ZinMirOptFullyConnectedLayer(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::target_type()
{
}

uint64_t IsInefficientFullyConnectedLayer(ZinNEConvLayer *a1, uint64_t *a2, uint64_t a3, int *a4, unsigned char *a5)
{
  for (uint64_t i = (void **)*((void *)a1 + 14); i != *((void ***)a1 + 15); ++i)
  {
    if (*(_DWORD *)((*i)[8] + 8) == 33)
    {
      uint64_t result = 0;
      *a5 = 0;
      return result;
    }
  }
  (*(void (**)(uint64_t *__return_ptr, ZinNEConvLayer *))(*(void *)a1 + 136))(&v65, a1);
  CFTypeID v10 = (void *)(*(uint64_t (**)(void, void, void))(***((void ***)a1 + 11) + 32))(**((void **)a1 + 11), 0, 0);
  uint64_t v11 = v10[6];
  uint64_t v12 = v10[8];
  uint64_t v13 = v10[10];
  uint64_t v14 = (void *)(*(uint64_t (**)(ZinNEConvLayer *, void, void))(*(void *)a1 + 32))(a1, 0, 0);
  uint64_t v15 = v14[6];
  uint64_t v16 = v14[8];
  uint64_t v17 = v14[10];
  BOOL v19 = v11 > 1 && v11 == v15;
  BOOL v20 = v13 == 1;
  if (v13 != 1) {
    BOOL v19 = 0;
  }
  if (v17 != 1) {
    BOOL v19 = 0;
  }
  if (v12 != 1) {
    BOOL v19 = 0;
  }
  if (v16 != 1) {
    BOOL v19 = 0;
  }
  if (v19)
  {
    BOOL v21 = 0;
    BOOL v20 = 0;
    *a4 = 0;
  }
  else
  {
    BOOL v25 = v13 > 1 && v13 == v17 && v12 == 1 && v16 == 1;
    BOOL v26 = v11 == 1 && v15 == 1;
    BOOL v21 = v26 && v25;
    if (!v26) {
      BOOL v20 = 0;
    }
  }
  BOOL v27 = v17 == 1 && v20;
  BOOL v28 = v12 == v16 && v27;
  if (v12 <= 1) {
    BOOL v28 = 0;
  }
  if (v21 || v28)
  {
    if (v28) {
      int v29 = 3;
    }
    else {
      int v29 = 1;
    }
    *a4 = v29;
  }
  if (!v21 && !v19 && !v28) {
    goto LABEL_91;
  }
  int v30 = *a4;
  uint64_t v31 = *a2;
  v116.__r_.__value_.__s.__data_[8] = 0;
  char v117 = 0;
  char v118 = 0;
  char v119 = 0;
  char v120 = 0;
  char v121 = 0;
  char v122 = 0;
  char v123 = 0;
  char v124 = 0;
  char v125 = 0;
  char v126 = 0;
  char v127 = 0;
  char v128 = 0;
  char v129 = 0;
  char v130 = 0;
  char v131 = 0;
  char v132 = 0;
  char v133 = 0;
  char v134 = 0;
  char v135 = 0;
  char v136 = 0;
  char v137 = 0;
  LOBYTE(v138) = 0;
  char v139 = 0;
  LOBYTE(v140) = 0;
  char v141 = 0;
  v116.__r_.__value_.__r.__words[0] = (std::string::size_type)&unk_26C34D080;
  __int16 v142 = 0;
  char v146 = 0;
  char v147 = 0;
  __int16 v148 = 256;
  long long v143 = 0u;
  uint64_t v144 = 0;
  __int16 v145 = 0;
  char v149 = 0;
  char v150 = 0;
  __int16 v151 = 0;
  char v152 = 0;
  char v153 = 0;
  char v154 = 0;
  char v155 = 0;
  char v156 = 0;
  char v157 = 0;
  char v158 = 0;
  char v159 = 0;
  char v160 = 0;
  char v161 = 0;
  char v162 = 0;
  char v163 = 0;
  char v164 = 0;
  char v165 = 0;
  __int16 v166 = 0;
  char v167 = 0;
  char v168 = 0;
  int v169 = 0;
  long long v32 = (ZinNEConvLayer *)*((void *)a1 + 54);
  if (!v32) {
    long long v32 = a1;
  }
  if (*((void *)v32 + 17) && *(void *)(ZinNEConvLayer::GetKernelDescriptor(a1) + 224) >= 2uLL)
  {
    uint64_t KernelDescriptor = ZinNEConvLayer::GetKernelDescriptor(a1);
    uint64_t v34 = &v138;
    uint64_t v140 = *(void *)(KernelDescriptor + 224);
    char v141 = 1;
    if (v139) {
      goto LABEL_69;
    }
    unint64_t v35 = &v139;
    goto LABEL_68;
  }
  uint64_t InputTensor = ZinIrOpLayer::GetInputTensor(a1, 0);
  uint64_t v34 = &v140;
  uint64_t v38 = *(void *)(InputTensor + 48);
  if (!v139) {
    char v139 = 1;
  }
  uint64_t v138 = v38;
  if (!v141)
  {
    unint64_t v35 = &v141;
LABEL_68:
    char *v35 = 1;
  }
LABEL_69:
  *uint64_t v34 = 1;
  ZinIrHalParameters::GetOperationCondition(*(ZinIrHalParameters **)v31, *(double *)(*(void *)(v31 + 8) + 104), *(_DWORD *)(*(void *)(v31 + 8) + 112), *(_DWORD *)(*(void *)(v31 + 8) + 116), (uint64_t)&v66);
  uint64_t v39 = *(ZinIrHalParameters **)v31;
  LOWORD(v88[0]) = 257;
  BYTE2(v88[0]) = 1;
  *(_DWORD *)((char *)v88 + 3) = 0;
  *(_DWORD *)((char *)v88 + 6) = 0;
  BYTE2(v88[1]) = 1;
  *(_DWORD *)((char *)&v88[1] + 3) = 0;
  ZinIrPerf::ZinIrPerf((uint64_t)__src, (uint64_t)v39, (long long *)&v66, (uint64_t *)v88);
  uint64_t v100 = 0;
  long long v99 = 0u;
  long long v98 = 0u;
  long long v97 = 0u;
  long long v96 = 0u;
  long long v95 = 0u;
  long long v94 = 0u;
  long long v93 = 0u;
  long long v92 = 0u;
  long long v91 = 0u;
  long long v90 = 0u;
  long long v89 = 0u;
  *(_OWORD *)uint64_t v88 = 0u;
  uint64_t v40 = operator new(8uLL);
  long long __p = v40;
  void *v40 = 0;
  BOOL v103 = v40 + 1;
  int v102 = v40 + 1;
  long long v104 = 0uLL;
  __asm { FMOV            V0.2D, #-1.0 }
  long long v105 = _Q0;
  long long v106 = _Q0;
  long long v107 = _Q0;
  long long v108 = _Q0;
  uint64_t v109 = 0;
  char v110 = 0;
  uint64_t v111 = 0;
  int v45 = ZinANELayer::CalculatePerf(a1, (ZinIrPerf *)__src, (const ZinCustomPerfInfo *)&v116, (ZinPerfDescriptor *)v88);
  if (v45)
  {
    if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
      IsInefficientFullyConnectedLayer();
    }
    if (__p)
    {
      int v102 = __p;
      operator delete(__p);
    }
    int v46 = 3;
  }
  else
  {
    int v46 = 0;
  }
  ZinIrPerf::~ZinIrPerf((ZinIrPerf *)__src);
  v116.__r_.__value_.__r.__words[0] = (std::string::size_type)&unk_26C34D080;
  if ((void)v143)
  {
    *((void *)&v143 + 1) = v143;
    operator delete((void *)v143);
  }
  ZinIrHalH13g::~ZinIrHalH13g((ZinIrHalH13g *)&v116);
  if (!v45)
  {
    uint64_t v47 = (*(uint64_t (**)(void, void, void))(***((void ***)a1 + 11) + 32))(**((void **)a1 + 11), 0, 0);
    int64x2_t v48 = *(int64x2_t *)(v47 + 64);
    int64x2_t v85 = *(int64x2_t *)(v47 + 48);
    int64x2_t v86 = v48;
    uint64_t v87 = *(void *)(v47 + 80);
    (*(uint64_t (**)(ZinNEConvLayer *, void, void))(*(void *)a1 + 32))(a1, 0, 0);
    (*(uint64_t (**)(ZinNEConvLayer *, void, void))(*(void *)a1 + 32))(a1, 0, 0);
    CreatePreTransposeMap(v30, &v83);
    int64x2_t v80 = v85;
    int64x2_t v81 = v86;
    uint64_t v82 = v87;
    uint64_t v49 = 1;
    int64x2_t v77 = vdupq_n_s64(1uLL);
    int64x2_t v78 = v77;
    uint64_t v79 = 1;
    memset(v76, 0, sizeof(v76));
    uint64_t v50 = 1;
    uint64_t v51 = v83;
    uint64_t v52 = v84;
    uint64_t v53 = 1;
    uint64_t v54 = 1;
    uint64_t v55 = 1;
    if (v83 != v84)
    {
      uint64_t v55 = 1;
      uint64_t v54 = 1;
      uint64_t v53 = 1;
      uint64_t v50 = 1;
      uint64_t v49 = 1;
      do
      {
        __src[1] = 0;
        __src[0] = 0;
        uint64_t v113 = 0;
        std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(__src, *(const void **)v51, *(void *)(v51 + 8), (uint64_t)(*(void *)(v51 + 8) - *(void *)v51) >> 3);
        ZinIrTransposeUnitInfo::TransposeDimensions<ZinTensorDimensions>(&v80, (uint64_t)__src, &v77);
        if (ZinIrTransposeUnit::IsCWTranspose((int **)__src))
        {
          std::vector<DimensionMapping>::__assign_with_size[abi:ne180100]<DimensionMapping const*,DimensionMapping const*>((char *)v76, (char *)__src[0], (uint64_t)__src[1], ((char *)__src[1] - (char *)__src[0]) >> 3);
          uint64_t v50 = v80.i64[1];
          uint64_t v49 = v80.i64[0];
          uint64_t v54 = v81.i64[1];
          uint64_t v53 = v81.i64[0];
          uint64_t v55 = v82;
        }
        int64x2_t v80 = v77;
        int64x2_t v81 = v78;
        uint64_t v82 = v79;
        if (__src[0])
        {
          __src[1] = __src[0];
          operator delete(__src[0]);
        }
        v51 += 24;
      }
      while (v51 != v52);
    }
    int64x2_t v73 = v77;
    int64x2_t v74 = v78;
    uint64_t v75 = v79;
    uint64_t v68 = v49;
    uint64_t v69 = v50;
    uint64_t v70 = v53;
    uint64_t v71 = v54;
    uint64_t v72 = v55;
    (*(void (**)(std::string *__return_ptr))(*(void *)a3 + 16))(&v116);
    uint64_t v67 = 0;
    v88[1] = 0;
    v88[0] = 0;
    LODWORD(__src[0]) = 0;
    uint64_t v114 = 0;
    __src[1] = 0;
    uint64_t v113 = 0;
    int v115 = 0;
    ZinIrTensor::CreateTensor();
  }
  if (!v46)
  {
LABEL_91:
    uint64_t result = 0;
    *a5 = 0;
    return result;
  }
  BOOL v56 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
  if (v56) {
    IsInefficientFullyConnectedLayer(v56, v57, v58, v59, v60, v61, v62, v63);
  }
  return 3;
}

void sub_21129CE2C(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, void *a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,void *a33,uint64_t a34,uint64_t a35,uint64_t a36,uint64_t a37,uint64_t a38,uint64_t a39,uint64_t a40,uint64_t a41,uint64_t a42,uint64_t a43,uint64_t a44,uint64_t a45,uint64_t a46,uint64_t a47,uint64_t a48,uint64_t a49,uint64_t a50,uint64_t a51,uint64_t a52,uint64_t a53,uint64_t a54,uint64_t a55,uint64_t a56,uint64_t a57,void *__p,void *a59)
{
  if (__p)
  {
    a59 = __p;
    operator delete(__p);
  }
  if (STACK[0x288]) {
    std::__shared_weak_count::__release_shared[abi:ne180100]((std::__shared_weak_count *)STACK[0x288]);
  }
  a33 = &STACK[0x2B8];
  std::vector<std::vector<ZinIrOpLayer *>>::__destroy_vector::operator()[abi:ne180100]((void ***)&a33);
  uint64_t v60 = (void *)STACK[0x398];
  if (STACK[0x398])
  {
    STACK[0x3A0] = (unint64_t)v60;
    operator delete(v60);
  }
  if (STACK[0x438]) {
    std::__shared_weak_count::__release_shared[abi:ne180100]((std::__shared_weak_count *)STACK[0x438]);
  }
  ZinNECustomPerfInfo::~ZinNECustomPerfInfo((ZinNECustomPerfInfo *)&STACK[0xA88]);
  uint64_t v61 = (void *)STACK[0x698];
  if (STACK[0x698])
  {
    STACK[0x6A0] = (unint64_t)v61;
    operator delete(v61);
  }
  ZinIrPerf::~ZinIrPerf((ZinIrPerf *)&STACK[0x720]);
  if (STACK[0x4C0]) {
    std::__shared_weak_count::__release_shared[abi:ne180100]((std::__shared_weak_count *)STACK[0x4C0]);
  }
  uint64_t v62 = (void *)STACK[0x518];
  if (STACK[0x518])
  {
    STACK[0x520] = (unint64_t)v62;
    operator delete(v62);
  }
  STACK[0x720] = (unint64_t)&STACK[0x588];
  std::vector<std::vector<ZinIrOpLayer *>>::__destroy_vector::operator()[abi:ne180100]((void ***)&STACK[0x720]);
  if (a13) {
    operator delete(a13);
  }
  _Unwind_Resume(a1);
}

void CreatePreTransposeMap(int a1@<W0>, void *a2@<X8>)
{
  uint64_t v12 = *MEMORY[0x263EF8340];
  unint64_t v4 = (char *)operator new(0x10uLL);
  *(_DWORD *)unint64_t v4 = a1;
  *(void *)(v4 + 4) = 0x300000003;
  *((_DWORD *)v4 + 3) = a1;
  v11[0] = v4;
  v11[1] = v4 + 16;
  v11[2] = v4 + 16;
  uint64_t v5 = operator new(0x10uLL);
  v11[3] = v5;
  *uint64_t v5 = xmmword_211ED3980;
  v11[4] = v5 + 1;
  v11[5] = v5 + 1;
  CFDictionaryRef v6 = operator new(0x10uLL);
  v11[6] = v6;
  _OWORD *v6 = xmmword_211EDF930;
  v11[7] = v6 + 1;
  v11[8] = v6 + 1;
  size_t v7 = operator new(0x10uLL);
  v11[9] = v7;
  _OWORD *v7 = xmmword_211ED3980;
  v11[10] = v7 + 1;
  v11[11] = v7 + 1;
  a2[1] = 0;
  a2[2] = 0;
  *a2 = 0;
  uint64_t v8 = operator new(0x60uLL);
  *a2 = v8;
  a2[1] = v8;
  a2[2] = v8 + 12;
  uint64_t v9 = 0;
  a2[1] = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::vector<DimensionMapping>>,std::vector<DimensionMapping> const*,std::vector<DimensionMapping> const*,std::vector<DimensionMapping>*>((uint64_t)(a2 + 2), (uint64_t)v11, (uint64_t)&v12, v8);
  do
  {
    CFTypeID v10 = (void *)v11[v9 + 9];
    if (v10)
    {
      v11[v9 + 10] = v10;
      operator delete(v10);
    }
    v9 -= 3;
  }
  while (v9 != -12);
}

void sub_21129D444(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, void **a12, uint64_t a13, char a14)
{
  uint64_t v16 = v15;
  *(void *)(v14 + 8) = v16;
  std::vector<std::vector<ZinIrOpLayer *>>::__destroy_vector::operator()[abi:ne180100](&a12);
  uint64_t v18 = 0;
  while (1)
  {
    BOOL v19 = *(void **)(&a14 + v18 + 72);
    if (v19)
    {
      *(void *)(&a14 + v18 + 80) = v19;
      operator delete(v19);
    }
    v18 -= 24;
    if (v18 == -96) {
      _Unwind_Resume(a1);
    }
  }
}

void CreatePostTransposeMap(int a1@<W0>, void *a2@<X8>)
{
  uint64_t v12 = *MEMORY[0x263EF8340];
  unint64_t v4 = operator new(0x10uLL);
  v11[0] = v4;
  *unint64_t v4 = xmmword_211ED3980;
  v11[1] = v4 + 1;
  v11[2] = v4 + 1;
  uint64_t v5 = operator new(0x10uLL);
  v11[3] = v5;
  *uint64_t v5 = xmmword_211EDF930;
  v11[4] = v5 + 1;
  v11[5] = v5 + 1;
  CFDictionaryRef v6 = operator new(0x10uLL);
  v11[6] = v6;
  _OWORD *v6 = xmmword_211ED3980;
  v11[7] = v6 + 1;
  v11[8] = v6 + 1;
  size_t v7 = (char *)operator new(0x10uLL);
  v11[10] = v7 + 16;
  v11[11] = v7 + 16;
  *(_DWORD *)size_t v7 = a1;
  *(void *)(v7 + 4) = 0x300000003;
  *((_DWORD *)v7 + 3) = a1;
  v11[9] = v7;
  a2[1] = 0;
  a2[2] = 0;
  *a2 = 0;
  uint64_t v8 = operator new(0x60uLL);
  *a2 = v8;
  a2[1] = v8;
  a2[2] = v8 + 12;
  uint64_t v9 = 0;
  a2[1] = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::vector<DimensionMapping>>,std::vector<DimensionMapping> const*,std::vector<DimensionMapping> const*,std::vector<DimensionMapping>*>((uint64_t)(a2 + 2), (uint64_t)v11, (uint64_t)&v12, v8);
  do
  {
    CFTypeID v10 = (void *)v11[v9 + 9];
    if (v10)
    {
      v11[v9 + 10] = v10;
      operator delete(v10);
    }
    v9 -= 3;
  }
  while (v9 != -12);
}

void sub_21129D630(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, void **a12, uint64_t a13, char a14)
{
  uint64_t v16 = v15;
  *(void *)(v14 + 8) = v16;
  std::vector<std::vector<ZinIrOpLayer *>>::__destroy_vector::operator()[abi:ne180100](&a12);
  uint64_t v18 = 0;
  while (1)
  {
    BOOL v19 = *(void **)(&a14 + v18 + 72);
    if (v19)
    {
      *(void *)(&a14 + v18 + 80) = v19;
      operator delete(v19);
    }
    v18 -= 24;
    if (v18 == -96) {
      _Unwind_Resume(a1);
    }
  }
}

uint64_t InsertTransposes(void *a1, ZinIrOpLayerGraph *a2, uint64_t **a3, int a4)
{
  uint64_t v27 = *MEMORY[0x263EF8340];
  size_t v7 = a3;
  if (a4) {
    size_t v7 = (uint64_t **)*a3[11];
  }
  BOOL v21 = (ZinIrOpLayerGraph *)v7;
  ((void (*)(uint64_t **, void, void))(*v7)[4])(v7, 0, 0);
  uint64_t v23 = 0;
  uint64_t v24 = 0;
  uint64_t v25 = 0;
  if (*a1 != a1[1])
  {
    (*(void (**)(ZinIrOpLayerGraph *, void, void))(*(void *)v21 + 32))(v21, 0, 0);
    ZinBuilder::CreateTranspose();
  }
  if (*(void *)((*(uint64_t (**)(ZinIrOpLayerGraph *, void, void))(*(void *)v21 + 32))(v21, 0, 0)+ 104))operator new(); {
  uint64_t v8 = (ZinIrOpLayer *)*(v24 - 1);
  }
  if (a4)
  {
    ZinIrOpLayerGraph::SwapEdgeSource((uint64_t)a2, v21, v8, (uint64_t)a3, 0xFFFFFFFFFFFFFFFFLL, 0xFFFFFFFFFFFFFFFFLL, 0xFFFFFFFFFFFFFFFFLL, 0xFFFFFFFFFFFFFFFFLL, 0, 0);
LABEL_10:
    uint64_t v10 = 0;
    goto LABEL_14;
  }
  *(void *)&long long v26 = *(void *)v23;
  std::unordered_set<ZinIrOpLayer *>::unordered_set((uint64_t)v22, &v26, 1);
  char v9 = ZinIrOpLayerGraph::MoveOutgoingEdges(a2, a3, v8, v22);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v22);
  if (v9) {
    goto LABEL_10;
  }
  BOOL v11 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
  if (v11) {
    std::__function::__func<ZinMirLayerFusion::Commit(void)::$_0,std::allocator<ZinMirLayerFusion::Commit(void)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::operator()(v11, v12, v13, v14, v15, v16, v17, v18);
  }
  uint64_t v10 = 3;
LABEL_14:
  if (v23)
  {
    uint64_t v24 = v23;
    operator delete(v23);
  }
  return v10;
}

void sub_21129DAEC(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, char a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,void *__p,uint64_t a22,uint64_t a23,void *a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28)
{
}

void std::__function::__func<ZinMirOptFullyConnectedLayer(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0,std::allocator<ZinMirOptFullyConnectedLayer(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::operator()(char *a1, void *a2)
{
  uint64_t v4 = *MEMORY[0x263EF8340];
  if (*a1 < 0) {
    a2 = (void *)*a2;
  }
  int v2 = 136315138;
  uint64_t v3 = a2;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "Error: ZinMirOptFullyConnectedLayer fails in %s.", (uint8_t *)&v2, 0xCu);
}

void std::__function::__func<ZinMirOptFullyConnectedLayer(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0,std::allocator<ZinMirOptFullyConnectedLayer(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::operator()(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "IsInefficientFullyConnectedLayer run failed.\n", a5, a6, a7, a8, 0);
}

void IsInefficientFullyConnectedLayer(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void IsInefficientFullyConnectedLayer()
{
  OUTLINED_FUNCTION_1_7();
  OUTLINED_FUNCTION_4_1(&dword_210C72000, &_os_log_internal, v0, "ERROR: Performance model call isn't successful, line: %d, file: %s", v1, v2, v3, v4, 2u);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;

  OUTLINED_FUNCTION_1_7();
  OUTLINED_FUNCTION_4_1(&dword_210C72000, &_os_log_internal, v0, "ERROR: Performance model call isn't successful, line: %d, file: %s", v1, v2, v3, v4, 2u);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;

  OUTLINED_FUNCTION_1_7();
  OUTLINED_FUNCTION_4_1(&dword_210C72000, &_os_log_internal, v0, "ERROR: Performance model call isn't successful, line: %d, file: %s", v1, v2, v3, v4, 2u);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;

  OUTLINED_FUNCTION_1_7();
  OUTLINED_FUNCTION_4_1(&dword_210C72000, &_os_log_internal, v0, "Perf model call isn't successful, line: %d, file: %s", v1, v2, v3, v4, 2u);
}

void ZinPerfUtil::GetTaskExecutionTimeEstimate(ZinIrOpLayer ***a1@<X0>, uint64_t a2@<X1>, _DWORD *a3@<X2>, void *a4@<X8>)
{
  uint64_t v99 = *MEMORY[0x263EF8340];
  long long v74 = 0uLL;
  unint64_t v75 = 0;
  uint64_t v5 = *(ZinIrHalParameters **)a2;
  ZinIrHalParameters::GetOperationCondition(*(ZinIrHalParameters **)a2, *(double *)(*(void *)(a2 + 8) + 104), *(_DWORD *)(*(void *)(a2 + 8) + 112), *(_DWORD *)(*(void *)(a2 + 8) + 116), (uint64_t)v73);
  *(_DWORD *)long long buf = 16843009;
  *(void *)&void buf[4] = 0x101010001010000;
  *(_WORD *)&unsigned char buf[12] = 0;
  buf[14] = 0;
  ZinIrPerf::ZinIrPerf((uint64_t)v72, (uint64_t)v5, v73, (uint64_t *)buf);
  size_t v7 = *a1;
  CFDictionaryRef v6 = a1[1];
  if (*a1 != v6)
  {
    __asm { FMOV            V0.2D, #-1.0 }
    long long v47 = _Q0;
    do
    {
      uint64_t v13 = *v7;
      memset(buf, 0, sizeof(buf));
      if (ZinIrOpLayer::IsNoOp(v13, (uint64_t *)buf))
      {
        if (*(void *)buf)
        {
          *(void *)&uint8_t buf[8] = *(void *)buf;
          operator delete(*(void **)buf);
        }
        goto LABEL_43;
      }
      BOOL IsANELayer = ZinIrOpLayer::IsANELayer(*v7);
      if (*(void *)buf)
      {
        *(void *)&uint8_t buf[8] = *(void *)buf;
        operator delete(*(void **)buf);
      }
      if (!IsANELayer) {
        goto LABEL_43;
      }
      uint64_t v61 = 0;
      long long v59 = 0u;
      long long v60 = 0u;
      long long v57 = 0u;
      long long v58 = 0u;
      long long v55 = 0u;
      long long v56 = 0u;
      long long v53 = 0u;
      long long v54 = 0u;
      long long v51 = 0u;
      long long v52 = 0u;
      long long v49 = 0u;
      long long v50 = 0u;
      uint64_t v15 = operator new(8uLL);
      uint64_t v62 = v15;
      *uint64_t v15 = 0;
      uint64_t v63 = v15 + 1;
      char v64 = v15 + 1;
      long long v65 = 0uLL;
      long long v66 = v47;
      long long v67 = v47;
      long long v68 = v47;
      long long v69 = v47;
      *(void *)&long long v70 = 0;
      BYTE8(v70) = 0;
      uint64_t v71 = 0;
      uint64_t v16 = *v7;
      int v17 = ZinANELayer::CalculatePerf(*v7, (ZinIrPerf *)v72, (ZinPerfDescriptor *)&v49);
      if (v17)
      {
        if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR))
        {
          *(_DWORD *)long long buf = 67109378;
          *(_DWORD *)&void buf[4] = 124;
          *(_WORD *)&uint8_t buf[8] = 2080;
          *(void *)&buf[10] = "/Library/Caches/com.apple.xbs/Sources/ANECompiler/libs/inference/compiler/ZinPerfModel/s"
                                "rc/ZinIrANEPerfModel.cpp";
          _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "Perf model isn't successful, line: %d, file: %s", buf, 0x12u);
        }
        *a3 = 3;
        a4[1] = 0;
        a4[2] = 0;
        *a4 = 0;
        goto LABEL_40;
      }
      int v48 = 0;
      uint64_t v18 = (_DWORD *)*((void *)v16 + 33);
      if (v18)
      {
        int HasChainRead = ZinEngineLayerMirInfo::HasChainRead(v18, &v48);
        uint64_t v20 = *((void *)&v74 + 1);
        if ((void)v74 == *((void *)&v74 + 1)) {
          goto LABEL_24;
        }
        if (HasChainRead) {
          goto LABEL_25;
        }
      }
      else
      {
        uint64_t v20 = *((void *)&v74 + 1);
        if ((void)v74 == *((void *)&v74 + 1))
        {
LABEL_24:
          double v25 = 0.0;
          goto LABEL_28;
        }
      }
      if (!(void)v58)
      {
        uint64_t v24 = (double *)(v20 - 344);
        goto LABEL_27;
      }
      uint64_t v21 = *(void *)(v20 - 184);
      unsigned __int8 v22 = ZinANELayer::IsChainedConsumer(*(ZinANELayer **)(v20 - 336));
      if (v21) {
        char v23 = 1;
      }
      else {
        char v23 = v22;
      }
      uint64_t v20 = *((void *)&v74 + 1);
      if ((v23 & 1) == 0)
      {
LABEL_25:
        uint64_t v24 = (double *)(v20 - 352);
        goto LABEL_27;
      }
      uint64_t v24 = (double *)(*((void *)&v74 + 1) - 696);
LABEL_27:
      double v25 = *v24;
LABEL_28:
      if (*((void *)v16 + 45)
        && ((uint64_t v26 = *((void *)v16 + 33), *(unsigned char *)(v26 + 344))
         || (uint64_t v27 = (ZinMirL2Config *)(v26 + 120), *(_DWORD *)ZinMirL2Config::GetL2SrcDep(v26 + 120, 0))
         || *(_DWORD *)ZinMirL2Config::GetL2SrcDep((uint64_t)v27, 1)
         || ZinMirL2Config::HasAlias(v27)))
      {
        double v28 = v25 + *((double *)&v51 + 1);
        if (*(double *)(*((void *)&v74 + 1) - 344) >= v25 + *((double *)&v51 + 1)) {
          double v28 = *(double *)(*((void *)&v74 + 1) - 344);
        }
      }
      else
      {
        double v28 = v25 + *((double *)&v51 + 1);
      }
      *(double *)long long buf = v25;
      *(double *)&uint8_t buf[8] = v28;
      *(void *)&uint8_t buf[16] = v16;
      long long v87 = v59;
      long long v88 = v60;
      uint64_t v89 = v61;
      long long v83 = v55;
      long long v84 = v56;
      long long v85 = v57;
      long long v86 = v58;
      long long v79 = v51;
      long long v80 = v52;
      long long v81 = v53;
      long long v82 = v54;
      long long v77 = v49;
      long long v78 = v50;
      long long v90 = 0uLL;
      uint64_t v91 = 0;
      std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(&v90, v62, (uint64_t)v63, (v63 - (unsigned char *)v62) >> 3);
      long long v96 = v69;
      long long v97 = v70;
      uint64_t v98 = v71;
      long long v92 = v65;
      long long v93 = v66;
      long long v94 = v67;
      long long v95 = v68;
      uint64_t v29 = *((void *)&v74 + 1);
      if (*((void *)&v74 + 1) >= v75)
      {
        *((void *)&v74 + 1) = std::vector<ZinPerfUtil::TaskStats>::__push_back_slow_path<ZinPerfUtil::TaskStats>((uint64_t *)&v74, (long long *)buf);
        if ((void)v90)
        {
          *((void *)&v90 + 1) = v90;
          operator delete((void *)v90);
        }
      }
      else
      {
        long long v30 = *(_OWORD *)buf;
        *(void *)(*((void *)&v74 + 1) + 16) = *(void *)&buf[16];
        *(_OWORD *)uint64_t v29 = v30;
        long long v31 = v80;
        long long v32 = v81;
        long long v33 = v79;
        *(_OWORD *)(v29 + 40) = v78;
        *(_OWORD *)(v29 + 88) = v32;
        *(_OWORD *)(v29 + 72) = v31;
        *(_OWORD *)(v29 + 56) = v33;
        long long v34 = v84;
        long long v35 = v85;
        long long v36 = v83;
        *(_OWORD *)(v29 + 104) = v82;
        *(_OWORD *)(v29 + 152) = v35;
        *(_OWORD *)(v29 + 136) = v34;
        *(_OWORD *)(v29 + 120) = v36;
        long long v38 = v87;
        long long v37 = v88;
        uint64_t v39 = v89;
        *(_OWORD *)(v29 + 168) = v86;
        *(_OWORD *)(v29 + 200) = v37;
        *(_OWORD *)(v29 + 184) = v38;
        *(void *)(v29 + 216) = v39;
        *(void *)(v29 + 224) = 0;
        *(_OWORD *)(v29 + 24) = v77;
        *(void *)(v29 + 2std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = 0;
        *(void *)(v29 + 240) = 0;
        *(_OWORD *)(v29 + 224) = v90;
        *(void *)(v29 + 240) = v91;
        long long v90 = 0uLL;
        uint64_t v91 = 0;
        long long v41 = v93;
        long long v40 = v94;
        *(_OWORD *)(v29 + 248) = v92;
        *(_OWORD *)(v29 + 264) = v41;
        *(_OWORD *)(v29 + 280) = v40;
        long long v43 = v96;
        long long v42 = v97;
        long long v44 = v95;
        *(void *)(v29 + 344) = v98;
        *(_OWORD *)(v29 + 312) = v43;
        *(_OWORD *)(v29 + 328) = v42;
        *(_OWORD *)(v29 + 296) = v44;
        *((void *)&v74 + 1) = v29 + 352;
      }
LABEL_40:
      if (v62)
      {
        uint64_t v63 = v62;
        operator delete(v62);
      }
      if (v17) {
        goto LABEL_45;
      }
LABEL_43:
      ++v7;
    }
    while (v7 != v6);
  }
  *a3 = 0;
  *(_OWORD *)a4 = v74;
  a4[2] = v75;
  long long v74 = 0uLL;
  unint64_t v75 = 0;
LABEL_45:
  ZinIrPerf::~ZinIrPerf((ZinIrPerf *)v72);
  v72[0] = (void **)&v74;
  std::vector<ZinPerfUtil::TaskStats>::__destroy_vector::operator()[abi:ne180100](v72);
}

void sub_21129E444(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33,uint64_t a34,uint64_t a35,uint64_t a36,uint64_t a37,uint64_t a38,uint64_t a39,uint64_t a40,uint64_t a41,uint64_t a42,uint64_t a43,uint64_t a44,uint64_t a45,uint64_t a46,uint64_t a47,uint64_t a48,uint64_t a49,uint64_t a50,uint64_t a51,uint64_t a52,uint64_t a53,uint64_t a54,uint64_t a55,uint64_t a56,uint64_t a57,uint64_t a58,uint64_t a59,uint64_t a60,void **a61)
{
  uint64_t v63 = (void *)v61[25];
  if (v63)
  {
    v61[26] = v63;
    operator delete(v63);
  }
  ZinIrPerf::~ZinIrPerf((ZinIrPerf *)&a61);
  v61[42] = &STACK[0x530];
  std::vector<ZinPerfUtil::TaskStats>::__destroy_vector::operator()[abi:ne180100](&a61);
  _Unwind_Resume(a1);
}

uint64_t ZinPerfUtil::GetThreadPerformanceStats(ZinIrOpLayer ***a1, ZinIrHalParameters *this, unsigned int a3, unsigned int a4, uint64_t a5, double a6)
{
  uint64_t v74 = *MEMORY[0x263EF8340];
  ZinIrHalParameters::GetOperationCondition(this, a6, a3, a4, (uint64_t)v68);
  __p[0] = (void *)0x101000001010101;
  LOWORD(__p[1]) = 256;
  BYTE2(__p[1]) = 1;
  *(_DWORD *)((char *)&__p[1] + 3) = 0;
  ZinIrPerf::ZinIrPerf((uint64_t)v67, (uint64_t)this, v68, (uint64_t *)__p);
  long long v9 = v68[1];
  *(_OWORD *)a5 = v68[0];
  *(_OWORD *)(a5 + 16) = v9;
  *(void *)(a5 + std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = v69;
  uint64_t v10 = *a1;
  BOOL v11 = a1[1];
  if (*a1 != v11)
  {
    unint64_t v12 = 0;
    double v13 = 0.0;
    __asm { FMOV            V0.2D, #-1.0 }
    long long v41 = _Q0;
    BOOL v19 = &_os_log_internal;
    double v20 = 0.0;
    double v21 = 0.0;
    double v22 = 0.0;
    double v23 = 0.0;
    double v24 = 0.0;
    while (1)
    {
      double v25 = *v10;
      __p[0] = 0;
      __p[1] = 0;
      *(void *)&long long v43 = 0;
      if (ZinIrOpLayer::IsNoOp(v25, (uint64_t *)__p))
      {
        if (__p[0])
        {
          __p[1] = __p[0];
          operator delete(__p[0]);
        }
      }
      else
      {
        BOOL IsANELayer = ZinIrOpLayer::IsANELayer(*v10);
        if (__p[0])
        {
          __p[1] = __p[0];
          operator delete(__p[0]);
        }
        if (IsANELayer)
        {
          uint64_t v54 = 0;
          long long v52 = 0u;
          long long v53 = 0u;
          long long v50 = 0u;
          long long v51 = 0u;
          long long v48 = 0u;
          long long v49 = 0u;
          long long v46 = 0u;
          long long v47 = 0u;
          long long v44 = 0u;
          long long v45 = 0u;
          *(_OWORD *)long long __p = 0u;
          long long v43 = 0u;
          uint64_t v27 = operator new(8uLL);
          long long v55 = v27;
          *uint64_t v27 = 0;
          long long v56 = v27 + 1;
          long long v57 = v27 + 1;
          uint64_t v58 = 0;
          uint64_t v59 = 0;
          long long v60 = v41;
          long long v61 = v41;
          long long v62 = v41;
          long long v63 = v41;
          uint64_t v64 = 0;
          char v65 = 0;
          uint64_t v66 = 0;
          int v28 = ZinANELayer::CalculatePerf(*v10, (ZinIrPerf *)v67, (ZinPerfDescriptor *)__p);
          if (v28)
          {
            if (os_log_type_enabled(v19, OS_LOG_TYPE_ERROR))
            {
              *(_DWORD *)long long buf = 67109378;
              int v71 = 196;
              __int16 v72 = 2080;
              int64x2_t v73 = "/Library/Caches/com.apple.xbs/Sources/ANECompiler/libs/inference/compiler/ZinPerfModel/src/ZinIrANEPerfModel.cpp";
              _os_log_error_impl(&dword_210C72000, v19, OS_LOG_TYPE_ERROR, "Perf model isn't successful, line: %d, file: %s", buf, 0x12u);
            }
          }
          else
          {
            double v23 = v23 + *(double *)&v43;
            double v24 = v24 + *((double *)&v43 + 1);
            double v13 = v13 + *(double *)&v44;
            double v20 = v20 + *((double *)&v44 + 1);
            v12 += *((void *)&v48 + 1) + v49 + v50;
            double v29 = v13 * 0.899999976;
            if (v23 >= v24) {
              double v30 = v23;
            }
            else {
              double v30 = v24;
            }
            double v31 = v29 - v30;
            double v32 = v30 - v29;
            BOOL v33 = v29 <= v30;
            double v34 = -0.0;
            if (v33) {
              double v35 = v32;
            }
            else {
              double v35 = -0.0;
            }
            double v22 = v22 + v35;
            if (!v33) {
              double v34 = v31;
            }
            double v21 = v21 + v34;
          }
          if (v55)
          {
            long long v56 = v55;
            operator delete(v55);
          }
          if (v28)
          {
            uint64_t v36 = 3;
            goto LABEL_28;
          }
        }
      }
      if (++v10 == v11) {
        goto LABEL_27;
      }
    }
  }
  unint64_t v12 = 0;
  double v24 = 0.0;
  double v23 = 0.0;
  double v22 = 0.0;
  double v21 = 0.0;
  double v20 = 0.0;
  double v13 = 0.0;
LABEL_27:
  uint64_t v36 = 0;
  *(void *)(a5 + 40) = (unint64_t)(v23 * 1000.0);
  *(void *)(a5 + 48) = (unint64_t)(v24 * 1000.0);
  *(void *)(a5 + 56) = (unint64_t)(v13 * 1000.0);
  *(void *)(a5 + 64) = (unint64_t)(v20 * 1000.0);
  *(void *)(a5 + 72) = (unint64_t)(v21 * 1000.0);
  *(void *)(a5 + 80) = (unint64_t)(v22 * 1000.0);
  *(_DWORD *)(a5 + 100) = 1063675494;
  float v37 = v21 / v20;
  float v38 = v22 / v20;
  *(float *)(a5 + 104) = v37;
  *(float *)(a5 + 108) = v38;
  *(void *)(a5 + 88) = v12;
  float v39 = (double)v12 / (v20 * 1000.0);
  *(float *)(a5 + 96) = v39;
LABEL_28:
  ZinIrPerf::~ZinIrPerf((ZinIrPerf *)v67);
  return v36;
}

void sub_21129E85C(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33,uint64_t a34,uint64_t a35,uint64_t a36,uint64_t a37,void *__p,uint64_t a39,uint64_t a40,uint64_t a41,uint64_t a42,uint64_t a43,uint64_t a44,uint64_t a45,uint64_t a46,uint64_t a47,uint64_t a48,uint64_t a49,uint64_t a50,uint64_t a51,uint64_t a52,uint64_t a53,uint64_t a54,char a55)
{
}

uint64_t ZinPerfUtil::ZinDebugPrintPerfEstimateParams(uint64_t a1, uint64_t a2)
{
  v45[19] = *MEMORY[0x263EF8340];
  uint64_t v4 = *(void *)(a2 + 8);
  if (*(char *)(v4 + 95) < 0)
  {
    std::string::__init_copy_ctor_external(&v40, *(const std::string::value_type **)(v4 + 72), *(void *)(v4 + 80));
    uint64_t v4 = *(void *)(a2 + 8);
  }
  else
  {
    std::string v40 = *(std::string *)(v4 + 72);
  }
  if (*(char *)(v4 + 47) < 0) {
    std::string::__init_copy_ctor_external(&v39, *(const std::string::value_type **)(v4 + 24), *(void *)(v4 + 32));
  }
  else {
    std::string v39 = *(std::string *)(v4 + 24);
  }
  if (!*(void *)(a1 + 344)) {
    ZinAssertImpl("Must run scheduler first");
  }
  std::map<ZinIrBasicBlock *,std::vector<ZinIrOpLayer *>,ScheduleComparator,std::allocator<std::pair<ZinIrBasicBlock * const,std::vector<ZinIrOpLayer *>>>>::map[abi:ne180100]((uint64_t *)&v37, a1 + 328);
  uint64_t v34 = 0;
  uint64_t v35 = 0;
  uint64_t v36 = 0;
  unsigned int v33 = 0;
  uint64_t v5 = v37;
  if (v37 == v38)
  {
LABEL_18:
    uint64_t v11 = MEMORY[0x263F8C310] + 64;
    v45[0] = MEMORY[0x263F8C310] + 64;
    uint64_t v12 = MEMORY[0x263F8C2B0];
    double v13 = *(void ***)(MEMORY[0x263F8C2B0] + 16);
    long long v41 = *(void ***)(MEMORY[0x263F8C2B0] + 8);
    *(void ***)((char *)&v41 + (void)*(v41 - 3)) = v13;
    uint64_t v14 = (std::ios_base *)((char *)&v41 + (void)*(v41 - 3));
    std::ios_base::init(v14, &__p);
    uint64_t v15 = (void **)(MEMORY[0x263F8C310] + 24);
    v14[1].__vftable = 0;
    v14[1].__fmtflags_ = -1;
    long long v41 = v15;
    v45[0] = v11;
    MEMORY[0x21667CDD0](&__p);
    if ((v39.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
      std::string::size_type size = HIBYTE(v39.__r_.__value_.__r.__words[2]);
    }
    else {
      std::string::size_type size = v39.__r_.__value_.__l.__size_;
    }
    int v17 = &v29;
    std::string::basic_string[abi:ne180100]((uint64_t)&v29, size + 1);
    if ((v29.__r_.__value_.__r.__words[2] & 0x8000000000000000) != 0) {
      int v17 = (std::string *)v29.__r_.__value_.__r.__words[0];
    }
    if (size)
    {
      if ((v39.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
        uint64_t v18 = &v39;
      }
      else {
        uint64_t v18 = (std::string *)v39.__r_.__value_.__r.__words[0];
      }
      memmove(v17, v18, size);
    }
    *(_WORD *)((char *)&v17->__r_.__value_.__l.__data_ + size) = 46;
    if ((v40.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
      BOOL v19 = &v40;
    }
    else {
      BOOL v19 = (std::string *)v40.__r_.__value_.__r.__words[0];
    }
    if ((v40.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
      std::string::size_type v20 = HIBYTE(v40.__r_.__value_.__r.__words[2]);
    }
    else {
      std::string::size_type v20 = v40.__r_.__value_.__l.__size_;
    }
    double v21 = std::string::append(&v29, (const std::string::value_type *)v19, v20);
    long long v22 = *(_OWORD *)&v21->__r_.__value_.__l.__data_;
    v30.__r_.__value_.__r.__words[2] = v21->__r_.__value_.__r.__words[2];
    *(_OWORD *)&v30.__r_.__value_.__l.__data_ = v22;
    v21->__r_.__value_.__l.__size_ = 0;
    v21->__r_.__value_.__r.__words[2] = 0;
    v21->__r_.__value_.__r.__words[0] = 0;
    double v23 = std::string::append(&v30, "_perf_all.csv", 0xDuLL);
    long long v24 = *(_OWORD *)&v23->__r_.__value_.__l.__data_;
    std::string::size_type v32 = v23->__r_.__value_.__r.__words[2];
    *(_OWORD *)double v31 = v24;
    v23->__r_.__value_.__l.__size_ = 0;
    v23->__r_.__value_.__r.__words[2] = 0;
    v23->__r_.__value_.__r.__words[0] = 0;
    std::ofstream::open();
    if (SHIBYTE(v32) < 0) {
      operator delete(v31[0]);
    }
    if (SHIBYTE(v30.__r_.__value_.__r.__words[2]) < 0) {
      operator delete(v30.__r_.__value_.__l.__data_);
    }
    if (SHIBYTE(v29.__r_.__value_.__r.__words[2]) < 0) {
      operator delete(v29.__r_.__value_.__l.__data_);
    }
    ZinPerfUtil::WritePerfCsvHeader(&v41);
    uint64_t v25 = v35;
    if (v34 != v35)
    {
      uint64_t v26 = v34 + 24;
      do
      {
        ZinPerfUtil::WritePerfCsvBody();
        uint64_t v27 = v26 + 328;
        v26 += 352;
      }
      while (v27 != v25);
    }
    ZinPerfUtil::WritePerfCsvFooter(&v41);
    long long v41 = *(void ***)v12;
    *(void ***)((char *)&v41 + (void)*(v41 - 3)) = *(void ***)(v12 + 24);
    MEMORY[0x21667CDE0](&__p);
    std::ostream::~ostream();
    MEMORY[0x21667D2B0](v45);
    uint64_t v7 = 0;
  }
  else
  {
    while (1)
    {
      CFDictionaryRef v6 = v5[5];
      long long v41 = (void **)v5[4];
      long long v43 = 0;
      uint64_t v44 = 0;
      long long __p = 0;
      std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(&__p, v6, (uint64_t)v5[6], v5[6] - v6);
      ZinPerfUtil::GetTaskExecutionTimeEstimate((ZinIrOpLayer ***)&__p, a2, &v33, v31);
      std::__unwrap_and_dispatch[abi:ne180100]<std::__overload<std::__copy_loop<std::_ClassicAlgPolicy>,std::__copy_trivial>,std::__wrap_iter<ZinPerfUtil::TaskStats *>,std::__wrap_iter<ZinPerfUtil::TaskStats *>,std::back_insert_iterator<std::vector<ZinPerfUtil::TaskStats>>,0>((long long *)v31[0], (long long *)v31[1], &v34);
      uint64_t v7 = v33;
      v30.__r_.__value_.__r.__words[0] = (std::string::size_type)v31;
      std::vector<ZinPerfUtil::TaskStats>::__destroy_vector::operator()[abi:ne180100]((void ***)&v30);
      if (__p)
      {
        long long v43 = __p;
        operator delete(__p);
      }
      if (v7) {
        break;
      }
      uint64_t v8 = v5[1];
      if (v8)
      {
        do
        {
          long long v9 = (void **)v8;
          uint64_t v8 = (void *)*v8;
        }
        while (v8);
      }
      else
      {
        do
        {
          long long v9 = (void **)v5[2];
          BOOL v10 = *v9 == v5;
          uint64_t v5 = v9;
        }
        while (!v10);
      }
      uint64_t v5 = v9;
      if (v9 == v38) {
        goto LABEL_18;
      }
    }
  }
  long long v41 = (void **)&v34;
  std::vector<ZinPerfUtil::TaskStats>::__destroy_vector::operator()[abi:ne180100](&v41);
  std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::destroy((uint64_t)&v37, v38[0]);
  if (SHIBYTE(v39.__r_.__value_.__r.__words[2]) < 0) {
    operator delete(v39.__r_.__value_.__l.__data_);
  }
  if (SHIBYTE(v40.__r_.__value_.__r.__words[2]) < 0) {
    operator delete(v40.__r_.__value_.__l.__data_);
  }
  return v7;
}

void sub_21129EDB8(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *a10, uint64_t a11, int a12, __int16 a13, char a14, char a15, void *a16, uint64_t a17, int a18, __int16 a19, char a20,char a21,uint64_t a22,void *a23,uint64_t a24,int a25,__int16 a26,char a27,char a28,uint64_t a29,char a30,uint64_t a31,uint64_t a32,char a33,uint64_t a34,uint64_t a35,void *a36,uint64_t a37,int a38,__int16 a39,char a40,char a41,uint64_t a42,void *__p,uint64_t a44,int a45,__int16 a46,char a47,char a48,uint64_t a49,uint64_t a50,void *a51,uint64_t a52)
{
  if (a48 < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinPerfUtil::WritePerfCsvHeader(void *a1)
{
  uint64_t v1 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(a1, (uint64_t)",", 1);
  uint64_t v2 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v1, (uint64_t)"is_chained", 10);
  uint64_t v3 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v2, (uint64_t)",", 1);
  uint64_t v4 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v3, (uint64_t)"NumWU", 5);
  uint64_t v5 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v4, (uint64_t)",", 1);
  CFDictionaryRef v6 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v5, (uint64_t)"mac_cycles_per_WU", 17);
  uint64_t v7 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v6, (uint64_t)",", 1);
  uint64_t v8 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v7, (uint64_t)"post_cycles_per_WU", 18);
  long long v9 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v8, (uint64_t)",", 1);
  BOOL v10 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v9, (uint64_t)"ne_cycle_single_buffering", 25);
  uint64_t v11 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v10, (uint64_t)",", 1);
  uint64_t v12 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v11, (uint64_t)"ne_cycle_double_buffering", 25);
  double v13 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v12, (uint64_t)",", 1);
  uint64_t v14 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v13, (uint64_t)"pe_cycle", 8);
  uint64_t v15 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v14, (uint64_t)",", 1);
  uint64_t v16 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v15, (uint64_t)"l2_bcast", 8);
  int v17 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v16, (uint64_t)",", 1);
  uint64_t v18 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v17, (uint64_t)"lw_writeback", 12);
  BOOL v19 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v18, (uint64_t)",", 1);
  std::string::size_type v20 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v19, (uint64_t)"kdma", 4);
  double v21 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v20, (uint64_t)",", 1);
  long long v22 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v21, (uint64_t)"rdma", 4);
  double v23 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v22, (uint64_t)",", 1);
  long long v24 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v23, (uint64_t)"wdma", 4);
  uint64_t v25 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v24, (uint64_t)",", 1);
  uint64_t v26 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v25, (uint64_t)"core_cycle_count", 16);
  uint64_t v27 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v26, (uint64_t)",", 1);
  int v28 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v27, (uint64_t)"l2_cycle_count", 14);
  std::string v29 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v28, (uint64_t)",", 1);
  std::string v30 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v29, (uint64_t)"power(W)", 8);
  double v31 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v30, (uint64_t)",", 1);
  std::string::size_type v32 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v31, (uint64_t)"estimated_time(ms)", 18);
  std::ios_base::getloc((const std::ios_base *)((char *)v32 + *(void *)(*v32 - 24)));
  unsigned int v33 = std::locale::use_facet(&v35, MEMORY[0x263F8C108]);
  ((void (*)(const std::locale::facet *, uint64_t))v33->__vftable[2].~facet_0)(v33, 10);
  std::locale::~locale(&v35);
  std::ostream::put();
  return std::ostream::flush();
}

void sub_21129F134(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, std::locale a10)
{
}

uint64_t ZinPerfUtil::WritePerfCsvBody()
{
  uint64_t v0 = (void *)std::ostream::operator<<();
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v0, (uint64_t)",", 1);
  uint64_t v1 = (void *)std::ostream::operator<<();
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v1, (uint64_t)",", 1);
  uint64_t v2 = (void *)std::ostream::operator<<();
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v2, (uint64_t)",", 1);
  uint64_t v3 = (void *)std::ostream::operator<<();
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v3, (uint64_t)",", 1);
  uint64_t v4 = (void *)std::ostream::operator<<();
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v4, (uint64_t)",", 1);
  uint64_t v5 = (void *)std::ostream::operator<<();
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v5, (uint64_t)",", 1);
  CFDictionaryRef v6 = (void *)std::ostream::operator<<();
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v6, (uint64_t)",", 1);
  uint64_t v7 = (void *)std::ostream::operator<<();
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v7, (uint64_t)",", 1);
  uint64_t v8 = (void *)std::ostream::operator<<();
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v8, (uint64_t)",", 1);
  long long v9 = (void *)std::ostream::operator<<();
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v9, (uint64_t)",", 1);
  BOOL v10 = (void *)std::ostream::operator<<();
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v10, (uint64_t)",", 1);
  uint64_t v11 = (void *)std::ostream::operator<<();
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v11, (uint64_t)",", 1);
  uint64_t v12 = (void *)std::ostream::operator<<();
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v12, (uint64_t)",", 1);
  double v13 = (void *)std::ostream::operator<<();
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v13, (uint64_t)",", 1);
  uint64_t v14 = (void *)std::ostream::operator<<();
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v14, (uint64_t)",", 1);
  uint64_t v15 = (void *)std::ostream::operator<<();
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v15, (uint64_t)",", 1);
  uint64_t v16 = (void *)std::ostream::operator<<();
  std::ios_base::getloc((const std::ios_base *)((char *)v16 + *(void *)(*v16 - 24)));
  int v17 = std::locale::use_facet(&v19, MEMORY[0x263F8C108]);
  ((void (*)(const std::locale::facet *, uint64_t))v17->__vftable[2].~facet_0)(v17, 10);
  std::locale::~locale(&v19);
  std::ostream::put();
  return std::ostream::flush();
}

void sub_21129F344(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, std::locale a10)
{
}

uint64_t ZinPerfUtil::WritePerfCsvFooter(void *a1)
{
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(a1, (uint64_t)", , , , , , , , , , , , , , , ,", 31);
  uint64_t v1 = (void *)std::ostream::operator<<();
  std::ios_base::getloc((const std::ios_base *)((char *)v1 + *(void *)(*v1 - 24)));
  uint64_t v2 = std::locale::use_facet(&v4, MEMORY[0x263F8C108]);
  ((void (*)(const std::locale::facet *, uint64_t))v2->__vftable[2].~facet_0)(v2, 10);
  std::locale::~locale(&v4);
  std::ostream::put();
  return std::ostream::flush();
}

void sub_21129F41C(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, std::locale a10)
{
}

uint64_t std::vector<ZinPerfUtil::TaskStats>::__push_back_slow_path<ZinPerfUtil::TaskStats>(uint64_t *a1, long long *a2)
{
  uint64_t v3 = *a1;
  uint64_t v4 = 0x2E8BA2E8BA2E8BA3 * ((a1[1] - *a1) >> 5);
  unint64_t v5 = v4 + 1;
  if ((unint64_t)(v4 + 1) > 0xBA2E8BA2E8BA2ELL) {
    std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
  }
  uint64_t v7 = (uint64_t)(a1 + 2);
  unint64_t v8 = 0x2E8BA2E8BA2E8BA3 * ((a1[2] - v3) >> 5);
  if (2 * v8 > v5) {
    unint64_t v5 = 2 * v8;
  }
  if (v8 >= 0x5D1745D1745D17) {
    unint64_t v9 = 0xBA2E8BA2E8BA2ELL;
  }
  else {
    unint64_t v9 = v5;
  }
  v29[4] = a1 + 2;
  if (v9) {
    BOOL v10 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ZinPerfUtil::TaskStats>>(v7, v9);
  }
  else {
    BOOL v10 = 0;
  }
  uint64_t v11 = &v10[352 * v4];
  v29[0] = v10;
  v29[1] = v11;
  void v29[3] = &v10[352 * v9];
  long long v12 = *a2;
  *((void *)v11 + 2) = *((void *)a2 + 2);
  *(_OWORD *)uint64_t v11 = v12;
  long long v13 = *(long long *)((char *)a2 + 40);
  long long v14 = *(long long *)((char *)a2 + 56);
  long long v15 = *(long long *)((char *)a2 + 72);
  *(_OWORD *)(v11 + 88) = *(long long *)((char *)a2 + 88);
  *(_OWORD *)(v11 + 72) = v15;
  *(_OWORD *)(v11 + 56) = v14;
  *(_OWORD *)(v11 + 40) = v13;
  long long v16 = *(long long *)((char *)a2 + 104);
  long long v17 = *(long long *)((char *)a2 + 120);
  long long v18 = *(long long *)((char *)a2 + 136);
  *(_OWORD *)(v11 + 152) = *(long long *)((char *)a2 + 152);
  *(_OWORD *)(v11 + 136) = v18;
  *(_OWORD *)(v11 + 120) = v17;
  *(_OWORD *)(v11 + 104) = v16;
  long long v19 = *(long long *)((char *)a2 + 168);
  long long v20 = *(long long *)((char *)a2 + 184);
  long long v21 = *(long long *)((char *)a2 + 200);
  *((void *)v11 + 27) = *((void *)a2 + 27);
  *(_OWORD *)(v11 + 200) = v21;
  *(_OWORD *)(v11 + 184) = v20;
  *(_OWORD *)(v11 + 168) = v19;
  *(_OWORD *)(v11 + 24) = *(long long *)((char *)a2 + 24);
  *((void *)v11 + 29) = 0;
  *((void *)v11 + 30) = 0;
  *((void *)v11 + 28) = 0;
  *((_OWORD *)v11 + 14) = a2[14];
  *((void *)v11 + 30) = *((void *)a2 + 30);
  *((void *)a2 + 29) = 0;
  *((void *)a2 + 30) = 0;
  *((void *)a2 + 28) = 0;
  long long v22 = *(long long *)((char *)a2 + 248);
  long long v23 = *(long long *)((char *)a2 + 280);
  *(_OWORD *)(v11 + 264) = *(long long *)((char *)a2 + 264);
  *(_OWORD *)(v11 + 248) = v22;
  long long v25 = *(long long *)((char *)a2 + 312);
  long long v24 = *(long long *)((char *)a2 + 328);
  long long v26 = *(long long *)((char *)a2 + 296);
  *((void *)v11 + 43) = *((void *)a2 + 43);
  *(_OWORD *)(v11 + 312) = v25;
  *(_OWORD *)(v11 + 328) = v24;
  *(_OWORD *)(v11 + 280) = v23;
  *(_OWORD *)(v11 + 296) = v26;
  v29[2] = v11 + 352;
  std::vector<ZinPerfUtil::TaskStats>::__swap_out_circular_buffer(a1, v29);
  uint64_t v27 = a1[1];
  std::__split_buffer<ZinPerfUtil::TaskStats>::~__split_buffer((uint64_t)v29);
  return v27;
}

void sub_21129F5F4(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::__split_buffer<ZinPerfUtil::TaskStats>::~__split_buffer((uint64_t)va);
  _Unwind_Resume(a1);
}

long long *std::__unwrap_and_dispatch[abi:ne180100]<std::__overload<std::__copy_loop<std::_ClassicAlgPolicy>,std::__copy_trivial>,std::__wrap_iter<ZinPerfUtil::TaskStats *>,std::__wrap_iter<ZinPerfUtil::TaskStats *>,std::back_insert_iterator<std::vector<ZinPerfUtil::TaskStats>>,0>(long long *a1, long long *a2, uint64_t *a3)
{
  uint64_t v3 = a1;
  CFDictionaryRef v6 = a3;
  if (a1 == a2) {
    return a1;
  }
  uint64_t v4 = a2;
  do
  {
    std::back_insert_iterator<std::vector<ZinPerfUtil::TaskStats>>::operator=[abi:ne180100](&v6, v3);
    v3 += 22;
  }
  while (v3 != v4);
  return v4;
}

uint64_t **std::back_insert_iterator<std::vector<ZinPerfUtil::TaskStats>>::operator=[abi:ne180100](uint64_t **a1, long long *a2)
{
  uint64_t v3 = *a1;
  unint64_t v5 = (*a1)[1];
  unint64_t v4 = (*a1)[2];
  CFDictionaryRef v6 = *a1;
  if (v5 >= v4)
  {
    uint64_t v7 = std::vector<ZinPerfUtil::TaskStats>::__push_back_slow_path<ZinPerfUtil::TaskStats const&>(v6, a2);
  }
  else
  {
    std::vector<ZinPerfUtil::TaskStats>::__construct_one_at_end[abi:ne180100]<ZinPerfUtil::TaskStats const&>((uint64_t)v6, a2);
    uint64_t v7 = v5 + 352;
  }
  v3[1] = v7;
  return a1;
}

__n128 std::vector<ZinPerfUtil::TaskStats>::__construct_one_at_end[abi:ne180100]<ZinPerfUtil::TaskStats const&>(uint64_t a1, long long *a2)
{
  uint64_t v4 = *(void *)(a1 + 8);
  long long v5 = *a2;
  *(void *)(v4 + 16) = *((void *)a2 + 2);
  *(_OWORD *)uint64_t v4 = v5;
  long long v6 = *(long long *)((char *)a2 + 40);
  long long v7 = *(long long *)((char *)a2 + 56);
  long long v8 = *(long long *)((char *)a2 + 72);
  *(_OWORD *)(v4 + 88) = *(long long *)((char *)a2 + 88);
  *(_OWORD *)(v4 + 72) = v8;
  *(_OWORD *)(v4 + 56) = v7;
  *(_OWORD *)(v4 + 40) = v6;
  long long v9 = *(long long *)((char *)a2 + 104);
  long long v10 = *(long long *)((char *)a2 + 120);
  long long v11 = *(long long *)((char *)a2 + 136);
  *(_OWORD *)(v4 + 152) = *(long long *)((char *)a2 + 152);
  *(_OWORD *)(v4 + 136) = v11;
  *(_OWORD *)(v4 + 120) = v10;
  *(_OWORD *)(v4 + 104) = v9;
  long long v12 = *(long long *)((char *)a2 + 168);
  long long v13 = *(long long *)((char *)a2 + 184);
  long long v14 = *(long long *)((char *)a2 + 200);
  *(void *)(v4 + 216) = *((void *)a2 + 27);
  *(_OWORD *)(v4 + 200) = v14;
  *(_OWORD *)(v4 + 184) = v13;
  *(_OWORD *)(v4 + 168) = v12;
  *(_OWORD *)(v4 + 24) = *(long long *)((char *)a2 + 24);
  *(void *)(v4 + 2std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = 0;
  *(void *)(v4 + 240) = 0;
  *(void *)(v4 + 224) = 0;
  std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>((void *)(v4 + 224), *((const void **)a2 + 28), *((void *)a2 + 29), (uint64_t)(*((void *)a2 + 29) - *((void *)a2 + 28)) >> 3);
  long long v15 = *(long long *)((char *)a2 + 248);
  long long v16 = *(long long *)((char *)a2 + 280);
  *(_OWORD *)(v4 + 264) = *(long long *)((char *)a2 + 264);
  *(_OWORD *)(v4 + 280) = v16;
  *(_OWORD *)(v4 + 248) = v15;
  __n128 result = *(__n128 *)((char *)a2 + 296);
  long long v18 = *(long long *)((char *)a2 + 312);
  long long v19 = *(long long *)((char *)a2 + 328);
  *(void *)(v4 + 344) = *((void *)a2 + 43);
  *(_OWORD *)(v4 + 312) = v18;
  *(_OWORD *)(v4 + 328) = v19;
  *(__n128 *)(v4 + 296) = result;
  *(void *)(a1 + 8) = v4 + 352;
  return result;
}

void sub_21129F7C0(_Unwind_Exception *a1)
{
  *(void *)(v1 + 8) = v2;
  _Unwind_Resume(a1);
}

uint64_t std::vector<ZinPerfUtil::TaskStats>::__push_back_slow_path<ZinPerfUtil::TaskStats const&>(uint64_t *a1, long long *a2)
{
  uint64_t v3 = *a1;
  uint64_t v4 = 0x2E8BA2E8BA2E8BA3 * ((a1[1] - *a1) >> 5);
  unint64_t v5 = v4 + 1;
  if ((unint64_t)(v4 + 1) > 0xBA2E8BA2E8BA2ELL) {
    std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
  }
  uint64_t v7 = (uint64_t)(a1 + 2);
  unint64_t v8 = 0x2E8BA2E8BA2E8BA3 * ((a1[2] - v3) >> 5);
  if (2 * v8 > v5) {
    unint64_t v5 = 2 * v8;
  }
  if (v8 >= 0x5D1745D1745D17) {
    unint64_t v9 = 0xBA2E8BA2E8BA2ELL;
  }
  else {
    unint64_t v9 = v5;
  }
  float v37 = a1 + 2;
  if (v9) {
    long long v10 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ZinPerfUtil::TaskStats>>(v7, v9);
  }
  else {
    long long v10 = 0;
  }
  long long v11 = &v10[352 * v4];
  v34[0] = v10;
  v34[1] = v11;
  std::locale v35 = v11;
  uint64_t v36 = &v10[352 * v9];
  long long v12 = *a2;
  *((void *)v11 + 2) = *((void *)a2 + 2);
  *(_OWORD *)long long v11 = v12;
  long long v13 = *(long long *)((char *)a2 + 24);
  long long v14 = *(long long *)((char *)a2 + 168);
  long long v15 = *(long long *)((char *)a2 + 184);
  long long v16 = *(long long *)((char *)a2 + 200);
  uint64_t v17 = *((void *)a2 + 27);
  long long v18 = *(long long *)((char *)a2 + 104);
  long long v19 = *(long long *)((char *)a2 + 120);
  long long v20 = *(long long *)((char *)a2 + 136);
  long long v21 = *(long long *)((char *)a2 + 152);
  long long v22 = *(long long *)((char *)a2 + 40);
  long long v23 = *(long long *)((char *)a2 + 56);
  long long v24 = *(long long *)((char *)a2 + 72);
  long long v25 = *(long long *)((char *)a2 + 88);
  *((void *)v11 + 28) = 0;
  v11 += 224;
  *(_OWORD *)(v11 - 136) = v25;
  *(_OWORD *)(v11 - 152) = v24;
  *(_OWORD *)(v11 - 168) = v23;
  *(_OWORD *)(v11 - 184) = v22;
  *(_OWORD *)(v11 - 72) = v21;
  *(_OWORD *)(v11 - 88) = v20;
  *(_OWORD *)(v11 - 104) = v19;
  *(_OWORD *)(v11 - 120) = v18;
  *((void *)v11 - 1) = v17;
  *(_OWORD *)(v11 - 24) = v16;
  *(_OWORD *)(v11 - 40) = v15;
  *(_OWORD *)(v11 - 56) = v14;
  *(_OWORD *)(v11 - 200) = v13;
  *((void *)v11 + 1) = 0;
  *((void *)v11 + 2) = 0;
  std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(v11, *((const void **)a2 + 28), *((void *)a2 + 29), (uint64_t)(*((void *)a2 + 29) - *((void *)a2 + 28)) >> 3);
  long long v26 = &v10[352 * v4];
  long long v28 = *(long long *)((char *)a2 + 264);
  long long v27 = *(long long *)((char *)a2 + 280);
  *(_OWORD *)(v26 + 248) = *(long long *)((char *)a2 + 248);
  *(_OWORD *)(v26 + 264) = v28;
  long long v29 = *(long long *)((char *)a2 + 296);
  long long v30 = *(long long *)((char *)a2 + 312);
  long long v31 = *(long long *)((char *)a2 + 328);
  *((void *)v26 + 43) = *((void *)a2 + 43);
  *(_OWORD *)(v26 + 312) = v30;
  *(_OWORD *)(v26 + 328) = v31;
  *(_OWORD *)(v26 + 280) = v27;
  *(_OWORD *)(v26 + 296) = v29;
  v35 += 352;
  std::vector<ZinPerfUtil::TaskStats>::__swap_out_circular_buffer(a1, v34);
  uint64_t v32 = a1[1];
  std::__split_buffer<ZinPerfUtil::TaskStats>::~__split_buffer((uint64_t)v34);
  return v32;
}

void sub_21129F994(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::__split_buffer<ZinPerfUtil::TaskStats>::~__split_buffer((uint64_t)va);
  _Unwind_Resume(a1);
}

uint64_t ZinReductionLayerUtils::PEReductionWithoutDimensionBalancer(const ZinIrReductionInfo *a1, void *a2, uint64_t a3, uint64_t a4, int a5, uint64_t *a6)
{
  uint64_t v6 = 1;
  switch(*((void *)a1 + 3))
  {
    case 2:
      uint64_t v7 = a2[2];
      uint64_t v8 = a2[3];
      if (v8 != 1 || v7 < 2) {
        goto LABEL_49;
      }
      uint64_t v10 = a2[1];
      uint64_t v32 = *a2;
      uint64_t v33 = v10 * v7;
      uint64_t v6 = 1;
      *(int64x2_t *)uint64_t v34 = vdupq_n_s64(1uLL);
      uint64_t v11 = a2[4];
      goto LABEL_23;
    case 4:
      if (a2[3] != 1) {
        return 0;
      }
      uint64_t v19 = a2[2];
      uint64_t v20 = a2[4];
      if (v19 >= 2 && v20 == 1 && (unint64_t)v19 < *(void *)(a4 + 960)) {
        goto LABEL_42;
      }
      if (v19 == 1 && a2[1] <= *(void *)(a4 + 352) && v20 >= 1) {
        goto LABEL_57;
      }
      return 0;
    case 8:
      uint64_t v8 = a2[3];
      uint64_t v7 = a2[4];
      if (v8 != 1 || v7 < 2) {
        goto LABEL_49;
      }
      uint64_t v29 = a2[1];
      uint64_t v32 = *a2;
      uint64_t v33 = v29 * v7;
      *(void *)uint64_t v34 = a2[2];
      uint64_t v6 = 1;
      int64x2_t v30 = vdupq_n_s64(1uLL);
      goto LABEL_64;
    case 0xALL:
      uint64_t v12 = a2[3];
      goto LABEL_56;
    case 0xELL:
      uint64_t v8 = a2[3];
      uint64_t v7 = a2[1];
      if (v8 == 1 && v7 >= 2)
      {
        uint64_t v6 = 1;
        uint64_t v32 = *a2;
        uint64_t v33 = 1;
        *(void *)uint64_t v34 = a2[2];
        *(void *)&v34[8] = 1;
        goto LABEL_22;
      }
LABEL_49:
      BOOL v26 = v8 == 1 && v7 == 1;
      goto LABEL_61;
    case 0x10:
      uint64_t v14 = a2[2];
      uint64_t v15 = a2[4];
      if (v14 > 1 || v15 >= 2)
      {
        uint64_t v17 = a2[1];
        uint64_t v32 = v15 * *a2;
        uint64_t v33 = v17 * v14;
        uint64_t v6 = 1;
        uint64_t v18 = a2[3];
        *(void *)uint64_t v34 = 1;
        *(void *)&v34[8] = v18;
        *(void *)&v34[16] = 1;
        ZinReductionLayerUtils::CreateReshapeReductionReshape(a1, (uint64_t)&v32, a3, a6);
        return v6;
      }
      BOOL v26 = v14 == 1 && v15 == 1;
      goto LABEL_61;
    case 0x12:
      uint64_t v12 = a2[2];
      if (v12 < 2) {
        goto LABEL_56;
      }
      uint64_t v27 = a2[1] * v12;
      uint64_t v32 = *a2;
      uint64_t v33 = v27;
      uint64_t v6 = 1;
      *(void *)uint64_t v34 = 1;
      int64x2_t v30 = *(int64x2_t *)(a2 + 3);
LABEL_64:
      *(int64x2_t *)&v34[8] = v30;
      goto LABEL_65;
    case 0x16:
LABEL_42:
      ZinReductionLayerUtils::CreateTransposeReductionTranspose(a1, 3u, a5, a6);
      goto LABEL_43;
    case 0x18:
      uint64_t v12 = a2[4];
      if (v12 >= 2)
      {
        uint64_t v28 = a2[1] * v12;
        uint64_t v32 = *a2;
        uint64_t v33 = v28;
        *(_OWORD *)uint64_t v34 = *((_OWORD *)a2 + 1);
        uint64_t v6 = 1;
        *(void *)&v34[16] = 1;
        goto LABEL_65;
      }
LABEL_56:
      BOOL v26 = v12 == 1;
LABEL_61:
      uint64_t v6 = v26;
      break;
    case 0x1ALL:
      return v6;
    case 0x1CLL:
      if (a2[4] >= *(void *)(a4 + 960)) {
        return 0;
      }
LABEL_57:
      uint64_t v6 = 1;
      ZinReductionLayerUtils::CreateTransposeReductionTranspose(a1, 1u, a5, a6);
      return v6;
    case 0x1ELL:
      uint64_t v7 = a2[1];
      if (v7 < 2)
      {
LABEL_43:
        uint64_t v6 = 1;
      }
      else
      {
        uint64_t v6 = 1;
        uint64_t v32 = *a2;
        uint64_t v33 = 1;
        *(_OWORD *)uint64_t v34 = *((_OWORD *)a2 + 1);
LABEL_22:
        uint64_t v11 = a2[4] * v7;
LABEL_23:
        *(void *)&v34[16] = v11;
LABEL_65:
        ZinReductionLayerUtils::CreateReshapeReductionReshape(a1, (uint64_t)&v32, a3, a6);
      }
      break;
    default:
      return 0;
  }
  return v6;
}

void ZinReductionLayerUtils::CreateReshapeReductionReshape(const ZinIrReductionInfo *a1, uint64_t a2, uint64_t a3, uint64_t *a4)
{
  uint64_t v36 = *MEMORY[0x263EF8340];
  ZinIrReshapeUnitInfo::ZinIrReshapeUnitInfo((uint64_t)&v13, a2);
  int v24 = 22;
  long long v25 = &unk_26C345B80;
  if (SHIBYTE(v14.__r_.__value_.__r.__words[2]) < 0) {
    std::string::__init_copy_ctor_external(&v26, v14.__r_.__value_.__l.__data_, v14.__r_.__value_.__l.__size_);
  }
  else {
    std::string v26 = v14;
  }
  int v27 = v15;
  memset(&v28, 0, sizeof(v28));
  std::vector<std::string>::__init_with_size[abi:ne180100]<std::string*,std::string*>(&v28, v16, v17, 0xAAAAAAAAAAAAAAABLL * (((char *)v17 - (char *)v16) >> 3));
  long long v29 = v18;
  long long v30 = v19;
  long long v31 = v20;
  long long v25 = &unk_26C34D9A0;
  uint64_t v32 = v21;
  uint64_t v33 = 0;
  uint64_t v34 = 0;
  uint64_t v35 = 0;
  std::vector<ZinIrPaddingMode>::__init_with_size[abi:ne180100]<ZinIrPaddingMode*,ZinIrPaddingMode*>(&v33, __p, (uint64_t)v23, (v23 - (unsigned char *)__p) >> 2);
  unint64_t v7 = a4[1];
  if (v7 >= a4[2])
  {
    uint64_t v8 = std::vector<ZinReductionLayerUtils::ReductionDecomposedDesc>::__push_back_slow_path<ZinReductionLayerUtils::ReductionDecomposedDesc const&>(a4, (const ZinReductionLayerUtils::ReductionDecomposedDesc *)&v24);
  }
  else
  {
    ZinReductionLayerUtils::ReductionDecomposedDesc::ReductionDecomposedDesc((ZinReductionLayerUtils::ReductionDecomposedDesc *)a4[1], (const ZinReductionLayerUtils::ReductionDecomposedDesc *)&v24);
    uint64_t v8 = v7 + 344;
    a4[1] = v7 + 344;
  }
  a4[1] = v8;
  ZinReductionLayerUtils::ReductionDecomposedDesc::~ReductionDecomposedDesc((ZinReductionLayerUtils::ReductionDecomposedDesc *)&v24);
  long long v13 = &unk_26C34D9A0;
  if (__p)
  {
    long long v23 = __p;
    operator delete(__p);
  }
  ZinIrUnitInfo::~ZinIrUnitInfo(&v13);
  int v24 = 20;
  ZinIrReductionInfo::ZinIrReductionInfo((ZinIrReductionInfo *)&v25, a1);
  unint64_t v9 = a4[1];
  if (v9 >= a4[2])
  {
    uint64_t v10 = std::vector<ZinReductionLayerUtils::ReductionDecomposedDesc>::__push_back_slow_path<ZinReductionLayerUtils::ReductionDecomposedDesc const&>(a4, (const ZinReductionLayerUtils::ReductionDecomposedDesc *)&v24);
  }
  else
  {
    ZinReductionLayerUtils::ReductionDecomposedDesc::ReductionDecomposedDesc((ZinReductionLayerUtils::ReductionDecomposedDesc *)a4[1], (const ZinReductionLayerUtils::ReductionDecomposedDesc *)&v24);
    uint64_t v10 = v9 + 344;
    a4[1] = v9 + 344;
  }
  a4[1] = v10;
  ZinReductionLayerUtils::ReductionDecomposedDesc::~ReductionDecomposedDesc((ZinReductionLayerUtils::ReductionDecomposedDesc *)&v24);
  ZinIrReshapeUnitInfo::ZinIrReshapeUnitInfo((uint64_t)&v13, a3);
  int v24 = 22;
  long long v25 = &unk_26C345B80;
  if (SHIBYTE(v14.__r_.__value_.__r.__words[2]) < 0) {
    std::string::__init_copy_ctor_external(&v26, v14.__r_.__value_.__l.__data_, v14.__r_.__value_.__l.__size_);
  }
  else {
    std::string v26 = v14;
  }
  int v27 = v15;
  memset(&v28, 0, sizeof(v28));
  std::vector<std::string>::__init_with_size[abi:ne180100]<std::string*,std::string*>(&v28, v16, v17, 0xAAAAAAAAAAAAAAABLL * (((char *)v17 - (char *)v16) >> 3));
  long long v29 = v18;
  long long v30 = v19;
  long long v31 = v20;
  long long v25 = &unk_26C34D9A0;
  uint64_t v32 = v21;
  uint64_t v33 = 0;
  uint64_t v34 = 0;
  uint64_t v35 = 0;
  std::vector<ZinIrPaddingMode>::__init_with_size[abi:ne180100]<ZinIrPaddingMode*,ZinIrPaddingMode*>(&v33, __p, (uint64_t)v23, (v23 - (unsigned char *)__p) >> 2);
  unint64_t v11 = a4[1];
  if (v11 >= a4[2])
  {
    uint64_t v12 = std::vector<ZinReductionLayerUtils::ReductionDecomposedDesc>::__push_back_slow_path<ZinReductionLayerUtils::ReductionDecomposedDesc const&>(a4, (const ZinReductionLayerUtils::ReductionDecomposedDesc *)&v24);
  }
  else
  {
    ZinReductionLayerUtils::ReductionDecomposedDesc::ReductionDecomposedDesc((ZinReductionLayerUtils::ReductionDecomposedDesc *)a4[1], (const ZinReductionLayerUtils::ReductionDecomposedDesc *)&v24);
    uint64_t v12 = v11 + 344;
    a4[1] = v11 + 344;
  }
  a4[1] = v12;
  ZinReductionLayerUtils::ReductionDecomposedDesc::~ReductionDecomposedDesc((ZinReductionLayerUtils::ReductionDecomposedDesc *)&v24);
  long long v13 = &unk_26C34D9A0;
  if (__p)
  {
    long long v23 = __p;
    operator delete(__p);
  }
  ZinIrUnitInfo::~ZinIrUnitInfo(&v13);
}

void sub_2112A0014(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,char a27,uint64_t a28,void *__p,uint64_t a30,int a31,__int16 a32,char a33,char a34)
{
}

void ZinReductionLayerUtils::CreateTransposeReductionTranspose(const ZinIrReductionInfo *a1, unsigned int a2, int a3, uint64_t *a4)
{
  char v5 = a2;
  v29[32] = *MEMORY[0x263EF8340];
  ZinIrTransposeUnitInfo::ZinIrTransposeUnitInfo((uint64_t)&v15, 2u, a2, a3);
  int v23 = 21;
  int v24 = &unk_26C345B80;
  if (SHIBYTE(v16.__r_.__value_.__r.__words[2]) < 0) {
    std::string::__init_copy_ctor_external(&v25, v16.__r_.__value_.__l.__data_, v16.__r_.__value_.__l.__size_);
  }
  else {
    std::string v25 = v16;
  }
  int v26 = v17;
  memset(&v27, 0, sizeof(v27));
  std::vector<std::string>::__init_with_size[abi:ne180100]<std::string*,std::string*>(&v27, v18, v19, 0xAAAAAAAAAAAAAAABLL * (((char *)v19 - (char *)v18) >> 3));
  long long v28 = v20;
  int v24 = &unk_26C34F988;
  memset(v29, 0, 24);
  std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(v29, __p, (uint64_t)v22, (v22 - (unsigned char *)__p) >> 3);
  int v15 = &unk_26C34F988;
  if (__p)
  {
    long long v22 = __p;
    operator delete(__p);
  }
  ZinIrUnitInfo::~ZinIrUnitInfo(&v15);
  unint64_t v7 = a4[1];
  if (v7 >= a4[2])
  {
    uint64_t v8 = std::vector<ZinReductionLayerUtils::ReductionDecomposedDesc>::__push_back_slow_path<ZinReductionLayerUtils::ReductionDecomposedDesc const&>(a4, (const ZinReductionLayerUtils::ReductionDecomposedDesc *)&v23);
  }
  else
  {
    ZinReductionLayerUtils::ReductionDecomposedDesc::ReductionDecomposedDesc((ZinReductionLayerUtils::ReductionDecomposedDesc *)a4[1], (const ZinReductionLayerUtils::ReductionDecomposedDesc *)&v23);
    uint64_t v8 = v7 + 344;
    a4[1] = v7 + 344;
  }
  a4[1] = v8;
  uint64_t v9 = *((void *)a1 + 3);
  ZinIrReductionInfo::ZinIrReductionInfo((ZinIrReductionInfo *)v14, a1);
  void v14[3] = v9 & 0x1B | (1 << v5) & 0x1F;
  LODWORD(v15) = 20;
  ZinIrReductionInfo::ZinIrReductionInfo((ZinIrReductionInfo *)&v16, (const ZinIrReductionInfo *)v14);
  unint64_t v10 = a4[1];
  if (v10 >= a4[2])
  {
    uint64_t v11 = std::vector<ZinReductionLayerUtils::ReductionDecomposedDesc>::__push_back_slow_path<ZinReductionLayerUtils::ReductionDecomposedDesc const&>(a4, (const ZinReductionLayerUtils::ReductionDecomposedDesc *)&v15);
  }
  else
  {
    ZinReductionLayerUtils::ReductionDecomposedDesc::ReductionDecomposedDesc((ZinReductionLayerUtils::ReductionDecomposedDesc *)a4[1], (const ZinReductionLayerUtils::ReductionDecomposedDesc *)&v15);
    uint64_t v11 = v10 + 344;
    a4[1] = v10 + 344;
  }
  a4[1] = v11;
  ZinReductionLayerUtils::ReductionDecomposedDesc::~ReductionDecomposedDesc((ZinReductionLayerUtils::ReductionDecomposedDesc *)&v15);
  unint64_t v12 = a4[1];
  if (v12 >= a4[2])
  {
    uint64_t v13 = std::vector<ZinReductionLayerUtils::ReductionDecomposedDesc>::__push_back_slow_path<ZinReductionLayerUtils::ReductionDecomposedDesc const&>(a4, (const ZinReductionLayerUtils::ReductionDecomposedDesc *)&v23);
  }
  else
  {
    ZinReductionLayerUtils::ReductionDecomposedDesc::ReductionDecomposedDesc((ZinReductionLayerUtils::ReductionDecomposedDesc *)a4[1], (const ZinReductionLayerUtils::ReductionDecomposedDesc *)&v23);
    uint64_t v13 = v12 + 344;
    a4[1] = v12 + 344;
  }
  a4[1] = v13;
  ZinIrHalH13g::~ZinIrHalH13g((ZinIrHalH13g *)v14);
  ZinReductionLayerUtils::ReductionDecomposedDesc::~ReductionDecomposedDesc((ZinReductionLayerUtils::ReductionDecomposedDesc *)&v23);
}

void sub_2112A0338(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, ...)
{
  va_start(va, a8);
  ZinIrTransposeUnitInfo::~ZinIrTransposeUnitInfo((ZinIrTransposeUnitInfo *)va);
  _Unwind_Resume(a1);
}

uint64_t ZinReductionLayerUtils::CreateReductionByPeelingOffADimension(int8x8_t *a1, uint64_t a2, uint64_t *a3)
{
  v18[42] = *MEMORY[0x263EF8340];
  int8x8_t v17 = a1[3];
  v14[0] = 1;
  if ((unint64_t)std::__count[abi:ne180100]<std::_ClassicAlgPolicy,std::__bitset<1ul,16ul>,true,BOOL,std::__identity,0>(&v17, 0, (uint64_t)&v17, 5u, v14) <= 1)ZinAssertImpl("The reduction should be multi-dimension reduction"); {
  int8x8_t v5 = a1[3];
  }
  if ((v5.i8[0] & 0x10) != 0)
  {
    unsigned int v6 = 16;
  }
  else if ((v5.i8[0] & 4) != 0)
  {
    unsigned int v6 = 4;
  }
  else
  {
    if (v5.i8[0]) {
      unsigned int v6 = 1;
    }
    else {
      unsigned int v6 = 16;
    }
    if ((v5.i8[0] & 5) == 0)
    {
      if ((v5.i8[0] & 8) != 0) {
        unsigned int v6 = 8;
      }
      if ((v5.i8[0] & 0xD) == 0)
      {
        if ((v5.i8[0] & 2) != 0) {
          unsigned int v6 = 2;
        }
        if ((v5.i8[0] & 0xF) == 0) {
          ZinAssertImpl("Reduction peeling failed.");
        }
      }
    }
  }
  int v7 = a1[1].i32[1];
  int8x8_t v17 = (int8x8_t)v6;
  ZinIrReductionInfo::ZinIrReductionInfo((uint64_t)v16, v7, &v17, 0, 0, 0, 0, 0, 1.0, 0.0);
  v17.i32[0] = 20;
  ZinIrReductionInfo::ZinIrReductionInfo((ZinIrReductionInfo *)v18, (const ZinIrReductionInfo *)v16);
  unint64_t v8 = a3[1];
  if (v8 >= a3[2])
  {
    uint64_t v9 = std::vector<ZinReductionLayerUtils::ReductionDecomposedDesc>::__push_back_slow_path<ZinReductionLayerUtils::ReductionDecomposedDesc const&>(a3, (const ZinReductionLayerUtils::ReductionDecomposedDesc *)&v17);
  }
  else
  {
    ZinReductionLayerUtils::ReductionDecomposedDesc::ReductionDecomposedDesc((ZinReductionLayerUtils::ReductionDecomposedDesc *)a3[1], (const ZinReductionLayerUtils::ReductionDecomposedDesc *)&v17);
    uint64_t v9 = v8 + 344;
    a3[1] = v8 + 344;
  }
  a3[1] = v9;
  ZinReductionLayerUtils::ReductionDecomposedDesc::~ReductionDecomposedDesc((ZinReductionLayerUtils::ReductionDecomposedDesc *)&v17);
  int8x8_t v10 = a1[3];
  ZinIrReductionInfo::ZinIrReductionInfo((ZinIrReductionInfo *)v14, (const ZinIrReductionInfo *)a1);
  uint64_t v15 = v10.i32[0] & (v6 ^ 0x1F);
  v17.i32[0] = 20;
  ZinIrReductionInfo::ZinIrReductionInfo((ZinIrReductionInfo *)v18, (const ZinIrReductionInfo *)v14);
  unint64_t v11 = a3[1];
  if (v11 >= a3[2])
  {
    uint64_t v12 = std::vector<ZinReductionLayerUtils::ReductionDecomposedDesc>::__push_back_slow_path<ZinReductionLayerUtils::ReductionDecomposedDesc const&>(a3, (const ZinReductionLayerUtils::ReductionDecomposedDesc *)&v17);
  }
  else
  {
    ZinReductionLayerUtils::ReductionDecomposedDesc::ReductionDecomposedDesc((ZinReductionLayerUtils::ReductionDecomposedDesc *)a3[1], (const ZinReductionLayerUtils::ReductionDecomposedDesc *)&v17);
    uint64_t v12 = v11 + 344;
    a3[1] = v11 + 344;
  }
  a3[1] = v12;
  ZinReductionLayerUtils::ReductionDecomposedDesc::~ReductionDecomposedDesc((ZinReductionLayerUtils::ReductionDecomposedDesc *)&v17);
  ZinIrHalH13g::~ZinIrHalH13g((ZinIrHalH13g *)v14);
  ZinIrHalH13g::~ZinIrHalH13g((ZinIrHalH13g *)v16);
  return 1;
}

void sub_2112A05FC(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, char a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,char a23)
{
}

void ZinReductionLayerUtils::HandleChannelReduction(int a1, uint64_t a2, uint64_t *a3, uint64_t a4)
{
  uint64_t v46 = *MEMORY[0x263EF8340];
  unint64_t v5 = *(void *)(a4 + 368);
  if (v5 < a2) {
    ZinAssertImpl("Error: channel size exceeds limit [%zu vs. %zu]", a2, v5);
  }
  if ((a1 - 1) > 1)
  {
    if (!a1)
    {
      ZinReductionLayerUtils::ToUnityChannelWiseConvInfo((uint64_t)&v23);
      int v42 = 1;
      ZinIrKernelUnitInfo::ZinIrKernelUnitInfo((ZinIrKernelUnitInfo *)v43, (const ZinIrKernelUnitInfo *)&v23);
      long long v17 = v39;
      long long v18 = v41[0];
      v19[18] = v40;
      v19[19] = v18;
      long long v20 = v37;
      v19[16] = v38;
      v19[17] = v17;
      long long v45 = *(_OWORD *)((char *)v41 + 12);
      v43[0] = &unk_26C34A9B8;
      long long v44 = v20;
      unint64_t v21 = a3[1];
      if (v21 >= a3[2])
      {
        uint64_t v22 = std::vector<ZinReductionLayerUtils::ReductionDecomposedDesc>::__push_back_slow_path<ZinReductionLayerUtils::ReductionDecomposedDesc const&>(a3, (const ZinReductionLayerUtils::ReductionDecomposedDesc *)&v42);
      }
      else
      {
        ZinReductionLayerUtils::ReductionDecomposedDesc::ReductionDecomposedDesc((ZinReductionLayerUtils::ReductionDecomposedDesc *)a3[1], (const ZinReductionLayerUtils::ReductionDecomposedDesc *)&v42);
        uint64_t v22 = v21 + 344;
        a3[1] = v21 + 344;
      }
      a3[1] = v22;
      ZinReductionLayerUtils::ReductionDecomposedDesc::~ReductionDecomposedDesc((ZinReductionLayerUtils::ReductionDecomposedDesc *)&v42);
      int v23 = &unk_26C34CC70;
      if ((void)__p)
      {
        *((void *)&__p + 1) = __p;
        operator delete((void *)__p);
      }
      if (*(void *)&v35[8])
      {
        *(void *)&unsigned char v35[16] = *(void *)&v35[8];
        operator delete(*(void **)&v35[8]);
      }
      goto LABEL_26;
    }
    if (a1 != 3) {
      return;
    }
    ZinReductionLayerUtils::ToUnityChannelWiseConvInfo((uint64_t)&v23);
    int v42 = 1;
    ZinIrKernelUnitInfo::ZinIrKernelUnitInfo((ZinIrKernelUnitInfo *)v43, (const ZinIrKernelUnitInfo *)&v23);
    long long v10 = v39;
    long long v11 = v41[0];
    v12[18] = v40;
    v12[19] = v11;
    long long v13 = v37;
    v12[16] = v38;
    v12[17] = v10;
    long long v45 = *(_OWORD *)((char *)v41 + 12);
    v43[0] = &unk_26C34A9B8;
    long long v44 = v13;
    unint64_t v14 = a3[1];
    if (v14 >= a3[2])
    {
      uint64_t v15 = std::vector<ZinReductionLayerUtils::ReductionDecomposedDesc>::__push_back_slow_path<ZinReductionLayerUtils::ReductionDecomposedDesc const&>(a3, (const ZinReductionLayerUtils::ReductionDecomposedDesc *)&v42);
    }
    else
    {
      ZinReductionLayerUtils::ReductionDecomposedDesc::ReductionDecomposedDesc((ZinReductionLayerUtils::ReductionDecomposedDesc *)a3[1], (const ZinReductionLayerUtils::ReductionDecomposedDesc *)&v42);
      uint64_t v15 = v14 + 344;
      a3[1] = v14 + 344;
    }
    a3[1] = v15;
    ZinReductionLayerUtils::ReductionDecomposedDesc::~ReductionDecomposedDesc((ZinReductionLayerUtils::ReductionDecomposedDesc *)&v42);
    int v23 = &unk_26C34CC70;
    if ((void)__p)
    {
      *((void *)&__p + 1) = __p;
      operator delete((void *)__p);
    }
    if (*(void *)&v35[8])
    {
      *(void *)&unsigned char v35[16] = *(void *)&v35[8];
      operator delete(*(void **)&v35[8]);
    }
    ZinIrUnitInfo::~ZinIrUnitInfo(&v23);
    uint64_t v24 = 0;
    uint64_t v25 = 0;
    int v27 = 0;
    uint64_t v26 = 0;
    long long v28 = 0u;
    long long v29 = 0u;
    uint64_t v30 = -1;
    *(void *)((char *)&v34 + 4) = -1;
    *(void *)&v35[12] = -1;
    int v23 = &unk_26C349940;
    LOBYTE(v34) = 0;
    *(void *)uint64_t v35 = -1;
    v35[8] = 0;
    *(void *)&v35[24] = -1;
    LOWORD(v31) = 1;
    float v32 = 1.0 / (float)a2;
    v33.i32[0] = 4;
    v33.i16[2] = 1;
    v33.i64[1] = 0x400000000;
    ZinElementWiseLayerUtils::ElementWiseDecomposedDesc::ElementWiseDecomposedDesc((ZinElementWiseLayerUtils::ElementWiseDecomposedDesc *)&v42, (ZinIrGOCUnitInfo *)&v23);
    unint64_t v9 = a3[1];
    if (v9 < a3[2]) {
      goto LABEL_24;
    }
  }
  else
  {
    *(_OWORD *)&v35[4] = 0uLL;
    if (a1 == 1) {
      int v7 = 4;
    }
    else {
      int v7 = 2;
    }
    if (a1 == 1) {
      int v8 = 5;
    }
    else {
      int v8 = 3;
    }
    *(void *)&v35[20] = 0;
    uint64_t v25 = 0;
    uint64_t v26 = 0;
    int v27 = 0;
    long long v28 = 0u;
    long long v29 = 0u;
    int v31 = v8;
    int64x2_t v33 = vdupq_n_s64(1uLL);
    *(void *)&long long v34 = 1;
    *((void *)&v34 + 1) = 0x100000001;
    *(_DWORD *)uint64_t v35 = 1;
    v35[28] = 0;
    LODWORD(__p) = v7;
    *(void *)((char *)&__p + 4) = 1065353216;
    int v23 = &unk_26C34AB58;
    uint64_t v24 = 0;
    uint64_t v30 = 1;
    ZinMirPoolUtils::PoolDecomposedDesc::PoolDecomposedDesc((ZinMirPoolUtils::PoolDecomposedDesc *)&v42, (ZinIrPoolUnitInfo *)&v23);
    unint64_t v9 = a3[1];
    if (v9 < a3[2])
    {
LABEL_24:
      ZinReductionLayerUtils::ReductionDecomposedDesc::ReductionDecomposedDesc((ZinReductionLayerUtils::ReductionDecomposedDesc *)a3[1], (const ZinReductionLayerUtils::ReductionDecomposedDesc *)&v42);
      uint64_t v16 = v9 + 344;
      a3[1] = v9 + 344;
      goto LABEL_25;
    }
  }
  uint64_t v16 = std::vector<ZinReductionLayerUtils::ReductionDecomposedDesc>::__push_back_slow_path<ZinReductionLayerUtils::ReductionDecomposedDesc const&>(a3, (const ZinReductionLayerUtils::ReductionDecomposedDesc *)&v42);
LABEL_25:
  a3[1] = v16;
  ZinReductionLayerUtils::ReductionDecomposedDesc::~ReductionDecomposedDesc((ZinReductionLayerUtils::ReductionDecomposedDesc *)&v42);
LABEL_26:
  ZinIrUnitInfo::~ZinIrUnitInfo(&v23);
}

void sub_2112A0A94(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, void *a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33,uint64_t a34,uint64_t a35,uint64_t a36,uint64_t a37,uint64_t a38,uint64_t a39,uint64_t a40,uint64_t a41,uint64_t a42,uint64_t a43,uint64_t a44,uint64_t a45,uint64_t a46,uint64_t a47,uint64_t a48,uint64_t a49,uint64_t a50,uint64_t a51,uint64_t a52,char a53)
{
}

void ZinReductionLayerUtils::HandleDepthReduction(int a1, uint64_t a2, int a3, uint64_t *a4, uint64_t a5)
{
  v27[32] = *MEMORY[0x263EF8340];
  ZinIrTransposeUnitInfo::ZinIrTransposeUnitInfo((uint64_t)&v13, 2u, 1u, a3);
  int v21 = 21;
  uint64_t v22 = &unk_26C345B80;
  if (SHIBYTE(v14.__r_.__value_.__r.__words[2]) < 0) {
    std::string::__init_copy_ctor_external(&v23, v14.__r_.__value_.__l.__data_, v14.__r_.__value_.__l.__size_);
  }
  else {
    std::string v23 = v14;
  }
  int v24 = v15;
  memset(&v25, 0, sizeof(v25));
  std::vector<std::string>::__init_with_size[abi:ne180100]<std::string*,std::string*>(&v25, v16, v17, 0xAAAAAAAAAAAAAAABLL * (((char *)v17 - (char *)v16) >> 3));
  long long v26 = v18;
  uint64_t v22 = &unk_26C34F988;
  memset(v27, 0, 24);
  std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(v27, __p, (uint64_t)v20, (v20 - (unsigned char *)__p) >> 3);
  long long v13 = &unk_26C34F988;
  if (__p)
  {
    long long v20 = __p;
    operator delete(__p);
  }
  ZinIrUnitInfo::~ZinIrUnitInfo(&v13);
  unint64_t v9 = a4[1];
  if (v9 >= a4[2])
  {
    uint64_t v10 = std::vector<ZinReductionLayerUtils::ReductionDecomposedDesc>::__push_back_slow_path<ZinReductionLayerUtils::ReductionDecomposedDesc const&>(a4, (const ZinReductionLayerUtils::ReductionDecomposedDesc *)&v21);
  }
  else
  {
    ZinReductionLayerUtils::ReductionDecomposedDesc::ReductionDecomposedDesc((ZinReductionLayerUtils::ReductionDecomposedDesc *)a4[1], (const ZinReductionLayerUtils::ReductionDecomposedDesc *)&v21);
    uint64_t v10 = v9 + 344;
    a4[1] = v9 + 344;
  }
  a4[1] = v10;
  ZinReductionLayerUtils::HandleChannelReduction(a1, *(void *)(a2 + 32), a4, a5);
  unint64_t v11 = a4[1];
  if (v11 >= a4[2])
  {
    uint64_t v12 = std::vector<ZinReductionLayerUtils::ReductionDecomposedDesc>::__push_back_slow_path<ZinReductionLayerUtils::ReductionDecomposedDesc const&>(a4, (const ZinReductionLayerUtils::ReductionDecomposedDesc *)&v21);
  }
  else
  {
    ZinReductionLayerUtils::ReductionDecomposedDesc::ReductionDecomposedDesc((ZinReductionLayerUtils::ReductionDecomposedDesc *)a4[1], (const ZinReductionLayerUtils::ReductionDecomposedDesc *)&v21);
    uint64_t v12 = v11 + 344;
    a4[1] = v11 + 344;
  }
  a4[1] = v12;
  ZinReductionLayerUtils::ReductionDecomposedDesc::~ReductionDecomposedDesc((ZinReductionLayerUtils::ReductionDecomposedDesc *)&v21);
}

void sub_2112A0D30(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, char a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,char a23,uint64_t a24,void *__p,uint64_t a26,int a27,__int16 a28,char a29,char a30)
{
}

void ZinReductionLayerUtils::HandleWidthReduction(int a1, uint64_t a2, int a3, uint64_t *a4, uint64_t a5)
{
  unsigned char v39[32] = *MEMORY[0x263EF8340];
  if (*(unsigned char *)(a5 + 1880))
  {
    if ((a1 - 1) > 1) {
      goto LABEL_8;
    }
    unint64_t v9 = *(_DWORD **)(a5 + 1488);
    uint64_t v10 = *(_DWORD **)(a5 + 1496);
    if (v9 != v10)
    {
      while ((*v9 & 0xFFFFFFFE) != 4)
      {
        if (++v9 == v10) {
          goto LABEL_10;
        }
      }
    }
    if (v9 != v10)
    {
LABEL_8:
      ZinIrTransposeUnitInfo::ZinIrTransposeUnitInfo((uint64_t)v18, 2u, 4u, a3);
      int v33 = 21;
      long long v34 = &unk_26C345B80;
      if (SHIBYTE(v18[3]) < 0) {
        std::string::__init_copy_ctor_external(&v35, (const std::string::value_type *)v18[1], (std::string::size_type)v18[2]);
      }
      else {
        std::string v35 = *(std::string *)&v18[1];
      }
      int v36 = v19;
      memset(&v37, 0, sizeof(v37));
      std::vector<std::string>::__init_with_size[abi:ne180100]<std::string*,std::string*>(&v37, (long long *)v20, *((long long **)&v20 + 1), 0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*((void *)&v20 + 1) - v20) >> 3));
      long long v38 = *(_OWORD *)&v21[8];
      long long v34 = &unk_26C34F988;
      memset(v39, 0, 24);
      std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(v39, __p, (uint64_t)v23, (v23 - (unsigned char *)__p) >> 3);
      v18[0] = &unk_26C34F988;
      if (__p)
      {
        std::string v23 = __p;
        operator delete(__p);
      }
      ZinIrUnitInfo::~ZinIrUnitInfo(v18);
      unint64_t v15 = a4[1];
      if (v15 >= a4[2])
      {
        uint64_t v16 = std::vector<ZinReductionLayerUtils::ReductionDecomposedDesc>::__push_back_slow_path<ZinReductionLayerUtils::ReductionDecomposedDesc const&>(a4, (const ZinReductionLayerUtils::ReductionDecomposedDesc *)&v33);
      }
      else
      {
        ZinReductionLayerUtils::ReductionDecomposedDesc::ReductionDecomposedDesc((ZinReductionLayerUtils::ReductionDecomposedDesc *)a4[1], (const ZinReductionLayerUtils::ReductionDecomposedDesc *)&v33);
        uint64_t v16 = v15 + 344;
        a4[1] = v15 + 344;
      }
      a4[1] = v16;
      ZinReductionLayerUtils::HandleChannelReduction(a1, *(void *)(a2 + 24), a4, a5);
      unint64_t v14 = a4[1];
      if (v14 < a4[2]) {
        goto LABEL_22;
      }
LABEL_23:
      uint64_t v17 = std::vector<ZinReductionLayerUtils::ReductionDecomposedDesc>::__push_back_slow_path<ZinReductionLayerUtils::ReductionDecomposedDesc const&>(a4, (const ZinReductionLayerUtils::ReductionDecomposedDesc *)&v33);
      goto LABEL_24;
    }
  }
LABEL_10:
  int v11 = 1;
  if (a1 != 3)
  {
    if (a1 != 2) {
      ZinAssertImpl("Error: can not be decomposed into a supported pooling layer type for the reduction layer.");
    }
    int v11 = 2;
  }
  uint64_t v12 = *(unsigned char **)(a2 + 24);
  uint64_t v28 = 0;
  uint64_t v27 = 0;
  uint64_t v29 = 0;
  uint64_t v13 = *(void *)(a2 + 8);
  int v19 = 0;
  long long v20 = 0u;
  *(_OWORD *)int v21 = 0u;
  LODWORD(__p) = v11;
  std::string v23 = v12;
  int64x2_t v24 = vdupq_n_s64(1uLL);
  uint64_t v25 = 0x100000001;
  int v26 = 1;
  char v30 = 0;
  int v31 = v11;
  uint64_t v32 = 1065353216;
  v18[0] = &unk_26C34AB58;
  memset(&v18[1], 0, 24);
  *(void *)&v21[16] = v13;
  ZinMirPoolUtils::PoolDecomposedDesc::PoolDecomposedDesc((ZinMirPoolUtils::PoolDecomposedDesc *)&v33, (ZinIrPoolUnitInfo *)v18);
  ZinIrUnitInfo::~ZinIrUnitInfo(v18);
  unint64_t v14 = a4[1];
  if (v14 >= a4[2]) {
    goto LABEL_23;
  }
LABEL_22:
  ZinReductionLayerUtils::ReductionDecomposedDesc::ReductionDecomposedDesc((ZinReductionLayerUtils::ReductionDecomposedDesc *)a4[1], (const ZinReductionLayerUtils::ReductionDecomposedDesc *)&v33);
  uint64_t v17 = v14 + 344;
  a4[1] = v14 + 344;
LABEL_24:
  a4[1] = v17;
  ZinReductionLayerUtils::ReductionDecomposedDesc::~ReductionDecomposedDesc((ZinReductionLayerUtils::ReductionDecomposedDesc *)&v33);
}

void sub_2112A10E0(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, char a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,char a31,uint64_t a32,void *__p,uint64_t a34,int a35,__int16 a36,char a37,char a38)
{
}

void ZinReductionLayerUtils::HandleBatchReduction(int a1, uint64_t *a2, int a3, uint64_t *a4, uint64_t a5)
{
  v27[32] = *MEMORY[0x263EF8340];
  ZinIrTransposeUnitInfo::ZinIrTransposeUnitInfo((uint64_t)&v13, 2u, 0, a3);
  int v21 = 21;
  uint64_t v22 = &unk_26C345B80;
  if (SHIBYTE(v14.__r_.__value_.__r.__words[2]) < 0) {
    std::string::__init_copy_ctor_external(&v23, v14.__r_.__value_.__l.__data_, v14.__r_.__value_.__l.__size_);
  }
  else {
    std::string v23 = v14;
  }
  int v24 = v15;
  memset(&v25, 0, sizeof(v25));
  std::vector<std::string>::__init_with_size[abi:ne180100]<std::string*,std::string*>(&v25, v16, v17, 0xAAAAAAAAAAAAAAABLL * (((char *)v17 - (char *)v16) >> 3));
  long long v26 = v18;
  uint64_t v22 = &unk_26C34F988;
  memset(v27, 0, 24);
  std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(v27, __p, (uint64_t)v20, (v20 - (unsigned char *)__p) >> 3);
  uint64_t v13 = &unk_26C34F988;
  if (__p)
  {
    long long v20 = __p;
    operator delete(__p);
  }
  ZinIrUnitInfo::~ZinIrUnitInfo(&v13);
  unint64_t v9 = a4[1];
  if (v9 >= a4[2])
  {
    uint64_t v10 = std::vector<ZinReductionLayerUtils::ReductionDecomposedDesc>::__push_back_slow_path<ZinReductionLayerUtils::ReductionDecomposedDesc const&>(a4, (const ZinReductionLayerUtils::ReductionDecomposedDesc *)&v21);
  }
  else
  {
    ZinReductionLayerUtils::ReductionDecomposedDesc::ReductionDecomposedDesc((ZinReductionLayerUtils::ReductionDecomposedDesc *)a4[1], (const ZinReductionLayerUtils::ReductionDecomposedDesc *)&v21);
    uint64_t v10 = v9 + 344;
    a4[1] = v9 + 344;
  }
  a4[1] = v10;
  ZinReductionLayerUtils::HandleChannelReduction(a1, *a2, a4, a5);
  unint64_t v11 = a4[1];
  if (v11 >= a4[2])
  {
    uint64_t v12 = std::vector<ZinReductionLayerUtils::ReductionDecomposedDesc>::__push_back_slow_path<ZinReductionLayerUtils::ReductionDecomposedDesc const&>(a4, (const ZinReductionLayerUtils::ReductionDecomposedDesc *)&v21);
  }
  else
  {
    ZinReductionLayerUtils::ReductionDecomposedDesc::ReductionDecomposedDesc((ZinReductionLayerUtils::ReductionDecomposedDesc *)a4[1], (const ZinReductionLayerUtils::ReductionDecomposedDesc *)&v21);
    uint64_t v12 = v11 + 344;
    a4[1] = v11 + 344;
  }
  a4[1] = v12;
  ZinReductionLayerUtils::ReductionDecomposedDesc::~ReductionDecomposedDesc((ZinReductionLayerUtils::ReductionDecomposedDesc *)&v21);
}

void sub_2112A137C(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, char a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,char a23,uint64_t a24,void *__p,uint64_t a26,int a27,__int16 a28,char a29,char a30)
{
}

int64x2_t ZinReductionLayerUtils::ToUnityChannelWiseConvInfo@<Q0>(uint64_t a1@<X8>)
{
  *(void *)(a1 + 8) = 0;
  *(void *)(a1 + 16) = 0;
  *(_DWORD *)(a1 + std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = 0;
  *(void *)(a1 + 24) = 0;
  *(_OWORD *)(a1 + 40) = 0u;
  *(_OWORD *)(a1 + 56) = 0u;
  *(_DWORD *)(a1 + 88) = -1;
  *(void *)(a1 + 96) = -1;
  *(_DWORD *)(a1 + 104) = -1;
  *(void *)(a1 + 112) = -1;
  *(_OWORD *)(a1 + 120) = 0u;
  *(_OWORD *)(a1 + 136) = 0u;
  *(_OWORD *)(a1 + 152) = 0u;
  *(void *)(a1 + 168) = 0;
  *(_DWORD *)(a1 + 176) = 1;
  *(unsigned char *)(a1 + 180) = 0;
  *(_WORD *)(a1 + 184) = 0;
  *(_DWORD *)(a1 + 192) = -1;
  *(void *)(a1 + 200) = -1;
  *(_DWORD *)(a1 + 208) = -1;
  *(void *)(a1 + 216) = -1;
  *(void *)(a1 + 224) = 0x3F80000000000006;
  *(_DWORD *)(a1 + 2std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = 0;
  *(void *)a1 = &unk_26C34A9B8;
  *(unsigned char *)(a1 + 244) = 0;
  *(void *)&long long v2 = 0x100000001;
  *((void *)&v2 + 1) = 0x100000001;
  *(_OWORD *)(a1 + 280) = v2;
  *(void *)(a1 + 296) = 0x100000001;
  *(void *)(a1 + 312) = 0;
  *(void *)(a1 + 320) = 0;
  *(void *)(a1 + 304) = 0;
  *(_DWORD *)(a1 + 328) = 1;
  *(_DWORD *)(a1 + 240) = 1;
  *(void *)(a1 + 80) = 0x1E0000000FLL;
  int64x2_t result = vdupq_n_s64(1uLL);
  *(int64x2_t *)(a1 + 248) = result;
  *(void *)(a1 + 264) = 1;
  *(void *)(a1 + 272) = 1;
  *(void *)(a1 + 72) = 1;
  return result;
}

void ZinAneLinker::ZinAneLinker(ZinAneLinker *this, int a2)
{
  *(void *)this = 0;
  *((void *)this + 1) = 0;
  *((void *)this + 2) = 0;
  *((_DWORD *)this + 6) = a2;
  *((void *)this + 4) = 0;
}

void ZinAneLinker::~ZinAneLinker(ZinComputeMutableProgramWrapper **this)
{
  std::unique_ptr<ZinComputeMutableProgramWrapper>::reset[abi:ne180100](this + 4, 0);
  long long v2 = this;
  std::vector<std::unique_ptr<ZinComputeMutableProgramWrapper>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v2);
}

BOOL ZinAneLinker::AddObject(uint64_t a1, ZinComputeMutableProgramWrapper **a2)
{
  if (*(void *)a1 == *(void *)(a1 + 8))
  {
    unsigned int CpuSubType = ZinComputeMutableProgramWrapper::GetCpuSubType(*a2);
    if (CpuSubType >= 0xC && CpuSubType != 15)
    {
      BOOL result = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (result)
      {
        ZinAneLinker::AddObject(result, v26, v27, v28, v29, v30, v31, v32);
        return 0;
      }
      return result;
    }
  }
  else
  {
    int v4 = ZinComputeMutableProgramWrapper::GetCpuSubType(**(ZinComputeMutableProgramWrapper ***)a1);
    if (v4 != ZinComputeMutableProgramWrapper::GetCpuSubType(*a2))
    {
      BOOL result = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (result)
      {
        ZinAneLinker::AddObject(result, v6, v7, v8, v9, v10, v11, v12);
        return 0;
      }
      return result;
    }
  }
  if (ZinComputeMutableProgramWrapper::GetFileType(*a2) == 1)
  {
    unint64_t v15 = *(void *)(a1 + 16);
    uint64_t v16 = *(ZinComputeMutableProgramWrapper ***)(a1 + 8);
    if ((unint64_t)v16 >= v15)
    {
      uint64_t v33 = ((uint64_t)v16 - *(void *)a1) >> 3;
      if ((unint64_t)(v33 + 1) >> 61) {
        std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
      }
      uint64_t v34 = v15 - *(void *)a1;
      uint64_t v35 = v34 >> 2;
      if (v34 >> 2 <= (unint64_t)(v33 + 1)) {
        uint64_t v35 = v33 + 1;
      }
      if ((unint64_t)v34 >= 0x7FFFFFFFFFFFFFF8) {
        unint64_t v36 = 0x1FFFFFFFFFFFFFFFLL;
      }
      else {
        unint64_t v36 = v35;
      }
      uint64_t v51 = a1 + 16;
      if (v36) {
        std::string v37 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>(a1 + 16, v36);
      }
      else {
        std::string v37 = 0;
      }
      long long v38 = (ZinComputeMutableProgramWrapper **)&v37[8 * v33];
      long long v39 = &v37[8 * v36];
      long long v50 = v39;
      long long v40 = *a2;
      *a2 = 0;
      uint64_t *v38 = v40;
      long long v18 = v38 + 1;
      v49.i64[1] = (uint64_t)(v38 + 1);
      int v42 = *(ZinComputeMutableProgramWrapper ***)a1;
      long long v41 = *(ZinComputeMutableProgramWrapper ***)(a1 + 8);
      if (v41 == *(ZinComputeMutableProgramWrapper ***)a1)
      {
        int64x2_t v44 = vdupq_n_s64((unint64_t)v41);
      }
      else
      {
        do
        {
          long long v43 = *--v41;
          *long long v41 = 0;
          *--long long v38 = v43;
        }
        while (v41 != v42);
        int64x2_t v44 = *(int64x2_t *)a1;
        long long v18 = (void *)v49.i64[1];
        long long v39 = v50;
      }
      *(void *)a1 = v38;
      *(void *)(a1 + 8) = v18;
      int64x2_t v49 = v44;
      long long v45 = *(char **)(a1 + 16);
      *(void *)(a1 + 16) = v39;
      long long v50 = v45;
      uint64_t v48 = v44.i64[0];
      std::__split_buffer<std::unique_ptr<ZinComputeMutableProgramWrapper>>::~__split_buffer((uint64_t)&v48);
    }
    else
    {
      uint64_t v17 = *a2;
      *a2 = 0;
      *uint64_t v16 = v17;
      long long v18 = v16 + 1;
    }
    *(void *)(a1 + 8) = v18;
    if ((void *)((char *)v18 - *(void *)a1) == (void *)8)
    {
      ZinComputeMutableProgramWrapper::GetProgramRT(**(ZinComputeMutableProgramWrapper ***)a1);
      ZinAneLinker::InitializeExecutableProgram((ZinComputeMutableProgramWrapper ***)a1);
    }
    uint64_t v46 = *(ZinComputeMutableProgramWrapper **)(a1 + 32);
    int Flags = ZinComputeMutableProgramWrapper::GetFlags(v46);
    ZinComputeMutableProgramWrapper::SetFlags(v46, Flags & 0xFFFFFFDF);
    return 1;
  }
  else
  {
    BOOL result = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (result)
    {
      ZinAneLinker::AddObject(result, v19, v20, v21, v22, v23, v24, v25);
      return 0;
    }
  }
  return result;
}

void ZinAneLinker::InitializeExecutableProgram(ZinComputeMutableProgramWrapper ***this)
{
  int32_t CpuSubType = ZinComputeMutableProgramWrapper::GetCpuSubType(**this);
  v3.magic = ZinComputeMutableProgramWrapper::GetMagicNumber(**this);
  v3.cputype = 128;
  v3.cpusubtype = CpuSubType;
  *(_OWORD *)&v3.filetype = xmmword_211F00560;
  v3.reserved = 0;
  operator new();
}

void sub_2112A182C(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::unique_ptr<ZinComputeMutableProgramWrapper>::reset[abi:ne180100]((ZinComputeMutableProgramWrapper **)va, 0);
  _Unwind_Resume(a1);
}

uint64_t ZinAneLinker::CheckSymbol(ZinAneLinker *this)
{
  uint64_t v16 = *MEMORY[0x263EF8340];
  long long v2 = (ZinComputeMutableProgramWrapper *)*((void *)this + 4);
  if (v2)
  {
    if (ZinComputeMutableProgramWrapper::GetSymbolCount(v2)
      && ZinComputeMutableProgramWrapper::GetSymbolCount(*((ZinComputeMutableProgramWrapper **)this + 4)))
    {
      unint64_t v3 = 0;
      int v4 = &_os_log_internal;
      char v5 = 1;
      do
      {
        uint64_t Symbol = ZinComputeMutableProgramWrapper::GetSymbol(*((ZinComputeMutableProgramWrapper **)this + 4), v3);
        if ((*(unsigned char *)(*(void *)Symbol + 4) & 0xEE) == 0)
        {
          uint64_t v7 = Symbol;
          if (os_log_type_enabled(v4, OS_LOG_TYPE_ERROR))
          {
            uint64_t v8 = *(void *)(v7 + 8);
            *(_DWORD *)long long buf = 136315650;
            uint64_t v11 = v8;
            __int16 v12 = 2080;
            uint64_t v13 = "/Library/Caches/com.apple.xbs/Sources/ANECompiler/libs/inference/compiler/ZinLinker/src/ZinLinker.cpp";
            __int16 v14 = 1024;
            int v15 = 128;
            _os_log_error_impl(&dword_210C72000, v4, OS_LOG_TYPE_ERROR, "error: undefined symbol %s, file %s, line %d\n", buf, 0x1Cu);
          }
          char v5 = 0;
        }
        ++v3;
      }
      while (v3 < ZinComputeMutableProgramWrapper::GetSymbolCount(*((ZinComputeMutableProgramWrapper **)this + 4)));
    }
    else
    {
      char v5 = 1;
    }
  }
  else
  {
    char v5 = 0;
  }
  return v5 & 1;
}

uint64_t ZinAneLinker::AssignVirtualAddress(ZinAneLinker *this)
{
  char v56[4] = *MEMORY[0x263EF8340];
  if (!*((void *)this + 4)) {
    return 0;
  }
  std::string::basic_string[abi:ne180100]<0>(__p, "__PAGEZERO");
  uint64_t v54 = 0;
  std::string::basic_string[abi:ne180100]<0>(v55, "__L2");
  v55[3] = 0x10000000;
  std::string::basic_string[abi:ne180100]<0>(v56, "__L3");
  v56[3] = 0x20000000;
  std::map<std::string,unsigned long long>::map[abi:ne180100]((uint64_t)v50, __p, 3);
  for (uint64_t i = 0; i != -12; i -= 4)
  {
    if (SHIBYTE(v56[i + 2]) < 0) {
      operator delete((void *)v56[i]);
    }
  }
  unint64_t v3 = 0;
  uint64_t v4 = 805306368;
  while (v3 < ZinComputeMutableProgramWrapper::GetSegmentCount(*((ZinComputeMutableProgramWrapper **)this + 4)))
  {
    Segment = (void *)ZinComputeMutableProgramWrapper::GetSegment(*((ZinComputeMutableProgramWrapper **)this + 4), v3);
    std::string::basic_string[abi:ne180100]<0>(__p, "__PAGEZERO");
    int v6 = (char)v53;
    if ((v53 & 0x80u) == 0) {
      size_t v7 = v53;
    }
    else {
      size_t v7 = (size_t)__p[1];
    }
    if (v7 == strlen((const char *)(*Segment + 8)))
    {
      if ((v53 & 0x80u) == 0) {
        uint64_t v8 = __p;
      }
      else {
        uint64_t v8 = (void **)__p[0];
      }
      BOOL v9 = memcmp(v8, (const void *)(*Segment + 8), v7) == 0;
      if ((v6 & 0x80000000) == 0)
      {
LABEL_18:
        if (v9) {
          goto LABEL_46;
        }
        goto LABEL_21;
      }
    }
    else
    {
      BOOL v9 = 0;
      if (((char)v53 & 0x80000000) == 0) {
        goto LABEL_18;
      }
    }
    operator delete(__p[0]);
    if (v9) {
      goto LABEL_46;
    }
LABEL_21:
    std::string::basic_string[abi:ne180100]<0>(__p, (char *)(*Segment + 8));
    uint64_t v10 = v4;
    if (std::__tree<std::__value_type<std::string,ZinIOBarInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIOBarInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIOBarInfo>>>::__count_unique<std::string>((uint64_t)v50, __p))
    {
      uint64_t v51 = __p;
      uint64_t v10 = std::__tree<std::__value_type<std::string,ZinIrOpLayer *>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrOpLayer *>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrOpLayer *>>>::__emplace_unique_key_args<std::string,std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>(v50, __p, (uint64_t)&std::piecewise_construct, (long long **)&v51)[7];
    }
    uint64_t v11 = *Segment;
    *(void *)(v11 + 24) = v10;
    if (*(_DWORD *)(v11 + 64))
    {
      if (*(void *)Segment[1])
      {
        uint64_t v12 = 0;
        unint64_t v13 = 0;
        while (1)
        {
          __int16 v14 = *(uint64_t **)(Segment[1] + 8 * v12);
          if (!v14) {
            break;
          }
          uint64_t v15 = *v14;
          unsigned int v16 = *(unsigned __int8 *)(*v14 + 64);
          BOOL v17 = v16 > 0x36;
          uint64_t v18 = (1 << v16) & 0x40006000000000;
          BOOL v19 = v17 || v18 == 0;
          if (!v19 && !*(void *)(v15 + 40)) {
            *(void *)(v15 + 40) = *((unsigned int *)this + 6);
          }
          uint64_t v20 = ZinAlignPower2(v13, 1 << *(_DWORD *)(v15 + 52));
          uint64_t v21 = *v14;
          *(void *)(v21 + std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = v20 + v10;
          unint64_t v13 = *(void *)(v21 + 40) + v20;
          if (++v12 >= (unint64_t)*(unsigned int *)(*Segment + 64))
          {
            if (v13 <= 1) {
              unint64_t v13 = 1;
            }
            uint64_t v22 = ZinAlignPower2(v13, *((unsigned int *)this + 6));
            int v23 = 0;
            *(void *)(*Segment + std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = v22;
            v4 += v22;
            goto LABEL_43;
          }
        }
        if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
          ZinAneLinker::AssignVirtualAddress(&v46, v47);
        }
      }
      else if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR))
      {
        ZinAneLinker::AssignVirtualAddress(&buf, v49);
      }
      int v23 = 1;
    }
    else
    {
      uint64_t v24 = *((unsigned int *)this + 6);
      *(void *)(v11 + std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = v24;
      v4 += v24;
      int v23 = 4;
    }
LABEL_43:
    if ((char)v53 < 0) {
      operator delete(__p[0]);
    }
    if ((v23 | 4) != 4) {
      goto LABEL_60;
    }
LABEL_46:
    ++v3;
  }
  for (unint64_t j = 0; ; ++j)
  {
    if (j >= ZinComputeMutableProgramWrapper::GetSymbolCount(*((ZinComputeMutableProgramWrapper **)this + 4)))
    {
      uint64_t v28 = 1;
      goto LABEL_61;
    }
    uint64_t Symbol = (void *)ZinComputeMutableProgramWrapper::GetSymbol(*((ZinComputeMutableProgramWrapper **)this + 4), j);
    if (!Symbol) {
      break;
    }
    if ((~*(unsigned __int8 *)(*Symbol + 4) & 0xE) == 0)
    {
      uint64_t v27 = Symbol[4];
      if (!v27)
      {
        BOOL v37 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
        if (v37) {
          ZinAneLinker::AssignVirtualAddress(v37, v38, v39, v40, v41, v42, v43, v44);
        }
        goto LABEL_60;
      }
      *(void *)(*Symbol + 8) += *(void *)(*(void *)v27 + 32);
    }
  }
  BOOL v29 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
  if (v29) {
    ZinAneLinker::AssignVirtualAddress(v29, v30, v31, v32, v33, v34, v35, v36);
  }
LABEL_60:
  uint64_t v28 = 0;
LABEL_61:
  std::__tree<std::__value_type<std::string,SpatialSplitMode>,std::__map_value_compare<std::string,std::__value_type<std::string,SpatialSplitMode>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,SpatialSplitMode>>>::destroy((uint64_t)v50, (char *)v50[1]);
  return v28;
}

void sub_2112A1DC4(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, char a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, void *__p, uint64_t a20,int a21,__int16 a22,char a23,char a24)
{
  uint64_t v26 = 0;
  while (1)
  {
    if (*(char *)(v24 + v26 + 87) < 0) {
      operator delete(*(void **)(v24 + v26 + 64));
    }
    v26 -= 32;
    if (v26 == -96) {
      _Unwind_Resume(exception_object);
    }
  }
}

void ZinAneLinker::Link(unsigned __int8 **this@<X0>, unsigned __int8 **a2@<X8>)
{
  if (ZinComputeMutableProgramWrapper::AddObjectsForCoalescing(this[4], (ZinComputeMutableProgramWrapper ***)this))
  {
    BOOL v4 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (v4) {
      ZinAneLinker::Link(v4, v5, v6, v7, v8, v9, v10, v11);
    }
LABEL_15:
    uint64_t v20 = 0;
    goto LABEL_16;
  }
  if (ZinComputeMutableProgramWrapper::Link((ZinComputeMutableProgramWrapper *)this[4]))
  {
    BOOL v12 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (v12) {
      ZinAneLinker::Link(v12, v13, v14, v15, v16, v17, v18, v19);
    }
    goto LABEL_15;
  }
  if ((ZinAneLinker::CheckSymbol((ZinAneLinker *)this) & 1) == 0)
  {
    BOOL v21 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (v21) {
      ZinAneLinker::Link(v21, v22, v23, v24, v25, v26, v27, v28);
    }
    goto LABEL_15;
  }
  if ((ZinAneLinker::AssignVirtualAddress((ZinAneLinker *)this) & 1) == 0)
  {
    BOOL v29 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (v29) {
      ZinAneLinker::Link(v29, v30, v31, v32, v33, v34, v35, v36);
    }
    goto LABEL_15;
  }
  uint64_t v20 = this[4];
  if (!v20) {
    ZinAssertImpl("Invalid compute program wrapper");
  }
  this[4] = 0;
LABEL_16:
  *a2 = v20;
}

void ZinAneLinker::GetMutableProgramInUnlinkedForm(ZinAneLinker *this@<X0>, void *a2@<X8>)
{
  if (ZinComputeMutableProgramWrapper::AddObjectsForCoalescing(*((unsigned __int8 **)this + 4), (ZinComputeMutableProgramWrapper ***)this))
  {
    BOOL v4 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (v4) {
      ZinAneLinker::Link(v4, v5, v6, v7, v8, v9, v10, v11);
    }
    uint64_t v12 = 0;
  }
  else
  {
    uint64_t v13 = (ZinComputeMutableProgramWrapper *)*((void *)this + 4);
    if (!v13 || (ZinComputeMutableProgramWrapper::SetFileType(v13, 1), (uint64_t v12 = *((void *)this + 4)) == 0)) {
      ZinAssertImpl("Invalid compute program wrapper");
    }
    *((void *)this + 4) = 0;
  }
  *a2 = v12;
}

void std::vector<std::unique_ptr<ZinComputeMutableProgramWrapper>>::__destroy_vector::operator()[abi:ne180100](void ***a1)
{
  uint64_t v1 = *a1;
  long long v2 = (ZinComputeMutableProgramWrapper **)**a1;
  if (v2)
  {
    BOOL v4 = (ZinComputeMutableProgramWrapper **)v1[1];
    uint64_t v5 = **a1;
    if (v4 != v2)
    {
      do
        std::unique_ptr<ZinComputeMutableProgramWrapper>::reset[abi:ne180100](--v4, 0);
      while (v4 != v2);
      uint64_t v5 = **a1;
    }
    v1[1] = v2;
    operator delete(v5);
  }
}

uint64_t std::__split_buffer<std::unique_ptr<ZinComputeMutableProgramWrapper>>::~__split_buffer(uint64_t a1)
{
  uint64_t v3 = *(void *)(a1 + 8);
  for (uint64_t i = *(void *)(a1 + 16); i != v3; uint64_t i = *(void *)(a1 + 16))
  {
    *(void *)(a1 + 16) = i - 8;
    std::unique_ptr<ZinComputeMutableProgramWrapper>::reset[abi:ne180100]((ZinComputeMutableProgramWrapper **)(i - 8), 0);
  }
  if (*(void *)a1) {
    operator delete(*(void **)a1);
  }
  return a1;
}

uint64_t std::map<std::string,unsigned long long>::map[abi:ne180100](uint64_t a1, void **a2, uint64_t a3)
{
  *(void *)(a1 + 8) = 0;
  uint64_t v4 = a1 + 8;
  *(void *)(a1 + 16) = 0;
  *(void *)a1 = a1 + 8;
  if (a3)
  {
    uint64_t v6 = 32 * a3;
    do
    {
      std::__tree<std::__value_type<std::string,ZinIrOpLayer *>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrOpLayer *>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrOpLayer *>>>::__emplace_hint_unique_key_args<std::string,std::pair<std::string const,ZinIrOpLayer *> const&>((uint64_t **)a1, v4, a2, (uint64_t)a2);
      a2 += 4;
      v6 -= 32;
    }
    while (v6);
  }
  return a1;
}

void sub_2112A2128(_Unwind_Exception *a1)
{
  std::__tree<std::__value_type<std::string,SpatialSplitMode>,std::__map_value_compare<std::string,std::__value_type<std::string,SpatialSplitMode>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,SpatialSplitMode>>>::destroy(v1, *(char **)(v1 + 8));
  _Unwind_Resume(a1);
}

void ZinAneLinker::AddObject(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "Expect MH_OBJECT filetype from each object being added\n", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "error: Unsupported CPU subtype\n", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "Expect consistent CPU subtype from each object being added\n", a5, a6, a7, a8, 0);
}

void ZinAneLinker::InitializeExecutableProgram(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void ZinAneLinker::AssignVirtualAddress(uint8_t *buf, unsigned char *a2)
{
  *uint8_t buf = 0;
  *a2 = 0;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "Expect has least 1 section inside a segment\n", buf, 2u);
}

{
  *uint8_t buf = 0;
  *a2 = 0;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "Expect a valid section on an index in range\n", buf, 2u);
}

void ZinAneLinker::AssignVirtualAddress(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "Expect a valid owning section\n", a5, a6, a7, a8, 0);
}

void ZinAneLinker::Link(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "error: there are still undef symbol(s) in the coalesced symbol table\n", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "error: Fail to call ZinComputeMutableProgramLink(.)\n", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "error: Fail to call ZinComputeMutableProgramAddObjects(.)\n", a5, a6, a7, a8, 0);
}

__CFDictionary *ZinCreateCropResizeUnit(const ZinIrCropResizeUnitInfo *a1)
{
  Unit = ZinCreateUnit(a1);
  TextureCommonUnit = ZinCreateTextureCommonUnit(a1);
  TextureUnitSamplingGridInfo = ZinCreateTextureUnitSamplingGridInfo((uint64_t)a1 + 160);
  CFDictionaryAddValue(TextureCommonUnit, @"SamplingGridInfo", TextureUnitSamplingGridInfo);
  CFRelease(TextureUnitSamplingGridInfo);
  uint64_t v5 = ZinIrCropResizeBoxModeToCFString(*((_DWORD *)a1 + 39));
  CFDictionaryAddValue(TextureCommonUnit, @"CoordinateMode", v5);
  CFAllocatorRef v6 = (const __CFAllocator *)*MEMORY[0x263EFFB08];
  if ((*((_DWORD *)a1 + 39) & 0xFFFFFFF4) != 0)
  {
    CFNumberRef v7 = CFNumberCreate((CFAllocatorRef)*MEMORY[0x263EFFB08], kCFNumberSInt32Type, (char *)a1 + 192);
    CFDictionaryAddValue(TextureCommonUnit, @"CropWidth", v7);
    CFRelease(v7);
    CFNumberRef v8 = CFNumberCreate(v6, kCFNumberSInt32Type, (char *)a1 + 196);
    CFDictionaryAddValue(TextureCommonUnit, @"CropHeight", v8);
    CFRelease(v8);
  }
  CFNumberRef v9 = CFNumberCreate(v6, kCFNumberSInt32Type, (char *)a1 + 184);
  CFDictionaryAddValue(TextureCommonUnit, @"OutputWidth", v9);
  CFRelease(v9);
  CFNumberRef v10 = CFNumberCreate(v6, kCFNumberSInt32Type, (char *)a1 + 188);
  CFDictionaryAddValue(TextureCommonUnit, @"OutputHeight", v10);
  CFRelease(v10);
  CFDictionaryAddValue(Unit, @"Params", TextureCommonUnit);
  CFRelease(TextureCommonUnit);
  return Unit;
}

uint64_t ZinIrOpt::CollapseBroadcast(void *a1, uint64_t a2)
{
  uint64_t v25[3] = *MEMORY[0x263EF8340];
  std::string::basic_string[abi:ne180100]<0>(v18, "bcast1");
  v19[0] = &unk_26C330C90;
  void v19[3] = v19;
  int v8 = 1;
  std::unordered_set<Attribute>::unordered_set((uint64_t)&v20, &v8, 1);
  std::string::basic_string[abi:ne180100]<0>(v21, "bcast");
  v22[0] = &unk_26C330C90;
  v22[3] = v22;
  int v7 = 2;
  std::unordered_set<Attribute>::unordered_set((uint64_t)v23, &v7, 1);
  CFNumberRef v9 = 0;
  uint64_t v10 = 0;
  uint64_t v11 = 0;
  uint64_t v14 = &v9;
  char v15 = 0;
  CFNumberRef v9 = (char *)operator new(0xC0uLL);
  uint64_t v10 = (uint64_t)v9;
  uint64_t v11 = v9 + 192;
  uint64_t v10 = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<ZinLinearPattern::AtomItemDesc>,ZinLinearPattern::AtomItemDesc const*,ZinLinearPattern::AtomItemDesc const*,ZinLinearPattern::AtomItemDesc*>((uint64_t)&v11, (uint64_t)v18, (uint64_t)v24, (uint64_t)v9);
  void v17[3] = 0;
  ZinLinearPattern::ZinLinearPattern(v24, &v9, a2, 0, v17, 0);
  std::allocate_shared[abi:ne180100]<ZinLinearPattern,std::allocator<ZinLinearPattern>,ZinLinearPattern,void>((uint64_t)v24, &v12);
  long long v13 = v12;
  long long v12 = 0uLL;
  v24[0] = &unk_26C349BA8;
  uint64_t v14 = (char **)v25;
  std::vector<ZinLinearPattern::AtomItemDesc>::__destroy_vector::operator()[abi:ne180100]((void ***)&v14);
  ZinPattern::~ZinPattern((ZinPattern *)v24);
  std::__function::__value_func<BOOL ()(ZinIrOpLayerGraph const*,ZinIrParameters const&,ZinPattern const*)>::~__value_func[abi:ne180100](v17);
  uint64_t v14 = &v9;
  std::vector<ZinLinearPattern::AtomItemDesc>::__destroy_vector::operator()[abi:ne180100]((void ***)&v14);
  for (uint64_t i = 0; i != -24; i -= 12)
  {
    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&v23[i * 8]);
    std::__function::__value_func<MatchStatus ()(MatchParams const&)>::~__value_func[abi:ne180100](&v22[i]);
    if (SHIBYTE(v21[i + 2]) < 0) {
      operator delete((void *)v21[i]);
    }
  }
  v16[0] = &unk_26C330CE8;
  v16[1] = &v13;
  void v16[3] = v16;
  uint64_t v5 = ZinIrControlFlowGraph::TraverseForward(a1, (uint64_t)v16, 1);
  std::__function::__value_func<ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::~__value_func[abi:ne180100](v16);
  if (*((void *)&v13 + 1)) {
    std::__shared_weak_count::__release_shared[abi:ne180100](*((std::__shared_weak_count **)&v13 + 1));
  }
  return v5;
}

void sub_2112A284C(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, std::__shared_weak_count *a9, uint64_t a10, uint64_t a11, uint64_t a12, ...)
{
  va_start(va, a12);
  std::__function::__value_func<ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::~__value_func[abi:ne180100](va);
  if (a9) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a9);
  }
  _Unwind_Resume(a1);
}

void std::__function::__func<ZinIrOpt::CollapseBroadcast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0,std::allocator<ZinIrOpt::CollapseBroadcast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0>,MatchStatus ()(MatchParams const&)>::~__func()
{
}

void *std::__function::__func<ZinIrOpt::CollapseBroadcast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0,std::allocator<ZinIrOpt::CollapseBroadcast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0>,MatchStatus ()(MatchParams const&)>::__clone()
{
  BOOL result = operator new(0x10uLL);
  void *result = &unk_26C330C90;
  return result;
}

void std::__function::__func<ZinIrOpt::CollapseBroadcast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0,std::allocator<ZinIrOpt::CollapseBroadcast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0>,MatchStatus ()(MatchParams const&)>::__clone(uint64_t a1, void *a2)
{
  *a2 = &unk_26C330C90;
}

uint64_t std::__function::__func<ZinIrOpt::CollapseBroadcast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0,std::allocator<ZinIrOpt::CollapseBroadcast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0>,MatchStatus ()(MatchParams const&)>::operator()(uint64_t a1, uint64_t a2)
{
  return (*(_DWORD *)(*(void *)(*(void *)(a2 + 8) + 64) + 8) == 18) | 0x100u;
}

uint64_t std::__function::__func<ZinIrOpt::CollapseBroadcast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0,std::allocator<ZinIrOpt::CollapseBroadcast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0>,MatchStatus ()(MatchParams const&)>::target(uint64_t a1, uint64_t a2)
{
  {
    return a1 + 8;
  }
  else
  {
    return 0;
  }
}

void *std::__function::__func<ZinIrOpt::CollapseBroadcast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0,std::allocator<ZinIrOpt::CollapseBroadcast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0>,MatchStatus ()(MatchParams const&)>::target_type()
{
}

void std::__function::__func<ZinIrOpt::CollapseBroadcast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1,std::allocator<ZinIrOpt::CollapseBroadcast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::~__func()
{
}

void *std::__function::__func<ZinIrOpt::CollapseBroadcast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1,std::allocator<ZinIrOpt::CollapseBroadcast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::__clone(uint64_t a1)
{
  BOOL result = operator new(0x10uLL);
  uint64_t v3 = *(void *)(a1 + 8);
  void *result = &unk_26C330CE8;
  result[1] = v3;
  return result;
}

uint64_t std::__function::__func<ZinIrOpt::CollapseBroadcast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1,std::allocator<ZinIrOpt::CollapseBroadcast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::__clone(uint64_t result, void *a2)
{
  uint64_t v2 = *(void *)(result + 8);
  *a2 = &unk_26C330CE8;
  a2[1] = v2;
  return result;
}

uint64_t std::__function::__func<ZinIrOpt::CollapseBroadcast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1,std::allocator<ZinIrOpt::CollapseBroadcast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::operator()(uint64_t a1, void *a2, void *a3)
{
  uint64_t v45 = *MEMORY[0x263EF8340];
  uint64_t result = (*(uint64_t (**)(void, void, void))(***(void ***)(a1 + 8) + 8))(**(void **)(a1 + 8), *a2, *a3);
  if (result)
  {
    uint64_t v5 = *(uint64_t **)(a1 + 8);
    uint64_t v6 = *v5;
    std::string::basic_string[abi:ne180100]<0>(__p, "bcast1");
    ZinPattern::GetMatch(v6, (unsigned __int8 *)__p, &v35);
    if (SBYTE7(v38) < 0) {
      operator delete(__p[0]);
    }
    uint64_t v7 = *v5;
    std::string::basic_string[abi:ne180100]<0>(__p, "bcast");
    ZinPattern::GetMatch(v7, (unsigned __int8 *)__p, &v33);
    if (SBYTE7(v38) < 0) {
      operator delete(__p[0]);
    }
    if (v33 != v34)
    {
      std::vector<ZinGOCLayer const*>::__insert_with_size[abi:ne180100]<std::__wrap_iter<ZinGOCLayer const**>,std::__wrap_iter<ZinGOCLayer const**>>((uint64_t)&v35, (uint64_t)__dst, (char *)v33, v34, (v34 - (unsigned char *)v33) >> 3);
      uint64_t v8 = *(void *)v35;
      if (*(char *)(*(void *)v35 + 47) >= 0) {
        size_t v9 = *(unsigned __int8 *)(*(void *)v35 + 47);
      }
      else {
        size_t v9 = *(void *)(*(void *)v35 + 32);
      }
      uint64_t v10 = v26;
      std::string::basic_string[abi:ne180100]((uint64_t)v26, v9 + 1);
      if (SBYTE7(v27) < 0) {
        uint64_t v10 = (void **)v26[0];
      }
      if (v9)
      {
        if (*(char *)(v8 + 47) >= 0) {
          uint64_t v11 = (const void *)(v8 + 24);
        }
        else {
          uint64_t v11 = *(const void **)(v8 + 24);
        }
        memmove(v10, v11, v9);
      }
      *(_WORD *)((char *)v10 + v9) = 95;
      std::string::basic_string[abi:ne180100]<0>(&v29, "clps_bcast");
      long long v12 = std::string::append(&v29, "_xfm", 4uLL);
      long long v13 = *(_OWORD *)&v12->__r_.__value_.__l.__data_;
      uint64_t v31 = (char *)v12->__r_.__value_.__r.__words[2];
      *(_OWORD *)uint64_t v30 = v13;
      v12->__r_.__value_.__l.__size_ = 0;
      v12->__r_.__value_.__r.__words[2] = 0;
      v12->__r_.__value_.__r.__words[0] = 0;
      if (SHIBYTE(v31) >= 0) {
        uint64_t v14 = v30;
      }
      else {
        uint64_t v14 = (void **)v30[0];
      }
      if (SHIBYTE(v31) >= 0) {
        std::string::size_type v15 = HIBYTE(v31);
      }
      else {
        std::string::size_type v15 = (std::string::size_type)v30[1];
      }
      uint64_t v16 = std::string::append((std::string *)v26, (const std::string::value_type *)v14, v15);
      long long v17 = *(_OWORD *)&v16->__r_.__value_.__l.__data_;
      *(void *)&long long v38 = *((void *)&v16->__r_.__value_.__l + 2);
      *(_OWORD *)long long __p = v17;
      v16->__r_.__value_.__l.__size_ = 0;
      v16->__r_.__value_.__r.__words[2] = 0;
      v16->__r_.__value_.__r.__words[0] = 0;
      ZinObjectNameFactory::ZinObjectNameFactory(&v32, __p);
      if (SBYTE7(v38) < 0) {
        operator delete(__p[0]);
      }
      if (SHIBYTE(v31) < 0) {
        operator delete(v30[0]);
      }
      if (SHIBYTE(v29.__r_.__value_.__r.__words[2]) < 0) {
        operator delete(v29.__r_.__value_.__l.__data_);
      }
      if (SBYTE7(v27) < 0) {
        operator delete(v26[0]);
      }
      *(_OWORD *)uint64_t v26 = 0u;
      long long v27 = 0u;
      int v28 = 1065353216;
      uint64_t v18 = (char *)v35;
      uint64_t v19 = (char *)__dst;
      if (v35 != __dst)
      {
        do
        {
          for (uint64_t i = *(int **)(*(void *)(*(void *)v18 + 64) + 32); i; uint64_t i = *(int **)i)
            std::__hash_table<std::__hash_value_type<ZinIrDimension,unsigned long>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,unsigned long>>>::__emplace_unique_key_args<ZinIrDimension,std::pair<ZinIrDimension const,unsigned long> const&>((uint64_t)v26, i + 4, (_OWORD *)i + 1);
          v18 += 8;
        }
        while (v18 != v19);
        uint64_t v18 = (char *)v35;
      }
      (*(void (**)(void **__return_ptr))(**(void **)v18 + 80))(__p);
      BOOL v21 = operator new(0x78uLL);
      v30[1] = v21 + 30;
      uint64_t v31 = (char *)(v21 + 30);
      v21[28] = v44;
      long long v22 = v43;
      long long v23 = v41;
      *((_OWORD *)v21 + 5) = v42;
      *((_OWORD *)v21 + 6) = v22;
      long long v24 = v38;
      *(_OWORD *)BOOL v21 = *(_OWORD *)__p;
      *((_OWORD *)v21 + 1) = v24;
      long long v25 = v40;
      *((_OWORD *)v21 + 2) = v39;
      *((_OWORD *)v21 + 3) = v25;
      *((_OWORD *)v21 + 4) = v23;
      v30[0] = v21;
      (*(void (**)(void, void, void))(**((void **)__dst - 1) + 32))(*((void *)__dst - 1), 0, 0);
      ZinBuilder::CreateBroadcast();
    }
    if (v33)
    {
      uint64_t v34 = (char *)v33;
      operator delete(v33);
    }
    if (v35)
    {
      __dst = v35;
      operator delete(v35);
    }
    return 0;
  }
  return result;
}

void sub_2112A2F50(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, int a11, __int16 a12, char a13, char a14, uint64_t a15, uint64_t a16, void *a17, uint64_t a18, int a19, __int16 a20,char a21,char a22,void *a23,uint64_t a24,int a25,__int16 a26,char a27,char a28,void *a29,void *__p,uint64_t a31,int a32,__int16 a33,char a34,char a35,uint64_t a36,void *a37,uint64_t a38,uint64_t a39,void *a40,uint64_t a41,uint64_t a42,void *a43,void *a44,uint64_t a45)
{
  a29 = &unk_26C34DA98;
  if (a35 < 0) {
    operator delete(__p);
  }
  if (a37)
  {
    a38 = (uint64_t)a37;
    operator delete(a37);
  }
  if (a40)
  {
    a41 = (uint64_t)a40;
    operator delete(a40);
  }
  _Unwind_Resume(a1);
}

uint64_t std::__function::__func<ZinIrOpt::CollapseBroadcast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1,std::allocator<ZinIrOpt::CollapseBroadcast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::target(uint64_t a1, uint64_t a2)
{
  {
    return a1 + 8;
  }
  else
  {
    return 0;
  }
}

void *std::__function::__func<ZinIrOpt::CollapseBroadcast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1,std::allocator<ZinIrOpt::CollapseBroadcast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::target_type()
{
}

void std::__function::__func<ZinIrOpt::CollapseBroadcast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1,std::allocator<ZinIrOpt::CollapseBroadcast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::operator()()
{
  *(_WORD *)uint64_t v0 = 0;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "Error: Unable to collpase broadcast layers.\n", v0, 2u);
}

void ZinConcatLayerUtils::CreateCopyForConcat(uint64_t a1@<X0>, uint64_t a2@<X1>, uint64_t a3@<X2>, uint64_t a4@<X3>, int a5@<W4>, void *a6@<X8>)
{
  uint64_t v36 = 0;
  BOOL v37 = 0;
  uint64_t v38 = 0;
  std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(&v36, *(const void **)a3, *(void *)(a3 + 8), (uint64_t)(*(void *)(a3 + 8) - *(void *)a3) >> 3);
  unint64_t v12 = (uint64_t)(*(void *)(a3 + 8) - *(void *)a3) >> 3;
  long long __p = 0;
  std::vector<ZinIrOpLayer *>::vector(a6, v12, &__p);
  long long v13 = v37;
  if (v37 == v36) {
    goto LABEL_40;
  }
  unint64_t v14 = 0;
  long long v13 = v36;
  do
  {
    std::string::size_type v15 = (ZinIrOpLayer *)v13[v14];
    long long __p = 0;
    uint64_t v34 = 0;
    uint64_t v35 = 0;
    int IsNoOp = ZinIrOpLayer::IsNoOp(v15, (uint64_t *)&__p);
    if (__p)
    {
      uint64_t v34 = __p;
      operator delete(__p);
    }
    if (IsNoOp)
    {
      long long v17 = (void *)v36[v14];
      int v18 = *(_DWORD *)(v17[8] + 8);
      if (v18 == 29)
      {
        if (ZinIrBatchUtils::LayersHaveBatches(&v36)
          && *(void *)((*(uint64_t (**)(void, void, void))(*(void *)v36[v14] + 32))(v36[v14], 0, 0)+ 48) == 1&& *(_DWORD *)(*(void *)(a4 + 64) + 12) != 5)
        {
          goto LABEL_26;
        }
LABEL_16:
        uint64_t v21 = v36[v14];
        uint64_t v22 = *(unsigned int *)((*(uint64_t (**)(uint64_t, void, void))(*(void *)v21 + 32))(v21, 0, 0)+ 88);
        uint64_t v32 = 0;
        Copyuint64_t Layer = (ZinIrOpLayer *)ZinBuilder::CreateCopyLayer(a1, v21, a2, v22, (uint64_t *)&v32);
        long long v24 = v32;
        uint64_t v32 = 0;
        if (v24) {
          std::default_delete<ZinIrTensor::MirInfo>::operator()[abi:ne180100]((uint64_t)&v32, v24);
        }
        long long __p = 0;
        uint64_t v34 = 0;
        uint64_t v35 = 0;
        char v25 = ZinIrOpLayer::IsNoOp(CopyLayer, (uint64_t *)&__p);
        if (a5 == 1) {
          char v26 = 1;
        }
        else {
          char v26 = v25;
        }
        if (__p)
        {
          uint64_t v34 = __p;
          operator delete(__p);
        }
        if ((v26 & 1) == 0) {
          operator new();
        }
        *(void *)(*a6 + 8 * v14) = CopyLayer;
        v36[v14] = CopyLayer;
        goto LABEL_26;
      }
      if (v18 != 7) {
        goto LABEL_16;
      }
      uint64_t v19 = v17[14];
      uint64_t v20 = v17[15];
      while (v19 != v20)
      {
        if (*(void *)v19 != a4 && *(_DWORD *)(*(void *)(*(void *)v19 + 64) + 8) == 7) {
          goto LABEL_16;
        }
        v19 += 8;
      }
    }
LABEL_26:
    ++v14;
    long long v13 = v36;
    long long v27 = v37;
  }
  while (v14 < v37 - v36);
  if (v36 != v37)
  {
    while (1)
    {
      uint64_t v28 = *(void *)((*(uint64_t (**)(void, void, void))(*(void *)*v13 + 32))(*v13, 0, 0)
                      + 104);
      if (v28)
      {
        if (*(_DWORD *)(v28 + 96) == 2) {
          break;
        }
      }
      if (++v13 == v27)
      {
        int v29 = 0;
        goto LABEL_33;
      }
    }
    int v29 = 1;
LABEL_33:
    uint64_t v30 = v36;
    long long v13 = v37;
    if (v36 != v37)
    {
      while (1)
      {
        uint64_t v31 = *(void *)((*(uint64_t (**)(void, void, void))(*(void *)*v30 + 32))(*v30, 0, 0)
                        + 104);
        if (v31)
        {
          if (*(_DWORD *)(v31 + 96) == 1) {
            break;
          }
        }
        if (++v30 == v13) {
          goto LABEL_39;
        }
      }
      if (v29) {
        ZinAssertImpl("ANEC Internal Error: Sources have incompatible allocation hint.");
      }
LABEL_39:
      long long v13 = v36;
    }
  }
LABEL_40:
  if (v13)
  {
    BOOL v37 = v13;
    operator delete(v13);
  }
}

void sub_2112A3550(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, void *a13, uint64_t a14, int a15, __int16 a16, char a17, char a18, void *__p, uint64_t a20)
{
  uint64_t v22 = *(void **)v20;
  if (*(void *)v20)
  {
    *(void *)(v20 + 8) = v22;
    operator delete(v22);
  }
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

void ZinConcatLayerUtils::ComputeConcatViewAndStep(int a1@<W0>, void **a2@<X1>, uint64_t a3@<X3>, void *a4@<X8>)
{
  *a4 = 0;
  a4[1] = 0;
  a4[2] = 0;
  uint64_t v8 = (*(uint64_t (**)(void, void, void))(*(void *)**a2 + 32))(**a2, 0, 0);
  long long v9 = *(_OWORD *)(v8 + 48);
  long long v10 = *(_OWORD *)(v8 + 64);
  *(void *)(a3 + std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(void *)(v8 + 80);
  *(_OWORD *)a3 = v9;
  *(_OWORD *)(a3 + 16) = v10;
  uint64_t v145 = a3;
  switch(a1)
  {
    case 1:
      uint64_t v11 = (char *)a2[1] - (char *)*a2;
      unint64_t v12 = v11 >> 3;
      if (v11)
      {
        long long v13 = 0;
        unint64_t v14 = 0;
        std::string::size_type v15 = a4 + 2;
        int64x2_t v146 = vdupq_n_s64(1uLL);
        do
        {
          if ((unint64_t)v13 >= *v15)
          {
            unint64_t v16 = 0xCCCCCCCCCCCCCCCDLL * ((uint64_t)&v13[-*a4] >> 4);
            unint64_t v17 = v16 + 1;
            if (v16 + 1 > 0x333333333333333) {
              std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
            }
            if (0x999999999999999ALL * ((uint64_t)(*v15 - *a4) >> 4) > v17) {
              unint64_t v17 = 0x999999999999999ALL * ((uint64_t)(*v15 - *a4) >> 4);
            }
            if (0xCCCCCCCCCCCCCCCDLL * ((uint64_t)(*v15 - *a4) >> 4) >= 0x199999999999999) {
              unint64_t v18 = 0x333333333333333;
            }
            else {
              unint64_t v18 = v17;
            }
            if (v18) {
              uint64_t v19 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ZinIrCodegenTDPartitionStats>>((uint64_t)(a4 + 2), v18);
            }
            else {
              uint64_t v19 = 0;
            }
            uint64_t v20 = &v19[80 * v16];
            *(void *)uint64_t v20 = 0;
            *((void *)v20 + 1) = v14;
            *((void *)v20 + 2) = 0;
            *((void *)v20 + 3) = 0;
            *((void *)v20 + 4) = 0;
            *((void *)v20 + 5) = 1;
            *((void *)v20 + 6) = v12;
            *(int64x2_t *)(v20 + 56) = vdupq_n_s64(1uLL);
            *((void *)v20 + 9) = 1;
            uint64_t v22 = (char *)*a4;
            uint64_t v21 = (char *)a4[1];
            long long v23 = v20;
            if (v21 != (char *)*a4)
            {
              do
              {
                *((_OWORD *)v23 - 5) = *((_OWORD *)v21 - 5);
                long long v24 = *((_OWORD *)v21 - 4);
                long long v25 = *((_OWORD *)v21 - 3);
                long long v26 = *((_OWORD *)v21 - 1);
                *((_OWORD *)v23 - 2) = *((_OWORD *)v21 - 2);
                *((_OWORD *)v23 - 1) = v26;
                *((_OWORD *)v23 - 4) = v24;
                *((_OWORD *)v23 - 3) = v25;
                v23 -= 80;
                v21 -= 80;
              }
              while (v21 != v22);
              uint64_t v21 = v22;
            }
            long long v13 = v20 + 80;
            *a4 = v23;
            a4[1] = v20 + 80;
            a4[2] = &v19[80 * v18];
            if (v21) {
              operator delete(v21);
            }
          }
          else
          {
            *(void *)long long v13 = 0;
            *((void *)v13 + 1) = v14;
            *((_OWORD *)v13 + 1) = 0uLL;
            *((void *)v13 + 4) = 0;
            *((void *)v13 + 5) = 1;
            *((void *)v13 + 6) = v12;
            *(int64x2_t *)(v13 + 56) = v146;
            *((void *)v13 + 9) = 1;
            v13 += 80;
          }
          a4[1] = v13;
          ++v14;
          unint64_t v12 = a2[1] - *a2;
        }
        while (v14 < v12);
      }
      *(void *)(v145 + 8) *= v12;
      break;
    case 2:
      uint64_t v87 = (uint64_t)*a2;
      if (a2[1] == *a2)
      {
        uint64_t v89 = 0;
      }
      else
      {
        unint64_t v88 = 0;
        uint64_t v89 = 0;
        int64x2_t v149 = vdupq_n_s64(1uLL);
        do
        {
          uint64_t v90 = (*(uint64_t (**)(void, void, void))(**(void **)(v87 + 8 * v88) + 32))(*(void *)(v87 + 8 * v88), 0, 0);
          unint64_t v91 = a4[1];
          unint64_t v92 = a4[2];
          if (v91 >= v92)
          {
            unint64_t v94 = 0xCCCCCCCCCCCCCCCDLL * ((uint64_t)(v91 - *a4) >> 4);
            unint64_t v95 = v94 + 1;
            if (v94 + 1 > 0x333333333333333) {
              std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
            }
            unint64_t v96 = 0xCCCCCCCCCCCCCCCDLL * ((uint64_t)(v92 - *a4) >> 4);
            if (2 * v96 > v95) {
              unint64_t v95 = 2 * v96;
            }
            if (v96 >= 0x199999999999999) {
              unint64_t v97 = 0x333333333333333;
            }
            else {
              unint64_t v97 = v95;
            }
            if (v97) {
              uint64_t v98 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ZinIrCodegenTDPartitionStats>>((uint64_t)(a4 + 2), v97);
            }
            else {
              uint64_t v98 = 0;
            }
            uint64_t v99 = &v98[80 * v94];
            *(void *)uint64_t v99 = 0;
            *((void *)v99 + 1) = 0;
            *((void *)v99 + 3) = 0;
            *((void *)v99 + 4) = 0;
            *((void *)v99 + 2) = v89;
            int64x2_t v100 = vdupq_n_s64(1uLL);
            *(int64x2_t *)(v99 + 40) = v100;
            *(int64x2_t *)(v99 + 56) = v100;
            *((void *)v99 + 9) = 1;
            int v102 = (char *)*a4;
            uint64_t v101 = (char *)a4[1];
            BOOL v103 = v99;
            if (v101 != (char *)*a4)
            {
              do
              {
                *((_OWORD *)v103 - 5) = *((_OWORD *)v101 - 5);
                long long v104 = *((_OWORD *)v101 - 4);
                long long v105 = *((_OWORD *)v101 - 3);
                long long v106 = *((_OWORD *)v101 - 1);
                *((_OWORD *)v103 - 2) = *((_OWORD *)v101 - 2);
                *((_OWORD *)v103 - 1) = v106;
                *((_OWORD *)v103 - 4) = v104;
                *((_OWORD *)v103 - 3) = v105;
                v103 -= 80;
                v101 -= 80;
              }
              while (v101 != v102);
              uint64_t v101 = v102;
            }
            long long v93 = v99 + 80;
            *a4 = v103;
            a4[1] = v99 + 80;
            a4[2] = &v98[80 * v97];
            if (v101) {
              operator delete(v101);
            }
          }
          else
          {
            *(void *)unint64_t v91 = 0;
            *(void *)(v91 + 8) = 0;
            *(void *)(v91 + 24) = 0;
            *(void *)(v91 + std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = 0;
            *(void *)(v91 + 16) = v89;
            *(int64x2_t *)(v91 + 40) = v149;
            *(int64x2_t *)(v91 + 56) = v149;
            long long v93 = (char *)(v91 + 80);
            *(void *)(v91 + 72) = 1;
          }
          a4[1] = v93;
          v89 += *(void *)(v90 + 64);
          ++v88;
          uint64_t v87 = (uint64_t)*a2;
        }
        while (v88 < a2[1] - *a2);
      }
      *(void *)(a3 + 16) = v89;
      break;
    case 3:
      uint64_t v47 = (uint64_t)*a2;
      if (a2[1] == *a2)
      {
        uint64_t v49 = 0;
      }
      else
      {
        unint64_t v48 = 0;
        uint64_t v49 = 0;
        int64x2_t v144 = vdupq_n_s64(1uLL);
        do
        {
          uint64_t v50 = (*(uint64_t (**)(void, void, void))(**(void **)(v47 + 8 * v48) + 32))(*(void *)(v47 + 8 * v48), 0, 0);
          unint64_t v51 = a4[1];
          unint64_t v52 = a4[2];
          if (v51 >= v52)
          {
            unint64_t v54 = 0xCCCCCCCCCCCCCCCDLL * ((uint64_t)(v51 - *a4) >> 4);
            unint64_t v55 = v54 + 1;
            if (v54 + 1 > 0x333333333333333) {
              std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
            }
            unint64_t v56 = 0xCCCCCCCCCCCCCCCDLL * ((uint64_t)(v52 - *a4) >> 4);
            if (2 * v56 > v55) {
              unint64_t v55 = 2 * v56;
            }
            if (v56 >= 0x199999999999999) {
              unint64_t v57 = 0x333333333333333;
            }
            else {
              unint64_t v57 = v55;
            }
            if (v57) {
              uint64_t v58 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ZinIrCodegenTDPartitionStats>>((uint64_t)(a4 + 2), v57);
            }
            else {
              uint64_t v58 = 0;
            }
            uint64_t v59 = (int64x2_t *)&v58[80 * v54];
            v59->i64[0] = 0;
            v59->i64[1] = 0;
            v59[1].i64[0] = 0;
            v59[1].i64[1] = v49;
            int64x2_t v60 = vdupq_n_s64(1uLL);
            void v59[2] = (int64x2_t)xmmword_211ED5A80;
            void v59[3] = v60;
            v59[4] = v60;
            long long v62 = (char *)*a4;
            long long v61 = (char *)a4[1];
            long long v63 = v59;
            if (v61 != (char *)*a4)
            {
              do
              {
                v63[-5] = *((int64x2_t *)v61 - 5);
                int64x2_t v64 = *((int64x2_t *)v61 - 4);
                int64x2_t v65 = *((int64x2_t *)v61 - 3);
                int64x2_t v66 = *((int64x2_t *)v61 - 1);
                v63[-2] = *((int64x2_t *)v61 - 2);
                v63[-1] = v66;
                v63[-4] = v64;
                v63[-3] = v65;
                v63 -= 5;
                v61 -= 80;
              }
              while (v61 != v62);
              long long v61 = v62;
            }
            i8 = v59[5].i8;
            *a4 = v63;
            a4[1] = v59 + 5;
            a4[2] = &v58[80 * v57];
            if (v61) {
              operator delete(v61);
            }
          }
          else
          {
            *(void *)unint64_t v51 = 0;
            *(void *)(v51 + 8) = 0;
            *(void *)(v51 + 16) = 0;
            *(void *)(v51 + 24) = v49;
            *(_OWORD *)(v51 + std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = xmmword_211ED5A80;
            *(int64x2_t *)(v51 + 48) = v144;
            i8 = (char *)(v51 + 80);
            *(int64x2_t *)(v51 + 64) = v144;
          }
          a4[1] = i8;
          v49 += *(void *)(v50 + 72);
          ++v48;
          uint64_t v47 = (uint64_t)*a2;
        }
        while (v48 < a2[1] - *a2);
      }
      *(void *)(a3 + 24) = v49;
      break;
    case 4:
      uint64_t v67 = (uint64_t)*a2;
      if (a2[1] == *a2)
      {
        uint64_t v69 = 0;
      }
      else
      {
        unint64_t v68 = 0;
        uint64_t v69 = 0;
        int64x2_t v148 = vdupq_n_s64(1uLL);
        do
        {
          uint64_t v70 = (*(uint64_t (**)(void, void, void))(**(void **)(v67 + 8 * v68) + 32))(*(void *)(v67 + 8 * v68), 0, 0);
          __int16 v72 = (char *)a4[1];
          unint64_t v71 = a4[2];
          if ((unint64_t)v72 >= v71)
          {
            uint64_t v74 = (char *)*a4;
            unint64_t v75 = 0xCCCCCCCCCCCCCCCDLL * ((uint64_t)&v72[-*a4] >> 4);
            unint64_t v76 = v75 + 1;
            if (v75 + 1 > 0x333333333333333) {
              std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
            }
            unint64_t v77 = 0xCCCCCCCCCCCCCCCDLL * ((uint64_t)(v71 - (void)v74) >> 4);
            if (2 * v77 > v76) {
              unint64_t v76 = 2 * v77;
            }
            if (v77 >= 0x199999999999999) {
              unint64_t v78 = 0x333333333333333;
            }
            else {
              unint64_t v78 = v76;
            }
            if (v78)
            {
              long long v79 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ZinIrCodegenTDPartitionStats>>((uint64_t)(a4 + 2), v78);
              uint64_t v74 = (char *)*a4;
              __int16 v72 = (char *)a4[1];
            }
            else
            {
              long long v79 = 0;
            }
            long long v80 = &v79[80 * v75];
            *(_OWORD *)long long v80 = 0u;
            *((_OWORD *)v80 + 1) = 0u;
            *((void *)v80 + 4) = v69;
            int64x2_t v81 = vdupq_n_s64(1uLL);
            *(int64x2_t *)(v80 + 40) = v81;
            *(int64x2_t *)(v80 + 56) = v81;
            *((void *)v80 + 9) = 1;
            if (v72 == v74)
            {
              long long v86 = &v79[80 * v75];
            }
            else
            {
              long long v82 = &v79[80 * v75];
              do
              {
                *((_OWORD *)v82 - 5) = *((_OWORD *)v72 - 5);
                long long v83 = *((_OWORD *)v72 - 4);
                long long v84 = *((_OWORD *)v72 - 3);
                long long v85 = *((_OWORD *)v72 - 1);
                long long v86 = v82 - 80;
                *((_OWORD *)v82 - 2) = *((_OWORD *)v72 - 2);
                *((_OWORD *)v82 - 1) = v85;
                *((_OWORD *)v82 - 4) = v83;
                *((_OWORD *)v82 - 3) = v84;
                v72 -= 80;
                v82 -= 80;
              }
              while (v72 != v74);
            }
            int64x2_t v73 = v80 + 80;
            *a4 = v86;
            a4[1] = v80 + 80;
            a4[2] = &v79[80 * v78];
            if (v74) {
              operator delete(v74);
            }
          }
          else
          {
            *(_OWORD *)__int16 v72 = 0u;
            *((_OWORD *)v72 + 1) = 0u;
            *((void *)v72 + 4) = v69;
            *(int64x2_t *)(v72 + 40) = v148;
            *(int64x2_t *)(v72 + 56) = v148;
            int64x2_t v73 = v72 + 80;
            *((void *)v72 + 9) = 1;
          }
          a4[1] = v73;
          v69 += *(void *)(v70 + 80);
          ++v68;
          uint64_t v67 = (uint64_t)*a2;
        }
        while (v68 < a2[1] - *a2);
      }
      *(void *)(a3 + std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = v69;
      break;
    case 5:
      uint64_t v27 = (uint64_t)*a2;
      if (a2[1] == *a2)
      {
        uint64_t v29 = 0;
      }
      else
      {
        unint64_t v28 = 0;
        uint64_t v29 = 0;
        int64x2_t v147 = vdupq_n_s64(1uLL);
        do
        {
          uint64_t v30 = (*(uint64_t (**)(void, void, void))(**(void **)(v27 + 8 * v28) + 32))(*(void *)(v27 + 8 * v28), 0, 0);
          uint64_t v32 = (char *)a4[1];
          unint64_t v31 = a4[2];
          if ((unint64_t)v32 >= v31)
          {
            uint64_t v34 = (char *)*a4;
            unint64_t v35 = 0xCCCCCCCCCCCCCCCDLL * ((uint64_t)&v32[-*a4] >> 4);
            unint64_t v36 = v35 + 1;
            if (v35 + 1 > 0x333333333333333) {
              std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
            }
            unint64_t v37 = 0xCCCCCCCCCCCCCCCDLL * ((uint64_t)(v31 - (void)v34) >> 4);
            if (2 * v37 > v36) {
              unint64_t v36 = 2 * v37;
            }
            if (v37 >= 0x199999999999999) {
              unint64_t v38 = 0x333333333333333;
            }
            else {
              unint64_t v38 = v36;
            }
            if (v38)
            {
              long long v39 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ZinIrCodegenTDPartitionStats>>((uint64_t)(a4 + 2), v38);
              uint64_t v34 = (char *)*a4;
              uint64_t v32 = (char *)a4[1];
            }
            else
            {
              long long v39 = 0;
            }
            long long v40 = &v39[80 * v35];
            *(void *)long long v40 = v29;
            *(_OWORD *)(v40 + 8) = 0u;
            *(_OWORD *)(v40 + 24) = 0u;
            int64x2_t v41 = vdupq_n_s64(1uLL);
            *(int64x2_t *)(v40 + 40) = v41;
            *(int64x2_t *)(v40 + 56) = v41;
            *((void *)v40 + 9) = 1;
            if (v32 == v34)
            {
              uint8_t v46 = &v39[80 * v35];
            }
            else
            {
              long long v42 = &v39[80 * v35];
              do
              {
                *((_OWORD *)v42 - 5) = *((_OWORD *)v32 - 5);
                long long v43 = *((_OWORD *)v32 - 4);
                long long v44 = *((_OWORD *)v32 - 3);
                long long v45 = *((_OWORD *)v32 - 1);
                uint8_t v46 = v42 - 80;
                *((_OWORD *)v42 - 2) = *((_OWORD *)v32 - 2);
                *((_OWORD *)v42 - 1) = v45;
                *((_OWORD *)v42 - 4) = v43;
                *((_OWORD *)v42 - 3) = v44;
                v32 -= 80;
                v42 -= 80;
              }
              while (v32 != v34);
            }
            uint64_t v33 = v40 + 80;
            *a4 = v46;
            a4[1] = v40 + 80;
            a4[2] = &v39[80 * v38];
            if (v34) {
              operator delete(v34);
            }
          }
          else
          {
            *(void *)uint64_t v32 = v29;
            *(_OWORD *)(v32 + 8) = 0u;
            *(_OWORD *)(v32 + 24) = 0u;
            *(int64x2_t *)(v32 + 40) = v147;
            *(int64x2_t *)(v32 + 56) = v147;
            uint64_t v33 = v32 + 80;
            *((void *)v32 + 9) = 1;
          }
          a4[1] = v33;
          v29 += *(void *)(v30 + 48);
          ++v28;
          uint64_t v27 = (uint64_t)*a2;
        }
        while (v28 < a2[1] - *a2);
      }
      *(void *)a3 = v29;
      break;
    case 6:
      uint64_t v107 = (char *)a2[1] - (char *)*a2;
      unint64_t v108 = v107 >> 3;
      if (v107)
      {
        uint64_t v109 = 0;
        unint64_t v110 = 0;
        uint64_t v111 = a4 + 2;
        int64x2_t v150 = vdupq_n_s64(1uLL);
        do
        {
          if ((unint64_t)v109 >= *v111)
          {
            unint64_t v112 = 0xCCCCCCCCCCCCCCCDLL * ((uint64_t)&v109[-*a4] >> 4);
            unint64_t v113 = v112 + 1;
            if (v112 + 1 > 0x333333333333333) {
              std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
            }
            if (0x999999999999999ALL * ((uint64_t)(*v111 - *a4) >> 4) > v113) {
              unint64_t v113 = 0x999999999999999ALL * ((uint64_t)(*v111 - *a4) >> 4);
            }
            if (0xCCCCCCCCCCCCCCCDLL * ((uint64_t)(*v111 - *a4) >> 4) >= 0x199999999999999) {
              unint64_t v114 = 0x333333333333333;
            }
            else {
              unint64_t v114 = v113;
            }
            if (v114) {
              int v115 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ZinIrCodegenTDPartitionStats>>((uint64_t)(a4 + 2), v114);
            }
            else {
              int v115 = 0;
            }
            std::string v116 = &v115[80 * v112];
            *(void *)std::string v116 = 0;
            *((void *)v116 + 1) = 0;
            *((void *)v116 + 3) = 0;
            *((void *)v116 + 4) = 0;
            *((void *)v116 + 2) = v110;
            int64x2_t v117 = vdupq_n_s64(1uLL);
            *(int64x2_t *)(v116 + 40) = v117;
            *((void *)v116 + 7) = v108;
            *((int64x2_t *)v116 + 4) = v117;
            char v119 = (char *)*a4;
            char v118 = (char *)a4[1];
            char v120 = v116;
            if (v118 != (char *)*a4)
            {
              do
              {
                *((_OWORD *)v120 - 5) = *((_OWORD *)v118 - 5);
                long long v121 = *((_OWORD *)v118 - 4);
                long long v122 = *((_OWORD *)v118 - 3);
                long long v123 = *((_OWORD *)v118 - 1);
                *((_OWORD *)v120 - 2) = *((_OWORD *)v118 - 2);
                *((_OWORD *)v120 - 1) = v123;
                *((_OWORD *)v120 - 4) = v121;
                *((_OWORD *)v120 - 3) = v122;
                v120 -= 80;
                v118 -= 80;
              }
              while (v118 != v119);
              char v118 = v119;
            }
            uint64_t v109 = v116 + 80;
            *a4 = v120;
            a4[1] = v116 + 80;
            a4[2] = &v115[80 * v114];
            if (v118) {
              operator delete(v118);
            }
          }
          else
          {
            *(void *)uint64_t v109 = 0;
            *((void *)v109 + 1) = 0;
            *((void *)v109 + 2) = v110;
            *(_OWORD *)(v109 + 24) = 0uLL;
            *(int64x2_t *)(v109 + 40) = v150;
            *((void *)v109 + 7) = v108;
            *((int64x2_t *)v109 + 4) = v150;
            v109 += 80;
          }
          a4[1] = v109;
          ++v110;
          unint64_t v108 = a2[1] - *a2;
        }
        while (v110 < v108);
      }
      *(void *)(v145 + 16) *= v108;
      break;
    default:
      uint64_t v124 = (uint64_t)*a2;
      if (a2[1] == *a2)
      {
        uint64_t v126 = 0;
      }
      else
      {
        unint64_t v125 = 0;
        uint64_t v126 = 0;
        int64x2_t v151 = vdupq_n_s64(1uLL);
        do
        {
          uint64_t v127 = (*(uint64_t (**)(void, void, void))(**(void **)(v124 + 8 * v125) + 32))(*(void *)(v124 + 8 * v125), 0, 0);
          unint64_t v128 = a4[1];
          unint64_t v129 = a4[2];
          if (v128 >= v129)
          {
            unint64_t v131 = 0xCCCCCCCCCCCCCCCDLL * ((uint64_t)(v128 - *a4) >> 4);
            unint64_t v132 = v131 + 1;
            if (v131 + 1 > 0x333333333333333) {
              std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
            }
            unint64_t v133 = 0xCCCCCCCCCCCCCCCDLL * ((uint64_t)(v129 - *a4) >> 4);
            if (2 * v133 > v132) {
              unint64_t v132 = 2 * v133;
            }
            if (v133 >= 0x199999999999999) {
              unint64_t v134 = 0x333333333333333;
            }
            else {
              unint64_t v134 = v132;
            }
            if (v134) {
              char v135 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ZinIrCodegenTDPartitionStats>>((uint64_t)(a4 + 2), v134);
            }
            else {
              char v135 = 0;
            }
            char v136 = &v135[80 * v131];
            *(void *)char v136 = 0;
            *((void *)v136 + 1) = v126;
            *((void *)v136 + 3) = 0;
            *((void *)v136 + 4) = 0;
            *((void *)v136 + 2) = 0;
            int64x2_t v137 = vdupq_n_s64(1uLL);
            *(int64x2_t *)(v136 + 40) = v137;
            *(int64x2_t *)(v136 + 56) = v137;
            *((void *)v136 + 9) = 1;
            char v139 = (char *)*a4;
            uint64_t v138 = (char *)a4[1];
            uint64_t v140 = v136;
            if (v138 != (char *)*a4)
            {
              do
              {
                *((_OWORD *)v140 - 5) = *((_OWORD *)v138 - 5);
                long long v141 = *((_OWORD *)v138 - 4);
                long long v142 = *((_OWORD *)v138 - 3);
                long long v143 = *((_OWORD *)v138 - 1);
                *((_OWORD *)v140 - 2) = *((_OWORD *)v138 - 2);
                *((_OWORD *)v140 - 1) = v143;
                *((_OWORD *)v140 - 4) = v141;
                *((_OWORD *)v140 - 3) = v142;
                v140 -= 80;
                v138 -= 80;
              }
              while (v138 != v139);
              uint64_t v138 = v139;
            }
            char v130 = v136 + 80;
            *a4 = v140;
            a4[1] = v136 + 80;
            a4[2] = &v135[80 * v134];
            if (v138) {
              operator delete(v138);
            }
          }
          else
          {
            *(void *)unint64_t v128 = 0;
            *(void *)(v128 + 8) = v126;
            *(void *)(v128 + 24) = 0;
            *(void *)(v128 + std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = 0;
            *(void *)(v128 + 16) = 0;
            *(int64x2_t *)(v128 + 40) = v151;
            *(int64x2_t *)(v128 + 56) = v151;
            char v130 = (char *)(v128 + 80);
            *(void *)(v128 + 72) = 1;
          }
          a4[1] = v130;
          v126 += *(void *)(v127 + 56);
          ++v125;
          uint64_t v124 = (uint64_t)*a2;
        }
        while (v125 < a2[1] - *a2);
      }
      *(void *)(a3 + 8) = v126;
      break;
  }
}

void sub_2112A4298(_Unwind_Exception *exception_object)
{
  uint64_t v3 = *(void **)v1;
  if (*(void *)v1)
  {
    *(void *)(v1 + 8) = v3;
    operator delete(v3);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinConcatLayerUtils::GetMode(unsigned int a1)
{
  if (a1 >= 5) {
    ZinAssertImpl("Unknown concat axis.");
  }
  return dword_211F00760[a1];
}

uint64_t ZinConcatLayerUtils::GetConcatAxis(unsigned int a1)
{
  if (a1 >= 7) {
    ZinAssertImpl("Unknown concat axis.");
  }
  return dword_211F00774[a1];
}

uint64_t ZinConcatLayerUtils::IsInterleavedConcat(unsigned int a1)
{
  if (a1 >= 7) {
    ZinAssertImpl("Unknown concat axis.", v1, v2);
  }
  return (0x42u >> a1) & 1;
}

uint64_t ZinConcatLayerUtils::GetConcatMode(unsigned int a1)
{
  if (a1 < 5) {
    return dword_211F00790[a1];
  }
  if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
    ZinConcatLayerUtils::GetConcatMode();
  }
  return 7;
}

void ZinConcatLayerUtils::GetConcatMode()
{
  *(_WORD *)uint64_t v0 = 0;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "Invalid concat axis\n", v0, 2u);
}

void ZinNEMatMulLayer::ZinNEMatMulLayer()
{
}

{
  ZinNEMatMulLayer::ZinNEMatMulLayer();
}

void sub_2112A4578(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, std::__shared_weak_count *a8, ...)
{
  va_start(va, a8);
  if (a8) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a8);
  }
  ZinLayerNormLayer::ZinLayerNormLayer((uint64_t *)va);
  _Unwind_Resume(a1);
}

uint64_t ZinNEMatMulLayer::LowerEngine(uint64_t a1, ZinTextureLayerUtils *a2, ZinANELayer ***a3)
{
  uint64_t v5 = ZinANELayer::LowerEngine(a1, a2, a3);
  if (!v5)
  {
    if (*(char *)(a1 + 47) >= 0) {
      size_t v6 = *(unsigned __int8 *)(a1 + 47);
    }
    else {
      size_t v6 = *(void *)(a1 + 32);
    }
    uint64_t v7 = __p;
    std::string::basic_string[abi:ne180100]((uint64_t)__p, v6 + 1);
    if (v11 < 0) {
      uint64_t v7 = (void **)__p[0];
    }
    if (v6)
    {
      if (*(char *)(a1 + 47) >= 0) {
        uint64_t v8 = (const void *)(a1 + 24);
      }
      else {
        uint64_t v8 = *(const void **)(a1 + 24);
      }
      memmove(v7, v8, v6);
    }
    *(_WORD *)((char *)v7 + v6) = 95;
    ZinObjectNameFactory::ZinObjectNameFactory(v12, __p);
    if (v11 < 0) {
      operator delete(__p[0]);
    }
    ZinMirMatMul::ZinMirMatMul(__p, (uint64_t)a2, a1, (uint64_t)v12);
    uint64_t v5 = ZinMirMatMul::Transform((ZinMirMatMul *)__p);
    v12[0] = &unk_26C34DA98;
    if (v13 < 0) {
      operator delete((void *)v12[1]);
    }
  }
  return v5;
}

void sub_2112A46EC(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, void *__p, uint64_t a10, int a11, __int16 a12, char a13, char a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, int a19, __int16 a20,char a21,char a22)
{
  if (a14 < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

void ZinNEMatMulLayer::Clone(void *a1, uint64_t a2, const void **a3)
{
  uint64_t v5 = *(void *)(*(void *)a2 + 16);
  uint64_t v6 = a1[25];
  if (*((char *)a3 + 23) >= 0) {
    size_t v7 = *((unsigned __int8 *)a3 + 23);
  }
  else {
    size_t v7 = (size_t)a3[1];
  }
  uint64_t v8 = &v52;
  std::string::basic_string[abi:ne180100]((uint64_t)&v52, v7 + 8);
  if (v53 < 0) {
    uint64_t v8 = (long long *)v52;
  }
  if (v7)
  {
    if (*((char *)a3 + 23) >= 0) {
      long long v9 = a3;
    }
    else {
      long long v9 = *a3;
    }
    memmove(v8, v9, v7);
  }
  strcpy((char *)v8 + v7, "_texture");
  ZinANELayer::CloneEncapsulatedLayer<ZinRCASLayer *>(v5, v6, (const void **)&v52);
  if (SHIBYTE(v53) < 0) {
    operator delete((void *)v52);
  }
  uint64_t v10 = a1[46];
  if (*((char *)a3 + 23) >= 0) {
    size_t v11 = *((unsigned __int8 *)a3 + 23);
  }
  else {
    size_t v11 = (size_t)a3[1];
  }
  unint64_t v12 = &v52;
  std::string::basic_string[abi:ne180100]((uint64_t)&v52, v11 + 11);
  if (v53 < 0) {
    unint64_t v12 = (long long *)v52;
  }
  if (v11)
  {
    if (*((char *)a3 + 23) >= 0) {
      char v13 = a3;
    }
    else {
      char v13 = *a3;
    }
    memmove(v12, v13, v11);
  }
  strcpy((char *)v12 + v11, "_ibroadcast");
  ZinANELayer::CloneEncapsulatedLayer<ZinRCASLayer *>(v5, v10, (const void **)&v52);
  if (SHIBYTE(v53) < 0) {
    operator delete((void *)v52);
  }
  uint64_t v14 = a1[47];
  if (*((char *)a3 + 23) >= 0) {
    size_t v15 = *((unsigned __int8 *)a3 + 23);
  }
  else {
    size_t v15 = (size_t)a3[1];
  }
  unint64_t v16 = &v52;
  std::string::basic_string[abi:ne180100]((uint64_t)&v52, v15 + 6);
  if (v53 < 0) {
    unint64_t v16 = (long long *)v52;
  }
  if (v15)
  {
    if (*((char *)a3 + 23) >= 0) {
      unint64_t v17 = a3;
    }
    else {
      unint64_t v17 = *a3;
    }
    memmove(v16, v17, v15);
  }
  strcpy((char *)v16 + v15, "_irelu");
  ZinANELayer::CloneEncapsulatedLayer<ZinRCASLayer *>(v5, v14, (const void **)&v52);
  if (SHIBYTE(v53) < 0) {
    operator delete((void *)v52);
  }
  uint64_t v18 = a1[54];
  if (*((char *)a3 + 23) >= 0) {
    size_t v19 = *((unsigned __int8 *)a3 + 23);
  }
  else {
    size_t v19 = (size_t)a3[1];
  }
  uint64_t v20 = &v52;
  std::string::basic_string[abi:ne180100]((uint64_t)&v52, v19 + 7);
  if (v53 < 0) {
    uint64_t v20 = (long long *)v52;
  }
  if (v19)
  {
    if (*((char *)a3 + 23) >= 0) {
      uint64_t v21 = a3;
    }
    else {
      uint64_t v21 = *a3;
    }
    memmove(v20, v21, v19);
  }
  strcpy((char *)v20 + v19, "_matmul");
  ZinANELayer::CloneEncapsulatedLayer<ZinRCASLayer *>(v5, v18, (const void **)&v52);
  if (SHIBYTE(v53) < 0) {
    operator delete((void *)v52);
  }
  uint64_t v22 = (*(uint64_t (**)(void *))(*a1 + 576))(a1);
  if (*((char *)a3 + 23) >= 0) {
    size_t v23 = *((unsigned __int8 *)a3 + 23);
  }
  else {
    size_t v23 = (size_t)a3[1];
  }
  long long v24 = &v52;
  std::string::basic_string[abi:ne180100]((uint64_t)&v52, v23 + 6);
  if (v53 < 0) {
    long long v24 = (long long *)v52;
  }
  if (v23)
  {
    if (*((char *)a3 + 23) >= 0) {
      long long v25 = a3;
    }
    else {
      long long v25 = *a3;
    }
    memmove(v24, v25, v23);
  }
  strcpy((char *)v24 + v23, "_round");
  ZinANELayer::CloneEncapsulatedLayer<ZinRCASLayer *>(v5, v22, (const void **)&v52);
  if (SHIBYTE(v53) < 0) {
    operator delete((void *)v52);
  }
  uint64_t v26 = a1[48];
  if (*((char *)a3 + 23) >= 0) {
    size_t v27 = *((unsigned __int8 *)a3 + 23);
  }
  else {
    size_t v27 = (size_t)a3[1];
  }
  unint64_t v28 = &v52;
  std::string::basic_string[abi:ne180100]((uint64_t)&v52, v27 + 4);
  if (v53 < 0) {
    unint64_t v28 = (long long *)v52;
  }
  if (v27)
  {
    if (*((char *)a3 + 23) >= 0) {
      uint64_t v29 = a3;
    }
    else {
      uint64_t v29 = *a3;
    }
    memmove(v28, v29, v27);
  }
  strcpy((char *)v28 + v27, "_goc");
  ZinANELayer::CloneEncapsulatedLayer<ZinRCASLayer *>(v5, v26, (const void **)&v52);
  if (SHIBYTE(v53) < 0) {
    operator delete((void *)v52);
  }
  uint64_t v30 = a1[49];
  if (*((char *)a3 + 23) >= 0) {
    size_t v31 = *((unsigned __int8 *)a3 + 23);
  }
  else {
    size_t v31 = (size_t)a3[1];
  }
  uint64_t v32 = &v52;
  std::string::basic_string[abi:ne180100]((uint64_t)&v52, v31 + 11);
  if (v53 < 0) {
    uint64_t v32 = (long long *)v52;
  }
  if (v31)
  {
    if (*((char *)a3 + 23) >= 0) {
      uint64_t v33 = a3;
    }
    else {
      uint64_t v33 = *a3;
    }
    memmove(v32, v33, v31);
  }
  strcpy((char *)v32 + v31, "_activation");
  ZinANELayer::CloneEncapsulatedLayer<ZinRCASLayer *>(v5, v30, (const void **)&v52);
  if (SHIBYTE(v53) < 0) {
    operator delete((void *)v52);
  }
  uint64_t v34 = (*(uint64_t (**)(void *))(*a1 + 416))(a1);
  if (*((char *)a3 + 23) >= 0) {
    size_t v35 = *((unsigned __int8 *)a3 + 23);
  }
  else {
    size_t v35 = (size_t)a3[1];
  }
  unint64_t v36 = &v51;
  std::string::basic_string[abi:ne180100]((uint64_t)&v51, v35 + 1);
  if ((v51.__r_.__value_.__r.__words[2] & 0x8000000000000000) != 0) {
    unint64_t v36 = (std::string *)v51.__r_.__value_.__r.__words[0];
  }
  if (v35)
  {
    if (*((char *)a3 + 23) >= 0) {
      unint64_t v37 = a3;
    }
    else {
      unint64_t v37 = *a3;
    }
    memmove(v36, v37, v35);
  }
  *(_WORD *)((char *)&v36->__r_.__value_.__l.__data_ + v35) = 95;
  std::string::basic_string[abi:ne180100]<0>(&v48, "nematmul_transp");
  unint64_t v38 = std::string::append(&v48, "_xfm", 4uLL);
  long long v39 = *(_OWORD *)&v38->__r_.__value_.__l.__data_;
  int64_t v50 = v38->__r_.__value_.__r.__words[2];
  *(_OWORD *)long long __p = v39;
  v38->__r_.__value_.__l.__size_ = 0;
  v38->__r_.__value_.__r.__words[2] = 0;
  v38->__r_.__value_.__r.__words[0] = 0;
  if (v50 >= 0) {
    long long v40 = __p;
  }
  else {
    long long v40 = (void **)__p[0];
  }
  if (v50 >= 0) {
    std::string::size_type v41 = HIBYTE(v50);
  }
  else {
    std::string::size_type v41 = (std::string::size_type)__p[1];
  }
  long long v42 = std::string::append(&v51, (const std::string::value_type *)v40, v41);
  long long v43 = *(_OWORD *)&v42->__r_.__value_.__l.__data_;
  int64_t v53 = v42->__r_.__value_.__r.__words[2];
  long long v52 = v43;
  v42->__r_.__value_.__l.__size_ = 0;
  v42->__r_.__value_.__r.__words[2] = 0;
  v42->__r_.__value_.__r.__words[0] = 0;
  ZinANELayer::CloneEncapsulatedLayer<ZinRCASLayer *>(v5, v34, (const void **)&v52);
  if (SHIBYTE(v53) < 0) {
    operator delete((void *)v52);
  }
  if (SHIBYTE(v50) < 0) {
    operator delete(__p[0]);
  }
  if (SHIBYTE(v48.__r_.__value_.__r.__words[2]) < 0) {
    operator delete(v48.__r_.__value_.__l.__data_);
  }
  if (SHIBYTE(v51.__r_.__value_.__r.__words[2]) < 0) {
    operator delete(v51.__r_.__value_.__l.__data_);
  }
  uint64_t v44 = a1[51];
  if (*((char *)a3 + 23) >= 0) {
    size_t v45 = *((unsigned __int8 *)a3 + 23);
  }
  else {
    size_t v45 = (size_t)a3[1];
  }
  uint8_t v46 = &v52;
  std::string::basic_string[abi:ne180100]((uint64_t)&v52, v45 + 6);
  if (v53 < 0) {
    uint8_t v46 = (long long *)v52;
  }
  if (v45)
  {
    if (*((char *)a3 + 23) >= 0) {
      uint64_t v47 = a3;
    }
    else {
      uint64_t v47 = *a3;
    }
    memmove(v46, v47, v45);
  }
  strcpy((char *)v46 + v45, "_quant");
  ZinANELayer::CloneEncapsulatedLayer<ZinRCASLayer *>(v5, v44, (const void **)&v52);
  if (SHIBYTE(v53) < 0) {
    operator delete((void *)v52);
  }
  operator new();
}

void sub_2112A4F94(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,void *a22,uint64_t a23,int a24,__int16 a25,char a26,char a27,void *__p,uint64_t a29,int a30,__int16 a31,char a32,char a33)
{
  std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)(v33 - 112), 0);
  _Unwind_Resume(a1);
}

uint64_t ZinNEMatMulLayer::DebugDetailPrint@<X0>(void *a1@<X8>)
{
  std::basic_stringstream<char,std::char_traits<char>,std::allocator<char>>::basic_stringstream[abi:ne180100]((uint64_t)v5);
  std::stringbuf::str[abi:ne180100]<std::allocator<char>>((uint64_t)v6, a1);
  v5[0] = *MEMORY[0x263F8C2B8];
  uint64_t v3 = *(void *)(MEMORY[0x263F8C2B8] + 72);
  *(void *)((char *)v5 + *(void *)(v5[0] - 24)) = *(void *)(MEMORY[0x263F8C2B8] + 64);
  v5[2] = v3;
  v6[0] = MEMORY[0x263F8C318] + 16;
  if (v7 < 0) {
    operator delete((void *)v6[8]);
  }
  std::streambuf::~streambuf();
  std::iostream::~basic_iostream();
  return MEMORY[0x21667D2B0](&v8);
}

void sub_2112A51DC(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
}

__n128 ZinNEMatMulLayer::ExecutionOrderSort@<Q0>(__n128 *this@<X0>, void *a2@<X8>)
{
  unint64_t v4 = this[12].n128_u64[1];
  __n128 v9 = this[23];
  __n128 v10 = this[24];
  __n128 v11 = this[27];
  uint64_t v5 = (*(uint64_t (**)(void))(this->n128_u64[0] + 416))();
  unint64_t v6 = this[25].n128_u64[1];
  a2[1] = 0;
  a2[2] = 0;
  *a2 = 0;
  char v7 = (char *)operator new(0x48uLL);
  a2[1] = v7 + 72;
  a2[2] = v7 + 72;
  *(void *)char v7 = v4;
  *(__n128 *)(v7 + 8) = v9;
  *(__n128 *)(v7 + 24) = v11;
  __n128 result = v10;
  *(__n128 *)(v7 + 40) = v10;
  *((void *)v7 + 7) = v5;
  *((void *)v7 + 8) = v6;
  *a2 = v7;
  return result;
}

void ZinNEMatMulLayer::SpatialSplitCopy(ZinNEMatMulLayer *this, const TiledLayerTensorRegions *a2)
{
}

void sub_2112A53E4(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11, int a12, __int16 a13, char a14, char a15, uint64_t a16, uint64_t a17, uint64_t a18, std::__shared_weak_count *a19)
{
  if (a19) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a19);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinNEMatMulLayer::HasValidOutputTranspose(ZinNEMatMulLayer *this)
{
  if (!(*(unsigned int (**)(ZinNEMatMulLayer *))(*(void *)this + 408))(this) || !*((void *)this + 33)) {
    return 0;
  }
  uint64_t v2 = (*(uint64_t (**)(ZinNEMatMulLayer *, void, void))(*(void *)this + 32))(this, 0, 0) + 48;
  uint64_t v3 = *(unsigned int *)((*(uint64_t (**)(ZinNEMatMulLayer *, void, void))(*(void *)this + 32))(this, 0, 0)+ 88);
  Hal = ZinIrTarget::GetHal(*((uint64_t **)this + 2), *(ZinIrTarget **)(*((void *)this + 2) + 160));
  uint64_t v5 = (*(uint64_t (**)(uint64_t *))(*Hal + 16))(Hal);
  unint64_t v6 = *(uint64_t (**)(ZinNEMatMulLayer *, uint64_t, uint64_t, char *, uint64_t, void))(*(void *)this + 600);

  return v6(this, v2, v3, (char *)this + 264, v5, 0);
}

uint64_t ZinScaledElementWiseLayer::QualifiesAsEW(ZinScaledElementWiseLayer *this)
{
  long long v13 = 0u;
  long long v14 = 0u;
  uint64_t v15 = -1;
  v11[0] = &unk_26C34E990;
  memset(&v11[1], 0, 24);
  __asm { FMOV            V0.2S, #1.0 }
  uint64_t v17 = _D0;
  int v18 = 0;
  __int16 v19 = 0;
  int v16 = 0;
  int v12 = 5;
  uint64_t v6 = *((void *)this + 8);
  BOOL v7 = *(float *)(v6 + 20) == 1.0 && *(float *)(v6 + 16) == 1.0 && *(float *)(v6 + 24) == 0.0;
  if (*(_DWORD *)(v6 + 12))
  {
    if (*(unsigned char *)(v6 + 28)) {
      BOOL v8 = 0;
    }
    else {
      BOOL v8 = *(unsigned __int8 *)(v6 + 29) == 0;
    }
  }
  else
  {
    BOOL v8 = 1;
  }
  uint64_t v9 = v7 & v8;
  ZinIrUnitInfo::~ZinIrUnitInfo(v11);
  return v9;
}

void ZinScaledElementWiseLayer::Clone()
{
}

void sub_2112A57A8(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12)
{
  if (v13) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v13);
  }
  if (a12) {
    (*(void (**)(uint64_t))(*(void *)a12 + 8))(a12);
  }
  MEMORY[0x21667D3C0](v12, 0x10B3C4024B96488);
  _Unwind_Resume(a1);
}

uint64_t ZinScaledElementWiseLayer::ComputeOutputDimensions(uint64_t a1, uint64_t *a2, int8x16_t *a3)
{
  uint64_t v4 = *a2;
  unint64_t v5 = 0xCCCCCCCCCCCCCCCDLL * ((a2[1] - *a2) >> 3);
  if (v5 == 2)
  {
    ZinElementWiseLayerUtils::GetOutputTensorDims((int64x2_t *)v4, (int64x2_t *)(v4 + 40), v10);
    uint64_t result = 0;
    int8x16_t v9 = v10[1];
    *a3 = v10[0];
    a3[1] = v9;
    a3[2].i64[0] = v11;
  }
  else if (v5 == 1)
  {
    uint64_t result = 0;
    int64x2_t v7 = *(int64x2_t *)v4;
    int8x16_t v8 = *(int8x16_t *)(v4 + 16);
    a3[2].i64[0] = *(void *)(v4 + 32);
    *a3 = (int8x16_t)v7;
    a3[1] = v8;
  }
  else
  {
    *a3 = (int8x16_t)xmmword_211ED5A80;
    a3[1] = (int8x16_t)vdupq_n_s64(1uLL);
    a3[2].i64[0] = 1;
    return 3;
  }
  return result;
}

void *ZinScaledElementWiseLayer::OpCodeKindToString@<X0>(ZinScaledElementWiseLayer *this@<X0>, void *a2@<X8>)
{
  return ScaledElementWiseModeToString(*(_DWORD *)(*((void *)this + 8) + 12), a2);
}

uint64_t ZinScaledElementWiseLayer::DebugDetailPrint@<X0>(void *a1@<X8>)
{
  std::basic_stringstream<char,std::char_traits<char>,std::allocator<char>>::basic_stringstream[abi:ne180100]((uint64_t)v5);
  std::stringbuf::str[abi:ne180100]<std::allocator<char>>((uint64_t)v6, a1);
  v5[0] = *MEMORY[0x263F8C2B8];
  uint64_t v3 = *(void *)(MEMORY[0x263F8C2B8] + 72);
  *(void *)((char *)v5 + *(void *)(v5[0] - 24)) = *(void *)(MEMORY[0x263F8C2B8] + 64);
  v5[2] = v3;
  v6[0] = MEMORY[0x263F8C318] + 16;
  if (v7 < 0) {
    operator delete((void *)v6[8]);
  }
  std::streambuf::~streambuf();
  std::iostream::~basic_iostream();
  return MEMORY[0x21667D2B0](&v8);
}

void sub_2112A5A44(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
}

uint64_t ZinScaledElementWiseLayer::IsRedundant(ZinScaledElementWiseLayer *this)
{
  uint64_t v1 = *((void *)this + 8);
  if (*(float *)(v1 + 16) != 1.0
    || *(float *)(v1 + 20) != 1.0
    || *(float *)(v1 + 24) != 0.0
    || *(unsigned char *)(*((void *)this + 2) + 1056))
  {
    return 0;
  }
  int v4 = *(_DWORD *)(v1 + 12);
  if (v4 == 2)
  {
    uint64_t v11 = (void *)*((void *)this + 11);
    if (*(_DWORD *)(*(void *)(*v11 + 64) + 8) == 29)
    {
      uint64_t v12 = (ZinIrTensor *)(*(uint64_t (**)(void, void, void))(*(void *)*v11 + 32))(*v11, 0, 0);
      int IsZero = ZinIrTensor::IsZero(v12);
      uint64_t v11 = (void *)*((void *)this + 11);
    }
    else
    {
      int IsZero = 0;
    }
    if (*((void *)this + 12) - (void)v11 == 8)
    {
      int v19 = 1;
    }
    else
    {
      uint64_t v20 = (void *)v11[1];
      if (*(_DWORD *)(v20[8] + 8) == 29)
      {
        uint64_t v21 = (ZinIrTensor *)(*(uint64_t (**)(void *, void, void))(*v20 + 32))(v20, 0, 0);
        int v19 = ZinIrTensor::IsZero(v21);
      }
      else
      {
        int v19 = 0;
      }
    }
    return IsZero & v19;
  }
  else if (v4 == 1)
  {
    uint64_t v8 = (void *)*((void *)this + 11);
    if (*(_DWORD *)(*(void *)(*v8 + 64) + 8) == 29)
    {
      int8x16_t v9 = (ZinIrTensor *)(*(uint64_t (**)(void, void, void))(*(void *)*v8 + 32))(*v8, 0, 0);
      int v10 = ZinIrTensor::IsZero(v9);
      uint64_t v8 = (void *)*((void *)this + 11);
    }
    else
    {
      int v10 = 0;
    }
    long long v14 = (void *)v8[1];
    if (*(_DWORD *)(v14[8] + 8) == 29)
    {
      uint64_t v15 = (ZinIrTensor *)(*(uint64_t (**)(void *, void, void))(*v14 + 32))(v14, 0, 0);
      unsigned int v16 = ZinIrTensor::IsZero(v15);
    }
    else
    {
      unsigned int v16 = 0;
    }
    return v10 | v16;
  }
  else
  {
    if (v4) {
      return 0;
    }
    unint64_t v5 = (void *)*((void *)this + 11);
    if (*(_DWORD *)(*(void *)(*v5 + 64) + 8) == 29)
    {
      uint64_t v6 = (ZinIrTensor *)(*(uint64_t (**)(void, void, void))(*(void *)*v5 + 32))(*v5, 0, 0);
      int v7 = ZinIrTensor::IsZero(v6);
      unint64_t v5 = (void *)*((void *)this + 11);
    }
    else
    {
      int v7 = 0;
    }
    uint64_t v17 = (void *)v5[1];
    if (*(_DWORD *)(v17[8] + 8) == 29)
    {
      int v18 = (ZinIrTensor *)(*(uint64_t (**)(void *, void, void))(*v17 + 32))(v17, 0, 0);
      uint64_t result = ZinIrTensor::IsZero(v18);
    }
    else
    {
      uint64_t result = 0;
    }
    if (v7 && !*(unsigned char *)(v1 + 29)) {
      return 1;
    }
    if (result) {
      return !*(unsigned char *)(v1 + 28);
    }
  }
  return result;
}

long long *GetAddressDefaultValueMapping(int a1)
{
  uint64_t v5 = *MEMORY[0x263EF8340];
  switch(a1)
  {
    case 4:
      {
        uint64_t v2 = &GetAddressDefaultValueMapping(int)::reg_value_map;
          goto LABEL_44;
        GetAddressDefaultValueMapping(int)::reg_value_map = 0u;
        unk_26777E440 = 0u;
        dword_26777E450 = 1065353216;
        __cxa_atexit((void (*)(void *))std::unordered_map<unsigned int,unsigned int>::~unordered_map[abi:ne180100], &GetAddressDefaultValueMapping(int)::reg_value_map, &dword_210C72000);
        goto LABEL_43;
      }
      uint64_t result = &GetAddressDefaultValueMapping(int)::reg_value_map;
      break;
    case 5:
      {
        memcpy(__dst, &unk_211F007E8, 0x580uLL);
        std::unordered_map<unsigned int,unsigned int>::unordered_map((uint64_t)&GetAddressDefaultValueMapping(int)::reg_value_map, __dst, 176);
        uint64_t v2 = (long long *)&GetAddressDefaultValueMapping(int)::reg_value_map;
        __cxa_atexit((void (*)(void *))std::unordered_map<unsigned int,unsigned int>::~unordered_map[abi:ne180100], &GetAddressDefaultValueMapping(int)::reg_value_map, &dword_210C72000);
        goto LABEL_43;
      }
      uint64_t result = (long long *)&GetAddressDefaultValueMapping(int)::reg_value_map;
      break;
    case 6:
      {
        memcpy(__dst, &unk_211F00D68, 0x6E0uLL);
        std::unordered_map<unsigned int,unsigned int>::unordered_map((uint64_t)&GetAddressDefaultValueMapping(int)::reg_value_map, __dst, 220);
        uint64_t v2 = (long long *)&GetAddressDefaultValueMapping(int)::reg_value_map;
        __cxa_atexit((void (*)(void *))std::unordered_map<unsigned int,unsigned int>::~unordered_map[abi:ne180100], &GetAddressDefaultValueMapping(int)::reg_value_map, &dword_210C72000);
        goto LABEL_43;
      }
      uint64_t result = (long long *)&GetAddressDefaultValueMapping(int)::reg_value_map;
      break;
    case 7:
      {
        memcpy(__dst, &unk_211F01448, 0x7D8uLL);
        std::unordered_map<unsigned int,unsigned int>::unordered_map((uint64_t)&GetAddressDefaultValueMapping(int)::reg_value_map, __dst, 251);
        uint64_t v2 = (long long *)&GetAddressDefaultValueMapping(int)::reg_value_map;
        __cxa_atexit((void (*)(void *))std::unordered_map<unsigned int,unsigned int>::~unordered_map[abi:ne180100], &GetAddressDefaultValueMapping(int)::reg_value_map, &dword_210C72000);
        goto LABEL_43;
      }
      uint64_t result = (long long *)&GetAddressDefaultValueMapping(int)::reg_value_map;
      break;
    case 8:
      {
        memcpy(__dst, &unk_211F01C20, 0x598uLL);
        std::unordered_map<unsigned int,unsigned int>::unordered_map((uint64_t)&GetAddressDefaultValueMapping(int)::reg_value_map, __dst, 179);
        uint64_t v2 = (long long *)&GetAddressDefaultValueMapping(int)::reg_value_map;
        __cxa_atexit((void (*)(void *))std::unordered_map<unsigned int,unsigned int>::~unordered_map[abi:ne180100], &GetAddressDefaultValueMapping(int)::reg_value_map, &dword_210C72000);
        goto LABEL_43;
      }
      uint64_t result = (long long *)&GetAddressDefaultValueMapping(int)::reg_value_map;
      break;
    case 9:
      {
        memcpy(__dst, &unk_211F021B8, 0x878uLL);
        std::unordered_map<unsigned int,unsigned int>::unordered_map((uint64_t)&GetAddressDefaultValueMapping(int)::reg_value_map, __dst, 271);
        uint64_t v2 = (long long *)&GetAddressDefaultValueMapping(int)::reg_value_map;
        __cxa_atexit((void (*)(void *))std::unordered_map<unsigned int,unsigned int>::~unordered_map[abi:ne180100], &GetAddressDefaultValueMapping(int)::reg_value_map, &dword_210C72000);
        goto LABEL_43;
      }
      uint64_t result = (long long *)&GetAddressDefaultValueMapping(int)::reg_value_map;
      break;
    case 10:
      {
        memcpy(__dst, &unk_211F02A30, sizeof(__dst));
        std::unordered_map<unsigned int,unsigned int>::unordered_map((uint64_t)&GetAddressDefaultValueMapping(int)::reg_value_map, __dst, 274);
        uint64_t v2 = (long long *)&GetAddressDefaultValueMapping(int)::reg_value_map;
        __cxa_atexit((void (*)(void *))std::unordered_map<unsigned int,unsigned int>::~unordered_map[abi:ne180100], &GetAddressDefaultValueMapping(int)::reg_value_map, &dword_210C72000);
        goto LABEL_43;
      }
      uint64_t result = (long long *)&GetAddressDefaultValueMapping(int)::reg_value_map;
      break;
    case 11:
      {
        memcpy(__dst, &unk_211F032C0, 0x888uLL);
        std::unordered_map<unsigned int,unsigned int>::unordered_map((uint64_t)&GetAddressDefaultValueMapping(int)::reg_value_map, __dst, 273);
        uint64_t v2 = (long long *)&GetAddressDefaultValueMapping(int)::reg_value_map;
        __cxa_atexit((void (*)(void *))std::unordered_map<unsigned int,unsigned int>::~unordered_map[abi:ne180100], &GetAddressDefaultValueMapping(int)::reg_value_map, &dword_210C72000);
        goto LABEL_43;
      }
      uint64_t result = (long long *)&GetAddressDefaultValueMapping(int)::reg_value_map;
      break;
    case 15:
      {
        uint64_t v2 = &GetAddressDefaultValueMapping(int)::reg_value_map;
          goto LABEL_44;
        GetAddressDefaultValueMapping(int)::reg_value_map = 0u;
        unk_26777E3E0 = 0u;
        dword_26777E3F0 = 1065353216;
        __cxa_atexit((void (*)(void *))std::unordered_map<unsigned int,unsigned int>::~unordered_map[abi:ne180100], &GetAddressDefaultValueMapping(int)::reg_value_map, &dword_210C72000);
        goto LABEL_43;
      }
      uint64_t result = &GetAddressDefaultValueMapping(int)::reg_value_map;
      break;
    default:
      {
        uint64_t result = &GetAddressDefaultValueMapping(int)::reg_value_map;
      }
      else
      {
        uint64_t v2 = &GetAddressDefaultValueMapping(int)::reg_value_map;
        {
          GetAddressDefaultValueMapping(int)::reg_value_map = 0u;
          unk_26777E4A0 = 0u;
          dword_26777E4B0 = 1065353216;
          __cxa_atexit((void (*)(void *))std::unordered_map<unsigned int,unsigned int>::~unordered_map[abi:ne180100], &GetAddressDefaultValueMapping(int)::reg_value_map, &dword_210C72000);
LABEL_43:
          __cxa_guard_release(v3);
        }
LABEL_44:
        uint64_t result = v2;
      }
      break;
  }
  return result;
}

void sub_2112A6290(_Unwind_Exception *a1)
{
}

uint64_t std::unordered_map<unsigned int,unsigned int>::unordered_map(uint64_t a1, unsigned int *a2, uint64_t a3)
{
  *(_OWORD *)a1 = 0u;
  *(_OWORD *)(a1 + 16) = 0u;
  *(_DWORD *)(a1 + std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = 1065353216;
  if (a3)
  {
    uint64_t v5 = 8 * a3;
    do
    {
      std::__hash_table<std::__hash_value_type<unsigned int,unsigned int>,std::__unordered_map_hasher<unsigned int,std::__hash_value_type<unsigned int,unsigned int>,std::hash<unsigned int>,std::equal_to<unsigned int>,true>,std::__unordered_map_equal<unsigned int,std::__hash_value_type<unsigned int,unsigned int>,std::equal_to<unsigned int>,std::hash<unsigned int>,true>,std::allocator<std::__hash_value_type<unsigned int,unsigned int>>>::__emplace_unique_key_args<unsigned int,std::pair<unsigned int const,unsigned int> const&>(a1, a2, a2);
      a2 += 2;
      v5 -= 8;
    }
    while (v5);
  }
  return a1;
}

void sub_2112A63A0(_Unwind_Exception *a1)
{
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table(v1);
  _Unwind_Resume(a1);
}

void *std::__hash_table<std::__hash_value_type<unsigned int,unsigned int>,std::__unordered_map_hasher<unsigned int,std::__hash_value_type<unsigned int,unsigned int>,std::hash<unsigned int>,std::equal_to<unsigned int>,true>,std::__unordered_map_equal<unsigned int,std::__hash_value_type<unsigned int,unsigned int>,std::equal_to<unsigned int>,std::hash<unsigned int>,true>,std::allocator<std::__hash_value_type<unsigned int,unsigned int>>>::__emplace_unique_key_args<unsigned int,std::pair<unsigned int const,unsigned int> const&>(uint64_t a1, unsigned int *a2, void *a3)
{
  unint64_t v6 = *a2;
  unint64_t v7 = *(void *)(a1 + 8);
  if (v7)
  {
    uint8x8_t v8 = (uint8x8_t)vcnt_s8((int8x8_t)v7);
    v8.i16[0] = vaddlv_u8(v8);
    if (v8.u32[0] > 1uLL)
    {
      unint64_t v3 = *a2;
      if (v7 <= v6) {
        unint64_t v3 = v6 % v7;
      }
    }
    else
    {
      unint64_t v3 = (v7 - 1) & v6;
    }
    int8x16_t v9 = *(void ***)(*(void *)a1 + 8 * v3);
    if (v9)
    {
      int v10 = *v9;
      if (*v9)
      {
        do
        {
          unint64_t v11 = v10[1];
          if (v11 == v6)
          {
            if (*((_DWORD *)v10 + 4) == v6) {
              return v10;
            }
          }
          else
          {
            if (v8.u32[0] > 1uLL)
            {
              if (v11 >= v7) {
                v11 %= v7;
              }
            }
            else
            {
              v11 &= v7 - 1;
            }
            if (v11 != v3) {
              break;
            }
          }
          int v10 = (void *)*v10;
        }
        while (v10);
      }
    }
  }
  int v10 = operator new(0x18uLL);
  *int v10 = 0;
  v10[1] = v6;
  int8x16_t v10[2] = *a3;
  float v12 = (float)(unint64_t)(*(void *)(a1 + 24) + 1);
  float v13 = *(float *)(a1 + 32);
  if (!v7 || (float)(v13 * (float)v7) < v12)
  {
    BOOL v14 = 1;
    if (v7 >= 3) {
      BOOL v14 = (v7 & (v7 - 1)) != 0;
    }
    unint64_t v15 = v14 | (2 * v7);
    unint64_t v16 = vcvtps_u32_f32(v12 / v13);
    if (v15 <= v16) {
      size_t v17 = v16;
    }
    else {
      size_t v17 = v15;
    }
    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::__rehash<true>(a1, v17);
    unint64_t v7 = *(void *)(a1 + 8);
    if ((v7 & (v7 - 1)) != 0)
    {
      if (v7 <= v6) {
        unint64_t v3 = v6 % v7;
      }
      else {
        unint64_t v3 = v6;
      }
    }
    else
    {
      unint64_t v3 = (v7 - 1) & v6;
    }
  }
  uint64_t v18 = *(void *)a1;
  int v19 = *(void **)(*(void *)a1 + 8 * v3);
  if (v19)
  {
    *int v10 = *v19;
LABEL_38:
    void *v19 = v10;
    goto LABEL_39;
  }
  *int v10 = *(void *)(a1 + 16);
  *(void *)(a1 + 16) = v10;
  *(void *)(v18 + 8 * v3) = a1 + 16;
  if (*v10)
  {
    unint64_t v20 = *(void *)(*v10 + 8);
    if ((v7 & (v7 - 1)) != 0)
    {
      if (v20 >= v7) {
        v20 %= v7;
      }
    }
    else
    {
      v20 &= v7 - 1;
    }
    int v19 = (void *)(*(void *)a1 + 8 * v20);
    goto LABEL_38;
  }
LABEL_39:
  ++*(void *)(a1 + 24);
  return v10;
}

void sub_2112A65C0(_Unwind_Exception *a1)
{
  operator delete(v1);
  _Unwind_Resume(a1);
}

void ZinIrLiveIOManager::ZinIrLiveIOManager(ZinIrLiveIOManager *this, const ZinIrHalParameters *a2)
{
  v22[3] = *MEMORY[0x263EF8340];
  *(void *)this = a2;
  unint64_t v3 = (char *)this + 16;
  *((void *)this + 1) = 0;
  unint64_t v15 = 0;
  uint64_t v16 = 0;
  BOOL v14 = &v15;
  int v17 = 0;
  std::map<std::string,ZinIrIOInfo>::map[abi:ne180100](v18, (uint64_t)&v14);
  float v12 = 0;
  uint64_t v13 = 0;
  unint64_t v11 = &v12;
  int v19 = 1;
  std::map<std::string,ZinIrIOInfo>::map[abi:ne180100](v20, (uint64_t)&v11);
  int8x16_t v9 = 0;
  uint64_t v10 = 0;
  uint8x8_t v8 = &v9;
  int v21 = 2;
  std::map<std::string,ZinIrIOInfo>::map[abi:ne180100](v22, (uint64_t)&v8);
  std::map<IOType,std::map<std::string,ZinIrIOInfo>>::map[abi:ne180100]((uint64_t)v3, &v17, 3);
  for (uint64_t i = 0; i != -12; i -= 4)
    std::__tree<std::__value_type<std::string,ZinIrIOInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrIOInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrIOInfo>>>::destroy((uint64_t)&v22[i], (void *)v22[i + 1]);
  std::__tree<std::__value_type<std::string,ZinIrIOInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrIOInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrIOInfo>>>::destroy((uint64_t)&v8, v9);
  std::__tree<std::__value_type<std::string,ZinIrIOInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrIOInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrIOInfo>>>::destroy((uint64_t)&v11, v12);
  std::__tree<std::__value_type<std::string,ZinIrIOInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrIOInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrIOInfo>>>::destroy((uint64_t)&v14, v15);
  unint64_t v15 = 0;
  uint64_t v16 = 0;
  BOOL v14 = &v15;
  int v17 = 0;
  std::set<std::string>::set[abi:ne180100](v18, (uint64_t)&v14);
  float v12 = 0;
  uint64_t v13 = 0;
  unint64_t v11 = &v12;
  int v19 = 1;
  std::set<std::string>::set[abi:ne180100](v20, (uint64_t)&v11);
  int8x16_t v9 = 0;
  uint64_t v10 = 0;
  uint8x8_t v8 = &v9;
  int v21 = 2;
  std::set<std::string>::set[abi:ne180100](v22, (uint64_t)&v8);
  std::map<IOType,std::set<std::string>>::map[abi:ne180100]((uint64_t)this + 40, &v17, 3);
  for (uint64_t j = 0; j != -12; j -= 4)
    std::__tree<std::__value_type<std::string,SpatialSplitMode>,std::__map_value_compare<std::string,std::__value_type<std::string,SpatialSplitMode>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,SpatialSplitMode>>>::destroy((uint64_t)&v22[j], (char *)v22[j + 1]);
  std::__tree<std::__value_type<std::string,SpatialSplitMode>,std::__map_value_compare<std::string,std::__value_type<std::string,SpatialSplitMode>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,SpatialSplitMode>>>::destroy((uint64_t)&v8, v9);
  std::__tree<std::__value_type<std::string,SpatialSplitMode>,std::__map_value_compare<std::string,std::__value_type<std::string,SpatialSplitMode>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,SpatialSplitMode>>>::destroy((uint64_t)&v11, v12);
  std::__tree<std::__value_type<std::string,SpatialSplitMode>,std::__map_value_compare<std::string,std::__value_type<std::string,SpatialSplitMode>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,SpatialSplitMode>>>::destroy((uint64_t)&v14, v15);
  unint64_t v15 = 0;
  uint64_t v16 = 0;
  BOOL v14 = &v15;
  int v17 = 0;
  std::set<std::string>::set[abi:ne180100](v18, (uint64_t)&v14);
  float v12 = 0;
  uint64_t v13 = 0;
  unint64_t v11 = &v12;
  int v19 = 1;
  std::set<std::string>::set[abi:ne180100](v20, (uint64_t)&v11);
  int8x16_t v9 = 0;
  uint64_t v10 = 0;
  uint8x8_t v8 = &v9;
  int v21 = 2;
  std::set<std::string>::set[abi:ne180100](v22, (uint64_t)&v8);
  std::map<IOType,std::set<std::string>>::map[abi:ne180100]((uint64_t)this + 64, &v17, 3);
  for (uint64_t k = 0; k != -12; k -= 4)
    std::__tree<std::__value_type<std::string,SpatialSplitMode>,std::__map_value_compare<std::string,std::__value_type<std::string,SpatialSplitMode>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,SpatialSplitMode>>>::destroy((uint64_t)&v22[k], (char *)v22[k + 1]);
  std::__tree<std::__value_type<std::string,SpatialSplitMode>,std::__map_value_compare<std::string,std::__value_type<std::string,SpatialSplitMode>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,SpatialSplitMode>>>::destroy((uint64_t)&v8, v9);
  std::__tree<std::__value_type<std::string,SpatialSplitMode>,std::__map_value_compare<std::string,std::__value_type<std::string,SpatialSplitMode>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,SpatialSplitMode>>>::destroy((uint64_t)&v11, v12);
  std::__tree<std::__value_type<std::string,SpatialSplitMode>,std::__map_value_compare<std::string,std::__value_type<std::string,SpatialSplitMode>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,SpatialSplitMode>>>::destroy((uint64_t)&v14, v15);
  unint64_t v15 = 0;
  uint64_t v16 = 0;
  BOOL v14 = &v15;
  int v17 = 0;
  std::set<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>::set[abi:ne180100](v18, (uint64_t)&v14);
  float v12 = 0;
  uint64_t v13 = 0;
  unint64_t v11 = &v12;
  int v19 = 1;
  std::set<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>::set[abi:ne180100](v20, (uint64_t)&v11);
  int8x16_t v9 = 0;
  uint64_t v10 = 0;
  uint8x8_t v8 = &v9;
  int v21 = 2;
  std::set<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>::set[abi:ne180100](v22, (uint64_t)&v8);
  std::map<IOType,std::set<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>>::map[abi:ne180100]((uint64_t)this + 88, &v17, 3);
  for (uint64_t m = 0; m != -12; m -= 4)
    std::__tree<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>::destroy((uint64_t)&v22[m], (void *)v22[m + 1]);
  std::__tree<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>::destroy((uint64_t)&v8, v9);
  std::__tree<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>::destroy((uint64_t)&v11, v12);
  std::__tree<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>::destroy((uint64_t)&v14, v15);
  *((void *)this + 15) = 0;
  *((void *)this + 14) = (char *)this + 120;
  *((void *)this + 18) = 0;
  *((void *)this + 16) = 0;
  *((void *)this + 17) = (char *)this + 144;
  *((void *)this + 21) = 0;
  *((void *)this + 19) = 0;
  *((void *)this + 20) = (char *)this + 168;
  *((void *)this + 24) = 0;
  *((void *)this + 22) = 0;
  *((void *)this + 23) = (char *)this + 192;
  *((void *)this + 27) = 0;
  *((void *)this + 25) = 0;
  *((void *)this + 26) = (char *)this + 216;
  *((void *)this + 30) = 0;
  *((void *)this + 28) = 0;
  *((void *)this + 29) = (char *)this + 240;
  *((void *)this + 33) = 0;
  *((void *)this + 34) = 0;
  *((void *)this + 31) = 0;
  *((void *)this + std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = (char *)this + 264;
}

void sub_2112A69F8(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, char a11, void *a12, uint64_t a13, char a14, void *a15, uint64_t a16, char a17, void *a18)
{
  for (uint64_t i = 0; i != -96; i -= 32)
    std::__tree<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>::destroy(v23 + i + 72, *(void **)(v23 + i + 80));
  std::__tree<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>::destroy((uint64_t)&a11, a12);
  std::__tree<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>::destroy((uint64_t)&a14, a15);
  std::__tree<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>::destroy((uint64_t)&a17, a18);
  std::__tree<std::__value_type<IOType,std::set<std::string>>,std::__map_value_compare<IOType,std::__value_type<IOType,std::set<std::string>>,std::less<IOType>,true>,std::allocator<std::__value_type<IOType,std::set<std::string>>>>::destroy(v22, v19[9]);
  std::__tree<std::__value_type<IOType,std::set<std::string>>,std::__map_value_compare<IOType,std::__value_type<IOType,std::set<std::string>>,std::less<IOType>,true>,std::allocator<std::__value_type<IOType,std::set<std::string>>>>::destroy(v21, v19[6]);
  std::__tree<std::__value_type<IOType,std::map<std::string,ZinIrIOInfo>>,std::__map_value_compare<IOType,std::__value_type<IOType,std::map<std::string,ZinIrIOInfo>>,std::less<IOType>,true>,std::allocator<std::__value_type<IOType,std::map<std::string,ZinIrIOInfo>>>>::destroy(v20, v19[3]);
  std::unique_ptr<ZinIrBindings>::reset[abi:ne180100](v18, 0);
  _Unwind_Resume(a1);
}

void sub_2112A6C3C(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, char a11, void *a12, uint64_t a13, char a14, void *a15, uint64_t a16, char a17, void *a18)
{
  for (uint64_t i = 0; i != -96; i -= 32)
    std::__tree<std::__value_type<std::string,ZinIrIOInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrIOInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrIOInfo>>>::destroy(v18 + i + 72, *(void **)(v18 + i + 80));
  std::__tree<std::__value_type<std::string,ZinIrIOInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrIOInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrIOInfo>>>::destroy((uint64_t)&a11, a12);
  std::__tree<std::__value_type<std::string,ZinIrIOInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrIOInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrIOInfo>>>::destroy((uint64_t)&a14, a15);
  std::__tree<std::__value_type<std::string,ZinIrIOInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrIOInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrIOInfo>>>::destroy((uint64_t)&a17, a18);
  JUMPOUT(0x2112A6C28);
}

uint64_t ZinIrLiveIOManager::ParseLiveInputs(ZinIrLiveIOManager *this, CFDictionaryRef theDict, CFArrayRef *a3)
{
  CFArrayRef Value = (const __CFArray *)CFDictionaryGetValue(theDict, @"Inputs");
  if (Value && (CFArrayRef v6 = Value, v7 = CFGetTypeID(Value), v7 == CFArrayGetTypeID()))
  {
    uint64_t v37 = 0;
    unint64_t v38 = 0;
    unint64_t v39 = 0;
    CFIndex Count = CFArrayGetCount(v6);
    if (Count < 1)
    {
LABEL_17:
      uint64_t v23 = ZinIrLiveIOManager::SetLiveIOs((uint64_t)this, 0, &v37);
    }
    else
    {
      CFIndex v8 = 0;
      while (1)
      {
        LODWORD(v29[0]) = 0;
        memset(v28, 0, sizeof(v28));
        *(_OWORD *)size_t v27 = 0u;
        *(void *)&long long v9 = -1;
        *((void *)&v9 + 1) = -1;
        *(_OWORD *)((char *)v29 + 8) = v9;
        *(_OWORD *)((char *)&v29[1] + 8) = v9;
        *((void *)&v29[2] + 1) = -1;
        LOBYTE(v30) = 0;
        BYTE8(vstd::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = 0;
        *(void *)size_t v35 = -1;
        long long v33 = v9;
        v34[0] = v9;
        *(_OWORD *)((char *)v34 + 12) = v9;
        v35[8] = 0;
        memset(&v35[12], 0, 28);
        LODWORD(v36) = 5;
        *((void *)&v36 + 1) = -1;
        CFStringRef ValueAtIndex = (const __CFString *)CFArrayGetValueAtIndex(v6, v8);
        CFStringRef v11 = ValueAtIndex;
        if (!ValueAtIndex) {
          break;
        }
        CFTypeID v12 = CFGetTypeID(ValueAtIndex);
        if (v12 != CFStringGetTypeID() || ZinParseInput(theDict, v11, (ZinIrIOInfo *)v27, a3)) {
          break;
        }
        unint64_t v13 = v38;
        if (v38 >= v39)
        {
          unint64_t v38 = std::vector<ZinIrIOInfo>::__emplace_back_slow_path<ZinIrIOInfo>(&v37, (long long *)v27);
          if (*(void *)&v35[16])
          {
            *(void *)&v35[24] = *(void *)&v35[16];
            operator delete(*(void **)&v35[16]);
          }
        }
        else
        {
          long long v14 = *(_OWORD *)v27;
          *(void **)(v38 + 16) = v28[0];
          *(_OWORD *)unint64_t v13 = v14;
          v27[1] = 0;
          v28[0] = 0;
          v27[0] = 0;
          unint64_t v15 = v28[3];
          *(_OWORD *)(v13 + 24) = *(_OWORD *)&v28[1];
          *(void *)(v13 + 40) = v15;
          memset(&v28[1], 0, 24);
          long long v16 = v29[1];
          *(_OWORD *)(v13 + 48) = v29[0];
          *(_OWORD *)(v13 + 64) = v16;
          long long v17 = v29[2];
          long long v18 = v30;
          long long v19 = v32;
          *(_OWORD *)(v13 + 112) = v31;
          *(_OWORD *)(v13 + 128) = v19;
          *(_OWORD *)(v13 + 80) = v17;
          *(_OWORD *)(v13 + 96) = v18;
          long long v20 = v33;
          long long v21 = v34[0];
          long long v22 = *(_OWORD *)v35;
          *(_OWORD *)(v13 + 176) = v34[1];
          *(_OWORD *)(v13 + 192) = v22;
          *(_OWORD *)(v13 + 144) = v20;
          *(_OWORD *)(v13 + 160) = v21;
          *(void *)(v13 + 208) = 0;
          *(void *)(v13 + 216) = 0;
          *(void *)(v13 + 224) = 0;
          *(_OWORD *)(v13 + 208) = *(_OWORD *)&v35[16];
          *(void *)(v13 + 224) = *(void *)&v35[32];
          memset(&v35[16], 0, 24);
          *(_OWORD *)(v13 + 2std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = v36;
          unint64_t v38 = v13 + 248;
        }
        if (SHIBYTE(v28[3]) < 0) {
          operator delete(v28[1]);
        }
        if (SHIBYTE(v28[0]) < 0) {
          operator delete(v27[0]);
        }
        if (Count == ++v8) {
          goto LABEL_17;
        }
      }
      ZinIrNetworkStatus::SetError(a3, @"InvalidInputSyntax");
      if (*(void *)&v35[16])
      {
        *(void *)&v35[24] = *(void *)&v35[16];
        operator delete(*(void **)&v35[16]);
      }
      if (SHIBYTE(v28[3]) < 0) {
        operator delete(v28[1]);
      }
      if (SHIBYTE(v28[0]) < 0) {
        operator delete(v27[0]);
      }
      uint64_t v23 = 0;
    }
    v27[0] = &v37;
    std::vector<ZinIrIOInfo>::__destroy_vector::operator()[abi:ne180100]((void ***)v27);
  }
  else
  {
    ZinIrNetworkStatus::SetError(a3, @"InvalidInputSyntax");
    return 0;
  }
  return v23;
}

void sub_2112A6FC4(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, void **a15)
{
  ZinIrIOInfo::~ZinIrIOInfo((ZinIrIOInfo *)&a15);
  a15 = (void **)(v15 - 112);
  std::vector<ZinIrIOInfo>::__destroy_vector::operator()[abi:ne180100](&a15);
  _Unwind_Resume(a1);
}

uint64_t ZinIrLiveIOManager::SetLiveIOs(uint64_t a1, int a2, uint64_t *a3)
{
  uint64_t v24 = *MEMORY[0x263EF8340];
  int v22 = a2;
  uint64_t v5 = std::map<ZinIrDimension,unsigned long>::at(a1 + 16, &v22);
  CFArrayRef v6 = std::map<ZinIrDimension,unsigned long>::at(a1 + 40, &v22);
  CFTypeID v7 = std::map<ZinIrDimension,unsigned long>::at(a1 + 64, &v22);
  uint64_t v8 = *a3;
  uint64_t v9 = a3[1];
  if (*a3 == v9) {
    return 1;
  }
  uint64_t v10 = v7;
  while (v5 + 1 == (uint64_t *)std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::find<std::string>((uint64_t)v5, (void **)v8))
  {
    *(void *)uint8_t buf = v8;
    CFStringRef v11 = std::__tree<std::__value_type<std::string,ZinIrIOInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrIOInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrIOInfo>>>::__emplace_unique_key_args<std::string,std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>((uint64_t **)v5, (void **)v8, (uint64_t)&std::piecewise_construct, (long long **)buf);
    std::string::operator=((std::string *)(v11 + 7), (const std::string *)v8);
    std::string::operator=((std::string *)(v11 + 10), (const std::string *)(v8 + 24));
    long long v12 = *(_OWORD *)(v8 + 64);
    *(_OWORD *)(v11 + 13) = *(_OWORD *)(v8 + 48);
    *(_OWORD *)(v11 + 15) = v12;
    long long v13 = *(_OWORD *)(v8 + 112);
    long long v14 = *(_OWORD *)(v8 + 128);
    long long v15 = *(_OWORD *)(v8 + 96);
    *(_OWORD *)(v11 + 17) = *(_OWORD *)(v8 + 80);
    *(_OWORD *)(v11 + 23) = v14;
    *(_OWORD *)(v11 + 21) = v13;
    *(_OWORD *)(v11 + 19) = v15;
    long long v16 = *(_OWORD *)(v8 + 176);
    long long v17 = *(_OWORD *)(v8 + 192);
    long long v18 = *(_OWORD *)(v8 + 160);
    *(_OWORD *)(v11 + 25) = *(_OWORD *)(v8 + 144);
    *(_OWORD *)(v11 + 31) = v17;
    *(_OWORD *)(v11 + 29) = v16;
    *(_OWORD *)(v11 + 27) = v18;
    if ((uint64_t *)v8 != v11 + 7) {
      std::vector<LayerAndUsageInfo>::__assign_with_size[abi:ne180100]<LayerAndUsageInfo*,LayerAndUsageInfo*>((char *)v11 + 264, *(char **)(v8 + 208), *(void *)(v8 + 216), (uint64_t)(*(void *)(v8 + 216) - *(void *)(v8 + 208)) >> 4);
    }
    *((_OWORD *)v11 + 18) = *(_OWORD *)(v8 + 232);
    if (*(unsigned char *)(v8 + 200)) {
      long long v19 = (uint64_t **)v6;
    }
    else {
      long long v19 = (uint64_t **)v10;
    }
    std::__tree<std::string>::__emplace_unique_key_args<std::string,std::string const&>(v19, (void **)v8, v8);
    v8 += 248;
    if (v8 == v9) {
      return 1;
    }
  }
  BOOL v21 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_DEFAULT);
  uint64_t result = 0;
  if (v21)
  {
    if (*(char *)(v8 + 23) < 0) {
      uint64_t v8 = *(void *)v8;
    }
    *(_DWORD *)uint8_t buf = 136315138;
    *(void *)&uint8_t buf[4] = v8;
    _os_log_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_DEFAULT, "Duplicate livein: %s\n", buf, 0xCu);
    return 0;
  }
  return result;
}

uint64_t ZinIrLiveIOManager::ParseLiveStates(ZinIrLiveIOManager *this, CFDictionaryRef theDict, CFArrayRef *a3)
{
  CFArrayRef Value = (const __CFArray *)CFDictionaryGetValue(theDict, @"States");
  if (!Value) {
    return 1;
  }
  CFArrayRef v6 = Value;
  CFTypeID v7 = CFGetTypeID(Value);
  if (v7 != CFArrayGetTypeID()) {
    return 1;
  }
  uint64_t v37 = 0;
  unint64_t v38 = 0;
  unint64_t v39 = 0;
  CFIndex Count = CFArrayGetCount(v6);
  if (Count < 1)
  {
LABEL_17:
    uint64_t v23 = ZinIrLiveIOManager::SetLiveIOs((uint64_t)this, 2, &v37);
  }
  else
  {
    CFIndex v8 = 0;
    while (1)
    {
      LODWORD(v29[0]) = 0;
      memset(v28, 0, sizeof(v28));
      *(_OWORD *)size_t v27 = 0u;
      *(void *)&long long v9 = -1;
      *((void *)&v9 + 1) = -1;
      *(_OWORD *)((char *)v29 + 8) = v9;
      *(_OWORD *)((char *)&v29[1] + 8) = v9;
      *((void *)&v29[2] + 1) = -1;
      LOBYTE(v30) = 0;
      BYTE8(vstd::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = 0;
      *(void *)size_t v35 = -1;
      long long v33 = v9;
      v34[0] = v9;
      *(_OWORD *)((char *)v34 + 12) = v9;
      v35[8] = 0;
      memset(&v35[12], 0, 28);
      LODWORD(v36) = 5;
      *((void *)&v36 + 1) = -1;
      CFStringRef ValueAtIndex = (const __CFString *)CFArrayGetValueAtIndex(v6, v8);
      CFStringRef v11 = ValueAtIndex;
      if (!ValueAtIndex) {
        break;
      }
      CFTypeID v12 = CFGetTypeID(ValueAtIndex);
      if (v12 != CFStringGetTypeID() || ZinParseState(theDict, v11, (ZinIrIOInfo *)v27, a3)) {
        break;
      }
      unint64_t v13 = v38;
      if (v38 >= v39)
      {
        unint64_t v38 = std::vector<ZinIrIOInfo>::__emplace_back_slow_path<ZinIrIOInfo>(&v37, (long long *)v27);
        if (*(void *)&v35[16])
        {
          *(void *)&v35[24] = *(void *)&v35[16];
          operator delete(*(void **)&v35[16]);
        }
      }
      else
      {
        long long v14 = *(_OWORD *)v27;
        *(void **)(v38 + 16) = v28[0];
        *(_OWORD *)unint64_t v13 = v14;
        v27[1] = 0;
        v28[0] = 0;
        v27[0] = 0;
        long long v15 = v28[3];
        *(_OWORD *)(v13 + 24) = *(_OWORD *)&v28[1];
        *(void *)(v13 + 40) = v15;
        memset(&v28[1], 0, 24);
        long long v16 = v29[1];
        *(_OWORD *)(v13 + 48) = v29[0];
        *(_OWORD *)(v13 + 64) = v16;
        long long v17 = v29[2];
        long long v18 = v30;
        long long v19 = v32;
        *(_OWORD *)(v13 + 112) = v31;
        *(_OWORD *)(v13 + 128) = v19;
        *(_OWORD *)(v13 + 80) = v17;
        *(_OWORD *)(v13 + 96) = v18;
        long long v20 = v33;
        long long v21 = v34[0];
        long long v22 = *(_OWORD *)v35;
        *(_OWORD *)(v13 + 176) = v34[1];
        *(_OWORD *)(v13 + 192) = v22;
        *(_OWORD *)(v13 + 144) = v20;
        *(_OWORD *)(v13 + 160) = v21;
        *(void *)(v13 + 208) = 0;
        *(void *)(v13 + 216) = 0;
        *(void *)(v13 + 224) = 0;
        *(_OWORD *)(v13 + 208) = *(_OWORD *)&v35[16];
        *(void *)(v13 + 224) = *(void *)&v35[32];
        memset(&v35[16], 0, 24);
        *(_OWORD *)(v13 + 2std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = v36;
        unint64_t v38 = v13 + 248;
      }
      if (SHIBYTE(v28[3]) < 0) {
        operator delete(v28[1]);
      }
      if (SHIBYTE(v28[0]) < 0) {
        operator delete(v27[0]);
      }
      if (Count == ++v8) {
        goto LABEL_17;
      }
    }
    ZinIrNetworkStatus::SetError(a3, @"InvalidStateSyntax");
    if (*(void *)&v35[16])
    {
      *(void *)&v35[24] = *(void *)&v35[16];
      operator delete(*(void **)&v35[16]);
    }
    if (SHIBYTE(v28[3]) < 0) {
      operator delete(v28[1]);
    }
    if (SHIBYTE(v28[0]) < 0) {
      operator delete(v27[0]);
    }
    uint64_t v23 = 0;
  }
  v27[0] = &v37;
  std::vector<ZinIrIOInfo>::__destroy_vector::operator()[abi:ne180100]((void ***)v27);
  return v23;
}

void sub_2112A74BC(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, void **a15)
{
  ZinIrIOInfo::~ZinIrIOInfo((ZinIrIOInfo *)&a15);
  a15 = (void **)(v15 - 112);
  std::vector<ZinIrIOInfo>::__destroy_vector::operator()[abi:ne180100](&a15);
  _Unwind_Resume(a1);
}

uint64_t ZinIrLiveIOManager::ParseLiveOutputs(ZinIrLiveIOManager *this, CFDictionaryRef theDict, CFArrayRef *a3)
{
  CFArrayRef Value = (const __CFArray *)CFDictionaryGetValue(theDict, @"Outputs");
  if (Value && (CFArrayRef v6 = Value, v7 = CFGetTypeID(Value), v7 == CFArrayGetTypeID()))
  {
    uint64_t v37 = 0;
    unint64_t v38 = 0;
    unint64_t v39 = 0;
    CFIndex Count = CFArrayGetCount(v6);
    if (Count < 1)
    {
LABEL_17:
      uint64_t v23 = ZinIrLiveIOManager::SetLiveIOs((uint64_t)this, 1, &v37);
    }
    else
    {
      CFIndex v8 = 0;
      while (1)
      {
        LODWORD(v29[0]) = 0;
        memset(v28, 0, sizeof(v28));
        *(_OWORD *)size_t v27 = 0u;
        *(void *)&long long v9 = -1;
        *((void *)&v9 + 1) = -1;
        *(_OWORD *)((char *)v29 + 8) = v9;
        *(_OWORD *)((char *)&v29[1] + 8) = v9;
        *((void *)&v29[2] + 1) = -1;
        LOBYTE(v30) = 0;
        BYTE8(vstd::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = 0;
        *(void *)size_t v35 = -1;
        long long v33 = v9;
        v34[0] = v9;
        *(_OWORD *)((char *)v34 + 12) = v9;
        v35[8] = 0;
        memset(&v35[12], 0, 28);
        LODWORD(v36) = 5;
        *((void *)&v36 + 1) = -1;
        CFStringRef ValueAtIndex = (const __CFString *)CFArrayGetValueAtIndex(v6, v8);
        CFStringRef v11 = ValueAtIndex;
        if (!ValueAtIndex) {
          break;
        }
        CFTypeID v12 = CFGetTypeID(ValueAtIndex);
        if (v12 != CFStringGetTypeID() || ZinParseOutput(theDict, v11, (ZinIrIOInfo *)v27, a3)) {
          break;
        }
        unint64_t v13 = v38;
        if (v38 >= v39)
        {
          unint64_t v38 = std::vector<ZinIrIOInfo>::__emplace_back_slow_path<ZinIrIOInfo>(&v37, (long long *)v27);
          if (*(void *)&v35[16])
          {
            *(void *)&v35[24] = *(void *)&v35[16];
            operator delete(*(void **)&v35[16]);
          }
        }
        else
        {
          long long v14 = *(_OWORD *)v27;
          *(void **)(v38 + 16) = v28[0];
          *(_OWORD *)unint64_t v13 = v14;
          v27[1] = 0;
          v28[0] = 0;
          v27[0] = 0;
          uint64_t v15 = v28[3];
          *(_OWORD *)(v13 + 24) = *(_OWORD *)&v28[1];
          *(void *)(v13 + 40) = v15;
          memset(&v28[1], 0, 24);
          long long v16 = v29[1];
          *(_OWORD *)(v13 + 48) = v29[0];
          *(_OWORD *)(v13 + 64) = v16;
          long long v17 = v29[2];
          long long v18 = v30;
          long long v19 = v32;
          *(_OWORD *)(v13 + 112) = v31;
          *(_OWORD *)(v13 + 128) = v19;
          *(_OWORD *)(v13 + 80) = v17;
          *(_OWORD *)(v13 + 96) = v18;
          long long v20 = v33;
          long long v21 = v34[0];
          long long v22 = *(_OWORD *)v35;
          *(_OWORD *)(v13 + 176) = v34[1];
          *(_OWORD *)(v13 + 192) = v22;
          *(_OWORD *)(v13 + 144) = v20;
          *(_OWORD *)(v13 + 160) = v21;
          *(void *)(v13 + 208) = 0;
          *(void *)(v13 + 216) = 0;
          *(void *)(v13 + 224) = 0;
          *(_OWORD *)(v13 + 208) = *(_OWORD *)&v35[16];
          *(void *)(v13 + 224) = *(void *)&v35[32];
          memset(&v35[16], 0, 24);
          *(_OWORD *)(v13 + 2std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = v36;
          unint64_t v38 = v13 + 248;
        }
        if (SHIBYTE(v28[3]) < 0) {
          operator delete(v28[1]);
        }
        if (SHIBYTE(v28[0]) < 0) {
          operator delete(v27[0]);
        }
        if (Count == ++v8) {
          goto LABEL_17;
        }
      }
      ZinIrNetworkStatus::SetError(a3, @"InvalidOutputSyntax");
      if (*(void *)&v35[16])
      {
        *(void *)&v35[24] = *(void *)&v35[16];
        operator delete(*(void **)&v35[16]);
      }
      if (SHIBYTE(v28[3]) < 0) {
        operator delete(v28[1]);
      }
      if (SHIBYTE(v28[0]) < 0) {
        operator delete(v27[0]);
      }
      uint64_t v23 = 0;
    }
    v27[0] = &v37;
    std::vector<ZinIrIOInfo>::__destroy_vector::operator()[abi:ne180100]((void ***)v27);
  }
  else
  {
    ZinIrNetworkStatus::SetError(a3, @"InvalidOutputSyntax");
    return 0;
  }
  return v23;
}

void sub_2112A77C0(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, void **a15)
{
  ZinIrIOInfo::~ZinIrIOInfo((ZinIrIOInfo *)&a15);
  a15 = (void **)(v15 - 112);
  std::vector<ZinIrIOInfo>::__destroy_vector::operator()[abi:ne180100](&a15);
  _Unwind_Resume(a1);
}

uint64_t ZinIrLiveIOManager::ParseLiveInputParams(ZinIrLiveIOManager *this, CFDictionaryRef theDict, CFArrayRef *a3)
{
  uint64_t v26 = *MEMORY[0x263EF8340];
  CFArrayRef Value = (const __CFArray *)CFDictionaryGetValue(theDict, @"InputParams");
  if (Value)
  {
    CFArrayRef v7 = Value;
    CFTypeID v8 = CFGetTypeID(Value);
    if (v8 == CFArrayGetTypeID())
    {
      CFIndex Count = CFArrayGetCount(v7);
      CFIndex v10 = Count - 1;
      if (Count >= 1)
      {
        CFIndex v11 = 0;
        CFTypeID v12 = (uint64_t **)((char *)this + 160);
        unint64_t v13 = (void **)((char *)this + 168);
        long long v14 = &_os_log_internal;
        while (1)
        {
          memset(&__p, 0, sizeof(__p));
          int v24 = 0;
          CFStringRef ValueAtIndex = CFArrayGetValueAtIndex(v7, v11);
          uint64_t v16 = (uint64_t)ValueAtIndex;
          if (ValueAtIndex)
          {
            CFTypeID v17 = CFGetTypeID(ValueAtIndex);
            if (v17 != CFStringGetTypeID()
              || ZinParseInputParam(theDict, (CFStringRef)v16, (uint64_t)&__p, a3))
            {
              goto LABEL_8;
            }
            if (v13 == std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::find<std::string>((uint64_t)v12, (void **)&__p.__r_.__value_.__l.__data_))
            {
              *(void *)uint8_t buf = &__p;
              long long v21 = std::__tree<std::__value_type<std::string,ZinIrInputParamInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrInputParamInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrInputParamInfo>>>::__emplace_unique_key_args<std::string,std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>(v12, (void **)&__p.__r_.__value_.__l.__data_, (uint64_t)&std::piecewise_construct, (long long **)buf);
              std::string::operator=((std::string *)(v21 + 7), &__p);
              *((_DWORD *)v21 + 20) = v24;
              uint64_t v16 = 1;
              goto LABEL_9;
            }
            uint64_t v16 = 0;
            if (os_log_type_enabled(v14, OS_LOG_TYPE_DEFAULT)) {
              break;
            }
          }
LABEL_9:
          if (SHIBYTE(__p.__r_.__value_.__r.__words[2]) < 0) {
            operator delete(__p.__r_.__value_.__l.__data_);
          }
          if (v10 == v11++) {
            char v19 = 0;
          }
          else {
            char v19 = v16;
          }
          if ((v19 & 1) == 0) {
            return v16;
          }
        }
        p_p = &__p;
        if ((__p.__r_.__value_.__r.__words[2] & 0x8000000000000000) != 0) {
          p_p = (std::string *)__p.__r_.__value_.__r.__words[0];
        }
        *(_DWORD *)uint8_t buf = 136315138;
        *(void *)&uint8_t buf[4] = p_p;
        _os_log_impl(&dword_210C72000, v14, OS_LOG_TYPE_DEFAULT, "Duplicate livein param: %s\n", buf, 0xCu);
LABEL_8:
        uint64_t v16 = 0;
        goto LABEL_9;
      }
    }
  }
  return 1;
}

void sub_2112A79FC(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, void *__p, uint64_t a13, int a14, __int16 a15, char a16, char a17)
{
  if (a17 < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

BOOL ZinIrLiveIOManager::ParseLiveIOUnits(ZinIrLiveIOManager *this, CFDictionaryRef theDict, ZinIrNetworkStatus *a3)
{
  uint64_t v42 = *MEMORY[0x263EF8340];
  CFArrayRef Value = (const __CFArray *)CFDictionaryGetValue(theDict, @"Units");
  if (Value)
  {
    CFArrayRef v6 = Value;
    CFTypeID v7 = CFGetTypeID(Value);
    if (v7 == CFArrayGetTypeID()) {
      CFArrayRef v8 = v6;
    }
    else {
      CFArrayRef v8 = 0;
    }
  }
  else
  {
    CFArrayRef v8 = 0;
  }
  CFIndex Count = CFArrayGetCount(v8);
  if (Count >= 1)
  {
    CFIndex v10 = Count;
    BOOL v11 = 0;
    CFIndex v12 = 0;
    int v40 = 0;
    long long v32 = (uint64_t **)((char *)this + 112);
    long long v30 = (void **)((char *)this + 120);
    long long v31 = (uint64_t **)((char *)this + 184);
    uint64_t v29 = (void **)((char *)this + 192);
    while (1)
    {
      CFArrayRef v13 = v8;
      CFStringRef ValueAtIndex = (const __CFString *)CFArrayGetValueAtIndex(v8, v12);
      CFStringRef v15 = ValueAtIndex;
      if (!ValueAtIndex) {
        return v11;
      }
      CFTypeID v16 = CFGetTypeID(ValueAtIndex);
      if (v16 != CFStringGetTypeID()) {
        return v11;
      }
      CFTypeID v17 = (CFArrayRef *)ZinIrNetworkStatus::AddUnit(a3, v15);
      CFDictionaryRef v18 = (const __CFDictionary *)CFDictionaryGetValue(theDict, v15);
      CFDictionaryRef v19 = v18;
      if (!v18) {
        return v11;
      }
      CFTypeID v20 = CFGetTypeID(v18);
      if (v20 != CFDictionaryGetTypeID() || ZinParseUnitType(v19, &v40, v17)) {
        return v11;
      }
      int v21 = v40;
      if (v40 == 48)
      {
        memset(&v35, 0, sizeof(v35));
        int v36 = 0;
        long long v37 = 0u;
        *(_OWORD *)unint64_t v38 = 0u;
        *(void *)&v38[16] = -1;
        uint64_t v34 = &unk_26C350E50;
        HIDWORD(v39) = -1;
        if (ZinParseUnit(theDict, v15, (ZinIrUnitInfo *)&v34, v17)
          || ZinParsePlaneReaderUnit(v19, (ZinIrPlaneReaderUnitInfo *)&v34, v17))
        {
          goto LABEL_41;
        }
        if (v30 != std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::find<std::string>((uint64_t)v32, (void **)&v35.__r_.__value_.__l.__data_))
        {
          if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_DEFAULT))
          {
            if ((v35.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
              int v24 = &v35;
            }
            else {
              int v24 = (std::string *)v35.__r_.__value_.__r.__words[0];
            }
            *(_DWORD *)uint8_t buf = 136315138;
            *(void *)&uint8_t buf[4] = v24;
            long long v25 = &_os_log_internal;
            uint64_t v26 = "Duplicate plane reader unit: %s\n";
LABEL_40:
            _os_log_impl(&dword_210C72000, v25, OS_LOG_TYPE_DEFAULT, v26, buf, 0xCu);
          }
LABEL_41:
          ZinIrUnitInfo::~ZinIrUnitInfo(&v34);
          return v11;
        }
        *(void *)uint8_t buf = &v35;
        long long v22 = std::__tree<std::__value_type<std::string,ZinIrPlaneReaderUnitInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrPlaneReaderUnitInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrPlaneReaderUnitInfo>>>::__emplace_unique_key_args<std::string,std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>(v32, (void **)&v35.__r_.__value_.__l.__data_, (uint64_t)&std::piecewise_construct, (long long **)buf);
        std::string::operator=((std::string *)(v22 + 8), &v35);
        *((_DWORD *)v22 + 22) = v36;
        if (v22 + 7 != (uint64_t *)&v34) {
          std::vector<std::string>::__assign_with_size[abi:ne180100]<std::string*,std::string*>((std::vector<std::string> *)v22 + 4, (std::string *)v37, *((long long **)&v37 + 1), 0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*((void *)&v37 + 1) - v37) >> 3));
        }
        *(_OWORD *)(v22 + 15) = *(_OWORD *)&v38[8];
        v22[17] = v39;
        ZinIrUnitInfo::~ZinIrUnitInfo(&v34);
        int v21 = v40;
      }
      if (v21 == 49)
      {
        memset(&v35, 0, sizeof(v35));
        int v36 = 0;
        long long v37 = 0u;
        *(_OWORD *)unint64_t v38 = 0u;
        *(void *)&v38[16] = -1;
        uint64_t v34 = &unk_26C350E70;
        if (ZinParseUnit(theDict, v15, (ZinIrUnitInfo *)&v34, v17)
          || ZinParsePlaneWriterUnit(v19, (ZinIrPlaneWriterUnitInfo *)&v34, v17))
        {
          goto LABEL_41;
        }
        if (v29 != std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::find<std::string>((uint64_t)v31, (void **)&v35.__r_.__value_.__l.__data_))
        {
          if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_DEFAULT))
          {
            if ((v35.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
              size_t v27 = &v35;
            }
            else {
              size_t v27 = (std::string *)v35.__r_.__value_.__r.__words[0];
            }
            *(_DWORD *)uint8_t buf = 136315138;
            *(void *)&uint8_t buf[4] = v27;
            long long v25 = &_os_log_internal;
            uint64_t v26 = "Duplicate plane writer unit: %s\n";
            goto LABEL_40;
          }
          goto LABEL_41;
        }
        *(void *)uint8_t buf = &v35;
        uint64_t v23 = std::__tree<std::__value_type<std::string,ZinIrPlaneWriterUnitInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrPlaneWriterUnitInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrPlaneWriterUnitInfo>>>::__emplace_unique_key_args<std::string,std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>(v31, (void **)&v35.__r_.__value_.__l.__data_, (uint64_t)&std::piecewise_construct, (long long **)buf);
        std::string::operator=((std::string *)(v23 + 8), &v35);
        *((_DWORD *)v23 + 22) = v36;
        if (v23 + 7 != (uint64_t *)&v34) {
          std::vector<std::string>::__assign_with_size[abi:ne180100]<std::string*,std::string*>((std::vector<std::string> *)v23 + 4, (std::string *)v37, *((long long **)&v37 + 1), 0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*((void *)&v37 + 1) - v37) >> 3));
        }
        *(_OWORD *)(v23 + 15) = *(_OWORD *)&v38[8];
        *((_DWORD *)v23 + 34) = v39;
        ZinIrUnitInfo::~ZinIrUnitInfo(&v34);
      }
      BOOL v11 = ++v12 >= v10;
      CFArrayRef v8 = v13;
      if (v10 == v12) {
        return v11;
      }
    }
  }
  return 1;
}

void sub_2112A7EA8(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, ...)
{
  va_start(va, a9);
  ZinIrUnitInfo::~ZinIrUnitInfo((void **)va);
  _Unwind_Resume(a1);
}

uint64_t ZinIrLiveIOManager::ParseLiveIO(ZinIrLiveIOManager *this, const __CFDictionary *a2, ZinIrNetworkStatus *a3)
{
  if (ZinIrLiveIOManager::ParseLiveInputs(this, a2, (CFArrayRef *)a3))
  {
    if (ZinIrLiveIOManager::ParseLiveStates(this, a2, (CFArrayRef *)a3))
    {
      if (ZinIrLiveIOManager::ParseLiveInputParams(this, a2, (CFArrayRef *)a3))
      {
        if (ZinIrLiveIOManager::ParseLiveOutputs(this, a2, (CFArrayRef *)a3))
        {
          if (ZinIrLiveIOManager::ParseLiveIOUnits(this, a2, a3)) {
            return 1;
          }
          CFStringRef v7 = @"InvalidUnit";
        }
        else
        {
          CFStringRef v7 = @"InvalidOutput";
        }
      }
      else
      {
        CFStringRef v7 = @"InvalidInputParam";
      }
    }
    else
    {
      CFStringRef v7 = @"InvalidState";
    }
  }
  else
  {
    CFStringRef v7 = @"InvalidInput";
  }
  ZinIrNetworkStatus::SetError((CFArrayRef *)a3, v7);
  return 0;
}

uint64_t ZinIrLiveIOManager::SetLiveInputParams(uint64_t a1, std::string **a2)
{
  uint64_t v10 = *MEMORY[0x263EF8340];
  uint64_t v2 = *a2;
  unint64_t v3 = (uint64_t *)a2[1];
  if (*a2 == (std::string *)v3) {
    return 1;
  }
  int v4 = (uint64_t **)(a1 + 160);
  uint64_t v5 = (void **)(a1 + 168);
  while (v5 == std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::find<std::string>((uint64_t)v4, (void **)&v2->__r_.__value_.__l.__data_))
  {
    *(void *)uint8_t buf = v2;
    CFArrayRef v6 = std::__tree<std::__value_type<std::string,ZinIrInputParamInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrInputParamInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrInputParamInfo>>>::__emplace_unique_key_args<std::string,std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>(v4, (void **)&v2->__r_.__value_.__l.__data_, (uint64_t)&std::piecewise_construct, (long long **)buf);
    std::string::operator=((std::string *)(v6 + 7), v2);
    *((_DWORD *)v6 + 20) = v2[1].__r_.__value_.__l.__data_;
    uint64_t v2 = (std::string *)((char *)v2 + 32);
    if (v2 == (std::string *)v3) {
      return 1;
    }
  }
  BOOL v8 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_DEFAULT);
  uint64_t result = 0;
  if (v8)
  {
    if (SHIBYTE(v2->__r_.__value_.__r.__words[2]) < 0) {
      uint64_t v2 = (std::string *)v2->__r_.__value_.__r.__words[0];
    }
    *(_DWORD *)uint8_t buf = 136315138;
    *(void *)&uint8_t buf[4] = v2;
    _os_log_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_DEFAULT, "Duplicate input param: %s\n", buf, 0xCu);
    return 0;
  }
  return result;
}

uint64_t ZinIrLiveIOManager::SetLiveIO(uint64_t a1, uint64_t a2, std::string **a3, CFArrayRef *this)
{
  CFArrayRef v6 = (int *)(a2 + 8);
  uint64_t v5 = *(void *)(a2 + 8);
  if (!v5) {
    goto LABEL_11;
  }
  uint64_t v10 = a2 + 8;
  uint64_t v11 = *(void *)(a2 + 8);
  do
  {
    int v12 = *(_DWORD *)(v11 + 32);
    BOOL v13 = v12 < 0;
    if (v12 >= 0) {
      long long v14 = (uint64_t *)v11;
    }
    else {
      long long v14 = (uint64_t *)(v11 + 8);
    }
    if (!v13) {
      uint64_t v10 = v11;
    }
    uint64_t v11 = *v14;
  }
  while (*v14);
  if ((int *)v10 == v6 || *(int *)(v10 + 32) > 0) {
    goto LABEL_11;
  }
  uint64_t v17 = a2 + 8;
  do
  {
    int v18 = *(_DWORD *)(v5 + 32);
    BOOL v19 = v18 < 1;
    if (v18 >= 1) {
      CFTypeID v20 = (uint64_t *)v5;
    }
    else {
      CFTypeID v20 = (uint64_t *)(v5 + 8);
    }
    if (!v19) {
      uint64_t v17 = v5;
    }
    uint64_t v5 = *v20;
  }
  while (*v20);
  if ((int *)v17 == v6 || *(int *)(v17 + 32) >= 2) {
    goto LABEL_23;
  }
  int v31 = 0;
  int v21 = std::map<ZinIrDimension,unsigned long>::at(a2, &v31);
  if ((ZinIrLiveIOManager::SetLiveIOs(a1, 0, v21) & 1) == 0)
  {
LABEL_11:
    CFStringRef v15 = @"InvalidInput";
    goto LABEL_12;
  }
  int v30 = 1;
  long long v22 = std::map<ZinIrDimension,unsigned long>::at(a2, &v30);
  if ((ZinIrLiveIOManager::SetLiveIOs(a1, 1, v22) & 1) == 0)
  {
LABEL_23:
    CFStringRef v15 = @"InvalidOutput";
    goto LABEL_12;
  }
  uint64_t v23 = *(void *)v6;
  if (!*(void *)v6) {
    goto LABEL_37;
  }
  int v24 = v6;
  do
  {
    int v25 = *(_DWORD *)(v23 + 32);
    BOOL v26 = v25 < 2;
    if (v25 >= 2) {
      size_t v27 = (uint64_t *)v23;
    }
    else {
      size_t v27 = (uint64_t *)(v23 + 8);
    }
    if (!v26) {
      int v24 = (int *)v23;
    }
    uint64_t v23 = *v27;
  }
  while (*v27);
  if (v24 == v6
    || v24[8] > 2
    || (int v29 = 2,
        unint64_t v28 = std::map<ZinIrDimension,unsigned long>::at(a2, &v29),
        (ZinIrLiveIOManager::SetLiveIOs(a1, 2, v28) & 1) != 0))
  {
LABEL_37:
    if (ZinIrLiveIOManager::SetLiveInputParams(a1, a3)) {
      return 1;
    }
    CFStringRef v15 = @"InvalidInputParam";
  }
  else
  {
    CFStringRef v15 = @"InvalidState";
  }
LABEL_12:
  ZinIrNetworkStatus::SetError(this, v15);
  return 0;
}

uint64_t ZinIrLiveIOManager::HasMultiplanarLiveIO(ZinIrLiveIOManager *this)
{
  unint64_t v3 = this;
  uint64_t v1 = 1;
  if ((ZinIrLiveIOManager::HasMultiplanarLiveIO(void)const::$_0::operator()((uint64_t *)&v3, 0) & 1) == 0
    && (ZinIrLiveIOManager::HasMultiplanarLiveIO(void)const::$_0::operator()((uint64_t *)&v3, 1) & 1) == 0)
  {
    return ZinIrLiveIOManager::HasMultiplanarLiveIO(void)const::$_0::operator()((uint64_t *)&v3, 2);
  }
  return v1;
}

uint64_t ZinIrLiveIOManager::HasMultiplanarLiveIO(void)const::$_0::operator()(uint64_t *a1, int a2)
{
  int v19 = a2;
  uint64_t v2 = *a1;
  unint64_t v3 = std::map<ZinIrDimension,unsigned long>::at(*a1 + 40, &v19);
  int v4 = std::map<ZinIrDimension,unsigned long>::at(v2 + 16, &v19);
  uint64_t v7 = *v3;
  uint64_t v5 = v3 + 1;
  CFArrayRef v6 = (void **)v7;
  if ((uint64_t *)v7 == v5) {
    return 0;
  }
  uint64_t v8 = (uint64_t)v4;
  long long v9 = (void **)(v4 + 1);
  while (1)
  {
    uint64_t v10 = std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::find<std::string>(v8, v6 + 4);
    if (v9 != v10)
    {
      ZinIr4CCInfo::ZinIr4CCInfo(v16, *((unsigned int *)v10 + 65));
      PlaneCFIndex Count = ZinIr4CCInfo::GetPlaneCount((ZinIr4CCInfo *)v16);
      if (__p)
      {
        int v18 = __p;
        operator delete(__p);
      }
      if (PlaneCount >= 2) {
        break;
      }
    }
    int v12 = (uint64_t *)v6[1];
    if (v12)
    {
      do
      {
        BOOL v13 = v12;
        int v12 = (uint64_t *)*v12;
      }
      while (v12);
    }
    else
    {
      do
      {
        BOOL v13 = (uint64_t *)v6[2];
        BOOL v14 = *v13 == (void)v6;
        CFArrayRef v6 = (void **)v13;
      }
      while (!v14);
    }
    CFArrayRef v6 = (void **)v13;
    if (v13 == v5) {
      return 0;
    }
  }
  return 1;
}

void sub_2112A83F0(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, void *__p, uint64_t a12)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t *ZinIrLiveIOManager::GetLiveIOTensors(uint64_t a1, int a2)
{
  int v3 = a2;
  return std::map<ZinIrDimension,unsigned long>::at(a1 + 88, &v3);
}

uint64_t *ZinIrLiveIOManager::GetLiveIOs(uint64_t a1, int a2)
{
  int v3 = a2;
  return std::map<ZinIrDimension,unsigned long>::at(a1 + 16, &v3);
}

BOOL ZinIrLiveIOManager::PrepareLiveIn(uint64_t **this, CFArrayRef *a2)
{
  LODWORD(v30[0]) = 0;
  int v3 = std::map<ZinIrDimension,unsigned long>::at((uint64_t)(this + 5), (int *)v30);
  int v25 = this;
  LODWORD(v30[0]) = 0;
  int v4 = std::map<ZinIrDimension,unsigned long>::at((uint64_t)(this + 2), (int *)v30);
  uint64_t v27 = (uint64_t)v3;
  uint64_t v7 = (void **)*v3;
  CFArrayRef v6 = (void **)(v3 + 1);
  uint64_t v5 = v7;
  if (v7 != v6)
  {
    do
    {
      v30[0] = (long long *)(v5 + 4);
      uint64_t v8 = std::__tree<std::__value_type<std::string,ZinIrIOInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrIOInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrIOInfo>>>::__emplace_unique_key_args<std::string,std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>((uint64_t **)v4, v5 + 4, (uint64_t)&std::piecewise_construct, v30);
      ZinIr4CCInfo::ZinIr4CCInfo(v30, *((unsigned int *)v8 + 65));
      PlaneCFIndex Count = ZinIr4CCInfo::GetPlaneCount((ZinIr4CCInfo *)v30);
      if (PlaneCount == 1)
      {
        if (*((char *)v5 + 55) < 0) {
          std::string::__init_copy_ctor_external(&__x, (const std::string::value_type *)v5[4], (std::string::size_type)v5[5]);
        }
        else {
          std::string __x = *(std::string *)(v5 + 4);
        }
      }
      else
      {
        std::string::basic_string[abi:ne180100]<0>(&__x, &byte_211F4AA5D);
      }
      std::vector<std::string>::vector(&v28, PlaneCount, &__x);
      long long v33 = (long long *)(v5 + 4);
      uint64_t v10 = (std::vector<std::string> *)(std::__tree<std::__value_type<std::string,std::vector<std::string>>,std::__map_value_compare<std::string,std::__value_type<std::string,std::vector<std::string>>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,std::vector<std::string>>>>::__emplace_unique_key_args<std::string,std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>(this + 17, v5 + 4, (uint64_t)&std::piecewise_construct, &v33)+ 7);
      if (v10 != &v28) {
        std::vector<std::string>::__assign_with_size[abi:ne180100]<std::string*,std::string*>(v10, v28.__begin_, (long long *)v28.__end_, 0xAAAAAAAAAAAAAAABLL * (((char *)v28.__end_ - (char *)v28.__begin_) >> 3));
      }
      uint64_t v34 = &v28;
      std::vector<std::string>::__destroy_vector::operator()[abi:ne180100]((void ***)&v34);
      if (SHIBYTE(__x.__r_.__value_.__r.__words[2]) < 0) {
        operator delete(__x.__r_.__value_.__l.__data_);
      }
      if (__p)
      {
        long long v32 = __p;
        operator delete(__p);
      }
      uint64_t v11 = (void **)v5[1];
      if (v11)
      {
        do
        {
          int v12 = v11;
          uint64_t v11 = (void **)*v11;
        }
        while (v11);
      }
      else
      {
        do
        {
          int v12 = (void **)v5[2];
          BOOL v13 = *v12 == v5;
          uint64_t v5 = v12;
        }
        while (!v13);
      }
      uint64_t v5 = v12;
    }
    while (v12 != v6);
  }
  BOOL v14 = this[14];
  CFStringRef v15 = (uint64_t *)(this + 15);
  if (v14 == (uint64_t *)(v25 + 15)) {
    return 1;
  }
  while (1)
  {
    CFTypeID v16 = (void **)v14[12];
    uint64_t v17 = *((unsigned int *)v14 + 34);
    unint64_t v18 = *((int *)v14 + 35);
    if (v6 == std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::find<std::string>(v27, v16))break; {
    v30[0] = (long long *)v16;
    }
    if (*((_DWORD *)std::__tree<std::__value_type<std::string,ZinIrIOInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrIOInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrIOInfo>>>::__emplace_unique_key_args<std::string,std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>((uint64_t **)v4, v16, (uint64_t)&std::piecewise_construct, v30)+ 65) != v17)break; {
    ZinIr4CCInfo::ZinIr4CCInfo(v30, v17);
    }
    unint64_t v19 = ZinIr4CCInfo::GetPlaneCount((ZinIr4CCInfo *)v30);
    BOOL v20 = v19 > v18;
    if (v19 > v18)
    {
      __x.__r_.__value_.__r.__words[0] = (std::string::size_type)v16;
      int v21 = std::__tree<std::__value_type<std::string,std::vector<std::string>>,std::__map_value_compare<std::string,std::__value_type<std::string,std::vector<std::string>>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,std::vector<std::string>>>>::__emplace_unique_key_args<std::string,std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>(v25 + 17, v16, (uint64_t)&std::piecewise_construct, (long long **)&__x);
      std::string::operator=((std::string *)(v21[7] + 24 * (int)v18), (const std::string *)(v14 + 4));
    }
    else
    {
      ZinIrNetworkStatus::SetError(a2, @"InvalidUnit");
    }
    if (__p)
    {
      long long v32 = __p;
      operator delete(__p);
    }
    if (v19 > v18)
    {
      long long v22 = (uint64_t *)v14[1];
      if (v22)
      {
        do
        {
          uint64_t v23 = v22;
          long long v22 = (uint64_t *)*v22;
        }
        while (v22);
      }
      else
      {
        do
        {
          uint64_t v23 = (uint64_t *)v14[2];
          BOOL v13 = *v23 == (void)v14;
          BOOL v14 = v23;
        }
        while (!v13);
      }
      BOOL v14 = v23;
      if (v23 != v15) {
        continue;
      }
    }
    return v20;
  }
  ZinIrNetworkStatus::SetError(a2, @"InvalidUnit");
  return 0;
}

void sub_2112A877C(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, char a12, uint64_t a13, uint64_t a14, void *a15, uint64_t a16, int a17, __int16 a18, char a19, char a20,uint64_t a21,uint64_t a22,uint64_t a23,void *__p,uint64_t a25)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinIrLiveIOManager::PrepareBindingsForLiveInsWithout4CC(uint64_t a1, int a2)
{
  uint64_t v12 = *MEMORY[0x263EF8340];
  int v11 = a2;
  if ((a2 & 0xFFFFFFFD) != 0) {
    ZinAssertImpl("PrepareBindingsForLiveInsWithout4CC should not be called on live outputs");
  }
  int v3 = std::map<ZinIrDimension,unsigned long>::at(a1 + 64, &v11);
  int v4 = std::map<ZinIrDimension,unsigned long>::at(a1 + 16, &v11);
  std::map<ZinIrDimension,unsigned long>::at(a1 + 88, &v11);
  uint64_t v5 = *v3;
  if ((uint64_t *)*v3 != v3 + 1)
  {
    uint64_t v10 = 0;
    long long v8 = 0u;
    long long v9 = 0u;
    std::string __p = (void *)(v5 + 32);
    std::__tree<std::__value_type<std::string,ZinIrIOInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrIOInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrIOInfo>>>::__emplace_unique_key_args<std::string,std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>((uint64_t **)v4, (void **)(v5 + 32), (uint64_t)&std::piecewise_construct, (long long **)&__p);
    operator new();
  }
  return 1;
}

void sub_2112A8B8C(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, void *a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,std::__shared_weak_count *a26,void *a27,void *__p,uint64_t a29)
{
  if (a26) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a26);
  }
  int v31 = a27;
  a27 = 0;
  if (v31) {
    std::default_delete<ZinIrTensor::MirInfo>::operator()[abi:ne180100]((uint64_t)&a27, v31);
  }
  if (__p)
  {
    a29 = (uint64_t)__p;
    operator delete(__p);
  }
  (*(void (**)(uint64_t))(*(void *)v29 + 8))(v29);
  _Unwind_Resume(a1);
}

void FindDimOrder(ZinIrIO **a1@<X0>, uint64_t a2@<X8>)
{
  DimensionOrderHint::DimensionOrderHint(a2, 0);
  if (ZinIrIO::HasCustomStrides(*a1))
  {
    int v4 = (int8x16_t *)*a1;
    uint64_t v5 = *((void *)*a1 + 22);
    uint64_t v9 = *((void *)*a1 + 23);
    int8x16_t v10 = vextq_s8(v4[10], v4[10], 8uLL);
    uint64_t v11 = 1;
    uint64_t v12 = v5;
    FindDimensionOrderFromStrides((const ZinTensorDimensions *)&v9, (const ZinTensorDimensions *)&v4[4], v4[9].u64[1], 1, (uint64_t)&__p);
    if (&__p == (void **)a2) {
      goto LABEL_6;
    }
  }
  else
  {
    DimensionOrderHint::DimensionOrderHint(&__p, 2);
    if (&__p == (void **)a2) {
      goto LABEL_6;
    }
  }
  std::vector<int>::__assign_with_size[abi:ne180100]<int *,int *>((char *)a2, (char *)__p, (uint64_t)v7, (v7 - (unsigned char *)__p) >> 2);
LABEL_6:
  *(_DWORD *)(a2 + 24) = v8;
  if (__p)
  {
    uint64_t v7 = __p;
    operator delete(__p);
  }
}

void sub_2112A8D74(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11)
{
  if (__p) {
    operator delete(__p);
  }
  BOOL v13 = *(void **)v11;
  if (*(void *)v11)
  {
    *(void *)(v11 + 8) = v13;
    operator delete(v13);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinIrLiveIOManager::PrepareBindingsForLiveInsWith4CC(uint64_t a1, int a2)
{
  uint64_t v12 = *MEMORY[0x263EF8340];
  int v10 = a2;
  if ((a2 & 0xFFFFFFFD) != 0) {
    ZinAssertImpl("PrepareBindingsForLiveInsWith4CC should not be called on live outputs");
  }
  int v3 = std::map<ZinIrDimension,unsigned long>::at(a1 + 40, &v10);
  int v8 = std::map<ZinIrDimension,unsigned long>::at(a1 + 16, &v10);
  std::map<ZinIrDimension,unsigned long>::at(a1 + 88, &v10);
  uint64_t v4 = *v3;
  if ((uint64_t *)*v3 != v3 + 1)
  {
    *(void *)&long long v11 = v4 + 32;
    uint64_t v5 = std::__tree<std::__value_type<std::string,ZinIrIOInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrIOInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrIOInfo>>>::__emplace_unique_key_args<std::string,std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>((uint64_t **)v8, (void **)(v4 + 32), (uint64_t)&std::piecewise_construct, (long long **)&v11);
    CFArrayRef v6 = (ZinIr4CCInfo *)ZinIr4CCInfo::ZinIr4CCInfo(v9, *((unsigned int *)v5 + 65));
    ZinIr4CCInfo::IsCompressed(v6);
    ZinIr4CCInfo::GetPlaneCount((ZinIr4CCInfo *)v9);
    operator new();
  }
  return 1;
}

void sub_2112A94B8(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33,uint64_t a34,uint64_t a35,uint64_t a36,uint64_t a37,uint64_t a38,uint64_t a39,uint64_t a40,uint64_t a41,void *a42,uint64_t a43,uint64_t a44,uint64_t a45,uint64_t a46,uint64_t a47,uint64_t a48,uint64_t a49,uint64_t a50,uint64_t a51,uint64_t a52,uint64_t a53,uint64_t a54,uint64_t a55,uint64_t a56,void *__p,uint64_t a58,uint64_t a59,uint64_t a60)
{
  if (__p) {
    operator delete(__p);
  }
  if (a60) {
    (*(void (**)(uint64_t))(*(void *)a60 + 8))(a60);
  }
  long long v62 = *(void **)(v60 - 240);
  if (v62)
  {
    *(void *)(v60 - 2std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = v62;
    operator delete(v62);
  }
  _Unwind_Resume(exception_object);
}

void std::make_unique[abi:ne180100]<ZinIrTensor::MirInfo,ZinIrTensor::AllocationHint,unsigned int &,DimensionOrderHint>()
{
}

void sub_2112A96F4(_Unwind_Exception *a1)
{
  MEMORY[0x21667D3C0](v1, 0x10B0C405A042323);
  _Unwind_Resume(a1);
}

void std::make_unique[abi:ne180100]<ZinIrTensor::MirInfo,ZinIrTensor::AllocationHint,unsigned int &,DimensionOrderHint &,ZinTensorDimensions &>()
{
}

void sub_2112A9790(_Unwind_Exception *a1)
{
  MEMORY[0x21667D3C0](v1, 0x10B0C405A042323);
  _Unwind_Resume(a1);
}

uint64_t ZinIrLiveIOManager::PrepareLiveInBinding(uint64_t a1)
{
  uint64_t result = ZinIrLiveIOManager::PrepareBindingsForLiveInsWithout4CC(a1, 0);
  if (result)
  {
    return ZinIrLiveIOManager::PrepareBindingsForLiveInsWith4CC(a1, 0);
  }
  return result;
}

uint64_t ZinIrLiveIOManager::PrepareLiveStateBinding(uint64_t a1)
{
  int v3 = 2;
  if (std::map<ZinIrDimension,unsigned long>::at(a1 + 40, &v3)[2]) {
    ZinAssertImpl("State with 4cc format are not supported");
  }
  return ZinIrLiveIOManager::PrepareBindingsForLiveInsWithout4CC(a1, 2);
}

uint64_t ZinIrLiveIOManager::PrepareLiveOut(ZinIrLiveIOManager *this, CFArrayRef *a2)
{
  LODWORD(__str.__r_.__value_.__l.__data_) = 1;
  int v3 = std::map<ZinIrDimension,unsigned long>::at((uint64_t)this + 64, (int *)&__str);
  LODWORD(__str.__r_.__value_.__l.__data_) = 1;
  uint64_t v70 = std::map<ZinIrDimension,unsigned long>::at((uint64_t)this + 40, (int *)&__str);
  uint64_t v74 = this;
  LODWORD(__str.__r_.__value_.__l.__data_) = 1;
  unint64_t v75 = std::map<ZinIrDimension,unsigned long>::at((uint64_t)this + 16, (int *)&__str);
  uint64_t v4 = (std::string *)*v3;
  unint64_t v78 = (std::string *)(v3 + 1);
  if ((uint64_t *)*v3 != v3 + 1)
  {
    uint64_t v5 = (uint64_t **)((char *)v74 + 256);
    CFArrayRef v6 = (void **)((char *)v74 + 264);
    do
    {
      __str.__r_.__value_.__r.__words[0] = (std::string::size_type)&v4[1].__r_.__value_.__l.__size_;
      uint64_t v7 = std::__tree<std::__value_type<std::string,ZinIrIOInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrIOInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrIOInfo>>>::__emplace_unique_key_args<std::string,std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>((uint64_t **)v75, (void **)&v4[1].__r_.__value_.__l.__size_, (uint64_t)&std::piecewise_construct, (long long **)&__str);
      int v8 = (char *)operator new(8uLL);
      *(void *)int v8 = 0;
      __str.__r_.__value_.__r.__words[0] = (std::string::size_type)&v4[1].__r_.__value_.__l.__size_;
      uint64_t v9 = std::__tree<std::__value_type<std::string,std::vector<ZinIrTensor *>>,std::__map_value_compare<std::string,std::__value_type<std::string,std::vector<ZinIrTensor *>>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,std::vector<ZinIrTensor *>>>>::__emplace_unique_key_args<std::string,std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>((uint64_t **)v74 + 26, (void **)&v4[1].__r_.__value_.__l.__size_, (uint64_t)&std::piecewise_construct, (long long **)&__str);
      std::vector<DimensionMapping>::__assign_with_size[abi:ne180100]<DimensionMapping const*,DimensionMapping const*>((char *)v9 + 56, v8, (uint64_t)(v8 + 8), 1uLL);
      if (*((char *)v7 + 79) < 0) {
        std::string::__init_copy_ctor_external(&__str, (const std::string::value_type *)v7[7], v7[8]);
      }
      else {
        std::string __str = *(std::string *)(v7 + 7);
      }
      int v10 = (long long *)(v7 + 10);
      if (*((char *)v7 + 103) < 0)
      {
        std::string::__init_copy_ctor_external(&v92, (const std::string::value_type *)v7[10], v7[11]);
      }
      else
      {
        *(_OWORD *)&v92.__r_.__value_.__l.__data_ = *v10;
        v92.__r_.__value_.__r.__words[2] = v7[12];
      }
      long long v11 = *(_OWORD *)(v7 + 27);
      long long v99 = *(_OWORD *)(v7 + 25);
      long long v100 = v11;
      long long v12 = *(_OWORD *)(v7 + 31);
      long long v101 = *(_OWORD *)(v7 + 29);
      long long v102 = v12;
      long long v13 = *(_OWORD *)(v7 + 19);
      long long v95 = *(_OWORD *)(v7 + 17);
      long long v96 = v13;
      long long v14 = *(_OWORD *)(v7 + 23);
      long long v97 = *(_OWORD *)(v7 + 21);
      long long v98 = v14;
      long long v15 = *(_OWORD *)(v7 + 15);
      long long v93 = *(_OWORD *)(v7 + 13);
      long long v94 = v15;
      long long v104 = 0;
      uint64_t v105 = 0;
      std::string __p = 0;
      std::vector<LayerAndUsageInfo>::__init_with_size[abi:ne180100]<LayerAndUsageInfo*,LayerAndUsageInfo*>(&__p, (const void *)v7[33], v7[34], (v7[34] - v7[33]) >> 4);
      long long v106 = *((_OWORD *)v7 + 18);
      unsigned int v107 = 0;
      CFTypeID v16 = std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::find<std::string>((uint64_t)v5, (void **)v7 + 10);
      if (v6 == v16)
      {
        v86[0] = v10;
        uint64_t v17 = std::__tree<std::__value_type<std::string,ZinIrLiveOutTensorInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrLiveOutTensorInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrLiveOutTensorInfo>>>::__emplace_unique_key_args<std::string,std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>(v5, (void **)v10, (uint64_t)&std::piecewise_construct, v86);
        std::string::operator=((std::string *)(v17 + 7), &__str);
        std::string::operator=((std::string *)(v17 + 10), &v92);
        long long v18 = v100;
        long long v20 = v101;
        long long v19 = v102;
        *(_OWORD *)(v17 + 25) = v99;
        *(_OWORD *)(v17 + 27) = v18;
        *(_OWORD *)(v17 + 29) = v20;
        *(_OWORD *)(v17 + 31) = v19;
        long long v21 = v96;
        long long v23 = v97;
        long long v22 = v98;
        *(_OWORD *)(v17 + 17) = v95;
        *(_OWORD *)(v17 + 19) = v21;
        *(_OWORD *)(v17 + 21) = v23;
        *(_OWORD *)(v17 + 23) = v22;
        long long v24 = v94;
        *(_OWORD *)(v17 + 13) = v93;
        *(_OWORD *)(v17 + 15) = v24;
        if (v17 + 7 != (uint64_t *)&__str) {
          std::vector<LayerAndUsageInfo>::__assign_with_size[abi:ne180100]<LayerAndUsageInfo*,LayerAndUsageInfo*>((char *)v17 + 264, (char *)__p, (uint64_t)v104, (v104 - (unsigned char *)__p) >> 4);
        }
        *((_OWORD *)v17 + 18) = v106;
        *((_DWORD *)v17 + 76) = v107;
      }
      else
      {
        if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
          ZinIrLiveIOManager::PrepareLiveOut(&v89, v90);
        }
        ZinIrNetworkStatus::SetError(a2, @"DuplicateOutput");
      }
      if (__p)
      {
        long long v104 = __p;
        operator delete(__p);
      }
      if (SHIBYTE(v92.__r_.__value_.__r.__words[2]) < 0) {
        operator delete(v92.__r_.__value_.__l.__data_);
      }
      if (SHIBYTE(__str.__r_.__value_.__r.__words[2]) < 0) {
        operator delete(__str.__r_.__value_.__l.__data_);
      }
      operator delete(v8);
      if (v6 != v16) {
        return 0;
      }
      std::string::size_type size = (std::string *)v4->__r_.__value_.__l.__size_;
      if (size)
      {
        do
        {
          BOOL v26 = size;
          std::string::size_type size = (std::string *)size->__r_.__value_.__r.__words[0];
        }
        while (size);
      }
      else
      {
        do
        {
          BOOL v26 = (std::string *)v4->__r_.__value_.__r.__words[2];
          BOOL v27 = v26->__r_.__value_.__r.__words[0] == (void)v4;
          uint64_t v4 = v26;
        }
        while (!v27);
      }
      uint64_t v4 = v26;
    }
    while (v26 != v78);
  }
  std::vector<std::string> v28 = (void **)*v70;
  unint64_t v71 = v70 + 1;
  if (v28 == (void **)v71) {
    return 1;
  }
  unint64_t v77 = (uint64_t **)((char *)v74 + 256);
  long long v79 = (void **)((char *)v74 + 264);
  while (1)
  {
    __str.__r_.__value_.__r.__words[0] = (std::string::size_type)(v28 + 4);
    uint64_t v29 = std::__tree<std::__value_type<std::string,ZinIrIOInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrIOInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrIOInfo>>>::__emplace_unique_key_args<std::string,std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>((uint64_t **)v75, v28 + 4, (uint64_t)&std::piecewise_construct, (long long **)&__str);
    uint64_t v30 = *((unsigned int *)v29 + 65);
    ZinIr4CCInfo::ZinIr4CCInfo(v86, v30);
    PlaneCFIndex Count = ZinIr4CCInfo::GetPlaneCount((ZinIr4CCInfo *)v86);
    __str.__r_.__value_.__r.__words[0] = 0;
    std::vector<ZinIrTensor *>::vector(&v84, PlaneCount, &__str);
    __str.__r_.__value_.__r.__words[0] = (std::string::size_type)(v28 + 4);
    long long v32 = (char *)(std::__tree<std::__value_type<std::string,std::vector<ZinIrTensor *>>,std::__map_value_compare<std::string,std::__value_type<std::string,std::vector<ZinIrTensor *>>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,std::vector<ZinIrTensor *>>>>::__emplace_unique_key_args<std::string,std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>((uint64_t **)v74 + 26, v28 + 4, (uint64_t)&std::piecewise_construct, (long long **)&__str)+ 7);
    if (v32 != (char *)&v84) {
      std::vector<DimensionMapping>::__assign_with_size[abi:ne180100]<DimensionMapping const*,DimensionMapping const*>(v32, (char *)v84, (uint64_t)v85, (v85 - (unsigned char *)v84) >> 3);
    }
    int64x2_t v73 = (void **)(v29 + 10);
    long long v33 = std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::find<std::string>((uint64_t)v74 + 184, (void **)v29 + 10);
    uint64_t v34 = v33;
    __int16 v72 = v29 + 7;
    if ((void **)((char *)v74 + 192) == v33)
    {
      if (*((char *)v29 + 79) < 0)
      {
        std::string::__init_copy_ctor_external(&__str, (const std::string::value_type *)v29[7], v29[8]);
      }
      else
      {
        *(_OWORD *)&__str.__r_.__value_.__l.__data_ = *v72;
        __str.__r_.__value_.__r.__words[2] = v29[9];
      }
      if (*((char *)v29 + 103) < 0)
      {
        std::string::__init_copy_ctor_external(&v92, (const std::string::value_type *)v29[10], v29[11]);
      }
      else
      {
        *(_OWORD *)&v92.__r_.__value_.__l.__data_ = *(_OWORD *)v73;
        v92.__r_.__value_.__r.__words[2] = v29[12];
      }
      long long v53 = *(_OWORD *)(v29 + 27);
      long long v99 = *(_OWORD *)(v29 + 25);
      long long v100 = v53;
      long long v54 = *(_OWORD *)(v29 + 31);
      long long v101 = *(_OWORD *)(v29 + 29);
      long long v102 = v54;
      long long v55 = *(_OWORD *)(v29 + 19);
      long long v95 = *(_OWORD *)(v29 + 17);
      long long v96 = v55;
      long long v56 = *(_OWORD *)(v29 + 23);
      long long v97 = *(_OWORD *)(v29 + 21);
      long long v98 = v56;
      long long v57 = *(_OWORD *)(v29 + 15);
      long long v93 = *(_OWORD *)(v29 + 13);
      long long v94 = v57;
      long long v104 = 0;
      uint64_t v105 = 0;
      std::string __p = 0;
      std::vector<LayerAndUsageInfo>::__init_with_size[abi:ne180100]<LayerAndUsageInfo*,LayerAndUsageInfo*>(&__p, (const void *)v29[33], v29[34], (v29[34] - v29[33]) >> 4);
      long long v106 = *((_OWORD *)v29 + 18);
      unsigned int v107 = 0;
      uint64_t v58 = std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::find<std::string>((uint64_t)v77, v73);
      if (v79 == v58)
      {
        v108[0] = (long long *)(v29 + 10);
        uint64_t v59 = std::__tree<std::__value_type<std::string,ZinIrLiveOutTensorInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrLiveOutTensorInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrLiveOutTensorInfo>>>::__emplace_unique_key_args<std::string,std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>(v77, v73, (uint64_t)&std::piecewise_construct, v108);
        std::string::operator=((std::string *)(v59 + 7), &__str);
        std::string::operator=((std::string *)(v59 + 10), &v92);
        long long v60 = v100;
        long long v62 = v101;
        long long v61 = v102;
        *(_OWORD *)(v59 + 25) = v99;
        *(_OWORD *)(v59 + 27) = v60;
        *(_OWORD *)(v59 + 29) = v62;
        *(_OWORD *)(v59 + 31) = v61;
        long long v63 = v96;
        long long v65 = v97;
        long long v64 = v98;
        *(_OWORD *)(v59 + 17) = v95;
        *(_OWORD *)(v59 + 19) = v63;
        *(_OWORD *)(v59 + 21) = v65;
        *(_OWORD *)(v59 + 23) = v64;
        long long v66 = v94;
        *(_OWORD *)(v59 + 13) = v93;
        *(_OWORD *)(v59 + 15) = v66;
        if (v59 + 7 != (uint64_t *)&__str) {
          std::vector<LayerAndUsageInfo>::__assign_with_size[abi:ne180100]<LayerAndUsageInfo*,LayerAndUsageInfo*>((char *)v59 + 264, (char *)__p, (uint64_t)v104, (v104 - (unsigned char *)__p) >> 4);
        }
        *((_OWORD *)v59 + 18) = v106;
        *((_DWORD *)v59 + 76) = v107;
      }
      else
      {
        if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
          ZinIrLiveIOManager::PrepareLiveOut(&v80, v81);
        }
        ZinIrNetworkStatus::SetError(a2, @"DuplicateOutput");
      }
      if (__p)
      {
        long long v104 = __p;
        operator delete(__p);
      }
      if (SHIBYTE(v92.__r_.__value_.__r.__words[2]) < 0) {
        operator delete(v92.__r_.__value_.__l.__data_);
      }
      if (SHIBYTE(__str.__r_.__value_.__r.__words[2]) < 0) {
        operator delete(__str.__r_.__value_.__l.__data_);
      }
      if (v79 != v58) {
        goto LABEL_93;
      }
      goto LABEL_79;
    }
    if (*((_DWORD *)v33 + 34) != v30)
    {
      if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
        ZinIrLiveIOManager::PrepareLiveOut();
      }
      ZinIrNetworkStatus::SetError(a2, @"InvalidOutput");
      goto LABEL_93;
    }
    std::string v35 = v33[12];
    if (v33[13] != v35) {
      break;
    }
LABEL_79:
    if (v84)
    {
      long long v85 = v84;
      operator delete(v84);
    }
    if (v87)
    {
      unint64_t v88 = v87;
      operator delete(v87);
    }
    uint64_t v67 = (uint64_t *)v28[1];
    if (v67)
    {
      do
      {
        unint64_t v68 = v67;
        uint64_t v67 = (uint64_t *)*v67;
      }
      while (v67);
    }
    else
    {
      do
      {
        unint64_t v68 = (uint64_t *)v28[2];
        BOOL v27 = *v68 == (void)v28;
        std::vector<std::string> v28 = (void **)v68;
      }
      while (!v27);
    }
    std::vector<std::string> v28 = (void **)v68;
    if (v68 == v71) {
      return 1;
    }
  }
  uint64_t v36 = 0;
  unsigned int v37 = 0;
  while (1)
  {
    if (*((char *)v29 + 79) < 0)
    {
      std::string::__init_copy_ctor_external(&__str, (const std::string::value_type *)v29[7], v29[8]);
    }
    else
    {
      *(_OWORD *)&__str.__r_.__value_.__l.__data_ = *v72;
      __str.__r_.__value_.__r.__words[2] = v29[9];
    }
    if (*((char *)v29 + 103) < 0)
    {
      std::string::__init_copy_ctor_external(&v92, (const std::string::value_type *)v29[10], v29[11]);
    }
    else
    {
      *(_OWORD *)&v92.__r_.__value_.__l.__data_ = *(_OWORD *)v73;
      v92.__r_.__value_.__r.__words[2] = v29[12];
    }
    long long v38 = *(_OWORD *)(v29 + 27);
    long long v99 = *(_OWORD *)(v29 + 25);
    long long v100 = v38;
    long long v39 = *(_OWORD *)(v29 + 31);
    long long v101 = *(_OWORD *)(v29 + 29);
    long long v102 = v39;
    long long v40 = *(_OWORD *)(v29 + 19);
    long long v95 = *(_OWORD *)(v29 + 17);
    long long v96 = v40;
    long long v41 = *(_OWORD *)(v29 + 23);
    long long v97 = *(_OWORD *)(v29 + 21);
    long long v98 = v41;
    long long v42 = *(_OWORD *)(v29 + 15);
    long long v93 = *(_OWORD *)(v29 + 13);
    long long v94 = v42;
    long long v104 = 0;
    uint64_t v105 = 0;
    std::string __p = 0;
    std::vector<LayerAndUsageInfo>::__init_with_size[abi:ne180100]<LayerAndUsageInfo*,LayerAndUsageInfo*>(&__p, (const void *)v29[33], v29[34], (v29[34] - v29[33]) >> 4);
    long long v43 = (void **)&v35[24 * v36];
    long long v106 = *((_OWORD *)v29 + 18);
    unsigned int v107 = v37;
    uint64_t v44 = std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::find<std::string>((uint64_t)v77, v43);
    if (v79 == v44)
    {
      v108[0] = (long long *)v43;
      size_t v45 = std::__tree<std::__value_type<std::string,ZinIrLiveOutTensorInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrLiveOutTensorInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrLiveOutTensorInfo>>>::__emplace_unique_key_args<std::string,std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>(v77, v43, (uint64_t)&std::piecewise_construct, v108);
      std::string::operator=((std::string *)(v45 + 7), &__str);
      std::string::operator=((std::string *)(v45 + 10), &v92);
      long long v46 = v100;
      long long v48 = v101;
      long long v47 = v102;
      *(_OWORD *)(v45 + 25) = v99;
      *(_OWORD *)(v45 + 27) = v46;
      *(_OWORD *)(v45 + 29) = v48;
      *(_OWORD *)(v45 + 31) = v47;
      long long v49 = v96;
      long long v51 = v97;
      long long v50 = v98;
      *(_OWORD *)(v45 + 17) = v95;
      *(_OWORD *)(v45 + 19) = v49;
      *(_OWORD *)(v45 + 21) = v51;
      *(_OWORD *)(v45 + 23) = v50;
      long long v52 = v94;
      *(_OWORD *)(v45 + 13) = v93;
      *(_OWORD *)(v45 + 15) = v52;
      if (v45 + 7 != (uint64_t *)&__str) {
        std::vector<LayerAndUsageInfo>::__assign_with_size[abi:ne180100]<LayerAndUsageInfo*,LayerAndUsageInfo*>((char *)v45 + 264, (char *)__p, (uint64_t)v104, (v104 - (unsigned char *)__p) >> 4);
      }
      *((_OWORD *)v45 + 18) = v106;
      *((_DWORD *)v45 + 76) = v107;
    }
    else
    {
      if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
        ZinIrLiveIOManager::PrepareLiveOut(&v82, v83);
      }
      ZinIrNetworkStatus::SetError(a2, @"DuplicateOutput");
    }
    if (__p)
    {
      long long v104 = __p;
      operator delete(__p);
    }
    if (SHIBYTE(v92.__r_.__value_.__r.__words[2]) < 0) {
      operator delete(v92.__r_.__value_.__l.__data_);
    }
    if (SHIBYTE(__str.__r_.__value_.__r.__words[2]) < 0) {
      operator delete(__str.__r_.__value_.__l.__data_);
    }
    if (v79 != v44) {
      break;
    }
    std::string v35 = v34[12];
    uint64_t v36 = ++v37;
    if (0xAAAAAAAAAAAAAAABLL * (((unsigned char *)v34[13] - v35) >> 3) <= v37) {
      goto LABEL_79;
    }
  }
LABEL_93:
  if (v84)
  {
    long long v85 = v84;
    operator delete(v84);
  }
  if (v87)
  {
    unint64_t v88 = v87;
    operator delete(v87);
  }
  return 0;
}

void sub_2112AA264(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,void *__p,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33,void *a34,uint64_t a35,uint64_t a36,uint64_t a37,uint64_t a38,void *a39,uint64_t a40,int a41,__int16 a42,char a43,char a44,void *a45,uint64_t a46,int a47,__int16 a48,char a49,char a50)
{
  if (__p) {
    operator delete(__p);
  }
  if (a34) {
    operator delete(a34);
  }
  _Unwind_Resume(exception_object);
}

void ZinIrLiveIOManager::CreateOutputTensor(uint64_t a1@<X0>, void **a2@<X2>, int a3@<W4>, CFArrayRef *a4@<X6>, void *a5@<X8>)
{
  uint64_t v19 = 0;
  uint64_t v20 = 0;
  uint64_t v9 = std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::find<std::string>(a1 + 256, a2);
  if ((void **)(a1 + 264) == v9)
  {
    uint64_t v18 = 0;
    int v13 = 0;
    long long v15 = 0;
    CFTypeID v16 = 0;
    uint64_t v14 = 0;
    LODWORD(v17) = 0;
    ZinIrTensor::CreateTensor();
  }
  int v10 = v9;
  if (*((unsigned char *)v9 + 256))
  {
    uint64_t v11 = ZinIr4CCInfo::ZinIr4CCInfo(&v13, *((unsigned int *)v9 + 65));
    *(void *)long long v12 = 0;
    if (ZinIr4CCInfo::GetPlaneFormat(v11, *((_DWORD *)v10 + 76), &v12[1])
      && ZinIr4CCInfo::GetPlaneInterleave((ZinIr4CCInfo *)&v13, *((_DWORD *)v10 + 76), v12))
    {
      operator new();
    }
    if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
      ZinIrLiveIOManager::CreateOutputTensor();
    }
    ZinIrNetworkStatus::SetError(a4, @"InvalidOutput");
    *a5 = 0;
    a5[1] = 0;
    if (v15)
    {
      CFTypeID v16 = v15;
      operator delete(v15);
    }
  }
  else
  {
    if (!*((_DWORD *)v9 + 76))
    {
      if (!*((_DWORD *)v9 + 26)) {
        *((_DWORD *)v9 + 26) = a3;
      }
      operator new();
    }
    if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
      ZinIrLiveIOManager::CreateOutputTensor();
    }
    ZinIrNetworkStatus::SetError(a4, @"InvalidOutput");
    *a5 = 0;
    a5[1] = 0;
  }
}

void sub_2112AAB2C(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, void *a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,void *a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,void *__p,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33)
{
  if (__p) {
    operator delete(__p);
  }
  if (a12) {
    operator delete(a12);
  }
  (*(void (**)(uint64_t))(*(void *)v33 + 8))(v33);
  _Unwind_Resume(a1);
}

void std::make_unique[abi:ne180100]<ZinIrTensor::MirInfo,ZinIrTensor::AllocationHint,long &,DimensionOrderHint &,ZinTensorDimensions &>()
{
}

void sub_2112AAE24(_Unwind_Exception *a1)
{
  MEMORY[0x21667D3C0](v1, 0x10B0C405A042323);
  _Unwind_Resume(a1);
}

BOOL ZinIrLiveIOManager::PrepareLiveOutBinding(uint64_t a1, uint64_t a2, uint64_t *a3, CFArrayRef *a4)
{
  *(void *)((char *)&v42[3] + 4) = *MEMORY[0x263EF8340];
  __p.n128_u32[0] = 1;
  uint64_t v7 = std::map<ZinIrDimension,unsigned long>::at(a1 + 64, (int *)&__p);
  __p.n128_u32[0] = 1;
  uint64_t v33 = std::map<ZinIrDimension,unsigned long>::at(a1 + 40, (int *)&__p);
  __p.n128_u32[0] = 1;
  int v8 = std::map<ZinIrDimension,unsigned long>::at(a1 + 16, (int *)&__p);
  uint64_t v11 = *v7;
  uint64_t v9 = v7 + 1;
  int v10 = (void **)v11;
  if ((uint64_t *)v11 == v9)
  {
LABEL_22:
    uint64_t v20 = *v33;
    if ((uint64_t *)*v33 == v33 + 1) {
      return 1;
    }
    uint64_t v21 = a1 + 208;
    long long v22 = (void **)(a1 + 216);
    do
    {
      uint64_t v23 = std::map<std::string,BOOL>::at((uint64_t)v8, (void **)(v20 + 32));
      ZinIr4CCInfo::ZinIr4CCInfo(&__p, *(unsigned int *)(v23 + 204));
      int IsCompressed = ZinIr4CCInfo::IsCompressed((ZinIr4CCInfo *)&__p);
      int v25 = std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::find<std::string>(v21, (void **)(v20 + 32));
      if (v22 == v25)
      {
        if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
          ZinIrLiveIOManager::PrepareLiveOutBinding(&v41, v20, (void *)(v20 + 32), v42);
        }
        ZinIrNetworkStatus::SetError(a4, @"InvalidOutput");
        int v28 = 1;
      }
      else
      {
        __n128 v34 = 0uLL;
        uint64_t v35 = 0;
        std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(&v34, v25[7], (uint64_t)v25[8], ((unsigned char *)v25[8] - (unsigned char *)v25[7]) >> 3);
        uint64_t v26 = *a3;
        if (IsCompressed) {
          ZinIrBindings::AddCompressedMapping(v26, (long long *)v23, 1, &v34);
        }
        else {
          ZinIrBindings::AddUncompressedMapping(v26, (long long *)v23, 1, &v34);
        }
        if (v27 || (ZinIrBindings::AddIO(*a3, (long long *)v23, 1, v23), v29))
        {
          if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
            ZinIrLiveIOManager::PrepareLiveOutBinding();
          }
          ZinIrNetworkStatus::SetError(a4, @"InvalidOutput");
          int v28 = 1;
        }
        else
        {
          int v28 = 0;
        }
        if (v34.n128_u64[0])
        {
          v34.n128_u64[1] = v34.n128_u64[0];
          operator delete((void *)v34.n128_u64[0]);
        }
      }
      if (v37)
      {
        long long v38 = v37;
        operator delete(v37);
      }
      BOOL result = v28 == 0;
      if (v28) {
        break;
      }
      int v31 = *(uint64_t **)(v20 + 8);
      if (v31)
      {
        do
        {
          long long v32 = v31;
          int v31 = (uint64_t *)*v31;
        }
        while (v31);
      }
      else
      {
        do
        {
          long long v32 = *(uint64_t **)(v20 + 16);
          BOOL v19 = *v32 == v20;
          uint64_t v20 = (uint64_t)v32;
        }
        while (!v19);
      }
      uint64_t v20 = (uint64_t)v32;
    }
    while (v32 != v33 + 1);
    return result;
  }
  while (1)
  {
    long long v12 = (long long *)std::map<std::string,BOOL>::at((uint64_t)v8, v10 + 4);
    int v13 = std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::find<std::string>(a1 + 208, v10 + 4);
    if ((void **)(a1 + 216) == v13) {
      break;
    }
    __n128 __p = 0uLL;
    unsigned int v37 = 0;
    std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(&__p, v13[7], (uint64_t)v13[8], ((unsigned char *)v13[8] - (unsigned char *)v13[7]) >> 3);
    if (__p.n128_u64[1] - __p.n128_u64[0] != 8)
    {
      if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
        ZinIrLiveIOManager::PrepareLiveOutBinding(&v39, v40);
      }
      goto LABEL_10;
    }
    ZinIrBindings::AddUncompressedMapping(*a3, v12, 1, &__p);
    if (v14 || (ZinIrBindings::AddIO(*a3, v12, 1, (uint64_t)v12), v15))
    {
      if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
        ZinIrLiveIOManager::PrepareLiveOutBinding();
      }
LABEL_10:
      ZinIrNetworkStatus::SetError(a4, @"InvalidOutput");
      int v16 = 0;
      goto LABEL_11;
    }
    int v16 = 1;
LABEL_11:
    if (__p.n128_u64[0])
    {
      __p.n128_u64[1] = __p.n128_u64[0];
      operator delete((void *)__p.n128_u64[0]);
    }
    if (!v16) {
      return 0;
    }
    uint64_t v17 = (uint64_t *)v10[1];
    if (v17)
    {
      do
      {
        uint64_t v18 = v17;
        uint64_t v17 = (uint64_t *)*v17;
      }
      while (v17);
    }
    else
    {
      do
      {
        uint64_t v18 = (uint64_t *)v10[2];
        BOOL v19 = *v18 == (void)v10;
        int v10 = (void **)v18;
      }
      while (!v19);
    }
    int v10 = (void **)v18;
    if (v18 == v9) {
      goto LABEL_22;
    }
  }
  if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
    ZinIrLiveIOManager::PrepareLiveOutBinding();
  }
  ZinIrNetworkStatus::SetError(a4, @"InvalidOutput");
  return 0;
}

void sub_2112AB260(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, void *a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, void *__p, uint64_t a19)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

BOOL ZinIrLiveIOManager::ValidateMultiplanarLiveOutput(ZinIrLiveIOManager *this)
{
  *(void *)((char *)&v37[1] + 4) = *MEMORY[0x263EF8340];
  v31[0] = 1;
  uint64_t v2 = std::map<ZinIrDimension,unsigned long>::at((uint64_t)this + 40, v31);
  v31[0] = 1;
  int v3 = std::map<ZinIrDimension,unsigned long>::at((uint64_t)this + 16, v31);
  uint64_t v6 = *v2;
  uint64_t v4 = v2 + 1;
  uint64_t v5 = v6;
  if ((uint64_t *)v6 == v4) {
    return 1;
  }
  uint64_t v7 = (uint64_t)v3;
  int v27 = (void **)(v3 + 1);
  long long v24 = (void **)((char *)this + 216);
  int v25 = (char *)this + 208;
  int64x2_t v26 = vdupq_n_s64(1uLL);
  while (1)
  {
    int v8 = std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::find<std::string>(v7, (void **)(v5 + 32));
    if (v27 == v8) {
      break;
    }
    ZinIr4CCInfo::ZinIr4CCInfo(v31, *((unsigned int *)v8 + 65));
    PlaneCFIndex Count = ZinIr4CCInfo::GetPlaneCount((ZinIr4CCInfo *)v31);
    if (PlaneCount == 1)
    {
      int v10 = 3;
      goto LABEL_25;
    }
    uint64_t v11 = std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::find<std::string>((uint64_t)v25, (void **)(v5 + 32));
    long long v12 = v11;
    if (v24 == v11 || (int v13 = v11[7], PlaneCount != ((unsigned char *)v11[8] - (unsigned char *)v13) >> 3))
    {
      if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
        ZinIrLiveIOManager::ValidateMultiplanarLiveOutput(&v36, v5, (void *)(v5 + 32), v37);
      }
LABEL_24:
      int v10 = 1;
      goto LABEL_25;
    }
    if (PlaneCount)
    {
      uint64_t v14 = 0;
      int v15 = (uint64_t *)*v13;
      while (1)
      {
        v29[0] = v26;
        v29[1] = v26;
        uint64_t v30 = 1;
        uint64_t v28 = 0;
        if (!ZinIr4CCInfo::GetPlaneInfo((ZinIr4CCInfo *)v31, v14, v15[9], v15[8], v15[7], v29, (_DWORD *)&v28 + 1, &v28))goto LABEL_24; {
        uint64_t v16 = *((void *)v12[7] + v14);
        }
        uint64_t Interleave = ZinIrTensor::GetInterleave((ZinIrTensor *)v16);
        if (v18) {
          uint64_t v19 = Interleave;
        }
        else {
          uint64_t v19 = 1;
        }
        if (!ZinTensorDimensionsEqual(v29, (void *)(v16 + 48))
          || (HIDWORD(v28) == *(_DWORD *)(v16 + 88) ? (BOOL v20 = v19 == v28) : (BOOL v20 = 0), !v20))
        {
          if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
            ZinIrLiveIOManager::ValidateMultiplanarLiveOutput(&v34, v5, (void *)(v5 + 32), &v35);
          }
          goto LABEL_24;
        }
        int v10 = 0;
        if (PlaneCount == ++v14) {
          goto LABEL_25;
        }
      }
    }
    int v10 = 0;
LABEL_25:
    if (__p)
    {
      uint64_t v33 = __p;
      operator delete(__p);
    }
    if (v10 != 3 && v10) {
      return 0;
    }
    uint64_t v21 = *(uint64_t **)(v5 + 8);
    if (v21)
    {
      do
      {
        long long v22 = v21;
        uint64_t v21 = (uint64_t *)*v21;
      }
      while (v21);
    }
    else
    {
      do
      {
        long long v22 = *(uint64_t **)(v5 + 16);
        BOOL v20 = *v22 == v5;
        uint64_t v5 = (uint64_t)v22;
      }
      while (!v20);
    }
    uint64_t v5 = (uint64_t)v22;
    if (v22 == v4) {
      return 1;
    }
  }
  BOOL result = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
  if (!result) {
    return result;
  }
  ZinIrLiveIOManager::ValidateMultiplanarLiveOutput();
  return 0;
}

void sub_2112AB580(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,void *__p,uint64_t a25)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinIrLiveIOManager::PrepareLiveInParamBinding(uint64_t a1)
{
  if (*(void *)(a1 + 160) != a1 + 168) {
    operator new();
  }
  return 1;
}

void sub_2112AB718(_Unwind_Exception *a1)
{
  MEMORY[0x21667D3C0](v1, 0x1012C405C87E9CELL);
  _Unwind_Resume(a1);
}

uint64_t *std::set<std::string>::set[abi:ne180100](uint64_t *a1, uint64_t a2)
{
  a1[2] = 0;
  a1[1] = 0;
  *a1 = (uint64_t)(a1 + 1);
  std::set<std::string>::insert[abi:ne180100]<std::__tree_const_iterator<std::string,std::__tree_node<std::string,void *> *,long>>(a1, *(void ***)a2, (void **)(a2 + 8));
  return a1;
}

void sub_2112AB798(_Unwind_Exception *a1)
{
  std::__tree<std::__value_type<std::string,SpatialSplitMode>,std::__map_value_compare<std::string,std::__value_type<std::string,SpatialSplitMode>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,SpatialSplitMode>>>::destroy(v1, *(char **)(v1 + 8));
  _Unwind_Resume(a1);
}

uint64_t *std::set<std::string>::insert[abi:ne180100]<std::__tree_const_iterator<std::string,std::__tree_node<std::string,void *> *,long>>(uint64_t *result, void **a2, void **a3)
{
  if (a2 != a3)
  {
    uint64_t v4 = a2;
    uint64_t v5 = (uint64_t **)result;
    uint64_t v6 = (uint64_t)(result + 1);
    do
    {
      BOOL result = std::__tree<std::string>::__emplace_hint_unique_key_args<std::string,std::string const&>(v5, v6, v4 + 4, (uint64_t)(v4 + 4));
      uint64_t v7 = (void **)v4[1];
      if (v7)
      {
        do
        {
          int v8 = v7;
          uint64_t v7 = (void **)*v7;
        }
        while (v7);
      }
      else
      {
        do
        {
          int v8 = (void **)v4[2];
          BOOL v9 = *v8 == v4;
          uint64_t v4 = v8;
        }
        while (!v9);
      }
      uint64_t v4 = v8;
    }
    while (v8 != a3);
  }
  return result;
}

uint64_t *std::__tree<std::string>::__emplace_hint_unique_key_args<std::string,std::string const&>(uint64_t **a1, uint64_t a2, void **a3, uint64_t a4)
{
  uint64_t v6 = (uint64_t **)std::__tree<std::__value_type<std::string,SpatialSplitMode>,std::__map_value_compare<std::string,std::__value_type<std::string,SpatialSplitMode>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,SpatialSplitMode>>>::__find_equal<std::string>(a1, a2, &v10, &v9, a3);
  BOOL result = *v6;
  if (!*v6)
  {
    std::__tree<std::string>::__construct_node<std::string const&>((uint64_t)a1, a4, (uint64_t)&v8);
    std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::__insert_node_at(a1, (uint64_t)v10, v6, v8);
    return v8;
  }
  return result;
}

uint64_t *std::set<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>::set[abi:ne180100](uint64_t *a1, uint64_t a2)
{
  a1[2] = 0;
  a1[1] = 0;
  *a1 = (uint64_t)(a1 + 1);
  std::set<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>::insert[abi:ne180100]<std::__tree_const_iterator<std::shared_ptr<ZinIrTensor>,std::__tree_node<std::shared_ptr<ZinIrTensor>,void *> *,long>>(a1, *(void **)a2, (void *)(a2 + 8));
  return a1;
}

void sub_2112AB900(_Unwind_Exception *a1)
{
  std::__tree<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>::destroy(v1, *(void **)(v1 + 8));
  _Unwind_Resume(a1);
}

uint64_t *std::set<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>::insert[abi:ne180100]<std::__tree_const_iterator<std::shared_ptr<ZinIrTensor>,std::__tree_node<std::shared_ptr<ZinIrTensor>,void *> *,long>>(uint64_t *result, void *a2, void *a3)
{
  if (a2 != a3)
  {
    uint64_t v4 = a2;
    uint64_t v5 = (uint64_t **)result;
    uint64_t v6 = result + 1;
    do
    {
      BOOL result = std::__tree<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>::__emplace_hint_unique_key_args<std::shared_ptr<ZinIrTensor>,std::shared_ptr<ZinIrTensor> const&>(v5, v6, v4 + 4, v4 + 4);
      uint64_t v7 = (void *)v4[1];
      if (v7)
      {
        do
        {
          int v8 = v7;
          uint64_t v7 = (void *)*v7;
        }
        while (v7);
      }
      else
      {
        do
        {
          int v8 = (void *)v4[2];
          BOOL v9 = *v8 == (void)v4;
          uint64_t v4 = v8;
        }
        while (!v9);
      }
      uint64_t v4 = v8;
    }
    while (v8 != a3);
  }
  return result;
}

uint64_t *std::__tree<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>::__emplace_hint_unique_key_args<std::shared_ptr<ZinIrTensor>,std::shared_ptr<ZinIrTensor> const&>(uint64_t **a1, void *a2, uint64_t *a3, uint64_t *a4)
{
  uint64_t v6 = (uint64_t **)std::__tree<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>::__find_equal<std::shared_ptr<ZinIrTensor>>(a1, a2, &v12, &v11, a3);
  uint64_t v7 = *v6;
  if (!*v6)
  {
    int v8 = v6;
    uint64_t v7 = (uint64_t *)operator new(0x30uLL);
    uint64_t v9 = a4[1];
    v7[4] = *a4;
    v7[5] = v9;
    if (v9) {
      atomic_fetch_add_explicit((atomic_ullong *volatile)(v9 + 8), 1uLL, memory_order_relaxed);
    }
    std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::__insert_node_at(a1, v12, v8, v7);
  }
  return v7;
}

void *std::__tree<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>::__find_equal<std::shared_ptr<ZinIrTensor>>(void *a1, void *a2, void *a3, void *a4, uint64_t *a5)
{
  if (a1 + 1 == a2) {
    goto LABEL_5;
  }
  uint64_t v5 = *a5;
  uint64_t v6 = a2[4];
  if (!*a5)
  {
    if (!v6) {
      goto LABEL_25;
    }
LABEL_12:
    uint64_t v12 = a2[1];
    if (v12)
    {
      int v13 = (void *)a2[1];
      do
      {
        a4 = v13;
        int v13 = (void *)*v13;
      }
      while (v13);
    }
    else
    {
      uint64_t v17 = a2;
      do
      {
        a4 = (void *)v17[2];
        BOOL v15 = *a4 == (void)v17;
        uint64_t v17 = a4;
      }
      while (!v15);
    }
    if (a4 == a1 + 1 || v5 && ((uint64_t v18 = a4[4]) == 0 || *(void *)(v5 + 8) < *(void *)(v18 + 8)))
    {
      if (v12)
      {
        *a3 = a4;
      }
      else
      {
        *a3 = a2;
        return a2 + 1;
      }
      return a4;
    }
    return std::__tree<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>::__find_equal<std::shared_ptr<ZinIrTensor>>((uint64_t)a1, a3, a5);
  }
  if (!v6 || (unint64_t v7 = *(void *)(v5 + 8), v8 = *(void *)(v6 + 8), v7 < v8))
  {
LABEL_5:
    uint64_t v9 = *a2;
    if ((void *)*a1 == a2)
    {
      uint64_t v11 = a2;
LABEL_21:
      if (v9)
      {
        *a3 = v11;
        return v11 + 1;
      }
      else
      {
        *a3 = a2;
        return a2;
      }
    }
    if (v9)
    {
      int v10 = (void *)*a2;
      do
      {
        uint64_t v11 = v10;
        int v10 = (void *)v10[1];
      }
      while (v10);
    }
    else
    {
      uint64_t v14 = a2;
      do
      {
        uint64_t v11 = (void *)v14[2];
        BOOL v15 = *v11 == (void)v14;
        uint64_t v14 = v11;
      }
      while (v15);
    }
    uint64_t v16 = v11[4];
    if (v16 && (!*a5 || *(void *)(v16 + 8) < *(void *)(*a5 + 8))) {
      goto LABEL_21;
    }
    return std::__tree<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>::__find_equal<std::shared_ptr<ZinIrTensor>>((uint64_t)a1, a3, a5);
  }
  if (v8 < v7) {
    goto LABEL_12;
  }
LABEL_25:
  *a3 = a2;
  *a4 = a2;
  return a4;
}

uint64_t std::vector<ZinIrIOInfo>::__emplace_back_slow_path<ZinIrIOInfo>(uint64_t *a1, long long *a2)
{
  uint64_t v3 = *a1;
  unint64_t v4 = 0xEF7BDEF7BDEF7BDFLL * ((a1[1] - *a1) >> 3);
  unint64_t v5 = v4 + 1;
  if (v4 + 1 > 0x108421084210842) {
    std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
  }
  uint64_t v7 = (uint64_t)(a1 + 2);
  unint64_t v8 = 0xEF7BDEF7BDEF7BDFLL * ((a1[2] - v3) >> 3);
  if (2 * v8 > v5) {
    unint64_t v5 = 2 * v8;
  }
  if (v8 >= 0x84210842108421) {
    unint64_t v9 = 0x108421084210842;
  }
  else {
    unint64_t v9 = v5;
  }
  v23[4] = a1 + 2;
  if (v9) {
    int v10 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ZinIrIOInfo>>(v7, v9);
  }
  else {
    int v10 = 0;
  }
  uint64_t v11 = &v10[248 * v4];
  v23[0] = v10;
  v23[1] = v11;
  v23[3] = &v10[248 * v9];
  long long v12 = *a2;
  *((void *)v11 + 2) = *((void *)a2 + 2);
  *(_OWORD *)uint64_t v11 = v12;
  *((void *)a2 + 1) = 0;
  *((void *)a2 + 2) = 0;
  *(void *)a2 = 0;
  long long v13 = *(long long *)((char *)a2 + 24);
  *((void *)v11 + 5) = *((void *)a2 + 5);
  *(_OWORD *)(v11 + 24) = v13;
  *((void *)a2 + 4) = 0;
  *((void *)a2 + 5) = 0;
  *((void *)a2 + 3) = 0;
  long long v14 = a2[4];
  *((_OWORD *)v11 + 3) = a2[3];
  *((_OWORD *)v11 + 4) = v14;
  long long v15 = a2[5];
  long long v16 = a2[6];
  long long v17 = a2[8];
  *((_OWORD *)v11 + 7) = a2[7];
  *((_OWORD *)v11 + 8) = v17;
  *((_OWORD *)v11 + 5) = v15;
  *((_OWORD *)v11 + 6) = v16;
  long long v18 = a2[9];
  long long v19 = a2[10];
  long long v20 = a2[12];
  *((_OWORD *)v11 + 11) = a2[11];
  *((_OWORD *)v11 + 12) = v20;
  *((_OWORD *)v11 + 9) = v18;
  *((_OWORD *)v11 + 10) = v19;
  *((void *)v11 + 27) = 0;
  *((void *)v11 + 28) = 0;
  *((void *)v11 + 26) = 0;
  *((_OWORD *)v11 + 13) = a2[13];
  *((void *)v11 + 28) = *((void *)a2 + 28);
  *((void *)a2 + 26) = 0;
  *((void *)a2 + 27) = 0;
  *((void *)a2 + 28) = 0;
  *(_OWORD *)(v11 + 2std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(long long *)((char *)a2 + 232);
  void v23[2] = v11 + 248;
  std::vector<ZinIrIOInfo>::__swap_out_circular_buffer(a1, v23);
  uint64_t v21 = a1[1];
  std::__split_buffer<ZinIrIOInfo>::~__split_buffer((uint64_t)v23);
  return v21;
}

void sub_2112ABD04(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::__split_buffer<ZinIrIOInfo>::~__split_buffer((uint64_t)va);
  _Unwind_Resume(a1);
}

uint64_t *std::vector<ZinIrIOInfo>::__swap_out_circular_buffer(uint64_t *result, void *a2)
{
  uint64_t v2 = *result;
  uint64_t v3 = result[1];
  uint64_t v4 = a2[1];
  if (v3 == *result)
  {
    uint64_t v5 = a2[1];
  }
  else
  {
    do
    {
      uint64_t v5 = v4 - 248;
      long long v6 = *(_OWORD *)(v3 - 248);
      *(void *)(v4 - 2std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(void *)(v3 - 232);
      *(_OWORD *)(v4 - 248) = v6;
      *(void *)(v3 - 240) = 0;
      *(void *)(v3 - 2std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = 0;
      *(void *)(v3 - 248) = 0;
      long long v7 = *(_OWORD *)(v3 - 224);
      *(void *)(v4 - 208) = *(void *)(v3 - 208);
      *(_OWORD *)(v4 - 224) = v7;
      *(void *)(v3 - 216) = 0;
      *(void *)(v3 - 208) = 0;
      *(void *)(v3 - 224) = 0;
      long long v8 = *(_OWORD *)(v3 - 200);
      *(_OWORD *)(v4 - 184) = *(_OWORD *)(v3 - 184);
      *(_OWORD *)(v4 - 200) = v8;
      long long v9 = *(_OWORD *)(v3 - 168);
      long long v10 = *(_OWORD *)(v3 - 152);
      long long v11 = *(_OWORD *)(v3 - 136);
      *(_OWORD *)(v4 - 120) = *(_OWORD *)(v3 - 120);
      *(_OWORD *)(v4 - 136) = v11;
      *(_OWORD *)(v4 - 152) = v10;
      *(_OWORD *)(v4 - 168) = v9;
      long long v12 = *(_OWORD *)(v3 - 104);
      long long v13 = *(_OWORD *)(v3 - 88);
      long long v14 = *(_OWORD *)(v3 - 72);
      *(_OWORD *)(v4 - 56) = *(_OWORD *)(v3 - 56);
      *(_OWORD *)(v4 - 72) = v14;
      *(_OWORD *)(v4 - 88) = v13;
      *(_OWORD *)(v4 - 104) = v12;
      *(void *)(v4 - std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = 0;
      *(void *)(v4 - 24) = 0;
      *(void *)(v4 - 40) = 0;
      *(_OWORD *)(v4 - 40) = *(_OWORD *)(v3 - 40);
      *(void *)(v4 - 24) = *(void *)(v3 - 24);
      *(void *)(v3 - 40) = 0;
      *(void *)(v3 - std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = 0;
      *(void *)(v3 - 24) = 0;
      *(_OWORD *)(v4 - 16) = *(_OWORD *)(v3 - 16);
      v3 -= 248;
      v4 -= 248;
    }
    while (v3 != v2);
  }
  a2[1] = v5;
  uint64_t v15 = *result;
  uint64_t *result = v5;
  a2[1] = v15;
  uint64_t v16 = result[1];
  result[1] = a2[2];
  a2[2] = v16;
  uint64_t v17 = result[2];
  result[2] = a2[3];
  a2[3] = v17;
  *a2 = a2[1];
  return result;
}

void *std::__allocate_at_least[abi:ne180100]<std::allocator<ZinIrIOInfo>>(uint64_t a1, unint64_t a2)
{
  if (a2 >= 0x108421084210843) {
    std::__throw_bad_array_new_length[abi:ne180100]();
  }
  return operator new(248 * a2);
}

void std::__destroy_at[abi:ne180100]<ZinIrIOInfo,0>(uint64_t a1)
{
  uint64_t v2 = *(void **)(a1 + 208);
  if (v2)
  {
    *(void *)(a1 + 216) = v2;
    operator delete(v2);
  }
  if (*(char *)(a1 + 47) < 0) {
    operator delete(*(void **)(a1 + 24));
  }
  if (*(char *)(a1 + 23) < 0)
  {
    uint64_t v3 = *(void **)a1;
    operator delete(v3);
  }
}

uint64_t std::__split_buffer<ZinIrIOInfo>::~__split_buffer(uint64_t a1)
{
  uint64_t v3 = *(void *)(a1 + 8);
  for (uint64_t i = *(void *)(a1 + 16); i != v3; uint64_t i = *(void *)(a1 + 16))
  {
    *(void *)(a1 + 16) = i - 248;
    std::__destroy_at[abi:ne180100]<ZinIrIOInfo,0>(i - 248);
  }
  if (*(void *)a1) {
    operator delete(*(void **)a1);
  }
  return a1;
}

void std::vector<ZinIrIOInfo>::__destroy_vector::operator()[abi:ne180100](void ***a1)
{
  uint64_t v1 = *a1;
  uint64_t v2 = **a1;
  if (v2)
  {
    uint64_t v4 = (uint64_t)v1[1];
    uint64_t v5 = **a1;
    if ((void *)v4 != v2)
    {
      do
      {
        v4 -= 248;
        std::__destroy_at[abi:ne180100]<ZinIrIOInfo,0>(v4);
      }
      while ((void *)v4 != v2);
      uint64_t v5 = **a1;
    }
    v1[1] = v2;
    operator delete(v5);
  }
}

std::vector<std::string> *__cdecl std::vector<std::string>::vector(std::vector<std::string> *this, std::vector<std::string>::size_type __n, const std::vector<std::string>::value_type *__x)
{
  this->__begin_ = 0;
  this->__end_ = 0;
  this->__end_cap_.__value_ = 0;
  if (__n)
  {
    std::vector<std::string>::__vallocate[abi:ne180100](this, __n);
    std::vector<std::string>::pointer end = this->__end_;
    std::vector<std::string>::size_type v7 = 3 * __n;
    long long v8 = &end[__n];
    uint64_t v9 = 8 * v7;
    do
    {
      if (SHIBYTE(__x->__r_.__value_.__r.__words[2]) < 0)
      {
        std::string::__init_copy_ctor_external(end, __x->__r_.__value_.__l.__data_, __x->__r_.__value_.__l.__size_);
      }
      else
      {
        long long v10 = *(_OWORD *)&__x->__r_.__value_.__l.__data_;
        end->__r_.__value_.__r.__words[2] = __x->__r_.__value_.__r.__words[2];
        *(_OWORD *)&end->__r_.__value_.__l.__data_ = v10;
      }
      ++end;
      v9 -= 24;
    }
    while (v9);
    this->__end_ = v8;
  }
  return this;
}

void sub_2112AC05C(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, void **a9)
{
}

void *std::vector<ZinIrTensor *>::vector(void *a1, unint64_t a2, void *a3)
{
  *a1 = 0;
  a1[1] = 0;
  a1[2] = 0;
  if (a2)
  {
    std::vector<double>::__vallocate[abi:ne180100](a1, a2);
    long long v6 = (void *)a1[1];
    std::vector<std::string>::size_type v7 = &v6[a2];
    uint64_t v8 = 8 * a2;
    do
    {
      *v6++ = *a3;
      v8 -= 8;
    }
    while (v8);
    a1[1] = v7;
  }
  return a1;
}

void sub_2112AC0E4(_Unwind_Exception *exception_object)
{
  uint64_t v3 = *(void **)v1;
  if (*(void *)v1)
  {
    *(void *)(v1 + 8) = v3;
    operator delete(v3);
  }
  _Unwind_Resume(exception_object);
}

uint64_t std::map<IOType,std::set<std::string>>::map[abi:ne180100](uint64_t a1, int *a2, uint64_t a3)
{
  *(void *)(a1 + 8) = 0;
  uint64_t v4 = (uint64_t *)(a1 + 8);
  *(void *)(a1 + 16) = 0;
  *(void *)a1 = a1 + 8;
  if (a3)
  {
    uint64_t v6 = 32 * a3;
    do
    {
      std::__tree<std::__value_type<IOType,std::set<std::string>>,std::__map_value_compare<IOType,std::__value_type<IOType,std::set<std::string>>,std::less<IOType>,true>,std::allocator<std::__value_type<IOType,std::set<std::string>>>>::__emplace_hint_unique_key_args<IOType,std::pair<IOType const,std::set<std::string>> const&>((uint64_t **)a1, v4, a2, a2);
      a2 += 8;
      v6 -= 32;
    }
    while (v6);
  }
  return a1;
}

void sub_2112AC168(_Unwind_Exception *a1)
{
  std::__tree<std::__value_type<IOType,std::set<std::string>>,std::__map_value_compare<IOType,std::__value_type<IOType,std::set<std::string>>,std::less<IOType>,true>,std::allocator<std::__value_type<IOType,std::set<std::string>>>>::destroy(v1, *(void **)(v1 + 8));
  _Unwind_Resume(a1);
}

uint64_t *std::__tree<std::__value_type<IOType,std::set<std::string>>,std::__map_value_compare<IOType,std::__value_type<IOType,std::set<std::string>>,std::less<IOType>,true>,std::allocator<std::__value_type<IOType,std::set<std::string>>>>::__emplace_hint_unique_key_args<IOType,std::pair<IOType const,std::set<std::string>> const&>(uint64_t **a1, uint64_t *a2, int *a3, _DWORD *a4)
{
  uint64_t v6 = (uint64_t **)std::__tree<std::__value_type<ZinIrDimension,unsigned long>,std::__map_value_compare<ZinIrDimension,std::__value_type<ZinIrDimension,unsigned long>,std::less<ZinIrDimension>,true>,std::allocator<std::__value_type<ZinIrDimension,unsigned long>>>::__find_equal<ZinIrDimension>(a1, a2, &v10, &v9, a3);
  BOOL result = *v6;
  if (!*v6)
  {
    std::__tree<std::__value_type<IOType,std::set<std::string>>,std::__map_value_compare<IOType,std::__value_type<IOType,std::set<std::string>>,std::less<IOType>,true>,std::allocator<std::__value_type<IOType,std::set<std::string>>>>::__construct_node<std::pair<IOType const,std::set<std::string>> const&>((uint64_t)a1, a4, (uint64_t)&v8);
    std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::__insert_node_at(a1, (uint64_t)v10, v6, v8);
    return v8;
  }
  return result;
}

uint64_t *std::__tree<std::__value_type<IOType,std::set<std::string>>,std::__map_value_compare<IOType,std::__value_type<IOType,std::set<std::string>>,std::less<IOType>,true>,std::allocator<std::__value_type<IOType,std::set<std::string>>>>::__construct_node<std::pair<IOType const,std::set<std::string>> const&>@<X0>(uint64_t a1@<X0>, _DWORD *a2@<X1>, uint64_t a3@<X8>)
{
  uint64_t v5 = a1 + 8;
  uint64_t v6 = operator new(0x40uLL);
  *(void *)(a3 + 8) = v5;
  *(void *)a3 = v6;
  *(unsigned char *)(a3 + 16) = 0;
  *((_DWORD *)v6 + 8) = *a2;
  BOOL result = std::set<std::string>::set[abi:ne180100]((uint64_t *)v6 + 5, (uint64_t)(a2 + 2));
  *(unsigned char *)(a3 + 16) = 1;
  return result;
}

void sub_2112AC274(_Unwind_Exception *a1)
{
  *uint64_t v1 = 0;
  std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<IOType,std::set<std::string>>,void *>>>::operator()[abi:ne180100](v3, v2);
  _Unwind_Resume(a1);
}

void std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<IOType,std::set<std::string>>,void *>>>::operator()[abi:ne180100](uint64_t a1, char **a2)
{
  if (*(unsigned char *)(a1 + 8))
  {
    std::__tree<std::__value_type<std::string,SpatialSplitMode>,std::__map_value_compare<std::string,std::__value_type<std::string,SpatialSplitMode>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,SpatialSplitMode>>>::destroy((uint64_t)(a2 + 5), a2[6]);
  }
  else if (!a2)
  {
    return;
  }

  operator delete(a2);
}

uint64_t std::map<IOType,std::set<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>>::map[abi:ne180100](uint64_t a1, int *a2, uint64_t a3)
{
  *(void *)(a1 + 8) = 0;
  uint64_t v4 = (uint64_t *)(a1 + 8);
  *(void *)(a1 + 16) = 0;
  *(void *)a1 = a1 + 8;
  if (a3)
  {
    uint64_t v6 = 32 * a3;
    do
    {
      std::__tree<std::__value_type<IOType,std::set<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>>,std::__map_value_compare<IOType,std::__value_type<IOType,std::set<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>>,std::less<IOType>,true>,std::allocator<std::__value_type<IOType,std::set<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>>>>::__emplace_hint_unique_key_args<IOType,std::pair<IOType const,std::set<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>> const&>((uint64_t **)a1, v4, a2, a2);
      a2 += 8;
      v6 -= 32;
    }
    while (v6);
  }
  return a1;
}

void sub_2112AC354(_Unwind_Exception *a1)
{
  std::__tree<std::__value_type<IOType,std::set<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>>,std::__map_value_compare<IOType,std::__value_type<IOType,std::set<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>>,std::less<IOType>,true>,std::allocator<std::__value_type<IOType,std::set<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>>>>::destroy(v1, *(void **)(v1 + 8));
  _Unwind_Resume(a1);
}

uint64_t *std::__tree<std::__value_type<IOType,std::set<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>>,std::__map_value_compare<IOType,std::__value_type<IOType,std::set<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>>,std::less<IOType>,true>,std::allocator<std::__value_type<IOType,std::set<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>>>>::__emplace_hint_unique_key_args<IOType,std::pair<IOType const,std::set<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>> const&>(uint64_t **a1, uint64_t *a2, int *a3, _DWORD *a4)
{
  uint64_t v6 = (uint64_t **)std::__tree<std::__value_type<ZinIrDimension,unsigned long>,std::__map_value_compare<ZinIrDimension,std::__value_type<ZinIrDimension,unsigned long>,std::less<ZinIrDimension>,true>,std::allocator<std::__value_type<ZinIrDimension,unsigned long>>>::__find_equal<ZinIrDimension>(a1, a2, &v10, &v9, a3);
  BOOL result = *v6;
  if (!*v6)
  {
    std::__tree<std::__value_type<IOType,std::set<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>>,std::__map_value_compare<IOType,std::__value_type<IOType,std::set<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>>,std::less<IOType>,true>,std::allocator<std::__value_type<IOType,std::set<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>>>>::__construct_node<std::pair<IOType const,std::set<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>> const&>((uint64_t)a1, a4, (uint64_t)&v8);
    std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::__insert_node_at(a1, (uint64_t)v10, v6, v8);
    return v8;
  }
  return result;
}

uint64_t *std::__tree<std::__value_type<IOType,std::set<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>>,std::__map_value_compare<IOType,std::__value_type<IOType,std::set<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>>,std::less<IOType>,true>,std::allocator<std::__value_type<IOType,std::set<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>>>>::__construct_node<std::pair<IOType const,std::set<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>> const&>@<X0>(uint64_t a1@<X0>, _DWORD *a2@<X1>, uint64_t a3@<X8>)
{
  uint64_t v5 = a1 + 8;
  uint64_t v6 = operator new(0x40uLL);
  *(void *)(a3 + 8) = v5;
  *(void *)a3 = v6;
  *(unsigned char *)(a3 + 16) = 0;
  *((_DWORD *)v6 + 8) = *a2;
  BOOL result = std::set<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>::set[abi:ne180100]((uint64_t *)v6 + 5, (uint64_t)(a2 + 2));
  *(unsigned char *)(a3 + 16) = 1;
  return result;
}

void sub_2112AC460(_Unwind_Exception *a1)
{
  *uint64_t v1 = 0;
  std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<IOType,std::set<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>>,void *>>>::operator()[abi:ne180100](v3, v2);
  _Unwind_Resume(a1);
}

void std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<IOType,std::set<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>>,void *>>>::operator()[abi:ne180100](uint64_t a1, void **a2)
{
  if (*(unsigned char *)(a1 + 8))
  {
    std::__tree<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>::destroy((uint64_t)(a2 + 5), a2[6]);
  }
  else if (!a2)
  {
    return;
  }

  operator delete(a2);
}

uint64_t *std::__tree<std::__value_type<std::string,ZinIrInputParamInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrInputParamInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrInputParamInfo>>>::__emplace_unique_key_args<std::string,std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>(uint64_t **a1, void **a2, uint64_t a3, long long **a4)
{
  uint64_t v6 = (uint64_t **)std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::__find_equal<std::string>((uint64_t)a1, &v11, a2);
  std::vector<std::string>::size_type v7 = *v6;
  if (!*v6)
  {
    uint64_t v8 = v6;
    std::__tree<std::__value_type<std::string,ZinIrInputParamInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrInputParamInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrInputParamInfo>>>::__construct_node<std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>((uint64_t)a1, a4, (uint64_t)v10);
    std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::__insert_node_at(a1, v11, v8, v10[0]);
    std::vector<std::string>::size_type v7 = v10[0];
    v10[0] = 0;
    std::unique_ptr<std::__tree_node<std::__value_type<std::string,std::string>,void *>,std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<std::string,std::string>,void *>>>>::reset[abi:ne180100]((uint64_t)v10, 0);
  }
  return v7;
}

double std::__tree<std::__value_type<std::string,ZinIrInputParamInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrInputParamInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrInputParamInfo>>>::__construct_node<std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>@<D0>(uint64_t a1@<X0>, long long **a2@<X2>, uint64_t a3@<X8>)
{
  uint64_t v5 = a1 + 8;
  uint64_t v6 = (char *)operator new(0x58uLL);
  *(void *)a3 = v6;
  *(void *)(a3 + 8) = v5;
  *(unsigned char *)(a3 + 16) = 0;
  std::vector<std::string>::size_type v7 = (std::string *)(v6 + 32);
  uint64_t v8 = *a2;
  if (*((char *)*a2 + 23) < 0)
  {
    std::string::__init_copy_ctor_external(v7, *(const std::string::value_type **)v8, *((void *)v8 + 1));
  }
  else
  {
    long long v9 = *v8;
    *((void *)v6 + 6) = *((void *)v8 + 2);
    *(_OWORD *)&v7->__r_.__value_.__l.__data_ = v9;
  }
  double result = 0.0;
  *(_OWORD *)(v6 + 72) = 0u;
  *(_OWORD *)(v6 + 56) = 0u;
  *(unsigned char *)(a3 + 16) = 1;
  return result;
}

void sub_2112AC608(_Unwind_Exception *a1)
{
  std::unique_ptr<std::__tree_node<std::__value_type<std::string,std::string>,void *>,std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<std::string,std::string>,void *>>>>::reset[abi:ne180100](v1, 0);
  _Unwind_Resume(a1);
}

uint64_t *std::__tree<std::__value_type<std::string,ZinIrPlaneReaderUnitInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrPlaneReaderUnitInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrPlaneReaderUnitInfo>>>::__emplace_unique_key_args<std::string,std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>(uint64_t **a1, void **a2, uint64_t a3, long long **a4)
{
  uint64_t v6 = (uint64_t **)std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::__find_equal<std::string>((uint64_t)a1, &v11, a2);
  std::vector<std::string>::size_type v7 = *v6;
  if (!*v6)
  {
    uint64_t v8 = v6;
    std::__tree<std::__value_type<std::string,ZinIrPlaneReaderUnitInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrPlaneReaderUnitInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrPlaneReaderUnitInfo>>>::__construct_node<std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>((uint64_t)a1, a4, (uint64_t)v10);
    std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::__insert_node_at(a1, v11, v8, v10[0]);
    std::vector<std::string>::size_type v7 = v10[0];
    v10[0] = 0;
    std::unique_ptr<std::__tree_node<std::__value_type<std::string,ZinIrPlaneReaderUnitInfo>,void *>,std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<std::string,ZinIrPlaneReaderUnitInfo>,void *>>>>::reset[abi:ne180100]((uint64_t)v10, 0);
  }
  return v7;
}

std::string *std::__tree<std::__value_type<std::string,ZinIrPlaneReaderUnitInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrPlaneReaderUnitInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrPlaneReaderUnitInfo>>>::__construct_node<std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>@<X0>(uint64_t a1@<X0>, long long **a2@<X2>, uint64_t a3@<X8>)
{
  uint64_t v5 = a1 + 8;
  uint64_t v6 = (char *)operator new(0x90uLL);
  *(void *)a3 = v6;
  *(void *)(a3 + 8) = v5;
  *(unsigned char *)(a3 + 16) = 0;
  double result = std::pair<std::string const,ZinIrPlaneReaderUnitInfo>::pair[abi:ne180100]<std::string const&>((std::string *)(v6 + 32), *a2);
  *(unsigned char *)(a3 + 16) = 1;
  return result;
}

void sub_2112AC720(_Unwind_Exception *a1)
{
  std::unique_ptr<std::__tree_node<std::__value_type<std::string,ZinIrPlaneReaderUnitInfo>,void *>,std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<std::string,ZinIrPlaneReaderUnitInfo>,void *>>>>::reset[abi:ne180100](v1, 0);
  _Unwind_Resume(a1);
}

std::string *std::pair<std::string const,ZinIrPlaneReaderUnitInfo>::pair[abi:ne180100]<std::string const&>(std::string *this, long long *a2)
{
  if (*((char *)a2 + 23) < 0)
  {
    std::string::__init_copy_ctor_external(this, *(const std::string::value_type **)a2, *((void *)a2 + 1));
  }
  else
  {
    long long v3 = *a2;
    this->__r_.__value_.__r.__words[2] = *((void *)a2 + 2);
    *(_OWORD *)&this->__r_.__value_.__l.__data_ = v3;
  }
  this[1].__r_.__value_.__l.__size_ = 0;
  this[1].__r_.__value_.__r.__words[2] = 0;
  LODWORD(this[2].__r_.__value_.__r.__words[1]) = 0;
  this[2].__r_.__value_.__r.__words[0] = 0;
  *(_OWORD *)&this[2].__r_.__value_.__r.__words[2] = 0u;
  *(_OWORD *)&this[3].__r_.__value_.__r.__words[1] = 0u;
  this[4].__r_.__value_.__r.__words[0] = -1;
  this[1].__r_.__value_.__r.__words[0] = (std::string::size_type)&unk_26C350E50;
  HIDWORD(this[4].__r_.__value_.__r.__words[1]) = -1;
  return this;
}

void std::unique_ptr<std::__tree_node<std::__value_type<std::string,ZinIrPlaneReaderUnitInfo>,void *>,std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<std::string,ZinIrPlaneReaderUnitInfo>,void *>>>>::reset[abi:ne180100](uint64_t a1, uint64_t a2)
{
  uint64_t v2 = *(void **)a1;
  *(void *)a1 = a2;
  if (v2)
  {
    if (*(unsigned char *)(a1 + 16)) {
      std::__destroy_at[abi:ne180100]<std::pair<std::string const,ZinIrPlaneWriterUnitInfo>,0>((uint64_t)v2 + 32);
    }
    operator delete(v2);
  }
}

uint64_t *std::__tree<std::__value_type<std::string,ZinIrPlaneWriterUnitInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrPlaneWriterUnitInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrPlaneWriterUnitInfo>>>::__emplace_unique_key_args<std::string,std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>(uint64_t **a1, void **a2, uint64_t a3, long long **a4)
{
  uint64_t v6 = (uint64_t **)std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::__find_equal<std::string>((uint64_t)a1, &v11, a2);
  std::vector<std::string>::size_type v7 = *v6;
  if (!*v6)
  {
    uint64_t v8 = v6;
    std::__tree<std::__value_type<std::string,ZinIrPlaneWriterUnitInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrPlaneWriterUnitInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrPlaneWriterUnitInfo>>>::__construct_node<std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>((uint64_t)a1, a4, (uint64_t)v10);
    std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::__insert_node_at(a1, v11, v8, v10[0]);
    std::vector<std::string>::size_type v7 = v10[0];
    v10[0] = 0;
    std::unique_ptr<std::__tree_node<std::__value_type<std::string,ZinIrPlaneReaderUnitInfo>,void *>,std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<std::string,ZinIrPlaneReaderUnitInfo>,void *>>>>::reset[abi:ne180100]((uint64_t)v10, 0);
  }
  return v7;
}

std::string *std::__tree<std::__value_type<std::string,ZinIrPlaneWriterUnitInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrPlaneWriterUnitInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrPlaneWriterUnitInfo>>>::__construct_node<std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>@<X0>(uint64_t a1@<X0>, long long **a2@<X2>, uint64_t a3@<X8>)
{
  uint64_t v5 = a1 + 8;
  uint64_t v6 = (char *)operator new(0x90uLL);
  *(void *)a3 = v6;
  *(void *)(a3 + 8) = v5;
  *(unsigned char *)(a3 + 16) = 0;
  double result = std::pair<std::string const,ZinIrPlaneWriterUnitInfo>::pair[abi:ne180100]<std::string const&>((std::string *)(v6 + 32), *a2);
  *(unsigned char *)(a3 + 16) = 1;
  return result;
}

void sub_2112AC924(_Unwind_Exception *a1)
{
  std::unique_ptr<std::__tree_node<std::__value_type<std::string,ZinIrPlaneReaderUnitInfo>,void *>,std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<std::string,ZinIrPlaneReaderUnitInfo>,void *>>>>::reset[abi:ne180100](v1, 0);
  _Unwind_Resume(a1);
}

std::string *std::pair<std::string const,ZinIrPlaneWriterUnitInfo>::pair[abi:ne180100]<std::string const&>(std::string *this, long long *a2)
{
  if (*((char *)a2 + 23) < 0)
  {
    std::string::__init_copy_ctor_external(this, *(const std::string::value_type **)a2, *((void *)a2 + 1));
  }
  else
  {
    long long v3 = *a2;
    this->__r_.__value_.__r.__words[2] = *((void *)a2 + 2);
    *(_OWORD *)&this->__r_.__value_.__l.__data_ = v3;
  }
  this[1].__r_.__value_.__l.__size_ = 0;
  this[1].__r_.__value_.__r.__words[2] = 0;
  LODWORD(this[2].__r_.__value_.__r.__words[1]) = 0;
  this[2].__r_.__value_.__r.__words[0] = 0;
  *(_OWORD *)&this[2].__r_.__value_.__r.__words[2] = 0u;
  *(_OWORD *)&this[3].__r_.__value_.__r.__words[1] = 0u;
  this[4].__r_.__value_.__r.__words[0] = -1;
  this[1].__r_.__value_.__r.__words[0] = (std::string::size_type)&unk_26C350E70;
  return this;
}

uint64_t *std::__tree<std::__value_type<std::string,ZinIrIOInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrIOInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrIOInfo>>>::__emplace_unique_key_args<std::string,std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>(uint64_t **a1, void **a2, uint64_t a3, long long **a4)
{
  uint64_t v6 = (uint64_t **)std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::__find_equal<std::string>((uint64_t)a1, &v11, a2);
  std::vector<std::string>::size_type v7 = *v6;
  if (!*v6)
  {
    uint64_t v8 = v6;
    std::__tree<std::__value_type<std::string,ZinIrIOInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrIOInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrIOInfo>>>::__construct_node<std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>((uint64_t)a1, a4, (uint64_t)v10);
    std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::__insert_node_at(a1, v11, v8, v10[0]);
    std::vector<std::string>::size_type v7 = v10[0];
    v10[0] = 0;
    std::unique_ptr<std::__tree_node<std::__value_type<std::string,ZinIrIOInfo>,void *>,std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<std::string,ZinIrIOInfo>,void *>>>>::reset[abi:ne180100]((uint64_t)v10, 0);
  }
  return v7;
}

std::string *std::__tree<std::__value_type<std::string,ZinIrIOInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrIOInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrIOInfo>>>::__construct_node<std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>@<X0>(uint64_t a1@<X0>, long long **a2@<X2>, uint64_t a3@<X8>)
{
  uint64_t v5 = a1 + 8;
  uint64_t v6 = (char *)operator new(0x130uLL);
  *(void *)a3 = v6;
  *(void *)(a3 + 8) = v5;
  *(unsigned char *)(a3 + 16) = 0;
  double result = std::pair<std::string const,ZinIrIOInfo>::pair[abi:ne180100]<std::string const&>((std::string *)(v6 + 32), *a2);
  *(unsigned char *)(a3 + 16) = 1;
  return result;
}

void sub_2112ACAC8(_Unwind_Exception *a1)
{
  std::unique_ptr<std::__tree_node<std::__value_type<std::string,ZinIrIOInfo>,void *>,std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<std::string,ZinIrIOInfo>,void *>>>>::reset[abi:ne180100](v1, 0);
  _Unwind_Resume(a1);
}

std::string *std::pair<std::string const,ZinIrIOInfo>::pair[abi:ne180100]<std::string const&>(std::string *this, long long *a2)
{
  if (*((char *)a2 + 23) < 0)
  {
    std::string::__init_copy_ctor_external(this, *(const std::string::value_type **)a2, *((void *)a2 + 1));
  }
  else
  {
    long long v3 = *a2;
    this->__r_.__value_.__r.__words[2] = *((void *)a2 + 2);
    *(_OWORD *)&this->__r_.__value_.__l.__data_ = v3;
  }
  *(_OWORD *)&this[3].__r_.__value_.__r.__words[2] = 0u;
  *(_OWORD *)&this[3].__r_.__value_.__l.__data_ = 0u;
  *(_OWORD *)&this[4].__r_.__value_.__r.__words[1] = 0u;
  *(_OWORD *)&this[10].__r_.__value_.__r.__words[1] = 0u;
  *(_OWORD *)&this[9].__r_.__value_.__r.__words[2] = 0u;
  *(_OWORD *)&this[9].__r_.__value_.__l.__data_ = 0u;
  *(_OWORD *)&this[8].__r_.__value_.__r.__words[1] = 0u;
  *(_OWORD *)&this[7].__r_.__value_.__r.__words[2] = 0u;
  *(_OWORD *)&this[7].__r_.__value_.__l.__data_ = 0u;
  *(_OWORD *)&this[6].__r_.__value_.__r.__words[1] = 0u;
  *(_OWORD *)&this[5].__r_.__value_.__r.__words[2] = 0u;
  *(_OWORD *)&this[5].__r_.__value_.__l.__data_ = 0u;
  *(_OWORD *)&this[2].__r_.__value_.__r.__words[1] = 0u;
  *(_OWORD *)&this[1].__r_.__value_.__r.__words[2] = 0u;
  *(_OWORD *)&this[1].__r_.__value_.__l.__data_ = 0u;
  *(void *)&long long v4 = -1;
  *((void *)&v4 + 1) = -1;
  *(_OWORD *)&this[3].__r_.__value_.__r.__words[1] = v4;
  *(_OWORD *)&this[4].__r_.__value_.__l.__data_ = v4;
  this[4].__r_.__value_.__r.__words[2] = -1;
  this[9].__r_.__value_.__r.__words[0] = -1;
  *(_OWORD *)((char *)this[8].__r_.__value_.__r.__words + 4) = v4;
  *(_OWORD *)&this[7].__r_.__value_.__r.__words[2] = v4;
  *(_OWORD *)&this[7].__r_.__value_.__l.__data_ = v4;
  *(std::string::size_type *)((char *)&this[9].__r_.__value_.__r.__words[2] + 4) = 0;
  *(std::string::size_type *)((char *)&this[9].__r_.__value_.__r.__words[1] + 4) = 0;
  *(std::string::size_type *)((char *)this[10].__r_.__value_.__r.__words + 4) = 0;
  HIDWORD(this[10].__r_.__value_.__r.__words[1]) = 0;
  LODWORD(this[10].__r_.__value_.__r.__words[2]) = 5;
  this[11].__r_.__value_.__r.__words[0] = -1;
  return this;
}

uint64_t *std::__tree<std::__value_type<std::string,std::vector<std::string>>,std::__map_value_compare<std::string,std::__value_type<std::string,std::vector<std::string>>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,std::vector<std::string>>>>::__emplace_unique_key_args<std::string,std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>(uint64_t **a1, void **a2, uint64_t a3, long long **a4)
{
  uint64_t v6 = (uint64_t **)std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::__find_equal<std::string>((uint64_t)a1, &v11, a2);
  std::vector<std::string>::size_type v7 = *v6;
  if (!*v6)
  {
    uint64_t v8 = v6;
    std::__tree<std::__value_type<std::string,std::vector<std::string>>,std::__map_value_compare<std::string,std::__value_type<std::string,std::vector<std::string>>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,std::vector<std::string>>>>::__construct_node<std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>((uint64_t)a1, a4, (uint64_t)v10);
    std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::__insert_node_at(a1, v11, v8, v10[0]);
    std::vector<std::string>::size_type v7 = v10[0];
    v10[0] = 0;
    std::unique_ptr<std::__tree_node<std::__value_type<std::string,std::vector<std::string>>,void *>,std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<std::string,std::vector<std::string>>,void *>>>>::reset[abi:ne180100]((uint64_t)v10, 0);
  }
  return v7;
}

void std::__tree<std::__value_type<std::string,std::vector<std::string>>,std::__map_value_compare<std::string,std::__value_type<std::string,std::vector<std::string>>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,std::vector<std::string>>>>::__construct_node<std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>(uint64_t a1@<X0>, long long **a2@<X2>, uint64_t a3@<X8>)
{
  uint64_t v5 = a1 + 8;
  uint64_t v6 = operator new(0x50uLL);
  *(void *)a3 = v6;
  *(void *)(a3 + 8) = v5;
  *(unsigned char *)(a3 + 16) = 0;
  std::vector<std::string>::size_type v7 = (std::string *)(v6 + 4);
  uint64_t v8 = *a2;
  if (*((char *)*a2 + 23) < 0)
  {
    std::string::__init_copy_ctor_external(v7, *(const std::string::value_type **)v8, *((void *)v8 + 1));
  }
  else
  {
    long long v9 = *v8;
    v6[6] = *((void *)v8 + 2);
    *(_OWORD *)&v7->__r_.__value_.__l.__data_ = v9;
  }
  v6[7] = 0;
  v6[8] = 0;
  v6[9] = 0;
  *(unsigned char *)(a3 + 16) = 1;
}

void sub_2112ACCD4(_Unwind_Exception *a1)
{
  std::unique_ptr<std::__tree_node<std::__value_type<std::string,std::vector<std::string>>,void *>,std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<std::string,std::vector<std::string>>,void *>>>>::reset[abi:ne180100](v1, 0);
  _Unwind_Resume(a1);
}

uint64_t *std::__tree<std::__value_type<std::string,std::vector<ZinIrTensor *>>,std::__map_value_compare<std::string,std::__value_type<std::string,std::vector<ZinIrTensor *>>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,std::vector<ZinIrTensor *>>>>::__emplace_unique_key_args<std::string,std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>(uint64_t **a1, void **a2, uint64_t a3, long long **a4)
{
  uint64_t v6 = (uint64_t **)std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::__find_equal<std::string>((uint64_t)a1, &v11, a2);
  std::vector<std::string>::size_type v7 = *v6;
  if (!*v6)
  {
    uint64_t v8 = v6;
    std::__tree<std::__value_type<std::string,std::vector<ZinIrTensor *>>,std::__map_value_compare<std::string,std::__value_type<std::string,std::vector<ZinIrTensor *>>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,std::vector<ZinIrTensor *>>>>::__construct_node<std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>((uint64_t)a1, a4, (uint64_t)v10);
    std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::__insert_node_at(a1, v11, v8, v10[0]);
    std::vector<std::string>::size_type v7 = v10[0];
    v10[0] = 0;
    std::unique_ptr<std::__tree_node<std::__value_type<std::string,std::vector<ZinIrTensor *>>,void *>,std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<std::string,std::vector<ZinIrTensor *>>,void *>>>>::reset[abi:ne180100]((uint64_t)v10, 0);
  }
  return v7;
}

void std::__tree<std::__value_type<std::string,std::vector<ZinIrTensor *>>,std::__map_value_compare<std::string,std::__value_type<std::string,std::vector<ZinIrTensor *>>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,std::vector<ZinIrTensor *>>>>::__construct_node<std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>(uint64_t a1@<X0>, long long **a2@<X2>, uint64_t a3@<X8>)
{
  uint64_t v5 = a1 + 8;
  uint64_t v6 = operator new(0x50uLL);
  *(void *)a3 = v6;
  *(void *)(a3 + 8) = v5;
  *(unsigned char *)(a3 + 16) = 0;
  std::vector<std::string>::size_type v7 = (std::string *)(v6 + 4);
  uint64_t v8 = *a2;
  if (*((char *)*a2 + 23) < 0)
  {
    std::string::__init_copy_ctor_external(v7, *(const std::string::value_type **)v8, *((void *)v8 + 1));
  }
  else
  {
    long long v9 = *v8;
    v6[6] = *((void *)v8 + 2);
    *(_OWORD *)&v7->__r_.__value_.__l.__data_ = v9;
  }
  v6[7] = 0;
  v6[8] = 0;
  v6[9] = 0;
  *(unsigned char *)(a3 + 16) = 1;
}

void sub_2112ACE18(_Unwind_Exception *a1)
{
  std::unique_ptr<std::__tree_node<std::__value_type<std::string,std::vector<ZinIrTensor *>>,void *>,std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<std::string,std::vector<ZinIrTensor *>>,void *>>>>::reset[abi:ne180100](v1, 0);
  _Unwind_Resume(a1);
}

void std::unique_ptr<std::__tree_node<std::__value_type<std::string,std::vector<ZinIrTensor *>>,void *>,std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<std::string,std::vector<ZinIrTensor *>>,void *>>>>::reset[abi:ne180100](uint64_t a1, uint64_t a2)
{
  uint64_t v2 = *(void **)a1;
  *(void *)a1 = a2;
  if (v2)
  {
    if (*(unsigned char *)(a1 + 16)) {
      std::__destroy_at[abi:ne180100]<std::pair<std::string const,std::vector<ZinIrTensor *>>,0>((uint64_t)v2 + 32);
    }
    operator delete(v2);
  }
}

uint64_t *std::__tree<std::__value_type<std::string,ZinIrLiveOutTensorInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrLiveOutTensorInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrLiveOutTensorInfo>>>::__emplace_unique_key_args<std::string,std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>(uint64_t **a1, void **a2, uint64_t a3, long long **a4)
{
  uint64_t v6 = (uint64_t **)std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::__find_equal<std::string>((uint64_t)a1, &v11, a2);
  std::vector<std::string>::size_type v7 = *v6;
  if (!*v6)
  {
    uint64_t v8 = v6;
    std::__tree<std::__value_type<std::string,ZinIrLiveOutTensorInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrLiveOutTensorInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrLiveOutTensorInfo>>>::__construct_node<std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>((uint64_t)a1, a4, (uint64_t)v10);
    std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::__insert_node_at(a1, v11, v8, v10[0]);
    std::vector<std::string>::size_type v7 = v10[0];
    v10[0] = 0;
    std::unique_ptr<std::__tree_node<std::__value_type<std::string,ZinIrIOInfo>,void *>,std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<std::string,ZinIrIOInfo>,void *>>>>::reset[abi:ne180100]((uint64_t)v10, 0);
  }
  return v7;
}

std::string *std::__tree<std::__value_type<std::string,ZinIrLiveOutTensorInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrLiveOutTensorInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrLiveOutTensorInfo>>>::__construct_node<std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>@<X0>(uint64_t a1@<X0>, long long **a2@<X2>, uint64_t a3@<X8>)
{
  uint64_t v5 = a1 + 8;
  uint64_t v6 = (char *)operator new(0x138uLL);
  *(void *)a3 = v6;
  *(void *)(a3 + 8) = v5;
  *(unsigned char *)(a3 + 16) = 0;
  double result = std::pair<std::string const,ZinIrLiveOutTensorInfo>::pair[abi:ne180100]<std::string const&>((std::string *)(v6 + 32), *a2);
  *(unsigned char *)(a3 + 16) = 1;
  return result;
}

void sub_2112ACF88(_Unwind_Exception *a1)
{
  std::unique_ptr<std::__tree_node<std::__value_type<std::string,ZinIrIOInfo>,void *>,std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<std::string,ZinIrIOInfo>,void *>>>>::reset[abi:ne180100](v1, 0);
  _Unwind_Resume(a1);
}

std::string *std::pair<std::string const,ZinIrLiveOutTensorInfo>::pair[abi:ne180100]<std::string const&>(std::string *this, long long *a2)
{
  if (*((char *)a2 + 23) < 0)
  {
    std::string::__init_copy_ctor_external(this, *(const std::string::value_type **)a2, *((void *)a2 + 1));
  }
  else
  {
    long long v3 = *a2;
    this->__r_.__value_.__r.__words[2] = *((void *)a2 + 2);
    *(_OWORD *)&this->__r_.__value_.__l.__data_ = v3;
  }
  *(_OWORD *)&this[3].__r_.__value_.__r.__words[2] = 0u;
  *(_OWORD *)&this[3].__r_.__value_.__l.__data_ = 0u;
  *(_OWORD *)&this[4].__r_.__value_.__r.__words[1] = 0u;
  *(_OWORD *)&this[10].__r_.__value_.__r.__words[1] = 0u;
  *(_OWORD *)&this[9].__r_.__value_.__r.__words[2] = 0u;
  *(_OWORD *)&this[9].__r_.__value_.__l.__data_ = 0u;
  *(_OWORD *)&this[8].__r_.__value_.__r.__words[1] = 0u;
  *(_OWORD *)&this[7].__r_.__value_.__r.__words[2] = 0u;
  *(_OWORD *)&this[7].__r_.__value_.__l.__data_ = 0u;
  *(_OWORD *)&this[6].__r_.__value_.__r.__words[1] = 0u;
  *(_OWORD *)&this[5].__r_.__value_.__r.__words[2] = 0u;
  *(_OWORD *)&this[5].__r_.__value_.__l.__data_ = 0u;
  *(_OWORD *)&this[2].__r_.__value_.__r.__words[1] = 0u;
  *(_OWORD *)&this[1].__r_.__value_.__r.__words[2] = 0u;
  *(_OWORD *)&this[1].__r_.__value_.__l.__data_ = 0u;
  *(_OWORD *)&this[11].__r_.__value_.__l.__data_ = 0u;
  *(void *)&long long v4 = -1;
  *((void *)&v4 + 1) = -1;
  *(_OWORD *)&this[3].__r_.__value_.__r.__words[1] = v4;
  *(_OWORD *)&this[4].__r_.__value_.__l.__data_ = v4;
  this[4].__r_.__value_.__r.__words[2] = -1;
  this[9].__r_.__value_.__r.__words[0] = -1;
  *(_OWORD *)((char *)this[8].__r_.__value_.__r.__words + 4) = v4;
  *(_OWORD *)&this[7].__r_.__value_.__r.__words[2] = v4;
  *(_OWORD *)&this[7].__r_.__value_.__l.__data_ = v4;
  *(std::string::size_type *)((char *)&this[9].__r_.__value_.__r.__words[2] + 4) = 0;
  *(std::string::size_type *)((char *)&this[9].__r_.__value_.__r.__words[1] + 4) = 0;
  *(std::string::size_type *)((char *)this[10].__r_.__value_.__r.__words + 4) = 0;
  HIDWORD(this[10].__r_.__value_.__r.__words[1]) = 0;
  LODWORD(this[10].__r_.__value_.__r.__words[2]) = 5;
  this[11].__r_.__value_.__r.__words[0] = -1;
  return this;
}

void std::default_delete<ZinIrInputParam>::operator()[abi:ne180100](uint64_t a1, uint64_t a2)
{
  if (a2)
  {
    if (*(char *)(a2 + 23) < 0) {
      operator delete(*(void **)a2);
    }
    JUMPOUT(0x21667D3C0);
  }
}

void ZinIrLiveIOManager::PrepareBindingsForLiveInsWithout4CC()
{
  OUTLINED_FUNCTION_6_3();
  if (v5 < 0) {
    uint64_t v2 = (void *)*v2;
  }
  OUTLINED_FUNCTION_14(4.8149e-34, v0, v1, (uint64_t)v2, v3, v4);
  OUTLINED_FUNCTION_1(&dword_210C72000, &_os_log_internal, v6, "Unable to add binding for livein %s\n", v7);
}

{
  uint64_t v0;
  uint64_t v1;
  void *v2;
  void *v3;
  float *v4;
  int v5;
  uint64_t v6;
  uint8_t *v7;

  OUTLINED_FUNCTION_6_3();
  if (v5 < 0) {
    uint64_t v2 = (void *)*v2;
  }
  OUTLINED_FUNCTION_14(4.8149e-34, v0, v1, (uint64_t)v2, v3, v4);
  OUTLINED_FUNCTION_1(&dword_210C72000, &_os_log_internal, v6, "Invalid livein %s\n", v7);
}

void ZinIrLiveIOManager::PrepareBindingsForLiveInsWith4CC(float *a1, char *a2, void *a3, void *a4)
{
  if (*a2 < 0) {
    a3 = (void *)*a3;
  }
  OUTLINED_FUNCTION_14(4.8149e-34, (uint64_t)a1, (uint64_t)a2, (uint64_t)a3, a4, a1);
  OUTLINED_FUNCTION_1(&dword_210C72000, &_os_log_internal, v4, "Invalid livein %s\n", v5);
}

void ZinIrLiveIOManager::PrepareLiveOut(unsigned char *a1, unsigned char *a2)
{
  OUTLINED_FUNCTION_0_3(a1, a2);
  OUTLINED_FUNCTION_1_3(&dword_210C72000, &_os_log_internal, v2, "Unsupported model topology, multiple liveouts with same bottom\n", v3);
}

void ZinIrLiveIOManager::PrepareLiveOut()
{
  uint64_t v2 = *MEMORY[0x263EF8340];
  OUTLINED_FUNCTION_5_5();
  OUTLINED_FUNCTION_1(&dword_210C72000, &_os_log_internal, v0, "incompatible 4cc format between plane writer unit and live out %s\n", v1);
}

void ZinIrLiveIOManager::CreateOutputTensor()
{
  OUTLINED_FUNCTION_0_0(*MEMORY[0x263EF8340]);
  OUTLINED_FUNCTION_5();
  OUTLINED_FUNCTION_1(&dword_210C72000, &_os_log_internal, v0, "Invalid stride for liveout tensor %s!\n", v1);
}

{
  uint64_t v0;
  uint8_t v1[24];

  OUTLINED_FUNCTION_0_0(*MEMORY[0x263EF8340]);
  OUTLINED_FUNCTION_5();
  OUTLINED_FUNCTION_1(&dword_210C72000, &_os_log_internal, v0, "Invalid liveout tensor %s!\n", v1);
}

{
  uint64_t v0;
  uint8_t v1[24];

  OUTLINED_FUNCTION_0_0(*MEMORY[0x263EF8340]);
  OUTLINED_FUNCTION_5();
  OUTLINED_FUNCTION_1(&dword_210C72000, &_os_log_internal, v0, "Invalid live output tensor %s!\n", v1);
}

{
  uint64_t v0;
  uint8_t v1[24];

  OUTLINED_FUNCTION_0_0(*MEMORY[0x263EF8340]);
  OUTLINED_FUNCTION_5();
  OUTLINED_FUNCTION_1(&dword_210C72000, &_os_log_internal, v0, "Invalid liveout %s\n", v1);
}

{
  uint64_t v0;
  uint8_t v1[24];

  OUTLINED_FUNCTION_0_0(*MEMORY[0x263EF8340]);
  OUTLINED_FUNCTION_5();
  OUTLINED_FUNCTION_1(&dword_210C72000, &_os_log_internal, v0, "Invalid plane index for liveout tensor %s!\n", v1);
}

void ZinIrLiveIOManager::PrepareLiveOutBinding(float *a1, uint64_t a2, void *a3, void *a4)
{
  if (*(char *)(a2 + 55) < 0) {
    a3 = (void *)*a3;
  }
  OUTLINED_FUNCTION_14(4.8149e-34, (uint64_t)a1, a2, (uint64_t)a3, a4, a1);
  OUTLINED_FUNCTION_1(&dword_210C72000, &_os_log_internal, v4, "Invalid live output %s!\n", v5);
}

void ZinIrLiveIOManager::PrepareLiveOutBinding()
{
  OUTLINED_FUNCTION_7_1();
  if (v5 != v6) {
    uint64_t v7 = v4;
  }
  else {
    uint64_t v7 = v1;
  }
  *uint64_t v0 = 136315138;
  *uint64_t v2 = v7;
  OUTLINED_FUNCTION_1(&dword_210C72000, &_os_log_internal, (uint64_t)v2, "Unable to add binding for liveout %s\n", v3);
}

{
  uint64_t v0;
  uint8_t v1[24];
  uint64_t v2;

  uint64_t v2 = *MEMORY[0x263EF8340];
  OUTLINED_FUNCTION_5_5();
  OUTLINED_FUNCTION_1(&dword_210C72000, &_os_log_internal, v0, "Invalid live output %s!\n", v1);
}

void ZinIrLiveIOManager::PrepareLiveOutBinding(unsigned char *a1, unsigned char *a2)
{
  OUTLINED_FUNCTION_0_3(a1, a2);
  OUTLINED_FUNCTION_1_3(&dword_210C72000, &_os_log_internal, v2, "LiveOutput without 4cc format should only have one liveout tensor\n", v3);
}

void ZinIrLiveIOManager::ValidateMultiplanarLiveOutput()
{
  uint64_t v2 = *MEMORY[0x263EF8340];
  OUTLINED_FUNCTION_5_5();
  OUTLINED_FUNCTION_1(&dword_210C72000, &_os_log_internal, v0, "Invalid liveout %s\n", v1);
}

void ZinIrLiveIOManager::ValidateMultiplanarLiveOutput(float *a1, uint64_t a2, void *a3, void *a4)
{
  if (*(char *)(a2 + 55) < 0) {
    a3 = (void *)*a3;
  }
  OUTLINED_FUNCTION_14(4.8149e-34, (uint64_t)a1, a2, (uint64_t)a3, a4, a1);
  OUTLINED_FUNCTION_1(&dword_210C72000, &_os_log_internal, v4, "Invalid number of planes for liveout %s\n", v5);
}

{
  uint64_t v4;
  uint8_t *v5;

  if (*(char *)(a2 + 55) < 0) {
    a3 = (void *)*a3;
  }
  OUTLINED_FUNCTION_14(4.8149e-34, (uint64_t)a1, a2, (uint64_t)a3, a4, a1);
  OUTLINED_FUNCTION_1(&dword_210C72000, &_os_log_internal, v4, "Plane dimensions, format or interleave are incompatible for liveout %s\n", v5);
}

void ZinIrLiveIOManager::PrepareLiveInParamBinding()
{
  uint64_t v2 = *MEMORY[0x263EF8340];
  OUTLINED_FUNCTION_5_5();
  OUTLINED_FUNCTION_1(&dword_210C72000, &_os_log_internal, v0, "Unable to add binding for livein param %s\n", v1);
}

{
  uint64_t v0;
  uint8_t v1[24];
  uint64_t v2;

  uint64_t v2 = *MEMORY[0x263EF8340];
  OUTLINED_FUNCTION_5_5();
  OUTLINED_FUNCTION_1(&dword_210C72000, &_os_log_internal, v0, "Invalid livein param %s\n", v1);
}

void ZinIrFileBacking::~ZinIrFileBacking(void **this)
{
  *this = &unk_26C349838;
  ZinIrFileBacking::Close((ZinIrFileBacking *)this);
  if (*((char *)this + 47) < 0) {
    operator delete(this[3]);
  }
}

BOOL ZinIrFileBacking::Open(uint64_t a1, const void **a2)
{
  uint64_t v22 = *MEMORY[0x263EF8340];
  if (*(_DWORD *)(a1 + 16) == -1)
  {
    if (*((char *)a2 + 23) >= 0) {
      size_t v13 = *((unsigned __int8 *)a2 + 23);
    }
    else {
      size_t v13 = (size_t)a2[1];
    }
    long long v14 = __p;
    std::string::basic_string[abi:ne180100]((uint64_t)__p, v13 + 26);
    if (v20 < 0) {
      long long v14 = (void **)__p[0];
    }
    if (v13)
    {
      if (*((char *)a2 + 23) >= 0) {
        uint64_t v15 = a2;
      }
      else {
        uint64_t v15 = *a2;
      }
      memmove(v14, v15, v13);
    }
    strcpy((char *)v14 + v13, "anecompiler.swap.XXXXXXXXX");
    uint64_t v16 = __p;
    if (v20 < 0) {
      uint64_t v16 = (void **)__p[0];
    }
    snprintf(__str, 0x400uLL, "%s", (const char *)v16);
    if (v20 < 0) {
      operator delete(__p[0]);
    }
    int v17 = mkstemp(__str);
    BOOL v10 = v17 != -1;
    if (v17 == -1)
    {
      if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
        ZinIrFileBacking::Open((uint64_t)__str);
      }
    }
    else
    {
      *(_DWORD *)(a1 + 16) = v17;
      *(void *)(a1 + 8) = 0;
      std::string::__assign_external((std::string *)(a1 + 24), __str);
      if (unlink(__str))
      {
        long long v18 = __error();
        strerror(*v18);
        if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
          ZinIrFileBacking::Open();
        }
      }
    }
  }
  else
  {
    if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
      ZinIrFileBacking::Open(a1, v3, v4, v5, v6, v7, v8, v9);
    }
    return 0;
  }
  return v10;
}

void ZinIrFileBacking::Close(ZinIrFileBacking *this)
{
  int v2 = *((_DWORD *)this + 4);
  if (v2 != -1)
  {
    if (close(v2))
    {
      uint64_t v3 = __error();
      strerror(*v3);
      if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
        ZinIrFileBacking::Close();
      }
    }
    *((_DWORD *)this + 4) = -1;
  }
}

BOOL ZinIrFileBacking::Valid(ZinIrFileBacking *this)
{
  return *((_DWORD *)this + 4) != -1;
}

void *ZinIrFileBacking::Allocate(ZinIrFileBacking *this, size_t a2)
{
  if (((*(uint64_t (**)(ZinIrFileBacking *))(*(void *)this + 24))(this) & 1) == 0) {
    ZinAssertImpl("Internal error: Tried to allocate %llu elements without file backing.", a2);
  }
  if (((*(uint64_t (**)(ZinIrFileBacking *))(*(void *)this + 16))(this) & 1) == 0)
  {
    if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
      ZinIrFileBacking::Allocate();
    }
    return 0;
  }
  {
    ZinIrFileBacking::Allocate(unsigned long long)::page_std::string::size_type size = sysconf(29);
  }
  off_t v4 = *((void *)this + 1);
  *((void *)this + 1) = v4 + ZinAlignPower2(a2, ZinIrFileBacking::Allocate(unsigned long long)::page_size);
  if (ftruncate(*((_DWORD *)this + 4), v4 + a2))
  {
    if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
      ZinIrFileBacking::Allocate();
    }
    return 0;
  }
  double result = mmap(0, a2, 3, 1, *((_DWORD *)this + 4), v4);
  if (result == (void *)-1)
  {
    if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
      ZinIrFileBacking::Allocate();
    }
    return 0;
  }
  return result;
}

void sub_2112ADC5C(_Unwind_Exception *a1)
{
}

uint64_t ZinIrFileBacking::UnmapSystem(ZinIrFileBacking *this, uint64_t a2)
{
  uint64_t v4 = sysconf(29);
  size_t v5 = ZinAlignPower2(a2, v4);

  return munmap(this, v5);
}

void ZinIrFileBacking::Open()
{
  uint64_t v4 = *MEMORY[0x263EF8340];
  OUTLINED_FUNCTION_1_13();
  __int16 v2 = 2080;
  uint64_t v3 = v0;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "ZinIrFileBacking: Temp file not removed: %s - %s", v1, 0x16u);
}

void ZinIrFileBacking::Open(uint64_t a1)
{
  uint64_t v8 = *MEMORY[0x263EF8340];
  __int16 v2 = __error();
  uint64_t v3 = strerror(*v2);
  int v4 = 136315394;
  uint64_t v5 = a1;
  __int16 v6 = 2080;
  uint64_t v7 = v3;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "ANECompiler internal error: Unable to create backing file %s: %s\n", (uint8_t *)&v4, 0x16u);
}

void ZinIrFileBacking::Open(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void ZinIrFileBacking::Close()
{
  OUTLINED_FUNCTION_1_13();
  OUTLINED_FUNCTION_2(&dword_210C72000, &_os_log_internal, v0, "ZinIrFileBacking: Could not close file backing - %s", v1, v2, v3, v4, v5);
}

void ZinIrFileBacking::Allocate()
{
  uint64_t v0 = __error();
  strerror(*v0);
  OUTLINED_FUNCTION_1_13();
  OUTLINED_FUNCTION_2(&dword_210C72000, &_os_log_internal, v1, "ANECompiler internal error: mmap failure: %s", v2, v3, v4, v5, v6);
}

{
  int *v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint8_t v6;

  uint64_t v0 = __error();
  strerror(*v0);
  OUTLINED_FUNCTION_1_13();
  OUTLINED_FUNCTION_2(&dword_210C72000, &_os_log_internal, v1, "ANECompiler internal error: ftruncate failure: %s", v2, v3, v4, v5, v6);
}

{
  uint8_t v0[16];

  *(_WORD *)uint64_t v0 = 0;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "ANECompiler internal error: file backing is not opened.", v0, 2u);
}

__CFDictionary *ZinCreatePEGOCUnit(const ZinIrPEGOCUnitInfo *a1)
{
  v4[4] = *MEMORY[0x263EF8340];
  Unit = ZinCreateUnit(a1);
  v4[0] = &unk_26C381690;
  v4[3] = v4;
  ZinCreatePEUnit((uint64_t)a1, (uint64_t)v4, Unit);
  std::__function::__value_func<void ()(ZinIrPEUnitInfo const&,std::vector<std::string> &,__CFDictionary *)>::~__value_func[abi:ne180100](v4);
  return Unit;
}

void sub_2112AE0D0(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::__function::__value_func<void ()(ZinIrPEUnitInfo const&,std::vector<std::string> &,__CFDictionary *)>::~__value_func[abi:ne180100]((uint64_t *)va);
  _Unwind_Resume(a1);
}

void std::__function::__func<ZinCreatePEGOCUnit(ZinIrPEGOCUnitInfo const&)::$_0,std::allocator<ZinCreatePEGOCUnit(ZinIrPEGOCUnitInfo const&)::$_0>,void ()(ZinIrPEUnitInfo const&,std::vector<std::string> &,__CFDictionary *)>::~__func()
{
}

void *std::__function::__func<ZinCreatePEGOCUnit(ZinIrPEGOCUnitInfo const&)::$_0,std::allocator<ZinCreatePEGOCUnit(ZinIrPEGOCUnitInfo const&)::$_0>,void ()(ZinIrPEUnitInfo const&,std::vector<std::string> &,__CFDictionary *)>::__clone()
{
  double result = operator new(0x10uLL);
  void *result = &unk_26C381690;
  return result;
}

void std::__function::__func<ZinCreatePEGOCUnit(ZinIrPEGOCUnitInfo const&)::$_0,std::allocator<ZinCreatePEGOCUnit(ZinIrPEGOCUnitInfo const&)::$_0>,void ()(ZinIrPEUnitInfo const&,std::vector<std::string> &,__CFDictionary *)>::__clone(uint64_t a1, void *a2)
{
  *a2 = &unk_26C381690;
}

void std::__function::__func<ZinCreatePEGOCUnit(ZinIrPEGOCUnitInfo const&)::$_0,std::allocator<ZinCreatePEGOCUnit(ZinIrPEGOCUnitInfo const&)::$_0>,void ()(ZinIrPEUnitInfo const&,std::vector<std::string> &,__CFDictionary *)>::operator()(uint64_t a1, uint64_t a2, std::vector<std::string> *a3, __CFDictionary **a4)
{
  *(void *)&long long v36 = *MEMORY[0x263EF8340];
  uint8_t v6 = *a4;
  ZinIrPEUnitInfo::ZinIrPEUnitInfo((ZinIrPEUnitInfo *)&v25, (const ZinIrPEUnitInfo *)a2);
  int v25 = &unk_26C34BF80;
  ZinIrDynamicGOCUnitInfo::ZinIrDynamicGOCUnitInfo((ZinIrDynamicGOCUnitInfo *)v30, (const ZinIrDynamicGOCUnitInfo *)(a2 + 968));
  ZinIrDynamicGOCUnitInfo::ZinIrDynamicGOCUnitInfo((ZinIrDynamicGOCUnitInfo *)&v18, (const ZinIrDynamicGOCUnitInfo *)v30);
  if ((v27 & 0x80u) == 0) {
    size_t v7 = v27;
  }
  else {
    size_t v7 = v26[1];
  }
  p_str = &__str;
  std::string::basic_string[abi:ne180100]((uint64_t)&__str, v7 + 12);
  if ((__str.__r_.__value_.__r.__words[2] & 0x8000000000000000) != 0) {
    p_str = (std::string *)__str.__r_.__value_.__r.__words[0];
  }
  if (v7)
  {
    if ((v27 & 0x80u) == 0) {
      uint64_t v9 = v26;
    }
    else {
      uint64_t v9 = (void *)v26[0];
    }
    memmove(p_str, v9, v7);
  }
  strcpy((char *)p_str + v7, ".dynamic_goc");
  if (SHIBYTE(__p.__r_.__value_.__r.__words[2]) < 0) {
    operator delete(__p.__r_.__value_.__l.__data_);
  }
  std::string __p = __str;
  uint64_t v21 = v28;
  uint64_t v22 = v29;
  std::vector<std::string>::pointer begin = a3->__begin_;
  if (SHIBYTE(a3->__begin_->__r_.__value_.__r.__words[2]) < 0)
  {
    std::string::__init_copy_ctor_external(&__str, begin->__r_.__value_.__l.__data_, begin->__r_.__value_.__l.__size_);
    std::vector<std::string>::pointer begin = a3->__begin_;
  }
  else
  {
    long long v11 = *(_OWORD *)&begin->__r_.__value_.__l.__data_;
    __str.__r_.__value_.__r.__words[2] = begin->__r_.__value_.__r.__words[2];
    *(_OWORD *)&__str.__r_.__value_.__l.__data_ = v11;
  }
  if (SHIBYTE(begin[1].__r_.__value_.__r.__words[2]) < 0)
  {
    std::string::__init_copy_ctor_external(&v34, begin[1].__r_.__value_.__l.__data_, begin[1].__r_.__value_.__l.__size_);
    std::vector<std::string>::pointer begin = a3->__begin_;
  }
  else
  {
    long long v12 = *(_OWORD *)&begin[1].__r_.__value_.__l.__data_;
    v34.__r_.__value_.__r.__words[2] = begin[1].__r_.__value_.__r.__words[2];
    *(_OWORD *)&v34.__r_.__value_.__l.__data_ = v12;
  }
  if (SHIBYTE(begin[1].__r_.__value_.__r.__words[2]) < 0)
  {
    std::string::__init_copy_ctor_external(&v35, begin[1].__r_.__value_.__l.__data_, begin[1].__r_.__value_.__l.__size_);
  }
  else
  {
    long long v13 = *(_OWORD *)&begin[1].__r_.__value_.__l.__data_;
    v35.__r_.__value_.__r.__words[2] = begin[1].__r_.__value_.__r.__words[2];
    *(_OWORD *)&v35.__r_.__value_.__l.__data_ = v13;
  }
  std::vector<std::string>::__assign_with_size[abi:ne180100]<std::string const*,std::string const*>(&v20, &__str, &v36, 3uLL);
  for (uint64_t i = 0; i != -9; i -= 3)
  {
    if (SHIBYTE(v35.__r_.__value_.__r.__words[i + 2]) < 0) {
      operator delete(*(void **)((char *)&v35.__r_.__value_.__l.__data_ + i * 8));
    }
  }
  if (SHIBYTE(__p.__r_.__value_.__r.__words[2]) < 0) {
    std::string::__init_copy_ctor_external(&__str, __p.__r_.__value_.__l.__data_, __p.__r_.__value_.__l.__size_);
  }
  else {
    std::string __str = __p;
  }
  std::vector<std::string>::__assign_with_size[abi:ne180100]<std::string const*,std::string const*>(a3, &__str, (long long *)&v34, 1uLL);
  if (SHIBYTE(__str.__r_.__value_.__r.__words[2]) < 0) {
    operator delete(__str.__r_.__value_.__l.__data_);
  }
  DynamicGOCUnit = ZinCreateDynamicGOCUnit((const ZinIrDynamicGOCUnitInfo *)&v18);
  if ((__p.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
    p_p = &__p;
  }
  else {
    p_p = (std::string *)__p.__r_.__value_.__r.__words[0];
  }
  CFStringRef v17 = CFStringCreateWithCString((CFAllocatorRef)*MEMORY[0x263EFFB08], (const char *)p_p, 0x8000100u);
  CFDictionaryAddValue(v6, v17, DynamicGOCUnit);
  CFRelease(DynamicGOCUnit);
  CFRelease(v17);
  long long v18 = &unk_26C3500C8;
  uint64_t v23 = &unk_26C34F840;
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&v24);
  ZinIrUnitInfo::~ZinIrUnitInfo(&v23);
  ZinIrUnitInfo::~ZinIrUnitInfo(&v18);
  int v25 = &unk_26C34BF80;
  v30[0] = &unk_26C3500C8;
  int v31 = &unk_26C34F840;
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&v32);
  ZinIrUnitInfo::~ZinIrUnitInfo(&v31);
  ZinIrUnitInfo::~ZinIrUnitInfo(v30);
  ZinIrPEUnitInfo::~ZinIrPEUnitInfo(&v25);
}

void sub_2112AE510(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, void *a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, void *a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33,uint64_t a34,uint64_t a35,void *a36)
{
  a9 = &unk_26C3500C8;
  a20 = &unk_26C34F840;
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&a30);
  ZinIrUnitInfo::~ZinIrUnitInfo(&a20);
  ZinIrUnitInfo::~ZinIrUnitInfo(&a9);
  STACK[0x4A0] = (unint64_t)&unk_26C3500C8;
  STACK[0x4F8] = (unint64_t)&unk_26C34F840;
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&STACK[0x548]);
  ZinIrUnitInfo::~ZinIrUnitInfo((void **)&STACK[0x4F8]);
  ZinIrUnitInfo::~ZinIrUnitInfo(v36);
  ZinIrPEUnitInfo::~ZinIrPEUnitInfo(&a36);
  _Unwind_Resume(a1);
}

uint64_t std::__function::__func<ZinCreatePEGOCUnit(ZinIrPEGOCUnitInfo const&)::$_0,std::allocator<ZinCreatePEGOCUnit(ZinIrPEGOCUnitInfo const&)::$_0>,void ()(ZinIrPEUnitInfo const&,std::vector<std::string> &,__CFDictionary *)>::target(uint64_t a1, uint64_t a2)
{
  {
    return a1 + 8;
  }
  else
  {
    return 0;
  }
}

void *std::__function::__func<ZinCreatePEGOCUnit(ZinIrPEGOCUnitInfo const&)::$_0,std::allocator<ZinCreatePEGOCUnit(ZinIrPEGOCUnitInfo const&)::$_0>,void ()(ZinIrPEUnitInfo const&,std::vector<std::string> &,__CFDictionary *)>::target_type()
{
}

uint64_t ZinParseSoftmaxUnit(const __CFDictionary *a1, ZinIrSoftmaxUnitInfo *a2, CFArrayRef *a3)
{
  CFDictionaryRef Value = (const __CFDictionary *)CFDictionaryGetValue(a1, @"Params");
  if (!Value || (CFDictionaryRef v6 = Value, v7 = CFGetTypeID(Value), v7 != CFDictionaryGetTypeID()))
  {
LABEL_18:
    ZinIrUnitStatus::SetError(a3, @"InvalidParamSyntax");
    return 3;
  }
  CFStringRef v8 = (const __CFString *)CFDictionaryGetValue(v6, @"Dimension");
  if (!v8 || (CFStringRef v9 = v8, v10 = CFGetTypeID(v8), v10 != CFStringGetTypeID()))
  {
    CFArrayRef v12 = (const __CFArray *)CFDictionaryGetValue(v6, @"Dimension");
    if (v12 && (CFArrayRef v13 = v12, v14 = CFGetTypeID(v12), v14 == CFArrayGetTypeID()))
    {
      int Count = CFArrayGetCount(v13);
      if (Count < 1)
      {
        BOOL v29 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
        if (v29) {
          ZinParseSoftmaxUnit(v29, v30, v31, v32, v33, v34, v35, v36);
        }
      }
      else
      {
        CFIndex v16 = 0;
        uint64_t v17 = Count;
        while (1)
        {
          CFStringRef ValueAtIndex = (const __CFString *)CFArrayGetValueAtIndex(v13, v16);
          if (!ValueAtIndex) {
            break;
          }
          CFStringRef v19 = ValueAtIndex;
          CFTypeID v20 = CFGetTypeID(ValueAtIndex);
          if (v20 != CFStringGetTypeID()) {
            break;
          }
          uint64_t result = ZinParseSoftmaxDimension(v19, a2, a3);
          if (result) {
            return result;
          }
          if (v17 == ++v16) {
            goto LABEL_15;
          }
        }
        if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
          ZinParseSoftmaxUnit(v16);
        }
      }
    }
    else
    {
      BOOL v21 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v21) {
        ZinParseSoftmaxUnit(v21, v22, v23, v24, v25, v26, v27, v28);
      }
    }
    goto LABEL_18;
  }
  uint64_t result = ZinParseSoftmaxDimension(v9, a2, a3);
  if (!result)
  {
LABEL_15:
    ZinParseBoolean(v6, @"SubtractMax", (BOOL *)a2 + 120);
    return 0;
  }
  return result;
}

uint64_t ZinParseSoftmaxDimension(const __CFString *a1, ZinIrSoftmaxUnitInfo *a2, CFArrayRef *a3)
{
  if (ZinCFStringEquals(a1, @"Channel"))
  {
    int v6 = 2;
LABEL_9:
    int v24 = v6;
    goto LABEL_10;
  }
  if (ZinCFStringEquals(a1, @"Height"))
  {
    int v6 = 3;
    goto LABEL_9;
  }
  if (ZinCFStringEquals(a1, @"Width"))
  {
    int v6 = 4;
    goto LABEL_9;
  }
  if (ZinCFStringEquals(a1, @"Depth"))
  {
    int v6 = 1;
    goto LABEL_9;
  }
  if (!ZinCFStringEquals(a1, @"Batch"))
  {
    BOOL v16 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (v16) {
      ZinParseSoftmaxDimension(v16, v17, v18, v19, v20, v21, v22, v23);
    }
    ZinIrUnitStatus::SetError(a3, @"InvalidUnitSoftmaxDimension");
    return 3;
  }
  int v24 = 0;
LABEL_10:
  CFTypeID v7 = (void *)((char *)a2 + 80);
  if (std::__hash_table<ZinIrDimension,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,std::allocator<ZinIrDimension>>::find<ZinIrDimension>(v7, &v24))
  {
    uint64_t result = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (!result) {
      return result;
    }
    ZinParseSoftmaxDimension(result, v9, v10, v11, v12, v13, v14, v15);
  }
  else
  {
    std::__hash_table<ZinIrDimension,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,std::allocator<ZinIrDimension>>::__emplace_unique_key_args<ZinIrDimension,ZinIrDimension const&>((uint64_t)v7, &v24, &v24);
  }
  return 0;
}

void ZinParseSoftmaxUnit(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "Softmax dimension array cannot be empty.\n", a5, a6, a7, a8, 0);
}

void ZinParseSoftmaxUnit(int a1)
{
  uint64_t v2 = *MEMORY[0x263EF8340];
  v1[0] = 67109120;
  v1[1] = a1;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "Unable to parse softmax dimension at index #%d.\n", (uint8_t *)v1, 8u);
}

void ZinParseSoftmaxDimension(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "Unknown or unsupported softmax dimension!\n", a5, a6, a7, a8, 0);
}

uint64_t ZinIrEWUnit::ZinIrEWUnit(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v5 = ZinIrUnit::ZinIrUnit((void *)a1, a3);
  *uint64_t v5 = &unk_26C343880;
  v5[7] = &unk_26C345B80;
  if (*(char *)(a2 + 31) < 0)
  {
    std::string::__init_copy_ctor_external((std::string *)(v5 + 8), *(const std::string::value_type **)(a2 + 8), *(void *)(a2 + 16));
  }
  else
  {
    long long v6 = *(_OWORD *)(a2 + 8);
    v5[10] = *(void *)(a2 + 24);
    *((_OWORD *)v5 + 4) = v6;
  }
  int v7 = *(_DWORD *)(a2 + 32);
  *(void *)(a1 + 96) = 0;
  *(_DWORD *)(a1 + 88) = v7;
  *(void *)(a1 + 104) = 0;
  *(void *)(a1 + 112) = 0;
  std::vector<std::string>::__init_with_size[abi:ne180100]<std::string*,std::string*>((std::string *)(a1 + 96), *(long long **)(a2 + 40), *(long long **)(a2 + 48), 0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*(void *)(a2 + 48) - *(void *)(a2 + 40)) >> 3));
  *(_OWORD *)(a1 + 120) = *(_OWORD *)(a2 + 64);
  *(void *)(a1 + 56) = &unk_26C348608;
  *(_DWORD *)(a1 + 136) = *(_DWORD *)(a2 + 80);
  return a1;
}

void sub_2112AEC1C(_Unwind_Exception *a1)
{
  ZinIrUnit::~ZinIrUnit(v1);
  _Unwind_Resume(a1);
}

void ZinIrEWUnit::CreateOpcode(ZinIrEWUnit *this, const ZinIrHalParameters *a2)
{
}

void sub_2112AECA4(_Unwind_Exception *a1)
{
  MEMORY[0x21667D3C0](v1, 0x1081C40FC6463CFLL);
  _Unwind_Resume(a1);
}

void ZinIrEWUnit::CreateLayer(ZinIrEWUnit *a1, const ZinIrHalParameters *a2)
{
}

void sub_2112AEDC8(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, std::__shared_weak_count *a10, uint64_t a11, uint64_t a12)
{
  if (a10) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a10);
  }
  MEMORY[0x21667D3C0](v12, 0x10B3C4024B96488);
  if (a12) {
    (*(void (**)(uint64_t))(*(void *)a12 + 8))(a12);
  }
  _Unwind_Resume(a1);
}

uint64_t ZinIrEWUnit::TensorDimensions(ZinIrEWUnit *this, const ZinIrHalParameters *a2, int8x16_t *a3, CFArrayRef *a4)
{
  unsigned int v5 = *((_DWORD *)this + 34);
  if (!v5) {
    return 3;
  }
  int v9 = IsEWTypeUnary(v5);
  uint64_t v10 = *((void *)this + 2) - *((void *)this + 1);
  if (v9)
  {
    if (v10 != 120)
    {
LABEL_4:
      CFStringRef v11 = @"InvalidBottomCount";
LABEL_5:
      ZinIrUnitStatus::SetError(a4, v11);
      return 3;
    }
  }
  else if (v10 != 240)
  {
    goto LABEL_4;
  }
  if ((IsEWTypeUnary(*((_DWORD *)this + 34)) & 1) == 0)
  {
    unsigned int v17 = *((_DWORD *)this + 34);
    uint64_t v18 = *((void *)this + 1);
    int64x2_t v19 = *(int64x2_t *)(v18 + 8);
    int8x16_t v20 = *(int8x16_t *)(v18 + 24);
    uint64_t v31 = *(void *)(v18 + 40);
    int64x2_t v29 = v19;
    int8x16_t v30 = v20;
    int64x2_t v21 = *(int64x2_t *)(v18 + 144);
    v27[0] = *(int64x2_t *)(v18 + 128);
    v27[1] = v21;
    uint64_t v28 = *(void *)(v18 + 160);
    if (v17 <= 4
      && ((1 << v17) & 0x16) != 0
      && ((IsSingularValue((const ZinTensorDimensions *)&v29) & 1) != 0
       || (IsSingularValue((const ZinTensorDimensions *)v27) & 1) != 0
       || v29.i64[1] == v27[0].i64[1]
       && (ZinElementWiseLayerUtils::IsChannelVector(&v29) || ZinElementWiseLayerUtils::IsChannelVector(v27))))
    {
      ZinElementWiseLayerUtils::GetOutputTensorDims((int64x2_t *)(*((void *)this + 1) + 8), (int64x2_t *)(*((void *)this + 1) + 128), v25);
      uint64_t result = 0;
      int8x16_t v22 = v25[1];
      *a3 = v25[0];
      a3[1] = v22;
      uint64_t v23 = v26;
      goto LABEL_17;
    }
    if (!ZinElementWiseLayerUtils::CanMatchDimensions((ZinElementWiseLayerUtils *)(*((void *)this + 1) + 8), (const ZinTensorDimensions *)(*((void *)this + 1) + 128), a2, v13))
    {
      CFStringRef v11 = @"InvalidBottomDimensions";
      goto LABEL_5;
    }
  }
  uint64_t v14 = *((void *)this + 1);
  int8x16_t v15 = *(int8x16_t *)(v14 + 8);
  int8x16_t v16 = *(int8x16_t *)(v14 + 24);
  a3[2].i64[0] = *(void *)(v14 + 40);
  *a3 = v15;
  a3[1] = v16;
  if (IsEWTypeUnary(*((_DWORD *)this + 34))) {
    return 0;
  }
  ZinElementWiseLayerUtils::GetOutputTensorDims((int64x2_t *)(*((void *)this + 1) + 8), (int64x2_t *)(*((void *)this + 1) + 128), (int8x16_t *)&v29);
  uint64_t result = 0;
  int8x16_t v24 = v30;
  *a3 = (int8x16_t)v29;
  a3[1] = v24;
  uint64_t v23 = v31;
LABEL_17:
  a3[2].i64[0] = v23;
  return result;
}

uint64_t ZinIrEWUnit::ValidateOutputChannel(ZinIrEWUnit *this, uint64_t a2, CFArrayRef *a3)
{
  uint64_t v3 = *((void *)this + 16);
  uint64_t v4 = *((void *)this + 1);
  if (v3 != -1)
  {
    uint64_t v5 = *(void *)(v4 + 16);
    if (a2 == 2)
    {
      if (v5 != v3 && *(void *)(v4 + 136) != v3) {
        goto LABEL_5;
      }
    }
    else if (v5 != v3)
    {
LABEL_5:
      ZinIrUnitStatus::SetError(a3, @"InvalidOutputChannels");
      return 3;
    }
    return 0;
  }
  if (a2 == 1)
  {
    uint64_t v7 = *(void *)(v4 + 16);
  }
  else
  {
    uint64_t v7 = *(void *)(v4 + 16);
    uint64_t v8 = *(void *)(v4 + 136);
    if (v7 <= v8) {
      uint64_t v7 = v8;
    }
  }
  uint64_t v6 = 0;
  *((void *)this + 16) = v7;
  return v6;
}

uint64_t ZinIrEWUnit::ValidateForDynamicShapes(ZinIrEWUnit *this, CFArrayRef *a2)
{
  unint64_t v2 = 0xEEEEEEEEEEEEEEEFLL * ((uint64_t)(*((void *)this + 2) - *((void *)this + 1)) >> 3);
  if (v2 == 1) {
    return 0;
  }
  if (v2 == 2)
  {
    unsigned int v3 = *((_DWORD *)this + 34) - 1;
    if (v3 < 0x15 && ((0x1F82FBu >> v3) & 1) != 0) {
      return 0;
    }
  }
  ZinIrUnitStatus::SetError(a2, @"UnsupportedForDynamicShapes");
  return 3;
}

__CFDictionary *ZinCreateNEPoolUnit(void **a1)
{
  *(void *)&long long v27 = *MEMORY[0x263EF8340];
  Unit = ZinCreateUnit((const ZinIrUnitInfo *)a1);
  uint64_t v13 = &unk_26C345B80;
  if (*((char *)a1 + 399) < 0) {
    std::string::__init_copy_ctor_external(&__p, (const std::string::value_type *)a1[47], (std::string::size_type)a1[48]);
  }
  else {
    std::string __p = *(std::string *)(a1 + 47);
  }
  int v15 = *((_DWORD *)a1 + 100);
  memset(&v16, 0, sizeof(v16));
  std::vector<std::string>::__init_with_size[abi:ne180100]<std::string*,std::string*>(&v16, (long long *)a1[51], (long long *)a1[52], 0xAAAAAAAAAAAAAAABLL * (((unsigned char *)a1[52] - (unsigned char *)a1[51]) >> 3));
  long long v17 = *((_OWORD *)a1 + 27);
  uint64_t v13 = &unk_26C34AB58;
  long long v3 = *((_OWORD *)a1 + 31);
  long long v20 = *((_OWORD *)a1 + 30);
  long long v21 = v3;
  long long v22 = *((_OWORD *)a1 + 32);
  int v23 = *((_DWORD *)a1 + 132);
  long long v4 = *((_OWORD *)a1 + 29);
  long long v18 = *((_OWORD *)a1 + 28);
  long long v19 = v4;
  if (*((char *)a1 + 31) >= 0) {
    size_t v5 = *((unsigned __int8 *)a1 + 31);
  }
  else {
    size_t v5 = (size_t)a1[2];
  }
  uint64_t v6 = &v12;
  std::string::basic_string[abi:ne180100]((uint64_t)&v12, v5 + 5);
  if ((v12.__r_.__value_.__r.__words[2] & 0x8000000000000000) != 0) {
    uint64_t v6 = (std::string *)v12.__r_.__value_.__r.__words[0];
  }
  if (v5)
  {
    if (*((char *)a1 + 31) >= 0) {
      uint64_t v7 = (char *)(a1 + 1);
    }
    else {
      uint64_t v7 = (char *)a1[1];
    }
    memmove(v6, v7, v5);
  }
  strcpy((char *)v6 + v5, ".pool");
  if (SHIBYTE(__p.__r_.__value_.__r.__words[2]) < 0) {
    operator delete(__p.__r_.__value_.__l.__data_);
  }
  std::string __p = v12;
  long long v17 = *((_OWORD *)a1 + 4);
  if (&v13 != a1) {
    std::vector<std::string>::__assign_with_size[abi:ne180100]<std::string*,std::string*>((std::vector<std::string> *)&v16, (std::string *)a1[5], (long long *)a1[6], 0xAAAAAAAAAAAAAAABLL * (((unsigned char *)a1[6] - (unsigned char *)a1[5]) >> 3));
  }
  PoolUnit = ZinCreatePoolUnit((const ZinIrPoolUnitInfo *)&v13);
  if ((__p.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
    p_p = &__p;
  }
  else {
    p_p = (std::string *)__p.__r_.__value_.__r.__words[0];
  }
  CFStringRef v10 = CFStringCreateWithCString((CFAllocatorRef)*MEMORY[0x263EFFB08], (const char *)p_p, 0x8000100u);
  CFDictionaryAddValue(Unit, v10, PoolUnit);
  CFRelease(v10);
  CFRelease(PoolUnit);
  if (SHIBYTE(__p.__r_.__value_.__r.__words[2]) < 0) {
    std::string::__init_copy_ctor_external(&v26, __p.__r_.__value_.__l.__data_, __p.__r_.__value_.__l.__size_);
  }
  else {
    std::string v26 = __p;
  }
  memset(&v12, 0, sizeof(v12));
  int8x16_t v24 = &v12;
  char v25 = 0;
  v12.__r_.__value_.__r.__words[0] = (std::string::size_type)operator new(0x18uLL);
  v12.__r_.__value_.__l.__size_ = v12.__r_.__value_.__r.__words[0];
  v12.__r_.__value_.__r.__words[2] = v12.__r_.__value_.__r.__words[0] + 24;
  v12.__r_.__value_.__l.__size_ = (std::string::size_type)std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::string>,std::string const*,std::string const*,std::string*>((uint64_t)&v12.__r_.__value_.__r.__words[2], (long long *)&v26, &v27, (std::string *)v12.__r_.__value_.__l.__data_);
  ZinCreateNEUnit((uint64_t)a1, (long long **)&v12, Unit);
  int8x16_t v24 = &v12;
  std::vector<std::string>::__destroy_vector::operator()[abi:ne180100]((void ***)&v24);
  if (SHIBYTE(v26.__r_.__value_.__r.__words[2]) < 0) {
    operator delete(v26.__r_.__value_.__l.__data_);
  }
  ZinIrUnitInfo::~ZinIrUnitInfo(&v13);
  return Unit;
}

void sub_2112AF478(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, void *a12, void *__p, uint64_t a14, int a15, __int16 a16, char a17, char a18)
{
}

void ZinEngineLayerMirInfo::ZinEngineLayerMirInfo(ZinEngineLayerMirInfo *this, uint64_t a2)
{
  uint64_t v4 = 0;
  int64x2_t v5 = vdupq_n_s64(1uLL);
  *((_OWORD *)this + 5) = 0u;
  *((int64x2_t *)this + 6) = v5;
  *(int64x2_t *)((char *)this + 120) = v5;
  uint64_t v6 = (ZinEngineLayerMirInfo *)((char *)this + 120);
  *((_DWORD *)this + 152) = 1065353216;
  *((_DWORD *)this + 164) = 1065353216;
  *((_DWORD *)this + 176) = 1065353216;
  *(_WORD *)this = 0;
  *((unsigned char *)this + 2) = 0;
  *((unsigned char *)this + 8) = 0;
  *((unsigned char *)this + 16) = 0;
  *((unsigned char *)this + 24) = 0;
  *((unsigned char *)this + std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = 0;
  *((unsigned char *)this + 40) = 0;
  *((_OWORD *)this + 3) = 0u;
  *((_OWORD *)this + 4) = 0u;
  *((_DWORD *)this + 28) = 0;
  *((void *)this + 23) = 0;
  *((unsigned char *)this + 192) = 0;
  *((void *)this + 20) = 0;
  *((void *)this + 21) = 0;
  *((unsigned char *)this + 176) = 0;
  *((unsigned char *)this + 152) = 0;
  *((void *)this + 17) = 1;
  *((void *)this + 18) = 0;
  *((void *)this + 25) = 1;
  *((void *)this + 26) = 0;
  *((void *)this + 27) = 0;
  *((void *)this + 28) = 0;
  *((_WORD *)this + 116) = 0;
  *((_OWORD *)this + 15) = xmmword_211ED33C0;
  *((unsigned char *)this + 256) = 0;
  *((_DWORD *)this + 88) = 0;
  *((void *)this + 52) = 0;
  *(_OWORD *)((char *)this + 360) = 0u;
  *(_OWORD *)((char *)this + 376) = 0u;
  *(_OWORD *)((char *)this + 392) = 0u;
  *((unsigned char *)this + 408) = 0;
  *((_DWORD *)this + 106) = 0;
  *((void *)this + 61) = 0;
  *((_OWORD *)this + 28) = 0u;
  *((_OWORD *)this + 29) = 0u;
  *((_OWORD *)this + 27) = 0u;
  *((unsigned char *)this + 480) = 0;
  *((_DWORD *)this + 124) = 0;
  *((void *)this + 70) = 0;
  *((unsigned char *)this + 552) = 0;
  *(_OWORD *)((char *)this + 504) = 0u;
  *(_OWORD *)((char *)this + 520) = 0u;
  *(_OWORD *)((char *)this + 536) = 0u;
  *((_DWORD *)this + 142) = 0;
  *((_OWORD *)this + 36) = 0u;
  *((_OWORD *)this + 37) = 0u;
  *(_OWORD *)((char *)this + 297) = 0u;
  *((_OWORD *)this + 17) = 0u;
  *((_OWORD *)this + 18) = 0u;
  *((unsigned char *)this + 344) = 0;
  *((void *)this + 40) = 0;
  *((void *)this + 41) = 0;
  *((void *)this + 42) = 0;
  *((_DWORD *)this + 154) = 0;
  *((_OWORD *)this + 39) = 0u;
  *((_OWORD *)this + 40) = 0u;
  *((_DWORD *)this + 166) = 0;
  *((_OWORD *)this + 42) = 0u;
  *((_OWORD *)this + 43) = 0u;
  do
  {
    uint64_t v7 = (char *)this + v4;
    *((_DWORD *)v7 + 178) = 0;
    uint64_t v8 = (char *)this + v4 + 720;
    v7[804] = 0;
    *((_OWORD *)v7 + 45) = 0uLL;
    *((_OWORD *)v7 + 46) = 0uLL;
    *((_OWORD *)v7 + 47) = 0uLL;
    *((_OWORD *)v7 + 48) = 0uLL;
    v4 += 96;
    *(_OWORD *)(v8 + 57) = 0uLL;
  }
  while (v4 != 192);
  *((_DWORD *)this + 226) = 0;
  *((unsigned char *)this + 996) = 0;
  *((_OWORD *)this + 57) = 0u;
  *((_OWORD *)this + 58) = 0u;
  *((_OWORD *)this + 59) = 0u;
  *((_OWORD *)this + 60) = 0u;
  *(_OWORD *)((char *)this + 969) = 0u;
  *(_OWORD *)((char *)this + 1000) = 0u;
  *(_OWORD *)((char *)this + 1016) = 0u;
  *(_OWORD *)((char *)this + 10std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = 0u;
  *(_OWORD *)((char *)this + 1048) = 0u;
  *(_OWORD *)((char *)this + 1064) = 0u;
  *(_OWORD *)((char *)this + 1080) = 0u;
  *(_OWORD *)((char *)this + 1096) = 0u;
  *(_OWORD *)((char *)this + 1112) = 0u;
  uint64_t v9 = 1000;
  *(_OWORD *)((char *)this + 1128) = 0u;
  *(_OWORD *)((char *)this + 1144) = 0u;
  do
  {
    CFStringRef v10 = (char *)this + v9;
    *(_DWORD *)CFStringRef v10 = 0;
    *(_OWORD *)(v10 + 40) = 0uLL;
    *(_OWORD *)(v10 + 56) = 0uLL;
    *((void *)v10 + 2) = 0;
    *((void *)v10 + 3) = 0;
    *((void *)v10 + 1) = 0;
    *((_DWORD *)v10 + 8) = 0;
    v9 += 80;
    *((_DWORD *)v10 + 18) = 1065353216;
  }
  while (v10 + 80 != (char *)this + 1160);
  *((_DWORD *)this + 290) = 0;
  *((_OWORD *)this + 75) = 0u;
  *((_OWORD *)this + 76) = 0u;
  *((void *)this + 146) = 0;
  *((_DWORD *)this + 298) = 0;
  *(_OWORD *)((char *)this + 1176) = 0u;
  *((_DWORD *)this + 308) = 1065353216;
  *((void *)this + 162) = 0;
  *((unsigned char *)this + 1304) = 0;
  *((void *)this + 164) = 0;
  *((_WORD *)this + 660) = 0;
  *(_OWORD *)((char *)this + 1268) = 0u;
  *(void *)((char *)this + 1281) = 0;
  *((void *)this + 166) = 0;
  *(_DWORD *)((char *)this + 1335) = 0;
  *((_DWORD *)this + 335) = 0;
  *(_DWORD *)((char *)this + 1343) = 0;
  *((void *)this + 171) = 0;
  *((_WORD *)this + 688) = 0;
  *(_OWORD *)((char *)this + 1348) = 0u;
  *((unsigned char *)this + 1384) = 0;
  *((void *)this + 157) = 0;
  *(_OWORD *)((char *)this + 1240) = 0u;
  *((unsigned char *)this + 1264) = 0;
  *(_WORD *)((char *)this + 1385) = 1;
  *((_DWORD *)this + 347) = 0;
  *((unsigned char *)this + 1392) = 0;
  *(void *)&long long v11 = 0x100000001;
  *((void *)&v11 + 1) = 0x100000001;
  *(_OWORD *)((char *)this + 1396) = xmmword_211EF5F90;
  *(_OWORD *)((char *)this + 1412) = v11;
  *(_OWORD *)((char *)this + 1428) = xmmword_211F03C70;
  *(_OWORD *)((char *)this + 1444) = xmmword_211EDE7D0;
  *((void *)this + 191) = 0;
  *((_DWORD *)this + 384) = 0;
  *(_OWORD *)((char *)this + 1512) = 0u;
  *(_OWORD *)((char *)this + 1544) = 0u;
  *((_DWORD *)this + 392) = 0;
  *((void *)this + 195) = 0;
  *((_DWORD *)this + 400) = 0;
  *((void *)this + 199) = 0;
  *(_OWORD *)((char *)this + 1576) = 0u;
  *((void *)this + 203) = 0;
  *((_DWORD *)this + 408) = 0;
  *(_OWORD *)((char *)this + 1608) = 0u;
  *(_OWORD *)((char *)this + 1464) = 0u;
  *(_OWORD *)((char *)this + 1480) = 0u;
  *(_OWORD *)((char *)this + 1489) = 0u;
  *((_DWORD *)this + 410) = 0;
  ZinMirPerfTracerConfig::ZinMirPerfTracerConfig((ZinEngineLayerMirInfo *)((char *)this + 1648), 0);
  *((unsigned char *)this + 1680) = 0;
  *((void *)this + 211) = 0;
  *((_OWORD *)this + 106) = xmmword_211EF1C60;
  *((_OWORD *)this + 107) = xmmword_211EF1C60;
  *((_OWORD *)this + 108) = xmmword_211EF1C60;
  *((_OWORD *)this + 109) = xmmword_211EF1C60;
  *((_OWORD *)this + 110) = xmmword_211EF1C60;
  *((void *)this + 222) = 0xFFFFLL;
  ZinMirL2Config::NE::SetNumNeededNEs(v6, a2);
  ZinMirL2Config::NE::SetOCGSize(v6, 1);
}

void sub_2112AF814(_Unwind_Exception *a1)
{
  CFStringRef v10 = *v8;
  if (*v8)
  {
    v1[202] = v10;
    operator delete(v10);
  }
  long long v11 = *v7;
  if (*v7)
  {
    v1[198] = v11;
    operator delete(v11);
  }
  std::string v12 = *v6;
  if (*v6)
  {
    v1[194] = v12;
    operator delete(v12);
  }
  uint64_t v13 = *v5;
  if (*v5)
  {
    v1[190] = v13;
    operator delete(v13);
  }
  ZinDramDependentInfo::~ZinDramDependentInfo(v4);
  std::array<ZinDramDependentInfo,2ul>::~array(v3);
  ZinMirL2Config::~ZinMirL2Config(v2);
  uint64_t v14 = (void *)v1[7];
  if (v14)
  {
    v1[8] = v14;
    operator delete(v14);
  }
  _Unwind_Resume(a1);
}

BOOL ZinEngineLayerMirInfo::SetNumNeededNEs(ZinEngineLayerMirInfo *this, uint64_t a2)
{
  return ZinMirL2Config::NE::SetNumNeededNEs((ZinEngineLayerMirInfo *)((char *)this + 120), a2);
}

BOOL ZinEngineLayerMirInfo::SetOCGSize(ZinEngineLayerMirInfo *this, uint64_t a2)
{
  return ZinMirL2Config::NE::SetOCGSize((ZinEngineLayerMirInfo *)((char *)this + 120), a2);
}

void ZinEngineLayerMirInfo::~ZinEngineLayerMirInfo(ZinEngineLayerMirInfo *this)
{
  unint64_t v2 = (void *)*((void *)this + 207);
  if (v2)
  {
    *((void *)this + 208) = v2;
    operator delete(v2);
  }
  uint64_t v3 = (void *)*((void *)this + 201);
  if (v3)
  {
    *((void *)this + 202) = v3;
    operator delete(v3);
  }
  uint64_t v4 = (void *)*((void *)this + 197);
  if (v4)
  {
    *((void *)this + 198) = v4;
    operator delete(v4);
  }
  int64x2_t v5 = (void *)*((void *)this + 193);
  if (v5)
  {
    *((void *)this + 194) = v5;
    operator delete(v5);
  }
  uint64_t v6 = (void *)*((void *)this + 189);
  if (v6)
  {
    *((void *)this + 190) = v6;
    operator delete(v6);
  }
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)this + 1200);
  uint64_t v7 = (void *)*((void *)this + 146);
  if (v7)
  {
    *((void *)this + 147) = v7;
    operator delete(v7);
  }
  for (uint64_t i = 0; i != -160; i -= 80)
  {
    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)this + i + 1120);
    uint64_t v9 = *(void **)((char *)this + i + 1088);
    if (v9)
    {
      *(void *)((char *)this + i + 1096) = v9;
      operator delete(v9);
    }
  }
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)this + 672);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)this + 624);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)this + 576);
  CFStringRef v10 = (void *)*((void *)this + 7);
  if (v10)
  {
    *((void *)this + 8) = v10;
    operator delete(v10);
  }
}

uint64_t ZinEngineLayerMirInfo::GetChannelAssignment(ZinEngineLayerMirInfo *this)
{
  return ZinMirL2Config::NE::GetChannelAssignment((ZinEngineLayerMirInfo *)((char *)this + 120));
}

__n128 ZinEngineLayerMirInfo::SetAddressTranslationBoundaryRegisters(uint64_t a1, int a2, uint64_t a3)
{
  if (a2 == 3)
  {
    uint64_t v3 = (_OWORD *)(a1 + 1752);
  }
  else if (a2 == 1)
  {
    uint64_t v3 = (_OWORD *)(a1 + 1720);
  }
  else
  {
    if (a2) {
      ZinAssertImpl("Type Undefined\n");
    }
    uint64_t v3 = (_OWORD *)(a1 + 1688);
  }
  __n128 result = *(__n128 *)a3;
  long long v5 = *(_OWORD *)(a3 + 16);
  *uint64_t v3 = *(_OWORD *)a3;
  v3[1] = v5;
  return result;
}

__n128 ZinEngineLayerMirInfo::GetAddressTranslationBoundaryRegisters@<Q0>(uint64_t a1@<X0>, int a2@<W1>, _OWORD *a3@<X8>)
{
  *a3 = xmmword_211F03C80;
  a3[1] = xmmword_211F03C80;
  if (a2 == 3)
  {
    uint64_t v3 = a1 + 1752;
  }
  else if (a2 == 1)
  {
    uint64_t v3 = a1 + 1720;
  }
  else
  {
    if (a2) {
      ZinAssertImpl("Type Undefined\n");
    }
    uint64_t v3 = a1 + 1688;
  }
  __n128 result = *(__n128 *)v3;
  long long v5 = *(_OWORD *)(v3 + 16);
  *a3 = *(_OWORD *)v3;
  a3[1] = v5;
  return result;
}

uint64_t ZinEngineLayerMirInfo::GetAllValidL2Symbols@<X0>(ZinEngineLayerMirInfo *this@<X0>, uint64_t a2@<X8>)
{
  *(void *)(a2 + 16) = 0;
  *(void *)(a2 + 8) = 0;
  *(void *)a2 = a2 + 8;
  uint64_t Symbol = ZinL2Access::GetSymbol((ZinEngineLayerMirInfo *)((char *)this + 1512));
  std::__tree<ZinIrSymbol *,ZinIrSymbol::Compare,std::allocator<ZinIrSymbol *>>::__emplace_unique_key_args<ZinIrSymbol *,ZinIrSymbol * const&>((uint64_t **)a2, &Symbol, &Symbol);
  uint64_t Symbol = ZinL2Access::GetSymbol((ZinEngineLayerMirInfo *)((char *)this + 1544));
  std::__tree<ZinIrSymbol *,ZinIrSymbol::Compare,std::allocator<ZinIrSymbol *>>::__emplace_unique_key_args<ZinIrSymbol *,ZinIrSymbol * const&>((uint64_t **)a2, &Symbol, &Symbol);
  uint64_t Symbol = ZinL2Access::GetSymbol((ZinEngineLayerMirInfo *)((char *)this + 1576));
  std::__tree<ZinIrSymbol *,ZinIrSymbol::Compare,std::allocator<ZinIrSymbol *>>::__emplace_unique_key_args<ZinIrSymbol *,ZinIrSymbol * const&>((uint64_t **)a2, &Symbol, &Symbol);
  uint64_t Symbol = ZinL2Access::GetSymbol((ZinEngineLayerMirInfo *)((char *)this + 1608));
  std::__tree<ZinIrSymbol *,ZinIrSymbol::Compare,std::allocator<ZinIrSymbol *>>::__emplace_unique_key_args<ZinIrSymbol *,ZinIrSymbol * const&>((uint64_t **)a2, &Symbol, &Symbol);
  uint64_t Symbol = 0;
  return std::__tree<ZinIrSymbol const*,ZinIrSymbol::Compare,std::allocator<ZinIrSymbol const*>>::__erase_unique<ZinIrSymbol const*>((uint64_t **)a2, &Symbol);
}

void sub_2112AFB0C(_Unwind_Exception *a1)
{
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy(v1, *(void **)(v1 + 8));
  _Unwind_Resume(a1);
}

uint64_t ZinEngineLayerMirInfo::GetL2RdSymbol(uint64_t a1, int a2)
{
  if (a2 == 2) {
    return ZinL2Access::GetSymbol((ZinL2Access *)(a1 + 1576));
  }
  if (a2 == 1) {
    return ZinL2Access::GetSymbol((ZinL2Access *)(a1 + 1544));
  }
  return ZinL2Access::GetSymbol((ZinL2Access *)(a1 + 1512));
}

uint64_t ZinEngineLayerMirInfo::GetL2WrSymbol(ZinEngineLayerMirInfo *this)
{
  return ZinL2Access::GetSymbol((ZinEngineLayerMirInfo *)((char *)this + 1608));
}

uint64_t ZinEngineLayerMirInfo::GetL2RdAccess(uint64_t a1, int a2)
{
  if (a2 == 2) {
    return a1 + 1576;
  }
  if (a2 == 1) {
    return a1 + 1544;
  }
  return a1 + 1512;
}

void *ZinEngineLayerMirInfo::GetL2RdSymbols@<X0>(uint64_t a1@<X0>, int a2@<W1>, void *a3@<X8>)
{
  if (a2 == 2)
  {
    uint64_t v5 = a1 + 1576;
  }
  else if (a2 == 1)
  {
    uint64_t v5 = a1 + 1544;
  }
  else
  {
    uint64_t v5 = a1 + 1512;
  }
  *a3 = 0;
  a3[1] = 0;
  a3[2] = 0;
  return std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(a3, *(const void **)v5, *(void *)(v5 + 8), (uint64_t)(*(void *)(v5 + 8) - *(void *)v5) >> 3);
}

void *ZinEngineLayerMirInfo::GetL2WrSymbols@<X0>(ZinEngineLayerMirInfo *this@<X0>, void *a2@<X8>)
{
  *a2 = 0;
  a2[1] = 0;
  a2[2] = 0;
  return std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(a2, *((const void **)this + 201), *((void *)this + 202), (uint64_t)(*((void *)this + 202) - *((void *)this + 201)) >> 3);
}

uint64_t ZinEngineLayerMirInfo::SetL2RdSymbols(uint64_t a1, const ZinIrSymbol ***a2, int a3, int a4)
{
  uint64_t v8 = *a2;
  uint64_t v9 = a2[1];
  while (v8 != v9)
  {
    if (!IsL2Symbol(*v8)) {
      return 0;
    }
    ++v8;
  }
  switch(a3)
  {
    case 2:
      uint64_t v10 = a1 + 1576;
      goto LABEL_12;
    case 1:
      uint64_t v10 = a1 + 1544;
      goto LABEL_12;
    case 0:
      uint64_t v10 = a1 + 1512;
LABEL_12:
      ZinL2Access::SetSymbols(v10, (uint64_t)a2, a4);
      break;
  }
  return 1;
}

BOOL IsL2Symbol(const ZinIrSymbol *a1)
{
  if (a1 && ZinIrSymbol::GetMemType(a1) == 2) {
    return 1;
  }
  BOOL result = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
  if (result)
  {
    IsL2Symbol();
    return 0;
  }
  return result;
}

uint64_t ZinEngineLayerMirInfo::SetL2WrSymbols(uint64_t a1, const ZinIrSymbol ***a2, int a3)
{
  uint64_t v6 = *a2;
  uint64_t v7 = a2[1];
  while (1)
  {
    if (v6 == v7)
    {
      ZinL2Access::SetSymbols(a1 + 1608, (uint64_t)a2, a3);
      return 1;
    }
    if (!IsL2Symbol(*v6)) {
      break;
    }
    ++v6;
  }
  return 0;
}

uint64_t ZinEngineLayerMirInfo::RemoveL2RdSymbol(uint64_t result, int a2)
{
  switch(a2)
  {
    case 2:
      return ZinL2Access::RemoveSymbol(result + 1576);
    case 1:
      return ZinL2Access::RemoveSymbol(result + 1544);
    case 0:
      return ZinL2Access::RemoveSymbol(result + 1512);
  }
  return result;
}

uint64_t ZinEngineLayerMirInfo::GetL2RdMode(uint64_t a1, int a2)
{
  if (a2 == 2)
  {
    uint64_t v2 = a1 + 1576;
  }
  else if (a2 == 1)
  {
    uint64_t v2 = a1 + 1544;
  }
  else
  {
    uint64_t v2 = a1 + 1512;
  }
  return *(unsigned int *)(v2 + 24);
}

uint64_t ZinEngineLayerMirInfo::HasChainRead(_DWORD *a1, int *a2)
{
  if (a1[384] == 4)
  {
    int v2 = 0;
LABEL_7:
    *a2 = v2;
    return 1;
  }
  if (a1[392] == 4)
  {
    int v2 = 1;
    goto LABEL_7;
  }
  if (a1[400] == 4)
  {
    int v2 = 2;
    goto LABEL_7;
  }
  return 0;
}

void ZinEngineLayerMirInfo::SetNeedInputDMACached(uint64_t a1, int a2, char a3)
{
  switch(a2)
  {
    case 2:
      if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
        ZinEngineLayerMirInfo::SetNeedInputDMACached();
      }
      break;
    case 1:
      *(unsigned char *)(a1 + 1641) = a3;
      break;
    case 0:
      *(unsigned char *)(a1 + 1640) = a3;
      break;
  }
}

BOOL ZinEngineLayerMirInfo::NeedInputDMACached(uint64_t a1, int a2)
{
  if (a2 == 1)
  {
    int v2 = (unsigned __int8 *)(a1 + 1641);
    return *v2 != 0;
  }
  if (!a2)
  {
    int v2 = (unsigned __int8 *)(a1 + 1640);
    return *v2 != 0;
  }
  return 0;
}

double ZinEngineLayerMirInfo::SetChannelAssignment(ZinEngineLayerMirInfo *this, const MirInfoChannelAssignment *a2)
{
  *(void *)&double result = ZinMirL2Config::NE::SetChannelAssignment((ZinEngineLayerMirInfo *)((char *)this + 120), a2).n128_u64[0];
  return result;
}

BOOL ZinEngineLayerMirInfo::SetFatTileEnable(ZinEngineLayerMirInfo *this, char a2)
{
  return ZinMirL2Config::NE::SetFatTileEnable((ZinEngineLayerMirInfo *)((char *)this + 120), a2);
}

BOOL ZinEngineLayerMirInfo::SetWUStackLog2(ZinEngineLayerMirInfo *this, uint64_t a2)
{
  return ZinMirL2Config::NE::SetWUStackLog2((ZinEngineLayerMirInfo *)((char *)this + 120), a2);
}

uint64_t ZinEngineLayerMirInfo::SetChannelAssignmentLock(ZinEngineLayerMirInfo *this, char a2)
{
  return ZinMirL2Config::NE::SetChannelAssignmentLock((ZinEngineLayerMirInfo *)((char *)this + 120), a2);
}

void IsL2Symbol()
{
  *(_WORD *)uint64_t v0 = 0;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "Error: Invalid L2 Symbol. Null symbol or non-L2 symbol.\n", v0, 2u);
}

void ZinEngineLayerMirInfo::SetNeedInputDMACached()
{
  *(_WORD *)uint64_t v0 = 0;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "Error: SrcIdx should always be resident for Crete+", v0, 2u);
}

CFMutableDictionaryRef ZinCreateBroadcastUnit(const ZinIrBroadcastUnitInfo *a1)
{
  CFMutableDictionaryRef Unit = ZinCreateUnit(a1);
  CFAllocatorRef v2 = (const __CFAllocator *)*MEMORY[0x263EFFB08];
  theDict = CFDictionaryCreateMutable((CFAllocatorRef)*MEMORY[0x263EFFB08], 0, MEMORY[0x263EFFF88], MEMORY[0x263EFFF90]);
  Mutable = CFArrayCreateMutable(v2, 0, MEMORY[0x263EFFF70]);
  uint64_t v4 = (uint64_t *)*((void *)a1 + 12);
  if (v4)
  {
    uint64_t v5 = (const CFDictionaryKeyCallBacks *)MEMORY[0x263EFFF88];
    uint64_t v6 = (const CFDictionaryValueCallBacks *)MEMORY[0x263EFFF90];
    do
    {
      uint64_t v7 = CFDictionaryCreateMutable(v2, 0, v5, v6);
      int valuePtr = v4[3];
      CFNumberRef v8 = CFNumberCreate(v2, kCFNumberSInt32Type, &valuePtr);
      uint64_t v9 = ZinIrCoordinateToCFString((_DWORD *)v4 + 4);
      CFDictionaryAddValue(v7, @"Dimension", v9);
      CFDictionaryAddValue(v7, @"Size", v8);
      CFArrayAppendValue(Mutable, v7);
      CFRelease(v8);
      CFRelease(v7);
      uint64_t v4 = (uint64_t *)*v4;
    }
    while (v4);
  }
  CFDictionaryAddValue(theDict, @"BroadcastInfo", Mutable);
  CFDictionaryAddValue(Unit, @"Params", theDict);
  CFRelease(Mutable);
  CFRelease(theDict);
  return Unit;
}

void ZinMirHoistGOCTexture::InitializePatterns(ZinMirHoistGOCTexture *this)
{
  v18[26] = *MEMORY[0x263EF8340];
  std::string::basic_string[abi:ne180100]<0>(&v12, "dequant_goc");
  v13[0] = &unk_26C380F00;
  v13[1] = MatchDequantGOC;
  uint64_t v13[3] = v13;
  int v5 = 1;
  std::unordered_set<Attribute>::unordered_set((uint64_t)&v14, &v5, 1);
  std::string::basic_string[abi:ne180100]<0>(v15, "texture");
  v16[0] = &unk_26C380F00;
  v16[1] = MatchTexture;
  void v16[3] = v16;
  int v4 = 1;
  std::unordered_set<Attribute>::unordered_set((uint64_t)v17, &v4, 1);
  uint64_t v6 = 0;
  uint64_t v7 = 0;
  CFNumberRef v8 = 0;
  uint64_t v9 = &v6;
  char v10 = 0;
  uint64_t v6 = (char *)operator new(0xC0uLL);
  uint64_t v7 = (uint64_t)v6;
  CFNumberRef v8 = v6 + 192;
  uint64_t v7 = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<ZinLinearPattern::AtomItemDesc>,ZinLinearPattern::AtomItemDesc const*,ZinLinearPattern::AtomItemDesc const*,ZinLinearPattern::AtomItemDesc*>((uint64_t)&v8, (uint64_t)&v12, (uint64_t)v18, (uint64_t)v6);
  uint64_t v2 = *((void *)this + 2);
  v11[0] = &unk_26C3811C0;
  v11[1] = IsValidPattern;
  v11[3] = v11;
  ZinLinearPattern::ZinLinearPattern(v18, &v6, v2, 0, v11, 0);
  std::__function::__value_func<BOOL ()(ZinIrOpLayerGraph const*,ZinIrParameters const&,ZinPattern const*)>::~__value_func[abi:ne180100](v11);
  uint64_t v9 = &v6;
  std::vector<ZinLinearPattern::AtomItemDesc>::__destroy_vector::operator()[abi:ne180100]((void ***)&v9);
  uint64_t v3 = 0;
  while (1)
  {
    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&v17[v3 * 8]);
    std::__function::__value_func<MatchStatus ()(MatchParams const&)>::~__value_func[abi:ne180100](&v16[v3]);
    if (SHIBYTE(v15[v3 + 2]) < 0) {
      operator delete((void *)v15[v3]);
    }
    v3 -= 12;
    if (v3 == -24) {
      operator new();
    }
  }
}

void sub_2112B0408(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, void *a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33,uint64_t a34,uint64_t a35,uint64_t a36,uint64_t a37,uint64_t a38,uint64_t a39,uint64_t a40,uint64_t a41,uint64_t a42,uint64_t a43,char a44)
{
}

uint64_t MatchDequantGOC(uint64_t a1)
{
  uint64_t v1 = *(void *)(a1 + 8);
  BOOL v3 = *(_DWORD *)(*(void *)(v1 + 64) + 8) == 2
    && ZinIrOpLayer::IsTensorFmtQuantized(**(ZinIrOpLayer ***)(v1 + 88))
    && *(void *)(*(void *)(a1 + 8) + 120) - *(void *)(*(void *)(a1 + 8) + 112) < 9uLL;
  return v3 | 0x100u;
}

uint64_t MatchTexture(uint64_t a1)
{
  return ZinIrOpLayer::IsTELayer(*(ZinIrOpLayer **)(a1 + 8)) | 0x100;
}

uint64_t IsValidPattern(uint64_t a1, uint64_t a2, uint64_t a3)
{
  std::string::basic_string[abi:ne180100]<0>(__p, "dequant_goc");
  SingleMatch = (ZinGOCLayer *)ZinPattern::GetSingleMatch(a3, (unsigned __int8 *)__p);
  if (v8 < 0) {
    operator delete(__p[0]);
  }
  std::string::basic_string[abi:ne180100]<0>(__p, "texture");
  int v5 = (void **)ZinPattern::GetSingleMatch(a3, (unsigned __int8 *)__p);
  if (v8 < 0) {
    operator delete(__p[0]);
  }
  if (SingleMatch != (ZinGOCLayer *)*v5[11]) {
    return 0;
  }
  if (ZinGOCLayer::IsSingularScaleBias(SingleMatch)) {
    return 1;
  }
  uint64_t result = ((uint64_t (*)(void **, uint64_t))(*v5)[43])(v5, 2);
  if (result) {
    return 1;
  }
  return result;
}

void sub_2112B067C(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11, int a12, __int16 a13, char a14, char a15)
{
  if (a15 < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

void ZinMirHoistGOCTexture::Hoist(ZinMirHoistGOCTexture *this, const ZinPattern *a2, ZinIrOpLayerGraph *a3)
{
  uint64_t v13 = *MEMORY[0x263EF8340];
  std::string::basic_string[abi:ne180100]<0>(&v11, "dequant_goc");
  uint64_t SingleMatch = ZinPattern::GetSingleMatch((uint64_t)a2, (unsigned __int8 *)&v11);
  if (v12 < 0) {
    operator delete(v11);
  }
  std::string::basic_string[abi:ne180100]<0>(&v11, "texture");
  uint64_t v5 = ZinPattern::GetSingleMatch((uint64_t)a2, (unsigned __int8 *)&v11);
  if (v12 < 0) {
    operator delete(v11);
  }
  if (*(char *)(SingleMatch + 47) >= 0) {
    size_t v6 = *(unsigned __int8 *)(SingleMatch + 47);
  }
  else {
    size_t v6 = *(void *)(SingleMatch + 32);
  }
  p_p = &__p;
  std::string::basic_string[abi:ne180100]((uint64_t)&__p, v6 + 14);
  if ((__p.__r_.__value_.__r.__words[2] & 0x8000000000000000) != 0) {
    p_p = (std::string *)__p.__r_.__value_.__r.__words[0];
  }
  if (v6)
  {
    if (*(char *)(SingleMatch + 47) >= 0) {
      char v8 = (const void *)(SingleMatch + 24);
    }
    else {
      char v8 = *(const void **)(SingleMatch + 24);
    }
    memmove(p_p, v8, v6);
  }
  strcpy((char *)p_p + v6, "SwapGOCTexture");
  __n128 v9 = ZinObjectNameFactory::ZinObjectNameFactory(&v11, &__p);
  if (SHIBYTE(__p.__r_.__value_.__r.__words[2]) < 0) {
    operator delete(__p.__r_.__value_.__l.__data_);
  }
  (*(void (**)(uint64_t, void, void, __n128))(*(void *)v5 + 32))(v5, 0, 0, v9);
  ZinObjectNameFactory::CreateName((uint64_t)&v11, 0, &__p);
  ZinIrTensor::CreateTensor();
}

void sub_2112B0A3C(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, char a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, void *a18, void *__p, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,std::__shared_weak_count *a25)
{
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&a11);
  if (a25) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a25);
  }
  *(void *)(v25 - 120) = &unk_26C34DA98;
  if (*(char *)(v25 - 89) < 0) {
    operator delete(*(void **)(v25 - 112));
  }
  _Unwind_Resume(a1);
}

void ZinMirHoistGOCTexture::Hoist()
{
  *(_WORD *)uint64_t v0 = 0;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "[ZinIrOptSwapGOCTexture] Graph Transformation Failed\n", v0, 2u);
}

void ZinChannelToSpaceLargeFactorCompositeLayer::ZinChannelToSpaceLargeFactorCompositeLayer(ZinChannelToSpaceLargeFactorCompositeLayer *this, ZinConvLayer *a2, ZinGOCLayer *a3, ZinChannelToSpaceLayer *a4)
{
}

void sub_2112B0E0C(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *a10, uint64_t a11, int a12, __int16 a13, char a14, char a15, void *a16, uint64_t a17, int a18, __int16 a19, char a20,char a21,void *a22,uint64_t a23,int a24,__int16 a25,char a26,char a27,void *__p,uint64_t a29,int a30,__int16 a31,char a32,char a33)
{
  std::unique_ptr<ZinIrKernel>::reset[abi:ne180100]((ZinIrKernel **)&a9, 0);
  if (a33 < 0) {
    operator delete(__p);
  }
  if (a21 < 0) {
    operator delete(a16);
  }
  if (a15 < 0) {
    operator delete(a10);
  }
  if (a27 < 0) {
    operator delete(a22);
  }
  uint64_t v35 = *(std::__shared_weak_count **)(v33 - 64);
  if (v35) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v35);
  }
  uint64_t v36 = *(void *)(v33 - 56);
  *(void *)(v33 - 56) = 0;
  if (v36) {
    (*(void (**)(uint64_t))(*(void *)v36 + 8))(v36);
  }
  _Unwind_Resume(a1);
}

void ZinChannelToSpaceLargeFactorCompositeLayer::Lower(void *a1)
{
  v125[1] = *MEMORY[0x263EF8340];
  uint64_t v2 = a1[24];
  if (v2)
  {
    uint64_t v3 = a1[26];
    if (v3)
    {
      int v4 = *(int **)(v3 + 64);
      if (v4[3] == 4 && v4[4] == 4 && v4[5] == 1)
      {
        if ((*(unsigned char *)((*(uint64_t (**)(uint64_t, void, void))(*(void *)v2 + 32))(v2, 0, 0) + 56) & 3) == 0)
        {
          long long v104 = *(ZinIrContext **)(a1[24] + 16);
          Hal = ZinIrTarget::GetHal((uint64_t *)v104, *((ZinIrTarget **)v104 + 20));
          (*(void (**)(uint64_t *))(*Hal + 16))(Hal);
          uint64_t v6 = (*(uint64_t (**)(void, void, void))(*(void *)a1[24] + 32))(a1[24], 0, 0);
          uint64_t v7 = *(void *)(v6 + 56);
          uint64_t v8 = v7 + 3;
          if (v7 >= 0) {
            uint64_t v8 = *(void *)(v6 + 56);
          }
          char v119 = 0;
          uint64_t v120 = v8 >> 2;
          int64x2_t v117 = 0;
          char v118 = 0;
          if (v7 < 1)
          {
            long long v20 = 0;
            __n128 v9 = 0;
          }
          else
          {
            __n128 v9 = 0;
            for (uint64_t i = 0; i < v7; uint64_t i = (int)v120 + (int)i)
            {
              if (v9 >= (uint64_t *)v119)
              {
                long long v11 = v117;
                uint64_t v12 = v9 - v117;
                unint64_t v13 = v12 + 1;
                if ((unint64_t)(v12 + 1) >> 61) {
                  std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
                }
                uint64_t v14 = v119 - (char *)v117;
                if ((v119 - (char *)v117) >> 2 > v13) {
                  unint64_t v13 = v14 >> 2;
                }
                if ((unint64_t)v14 >= 0x7FFFFFFFFFFFFFF8) {
                  unint64_t v15 = 0x1FFFFFFFFFFFFFFFLL;
                }
                else {
                  unint64_t v15 = v13;
                }
                if (v15)
                {
                  std::string v16 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)&v119, v15);
                  long long v11 = v117;
                  __n128 v9 = v118;
                }
                else
                {
                  std::string v16 = 0;
                }
                long long v17 = (uint64_t *)&v16[8 * v12];
                uint64_t *v17 = i;
                long long v18 = v17 + 1;
                while (v9 != v11)
                {
                  uint64_t v19 = *--v9;
                  *--long long v17 = v19;
                }
                int64x2_t v117 = v17;
                char v118 = v18;
                char v119 = &v16[8 * v15];
                if (v11) {
                  operator delete(v11);
                }
                __n128 v9 = v18;
              }
              else
              {
                *v9++ = i;
              }
              char v118 = v9;
            }
            long long v20 = (char *)v117;
          }
          if ((char *)v9 - v20 == 32)
          {
            uint64_t v21 = 0;
            unint64_t v114 = 0;
            int v115 = 0;
            unint64_t v116 = 0;
            while (1)
            {
              v108.__r_.__value_.__s.__data_[0] = 0;
              std::allocate_shared[abi:ne180100]<ZinIrTransformPartial,std::allocator<ZinIrTransformPartial>,long &,unsigned long &,ZinPartialTransformDimension,void>(&v120, &v117[v21], (char *)&v108, &v110);
              long long v22 = v115;
              if ((unint64_t)v115 >= v116)
              {
                uint64_t v23 = (v115 - v114) >> 4;
                unint64_t v24 = v23 + 1;
                if ((unint64_t)(v23 + 1) >> 60) {
                  std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
                }
                uint64_t v25 = v116 - (void)v114;
                if ((uint64_t)(v116 - (void)v114) >> 3 > v24) {
                  unint64_t v24 = v25 >> 3;
                }
                if ((unint64_t)v25 >= 0x7FFFFFFFFFFFFFF0) {
                  unint64_t v26 = 0xFFFFFFFFFFFFFFFLL;
                }
                else {
                  unint64_t v26 = v24;
                }
                __v.__end_cap_.__value_ = (std::allocator<std::string> *)&v116;
                long long v27 = (std::string *)std::__allocate_at_least[abi:ne180100]<std::allocator<std::pair<unsigned long,unsigned long>>>((uint64_t)&v116, v26);
                uint64_t v28 = (char *)v27 + 16 * v23;
                __v.__first_ = v27;
                __v.__begin_ = (std::__split_buffer<std::string>::pointer)v28;
                __v.__end_cap_.__value_ = (std::string *)((char *)v27 + 16 * v29);
                *(_OWORD *)uint64_t v28 = *(_OWORD *)&v110.__r_.__value_.__l.__data_;
                *(_OWORD *)&v110.__r_.__value_.__l.__data_ = 0uLL;
                __v.__end_ = (std::__split_buffer<std::string>::pointer)(v28 + 16);
                std::vector<std::shared_ptr<ZinIrTransformPartial>>::__swap_out_circular_buffer((uint64_t *)&v114, &__v);
                int8x16_t v30 = v115;
                std::__split_buffer<std::shared_ptr<ZinIrConstData>>::~__split_buffer((void **)&__v.__first_);
                int v115 = v30;
                if (v110.__r_.__value_.__l.__size_) {
                  std::__shared_weak_count::__release_shared[abi:ne180100]((std::__shared_weak_count *)v110.__r_.__value_.__l.__size_);
                }
              }
              else
              {
                *(_OWORD *)int v115 = *(_OWORD *)&v110.__r_.__value_.__l.__data_;
                int v115 = v22 + 16;
              }
              if (++v21 == 4)
              {
                if (v115 - v114 == 64)
                {
                  int v31 = 0;
                  memset(&v113, 0, sizeof(v113));
                  while (1)
                  {
                    uint64_t v32 = a1[24];
                    if (*(char *)(v32 + 47) >= 0) {
                      size_t v33 = *(unsigned __int8 *)(v32 + 47);
                    }
                    else {
                      size_t v33 = *(void *)(v32 + 32);
                    }
                    std::string::basic_string[abi:ne180100]((uint64_t)&v107, v33 + 7);
                    if ((v107.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
                      uint64_t v34 = &v107;
                    }
                    else {
                      uint64_t v34 = (std::string *)v107.__r_.__value_.__r.__words[0];
                    }
                    if (v33)
                    {
                      if (*(char *)(v32 + 47) >= 0) {
                        uint64_t v35 = (const void *)(v32 + 24);
                      }
                      else {
                        uint64_t v35 = *(const void **)(v32 + 24);
                      }
                      memmove(v34, v35, v33);
                    }
                    strcpy((char *)v34 + v33, "_split_");
                    std::to_string(&v109, v31);
                    if ((v109.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
                      uint64_t v36 = &v109;
                    }
                    else {
                      uint64_t v36 = (std::string *)v109.__r_.__value_.__r.__words[0];
                    }
                    if ((v109.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
                      std::string::size_type size = HIBYTE(v109.__r_.__value_.__r.__words[2]);
                    }
                    else {
                      std::string::size_type size = v109.__r_.__value_.__l.__size_;
                    }
                    long long v38 = std::string::append(&v107, (const std::string::value_type *)v36, size);
                    long long v39 = *(_OWORD *)&v38->__r_.__value_.__l.__data_;
                    v108.__r_.__value_.__r.__words[2] = v38->__r_.__value_.__r.__words[2];
                    *(_OWORD *)&v108.__r_.__value_.__l.__data_ = v39;
                    v38->__r_.__value_.__l.__size_ = 0;
                    v38->__r_.__value_.__r.__words[2] = 0;
                    v38->__r_.__value_.__r.__words[0] = 0;
                    long long v40 = std::string::append(&v108, "_", 1uLL);
                    long long v41 = *(_OWORD *)&v40->__r_.__value_.__l.__data_;
                    v110.__r_.__value_.__r.__words[2] = v40->__r_.__value_.__r.__words[2];
                    *(_OWORD *)&v110.__r_.__value_.__l.__data_ = v41;
                    v40->__r_.__value_.__l.__size_ = 0;
                    v40->__r_.__value_.__r.__words[2] = 0;
                    v40->__r_.__value_.__r.__words[0] = 0;
                    std::string::basic_string[abi:ne180100]<0>(&v112, "c2s_comp");
                    long long v42 = std::string::append(&v112, "_xfm", 4uLL);
                    long long v43 = *(_OWORD *)&v42->__r_.__value_.__l.__data_;
                    int64_t v106 = v42->__r_.__value_.__r.__words[2];
                    *(_OWORD *)std::string __p = v43;
                    v42->__r_.__value_.__l.__size_ = 0;
                    v42->__r_.__value_.__r.__words[2] = 0;
                    v42->__r_.__value_.__r.__words[0] = 0;
                    if (v106 >= 0) {
                      uint64_t v44 = __p;
                    }
                    else {
                      uint64_t v44 = (void **)__p[0];
                    }
                    if (v106 >= 0) {
                      std::string::size_type v45 = HIBYTE(v106);
                    }
                    else {
                      std::string::size_type v45 = (std::string::size_type)__p[1];
                    }
                    long long v46 = std::string::append(&v110, (const std::string::value_type *)v44, v45);
                    long long v47 = (char *)v46->__r_.__value_.__r.__words[0];
                    *(void *)&long long v124 = v46->__r_.__value_.__l.__size_;
                    *(void *)((char *)&v124 + 7) = *(std::string::size_type *)((char *)&v46->__r_.__value_.__r.__words[1]
                                                                               + 7);
                    char v48 = HIBYTE(v46->__r_.__value_.__r.__words[2]);
                    v46->__r_.__value_.__l.__size_ = 0;
                    v46->__r_.__value_.__r.__words[2] = 0;
                    v46->__r_.__value_.__r.__words[0] = 0;
                    std::vector<std::string>::pointer end = v113.__end_;
                    if (v113.__end_ >= v113.__end_cap_.__value_)
                    {
                      unint64_t v51 = 0xAAAAAAAAAAAAAAABLL * (((char *)v113.__end_ - (char *)v113.__begin_) >> 3);
                      unint64_t v52 = v51 + 1;
                      if (v51 + 1 > 0xAAAAAAAAAAAAAAALL) {
                        std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
                      }
                      if (0x5555555555555556 * (((char *)v113.__end_cap_.__value_ - (char *)v113.__begin_) >> 3) > v52) {
                        unint64_t v52 = 0x5555555555555556 * (((char *)v113.__end_cap_.__value_ - (char *)v113.__begin_) >> 3);
                      }
                      if (0xAAAAAAAAAAAAAAABLL * (((char *)v113.__end_cap_.__value_ - (char *)v113.__begin_) >> 3) >= 0x555555555555555) {
                        unint64_t v53 = 0xAAAAAAAAAAAAAAALL;
                      }
                      else {
                        unint64_t v53 = v52;
                      }
                      __v.__end_cap_.__value_ = (std::allocator<std::string> *)&v113.__end_cap_;
                      if (v53) {
                        long long v54 = (std::string *)std::__allocate_at_least[abi:ne180100]<std::allocator<std::string>>((uint64_t)&v113.__end_cap_, v53);
                      }
                      else {
                        long long v54 = 0;
                      }
                      long long v55 = v54 + v51;
                      __v.__first_ = v54;
                      __v.__begin_ = v55;
                      __v.__end_cap_.__value_ = &v54[v53];
                      v55->__r_.__value_.__r.__words[0] = (std::string::size_type)v47;
                      v55->__r_.__value_.__l.__size_ = v124;
                      *(std::string::size_type *)((char *)&v55->__r_.__value_.__r.__words[1] + 7) = *(void *)((char *)&v124 + 7);
                      *((unsigned char *)&v55->__r_.__value_.__s + 23) = v48;
                      *(void *)&long long v124 = 0;
                      *(void *)((char *)&v124 + 7) = 0;
                      __v.__end_ = v55 + 1;
                      std::vector<std::string>::__swap_out_circular_buffer(&v113, &__v);
                      long long v50 = v113.__end_;
                      std::__split_buffer<std::string>::~__split_buffer(&__v);
                    }
                    else
                    {
                      v113.__end_->__r_.__value_.__l.__data_ = v47;
                      end->__r_.__value_.__l.__size_ = v124;
                      *(std::string::size_type *)((char *)&end->__r_.__value_.__r.__words[1] + 7) = *(void *)((char *)&v124 + 7);
                      *((unsigned char *)&end->__r_.__value_.__s + 23) = v48;
                      *(void *)&long long v124 = 0;
                      *(void *)((char *)&v124 + 7) = 0;
                      long long v50 = end + 1;
                    }
                    v113.__end_ = v50;
                    if (SHIBYTE(v106) < 0) {
                      operator delete(__p[0]);
                    }
                    if (SHIBYTE(v112.__r_.__value_.__r.__words[2]) < 0) {
                      operator delete(v112.__r_.__value_.__l.__data_);
                    }
                    if (SHIBYTE(v110.__r_.__value_.__r.__words[2]) < 0) {
                      operator delete(v110.__r_.__value_.__l.__data_);
                    }
                    if (SHIBYTE(v108.__r_.__value_.__r.__words[2]) < 0) {
                      operator delete(v108.__r_.__value_.__l.__data_);
                    }
                    if (SHIBYTE(v109.__r_.__value_.__r.__words[2]) < 0) {
                      operator delete(v109.__r_.__value_.__l.__data_);
                    }
                    if (SHIBYTE(v107.__r_.__value_.__r.__words[2]) < 0) {
                      operator delete(v107.__r_.__value_.__l.__data_);
                    }
                    if (++v31 == 4)
                    {
                      if ((std::vector<std::string>::pointer)((char *)v113.__end_ - (char *)v113.__begin_) == (std::vector<std::string>::pointer)96)
                      {
                        memset(&v112, 0, sizeof(v112));
                        if (a1[25])
                        {
                          for (int j = 0; j != 4; ++j)
                          {
                            uint64_t v57 = a1[25];
                            if (*(char *)(v57 + 47) >= 0) {
                              size_t v58 = *(unsigned __int8 *)(v57 + 47);
                            }
                            else {
                              size_t v58 = *(void *)(v57 + 32);
                            }
                            std::string::basic_string[abi:ne180100]((uint64_t)&v107, v58 + 7);
                            if ((v107.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
                              uint64_t v59 = &v107;
                            }
                            else {
                              uint64_t v59 = (std::string *)v107.__r_.__value_.__r.__words[0];
                            }
                            if (v58)
                            {
                              if (*(char *)(v57 + 47) >= 0) {
                                long long v60 = (const void *)(v57 + 24);
                              }
                              else {
                                long long v60 = *(const void **)(v57 + 24);
                              }
                              memmove(v59, v60, v58);
                            }
                            strcpy((char *)v59 + v58, "_split_");
                            std::to_string(&v109, j);
                            if ((v109.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
                              long long v61 = &v109;
                            }
                            else {
                              long long v61 = (std::string *)v109.__r_.__value_.__r.__words[0];
                            }
                            if ((v109.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
                              std::string::size_type v62 = HIBYTE(v109.__r_.__value_.__r.__words[2]);
                            }
                            else {
                              std::string::size_type v62 = v109.__r_.__value_.__l.__size_;
                            }
                            long long v63 = std::string::append(&v107, (const std::string::value_type *)v61, v62);
                            long long v64 = *(_OWORD *)&v63->__r_.__value_.__l.__data_;
                            v108.__r_.__value_.__r.__words[2] = v63->__r_.__value_.__r.__words[2];
                            *(_OWORD *)&v108.__r_.__value_.__l.__data_ = v64;
                            v63->__r_.__value_.__l.__size_ = 0;
                            v63->__r_.__value_.__r.__words[2] = 0;
                            v63->__r_.__value_.__r.__words[0] = 0;
                            long long v65 = std::string::append(&v108, "_", 1uLL);
                            long long v66 = *(_OWORD *)&v65->__r_.__value_.__l.__data_;
                            v110.__r_.__value_.__r.__words[2] = v65->__r_.__value_.__r.__words[2];
                            *(_OWORD *)&v110.__r_.__value_.__l.__data_ = v66;
                            v65->__r_.__value_.__l.__size_ = 0;
                            v65->__r_.__value_.__r.__words[2] = 0;
                            v65->__r_.__value_.__r.__words[0] = 0;
                            uint64_t v67 = (std::string *)std::string::basic_string[abi:ne180100]<0>(&v124, "c2s_comp");
                            unint64_t v68 = std::string::append(v67, "_xfm", 4uLL);
                            long long v69 = *(_OWORD *)&v68->__r_.__value_.__l.__data_;
                            int64_t v106 = v68->__r_.__value_.__r.__words[2];
                            *(_OWORD *)std::string __p = v69;
                            v68->__r_.__value_.__l.__size_ = 0;
                            v68->__r_.__value_.__r.__words[2] = 0;
                            v68->__r_.__value_.__r.__words[0] = 0;
                            if (v106 >= 0) {
                              uint64_t v70 = __p;
                            }
                            else {
                              uint64_t v70 = (void **)__p[0];
                            }
                            if (v106 >= 0) {
                              std::string::size_type v71 = HIBYTE(v106);
                            }
                            else {
                              std::string::size_type v71 = (std::string::size_type)__p[1];
                            }
                            __int16 v72 = std::string::append(&v110, (const std::string::value_type *)v70, v71);
                            std::string::size_type v73 = v72->__r_.__value_.__r.__words[0];
                            *(void *)&long long v122 = v72->__r_.__value_.__l.__size_;
                            *(void *)((char *)&v122 + 7) = *(std::string::size_type *)((char *)&v72->__r_.__value_.__r.__words[1]
                                                                                       + 7);
                            char v74 = HIBYTE(v72->__r_.__value_.__r.__words[2]);
                            v72->__r_.__value_.__l.__size_ = 0;
                            v72->__r_.__value_.__r.__words[2] = 0;
                            v72->__r_.__value_.__r.__words[0] = 0;
                            std::string::size_type v75 = v112.__r_.__value_.__l.__size_;
                            if (v112.__r_.__value_.__l.__size_ >= v112.__r_.__value_.__r.__words[2])
                            {
                              unint64_t v77 = 0xAAAAAAAAAAAAAAABLL
                                  * ((uint64_t)(v112.__r_.__value_.__l.__size_ - v112.__r_.__value_.__r.__words[0]) >> 3);
                              unint64_t v78 = v77 + 1;
                              if (v77 + 1 > 0xAAAAAAAAAAAAAAALL) {
                                std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
                              }
                              if (0x5555555555555556
                                 * ((uint64_t)(v112.__r_.__value_.__r.__words[2] - v112.__r_.__value_.__r.__words[0]) >> 3) > v78)
                                unint64_t v78 = 0x5555555555555556
                                    * ((uint64_t)(v112.__r_.__value_.__r.__words[2] - v112.__r_.__value_.__r.__words[0]) >> 3);
                              if (0xAAAAAAAAAAAAAAABLL
                                 * ((uint64_t)(v112.__r_.__value_.__r.__words[2] - v112.__r_.__value_.__r.__words[0]) >> 3) >= 0x555555555555555)
                                unint64_t v79 = 0xAAAAAAAAAAAAAAALL;
                              else {
                                unint64_t v79 = v78;
                              }
                              __v.__end_cap_.__value_ = (std::allocator<std::string> *)&v112.__r_.__value_.__r.__words[2];
                              if (v79) {
                                char v80 = (std::string *)std::__allocate_at_least[abi:ne180100]<std::allocator<std::string>>((uint64_t)&v112.__r_.__value_.__r.__words[2], v79);
                              }
                              else {
                                char v80 = 0;
                              }
                              int64x2_t v81 = v80 + v77;
                              __v.__first_ = v80;
                              __v.__begin_ = v81;
                              __v.__end_cap_.__value_ = &v80[v79];
                              v81->__r_.__value_.__r.__words[0] = v73;
                              v81->__r_.__value_.__l.__size_ = v122;
                              *(std::string::size_type *)((char *)&v81->__r_.__value_.__r.__words[1] + 7) = *(void *)((char *)&v122 + 7);
                              *((unsigned char *)&v81->__r_.__value_.__s + 23) = v74;
                              *(void *)&long long v122 = 0;
                              *(void *)((char *)&v122 + 7) = 0;
                              __v.__end_ = v81 + 1;
                              std::vector<std::string>::__swap_out_circular_buffer((std::vector<std::string> *)&v112, &__v);
                              std::string::size_type v76 = v112.__r_.__value_.__l.__size_;
                              std::__split_buffer<std::string>::~__split_buffer(&__v);
                            }
                            else
                            {
                              *(void *)v112.__r_.__value_.__l.__size_ = v73;
                              *(void *)(v75 + 8) = v122;
                              *(void *)(v75 + 15) = *(void *)((char *)&v122 + 7);
                              *(unsigned char *)(v75 + 23) = v74;
                              *(void *)&long long v122 = 0;
                              *(void *)((char *)&v122 + 7) = 0;
                              std::string::size_type v76 = v75 + 24;
                            }
                            v112.__r_.__value_.__l.__size_ = v76;
                            if (SHIBYTE(v106) < 0) {
                              operator delete(__p[0]);
                            }
                            if (SHIBYTE(v125[0]) < 0) {
                              operator delete((void *)v124);
                            }
                            if (SHIBYTE(v110.__r_.__value_.__r.__words[2]) < 0) {
                              operator delete(v110.__r_.__value_.__l.__data_);
                            }
                            if (SHIBYTE(v108.__r_.__value_.__r.__words[2]) < 0) {
                              operator delete(v108.__r_.__value_.__l.__data_);
                            }
                            if (SHIBYTE(v109.__r_.__value_.__r.__words[2]) < 0) {
                              operator delete(v109.__r_.__value_.__l.__data_);
                            }
                            if (SHIBYTE(v107.__r_.__value_.__r.__words[2]) < 0) {
                              operator delete(v107.__r_.__value_.__l.__data_);
                            }
                          }
                          if (v112.__r_.__value_.__l.__size_ - v112.__r_.__value_.__r.__words[0] != 96) {
                            ZinAssertImpl("Split name vector size must be same as split");
                          }
                        }
                        uint64_t v82 = v4[3];
                        if (v82 == v4[4])
                        {
                          long long v124 = 0uLL;
                          v125[0] = 0;
                          uint64_t v83 = v120 / v82;
                          if (v120 / v82 >= 1)
                          {
                            long long v84 = 0;
                            uint64_t v85 = 0;
                            do
                            {
                              if ((int)v82 < 1)
                              {
                                unint64_t v88 = v84;
                              }
                              else
                              {
                                uint64_t v86 = 0;
                                do
                                {
                                  uint64_t v87 = v85 + v83 * v86;
                                  if ((unint64_t)v84 >= v125[0])
                                  {
                                    char v89 = (void *)v124;
                                    uint64_t v90 = (uint64_t)((uint64_t)v84 - v124) >> 3;
                                    unint64_t v91 = v90 + 1;
                                    if ((unint64_t)(v90 + 1) >> 61) {
                                      std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
                                    }
                                    uint64_t v92 = v125[0] - v124;
                                    if ((uint64_t)(v125[0] - v124) >> 2 > v91) {
                                      unint64_t v91 = v92 >> 2;
                                    }
                                    if ((unint64_t)v92 >= 0x7FFFFFFFFFFFFFF8) {
                                      unint64_t v93 = 0x1FFFFFFFFFFFFFFFLL;
                                    }
                                    else {
                                      unint64_t v93 = v91;
                                    }
                                    if (v93)
                                    {
                                      long long v94 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)v125, v93);
                                      long long v84 = (void *)*((void *)&v124 + 1);
                                      char v89 = (void *)v124;
                                    }
                                    else
                                    {
                                      long long v94 = 0;
                                    }
                                    long long v95 = &v94[8 * v90];
                                    *(void *)long long v95 = v87;
                                    unint64_t v88 = v95 + 8;
                                    while (v84 != v89)
                                    {
                                      uint64_t v96 = *--v84;
                                      *((void *)v95 - 1) = v96;
                                      v95 -= 8;
                                    }
                                    *(void *)&long long v124 = v95;
                                    *((void *)&v124 + 1) = v88;
                                    v125[0] = &v94[8 * v93];
                                    if (v89) {
                                      operator delete(v89);
                                    }
                                  }
                                  else
                                  {
                                    *long long v84 = v87;
                                    unint64_t v88 = v84 + 1;
                                  }
                                  *((void *)&v124 + 1) = v88;
                                  ++v86;
                                  long long v84 = v88;
                                }
                                while (v86 != v82);
                              }
                              ++v85;
                              long long v84 = v88;
                            }
                            while (v85 != v83);
                          }
                          (*(void (**)(void, void, void))(*(void *)a1[24] + 32))(a1[24], 0, 0);
                          uint64_t v103 = a1[24];
                          long long v122 = 0uLL;
                          uint64_t v123 = 0;
                          long long v97 = *(void **)(v103 + 136);
                          long long v98 = *(_OWORD *)v114;
                          long long v111 = v98;
                          if (*((void *)&v98 + 1)) {
                            atomic_fetch_add_explicit((atomic_ullong *volatile)(*((void *)&v98 + 1) + 8), 1uLL, memory_order_relaxed);
                          }
                          std::vector<std::string>::pointer begin = v113.__begin_;
                          if ((v113.__begin_->__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
                            std::string::size_type v100 = HIBYTE(v113.__begin_->__r_.__value_.__r.__words[2]);
                          }
                          else {
                            std::string::size_type v100 = v113.__begin_->__r_.__value_.__l.__size_;
                          }
                          std::string::basic_string[abi:ne180100]((uint64_t)&__v, v100 + 7);
                          if (SHIBYTE(__v.__end_) >= 0) {
                            p_v = &__v;
                          }
                          else {
                            p_v = __v.__first_;
                          }
                          if (v100)
                          {
                            if ((begin->__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
                              std::vector<std::string>::pointer v102 = begin;
                            }
                            else {
                              std::vector<std::string>::pointer v102 = (std::vector<std::string>::pointer)begin->__r_.__value_.__r.__words[0];
                            }
                            memmove(p_v, v102, v100);
                          }
                          strcpy((char *)p_v + v100, "_kernel");
                          ZinIrContext::GetKernelSparsityCache(v104);
                          ZinIrKernel::Partial(v97, (uint64_t *)&v111, (uint64_t)&__v);
                        }
                        ZinAssertImpl("We only support 4x4x1");
                      }
                      ZinAssertImpl("Split name vector size must be same as split");
                    }
                  }
                }
                ZinAssertImpl("Split transforms vector size must be same as split");
              }
            }
          }
          ZinAssertImpl("Split cout offset vector size must be same as split");
        }
        ZinAssertImpl("Conv output channel must be divisible by split");
      }
      ZinAssertImpl("Factor of 4x4x1 is the only supported large factor");
    }
    ZinAssertImpl("C2S is required in a ZinChannelToSpaceLargeFactorCompositeLayer");
  }
  ZinAssertImpl("Conv is required in a ZinChannelToSpaceLargeFactorCompositeLayer");
}

void sub_2112B2DAC(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,void *a25,void *a26,uint64_t a27,uint64_t a28,void *a29,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33,uint64_t a34,uint64_t a35,void *a36,uint64_t a37,uint64_t a38,void *a39,uint64_t a40,uint64_t a41,uint64_t a42,void *a43,void *a44,uint64_t a45,uint64_t a46,uint64_t a47,uint64_t a48,void *a49,uint64_t a50,uint64_t a51,uint64_t a52,void *a53,uint64_t a54,uint64_t a55,uint64_t a56,uint64_t a57,uint64_t a58,uint64_t a59,uint64_t a60,uint64_t a61,void *__p,uint64_t a63)
{
  if (__p) {
    operator delete(__p);
  }
  long long v69 = *(void **)(v67 - 152);
  if (v69)
  {
    *(void *)(v67 - 144) = v69;
    operator delete(v69);
  }
  uint64_t v70 = *(void **)(v67 - 128);
  if (v70)
  {
    *(void *)(v67 - 120) = v70;
    operator delete(v70);
  }
  a67 = &STACK[0x218];
  std::vector<std::string>::__destroy_vector::operator()[abi:ne180100]((void ***)&a67);
  a67 = &STACK[0x230];
  std::vector<std::string>::__destroy_vector::operator()[abi:ne180100]((void ***)&a67);
  a67 = (void *)(v67 - 248);
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100]((void ***)&a67);
  std::string::size_type v71 = *(void **)(v67 - 224);
  if (v71)
  {
    *(void *)(v67 - 216) = v71;
    operator delete(v71);
  }
  _Unwind_Resume(a1);
}

uint64_t ZinChannelToSpaceLargeFactorCompositeLayer::MatchConv(uint64_t a1)
{
  if (*(_DWORD *)(*(void *)(*(void *)(a1 + 8) + 64) + 8)) {
    goto LABEL_14;
  }
  uint64_t v2 = *(void **)(a1 + 24);
  std::string::basic_string[abi:ne180100]<0>(__p, "c2s");
  uint64_t SingleMatch = ZinPattern::State::GetSingleMatch(v2, (unsigned __int8 *)__p);
  if (v12 < 0) {
    operator delete(__p[0]);
  }
  int v4 = *(ZinIrKernel ***)(a1 + 8);
  uint64_t v5 = v4[17];
  if (!ZinIrKernel::IsMutable(v5)
    && (int v6 = *(_DWORD *)((*((uint64_t (**)(ZinIrKernel **, void, void))*v4 + 4))(v4, 0, 0) + 88),
        uint64_t v7 = (*(uint64_t (**)(uint64_t, void, void))(*(void *)SingleMatch + 32))(SingleMatch, 0, 0),
        ZinQuantizationUtils::TensorFormatCompatible(v6, *(_DWORD *)(v7 + 88)))
    && *((_DWORD *)v5 + 85) == 1
    && *((_DWORD *)v5 + 86) == 1
    && *((_DWORD *)v5 + 87) == 1
    && *((_DWORD *)v5 + 82) == 1
    && *((_DWORD *)v5 + 83) == 1
    && *((_DWORD *)v5 + 84) == 1
    && *((void *)v5 + 50) < 2uLL
    && !ZinIrKernel::HasVectorPalettizedWeight(v4[17]))
  {
    LOBYTE(v8) = 1;
    int v9 = 1;
  }
  else
  {
LABEL_14:
    __int16 v8 = ZinPatternAtom::NoMatch((ZinPatternAtom *)1);
    int v9 = HIBYTE(v8);
  }
  return v8 | (v9 << 8);
}

void sub_2112B36D0(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11, int a12, __int16 a13, char a14, char a15)
{
  if (a15 < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinChannelToSpaceLargeFactorCompositeLayer::MatchGOC(uint64_t *a1)
{
  uint64_t v2 = (void *)a1[1];
  if (*(_DWORD *)(v2[8] + 8) != 2
    || (*(unsigned int (**)(void *))(*v2 + 120))(v2)
    || (uint64_t v3 = a1[1], ZinIrKernel::HasPerCoutScale(*(ZinIrKernel **)(v3 + 136))))
  {
    __int16 v4 = ZinPatternAtom::NoMatch((ZinPatternAtom *)1);
    unsigned __int8 v5 = v4;
    int v6 = HIBYTE(v4);
  }
  else
  {
    __int16 v8 = (void *)a1[3];
    std::string::basic_string[abi:ne180100]<0>(v24, "goc");
    ZinPattern::State::GetMatch(v8, (unsigned __int8 *)v24, &__p);
    ZinPatternUtils::ToGOC((uint64_t **)&__p, &v26);
    if (__p)
    {
      long long v22 = __p;
      operator delete(__p);
    }
    if (v25 < 0) {
      operator delete(v24[0]);
    }
    int v9 = v27;
    if ((unint64_t)v27 >= v28)
    {
      uint64_t v11 = v27 - v26;
      if ((unint64_t)(v11 + 1) >> 61) {
        std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
      }
      unint64_t v12 = (uint64_t)(v28 - (void)v26) >> 2;
      if (v12 <= v11 + 1) {
        unint64_t v12 = v11 + 1;
      }
      if (v28 - (unint64_t)v26 >= 0x7FFFFFFFFFFFFFF8) {
        unint64_t v13 = 0x1FFFFFFFFFFFFFFFLL;
      }
      else {
        unint64_t v13 = v12;
      }
      if (v13) {
        uint64_t v14 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)&v28, v13);
      }
      else {
        uint64_t v14 = 0;
      }
      unint64_t v15 = (uint64_t *)&v14[8 * v11];
      std::string v16 = &v14[8 * v13];
      *unint64_t v15 = v3;
      char v10 = v15 + 1;
      long long v18 = v26;
      long long v17 = v27;
      if (v27 != v26)
      {
        do
        {
          uint64_t v19 = *--v17;
          *--unint64_t v15 = v19;
        }
        while (v17 != v18);
        long long v17 = v26;
      }
      unint64_t v26 = v15;
      long long v27 = v10;
      unint64_t v28 = (unint64_t)v16;
      if (v17) {
        operator delete(v17);
      }
    }
    else
    {
      *long long v27 = v3;
      char v10 = v9 + 1;
    }
    long long v27 = v10;
    ZinObjectNameFactory::ZinObjectNameFactory(&__p, v3 + 24);
    if (ZinMergeGOCSequence(*a1, (uint64_t)&__p, (uint64_t)&v26))
    {
      unsigned __int8 v5 = 1;
      int v6 = 1;
    }
    else
    {
      __int16 v20 = ZinPatternAtom::NoMatch((ZinPatternAtom *)1);
      unsigned __int8 v5 = v20;
      int v6 = HIBYTE(v20);
    }
    std::string __p = &unk_26C34DA98;
    if (v23 < 0) {
      operator delete(v22);
    }
    if (v26)
    {
      long long v27 = v26;
      operator delete(v26);
    }
  }
  return v5 | (v6 << 8);
}

void sub_2112B3908(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, void *a11, uint64_t a12, int a13, __int16 a14, char a15, char a16, uint64_t a17, uint64_t a18, uint64_t a19, int a20,__int16 a21,char a22,char a23)
{
  char v25 = *(void **)(v23 - 56);
  if (v25)
  {
    *(void *)(v23 - 48) = v25;
    operator delete(v25);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinChannelToSpaceLargeFactorCompositeLayer::MatchQuant(uint64_t a1)
{
  return (*(_DWORD *)(*(void *)(*(void *)(a1 + 8) + 64) + 8) == 103) | 0x100u;
}

uint64_t ZinChannelToSpaceLargeFactorCompositeLayer::MatchDequant(uint64_t a1)
{
  return (*(_DWORD *)(*(void *)(*(void *)(a1 + 8) + 64) + 8) == 104) | 0x100u;
}

void ZinChannelToSpaceLargeFactorCompositeLayer::Clone()
{
}

uint64_t std::vector<std::shared_ptr<ZinIrTransformPartial>>::__swap_out_circular_buffer(uint64_t *a1, void *a2)
{
  uint64_t result = std::__uninitialized_allocator_move_if_noexcept[abi:ne180100]<std::allocator<std::shared_ptr<ZinIrTransformPartial>>,std::reverse_iterator<std::shared_ptr<ZinIrTransformPartial>*>,std::reverse_iterator<std::shared_ptr<ZinIrTransformPartial>*>,std::reverse_iterator<std::shared_ptr<ZinIrTransformPartial>*>>((uint64_t)(a1 + 2), a1[1], (void *)a1[1], *a1, (void *)*a1, a2[1], a2[1]);
  a2[1] = v5;
  uint64_t v6 = *a1;
  *a1 = v5;
  a2[1] = v6;
  uint64_t v7 = a1[1];
  a1[1] = a2[2];
  a2[2] = v7;
  uint64_t v8 = a1[2];
  a1[2] = a2[3];
  a2[3] = v8;
  *a2 = a2[1];
  return result;
}

uint64_t std::__uninitialized_allocator_move_if_noexcept[abi:ne180100]<std::allocator<std::shared_ptr<ZinIrTransformPartial>>,std::reverse_iterator<std::shared_ptr<ZinIrTransformPartial>*>,std::reverse_iterator<std::shared_ptr<ZinIrTransformPartial>*>,std::reverse_iterator<std::shared_ptr<ZinIrTransformPartial>*>>(uint64_t a1, uint64_t a2, void *a3, uint64_t a4, void *a5, uint64_t a6, uint64_t a7)
{
  uint64_t v7 = a7;
  *(void *)&long long v15 = a6;
  *((void *)&v15 + 1) = a7;
  long long v14 = v15;
  v12[0] = a1;
  v12[1] = &v14;
  unsigned int v12[2] = &v15;
  if (a3 == a5)
  {
    uint64_t v10 = a6;
  }
  else
  {
    uint64_t v8 = (_OWORD *)(a7 - 16);
    do
    {
      long long v9 = *((_OWORD *)a3 - 1);
      a3 -= 2;
      *uint64_t v8 = v9;
      *a3 = 0;
      a3[1] = 0;
      *((void *)&v15 + 1) = v8;
      v7 -= 16;
      --v8;
    }
    while (a3 != a5);
    uint64_t v10 = v15;
  }
  char v13 = 1;
  std::__exception_guard_exceptions<std::_AllocatorDestroyRangeReverse<std::allocator<std::shared_ptr<ZinIrTransformPartial>>,std::reverse_iterator<std::shared_ptr<ZinIrTransformPartial>*>>>::~__exception_guard_exceptions[abi:ne180100]((uint64_t)v12);
  return v10;
}

uint64_t std::__exception_guard_exceptions<std::_AllocatorDestroyRangeReverse<std::allocator<std::shared_ptr<ZinIrTransformPartial>>,std::reverse_iterator<std::shared_ptr<ZinIrTransformPartial>*>>>::~__exception_guard_exceptions[abi:ne180100](uint64_t a1)
{
  if (!*(unsigned char *)(a1 + 24)) {
    std::_AllocatorDestroyRangeReverse<std::allocator<std::shared_ptr<ZinIrConstData>>,std::reverse_iterator<std::shared_ptr<ZinIrConstData>*>>::operator()[abi:ne180100](a1);
  }
  return a1;
}

void *std::allocate_shared[abi:ne180100]<ZinIrTransformPartial,std::allocator<ZinIrTransformPartial>,long &,unsigned long &,ZinPartialTransformDimension,void>@<X0>(uint64_t *a1@<X1>, uint64_t *a2@<X2>, char *a3@<X3>, void *a4@<X8>)
{
  uint64_t v8 = operator new(0x40uLL);
  uint64_t result = std::__shared_ptr_emplace<ZinIrTransformPartial>::__shared_ptr_emplace[abi:ne180100]<unsigned long const&,unsigned long &,ZinPartialTransformDimension,std::allocator<ZinIrTransformPartial>,0>(v8, a1, a2, a3);
  *a4 = v8 + 3;
  a4[1] = v8;
  return result;
}

void sub_2112B3B7C(_Unwind_Exception *a1)
{
  operator delete(v1);
  _Unwind_Resume(a1);
}

void ZinPESecureFlushLayer::ZinPESecureFlushLayer()
{
}

void sub_2112B3CAC(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, std::__shared_weak_count *a6, ...)
{
  va_start(va, a6);
  if (a6) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a6);
  }
  ZinLayerNormLayer::ZinLayerNormLayer((uint64_t *)va);
  _Unwind_Resume(a1);
}

uint64_t ZinPESecureFlushLayer::Lower()
{
  return 3;
}

uint64_t ZinPESecureFlushLayer::Clone()
{
  return 0;
}

uint64_t ZinPESecureFlushLayer::GetLastEncapsulatedLayer(ZinPESecureFlushLayer *this)
{
  return 0;
}

void ZinPESecureFlushLayer::ExecutionOrderSort(void *a1@<X8>)
{
  *a1 = 0;
  a1[1] = 0;
  a1[2] = 0;
}

uint64_t ZinPESecureFlushLayer::HasBinaryTaskType(ZinPESecureFlushLayer *this)
{
  return *((unsigned __int8 *)this + 396);
}

uint64_t ZinPESecureFlushLayer::SpatialSplitCopy(ZinPESecureFlushLayer *this, const TiledLayerTensorRegions *a2)
{
  return 0;
}

uint64_t ZinPESecureFlushLayer::DebugDetailPrint@<X0>(void *a1@<X8>)
{
  std::basic_stringstream<char,std::char_traits<char>,std::allocator<char>>::basic_stringstream[abi:ne180100]((uint64_t)v5);
  std::stringbuf::str[abi:ne180100]<std::allocator<char>>((uint64_t)v6, a1);
  v5[0] = *MEMORY[0x263F8C2B8];
  uint64_t v3 = *(void *)(MEMORY[0x263F8C2B8] + 72);
  *(void *)((char *)v5 + *(void *)(v5[0] - 24)) = *(void *)(MEMORY[0x263F8C2B8] + 64);
  v5[2] = v3;
  v6[0] = MEMORY[0x263F8C318] + 16;
  if (v7 < 0) {
    operator delete((void *)v6[8]);
  }
  std::streambuf::~streambuf();
  std::iostream::~basic_iostream();
  return MEMORY[0x21667D2B0](&v8);
}

void sub_2112B3E80(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
}

int64x2_t ZinPESecureFlushLayer::GetProgrammedKernelSize@<Q0>(int64x2_t *a1@<X8>)
{
  int64x2_t result = vdupq_n_s64(1uLL);
  *a1 = result;
  a1[1].i64[0] = 1;
  return result;
}

uint64_t ZinPESecureFlushLayer::GetProgrammedInputStride(ZinPESecureFlushLayer *this)
{
  return 0x100000001;
}

void ZinPESecureFlushLayer::GetProgrammedPadding(void *a1@<X8>)
{
  *a1 = 0;
  a1[1] = 0;
  a1[2] = 0;
}

void ZinPESecureFlushLayer::GetProjectedCoreInputDims(ZinPESecureFlushLayer *this@<X0>, uint64_t a2@<X8>)
{
  ZinIrOpLayer::GetInputTensorDimensions(this, __p);
  uint64_t v3 = __p[0];
  long long v4 = *((_OWORD *)__p[0] + 1);
  *(_OWORD *)a2 = *(_OWORD *)__p[0];
  *(_OWORD *)(a2 + 16) = v4;
  *(void *)(a2 + std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = v3[4];
  __p[1] = v3;
  operator delete(v3);
}

uint64_t ZinPESecureFlushLayer::IsQualifiedForInPlace()
{
  return 0;
}

void ZinPESecureFlushLayer::~ZinPESecureFlushLayer(ZinEngineLayerMirInfo **this)
{
  ZinANELayer::~ZinANELayer(this);

  JUMPOUT(0x21667D3C0);
}

uint64_t EncryptedFile::EncryptedFile(uint64_t a1, long long *a2)
{
  *(_DWORD *)a1 = -1;
  uint64_t v3 = (std::string *)(a1 + 40);
  *(_OWORD *)(a1 + 8) = 0u;
  *(_OWORD *)(a1 + 24) = 0u;
  if (*((char *)a2 + 23) < 0)
  {
    std::string::__init_copy_ctor_external(v3, *(const std::string::value_type **)a2, *((void *)a2 + 1));
  }
  else
  {
    long long v4 = *a2;
    v3->__r_.__value_.__r.__words[2] = *((void *)a2 + 2);
    *(_OWORD *)&v3->__r_.__value_.__l.__data_ = v4;
  }
  return a1;
}

uint64_t EncryptedFile::LoadFile(EncryptedFile *this)
{
  if (*(_DWORD *)this != -1)
  {
    EncryptedFile::UnloadFile(this);
    exception = (std::runtime_error *)__cxa_allocate_exception(0x10uLL);
    std::runtime_error::runtime_error(exception, "File is already opened.");
    goto LABEL_35;
  }
  uint64_t v2 = (char *)this + 40;
  if (*((char *)this + 63) < 0) {
    uint64_t v2 = *(const char **)v2;
  }
  int v3 = open(v2, 0);
  *(_DWORD *)this = v3;
  if (v3 == -1)
  {
    exception = (std::runtime_error *)__cxa_allocate_exception(0x10uLL);
    std::runtime_error::runtime_error(exception, "File cannot be opened.");
    goto LABEL_35;
  }
  v28.st_std::string::size_type size = 0;
  if (fstat(v3, &v28) == -1)
  {
    EncryptedFile::UnloadFile(this);
    char v13 = __cxa_allocate_exception(0x10uLL);
    long long v14 = __error();
    std::to_string(&v26, *v14);
    __n128 v15 = std::operator+[abi:ne180100]<char,std::char_traits<char>,std::allocator<char>>("Cannot be fstat'd with error code: ", &v26, &v27);
    MEMORY[0x21667CC30](v13, &v27, v15);
    __cxa_throw(v13, MEMORY[0x263F8C1F0], MEMORY[0x263F8C070]);
  }
  st_std::string::size_type size = v28.st_size;
  *((void *)this + 2) = v28.st_size;
  if (st_size <= 0x40)
  {
    EncryptedFile::UnloadFile(this);
    exception = (std::runtime_error *)__cxa_allocate_exception(0x10uLL);
    std::runtime_error::runtime_error(exception, "Does not contain encrypted model header. Is the file encrypted?");
    goto LABEL_35;
  }
  if ((v28.st_mode & 0xF000) != 0x8000)
  {
    EncryptedFile::UnloadFile(this);
    exception = (std::runtime_error *)__cxa_allocate_exception(0x10uLL);
    std::runtime_error::runtime_error(exception, "File must be a regular file.");
    goto LABEL_35;
  }
  uint64_t v5 = (unsigned __int8 *)mmap(0, st_size, 1, 2, *(_DWORD *)this, 0);
  *((void *)this + 1) = v5;
  if (v5 == (unsigned __int8 *)-1)
  {
    EncryptedFile::UnloadFile(this);
    std::string v16 = __cxa_allocate_exception(0x10uLL);
    long long v17 = __error();
    std::to_string(&v26, *v17);
    __n128 v18 = std::operator+[abi:ne180100]<char,std::char_traits<char>,std::allocator<char>>("Cannot be loaded, with error code: ", &v26, &v27);
    MEMORY[0x21667CC30](v16, &v27, v18);
    __cxa_throw(v16, MEMORY[0x263F8C1F0], MEMORY[0x263F8C070]);
  }
  if (*(_DWORD *)v5 != 1162759500)
  {
    EncryptedFile::UnloadFile(this);
    exception = (std::runtime_error *)__cxa_allocate_exception(0x10uLL);
    std::runtime_error::runtime_error(exception, "Unrecognized magic word in the encrypted model header. Is the file encrypted?");
    goto LABEL_35;
  }
  if (!v5[4] || v5[4] >= 3u)
  {
    EncryptedFile::UnloadFile(this);
    exception = (std::runtime_error *)__cxa_allocate_exception(0x10uLL);
    std::runtime_error::runtime_error(exception, "Unrecognized encryption version");
    goto LABEL_35;
  }
  if (v5[4] == 1) {
    unsigned int v6 = 64;
  }
  else {
    unsigned int v6 = v5[7];
  }
  unint64_t v7 = v6;
  unint64_t v8 = *((void *)this + 2);
  if (v8 <= v6)
  {
    EncryptedFile::UnloadFile(this);
    uint64_t v19 = __cxa_allocate_exception(0x10uLL);
    std::to_string(&v26, v7);
    __n128 v20 = std::operator+[abi:ne180100]<char,std::char_traits<char>,std::allocator<char>>("File does not contain any payload, size_of_header = ", &v26, &v27);
    MEMORY[0x21667CC30](v19, &v27, v20);
    __cxa_throw(v19, MEMORY[0x263F8C1F0], MEMORY[0x263F8C070]);
  }
  unint64_t v9 = *((void *)v5 + 1);
  if (v9 - 1 >= v8 - v6)
  {
    EncryptedFile::UnloadFile(this);
    uint64_t v21 = __cxa_allocate_exception(0x10uLL);
    std::to_string(&v26, v9);
    __n128 v22 = std::operator+[abi:ne180100]<char,std::char_traits<char>,std::allocator<char>>("Illegal value for original file size = ", &v26, &v27);
    MEMORY[0x21667CC30](v21, &v27, v22);
    __cxa_throw(v21, MEMORY[0x263F8C1F0], MEMORY[0x263F8C070]);
  }
  if (*((void *)v5 + 2))
  {
    unint64_t v10 = *((void *)v5 + 2);
    if (v10 >> 52)
    {
      EncryptedFile::UnloadFile(this);
      exception = (std::runtime_error *)__cxa_allocate_exception(0x10uLL);
      std::runtime_error::runtime_error(exception, "Illegal value for number of encrypted pages");
    }
    else
    {
      if (v10 << 12 <= v8)
      {
        if (mremap_encrypted())
        {
          EncryptedFile::UnloadFile(this);
          uint64_t v23 = __cxa_allocate_exception(0x10uLL);
          unint64_t v24 = __error();
          std::to_string(&v26, *v24);
          __n128 v25 = std::operator+[abi:ne180100]<char,std::char_traits<char>,std::allocator<char>>("Failed to setup decryption path due to error: ", &v26, &v27);
          MEMORY[0x21667CC30](v23, &v27, v25);
          __cxa_throw(v23, MEMORY[0x263F8C1F0], MEMORY[0x263F8C070]);
        }
        uint64_t v5 = (unsigned __int8 *)*((void *)this + 1);
        goto LABEL_22;
      }
      EncryptedFile::UnloadFile(this);
      exception = (std::runtime_error *)__cxa_allocate_exception(0x10uLL);
      std::runtime_error::runtime_error(exception, "Illegal number of encrypted bytes");
    }
LABEL_35:
    __cxa_throw(exception, MEMORY[0x263F8C1F0], MEMORY[0x263F8C070]);
  }
LABEL_22:
  *((void *)this + 3) = &v5[v7];
  *((void *)this + 4) = v9;
  return close(*(_DWORD *)this);
}

void sub_2112B446C(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, void *a9, uint64_t a10, int a11, __int16 a12, char a13, char a14, void *__p, uint64_t a16, int a17, __int16 a18, char a19, char a20)
{
  if (a20 < 0) {
    operator delete(__p);
  }
  if (a14 < 0) {
    operator delete(a9);
  }
  if (v21) {
    __cxa_free_exception(v20);
  }
  _Unwind_Resume(exception_object);
}

double EncryptedFile::UnloadFile(EncryptedFile *this)
{
  int v3 = (_OWORD *)((char *)this + 8);
  uint64_t v2 = (void *)*((void *)this + 1);
  if (v2) {
    munmap(v2, *((void *)this + 2));
  }
  if (*(_DWORD *)this != -1) {
    close(*(_DWORD *)this);
  }
  *(_DWORD *)this = -1;
  double result = 0.0;
  *int v3 = 0u;
  v3[1] = 0u;
  return result;
}

uint64_t ZinMirTensorTransform::FixAllocation(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t *a4, int a5, unint64_t a6, char a7)
{
  int v10 = a3;
  int IsCompatibleWithAllocationHint = ZinIrTensor::IsCompatibleWithAllocationHint((ZinIrTensor *)a1, a3);
  uint64_t v14 = *(void *)(a1 + 96);
  if (IsCompatibleWithAllocationHint)
  {
    int v15 = ZinIrTensor::SetAllocationHint((ZinIrTensor *)a1, v10, 1);
    Copyuint64_t Layer = 0;
    long long v17 = (ZinIrTensor *)a1;
  }
  else
  {
    uint64_t v18 = *(void *)(v14 + 16);
    uint64_t v19 = *(unsigned int *)(a1 + 88);
    v37[0] = 0;
    Copyuint64_t Layer = ZinBuilder::CreateCopyLayer(v18, v14, a2, v19, v37);
    __n128 v20 = (void *)v37[0];
    v37[0] = 0;
    if (v20) {
      std::default_delete<ZinIrTensor::MirInfo>::operator()[abi:ne180100]((uint64_t)v37, v20);
    }
    long long v17 = (ZinIrTensor *)(*(uint64_t (**)(uint64_t, void, void))(*(void *)CopyLayer + 32))(CopyLayer, 0, 0);
    int v15 = ZinIrTensor::SetAllocationHint(v17, v10, 1);
  }
  BOOL v21 = v10 == 2 && !ZinIrTensor::IsValidInterleave(v17, a6, a7);
  uint64_t Interleave = ZinIrTensor::GetInterleave(v17);
  BOOL v24 = HasInterleaveMismatch(Interleave, v23, a6, a7);
  if (v21 || v24)
  {
    uint64_t v25 = *(void *)(v14 + 16);
    uint64_t v26 = *(unsigned int *)(a1 + 88);
    uint64_t v36 = 0;
    Copyuint64_t Layer = ZinBuilder::CreateCopyLayer(v25, v14, a2, v26, (uint64_t *)&v36);
    std::string v27 = v36;
    uint64_t v36 = 0;
    if (v27) {
      std::default_delete<ZinIrTensor::MirInfo>::operator()[abi:ne180100]((uint64_t)&v36, v27);
    }
    long long v17 = (ZinIrTensor *)(*(uint64_t (**)(uint64_t, void, void))(*(void *)CopyLayer + 32))(CopyLayer, 0, 0);
  }
  int v28 = ZinIrTensor::SetInterleave(v17, a6, a7, 1);
  if (!a5 && CopyLayer)
  {
    uint64_t v29 = *(void *)(v14 + 16);
    uint64_t v30 = *(unsigned int *)((*(uint64_t (**)(uint64_t, void, void))(*(void *)CopyLayer + 32))(CopyLayer, 0, 0)+ 88);
    uint64_t v31 = (*(uint64_t (**)(uint64_t, void, void))(*(void *)CopyLayer + 32))(CopyLayer, 0, 0);
    ZinIrTensor::CopyTensorMirInfo(v31, &v35);
    v34[0] = 0;
    v34[168] = 0;
    ZinBuilder::CreateNEBypass(v29, a2, v14, v30, &v35, 0, (uint64_t)v34, 1.0);
  }
  *a4 = CopyLayer;
  if (v28 | v15) {
    return 3;
  }
  else {
    return 0;
  }
}

void sub_2112B4818(_Unwind_Exception *exception_object)
{
  int v3 = *(void **)(v1 - 112);
  *(void *)(v1 - 112) = 0;
  if (v3) {
    std::default_delete<ZinIrTensor::MirInfo>::operator()[abi:ne180100](v1 - 112, v3);
  }
  _Unwind_Resume(exception_object);
}

ZinIrOpLayer *ZinMirTensorTransform::InsertCopyBetween(uint64_t **a1, ZinIrOpLayer *a2, ZinIrOpLayer *a3, uint64_t a4, int a5)
{
  int64x2_t v27[2] = *MEMORY[0x263EF8340];
  uint64_t v10 = *((void *)a2 + 2);
  uint64_t v11 = *(unsigned int *)((*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)a2 + 32))(a2, 0, 0)+ 88);
  uint64_t v25 = 0;
  Copyuint64_t Layer = (ZinIrOpLayer *)ZinBuilder::CreateCopyLayer(v10, (uint64_t)a2, a4, v11, (uint64_t *)&v25);
  char v13 = v25;
  uint64_t v25 = 0;
  if (v13) {
    std::default_delete<ZinIrTensor::MirInfo>::operator()[abi:ne180100]((uint64_t)&v25, v13);
  }
  v27[0] = a2;
  uint64_t v19 = v27;
  *(void *)&long long v20 = 1;
  Layer2TDMapper::SourceLayer::SourceLayer(&v22, &v19);
  if ((*(_DWORD *)(*((void *)a2 + 8) + 8) & 0xFFFFFFFC) == 0x1C)
  {
    uint64_t v26 = a3;
    v27[0] = &v26;
    v27[1] = 1;
    Layer2TDMapper::SourceLayer::SourceLayer(&v19, v27);
    if ((void)v23)
    {
      *((void *)&v23 + 1) = v23;
      operator delete((void *)v23);
    }
    long long v23 = v20;
    uint64_t v24 = v21;
  }
  if (a5)
  {
    uint64_t v14 = *(unsigned int *)((*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)CopyLayer + 32))(CopyLayer, 0, 0)+ 88);
    uint64_t v18 = 0;
    v17[0] = 0;
    v17[168] = 0;
    ZinBuilder::CreateNEBypass(v10, a4, (uint64_t)a2, v14, &v18, 0, (uint64_t)v17, 1.0);
  }
  if ((ZinIrOpLayerGraph::InsertNodeBetween(a1, CopyLayer, a2, a3, &v22) & 1) == 0)
  {
    std::string v16 = (char *)a2 + 24;
    if (*((char *)a2 + 47) < 0) {
      std::string v16 = *(const char **)v16;
    }
    ZinAssertImpl("Dim order propagation fails in %s", v16);
  }
  __n128 v22 = (ZinIrOpLayer **)&unk_26C359A08;
  if ((void)v23)
  {
    *((void *)&v23 + 1) = v23;
    operator delete((void *)v23);
  }
  return CopyLayer;
}

void sub_2112B4AB8(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,char a33)
{
  uint64_t v35 = *(void **)v33;
  *(void *)uint64_t v33 = 0;
  if (v35) {
    std::default_delete<ZinIrTensor::MirInfo>::operator()[abi:ne180100]((uint64_t)&a33, v35);
  }
  *(void *)(v33 + 40) = &unk_26C359A08;
  uint64_t v36 = *(void **)(v33 + 48);
  if (v36)
  {
    *(void *)(v33 + 56) = v36;
    operator delete(v36);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinMirTensorTransform::ReconcileInputTensorFormat(uint64_t **a1, ZinIrOpLayer *a2, uint64_t a3, uint64_t a4)
{
  uint64_t v59 = *MEMORY[0x263EF8340];
  long long v55 = 0;
  long long v56 = 0;
  uint64_t v57 = 0;
  std::vector<unsigned long>::reserve((void **)&v55, (uint64_t)(*((void *)a2 + 12) - *((void *)a2 + 11)) >> 3);
  uint64_t v7 = *((void *)a2 + 11);
  if (*((void *)a2 + 12) != v7)
  {
    unint64_t v8 = 0;
    do
    {
      if (*(_DWORD *)((*(uint64_t (**)(void, void, void))(**(void **)(v7 + 8 * v8) + 32))(*(void *)(v7 + 8 * v8), 0, 0)+ 88) != a4)
      {
        unint64_t v9 = v56;
        if (v56 >= v57)
        {
          uint64_t v11 = v55;
          uint64_t v12 = v56 - v55;
          unint64_t v13 = v12 + 1;
          if ((unint64_t)(v12 + 1) >> 61) {
            std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
          }
          uint64_t v14 = (char *)v57 - (char *)v55;
          if (((char *)v57 - (char *)v55) >> 2 > v13) {
            unint64_t v13 = v14 >> 2;
          }
          if ((unint64_t)v14 >= 0x7FFFFFFFFFFFFFF8) {
            unint64_t v15 = 0x1FFFFFFFFFFFFFFFLL;
          }
          else {
            unint64_t v15 = v13;
          }
          if (v15)
          {
            std::string v16 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)&v57, v15);
            uint64_t v11 = v55;
            unint64_t v9 = v56;
          }
          else
          {
            std::string v16 = 0;
          }
          long long v17 = (unint64_t *)&v16[8 * v12];
          unint64_t *v17 = v8;
          uint64_t v10 = v17 + 1;
          while (v9 != v11)
          {
            unint64_t v18 = *--v9;
            *--long long v17 = v18;
          }
          long long v55 = v17;
          long long v56 = v10;
          uint64_t v57 = (unint64_t *)&v16[8 * v15];
          if (v11) {
            operator delete(v11);
          }
        }
        else
        {
          unint64_t *v56 = v8;
          uint64_t v10 = v9 + 1;
        }
        long long v56 = v10;
      }
      ++v8;
      uint64_t v7 = *((void *)a2 + 11);
    }
    while (v8 < (*((void *)a2 + 12) - v7) >> 3);
  }
  long long v20 = v55;
  uint64_t v19 = v56;
  if (v56 != v55)
  {
    do
    {
      unint64_t v21 = *v20;
      uint64_t v22 = *((void *)a2 + 11);
      long long v23 = *(ZinIrOpLayer **)(v22 + 8 * *v20);
      if ((*(_DWORD *)(*((void *)v23 + 8) + 8) - 28) >= 3
        && *((void *)v23 + 15) - *((void *)v23 + 14) <= 8uLL)
      {
        BOOL IsANELayer = ZinIrOpLayer::IsANELayer(v23);
        uint64_t v25 = *(void **)(v22 + 8 * v21);
        if (!IsANELayer || !v25[33])
        {
          uint64_t v32 = (uint64_t *)(*(uint64_t (**)(void *, void, void))(*v25 + 40))(v25, 0, 0);
          uint64_t v34 = *v32;
          uint64_t v33 = v32[1];
          if (v33) {
            atomic_fetch_add_explicit((atomic_ullong *volatile)(v33 + 8), 1uLL, memory_order_relaxed);
          }
          (*(void (**)(std::string *__return_ptr))(*(void *)a3 + 16))(&v58);
          int v35 = *(char *)(v34 + 47);
          if (v35 >= 0) {
            uint64_t v36 = (const std::string::value_type *)(v34 + 24);
          }
          else {
            uint64_t v36 = *(const std::string::value_type **)(v34 + 24);
          }
          if (v35 >= 0) {
            std::string::size_type v37 = *(unsigned __int8 *)(v34 + 47);
          }
          else {
            std::string::size_type v37 = *(void *)(v34 + 32);
          }
          long long v38 = std::string::insert(&v58, 0, v36, v37);
          long long v39 = *(_OWORD *)&v38->__r_.__value_.__l.__data_;
          std::string::size_type v51 = v38->__r_.__value_.__r.__words[2];
          *(_OWORD *)long long v50 = v39;
          v38->__r_.__value_.__l.__size_ = 0;
          v38->__r_.__value_.__r.__words[2] = 0;
          v38->__r_.__value_.__r.__words[0] = 0;
          ZinIrTensor::CopyTensorMirInfo(v34, &v49);
          uint64_t v47 = 0;
          uint64_t v48 = 0;
          LODWORD(v42) = 0;
          uint64_t v44 = 0;
          uint64_t v45 = 0;
          std::string __p = 0;
          int v46 = 0;
          ZinIrTensor::CreateTensor();
        }
      }
      BOOL v26 = ZinIrOpLayer::IsANELayer(a2);
      uint64_t v27 = *(void *)(v22 + 8 * v21);
      uint64_t v28 = *(void *)(v27 + 16);
      if (v26)
      {
        uint64_t v54 = 0;
        v53[0] = 0;
        v53[168] = 0;
        ZinBuilder::CreateNEBypass(v28, a3, v27, a4, &v54, 0, (uint64_t)v53, 1.0);
      }
      unint64_t v52 = 0;
      Copyuint64_t Layer = (ZinIrOpLayer *)ZinBuilder::CreateCopyLayer(v28, v27, a3, a4, (uint64_t *)&v52);
      uint64_t v30 = v52;
      unint64_t v52 = 0;
      if (v30) {
        std::default_delete<ZinIrTensor::MirInfo>::operator()[abi:ne180100]((uint64_t)&v52, v30);
      }
      v58.__r_.__value_.__r.__words[0] = (std::string::size_type)a2;
      v50[0] = &v58;
      v50[1] = (void *)1;
      Layer2TDMapper::SourceLayer::SourceLayer(&v42, v50);
      ZinIrOpLayerGraph::AddNode(a1, CopyLayer, &v42);
      long long v42 = (ZinIrOpLayer **)&unk_26C359A08;
      if (__p)
      {
        uint64_t v44 = __p;
        operator delete(__p);
      }
      ZinIrOpLayerGraph::AddEdge((uint64_t)a1, *(void *)(v22 + 8 * v21), (uint64_t)CopyLayer, 0xFFFFFFFFFFFFFFFFLL, 0xFFFFFFFFFFFFFFFFLL, 0);
      IndexOfMatchedIncominguint64_t Layer = ZinIrOpLayerGraph::GetIndexOfMatchedIncomingLayer((ZinIrOpLayerGraph *)a1, a2, *(const ZinIrOpLayer **)(v22 + 8 * v21));
      ZinIrOpLayerGraph::SwapEdgeSource((uint64_t)a1, *(ZinIrOpLayerGraph **)(v22 + 8 * v21), CopyLayer, (uint64_t)a2, 0xFFFFFFFFFFFFFFFFLL, IndexOfMatchedIncomingLayer, 0xFFFFFFFFFFFFFFFFLL, 0xFFFFFFFFFFFFFFFFLL, 0, 0);
      ++v20;
    }
    while (v20 != v19);
    uint64_t v19 = v55;
  }
  if (v19)
  {
    long long v56 = v19;
    operator delete(v19);
  }
  return 0;
}

void sub_2112B5068(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, void *a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,void *__p,uint64_t a24,int a25,__int16 a26,char a27,char a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32)
{
  uint64_t v34 = *(void **)(v32 - 144);
  if (v34)
  {
    *(void *)(v32 - 136) = v34;
    operator delete(v34);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinMirTensorTransform::ChannelVectorInsertPaddingInL2(uint64_t **this, ZinIrOpLayerGraph *a2, unint64_t a3, unint64_t a4, uint64_t a5, ZinObjectNameFactory *a6)
{
  uint64_t v35 = *MEMORY[0x263EF8340];
  if (a2)
  {
    unint64_t v8 = a2;
    uint64_t v10 = (*(uint64_t (**)(ZinIrOpLayerGraph *, void, void))(*(void *)a2 + 32))(a2, 0, 0);
    if (*(void *)(v10 + 72) == 1)
    {
      uint64_t v11 = (void *)v10;
      uint64_t v30 = 0;
      uint64_t v12 = (*(uint64_t (**)(ZinIrOpLayerGraph *, void, void))(*(void *)v8 + 32))(v8, 0, 0);
      ZinMirTensorTransform::FixAllocation(v12, a5, 1, (uint64_t *)&v30, 1, 0, 0);
      unint64_t v13 = v30;
      if (v30)
      {
        v34[0].i64[0] = (uint64_t)v8;
        uint64_t v26 = (uint64_t)v34;
        unint64_t v27 = 1;
        Layer2TDMapper::SourceLayer::SourceLayer(&v31, &v26);
        ZinIrOpLayerGraph::AddNode(this, v13, &v31);
        uint64_t v31 = (ZinIrOpLayer **)&unk_26C359A08;
        if (__p)
        {
          uint64_t v33 = __p;
          operator delete(__p);
        }
        ZinIrOpLayerGraph::AddEdge((uint64_t)this, (uint64_t)v8, (uint64_t)v13, 0xFFFFFFFFFFFFFFFFLL, 0xFFFFFFFFFFFFFFFFLL, 0);
        unint64_t v8 = v13;
      }
      unint64_t v14 = v11[10] * v11[6] * v11[7] * v11[8] * v11[9] / a3;
      unint64_t v27 = a3;
      unint64_t v28 = v14;
      uint64_t v26 = 1;
      int64x2_t v29 = vdupq_n_s64(1uLL);
      DimensionOrderHint::DimensionOrderHint(&v25, 1);
      uint64_t v15 = (*(uint64_t (**)(ZinIrOpLayerGraph *, void, void))(*(void *)v8 + 32))(v8, 0, 0);
      ZinIrTensor::CreateDefaultStride((const ZinTensorDimensions *)&v26, *(_DWORD *)(v15 + 88), 1, (uint64_t)&v25, 16, 1, 1, v34);
      operator new();
    }
    BOOL v16 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (v16) {
      goto LABEL_11;
    }
  }
  else
  {
    BOOL v16 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (v16) {
LABEL_11:
    }
      ZinMirTensorTransform::ChannelVectorInsertPaddingInL2(v16, v17, v18, v19, v20, v21, v22, v23);
  }
  return 0;
}

void sub_2112B5910(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, void *a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,void *a32,uint64_t a33,uint64_t a34,uint64_t a35,void *__p,uint64_t a37)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

void ZinMirTensorTransform::Split(uint64_t a1@<X1>, int64_t a2@<X2>, int a3@<W3>, uint64_t a4@<X4>, void **a5@<X8>)
{
  uint64_t v48 = *MEMORY[0x263EF8340];
  if (a1)
  {
    *a5 = 0;
    a5[1] = 0;
    a5[2] = 0;
    uint64_t v36 = (*(uint64_t (**)(uint64_t, void, void))(*(void *)a1 + 32))(a1, 0, 0);
    switch(a3)
    {
      case 0:
        uint64_t v7 = (uint64_t *)(v36 + 48);
        break;
      case 1:
        uint64_t v7 = (uint64_t *)(v36 + 56);
        break;
      case 2:
        uint64_t v7 = (uint64_t *)(v36 + 64);
        break;
      case 3:
        uint64_t v7 = (uint64_t *)(v36 + 72);
        break;
      default:
        uint64_t v7 = (uint64_t *)(v36 + 80);
        break;
    }
    if (*v7 <= (unint64_t)a2)
    {
      unint64_t v23 = (unint64_t)a5[2];
      uint64_t v24 = a5[1];
      if ((unint64_t)v24 >= v23)
      {
        uint64_t v26 = ((char *)v24 - (unsigned char *)*a5) >> 3;
        if ((unint64_t)(v26 + 1) >> 61) {
          std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
        }
        uint64_t v27 = v23 - (void)*a5;
        uint64_t v28 = v27 >> 2;
        if (v27 >> 2 <= (unint64_t)(v26 + 1)) {
          uint64_t v28 = v26 + 1;
        }
        if ((unint64_t)v27 >= 0x7FFFFFFFFFFFFFF8) {
          unint64_t v29 = 0x1FFFFFFFFFFFFFFFLL;
        }
        else {
          unint64_t v29 = v28;
        }
        if (v29) {
          uint64_t v30 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)(a5 + 2), v29);
        }
        else {
          uint64_t v30 = 0;
        }
        uint64_t v31 = &v30[8 * v26];
        uint64_t v32 = &v30[8 * v29];
        *(void *)uint64_t v31 = a1;
        uint64_t v25 = v31 + 8;
        uint64_t v34 = (char *)*a5;
        uint64_t v33 = (char *)a5[1];
        if (v33 != *a5)
        {
          do
          {
            uint64_t v35 = *((void *)v33 - 1);
            v33 -= 8;
            *((void *)v31 - 1) = v35;
            v31 -= 8;
          }
          while (v33 != v34);
          uint64_t v33 = (char *)*a5;
        }
        *a5 = v31;
        a5[1] = v25;
        a5[2] = v32;
        if (v33) {
          operator delete(v33);
        }
      }
      else
      {
        *uint64_t v24 = a1;
        uint64_t v25 = v24 + 1;
      }
      a5[1] = v25;
    }
    else if (*v7 >= 1)
    {
      BOOL v16 = (int64_t *)(v36 + 48);
      int64x2_t v37 = vdupq_n_s64(1uLL);
      long long v17 = *(_OWORD *)(v36 + 64);
      long long v45 = *(_OWORD *)(v36 + 48);
      long long v46 = v17;
      int64_t v47 = *(void *)(v36 + 80);
      switch(a3)
      {
        case 0:
          int64_t v18 = a2;
          if (a2 >= *v16) {
            int64_t v18 = *v16;
          }
          *(void *)&long long v45 = v18;
          break;
        case 1:
          int64_t v22 = a2;
          if (a2 >= *(void *)(v36 + 56)) {
            int64_t v22 = *(void *)(v36 + 56);
          }
          *((void *)&v45 + 1) = v22;
          break;
        case 2:
          int64_t v20 = a2;
          if (a2 >= *(void *)(v36 + 64)) {
            int64_t v20 = *(void *)(v36 + 64);
          }
          *(void *)&long long v46 = v20;
          break;
        case 3:
          int64_t v21 = a2;
          if (a2 >= *(void *)(v36 + 72)) {
            int64_t v21 = *(void *)(v36 + 72);
          }
          *((void *)&v46 + 1) = v21;
          break;
        case 4:
          int64_t v19 = a2;
          if (a2 >= *(void *)(v36 + 80)) {
            int64_t v19 = *(void *)(v36 + 80);
          }
          int64_t v47 = v19;
          break;
        default:
          break;
      }
      (*(void (**)(void **__return_ptr))(*(void *)a4 + 16))(__p);
      (*(void (**)(uint64_t, void, void))(*(void *)a1 + 32))(a1, 0, 0);
      memset(&__p[4], 0, 40);
      int64x2_t v42 = v37;
      int64x2_t v43 = v37;
      uint64_t v44 = 1;
      ZinBuilder::CreateView();
    }
  }
  else
  {
    BOOL v8 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (v8) {
      ZinMirTensorTransform::Split(v8, v9, v10, v11, v12, v13, v14, v15);
    }
    *a5 = 0;
    a5[1] = 0;
    a5[2] = 0;
  }
}

void sub_2112B6080(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,void *__p,uint64_t a25)
{
}

ZinIrOpLayerGraph *ZinMirTensorTransform::NonResidentLinearizeToChannelInL2(uint64_t **this, ZinIrOpLayerGraph *a2, ZinIrOpLayer *a3, ZinObjectNameFactory *a4)
{
  v60[4] = *MEMORY[0x263EF8340];
  if (!a2)
  {
    BOOL v22 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (v22) {
      ZinMirTensorTransform::NonResidentLinearizeToChannelInL2(v22, v23, v24, v25, v26, v27, v28, v29);
    }
    return 0;
  }
  uint64_t v5 = a2;
  uint64_t v7 = (*(uint64_t (**)(ZinIrOpLayerGraph *, void, void, ZinObjectNameFactory *))(*(void *)a2 + 32))(a2, 0, 0, a4);
  __p[0] = 0;
  __p[1] = 0;
  *(void *)&long long v58 = 0;
  if (!ZinIrOpLayer::IsNoOp(v5, (uint64_t *)__p))
  {
    if (__p[0])
    {
      __p[1] = __p[0];
      operator delete(__p[0]);
    }
    goto LABEL_17;
  }
  int v8 = *(_DWORD *)(*((void *)v5 + 8) + 8);
  if (__p[0])
  {
    __p[1] = __p[0];
    operator delete(__p[0]);
  }
  if (v8 != 37)
  {
LABEL_17:
    v59[0].i64[0] = 0;
    ZinMirTensorTransform::FixAllocation(v7, (uint64_t)a3, 2, v59[0].i64, 1, 1uLL, 1);
    uint64_t v30 = (ZinIrOpLayer *)v59[0].i64[0];
    if (v59[0].i64[0])
    {
      v60[0] = v5;
      uint64_t v51 = (uint64_t)v60;
      uint64_t v52 = 1;
      Layer2TDMapper::SourceLayer::SourceLayer(__p, &v51);
      ZinIrOpLayerGraph::AddNode(this, v30, (ZinIrOpLayer ***)__p);
      __p[0] = &unk_26C359A08;
      if (__p[1])
      {
        *(void **)&long long v58 = __p[1];
        operator delete(__p[1]);
      }
      ZinIrOpLayerGraph::AddEdge((uint64_t)this, (uint64_t)v5, (uint64_t)v30, 0xFFFFFFFFFFFFFFFFLL, 0xFFFFFFFFFFFFFFFFLL, 0);
      uint64_t v5 = v30;
    }
    goto LABEL_21;
  }
  uint64_t v9 = *((void *)v5 + 2);
  uint64_t v10 = *(unsigned int *)(v7 + 88);
  long long v56 = 0;
  Copyuint64_t Layer = (ZinIrOpLayer *)ZinBuilder::CreateCopyLayer(v9, (uint64_t)v5, (uint64_t)a3, v10, (uint64_t *)&v56);
  uint64_t v12 = v56;
  long long v56 = 0;
  if (v12) {
    std::default_delete<ZinIrTensor::MirInfo>::operator()[abi:ne180100]((uint64_t)&v56, v12);
  }
  v59[0].i64[0] = (uint64_t)v5;
  uint64_t v51 = (uint64_t)v59;
  uint64_t v52 = 1;
  Layer2TDMapper::SourceLayer::SourceLayer(__p, &v51);
  ZinIrOpLayerGraph::AddNode(this, CopyLayer, (ZinIrOpLayer ***)__p);
  __p[0] = &unk_26C359A08;
  if (__p[1])
  {
    *(void **)&long long v58 = __p[1];
    operator delete(__p[1]);
  }
  ZinIrOpLayerGraph::AddEdge((uint64_t)this, (uint64_t)v5, (uint64_t)CopyLayer, 0xFFFFFFFFFFFFFFFFLL, 0xFFFFFFFFFFFFFFFFLL, 0);
  __p[0] = 0;
  uint64_t v13 = (*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)CopyLayer + 32))(CopyLayer, 0, 0);
  ZinMirTensorTransform::FixAllocation(v13, (uint64_t)a3, 2, (uint64_t *)__p, 1, 1uLL, 1);
  if (__p[0])
  {
    BOOL v14 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (v14) {
      ZinMirTensorTransform::NonResidentLinearizeToChannelInL2(v14, v15, v16, v17, v18, v19, v20, v21);
    }
    return 0;
  }
LABEL_21:
  uint64_t v31 = *(void *)(v7 + 48);
  uint64_t v32 = *(void *)(v7 + 56);
  uint64_t v34 = *(void *)(v7 + 64);
  unint64_t v33 = *(void *)(v7 + 72);
  uint64_t v35 = *(void *)(v7 + 80);
  Hal = ZinIrTarget::GetHal(*(uint64_t **)(v7 + 16), *(ZinIrTarget **)(*(void *)(v7 + 16) + 160));
  uint64_t v37 = (*(uint64_t (**)(uint64_t *))(*Hal + 16))(Hal);
  uint64_t v38 = v37;
  if (v33 > *(void *)(v37 + 1680))
  {
    BOOL v39 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (v39) {
      ZinMirTensorTransform::NonResidentLinearizeToChannelInL2(v39, v40, v41, v42, v43, v44, v45, v46);
    }
    return 0;
  }
  if (v33 != 1)
  {
    uint64_t v49 = 0;
    uint64_t v50 = 1;
    while (*(void *)(v37 + 1656 + v49) < v33)
    {
      v49 += 8;
      if (v49 == 32) {
        goto LABEL_33;
      }
    }
    uint64_t v50 = *(void *)(v37 + 1656 + v49);
LABEL_33:
    uint64_t v51 = 1;
    uint64_t v52 = v33;
    uint64_t v53 = v32 * v31 * v34;
    uint64_t v54 = 1;
    uint64_t v55 = v35;
    DimensionOrderHint::DimensionOrderHint(v60, 2);
    ZinIrTensor::CreateDefaultStride((const ZinTensorDimensions *)&v51, *(_DWORD *)(v7 + 88), 2, (uint64_t)v60, *(void *)(v38 + 528), v50, 1, v59);
    operator new();
  }
  return v5;
}

void sub_2112B683C(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, void *a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,void *a25,void *__p,uint64_t a27)
{
  a25 = &unk_26C359A08;
  if (__p)
  {
    a27 = (uint64_t)__p;
    operator delete(__p);
  }
  uint64_t v29 = a16;
  a16 = 0;
  if (v29) {
    std::default_delete<ZinIrTensor::MirInfo>::operator()[abi:ne180100]((uint64_t)&a16, v29);
  }
  uint64_t v30 = *(void **)(v27 - 128);
  if (v30)
  {
    *(void *)(v27 - 120) = v30;
    operator delete(v30);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinMirTensorTransform::TransposeChannelVectorToWidthFP16InL2(uint64_t **this, ZinIrOpLayerGraph *a2, ZinIrOpLayer *a3, ZinObjectNameFactory *a4, const ZinIrHalParameters *a5)
{
  uint64_t v53 = *MEMORY[0x263EF8340];
  if (a2)
  {
    unsigned int v6 = a2;
    int v8 = (std::string *)std::string::basic_string[abi:ne180100]<0>(&v51, "fix_alloc_hint");
    uint64_t v9 = std::string::append(v8, "_xfm", 4uLL);
    long long v10 = *(_OWORD *)&v9->__r_.__value_.__l.__data_;
    v44.__r_.__value_.__r.__words[2] = v9->__r_.__value_.__r.__words[2];
    *(_OWORD *)&v44.__r_.__value_.__l.__data_ = v10;
    v9->__r_.__value_.__l.__size_ = 0;
    v9->__r_.__value_.__r.__words[2] = 0;
    v9->__r_.__value_.__r.__words[0] = 0;
    int v11 = *((char *)v6 + 47);
    if (v11 >= 0) {
      uint64_t v12 = (char *)v6 + 24;
    }
    else {
      uint64_t v12 = (const std::string::value_type *)*((void *)v6 + 3);
    }
    if (v11 >= 0) {
      std::string::size_type v13 = *((unsigned __int8 *)v6 + 47);
    }
    else {
      std::string::size_type v13 = *((void *)v6 + 4);
    }
    BOOL v14 = std::string::insert(&v44, 0, v12, v13);
    long long v15 = *(_OWORD *)&v14->__r_.__value_.__l.__data_;
    std::string::size_type v50 = v14->__r_.__value_.__r.__words[2];
    long long __p = v15;
    v14->__r_.__value_.__l.__size_ = 0;
    v14->__r_.__value_.__r.__words[2] = 0;
    v14->__r_.__value_.__r.__words[0] = 0;
    __n128 v16 = ZinObjectNameFactory::ZinObjectNameFactory(v47, &__p);
    if (SHIBYTE(v50) < 0) {
      operator delete((void *)__p);
    }
    if (SHIBYTE(v44.__r_.__value_.__r.__words[2]) < 0) {
      operator delete(v44.__r_.__value_.__l.__data_);
    }
    if (v52 < 0) {
      operator delete((void *)v51.i64[0]);
    }
    uint64_t v46 = 0;
    uint64_t v17 = (*(uint64_t (**)(ZinIrOpLayerGraph *, void, void, __n128))(*(void *)v6 + 32))(v6, 0, 0, v16);
    ZinMirTensorTransform::FixAllocation(v17, (uint64_t)v47, 1, (uint64_t *)&v46, 1, 0, 0);
    uint64_t v18 = v46;
    if (v46)
    {
      v51.i64[0] = (uint64_t)v6;
      v44.__r_.__value_.__r.__words[0] = (std::string::size_type)&v51;
      v44.__r_.__value_.__l.__size_ = 1;
      Layer2TDMapper::SourceLayer::SourceLayer(&__p, &v44);
      ZinIrOpLayerGraph::AddNode(this, v18, (ZinIrOpLayer ***)&__p);
      *(void *)&long long __p = &unk_26C359A08;
      if (*((void *)&__p + 1))
      {
        std::string::size_type v50 = *((void *)&__p + 1);
        operator delete(*((void **)&__p + 1));
      }
      ZinIrOpLayerGraph::AddEdge((uint64_t)this, (uint64_t)v6, (uint64_t)v18, 0xFFFFFFFFFFFFFFFFLL, 0xFFFFFFFFFFFFFFFFLL, 0);
      unsigned int v6 = v18;
    }
    uint64_t v27 = (void *)(*(uint64_t (**)(ZinIrOpLayerGraph *, void, void))(*(void *)v6 + 32))(v6, 0, 0);
    if (v27[9] == 1)
    {
      uint64_t v28 = (*(uint64_t (**)(ZinIrOpLayerGraph *, void, void))(*(void *)v6 + 32))(v6, 0, 0);
      uint64_t v29 = v27[7];
      uint64_t v30 = v27[8];
      if (ZinIrTensor::MirInfo::HasCustomStrides(*(ZinIrTensor::MirInfo **)(v28 + 104))) {
        unint64_t v31 = v27[8] * (*(void *)(*(void *)(v28 + 104) + 16) / *((void *)a4 + 52));
      }
      else {
        unint64_t v31 = v30 * v29;
      }
      std::string::size_type v40 = *((void *)a4 + 210);
      if (!(v31 % v40))
      {
        v44.__r_.__value_.__r.__words[0] = 1;
        v44.__r_.__value_.__l.__size_ = v40;
        v44.__r_.__value_.__r.__words[2] = v31 / v40;
        int64x2_t v45 = vdupq_n_s64(1uLL);
        DimensionOrderHint::DimensionOrderHint(&v43, 1);
        uint64_t v42 = (*(uint64_t (**)(ZinIrOpLayerGraph *, void, void))(*(void *)v6 + 32))(v6, 0, 0);
        ZinIrTensor::CreateDefaultStride((const ZinTensorDimensions *)&v44, *(_DWORD *)(v42 + 88), 1, (uint64_t)&v43, 16, 1, 1, &v51);
        operator new();
      }
      BOOL v32 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (!v32) {
        goto LABEL_30;
      }
    }
    else
    {
      BOOL v32 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (!v32) {
        goto LABEL_30;
      }
    }
    ZinMirTensorTransform::TransposeChannelVectorToWidthFP16InL2(v32, v33, v34, v35, v36, v37, v38, v39);
LABEL_30:
    v47[0] = &unk_26C34DA98;
    if (v48 < 0) {
      operator delete((void *)v47[1]);
    }
    return 0;
  }
  BOOL v19 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
  if (v19) {
    ZinMirTensorTransform::TransposeChannelVectorToWidthFP16InL2(v19, v20, v21, v22, v23, v24, v25, v26);
  }
  return 0;
}

void sub_2112B74D4(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, void *a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,void *a26,void *a27,uint64_t a28,uint64_t a29,uint64_t a30,void *a31,uint64_t a32,int a33,__int16 a34,char a35,char a36,uint64_t a37,uint64_t a38,uint64_t a39,void *a40,void *a41,uint64_t a42,int a43,__int16 a44,char a45,char a46,uint64_t a47,uint64_t a48,uint64_t a49,uint64_t a50,uint64_t a51,uint64_t a52,uint64_t a53,uint64_t a54,void *a55,void *__p,uint64_t a57)
{
  a55 = &unk_26C359A08;
  if (__p)
  {
    a57 = (uint64_t)__p;
    operator delete(__p);
  }
  long long v58 = a26;
  a26 = 0;
  if (v58) {
    std::default_delete<ZinIrTensor::MirInfo>::operator()[abi:ne180100]((uint64_t)&a26, v58);
  }
  if (a27)
  {
    a28 = (uint64_t)a27;
    operator delete(a27);
  }
  a40 = &unk_26C34DA98;
  if (a46 < 0) {
    operator delete(a41);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinMirTensorTransform::ReplaceTensorWithNewFormat(uint64_t a1, uint64_t a2, int a3, uint64_t a4)
{
  if (a2)
  {
    uint64_t v4 = a2;
    if (*(_DWORD *)(a2 + 88) != a3)
    {
      (*(void (**)(uint64_t *__return_ptr, uint64_t, void))(*(void *)a4 + 16))(&v22, a4, 0);
      ZinIrTensor::CopyTensorMirInfo(v4, &v21);
      uint64_t v5 = v21;
      uint64_t v21 = 0;
      uint64_t v19 = 0;
      uint64_t v20 = v5;
      uint64_t v18 = 0;
      LODWORD(v15.__r_.__value_.__l.__data_) = 0;
      uint64_t v16 = 0;
      *(_OWORD *)&v15.__r_.__value_.__r.__words[1] = 0uLL;
      int v17 = 0;
      ZinIrTensor::CreateTensor();
    }
  }
  else
  {
    BOOL v6 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (v6) {
      ZinMirTensorTransform::ReplaceTensorWithNewFormat(v6, v7, v8, v9, v10, v11, v12, v13);
    }
    return 0;
  }
  return v4;
}

void sub_2112B799C(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, void *__p, uint64_t a12, int a13, __int16 a14, char a15, char a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,std::__shared_weak_count *a23)
{
  if (a23) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a23);
  }
  uint64_t v25 = *(void **)(v23 - 64);
  *(void *)(v23 - 64) = 0;
  if (v25) {
    std::default_delete<ZinIrTensor::MirInfo>::operator()[abi:ne180100](v23 - 64, v25);
  }
  if (*(char *)(v23 - 33) < 0) {
    operator delete(*(void **)(v23 - 56));
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinMirTensorTransform::SplitLayerPerBatch(ZinIrOpLayerGraph *a1, const std::string *a2, uint64_t a3)
{
  uint64_t v59 = *MEMORY[0x263EF8340];
  uint64_t v55 = 0;
  long long v56 = a2;
  uint64_t v53 = 0;
  uint64_t v54 = 0;
  int64x2_t v51 = 0;
  long long __p = 0;
  uint64_t v52 = 0;
  v49[1] = 0;
  v49[0] = 0;
  char v48 = v49;
  int v3 = *(void **)a3;
  if (*(void *)a3 == *(void *)(a3 + 8))
  {
    uint64_t v12 = v48;
    if (v48 != v49)
    {
      int v13 = 1;
      do
      {
        uint64_t v14 = v12[4];
        std::string v15 = *(uint64_t **)(v14 + 112);
        uint64_t v16 = *(uint64_t **)(v14 + 120);
        if (v15 != v16)
        {
          while (*(_DWORD *)(*(void *)(*v15 + 64) + 8) != 31)
          {
            if (++v15 == v16) {
              goto LABEL_26;
            }
          }
        }
        if (v15 != v16) {
          v13 &= ZinIrOpLayerGraph::SwapEdgeSource((uint64_t)a1, (ZinIrOpLayerGraph *)v14, **(ZinIrOpLayer ***)(v14 + 88), *v15, 0xFFFFFFFFFFFFFFFFLL, 0xFFFFFFFFFFFFFFFFLL, 0xFFFFFFFFFFFFFFFFLL, 0xFFFFFFFFFFFFFFFFLL, 0, 0);
        }
LABEL_26:
        BOOL v17 = ZinIrOpLayerGraph::RemoveNode(a1, (ZinIrOpLayer *)v14, 0);
        uint64_t v18 = (void *)v12[1];
        if (v18)
        {
          do
          {
            uint64_t v19 = (void **)v18;
            uint64_t v18 = (void *)*v18;
          }
          while (v18);
        }
        else
        {
          do
          {
            uint64_t v19 = (void **)v12[2];
            BOOL v20 = *v19 == v12;
            uint64_t v12 = v19;
          }
          while (!v20);
        }
        v13 &= v17;
        uint64_t v12 = v19;
      }
      while (v19 != v49);
    }
    uint64_t v21 = v56;
    if ((v56[1].__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
      size_t size = HIBYTE(v56[1].__r_.__value_.__r.__words[2]);
    }
    else {
      size_t size = v56[1].__r_.__value_.__l.__size_;
    }
    std::string::basic_string[abi:ne180100]((uint64_t)&v45, size + 7);
    if ((SBYTE7(v46) & 0x80u) == 0) {
      uint64_t v23 = &v45;
    }
    else {
      uint64_t v23 = (long long *)v45;
    }
    if (size)
    {
      if ((v21[1].__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
        data = v21 + 1;
      }
      else {
        data = (const std::string *)v21[1].__r_.__value_.__l.__data_;
      }
      memmove(v23, data, size);
    }
    strcpy((char *)v23 + size, "_gather");
    __n128 v25 = ZinObjectNameFactory::ZinObjectNameFactory(&v38, &v45);
    if (SBYTE7(v46) < 0) {
      operator delete((void *)v45);
    }
    (*(void (**)(const std::string *, void, void, __n128))(v56->__r_.__value_.__r.__words[0] + 32))(v56, 0, 0, v25);
    uint64_t v26 = (*(uint64_t (**)(const std::string *, void, void))(v56->__r_.__value_.__r.__words[0] + 32))(v56, 0, 0);
    ZinIrTensor::CopyTensorMirInfo(v26, &v37);
    ZinBuilder::CreateConcat();
  }
  if (*v3)
  {
    uint64_t v4 = (*(uint64_t (**)(const std::string *, void, void))(v56->__r_.__value_.__r.__words[0] + 32))(v56, 0, 0);
    uint64_t v47 = *(void *)(v4 + 80);
    long long v5 = *(_OWORD *)(v4 + 64);
    long long v45 = *(_OWORD *)(v4 + 48);
    long long v46 = v5;
    *(void *)&long long v45 = *v3;
    std::string::basic_string(&__s2, v56 + 1, 0, 2uLL, (std::allocator<char> *)&v57);
    std::operator+<char>();
    BOOL v6 = std::string::append(&v41, "_split_", 7uLL);
    long long v7 = *(_OWORD *)&v6->__r_.__value_.__l.__data_;
    v38.__r_.__value_.__r.__words[2] = v6->__r_.__value_.__r.__words[2];
    *(_OWORD *)&v38.__r_.__value_.__l.__data_ = v7;
    v6->__r_.__value_.__l.__size_ = 0;
    v6->__r_.__value_.__r.__words[2] = 0;
    v6->__r_.__value_.__r.__words[0] = 0;
    std::to_string(&v57, 0);
    if ((v57.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
      uint64_t v8 = &v57;
    }
    else {
      uint64_t v8 = (std::string *)v57.__r_.__value_.__r.__words[0];
    }
    if ((v57.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
      std::string::size_type v9 = HIBYTE(v57.__r_.__value_.__r.__words[2]);
    }
    else {
      std::string::size_type v9 = v57.__r_.__value_.__l.__size_;
    }
    uint64_t v10 = std::string::append(&v38, (const std::string::value_type *)v8, v9);
    long long v11 = *(_OWORD *)&v10->__r_.__value_.__l.__data_;
    std::string::size_type v44 = v10->__r_.__value_.__r.__words[2];
    long long v43 = v11;
    v10->__r_.__value_.__l.__size_ = 0;
    v10->__r_.__value_.__r.__words[2] = 0;
    v10->__r_.__value_.__r.__words[0] = 0;
    if (SHIBYTE(v57.__r_.__value_.__r.__words[2]) < 0) {
      operator delete(v57.__r_.__value_.__l.__data_);
    }
    if (SHIBYTE(v38.__r_.__value_.__r.__words[2]) < 0) {
      operator delete(v38.__r_.__value_.__l.__data_);
    }
    if (SHIBYTE(v41.__r_.__value_.__r.__words[2]) < 0) {
      operator delete(v41.__r_.__value_.__l.__data_);
    }
    if (SHIBYTE(__s2.__r_.__value_.__r.__words[2]) < 0) {
      operator delete(__s2.__r_.__value_.__l.__data_);
    }
    (*(void (**)(const std::string *, void, void))(v56->__r_.__value_.__r.__words[0] + 32))(v56, 0, 0);
    uint64_t v42 = 0;
    *(_OWORD *)&v41.__r_.__value_.__l.__data_ = 0uLL;
    LODWORD(v38.__r_.__value_.__l.__data_) = 0;
    uint64_t v39 = 0;
    *(_OWORD *)&v38.__r_.__value_.__r.__words[1] = 0uLL;
    LODWORD(v40) = 0;
    ZinIrTensor::CreateTensor();
  }
  BOOL v27 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
  if (v27) {
    ZinMirTensorTransform::SplitLayerPerBatch(v27, v28, v29, v30, v31, v32, v33, v34);
  }
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v48, v49[0]);
  if (__p)
  {
    int64x2_t v51 = __p;
    operator delete(__p);
  }
  if (v53)
  {
    uint64_t v54 = v53;
    operator delete(v53);
  }
  return 3;
}

void sub_2112B8F48(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,std::__shared_weak_count *a22)
{
  if (a22) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a22);
  }
  uint64_t v24 = (void *)STACK[0x2A0];
  if (STACK[0x2A0])
  {
    STACK[0x2A8] = (unint64_t)v24;
    operator delete(v24);
  }
  if (STACK[0x2C8]) {
    std::__shared_weak_count::__release_shared[abi:ne180100]((std::__shared_weak_count *)STACK[0x2C8]);
  }
  if (SLOBYTE(STACK[0x2E7]) < 0) {
    operator delete((void *)STACK[0x2D0]);
  }
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&STACK[0x320], (void *)STACK[0x328]);
  __n128 v25 = (void *)STACK[0x338];
  if (STACK[0x338])
  {
    STACK[0x340] = (unint64_t)v25;
    operator delete(v25);
  }
  uint64_t v26 = *(void **)(v22 - 256);
  if (v26)
  {
    *(void *)(v22 - 248) = v26;
    operator delete(v26);
  }
  _Unwind_Resume(a1);
}

uint64_t ZinMirTensorTransform::PropagateSpatialSplitInfo<std::list<ZinIrOpLayer *>>(uint64_t a1, uint64_t a2)
{
  uint64_t result = (*(uint64_t (**)(uint64_t, void, void))(*(void *)a1 + 32))(a1, 0, 0);
  if (*(unsigned char *)(result + 144))
  {
    uint64_t result = (*(uint64_t (**)(uint64_t, void, void))(*(void *)a1 + 32))(a1, 0, 0);
    if (!*(unsigned char *)(result + 144)) {
      goto LABEL_11;
    }
    if (*(_DWORD *)(result + 132) != 2) {
      return result;
    }
    uint64_t result = (*(uint64_t (**)(uint64_t, void, void))(*(void *)a1 + 32))(a1, 0, 0);
    if (!*(unsigned char *)(result + 144)) {
LABEL_11:
    }
      std::__throw_bad_optional_access[abi:ne180100]();
    uint64_t v5 = *(void *)(a2 + 8);
    if (v5 != a2)
    {
      __int16 v6 = *(_WORD *)(result + 128);
      uint64_t v7 = *(void *)(result + 136);
      do
      {
        uint64_t result = (*(uint64_t (**)(void, void, void))(**(void **)(v5 + 16) + 32))(*(void *)(v5 + 16), 0, 0);
        int v8 = *(unsigned __int8 *)(result + 144);
        *(_WORD *)(result + 128) = v6;
        *(_DWORD *)(result + 1std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = 2;
        *(void *)(result + 136) = v7;
        if (!v8) {
          *(unsigned char *)(result + 144) = 1;
        }
        uint64_t v5 = *(void *)(v5 + 8);
      }
      while (v5 != a2);
    }
  }
  return result;
}

uint64_t ZinMirTensorTransform::CopyAndReplaceInputAtIndex(ZinMirTensorTransform *this, ZinIrOpLayerGraph *a2, uint64_t a3)
{
  uint64_t v55 = *MEMORY[0x263EF8340];
  uint64_t v53 = a2;
  v51[0] = (unint64_t *)&v53;
  uint64_t v5 = std::__hash_table<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::__unordered_map_hasher<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::__unordered_map_equal<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>>>::find<std::reference_wrapper<ZinIrOpLayer * const>>((void *)this + 8, v51);
  __int16 v6 = (void *)((char *)this + 104);
  if (v5) {
    __int16 v6 = v5 + 3;
  }
  int v8 = v6;
  uint64_t v7 = *v6;
  if (a3 >= (unint64_t)((v8[1] - v7) >> 3))
  {
    if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
      ZinMirTensorTransform::CopyAndReplaceInputAtIndex(a3, v35, v36, v37, v38, v39, v40, v41);
    }
    return 3;
  }
  else
  {
    std::string::size_type v9 = **(ZinIrOpLayerGraph ***)(v7 + 8 * a3);
    uint64_t v10 = (*(uint64_t (**)(ZinIrOpLayerGraph *, void, void))(*(void *)v9 + 32))(v9, 0, 0);
    long long v11 = v53;
    if (*((char *)v53 + 47) >= 0) {
      size_t v12 = *((unsigned __int8 *)v53 + 47);
    }
    else {
      size_t v12 = *((void *)v53 + 4);
    }
    int v13 = &v49;
    std::string::basic_string[abi:ne180100]((uint64_t)&v49, v12 + 1);
    if ((v49.__r_.__value_.__r.__words[2] & 0x8000000000000000) != 0) {
      int v13 = (std::string *)v49.__r_.__value_.__r.__words[0];
    }
    if (v12)
    {
      uint64_t v16 = (char *)*((void *)v11 + 3);
      std::string v15 = (char *)v11 + 24;
      uint64_t v14 = v16;
      if (v15[23] >= 0) {
        BOOL v17 = v15;
      }
      else {
        BOOL v17 = v14;
      }
      memmove(v13, v17, v12);
    }
    *(_WORD *)((char *)&v13->__r_.__value_.__l.__data_ + v12) = 95;
    std::string::basic_string[abi:ne180100]<0>(&v46, "copy_at_idx");
    uint64_t v18 = std::string::append(&v46, "_xfm", 4uLL);
    long long v19 = *(_OWORD *)&v18->__r_.__value_.__l.__data_;
    int64_t v48 = v18->__r_.__value_.__r.__words[2];
    *(_OWORD *)uint64_t v47 = v19;
    v18->__r_.__value_.__l.__size_ = 0;
    v18->__r_.__value_.__r.__words[2] = 0;
    v18->__r_.__value_.__r.__words[0] = 0;
    if (v48 >= 0) {
      BOOL v20 = v47;
    }
    else {
      BOOL v20 = (void **)v47[0];
    }
    if (v48 >= 0) {
      std::string::size_type v21 = HIBYTE(v48);
    }
    else {
      std::string::size_type v21 = (std::string::size_type)v47[1];
    }
    uint64_t v22 = std::string::append(&v49, (const std::string::value_type *)v20, v21);
    long long v23 = *(_OWORD *)&v22->__r_.__value_.__l.__data_;
    v54.__r_.__value_.__r.__words[2] = v22->__r_.__value_.__r.__words[2];
    *(_OWORD *)&v54.__r_.__value_.__l.__data_ = v23;
    v22->__r_.__value_.__l.__size_ = 0;
    v22->__r_.__value_.__r.__words[2] = 0;
    v22->__r_.__value_.__r.__words[0] = 0;
    uint64_t v24 = std::string::append(&v54, "_", 1uLL);
    long long v25 = *(_OWORD *)&v24->__r_.__value_.__l.__data_;
    v50.__r_.__value_.__r.__words[2] = v24->__r_.__value_.__r.__words[2];
    *(_OWORD *)&v50.__r_.__value_.__l.__data_ = v25;
    v24->__r_.__value_.__l.__size_ = 0;
    v24->__r_.__value_.__r.__words[2] = 0;
    v24->__r_.__value_.__r.__words[0] = 0;
    std::to_string(&v45, a3);
    if ((v45.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
      uint64_t v26 = &v45;
    }
    else {
      uint64_t v26 = (std::string *)v45.__r_.__value_.__r.__words[0];
    }
    if ((v45.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
      std::string::size_type size = HIBYTE(v45.__r_.__value_.__r.__words[2]);
    }
    else {
      std::string::size_type size = v45.__r_.__value_.__l.__size_;
    }
    uint64_t v28 = std::string::append(&v50, (const std::string::value_type *)v26, size);
    long long v29 = *(_OWORD *)&v28->__r_.__value_.__l.__data_;
    long long v43 = (void *)v28->__r_.__value_.__r.__words[2];
    *(_OWORD *)long long __p = v29;
    v28->__r_.__value_.__l.__size_ = 0;
    v28->__r_.__value_.__r.__words[2] = 0;
    v28->__r_.__value_.__r.__words[0] = 0;
    ZinObjectNameFactory::ZinObjectNameFactory(v51, __p);
    if (SHIBYTE(v43) < 0) {
      operator delete(__p[0]);
    }
    if (SHIBYTE(v45.__r_.__value_.__r.__words[2]) < 0) {
      operator delete(v45.__r_.__value_.__l.__data_);
    }
    if (SHIBYTE(v50.__r_.__value_.__r.__words[2]) < 0) {
      operator delete(v50.__r_.__value_.__l.__data_);
    }
    if (SHIBYTE(v54.__r_.__value_.__r.__words[2]) < 0) {
      operator delete(v54.__r_.__value_.__l.__data_);
    }
    if (SHIBYTE(v48) < 0) {
      operator delete(v47[0]);
    }
    if (SHIBYTE(v46.__r_.__value_.__r.__words[2]) < 0) {
      operator delete(v46.__r_.__value_.__l.__data_);
    }
    if (SHIBYTE(v49.__r_.__value_.__r.__words[2]) < 0) {
      operator delete(v49.__r_.__value_.__l.__data_);
    }
    uint64_t v30 = *((void *)v9 + 2);
    uint64_t v31 = *(unsigned int *)(v10 + 88);
    std::string::size_type v44 = 0;
    Copyuint64_t Layer = (ZinIrOpLayer *)ZinBuilder::CreateCopyLayer(v30, (uint64_t)v9, (uint64_t)v51, v31, (uint64_t *)&v44);
    uint64_t v33 = v44;
    std::string::size_type v44 = 0;
    if (v33) {
      std::default_delete<ZinIrTensor::MirInfo>::operator()[abi:ne180100]((uint64_t)&v44, v33);
    }
    v54.__r_.__value_.__r.__words[0] = (std::string::size_type)v53;
    v50.__r_.__value_.__r.__words[0] = (std::string::size_type)&v54;
    v50.__r_.__value_.__l.__size_ = 1;
    Layer2TDMapper::SourceLayer::SourceLayer(__p, &v50);
    ZinIrOpLayerGraph::AddNode((uint64_t **)this, CopyLayer, (ZinIrOpLayer ***)__p);
    __p[0] = &unk_26C359A08;
    if (__p[1])
    {
      long long v43 = __p[1];
      operator delete(__p[1]);
    }
    ZinIrOpLayerGraph::AddEdge((uint64_t)this, (uint64_t)v9, (uint64_t)CopyLayer, 0xFFFFFFFFFFFFFFFFLL, 0xFFFFFFFFFFFFFFFFLL, 0);
    ZinIrOpLayerGraph::SwapEdgeSource((uint64_t)this, v9, CopyLayer, (uint64_t)v53, 0xFFFFFFFFFFFFFFFFLL, a3, 0xFFFFFFFFFFFFFFFFLL, 0xFFFFFFFFFFFFFFFFLL, 0, 0);
    v51[0] = (unint64_t *)&unk_26C34DA98;
    if (v52 < 0) {
      operator delete(v51[1]);
    }
    return 0;
  }
}

void sub_2112B980C(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, void *a11, void *__p, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, void *a17, uint64_t a18, int a19, __int16 a20,char a21,char a22,void *a23,uint64_t a24,int a25,__int16 a26,char a27,char a28,void *a29,uint64_t a30,int a31,__int16 a32,char a33,char a34,uint64_t a35,uint64_t a36,int a37,__int16 a38,char a39,char a40,void *a41,uint64_t a42,int a43,__int16 a44,char a45,char a46)
{
  if (__p) {
    operator delete(__p);
  }
  *(void *)(v46 - 144) = &unk_26C34DA98;
  if (*(char *)(v46 - 113) < 0) {
    operator delete(*(void **)(v46 - 136));
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinMirTensorTransform::GetSinglePreviousLayer(ZinMirTensorTransform *this, ZinIrOpLayer *a2)
{
  uint64_t v2 = *((void *)this + 11);
  if (*((void *)this + 12) - v2 == 8) {
    return *(void *)v2;
  }
  else {
    return 0;
  }
}

uint64_t ZinMirTensorTransform::GetSingleNextLayer(ZinMirTensorTransform *this, unint64_t a2)
{
  uint64_t v2 = *((void *)this + 14);
  if (a2 >= (*((void *)this + 15) - v2) >> 3) {
    return 0;
  }
  else {
    return *(void *)(v2 + 8 * a2);
  }
}

void *std::__function::__func<ZinMirTensorTransform::FixDimensionOrder(ZinIrTensor *,ZinIrOpLayerGraph *,DimensionOrderHint const&,ZinMirTensorTransform::OutputLayerType)::$_0,std::allocator<ZinMirTensorTransform::FixDimensionOrder(ZinIrTensor *,ZinIrOpLayerGraph *,DimensionOrderHint const&,ZinMirTensorTransform::OutputLayerType)::$_0>,BOOL ()(ZinIrTensor *)>::~__func(void *a1)
{
  *a1 = &unk_26C386650;
  uint64_t v2 = (void *)a1[1];
  if (v2)
  {
    a1[2] = v2;
    operator delete(v2);
  }
  return a1;
}

void std::__function::__func<ZinMirTensorTransform::FixDimensionOrder(ZinIrTensor *,ZinIrOpLayerGraph *,DimensionOrderHint const&,ZinMirTensorTransform::OutputLayerType)::$_0,std::allocator<ZinMirTensorTransform::FixDimensionOrder(ZinIrTensor *,ZinIrOpLayerGraph *,DimensionOrderHint const&,ZinMirTensorTransform::OutputLayerType)::$_0>,BOOL ()(ZinIrTensor *)>::~__func(void *a1)
{
  *a1 = &unk_26C386650;
  uint64_t v2 = (void *)a1[1];
  if (v2)
  {
    a1[2] = v2;
    operator delete(v2);
  }

  JUMPOUT(0x21667D3C0);
}

__n128 std::__function::__func<ZinMirTensorTransform::FixDimensionOrder(ZinIrTensor *,ZinIrOpLayerGraph *,DimensionOrderHint const&,ZinMirTensorTransform::OutputLayerType)::$_0,std::allocator<ZinMirTensorTransform::FixDimensionOrder(ZinIrTensor *,ZinIrOpLayerGraph *,DimensionOrderHint const&,ZinMirTensorTransform::OutputLayerType)::$_0>,BOOL ()(ZinIrTensor *)>::__clone(uint64_t a1, uint64_t a2)
{
  *(void *)a2 = &unk_26C386650;
  *(void *)(a2 + 16) = 0;
  *(void *)(a2 + 24) = 0;
  *(void *)(a2 + 8) = 0;
  std::vector<ZinIrPaddingMode>::__init_with_size[abi:ne180100]<ZinIrPaddingMode*,ZinIrPaddingMode*>((void *)(a2 + 8), *(const void **)(a1 + 8), *(void *)(a1 + 16), (uint64_t)(*(void *)(a1 + 16) - *(void *)(a1 + 8)) >> 2);
  *(_DWORD *)(a2 + std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_DWORD *)(a1 + 32);
  __n128 result = *(__n128 *)(a1 + 40);
  *(_DWORD *)(a2 + 56) = *(_DWORD *)(a1 + 56);
  *(__n128 *)(a2 + 40) = result;
  return result;
}

void std::__function::__func<ZinMirTensorTransform::FixDimensionOrder(ZinIrTensor *,ZinIrOpLayerGraph *,DimensionOrderHint const&,ZinMirTensorTransform::OutputLayerType)::$_0,std::allocator<ZinMirTensorTransform::FixDimensionOrder(ZinIrTensor *,ZinIrOpLayerGraph *,DimensionOrderHint const&,ZinMirTensorTransform::OutputLayerType)::$_0>,BOOL ()(ZinIrTensor *)>::destroy(uint64_t a1)
{
  uint64_t v2 = *(void **)(a1 + 8);
  if (v2)
  {
    *(void *)(a1 + 16) = v2;
    operator delete(v2);
  }
}

uint64_t std::__function::__func<ZinMirTensorTransform::FixDimensionOrder(ZinIrTensor *,ZinIrOpLayerGraph *,DimensionOrderHint const&,ZinMirTensorTransform::OutputLayerType)::$_0,std::allocator<ZinMirTensorTransform::FixDimensionOrder(ZinIrTensor *,ZinIrOpLayerGraph *,DimensionOrderHint const&,ZinMirTensorTransform::OutputLayerType)::$_0>,BOOL ()(ZinIrTensor *)>::target(uint64_t a1, uint64_t a2)
{
  {
    return a1 + 8;
  }
  else
  {
    return 0;
  }
}

void *std::__function::__func<ZinMirTensorTransform::FixDimensionOrder(ZinIrTensor *,ZinIrOpLayerGraph *,DimensionOrderHint const&,ZinMirTensorTransform::OutputLayerType)::$_0,std::allocator<ZinMirTensorTransform::FixDimensionOrder(ZinIrTensor *,ZinIrOpLayerGraph *,DimensionOrderHint const&,ZinMirTensorTransform::OutputLayerType)::$_0>,BOOL ()(ZinIrTensor *)>::target_type()
{
}

void ZinMirTensorTransform::ChannelVectorInsertPaddingInL2(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void ZinMirTensorTransform::ChannelVectorInsertPaddingInL2()
{
  OUTLINED_FUNCTION_3_0(*MEMORY[0x263EF8340]);
  OUTLINED_FUNCTION_2(&dword_210C72000, &_os_log_internal, v0, "Error: Could not complete ChannelVectorInsertPaddingInL2 for layer \"%s\"", v1, v2, v3, v4, 2u);
}

void ZinMirTensorTransform::Split(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void ZinMirTensorTransform::NonResidentLinearizeToChannelInL2(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "Error: There must not be a new copy inserted by FixAllocation.", a5, a6, a7, a8, 0);
}

void ZinMirTensorTransform::NonResidentLinearizeToChannelInL2()
{
  OUTLINED_FUNCTION_3_0(*MEMORY[0x263EF8340]);
  OUTLINED_FUNCTION_2(&dword_210C72000, &_os_log_internal, v0, "Error: Could not complete NonResidentLinearizeToChannelInL2 for layer \"%s\"", v1, v2, v3, v4, 2u);
}

void ZinMirTensorTransform::TransposeChannelVectorToWidthFP16InL2(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void ZinMirTensorTransform::TransposeChannelVectorToWidthFP16InL2()
{
  OUTLINED_FUNCTION_3_0(*MEMORY[0x263EF8340]);
  OUTLINED_FUNCTION_2(&dword_210C72000, &_os_log_internal, v0, "Error: Could not successfully complete TransposeChannelVectorToWidthFP16InL2 for layer \"%s\"", v1, v2, v3, v4, 2u);
}

void ZinMirTensorTransform::ReplaceTensorWithNewFormat(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void ZinMirTensorTransform::SplitLayerPerBatch(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "Batch size should be 1 or more\n", a5, a6, a7, a8, 0);
}

void ZinMirTensorTransform::SplitLayerPerBatch(uint8_t *buf, int a2, _DWORD *a3)
{
  *(_DWORD *)uint8_t buf = 67109120;
  *a3 = a2;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "Error: Graph manipulation error during SplitLayerPerBatch at Split #%d.", buf, 8u);
}

void ZinMirTensorTransform::CopyAndReplaceInputAtIndex(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void *ZinIrOpLayerGraph::GetOutputPortsOfInEdges(ZinIrOpLayerGraph *this, ZinIrOpLayer *a2)
{
  uint64_t v5 = a2;
  uint64_t v3 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)this + 36, &v5);
  if (v3) {
    return v3 + 3;
  }
  else {
    return (void *)((char *)this + 328);
  }
}

uint64_t ZinIrOpLayerGraph::MoveIncomingEdges(ZinIrOpLayerGraph *this, ZinIrOpLayer *a2, ZinIrOpLayer *a3)
{
  long long v23 = a2;
  long long __p = &v23;
  uint64_t v5 = std::__hash_table<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::__unordered_map_hasher<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::__unordered_map_equal<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>>>::find<std::reference_wrapper<ZinIrOpLayer * const>>((void *)this + 8, (unint64_t **)&__p);
  __int16 v6 = (char *)this + 104;
  if (v5) {
    __int16 v6 = (char *)(v5 + 3);
  }
  std::string::size_type v21 = 0;
  uint64_t v22 = 0;
  BOOL v20 = 0;
  std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(&v20, *(const void **)v6, *((void *)v6 + 1), (uint64_t)(*((void *)v6 + 1) - *(void *)v6) >> 3);
  uint64_t v24 = v23;
  uint64_t v7 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)this + 36, &v24);
  int v8 = (char *)this + 328;
  if (v7) {
    int v8 = (char *)(v7 + 3);
  }
  uint64_t v18 = 0;
  uint64_t v19 = 0;
  long long __p = 0;
  std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(&__p, *(const void **)v8, *((void *)v8 + 1), (uint64_t)(*((void *)v8 + 1) - *(void *)v8) >> 3);
  std::string::size_type v9 = v20;
  uint64_t v10 = __p;
  if (v21 - (unsigned char *)v20 != v18 - (unsigned char *)__p) {
    ZinAssertImpl("nodes/ports are not synced for in edges");
  }
  if (v21 == v20)
  {
    uint64_t v15 = 1;
    if (__p)
    {
LABEL_14:
      uint64_t v18 = v10;
      operator delete(v10);
    }
  }
  else
  {
    unint64_t v11 = 0;
    while (1)
    {
      size_t v12 = (ZinIrOpLayer **)v9[v11];
      uint64_t v13 = *((void *)__p + v11);
      IndexOfMatchedOutgoinguint64_t Layer = ZinIrOpLayerGraph::GetIndexOfMatchedOutgoingLayer(this, *v12, v23, 0xFFFFFFFFFFFFFFFFLL);
      if ((ZinIrOpLayerGraph::RemoveEdge((uint64_t)this, (uint64_t)*v12, (uint64_t)v23, 0xFFFFFFFFFFFFFFFFLL, 0xFFFFFFFFFFFFFFFFLL, v13) & 1) == 0|| (ZinIrOpLayerGraph::AddEdge((uint64_t)this, (uint64_t)*v12, (uint64_t)a3, IndexOfMatchedOutgoingLayer, 0xFFFFFFFFFFFFFFFFLL, v13) & 1) == 0)
      {
        break;
      }
      ++v11;
      std::string::size_type v9 = v20;
      if (v11 >= (v21 - (unsigned char *)v20) >> 3)
      {
        uint64_t v15 = 1;
        goto LABEL_13;
      }
    }
    uint64_t v15 = 0;
LABEL_13:
    uint64_t v10 = __p;
    if (__p) {
      goto LABEL_14;
    }
  }
  if (v20)
  {
    std::string::size_type v21 = v20;
    operator delete(v20);
  }
  return v15;
}

void sub_2112BA144(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, void *__p, uint64_t a10, uint64_t a11, void *a12, uint64_t a13)
{
  if (__p) {
    operator delete(__p);
  }
  if (a12) {
    operator delete(a12);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinIrOpLayerGraph::GetIndexOfMatchedOutgoingLayer(ZinIrOpLayerGraph *this, ZinIrOpLayer *a2, ZinIrOpLayer *a3, unint64_t a4)
{
  std::string::size_type v21 = a3;
  uint64_t v22 = a2;
  long long v23 = &v21;
  uint64_t v7 = std::__hash_table<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::__unordered_map_hasher<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::__unordered_map_equal<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>>>::find<std::reference_wrapper<ZinIrOpLayer * const>>((void *)this + 8, (unint64_t **)&v23);
  if ((a4 & 0x8000000000000000) != 0)
  {
    uint64_t v11 = 1;
  }
  else
  {
    int v8 = (ZinIrOpLayer ****)(v7 + 3);
    if (!v7) {
      int v8 = (ZinIrOpLayer ****)((char *)this + 104);
    }
    uint64_t v10 = v8;
    std::string::size_type v9 = *v8;
    if (a4 >= v10[1] - v9 || *v9[a4] != a2) {
      return -1;
    }
    uint64_t v11 = 0;
    unint64_t v12 = a4 + 1;
    do
    {
      uint64_t v13 = *v9++;
      if (*v13 == a2) {
        ++v11;
      }
      --v12;
    }
    while (v12);
  }
  long long v23 = &v22;
  uint64_t v14 = std::__hash_table<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::__unordered_map_hasher<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::__unordered_map_equal<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>>>::find<std::reference_wrapper<ZinIrOpLayer * const>>((void *)this + 3, (unint64_t **)&v23);
  uint64_t v15 = v14 + 3;
  if (!v14) {
    uint64_t v15 = (void *)((char *)this + 104);
  }
  BOOL v17 = v15;
  uint64_t v16 = *v15;
  uint64_t v18 = v17[1] - v16;
  if (!v18) {
    return -1;
  }
  uint64_t result = 0;
  uint64_t v20 = v18 >> 3;
  if ((unint64_t)(v18 >> 3) <= 1) {
    uint64_t v20 = 1;
  }
  while (v21 != **(ZinIrOpLayer ***)(v16 + 8 * result) || --v11)
  {
    if (v20 == ++result) {
      return -1;
    }
  }
  return result;
}

uint64_t ZinIrOpLayerGraph::TraverseForward(uint64_t a1, uint64_t a2, char a3)
{
  v8[4] = *MEMORY[0x263EF8340];
  std::__function::__value_func<ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::__value_func[abi:ne180100]((uint64_t)v8, a2);
  uint64_t v5 = ZinIrOpLayerGraph::Traverse(a1, (uint64_t)v8, &v7, a3, 0);
  std::__function::__value_func<ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::~__value_func[abi:ne180100](v8);
  return v5;
}

void sub_2112BA320(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::__function::__value_func<ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::~__value_func[abi:ne180100]((uint64_t *)va);
  _Unwind_Resume(a1);
}

void ZinIrOpLayerGraph::GetIndicesOfMatchedIncomingLayer(ZinIrOpLayerGraph *this@<X0>, ZinIrOpLayer *a2@<X1>, const ZinIrOpLayer *a3@<X2>, unint64_t **a4@<X8>)
{
  a4[1] = 0;
  a4[2] = 0;
  *a4 = 0;
  long long v23 = a2;
  uint64_t v24 = &v23;
  char v7 = std::__hash_table<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::__unordered_map_hasher<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::__unordered_map_equal<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>>>::find<std::reference_wrapper<ZinIrOpLayer * const>>((void *)this + 8, (unint64_t **)&v24);
  if (v7) {
    int v8 = (uint64_t *)(v7 + 3);
  }
  else {
    int v8 = (uint64_t *)((char *)this + 104);
  }
  uint64_t v10 = *v8;
  uint64_t v9 = v8[1];
  if (v9 != *v8)
  {
    uint64_t v11 = 0;
    unint64_t v12 = 0;
    uint64_t v13 = a4 + 2;
    do
    {
      if (**(const ZinIrOpLayer ***)(v10 + 8 * v12) == a3)
      {
        if ((unint64_t)v11 >= *v13)
        {
          uint64_t v15 = *a4;
          uint64_t v16 = v11 - *a4;
          unint64_t v17 = v16 + 1;
          if ((unint64_t)(v16 + 1) >> 61) {
            std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
          }
          uint64_t v18 = *v13 - (void)v15;
          if (v18 >> 2 > v17) {
            unint64_t v17 = v18 >> 2;
          }
          if ((unint64_t)v18 >= 0x7FFFFFFFFFFFFFF8) {
            unint64_t v19 = 0x1FFFFFFFFFFFFFFFLL;
          }
          else {
            unint64_t v19 = v17;
          }
          if (v19)
          {
            uint64_t v20 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)(a4 + 2), v19);
            uint64_t v15 = *a4;
            uint64_t v11 = a4[1];
          }
          else
          {
            uint64_t v20 = 0;
          }
          std::string::size_type v21 = (unint64_t *)&v20[8 * v16];
          unint64_t *v21 = v12;
          uint64_t v14 = v21 + 1;
          while (v11 != v15)
          {
            unint64_t v22 = *--v11;
            *--std::string::size_type v21 = v22;
          }
          *a4 = v21;
          a4[1] = v14;
          a4[2] = (unint64_t *)&v20[8 * v19];
          if (v15) {
            operator delete(v15);
          }
        }
        else
        {
          unint64_t *v11 = v12;
          uint64_t v14 = v11 + 1;
        }
        a4[1] = v14;
        uint64_t v10 = *v8;
        uint64_t v9 = v8[1];
        uint64_t v11 = v14;
      }
      ++v12;
    }
    while (v12 < (v9 - v10) >> 3);
  }
}

void sub_2112BA4A0(_Unwind_Exception *exception_object)
{
  uint64_t v3 = *(void **)v1;
  if (*(void *)v1)
  {
    *(void *)(v1 + 8) = v3;
    operator delete(v3);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinIrOpLayerGraph::ReplaceNode(uint64_t **this, ZinIrOpLayer *a2, ZinIrOpLayer *a3, const Layer2TDMapper::SourceLayer *a4)
{
  v20[1] = *MEMORY[0x263EF8340];
  if (*(_DWORD *)(*((void *)a2 + 8) + 8) == 29)
  {
    long long __p = 0;
    uint64_t v18 = 0;
    uint64_t v19 = 0;
    uint64_t v16 = (ZinIrOpLayer **)&unk_26C359A20;
    BOOL v7 = ZinIrOpLayerGraph::AddNode(this, a3, &v16);
    uint64_t v16 = (ZinIrOpLayer **)&unk_26C359A08;
    if (__p)
    {
      uint64_t v18 = __p;
      operator delete(__p);
    }
    if (!v7) {
      return 0;
    }
    goto LABEL_12;
  }
  v20[0] = a2;
  v15[0] = v20;
  v15[1] = 1;
  Layer2TDMapper::SourceLayer::SourceLayer(&v16, v15);
  BOOL v9 = ZinIrOpLayerGraph::AddNode(this, a3, &v16);
  uint64_t v16 = (ZinIrOpLayer **)&unk_26C359A08;
  if (__p)
  {
    uint64_t v18 = __p;
    operator delete(__p);
  }
  if (!v9) {
    return 0;
  }
  DynamicOffsetInfo = (void *)ZinDynamicOffsetCustomBarCmd::GetDynamicOffsetInfo(a4);
  if (DynamicOffsetInfo[1] == *DynamicOffsetInfo
    || (uint64_t result = Layer2TDMapper::LayerTracker::RecordSourceLayers((Layer2TDMapper::LayerTracker *)(this + 19), a3, (ZinIrOpLayer ***)a4), result))
  {
    uint64_t result = ZinIrOpLayerGraph::MoveIncomingEdges((ZinIrOpLayerGraph *)this, a2, a3);
    if (result)
    {
LABEL_12:
      memset(v13, 0, sizeof(v13));
      int v14 = 1065353216;
      char v12 = ZinIrOpLayerGraph::MoveOutgoingEdges((ZinIrOpLayerGraph *)this, (uint64_t **)a2, a3, v13);
      std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v13);
      if (v12) {
        return ZinIrOpLayerGraph::RemoveNode((ZinIrOpLayerGraph *)this, a2, 0);
      }
      return 0;
    }
  }
  return result;
}

void sub_2112BA6A0(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, void *__p, uint64_t a19)
{
}

BOOL ZinIrOpLayerGraph::ReplaceNode(uint64_t a1, ZinIrOpLayer *a2, ZinIrOpLayer ***a3)
{
  v27[1] = *MEMORY[0x263EF8340];
  uint64_t v26 = a2;
  if (!std::__tree<ZinIrOpLayer *,ZinIrIdComparator<ZinIrOpLayer *>,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>(a1, (uint64_t *)&v26))ZinAssertImpl("The old node should be present in the graph."); {
  uint64_t v5 = *a3;
  }
  __int16 v6 = a3[1];
  if (*a3 == v6) {
    return 0;
  }
  do
  {
    std::string::size_type v21 = *v5;
    if (std::__tree<ZinIrOpLayer *,ZinIrIdComparator<ZinIrOpLayer *>,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>(a1, (uint64_t *)&v21))
    {
      goto LABEL_33;
    }
    long long v23 = &v21;
    BOOL v7 = std::__hash_table<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::__unordered_map_hasher<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::__unordered_map_equal<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>>>::find<std::reference_wrapper<ZinIrOpLayer * const>>((void *)(a1 + 64), (unint64_t **)&v23);
    int v8 = v7 + 3;
    if (!v7) {
      int v8 = (void *)(a1 + 104);
    }
    if (v8[1] != *v8) {
      goto LABEL_33;
    }
    long long v23 = &v21;
    BOOL v9 = std::__hash_table<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::__unordered_map_hasher<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::__unordered_map_equal<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>>>::find<std::reference_wrapper<ZinIrOpLayer * const>>((void *)(a1 + 24), (unint64_t **)&v23);
    uint64_t v10 = v9 + 3;
    if (!v9) {
      uint64_t v10 = (void *)(a1 + 104);
    }
    if (v10[1] != *v10) {
LABEL_33:
    }
      ZinAssertImpl("new node in the chain should not have any edge at this point");
    ++v5;
  }
  while (v5 != v6);
  if (*a3 == a3[1]) {
    return 0;
  }
  uint64_t v11 = **a3;
  v27[0] = v26;
  std::string::size_type v21 = (ZinIrOpLayer *)v27;
  uint64_t v22 = 1;
  Layer2TDMapper::SourceLayer::SourceLayer(&v23, &v21);
  BOOL v12 = ZinIrOpLayerGraph::AddNode((uint64_t **)a1, v11, &v23);
  long long v23 = (ZinIrOpLayer **)&unk_26C359A08;
  if (__p)
  {
    long long v25 = __p;
    operator delete(__p);
  }
  if (!v12) {
    return 0;
  }
  if (!ZinIrOpLayerGraph::MoveIncomingEdges((ZinIrOpLayerGraph *)a1, v26, v11))
  {
    BOOL result = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (!result) {
      return result;
    }
    ZinIrOpLayerGraph::ReplaceNode();
    return 0;
  }
  uint64_t v13 = *a3;
  if ((unint64_t)((char *)a3[1] - (char *)*a3) >= 9)
  {
    unint64_t v14 = 1;
    while (1)
    {
      uint64_t v15 = v13[v14];
      v27[0] = v26;
      std::string::size_type v21 = (ZinIrOpLayer *)v27;
      uint64_t v22 = 1;
      Layer2TDMapper::SourceLayer::SourceLayer(&v23, &v21);
      BOOL v16 = ZinIrOpLayerGraph::AddNode((uint64_t **)a1, v15, &v23);
      long long v23 = (ZinIrOpLayer **)&unk_26C359A08;
      if (__p)
      {
        long long v25 = __p;
        operator delete(__p);
      }
      if (!v16
        || (ZinIrOpLayerGraph::AddEdge(a1, (uint64_t)v11, (uint64_t)v15, 0xFFFFFFFFFFFFFFFFLL, 0xFFFFFFFFFFFFFFFFLL, 0) & 1) == 0)
      {
        return 0;
      }
      ++v14;
      uint64_t v13 = *a3;
      uint64_t v11 = v15;
      if (v14 >= a3[1] - *a3) {
        goto LABEL_27;
      }
    }
  }
  uint64_t v15 = v11;
LABEL_27:
  memset(v19, 0, sizeof(v19));
  int v20 = 1065353216;
  char v18 = ZinIrOpLayerGraph::MoveOutgoingEdges((ZinIrOpLayerGraph *)a1, (uint64_t **)v26, v15, v19);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v19);
  if (v18) {
    return ZinIrOpLayerGraph::RemoveNode((ZinIrOpLayerGraph *)a1, v26, 0);
  }
  BOOL result = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
  if (result)
  {
    MirOpt::MergeGOCsToConvs();
    return 0;
  }
  return result;
}

void sub_2112BAA14(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, void *__p, uint64_t a18)
{
}

uint64_t ZinIrOpLayerGraph::MoveNodeBefore(ZinIrOpLayerGraph *this, size_t *a2, ZinIrOpLayer *a3)
{
  uint64_t v47 = *MEMORY[0x263EF8340];
  std::string::size_type v44 = a3;
  std::string v45 = a2;
  if (!std::__tree<ZinIrOpLayer *,ZinIrIdComparator<ZinIrOpLayer *>,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)this, (uint64_t *)&v45)|| !std::__tree<ZinIrOpLayer *,ZinIrIdComparator<ZinIrOpLayer *>,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)this, (uint64_t *)&v44))
  {
    return 0;
  }
  v36.__r_.__value_.__r.__words[0] = (std::string::size_type)&v44;
  uint64_t v4 = std::__hash_table<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::__unordered_map_hasher<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::__unordered_map_equal<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>>>::find<std::reference_wrapper<ZinIrOpLayer * const>>((void *)this + 8, (unint64_t **)&v36);
  if (v4) {
    uint64_t v5 = (char *)(v4 + 3);
  }
  else {
    uint64_t v5 = (char *)this + 104;
  }
  v36.__r_.__value_.__r.__words[0] = (std::string::size_type)&v45;
  __int16 v6 = std::__hash_table<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::__unordered_map_hasher<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::__unordered_map_equal<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>>>::find<std::reference_wrapper<ZinIrOpLayer * const>>((void *)this + 8, (unint64_t **)&v36);
  BOOL v7 = v6 + 3;
  if (!v6) {
    BOOL v7 = (void *)((char *)this + 104);
  }
  if (v7[1] - *v7 != 8) {
    return 0;
  }
  v36.__r_.__value_.__r.__words[0] = (std::string::size_type)&v45;
  int v8 = std::__hash_table<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::__unordered_map_hasher<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::__unordered_map_equal<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>>>::find<std::reference_wrapper<ZinIrOpLayer * const>>((void *)this + 3, (unint64_t **)&v36);
  BOOL v9 = v8 + 3;
  if (!v8) {
    BOOL v9 = (void *)((char *)this + 104);
  }
  if (v9[1] == *v9) {
    return 0;
  }
  uint64_t v10 = (uint64_t **)*((void *)v5 + 1);
  if (v10 == *(uint64_t ***)v5) {
    return 0;
  }
  std::set<ZinIrOpLayer *,ZinIrIdComparator<ZinIrOpLayer *>,std::allocator<ZinIrOpLayer *>>::set[abi:ne180100]<std::__wrap_iter<std::reference_wrapper<ZinIrOpLayer * const> const*>>((uint64_t)&v42, *(uint64_t ***)v5, v10);
  if (v42 != &v43)
  {
    std::string::basic_string[abi:ne180100]<0>(&v36, "move_before");
    uint64_t v11 = std::string::append(&v36, "_xfm", 4uLL);
    long long v12 = *(_OWORD *)&v11->__r_.__value_.__l.__data_;
    int64_t v41 = v11->__r_.__value_.__r.__words[2];
    long long v40 = v12;
    v11->__r_.__value_.__l.__size_ = 0;
    v11->__r_.__value_.__r.__words[2] = 0;
    v11->__r_.__value_.__r.__words[0] = 0;
    if (SHIBYTE(v36.__r_.__value_.__r.__words[2]) < 0) {
      operator delete(v36.__r_.__value_.__l.__data_);
    }
    (*(void (**)(size_t *, void, void))(*v45 + 32))(v45, 0, 0);
    uint64_t v13 = (ZinIrOpLayer *)v45;
    if (*((char *)v45 + 47) >= 0) {
      size_t v14 = *((unsigned __int8 *)v45 + 47);
    }
    else {
      size_t v14 = v45[4];
    }
    std::string::basic_string[abi:ne180100]((uint64_t)&v38, v14 + 1);
    if ((v38.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
      uint64_t v15 = &v38;
    }
    else {
      uint64_t v15 = (std::string *)v38.__r_.__value_.__r.__words[0];
    }
    if (v14)
    {
      if (*((char *)v13 + 47) >= 0) {
        BOOL v16 = (char *)v13 + 24;
      }
      else {
        BOOL v16 = (const void *)*((void *)v13 + 3);
      }
      memmove(v15, v16, v14);
    }
    *(_WORD *)((char *)&v15->__r_.__value_.__l.__data_ + v14) = 95;
    if (v41 >= 0) {
      unint64_t v17 = (const std::string::value_type *)&v40;
    }
    else {
      unint64_t v17 = (const std::string::value_type *)v40;
    }
    if (v41 >= 0) {
      std::string::size_type v18 = HIBYTE(v41);
    }
    else {
      std::string::size_type v18 = *((void *)&v40 + 1);
    }
    uint64_t v19 = std::string::append(&v38, v17, v18);
    long long v20 = *(_OWORD *)&v19->__r_.__value_.__l.__data_;
    v46.__r_.__value_.__r.__words[2] = v19->__r_.__value_.__r.__words[2];
    *(_OWORD *)&v46.__r_.__value_.__l.__data_ = v20;
    v19->__r_.__value_.__l.__size_ = 0;
    v19->__r_.__value_.__r.__words[2] = 0;
    v19->__r_.__value_.__r.__words[0] = 0;
    std::string::size_type v21 = std::string::append(&v46, "_tensor", 7uLL);
    long long v22 = *(_OWORD *)&v21->__r_.__value_.__l.__data_;
    v39.__r_.__value_.__r.__words[2] = v21->__r_.__value_.__r.__words[2];
    *(_OWORD *)&v39.__r_.__value_.__l.__data_ = v22;
    v21->__r_.__value_.__l.__size_ = 0;
    v21->__r_.__value_.__r.__words[2] = 0;
    v21->__r_.__value_.__r.__words[0] = 0;
    std::to_string(&v37, 0);
    if ((v37.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
      long long v23 = &v37;
    }
    else {
      long long v23 = (std::string *)v37.__r_.__value_.__r.__words[0];
    }
    if ((v37.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
      std::string::size_type size = HIBYTE(v37.__r_.__value_.__r.__words[2]);
    }
    else {
      std::string::size_type size = v37.__r_.__value_.__l.__size_;
    }
    long long v25 = std::string::append(&v39, (const std::string::value_type *)v23, size);
    long long v26 = *(_OWORD *)&v25->__r_.__value_.__l.__data_;
    v36.__r_.__value_.__r.__words[2] = v25->__r_.__value_.__r.__words[2];
    *(_OWORD *)&v36.__r_.__value_.__l.__data_ = v26;
    v25->__r_.__value_.__l.__size_ = 0;
    v25->__r_.__value_.__r.__words[2] = 0;
    v25->__r_.__value_.__r.__words[0] = 0;
    ZinIrTensor::CreateTensor();
  }
  long long v29 = (uint64_t **)v45;
  v36.__r_.__value_.__r.__words[0] = (std::string::size_type)&v45;
  uint64_t v30 = std::__hash_table<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::__unordered_map_hasher<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::__unordered_map_equal<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>>>::find<std::reference_wrapper<ZinIrOpLayer * const>>((void *)this + 8, (unint64_t **)&v36);
  uint64_t v31 = (ZinIrOpLayer ****)(v30 + 3);
  if (!v30) {
    uint64_t v31 = (ZinIrOpLayer ****)((char *)this + 104);
  }
  uint64_t v32 = ***v31;
  memset(v34, 0, sizeof(v34));
  int v35 = 1065353216;
  int v33 = ZinIrOpLayerGraph::MoveOutgoingEdges(this, v29, v32, v34);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v34);
  uint64_t v27 = v33 & ZinIrOpLayerGraph::RemoveNode(this, (ZinIrOpLayer *)v45, 0) & 1;
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v42, v43);
  return v27;
}

void sub_2112BB0B4(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, char a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, void *a17, void *__p, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,void *a23,uint64_t a24,int a25,__int16 a26,char a27,char a28,void *a29,uint64_t a30,int a31,__int16 a32,char a33,char a34,void *a35,uint64_t a36,int a37,__int16 a38,char a39,char a40,uint64_t a41,uint64_t a42,uint64_t a43)
{
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&a11);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy(v43 - 168, *(void **)(v43 - 160));
  _Unwind_Resume(a1);
}

void sub_2112BB22C(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, int a19, __int16 a20,char a21,char a22)
{
  if (a22 < 0) {
    JUMPOUT(0x2112BB214);
  }
  JUMPOUT(0x2112BB218);
}

void sub_2112BB248()
{
}

uint64_t ZinIrOpLayerGraph::SwapNodes(ZinIrOpLayerGraph *this, ZinIrOpLayer *a2, ZinIrOpLayer *a3)
{
  long long v12 = a2;
  uint64_t v11 = a3;
  uint64_t result = ZinIrNgraph<ZinIrOpLayer *,ZinIrIdComparator<ZinIrOpLayer *>>::IsConnected((uint64_t)this, (unint64_t *)&v12, (uint64_t *)&v11);
  if (result)
  {
    if (*((void *)v12 + 12) - *((void *)v12 + 11) == 8)
    {
      uint64_t v5 = v11;
    }
    else
    {
      uint64_t v5 = v11;
      if (*((void *)v12 + 15) - *((void *)v12 + 14) == 8 && *((void *)v11 + 12) - *((void *)v11 + 11) != 8) {
        return 0;
      }
    }
    int v6 = ZinIrOpLayerGraph::RemoveEdge((uint64_t)this, (uint64_t)v12, (uint64_t)v5, 0xFFFFFFFFFFFFFFFFLL, 0xFFFFFFFFFFFFFFFFLL, 0);
    int v7 = ZinIrOpLayerGraph::MoveIncomingEdges(this, v12, v11);
    memset(v9, 0, sizeof(v9));
    int v10 = 1065353216;
    int v8 = ZinIrOpLayerGraph::MoveOutgoingEdges(this, (uint64_t **)v11, v12, v9);
    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v9);
    return v6 & v7 & v8 & ZinIrOpLayerGraph::AddEdge((uint64_t)this, (uint64_t)v11, (uint64_t)v12, 0xFFFFFFFFFFFFFFFFLL, 0xFFFFFFFFFFFFFFFFLL, 0);
  }
  return result;
}

void sub_2112BB364(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
}

uint64_t ZinIrOpLayerGraph::DebugPrint@<X0>(void *a1@<X8>)
{
  std::basic_stringstream<char,std::char_traits<char>,std::allocator<char>>::basic_stringstream[abi:ne180100]((uint64_t)v5);
  std::stringbuf::str[abi:ne180100]<std::allocator<char>>((uint64_t)v6, a1);
  v5[0] = *MEMORY[0x263F8C2B8];
  uint64_t v3 = *(void *)(MEMORY[0x263F8C2B8] + 72);
  *(void *)((char *)v5 + *(void *)(v5[0] - 24)) = *(void *)(MEMORY[0x263F8C2B8] + 64);
  v5[2] = v3;
  v6[0] = MEMORY[0x263F8C318] + 16;
  if (v7 < 0) {
    operator delete((void *)v6[8]);
  }
  std::streambuf::~streambuf();
  std::iostream::~basic_iostream();
  return MEMORY[0x21667D2B0](&v8);
}

void sub_2112BB4D4(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
}

void ZinIrOpLayerGraph::CloneSubGraph(uint64_t a1@<X8>)
{
  *(void *)(a1 + std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = 0;
  *(_OWORD *)a1 = 0u;
  *(_OWORD *)(a1 + 16) = 0u;
  *(_DWORD *)(a1 + 40) = 1065353216;
  operator new();
}

void sub_2112BBA84(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, void *a17, void *a18, int a19, __int16 a20,char a21,char a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,void *__p,uint64_t a30,int a31,__int16 a32,char a33,char a34,void *a35,uint64_t a36,int a37,__int16 a38,char a39,char a40)
{
  ZinIrClonedGraphInfo::~ZinIrClonedGraphInfo(v40);
  _Unwind_Resume(a1);
}

uint64_t std::set<ZinIrOpLayer *,ZinIrIdComparator<ZinIrOpLayer *>,std::allocator<ZinIrOpLayer *>>::set[abi:ne180100]<std::__wrap_iter<std::reference_wrapper<ZinIrOpLayer * const> const*>>(uint64_t a1, uint64_t **a2, uint64_t **a3)
{
  *(void *)(a1 + 8) = 0;
  uint64_t v4 = (void *)(a1 + 8);
  *(void *)(a1 + 16) = 0;
  *(void *)a1 = a1 + 8;
  if (a2 != a3)
  {
    int v6 = a2;
    do
      std::__tree<ZinIrOpLayer *,ZinIrIdComparator<ZinIrOpLayer *>,std::allocator<ZinIrOpLayer *>>::__emplace_hint_unique_impl<std::reference_wrapper<ZinIrOpLayer * const> const&>((uint64_t **)a1, v4, v6++);
    while (v6 != a3);
  }
  return a1;
}

void sub_2112BBC38(_Unwind_Exception *a1)
{
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy(v1, *(void **)(v1 + 8));
  _Unwind_Resume(a1);
}

uint64_t *std::__tree<ZinIrOpLayer *,ZinIrIdComparator<ZinIrOpLayer *>,std::allocator<ZinIrOpLayer *>>::__emplace_hint_unique_impl<std::reference_wrapper<ZinIrOpLayer * const> const&>(uint64_t **a1, void *a2, uint64_t **a3)
{
  int v6 = (uint64_t *)operator new(0x28uLL);
  v6[4] = **a3;
  char v7 = (uint64_t **)std::__tree<ZinIrTensor *,ZinIrIdComparator<ZinIrTensor *>,std::allocator<ZinIrTensor *>>::__find_equal<ZinIrTensor *>(a1, a2, &v11, &v10, v6 + 4);
  uint64_t v8 = *v7;
  if (*v7)
  {
    operator delete(v6);
    return v8;
  }
  else
  {
    std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::__insert_node_at(a1, v11, v7, v6);
  }
  return v6;
}

void sub_2112BBCE8(_Unwind_Exception *a1)
{
  operator delete(v1);
  _Unwind_Resume(a1);
}

void ZinIrOpLayerGraph::ReplaceNode()
{
  *(_WORD *)uint64_t v0 = 0;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "Failed in moving incoming edges.\n", v0, 2u);
}

void ZinNEDualSourceElementWiseLayer::ZinNEDualSourceElementWiseLayer()
{
}

void sub_2112BBE74(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, std::__shared_weak_count *a8, ...)
{
  va_start(va, a8);
  if (a8) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a8);
  }
  ZinLayerNormLayer::ZinLayerNormLayer((uint64_t *)va);
  _Unwind_Resume(a1);
}

uint64_t ZinNEDualSourceElementWiseLayer::Lower()
{
  return 0;
}

uint64_t ZinNEDualSourceElementWiseLayer::LowerEngineCore()
{
  return 0;
}

__n128 ZinNEDualSourceElementWiseLayer::ExecutionOrderSort@<Q0>(int8x16_t *this@<X0>, void *a2@<X8>)
{
  uint64_t v4 = this[23].i64[0];
  a2[1] = 0;
  a2[2] = 0;
  *a2 = 0;
  uint64_t v5 = (char *)operator new(0x28uLL);
  a2[1] = v5 + 40;
  a2[2] = v5 + 40;
  *(void *)uint64_t v5 = v4;
  *(int8x16_t *)(v5 + 8) = vextq_s8(this[27], this[27], 8uLL);
  __n128 result = (__n128)this[24];
  *(__n128 *)(v5 + 24) = result;
  *a2 = v5;
  return result;
}

void ZinNEDualSourceElementWiseLayer::Clone(void *a1, uint64_t a2, const void **a3)
{
  uint64_t v5 = *(void *)(*(void *)a2 + 16);
  uint64_t v6 = a1[46];
  if (*((char *)a3 + 23) >= 0) {
    size_t v7 = *((unsigned __int8 *)a3 + 23);
  }
  else {
    size_t v7 = (size_t)a3[1];
  }
  uint64_t v8 = __p;
  std::string::basic_string[abi:ne180100]((uint64_t)__p, v7 + 12);
  if (v27 < 0) {
    uint64_t v8 = (void **)__p[0];
  }
  if (v7)
  {
    if (*((char *)a3 + 23) >= 0) {
      BOOL v9 = a3;
    }
    else {
      BOOL v9 = *a3;
    }
    memmove(v8, v9, v7);
  }
  strcpy((char *)v8 + v7, "_ibroadcast1");
  ZinANELayer::CloneEncapsulatedLayer<ZinRCASLayer *>(v5, v6, (const void **)__p);
  if (v27 < 0) {
    operator delete(__p[0]);
  }
  uint64_t v10 = a1[55];
  if (*((char *)a3 + 23) >= 0) {
    size_t v11 = *((unsigned __int8 *)a3 + 23);
  }
  else {
    size_t v11 = (size_t)a3[1];
  }
  std::string::basic_string[abi:ne180100]((uint64_t)__p, v11 + 12);
  if (v27 >= 0) {
    long long v12 = __p;
  }
  else {
    long long v12 = (void **)__p[0];
  }
  if (v11)
  {
    if (*((char *)a3 + 23) >= 0) {
      uint64_t v13 = a3;
    }
    else {
      uint64_t v13 = *a3;
    }
    memmove(v12, v13, v11);
  }
  strcpy((char *)v12 + v11, "_ibroadcast2");
  ZinANELayer::CloneEncapsulatedLayer<ZinRCASLayer *>(v5, v10, (const void **)__p);
  if (v27 < 0) {
    operator delete(__p[0]);
  }
  uint64_t v14 = a1[54];
  if (*((char *)a3 + 23) >= 0) {
    size_t v15 = *((unsigned __int8 *)a3 + 23);
  }
  else {
    size_t v15 = (size_t)a3[1];
  }
  BOOL v16 = __p;
  std::string::basic_string[abi:ne180100]((uint64_t)__p, v15 + 3);
  if (v27 < 0) {
    BOOL v16 = (void **)__p[0];
  }
  if (v15)
  {
    if (*((char *)a3 + 23) >= 0) {
      unint64_t v17 = a3;
    }
    else {
      unint64_t v17 = *a3;
    }
    memmove(v16, v17, v15);
  }
  *(_DWORD *)((char *)v16 + v15) = 7824735;
  ZinANELayer::CloneEncapsulatedLayer<ZinRCASLayer *>(v5, v14, (const void **)__p);
  if (v27 < 0) {
    operator delete(__p[0]);
  }
  uint64_t v18 = a1[48];
  if (*((char *)a3 + 23) >= 0) {
    size_t v19 = *((unsigned __int8 *)a3 + 23);
  }
  else {
    size_t v19 = (size_t)a3[1];
  }
  long long v20 = __p;
  std::string::basic_string[abi:ne180100]((uint64_t)__p, v19 + 4);
  if (v27 < 0) {
    long long v20 = (void **)__p[0];
  }
  if (v19)
  {
    if (*((char *)a3 + 23) >= 0) {
      std::string::size_type v21 = a3;
    }
    else {
      std::string::size_type v21 = *a3;
    }
    memmove(v20, v21, v19);
  }
  strcpy((char *)v20 + v19, "_goc");
  ZinANELayer::CloneEncapsulatedLayer<ZinRCASLayer *>(v5, v18, (const void **)__p);
  if (v27 < 0) {
    operator delete(__p[0]);
  }
  uint64_t v22 = a1[49];
  if (*((char *)a3 + 23) >= 0) {
    size_t v23 = *((unsigned __int8 *)a3 + 23);
  }
  else {
    size_t v23 = (size_t)a3[1];
  }
  uint64_t v24 = __p;
  std::string::basic_string[abi:ne180100]((uint64_t)__p, v23 + 11);
  if (v27 < 0) {
    uint64_t v24 = (void **)__p[0];
  }
  if (v23)
  {
    if (*((char *)a3 + 23) >= 0) {
      long long v25 = a3;
    }
    else {
      long long v25 = *a3;
    }
    memmove(v24, v25, v23);
  }
  strcpy((char *)v24 + v23, "_activation");
  ZinANELayer::CloneEncapsulatedLayer<ZinRCASLayer *>(v5, v22, (const void **)__p);
  if (v27 < 0) {
    operator delete(__p[0]);
  }
  operator new();
}

void sub_2112BC400(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, void *__p, uint64_t a14, int a15, __int16 a16, char a17, char a18)
{
}

uint64_t ZinNEDualSourceElementWiseLayer::DebugDetailPrint@<X0>(void *a1@<X8>)
{
  std::basic_stringstream<char,std::char_traits<char>,std::allocator<char>>::basic_stringstream[abi:ne180100]((uint64_t)v5);
  std::stringbuf::str[abi:ne180100]<std::allocator<char>>((uint64_t)v6, a1);
  v5[0] = *MEMORY[0x263F8C2B8];
  uint64_t v3 = *(void *)(MEMORY[0x263F8C2B8] + 72);
  *(void *)((char *)v5 + *(void *)(v5[0] - 24)) = *(void *)(MEMORY[0x263F8C2B8] + 64);
  v5[2] = v3;
  v6[0] = MEMORY[0x263F8C318] + 16;
  if (v7 < 0) {
    operator delete((void *)v6[8]);
  }
  std::streambuf::~streambuf();
  std::iostream::~basic_iostream();
  return MEMORY[0x21667D2B0](&v8);
}

void sub_2112BC5E0(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
}

void ZinNEDualSourceElementWiseLayer::SpatialSplitCopy(ZinNEDualSourceElementWiseLayer *this, const TiledLayerTensorRegions *a2)
{
}

void sub_2112BC6D0(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11, int a12, __int16 a13, char a14, char a15, uint64_t a16, std::__shared_weak_count *a17)
{
  if (a15 < 0) {
    operator delete(__p);
  }
  if (a17) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a17);
  }
  size_t v19 = *(std::__shared_weak_count **)(v17 - 24);
  if (v19) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v19);
  }
  _Unwind_Resume(exception_object);
}

ZinIrKernel *ZinNEDualSourceElementWiseLayer::GetFusedKernel@<X0>(ZinIrKernel *result@<X0>, uint64_t *a2@<X8>)
{
  uint64_t v2 = result;
  char v27 = 0;
  if (*(_DWORD *)(*(void *)(*((void *)result + 54) + 64) + 12) == 4)
  {
    uint64_t v4 = (*(uint64_t (**)(ZinIrKernel *, void, void))(*(void *)result + 32))(result, 0, 0);
    int v26 = 0;
    v24.__r_.__value_.__r.__words[0] = *(void *)(v4 + 56);
    *(_OWORD *)&v24.__r_.__value_.__r.__words[1] = xmmword_211ED2790;
    int64x2_t v25 = vdupq_n_s64(1uLL);
    uint64_t v5 = (*(uint64_t (**)(ZinIrKernel *, void, void))(*(void *)v2 + 32))(v2, 0, 0);
    CreateElementWiseSubCoefficients((uint64_t)v24.__r_.__value_.__l.__data_, *(_DWORD *)(v5 + 88), &v26, &v20);
    if (*((char *)v2 + 47) < 0) {
      std::string::__init_copy_ctor_external(&v23, *((const std::string::value_type **)v2 + 3), *((void *)v2 + 4));
    }
    else {
      std::string v23 = *(std::string *)((unsigned char *)v2 + 1);
    }
    __p[0] = 0;
    std::make_unique[abi:ne180100]<ZinIrWeight,std::shared_ptr<ZinIrConstData> &,decltype(nullptr),ZinKernelFormat &,ZinKernelDimensions &>();
  }
  uint64_t v6 = *((void *)result + 48);
  if (v6)
  {
    uint64_t v8 = *(void *)(v6 + 136);
    char v7 = (char **)(v6 + 136);
    *a2 = 0;
    if (v8)
    {
      BOOL v9 = *v7;
      if ((*v7)[23] >= 0) {
        size_t v10 = (*v7)[23];
      }
      else {
        size_t v10 = *((void *)*v7 + 1);
      }
      size_t v11 = &v24;
      std::string::basic_string[abi:ne180100]((uint64_t)&v24, v10 + 1);
      if ((v24.__r_.__value_.__r.__words[2] & 0x8000000000000000) != 0) {
        size_t v11 = (std::string *)v24.__r_.__value_.__r.__words[0];
      }
      if (v10)
      {
        if (v9[23] >= 0) {
          long long v12 = v9;
        }
        else {
          long long v12 = *(char **)v9;
        }
        memmove(v11, v12, v10);
      }
      *(_WORD *)((char *)&v11->__r_.__value_.__l.__data_ + v1std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = 95;
      std::string::basic_string[abi:ne180100]<0>(&v20, "fuse_negoc_kernel");
      uint64_t v13 = std::string::append(&v20, "_xfm", 4uLL);
      long long v14 = *(_OWORD *)&v13->__r_.__value_.__l.__data_;
      v23.__r_.__value_.__r.__words[2] = v13->__r_.__value_.__r.__words[2];
      *(_OWORD *)&v23.__r_.__value_.__l.__data_ = v14;
      v13->__r_.__value_.__l.__size_ = 0;
      v13->__r_.__value_.__r.__words[2] = 0;
      v13->__r_.__value_.__r.__words[0] = 0;
      if ((v23.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
        size_t v15 = &v23;
      }
      else {
        size_t v15 = (std::string *)v23.__r_.__value_.__r.__words[0];
      }
      if ((v23.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
        std::string::size_type size = HIBYTE(v23.__r_.__value_.__r.__words[2]);
      }
      else {
        std::string::size_type size = v23.__r_.__value_.__l.__size_;
      }
      uint64_t v17 = std::string::append(&v24, (const std::string::value_type *)v15, size);
      long long v18 = *(_OWORD *)&v17->__r_.__value_.__l.__data_;
      std::string::size_type v22 = v17->__r_.__value_.__r.__words[2];
      *(_OWORD *)long long __p = v18;
      v17->__r_.__value_.__l.__size_ = 0;
      v17->__r_.__value_.__r.__words[2] = 0;
      v17->__r_.__value_.__r.__words[0] = 0;
      std::make_unique[abi:ne180100]<ZinIrKernel,std::unique_ptr<ZinIrKernel> const&,std::string>();
    }
    if (*a2)
    {
      uint64_t v19 = *((void *)result + 33);
      if (v19) {
        ZinIrKernel::SetSmallSourceMode(*a2, *(_DWORD *)(v19 + 144));
      }
    }
    __n128 result = v27;
    char v27 = 0;
    if (result)
    {
      ZinIrKernel::~ZinIrKernel(result);
      return (ZinIrKernel *)MEMORY[0x21667D3C0]();
    }
  }
  else
  {
    *a2 = 0;
  }
  return result;
}

void sub_2112BCD20(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, void *a9, uint64_t a10, int a11, __int16 a12, char a13, char a14, uint64_t a15, uint64_t a16, uint64_t a17, void *__p, uint64_t a19, int a20,__int16 a21,char a22,char a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33,uint64_t a34)
{
  if (a23 < 0) {
    operator delete(__p);
  }
  if (*(char *)(v35 - 121) < 0) {
    operator delete(*(void **)(v35 - 144));
  }
  if (a14 < 0) {
    operator delete(a9);
  }
  if (*(char *)(v35 - 97) < 0) {
    operator delete(*(void **)(v35 - 120));
  }
  std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](v34, 0);
  std::unique_ptr<ZinIrKernel>::reset[abi:ne180100]((ZinIrKernel **)(v35 - 72), 0);
  _Unwind_Resume(a1);
}

uint64_t ZinNEDualSourceElementWiseLayer::ComputeMirInfoCore(uint64_t a1, uint64_t a2, void *a3)
{
  (*(void (**)(void *__return_ptr))(*(void *)a1 + 376))(v9);
  uint64_t v5 = (*(uint64_t (**)(uint64_t, void, void))(*(void *)a1 + 32))(a1, 0, 0);
  uint64_t v6 = (void *)*a3;
  uint64_t v7 = v9[0];
  void v6[10] = v9[1];
  v6[11] = *(void *)(v5 + 56);
  v6[13] = v7;
  return 0;
}

uint64_t ZinChannelToSpaceUtils::CreateFusedDeconv(uint64_t a1, void *a2, uint64_t a3, void *a4, uint64_t a5, uint64_t a6)
{
  long long v65 = (int *)a4[8];
  uint64_t v10 = (*(uint64_t (**)(void *, void, void))(*a2 + 32))(a2, 0, 0);
  size_t v11 = (int *)a2[17];
  ZinIrKernel::GetWeightDimensions((ZinIrKernel *)v11, (uint64_t)&v82);
  uint64_t v81 = 0;
  long long v79 = 0u;
  long long v80 = 0u;
  long long v64 = a2;
  uint64_t v12 = (*(uint64_t (**)(void *, void, void))(*a2 + 32))(a2, 0, 0);
  uint64_t v61 = a6;
  int ShuffledKernelDimensions = ZinPixelShuffleUtils::GetShuffledKernelDimensions((uint64_t *)&v82, v65 + 3, a6, *(_DWORD *)(v12 + 88), (uint64_t *)&v79);
  memset(&v78, 0, sizeof(v78));
  std::string::size_type v62 = v11;
  uint64_t v63 = v10;
  char FusedPadding = ZinPixelShuffleUtils::GetFusedPadding(a3, v10 + 48, (uint64_t)&v82, v11 + 88, &v79, v65 + 3, (int *)&v78);
  if (ShuffledKernelDimensions && (FusedPadding & 1) != 0)
  {
    uint64_t v59 = a1;
    uint64_t v15 = v65[3];
    uint64_t v16 = v65[4];
    details::ZinIrMappedData_Impl<ZinKernelPosition>::ZinIrMappedData_Impl((uint64_t)&v74, *((void *)&v79 + 1) * v79 * v80 * *((void *)&v80 + 1) * v81);
    uint64_t v17 = v79;
    if ((uint64_t)v79 >= 1)
    {
      uint64_t v18 = 0;
      uint64_t v19 = 0;
      uint64_t v20 = *((void *)&v79 + 1);
      do
      {
        if (v20 >= 1)
        {
          int64_t v21 = 0;
          uint64_t v22 = v80;
          do
          {
            if (v22 >= 1)
            {
              uint64_t v23 = 0;
              uint64_t v24 = *((void *)&v80 + 1);
              do
              {
                uint64_t v25 = v23 + 1;
                if (v24 >= 1)
                {
                  uint64_t v26 = 0;
                  uint64_t v66 = v19;
                  uint64_t v27 = 40 * v19;
                  do
                  {
                    uint64_t v28 = v79;
                    int v29 = (*(uint64_t (**)(uint64_t))(*(void *)details::ZinIrMappedDataBase_Impl::backing_
                                                             + 24))(details::ZinIrMappedDataBase_Impl::backing_);
                    uint64_t v30 = (std::string *)(v77 + v27);
                    if (!v29) {
                      uint64_t v30 = &v74;
                    }
                    uint64_t v31 = v26 / v15;
                    v30->__r_.__value_.__r.__words[0] = v18 + (++v26 % v15 + v25 % v16 * v15) * v28;
                    v30->__r_.__value_.__l.__size_ = v21;
                    v30->__r_.__value_.__r.__words[2] = v23 / v16;
                    v30[1].__r_.__value_.__r.__words[0] = v31;
                    v30[1].__r_.__value_.__l.__size_ = 0;
                    uint64_t v24 = *((void *)&v80 + 1);
                    v27 += 40;
                  }
                  while (*((uint64_t *)&v80 + 1) > v26);
                  uint64_t v22 = v80;
                  uint64_t v19 = v66 + v26;
                }
                ++v23;
              }
              while (v22 > v25);
              uint64_t v20 = *((void *)&v79 + 1);
            }
            ++v21;
          }
          while (v20 > v21);
          uint64_t v17 = v79;
        }
        ++v18;
      }
      while (v17 > v18);
    }
    uint64_t v32 = v64[17];
    if (*(char *)(v63 + 47) >= 0) {
      size_t v33 = *(unsigned __int8 *)(v63 + 47);
    }
    else {
      size_t v33 = *(void *)(v63 + 32);
    }
    uint64_t v34 = &v71;
    std::string::basic_string[abi:ne180100]((uint64_t)&v71, v33 + 1);
    if ((v71.__r_.__value_.__r.__words[2] & 0x8000000000000000) != 0) {
      uint64_t v34 = (std::string *)v71.__r_.__value_.__r.__words[0];
    }
    if (v33)
    {
      if (*(char *)(v63 + 47) >= 0) {
        uint64_t v35 = (const void *)(v63 + 24);
      }
      else {
        uint64_t v35 = *(const void **)(v63 + 24);
      }
      memmove(v34, v35, v33);
    }
    *(_WORD *)((char *)&v34->__r_.__value_.__l.__data_ + v33) = 95;
    std::string::basic_string[abi:ne180100]<0>(&v68, "ctos_kernel");
    std::string v36 = std::string::append(&v68, "_xfm", 4uLL);
    long long v37 = *(_OWORD *)&v36->__r_.__value_.__l.__data_;
    int64_t v70 = v36->__r_.__value_.__r.__words[2];
    *(_OWORD *)long long v69 = v37;
    v36->__r_.__value_.__l.__size_ = 0;
    v36->__r_.__value_.__r.__words[2] = 0;
    v36->__r_.__value_.__r.__words[0] = 0;
    if (v70 >= 0) {
      std::string v38 = v69;
    }
    else {
      std::string v38 = (void **)v69[0];
    }
    if (v70 >= 0) {
      std::string::size_type v39 = HIBYTE(v70);
    }
    else {
      std::string::size_type v39 = (std::string::size_type)v69[1];
    }
    long long v40 = std::string::append(&v71, (const std::string::value_type *)v38, v39);
    long long v41 = *(_OWORD *)&v40->__r_.__value_.__l.__data_;
    std::string::size_type v73 = v40->__r_.__value_.__r.__words[2];
    *(_OWORD *)long long __p = v41;
    v40->__r_.__value_.__l.__size_ = 0;
    v40->__r_.__value_.__r.__words[2] = 0;
    v40->__r_.__value_.__r.__words[0] = 0;
    int v42 = v62[82];
    int v43 = v62[83];
    int v44 = v62[84];
    int v46 = v65[3];
    int v45 = v65[4];
    uint64_t v47 = v65[5];
    KernelSparsityCache = (ZinKernelSparsityCache *)ZinIrContext::GetKernelSparsityCache((ZinIrContext *)v64[2]);
    ZinIrKernel::ShuffleKernel(v32, (uint64_t)&v74, v42, v43, v44, v46, v45, &v67, v47, (uint64_t)&v79, v61, KernelSparsityCache, (long long *)&v78, 1, v62[94]);
    if (SHIBYTE(v73) < 0) {
      operator delete(__p[0]);
    }
    if (SHIBYTE(v70) < 0) {
      operator delete(v69[0]);
    }
    if (SHIBYTE(v68.__r_.__value_.__r.__words[2]) < 0) {
      operator delete(v68.__r_.__value_.__l.__data_);
    }
    if (SHIBYTE(v71.__r_.__value_.__r.__words[2]) < 0) {
      operator delete(v71.__r_.__value_.__l.__data_);
    }
    details::ZinIrMappedData_Impl<ZinKernelPosition>::~ZinIrMappedData_Impl((uint64_t)&v74);
    if (v67)
    {
      (*(void (**)(void *, void, void))(*a4 + 32))(a4, 0, 0);
      std::string v49 = (std::string *)std::string::basic_string[abi:ne180100]<0>(&v79, "ctos_fused");
      std::string v50 = std::string::append(v49, "_xfm", 4uLL);
      long long v51 = *(_OWORD *)&v50->__r_.__value_.__l.__data_;
      v74.__r_.__value_.__r.__words[2] = v50->__r_.__value_.__r.__words[2];
      *(_OWORD *)&v74.__r_.__value_.__l.__data_ = v51;
      v50->__r_.__value_.__l.__size_ = 0;
      v50->__r_.__value_.__r.__words[2] = 0;
      v50->__r_.__value_.__r.__words[0] = 0;
      char v52 = std::string::insert(&v74, 0, "_", 1uLL);
      long long v53 = *(_OWORD *)&v52->__r_.__value_.__l.__data_;
      int64_t v83 = v52->__r_.__value_.__r.__words[2];
      long long v82 = v53;
      v52->__r_.__value_.__l.__size_ = 0;
      v52->__r_.__value_.__r.__words[2] = 0;
      v52->__r_.__value_.__r.__words[0] = 0;
      if (SHIBYTE(v74.__r_.__value_.__r.__words[2]) < 0) {
        operator delete(v74.__r_.__value_.__l.__data_);
      }
      if (SBYTE7(v80) < 0) {
        operator delete((void *)v79);
      }
      (*(void (**)(std::string *__return_ptr))(*(void *)v59 + 16))(&v78);
      if (v83 >= 0) {
        std::string v54 = (const std::string::value_type *)&v82;
      }
      else {
        std::string v54 = (const std::string::value_type *)v82;
      }
      if (v83 >= 0) {
        std::string::size_type v55 = HIBYTE(v83);
      }
      else {
        std::string::size_type v55 = *((void *)&v82 + 1);
      }
      long long v56 = std::string::append(&v78, v54, v55);
      long long v57 = *(_OWORD *)&v56->__r_.__value_.__l.__data_;
      *(void *)&long long v80 = *((void *)&v56->__r_.__value_.__l + 2);
      long long v79 = v57;
      v56->__r_.__value_.__l.__size_ = 0;
      v56->__r_.__value_.__r.__words[2] = 0;
      v56->__r_.__value_.__r.__words[0] = 0;
      *(_OWORD *)&v71.__r_.__value_.__l.__data_ = 0uLL;
      LODWORD(v74.__r_.__value_.__l.__data_) = 0;
      uint64_t v75 = 0;
      *(_OWORD *)&v74.__r_.__value_.__r.__words[1] = 0uLL;
      int v76 = 0;
      ZinIrTensor::CreateTensor();
    }
  }
  return 0;
}

void sub_2112BD638(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,std::__shared_weak_count *a25,uint64_t a26,ZinIrKernel *a27,void *a28,uint64_t a29,int a30,__int16 a31,char a32,char a33,void *a34,uint64_t a35,int a36,__int16 a37,char a38,char a39,void *a40,uint64_t a41,int a42,__int16 a43,char a44,char a45,void *a46,std::__shared_weak_count *a47,int a48,__int16 a49,char a50,char a51,uint64_t a52,void *__p,uint64_t a54,int a55,__int16 a56,char a57,char a58)
{
  if (a58 < 0) {
    operator delete(__p);
  }
  if (*(char *)(v59 - 169) < 0) {
    operator delete(*(void **)(v59 - 192));
  }
  if (a25) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a25);
  }
  uint64_t v61 = *(void *)(v59 - 216);
  *(void *)(v59 - 216) = 0;
  if (v61) {
    (*(void (**)(uint64_t))(*(void *)v61 + 8))(v61);
  }
  MEMORY[0x21667D3C0](v58, 0x10B3C4024B96488);
  if (a47) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a47);
  }
  if (*(char *)(v59 - 121) < 0) {
    operator delete(*(void **)(v59 - 144));
  }
  std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a27, 0);
  _Unwind_Resume(a1);
}

void ZinMirMemCacheStrategyNone::ZinMirMemCacheStrategyNone(ZinMirMemCacheStrategyNone *this, uint64_t a2, uint64_t a3, char a4, BOOL a5, char a6, char a7)
{
  ZinMirMemCacheStrategyBase::ZinMirMemCacheStrategyBase(this, a2, a3, a4, a5, a6, a7);
  void *v7 = &unk_26C351B88;
}

void ZinMirMemCacheStrategyNone::~ZinMirMemCacheStrategyNone(ZinMirMemCacheStrategyNone *this)
{
  ZinIrHalH13g::~ZinIrHalH13g(this);

  JUMPOUT(0x21667D3C0);
}

uint64_t ZinMirMemCacheStrategyNone::PerformAllocation(ZinMirMemCacheStrategyNone *this, const ZinIrControlFlowGraph *a2)
{
  return 0;
}

uint64_t ZinParseRingBufferReaderUnit(const __CFDictionary *a1, ZinIrRingBufferReaderUnitInfo *a2, CFArrayRef *a3)
{
  CFDictionaryRef Value = (const __CFDictionary *)CFDictionaryGetValue(a1, @"Params");
  if (!Value || (CFDictionaryRef v6 = Value, v7 = CFGetTypeID(Value), v7 != CFDictionaryGetTypeID()))
  {
    CFStringRef v11 = @"InvalidParams";
LABEL_10:
    ZinIrUnitStatus::SetError(a3, v11);
    return 3;
  }
  CFArrayRef v8 = (const __CFArray *)CFDictionaryGetValue(v6, @"RingBufferReaderOffsetInfo");
  if (!v8
    || (CFArrayRef v9 = v8, v10 = CFGetTypeID(v8), v10 != CFArrayGetTypeID())
    || ZinParseRingBufferOffset(v9, a2, a3))
  {
    if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
      ZinParseRingBufferReaderUnit();
    }
    CFStringRef v11 = @"InvalidUnitRingBufferOffset";
    goto LABEL_10;
  }
  uint64_t result = ZinParseRingBufferReaderOutputSize(v6, a2, a3);
  if (result)
  {
    CFStringRef v11 = @"InvalidUnitRingBufferReaderOutputSizeInfo";
    goto LABEL_10;
  }
  return result;
}

void ZinParseRingBufferReaderUnit()
{
  *(_WORD *)uint64_t v0 = 0;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "Failed to retrieve the array containing offset info for RingBufferReader.\n", v0, 2u);
}

void ZinAneTdHw_v11::ZinAneTdHw_v11(ZinAneTdHw_v11 *this, unsigned int a2, char a3, int a4)
{
  *((void *)this + 128) = 0;
  *((_OWORD *)this + 63) = 0u;
  bzero(this, 0x3E5uLL);
  *((unsigned char *)this + 996) = a3;
  *((_DWORD *)this + 25std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = a4;
}

uint64_t ZinAneTdHw_v11::GetRegisterValueFromAddress(ZinAneTdHw_v11 *this, unsigned int a2)
{
  if (a2 <= 0x4B)
  {
    uint64_t v2 = (char *)this + 484;
    return *(unsigned int *)&v2[a2 & 0xFFFFFFFC];
  }
  unsigned int v3 = a2 - 1280;
  if (a2 - 1280 <= 0x63)
  {
    uint64_t v2 = (char *)this + 788;
LABEL_13:
    a2 = v3;
    return *(unsigned int *)&v2[a2 & 0xFFFFFFFC];
  }
  unsigned int v3 = a2 - 2304;
  if (a2 - 2304 <= 0x13)
  {
    uint64_t v2 = (char *)this + 896;
    goto LABEL_13;
  }
  unsigned int v3 = a2 - 3328;
  if (a2 - 3328 <= 0x13)
  {
    uint64_t v2 = (char *)this + 924;
    goto LABEL_13;
  }
  unsigned int v3 = a2 - 4352;
  if (a2 - 4352 <= 0xD3)
  {
    uint64_t v2 = (char *)this + 568;
    goto LABEL_13;
  }
  unsigned int v3 = a2 - 5376;
  if (a2 - 5376 <= 0x23)
  {
    uint64_t v2 = (char *)this + 952;
    goto LABEL_13;
  }
  a2 -= 6400;
  if (a2 <= 0x117)
  {
    uint64_t v2 = (char *)this + 36;
    return *(unsigned int *)&v2[a2 & 0xFFFFFFFC];
  }
  return 0;
}

uint64_t ZinAneTdHw_v11::AddRelocInfo(uint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
  unsigned int v15 = a4;
  unsigned int v16 = a3;
  unsigned int v14 = a5;
  unsigned __int8 v13 = a6;
  unsigned __int8 v12 = a7;
  unsigned __int8 v11 = a8;
  unint64_t v9 = a1[127];
  if (v9 >= a1[128])
  {
    uint64_t result = std::vector<ZinAneRelocInfo>::__emplace_back_slow_path<std::string const&,unsigned int &,unsigned int &,ane_relocation_command_size_v11_t &,BOOL &,BOOL &,BOOL &>(a1 + 126, a2, &v16, &v15, &v14, &v13, &v12, &v11);
  }
  else
  {
    ZinAneRelocInfo::ZinAneRelocInfo(a1[127], a2, a3, a4, a5, a6, a7, a8);
    uint64_t result = v9 + 40;
    a1[127] = v9 + 40;
  }
  a1[127] = result;
  return result;
}

void sub_2112BDB58(_Unwind_Exception *a1)
{
  *(void *)(v1 + 1016) = v2;
  _Unwind_Resume(a1);
}

uint64_t ZinAneTdHw_v11::GetRelocInfos(ZinAneTdHw_v11 *this)
{
  return (uint64_t)this + 1008;
}

uint64_t ZinIrOpt::TopkGatherToTopk(void *a1, uint64_t a2)
{
  v29[1] = *MEMORY[0x263EF8340];
  std::string::basic_string[abi:ne180100]<0>(v20, "topk");
  v21[0] = &unk_26C330AD8;
  void v21[3] = v21;
  int v8 = 1;
  std::unordered_set<Attribute>::unordered_set((uint64_t)&v22, &v8, 1);
  std::string::basic_string[abi:ne180100]<0>(v23, "gather");
  v24[0] = &unk_26C330B30;
  _OWORD v24[3] = v24;
  int v7 = 1;
  std::unordered_set<Attribute>::unordered_set((uint64_t)v25, &v7, 1);
  unint64_t v9 = 0;
  uint64_t v10 = 0;
  unsigned __int8 v11 = 0;
  unsigned int v16 = &v9;
  char v17 = 0;
  unint64_t v9 = (char *)operator new(0xC0uLL);
  uint64_t v10 = (uint64_t)v9;
  unsigned __int8 v11 = v9 + 192;
  uint64_t v10 = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<ZinLinearPattern::AtomItemDesc>,ZinLinearPattern::AtomItemDesc const*,ZinLinearPattern::AtomItemDesc const*,ZinLinearPattern::AtomItemDesc*>((uint64_t)&v11, (uint64_t)v20, (uint64_t)v26, (uint64_t)v9);
  v19[0] = &unk_26C330B88;
  void v19[3] = v19;
  ZinLinearPattern::ZinLinearPattern(v26, &v9, a2, 0, v19, 0);
  std::allocate_shared[abi:ne180100]<ZinLinearPattern,std::allocator<ZinLinearPattern>,ZinLinearPattern,void>((uint64_t)v26, &v12);
  long long v28 = v12;
  long long v12 = 0uLL;
  unsigned int v14 = 0;
  unsigned int v15 = 0;
  unsigned __int8 v13 = 0;
  unsigned int v16 = (char **)&v13;
  char v17 = 0;
  unsigned __int8 v13 = operator new(0x10uLL);
  unsigned int v14 = v13;
  unsigned int v15 = v13 + 2;
  unsigned int v14 = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::shared_ptr<ZinPattern>>,std::shared_ptr<ZinPattern> const*,std::shared_ptr<ZinPattern> const*,std::shared_ptr<ZinPattern>*>((uint64_t)&v15, &v28, v29, v13);
  if (*((void *)&v28 + 1)) {
    std::__shared_weak_count::__release_shared[abi:ne180100](*((std::__shared_weak_count **)&v28 + 1));
  }
  if (*((void *)&v12 + 1)) {
    std::__shared_weak_count::__release_shared[abi:ne180100](*((std::__shared_weak_count **)&v12 + 1));
  }
  v26[0] = (void **)&unk_26C349BA8;
  unsigned int v16 = (char **)&v27;
  std::vector<ZinLinearPattern::AtomItemDesc>::__destroy_vector::operator()[abi:ne180100]((void ***)&v16);
  ZinPattern::~ZinPattern((ZinPattern *)v26);
  std::__function::__value_func<BOOL ()(ZinIrOpLayerGraph const*,ZinIrParameters const&,ZinPattern const*)>::~__value_func[abi:ne180100](v19);
  unsigned int v16 = &v9;
  std::vector<ZinLinearPattern::AtomItemDesc>::__destroy_vector::operator()[abi:ne180100]((void ***)&v16);
  for (uint64_t i = 0; i != -24; i -= 12)
  {
    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&v25[i * 8]);
    std::__function::__value_func<MatchStatus ()(MatchParams const&)>::~__value_func[abi:ne180100](&v24[i]);
    if (SHIBYTE(v23[i + 2]) < 0) {
      operator delete((void *)v23[i]);
    }
  }
  v18[0] = &unk_26C330BE0;
  v18[1] = &v13;
  uint64_t v18[3] = v18;
  uint64_t v5 = ZinIrControlFlowGraph::TraverseForward(a1, (uint64_t)v18, 1);
  std::__function::__value_func<ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::~__value_func[abi:ne180100](v18);
  v26[0] = (void **)&v13;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100](v26);
  return v5;
}

void sub_2112BDE54(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33,uint64_t a34,uint64_t a35,uint64_t a36,uint64_t a37,uint64_t a38,uint64_t a39,uint64_t a40,uint64_t a41,uint64_t a42,uint64_t a43,uint64_t a44,uint64_t a45,uint64_t a46,uint64_t a47,uint64_t a48,uint64_t a49,uint64_t a50,uint64_t a51,uint64_t a52,void **a53)
{
}

void std::__function::__func<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0,std::allocator<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0>,MatchStatus ()(MatchParams const&)>::~__func()
{
}

void *std::__function::__func<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0,std::allocator<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0>,MatchStatus ()(MatchParams const&)>::__clone()
{
  uint64_t result = operator new(0x10uLL);
  void *result = &unk_26C330AD8;
  return result;
}

void std::__function::__func<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0,std::allocator<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0>,MatchStatus ()(MatchParams const&)>::__clone(uint64_t a1, void *a2)
{
  *a2 = &unk_26C330AD8;
}

uint64_t std::__function::__func<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0,std::allocator<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0>,MatchStatus ()(MatchParams const&)>::operator()(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = *(void *)(*(void *)(a2 + 8) + 64);
  BOOL v3 = *(_DWORD *)(v2 + 8) == 66 && *(unsigned __int8 *)(v2 + 56) != 0;
  return v3 | 0x100u;
}

uint64_t std::__function::__func<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0,std::allocator<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0>,MatchStatus ()(MatchParams const&)>::target(uint64_t a1, uint64_t a2)
{
  {
    return a1 + 8;
  }
  else
  {
    return 0;
  }
}

void *std::__function::__func<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0,std::allocator<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0>,MatchStatus ()(MatchParams const&)>::target_type()
{
}

void std::__function::__func<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1,std::allocator<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1>,MatchStatus ()(MatchParams const&)>::~__func()
{
}

void *std::__function::__func<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1,std::allocator<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1>,MatchStatus ()(MatchParams const&)>::__clone()
{
  uint64_t result = operator new(0x10uLL);
  void *result = &unk_26C330B30;
  return result;
}

void std::__function::__func<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1,std::allocator<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1>,MatchStatus ()(MatchParams const&)>::__clone(uint64_t a1, void *a2)
{
  *a2 = &unk_26C330B30;
}

uint64_t std::__function::__func<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1,std::allocator<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1>,MatchStatus ()(MatchParams const&)>::operator()(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = *(void **)(a2 + 8);
  uint64_t v3 = v2[8];
  if (*(_DWORD *)(v3 + 8) == 55 && v2[12] - v2[11] == 16)
  {
    long long __p = 0;
    unsigned int v16 = 0;
    uint64_t v17 = 0;
    std::vector<ZinIrPaddingMode>::__init_with_size[abi:ne180100]<ZinIrPaddingMode*,ZinIrPaddingMode*>(&__p, *(const void **)(v3 + 176), *(void *)(v3 + 184), (uint64_t)(*(void *)(v3 + 184) - *(void *)(v3 + 176)) >> 2);
    uint64_t v5 = __p;
    if (v16 - (unsigned char *)__p != 4)
    {
      BOOL v13 = 0;
      if (!__p) {
        return v13 | 0x100u;
      }
      goto LABEL_17;
    }
    uint64_t v6 = *(void *)(*(void *)(*(void *)(a2 + 8) + 88) + 8);
    uint64_t v7 = (*(uint64_t (**)(uint64_t, void, void))(*(void *)v6 + 32))(v6, 0, 0);
    uint64_t v8 = **(void **)(*(void *)(a2 + 8) + 88);
    uint64_t v9 = (*(uint64_t (**)(uint64_t, void, void))(*(void *)v8 + 32))(v8, 0, 0);
    if (v9) {
      BOOL v10 = v7 == 0;
    }
    else {
      BOOL v10 = 1;
    }
    BOOL v13 = !v10
       && (unint64_t ValueAt = GetValueAtDimension<ZinTensorDimensions>((uint64_t *)(v7 + 48), *(_DWORD *)__p),
           GetValueAtDimension<ZinTensorDimensions>((uint64_t *)(v9 + 48), *(_DWORD *)__p) >= ValueAt)
       && (uint64_t v12 = *(void *)(*(void *)(*(void *)(*(void *)(a2 + 8) + 88) + 8) + 64),
           *(_DWORD *)(v12 + 8) == 66)
       && *(void *)(v12 + 16) == ValueAt;
    uint64_t v5 = __p;
    if (__p)
    {
LABEL_17:
      unsigned int v16 = v5;
      operator delete(v5);
    }
  }
  else
  {
    BOOL v13 = 0;
  }
  return v13 | 0x100u;
}

void sub_2112BE234(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t std::__function::__func<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1,std::allocator<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1>,MatchStatus ()(MatchParams const&)>::target(uint64_t a1, uint64_t a2)
{
  {
    return a1 + 8;
  }
  else
  {
    return 0;
  }
}

void *std::__function::__func<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1,std::allocator<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1>,MatchStatus ()(MatchParams const&)>::target_type()
{
}

void std::__function::__func<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_2,std::allocator<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_2>,BOOL ()(ZinIrOpLayerGraph const*,ZinIrParameters const&,ZinPattern const*)>::~__func()
{
}

void *std::__function::__func<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_2,std::allocator<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_2>,BOOL ()(ZinIrOpLayerGraph const*,ZinIrParameters const&,ZinPattern const*)>::__clone()
{
  uint64_t result = operator new(0x10uLL);
  void *result = &unk_26C330B88;
  return result;
}

void std::__function::__func<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_2,std::allocator<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_2>,BOOL ()(ZinIrOpLayerGraph const*,ZinIrParameters const&,ZinPattern const*)>::__clone(uint64_t a1, void *a2)
{
  *a2 = &unk_26C330B88;
}

BOOL std::__function::__func<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_2,std::allocator<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_2>,BOOL ()(ZinIrOpLayerGraph const*,ZinIrParameters const&,ZinPattern const*)>::operator()(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t *a4)
{
  uint64_t v4 = *a4;
  std::string::basic_string[abi:ne180100]<0>(__p, "gather");
  uint64_t SingleMatch = ZinPattern::GetSingleMatch(v4, (unsigned __int8 *)__p);
  if (v8 < 0) {
    operator delete(__p[0]);
  }
  return **(void **)(*(void *)(*(void *)(SingleMatch + 88) + 8) + 88) == **(void **)(SingleMatch + 88);
}

void sub_2112BE390(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11, int a12, __int16 a13, char a14, char a15)
{
  if (a15 < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t std::__function::__func<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_2,std::allocator<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_2>,BOOL ()(ZinIrOpLayerGraph const*,ZinIrParameters const&,ZinPattern const*)>::target(uint64_t a1, uint64_t a2)
{
  {
    return a1 + 8;
  }
  else
  {
    return 0;
  }
}

void *std::__function::__func<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_2,std::allocator<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_2>,BOOL ()(ZinIrOpLayerGraph const*,ZinIrParameters const&,ZinPattern const*)>::target_type()
{
}

void std::__function::__func<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_3,std::allocator<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_3>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::~__func()
{
}

void *std::__function::__func<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_3,std::allocator<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_3>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::__clone(uint64_t a1)
{
  uint64_t result = operator new(0x10uLL);
  uint64_t v3 = *(void *)(a1 + 8);
  void *result = &unk_26C330BE0;
  result[1] = v3;
  return result;
}

uint64_t std::__function::__func<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_3,std::allocator<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_3>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::__clone(uint64_t result, void *a2)
{
  uint64_t v2 = *(void *)(result + 8);
  *a2 = &unk_26C330BE0;
  a2[1] = v2;
  return result;
}

uint64_t std::__function::__func<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_3,std::allocator<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_3>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::operator()(uint64_t a1, uint64_t *a2)
{
  v32[6] = *MEMORY[0x263EF8340];
  uint64_t v2 = *(uint64_t ***)(a1 + 8);
  uint64_t v4 = *v2;
  uint64_t v3 = v2[1];
  if (*v2 != v3)
  {
    uint64_t v5 = *a2;
    do
    {
      uint64_t v6 = v5;
      if ((*(unsigned int (**)(void))(*(void *)*v4 + 8))())
      {
        uint64_t v7 = *v4;
        std::string::basic_string[abi:ne180100]<0>(__p, "gather");
        uint64_t SingleMatch = ZinPattern::GetSingleMatch(v7, __p);
        uint64_t v9 = (void *)SingleMatch;
        if ((__p[23] & 0x80000000) != 0)
        {
          operator delete(*(void **)__p);
          if (v9)
          {
LABEL_8:
            BOOL v10 = (uint64_t *)v9[11];
            uint64_t v12 = *v10;
            uint64_t v11 = v10[1];
            (*(uint64_t (**)(void *, void, void))(*v9 + 32))(v9, 0, 0);
            if (*(char *)(v11 + 47) >= 0) {
              size_t v13 = *(unsigned __int8 *)(v11 + 47);
            }
            else {
              size_t v13 = *(void *)(v11 + 32);
            }
            std::string::basic_string[abi:ne180100]((uint64_t)__p, v13 + 4);
            if (__p[23] >= 0) {
              unsigned int v14 = __p;
            }
            else {
              unsigned int v14 = *(unsigned char **)__p;
            }
            if (v13)
            {
              if (*(char *)(v11 + 47) >= 0) {
                unsigned int v15 = (const void *)(v11 + 24);
              }
              else {
                unsigned int v15 = *(const void **)(v11 + 24);
              }
              memmove(v14, v15, v13);
            }
            strcpy(&v14[v13], "topk");
            __n128 v16 = ZinObjectNameFactory::ZinObjectNameFactory(v32, __p);
            if ((__p[23] & 0x80000000) != 0) {
              operator delete(*(void **)__p);
            }
            (*(void (**)(unsigned char *__return_ptr, uint64_t, void, void, __n128))(*(void *)v12 + 80))(__p, v12, 0, 0, v16);
            uint64_t v17 = (*(uint64_t (**)(void *, void, void))(*v9 + 32))(v9, 0, 0);
            long long v18 = *(_OWORD *)(v17 + 64);
            *(_OWORD *)&__p[8] = *(_OWORD *)(v17 + 48);
            *(_OWORD *)&__p[24] = v18;
            *(void *)&__p[40] = *(void *)(v17 + 80);
            uint64_t v19 = *(void *)(v11 + 16);
            uint64_t v20 = operator new(0x78uLL);
            v25[1] = (char *)v20 + 120;
            int8x16_t v25[2] = (char *)v20 + 120;
            long long v21 = v29;
            void v20[4] = v28;
            v20[5] = v21;
            v20[6] = v30;
            *((_DWORD *)v20 + 28) = v31;
            long long v22 = *(_OWORD *)&__p[16];
            _OWORD *v20 = *(_OWORD *)__p;
            v20[1] = v22;
            long long v23 = v27;
            void v20[2] = *(_OWORD *)&__p[32];
            void v20[3] = v23;
            v25[0] = v20;
            ZinBuilder::CreateTopK(v19, (uint64_t)v32, v25);
          }
        }
        else if (SingleMatch)
        {
          goto LABEL_8;
        }
      }
      v4 += 2;
      uint64_t v5 = v6;
    }
    while (v4 != v3);
  }
  return 0;
}

void sub_2112BE8E0(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,void *__p,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,int a26,__int16 a27,char a28,char a29)
{
  if (__p) {
    operator delete(__p);
  }
  *(void *)(v29 - 144) = &unk_26C34DA98;
  if (*(char *)(v29 - 113) < 0) {
    operator delete(*(void **)(v29 - 136));
  }
  _Unwind_Resume(exception_object);
}

uint64_t std::__function::__func<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_3,std::allocator<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_3>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::target(uint64_t a1, uint64_t a2)
{
  {
    return a1 + 8;
  }
  else
  {
    return 0;
  }
}

void *std::__function::__func<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_3,std::allocator<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_3>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::target_type()
{
}

void std::__function::__func<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_3,std::allocator<ZinIrOpt::TopkGatherToTopk(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_3>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::operator()(uint64_t a1)
{
  uint64_t v4 = *MEMORY[0x263EF8340];
  uint64_t v1 = (void *)(a1 + 24);
  if (*(char *)(a1 + 47) < 0) {
    uint64_t v1 = (void *)*v1;
  }
  int v2 = 136315138;
  uint64_t v3 = v1;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "Error: Unable to fuse %s and gather to topk\n", (uint8_t *)&v2, 0xCu);
}

uint64_t ZinPixelShuffleUnshuffleTransform::ZinPixelShuffleUnshuffleTransform(uint64_t result, uint64_t a2, _OWORD *a3, void *a4)
{
  *(void *)uint64_t result = &unk_26C353B10;
  *(void *)(result + 8) = a2;
  *(_OWORD *)(result + 16) = *a3;
  *(void *)(result + std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *a4;
  uint64_t v4 = a4 + 1;
  uint64_t v5 = a4[1];
  *(void *)(result + 4std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v5;
  uint64_t v6 = result + 40;
  uint64_t v7 = a4[2];
  *(void *)(result + 48) = v7;
  if (v7)
  {
    *(void *)(v5 + 16) = v6;
    *a4 = v4;
    *uint64_t v4 = 0;
    a4[2] = 0;
  }
  else
  {
    *(void *)(result + std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = v6;
  }
  *(void *)(result + 56) = 0;
  return result;
}

uint64_t ZinPixelShuffleUnshuffleTransform::Run(uint64_t a1, uint64_t a2, ZinSpatialSplitTransform **a3, void *a4)
{
  if (*(void *)(a1 + 8) != *((void *)*a3 + 11)) {
    ZinAssertImpl("Error: Serialized source layer group ID does not match current node.");
  }
  if (a4[1] == *a4) {
    ZinAssertImpl("Error: Invalid number of input dimensions.");
  }
  uint64_t v5 = *(void *)(a1 + 56);
  if (!v5)
  {
    int v6 = *(_DWORD *)(a1 + 16);
    if (v6 != 1)
    {
      if (!v6) {
        operator new();
      }
      ZinAssertImpl("Error: Unknown ZinPixelShuffleUnshuffleTransform type.");
    }
    operator new();
  }
  uint64_t PaddingInfo = ZinSpatialSplitTransform::GetPaddingInfo(*a3);
  uint64_t result = (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)v5 + 24))(v5, PaddingInfo);
  if (result)
  {
    uint64_t v9 = *(uint64_t (**)(void))(**(void **)(a1 + 56) + 16);
    return v9();
  }
  return result;
}

uint64_t ZinPixelShuffleUnshuffleTransform::GetTransformType(ZinPixelShuffleUnshuffleTransform *this)
{
  return 3;
}

BOOL ZinPixelShuffleUnshuffleTransform::operator==(_DWORD *a1, _DWORD *a2)
{
  int v4 = (*(uint64_t (**)(_DWORD *))(*(void *)a1 + 40))(a1);
  return v4 == (*(unsigned int (**)(_DWORD *))(*(void *)a2 + 40))(a2)
      && a1[4] == a2[4]
      && a1[5] == a2[5]
      && a1[6] == a2[6]
      && a1[7] == a2[7];
}

void ZinPixelShuffleUnshuffleTransform::~ZinPixelShuffleUnshuffleTransform(ZinPixelShuffleUnshuffleTransform *this)
{
  ZinPixelShuffleUnshuffleTransform::~ZinPixelShuffleUnshuffleTransform(this);

  JUMPOUT(0x21667D3C0);
}

{
  uint64_t v2;

  *(void *)this = &unk_26C353B10;
  int v2 = *((void *)this + 7);
  *((void *)this + 7) = 0;
  if (v2) {
    (*(void (**)(uint64_t))(*(void *)v2 + 8))(v2);
  }
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)this + 32, *((void **)this + 5));
}

uint64_t PixelShuffleHandler::Run(uint64_t a1, uint64_t a2, ZinSpatialSplitTransform **a3, uint64_t *a4)
{
  if (*(_DWORD *)ZinSpatialSplitTransform::GetPaddingInfo(*a3) != 33) {
    return 0;
  }

  return PixelShuffleHandler::UpdateAliasNodeOutputDims(a1, a2, (uint64_t *)a3, a4);
}

BOOL PixelShuffleHandler::ShouldHandleOp(uint64_t a1, _DWORD *a2)
{
  return *a2 == 33;
}

uint64_t PixelShuffleHandler::UpdateAliasNodeOutputDims(uint64_t a1, uint64_t a2, uint64_t *a3, uint64_t *a4)
{
  uint64_t v5 = *a4;
  if (a4[1] - *a4 != 40) {
    ZinAssertImpl("Error: Invalid number of inputs for Alias.");
  }
  uint64_t v6 = *(void *)(a1 + 8);
  int v8 = *(_DWORD *)(v6 + 4);
  uint64_t v7 = (int *)(v6 + 4);
  if (*(void *)(v5 + 8) % (v7[1] * (uint64_t)v8 * v7[2])) {
    ZinAssertImpl("Error: Input dimensions are invalid; must be a multiple of the shuffle factor.");
  }
  ZinPixelShuffleUtils::GetAliasDims(v5, v7, (uint64_t)v11);
  return ZinMirAliasUnit::SetOutputDimensions(*a3, v11);
}

void PixelUnshuffleHandler::~PixelUnshuffleHandler(PixelUnshuffleHandler *this)
{
}

uint64_t PixelUnshuffleHandler::Run(uint64_t a1, uint64_t a2, ZinSpatialSplitTransform **a3, uint64_t *a4)
{
  int v8 = *(_DWORD *)ZinSpatialSplitTransform::GetPaddingInfo(*a3);
  switch(v8)
  {
    case '$':
      return PixelUnshuffleHandler::UpdateViewNodeViewInfoSize(a1, a2, a3, a4);
    case '#':
      return PixelUnshuffleHandler::UpdateReshapeNodeOutputDims(a1, a2, a3, a4);
    case '!':
      return PixelUnshuffleHandler::UpdateAliasNodeOutputDims(a1, a2, (uint64_t *)a3, a4);
    default:
      return 0;
  }
}

uint64_t PixelUnshuffleHandler::ShouldHandleOp(uint64_t a1, _DWORD *a2)
{
  return (*a2 < 0x25uLL) & (0x1A00000000uLL >> *a2);
}

uint64_t PixelUnshuffleHandler::UpdateAliasNodeOutputDims(uint64_t a1, uint64_t a2, uint64_t *a3, uint64_t *a4)
{
  uint64_t v4 = *a4;
  if (a4[1] - *a4 != 40) {
    ZinAssertImpl("Error: Invalid number of inputs for Alias.");
  }
  uint64_t v5 = *(void *)(a1 + 8);
  if (*(_DWORD *)(v5 + 12) != 1) {
    ZinAssertImpl("Error: PixelShuffle factor z have to be 1");
  }
  uint64_t v6 = *(int *)(v5 + 4);
  if (*(void *)(v4 + 24) % v6) {
    ZinAssertImpl("Error: Input dimensions are invalid; must be a multiple of the shuffle factor.");
  }
  uint64_t v7 = *(void *)(v4 + 32);
  long long v8 = *(_OWORD *)(v4 + 16);
  *(void *)&long long v10 = *(void *)v4;
  long long v11 = v8;
  uint64_t v12 = v7;
  *((void *)&v10 + 1) = v6;
  if (!v6 || *((void *)&v11 + 1) % v6) {
    ZinAssertImpl("Input width cannot divided by factor.x", v10, (void)v11);
  }
  *((uint64_t *)&v11 + 1) /= v6;
  return ZinMirAliasUnit::SetOutputDimensions(*a3, &v10);
}

uint64_t PixelUnshuffleHandler::UpdateViewNodeViewInfoSize(uint64_t a1, uint64_t a2, ZinANELayer **a3, void *a4)
{
  uint64_t v4 = *(void *)(a1 + 16);
  uint64_t v7 = *(void **)(v4 + 8);
  uint64_t v5 = (void *)(v4 + 8);
  uint64_t v6 = v7;
  if (v7)
  {
    unint64_t v9 = *((void *)*a3 + 10);
    long long v10 = v5;
    do
    {
      unint64_t v11 = v6[4];
      BOOL v12 = v11 >= v9;
      if (v11 >= v9) {
        size_t v13 = v6;
      }
      else {
        size_t v13 = v6 + 1;
      }
      if (v12) {
        long long v10 = v6;
      }
      uint64_t v6 = (void *)*v13;
    }
    while (*v13);
    if (v10 != v5 && v9 >= v10[4])
    {
      if (a4[1] - *a4 != 40) {
        ZinAssertImpl("Error: Invalid number of inputs for View.");
      }
      uint64_t v14 = *(void *)(a1 + 8);
      if (*(void *)(*a4 + 16) % *(int *)(v14 + 8)) {
        ZinAssertImpl("Error: Input dimensions are invalid; height must be a multiple of the shuffle factor.");
      }
      BondedInfo = (uint64_t *)ZinANELayer::GetBondedInfo(*a3);
      uint64_t v16 = *BondedInfo;
      uint64_t v17 = BondedInfo[1];
      if (*BondedInfo != v17)
      {
        uint64_t v18 = *a4;
        do
        {
          if (*(_DWORD *)(*(void *)v16 + 92) != 3) {
            ZinAssertImpl("Error: Unexpected view dimension.");
          }
          *(_DWORD *)(*(void *)v16 + 84) = *(void *)(v18 + 16) / *(int *)(v14 + 8);
          v16 += 8;
        }
        while (v16 != v17);
      }
    }
  }
  return 0;
}

uint64_t PixelUnshuffleHandler::UpdateReshapeNodeOutputDims(uint64_t a1, uint64_t a2, ZinMirUnit **a3, void *a4)
{
  if (a4[1] - *a4 != 40) {
    ZinAssertImpl("Error: Invalid number of inputs for View.");
  }
  uint64_t AotTensorDims = ZinMirUnit::GetAotTensorDims(*a3);
  long long v7 = *(_OWORD *)AotTensorDims;
  long long v8 = *(_OWORD *)(AotTensorDims + 16);
  uint64_t v12 = *(void *)(AotTensorDims + 32);
  long long v10 = v7;
  long long v11 = v8;
  long long v11 = *(_OWORD *)(*a4 + 16);
  return ZinMirReshapeUnit::SetOutputDimensions((uint64_t)*a3, &v10);
}

void ZinAneTd<1u>::SetL2Barrier()
{
}

BOOL ZinAneTd<1u>::SetL2SrcBaseAddress(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 432) + 224), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src Start Address");
  }
  *(_DWORD *)(a1 + 68) = *(_DWORD *)(a1 + 68) & 0xFFE00000 | v4 & 0x1FFFFF;
  return result;
}

BOOL ZinAneTd<1u>::SetL2Src1ChannelStride(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 432) + 272), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src Channel Stride");
  }
  *(_DWORD *)(a1 + 88) = *(_DWORD *)(a1 + 88) & 0xFFE00000 | v4 & 0x1FFFFF;
  return result;
}

BOOL ZinAneTd<1u>::SetL2SrcRowStride(uint64_t a1, ZinCodegen *this, ZinTensorDimensions *a3, uint64_t a4, uint64_t *a5)
{
  uint64_t v8 = 0;
  ZinCodegen::GetL2RowStride(this, a3, *(unsigned int *)(*(void *)(a1 + 432) + 268), &v8, a5);
  int v7 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(v8, (unsigned int *)(*(void *)(a1 + 432) + 264), &v7);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src Row Stride");
  }
  *(_DWORD *)(a1 + 84) = *(_DWORD *)(a1 + 84) & 0xFFE00000 | v7 & 0x1FFFFF;
  return result;
}

void ZinAneTd<1u>::SetL2Src1DepthStride()
{
  if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_INFO))
  {
    *(_WORD *)uint64_t v0 = 0;
    _os_log_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_INFO, "Depth Stride not programmed", v0, 2u);
  }
}

BOOL ZinAneTd<1u>::SetL2Src1GroupStride(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 432) + 280), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src Group Stride");
  }
  *(_DWORD *)(a1 + 96) = *(_DWORD *)(a1 + 96) & 0xFFE00000 | v4 & 0x1FFFFF;
  return result;
}

uint64_t ZinAneTd<1u>::SetL2Src1DmaFormat(uint64_t result, int a2)
{
  switch(a2)
  {
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 16) & 0xFFFFFCFF | 0x200;
      break;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 16) & 0xFFFFFCFF;
      break;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 16) & 0xFFFFFCFF | 0x100;
      break;
    default:
      ZinAssertImpl("Invalid input tensor format used\n");
  }
  *(_DWORD *)(result + 16) = v2;
  return result;
}

BOOL ZinAneTd<1u>::SetSrc1BoundaryRegisters(uint64_t a1, unint64_t *a2)
{
  int v5 = 0;
  if (!ZinCodegenUtil::ValueToRegister(*a2, (unsigned int *)(*(void *)(a1 + 432) + 232), &v5) {
    || (*(_DWORD *)(a1 + 76) = *(_DWORD *)(a1 + 76) & 0x8000FFFF | ((v5 & 0x7FFF) << 16),
  }
        int v5 = 0,
        !ZinCodegenUtil::ValueToRegister(a2[1], (unsigned int *)(*(void *)(a1 + 432) + 240), &v5))
    || (*(_WORD *)(a1 + 76) = v5,
        int v5 = 0,
        !ZinCodegenUtil::ValueToRegister(a2[2], (unsigned int *)(*(void *)(a1 + 432) + 248), &v5))
    || (*(_DWORD *)(a1 + 8std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 80) & 0x8000FFFF | ((v5 & 0x7FFF) << 16),
        int v5 = 0,
        !(BOOL result = ZinCodegenUtil::ValueToRegister(a2[3], (unsigned int *)(*(void *)(a1 + 432) + 256), &v5))))
  {
    ZinAssertImpl("Illegal Value");
  }
  *(_WORD *)(a1 + 8std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v5;
  return result;
}

uint64_t ZinAneTd<1u>::SetL2ResultCfgDmaFmt(uint64_t result, int a2)
{
  switch(a2)
  {
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 16) & 0xFFFFCFFF | 0x2000;
      break;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 16) & 0xFFFFCFFF;
      break;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 16) & 0xFFFFCFFF | 0x1000;
      break;
    default:
      ZinAssertImpl("Invalid tensor format");
  }
  *(_DWORD *)(result + 16) = v2;
  return result;
}

BOOL ZinAneTd<1u>::SetDstBoundaryRegisters(uint64_t a1, unint64_t *a2)
{
  int v5 = 0;
  if (!ZinCodegenUtil::ValueToRegister(*a2, (unsigned int *)(*(void *)(a1 + 432) + 360), &v5) {
    || (*(_DWORD *)(a1 + 156) = *(_DWORD *)(a1 + 156) & 0x8000FFFF | ((v5 & 0x7FFF) << 16),
  }
        int v5 = 0,
        !ZinCodegenUtil::ValueToRegister(a2[1], (unsigned int *)(*(void *)(a1 + 432) + 368), &v5))
    || (*(_WORD *)(a1 + 156) = v5,
        int v5 = 0,
        !ZinCodegenUtil::ValueToRegister(a2[2], (unsigned int *)(*(void *)(a1 + 432) + 376), &v5))
    || (*(_DWORD *)(a1 + 16std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 160) & 0x8000FFFF | ((v5 & 0x7FFF) << 16),
        int v5 = 0,
        !(BOOL result = ZinCodegenUtil::ValueToRegister(a2[3], (unsigned int *)(*(void *)(a1 + 432) + 384), &v5))))
  {
    ZinAssertImpl("Illegal Value");
  }
  *(_WORD *)(a1 + 16std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v5;
  return result;
}

void ZinAneTd<1u>::SetL2SrcOffsetXlsbs(uint64_t a1, int a2)
{
  if (a2) {
    ZinAssertImpl("Invalid Offset X Lsbs for architecture", v2, v3);
  }
}

unint64_t ZinAneTd<1u>::SetL2SrcNumInterleavedChannels(uint64_t a1, unint64_t a2)
{
  unint64_t result = ZinIrCodegenValueToRegister(a2, dword_267770220);
  *(_DWORD *)(a1 + 2std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 20) & 0xFFFFF000 | result & 0xFFF;
  return result;
}

void ZinAneTd<1u>::SetSourceAddrWrap(uint64_t a1, int a2, int a3)
{
  if (a3 | a2) {
    ZinAssertImpl("Source wrapping start offset or wrap index not acceptable\n", v3, v4);
  }
}

void ZinAneTd<1u>::SetSourceWrap(uint64_t a1, uint64_t a2, int a3, int a4)
{
  if (a4 | a3) {
    ZinAssertImpl("Source wrapping start offset or wrap index not acceptable\n", v4, v5);
  }
}

void ZinAneTd<1u>::SetL2Src1FIFOMode(uint64_t a1, int a2)
{
  if (a2) {
    ZinAssertImpl("Input DMA FIFO is not supported", v2, v3);
  }
}

BOOL ZinAneTd<1u>::SetL2Src2BaseAddress(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 432) + 296), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src2 Base Address");
  }
  *(_DWORD *)(a1 + 116) = *(_DWORD *)(a1 + 116) & 0xFFE00000 | v4 & 0x1FFFFF;
  return result;
}

BOOL ZinAneTd<1u>::SetL2Src2ChannelStride(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 432) + 344), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src2 Channel Stride");
  }
  *(_DWORD *)(a1 + 136) = *(_DWORD *)(a1 + 136) & 0xFFE00000 | v4 & 0x1FFFFF;
  return result;
}

BOOL ZinAneTd<1u>::SetL2Src2RowStride(uint64_t a1, ZinCodegen *this, ZinTensorDimensions *a3, uint64_t a4, uint64_t *a5)
{
  uint64_t v8 = 0;
  ZinCodegen::GetL2RowStride(this, a3, *(unsigned int *)(*(void *)(a1 + 432) + 340), &v8, a5);
  int v7 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(v8, (unsigned int *)(*(void *)(a1 + 432) + 336), &v7);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src2 Row Stride");
  }
  *(_DWORD *)(a1 + 1std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_DWORD *)(a1 + 132) & 0xFFE00000 | v7 & 0x1FFFFF;
  return result;
}

void ZinAneTd<1u>::SetL2Src2DepthStride()
{
}

void ZinAneTd<1u>::SetL2Src2GroupStride()
{
}

void ZinAneTd<1u>::SetL2Src2OffsetXlsbs(uint64_t a1, int a2)
{
  if (a2) {
    ZinAssertImpl("Invalid Offset2 X Lsbs for architecture", v2, v3);
  }
}

unint64_t ZinAneTd<1u>::SetL2Src2NumInterleavedChannels(uint64_t a1, unint64_t a2)
{
  unint64_t result = ZinIrCodegenValueToRegister(a2, &dword_2677701F8[8]);
  *(_DWORD *)(a1 + 16) = *(_DWORD *)(a1 + 16) & 0xF000FFFF | ((result & 0xFFF) << 16);
  return result;
}

BOOL ZinAneTd<1u>::SetSrc2BoundaryRegisters(uint64_t a1, unint64_t *a2)
{
  int v5 = 0;
  if (!ZinCodegenUtil::ValueToRegister(*a2, (unsigned int *)(*(void *)(a1 + 432) + 304), &v5)
    || (*(_DWORD *)(a1 + 124) = *(_DWORD *)(a1 + 124) & 0x8000FFFF | ((v5 & 0x7FFF) << 16),
        int v5 = 0,
        !ZinCodegenUtil::ValueToRegister(a2[1], (unsigned int *)(*(void *)(a1 + 432) + 312), &v5))
    || (*(_WORD *)(a1 + 124) = v5,
        int v5 = 0,
        !ZinCodegenUtil::ValueToRegister(a2[2], (unsigned int *)(*(void *)(a1 + 432) + 320), &v5))
    || (*(_DWORD *)(a1 + 128) = *(_DWORD *)(a1 + 128) & 0x8000FFFF | ((v5 & 0x7FFF) << 16),
        int v5 = 0,
        !(BOOL result = ZinCodegenUtil::ValueToRegister(a2[3], (unsigned int *)(*(void *)(a1 + 432) + 328), &v5))))
  {
    ZinAssertImpl("Illegal Value");
  }
  *(_WORD *)(a1 + 128) = v5;
  return result;
}

uint64_t ZinAneTd<1u>::SetOpMode(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 44) & 0xFFFFFFF8;
      goto LABEL_5;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 44) & 0xFFFFFFF8 | 1;
      goto LABEL_5;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 44) & 0xFFFFFFF8 | 3;
LABEL_5:
      *(_DWORD *)(result + 44) = v2;
      break;
    case 3:
      ZinAssertImpl("EWSqr not valid for architecture");
    case 4:
      ZinAssertImpl("EWMul not valid for architecture");
    case 5:
    case 6:
      ZinAssertImpl("Bypass and RCAS not valid for architecture");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<1u>::SetElementWiseOp(uint64_t result, int a2)
{
  if (a2 == 2)
  {
    unsigned int v2 = *(_DWORD *)(result + 44) & 0xFF8FFFFF | 0x300000;
  }
  else if (a2 == 1)
  {
    unsigned int v2 = *(_DWORD *)(result + 44) & 0xFF8FFFFF | 0x100000;
  }
  else
  {
    if (a2) {
      ZinAssertImpl("Invalid ElementWiseOp for this architecture");
    }
    unsigned int v2 = *(_DWORD *)(result + 44) & 0xFF8FFFFF;
  }
  *(_DWORD *)(result + 44) = v2;
  return result;
}

BOOL ZinAneTd<1u>::SetSplitRowCompute(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 432) + 8), &v4);
  if (!result) {
    ZinAssertImpl("Illegal Value");
  }
  *(_DWORD *)(a1 + 16) = *(_DWORD *)(a1 + 16) & 0xFFFFFFDF | (32 * (v4 & 1));
  return result;
}

uint64_t ZinAneTd<1u>::SetKernelMode(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 44) & 0xFFFFFFF7;
LABEL_7:
      *(_DWORD *)(result + 44) = v2;
      return result;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 44) | 8;
      goto LABEL_7;
    case 1:
      ZinAssertImpl("Unsupported Kernel Mode");
  }
  return result;
}

void ZinAneTd<1u>::SetPassthroughEnable(uint64_t a1, int a2)
{
  if (a2) {
    ZinAssertImpl("Passthrough flag not supported on this arch.", v2, v3);
  }
}

uint64_t ZinAneTd<1u>::SetKernelFmt(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 40) & 0xFFFFFFFC;
      goto LABEL_5;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 40) & 0xFFFFFFFC | 1;
      goto LABEL_5;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 40) & 0xFFFFFFFC | 2;
LABEL_5:
      *(_DWORD *)(result + 4std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2;
      break;
    case 3:
      ZinAssertImpl("Unsupported kernel format");
    default:
      return result;
  }
  return result;
}

BOOL ZinAneTd<1u>::SetTileDmaSrc1ChannelStride(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 432) + 496), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc1 Channel Stride");
  }
  *(_DWORD *)(a1 + 336) = *(_DWORD *)(a1 + 336) & 0xF | (16 * v4);
  return result;
}

BOOL ZinAneTd<1u>::SetTileDmaSrc1RowStride(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 432) + 488), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc1 Row Stride");
  }
  *(_DWORD *)(a1 + 3std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_DWORD *)(a1 + 332) & 0xF | (16 * v4);
  return result;
}

BOOL ZinAneTd<1u>::SetTileDmaSrc2ChannelStride(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 432) + 496), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc2 Channel Stride");
  }
  *(_DWORD *)(a1 + 336) = *(_DWORD *)(a1 + 336) & 0xF | (16 * v4);
  return result;
}

BOOL ZinAneTd<1u>::SetTileDmaSrc2RowStride(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 432) + 488), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc2 Row Stride");
  }
  *(_DWORD *)(a1 + 3std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_DWORD *)(a1 + 332) & 0xF | (16 * v4);
  return result;
}

uint64_t ZinAneTd<1u>::SetTileDmaDstFormat(uint64_t result, int a2)
{
  switch(a2)
  {
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 316) & 0xFFFFCFCC | 0x2031;
      break;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 316) & 0xFFFFCFFC;
      break;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 316) & 0xFFFFCFFC | 0x1000;
      break;
    default:
      ZinAssertImpl("dma format %d format not implemented yet\n", a2);
  }
  *(_DWORD *)(result + 316) = v2;
  return result;
}

void ZinAneTd<1u>::SetTileDmaDstandL2DstInterleave()
{
  if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_INFO))
  {
    *(_WORD *)uint64_t v0 = 0;
    _os_log_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_INFO, "HW does not support DMA Interleave", v0, 2u);
  }
}

BOOL ZinAneTd<1u>::SetTileDmaDstChannelStride(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 432) + 496), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaDst Channel Stride");
  }
  *(_DWORD *)(a1 + 336) = *(_DWORD *)(a1 + 336) & 0xF | (16 * v4);
  return result;
}

BOOL ZinAneTd<1u>::SetTileDmaDstRowStride(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 432) + 488), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaDst Row Stride");
  }
  *(_DWORD *)(a1 + 3std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_DWORD *)(a1 + 332) & 0xF | (16 * v4);
  return result;
}

void ZinAneTd<1u>::SetCacheDmaPreEnable(uint64_t a1, int a2)
{
  if (a2) {
    ZinAssertImpl("Cache Prefetch not supported", v2, v3);
  }
}

void ZinAneTd<1u>::SetCacheDmaPreFlush()
{
}

void ZinAneTd<1u>::SetCacheDmaPrePause(uint64_t a1, char a2, char a3, int a4, int a5)
{
  if ((a2 & 1) != 0 || (a3 & 1) != 0 || a5 || a4) {
    ZinAssertImpl("Cache Prefetch Pause not supported", v5, v6);
  }
}

void ZinAneTd<1u>::SetCacheDmaPreThrottle(uint64_t a1, char a2, char a3, int a4, int a5, int a6)
{
  if ((a2 & 1) != 0 || (a3 & 1) != 0 || a6 | a5 || a4) {
    ZinAssertImpl("Cache Prefetch Throttle not supported", v6, v7);
  }
}

void ZinAneTd<1u>::SetCacheDmaPrePrefetchRate(uint64_t a1, int a2)
{
  if (a2) {
    ZinAssertImpl("Cache Prefetch Rate not supported", v2, v3);
  }
}

void ZinAneTd<1u>::Set1DWinogradMode(uint64_t a1, int a2)
{
  if (a2) {
    ZinAssertImpl("1D Winograd is not supported", v2, v3);
  }
}

void ZinAneTd<1u>::SetRcasKeyMask()
{
}

uint64_t ZinAneTd<1u>::SetKernelPalettizedEn(uint64_t result, int a2)
{
  if ((a2 - 19) >= 4)
  {
    int v2 = 0;
    switch(a2)
    {
      case 0:
      case 3:
      case 28:
      case 29:
      case 30:
      case 31:
      case 32:
        ZinAssertImpl("Unknown kernel format in codegen\n");
      case 7:
      case 8:
      case 9:
      case 10:
      case 11:
      case 12:
      case 13:
      case 14:
      case 15:
      case 16:
      case 17:
      case 18:
      case 23:
      case 24:
      case 25:
      case 26:
      case 27:
        ZinAssertImpl("Invalid kernel format");
      default:
        break;
    }
  }
  else
  {
    int v2 = 4;
  }
  *(_DWORD *)(result + 4std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 40) & 0xFFFFFFFB | v2;
  return result;
}

uint64_t ZinAneTd<1u>::SetKernelPalettizedBits(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
    case 3:
    case 28:
    case 29:
    case 30:
    case 31:
    case 32:
      ZinAssertImpl("Unknown kernel format in codegen\n");
    case 7:
    case 8:
    case 9:
    case 10:
    case 11:
    case 12:
    case 13:
    case 14:
    case 15:
    case 16:
    case 17:
    case 18:
    case 23:
    case 24:
    case 25:
    case 26:
    case 27:
      ZinAssertImpl("Invalid kernel format");
    default:
      *(_DWORD *)(result + 40) &= 0xFFFFFFE7;
      return result;
  }
}

void ZinAneTd<1u>::SetStochasticRoundMode()
{
}

uint64_t ZinAneTd<1u>::SetNEBinaryPoint(uint64_t result, char a2)
{
  *(_DWORD *)(result + 44) = *(_DWORD *)(result + 44) & 0xFFFFC0FF | ((a2 & 0x1F) << 8);
  return result;
}

uint64_t ZinAneTd<1u>::SetNENonLinearMode(uint64_t result, int a2, uint64_t a3)
{
  if (a2)
  {
    if (a2 == 1)
    {
      a2 = 0x20000;
    }
    else
    {
      int v4 = *(_DWORD **)a3;
      uint64_t v3 = *(_DWORD **)(a3 + 8);
      if (*(_DWORD **)a3 != v3)
      {
        while (*v4 != a2)
        {
          if (++v4 == v3)
          {
            int v4 = *(_DWORD **)(a3 + 8);
            break;
          }
        }
      }
      if (v4 == v3) {
        ZinAssertImpl("Error: illegal non-linear mode\n");
      }
      a2 = 0x40000;
    }
  }
  *(_DWORD *)(result + 44) = *(_DWORD *)(result + 44) & 0xFFF9FFFF | a2;
  return result;
}

uint64_t ZinAneTd<1u>::SetNEPostScale(uint64_t result, unint64_t a2, char a3)
{
  _S0 = a2;
  __asm { FCVT            H0, S0 }
  int v8 = _S0;
  if (!_ZF) {
    int v8 = 15360;
  }
  int v9 = ((a2 & 0xFF0000000000) != 0) << 16;
  int v10 = -((a2 >> 16) & 0x1F0000) & 0x1F0000 | v8;
  if (!a3)
  {
    int v9 = 0;
    int v10 = 15360;
  }
  *(_DWORD *)(result + 44) = *(_DWORD *)(result + 44) & 0xFFFEFFFF | v9;
  *(_DWORD *)(result + 52) = v10 | *(_DWORD *)(result + 52) & 0xFFE00000;
  return result;
}

int8x8_t ZinAneTd<1u>::SetNEBias(uint64_t a1, unint64_t a2, char a3)
{
  if (a3)
  {
    _S0 = a2;
    __asm { FCVT            H0, S0 }
    int v8 = _S0;
    if (!_ZF) {
      int v8 = 0;
    }
    v9.i32[0] = 16 * ((a2 & 0xFF0000000000) != 0);
    v9.i32[1] = (a2 >> 16) & 0x1F0000 | v8;
  }
  else
  {
    int8x8_t v9 = 0;
  }
  int8x8_t result = vorr_s8(vand_s8(*(int8x8_t *)(a1 + 44), (int8x8_t)0xFFE00000FFFFFFCFLL), v9);
  *(int8x8_t *)(a1 + 44) = result;
  return result;
}

uint64_t ZinAneTd<1u>::SetNEOcgSize(uint64_t result, char a2)
{
  *(_DWORD *)(result + 16) = *(_DWORD *)(result + 16) & 0xFFFFFFF8 | a2 & 7;
  return result;
}

void ZinAneTd<1u>::SetNEHalfWUMode(uint64_t a1, char a2)
{
  if (a2) {
    ZinAssertImpl("Error: HalfWU mode is not supported", v2, v3);
  }
}

uint64_t ZinAneTd<1u>::SetCommonInFmt(uint64_t result, int a2)
{
  switch(a2)
  {
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 16) & 0xFFFFFCFF | 0x200;
      break;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 16) & 0xFFFFFCFF;
      break;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 16) & 0xFFFFFCFF | 0x100;
      break;
    default:
      ZinAssertImpl("Error: Invalid TD programming for Src1 input format");
  }
  *(_DWORD *)(result + 16) = v2;
  return result;
}

uint64_t ZinAneTd<1u>::SetCommonSrc2InFmt(uint64_t result, int a2)
{
  switch(a2)
  {
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 16) & 0xFFFFF3FF | 0x800;
      break;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 16) & 0xFFFFF3FF;
      break;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 16) & 0xFFFFF3FF | 0x400;
      break;
    default:
      ZinAssertImpl("Error: Invalid TD programming for Src2 input format");
  }
  *(_DWORD *)(result + 16) = v2;
  return result;
}

uint64_t ZinAneTd<1u>::SetCommonOutFmt(uint64_t result, int a2)
{
  switch(a2)
  {
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 16) & 0xFFFFCFFF | 0x2000;
      break;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 16) & 0xFFFFCFFF;
      break;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 16) & 0xFFFFCFFF | 0x1000;
      break;
    default:
      ZinAssertImpl("Error: Invalid output format");
  }
  *(_DWORD *)(result + 16) = v2;
  return result;
}

uint64_t ZinAneTd<1u>::SetCommonConvCfgKh(uint64_t a1, char a2)
{
  *(_DWORD *)(a1 + 6std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 60) & 0xFFFF03FF | ((a2 & 0x3F) << 10);
  return 1;
}

uint64_t ZinAneTd<1u>::SetCommonConvCfgKw(uint64_t a1, __int16 a2)
{
  *(_DWORD *)(a1 + 6std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 60) & 0xFFFFFC00 | a2 & 0x3FF;
  return 1;
}

uint64_t ZinAneTd<1u>::SetCommonConvCfg3dKd(uint64_t a1, uint64_t a2)
{
  if (a2 != 1) {
    ZinAssertImpl("Error: kernel depth is not supported", v2, v3);
  }
  return 1;
}

uint64_t ZinAneTd<1u>::SetCommonConvCfgSx(uint64_t a1, char a2)
{
  *(unsigned char *)(a1 + 62) = a2;
  return 1;
}

uint64_t ZinAneTd<1u>::SetCommonConvCfgSy(uint64_t a1, char a2)
{
  *(unsigned char *)(a1 + 63) = a2;
  return 1;
}

uint64_t ZinAneTd<1u>::SetCommonConvCfg3dSz(uint64_t a1, uint64_t a2)
{
  if (a2 != 1) {
    ZinAssertImpl("Error: Invalid input stride z", v2, v3);
  }
  return 1;
}

uint64_t ZinAneTd<1u>::SetCommonConvCfg3dOz(uint64_t a1, uint64_t a2)
{
  if (a2 != 1) {
    ZinAssertImpl("Error: Invalid output stride z", v2, v3);
  }
  return 1;
}

BOOL ZinAneTd<1u>::SetCommonConvCfgPadLeft(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 432) + 192), &v4);
  if (result) {
    *(_DWORD *)(a1 + 64) = *(_DWORD *)(a1 + 64) & 0xFFFFFC00 | v4 & 0x3FF;
  }
  return result;
}

BOOL ZinAneTd<1u>::SetCommonConvCfgPadTop(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 432) + 200), &v4);
  if (result) {
    *(_DWORD *)(a1 + 64) = *(_DWORD *)(a1 + 64) & 0xFFFF03FF | ((v4 & 0x3F) << 10);
  }
  return result;
}

uint64_t ZinAneTd<1u>::SetCommonConvCfg3dPz(uint64_t a1, uint64_t a2)
{
  if (a2) {
    ZinAssertImpl("Error: Invalid pad z", v2, v3);
  }
  return 1;
}

BOOL ZinAneTd<1u>::SetOrReturnNumGroups(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 432) + 128), &v4);
  if (result) {
    *(_WORD *)(a1 + 38) = v4;
  }
  return result;
}

BOOL ZinAneTd<1u>::SetOrReturnWin(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 432) + 72), &v4);
  if (result) {
    *(_WORD *)(a1 + 24) = v4;
  }
  return result;
}

BOOL ZinAneTd<1u>::SetOrReturnHin(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 432) + 80), &v4);
  if (result) {
    *(_WORD *)(a1 + 26) = v4;
  }
  return result;
}

uint64_t ZinAneTd<1u>::SetOrReturnDin(uint64_t a1, uint64_t a2)
{
  if (a2 != 1) {
    ZinAssertImpl("Error: Din not supported", v2, v3);
  }
  return 1;
}

BOOL ZinAneTd<1u>::SetOrReturnCin(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 432) + 88), &v4);
  if (result) {
    *(_WORD *)(a1 + 28) = v4;
  }
  return result;
}

BOOL ZinAneTd<1u>::SetOrReturnWout(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 432) + 104), &v4);
  if (result) {
    *(_WORD *)(a1 + std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = v4;
  }
  return result;
}

BOOL ZinAneTd<1u>::SetOrReturnHout(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 432) + 112), &v4);
  if (result) {
    *(_WORD *)(a1 + 34) = v4;
  }
  return result;
}

uint64_t ZinAneTd<1u>::SetOrReturnDout(uint64_t a1, uint64_t a2)
{
  if (a2 != 1) {
    ZinAssertImpl("Error: Dout not supported", v2, v3);
  }
  return 1;
}

BOOL ZinAneTd<1u>::SetOrReturnCout(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 432) + 120), &v4);
  if (result) {
    *(_WORD *)(a1 + 36) = v4;
  }
  return result;
}

void ZinAneTd<4u>::SetL2Barrier()
{
}

uint64_t ZinAneTd<4u>::SetEventFlags(uint64_t result, __int16 a2, __int16 a3, int a4)
{
  *(_WORD *)(result + 16) = a2;
  if (a4) {
    ZinAssertImpl("DRAM Events not supported for architecture");
  }
  *(_WORD *)(result + 2std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = a3;
  return result;
}

BOOL ZinAneTd<4u>::SetL2SrcBaseAddress(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 280) + 192), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src Base Address");
  }
  *(_DWORD *)(a1 + 18std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 180) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<4u>::SetL2Src1ChannelStride(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 280) + 200), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src Channel Stride");
  }
  *(_DWORD *)(a1 + 184) = *(_DWORD *)(a1 + 184) & 0xFFFF000F | (16 * (v4 & 0xFFF));
  return result;
}

BOOL ZinAneTd<4u>::SetL2SrcRowStride(uint64_t a1, ZinCodegen *this, ZinTensorDimensions *a3, uint64_t a4, uint64_t *a5)
{
  uint64_t v8 = 0;
  ZinCodegen::GetL2RowStride(this, a3, *(unsigned int *)(*(void *)(a1 + 280) + 212), &v8, a5);
  int v7 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(v8, (unsigned int *)(*(void *)(a1 + 280) + 208), &v7);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src Row Stride");
  }
  *(_DWORD *)(a1 + 188) = *(_DWORD *)(a1 + 188) & 0xFFF0000F | (16 * (unsigned __int16)v7);
  return result;
}

uint64_t ZinAneTd<4u>::SetL2Src1DmaFormat(uint64_t result, int a2)
{
  switch(a2)
  {
    case 1:
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 176) & 0xFFFFFF3F;
      break;
    case 3:
    case 4:
    case 5:
    case 6:
    case 7:
    case 9:
    case 10:
      unsigned int v2 = *(_DWORD *)(result + 176) & 0xFFFFFF3F | 0x40;
      break;
    case 8:
      ZinAssertImpl("packed10 format not fully implemented yet");
    case 11:
      ZinAssertImpl("Float32 not supported for architecture");
    default:
      ZinAssertImpl("Invalid tensor format");
  }
  *(_DWORD *)(result + 176) = v2;
  return result;
}

uint64_t ZinAneTd<4u>::SetL2ResultCfgDmaFmt(uint64_t result, int a2)
{
  switch(a2)
  {
    case 1:
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 192) & 0xFFFFFF3F;
      break;
    case 3:
    case 4:
    case 5:
    case 6:
    case 7:
    case 9:
    case 10:
      unsigned int v2 = *(_DWORD *)(result + 192) & 0xFFFFFF3F | 0x40;
      break;
    case 8:
      ZinAssertImpl("packed10 format not fully implemented yet");
    case 11:
      ZinAssertImpl("Float32 not supported for architecture");
    default:
      ZinAssertImpl("Invalid tensor format");
  }
  *(_DWORD *)(result + 192) = v2;
  return result;
}

void ZinAneTd<4u>::SetL2ResultWrapCfg(uint64_t a1, int a2)
{
  if (a2 != 5) {
    ZinAssertImpl("Error: Invalid Wrap Axis", v2, v3);
  }
}

void ZinAneTd<4u>::SetL2ResultWrapStartOffset(uint64_t a1, uint64_t a2)
{
  if (a2) {
    ZinAssertImpl("Error: Invalid wrap start offset", v2, v3);
  }
}

void ZinAneTd<4u>::SetL2ResultWrapIndex(uint64_t a1, int a2)
{
  if (a2) {
    ZinAssertImpl("Error: Invalid wrap index", v2, v3);
  }
}

void ZinAneTd<4u>::SetL2ResultWrapAddrOffset(uint64_t a1, uint64_t a2)
{
  if (a2) {
    ZinAssertImpl("Error: Result Wrap Addr Offset is invalid", v2, v3);
  }
}

void ZinAneTd<4u>::SetL2ResultWrapAddr(uint64_t a1, uint64_t a2)
{
  if (a2) {
    ZinAssertImpl("Error: Result Wrap Addr is invalid", v2, v3);
  }
}

void ZinAneTd<4u>::SetL2OutputCropOffsetXLSBs(uint64_t a1, uint64_t a2)
{
  if (a2) {
    ZinAssertImpl("Invalid Output Crop Offset X LSBs for architecture", v2, v3);
  }
}

BOOL ZinAneTd<4u>::SetL2Src1Interleave(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 280) + 288), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Source Interleave");
  }
  *(_DWORD *)(a1 + 176) = *(_DWORD *)(a1 + 176) & 0xFFFFF0FF | ((v4 & 0xF) << 8);
  return result;
}

uint64_t ZinAneTd<4u>::SetL2Src1SourceType(uint64_t result, int a2)
{
  int v2 = 0;
  switch(a2)
  {
    case 0:
      ZinAssertImpl("Error: It must have a valid L2 access mode");
    case 1:
      int v2 = 2;
      break;
    case 2:
      int v2 = 1;
      break;
    case 4:
      ZinAssertImpl("Invalid L2 Source Type");
    default:
      break;
  }
  *(_DWORD *)(result + 176) = *(_DWORD *)(result + 176) & 0xFFFFFFFC | v2;
  return result;
}

uint64_t ZinAneTd<4u>::SetOpMode(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 224) & 0xFFFFFFF8;
      goto LABEL_7;
    case 1:
      ZinAssertImpl("ElemWise not valid for architecture");
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 224) & 0xFFFFFFF8 | 3;
      goto LABEL_7;
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 224) & 0xFFFFFFF8 | 1;
      goto LABEL_7;
    case 4:
      unsigned int v2 = *(_DWORD *)(result + 224) & 0xFFFFFFF8 | 2;
      goto LABEL_7;
    case 5:
      unsigned int v2 = *(_DWORD *)(result + 224) & 0xFFFFFFF8 | 4;
LABEL_7:
      *(_DWORD *)(result + 224) = v2;
      break;
    case 6:
      ZinAssertImpl("RCAS not valid for architecture");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<4u>::SetKernelMode(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 224) & 0xFFFFFFF7;
LABEL_7:
      *(_DWORD *)(result + 224) = v2;
      return result;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 224) | 8;
      goto LABEL_7;
    case 2:
      ZinAssertImpl("Unsupported Kernel Mode");
  }
  return result;
}

uint64_t ZinAneTd<4u>::SetKernelFmt(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 220) & 0xFFFFFFFC;
      goto LABEL_5;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 220) & 0xFFFFFFFC | 1;
      goto LABEL_5;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 220) & 0xFFFFFFFC | 2;
LABEL_5:
      *(_DWORD *)(result + 22std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2;
      break;
    case 3:
      ZinAssertImpl("Unimplemented or Unsupported kernel format");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<4u>::SetKernelBaseHeader(uint64_t result, char a2)
{
  *(_DWORD *)(result + std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_DWORD *)(result + 32) & 0xFFFFFFF0 | a2 & 7 | 8;
  return result;
}

uint64_t ZinAneTd<4u>::SetKernelDmaSrcCoeffDmaEn(uint64_t result, int a2, uint64_t a3)
{
  *(_DWORD *)(*(void *)(result + 40) + 24 * a3 + 4) = *(_DWORD *)(*(void *)(result + 40) + 24 * a3 + 4) & 0xFFFFFFFE | a2;
  return result;
}

void ZinAneTd<4u>::SetKernelDmaSrcConfigPrefetch()
{
}

uint64_t ZinAneTd<4u>::SetKernelDmaSrcCoeffDmaCacheHint(uint64_t result, int a2, uint64_t a3)
{
  int v3 = 57344;
  switch(a2)
  {
    case 0:
      goto LABEL_5;
    case 1:
      int v3 = 0x2000;
      goto LABEL_5;
    case 2:
      int v3 = 0x4000;
      goto LABEL_5;
    case 3:
      int v3 = 49152;
LABEL_5:
      *(_DWORD *)(*(void *)(result + 40) + 24 * a3 + 4) = *(_DWORD *)(*(void *)(result + 40) + 24 * a3 + 4) & 0xFFFF0FFF | v3;
      break;
    case 4:
      ZinAssertImpl("Error: Invalid KernelDmaSrc CoeffDma CacheHint");
    default:
      return result;
  }
  return result;
}

BOOL ZinAneTd<4u>::SetKernelDmaSrcCoeffMemBufferSize(uint64_t a1, unsigned int a2, uint64_t a3)
{
  int v6 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 280) + 304), &v6);
  if (result) {
    *(_DWORD *)(*(void *)(a1 + 40) + 24 * a3 + 12) = *(_DWORD *)(*(void *)(a1 + 40) + 24 * a3 + 12) & 0xFFFE003F | ((v6 & 0x7FF) << 6);
  }
  return result;
}

void ZinAneTd<4u>::SetKernelDmaSrcCoeffBaseOffset()
{
}

uint64_t ZinAneTd<4u>::SetPaddingMode(uint64_t result, int a2, int a3)
{
  switch(a2)
  {
    case 1:
      if (a3) {
        goto LABEL_7;
      }
      int v3 = 0;
      break;
    case 2:
      if (a3) {
LABEL_7:
      }
        ZinAssertImpl("Error: padding-mode doesn't support constants");
      int v3 = 4;
      break;
    case 3:
      ZinAssertImpl("Platform doesn't support replication padding-mode");
    case 4:
      ZinAssertImpl("Platform doesn't support positive padding-mode");
    case 6:
      ZinAssertImpl("Platform doesn't support reflective padding mode");
    case 9:
      ZinAssertImpl("Platform doesn't support constant padding-mode");
    default:
      ZinAssertImpl("Invalid padding mode: %d", a2);
  }
  *(_DWORD *)(result + 172) = *(_DWORD *)(result + 172) & 0xFFFFFFFB | v3;
  return result;
}

BOOL ZinAneTd<4u>::SetL2ResultBaseAddr(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 280) + 216), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Result Base Address");
  }
  *(_DWORD *)(a1 + 196) = *(_DWORD *)(a1 + 196) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<4u>::SetL2ResultChannelStride(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 280) + 224), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Result Channel Stride");
  }
  *(_DWORD *)(a1 + 20std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 200) & 0xFFFF000F | (16 * (v4 & 0xFFF));
  return result;
}

BOOL ZinAneTd<4u>::SetL2ResultRowStride(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 280) + 232), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Result Row Stride");
  }
  *(_DWORD *)(a1 + 204) = *(_DWORD *)(a1 + 204) & 0xFFF0000F | (16 * (unsigned __int16)v4);
  return result;
}

uint64_t ZinAneTd<4u>::SetL2BfrMode(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 8;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 192) = *(_DWORD *)(result + 192) & 0xFFFFFFF7 | v2;
  return result;
}

uint64_t ZinAneTd<4u>::SetL2ResultType(uint64_t result, int a2)
{
  if (a2 == 2)
  {
    unsigned int v2 = *(_DWORD *)(result + 192) & 0xFFFFFFFC | 1;
  }
  else if (a2 == 3)
  {
    unsigned int v2 = *(_DWORD *)(result + 192) & 0xFFFFFFFC;
  }
  else
  {
    unsigned int v2 = *(_DWORD *)(result + 192) & 0xFFFFFFFC | 2;
  }
  *(_DWORD *)(result + 192) = v2;
  return result;
}

uint64_t ZinAneTd<4u>::SetTileDmaSrc1DependencyMode(uint64_t result, int a2)
{
  if (a2 == 2)
  {
    int v2 = *(_DWORD *)(result + 124);
    int v3 = 0x1000000;
LABEL_7:
    *(_DWORD *)(result + 124) = v2 & 0xFCFFFFFF | v3;
    return result;
  }
  if (a2 == 1)
  {
    int v2 = *(_DWORD *)(result + 124);
    if ((v2 & 0x3000000) == 0)
    {
      int v3 = 0x2000000;
      goto LABEL_7;
    }
  }
  return result;
}

uint64_t ZinAneTd<4u>::SetTileDmaDstFormat(uint64_t result, int a2, int a3)
{
  switch(a2)
  {
    case 1:
      unsigned int v3 = *(_DWORD *)(result + 268) & 0xFFFFCFFC | 0x1000;
      goto LABEL_15;
    case 2:
      unsigned int v3 = *(_DWORD *)(result + 268) & 0xFFFFCFFC;
      goto LABEL_15;
    case 3:
      unsigned int v4 = *(_DWORD *)(result + 268) & 0xFFFFCFCC;
      int v5 = 8241;
      break;
    case 4:
      unsigned int v3 = *(_DWORD *)(result + 268) & 0xFFFFCECC | 1;
      goto LABEL_15;
    case 5:
      unsigned int v4 = *(_DWORD *)(result + 268) & 0xFFFFCECC;
      int v5 = 257;
      break;
    case 6:
      unsigned int v4 = *(_DWORD *)(result + 268) & 0xFFFFCECC;
      int v5 = 17;
      break;
    case 7:
      unsigned int v4 = *(_DWORD *)(result + 268) & 0xFFFFCECC;
      int v5 = 273;
      break;
    case 8:
      ZinAssertImpl("Packed10 format not supported");
    case 9:
      unsigned int v4 = *(_DWORD *)(result + 268) & 0xFFFFCECC;
      if (!a3) {
        goto LABEL_10;
      }
      int v5 = 4401;
      break;
    case 10:
      unsigned int v4 = *(_DWORD *)(result + 268) & 0xFFFFCECC;
      if (a3) {
        int v5 = 305;
      }
      else {
LABEL_10:
      }
        int v5 = 8497;
      break;
    case 11:
      ZinAssertImpl("Invalid format provided for architecture");
    case 12:
      ZinAssertImpl("E4M3 is not supported");
    case 13:
      ZinAssertImpl("E5M2 is not supported");
    default:
      ZinAssertImpl("Invalid format provided");
  }
  unsigned int v3 = v4 | v5;
LABEL_15:
  *(_DWORD *)(result + 268) = v3;
  return result;
}

BOOL ZinAneTd<4u>::SetL2ResultInterleave(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 280) + 288), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Result Interleave");
  }
  *(_DWORD *)(a1 + 192) = *(_DWORD *)(a1 + 192) & 0xFFFFF0FF | ((v4 & 0xF) << 8);
  return result;
}

uint64_t ZinAneTd<4u>::SetTileDmaDstZeroPad(uint64_t result, _DWORD *a2)
{
  unsigned int v2 = *(_DWORD *)(result + 268) & 0xFFDFFFFF | ((*a2 == 0) << 21);
  *(_DWORD *)(result + 268) = v2;
  *(_DWORD *)(result + 268) = v2 & 0xFFEFFFFF | ((a2[1] == 0) << 20);
  return result;
}

void ZinAneTd<4u>::SetDoubleInt8Enable(uint64_t a1, int a2)
{
  if (a2) {
    ZinAssertImpl("2xInt8 mode is not supported", v2, v3);
  }
}

void ZinAneTd<4u>::SetPaletteBlockSize(uint64_t a1, int a2)
{
  if (a2) {
    ZinAssertImpl("Palette block size is not supported", v2, v3);
  }
}

uint64_t ZinAneTd<4u>::SetGroupKernelReuse(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 1024;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 22std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 220) & 0xFFFFFBFF | v2;
  return result;
}

uint64_t ZinAneTd<4u>::SetKernelSparseFmt(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 256;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 22std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 220) & 0xFFFFFEFF | v2;
  return result;
}

void ZinAneTd<4u>::SetKernelSparseBinary(uint64_t a1, int a2)
{
  if (a2) {
    ZinAssertImpl("Sparse binary mode is not supported", v2, v3);
  }
}

uint64_t ZinAneTd<4u>::SetKernelPalettizedEn(uint64_t result, int a2)
{
  int v2 = 0;
  switch(a2)
  {
    case 0:
    case 3:
    case 28:
    case 29:
    case 30:
    case 31:
    case 32:
      ZinAssertImpl("Unknown kernel format in codegen\n");
    case 7:
    case 8:
    case 9:
    case 10:
    case 11:
    case 12:
    case 13:
    case 14:
    case 15:
    case 16:
    case 17:
    case 18:
      ZinAssertImpl("Invalid kernel format");
    case 19:
    case 20:
    case 21:
    case 22:
    case 23:
    case 24:
    case 25:
    case 26:
    case 27:
      int v2 = 4;
      break;
    default:
      break;
  }
  *(_DWORD *)(result + 22std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 220) & 0xFFFFFFFB | v2;
  return result;
}

uint64_t ZinAneTd<4u>::SetKernelPalettizedBits(uint64_t result, int a2)
{
  int v2 = 128;
  switch(a2)
  {
    case 0:
    case 3:
    case 28:
    case 29:
    case 30:
    case 31:
    case 32:
      ZinAssertImpl("Unknown kernel format in codegen\n");
    case 7:
    case 8:
    case 9:
    case 10:
    case 11:
    case 12:
    case 13:
    case 14:
    case 15:
    case 16:
    case 17:
    case 18:
      ZinAssertImpl("Invalid kernel format");
    case 19:
    case 20:
    case 21:
    case 22:
      int v2 = 64;
      break;
    case 23:
    case 24:
    case 25:
    case 26:
      int v2 = 96;
      break;
    default:
      break;
  }
  *(_DWORD *)(result + 22std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 220) & 0xFFFFFF0F | v2;
  return result;
}

void ZinAneTd<4u>::SetKernelAsymQuantEn(uint64_t a1, int a2)
{
  if (a2) {
    ZinAssertImpl("Asym quantization is not supported", v2, v3);
  }
}

void ZinAneTd<4u>::SetKernelDetectZeros(uint64_t a1, int a2)
{
  if (a2) {
    ZinAssertImpl("On-the-fly Sparse Encoding is not supported", v2, v3);
  }
}

void ZinAneTd<4u>::SetQuantizationOutputZeroOffset(uint64_t a1, int a2, int a3)
{
  if (a3)
  {
    if (a2) {
      ZinAssertImpl("Quantization output zero offset is not supported", v3, v4);
    }
  }
}

uint64_t ZinAneTd<4u>::SetNEBinaryPoint(uint64_t result, char a2)
{
  *(_DWORD *)(result + 224) = *(_DWORD *)(result + 224) & 0xFFFFE0FF | ((a2 & 0x1F) << 8);
  return result;
}

uint64_t ZinAneTd<4u>::SetNENonLinearMode(uint64_t result, int a2, uint64_t a3)
{
  if (a2)
  {
    if (a2 == 1)
    {
      a2 = 0x10000;
    }
    else
    {
      uint64_t v4 = *(_DWORD **)a3;
      uint64_t v3 = *(_DWORD **)(a3 + 8);
      if (*(_DWORD **)a3 != v3)
      {
        while (*v4 != a2)
        {
          if (++v4 == v3)
          {
            uint64_t v4 = *(_DWORD **)(a3 + 8);
            break;
          }
        }
      }
      if (v4 == v3) {
        ZinAssertImpl("Error: illegal non-linear mode\n");
      }
      a2 = 0x20000;
    }
  }
  *(_DWORD *)(result + 224) = *(_DWORD *)(result + 224) & 0xFFFCFFFF | a2;
  return result;
}

uint64_t ZinAneTd<4u>::SetNEPostScale(uint64_t result, unint64_t a2, char a3)
{
  _S0 = a2;
  __asm { FCVT            H0, S0 }
  int v8 = _S0;
  if (!_ZF) {
    int v8 = 0;
  }
  int v9 = ((a2 & 0xFF0000000000) != 0) << 14;
  int v10 = -((a2 >> 16) & 0x1F0000) & 0x1F0000 | v8;
  if (!a3)
  {
    int v9 = 0;
    int v10 = 15360;
  }
  *(_DWORD *)(result + 224) = *(_DWORD *)(result + 224) & 0xFFFFBFFF | v9;
  *(_DWORD *)(result + 236) = v10 | *(_DWORD *)(result + 236) & 0xFFE00000;
  return result;
}

uint64_t ZinAneTd<4u>::SetNEBias(uint64_t result, unint64_t a2, char a3)
{
  _S0 = a2;
  __asm { FCVT            H0, S0 }
  int v8 = _S0;
  if (!_ZF) {
    int v8 = 0;
  }
  int v9 = 16 * ((a2 & 0xFF0000000000) != 0);
  int v10 = (a2 >> 16) & 0x1F0000 | v8;
  if (!a3)
  {
    int v9 = 0;
    int v10 = 0;
  }
  *(_DWORD *)(result + 224) = *(_DWORD *)(result + 224) & 0xFFFFFFEF | v9;
  *(_DWORD *)(result + 2std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = v10 | *(_DWORD *)(result + 232) & 0xFFE00000;
  return result;
}

ZinIrKernel *ZinAneTd<4u>::SetNEMatrixVectorBias(uint64_t a1, ZinIrKernel **a2, uint64_t a3)
{
  BOOL result = *a2;
  if (*a2) {
    _ZF = (a3 & 0xFF00000000) == 0;
  }
  else {
    _ZF = 1;
  }
  if (_ZF)
  {
    int v6 = 0;
  }
  else
  {
    _S8 = *(float *)&a3;
    BOOL result = (ZinIrKernel *)ZinIrKernel::GetWeightFormat(result);
    if (result == 4)
    {
      __asm { FCVT            H0, S8 }
      LOWORD(v8) = _H0;
    }
    else
    {
      if (result != 2 && result != 1) {
        ZinAssertImpl("Error: Invalid kernel format");
      }
      int v8 = (int)_S8;
    }
    *(_WORD *)(a1 + 228) = v8;
    int v6 = 64;
  }
  *(_DWORD *)(a1 + 224) = *(_DWORD *)(a1 + 224) & 0xFFFFFFBF | v6;
  return result;
}

uint64_t ZinAneTd<4u>::SetNEOcgSize(uint64_t result, char a2)
{
  *(_DWORD *)(result + 88) = *(_DWORD *)(result + 88) & 0xFFFF8FFF | ((a2 & 7) << 12);
  return result;
}

uint64_t ZinAneTd<4u>::SetNESmallSourceMode(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 100) & 0xFFFFFFFB;
      goto LABEL_4;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 100) | 4;
LABEL_4:
      *(_DWORD *)(result + 10std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2;
      break;
    case 2:
      ZinAssertImpl("Error: Tiny source mode is not supported for this arch");
    case 3:
    case 4:
      ZinAssertImpl("Error: NP2 small source mode  is not supported for this arch");
    default:
      return result;
  }
  return result;
}

_DWORD *ZinAneTd<4u>::SetDoubleBufferingBasedOnOtherRegisters(_DWORD *result, unsigned int a2)
{
  int v2 = result[25];
  if ((v2 & 0x4000000) == 0)
  {
    if ((v2 & 4) != 0)
    {
      unsigned __int16 v3 = 4;
    }
    else if ((result[18] & 3) == 2)
    {
      unsigned __int16 v3 = 2;
    }
    else
    {
      unsigned __int16 v3 = 1;
    }
    unsigned int v4 = (((result[22] >> 28) & 3u) << ((result[22] >> 12) & 7)) * (result[22] >> 30) / v3;
    if (v4 <= 1) {
      unsigned int v4 = 1;
    }
    if (v4 <= a2 >> 1) {
      result[25] = v2 | 0x4000000;
    }
  }
  return result;
}

uint64_t ZinAneTd<4u>::SetCommonInFmt(uint64_t result, int a2)
{
  if (a2 > 2)
  {
    if (a2 == 3)
    {
      unsigned int v2 = *(_DWORD *)(result + 72) & 0xFFFFFFFC | 2;
      goto LABEL_8;
    }
    if (a2 == 12) {
      ZinAssertImpl("Error: Invalid Common InFmt E4M3");
    }
LABEL_11:
    ZinAssertImpl("Error: Invalid TD programming for Src1 input format");
  }
  if (a2 == 1)
  {
    unsigned int v2 = *(_DWORD *)(result + 72) & 0xFFFFFFFC | 1;
    goto LABEL_8;
  }
  if (a2 != 2) {
    goto LABEL_11;
  }
  unsigned int v2 = *(_DWORD *)(result + 72) & 0xFFFFFFFC;
LABEL_8:
  *(_DWORD *)(result + 72) = v2;
  return result;
}

uint64_t ZinAneTd<4u>::SetCommonOutFmt(uint64_t result, int a2)
{
  if ((a2 - 3) < 9) {
    goto LABEL_2;
  }
  if (a2 <= 11)
  {
    if (a2 == 1)
    {
      unsigned int v2 = *(_DWORD *)(result + 72) & 0xFFFFFFCF | 0x10;
      goto LABEL_3;
    }
    if (a2 == 2)
    {
      unsigned int v2 = *(_DWORD *)(result + 72) & 0xFFFFFFCF;
      goto LABEL_3;
    }
LABEL_12:
    ZinAssertImpl("Error: Invalid output format");
  }
  if (a2 != 13)
  {
    if (a2 == 12) {
      ZinAssertImpl("Error: E4M3 is not supported");
    }
    goto LABEL_12;
  }
LABEL_2:
  unsigned int v2 = *(_DWORD *)(result + 72) & 0xFFFFFFCF | 0x20;
LABEL_3:
  *(_DWORD *)(result + 72) = v2;
  return result;
}

BOOL ZinAneTd<4u>::SetTileHeight(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 280) + 152), &v4);
  if (result) {
    *(_DWORD *)(a1 + 96) = *(_DWORD *)(a1 + 96) & 0xFFFF8000 | v4 & 0x7FFF;
  }
  return result;
}

BOOL ZinAneTd<4u>::SetCommonConvCfgKh(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 280) + 120), &v4);
  if (result) {
    *(_DWORD *)(a1 + 88) = *(_DWORD *)(a1 + 88) & 0xFFFFF83F | ((v4 & 0x1F) << 6);
  }
  return result;
}

BOOL ZinAneTd<4u>::SetCommonConvCfgKw(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 280) + 128), &v4);
  if (result) {
    *(_DWORD *)(a1 + 88) = *(_DWORD *)(a1 + 88) & 0xFFFFFFE0 | v4 & 0x1F;
  }
  return result;
}

BOOL ZinAneTd<4u>::SetCommonConvCfgSx(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 280) + 104), &v4);
  if (result) {
    *(_DWORD *)(a1 + 88) = *(_DWORD *)(a1 + 88) & 0xFFFCFFFF | ((v4 & 3) << 16);
  }
  return result;
}

BOOL ZinAneTd<4u>::SetCommonConvCfgSy(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 280) + 96), &v4);
  if (result) {
    *(_DWORD *)(a1 + 88) = *(_DWORD *)(a1 + 88) & 0xFFF3FFFF | ((v4 & 3) << 18);
  }
  return result;
}

BOOL ZinAneTd<4u>::SetCommonConvCfgOx(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 280) + 72), &v4);
  if (result) {
    *(_DWORD *)(a1 + 88) = *(_DWORD *)(a1 + 88) & 0xCFFFFFFF | ((v4 & 3) << 28);
  }
  return result;
}

BOOL ZinAneTd<4u>::SetCommonConvCfgOy(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 280) + 64), &v4);
  if (result) {
    *(_DWORD *)(a1 + 88) = *(_DWORD *)(a1 + 88) & 0x3FFFFFFF | (v4 << 30);
  }
  return result;
}

BOOL ZinAneTd<4u>::SetCommonConvCfgPadLeft(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 280) + 88), &v4);
  if (result) {
    *(_DWORD *)(a1 + 88) = *(_DWORD *)(a1 + 88) & 0xFF0FFFFF | ((v4 & 0xF) << 20);
  }
  return result;
}

BOOL ZinAneTd<4u>::SetCommonConvCfgPadTop(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 280) + 80), &v4);
  if (result) {
    *(_DWORD *)(a1 + 88) = *(_DWORD *)(a1 + 88) & 0xF0FFFFFF | ((v4 & 0xF) << 24);
  }
  return result;
}

BOOL ZinAneTd<4u>::SetOrReturnNumGroups(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 280) + 136), &v4);
  if (result) {
    *(_DWORD *)(a1 + 92) = *(_DWORD *)(a1 + 92) & 0xFFFFE000 | v4 & 0x1FFF;
  }
  return result;
}

BOOL ZinAneTd<4u>::SetOrReturnWin(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 280) + 24), &v4);
  if (result) {
    *(_DWORD *)(a1 + 68) = *(_DWORD *)(a1 + 68) & 0xFFFF8000 | v4 & 0x7FFF;
  }
  return result;
}

BOOL ZinAneTd<4u>::SetOrReturnHin(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 280) + 16), &v4);
  if (result) {
    *(_DWORD *)(a1 + 68) = *(_DWORD *)(a1 + 68) & 0x8000FFFF | ((v4 & 0x7FFF) << 16);
  }
  return result;
}

BOOL ZinAneTd<4u>::SetOrReturnWout(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 280) + 56), &v4);
  if (result) {
    *(_DWORD *)(a1 + 84) = *(_DWORD *)(a1 + 84) & 0xFFFF8000 | v4 & 0x7FFF;
  }
  return result;
}

BOOL ZinAneTd<4u>::SetOrReturnHout(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 280) + 48), &v4);
  if (result) {
    *(_DWORD *)(a1 + 84) = *(_DWORD *)(a1 + 84) & 0x8000FFFF | ((v4 & 0x7FFF) << 16);
  }
  return result;
}

BOOL ZinAneTd<4u>::SetOrReturnCout(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 280) + 40), &v4);
  if (result) {
    *(_DWORD *)(a1 + 8std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 80) & 0xFFFE0000 | v4 & 0x1FFFF;
  }
  return result;
}

uint64_t ZinAneTd<4u>::SetUnicastEn(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 0x4000;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 92) = *(_DWORD *)(result + 92) & 0xFFFFBFFF | v2;
  return result;
}

BOOL ZinAneTd<4u>::SetUnicastCin(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 280) + 144), &v4);
  if (result) {
    *(_WORD *)(a1 + 94) = v4;
  }
  return result;
}

void ZinAneTd<5u>::SetL2Barrier()
{
}

uint64_t ZinAneTd<5u>::SetEventFlags(uint64_t result, __int16 a2, __int16 a3, int a4)
{
  *(_WORD *)(result + 16) = a2;
  if (a4) {
    ZinAssertImpl("DRAM Events not supported for architecture");
  }
  *(_WORD *)(result + 2std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = a3;
  return result;
}

uint64_t ZinAneTd<5u>::SetL2Src1DmaFormat(uint64_t result, int a2)
{
  switch(a2)
  {
    case 1:
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 176) & 0xFFFFFF3F;
      break;
    case 3:
    case 4:
    case 5:
    case 6:
    case 7:
    case 9:
    case 10:
      unsigned int v2 = *(_DWORD *)(result + 176) & 0xFFFFFF3F | 0x40;
      break;
    case 8:
      ZinAssertImpl("packed10 format not fully implemented yet");
    case 11:
      ZinAssertImpl("Float32 not supported for architecture");
    default:
      ZinAssertImpl("Invalid tensor format");
  }
  *(_DWORD *)(result + 176) = v2;
  return result;
}

uint64_t ZinAneTd<5u>::SetL2ResultCfgDmaFmt(uint64_t result, int a2)
{
  switch(a2)
  {
    case 1:
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 192) & 0xFFFFFF3F;
      break;
    case 3:
    case 4:
    case 5:
    case 6:
    case 7:
    case 9:
    case 10:
      unsigned int v2 = *(_DWORD *)(result + 192) & 0xFFFFFF3F | 0x40;
      break;
    case 8:
      ZinAssertImpl("packed10 format not fully implemented yet");
    case 11:
      ZinAssertImpl("Float32 not supported for architecture");
    default:
      ZinAssertImpl("Invalid tensor format");
  }
  *(_DWORD *)(result + 192) = v2;
  return result;
}

uint64_t ZinAneTd<5u>::SetL2Src1SourceType(uint64_t result, int a2)
{
  int v2 = 0;
  switch(a2)
  {
    case 0:
      ZinAssertImpl("Error: It must have a valid L2 access mode");
    case 1:
      int v2 = 2;
      break;
    case 2:
      int v2 = 1;
      break;
    case 4:
      ZinAssertImpl("Invalid L2 Source Type");
    default:
      break;
  }
  *(_DWORD *)(result + 176) = *(_DWORD *)(result + 176) & 0xFFFFFFFC | v2;
  return result;
}

uint64_t ZinAneTd<5u>::SetOpMode(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 224) & 0xFFFFFFF8;
      goto LABEL_7;
    case 1:
      ZinAssertImpl("ElemWise not valid for architecture");
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 224) & 0xFFFFFFF8 | 3;
      goto LABEL_7;
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 224) & 0xFFFFFFF8 | 1;
      goto LABEL_7;
    case 4:
      unsigned int v2 = *(_DWORD *)(result + 224) & 0xFFFFFFF8 | 2;
      goto LABEL_7;
    case 5:
      unsigned int v2 = *(_DWORD *)(result + 224) & 0xFFFFFFF8 | 4;
LABEL_7:
      *(_DWORD *)(result + 224) = v2;
      break;
    case 6:
      ZinAssertImpl("RCAS not valid for architecture");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<5u>::SetKernelFmt(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 220) & 0xFFFFFFFC;
      goto LABEL_5;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 220) & 0xFFFFFFFC | 1;
      goto LABEL_5;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 220) & 0xFFFFFFFC | 2;
LABEL_5:
      *(_DWORD *)(result + 22std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2;
      break;
    case 3:
      ZinAssertImpl("Unimplemented or Unsupported kernel format");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<5u>::SetKernelDmaSrcCoeffDmaCacheHint(uint64_t result, int a2, uint64_t a3)
{
  int v3 = 57344;
  switch(a2)
  {
    case 0:
      goto LABEL_5;
    case 1:
      int v3 = 0x2000;
      goto LABEL_5;
    case 2:
      int v3 = 0x4000;
      goto LABEL_5;
    case 3:
      int v3 = 49152;
LABEL_5:
      *(_DWORD *)(*(void *)(result + 40) + 24 * a3 + 4) = *(_DWORD *)(*(void *)(result + 40) + 24 * a3 + 4) & 0xFFFF0FFF | v3;
      break;
    case 4:
      ZinAssertImpl("Error: Invalid KernelDmaSrc CoeffDma CacheHint");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<5u>::SetPaddingMode(uint64_t result, int a2, int a3)
{
  switch(a2)
  {
    case 1:
      if (a3) {
        goto LABEL_7;
      }
      int v3 = 0;
      break;
    case 2:
      if (a3) {
LABEL_7:
      }
        ZinAssertImpl("Error: padding-mode doesn't support constants");
      int v3 = 4;
      break;
    case 3:
      ZinAssertImpl("Platform doesn't support replication padding-mode");
    case 4:
      ZinAssertImpl("Platform doesn't support positive padding-mode");
    case 6:
      ZinAssertImpl("Platform doesn't support reflective padding mode");
    case 9:
      ZinAssertImpl("Platform doesn't support constant padding-mode");
    default:
      ZinAssertImpl("Invalid padding mode: %d", a2);
  }
  *(_DWORD *)(result + 172) = *(_DWORD *)(result + 172) & 0xFFFFFFFB | v3;
  return result;
}

uint64_t ZinAneTd<5u>::SetTileDmaDstFormat(uint64_t result, int a2, int a3)
{
  switch(a2)
  {
    case 1:
      unsigned int v3 = *(_DWORD *)(result + 268) & 0xFFFFCFFC | 0x1000;
      goto LABEL_15;
    case 2:
      unsigned int v3 = *(_DWORD *)(result + 268) & 0xFFFFCFFC;
      goto LABEL_15;
    case 3:
      unsigned int v4 = *(_DWORD *)(result + 268) & 0xFFFFCFCC;
      int v5 = 8241;
      break;
    case 4:
      unsigned int v3 = *(_DWORD *)(result + 268) & 0xFFFFCECC | 1;
      goto LABEL_15;
    case 5:
      unsigned int v4 = *(_DWORD *)(result + 268) & 0xFFFFCECC;
      int v5 = 257;
      break;
    case 6:
      unsigned int v4 = *(_DWORD *)(result + 268) & 0xFFFFCECC;
      int v5 = 17;
      break;
    case 7:
      unsigned int v4 = *(_DWORD *)(result + 268) & 0xFFFFCECC;
      int v5 = 273;
      break;
    case 8:
      ZinAssertImpl("Packed10 format not supported");
    case 9:
      unsigned int v4 = *(_DWORD *)(result + 268) & 0xFFFFCECC;
      if (!a3) {
        goto LABEL_10;
      }
      int v5 = 4401;
      break;
    case 10:
      unsigned int v4 = *(_DWORD *)(result + 268) & 0xFFFFCECC;
      if (a3) {
        int v5 = 305;
      }
      else {
LABEL_10:
      }
        int v5 = 8497;
      break;
    case 11:
      ZinAssertImpl("Invalid format provided for architecture");
    case 12:
      ZinAssertImpl("E4M3 is not supported");
    case 13:
      ZinAssertImpl("E5M2 is not supported");
    default:
      ZinAssertImpl("Invalid format provided");
  }
  unsigned int v3 = v4 | v5;
LABEL_15:
  *(_DWORD *)(result + 268) = v3;
  return result;
}

uint64_t ZinAneTd<5u>::SetKernelPalettizedEn(uint64_t result, int a2)
{
  int v2 = 0;
  switch(a2)
  {
    case 0:
    case 3:
    case 28:
    case 29:
    case 30:
    case 31:
    case 32:
      ZinAssertImpl("Unknown kernel format in codegen\n");
    case 7:
    case 8:
    case 9:
    case 10:
    case 11:
    case 12:
    case 13:
    case 14:
    case 15:
    case 16:
    case 17:
    case 18:
      ZinAssertImpl("Invalid kernel format");
    case 19:
    case 20:
    case 21:
    case 22:
    case 23:
    case 24:
    case 25:
    case 26:
    case 27:
      int v2 = 4;
      break;
    default:
      break;
  }
  *(_DWORD *)(result + 22std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 220) & 0xFFFFFFFB | v2;
  return result;
}

uint64_t ZinAneTd<5u>::SetKernelPalettizedBits(uint64_t result, int a2)
{
  int v2 = 128;
  switch(a2)
  {
    case 0:
    case 3:
    case 28:
    case 29:
    case 30:
    case 31:
    case 32:
      ZinAssertImpl("Unknown kernel format in codegen\n");
    case 7:
    case 8:
    case 9:
    case 10:
    case 11:
    case 12:
    case 13:
    case 14:
    case 15:
    case 16:
    case 17:
    case 18:
      ZinAssertImpl("Invalid kernel format");
    case 19:
    case 20:
    case 21:
    case 22:
      int v2 = 64;
      break;
    case 23:
    case 24:
    case 25:
    case 26:
      int v2 = 96;
      break;
    default:
      break;
  }
  *(_DWORD *)(result + 22std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 220) & 0xFFFFFF0F | v2;
  return result;
}

uint64_t ZinAneTd<5u>::SetNESmallSourceMode(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 100) & 0xFFFFFFFB;
      goto LABEL_4;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 100) | 4;
LABEL_4:
      *(_DWORD *)(result + 10std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2;
      break;
    case 2:
      ZinAssertImpl("Error: Tiny source mode is not supported for this arch");
    case 3:
    case 4:
      ZinAssertImpl("Error: NP2 small source mode  is not supported for this arch");
    default:
      return result;
  }
  return result;
}

void ZinAneTd<6u>::SetL2Barrier()
{
}

uint64_t ZinAneTd<6u>::SetEventFlags(uint64_t result, __int16 a2, __int16 a3, int a4)
{
  *(_WORD *)(result + 16) = a2;
  if (a4) {
    ZinAssertImpl("DRAM Events not supported for architecture");
  }
  *(_WORD *)(result + 2std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = a3;
  return result;
}

uint64_t ZinAneTd<6u>::SetL2Src1DmaFormat(uint64_t result, int a2)
{
  switch(a2)
  {
    case 1:
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 176) & 0xFFFFFF3F;
      break;
    case 3:
    case 4:
    case 5:
    case 6:
    case 7:
    case 9:
    case 10:
      unsigned int v2 = *(_DWORD *)(result + 176) & 0xFFFFFF3F | 0x40;
      break;
    case 8:
      ZinAssertImpl("packed10 format not fully implemented yet");
    case 11:
      ZinAssertImpl("Float32 not supported for architecture");
    default:
      ZinAssertImpl("Invalid tensor format");
  }
  *(_DWORD *)(result + 176) = v2;
  return result;
}

uint64_t ZinAneTd<6u>::SetL2ResultCfgDmaFmt(uint64_t result, int a2)
{
  switch(a2)
  {
    case 1:
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 192) & 0xFFFFFF3F;
      break;
    case 3:
    case 4:
    case 5:
    case 6:
    case 7:
    case 9:
    case 10:
      unsigned int v2 = *(_DWORD *)(result + 192) & 0xFFFFFF3F | 0x40;
      break;
    case 8:
      ZinAssertImpl("packed10 format not fully implemented yet");
    case 11:
      ZinAssertImpl("Float32 not supported for architecture");
    default:
      ZinAssertImpl("Invalid tensor format");
  }
  *(_DWORD *)(result + 192) = v2;
  return result;
}

uint64_t ZinAneTd<6u>::SetL2Src1SourceType(uint64_t result, int a2)
{
  int v2 = 0;
  switch(a2)
  {
    case 0:
      ZinAssertImpl("Error: It must have a valid L2 access mode");
    case 1:
      int v2 = 2;
      break;
    case 2:
      int v2 = 1;
      break;
    case 4:
      ZinAssertImpl("Invalid L2 Source Type");
    default:
      break;
  }
  *(_DWORD *)(result + 176) = *(_DWORD *)(result + 176) & 0xFFFFFFFC | v2;
  return result;
}

uint64_t ZinAneTd<6u>::SetOpMode(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 224) & 0xFFFFFFF8;
      goto LABEL_7;
    case 1:
      ZinAssertImpl("ElemWise not valid for architecture");
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 224) & 0xFFFFFFF8 | 3;
      goto LABEL_7;
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 224) & 0xFFFFFFF8 | 1;
      goto LABEL_7;
    case 4:
      unsigned int v2 = *(_DWORD *)(result + 224) & 0xFFFFFFF8 | 2;
      goto LABEL_7;
    case 5:
      unsigned int v2 = *(_DWORD *)(result + 224) & 0xFFFFFFF8 | 4;
LABEL_7:
      *(_DWORD *)(result + 224) = v2;
      break;
    case 6:
      ZinAssertImpl("RCAS not valid for architecture");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<6u>::SetKernelFmt(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 220) & 0xFFFFFFFC;
      goto LABEL_5;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 220) & 0xFFFFFFFC | 1;
      goto LABEL_5;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 220) & 0xFFFFFFFC | 2;
LABEL_5:
      *(_DWORD *)(result + 22std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2;
      break;
    case 3:
      ZinAssertImpl("Unimplemented or Unsupported kernel format");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<6u>::SetKernelDmaSrcCoeffDmaCacheHint(uint64_t result, int a2, uint64_t a3)
{
  int v3 = 57344;
  switch(a2)
  {
    case 0:
      goto LABEL_5;
    case 1:
      int v3 = 0x2000;
      goto LABEL_5;
    case 2:
      int v3 = 0x4000;
      goto LABEL_5;
    case 3:
      int v3 = 49152;
LABEL_5:
      *(_DWORD *)(*(void *)(result + 40) + 24 * a3 + 4) = *(_DWORD *)(*(void *)(result + 40) + 24 * a3 + 4) & 0xFFFF0FFF | v3;
      break;
    case 4:
      ZinAssertImpl("Error: Invalid KernelDmaSrc CoeffDma CacheHint");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<6u>::SetPaddingMode(uint64_t result, int a2, int a3)
{
  switch(a2)
  {
    case 1:
      if (a3) {
        goto LABEL_9;
      }
      int v3 = 0;
      break;
    case 2:
      if (a3) {
        goto LABEL_9;
      }
      int v3 = 4;
      break;
    case 3:
      if (a3) {
LABEL_9:
      }
        ZinAssertImpl("Error: padding-mode doesn't support constants");
      int v3 = 8;
      break;
    case 4:
      ZinAssertImpl("Platform doesn't support positive padding-mode");
    case 6:
      ZinAssertImpl("Platform doesn't support reflective padding mode");
    case 9:
      ZinAssertImpl("Platform doesn't support constant padding-mode");
    default:
      ZinAssertImpl("Invalid padding mode: %d", a2);
  }
  *(_DWORD *)(result + 172) = *(_DWORD *)(result + 172) & 0xFFFFFFF3 | v3;
  return result;
}

uint64_t ZinAneTd<6u>::SetTileDmaDstFormat(uint64_t result, int a2, int a3)
{
  switch(a2)
  {
    case 1:
      unsigned int v3 = *(_DWORD *)(result + 268) & 0xFFFFCFFC | 0x1000;
      goto LABEL_15;
    case 2:
      unsigned int v3 = *(_DWORD *)(result + 268) & 0xFFFFCFFC;
      goto LABEL_15;
    case 3:
      unsigned int v4 = *(_DWORD *)(result + 268) & 0xFFFFCFCC;
      int v5 = 8241;
      break;
    case 4:
      unsigned int v3 = *(_DWORD *)(result + 268) & 0xFFFFCECC | 1;
      goto LABEL_15;
    case 5:
      unsigned int v4 = *(_DWORD *)(result + 268) & 0xFFFFCECC;
      int v5 = 257;
      break;
    case 6:
      unsigned int v4 = *(_DWORD *)(result + 268) & 0xFFFFCECC;
      int v5 = 17;
      break;
    case 7:
      unsigned int v4 = *(_DWORD *)(result + 268) & 0xFFFFCECC;
      int v5 = 273;
      break;
    case 8:
      ZinAssertImpl("Packed10 format not supported");
    case 9:
      unsigned int v4 = *(_DWORD *)(result + 268) & 0xFFFFCECC;
      if (!a3) {
        goto LABEL_10;
      }
      int v5 = 4401;
      break;
    case 10:
      unsigned int v4 = *(_DWORD *)(result + 268) & 0xFFFFCECC;
      if (a3) {
        int v5 = 305;
      }
      else {
LABEL_10:
      }
        int v5 = 8497;
      break;
    case 11:
      ZinAssertImpl("Invalid format provided for architecture");
    case 12:
      ZinAssertImpl("E4M3 is not supported");
    case 13:
      ZinAssertImpl("E5M2 is not supported");
    default:
      ZinAssertImpl("Invalid format provided");
  }
  unsigned int v3 = v4 | v5;
LABEL_15:
  *(_DWORD *)(result + 268) = v3;
  return result;
}

uint64_t ZinAneTd<6u>::SetKernelPalettizedEn(uint64_t result, int a2)
{
  int v2 = 0;
  switch(a2)
  {
    case 0:
    case 3:
    case 28:
    case 29:
    case 30:
    case 31:
    case 32:
      ZinAssertImpl("Unknown kernel format in codegen\n");
    case 7:
    case 8:
    case 9:
    case 10:
    case 11:
    case 12:
    case 13:
    case 14:
    case 15:
    case 16:
    case 17:
    case 18:
      ZinAssertImpl("Invalid kernel format");
    case 19:
    case 20:
    case 21:
    case 22:
    case 23:
    case 24:
    case 25:
    case 26:
    case 27:
      int v2 = 4;
      break;
    default:
      break;
  }
  *(_DWORD *)(result + 22std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 220) & 0xFFFFFFFB | v2;
  return result;
}

uint64_t ZinAneTd<6u>::SetKernelPalettizedBits(uint64_t result, int a2)
{
  int v2 = 128;
  switch(a2)
  {
    case 0:
    case 3:
    case 28:
    case 29:
    case 30:
    case 31:
    case 32:
      ZinAssertImpl("Unknown kernel format in codegen\n");
    case 7:
    case 8:
    case 9:
    case 10:
    case 11:
    case 12:
    case 13:
    case 14:
    case 15:
    case 16:
    case 17:
    case 18:
      ZinAssertImpl("Invalid kernel format");
    case 19:
    case 20:
    case 21:
    case 22:
      int v2 = 64;
      break;
    case 23:
    case 24:
    case 25:
    case 26:
      int v2 = 96;
      break;
    default:
      break;
  }
  *(_DWORD *)(result + 22std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 220) & 0xFFFFFF0F | v2;
  return result;
}

uint64_t ZinAneTd<6u>::SetNESmallSourceMode(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 100) & 0xFFFFFFFB;
      goto LABEL_4;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 100) | 4;
LABEL_4:
      *(_DWORD *)(result + 10std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2;
      break;
    case 2:
      ZinAssertImpl("Error: Tiny source mode is not supported for this arch");
    case 3:
    case 4:
      ZinAssertImpl("Error: NP2 small source mode  is not supported for this arch");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<7u>::SetWARdmaDependency(uint64_t result, uint64_t a2, int a3, char a4, int **a5)
{
  if (*(unsigned char *)(a2 + 1323)) {
    ZinAssertImpl("inconsistent WAR support");
  }
  if (a3)
  {
    int v5 = *a5;
    int v6 = a5[1];
    if (*a5 != v6)
    {
      do
      {
        uint64_t v7 = *v5;
        if (v7 <= 2) {
          *(_DWORD *)(result + 792) |= dword_211F042F8[v7];
        }
        ++v5;
      }
      while (v5 != v6);
    }
    *(_DWORD *)(result + 792) = *(_DWORD *)(result + 792) & 0xFC3FFFFF | ((a4 & 0xF) << 22);
  }
  return result;
}

uint64_t ZinAneTd<7u>::SetL2Barrier(uint64_t result)
{
  *(_DWORD *)(result + 520) |= 0x800000u;
  return result;
}

uint64_t ZinAneTd<7u>::SetEventFlags(uint64_t result, int a2, int a3, int a4)
{
  *(_DWORD *)(result + 16) = a2 & 0xFFFFFF | (*(unsigned __int8 *)(result + 19) << 24);
  if (a4) {
    ZinAssertImpl("DRAM Events not supported for architecture");
  }
  *(_DWORD *)(result + 24) = a3 & 0xFFFFFF | (*(unsigned __int8 *)(result + 27) << 24);
  return result;
}

BOOL ZinAneTd<7u>::SetL2SrcBaseAddress(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 840) + 296), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src Base Address");
  }
  *(_DWORD *)(a1 + 668) = *(_DWORD *)(a1 + 668) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<7u>::SetL2Src1ChannelStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x11uLL, (unsigned int *)(*(void *)(a1 + 840) + 304), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src Channel Stride");
  }
  *(_DWORD *)(a1 + 672) = *(_DWORD *)(a1 + 672) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<7u>::SetL2SrcRowStride(uint64_t a1, ZinCodegen *this, ZinTensorDimensions *a3, uint64_t a4, uint64_t *a5)
{
  int v8 = 0;
  ZinCodegen::GetL2RowStride(this, a3, *(unsigned int *)(*(void *)(a1 + 840) + 316), &v8, a5);
  unsigned int v7 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(v8, 0x11uLL, (unsigned int *)(*(void *)(a1 + 840) + 312), &v7);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src Row Stride");
  }
  *(_DWORD *)(a1 + 676) = *(_DWORD *)(a1 + 676) & 0xFFE0000F | (16 * (v7 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<7u>::SetL2Src1DepthStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x11uLL, (unsigned int *)(*(void *)(a1 + 840) + 328), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src Depth Stride");
  }
  *(_DWORD *)(a1 + 68std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 680) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<7u>::SetL2Src1GroupStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x11uLL, (unsigned int *)(*(void *)(a1 + 840) + 336), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src Group Stride");
  }
  *(_DWORD *)(a1 + 684) = *(_DWORD *)(a1 + 684) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

uint64_t ZinAneTd<7u>::SetL2Src1DmaFormat(uint64_t result, int a2)
{
  switch(a2)
  {
    case 1:
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 664) & 0xFFFFFF3F;
      break;
    case 3:
    case 4:
    case 5:
    case 6:
    case 7:
    case 9:
    case 10:
      unsigned int v2 = *(_DWORD *)(result + 664) & 0xFFFFFF3F | 0x40;
      break;
    case 8:
      ZinAssertImpl("Packed10 format not fully implemented yet\n");
    case 11:
      ZinAssertImpl("32 bit format not supported");
    case 12:
    case 13:
      ZinAssertImpl("E4M3 or E5M2 format not supported");
    default:
      ZinAssertImpl("Invalid Dma Format");
  }
  *(_DWORD *)(result + 664) = v2;
  return result;
}

uint64_t ZinAneTd<7u>::SetL2ResultCfgDmaFmt(uint64_t result, int a2)
{
  switch(a2)
  {
    case 1:
    case 2:
    case 12:
    case 13:
      unsigned int v2 = *(_DWORD *)(result + 708) & 0xFFFFFF3F;
      break;
    case 3:
    case 4:
    case 5:
    case 6:
    case 7:
    case 9:
    case 10:
      unsigned int v2 = *(_DWORD *)(result + 708) & 0xFFFFFF3F | 0x40;
      break;
    case 8:
      ZinAssertImpl("packed10 format not fully implemented yet");
    case 11:
      ZinAssertImpl("Float32 not supported for architecture");
    default:
      ZinAssertImpl("Invalid tensor format");
  }
  *(_DWORD *)(result + 708) = v2;
  return result;
}

uint64_t ZinAneTd<7u>::SetL2SrcOffsetYlsbsFromCropOffsetY(uint64_t a1)
{
  uint64_t result = ZinExtractLSBs(*(unsigned __int16 *)(a1 + 616), 2);
  *(_DWORD *)(a1 + 664) = *(_DWORD *)(a1 + 664) & 0x3FFFFFFF | (result << 30);
  return result;
}

BOOL ZinAneTd<7u>::SetL2Src1Interleave(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 840) + 552), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Source Interleave");
  }
  *(_DWORD *)(a1 + 664) = *(_DWORD *)(a1 + 664) & 0xFFFFF0FF | ((v4 & 0xF) << 8);
  return result;
}

uint64_t ZinAneTd<7u>::SetL2Src1SourceType(uint64_t result, int a2)
{
  int v2 = 0;
  switch(a2)
  {
    case 0:
      ZinAssertImpl("Error: It must have a valid L2 access mode");
    case 1:
      int v2 = 2;
      break;
    case 2:
      int v2 = 1;
      break;
    case 4:
      int v2 = 3;
      break;
    default:
      break;
  }
  *(_DWORD *)(result + 664) = *(_DWORD *)(result + 664) & 0xFFFFFFFC | v2;
  return result;
}

uint64_t ZinAneTd<7u>::SetL2Src2SourceType(uint64_t result, int a2)
{
  int v2 = 0;
  switch(a2)
  {
    case 0:
      ZinAssertImpl("Error: It must have a valid L2 access mode");
    case 1:
      int v2 = 0x1000000;
      break;
    case 2:
      int v2 = 0x800000;
      break;
    case 4:
      int v2 = 25165824;
      break;
    default:
      break;
  }
  *(_DWORD *)(result + 664) = *(_DWORD *)(result + 664) & 0xFE7FFFFF | v2;
  return result;
}

BOOL ZinAneTd<7u>::SetL2Src2BaseAddress(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 840) + 344), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src2 Base Address");
  }
  *(_DWORD *)(a1 + 688) = *(_DWORD *)(a1 + 688) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<7u>::SetL2Src2ChannelStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x11uLL, (unsigned int *)(*(void *)(a1 + 840) + 352), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Source 2 Channel Stride");
  }
  *(_DWORD *)(a1 + 692) = *(_DWORD *)(a1 + 692) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<7u>::SetL2Src2RowStride(uint64_t a1, ZinCodegen *this, ZinTensorDimensions *a3, uint64_t a4, uint64_t *a5)
{
  int v8 = 0;
  ZinCodegen::GetL2RowStride(this, a3, *(unsigned int *)(*(void *)(a1 + 840) + 364), &v8, a5);
  unsigned int v7 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(v8, 0x11uLL, (unsigned int *)(*(void *)(a1 + 840) + 360), &v7);
  if (!result) {
    ZinAssertImpl("Illegal L2 Source 2 Row Stride");
  }
  *(_DWORD *)(a1 + 696) = *(_DWORD *)(a1 + 696) & 0xFFE0000F | (16 * (v7 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<7u>::SetL2Src2DepthStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x11uLL, (unsigned int *)(*(void *)(a1 + 840) + 368), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Source 2 Depth Stride");
  }
  *(_DWORD *)(a1 + 70std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 700) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<7u>::SetL2Src2GroupStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x11uLL, (unsigned int *)(*(void *)(a1 + 840) + 376), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Source 2 Group Stride");
  }
  *(_DWORD *)(a1 + 704) = *(_DWORD *)(a1 + 704) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

uint64_t ZinAneTd<7u>::SetL2Src1CfgForCompression(uint64_t result, int a2)
{
  unsigned int v2 = *(_DWORD *)(result + 664) & 0xF7F80FFF;
  *(_DWORD *)(result + 664) = v2 | 0x8000000;
  switch(a2)
  {
    case 1:
      unsigned int v3 = v2 & 0xE7F80FFF | 0x8000000;
LABEL_7:
      *(_DWORD *)(result + 664) = v3;
      return result;
    case 2:
      unsigned int v3 = v2 | 0x18000000;
      goto LABEL_7;
    case 0:
      ZinAssertImpl("Invalid macro block size");
  }
  return result;
}

uint64_t ZinAneTd<7u>::SetOpMode(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 768) & 0xFFFFFFF8;
      goto LABEL_7;
    case 1:
      ZinAssertImpl("ElemWise not valid for architecture");
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 768) & 0xFFFFFFF8 | 3;
      goto LABEL_7;
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 768) & 0xFFFFFFF8 | 1;
      goto LABEL_7;
    case 4:
      unsigned int v2 = *(_DWORD *)(result + 768) & 0xFFFFFFF8 | 2;
      goto LABEL_7;
    case 5:
      unsigned int v2 = *(_DWORD *)(result + 768) & 0xFFFFFFF8 | 4;
LABEL_7:
      *(_DWORD *)(result + 768) = v2;
      break;
    case 6:
      ZinAssertImpl("RCAS not valid for architecture");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<7u>::SetKernelMode(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 768) & 0xFFFFFFF7;
LABEL_7:
      *(_DWORD *)(result + 768) = v2;
      return result;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 768) | 8;
      goto LABEL_7;
    case 2:
      ZinAssertImpl("Unsupported Kernel Mode");
  }
  return result;
}

uint64_t ZinAneTd<7u>::SetKernelFmt(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 764) & 0xFFFFFFFC;
      goto LABEL_5;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 764) & 0xFFFFFFFC | 1;
      goto LABEL_5;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 764) & 0xFFFFFFFC | 2;
LABEL_5:
      *(_DWORD *)(result + 764) = v2;
      break;
    case 3:
      ZinAssertImpl("Unimplemented or Unsupported kernel format");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<7u>::SetKernelBaseHeader(uint64_t result, char a2)
{
  *(_DWORD *)(result + 44) = *(_DWORD *)(result + 44) & 0xFFFFFFC0 | a2 & 0x1F | 0x20;
  return result;
}

uint64_t ZinAneTd<7u>::SetKernelDmaSrcCoeffDmaEn(uint64_t result, int a2, uint64_t a3)
{
  *(_DWORD *)(result + 4 * a3 + 6std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 4 * a3 + 60) & 0xFFFFFFFE | a2;
  return result;
}

uint64_t ZinAneTd<7u>::SetKernelDmaSrcCoeffDmaCacheHint(uint64_t result, int a2, uint64_t a3)
{
  int v3 = 896;
  switch(a2)
  {
    case 0:
      goto LABEL_5;
    case 1:
      int v3 = 128;
      goto LABEL_5;
    case 2:
      int v3 = 256;
      goto LABEL_5;
    case 3:
      int v3 = 768;
LABEL_5:
      *(_DWORD *)(result + 4 * a3 + 6std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 4 * a3 + 60) & 0xFFFFFC3F | v3;
      break;
    case 4:
      ZinAssertImpl("Error: Invalid KernelDmaSrc CoeffDma CacheHint");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<7u>::SetKernelDmaSrcHeaderDmaCacheHint(uint64_t result, int a2, uint64_t a3)
{
  int v3 = 896;
  switch(a2)
  {
    case 0:
      goto LABEL_5;
    case 1:
      int v3 = 128;
      goto LABEL_5;
    case 2:
      int v3 = 256;
      goto LABEL_5;
    case 3:
      int v3 = 768;
LABEL_5:
      *(_DWORD *)(result + 4 * a3 + 252) = *(_DWORD *)(result + 4 * a3 + 252) & 0xFFFFFC3F | v3;
      break;
    case 4:
      ZinAssertImpl("Error: Invalid KernelDmaSrc PostScale Dma CacheHint");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<7u>::SetKernelDmaSrcPostScaleDmaCacheHint(uint64_t a1, int a2)
{
  return ZinAneTd<7u>::SetKernelDmaSrcHeaderDmaCacheHint(a1, a2, 1);
}

uint64_t ZinAneTd<7u>::SetKernelDmaSrcBiasDmaCacheHint(uint64_t a1, int a2)
{
  return ZinAneTd<7u>::SetKernelDmaSrcHeaderDmaCacheHint(a1, a2, 0);
}

uint64_t ZinAneTd<7u>::SetKernelDmaSrcPaletteLutDmaCacheHint(uint64_t a1, int a2)
{
  return ZinAneTd<7u>::SetKernelDmaSrcHeaderDmaCacheHint(a1, a2, 2);
}

uint64_t ZinAneTd<7u>::SetKernelDmaSrcNonLinearLutDmaCacheHint(uint64_t a1, int a2)
{
  return ZinAneTd<7u>::SetKernelDmaSrcHeaderDmaCacheHint(a1, a2, 3);
}

BOOL ZinAneTd<7u>::SetKernelDmaSrcCoeffMemBufferSize(uint64_t a1, unsigned int a2, uint64_t a3)
{
  int v6 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 840) + 528), &v6);
  if (result) {
    *(_DWORD *)(a1 + 4 * a3 + 188) = *(_DWORD *)(a1 + 4 * a3 + 188) & 0x3F | (v6 << 6);
  }
  return result;
}

uint64_t ZinAneTd<7u>::SetPaddingMode(uint64_t result, int a2, int a3)
{
  switch(a2)
  {
    case 1:
      if (a3) {
        goto LABEL_11;
      }
      int v3 = 0;
      int v4 = 0;
      break;
    case 2:
      if (a3) {
        goto LABEL_11;
      }
      int v3 = 0;
      int v4 = 4;
      break;
    case 3:
      if (a3) {
        goto LABEL_11;
      }
      int v4 = 8;
      int v3 = 0x40000;
      break;
    case 4:
      if (a3) {
LABEL_11:
      }
        ZinAssertImpl("Error: padding-mode doesn't support constants");
      int v3 = 0;
      int v4 = 12;
      break;
    case 6:
      ZinAssertImpl("Platform doesn't support reflective padding mode");
    case 9:
      ZinAssertImpl("Platform doesn't support constant padding-mode");
    default:
      ZinAssertImpl("Invalid padding mode: %d", a2);
  }
  *(_DWORD *)(result + 66std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 660) & 0xFFFFFFF3 | v4;
  *(_DWORD *)(result + 768) = *(_DWORD *)(result + 768) & 0xFFFBFFFF | v3;
  return result;
}

uint64_t ZinAneTd<7u>::SetKernelBaseHeaderAligned(uint64_t result, char a2, signed int a3)
{
  if (a3 >= 4) {
    ZinAssertImpl("bad H13 aligned header selector");
  }
  *(_DWORD *)(result + 44) = *(_DWORD *)(result + 44) & dword_211F043F0[a3] | ((a2 & 0x1F) << (6 * a3 + 6)) | dword_211F04400[a3];
  return result;
}

uint64_t ZinAneTd<7u>::SetKernelDmaSrcEnable(uint64_t result)
{
  *(_DWORD *)(result + 52) |= 0x40u;
  return result;
}

uint64_t ZinAneTd<7u>::SetKernelAlignmentFormat(uint64_t result, int a2)
{
  if (a2)
  {
    if (a2 != 1) {
      return result;
    }
    unsigned int v2 = *(_DWORD *)(result + 764) & 0xFFFEFFFF;
  }
  else
  {
    unsigned int v2 = *(_DWORD *)(result + 764) | 0x10000;
  }
  *(_DWORD *)(result + 764) = v2;
  return result;
}

_DWORD *ZinAneTd<7u>::SetAlignedKernelBias(_DWORD *result, char a2, uint64_t a3, int a4)
{
  result[71] = result[71] & 0x3F | (a4 << 6);
  result[63] |= 1u;
  result[11] = result[11] & 0xFFFFF03F | ((a2 & 0x1F) << 6) | 0x800;
  return result;
}

_DWORD *ZinAneTd<7u>::SetAlignedKernelPostScale(_DWORD *result, char a2, uint64_t a3, int a4)
{
  result[72] = result[72] & 0x3F | (a4 << 6);
  result[64] |= 1u;
  result[11] = result[11] & 0xFFFC0FFF | ((a2 & 0x1F) << 12) | 0x20000;
  return result;
}

_DWORD *ZinAneTd<7u>::SetAlignedKernelPaletteLut(_DWORD *result, char a2, uint64_t a3, int a4)
{
  result[73] = result[73] & 0x3F | (a4 << 6);
  result[65] |= 1u;
  result[11] = result[11] & 0xFF03FFFF | ((a2 & 0x1F) << 18) | 0x800000;
  return result;
}

_DWORD *ZinAneTd<7u>::SetAlignedKernelNonLinearLut(_DWORD *result, char a2, uint64_t a3, int a4)
{
  result[74] = result[74] & 0x3F | (a4 << 6);
  result[66] |= 1u;
  result[11] = result[11] & 0xFF03FFFF | ((a2 & 0x1F) << 18) | 0x800000;
  return result;
}

void ZinAneTd<7u>::SetQuantizationSrc1InputOffset()
{
}

void ZinAneTd<7u>::SetQuantizationSrc2InputOffset()
{
}

void ZinAneTd<7u>::SetPEOutputQuantization()
{
}

uint64_t ZinAneTd<7u>::SetPEFinalScale(uint64_t result, float a2)
{
  *(float *)(result + 752) = a2;
  return result;
}

__int16 ZinAneTd<7u>::SetPEScale@<H0>(uint64_t a1@<X0>, float _S0@<S0>)
{
  __asm { FCVT            H0, S0 }
  *(_WORD *)(a1 + 746) = result;
  return result;
}

__int16 ZinAneTd<7u>::SetPEBias@<H0>(uint64_t a1@<X0>, float _S0@<S0>)
{
  __asm { FCVT            H0, S0 }
  *(_WORD *)(a1 + 744) = result;
  return result;
}

__int16 ZinAneTd<7u>::SetPEPreScale@<H0>(uint64_t a1@<X0>, float _S0@<S0>)
{
  __asm { FCVT            H0, S0 }
  *(_WORD *)(a1 + 75std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = result;
  return result;
}

uint64_t ZinAneTd<7u>::SetPESrc1ReLu(uint64_t result, int a2)
{
  *(_DWORD *)(result + 66std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 660) & 0xFFFFFFFE | a2;
  return result;
}

uint64_t ZinAneTd<7u>::SetPESrc2ReLu(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 16;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 66std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 660) & 0xFFFFFFEF | v2;
  return result;
}

uint64_t ZinAneTd<7u>::SetPESrc1Transpose(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 256;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 516) = *(_DWORD *)(result + 516) & 0xFFFFFEFF | v2;
  return result;
}

uint64_t ZinAneTd<7u>::SetPESrc2Transpose(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 512;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 516) = *(_DWORD *)(result + 516) & 0xFFFFFDFF | v2;
  return result;
}

uint64_t ZinAneTd<7u>::SetPESrc1Broadcast(uint64_t result, uint64_t a2)
{
  for (uint64_t i = *(uint64_t **)(a2 + 16); i; uint64_t i = (uint64_t *)*i)
  {
    int v3 = *((_DWORD *)i + 4) - 1;
    if (v3 <= 3) {
      *(_DWORD *)(result + 516) |= dword_211F04430[v3];
    }
  }
  return result;
}

uint64_t ZinAneTd<7u>::SetPESrc2Broadcast(uint64_t result, uint64_t a2, char a3)
{
  for (uint64_t i = *(uint64_t **)(a2 + 16); i; uint64_t i = (uint64_t *)*i)
  {
    int v4 = 128;
    switch(*((_DWORD *)i + 4))
    {
      case 1:
        int v4 = 64;
        break;
      case 2:
        break;
      case 3:
        if (a3) {
          continue;
        }
        int v4 = 32;
        break;
      case 4:
        if (a3) {
          continue;
        }
        int v4 = 16;
        break;
      default:
        continue;
    }
    *(_DWORD *)(result + 516) |= v4;
  }
  return result;
}

uint64_t ZinAneTd<7u>::SetPEOperationMode(uint64_t a1, int a2)
{
  uint64_t v2 = 0;
  switch(a2)
  {
    case 0:
      *(_DWORD *)(a1 + 740) &= 0xFFFFFFE3;
      int v3 = (unsigned int *)(*(void *)(a1 + 840) + 560);
      unint64_t v4 = 0;
      goto LABEL_8;
    case 1:
      *(_DWORD *)(a1 + 74std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 740) & 0xFFFFFFE3 | 4;
      int v3 = (unsigned int *)(*(void *)(a1 + 840) + 560);
      unint64_t v4 = 1;
      goto LABEL_8;
    case 2:
      *(_DWORD *)(a1 + 74std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 740) & 0xFFFFFFE3 | 0x10;
      if (!CheckRegValueRange(4uLL, (unsigned int *)(*(void *)(a1 + 840) + 560))) {
        goto LABEL_5;
      }
      goto LABEL_9;
    case 3:
      *(_DWORD *)(a1 + 74std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 740) & 0xFFFFFFE3 | 8;
      int v3 = (unsigned int *)(*(void *)(a1 + 840) + 560);
      unint64_t v4 = 2;
      goto LABEL_8;
    case 4:
      *(_DWORD *)(a1 + 74std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 740) & 0xFFFFFFE3 | 0xC;
      int v3 = (unsigned int *)(*(void *)(a1 + 840) + 560);
      unint64_t v4 = 3;
LABEL_8:
      if (CheckRegValueRange(v4, v3)) {
        goto LABEL_9;
      }
LABEL_5:
      uint64_t v2 = 0;
      break;
    case 5:
      return v2;
    default:
LABEL_9:
      uint64_t v2 = 1;
      break;
  }
  return v2;
}

uint64_t ZinAneTd<7u>::SetPEFirstSource(uint64_t result, int a2)
{
  if (a2)
  {
    if (a2 != 1) {
      return result;
    }
    unsigned int v2 = *(_DWORD *)(result + 740) & 0xFFFEFFFF;
  }
  else
  {
    unsigned int v2 = *(_DWORD *)(result + 740) | 0x10000;
  }
  *(_DWORD *)(result + 74std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2;
  return result;
}

uint64_t ZinAneTd<7u>::SetPESecondSource(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 740) & 0xFFF3FFFF;
      goto LABEL_6;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 740) & 0xFFF3FFFF | 0x40000;
      goto LABEL_6;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 740) & 0xFFF3FFFF | 0x80000;
      goto LABEL_6;
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 740) | 0xC0000;
LABEL_6:
      *(_DWORD *)(result + 74std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2;
      break;
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<7u>::SetPECondition(uint64_t result, int a2)
{
  if (a2 != 1) {
    ZinAssertImpl("Error: invalid PE Condition");
  }
  *(_DWORD *)(result + 740) |= 0x40u;
  return result;
}

uint64_t ZinAneTd<7u>::SetPEOutputReLU(uint64_t result)
{
  *(_DWORD *)(result + 740) |= 0x20u;
  return result;
}

uint64_t ZinAneTd<7u>::SetPEOutputCtoW(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 1024;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 516) = *(_DWORD *)(result + 516) & 0xFFFFFBFF | v2;
  return result;
}

BOOL ZinAneTd<7u>::SetL2ResultBaseAddr(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 840) + 384), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Result Base Address");
  }
  *(_DWORD *)(a1 + 712) = *(_DWORD *)(a1 + 712) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<7u>::SetL2ResultChannelStride(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 840) + 392), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Result Channel Stride");
  }
  *(_DWORD *)(a1 + 716) = *(_DWORD *)(a1 + 716) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<7u>::SetL2ResultRowStride(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 840) + 400), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Result Row Stride");
  }
  *(_DWORD *)(a1 + 72std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 720) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<7u>::SetL2ResultDepthStride(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 840) + 408), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Result Depth Stride");
  }
  *(_DWORD *)(a1 + 724) = *(_DWORD *)(a1 + 724) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<7u>::SetL2ResultGroupStride(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 840) + 416), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Result Group Stride");
  }
  *(_DWORD *)(a1 + 728) = *(_DWORD *)(a1 + 728) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

uint64_t ZinAneTd<7u>::SetL2BfrMode(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 8;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 708) = *(_DWORD *)(result + 708) & 0xFFFFFFF7 | v2;
  return result;
}

uint64_t ZinAneTd<7u>::SetL2ResultType(uint64_t result, int a2)
{
  switch(a2)
  {
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 708) & 0xFFFFFFFC | 2;
      break;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 708) & 0xFFFFFFFC | 1;
      break;
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 708) & 0xFFFFFFFC;
      break;
    case 4:
      unsigned int v2 = *(_DWORD *)(result + 708) | 3;
      break;
    default:
      ZinAssertImpl("Invalid L2 Result Type");
  }
  *(_DWORD *)(result + 708) = v2;
  return result;
}

uint64_t ZinAneTd<7u>::SetTileDmaSrc1Format(uint64_t result, int a2, int a3)
{
  switch(a2)
  {
    case 1:
      unsigned int v3 = *(_DWORD *)(result + 596) & 0xFFFFCFFC | 0x1000;
      goto LABEL_15;
    case 2:
      unsigned int v3 = *(_DWORD *)(result + 596) & 0xFFFFCFFC;
      goto LABEL_15;
    case 3:
      unsigned int v4 = *(_DWORD *)(result + 596) & 0xFFFFCFCC;
      int v5 = 8241;
      break;
    case 4:
      unsigned int v3 = *(_DWORD *)(result + 596) & 0xFFFFCECC | 1;
      goto LABEL_15;
    case 5:
      unsigned int v4 = *(_DWORD *)(result + 596) & 0xFFFFCECC;
      int v5 = 257;
      break;
    case 6:
      unsigned int v4 = *(_DWORD *)(result + 596) & 0xFFFFCECC;
      int v5 = 17;
      break;
    case 7:
      unsigned int v4 = *(_DWORD *)(result + 596) & 0xFFFFCECC;
      int v5 = 273;
      break;
    case 8:
      ZinAssertImpl("Packed10 format not supported");
    case 9:
      unsigned int v4 = *(_DWORD *)(result + 596) & 0xFFFFCECC;
      if (!a3) {
        goto LABEL_10;
      }
      int v5 = 4401;
      break;
    case 10:
      unsigned int v4 = *(_DWORD *)(result + 596) & 0xFFFFCECC;
      if (a3) {
        int v5 = 305;
      }
      else {
LABEL_10:
      }
        int v5 = 8497;
      break;
    case 11:
      ZinAssertImpl("Invalid format provided for architecture");
    case 12:
      ZinAssertImpl("E4M3 format is not supported");
    case 13:
      ZinAssertImpl("E5M2 format is not supported");
    default:
      ZinAssertImpl("Invalid format provided");
  }
  unsigned int v3 = v4 | v5;
LABEL_15:
  *(_DWORD *)(result + 596) = v3;
  return result;
}

BOOL ZinAneTd<7u>::SetTileDmaSrc1Interleave(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 840) + 552), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc1 Interleave");
  }
  *(_DWORD *)(a1 + 596) = *(_DWORD *)(a1 + 596) & 0xF0FFFFFF | ((v4 & 0xF) << 24);
  return result;
}

uint64_t ZinAneTd<7u>::SetTileDmaSrc1Enable(uint64_t result)
{
  *(_DWORD *)(result + 540) |= 1u;
  *(_DWORD *)(result + 32) |= 0x10000000u;
  return result;
}

void ZinAneTd<7u>::SetTileDmaSrc1E4M3Overflow(uint64_t a1, uint64_t a2)
{
  if ((a2 & 0xFF00000000) != 0) {
    ZinAssertImpl("E4M3Overflow is not supported.", v2, v3);
  }
}

uint64_t ZinAneTd<7u>::SetTileDmaSrc1CacheHint(uint64_t result, int a2, int a3, int a4)
{
  int v4 = 896;
  switch(a2)
  {
    case 0:
      goto LABEL_5;
    case 1:
      int v4 = 128;
      goto LABEL_5;
    case 2:
      int v4 = 256;
      goto LABEL_5;
    case 3:
      int v4 = 768;
LABEL_5:
      *(_DWORD *)(result + 54std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 540) & 0xFFFFFC3F | v4;
      break;
    case 4:
LABEL_15:
      ZinAssertImpl("Invalid CacheHint");
    default:
      break;
  }
  int v5 = 0x8000;
  switch(a4)
  {
    case 0:
      int v5 = 229376;
      goto LABEL_10;
    case 2:
      int v5 = 0x10000;
      goto LABEL_10;
    case 3:
      int v5 = 196608;
      goto LABEL_10;
    case 4:
      goto LABEL_15;
    default:
LABEL_10:
      int v6 = 2048;
      switch(a3)
      {
        case 0:
          int v6 = 14336;
          goto LABEL_14;
        case 2:
          int v6 = 4096;
          goto LABEL_14;
        case 3:
          int v6 = 12288;
          goto LABEL_14;
        case 4:
          goto LABEL_15;
        default:
LABEL_14:
          *(_DWORD *)(result + 54std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v6 | v5 | *(_DWORD *)(result + 540) & 0xFFFC03FF;
          return result;
      }
  }
}

uint64_t ZinAneTd<7u>::SetTileDmaSrc2CacheHint(uint64_t result, int a2, int a3, int a4)
{
  int v4 = 896;
  switch(a2)
  {
    case 0:
      goto LABEL_5;
    case 1:
      int v4 = 128;
      goto LABEL_5;
    case 2:
      int v4 = 256;
      goto LABEL_5;
    case 3:
      int v4 = 768;
LABEL_5:
      *(_DWORD *)(result + 544) = *(_DWORD *)(result + 544) & 0xFFFFFC3F | v4;
      break;
    case 4:
LABEL_15:
      ZinAssertImpl("Invalid CacheHint");
    default:
      break;
  }
  int v5 = 0x8000;
  switch(a4)
  {
    case 0:
      int v5 = 229376;
      goto LABEL_10;
    case 2:
      int v5 = 0x10000;
      goto LABEL_10;
    case 3:
      int v5 = 196608;
      goto LABEL_10;
    case 4:
      goto LABEL_15;
    default:
LABEL_10:
      int v6 = 2048;
      switch(a3)
      {
        case 0:
          int v6 = 14336;
          goto LABEL_14;
        case 2:
          int v6 = 4096;
          goto LABEL_14;
        case 3:
          int v6 = 12288;
          goto LABEL_14;
        case 4:
          goto LABEL_15;
        default:
LABEL_14:
          *(_DWORD *)(result + 544) = v6 | v5 | *(_DWORD *)(result + 544) & 0xFFFC03FF;
          return result;
      }
  }
}

BOOL ZinAneTd<7u>::SetTileDmaSrc1ChannelStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 840) + 440), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc1 Channel Stride");
  }
  *(_DWORD *)(a1 + 556) = *(_DWORD *)(a1 + 556) & 0x3F | (v4 << 6);
  return result;
}

BOOL ZinAneTd<7u>::SetTileDmaSrc1RowStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 840) + 432), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc1 Row Stride");
  }
  *(_DWORD *)(a1 + 552) = *(_DWORD *)(a1 + 552) & 0x3F | (v4 << 6);
  return result;
}

BOOL ZinAneTd<7u>::SetTileDmaSrc1DepthStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 840) + 448), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc1 Depth Stride");
  }
  *(_DWORD *)(a1 + 56std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 560) & 0x3F | (v4 << 6);
  return result;
}

BOOL ZinAneTd<7u>::SetTileDmaSrc1GroupStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 840) + 456), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc1 Group Stride");
  }
  *(_DWORD *)(a1 + 564) = *(_DWORD *)(a1 + 564) & 0x3F | (v4 << 6);
  return result;
}

void ZinAneTd<7u>::SetTileDmaSrc1CropOffset(uint64_t a1, int a2)
{
  if (a2) {
    ZinAssertImpl("Invalid Crop Offset for architecture", v2, v3);
  }
}

void ZinAneTd<7u>::SetTileDmaSrc1WrapStatic()
{
}

uint64_t ZinAneTd<7u>::SetTileDmaSrc1FmtOffsetCh(uint64_t result, char a2)
{
  *(_DWORD *)(result + 596) = *(_DWORD *)(result + 596) & 0xFFF8FFFF | ((a2 & 7) << 16);
  return result;
}

uint64_t ZinAneTd<7u>::SetTileDmaSrc1FmtCmpVec(uint64_t result, unsigned __int8 a2)
{
  *(_DWORD *)(result + 596) = *(_DWORD *)(result + 596) & 0xFFFFFFF | (a2 << 28);
  return result;
}

uint64_t ZinAneTd<7u>::SetTileDmaSrc1BaseAddrLo(uint64_t result, uint64_t a2, char a3)
{
  *(_DWORD *)(result + 4std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 40) & 0xFFFFFFC0 | a3 & 0x1F | 0x20;
  return result;
}

uint64_t ZinAneTd<7u>::SetTileDmaSrc1DependencyMode(uint64_t result, int a2)
{
  if (a2 == 2)
  {
    int v2 = *(_DWORD *)(result + 540);
    int v3 = 0x40000;
LABEL_7:
    *(_DWORD *)(result + 54std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2 & 0xFFF3FFFF | v3;
    return result;
  }
  if (a2 == 1)
  {
    int v2 = *(_DWORD *)(result + 540);
    if ((v2 & 0xC0000) == 0)
    {
      int v3 = 0x80000;
      goto LABEL_7;
    }
  }
  return result;
}

uint64_t ZinAneTd<7u>::SetTileDmaSrc1OffsetY(uint64_t result, __int16 a2)
{
  *(_WORD *)(result + 616) = a2;
  return result;
}

uint64_t ZinAneTd<7u>::SetTileDmaSrc1CompressedInfo(uint64_t result, int a2, int a3, int a4)
{
  int v4 = *(_DWORD *)(result + 604);
  *(_DWORD *)(result + 604) = v4 | 1;
  if (a4) {
    ZinAssertImpl("Architecture only supports lossless compression");
  }
  if (a3 == 2)
  {
    unsigned int v5 = v4 | 0x10001;
  }
  else
  {
    if (a3 != 1) {
      ZinAssertImpl("Unsupported macro block size");
    }
    unsigned int v5 = v4 & 0xFFFEFFFE | 1;
  }
  *(_DWORD *)(result + 604) = v5;
  if ((a2 - 1) >= 0x13) {
    ZinAssertImpl("Invalid packing format");
  }
  *(_DWORD *)(result + 604) = v5 & 0xFFFFC0FF | dword_211F04304[a2 - 1];
  return result;
}

BOOL ZinAneTd<7u>::SetTileDmaSrc1CompressedSize(uint64_t a1, unsigned int a2, unsigned int a3)
{
  int v7 = 0;
  if (!ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 840) + 24), &v7)) {
    ZinAssertImpl("Illegal TileDmaSrc1 Compressed Width");
  }
  *(_DWORD *)(a1 + 608) = *(_DWORD *)(a1 + 608) & 0xFFFE0000 | v7 & 0x1FFFF;
  int v6 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a3, (unsigned int *)(*(void *)(a1 + 840) + 16), &v6);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc1 Compressed Height");
  }
  *(_DWORD *)(a1 + 612) = *(_DWORD *)(a1 + 612) & 0xFFFE0000 | v6 & 0x1FFFF;
  return result;
}

uint64_t ZinAneTd<7u>::SetTileDmaSrc1MetaData(uint64_t result, uint64_t a2, char a3)
{
  *(_DWORD *)(result + 4std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 40) & 0xFFFFF03F | ((a3 & 0x1F) << 6) | 0x800;
  return result;
}

uint64_t ZinAneTd<7u>::SetTileDmaSrc1NoMetaData(uint64_t result)
{
  *(_DWORD *)(result + 604) |= 0x20000u;
  return result;
}

void ZinAneTd<7u>::SetL2Src2Interleave(uint64_t a1, int a2)
{
  if (a2 != 1) {
    ZinAssertImpl("No Source2 for architecture", v2, v3);
  }
}

uint64_t ZinAneTd<7u>::SetTileDmaSrc2Enable(uint64_t result)
{
  *(_DWORD *)(result + 540) |= 1u;
  return result;
}

int8x16_t ZinAneTd<7u>::SetTileDmaSrc2PixelOffset(uint64_t a1, unsigned int a2, unsigned int a3, unsigned int a4, unsigned int a5)
{
  v5.i64[0] = __PAIR64__(a3, a2);
  v5.i64[1] = __PAIR64__(a5, a4);
  v6.i64[0] = 0xFFFF0000FFFF0000;
  v6.i64[1] = 0xFFFF0000FFFF0000;
  int8x16_t result = vbslq_s8(v6, *(int8x16_t *)(a1 + 636), v5);
  *(int8x16_t *)(a1 + 636) = result;
  return result;
}

void ZinAneTd<7u>::SetTileDmaSrc2CompressedInfo(uint64_t a1, int a2, int a3, int a4)
{
}

BOOL ZinAneTd<7u>::SetTileDmaSrc2CompressedSize(uint64_t a1, unsigned int a2, unsigned int a3)
{
  int v7 = 0;
  if (!ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 840) + 24), &v7)) {
    ZinAssertImpl("Illegal TileDmaSrc2 Compressed Width");
  }
  *(_DWORD *)(a1 + 608) = *(_DWORD *)(a1 + 608) & 0xFFFE0000 | v7 & 0x1FFFF;
  int v6 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a3, (unsigned int *)(*(void *)(a1 + 840) + 16), &v6);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc2 Compressed Height");
  }
  *(_DWORD *)(a1 + 612) = *(_DWORD *)(a1 + 612) & 0xFFFE0000 | v6 & 0x1FFFF;
  return result;
}

uint64_t ZinAneTd<7u>::SetTileDmaDstFormat(uint64_t result, int a2, int a3)
{
  switch(a2)
  {
    case 1:
      unsigned int v3 = *(_DWORD *)(result + 816) & 0xFFFFCFFC | 0x1000;
      goto LABEL_15;
    case 2:
      unsigned int v3 = *(_DWORD *)(result + 816) & 0xFFFFCFFC;
      goto LABEL_15;
    case 3:
      unsigned int v4 = *(_DWORD *)(result + 816) & 0xFFFFCFCC;
      int v5 = 8241;
      break;
    case 4:
      unsigned int v3 = *(_DWORD *)(result + 816) & 0xFFFFCECC | 1;
      goto LABEL_15;
    case 5:
      unsigned int v4 = *(_DWORD *)(result + 816) & 0xFFFFCECC;
      int v5 = 257;
      break;
    case 6:
      unsigned int v4 = *(_DWORD *)(result + 816) & 0xFFFFCECC;
      int v5 = 17;
      break;
    case 7:
      unsigned int v4 = *(_DWORD *)(result + 816) & 0xFFFFCECC;
      int v5 = 273;
      break;
    case 8:
      ZinAssertImpl("Packed10 format not supported");
    case 9:
      unsigned int v4 = *(_DWORD *)(result + 816) & 0xFFFFCECC;
      if (!a3) {
        goto LABEL_10;
      }
      int v5 = 4401;
      break;
    case 10:
      unsigned int v4 = *(_DWORD *)(result + 816) & 0xFFFFCECC;
      if (a3) {
        int v5 = 305;
      }
      else {
LABEL_10:
      }
        int v5 = 8497;
      break;
    case 11:
      ZinAssertImpl("Invalid format provided for architecture");
    case 12:
      ZinAssertImpl("E4M3 is not supported");
    case 13:
      ZinAssertImpl("E5M2 is not supported");
    default:
      ZinAssertImpl("Invalid format provided");
  }
  unsigned int v3 = v4 | v5;
LABEL_15:
  *(_DWORD *)(result + 816) = v3;
  return result;
}

BOOL ZinAneTd<7u>::SetTileDmaDstandL2DstInterleave(uint64_t a1, unsigned int a2)
{
  int v6 = 0;
  unint64_t v3 = a2;
  if (!ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 840) + 552), &v6)) {
    ZinAssertImpl("Illegal L2 Result Interleave");
  }
  *(_DWORD *)(a1 + 708) = *(_DWORD *)(a1 + 708) & 0xFFFFF0FF | ((v6 & 0xF) << 8);
  int v5 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(v3, (unsigned int *)(*(void *)(a1 + 840) + 552), &v5);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaDst Interleave");
  }
  *(_DWORD *)(a1 + 816) = *(_DWORD *)(a1 + 816) & 0xF0FFFFFF | ((v5 & 0xF) << 24);
  return result;
}

BOOL ZinAneTd<7u>::SetL2ResultInterleave(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 840) + 552), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Result Interleave");
  }
  *(_DWORD *)(a1 + 708) = *(_DWORD *)(a1 + 708) & 0xFFFFF0FF | ((v4 & 0xF) << 8);
  return result;
}

uint64_t ZinAneTd<7u>::SetTileDmaDstandL2DstFifoMode(uint64_t result, int a2)
{
  unsigned int v2 = *(_DWORD *)(result + 708) & 0xFFFFFFF7;
  if (a2) {
    int v3 = 0x4000000;
  }
  else {
    int v3 = 0;
  }
  unsigned int v4 = *(_DWORD *)(result + 792) & 0xFBFFFFFF | v3;
  if (a2) {
    int v5 = 8;
  }
  else {
    int v5 = 0;
  }
  *(_DWORD *)(result + 792) = v4;
  *(_DWORD *)(result + 708) = v2 | v5;
  return result;
}

uint64_t ZinAneTd<7u>::SetTileDmaDstEnable(uint64_t result)
{
  *(_DWORD *)(result + 792) |= 1u;
  *(_DWORD *)(result + 32) |= 0x20000000u;
  return result;
}

uint64_t ZinAneTd<7u>::SetTileDmaDstCacheHint(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 792) | 0x3C0;
      goto LABEL_5;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 792) & 0xFFFFFC3F | 0xC0;
      goto LABEL_5;
    case 2:
      ZinAssertImpl("Drop CacheHint not supported on Dst");
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 792) & 0xFFFFFC3F | 0x340;
LABEL_5:
      *(_DWORD *)(result + 792) = v2;
      break;
    case 4:
      ZinAssertImpl("Invalid CacheHint");
    default:
      return result;
  }
  return result;
}

BOOL ZinAneTd<7u>::SetTileDmaDstChannelStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 840) + 480), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaDst Channel Stride");
  }
  *(_DWORD *)(a1 + 804) = *(_DWORD *)(a1 + 804) & 0x3F | (v4 << 6);
  return result;
}

BOOL ZinAneTd<7u>::SetTileDmaDstRowStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 840) + 472), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaDst Row Stride");
  }
  *(_DWORD *)(a1 + 80std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 800) & 0x3F | (v4 << 6);
  return result;
}

BOOL ZinAneTd<7u>::SetTileDmaDstDepthStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 840) + 488), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaDst Depth Stride");
  }
  *(_DWORD *)(a1 + 808) = *(_DWORD *)(a1 + 808) & 0x3F | (v4 << 6);
  return result;
}

BOOL ZinAneTd<7u>::SetTileDmaDstGroupStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 840) + 496), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaDst Group Stride");
  }
  *(_DWORD *)(a1 + 812) = *(_DWORD *)(a1 + 812) & 0x3F | (v4 << 6);
  return result;
}

uint64_t ZinAneTd<7u>::SetTileDmaDstZeroPad(uint64_t result, _DWORD *a2)
{
  unsigned int v2 = *(_DWORD *)(result + 816) & 0xFFDFFFFF | ((*a2 == 0) << 21);
  *(_DWORD *)(result + 816) = v2;
  *(_DWORD *)(result + 816) = v2 & 0xFFEFFFFF | ((a2[1] == 0) << 20);
  return result;
}

void ZinAneTd<7u>::SetTileDmaDstCropOffset(uint64_t a1, int a2, int a3)
{
  if (a3 | a2) {
    ZinAssertImpl("Invalid Crop Offset for architecture", v3, v4);
  }
}

uint64_t ZinAneTd<7u>::SetTileDmaDstFmtOffsetCh(uint64_t result, char a2)
{
  *(_DWORD *)(result + 816) = *(_DWORD *)(result + 816) & 0xFFF8FFFF | ((a2 & 7) << 16);
  return result;
}

uint64_t ZinAneTd<7u>::SetTileDmaDstFmtCmpVec(uint64_t result, unsigned __int8 a2)
{
  *(_DWORD *)(result + 816) = *(_DWORD *)(result + 816) & 0xFFFFFFF | (a2 << 28);
  return result;
}

uint64_t ZinAneTd<7u>::SetTileDmaDstBaseAddrLo(uint64_t result, uint64_t a2, char a3)
{
  *(_DWORD *)(result + 4std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 40) & 0xFFFC0FFF | ((a3 & 0x1F) << 12) | 0x20000;
  return result;
}

void ZinAneTd<7u>::SetTileDmaDstCompressedInfo()
{
}

uint64_t ZinAneTd<7u>::SetArgOutputSelect(uint64_t result, int a2)
{
  if ((a2 - 6) > 5) {
    int v2 = 0x100000;
  }
  else {
    int v2 = dword_211F043B4[a2 - 6];
  }
  *(_DWORD *)(result + 768) = *(_DWORD *)(result + 768) & 0xFF8FFFFF | v2;
  return result;
}

uint64_t ZinAneTd<7u>::SetMaxPoolMode(uint64_t result, unsigned int a2)
{
  if (a2 <= 0xE && ((1 << a2) & 0x48E2) != 0) {
    unsigned int v2 = *(_DWORD *)(result + 768) | 0x80000;
  }
  else {
    unsigned int v2 = *(_DWORD *)(result + 768) & 0xFFF7FFFF;
  }
  *(_DWORD *)(result + 768) = v2;
  return result;
}

uint64_t ZinAneTd<7u>::SetGroupKernelReuse(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 1024;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 764) = *(_DWORD *)(result + 764) & 0xFFFFFBFF | v2;
  if (a2) {
    int v3 = 16;
  }
  else {
    int v3 = 0;
  }
  *(_DWORD *)(result + 52) = *(_DWORD *)(result + 52) & 0xFFFFFFEF | v3;
  return result;
}

uint64_t ZinAneTd<7u>::SetKernelSparseFmt(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 256;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 764) = *(_DWORD *)(result + 764) & 0xFFFFFEFF | v2;
  if (a2) {
    int v3 = 32;
  }
  else {
    int v3 = 0;
  }
  *(_DWORD *)(result + 52) = *(_DWORD *)(result + 52) & 0xFFFFFFDF | v3;
  return result;
}

uint64_t ZinAneTd<7u>::SetKernelSparseBinary(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 0x8000;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 764) = *(_DWORD *)(result + 764) & 0xFFFF7FFF | v2;
  return result;
}

uint64_t ZinAneTd<7u>::SetKernelPalettizedEn(uint64_t result, int a2)
{
  int v2 = 0;
  switch(a2)
  {
    case 0:
    case 3:
    case 28:
    case 29:
    case 30:
    case 31:
    case 32:
      ZinAssertImpl("Unknown kernel format in codegen\n");
    case 7:
    case 8:
    case 9:
    case 10:
    case 11:
    case 12:
    case 13:
    case 14:
    case 19:
    case 20:
    case 21:
    case 22:
    case 23:
    case 24:
    case 25:
    case 26:
    case 27:
      int v2 = 4;
      break;
    case 15:
    case 16:
    case 17:
    case 18:
      ZinAssertImpl("Invalid kernel format");
    default:
      break;
  }
  *(_DWORD *)(result + 764) = *(_DWORD *)(result + 764) & 0xFFFFFFFB | v2;
  return result;
}

uint64_t ZinAneTd<7u>::SetKernelPalettizedBits(uint64_t result, int a2)
{
  int v2 = 128;
  switch(a2)
  {
    case 0:
    case 3:
    case 28:
    case 29:
    case 30:
    case 31:
    case 32:
      ZinAssertImpl("Unknown kernel format in codegen\n");
    case 7:
    case 8:
    case 9:
    case 10:
      int v2 = 16;
      break;
    case 11:
    case 12:
    case 13:
    case 14:
      int v2 = 32;
      break;
    case 15:
    case 16:
    case 17:
    case 18:
      ZinAssertImpl("Invalid kernel format");
    case 19:
    case 20:
    case 21:
    case 22:
      int v2 = 64;
      break;
    case 23:
    case 24:
    case 25:
    case 26:
      int v2 = 96;
      break;
    default:
      break;
  }
  *(_DWORD *)(result + 764) = *(_DWORD *)(result + 764) & 0xFFFFFF0F | v2;
  return result;
}

uint64_t ZinAneTd<7u>::SetNEBinaryPoint(uint64_t result, char a2)
{
  *(_DWORD *)(result + 768) = *(_DWORD *)(result + 768) & 0xFFFFE0FF | ((a2 & 0x1F) << 8);
  return result;
}

uint64_t ZinAneTd<7u>::SetNENonLinearMode(uint64_t result, int a2, uint64_t a3)
{
  if (a2)
  {
    if (a2 == 1)
    {
      a2 = 0x10000;
    }
    else
    {
      uint64_t v4 = *(_DWORD **)a3;
      int v3 = *(_DWORD **)(a3 + 8);
      if (*(_DWORD **)a3 != v3)
      {
        while (*v4 != a2)
        {
          if (++v4 == v3)
          {
            uint64_t v4 = *(_DWORD **)(a3 + 8);
            break;
          }
        }
      }
      if (v4 == v3) {
        ZinAssertImpl("Error: illegal non-linear mode\n");
      }
      a2 = 0x20000;
    }
  }
  *(_DWORD *)(result + 768) = *(_DWORD *)(result + 768) & 0xFFFCFFFF | a2;
  return result;
}

uint64_t ZinAneTd<7u>::SetNEPostScale(uint64_t result, unint64_t a2, char a3)
{
  _S0 = a2;
  __asm { FCVT            H0, S0 }
  int v8 = _S0;
  if (!_ZF) {
    int v8 = 0;
  }
  int v9 = ((a2 & 0xFF0000000000) != 0) << 14;
  int v10 = -((a2 >> 16) & 0x1F0000) & 0x1F0000 | v8;
  if (!a3)
  {
    int v9 = 0;
    int v10 = 15360;
  }
  *(_DWORD *)(result + 768) = *(_DWORD *)(result + 768) & 0xFFFFBFFF | v9;
  *(_DWORD *)(result + 78std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v10 | *(_DWORD *)(result + 780) & 0xFFE00000;
  return result;
}

uint64_t ZinAneTd<7u>::SetNEBias(uint64_t result, unint64_t a2, char a3)
{
  _S0 = a2;
  __asm { FCVT            H0, S0 }
  int v8 = _S0;
  if (!_ZF) {
    int v8 = 0;
  }
  int v9 = 16 * ((a2 & 0xFF0000000000) != 0);
  int v10 = (a2 >> 16) & 0x1F0000 | v8;
  if (!a3)
  {
    int v9 = 0;
    int v10 = 0;
  }
  *(_DWORD *)(result + 768) = *(_DWORD *)(result + 768) & 0xFFFFFFEF | v9;
  *(_DWORD *)(result + 776) = v10 | *(_DWORD *)(result + 776) & 0xFFE00000;
  return result;
}

ZinIrKernel *ZinAneTd<7u>::SetNEMatrixVectorBias(uint64_t a1, ZinIrKernel **a2, uint64_t a3)
{
  BOOL result = *a2;
  if (*a2) {
    _ZF = (a3 & 0xFF00000000) == 0;
  }
  else {
    _ZF = 1;
  }
  if (_ZF)
  {
    int v6 = 0;
  }
  else
  {
    _S8 = *(float *)&a3;
    BOOL result = (ZinIrKernel *)ZinIrKernel::GetWeightFormat(result);
    if (result == 4)
    {
      __asm { FCVT            H0, S8 }
      LOWORD(v8) = _H0;
    }
    else
    {
      if (result != 2 && result != 1) {
        ZinAssertImpl("Error: Invalid kernel format");
      }
      int v8 = (int)_S8;
    }
    *(_WORD *)(a1 + 772) = v8;
    int v6 = 64;
  }
  *(_DWORD *)(a1 + 768) = *(_DWORD *)(a1 + 768) & 0xFFFFFFBF | v6;
  return result;
}

uint64_t ZinAneTd<7u>::SetNEOcgSize(uint64_t result, char a2)
{
  *(_DWORD *)(result + 496) = *(_DWORD *)(result + 496) & 0xFFFFE3FF | ((a2 & 7) << 10);
  return result;
}

uint64_t ZinAneTd<7u>::SetOutputTranspose(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 0x10000000;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 52std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 520) & 0xEFFFFFFF | v2;
  return result;
}

uint64_t ZinAneTd<7u>::SetNESmallSourceMode(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 520) & 0xFFFFFFFB;
      goto LABEL_4;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 520) | 4;
LABEL_4:
      *(_DWORD *)(result + 52std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2;
      break;
    case 2:
      ZinAssertImpl("Error: Tiny source mode is not supported for this arch");
    case 3:
    case 4:
      ZinAssertImpl("Error: NP2 small source mode  is not supported for this arch");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<7u>::GetNESmallSourceMode(uint64_t a1)
{
  return (*(_DWORD *)(a1 + 520) >> 2) & 1;
}

uint64_t ZinAneTd<7u>::SetNEKeepKernel(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 4096;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 764) = *(_DWORD *)(result + 764) & 0xFFFFEFFF | v2;
  return result;
}

uint64_t ZinAneTd<7u>::SetNEUsePrevKernel(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 0x4000;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 764) = *(_DWORD *)(result + 764) & 0xFFFFBFFF | v2;
  return result;
}

uint64_t ZinAneTd<7u>::SetCommonTaskType(uint64_t result, int a2)
{
  int v2 = 16;
  switch(a2)
  {
    case 0:
      *(_DWORD *)(result + 520) &= 0xFFFFFF8F;
      goto LABEL_9;
    case 1:
LABEL_9:
      ZinAssertImpl("Error: Invalid Task Type");
    case 2:
      goto LABEL_7;
    case 3:
      int v2 = 96;
      goto LABEL_7;
    case 4:
      int v2 = 80;
      goto LABEL_7;
    case 5:
      int v2 = 48;
      goto LABEL_7;
    case 6:
      int v2 = 32;
      goto LABEL_7;
    case 7:
      int v2 = 64;
LABEL_7:
      *(_DWORD *)(result + 52std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 520) & 0xFFFFFF8F | v2;
      break;
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<7u>::SetCommonInFmt(uint64_t result, int a2)
{
  if (a2 > 2)
  {
    if (a2 == 3)
    {
      unsigned int v2 = *(_DWORD *)(result + 476) & 0xFFFFFFFC | 2;
      goto LABEL_8;
    }
    if (a2 == 12) {
      ZinAssertImpl("Error: Invalid Common InFmt E4M3");
    }
LABEL_11:
    ZinAssertImpl("Error: Invalid TD programming for Src1 input format");
  }
  if (a2 == 1)
  {
    unsigned int v2 = *(_DWORD *)(result + 476) & 0xFFFFFFFC | 1;
    goto LABEL_8;
  }
  if (a2 != 2) {
    goto LABEL_11;
  }
  unsigned int v2 = *(_DWORD *)(result + 476) & 0xFFFFFFFC;
LABEL_8:
  *(_DWORD *)(result + 476) = v2;
  return result;
}

uint64_t ZinAneTd<7u>::SetCommonSrc2InFmt(uint64_t result, int a2)
{
  if (a2 > 2)
  {
    if (a2 == 3)
    {
      unsigned int v2 = *(_DWORD *)(result + 476) & 0xFFFFFFF3 | 8;
      goto LABEL_8;
    }
    if (a2 == 12) {
      ZinAssertImpl("Error: Invalid TD programming for Src2 input format: E4M3");
    }
LABEL_11:
    ZinAssertImpl("Error: Invalid TD programming for Src2 input format");
  }
  if (a2 == 1)
  {
    unsigned int v2 = *(_DWORD *)(result + 476) & 0xFFFFFFF3 | 4;
    goto LABEL_8;
  }
  if (a2 != 2) {
    goto LABEL_11;
  }
  unsigned int v2 = *(_DWORD *)(result + 476) & 0xFFFFFFF3;
LABEL_8:
  *(_DWORD *)(result + 476) = v2;
  return result;
}

uint64_t ZinAneTd<7u>::SetCommonOutFmt(uint64_t result, int a2)
{
  if ((a2 - 3) < 9) {
    goto LABEL_2;
  }
  if (a2 <= 11)
  {
    if (a2 == 1)
    {
      unsigned int v2 = *(_DWORD *)(result + 476) & 0xFFFFFFCF | 0x10;
      goto LABEL_3;
    }
    if (a2 == 2)
    {
      unsigned int v2 = *(_DWORD *)(result + 476) & 0xFFFFFFCF;
      goto LABEL_3;
    }
LABEL_12:
    ZinAssertImpl("Error: Invalid output format");
  }
  if (a2 != 13)
  {
    if (a2 == 12) {
      ZinAssertImpl("Error: E4M3 is not supported");
    }
    goto LABEL_12;
  }
LABEL_2:
  unsigned int v2 = *(_DWORD *)(result + 476) & 0xFFFFFFCF | 0x20;
LABEL_3:
  *(_DWORD *)(result + 476) = v2;
  return result;
}

uint64_t ZinAneTd<7u>::SetCommonSourceRouting(uint64_t result, int a2)
{
  if (a2 == 2)
  {
    unsigned int v2 = *(_DWORD *)(result + 520) & 0xFFFFFFFC | 2;
  }
  else if (a2 == 1)
  {
    unsigned int v2 = *(_DWORD *)(result + 520) & 0xFFFFFFFC | 1;
  }
  else
  {
    if (a2) {
      return result;
    }
    unsigned int v2 = *(_DWORD *)(result + 520) | 3;
  }
  *(_DWORD *)(result + 52std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2;
  return result;
}

BOOL ZinAneTd<7u>::SetPatchHeight(uint64_t a1, unint64_t a2)
{
  *(_DWORD *)(a1 + 512) = *(_DWORD *)(a1 + 512) & 0xFFFFFF0F | (16 * (a2 & 0xF));
  return CheckRegValueRange(a2, (unsigned int *)(*(void *)(a1 + 840) + 288));
}

BOOL ZinAneTd<7u>::SetPatchWidth(uint64_t a1, unint64_t a2)
{
  *(_DWORD *)(a1 + 512) = *(_DWORD *)(a1 + 512) & 0xFFFFFFF0 | a2 & 0xF;
  return CheckRegValueRange(a2, (unsigned int *)(*(void *)(a1 + 840) + 280));
}

BOOL ZinAneTd<7u>::SetTileHeight(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 840) + 200), &v4);
  if (result) {
    *(_DWORD *)(a1 + 508) = *(_DWORD *)(a1 + 508) & 0xFFFF8000 | v4 & 0x7FFF;
  }
  return result;
}

BOOL ZinAneTd<7u>::SetTileOverlap(uint64_t a1, unint64_t a2)
{
  *(_DWORD *)(a1 + 508) = *(_DWORD *)(a1 + 508) & 0xFFE0FFFF | ((a2 & 0x1F) << 16);
  return CheckRegValueRange(a2, (unsigned int *)(*(void *)(a1 + 840) + 216));
}

BOOL ZinAneTd<7u>::SetTileOverlapPadBottom(uint64_t a1, unint64_t a2)
{
  *(_DWORD *)(a1 + 508) = *(_DWORD *)(a1 + 508) & 0x83FFFFFF | ((a2 & 0x1F) << 26);
  return CheckRegValueRange(a2, (unsigned int *)(*(void *)(a1 + 840) + 224));
}

BOOL ZinAneTd<7u>::SetTileOverlapPadTop(uint64_t a1, unint64_t a2)
{
  *(_DWORD *)(a1 + 508) = *(_DWORD *)(a1 + 508) & 0xFC1FFFFF | ((a2 & 0x1F) << 21);
  return CheckRegValueRange(a2, (unsigned int *)(*(void *)(a1 + 840) + 208));
}

void ZinAneTd<7u>::SetTileOverlapPadReflect(uint64_t a1, int a2)
{
  if (a2) {
    ZinAssertImpl("Error: Overlap pad reflect is not supported", v2, v3);
  }
}

BOOL ZinAneTd<7u>::SetCommonConvCfgKh(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 840) + 136), &v4);
  if (result) {
    *(_DWORD *)(a1 + 496) = *(_DWORD *)(a1 + 496) & 0xFFFFFC1F | (32 * (v4 & 0x1F));
  }
  return result;
}

BOOL ZinAneTd<7u>::SetCommonConvCfgKw(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 840) + 144), &v4);
  if (result) {
    *(_DWORD *)(a1 + 496) = *(_DWORD *)(a1 + 496) & 0xFFFFFFE0 | v4 & 0x1F;
  }
  return result;
}

BOOL ZinAneTd<7u>::SetCommonConvCfg3dKd(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 840) + 176), &v4);
  if (result) {
    *(_DWORD *)(a1 + 50std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 500) & 0xFFFFFFE0 | v4 & 0x1F;
  }
  return result;
}

BOOL ZinAneTd<7u>::SetCommonConvCfgSx(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 840) + 120), &v4);
  if (result) {
    *(_DWORD *)(a1 + 496) = *(_DWORD *)(a1 + 496) & 0xFFFF9FFF | ((v4 & 3) << 13);
  }
  return result;
}

BOOL ZinAneTd<7u>::SetCommonConvCfgSy(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 840) + 112), &v4);
  if (result) {
    *(_DWORD *)(a1 + 496) = *(_DWORD *)(a1 + 496) & 0xFFFE7FFF | ((v4 & 3) << 15);
  }
  return result;
}

BOOL ZinAneTd<7u>::SetCommonConvCfg3dSz(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 840) + 152), &v4);
  if (result) {
    *(_DWORD *)(a1 + 50std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 500) & 0xFFFFFF3F | ((v4 & 3) << 6);
  }
  return result;
}

BOOL ZinAneTd<7u>::SetCommonConvCfgOx(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 840) + 88), &v4);
  if (result) {
    *(_DWORD *)(a1 + 496) = *(_DWORD *)(a1 + 496) & 0xCFFFFFFF | ((v4 & 3) << 28);
  }
  return result;
}

BOOL ZinAneTd<7u>::SetCommonConvCfgOy(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 840) + 80), &v4);
  if (result) {
    *(_DWORD *)(a1 + 496) = *(_DWORD *)(a1 + 496) & 0x3FFFFFFF | (v4 << 30);
  }
  return result;
}

BOOL ZinAneTd<7u>::SetCommonConvCfg3dOz(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 840) + 168), &v4);
  if (result) {
    *(_DWORD *)(a1 + 50std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 500) & 0xFFFF9FFF | ((v4 & 3) << 13);
  }
  return result;
}

BOOL ZinAneTd<7u>::SetCommonConvCfgPadLeft(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 840) + 104), &v4);
  if (result) {
    *(_DWORD *)(a1 + 496) = *(_DWORD *)(a1 + 496) & 0xFFC1FFFF | ((v4 & 0x1F) << 17);
  }
  return result;
}

BOOL ZinAneTd<7u>::SetCommonConvCfgPadTop(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 840) + 96), &v4);
  if (result) {
    *(_DWORD *)(a1 + 496) = *(_DWORD *)(a1 + 496) & 0xF83FFFFF | ((v4 & 0x1F) << 22);
  }
  return result;
}

BOOL ZinAneTd<7u>::SetCommonConvCfg3dPz(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 840) + 160), &v4);
  if (result) {
    *(_DWORD *)(a1 + 50std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 500) & 0xFFFFF0FF | ((v4 & 0xF) << 8);
  }
  return result;
}

BOOL ZinAneTd<7u>::SetOrReturnNumGroups(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 840) + 184), &v4);
  if (result) {
    *(_DWORD *)(a1 + 504) = *(_DWORD *)(a1 + 504) & 0xFFFFE000 | v4 & 0x1FFF;
  }
  return result;
}

BOOL ZinAneTd<7u>::SetOrReturnWin(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 840) + 24), &v4);
  if (result) {
    *(_DWORD *)(a1 + 468) = *(_DWORD *)(a1 + 468) & 0xFFFF8000 | v4 & 0x7FFF;
  }
  return result;
}

BOOL ZinAneTd<7u>::SetOrReturnHin(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 840) + 16), &v4);
  if (result) {
    *(_DWORD *)(a1 + 468) = *(_DWORD *)(a1 + 468) & 0x8000FFFF | ((v4 & 0x7FFF) << 16);
  }
  return result;
}

BOOL ZinAneTd<7u>::SetOrReturnDin(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 840) + 32), &v4);
  if (result) {
    *(_DWORD *)(a1 + 472) = *(_DWORD *)(a1 + 472) & 0xFFFF8000 | v4 & 0x7FFF;
  }
  return result;
}

BOOL ZinAneTd<7u>::SetOrReturnCin(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 840) + 40), &v4);
  if (result) {
    *(_DWORD *)(a1 + 48std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 480) & 0xFFFE0000 | v4 & 0x1FFFF;
  }
  return result;
}

BOOL ZinAneTd<7u>::SetOrReturnWout(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 840) + 64), &v4);
  if (result) {
    *(_DWORD *)(a1 + 488) = *(_DWORD *)(a1 + 488) & 0xFFFF8000 | v4 & 0x7FFF;
  }
  return result;
}

BOOL ZinAneTd<7u>::SetOrReturnHout(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 840) + 56), &v4);
  if (result) {
    *(_DWORD *)(a1 + 488) = *(_DWORD *)(a1 + 488) & 0x8000FFFF | ((v4 & 0x7FFF) << 16);
  }
  return result;
}

BOOL ZinAneTd<7u>::SetOrReturnDout(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 840) + 72), &v4);
  if (result) {
    *(_DWORD *)(a1 + 492) = *(_DWORD *)(a1 + 492) & 0xFFFF8000 | v4 & 0x7FFF;
  }
  return result;
}

BOOL ZinAneTd<7u>::SetOrReturnCout(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 840) + 48), &v4);
  if (result) {
    *(_DWORD *)(a1 + 484) = *(_DWORD *)(a1 + 484) & 0xFFFE0000 | v4 & 0x1FFFF;
  }
  return result;
}

uint64_t ZinAneTd<7u>::SetUnicastEn(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 0x4000;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 504) = *(_DWORD *)(result + 504) & 0xFFFFBFFF | v2;
  return result;
}

BOOL ZinAneTd<7u>::SetUnicastCin(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 840) + 192), &v4);
  if (result) {
    *(_WORD *)(a1 + 506) = v4;
  }
  return result;
}

uint64_t ZinAneTd<8u>::SetWARdmaDependency(uint64_t result, uint64_t a2, int a3, unsigned __int8 a4, int **a5)
{
  if (!*(unsigned char *)(a2 + 1323)) {
    ZinAssertImpl("inconsistent WAR support");
  }
  if (a3)
  {
    int v5 = *a5;
    int v6 = a5[1];
    if (*a5 != v6)
    {
      do
      {
        uint64_t v7 = *v5;
        if (v7 <= 2) {
          *(_DWORD *)(result + 1116) |= dword_211F0435C[v7];
        }
        ++v5;
      }
      while (v5 != v6);
    }
    *(_DWORD *)(result + 1116) = *(_DWORD *)(result + 1116) & 0x7FFFFFF | (a4 << 27);
  }
  return result;
}

uint64_t ZinAneTd<8u>::SetL2Barrier(uint64_t result)
{
  *(_DWORD *)(result + 556) |= 0x800000u;
  return result;
}

uint64_t ZinAneTd<8u>::SetEventFlags(uint64_t result, int a2, int a3, int a4)
{
  *(_DWORD *)(result + 16) = *(_DWORD *)(result + 16) & 0xFC000000 | a2 & 0x3FFFFFF;
  if (a4) {
    ZinAssertImpl("DRAM Events not supported for architecture");
  }
  *(_DWORD *)(result + 24) = *(_DWORD *)(result + 24) & 0xFC000000 | a3 & 0x3FFFFFF;
  return result;
}

BOOL ZinAneTd<8u>::SetL2SrcBaseAddress(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 296), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src Base Address");
  }
  *(_DWORD *)(a1 + 88std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 880) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<8u>::SetL2Src1ChannelStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x11uLL, (unsigned int *)(*(void *)(a1 + 1296) + 304), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src Channel Stride");
  }
  *(_DWORD *)(a1 + 884) = *(_DWORD *)(a1 + 884) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<8u>::SetL2SrcRowStride(uint64_t a1, ZinCodegen *this, ZinTensorDimensions *a3, uint64_t a4, uint64_t *a5)
{
  int v8 = 0;
  ZinCodegen::GetL2RowStride(this, a3, *(unsigned int *)(*(void *)(a1 + 1296) + 316), &v8, a5);
  unsigned int v7 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(v8, 0x11uLL, (unsigned int *)(*(void *)(a1 + 1296) + 312), &v7);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src Row Stride");
  }
  *(_DWORD *)(a1 + 888) = *(_DWORD *)(a1 + 888) & 0xFFE0000F | (16 * (v7 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<8u>::SetL2Src1DepthStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x11uLL, (unsigned int *)(*(void *)(a1 + 1296) + 320), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src Depth Stride");
  }
  *(_DWORD *)(a1 + 892) = *(_DWORD *)(a1 + 892) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<8u>::SetL2Src1GroupStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x11uLL, (unsigned int *)(*(void *)(a1 + 1296) + 328), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src Group Stride");
  }
  *(_DWORD *)(a1 + 896) = *(_DWORD *)(a1 + 896) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

uint64_t ZinAneTd<8u>::SetL2Src1DmaFormat(uint64_t result, int a2)
{
  switch(a2)
  {
    case 1:
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 872) & 0xFFFFFF3F;
      break;
    case 3:
    case 4:
    case 5:
    case 6:
    case 7:
    case 9:
    case 10:
      unsigned int v2 = *(_DWORD *)(result + 872) & 0xFFFFFF3F | 0x40;
      break;
    case 8:
      ZinAssertImpl("Packed10 format not fully implemented yet\n");
    case 11:
      unsigned int v2 = *(_DWORD *)(result + 872) | 0xC0;
      break;
    case 12:
    case 13:
      ZinAssertImpl("E4M3 or E5M2 format not supported");
    default:
      ZinAssertImpl("Invalid Dma Format");
  }
  *(_DWORD *)(result + 872) = v2;
  return result;
}

uint64_t ZinAneTd<8u>::SetL2Src2DmaFormat(uint64_t result, int a2)
{
  switch(a2)
  {
    case 1:
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 876) & 0xFFFFFF3F;
      break;
    case 3:
    case 4:
    case 5:
    case 6:
    case 7:
    case 9:
    case 10:
      unsigned int v2 = *(_DWORD *)(result + 876) & 0xFFFFFF3F | 0x40;
      break;
    case 8:
      ZinAssertImpl("Packed10 format not fully implemented yet\n");
    case 11:
      unsigned int v2 = *(_DWORD *)(result + 876) | 0xC0;
      break;
    case 12:
    case 13:
      ZinAssertImpl("E4M3 or E5M2 format not supported");
    default:
      ZinAssertImpl("Invalid Dma Format");
  }
  *(_DWORD *)(result + 876) = v2;
  return result;
}

uint64_t ZinAneTd<8u>::SetL2ResultCfgDmaFmt(uint64_t result, int a2)
{
  switch(a2)
  {
    case 1:
    case 2:
    case 12:
    case 13:
      unsigned int v2 = *(_DWORD *)(result + 920) & 0xFFFFFF3F;
      break;
    case 3:
    case 4:
    case 5:
    case 6:
    case 7:
    case 9:
    case 10:
      unsigned int v2 = *(_DWORD *)(result + 920) & 0xFFFFFF3F | 0x40;
      break;
    case 8:
      ZinAssertImpl("packed10 format not fully implemented yet");
    case 11:
      unsigned int v2 = *(_DWORD *)(result + 920) | 0xC0;
      break;
    default:
      ZinAssertImpl("Invalid tensor format");
  }
  *(_DWORD *)(result + 92std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2;
  return result;
}

uint64_t ZinAneTd<8u>::SetL2ResultWrapCfg(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 948) & 0xFFFFF8FF | 0x400;
      goto LABEL_7;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 948) & 0xFFFFF8FF | 0x300;
      goto LABEL_7;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 948) & 0xFFFFF8FF | 0x100;
      goto LABEL_7;
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 948) & 0xFFFFF8FF | 0x200;
      goto LABEL_7;
    case 4:
      ZinAssertImpl("Error: Invalid Wrap Axis");
    case 5:
      unsigned int v2 = *(_DWORD *)(result + 948) & 0xFFFFF8FF;
LABEL_7:
      *(_DWORD *)(result + 948) = v2;
      break;
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<8u>::SetL2ResultWrapStartOffset(uint64_t result, __int16 a2)
{
  *(_WORD *)(result + 962) = a2;
  return result;
}

uint64_t ZinAneTd<8u>::SetL2ResultWrapIndex(uint64_t result, __int16 a2)
{
  *(_WORD *)(result + 96std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = a2;
  return result;
}

uint64_t ZinAneTd<8u>::SetL2ResultWrapAddrOffset(uint64_t result, __int16 a2)
{
  *(_DWORD *)(result + 984) = *(_DWORD *)(result + 984) & 0xF800FFFF | ((a2 & 0x7FF) << 16);
  return result;
}

uint64_t ZinAneTd<8u>::SetL2ResultWrapAddr(uint64_t result, __int16 a2)
{
  *(_DWORD *)(result + 984) = *(_DWORD *)(result + 984) & 0xFFFFF000 | a2 & 0xFFF;
  return result;
}

uint64_t ZinAneTd<8u>::SetL2SrcOffsetYlsbsFromCropOffsetY(uint64_t a1)
{
  uint64_t result = ZinExtractLSBs(*(unsigned __int16 *)(a1 + 716), 5);
  *(_DWORD *)(a1 + 872) = *(_DWORD *)(a1 + 872) & 0x7FFFFFF | (result << 27);
  return result;
}

uint64_t ZinAneTd<8u>::SetSourceAddrWrap(uint64_t result, __int16 a2, __int16 a3)
{
  *(_DWORD *)(result + 976) = a3 & 0xFFF | ((a2 & 0x7FF) << 16) | *(_DWORD *)(result + 976) & 0xF800F000;
  return result;
}

uint64_t ZinAneTd<8u>::SetSourceWrap(uint64_t result, unsigned int a2, unsigned __int16 a3, unsigned __int16 a4)
{
  if (a2 >= 4) {
    ZinAssertImpl("Source wrapping dimension not acceptable\n");
  }
  *(_DWORD *)(result + 948) = *(_DWORD *)(result + 948) & 0xFFFFFFF8 | dword_211F04410[a2];
  *(_DWORD *)(result + 952) = a4 | (a3 << 16);
  return result;
}

BOOL ZinAneTd<8u>::SetL2Src1Interleave(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 584), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Source Interleave");
  }
  *(_DWORD *)(a1 + 872) = *(_DWORD *)(a1 + 872) & 0xFFFFF0FF | ((v4 & 0xF) << 8);
  return result;
}

uint64_t ZinAneTd<8u>::SetL2Src1SourceType(uint64_t result, int a2)
{
  int v2 = 0;
  switch(a2)
  {
    case 0:
      ZinAssertImpl("Error: It must have a valid L2 access mode");
    case 1:
      int v2 = 2;
      break;
    case 2:
      int v2 = 1;
      break;
    case 4:
      int v2 = 3;
      break;
    default:
      break;
  }
  *(_DWORD *)(result + 872) = *(_DWORD *)(result + 872) & 0xFFFFFFFC | v2;
  return result;
}

uint64_t ZinAneTd<8u>::SetL2Src2SourceType(uint64_t result, int a2)
{
  int v2 = 0;
  switch(a2)
  {
    case 0:
      ZinAssertImpl("Error: It must have a valid L2 access mode");
    case 1:
      int v2 = 2;
      break;
    case 2:
      int v2 = 1;
      break;
    case 4:
      int v2 = 3;
      break;
    default:
      break;
  }
  *(_DWORD *)(result + 876) = *(_DWORD *)(result + 876) & 0xFFFFFFFC | v2;
  return result;
}

BOOL ZinAneTd<8u>::SetL2Src2BaseAddress(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 336), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src2 Base Address");
  }
  *(_DWORD *)(a1 + 90std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 900) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<8u>::SetL2Src2ChannelStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x11uLL, (unsigned int *)(*(void *)(a1 + 1296) + 344), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Source 2 Channel Stride");
  }
  *(_DWORD *)(a1 + 904) = *(_DWORD *)(a1 + 904) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<8u>::SetL2Src2RowStride(uint64_t a1, ZinCodegen *this, ZinTensorDimensions *a3, uint64_t a4, uint64_t *a5)
{
  int v8 = 0;
  ZinCodegen::GetL2RowStride(this, a3, *(unsigned int *)(*(void *)(a1 + 1296) + 356), &v8, a5);
  unsigned int v7 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(v8, 0x11uLL, (unsigned int *)(*(void *)(a1 + 1296) + 352), &v7);
  if (!result) {
    ZinAssertImpl("Illegal L2 Source 2 Row Stride");
  }
  *(_DWORD *)(a1 + 908) = *(_DWORD *)(a1 + 908) & 0xFFE0000F | (16 * (v7 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<8u>::SetL2Src2DepthStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x11uLL, (unsigned int *)(*(void *)(a1 + 1296) + 360), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Source 2 Depth Stride");
  }
  *(_DWORD *)(a1 + 912) = *(_DWORD *)(a1 + 912) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<8u>::SetL2Src2GroupStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x11uLL, (unsigned int *)(*(void *)(a1 + 1296) + 368), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Source 2 Group Stride");
  }
  *(_DWORD *)(a1 + 916) = *(_DWORD *)(a1 + 916) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

uint64_t ZinAneTd<8u>::SetL2Src2OffsetYlsbsFromCropOffsetY(uint64_t a1)
{
  uint64_t result = ZinExtractLSBs(*(unsigned __int16 *)(a1 + 732), 5);
  *(_DWORD *)(a1 + 876) = *(_DWORD *)(a1 + 876) & 0x7FFFFFF | (result << 27);
  return result;
}

uint64_t ZinAneTd<8u>::SetL2Src1CfgForCompression(uint64_t result, int a2)
{
  unsigned int v2 = *(_DWORD *)(result + 872) & 0xFDF80FFF;
  *(_DWORD *)(result + 872) = v2 | 0x2000000;
  switch(a2)
  {
    case 1:
      unsigned int v3 = v2 & 0xF9F80FFF | 0x2000000;
LABEL_7:
      *(_DWORD *)(result + 872) = v3;
      return result;
    case 2:
      unsigned int v3 = v2 | 0x6000000;
      goto LABEL_7;
    case 0:
      ZinAssertImpl("Invalid macro block size");
  }
  return result;
}

uint64_t ZinAneTd<8u>::SetL2Src2CfgForCompression(uint64_t result, int a2)
{
  unsigned int v2 = *(_DWORD *)(result + 876) & 0xFDF80FFF;
  *(_DWORD *)(result + 876) = v2 | 0x2000000;
  switch(a2)
  {
    case 1:
      unsigned int v3 = v2 & 0xF9F80FFF | 0x2000000;
LABEL_7:
      *(_DWORD *)(result + 876) = v3;
      return result;
    case 2:
      unsigned int v3 = v2 | 0x6000000;
      goto LABEL_7;
    case 0:
      ZinAssertImpl("Invalid macro block size");
  }
  return result;
}

uint64_t ZinAneTd<8u>::SetL2ResultCfgForCompression(uint64_t result, int a2)
{
  unsigned int v2 = *(_DWORD *)(result + 920) & 0xFDF80FFF;
  *(_DWORD *)(result + 92std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2 | 0x2000000;
  switch(a2)
  {
    case 1:
      unsigned int v3 = v2 & 0xF9F80FFF | 0x2000000;
LABEL_7:
      *(_DWORD *)(result + 92std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v3;
      return result;
    case 2:
      unsigned int v3 = v2 | 0x6000000;
      goto LABEL_7;
    case 0:
      ZinAssertImpl("Invalid macro block size");
  }
  return result;
}

uint64_t ZinAneTd<8u>::SetSource2AddrWrap(uint64_t result, __int16 a2, __int16 a3)
{
  *(_DWORD *)(result + 98std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = a3 & 0xFFF | ((a2 & 0x7FF) << 16) | *(_DWORD *)(result + 980) & 0xF800F000;
  return result;
}

uint64_t ZinAneTd<8u>::SetSource2Wrap(uint64_t result, unsigned int a2, unsigned __int16 a3, unsigned __int16 a4)
{
  if (a2 >= 4) {
    ZinAssertImpl("Source wrapping dimension not acceptable\n");
  }
  *(_DWORD *)(result + 948) = *(_DWORD *)(result + 948) & 0xFFFFFF8F | dword_211F04420[a2];
  *(_DWORD *)(result + 956) = a4 | (a3 << 16);
  return result;
}

uint64_t ZinAneTd<8u>::SetOpMode(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 1064) & 0xFFFFFFF8;
      goto LABEL_8;
    case 1:
      ZinAssertImpl("ElemWise not valid for architecture");
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 1064) & 0xFFFFFFF8 | 3;
      goto LABEL_8;
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 1064) & 0xFFFFFFF8 | 1;
      goto LABEL_8;
    case 4:
      unsigned int v2 = *(_DWORD *)(result + 1064) & 0xFFFFFFF8 | 2;
      goto LABEL_8;
    case 5:
      unsigned int v2 = *(_DWORD *)(result + 1064) & 0xFFFFFFF8 | 4;
      goto LABEL_8;
    case 6:
      unsigned int v2 = *(_DWORD *)(result + 1064) & 0xFFFFFFF8 | 5;
LABEL_8:
      *(_DWORD *)(result + 1064) = v2;
      break;
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<8u>::SetKernelMode(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 1064) & 0xFFFFFFF7;
LABEL_7:
      *(_DWORD *)(result + 1064) = v2;
      return result;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 1064) | 8;
      goto LABEL_7;
    case 2:
      ZinAssertImpl("Unsupported Kernel Mode");
  }
  return result;
}

uint64_t ZinAneTd<8u>::SetPassthroughEnable(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 32;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 1064) = *(_DWORD *)(result + 1064) & 0xFFFFFFDF | v2;
  return result;
}

uint64_t ZinAneTd<8u>::SetKernelFmt(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 1060) & 0xFFFFFFFC;
      goto LABEL_5;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 1060) & 0xFFFFFFFC | 1;
      goto LABEL_5;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 1060) & 0xFFFFFFFC | 2;
LABEL_5:
      *(_DWORD *)(result + 106std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2;
      break;
    case 3:
      ZinAssertImpl("Unimplemented or Unsupported kernel format");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<8u>::SetKernelDmaSrcKid(uint64_t result, __int16 a2)
{
  *(_WORD *)(result + 46) = a2;
  return result;
}

uint64_t ZinAneTd<8u>::SetKernelDmaSrcNoReuseHint(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 512;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 44) = *(_DWORD *)(result + 44) & 0xFFFFFDFF | v2;
  return result;
}

uint64_t ZinAneTd<8u>::SetKernelDmaSrcCoeffDmaEn(uint64_t result, int a2, uint64_t a3)
{
  *(_DWORD *)(result + 4 * a3 + 76) = *(_DWORD *)(result + 4 * a3 + 76) & 0xFFFFFFFE | a2;
  return result;
}

uint64_t ZinAneTd<8u>::SetKernelDmaSrcConfigPrefetch(uint64_t result, uint64_t a2)
{
  if (*(_DWORD *)(a2 + 96) == 1)
  {
    int v2 = *(unsigned __int16 *)(result + 52) | (*(_DWORD *)(a2 + 104) << 16);
    *(_DWORD *)(result + 52) = v2;
    unsigned int v3 = v2 & 0xFFFFFFFE | *(unsigned __int8 *)(a2 + 112);
    *(_DWORD *)(result + 52) = v3;
    *(_DWORD *)(result + 52) = v3 & 0xFFFFFFFD | (2 * *(unsigned __int8 *)(a2 + 113));
  }
  return result;
}

uint64_t ZinAneTd<8u>::SetKernelDmaSrcCoeffDmaCacheHint(uint64_t result, int a2, uint64_t a3)
{
  int v3 = 224;
  switch(a2)
  {
    case 0:
      goto LABEL_5;
    case 1:
      int v3 = 32;
      goto LABEL_5;
    case 2:
      int v3 = 64;
      goto LABEL_5;
    case 3:
      int v3 = 192;
LABEL_5:
      *(_DWORD *)(result + 4 * a3 + 76) = *(_DWORD *)(result + 4 * a3 + 76) & 0xFFFFFF0F | v3;
      break;
    case 4:
      ZinAssertImpl("Error: Invalid KernelDmaSrc CoeffDma CacheHint");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<8u>::SetKernelDmaSrcPostScaleDmaCacheHint(uint64_t result, int a2)
{
  int v2 = 224;
  switch(a2)
  {
    case 0:
      goto LABEL_5;
    case 1:
      int v2 = 32;
      goto LABEL_5;
    case 2:
      int v2 = 64;
      goto LABEL_5;
    case 3:
      int v2 = 192;
LABEL_5:
      *(_DWORD *)(result + 284) = *(_DWORD *)(result + 284) & 0xFFFFFF0F | v2;
      break;
    case 4:
      ZinAssertImpl("Error: Invalid KernelDmaSrc PostScale Dma CacheHint");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<8u>::SetKernelDmaSrcBiasDmaCacheHint(uint64_t result, int a2)
{
  int v2 = 224;
  switch(a2)
  {
    case 0:
      goto LABEL_5;
    case 1:
      int v2 = 32;
      goto LABEL_5;
    case 2:
      int v2 = 64;
      goto LABEL_5;
    case 3:
      int v2 = 192;
LABEL_5:
      *(_DWORD *)(result + 268) = *(_DWORD *)(result + 268) & 0xFFFFFF0F | v2;
      break;
    case 4:
      ZinAssertImpl("Error: Invalid KernelDmaSrc PostScale Dma CacheHint");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<8u>::SetKernelDmaSrcPaletteLutDmaCacheHint(uint64_t result, int a2)
{
  int v2 = 224;
  switch(a2)
  {
    case 0:
      goto LABEL_5;
    case 1:
      int v2 = 32;
      goto LABEL_5;
    case 2:
      int v2 = 64;
      goto LABEL_5;
    case 3:
      int v2 = 192;
LABEL_5:
      *(_DWORD *)(result + 30std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 300) & 0xFFFFFF0F | v2;
      break;
    case 4:
      ZinAssertImpl("Error: Invalid KernelDmaSrc PaletteLut Dma CacheHint");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<8u>::SetKernelDmaSrcNonLinearLutDmaCacheHint(uint64_t result, int a2)
{
  int v2 = 224;
  switch(a2)
  {
    case 0:
      goto LABEL_5;
    case 1:
      int v2 = 32;
      goto LABEL_5;
    case 2:
      int v2 = 64;
      goto LABEL_5;
    case 3:
      int v2 = 192;
LABEL_5:
      *(_DWORD *)(result + 316) = *(_DWORD *)(result + 316) & 0xFFFFFF0F | v2;
      break;
    case 4:
      ZinAssertImpl("Error: Invalid KernelDmaSrc PostScale Dma CacheHint");
    default:
      return result;
  }
  return result;
}

BOOL ZinAneTd<8u>::SetKernelDmaSrcCoeffMemBufferSize(uint64_t a1, unsigned int a2, uint64_t a3)
{
  int v6 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 568), &v6);
  if (result) {
    *(_DWORD *)(a1 + 4 * a3 + 204) = *(_DWORD *)(a1 + 4 * a3 + 204) & 0x3F | (v6 << 6);
  }
  return result;
}

BOOL ZinAneTd<8u>::SetKernelDmaSrcCoeffBaseOffset(uint64_t a1, unsigned int a2, uint64_t a3)
{
  int v6 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 560), &v6);
  if (result) {
    *(_DWORD *)(a1 + 4 * a3 + 14std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 4 * a3 + 140) & 0x3F | (v6 << 6);
  }
  return result;
}

uint64_t ZinAneTd<8u>::SetKernelDmaSrcDataSetId(uint64_t result, char a2, uint64_t a3)
{
  *(unsigned char *)(result + 4 * a3 + 77) = a2;
  return result;
}

uint64_t ZinAneTd<8u>::SetPaddingMode(uint64_t result, int a2, int a3)
{
  switch(a2)
  {
    case 1:
      if (a3) {
        goto LABEL_11;
      }
      int v3 = 0;
      int v4 = 0;
      break;
    case 2:
      if (a3) {
        goto LABEL_11;
      }
      int v3 = 0;
      int v4 = 4;
      break;
    case 3:
      if (a3) {
        goto LABEL_11;
      }
      int v4 = 8;
      int v3 = 0x40000;
      break;
    case 4:
      if (a3) {
LABEL_11:
      }
        ZinAssertImpl("Error: padding-mode doesn't support constants");
      int v3 = 0;
      int v4 = 12;
      break;
    case 6:
      ZinAssertImpl("Platform doesn't support reflective padding mode");
    case 9:
      ZinAssertImpl("Platform doesn't support constant padding-mode");
    default:
      ZinAssertImpl("Invalid padding mode: %d", a2);
  }
  *(_DWORD *)(result + 868) = *(_DWORD *)(result + 868) & 0xFFFFFFF3 | v4;
  *(_DWORD *)(result + 1064) = *(_DWORD *)(result + 1064) & 0xFFFBFFFF | v3;
  return result;
}

uint64_t ZinAneTd<8u>::SetKernelDmaSrcEnable(uint64_t result)
{
  *(_DWORD *)(result + 44) |= 0x40u;
  return result;
}

uint64_t ZinAneTd<8u>::SetKernelAlignmentFormat(uint64_t result, int a2)
{
  if (a2)
  {
    if (a2 != 1) {
      return result;
    }
    unsigned int v2 = *(_DWORD *)(result + 1060) & 0xFFFEFFFF;
  }
  else
  {
    unsigned int v2 = *(_DWORD *)(result + 1060) | 0x10000;
  }
  *(_DWORD *)(result + 106std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2;
  return result;
}

void ZinAneTd<8u>::SetAlignedKernelRelocationCommand(uint64_t a1, void *a2, uint64_t a3, const void **a4, uint64_t a5)
{
  if (a2[1])
  {
    if (*((char *)a4 + 23) >= 0) {
      size_t v10 = *((unsigned __int8 *)a4 + 23);
    }
    else {
      size_t v10 = (size_t)a4[1];
    }
    long long v11 = __p;
    std::string::basic_string[abi:ne180100]((uint64_t)__p, v10 + 7);
    if (v24 < 0) {
      long long v11 = (void **)__p[0];
    }
    if (v10)
    {
      if (*((char *)a4 + 23) >= 0) {
        uint64_t v12 = a4;
      }
      else {
        uint64_t v12 = *a4;
      }
      memmove(v11, v12, v10);
    }
    strcpy((char *)v11 + v10, "_actlut");
    ZinAneTdHw_v8::AddRelocInfo((uint64_t *)(a1 + 8), (uint64_t)__p, 5510, a3, 1, 1, a5, 0);
    if (v24 < 0) {
      operator delete(__p[0]);
    }
  }
  if (a2[2])
  {
    if (*((char *)a4 + 23) >= 0) {
      size_t v13 = *((unsigned __int8 *)a4 + 23);
    }
    else {
      size_t v13 = (size_t)a4[1];
    }
    uint64_t v14 = __p;
    std::string::basic_string[abi:ne180100]((uint64_t)__p, v13 + 7);
    if (v24 < 0) {
      uint64_t v14 = (void **)__p[0];
    }
    if (v13)
    {
      if (*((char *)a4 + 23) >= 0) {
        unsigned int v15 = a4;
      }
      else {
        unsigned int v15 = *a4;
      }
      memmove(v14, v15, v13);
    }
    strcpy((char *)v14 + v13, "_pallut");
    ZinAneTdHw_v8::AddRelocInfo((uint64_t *)(a1 + 8), (uint64_t)__p, 5506, a3, 1, 1, a5, 0);
    if (v24 < 0) {
      operator delete(__p[0]);
    }
  }
  if (a2[3])
  {
    if (*((char *)a4 + 23) >= 0) {
      size_t v16 = *((unsigned __int8 *)a4 + 23);
    }
    else {
      size_t v16 = (size_t)a4[1];
    }
    uint64_t v17 = __p;
    std::string::basic_string[abi:ne180100]((uint64_t)__p, v16 + 6);
    if (v24 < 0) {
      uint64_t v17 = (void **)__p[0];
    }
    if (v16)
    {
      if (*((char *)a4 + 23) >= 0) {
        uint64_t v18 = a4;
      }
      else {
        uint64_t v18 = *a4;
      }
      memmove(v17, v18, v16);
    }
    strcpy((char *)v17 + v16, "_scale");
    ZinAneTdHw_v8::AddRelocInfo((uint64_t *)(a1 + 8), (uint64_t)__p, 5502, a3, 1, 1, a5, 0);
    if (v24 < 0) {
      operator delete(__p[0]);
    }
  }
  if (a2[4])
  {
    uint64_t v19 = (uint64_t *)(a1 + 8);
    if (*((char *)a4 + 23) >= 0) {
      size_t v20 = *((unsigned __int8 *)a4 + 23);
    }
    else {
      size_t v20 = (size_t)a4[1];
    }
    long long v21 = __p;
    std::string::basic_string[abi:ne180100]((uint64_t)__p, v20 + 5);
    if (v24 < 0) {
      long long v21 = (void **)__p[0];
    }
    if (v20)
    {
      if (*((char *)a4 + 23) >= 0) {
        long long v22 = a4;
      }
      else {
        long long v22 = *a4;
      }
      memmove(v21, v22, v20);
    }
    strcpy((char *)v21 + v20, "_bias");
    ZinAneTdHw_v8::AddRelocInfo(v19, (uint64_t)__p, 5498, a3, 1, 1, a5, 0);
    if (v24 < 0) {
      operator delete(__p[0]);
    }
  }
}

void sub_2112C7ED0(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, void *__p, uint64_t a10, int a11, __int16 a12, char a13, char a14)
{
  if (a14 < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

_DWORD *ZinAneTd<8u>::SetAlignedKernelBias(_DWORD *result, uint64_t a2, uint64_t a3, int a4)
{
  result[11] = result[11] & 0xFFFFFFF3 | 8;
  result[265] = result[265] & 0xFFF9FFFF | 0x40000;
  result[68] = result[68] & 0x3F | (a4 << 6);
  result[67] |= 1u;
  return result;
}

_DWORD *ZinAneTd<8u>::SetAlignedKernelPostScale(_DWORD *result, uint64_t a2, uint64_t a3, int a4)
{
  result[11] = result[11] & 0xFFFFFFFC | 2;
  result[265] = result[265] & 0xFFE7FFFF | 0x100000;
  result[72] = result[72] & 0x3F | (a4 << 6);
  result[71] |= 1u;
  return result;
}

uint64_t ZinAneTd<8u>::SetAlignedKernelPaletteLut(uint64_t result, uint64_t a2, uint64_t a3, int a4)
{
  *(_DWORD *)(result + 304) = *(_DWORD *)(result + 304) & 0x3F | (a4 << 6);
  *(_DWORD *)(result + 300) |= 1u;
  return result;
}

uint64_t ZinAneTd<8u>::SetAlignedKernelNonLinearLut(uint64_t result, uint64_t a2, uint64_t a3, int a4)
{
  *(_DWORD *)(result + 32std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 320) & 0x3F | (a4 << 6);
  *(_DWORD *)(result + 316) |= 1u;
  return result;
}

uint64_t ZinAneTd<8u>::SetAlignedCoeffSizePerCh(uint64_t result, int a2)
{
  *(_DWORD *)(result + 48) = *(_DWORD *)(result + 48) & 0xF0000000 | a2 & 0xFFFFFFF;
  return result;
}

uint64_t ZinAneTd<8u>::SetPEFinalScale(uint64_t result, float a2)
{
  *(float *)(result + 1016) = a2;
  return result;
}

void ZinAneTd<8u>::SetPEScale(uint64_t a1, float a2)
{
  *(float *)(a1 + 1004) = ZinF32ToNearestF19(a2);
}

void ZinAneTd<8u>::SetPEBias(uint64_t a1, float a2)
{
  *(float *)(a1 + 100std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = ZinF32ToNearestF19(a2);
}

void ZinAneTd<8u>::SetPEPreScale(uint64_t a1, float a2)
{
  *(float *)(a1 + 1012) = ZinF32ToNearestF19(a2);
}

uint64_t ZinAneTd<8u>::SetPESrc1ReLu(uint64_t result, int a2)
{
  *(_DWORD *)(result + 868) = *(_DWORD *)(result + 868) & 0xFFFFFFFE | a2;
  return result;
}

uint64_t ZinAneTd<8u>::SetPESrc2ReLu(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 16;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 868) = *(_DWORD *)(result + 868) & 0xFFFFFFEF | v2;
  return result;
}

uint64_t ZinAneTd<8u>::SetPESrc1Transpose(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 256;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 552) = *(_DWORD *)(result + 552) & 0xFFFFFEFF | v2;
  return result;
}

uint64_t ZinAneTd<8u>::SetPESrc2Transpose(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 512;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 552) = *(_DWORD *)(result + 552) & 0xFFFFFDFF | v2;
  return result;
}

uint64_t ZinAneTd<8u>::SetPESrc1Broadcast(uint64_t result, uint64_t a2)
{
  for (uint64_t i = *(uint64_t **)(a2 + 16); i; uint64_t i = (uint64_t *)*i)
  {
    unsigned int v3 = *((_DWORD *)i + 4) - 1;
    if (v3 <= 3) {
      *(_DWORD *)(result + 552) |= dword_211F04430[v3];
    }
  }
  return result;
}

uint64_t ZinAneTd<8u>::SetPESrc2Broadcast(uint64_t result, uint64_t a2, char a3)
{
  for (uint64_t i = *(uint64_t **)(a2 + 16); i; uint64_t i = (uint64_t *)*i)
  {
    int v4 = 128;
    switch(*((_DWORD *)i + 4))
    {
      case 1:
        int v4 = 64;
        break;
      case 2:
        break;
      case 3:
        if (a3) {
          continue;
        }
        int v4 = 32;
        break;
      case 4:
        if (a3) {
          continue;
        }
        int v4 = 16;
        break;
      default:
        continue;
    }
    *(_DWORD *)(result + 552) |= v4;
  }
  return result;
}

void ZinAneTd<8u>::SetPEIndexMode(uint64_t a1, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(a1 + 972) & 0xFFF8FFFF | 0x10000;
      goto LABEL_7;
    case 1:
      unsigned int v2 = *(_DWORD *)(a1 + 972) & 0xFFF8FFFF | 0x20000;
      goto LABEL_7;
    case 2:
      unsigned int v2 = *(_DWORD *)(a1 + 972) & 0xFFF8FFFF | 0x50000;
      goto LABEL_7;
    case 3:
      unsigned int v2 = *(_DWORD *)(a1 + 972) & 0xFFF8FFFF | 0x30000;
      goto LABEL_7;
    case 4:
      unsigned int v2 = *(_DWORD *)(a1 + 972) & 0xFFF8FFFF | 0x40000;
LABEL_7:
      *(_DWORD *)(a1 + 972) = v2;
      break;
    case 5:
      BOOL v3 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v3) {
        ZinAneTd<8u>::SetPEIndexMode(v3, v4, v5, v6, v7, v8, v9, v10);
      }
      break;
    default:
      return;
  }
}

uint64_t ZinAneTd<8u>::SetPEIndexTranspose(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 0x4000000;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 972) = *(_DWORD *)(result + 972) & 0xFBFFFFFF | v2;
  return result;
}

uint64_t ZinAneTd<8u>::SetPEIndexBroadcast(uint64_t result, uint64_t a2)
{
  int v2 = *(uint64_t **)(a2 + 16);
  if (v2)
  {
    while (1)
    {
      int v3 = *((_DWORD *)v2 + 4);
      if (v3 == 2) {
        break;
      }
      if (v3 == 1)
      {
        int v4 = 0x1000000;
LABEL_6:
        *(_DWORD *)(result + 972) |= v4;
      }
      int v2 = (uint64_t *)*v2;
      if (!v2) {
        return result;
      }
    }
    int v4 = 0x2000000;
    goto LABEL_6;
  }
  return result;
}

uint64_t ZinAneTd<8u>::SetPEMaxIndex(uint64_t result, __int16 a2)
{
  *(_WORD *)(result + 972) = a2;
  return result;
}

uint64_t ZinAneTd<8u>::SetPEOperationMode(uint64_t a1, int a2)
{
  uint64_t v2 = 0;
  switch(a2)
  {
    case 0:
      *(_DWORD *)(a1 + 996) &= 0xFFFFFFE3;
      int v3 = (unsigned int *)(*(void *)(a1 + 1296) + 600);
      unint64_t v4 = 0;
      goto LABEL_8;
    case 1:
      *(_DWORD *)(a1 + 996) = *(_DWORD *)(a1 + 996) & 0xFFFFFFE3 | 4;
      int v3 = (unsigned int *)(*(void *)(a1 + 1296) + 600);
      unint64_t v4 = 1;
      goto LABEL_8;
    case 2:
      *(_DWORD *)(a1 + 996) = *(_DWORD *)(a1 + 996) & 0xFFFFFFE3 | 0x10;
      if (!CheckRegValueRange(4uLL, (unsigned int *)(*(void *)(a1 + 1296) + 600))) {
        goto LABEL_5;
      }
      goto LABEL_9;
    case 3:
      *(_DWORD *)(a1 + 996) = *(_DWORD *)(a1 + 996) & 0xFFFFFFE3 | 8;
      int v3 = (unsigned int *)(*(void *)(a1 + 1296) + 600);
      unint64_t v4 = 2;
      goto LABEL_8;
    case 4:
      *(_DWORD *)(a1 + 996) = *(_DWORD *)(a1 + 996) & 0xFFFFFFE3 | 0xC;
      int v3 = (unsigned int *)(*(void *)(a1 + 1296) + 600);
      unint64_t v4 = 3;
LABEL_8:
      if (CheckRegValueRange(v4, v3)) {
        goto LABEL_9;
      }
LABEL_5:
      uint64_t v2 = 0;
      break;
    case 5:
      return v2;
    default:
LABEL_9:
      uint64_t v2 = 1;
      break;
  }
  return v2;
}

uint64_t ZinAneTd<8u>::SetPEFirstSource(uint64_t result, int a2)
{
  if (a2)
  {
    if (a2 != 1) {
      return result;
    }
    unsigned int v2 = *(_DWORD *)(result + 996) & 0xFFFEFFFF;
  }
  else
  {
    unsigned int v2 = *(_DWORD *)(result + 996) | 0x10000;
  }
  *(_DWORD *)(result + 996) = v2;
  return result;
}

uint64_t ZinAneTd<8u>::SetPESecondSource(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 996) & 0xFFF3FFFF;
      goto LABEL_6;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 996) & 0xFFF3FFFF | 0x40000;
      goto LABEL_6;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 996) & 0xFFF3FFFF | 0x80000;
      goto LABEL_6;
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 996) | 0xC0000;
LABEL_6:
      *(_DWORD *)(result + 996) = v2;
      break;
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<8u>::SetPECondition(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 996) & 0xFFFFFE3F;
      goto LABEL_10;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 996) | 0x1C0;
      goto LABEL_10;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 996) & 0xFFFFFE3F | 0x100;
      goto LABEL_10;
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 996) & 0xFFFFFE3F | 0x180;
      goto LABEL_10;
    case 4:
      unsigned int v2 = *(_DWORD *)(result + 996) & 0xFFFFFE3F | 0x80;
      goto LABEL_10;
    case 5:
      unsigned int v2 = *(_DWORD *)(result + 996) & 0xFFFFFE3F | 0x140;
      goto LABEL_10;
    case 6:
      unsigned int v2 = *(_DWORD *)(result + 996) & 0xFFFFFE3F | 0x40;
      goto LABEL_10;
    case 7:
      unsigned int v2 = *(_DWORD *)(result + 996) & 0xFFFFFE3F | 0xC0;
LABEL_10:
      *(_DWORD *)(result + 996) = v2;
      break;
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<8u>::SetPEOutputCtoW(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 1024;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 552) = *(_DWORD *)(result + 552) & 0xFFFFFBFF | v2;
  return result;
}

BOOL ZinAneTd<8u>::SetL2ResultBaseAddr(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 376), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Result Base Address");
  }
  *(_DWORD *)(a1 + 924) = *(_DWORD *)(a1 + 924) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<8u>::SetL2ResultChannelStride(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 384), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Result Channel Stride");
  }
  *(_DWORD *)(a1 + 928) = *(_DWORD *)(a1 + 928) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<8u>::SetL2ResultRowStride(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 392), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Result Row Stride");
  }
  *(_DWORD *)(a1 + 9std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_DWORD *)(a1 + 932) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<8u>::SetL2ResultDepthStride(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 400), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Result Depth Stride");
  }
  *(_DWORD *)(a1 + 936) = *(_DWORD *)(a1 + 936) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<8u>::SetL2ResultGroupStride(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 408), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Result Group Stride");
  }
  *(_DWORD *)(a1 + 94std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 940) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

uint64_t ZinAneTd<8u>::SetL2BfrMode(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 8;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 92std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 920) & 0xFFFFFFF7 | v2;
  return result;
}

uint64_t ZinAneTd<8u>::SetL2ResultType(uint64_t result, int a2)
{
  switch(a2)
  {
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 920) & 0xFFFFFFFC | 2;
      break;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 920) & 0xFFFFFFFC | 1;
      break;
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 920) & 0xFFFFFFFC;
      break;
    case 4:
      unsigned int v2 = *(_DWORD *)(result + 920) | 3;
      break;
    default:
      ZinAssertImpl("Invalid L2 Result Type");
  }
  *(_DWORD *)(result + 92std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2;
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaSrc1Format(uint64_t result, int a2, int a3)
{
  switch(a2)
  {
    case 1:
      unsigned int v3 = *(_DWORD *)(result + 688) & 0xFFFFCFFC | 0x1000;
      goto LABEL_16;
    case 2:
      unsigned int v3 = *(_DWORD *)(result + 688) & 0xFFFFCFFC;
      goto LABEL_16;
    case 3:
      unsigned int v4 = *(_DWORD *)(result + 688) & 0xFFFFCFCC;
      int v5 = 8241;
      break;
    case 4:
      unsigned int v3 = *(_DWORD *)(result + 688) & 0xFFFFCECC | 1;
      goto LABEL_16;
    case 5:
      unsigned int v4 = *(_DWORD *)(result + 688) & 0xFFFFCECC;
      int v5 = 257;
      break;
    case 6:
      unsigned int v4 = *(_DWORD *)(result + 688) & 0xFFFFCECC;
      int v5 = 17;
      break;
    case 7:
      unsigned int v4 = *(_DWORD *)(result + 688) & 0xFFFFCECC;
      int v5 = 273;
      break;
    case 8:
      ZinAssertImpl("Packed10 format not supported");
    case 9:
      unsigned int v4 = *(_DWORD *)(result + 688) & 0xFFFFCECC;
      if (!a3) {
        goto LABEL_14;
      }
      int v5 = 4401;
      break;
    case 10:
      unsigned int v4 = *(_DWORD *)(result + 688) & 0xFFFFCECC;
      if (a3) {
        int v5 = 305;
      }
      else {
LABEL_14:
      }
        int v5 = 8497;
      break;
    case 11:
      unsigned int v4 = *(_DWORD *)(result + 688) & 0xFFFFFFCF;
      int v5 = 12547;
      break;
    case 12:
      ZinAssertImpl("E4M3 format is not supported");
    case 13:
      ZinAssertImpl("E5M2 format is not supported");
    default:
      ZinAssertImpl("Invalid format provided");
  }
  unsigned int v3 = v4 | v5;
LABEL_16:
  *(_DWORD *)(result + 688) = v3;
  return result;
}

BOOL ZinAneTd<8u>::SetTileDmaSrc1Interleave(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 584), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc1 Interleave");
  }
  *(_DWORD *)(a1 + 688) = *(_DWORD *)(a1 + 688) & 0xF0FFFFFF | ((v4 & 0xF) << 24);
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaSrc1Enable(uint64_t result)
{
  *(_DWORD *)(result + 584) |= 1u;
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaSrc1CacheHint(uint64_t result, int a2, int a3, int a4)
{
  int v4 = 224;
  switch(a2)
  {
    case 0:
      goto LABEL_5;
    case 1:
      int v4 = 32;
      goto LABEL_5;
    case 2:
      int v4 = 64;
      goto LABEL_5;
    case 3:
      int v4 = 192;
LABEL_5:
      *(_DWORD *)(result + 584) = *(_DWORD *)(result + 584) & 0xFFFFFF0F | v4;
      break;
    case 4:
LABEL_15:
      ZinAssertImpl("Invalid CacheHint");
    default:
      break;
  }
  char v5 = 32;
  switch(a4)
  {
    case 0:
      char v5 = -32;
      goto LABEL_10;
    case 2:
      char v5 = 64;
      goto LABEL_10;
    case 3:
      char v5 = -64;
      goto LABEL_10;
    case 4:
      goto LABEL_15;
    default:
LABEL_10:
      char v6 = 2;
      switch(a3)
      {
        case 0:
          char v6 = 14;
          goto LABEL_14;
        case 2:
          char v6 = 4;
          goto LABEL_14;
        case 3:
          char v6 = 12;
          goto LABEL_14;
        case 4:
          goto LABEL_15;
        default:
LABEL_14:
          *(unsigned char *)(result + 592) = v6 | v5;
          return result;
      }
  }
}

uint64_t ZinAneTd<8u>::SetTileDmaSrc2CacheHint(uint64_t result, int a2, int a3, int a4)
{
  int v4 = 224;
  switch(a2)
  {
    case 0:
      goto LABEL_5;
    case 1:
      int v4 = 32;
      goto LABEL_5;
    case 2:
      int v4 = 64;
      goto LABEL_5;
    case 3:
      int v4 = 192;
LABEL_5:
      *(_DWORD *)(result + 588) = *(_DWORD *)(result + 588) & 0xFFFFFF0F | v4;
      break;
    case 4:
LABEL_15:
      ZinAssertImpl("Invalid CacheHint");
    default:
      break;
  }
  char v5 = 32;
  switch(a4)
  {
    case 0:
      char v5 = -32;
      goto LABEL_10;
    case 2:
      char v5 = 64;
      goto LABEL_10;
    case 3:
      char v5 = -64;
      goto LABEL_10;
    case 4:
      goto LABEL_15;
    default:
LABEL_10:
      char v6 = 2;
      switch(a3)
      {
        case 0:
          char v6 = 14;
          goto LABEL_14;
        case 2:
          char v6 = 4;
          goto LABEL_14;
        case 3:
          char v6 = 12;
          goto LABEL_14;
        case 4:
          goto LABEL_15;
        default:
LABEL_14:
          *(unsigned char *)(result + 596) = v6 | v5;
          return result;
      }
  }
}

BOOL ZinAneTd<8u>::SetTileDmaSrc1ChannelStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 1296) + 440), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc1 Channel Stride");
  }
  *(_DWORD *)(a1 + 612) = *(_DWORD *)(a1 + 612) & 0x3F | (v4 << 6);
  return result;
}

BOOL ZinAneTd<8u>::SetTileDmaSrc1RowStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 1296) + 432), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc1 Row Stride");
  }
  *(_DWORD *)(a1 + 608) = *(_DWORD *)(a1 + 608) & 0x3F | (v4 << 6);
  return result;
}

BOOL ZinAneTd<8u>::SetTileDmaSrc1DepthStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 1296) + 448), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc1 Depth Stride");
  }
  *(_DWORD *)(a1 + 616) = *(_DWORD *)(a1 + 616) & 0x3F | (v4 << 6);
  return result;
}

BOOL ZinAneTd<8u>::SetTileDmaSrc1GroupStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 1296) + 456), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc1 Group Stride");
  }
  *(_DWORD *)(a1 + 62std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 620) & 0x3F | (v4 << 6);
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaSrc1WrapStatic(uint64_t a1, unsigned __int16 a2, unsigned __int16 a3, unsigned int a4)
{
  uint64_t result = ZinAneTd<8u>::SetTileDmaSrc1WrapCfg(a1, a4);
  *(_DWORD *)(a1 + 768) = a3 | (a2 << 16);
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaSrc1WrapCfg(uint64_t a1, unsigned int a2)
{
  if (a2 == 4) {
    ZinAssertImpl("Width wrap axis is not supported on this architecture");
  }
  uint64_t result = ZinIrCodegenGetDMAWrapCfgDim(a2);
  *(_DWORD *)(a1 + 592) = *(_DWORD *)(a1 + 592) & 0xFFFFF8FF | ((result & 7) << 8);
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaSrc1WrapDynamic(uint64_t a1, uint64_t a2, unsigned int a3)
{
  char v6 = (uint64_t *)(a1 + 8);
  std::string::basic_string[abi:ne180100]<0>(__p, &byte_211F4AA5D);
  ZinAneTdHw_v8::AddRelocInfo(v6, (uint64_t)__p, 4974, a2, 0, 0, 0, 0);
  if (v9 < 0) {
    operator delete(__p[0]);
  }
  return ZinAneTd<8u>::SetTileDmaSrc1WrapCfg(a1, a3);
}

void sub_2112C8F0C(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11, int a12, __int16 a13, char a14, char a15)
{
  if (a15 < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinAneTd<8u>::SetTileDmaSrc1FmtOffsetCh(uint64_t result, char a2)
{
  *(_DWORD *)(result + 688) = *(_DWORD *)(result + 688) & 0xFFF8FFFF | ((a2 & 7) << 16);
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaSrc1FmtCmpVec(uint64_t result, unsigned __int8 a2)
{
  *(_DWORD *)(result + 688) = *(_DWORD *)(result + 688) & 0xFFFFFFF | (a2 << 28);
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaSrc1BaseAddrLo(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return ZinAneTdHw_v8::AddRelocInfo((uint64_t *)(a1 + 8), a2, 4932, a3, 1, 1, 0, 0);
}

uint64_t ZinAneTd<8u>::SetTileDmaSrc1DependencyMode(uint64_t result, int a2)
{
  if (a2 == 2)
  {
    unsigned int v2 = *(_DWORD *)(result + 584) & 0xCFFFFFFF | 0x10000000;
  }
  else if (a2 == 1)
  {
    unsigned int v2 = *(_DWORD *)(result + 584) & 0xCFFFFFFF | 0x20000000;
  }
  else
  {
    if (a2) {
      return result;
    }
    unsigned int v2 = *(_DWORD *)(result + 584) & 0xCFFFFFFF;
  }
  *(_DWORD *)(result + 584) = v2;
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaSrc2DependencyMode(uint64_t result, int a2)
{
  if (a2 == 2)
  {
    unsigned int v2 = *(_DWORD *)(result + 588) & 0xCFFFFFFF | 0x10000000;
  }
  else if (a2 == 1)
  {
    unsigned int v2 = *(_DWORD *)(result + 588) & 0xCFFFFFFF | 0x20000000;
  }
  else
  {
    if (a2) {
      return result;
    }
    unsigned int v2 = *(_DWORD *)(result + 588) & 0xCFFFFFFF;
  }
  *(_DWORD *)(result + 588) = v2;
  return result;
}

unint64_t ZinAneTd<8u>::SetTileDmaSrc1DependencyInterval(uint64_t a1, unsigned int a2)
{
  unint64_t result = ZinIrCodegenValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 592));
  *(_DWORD *)(a1 + 584) = *(_DWORD *)(a1 + 584) & 0xF0FFFFFF | ((result & 0xF) << 24);
  return result;
}

unint64_t ZinAneTd<8u>::SetTileDmaSrc2DependencyInterval(uint64_t a1, unsigned int a2)
{
  unint64_t result = ZinIrCodegenValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 592));
  *(_DWORD *)(a1 + 588) = *(_DWORD *)(a1 + 588) & 0xF0FFFFFF | ((result & 0xF) << 24);
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaSrc1DependencyOffset(uint64_t a1, uint64_t a2)
{
  char v5 = 0;
  if (GetProgrammedDependencyOffsetAndDimension(a2, &v5, (_DWORD *)&v5 + 1)) {
    ZinAssertImpl("Failed to get dependency offset or dimension.");
  }
  if (HIDWORD(v5) == 2)
  {
    unsigned int v3 = *(_DWORD *)(a1 + 776) & 0xFFFFFFFC | 2;
  }
  else if (HIDWORD(v5) == 1)
  {
    unsigned int v3 = *(_DWORD *)(a1 + 776) & 0xFFFFFFFC | 1;
  }
  else
  {
    unsigned int v3 = *(_DWORD *)(a1 + 776) & 0xFFFFFFFC;
  }
  *(_DWORD *)(a1 + 776) = v3;
  uint64_t result = ZinCodegenUtil::ConvertInt32ToCustomUnsignedType((ZinCodegenUtil *)v5, 0x1DuLL);
  *(_DWORD *)(a1 + 776) = *(_DWORD *)(a1 + 776) & 0x80000003 | (4 * (result & 0x1FFFFFFF));
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaSrc2DependencyOffset(uint64_t a1, uint64_t a2)
{
  char v5 = 0;
  if (GetProgrammedDependencyOffsetAndDimension(a2, &v5, (_DWORD *)&v5 + 1)) {
    ZinAssertImpl("Failed to get dependency offset or dimension");
  }
  if (HIDWORD(v5) == 2)
  {
    unsigned int v3 = *(_DWORD *)(a1 + 780) & 0xFFFFFFFC | 2;
  }
  else if (HIDWORD(v5) == 1)
  {
    unsigned int v3 = *(_DWORD *)(a1 + 780) & 0xFFFFFFFC | 1;
  }
  else
  {
    unsigned int v3 = *(_DWORD *)(a1 + 780) & 0xFFFFFFFC;
  }
  *(_DWORD *)(a1 + 78std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v3;
  uint64_t result = ZinCodegenUtil::ConvertInt32ToCustomUnsignedType((ZinCodegenUtil *)v5, 0x1DuLL);
  *(_DWORD *)(a1 + 78std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 780) & 0x80000003 | (4 * (result & 0x1FFFFFFF));
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaSrc1OffsetY(uint64_t result, __int16 a2)
{
  *(_WORD *)(result + 716) = a2;
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaSrc1CompressedInfo(uint64_t result, int a2, int a3, int a4)
{
  int v4 = *(_DWORD *)(result + 704);
  *(_DWORD *)(result + 704) = v4 | 1;
  switch(a4)
  {
    case 0:
      unsigned int v5 = v4 & 0xFFFFCFFE | 1;
      break;
    case 1:
      unsigned int v5 = v4 & 0xFFFFCFFE | 0x1001;
      break;
    case 2:
      unsigned int v5 = v4 & 0xFFFFCFFE | 0x2001;
      break;
    case 3:
      unsigned int v5 = v4 | 0x3001;
      break;
    default:
      ZinAssertImpl("Invalid Lossy Mode");
  }
  *(_DWORD *)(result + 704) = v5;
  if (a3 == 2)
  {
    unsigned int v6 = v5 | 4;
  }
  else
  {
    if (a3 != 1) {
      ZinAssertImpl("Unsupported macro block size");
    }
    unsigned int v6 = v5 & 0xFFFFFFFB;
  }
  *(_DWORD *)(result + 704) = v6;
  if ((a2 - 1) >= 0x13) {
    ZinAssertImpl("Invalid packing format");
  }
  *(_DWORD *)(result + 704) = v6 & 0xFFFFFC0F | dword_211F04368[a2 - 1];
  return result;
}

BOOL ZinAneTd<8u>::SetTileDmaSrc1CompressedSize(uint64_t a1, unsigned int a2, unsigned int a3)
{
  int v7 = 0;
  if (!ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 24), &v7)) {
    ZinAssertImpl("Illegal TileDmaSrc1 Compressed Width");
  }
  *(_DWORD *)(a1 + 708) = *(_DWORD *)(a1 + 708) & 0xFFFE0000 | v7 & 0x1FFFF;
  int v6 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a3, (unsigned int *)(*(void *)(a1 + 1296) + 16), &v6);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc1 Compressed Height");
  }
  *(_DWORD *)(a1 + 712) = *(_DWORD *)(a1 + 712) & 0xFFFE0000 | v6 & 0x1FFFF;
  return result;
}

double ZinAneTd<8u>::SetTileDmaSrc1MetaData(uint64_t a1, uint64_t a2, uint64_t a3, unsigned int a4, unsigned int a5, int a6)
{
  ZinAneTdHw_v8::AddRelocInfo((uint64_t *)(a1 + 8), a2, 4944, a3, 1, 1, 0, 0);
  *(_DWORD *)(a1 + 704) &= ~8u;
  double result = COERCE_DOUBLE(__PAIR64__(a5, a4));
  *(int32x2_t *)(a1 + 664) = vsli_n_s32(*(int32x2_t *)(a1 + 664), (int32x2_t)__PAIR64__(a5, a4), 7uLL);
  *(_DWORD *)(a1 + 672) = *(_DWORD *)(a1 + 672) & 0x7F | (a6 << 7);
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaSrc1NoMetaData(uint64_t result)
{
  *(_DWORD *)(result + 704) |= 8u;
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaSrc1DataSetId(uint64_t result, char a2)
{
  *(unsigned char *)(result + 585) = a2;
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaSrc2Format(uint64_t result, int a2, int a3)
{
  switch(a2)
  {
    case 1:
    case 2:
    case 12:
    case 13:
      int v3 = *(_DWORD *)(result + 692);
      unsigned int v4 = v3 & 0xFFFFFFFC;
      *(_DWORD *)(result + 692) = v3 & 0xFFFFFFFC;
      switch(a2)
      {
        case 1:
          unsigned int v5 = v3 & 0xFFFFCFFC | 0x1000;
          goto LABEL_24;
        case 2:
          unsigned int v5 = v3 & 0xFFFFCFFC;
          goto LABEL_24;
        case 3:
          goto LABEL_5;
        case 4:
          goto LABEL_7;
        case 5:
          goto LABEL_9;
        case 6:
          goto LABEL_11;
        case 7:
          goto LABEL_13;
        case 8:
          goto LABEL_26;
        case 9:
          goto LABEL_15;
        case 10:
          goto LABEL_18;
        case 11:
          goto LABEL_22;
        case 12:
          ZinAssertImpl("E4M3 is not supported");
        case 13:
          ZinAssertImpl("E5M2 is not supported");
        default:
          goto LABEL_27;
      }
    case 3:
      unsigned int v4 = *(_DWORD *)(result + 692) & 0xFFFFFFFC | 1;
LABEL_5:
      unsigned int v6 = v4 & 0xFFFFCFFF;
      int v7 = 8240;
      break;
    case 4:
      unsigned int v4 = *(_DWORD *)(result + 692) & 0xFFFFFFFC | 1;
LABEL_7:
      unsigned int v5 = v4 & 0xFFFFCECF;
      goto LABEL_24;
    case 5:
      unsigned int v4 = *(_DWORD *)(result + 692) & 0xFFFFFFFC | 1;
LABEL_9:
      unsigned int v5 = v4 & 0xFFFFCECF | 0x100;
      goto LABEL_24;
    case 6:
      unsigned int v4 = *(_DWORD *)(result + 692) & 0xFFFFFFFC | 1;
LABEL_11:
      unsigned int v5 = v4 & 0xFFFFCECF | 0x10;
      goto LABEL_24;
    case 7:
      unsigned int v4 = *(_DWORD *)(result + 692) & 0xFFFFFFFC | 1;
LABEL_13:
      unsigned int v6 = v4 & 0xFFFFCECF;
      int v7 = 272;
      break;
    case 8:
LABEL_26:
      ZinAssertImpl("Packed10 format not supported");
    case 9:
      unsigned int v4 = *(_DWORD *)(result + 692) & 0xFFFFFFFC | 1;
LABEL_15:
      unsigned int v6 = v4 & 0xFFFFCECF;
      if (!a3) {
        goto LABEL_20;
      }
      int v7 = 4400;
      break;
    case 10:
      unsigned int v4 = *(_DWORD *)(result + 692) & 0xFFFFFFFC | 1;
LABEL_18:
      unsigned int v6 = v4 & 0xFFFFCECF;
      if (a3) {
        int v7 = 304;
      }
      else {
LABEL_20:
      }
        int v7 = 8496;
      break;
    case 11:
      unsigned int v4 = *(_DWORD *)(result + 692) | 3;
LABEL_22:
      unsigned int v6 = v4 & 0xFFFFFFCF;
      int v7 = 12544;
      break;
    default:
LABEL_27:
      ZinAssertImpl("Invalid format provided");
  }
  unsigned int v5 = v6 | v7;
LABEL_24:
  *(_DWORD *)(result + 692) = v5;
  return result;
}

BOOL ZinAneTd<8u>::SetTileDmaSrc2Interleave(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 584), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc1 Interleave");
  }
  *(_DWORD *)(a1 + 692) = *(_DWORD *)(a1 + 692) & 0xF0FFFFFF | ((v4 & 0xF) << 24);
  return result;
}

BOOL ZinAneTd<8u>::SetL2Src2Interleave(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 584), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Source Interleave");
  }
  *(_DWORD *)(a1 + 876) = *(_DWORD *)(a1 + 876) & 0xFFFFF0FF | ((v4 & 0xF) << 8);
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaSrc2Enable(uint64_t result)
{
  *(_DWORD *)(result + 588) |= 1u;
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaSrc2WrapStatic(uint64_t a1, unsigned __int16 a2, unsigned __int16 a3, unsigned int a4)
{
  uint64_t result = ZinAneTd<8u>::SetTileDmaSrc2WrapCfg(a1, a4);
  *(_DWORD *)(a1 + 772) = a3 | (a2 << 16);
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaSrc2WrapCfg(uint64_t a1, unsigned int a2)
{
  if (a2 == 4) {
    ZinAssertImpl("Width wrap axis is not supported on this architecture");
  }
  uint64_t result = ZinIrCodegenGetDMAWrapCfgDim(a2);
  *(_DWORD *)(a1 + 596) = *(_DWORD *)(a1 + 596) & 0xFFFFF8FF | ((result & 7) << 8);
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaSrc2WrapDynamic(uint64_t a1, uint64_t a2, unsigned int a3)
{
  unsigned int v6 = (uint64_t *)(a1 + 8);
  std::string::basic_string[abi:ne180100]<0>(__p, &byte_211F4AA5D);
  ZinAneTdHw_v8::AddRelocInfo(v6, (uint64_t)__p, 4975, a2, 0, 0, 0, 0);
  if (v9 < 0) {
    operator delete(__p[0]);
  }
  return ZinAneTd<8u>::SetTileDmaSrc2WrapCfg(a1, a3);
}

void sub_2112C97DC(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11, int a12, __int16 a13, char a14, char a15)
{
  if (a15 < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinAneTd<8u>::SetTileDmaSrc2FmtOffsetCh(uint64_t result, char a2)
{
  *(_DWORD *)(result + 692) = *(_DWORD *)(result + 692) & 0xFFF8FFFF | ((a2 & 7) << 16);
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaSrc2FmtCmpVec(uint64_t result, unsigned __int8 a2)
{
  *(_DWORD *)(result + 692) = *(_DWORD *)(result + 692) & 0xFFFFFFF | (a2 << 28);
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaSrc2OffsetY(uint64_t result, __int16 a2)
{
  *(_WORD *)(result + 7std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = a2;
  return result;
}

int8x16_t ZinAneTd<8u>::SetTileDmaSrc2PixelOffset(int8x16_t *a1, unsigned int a2, unsigned int a3, unsigned int a4, unsigned int a5)
{
  v5.i64[0] = __PAIR64__(a3, a2);
  v5.i64[1] = __PAIR64__(a5, a4);
  v6.i64[0] = 0xFFFF0000FFFF0000;
  v6.i64[1] = 0xFFFF0000FFFF0000;
  int8x16_t result = vbslq_s8(v6, a1[47], v5);
  a1[47] = result;
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaSrc2CompressedInfo(uint64_t result, int a2, int a3, int a4)
{
  int v4 = *(_DWORD *)(result + 720);
  *(_DWORD *)(result + 72std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v4 | 1;
  switch(a4)
  {
    case 0:
      unsigned int v5 = v4 & 0xFFFFCFFE | 1;
      break;
    case 1:
      unsigned int v5 = v4 & 0xFFFFCFFE | 0x1001;
      break;
    case 2:
      unsigned int v5 = v4 & 0xFFFFCFFE | 0x2001;
      break;
    case 3:
      unsigned int v5 = v4 | 0x3001;
      break;
    default:
      ZinAssertImpl("Invalid Lossy Mode");
  }
  *(_DWORD *)(result + 72std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v5;
  if (a3 == 2)
  {
    unsigned int v6 = v5 | 4;
  }
  else
  {
    if (a3 != 1) {
      ZinAssertImpl("Unsupported macro block size");
    }
    unsigned int v6 = v5 & 0xFFFFFFFB;
  }
  *(_DWORD *)(result + 72std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v6;
  if ((a2 - 1) >= 0x13) {
    ZinAssertImpl("Invalid packing format");
  }
  *(_DWORD *)(result + 72std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v6 & 0xFFFFFC0F | dword_211F04368[a2 - 1];
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaSrc2DataSetId(uint64_t result, char a2)
{
  *(unsigned char *)(result + 589) = a2;
  return result;
}

BOOL ZinAneTd<8u>::SetTileDmaSrc2CompressedSize(uint64_t a1, unsigned int a2, unsigned int a3)
{
  int v7 = 0;
  if (!ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 24), &v7)) {
    ZinAssertImpl("Illegal TileDmaSrc2 Compressed Width");
  }
  *(_DWORD *)(a1 + 724) = *(_DWORD *)(a1 + 724) & 0xFFFE0000 | v7 & 0x1FFFF;
  int v6 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a3, (unsigned int *)(*(void *)(a1 + 1296) + 16), &v6);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc2 Compressed Height");
  }
  *(_DWORD *)(a1 + 728) = *(_DWORD *)(a1 + 728) & 0xFFFE0000 | v6 & 0x1FFFF;
  return result;
}

double ZinAneTd<8u>::SetTileDmaSrc2MetaData(uint64_t a1, uint64_t a2, uint64_t a3, unsigned int a4, unsigned int a5, int a6)
{
  ZinAneTdHw_v8::AddRelocInfo((uint64_t *)(a1 + 8), a2, 4946, a3, 1, 1, 0, 0);
  *(_DWORD *)(a1 + 720) &= ~8u;
  double result = COERCE_DOUBLE(__PAIR64__(a5, a4));
  *(int32x2_t *)(a1 + 676) = vsli_n_s32(*(int32x2_t *)(a1 + 676), (int32x2_t)__PAIR64__(a5, a4), 7uLL);
  *(_DWORD *)(a1 + 684) = *(_DWORD *)(a1 + 684) & 0x7F | (a6 << 7);
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaDstFormat(uint64_t result, int a2, int a3)
{
  switch(a2)
  {
    case 1:
      unsigned int v3 = *(_DWORD *)(result + 1168) & 0xFFFFCFFC | 0x1000;
      goto LABEL_16;
    case 2:
      unsigned int v3 = *(_DWORD *)(result + 1168) & 0xFFFFCFFC;
      goto LABEL_16;
    case 3:
      unsigned int v4 = *(_DWORD *)(result + 1168) & 0xFFFFCFCC;
      int v5 = 8241;
      break;
    case 4:
      unsigned int v3 = *(_DWORD *)(result + 1168) & 0xFFFFCECC | 1;
      goto LABEL_16;
    case 5:
      unsigned int v4 = *(_DWORD *)(result + 1168) & 0xFFFFCECC;
      int v5 = 257;
      break;
    case 6:
      unsigned int v4 = *(_DWORD *)(result + 1168) & 0xFFFFCECC;
      int v5 = 17;
      break;
    case 7:
      unsigned int v4 = *(_DWORD *)(result + 1168) & 0xFFFFCECC;
      int v5 = 273;
      break;
    case 8:
      ZinAssertImpl("Packed10 format not supported");
    case 9:
      unsigned int v4 = *(_DWORD *)(result + 1168) & 0xFFFFCECC;
      if (!a3) {
        goto LABEL_14;
      }
      int v5 = 4401;
      break;
    case 10:
      unsigned int v4 = *(_DWORD *)(result + 1168) & 0xFFFFCECC;
      if (a3) {
        int v5 = 305;
      }
      else {
LABEL_14:
      }
        int v5 = 8497;
      break;
    case 11:
      unsigned int v4 = *(_DWORD *)(result + 1168) & 0xFFFFFFCF;
      int v5 = 12547;
      break;
    case 12:
      ZinAssertImpl("E4M3 is not supported");
    case 13:
      ZinAssertImpl("E5M2 is not supported");
    default:
      ZinAssertImpl("Invalid format provided");
  }
  unsigned int v3 = v4 | v5;
LABEL_16:
  *(_DWORD *)(result + 1168) = v3;
  return result;
}

BOOL ZinAneTd<8u>::SetTileDmaDstandL2DstInterleave(uint64_t a1, unsigned int a2)
{
  int v6 = 0;
  unint64_t v3 = a2;
  if (!ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 584), &v6)) {
    ZinAssertImpl("Illegal L2 Result Interleave");
  }
  *(_DWORD *)(a1 + 92std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 920) & 0xFFFFF0FF | ((v6 & 0xF) << 8);
  int v5 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(v3, (unsigned int *)(*(void *)(a1 + 1296) + 584), &v5);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaDst Interleave");
  }
  *(_DWORD *)(a1 + 1168) = *(_DWORD *)(a1 + 1168) & 0xF0FFFFFF | ((v5 & 0xF) << 24);
  return result;
}

BOOL ZinAneTd<8u>::SetL2ResultInterleave(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 584), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Result Interleave");
  }
  *(_DWORD *)(a1 + 92std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 920) & 0xFFFFF0FF | ((v4 & 0xF) << 8);
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaDstandL2DstFifoMode(uint64_t result, int a2)
{
  unsigned int v2 = *(_DWORD *)(result + 920) & 0xFFFFFFF7;
  if (a2) {
    int v3 = 0x1000000;
  }
  else {
    int v3 = 0;
  }
  unsigned int v4 = *(_DWORD *)(result + 1112) & 0xFEFFFFFF | v3;
  if (a2) {
    int v5 = 8;
  }
  else {
    int v5 = 0;
  }
  *(_DWORD *)(result + 1112) = v4;
  *(_DWORD *)(result + 92std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2 | v5;
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaDstEnable(uint64_t result)
{
  *(_DWORD *)(result + 1112) |= 1u;
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaDstCacheHint(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 1112) | 0xF0;
      goto LABEL_5;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 1112) & 0xFFFFFF0F | 0x30;
      goto LABEL_5;
    case 2:
      ZinAssertImpl("Drop CacheHint not supported on Dst");
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 1112) & 0xFFFFFF0F | 0xD0;
LABEL_5:
      *(_DWORD *)(result + 1112) = v2;
      break;
    case 4:
      ZinAssertImpl("Invalid CacheHint");
    default:
      return result;
  }
  return result;
}

BOOL ZinAneTd<8u>::SetTileDmaDstChannelStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 1296) + 496), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaDst Channel Stride");
  }
  *(_DWORD *)(a1 + 11std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_DWORD *)(a1 + 1132) & 0x3F | (v4 << 6);
  return result;
}

BOOL ZinAneTd<8u>::SetTileDmaDstRowStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 1296) + 488), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaDst Row Stride");
  }
  *(_DWORD *)(a1 + 1128) = *(_DWORD *)(a1 + 1128) & 0x3F | (v4 << 6);
  return result;
}

BOOL ZinAneTd<8u>::SetTileDmaDstDepthStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 1296) + 504), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaDst Depth Stride");
  }
  *(_DWORD *)(a1 + 1136) = *(_DWORD *)(a1 + 1136) & 0x3F | (v4 << 6);
  return result;
}

BOOL ZinAneTd<8u>::SetTileDmaDstGroupStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 1296) + 512), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaDst Group Stride");
  }
  *(_DWORD *)(a1 + 114std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 1140) & 0x3F | (v4 << 6);
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaDstZeroPad(uint64_t result, _DWORD *a2)
{
  unsigned int v2 = *(_DWORD *)(result + 1168) & 0xFFDFFFFF | ((*a2 == 0) << 21);
  *(_DWORD *)(result + 1168) = v2;
  *(_DWORD *)(result + 1168) = v2 & 0xFFEFFFFF | ((a2[1] == 0) << 20);
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaDstCropOffset(uint64_t result, int a2, __int16 a3)
{
  *(_WORD *)(result + 1192) = a3;
  if (a2) {
    ZinAssertImpl("Invalid Crop Offset X for architecture");
  }
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaDstWrapStatic(uint64_t a1, unsigned __int16 a2, unsigned __int16 a3, unsigned int a4)
{
  uint64_t result = ZinAneTd<8u>::SetTileDmaDstWrapCfg(a1, a4);
  *(_DWORD *)(a1 + 1164) = a3 | (a2 << 16);
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaDstWrapCfg(uint64_t a1, unsigned int a2)
{
  if (a2 == 4) {
    ZinAssertImpl("Width wrap axis is not supported on this architecture");
  }
  uint64_t result = ZinIrCodegenGetDMAWrapCfgDim(a2);
  *(_DWORD *)(a1 + 1116) = *(_DWORD *)(a1 + 1116) & 0xFFFFF8FF | ((result & 7) << 8);
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaDstWrapDynamic(uint64_t a1, uint64_t a2, unsigned int a3)
{
  int v6 = (uint64_t *)(a1 + 8);
  std::string::basic_string[abi:ne180100]<0>(__p, &byte_211F4AA5D);
  ZinAneTdHw_v8::AddRelocInfo(v6, (uint64_t)__p, 5197, a2, 0, 0, 0, 0);
  if (v9 < 0) {
    operator delete(__p[0]);
  }
  return ZinAneTd<8u>::SetTileDmaDstWrapCfg(a1, a3);
}

void sub_2112CA0AC(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11, int a12, __int16 a13, char a14, char a15)
{
  if (a15 < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinAneTd<8u>::SetTileDmaDstFmtOffsetCh(uint64_t result, char a2)
{
  *(_DWORD *)(result + 1168) = *(_DWORD *)(result + 1168) & 0xFFF8FFFF | ((a2 & 7) << 16);
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaDstFmtCmpVec(uint64_t result, unsigned __int8 a2)
{
  *(_DWORD *)(result + 1168) = *(_DWORD *)(result + 1168) & 0xFFFFFFF | (a2 << 28);
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaDstBaseAddrLo(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return ZinAneTdHw_v8::AddRelocInfo((uint64_t *)(a1 + 8), a2, 5186, a3, 1, 1, 0, 0);
}

BOOL ZinAneTd<8u>::SetTileDmaDstCompressedSize(uint64_t a1, unsigned int a2, unsigned int a3)
{
  int v7 = 0;
  if (!ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 24), &v7)) {
    ZinAssertImpl("Illegal TileDmaDst Compressed Width");
  }
  *(_DWORD *)(a1 + 1184) = *(_DWORD *)(a1 + 1184) & 0xFFFE0000 | v7 & 0x1FFFF;
  int v6 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a3, (unsigned int *)(*(void *)(a1 + 1296) + 16), &v6);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaDst Compressed Height");
  }
  *(_DWORD *)(a1 + 1188) = *(_DWORD *)(a1 + 1188) & 0xFFFE0000 | v6 & 0x1FFFF;
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaDstCompressedInfo(uint64_t result, int a2, int a3, int a4)
{
  int v4 = *(_DWORD *)(result + 1176);
  *(_DWORD *)(result + 1176) = v4 | 1;
  switch(a4)
  {
    case 0:
      unsigned int v5 = v4 & 0xFFFFCFFE | 1;
      break;
    case 1:
      unsigned int v5 = v4 & 0xFFFFCFFE | 0x1001;
      break;
    case 2:
      unsigned int v5 = v4 & 0xFFFFCFFE | 0x2001;
      break;
    case 3:
      unsigned int v5 = v4 | 0x3001;
      break;
    default:
      ZinAssertImpl("Invalid Lossy Mode");
  }
  *(_DWORD *)(result + 1176) = v5;
  if (a3 == 2)
  {
    unsigned int v6 = v5 | 4;
  }
  else
  {
    if (a3 != 1) {
      ZinAssertImpl("Unsupported macro block size");
    }
    unsigned int v6 = v5 & 0xFFFFFFFB;
  }
  *(_DWORD *)(result + 1176) = v6;
  if ((a2 - 1) >= 0x13) {
    ZinAssertImpl("Invalid packing format");
  }
  *(_DWORD *)(result + 1176) = v6 & 0xFFFFFC0F | dword_211F04368[a2 - 1];
  return result;
}

double ZinAneTd<8u>::SetTileDmaDstMetaData(uint64_t a1, uint64_t a2, uint64_t a3, unsigned int a4, unsigned int a5, int a6)
{
  ZinAneTdHw_v8::AddRelocInfo((uint64_t *)(a1 + 8), a2, 5192, a3, 1, 1, 0, 0);
  *(_DWORD *)(a1 + 1176) &= ~8u;
  double result = COERCE_DOUBLE(__PAIR64__(a5, a4));
  *(int32x2_t *)(a1 + 1152) = vsli_n_s32(*(int32x2_t *)(a1 + 1152), (int32x2_t)__PAIR64__(a5, a4), 7uLL);
  *(_DWORD *)(a1 + 116std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 1160) & 0x7F | (a6 << 7);
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaDstNoMetaData(uint64_t result)
{
  *(_DWORD *)(result + 1176) |= 8u;
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaDstDataSetId(uint64_t result, char a2)
{
  *(unsigned char *)(result + 1113) = a2;
  return result;
}

uint64_t ZinAneTd<8u>::SetCacheDmaPreEnable(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 2;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 1204) = *(_DWORD *)(result + 1204) & 0xFFFFFFFD | v2;
  return result;
}

uint64_t ZinAneTd<8u>::SetCacheDmaPreFlush(uint64_t result, int a2, __int16 a3)
{
  *(_DWORD *)(result + 1204) = *(_DWORD *)(result + 1204) & 0xFFFFFFFE | a2;
  *(_WORD *)(result + 124std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = a3;
  return result;
}

uint64_t ZinAneTd<8u>::SetCacheDmaPreTaskSync(uint64_t result, int a2, int a3)
{
  if (a3) {
    int v3 = 4;
  }
  else {
    int v3 = 0;
  }
  if (a2) {
    int v4 = 8;
  }
  else {
    int v4 = 0;
  }
  *(_DWORD *)(result + 1204) = v3 | v4 | *(_DWORD *)(result + 1204) & 0xFFFFFFF3;
  return result;
}

uint64_t ZinAneTd<8u>::SetCacheDmaPreEarlyTermination(uint64_t result, int a2, int a3, int a4, int a5, int a6, int a7, __int16 a8, __int16 a9, __int16 a10, char a11, __int16 a12, char a13)
{
  if (a2) {
    int v13 = 16;
  }
  else {
    int v13 = 0;
  }
  if (a3) {
    int v14 = 32;
  }
  else {
    int v14 = 0;
  }
  if (a4) {
    int v15 = 64;
  }
  else {
    int v15 = 0;
  }
  if (a5) {
    int v16 = 128;
  }
  else {
    int v16 = 0;
  }
  if (a6) {
    int v17 = 256;
  }
  else {
    int v17 = 0;
  }
  *(_DWORD *)(result + 1204) = v14 | v13 | v15 | v16 | v17 | *(_DWORD *)(result + 1204) & 0xFFFFFE0F;
  if (a3)
  {
    *(_WORD *)(result + 1236) = a8;
    if (!a4)
    {
LABEL_18:
      if (!a6) {
        goto LABEL_19;
      }
      goto LABEL_23;
    }
  }
  else if (!a4)
  {
    goto LABEL_18;
  }
  *(_WORD *)(result + 1238) = a9;
  if (!a6)
  {
LABEL_19:
    if (a5) {
      goto LABEL_25;
    }
LABEL_24:
    if (!a7) {
      return result;
    }
    goto LABEL_25;
  }
LABEL_23:
  *(unsigned char *)(result + 1244) = a11;
  if ((a5 & 1) == 0) {
    goto LABEL_24;
  }
LABEL_25:
  *(unsigned char *)(result + 1246) = a13;
  return result;
}

uint64_t ZinAneTd<8u>::SetCacheDmaPreTelemetryBackOff(uint64_t result, int a2, char a3, unsigned __int8 a4, unsigned __int8 a5, int a6)
{
  unsigned int v6 = *(_DWORD *)(result + 1248) & 0xFFFFFFFE | a2;
  if (a2) {
    unsigned int v6 = (16 * (a3 & 0xF)) | (unsigned __int16)(a4 << 8) | (a5 << 16) | (a6 << 24) | *(_DWORD *)(result + 1248) & 0xE | a2 & 0xF;
  }
  *(_DWORD *)(result + 1248) = v6;
  return result;
}

uint64_t ZinAneTd<8u>::SetCacheDmaPreFootprintLimiter(uint64_t result, int a2, __int16 a3, unsigned __int16 a4)
{
  if (a2) {
    int v4 = 512;
  }
  else {
    int v4 = 0;
  }
  unsigned int v5 = *(_DWORD *)(result + 1204) & 0xFFFFFDFF | v4;
  *(_DWORD *)(result + 1204) = v5;
  if (a2)
  {
    *(_DWORD *)(result + 1204) = (unsigned __int16)v5 | (a4 << 16);
    *(_DWORD *)(result + 12std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_DWORD *)(result + 1232) & 0xF001FFFF | ((a3 & 0x7FF) << 17);
  }
  return result;
}

uint64_t ZinAneTd<8u>::SetCacheDmaPreSieveFiltering(uint64_t result, char a2, char a3)
{
  *(_DWORD *)(result + 1208) = a2 & 7 | (16 * (a3 & 0xF)) | *(_DWORD *)(result + 1208) & 0xFFFFFF08;
  return result;
}

uint64_t ZinAneTd<8u>::SetCacheDmaPreBandwidthLimit(uint64_t result, __int16 a2)
{
  *(_DWORD *)(result + 1208) = *(_DWORD *)(result + 1208) & 0xFFFE00FF | ((a2 & 0x1FF) << 8);
  return result;
}

uint64_t ZinAneTd<8u>::SetCacheDmaPreTelemetryResponseAgeOut(uint64_t result, char a2)
{
  *(_DWORD *)(result + 1208) = *(_DWORD *)(result + 1208) & 0xFF0FFFFF | ((a2 & 0xF) << 20);
  return result;
}

void ZinAneTd<8u>::SetCacheDmaPreDSIDAndSize(uint64_t a1, unsigned __int16 *a2, int a3)
{
  *(_DWORD *)(a1 + 1228) = *(_DWORD *)(a1 + 1228) & 0xC000007F | ((a3 & 0x7FFFFF) << 7);
  if (*((unsigned char *)a2 + 2))
  {
    int v4 = (uint64_t *)(a1 + 8);
    std::string::basic_string[abi:ne180100]<0>(__p, &byte_211F4AA5D);
    ZinAneTdHw_v8::AddRelocInfo(v4, (uint64_t)__p, 5698, *a2, 0, 0, 0, 0);
    if (v6 < 0) {
      operator delete(__p[0]);
    }
  }
}

void sub_2112CA564(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11, int a12, __int16 a13, char a14, char a15)
{
  if (a15 < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinAneTd<8u>::SetCacheDmaPreAddress(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return ZinAneTdHw_v8::AddRelocInfo((uint64_t *)(a1 + 8), a3, 5700, a2, 1, 1, 0, 0);
}

uint64_t ZinAneTd<8u>::SetFillLowerNEFirst(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 0x20000000;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 556) = *(_DWORD *)(result + 556) & 0xDFFFFFFF | v2;
  return result;
}

uint64_t ZinAneTd<8u>::SetArgOutputSelect(uint64_t result, int a2)
{
  if ((a2 - 6) > 5) {
    int v2 = 0x100000;
  }
  else {
    int v2 = dword_211F043B4[a2 - 6];
  }
  *(_DWORD *)(result + 1064) = *(_DWORD *)(result + 1064) & 0xFF0FFFFF | v2;
  return result;
}

uint64_t ZinAneTd<8u>::SetMaxPoolMode(uint64_t result, unsigned int a2)
{
  if (a2 <= 0xE && ((1 << a2) & 0x48E2) != 0) {
    unsigned int v2 = *(_DWORD *)(result + 1064) | 0x80000;
  }
  else {
    unsigned int v2 = *(_DWORD *)(result + 1064) & 0xFFF7FFFF;
  }
  *(_DWORD *)(result + 1064) = v2;
  return result;
}

BOOL ZinAneTd<8u>::SetKernelStrideRegisters(uint64_t a1, unsigned int a2, unsigned int a3)
{
  int v7 = 0;
  if (!ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 688), &v7)) {
    ZinAssertImpl("Illegal Kernel Group Stride");
  }
  *(_DWORD *)(a1 + 68) = *(_DWORD *)(a1 + 68) & 0x3F | (v7 << 6);
  int v6 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a3, (unsigned int *)(*(void *)(a1 + 1296) + 680), &v6);
  if (!result) {
    ZinAssertImpl("Illegal Kernel OCG Stride");
  }
  *(_DWORD *)(a1 + 72) = *(_DWORD *)(a1 + 72) & 0x3F | (v6 << 6);
  return result;
}

uint64_t ZinAneTd<8u>::SetKernelSparseBlockSize(uint64_t result, char a2)
{
  *(_DWORD *)(result + 106std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 1060) & 0xFF1FFFFF | ((a2 & 7) << 21);
  return result;
}

uint64_t ZinAneTd<8u>::SetRcasKeyMask(uint64_t result, char a2)
{
  *(unsigned char *)(result + 108std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = a2;
  return result;
}

uint64_t ZinAneTd<8u>::SetRcasMode(uint64_t result, int a2)
{
  switch(a2)
  {
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 1080) & 0xFFEFFFFF;
LABEL_7:
      *(_DWORD *)(result + 108std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2;
      return result;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 1080) | 0x100000;
      goto LABEL_7;
    case 0:
      ZinAssertImpl("Unknown RCAS Mode.\n");
  }
  return result;
}

uint64_t ZinAneTd<8u>::SetRcasSenseAxis(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 1080) | 0x3000;
      goto LABEL_6;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 1080) & 0xFFFFCFFF | 0x1000;
      goto LABEL_6;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 1080) & 0xFFFFCFFF | 0x2000;
      goto LABEL_6;
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 1080) & 0xFFFFCFFF;
LABEL_6:
      *(_DWORD *)(result + 108std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2;
      break;
    case 4:
    case 5:
      ZinAssertImpl("Unknown RCAS Sense Axis.\n");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<8u>::SetRcasSenseBit(uint64_t result, char a2)
{
  *(_DWORD *)(result + 108std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 1080) & 0xFFF0FFFF | ((a2 & 0xF) << 16);
  return result;
}

uint64_t ZinAneTd<8u>::SetRcasCmpBit(uint64_t result, char a2)
{
  *(_DWORD *)(result + 108std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 1080) & 0xFFFFF8FF | ((a2 & 7) << 8);
  return result;
}

uint64_t ZinAneTd<8u>::SetGroupKernelReuse(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 1024;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 106std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 1060) & 0xFFFFFBFF | v2;
  if (a2) {
    int v3 = 16;
  }
  else {
    int v3 = 0;
  }
  *(_DWORD *)(result + 44) = *(_DWORD *)(result + 44) & 0xFFFFFFEF | v3;
  return result;
}

uint64_t ZinAneTd<8u>::SetKernelSparseFmt(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 256;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 106std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 1060) & 0xFFFFFEFF | v2;
  if (a2) {
    int v3 = 32;
  }
  else {
    int v3 = 0;
  }
  *(_DWORD *)(result + 44) = *(_DWORD *)(result + 44) & 0xFFFFFFDF | v3;
  return result;
}

uint64_t ZinAneTd<8u>::SetKernelSparseBinary(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 0x8000;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 106std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 1060) & 0xFFFF7FFF | v2;
  return result;
}

uint64_t ZinAneTd<8u>::SetKernelPalettizedEn(uint64_t result, int a2)
{
  int v2 = 0;
  switch(a2)
  {
    case 0:
    case 3:
    case 28:
    case 29:
    case 30:
    case 31:
    case 32:
      ZinAssertImpl("Unknown kernel format in codegen\n");
    case 7:
    case 8:
    case 9:
    case 10:
    case 11:
    case 12:
    case 13:
    case 14:
    case 19:
    case 20:
    case 21:
    case 22:
    case 23:
    case 24:
    case 25:
    case 26:
    case 27:
      int v2 = 4;
      break;
    case 15:
    case 16:
    case 17:
    case 18:
      ZinAssertImpl("Invalid kernel format");
    default:
      break;
  }
  *(_DWORD *)(result + 106std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 1060) & 0xFFFFFFFB | v2;
  return result;
}

uint64_t ZinAneTd<8u>::SetKernelPalettizedBits(uint64_t result, int a2)
{
  int v2 = 128;
  switch(a2)
  {
    case 0:
    case 3:
    case 28:
    case 29:
    case 30:
    case 31:
    case 32:
      ZinAssertImpl("Unknown kernel format in codegen\n");
    case 7:
    case 8:
    case 9:
    case 10:
      int v2 = 16;
      break;
    case 11:
    case 12:
    case 13:
    case 14:
      int v2 = 32;
      break;
    case 15:
    case 16:
    case 17:
    case 18:
      ZinAssertImpl("Invalid kernel format");
    case 19:
    case 20:
    case 21:
    case 22:
      int v2 = 64;
      break;
    case 23:
    case 24:
    case 25:
    case 26:
      int v2 = 96;
      break;
    default:
      break;
  }
  *(_DWORD *)(result + 106std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 1060) & 0xFFFFFF0F | v2;
  return result;
}

uint64_t ZinAneTd<8u>::SetStochasticRoundMode(uint64_t result, int a2)
{
  if (a2 != 1 && a2 != 2)
  {
    if (!a2) {
      ZinAssertImpl("Invalid stochastic rounding mode");
    }
    a2 = 0;
  }
  *(_DWORD *)(result + 1084) = *(_DWORD *)(result + 1084) & 0xFFFFFFFC | a2;
  return result;
}

uint64_t ZinAneTd<8u>::SetStochasticRoundSeed(uint64_t result, int a2, uint64_t a3)
{
  *(_DWORD *)(result + 4 * a3 + 1088) = a2;
  return result;
}

uint64_t ZinAneTd<8u>::SetStochasticRoundIntegerBits(uint64_t result, char a2)
{
  *(_DWORD *)(result + 1084) = *(_DWORD *)(result + 1084) & 0xFFFFFE0F | (16 * (a2 & 0x1F));
  return result;
}

uint64_t ZinAneTd<8u>::SetNEBinaryPoint(uint64_t result, char a2)
{
  *(_DWORD *)(result + 1064) = *(_DWORD *)(result + 1064) & 0xFFFFE0FF | ((a2 & 0x1F) << 8);
  return result;
}

uint64_t ZinAneTd<8u>::SetNENonLinearMode(uint64_t result, int a2, uint64_t a3)
{
  if (a2)
  {
    if (a2 == 1)
    {
      a2 = 0x10000;
    }
    else
    {
      int v4 = *(_DWORD **)a3;
      int v3 = *(_DWORD **)(a3 + 8);
      if (*(_DWORD **)a3 != v3)
      {
        while (*v4 != a2)
        {
          if (++v4 == v3)
          {
            int v4 = *(_DWORD **)(a3 + 8);
            break;
          }
        }
      }
      if (v4 == v3) {
        ZinAssertImpl("Error: illegal non-linear mode\n");
      }
      a2 = 0x20000;
    }
  }
  *(_DWORD *)(result + 1064) = *(_DWORD *)(result + 1064) & 0xFFFCFFFF | a2;
  return result;
}

uint64_t ZinAneTd<8u>::SetNEPostScale(uint64_t result, unint64_t a2, char a3)
{
  _S0 = a2;
  __asm { FCVT            H0, S0 }
  int v8 = _S0;
  if (!_ZF) {
    int v8 = 0;
  }
  int v9 = ((a2 & 0xFF0000000000) != 0) << 14;
  int v10 = -((a2 >> 16) & 0x1F0000) & 0x1F0000 | v8;
  if (!a3)
  {
    int v9 = 0;
    int v10 = 15360;
  }
  *(_DWORD *)(result + 1064) = *(_DWORD *)(result + 1064) & 0xFFFFBFFF | v9;
  *(_DWORD *)(result + 1076) = v10 | *(_DWORD *)(result + 1076) & 0xFFE00000;
  return result;
}

uint64_t ZinAneTd<8u>::SetNEBias(uint64_t result, unint64_t a2, char a3)
{
  _S0 = a2;
  __asm { FCVT            H0, S0 }
  int v8 = _S0;
  if (!_ZF) {
    int v8 = 0;
  }
  int v9 = 16 * ((a2 & 0xFF0000000000) != 0);
  int v10 = (a2 >> 16) & 0x1F0000 | v8;
  if (!a3)
  {
    int v9 = 0;
    int v10 = 0;
  }
  *(_DWORD *)(result + 1064) = *(_DWORD *)(result + 1064) & 0xFFFFFFEF | v9;
  *(_DWORD *)(result + 1072) = v10 | *(_DWORD *)(result + 1072) & 0xFFE00000;
  return result;
}

ZinIrKernel *ZinAneTd<8u>::SetNEMatrixVectorBias(uint64_t a1, ZinIrKernel **a2, uint64_t a3)
{
  BOOL result = *a2;
  if (*a2) {
    _ZF = (a3 & 0xFF00000000) == 0;
  }
  else {
    _ZF = 1;
  }
  if (_ZF)
  {
    int v6 = 0;
  }
  else
  {
    _S8 = *(float *)&a3;
    BOOL result = (ZinIrKernel *)ZinIrKernel::GetWeightFormat(result);
    if (result == 4)
    {
      __asm { FCVT            H0, S8 }
      LOWORD(v8) = _H0;
    }
    else
    {
      if (result != 2 && result != 1) {
        ZinAssertImpl("Error: Invalid kernel format");
      }
      int v8 = (int)_S8;
    }
    *(_WORD *)(a1 + 1068) = v8;
    int v6 = 64;
  }
  *(_DWORD *)(a1 + 1064) = *(_DWORD *)(a1 + 1064) & 0xFFFFFFBF | v6;
  return result;
}

uint64_t ZinAneTd<8u>::SetNEOcgSize(uint64_t result, char a2)
{
  *(_DWORD *)(result + 528) = *(_DWORD *)(result + 528) & 0xFFFFFFF8 | a2 & 7;
  return result;
}

uint64_t ZinAneTd<8u>::SetOutputTranspose(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 0x10000000;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 556) = *(_DWORD *)(result + 556) & 0xEFFFFFFF | v2;
  return result;
}

uint64_t ZinAneTd<8u>::SetNESmallSourceMode(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 556) & 0xFFFFFFF3;
      goto LABEL_6;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 556) & 0xFFFFFFF3 | 4;
      goto LABEL_6;
    case 2:
      ZinAssertImpl("Error: Tiny source mode is not supported for this arch");
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 556) | 0xC;
      goto LABEL_6;
    case 4:
      unsigned int v2 = *(_DWORD *)(result + 556) & 0xFFFFFFF3 | 8;
LABEL_6:
      *(_DWORD *)(result + 556) = v2;
      break;
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<8u>::GetNESmallSourceMode(uint64_t a1)
{
  return *(unsigned int *)((char *)&unk_211ED50F0 + (*(_DWORD *)(a1 + 556) & 0xC));
}

uint64_t ZinAneTd<8u>::SetTileDmaSrcDma1UserTag(uint64_t result, char a2)
{
  *(unsigned char *)(result + 586) = a2;
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaSrcDma2UserTag(uint64_t result, char a2)
{
  *(unsigned char *)(result + 59std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = a2;
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaSrcCompressedMdUserTag(uint64_t result, char a2)
{
  *(unsigned char *)(result + 707) = a2;
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaSrcCompressed2MdUserTag(uint64_t result, char a2)
{
  *(unsigned char *)(result + 723) = a2;
  return result;
}

uint64_t ZinAneTd<8u>::SetTileDmaDstUserTag(uint64_t result, char a2)
{
  *(unsigned char *)(result + 1114) = a2;
  return result;
}

uint64_t ZinAneTd<8u>::SetKernelDmaSrcCoeffUserTag(uint64_t result, unsigned __int8 a2)
{
  uint64_t v2 = 0;
  int8x16_t v3 = (int8x16_t)vdupq_n_s32(a2 << 16);
  do
  {
    *(int8x16_t *)(result + 76 + v2) = vorrq_s8((int8x16_t)(*(_OWORD *)(result + 76 + v2) & __PAIR128__(0xFF00FFFFFF00FFFFLL, 0xFF00FFFFFF00FFFFLL)), v3);
    v2 += 16;
  }
  while (v2 != 64);
  return result;
}

uint64_t ZinAneTd<8u>::SetCachePrefetchDmaUserTag(uint64_t result, char a2)
{
  *(unsigned char *)(result + 1214) = a2;
  return result;
}

uint64_t ZinAneTd<8u>::SetKernelDmaSrcPostScaleUserTag(uint64_t result, char a2)
{
  *(unsigned char *)(result + 286) = a2;
  return result;
}

uint64_t ZinAneTd<8u>::SetKernelDmaSrcPaletteLutUserTag(uint64_t result, char a2)
{
  *(unsigned char *)(result + 302) = a2;
  return result;
}

uint64_t ZinAneTd<8u>::SetKernelDmaSrcBiasUserTag(uint64_t result, char a2)
{
  *(unsigned char *)(result + 27std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = a2;
  return result;
}

uint64_t ZinAneTd<8u>::SetKernelDmaSrcNonLinearLutUserTag(uint64_t result, char a2)
{
  *(unsigned char *)(result + 318) = a2;
  return result;
}

uint64_t ZinAneTd<8u>::SetCommonTaskType(uint64_t result, unsigned int a2)
{
  if (a2 <= 7) {
    *(_DWORD *)(result + 556) = *(_DWORD *)(result + 556) & 0xFFFFFF0F | dword_211F043CC[a2];
  }
  return result;
}

uint64_t ZinAneTd<8u>::SetCommonInFmt(uint64_t result, int a2)
{
  if (a2 > 2)
  {
    if (a2 == 3)
    {
      unsigned int v2 = *(_DWORD *)(result + 508) & 0xFFFFFFFC | 2;
      goto LABEL_8;
    }
    if (a2 == 12) {
      ZinAssertImpl("Error: Invalid Common InFmt E4M3");
    }
LABEL_11:
    ZinAssertImpl("Error: Invalid TD programming for Src1 input format");
  }
  if (a2 == 1)
  {
    unsigned int v2 = *(_DWORD *)(result + 508) & 0xFFFFFFFC | 1;
    goto LABEL_8;
  }
  if (a2 != 2) {
    goto LABEL_11;
  }
  unsigned int v2 = *(_DWORD *)(result + 508) & 0xFFFFFFFC;
LABEL_8:
  *(_DWORD *)(result + 508) = v2;
  return result;
}

uint64_t ZinAneTd<8u>::SetCommonSrc2InFmt(uint64_t result, int a2)
{
  if (a2 > 2)
  {
    if (a2 == 3)
    {
      unsigned int v2 = *(_DWORD *)(result + 508) & 0xFFFFFFF3 | 8;
      goto LABEL_8;
    }
    if (a2 == 12) {
      ZinAssertImpl("Error: Invalid TD programming for Src2 input format: E4M3");
    }
LABEL_11:
    ZinAssertImpl("Error: Invalid TD programming for Src2 input format");
  }
  if (a2 == 1)
  {
    unsigned int v2 = *(_DWORD *)(result + 508) & 0xFFFFFFF3 | 4;
    goto LABEL_8;
  }
  if (a2 != 2) {
    goto LABEL_11;
  }
  unsigned int v2 = *(_DWORD *)(result + 508) & 0xFFFFFFF3;
LABEL_8:
  *(_DWORD *)(result + 508) = v2;
  return result;
}

uint64_t ZinAneTd<8u>::SetCommonOutFmt(uint64_t result, int a2)
{
  if ((a2 - 3) < 9) {
    goto LABEL_2;
  }
  if (a2 <= 11)
  {
    if (a2 == 1)
    {
      unsigned int v2 = *(_DWORD *)(result + 508) & 0xFFFFFFCF | 0x10;
      goto LABEL_3;
    }
    if (a2 == 2)
    {
      unsigned int v2 = *(_DWORD *)(result + 508) & 0xFFFFFFCF;
      goto LABEL_3;
    }
LABEL_12:
    ZinAssertImpl("Error: Invalid output format");
  }
  if (a2 != 13)
  {
    if (a2 == 12) {
      ZinAssertImpl("Error: E4M3 is not supported");
    }
    goto LABEL_12;
  }
LABEL_2:
  unsigned int v2 = *(_DWORD *)(result + 508) & 0xFFFFFFCF | 0x20;
LABEL_3:
  *(_DWORD *)(result + 508) = v2;
  return result;
}

BOOL ZinAneTd<8u>::SetPatchHeight(uint64_t a1, unint64_t a2)
{
  *(_DWORD *)(a1 + 548) = *(_DWORD *)(a1 + 548) & 0xFFFFFF0F | (16 * (a2 & 0xF));
  return CheckRegValueRange(a2, (unsigned int *)(*(void *)(a1 + 1296) + 288));
}

BOOL ZinAneTd<8u>::SetPatchWidth(uint64_t a1, unint64_t a2)
{
  *(_DWORD *)(a1 + 548) = *(_DWORD *)(a1 + 548) & 0xFFFFFFF0 | a2 & 0xF;
  return CheckRegValueRange(a2, (unsigned int *)(*(void *)(a1 + 1296) + 280));
}

BOOL ZinAneTd<8u>::SetTileHeight(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 200), &v4);
  if (result) {
    *(_DWORD *)(a1 + 544) = *(_DWORD *)(a1 + 544) & 0xFFFF8000 | v4 & 0x7FFF;
  }
  return result;
}

BOOL ZinAneTd<8u>::SetTileOverlap(uint64_t a1, unint64_t a2)
{
  *(_DWORD *)(a1 + 544) = *(_DWORD *)(a1 + 544) & 0xFFE0FFFF | ((a2 & 0x1F) << 16);
  return CheckRegValueRange(a2, (unsigned int *)(*(void *)(a1 + 1296) + 216));
}

BOOL ZinAneTd<8u>::SetTileOverlapPadBottom(uint64_t a1, unint64_t a2)
{
  *(_DWORD *)(a1 + 544) = *(_DWORD *)(a1 + 544) & 0x83FFFFFF | ((a2 & 0x1F) << 26);
  return CheckRegValueRange(a2, (unsigned int *)(*(void *)(a1 + 1296) + 224));
}

BOOL ZinAneTd<8u>::SetTileOverlapPadTop(uint64_t a1, unint64_t a2)
{
  *(_DWORD *)(a1 + 544) = *(_DWORD *)(a1 + 544) & 0xFC1FFFFF | ((a2 & 0x1F) << 21);
  return CheckRegValueRange(a2, (unsigned int *)(*(void *)(a1 + 1296) + 208));
}

BOOL ZinAneTd<8u>::SetCommonConvCfgKh(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 128), &v4);
  if (result) {
    *(_DWORD *)(a1 + 5std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_DWORD *)(a1 + 532) & 0xFFFFF03F | ((v4 & 0x3F) << 6);
  }
  return result;
}

BOOL ZinAneTd<8u>::SetCommonConvCfgKw(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 136), &v4);
  if (result) {
    *(_DWORD *)(a1 + 5std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_DWORD *)(a1 + 532) & 0xFFFFFFC0 | v4 & 0x3F;
  }
  return result;
}

BOOL ZinAneTd<8u>::SetCommonConvCfg3dKd(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 168), &v4);
  if (result) {
    *(_DWORD *)(a1 + 536) = *(_DWORD *)(a1 + 536) & 0xFFFFFFE0 | v4 & 0x1F;
  }
  return result;
}

BOOL ZinAneTd<8u>::SetCommonConvCfgSx(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 120), &v4);
  if (result) {
    *(_DWORD *)(a1 + 5std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_DWORD *)(a1 + 532) & 0xFFFF9FFF | ((v4 & 3) << 13);
  }
  return result;
}

BOOL ZinAneTd<8u>::SetCommonConvCfgSy(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 112), &v4);
  if (result) {
    *(_DWORD *)(a1 + 5std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_DWORD *)(a1 + 532) & 0xFFFE7FFF | ((v4 & 3) << 15);
  }
  return result;
}

BOOL ZinAneTd<8u>::SetCommonConvCfg3dSz(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 144), &v4);
  if (result) {
    *(_DWORD *)(a1 + 536) = *(_DWORD *)(a1 + 536) & 0xFFFFFF3F | ((v4 & 3) << 6);
  }
  return result;
}

BOOL ZinAneTd<8u>::SetCommonConvCfgOx(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 88), &v4);
  if (result) {
    *(_DWORD *)(a1 + 5std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_DWORD *)(a1 + 532) & 0xCFFFFFFF | ((v4 & 3) << 28);
  }
  return result;
}

BOOL ZinAneTd<8u>::SetCommonConvCfgOy(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 80), &v4);
  if (result) {
    *(_DWORD *)(a1 + 5std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_DWORD *)(a1 + 532) & 0x3FFFFFFF | (v4 << 30);
  }
  return result;
}

BOOL ZinAneTd<8u>::SetCommonConvCfg3dOz(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 160), &v4);
  if (result) {
    *(_DWORD *)(a1 + 536) = *(_DWORD *)(a1 + 536) & 0xFFFF9FFF | ((v4 & 3) << 13);
  }
  return result;
}

BOOL ZinAneTd<8u>::SetCommonConvCfgPadLeft(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 104), &v4);
  if (result) {
    *(_DWORD *)(a1 + 5std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_DWORD *)(a1 + 532) & 0xFFC1FFFF | ((v4 & 0x1F) << 17);
  }
  return result;
}

BOOL ZinAneTd<8u>::SetCommonConvCfgPadTop(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 96), &v4);
  if (result) {
    *(_DWORD *)(a1 + 5std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_DWORD *)(a1 + 532) & 0xF83FFFFF | ((v4 & 0x1F) << 22);
  }
  return result;
}

BOOL ZinAneTd<8u>::SetCommonConvCfg3dPz(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 152), &v4);
  if (result) {
    *(_DWORD *)(a1 + 536) = *(_DWORD *)(a1 + 536) & 0xFFFFF0FF | ((v4 & 0xF) << 8);
  }
  return result;
}

BOOL ZinAneTd<8u>::SetOrReturnNumGroups(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 184), &v4);
  if (result) {
    *(_DWORD *)(a1 + 54std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 540) & 0xFFFFE000 | v4 & 0x1FFF;
  }
  return result;
}

BOOL ZinAneTd<8u>::SetOrReturnWin(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 24), &v4);
  if (result) {
    *(_DWORD *)(a1 + 50std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 500) & 0xFFFF8000 | v4 & 0x7FFF;
  }
  return result;
}

BOOL ZinAneTd<8u>::SetOrReturnHin(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 16), &v4);
  if (result) {
    *(_DWORD *)(a1 + 50std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 500) & 0x8000FFFF | ((v4 & 0x7FFF) << 16);
  }
  return result;
}

BOOL ZinAneTd<8u>::SetOrReturnDin(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 32), &v4);
  if (result) {
    *(_DWORD *)(a1 + 504) = *(_DWORD *)(a1 + 504) & 0xFFFF8000 | v4 & 0x7FFF;
  }
  return result;
}

BOOL ZinAneTd<8u>::SetOrReturnCin(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 40), &v4);
  if (result) {
    *(_DWORD *)(a1 + 512) = *(_DWORD *)(a1 + 512) & 0xFFFE0000 | v4 & 0x1FFFF;
  }
  return result;
}

BOOL ZinAneTd<8u>::SetOrReturnWout(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 64), &v4);
  if (result) {
    *(_DWORD *)(a1 + 52std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 520) & 0xFFFF8000 | v4 & 0x7FFF;
  }
  return result;
}

BOOL ZinAneTd<8u>::SetOrReturnHout(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 56), &v4);
  if (result) {
    *(_DWORD *)(a1 + 52std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 520) & 0x8000FFFF | ((v4 & 0x7FFF) << 16);
  }
  return result;
}

BOOL ZinAneTd<8u>::SetOrReturnDout(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 72), &v4);
  if (result) {
    *(_DWORD *)(a1 + 524) = *(_DWORD *)(a1 + 524) & 0xFFFF8000 | v4 & 0x7FFF;
  }
  return result;
}

BOOL ZinAneTd<8u>::SetOrReturnCout(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 48), &v4);
  if (result) {
    *(_DWORD *)(a1 + 516) = *(_DWORD *)(a1 + 516) & 0xFFFE0000 | v4 & 0x1FFFF;
  }
  return result;
}

uint64_t ZinAneTd<8u>::SetUnicastEn(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 0x4000;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 54std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 540) & 0xFFFFBFFF | v2;
  return result;
}

BOOL ZinAneTd<8u>::SetUnicastCin(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1296) + 192), &v4);
  if (result) {
    *(_WORD *)(a1 + 542) = v4;
  }
  return result;
}

uint64_t ZinAneTd<10u>::SetWARdmaDependency(uint64_t result, uint64_t a2, int a3, unsigned __int8 a4, int **a5)
{
  if (!*(unsigned char *)(a2 + 1323)) {
    ZinAssertImpl("inconsistent WAR support");
  }
  if (a3)
  {
    unsigned int v5 = *a5;
    int v6 = a5[1];
    if (*a5 != v6)
    {
      do
      {
        uint64_t v7 = *v5;
        if (v7 <= 2) {
          *(_DWORD *)(result + 868) |= dword_211F0435C[v7];
        }
        ++v5;
      }
      while (v5 != v6);
    }
    *(_DWORD *)(result + 868) = *(_DWORD *)(result + 868) & 0x7FFFFFF | (a4 << 27);
  }
  return result;
}

uint64_t ZinAneTd<10u>::SetL2Barrier(uint64_t result)
{
  *(_DWORD *)(result + 308) |= 0x800000u;
  return result;
}

uint64_t ZinAneTd<10u>::SetEventFlags(uint64_t result, int a2, int a3, int a4)
{
  *(_DWORD *)(result + 16) = *(_DWORD *)(result + 16) & 0xFC000000 | a2 & 0x3FFFFFF;
  if (a4) {
    ZinAssertImpl("DRAM Events not supported for architecture");
  }
  *(_DWORD *)(result + 24) = *(_DWORD *)(result + 24) & 0xFC000000 | a3 & 0x3FFFFFF;
  return result;
}

BOOL ZinAneTd<10u>::SetL2SrcBaseAddress(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 296), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src Base Address");
  }
  *(_DWORD *)(a1 + 6std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_DWORD *)(a1 + 632) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<10u>::SetL2Src1ChannelStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x11uLL, (unsigned int *)(*(void *)(a1 + 992) + 304), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src Channel Stride");
  }
  *(_DWORD *)(a1 + 636) = *(_DWORD *)(a1 + 636) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<10u>::SetL2SrcRowStride(uint64_t a1, ZinCodegen *this, ZinTensorDimensions *a3, uint64_t a4, uint64_t *a5)
{
  int v8 = 0;
  ZinCodegen::GetL2RowStride(this, a3, *(unsigned int *)(*(void *)(a1 + 992) + 316), &v8, a5);
  unsigned int v7 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(v8, 0x11uLL, (unsigned int *)(*(void *)(a1 + 992) + 312), &v7);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src Row Stride");
  }
  *(_DWORD *)(a1 + 64std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 640) & 0xFFE0000F | (16 * (v7 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<10u>::SetL2Src1DepthStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x11uLL, (unsigned int *)(*(void *)(a1 + 992) + 320), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src Depth Stride");
  }
  *(_DWORD *)(a1 + 644) = *(_DWORD *)(a1 + 644) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<10u>::SetL2Src1GroupStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x11uLL, (unsigned int *)(*(void *)(a1 + 992) + 328), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src Group Stride");
  }
  *(_DWORD *)(a1 + 648) = *(_DWORD *)(a1 + 648) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

uint64_t ZinAneTd<10u>::SetL2Src1DmaFormat(uint64_t result, int a2)
{
  switch(a2)
  {
    case 1:
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 624) & 0xFFFFFF3F;
      break;
    case 3:
    case 4:
    case 5:
    case 6:
    case 7:
    case 9:
    case 10:
      unsigned int v2 = *(_DWORD *)(result + 624) & 0xFFFFFF3F | 0x40;
      break;
    case 8:
      ZinAssertImpl("Packed10 format not fully implemented yet\n");
    case 11:
      unsigned int v2 = *(_DWORD *)(result + 624) | 0xC0;
      break;
    case 12:
    case 13:
      ZinAssertImpl("E4M3 or E5M2 format not supported");
    default:
      ZinAssertImpl("Invalid Dma Format");
  }
  *(_DWORD *)(result + 624) = v2;
  return result;
}

uint64_t ZinAneTd<10u>::SetL2Src2DmaFormat(uint64_t result, int a2)
{
  switch(a2)
  {
    case 1:
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 628) & 0xFFFFFF3F;
      break;
    case 3:
    case 4:
    case 5:
    case 6:
    case 7:
    case 9:
    case 10:
      unsigned int v2 = *(_DWORD *)(result + 628) & 0xFFFFFF3F | 0x40;
      break;
    case 8:
      ZinAssertImpl("Packed10 format not fully implemented yet\n");
    case 11:
      unsigned int v2 = *(_DWORD *)(result + 628) | 0xC0;
      break;
    case 12:
    case 13:
      ZinAssertImpl("E4M3 or E5M2 format not supported");
    default:
      ZinAssertImpl("Invalid Dma Format");
  }
  *(_DWORD *)(result + 628) = v2;
  return result;
}

uint64_t ZinAneTd<10u>::SetL2ResultCfgDmaFmt(uint64_t result, int a2)
{
  switch(a2)
  {
    case 1:
    case 2:
    case 12:
    case 13:
      unsigned int v2 = *(_DWORD *)(result + 672) & 0xFFFFFF3F;
      break;
    case 3:
    case 4:
    case 5:
    case 6:
    case 7:
    case 9:
    case 10:
      unsigned int v2 = *(_DWORD *)(result + 672) & 0xFFFFFF3F | 0x40;
      break;
    case 8:
      ZinAssertImpl("packed10 format not fully implemented yet");
    case 11:
      unsigned int v2 = *(_DWORD *)(result + 672) | 0xC0;
      break;
    default:
      ZinAssertImpl("Invalid tensor format");
  }
  *(_DWORD *)(result + 672) = v2;
  return result;
}

uint64_t ZinAneTd<10u>::SetL2ResultWrapCfg(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 700) & 0xFFFFF8FF | 0x400;
      goto LABEL_7;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 700) & 0xFFFFF8FF | 0x300;
      goto LABEL_7;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 700) & 0xFFFFF8FF | 0x100;
      goto LABEL_7;
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 700) & 0xFFFFF8FF | 0x200;
      goto LABEL_7;
    case 4:
      ZinAssertImpl("Error: Invalid Wrap Axis");
    case 5:
      unsigned int v2 = *(_DWORD *)(result + 700) & 0xFFFFF8FF;
LABEL_7:
      *(_DWORD *)(result + 70std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2;
      break;
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<10u>::SetL2ResultWrapStartOffset(uint64_t result, __int16 a2)
{
  *(_WORD *)(result + 714) = a2;
  return result;
}

uint64_t ZinAneTd<10u>::SetL2ResultWrapIndex(uint64_t result, __int16 a2)
{
  *(_WORD *)(result + 712) = a2;
  return result;
}

uint64_t ZinAneTd<10u>::SetL2ResultWrapAddrOffset(uint64_t result, __int16 a2)
{
  *(_DWORD *)(result + 736) = *(_DWORD *)(result + 736) & 0xF800FFFF | ((a2 & 0x7FF) << 16);
  return result;
}

uint64_t ZinAneTd<10u>::SetL2ResultWrapAddr(uint64_t result, __int16 a2)
{
  *(_DWORD *)(result + 736) = *(_DWORD *)(result + 736) & 0xFFFFF000 | a2 & 0xFFF;
  return result;
}

uint64_t ZinAneTd<10u>::SetL2SrcOffsetYlsbsFromCropOffsetY(uint64_t a1)
{
  uint64_t result = ZinExtractLSBs(*(unsigned __int16 *)(a1 + 468), 5);
  *(_DWORD *)(a1 + 624) = *(_DWORD *)(a1 + 624) & 0x7FFFFFF | (result << 27);
  return result;
}

uint64_t ZinAneTd<10u>::SetSourceAddrWrap(uint64_t result, __int16 a2, __int16 a3)
{
  *(_DWORD *)(result + 728) = a3 & 0xFFF | ((a2 & 0x7FF) << 16) | *(_DWORD *)(result + 728) & 0xF800F000;
  return result;
}

uint64_t ZinAneTd<10u>::SetSourceWrap(uint64_t result, unsigned int a2, unsigned __int16 a3, unsigned __int16 a4)
{
  if (a2 >= 4) {
    ZinAssertImpl("Source wrapping dimension not acceptable\n");
  }
  *(_DWORD *)(result + 70std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 700) & 0xFFFFFFF8 | dword_211F04410[a2];
  *(_DWORD *)(result + 704) = a4 | (a3 << 16);
  return result;
}

BOOL ZinAneTd<10u>::SetL2Src1Interleave(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 584), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Source Interleave");
  }
  *(_DWORD *)(a1 + 624) = *(_DWORD *)(a1 + 624) & 0xFFFFF0FF | ((v4 & 0xF) << 8);
  return result;
}

uint64_t ZinAneTd<10u>::SetL2Src1SourceType(uint64_t result, int a2)
{
  int v2 = 0;
  switch(a2)
  {
    case 0:
      ZinAssertImpl("Error: It must have a valid L2 access mode");
    case 1:
      int v2 = 2;
      break;
    case 2:
      int v2 = 1;
      break;
    case 4:
      int v2 = 3;
      break;
    default:
      break;
  }
  *(_DWORD *)(result + 624) = *(_DWORD *)(result + 624) & 0xFFFFFFFC | v2;
  return result;
}

uint64_t ZinAneTd<10u>::SetL2Src2SourceType(uint64_t result, int a2)
{
  int v2 = 0;
  switch(a2)
  {
    case 0:
      ZinAssertImpl("Error: It must have a valid L2 access mode");
    case 1:
      int v2 = 2;
      break;
    case 2:
      int v2 = 1;
      break;
    case 4:
      int v2 = 3;
      break;
    default:
      break;
  }
  *(_DWORD *)(result + 628) = *(_DWORD *)(result + 628) & 0xFFFFFFFC | v2;
  return result;
}

BOOL ZinAneTd<10u>::SetL2Src2BaseAddress(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 336), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src2 Base Address");
  }
  *(_DWORD *)(a1 + 652) = *(_DWORD *)(a1 + 652) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<10u>::SetL2Src2ChannelStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x11uLL, (unsigned int *)(*(void *)(a1 + 992) + 344), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Source 2 Channel Stride");
  }
  *(_DWORD *)(a1 + 656) = *(_DWORD *)(a1 + 656) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<10u>::SetL2Src2RowStride(uint64_t a1, ZinCodegen *this, ZinTensorDimensions *a3, uint64_t a4, uint64_t *a5)
{
  int v8 = 0;
  ZinCodegen::GetL2RowStride(this, a3, *(unsigned int *)(*(void *)(a1 + 992) + 356), &v8, a5);
  unsigned int v7 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(v8, 0x11uLL, (unsigned int *)(*(void *)(a1 + 992) + 352), &v7);
  if (!result) {
    ZinAssertImpl("Illegal L2 Source 2 Row Stride");
  }
  *(_DWORD *)(a1 + 66std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 660) & 0xFFE0000F | (16 * (v7 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<10u>::SetL2Src2DepthStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x11uLL, (unsigned int *)(*(void *)(a1 + 992) + 360), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Source 2 Depth Stride");
  }
  *(_DWORD *)(a1 + 664) = *(_DWORD *)(a1 + 664) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<10u>::SetL2Src2GroupStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x11uLL, (unsigned int *)(*(void *)(a1 + 992) + 368), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Source 2 Group Stride");
  }
  *(_DWORD *)(a1 + 668) = *(_DWORD *)(a1 + 668) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

uint64_t ZinAneTd<10u>::SetL2Src2OffsetYlsbsFromCropOffsetY(uint64_t a1)
{
  uint64_t result = ZinExtractLSBs(*(unsigned __int16 *)(a1 + 484), 5);
  *(_DWORD *)(a1 + 628) = *(_DWORD *)(a1 + 628) & 0x7FFFFFF | (result << 27);
  return result;
}

uint64_t ZinAneTd<10u>::SetL2Src1CfgForCompression(uint64_t result, int a2)
{
  unsigned int v2 = *(_DWORD *)(result + 624) & 0xFDF80FFF;
  *(_DWORD *)(result + 624) = v2 | 0x2000000;
  switch(a2)
  {
    case 1:
      unsigned int v3 = v2 & 0xF9F80FFF | 0x2000000;
LABEL_7:
      *(_DWORD *)(result + 624) = v3;
      return result;
    case 2:
      unsigned int v3 = v2 | 0x6000000;
      goto LABEL_7;
    case 0:
      ZinAssertImpl("Invalid macro block size");
  }
  return result;
}

uint64_t ZinAneTd<10u>::SetL2Src2CfgForCompression(uint64_t result, int a2)
{
  unsigned int v2 = *(_DWORD *)(result + 628) & 0xFDF80FFF;
  *(_DWORD *)(result + 628) = v2 | 0x2000000;
  switch(a2)
  {
    case 1:
      unsigned int v3 = v2 & 0xF9F80FFF | 0x2000000;
LABEL_7:
      *(_DWORD *)(result + 628) = v3;
      return result;
    case 2:
      unsigned int v3 = v2 | 0x6000000;
      goto LABEL_7;
    case 0:
      ZinAssertImpl("Invalid macro block size");
  }
  return result;
}

uint64_t ZinAneTd<10u>::SetL2ResultCfgForCompression(uint64_t result, int a2)
{
  unsigned int v2 = *(_DWORD *)(result + 672) & 0xFDF80FFF;
  *(_DWORD *)(result + 672) = v2 | 0x2000000;
  switch(a2)
  {
    case 1:
      unsigned int v3 = v2 & 0xF9F80FFF | 0x2000000;
LABEL_7:
      *(_DWORD *)(result + 672) = v3;
      return result;
    case 2:
      unsigned int v3 = v2 | 0x6000000;
      goto LABEL_7;
    case 0:
      ZinAssertImpl("Invalid macro block size");
  }
  return result;
}

uint64_t ZinAneTd<10u>::SetSource2AddrWrap(uint64_t result, __int16 a2, __int16 a3)
{
  *(_DWORD *)(result + 7std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = a3 & 0xFFF | ((a2 & 0x7FF) << 16) | *(_DWORD *)(result + 732) & 0xF800F000;
  return result;
}

uint64_t ZinAneTd<10u>::SetSource2Wrap(uint64_t result, unsigned int a2, unsigned __int16 a3, unsigned __int16 a4)
{
  if (a2 >= 4) {
    ZinAssertImpl("Source wrapping dimension not acceptable\n");
  }
  *(_DWORD *)(result + 70std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 700) & 0xFFFFFF8F | dword_211F04420[a2];
  *(_DWORD *)(result + 708) = a4 | (a3 << 16);
  return result;
}

uint64_t ZinAneTd<10u>::SetOpMode(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 816) & 0xFFFFFFF8;
      goto LABEL_8;
    case 1:
      ZinAssertImpl("ElemWise not valid for architecture");
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 816) & 0xFFFFFFF8 | 3;
      goto LABEL_8;
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 816) & 0xFFFFFFF8 | 1;
      goto LABEL_8;
    case 4:
      unsigned int v2 = *(_DWORD *)(result + 816) & 0xFFFFFFF8 | 2;
      goto LABEL_8;
    case 5:
      unsigned int v2 = *(_DWORD *)(result + 816) & 0xFFFFFFF8 | 4;
      goto LABEL_8;
    case 6:
      unsigned int v2 = *(_DWORD *)(result + 816) & 0xFFFFFFF8 | 5;
LABEL_8:
      *(_DWORD *)(result + 816) = v2;
      break;
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<10u>::SetKernelMode(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 816) & 0xFFFFFFF7;
LABEL_7:
      *(_DWORD *)(result + 816) = v2;
      return result;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 816) | 8;
      goto LABEL_7;
    case 2:
      ZinAssertImpl("Unsupported Kernel Mode");
  }
  return result;
}

uint64_t ZinAneTd<10u>::SetPassthroughEnable(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 32;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 816) = *(_DWORD *)(result + 816) & 0xFFFFFFDF | v2;
  return result;
}

uint64_t ZinAneTd<10u>::SetKernelFmt(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 812) & 0xFFFFFFFC;
      goto LABEL_5;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 812) & 0xFFFFFFFC | 1;
      goto LABEL_5;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 812) & 0xFFFFFFFC | 2;
LABEL_5:
      *(_DWORD *)(result + 812) = v2;
      break;
    case 3:
      ZinAssertImpl("Unimplemented or Unsupported kernel format");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<10u>::SetKernelDmaSrcCoeffDmaEn(uint64_t result, int a2, uint64_t a3)
{
  *(_DWORD *)(result + 4 * a3 + 68) = *(_DWORD *)(result + 4 * a3 + 68) & 0xFFFFFFFE | a2;
  return result;
}

uint64_t ZinAneTd<10u>::SetKernelDmaSrcCoeffDmaCacheHint(uint64_t result, int a2, uint64_t a3)
{
  int v3 = 224;
  switch(a2)
  {
    case 0:
      goto LABEL_5;
    case 1:
      int v3 = 32;
      goto LABEL_5;
    case 2:
      int v3 = 64;
      goto LABEL_5;
    case 3:
      int v3 = 192;
LABEL_5:
      *(_DWORD *)(result + 4 * a3 + 68) = *(_DWORD *)(result + 4 * a3 + 68) & 0xFFFFFF0F | v3;
      break;
    case 4:
      ZinAssertImpl("Error: Invalid KernelDmaSrc CoeffDma CacheHint");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<10u>::SetKernelDmaSrcPostScaleDmaCacheHint(uint64_t result, int a2)
{
  int v2 = 224;
  switch(a2)
  {
    case 0:
      goto LABEL_5;
    case 1:
      int v2 = 32;
      goto LABEL_5;
    case 2:
      int v2 = 64;
      goto LABEL_5;
    case 3:
      int v2 = 192;
LABEL_5:
      *(_DWORD *)(result + 1std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_DWORD *)(result + 132) & 0xFFFFFF0F | v2;
      break;
    case 4:
      ZinAssertImpl("Error: Invalid KernelDmaSrc PostScale Dma CacheHint");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<10u>::SetKernelDmaSrcBiasDmaCacheHint(uint64_t result, int a2)
{
  int v2 = 224;
  switch(a2)
  {
    case 0:
      goto LABEL_5;
    case 1:
      int v2 = 32;
      goto LABEL_5;
    case 2:
      int v2 = 64;
      goto LABEL_5;
    case 3:
      int v2 = 192;
LABEL_5:
      *(_DWORD *)(result + 116) = *(_DWORD *)(result + 116) & 0xFFFFFF0F | v2;
      break;
    case 4:
      ZinAssertImpl("Error: Invalid KernelDmaSrc PostScale Dma CacheHint");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<10u>::SetKernelDmaSrcPaletteLutDmaCacheHint(uint64_t result, int a2)
{
  int v2 = 224;
  switch(a2)
  {
    case 0:
      goto LABEL_5;
    case 1:
      int v2 = 32;
      goto LABEL_5;
    case 2:
      int v2 = 64;
      goto LABEL_5;
    case 3:
      int v2 = 192;
LABEL_5:
      *(_DWORD *)(result + 148) = *(_DWORD *)(result + 148) & 0xFFFFFF0F | v2;
      break;
    case 4:
      ZinAssertImpl("Error: Invalid KernelDmaSrc PaletteLut Dma CacheHint");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<10u>::SetKernelDmaSrcNonLinearLutDmaCacheHint(uint64_t result, int a2)
{
  int v2 = 224;
  switch(a2)
  {
    case 0:
      goto LABEL_5;
    case 1:
      int v2 = 32;
      goto LABEL_5;
    case 2:
      int v2 = 64;
      goto LABEL_5;
    case 3:
      int v2 = 192;
LABEL_5:
      *(_DWORD *)(result + 164) = *(_DWORD *)(result + 164) & 0xFFFFFF0F | v2;
      break;
    case 4:
      ZinAssertImpl("Error: Invalid KernelDmaSrc PostScale Dma CacheHint");
    default:
      return result;
  }
  return result;
}

BOOL ZinAneTd<10u>::SetKernelDmaSrcCoeffMemBufferSize(uint64_t a1, unsigned int a2, uint64_t a3)
{
  int v6 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 568), &v6);
  if (result) {
    *(_DWORD *)(a1 + 4 * a3 + 10std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 4 * a3 + 100) & 0x3F | (v6 << 6);
  }
  return result;
}

BOOL ZinAneTd<10u>::SetKernelDmaSrcCoeffBaseOffset(uint64_t a1, unsigned int a2, uint64_t a3)
{
  int v6 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 560), &v6);
  if (result) {
    *(_DWORD *)(a1 + 4 * a3 + 84) = *(_DWORD *)(a1 + 4 * a3 + 84) & 0x3F | (v6 << 6);
  }
  return result;
}

uint64_t ZinAneTd<10u>::SetKernelDmaSrcDataSetId(uint64_t result, char a2, uint64_t a3)
{
  *(unsigned char *)(result + 4 * a3 + 69) = a2;
  return result;
}

uint64_t ZinAneTd<10u>::SetPaddingMode(uint64_t result, int a2, int a3)
{
  switch(a2)
  {
    case 1:
      if (a3) {
        goto LABEL_11;
      }
      int v3 = 0;
      int v4 = 0;
      break;
    case 2:
      if (a3) {
        goto LABEL_11;
      }
      int v3 = 0;
      int v4 = 4;
      break;
    case 3:
      if (a3) {
        goto LABEL_11;
      }
      int v4 = 8;
      int v3 = 0x40000;
      break;
    case 4:
      if (a3) {
LABEL_11:
      }
        ZinAssertImpl("Error: padding-mode doesn't support constants");
      int v3 = 0;
      int v4 = 12;
      break;
    case 6:
      ZinAssertImpl("Platform doesn't support reflective padding mode");
    case 9:
      ZinAssertImpl("Platform doesn't support constant padding-mode");
    default:
      ZinAssertImpl("Invalid padding mode: %d", a2);
  }
  *(_DWORD *)(result + 62std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 620) & 0xFFFFFFF3 | v4;
  *(_DWORD *)(result + 816) = *(_DWORD *)(result + 816) & 0xFFFBFFFF | v3;
  return result;
}

uint64_t ZinAneTd<10u>::SetKernelAlignmentFormat(uint64_t result, int a2)
{
  if (a2)
  {
    if (a2 != 1) {
      return result;
    }
    unsigned int v2 = *(_DWORD *)(result + 812) & 0xFFFEFFFF;
  }
  else
  {
    unsigned int v2 = *(_DWORD *)(result + 812) | 0x10000;
  }
  *(_DWORD *)(result + 812) = v2;
  return result;
}

void ZinAneTd<10u>::SetAlignedKernelRelocationCommand(uint64_t a1, void *a2, uint64_t a3, const void **a4, uint64_t a5)
{
  if (a2[1])
  {
    if (*((char *)a4 + 23) >= 0) {
      size_t v10 = *((unsigned __int8 *)a4 + 23);
    }
    else {
      size_t v10 = (size_t)a4[1];
    }
    long long v11 = __p;
    std::string::basic_string[abi:ne180100]((uint64_t)__p, v10 + 7);
    if (v24 < 0) {
      long long v11 = (void **)__p[0];
    }
    if (v10)
    {
      if (*((char *)a4 + 23) >= 0) {
        uint64_t v12 = a4;
      }
      else {
        uint64_t v12 = *a4;
      }
      memmove(v11, v12, v10);
    }
    strcpy((char *)v11 + v10, "_actlut");
    ZinAneTdHw_v10::AddRelocInfo((uint64_t *)(a1 + 8), (uint64_t)__p, 5472, a3, 1, 1, a5, 0);
    if (v24 < 0) {
      operator delete(__p[0]);
    }
  }
  if (a2[2])
  {
    if (*((char *)a4 + 23) >= 0) {
      size_t v13 = *((unsigned __int8 *)a4 + 23);
    }
    else {
      size_t v13 = (size_t)a4[1];
    }
    int v14 = __p;
    std::string::basic_string[abi:ne180100]((uint64_t)__p, v13 + 7);
    if (v24 < 0) {
      int v14 = (void **)__p[0];
    }
    if (v13)
    {
      if (*((char *)a4 + 23) >= 0) {
        int v15 = a4;
      }
      else {
        int v15 = *a4;
      }
      memmove(v14, v15, v13);
    }
    strcpy((char *)v14 + v13, "_pallut");
    ZinAneTdHw_v10::AddRelocInfo((uint64_t *)(a1 + 8), (uint64_t)__p, 5468, a3, 1, 1, a5, 0);
    if (v24 < 0) {
      operator delete(__p[0]);
    }
  }
  if (a2[3])
  {
    if (*((char *)a4 + 23) >= 0) {
      size_t v16 = *((unsigned __int8 *)a4 + 23);
    }
    else {
      size_t v16 = (size_t)a4[1];
    }
    int v17 = __p;
    std::string::basic_string[abi:ne180100]((uint64_t)__p, v16 + 6);
    if (v24 < 0) {
      int v17 = (void **)__p[0];
    }
    if (v16)
    {
      if (*((char *)a4 + 23) >= 0) {
        uint64_t v18 = a4;
      }
      else {
        uint64_t v18 = *a4;
      }
      memmove(v17, v18, v16);
    }
    strcpy((char *)v17 + v16, "_scale");
    ZinAneTdHw_v10::AddRelocInfo((uint64_t *)(a1 + 8), (uint64_t)__p, 5464, a3, 1, 1, a5, 0);
    if (v24 < 0) {
      operator delete(__p[0]);
    }
  }
  if (a2[4])
  {
    uint64_t v19 = (uint64_t *)(a1 + 8);
    if (*((char *)a4 + 23) >= 0) {
      size_t v20 = *((unsigned __int8 *)a4 + 23);
    }
    else {
      size_t v20 = (size_t)a4[1];
    }
    long long v21 = __p;
    std::string::basic_string[abi:ne180100]((uint64_t)__p, v20 + 5);
    if (v24 < 0) {
      long long v21 = (void **)__p[0];
    }
    if (v20)
    {
      if (*((char *)a4 + 23) >= 0) {
        long long v22 = a4;
      }
      else {
        long long v22 = *a4;
      }
      memmove(v21, v22, v20);
    }
    strcpy((char *)v21 + v20, "_bias");
    ZinAneTdHw_v10::AddRelocInfo(v19, (uint64_t)__p, 5460, a3, 1, 1, a5, 0);
    if (v24 < 0) {
      operator delete(__p[0]);
    }
  }
}

void sub_2112CCE0C(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, void *__p, uint64_t a10, int a11, __int16 a12, char a13, char a14)
{
  if (a14 < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

_DWORD *ZinAneTd<10u>::SetAlignedKernelBias(_DWORD *result, uint64_t a2, uint64_t a3, int a4)
{
  result[11] = result[11] & 0xFFFFFFF3 | 8;
  result[203] = result[203] & 0xFFF9FFFF | 0x40000;
  int v4 = result[30] & 0x3F | (a4 << 6);
  result[29] |= 1u;
  result[30] = v4;
  return result;
}

_DWORD *ZinAneTd<10u>::SetAlignedKernelPostScale(_DWORD *result, uint64_t a2, uint64_t a3, int a4)
{
  result[11] = result[11] & 0xFFFFFFFC | 2;
  result[203] = result[203] & 0xFFE7FFFF | 0x100000;
  int v4 = result[34] & 0x3F | (a4 << 6);
  result[33] |= 1u;
  result[34] = v4;
  return result;
}

uint64_t ZinAneTd<10u>::SetAlignedKernelPaletteLut(uint64_t result, uint64_t a2, uint64_t a3, int a4)
{
  int v4 = *(_DWORD *)(result + 152) & 0x3F | (a4 << 6);
  *(_DWORD *)(result + 148) |= 1u;
  *(_DWORD *)(result + 152) = v4;
  return result;
}

uint64_t ZinAneTd<10u>::SetAlignedKernelNonLinearLut(uint64_t result, uint64_t a2, uint64_t a3, int a4)
{
  int v4 = *(_DWORD *)(result + 168) & 0x3F | (a4 << 6);
  *(_DWORD *)(result + 164) |= 1u;
  *(_DWORD *)(result + 168) = v4;
  return result;
}

uint64_t ZinAneTd<10u>::SetPEFinalScale(uint64_t result, float a2)
{
  *(float *)(result + 768) = a2;
  return result;
}

void ZinAneTd<10u>::SetPEScale(uint64_t a1, float a2)
{
  *(float *)(a1 + 756) = ZinF32ToNearestF19(a2);
}

void ZinAneTd<10u>::SetPEBias(uint64_t a1, float a2)
{
  *(float *)(a1 + 752) = ZinF32ToNearestF19(a2);
}

void ZinAneTd<10u>::SetPEPreScale(uint64_t a1, float a2)
{
  *(float *)(a1 + 764) = ZinF32ToNearestF19(a2);
}

uint64_t ZinAneTd<10u>::SetPESrc1ReLu(uint64_t result, int a2)
{
  *(_DWORD *)(result + 62std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 620) & 0xFFFFFFFE | a2;
  return result;
}

uint64_t ZinAneTd<10u>::SetPESrc2ReLu(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 16;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 62std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 620) & 0xFFFFFFEF | v2;
  return result;
}

uint64_t ZinAneTd<10u>::SetPESrc1Transpose(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 256;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 304) = *(_DWORD *)(result + 304) & 0xFFFFFEFF | v2;
  return result;
}

uint64_t ZinAneTd<10u>::SetPESrc2Transpose(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 512;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 304) = *(_DWORD *)(result + 304) & 0xFFFFFDFF | v2;
  return result;
}

uint64_t ZinAneTd<10u>::SetPESrc1Broadcast(uint64_t result, uint64_t a2)
{
  for (uint64_t i = *(uint64_t **)(a2 + 16); i; uint64_t i = (uint64_t *)*i)
  {
    unsigned int v3 = *((_DWORD *)i + 4) - 1;
    if (v3 <= 3) {
      *(_DWORD *)(result + 304) |= dword_211F04430[v3];
    }
  }
  return result;
}

uint64_t ZinAneTd<10u>::SetPESrc2Broadcast(uint64_t result, uint64_t a2, char a3)
{
  for (uint64_t i = *(uint64_t **)(a2 + 16); i; uint64_t i = (uint64_t *)*i)
  {
    int v4 = 128;
    switch(*((_DWORD *)i + 4))
    {
      case 1:
        int v4 = 64;
        break;
      case 2:
        break;
      case 3:
        if (a3) {
          continue;
        }
        int v4 = 32;
        break;
      case 4:
        if (a3) {
          continue;
        }
        int v4 = 16;
        break;
      default:
        continue;
    }
    *(_DWORD *)(result + 304) |= v4;
  }
  return result;
}

void ZinAneTd<10u>::SetPEIndexMode(uint64_t a1, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(a1 + 724) & 0xFFF8FFFF | 0x10000;
      goto LABEL_7;
    case 1:
      unsigned int v2 = *(_DWORD *)(a1 + 724) & 0xFFF8FFFF | 0x20000;
      goto LABEL_7;
    case 2:
      unsigned int v2 = *(_DWORD *)(a1 + 724) & 0xFFF8FFFF | 0x50000;
      goto LABEL_7;
    case 3:
      unsigned int v2 = *(_DWORD *)(a1 + 724) & 0xFFF8FFFF | 0x30000;
      goto LABEL_7;
    case 4:
      unsigned int v2 = *(_DWORD *)(a1 + 724) & 0xFFF8FFFF | 0x40000;
LABEL_7:
      *(_DWORD *)(a1 + 724) = v2;
      break;
    case 5:
      BOOL v3 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v3) {
        ZinAneTd<8u>::SetPEIndexMode(v3, v4, v5, v6, v7, v8, v9, v10);
      }
      break;
    default:
      return;
  }
}

uint64_t ZinAneTd<10u>::SetPEIndexTranspose(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 0x4000000;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 724) = *(_DWORD *)(result + 724) & 0xFBFFFFFF | v2;
  return result;
}

uint64_t ZinAneTd<10u>::SetPEIndexBroadcast(uint64_t result, uint64_t a2)
{
  int v2 = *(uint64_t **)(a2 + 16);
  if (v2)
  {
    while (1)
    {
      int v3 = *((_DWORD *)v2 + 4);
      if (v3 == 2) {
        break;
      }
      if (v3 == 1)
      {
        int v4 = 0x1000000;
LABEL_6:
        *(_DWORD *)(result + 724) |= v4;
      }
      int v2 = (uint64_t *)*v2;
      if (!v2) {
        return result;
      }
    }
    int v4 = 0x2000000;
    goto LABEL_6;
  }
  return result;
}

uint64_t ZinAneTd<10u>::SetPEOperationMode(uint64_t a1, int a2)
{
  uint64_t v2 = 0;
  switch(a2)
  {
    case 0:
      *(_DWORD *)(a1 + 748) &= 0xFFFFFFE3;
      int v3 = (unsigned int *)(*(void *)(a1 + 992) + 600);
      unint64_t v4 = 0;
      goto LABEL_8;
    case 1:
      *(_DWORD *)(a1 + 748) = *(_DWORD *)(a1 + 748) & 0xFFFFFFE3 | 4;
      int v3 = (unsigned int *)(*(void *)(a1 + 992) + 600);
      unint64_t v4 = 1;
      goto LABEL_8;
    case 2:
      *(_DWORD *)(a1 + 748) = *(_DWORD *)(a1 + 748) & 0xFFFFFFE3 | 0x10;
      if (!CheckRegValueRange(4uLL, (unsigned int *)(*(void *)(a1 + 992) + 600))) {
        goto LABEL_5;
      }
      goto LABEL_9;
    case 3:
      *(_DWORD *)(a1 + 748) = *(_DWORD *)(a1 + 748) & 0xFFFFFFE3 | 8;
      int v3 = (unsigned int *)(*(void *)(a1 + 992) + 600);
      unint64_t v4 = 2;
      goto LABEL_8;
    case 4:
      *(_DWORD *)(a1 + 748) = *(_DWORD *)(a1 + 748) & 0xFFFFFFE3 | 0xC;
      int v3 = (unsigned int *)(*(void *)(a1 + 992) + 600);
      unint64_t v4 = 3;
LABEL_8:
      if (CheckRegValueRange(v4, v3)) {
        goto LABEL_9;
      }
LABEL_5:
      uint64_t v2 = 0;
      break;
    case 5:
      return v2;
    default:
LABEL_9:
      uint64_t v2 = 1;
      break;
  }
  return v2;
}

uint64_t ZinAneTd<10u>::SetPEFirstSource(uint64_t result, int a2)
{
  if (a2)
  {
    if (a2 != 1) {
      return result;
    }
    unsigned int v2 = *(_DWORD *)(result + 748) & 0xFFFEFFFF;
  }
  else
  {
    unsigned int v2 = *(_DWORD *)(result + 748) | 0x10000;
  }
  *(_DWORD *)(result + 748) = v2;
  return result;
}

uint64_t ZinAneTd<10u>::SetPESecondSource(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 748) & 0xFFF3FFFF;
      goto LABEL_6;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 748) & 0xFFF3FFFF | 0x40000;
      goto LABEL_6;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 748) & 0xFFF3FFFF | 0x80000;
      goto LABEL_6;
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 748) | 0xC0000;
LABEL_6:
      *(_DWORD *)(result + 748) = v2;
      break;
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<10u>::SetPECondition(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 748) & 0xFFFFFE3F;
      goto LABEL_10;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 748) | 0x1C0;
      goto LABEL_10;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 748) & 0xFFFFFE3F | 0x100;
      goto LABEL_10;
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 748) & 0xFFFFFE3F | 0x180;
      goto LABEL_10;
    case 4:
      unsigned int v2 = *(_DWORD *)(result + 748) & 0xFFFFFE3F | 0x80;
      goto LABEL_10;
    case 5:
      unsigned int v2 = *(_DWORD *)(result + 748) & 0xFFFFFE3F | 0x140;
      goto LABEL_10;
    case 6:
      unsigned int v2 = *(_DWORD *)(result + 748) & 0xFFFFFE3F | 0x40;
      goto LABEL_10;
    case 7:
      unsigned int v2 = *(_DWORD *)(result + 748) & 0xFFFFFE3F | 0xC0;
LABEL_10:
      *(_DWORD *)(result + 748) = v2;
      break;
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<10u>::SetPEOutputCtoW(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 1024;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 304) = *(_DWORD *)(result + 304) & 0xFFFFFBFF | v2;
  return result;
}

BOOL ZinAneTd<10u>::SetL2ResultBaseAddr(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 376), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Result Base Address");
  }
  *(_DWORD *)(a1 + 676) = *(_DWORD *)(a1 + 676) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<10u>::SetL2ResultChannelStride(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 384), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Result Channel Stride");
  }
  *(_DWORD *)(a1 + 68std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 680) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<10u>::SetL2ResultRowStride(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 392), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Result Row Stride");
  }
  *(_DWORD *)(a1 + 684) = *(_DWORD *)(a1 + 684) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<10u>::SetL2ResultDepthStride(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 400), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Result Depth Stride");
  }
  *(_DWORD *)(a1 + 688) = *(_DWORD *)(a1 + 688) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<10u>::SetL2ResultGroupStride(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 408), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Result Group Stride");
  }
  *(_DWORD *)(a1 + 692) = *(_DWORD *)(a1 + 692) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

uint64_t ZinAneTd<10u>::SetL2BfrMode(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 8;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 672) = *(_DWORD *)(result + 672) & 0xFFFFFFF7 | v2;
  return result;
}

uint64_t ZinAneTd<10u>::SetL2ResultType(uint64_t result, int a2)
{
  switch(a2)
  {
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 672) & 0xFFFFFFFC | 2;
      break;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 672) & 0xFFFFFFFC | 1;
      break;
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 672) & 0xFFFFFFFC;
      break;
    case 4:
      unsigned int v2 = *(_DWORD *)(result + 672) | 3;
      break;
    default:
      ZinAssertImpl("Invalid L2 Result Type");
  }
  *(_DWORD *)(result + 672) = v2;
  return result;
}

uint64_t ZinAneTd<10u>::SetTileDmaSrc1Format(uint64_t result, int a2, int a3)
{
  switch(a2)
  {
    case 1:
      unsigned int v3 = *(_DWORD *)(result + 440) & 0xFFFFCFFC | 0x1000;
      goto LABEL_16;
    case 2:
      unsigned int v3 = *(_DWORD *)(result + 440) & 0xFFFFCFFC;
      goto LABEL_16;
    case 3:
      unsigned int v4 = *(_DWORD *)(result + 440) & 0xFFFFCFCC;
      int v5 = 8241;
      break;
    case 4:
      unsigned int v3 = *(_DWORD *)(result + 440) & 0xFFFFCECC | 1;
      goto LABEL_16;
    case 5:
      unsigned int v4 = *(_DWORD *)(result + 440) & 0xFFFFCECC;
      int v5 = 257;
      break;
    case 6:
      unsigned int v4 = *(_DWORD *)(result + 440) & 0xFFFFCECC;
      int v5 = 17;
      break;
    case 7:
      unsigned int v4 = *(_DWORD *)(result + 440) & 0xFFFFCECC;
      int v5 = 273;
      break;
    case 8:
      ZinAssertImpl("Packed10 format not supported");
    case 9:
      unsigned int v4 = *(_DWORD *)(result + 440) & 0xFFFFCECC;
      if (!a3) {
        goto LABEL_14;
      }
      int v5 = 4401;
      break;
    case 10:
      unsigned int v4 = *(_DWORD *)(result + 440) & 0xFFFFCECC;
      if (a3) {
        int v5 = 305;
      }
      else {
LABEL_14:
      }
        int v5 = 8497;
      break;
    case 11:
      unsigned int v4 = *(_DWORD *)(result + 440) & 0xFFFFFFCF;
      int v5 = 12547;
      break;
    case 12:
      ZinAssertImpl("E4M3 format is not supported");
    case 13:
      ZinAssertImpl("E5M2 format is not supported");
    default:
      ZinAssertImpl("Invalid format provided");
  }
  unsigned int v3 = v4 | v5;
LABEL_16:
  *(_DWORD *)(result + 44std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v3;
  return result;
}

BOOL ZinAneTd<10u>::SetTileDmaSrc1Interleave(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 584), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc1 Interleave");
  }
  *(_DWORD *)(a1 + 44std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 440) & 0xF0FFFFFF | ((v4 & 0xF) << 24);
  return result;
}

uint64_t ZinAneTd<10u>::SetTileDmaSrc1Enable(uint64_t result)
{
  *(_DWORD *)(result + 336) |= 1u;
  return result;
}

uint64_t ZinAneTd<10u>::SetTileDmaSrc1CacheHint(uint64_t result, int a2, int a3, int a4)
{
  int v4 = 224;
  switch(a2)
  {
    case 0:
      goto LABEL_5;
    case 1:
      int v4 = 32;
      goto LABEL_5;
    case 2:
      int v4 = 64;
      goto LABEL_5;
    case 3:
      int v4 = 192;
LABEL_5:
      *(_DWORD *)(result + 336) = *(_DWORD *)(result + 336) & 0xFFFFFF0F | v4;
      break;
    case 4:
LABEL_15:
      ZinAssertImpl("Invalid CacheHint");
    default:
      break;
  }
  char v5 = 32;
  switch(a4)
  {
    case 0:
      char v5 = -32;
      goto LABEL_10;
    case 2:
      char v5 = 64;
      goto LABEL_10;
    case 3:
      char v5 = -64;
      goto LABEL_10;
    case 4:
      goto LABEL_15;
    default:
LABEL_10:
      char v6 = 2;
      switch(a3)
      {
        case 0:
          char v6 = 14;
          goto LABEL_14;
        case 2:
          char v6 = 4;
          goto LABEL_14;
        case 3:
          char v6 = 12;
          goto LABEL_14;
        case 4:
          goto LABEL_15;
        default:
LABEL_14:
          *(unsigned char *)(result + 344) = v6 | v5;
          return result;
      }
  }
}

uint64_t ZinAneTd<10u>::SetTileDmaSrc2CacheHint(uint64_t result, int a2, int a3, int a4)
{
  int v4 = 224;
  switch(a2)
  {
    case 0:
      goto LABEL_5;
    case 1:
      int v4 = 32;
      goto LABEL_5;
    case 2:
      int v4 = 64;
      goto LABEL_5;
    case 3:
      int v4 = 192;
LABEL_5:
      *(_DWORD *)(result + 34std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 340) & 0xFFFFFF0F | v4;
      break;
    case 4:
LABEL_15:
      ZinAssertImpl("Invalid CacheHint");
    default:
      break;
  }
  char v5 = 32;
  switch(a4)
  {
    case 0:
      char v5 = -32;
      goto LABEL_10;
    case 2:
      char v5 = 64;
      goto LABEL_10;
    case 3:
      char v5 = -64;
      goto LABEL_10;
    case 4:
      goto LABEL_15;
    default:
LABEL_10:
      char v6 = 2;
      switch(a3)
      {
        case 0:
          char v6 = 14;
          goto LABEL_14;
        case 2:
          char v6 = 4;
          goto LABEL_14;
        case 3:
          char v6 = 12;
          goto LABEL_14;
        case 4:
          goto LABEL_15;
        default:
LABEL_14:
          *(unsigned char *)(result + 348) = v6 | v5;
          return result;
      }
  }
}

BOOL ZinAneTd<10u>::SetTileDmaSrc1ChannelStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 992) + 440), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc1 Channel Stride");
  }
  *(_DWORD *)(a1 + 364) = *(_DWORD *)(a1 + 364) & 0x3F | (v4 << 6);
  return result;
}

BOOL ZinAneTd<10u>::SetTileDmaSrc1RowStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 992) + 432), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc1 Row Stride");
  }
  *(_DWORD *)(a1 + 36std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 360) & 0x3F | (v4 << 6);
  return result;
}

BOOL ZinAneTd<10u>::SetTileDmaSrc1DepthStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 992) + 448), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc1 Depth Stride");
  }
  *(_DWORD *)(a1 + 368) = *(_DWORD *)(a1 + 368) & 0x3F | (v4 << 6);
  return result;
}

BOOL ZinAneTd<10u>::SetTileDmaSrc1GroupStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 992) + 456), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc1 Group Stride");
  }
  *(_DWORD *)(a1 + 372) = *(_DWORD *)(a1 + 372) & 0x3F | (v4 << 6);
  return result;
}

uint64_t ZinAneTd<10u>::SetTileDmaSrc1WrapStatic(uint64_t a1, unsigned __int16 a2, unsigned __int16 a3, unsigned int a4)
{
  uint64_t result = ZinAneTd<10u>::SetTileDmaSrc1WrapCfg(a1, a4);
  *(_DWORD *)(a1 + 52std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = a3 | (a2 << 16);
  return result;
}

uint64_t ZinAneTd<10u>::SetTileDmaSrc1WrapCfg(uint64_t a1, unsigned int a2)
{
  if (a2 == 4) {
    ZinAssertImpl("Width wrap axis is not supported on this architecture");
  }
  uint64_t result = ZinIrCodegenGetDMAWrapCfgDim(a2);
  *(_DWORD *)(a1 + 344) = *(_DWORD *)(a1 + 344) & 0xFFFFF8FF | ((result & 7) << 8);
  return result;
}

uint64_t ZinAneTd<10u>::SetTileDmaSrc1WrapDynamic(uint64_t a1, uint64_t a2, unsigned int a3)
{
  char v6 = (uint64_t *)(a1 + 8);
  std::string::basic_string[abi:ne180100]<0>(__p, &byte_211F4AA5D);
  ZinAneTdHw_v10::AddRelocInfo(v6, (uint64_t)__p, 4974, a2, 0, 0, 0, 0);
  if (v9 < 0) {
    operator delete(__p[0]);
  }
  return ZinAneTd<10u>::SetTileDmaSrc1WrapCfg(a1, a3);
}

void sub_2112CDE10(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11, int a12, __int16 a13, char a14, char a15)
{
  if (a15 < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinAneTd<10u>::SetTileDmaSrc1FmtOffsetCh(uint64_t result, char a2)
{
  *(_DWORD *)(result + 44std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 440) & 0xFFF8FFFF | ((a2 & 7) << 16);
  return result;
}

uint64_t ZinAneTd<10u>::SetTileDmaSrc1FmtCmpVec(uint64_t result, unsigned __int8 a2)
{
  *(_DWORD *)(result + 44std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 440) & 0xFFFFFFF | (a2 << 28);
  return result;
}

uint64_t ZinAneTd<10u>::SetTileDmaSrc1BaseAddrLo(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return ZinAneTdHw_v10::AddRelocInfo((uint64_t *)(a1 + 8), a2, 4932, a3, 1, 1, 0, 0);
}

uint64_t ZinAneTd<10u>::SetTileDmaSrc1DependencyMode(uint64_t result, int a2)
{
  if (a2 == 2)
  {
    unsigned int v2 = *(_DWORD *)(result + 336) & 0xCFFFFFFF | 0x10000000;
  }
  else if (a2 == 1)
  {
    unsigned int v2 = *(_DWORD *)(result + 336) & 0xCFFFFFFF | 0x20000000;
  }
  else
  {
    if (a2) {
      return result;
    }
    unsigned int v2 = *(_DWORD *)(result + 336) & 0xCFFFFFFF;
  }
  *(_DWORD *)(result + 336) = v2;
  return result;
}

uint64_t ZinAneTd<10u>::SetTileDmaSrc2DependencyMode(uint64_t result, int a2)
{
  if (a2 == 2)
  {
    unsigned int v2 = *(_DWORD *)(result + 340) & 0xCFFFFFFF | 0x10000000;
  }
  else if (a2 == 1)
  {
    unsigned int v2 = *(_DWORD *)(result + 340) & 0xCFFFFFFF | 0x20000000;
  }
  else
  {
    if (a2) {
      return result;
    }
    unsigned int v2 = *(_DWORD *)(result + 340) & 0xCFFFFFFF;
  }
  *(_DWORD *)(result + 34std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2;
  return result;
}

unint64_t ZinAneTd<10u>::SetTileDmaSrc1DependencyInterval(uint64_t a1, unsigned int a2)
{
  unint64_t result = ZinIrCodegenValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 592));
  *(_DWORD *)(a1 + 336) = *(_DWORD *)(a1 + 336) & 0xF0FFFFFF | ((result & 0xF) << 24);
  return result;
}

unint64_t ZinAneTd<10u>::SetTileDmaSrc2DependencyInterval(uint64_t a1, unsigned int a2)
{
  unint64_t result = ZinIrCodegenValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 592));
  *(_DWORD *)(a1 + 34std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 340) & 0xF0FFFFFF | ((result & 0xF) << 24);
  return result;
}

uint64_t ZinAneTd<10u>::SetTileDmaSrc1DependencyOffset(uint64_t a1, uint64_t a2)
{
  char v5 = 0;
  if (GetProgrammedDependencyOffsetAndDimension(a2, &v5, (_DWORD *)&v5 + 1)) {
    ZinAssertImpl("Failed to get dependency offset or dimension.");
  }
  if (HIDWORD(v5) == 2)
  {
    unsigned int v3 = *(_DWORD *)(a1 + 528) & 0xFFFFFFFC | 2;
  }
  else if (HIDWORD(v5) == 1)
  {
    unsigned int v3 = *(_DWORD *)(a1 + 528) & 0xFFFFFFFC | 1;
  }
  else
  {
    unsigned int v3 = *(_DWORD *)(a1 + 528) & 0xFFFFFFFC;
  }
  *(_DWORD *)(a1 + 528) = v3;
  uint64_t result = ZinCodegenUtil::ConvertInt32ToCustomUnsignedType((ZinCodegenUtil *)v5, 0x1DuLL);
  *(_DWORD *)(a1 + 528) = *(_DWORD *)(a1 + 528) & 0x80000003 | (4 * (result & 0x1FFFFFFF));
  return result;
}

uint64_t ZinAneTd<10u>::SetTileDmaSrc2DependencyOffset(uint64_t a1, uint64_t a2)
{
  char v5 = 0;
  if (GetProgrammedDependencyOffsetAndDimension(a2, &v5, (_DWORD *)&v5 + 1)) {
    ZinAssertImpl("Failed to get dependency offset or dimension");
  }
  if (HIDWORD(v5) == 2)
  {
    unsigned int v3 = *(_DWORD *)(a1 + 532) & 0xFFFFFFFC | 2;
  }
  else if (HIDWORD(v5) == 1)
  {
    unsigned int v3 = *(_DWORD *)(a1 + 532) & 0xFFFFFFFC | 1;
  }
  else
  {
    unsigned int v3 = *(_DWORD *)(a1 + 532) & 0xFFFFFFFC;
  }
  *(_DWORD *)(a1 + 5std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = v3;
  uint64_t result = ZinCodegenUtil::ConvertInt32ToCustomUnsignedType((ZinCodegenUtil *)v5, 0x1DuLL);
  *(_DWORD *)(a1 + 5std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_DWORD *)(a1 + 532) & 0x80000003 | (4 * (result & 0x1FFFFFFF));
  return result;
}

uint64_t ZinAneTd<10u>::SetTileDmaSrc1OffsetY(uint64_t result, __int16 a2)
{
  *(_WORD *)(result + 468) = a2;
  return result;
}

uint64_t ZinAneTd<10u>::SetTileDmaSrc1CompressedInfo(uint64_t result, int a2, int a3, int a4)
{
  int v4 = *(_DWORD *)(result + 456);
  *(_DWORD *)(result + 456) = v4 | 1;
  switch(a4)
  {
    case 0:
      unsigned int v5 = v4 & 0xFFFFCFFE | 1;
      break;
    case 1:
      unsigned int v5 = v4 & 0xFFFFCFFE | 0x1001;
      break;
    case 2:
      unsigned int v5 = v4 & 0xFFFFCFFE | 0x2001;
      break;
    case 3:
      unsigned int v5 = v4 | 0x3001;
      break;
    default:
      ZinAssertImpl("Invalid Lossy Mode");
  }
  *(_DWORD *)(result + 456) = v5;
  if (a3 == 2)
  {
    unsigned int v6 = v5 | 4;
  }
  else
  {
    if (a3 != 1) {
      ZinAssertImpl("Unsupported macro block size");
    }
    unsigned int v6 = v5 & 0xFFFFFFFB;
  }
  *(_DWORD *)(result + 456) = v6;
  if ((a2 - 1) >= 0x13) {
    ZinAssertImpl("Invalid packing format");
  }
  *(_DWORD *)(result + 456) = v6 & 0xFFFFFC0F | dword_211F04368[a2 - 1];
  return result;
}

BOOL ZinAneTd<10u>::SetTileDmaSrc1CompressedSize(uint64_t a1, unsigned int a2, unsigned int a3)
{
  int v7 = 0;
  if (!ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 24), &v7)) {
    ZinAssertImpl("Illegal TileDmaSrc1 Compressed Width");
  }
  *(_DWORD *)(a1 + 46std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 460) & 0xFFFE0000 | v7 & 0x1FFFF;
  int v6 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a3, (unsigned int *)(*(void *)(a1 + 992) + 16), &v6);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc1 Compressed Height");
  }
  *(_DWORD *)(a1 + 464) = *(_DWORD *)(a1 + 464) & 0xFFFE0000 | v6 & 0x1FFFF;
  return result;
}

double ZinAneTd<10u>::SetTileDmaSrc1MetaData(uint64_t a1, uint64_t a2, uint64_t a3, unsigned int a4, unsigned int a5, int a6)
{
  ZinAneTdHw_v10::AddRelocInfo((uint64_t *)(a1 + 8), a2, 4944, a3, 1, 1, 0, 0);
  *(_DWORD *)(a1 + 456) &= ~8u;
  double result = COERCE_DOUBLE(__PAIR64__(a5, a4));
  *(int32x2_t *)(a1 + 416) = vsli_n_s32(*(int32x2_t *)(a1 + 416), (int32x2_t)__PAIR64__(a5, a4), 7uLL);
  *(_DWORD *)(a1 + 424) = *(_DWORD *)(a1 + 424) & 0x7F | (a6 << 7);
  return result;
}

uint64_t ZinAneTd<10u>::SetTileDmaSrc1NoMetaData(uint64_t result)
{
  *(_DWORD *)(result + 456) |= 8u;
  return result;
}

uint64_t ZinAneTd<10u>::SetTileDmaSrc1DataSetId(uint64_t result, char a2)
{
  *(unsigned char *)(result + 337) = a2;
  return result;
}

uint64_t ZinAneTd<10u>::SetTileDmaSrc2Format(uint64_t result, int a2, int a3)
{
  switch(a2)
  {
    case 1:
    case 2:
    case 12:
    case 13:
      int v3 = *(_DWORD *)(result + 444);
      unsigned int v4 = v3 & 0xFFFFFFFC;
      *(_DWORD *)(result + 444) = v3 & 0xFFFFFFFC;
      switch(a2)
      {
        case 1:
          unsigned int v5 = v3 & 0xFFFFCFFC | 0x1000;
          goto LABEL_24;
        case 2:
          unsigned int v5 = v3 & 0xFFFFCFFC;
          goto LABEL_24;
        case 3:
          goto LABEL_5;
        case 4:
          goto LABEL_7;
        case 5:
          goto LABEL_9;
        case 6:
          goto LABEL_11;
        case 7:
          goto LABEL_13;
        case 8:
          goto LABEL_26;
        case 9:
          goto LABEL_15;
        case 10:
          goto LABEL_18;
        case 11:
          goto LABEL_22;
        case 12:
          ZinAssertImpl("E4M3 is not supported");
        case 13:
          ZinAssertImpl("E5M2 is not supported");
        default:
          goto LABEL_27;
      }
    case 3:
      unsigned int v4 = *(_DWORD *)(result + 444) & 0xFFFFFFFC | 1;
LABEL_5:
      unsigned int v6 = v4 & 0xFFFFCFFF;
      int v7 = 8240;
      break;
    case 4:
      unsigned int v4 = *(_DWORD *)(result + 444) & 0xFFFFFFFC | 1;
LABEL_7:
      unsigned int v5 = v4 & 0xFFFFCECF;
      goto LABEL_24;
    case 5:
      unsigned int v4 = *(_DWORD *)(result + 444) & 0xFFFFFFFC | 1;
LABEL_9:
      unsigned int v5 = v4 & 0xFFFFCECF | 0x100;
      goto LABEL_24;
    case 6:
      unsigned int v4 = *(_DWORD *)(result + 444) & 0xFFFFFFFC | 1;
LABEL_11:
      unsigned int v5 = v4 & 0xFFFFCECF | 0x10;
      goto LABEL_24;
    case 7:
      unsigned int v4 = *(_DWORD *)(result + 444) & 0xFFFFFFFC | 1;
LABEL_13:
      unsigned int v6 = v4 & 0xFFFFCECF;
      int v7 = 272;
      break;
    case 8:
LABEL_26:
      ZinAssertImpl("Packed10 format not supported");
    case 9:
      unsigned int v4 = *(_DWORD *)(result + 444) & 0xFFFFFFFC | 1;
LABEL_15:
      unsigned int v6 = v4 & 0xFFFFCECF;
      if (!a3) {
        goto LABEL_20;
      }
      int v7 = 4400;
      break;
    case 10:
      unsigned int v4 = *(_DWORD *)(result + 444) & 0xFFFFFFFC | 1;
LABEL_18:
      unsigned int v6 = v4 & 0xFFFFCECF;
      if (a3) {
        int v7 = 304;
      }
      else {
LABEL_20:
      }
        int v7 = 8496;
      break;
    case 11:
      unsigned int v4 = *(_DWORD *)(result + 444) | 3;
LABEL_22:
      unsigned int v6 = v4 & 0xFFFFFFCF;
      int v7 = 12544;
      break;
    default:
LABEL_27:
      ZinAssertImpl("Invalid format provided");
  }
  unsigned int v5 = v6 | v7;
LABEL_24:
  *(_DWORD *)(result + 444) = v5;
  return result;
}

BOOL ZinAneTd<10u>::SetTileDmaSrc2Interleave(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 584), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc1 Interleave");
  }
  *(_DWORD *)(a1 + 444) = *(_DWORD *)(a1 + 444) & 0xF0FFFFFF | ((v4 & 0xF) << 24);
  return result;
}

BOOL ZinAneTd<10u>::SetL2Src2Interleave(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 584), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Source Interleave");
  }
  *(_DWORD *)(a1 + 628) = *(_DWORD *)(a1 + 628) & 0xFFFFF0FF | ((v4 & 0xF) << 8);
  return result;
}

uint64_t ZinAneTd<10u>::SetTileDmaSrc2Enable(uint64_t result)
{
  *(_DWORD *)(result + 340) |= 1u;
  return result;
}

uint64_t ZinAneTd<10u>::SetTileDmaSrc2WrapStatic(uint64_t a1, unsigned __int16 a2, unsigned __int16 a3, unsigned int a4)
{
  uint64_t result = ZinAneTd<10u>::SetTileDmaSrc2WrapCfg(a1, a4);
  *(_DWORD *)(a1 + 524) = a3 | (a2 << 16);
  return result;
}

uint64_t ZinAneTd<10u>::SetTileDmaSrc2WrapCfg(uint64_t a1, unsigned int a2)
{
  if (a2 == 4) {
    ZinAssertImpl("Width wrap axis is not supported on this architecture");
  }
  uint64_t result = ZinIrCodegenGetDMAWrapCfgDim(a2);
  *(_DWORD *)(a1 + 348) = *(_DWORD *)(a1 + 348) & 0xFFFFF8FF | ((result & 7) << 8);
  return result;
}

uint64_t ZinAneTd<10u>::SetTileDmaSrc2WrapDynamic(uint64_t a1, uint64_t a2, unsigned int a3)
{
  unsigned int v6 = (uint64_t *)(a1 + 8);
  std::string::basic_string[abi:ne180100]<0>(__p, &byte_211F4AA5D);
  ZinAneTdHw_v10::AddRelocInfo(v6, (uint64_t)__p, 4975, a2, 0, 0, 0, 0);
  if (v9 < 0) {
    operator delete(__p[0]);
  }
  return ZinAneTd<10u>::SetTileDmaSrc2WrapCfg(a1, a3);
}

void sub_2112CE6E0(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11, int a12, __int16 a13, char a14, char a15)
{
  if (a15 < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinAneTd<10u>::SetTileDmaSrc2FmtOffsetCh(uint64_t result, char a2)
{
  *(_DWORD *)(result + 444) = *(_DWORD *)(result + 444) & 0xFFF8FFFF | ((a2 & 7) << 16);
  return result;
}

uint64_t ZinAneTd<10u>::SetTileDmaSrc2FmtCmpVec(uint64_t result, unsigned __int8 a2)
{
  *(_DWORD *)(result + 444) = *(_DWORD *)(result + 444) & 0xFFFFFFF | (a2 << 28);
  return result;
}

uint64_t ZinAneTd<10u>::SetTileDmaSrc2OffsetY(uint64_t result, __int16 a2)
{
  *(_WORD *)(result + 484) = a2;
  return result;
}

int8x16_t ZinAneTd<10u>::SetTileDmaSrc2PixelOffset(uint64_t a1, unsigned int a2, unsigned int a3, unsigned int a4, unsigned int a5)
{
  v5.i64[0] = __PAIR64__(a3, a2);
  v5.i64[1] = __PAIR64__(a5, a4);
  v6.i64[0] = 0xFFFF0000FFFF0000;
  v6.i64[1] = 0xFFFF0000FFFF0000;
  int8x16_t result = vbslq_s8(v6, *(int8x16_t *)(a1 + 504), v5);
  *(int8x16_t *)(a1 + 504) = result;
  return result;
}

uint64_t ZinAneTd<10u>::SetTileDmaSrc2CompressedInfo(uint64_t result, int a2, int a3, int a4)
{
  int v4 = *(_DWORD *)(result + 472);
  *(_DWORD *)(result + 472) = v4 | 1;
  switch(a4)
  {
    case 0:
      unsigned int v5 = v4 & 0xFFFFCFFE | 1;
      break;
    case 1:
      unsigned int v5 = v4 & 0xFFFFCFFE | 0x1001;
      break;
    case 2:
      unsigned int v5 = v4 & 0xFFFFCFFE | 0x2001;
      break;
    case 3:
      unsigned int v5 = v4 | 0x3001;
      break;
    default:
      ZinAssertImpl("Invalid Lossy Mode");
  }
  *(_DWORD *)(result + 472) = v5;
  if (a3 == 2)
  {
    unsigned int v6 = v5 | 4;
  }
  else
  {
    if (a3 != 1) {
      ZinAssertImpl("Unsupported macro block size");
    }
    unsigned int v6 = v5 & 0xFFFFFFFB;
  }
  *(_DWORD *)(result + 472) = v6;
  if ((a2 - 1) >= 0x13) {
    ZinAssertImpl("Invalid packing format");
  }
  *(_DWORD *)(result + 472) = v6 & 0xFFFFFC0F | dword_211F04368[a2 - 1];
  return result;
}

uint64_t ZinAneTd<10u>::SetTileDmaSrc2DataSetId(uint64_t result, char a2)
{
  *(unsigned char *)(result + 341) = a2;
  return result;
}

BOOL ZinAneTd<10u>::SetTileDmaSrc2CompressedSize(uint64_t a1, unsigned int a2, unsigned int a3)
{
  int v7 = 0;
  if (!ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 24), &v7)) {
    ZinAssertImpl("Illegal TileDmaSrc2 Compressed Width");
  }
  *(_DWORD *)(a1 + 476) = *(_DWORD *)(a1 + 476) & 0xFFFE0000 | v7 & 0x1FFFF;
  int v6 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a3, (unsigned int *)(*(void *)(a1 + 992) + 16), &v6);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc2 Compressed Height");
  }
  *(_DWORD *)(a1 + 48std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 480) & 0xFFFE0000 | v6 & 0x1FFFF;
  return result;
}

double ZinAneTd<10u>::SetTileDmaSrc2MetaData(uint64_t a1, uint64_t a2, uint64_t a3, unsigned int a4, unsigned int a5, int a6)
{
  ZinAneTdHw_v10::AddRelocInfo((uint64_t *)(a1 + 8), a2, 4946, a3, 1, 1, 0, 0);
  *(_DWORD *)(a1 + 472) &= ~8u;
  double result = COERCE_DOUBLE(__PAIR64__(a5, a4));
  *(int32x2_t *)(a1 + 428) = vsli_n_s32(*(int32x2_t *)(a1 + 428), (int32x2_t)__PAIR64__(a5, a4), 7uLL);
  *(_DWORD *)(a1 + 436) = *(_DWORD *)(a1 + 436) & 0x7F | (a6 << 7);
  return result;
}

uint64_t ZinAneTd<10u>::SetTileDmaDstFormat(uint64_t result, int a2, int a3)
{
  switch(a2)
  {
    case 1:
      unsigned int v3 = *(_DWORD *)(result + 920) & 0xFFFFCFFC | 0x1000;
      goto LABEL_16;
    case 2:
      unsigned int v3 = *(_DWORD *)(result + 920) & 0xFFFFCFFC;
      goto LABEL_16;
    case 3:
      unsigned int v4 = *(_DWORD *)(result + 920) & 0xFFFFCFCC;
      int v5 = 8241;
      break;
    case 4:
      unsigned int v3 = *(_DWORD *)(result + 920) & 0xFFFFCECC | 1;
      goto LABEL_16;
    case 5:
      unsigned int v4 = *(_DWORD *)(result + 920) & 0xFFFFCECC;
      int v5 = 257;
      break;
    case 6:
      unsigned int v4 = *(_DWORD *)(result + 920) & 0xFFFFCECC;
      int v5 = 17;
      break;
    case 7:
      unsigned int v4 = *(_DWORD *)(result + 920) & 0xFFFFCECC;
      int v5 = 273;
      break;
    case 8:
      ZinAssertImpl("Packed10 format not supported");
    case 9:
      unsigned int v4 = *(_DWORD *)(result + 920) & 0xFFFFCECC;
      if (!a3) {
        goto LABEL_14;
      }
      int v5 = 4401;
      break;
    case 10:
      unsigned int v4 = *(_DWORD *)(result + 920) & 0xFFFFCECC;
      if (a3) {
        int v5 = 305;
      }
      else {
LABEL_14:
      }
        int v5 = 8497;
      break;
    case 11:
      unsigned int v4 = *(_DWORD *)(result + 920) & 0xFFFFFFCF;
      int v5 = 12547;
      break;
    case 12:
      ZinAssertImpl("E4M3 is not supported");
    case 13:
      ZinAssertImpl("E5M2 is not supported");
    default:
      ZinAssertImpl("Invalid format provided");
  }
  unsigned int v3 = v4 | v5;
LABEL_16:
  *(_DWORD *)(result + 92std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v3;
  return result;
}

BOOL ZinAneTd<10u>::SetTileDmaDstandL2DstInterleave(uint64_t a1, unsigned int a2)
{
  int v6 = 0;
  unint64_t v3 = a2;
  if (!ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 584), &v6)) {
    ZinAssertImpl("Illegal L2 Result Interleave");
  }
  *(_DWORD *)(a1 + 672) = *(_DWORD *)(a1 + 672) & 0xFFFFF0FF | ((v6 & 0xF) << 8);
  int v5 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(v3, (unsigned int *)(*(void *)(a1 + 992) + 584), &v5);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaDst Interleave");
  }
  *(_DWORD *)(a1 + 92std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 920) & 0xF0FFFFFF | ((v5 & 0xF) << 24);
  return result;
}

BOOL ZinAneTd<10u>::SetL2ResultInterleave(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 584), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Result Interleave");
  }
  *(_DWORD *)(a1 + 672) = *(_DWORD *)(a1 + 672) & 0xFFFFF0FF | ((v4 & 0xF) << 8);
  return result;
}

uint64_t ZinAneTd<10u>::SetTileDmaDstandL2DstFifoMode(uint64_t result, int a2)
{
  unsigned int v2 = *(_DWORD *)(result + 672) & 0xFFFFFFF7;
  if (a2) {
    int v3 = 0x1000000;
  }
  else {
    int v3 = 0;
  }
  unsigned int v4 = *(_DWORD *)(result + 864) & 0xFEFFFFFF | v3;
  if (a2) {
    int v5 = 8;
  }
  else {
    int v5 = 0;
  }
  *(_DWORD *)(result + 864) = v4;
  *(_DWORD *)(result + 672) = v2 | v5;
  return result;
}

uint64_t ZinAneTd<10u>::SetTileDmaDstEnable(uint64_t result)
{
  *(_DWORD *)(result + 864) |= 1u;
  return result;
}

uint64_t ZinAneTd<10u>::SetTileDmaDstCacheHint(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 864) | 0xF0;
      goto LABEL_5;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 864) & 0xFFFFFF0F | 0x30;
      goto LABEL_5;
    case 2:
      ZinAssertImpl("Drop CacheHint not supported on Dst");
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 864) & 0xFFFFFF0F | 0xD0;
LABEL_5:
      *(_DWORD *)(result + 864) = v2;
      break;
    case 4:
      ZinAssertImpl("Invalid CacheHint");
    default:
      return result;
  }
  return result;
}

BOOL ZinAneTd<10u>::SetTileDmaDstChannelStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 992) + 496), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaDst Channel Stride");
  }
  *(_DWORD *)(a1 + 884) = *(_DWORD *)(a1 + 884) & 0x3F | (v4 << 6);
  return result;
}

BOOL ZinAneTd<10u>::SetTileDmaDstRowStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 992) + 488), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaDst Row Stride");
  }
  *(_DWORD *)(a1 + 88std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 880) & 0x3F | (v4 << 6);
  return result;
}

BOOL ZinAneTd<10u>::SetTileDmaDstDepthStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 992) + 504), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaDst Depth Stride");
  }
  *(_DWORD *)(a1 + 888) = *(_DWORD *)(a1 + 888) & 0x3F | (v4 << 6);
  return result;
}

BOOL ZinAneTd<10u>::SetTileDmaDstGroupStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 992) + 512), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaDst Group Stride");
  }
  *(_DWORD *)(a1 + 892) = *(_DWORD *)(a1 + 892) & 0x3F | (v4 << 6);
  return result;
}

uint64_t ZinAneTd<10u>::SetTileDmaDstZeroPad(uint64_t result, _DWORD *a2)
{
  unsigned int v2 = *(_DWORD *)(result + 920) & 0xFFDFFFFF | ((*a2 == 0) << 21);
  *(_DWORD *)(result + 92std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2;
  *(_DWORD *)(result + 92std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2 & 0xFFEFFFFF | ((a2[1] == 0) << 20);
  return result;
}

uint64_t ZinAneTd<10u>::SetTileDmaDstCropOffset(uint64_t result, int a2, __int16 a3)
{
  *(_WORD *)(result + 944) = a3;
  if (a2) {
    ZinAssertImpl("Invalid Crop Offset X for architecture");
  }
  return result;
}

uint64_t ZinAneTd<10u>::SetTileDmaDstWrapStatic(uint64_t a1, unsigned __int16 a2, unsigned __int16 a3, unsigned int a4)
{
  uint64_t result = ZinAneTd<10u>::SetTileDmaDstWrapCfg(a1, a4);
  *(_DWORD *)(a1 + 916) = a3 | (a2 << 16);
  return result;
}

uint64_t ZinAneTd<10u>::SetTileDmaDstWrapCfg(uint64_t a1, unsigned int a2)
{
  if (a2 == 4) {
    ZinAssertImpl("Width wrap axis is not supported on this architecture");
  }
  uint64_t result = ZinIrCodegenGetDMAWrapCfgDim(a2);
  *(_DWORD *)(a1 + 868) = *(_DWORD *)(a1 + 868) & 0xFFFFF8FF | ((result & 7) << 8);
  return result;
}

uint64_t ZinAneTd<10u>::SetTileDmaDstWrapDynamic(uint64_t a1, uint64_t a2, unsigned int a3)
{
  int v6 = (uint64_t *)(a1 + 8);
  std::string::basic_string[abi:ne180100]<0>(__p, &byte_211F4AA5D);
  ZinAneTdHw_v10::AddRelocInfo(v6, (uint64_t)__p, 5197, a2, 0, 0, 0, 0);
  if (v9 < 0) {
    operator delete(__p[0]);
  }
  return ZinAneTd<10u>::SetTileDmaDstWrapCfg(a1, a3);
}

void sub_2112CEFB4(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11, int a12, __int16 a13, char a14, char a15)
{
  if (a15 < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinAneTd<10u>::SetTileDmaDstFmtOffsetCh(uint64_t result, char a2)
{
  *(_DWORD *)(result + 92std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 920) & 0xFFF8FFFF | ((a2 & 7) << 16);
  return result;
}

uint64_t ZinAneTd<10u>::SetTileDmaDstFmtCmpVec(uint64_t result, unsigned __int8 a2)
{
  *(_DWORD *)(result + 92std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 920) & 0xFFFFFFF | (a2 << 28);
  return result;
}

uint64_t ZinAneTd<10u>::SetTileDmaDstBaseAddrLo(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return ZinAneTdHw_v10::AddRelocInfo((uint64_t *)(a1 + 8), a2, 5186, a3, 1, 1, 0, 0);
}

BOOL ZinAneTd<10u>::SetTileDmaDstCompressedSize(uint64_t a1, unsigned int a2, unsigned int a3)
{
  int v7 = 0;
  if (!ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 24), &v7)) {
    ZinAssertImpl("Illegal TileDmaDst Compressed Width");
  }
  *(_DWORD *)(a1 + 936) = *(_DWORD *)(a1 + 936) & 0xFFFE0000 | v7 & 0x1FFFF;
  int v6 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a3, (unsigned int *)(*(void *)(a1 + 992) + 16), &v6);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaDst Compressed Height");
  }
  *(_DWORD *)(a1 + 94std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 940) & 0xFFFE0000 | v6 & 0x1FFFF;
  return result;
}

uint64_t ZinAneTd<10u>::SetTileDmaDstDataSetId(uint64_t result, char a2)
{
  *(unsigned char *)(result + 865) = a2;
  return result;
}

uint64_t ZinAneTd<10u>::SetFillLowerNEFirst(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 0x20000000;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 308) = *(_DWORD *)(result + 308) & 0xDFFFFFFF | v2;
  return result;
}

uint64_t ZinAneTd<10u>::SetArgOutputSelect(uint64_t result, int a2)
{
  if ((a2 - 6) > 5) {
    int v2 = 0x100000;
  }
  else {
    int v2 = dword_211F043B4[a2 - 6];
  }
  *(_DWORD *)(result + 816) = *(_DWORD *)(result + 816) & 0xFF0FFFFF | v2;
  return result;
}

uint64_t ZinAneTd<10u>::SetMaxPoolMode(uint64_t result, unsigned int a2)
{
  if (a2 <= 0xE && ((1 << a2) & 0x48E2) != 0) {
    unsigned int v2 = *(_DWORD *)(result + 816) | 0x80000;
  }
  else {
    unsigned int v2 = *(_DWORD *)(result + 816) & 0xFFF7FFFF;
  }
  *(_DWORD *)(result + 816) = v2;
  return result;
}

BOOL ZinAneTd<10u>::SetKernelStrideRegisters(uint64_t a1, unsigned int a2, unsigned int a3)
{
  int v7 = 0;
  if (!ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 688), &v7)) {
    ZinAssertImpl("Illegal Kernel Group Stride");
  }
  *(_DWORD *)(a1 + 6std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 60) & 0x3F | (v7 << 6);
  int v6 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a3, (unsigned int *)(*(void *)(a1 + 992) + 680), &v6);
  if (!result) {
    ZinAssertImpl("Illegal Kernel OCG Stride");
  }
  *(_DWORD *)(a1 + 64) = *(_DWORD *)(a1 + 64) & 0x3F | (v6 << 6);
  return result;
}

uint64_t ZinAneTd<10u>::SetKernelSparseBlockSize(uint64_t result, char a2)
{
  *(_DWORD *)(result + 812) = *(_DWORD *)(result + 812) & 0xFF1FFFFF | ((a2 & 7) << 21);
  return result;
}

uint64_t ZinAneTd<10u>::SetRcasKeyMask(uint64_t result, char a2)
{
  *(unsigned char *)(result + 8std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = a2;
  return result;
}

uint64_t ZinAneTd<10u>::SetRcasMode(uint64_t result, int a2)
{
  switch(a2)
  {
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 832) & 0xFFEFFFFF;
LABEL_7:
      *(_DWORD *)(result + 8std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = v2;
      return result;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 832) | 0x100000;
      goto LABEL_7;
    case 0:
      ZinAssertImpl("Unknown RCAS Mode.\n");
  }
  return result;
}

uint64_t ZinAneTd<10u>::SetRcasSenseAxis(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 832) | 0x3000;
      goto LABEL_6;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 832) & 0xFFFFCFFF | 0x1000;
      goto LABEL_6;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 832) & 0xFFFFCFFF | 0x2000;
      goto LABEL_6;
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 832) & 0xFFFFCFFF;
LABEL_6:
      *(_DWORD *)(result + 8std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = v2;
      break;
    case 4:
    case 5:
      ZinAssertImpl("Unknown RCAS Sense Axis.\n");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<10u>::SetRcasSenseBit(uint64_t result, char a2)
{
  *(_DWORD *)(result + 8std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_DWORD *)(result + 832) & 0xFFF0FFFF | ((a2 & 0xF) << 16);
  return result;
}

uint64_t ZinAneTd<10u>::SetRcasCmpBit(uint64_t result, char a2)
{
  *(_DWORD *)(result + 8std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_DWORD *)(result + 832) & 0xFFFFF8FF | ((a2 & 7) << 8);
  return result;
}

uint64_t ZinAneTd<10u>::SetGroupKernelReuse(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 1024;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 812) = *(_DWORD *)(result + 812) & 0xFFFFFBFF | v2;
  if (a2) {
    int v3 = 16;
  }
  else {
    int v3 = 0;
  }
  *(_DWORD *)(result + 44) = *(_DWORD *)(result + 44) & 0xFFFFFFEF | v3;
  return result;
}

uint64_t ZinAneTd<10u>::SetKernelSparseFmt(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 256;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 812) = *(_DWORD *)(result + 812) & 0xFFFFFEFF | v2;
  if (a2) {
    int v3 = 32;
  }
  else {
    int v3 = 0;
  }
  *(_DWORD *)(result + 44) = *(_DWORD *)(result + 44) & 0xFFFFFFDF | v3;
  return result;
}

uint64_t ZinAneTd<10u>::SetKernelSparseBinary(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 0x8000;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 812) = *(_DWORD *)(result + 812) & 0xFFFF7FFF | v2;
  return result;
}

uint64_t ZinAneTd<10u>::SetKernelPalettizedEn(uint64_t result, int a2)
{
  int v2 = 0;
  switch(a2)
  {
    case 0:
    case 3:
    case 28:
    case 29:
    case 30:
    case 31:
    case 32:
      ZinAssertImpl("Unknown kernel format in codegen\n");
    case 7:
    case 8:
    case 9:
    case 10:
    case 11:
    case 12:
    case 13:
    case 14:
    case 19:
    case 20:
    case 21:
    case 22:
    case 23:
    case 24:
    case 25:
    case 26:
    case 27:
      int v2 = 4;
      break;
    case 15:
    case 16:
    case 17:
    case 18:
      ZinAssertImpl("Invalid kernel format");
    default:
      break;
  }
  *(_DWORD *)(result + 812) = *(_DWORD *)(result + 812) & 0xFFFFFFFB | v2;
  return result;
}

uint64_t ZinAneTd<10u>::SetKernelPalettizedBits(uint64_t result, int a2)
{
  int v2 = 128;
  switch(a2)
  {
    case 0:
    case 3:
    case 28:
    case 29:
    case 30:
    case 31:
    case 32:
      ZinAssertImpl("Unknown kernel format in codegen\n");
    case 7:
    case 8:
    case 9:
    case 10:
      int v2 = 16;
      break;
    case 11:
    case 12:
    case 13:
    case 14:
      int v2 = 32;
      break;
    case 15:
    case 16:
    case 17:
    case 18:
      ZinAssertImpl("Invalid kernel format");
    case 19:
    case 20:
    case 21:
    case 22:
      int v2 = 64;
      break;
    case 23:
    case 24:
    case 25:
    case 26:
      int v2 = 96;
      break;
    default:
      break;
  }
  *(_DWORD *)(result + 812) = *(_DWORD *)(result + 812) & 0xFFFFFF0F | v2;
  return result;
}

uint64_t ZinAneTd<10u>::SetStochasticRoundMode(uint64_t result, int a2)
{
  if (a2 != 1 && a2 != 2)
  {
    if (!a2) {
      ZinAssertImpl("Invalid stochastic rounding mode");
    }
    a2 = 0;
  }
  *(_DWORD *)(result + 836) = *(_DWORD *)(result + 836) & 0xFFFFFFFC | a2;
  return result;
}

uint64_t ZinAneTd<10u>::SetStochasticRoundSeed(uint64_t result, int a2, uint64_t a3)
{
  *(_DWORD *)(result + 4 * a3 + 84std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = a2;
  return result;
}

uint64_t ZinAneTd<10u>::SetStochasticRoundIntegerBits(uint64_t result, char a2)
{
  *(_DWORD *)(result + 836) = *(_DWORD *)(result + 836) & 0xFFFFFE0F | (16 * (a2 & 0x1F));
  return result;
}

uint64_t ZinAneTd<10u>::SetNEBinaryPoint(uint64_t result, char a2)
{
  *(_DWORD *)(result + 816) = *(_DWORD *)(result + 816) & 0xFFFFE0FF | ((a2 & 0x1F) << 8);
  return result;
}

uint64_t ZinAneTd<10u>::SetNENonLinearMode(uint64_t result, int a2, uint64_t a3)
{
  if (a2)
  {
    if (a2 == 1)
    {
      a2 = 0x10000;
    }
    else
    {
      unsigned int v4 = *(_DWORD **)a3;
      int v3 = *(_DWORD **)(a3 + 8);
      if (*(_DWORD **)a3 != v3)
      {
        while (*v4 != a2)
        {
          if (++v4 == v3)
          {
            unsigned int v4 = *(_DWORD **)(a3 + 8);
            break;
          }
        }
      }
      if (v4 == v3) {
        ZinAssertImpl("Error: illegal non-linear mode\n");
      }
      a2 = 0x20000;
    }
  }
  *(_DWORD *)(result + 816) = *(_DWORD *)(result + 816) & 0xFFFCFFFF | a2;
  return result;
}

uint64_t ZinAneTd<10u>::SetNEPostScale(uint64_t result, unint64_t a2, char a3)
{
  _S0 = a2;
  __asm { FCVT            H0, S0 }
  int v8 = _S0;
  if (!_ZF) {
    int v8 = 0;
  }
  int v9 = ((a2 & 0xFF0000000000) != 0) << 14;
  int v10 = -((a2 >> 16) & 0x1F0000) & 0x1F0000 | v8;
  if (!a3)
  {
    int v9 = 0;
    int v10 = 15360;
  }
  *(_DWORD *)(result + 816) = *(_DWORD *)(result + 816) & 0xFFFFBFFF | v9;
  *(_DWORD *)(result + 828) = v10 | *(_DWORD *)(result + 828) & 0xFFE00000;
  return result;
}

uint64_t ZinAneTd<10u>::SetNEBias(uint64_t result, unint64_t a2, char a3)
{
  _S0 = a2;
  __asm { FCVT            H0, S0 }
  int v8 = _S0;
  if (!_ZF) {
    int v8 = 0;
  }
  int v9 = 16 * ((a2 & 0xFF0000000000) != 0);
  int v10 = (a2 >> 16) & 0x1F0000 | v8;
  if (!a3)
  {
    int v9 = 0;
    int v10 = 0;
  }
  *(_DWORD *)(result + 816) = *(_DWORD *)(result + 816) & 0xFFFFFFEF | v9;
  *(_DWORD *)(result + 824) = v10 | *(_DWORD *)(result + 824) & 0xFFE00000;
  return result;
}

ZinIrKernel *ZinAneTd<10u>::SetNEMatrixVectorBias(uint64_t a1, ZinIrKernel **a2, uint64_t a3)
{
  BOOL result = *a2;
  if (*a2) {
    _ZF = (a3 & 0xFF00000000) == 0;
  }
  else {
    _ZF = 1;
  }
  if (_ZF)
  {
    int v6 = 0;
  }
  else
  {
    _S8 = *(float *)&a3;
    BOOL result = (ZinIrKernel *)ZinIrKernel::GetWeightFormat(result);
    if (result == 4)
    {
      __asm { FCVT            H0, S8 }
      LOWORD(v8) = _H0;
    }
    else
    {
      if (result != 2 && result != 1) {
        ZinAssertImpl("Error: Invalid kernel format");
      }
      int v8 = (int)_S8;
    }
    *(_WORD *)(a1 + 82std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v8;
    int v6 = 64;
  }
  *(_DWORD *)(a1 + 816) = *(_DWORD *)(a1 + 816) & 0xFFFFFFBF | v6;
  return result;
}

uint64_t ZinAneTd<10u>::SetNEOcgSize(uint64_t result, char a2)
{
  *(_DWORD *)(result + 28std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 280) & 0xFFFFFFF8 | a2 & 7;
  return result;
}

uint64_t ZinAneTd<10u>::SetOutputTranspose(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 0x10000000;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 308) = *(_DWORD *)(result + 308) & 0xEFFFFFFF | v2;
  return result;
}

uint64_t ZinAneTd<10u>::SetNESmallSourceMode(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 308) & 0xFFFFFFF3;
      goto LABEL_6;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 308) & 0xFFFFFFF3 | 4;
      goto LABEL_6;
    case 2:
      ZinAssertImpl("Error: Tiny source mode is not supported for this arch");
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 308) | 0xC;
      goto LABEL_6;
    case 4:
      unsigned int v2 = *(_DWORD *)(result + 308) & 0xFFFFFFF3 | 8;
LABEL_6:
      *(_DWORD *)(result + 308) = v2;
      break;
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<10u>::GetNESmallSourceMode(uint64_t a1)
{
  return *(unsigned int *)((char *)&unk_211ED50F0 + (*(_DWORD *)(a1 + 308) & 0xC));
}

uint64_t ZinAneTd<10u>::SetTileDmaSrcDma1UserTag(uint64_t result, char a2)
{
  *(unsigned char *)(result + 338) = a2;
  return result;
}

uint64_t ZinAneTd<10u>::SetTileDmaSrcDma2UserTag(uint64_t result, char a2)
{
  *(unsigned char *)(result + 342) = a2;
  return result;
}

uint64_t ZinAneTd<10u>::SetTileDmaSrcCompressedMdUserTag(uint64_t result, char a2)
{
  *(unsigned char *)(result + 459) = a2;
  return result;
}

uint64_t ZinAneTd<10u>::SetTileDmaSrcCompressed2MdUserTag(uint64_t result, char a2)
{
  *(unsigned char *)(result + 475) = a2;
  return result;
}

uint64_t ZinAneTd<10u>::SetTileDmaDstUserTag(uint64_t result, char a2)
{
  *(unsigned char *)(result + 866) = a2;
  return result;
}

int8x16_t ZinAneTd<10u>::SetKernelDmaSrcCoeffUserTag(uint64_t a1, unsigned __int8 a2)
{
  int8x16_t result = vorrq_s8((int8x16_t)(*(_OWORD *)(a1 + 68) & __PAIR128__(0xFF00FFFFFF00FFFFLL, 0xFF00FFFFFF00FFFFLL)), (int8x16_t)vdupq_n_s32(a2 << 16));
  *(int8x16_t *)(a1 + 68) = result;
  return result;
}

uint64_t ZinAneTd<10u>::SetKernelDmaSrcPostScaleUserTag(uint64_t result, char a2)
{
  *(unsigned char *)(result + 134) = a2;
  return result;
}

uint64_t ZinAneTd<10u>::SetKernelDmaSrcPaletteLutUserTag(uint64_t result, char a2)
{
  *(unsigned char *)(result + 15std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = a2;
  return result;
}

uint64_t ZinAneTd<10u>::SetKernelDmaSrcBiasUserTag(uint64_t result, char a2)
{
  *(unsigned char *)(result + 118) = a2;
  return result;
}

uint64_t ZinAneTd<10u>::SetKernelDmaSrcNonLinearLutUserTag(uint64_t result, char a2)
{
  *(unsigned char *)(result + 166) = a2;
  return result;
}

uint64_t ZinAneTd<10u>::SetCommonTaskType(uint64_t result, unsigned int a2)
{
  if (a2 <= 7) {
    *(_DWORD *)(result + 308) = *(_DWORD *)(result + 308) & 0xFFFFFF0F | dword_211F043CC[a2];
  }
  return result;
}

uint64_t ZinAneTd<10u>::SetCommonInFmt(uint64_t result, int a2)
{
  if (a2 > 2)
  {
    if (a2 == 3)
    {
      unsigned int v2 = *(_DWORD *)(result + 260) & 0xFFFFFFFC | 2;
      goto LABEL_8;
    }
    if (a2 == 12) {
      ZinAssertImpl("Error: Invalid Common InFmt E4M3");
    }
LABEL_11:
    ZinAssertImpl("Error: Invalid TD programming for Src1 input format");
  }
  if (a2 == 1)
  {
    unsigned int v2 = *(_DWORD *)(result + 260) & 0xFFFFFFFC | 1;
    goto LABEL_8;
  }
  if (a2 != 2) {
    goto LABEL_11;
  }
  unsigned int v2 = *(_DWORD *)(result + 260) & 0xFFFFFFFC;
LABEL_8:
  *(_DWORD *)(result + 26std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2;
  return result;
}

uint64_t ZinAneTd<10u>::SetCommonSrc2InFmt(uint64_t result, int a2)
{
  if (a2 > 2)
  {
    if (a2 == 3)
    {
      unsigned int v2 = *(_DWORD *)(result + 260) & 0xFFFFFFF3 | 8;
      goto LABEL_8;
    }
    if (a2 == 12) {
      ZinAssertImpl("Error: Invalid TD programming for Src2 input format: E4M3");
    }
LABEL_11:
    ZinAssertImpl("Error: Invalid TD programming for Src2 input format");
  }
  if (a2 == 1)
  {
    unsigned int v2 = *(_DWORD *)(result + 260) & 0xFFFFFFF3 | 4;
    goto LABEL_8;
  }
  if (a2 != 2) {
    goto LABEL_11;
  }
  unsigned int v2 = *(_DWORD *)(result + 260) & 0xFFFFFFF3;
LABEL_8:
  *(_DWORD *)(result + 26std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2;
  return result;
}

uint64_t ZinAneTd<10u>::SetCommonOutFmt(uint64_t result, int a2)
{
  if ((a2 - 3) < 9) {
    goto LABEL_2;
  }
  if (a2 <= 11)
  {
    if (a2 == 1)
    {
      unsigned int v2 = *(_DWORD *)(result + 260) & 0xFFFFFFCF | 0x10;
      goto LABEL_3;
    }
    if (a2 == 2)
    {
      unsigned int v2 = *(_DWORD *)(result + 260) & 0xFFFFFFCF;
      goto LABEL_3;
    }
LABEL_12:
    ZinAssertImpl("Error: Invalid output format");
  }
  if (a2 != 13)
  {
    if (a2 == 12) {
      ZinAssertImpl("Error: E4M3 is not supported");
    }
    goto LABEL_12;
  }
LABEL_2:
  unsigned int v2 = *(_DWORD *)(result + 260) & 0xFFFFFFCF | 0x20;
LABEL_3:
  *(_DWORD *)(result + 26std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2;
  return result;
}

BOOL ZinAneTd<10u>::SetPatchHeight(uint64_t a1, unint64_t a2)
{
  *(_DWORD *)(a1 + 30std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 300) & 0xFFFFFF0F | (16 * (a2 & 0xF));
  return CheckRegValueRange(a2, (unsigned int *)(*(void *)(a1 + 992) + 288));
}

BOOL ZinAneTd<10u>::SetPatchWidth(uint64_t a1, unint64_t a2)
{
  *(_DWORD *)(a1 + 30std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 300) & 0xFFFFFFF0 | a2 & 0xF;
  return CheckRegValueRange(a2, (unsigned int *)(*(void *)(a1 + 992) + 280));
}

BOOL ZinAneTd<10u>::SetTileHeight(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 200), &v4);
  if (result) {
    *(_DWORD *)(a1 + 296) = *(_DWORD *)(a1 + 296) & 0xFFFF8000 | v4 & 0x7FFF;
  }
  return result;
}

BOOL ZinAneTd<10u>::SetTileOverlap(uint64_t a1, unint64_t a2)
{
  *(_DWORD *)(a1 + 296) = *(_DWORD *)(a1 + 296) & 0xFFE0FFFF | ((a2 & 0x1F) << 16);
  return CheckRegValueRange(a2, (unsigned int *)(*(void *)(a1 + 992) + 216));
}

BOOL ZinAneTd<10u>::SetTileOverlapPadBottom(uint64_t a1, unint64_t a2)
{
  *(_DWORD *)(a1 + 296) = *(_DWORD *)(a1 + 296) & 0x83FFFFFF | ((a2 & 0x1F) << 26);
  return CheckRegValueRange(a2, (unsigned int *)(*(void *)(a1 + 992) + 224));
}

BOOL ZinAneTd<10u>::SetTileOverlapPadTop(uint64_t a1, unint64_t a2)
{
  *(_DWORD *)(a1 + 296) = *(_DWORD *)(a1 + 296) & 0xFC1FFFFF | ((a2 & 0x1F) << 21);
  return CheckRegValueRange(a2, (unsigned int *)(*(void *)(a1 + 992) + 208));
}

BOOL ZinAneTd<10u>::SetCommonConvCfgKh(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 128), &v4);
  if (result) {
    *(_DWORD *)(a1 + 284) = *(_DWORD *)(a1 + 284) & 0xFFFFF03F | ((v4 & 0x3F) << 6);
  }
  return result;
}

BOOL ZinAneTd<10u>::SetCommonConvCfgKw(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 136), &v4);
  if (result) {
    *(_DWORD *)(a1 + 284) = *(_DWORD *)(a1 + 284) & 0xFFFFFFC0 | v4 & 0x3F;
  }
  return result;
}

BOOL ZinAneTd<10u>::SetCommonConvCfg3dKd(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 168), &v4);
  if (result) {
    *(_DWORD *)(a1 + 288) = *(_DWORD *)(a1 + 288) & 0xFFFFFFE0 | v4 & 0x1F;
  }
  return result;
}

BOOL ZinAneTd<10u>::SetCommonConvCfgSx(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 120), &v4);
  if (result) {
    *(_DWORD *)(a1 + 284) = *(_DWORD *)(a1 + 284) & 0xFFFF9FFF | ((v4 & 3) << 13);
  }
  return result;
}

BOOL ZinAneTd<10u>::SetCommonConvCfgSy(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 112), &v4);
  if (result) {
    *(_DWORD *)(a1 + 284) = *(_DWORD *)(a1 + 284) & 0xFFFE7FFF | ((v4 & 3) << 15);
  }
  return result;
}

BOOL ZinAneTd<10u>::SetCommonConvCfg3dSz(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 144), &v4);
  if (result) {
    *(_DWORD *)(a1 + 288) = *(_DWORD *)(a1 + 288) & 0xFFFFFF3F | ((v4 & 3) << 6);
  }
  return result;
}

BOOL ZinAneTd<10u>::SetCommonConvCfgOx(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 88), &v4);
  if (result) {
    *(_DWORD *)(a1 + 284) = *(_DWORD *)(a1 + 284) & 0xCFFFFFFF | ((v4 & 3) << 28);
  }
  return result;
}

BOOL ZinAneTd<10u>::SetCommonConvCfgOy(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 80), &v4);
  if (result) {
    *(_DWORD *)(a1 + 284) = *(_DWORD *)(a1 + 284) & 0x3FFFFFFF | (v4 << 30);
  }
  return result;
}

BOOL ZinAneTd<10u>::SetCommonConvCfg3dOz(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 160), &v4);
  if (result) {
    *(_DWORD *)(a1 + 288) = *(_DWORD *)(a1 + 288) & 0xFFFF9FFF | ((v4 & 3) << 13);
  }
  return result;
}

BOOL ZinAneTd<10u>::SetCommonConvCfgPadLeft(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 104), &v4);
  if (result) {
    *(_DWORD *)(a1 + 284) = *(_DWORD *)(a1 + 284) & 0xFFC1FFFF | ((v4 & 0x1F) << 17);
  }
  return result;
}

BOOL ZinAneTd<10u>::SetCommonConvCfgPadTop(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 96), &v4);
  if (result) {
    *(_DWORD *)(a1 + 284) = *(_DWORD *)(a1 + 284) & 0xF83FFFFF | ((v4 & 0x1F) << 22);
  }
  return result;
}

BOOL ZinAneTd<10u>::SetCommonConvCfg3dPz(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 152), &v4);
  if (result) {
    *(_DWORD *)(a1 + 288) = *(_DWORD *)(a1 + 288) & 0xFFFFF0FF | ((v4 & 0xF) << 8);
  }
  return result;
}

BOOL ZinAneTd<10u>::SetOrReturnNumGroups(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 184), &v4);
  if (result) {
    *(_DWORD *)(a1 + 292) = *(_DWORD *)(a1 + 292) & 0xFFFFE000 | v4 & 0x1FFF;
  }
  return result;
}

BOOL ZinAneTd<10u>::SetOrReturnWin(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 24), &v4);
  if (result) {
    *(_DWORD *)(a1 + 252) = *(_DWORD *)(a1 + 252) & 0xFFFF8000 | v4 & 0x7FFF;
  }
  return result;
}

BOOL ZinAneTd<10u>::SetOrReturnHin(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 16), &v4);
  if (result) {
    *(_DWORD *)(a1 + 252) = *(_DWORD *)(a1 + 252) & 0x8000FFFF | ((v4 & 0x7FFF) << 16);
  }
  return result;
}

BOOL ZinAneTd<10u>::SetOrReturnDin(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 32), &v4);
  if (result) {
    *(_DWORD *)(a1 + 256) = *(_DWORD *)(a1 + 256) & 0xFFFF8000 | v4 & 0x7FFF;
  }
  return result;
}

BOOL ZinAneTd<10u>::SetOrReturnCin(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 40), &v4);
  if (result) {
    *(_DWORD *)(a1 + 264) = *(_DWORD *)(a1 + 264) & 0xFFFE0000 | v4 & 0x1FFFF;
  }
  return result;
}

BOOL ZinAneTd<10u>::SetOrReturnWout(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 64), &v4);
  if (result) {
    *(_DWORD *)(a1 + 272) = *(_DWORD *)(a1 + 272) & 0xFFFF8000 | v4 & 0x7FFF;
  }
  return result;
}

BOOL ZinAneTd<10u>::SetOrReturnHout(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 56), &v4);
  if (result) {
    *(_DWORD *)(a1 + 272) = *(_DWORD *)(a1 + 272) & 0x8000FFFF | ((v4 & 0x7FFF) << 16);
  }
  return result;
}

BOOL ZinAneTd<10u>::SetOrReturnDout(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 72), &v4);
  if (result) {
    *(_DWORD *)(a1 + 276) = *(_DWORD *)(a1 + 276) & 0xFFFF8000 | v4 & 0x7FFF;
  }
  return result;
}

BOOL ZinAneTd<10u>::SetOrReturnCout(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 48), &v4);
  if (result) {
    *(_DWORD *)(a1 + 268) = *(_DWORD *)(a1 + 268) & 0xFFFE0000 | v4 & 0x1FFFF;
  }
  return result;
}

uint64_t ZinAneTd<10u>::SetUnicastEn(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 0x4000;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 292) = *(_DWORD *)(result + 292) & 0xFFFFBFFF | v2;
  return result;
}

BOOL ZinAneTd<10u>::SetUnicastCin(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 992) + 192), &v4);
  if (result) {
    *(_WORD *)(a1 + 294) = v4;
  }
  return result;
}

uint64_t ZinAneTd<11u>::SetWARdmaDependency(uint64_t result, uint64_t a2, int a3, unsigned __int8 a4, int **a5)
{
  if (*(unsigned char *)(a2 + 1323)) {
    ZinAssertImpl("inconsistent WAR support");
  }
  if (a3)
  {
    int v5 = *a5;
    int v6 = a5[1];
    if (*a5 != v6)
    {
      do
      {
        uint64_t v7 = *v5;
        if (v7 <= 2) {
          *(_DWORD *)(result + 960) |= dword_211F04350[v7];
        }
        ++v5;
      }
      while (v5 != v6);
    }
    *(_DWORD *)(result + 96std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 960) & 0xFFFFFFF | (a4 << 28);
  }
  return result;
}

uint64_t ZinAneTd<11u>::SetL2Barrier(uint64_t result)
{
  *(_DWORD *)(result + 548) |= 0x800000u;
  return result;
}

uint64_t ZinAneTd<11u>::SetEventFlags(uint64_t result, int a2, int a3, int a4)
{
  *(_DWORD *)(result + 16) = a2 & 0xFFFFFF | (*(unsigned __int8 *)(result + 19) << 24);
  if (a4) {
    ZinAssertImpl("DRAM Events not supported for architecture");
  }
  *(_DWORD *)(result + 24) = a3 & 0xFFFFFF | (*(unsigned __int8 *)(result + 27) << 24);
  return result;
}

BOOL ZinAneTd<11u>::SetL2SrcBaseAddress(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1040) + 296), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src Base Address");
  }
  *(_DWORD *)(a1 + 804) = *(_DWORD *)(a1 + 804) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<11u>::SetL2Src1ChannelStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x11uLL, (unsigned int *)(*(void *)(a1 + 1040) + 304), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src Channel Stride");
  }
  *(_DWORD *)(a1 + 808) = *(_DWORD *)(a1 + 808) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<11u>::SetL2SrcRowStride(uint64_t a1, ZinCodegen *this, ZinTensorDimensions *a3, uint64_t a4, uint64_t *a5)
{
  int v8 = 0;
  ZinCodegen::GetL2RowStride(this, a3, *(unsigned int *)(*(void *)(a1 + 1040) + 316), &v8, a5);
  unsigned int v7 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(v8, 0x11uLL, (unsigned int *)(*(void *)(a1 + 1040) + 312), &v7);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src Row Stride");
  }
  *(_DWORD *)(a1 + 812) = *(_DWORD *)(a1 + 812) & 0xFFE0000F | (16 * (v7 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<11u>::SetL2Src1DepthStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x11uLL, (unsigned int *)(*(void *)(a1 + 1040) + 328), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src Depth Stride");
  }
  *(_DWORD *)(a1 + 816) = *(_DWORD *)(a1 + 816) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<11u>::SetL2Src1GroupStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x11uLL, (unsigned int *)(*(void *)(a1 + 1040) + 336), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src Group Stride");
  }
  *(_DWORD *)(a1 + 82std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 820) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

uint64_t ZinAneTd<11u>::SetL2Src1DmaFormat(uint64_t result, int a2)
{
  switch(a2)
  {
    case 1:
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 800) & 0xFFFFFF3F;
      break;
    case 3:
    case 4:
    case 5:
    case 6:
    case 7:
    case 9:
    case 10:
      unsigned int v2 = *(_DWORD *)(result + 800) & 0xFFFFFF3F | 0x40;
      break;
    case 8:
      ZinAssertImpl("Packed10 format not fully implemented yet\n");
    case 11:
      unsigned int v2 = *(_DWORD *)(result + 800) | 0xC0;
      break;
    case 12:
    case 13:
      ZinAssertImpl("E4M3 or E5M2 format not supported");
    default:
      ZinAssertImpl("Invalid Dma Format");
  }
  *(_DWORD *)(result + 80std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2;
  return result;
}

uint64_t ZinAneTd<11u>::SetL2ResultCfgDmaFmt(uint64_t result, int a2)
{
  switch(a2)
  {
    case 1:
    case 2:
    case 12:
    case 13:
      unsigned int v2 = *(_DWORD *)(result + 844) & 0xFFFFFF3F;
      break;
    case 3:
    case 4:
    case 5:
    case 6:
    case 7:
    case 9:
    case 10:
      unsigned int v2 = *(_DWORD *)(result + 844) & 0xFFFFFF3F | 0x40;
      break;
    case 8:
      ZinAssertImpl("packed10 format not fully implemented yet");
    case 11:
      unsigned int v2 = *(_DWORD *)(result + 844) | 0xC0;
      break;
    default:
      ZinAssertImpl("Invalid tensor format");
  }
  *(_DWORD *)(result + 844) = v2;
  return result;
}

uint64_t ZinAneTd<11u>::SetL2ResultWrapCfg(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 872) & 0xFFFFF8FF | 0x400;
      goto LABEL_7;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 872) & 0xFFFFF8FF | 0x300;
      goto LABEL_7;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 872) & 0xFFFFF8FF | 0x100;
      goto LABEL_7;
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 872) & 0xFFFFF8FF | 0x200;
      goto LABEL_7;
    case 4:
      ZinAssertImpl("Error: Invalid Wrap Axis");
    case 5:
      unsigned int v2 = *(_DWORD *)(result + 872) & 0xFFFFF8FF;
LABEL_7:
      *(_DWORD *)(result + 872) = v2;
      break;
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<11u>::SetL2ResultWrapStartOffset(uint64_t result, __int16 a2)
{
  *(_WORD *)(result + 886) = a2;
  return result;
}

uint64_t ZinAneTd<11u>::SetL2ResultWrapIndex(uint64_t result, __int16 a2)
{
  *(_WORD *)(result + 884) = a2;
  return result;
}

uint64_t ZinAneTd<11u>::SetL2SrcOffsetYlsbsFromCropOffsetY(uint64_t a1)
{
  uint64_t result = ZinExtractLSBs(*(unsigned __int16 *)(a1 + 676), 2);
  *(_DWORD *)(a1 + 80std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 800) & 0x3FFFFFFF | (result << 30);
  return result;
}

uint64_t ZinAneTd<11u>::SetSourceWrap(uint64_t result, unsigned int a2, unsigned __int16 a3, unsigned __int16 a4)
{
  if (a2 >= 4) {
    ZinAssertImpl("Source wrapping dimension not acceptable\n");
  }
  *(_DWORD *)(result + 872) = *(_DWORD *)(result + 872) & 0xFFFFFFF8 | dword_211F04410[a2];
  *(_DWORD *)(result + 876) = a4 | (a3 << 16);
  return result;
}

BOOL ZinAneTd<11u>::SetL2Src1Interleave(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1040) + 592), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Source Interleave");
  }
  *(_DWORD *)(a1 + 80std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 800) & 0xFFFFF0FF | ((v4 & 0xF) << 8);
  return result;
}

uint64_t ZinAneTd<11u>::SetL2Src1SourceType(uint64_t result, int a2)
{
  int v2 = 0;
  switch(a2)
  {
    case 0:
      ZinAssertImpl("Error: It must have a valid L2 access mode");
    case 1:
      int v2 = 2;
      break;
    case 2:
      int v2 = 1;
      break;
    case 4:
      int v2 = 3;
      break;
    default:
      break;
  }
  *(_DWORD *)(result + 80std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 800) & 0xFFFFFFFC | v2;
  return result;
}

uint64_t ZinAneTd<11u>::SetL2Src2SourceType(uint64_t result, int a2)
{
  int v2 = 0;
  switch(a2)
  {
    case 0:
      ZinAssertImpl("Error: It must have a valid L2 access mode");
    case 1:
      int v2 = 0x1000000;
      break;
    case 2:
      int v2 = 0x800000;
      break;
    case 4:
      int v2 = 25165824;
      break;
    default:
      break;
  }
  *(_DWORD *)(result + 80std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 800) & 0xFE7FFFFF | v2;
  return result;
}

BOOL ZinAneTd<11u>::SetL2Src2BaseAddress(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1040) + 344), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src2 Base Address");
  }
  *(_DWORD *)(a1 + 824) = *(_DWORD *)(a1 + 824) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<11u>::SetL2Src2ChannelStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x11uLL, (unsigned int *)(*(void *)(a1 + 1040) + 352), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Source 2 Channel Stride");
  }
  *(_DWORD *)(a1 + 828) = *(_DWORD *)(a1 + 828) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<11u>::SetL2Src2RowStride(uint64_t a1, ZinCodegen *this, ZinTensorDimensions *a3, uint64_t a4, uint64_t *a5)
{
  int v8 = 0;
  ZinCodegen::GetL2RowStride(this, a3, *(unsigned int *)(*(void *)(a1 + 1040) + 364), &v8, a5);
  unsigned int v7 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(v8, 0x11uLL, (unsigned int *)(*(void *)(a1 + 1040) + 360), &v7);
  if (!result) {
    ZinAssertImpl("Illegal L2 Source 2 Row Stride");
  }
  *(_DWORD *)(a1 + 8std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_DWORD *)(a1 + 832) & 0xFFE0000F | (16 * (v7 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<11u>::SetL2Src2DepthStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x11uLL, (unsigned int *)(*(void *)(a1 + 1040) + 368), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Source 2 Depth Stride");
  }
  *(_DWORD *)(a1 + 836) = *(_DWORD *)(a1 + 836) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<11u>::SetL2Src2GroupStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x11uLL, (unsigned int *)(*(void *)(a1 + 1040) + 376), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Source 2 Group Stride");
  }
  *(_DWORD *)(a1 + 84std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 840) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

uint64_t ZinAneTd<11u>::SetL2Src1CfgForCompression(uint64_t result, int a2)
{
  unsigned int v2 = *(_DWORD *)(result + 800) & 0xF7F80FFF;
  *(_DWORD *)(result + 80std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2 | 0x8000000;
  switch(a2)
  {
    case 1:
      unsigned int v3 = v2 & 0xE7F80FFF | 0x8000000;
LABEL_7:
      *(_DWORD *)(result + 80std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v3;
      return result;
    case 2:
      unsigned int v3 = v2 | 0x18000000;
      goto LABEL_7;
    case 0:
      ZinAssertImpl("Invalid macro block size");
  }
  return result;
}

uint64_t ZinAneTd<11u>::SetSource2Wrap(uint64_t result, unsigned int a2, unsigned __int16 a3, unsigned __int16 a4)
{
  if (a2 >= 4) {
    ZinAssertImpl("Source wrapping dimension not acceptable\n");
  }
  *(_DWORD *)(result + 872) = *(_DWORD *)(result + 872) & 0xFFFFFF8F | dword_211F04420[a2];
  *(_DWORD *)(result + 88std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = a4 | (a3 << 16);
  return result;
}

uint64_t ZinAneTd<11u>::SetOpMode(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 936) & 0xFFFFFFF8;
      goto LABEL_7;
    case 1:
      ZinAssertImpl("ElemWise not valid for architecture");
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 936) & 0xFFFFFFF8 | 3;
      goto LABEL_7;
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 936) & 0xFFFFFFF8 | 1;
      goto LABEL_7;
    case 4:
      unsigned int v2 = *(_DWORD *)(result + 936) & 0xFFFFFFF8 | 2;
      goto LABEL_7;
    case 5:
      unsigned int v2 = *(_DWORD *)(result + 936) & 0xFFFFFFF8 | 4;
LABEL_7:
      *(_DWORD *)(result + 936) = v2;
      break;
    case 6:
      ZinAssertImpl("RCAS not valid for architecture");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<11u>::SetKernelMode(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 936) & 0xFFFFFFF7;
LABEL_7:
      *(_DWORD *)(result + 936) = v2;
      return result;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 936) | 8;
      goto LABEL_7;
    case 2:
      ZinAssertImpl("Unsupported Kernel Mode");
  }
  return result;
}

uint64_t ZinAneTd<11u>::SetKernelFmt(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 932) & 0xFFFFFFFC;
      goto LABEL_5;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 932) & 0xFFFFFFFC | 1;
      goto LABEL_5;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 932) & 0xFFFFFFFC | 2;
LABEL_5:
      *(_DWORD *)(result + 9std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = v2;
      break;
    case 3:
      ZinAssertImpl("Unimplemented or Unsupported kernel format");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<11u>::SetKernelDmaSrcCoeffDmaCacheHint(uint64_t result, int a2, uint64_t a3)
{
  int v3 = 224;
  switch(a2)
  {
    case 0:
      goto LABEL_5;
    case 1:
      int v3 = 32;
      goto LABEL_5;
    case 2:
      int v3 = 64;
      goto LABEL_5;
    case 3:
      int v3 = 192;
LABEL_5:
      *(_DWORD *)(result + 4 * a3 + 68) = *(_DWORD *)(result + 4 * a3 + 68) & 0xFFFFFF0F | v3;
      break;
    case 4:
      ZinAssertImpl("Error: Invalid KernelDmaSrc CoeffDma CacheHint");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<11u>::SetKernelDmaSrcHeaderDmaCacheHint(uint64_t result, int a2, uint64_t a3)
{
  int v3 = 224;
  switch(a2)
  {
    case 0:
      goto LABEL_5;
    case 1:
      int v3 = 32;
      goto LABEL_5;
    case 2:
      int v3 = 64;
      goto LABEL_5;
    case 3:
      int v3 = 192;
LABEL_5:
      *(_DWORD *)(result + 4 * a3 + 26std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 4 * a3 + 260) & 0xFFFFFF0F | v3;
      break;
    case 4:
      ZinAssertImpl("Error: Invalid KernelDmaSrc PostScale Dma CacheHint");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<11u>::SetKernelDmaSrcPostScaleDmaCacheHint(uint64_t a1, int a2)
{
  return ZinAneTd<11u>::SetKernelDmaSrcHeaderDmaCacheHint(a1, a2, 1);
}

uint64_t ZinAneTd<11u>::SetKernelDmaSrcBiasDmaCacheHint(uint64_t a1, int a2)
{
  return ZinAneTd<11u>::SetKernelDmaSrcHeaderDmaCacheHint(a1, a2, 0);
}

uint64_t ZinAneTd<11u>::SetKernelDmaSrcPaletteLutDmaCacheHint(uint64_t a1, int a2)
{
  return ZinAneTd<11u>::SetKernelDmaSrcHeaderDmaCacheHint(a1, a2, 2);
}

uint64_t ZinAneTd<11u>::SetKernelDmaSrcNonLinearLutDmaCacheHint(uint64_t a1, int a2)
{
  return ZinAneTd<11u>::SetKernelDmaSrcHeaderDmaCacheHint(a1, a2, 3);
}

BOOL ZinAneTd<11u>::SetKernelDmaSrcCoeffMemBufferSize(uint64_t a1, unsigned int a2, uint64_t a3)
{
  int v6 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1040) + 568), &v6);
  if (result) {
    *(_DWORD *)(a1 + 4 * a3 + 196) = *(_DWORD *)(a1 + 4 * a3 + 196) & 0x3F | (v6 << 6);
  }
  return result;
}

BOOL ZinAneTd<11u>::SetKernelDmaSrcCoeffBaseOffset(uint64_t a1, unsigned int a2, uint64_t a3)
{
  int v6 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1040) + 560), &v6);
  if (result) {
    *(_DWORD *)(a1 + 4 * a3 + 1std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_DWORD *)(a1 + 4 * a3 + 132) & 0x3F | (v6 << 6);
  }
  return result;
}

uint64_t ZinAneTd<11u>::SetPaddingMode(uint64_t result, int a2, int a3)
{
  switch(a2)
  {
    case 1:
      if (a3) {
        goto LABEL_11;
      }
      int v3 = 0;
      int v4 = 0;
      break;
    case 2:
      if (a3) {
        goto LABEL_11;
      }
      int v3 = 0;
      int v4 = 4;
      break;
    case 3:
      if (a3) {
        goto LABEL_11;
      }
      int v4 = 8;
      int v3 = 0x40000;
      break;
    case 4:
      if (a3) {
LABEL_11:
      }
        ZinAssertImpl("Error: padding-mode doesn't support constants");
      int v3 = 0;
      int v4 = 12;
      break;
    case 6:
      ZinAssertImpl("Platform doesn't support reflective padding mode");
    case 9:
      ZinAssertImpl("Platform doesn't support constant padding-mode");
    default:
      ZinAssertImpl("Invalid padding mode: %d", a2);
  }
  *(_DWORD *)(result + 796) = *(_DWORD *)(result + 796) & 0xFFFFFFF3 | v4;
  *(_DWORD *)(result + 936) = *(_DWORD *)(result + 936) & 0xFFFBFFFF | v3;
  return result;
}

uint64_t ZinAneTd<11u>::SetKernelAlignmentFormat(uint64_t result, int a2)
{
  if (a2)
  {
    if (a2 != 1) {
      return result;
    }
    unsigned int v2 = *(_DWORD *)(result + 932) & 0xFFFEFFFF;
  }
  else
  {
    unsigned int v2 = *(_DWORD *)(result + 932) | 0x10000;
  }
  *(_DWORD *)(result + 9std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = v2;
  return result;
}

void ZinAneTd<11u>::SetAlignedKernelRelocationCommand(uint64_t a1, void *a2, uint64_t a3, const void **a4, uint64_t a5)
{
  if (a2[1])
  {
    if (*((char *)a4 + 23) >= 0) {
      size_t v10 = *((unsigned __int8 *)a4 + 23);
    }
    else {
      size_t v10 = (size_t)a4[1];
    }
    long long v11 = __p;
    std::string::basic_string[abi:ne180100]((uint64_t)__p, v10 + 7);
    if (v36 < 0) {
      long long v11 = (void **)__p[0];
    }
    if (v10)
    {
      if (*((char *)a4 + 23) >= 0) {
        uint64_t v12 = a4;
      }
      else {
        uint64_t v12 = *a4;
      }
      memmove(v11, v12, v10);
    }
    strcpy((char *)v11 + v10, "_actlut");
    ZinAneTdHw_v11::AddRelocInfo((uint64_t *)(a1 + 8), (uint64_t)__p, 1664, a3, 1, 1, a5, 0);
    if (v36 < 0) {
      operator delete(__p[0]);
    }
  }
  if (a2[2])
  {
    if (*((char *)a4 + 23) >= 0) {
      size_t v13 = *((unsigned __int8 *)a4 + 23);
    }
    else {
      size_t v13 = (size_t)a4[1];
    }
    int v14 = __p;
    std::string::basic_string[abi:ne180100]((uint64_t)__p, v13 + 7);
    if (v36 < 0) {
      int v14 = (void **)__p[0];
    }
    if (v13)
    {
      if (*((char *)a4 + 23) >= 0) {
        int v15 = a4;
      }
      else {
        int v15 = *a4;
      }
      memmove(v14, v15, v13);
    }
    strcpy((char *)v14 + v13, "_pallut");
    ZinAneTdHw_v11::AddRelocInfo((uint64_t *)(a1 + 8), (uint64_t)__p, 1663, a3, 1, 1, a5, 0);
    if (v36 < 0) {
      operator delete(__p[0]);
    }
  }
  if (a2[3])
  {
    if (*((char *)a4 + 23) >= 0) {
      size_t v16 = *((unsigned __int8 *)a4 + 23);
    }
    else {
      size_t v16 = (size_t)a4[1];
    }
    int v17 = __p;
    std::string::basic_string[abi:ne180100]((uint64_t)__p, v16 + 6);
    if (v36 < 0) {
      int v17 = (void **)__p[0];
    }
    if (v16)
    {
      if (*((char *)a4 + 23) >= 0) {
        uint64_t v18 = a4;
      }
      else {
        uint64_t v18 = *a4;
      }
      memmove(v17, v18, v16);
    }
    strcpy((char *)v17 + v16, "_scale");
    ZinAneTdHw_v11::AddRelocInfo((uint64_t *)(a1 + 8), (uint64_t)__p, 1662, a3, 1, 1, a5, 0);
    if (v36 < 0) {
      operator delete(__p[0]);
    }
  }
  if (a2[4])
  {
    if (*((char *)a4 + 23) >= 0) {
      size_t v19 = *((unsigned __int8 *)a4 + 23);
    }
    else {
      size_t v19 = (size_t)a4[1];
    }
    size_t v20 = __p;
    std::string::basic_string[abi:ne180100]((uint64_t)__p, v19 + 5);
    if (v36 < 0) {
      size_t v20 = (void **)__p[0];
    }
    if (v19)
    {
      if (*((char *)a4 + 23) >= 0) {
        long long v21 = a4;
      }
      else {
        long long v21 = *a4;
      }
      memmove(v20, v21, v19);
    }
    strcpy((char *)v20 + v19, "_bias");
    ZinAneTdHw_v11::AddRelocInfo((uint64_t *)(a1 + 8), (uint64_t)__p, 1661, a3, 1, 1, a5, 0);
    if (v36 < 0) {
      operator delete(__p[0]);
    }
    if (a2[4])
    {
      if (*((char *)a4 + 23) >= 0) {
        size_t v22 = *((unsigned __int8 *)a4 + 23);
      }
      else {
        size_t v22 = (size_t)a4[1];
      }
      long long v23 = __p;
      std::string::basic_string[abi:ne180100]((uint64_t)__p, v22 + 5);
      if (v36 < 0) {
        long long v23 = (void **)__p[0];
      }
      if (v22)
      {
        if (*((char *)a4 + 23) >= 0) {
          char v24 = a4;
        }
        else {
          char v24 = *a4;
        }
        memmove(v23, v24, v22);
      }
      strcpy((char *)v23 + v22, "_bias");
      ZinAneTdHw_v11::AddRelocInfo((uint64_t *)(a1 + 8), (uint64_t)__p, 1658, a3, 0, 1, a5, 0);
      if (v36 < 0) {
        operator delete(__p[0]);
      }
    }
  }
  if (a2[3])
  {
    if (*((char *)a4 + 23) >= 0) {
      size_t v25 = *((unsigned __int8 *)a4 + 23);
    }
    else {
      size_t v25 = (size_t)a4[1];
    }
    uint64_t v26 = __p;
    std::string::basic_string[abi:ne180100]((uint64_t)__p, v25 + 6);
    if (v36 < 0) {
      uint64_t v26 = (void **)__p[0];
    }
    if (v25)
    {
      if (*((char *)a4 + 23) >= 0) {
        long long v27 = a4;
      }
      else {
        long long v27 = *a4;
      }
      memmove(v26, v27, v25);
    }
    strcpy((char *)v26 + v25, "_scale");
    ZinAneTdHw_v11::AddRelocInfo((uint64_t *)(a1 + 8), (uint64_t)__p, 1659, a3, 0, 1, a5, 0);
    if (v36 < 0) {
      operator delete(__p[0]);
    }
  }
  if (a2[2])
  {
    if (*((char *)a4 + 23) >= 0) {
      size_t v28 = *((unsigned __int8 *)a4 + 23);
    }
    else {
      size_t v28 = (size_t)a4[1];
    }
    uint64_t v29 = __p;
    std::string::basic_string[abi:ne180100]((uint64_t)__p, v28 + 7);
    if (v36 < 0) {
      uint64_t v29 = (void **)__p[0];
    }
    if (v28)
    {
      if (*((char *)a4 + 23) >= 0) {
        long long v30 = a4;
      }
      else {
        long long v30 = *a4;
      }
      memmove(v29, v30, v28);
    }
    strcpy((char *)v29 + v28, "_pallut");
    ZinAneTdHw_v11::AddRelocInfo((uint64_t *)(a1 + 8), (uint64_t)__p, 1660, a3, 0, 1, a5, 0);
    if (v36 < 0) {
      operator delete(__p[0]);
    }
  }
  if (a2[1])
  {
    int v31 = (uint64_t *)(a1 + 8);
    if (*((char *)a4 + 23) >= 0) {
      size_t v32 = *((unsigned __int8 *)a4 + 23);
    }
    else {
      size_t v32 = (size_t)a4[1];
    }
    size_t v33 = __p;
    std::string::basic_string[abi:ne180100]((uint64_t)__p, v32 + 7);
    if (v36 < 0) {
      size_t v33 = (void **)__p[0];
    }
    if (v32)
    {
      if (*((char *)a4 + 23) >= 0) {
        uint64_t v34 = a4;
      }
      else {
        uint64_t v34 = *a4;
      }
      memmove(v33, v34, v32);
    }
    strcpy((char *)v33 + v32, "_actlut");
    ZinAneTdHw_v11::AddRelocInfo(v31, (uint64_t)__p, 1661, a3, 0, 1, a5, 0);
    if (v36 < 0) {
      operator delete(__p[0]);
    }
  }
}

void sub_2112D17F8(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, void *__p, uint64_t a10, int a11, __int16 a12, char a13, char a14)
{
  if (a14 < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

_DWORD *ZinAneTd<11u>::SetAlignedKernelBias(_DWORD *result, uint64_t a2, uint64_t a3, int a4)
{
  result[11] = result[11] & 0xFFFFFFF3 | 8;
  result[233] = result[233] & 0xFFF9FFFF | 0x40000;
  result[77] = result[77] & 0x3F | (a4 << 6);
  result[65] |= 1u;
  return result;
}

_DWORD *ZinAneTd<11u>::SetAlignedKernelPostScale(_DWORD *result, uint64_t a2, uint64_t a3, int a4)
{
  result[11] = result[11] & 0xFFFFFFFC | 2;
  result[233] = result[233] & 0xFFE7FFFF | 0x100000;
  result[78] = result[78] & 0x3F | (a4 << 6);
  result[66] |= 1u;
  return result;
}

uint64_t ZinAneTd<11u>::SetAlignedKernelPaletteLut(uint64_t result, uint64_t a2, uint64_t a3, int a4)
{
  *(_DWORD *)(result + 316) = *(_DWORD *)(result + 316) & 0x3F | (a4 << 6);
  *(_DWORD *)(result + 268) |= 1u;
  return result;
}

uint64_t ZinAneTd<11u>::SetAlignedKernelNonLinearLut(uint64_t result, uint64_t a2, uint64_t a3, int a4)
{
  *(_DWORD *)(result + 32std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 320) & 0x3F | (a4 << 6);
  *(_DWORD *)(result + 272) |= 1u;
  return result;
}

uint64_t ZinAneTd<11u>::SetPEFinalScale(uint64_t result, float a2)
{
  *(float *)(result + 916) = a2;
  return result;
}

__int16 ZinAneTd<11u>::SetPEScale@<H0>(uint64_t a1@<X0>, float _S0@<S0>)
{
  __asm { FCVT            H0, S0 }
  *(_WORD *)(a1 + 91std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = result;
  return result;
}

__int16 ZinAneTd<11u>::SetPEBias@<H0>(uint64_t a1@<X0>, float _S0@<S0>)
{
  __asm { FCVT            H0, S0 }
  *(_WORD *)(a1 + 908) = result;
  return result;
}

__int16 ZinAneTd<11u>::SetPEPreScale@<H0>(uint64_t a1@<X0>, float _S0@<S0>)
{
  __asm { FCVT            H0, S0 }
  *(_WORD *)(a1 + 914) = result;
  return result;
}

uint64_t ZinAneTd<11u>::SetPESrc1ReLu(uint64_t result, int a2)
{
  *(_DWORD *)(result + 796) = *(_DWORD *)(result + 796) & 0xFFFFFFFE | a2;
  return result;
}

uint64_t ZinAneTd<11u>::SetPESrc2ReLu(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 16;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 796) = *(_DWORD *)(result + 796) & 0xFFFFFFEF | v2;
  return result;
}

uint64_t ZinAneTd<11u>::SetPESrc1Transpose(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 256;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 544) = *(_DWORD *)(result + 544) & 0xFFFFFEFF | v2;
  return result;
}

uint64_t ZinAneTd<11u>::SetPESrc2Transpose(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 512;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 544) = *(_DWORD *)(result + 544) & 0xFFFFFDFF | v2;
  return result;
}

uint64_t ZinAneTd<11u>::SetPESrc1Broadcast(uint64_t result, uint64_t a2)
{
  for (uint64_t i = *(uint64_t **)(a2 + 16); i; uint64_t i = (uint64_t *)*i)
  {
    unsigned int v3 = *((_DWORD *)i + 4) - 1;
    if (v3 <= 3) {
      *(_DWORD *)(result + 544) |= dword_211F04430[v3];
    }
  }
  return result;
}

uint64_t ZinAneTd<11u>::SetPESrc2Broadcast(uint64_t result, uint64_t a2, char a3)
{
  for (uint64_t i = *(uint64_t **)(a2 + 16); i; uint64_t i = (uint64_t *)*i)
  {
    int v4 = 128;
    switch(*((_DWORD *)i + 4))
    {
      case 1:
        int v4 = 64;
        break;
      case 2:
        break;
      case 3:
        if (a3) {
          continue;
        }
        int v4 = 32;
        break;
      case 4:
        if (a3) {
          continue;
        }
        int v4 = 16;
        break;
      default:
        continue;
    }
    *(_DWORD *)(result + 544) |= v4;
  }
  return result;
}

uint64_t ZinAneTd<11u>::SetPEOperationMode(uint64_t a1, int a2)
{
  uint64_t v2 = 0;
  switch(a2)
  {
    case 0:
      *(_DWORD *)(a1 + 904) &= 0xFFFFFFE3;
      unsigned int v3 = (unsigned int *)(*(void *)(a1 + 1040) + 608);
      unint64_t v4 = 0;
      goto LABEL_8;
    case 1:
      *(_DWORD *)(a1 + 904) = *(_DWORD *)(a1 + 904) & 0xFFFFFFE3 | 4;
      unsigned int v3 = (unsigned int *)(*(void *)(a1 + 1040) + 608);
      unint64_t v4 = 1;
      goto LABEL_8;
    case 2:
      *(_DWORD *)(a1 + 904) = *(_DWORD *)(a1 + 904) & 0xFFFFFFE3 | 0x10;
      if (!CheckRegValueRange(4uLL, (unsigned int *)(*(void *)(a1 + 1040) + 608))) {
        goto LABEL_5;
      }
      goto LABEL_9;
    case 3:
      *(_DWORD *)(a1 + 904) = *(_DWORD *)(a1 + 904) & 0xFFFFFFE3 | 8;
      unsigned int v3 = (unsigned int *)(*(void *)(a1 + 1040) + 608);
      unint64_t v4 = 2;
      goto LABEL_8;
    case 4:
      *(_DWORD *)(a1 + 904) = *(_DWORD *)(a1 + 904) & 0xFFFFFFE3 | 0xC;
      unsigned int v3 = (unsigned int *)(*(void *)(a1 + 1040) + 608);
      unint64_t v4 = 3;
LABEL_8:
      if (CheckRegValueRange(v4, v3)) {
        goto LABEL_9;
      }
LABEL_5:
      uint64_t v2 = 0;
      break;
    case 5:
      return v2;
    default:
LABEL_9:
      uint64_t v2 = 1;
      break;
  }
  return v2;
}

uint64_t ZinAneTd<11u>::SetPEFirstSource(uint64_t result, int a2)
{
  if (a2)
  {
    if (a2 != 1) {
      return result;
    }
    unsigned int v2 = *(_DWORD *)(result + 904) & 0xFFFEFFFF;
  }
  else
  {
    unsigned int v2 = *(_DWORD *)(result + 904) | 0x10000;
  }
  *(_DWORD *)(result + 904) = v2;
  return result;
}

uint64_t ZinAneTd<11u>::SetPESecondSource(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 904) & 0xFFF3FFFF;
      goto LABEL_6;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 904) & 0xFFF3FFFF | 0x40000;
      goto LABEL_6;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 904) & 0xFFF3FFFF | 0x80000;
      goto LABEL_6;
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 904) | 0xC0000;
LABEL_6:
      *(_DWORD *)(result + 904) = v2;
      break;
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<11u>::SetPECondition(uint64_t result, int a2)
{
  if (a2 != 1) {
    ZinAssertImpl("Error: invalid PE Condition");
  }
  *(_DWORD *)(result + 904) |= 0x40u;
  return result;
}

__int16 ZinAneTd<11u>::SetPEOutputReLU@<H0>(uint64_t a1@<X0>, _DWORD *a2@<X1>)
{
  *(_DWORD *)(a1 + 904) |= 0x20u;
  if (*a2 == 7)
  {
    _S0 = a2[3];
    __asm { FCVT            H0, S0 }
    int v7 = _S0;
    *(_WORD *)(a1 + 92std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = _S0;
    _S0 = a2[4];
    __asm { FCVT            H0, S0 }
    *(_DWORD *)(a1 + 92std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v7 | (_S0 << 16);
  }
  return _S0;
}

uint64_t ZinAneTd<11u>::SetPEOutputCtoW(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 1024;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 544) = *(_DWORD *)(result + 544) & 0xFFFFFBFF | v2;
  return result;
}

BOOL ZinAneTd<11u>::SetL2ResultBaseAddr(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1040) + 384), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Result Base Address");
  }
  *(_DWORD *)(a1 + 848) = *(_DWORD *)(a1 + 848) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<11u>::SetL2ResultChannelStride(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1040) + 392), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Result Channel Stride");
  }
  *(_DWORD *)(a1 + 852) = *(_DWORD *)(a1 + 852) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<11u>::SetL2ResultRowStride(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1040) + 400), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Result Row Stride");
  }
  *(_DWORD *)(a1 + 856) = *(_DWORD *)(a1 + 856) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<11u>::SetL2ResultDepthStride(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1040) + 408), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Result Depth Stride");
  }
  *(_DWORD *)(a1 + 86std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 860) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<11u>::SetL2ResultGroupStride(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1040) + 416), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Result Group Stride");
  }
  *(_DWORD *)(a1 + 864) = *(_DWORD *)(a1 + 864) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

uint64_t ZinAneTd<11u>::SetL2BfrMode(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 8;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 844) = *(_DWORD *)(result + 844) & 0xFFFFFFF7 | v2;
  return result;
}

uint64_t ZinAneTd<11u>::SetL2ResultType(uint64_t result, int a2)
{
  switch(a2)
  {
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 844) & 0xFFFFFFFC | 2;
      break;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 844) & 0xFFFFFFFC | 1;
      break;
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 844) & 0xFFFFFFFC;
      break;
    case 4:
      unsigned int v2 = *(_DWORD *)(result + 844) | 3;
      break;
    default:
      ZinAssertImpl("Invalid L2 Result Type");
  }
  *(_DWORD *)(result + 844) = v2;
  return result;
}

uint64_t ZinAneTd<11u>::SetTileDmaSrc1Format(uint64_t result, int a2, int a3)
{
  switch(a2)
  {
    case 1:
      unsigned int v3 = *(_DWORD *)(result + 656) & 0xFFFFCFFC | 0x1000;
      goto LABEL_16;
    case 2:
      unsigned int v3 = *(_DWORD *)(result + 656) & 0xFFFFCFFC;
      goto LABEL_16;
    case 3:
      unsigned int v4 = *(_DWORD *)(result + 656) & 0xFFFFCFCC;
      int v5 = 8241;
      break;
    case 4:
      unsigned int v3 = *(_DWORD *)(result + 656) & 0xFFFFCECC | 1;
      goto LABEL_16;
    case 5:
      unsigned int v4 = *(_DWORD *)(result + 656) & 0xFFFFCECC;
      int v5 = 257;
      break;
    case 6:
      unsigned int v4 = *(_DWORD *)(result + 656) & 0xFFFFCECC;
      int v5 = 17;
      break;
    case 7:
      unsigned int v4 = *(_DWORD *)(result + 656) & 0xFFFFCECC;
      int v5 = 273;
      break;
    case 8:
      ZinAssertImpl("Packed10 format not supported");
    case 9:
      unsigned int v4 = *(_DWORD *)(result + 656) & 0xFFFFCECC;
      if (!a3) {
        goto LABEL_14;
      }
      int v5 = 4401;
      break;
    case 10:
      unsigned int v4 = *(_DWORD *)(result + 656) & 0xFFFFCECC;
      if (a3) {
        int v5 = 305;
      }
      else {
LABEL_14:
      }
        int v5 = 8497;
      break;
    case 11:
      unsigned int v4 = *(_DWORD *)(result + 656) & 0xFFFFFFCF;
      int v5 = 12547;
      break;
    case 12:
      ZinAssertImpl("E4M3 format is not supported");
    case 13:
      ZinAssertImpl("E5M2 format is not supported");
    default:
      ZinAssertImpl("Invalid format provided");
  }
  unsigned int v3 = v4 | v5;
LABEL_16:
  *(_DWORD *)(result + 656) = v3;
  return result;
}

BOOL ZinAneTd<11u>::SetTileDmaSrc1Interleave(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1040) + 592), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc1 Interleave");
  }
  *(_DWORD *)(a1 + 656) = *(_DWORD *)(a1 + 656) & 0xF0FFFFFF | ((v4 & 0xF) << 24);
  return result;
}

uint64_t ZinAneTd<11u>::SetTileDmaSrc1Enable(uint64_t result)
{
  *(_DWORD *)(result + 576) |= 1u;
  return result;
}

uint64_t ZinAneTd<11u>::SetTileDmaSrc1CacheHint(uint64_t result, int a2, int a3, int a4)
{
  int v4 = 224;
  switch(a2)
  {
    case 0:
      goto LABEL_5;
    case 1:
      int v4 = 32;
      goto LABEL_5;
    case 2:
      int v4 = 64;
      goto LABEL_5;
    case 3:
      int v4 = 192;
LABEL_5:
      *(_DWORD *)(result + 576) = *(_DWORD *)(result + 576) & 0xFFFFFF0F | v4;
      break;
    case 4:
LABEL_15:
      ZinAssertImpl("Invalid CacheHint");
    default:
      break;
  }
  char v5 = 32;
  switch(a4)
  {
    case 0:
      char v5 = -32;
      goto LABEL_10;
    case 2:
      char v5 = 64;
      goto LABEL_10;
    case 3:
      char v5 = -64;
      goto LABEL_10;
    case 4:
      goto LABEL_15;
    default:
LABEL_10:
      char v6 = 2;
      switch(a3)
      {
        case 0:
          char v6 = 14;
          goto LABEL_14;
        case 2:
          char v6 = 4;
          goto LABEL_14;
        case 3:
          char v6 = 12;
          goto LABEL_14;
        case 4:
          goto LABEL_15;
        default:
LABEL_14:
          *(unsigned char *)(result + 584) = v6 | v5;
          return result;
      }
  }
}

uint64_t ZinAneTd<11u>::SetTileDmaSrc2CacheHint(uint64_t result, int a2, int a3, int a4)
{
  int v4 = 224;
  switch(a2)
  {
    case 0:
      goto LABEL_5;
    case 1:
      int v4 = 32;
      goto LABEL_5;
    case 2:
      int v4 = 64;
      goto LABEL_5;
    case 3:
      int v4 = 192;
LABEL_5:
      *(_DWORD *)(result + 58std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 580) & 0xFFFFFF0F | v4;
      break;
    case 4:
LABEL_15:
      ZinAssertImpl("Invalid CacheHint");
    default:
      break;
  }
  char v5 = 32;
  switch(a4)
  {
    case 0:
      char v5 = -32;
      goto LABEL_10;
    case 2:
      char v5 = 64;
      goto LABEL_10;
    case 3:
      char v5 = -64;
      goto LABEL_10;
    case 4:
      goto LABEL_15;
    default:
LABEL_10:
      char v6 = 2;
      switch(a3)
      {
        case 0:
          char v6 = 14;
          goto LABEL_14;
        case 2:
          char v6 = 4;
          goto LABEL_14;
        case 3:
          char v6 = 12;
          goto LABEL_14;
        case 4:
          goto LABEL_15;
        default:
LABEL_14:
          *(unsigned char *)(result + 588) = v6 | v5;
          return result;
      }
  }
}

BOOL ZinAneTd<11u>::SetTileDmaSrc1ChannelStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 1040) + 448), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc1 Channel Stride");
  }
  *(_DWORD *)(a1 + 604) = *(_DWORD *)(a1 + 604) & 0x3F | (v4 << 6);
  return result;
}

BOOL ZinAneTd<11u>::SetTileDmaSrc1RowStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 1040) + 440), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc1 Row Stride");
  }
  *(_DWORD *)(a1 + 60std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 600) & 0x3F | (v4 << 6);
  return result;
}

BOOL ZinAneTd<11u>::SetTileDmaSrc1DepthStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 1040) + 456), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc1 Depth Stride");
  }
  *(_DWORD *)(a1 + 608) = *(_DWORD *)(a1 + 608) & 0x3F | (v4 << 6);
  return result;
}

BOOL ZinAneTd<11u>::SetTileDmaSrc1GroupStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 1040) + 464), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc1 Group Stride");
  }
  *(_DWORD *)(a1 + 612) = *(_DWORD *)(a1 + 612) & 0x3F | (v4 << 6);
  return result;
}

uint64_t ZinAneTd<11u>::SetTileDmaSrc1FmtOffsetCh(uint64_t result, char a2)
{
  *(_DWORD *)(result + 656) = *(_DWORD *)(result + 656) & 0xFFF8FFFF | ((a2 & 7) << 16);
  return result;
}

uint64_t ZinAneTd<11u>::SetTileDmaSrc1FmtCmpVec(uint64_t result, unsigned __int8 a2)
{
  *(_DWORD *)(result + 656) = *(_DWORD *)(result + 656) & 0xFFFFFFF | (a2 << 28);
  return result;
}

uint64_t ZinAneTd<11u>::SetTileDmaSrc1BaseAddrLo(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return ZinAneTdHw_v11::AddRelocInfo((uint64_t *)(a1 + 8), a2, 1092, a3, 1, 1, 0, 0);
}

uint64_t ZinAneTd<11u>::SetTileDmaSrc1DependencyMode(uint64_t result, int a2)
{
  if ((a2 - 1) <= 1) {
    *(_DWORD *)(result + 576) = *(_DWORD *)(result + 576) & 0xCFFFFFFF | 0x10000000;
  }
  return result;
}

unint64_t ZinAneTd<11u>::SetTileDmaSrc1DependencyInterval(uint64_t a1, unsigned int a2)
{
  unint64_t result = ZinIrCodegenValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1040) + 600));
  *(_DWORD *)(a1 + 576) = *(_DWORD *)(a1 + 576) & 0xF0FFFFFF | ((result & 0xF) << 24);
  return result;
}

uint64_t ZinAneTd<11u>::SetTileDmaSrc1OffsetY(uint64_t result, __int16 a2)
{
  *(_WORD *)(result + 676) = a2;
  return result;
}

uint64_t ZinAneTd<11u>::SetTileDmaSrc1CompressedInfo(uint64_t result, int a2, int a3, int a4)
{
  int v4 = *(_DWORD *)(result + 664);
  *(_DWORD *)(result + 664) = v4 | 1;
  switch(a4)
  {
    case 0:
      unsigned int v5 = v4 & 0xFFFFCFFE | 1;
      break;
    case 1:
      unsigned int v5 = v4 & 0xFFFFCFFE | 0x1001;
      break;
    case 2:
      unsigned int v5 = v4 & 0xFFFFCFFE | 0x2001;
      break;
    case 3:
      unsigned int v5 = v4 | 0x3001;
      break;
    default:
      ZinAssertImpl("Invalid Lossy Mode");
  }
  *(_DWORD *)(result + 664) = v5;
  if (a3 == 2)
  {
    unsigned int v6 = v5 | 4;
  }
  else
  {
    if (a3 != 1) {
      ZinAssertImpl("Unsupported macro block size");
    }
    unsigned int v6 = v5 & 0xFFFFFFFB;
  }
  *(_DWORD *)(result + 664) = v6;
  if ((a2 - 1) >= 0x13) {
    ZinAssertImpl("Invalid packing format");
  }
  *(_DWORD *)(result + 664) = v6 & 0xFFFFFC0F | dword_211F04368[a2 - 1];
  return result;
}

BOOL ZinAneTd<11u>::SetTileDmaSrc1CompressedSize(uint64_t a1, unsigned int a2, unsigned int a3)
{
  int v7 = 0;
  if (!ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1040) + 24), &v7)) {
    ZinAssertImpl("Illegal TileDmaSrc1 Compressed Width");
  }
  *(_DWORD *)(a1 + 668) = *(_DWORD *)(a1 + 668) & 0xFFFE0000 | v7 & 0x1FFFF;
  int v6 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a3, (unsigned int *)(*(void *)(a1 + 1040) + 16), &v6);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc1 Compressed Height");
  }
  *(_DWORD *)(a1 + 672) = *(_DWORD *)(a1 + 672) & 0xFFFE0000 | v6 & 0x1FFFF;
  return result;
}

uint64_t ZinAneTd<11u>::SetTileDmaSrc1MetaData(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t result = ZinAneTdHw_v11::AddRelocInfo((uint64_t *)(a1 + 8), a2, 1104, a3, 1, 1, 0, 0);
  *(_DWORD *)(a1 + 664) &= ~8u;
  return result;
}

uint64_t ZinAneTd<11u>::SetTileDmaSrc1NoMetaData(uint64_t result)
{
  *(_DWORD *)(result + 664) |= 8u;
  return result;
}

uint64_t ZinAneTd<11u>::SetTileDmaSrc1DataSetId(uint64_t result, char a2)
{
  *(unsigned char *)(result + 577) = a2;
  return result;
}

uint64_t ZinAneTd<11u>::SetTileDmaSrc2FmtOffsetCh(uint64_t result, char a2)
{
  *(_DWORD *)(result + 66std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 660) & 0xFFF8FFFF | ((a2 & 7) << 16);
  return result;
}

uint64_t ZinAneTd<11u>::SetTileDmaSrc2FmtCmpVec(uint64_t result, unsigned __int8 a2)
{
  *(_DWORD *)(result + 66std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 660) & 0xFFFFFFF | (a2 << 28);
  return result;
}

int8x16_t ZinAneTd<11u>::SetTileDmaSrc2PixelOffset(uint64_t a1, unsigned int a2, unsigned int a3, unsigned int a4, unsigned int a5)
{
  v5.i64[0] = __PAIR64__(a3, a2);
  v5.i64[1] = __PAIR64__(a5, a4);
  v6.i64[0] = 0xFFFF0000FFFF0000;
  v6.i64[1] = 0xFFFF0000FFFF0000;
  int8x16_t result = vbslq_s8(v6, *(int8x16_t *)(a1 + 696), v5);
  *(int8x16_t *)(a1 + 696) = result;
  return result;
}

void ZinAneTd<11u>::SetTileDmaSrc2CompressedInfo(uint64_t a1, int a2, int a3, int a4)
{
}

uint64_t ZinAneTd<11u>::SetTileDmaSrc2DataSetId(uint64_t result, char a2)
{
  *(unsigned char *)(result + 581) = a2;
  return result;
}

BOOL ZinAneTd<11u>::SetTileDmaSrc2CompressedSize(uint64_t a1, unsigned int a2, unsigned int a3)
{
  int v7 = 0;
  if (!ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1040) + 24), &v7)) {
    ZinAssertImpl("Illegal TileDmaSrc2 Compressed Width");
  }
  *(_DWORD *)(a1 + 668) = *(_DWORD *)(a1 + 668) & 0xFFFE0000 | v7 & 0x1FFFF;
  int v6 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a3, (unsigned int *)(*(void *)(a1 + 1040) + 16), &v6);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc2 Compressed Height");
  }
  *(_DWORD *)(a1 + 672) = *(_DWORD *)(a1 + 672) & 0xFFFE0000 | v6 & 0x1FFFF;
  return result;
}

uint64_t ZinAneTd<11u>::SetTileDmaDstFormat(uint64_t result, int a2, int a3)
{
  switch(a2)
  {
    case 1:
      unsigned int v3 = *(_DWORD *)(result + 992) & 0xFFFFCFFC | 0x1000;
      goto LABEL_16;
    case 2:
      unsigned int v3 = *(_DWORD *)(result + 992) & 0xFFFFCFFC;
      goto LABEL_16;
    case 3:
      unsigned int v4 = *(_DWORD *)(result + 992) & 0xFFFFCFCC;
      int v5 = 8241;
      break;
    case 4:
      unsigned int v3 = *(_DWORD *)(result + 992) & 0xFFFFCECC | 1;
      goto LABEL_16;
    case 5:
      unsigned int v4 = *(_DWORD *)(result + 992) & 0xFFFFCECC;
      int v5 = 257;
      break;
    case 6:
      unsigned int v4 = *(_DWORD *)(result + 992) & 0xFFFFCECC;
      int v5 = 17;
      break;
    case 7:
      unsigned int v4 = *(_DWORD *)(result + 992) & 0xFFFFCECC;
      int v5 = 273;
      break;
    case 8:
      ZinAssertImpl("Packed10 format not supported");
    case 9:
      unsigned int v4 = *(_DWORD *)(result + 992) & 0xFFFFCECC;
      if (!a3) {
        goto LABEL_14;
      }
      int v5 = 4401;
      break;
    case 10:
      unsigned int v4 = *(_DWORD *)(result + 992) & 0xFFFFCECC;
      if (a3) {
        int v5 = 305;
      }
      else {
LABEL_14:
      }
        int v5 = 8497;
      break;
    case 11:
      unsigned int v4 = *(_DWORD *)(result + 992) & 0xFFFFFFCF;
      int v5 = 12547;
      break;
    case 12:
      ZinAssertImpl("E4M3 is not supported");
    case 13:
      ZinAssertImpl("E5M2 is not supported");
    default:
      ZinAssertImpl("Invalid format provided");
  }
  unsigned int v3 = v4 | v5;
LABEL_16:
  *(_DWORD *)(result + 992) = v3;
  return result;
}

BOOL ZinAneTd<11u>::SetTileDmaDstandL2DstInterleave(uint64_t a1, unsigned int a2)
{
  int v6 = 0;
  unint64_t v3 = a2;
  if (!ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1040) + 592), &v6)) {
    ZinAssertImpl("Illegal L2 Result Interleave");
  }
  *(_DWORD *)(a1 + 844) = *(_DWORD *)(a1 + 844) & 0xFFFFF0FF | ((v6 & 0xF) << 8);
  int v5 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(v3, (unsigned int *)(*(void *)(a1 + 1040) + 592), &v5);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaDst Interleave");
  }
  *(_DWORD *)(a1 + 992) = *(_DWORD *)(a1 + 992) & 0xF0FFFFFF | ((v5 & 0xF) << 24);
  return result;
}

BOOL ZinAneTd<11u>::SetL2ResultInterleave(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1040) + 592), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Result Interleave");
  }
  *(_DWORD *)(a1 + 844) = *(_DWORD *)(a1 + 844) & 0xFFFFF0FF | ((v4 & 0xF) << 8);
  return result;
}

uint64_t ZinAneTd<11u>::SetTileDmaDstandL2DstFifoMode(uint64_t result, int a2)
{
  unsigned int v2 = *(_DWORD *)(result + 844) & 0xFFFFFFF7;
  if (a2) {
    int v3 = 0x1000000;
  }
  else {
    int v3 = 0;
  }
  unsigned int v4 = *(_DWORD *)(result + 960) & 0xFEFFFFFF | v3;
  if (a2) {
    int v5 = 8;
  }
  else {
    int v5 = 0;
  }
  *(_DWORD *)(result + 96std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v4;
  *(_DWORD *)(result + 844) = v2 | v5;
  return result;
}

uint64_t ZinAneTd<11u>::SetTileDmaDstEnable(uint64_t result)
{
  *(_DWORD *)(result + 960) |= 1u;
  return result;
}

uint64_t ZinAneTd<11u>::SetTileDmaDstCacheHint(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 960) | 0xF0;
      goto LABEL_5;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 960) & 0xFFFFFF0F | 0x30;
      goto LABEL_5;
    case 2:
      ZinAssertImpl("Drop CacheHint not supported on Dst");
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 960) & 0xFFFFFF0F | 0xD0;
LABEL_5:
      *(_DWORD *)(result + 96std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2;
      break;
    case 4:
      ZinAssertImpl("Invalid CacheHint");
    default:
      return result;
  }
  return result;
}

BOOL ZinAneTd<11u>::SetTileDmaDstChannelStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 1040) + 496), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaDst Channel Stride");
  }
  *(_DWORD *)(a1 + 98std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 980) & 0x3F | (v4 << 6);
  return result;
}

BOOL ZinAneTd<11u>::SetTileDmaDstRowStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 1040) + 488), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaDst Row Stride");
  }
  *(_DWORD *)(a1 + 976) = *(_DWORD *)(a1 + 976) & 0x3F | (v4 << 6);
  return result;
}

BOOL ZinAneTd<11u>::SetTileDmaDstDepthStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 1040) + 504), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaDst Depth Stride");
  }
  *(_DWORD *)(a1 + 984) = *(_DWORD *)(a1 + 984) & 0x3F | (v4 << 6);
  return result;
}

BOOL ZinAneTd<11u>::SetTileDmaDstGroupStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 1040) + 512), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaDst Group Stride");
  }
  *(_DWORD *)(a1 + 988) = *(_DWORD *)(a1 + 988) & 0x3F | (v4 << 6);
  return result;
}

uint64_t ZinAneTd<11u>::SetTileDmaDstZeroPad(uint64_t result, _DWORD *a2)
{
  unsigned int v2 = *(_DWORD *)(result + 992) & 0xFFDFFFFF | ((*a2 == 0) << 21);
  *(_DWORD *)(result + 992) = v2;
  *(_DWORD *)(result + 992) = v2 & 0xFFEFFFFF | ((a2[1] == 0) << 20);
  return result;
}

uint64_t ZinAneTd<11u>::SetTileDmaDstFmtOffsetCh(uint64_t result, char a2)
{
  *(_DWORD *)(result + 992) = *(_DWORD *)(result + 992) & 0xFFF8FFFF | ((a2 & 7) << 16);
  return result;
}

uint64_t ZinAneTd<11u>::SetTileDmaDstFmtCmpVec(uint64_t result, unsigned __int8 a2)
{
  *(_DWORD *)(result + 992) = *(_DWORD *)(result + 992) & 0xFFFFFFF | (a2 << 28);
  return result;
}

uint64_t ZinAneTd<11u>::SetTileDmaDstBaseAddrLo(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return ZinAneTdHw_v11::AddRelocInfo((uint64_t *)(a1 + 8), a2, 1346, a3, 1, 1, 0, 0);
}

uint64_t ZinAneTd<11u>::SetTileDmaDstDataSetId(uint64_t result, char a2)
{
  *(unsigned char *)(result + 961) = a2;
  return result;
}

uint64_t ZinAneTd<11u>::SetFillLowerNEFirst(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 0x20000000;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 548) = *(_DWORD *)(result + 548) & 0xDFFFFFFF | v2;
  return result;
}

uint64_t ZinAneTd<11u>::SetArgOutputSelect(uint64_t result, int a2)
{
  if ((a2 - 6) > 5) {
    int v2 = 0x100000;
  }
  else {
    int v2 = dword_211F043B4[a2 - 6];
  }
  *(_DWORD *)(result + 936) = *(_DWORD *)(result + 936) & 0xFF0FFFFF | v2;
  return result;
}

uint64_t ZinAneTd<11u>::SetMaxPoolMode(uint64_t result, unsigned int a2)
{
  if (a2 <= 0xE && ((1 << a2) & 0x48E2) != 0) {
    unsigned int v2 = *(_DWORD *)(result + 936) | 0x80000;
  }
  else {
    unsigned int v2 = *(_DWORD *)(result + 936) & 0xFFF7FFFF;
  }
  *(_DWORD *)(result + 936) = v2;
  return result;
}

BOOL ZinAneTd<11u>::SetKernelStrideRegisters(uint64_t a1, unsigned int a2, unsigned int a3)
{
  int v7 = 0;
  if (!ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1040) + 696), &v7)) {
    ZinAssertImpl("Illegal Kernel Group Stride");
  }
  *(_DWORD *)(a1 + 6std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 60) & 0x3F | (v7 << 6);
  int v6 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a3, (unsigned int *)(*(void *)(a1 + 1040) + 688), &v6);
  if (!result) {
    ZinAssertImpl("Illegal Kernel OCG Stride");
  }
  *(_DWORD *)(a1 + 64) = *(_DWORD *)(a1 + 64) & 0x3F | (v6 << 6);
  return result;
}

uint64_t ZinAneTd<11u>::SetKernelSparseBlockSize(uint64_t result, char a2)
{
  *(_DWORD *)(result + 9std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_DWORD *)(result + 932) & 0xFF1FFFFF | ((a2 & 7) << 21);
  return result;
}

uint64_t ZinAneTd<11u>::SetGroupKernelReuse(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 1024;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 9std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_DWORD *)(result + 932) & 0xFFFFFBFF | v2;
  if (a2) {
    int v3 = 16;
  }
  else {
    int v3 = 0;
  }
  *(_DWORD *)(result + 44) = *(_DWORD *)(result + 44) & 0xFFFFFFEF | v3;
  return result;
}

uint64_t ZinAneTd<11u>::SetKernelSparseFmt(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 256;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 9std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_DWORD *)(result + 932) & 0xFFFFFEFF | v2;
  if (a2) {
    int v3 = 32;
  }
  else {
    int v3 = 0;
  }
  *(_DWORD *)(result + 44) = *(_DWORD *)(result + 44) & 0xFFFFFFDF | v3;
  return result;
}

uint64_t ZinAneTd<11u>::SetKernelSparseBinary(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 0x8000;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 9std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_DWORD *)(result + 932) & 0xFFFF7FFF | v2;
  return result;
}

uint64_t ZinAneTd<11u>::SetKernelPalettizedEn(uint64_t result, int a2)
{
  int v2 = 0;
  switch(a2)
  {
    case 0:
    case 3:
    case 28:
    case 29:
    case 30:
    case 31:
    case 32:
      ZinAssertImpl("Unknown kernel format in codegen\n");
    case 7:
    case 8:
    case 9:
    case 10:
    case 11:
    case 12:
    case 13:
    case 14:
    case 19:
    case 20:
    case 21:
    case 22:
    case 23:
    case 24:
    case 25:
    case 26:
    case 27:
      int v2 = 4;
      break;
    case 15:
    case 16:
    case 17:
    case 18:
      ZinAssertImpl("Invalid kernel format");
    default:
      break;
  }
  *(_DWORD *)(result + 9std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_DWORD *)(result + 932) & 0xFFFFFFFB | v2;
  return result;
}

uint64_t ZinAneTd<11u>::SetKernelPalettizedBits(uint64_t result, int a2)
{
  int v2 = 128;
  switch(a2)
  {
    case 0:
    case 3:
    case 28:
    case 29:
    case 30:
    case 31:
    case 32:
      ZinAssertImpl("Unknown kernel format in codegen\n");
    case 7:
    case 8:
    case 9:
    case 10:
      int v2 = 16;
      break;
    case 11:
    case 12:
    case 13:
    case 14:
      int v2 = 32;
      break;
    case 15:
    case 16:
    case 17:
    case 18:
      ZinAssertImpl("Invalid kernel format");
    case 19:
    case 20:
    case 21:
    case 22:
      int v2 = 64;
      break;
    case 23:
    case 24:
    case 25:
    case 26:
      int v2 = 96;
      break;
    default:
      break;
  }
  *(_DWORD *)(result + 9std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_DWORD *)(result + 932) & 0xFFFFFF0F | v2;
  return result;
}

uint64_t ZinAneTd<11u>::SetNEBinaryPoint(uint64_t result, char a2)
{
  *(_DWORD *)(result + 936) = *(_DWORD *)(result + 936) & 0xFFFFE0FF | ((a2 & 0x1F) << 8);
  return result;
}

uint64_t ZinAneTd<11u>::SetNENonLinearMode(uint64_t result, int a2, uint64_t a3)
{
  if (a2)
  {
    if (a2 == 1)
    {
      a2 = 0x10000;
    }
    else
    {
      unsigned int v4 = *(_DWORD **)a3;
      int v3 = *(_DWORD **)(a3 + 8);
      if (*(_DWORD **)a3 != v3)
      {
        while (*v4 != a2)
        {
          if (++v4 == v3)
          {
            unsigned int v4 = *(_DWORD **)(a3 + 8);
            break;
          }
        }
      }
      if (v4 == v3) {
        ZinAssertImpl("Error: illegal non-linear mode\n");
      }
      a2 = 0x20000;
    }
  }
  *(_DWORD *)(result + 936) = *(_DWORD *)(result + 936) & 0xFFFCFFFF | a2;
  return result;
}

uint64_t ZinAneTd<11u>::SetNEPostScale(uint64_t result, unint64_t a2, char a3)
{
  _S0 = a2;
  __asm { FCVT            H0, S0 }
  int v8 = _S0;
  if (!_ZF) {
    int v8 = 0;
  }
  int v9 = ((a2 & 0xFF0000000000) != 0) << 14;
  int v10 = -((a2 >> 16) & 0x1F0000) & 0x1F0000 | v8;
  if (!a3)
  {
    int v9 = 0;
    int v10 = 15360;
  }
  *(_DWORD *)(result + 936) = *(_DWORD *)(result + 936) & 0xFFFFBFFF | v9;
  *(_DWORD *)(result + 948) = v10 | *(_DWORD *)(result + 948) & 0xFFE00000;
  return result;
}

uint64_t ZinAneTd<11u>::SetNEBias(uint64_t result, unint64_t a2, char a3)
{
  _S0 = a2;
  __asm { FCVT            H0, S0 }
  int v8 = _S0;
  if (!_ZF) {
    int v8 = 0;
  }
  int v9 = 16 * ((a2 & 0xFF0000000000) != 0);
  int v10 = (a2 >> 16) & 0x1F0000 | v8;
  if (!a3)
  {
    int v9 = 0;
    int v10 = 0;
  }
  *(_DWORD *)(result + 936) = *(_DWORD *)(result + 936) & 0xFFFFFFEF | v9;
  *(_DWORD *)(result + 944) = v10 | *(_DWORD *)(result + 944) & 0xFFE00000;
  return result;
}

ZinIrKernel *ZinAneTd<11u>::SetNEMatrixVectorBias(uint64_t a1, ZinIrKernel **a2, uint64_t a3)
{
  BOOL result = *a2;
  if (*a2) {
    _ZF = (a3 & 0xFF00000000) == 0;
  }
  else {
    _ZF = 1;
  }
  if (_ZF)
  {
    int v6 = 0;
  }
  else
  {
    _S8 = *(float *)&a3;
    BOOL result = (ZinIrKernel *)ZinIrKernel::GetWeightFormat(result);
    if (result == 4)
    {
      __asm { FCVT            H0, S8 }
      LOWORD(v8) = _H0;
    }
    else
    {
      if (result != 2 && result != 1) {
        ZinAssertImpl("Error: Invalid kernel format");
      }
      int v8 = (int)_S8;
    }
    *(_WORD *)(a1 + 94std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v8;
    int v6 = 64;
  }
  *(_DWORD *)(a1 + 936) = *(_DWORD *)(a1 + 936) & 0xFFFFFFBF | v6;
  return result;
}

uint64_t ZinAneTd<11u>::SetNEOcgSize(uint64_t result, char a2)
{
  *(_DWORD *)(result + 52std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 520) & 0xFFFFFFF8 | a2 & 7;
  return result;
}

uint64_t ZinAneTd<11u>::SetOutputTranspose(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 0x10000000;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 548) = *(_DWORD *)(result + 548) & 0xEFFFFFFF | v2;
  return result;
}

uint64_t ZinAneTd<11u>::SetNESmallSourceMode(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 548) & 0xFFFFFFF3;
      goto LABEL_6;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 548) & 0xFFFFFFF3 | 4;
      goto LABEL_6;
    case 2:
      ZinAssertImpl("Error: Tiny source mode is not supported for this arch");
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 548) | 0xC;
      goto LABEL_6;
    case 4:
      unsigned int v2 = *(_DWORD *)(result + 548) & 0xFFFFFFF3 | 8;
LABEL_6:
      *(_DWORD *)(result + 548) = v2;
      break;
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<11u>::GetNESmallSourceMode(uint64_t a1)
{
  return *(unsigned int *)((char *)&unk_211ED50F0 + (*(_DWORD *)(a1 + 548) & 0xC));
}

uint64_t ZinAneTd<11u>::SetTileDmaSrcDma1UserTag(uint64_t result, char a2)
{
  *(unsigned char *)(result + 578) = a2;
  return result;
}

uint64_t ZinAneTd<11u>::SetTileDmaSrcDma2UserTag(uint64_t result, char a2)
{
  *(unsigned char *)(result + 582) = a2;
  return result;
}

uint64_t ZinAneTd<11u>::SetTileDmaSrcCompressedMdUserTag(uint64_t result, char a2)
{
  *(unsigned char *)(result + 667) = a2;
  return result;
}

uint64_t ZinAneTd<11u>::SetTileDmaDstUserTag(uint64_t result, char a2)
{
  *(unsigned char *)(result + 962) = a2;
  return result;
}

uint64_t ZinAneTd<11u>::SetKernelDmaSrcCoeffUserTag(uint64_t result, unsigned __int8 a2)
{
  uint64_t v2 = 0;
  int8x16_t v3 = (int8x16_t)vdupq_n_s32(a2 << 16);
  do
  {
    *(int8x16_t *)(result + 68 + v2) = vorrq_s8((int8x16_t)(*(_OWORD *)(result + 68 + v2) & __PAIR128__(0xFF00FFFFFF00FFFFLL, 0xFF00FFFFFF00FFFFLL)), v3);
    v2 += 16;
  }
  while (v2 != 64);
  return result;
}

int8x16_t ZinAneTd<11u>::SetKernelDmaSrcPostScaleUserTag(uint64_t a1, unsigned __int8 a2)
{
  int8x16_t result = vorrq_s8((int8x16_t)(*(_OWORD *)(a1 + 260) & __PAIR128__(0xFF00FFFFFF00FFFFLL, 0xFF00FFFFFF00FFFFLL)), (int8x16_t)vdupq_n_s32(a2 << 16));
  *(int8x16_t *)(a1 + 26std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = result;
  return result;
}

uint64_t ZinAneTd<11u>::SetCommonTaskType(uint64_t result, int a2)
{
  int v2 = 16;
  switch(a2)
  {
    case 0:
      *(_DWORD *)(result + 548) &= 0xFFFFFF8F;
      goto LABEL_9;
    case 1:
LABEL_9:
      ZinAssertImpl("Error: Invalid Task Type");
    case 2:
      goto LABEL_7;
    case 3:
      int v2 = 96;
      goto LABEL_7;
    case 4:
      int v2 = 80;
      goto LABEL_7;
    case 5:
      int v2 = 48;
      goto LABEL_7;
    case 6:
      int v2 = 32;
      goto LABEL_7;
    case 7:
      int v2 = 64;
LABEL_7:
      *(_DWORD *)(result + 548) = *(_DWORD *)(result + 548) & 0xFFFFFF8F | v2;
      break;
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<11u>::SetCommonInFmt(uint64_t result, int a2)
{
  if (a2 > 2)
  {
    if (a2 == 3)
    {
      unsigned int v2 = *(_DWORD *)(result + 500) & 0xFFFFFFFC | 2;
      goto LABEL_8;
    }
    if (a2 == 12) {
      ZinAssertImpl("Error: Invalid Common InFmt E4M3");
    }
LABEL_11:
    ZinAssertImpl("Error: Invalid TD programming for Src1 input format");
  }
  if (a2 == 1)
  {
    unsigned int v2 = *(_DWORD *)(result + 500) & 0xFFFFFFFC | 1;
    goto LABEL_8;
  }
  if (a2 != 2) {
    goto LABEL_11;
  }
  unsigned int v2 = *(_DWORD *)(result + 500) & 0xFFFFFFFC;
LABEL_8:
  *(_DWORD *)(result + 50std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2;
  return result;
}

uint64_t ZinAneTd<11u>::SetCommonSrc2InFmt(uint64_t result, int a2)
{
  if (a2 > 2)
  {
    if (a2 == 3)
    {
      unsigned int v2 = *(_DWORD *)(result + 500) & 0xFFFFFFF3 | 8;
      goto LABEL_8;
    }
    if (a2 == 12) {
      ZinAssertImpl("Error: Invalid TD programming for Src2 input format: E4M3");
    }
LABEL_11:
    ZinAssertImpl("Error: Invalid TD programming for Src2 input format");
  }
  if (a2 == 1)
  {
    unsigned int v2 = *(_DWORD *)(result + 500) & 0xFFFFFFF3 | 4;
    goto LABEL_8;
  }
  if (a2 != 2) {
    goto LABEL_11;
  }
  unsigned int v2 = *(_DWORD *)(result + 500) & 0xFFFFFFF3;
LABEL_8:
  *(_DWORD *)(result + 50std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2;
  return result;
}

uint64_t ZinAneTd<11u>::SetCommonOutFmt(uint64_t result, int a2)
{
  if ((a2 - 3) < 9) {
    goto LABEL_2;
  }
  if (a2 <= 11)
  {
    if (a2 == 1)
    {
      unsigned int v2 = *(_DWORD *)(result + 500) & 0xFFFFFFCF | 0x10;
      goto LABEL_3;
    }
    if (a2 == 2)
    {
      unsigned int v2 = *(_DWORD *)(result + 500) & 0xFFFFFFCF;
      goto LABEL_3;
    }
LABEL_12:
    ZinAssertImpl("Error: Invalid output format");
  }
  if (a2 != 13)
  {
    if (a2 == 12) {
      ZinAssertImpl("Error: E4M3 is not supported");
    }
    goto LABEL_12;
  }
LABEL_2:
  unsigned int v2 = *(_DWORD *)(result + 500) & 0xFFFFFFCF | 0x20;
LABEL_3:
  *(_DWORD *)(result + 50std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2;
  return result;
}

uint64_t ZinAneTd<11u>::SetCommonSourceRouting(uint64_t result, int a2)
{
  if (a2 == 2)
  {
    unsigned int v2 = *(_DWORD *)(result + 548) & 0xFFFFFFFC | 2;
  }
  else if (a2 == 1)
  {
    unsigned int v2 = *(_DWORD *)(result + 548) & 0xFFFFFFFC | 1;
  }
  else
  {
    if (a2) {
      return result;
    }
    unsigned int v2 = *(_DWORD *)(result + 548) | 3;
  }
  *(_DWORD *)(result + 548) = v2;
  return result;
}

BOOL ZinAneTd<11u>::SetPatchHeight(uint64_t a1, unint64_t a2)
{
  *(_DWORD *)(a1 + 54std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 540) & 0xFFFFFF0F | (16 * (a2 & 0xF));
  return CheckRegValueRange(a2, (unsigned int *)(*(void *)(a1 + 1040) + 288));
}

BOOL ZinAneTd<11u>::SetPatchWidth(uint64_t a1, unint64_t a2)
{
  *(_DWORD *)(a1 + 54std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 540) & 0xFFFFFFF0 | a2 & 0xF;
  return CheckRegValueRange(a2, (unsigned int *)(*(void *)(a1 + 1040) + 280));
}

BOOL ZinAneTd<11u>::SetTileHeight(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1040) + 200), &v4);
  if (result) {
    *(_DWORD *)(a1 + 536) = *(_DWORD *)(a1 + 536) & 0xFFFF8000 | v4 & 0x7FFF;
  }
  return result;
}

BOOL ZinAneTd<11u>::SetTileOverlap(uint64_t a1, unint64_t a2)
{
  *(_DWORD *)(a1 + 536) = *(_DWORD *)(a1 + 536) & 0xFFE0FFFF | ((a2 & 0x1F) << 16);
  return CheckRegValueRange(a2, (unsigned int *)(*(void *)(a1 + 1040) + 216));
}

BOOL ZinAneTd<11u>::SetTileOverlapPadBottom(uint64_t a1, unint64_t a2)
{
  *(_DWORD *)(a1 + 536) = *(_DWORD *)(a1 + 536) & 0x83FFFFFF | ((a2 & 0x1F) << 26);
  return CheckRegValueRange(a2, (unsigned int *)(*(void *)(a1 + 1040) + 224));
}

BOOL ZinAneTd<11u>::SetTileOverlapPadTop(uint64_t a1, unint64_t a2)
{
  *(_DWORD *)(a1 + 536) = *(_DWORD *)(a1 + 536) & 0xFC1FFFFF | ((a2 & 0x1F) << 21);
  return CheckRegValueRange(a2, (unsigned int *)(*(void *)(a1 + 1040) + 208));
}

BOOL ZinAneTd<11u>::SetCommonConvCfgKh(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1040) + 128), &v4);
  if (result) {
    *(_DWORD *)(a1 + 524) = *(_DWORD *)(a1 + 524) & 0xFFFFF03F | ((v4 & 0x3F) << 6);
  }
  return result;
}

BOOL ZinAneTd<11u>::SetCommonConvCfgKw(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1040) + 136), &v4);
  if (result) {
    *(_DWORD *)(a1 + 524) = *(_DWORD *)(a1 + 524) & 0xFFFFFFC0 | v4 & 0x3F;
  }
  return result;
}

BOOL ZinAneTd<11u>::SetCommonConvCfg3dKd(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1040) + 168), &v4);
  if (result) {
    *(_DWORD *)(a1 + 528) = *(_DWORD *)(a1 + 528) & 0xFFFFFFE0 | v4 & 0x1F;
  }
  return result;
}

BOOL ZinAneTd<11u>::SetCommonConvCfgSx(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1040) + 120), &v4);
  if (result) {
    *(_DWORD *)(a1 + 524) = *(_DWORD *)(a1 + 524) & 0xFFFF9FFF | ((v4 & 3) << 13);
  }
  return result;
}

BOOL ZinAneTd<11u>::SetCommonConvCfgSy(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1040) + 112), &v4);
  if (result) {
    *(_DWORD *)(a1 + 524) = *(_DWORD *)(a1 + 524) & 0xFFFE7FFF | ((v4 & 3) << 15);
  }
  return result;
}

BOOL ZinAneTd<11u>::SetCommonConvCfg3dSz(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1040) + 144), &v4);
  if (result) {
    *(_DWORD *)(a1 + 528) = *(_DWORD *)(a1 + 528) & 0xFFFFFF3F | ((v4 & 3) << 6);
  }
  return result;
}

BOOL ZinAneTd<11u>::SetCommonConvCfgOx(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1040) + 88), &v4);
  if (result) {
    *(_DWORD *)(a1 + 524) = *(_DWORD *)(a1 + 524) & 0xCFFFFFFF | ((v4 & 3) << 28);
  }
  return result;
}

BOOL ZinAneTd<11u>::SetCommonConvCfgOy(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1040) + 80), &v4);
  if (result) {
    *(_DWORD *)(a1 + 524) = *(_DWORD *)(a1 + 524) & 0x3FFFFFFF | (v4 << 30);
  }
  return result;
}

BOOL ZinAneTd<11u>::SetCommonConvCfg3dOz(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1040) + 160), &v4);
  if (result) {
    *(_DWORD *)(a1 + 528) = *(_DWORD *)(a1 + 528) & 0xFFFF9FFF | ((v4 & 3) << 13);
  }
  return result;
}

BOOL ZinAneTd<11u>::SetCommonConvCfgPadLeft(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1040) + 104), &v4);
  if (result) {
    *(_DWORD *)(a1 + 524) = *(_DWORD *)(a1 + 524) & 0xFFC1FFFF | ((v4 & 0x1F) << 17);
  }
  return result;
}

BOOL ZinAneTd<11u>::SetCommonConvCfgPadTop(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1040) + 96), &v4);
  if (result) {
    *(_DWORD *)(a1 + 524) = *(_DWORD *)(a1 + 524) & 0xF83FFFFF | ((v4 & 0x1F) << 22);
  }
  return result;
}

BOOL ZinAneTd<11u>::SetCommonConvCfg3dPz(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1040) + 152), &v4);
  if (result) {
    *(_DWORD *)(a1 + 528) = *(_DWORD *)(a1 + 528) & 0xFFFFF0FF | ((v4 & 0xF) << 8);
  }
  return result;
}

BOOL ZinAneTd<11u>::SetOrReturnNumGroups(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1040) + 184), &v4);
  if (result) {
    *(_DWORD *)(a1 + 5std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_DWORD *)(a1 + 532) & 0xFFFFE000 | v4 & 0x1FFF;
  }
  return result;
}

BOOL ZinAneTd<11u>::SetOrReturnWin(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1040) + 24), &v4);
  if (result) {
    *(_DWORD *)(a1 + 492) = *(_DWORD *)(a1 + 492) & 0xFFFF8000 | v4 & 0x7FFF;
  }
  return result;
}

BOOL ZinAneTd<11u>::SetOrReturnHin(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1040) + 16), &v4);
  if (result) {
    *(_DWORD *)(a1 + 492) = *(_DWORD *)(a1 + 492) & 0x8000FFFF | ((v4 & 0x7FFF) << 16);
  }
  return result;
}

BOOL ZinAneTd<11u>::SetOrReturnDin(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1040) + 32), &v4);
  if (result) {
    *(_DWORD *)(a1 + 496) = *(_DWORD *)(a1 + 496) & 0xFFFF8000 | v4 & 0x7FFF;
  }
  return result;
}

BOOL ZinAneTd<11u>::SetOrReturnCin(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1040) + 40), &v4);
  if (result) {
    *(_DWORD *)(a1 + 504) = *(_DWORD *)(a1 + 504) & 0xFFFE0000 | v4 & 0x1FFFF;
  }
  return result;
}

BOOL ZinAneTd<11u>::SetOrReturnWout(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1040) + 64), &v4);
  if (result) {
    *(_DWORD *)(a1 + 512) = *(_DWORD *)(a1 + 512) & 0xFFFF8000 | v4 & 0x7FFF;
  }
  return result;
}

BOOL ZinAneTd<11u>::SetOrReturnHout(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1040) + 56), &v4);
  if (result) {
    *(_DWORD *)(a1 + 512) = *(_DWORD *)(a1 + 512) & 0x8000FFFF | ((v4 & 0x7FFF) << 16);
  }
  return result;
}

BOOL ZinAneTd<11u>::SetOrReturnDout(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1040) + 72), &v4);
  if (result) {
    *(_DWORD *)(a1 + 516) = *(_DWORD *)(a1 + 516) & 0xFFFF8000 | v4 & 0x7FFF;
  }
  return result;
}

BOOL ZinAneTd<11u>::SetOrReturnCout(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1040) + 48), &v4);
  if (result) {
    *(_DWORD *)(a1 + 508) = *(_DWORD *)(a1 + 508) & 0xFFFE0000 | v4 & 0x1FFFF;
  }
  return result;
}

uint64_t ZinAneTd<11u>::SetUnicastEn(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 0x4000;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 5std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_DWORD *)(result + 532) & 0xFFFFBFFF | v2;
  return result;
}

BOOL ZinAneTd<11u>::SetUnicastCin(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1040) + 192), &v4);
  if (result) {
    *(_WORD *)(a1 + 534) = v4;
  }
  return result;
}

uint64_t ZinAneTd<17u>::SetWARdmaDependency(uint64_t result, uint64_t a2, int a3, unsigned __int8 a4, int **a5)
{
  if (!*(unsigned char *)(a2 + 1323)) {
    ZinAssertImpl("inconsistent WAR support");
  }
  if (a3)
  {
    int v5 = *a5;
    int v6 = a5[1];
    if (*a5 != v6)
    {
      do
      {
        uint64_t v7 = *v5;
        if (v7 <= 2) {
          *(_DWORD *)(result + 1236) |= dword_211F0435C[v7];
        }
        ++v5;
      }
      while (v5 != v6);
    }
    *(_DWORD *)(result + 1236) = *(_DWORD *)(result + 1236) & 0x7FFFFFF | (a4 << 27);
  }
  return result;
}

uint64_t ZinAneTd<17u>::SetL2Barrier(uint64_t result)
{
  *(_DWORD *)(result + 564) |= 0x800000u;
  return result;
}

_DWORD *ZinAneTd<17u>::SetEventFlags(_DWORD *result, int a2, int a3, int a4)
{
  result[4] = result[4] & 0xF0000000 | a2 & 0xFFFFFFF;
  result[8] = result[8] & 0xFC000000 | a4 & 0x3FFFFFF;
  result[6] = result[6] & 0xF0000000 | a3 & 0xFFFFFFF;
  return result;
}

BOOL ZinAneTd<17u>::SetL2SrcBaseAddress(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 312), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src Base Address");
  }
  *(_DWORD *)(a1 + 952) = *(_DWORD *)(a1 + 952) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<17u>::SetL2Src1ChannelStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x11uLL, (unsigned int *)(*(void *)(a1 + 1416) + 320), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src Channel Stride");
  }
  *(_DWORD *)(a1 + 956) = *(_DWORD *)(a1 + 956) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<17u>::SetL2SrcRowStride(uint64_t a1, ZinCodegen *this, ZinTensorDimensions *a3, uint64_t a4, uint64_t *a5)
{
  int v8 = 0;
  ZinCodegen::GetL2RowStride(this, a3, *(unsigned int *)(*(void *)(a1 + 1416) + 332), &v8, a5);
  unsigned int v7 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(v8, 0x11uLL, (unsigned int *)(*(void *)(a1 + 1416) + 328), &v7);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src Row Stride");
  }
  *(_DWORD *)(a1 + 96std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 960) & 0xFFE0000F | (16 * (v7 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<17u>::SetL2Src1DepthStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x11uLL, (unsigned int *)(*(void *)(a1 + 1416) + 336), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src Depth Stride");
  }
  *(_DWORD *)(a1 + 964) = *(_DWORD *)(a1 + 964) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<17u>::SetL2Src1GroupStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x11uLL, (unsigned int *)(*(void *)(a1 + 1416) + 344), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src Group Stride");
  }
  *(_DWORD *)(a1 + 968) = *(_DWORD *)(a1 + 968) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

uint64_t ZinAneTd<17u>::SetL2Src1DmaFormat(uint64_t result, int a2)
{
  switch(a2)
  {
    case 1:
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 940) & 0xFFFFFF3F;
      break;
    case 3:
    case 4:
    case 5:
    case 6:
    case 7:
    case 9:
    case 10:
      unsigned int v2 = *(_DWORD *)(result + 940) & 0xFFFFFF3F | 0x40;
      break;
    case 8:
      ZinAssertImpl("Packed10 format not fully implemented yet\n");
    case 11:
      unsigned int v2 = *(_DWORD *)(result + 940) | 0xC0;
      break;
    case 12:
    case 13:
      ZinAssertImpl("E4M3 or E5M2 format not supported");
    default:
      ZinAssertImpl("Invalid Dma Format");
  }
  *(_DWORD *)(result + 94std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2;
  return result;
}

uint64_t ZinAneTd<17u>::SetL2Src2DmaFormat(uint64_t result, int a2)
{
  switch(a2)
  {
    case 1:
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 944) & 0xFFFFFF3F;
      break;
    case 3:
    case 4:
    case 5:
    case 6:
    case 7:
    case 9:
    case 10:
      unsigned int v2 = *(_DWORD *)(result + 944) & 0xFFFFFF3F | 0x40;
      break;
    case 8:
      ZinAssertImpl("Packed10 format not fully implemented yet\n");
    case 11:
      unsigned int v2 = *(_DWORD *)(result + 944) | 0xC0;
      break;
    case 12:
    case 13:
      ZinAssertImpl("E4M3 or E5M2 format not supported");
    default:
      ZinAssertImpl("Invalid Dma Format");
  }
  *(_DWORD *)(result + 944) = v2;
  return result;
}

uint64_t ZinAneTd<17u>::SetL2ResultCfgDmaFmt(uint64_t result, int a2)
{
  switch(a2)
  {
    case 1:
    case 2:
    case 12:
    case 13:
      unsigned int v2 = *(_DWORD *)(result + 1008) & 0xFFFFFF3F;
      break;
    case 3:
    case 4:
    case 5:
    case 6:
    case 7:
    case 9:
    case 10:
      unsigned int v2 = *(_DWORD *)(result + 1008) & 0xFFFFFF3F | 0x40;
      break;
    case 8:
      ZinAssertImpl("packed10 format not fully implemented yet");
    case 11:
      unsigned int v2 = *(_DWORD *)(result + 1008) | 0xC0;
      break;
    default:
      ZinAssertImpl("Invalid tensor format");
  }
  *(_DWORD *)(result + 1008) = v2;
  return result;
}

uint64_t ZinAneTd<17u>::SetL2ResultWrapCfg(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 1036) & 0xFFFFF8FF | 0x400;
      goto LABEL_7;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 1036) & 0xFFFFF8FF | 0x300;
      goto LABEL_7;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 1036) & 0xFFFFF8FF | 0x100;
      goto LABEL_7;
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 1036) & 0xFFFFF8FF | 0x200;
      goto LABEL_7;
    case 4:
      ZinAssertImpl("Error: Invalid Wrap Axis");
    case 5:
      unsigned int v2 = *(_DWORD *)(result + 1036) & 0xFFFFF8FF;
LABEL_7:
      *(_DWORD *)(result + 1036) = v2;
      break;
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<17u>::SetL2ResultWrapStartOffset(uint64_t result, __int16 a2)
{
  *(_WORD *)(result + 1054) = a2;
  return result;
}

uint64_t ZinAneTd<17u>::SetL2ResultWrapIndex(uint64_t result, __int16 a2)
{
  *(_WORD *)(result + 1052) = a2;
  return result;
}

uint64_t ZinAneTd<17u>::SetL2ResultWrapAddrOffset(uint64_t result, __int16 a2)
{
  *(_DWORD *)(result + 1092) = *(_DWORD *)(result + 1092) & 0xF800FFFF | ((a2 & 0x7FF) << 16);
  return result;
}

uint64_t ZinAneTd<17u>::SetL2ResultWrapAddr(uint64_t result, __int16 a2)
{
  *(_DWORD *)(result + 1092) = *(_DWORD *)(result + 1092) & 0xFFFFF000 | a2 & 0xFFF;
  return result;
}

uint64_t ZinAneTd<17u>::SetL2SrcOffsetXlsbs(uint64_t result, char a2)
{
  *(_DWORD *)(result + 1096) = *(_DWORD *)(result + 1096) & 0xFFFFFFC0 | a2 & 0x3F;
  return result;
}

uint64_t ZinAneTd<17u>::SetL2SrcOffsetYlsbsFromCropOffsetY(uint64_t a1)
{
  uint64_t result = ZinExtractLSBs(*(unsigned __int16 *)(a1 + 736), 5);
  *(_DWORD *)(a1 + 1096) = *(_DWORD *)(a1 + 1096) & 0xFFFFE0FF | ((result & 0x1F) << 8);
  return result;
}

uint64_t ZinAneTd<17u>::SetSourceAddrWrap(uint64_t result, __int16 a2, __int16 a3)
{
  *(_DWORD *)(result + 108std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = a3 & 0xFFF | ((a2 & 0x7FF) << 16) | *(_DWORD *)(result + 1080) & 0xF800F000;
  return result;
}

uint64_t ZinAneTd<17u>::SetSourceWrap(uint64_t result, unsigned int a2, unsigned __int16 a3, unsigned __int16 a4)
{
  if (a2 >= 4) {
    ZinAssertImpl("Source wrapping dimension not acceptable\n");
  }
  *(_DWORD *)(result + 1036) = *(_DWORD *)(result + 1036) & 0xFFFFFFF8 | dword_211F04410[a2];
  *(_DWORD *)(result + 104std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = a4 | (a3 << 16);
  return result;
}

BOOL ZinAneTd<17u>::SetL2Src1Interleave(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 632), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Source Interleave");
  }
  *(_DWORD *)(a1 + 94std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 940) & 0xFFFFF0FF | ((v4 & 0xF) << 8);
  return result;
}

uint64_t ZinAneTd<17u>::SetL2Src1SourceType(uint64_t result, int a2)
{
  int v2 = 0;
  switch(a2)
  {
    case 0:
      ZinAssertImpl("Error: It must have a valid L2 access mode");
    case 1:
      int v2 = 2;
      break;
    case 2:
      int v2 = 1;
      break;
    case 4:
      int v2 = 3;
      break;
    default:
      break;
  }
  *(_DWORD *)(result + 94std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 940) & 0xFFFFFFFC | v2;
  return result;
}

uint64_t ZinAneTd<17u>::SetL2Src2SourceType(uint64_t result, int a2)
{
  int v2 = 0;
  switch(a2)
  {
    case 0:
      ZinAssertImpl("Error: It must have a valid L2 access mode");
    case 1:
      int v2 = 2;
      break;
    case 2:
      int v2 = 1;
      break;
    case 4:
      int v2 = 3;
      break;
    default:
      break;
  }
  *(_DWORD *)(result + 944) = *(_DWORD *)(result + 944) & 0xFFFFFFFC | v2;
  return result;
}

BOOL ZinAneTd<17u>::SetL2Src2BaseAddress(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 352), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src2 Base Address");
  }
  *(_DWORD *)(a1 + 972) = *(_DWORD *)(a1 + 972) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<17u>::SetL2Src2ChannelStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x11uLL, (unsigned int *)(*(void *)(a1 + 1416) + 360), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Source 2 Channel Stride");
  }
  *(_DWORD *)(a1 + 976) = *(_DWORD *)(a1 + 976) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<17u>::SetL2Src2RowStride(uint64_t a1, ZinCodegen *this, ZinTensorDimensions *a3, uint64_t a4, uint64_t *a5)
{
  int v8 = 0;
  ZinCodegen::GetL2RowStride(this, a3, *(unsigned int *)(*(void *)(a1 + 1416) + 372), &v8, a5);
  unsigned int v7 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(v8, 0x11uLL, (unsigned int *)(*(void *)(a1 + 1416) + 368), &v7);
  if (!result) {
    ZinAssertImpl("Illegal L2 Source 2 Row Stride");
  }
  *(_DWORD *)(a1 + 98std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 980) & 0xFFE0000F | (16 * (v7 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<17u>::SetL2Src2DepthStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x11uLL, (unsigned int *)(*(void *)(a1 + 1416) + 376), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Source 2 Depth Stride");
  }
  *(_DWORD *)(a1 + 984) = *(_DWORD *)(a1 + 984) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<17u>::SetL2Src2GroupStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x11uLL, (unsigned int *)(*(void *)(a1 + 1416) + 384), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Source 2 Group Stride");
  }
  *(_DWORD *)(a1 + 988) = *(_DWORD *)(a1 + 988) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

uint64_t ZinAneTd<17u>::SetL2Src2OffsetXlsbs(uint64_t result, char a2)
{
  *(_DWORD *)(result + 1096) = *(_DWORD *)(result + 1096) & 0xFFC0FFFF | ((a2 & 0x3F) << 16);
  return result;
}

uint64_t ZinAneTd<17u>::SetL2Src2OffsetYlsbsFromCropOffsetY(uint64_t a1)
{
  uint64_t result = ZinExtractLSBs(*(unsigned __int16 *)(a1 + 752), 5);
  *(_DWORD *)(a1 + 1096) = *(_DWORD *)(a1 + 1096) & 0xE0FFFFFF | ((result & 0x1F) << 24);
  return result;
}

uint64_t ZinAneTd<17u>::SetL2Src1CfgForCompression(uint64_t result, int a2)
{
  unsigned int v2 = *(_DWORD *)(result + 940) & 0xFDF80FFF;
  *(_DWORD *)(result + 94std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2 | 0x2000000;
  switch(a2)
  {
    case 1:
      unsigned int v3 = v2 & 0xF9F80FFF | 0x2000000;
LABEL_7:
      *(_DWORD *)(result + 94std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v3;
      return result;
    case 2:
      unsigned int v3 = v2 | 0x6000000;
      goto LABEL_7;
    case 0:
      ZinAssertImpl("Invalid macro block size");
  }
  return result;
}

uint64_t ZinAneTd<17u>::SetL2Src2CfgForCompression(uint64_t result, int a2)
{
  unsigned int v2 = *(_DWORD *)(result + 944) & 0xFDF80FFF;
  *(_DWORD *)(result + 944) = v2 | 0x2000000;
  switch(a2)
  {
    case 1:
      unsigned int v3 = v2 & 0xF9F80FFF | 0x2000000;
LABEL_7:
      *(_DWORD *)(result + 944) = v3;
      return result;
    case 2:
      unsigned int v3 = v2 | 0x6000000;
      goto LABEL_7;
    case 0:
      ZinAssertImpl("Invalid macro block size");
  }
  return result;
}

BOOL ZinAneTd<17u>::SetL2SrcIdxBaseAddr(uint64_t a1, unsigned int a2)
{
  *(_DWORD *)(a1 + 992) = *(_DWORD *)(a1 + 992) & 0xFFE0000F | (16 * (a2 & 0x1FFFF));
  return CheckRegValueRange(a2, (unsigned int *)(*(void *)(a1 + 1416) + 392));
}

BOOL ZinAneTd<17u>::SetL2SrcIdxChannelStride(uint64_t a1, unsigned int a2)
{
  *(_DWORD *)(a1 + 996) = *(_DWORD *)(a1 + 996) & 0xFFE0000F | (16 * (a2 & 0x1FFFF));
  return CheckRegValueRange(a2, (unsigned int *)(*(void *)(a1 + 1416) + 400));
}

BOOL ZinAneTd<17u>::SetL2SrcIdxGroupStride(uint64_t a1, unsigned int a2)
{
  *(_DWORD *)(a1 + 1004) = *(_DWORD *)(a1 + 1004) & 0xFFE0000F | (16 * (a2 & 0x1FFFF));
  return CheckRegValueRange(a2, (unsigned int *)(*(void *)(a1 + 1416) + 416));
}

BOOL ZinAneTd<17u>::SetL2SrcIdxDepthStride(uint64_t a1, unsigned int a2)
{
  *(_DWORD *)(a1 + 100std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 1000) & 0xFFE0000F | (16 * (a2 & 0x1FFFF));
  return CheckRegValueRange(a2, (unsigned int *)(*(void *)(a1 + 1416) + 408));
}

uint64_t ZinAneTd<17u>::SetL2ResultCfgForCompression(uint64_t result, int a2)
{
  unsigned int v2 = *(_DWORD *)(result + 1008) & 0xFDF80FFF;
  *(_DWORD *)(result + 1008) = v2 | 0x2000000;
  switch(a2)
  {
    case 1:
      unsigned int v3 = v2 & 0xF9F80FFF | 0x2000000;
LABEL_7:
      *(_DWORD *)(result + 1008) = v3;
      return result;
    case 2:
      unsigned int v3 = v2 | 0x6000000;
      goto LABEL_7;
    case 0:
      ZinAssertImpl("Invalid macro block size");
  }
  return result;
}

uint64_t ZinAneTd<17u>::SetSource2AddrWrap(uint64_t result, __int16 a2, __int16 a3)
{
  *(_DWORD *)(result + 1084) = a3 & 0xFFF | ((a2 & 0x7FF) << 16) | *(_DWORD *)(result + 1084) & 0xF800F000;
  return result;
}

uint64_t ZinAneTd<17u>::SetSource2Wrap(uint64_t result, unsigned int a2, unsigned __int16 a3, unsigned __int16 a4)
{
  if (a2 >= 4) {
    ZinAssertImpl("Source wrapping dimension not acceptable\n");
  }
  *(_DWORD *)(result + 1036) = *(_DWORD *)(result + 1036) & 0xFFFFFF8F | dword_211F04420[a2];
  *(_DWORD *)(result + 1044) = a4 | (a3 << 16);
  return result;
}

uint64_t ZinAneTd<17u>::SetOpMode(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 1180) & 0xFFFFFFF8;
      goto LABEL_8;
    case 1:
      ZinAssertImpl("ElemWise not valid for architecture");
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 1180) & 0xFFFFFFF8 | 3;
      goto LABEL_8;
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 1180) & 0xFFFFFFF8 | 1;
      goto LABEL_8;
    case 4:
      unsigned int v2 = *(_DWORD *)(result + 1180) & 0xFFFFFFF8 | 2;
      goto LABEL_8;
    case 5:
      unsigned int v2 = *(_DWORD *)(result + 1180) & 0xFFFFFFF8 | 4;
      goto LABEL_8;
    case 6:
      unsigned int v2 = *(_DWORD *)(result + 1180) & 0xFFFFFFF8 | 5;
LABEL_8:
      *(_DWORD *)(result + 118std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2;
      break;
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<17u>::SetKernelMode(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 1180) & 0xFFFFFFF7;
LABEL_7:
      *(_DWORD *)(result + 118std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2;
      return result;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 1180) | 8;
      goto LABEL_7;
    case 2:
      ZinAssertImpl("Unsupported Kernel Mode");
  }
  return result;
}

uint64_t ZinAneTd<17u>::SetPassthroughEnable(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 32;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 118std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 1180) & 0xFFFFFFDF | v2;
  return result;
}

uint64_t ZinAneTd<17u>::SetKernelFmt(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 1176) & 0xFFFFFFFC;
      goto LABEL_5;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 1176) & 0xFFFFFFFC | 1;
      goto LABEL_5;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 1176) & 0xFFFFFFFC | 2;
LABEL_5:
      *(_DWORD *)(result + 1176) = v2;
      break;
    case 3:
      ZinAssertImpl("Unimplemented or Unsupported kernel format");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<17u>::SetKernelDmaSrcCoeffDmaEn(uint64_t result, int a2, uint64_t a3)
{
  *(_DWORD *)(result + 4 * a3 + 8std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 4 * a3 + 80) & 0xFFFFFFFE | a2;
  return result;
}

uint64_t ZinAneTd<17u>::SetKernelDmaSrcConfigPrefetch(uint64_t result, uint64_t a2)
{
  if (*(_DWORD *)(a2 + 96) == 1)
  {
    int v2 = *(unsigned __int16 *)(result + 56) | (*(_DWORD *)(a2 + 104) << 16);
    *(_DWORD *)(result + 56) = v2;
    unsigned int v3 = v2 & 0xFFFFFFFE | *(unsigned __int8 *)(a2 + 112);
    *(_DWORD *)(result + 56) = v3;
    *(_DWORD *)(result + 56) = v3 & 0xFFFFFFFD | (2 * *(unsigned __int8 *)(a2 + 113));
  }
  return result;
}

uint64_t ZinAneTd<17u>::SetKernelDmaSrcCoeffDmaCacheHint(uint64_t result, int a2, uint64_t a3)
{
  int v3 = 224;
  switch(a2)
  {
    case 0:
      goto LABEL_5;
    case 1:
      int v3 = 32;
      goto LABEL_5;
    case 2:
      int v3 = 64;
      goto LABEL_5;
    case 3:
      int v3 = 192;
LABEL_5:
      *(_DWORD *)(result + 4 * a3 + 8std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 4 * a3 + 80) & 0xFFFFFF0F | v3;
      break;
    case 4:
      ZinAssertImpl("Error: Invalid KernelDmaSrc CoeffDma CacheHint");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<17u>::SetKernelDmaSrcPostScaleDmaCacheHint(uint64_t result, int a2)
{
  int v2 = 224;
  switch(a2)
  {
    case 0:
      goto LABEL_5;
    case 1:
      int v2 = 32;
      goto LABEL_5;
    case 2:
      int v2 = 64;
      goto LABEL_5;
    case 3:
      int v2 = 192;
LABEL_5:
      *(_DWORD *)(result + 288) = *(_DWORD *)(result + 288) & 0xFFFFFF0F | v2;
      break;
    case 4:
      ZinAssertImpl("Error: Invalid KernelDmaSrc PostScale Dma CacheHint");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<17u>::SetKernelDmaSrcBiasDmaCacheHint(uint64_t result, int a2)
{
  int v2 = 224;
  switch(a2)
  {
    case 0:
      goto LABEL_5;
    case 1:
      int v2 = 32;
      goto LABEL_5;
    case 2:
      int v2 = 64;
      goto LABEL_5;
    case 3:
      int v2 = 192;
LABEL_5:
      *(_DWORD *)(result + 272) = *(_DWORD *)(result + 272) & 0xFFFFFF0F | v2;
      break;
    case 4:
      ZinAssertImpl("Error: Invalid KernelDmaSrc PostScale Dma CacheHint");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<17u>::SetKernelDmaSrcPaletteLutDmaCacheHint(uint64_t result, int a2)
{
  int v2 = 224;
  switch(a2)
  {
    case 0:
      goto LABEL_5;
    case 1:
      int v2 = 32;
      goto LABEL_5;
    case 2:
      int v2 = 64;
      goto LABEL_5;
    case 3:
      int v2 = 192;
LABEL_5:
      *(_DWORD *)(result + 304) = *(_DWORD *)(result + 304) & 0xFFFFFF0F | v2;
      break;
    case 4:
      ZinAssertImpl("Error: Invalid KernelDmaSrc PaletteLut Dma CacheHint");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<17u>::SetKernelDmaSrcNonLinearLutDmaCacheHint(uint64_t result, int a2)
{
  int v2 = 224;
  switch(a2)
  {
    case 0:
      goto LABEL_5;
    case 1:
      int v2 = 32;
      goto LABEL_5;
    case 2:
      int v2 = 64;
      goto LABEL_5;
    case 3:
      int v2 = 192;
LABEL_5:
      *(_DWORD *)(result + 32std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 320) & 0xFFFFFF0F | v2;
      break;
    case 4:
      ZinAssertImpl("Error: Invalid KernelDmaSrc PostScale Dma CacheHint");
    default:
      return result;
  }
  return result;
}

BOOL ZinAneTd<17u>::SetKernelDmaSrcCoeffMemBufferSize(uint64_t a1, unsigned int a2, uint64_t a3)
{
  int v6 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 616), &v6);
  if (result) {
    *(_DWORD *)(a1 + 4 * a3 + 208) = *(_DWORD *)(a1 + 4 * a3 + 208) & 0x3F | (v6 << 6);
  }
  return result;
}

BOOL ZinAneTd<17u>::SetKernelDmaSrcCoeffBaseOffset(uint64_t a1, unsigned int a2, uint64_t a3)
{
  int v6 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 608), &v6);
  if (result) {
    *(_DWORD *)(a1 + 4 * a3 + 144) = *(_DWORD *)(a1 + 4 * a3 + 144) & 0x3F | (v6 << 6);
  }
  return result;
}

uint64_t ZinAneTd<17u>::SetKernelDmaSrcDataSetId(uint64_t result, char a2, uint64_t a3)
{
  *(unsigned char *)(result + 4 * a3 + 81) = a2;
  return result;
}

uint64_t ZinAneTd<17u>::SetPaddingMode(uint64_t result, int a2, int a3)
{
  switch(a2)
  {
    case 1:
      if (a3) {
        goto LABEL_12;
      }
      int v3 = 0;
      int v4 = 0;
      break;
    case 2:
      if (a3) {
        goto LABEL_12;
      }
      int v3 = 0;
      int v4 = 4;
      break;
    case 3:
      if (a3) {
        goto LABEL_12;
      }
      int v4 = 8;
      int v3 = 0x40000;
      break;
    case 4:
      if (a3) {
LABEL_12:
      }
        ZinAssertImpl("Error: padding-mode doesn't support constants");
      int v3 = 0;
      int v4 = 12;
      break;
    case 6:
      ZinAssertImpl("Platform doesn't support reflective padding mode");
    case 9:
      int v4 = 0;
      int v3 = (a3 != 0) << 18;
      break;
    default:
      ZinAssertImpl("Invalid padding mode: %d", a2);
  }
  *(_DWORD *)(result + 936) = v4 & 0xFF00FFFF | (a3 << 16) | *(_DWORD *)(result + 936) & 0xFF00FFF3;
  *(_DWORD *)(result + 118std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 1180) & 0xFFFBFFFF | v3;
  return result;
}

uint64_t ZinAneTd<17u>::SetKernelDmaSrcEnable(uint64_t result)
{
  *(_DWORD *)(result + 48) |= 0x40u;
  return result;
}

uint64_t ZinAneTd<17u>::SetKernelAlignmentFormat(uint64_t result, int a2)
{
  if (a2)
  {
    if (a2 != 1) {
      return result;
    }
    unsigned int v2 = *(_DWORD *)(result + 1176) & 0xFFFEFFFF;
  }
  else
  {
    unsigned int v2 = *(_DWORD *)(result + 1176) | 0x10000;
  }
  *(_DWORD *)(result + 1176) = v2;
  return result;
}

void ZinAneTd<17u>::SetAlignedKernelRelocationCommand(uint64_t a1, void *a2, uint64_t a3, const void **a4, uint64_t a5)
{
  if (a2[1])
  {
    if (*((char *)a4 + 23) >= 0) {
      size_t v10 = *((unsigned __int8 *)a4 + 23);
    }
    else {
      size_t v10 = (size_t)a4[1];
    }
    long long v11 = __p;
    std::string::basic_string[abi:ne180100]((uint64_t)__p, v10 + 7);
    if (v24 < 0) {
      long long v11 = (void **)__p[0];
    }
    if (v10)
    {
      if (*((char *)a4 + 23) >= 0) {
        uint64_t v12 = a4;
      }
      else {
        uint64_t v12 = *a4;
      }
      memmove(v11, v12, v10);
    }
    strcpy((char *)v11 + v10, "_actlut");
    ZinAneTdHw_v17::AddRelocInfo((uint64_t *)(a1 + 8), (uint64_t)__p, 5510, a3, 1, 1, a5, 0);
    if (v24 < 0) {
      operator delete(__p[0]);
    }
  }
  if (a2[2])
  {
    if (*((char *)a4 + 23) >= 0) {
      size_t v13 = *((unsigned __int8 *)a4 + 23);
    }
    else {
      size_t v13 = (size_t)a4[1];
    }
    int v14 = __p;
    std::string::basic_string[abi:ne180100]((uint64_t)__p, v13 + 7);
    if (v24 < 0) {
      int v14 = (void **)__p[0];
    }
    if (v13)
    {
      if (*((char *)a4 + 23) >= 0) {
        int v15 = a4;
      }
      else {
        int v15 = *a4;
      }
      memmove(v14, v15, v13);
    }
    strcpy((char *)v14 + v13, "_pallut");
    ZinAneTdHw_v17::AddRelocInfo((uint64_t *)(a1 + 8), (uint64_t)__p, 5506, a3, 1, 1, a5, 0);
    if (v24 < 0) {
      operator delete(__p[0]);
    }
  }
  if (a2[3])
  {
    if (*((char *)a4 + 23) >= 0) {
      size_t v16 = *((unsigned __int8 *)a4 + 23);
    }
    else {
      size_t v16 = (size_t)a4[1];
    }
    int v17 = __p;
    std::string::basic_string[abi:ne180100]((uint64_t)__p, v16 + 6);
    if (v24 < 0) {
      int v17 = (void **)__p[0];
    }
    if (v16)
    {
      if (*((char *)a4 + 23) >= 0) {
        uint64_t v18 = a4;
      }
      else {
        uint64_t v18 = *a4;
      }
      memmove(v17, v18, v16);
    }
    strcpy((char *)v17 + v16, "_scale");
    ZinAneTdHw_v17::AddRelocInfo((uint64_t *)(a1 + 8), (uint64_t)__p, 5502, a3, 1, 1, a5, 0);
    if (v24 < 0) {
      operator delete(__p[0]);
    }
  }
  if (a2[4])
  {
    size_t v19 = (uint64_t *)(a1 + 8);
    if (*((char *)a4 + 23) >= 0) {
      size_t v20 = *((unsigned __int8 *)a4 + 23);
    }
    else {
      size_t v20 = (size_t)a4[1];
    }
    long long v21 = __p;
    std::string::basic_string[abi:ne180100]((uint64_t)__p, v20 + 5);
    if (v24 < 0) {
      long long v21 = (void **)__p[0];
    }
    if (v20)
    {
      if (*((char *)a4 + 23) >= 0) {
        size_t v22 = a4;
      }
      else {
        size_t v22 = *a4;
      }
      memmove(v21, v22, v20);
    }
    strcpy((char *)v21 + v20, "_bias");
    ZinAneTdHw_v17::AddRelocInfo(v19, (uint64_t)__p, 5498, a3, 1, 1, a5, 0);
    if (v24 < 0) {
      operator delete(__p[0]);
    }
  }
}

void sub_2112D5714(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, void *__p, uint64_t a10, int a11, __int16 a12, char a13, char a14)
{
  if (a14 < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

_DWORD *ZinAneTd<17u>::SetAlignedKernelBias(_DWORD *result, uint64_t a2, uint64_t a3, int a4)
{
  result[12] = result[12] & 0xFFFFFFF3 | 8;
  result[294] = result[294] & 0xFFF9FFFF | 0x40000;
  result[69] = result[69] & 0x3F | (a4 << 6);
  result[68] |= 1u;
  return result;
}

_DWORD *ZinAneTd<17u>::SetAlignedKernelPostScale(_DWORD *result, uint64_t a2, uint64_t a3, int a4)
{
  result[12] = result[12] & 0xFFFFFFFC | 2;
  result[294] = result[294] & 0xFFE7FFFF | 0x100000;
  result[73] = result[73] & 0x3F | (a4 << 6);
  result[72] |= 1u;
  return result;
}

uint64_t ZinAneTd<17u>::SetAlignedKernelPaletteLut(uint64_t result, uint64_t a2, uint64_t a3, int a4)
{
  *(_DWORD *)(result + 308) = *(_DWORD *)(result + 308) & 0x3F | (a4 << 6);
  *(_DWORD *)(result + 304) |= 1u;
  return result;
}

uint64_t ZinAneTd<17u>::SetAlignedKernelNonLinearLut(uint64_t result, uint64_t a2, uint64_t a3, int a4)
{
  *(_DWORD *)(result + 324) = *(_DWORD *)(result + 324) & 0x3F | (a4 << 6);
  *(_DWORD *)(result + 320) |= 1u;
  return result;
}

uint64_t ZinAneTd<17u>::SetAlignedCoeffSizePerCh(uint64_t result, int a2)
{
  *(_DWORD *)(result + 52) = *(_DWORD *)(result + 52) & 0xF0000000 | a2 & 0xFFFFFFF;
  return result;
}

uint64_t ZinAneTd<17u>::SetQuantizationSrc1InputOffset(uint64_t result, char a2)
{
  *(unsigned char *)(result + 1164) = a2;
  return result;
}

uint64_t ZinAneTd<17u>::SetQuantizationSrc2InputOffset(uint64_t result, char a2)
{
  *(unsigned char *)(result + 1165) = a2;
  return result;
}

uint64_t ZinAneTd<17u>::SetPEOutputQuantization(uint64_t result, char a2)
{
  *(unsigned char *)(result + 1166) = a2;
  return result;
}

uint64_t ZinAneTd<17u>::SetPEFinalScale(uint64_t result, float a2)
{
  *(float *)(result + 1128) = a2;
  return result;
}

void ZinAneTd<17u>::SetPEScale(uint64_t a1, float a2)
{
  *(float *)(a1 + 1116) = ZinF32ToNearestF19(a2);
}

void ZinAneTd<17u>::SetPEBias(uint64_t a1, float a2)
{
  *(float *)(a1 + 1112) = ZinF32ToNearestF19(a2);
}

void ZinAneTd<17u>::SetPEPreScale(uint64_t a1, float a2)
{
  *(float *)(a1 + 1124) = ZinF32ToNearestF19(a2);
}

uint64_t ZinAneTd<17u>::SetPESrc1ReLu(uint64_t result, int a2)
{
  *(_DWORD *)(result + 936) = *(_DWORD *)(result + 936) & 0xFFFFFFFE | a2;
  return result;
}

uint64_t ZinAneTd<17u>::SetPESrc2ReLu(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 16;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 936) = *(_DWORD *)(result + 936) & 0xFFFFFFEF | v2;
  return result;
}

uint64_t ZinAneTd<17u>::SetPESrc1Transpose(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 256;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 576) = *(_DWORD *)(result + 576) & 0xFFFFFEFF | v2;
  return result;
}

uint64_t ZinAneTd<17u>::SetPESrc2Transpose(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 512;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 576) = *(_DWORD *)(result + 576) & 0xFFFFFDFF | v2;
  return result;
}

uint64_t ZinAneTd<17u>::SetPESrc1Broadcast(uint64_t result, uint64_t a2)
{
  for (uint64_t i = *(uint64_t **)(a2 + 16); i; uint64_t i = (uint64_t *)*i)
  {
    unsigned int v3 = *((_DWORD *)i + 4) - 1;
    if (v3 <= 3) {
      *(_DWORD *)(result + 576) |= dword_211F04430[v3];
    }
  }
  return result;
}

uint64_t ZinAneTd<17u>::SetPESrc2Broadcast(uint64_t result, uint64_t a2, char a3)
{
  for (uint64_t i = *(uint64_t **)(a2 + 16); i; uint64_t i = (uint64_t *)*i)
  {
    int v4 = 128;
    switch(*((_DWORD *)i + 4))
    {
      case 1:
        int v4 = 64;
        break;
      case 2:
        break;
      case 3:
        if (a3) {
          continue;
        }
        int v4 = 32;
        break;
      case 4:
        if (a3) {
          continue;
        }
        int v4 = 16;
        break;
      default:
        continue;
    }
    *(_DWORD *)(result + 576) |= v4;
  }
  return result;
}

void ZinAneTd<17u>::SetPEIndexMode(uint64_t a1, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(a1 + 1076) & 0xFFF8FFFF | 0x10000;
      goto LABEL_7;
    case 1:
      unsigned int v2 = *(_DWORD *)(a1 + 1076) & 0xFFF8FFFF | 0x20000;
      goto LABEL_7;
    case 2:
      unsigned int v2 = *(_DWORD *)(a1 + 1076) & 0xFFF8FFFF | 0x50000;
      goto LABEL_7;
    case 3:
      unsigned int v2 = *(_DWORD *)(a1 + 1076) & 0xFFF8FFFF | 0x30000;
      goto LABEL_7;
    case 4:
      unsigned int v2 = *(_DWORD *)(a1 + 1076) & 0xFFF8FFFF | 0x40000;
LABEL_7:
      *(_DWORD *)(a1 + 1076) = v2;
      break;
    case 5:
      BOOL v3 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v3) {
        ZinAneTd<8u>::SetPEIndexMode(v3, v4, v5, v6, v7, v8, v9, v10);
      }
      break;
    default:
      return;
  }
}

uint64_t ZinAneTd<17u>::SetPEIndexTranspose(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 0x4000000;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 1076) = *(_DWORD *)(result + 1076) & 0xFBFFFFFF | v2;
  return result;
}

uint64_t ZinAneTd<17u>::SetPEIndexBroadcast(uint64_t result, uint64_t a2)
{
  int v2 = *(uint64_t **)(a2 + 16);
  if (v2)
  {
    while (1)
    {
      int v3 = *((_DWORD *)v2 + 4);
      if (v3 == 2) {
        break;
      }
      if (v3 == 1)
      {
        int v4 = 0x1000000;
LABEL_6:
        *(_DWORD *)(result + 1076) |= v4;
      }
      int v2 = (uint64_t *)*v2;
      if (!v2) {
        return result;
      }
    }
    int v4 = 0x2000000;
    goto LABEL_6;
  }
  return result;
}

uint64_t ZinAneTd<17u>::SetPEMaxIndex(uint64_t result, __int16 a2)
{
  *(_WORD *)(result + 1076) = a2;
  return result;
}

uint64_t ZinAneTd<17u>::SetPEOperationMode(uint64_t a1, int a2)
{
  uint64_t v2 = 0;
  switch(a2)
  {
    case 0:
      *(_DWORD *)(a1 + 1108) &= 0xFFFFFFE3;
      int v3 = (unsigned int *)(*(void *)(a1 + 1416) + 648);
      unint64_t v4 = 0;
      goto LABEL_8;
    case 1:
      *(_DWORD *)(a1 + 1108) = *(_DWORD *)(a1 + 1108) & 0xFFFFFFE3 | 4;
      int v3 = (unsigned int *)(*(void *)(a1 + 1416) + 648);
      unint64_t v4 = 1;
      goto LABEL_8;
    case 2:
      *(_DWORD *)(a1 + 1108) = *(_DWORD *)(a1 + 1108) & 0xFFFFFFE3 | 0x10;
      if (!CheckRegValueRange(4uLL, (unsigned int *)(*(void *)(a1 + 1416) + 648))) {
        goto LABEL_5;
      }
      goto LABEL_9;
    case 3:
      *(_DWORD *)(a1 + 1108) = *(_DWORD *)(a1 + 1108) & 0xFFFFFFE3 | 8;
      int v3 = (unsigned int *)(*(void *)(a1 + 1416) + 648);
      unint64_t v4 = 2;
      goto LABEL_8;
    case 4:
      *(_DWORD *)(a1 + 1108) = *(_DWORD *)(a1 + 1108) & 0xFFFFFFE3 | 0xC;
      int v3 = (unsigned int *)(*(void *)(a1 + 1416) + 648);
      unint64_t v4 = 3;
LABEL_8:
      if (CheckRegValueRange(v4, v3)) {
        goto LABEL_9;
      }
LABEL_5:
      uint64_t v2 = 0;
      break;
    case 5:
      return v2;
    default:
LABEL_9:
      uint64_t v2 = 1;
      break;
  }
  return v2;
}

uint64_t ZinAneTd<17u>::SetPEFirstSource(uint64_t result, int a2)
{
  if (a2)
  {
    if (a2 != 1) {
      return result;
    }
    unsigned int v2 = *(_DWORD *)(result + 1108) & 0xFFFEFFFF;
  }
  else
  {
    unsigned int v2 = *(_DWORD *)(result + 1108) | 0x10000;
  }
  *(_DWORD *)(result + 1108) = v2;
  return result;
}

uint64_t ZinAneTd<17u>::SetPESecondSource(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 1108) & 0xFFF3FFFF;
      goto LABEL_6;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 1108) & 0xFFF3FFFF | 0x40000;
      goto LABEL_6;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 1108) & 0xFFF3FFFF | 0x80000;
      goto LABEL_6;
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 1108) | 0xC0000;
LABEL_6:
      *(_DWORD *)(result + 1108) = v2;
      break;
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<17u>::SetPECondition(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 1108) & 0xFFFFFE3F;
      goto LABEL_10;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 1108) | 0x1C0;
      goto LABEL_10;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 1108) & 0xFFFFFE3F | 0x100;
      goto LABEL_10;
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 1108) & 0xFFFFFE3F | 0x180;
      goto LABEL_10;
    case 4:
      unsigned int v2 = *(_DWORD *)(result + 1108) & 0xFFFFFE3F | 0x80;
      goto LABEL_10;
    case 5:
      unsigned int v2 = *(_DWORD *)(result + 1108) & 0xFFFFFE3F | 0x140;
      goto LABEL_10;
    case 6:
      unsigned int v2 = *(_DWORD *)(result + 1108) & 0xFFFFFE3F | 0x40;
      goto LABEL_10;
    case 7:
      unsigned int v2 = *(_DWORD *)(result + 1108) & 0xFFFFFE3F | 0xC0;
LABEL_10:
      *(_DWORD *)(result + 1108) = v2;
      break;
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<17u>::SetPEOutputCtoW(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 1024;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 576) = *(_DWORD *)(result + 576) & 0xFFFFFBFF | v2;
  return result;
}

BOOL ZinAneTd<17u>::SetL2ResultBaseAddr(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 424), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Result Base Address");
  }
  *(_DWORD *)(a1 + 1012) = *(_DWORD *)(a1 + 1012) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<17u>::SetL2ResultChannelStride(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 432), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Result Channel Stride");
  }
  *(_DWORD *)(a1 + 1016) = *(_DWORD *)(a1 + 1016) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<17u>::SetL2ResultRowStride(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 440), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Result Row Stride");
  }
  *(_DWORD *)(a1 + 102std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 1020) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<17u>::SetL2ResultDepthStride(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 448), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Result Depth Stride");
  }
  *(_DWORD *)(a1 + 1024) = *(_DWORD *)(a1 + 1024) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<17u>::SetL2ResultGroupStride(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 456), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Result Group Stride");
  }
  *(_DWORD *)(a1 + 1028) = *(_DWORD *)(a1 + 1028) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

uint64_t ZinAneTd<17u>::SetL2BfrMode(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 8;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 1008) = *(_DWORD *)(result + 1008) & 0xFFFFFFF7 | v2;
  return result;
}

uint64_t ZinAneTd<17u>::SetL2ResultType(uint64_t result, int a2)
{
  switch(a2)
  {
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 1008) & 0xFFFFFFFC | 2;
      break;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 1008) & 0xFFFFFFFC | 1;
      break;
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 1008) & 0xFFFFFFFC;
      break;
    case 4:
      unsigned int v2 = *(_DWORD *)(result + 1008) | 3;
      break;
    default:
      ZinAssertImpl("Invalid L2 Result Type");
  }
  *(_DWORD *)(result + 1008) = v2;
  return result;
}

uint64_t ZinAneTd<17u>::SetTileDmaSrc1Format(uint64_t result, int a2, int a3)
{
  switch(a2)
  {
    case 1:
      unsigned int v3 = *(_DWORD *)(result + 708) & 0xFFFFCFFC | 0x1000;
      goto LABEL_16;
    case 2:
      unsigned int v3 = *(_DWORD *)(result + 708) & 0xFFFFCFFC;
      goto LABEL_16;
    case 3:
      unsigned int v4 = *(_DWORD *)(result + 708) & 0xFFFFCFCC;
      int v5 = 8241;
      break;
    case 4:
      unsigned int v3 = *(_DWORD *)(result + 708) & 0xFFFFCECC | 1;
      goto LABEL_16;
    case 5:
      unsigned int v4 = *(_DWORD *)(result + 708) & 0xFFFFCECC;
      int v5 = 257;
      break;
    case 6:
      unsigned int v4 = *(_DWORD *)(result + 708) & 0xFFFFCECC;
      int v5 = 17;
      break;
    case 7:
      unsigned int v4 = *(_DWORD *)(result + 708) & 0xFFFFCECC;
      int v5 = 273;
      break;
    case 8:
      ZinAssertImpl("Packed10 format not supported");
    case 9:
      unsigned int v4 = *(_DWORD *)(result + 708) & 0xFFFFCECC;
      if (!a3) {
        goto LABEL_14;
      }
      int v5 = 4401;
      break;
    case 10:
      unsigned int v4 = *(_DWORD *)(result + 708) & 0xFFFFCECC;
      if (a3) {
        int v5 = 305;
      }
      else {
LABEL_14:
      }
        int v5 = 8497;
      break;
    case 11:
      unsigned int v4 = *(_DWORD *)(result + 708) & 0xFFFFFFCF;
      int v5 = 12547;
      break;
    case 12:
      ZinAssertImpl("E4M3 format is not supported");
    case 13:
      ZinAssertImpl("E5M2 format is not supported");
    default:
      ZinAssertImpl("Invalid format provided");
  }
  unsigned int v3 = v4 | v5;
LABEL_16:
  *(_DWORD *)(result + 708) = v3;
  return result;
}

BOOL ZinAneTd<17u>::SetTileDmaSrc1Interleave(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 632), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc1 Interleave");
  }
  *(_DWORD *)(a1 + 708) = *(_DWORD *)(a1 + 708) & 0xF0FFFFFF | ((v4 & 0xF) << 24);
  return result;
}

uint64_t ZinAneTd<17u>::SetTileDmaSrc1Enable(uint64_t result)
{
  *(_DWORD *)(result + 604) |= 1u;
  return result;
}

uint64_t ZinAneTd<17u>::SetTileDmaSrc1CacheHint(uint64_t result, int a2, int a3, int a4)
{
  int v4 = 224;
  switch(a2)
  {
    case 0:
      goto LABEL_5;
    case 1:
      int v4 = 32;
      goto LABEL_5;
    case 2:
      int v4 = 64;
      goto LABEL_5;
    case 3:
      int v4 = 192;
LABEL_5:
      *(_DWORD *)(result + 604) = *(_DWORD *)(result + 604) & 0xFFFFFF0F | v4;
      break;
    case 4:
LABEL_15:
      ZinAssertImpl("Invalid CacheHint");
    default:
      break;
  }
  char v5 = 32;
  switch(a4)
  {
    case 0:
      char v5 = -32;
      goto LABEL_10;
    case 2:
      char v5 = 64;
      goto LABEL_10;
    case 3:
      char v5 = -64;
      goto LABEL_10;
    case 4:
      goto LABEL_15;
    default:
LABEL_10:
      char v6 = 2;
      switch(a3)
      {
        case 0:
          char v6 = 14;
          goto LABEL_14;
        case 2:
          char v6 = 4;
          goto LABEL_14;
        case 3:
          char v6 = 12;
          goto LABEL_14;
        case 4:
          goto LABEL_15;
        default:
LABEL_14:
          *(unsigned char *)(result + 612) = v6 | v5;
          return result;
      }
  }
}

BOOL ZinAneTd<17u>::SetTileDmaSrc1ChannelStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 1416) + 488), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc1 Channel Stride");
  }
  *(_DWORD *)(a1 + 6std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_DWORD *)(a1 + 632) & 0x3F | (v4 << 6);
  return result;
}

BOOL ZinAneTd<17u>::SetTileDmaSrc1RowStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 1416) + 480), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc1 Row Stride");
  }
  *(_DWORD *)(a1 + 628) = *(_DWORD *)(a1 + 628) & 0x3F | (v4 << 6);
  return result;
}

BOOL ZinAneTd<17u>::SetTileDmaSrc1DepthStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 1416) + 496), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc1 Depth Stride");
  }
  *(_DWORD *)(a1 + 636) = *(_DWORD *)(a1 + 636) & 0x3F | (v4 << 6);
  return result;
}

BOOL ZinAneTd<17u>::SetTileDmaSrc1GroupStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 1416) + 504), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc1 Group Stride");
  }
  *(_DWORD *)(a1 + 64std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 640) & 0x3F | (v4 << 6);
  return result;
}

uint64_t ZinAneTd<17u>::SetTileDmaSrc1CropOffset(uint64_t result, unsigned __int16 a2, unsigned __int16 a3)
{
  *(_DWORD *)(result + 736) = a3 | (a2 << 16);
  return result;
}

uint64_t ZinAneTd<17u>::SetTileDmaSrc1WrapStatic(uint64_t a1, unsigned __int16 a2, unsigned __int16 a3, unsigned int a4)
{
  uint64_t result = ZinAneTd<17u>::SetTileDmaSrc1WrapCfg(a1, a4);
  *(_DWORD *)(a1 + 788) = a3 | (a2 << 16);
  return result;
}

uint64_t ZinAneTd<17u>::SetTileDmaSrc1WrapCfg(uint64_t a1, unsigned int a2)
{
  if (a2 == 4) {
    ZinAssertImpl("Width wrap axis is not supported on this architecture");
  }
  uint64_t result = ZinIrCodegenGetDMAWrapCfgDim(a2);
  *(_DWORD *)(a1 + 612) = *(_DWORD *)(a1 + 612) & 0xFFFFF8FF | ((result & 7) << 8);
  return result;
}

uint64_t ZinAneTd<17u>::SetTileDmaSrc1WrapDynamic(uint64_t a1, uint64_t a2, unsigned int a3)
{
  char v6 = (uint64_t *)(a1 + 8);
  std::string::basic_string[abi:ne180100]<0>(__p, &byte_211F4AA5D);
  ZinAneTdHw_v17::AddRelocInfo(v6, (uint64_t)__p, 4974, a2, 0, 0, 0, 0);
  if (v9 < 0) {
    operator delete(__p[0]);
  }
  return ZinAneTd<17u>::SetTileDmaSrc1WrapCfg(a1, a3);
}

void sub_2112D6634(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11, int a12, __int16 a13, char a14, char a15)
{
  if (a15 < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinAneTd<17u>::SetTileDmaSrc1FmtOffsetCh(uint64_t result, char a2)
{
  *(_DWORD *)(result + 708) = *(_DWORD *)(result + 708) & 0xFFF8FFFF | ((a2 & 7) << 16);
  return result;
}

uint64_t ZinAneTd<17u>::SetTileDmaSrc1FmtCmpVec(uint64_t result, unsigned __int8 a2)
{
  *(_DWORD *)(result + 708) = *(_DWORD *)(result + 708) & 0xFFFFFFF | (a2 << 28);
  return result;
}

uint64_t ZinAneTd<17u>::SetTileDmaSrc1BaseAddrLo(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return ZinAneTdHw_v17::AddRelocInfo((uint64_t *)(a1 + 8), a2, 4932, a3, 1, 1, 0, 0);
}

uint64_t ZinAneTd<17u>::SetTileDmaSrc1DependencyMode(uint64_t result, int a2)
{
  if (a2 == 2)
  {
    unsigned int v2 = *(_DWORD *)(result + 604) & 0xCFFFFFFF | 0x10000000;
  }
  else if (a2 == 1)
  {
    unsigned int v2 = *(_DWORD *)(result + 604) & 0xCFFFFFFF | 0x20000000;
  }
  else
  {
    if (a2) {
      return result;
    }
    unsigned int v2 = *(_DWORD *)(result + 604) & 0xCFFFFFFF;
  }
  *(_DWORD *)(result + 604) = v2;
  return result;
}

uint64_t ZinAneTd<17u>::SetTileDmaSrc2DependencyMode(uint64_t result, int a2)
{
  if (a2 == 2)
  {
    unsigned int v2 = *(_DWORD *)(result + 608) & 0xCFFFFFFF | 0x10000000;
  }
  else if (a2 == 1)
  {
    unsigned int v2 = *(_DWORD *)(result + 608) & 0xCFFFFFFF | 0x20000000;
  }
  else
  {
    if (a2) {
      return result;
    }
    unsigned int v2 = *(_DWORD *)(result + 608) & 0xCFFFFFFF;
  }
  *(_DWORD *)(result + 608) = v2;
  return result;
}

unint64_t ZinAneTd<17u>::SetTileDmaSrc1DependencyInterval(uint64_t a1, unsigned int a2)
{
  unint64_t result = ZinIrCodegenValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 640));
  *(_DWORD *)(a1 + 604) = *(_DWORD *)(a1 + 604) & 0xF0FFFFFF | ((result & 0xF) << 24);
  return result;
}

unint64_t ZinAneTd<17u>::SetTileDmaSrc2DependencyInterval(uint64_t a1, unsigned int a2)
{
  unint64_t result = ZinIrCodegenValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 640));
  *(_DWORD *)(a1 + 608) = *(_DWORD *)(a1 + 608) & 0xF0FFFFFF | ((result & 0xF) << 24);
  return result;
}

uint64_t *ZinAneTd<17u>::SetTileDmaSrc1DependencyOffset(uint64_t a1, void *a2)
{
  int v4 = 1;
  unint64_t result = std::__hash_table<ZinIrDimension,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,std::allocator<ZinIrDimension>>::find<ZinIrDimension>(a2, &v4);
  if (result) {
    *(_DWORD *)(a1 + 796) = result[3];
  }
  return result;
}

uint64_t *ZinAneTd<17u>::SetTileDmaSrc2DependencyOffset(uint64_t a1, void *a2)
{
  int v4 = 1;
  unint64_t result = std::__hash_table<ZinIrDimension,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,std::allocator<ZinIrDimension>>::find<ZinIrDimension>(a2, &v4);
  if (result) {
    *(_DWORD *)(a1 + 80std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = result[3];
  }
  return result;
}

uint64_t ZinAneTd<17u>::SetTileDmaSrc1OffsetY(uint64_t result, __int16 a2)
{
  *(_WORD *)(result + 736) = a2;
  return result;
}

int8x16_t ZinAneTd<17u>::SetTileDmaSrc1PixelOffset(uint64_t a1, unsigned int a2, unsigned int a3, unsigned int a4, unsigned int a5)
{
  v5.i64[0] = __PAIR64__(a3, a2);
  v5.i64[1] = __PAIR64__(a5, a4);
  v6.i64[0] = 0xFFFF0000FFFF0000;
  v6.i64[1] = 0xFFFF0000FFFF0000;
  int8x16_t result = vbslq_s8(v6, *(int8x16_t *)(a1 + 756), v5);
  *(int8x16_t *)(a1 + 756) = result;
  return result;
}

uint64_t ZinAneTd<17u>::SetTileDmaSrc1CompressedInfo(uint64_t result, int a2, int a3, int a4)
{
  int v4 = *(_DWORD *)(result + 724);
  *(_DWORD *)(result + 724) = v4 | 1;
  switch(a4)
  {
    case 0:
      unsigned int v5 = v4 & 0xFFFFCFFE | 1;
      break;
    case 1:
      unsigned int v5 = v4 & 0xFFFFCFFE | 0x1001;
      break;
    case 2:
      unsigned int v5 = v4 & 0xFFFFCFFE | 0x2001;
      break;
    case 3:
      unsigned int v5 = v4 | 0x3001;
      break;
    default:
      ZinAssertImpl("Invalid Lossy Mode");
  }
  *(_DWORD *)(result + 724) = v5;
  if (a3 == 2)
  {
    unsigned int v6 = v5 | 4;
  }
  else
  {
    if (a3 != 1) {
      ZinAssertImpl("Unsupported macro block size");
    }
    unsigned int v6 = v5 & 0xFFFFFFFB;
  }
  *(_DWORD *)(result + 724) = v6;
  if ((a2 - 1) >= 0x13) {
    ZinAssertImpl("Invalid packing format");
  }
  *(_DWORD *)(result + 724) = v6 & 0xFFFFFC0F | dword_211F04368[a2 - 1];
  return result;
}

BOOL ZinAneTd<17u>::SetTileDmaSrc1CompressedSize(uint64_t a1, unsigned int a2, unsigned int a3)
{
  int v7 = 0;
  if (!ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 24), &v7)) {
    ZinAssertImpl("Illegal TileDmaSrc1 Compressed Width");
  }
  *(_DWORD *)(a1 + 728) = *(_DWORD *)(a1 + 728) & 0xFFFE0000 | v7 & 0x1FFFF;
  int v6 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a3, (unsigned int *)(*(void *)(a1 + 1416) + 16), &v6);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc1 Compressed Height");
  }
  *(_DWORD *)(a1 + 7std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_DWORD *)(a1 + 732) & 0xFFFE0000 | v6 & 0x1FFFF;
  return result;
}

double ZinAneTd<17u>::SetTileDmaSrc1MetaData(uint64_t a1, uint64_t a2, uint64_t a3, unsigned int a4, unsigned int a5, int a6)
{
  ZinAneTdHw_v17::AddRelocInfo((uint64_t *)(a1 + 8), a2, 4944, a3, 1, 1, 0, 0);
  *(_DWORD *)(a1 + 724) &= ~8u;
  double result = COERCE_DOUBLE(__PAIR64__(a5, a4));
  *(int32x2_t *)(a1 + 684) = vsli_n_s32(*(int32x2_t *)(a1 + 684), (int32x2_t)__PAIR64__(a5, a4), 7uLL);
  *(_DWORD *)(a1 + 692) = *(_DWORD *)(a1 + 692) & 0x7F | (a6 << 7);
  return result;
}

uint64_t ZinAneTd<17u>::SetTileDmaSrc1NoMetaData(uint64_t result)
{
  *(_DWORD *)(result + 724) |= 8u;
  return result;
}

uint64_t ZinAneTd<17u>::SetTileDmaSrc1DataSetId(uint64_t result, char a2)
{
  *(unsigned char *)(result + 605) = a2;
  return result;
}

BOOL ZinAneTd<17u>::SetL2Src2Interleave(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 632), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Source Interleave");
  }
  *(_DWORD *)(a1 + 944) = *(_DWORD *)(a1 + 944) & 0xFFFFF0FF | ((v4 & 0xF) << 8);
  return result;
}

uint64_t ZinAneTd<17u>::SetTileDmaSrc2Enable(uint64_t result)
{
  *(_DWORD *)(result + 608) |= 1u;
  return result;
}

uint64_t ZinAneTd<17u>::SetTileDmaSrc2CropOffset(uint64_t result, unsigned __int16 a2, unsigned __int16 a3)
{
  *(_DWORD *)(result + 752) = a3 | (a2 << 16);
  return result;
}

uint64_t ZinAneTd<17u>::SetTileDmaSrc2WrapStatic(uint64_t a1, unsigned __int16 a2, unsigned __int16 a3, unsigned int a4)
{
  uint64_t result = ZinAneTd<17u>::SetTileDmaSrc2WrapCfg(a1, a4);
  *(_DWORD *)(a1 + 792) = a3 | (a2 << 16);
  return result;
}

uint64_t ZinAneTd<17u>::SetTileDmaSrc2WrapCfg(uint64_t a1, unsigned int a2)
{
  if (a2 == 4) {
    ZinAssertImpl("Width wrap axis is not supported on this architecture");
  }
  uint64_t result = ZinIrCodegenGetDMAWrapCfgDim(a2);
  *(_DWORD *)(a1 + 616) = *(_DWORD *)(a1 + 616) & 0xFFFFF8FF | ((result & 7) << 8);
  return result;
}

uint64_t ZinAneTd<17u>::SetTileDmaSrc2WrapDynamic(uint64_t a1, uint64_t a2, unsigned int a3)
{
  int v6 = (uint64_t *)(a1 + 8);
  std::string::basic_string[abi:ne180100]<0>(__p, &byte_211F4AA5D);
  ZinAneTdHw_v17::AddRelocInfo(v6, (uint64_t)__p, 4975, a2, 0, 0, 0, 0);
  if (v9 < 0) {
    operator delete(__p[0]);
  }
  return ZinAneTd<17u>::SetTileDmaSrc2WrapCfg(a1, a3);
}

void sub_2112D6C10(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11, int a12, __int16 a13, char a14, char a15)
{
  if (a15 < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinAneTd<17u>::SetTileDmaSrc2FmtOffsetCh(uint64_t result, char a2)
{
  *(_DWORD *)(result + 712) = *(_DWORD *)(result + 712) & 0xFFF8FFFF | ((a2 & 7) << 16);
  return result;
}

uint64_t ZinAneTd<17u>::SetTileDmaSrc2FmtCmpVec(uint64_t result, unsigned __int8 a2)
{
  *(_DWORD *)(result + 712) = *(_DWORD *)(result + 712) & 0xFFFFFFF | (a2 << 28);
  return result;
}

uint64_t ZinAneTd<17u>::SetTileDmaSrc2OffsetY(uint64_t result, __int16 a2)
{
  *(_WORD *)(result + 752) = a2;
  return result;
}

int8x16_t ZinAneTd<17u>::SetTileDmaSrc2PixelOffset(uint64_t a1, unsigned int a2, unsigned int a3, unsigned int a4, unsigned int a5)
{
  v5.i64[0] = __PAIR64__(a3, a2);
  v5.i64[1] = __PAIR64__(a5, a4);
  v6.i64[0] = 0xFFFF0000FFFF0000;
  v6.i64[1] = 0xFFFF0000FFFF0000;
  int8x16_t result = vbslq_s8(v6, *(int8x16_t *)(a1 + 772), v5);
  *(int8x16_t *)(a1 + 772) = result;
  return result;
}

uint64_t ZinAneTd<17u>::SetTileDmaSrc2CompressedInfo(uint64_t result, int a2, int a3, int a4)
{
  int v4 = *(_DWORD *)(result + 740);
  *(_DWORD *)(result + 74std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v4 | 1;
  switch(a4)
  {
    case 0:
      unsigned int v5 = v4 & 0xFFFFCFFE | 1;
      break;
    case 1:
      unsigned int v5 = v4 & 0xFFFFCFFE | 0x1001;
      break;
    case 2:
      unsigned int v5 = v4 & 0xFFFFCFFE | 0x2001;
      break;
    case 3:
      unsigned int v5 = v4 | 0x3001;
      break;
    default:
      ZinAssertImpl("Invalid Lossy Mode");
  }
  *(_DWORD *)(result + 74std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v5;
  if (a3 == 2)
  {
    unsigned int v6 = v5 | 4;
  }
  else
  {
    if (a3 != 1) {
      ZinAssertImpl("Unsupported macro block size");
    }
    unsigned int v6 = v5 & 0xFFFFFFFB;
  }
  *(_DWORD *)(result + 74std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v6;
  if ((a2 - 1) >= 0x13) {
    ZinAssertImpl("Invalid packing format");
  }
  *(_DWORD *)(result + 74std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v6 & 0xFFFFFC0F | dword_211F04368[a2 - 1];
  return result;
}

uint64_t ZinAneTd<17u>::SetTileDmaSrc2DataSetId(uint64_t result, char a2)
{
  *(unsigned char *)(result + 609) = a2;
  return result;
}

BOOL ZinAneTd<17u>::SetTileDmaSrc2CompressedSize(uint64_t a1, unsigned int a2, unsigned int a3)
{
  int v7 = 0;
  if (!ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 24), &v7)) {
    ZinAssertImpl("Illegal TileDmaSrc2 Compressed Width");
  }
  *(_DWORD *)(a1 + 744) = *(_DWORD *)(a1 + 744) & 0xFFFE0000 | v7 & 0x1FFFF;
  int v6 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a3, (unsigned int *)(*(void *)(a1 + 1416) + 16), &v6);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc2 Compressed Height");
  }
  *(_DWORD *)(a1 + 748) = *(_DWORD *)(a1 + 748) & 0xFFFE0000 | v6 & 0x1FFFF;
  return result;
}

double ZinAneTd<17u>::SetTileDmaSrc2MetaData(uint64_t a1, uint64_t a2, uint64_t a3, unsigned int a4, unsigned int a5, int a6)
{
  ZinAneTdHw_v17::AddRelocInfo((uint64_t *)(a1 + 8), a2, 4946, a3, 1, 1, 0, 0);
  *(_DWORD *)(a1 + 740) &= ~8u;
  double result = COERCE_DOUBLE(__PAIR64__(a5, a4));
  *(int32x2_t *)(a1 + 696) = vsli_n_s32(*(int32x2_t *)(a1 + 696), (int32x2_t)__PAIR64__(a5, a4), 7uLL);
  *(_DWORD *)(a1 + 704) = *(_DWORD *)(a1 + 704) & 0x7F | (a6 << 7);
  return result;
}

uint64_t ZinAneTd<17u>::SetTileDmaDstFormat(uint64_t result, int a2, int a3)
{
  switch(a2)
  {
    case 1:
      unsigned int v3 = *(_DWORD *)(result + 1288) & 0xFFFFCFFC | 0x1000;
      goto LABEL_16;
    case 2:
      unsigned int v3 = *(_DWORD *)(result + 1288) & 0xFFFFCFFC;
      goto LABEL_16;
    case 3:
      unsigned int v4 = *(_DWORD *)(result + 1288) & 0xFFFFCFCC;
      int v5 = 8241;
      break;
    case 4:
      unsigned int v3 = *(_DWORD *)(result + 1288) & 0xFFFFCECC | 1;
      goto LABEL_16;
    case 5:
      unsigned int v4 = *(_DWORD *)(result + 1288) & 0xFFFFCECC;
      int v5 = 257;
      break;
    case 6:
      unsigned int v4 = *(_DWORD *)(result + 1288) & 0xFFFFCECC;
      int v5 = 17;
      break;
    case 7:
      unsigned int v4 = *(_DWORD *)(result + 1288) & 0xFFFFCECC;
      int v5 = 273;
      break;
    case 8:
      ZinAssertImpl("Packed10 format not supported");
    case 9:
      unsigned int v4 = *(_DWORD *)(result + 1288) & 0xFFFFCECC;
      if (!a3) {
        goto LABEL_14;
      }
      int v5 = 4401;
      break;
    case 10:
      unsigned int v4 = *(_DWORD *)(result + 1288) & 0xFFFFCECC;
      if (a3) {
        int v5 = 305;
      }
      else {
LABEL_14:
      }
        int v5 = 8497;
      break;
    case 11:
      unsigned int v4 = *(_DWORD *)(result + 1288) & 0xFFFFFFCF;
      int v5 = 12547;
      break;
    case 12:
      ZinAssertImpl("E4M3 is not supported");
    case 13:
      ZinAssertImpl("E5M2 is not supported");
    default:
      ZinAssertImpl("Invalid format provided");
  }
  unsigned int v3 = v4 | v5;
LABEL_16:
  *(_DWORD *)(result + 1288) = v3;
  return result;
}

BOOL ZinAneTd<17u>::SetTileDmaDstandL2DstInterleave(uint64_t a1, unsigned int a2)
{
  int v6 = 0;
  unint64_t v3 = a2;
  if (!ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 632), &v6)) {
    ZinAssertImpl("Illegal L2 Result Interleave");
  }
  *(_DWORD *)(a1 + 1008) = *(_DWORD *)(a1 + 1008) & 0xFFFFF0FF | ((v6 & 0xF) << 8);
  int v5 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(v3, (unsigned int *)(*(void *)(a1 + 1416) + 632), &v5);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaDst Interleave");
  }
  *(_DWORD *)(a1 + 1288) = *(_DWORD *)(a1 + 1288) & 0xF0FFFFFF | ((v5 & 0xF) << 24);
  return result;
}

BOOL ZinAneTd<17u>::SetL2ResultInterleave(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 632), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Result Interleave");
  }
  *(_DWORD *)(a1 + 1008) = *(_DWORD *)(a1 + 1008) & 0xFFFFF0FF | ((v4 & 0xF) << 8);
  return result;
}

uint64_t ZinAneTd<17u>::SetTileDmaDstandL2DstFifoMode(uint64_t result, int a2)
{
  unsigned int v2 = *(_DWORD *)(result + 1008) & 0xFFFFFFF7;
  if (a2) {
    int v3 = 0x1000000;
  }
  else {
    int v3 = 0;
  }
  unsigned int v4 = *(_DWORD *)(result + 1232) & 0xFEFFFFFF | v3;
  if (a2) {
    int v5 = 8;
  }
  else {
    int v5 = 0;
  }
  *(_DWORD *)(result + 12std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = v4;
  *(_DWORD *)(result + 1008) = v2 | v5;
  return result;
}

uint64_t ZinAneTd<17u>::SetTileDmaDstEnable(uint64_t result)
{
  *(_DWORD *)(result + 1232) |= 1u;
  return result;
}

uint64_t ZinAneTd<17u>::SetTileDmaDstCacheHint(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 1232) | 0xF0;
      goto LABEL_5;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 1232) & 0xFFFFFF0F | 0x30;
      goto LABEL_5;
    case 2:
      ZinAssertImpl("Drop CacheHint not supported on Dst");
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 1232) & 0xFFFFFF0F | 0xD0;
LABEL_5:
      *(_DWORD *)(result + 12std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = v2;
      break;
    case 4:
      ZinAssertImpl("Invalid CacheHint");
    default:
      return result;
  }
  return result;
}

BOOL ZinAneTd<17u>::SetTileDmaDstChannelStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 1416) + 544), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaDst Channel Stride");
  }
  *(_DWORD *)(a1 + 1252) = *(_DWORD *)(a1 + 1252) & 0x3F | (v4 << 6);
  return result;
}

BOOL ZinAneTd<17u>::SetTileDmaDstRowStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 1416) + 536), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaDst Row Stride");
  }
  *(_DWORD *)(a1 + 1248) = *(_DWORD *)(a1 + 1248) & 0x3F | (v4 << 6);
  return result;
}

BOOL ZinAneTd<17u>::SetTileDmaDstDepthStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 1416) + 552), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaDst Depth Stride");
  }
  *(_DWORD *)(a1 + 1256) = *(_DWORD *)(a1 + 1256) & 0x3F | (v4 << 6);
  return result;
}

BOOL ZinAneTd<17u>::SetTileDmaDstGroupStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 1416) + 560), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaDst Group Stride");
  }
  *(_DWORD *)(a1 + 126std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 1260) & 0x3F | (v4 << 6);
  return result;
}

uint64_t ZinAneTd<17u>::SetTileDmaDstZeroPad(uint64_t result, _DWORD *a2)
{
  unsigned int v2 = *(_DWORD *)(result + 1288) & 0xFFDFFFFF | ((*a2 == 0) << 21);
  *(_DWORD *)(result + 1288) = v2;
  *(_DWORD *)(result + 1288) = v2 & 0xFFEFFFFF | ((a2[1] == 0) << 20);
  return result;
}

uint64_t ZinAneTd<17u>::SetTileDmaDstCropOffset(uint64_t result, unsigned __int16 a2, unsigned __int16 a3)
{
  *(_DWORD *)(result + 1312) = a3 | (a2 << 16);
  return result;
}

uint64_t ZinAneTd<17u>::SetTileDmaDstWrapStatic(uint64_t a1, unsigned __int16 a2, unsigned __int16 a3, unsigned int a4)
{
  uint64_t result = ZinAneTd<17u>::SetTileDmaDstWrapCfg(a1, a4);
  *(_DWORD *)(a1 + 1284) = a3 | (a2 << 16);
  return result;
}

uint64_t ZinAneTd<17u>::SetTileDmaDstWrapCfg(uint64_t a1, unsigned int a2)
{
  if (a2 == 4) {
    ZinAssertImpl("Width wrap axis is not supported on this architecture");
  }
  uint64_t result = ZinIrCodegenGetDMAWrapCfgDim(a2);
  *(_DWORD *)(a1 + 1236) = *(_DWORD *)(a1 + 1236) & 0xFFFFF8FF | ((result & 7) << 8);
  return result;
}

uint64_t ZinAneTd<17u>::SetTileDmaDstWrapDynamic(uint64_t a1, uint64_t a2, unsigned int a3)
{
  int v6 = (uint64_t *)(a1 + 8);
  std::string::basic_string[abi:ne180100]<0>(__p, &byte_211F4AA5D);
  ZinAneTdHw_v17::AddRelocInfo(v6, (uint64_t)__p, 5197, a2, 0, 0, 0, 0);
  if (v9 < 0) {
    operator delete(__p[0]);
  }
  return ZinAneTd<17u>::SetTileDmaDstWrapCfg(a1, a3);
}

void sub_2112D74C4(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11, int a12, __int16 a13, char a14, char a15)
{
  if (a15 < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinAneTd<17u>::SetTileDmaDstFmtOffsetCh(uint64_t result, char a2)
{
  *(_DWORD *)(result + 1288) = *(_DWORD *)(result + 1288) & 0xFFF8FFFF | ((a2 & 7) << 16);
  return result;
}

uint64_t ZinAneTd<17u>::SetTileDmaDstFmtCmpVec(uint64_t result, unsigned __int8 a2)
{
  *(_DWORD *)(result + 1288) = *(_DWORD *)(result + 1288) & 0xFFFFFFF | (a2 << 28);
  return result;
}

uint64_t ZinAneTd<17u>::SetTileDmaDstBaseAddrLo(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return ZinAneTdHw_v17::AddRelocInfo((uint64_t *)(a1 + 8), a2, 5186, a3, 1, 1, 0, 0);
}

BOOL ZinAneTd<17u>::SetTileDmaDstCompressedSize(uint64_t a1, unsigned int a2, unsigned int a3)
{
  int v7 = 0;
  if (!ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 24), &v7)) {
    ZinAssertImpl("Illegal TileDmaDst Compressed Width");
  }
  *(_DWORD *)(a1 + 1304) = *(_DWORD *)(a1 + 1304) & 0xFFFE0000 | v7 & 0x1FFFF;
  int v6 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a3, (unsigned int *)(*(void *)(a1 + 1416) + 16), &v6);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaDst Compressed Height");
  }
  *(_DWORD *)(a1 + 1308) = *(_DWORD *)(a1 + 1308) & 0xFFFE0000 | v6 & 0x1FFFF;
  return result;
}

uint64_t ZinAneTd<17u>::SetTileDmaDstCompressedInfo(uint64_t result, int a2, int a3, int a4)
{
  int v4 = *(_DWORD *)(result + 1296);
  *(_DWORD *)(result + 1296) = v4 | 1;
  switch(a4)
  {
    case 0:
      unsigned int v5 = v4 & 0xFFFFCFFE | 1;
      break;
    case 1:
      unsigned int v5 = v4 & 0xFFFFCFFE | 0x1001;
      break;
    case 2:
      unsigned int v5 = v4 & 0xFFFFCFFE | 0x2001;
      break;
    case 3:
      unsigned int v5 = v4 | 0x3001;
      break;
    default:
      ZinAssertImpl("Invalid Lossy Mode");
  }
  *(_DWORD *)(result + 1296) = v5;
  if (a3 == 2)
  {
    unsigned int v6 = v5 | 4;
  }
  else
  {
    if (a3 != 1) {
      ZinAssertImpl("Unsupported macro block size");
    }
    unsigned int v6 = v5 & 0xFFFFFFFB;
  }
  *(_DWORD *)(result + 1296) = v6;
  if ((a2 - 1) >= 0x13) {
    ZinAssertImpl("Invalid packing format");
  }
  *(_DWORD *)(result + 1296) = v6 & 0xFFFFFC0F | dword_211F04368[a2 - 1];
  return result;
}

double ZinAneTd<17u>::SetTileDmaDstMetaData(uint64_t a1, uint64_t a2, uint64_t a3, unsigned int a4, unsigned int a5, int a6)
{
  ZinAneTdHw_v17::AddRelocInfo((uint64_t *)(a1 + 8), a2, 5192, a3, 1, 1, 0, 0);
  *(_DWORD *)(a1 + 1296) &= ~8u;
  double result = COERCE_DOUBLE(__PAIR64__(a5, a4));
  *(int32x2_t *)(a1 + 1272) = vsli_n_s32(*(int32x2_t *)(a1 + 1272), (int32x2_t)__PAIR64__(a5, a4), 7uLL);
  *(_DWORD *)(a1 + 128std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 1280) & 0x7F | (a6 << 7);
  return result;
}

uint64_t ZinAneTd<17u>::SetTileDmaDstNoMetaData(uint64_t result)
{
  *(_DWORD *)(result + 1296) |= 8u;
  return result;
}

uint64_t ZinAneTd<17u>::SetTileDmaDstDataSetId(uint64_t result, char a2)
{
  *(unsigned char *)(result + 1233) = a2;
  return result;
}

uint64_t ZinAneTd<17u>::SetCacheDmaPreEnable(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 2;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 1324) = *(_DWORD *)(result + 1324) & 0xFFFFFFFD | v2;
  return result;
}

uint64_t ZinAneTd<17u>::SetCacheDmaPreFlush(uint64_t result, int a2, __int16 a3)
{
  *(_DWORD *)(result + 1324) = *(_DWORD *)(result + 1324) & 0xFFFFFFFE | a2;
  *(_WORD *)(result + 136std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = a3;
  return result;
}

uint64_t ZinAneTd<17u>::SetCacheDmaPreTaskSync(uint64_t result, int a2, int a3)
{
  if (a3) {
    int v3 = 4;
  }
  else {
    int v3 = 0;
  }
  if (a2) {
    int v4 = 8;
  }
  else {
    int v4 = 0;
  }
  *(_DWORD *)(result + 1324) = v3 | v4 | *(_DWORD *)(result + 1324) & 0xFFFFFFF3;
  return result;
}

uint64_t ZinAneTd<17u>::SetCacheDmaPreEarlyTermination(uint64_t result, int a2, int a3, int a4, int a5, int a6, int a7, __int16 a8, __int16 a9, __int16 a10, char a11, __int16 a12, char a13)
{
  if (a2) {
    int v13 = 16;
  }
  else {
    int v13 = 0;
  }
  if (a3) {
    int v14 = 32;
  }
  else {
    int v14 = 0;
  }
  if (a4) {
    int v15 = 64;
  }
  else {
    int v15 = 0;
  }
  if (a5) {
    int v16 = 128;
  }
  else {
    int v16 = 0;
  }
  if (a6) {
    int v17 = 256;
  }
  else {
    int v17 = 0;
  }
  *(_DWORD *)(result + 1324) = v14 | v13 | v15 | v16 | v17 | *(_DWORD *)(result + 1324) & 0xFFFFFE0F;
  if (a3)
  {
    *(_WORD *)(result + 1356) = a8;
    if (!a4)
    {
LABEL_18:
      if (!a6) {
        goto LABEL_19;
      }
      goto LABEL_23;
    }
  }
  else if (!a4)
  {
    goto LABEL_18;
  }
  *(_WORD *)(result + 1358) = a9;
  if (!a6)
  {
LABEL_19:
    if (a5) {
      goto LABEL_25;
    }
LABEL_24:
    if (!a7) {
      return result;
    }
    goto LABEL_25;
  }
LABEL_23:
  *(unsigned char *)(result + 1364) = a11;
  if ((a5 & 1) == 0) {
    goto LABEL_24;
  }
LABEL_25:
  *(unsigned char *)(result + 1366) = a13;
  return result;
}

uint64_t ZinAneTd<17u>::SetCacheDmaPreTelemetryBackOff(uint64_t result, int a2, char a3, unsigned __int8 a4, unsigned __int8 a5, int a6)
{
  unsigned int v6 = *(_DWORD *)(result + 1368) & 0xFFFFFFFE | a2;
  if (a2) {
    unsigned int v6 = (16 * (a3 & 0xF)) | (unsigned __int16)(a4 << 8) | (a5 << 16) | (a6 << 24) | *(_DWORD *)(result + 1368) & 0xE | a2 & 0xF;
  }
  *(_DWORD *)(result + 1368) = v6;
  return result;
}

uint64_t ZinAneTd<17u>::SetCacheDmaPreFootprintLimiter(uint64_t result, int a2, __int16 a3, unsigned __int16 a4)
{
  if (a2) {
    int v4 = 512;
  }
  else {
    int v4 = 0;
  }
  unsigned int v5 = *(_DWORD *)(result + 1324) & 0xFFFFFDFF | v4;
  *(_DWORD *)(result + 1324) = v5;
  if (a2)
  {
    *(_DWORD *)(result + 1324) = (unsigned __int16)v5 | (a4 << 16);
    *(_DWORD *)(result + 1352) = *(_DWORD *)(result + 1352) & 0xF001FFFF | ((a3 & 0x7FF) << 17);
  }
  return result;
}

uint64_t ZinAneTd<17u>::SetCacheDmaPreSieveFiltering(uint64_t result, char a2, char a3)
{
  *(_DWORD *)(result + 1328) = a2 & 7 | (16 * (a3 & 0xF)) | *(_DWORD *)(result + 1328) & 0xFFFFFF08;
  return result;
}

uint64_t ZinAneTd<17u>::SetCacheDmaPreBandwidthLimit(uint64_t result, __int16 a2)
{
  *(_DWORD *)(result + 1328) = *(_DWORD *)(result + 1328) & 0xFFFE00FF | ((a2 & 0x1FF) << 8);
  return result;
}

uint64_t ZinAneTd<17u>::SetCacheDmaPreTelemetryResponseAgeOut(uint64_t result, char a2)
{
  *(_DWORD *)(result + 1328) = *(_DWORD *)(result + 1328) & 0xFF0FFFFF | ((a2 & 0xF) << 20);
  return result;
}

void ZinAneTd<17u>::SetCacheDmaPreDSIDAndSize(uint64_t a1, unsigned __int16 *a2, int a3)
{
  *(_DWORD *)(a1 + 1348) = *(_DWORD *)(a1 + 1348) & 0xC000007F | ((a3 & 0x7FFFFF) << 7);
  if (*((unsigned char *)a2 + 2))
  {
    int v4 = (uint64_t *)(a1 + 8);
    std::string::basic_string[abi:ne180100]<0>(__p, &byte_211F4AA5D);
    ZinAneTdHw_v17::AddRelocInfo(v4, (uint64_t)__p, 5698, *a2, 0, 0, 0, 0);
    if (v6 < 0) {
      operator delete(__p[0]);
    }
  }
}

void sub_2112D797C(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11, int a12, __int16 a13, char a14, char a15)
{
  if (a15 < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinAneTd<17u>::SetCacheDmaPreAddress(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return ZinAneTdHw_v17::AddRelocInfo((uint64_t *)(a1 + 8), a3, 5700, a2, 1, 1, 0, 0);
}

uint64_t ZinAneTd<17u>::SetFillLowerNEFirst(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 0x20000000;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 564) = *(_DWORD *)(result + 564) & 0xDFFFFFFF | v2;
  return result;
}

uint64_t ZinAneTd<17u>::SetDoubleInt8Enable(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 0x4000000;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 118std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 1180) & 0xFBFFFFFF | v2;
  return result;
}

uint64_t ZinAneTd<17u>::SetArgOutputSelect(uint64_t result, int a2)
{
  if ((a2 - 6) > 5) {
    int v2 = 0x100000;
  }
  else {
    int v2 = dword_211F043B4[a2 - 6];
  }
  *(_DWORD *)(result + 118std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 1180) & 0xFF0FFFFF | v2;
  return result;
}

uint64_t ZinAneTd<17u>::SetMaxPoolMode(uint64_t result, unsigned int a2)
{
  if (a2 <= 0xE && ((1 << a2) & 0x48E2) != 0) {
    unsigned int v2 = *(_DWORD *)(result + 1180) | 0x80000;
  }
  else {
    unsigned int v2 = *(_DWORD *)(result + 1180) & 0xFFF7FFFF;
  }
  *(_DWORD *)(result + 118std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2;
  return result;
}

BOOL ZinAneTd<17u>::SetKernelStrideRegisters(uint64_t a1, unsigned int a2, unsigned int a3)
{
  int v7 = 0;
  if (!ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 736), &v7)) {
    ZinAssertImpl("Illegal Kernel Group Stride");
  }
  *(_DWORD *)(a1 + 72) = *(_DWORD *)(a1 + 72) & 0x3F | (v7 << 6);
  int v6 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a3, (unsigned int *)(*(void *)(a1 + 1416) + 728), &v6);
  if (!result) {
    ZinAssertImpl("Illegal Kernel OCG Stride");
  }
  *(_DWORD *)(a1 + 76) = *(_DWORD *)(a1 + 76) & 0x3F | (v6 << 6);
  return result;
}

uint64_t ZinAneTd<17u>::SetKernelSparseBlockSize(uint64_t result, char a2)
{
  *(_DWORD *)(result + 1176) = *(_DWORD *)(result + 1176) & 0xFF1FFFFF | ((a2 & 7) << 21);
  return result;
}

uint64_t ZinAneTd<17u>::SetRcasKeyMask(uint64_t result, char a2)
{
  *(unsigned char *)(result + 1196) = a2;
  return result;
}

uint64_t ZinAneTd<17u>::SetRcasMode(uint64_t result, int a2)
{
  switch(a2)
  {
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 1196) & 0xFFEFFFFF;
LABEL_7:
      *(_DWORD *)(result + 1196) = v2;
      return result;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 1196) | 0x100000;
      goto LABEL_7;
    case 0:
      ZinAssertImpl("Unknown RCAS Mode.\n");
  }
  return result;
}

uint64_t ZinAneTd<17u>::SetRcasSenseAxis(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 1196) | 0x3000;
      goto LABEL_6;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 1196) & 0xFFFFCFFF | 0x1000;
      goto LABEL_6;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 1196) & 0xFFFFCFFF | 0x2000;
      goto LABEL_6;
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 1196) & 0xFFFFCFFF;
LABEL_6:
      *(_DWORD *)(result + 1196) = v2;
      break;
    case 4:
    case 5:
      ZinAssertImpl("Unknown RCAS Sense Axis.\n");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<17u>::SetRcasSenseBit(uint64_t result, char a2)
{
  *(_DWORD *)(result + 1196) = *(_DWORD *)(result + 1196) & 0xFFF0FFFF | ((a2 & 0xF) << 16);
  return result;
}

uint64_t ZinAneTd<17u>::SetRcasCmpBit(uint64_t result, char a2)
{
  *(_DWORD *)(result + 1196) = *(_DWORD *)(result + 1196) & 0xFFFFF8FF | ((a2 & 7) << 8);
  return result;
}

uint64_t ZinAneTd<17u>::SetGroupKernelReuse(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 1024;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 1176) = *(_DWORD *)(result + 1176) & 0xFFFFFBFF | v2;
  if (a2) {
    int v3 = 16;
  }
  else {
    int v3 = 0;
  }
  *(_DWORD *)(result + 48) = *(_DWORD *)(result + 48) & 0xFFFFFFEF | v3;
  return result;
}

uint64_t ZinAneTd<17u>::SetKernelSparseFmt(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 256;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 1176) = *(_DWORD *)(result + 1176) & 0xFFFFFEFF | v2;
  if (a2) {
    int v3 = 32;
  }
  else {
    int v3 = 0;
  }
  *(_DWORD *)(result + 48) = *(_DWORD *)(result + 48) & 0xFFFFFFDF | v3;
  return result;
}

uint64_t ZinAneTd<17u>::SetKernelSparseBinary(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 0x8000;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 1176) = *(_DWORD *)(result + 1176) & 0xFFFF7FFF | v2;
  return result;
}

uint64_t ZinAneTd<17u>::SetKernelPalettizedEn(uint64_t result, int a2)
{
  int v2 = 0;
  switch(a2)
  {
    case 0:
    case 3:
    case 28:
    case 29:
    case 30:
    case 31:
    case 32:
      ZinAssertImpl("Unknown kernel format in codegen\n");
    case 7:
    case 8:
    case 9:
    case 10:
    case 11:
    case 12:
    case 13:
    case 14:
    case 19:
    case 20:
    case 21:
    case 22:
    case 23:
    case 24:
    case 25:
    case 26:
    case 27:
      int v2 = 4;
      break;
    case 15:
    case 16:
    case 17:
    case 18:
      ZinAssertImpl("Invalid kernel format");
    default:
      break;
  }
  *(_DWORD *)(result + 1176) = *(_DWORD *)(result + 1176) & 0xFFFFFFFB | v2;
  return result;
}

uint64_t ZinAneTd<17u>::SetKernelPalettizedBits(uint64_t result, int a2)
{
  int v2 = 128;
  switch(a2)
  {
    case 0:
    case 3:
    case 28:
    case 29:
    case 30:
    case 31:
    case 32:
      ZinAssertImpl("Unknown kernel format in codegen\n");
    case 7:
    case 8:
    case 9:
    case 10:
      int v2 = 16;
      break;
    case 11:
    case 12:
    case 13:
    case 14:
      int v2 = 32;
      break;
    case 15:
    case 16:
    case 17:
    case 18:
      ZinAssertImpl("Invalid kernel format");
    case 19:
    case 20:
    case 21:
    case 22:
      int v2 = 64;
      break;
    case 23:
    case 24:
    case 25:
    case 26:
      int v2 = 96;
      break;
    default:
      break;
  }
  *(_DWORD *)(result + 1176) = *(_DWORD *)(result + 1176) & 0xFFFFFF0F | v2;
  return result;
}

uint64_t ZinAneTd<17u>::SetKernelAsymQuantEn(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 0x1000000;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 1176) = *(_DWORD *)(result + 1176) & 0xFEFFFFFF | v2;
  return result;
}

uint64_t ZinAneTd<17u>::SetStochasticRoundMode(uint64_t result, int a2)
{
  if (a2 != 1 && a2 != 2)
  {
    if (!a2) {
      ZinAssertImpl("Invalid stochastic rounding mode");
    }
    a2 = 0;
  }
  *(_DWORD *)(result + 120std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 1200) & 0xFFFFFFFC | a2;
  return result;
}

uint64_t ZinAneTd<17u>::SetStochasticRoundSeed(uint64_t result, int a2, uint64_t a3)
{
  *(_DWORD *)(result + 4 * a3 + 1204) = a2;
  return result;
}

uint64_t ZinAneTd<17u>::SetStochasticRoundIntegerBits(uint64_t result, char a2)
{
  *(_DWORD *)(result + 120std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 1200) & 0xFFFFFE0F | (16 * (a2 & 0x1F));
  return result;
}

uint64_t ZinAneTd<17u>::SetQuantizationOutputZeroOffset(uint64_t result, int a2, char a3, int a4, uint64_t a5)
{
  int v6 = *(_DWORD **)a5;
  unsigned int v5 = *(_DWORD **)(a5 + 8);
  if (*(_DWORD **)a5 != v5)
  {
    while (*v6 != a4)
    {
      if (++v6 == v5)
      {
        int v6 = *(_DWORD **)(a5 + 8);
        break;
      }
    }
  }
  if (v6 != v5)
  {
    if (!a2) {
      a3 = 0;
    }
    *(unsigned char *)(result + 122std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = a3;
  }
  return result;
}

uint64_t ZinAneTd<17u>::SetNEBinaryPoint(uint64_t result, char a2)
{
  *(_DWORD *)(result + 118std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 1180) & 0xFFFFC0FF | ((a2 & 0x3F) << 8);
  return result;
}

uint64_t ZinAneTd<17u>::SetNENonLinearMode(uint64_t result, int a2, uint64_t a3)
{
  if (a2)
  {
    if (a2 == 1)
    {
      a2 = 0x10000;
    }
    else
    {
      int v4 = *(_DWORD **)a3;
      int v3 = *(_DWORD **)(a3 + 8);
      if (*(_DWORD **)a3 != v3)
      {
        while (*v4 != a2)
        {
          if (++v4 == v3)
          {
            int v4 = *(_DWORD **)(a3 + 8);
            break;
          }
        }
      }
      if (v4 == v3) {
        ZinAssertImpl("Error: illegal non-linear mode\n");
      }
      a2 = 0x20000;
    }
  }
  *(_DWORD *)(result + 118std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 1180) & 0xFFFCFFFF | a2;
  return result;
}

uint64_t ZinAneTd<17u>::SetNEPostScale(uint64_t result, unint64_t a2, char a3)
{
  _S0 = a2;
  __asm { FCVT            H0, S0 }
  int v8 = _S0;
  if (!_ZF) {
    int v8 = 0;
  }
  int v9 = ((a2 & 0xFF0000000000) != 0) << 14;
  int v10 = -((a2 >> 16) & 0x1F0000) & 0x1F0000 | v8;
  if (!a3)
  {
    int v9 = 0;
    int v10 = 15360;
  }
  *(_DWORD *)(result + 118std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 1180) & 0xFFFFBFFF | v9;
  *(_DWORD *)(result + 1192) = v10 | *(_DWORD *)(result + 1192) & 0xFFE00000;
  return result;
}

uint64_t ZinAneTd<17u>::SetNEBias(uint64_t result, unint64_t a2, char a3)
{
  _S0 = a2;
  __asm { FCVT            H0, S0 }
  int v8 = _S0;
  if (!_ZF) {
    int v8 = 0;
  }
  int v9 = 16 * ((a2 & 0xFF0000000000) != 0);
  int v10 = (a2 >> 16) & 0x1F0000 | v8;
  if (!a3)
  {
    int v9 = 0;
    int v10 = 0;
  }
  *(_DWORD *)(result + 118std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 1180) & 0xFFFFFFEF | v9;
  *(_DWORD *)(result + 1188) = v10 | *(_DWORD *)(result + 1188) & 0xFFE00000;
  return result;
}

ZinIrKernel *ZinAneTd<17u>::SetNEMatrixVectorBias(uint64_t a1, ZinIrKernel **a2, uint64_t a3)
{
  BOOL result = *a2;
  if (*a2) {
    _ZF = (a3 & 0xFF00000000) == 0;
  }
  else {
    _ZF = 1;
  }
  if (_ZF)
  {
    int v6 = 0;
  }
  else
  {
    _S8 = *(float *)&a3;
    BOOL result = (ZinIrKernel *)ZinIrKernel::GetWeightFormat(result);
    if (result == 4)
    {
      __asm { FCVT            H0, S8 }
      LOWORD(v8) = _H0;
    }
    else
    {
      if (result != 2 && result != 1) {
        ZinAssertImpl("Error: Invalid kernel format");
      }
      int v8 = (int)_S8;
    }
    *(_WORD *)(a1 + 1184) = v8;
    int v6 = 64;
  }
  *(_DWORD *)(a1 + 118std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 1180) & 0xFFFFFFBF | v6;
  return result;
}

uint64_t ZinAneTd<17u>::SetNEOcgSize(uint64_t result, char a2)
{
  *(_DWORD *)(result + 568) = *(_DWORD *)(result + 568) & 0xFFFFFFF8 | a2 & 7;
  return result;
}

uint64_t ZinAneTd<17u>::SetOutputTranspose(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 0x10000000;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 564) = *(_DWORD *)(result + 564) & 0xEFFFFFFF | v2;
  return result;
}

uint64_t ZinAneTd<17u>::SetNESmallSourceMode(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 564) & 0xFFFFFFF3;
      goto LABEL_6;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 564) & 0xFFFFFFF3 | 4;
      goto LABEL_6;
    case 2:
      ZinAssertImpl("Error: Tiny source mode is not supported for this arch");
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 564) | 0xC;
      goto LABEL_6;
    case 4:
      unsigned int v2 = *(_DWORD *)(result + 564) & 0xFFFFFFF3 | 8;
LABEL_6:
      *(_DWORD *)(result + 564) = v2;
      break;
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<17u>::GetNESmallSourceMode(uint64_t a1)
{
  return *(unsigned int *)((char *)&unk_211ED50F0 + (*(_DWORD *)(a1 + 564) & 0xC));
}

uint64_t ZinAneTd<17u>::SetTileDmaSrcDma1UserTag(uint64_t result, char a2)
{
  *(unsigned char *)(result + 606) = a2;
  return result;
}

uint64_t ZinAneTd<17u>::SetTileDmaSrcDma2UserTag(uint64_t result, char a2)
{
  *(unsigned char *)(result + 61std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = a2;
  return result;
}

uint64_t ZinAneTd<17u>::SetTileDmaSrcCompressedMdUserTag(uint64_t result, char a2)
{
  *(unsigned char *)(result + 727) = a2;
  return result;
}

uint64_t ZinAneTd<17u>::SetTileDmaSrcCompressed2MdUserTag(uint64_t result, char a2)
{
  *(unsigned char *)(result + 743) = a2;
  return result;
}

uint64_t ZinAneTd<17u>::SetTileDmaDstUserTag(uint64_t result, char a2)
{
  *(unsigned char *)(result + 1234) = a2;
  return result;
}

uint64_t ZinAneTd<17u>::SetKernelDmaSrcCoeffUserTag(uint64_t result, unsigned __int8 a2)
{
  uint64_t v2 = 0;
  int8x16_t v3 = (int8x16_t)vdupq_n_s32(a2 << 16);
  do
  {
    *(int8x16_t *)(result + 80 + v2) = vorrq_s8((int8x16_t)(*(_OWORD *)(result + 80 + v2) & __PAIR128__(0xFF00FFFFFF00FFFFLL, 0xFF00FFFFFF00FFFFLL)), v3);
    v2 += 16;
  }
  while (v2 != 64);
  return result;
}

uint64_t ZinAneTd<17u>::SetCachePrefetchDmaUserTag(uint64_t result, char a2)
{
  *(unsigned char *)(result + 1334) = a2;
  return result;
}

uint64_t ZinAneTd<17u>::SetKernelDmaSrcPostScaleUserTag(uint64_t result, char a2)
{
  *(unsigned char *)(result + 29std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = a2;
  return result;
}

uint64_t ZinAneTd<17u>::SetKernelDmaSrcPaletteLutUserTag(uint64_t result, char a2)
{
  *(unsigned char *)(result + 306) = a2;
  return result;
}

uint64_t ZinAneTd<17u>::SetKernelDmaSrcBiasUserTag(uint64_t result, char a2)
{
  *(unsigned char *)(result + 274) = a2;
  return result;
}

uint64_t ZinAneTd<17u>::SetKernelDmaSrcNonLinearLutUserTag(uint64_t result, char a2)
{
  *(unsigned char *)(result + 322) = a2;
  return result;
}

uint64_t ZinAneTd<17u>::SetCommonTaskType(uint64_t result, unsigned int a2)
{
  if (a2 <= 7) {
    *(_DWORD *)(result + 564) = *(_DWORD *)(result + 564) & 0xFFFFFF0F | dword_211F043CC[a2];
  }
  return result;
}

uint64_t ZinAneTd<17u>::SetCommonInFmt(uint64_t result, int a2)
{
  if (a2 > 2)
  {
    if (a2 == 3)
    {
      unsigned int v2 = *(_DWORD *)(result + 504) & 0xFFFFFFFC | 2;
      goto LABEL_8;
    }
    if (a2 == 12) {
      ZinAssertImpl("Error: Invalid Common InFmt E4M3");
    }
LABEL_11:
    ZinAssertImpl("Error: Invalid TD programming for Src1 input format");
  }
  if (a2 == 1)
  {
    unsigned int v2 = *(_DWORD *)(result + 504) & 0xFFFFFFFC | 1;
    goto LABEL_8;
  }
  if (a2 != 2) {
    goto LABEL_11;
  }
  unsigned int v2 = *(_DWORD *)(result + 504) & 0xFFFFFFFC;
LABEL_8:
  *(_DWORD *)(result + 504) = v2;
  return result;
}

uint64_t ZinAneTd<17u>::SetCommonSrc2InFmt(uint64_t result, int a2)
{
  if (a2 > 2)
  {
    if (a2 == 3)
    {
      unsigned int v2 = *(_DWORD *)(result + 504) & 0xFFFFFFF3 | 8;
      goto LABEL_8;
    }
    if (a2 == 12) {
      ZinAssertImpl("Error: Invalid TD programming for Src2 input format: E4M3");
    }
LABEL_11:
    ZinAssertImpl("Error: Invalid TD programming for Src2 input format");
  }
  if (a2 == 1)
  {
    unsigned int v2 = *(_DWORD *)(result + 504) & 0xFFFFFFF3 | 4;
    goto LABEL_8;
  }
  if (a2 != 2) {
    goto LABEL_11;
  }
  unsigned int v2 = *(_DWORD *)(result + 504) & 0xFFFFFFF3;
LABEL_8:
  *(_DWORD *)(result + 504) = v2;
  return result;
}

uint64_t ZinAneTd<17u>::SetCommonOutFmt(uint64_t result, int a2)
{
  if ((a2 - 3) < 9) {
    goto LABEL_2;
  }
  if (a2 <= 11)
  {
    if (a2 == 1)
    {
      unsigned int v2 = *(_DWORD *)(result + 504) & 0xFFFFFFCF | 0x10;
      goto LABEL_3;
    }
    if (a2 == 2)
    {
      unsigned int v2 = *(_DWORD *)(result + 504) & 0xFFFFFFCF;
      goto LABEL_3;
    }
LABEL_12:
    ZinAssertImpl("Error: Invalid output format");
  }
  if (a2 != 13)
  {
    if (a2 == 12) {
      ZinAssertImpl("Error: E4M3 is not supported");
    }
    goto LABEL_12;
  }
LABEL_2:
  unsigned int v2 = *(_DWORD *)(result + 504) & 0xFFFFFFCF | 0x20;
LABEL_3:
  *(_DWORD *)(result + 504) = v2;
  return result;
}

BOOL ZinAneTd<17u>::SetPatchHeight(uint64_t a1, unint64_t a2)
{
  *(_DWORD *)(a1 + 572) = *(_DWORD *)(a1 + 572) & 0xFFFFFE0F | (16 * (a2 & 0x1F));
  return CheckRegValueRange(a2, (unsigned int *)(*(void *)(a1 + 1416) + 304));
}

BOOL ZinAneTd<17u>::SetPatchWidth(uint64_t a1, unint64_t a2)
{
  *(_DWORD *)(a1 + 572) = *(_DWORD *)(a1 + 572) & 0xFFFFFFF0 | a2 & 0xF;
  return CheckRegValueRange(a2, (unsigned int *)(*(void *)(a1 + 1416) + 296));
}

BOOL ZinAneTd<17u>::SetTileHeight(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 216), &v4);
  if (result) {
    *(_DWORD *)(a1 + 556) = *(_DWORD *)(a1 + 556) & 0xFFFE0000 | v4 & 0x1FFFF;
  }
  return result;
}

BOOL ZinAneTd<17u>::SetTileOverlap(uint64_t a1, unint64_t a2)
{
  *(_DWORD *)(a1 + 56std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 560) & 0xFFE0FFFF | ((a2 & 0x1F) << 16);
  return CheckRegValueRange(a2, (unsigned int *)(*(void *)(a1 + 1416) + 232));
}

BOOL ZinAneTd<17u>::SetTileOverlapPadBottom(uint64_t a1, unint64_t a2)
{
  *(_DWORD *)(a1 + 56std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 560) & 0x83FFFFFF | ((a2 & 0x1F) << 26);
  return CheckRegValueRange(a2, (unsigned int *)(*(void *)(a1 + 1416) + 240));
}

BOOL ZinAneTd<17u>::SetTileOverlapPadTop(uint64_t a1, unint64_t a2)
{
  *(_DWORD *)(a1 + 56std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 560) & 0xFC1FFFFF | ((a2 & 0x1F) << 21);
  return CheckRegValueRange(a2, (unsigned int *)(*(void *)(a1 + 1416) + 224));
}

BOOL ZinAneTd<17u>::SetCommonConvCfgKh(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 128), &v4);
  if (result) {
    *(_DWORD *)(a1 + 544) = *(_DWORD *)(a1 + 544) & 0xFFFFF03F | ((v4 & 0x3F) << 6);
  }
  return result;
}

BOOL ZinAneTd<17u>::SetCommonConvCfgKw(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 136), &v4);
  if (result) {
    *(_DWORD *)(a1 + 544) = *(_DWORD *)(a1 + 544) & 0xFFFFFFC0 | v4 & 0x3F;
  }
  return result;
}

BOOL ZinAneTd<17u>::SetCommonConvCfg3dKd(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 168), &v4);
  if (result) {
    *(_DWORD *)(a1 + 548) = *(_DWORD *)(a1 + 548) & 0xFFFFFFE0 | v4 & 0x1F;
  }
  return result;
}

BOOL ZinAneTd<17u>::SetCommonConvCfgSx(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 120), &v4);
  if (result) {
    *(_DWORD *)(a1 + 544) = *(_DWORD *)(a1 + 544) & 0xFFFF9FFF | ((v4 & 3) << 13);
  }
  return result;
}

BOOL ZinAneTd<17u>::SetCommonConvCfgSy(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 112), &v4);
  if (result) {
    *(_DWORD *)(a1 + 544) = *(_DWORD *)(a1 + 544) & 0xFFFE7FFF | ((v4 & 3) << 15);
  }
  return result;
}

BOOL ZinAneTd<17u>::SetCommonConvCfg3dSz(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 144), &v4);
  if (result) {
    *(_DWORD *)(a1 + 548) = *(_DWORD *)(a1 + 548) & 0xFFFFFF3F | ((v4 & 3) << 6);
  }
  return result;
}

BOOL ZinAneTd<17u>::SetCommonConvCfgOx(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 88), &v4);
  if (result) {
    *(_DWORD *)(a1 + 544) = *(_DWORD *)(a1 + 544) & 0xCFFFFFFF | ((v4 & 3) << 28);
  }
  return result;
}

BOOL ZinAneTd<17u>::SetCommonConvCfgOy(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 80), &v4);
  if (result) {
    *(_DWORD *)(a1 + 544) = *(_DWORD *)(a1 + 544) & 0x3FFFFFFF | (v4 << 30);
  }
  return result;
}

BOOL ZinAneTd<17u>::SetCommonConvCfg3dOz(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 160), &v4);
  if (result) {
    *(_DWORD *)(a1 + 548) = *(_DWORD *)(a1 + 548) & 0xFFFF9FFF | ((v4 & 3) << 13);
  }
  return result;
}

BOOL ZinAneTd<17u>::SetCommonConvCfgPadLeft(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 104), &v4);
  if (result) {
    *(_DWORD *)(a1 + 544) = *(_DWORD *)(a1 + 544) & 0xFFC1FFFF | ((v4 & 0x1F) << 17);
  }
  return result;
}

BOOL ZinAneTd<17u>::SetCommonConvCfgPadTop(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 96), &v4);
  if (result) {
    *(_DWORD *)(a1 + 544) = *(_DWORD *)(a1 + 544) & 0xF83FFFFF | ((v4 & 0x1F) << 22);
  }
  return result;
}

BOOL ZinAneTd<17u>::SetCommonConvCfg3dPz(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 152), &v4);
  if (result) {
    *(_DWORD *)(a1 + 548) = *(_DWORD *)(a1 + 548) & 0xFFFFF0FF | ((v4 & 0xF) << 8);
  }
  return result;
}

BOOL ZinAneTd<17u>::SetOrReturnNumGroups(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 200), &v4);
  if (result) {
    *(_DWORD *)(a1 + 54std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 540) & 0xFFFE0000 | v4 & 0x1FFFF;
  }
  return result;
}

BOOL ZinAneTd<17u>::SetOrReturnWin(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 24), &v4);
  if (result) {
    *(_DWORD *)(a1 + 508) = *(_DWORD *)(a1 + 508) & 0xFFFE0000 | v4 & 0x1FFFF;
  }
  return result;
}

BOOL ZinAneTd<17u>::SetOrReturnHin(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 16), &v4);
  if (result) {
    *(_DWORD *)(a1 + 512) = *(_DWORD *)(a1 + 512) & 0xFFFE0000 | v4 & 0x1FFFF;
  }
  return result;
}

BOOL ZinAneTd<17u>::SetOrReturnDin(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 32), &v4);
  if (result) {
    *(_DWORD *)(a1 + 52std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 520) & 0xFFFE0000 | v4 & 0x1FFFF;
  }
  return result;
}

BOOL ZinAneTd<17u>::SetOrReturnCin(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 40), &v4);
  if (result) {
    *(_DWORD *)(a1 + 516) = *(_DWORD *)(a1 + 516) & 0xFFFE0000 | v4 & 0x1FFFF;
  }
  return result;
}

BOOL ZinAneTd<17u>::SetOrReturnWout(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 64), &v4);
  if (result) {
    *(_DWORD *)(a1 + 524) = *(_DWORD *)(a1 + 524) & 0xFFFE0000 | v4 & 0x1FFFF;
  }
  return result;
}

BOOL ZinAneTd<17u>::SetOrReturnHout(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 56), &v4);
  if (result) {
    *(_DWORD *)(a1 + 528) = *(_DWORD *)(a1 + 528) & 0xFFFE0000 | v4 & 0x1FFFF;
  }
  return result;
}

BOOL ZinAneTd<17u>::SetOrReturnDout(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 72), &v4);
  if (result) {
    *(_DWORD *)(a1 + 536) = *(_DWORD *)(a1 + 536) & 0xFFFE0000 | v4 & 0x1FFFF;
  }
  return result;
}

BOOL ZinAneTd<17u>::SetOrReturnCout(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 48), &v4);
  if (result) {
    *(_DWORD *)(a1 + 5std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_DWORD *)(a1 + 532) & 0xFFFE0000 | v4 & 0x1FFFF;
  }
  return result;
}

uint64_t ZinAneTd<17u>::SetUnicastEn(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 0x4000;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 552) = *(_DWORD *)(result + 552) & 0xFFFFBFFF | v2;
  return result;
}

BOOL ZinAneTd<17u>::SetUnicastCin(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1416) + 208), &v4);
  if (result) {
    *(_WORD *)(a1 + 554) = v4;
  }
  return result;
}

uint64_t ZinAneTd<19u>::SetWARdmaDependency(uint64_t result, uint64_t a2, int a3, unsigned __int8 a4, int **a5)
{
  if (!*(unsigned char *)(a2 + 1323)) {
    ZinAssertImpl("inconsistent WAR support");
  }
  if (a3)
  {
    unsigned int v5 = *a5;
    int v6 = a5[1];
    if (*a5 != v6)
    {
      do
      {
        uint64_t v7 = *v5;
        if (v7 <= 2) {
          *(_DWORD *)(result + 1268) |= dword_211F0435C[v7];
        }
        ++v5;
      }
      while (v5 != v6);
    }
    *(_DWORD *)(result + 1268) = *(_DWORD *)(result + 1268) & 0x7FFFFFF | (a4 << 27);
  }
  return result;
}

uint64_t ZinAneTd<19u>::SetL2Barrier(uint64_t result)
{
  *(_DWORD *)(result + 576) |= 0x800000u;
  return result;
}

_DWORD *ZinAneTd<19u>::SetEventFlags(_DWORD *result, int a2, int a3, int a4)
{
  result[4] = a2;
  result[8] = a4;
  result[6] = a3;
  return result;
}

BOOL ZinAneTd<19u>::SetL2SrcBaseAddress(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1464) + 312), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src Base Address");
  }
  *(_DWORD *)(a1 + 972) = *(_DWORD *)(a1 + 972) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<19u>::SetL2Src1ChannelStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x11uLL, (unsigned int *)(*(void *)(a1 + 1464) + 320), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src Channel Stride");
  }
  *(_DWORD *)(a1 + 976) = *(_DWORD *)(a1 + 976) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<19u>::SetL2SrcRowStride(uint64_t a1, ZinCodegen *this, ZinTensorDimensions *a3, uint64_t a4, uint64_t *a5)
{
  int v8 = 0;
  ZinCodegen::GetL2RowStride(this, a3, *(unsigned int *)(*(void *)(a1 + 1464) + 332), &v8, a5);
  unsigned int v7 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(v8, 0x11uLL, (unsigned int *)(*(void *)(a1 + 1464) + 328), &v7);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src Row Stride");
  }
  *(_DWORD *)(a1 + 98std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 980) & 0xFFE0000F | (16 * (v7 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<19u>::SetL2Src1DepthStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x11uLL, (unsigned int *)(*(void *)(a1 + 1464) + 336), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src Depth Stride");
  }
  *(_DWORD *)(a1 + 984) = *(_DWORD *)(a1 + 984) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<19u>::SetL2Src1GroupStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x11uLL, (unsigned int *)(*(void *)(a1 + 1464) + 344), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src Group Stride");
  }
  *(_DWORD *)(a1 + 988) = *(_DWORD *)(a1 + 988) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

uint64_t ZinAneTd<19u>::SetL2Src1DmaFormat(uint64_t result, int a2)
{
  switch(a2)
  {
    case 1:
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 960) & 0xFFFFFF3F;
      break;
    case 3:
    case 4:
    case 5:
    case 6:
    case 7:
    case 9:
    case 10:
      unsigned int v2 = *(_DWORD *)(result + 960) & 0xFFFFFF3F | 0x40;
      break;
    case 8:
      ZinAssertImpl("Packed10 format not fully implemented yet\n");
    case 11:
      unsigned int v2 = *(_DWORD *)(result + 960) | 0xC0;
      break;
    case 12:
    case 13:
      ZinAssertImpl("E4M3 or E5M2 format not supported");
    default:
      ZinAssertImpl("Invalid Dma Format");
  }
  *(_DWORD *)(result + 96std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2;
  return result;
}

uint64_t ZinAneTd<19u>::SetL2Src2DmaFormat(uint64_t result, int a2)
{
  switch(a2)
  {
    case 1:
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 964) & 0xFFFFFF3F;
      break;
    case 3:
    case 4:
    case 5:
    case 6:
    case 7:
    case 9:
    case 10:
      unsigned int v2 = *(_DWORD *)(result + 964) & 0xFFFFFF3F | 0x40;
      break;
    case 8:
      ZinAssertImpl("Packed10 format not fully implemented yet\n");
    case 11:
      unsigned int v2 = *(_DWORD *)(result + 964) | 0xC0;
      break;
    case 12:
    case 13:
      ZinAssertImpl("E4M3 or E5M2 format not supported");
    default:
      ZinAssertImpl("Invalid Dma Format");
  }
  *(_DWORD *)(result + 964) = v2;
  return result;
}

uint64_t ZinAneTd<19u>::SetL2ResultCfgDmaFmt(uint64_t result, int a2)
{
  switch(a2)
  {
    case 1:
    case 2:
    case 12:
    case 13:
      unsigned int v2 = *(_DWORD *)(result + 1028) & 0xFFFFFF3F;
      break;
    case 3:
    case 4:
    case 5:
    case 6:
    case 7:
    case 9:
    case 10:
      unsigned int v2 = *(_DWORD *)(result + 1028) & 0xFFFFFF3F | 0x40;
      break;
    case 8:
      ZinAssertImpl("packed10 format not fully implemented yet");
    case 11:
      unsigned int v2 = *(_DWORD *)(result + 1028) | 0xC0;
      break;
    default:
      ZinAssertImpl("Invalid tensor format");
  }
  *(_DWORD *)(result + 1028) = v2;
  return result;
}

uint64_t ZinAneTd<19u>::SetL2ResultWrapCfg(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 1056) & 0xFFFFF8FF | 0x400;
      goto LABEL_7;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 1056) & 0xFFFFF8FF | 0x300;
      goto LABEL_7;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 1056) & 0xFFFFF8FF | 0x100;
      goto LABEL_7;
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 1056) & 0xFFFFF8FF | 0x200;
      goto LABEL_7;
    case 4:
      ZinAssertImpl("Error: Invalid Wrap Axis");
    case 5:
      unsigned int v2 = *(_DWORD *)(result + 1056) & 0xFFFFF8FF;
LABEL_7:
      *(_DWORD *)(result + 1056) = v2;
      break;
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<19u>::SetL2ResultWrapStartOffset(uint64_t result, __int16 a2)
{
  *(_WORD *)(result + 1074) = a2;
  return result;
}

uint64_t ZinAneTd<19u>::SetL2ResultWrapIndex(uint64_t result, __int16 a2)
{
  *(_WORD *)(result + 1072) = a2;
  return result;
}

uint64_t ZinAneTd<19u>::SetL2ResultWrapAddrOffset(uint64_t result, __int16 a2)
{
  *(_DWORD *)(result + 1112) = *(_DWORD *)(result + 1112) & 0xF800FFFF | ((a2 & 0x7FF) << 16);
  return result;
}

uint64_t ZinAneTd<19u>::SetL2ResultWrapAddr(uint64_t result, __int16 a2)
{
  *(_DWORD *)(result + 1112) = *(_DWORD *)(result + 1112) & 0xFFFFF000 | a2 & 0xFFF;
  return result;
}

uint64_t ZinAneTd<19u>::SetL2SrcOffsetXlsbs(uint64_t result, char a2)
{
  *(_DWORD *)(result + 1116) = *(_DWORD *)(result + 1116) & 0xFFFFFFC0 | a2 & 0x3F;
  return result;
}

uint64_t ZinAneTd<19u>::SetL2SrcOffsetYlsbsFromCropOffsetY(uint64_t a1)
{
  uint64_t result = ZinExtractLSBs(*(unsigned __int16 *)(a1 + 748), 5);
  *(_DWORD *)(a1 + 1116) = *(_DWORD *)(a1 + 1116) & 0xFFFFE0FF | ((result & 0x1F) << 8);
  return result;
}

uint64_t ZinAneTd<19u>::SetSourceAddrWrap(uint64_t result, __int16 a2, __int16 a3)
{
  *(_DWORD *)(result + 110std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = a3 & 0xFFF | ((a2 & 0x7FF) << 16) | *(_DWORD *)(result + 1100) & 0xF800F000;
  return result;
}

uint64_t ZinAneTd<19u>::SetSourceWrap(uint64_t result, unsigned int a2, unsigned __int16 a3, unsigned __int16 a4)
{
  if (a2 >= 4) {
    ZinAssertImpl("Source wrapping dimension not acceptable\n");
  }
  *(_DWORD *)(result + 1056) = *(_DWORD *)(result + 1056) & 0xFFFFFFF8 | dword_211F04410[a2];
  *(_DWORD *)(result + 106std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = a4 | (a3 << 16);
  return result;
}

uint64_t ZinAneTd<19u>::SetL2Src1FIFOMode(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 0x8000000;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 96std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 960) & 0xF7FFFFFF | v2;
  return result;
}

BOOL ZinAneTd<19u>::SetL2Src1Interleave(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1464) + 632), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Source Interleave");
  }
  *(_DWORD *)(a1 + 96std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 960) & 0xFFFFF0FF | ((v4 & 0xF) << 8);
  return result;
}

uint64_t ZinAneTd<19u>::SetL2Src1SourceType(uint64_t result, int a2)
{
  int v2 = 0;
  switch(a2)
  {
    case 0:
      ZinAssertImpl("Error: It must have a valid L2 access mode");
    case 1:
      int v2 = 2;
      break;
    case 2:
      int v2 = 1;
      break;
    case 4:
      int v2 = 3;
      break;
    default:
      break;
  }
  *(_DWORD *)(result + 96std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 960) & 0xFFFFFFFC | v2;
  return result;
}

uint64_t ZinAneTd<19u>::SetL2Src2SourceType(uint64_t result, int a2)
{
  int v2 = 0;
  switch(a2)
  {
    case 0:
      ZinAssertImpl("Error: It must have a valid L2 access mode");
    case 1:
      int v2 = 2;
      break;
    case 2:
      int v2 = 1;
      break;
    case 4:
      int v2 = 3;
      break;
    default:
      break;
  }
  *(_DWORD *)(result + 964) = *(_DWORD *)(result + 964) & 0xFFFFFFFC | v2;
  return result;
}

BOOL ZinAneTd<19u>::SetL2Src2BaseAddress(uint64_t a1, unint64_t a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1464) + 352), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Src2 Base Address");
  }
  *(_DWORD *)(a1 + 992) = *(_DWORD *)(a1 + 992) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<19u>::SetL2Src2ChannelStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x11uLL, (unsigned int *)(*(void *)(a1 + 1464) + 360), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Source 2 Channel Stride");
  }
  *(_DWORD *)(a1 + 996) = *(_DWORD *)(a1 + 996) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<19u>::SetL2Src2RowStride(uint64_t a1, ZinCodegen *this, ZinTensorDimensions *a3, uint64_t a4, uint64_t *a5)
{
  int v8 = 0;
  ZinCodegen::GetL2RowStride(this, a3, *(unsigned int *)(*(void *)(a1 + 1464) + 372), &v8, a5);
  unsigned int v7 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(v8, 0x11uLL, (unsigned int *)(*(void *)(a1 + 1464) + 368), &v7);
  if (!result) {
    ZinAssertImpl("Illegal L2 Source 2 Row Stride");
  }
  *(_DWORD *)(a1 + 100std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 1000) & 0xFFE0000F | (16 * (v7 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<19u>::SetL2Src2DepthStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x11uLL, (unsigned int *)(*(void *)(a1 + 1464) + 376), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Source 2 Depth Stride");
  }
  *(_DWORD *)(a1 + 1004) = *(_DWORD *)(a1 + 1004) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<19u>::SetL2Src2GroupStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x11uLL, (unsigned int *)(*(void *)(a1 + 1464) + 384), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Source 2 Group Stride");
  }
  *(_DWORD *)(a1 + 1008) = *(_DWORD *)(a1 + 1008) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

uint64_t ZinAneTd<19u>::SetL2Src2OffsetXlsbs(uint64_t result, char a2)
{
  *(_DWORD *)(result + 1116) = *(_DWORD *)(result + 1116) & 0xFFC0FFFF | ((a2 & 0x3F) << 16);
  return result;
}

uint64_t ZinAneTd<19u>::SetL2Src2OffsetYlsbsFromCropOffsetY(uint64_t a1)
{
  uint64_t result = ZinExtractLSBs(*(unsigned __int16 *)(a1 + 764), 5);
  *(_DWORD *)(a1 + 1116) = *(_DWORD *)(a1 + 1116) & 0xE0FFFFFF | ((result & 0x1F) << 24);
  return result;
}

uint64_t ZinAneTd<19u>::SetL2Src1CfgForCompression(uint64_t result, int a2)
{
  unsigned int v2 = *(_DWORD *)(result + 960) & 0xFDF80FFF;
  *(_DWORD *)(result + 96std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2 | 0x2000000;
  switch(a2)
  {
    case 1:
      unsigned int v3 = v2 & 0xF9F80FFF | 0x2000000;
LABEL_7:
      *(_DWORD *)(result + 96std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v3;
      return result;
    case 2:
      unsigned int v3 = v2 | 0x6000000;
      goto LABEL_7;
    case 0:
      ZinAssertImpl("Invalid macro block size");
  }
  return result;
}

uint64_t ZinAneTd<19u>::SetL2Src2CfgForCompression(uint64_t result, int a2)
{
  unsigned int v2 = *(_DWORD *)(result + 964) & 0xFDF80FFF;
  *(_DWORD *)(result + 964) = v2 | 0x2000000;
  switch(a2)
  {
    case 1:
      unsigned int v3 = v2 & 0xF9F80FFF | 0x2000000;
LABEL_7:
      *(_DWORD *)(result + 964) = v3;
      return result;
    case 2:
      unsigned int v3 = v2 | 0x6000000;
      goto LABEL_7;
    case 0:
      ZinAssertImpl("Invalid macro block size");
  }
  return result;
}

BOOL ZinAneTd<19u>::SetL2SrcIdxBaseAddr(uint64_t a1, unsigned int a2)
{
  *(_DWORD *)(a1 + 1012) = *(_DWORD *)(a1 + 1012) & 0xFFE0000F | (16 * (a2 & 0x1FFFF));
  return CheckRegValueRange(a2, (unsigned int *)(*(void *)(a1 + 1464) + 392));
}

BOOL ZinAneTd<19u>::SetL2SrcIdxChannelStride(uint64_t a1, unsigned int a2)
{
  *(_DWORD *)(a1 + 1016) = *(_DWORD *)(a1 + 1016) & 0xFFE0000F | (16 * (a2 & 0x1FFFF));
  return CheckRegValueRange(a2, (unsigned int *)(*(void *)(a1 + 1464) + 400));
}

BOOL ZinAneTd<19u>::SetL2SrcIdxGroupStride(uint64_t a1, unsigned int a2)
{
  *(_DWORD *)(a1 + 1024) = *(_DWORD *)(a1 + 1024) & 0xFFE0000F | (16 * (a2 & 0x1FFFF));
  return CheckRegValueRange(a2, (unsigned int *)(*(void *)(a1 + 1464) + 416));
}

BOOL ZinAneTd<19u>::SetL2SrcIdxDepthStride(uint64_t a1, unsigned int a2)
{
  *(_DWORD *)(a1 + 102std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 1020) & 0xFFE0000F | (16 * (a2 & 0x1FFFF));
  return CheckRegValueRange(a2, (unsigned int *)(*(void *)(a1 + 1464) + 408));
}

uint64_t ZinAneTd<19u>::SetL2ResultCfgForCompression(uint64_t result, int a2)
{
  unsigned int v2 = *(_DWORD *)(result + 1028) & 0xFDF80FFF;
  *(_DWORD *)(result + 1028) = v2 | 0x2000000;
  switch(a2)
  {
    case 1:
      unsigned int v3 = v2 & 0xF9F80FFF | 0x2000000;
LABEL_7:
      *(_DWORD *)(result + 1028) = v3;
      return result;
    case 2:
      unsigned int v3 = v2 | 0x6000000;
      goto LABEL_7;
    case 0:
      ZinAssertImpl("Invalid macro block size");
  }
  return result;
}

uint64_t ZinAneTd<19u>::SetSource2AddrWrap(uint64_t result, __int16 a2, __int16 a3)
{
  *(_DWORD *)(result + 1104) = a3 & 0xFFF | ((a2 & 0x7FF) << 16) | *(_DWORD *)(result + 1104) & 0xF800F000;
  return result;
}

uint64_t ZinAneTd<19u>::SetSource2Wrap(uint64_t result, unsigned int a2, unsigned __int16 a3, unsigned __int16 a4)
{
  if (a2 >= 4) {
    ZinAssertImpl("Source wrapping dimension not acceptable\n");
  }
  *(_DWORD *)(result + 1056) = *(_DWORD *)(result + 1056) & 0xFFFFFF8F | dword_211F04420[a2];
  *(_DWORD *)(result + 1064) = a4 | (a3 << 16);
  return result;
}

uint64_t ZinAneTd<19u>::SetL2Src2FIFOMode(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 0x8000000;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 964) = *(_DWORD *)(result + 964) & 0xF7FFFFFF | v2;
  return result;
}

uint64_t ZinAneTd<19u>::SetOpMode(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 1208) & 0xFFFFFFF8;
      goto LABEL_8;
    case 1:
      ZinAssertImpl("ElemWise not valid for architecture");
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 1208) & 0xFFFFFFF8 | 3;
      goto LABEL_8;
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 1208) & 0xFFFFFFF8 | 1;
      goto LABEL_8;
    case 4:
      unsigned int v2 = *(_DWORD *)(result + 1208) & 0xFFFFFFF8 | 2;
      goto LABEL_8;
    case 5:
      unsigned int v2 = *(_DWORD *)(result + 1208) & 0xFFFFFFF8 | 4;
      goto LABEL_8;
    case 6:
      unsigned int v2 = *(_DWORD *)(result + 1208) & 0xFFFFFFF8 | 5;
LABEL_8:
      *(_DWORD *)(result + 1208) = v2;
      break;
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<19u>::SetKernelMode(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 1208) & 0xFFFFFFF7;
LABEL_7:
      *(_DWORD *)(result + 1208) = v2;
      return result;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 1208) | 8;
      goto LABEL_7;
    case 2:
      ZinAssertImpl("Unsupported Kernel Mode");
  }
  return result;
}

uint64_t ZinAneTd<19u>::SetPassthroughEnable(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 32;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 1208) = *(_DWORD *)(result + 1208) & 0xFFFFFFDF | v2;
  return result;
}

uint64_t ZinAneTd<19u>::SetKernelFmt(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 1204) & 0xFFFFFFFC;
      goto LABEL_5;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 1204) & 0xFFFFFFFC | 1;
      goto LABEL_5;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 1204) & 0xFFFFFFFC | 2;
LABEL_5:
      *(_DWORD *)(result + 1204) = v2;
      break;
    case 3:
      ZinAssertImpl("Unimplemented or Unsupported kernel format");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<19u>::SetKernelDmaSrcCoeffDmaEn(uint64_t result, int a2, uint64_t a3)
{
  *(_DWORD *)(result + 4 * a3 + 84) = *(_DWORD *)(result + 4 * a3 + 84) & 0xFFFFFFFE | a2;
  return result;
}

uint64_t ZinAneTd<19u>::SetKernelDmaSrcConfigPrefetch(uint64_t result, uint64_t a2)
{
  if (*(_DWORD *)(a2 + 96) == 1)
  {
    int v2 = *(unsigned __int16 *)(result + 60) | (*(_DWORD *)(a2 + 104) << 16);
    *(_DWORD *)(result + 6std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2;
    unsigned int v3 = v2 & 0xFFFFFFFE | *(unsigned __int8 *)(a2 + 112);
    *(_DWORD *)(result + 6std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v3;
    *(_DWORD *)(result + 6std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v3 & 0xFFFFFFFD | (2 * *(unsigned __int8 *)(a2 + 113));
  }
  return result;
}

uint64_t ZinAneTd<19u>::SetKernelDmaSrcCoeffDmaCacheHint(uint64_t result, int a2, uint64_t a3)
{
  int v3 = 224;
  switch(a2)
  {
    case 0:
      goto LABEL_5;
    case 1:
      int v3 = 32;
      goto LABEL_5;
    case 2:
      int v3 = 64;
      goto LABEL_5;
    case 3:
      int v3 = 192;
LABEL_5:
      *(_DWORD *)(result + 4 * a3 + 84) = *(_DWORD *)(result + 4 * a3 + 84) & 0xFFFFFF0F | v3;
      break;
    case 4:
      ZinAssertImpl("Error: Invalid KernelDmaSrc CoeffDma CacheHint");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<19u>::SetKernelDmaSrcPostScaleDmaCacheHint(uint64_t result, int a2)
{
  int v2 = 224;
  switch(a2)
  {
    case 0:
      goto LABEL_5;
    case 1:
      int v2 = 32;
      goto LABEL_5;
    case 2:
      int v2 = 64;
      goto LABEL_5;
    case 3:
      int v2 = 192;
LABEL_5:
      *(_DWORD *)(result + 292) = *(_DWORD *)(result + 292) & 0xFFFFFF0F | v2;
      break;
    case 4:
      ZinAssertImpl("Error: Invalid KernelDmaSrc PostScale Dma CacheHint");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<19u>::SetKernelDmaSrcBiasDmaCacheHint(uint64_t result, int a2)
{
  int v2 = 224;
  switch(a2)
  {
    case 0:
      goto LABEL_5;
    case 1:
      int v2 = 32;
      goto LABEL_5;
    case 2:
      int v2 = 64;
      goto LABEL_5;
    case 3:
      int v2 = 192;
LABEL_5:
      *(_DWORD *)(result + 276) = *(_DWORD *)(result + 276) & 0xFFFFFF0F | v2;
      break;
    case 4:
      ZinAssertImpl("Error: Invalid KernelDmaSrc PostScale Dma CacheHint");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<19u>::SetKernelDmaSrcPaletteLutDmaCacheHint(uint64_t result, int a2)
{
  int v2 = 224;
  switch(a2)
  {
    case 0:
      goto LABEL_5;
    case 1:
      int v2 = 32;
      goto LABEL_5;
    case 2:
      int v2 = 64;
      goto LABEL_5;
    case 3:
      int v2 = 192;
LABEL_5:
      *(_DWORD *)(result + 308) = *(_DWORD *)(result + 308) & 0xFFFFFF0F | v2;
      break;
    case 4:
      ZinAssertImpl("Error: Invalid KernelDmaSrc PaletteLut Dma CacheHint");
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<19u>::SetKernelDmaSrcNonLinearLutDmaCacheHint(uint64_t result, int a2)
{
  int v2 = 224;
  switch(a2)
  {
    case 0:
      goto LABEL_5;
    case 1:
      int v2 = 32;
      goto LABEL_5;
    case 2:
      int v2 = 64;
      goto LABEL_5;
    case 3:
      int v2 = 192;
LABEL_5:
      *(_DWORD *)(result + 324) = *(_DWORD *)(result + 324) & 0xFFFFFF0F | v2;
      break;
    case 4:
      ZinAssertImpl("Error: Invalid KernelDmaSrc PostScale Dma CacheHint");
    default:
      return result;
  }
  return result;
}

BOOL ZinAneTd<19u>::SetKernelDmaSrcCoeffMemBufferSize(uint64_t a1, unsigned int a2, uint64_t a3)
{
  int v6 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1464) + 616), &v6);
  if (result) {
    *(_DWORD *)(a1 + 4 * a3 + 212) = *(_DWORD *)(a1 + 4 * a3 + 212) & 0x3F | (v6 << 6);
  }
  return result;
}

BOOL ZinAneTd<19u>::SetKernelDmaSrcCoeffBaseOffset(uint64_t a1, unsigned int a2, uint64_t a3)
{
  int v6 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1464) + 608), &v6);
  if (result) {
    *(_DWORD *)(a1 + 4 * a3 + 148) = *(_DWORD *)(a1 + 4 * a3 + 148) & 0x3F | (v6 << 6);
  }
  return result;
}

uint64_t ZinAneTd<19u>::SetKernelDmaSrcDataSetId(uint64_t result, char a2, uint64_t a3)
{
  *(unsigned char *)(result + 4 * a3 + 85) = a2;
  return result;
}

uint64_t ZinAneTd<19u>::SetPaddingMode(uint64_t result, int a2, int a3)
{
  switch(a2)
  {
    case 1:
      if (a3) {
        goto LABEL_12;
      }
      int v3 = 0;
      int v4 = 0;
      break;
    case 2:
      if (a3) {
        goto LABEL_12;
      }
      int v3 = 0;
      int v4 = 4;
      break;
    case 3:
      if (a3) {
        goto LABEL_12;
      }
      int v4 = 8;
      int v3 = 0x40000;
      break;
    case 4:
      if (a3) {
LABEL_12:
      }
        ZinAssertImpl("Error: padding-mode doesn't support constants");
      int v3 = 0;
      int v4 = 12;
      break;
    case 6:
      ZinAssertImpl("Platform doesn't support reflective padding mode");
    case 9:
      int v4 = 0;
      int v3 = (a3 != 0) << 18;
      break;
    default:
      ZinAssertImpl("Invalid padding mode: %d", a2);
  }
  *(_DWORD *)(result + 956) = v4 & 0xFF00FFFF | (a3 << 16) | *(_DWORD *)(result + 956) & 0xFF00FFF3;
  *(_DWORD *)(result + 1208) = *(_DWORD *)(result + 1208) & 0xFFFBFFFF | v3;
  return result;
}

uint64_t ZinAneTd<19u>::SetKernelAlignmentFormat(uint64_t result, int a2)
{
  if (a2)
  {
    if (a2 != 1) {
      return result;
    }
    unsigned int v2 = *(_DWORD *)(result + 1204) & 0xFFFEFFFF;
  }
  else
  {
    unsigned int v2 = *(_DWORD *)(result + 1204) | 0x10000;
  }
  *(_DWORD *)(result + 1204) = v2;
  return result;
}

void ZinAneTd<19u>::SetAlignedKernelRelocationCommand(uint64_t a1, void *a2, uint64_t a3, const void **a4, uint64_t a5)
{
  if (a2[1])
  {
    if (*((char *)a4 + 23) >= 0) {
      size_t v10 = *((unsigned __int8 *)a4 + 23);
    }
    else {
      size_t v10 = (size_t)a4[1];
    }
    long long v11 = __p;
    std::string::basic_string[abi:ne180100]((uint64_t)__p, v10 + 7);
    if (v24 < 0) {
      long long v11 = (void **)__p[0];
    }
    if (v10)
    {
      if (*((char *)a4 + 23) >= 0) {
        uint64_t v12 = a4;
      }
      else {
        uint64_t v12 = *a4;
      }
      memmove(v11, v12, v10);
    }
    strcpy((char *)v11 + v10, "_actlut");
    ZinAneTdHw_v19::AddRelocInfo((uint64_t *)(a1 + 8), (uint64_t)__p, 5510, a3, 1, 1, a5, 0);
    if (v24 < 0) {
      operator delete(__p[0]);
    }
  }
  if (a2[2])
  {
    if (*((char *)a4 + 23) >= 0) {
      size_t v13 = *((unsigned __int8 *)a4 + 23);
    }
    else {
      size_t v13 = (size_t)a4[1];
    }
    int v14 = __p;
    std::string::basic_string[abi:ne180100]((uint64_t)__p, v13 + 7);
    if (v24 < 0) {
      int v14 = (void **)__p[0];
    }
    if (v13)
    {
      if (*((char *)a4 + 23) >= 0) {
        int v15 = a4;
      }
      else {
        int v15 = *a4;
      }
      memmove(v14, v15, v13);
    }
    strcpy((char *)v14 + v13, "_pallut");
    ZinAneTdHw_v19::AddRelocInfo((uint64_t *)(a1 + 8), (uint64_t)__p, 5506, a3, 1, 1, a5, 0);
    if (v24 < 0) {
      operator delete(__p[0]);
    }
  }
  if (a2[3])
  {
    if (*((char *)a4 + 23) >= 0) {
      size_t v16 = *((unsigned __int8 *)a4 + 23);
    }
    else {
      size_t v16 = (size_t)a4[1];
    }
    int v17 = __p;
    std::string::basic_string[abi:ne180100]((uint64_t)__p, v16 + 6);
    if (v24 < 0) {
      int v17 = (void **)__p[0];
    }
    if (v16)
    {
      if (*((char *)a4 + 23) >= 0) {
        uint64_t v18 = a4;
      }
      else {
        uint64_t v18 = *a4;
      }
      memmove(v17, v18, v16);
    }
    strcpy((char *)v17 + v16, "_scale");
    ZinAneTdHw_v19::AddRelocInfo((uint64_t *)(a1 + 8), (uint64_t)__p, 5502, a3, 1, 1, a5, 0);
    if (v24 < 0) {
      operator delete(__p[0]);
    }
  }
  if (a2[4])
  {
    size_t v19 = (uint64_t *)(a1 + 8);
    if (*((char *)a4 + 23) >= 0) {
      size_t v20 = *((unsigned __int8 *)a4 + 23);
    }
    else {
      size_t v20 = (size_t)a4[1];
    }
    long long v21 = __p;
    std::string::basic_string[abi:ne180100]((uint64_t)__p, v20 + 5);
    if (v24 < 0) {
      long long v21 = (void **)__p[0];
    }
    if (v20)
    {
      if (*((char *)a4 + 23) >= 0) {
        size_t v22 = a4;
      }
      else {
        size_t v22 = *a4;
      }
      memmove(v21, v22, v20);
    }
    strcpy((char *)v21 + v20, "_bias");
    ZinAneTdHw_v19::AddRelocInfo(v19, (uint64_t)__p, 5498, a3, 1, 1, a5, 0);
    if (v24 < 0) {
      operator delete(__p[0]);
    }
  }
}

void sub_2112DA3DC(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, void *__p, uint64_t a10, int a11, __int16 a12, char a13, char a14)
{
  if (a14 < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

_DWORD *ZinAneTd<19u>::SetAlignedKernelBias(_DWORD *result, uint64_t a2, uint64_t a3, int a4)
{
  result[13] = result[13] & 0xFFFFFFF3 | 8;
  result[301] = result[301] & 0xFFF9FFFF | 0x40000;
  result[70] = result[70] & 0x3F | (a4 << 6);
  result[69] |= 1u;
  return result;
}

_DWORD *ZinAneTd<19u>::SetAlignedKernelPostScale(_DWORD *result, uint64_t a2, uint64_t a3, int a4)
{
  result[13] = result[13] & 0xFFFFFFFC | 2;
  result[301] = result[301] & 0xFFE7FFFF | 0x100000;
  result[74] = result[74] & 0x3F | (a4 << 6);
  result[73] |= 1u;
  return result;
}

uint64_t ZinAneTd<19u>::SetAlignedKernelPaletteLut(uint64_t result, uint64_t a2, uint64_t a3, int a4)
{
  *(_DWORD *)(result + 312) = *(_DWORD *)(result + 312) & 0x3F | (a4 << 6);
  *(_DWORD *)(result + 308) |= 1u;
  return result;
}

uint64_t ZinAneTd<19u>::SetAlignedKernelNonLinearLut(uint64_t result, uint64_t a2, uint64_t a3, int a4)
{
  *(_DWORD *)(result + 328) = *(_DWORD *)(result + 328) & 0x3F | (a4 << 6);
  *(_DWORD *)(result + 324) |= 1u;
  return result;
}

uint64_t ZinAneTd<19u>::SetAlignedCoeffSizePerCh(uint64_t result, int a2)
{
  *(_DWORD *)(result + 56) = *(_DWORD *)(result + 56) & 0xF0000000 | a2 & 0xFFFFFFF;
  return result;
}

uint64_t ZinAneTd<19u>::SetQuantizationSrc1InputOffset(uint64_t result, char a2)
{
  *(unsigned char *)(result + 1188) = a2;
  return result;
}

uint64_t ZinAneTd<19u>::SetQuantizationSrc2InputOffset(uint64_t result, char a2)
{
  *(unsigned char *)(result + 1189) = a2;
  return result;
}

uint64_t ZinAneTd<19u>::SetPEOutputQuantization(uint64_t result, char a2)
{
  *(unsigned char *)(result + 119std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = a2;
  return result;
}

uint64_t ZinAneTd<19u>::SetPEFinalScale(uint64_t result, float a2)
{
  *(float *)(result + 1152) = a2;
  return result;
}

void ZinAneTd<19u>::SetPEScale(uint64_t a1, float a2)
{
  *(float *)(a1 + 114std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = ZinF32ToNearestF19(a2);
}

void ZinAneTd<19u>::SetPEBias(uint64_t a1, float a2)
{
  *(float *)(a1 + 1136) = ZinF32ToNearestF19(a2);
}

void ZinAneTd<19u>::SetPEPreScale(uint64_t a1, float a2)
{
  *(float *)(a1 + 1148) = ZinF32ToNearestF19(a2);
}

uint64_t ZinAneTd<19u>::SetPESrc1ReLu(uint64_t result, int a2)
{
  *(_DWORD *)(result + 956) = *(_DWORD *)(result + 956) & 0xFFFFFFFE | a2;
  return result;
}

uint64_t ZinAneTd<19u>::SetPESrc2ReLu(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 16;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 956) = *(_DWORD *)(result + 956) & 0xFFFFFFEF | v2;
  return result;
}

uint64_t ZinAneTd<19u>::SetPESrc1Transpose(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 256;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 588) = *(_DWORD *)(result + 588) & 0xFFFFFEFF | v2;
  return result;
}

uint64_t ZinAneTd<19u>::SetPESrc2Transpose(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 512;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 588) = *(_DWORD *)(result + 588) & 0xFFFFFDFF | v2;
  return result;
}

uint64_t ZinAneTd<19u>::SetPESrc1Broadcast(uint64_t result, uint64_t a2)
{
  for (uint64_t i = *(uint64_t **)(a2 + 16); i; uint64_t i = (uint64_t *)*i)
  {
    unsigned int v3 = *((_DWORD *)i + 4) - 1;
    if (v3 <= 3) {
      *(_DWORD *)(result + 588) |= dword_211F04430[v3];
    }
  }
  return result;
}

uint64_t ZinAneTd<19u>::SetPESrc2Broadcast(uint64_t result, uint64_t a2, char a3)
{
  for (uint64_t i = *(uint64_t **)(a2 + 16); i; uint64_t i = (uint64_t *)*i)
  {
    int v4 = 128;
    switch(*((_DWORD *)i + 4))
    {
      case 1:
        int v4 = 64;
        break;
      case 2:
        break;
      case 3:
        if (a3) {
          continue;
        }
        int v4 = 32;
        break;
      case 4:
        if (a3) {
          continue;
        }
        int v4 = 16;
        break;
      default:
        continue;
    }
    *(_DWORD *)(result + 588) |= v4;
  }
  return result;
}

void ZinAneTd<19u>::SetPEIndexMode(uint64_t a1, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(a1 + 1096) & 0xFFF8FFFF | 0x10000;
      goto LABEL_7;
    case 1:
      unsigned int v2 = *(_DWORD *)(a1 + 1096) & 0xFFF8FFFF | 0x20000;
      goto LABEL_7;
    case 2:
      unsigned int v2 = *(_DWORD *)(a1 + 1096) & 0xFFF8FFFF | 0x50000;
      goto LABEL_7;
    case 3:
      unsigned int v2 = *(_DWORD *)(a1 + 1096) & 0xFFF8FFFF | 0x30000;
      goto LABEL_7;
    case 4:
      unsigned int v2 = *(_DWORD *)(a1 + 1096) & 0xFFF8FFFF | 0x40000;
LABEL_7:
      *(_DWORD *)(a1 + 1096) = v2;
      break;
    case 5:
      BOOL v3 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v3) {
        ZinAneTd<8u>::SetPEIndexMode(v3, v4, v5, v6, v7, v8, v9, v10);
      }
      break;
    default:
      return;
  }
}

uint64_t ZinAneTd<19u>::SetPEIndexTranspose(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 0x4000000;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 1096) = *(_DWORD *)(result + 1096) & 0xFBFFFFFF | v2;
  return result;
}

uint64_t ZinAneTd<19u>::SetPEIndexBroadcast(uint64_t result, uint64_t a2)
{
  int v2 = *(uint64_t **)(a2 + 16);
  if (v2)
  {
    while (1)
    {
      int v3 = *((_DWORD *)v2 + 4);
      if (v3 == 2) {
        break;
      }
      if (v3 == 1)
      {
        int v4 = 0x1000000;
LABEL_6:
        *(_DWORD *)(result + 1096) |= v4;
      }
      int v2 = (uint64_t *)*v2;
      if (!v2) {
        return result;
      }
    }
    int v4 = 0x2000000;
    goto LABEL_6;
  }
  return result;
}

uint64_t ZinAneTd<19u>::SetPEMaxIndex(uint64_t result, __int16 a2)
{
  *(_WORD *)(result + 1096) = a2;
  return result;
}

uint64_t ZinAneTd<19u>::SetPEOperationMode(uint64_t a1, int a2)
{
  uint64_t v2 = 0;
  switch(a2)
  {
    case 0:
      *(_DWORD *)(a1 + 1132) &= 0xFFFFFFE3;
      int v3 = (unsigned int *)(*(void *)(a1 + 1464) + 648);
      unint64_t v4 = 0;
      goto LABEL_8;
    case 1:
      *(_DWORD *)(a1 + 11std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_DWORD *)(a1 + 1132) & 0xFFFFFFE3 | 4;
      int v3 = (unsigned int *)(*(void *)(a1 + 1464) + 648);
      unint64_t v4 = 1;
      goto LABEL_8;
    case 2:
      *(_DWORD *)(a1 + 11std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_DWORD *)(a1 + 1132) & 0xFFFFFFE3 | 0x10;
      if (!CheckRegValueRange(4uLL, (unsigned int *)(*(void *)(a1 + 1464) + 648))) {
        goto LABEL_5;
      }
      goto LABEL_9;
    case 3:
      *(_DWORD *)(a1 + 11std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_DWORD *)(a1 + 1132) & 0xFFFFFFE3 | 8;
      int v3 = (unsigned int *)(*(void *)(a1 + 1464) + 648);
      unint64_t v4 = 2;
      goto LABEL_8;
    case 4:
      *(_DWORD *)(a1 + 11std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_DWORD *)(a1 + 1132) & 0xFFFFFFE3 | 0xC;
      int v3 = (unsigned int *)(*(void *)(a1 + 1464) + 648);
      unint64_t v4 = 3;
LABEL_8:
      if (CheckRegValueRange(v4, v3)) {
        goto LABEL_9;
      }
LABEL_5:
      uint64_t v2 = 0;
      break;
    case 5:
      return v2;
    default:
LABEL_9:
      uint64_t v2 = 1;
      break;
  }
  return v2;
}

uint64_t ZinAneTd<19u>::SetPEFirstSource(uint64_t result, int a2)
{
  if (a2)
  {
    if (a2 != 1) {
      return result;
    }
    unsigned int v2 = *(_DWORD *)(result + 1132) & 0xFFFEFFFF;
  }
  else
  {
    unsigned int v2 = *(_DWORD *)(result + 1132) | 0x10000;
  }
  *(_DWORD *)(result + 11std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = v2;
  return result;
}

uint64_t ZinAneTd<19u>::SetPESecondSource(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 1132) & 0xFFF3FFFF;
      goto LABEL_6;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 1132) & 0xFFF3FFFF | 0x40000;
      goto LABEL_6;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 1132) & 0xFFF3FFFF | 0x80000;
      goto LABEL_6;
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 1132) | 0xC0000;
LABEL_6:
      *(_DWORD *)(result + 11std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = v2;
      break;
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<19u>::SetPECondition(uint64_t result, int a2)
{
  switch(a2)
  {
    case 0:
      unsigned int v2 = *(_DWORD *)(result + 1132) & 0xFFFFFE3F;
      goto LABEL_10;
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 1132) | 0x1C0;
      goto LABEL_10;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 1132) & 0xFFFFFE3F | 0x100;
      goto LABEL_10;
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 1132) & 0xFFFFFE3F | 0x180;
      goto LABEL_10;
    case 4:
      unsigned int v2 = *(_DWORD *)(result + 1132) & 0xFFFFFE3F | 0x80;
      goto LABEL_10;
    case 5:
      unsigned int v2 = *(_DWORD *)(result + 1132) & 0xFFFFFE3F | 0x140;
      goto LABEL_10;
    case 6:
      unsigned int v2 = *(_DWORD *)(result + 1132) & 0xFFFFFE3F | 0x40;
      goto LABEL_10;
    case 7:
      unsigned int v2 = *(_DWORD *)(result + 1132) & 0xFFFFFE3F | 0xC0;
LABEL_10:
      *(_DWORD *)(result + 11std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = v2;
      break;
    default:
      return result;
  }
  return result;
}

uint64_t ZinAneTd<19u>::SetPEOutputCtoW(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 1024;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 588) = *(_DWORD *)(result + 588) & 0xFFFFFBFF | v2;
  return result;
}

BOOL ZinAneTd<19u>::SetL2ResultBaseAddr(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1464) + 424), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Result Base Address");
  }
  *(_DWORD *)(a1 + 10std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)this + 32) = *(_DWORD *)(a1 + 1032) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<19u>::SetL2ResultChannelStride(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1464) + 432), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Result Channel Stride");
  }
  *(_DWORD *)(a1 + 1036) = *(_DWORD *)(a1 + 1036) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<19u>::SetL2ResultRowStride(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1464) + 440), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Result Row Stride");
  }
  *(_DWORD *)(a1 + 104std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 1040) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<19u>::SetL2ResultDepthStride(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1464) + 448), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Result Depth Stride");
  }
  *(_DWORD *)(a1 + 1044) = *(_DWORD *)(a1 + 1044) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

BOOL ZinAneTd<19u>::SetL2ResultGroupStride(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1464) + 456), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Result Group Stride");
  }
  *(_DWORD *)(a1 + 1048) = *(_DWORD *)(a1 + 1048) & 0xFFE0000F | (16 * (v4 & 0x1FFFF));
  return result;
}

uint64_t ZinAneTd<19u>::SetL2BfrMode(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 8;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 1028) = *(_DWORD *)(result + 1028) & 0xFFFFFFF7 | v2;
  return result;
}

uint64_t ZinAneTd<19u>::SetL2ResultType(uint64_t result, int a2)
{
  switch(a2)
  {
    case 1:
      unsigned int v2 = *(_DWORD *)(result + 1028) & 0xFFFFFFFC | 2;
      break;
    case 2:
      unsigned int v2 = *(_DWORD *)(result + 1028) & 0xFFFFFFFC | 1;
      break;
    case 3:
      unsigned int v2 = *(_DWORD *)(result + 1028) & 0xFFFFFFFC;
      break;
    case 4:
      unsigned int v2 = *(_DWORD *)(result + 1028) | 3;
      break;
    default:
      ZinAssertImpl("Invalid L2 Result Type");
  }
  *(_DWORD *)(result + 1028) = v2;
  return result;
}

uint64_t ZinAneTd<19u>::SetTileDmaSrc1Format(uint64_t result, int a2, int a3)
{
  switch(a2)
  {
    case 1:
      unsigned int v3 = *(_DWORD *)(result + 720) & 0xFFFFCFFC | 0x1000;
      goto LABEL_16;
    case 2:
      unsigned int v3 = *(_DWORD *)(result + 720) & 0xFFFFCFFC;
      goto LABEL_16;
    case 3:
      unsigned int v4 = *(_DWORD *)(result + 720) & 0xFFFFCFCC;
      int v5 = 8241;
      break;
    case 4:
      unsigned int v3 = *(_DWORD *)(result + 720) & 0xFFFFCECC | 1;
      goto LABEL_16;
    case 5:
      unsigned int v4 = *(_DWORD *)(result + 720) & 0xFFFFCECC;
      int v5 = 257;
      break;
    case 6:
      unsigned int v4 = *(_DWORD *)(result + 720) & 0xFFFFCECC;
      int v5 = 17;
      break;
    case 7:
      unsigned int v4 = *(_DWORD *)(result + 720) & 0xFFFFCECC;
      int v5 = 273;
      break;
    case 8:
      ZinAssertImpl("Packed10 format not supported");
    case 9:
      unsigned int v4 = *(_DWORD *)(result + 720) & 0xFFFFCECC;
      if (!a3) {
        goto LABEL_14;
      }
      int v5 = 4401;
      break;
    case 10:
      unsigned int v4 = *(_DWORD *)(result + 720) & 0xFFFFCECC;
      if (a3) {
        int v5 = 305;
      }
      else {
LABEL_14:
      }
        int v5 = 8497;
      break;
    case 11:
      unsigned int v4 = *(_DWORD *)(result + 720) & 0xFFFFFFCF;
      int v5 = 12547;
      break;
    case 12:
      ZinAssertImpl("E4M3 format is not supported");
    case 13:
      ZinAssertImpl("E5M2 format is not supported");
    default:
      ZinAssertImpl("Invalid format provided");
  }
  unsigned int v3 = v4 | v5;
LABEL_16:
  *(_DWORD *)(result + 72std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v3;
  return result;
}

BOOL ZinAneTd<19u>::SetTileDmaSrc1Interleave(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1464) + 632), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc1 Interleave");
  }
  *(_DWORD *)(a1 + 72std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 720) & 0xF0FFFFFF | ((v4 & 0xF) << 24);
  return result;
}

uint64_t ZinAneTd<19u>::SetTileDmaSrc1FIFOMode(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 0x40000000;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 616) = *(_DWORD *)(result + 616) & 0xBFFFFFFF | v2;
  return result;
}

uint64_t ZinAneTd<19u>::SetTileDmaSrc1Enable(uint64_t result)
{
  *(_DWORD *)(result + 616) |= 1u;
  return result;
}

uint64_t ZinAneTd<19u>::SetTileDmaSrc1CacheHint(uint64_t result, int a2, int a3, int a4)
{
  int v4 = 224;
  switch(a2)
  {
    case 0:
      goto LABEL_5;
    case 1:
      int v4 = 32;
      goto LABEL_5;
    case 2:
      int v4 = 64;
      goto LABEL_5;
    case 3:
      int v4 = 192;
LABEL_5:
      *(_DWORD *)(result + 616) = *(_DWORD *)(result + 616) & 0xFFFFFF0F | v4;
      break;
    case 4:
LABEL_15:
      ZinAssertImpl("Invalid CacheHint");
    default:
      break;
  }
  char v5 = 32;
  switch(a4)
  {
    case 0:
      char v5 = -32;
      goto LABEL_10;
    case 2:
      char v5 = 64;
      goto LABEL_10;
    case 3:
      char v5 = -64;
      goto LABEL_10;
    case 4:
      goto LABEL_15;
    default:
LABEL_10:
      char v6 = 2;
      switch(a3)
      {
        case 0:
          char v6 = 14;
          goto LABEL_14;
        case 2:
          char v6 = 4;
          goto LABEL_14;
        case 3:
          char v6 = 12;
          goto LABEL_14;
        case 4:
          goto LABEL_15;
        default:
LABEL_14:
          *(unsigned char *)(result + 624) = v6 | v5;
          return result;
      }
  }
}

BOOL ZinAneTd<19u>::SetTileDmaSrc1ChannelStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 1464) + 488), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc1 Channel Stride");
  }
  *(_DWORD *)(a1 + 644) = *(_DWORD *)(a1 + 644) & 0x3F | (v4 << 6);
  return result;
}

BOOL ZinAneTd<19u>::SetTileDmaSrc1RowStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 1464) + 480), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc1 Row Stride");
  }
  *(_DWORD *)(a1 + 64std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 640) & 0x3F | (v4 << 6);
  return result;
}

BOOL ZinAneTd<19u>::SetTileDmaSrc1DepthStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 1464) + 496), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc1 Depth Stride");
  }
  *(_DWORD *)(a1 + 648) = *(_DWORD *)(a1 + 648) & 0x3F | (v4 << 6);
  return result;
}

BOOL ZinAneTd<19u>::SetTileDmaSrc1GroupStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 1464) + 504), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc1 Group Stride");
  }
  *(_DWORD *)(a1 + 652) = *(_DWORD *)(a1 + 652) & 0x3F | (v4 << 6);
  return result;
}

uint64_t ZinAneTd<19u>::SetTileDmaSrc1CropOffset(uint64_t result, unsigned __int16 a2, unsigned __int16 a3)
{
  *(_DWORD *)(result + 748) = a3 | (a2 << 16);
  return result;
}

uint64_t ZinAneTd<19u>::SetTileDmaSrc1WrapStatic(uint64_t a1, unsigned __int16 a2, unsigned __int16 a3, unsigned int a4)
{
  uint64_t result = ZinAneTd<19u>::SetTileDmaSrc1WrapCfg(a1, a4);
  *(_DWORD *)(a1 + 80std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = a3 | (a2 << 16);
  return result;
}

uint64_t ZinAneTd<19u>::SetTileDmaSrc1WrapCfg(uint64_t a1, unsigned int a2)
{
  if (a2 == 4) {
    ZinAssertImpl("Width wrap axis is not supported on this architecture");
  }
  uint64_t result = ZinIrCodegenGetDMAWrapCfgDim(a2);
  *(_DWORD *)(a1 + 624) = *(_DWORD *)(a1 + 624) & 0xFFFFF8FF | ((result & 7) << 8);
  return result;
}

uint64_t ZinAneTd<19u>::SetTileDmaSrc1WrapDynamic(uint64_t a1, uint64_t a2, unsigned int a3)
{
  char v6 = (uint64_t *)(a1 + 8);
  std::string::basic_string[abi:ne180100]<0>(__p, &byte_211F4AA5D);
  ZinAneTdHw_v19::AddRelocInfo(v6, (uint64_t)__p, 4974, a2, 0, 0, 0, 0);
  if (v9 < 0) {
    operator delete(__p[0]);
  }
  return ZinAneTd<19u>::SetTileDmaSrc1WrapCfg(a1, a3);
}

void sub_2112DB31C(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11, int a12, __int16 a13, char a14, char a15)
{
  if (a15 < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinAneTd<19u>::SetTileDmaSrc1FmtOffsetCh(uint64_t result, char a2)
{
  *(_DWORD *)(result + 72std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 720) & 0xFFF8FFFF | ((a2 & 7) << 16);
  return result;
}

uint64_t ZinAneTd<19u>::SetTileDmaSrc1FmtCmpVec(uint64_t result, unsigned __int8 a2)
{
  *(_DWORD *)(result + 72std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 720) & 0xFFFFFFF | (a2 << 28);
  return result;
}

uint64_t ZinAneTd<19u>::SetTileDmaSrc1BaseAddrLo(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return ZinAneTdHw_v19::AddRelocInfo((uint64_t *)(a1 + 8), a2, 4932, a3, 1, 1, 0, 0);
}

uint64_t ZinAneTd<19u>::SetTileDmaSrc1DependencyMode(uint64_t result, int a2)
{
  if (a2 == 2)
  {
    unsigned int v2 = *(_DWORD *)(result + 616) & 0xCFFFFFFF | 0x10000000;
  }
  else if (a2 == 1)
  {
    unsigned int v2 = *(_DWORD *)(result + 616) & 0xCFFFFFFF | 0x20000000;
  }
  else
  {
    if (a2) {
      return result;
    }
    unsigned int v2 = *(_DWORD *)(result + 616) & 0xCFFFFFFF;
  }
  *(_DWORD *)(result + 616) = v2;
  return result;
}

uint64_t ZinAneTd<19u>::SetTileDmaSrc2DependencyMode(uint64_t result, int a2)
{
  if (a2 == 2)
  {
    unsigned int v2 = *(_DWORD *)(result + 620) & 0xCFFFFFFF | 0x10000000;
  }
  else if (a2 == 1)
  {
    unsigned int v2 = *(_DWORD *)(result + 620) & 0xCFFFFFFF | 0x20000000;
  }
  else
  {
    if (a2) {
      return result;
    }
    unsigned int v2 = *(_DWORD *)(result + 620) & 0xCFFFFFFF;
  }
  *(_DWORD *)(result + 62std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v2;
  return result;
}

unint64_t ZinAneTd<19u>::SetTileDmaSrc1DependencyInterval(uint64_t a1, unsigned int a2)
{
  unint64_t result = ZinIrCodegenValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1464) + 640));
  *(_DWORD *)(a1 + 616) = *(_DWORD *)(a1 + 616) & 0xF0FFFFFF | ((result & 0xF) << 24);
  return result;
}

unint64_t ZinAneTd<19u>::SetTileDmaSrc2DependencyInterval(uint64_t a1, unsigned int a2)
{
  unint64_t result = ZinIrCodegenValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1464) + 640));
  *(_DWORD *)(a1 + 62std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 620) & 0xF0FFFFFF | ((result & 0xF) << 24);
  return result;
}

uint64_t *ZinAneTd<19u>::SetTileDmaSrc1DependencyOffset(uint64_t a1, void *a2)
{
  int v4 = 1;
  unint64_t result = std::__hash_table<ZinIrDimension,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,std::allocator<ZinIrDimension>>::find<ZinIrDimension>(a2, &v4);
  if (result) {
    *(_DWORD *)(a1 + 808) = result[3];
  }
  return result;
}

uint64_t *ZinAneTd<19u>::SetTileDmaSrc2DependencyOffset(uint64_t a1, void *a2)
{
  int v4 = 1;
  unint64_t result = std::__hash_table<ZinIrDimension,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,std::allocator<ZinIrDimension>>::find<ZinIrDimension>(a2, &v4);
  if (result) {
    *(_DWORD *)(a1 + 812) = result[3];
  }
  return result;
}

uint64_t ZinAneTd<19u>::SetTileDmaSrc1OffsetY(uint64_t result, __int16 a2)
{
  *(_WORD *)(result + 748) = a2;
  return result;
}

int8x16_t ZinAneTd<19u>::SetTileDmaSrc1PixelOffset(int8x16_t *a1, unsigned int a2, unsigned int a3, unsigned int a4, unsigned int a5)
{
  v5.i64[0] = __PAIR64__(a3, a2);
  v5.i64[1] = __PAIR64__(a5, a4);
  v6.i64[0] = 0xFFFF0000FFFF0000;
  v6.i64[1] = 0xFFFF0000FFFF0000;
  int8x16_t result = vbslq_s8(v6, a1[48], v5);
  a1[48] = result;
  return result;
}

uint64_t ZinAneTd<19u>::SetTileDmaSrc1CompressedInfo(uint64_t result, int a2, int a3, int a4)
{
  int v4 = *(_DWORD *)(result + 736);
  *(_DWORD *)(result + 736) = v4 | 1;
  switch(a4)
  {
    case 0:
      unsigned int v5 = v4 & 0xFFFFCFFE | 1;
      break;
    case 1:
      unsigned int v5 = v4 & 0xFFFFCFFE | 0x1001;
      break;
    case 2:
      unsigned int v5 = v4 & 0xFFFFCFFE | 0x2001;
      break;
    case 3:
      unsigned int v5 = v4 | 0x3001;
      break;
    default:
      ZinAssertImpl("Invalid Lossy Mode");
  }
  *(_DWORD *)(result + 736) = v5;
  if (a3 == 2)
  {
    unsigned int v6 = v5 | 4;
  }
  else
  {
    if (a3 != 1) {
      ZinAssertImpl("Unsupported macro block size");
    }
    unsigned int v6 = v5 & 0xFFFFFFFB;
  }
  *(_DWORD *)(result + 736) = v6;
  if ((a2 - 1) >= 0x13) {
    ZinAssertImpl("Invalid packing format");
  }
  *(_DWORD *)(result + 736) = v6 & 0xFFFFFC0F | dword_211F04368[a2 - 1];
  return result;
}

BOOL ZinAneTd<19u>::SetTileDmaSrc1CompressedSize(uint64_t a1, unsigned int a2, unsigned int a3)
{
  int v7 = 0;
  if (!ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1464) + 24), &v7)) {
    ZinAssertImpl("Illegal TileDmaSrc1 Compressed Width");
  }
  *(_DWORD *)(a1 + 74std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 740) & 0xFFFE0000 | v7 & 0x1FFFF;
  int v6 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a3, (unsigned int *)(*(void *)(a1 + 1464) + 16), &v6);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc1 Compressed Height");
  }
  *(_DWORD *)(a1 + 744) = *(_DWORD *)(a1 + 744) & 0xFFFE0000 | v6 & 0x1FFFF;
  return result;
}

double ZinAneTd<19u>::SetTileDmaSrc1MetaData(uint64_t a1, uint64_t a2, uint64_t a3, unsigned int a4, unsigned int a5, int a6)
{
  ZinAneTdHw_v19::AddRelocInfo((uint64_t *)(a1 + 8), a2, 4944, a3, 1, 1, 0, 0);
  *(_DWORD *)(a1 + 736) &= ~8u;
  double result = COERCE_DOUBLE(__PAIR64__(a5, a4));
  *(int32x2_t *)(a1 + 696) = vsli_n_s32(*(int32x2_t *)(a1 + 696), (int32x2_t)__PAIR64__(a5, a4), 7uLL);
  *(_DWORD *)(a1 + 704) = *(_DWORD *)(a1 + 704) & 0x7F | (a6 << 7);
  return result;
}

uint64_t ZinAneTd<19u>::SetTileDmaSrc1NoMetaData(uint64_t result)
{
  *(_DWORD *)(result + 736) |= 8u;
  return result;
}

uint64_t ZinAneTd<19u>::SetTileDmaSrc1DataSetId(uint64_t result, char a2)
{
  *(unsigned char *)(result + 617) = a2;
  return result;
}

BOOL ZinAneTd<19u>::SetL2Src2Interleave(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1464) + 632), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Source Interleave");
  }
  *(_DWORD *)(a1 + 964) = *(_DWORD *)(a1 + 964) & 0xFFFFF0FF | ((v4 & 0xF) << 8);
  return result;
}

uint64_t ZinAneTd<19u>::SetTileDmaSrc2FIFOMode(uint64_t result, int a2)
{
  if (a2) {
    int v2 = 0x40000000;
  }
  else {
    int v2 = 0;
  }
  *(_DWORD *)(result + 62std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(result + 620) & 0xBFFFFFFF | v2;
  return result;
}

uint64_t ZinAneTd<19u>::SetTileDmaSrc2Enable(uint64_t result)
{
  *(_DWORD *)(result + 620) |= 1u;
  return result;
}

uint64_t ZinAneTd<19u>::SetTileDmaSrc2CropOffset(uint64_t result, unsigned __int16 a2, unsigned __int16 a3)
{
  *(_DWORD *)(result + 764) = a3 | (a2 << 16);
  return result;
}

uint64_t ZinAneTd<19u>::SetTileDmaSrc2WrapStatic(uint64_t a1, unsigned __int16 a2, unsigned __int16 a3, unsigned int a4)
{
  uint64_t result = ZinAneTd<19u>::SetTileDmaSrc2WrapCfg(a1, a4);
  *(_DWORD *)(a1 + 804) = a3 | (a2 << 16);
  return result;
}

uint64_t ZinAneTd<19u>::SetTileDmaSrc2WrapCfg(uint64_t a1, unsigned int a2)
{
  if (a2 == 4) {
    ZinAssertImpl("Width wrap axis is not supported on this architecture");
  }
  uint64_t result = ZinIrCodegenGetDMAWrapCfgDim(a2);
  *(_DWORD *)(a1 + 628) = *(_DWORD *)(a1 + 628) & 0xFFFFF8FF | ((result & 7) << 8);
  return result;
}

uint64_t ZinAneTd<19u>::SetTileDmaSrc2WrapDynamic(uint64_t a1, uint64_t a2, unsigned int a3)
{
  int v6 = (uint64_t *)(a1 + 8);
  std::string::basic_string[abi:ne180100]<0>(__p, &byte_211F4AA5D);
  ZinAneTdHw_v19::AddRelocInfo(v6, (uint64_t)__p, 4975, a2, 0, 0, 0, 0);
  if (v9 < 0) {
    operator delete(__p[0]);
  }
  return ZinAneTd<19u>::SetTileDmaSrc2WrapCfg(a1, a3);
}

void sub_2112DB910(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11, int a12, __int16 a13, char a14, char a15)
{
  if (a15 < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinAneTd<19u>::SetTileDmaSrc2FmtOffsetCh(uint64_t result, char a2)
{
  *(_DWORD *)(result + 724) = *(_DWORD *)(result + 724) & 0xFFF8FFFF | ((a2 & 7) << 16);
  return result;
}

uint64_t ZinAneTd<19u>::SetTileDmaSrc2FmtCmpVec(uint64_t result, unsigned __int8 a2)
{
  *(_DWORD *)(result + 724) = *(_DWORD *)(result + 724) & 0xFFFFFFF | (a2 << 28);
  return result;
}

uint64_t ZinAneTd<19u>::SetTileDmaSrc2OffsetY(uint64_t result, __int16 a2)
{
  *(_WORD *)(result + 764) = a2;
  return result;
}

int8x16_t ZinAneTd<19u>::SetTileDmaSrc2PixelOffset(int8x16_t *a1, unsigned int a2, unsigned int a3, unsigned int a4, unsigned int a5)
{
  v5.i64[0] = __PAIR64__(a3, a2);
  v5.i64[1] = __PAIR64__(a5, a4);
  v6.i64[0] = 0xFFFF0000FFFF0000;
  v6.i64[1] = 0xFFFF0000FFFF0000;
  int8x16_t result = vbslq_s8(v6, a1[49], v5);
  a1[49] = result;
  return result;
}

uint64_t ZinAneTd<19u>::SetTileDmaSrc2CompressedInfo(uint64_t result, int a2, int a3, int a4)
{
  int v4 = *(_DWORD *)(result + 752);
  *(_DWORD *)(result + 752) = v4 | 1;
  switch(a4)
  {
    case 0:
      unsigned int v5 = v4 & 0xFFFFCFFE | 1;
      break;
    case 1:
      unsigned int v5 = v4 & 0xFFFFCFFE | 0x1001;
      break;
    case 2:
      unsigned int v5 = v4 & 0xFFFFCFFE | 0x2001;
      break;
    case 3:
      unsigned int v5 = v4 | 0x3001;
      break;
    default:
      ZinAssertImpl("Invalid Lossy Mode");
  }
  *(_DWORD *)(result + 752) = v5;
  if (a3 == 2)
  {
    unsigned int v6 = v5 | 4;
  }
  else
  {
    if (a3 != 1) {
      ZinAssertImpl("Unsupported macro block size");
    }
    unsigned int v6 = v5 & 0xFFFFFFFB;
  }
  *(_DWORD *)(result + 752) = v6;
  if ((a2 - 1) >= 0x13) {
    ZinAssertImpl("Invalid packing format");
  }
  *(_DWORD *)(result + 752) = v6 & 0xFFFFFC0F | dword_211F04368[a2 - 1];
  return result;
}

uint64_t ZinAneTd<19u>::SetTileDmaSrc2DataSetId(uint64_t result, char a2)
{
  *(unsigned char *)(result + 621) = a2;
  return result;
}

BOOL ZinAneTd<19u>::SetTileDmaSrc2CompressedSize(uint64_t a1, unsigned int a2, unsigned int a3)
{
  int v7 = 0;
  if (!ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1464) + 24), &v7)) {
    ZinAssertImpl("Illegal TileDmaSrc2 Compressed Width");
  }
  *(_DWORD *)(a1 + 756) = *(_DWORD *)(a1 + 756) & 0xFFFE0000 | v7 & 0x1FFFF;
  int v6 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a3, (unsigned int *)(*(void *)(a1 + 1464) + 16), &v6);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaSrc2 Compressed Height");
  }
  *(_DWORD *)(a1 + 76std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 760) & 0xFFFE0000 | v6 & 0x1FFFF;
  return result;
}

double ZinAneTd<19u>::SetTileDmaSrc2MetaData(uint64_t a1, uint64_t a2, uint64_t a3, unsigned int a4, unsigned int a5, int a6)
{
  ZinAneTdHw_v19::AddRelocInfo((uint64_t *)(a1 + 8), a2, 4946, a3, 1, 1, 0, 0);
  *(_DWORD *)(a1 + 752) &= ~8u;
  double result = COERCE_DOUBLE(__PAIR64__(a5, a4));
  *(int32x2_t *)(a1 + 708) = vsli_n_s32(*(int32x2_t *)(a1 + 708), (int32x2_t)__PAIR64__(a5, a4), 7uLL);
  *(_DWORD *)(a1 + 716) = *(_DWORD *)(a1 + 716) & 0x7F | (a6 << 7);
  return result;
}

uint64_t ZinAneTd<19u>::SetTileDmaDstFormat(uint64_t result, int a2, int a3)
{
  switch(a2)
  {
    case 1:
      unsigned int v3 = *(_DWORD *)(result + 1320) & 0xFFFFCFFC | 0x1000;
      goto LABEL_16;
    case 2:
      unsigned int v3 = *(_DWORD *)(result + 1320) & 0xFFFFCFFC;
      goto LABEL_16;
    case 3:
      unsigned int v4 = *(_DWORD *)(result + 1320) & 0xFFFFCFCC;
      int v5 = 8241;
      break;
    case 4:
      unsigned int v3 = *(_DWORD *)(result + 1320) & 0xFFFFCECC | 1;
      goto LABEL_16;
    case 5:
      unsigned int v4 = *(_DWORD *)(result + 1320) & 0xFFFFCECC;
      int v5 = 257;
      break;
    case 6:
      unsigned int v4 = *(_DWORD *)(result + 1320) & 0xFFFFCECC;
      int v5 = 17;
      break;
    case 7:
      unsigned int v4 = *(_DWORD *)(result + 1320) & 0xFFFFCECC;
      int v5 = 273;
      break;
    case 8:
      ZinAssertImpl("Packed10 format not supported");
    case 9:
      unsigned int v4 = *(_DWORD *)(result + 1320) & 0xFFFFCECC;
      if (!a3) {
        goto LABEL_14;
      }
      int v5 = 4401;
      break;
    case 10:
      unsigned int v4 = *(_DWORD *)(result + 1320) & 0xFFFFCECC;
      if (a3) {
        int v5 = 305;
      }
      else {
LABEL_14:
      }
        int v5 = 8497;
      break;
    case 11:
      unsigned int v4 = *(_DWORD *)(result + 1320) & 0xFFFFFFCF;
      int v5 = 12547;
      break;
    case 12:
      ZinAssertImpl("E4M3 is not supported");
    case 13:
      ZinAssertImpl("E5M2 is not supported");
    default:
      ZinAssertImpl("Invalid format provided");
  }
  unsigned int v3 = v4 | v5;
LABEL_16:
  *(_DWORD *)(result + 132std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = v3;
  return result;
}

BOOL ZinAneTd<19u>::SetTileDmaDstandL2DstInterleave(uint64_t a1, unsigned int a2)
{
  int v6 = 0;
  unint64_t v3 = a2;
  if (!ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1464) + 632), &v6)) {
    ZinAssertImpl("Illegal L2 Result Interleave");
  }
  *(_DWORD *)(a1 + 1028) = *(_DWORD *)(a1 + 1028) & 0xFFFFF0FF | ((v6 & 0xF) << 8);
  int v5 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(v3, (unsigned int *)(*(void *)(a1 + 1464) + 632), &v5);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaDst Interleave");
  }
  *(_DWORD *)(a1 + 132std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 1320) & 0xF0FFFFFF | ((v5 & 0xF) << 24);
  return result;
}

BOOL ZinAneTd<19u>::SetL2ResultInterleave(uint64_t a1, unsigned int a2)
{
  int v4 = 0;
  BOOL result = ZinCodegenUtil::ValueToRegister(a2, (unsigned int *)(*(void *)(a1 + 1464) + 632), &v4);
  if (!result) {
    ZinAssertImpl("Illegal L2 Result Interleave");
  }
  *(_DWORD *)(a1 + 1028) = *(_DWORD *)(a1 + 1028) & 0xFFFFF0FF | ((v4 & 0xF) << 8);
  return result;
}

uint64_t ZinAneTd<19u>::SetTileDmaDstandL2DstFifoMode(uint64_t result, int a2)
{
  unsigned int v2 = *(_DWORD *)(result + 1028) & 0xFFFFFFF7;
  if (a2) {
    int v3 = 0x1000000;
  }
  else {
    int v3 = 0;
  }
  unsigned int v4 = *(_DWORD *)(result + 1264) & 0xFEFFFFFF | v3;
  if (a2) {
    int v5 = 8;
  }
  else {
    int v5 = 0;
  }
  *(_DWORD *)(result + 1264) = v4;
  *(_DWORD *)(result + 1028) = v2 | v5;
  return result;
}

uint64_t ZinAneTd<19u>::SetTileDmaDstEnable(uint64_t result)
{
  *(_DWORD *)(result + 1264) |= 1u;
  return result;
}

uint64_t ZinAneTd<19u>::SetTileDmaDstCacheHint(uint64_t result, int a2)
{
  int v2 = 224;
  switch(a2)
  {
    case 0:
      goto LABEL_4;
    case 1:
      int v2 = 32;
      goto LABEL_4;
    case 2:
      ZinAssertImpl("Drop CacheHint not supported on Dst");
    case 3:
      int v2 = 192;
LABEL_4:
      *(_DWORD *)(result + 1264) = *(_DWORD *)(result + 1264) & 0xFFFFFF0F | v2;
      break;
    case 4:
      ZinAssertImpl("Invalid CacheHint");
    default:
      return result;
  }
  return result;
}

BOOL ZinAneTd<19u>::SetTileDmaDstChannelStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 1464) + 544), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaDst Channel Stride");
  }
  *(_DWORD *)(a1 + 1284) = *(_DWORD *)(a1 + 1284) & 0x3F | (v4 << 6);
  return result;
}

BOOL ZinAneTd<19u>::SetTileDmaDstRowStride(uint64_t a1, ZinCodegenUtil *a2)
{
  unsigned int v4 = 0;
  BOOL result = ZinCodegenUtil::SignedValueToRegister(a2, 0x1AuLL, (unsigned int *)(*(void *)(a1 + 1464) + 536), &v4);
  if (!result) {
    ZinAssertImpl("Illegal TileDmaDst Row Stride");
  }
  *(_DWORD *)(a1 + 128std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)&__p, 0) = *(_DWORD *)(a1 + 1280) & 0x3F | (v4 << 6);
  return result;
}