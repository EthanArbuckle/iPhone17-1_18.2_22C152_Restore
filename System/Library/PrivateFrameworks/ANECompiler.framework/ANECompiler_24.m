uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::InsertSliceOp>::~Model(uint64_t a1)
{
  void **v2;
  uint64_t v3;
  uint64_t v4;
  void **v5;
  void *v6;

  *(void *)a1 = &unk_26C361F50;
  v2 = *(void ***)(a1 + 32);
  v3 = *(unsigned int *)(a1 + 40);
  if (v3)
  {
    v4 = 16 * v3;
    v5 = v2 + 1;
    do
    {
      v6 = *v5;
      v5 += 2;
      free(v6);
      v4 -= 16;
    }
    while (v4);
    v2 = *(void ***)(a1 + 32);
  }
  if (v2 != (void **)(a1 + 48)) {
    free(v2);
  }
  return a1;
}

void mlir::RegisteredOperationName::Model<mlir::tensor::InsertSliceOp>::~Model(uint64_t a1)
{
  *(void *)a1 = &unk_26C361F50;
  v2 = *(void ***)(a1 + 32);
  uint64_t v3 = *(unsigned int *)(a1 + 40);
  if (v3)
  {
    uint64_t v4 = 16 * v3;
    v5 = v2 + 1;
    do
    {
      v6 = *v5;
      v5 += 2;
      free(v6);
      v4 -= 16;
    }
    while (v4);
    v2 = *(void ***)(a1 + 32);
  }
  if (v2 != (void **)(a1 + 48)) {
    free(v2);
  }

  JUMPOUT(0x21667D3C0);
}

BOOL mlir::RegisteredOperationName::Model<mlir::tensor::InsertSliceOp>::foldHook(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v15 = *MEMORY[0x263EF8340];
  unint64_t v14 = (unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &>::CallbacksHolder<mlir::Op<mlir::tensor::InsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1},mlir::Op<mlir::tensor::InsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1} const,void>::Callbacks
      + 2;
  BOOL v9 = (*(BOOL (**)(uint64_t, uint64_t, uint64_t, uint64_t, uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &>::CallbacksHolder<mlir::Op<mlir::tensor::InsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1},mlir::Op<mlir::tensor::InsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1} const,void>::Callbacks
                                                                            + 2) & 0xFFFFFFFFFFFFFFF8))((uint64_t)v13, a2, a3, a4, a5);
  char v10 = v14;
  if (v14 >= 8)
  {
    if ((v14 & 4) != 0)
    {
      if ((v14 & 2) != 0) {
        v11 = v13;
      }
      else {
        v11 = (llvm **)v13[0];
      }
      (*(void (**)(uint64_t, mlir::Operation *, uint64_t, uint64_t, uint64_t))((v14 & 0xFFFFFFFFFFFFFFF8) + 16))((uint64_t)v11, v5, v6, v7, v8);
    }
    if ((v10 & 2) == 0) {
      llvm::deallocate_buffer(v13[0], v13[1]);
    }
  }
  return v9;
}

void mlir::RegisteredOperationName::Model<mlir::tensor::InsertSliceOp>::getCanonicalizationPatterns()
{
}

BOOL mlir::RegisteredOperationName::Model<mlir::tensor::InsertSliceOp>::hasTrait(uint64_t a1, uint64_t a2)
{
  uint64_t v9 = *MEMORY[0x263EF8340];
  unint64_t v8 = (unint64_t)llvm::detail::UniqueFunctionBase<BOOL,mlir::TypeID>::CallbacksHolder<mlir::Op<mlir::tensor::InsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1},mlir::Op<mlir::tensor::InsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1} const,void>::Callbacks
     + 2;
  BOOL v3 = (*(BOOL (**)(uint64_t, uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<BOOL,mlir::TypeID>::CallbacksHolder<mlir::Op<mlir::tensor::InsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1},mlir::Op<mlir::tensor::InsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1} const,void>::Callbacks
                                                 + 2) & 0xFFFFFFFFFFFFFFF8))((uint64_t)v7, a2);
  char v4 = v8;
  if (v8 >= 8)
  {
    if ((v8 & 4) != 0)
    {
      if ((v8 & 2) != 0) {
        v5 = v7;
      }
      else {
        v5 = (llvm **)v7[0];
      }
      (*(void (**)(uint64_t, uint64_t))((v8 & 0xFFFFFFFFFFFFFFF8) + 16))((uint64_t)v5, v2);
    }
    if ((v4 & 2) == 0) {
      llvm::deallocate_buffer(v7[0], v7[1]);
    }
  }
  return v3;
}

void mlir::RegisteredOperationName::Model<mlir::tensor::InsertSliceOp>::getParseAssemblyFn(uint64_t (**a1)(uint64_t a1, uint64_t a2)@<X8>)
{
  *a1 = mlir::tensor::InsertSliceOp::parse;
  a1[3] = (uint64_t (*)(uint64_t, uint64_t))((char *)llvm::detail::UniqueFunctionBase<mlir::ParseResult,mlir::OpAsmParser &,mlir::OperationState &>::CallbacksHolder<mlir::ParseResult (*)(mlir::OpAsmParser &,mlir::OperationState &),mlir::ParseResult (*)(mlir::OpAsmParser &,mlir::OperationState &),void>::Callbacks
                                                   + 2);
}

void mlir::RegisteredOperationName::Model<mlir::tensor::InsertSliceOp>::printAssembly(uint64_t a1, uint64_t a2, mlir::OpAsmPrinter *a3, uint64_t a4, uint64_t a5)
{
  uint64_t v13 = *MEMORY[0x263EF8340];
  unint64_t v12 = (unint64_t)llvm::detail::UniqueFunctionBase<void,mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef>::CallbacksHolder<mlir::Op<mlir::tensor::InsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1},mlir::Op<mlir::tensor::InsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1} const,void>::Callbacks
      + 2;
  (*(void (**)(uint64_t, uint64_t, mlir::OpAsmPrinter *, uint64_t, uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<void,mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef>::CallbacksHolder<mlir::Op<mlir::tensor::InsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1},mlir::Op<mlir::tensor::InsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1} const,void>::Callbacks
                                                                                    + 2) & 0xFFFFFFFFFFFFFFF8))((uint64_t)v11, a2, a3, a4, a5);
  char v9 = v12;
  if (v12 >= 8)
  {
    if ((v12 & 4) != 0)
    {
      if ((v12 & 2) != 0) {
        char v10 = v11;
      }
      else {
        char v10 = (llvm **)v11[0];
      }
      (*(void (**)(uint64_t, mlir::Operation *, mlir::OpAsmPrinter *, uint64_t, uint64_t))((v12 & 0xFFFFFFFFFFFFFFF8)
                                                                                                 + 16))((uint64_t)v10, v5, v6, v7, v8);
    }
    if ((v9 & 2) == 0) {
      llvm::deallocate_buffer(v11[0], v11[1]);
    }
  }
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::InsertSliceOp>::verifyInvariants(uint64_t a1, uint64_t a2)
{
  uint64_t v7 = *MEMORY[0x263EF8340];
  v5[0] = (uint64_t (*)(uint64_t))mlir::Op<mlir::tensor::InsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::verifyInvariants;
  unint64_t v6 = (unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *>::CallbacksHolder<mlir::LogicalResult (*)(mlir::Operation *),mlir::LogicalResult (* const)(mlir::Operation *),void>::Callbacks
     + 2;
  uint64_t v2 = (*(uint64_t (**)(uint64_t (**)(uint64_t), uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *>::CallbacksHolder<mlir::LogicalResult (*)(mlir::Operation *),mlir::LogicalResult (* const)(mlir::Operation *),void>::Callbacks
                                                                             + 2) & 0xFFFFFFFFFFFFFFF8))(v5, a2);
  char v3 = v6;
  if (v6 >= 8)
  {
    if ((v6 & 4) != 0) {
      (*(void (__cdecl **)())((v6 & 0xFFFFFFFFFFFFFFF8) + 16))();
    }
    if ((v3 & 2) == 0) {
      llvm::deallocate_buffer((llvm *)v5[0], v5[1]);
    }
  }
  return v2;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::InsertSliceOp>::verifyRegionInvariants(uint64_t a1, uint64_t a2)
{
  uint64_t v7 = *MEMORY[0x263EF8340];
  v5[0] = (uint64_t (*)(uint64_t))mlir::Op<mlir::tensor::InsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::verifyRegionInvariants;
  unint64_t v6 = (unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *>::CallbacksHolder<mlir::LogicalResult (*)(mlir::Operation *),mlir::LogicalResult (* const)(mlir::Operation *),void>::Callbacks
     + 2;
  uint64_t v2 = (*(uint64_t (**)(uint64_t (**)(uint64_t), uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *>::CallbacksHolder<mlir::LogicalResult (*)(mlir::Operation *),mlir::LogicalResult (* const)(mlir::Operation *),void>::Callbacks
                                                                             + 2) & 0xFFFFFFFFFFFFFFF8))(v5, a2);
  char v3 = v6;
  if (v6 >= 8)
  {
    if ((v6 & 4) != 0) {
      (*(void (__cdecl **)())((v6 & 0xFFFFFFFFFFFFFFF8) + 16))();
    }
    if ((v3 & 2) == 0) {
      llvm::deallocate_buffer((llvm *)v5[0], v5[1]);
    }
  }
  return v2;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::InsertSliceOp>::getInherentAttr(uint64_t a1, uint64_t a2, char *a3, size_t a4)
{
  Context = (mlir::MLIRContext *)mlir::Attribute::getContext((mlir::Attribute *)(a2 + 24));
  if (HIBYTE(*(_DWORD *)(a2 + 44))) {
    uint64_t v8 = (uint64_t *)(a2 + 16 * (((unint64_t)*(unsigned int *)(a2 + 44) >> 23) & 1) + 64);
  }
  else {
    uint64_t v8 = 0;
  }

  return mlir::tensor::InsertSliceOp::getInherentAttr(Context, v8, a3, a4);
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::InsertSliceOp>::setInherentAttr(uint64_t a1, uint64_t a2, uint64_t a3, void *a4)
{
  uint64_t v9 = a3;
  if (HIBYTE(*(_DWORD *)(a2 + 44))) {
    uint64_t v5 = a2 + 16 * (((unint64_t)*(unsigned int *)(a2 + 44) >> 23) & 1) + 64;
  }
  else {
    uint64_t v5 = 0;
  }
  AttrData = (char *)mlir::OpaqueAttr::getAttrData((mlir::OpaqueAttr *)&v9);
  return mlir::tensor::InsertSliceOp::setInherentAttr(v5, AttrData, v7, a4);
}

void mlir::RegisteredOperationName::Model<mlir::tensor::InsertSliceOp>::populateInherentAttrs(uint64_t a1, uint64_t a2, uint64_t a3)
{
  Context = (mlir::MLIRContext *)mlir::Attribute::getContext((mlir::Attribute *)(a2 + 24));
  if (HIBYTE(*(_DWORD *)(a2 + 44))) {
    unint64_t v6 = (uint64_t *)(a2 + 16 * (((unint64_t)*(unsigned int *)(a2 + 44) >> 23) & 1) + 64);
  }
  else {
    unint64_t v6 = 0;
  }

  mlir::tensor::InsertSliceOp::populateInherentAttrs(Context, v6, a3);
}

BOOL mlir::RegisteredOperationName::Model<mlir::tensor::InsertSliceOp>::verifyInherentAttrs(uint64_t a1, uint64_t a2, uint64_t a3, void (*a4)(uint64_t *__return_ptr, uint64_t), uint64_t a5)
{
  return mlir::memref::ReinterpretCastOp::verifyInherentAttrs(a2, a3, a4, a5);
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::InsertSliceOp>::getOpPropertyByteSize()
{
  return 48;
}

double mlir::RegisteredOperationName::Model<mlir::tensor::InsertSliceOp>::initProperties(uint64_t a1, uint64_t a2, _OWORD *a3, long long *a4)
{
  if (a4)
  {
    long long v4 = *a4;
    long long v5 = a4[2];
    a3[1] = a4[1];
    a3[2] = v5;
    *a3 = v4;
  }
  else
  {
    *(void *)&long long v4 = 0;
    a3[1] = 0u;
    a3[2] = 0u;
    *a3 = 0u;
  }
  return *(double *)&v4;
}

BOOL mlir::RegisteredOperationName::Model<mlir::tensor::InsertSliceOp>::setPropertiesFromAttr(uint64_t a1, uint64_t a2, uint64_t *a3, uint64_t a4, void (*a5)(uint64_t *__return_ptr, uint64_t), uint64_t a6)
{
  return mlir::tensor::InsertSliceOp::setPropertiesFromAttr(a3, a4, a5, a6);
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::InsertSliceOp>::getPropertiesAsAttr(uint64_t a1, uint64_t a2)
{
  Context = (mlir::DictionaryAttr *)mlir::Attribute::getContext((mlir::Attribute *)(a2 + 24));
  if (HIBYTE(*(_DWORD *)(a2 + 44))) {
    long long v4 = (uint64_t *)(a2 + 16 * (((unint64_t)*(unsigned int *)(a2 + 44) >> 23) & 1) + 64);
  }
  else {
    long long v4 = 0;
  }

  return mlir::tensor::InsertSliceOp::getPropertiesAsAttr(Context, v4);
}

__n128 mlir::RegisteredOperationName::Model<mlir::tensor::InsertSliceOp>::copyProperties(uint64_t a1, uint64_t a2, uint64_t a3)
{
  __n128 result = *(__n128 *)a3;
  long long v4 = *(_OWORD *)(a3 + 16);
  *(_OWORD *)(a2 + 28) = *(_OWORD *)(a3 + 28);
  *(__n128 *)a2 = result;
  *(_OWORD *)(a2 + 16) = v4;
  return result;
}

BOOL mlir::RegisteredOperationName::Model<mlir::tensor::InsertSliceOp>::compareProperties(uint64_t a1, uint64_t a2, uint64_t a3)
{
  if (*(void *)a3 != *(void *)a2) {
    return 0;
  }
  if (*(void *)(a3 + 8) != *(void *)(a2 + 8)) {
    return 0;
  }
  if (*(void *)(a3 + 16) != *(void *)(a2 + 16)) {
    return 0;
  }
  return *(void *)(a3 + 24) == *(void *)(a2 + 24)
      && *(void *)(a3 + 32) == *(void *)(a2 + 32)
      && *(_DWORD *)(a3 + 40) == (unint64_t)*(unsigned int *)(a2 + 40);
}

unint64_t mlir::RegisteredOperationName::Model<mlir::tensor::InsertSliceOp>::hashProperties(uint64_t a1, unint64_t *a2)
{
  return mlir::tensor::InsertSliceOp::computePropertiesHash(a2);
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::BytecodeOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(0x10uLL, 0x80040803F642BuLL);
  *uint64_t v2 = mlir::detail::BytecodeOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::readProperties;
  v2[1] = mlir::detail::BytecodeOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::writeProperties;
  char v3 = &unk_267771000;
  {
    unint64_t v12 = v2;
    char v3 = (void *)&unk_267771000;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::BytecodeOpInterface]";
      unint64_t v14 = 75;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      size_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::BytecodeOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      char v3 = (void *)&unk_267771000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[312], v2);
}

uint64_t mlir::detail::BytecodeOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::writeProperties(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = a2;
  return mlir::tensor::InsertSliceOp::writeProperties((uint64_t)&v4, a3);
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(0x20uLL, 0x8004018A671A6uLL);
  *uint64_t v2 = mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getAsmResultNames;
  v2[1] = mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getAsmBlockArgumentNames;
  v2[2] = mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getAsmBlockNames;
  v2[3] = mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getDefaultDialect;
  char v3 = &unk_267771000;
  {
    unint64_t v12 = v2;
    char v3 = (void *)&unk_267771000;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpAsmOpInterface]";
      unint64_t v14 = 72;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      size_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::OpAsmOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      char v3 = (void *)&unk_267771000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[346], v2);
}

uint64_t mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getAsmResultNames(uint64_t a1, uint64_t a2, uint64_t (*a3)(uint64_t, uint64_t, const char *, uint64_t), uint64_t a4)
{
  uint64_t v5 = a2;
  return mlir::tensor::InsertSliceOp::getAsmResultNames((uint64_t)&v5, a3, a4);
}

char *mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getDefaultDialect()
{
  return &byte_211F4AA5D;
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::ReifyRankedShapedTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(8uLL, 0x80040B8603338uLL);
  *uint64_t v2 = mlir::detail::ReifyRankedShapedTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::reifyResultShapes;
  char v3 = &unk_267772000;
  {
    unint64_t v12 = v2;
    char v3 = (void *)&unk_267772000;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ReifyRankedShapedTypeOpInterface]";
      unint64_t v14 = 88;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      size_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::ReifyRankedShapedTypeOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      char v3 = (void *)&unk_267772000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[181], v2);
}

uint64_t mlir::detail::ReifyRankedShapedTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::reifyResultShapes(uint64_t a1, uint64_t a2, mlir::IndexType **a3, uint64_t a4)
{
  uint64_t v5 = a2;
  return mlir::tensor::InsertSliceOp::reifyResultShapes((uint64_t)&v5, a3, a4);
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::DestinationStyleOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(8uLL, 0x80040B8603338uLL);
  *uint64_t v2 = mlir::detail::DestinationStyleOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getDpsInitsMutable;
  char v3 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
  {
    unint64_t v12 = v2;
    char v3 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::DestinationStyleOpInterface]";
      unint64_t v14 = 83;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      size_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::DestinationStyleOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      char v3 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[134], v2);
}

mlir::MutableOperandRange *mlir::detail::DestinationStyleOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getDpsInitsMutable@<X0>(uint64_t a1@<X1>, mlir::MutableOperandRange *a2@<X8>)
{
  uint64_t v5 = a1;
  DestMutable = (mlir::OpOperand *)mlir::tensor::InsertSliceOp::getDestMutable((mlir::tensor::InsertSliceOp *)&v5);
  return mlir::MutableOperandRange::MutableOperandRange(a2, DestMutable);
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::ConditionallySpeculatableInterfaceTraits::Model<mlir::tensor::InsertSliceOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(8uLL, 0x80040B8603338uLL);
  *uint64_t v2 = mlir::detail::ConditionallySpeculatableInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getSpeculatability;
  char v3 = &unk_267771000;
  {
    unint64_t v12 = v2;
    char v3 = (void *)&unk_267771000;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ConditionallySpeculatable]";
      unint64_t v14 = 81;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      size_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::ConditionallySpeculatable,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      char v3 = (void *)&unk_267771000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[314], v2);
}

uint64_t mlir::detail::ConditionallySpeculatableInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getSpeculatability()
{
  return 1;
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::MemoryEffectOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(8uLL, 0x80040B8603338uLL);
  *uint64_t v2 = mlir::detail::MemoryEffectOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getEffects;
  char v3 = &unk_267771000;
  {
    unint64_t v12 = v2;
    char v3 = (void *)&unk_267771000;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::MemoryEffectOpInterface]";
      unint64_t v14 = 79;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      size_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::MemoryEffectOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      char v3 = (void *)&unk_267771000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[11], v2);
}

void mlir::detail::MemoryEffectOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getEffects(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = a2;
  ZinIrHalH13g::~ZinIrHalH13g((ZinIrHalH13g *)&v2);
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(0xD0uLL, 0x80040B342C78EuLL);
  *uint64_t v2 = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getOffsetSizeAndStrideStartOperandIndex;
  v2[1] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getArrayAttrMaxRanks;
  v2[2] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getOffsets;
  v2[3] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getSizes;
  v2[4] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getStrides;
  v2[5] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getStaticOffsets;
  v2[6] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getStaticSizes;
  v2[7] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getStaticStrides;
  v2[8] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getMixedOffsets;
  v2[9] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getMixedSizes;
  v2[10] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getMixedStrides;
  v2[11] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::isDynamicOffset;
  v2[12] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::isDynamicSize;
  v2[13] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::isDynamicStride;
  v2[14] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getStaticOffset;
  v2[15] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getStaticSize;
  v2[16] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getStaticStride;
  v2[17] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getIndexOfDynamicOffset;
  v2[18] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getIndexOfDynamicSize;
  v2[19] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getIndexOfDynamicStride;
  v2[20] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getDynamicOffset;
  v2[21] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getDynamicSize;
  v2[22] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getDynamicStride;
  v2[23] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::isSameAs;
  v2[24] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::hasUnitStride;
  v2[25] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::hasZeroOffset;
  char v3 = &unk_267772000;
  {
    unint64_t v12 = v2;
    char v3 = (void *)&unk_267772000;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OffsetSizeAndStrideOpInterface]";
      unint64_t v14 = 86;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      size_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::OffsetSizeAndStrideOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      char v3 = (void *)&unk_267772000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[269], v2);
}

uint64_t mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getOffsetSizeAndStrideStartOperandIndex()
{
  return 2;
}

unint64_t mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getArrayAttrMaxRanks(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = a2;
  unint64_t v5 = *(void *)(mlir::anec::Convolution::getResult((mlir::anec::Convolution *)&v4) + 8) & 0xFFFFFFFFFFFFFFF8;
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v5);
  return v2 | ((unint64_t)v2 << 32);
}

uint64_t mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getOffsets(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = a2;
  return mlir::memref::ReinterpretCastOp::getSizes((mlir::memref::ReinterpretCastOp *)&v3);
}

uint64_t mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getSizes(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = a2;
  return mlir::memref::ReinterpretCastOp::getStrides((mlir::memref::ReinterpretCastOp *)&v3);
}

uint64_t mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getStrides(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = a2;
  return mlir::tensor::InsertSliceOp::getStrides((mlir::tensor::InsertSliceOp *)&v3);
}

uint64_t mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getStaticOffsets(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = a2;
  return mlir::memref::ReinterpretCastOp::getStaticOffsets((mlir::memref::ReinterpretCastOp *)&v3);
}

uint64_t mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getStaticSizes(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = a2;
  return mlir::memref::ReinterpretCastOp::getStaticSizes((mlir::memref::ReinterpretCastOp *)&v3);
}

uint64_t mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getStaticStrides(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = a2;
  return mlir::memref::ReinterpretCastOp::getStaticStrides((mlir::memref::ReinterpretCastOp *)&v3);
}

void mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getMixedOffsets(uint64_t a1@<X1>, uint64_t a2@<X8>)
{
  uint64_t v2 = a1;
  mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::tensor::InsertSliceOp>::getMixedOffsets((mlir::memref::ReinterpretCastOp *)&v2, a2);
}

void mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getMixedSizes(uint64_t a1@<X1>, uint64_t a2@<X8>)
{
  uint64_t v2 = a1;
  mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::tensor::InsertSliceOp>::getMixedSizes((mlir::memref::ReinterpretCastOp *)&v2, a2);
}

void mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getMixedStrides(uint64_t a1@<X1>, uint64_t a2@<X8>)
{
  uint64_t v2 = a1;
  mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::tensor::InsertSliceOp>::getMixedStrides((mlir::memref::ReinterpretCastOp *)&v2, a2);
}

BOOL mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::isDynamicOffset(uint64_t a1, uint64_t a2, unsigned int a3)
{
  uint64_t v4 = a2;
  return *(void *)(mlir::memref::ReinterpretCastOp::getStaticOffsets((mlir::memref::ReinterpretCastOp *)&v4) + 8 * a3) == 0x8000000000000000;
}

BOOL mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::isDynamicSize(uint64_t a1, uint64_t a2, unsigned int a3)
{
  uint64_t v4 = a2;
  return *(void *)(mlir::memref::ReinterpretCastOp::getStaticSizes((mlir::memref::ReinterpretCastOp *)&v4) + 8 * a3) == 0x8000000000000000;
}

BOOL mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::isDynamicStride(uint64_t a1, uint64_t a2, unsigned int a3)
{
  uint64_t v4 = a2;
  return *(void *)(mlir::memref::ReinterpretCastOp::getStaticStrides((mlir::memref::ReinterpretCastOp *)&v4) + 8 * a3) == 0x8000000000000000;
}

uint64_t mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getStaticOffset(uint64_t a1, uint64_t a2, unsigned int a3)
{
  uint64_t v4 = a2;
  return *(void *)(mlir::memref::ReinterpretCastOp::getStaticOffsets((mlir::memref::ReinterpretCastOp *)&v4) + 8 * a3);
}

uint64_t mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getStaticSize(uint64_t a1, uint64_t a2, unsigned int a3)
{
  uint64_t v4 = a2;
  return *(void *)(mlir::memref::ReinterpretCastOp::getStaticSizes((mlir::memref::ReinterpretCastOp *)&v4) + 8 * a3);
}

uint64_t mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getStaticStride(uint64_t a1, uint64_t a2, unsigned int a3)
{
  uint64_t v4 = a2;
  return *(void *)(mlir::memref::ReinterpretCastOp::getStaticStrides((mlir::memref::ReinterpretCastOp *)&v4) + 8 * a3);
}

uint64_t mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getIndexOfDynamicOffset(uint64_t a1, uint64_t a2, unsigned int a3)
{
  uint64_t v7 = a2;
  StaticOffsets = (int64x2_t *)mlir::memref::ReinterpretCastOp::getStaticOffsets((mlir::memref::ReinterpretCastOp *)&v7);
  return mlir::detail::getNumDynamicEntriesUpToIdx(StaticOffsets, v5, a3) + 2;
}

uint64_t mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getIndexOfDynamicSize(uint64_t a1, uint64_t a2, unsigned int a3)
{
  uint64_t v9 = a2;
  StaticSizes = (int64x2_t *)mlir::memref::ReinterpretCastOp::getStaticSizes((mlir::memref::ReinterpretCastOp *)&v9);
  int NumDynamicEntriesUpToIdx = mlir::detail::getNumDynamicEntriesUpToIdx(StaticSizes, v5, a3);
  mlir::memref::ReinterpretCastOp::getSizes((mlir::memref::ReinterpretCastOp *)&v9);
  return (NumDynamicEntriesUpToIdx + v7 + 2);
}

uint64_t mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getIndexOfDynamicStride(uint64_t a1, uint64_t a2, unsigned int a3)
{
  uint64_t v11 = a2;
  StaticStrides = (int64x2_t *)mlir::memref::ReinterpretCastOp::getStaticStrides((mlir::memref::ReinterpretCastOp *)&v11);
  int NumDynamicEntriesUpToIdx = mlir::detail::getNumDynamicEntriesUpToIdx(StaticStrides, v5, a3);
  mlir::memref::ReinterpretCastOp::getSizes((mlir::memref::ReinterpretCastOp *)&v11);
  int v8 = v7;
  mlir::memref::ReinterpretCastOp::getStrides((mlir::memref::ReinterpretCastOp *)&v11);
  return (v8 + v9 + NumDynamicEntriesUpToIdx + 2);
}

uint64_t mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getDynamicOffset(uint64_t a1, uint64_t a2, unsigned int a3)
{
  uint64_t v8 = a2;
  StaticOffsets = (int64x2_t *)mlir::memref::ReinterpretCastOp::getStaticOffsets((mlir::memref::ReinterpretCastOp *)&v8);
  int NumDynamicEntriesUpToIdx = mlir::detail::getNumDynamicEntriesUpToIdx(StaticOffsets, v5, a3);
  return *(void *)(*(void *)(v8 + 72) + 32 * (NumDynamicEntriesUpToIdx + 2) + 24);
}

uint64_t mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getDynamicSize(uint64_t a1, uint64_t a2, unsigned int a3)
{
  uint64_t v9 = a2;
  StaticSizes = (int64x2_t *)mlir::memref::ReinterpretCastOp::getStaticSizes((mlir::memref::ReinterpretCastOp *)&v9);
  int NumDynamicEntriesUpToIdx = mlir::detail::getNumDynamicEntriesUpToIdx(StaticSizes, v5, a3);
  mlir::memref::ReinterpretCastOp::getSizes((mlir::memref::ReinterpretCastOp *)&v9);
  return *(void *)(*(void *)(v9 + 72) + 32 * (NumDynamicEntriesUpToIdx + v7 + 2) + 24);
}

uint64_t mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::getDynamicStride(uint64_t a1, uint64_t a2, unsigned int a3)
{
  uint64_t v11 = a2;
  StaticStrides = (int64x2_t *)mlir::memref::ReinterpretCastOp::getStaticStrides((mlir::memref::ReinterpretCastOp *)&v11);
  int NumDynamicEntriesUpToIdx = mlir::detail::getNumDynamicEntriesUpToIdx(StaticStrides, v5, a3);
  mlir::memref::ReinterpretCastOp::getSizes((mlir::memref::ReinterpretCastOp *)&v11);
  int v8 = v7;
  mlir::memref::ReinterpretCastOp::getStrides((mlir::memref::ReinterpretCastOp *)&v11);
  return *(void *)(*(void *)(v11 + 72) + 32 * (v8 + v9 + NumDynamicEntriesUpToIdx + 2) + 24);
}

uint64_t mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::isSameAs(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t (*a5)(uint64_t, void, void), uint64_t a6)
{
  uint64_t v7 = a2;
  return mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::memref::ReinterpretCastOp>::isSameAs(&v7, a3, a4, a5, a6);
}

uint64_t mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::hasUnitStride(uint64_t a1, uint64_t a2)
{
  v14[4] = *MEMORY[0x263EF8340];
  uint64_t v11 = a2;
  mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::tensor::InsertSliceOp>::getMixedStrides((mlir::memref::ReinterpretCastOp *)&v11, (uint64_t)&v12);
  uint64_t v2 = (uint64_t *)v12;
  if (!v13)
  {
    uint64_t v8 = 1;
    if (v12 == v14) {
      return v8;
    }
    goto LABEL_15;
  }
  uint64_t v3 = 8 * v13 - 8;
  do
  {
    uint64_t v4 = *v2++;
    unint64_t ConstantIntValue = mlir::getConstantIntValue(v4);
    if (v6) {
      BOOL v7 = ConstantIntValue == 1;
    }
    else {
      BOOL v7 = 0;
    }
    uint64_t v8 = v7;
    BOOL v9 = v8 != 1 || v3 == 0;
    v3 -= 8;
  }
  while (!v9);
  uint64_t v2 = (uint64_t *)v12;
  if (v12 != v14) {
LABEL_15:
  }
    free(v2);
  return v8;
}

uint64_t mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::hasZeroOffset(uint64_t a1, uint64_t a2)
{
  v14[4] = *MEMORY[0x263EF8340];
  uint64_t v11 = a2;
  mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::tensor::InsertSliceOp>::getMixedOffsets((mlir::memref::ReinterpretCastOp *)&v11, (uint64_t)&v12);
  uint64_t v2 = (uint64_t *)v12;
  if (!v13)
  {
    uint64_t v8 = 1;
    if (v12 == v14) {
      return v8;
    }
    goto LABEL_15;
  }
  uint64_t v3 = 8 * v13 - 8;
  do
  {
    uint64_t v4 = *v2++;
    unint64_t ConstantIntValue = mlir::getConstantIntValue(v4);
    if (v6) {
      BOOL v7 = ConstantIntValue == 0;
    }
    else {
      BOOL v7 = 0;
    }
    uint64_t v8 = v7;
    BOOL v9 = v8 != 1 || v3 == 0;
    v3 -= 8;
  }
  while (!v9);
  uint64_t v2 = (uint64_t *)v12;
  if (v12 != v14) {
LABEL_15:
  }
    free(v2);
  return v8;
}

void mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::tensor::InsertSliceOp>::getMixedOffsets(mlir::memref::ReinterpretCastOp *a1@<X0>, uint64_t a2@<X8>)
{
  v18[6] = *MEMORY[0x263EF8340];
  uint64_t Context = mlir::Attribute::getContext((mlir::Attribute *)(*(void *)a1 + 24));
  StaticOffsets = (uint64_t *)mlir::memref::ReinterpretCastOp::getStaticOffsets(a1);
  unint64_t v6 = v5;
  uint64_t Sizes = mlir::memref::ReinterpretCastOp::getSizes(a1);
  mlir::ValueRange::ValueRange(v14, Sizes, v8);
  mlir::getMixedValues(StaticOffsets, v6, v14[0], v14[1], (mlir::Builder *)&Context, (uint64_t)&__src);
  *(void *)a2 = a2 + 16;
  *(void *)(a2 + 8) = 0x400000000;
  unsigned int v9 = v16;
  unint64_t v10 = __src;
  if (v16 && &__src != (void **)a2)
  {
    if (__src == v18)
    {
      unsigned int v12 = v16;
      if (v16 < 5
        || (llvm::SmallVectorBase<unsigned int>::grow_pod(a2, (void *)(a2 + 16), v16, 8), v12 = v16, unint64_t v10 = __src, v16))
      {
        memcpy(*(void **)a2, v10, 8 * v12);
        unint64_t v10 = __src;
      }
      *(_DWORD *)(a2 + 8) = v9;
    }
    else
    {
      *(void *)a2 = __src;
      int v11 = v17;
      *(_DWORD *)(a2 + 8) = v9;
      *(_DWORD *)(a2 + 12) = v11;
      __src = v18;
      int v17 = 0;
      unint64_t v10 = v18;
    }
    unsigned int v16 = 0;
  }
  if (v10 != v18) {
    free(v10);
  }
}

void mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::tensor::InsertSliceOp>::getMixedSizes(mlir::memref::ReinterpretCastOp *a1@<X0>, uint64_t a2@<X8>)
{
  v18[6] = *MEMORY[0x263EF8340];
  uint64_t Context = mlir::Attribute::getContext((mlir::Attribute *)(*(void *)a1 + 24));
  Staticuint64_t Sizes = (uint64_t *)mlir::memref::ReinterpretCastOp::getStaticSizes(a1);
  unint64_t v6 = v5;
  uint64_t Strides = mlir::memref::ReinterpretCastOp::getStrides(a1);
  mlir::ValueRange::ValueRange(v14, Strides, v8);
  mlir::getMixedValues(StaticSizes, v6, v14[0], v14[1], (mlir::Builder *)&Context, (uint64_t)&__src);
  *(void *)a2 = a2 + 16;
  *(void *)(a2 + 8) = 0x400000000;
  unsigned int v9 = v16;
  unint64_t v10 = __src;
  if (v16 && &__src != (void **)a2)
  {
    if (__src == v18)
    {
      unsigned int v12 = v16;
      if (v16 < 5
        || (llvm::SmallVectorBase<unsigned int>::grow_pod(a2, (void *)(a2 + 16), v16, 8), v12 = v16, unint64_t v10 = __src, v16))
      {
        memcpy(*(void **)a2, v10, 8 * v12);
        unint64_t v10 = __src;
      }
      *(_DWORD *)(a2 + 8) = v9;
    }
    else
    {
      *(void *)a2 = __src;
      int v11 = v17;
      *(_DWORD *)(a2 + 8) = v9;
      *(_DWORD *)(a2 + 12) = v11;
      __src = v18;
      int v17 = 0;
      unint64_t v10 = v18;
    }
    unsigned int v16 = 0;
  }
  if (v10 != v18) {
    free(v10);
  }
}

void mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::tensor::InsertSliceOp>::getMixedStrides(mlir::memref::ReinterpretCastOp *a1@<X0>, uint64_t a2@<X8>)
{
  v18[6] = *MEMORY[0x263EF8340];
  uint64_t Context = mlir::Attribute::getContext((mlir::Attribute *)(*(void *)a1 + 24));
  Staticuint64_t Strides = (uint64_t *)mlir::memref::ReinterpretCastOp::getStaticStrides(a1);
  unint64_t v6 = v5;
  uint64_t Strides = mlir::tensor::InsertSliceOp::getStrides(a1);
  mlir::ValueRange::ValueRange(v14, Strides, v8);
  mlir::getMixedValues(StaticStrides, v6, v14[0], v14[1], (mlir::Builder *)&Context, (uint64_t)&__src);
  *(void *)a2 = a2 + 16;
  *(void *)(a2 + 8) = 0x400000000;
  unsigned int v9 = v16;
  unint64_t v10 = __src;
  if (v16 && &__src != (void **)a2)
  {
    if (__src == v18)
    {
      unsigned int v12 = v16;
      if (v16 < 5
        || (llvm::SmallVectorBase<unsigned int>::grow_pod(a2, (void *)(a2 + 16), v16, 8), v12 = v16, unint64_t v10 = __src, v16))
      {
        memcpy(*(void **)a2, v10, 8 * v12);
        unint64_t v10 = __src;
      }
      *(_DWORD *)(a2 + 8) = v9;
    }
    else
    {
      *(void *)a2 = __src;
      int v11 = v17;
      *(_DWORD *)(a2 + 8) = v9;
      *(_DWORD *)(a2 + 12) = v11;
      __src = v18;
      int v17 = 0;
      unint64_t v10 = v18;
    }
    unsigned int v16 = 0;
  }
  if (v10 != v18) {
    free(v10);
  }
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::InferTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(0x18uLL, 0x80040D6874129uLL);
  *uint64_t v2 = mlir::detail::InferTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::inferReturnTypes;
  v2[1] = mlir::detail::InferTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::refineReturnTypes;
  v2[2] = mlir::detail::InferTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::isCompatibleReturnTypes;
  uint64_t v3 = &unk_267771000;
  {
    unsigned int v12 = v2;
    uint64_t v3 = (void *)&unk_267771000;
    uint64_t v2 = v12;
    if (v4)
    {
      unsigned int v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::InferTypeOpInterface]";
      unint64_t v14 = 76;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      BOOL v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::InferTypeOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      uint64_t v3 = (void *)&unk_267771000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[17], v2);
}

uint64_t mlir::detail::InferTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::inferReturnTypes(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11)
{
  return mlir::tensor::InsertOp::inferReturnTypes(a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, a11);
}

uint64_t mlir::detail::InferTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::refineReturnTypes(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11)
{
  return mlir::detail::InferTypeOpInterfaceTrait<mlir::tensor::InsertSliceOp>::refineReturnTypes(a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, a11);
}

BOOL mlir::detail::InferTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::InsertSliceOp>::isCompatibleReturnTypes(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return a2 == a4
      && std::__equal_impl[abi:nn180100]<llvm::detail::indexed_accessor_range_base<mlir::TypeRange,llvm::PointerUnion<mlir::Value const*,mlir::Type const*,mlir::OpOperand *,mlir::detail::OpResultImpl *>,mlir::Type,mlir::Type,mlir::Type>::iterator,llvm::detail::indexed_accessor_range_base<mlir::TypeRange,llvm::PointerUnion<mlir::Value const*,mlir::Type const*,mlir::OpOperand *,mlir::detail::OpResultImpl *>,mlir::Type,mlir::Type,mlir::Type>::iterator,llvm::detail::indexed_accessor_range_base<mlir::TypeRange,llvm::PointerUnion<mlir::Value const*,mlir::Type const*,mlir::OpOperand *,mlir::detail::OpResultImpl *>,mlir::Type,mlir::Type,mlir::Type>::iterator,llvm::detail::indexed_accessor_range_base<mlir::TypeRange,llvm::PointerUnion<mlir::Value const*,mlir::Type const*,mlir::OpOperand *,mlir::detail::OpResultImpl *>,mlir::Type,mlir::Type,mlir::Type>::iterator,std::__equal_to,std::__identity,std::__identity>(a1, 0, a1, a2, a3, 0, a3, a2);
}

uint64_t mlir::detail::InferTypeOpInterfaceTrait<mlir::tensor::InsertSliceOp>::refineReturnTypes(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11)
{
  char v11 = a3;
  v22[4] = *MEMORY[0x263EF8340];
  v20 = v22;
  uint64_t v21 = 0x400000000;
  if (!mlir::tensor::InsertOp::inferReturnTypes(a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, (uint64_t)&v20))
  {
    uint64_t v13 = 0;
    unint64_t v14 = v20;
    if (v20 == v22) {
      return v13;
    }
    goto LABEL_7;
  }
  mlir::ValueRange::ValueRange((unint64_t *)&v18, (uint64_t)v20, v21);
  mlir::ValueRange::ValueRange(v17, *(void *)a11, *(unsigned int *)(a11 + 8));
  if (v19 == v17[1]
    && std::__equal_impl[abi:nn180100]<llvm::detail::indexed_accessor_range_base<mlir::TypeRange,llvm::PointerUnion<mlir::Value const*,mlir::Type const*,mlir::OpOperand *,mlir::detail::OpResultImpl *>,mlir::Type,mlir::Type,mlir::Type>::iterator,llvm::detail::indexed_accessor_range_base<mlir::TypeRange,llvm::PointerUnion<mlir::Value const*,mlir::Type const*,mlir::OpOperand *,mlir::detail::OpResultImpl *>,mlir::Type,mlir::Type,mlir::Type>::iterator,llvm::detail::indexed_accessor_range_base<mlir::TypeRange,llvm::PointerUnion<mlir::Value const*,mlir::Type const*,mlir::OpOperand *,mlir::detail::OpResultImpl *>,mlir::Type,mlir::Type,mlir::Type>::iterator,llvm::detail::indexed_accessor_range_base<mlir::TypeRange,llvm::PointerUnion<mlir::Value const*,mlir::Type const*,mlir::OpOperand *,mlir::detail::OpResultImpl *>,mlir::Type,mlir::Type,mlir::Type>::iterator,std::__equal_to,std::__identity,std::__identity>(v18, 0, v18, v19, v17[0], 0, v17[0], v19))
  {
    uint64_t v13 = 1;
    unint64_t v14 = v20;
    if (v20 == v22) {
      return v13;
    }
    goto LABEL_7;
  }
  v16[0] = "tensor.insert_slice";
  v16[1] = 19;
  uint64_t v13 = mlir::emitOptionalError<char const(&)[2],llvm::StringLiteral,char const(&)[23],llvm::SmallVector<mlir::Type,4u> &,char const(&)[52],llvm::SmallVectorImpl<mlir::Type> &>(a2, v11, "'", (uint64_t)v16, "' op inferred type(s) ", (uint64_t)&v20, " are incompatible with return type(s) of operation ", a11);
  unint64_t v14 = v20;
  if (v20 != v22) {
LABEL_7:
  }
    free(v14);
  return v13;
}

BOOL llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &>::CallImpl<mlir::Op<mlir::tensor::InsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1} const>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v17 = *MEMORY[0x263EF8340];
  uint64_t v13 = a2;
  mlir::tensor::detail::InsertSliceOpGenericAdaptorBase::InsertSliceOpGenericAdaptorBase((uint64_t)v14, a2);
  uint64_t v15 = a3;
  uint64_t v16 = a4;
  unint64_t v9 = mlir::tensor::InsertSliceOp::fold(&v13);
  unint64_t v10 = v9;
  if (v9 < 8 || a2 - 16 == (v9 & ((uint64_t)(v9 << 61) >> 63) & 0xFFFFFFFFFFFFFFF8)) {
    return v9 > 7;
  }
  uint64_t v11 = *(unsigned int *)(a5 + 8);
  if (v11 >= *(_DWORD *)(a5 + 12))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod(a5, (void *)(a5 + 16), v11 + 1, 8);
    LODWORD(v11) = *(_DWORD *)(a5 + 8);
  }
  *(void *)(*(void *)a5 + 8 * v11) = v10;
  ++*(_DWORD *)(a5 + 8);
  return 1;
}

BOOL llvm::detail::UniqueFunctionBase<BOOL,mlir::TypeID>::CallImpl<mlir::Op<mlir::tensor::InsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1} const>(uint64_t a1, uint64_t a2)
{
  return mlir::op_definition_impl::hasTrait<mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait,mlir::InferTypeOpInterface::Trait>(a2);
}

BOOL mlir::op_definition_impl::hasTrait<mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait,mlir::InferTypeOpInterface::Trait>(uint64_t a1)
{
  v1 = &unk_267771000;
  {
    uint64_t v312 = a1;
    v1 = (void *)&unk_267771000;
    int v49 = v48;
    a1 = v312;
    if (v49)
    {
      v328 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::ZeroRegions<Empty>]";
      unint64_t v329 = 83;
      unint64_t v50 = llvm::StringRef::find((uint64_t *)&v328, "DesiredTypeName = ", 0x12uLL, 0);
      if (v329 >= v50) {
        unint64_t v51 = v50;
      }
      else {
        unint64_t v51 = v329;
      }
      v52 = &v328[v51];
      unint64_t v53 = v329 - v51;
      if (v329 - v51 >= 0x12) {
        uint64_t v54 = 18;
      }
      else {
        uint64_t v54 = v329 - v51;
      }
      unint64_t v55 = v53 - v54;
      if (v55 >= v55 - 1) {
        uint64_t v56 = v55 - 1;
      }
      else {
        uint64_t v56 = v55;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::ZeroRegions<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::ZeroRegions>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v52[v54], v56);
      v1 = (void *)&unk_267771000;
      a1 = v312;
    }
  }
  uint64_t v2 = v1[23];
  uint64_t v3 = &unk_267771000;
  {
    uint64_t v297 = v2;
    uint64_t v313 = a1;
    uint64_t v3 = (void *)&unk_267771000;
    int v58 = v57;
    uint64_t v2 = v297;
    a1 = v313;
    if (v58)
    {
      v328 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::OneResult<Empty>]";
      unint64_t v329 = 81;
      unint64_t v59 = llvm::StringRef::find((uint64_t *)&v328, "DesiredTypeName = ", 0x12uLL, 0);
      if (v329 >= v59) {
        unint64_t v60 = v59;
      }
      else {
        unint64_t v60 = v329;
      }
      v61 = &v328[v60];
      unint64_t v62 = v329 - v60;
      if (v329 - v60 >= 0x12) {
        uint64_t v63 = 18;
      }
      else {
        uint64_t v63 = v329 - v60;
      }
      unint64_t v64 = v62 - v63;
      if (v64 >= v64 - 1) {
        uint64_t v65 = v64 - 1;
      }
      else {
        uint64_t v65 = v64;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::OneResult<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::OneResult>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v61[v63], v65);
      uint64_t v3 = (void *)&unk_267771000;
      uint64_t v2 = v297;
      a1 = v313;
    }
  }
  uint64_t v4 = v3[25];
  unint64_t v5 = &unk_267771000;
  {
    uint64_t v298 = v2;
    uint64_t v314 = a1;
    uint64_t v283 = v4;
    unint64_t v5 = (void *)&unk_267771000;
    uint64_t v4 = v283;
    uint64_t v2 = v298;
    int v67 = v66;
    a1 = v314;
    if (v67)
    {
      v328 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl<Empty>]";
      unint64_t v329 = 116;
      unint64_t v68 = llvm::StringRef::find((uint64_t *)&v328, "DesiredTypeName = ", 0x12uLL, 0);
      if (v329 >= v68) {
        unint64_t v69 = v68;
      }
      else {
        unint64_t v69 = v329;
      }
      v70 = &v328[v69];
      unint64_t v71 = v329 - v69;
      if (v329 - v69 >= 0x12) {
        uint64_t v72 = 18;
      }
      else {
        uint64_t v72 = v329 - v69;
      }
      unint64_t v73 = v71 - v72;
      if (v73 >= v73 - 1) {
        uint64_t v74 = v73 - 1;
      }
      else {
        uint64_t v74 = v73;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v70[v72], v74);
      unint64_t v5 = (void *)&unk_267771000;
      uint64_t v4 = v283;
      uint64_t v2 = v298;
      a1 = v314;
    }
  }
  uint64_t v6 = v5[435];
  BOOL v7 = &unk_267770000;
  {
    uint64_t v299 = v2;
    uint64_t v315 = a1;
    uint64_t v270 = v6;
    uint64_t v284 = v4;
    BOOL v7 = (void *)&unk_267770000;
    uint64_t v6 = v270;
    uint64_t v4 = v284;
    int v76 = v75;
    uint64_t v2 = v299;
    a1 = v315;
    if (v76)
    {
      v328 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::ZeroSuccessors<Empty>]";
      unint64_t v329 = 86;
      unint64_t v77 = llvm::StringRef::find((uint64_t *)&v328, "DesiredTypeName = ", 0x12uLL, 0);
      if (v329 >= v77) {
        unint64_t v78 = v77;
      }
      else {
        unint64_t v78 = v329;
      }
      v79 = &v328[v78];
      unint64_t v80 = v329 - v78;
      if (v329 - v78 >= 0x12) {
        uint64_t v81 = 18;
      }
      else {
        uint64_t v81 = v329 - v78;
      }
      unint64_t v82 = v80 - v81;
      if (v82 >= v82 - 1) {
        uint64_t v83 = v82 - 1;
      }
      else {
        uint64_t v83 = v82;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::ZeroSuccessors<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::ZeroSuccessors>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v79[v81], v83);
      BOOL v7 = (void *)&unk_267770000;
      uint64_t v6 = v270;
      uint64_t v4 = v284;
      uint64_t v2 = v299;
      a1 = v315;
    }
  }
  uint64_t v8 = v7[431];
  unint64_t v9 = &unk_267771000;
  {
    uint64_t v300 = v2;
    uint64_t v316 = a1;
    uint64_t v271 = v6;
    uint64_t v285 = v4;
    uint64_t v258 = v8;
    unint64_t v9 = (void *)&unk_267771000;
    uint64_t v8 = v258;
    uint64_t v6 = v271;
    uint64_t v4 = v285;
    uint64_t v2 = v300;
    int v85 = v84;
    a1 = v316;
    if (v85)
    {
      v328 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::AtLeastNOperands<2>::Impl<Empty>]";
      unint64_t v329 = 97;
      unint64_t v86 = llvm::StringRef::find((uint64_t *)&v328, "DesiredTypeName = ", 0x12uLL, 0);
      if (v329 >= v86) {
        unint64_t v87 = v86;
      }
      else {
        unint64_t v87 = v329;
      }
      v88 = &v328[v87];
      unint64_t v89 = v329 - v87;
      if (v329 - v87 >= 0x12) {
        uint64_t v90 = 18;
      }
      else {
        uint64_t v90 = v329 - v87;
      }
      unint64_t v91 = v89 - v90;
      if (v91 >= v91 - 1) {
        uint64_t v92 = v91 - 1;
      }
      else {
        uint64_t v92 = v91;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::AtLeastNOperands<2u>::Impl<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::AtLeastNOperands<2u>::Impl>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v88[v90], v92);
      unint64_t v9 = (void *)&unk_267771000;
      uint64_t v8 = v258;
      uint64_t v6 = v271;
      uint64_t v4 = v285;
      uint64_t v2 = v300;
      a1 = v316;
    }
  }
  uint64_t v10 = v9[441];
  uint64_t v11 = &unk_267772000;
  {
    uint64_t v301 = v2;
    uint64_t v317 = a1;
    uint64_t v272 = v6;
    uint64_t v286 = v4;
    uint64_t v259 = v8;
    uint64_t v247 = v10;
    uint64_t v11 = (void *)&unk_267772000;
    uint64_t v10 = v247;
    uint64_t v8 = v259;
    uint64_t v6 = v272;
    uint64_t v4 = v286;
    uint64_t v2 = v301;
    int v94 = v93;
    a1 = v317;
    if (v94)
    {
      v328 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::AttrSizedOperandSegments<Empty>]";
      unint64_t v329 = 96;
      unint64_t v95 = llvm::StringRef::find((uint64_t *)&v328, "DesiredTypeName = ", 0x12uLL, 0);
      if (v329 >= v95) {
        unint64_t v96 = v95;
      }
      else {
        unint64_t v96 = v329;
      }
      v97 = &v328[v96];
      unint64_t v98 = v329 - v96;
      if (v329 - v96 >= 0x12) {
        uint64_t v99 = 18;
      }
      else {
        uint64_t v99 = v329 - v96;
      }
      unint64_t v100 = v98 - v99;
      if (v100 >= v100 - 1) {
        uint64_t v101 = v100 - 1;
      }
      else {
        uint64_t v101 = v100;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::AttrSizedOperandSegments<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::AttrSizedOperandSegments>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v97[v99], v101);
      uint64_t v11 = (void *)&unk_267772000;
      uint64_t v10 = v247;
      uint64_t v8 = v259;
      uint64_t v6 = v272;
      uint64_t v4 = v286;
      uint64_t v2 = v301;
      a1 = v317;
    }
  }
  uint64_t v12 = v11[47];
  uint64_t v13 = &unk_267770000;
  {
    uint64_t v302 = v2;
    uint64_t v318 = a1;
    uint64_t v273 = v6;
    uint64_t v287 = v4;
    uint64_t v260 = v8;
    uint64_t v237 = v12;
    uint64_t v248 = v10;
    uint64_t v13 = (void *)&unk_267770000;
    uint64_t v12 = v237;
    uint64_t v10 = v248;
    uint64_t v8 = v260;
    uint64_t v6 = v273;
    uint64_t v4 = v287;
    uint64_t v2 = v302;
    int v103 = v102;
    a1 = v318;
    if (v103)
    {
      v328 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::OpInvariants<Empty>]";
      unint64_t v329 = 84;
      unint64_t v104 = llvm::StringRef::find((uint64_t *)&v328, "DesiredTypeName = ", 0x12uLL, 0);
      if (v329 >= v104) {
        unint64_t v105 = v104;
      }
      else {
        unint64_t v105 = v329;
      }
      v106 = &v328[v105];
      unint64_t v107 = v329 - v105;
      if (v329 - v105 >= 0x12) {
        uint64_t v108 = 18;
      }
      else {
        uint64_t v108 = v329 - v105;
      }
      unint64_t v109 = v107 - v108;
      if (v109 >= v109 - 1) {
        uint64_t v110 = v109 - 1;
      }
      else {
        uint64_t v110 = v109;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::OpInvariants<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::OpInvariants>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v106[v108], v110);
      uint64_t v13 = (void *)&unk_267770000;
      uint64_t v12 = v237;
      uint64_t v10 = v248;
      uint64_t v8 = v260;
      uint64_t v6 = v273;
      uint64_t v4 = v287;
      uint64_t v2 = v302;
      a1 = v318;
    }
  }
  uint64_t v14 = v13[435];
  uint64_t v15 = &unk_267771000;
  {
    uint64_t v303 = v2;
    uint64_t v319 = a1;
    uint64_t v274 = v6;
    uint64_t v288 = v4;
    uint64_t v261 = v8;
    uint64_t v238 = v12;
    uint64_t v249 = v10;
    uint64_t v228 = v14;
    uint64_t v15 = (void *)&unk_267771000;
    uint64_t v14 = v228;
    uint64_t v12 = v238;
    uint64_t v10 = v249;
    uint64_t v8 = v261;
    uint64_t v6 = v274;
    uint64_t v4 = v288;
    uint64_t v2 = v303;
    int v112 = v111;
    a1 = v319;
    if (v112)
    {
      v328 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::BytecodeOpInterface::Trait<Empty>]";
      unint64_t v329 = 89;
      unint64_t v113 = llvm::StringRef::find((uint64_t *)&v328, "DesiredTypeName = ", 0x12uLL, 0);
      if (v329 >= v113) {
        unint64_t v114 = v113;
      }
      else {
        unint64_t v114 = v329;
      }
      v115 = &v328[v114];
      unint64_t v116 = v329 - v114;
      if (v329 - v114 >= 0x12) {
        uint64_t v117 = 18;
      }
      else {
        uint64_t v117 = v329 - v114;
      }
      unint64_t v118 = v116 - v117;
      if (v118 >= v118 - 1) {
        uint64_t v119 = v118 - 1;
      }
      else {
        uint64_t v119 = v118;
      }
      mlir::detail::TypeIDResolver<mlir::BytecodeOpInterface::Trait<mlir::TypeID mlir::TypeID::get<mlir::BytecodeOpInterface::Trait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v115[v117], v119);
      uint64_t v15 = (void *)&unk_267771000;
      uint64_t v14 = v228;
      uint64_t v12 = v238;
      uint64_t v10 = v249;
      uint64_t v8 = v261;
      uint64_t v6 = v274;
      uint64_t v4 = v288;
      uint64_t v2 = v303;
      a1 = v319;
    }
  }
  uint64_t v16 = v15[320];
  uint64_t v17 = &unk_267771000;
  {
    uint64_t v304 = v2;
    uint64_t v320 = a1;
    uint64_t v275 = v6;
    uint64_t v289 = v4;
    uint64_t v262 = v8;
    uint64_t v239 = v12;
    uint64_t v250 = v10;
    uint64_t v220 = v16;
    uint64_t v229 = v14;
    uint64_t v17 = (void *)&unk_267771000;
    uint64_t v16 = v220;
    uint64_t v14 = v229;
    uint64_t v12 = v239;
    uint64_t v10 = v250;
    uint64_t v8 = v262;
    uint64_t v6 = v275;
    uint64_t v4 = v289;
    uint64_t v2 = v304;
    int v121 = v120;
    a1 = v320;
    if (v121)
    {
      v328 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpAsmOpInterface::Trait<Empty>]";
      unint64_t v329 = 86;
      unint64_t v122 = llvm::StringRef::find((uint64_t *)&v328, "DesiredTypeName = ", 0x12uLL, 0);
      if (v329 >= v122) {
        unint64_t v123 = v122;
      }
      else {
        unint64_t v123 = v329;
      }
      v124 = &v328[v123];
      unint64_t v125 = v329 - v123;
      if (v329 - v123 >= 0x12) {
        uint64_t v126 = 18;
      }
      else {
        uint64_t v126 = v329 - v123;
      }
      unint64_t v127 = v125 - v126;
      if (v127 >= v127 - 1) {
        uint64_t v128 = v127 - 1;
      }
      else {
        uint64_t v128 = v127;
      }
      mlir::detail::TypeIDResolver<mlir::OpAsmOpInterface::Trait<mlir::TypeID mlir::TypeID::get<mlir::OpAsmOpInterface::Trait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v124[v126], v128);
      uint64_t v17 = (void *)&unk_267771000;
      uint64_t v16 = v220;
      uint64_t v14 = v229;
      uint64_t v12 = v239;
      uint64_t v10 = v250;
      uint64_t v8 = v262;
      uint64_t v6 = v275;
      uint64_t v4 = v289;
      uint64_t v2 = v304;
      a1 = v320;
    }
  }
  uint64_t v18 = v17[350];
  uint64_t v19 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
  {
    uint64_t v305 = v2;
    uint64_t v321 = a1;
    uint64_t v276 = v6;
    uint64_t v290 = v4;
    uint64_t v263 = v8;
    uint64_t v240 = v12;
    uint64_t v251 = v10;
    uint64_t v221 = v16;
    uint64_t v230 = v14;
    uint64_t v213 = v18;
    uint64_t v19 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
    uint64_t v18 = v213;
    uint64_t v16 = v221;
    uint64_t v14 = v230;
    uint64_t v12 = v240;
    uint64_t v10 = v251;
    uint64_t v8 = v263;
    uint64_t v6 = v276;
    uint64_t v4 = v290;
    uint64_t v2 = v305;
    int v130 = v129;
    a1 = v321;
    if (v130)
    {
      v328 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ReifyRankedShapedTypeOpInterface::Trait<Empty>]";
      unint64_t v329 = 102;
      unint64_t v131 = llvm::StringRef::find((uint64_t *)&v328, "DesiredTypeName = ", 0x12uLL, 0);
      if (v329 >= v131) {
        unint64_t v132 = v131;
      }
      else {
        unint64_t v132 = v329;
      }
      v133 = &v328[v132];
      unint64_t v134 = v329 - v132;
      if (v329 - v132 >= 0x12) {
        uint64_t v135 = 18;
      }
      else {
        uint64_t v135 = v329 - v132;
      }
      unint64_t v136 = v134 - v135;
      if (v136 >= v136 - 1) {
        uint64_t v137 = v136 - 1;
      }
      else {
        uint64_t v137 = v136;
      }
      mlir::detail::TypeIDResolver<mlir::ReifyRankedShapedTypeOpInterface::Trait<mlir::TypeID mlir::TypeID::get<mlir::ReifyRankedShapedTypeOpInterface::Trait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v133[v135], v137);
      uint64_t v19 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
      uint64_t v18 = v213;
      uint64_t v16 = v221;
      uint64_t v14 = v230;
      uint64_t v12 = v240;
      uint64_t v10 = v251;
      uint64_t v8 = v263;
      uint64_t v6 = v276;
      uint64_t v4 = v290;
      uint64_t v2 = v305;
      a1 = v321;
    }
  }
  uint64_t v20 = v19[178];
  uint64_t v21 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
  {
    uint64_t v306 = v2;
    uint64_t v322 = a1;
    uint64_t v277 = v6;
    uint64_t v291 = v4;
    uint64_t v264 = v8;
    uint64_t v241 = v12;
    uint64_t v252 = v10;
    uint64_t v222 = v16;
    uint64_t v231 = v14;
    uint64_t v207 = v20;
    uint64_t v214 = v18;
    uint64_t v21 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
    uint64_t v20 = v207;
    uint64_t v18 = v214;
    uint64_t v16 = v222;
    uint64_t v14 = v231;
    uint64_t v12 = v241;
    uint64_t v10 = v252;
    uint64_t v8 = v264;
    uint64_t v6 = v277;
    uint64_t v4 = v291;
    uint64_t v2 = v306;
    int v139 = v138;
    a1 = v322;
    if (v139)
    {
      v328 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::DestinationStyleOpInterface::Trait<Empty>]";
      unint64_t v329 = 97;
      unint64_t v140 = llvm::StringRef::find((uint64_t *)&v328, "DesiredTypeName = ", 0x12uLL, 0);
      if (v329 >= v140) {
        unint64_t v141 = v140;
      }
      else {
        unint64_t v141 = v329;
      }
      v142 = &v328[v141];
      unint64_t v143 = v329 - v141;
      if (v329 - v141 >= 0x12) {
        uint64_t v144 = 18;
      }
      else {
        uint64_t v144 = v329 - v141;
      }
      unint64_t v145 = v143 - v144;
      if (v145 >= v145 - 1) {
        uint64_t v146 = v145 - 1;
      }
      else {
        uint64_t v146 = v145;
      }
      mlir::detail::TypeIDResolver<mlir::DestinationStyleOpInterface::Trait<mlir::TypeID mlir::TypeID::get<mlir::DestinationStyleOpInterface::Trait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v142[v144], v146);
      uint64_t v21 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
      uint64_t v20 = v207;
      uint64_t v18 = v214;
      uint64_t v16 = v222;
      uint64_t v14 = v231;
      uint64_t v12 = v241;
      uint64_t v10 = v252;
      uint64_t v8 = v264;
      uint64_t v6 = v277;
      uint64_t v4 = v291;
      uint64_t v2 = v306;
      a1 = v322;
    }
  }
  uint64_t v22 = v21[138];
  v23 = &unk_267771000;
  {
    uint64_t v307 = v2;
    uint64_t v323 = a1;
    uint64_t v278 = v6;
    uint64_t v292 = v4;
    uint64_t v265 = v8;
    uint64_t v242 = v12;
    uint64_t v253 = v10;
    uint64_t v223 = v16;
    uint64_t v232 = v14;
    uint64_t v208 = v20;
    uint64_t v215 = v18;
    uint64_t v202 = v22;
    v23 = (void *)&unk_267771000;
    uint64_t v22 = v202;
    uint64_t v20 = v208;
    uint64_t v18 = v215;
    uint64_t v16 = v223;
    uint64_t v14 = v232;
    uint64_t v12 = v242;
    uint64_t v10 = v253;
    uint64_t v8 = v265;
    uint64_t v6 = v278;
    uint64_t v4 = v292;
    uint64_t v2 = v307;
    int v148 = v147;
    a1 = v323;
    if (v148)
    {
      v328 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ConditionallySpeculatable::Trait<Empty>]";
      unint64_t v329 = 95;
      unint64_t v149 = llvm::StringRef::find((uint64_t *)&v328, "DesiredTypeName = ", 0x12uLL, 0);
      if (v329 >= v149) {
        unint64_t v150 = v149;
      }
      else {
        unint64_t v150 = v329;
      }
      v151 = &v328[v150];
      unint64_t v152 = v329 - v150;
      if (v329 - v150 >= 0x12) {
        uint64_t v153 = 18;
      }
      else {
        uint64_t v153 = v329 - v150;
      }
      unint64_t v154 = v152 - v153;
      if (v154 >= v154 - 1) {
        uint64_t v155 = v154 - 1;
      }
      else {
        uint64_t v155 = v154;
      }
      mlir::detail::TypeIDResolver<mlir::ConditionallySpeculatable::Trait<mlir::TypeID mlir::TypeID::get<mlir::ConditionallySpeculatable::Trait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v151[v153], v155);
      v23 = (void *)&unk_267771000;
      uint64_t v22 = v202;
      uint64_t v20 = v208;
      uint64_t v18 = v215;
      uint64_t v16 = v223;
      uint64_t v14 = v232;
      uint64_t v12 = v242;
      uint64_t v10 = v253;
      uint64_t v8 = v265;
      uint64_t v6 = v278;
      uint64_t v4 = v292;
      uint64_t v2 = v307;
      a1 = v323;
    }
  }
  uint64_t v24 = v23[322];
  v25 = &unk_267771000;
  {
    uint64_t v308 = v2;
    uint64_t v324 = a1;
    uint64_t v279 = v6;
    uint64_t v293 = v4;
    uint64_t v266 = v8;
    uint64_t v243 = v12;
    uint64_t v254 = v10;
    uint64_t v224 = v16;
    uint64_t v233 = v14;
    uint64_t v209 = v20;
    uint64_t v216 = v18;
    uint64_t v198 = v24;
    uint64_t v203 = v22;
    v25 = (void *)&unk_267771000;
    uint64_t v24 = v198;
    uint64_t v22 = v203;
    uint64_t v20 = v209;
    uint64_t v18 = v216;
    uint64_t v16 = v224;
    uint64_t v14 = v233;
    uint64_t v12 = v243;
    uint64_t v10 = v254;
    uint64_t v8 = v266;
    uint64_t v6 = v279;
    uint64_t v4 = v293;
    uint64_t v2 = v308;
    int v157 = v156;
    a1 = v324;
    if (v157)
    {
      v328 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::AlwaysSpeculatableImplTrait<Empty>]";
      unint64_t v329 = 99;
      unint64_t v158 = llvm::StringRef::find((uint64_t *)&v328, "DesiredTypeName = ", 0x12uLL, 0);
      if (v329 >= v158) {
        unint64_t v159 = v158;
      }
      else {
        unint64_t v159 = v329;
      }
      v160 = &v328[v159];
      unint64_t v161 = v329 - v159;
      if (v329 - v159 >= 0x12) {
        uint64_t v162 = 18;
      }
      else {
        uint64_t v162 = v329 - v159;
      }
      unint64_t v163 = v161 - v162;
      if (v163 >= v163 - 1) {
        uint64_t v164 = v163 - 1;
      }
      else {
        uint64_t v164 = v163;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::AlwaysSpeculatableImplTrait<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::AlwaysSpeculatableImplTrait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v160[v162], v164);
      v25 = (void *)&unk_267771000;
      uint64_t v24 = v198;
      uint64_t v22 = v203;
      uint64_t v20 = v209;
      uint64_t v18 = v216;
      uint64_t v16 = v224;
      uint64_t v14 = v233;
      uint64_t v12 = v243;
      uint64_t v10 = v254;
      uint64_t v8 = v266;
      uint64_t v6 = v279;
      uint64_t v4 = v293;
      uint64_t v2 = v308;
      a1 = v324;
    }
  }
  uint64_t v26 = v25[324];
  v27 = &unk_267771000;
  {
    uint64_t v309 = v2;
    uint64_t v325 = a1;
    uint64_t v280 = v6;
    uint64_t v294 = v4;
    uint64_t v267 = v8;
    uint64_t v244 = v12;
    uint64_t v255 = v10;
    uint64_t v225 = v16;
    uint64_t v234 = v14;
    uint64_t v210 = v20;
    uint64_t v217 = v18;
    uint64_t v199 = v24;
    uint64_t v204 = v22;
    uint64_t v195 = v26;
    v27 = (void *)&unk_267771000;
    uint64_t v26 = v195;
    uint64_t v24 = v199;
    uint64_t v22 = v204;
    uint64_t v20 = v210;
    uint64_t v18 = v217;
    uint64_t v16 = v225;
    uint64_t v14 = v234;
    uint64_t v12 = v244;
    uint64_t v10 = v255;
    uint64_t v8 = v267;
    uint64_t v6 = v280;
    uint64_t v4 = v294;
    uint64_t v2 = v309;
    int v166 = v165;
    a1 = v325;
    if (v166)
    {
      v328 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::MemoryEffectOpInterface::Trait<Empty>]";
      unint64_t v329 = 93;
      unint64_t v167 = llvm::StringRef::find((uint64_t *)&v328, "DesiredTypeName = ", 0x12uLL, 0);
      if (v329 >= v167) {
        unint64_t v168 = v167;
      }
      else {
        unint64_t v168 = v329;
      }
      v169 = &v328[v168];
      unint64_t v170 = v329 - v168;
      if (v329 - v168 >= 0x12) {
        uint64_t v171 = 18;
      }
      else {
        uint64_t v171 = v329 - v168;
      }
      unint64_t v172 = v170 - v171;
      if (v172 >= v172 - 1) {
        uint64_t v173 = v172 - 1;
      }
      else {
        uint64_t v173 = v172;
      }
      mlir::detail::TypeIDResolver<mlir::MemoryEffectOpInterface::Trait<mlir::TypeID mlir::TypeID::get<mlir::MemoryEffectOpInterface::Trait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v169[v171], v173);
      v27 = (void *)&unk_267771000;
      uint64_t v26 = v195;
      uint64_t v24 = v199;
      uint64_t v22 = v204;
      uint64_t v20 = v210;
      uint64_t v18 = v217;
      uint64_t v16 = v225;
      uint64_t v14 = v234;
      uint64_t v12 = v244;
      uint64_t v10 = v255;
      uint64_t v8 = v267;
      uint64_t v6 = v280;
      uint64_t v4 = v294;
      uint64_t v2 = v309;
      a1 = v325;
    }
  }
  uint64_t v28 = v27[31];
  v29 = &unk_267772000;
  {
    uint64_t v310 = v2;
    uint64_t v326 = a1;
    uint64_t v281 = v6;
    uint64_t v295 = v4;
    uint64_t v268 = v8;
    uint64_t v245 = v12;
    uint64_t v256 = v10;
    uint64_t v226 = v16;
    uint64_t v235 = v14;
    uint64_t v211 = v20;
    uint64_t v218 = v18;
    uint64_t v200 = v24;
    uint64_t v205 = v22;
    uint64_t v193 = v28;
    uint64_t v196 = v26;
    v29 = (void *)&unk_267772000;
    uint64_t v28 = v193;
    uint64_t v26 = v196;
    uint64_t v24 = v200;
    uint64_t v22 = v205;
    uint64_t v20 = v211;
    uint64_t v18 = v218;
    uint64_t v16 = v226;
    uint64_t v14 = v235;
    uint64_t v12 = v245;
    uint64_t v10 = v256;
    uint64_t v8 = v268;
    uint64_t v6 = v281;
    uint64_t v4 = v295;
    uint64_t v2 = v310;
    int v175 = v174;
    a1 = v326;
    if (v175)
    {
      v328 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OffsetSizeAndStrideOpInterface::Trait<Empty>]";
      unint64_t v329 = 100;
      unint64_t v176 = llvm::StringRef::find((uint64_t *)&v328, "DesiredTypeName = ", 0x12uLL, 0);
      if (v329 >= v176) {
        unint64_t v177 = v176;
      }
      else {
        unint64_t v177 = v329;
      }
      v178 = &v328[v177];
      unint64_t v179 = v329 - v177;
      if (v329 - v177 >= 0x12) {
        uint64_t v180 = 18;
      }
      else {
        uint64_t v180 = v329 - v177;
      }
      unint64_t v181 = v179 - v180;
      if (v181 >= v181 - 1) {
        uint64_t v182 = v181 - 1;
      }
      else {
        uint64_t v182 = v181;
      }
      mlir::detail::TypeIDResolver<mlir::OffsetSizeAndStrideOpInterface::Trait<mlir::TypeID mlir::TypeID::get<mlir::OffsetSizeAndStrideOpInterface::Trait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v178[v180], v182);
      v29 = (void *)&unk_267772000;
      uint64_t v28 = v193;
      uint64_t v26 = v196;
      uint64_t v24 = v200;
      uint64_t v22 = v205;
      uint64_t v20 = v211;
      uint64_t v18 = v218;
      uint64_t v16 = v226;
      uint64_t v14 = v235;
      uint64_t v12 = v245;
      uint64_t v10 = v256;
      uint64_t v8 = v268;
      uint64_t v6 = v281;
      uint64_t v4 = v295;
      uint64_t v2 = v310;
      a1 = v326;
    }
  }
  uint64_t v30 = v29[271];
  v31 = &unk_267771000;
  {
    uint64_t v311 = v2;
    uint64_t v327 = a1;
    uint64_t v282 = v6;
    uint64_t v296 = v4;
    uint64_t v269 = v8;
    uint64_t v246 = v12;
    uint64_t v257 = v10;
    uint64_t v227 = v16;
    uint64_t v236 = v14;
    uint64_t v212 = v20;
    uint64_t v219 = v18;
    uint64_t v201 = v24;
    uint64_t v206 = v22;
    uint64_t v194 = v28;
    uint64_t v197 = v26;
    uint64_t v192 = v30;
    v31 = (void *)&unk_267771000;
    uint64_t v30 = v192;
    uint64_t v28 = v194;
    uint64_t v26 = v197;
    uint64_t v24 = v201;
    uint64_t v22 = v206;
    uint64_t v20 = v212;
    uint64_t v18 = v219;
    uint64_t v16 = v227;
    uint64_t v14 = v236;
    uint64_t v12 = v246;
    uint64_t v10 = v257;
    uint64_t v8 = v269;
    uint64_t v6 = v282;
    uint64_t v4 = v296;
    uint64_t v2 = v311;
    int v184 = v183;
    a1 = v327;
    if (v184)
    {
      v328 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::InferTypeOpInterface::Trait<Empty>]";
      unint64_t v329 = 90;
      unint64_t v185 = llvm::StringRef::find((uint64_t *)&v328, "DesiredTypeName = ", 0x12uLL, 0);
      if (v329 >= v185) {
        unint64_t v186 = v185;
      }
      else {
        unint64_t v186 = v329;
      }
      v187 = &v328[v186];
      unint64_t v188 = v329 - v186;
      if (v329 - v186 >= 0x12) {
        uint64_t v189 = 18;
      }
      else {
        uint64_t v189 = v329 - v186;
      }
      unint64_t v190 = v188 - v189;
      if (v190 >= v190 - 1) {
        uint64_t v191 = v190 - 1;
      }
      else {
        uint64_t v191 = v190;
      }
      mlir::detail::TypeIDResolver<mlir::InferTypeOpInterface::Trait<mlir::TypeID mlir::TypeID::get<mlir::InferTypeOpInterface::Trait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v187[v189], v191);
      v31 = (void *)&unk_267771000;
      uint64_t v30 = v192;
      uint64_t v28 = v194;
      uint64_t v26 = v197;
      uint64_t v24 = v201;
      uint64_t v22 = v206;
      uint64_t v20 = v212;
      uint64_t v18 = v219;
      uint64_t v16 = v227;
      uint64_t v14 = v236;
      uint64_t v12 = v246;
      uint64_t v10 = v257;
      uint64_t v8 = v269;
      uint64_t v6 = v282;
      uint64_t v4 = v296;
      uint64_t v2 = v311;
      a1 = v327;
    }
  }
  return v2 == a1
      || v4 == a1
      || v6 == a1
      || v8 == a1
      || v10 == a1
      || v12 == a1
      || v14 == a1
      || v16 == a1
      || v18 == a1
      || v20 == a1
      || v22 == a1
      || v24 == a1
      || v26 == a1
      || v28 == a1
      || v30 == a1
      || v31[37] == a1;
}

void llvm::detail::UniqueFunctionBase<void,mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef>::CallImpl<mlir::Op<mlir::tensor::InsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1} const>(uint64_t a1, uint64_t a2, mlir::OpAsmPrinter *a3, uint64_t a4, uint64_t a5)
{
  mlir::OpState::printOpName(a2, (uint64_t)a3, a4, a5);
  uint64_t v7 = a2;
  mlir::tensor::InsertSliceOp::print((mlir::tensor::InsertSliceOp *)&v7, a3);
}

BOOL mlir::Op<mlir::tensor::InsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::verifyInvariants(mlir::OpTrait::impl *a1, mlir::Operation *a2)
{
  if (!mlir::op_definition_impl::verifyTraits<mlir::OpTrait::ZeroRegions<mlir::tensor::InsertSliceOp>,mlir::OpTrait::OneResult<mlir::tensor::InsertSliceOp>,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl<mlir::tensor::InsertSliceOp>,mlir::OpTrait::ZeroSuccessors<mlir::tensor::InsertSliceOp>,mlir::OpTrait::AtLeastNOperands<2u>::Impl<mlir::tensor::InsertSliceOp>,mlir::OpTrait::AttrSizedOperandSegments<mlir::tensor::InsertSliceOp>,mlir::OpTrait::OpInvariants<mlir::tensor::InsertSliceOp>,mlir::BytecodeOpInterface::Trait<mlir::tensor::InsertSliceOp>,mlir::OpAsmOpInterface::Trait<mlir::tensor::InsertSliceOp>,mlir::ReifyRankedShapedTypeOpInterface::Trait<mlir::tensor::InsertSliceOp>,mlir::DestinationStyleOpInterface::Trait<mlir::tensor::InsertSliceOp>,mlir::ConditionallySpeculatable::Trait<mlir::tensor::InsertSliceOp>,mlir::OpTrait::AlwaysSpeculatableImplTrait<mlir::tensor::InsertSliceOp>,mlir::MemoryEffectOpInterface::Trait<mlir::tensor::InsertSliceOp>,mlir::OffsetSizeAndStrideOpInterface::Trait<mlir::tensor::InsertSliceOp>,mlir::InferTypeOpInterface::Trait<mlir::tensor::InsertSliceOp>>(a1, a2))return 0; {
  uint64_t v4 = a1;
  }
  return mlir::tensor::InsertSliceOp::verify((mlir::tensor::InsertSliceOp *)&v4) != 0;
}

BOOL mlir::op_definition_impl::verifyTraits<mlir::OpTrait::ZeroRegions<mlir::tensor::InsertSliceOp>,mlir::OpTrait::OneResult<mlir::tensor::InsertSliceOp>,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl<mlir::tensor::InsertSliceOp>,mlir::OpTrait::ZeroSuccessors<mlir::tensor::InsertSliceOp>,mlir::OpTrait::AtLeastNOperands<2u>::Impl<mlir::tensor::InsertSliceOp>,mlir::OpTrait::AttrSizedOperandSegments<mlir::tensor::InsertSliceOp>,mlir::OpTrait::OpInvariants<mlir::tensor::InsertSliceOp>,mlir::BytecodeOpInterface::Trait<mlir::tensor::InsertSliceOp>,mlir::OpAsmOpInterface::Trait<mlir::tensor::InsertSliceOp>,mlir::ReifyRankedShapedTypeOpInterface::Trait<mlir::tensor::InsertSliceOp>,mlir::DestinationStyleOpInterface::Trait<mlir::tensor::InsertSliceOp>,mlir::ConditionallySpeculatable::Trait<mlir::tensor::InsertSliceOp>,mlir::OpTrait::AlwaysSpeculatableImplTrait<mlir::tensor::InsertSliceOp>,mlir::MemoryEffectOpInterface::Trait<mlir::tensor::InsertSliceOp>,mlir::OffsetSizeAndStrideOpInterface::Trait<mlir::tensor::InsertSliceOp>,mlir::InferTypeOpInterface::Trait<mlir::tensor::InsertSliceOp>>(mlir::OpTrait::impl *a1, mlir::Operation *a2)
{
  if (mlir::OpTrait::impl::verifyZeroRegions(a1, a2)
    && mlir::OpTrait::impl::verifyOneResult(a1, v3)
    && mlir::OpTrait::impl::verifyZeroSuccessors(a1, v4)
    && mlir::OpTrait::impl::verifyAtLeastNOperands(a1, (mlir::Operation *)2)
    && mlir::OpTrait::impl::verifyOperandSizeAttr((uint64_t)a1, "operandSegmentSizes", 0x13uLL)
    && (uint64_t v6 = a1, mlir::tensor::InsertSliceOp::verifyInvariantsImpl((mlir::tensor::InsertSliceOp *)&v6)))
  {
    return mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::memref::ReinterpretCastOp>::verifyTrait((uint64_t)a1) != 0;
  }
  else
  {
    return 0;
  }
}

BOOL mlir::Op<mlir::tensor::InsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::verifyRegionInvariants(mlir::detail *a1, mlir::Operation *a2)
{
  return mlir::detail::verifyDestinationStyleOpInterface(a1, a2)
      && mlir::detail::verifyInferredResultTypes(a1, v3) != 0;
}

void *mlir::RegisteredOperationName::Model<mlir::tensor::PackOp>::Model(void *a1, uint64_t a2)
{
  v11[6] = *MEMORY[0x263EF8340];
  unint64_t v9 = v11;
  uint64_t v10 = 0x300000000;
  mlir::detail::InterfaceMap::insertModel<mlir::detail::BytecodeOpInterfaceInterfaceTraits::Model<mlir::tensor::PackOp>>((uint64_t)&v9);
  mlir::detail::InterfaceMap::insertModel<mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::PackOp>>((uint64_t)&v9);
  mlir::detail::InterfaceMap::insertModel<mlir::detail::DestinationStyleOpInterfaceInterfaceTraits::Model<mlir::tensor::PackOp>>((uint64_t)&v9);
  mlir::detail::InterfaceMap::insertModel<mlir::detail::ConditionallySpeculatableInterfaceTraits::Model<mlir::tensor::PackOp>>((uint64_t)&v9);
  mlir::detail::InterfaceMap::insertModel<mlir::detail::MemoryEffectOpInterfaceInterfaceTraits::Model<mlir::tensor::PackOp>>((uint64_t)&v9);
  mlir::detail::InterfaceMap::insertModel<mlir::detail::ReifyRankedShapedTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::PackOp>>((uint64_t)&v9);
  mlir::detail::InterfaceMap::insertModel<mlir::detail::InferTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::PackOp>>((uint64_t)&v9);
  mlir::OperationName::Impl::Impl(a1, (uint64_t)"tensor.pack", 11, a2, (uint64_t)&mlir::detail::TypeIDResolver<mlir::tensor::PackOp,void>::id, (uint64_t)&v9);
  uint64_t v4 = v9;
  if (v10)
  {
    uint64_t v5 = 16 * v10;
    uint64_t v6 = (void **)((char *)v9 + 8);
    do
    {
      uint64_t v7 = *v6;
      v6 += 2;
      free(v7);
      v5 -= 16;
    }
    while (v5);
    uint64_t v4 = v9;
  }
  if (v4 != v11) {
    free(v4);
  }
  *a1 = &unk_26C37AEE8;
  return a1;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::PackOp>::~Model(uint64_t a1)
{
  *(void *)a1 = &unk_26C361F50;
  uint64_t v2 = *(void ***)(a1 + 32);
  uint64_t v3 = *(unsigned int *)(a1 + 40);
  if (v3)
  {
    uint64_t v4 = 16 * v3;
    uint64_t v5 = v2 + 1;
    do
    {
      uint64_t v6 = *v5;
      v5 += 2;
      free(v6);
      v4 -= 16;
    }
    while (v4);
    uint64_t v2 = *(void ***)(a1 + 32);
  }
  if (v2 != (void **)(a1 + 48)) {
    free(v2);
  }
  return a1;
}

void mlir::RegisteredOperationName::Model<mlir::tensor::PackOp>::~Model(uint64_t a1)
{
  *(void *)a1 = &unk_26C361F50;
  uint64_t v2 = *(void ***)(a1 + 32);
  uint64_t v3 = *(unsigned int *)(a1 + 40);
  if (v3)
  {
    uint64_t v4 = 16 * v3;
    uint64_t v5 = v2 + 1;
    do
    {
      uint64_t v6 = *v5;
      v5 += 2;
      free(v6);
      v4 -= 16;
    }
    while (v4);
    uint64_t v2 = *(void ***)(a1 + 32);
  }
  if (v2 != (void **)(a1 + 48)) {
    free(v2);
  }

  JUMPOUT(0x21667D3C0);
}

BOOL mlir::RegisteredOperationName::Model<mlir::tensor::PackOp>::foldHook(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v10 = *MEMORY[0x263EF8340];
  unint64_t v9 = (unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &>::CallbacksHolder<mlir::Op<mlir::tensor::PackOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1},mlir::Op<mlir::tensor::PackOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1} const,void>::Callbacks
     + 2;
  BOOL v5 = (*(BOOL (**)(uint64_t, uint64_t, uint64_t, uint64_t, uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &>::CallbacksHolder<mlir::Op<mlir::tensor::PackOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1},mlir::Op<mlir::tensor::PackOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1} const,void>::Callbacks
                                                                            + 2) & 0xFFFFFFFFFFFFFFF8))((uint64_t)v8, a2, a3, a4, a5);
  char v6 = v9;
  if (v9 >= 8)
  {
    if ((v9 & 4) != 0) {
      (*(void (__cdecl **)())((v9 & 0xFFFFFFFFFFFFFFF8) + 16))();
    }
    if ((v6 & 2) == 0) {
      llvm::deallocate_buffer(v8[0], v8[1]);
    }
  }
  return v5;
}

void mlir::RegisteredOperationName::Model<mlir::tensor::PackOp>::getCanonicalizationPatterns()
{
}

BOOL mlir::RegisteredOperationName::Model<mlir::tensor::PackOp>::hasTrait(uint64_t a1, uint64_t a2)
{
  uint64_t v9 = *MEMORY[0x263EF8340];
  unint64_t v8 = (unint64_t)llvm::detail::UniqueFunctionBase<BOOL,mlir::TypeID>::CallbacksHolder<mlir::Op<mlir::tensor::PackOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1},mlir::Op<mlir::tensor::PackOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1} const,void>::Callbacks
     + 2;
  BOOL v3 = (*(BOOL (**)(uint64_t, uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<BOOL,mlir::TypeID>::CallbacksHolder<mlir::Op<mlir::tensor::PackOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1},mlir::Op<mlir::tensor::PackOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1} const,void>::Callbacks
                                                 + 2) & 0xFFFFFFFFFFFFFFF8))((uint64_t)v7, a2);
  char v4 = v8;
  if (v8 >= 8)
  {
    if ((v8 & 4) != 0)
    {
      if ((v8 & 2) != 0) {
        BOOL v5 = v7;
      }
      else {
        BOOL v5 = (llvm **)v7[0];
      }
      (*(void (**)(uint64_t, uint64_t))((v8 & 0xFFFFFFFFFFFFFFF8) + 16))((uint64_t)v5, v2);
    }
    if ((v4 & 2) == 0) {
      llvm::deallocate_buffer(v7[0], v7[1]);
    }
  }
  return v3;
}

void mlir::RegisteredOperationName::Model<mlir::tensor::PackOp>::getParseAssemblyFn(uint64_t (**a1)(uint64_t a1, uint64_t a2)@<X8>)
{
  *a1 = mlir::tensor::PackOp::parse;
  a1[3] = (uint64_t (*)(uint64_t, uint64_t))((char *)llvm::detail::UniqueFunctionBase<mlir::ParseResult,mlir::OpAsmParser &,mlir::OperationState &>::CallbacksHolder<mlir::ParseResult (*)(mlir::OpAsmParser &,mlir::OperationState &),mlir::ParseResult (*)(mlir::OpAsmParser &,mlir::OperationState &),void>::Callbacks
                                                   + 2);
}

void mlir::RegisteredOperationName::Model<mlir::tensor::PackOp>::printAssembly(uint64_t a1, uint64_t a2, mlir::OpAsmPrinter *a3, uint64_t a4, uint64_t a5)
{
  uint64_t v13 = *MEMORY[0x263EF8340];
  unint64_t v12 = (unint64_t)llvm::detail::UniqueFunctionBase<void,mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef>::CallbacksHolder<mlir::Op<mlir::tensor::PackOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1},mlir::Op<mlir::tensor::PackOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1} const,void>::Callbacks
      + 2;
  (*(void (**)(uint64_t, uint64_t, mlir::OpAsmPrinter *, uint64_t, uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<void,mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef>::CallbacksHolder<mlir::Op<mlir::tensor::PackOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1},mlir::Op<mlir::tensor::PackOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1} const,void>::Callbacks
                                                                                    + 2) & 0xFFFFFFFFFFFFFFF8))((uint64_t)v11, a2, a3, a4, a5);
  char v9 = v12;
  if (v12 >= 8)
  {
    if ((v12 & 4) != 0)
    {
      if ((v12 & 2) != 0) {
        uint64_t v10 = v11;
      }
      else {
        uint64_t v10 = (llvm **)v11[0];
      }
      (*(void (**)(uint64_t, mlir::Operation *, mlir::OpAsmPrinter *, uint64_t, uint64_t))((v12 & 0xFFFFFFFFFFFFFFF8)
                                                                                                 + 16))((uint64_t)v10, v5, v6, v7, v8);
    }
    if ((v9 & 2) == 0) {
      llvm::deallocate_buffer(v11[0], v11[1]);
    }
  }
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::PackOp>::verifyInvariants(uint64_t a1, uint64_t a2)
{
  uint64_t v7 = *MEMORY[0x263EF8340];
  v5[0] = (uint64_t (*)(uint64_t))mlir::Op<mlir::tensor::PackOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::verifyInvariants;
  unint64_t v6 = (unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *>::CallbacksHolder<mlir::LogicalResult (*)(mlir::Operation *),mlir::LogicalResult (* const)(mlir::Operation *),void>::Callbacks
     + 2;
  uint64_t v2 = (*(uint64_t (**)(uint64_t (**)(uint64_t), uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *>::CallbacksHolder<mlir::LogicalResult (*)(mlir::Operation *),mlir::LogicalResult (* const)(mlir::Operation *),void>::Callbacks
                                                                             + 2) & 0xFFFFFFFFFFFFFFF8))(v5, a2);
  char v3 = v6;
  if (v6 >= 8)
  {
    if ((v6 & 4) != 0) {
      (*(void (__cdecl **)())((v6 & 0xFFFFFFFFFFFFFFF8) + 16))();
    }
    if ((v3 & 2) == 0) {
      llvm::deallocate_buffer((llvm *)v5[0], v5[1]);
    }
  }
  return v2;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::PackOp>::verifyRegionInvariants(uint64_t a1, uint64_t a2)
{
  uint64_t v7 = *MEMORY[0x263EF8340];
  v5[0] = (uint64_t (*)(uint64_t))mlir::Op<mlir::tensor::PackOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::verifyRegionInvariants;
  unint64_t v6 = (unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *>::CallbacksHolder<mlir::LogicalResult (*)(mlir::Operation *),mlir::LogicalResult (* const)(mlir::Operation *),void>::Callbacks
     + 2;
  uint64_t v2 = (*(uint64_t (**)(uint64_t (**)(uint64_t), uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *>::CallbacksHolder<mlir::LogicalResult (*)(mlir::Operation *),mlir::LogicalResult (* const)(mlir::Operation *),void>::Callbacks
                                                                             + 2) & 0xFFFFFFFFFFFFFFF8))(v5, a2);
  char v3 = v6;
  if (v6 >= 8)
  {
    if ((v6 & 4) != 0) {
      (*(void (__cdecl **)())((v6 & 0xFFFFFFFFFFFFFFF8) + 16))();
    }
    if ((v3 & 2) == 0) {
      llvm::deallocate_buffer((llvm *)v5[0], v5[1]);
    }
  }
  return v2;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::PackOp>::getInherentAttr(uint64_t a1, uint64_t a2, void *a3, size_t a4)
{
  uint64_t Context = (mlir::MLIRContext *)mlir::Attribute::getContext((mlir::Attribute *)(a2 + 24));
  if (HIBYTE(*(_DWORD *)(a2 + 44))) {
    uint64_t v8 = (void *)(a2 + 16 * (((unint64_t)*(unsigned int *)(a2 + 44) >> 23) & 1) + 64);
  }
  else {
    uint64_t v8 = 0;
  }

  return mlir::tensor::PackOp::getInherentAttr(Context, v8, a3, a4);
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::PackOp>::setInherentAttr(uint64_t a1, uint64_t a2, uint64_t a3, void *a4)
{
  uint64_t v9 = a3;
  if (HIBYTE(*(_DWORD *)(a2 + 44))) {
    uint64_t v5 = a2 + 16 * (((unint64_t)*(unsigned int *)(a2 + 44) >> 23) & 1) + 64;
  }
  else {
    uint64_t v5 = 0;
  }
  AttrData = (void *)mlir::OpaqueAttr::getAttrData((mlir::OpaqueAttr *)&v9);
  return mlir::tensor::PackOp::setInherentAttr(v5, AttrData, v7, a4);
}

void mlir::RegisteredOperationName::Model<mlir::tensor::PackOp>::populateInherentAttrs(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t Context = (mlir::MLIRContext *)mlir::Attribute::getContext((mlir::Attribute *)(a2 + 24));
  if (HIBYTE(*(_DWORD *)(a2 + 44))) {
    unint64_t v6 = (uint64_t *)(a2 + 16 * (((unint64_t)*(unsigned int *)(a2 + 44) >> 23) & 1) + 64);
  }
  else {
    unint64_t v6 = 0;
  }

  mlir::tensor::PackOp::populateInherentAttrs(Context, v6, a3);
}

BOOL mlir::RegisteredOperationName::Model<mlir::tensor::PackOp>::verifyInherentAttrs(uint64_t a1, uint64_t a2, uint64_t a3, void (*a4)(uint64_t *__return_ptr, uint64_t), uint64_t a5)
{
  return mlir::tensor::PackOp::verifyInherentAttrs(a2, a3, a4, a5);
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::PackOp>::getOpPropertyByteSize()
{
  return 40;
}

double mlir::RegisteredOperationName::Model<mlir::tensor::PackOp>::initProperties(uint64_t a1, uint64_t a2, uint64_t a3, long long *a4)
{
  if (a4)
  {
    long long v4 = *a4;
    long long v5 = a4[1];
    *(void *)(a3 + 32) = *((void *)a4 + 4);
    *(_OWORD *)a3 = v4;
    *(_OWORD *)(a3 + 16) = v5;
  }
  else
  {
    *(void *)(a3 + 32) = 0;
    *(void *)&long long v4 = 0;
    *(_OWORD *)a3 = 0u;
    *(_OWORD *)(a3 + 16) = 0u;
  }
  return *(double *)&v4;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::PackOp>::setPropertiesFromAttr(uint64_t a1, uint64_t a2, uint64_t *a3, uint64_t a4, void (*a5)(uint64_t *__return_ptr, uint64_t), uint64_t a6)
{
  return mlir::tensor::PackOp::setPropertiesFromAttr(a3, a4, a5, a6);
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::PackOp>::getPropertiesAsAttr(uint64_t a1, uint64_t a2)
{
  uint64_t Context = (mlir::DictionaryAttr *)mlir::Attribute::getContext((mlir::Attribute *)(a2 + 24));
  if (HIBYTE(*(_DWORD *)(a2 + 44))) {
    long long v4 = (uint64_t *)(a2 + 16 * (((unint64_t)*(unsigned int *)(a2 + 44) >> 23) & 1) + 64);
  }
  else {
    long long v4 = 0;
  }

  return mlir::tensor::PackOp::getPropertiesAsAttr(Context, v4);
}

__n128 mlir::RegisteredOperationName::Model<mlir::tensor::PackOp>::copyProperties(uint64_t a1, uint64_t a2, uint64_t a3)
{
  __n128 result = *(__n128 *)a3;
  long long v4 = *(_OWORD *)(a3 + 16);
  *(void *)(a2 + 32) = *(void *)(a3 + 32);
  *(__n128 *)a2 = result;
  *(_OWORD *)(a2 + 16) = v4;
  return result;
}

BOOL mlir::RegisteredOperationName::Model<mlir::tensor::PackOp>::compareProperties(uint64_t a1, void *a2, void *a3)
{
  if (*a3 != *a2) {
    return 0;
  }
  if (a3[1] != a2[1]) {
    return 0;
  }
  if (a3[2] != a2[2]) {
    return 0;
  }
  return a3[3] == a2[3] && a3[4] == a2[4];
}

unint64_t mlir::RegisteredOperationName::Model<mlir::tensor::PackOp>::hashProperties(uint64_t a1, unint64_t *a2)
{
  return mlir::memref::ReinterpretCastOp::computePropertiesHash(a2);
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::BytecodeOpInterfaceInterfaceTraits::Model<mlir::tensor::PackOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(0x10uLL, 0x80040803F642BuLL);
  *uint64_t v2 = mlir::detail::BytecodeOpInterfaceInterfaceTraits::Model<mlir::tensor::PackOp>::readProperties;
  v2[1] = mlir::detail::BytecodeOpInterfaceInterfaceTraits::Model<mlir::tensor::PackOp>::writeProperties;
  char v3 = &unk_267771000;
  {
    unint64_t v12 = v2;
    char v3 = (void *)&unk_267771000;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::BytecodeOpInterface]";
      unint64_t v14 = 75;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      size_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::BytecodeOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      char v3 = (void *)&unk_267771000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[312], v2);
}

uint64_t mlir::detail::BytecodeOpInterfaceInterfaceTraits::Model<mlir::tensor::PackOp>::writeProperties(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = a2;
  return mlir::tensor::PackOp::writeProperties((uint64_t)&v4, a3);
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::PackOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(0x20uLL, 0x8004018A671A6uLL);
  *uint64_t v2 = mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::PackOp>::getAsmResultNames;
  v2[1] = mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::PackOp>::getAsmBlockArgumentNames;
  v2[2] = mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::PackOp>::getAsmBlockNames;
  v2[3] = mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::PackOp>::getDefaultDialect;
  char v3 = &unk_267771000;
  {
    unint64_t v12 = v2;
    char v3 = (void *)&unk_267771000;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpAsmOpInterface]";
      unint64_t v14 = 72;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      size_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::OpAsmOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      char v3 = (void *)&unk_267771000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[346], v2);
}

uint64_t mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::PackOp>::getAsmResultNames(uint64_t a1, uint64_t a2, uint64_t (*a3)(uint64_t, uint64_t, const char *, uint64_t), uint64_t a4)
{
  uint64_t v5 = a2;
  return mlir::tensor::PackOp::getAsmResultNames((uint64_t)&v5, a3, a4);
}

char *mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::PackOp>::getDefaultDialect()
{
  return &byte_211F4AA5D;
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::DestinationStyleOpInterfaceInterfaceTraits::Model<mlir::tensor::PackOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(8uLL, 0x80040B8603338uLL);
  *uint64_t v2 = mlir::detail::DestinationStyleOpInterfaceInterfaceTraits::Model<mlir::tensor::PackOp>::getDpsInitsMutable;
  char v3 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
  {
    unint64_t v12 = v2;
    char v3 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::DestinationStyleOpInterface]";
      unint64_t v14 = 83;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      size_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::DestinationStyleOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      char v3 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[134], v2);
}

mlir::MutableOperandRange *mlir::detail::DestinationStyleOpInterfaceInterfaceTraits::Model<mlir::tensor::PackOp>::getDpsInitsMutable@<X0>(uint64_t a1@<X1>, mlir::MutableOperandRange *a2@<X8>)
{
  uint64_t v5 = a1;
  DestMutable = (mlir::OpOperand *)mlir::tensor::InsertSliceOp::getDestMutable((mlir::tensor::InsertSliceOp *)&v5);
  return mlir::MutableOperandRange::MutableOperandRange(a2, DestMutable);
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::ConditionallySpeculatableInterfaceTraits::Model<mlir::tensor::PackOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(8uLL, 0x80040B8603338uLL);
  *uint64_t v2 = mlir::detail::ConditionallySpeculatableInterfaceTraits::Model<mlir::tensor::PackOp>::getSpeculatability;
  char v3 = &unk_267771000;
  {
    unint64_t v12 = v2;
    char v3 = (void *)&unk_267771000;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ConditionallySpeculatable]";
      unint64_t v14 = 81;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      size_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::ConditionallySpeculatable,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      char v3 = (void *)&unk_267771000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[314], v2);
}

uint64_t mlir::detail::ConditionallySpeculatableInterfaceTraits::Model<mlir::tensor::PackOp>::getSpeculatability(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = a2;
  return mlir::tensor::PackOp::getSpeculatability((mlir::tensor::PackOp *)&v3);
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::MemoryEffectOpInterfaceInterfaceTraits::Model<mlir::tensor::PackOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(8uLL, 0x80040B8603338uLL);
  *uint64_t v2 = mlir::detail::MemoryEffectOpInterfaceInterfaceTraits::Model<mlir::tensor::PackOp>::getEffects;
  uint64_t v3 = &unk_267771000;
  {
    unint64_t v12 = v2;
    uint64_t v3 = (void *)&unk_267771000;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::MemoryEffectOpInterface]";
      unint64_t v14 = 79;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      size_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::MemoryEffectOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      uint64_t v3 = (void *)&unk_267771000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[11], v2);
}

void mlir::detail::MemoryEffectOpInterfaceInterfaceTraits::Model<mlir::tensor::PackOp>::getEffects(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = a2;
  ZinIrHalH13g::~ZinIrHalH13g((ZinIrHalH13g *)&v2);
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::ReifyRankedShapedTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::PackOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(8uLL, 0x80040B8603338uLL);
  *uint64_t v2 = mlir::detail::ReifyRankedShapedTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::PackOp>::reifyResultShapes;
  uint64_t v3 = &unk_267772000;
  {
    unint64_t v12 = v2;
    uint64_t v3 = (void *)&unk_267772000;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ReifyRankedShapedTypeOpInterface]";
      unint64_t v14 = 88;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      size_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::ReifyRankedShapedTypeOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      uint64_t v3 = (void *)&unk_267772000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[181], v2);
}

uint64_t mlir::detail::ReifyRankedShapedTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::PackOp>::reifyResultShapes(uint64_t a1, uint64_t a2, mlir::IndexType **a3, uint64_t a4)
{
  uint64_t v5 = a2;
  return mlir::tensor::PackOp::reifyResultShapes(&v5, a3, a4);
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::InferTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::PackOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(0x18uLL, 0x80040D6874129uLL);
  *uint64_t v2 = mlir::detail::InferTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::PackOp>::inferReturnTypes;
  v2[1] = mlir::detail::InferTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::PackOp>::refineReturnTypes;
  v2[2] = mlir::detail::InferTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::PackOp>::isCompatibleReturnTypes;
  uint64_t v3 = &unk_267771000;
  {
    unint64_t v12 = v2;
    uint64_t v3 = (void *)&unk_267771000;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::InferTypeOpInterface]";
      unint64_t v14 = 76;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      size_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::InferTypeOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      uint64_t v3 = (void *)&unk_267771000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[17], v2);
}

uint64_t mlir::detail::InferTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::PackOp>::inferReturnTypes(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11)
{
  return mlir::tensor::InsertOp::inferReturnTypes(a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, a11);
}

uint64_t mlir::detail::InferTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::PackOp>::refineReturnTypes(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11)
{
  return mlir::detail::InferTypeOpInterfaceTrait<mlir::tensor::PackOp>::refineReturnTypes(a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, a11);
}

BOOL mlir::detail::InferTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::PackOp>::isCompatibleReturnTypes(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return a2 == a4
      && std::__equal_impl[abi:nn180100]<llvm::detail::indexed_accessor_range_base<mlir::TypeRange,llvm::PointerUnion<mlir::Value const*,mlir::Type const*,mlir::OpOperand *,mlir::detail::OpResultImpl *>,mlir::Type,mlir::Type,mlir::Type>::iterator,llvm::detail::indexed_accessor_range_base<mlir::TypeRange,llvm::PointerUnion<mlir::Value const*,mlir::Type const*,mlir::OpOperand *,mlir::detail::OpResultImpl *>,mlir::Type,mlir::Type,mlir::Type>::iterator,llvm::detail::indexed_accessor_range_base<mlir::TypeRange,llvm::PointerUnion<mlir::Value const*,mlir::Type const*,mlir::OpOperand *,mlir::detail::OpResultImpl *>,mlir::Type,mlir::Type,mlir::Type>::iterator,llvm::detail::indexed_accessor_range_base<mlir::TypeRange,llvm::PointerUnion<mlir::Value const*,mlir::Type const*,mlir::OpOperand *,mlir::detail::OpResultImpl *>,mlir::Type,mlir::Type,mlir::Type>::iterator,std::__equal_to,std::__identity,std::__identity>(a1, 0, a1, a2, a3, 0, a3, a2);
}

uint64_t mlir::detail::InferTypeOpInterfaceTrait<mlir::tensor::PackOp>::refineReturnTypes(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11)
{
  char v11 = a3;
  v22[4] = *MEMORY[0x263EF8340];
  uint64_t v20 = v22;
  uint64_t v21 = 0x400000000;
  if (!mlir::tensor::InsertOp::inferReturnTypes(a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, (uint64_t)&v20))
  {
    uint64_t v13 = 0;
    unint64_t v14 = v20;
    if (v20 == v22) {
      return v13;
    }
    goto LABEL_7;
  }
  mlir::ValueRange::ValueRange((unint64_t *)&v18, (uint64_t)v20, v21);
  mlir::ValueRange::ValueRange(v17, *(void *)a11, *(unsigned int *)(a11 + 8));
  if (v19 == v17[1]
    && std::__equal_impl[abi:nn180100]<llvm::detail::indexed_accessor_range_base<mlir::TypeRange,llvm::PointerUnion<mlir::Value const*,mlir::Type const*,mlir::OpOperand *,mlir::detail::OpResultImpl *>,mlir::Type,mlir::Type,mlir::Type>::iterator,llvm::detail::indexed_accessor_range_base<mlir::TypeRange,llvm::PointerUnion<mlir::Value const*,mlir::Type const*,mlir::OpOperand *,mlir::detail::OpResultImpl *>,mlir::Type,mlir::Type,mlir::Type>::iterator,llvm::detail::indexed_accessor_range_base<mlir::TypeRange,llvm::PointerUnion<mlir::Value const*,mlir::Type const*,mlir::OpOperand *,mlir::detail::OpResultImpl *>,mlir::Type,mlir::Type,mlir::Type>::iterator,llvm::detail::indexed_accessor_range_base<mlir::TypeRange,llvm::PointerUnion<mlir::Value const*,mlir::Type const*,mlir::OpOperand *,mlir::detail::OpResultImpl *>,mlir::Type,mlir::Type,mlir::Type>::iterator,std::__equal_to,std::__identity,std::__identity>(v18, 0, v18, v19, v17[0], 0, v17[0], v19))
  {
    uint64_t v13 = 1;
    unint64_t v14 = v20;
    if (v20 == v22) {
      return v13;
    }
    goto LABEL_7;
  }
  v16[0] = "tensor.pack";
  v16[1] = 11;
  uint64_t v13 = mlir::emitOptionalError<char const(&)[2],llvm::StringLiteral,char const(&)[23],llvm::SmallVector<mlir::Type,4u> &,char const(&)[52],llvm::SmallVectorImpl<mlir::Type> &>(a2, v11, "'", (uint64_t)v16, "' op inferred type(s) ", (uint64_t)&v20, " are incompatible with return type(s) of operation ", a11);
  unint64_t v14 = v20;
  if (v20 != v22) {
LABEL_7:
  }
    free(v14);
  return v13;
}

BOOL llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &>::CallImpl<mlir::Op<mlir::tensor::PackOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1} const>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v17 = *MEMORY[0x263EF8340];
  uint64_t v13 = a2;
  mlir::tensor::detail::PackOpGenericAdaptorBase::PackOpGenericAdaptorBase((uint64_t)v14, a2);
  uint64_t v15 = a3;
  uint64_t v16 = a4;
  unint64_t v9 = mlir::tensor::PackOp::fold((uint64_t)&v13, (uint64_t)v14);
  unint64_t v10 = v9;
  if (v9 < 8 || a2 - 16 == (v9 & ((uint64_t)(v9 << 61) >> 63) & 0xFFFFFFFFFFFFFFF8)) {
    return v9 > 7;
  }
  uint64_t v11 = *(unsigned int *)(a5 + 8);
  if (v11 >= *(_DWORD *)(a5 + 12))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod(a5, (void *)(a5 + 16), v11 + 1, 8);
    LODWORD(v11) = *(_DWORD *)(a5 + 8);
  }
  *(void *)(*(void *)a5 + 8 * v11) = v10;
  ++*(_DWORD *)(a5 + 8);
  return 1;
}

BOOL llvm::detail::UniqueFunctionBase<BOOL,mlir::TypeID>::CallImpl<mlir::Op<mlir::tensor::PackOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1} const>(uint64_t a1, uint64_t a2)
{
  return mlir::op_definition_impl::hasTrait<mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>(a2);
}

BOOL mlir::op_definition_impl::hasTrait<mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>(uint64_t a1)
{
  v1 = &unk_267771000;
  {
    uint64_t v259 = a1;
    v1 = (void *)&unk_267771000;
    int v43 = v42;
    a1 = v259;
    if (v43)
    {
      uint64_t v273 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::ZeroRegions<Empty>]";
      unint64_t v274 = 83;
      unint64_t v44 = llvm::StringRef::find((uint64_t *)&v273, "DesiredTypeName = ", 0x12uLL, 0);
      if (v274 >= v44) {
        unint64_t v45 = v44;
      }
      else {
        unint64_t v45 = v274;
      }
      v46 = &v273[v45];
      unint64_t v47 = v274 - v45;
      if (v274 - v45 >= 0x12) {
        uint64_t v48 = 18;
      }
      else {
        uint64_t v48 = v274 - v45;
      }
      unint64_t v49 = v47 - v48;
      if (v49 >= v49 - 1) {
        uint64_t v50 = v49 - 1;
      }
      else {
        uint64_t v50 = v49;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::ZeroRegions<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::ZeroRegions>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v46[v48], v50);
      v1 = (void *)&unk_267771000;
      a1 = v259;
    }
  }
  uint64_t v2 = v1[23];
  uint64_t v3 = &unk_267771000;
  {
    uint64_t v246 = v2;
    uint64_t v260 = a1;
    uint64_t v3 = (void *)&unk_267771000;
    int v52 = v51;
    uint64_t v2 = v246;
    a1 = v260;
    if (v52)
    {
      uint64_t v273 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::OneResult<Empty>]";
      unint64_t v274 = 81;
      unint64_t v53 = llvm::StringRef::find((uint64_t *)&v273, "DesiredTypeName = ", 0x12uLL, 0);
      if (v274 >= v53) {
        unint64_t v54 = v53;
      }
      else {
        unint64_t v54 = v274;
      }
      unint64_t v55 = &v273[v54];
      unint64_t v56 = v274 - v54;
      if (v274 - v54 >= 0x12) {
        uint64_t v57 = 18;
      }
      else {
        uint64_t v57 = v274 - v54;
      }
      unint64_t v58 = v56 - v57;
      if (v58 >= v58 - 1) {
        uint64_t v59 = v58 - 1;
      }
      else {
        uint64_t v59 = v58;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::OneResult<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::OneResult>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v55[v57], v59);
      uint64_t v3 = (void *)&unk_267771000;
      uint64_t v2 = v246;
      a1 = v260;
    }
  }
  uint64_t v4 = v3[25];
  unint64_t v5 = &unk_267771000;
  {
    uint64_t v247 = v2;
    uint64_t v261 = a1;
    uint64_t v234 = v4;
    unint64_t v5 = (void *)&unk_267771000;
    uint64_t v4 = v234;
    uint64_t v2 = v247;
    int v61 = v60;
    a1 = v261;
    if (v61)
    {
      uint64_t v273 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl<Empty>]";
      unint64_t v274 = 116;
      unint64_t v62 = llvm::StringRef::find((uint64_t *)&v273, "DesiredTypeName = ", 0x12uLL, 0);
      if (v274 >= v62) {
        unint64_t v63 = v62;
      }
      else {
        unint64_t v63 = v274;
      }
      unint64_t v64 = &v273[v63];
      unint64_t v65 = v274 - v63;
      if (v274 - v63 >= 0x12) {
        uint64_t v66 = 18;
      }
      else {
        uint64_t v66 = v274 - v63;
      }
      unint64_t v67 = v65 - v66;
      if (v67 >= v67 - 1) {
        uint64_t v68 = v67 - 1;
      }
      else {
        uint64_t v68 = v67;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v64[v66], v68);
      unint64_t v5 = (void *)&unk_267771000;
      uint64_t v4 = v234;
      uint64_t v2 = v247;
      a1 = v261;
    }
  }
  uint64_t v6 = v5[435];
  size_t v7 = &unk_267770000;
  {
    uint64_t v248 = v2;
    uint64_t v262 = a1;
    uint64_t v223 = v6;
    uint64_t v235 = v4;
    size_t v7 = (void *)&unk_267770000;
    uint64_t v6 = v223;
    uint64_t v4 = v235;
    int v70 = v69;
    uint64_t v2 = v248;
    a1 = v262;
    if (v70)
    {
      uint64_t v273 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::ZeroSuccessors<Empty>]";
      unint64_t v274 = 86;
      unint64_t v71 = llvm::StringRef::find((uint64_t *)&v273, "DesiredTypeName = ", 0x12uLL, 0);
      if (v274 >= v71) {
        unint64_t v72 = v71;
      }
      else {
        unint64_t v72 = v274;
      }
      unint64_t v73 = &v273[v72];
      unint64_t v74 = v274 - v72;
      if (v274 - v72 >= 0x12) {
        uint64_t v75 = 18;
      }
      else {
        uint64_t v75 = v274 - v72;
      }
      unint64_t v76 = v74 - v75;
      if (v76 >= v76 - 1) {
        uint64_t v77 = v76 - 1;
      }
      else {
        uint64_t v77 = v76;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::ZeroSuccessors<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::ZeroSuccessors>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v73[v75], v77);
      size_t v7 = (void *)&unk_267770000;
      uint64_t v6 = v223;
      uint64_t v4 = v235;
      uint64_t v2 = v248;
      a1 = v262;
    }
  }
  uint64_t v8 = v7[431];
  unint64_t v9 = &unk_267771000;
  {
    uint64_t v249 = v2;
    uint64_t v263 = a1;
    uint64_t v224 = v6;
    uint64_t v236 = v4;
    uint64_t v213 = v8;
    unint64_t v9 = (void *)&unk_267771000;
    uint64_t v8 = v213;
    uint64_t v6 = v224;
    uint64_t v4 = v236;
    int v79 = v78;
    uint64_t v2 = v249;
    a1 = v263;
    if (v79)
    {
      uint64_t v273 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::AtLeastNOperands<2>::Impl<Empty>]";
      unint64_t v274 = 97;
      unint64_t v80 = llvm::StringRef::find((uint64_t *)&v273, "DesiredTypeName = ", 0x12uLL, 0);
      if (v274 >= v80) {
        unint64_t v81 = v80;
      }
      else {
        unint64_t v81 = v274;
      }
      unint64_t v82 = &v273[v81];
      unint64_t v83 = v274 - v81;
      if (v274 - v81 >= 0x12) {
        uint64_t v84 = 18;
      }
      else {
        uint64_t v84 = v274 - v81;
      }
      unint64_t v85 = v83 - v84;
      if (v85 >= v85 - 1) {
        uint64_t v86 = v85 - 1;
      }
      else {
        uint64_t v86 = v85;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::AtLeastNOperands<2u>::Impl<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::AtLeastNOperands<2u>::Impl>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v82[v84], v86);
      unint64_t v9 = (void *)&unk_267771000;
      uint64_t v8 = v213;
      uint64_t v6 = v224;
      uint64_t v4 = v236;
      uint64_t v2 = v249;
      a1 = v263;
    }
  }
  uint64_t v10 = v9[441];
  uint64_t v11 = &unk_267772000;
  {
    uint64_t v250 = v2;
    uint64_t v264 = a1;
    uint64_t v225 = v6;
    uint64_t v237 = v4;
    uint64_t v204 = v10;
    uint64_t v214 = v8;
    uint64_t v11 = (void *)&unk_267772000;
    uint64_t v10 = v204;
    uint64_t v8 = v214;
    uint64_t v6 = v225;
    uint64_t v4 = v237;
    int v88 = v87;
    uint64_t v2 = v250;
    a1 = v264;
    if (v88)
    {
      uint64_t v273 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::AttrSizedOperandSegments<Empty>]";
      unint64_t v274 = 96;
      unint64_t v89 = llvm::StringRef::find((uint64_t *)&v273, "DesiredTypeName = ", 0x12uLL, 0);
      if (v274 >= v89) {
        unint64_t v90 = v89;
      }
      else {
        unint64_t v90 = v274;
      }
      unint64_t v91 = &v273[v90];
      unint64_t v92 = v274 - v90;
      if (v274 - v90 >= 0x12) {
        uint64_t v93 = 18;
      }
      else {
        uint64_t v93 = v274 - v90;
      }
      unint64_t v94 = v92 - v93;
      if (v94 >= v94 - 1) {
        uint64_t v95 = v94 - 1;
      }
      else {
        uint64_t v95 = v94;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::AttrSizedOperandSegments<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::AttrSizedOperandSegments>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v91[v93], v95);
      uint64_t v11 = (void *)&unk_267772000;
      uint64_t v10 = v204;
      uint64_t v8 = v214;
      uint64_t v6 = v225;
      uint64_t v4 = v237;
      uint64_t v2 = v250;
      a1 = v264;
    }
  }
  uint64_t v12 = v11[47];
  uint64_t v13 = &unk_267770000;
  {
    uint64_t v251 = v2;
    uint64_t v265 = a1;
    uint64_t v226 = v6;
    uint64_t v238 = v4;
    uint64_t v205 = v10;
    uint64_t v215 = v8;
    uint64_t v196 = v12;
    uint64_t v13 = (void *)&unk_267770000;
    uint64_t v12 = v196;
    uint64_t v10 = v205;
    uint64_t v8 = v215;
    uint64_t v6 = v226;
    uint64_t v4 = v238;
    int v97 = v96;
    uint64_t v2 = v251;
    a1 = v265;
    if (v97)
    {
      uint64_t v273 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::OpInvariants<Empty>]";
      unint64_t v274 = 84;
      unint64_t v98 = llvm::StringRef::find((uint64_t *)&v273, "DesiredTypeName = ", 0x12uLL, 0);
      if (v274 >= v98) {
        unint64_t v99 = v98;
      }
      else {
        unint64_t v99 = v274;
      }
      unint64_t v100 = &v273[v99];
      unint64_t v101 = v274 - v99;
      if (v274 - v99 >= 0x12) {
        uint64_t v102 = 18;
      }
      else {
        uint64_t v102 = v274 - v99;
      }
      unint64_t v103 = v101 - v102;
      if (v103 >= v103 - 1) {
        uint64_t v104 = v103 - 1;
      }
      else {
        uint64_t v104 = v103;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::OpInvariants<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::OpInvariants>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v100[v102], v104);
      uint64_t v13 = (void *)&unk_267770000;
      uint64_t v12 = v196;
      uint64_t v10 = v205;
      uint64_t v8 = v215;
      uint64_t v6 = v226;
      uint64_t v4 = v238;
      uint64_t v2 = v251;
      a1 = v265;
    }
  }
  uint64_t v14 = v13[435];
  uint64_t v15 = &unk_267771000;
  {
    uint64_t v252 = v2;
    uint64_t v266 = a1;
    uint64_t v227 = v6;
    uint64_t v239 = v4;
    uint64_t v206 = v10;
    uint64_t v216 = v8;
    uint64_t v189 = v14;
    uint64_t v197 = v12;
    uint64_t v15 = (void *)&unk_267771000;
    uint64_t v14 = v189;
    uint64_t v12 = v197;
    uint64_t v10 = v206;
    uint64_t v8 = v216;
    uint64_t v6 = v227;
    uint64_t v4 = v239;
    int v106 = v105;
    uint64_t v2 = v252;
    a1 = v266;
    if (v106)
    {
      uint64_t v273 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::BytecodeOpInterface::Trait<Empty>]";
      unint64_t v274 = 89;
      unint64_t v107 = llvm::StringRef::find((uint64_t *)&v273, "DesiredTypeName = ", 0x12uLL, 0);
      if (v274 >= v107) {
        unint64_t v108 = v107;
      }
      else {
        unint64_t v108 = v274;
      }
      unint64_t v109 = &v273[v108];
      unint64_t v110 = v274 - v108;
      if (v274 - v108 >= 0x12) {
        uint64_t v111 = 18;
      }
      else {
        uint64_t v111 = v274 - v108;
      }
      unint64_t v112 = v110 - v111;
      if (v112 >= v112 - 1) {
        uint64_t v113 = v112 - 1;
      }
      else {
        uint64_t v113 = v112;
      }
      mlir::detail::TypeIDResolver<mlir::BytecodeOpInterface::Trait<mlir::TypeID mlir::TypeID::get<mlir::BytecodeOpInterface::Trait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v109[v111], v113);
      uint64_t v15 = (void *)&unk_267771000;
      uint64_t v14 = v189;
      uint64_t v12 = v197;
      uint64_t v10 = v206;
      uint64_t v8 = v216;
      uint64_t v6 = v227;
      uint64_t v4 = v239;
      uint64_t v2 = v252;
      a1 = v266;
    }
  }
  uint64_t v16 = v15[320];
  uint64_t v17 = &unk_267771000;
  {
    uint64_t v253 = v2;
    uint64_t v267 = a1;
    uint64_t v228 = v6;
    uint64_t v240 = v4;
    uint64_t v207 = v10;
    uint64_t v217 = v8;
    uint64_t v190 = v14;
    uint64_t v198 = v12;
    uint64_t v183 = v16;
    uint64_t v17 = (void *)&unk_267771000;
    uint64_t v16 = v183;
    uint64_t v14 = v190;
    uint64_t v12 = v198;
    uint64_t v10 = v207;
    uint64_t v8 = v217;
    uint64_t v6 = v228;
    uint64_t v4 = v240;
    int v115 = v114;
    uint64_t v2 = v253;
    a1 = v267;
    if (v115)
    {
      uint64_t v273 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpAsmOpInterface::Trait<Empty>]";
      unint64_t v274 = 86;
      unint64_t v116 = llvm::StringRef::find((uint64_t *)&v273, "DesiredTypeName = ", 0x12uLL, 0);
      if (v274 >= v116) {
        unint64_t v117 = v116;
      }
      else {
        unint64_t v117 = v274;
      }
      unint64_t v118 = &v273[v117];
      unint64_t v119 = v274 - v117;
      if (v274 - v117 >= 0x12) {
        uint64_t v120 = 18;
      }
      else {
        uint64_t v120 = v274 - v117;
      }
      unint64_t v121 = v119 - v120;
      if (v121 >= v121 - 1) {
        uint64_t v122 = v121 - 1;
      }
      else {
        uint64_t v122 = v121;
      }
      mlir::detail::TypeIDResolver<mlir::OpAsmOpInterface::Trait<mlir::TypeID mlir::TypeID::get<mlir::OpAsmOpInterface::Trait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v118[v120], v122);
      uint64_t v17 = (void *)&unk_267771000;
      uint64_t v16 = v183;
      uint64_t v14 = v190;
      uint64_t v12 = v198;
      uint64_t v10 = v207;
      uint64_t v8 = v217;
      uint64_t v6 = v228;
      uint64_t v4 = v240;
      uint64_t v2 = v253;
      a1 = v267;
    }
  }
  uint64_t v18 = v17[350];
  uint64_t v19 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
  {
    uint64_t v254 = v2;
    uint64_t v268 = a1;
    uint64_t v229 = v6;
    uint64_t v241 = v4;
    uint64_t v208 = v10;
    uint64_t v218 = v8;
    uint64_t v191 = v14;
    uint64_t v199 = v12;
    uint64_t v178 = v18;
    uint64_t v184 = v16;
    uint64_t v19 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
    uint64_t v18 = v178;
    uint64_t v16 = v184;
    uint64_t v14 = v191;
    uint64_t v12 = v199;
    uint64_t v10 = v208;
    uint64_t v8 = v218;
    uint64_t v6 = v229;
    uint64_t v4 = v241;
    int v124 = v123;
    uint64_t v2 = v254;
    a1 = v268;
    if (v124)
    {
      uint64_t v273 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::DestinationStyleOpInterface::Trait<Empty>]";
      unint64_t v274 = 97;
      unint64_t v125 = llvm::StringRef::find((uint64_t *)&v273, "DesiredTypeName = ", 0x12uLL, 0);
      if (v274 >= v125) {
        unint64_t v126 = v125;
      }
      else {
        unint64_t v126 = v274;
      }
      unint64_t v127 = &v273[v126];
      unint64_t v128 = v274 - v126;
      if (v274 - v126 >= 0x12) {
        uint64_t v129 = 18;
      }
      else {
        uint64_t v129 = v274 - v126;
      }
      unint64_t v130 = v128 - v129;
      if (v130 >= v130 - 1) {
        uint64_t v131 = v130 - 1;
      }
      else {
        uint64_t v131 = v130;
      }
      mlir::detail::TypeIDResolver<mlir::DestinationStyleOpInterface::Trait<mlir::TypeID mlir::TypeID::get<mlir::DestinationStyleOpInterface::Trait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v127[v129], v131);
      uint64_t v19 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
      uint64_t v18 = v178;
      uint64_t v16 = v184;
      uint64_t v14 = v191;
      uint64_t v12 = v199;
      uint64_t v10 = v208;
      uint64_t v8 = v218;
      uint64_t v6 = v229;
      uint64_t v4 = v241;
      uint64_t v2 = v254;
      a1 = v268;
    }
  }
  uint64_t v20 = v19[138];
  uint64_t v21 = &unk_267771000;
  {
    uint64_t v255 = v2;
    uint64_t v269 = a1;
    uint64_t v230 = v6;
    uint64_t v242 = v4;
    uint64_t v209 = v10;
    uint64_t v219 = v8;
    uint64_t v192 = v14;
    uint64_t v200 = v12;
    uint64_t v179 = v18;
    uint64_t v185 = v16;
    uint64_t v174 = v20;
    uint64_t v21 = (void *)&unk_267771000;
    uint64_t v20 = v174;
    uint64_t v18 = v179;
    uint64_t v16 = v185;
    uint64_t v14 = v192;
    uint64_t v12 = v200;
    uint64_t v10 = v209;
    uint64_t v8 = v219;
    uint64_t v6 = v230;
    uint64_t v4 = v242;
    int v133 = v132;
    uint64_t v2 = v255;
    a1 = v269;
    if (v133)
    {
      uint64_t v273 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ConditionallySpeculatable::Trait<Empty>]";
      unint64_t v274 = 95;
      unint64_t v134 = llvm::StringRef::find((uint64_t *)&v273, "DesiredTypeName = ", 0x12uLL, 0);
      if (v274 >= v134) {
        unint64_t v135 = v134;
      }
      else {
        unint64_t v135 = v274;
      }
      unint64_t v136 = &v273[v135];
      unint64_t v137 = v274 - v135;
      if (v274 - v135 >= 0x12) {
        uint64_t v138 = 18;
      }
      else {
        uint64_t v138 = v274 - v135;
      }
      unint64_t v139 = v137 - v138;
      if (v139 >= v139 - 1) {
        uint64_t v140 = v139 - 1;
      }
      else {
        uint64_t v140 = v139;
      }
      mlir::detail::TypeIDResolver<mlir::ConditionallySpeculatable::Trait<mlir::TypeID mlir::TypeID::get<mlir::ConditionallySpeculatable::Trait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v136[v138], v140);
      uint64_t v21 = (void *)&unk_267771000;
      uint64_t v20 = v174;
      uint64_t v18 = v179;
      uint64_t v16 = v185;
      uint64_t v14 = v192;
      uint64_t v12 = v200;
      uint64_t v10 = v209;
      uint64_t v8 = v219;
      uint64_t v6 = v230;
      uint64_t v4 = v242;
      uint64_t v2 = v255;
      a1 = v269;
    }
  }
  uint64_t v22 = v21[322];
  v23 = &unk_267771000;
  {
    uint64_t v256 = v2;
    uint64_t v270 = a1;
    uint64_t v231 = v6;
    uint64_t v243 = v4;
    uint64_t v210 = v10;
    uint64_t v220 = v8;
    uint64_t v193 = v14;
    uint64_t v201 = v12;
    uint64_t v180 = v18;
    uint64_t v186 = v16;
    uint64_t v171 = v22;
    uint64_t v175 = v20;
    v23 = (void *)&unk_267771000;
    uint64_t v22 = v171;
    uint64_t v20 = v175;
    uint64_t v18 = v180;
    uint64_t v16 = v186;
    uint64_t v14 = v193;
    uint64_t v12 = v201;
    uint64_t v10 = v210;
    uint64_t v8 = v220;
    uint64_t v6 = v231;
    uint64_t v4 = v243;
    int v142 = v141;
    uint64_t v2 = v256;
    a1 = v270;
    if (v142)
    {
      uint64_t v273 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::MemoryEffectOpInterface::Trait<Empty>]";
      unint64_t v274 = 93;
      unint64_t v143 = llvm::StringRef::find((uint64_t *)&v273, "DesiredTypeName = ", 0x12uLL, 0);
      if (v274 >= v143) {
        unint64_t v144 = v143;
      }
      else {
        unint64_t v144 = v274;
      }
      unint64_t v145 = &v273[v144];
      unint64_t v146 = v274 - v144;
      if (v274 - v144 >= 0x12) {
        uint64_t v147 = 18;
      }
      else {
        uint64_t v147 = v274 - v144;
      }
      unint64_t v148 = v146 - v147;
      if (v148 >= v148 - 1) {
        uint64_t v149 = v148 - 1;
      }
      else {
        uint64_t v149 = v148;
      }
      mlir::detail::TypeIDResolver<mlir::MemoryEffectOpInterface::Trait<mlir::TypeID mlir::TypeID::get<mlir::MemoryEffectOpInterface::Trait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v145[v147], v149);
      v23 = (void *)&unk_267771000;
      uint64_t v22 = v171;
      uint64_t v20 = v175;
      uint64_t v18 = v180;
      uint64_t v16 = v186;
      uint64_t v14 = v193;
      uint64_t v12 = v201;
      uint64_t v10 = v210;
      uint64_t v8 = v220;
      uint64_t v6 = v231;
      uint64_t v4 = v243;
      uint64_t v2 = v256;
      a1 = v270;
    }
  }
  uint64_t v24 = v23[31];
  v25 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
  {
    uint64_t v257 = v2;
    uint64_t v271 = a1;
    uint64_t v232 = v6;
    uint64_t v244 = v4;
    uint64_t v211 = v10;
    uint64_t v221 = v8;
    uint64_t v194 = v14;
    uint64_t v202 = v12;
    uint64_t v181 = v18;
    uint64_t v187 = v16;
    uint64_t v172 = v22;
    uint64_t v176 = v20;
    uint64_t v169 = v24;
    v25 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
    uint64_t v24 = v169;
    uint64_t v22 = v172;
    uint64_t v20 = v176;
    uint64_t v18 = v181;
    uint64_t v16 = v187;
    uint64_t v14 = v194;
    uint64_t v12 = v202;
    uint64_t v10 = v211;
    uint64_t v8 = v221;
    uint64_t v6 = v232;
    uint64_t v4 = v244;
    int v151 = v150;
    uint64_t v2 = v257;
    a1 = v271;
    if (v151)
    {
      uint64_t v273 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ReifyRankedShapedTypeOpInterface::Trait<Empty>]";
      unint64_t v274 = 102;
      unint64_t v152 = llvm::StringRef::find((uint64_t *)&v273, "DesiredTypeName = ", 0x12uLL, 0);
      if (v274 >= v152) {
        unint64_t v153 = v152;
      }
      else {
        unint64_t v153 = v274;
      }
      unint64_t v154 = &v273[v153];
      unint64_t v155 = v274 - v153;
      if (v274 - v153 >= 0x12) {
        uint64_t v156 = 18;
      }
      else {
        uint64_t v156 = v274 - v153;
      }
      unint64_t v157 = v155 - v156;
      if (v157 >= v157 - 1) {
        uint64_t v158 = v157 - 1;
      }
      else {
        uint64_t v158 = v157;
      }
      mlir::detail::TypeIDResolver<mlir::ReifyRankedShapedTypeOpInterface::Trait<mlir::TypeID mlir::TypeID::get<mlir::ReifyRankedShapedTypeOpInterface::Trait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v154[v156], v158);
      v25 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
      uint64_t v24 = v169;
      uint64_t v22 = v172;
      uint64_t v20 = v176;
      uint64_t v18 = v181;
      uint64_t v16 = v187;
      uint64_t v14 = v194;
      uint64_t v12 = v202;
      uint64_t v10 = v211;
      uint64_t v8 = v221;
      uint64_t v6 = v232;
      uint64_t v4 = v244;
      uint64_t v2 = v257;
      a1 = v271;
    }
  }
  uint64_t v26 = v25[178];
  v27 = &unk_267771000;
  {
    uint64_t v258 = v2;
    uint64_t v272 = a1;
    uint64_t v233 = v6;
    uint64_t v245 = v4;
    uint64_t v212 = v10;
    uint64_t v222 = v8;
    uint64_t v195 = v14;
    uint64_t v203 = v12;
    uint64_t v182 = v18;
    uint64_t v188 = v16;
    uint64_t v173 = v22;
    uint64_t v177 = v20;
    uint64_t v168 = v26;
    uint64_t v170 = v24;
    v27 = (void *)&unk_267771000;
    uint64_t v26 = v168;
    uint64_t v24 = v170;
    uint64_t v22 = v173;
    uint64_t v20 = v177;
    uint64_t v18 = v182;
    uint64_t v16 = v188;
    uint64_t v14 = v195;
    uint64_t v12 = v203;
    uint64_t v10 = v212;
    uint64_t v8 = v222;
    uint64_t v6 = v233;
    uint64_t v4 = v245;
    int v160 = v159;
    uint64_t v2 = v258;
    a1 = v272;
    if (v160)
    {
      uint64_t v273 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::InferTypeOpInterface::Trait<Empty>]";
      unint64_t v274 = 90;
      unint64_t v161 = llvm::StringRef::find((uint64_t *)&v273, "DesiredTypeName = ", 0x12uLL, 0);
      if (v274 >= v161) {
        unint64_t v162 = v161;
      }
      else {
        unint64_t v162 = v274;
      }
      unint64_t v163 = &v273[v162];
      unint64_t v164 = v274 - v162;
      if (v274 - v162 >= 0x12) {
        uint64_t v165 = 18;
      }
      else {
        uint64_t v165 = v274 - v162;
      }
      unint64_t v166 = v164 - v165;
      if (v166 >= v166 - 1) {
        uint64_t v167 = v166 - 1;
      }
      else {
        uint64_t v167 = v166;
      }
      mlir::detail::TypeIDResolver<mlir::InferTypeOpInterface::Trait<mlir::TypeID mlir::TypeID::get<mlir::InferTypeOpInterface::Trait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v163[v165], v167);
      v27 = (void *)&unk_267771000;
      uint64_t v26 = v168;
      uint64_t v24 = v170;
      uint64_t v22 = v173;
      uint64_t v20 = v177;
      uint64_t v18 = v182;
      uint64_t v16 = v188;
      uint64_t v14 = v195;
      uint64_t v12 = v203;
      uint64_t v10 = v212;
      uint64_t v8 = v222;
      uint64_t v6 = v233;
      uint64_t v4 = v245;
      uint64_t v2 = v258;
      a1 = v272;
    }
  }
  return v2 == a1
      || v4 == a1
      || v6 == a1
      || v8 == a1
      || v10 == a1
      || v12 == a1
      || v14 == a1
      || v16 == a1
      || v18 == a1
      || v20 == a1
      || v22 == a1
      || v24 == a1
      || v26 == a1
      || v27[37] == a1;
}

void llvm::detail::UniqueFunctionBase<void,mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef>::CallImpl<mlir::Op<mlir::tensor::PackOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1} const>(uint64_t a1, uint64_t a2, mlir::OpAsmPrinter *a3, uint64_t a4, uint64_t a5)
{
  mlir::OpState::printOpName(a2, (uint64_t)a3, a4, a5);
  uint64_t v7 = a2;
  mlir::tensor::PackOp::print((mlir::tensor::PackOp *)&v7, a3);
}

BOOL mlir::Op<mlir::tensor::PackOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::verifyInvariants(mlir::OpTrait::impl *a1, mlir::Operation *a2)
{
  if (!mlir::op_definition_impl::verifyTraits<mlir::OpTrait::ZeroRegions<mlir::tensor::PackOp>,mlir::OpTrait::OneResult<mlir::tensor::PackOp>,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl<mlir::tensor::PackOp>,mlir::OpTrait::ZeroSuccessors<mlir::tensor::PackOp>,mlir::OpTrait::AtLeastNOperands<2u>::Impl<mlir::tensor::PackOp>,mlir::OpTrait::AttrSizedOperandSegments<mlir::tensor::PackOp>,mlir::OpTrait::OpInvariants<mlir::tensor::PackOp>,mlir::BytecodeOpInterface::Trait<mlir::tensor::PackOp>,mlir::OpAsmOpInterface::Trait<mlir::tensor::PackOp>,mlir::DestinationStyleOpInterface::Trait<mlir::tensor::PackOp>,mlir::ConditionallySpeculatable::Trait<mlir::tensor::PackOp>,mlir::MemoryEffectOpInterface::Trait<mlir::tensor::PackOp>,mlir::ReifyRankedShapedTypeOpInterface::Trait<mlir::tensor::PackOp>,mlir::InferTypeOpInterface::Trait<mlir::tensor::PackOp>>(a1, a2))return 0; {
  uint64_t v4 = a1;
  }
  return mlir::tensor::PackOp::verify((mlir::tensor::PackOp *)&v4) != 0;
}

BOOL mlir::op_definition_impl::verifyTraits<mlir::OpTrait::ZeroRegions<mlir::tensor::PackOp>,mlir::OpTrait::OneResult<mlir::tensor::PackOp>,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl<mlir::tensor::PackOp>,mlir::OpTrait::ZeroSuccessors<mlir::tensor::PackOp>,mlir::OpTrait::AtLeastNOperands<2u>::Impl<mlir::tensor::PackOp>,mlir::OpTrait::AttrSizedOperandSegments<mlir::tensor::PackOp>,mlir::OpTrait::OpInvariants<mlir::tensor::PackOp>,mlir::BytecodeOpInterface::Trait<mlir::tensor::PackOp>,mlir::OpAsmOpInterface::Trait<mlir::tensor::PackOp>,mlir::DestinationStyleOpInterface::Trait<mlir::tensor::PackOp>,mlir::ConditionallySpeculatable::Trait<mlir::tensor::PackOp>,mlir::MemoryEffectOpInterface::Trait<mlir::tensor::PackOp>,mlir::ReifyRankedShapedTypeOpInterface::Trait<mlir::tensor::PackOp>,mlir::InferTypeOpInterface::Trait<mlir::tensor::PackOp>>(mlir::OpTrait::impl *a1, mlir::Operation *a2)
{
  if (!mlir::OpTrait::impl::verifyZeroRegions(a1, a2)
    || !mlir::OpTrait::impl::verifyOneResult(a1, v3)
    || !mlir::OpTrait::impl::verifyZeroSuccessors(a1, v4)
    || !mlir::OpTrait::impl::verifyAtLeastNOperands(a1, (mlir::Operation *)2)
    || !mlir::OpTrait::impl::verifyOperandSizeAttr((uint64_t)a1, "operandSegmentSizes", 0x13uLL))
  {
    return 0;
  }
  uint64_t v6 = a1;
  return mlir::tensor::PackOp::verifyInvariantsImpl((mlir::tensor::PackOp *)&v6) != 0;
}

BOOL mlir::Op<mlir::tensor::PackOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::verifyRegionInvariants(mlir::detail *a1, mlir::Operation *a2)
{
  return mlir::detail::verifyDestinationStyleOpInterface(a1, a2)
      && mlir::detail::verifyInferredResultTypes(a1, v3) != 0;
}

void *mlir::RegisteredOperationName::Model<mlir::tensor::PadOp>::Model(void *a1, uint64_t a2)
{
  v11[6] = *MEMORY[0x263EF8340];
  unint64_t v9 = v11;
  uint64_t v10 = 0x300000000;
  mlir::detail::InterfaceMap::insertModel<mlir::detail::BytecodeOpInterfaceInterfaceTraits::Model<mlir::tensor::PadOp>>((uint64_t)&v9);
  mlir::detail::InterfaceMap::insertModel<mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::PadOp>>((uint64_t)&v9);
  mlir::detail::InterfaceMap::insertModel<mlir::detail::ConditionallySpeculatableInterfaceTraits::Model<mlir::tensor::PadOp>>((uint64_t)&v9);
  mlir::detail::InterfaceMap::insertModel<mlir::detail::MemoryEffectOpInterfaceInterfaceTraits::Model<mlir::tensor::PadOp>>((uint64_t)&v9);
  mlir::OperationName::Impl::Impl(a1, (uint64_t)"tensor.pad", 10, a2, (uint64_t)&mlir::detail::TypeIDResolver<mlir::tensor::PadOp,void>::id, (uint64_t)&v9);
  uint64_t v4 = v9;
  if (v10)
  {
    uint64_t v5 = 16 * v10;
    uint64_t v6 = (void **)((char *)v9 + 8);
    do
    {
      uint64_t v7 = *v6;
      v6 += 2;
      free(v7);
      v5 -= 16;
    }
    while (v5);
    uint64_t v4 = v9;
  }
  if (v4 != v11) {
    free(v4);
  }
  *a1 = &unk_26C37AD58;
  return a1;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::PadOp>::~Model(uint64_t a1)
{
  *(void *)a1 = &unk_26C361F50;
  uint64_t v2 = *(void ***)(a1 + 32);
  uint64_t v3 = *(unsigned int *)(a1 + 40);
  if (v3)
  {
    uint64_t v4 = 16 * v3;
    uint64_t v5 = v2 + 1;
    do
    {
      uint64_t v6 = *v5;
      v5 += 2;
      free(v6);
      v4 -= 16;
    }
    while (v4);
    uint64_t v2 = *(void ***)(a1 + 32);
  }
  if (v2 != (void **)(a1 + 48)) {
    free(v2);
  }
  return a1;
}

void mlir::RegisteredOperationName::Model<mlir::tensor::PadOp>::~Model(uint64_t a1)
{
  *(void *)a1 = &unk_26C361F50;
  uint64_t v2 = *(void ***)(a1 + 32);
  uint64_t v3 = *(unsigned int *)(a1 + 40);
  if (v3)
  {
    uint64_t v4 = 16 * v3;
    uint64_t v5 = v2 + 1;
    do
    {
      uint64_t v6 = *v5;
      v5 += 2;
      free(v6);
      v4 -= 16;
    }
    while (v4);
    uint64_t v2 = *(void ***)(a1 + 32);
  }
  if (v2 != (void **)(a1 + 48)) {
    free(v2);
  }

  JUMPOUT(0x21667D3C0);
}

BOOL mlir::RegisteredOperationName::Model<mlir::tensor::PadOp>::foldHook(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v15 = *MEMORY[0x263EF8340];
  unint64_t v14 = (unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &>::CallbacksHolder<mlir::Op<mlir::tensor::PadOp,mlir::OpTrait::OneRegion,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<1u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::SingleBlock,mlir::OpTrait::SingleBlockImplicitTerminator<mlir::tensor::YieldOp>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1},mlir::Op<mlir::tensor::PadOp,mlir::OpTrait::OneRegion,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<1u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::SingleBlock,mlir::OpTrait::SingleBlockImplicitTerminator<mlir::tensor::YieldOp>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1} const,void>::Callbacks
      + 2;
  BOOL v9 = (*(BOOL (**)(uint64_t, uint64_t, uint64_t, uint64_t, uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &>::CallbacksHolder<mlir::Op<mlir::tensor::PadOp,mlir::OpTrait::OneRegion,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<1u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::SingleBlock,mlir::OpTrait::SingleBlockImplicitTerminator<mlir::tensor::YieldOp>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1},mlir::Op<mlir::tensor::PadOp,mlir::OpTrait::OneRegion,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<1u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::SingleBlock,mlir::OpTrait::SingleBlockImplicitTerminator<mlir::tensor::YieldOp>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1} const,void>::Callbacks
                                                                            + 2) & 0xFFFFFFFFFFFFFFF8))((uint64_t)v13, a2, a3, a4, a5);
  char v10 = v14;
  if (v14 >= 8)
  {
    if ((v14 & 4) != 0)
    {
      if ((v14 & 2) != 0) {
        uint64_t v11 = v13;
      }
      else {
        uint64_t v11 = (llvm **)v13[0];
      }
      (*(void (**)(uint64_t, uint64_t, uint64_t, uint64_t, uint64_t))((v14 & 0xFFFFFFFFFFFFFFF8) + 16))((uint64_t)v11, v5, v6, v7, v8);
    }
    if ((v10 & 2) == 0) {
      llvm::deallocate_buffer(v13[0], v13[1]);
    }
  }
  return v9;
}

void mlir::RegisteredOperationName::Model<mlir::tensor::PadOp>::getCanonicalizationPatterns()
{
}

BOOL mlir::RegisteredOperationName::Model<mlir::tensor::PadOp>::hasTrait(uint64_t a1, uint64_t a2)
{
  uint64_t v9 = *MEMORY[0x263EF8340];
  unint64_t v8 = (unint64_t)llvm::detail::UniqueFunctionBase<BOOL,mlir::TypeID>::CallbacksHolder<mlir::Op<mlir::tensor::PadOp,mlir::OpTrait::OneRegion,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<1u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::SingleBlock,mlir::OpTrait::SingleBlockImplicitTerminator<mlir::tensor::YieldOp>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1},mlir::Op<mlir::tensor::PadOp,mlir::OpTrait::OneRegion,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<1u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::SingleBlock,mlir::OpTrait::SingleBlockImplicitTerminator<mlir::tensor::YieldOp>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1} const,void>::Callbacks
     + 2;
  BOOL v3 = (*(BOOL (**)(uint64_t, uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<BOOL,mlir::TypeID>::CallbacksHolder<mlir::Op<mlir::tensor::PadOp,mlir::OpTrait::OneRegion,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<1u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::SingleBlock,mlir::OpTrait::SingleBlockImplicitTerminator<mlir::tensor::YieldOp>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1},mlir::Op<mlir::tensor::PadOp,mlir::OpTrait::OneRegion,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<1u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::SingleBlock,mlir::OpTrait::SingleBlockImplicitTerminator<mlir::tensor::YieldOp>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1} const,void>::Callbacks
                                                 + 2) & 0xFFFFFFFFFFFFFFF8))((uint64_t)v7, a2);
  char v4 = v8;
  if (v8 >= 8)
  {
    if ((v8 & 4) != 0)
    {
      if ((v8 & 2) != 0) {
        uint64_t v5 = v7;
      }
      else {
        uint64_t v5 = (llvm **)v7[0];
      }
      (*(void (**)(uint64_t, uint64_t))((v8 & 0xFFFFFFFFFFFFFFF8) + 16))((uint64_t)v5, v2);
    }
    if ((v4 & 2) == 0) {
      llvm::deallocate_buffer(v7[0], v7[1]);
    }
  }
  return v3;
}

void mlir::RegisteredOperationName::Model<mlir::tensor::PadOp>::getParseAssemblyFn(void (**a1)()@<X8>)
{
  *a1 = mlir::tensor::PadOp::parse;
  a1[3] = (void (*)())((char *)llvm::detail::UniqueFunctionBase<mlir::ParseResult,mlir::OpAsmParser &,mlir::OperationState &>::CallbacksHolder<mlir::ParseResult (*)(mlir::OpAsmParser &,mlir::OperationState &),mlir::ParseResult (*)(mlir::OpAsmParser &,mlir::OperationState &),void>::Callbacks
                                + 2);
}

void mlir::RegisteredOperationName::Model<mlir::tensor::PadOp>::printAssembly(uint64_t a1, uint64_t a2, mlir::OpAsmPrinter *a3, uint64_t a4, uint64_t a5)
{
  uint64_t v13 = *MEMORY[0x263EF8340];
  unint64_t v12 = (unint64_t)llvm::detail::UniqueFunctionBase<void,mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef>::CallbacksHolder<mlir::Op<mlir::tensor::PadOp,mlir::OpTrait::OneRegion,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<1u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::SingleBlock,mlir::OpTrait::SingleBlockImplicitTerminator<mlir::tensor::YieldOp>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1},mlir::Op<mlir::tensor::PadOp,mlir::OpTrait::OneRegion,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<1u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::SingleBlock,mlir::OpTrait::SingleBlockImplicitTerminator<mlir::tensor::YieldOp>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1} const,void>::Callbacks
      + 2;
  (*(void (**)(uint64_t, uint64_t, mlir::OpAsmPrinter *, uint64_t, uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<void,mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef>::CallbacksHolder<mlir::Op<mlir::tensor::PadOp,mlir::OpTrait::OneRegion,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<1u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::SingleBlock,mlir::OpTrait::SingleBlockImplicitTerminator<mlir::tensor::YieldOp>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1},mlir::Op<mlir::tensor::PadOp,mlir::OpTrait::OneRegion,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<1u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::SingleBlock,mlir::OpTrait::SingleBlockImplicitTerminator<mlir::tensor::YieldOp>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1} const,void>::Callbacks
                                                                                    + 2) & 0xFFFFFFFFFFFFFFF8))((uint64_t)v11, a2, a3, a4, a5);
  char v9 = v12;
  if (v12 >= 8)
  {
    if ((v12 & 4) != 0)
    {
      if ((v12 & 2) != 0) {
        char v10 = v11;
      }
      else {
        char v10 = (llvm **)v11[0];
      }
      (*(void (**)(uint64_t, uint64_t, mlir::OpAsmPrinter *, uint64_t, uint64_t))((v12 & 0xFFFFFFFFFFFFFFF8)
                                                                                       + 16))((uint64_t)v10, v5, v6, v7, v8);
    }
    if ((v9 & 2) == 0) {
      llvm::deallocate_buffer(v11[0], v11[1]);
    }
  }
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::PadOp>::verifyInvariants(uint64_t a1, uint64_t a2)
{
  uint64_t v7 = *MEMORY[0x263EF8340];
  v5[0] = (uint64_t (*)(uint64_t))mlir::Op<mlir::tensor::PadOp,mlir::OpTrait::OneRegion,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<1u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::SingleBlock,mlir::OpTrait::SingleBlockImplicitTerminator<mlir::tensor::YieldOp>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::verifyInvariants;
  unint64_t v6 = (unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *>::CallbacksHolder<mlir::LogicalResult (*)(mlir::Operation *),mlir::LogicalResult (* const)(mlir::Operation *),void>::Callbacks
     + 2;
  uint64_t v2 = (*(uint64_t (**)(uint64_t (**)(uint64_t), uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *>::CallbacksHolder<mlir::LogicalResult (*)(mlir::Operation *),mlir::LogicalResult (* const)(mlir::Operation *),void>::Callbacks
                                                                             + 2) & 0xFFFFFFFFFFFFFFF8))(v5, a2);
  char v3 = v6;
  if (v6 >= 8)
  {
    if ((v6 & 4) != 0) {
      (*(void (__cdecl **)())((v6 & 0xFFFFFFFFFFFFFFF8) + 16))();
    }
    if ((v3 & 2) == 0) {
      llvm::deallocate_buffer((llvm *)v5[0], v5[1]);
    }
  }
  return v2;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::PadOp>::verifyRegionInvariants(uint64_t a1, uint64_t a2)
{
  uint64_t v7 = *MEMORY[0x263EF8340];
  v5[0] = (uint64_t (*)(uint64_t))mlir::Op<mlir::tensor::PadOp,mlir::OpTrait::OneRegion,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<1u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::SingleBlock,mlir::OpTrait::SingleBlockImplicitTerminator<mlir::tensor::YieldOp>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::verifyRegionInvariants;
  unint64_t v6 = (unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *>::CallbacksHolder<mlir::LogicalResult (*)(mlir::Operation *),mlir::LogicalResult (* const)(mlir::Operation *),void>::Callbacks
     + 2;
  uint64_t v2 = (*(uint64_t (**)(uint64_t (**)(uint64_t), uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *>::CallbacksHolder<mlir::LogicalResult (*)(mlir::Operation *),mlir::LogicalResult (* const)(mlir::Operation *),void>::Callbacks
                                                                             + 2) & 0xFFFFFFFFFFFFFFF8))(v5, a2);
  char v3 = v6;
  if (v6 >= 8)
  {
    if ((v6 & 4) != 0) {
      (*(void (__cdecl **)())((v6 & 0xFFFFFFFFFFFFFFF8) + 16))();
    }
    if ((v3 & 2) == 0) {
      llvm::deallocate_buffer((llvm *)v5[0], v5[1]);
    }
  }
  return v2;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::PadOp>::getInherentAttr(uint64_t a1, uint64_t a2, _WORD *a3, size_t a4)
{
  uint64_t Context = (mlir::MLIRContext *)mlir::Attribute::getContext((mlir::Attribute *)(a2 + 24));
  if (HIBYTE(*(_DWORD *)(a2 + 44))) {
    uint64_t v8 = (void *)(a2 + 16 * (((unint64_t)*(unsigned int *)(a2 + 44) >> 23) & 1) + 64);
  }
  else {
    uint64_t v8 = 0;
  }

  return mlir::tensor::PadOp::getInherentAttr(Context, v8, a3, a4);
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::PadOp>::setInherentAttr(uint64_t a1, uint64_t a2, uint64_t a3, void *a4)
{
  uint64_t v9 = a3;
  if (HIBYTE(*(_DWORD *)(a2 + 44))) {
    uint64_t v5 = a2 + 16 * (((unint64_t)*(unsigned int *)(a2 + 44) >> 23) & 1) + 64;
  }
  else {
    uint64_t v5 = 0;
  }
  AttrData = (_WORD *)mlir::OpaqueAttr::getAttrData((mlir::OpaqueAttr *)&v9);
  return mlir::tensor::PadOp::setInherentAttr(v5, AttrData, v7, a4);
}

void mlir::RegisteredOperationName::Model<mlir::tensor::PadOp>::populateInherentAttrs(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t Context = (mlir::MLIRContext *)mlir::Attribute::getContext((mlir::Attribute *)(a2 + 24));
  if (HIBYTE(*(_DWORD *)(a2 + 44))) {
    unint64_t v6 = (uint64_t *)(a2 + 16 * (((unint64_t)*(unsigned int *)(a2 + 44) >> 23) & 1) + 64);
  }
  else {
    unint64_t v6 = 0;
  }

  mlir::tensor::PadOp::populateInherentAttrs(Context, v6, a3);
}

BOOL mlir::RegisteredOperationName::Model<mlir::tensor::PadOp>::verifyInherentAttrs(uint64_t a1, uint64_t a2, uint64_t a3, void (*a4)(uint64_t *__return_ptr, uint64_t), uint64_t a5)
{
  return mlir::tensor::PadOp::verifyInherentAttrs(a2, a3, a4, a5);
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::PadOp>::getOpPropertyByteSize()
{
  return 40;
}

double mlir::RegisteredOperationName::Model<mlir::tensor::PadOp>::initProperties(uint64_t a1, uint64_t a2, uint64_t a3, long long *a4)
{
  if (a4)
  {
    long long v4 = *a4;
    long long v5 = a4[1];
    *(void *)(a3 + 32) = *((void *)a4 + 4);
    *(_OWORD *)a3 = v4;
    *(_OWORD *)(a3 + 16) = v5;
  }
  else
  {
    *(void *)(a3 + 32) = 0;
    *(void *)&long long v4 = 0;
    *(_OWORD *)a3 = 0u;
    *(_OWORD *)(a3 + 16) = 0u;
  }
  return *(double *)&v4;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::PadOp>::setPropertiesFromAttr(uint64_t a1, uint64_t a2, uint64_t *a3, uint64_t a4, void (*a5)(uint64_t *__return_ptr, uint64_t), uint64_t a6)
{
  return mlir::tensor::PadOp::setPropertiesFromAttr(a3, a4, a5, a6);
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::PadOp>::getPropertiesAsAttr(uint64_t a1, uint64_t a2)
{
  uint64_t Context = (mlir::DictionaryAttr *)mlir::Attribute::getContext((mlir::Attribute *)(a2 + 24));
  if (HIBYTE(*(_DWORD *)(a2 + 44))) {
    long long v4 = (uint64_t *)(a2 + 16 * (((unint64_t)*(unsigned int *)(a2 + 44) >> 23) & 1) + 64);
  }
  else {
    long long v4 = 0;
  }

  return mlir::tensor::PadOp::getPropertiesAsAttr(Context, v4);
}

__n128 mlir::RegisteredOperationName::Model<mlir::tensor::PadOp>::copyProperties(uint64_t a1, uint64_t a2, uint64_t a3)
{
  __n128 result = *(__n128 *)a3;
  long long v4 = *(_OWORD *)(a3 + 16);
  *(_DWORD *)(a2 + 32) = *(_DWORD *)(a3 + 32);
  *(__n128 *)a2 = result;
  *(_OWORD *)(a2 + 16) = v4;
  return result;
}

BOOL mlir::RegisteredOperationName::Model<mlir::tensor::PadOp>::compareProperties(uint64_t a1, uint64_t a2, uint64_t a3)
{
  if (*(void *)a3 != *(void *)a2) {
    return 0;
  }
  if (*(void *)(a3 + 8) != *(void *)(a2 + 8)) {
    return 0;
  }
  if (*(void *)(a3 + 16) != *(void *)(a2 + 16)) {
    return 0;
  }
  return *(void *)(a3 + 24) == *(void *)(a2 + 24)
      && *(_DWORD *)(a3 + 32) == (unint64_t)*(unsigned int *)(a2 + 32);
}

unint64_t mlir::RegisteredOperationName::Model<mlir::tensor::PadOp>::hashProperties(uint64_t a1, unint64_t *a2)
{
  return mlir::pdl_interp::CreateOperationOp::computePropertiesHash(a2);
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::BytecodeOpInterfaceInterfaceTraits::Model<mlir::tensor::PadOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(0x10uLL, 0x80040803F642BuLL);
  *uint64_t v2 = mlir::detail::BytecodeOpInterfaceInterfaceTraits::Model<mlir::tensor::PadOp>::readProperties;
  v2[1] = mlir::detail::BytecodeOpInterfaceInterfaceTraits::Model<mlir::tensor::PadOp>::writeProperties;
  char v3 = &unk_267771000;
  {
    unint64_t v12 = v2;
    char v3 = (void *)&unk_267771000;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::BytecodeOpInterface]";
      unint64_t v14 = 75;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      size_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::BytecodeOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      char v3 = (void *)&unk_267771000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[312], v2);
}

uint64_t mlir::detail::BytecodeOpInterfaceInterfaceTraits::Model<mlir::tensor::PadOp>::writeProperties(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = a2;
  return mlir::tensor::PadOp::writeProperties((uint64_t)&v4, a3);
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::PadOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(0x20uLL, 0x8004018A671A6uLL);
  *uint64_t v2 = mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::PadOp>::getAsmResultNames;
  v2[1] = mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::PadOp>::getAsmBlockArgumentNames;
  v2[2] = mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::PadOp>::getAsmBlockNames;
  v2[3] = mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::PadOp>::getDefaultDialect;
  char v3 = &unk_267771000;
  {
    unint64_t v12 = v2;
    char v3 = (void *)&unk_267771000;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpAsmOpInterface]";
      unint64_t v14 = 72;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      size_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::OpAsmOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      char v3 = (void *)&unk_267771000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[346], v2);
}

uint64_t mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::PadOp>::getAsmResultNames(uint64_t a1, uint64_t a2, uint64_t (*a3)(uint64_t, uint64_t, const char *, uint64_t), uint64_t a4)
{
  uint64_t v5 = a2;
  return mlir::tensor::PadOp::getAsmResultNames((uint64_t)&v5, a3, a4);
}

char *mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::PadOp>::getDefaultDialect()
{
  return &byte_211F4AA5D;
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::ConditionallySpeculatableInterfaceTraits::Model<mlir::tensor::PadOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(8uLL, 0x80040B8603338uLL);
  *uint64_t v2 = mlir::detail::ConditionallySpeculatableInterfaceTraits::Model<mlir::tensor::PadOp>::getSpeculatability;
  char v3 = &unk_267771000;
  {
    unint64_t v12 = v2;
    char v3 = (void *)&unk_267771000;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ConditionallySpeculatable]";
      unint64_t v14 = 81;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      size_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::ConditionallySpeculatable,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      char v3 = (void *)&unk_267771000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[314], v2);
}

uint64_t mlir::detail::ConditionallySpeculatableInterfaceTraits::Model<mlir::tensor::PadOp>::getSpeculatability()
{
  return 1;
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::MemoryEffectOpInterfaceInterfaceTraits::Model<mlir::tensor::PadOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(8uLL, 0x80040B8603338uLL);
  *uint64_t v2 = mlir::detail::MemoryEffectOpInterfaceInterfaceTraits::Model<mlir::tensor::PadOp>::getEffects;
  char v3 = &unk_267771000;
  {
    unint64_t v12 = v2;
    char v3 = (void *)&unk_267771000;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::MemoryEffectOpInterface]";
      unint64_t v14 = 79;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      size_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::MemoryEffectOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      char v3 = (void *)&unk_267771000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[11], v2);
}

void mlir::detail::MemoryEffectOpInterfaceInterfaceTraits::Model<mlir::tensor::PadOp>::getEffects(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = a2;
  ZinIrHalH13g::~ZinIrHalH13g((ZinIrHalH13g *)&v2);
}

BOOL llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &>::CallImpl<mlir::Op<mlir::tensor::PadOp,mlir::OpTrait::OneRegion,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<1u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::SingleBlock,mlir::OpTrait::SingleBlockImplicitTerminator<mlir::tensor::YieldOp>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1} const>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v17 = *MEMORY[0x263EF8340];
  uint64_t v13 = a2;
  mlir::tensor::detail::PadOpGenericAdaptorBase::PadOpGenericAdaptorBase((uint64_t)v14, a2);
  uint64_t v15 = a3;
  uint64_t v16 = a4;
  unint64_t v9 = mlir::tensor::PadOp::fold((uint64_t)&v13);
  unint64_t v10 = v9;
  if (v9 < 8 || a2 - 16 == (v9 & ((uint64_t)(v9 << 61) >> 63) & 0xFFFFFFFFFFFFFFF8)) {
    return v9 > 7;
  }
  uint64_t v11 = *(unsigned int *)(a5 + 8);
  if (v11 >= *(_DWORD *)(a5 + 12))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod(a5, (void *)(a5 + 16), v11 + 1, 8);
    LODWORD(v11) = *(_DWORD *)(a5 + 8);
  }
  *(void *)(*(void *)a5 + 8 * v11) = v10;
  ++*(_DWORD *)(a5 + 8);
  return 1;
}

BOOL llvm::detail::UniqueFunctionBase<BOOL,mlir::TypeID>::CallImpl<mlir::Op<mlir::tensor::PadOp,mlir::OpTrait::OneRegion,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<1u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::SingleBlock,mlir::OpTrait::SingleBlockImplicitTerminator<mlir::tensor::YieldOp>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1} const>(uint64_t a1, uint64_t a2)
{
  return mlir::op_definition_impl::hasTrait<mlir::OpTrait::OneRegion,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<1u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::SingleBlock,mlir::OpTrait::SingleBlockImplicitTerminator<mlir::tensor::YieldOp>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>(a2);
}

BOOL mlir::op_definition_impl::hasTrait<mlir::OpTrait::OneRegion,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<1u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::SingleBlock,mlir::OpTrait::SingleBlockImplicitTerminator<mlir::tensor::YieldOp>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>(uint64_t a1)
{
  v1 = &unk_267770000;
  {
    uint64_t v259 = a1;
    v1 = (void *)&unk_267770000;
    int v43 = v42;
    a1 = v259;
    if (v43)
    {
      uint64_t v273 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::OneRegion<Empty>]";
      unint64_t v274 = 81;
      unint64_t v44 = llvm::StringRef::find((uint64_t *)&v273, "DesiredTypeName = ", 0x12uLL, 0);
      if (v274 >= v44) {
        unint64_t v45 = v44;
      }
      else {
        unint64_t v45 = v274;
      }
      v46 = &v273[v45];
      unint64_t v47 = v274 - v45;
      if (v274 - v45 >= 0x12) {
        uint64_t v48 = 18;
      }
      else {
        uint64_t v48 = v274 - v45;
      }
      unint64_t v49 = v47 - v48;
      if (v49 >= v49 - 1) {
        uint64_t v50 = v49 - 1;
      }
      else {
        uint64_t v50 = v49;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::OneRegion<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::OneRegion>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v46[v48], v50);
      v1 = (void *)&unk_267770000;
      a1 = v259;
    }
  }
  uint64_t v2 = v1[427];
  char v3 = &unk_267771000;
  {
    uint64_t v246 = v2;
    uint64_t v260 = a1;
    char v3 = (void *)&unk_267771000;
    int v52 = v51;
    uint64_t v2 = v246;
    a1 = v260;
    if (v52)
    {
      uint64_t v273 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::OneResult<Empty>]";
      unint64_t v274 = 81;
      unint64_t v53 = llvm::StringRef::find((uint64_t *)&v273, "DesiredTypeName = ", 0x12uLL, 0);
      if (v274 >= v53) {
        unint64_t v54 = v53;
      }
      else {
        unint64_t v54 = v274;
      }
      unint64_t v55 = &v273[v54];
      unint64_t v56 = v274 - v54;
      if (v274 - v54 >= 0x12) {
        uint64_t v57 = 18;
      }
      else {
        uint64_t v57 = v274 - v54;
      }
      unint64_t v58 = v56 - v57;
      if (v58 >= v58 - 1) {
        uint64_t v59 = v58 - 1;
      }
      else {
        uint64_t v59 = v58;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::OneResult<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::OneResult>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v55[v57], v59);
      char v3 = (void *)&unk_267771000;
      uint64_t v2 = v246;
      a1 = v260;
    }
  }
  uint64_t v4 = v3[25];
  unint64_t v5 = &unk_267771000;
  {
    uint64_t v247 = v2;
    uint64_t v261 = a1;
    uint64_t v234 = v4;
    unint64_t v5 = (void *)&unk_267771000;
    uint64_t v4 = v234;
    uint64_t v2 = v247;
    int v61 = v60;
    a1 = v261;
    if (v61)
    {
      uint64_t v273 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl<Empty>]";
      unint64_t v274 = 116;
      unint64_t v62 = llvm::StringRef::find((uint64_t *)&v273, "DesiredTypeName = ", 0x12uLL, 0);
      if (v274 >= v62) {
        unint64_t v63 = v62;
      }
      else {
        unint64_t v63 = v274;
      }
      unint64_t v64 = &v273[v63];
      unint64_t v65 = v274 - v63;
      if (v274 - v63 >= 0x12) {
        uint64_t v66 = 18;
      }
      else {
        uint64_t v66 = v274 - v63;
      }
      unint64_t v67 = v65 - v66;
      if (v67 >= v67 - 1) {
        uint64_t v68 = v67 - 1;
      }
      else {
        uint64_t v68 = v67;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v64[v66], v68);
      unint64_t v5 = (void *)&unk_267771000;
      uint64_t v4 = v234;
      uint64_t v2 = v247;
      a1 = v261;
    }
  }
  uint64_t v6 = v5[435];
  size_t v7 = &unk_267770000;
  {
    uint64_t v248 = v2;
    uint64_t v262 = a1;
    uint64_t v223 = v6;
    uint64_t v235 = v4;
    size_t v7 = (void *)&unk_267770000;
    uint64_t v6 = v223;
    uint64_t v4 = v235;
    int v70 = v69;
    uint64_t v2 = v248;
    a1 = v262;
    if (v70)
    {
      uint64_t v273 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::ZeroSuccessors<Empty>]";
      unint64_t v274 = 86;
      unint64_t v71 = llvm::StringRef::find((uint64_t *)&v273, "DesiredTypeName = ", 0x12uLL, 0);
      if (v274 >= v71) {
        unint64_t v72 = v71;
      }
      else {
        unint64_t v72 = v274;
      }
      unint64_t v73 = &v273[v72];
      unint64_t v74 = v274 - v72;
      if (v274 - v72 >= 0x12) {
        uint64_t v75 = 18;
      }
      else {
        uint64_t v75 = v274 - v72;
      }
      unint64_t v76 = v74 - v75;
      if (v76 >= v76 - 1) {
        uint64_t v77 = v76 - 1;
      }
      else {
        uint64_t v77 = v76;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::ZeroSuccessors<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::ZeroSuccessors>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v73[v75], v77);
      size_t v7 = (void *)&unk_267770000;
      uint64_t v6 = v223;
      uint64_t v4 = v235;
      uint64_t v2 = v248;
      a1 = v262;
    }
  }
  uint64_t v8 = v7[431];
  unint64_t v9 = &unk_267771000;
  {
    uint64_t v249 = v2;
    uint64_t v263 = a1;
    uint64_t v224 = v6;
    uint64_t v236 = v4;
    uint64_t v213 = v8;
    unint64_t v9 = (void *)&unk_267771000;
    uint64_t v8 = v213;
    uint64_t v6 = v224;
    uint64_t v4 = v236;
    int v79 = v78;
    uint64_t v2 = v249;
    a1 = v263;
    if (v79)
    {
      uint64_t v273 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::AtLeastNOperands<1>::Impl<Empty>]";
      unint64_t v274 = 97;
      unint64_t v80 = llvm::StringRef::find((uint64_t *)&v273, "DesiredTypeName = ", 0x12uLL, 0);
      if (v274 >= v80) {
        unint64_t v81 = v80;
      }
      else {
        unint64_t v81 = v274;
      }
      unint64_t v82 = &v273[v81];
      unint64_t v83 = v274 - v81;
      if (v274 - v81 >= 0x12) {
        uint64_t v84 = 18;
      }
      else {
        uint64_t v84 = v274 - v81;
      }
      unint64_t v85 = v83 - v84;
      if (v85 >= v85 - 1) {
        uint64_t v86 = v85 - 1;
      }
      else {
        uint64_t v86 = v85;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::AtLeastNOperands<1u>::Impl<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::AtLeastNOperands<1u>::Impl>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v82[v84], v86);
      unint64_t v9 = (void *)&unk_267771000;
      uint64_t v8 = v213;
      uint64_t v6 = v224;
      uint64_t v4 = v236;
      uint64_t v2 = v249;
      a1 = v263;
    }
  }
  uint64_t v10 = v9[433];
  uint64_t v11 = &unk_267772000;
  {
    uint64_t v250 = v2;
    uint64_t v264 = a1;
    uint64_t v225 = v6;
    uint64_t v237 = v4;
    uint64_t v204 = v10;
    uint64_t v214 = v8;
    uint64_t v11 = (void *)&unk_267772000;
    uint64_t v10 = v204;
    uint64_t v8 = v214;
    uint64_t v6 = v225;
    uint64_t v4 = v237;
    int v88 = v87;
    uint64_t v2 = v250;
    a1 = v264;
    if (v88)
    {
      uint64_t v273 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::AttrSizedOperandSegments<Empty>]";
      unint64_t v274 = 96;
      unint64_t v89 = llvm::StringRef::find((uint64_t *)&v273, "DesiredTypeName = ", 0x12uLL, 0);
      if (v274 >= v89) {
        unint64_t v90 = v89;
      }
      else {
        unint64_t v90 = v274;
      }
      unint64_t v91 = &v273[v90];
      unint64_t v92 = v274 - v90;
      if (v274 - v90 >= 0x12) {
        uint64_t v93 = 18;
      }
      else {
        uint64_t v93 = v274 - v90;
      }
      unint64_t v94 = v92 - v93;
      if (v94 >= v94 - 1) {
        uint64_t v95 = v94 - 1;
      }
      else {
        uint64_t v95 = v94;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::AttrSizedOperandSegments<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::AttrSizedOperandSegments>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v91[v93], v95);
      uint64_t v11 = (void *)&unk_267772000;
      uint64_t v10 = v204;
      uint64_t v8 = v214;
      uint64_t v6 = v225;
      uint64_t v4 = v237;
      uint64_t v2 = v250;
      a1 = v264;
    }
  }
  uint64_t v12 = v11[47];
  uint64_t v13 = &unk_267771000;
  {
    uint64_t v251 = v2;
    uint64_t v265 = a1;
    uint64_t v226 = v6;
    uint64_t v238 = v4;
    uint64_t v205 = v10;
    uint64_t v215 = v8;
    uint64_t v196 = v12;
    uint64_t v13 = (void *)&unk_267771000;
    uint64_t v12 = v196;
    uint64_t v10 = v205;
    uint64_t v8 = v215;
    uint64_t v6 = v226;
    uint64_t v4 = v238;
    int v97 = v96;
    uint64_t v2 = v251;
    a1 = v265;
    if (v97)
    {
      uint64_t v273 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::SingleBlock<Empty>]";
      unint64_t v274 = 83;
      unint64_t v98 = llvm::StringRef::find((uint64_t *)&v273, "DesiredTypeName = ", 0x12uLL, 0);
      if (v274 >= v98) {
        unint64_t v99 = v98;
      }
      else {
        unint64_t v99 = v274;
      }
      unint64_t v100 = &v273[v99];
      unint64_t v101 = v274 - v99;
      if (v274 - v99 >= 0x12) {
        uint64_t v102 = 18;
      }
      else {
        uint64_t v102 = v274 - v99;
      }
      unint64_t v103 = v101 - v102;
      if (v103 >= v103 - 1) {
        uint64_t v104 = v103 - 1;
      }
      else {
        uint64_t v104 = v103;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::SingleBlock<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::SingleBlock>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v100[v102], v104);
      uint64_t v13 = (void *)&unk_267771000;
      uint64_t v12 = v196;
      uint64_t v10 = v205;
      uint64_t v8 = v215;
      uint64_t v6 = v226;
      uint64_t v4 = v238;
      uint64_t v2 = v251;
      a1 = v265;
    }
  }
  uint64_t v14 = v13[443];
  uint64_t v15 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
  {
    uint64_t v252 = v2;
    uint64_t v266 = a1;
    uint64_t v227 = v6;
    uint64_t v239 = v4;
    uint64_t v206 = v10;
    uint64_t v216 = v8;
    uint64_t v189 = v14;
    uint64_t v197 = v12;
    uint64_t v15 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
    uint64_t v14 = v189;
    uint64_t v12 = v197;
    uint64_t v10 = v206;
    uint64_t v8 = v216;
    uint64_t v6 = v227;
    uint64_t v4 = v239;
    int v106 = v105;
    uint64_t v2 = v252;
    a1 = v266;
    if (v106)
    {
      uint64_t v273 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::SingleBlockImplicitTerminator<mlir::tensor:"
             ":YieldOp>::Impl<Empty>]";
      unint64_t v274 = 130;
      unint64_t v107 = llvm::StringRef::find((uint64_t *)&v273, "DesiredTypeName = ", 0x12uLL, 0);
      if (v274 >= v107) {
        unint64_t v108 = v107;
      }
      else {
        unint64_t v108 = v274;
      }
      unint64_t v109 = &v273[v108];
      unint64_t v110 = v274 - v108;
      if (v274 - v108 >= 0x12) {
        uint64_t v111 = 18;
      }
      else {
        uint64_t v111 = v274 - v108;
      }
      unint64_t v112 = v110 - v111;
      if (v112 >= v112 - 1) {
        uint64_t v113 = v112 - 1;
      }
      else {
        uint64_t v113 = v112;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::SingleBlockImplicitTerminator<mlir::tensor::YieldOp>::Impl<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::SingleBlockImplicitTerminator<mlir::tensor::YieldOp>::Impl>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v109[v111], v113);
      uint64_t v15 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
      uint64_t v14 = v189;
      uint64_t v12 = v197;
      uint64_t v10 = v206;
      uint64_t v8 = v216;
      uint64_t v6 = v227;
      uint64_t v4 = v239;
      uint64_t v2 = v252;
      a1 = v266;
    }
  }
  uint64_t v16 = v15[194];
  uint64_t v17 = &unk_267770000;
  {
    uint64_t v253 = v2;
    uint64_t v267 = a1;
    uint64_t v228 = v6;
    uint64_t v240 = v4;
    uint64_t v207 = v10;
    uint64_t v217 = v8;
    uint64_t v190 = v14;
    uint64_t v198 = v12;
    uint64_t v183 = v16;
    uint64_t v17 = (void *)&unk_267770000;
    uint64_t v16 = v183;
    uint64_t v14 = v190;
    uint64_t v12 = v198;
    uint64_t v10 = v207;
    uint64_t v8 = v217;
    uint64_t v6 = v228;
    uint64_t v4 = v240;
    int v115 = v114;
    uint64_t v2 = v253;
    a1 = v267;
    if (v115)
    {
      uint64_t v273 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::OpInvariants<Empty>]";
      unint64_t v274 = 84;
      unint64_t v116 = llvm::StringRef::find((uint64_t *)&v273, "DesiredTypeName = ", 0x12uLL, 0);
      if (v274 >= v116) {
        unint64_t v117 = v116;
      }
      else {
        unint64_t v117 = v274;
      }
      unint64_t v118 = &v273[v117];
      unint64_t v119 = v274 - v117;
      if (v274 - v117 >= 0x12) {
        uint64_t v120 = 18;
      }
      else {
        uint64_t v120 = v274 - v117;
      }
      unint64_t v121 = v119 - v120;
      if (v121 >= v121 - 1) {
        uint64_t v122 = v121 - 1;
      }
      else {
        uint64_t v122 = v121;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::OpInvariants<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::OpInvariants>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v118[v120], v122);
      uint64_t v17 = (void *)&unk_267770000;
      uint64_t v16 = v183;
      uint64_t v14 = v190;
      uint64_t v12 = v198;
      uint64_t v10 = v207;
      uint64_t v8 = v217;
      uint64_t v6 = v228;
      uint64_t v4 = v240;
      uint64_t v2 = v253;
      a1 = v267;
    }
  }
  uint64_t v18 = v17[435];
  uint64_t v19 = &unk_267771000;
  {
    uint64_t v254 = v2;
    uint64_t v268 = a1;
    uint64_t v229 = v6;
    uint64_t v241 = v4;
    uint64_t v208 = v10;
    uint64_t v218 = v8;
    uint64_t v191 = v14;
    uint64_t v199 = v12;
    uint64_t v178 = v18;
    uint64_t v184 = v16;
    uint64_t v19 = (void *)&unk_267771000;
    uint64_t v18 = v178;
    uint64_t v16 = v184;
    uint64_t v14 = v191;
    uint64_t v12 = v199;
    uint64_t v10 = v208;
    uint64_t v8 = v218;
    uint64_t v6 = v229;
    uint64_t v4 = v241;
    int v124 = v123;
    uint64_t v2 = v254;
    a1 = v268;
    if (v124)
    {
      uint64_t v273 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::BytecodeOpInterface::Trait<Empty>]";
      unint64_t v274 = 89;
      unint64_t v125 = llvm::StringRef::find((uint64_t *)&v273, "DesiredTypeName = ", 0x12uLL, 0);
      if (v274 >= v125) {
        unint64_t v126 = v125;
      }
      else {
        unint64_t v126 = v274;
      }
      unint64_t v127 = &v273[v126];
      unint64_t v128 = v274 - v126;
      if (v274 - v126 >= 0x12) {
        uint64_t v129 = 18;
      }
      else {
        uint64_t v129 = v274 - v126;
      }
      unint64_t v130 = v128 - v129;
      if (v130 >= v130 - 1) {
        uint64_t v131 = v130 - 1;
      }
      else {
        uint64_t v131 = v130;
      }
      mlir::detail::TypeIDResolver<mlir::BytecodeOpInterface::Trait<mlir::TypeID mlir::TypeID::get<mlir::BytecodeOpInterface::Trait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v127[v129], v131);
      uint64_t v19 = (void *)&unk_267771000;
      uint64_t v18 = v178;
      uint64_t v16 = v184;
      uint64_t v14 = v191;
      uint64_t v12 = v199;
      uint64_t v10 = v208;
      uint64_t v8 = v218;
      uint64_t v6 = v229;
      uint64_t v4 = v241;
      uint64_t v2 = v254;
      a1 = v268;
    }
  }
  uint64_t v20 = v19[320];
  uint64_t v21 = &unk_267771000;
  {
    uint64_t v255 = v2;
    uint64_t v269 = a1;
    uint64_t v230 = v6;
    uint64_t v242 = v4;
    uint64_t v209 = v10;
    uint64_t v219 = v8;
    uint64_t v192 = v14;
    uint64_t v200 = v12;
    uint64_t v179 = v18;
    uint64_t v185 = v16;
    uint64_t v174 = v20;
    uint64_t v21 = (void *)&unk_267771000;
    uint64_t v20 = v174;
    uint64_t v18 = v179;
    uint64_t v16 = v185;
    uint64_t v14 = v192;
    uint64_t v12 = v200;
    uint64_t v10 = v209;
    uint64_t v8 = v219;
    uint64_t v6 = v230;
    uint64_t v4 = v242;
    int v133 = v132;
    uint64_t v2 = v255;
    a1 = v269;
    if (v133)
    {
      uint64_t v273 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpAsmOpInterface::Trait<Empty>]";
      unint64_t v274 = 86;
      unint64_t v134 = llvm::StringRef::find((uint64_t *)&v273, "DesiredTypeName = ", 0x12uLL, 0);
      if (v274 >= v134) {
        unint64_t v135 = v134;
      }
      else {
        unint64_t v135 = v274;
      }
      unint64_t v136 = &v273[v135];
      unint64_t v137 = v274 - v135;
      if (v274 - v135 >= 0x12) {
        uint64_t v138 = 18;
      }
      else {
        uint64_t v138 = v274 - v135;
      }
      unint64_t v139 = v137 - v138;
      if (v139 >= v139 - 1) {
        uint64_t v140 = v139 - 1;
      }
      else {
        uint64_t v140 = v139;
      }
      mlir::detail::TypeIDResolver<mlir::OpAsmOpInterface::Trait<mlir::TypeID mlir::TypeID::get<mlir::OpAsmOpInterface::Trait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v136[v138], v140);
      uint64_t v21 = (void *)&unk_267771000;
      uint64_t v20 = v174;
      uint64_t v18 = v179;
      uint64_t v16 = v185;
      uint64_t v14 = v192;
      uint64_t v12 = v200;
      uint64_t v10 = v209;
      uint64_t v8 = v219;
      uint64_t v6 = v230;
      uint64_t v4 = v242;
      uint64_t v2 = v255;
      a1 = v269;
    }
  }
  uint64_t v22 = v21[350];
  v23 = &unk_267771000;
  {
    uint64_t v256 = v2;
    uint64_t v270 = a1;
    uint64_t v231 = v6;
    uint64_t v243 = v4;
    uint64_t v210 = v10;
    uint64_t v220 = v8;
    uint64_t v193 = v14;
    uint64_t v201 = v12;
    uint64_t v180 = v18;
    uint64_t v186 = v16;
    uint64_t v171 = v22;
    uint64_t v175 = v20;
    v23 = (void *)&unk_267771000;
    uint64_t v22 = v171;
    uint64_t v20 = v175;
    uint64_t v18 = v180;
    uint64_t v16 = v186;
    uint64_t v14 = v193;
    uint64_t v12 = v201;
    uint64_t v10 = v210;
    uint64_t v8 = v220;
    uint64_t v6 = v231;
    uint64_t v4 = v243;
    int v142 = v141;
    uint64_t v2 = v256;
    a1 = v270;
    if (v142)
    {
      uint64_t v273 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ConditionallySpeculatable::Trait<Empty>]";
      unint64_t v274 = 95;
      unint64_t v143 = llvm::StringRef::find((uint64_t *)&v273, "DesiredTypeName = ", 0x12uLL, 0);
      if (v274 >= v143) {
        unint64_t v144 = v143;
      }
      else {
        unint64_t v144 = v274;
      }
      unint64_t v145 = &v273[v144];
      unint64_t v146 = v274 - v144;
      if (v274 - v144 >= 0x12) {
        uint64_t v147 = 18;
      }
      else {
        uint64_t v147 = v274 - v144;
      }
      unint64_t v148 = v146 - v147;
      if (v148 >= v148 - 1) {
        uint64_t v149 = v148 - 1;
      }
      else {
        uint64_t v149 = v148;
      }
      mlir::detail::TypeIDResolver<mlir::ConditionallySpeculatable::Trait<mlir::TypeID mlir::TypeID::get<mlir::ConditionallySpeculatable::Trait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v145[v147], v149);
      v23 = (void *)&unk_267771000;
      uint64_t v22 = v171;
      uint64_t v20 = v175;
      uint64_t v18 = v180;
      uint64_t v16 = v186;
      uint64_t v14 = v193;
      uint64_t v12 = v201;
      uint64_t v10 = v210;
      uint64_t v8 = v220;
      uint64_t v6 = v231;
      uint64_t v4 = v243;
      uint64_t v2 = v256;
      a1 = v270;
    }
  }
  uint64_t v24 = v23[322];
  v25 = &unk_267771000;
  {
    uint64_t v257 = v2;
    uint64_t v271 = a1;
    uint64_t v232 = v6;
    uint64_t v244 = v4;
    uint64_t v211 = v10;
    uint64_t v221 = v8;
    uint64_t v194 = v14;
    uint64_t v202 = v12;
    uint64_t v181 = v18;
    uint64_t v187 = v16;
    uint64_t v172 = v22;
    uint64_t v176 = v20;
    uint64_t v169 = v24;
    v25 = (void *)&unk_267771000;
    uint64_t v24 = v169;
    uint64_t v22 = v172;
    uint64_t v20 = v176;
    uint64_t v18 = v181;
    uint64_t v16 = v187;
    uint64_t v14 = v194;
    uint64_t v12 = v202;
    uint64_t v10 = v211;
    uint64_t v8 = v221;
    uint64_t v6 = v232;
    uint64_t v4 = v244;
    int v151 = v150;
    uint64_t v2 = v257;
    a1 = v271;
    if (v151)
    {
      uint64_t v273 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::AlwaysSpeculatableImplTrait<Empty>]";
      unint64_t v274 = 99;
      unint64_t v152 = llvm::StringRef::find((uint64_t *)&v273, "DesiredTypeName = ", 0x12uLL, 0);
      if (v274 >= v152) {
        unint64_t v153 = v152;
      }
      else {
        unint64_t v153 = v274;
      }
      unint64_t v154 = &v273[v153];
      unint64_t v155 = v274 - v153;
      if (v274 - v153 >= 0x12) {
        uint64_t v156 = 18;
      }
      else {
        uint64_t v156 = v274 - v153;
      }
      unint64_t v157 = v155 - v156;
      if (v157 >= v157 - 1) {
        uint64_t v158 = v157 - 1;
      }
      else {
        uint64_t v158 = v157;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::AlwaysSpeculatableImplTrait<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::AlwaysSpeculatableImplTrait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v154[v156], v158);
      v25 = (void *)&unk_267771000;
      uint64_t v24 = v169;
      uint64_t v22 = v172;
      uint64_t v20 = v176;
      uint64_t v18 = v181;
      uint64_t v16 = v187;
      uint64_t v14 = v194;
      uint64_t v12 = v202;
      uint64_t v10 = v211;
      uint64_t v8 = v221;
      uint64_t v6 = v232;
      uint64_t v4 = v244;
      uint64_t v2 = v257;
      a1 = v271;
    }
  }
  uint64_t v26 = v25[324];
  v27 = &unk_267771000;
  {
    uint64_t v258 = v2;
    uint64_t v272 = a1;
    uint64_t v233 = v6;
    uint64_t v245 = v4;
    uint64_t v212 = v10;
    uint64_t v222 = v8;
    uint64_t v195 = v14;
    uint64_t v203 = v12;
    uint64_t v182 = v18;
    uint64_t v188 = v16;
    uint64_t v173 = v22;
    uint64_t v177 = v20;
    uint64_t v168 = v26;
    uint64_t v170 = v24;
    v27 = (void *)&unk_267771000;
    uint64_t v26 = v168;
    uint64_t v24 = v170;
    uint64_t v22 = v173;
    uint64_t v20 = v177;
    uint64_t v18 = v182;
    uint64_t v16 = v188;
    uint64_t v14 = v195;
    uint64_t v12 = v203;
    uint64_t v10 = v212;
    uint64_t v8 = v222;
    uint64_t v6 = v233;
    uint64_t v4 = v245;
    int v160 = v159;
    uint64_t v2 = v258;
    a1 = v272;
    if (v160)
    {
      uint64_t v273 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::MemoryEffectOpInterface::Trait<Empty>]";
      unint64_t v274 = 93;
      unint64_t v161 = llvm::StringRef::find((uint64_t *)&v273, "DesiredTypeName = ", 0x12uLL, 0);
      if (v274 >= v161) {
        unint64_t v162 = v161;
      }
      else {
        unint64_t v162 = v274;
      }
      unint64_t v163 = &v273[v162];
      unint64_t v164 = v274 - v162;
      if (v274 - v162 >= 0x12) {
        uint64_t v165 = 18;
      }
      else {
        uint64_t v165 = v274 - v162;
      }
      unint64_t v166 = v164 - v165;
      if (v166 >= v166 - 1) {
        uint64_t v167 = v166 - 1;
      }
      else {
        uint64_t v167 = v166;
      }
      mlir::detail::TypeIDResolver<mlir::MemoryEffectOpInterface::Trait<mlir::TypeID mlir::TypeID::get<mlir::MemoryEffectOpInterface::Trait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v163[v165], v167);
      v27 = (void *)&unk_267771000;
      uint64_t v26 = v168;
      uint64_t v24 = v170;
      uint64_t v22 = v173;
      uint64_t v20 = v177;
      uint64_t v18 = v182;
      uint64_t v16 = v188;
      uint64_t v14 = v195;
      uint64_t v12 = v203;
      uint64_t v10 = v212;
      uint64_t v8 = v222;
      uint64_t v6 = v233;
      uint64_t v4 = v245;
      uint64_t v2 = v258;
      a1 = v272;
    }
  }
  return v2 == a1
      || v4 == a1
      || v6 == a1
      || v8 == a1
      || v10 == a1
      || v12 == a1
      || v14 == a1
      || v16 == a1
      || v18 == a1
      || v20 == a1
      || v22 == a1
      || v24 == a1
      || v26 == a1
      || v27[31] == a1;
}

void llvm::detail::UniqueFunctionBase<void,mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef>::CallImpl<mlir::Op<mlir::tensor::PadOp,mlir::OpTrait::OneRegion,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<1u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::SingleBlock,mlir::OpTrait::SingleBlockImplicitTerminator<mlir::tensor::YieldOp>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1} const>(uint64_t a1, uint64_t a2, mlir::OpAsmPrinter *a3, uint64_t a4, uint64_t a5)
{
  mlir::OpState::printOpName(a2, (uint64_t)a3, a4, a5);
  uint64_t v7 = a2;
  mlir::tensor::PadOp::print((mlir::tensor::PadOp *)&v7, a3);
}

BOOL mlir::Op<mlir::tensor::PadOp,mlir::OpTrait::OneRegion,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<1u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::SingleBlock,mlir::OpTrait::SingleBlockImplicitTerminator<mlir::tensor::YieldOp>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::verifyInvariants(mlir::OpTrait::impl *a1, mlir::Operation *a2)
{
  if (!mlir::op_definition_impl::verifyTraits<mlir::OpTrait::OneRegion<mlir::tensor::PadOp>,mlir::OpTrait::OneResult<mlir::tensor::PadOp>,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl<mlir::tensor::PadOp>,mlir::OpTrait::ZeroSuccessors<mlir::tensor::PadOp>,mlir::OpTrait::AtLeastNOperands<1u>::Impl<mlir::tensor::PadOp>,mlir::OpTrait::AttrSizedOperandSegments<mlir::tensor::PadOp>,mlir::OpTrait::SingleBlock<mlir::tensor::PadOp>,mlir::OpTrait::SingleBlockImplicitTerminator<mlir::tensor::YieldOp>::Impl<mlir::tensor::PadOp>,mlir::OpTrait::OpInvariants<mlir::tensor::PadOp>,mlir::BytecodeOpInterface::Trait<mlir::tensor::PadOp>,mlir::OpAsmOpInterface::Trait<mlir::tensor::PadOp>,mlir::ConditionallySpeculatable::Trait<mlir::tensor::PadOp>,mlir::OpTrait::AlwaysSpeculatableImplTrait<mlir::tensor::PadOp>,mlir::MemoryEffectOpInterface::Trait<mlir::tensor::PadOp>>(a1, a2))return 0; {
  uint64_t v4 = a1;
  }
  return mlir::tensor::PadOp::verify((mlir::tensor::PadOp *)&v4) != 0;
}

BOOL mlir::op_definition_impl::verifyTraits<mlir::OpTrait::OneRegion<mlir::tensor::PadOp>,mlir::OpTrait::OneResult<mlir::tensor::PadOp>,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl<mlir::tensor::PadOp>,mlir::OpTrait::ZeroSuccessors<mlir::tensor::PadOp>,mlir::OpTrait::AtLeastNOperands<1u>::Impl<mlir::tensor::PadOp>,mlir::OpTrait::AttrSizedOperandSegments<mlir::tensor::PadOp>,mlir::OpTrait::SingleBlock<mlir::tensor::PadOp>,mlir::OpTrait::SingleBlockImplicitTerminator<mlir::tensor::YieldOp>::Impl<mlir::tensor::PadOp>,mlir::OpTrait::OpInvariants<mlir::tensor::PadOp>,mlir::BytecodeOpInterface::Trait<mlir::tensor::PadOp>,mlir::OpAsmOpInterface::Trait<mlir::tensor::PadOp>,mlir::ConditionallySpeculatable::Trait<mlir::tensor::PadOp>,mlir::OpTrait::AlwaysSpeculatableImplTrait<mlir::tensor::PadOp>,mlir::MemoryEffectOpInterface::Trait<mlir::tensor::PadOp>>(mlir::OpTrait::impl *a1, mlir::Operation *a2)
{
  if (!mlir::OpTrait::impl::verifyOneRegion(a1, a2)
    || !mlir::OpTrait::impl::verifyOneResult(a1, v3)
    || !mlir::OpTrait::impl::verifyZeroSuccessors(a1, v4)
    || !mlir::OpTrait::impl::verifyAtLeastNOperands(a1, (mlir::Operation *)1)
    || !mlir::OpTrait::impl::verifyOperandSizeAttr((uint64_t)a1, "operandSegmentSizes", 0x13uLL)
    || !mlir::OpTrait::SingleBlock<mlir::memref::GenericAtomicRMWOp>::verifyTrait((uint64_t)a1))
  {
    return 0;
  }
  uint64_t v6 = a1;
  return mlir::tensor::PadOp::verifyInvariantsImpl((mlir::tensor::PadOp *)&v6);
}

BOOL mlir::Op<mlir::tensor::PadOp,mlir::OpTrait::OneRegion,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<1u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::SingleBlock,mlir::OpTrait::SingleBlockImplicitTerminator<mlir::tensor::YieldOp>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::verifyRegionInvariants(uint64_t a1)
{
  if (!mlir::OpTrait::SingleBlockImplicitTerminator<mlir::tensor::YieldOp>::Impl<mlir::tensor::GenerateOp>::verifyRegionTrait(a1)) {
    return 0;
  }
  uint64_t v3 = a1;
  return mlir::tensor::PadOp::verifyRegions((mlir::tensor::PadOp *)&v3) != 0;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::ParallelInsertSliceOp>::~Model(uint64_t a1)
{
  *(void *)a1 = &unk_26C361F50;
  uint64_t v2 = *(void ***)(a1 + 32);
  uint64_t v3 = *(unsigned int *)(a1 + 40);
  if (v3)
  {
    uint64_t v4 = 16 * v3;
    unint64_t v5 = v2 + 1;
    do
    {
      uint64_t v6 = *v5;
      v5 += 2;
      free(v6);
      v4 -= 16;
    }
    while (v4);
    uint64_t v2 = *(void ***)(a1 + 32);
  }
  if (v2 != (void **)(a1 + 48)) {
    free(v2);
  }
  return a1;
}

void mlir::RegisteredOperationName::Model<mlir::tensor::ParallelInsertSliceOp>::~Model(uint64_t a1)
{
  *(void *)a1 = &unk_26C361F50;
  uint64_t v2 = *(void ***)(a1 + 32);
  uint64_t v3 = *(unsigned int *)(a1 + 40);
  if (v3)
  {
    uint64_t v4 = 16 * v3;
    unint64_t v5 = v2 + 1;
    do
    {
      uint64_t v6 = *v5;
      v5 += 2;
      free(v6);
      v4 -= 16;
    }
    while (v4);
    uint64_t v2 = *(void ***)(a1 + 32);
  }
  if (v2 != (void **)(a1 + 48)) {
    free(v2);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::ParallelInsertSliceOp>::foldHook()
{
  uint64_t v9 = *MEMORY[0x263EF8340];
  unint64_t v8 = (unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &>::CallbacksHolder<mlir::Op<mlir::tensor::ParallelInsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1},mlir::Op<mlir::tensor::ParallelInsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1} const,void>::Callbacks
     + 2;
  uint64_t v4 = (*(uint64_t (__cdecl **)())(((unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &>::CallbacksHolder<mlir::Op<mlir::tensor::ParallelInsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1},mlir::Op<mlir::tensor::ParallelInsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1} const,void>::Callbacks
                                 + 2) & 0xFFFFFFFFFFFFFFF8))();
  if ((unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &>::CallbacksHolder<mlir::Op<mlir::tensor::ParallelInsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1},mlir::Op<mlir::tensor::ParallelInsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1} const,void>::Callbacks
     + 2 >= 8)
  {
    if ((v8 & 4) != 0)
    {
      if ((v8 & 2) != 0) {
        unint64_t v5 = v7;
      }
      else {
        unint64_t v5 = (llvm **)v7[0];
      }
      (*(void (**)(uint64_t, uint64_t, uint64_t, uint64_t, uint64_t))((v8 & 0xFFFFFFFFFFFFFFF8) + 16))((uint64_t)v5, v0, v1, v2, v3);
    }
    if (((llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &>::CallbacksHolder<mlir::Op<mlir::tensor::ParallelInsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1},mlir::Op<mlir::tensor::ParallelInsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1} const,void>::Callbacks
         + 2) & 2) == 0)
      llvm::deallocate_buffer(v7[0], v7[1]);
  }
  return v4;
}

void mlir::RegisteredOperationName::Model<mlir::tensor::ParallelInsertSliceOp>::getCanonicalizationPatterns()
{
}

BOOL mlir::RegisteredOperationName::Model<mlir::tensor::ParallelInsertSliceOp>::hasTrait(uint64_t a1, uint64_t a2)
{
  uint64_t v9 = *MEMORY[0x263EF8340];
  unint64_t v8 = (unint64_t)llvm::detail::UniqueFunctionBase<BOOL,mlir::TypeID>::CallbacksHolder<mlir::Op<mlir::tensor::ParallelInsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1},mlir::Op<mlir::tensor::ParallelInsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1} const,void>::Callbacks
     + 2;
  BOOL v3 = (*(BOOL (**)(uint64_t, uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<BOOL,mlir::TypeID>::CallbacksHolder<mlir::Op<mlir::tensor::ParallelInsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1},mlir::Op<mlir::tensor::ParallelInsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1} const,void>::Callbacks
                                                 + 2) & 0xFFFFFFFFFFFFFFF8))((uint64_t)v7, a2);
  char v4 = v8;
  if (v8 >= 8)
  {
    if ((v8 & 4) != 0)
    {
      if ((v8 & 2) != 0) {
        unint64_t v5 = v7;
      }
      else {
        unint64_t v5 = (llvm **)v7[0];
      }
      (*(void (**)(uint64_t, uint64_t))((v8 & 0xFFFFFFFFFFFFFFF8) + 16))((uint64_t)v5, v2);
    }
    if ((v4 & 2) == 0) {
      llvm::deallocate_buffer(v7[0], v7[1]);
    }
  }
  return v3;
}

void mlir::RegisteredOperationName::Model<mlir::tensor::ParallelInsertSliceOp>::getParseAssemblyFn(uint64_t (**a1)(uint64_t a1, uint64_t a2)@<X8>)
{
  *a1 = mlir::tensor::ParallelInsertSliceOp::parse;
  a1[3] = (uint64_t (*)(uint64_t, uint64_t))((char *)llvm::detail::UniqueFunctionBase<mlir::ParseResult,mlir::OpAsmParser &,mlir::OperationState &>::CallbacksHolder<mlir::ParseResult (*)(mlir::OpAsmParser &,mlir::OperationState &),mlir::ParseResult (*)(mlir::OpAsmParser &,mlir::OperationState &),void>::Callbacks
                                                   + 2);
}

void mlir::RegisteredOperationName::Model<mlir::tensor::ParallelInsertSliceOp>::printAssembly(uint64_t a1, uint64_t a2, mlir::OpAsmPrinter *a3, uint64_t a4, uint64_t a5)
{
  uint64_t v13 = *MEMORY[0x263EF8340];
  unint64_t v12 = (unint64_t)llvm::detail::UniqueFunctionBase<void,mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef>::CallbacksHolder<mlir::Op<mlir::tensor::ParallelInsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1},mlir::Op<mlir::tensor::ParallelInsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1} const,void>::Callbacks
      + 2;
  (*(void (**)(uint64_t, uint64_t, mlir::OpAsmPrinter *, uint64_t, uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<void,mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef>::CallbacksHolder<mlir::Op<mlir::tensor::ParallelInsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1},mlir::Op<mlir::tensor::ParallelInsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1} const,void>::Callbacks
                                                                                    + 2) & 0xFFFFFFFFFFFFFFF8))((uint64_t)v11, a2, a3, a4, a5);
  char v9 = v12;
  if (v12 >= 8)
  {
    if ((v12 & 4) != 0)
    {
      if ((v12 & 2) != 0) {
        uint64_t v10 = v11;
      }
      else {
        uint64_t v10 = (llvm **)v11[0];
      }
      (*(void (**)(uint64_t, uint64_t, mlir::OpAsmPrinter *, uint64_t, uint64_t))((v12 & 0xFFFFFFFFFFFFFFF8)
                                                                                       + 16))((uint64_t)v10, v5, v6, v7, v8);
    }
    if ((v9 & 2) == 0) {
      llvm::deallocate_buffer(v11[0], v11[1]);
    }
  }
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::ParallelInsertSliceOp>::verifyInvariants(uint64_t a1, uint64_t a2)
{
  uint64_t v7 = *MEMORY[0x263EF8340];
  v5[0] = (uint64_t (*)(uint64_t))mlir::Op<mlir::tensor::ParallelInsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait>::verifyInvariants;
  unint64_t v6 = (unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *>::CallbacksHolder<mlir::LogicalResult (*)(mlir::Operation *),mlir::LogicalResult (* const)(mlir::Operation *),void>::Callbacks
     + 2;
  uint64_t v2 = (*(uint64_t (**)(uint64_t (**)(uint64_t), uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *>::CallbacksHolder<mlir::LogicalResult (*)(mlir::Operation *),mlir::LogicalResult (* const)(mlir::Operation *),void>::Callbacks
                                                                             + 2) & 0xFFFFFFFFFFFFFFF8))(v5, a2);
  char v3 = v6;
  if (v6 >= 8)
  {
    if ((v6 & 4) != 0) {
      (*(void (__cdecl **)())((v6 & 0xFFFFFFFFFFFFFFF8) + 16))();
    }
    if ((v3 & 2) == 0) {
      llvm::deallocate_buffer((llvm *)v5[0], v5[1]);
    }
  }
  return v2;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::ParallelInsertSliceOp>::verifyRegionInvariants(uint64_t a1, uint64_t a2)
{
  uint64_t v7 = *MEMORY[0x263EF8340];
  v5[0] = (uint64_t (*)(uint64_t))mlir::Op<mlir::tensor::ParallelInsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait>::verifyRegionInvariants;
  unint64_t v6 = (unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *>::CallbacksHolder<mlir::LogicalResult (*)(mlir::Operation *),mlir::LogicalResult (* const)(mlir::Operation *),void>::Callbacks
     + 2;
  uint64_t v2 = (*(uint64_t (**)(uint64_t (**)(uint64_t), uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *>::CallbacksHolder<mlir::LogicalResult (*)(mlir::Operation *),mlir::LogicalResult (* const)(mlir::Operation *),void>::Callbacks
                                                                             + 2) & 0xFFFFFFFFFFFFFFF8))(v5, a2);
  char v3 = v6;
  if (v6 >= 8)
  {
    if ((v6 & 4) != 0) {
      (*(void (__cdecl **)())((v6 & 0xFFFFFFFFFFFFFFF8) + 16))();
    }
    if ((v3 & 2) == 0) {
      llvm::deallocate_buffer((llvm *)v5[0], v5[1]);
    }
  }
  return v2;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::ParallelInsertSliceOp>::getInherentAttr(uint64_t a1, uint64_t a2, char *a3, size_t a4)
{
  uint64_t Context = (mlir::MLIRContext *)mlir::Attribute::getContext((mlir::Attribute *)(a2 + 24));
  if (HIBYTE(*(_DWORD *)(a2 + 44))) {
    uint64_t v8 = (uint64_t *)(a2 + 16 * (((unint64_t)*(unsigned int *)(a2 + 44) >> 23) & 1) + 64);
  }
  else {
    uint64_t v8 = 0;
  }

  return mlir::tensor::ParallelInsertSliceOp::getInherentAttr(Context, v8, a3, a4);
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::ParallelInsertSliceOp>::setInherentAttr(uint64_t a1, uint64_t a2, uint64_t a3, void *a4)
{
  uint64_t v9 = a3;
  if (HIBYTE(*(_DWORD *)(a2 + 44))) {
    uint64_t v5 = a2 + 16 * (((unint64_t)*(unsigned int *)(a2 + 44) >> 23) & 1) + 64;
  }
  else {
    uint64_t v5 = 0;
  }
  AttrData = (char *)mlir::OpaqueAttr::getAttrData((mlir::OpaqueAttr *)&v9);
  return mlir::tensor::ParallelInsertSliceOp::setInherentAttr(v5, AttrData, v7, a4);
}

void mlir::RegisteredOperationName::Model<mlir::tensor::ParallelInsertSliceOp>::populateInherentAttrs(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t Context = (mlir::MLIRContext *)mlir::Attribute::getContext((mlir::Attribute *)(a2 + 24));
  if (HIBYTE(*(_DWORD *)(a2 + 44))) {
    unint64_t v6 = (uint64_t *)(a2 + 16 * (((unint64_t)*(unsigned int *)(a2 + 44) >> 23) & 1) + 64);
  }
  else {
    unint64_t v6 = 0;
  }

  mlir::tensor::InsertSliceOp::populateInherentAttrs(Context, v6, a3);
}

BOOL mlir::RegisteredOperationName::Model<mlir::tensor::ParallelInsertSliceOp>::verifyInherentAttrs(uint64_t a1, uint64_t a2, uint64_t a3, void (*a4)(uint64_t *__return_ptr, uint64_t), uint64_t a5)
{
  return mlir::memref::ReinterpretCastOp::verifyInherentAttrs(a2, a3, a4, a5);
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::ParallelInsertSliceOp>::getOpPropertyByteSize()
{
  return 48;
}

double mlir::RegisteredOperationName::Model<mlir::tensor::ParallelInsertSliceOp>::initProperties(uint64_t a1, uint64_t a2, _OWORD *a3, long long *a4)
{
  if (a4)
  {
    long long v4 = *a4;
    long long v5 = a4[2];
    a3[1] = a4[1];
    a3[2] = v5;
    *a3 = v4;
  }
  else
  {
    *(void *)&long long v4 = 0;
    a3[1] = 0u;
    a3[2] = 0u;
    *a3 = 0u;
  }
  return *(double *)&v4;
}

BOOL mlir::RegisteredOperationName::Model<mlir::tensor::ParallelInsertSliceOp>::setPropertiesFromAttr(uint64_t a1, uint64_t a2, uint64_t *a3, uint64_t a4, void (*a5)(uint64_t *__return_ptr, uint64_t), uint64_t a6)
{
  return mlir::tensor::InsertSliceOp::setPropertiesFromAttr(a3, a4, a5, a6);
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::ParallelInsertSliceOp>::getPropertiesAsAttr(uint64_t a1, uint64_t a2)
{
  uint64_t Context = (mlir::DictionaryAttr *)mlir::Attribute::getContext((mlir::Attribute *)(a2 + 24));
  if (HIBYTE(*(_DWORD *)(a2 + 44))) {
    long long v4 = (uint64_t *)(a2 + 16 * (((unint64_t)*(unsigned int *)(a2 + 44) >> 23) & 1) + 64);
  }
  else {
    long long v4 = 0;
  }

  return mlir::tensor::InsertSliceOp::getPropertiesAsAttr(Context, v4);
}

__n128 mlir::RegisteredOperationName::Model<mlir::tensor::ParallelInsertSliceOp>::copyProperties(uint64_t a1, uint64_t a2, uint64_t a3)
{
  __n128 result = *(__n128 *)a3;
  long long v4 = *(_OWORD *)(a3 + 16);
  *(_OWORD *)(a2 + 28) = *(_OWORD *)(a3 + 28);
  *(__n128 *)a2 = result;
  *(_OWORD *)(a2 + 16) = v4;
  return result;
}

BOOL mlir::RegisteredOperationName::Model<mlir::tensor::ParallelInsertSliceOp>::compareProperties(uint64_t a1, uint64_t a2, uint64_t a3)
{
  if (*(void *)a3 != *(void *)a2) {
    return 0;
  }
  if (*(void *)(a3 + 8) != *(void *)(a2 + 8)) {
    return 0;
  }
  if (*(void *)(a3 + 16) != *(void *)(a2 + 16)) {
    return 0;
  }
  return *(void *)(a3 + 24) == *(void *)(a2 + 24)
      && *(void *)(a3 + 32) == *(void *)(a2 + 32)
      && *(_DWORD *)(a3 + 40) == (unint64_t)*(unsigned int *)(a2 + 40);
}

unint64_t mlir::RegisteredOperationName::Model<mlir::tensor::ParallelInsertSliceOp>::hashProperties(uint64_t a1, unint64_t *a2)
{
  return mlir::tensor::InsertSliceOp::computePropertiesHash(a2);
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::BytecodeOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(0x10uLL, 0x80040803F642BuLL);
  *uint64_t v2 = mlir::detail::BytecodeOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::readProperties;
  v2[1] = mlir::detail::BytecodeOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::writeProperties;
  char v3 = &unk_267771000;
  {
    unint64_t v12 = v2;
    char v3 = (void *)&unk_267771000;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::BytecodeOpInterface]";
      unint64_t v14 = 75;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      size_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::BytecodeOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      char v3 = (void *)&unk_267771000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[312], v2);
}

uint64_t mlir::detail::BytecodeOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::writeProperties(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = a2;
  return mlir::tensor::InsertSliceOp::writeProperties((uint64_t)&v4, a3);
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(0xD0uLL, 0x80040B342C78EuLL);
  *uint64_t v2 = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::getOffsetSizeAndStrideStartOperandIndex;
  v2[1] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::getArrayAttrMaxRanks;
  v2[2] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::getOffsets;
  v2[3] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::getSizes;
  v2[4] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::getStrides;
  v2[5] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::getStaticOffsets;
  v2[6] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::getStaticSizes;
  v2[7] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::getStaticStrides;
  v2[8] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::getMixedOffsets;
  v2[9] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::getMixedSizes;
  v2[10] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::getMixedStrides;
  v2[11] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::isDynamicOffset;
  v2[12] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::isDynamicSize;
  v2[13] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::isDynamicStride;
  v2[14] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::getStaticOffset;
  v2[15] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::getStaticSize;
  v2[16] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::getStaticStride;
  v2[17] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::getIndexOfDynamicOffset;
  v2[18] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::getIndexOfDynamicSize;
  v2[19] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::getIndexOfDynamicStride;
  v2[20] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::getDynamicOffset;
  v2[21] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::getDynamicSize;
  v2[22] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::getDynamicStride;
  v2[23] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::isSameAs;
  v2[24] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::hasUnitStride;
  v2[25] = mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::hasZeroOffset;
  char v3 = &unk_267772000;
  {
    unint64_t v12 = v2;
    char v3 = (void *)&unk_267772000;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OffsetSizeAndStrideOpInterface]";
      unint64_t v14 = 86;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      size_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::OffsetSizeAndStrideOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      char v3 = (void *)&unk_267772000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[269], v2);
}

uint64_t mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::getOffsetSizeAndStrideStartOperandIndex()
{
  return 1;
}

unint64_t mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::getArrayAttrMaxRanks(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = a2;
  unint64_t v5 = *(void *)(mlir::tensor::ParallelInsertSliceOp::getDest((mlir::tensor::ParallelInsertSliceOp *)&v4) + 8) & 0xFFFFFFFFFFFFFFF8;
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v5);
  return v2 | ((unint64_t)v2 << 32);
}

uint64_t mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::getOffsets(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = a2;
  return mlir::memref::ReinterpretCastOp::getSizes((mlir::memref::ReinterpretCastOp *)&v3);
}

uint64_t mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::getSizes(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = a2;
  return mlir::memref::ReinterpretCastOp::getStrides((mlir::memref::ReinterpretCastOp *)&v3);
}

uint64_t mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::getStrides(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = a2;
  return mlir::tensor::InsertSliceOp::getStrides((mlir::tensor::InsertSliceOp *)&v3);
}

uint64_t mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::getStaticOffsets(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = a2;
  return mlir::memref::ReinterpretCastOp::getStaticOffsets((mlir::memref::ReinterpretCastOp *)&v3);
}

uint64_t mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::getStaticSizes(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = a2;
  return mlir::memref::ReinterpretCastOp::getStaticSizes((mlir::memref::ReinterpretCastOp *)&v3);
}

uint64_t mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::getStaticStrides(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = a2;
  return mlir::memref::ReinterpretCastOp::getStaticStrides((mlir::memref::ReinterpretCastOp *)&v3);
}

void mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::getMixedOffsets(uint64_t a1@<X1>, uint64_t a2@<X8>)
{
  uint64_t v2 = a1;
  mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::tensor::InsertSliceOp>::getMixedOffsets((mlir::memref::ReinterpretCastOp *)&v2, a2);
}

void mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::getMixedSizes(uint64_t a1@<X1>, uint64_t a2@<X8>)
{
  uint64_t v2 = a1;
  mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::tensor::InsertSliceOp>::getMixedSizes((mlir::memref::ReinterpretCastOp *)&v2, a2);
}

void mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::getMixedStrides(uint64_t a1@<X1>, uint64_t a2@<X8>)
{
  uint64_t v2 = a1;
  mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::tensor::InsertSliceOp>::getMixedStrides((mlir::memref::ReinterpretCastOp *)&v2, a2);
}

BOOL mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::isDynamicOffset(uint64_t a1, uint64_t a2, unsigned int a3)
{
  uint64_t v4 = a2;
  return *(void *)(mlir::memref::ReinterpretCastOp::getStaticOffsets((mlir::memref::ReinterpretCastOp *)&v4) + 8 * a3) == 0x8000000000000000;
}

BOOL mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::isDynamicSize(uint64_t a1, uint64_t a2, unsigned int a3)
{
  uint64_t v4 = a2;
  return *(void *)(mlir::memref::ReinterpretCastOp::getStaticSizes((mlir::memref::ReinterpretCastOp *)&v4) + 8 * a3) == 0x8000000000000000;
}

BOOL mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::isDynamicStride(uint64_t a1, uint64_t a2, unsigned int a3)
{
  uint64_t v4 = a2;
  return *(void *)(mlir::memref::ReinterpretCastOp::getStaticStrides((mlir::memref::ReinterpretCastOp *)&v4) + 8 * a3) == 0x8000000000000000;
}

uint64_t mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::getStaticOffset(uint64_t a1, uint64_t a2, unsigned int a3)
{
  uint64_t v4 = a2;
  return *(void *)(mlir::memref::ReinterpretCastOp::getStaticOffsets((mlir::memref::ReinterpretCastOp *)&v4) + 8 * a3);
}

uint64_t mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::getStaticSize(uint64_t a1, uint64_t a2, unsigned int a3)
{
  uint64_t v4 = a2;
  return *(void *)(mlir::memref::ReinterpretCastOp::getStaticSizes((mlir::memref::ReinterpretCastOp *)&v4) + 8 * a3);
}

uint64_t mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::getStaticStride(uint64_t a1, uint64_t a2, unsigned int a3)
{
  uint64_t v4 = a2;
  return *(void *)(mlir::memref::ReinterpretCastOp::getStaticStrides((mlir::memref::ReinterpretCastOp *)&v4) + 8 * a3);
}

uint64_t mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::getIndexOfDynamicOffset(uint64_t a1, uint64_t a2, unsigned int a3)
{
  uint64_t v7 = a2;
  StaticOffsets = (int64x2_t *)mlir::memref::ReinterpretCastOp::getStaticOffsets((mlir::memref::ReinterpretCastOp *)&v7);
  return mlir::detail::getNumDynamicEntriesUpToIdx(StaticOffsets, v5, a3) + 1;
}

uint64_t mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::getIndexOfDynamicSize(uint64_t a1, uint64_t a2, unsigned int a3)
{
  uint64_t v9 = a2;
  Staticuint64_t Sizes = (int64x2_t *)mlir::memref::ReinterpretCastOp::getStaticSizes((mlir::memref::ReinterpretCastOp *)&v9);
  int NumDynamicEntriesUpToIdx = mlir::detail::getNumDynamicEntriesUpToIdx(StaticSizes, v5, a3);
  mlir::memref::ReinterpretCastOp::getSizes((mlir::memref::ReinterpretCastOp *)&v9);
  return (NumDynamicEntriesUpToIdx + v7 + 1);
}

uint64_t mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::getIndexOfDynamicStride(uint64_t a1, uint64_t a2, unsigned int a3)
{
  uint64_t v11 = a2;
  Staticuint64_t Strides = (int64x2_t *)mlir::memref::ReinterpretCastOp::getStaticStrides((mlir::memref::ReinterpretCastOp *)&v11);
  int NumDynamicEntriesUpToIdx = mlir::detail::getNumDynamicEntriesUpToIdx(StaticStrides, v5, a3);
  mlir::memref::ReinterpretCastOp::getSizes((mlir::memref::ReinterpretCastOp *)&v11);
  int v8 = v7;
  mlir::memref::ReinterpretCastOp::getStrides((mlir::memref::ReinterpretCastOp *)&v11);
  return (v8 + v9 + NumDynamicEntriesUpToIdx + 1);
}

uint64_t mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::getDynamicOffset(uint64_t a1, uint64_t a2, unsigned int a3)
{
  uint64_t v8 = a2;
  StaticOffsets = (int64x2_t *)mlir::memref::ReinterpretCastOp::getStaticOffsets((mlir::memref::ReinterpretCastOp *)&v8);
  int NumDynamicEntriesUpToIdx = mlir::detail::getNumDynamicEntriesUpToIdx(StaticOffsets, v5, a3);
  return *(void *)(*(void *)(v8 + 72) + 32 * (NumDynamicEntriesUpToIdx + 1) + 24);
}

uint64_t mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::getDynamicSize(uint64_t a1, uint64_t a2, unsigned int a3)
{
  uint64_t v9 = a2;
  Staticuint64_t Sizes = (int64x2_t *)mlir::memref::ReinterpretCastOp::getStaticSizes((mlir::memref::ReinterpretCastOp *)&v9);
  int NumDynamicEntriesUpToIdx = mlir::detail::getNumDynamicEntriesUpToIdx(StaticSizes, v5, a3);
  mlir::memref::ReinterpretCastOp::getSizes((mlir::memref::ReinterpretCastOp *)&v9);
  return *(void *)(*(void *)(v9 + 72) + 32 * (NumDynamicEntriesUpToIdx + v7 + 1) + 24);
}

uint64_t mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::getDynamicStride(uint64_t a1, uint64_t a2, unsigned int a3)
{
  uint64_t v11 = a2;
  Staticuint64_t Strides = (int64x2_t *)mlir::memref::ReinterpretCastOp::getStaticStrides((mlir::memref::ReinterpretCastOp *)&v11);
  int NumDynamicEntriesUpToIdx = mlir::detail::getNumDynamicEntriesUpToIdx(StaticStrides, v5, a3);
  mlir::memref::ReinterpretCastOp::getSizes((mlir::memref::ReinterpretCastOp *)&v11);
  int v8 = v7;
  mlir::memref::ReinterpretCastOp::getStrides((mlir::memref::ReinterpretCastOp *)&v11);
  return *(void *)(*(void *)(v11 + 72) + 32 * (v8 + v9 + NumDynamicEntriesUpToIdx + 1) + 24);
}

uint64_t mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::isSameAs(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t (*a5)(uint64_t, void, void), uint64_t a6)
{
  uint64_t v7 = a2;
  return mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::memref::ReinterpretCastOp>::isSameAs(&v7, a3, a4, a5, a6);
}

uint64_t mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::hasUnitStride(uint64_t a1, uint64_t a2)
{
  v14[4] = *MEMORY[0x263EF8340];
  uint64_t v11 = a2;
  mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::tensor::InsertSliceOp>::getMixedStrides((mlir::memref::ReinterpretCastOp *)&v11, (uint64_t)&v12);
  uint64_t v2 = (uint64_t *)v12;
  if (!v13)
  {
    uint64_t v8 = 1;
    if (v12 == v14) {
      return v8;
    }
    goto LABEL_15;
  }
  uint64_t v3 = 8 * v13 - 8;
  do
  {
    uint64_t v4 = *v2++;
    unint64_t ConstantIntValue = mlir::getConstantIntValue(v4);
    if (v6) {
      BOOL v7 = ConstantIntValue == 1;
    }
    else {
      BOOL v7 = 0;
    }
    uint64_t v8 = v7;
    BOOL v9 = v8 != 1 || v3 == 0;
    v3 -= 8;
  }
  while (!v9);
  uint64_t v2 = (uint64_t *)v12;
  if (v12 != v14) {
LABEL_15:
  }
    free(v2);
  return v8;
}

uint64_t mlir::detail::OffsetSizeAndStrideOpInterfaceInterfaceTraits::Model<mlir::tensor::ParallelInsertSliceOp>::hasZeroOffset(uint64_t a1, uint64_t a2)
{
  v14[4] = *MEMORY[0x263EF8340];
  uint64_t v11 = a2;
  mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::tensor::InsertSliceOp>::getMixedOffsets((mlir::memref::ReinterpretCastOp *)&v11, (uint64_t)&v12);
  uint64_t v2 = (uint64_t *)v12;
  if (!v13)
  {
    uint64_t v8 = 1;
    if (v12 == v14) {
      return v8;
    }
    goto LABEL_15;
  }
  uint64_t v3 = 8 * v13 - 8;
  do
  {
    uint64_t v4 = *v2++;
    unint64_t ConstantIntValue = mlir::getConstantIntValue(v4);
    if (v6) {
      BOOL v7 = ConstantIntValue == 0;
    }
    else {
      BOOL v7 = 0;
    }
    uint64_t v8 = v7;
    BOOL v9 = v8 != 1 || v3 == 0;
    v3 -= 8;
  }
  while (!v9);
  uint64_t v2 = (uint64_t *)v12;
  if (v12 != v14) {
LABEL_15:
  }
    free(v2);
  return v8;
}

uint64_t llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &>::CallImpl<mlir::Op<mlir::tensor::ParallelInsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1} const>()
{
  return 0;
}

BOOL llvm::detail::UniqueFunctionBase<BOOL,mlir::TypeID>::CallImpl<mlir::Op<mlir::tensor::ParallelInsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1} const>(uint64_t a1, uint64_t a2)
{
  return mlir::op_definition_impl::hasTrait<mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait>(a2);
}

BOOL mlir::op_definition_impl::hasTrait<mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait>(uint64_t a1)
{
  uint64_t v1 = &unk_267771000;
  {
    uint64_t v124 = a1;
    uint64_t v1 = (void *)&unk_267771000;
    int v25 = v24;
    a1 = v124;
    if (v25)
    {
      int v132 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::ZeroRegions<Empty>]";
      unint64_t v133 = 83;
      unint64_t v26 = llvm::StringRef::find((uint64_t *)&v132, "DesiredTypeName = ", 0x12uLL, 0);
      if (v133 >= v26) {
        unint64_t v27 = v26;
      }
      else {
        unint64_t v27 = v133;
      }
      uint64_t v28 = &v132[v27];
      unint64_t v29 = v133 - v27;
      if (v133 - v27 >= 0x12) {
        uint64_t v30 = 18;
      }
      else {
        uint64_t v30 = v133 - v27;
      }
      unint64_t v31 = v29 - v30;
      if (v31 >= v31 - 1) {
        uint64_t v32 = v31 - 1;
      }
      else {
        uint64_t v32 = v31;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::ZeroRegions<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::ZeroRegions>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v28[v30], v32);
      uint64_t v1 = (void *)&unk_267771000;
      a1 = v124;
    }
  }
  uint64_t v2 = v1[23];
  uint64_t v3 = &unk_267770000;
  {
    uint64_t v125 = a1;
    uint64_t v117 = v2;
    uint64_t v3 = (void *)&unk_267770000;
    uint64_t v2 = v117;
    int v34 = v33;
    a1 = v125;
    if (v34)
    {
      int v132 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::ZeroResults<Empty>]";
      unint64_t v133 = 83;
      unint64_t v35 = llvm::StringRef::find((uint64_t *)&v132, "DesiredTypeName = ", 0x12uLL, 0);
      if (v133 >= v35) {
        unint64_t v36 = v35;
      }
      else {
        unint64_t v36 = v133;
      }
      v37 = &v132[v36];
      unint64_t v38 = v133 - v36;
      if (v133 - v36 >= 0x12) {
        uint64_t v39 = 18;
      }
      else {
        uint64_t v39 = v133 - v36;
      }
      unint64_t v40 = v38 - v39;
      if (v40 >= v40 - 1) {
        uint64_t v41 = v40 - 1;
      }
      else {
        uint64_t v41 = v40;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::ZeroResults<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::ZeroResults>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v37[v39], v41);
      uint64_t v3 = (void *)&unk_267770000;
      uint64_t v2 = v117;
      a1 = v125;
    }
  }
  uint64_t v4 = v3[429];
  uint64_t v5 = &unk_267770000;
  {
    uint64_t v126 = a1;
    uint64_t v111 = v4;
    uint64_t v118 = v2;
    uint64_t v5 = (void *)&unk_267770000;
    uint64_t v4 = v111;
    uint64_t v2 = v118;
    int v43 = v42;
    a1 = v126;
    if (v43)
    {
      int v132 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::ZeroSuccessors<Empty>]";
      unint64_t v133 = 86;
      unint64_t v44 = llvm::StringRef::find((uint64_t *)&v132, "DesiredTypeName = ", 0x12uLL, 0);
      if (v133 >= v44) {
        unint64_t v45 = v44;
      }
      else {
        unint64_t v45 = v133;
      }
      v46 = &v132[v45];
      unint64_t v47 = v133 - v45;
      if (v133 - v45 >= 0x12) {
        uint64_t v48 = 18;
      }
      else {
        uint64_t v48 = v133 - v45;
      }
      unint64_t v49 = v47 - v48;
      if (v49 >= v49 - 1) {
        uint64_t v50 = v49 - 1;
      }
      else {
        uint64_t v50 = v49;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::ZeroSuccessors<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::ZeroSuccessors>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v46[v48], v50);
      uint64_t v5 = (void *)&unk_267770000;
      uint64_t v4 = v111;
      uint64_t v2 = v118;
      a1 = v126;
    }
  }
  uint64_t v6 = v5[431];
  BOOL v7 = &unk_267771000;
  {
    uint64_t v127 = a1;
    uint64_t v112 = v4;
    uint64_t v119 = v2;
    uint64_t v106 = v6;
    BOOL v7 = (void *)&unk_267771000;
    uint64_t v6 = v106;
    uint64_t v4 = v112;
    uint64_t v2 = v119;
    int v52 = v51;
    a1 = v127;
    if (v52)
    {
      int v132 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::AtLeastNOperands<2>::Impl<Empty>]";
      unint64_t v133 = 97;
      unint64_t v53 = llvm::StringRef::find((uint64_t *)&v132, "DesiredTypeName = ", 0x12uLL, 0);
      if (v133 >= v53) {
        unint64_t v54 = v53;
      }
      else {
        unint64_t v54 = v133;
      }
      unint64_t v55 = &v132[v54];
      unint64_t v56 = v133 - v54;
      if (v133 - v54 >= 0x12) {
        uint64_t v57 = 18;
      }
      else {
        uint64_t v57 = v133 - v54;
      }
      unint64_t v58 = v56 - v57;
      if (v58 >= v58 - 1) {
        uint64_t v59 = v58 - 1;
      }
      else {
        uint64_t v59 = v58;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::AtLeastNOperands<2u>::Impl<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::AtLeastNOperands<2u>::Impl>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v55[v57], v59);
      BOOL v7 = (void *)&unk_267771000;
      uint64_t v6 = v106;
      uint64_t v4 = v112;
      uint64_t v2 = v119;
      a1 = v127;
    }
  }
  uint64_t v8 = v7[441];
  BOOL v9 = &unk_267772000;
  {
    uint64_t v128 = a1;
    uint64_t v113 = v4;
    uint64_t v120 = v2;
    uint64_t v102 = v8;
    uint64_t v107 = v6;
    BOOL v9 = (void *)&unk_267772000;
    uint64_t v8 = v102;
    uint64_t v6 = v107;
    uint64_t v4 = v113;
    uint64_t v2 = v120;
    int v61 = v60;
    a1 = v128;
    if (v61)
    {
      int v132 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::AttrSizedOperandSegments<Empty>]";
      unint64_t v133 = 96;
      unint64_t v62 = llvm::StringRef::find((uint64_t *)&v132, "DesiredTypeName = ", 0x12uLL, 0);
      if (v133 >= v62) {
        unint64_t v63 = v62;
      }
      else {
        unint64_t v63 = v133;
      }
      unint64_t v64 = &v132[v63];
      unint64_t v65 = v133 - v63;
      if (v133 - v63 >= 0x12) {
        uint64_t v66 = 18;
      }
      else {
        uint64_t v66 = v133 - v63;
      }
      unint64_t v67 = v65 - v66;
      if (v67 >= v67 - 1) {
        uint64_t v68 = v67 - 1;
      }
      else {
        uint64_t v68 = v67;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::AttrSizedOperandSegments<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::AttrSizedOperandSegments>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v64[v66], v68);
      BOOL v9 = (void *)&unk_267772000;
      uint64_t v8 = v102;
      uint64_t v6 = v107;
      uint64_t v4 = v113;
      uint64_t v2 = v120;
      a1 = v128;
    }
  }
  uint64_t v10 = v9[47];
  uint64_t v11 = &unk_267770000;
  {
    uint64_t v129 = a1;
    uint64_t v114 = v4;
    uint64_t v121 = v2;
    uint64_t v103 = v8;
    uint64_t v108 = v6;
    uint64_t v99 = v10;
    uint64_t v11 = (void *)&unk_267770000;
    uint64_t v10 = v99;
    uint64_t v8 = v103;
    uint64_t v6 = v108;
    uint64_t v4 = v114;
    uint64_t v2 = v121;
    int v70 = v69;
    a1 = v129;
    if (v70)
    {
      int v132 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::OpInvariants<Empty>]";
      unint64_t v133 = 84;
      unint64_t v71 = llvm::StringRef::find((uint64_t *)&v132, "DesiredTypeName = ", 0x12uLL, 0);
      if (v133 >= v71) {
        unint64_t v72 = v71;
      }
      else {
        unint64_t v72 = v133;
      }
      unint64_t v73 = &v132[v72];
      unint64_t v74 = v133 - v72;
      if (v133 - v72 >= 0x12) {
        uint64_t v75 = 18;
      }
      else {
        uint64_t v75 = v133 - v72;
      }
      unint64_t v76 = v74 - v75;
      if (v76 >= v76 - 1) {
        uint64_t v77 = v76 - 1;
      }
      else {
        uint64_t v77 = v76;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::OpInvariants<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::OpInvariants>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v73[v75], v77);
      uint64_t v11 = (void *)&unk_267770000;
      uint64_t v10 = v99;
      uint64_t v8 = v103;
      uint64_t v6 = v108;
      uint64_t v4 = v114;
      uint64_t v2 = v121;
      a1 = v129;
    }
  }
  uint64_t v12 = v11[435];
  unsigned int v13 = &unk_267771000;
  {
    uint64_t v130 = a1;
    uint64_t v115 = v4;
    uint64_t v122 = v2;
    uint64_t v104 = v8;
    uint64_t v109 = v6;
    uint64_t v97 = v12;
    uint64_t v100 = v10;
    unsigned int v13 = (void *)&unk_267771000;
    uint64_t v12 = v97;
    uint64_t v10 = v100;
    uint64_t v8 = v104;
    uint64_t v6 = v109;
    uint64_t v4 = v115;
    uint64_t v2 = v122;
    int v79 = v78;
    a1 = v130;
    if (v79)
    {
      int v132 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::BytecodeOpInterface::Trait<Empty>]";
      unint64_t v133 = 89;
      unint64_t v80 = llvm::StringRef::find((uint64_t *)&v132, "DesiredTypeName = ", 0x12uLL, 0);
      if (v133 >= v80) {
        unint64_t v81 = v80;
      }
      else {
        unint64_t v81 = v133;
      }
      unint64_t v82 = &v132[v81];
      unint64_t v83 = v133 - v81;
      if (v133 - v81 >= 0x12) {
        uint64_t v84 = 18;
      }
      else {
        uint64_t v84 = v133 - v81;
      }
      unint64_t v85 = v83 - v84;
      if (v85 >= v85 - 1) {
        uint64_t v86 = v85 - 1;
      }
      else {
        uint64_t v86 = v85;
      }
      mlir::detail::TypeIDResolver<mlir::BytecodeOpInterface::Trait<mlir::TypeID mlir::TypeID::get<mlir::BytecodeOpInterface::Trait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v82[v84], v86);
      unsigned int v13 = (void *)&unk_267771000;
      uint64_t v12 = v97;
      uint64_t v10 = v100;
      uint64_t v8 = v104;
      uint64_t v6 = v109;
      uint64_t v4 = v115;
      uint64_t v2 = v122;
      a1 = v130;
    }
  }
  uint64_t v14 = v13[320];
  uint64_t v15 = &unk_267772000;
  {
    uint64_t v131 = a1;
    uint64_t v116 = v4;
    uint64_t v123 = v2;
    uint64_t v105 = v8;
    uint64_t v110 = v6;
    uint64_t v98 = v12;
    uint64_t v101 = v10;
    uint64_t v96 = v14;
    uint64_t v15 = (void *)&unk_267772000;
    uint64_t v14 = v96;
    uint64_t v12 = v98;
    uint64_t v10 = v101;
    uint64_t v8 = v105;
    uint64_t v6 = v110;
    uint64_t v4 = v116;
    uint64_t v2 = v123;
    int v88 = v87;
    a1 = v131;
    if (v88)
    {
      int v132 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OffsetSizeAndStrideOpInterface::Trait<Empty>]";
      unint64_t v133 = 100;
      unint64_t v89 = llvm::StringRef::find((uint64_t *)&v132, "DesiredTypeName = ", 0x12uLL, 0);
      if (v133 >= v89) {
        unint64_t v90 = v89;
      }
      else {
        unint64_t v90 = v133;
      }
      unint64_t v91 = &v132[v90];
      unint64_t v92 = v133 - v90;
      if (v133 - v90 >= 0x12) {
        uint64_t v93 = 18;
      }
      else {
        uint64_t v93 = v133 - v90;
      }
      unint64_t v94 = v92 - v93;
      if (v94 >= v94 - 1) {
        uint64_t v95 = v94 - 1;
      }
      else {
        uint64_t v95 = v94;
      }
      mlir::detail::TypeIDResolver<mlir::OffsetSizeAndStrideOpInterface::Trait<mlir::TypeID mlir::TypeID::get<mlir::OffsetSizeAndStrideOpInterface::Trait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v91[v93], v95);
      uint64_t v15 = (void *)&unk_267772000;
      uint64_t v14 = v96;
      uint64_t v12 = v98;
      uint64_t v10 = v101;
      uint64_t v8 = v105;
      uint64_t v6 = v110;
      uint64_t v4 = v116;
      uint64_t v2 = v123;
      a1 = v131;
    }
  }
  return v2 == a1 || v4 == a1 || v6 == a1 || v8 == a1 || v10 == a1 || v12 == a1 || v14 == a1 || v15[271] == a1;
}

void llvm::detail::UniqueFunctionBase<void,mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef>::CallImpl<mlir::Op<mlir::tensor::ParallelInsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1} const>(uint64_t a1, uint64_t a2, mlir::OpAsmPrinter *a3, uint64_t a4, uint64_t a5)
{
  mlir::OpState::printOpName(a2, (uint64_t)a3, a4, a5);
  uint64_t v7 = a2;
  mlir::tensor::InsertSliceOp::print((mlir::tensor::InsertSliceOp *)&v7, a3);
}

BOOL mlir::Op<mlir::tensor::ParallelInsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait>::verifyInvariants(mlir::OpTrait::impl *a1, mlir::Operation *a2)
{
  if (!mlir::op_definition_impl::verifyTraits<mlir::OpTrait::ZeroRegions<mlir::tensor::ParallelInsertSliceOp>,mlir::OpTrait::ZeroResults<mlir::tensor::ParallelInsertSliceOp>,mlir::OpTrait::ZeroSuccessors<mlir::tensor::ParallelInsertSliceOp>,mlir::OpTrait::AtLeastNOperands<2u>::Impl<mlir::tensor::ParallelInsertSliceOp>,mlir::OpTrait::AttrSizedOperandSegments<mlir::tensor::ParallelInsertSliceOp>,mlir::OpTrait::OpInvariants<mlir::tensor::ParallelInsertSliceOp>,mlir::BytecodeOpInterface::Trait<mlir::tensor::ParallelInsertSliceOp>,mlir::OffsetSizeAndStrideOpInterface::Trait<mlir::tensor::ParallelInsertSliceOp>>(a1, a2))return 0; {
  uint64_t v4 = a1;
  }
  return mlir::tensor::ParallelInsertSliceOp::verify((mlir::tensor::ParallelInsertSliceOp *)&v4) != 0;
}

BOOL mlir::op_definition_impl::verifyTraits<mlir::OpTrait::ZeroRegions<mlir::tensor::ParallelInsertSliceOp>,mlir::OpTrait::ZeroResults<mlir::tensor::ParallelInsertSliceOp>,mlir::OpTrait::ZeroSuccessors<mlir::tensor::ParallelInsertSliceOp>,mlir::OpTrait::AtLeastNOperands<2u>::Impl<mlir::tensor::ParallelInsertSliceOp>,mlir::OpTrait::AttrSizedOperandSegments<mlir::tensor::ParallelInsertSliceOp>,mlir::OpTrait::OpInvariants<mlir::tensor::ParallelInsertSliceOp>,mlir::BytecodeOpInterface::Trait<mlir::tensor::ParallelInsertSliceOp>,mlir::OffsetSizeAndStrideOpInterface::Trait<mlir::tensor::ParallelInsertSliceOp>>(mlir::OpTrait::impl *a1, mlir::Operation *a2)
{
  if (mlir::OpTrait::impl::verifyZeroRegions(a1, a2)
    && mlir::OpTrait::impl::verifyZeroResults(a1, v3)
    && mlir::OpTrait::impl::verifyZeroSuccessors(a1, v4)
    && mlir::OpTrait::impl::verifyAtLeastNOperands(a1, (mlir::Operation *)2)
    && mlir::OpTrait::impl::verifyOperandSizeAttr((uint64_t)a1, "operandSegmentSizes", 0x13uLL)
    && (uint64_t v6 = a1,
        mlir::tensor::ParallelInsertSliceOp::verifyInvariantsImpl((mlir::tensor::ParallelInsertSliceOp *)&v6)))
  {
    return mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::memref::ReinterpretCastOp>::verifyTrait((uint64_t)a1) != 0;
  }
  else
  {
    return 0;
  }
}

uint64_t mlir::Op<mlir::tensor::ParallelInsertSliceOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::AttrSizedOperandSegments,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OffsetSizeAndStrideOpInterface::Trait>::verifyRegionInvariants()
{
  return 1;
}

void *mlir::RegisteredOperationName::Model<mlir::tensor::RankOp>::Model(void *a1, uint64_t a2)
{
  v11[6] = *MEMORY[0x263EF8340];
  BOOL v9 = v11;
  uint64_t v10 = 0x300000000;
  mlir::detail::InterfaceMap::insertModel<mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::RankOp>>((uint64_t)&v9);
  mlir::detail::InterfaceMap::insertModel<mlir::detail::ConditionallySpeculatableInterfaceTraits::Model<mlir::tensor::RankOp>>((uint64_t)&v9);
  mlir::detail::InterfaceMap::insertModel<mlir::detail::MemoryEffectOpInterfaceInterfaceTraits::Model<mlir::tensor::RankOp>>((uint64_t)&v9);
  mlir::detail::InterfaceMap::insertModel<mlir::detail::InferTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::RankOp>>((uint64_t)&v9);
  mlir::OperationName::Impl::Impl(a1, (uint64_t)"tensor.rank", 11, a2, (uint64_t)&mlir::detail::TypeIDResolver<mlir::tensor::RankOp,void>::id, (uint64_t)&v9);
  uint64_t v4 = v9;
  if (v10)
  {
    uint64_t v5 = 16 * v10;
    uint64_t v6 = (void **)((char *)v9 + 8);
    do
    {
      uint64_t v7 = *v6;
      v6 += 2;
      free(v7);
      v5 -= 16;
    }
    while (v5);
    uint64_t v4 = v9;
  }
  if (v4 != v11) {
    free(v4);
  }
  *a1 = &unk_26C37AFB0;
  return a1;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::RankOp>::~Model(uint64_t a1)
{
  *(void *)a1 = &unk_26C361F50;
  uint64_t v2 = *(void ***)(a1 + 32);
  uint64_t v3 = *(unsigned int *)(a1 + 40);
  if (v3)
  {
    uint64_t v4 = 16 * v3;
    uint64_t v5 = v2 + 1;
    do
    {
      uint64_t v6 = *v5;
      v5 += 2;
      free(v6);
      v4 -= 16;
    }
    while (v4);
    uint64_t v2 = *(void ***)(a1 + 32);
  }
  if (v2 != (void **)(a1 + 48)) {
    free(v2);
  }
  return a1;
}

void mlir::RegisteredOperationName::Model<mlir::tensor::RankOp>::~Model(uint64_t a1)
{
  *(void *)a1 = &unk_26C361F50;
  uint64_t v2 = *(void ***)(a1 + 32);
  uint64_t v3 = *(unsigned int *)(a1 + 40);
  if (v3)
  {
    uint64_t v4 = 16 * v3;
    uint64_t v5 = v2 + 1;
    do
    {
      uint64_t v6 = *v5;
      v5 += 2;
      free(v6);
      v4 -= 16;
    }
    while (v4);
    uint64_t v2 = *(void ***)(a1 + 32);
  }
  if (v2 != (void **)(a1 + 48)) {
    free(v2);
  }

  JUMPOUT(0x21667D3C0);
}

BOOL mlir::RegisteredOperationName::Model<mlir::tensor::RankOp>::foldHook(uint64_t a1, mlir::Operation *a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v15 = *MEMORY[0x263EF8340];
  unint64_t v14 = (unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &>::CallbacksHolder<mlir::Op<mlir::tensor::RankOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::IndexType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1},mlir::Op<mlir::tensor::RankOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::IndexType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1} const,void>::Callbacks
      + 2;
  BOOL v9 = (*(BOOL (**)(uint64_t, mlir::Operation *, uint64_t, uint64_t, uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &>::CallbacksHolder<mlir::Op<mlir::tensor::RankOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::IndexType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1},mlir::Op<mlir::tensor::RankOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::IndexType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1} const,void>::Callbacks
                                                                                      + 2) & 0xFFFFFFFFFFFFFFF8))((uint64_t)v13, a2, a3, a4, a5);
  char v10 = v14;
  if (v14 >= 8)
  {
    if ((v14 & 4) != 0)
    {
      if ((v14 & 2) != 0) {
        uint64_t v11 = v13;
      }
      else {
        uint64_t v11 = (llvm **)v13[0];
      }
      (*(void (**)(uint64_t, mlir::Operation *, uint64_t, uint64_t, uint64_t))((v14 & 0xFFFFFFFFFFFFFFF8) + 16))((uint64_t)v11, v5, v6, v7, v8);
    }
    if ((v10 & 2) == 0) {
      llvm::deallocate_buffer(v13[0], v13[1]);
    }
  }
  return v9;
}

BOOL mlir::RegisteredOperationName::Model<mlir::tensor::RankOp>::hasTrait(uint64_t a1, uint64_t a2)
{
  uint64_t v9 = *MEMORY[0x263EF8340];
  unint64_t v8 = (unint64_t)llvm::detail::UniqueFunctionBase<BOOL,mlir::TypeID>::CallbacksHolder<mlir::Op<mlir::tensor::RankOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::IndexType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1},mlir::Op<mlir::tensor::RankOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::IndexType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1} const,void>::Callbacks
     + 2;
  BOOL v3 = (*(BOOL (**)(uint64_t, uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<BOOL,mlir::TypeID>::CallbacksHolder<mlir::Op<mlir::tensor::RankOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::IndexType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1},mlir::Op<mlir::tensor::RankOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::IndexType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1} const,void>::Callbacks
                                                 + 2) & 0xFFFFFFFFFFFFFFF8))((uint64_t)v7, a2);
  char v4 = v8;
  if (v8 >= 8)
  {
    if ((v8 & 4) != 0)
    {
      if ((v8 & 2) != 0) {
        uint64_t v5 = v7;
      }
      else {
        uint64_t v5 = (llvm **)v7[0];
      }
      (*(void (**)(uint64_t, uint64_t))((v8 & 0xFFFFFFFFFFFFFFF8) + 16))((uint64_t)v5, v2);
    }
    if ((v4 & 2) == 0) {
      llvm::deallocate_buffer(v7[0], v7[1]);
    }
  }
  return v3;
}

void mlir::RegisteredOperationName::Model<mlir::tensor::RankOp>::getParseAssemblyFn(BOOL (**a1)(uint64_t a1, uint64_t a2)@<X8>)
{
  *a1 = mlir::tensor::RankOp::parse;
  a1[3] = (BOOL (*)(uint64_t, uint64_t))((char *)llvm::detail::UniqueFunctionBase<mlir::ParseResult,mlir::OpAsmParser &,mlir::OperationState &>::CallbacksHolder<mlir::ParseResult (*)(mlir::OpAsmParser &,mlir::OperationState &),mlir::ParseResult (*)(mlir::OpAsmParser &,mlir::OperationState &),void>::Callbacks
                                                + 2);
}

void mlir::RegisteredOperationName::Model<mlir::tensor::RankOp>::printAssembly(uint64_t a1, mlir::Operation *a2, mlir::OpAsmPrinter *a3, uint64_t a4, uint64_t a5)
{
  uint64_t v13 = *MEMORY[0x263EF8340];
  unint64_t v12 = (unint64_t)llvm::detail::UniqueFunctionBase<void,mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef>::CallbacksHolder<mlir::Op<mlir::tensor::RankOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::IndexType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1},mlir::Op<mlir::tensor::RankOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::IndexType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1} const,void>::Callbacks
      + 2;
  (*(void (**)(uint64_t, mlir::Operation *, mlir::OpAsmPrinter *, uint64_t, uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<void,mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef>::CallbacksHolder<mlir::Op<mlir::tensor::RankOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::IndexType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1},mlir::Op<mlir::tensor::RankOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::IndexType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1} const,void>::Callbacks
                                                                                              + 2) & 0xFFFFFFFFFFFFFFF8))((uint64_t)v11, a2, a3, a4, a5);
  char v9 = v12;
  if (v12 >= 8)
  {
    if ((v12 & 4) != 0)
    {
      if ((v12 & 2) != 0) {
        char v10 = v11;
      }
      else {
        char v10 = (llvm **)v11[0];
      }
      (*(void (**)(uint64_t, mlir::Operation *, mlir::OpAsmPrinter *, uint64_t, uint64_t))((v12 & 0xFFFFFFFFFFFFFFF8)
                                                                                                 + 16))((uint64_t)v10, v5, v6, v7, v8);
    }
    if ((v9 & 2) == 0) {
      llvm::deallocate_buffer(v11[0], v11[1]);
    }
  }
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::RankOp>::verifyInvariants(uint64_t a1, uint64_t a2)
{
  uint64_t v7 = *MEMORY[0x263EF8340];
  v5[0] = (uint64_t (*)(uint64_t))mlir::Op<mlir::tensor::RankOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::IndexType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::verifyInvariants;
  unint64_t v6 = (unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *>::CallbacksHolder<mlir::LogicalResult (*)(mlir::Operation *),mlir::LogicalResult (* const)(mlir::Operation *),void>::Callbacks
     + 2;
  uint64_t v2 = (*(uint64_t (**)(uint64_t (**)(uint64_t), uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *>::CallbacksHolder<mlir::LogicalResult (*)(mlir::Operation *),mlir::LogicalResult (* const)(mlir::Operation *),void>::Callbacks
                                                                             + 2) & 0xFFFFFFFFFFFFFFF8))(v5, a2);
  char v3 = v6;
  if (v6 >= 8)
  {
    if ((v6 & 4) != 0) {
      (*(void (__cdecl **)())((v6 & 0xFFFFFFFFFFFFFFF8) + 16))();
    }
    if ((v3 & 2) == 0) {
      llvm::deallocate_buffer((llvm *)v5[0], v5[1]);
    }
  }
  return v2;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::RankOp>::verifyRegionInvariants(uint64_t a1, uint64_t a2)
{
  uint64_t v7 = *MEMORY[0x263EF8340];
  v5[0] = (uint64_t (*)(uint64_t))mlir::Op<mlir::tensor::RankOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::IndexType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::verifyRegionInvariants;
  unint64_t v6 = (unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *>::CallbacksHolder<mlir::LogicalResult (*)(mlir::Operation *),mlir::LogicalResult (* const)(mlir::Operation *),void>::Callbacks
     + 2;
  uint64_t v2 = (*(uint64_t (**)(uint64_t (**)(uint64_t), uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *>::CallbacksHolder<mlir::LogicalResult (*)(mlir::Operation *),mlir::LogicalResult (* const)(mlir::Operation *),void>::Callbacks
                                                                             + 2) & 0xFFFFFFFFFFFFFFF8))(v5, a2);
  char v3 = v6;
  if (v6 >= 8)
  {
    if ((v6 & 4) != 0) {
      (*(void (__cdecl **)())((v6 & 0xFFFFFFFFFFFFFFF8) + 16))();
    }
    if ((v3 & 2) == 0) {
      llvm::deallocate_buffer((llvm *)v5[0], v5[1]);
    }
  }
  return v2;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::RankOp>::getInherentAttr(uint64_t a1, uint64_t a2, const void *a3, size_t a4)
{
  return mlir::DictionaryAttr::get(a2 + 56, a3, a4);
}

void mlir::RegisteredOperationName::Model<mlir::tensor::RankOp>::setInherentAttr(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  v9[9] = *MEMORY[0x263EF8340];
  mlir::NamedAttrList::NamedAttrList(v8, *(void *)(a2 + 56));
  if (mlir::NamedAttrList::set((uint64_t)v8, a3, a4) != a4)
  {
    uint64_t Context = (mlir::MLIRContext *)mlir::Attribute::getContext((mlir::Attribute *)(a2 + 24));
    *(void *)(a2 + 56) = mlir::NamedAttrList::getDictionary((mlir::NamedAttrList *)v8, Context);
  }
  if (v8[0] != v9) {
    free(v8[0]);
  }
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::RankOp>::verifyInherentAttrs()
{
  return 1;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::RankOp>::getOpPropertyByteSize()
{
  return 0;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::RankOp>::setPropertiesFromAttr(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, void (*a5)(void *__return_ptr, uint64_t), uint64_t a6)
{
  uint64_t v34 = *MEMORY[0x263EF8340];
  a5(v24, a6);
  if (v24[0])
  {
    int v21 = 3;
    uint64_t v22 = "this operation does not support properties";
    uint64_t v23 = 42;
    unint64_t v6 = &v21;
    uint64_t v7 = (char *)v25;
    if (v26 >= v27)
    {
      unint64_t v19 = v26 + 1;
      if (v25 <= &v21 && (char *)v25 + 24 * v26 > (char *)&v21)
      {
        int64_t v20 = (char *)&v21 - (unsigned char *)v25;
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v25, v28, v19, 24);
        uint64_t v7 = (char *)v25;
        unint64_t v6 = (int *)((char *)v25 + v20);
      }
      else
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v25, v28, v19, 24);
        unint64_t v6 = &v21;
        uint64_t v7 = (char *)v25;
      }
    }
    uint64_t v8 = &v7[24 * v26];
    long long v9 = *(_OWORD *)v6;
    *((void *)v8 + 2) = *((void *)v6 + 2);
    *(_OWORD *)uint64_t v8 = v9;
    ++v26;
    if (v24[0]) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v24);
    }
  }
  if (v33)
  {
    char v10 = __p;
    if (__p)
    {
      uint64_t v11 = v32;
      unint64_t v12 = __p;
      if (v32 != __p)
      {
        do
          uint64_t v11 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v11 - 1);
        while (v11 != v10);
        unint64_t v12 = __p;
      }
      uint64_t v32 = v10;
      operator delete(v12);
    }
    uint64_t v13 = v29;
    if (v29)
    {
      unint64_t v14 = v30;
      uint64_t v15 = v29;
      if (v30 != v29)
      {
        do
        {
          uint64_t v17 = *--v14;
          uint64_t v16 = v17;
          *unint64_t v14 = 0;
          if (v17) {
            MEMORY[0x21667D390](v16, 0x1000C8077774924);
          }
        }
        while (v14 != v13);
        uint64_t v15 = v29;
      }
      uint64_t v30 = v13;
      operator delete(v15);
    }
    if (v25 != v28) {
      free(v25);
    }
  }
  return 0;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::RankOp>::getPropertiesAsAttr()
{
  return 0;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::RankOp>::compareProperties()
{
  return 1;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::RankOp>::hashProperties()
{
  return 0;
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::RankOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(0x20uLL, 0x8004018A671A6uLL);
  *uint64_t v2 = mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::RankOp>::getAsmResultNames;
  v2[1] = mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::RankOp>::getAsmBlockArgumentNames;
  v2[2] = mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::RankOp>::getAsmBlockNames;
  v2[3] = mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::RankOp>::getDefaultDialect;
  char v3 = &unk_267771000;
  {
    unint64_t v12 = v2;
    char v3 = (void *)&unk_267771000;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpAsmOpInterface]";
      unint64_t v14 = 72;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      uint64_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::OpAsmOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      char v3 = (void *)&unk_267771000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[346], v2);
}

uint64_t mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::RankOp>::getAsmResultNames(uint64_t a1, uint64_t a2, uint64_t (*a3)(uint64_t, uint64_t, const char *, uint64_t), uint64_t a4)
{
  uint64_t v5 = a2;
  return mlir::tensor::RankOp::getAsmResultNames(&v5, a3, a4);
}

char *mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::RankOp>::getDefaultDialect()
{
  return &byte_211F4AA5D;
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::ConditionallySpeculatableInterfaceTraits::Model<mlir::tensor::RankOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(8uLL, 0x80040B8603338uLL);
  *uint64_t v2 = mlir::detail::ConditionallySpeculatableInterfaceTraits::Model<mlir::tensor::RankOp>::getSpeculatability;
  char v3 = &unk_267771000;
  {
    unint64_t v12 = v2;
    char v3 = (void *)&unk_267771000;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ConditionallySpeculatable]";
      unint64_t v14 = 81;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      uint64_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::ConditionallySpeculatable,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      char v3 = (void *)&unk_267771000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[314], v2);
}

uint64_t mlir::detail::ConditionallySpeculatableInterfaceTraits::Model<mlir::tensor::RankOp>::getSpeculatability()
{
  return 1;
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::MemoryEffectOpInterfaceInterfaceTraits::Model<mlir::tensor::RankOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(8uLL, 0x80040B8603338uLL);
  *uint64_t v2 = mlir::detail::MemoryEffectOpInterfaceInterfaceTraits::Model<mlir::tensor::RankOp>::getEffects;
  char v3 = &unk_267771000;
  {
    unint64_t v12 = v2;
    char v3 = (void *)&unk_267771000;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::MemoryEffectOpInterface]";
      unint64_t v14 = 79;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      uint64_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::MemoryEffectOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      char v3 = (void *)&unk_267771000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[11], v2);
}

void mlir::detail::MemoryEffectOpInterfaceInterfaceTraits::Model<mlir::tensor::RankOp>::getEffects(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = a2;
  ZinIrHalH13g::~ZinIrHalH13g((ZinIrHalH13g *)&v2);
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::InferTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::RankOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(0x18uLL, 0x80040D6874129uLL);
  *uint64_t v2 = mlir::detail::InferTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::RankOp>::inferReturnTypes;
  v2[1] = mlir::detail::InferTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::RankOp>::refineReturnTypes;
  v2[2] = mlir::detail::InferTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::RankOp>::isCompatibleReturnTypes;
  char v3 = &unk_267771000;
  {
    unint64_t v12 = v2;
    char v3 = (void *)&unk_267771000;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::InferTypeOpInterface]";
      unint64_t v14 = 76;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      uint64_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::InferTypeOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      char v3 = (void *)&unk_267771000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[17], v2);
}

uint64_t mlir::detail::InferTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::RankOp>::inferReturnTypes(mlir::IndexType *a1, mlir::MLIRContext *a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11)
{
  return mlir::memref::DimOp::inferReturnTypes(a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, a11);
}

uint64_t mlir::detail::InferTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::RankOp>::refineReturnTypes(mlir::IndexType *a1, mlir::MLIRContext *a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11)
{
  return mlir::detail::InferTypeOpInterfaceTrait<mlir::tensor::RankOp>::refineReturnTypes(a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, a11);
}

BOOL mlir::detail::InferTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::RankOp>::isCompatibleReturnTypes(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return a2 == a4
      && std::__equal_impl[abi:nn180100]<llvm::detail::indexed_accessor_range_base<mlir::TypeRange,llvm::PointerUnion<mlir::Value const*,mlir::Type const*,mlir::OpOperand *,mlir::detail::OpResultImpl *>,mlir::Type,mlir::Type,mlir::Type>::iterator,llvm::detail::indexed_accessor_range_base<mlir::TypeRange,llvm::PointerUnion<mlir::Value const*,mlir::Type const*,mlir::OpOperand *,mlir::detail::OpResultImpl *>,mlir::Type,mlir::Type,mlir::Type>::iterator,llvm::detail::indexed_accessor_range_base<mlir::TypeRange,llvm::PointerUnion<mlir::Value const*,mlir::Type const*,mlir::OpOperand *,mlir::detail::OpResultImpl *>,mlir::Type,mlir::Type,mlir::Type>::iterator,llvm::detail::indexed_accessor_range_base<mlir::TypeRange,llvm::PointerUnion<mlir::Value const*,mlir::Type const*,mlir::OpOperand *,mlir::detail::OpResultImpl *>,mlir::Type,mlir::Type,mlir::Type>::iterator,std::__equal_to,std::__identity,std::__identity>(a1, 0, a1, a2, a3, 0, a3, a2);
}

uint64_t mlir::detail::InferTypeOpInterfaceTrait<mlir::tensor::RankOp>::refineReturnTypes(mlir::IndexType *a1, mlir::MLIRContext *a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11)
{
  char v11 = a3;
  v22[4] = *MEMORY[0x263EF8340];
  int64_t v20 = v22;
  uint64_t v21 = 0x400000000;
  if (!mlir::memref::DimOp::inferReturnTypes(a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, (uint64_t)&v20))
  {
    uint64_t v13 = 0;
    unint64_t v14 = v20;
    if (v20 == v22) {
      return v13;
    }
    goto LABEL_7;
  }
  mlir::ValueRange::ValueRange((unint64_t *)&v18, (uint64_t)v20, v21);
  mlir::ValueRange::ValueRange(v17, *(void *)a11, *(unsigned int *)(a11 + 8));
  if (v19 == v17[1]
    && std::__equal_impl[abi:nn180100]<llvm::detail::indexed_accessor_range_base<mlir::TypeRange,llvm::PointerUnion<mlir::Value const*,mlir::Type const*,mlir::OpOperand *,mlir::detail::OpResultImpl *>,mlir::Type,mlir::Type,mlir::Type>::iterator,llvm::detail::indexed_accessor_range_base<mlir::TypeRange,llvm::PointerUnion<mlir::Value const*,mlir::Type const*,mlir::OpOperand *,mlir::detail::OpResultImpl *>,mlir::Type,mlir::Type,mlir::Type>::iterator,llvm::detail::indexed_accessor_range_base<mlir::TypeRange,llvm::PointerUnion<mlir::Value const*,mlir::Type const*,mlir::OpOperand *,mlir::detail::OpResultImpl *>,mlir::Type,mlir::Type,mlir::Type>::iterator,llvm::detail::indexed_accessor_range_base<mlir::TypeRange,llvm::PointerUnion<mlir::Value const*,mlir::Type const*,mlir::OpOperand *,mlir::detail::OpResultImpl *>,mlir::Type,mlir::Type,mlir::Type>::iterator,std::__equal_to,std::__identity,std::__identity>(v18, 0, v18, v19, v17[0], 0, v17[0], v19))
  {
    uint64_t v13 = 1;
    unint64_t v14 = v20;
    if (v20 == v22) {
      return v13;
    }
    goto LABEL_7;
  }
  v16[0] = "tensor.rank";
  v16[1] = 11;
  uint64_t v13 = mlir::emitOptionalError<char const(&)[2],llvm::StringLiteral,char const(&)[23],llvm::SmallVector<mlir::Type,4u> &,char const(&)[52],llvm::SmallVectorImpl<mlir::Type> &>((uint64_t)a2, v11, "'", (uint64_t)v16, "' op inferred type(s) ", (uint64_t)&v20, " are incompatible with return type(s) of operation ", a11);
  unint64_t v14 = v20;
  if (v20 != v22) {
LABEL_7:
  }
    free(v14);
  return v13;
}

BOOL llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &>::CallImpl<mlir::Op<mlir::tensor::RankOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::IndexType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1} const>(uint64_t a1, mlir::Operation *a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v17 = *MEMORY[0x263EF8340];
  uint64_t v13 = a2;
  mlir::tensor::detail::RankOpGenericAdaptorBase::RankOpGenericAdaptorBase((uint64_t)v14, a2);
  uint64_t v15 = a3;
  uint64_t v16 = a4;
  unint64_t v9 = mlir::memref::RankOp::fold((uint64_t)&v13);
  unint64_t v10 = v9;
  if (v9 < 8
    || (mlir::Operation *)((char *)a2 - 16) == (mlir::Operation *)(v9 & ((uint64_t)(v9 << 61) >> 63) & 0xFFFFFFFFFFFFFFF8))
  {
    return v9 > 7;
  }
  uint64_t v11 = *(unsigned int *)(a5 + 8);
  if (v11 >= *(_DWORD *)(a5 + 12))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod(a5, (void *)(a5 + 16), v11 + 1, 8);
    LODWORD(v11) = *(_DWORD *)(a5 + 8);
  }
  *(void *)(*(void *)a5 + 8 * v11) = v10;
  ++*(_DWORD *)(a5 + 8);
  return 1;
}

BOOL llvm::detail::UniqueFunctionBase<BOOL,mlir::TypeID>::CallImpl<mlir::Op<mlir::tensor::RankOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::IndexType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1} const>(uint64_t a1, uint64_t a2)
{
  return mlir::op_definition_impl::hasTrait<mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::IndexType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::InferTypeOpInterface::Trait>(a2);
}

void llvm::detail::UniqueFunctionBase<void,mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef>::CallImpl<mlir::Op<mlir::tensor::RankOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::IndexType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1} const>(uint64_t a1, mlir::Operation *a2, mlir::OpAsmPrinter *a3, uint64_t a4, uint64_t a5)
{
  mlir::OpState::printOpName((uint64_t)a2, (uint64_t)a3, a4, a5);
  uint64_t v7 = a2;
  mlir::memref::AtomicYieldOp::print(&v7, a3);
}

BOOL mlir::Op<mlir::tensor::RankOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::IndexType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::verifyInvariants(mlir::OpTrait::impl *a1, mlir::Operation *a2)
{
  if (!mlir::OpTrait::impl::verifyZeroRegions(a1, a2)
    || !mlir::OpTrait::impl::verifyOneResult(a1, v3)
    || !mlir::OpTrait::impl::verifyZeroSuccessors(a1, v4)
    || !mlir::OpTrait::impl::verifyOneOperand(a1, v5))
  {
    return 0;
  }
  uint64_t v7 = a1;
  return mlir::tensor::RankOp::verifyInvariantsImpl((mlir::tensor::RankOp *)&v7);
}

BOOL mlir::Op<mlir::tensor::RankOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::IndexType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::verifyRegionInvariants(mlir::detail *a1, mlir::Operation *a2)
{
  return mlir::detail::verifyInferredResultTypes(a1, a2) != 0;
}

void *mlir::RegisteredOperationName::Model<mlir::tensor::ReshapeOp>::Model(void *a1, uint64_t a2)
{
  v11[6] = *MEMORY[0x263EF8340];
  unint64_t v9 = v11;
  uint64_t v10 = 0x300000000;
  mlir::detail::InterfaceMap::insertModel<mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::ReshapeOp>>((uint64_t)&v9);
  mlir::detail::InterfaceMap::insertModel<mlir::detail::ConditionallySpeculatableInterfaceTraits::Model<mlir::tensor::ReshapeOp>>((uint64_t)&v9);
  mlir::detail::InterfaceMap::insertModel<mlir::detail::MemoryEffectOpInterfaceInterfaceTraits::Model<mlir::tensor::ReshapeOp>>((uint64_t)&v9);
  mlir::OperationName::Impl::Impl(a1, (uint64_t)"tensor.reshape", 14, a2, (uint64_t)&mlir::detail::TypeIDResolver<mlir::tensor::ReshapeOp,void>::id, (uint64_t)&v9);
  int v4 = v9;
  if (v10)
  {
    uint64_t v5 = 16 * v10;
    unint64_t v6 = (void **)((char *)v9 + 8);
    do
    {
      uint64_t v7 = *v6;
      v6 += 2;
      free(v7);
      v5 -= 16;
    }
    while (v5);
    int v4 = v9;
  }
  if (v4 != v11) {
    free(v4);
  }
  *a1 = &unk_26C37B6B8;
  return a1;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::ReshapeOp>::~Model(uint64_t a1)
{
  *(void *)a1 = &unk_26C361F50;
  uint64_t v2 = *(void ***)(a1 + 32);
  uint64_t v3 = *(unsigned int *)(a1 + 40);
  if (v3)
  {
    uint64_t v4 = 16 * v3;
    uint64_t v5 = v2 + 1;
    do
    {
      unint64_t v6 = *v5;
      v5 += 2;
      free(v6);
      v4 -= 16;
    }
    while (v4);
    uint64_t v2 = *(void ***)(a1 + 32);
  }
  if (v2 != (void **)(a1 + 48)) {
    free(v2);
  }
  return a1;
}

void mlir::RegisteredOperationName::Model<mlir::tensor::ReshapeOp>::~Model(uint64_t a1)
{
  *(void *)a1 = &unk_26C361F50;
  uint64_t v2 = *(void ***)(a1 + 32);
  uint64_t v3 = *(unsigned int *)(a1 + 40);
  if (v3)
  {
    uint64_t v4 = 16 * v3;
    uint64_t v5 = v2 + 1;
    do
    {
      unint64_t v6 = *v5;
      v5 += 2;
      free(v6);
      v4 -= 16;
    }
    while (v4);
    uint64_t v2 = *(void ***)(a1 + 32);
  }
  if (v2 != (void **)(a1 + 48)) {
    free(v2);
  }

  JUMPOUT(0x21667D3C0);
}

BOOL mlir::RegisteredOperationName::Model<mlir::tensor::ReshapeOp>::foldHook(uint64_t a1, unsigned int *a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v15 = *MEMORY[0x263EF8340];
  unint64_t v14 = (unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &>::CallbacksHolder<mlir::Op<mlir::tensor::ReshapeOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::TensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1},mlir::Op<mlir::tensor::ReshapeOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::TensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1} const,void>::Callbacks
      + 2;
  BOOL v9 = (*(BOOL (**)(uint64_t, unsigned int *, uint64_t, uint64_t, uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &>::CallbacksHolder<mlir::Op<mlir::tensor::ReshapeOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::TensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1},mlir::Op<mlir::tensor::ReshapeOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::TensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1} const,void>::Callbacks
                                                                                   + 2) & 0xFFFFFFFFFFFFFFF8))((uint64_t)v13, a2, a3, a4, a5);
  char v10 = v14;
  if (v14 >= 8)
  {
    if ((v14 & 4) != 0)
    {
      if ((v14 & 2) != 0) {
        uint64_t v11 = v13;
      }
      else {
        uint64_t v11 = (llvm **)v13[0];
      }
      (*(void (**)(uint64_t, uint64_t, uint64_t, uint64_t, uint64_t))((v14 & 0xFFFFFFFFFFFFFFF8) + 16))((uint64_t)v11, v5, v6, v7, v8);
    }
    if ((v10 & 2) == 0) {
      llvm::deallocate_buffer(v13[0], v13[1]);
    }
  }
  return v9;
}

BOOL mlir::RegisteredOperationName::Model<mlir::tensor::ReshapeOp>::hasTrait(uint64_t a1, uint64_t a2)
{
  uint64_t v9 = *MEMORY[0x263EF8340];
  unint64_t v8 = (unint64_t)llvm::detail::UniqueFunctionBase<BOOL,mlir::TypeID>::CallbacksHolder<mlir::Op<mlir::tensor::ReshapeOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::TensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1},mlir::Op<mlir::tensor::ReshapeOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::TensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1} const,void>::Callbacks
     + 2;
  BOOL v3 = (*(BOOL (**)(uint64_t, uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<BOOL,mlir::TypeID>::CallbacksHolder<mlir::Op<mlir::tensor::ReshapeOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::TensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1},mlir::Op<mlir::tensor::ReshapeOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::TensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1} const,void>::Callbacks
                                                 + 2) & 0xFFFFFFFFFFFFFFF8))((uint64_t)v7, a2);
  char v4 = v8;
  if (v8 >= 8)
  {
    if ((v8 & 4) != 0)
    {
      if ((v8 & 2) != 0) {
        uint64_t v5 = v7;
      }
      else {
        uint64_t v5 = (llvm **)v7[0];
      }
      (*(void (**)(uint64_t, uint64_t))((v8 & 0xFFFFFFFFFFFFFFF8) + 16))((uint64_t)v5, v2);
    }
    if ((v4 & 2) == 0) {
      llvm::deallocate_buffer(v7[0], v7[1]);
    }
  }
  return v3;
}

void mlir::RegisteredOperationName::Model<mlir::tensor::ReshapeOp>::getParseAssemblyFn(BOOL (**a1)(uint64_t a1, uint64_t a2)@<X8>)
{
  *a1 = mlir::tensor::ReshapeOp::parse;
  a1[3] = (BOOL (*)(uint64_t, uint64_t))((char *)llvm::detail::UniqueFunctionBase<mlir::ParseResult,mlir::OpAsmParser &,mlir::OperationState &>::CallbacksHolder<mlir::ParseResult (*)(mlir::OpAsmParser &,mlir::OperationState &),mlir::ParseResult (*)(mlir::OpAsmParser &,mlir::OperationState &),void>::Callbacks
                                                + 2);
}

void mlir::RegisteredOperationName::Model<mlir::tensor::ReshapeOp>::printAssembly(uint64_t a1, mlir::Operation *a2, mlir::OpAsmPrinter *a3, uint64_t a4, uint64_t a5)
{
  uint64_t v13 = *MEMORY[0x263EF8340];
  unint64_t v12 = (unint64_t)llvm::detail::UniqueFunctionBase<void,mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef>::CallbacksHolder<mlir::Op<mlir::tensor::ReshapeOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::TensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1},mlir::Op<mlir::tensor::ReshapeOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::TensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1} const,void>::Callbacks
      + 2;
  (*(void (**)(uint64_t, mlir::Operation *, mlir::OpAsmPrinter *, uint64_t, uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<void,mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef>::CallbacksHolder<mlir::Op<mlir::tensor::ReshapeOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::TensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1},mlir::Op<mlir::tensor::ReshapeOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::TensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1} const,void>::Callbacks
                                                                                              + 2) & 0xFFFFFFFFFFFFFFF8))((uint64_t)v11, a2, a3, a4, a5);
  char v9 = v12;
  if (v12 >= 8)
  {
    if ((v12 & 4) != 0)
    {
      if ((v12 & 2) != 0) {
        char v10 = v11;
      }
      else {
        char v10 = (llvm **)v11[0];
      }
      (*(void (**)(uint64_t, mlir::Operation *, mlir::OpAsmPrinter *, uint64_t, uint64_t))((v12 & 0xFFFFFFFFFFFFFFF8)
                                                                                                 + 16))((uint64_t)v10, v5, v6, v7, v8);
    }
    if ((v9 & 2) == 0) {
      llvm::deallocate_buffer(v11[0], v11[1]);
    }
  }
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::ReshapeOp>::verifyInvariants(uint64_t a1, uint64_t a2)
{
  uint64_t v7 = *MEMORY[0x263EF8340];
  v5[0] = (uint64_t (*)(uint64_t))mlir::Op<mlir::tensor::ReshapeOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::TensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::verifyInvariants;
  unint64_t v6 = (unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *>::CallbacksHolder<mlir::LogicalResult (*)(mlir::Operation *),mlir::LogicalResult (* const)(mlir::Operation *),void>::Callbacks
     + 2;
  uint64_t v2 = (*(uint64_t (**)(uint64_t (**)(uint64_t), uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *>::CallbacksHolder<mlir::LogicalResult (*)(mlir::Operation *),mlir::LogicalResult (* const)(mlir::Operation *),void>::Callbacks
                                                                             + 2) & 0xFFFFFFFFFFFFFFF8))(v5, a2);
  char v3 = v6;
  if (v6 >= 8)
  {
    if ((v6 & 4) != 0) {
      (*(void (__cdecl **)())((v6 & 0xFFFFFFFFFFFFFFF8) + 16))();
    }
    if ((v3 & 2) == 0) {
      llvm::deallocate_buffer((llvm *)v5[0], v5[1]);
    }
  }
  return v2;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::ReshapeOp>::verifyRegionInvariants(uint64_t a1, uint64_t a2)
{
  uint64_t v7 = *MEMORY[0x263EF8340];
  v5[0] = (uint64_t (*)(uint64_t))mlir::Op<mlir::tensor::ReshapeOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::TensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::verifyRegionInvariants;
  unint64_t v6 = (unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *>::CallbacksHolder<mlir::LogicalResult (*)(mlir::Operation *),mlir::LogicalResult (* const)(mlir::Operation *),void>::Callbacks
     + 2;
  uint64_t v2 = (*(uint64_t (**)(uint64_t (**)(uint64_t), uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *>::CallbacksHolder<mlir::LogicalResult (*)(mlir::Operation *),mlir::LogicalResult (* const)(mlir::Operation *),void>::Callbacks
                                                                             + 2) & 0xFFFFFFFFFFFFFFF8))(v5, a2);
  char v3 = v6;
  if (v6 >= 8)
  {
    if ((v6 & 4) != 0) {
      (*(void (__cdecl **)())((v6 & 0xFFFFFFFFFFFFFFF8) + 16))();
    }
    if ((v3 & 2) == 0) {
      llvm::deallocate_buffer((llvm *)v5[0], v5[1]);
    }
  }
  return v2;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::ReshapeOp>::getInherentAttr(uint64_t a1, uint64_t a2, const void *a3, size_t a4)
{
  return mlir::DictionaryAttr::get(a2 + 56, a3, a4);
}

void mlir::RegisteredOperationName::Model<mlir::tensor::ReshapeOp>::setInherentAttr(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  v9[9] = *MEMORY[0x263EF8340];
  mlir::NamedAttrList::NamedAttrList(v8, *(void *)(a2 + 56));
  if (mlir::NamedAttrList::set((uint64_t)v8, a3, a4) != a4)
  {
    uint64_t Context = (mlir::MLIRContext *)mlir::Attribute::getContext((mlir::Attribute *)(a2 + 24));
    *(void *)(a2 + 56) = mlir::NamedAttrList::getDictionary((mlir::NamedAttrList *)v8, Context);
  }
  if (v8[0] != v9) {
    free(v8[0]);
  }
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::ReshapeOp>::verifyInherentAttrs()
{
  return 1;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::ReshapeOp>::getOpPropertyByteSize()
{
  return 0;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::ReshapeOp>::setPropertiesFromAttr(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, void (*a5)(void *__return_ptr, uint64_t), uint64_t a6)
{
  uint64_t v34 = *MEMORY[0x263EF8340];
  a5(v24, a6);
  if (v24[0])
  {
    int v21 = 3;
    uint64_t v22 = "this operation does not support properties";
    uint64_t v23 = 42;
    unint64_t v6 = &v21;
    uint64_t v7 = (char *)v25;
    if (v26 >= v27)
    {
      unint64_t v19 = v26 + 1;
      if (v25 <= &v21 && (char *)v25 + 24 * v26 > (char *)&v21)
      {
        int64_t v20 = (char *)&v21 - (unsigned char *)v25;
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v25, v28, v19, 24);
        uint64_t v7 = (char *)v25;
        unint64_t v6 = (int *)((char *)v25 + v20);
      }
      else
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v25, v28, v19, 24);
        unint64_t v6 = &v21;
        uint64_t v7 = (char *)v25;
      }
    }
    uint64_t v8 = &v7[24 * v26];
    long long v9 = *(_OWORD *)v6;
    *((void *)v8 + 2) = *((void *)v6 + 2);
    *(_OWORD *)uint64_t v8 = v9;
    ++v26;
    if (v24[0]) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v24);
    }
  }
  if (v33)
  {
    char v10 = __p;
    if (__p)
    {
      uint64_t v11 = v32;
      unint64_t v12 = __p;
      if (v32 != __p)
      {
        do
          uint64_t v11 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v11 - 1);
        while (v11 != v10);
        unint64_t v12 = __p;
      }
      uint64_t v32 = v10;
      operator delete(v12);
    }
    uint64_t v13 = v29;
    if (v29)
    {
      unint64_t v14 = v30;
      uint64_t v15 = v29;
      if (v30 != v29)
      {
        do
        {
          uint64_t v17 = *--v14;
          uint64_t v16 = v17;
          *unint64_t v14 = 0;
          if (v17) {
            MEMORY[0x21667D390](v16, 0x1000C8077774924);
          }
        }
        while (v14 != v13);
        uint64_t v15 = v29;
      }
      uint64_t v30 = v13;
      operator delete(v15);
    }
    if (v25 != v28) {
      free(v25);
    }
  }
  return 0;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::ReshapeOp>::getPropertiesAsAttr()
{
  return 0;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::ReshapeOp>::compareProperties()
{
  return 1;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::ReshapeOp>::hashProperties()
{
  return 0;
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::ReshapeOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(0x20uLL, 0x8004018A671A6uLL);
  *uint64_t v2 = mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::ReshapeOp>::getAsmResultNames;
  v2[1] = mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::ReshapeOp>::getAsmBlockArgumentNames;
  v2[2] = mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::ReshapeOp>::getAsmBlockNames;
  v2[3] = mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::ReshapeOp>::getDefaultDialect;
  char v3 = &unk_267771000;
  {
    unint64_t v12 = v2;
    char v3 = (void *)&unk_267771000;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpAsmOpInterface]";
      unint64_t v14 = 72;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      uint64_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::OpAsmOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      char v3 = (void *)&unk_267771000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[346], v2);
}

uint64_t mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::ReshapeOp>::getAsmResultNames(uint64_t a1, uint64_t a2, uint64_t (*a3)(uint64_t, uint64_t, const char *, uint64_t), uint64_t a4)
{
  uint64_t v5 = a2;
  return mlir::memref::ReshapeOp::getAsmResultNames((uint64_t)&v5, a3, a4);
}

char *mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::ReshapeOp>::getDefaultDialect()
{
  return &byte_211F4AA5D;
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::ConditionallySpeculatableInterfaceTraits::Model<mlir::tensor::ReshapeOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(8uLL, 0x80040B8603338uLL);
  *uint64_t v2 = mlir::detail::ConditionallySpeculatableInterfaceTraits::Model<mlir::tensor::ReshapeOp>::getSpeculatability;
  char v3 = &unk_267771000;
  {
    unint64_t v12 = v2;
    char v3 = (void *)&unk_267771000;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ConditionallySpeculatable]";
      unint64_t v14 = 81;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      uint64_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::ConditionallySpeculatable,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      char v3 = (void *)&unk_267771000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[314], v2);
}

uint64_t mlir::detail::ConditionallySpeculatableInterfaceTraits::Model<mlir::tensor::ReshapeOp>::getSpeculatability()
{
  return 1;
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::MemoryEffectOpInterfaceInterfaceTraits::Model<mlir::tensor::ReshapeOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(8uLL, 0x80040B8603338uLL);
  *uint64_t v2 = mlir::detail::MemoryEffectOpInterfaceInterfaceTraits::Model<mlir::tensor::ReshapeOp>::getEffects;
  char v3 = &unk_267771000;
  {
    unint64_t v12 = v2;
    char v3 = (void *)&unk_267771000;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::MemoryEffectOpInterface]";
      unint64_t v14 = 79;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      uint64_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::MemoryEffectOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      char v3 = (void *)&unk_267771000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[11], v2);
}

void mlir::detail::MemoryEffectOpInterfaceInterfaceTraits::Model<mlir::tensor::ReshapeOp>::getEffects(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = a2;
  ZinIrHalH13g::~ZinIrHalH13g((ZinIrHalH13g *)&v2);
}

BOOL llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &>::CallImpl<mlir::Op<mlir::tensor::ReshapeOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::TensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1} const>(uint64_t a1, unsigned int *a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v17 = *MEMORY[0x263EF8340];
  uint64_t v13 = a2;
  mlir::tensor::detail::ReshapeOpGenericAdaptorBase::ReshapeOpGenericAdaptorBase((uint64_t)v14, a2);
  uint64_t v15 = a3;
  uint64_t v16 = a4;
  unint64_t v9 = mlir::tensor::ReshapeOp::fold((uint64_t)&v13, (uint64_t)v14);
  unint64_t v10 = v9;
  if (v9 < 8 || a2 - 4 == (unsigned int *)(v9 & ((uint64_t)(v9 << 61) >> 63) & 0xFFFFFFFFFFFFFFF8)) {
    return v9 > 7;
  }
  uint64_t v11 = *(unsigned int *)(a5 + 8);
  if (v11 >= *(_DWORD *)(a5 + 12))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod(a5, (void *)(a5 + 16), v11 + 1, 8);
    LODWORD(v11) = *(_DWORD *)(a5 + 8);
  }
  *(void *)(*(void *)a5 + 8 * v11) = v10;
  ++*(_DWORD *)(a5 + 8);
  return 1;
}

BOOL llvm::detail::UniqueFunctionBase<BOOL,mlir::TypeID>::CallImpl<mlir::Op<mlir::tensor::ReshapeOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::TensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1} const>(uint64_t a1, uint64_t a2)
{
  return mlir::op_definition_impl::hasTrait<mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::TensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>(a2);
}

BOOL mlir::op_definition_impl::hasTrait<mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::TensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>(uint64_t a1)
{
  uint64_t v1 = &unk_267771000;
  {
    uint64_t v165 = a1;
    uint64_t v1 = (void *)&unk_267771000;
    int v31 = v30;
    a1 = v165;
    if (v31)
    {
      uint64_t v175 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::ZeroRegions<Empty>]";
      unint64_t v176 = 83;
      unint64_t v32 = llvm::StringRef::find((uint64_t *)&v175, "DesiredTypeName = ", 0x12uLL, 0);
      if (v176 >= v32) {
        unint64_t v33 = v32;
      }
      else {
        unint64_t v33 = v176;
      }
      uint64_t v34 = &v175[v33];
      unint64_t v35 = v176 - v33;
      if (v176 - v33 >= 0x12) {
        uint64_t v36 = 18;
      }
      else {
        uint64_t v36 = v176 - v33;
      }
      unint64_t v37 = v35 - v36;
      if (v37 >= v37 - 1) {
        uint64_t v38 = v37 - 1;
      }
      else {
        uint64_t v38 = v37;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::ZeroRegions<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::ZeroRegions>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v34[v36], v38);
      uint64_t v1 = (void *)&unk_267771000;
      a1 = v165;
    }
  }
  uint64_t v2 = v1[23];
  char v3 = &unk_267771000;
  {
    uint64_t v156 = v2;
    uint64_t v166 = a1;
    char v3 = (void *)&unk_267771000;
    int v40 = v39;
    uint64_t v2 = v156;
    a1 = v166;
    if (v40)
    {
      uint64_t v175 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::OneResult<Empty>]";
      unint64_t v176 = 81;
      unint64_t v41 = llvm::StringRef::find((uint64_t *)&v175, "DesiredTypeName = ", 0x12uLL, 0);
      if (v176 >= v41) {
        unint64_t v42 = v41;
      }
      else {
        unint64_t v42 = v176;
      }
      int v43 = &v175[v42];
      unint64_t v44 = v176 - v42;
      if (v176 - v42 >= 0x12) {
        uint64_t v45 = 18;
      }
      else {
        uint64_t v45 = v176 - v42;
      }
      unint64_t v46 = v44 - v45;
      if (v46 >= v46 - 1) {
        uint64_t v47 = v46 - 1;
      }
      else {
        uint64_t v47 = v46;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::OneResult<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::OneResult>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v43[v45], v47);
      char v3 = (void *)&unk_267771000;
      uint64_t v2 = v156;
      a1 = v166;
    }
  }
  uint64_t v4 = v3[25];
  unint64_t v5 = &unk_267771000;
  {
    uint64_t v157 = v2;
    uint64_t v167 = a1;
    uint64_t v148 = v4;
    unint64_t v5 = (void *)&unk_267771000;
    uint64_t v4 = v148;
    int v49 = v48;
    uint64_t v2 = v157;
    a1 = v167;
    if (v49)
    {
      uint64_t v175 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::OneTypedResult<mlir::TensorType>::Impl<Empty>]";
      unint64_t v176 = 110;
      unint64_t v50 = llvm::StringRef::find((uint64_t *)&v175, "DesiredTypeName = ", 0x12uLL, 0);
      if (v176 >= v50) {
        unint64_t v51 = v50;
      }
      else {
        unint64_t v51 = v176;
      }
      int v52 = &v175[v51];
      unint64_t v53 = v176 - v51;
      if (v176 - v51 >= 0x12) {
        uint64_t v54 = 18;
      }
      else {
        uint64_t v54 = v176 - v51;
      }
      unint64_t v55 = v53 - v54;
      if (v55 >= v55 - 1) {
        uint64_t v56 = v55 - 1;
      }
      else {
        uint64_t v56 = v55;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::OneTypedResult<mlir::TensorType>::Impl<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::TensorType>::Impl>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v52[v54], v56);
      unint64_t v5 = (void *)&unk_267771000;
      uint64_t v4 = v148;
      uint64_t v2 = v157;
      a1 = v167;
    }
  }
  uint64_t v6 = v5[431];
  uint64_t v7 = &unk_267770000;
  {
    uint64_t v158 = v2;
    uint64_t v168 = a1;
    uint64_t v141 = v6;
    uint64_t v149 = v4;
    uint64_t v7 = (void *)&unk_267770000;
    uint64_t v6 = v141;
    uint64_t v4 = v149;
    int v58 = v57;
    uint64_t v2 = v158;
    a1 = v168;
    if (v58)
    {
      uint64_t v175 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::ZeroSuccessors<Empty>]";
      unint64_t v176 = 86;
      unint64_t v59 = llvm::StringRef::find((uint64_t *)&v175, "DesiredTypeName = ", 0x12uLL, 0);
      if (v176 >= v59) {
        unint64_t v60 = v59;
      }
      else {
        unint64_t v60 = v176;
      }
      int v61 = &v175[v60];
      unint64_t v62 = v176 - v60;
      if (v176 - v60 >= 0x12) {
        uint64_t v63 = 18;
      }
      else {
        uint64_t v63 = v176 - v60;
      }
      unint64_t v64 = v62 - v63;
      if (v64 >= v64 - 1) {
        uint64_t v65 = v64 - 1;
      }
      else {
        uint64_t v65 = v64;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::ZeroSuccessors<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::ZeroSuccessors>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v61[v63], v65);
      uint64_t v7 = (void *)&unk_267770000;
      uint64_t v6 = v141;
      uint64_t v4 = v149;
      uint64_t v2 = v158;
      a1 = v168;
    }
  }
  uint64_t v8 = v7[431];
  unint64_t v9 = &unk_267771000;
  {
    uint64_t v159 = v2;
    uint64_t v169 = a1;
    uint64_t v142 = v6;
    uint64_t v150 = v4;
    uint64_t v135 = v8;
    unint64_t v9 = (void *)&unk_267771000;
    uint64_t v8 = v135;
    uint64_t v6 = v142;
    uint64_t v4 = v150;
    int v67 = v66;
    uint64_t v2 = v159;
    a1 = v169;
    if (v67)
    {
      uint64_t v175 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::NOperands<2>::Impl<Empty>]";
      unint64_t v176 = 90;
      unint64_t v68 = llvm::StringRef::find((uint64_t *)&v175, "DesiredTypeName = ", 0x12uLL, 0);
      if (v176 >= v68) {
        unint64_t v69 = v68;
      }
      else {
        unint64_t v69 = v176;
      }
      int v70 = &v175[v69];
      unint64_t v71 = v176 - v69;
      if (v176 - v69 >= 0x12) {
        uint64_t v72 = 18;
      }
      else {
        uint64_t v72 = v176 - v69;
      }
      unint64_t v73 = v71 - v72;
      if (v73 >= v73 - 1) {
        uint64_t v74 = v73 - 1;
      }
      else {
        uint64_t v74 = v73;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::NOperands<2u>::Impl<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::NOperands<2u>::Impl>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v70[v72], v74);
      unint64_t v9 = (void *)&unk_267771000;
      uint64_t v8 = v135;
      uint64_t v6 = v142;
      uint64_t v4 = v150;
      uint64_t v2 = v159;
      a1 = v169;
    }
  }
  uint64_t v10 = v9[89];
  uint64_t v11 = &unk_267770000;
  {
    uint64_t v160 = v2;
    uint64_t v170 = a1;
    uint64_t v143 = v6;
    uint64_t v151 = v4;
    uint64_t v130 = v10;
    uint64_t v136 = v8;
    uint64_t v11 = (void *)&unk_267770000;
    uint64_t v10 = v130;
    uint64_t v8 = v136;
    uint64_t v6 = v143;
    uint64_t v4 = v151;
    int v76 = v75;
    uint64_t v2 = v160;
    a1 = v170;
    if (v76)
    {
      uint64_t v175 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::OpInvariants<Empty>]";
      unint64_t v176 = 84;
      unint64_t v77 = llvm::StringRef::find((uint64_t *)&v175, "DesiredTypeName = ", 0x12uLL, 0);
      if (v176 >= v77) {
        unint64_t v78 = v77;
      }
      else {
        unint64_t v78 = v176;
      }
      int v79 = &v175[v78];
      unint64_t v80 = v176 - v78;
      if (v176 - v78 >= 0x12) {
        uint64_t v81 = 18;
      }
      else {
        uint64_t v81 = v176 - v78;
      }
      unint64_t v82 = v80 - v81;
      if (v82 >= v82 - 1) {
        uint64_t v83 = v82 - 1;
      }
      else {
        uint64_t v83 = v82;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::OpInvariants<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::OpInvariants>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v79[v81], v83);
      uint64_t v11 = (void *)&unk_267770000;
      uint64_t v10 = v130;
      uint64_t v8 = v136;
      uint64_t v6 = v143;
      uint64_t v4 = v151;
      uint64_t v2 = v160;
      a1 = v170;
    }
  }
  uint64_t v12 = v11[435];
  uint64_t v13 = &unk_267771000;
  {
    uint64_t v161 = v2;
    uint64_t v171 = a1;
    uint64_t v144 = v6;
    uint64_t v152 = v4;
    uint64_t v131 = v10;
    uint64_t v137 = v8;
    uint64_t v126 = v12;
    uint64_t v13 = (void *)&unk_267771000;
    uint64_t v12 = v126;
    uint64_t v10 = v131;
    uint64_t v8 = v137;
    uint64_t v6 = v144;
    uint64_t v4 = v152;
    int v85 = v84;
    uint64_t v2 = v161;
    a1 = v171;
    if (v85)
    {
      uint64_t v175 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpAsmOpInterface::Trait<Empty>]";
      unint64_t v176 = 86;
      unint64_t v86 = llvm::StringRef::find((uint64_t *)&v175, "DesiredTypeName = ", 0x12uLL, 0);
      if (v176 >= v86) {
        unint64_t v87 = v86;
      }
      else {
        unint64_t v87 = v176;
      }
      int v88 = &v175[v87];
      unint64_t v89 = v176 - v87;
      if (v176 - v87 >= 0x12) {
        uint64_t v90 = 18;
      }
      else {
        uint64_t v90 = v176 - v87;
      }
      unint64_t v91 = v89 - v90;
      if (v91 >= v91 - 1) {
        uint64_t v92 = v91 - 1;
      }
      else {
        uint64_t v92 = v91;
      }
      mlir::detail::TypeIDResolver<mlir::OpAsmOpInterface::Trait<mlir::TypeID mlir::TypeID::get<mlir::OpAsmOpInterface::Trait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v88[v90], v92);
      uint64_t v13 = (void *)&unk_267771000;
      uint64_t v12 = v126;
      uint64_t v10 = v131;
      uint64_t v8 = v137;
      uint64_t v6 = v144;
      uint64_t v4 = v152;
      uint64_t v2 = v161;
      a1 = v171;
    }
  }
  uint64_t v14 = v13[350];
  uint64_t v15 = &unk_267771000;
  {
    uint64_t v162 = v2;
    uint64_t v172 = a1;
    uint64_t v145 = v6;
    uint64_t v153 = v4;
    uint64_t v132 = v10;
    uint64_t v138 = v8;
    uint64_t v123 = v14;
    uint64_t v127 = v12;
    uint64_t v15 = (void *)&unk_267771000;
    uint64_t v14 = v123;
    uint64_t v12 = v127;
    uint64_t v10 = v132;
    uint64_t v8 = v138;
    uint64_t v6 = v145;
    uint64_t v4 = v153;
    int v94 = v93;
    uint64_t v2 = v162;
    a1 = v172;
    if (v94)
    {
      uint64_t v175 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ConditionallySpeculatable::Trait<Empty>]";
      unint64_t v176 = 95;
      unint64_t v95 = llvm::StringRef::find((uint64_t *)&v175, "DesiredTypeName = ", 0x12uLL, 0);
      if (v176 >= v95) {
        unint64_t v96 = v95;
      }
      else {
        unint64_t v96 = v176;
      }
      uint64_t v97 = &v175[v96];
      unint64_t v98 = v176 - v96;
      if (v176 - v96 >= 0x12) {
        uint64_t v99 = 18;
      }
      else {
        uint64_t v99 = v176 - v96;
      }
      unint64_t v100 = v98 - v99;
      if (v100 >= v100 - 1) {
        uint64_t v101 = v100 - 1;
      }
      else {
        uint64_t v101 = v100;
      }
      mlir::detail::TypeIDResolver<mlir::ConditionallySpeculatable::Trait<mlir::TypeID mlir::TypeID::get<mlir::ConditionallySpeculatable::Trait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v97[v99], v101);
      uint64_t v15 = (void *)&unk_267771000;
      uint64_t v14 = v123;
      uint64_t v12 = v127;
      uint64_t v10 = v132;
      uint64_t v8 = v138;
      uint64_t v6 = v145;
      uint64_t v4 = v153;
      uint64_t v2 = v162;
      a1 = v172;
    }
  }
  uint64_t v16 = v15[322];
  uint64_t v17 = &unk_267771000;
  {
    uint64_t v163 = v2;
    uint64_t v173 = a1;
    uint64_t v146 = v6;
    uint64_t v154 = v4;
    uint64_t v133 = v10;
    uint64_t v139 = v8;
    uint64_t v124 = v14;
    uint64_t v128 = v12;
    uint64_t v121 = v16;
    uint64_t v17 = (void *)&unk_267771000;
    uint64_t v16 = v121;
    uint64_t v14 = v124;
    uint64_t v12 = v128;
    uint64_t v10 = v133;
    uint64_t v8 = v139;
    uint64_t v6 = v146;
    uint64_t v4 = v154;
    int v103 = v102;
    uint64_t v2 = v163;
    a1 = v173;
    if (v103)
    {
      uint64_t v175 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::AlwaysSpeculatableImplTrait<Empty>]";
      unint64_t v176 = 99;
      unint64_t v104 = llvm::StringRef::find((uint64_t *)&v175, "DesiredTypeName = ", 0x12uLL, 0);
      if (v176 >= v104) {
        unint64_t v105 = v104;
      }
      else {
        unint64_t v105 = v176;
      }
      uint64_t v106 = &v175[v105];
      unint64_t v107 = v176 - v105;
      if (v176 - v105 >= 0x12) {
        uint64_t v108 = 18;
      }
      else {
        uint64_t v108 = v176 - v105;
      }
      unint64_t v109 = v107 - v108;
      if (v109 >= v109 - 1) {
        uint64_t v110 = v109 - 1;
      }
      else {
        uint64_t v110 = v109;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::AlwaysSpeculatableImplTrait<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::AlwaysSpeculatableImplTrait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v106[v108], v110);
      uint64_t v17 = (void *)&unk_267771000;
      uint64_t v16 = v121;
      uint64_t v14 = v124;
      uint64_t v12 = v128;
      uint64_t v10 = v133;
      uint64_t v8 = v139;
      uint64_t v6 = v146;
      uint64_t v4 = v154;
      uint64_t v2 = v163;
      a1 = v173;
    }
  }
  uint64_t v18 = v17[324];
  unint64_t v19 = &unk_267771000;
  {
    uint64_t v164 = v2;
    uint64_t v174 = a1;
    uint64_t v147 = v6;
    uint64_t v155 = v4;
    uint64_t v134 = v10;
    uint64_t v140 = v8;
    uint64_t v125 = v14;
    uint64_t v129 = v12;
    uint64_t v120 = v18;
    uint64_t v122 = v16;
    unint64_t v19 = (void *)&unk_267771000;
    uint64_t v18 = v120;
    uint64_t v16 = v122;
    uint64_t v14 = v125;
    uint64_t v12 = v129;
    uint64_t v10 = v134;
    uint64_t v8 = v140;
    uint64_t v6 = v147;
    uint64_t v4 = v155;
    int v112 = v111;
    uint64_t v2 = v164;
    a1 = v174;
    if (v112)
    {
      uint64_t v175 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::MemoryEffectOpInterface::Trait<Empty>]";
      unint64_t v176 = 93;
      unint64_t v113 = llvm::StringRef::find((uint64_t *)&v175, "DesiredTypeName = ", 0x12uLL, 0);
      if (v176 >= v113) {
        unint64_t v114 = v113;
      }
      else {
        unint64_t v114 = v176;
      }
      uint64_t v115 = &v175[v114];
      unint64_t v116 = v176 - v114;
      if (v176 - v114 >= 0x12) {
        uint64_t v117 = 18;
      }
      else {
        uint64_t v117 = v176 - v114;
      }
      unint64_t v118 = v116 - v117;
      if (v118 >= v118 - 1) {
        uint64_t v119 = v118 - 1;
      }
      else {
        uint64_t v119 = v118;
      }
      mlir::detail::TypeIDResolver<mlir::MemoryEffectOpInterface::Trait<mlir::TypeID mlir::TypeID::get<mlir::MemoryEffectOpInterface::Trait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v115[v117], v119);
      unint64_t v19 = (void *)&unk_267771000;
      uint64_t v18 = v120;
      uint64_t v16 = v122;
      uint64_t v14 = v125;
      uint64_t v12 = v129;
      uint64_t v10 = v134;
      uint64_t v8 = v140;
      uint64_t v6 = v147;
      uint64_t v4 = v155;
      uint64_t v2 = v164;
      a1 = v174;
    }
  }
  return v2 == a1
      || v4 == a1
      || v6 == a1
      || v8 == a1
      || v10 == a1
      || v12 == a1
      || v14 == a1
      || v16 == a1
      || v18 == a1
      || v19[31] == a1;
}

void llvm::detail::UniqueFunctionBase<void,mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef>::CallImpl<mlir::Op<mlir::tensor::ReshapeOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::TensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1} const>(uint64_t a1, mlir::Operation *a2, mlir::OpAsmPrinter *a3, uint64_t a4, uint64_t a5)
{
  mlir::OpState::printOpName((uint64_t)a2, (uint64_t)a3, a4, a5);
  uint64_t v7 = a2;
  mlir::memref::ReshapeOp::print(&v7, a3);
}

BOOL mlir::Op<mlir::tensor::ReshapeOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::TensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::verifyInvariants(mlir::OpTrait::impl *a1, mlir::Operation *a2)
{
  if (!mlir::OpTrait::impl::verifyZeroRegions(a1, a2)) {
    return 0;
  }
  if (!mlir::OpTrait::impl::verifyOneResult(a1, v3)) {
    return 0;
  }
  if (!mlir::OpTrait::impl::verifyZeroSuccessors(a1, v4)) {
    return 0;
  }
  if (!mlir::OpTrait::impl::verifyNOperands(a1, (mlir::Operation *)2)) {
    return 0;
  }
  uint64_t v6 = a1;
  if (!mlir::tensor::ReshapeOp::verifyInvariantsImpl((mlir::tensor::ReshapeOp *)&v6)) {
    return 0;
  }
  uint64_t v6 = a1;
  return mlir::tensor::ReshapeOp::verify((mlir::tensor::ReshapeOp *)&v6) != 0;
}

uint64_t mlir::Op<mlir::tensor::ReshapeOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::TensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::verifyRegionInvariants()
{
  return 1;
}

void *mlir::RegisteredOperationName::Model<mlir::tensor::ScatterOp>::Model(void *a1, uint64_t a2)
{
  v11[6] = *MEMORY[0x263EF8340];
  unint64_t v9 = v11;
  uint64_t v10 = 0x300000000;
  mlir::detail::InterfaceMap::insertModel<mlir::detail::BytecodeOpInterfaceInterfaceTraits::Model<mlir::tensor::ScatterOp>>((uint64_t)&v9);
  mlir::detail::InterfaceMap::insertModel<mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::ScatterOp>>((uint64_t)&v9);
  mlir::detail::InterfaceMap::insertModel<mlir::detail::ConditionallySpeculatableInterfaceTraits::Model<mlir::tensor::ScatterOp>>((uint64_t)&v9);
  mlir::detail::InterfaceMap::insertModel<mlir::detail::MemoryEffectOpInterfaceInterfaceTraits::Model<mlir::tensor::ScatterOp>>((uint64_t)&v9);
  mlir::OperationName::Impl::Impl(a1, (uint64_t)"tensor.scatter", 14, a2, (uint64_t)&mlir::detail::TypeIDResolver<mlir::tensor::ScatterOp,void>::id, (uint64_t)&v9);
  uint64_t v4 = v9;
  if (v10)
  {
    uint64_t v5 = 16 * v10;
    uint64_t v6 = (void **)((char *)v9 + 8);
    do
    {
      uint64_t v7 = *v6;
      v6 += 2;
      free(v7);
      v5 -= 16;
    }
    while (v5);
    uint64_t v4 = v9;
  }
  if (v4 != v11) {
    free(v4);
  }
  *a1 = &unk_26C37B780;
  return a1;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::ScatterOp>::~Model(uint64_t a1)
{
  *(void *)a1 = &unk_26C361F50;
  uint64_t v2 = *(void ***)(a1 + 32);
  uint64_t v3 = *(unsigned int *)(a1 + 40);
  if (v3)
  {
    uint64_t v4 = 16 * v3;
    uint64_t v5 = v2 + 1;
    do
    {
      uint64_t v6 = *v5;
      v5 += 2;
      free(v6);
      v4 -= 16;
    }
    while (v4);
    uint64_t v2 = *(void ***)(a1 + 32);
  }
  if (v2 != (void **)(a1 + 48)) {
    free(v2);
  }
  return a1;
}

void mlir::RegisteredOperationName::Model<mlir::tensor::ScatterOp>::~Model(uint64_t a1)
{
  *(void *)a1 = &unk_26C361F50;
  uint64_t v2 = *(void ***)(a1 + 32);
  uint64_t v3 = *(unsigned int *)(a1 + 40);
  if (v3)
  {
    uint64_t v4 = 16 * v3;
    uint64_t v5 = v2 + 1;
    do
    {
      uint64_t v6 = *v5;
      v5 += 2;
      free(v6);
      v4 -= 16;
    }
    while (v4);
    uint64_t v2 = *(void ***)(a1 + 32);
  }
  if (v2 != (void **)(a1 + 48)) {
    free(v2);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::ScatterOp>::foldHook()
{
  uint64_t v0 = (*(uint64_t (__cdecl **)())(((unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &>::CallbacksHolder<mlir::Op<mlir::tensor::ScatterOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<3u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1},mlir::Op<mlir::tensor::ScatterOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<3u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1} const,void>::Callbacks
                                 + 2) & 0xFFFFFFFFFFFFFFF8))();
  if ((unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &>::CallbacksHolder<mlir::Op<mlir::tensor::ScatterOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<3u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1},mlir::Op<mlir::tensor::ScatterOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<3u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1} const,void>::Callbacks
     + 2 >= 8)
  {
    if (((llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &>::CallbacksHolder<mlir::Op<mlir::tensor::ScatterOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<3u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1},mlir::Op<mlir::tensor::ScatterOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<3u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1} const,void>::Callbacks
         + 2) & 4) != 0)
      (*(void (__cdecl **)())((((unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &>::CallbacksHolder<mlir::Op<mlir::tensor::ScatterOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<3u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1},mlir::Op<mlir::tensor::ScatterOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<3u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1} const,void>::Callbacks
                              + 2) & 0xFFFFFFFFFFFFFFF8)
                            + 16))();
    if (((llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &>::CallbacksHolder<mlir::Op<mlir::tensor::ScatterOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<3u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1},mlir::Op<mlir::tensor::ScatterOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<3u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1} const,void>::Callbacks
         + 2) & 2) == 0)
      llvm::deallocate_buffer(v2, v3);
  }
  return v0;
}

BOOL mlir::RegisteredOperationName::Model<mlir::tensor::ScatterOp>::hasTrait(uint64_t a1, uint64_t a2)
{
  uint64_t v9 = *MEMORY[0x263EF8340];
  unint64_t v8 = (unint64_t)llvm::detail::UniqueFunctionBase<BOOL,mlir::TypeID>::CallbacksHolder<mlir::Op<mlir::tensor::ScatterOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<3u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1},mlir::Op<mlir::tensor::ScatterOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<3u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1} const,void>::Callbacks
     + 2;
  BOOL v3 = (*(BOOL (**)(uint64_t, uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<BOOL,mlir::TypeID>::CallbacksHolder<mlir::Op<mlir::tensor::ScatterOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<3u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1},mlir::Op<mlir::tensor::ScatterOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<3u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1} const,void>::Callbacks
                                                 + 2) & 0xFFFFFFFFFFFFFFF8))((uint64_t)v7, a2);
  char v4 = v8;
  if (v8 >= 8)
  {
    if ((v8 & 4) != 0)
    {
      if ((v8 & 2) != 0) {
        uint64_t v5 = v7;
      }
      else {
        uint64_t v5 = (llvm **)v7[0];
      }
      (*(void (**)(uint64_t, uint64_t))((v8 & 0xFFFFFFFFFFFFFFF8) + 16))((uint64_t)v5, v2);
    }
    if ((v4 & 2) == 0) {
      llvm::deallocate_buffer(v7[0], v7[1]);
    }
  }
  return v3;
}

void mlir::RegisteredOperationName::Model<mlir::tensor::ScatterOp>::getParseAssemblyFn(BOOL (**a1)(uint64_t *a1, uint64_t a2)@<X8>)
{
  *a1 = mlir::tensor::ScatterOp::parse;
  a1[3] = (BOOL (*)(uint64_t *, uint64_t))((char *)llvm::detail::UniqueFunctionBase<mlir::ParseResult,mlir::OpAsmParser &,mlir::OperationState &>::CallbacksHolder<mlir::ParseResult (*)(mlir::OpAsmParser &,mlir::OperationState &),mlir::ParseResult (*)(mlir::OpAsmParser &,mlir::OperationState &),void>::Callbacks
                                                  + 2);
}

void mlir::RegisteredOperationName::Model<mlir::tensor::ScatterOp>::printAssembly(uint64_t a1, mlir::Operation *a2, mlir::OpAsmPrinter *a3, uint64_t a4, uint64_t a5)
{
  uint64_t v13 = *MEMORY[0x263EF8340];
  unint64_t v12 = (unint64_t)llvm::detail::UniqueFunctionBase<void,mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef>::CallbacksHolder<mlir::Op<mlir::tensor::ScatterOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<3u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1},mlir::Op<mlir::tensor::ScatterOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<3u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1} const,void>::Callbacks
      + 2;
  (*(void (**)(uint64_t, mlir::Operation *, mlir::OpAsmPrinter *, uint64_t, uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<void,mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef>::CallbacksHolder<mlir::Op<mlir::tensor::ScatterOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<3u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1},mlir::Op<mlir::tensor::ScatterOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<3u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1} const,void>::Callbacks
                                                                                              + 2) & 0xFFFFFFFFFFFFFFF8))((uint64_t)v11, a2, a3, a4, a5);
  char v9 = v12;
  if (v12 >= 8)
  {
    if ((v12 & 4) != 0)
    {
      if ((v12 & 2) != 0) {
        uint64_t v10 = v11;
      }
      else {
        uint64_t v10 = (llvm **)v11[0];
      }
      (*(void (**)(uint64_t, mlir::Operation *, mlir::OpAsmPrinter *, uint64_t, uint64_t))((v12 & 0xFFFFFFFFFFFFFFF8)
                                                                                                 + 16))((uint64_t)v10, v5, v6, v7, v8);
    }
    if ((v9 & 2) == 0) {
      llvm::deallocate_buffer(v11[0], v11[1]);
    }
  }
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::ScatterOp>::verifyInvariants(uint64_t a1, uint64_t a2)
{
  uint64_t v7 = *MEMORY[0x263EF8340];
  v5[0] = (uint64_t (*)(uint64_t))mlir::Op<mlir::tensor::ScatterOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<3u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::verifyInvariants;
  unint64_t v6 = (unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *>::CallbacksHolder<mlir::LogicalResult (*)(mlir::Operation *),mlir::LogicalResult (* const)(mlir::Operation *),void>::Callbacks
     + 2;
  uint64_t v2 = (*(uint64_t (**)(uint64_t (**)(uint64_t), uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *>::CallbacksHolder<mlir::LogicalResult (*)(mlir::Operation *),mlir::LogicalResult (* const)(mlir::Operation *),void>::Callbacks
                                                                             + 2) & 0xFFFFFFFFFFFFFFF8))(v5, a2);
  char v3 = v6;
  if (v6 >= 8)
  {
    if ((v6 & 4) != 0) {
      (*(void (__cdecl **)())((v6 & 0xFFFFFFFFFFFFFFF8) + 16))();
    }
    if ((v3 & 2) == 0) {
      llvm::deallocate_buffer((llvm *)v5[0], v5[1]);
    }
  }
  return v2;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::ScatterOp>::verifyRegionInvariants(uint64_t a1, uint64_t a2)
{
  uint64_t v7 = *MEMORY[0x263EF8340];
  v5[0] = (uint64_t (*)(uint64_t))mlir::Op<mlir::tensor::ScatterOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<3u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::verifyRegionInvariants;
  unint64_t v6 = (unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *>::CallbacksHolder<mlir::LogicalResult (*)(mlir::Operation *),mlir::LogicalResult (* const)(mlir::Operation *),void>::Callbacks
     + 2;
  uint64_t v2 = (*(uint64_t (**)(uint64_t (**)(uint64_t), uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *>::CallbacksHolder<mlir::LogicalResult (*)(mlir::Operation *),mlir::LogicalResult (* const)(mlir::Operation *),void>::Callbacks
                                                                             + 2) & 0xFFFFFFFFFFFFFFF8))(v5, a2);
  char v3 = v6;
  if (v6 >= 8)
  {
    if ((v6 & 4) != 0) {
      (*(void (__cdecl **)())((v6 & 0xFFFFFFFFFFFFFFF8) + 16))();
    }
    if ((v3 & 2) == 0) {
      llvm::deallocate_buffer((llvm *)v5[0], v5[1]);
    }
  }
  return v2;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::ScatterOp>::getInherentAttr(uint64_t a1, uint64_t a2, void *a3, size_t a4)
{
  int Context = mlir::Attribute::getContext((mlir::Attribute *)(a2 + 24));
  if (HIBYTE(*(_DWORD *)(a2 + 44))) {
    uint64_t v8 = (void *)(a2 + 16 * (((unint64_t)*(unsigned int *)(a2 + 44) >> 23) & 1) + 64);
  }
  else {
    uint64_t v8 = 0;
  }

  return mlir::tensor::ScatterOp::getInherentAttr(Context, v8, a3, a4);
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::ScatterOp>::setInherentAttr(uint64_t a1, uint64_t a2, uint64_t a3, void *a4)
{
  uint64_t v9 = a3;
  if (HIBYTE(*(_DWORD *)(a2 + 44))) {
    uint64_t v5 = a2 + 16 * (((unint64_t)*(unsigned int *)(a2 + 44) >> 23) & 1) + 64;
  }
  else {
    uint64_t v5 = 0;
  }
  AttrData = (void *)mlir::OpaqueAttr::getAttrData((mlir::OpaqueAttr *)&v9);
  return mlir::tensor::ScatterOp::setInherentAttr(v5, AttrData, v7, a4);
}

void mlir::RegisteredOperationName::Model<mlir::tensor::ScatterOp>::populateInherentAttrs(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t Context = mlir::Attribute::getContext((mlir::Attribute *)(a2 + 24));
  if (HIBYTE(*(_DWORD *)(a2 + 44))) {
    unint64_t v6 = (uint64_t *)(a2 + 16 * (((unint64_t)*(unsigned int *)(a2 + 44) >> 23) & 1) + 64);
  }
  else {
    unint64_t v6 = 0;
  }

  mlir::tensor::ScatterOp::populateInherentAttrs(Context, v6, a3);
}

BOOL mlir::RegisteredOperationName::Model<mlir::tensor::ScatterOp>::verifyInherentAttrs(uint64_t a1, uint64_t a2, uint64_t a3, void (*a4)(uint64_t *__return_ptr, uint64_t), uint64_t a5)
{
  return mlir::tensor::ScatterOp::verifyInherentAttrs(a2, a3, a4, a5);
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::ScatterOp>::getOpPropertyByteSize()
{
  return 16;
}

void mlir::RegisteredOperationName::Model<mlir::tensor::ScatterOp>::initProperties(uint64_t a1, uint64_t a2, uint64_t a3, _OWORD *a4)
{
  if (a4)
  {
    *(_OWORD *)a3 = *a4;
  }
  else
  {
    *(void *)a3 = 0;
    *(void *)(a3 + 8) = 0;
  }
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::ScatterOp>::setPropertiesFromAttr(uint64_t a1, uint64_t a2, uint64_t *a3, uint64_t a4, void (*a5)(void *__return_ptr, uint64_t), uint64_t a6)
{
  return mlir::tensor::ScatterOp::setPropertiesFromAttr(a3, a4, a5, a6);
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::ScatterOp>::getPropertiesAsAttr(uint64_t a1, uint64_t a2)
{
  uint64_t Context = (mlir::DictionaryAttr *)mlir::Attribute::getContext((mlir::Attribute *)(a2 + 24));
  if (HIBYTE(*(_DWORD *)(a2 + 44))) {
    char v4 = (uint64_t *)(a2 + 16 * (((unint64_t)*(unsigned int *)(a2 + 44) >> 23) & 1) + 64);
  }
  else {
    char v4 = 0;
  }

  return mlir::tensor::ScatterOp::getPropertiesAsAttr(Context, v4);
}

__n128 mlir::RegisteredOperationName::Model<mlir::tensor::ScatterOp>::copyProperties(uint64_t a1, __n128 *a2, __n128 *a3)
{
  __n128 result = *a3;
  *a2 = *a3;
  return result;
}

BOOL mlir::RegisteredOperationName::Model<mlir::tensor::ScatterOp>::compareProperties(uint64_t a1, void *a2, void *a3)
{
  return *a3 == *a2 && a3[1] == a2[1];
}

unint64_t mlir::RegisteredOperationName::Model<mlir::tensor::ScatterOp>::hashProperties(uint64_t a1, unint64_t *a2)
{
  return mlir::ModuleOp::computePropertiesHash(a2);
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::BytecodeOpInterfaceInterfaceTraits::Model<mlir::tensor::ScatterOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(0x10uLL, 0x80040803F642BuLL);
  *uint64_t v2 = mlir::detail::BytecodeOpInterfaceInterfaceTraits::Model<mlir::tensor::ScatterOp>::readProperties;
  v2[1] = mlir::detail::BytecodeOpInterfaceInterfaceTraits::Model<mlir::tensor::ScatterOp>::writeProperties;
  char v3 = &unk_267771000;
  {
    unint64_t v12 = v2;
    char v3 = (void *)&unk_267771000;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::BytecodeOpInterface]";
      unint64_t v14 = 75;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      uint64_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::BytecodeOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      char v3 = (void *)&unk_267771000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[312], v2);
}

uint64_t mlir::detail::BytecodeOpInterfaceInterfaceTraits::Model<mlir::tensor::ScatterOp>::writeProperties(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = a2;
  return mlir::tensor::GatherOp::writeProperties((uint64_t)&v4, a3);
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::ScatterOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(0x20uLL, 0x8004018A671A6uLL);
  *uint64_t v2 = mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::ScatterOp>::getAsmResultNames;
  v2[1] = mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::ScatterOp>::getAsmBlockArgumentNames;
  v2[2] = mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::ScatterOp>::getAsmBlockNames;
  v2[3] = mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::ScatterOp>::getDefaultDialect;
  char v3 = &unk_267771000;
  {
    unint64_t v12 = v2;
    char v3 = (void *)&unk_267771000;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpAsmOpInterface]";
      unint64_t v14 = 72;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      uint64_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::OpAsmOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      char v3 = (void *)&unk_267771000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[346], v2);
}

uint64_t mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::ScatterOp>::getAsmResultNames(uint64_t a1, uint64_t a2, uint64_t (*a3)(uint64_t, uint64_t, const char *, uint64_t), uint64_t a4)
{
  uint64_t v5 = a2;
  return mlir::tensor::ScatterOp::getAsmResultNames((uint64_t)&v5, a3, a4);
}

char *mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::ScatterOp>::getDefaultDialect()
{
  return &byte_211F4AA5D;
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::ConditionallySpeculatableInterfaceTraits::Model<mlir::tensor::ScatterOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(8uLL, 0x80040B8603338uLL);
  *uint64_t v2 = mlir::detail::ConditionallySpeculatableInterfaceTraits::Model<mlir::tensor::ScatterOp>::getSpeculatability;
  char v3 = &unk_267771000;
  {
    unint64_t v12 = v2;
    char v3 = (void *)&unk_267771000;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ConditionallySpeculatable]";
      unint64_t v14 = 81;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      uint64_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::ConditionallySpeculatable,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      char v3 = (void *)&unk_267771000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[314], v2);
}

uint64_t mlir::detail::ConditionallySpeculatableInterfaceTraits::Model<mlir::tensor::ScatterOp>::getSpeculatability()
{
  return 1;
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::MemoryEffectOpInterfaceInterfaceTraits::Model<mlir::tensor::ScatterOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(8uLL, 0x80040B8603338uLL);
  *uint64_t v2 = mlir::detail::MemoryEffectOpInterfaceInterfaceTraits::Model<mlir::tensor::ScatterOp>::getEffects;
  char v3 = &unk_267771000;
  {
    unint64_t v12 = v2;
    char v3 = (void *)&unk_267771000;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::MemoryEffectOpInterface]";
      unint64_t v14 = 79;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      uint64_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::MemoryEffectOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      char v3 = (void *)&unk_267771000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[11], v2);
}

void mlir::detail::MemoryEffectOpInterfaceInterfaceTraits::Model<mlir::tensor::ScatterOp>::getEffects(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = a2;
  ZinIrHalH13g::~ZinIrHalH13g((ZinIrHalH13g *)&v2);
}

uint64_t llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &>::CallImpl<mlir::Op<mlir::tensor::ScatterOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<3u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1} const>()
{
  return 0;
}

BOOL llvm::detail::UniqueFunctionBase<BOOL,mlir::TypeID>::CallImpl<mlir::Op<mlir::tensor::ScatterOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<3u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1} const>(uint64_t a1, uint64_t a2)
{
  return mlir::op_definition_impl::hasTrait<mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<3u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>(a2);
}

BOOL mlir::op_definition_impl::hasTrait<mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<3u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>(uint64_t a1)
{
  uint64_t v1 = &unk_267771000;
  {
    uint64_t v187 = a1;
    uint64_t v1 = (void *)&unk_267771000;
    int v34 = v33;
    a1 = v187;
    if (v34)
    {
      uint64_t v198 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::ZeroRegions<Empty>]";
      unint64_t v199 = 83;
      unint64_t v35 = llvm::StringRef::find((uint64_t *)&v198, "DesiredTypeName = ", 0x12uLL, 0);
      if (v199 >= v35) {
        unint64_t v36 = v35;
      }
      else {
        unint64_t v36 = v199;
      }
      unint64_t v37 = &v198[v36];
      unint64_t v38 = v199 - v36;
      if (v199 - v36 >= 0x12) {
        uint64_t v39 = 18;
      }
      else {
        uint64_t v39 = v199 - v36;
      }
      unint64_t v40 = v38 - v39;
      if (v40 >= v40 - 1) {
        uint64_t v41 = v40 - 1;
      }
      else {
        uint64_t v41 = v40;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::ZeroRegions<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::ZeroRegions>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v37[v39], v41);
      uint64_t v1 = (void *)&unk_267771000;
      a1 = v187;
    }
  }
  uint64_t v2 = v1[23];
  char v3 = &unk_267771000;
  {
    uint64_t v177 = v2;
    uint64_t v188 = a1;
    char v3 = (void *)&unk_267771000;
    int v43 = v42;
    uint64_t v2 = v177;
    a1 = v188;
    if (v43)
    {
      uint64_t v198 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::OneResult<Empty>]";
      unint64_t v199 = 81;
      unint64_t v44 = llvm::StringRef::find((uint64_t *)&v198, "DesiredTypeName = ", 0x12uLL, 0);
      if (v199 >= v44) {
        unint64_t v45 = v44;
      }
      else {
        unint64_t v45 = v199;
      }
      unint64_t v46 = &v198[v45];
      unint64_t v47 = v199 - v45;
      if (v199 - v45 >= 0x12) {
        uint64_t v48 = 18;
      }
      else {
        uint64_t v48 = v199 - v45;
      }
      unint64_t v49 = v47 - v48;
      if (v49 >= v49 - 1) {
        uint64_t v50 = v49 - 1;
      }
      else {
        uint64_t v50 = v49;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::OneResult<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::OneResult>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v46[v48], v50);
      char v3 = (void *)&unk_267771000;
      uint64_t v2 = v177;
      a1 = v188;
    }
  }
  uint64_t v4 = v3[25];
  unint64_t v5 = &unk_267771000;
  {
    uint64_t v178 = v2;
    uint64_t v189 = a1;
    uint64_t v168 = v4;
    unint64_t v5 = (void *)&unk_267771000;
    uint64_t v4 = v168;
    uint64_t v2 = v178;
    int v52 = v51;
    a1 = v189;
    if (v52)
    {
      uint64_t v198 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl<Empty>]";
      unint64_t v199 = 116;
      unint64_t v53 = llvm::StringRef::find((uint64_t *)&v198, "DesiredTypeName = ", 0x12uLL, 0);
      if (v199 >= v53) {
        unint64_t v54 = v53;
      }
      else {
        unint64_t v54 = v199;
      }
      unint64_t v55 = &v198[v54];
      unint64_t v56 = v199 - v54;
      if (v199 - v54 >= 0x12) {
        uint64_t v57 = 18;
      }
      else {
        uint64_t v57 = v199 - v54;
      }
      unint64_t v58 = v56 - v57;
      if (v58 >= v58 - 1) {
        uint64_t v59 = v58 - 1;
      }
      else {
        uint64_t v59 = v58;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v55[v57], v59);
      unint64_t v5 = (void *)&unk_267771000;
      uint64_t v4 = v168;
      uint64_t v2 = v178;
      a1 = v189;
    }
  }
  uint64_t v6 = v5[435];
  uint64_t v7 = &unk_267770000;
  {
    uint64_t v179 = v2;
    uint64_t v190 = a1;
    uint64_t v169 = v4;
    uint64_t v160 = v6;
    uint64_t v7 = (void *)&unk_267770000;
    uint64_t v6 = v160;
    uint64_t v4 = v169;
    uint64_t v2 = v179;
    int v61 = v60;
    a1 = v190;
    if (v61)
    {
      uint64_t v198 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::ZeroSuccessors<Empty>]";
      unint64_t v199 = 86;
      unint64_t v62 = llvm::StringRef::find((uint64_t *)&v198, "DesiredTypeName = ", 0x12uLL, 0);
      if (v199 >= v62) {
        unint64_t v63 = v62;
      }
      else {
        unint64_t v63 = v199;
      }
      unint64_t v64 = &v198[v63];
      unint64_t v65 = v199 - v63;
      if (v199 - v63 >= 0x12) {
        uint64_t v66 = 18;
      }
      else {
        uint64_t v66 = v199 - v63;
      }
      unint64_t v67 = v65 - v66;
      if (v67 >= v67 - 1) {
        uint64_t v68 = v67 - 1;
      }
      else {
        uint64_t v68 = v67;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::ZeroSuccessors<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::ZeroSuccessors>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v64[v66], v68);
      uint64_t v7 = (void *)&unk_267770000;
      uint64_t v6 = v160;
      uint64_t v4 = v169;
      uint64_t v2 = v179;
      a1 = v190;
    }
  }
  uint64_t v8 = v7[431];
  uint64_t v9 = &unk_267771000;
  {
    uint64_t v180 = v2;
    uint64_t v191 = a1;
    uint64_t v170 = v4;
    uint64_t v153 = v8;
    uint64_t v161 = v6;
    uint64_t v9 = (void *)&unk_267771000;
    uint64_t v8 = v153;
    uint64_t v6 = v161;
    uint64_t v4 = v170;
    uint64_t v2 = v180;
    int v70 = v69;
    a1 = v191;
    if (v70)
    {
      uint64_t v198 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::NOperands<3>::Impl<Empty>]";
      unint64_t v199 = 90;
      unint64_t v71 = llvm::StringRef::find((uint64_t *)&v198, "DesiredTypeName = ", 0x12uLL, 0);
      if (v199 >= v71) {
        unint64_t v72 = v71;
      }
      else {
        unint64_t v72 = v199;
      }
      unint64_t v73 = &v198[v72];
      unint64_t v74 = v199 - v72;
      if (v199 - v72 >= 0x12) {
        uint64_t v75 = 18;
      }
      else {
        uint64_t v75 = v199 - v72;
      }
      unint64_t v76 = v74 - v75;
      if (v76 >= v76 - 1) {
        uint64_t v77 = v76 - 1;
      }
      else {
        uint64_t v77 = v76;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::NOperands<3u>::Impl<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::NOperands<3u>::Impl>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v73[v75], v77);
      uint64_t v9 = (void *)&unk_267771000;
      uint64_t v8 = v153;
      uint64_t v6 = v161;
      uint64_t v4 = v170;
      uint64_t v2 = v180;
      a1 = v191;
    }
  }
  uint64_t v10 = v9[159];
  uint64_t v11 = &unk_267770000;
  {
    uint64_t v181 = v2;
    uint64_t v192 = a1;
    uint64_t v171 = v4;
    uint64_t v154 = v8;
    uint64_t v162 = v6;
    uint64_t v147 = v10;
    uint64_t v11 = (void *)&unk_267770000;
    uint64_t v10 = v147;
    uint64_t v8 = v154;
    uint64_t v6 = v162;
    uint64_t v4 = v171;
    uint64_t v2 = v181;
    int v79 = v78;
    a1 = v192;
    if (v79)
    {
      uint64_t v198 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::OpInvariants<Empty>]";
      unint64_t v199 = 84;
      unint64_t v80 = llvm::StringRef::find((uint64_t *)&v198, "DesiredTypeName = ", 0x12uLL, 0);
      if (v199 >= v80) {
        unint64_t v81 = v80;
      }
      else {
        unint64_t v81 = v199;
      }
      unint64_t v82 = &v198[v81];
      unint64_t v83 = v199 - v81;
      if (v199 - v81 >= 0x12) {
        uint64_t v84 = 18;
      }
      else {
        uint64_t v84 = v199 - v81;
      }
      unint64_t v85 = v83 - v84;
      if (v85 >= v85 - 1) {
        uint64_t v86 = v85 - 1;
      }
      else {
        uint64_t v86 = v85;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::OpInvariants<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::OpInvariants>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v82[v84], v86);
      uint64_t v11 = (void *)&unk_267770000;
      uint64_t v10 = v147;
      uint64_t v8 = v154;
      uint64_t v6 = v162;
      uint64_t v4 = v171;
      uint64_t v2 = v181;
      a1 = v192;
    }
  }
  uint64_t v12 = v11[435];
  uint64_t v13 = &unk_267771000;
  {
    uint64_t v182 = v2;
    uint64_t v193 = a1;
    uint64_t v172 = v4;
    uint64_t v155 = v8;
    uint64_t v163 = v6;
    uint64_t v142 = v12;
    uint64_t v148 = v10;
    uint64_t v13 = (void *)&unk_267771000;
    uint64_t v12 = v142;
    uint64_t v10 = v148;
    uint64_t v8 = v155;
    uint64_t v6 = v163;
    uint64_t v4 = v172;
    uint64_t v2 = v182;
    int v88 = v87;
    a1 = v193;
    if (v88)
    {
      uint64_t v198 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::BytecodeOpInterface::Trait<Empty>]";
      unint64_t v199 = 89;
      unint64_t v89 = llvm::StringRef::find((uint64_t *)&v198, "DesiredTypeName = ", 0x12uLL, 0);
      if (v199 >= v89) {
        unint64_t v90 = v89;
      }
      else {
        unint64_t v90 = v199;
      }
      unint64_t v91 = &v198[v90];
      unint64_t v92 = v199 - v90;
      if (v199 - v90 >= 0x12) {
        uint64_t v93 = 18;
      }
      else {
        uint64_t v93 = v199 - v90;
      }
      unint64_t v94 = v92 - v93;
      if (v94 >= v94 - 1) {
        uint64_t v95 = v94 - 1;
      }
      else {
        uint64_t v95 = v94;
      }
      mlir::detail::TypeIDResolver<mlir::BytecodeOpInterface::Trait<mlir::TypeID mlir::TypeID::get<mlir::BytecodeOpInterface::Trait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v91[v93], v95);
      uint64_t v13 = (void *)&unk_267771000;
      uint64_t v12 = v142;
      uint64_t v10 = v148;
      uint64_t v8 = v155;
      uint64_t v6 = v163;
      uint64_t v4 = v172;
      uint64_t v2 = v182;
      a1 = v193;
    }
  }
  uint64_t v14 = v13[320];
  uint64_t v15 = &unk_267771000;
  {
    uint64_t v183 = v2;
    uint64_t v194 = a1;
    uint64_t v173 = v4;
    uint64_t v156 = v8;
    uint64_t v164 = v6;
    uint64_t v143 = v12;
    uint64_t v149 = v10;
    uint64_t v138 = v14;
    uint64_t v15 = (void *)&unk_267771000;
    uint64_t v14 = v138;
    uint64_t v12 = v143;
    uint64_t v10 = v149;
    uint64_t v8 = v156;
    uint64_t v6 = v164;
    uint64_t v4 = v173;
    uint64_t v2 = v183;
    int v97 = v96;
    a1 = v194;
    if (v97)
    {
      uint64_t v198 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpAsmOpInterface::Trait<Empty>]";
      unint64_t v199 = 86;
      unint64_t v98 = llvm::StringRef::find((uint64_t *)&v198, "DesiredTypeName = ", 0x12uLL, 0);
      if (v199 >= v98) {
        unint64_t v99 = v98;
      }
      else {
        unint64_t v99 = v199;
      }
      unint64_t v100 = &v198[v99];
      unint64_t v101 = v199 - v99;
      if (v199 - v99 >= 0x12) {
        uint64_t v102 = 18;
      }
      else {
        uint64_t v102 = v199 - v99;
      }
      unint64_t v103 = v101 - v102;
      if (v103 >= v103 - 1) {
        uint64_t v104 = v103 - 1;
      }
      else {
        uint64_t v104 = v103;
      }
      mlir::detail::TypeIDResolver<mlir::OpAsmOpInterface::Trait<mlir::TypeID mlir::TypeID::get<mlir::OpAsmOpInterface::Trait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v100[v102], v104);
      uint64_t v15 = (void *)&unk_267771000;
      uint64_t v14 = v138;
      uint64_t v12 = v143;
      uint64_t v10 = v149;
      uint64_t v8 = v156;
      uint64_t v6 = v164;
      uint64_t v4 = v173;
      uint64_t v2 = v183;
      a1 = v194;
    }
  }
  uint64_t v16 = v15[350];
  uint64_t v17 = &unk_267771000;
  {
    uint64_t v184 = v2;
    uint64_t v195 = a1;
    uint64_t v174 = v4;
    uint64_t v157 = v8;
    uint64_t v165 = v6;
    uint64_t v144 = v12;
    uint64_t v150 = v10;
    uint64_t v135 = v16;
    uint64_t v139 = v14;
    uint64_t v17 = (void *)&unk_267771000;
    uint64_t v16 = v135;
    uint64_t v14 = v139;
    uint64_t v12 = v144;
    uint64_t v10 = v150;
    uint64_t v8 = v157;
    uint64_t v6 = v165;
    uint64_t v4 = v174;
    uint64_t v2 = v184;
    int v106 = v105;
    a1 = v195;
    if (v106)
    {
      uint64_t v198 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ConditionallySpeculatable::Trait<Empty>]";
      unint64_t v199 = 95;
      unint64_t v107 = llvm::StringRef::find((uint64_t *)&v198, "DesiredTypeName = ", 0x12uLL, 0);
      if (v199 >= v107) {
        unint64_t v108 = v107;
      }
      else {
        unint64_t v108 = v199;
      }
      unint64_t v109 = &v198[v108];
      unint64_t v110 = v199 - v108;
      if (v199 - v108 >= 0x12) {
        uint64_t v111 = 18;
      }
      else {
        uint64_t v111 = v199 - v108;
      }
      unint64_t v112 = v110 - v111;
      if (v112 >= v112 - 1) {
        uint64_t v113 = v112 - 1;
      }
      else {
        uint64_t v113 = v112;
      }
      mlir::detail::TypeIDResolver<mlir::ConditionallySpeculatable::Trait<mlir::TypeID mlir::TypeID::get<mlir::ConditionallySpeculatable::Trait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v109[v111], v113);
      uint64_t v17 = (void *)&unk_267771000;
      uint64_t v16 = v135;
      uint64_t v14 = v139;
      uint64_t v12 = v144;
      uint64_t v10 = v150;
      uint64_t v8 = v157;
      uint64_t v6 = v165;
      uint64_t v4 = v174;
      uint64_t v2 = v184;
      a1 = v195;
    }
  }
  uint64_t v18 = v17[322];
  unint64_t v19 = &unk_267771000;
  {
    uint64_t v185 = v2;
    uint64_t v196 = a1;
    uint64_t v175 = v4;
    uint64_t v158 = v8;
    uint64_t v166 = v6;
    uint64_t v145 = v12;
    uint64_t v151 = v10;
    uint64_t v136 = v16;
    uint64_t v140 = v14;
    uint64_t v133 = v18;
    unint64_t v19 = (void *)&unk_267771000;
    uint64_t v18 = v133;
    uint64_t v16 = v136;
    uint64_t v14 = v140;
    uint64_t v12 = v145;
    uint64_t v10 = v151;
    uint64_t v8 = v158;
    uint64_t v6 = v166;
    uint64_t v4 = v175;
    uint64_t v2 = v185;
    int v115 = v114;
    a1 = v196;
    if (v115)
    {
      uint64_t v198 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::AlwaysSpeculatableImplTrait<Empty>]";
      unint64_t v199 = 99;
      unint64_t v116 = llvm::StringRef::find((uint64_t *)&v198, "DesiredTypeName = ", 0x12uLL, 0);
      if (v199 >= v116) {
        unint64_t v117 = v116;
      }
      else {
        unint64_t v117 = v199;
      }
      unint64_t v118 = &v198[v117];
      unint64_t v119 = v199 - v117;
      if (v199 - v117 >= 0x12) {
        uint64_t v120 = 18;
      }
      else {
        uint64_t v120 = v199 - v117;
      }
      unint64_t v121 = v119 - v120;
      if (v121 >= v121 - 1) {
        uint64_t v122 = v121 - 1;
      }
      else {
        uint64_t v122 = v121;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::AlwaysSpeculatableImplTrait<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::AlwaysSpeculatableImplTrait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v118[v120], v122);
      unint64_t v19 = (void *)&unk_267771000;
      uint64_t v18 = v133;
      uint64_t v16 = v136;
      uint64_t v14 = v140;
      uint64_t v12 = v145;
      uint64_t v10 = v151;
      uint64_t v8 = v158;
      uint64_t v6 = v166;
      uint64_t v4 = v175;
      uint64_t v2 = v185;
      a1 = v196;
    }
  }
  uint64_t v20 = v19[324];
  int v21 = &unk_267771000;
  {
    uint64_t v186 = v2;
    uint64_t v197 = a1;
    uint64_t v176 = v4;
    uint64_t v159 = v8;
    uint64_t v167 = v6;
    uint64_t v146 = v12;
    uint64_t v152 = v10;
    uint64_t v137 = v16;
    uint64_t v141 = v14;
    uint64_t v132 = v20;
    uint64_t v134 = v18;
    int v21 = (void *)&unk_267771000;
    uint64_t v20 = v132;
    uint64_t v18 = v134;
    uint64_t v16 = v137;
    uint64_t v14 = v141;
    uint64_t v12 = v146;
    uint64_t v10 = v152;
    uint64_t v8 = v159;
    uint64_t v6 = v167;
    uint64_t v4 = v176;
    uint64_t v2 = v186;
    int v124 = v123;
    a1 = v197;
    if (v124)
    {
      uint64_t v198 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::MemoryEffectOpInterface::Trait<Empty>]";
      unint64_t v199 = 93;
      unint64_t v125 = llvm::StringRef::find((uint64_t *)&v198, "DesiredTypeName = ", 0x12uLL, 0);
      if (v199 >= v125) {
        unint64_t v126 = v125;
      }
      else {
        unint64_t v126 = v199;
      }
      uint64_t v127 = &v198[v126];
      unint64_t v128 = v199 - v126;
      if (v199 - v126 >= 0x12) {
        uint64_t v129 = 18;
      }
      else {
        uint64_t v129 = v199 - v126;
      }
      unint64_t v130 = v128 - v129;
      if (v130 >= v130 - 1) {
        uint64_t v131 = v130 - 1;
      }
      else {
        uint64_t v131 = v130;
      }
      mlir::detail::TypeIDResolver<mlir::MemoryEffectOpInterface::Trait<mlir::TypeID mlir::TypeID::get<mlir::MemoryEffectOpInterface::Trait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v127[v129], v131);
      int v21 = (void *)&unk_267771000;
      uint64_t v20 = v132;
      uint64_t v18 = v134;
      uint64_t v16 = v137;
      uint64_t v14 = v141;
      uint64_t v12 = v146;
      uint64_t v10 = v152;
      uint64_t v8 = v159;
      uint64_t v6 = v167;
      uint64_t v4 = v176;
      uint64_t v2 = v186;
      a1 = v197;
    }
  }
  return v2 == a1
      || v4 == a1
      || v6 == a1
      || v8 == a1
      || v10 == a1
      || v12 == a1
      || v14 == a1
      || v16 == a1
      || v18 == a1
      || v20 == a1
      || v21[31] == a1;
}

void llvm::detail::UniqueFunctionBase<void,mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef>::CallImpl<mlir::Op<mlir::tensor::ScatterOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<3u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1} const>(uint64_t a1, mlir::Operation *a2, mlir::OpAsmPrinter *a3, uint64_t a4, uint64_t a5)
{
  mlir::OpState::printOpName((uint64_t)a2, (uint64_t)a3, a4, a5);
  uint64_t v7 = a2;
  mlir::tensor::ScatterOp::print(&v7, a3);
}

BOOL mlir::Op<mlir::tensor::ScatterOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<3u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::verifyInvariants(mlir::OpTrait::impl *a1, mlir::Operation *a2)
{
  if (!mlir::OpTrait::impl::verifyZeroRegions(a1, a2)) {
    return 0;
  }
  if (!mlir::OpTrait::impl::verifyOneResult(a1, v3)) {
    return 0;
  }
  if (!mlir::OpTrait::impl::verifyZeroSuccessors(a1, v4)) {
    return 0;
  }
  if (!mlir::OpTrait::impl::verifyNOperands(a1, (mlir::Operation *)3)) {
    return 0;
  }
  uint64_t v6 = a1;
  if (!mlir::tensor::ScatterOp::verifyInvariantsImpl((mlir::tensor::ScatterOp *)&v6)) {
    return 0;
  }
  uint64_t v6 = a1;
  return mlir::tensor::ScatterOp::verify((mlir::tensor::ScatterOp *)&v6) != 0;
}

uint64_t mlir::Op<mlir::tensor::ScatterOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::NOperands<3u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::verifyRegionInvariants()
{
  return 1;
}

void *mlir::RegisteredOperationName::Model<mlir::tensor::SplatOp>::Model(void *a1, uint64_t a2)
{
  v11[6] = *MEMORY[0x263EF8340];
  uint64_t v9 = v11;
  uint64_t v10 = 0x300000000;
  mlir::detail::InterfaceMap::insertModel<mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::SplatOp>>((uint64_t)&v9);
  mlir::detail::InterfaceMap::insertModel<mlir::detail::ConditionallySpeculatableInterfaceTraits::Model<mlir::tensor::SplatOp>>((uint64_t)&v9);
  mlir::detail::InterfaceMap::insertModel<mlir::detail::MemoryEffectOpInterfaceInterfaceTraits::Model<mlir::tensor::SplatOp>>((uint64_t)&v9);
  mlir::OperationName::Impl::Impl(a1, (uint64_t)"tensor.splat", 12, a2, (uint64_t)&mlir::detail::TypeIDResolver<mlir::tensor::SplatOp,void>::id, (uint64_t)&v9);
  uint64_t v4 = v9;
  if (v10)
  {
    uint64_t v5 = 16 * v10;
    uint64_t v6 = (void **)((char *)v9 + 8);
    do
    {
      uint64_t v7 = *v6;
      v6 += 2;
      free(v7);
      v5 -= 16;
    }
    while (v5);
    uint64_t v4 = v9;
  }
  if (v4 != v11) {
    free(v4);
  }
  *a1 = &unk_26C37B140;
  return a1;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::SplatOp>::~Model(uint64_t a1)
{
  *(void *)a1 = &unk_26C361F50;
  uint64_t v2 = *(void ***)(a1 + 32);
  uint64_t v3 = *(unsigned int *)(a1 + 40);
  if (v3)
  {
    uint64_t v4 = 16 * v3;
    uint64_t v5 = v2 + 1;
    do
    {
      uint64_t v6 = *v5;
      v5 += 2;
      free(v6);
      v4 -= 16;
    }
    while (v4);
    uint64_t v2 = *(void ***)(a1 + 32);
  }
  if (v2 != (void **)(a1 + 48)) {
    free(v2);
  }
  return a1;
}

void mlir::RegisteredOperationName::Model<mlir::tensor::SplatOp>::~Model(uint64_t a1)
{
  *(void *)a1 = &unk_26C361F50;
  uint64_t v2 = *(void ***)(a1 + 32);
  uint64_t v3 = *(unsigned int *)(a1 + 40);
  if (v3)
  {
    uint64_t v4 = 16 * v3;
    uint64_t v5 = v2 + 1;
    do
    {
      uint64_t v6 = *v5;
      v5 += 2;
      free(v6);
      v4 -= 16;
    }
    while (v4);
    uint64_t v2 = *(void ***)(a1 + 32);
  }
  if (v2 != (void **)(a1 + 48)) {
    free(v2);
  }

  JUMPOUT(0x21667D3C0);
}

BOOL mlir::RegisteredOperationName::Model<mlir::tensor::SplatOp>::foldHook(uint64_t a1, mlir::Operation *a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v15 = *MEMORY[0x263EF8340];
  unint64_t v14 = (unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &>::CallbacksHolder<mlir::Op<mlir::tensor::SplatOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1},mlir::Op<mlir::tensor::SplatOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1} const,void>::Callbacks
      + 2;
  BOOL v9 = (*(BOOL (**)(uint64_t, mlir::Operation *, uint64_t, uint64_t, uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &>::CallbacksHolder<mlir::Op<mlir::tensor::SplatOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1},mlir::Op<mlir::tensor::SplatOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1} const,void>::Callbacks
                                                                                      + 2) & 0xFFFFFFFFFFFFFFF8))((uint64_t)v13, a2, a3, a4, a5);
  char v10 = v14;
  if (v14 >= 8)
  {
    if ((v14 & 4) != 0)
    {
      if ((v14 & 2) != 0) {
        uint64_t v11 = v13;
      }
      else {
        uint64_t v11 = (llvm **)v13[0];
      }
      (*(void (**)(uint64_t, uint64_t, uint64_t, uint64_t, uint64_t))((v14 & 0xFFFFFFFFFFFFFFF8) + 16))((uint64_t)v11, v5, v6, v7, v8);
    }
    if ((v10 & 2) == 0) {
      llvm::deallocate_buffer(v13[0], v13[1]);
    }
  }
  return v9;
}

BOOL mlir::RegisteredOperationName::Model<mlir::tensor::SplatOp>::hasTrait(uint64_t a1, uint64_t a2)
{
  uint64_t v9 = *MEMORY[0x263EF8340];
  unint64_t v8 = (unint64_t)llvm::detail::UniqueFunctionBase<BOOL,mlir::TypeID>::CallbacksHolder<mlir::Op<mlir::tensor::SplatOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1},mlir::Op<mlir::tensor::SplatOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1} const,void>::Callbacks
     + 2;
  BOOL v3 = (*(BOOL (**)(uint64_t, uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<BOOL,mlir::TypeID>::CallbacksHolder<mlir::Op<mlir::tensor::SplatOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1},mlir::Op<mlir::tensor::SplatOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1} const,void>::Callbacks
                                                 + 2) & 0xFFFFFFFFFFFFFFF8))((uint64_t)v7, a2);
  char v4 = v8;
  if (v8 >= 8)
  {
    if ((v8 & 4) != 0)
    {
      if ((v8 & 2) != 0) {
        uint64_t v5 = v7;
      }
      else {
        uint64_t v5 = (llvm **)v7[0];
      }
      (*(void (**)(uint64_t, uint64_t))((v8 & 0xFFFFFFFFFFFFFFF8) + 16))((uint64_t)v5, v2);
    }
    if ((v4 & 2) == 0) {
      llvm::deallocate_buffer(v7[0], v7[1]);
    }
  }
  return v3;
}

void mlir::RegisteredOperationName::Model<mlir::tensor::SplatOp>::getParseAssemblyFn(BOOL (**a1)(uint64_t a1, uint64_t a2)@<X8>)
{
  *a1 = mlir::tensor::SplatOp::parse;
  a1[3] = (BOOL (*)(uint64_t, uint64_t))((char *)llvm::detail::UniqueFunctionBase<mlir::ParseResult,mlir::OpAsmParser &,mlir::OperationState &>::CallbacksHolder<mlir::ParseResult (*)(mlir::OpAsmParser &,mlir::OperationState &),mlir::ParseResult (*)(mlir::OpAsmParser &,mlir::OperationState &),void>::Callbacks
                                                + 2);
}

void mlir::RegisteredOperationName::Model<mlir::tensor::SplatOp>::printAssembly(uint64_t a1, mlir::Operation *a2, mlir::OpAsmPrinter *a3, uint64_t a4, uint64_t a5)
{
  uint64_t v13 = *MEMORY[0x263EF8340];
  unint64_t v12 = (unint64_t)llvm::detail::UniqueFunctionBase<void,mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef>::CallbacksHolder<mlir::Op<mlir::tensor::SplatOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1},mlir::Op<mlir::tensor::SplatOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1} const,void>::Callbacks
      + 2;
  (*(void (**)(uint64_t, mlir::Operation *, mlir::OpAsmPrinter *, uint64_t, uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<void,mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef>::CallbacksHolder<mlir::Op<mlir::tensor::SplatOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1},mlir::Op<mlir::tensor::SplatOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1} const,void>::Callbacks
                                                                                              + 2) & 0xFFFFFFFFFFFFFFF8))((uint64_t)v11, a2, a3, a4, a5);
  char v9 = v12;
  if (v12 >= 8)
  {
    if ((v12 & 4) != 0)
    {
      if ((v12 & 2) != 0) {
        char v10 = v11;
      }
      else {
        char v10 = (llvm **)v11[0];
      }
      (*(void (**)(uint64_t, mlir::Operation *, mlir::OpAsmPrinter *, uint64_t, uint64_t))((v12 & 0xFFFFFFFFFFFFFFF8)
                                                                                                 + 16))((uint64_t)v10, v5, v6, v7, v8);
    }
    if ((v9 & 2) == 0) {
      llvm::deallocate_buffer(v11[0], v11[1]);
    }
  }
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::SplatOp>::verifyInvariants(uint64_t a1, uint64_t a2)
{
  uint64_t v7 = *MEMORY[0x263EF8340];
  v5[0] = (uint64_t (*)(uint64_t))mlir::Op<mlir::tensor::SplatOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::verifyInvariants;
  unint64_t v6 = (unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *>::CallbacksHolder<mlir::LogicalResult (*)(mlir::Operation *),mlir::LogicalResult (* const)(mlir::Operation *),void>::Callbacks
     + 2;
  uint64_t v2 = (*(uint64_t (**)(uint64_t (**)(uint64_t), uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *>::CallbacksHolder<mlir::LogicalResult (*)(mlir::Operation *),mlir::LogicalResult (* const)(mlir::Operation *),void>::Callbacks
                                                                             + 2) & 0xFFFFFFFFFFFFFFF8))(v5, a2);
  char v3 = v6;
  if (v6 >= 8)
  {
    if ((v6 & 4) != 0) {
      (*(void (__cdecl **)())((v6 & 0xFFFFFFFFFFFFFFF8) + 16))();
    }
    if ((v3 & 2) == 0) {
      llvm::deallocate_buffer((llvm *)v5[0], v5[1]);
    }
  }
  return v2;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::SplatOp>::verifyRegionInvariants(uint64_t a1, uint64_t a2)
{
  uint64_t v7 = *MEMORY[0x263EF8340];
  v5[0] = (uint64_t (*)(uint64_t))mlir::Op<mlir::tensor::SplatOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::verifyRegionInvariants;
  unint64_t v6 = (unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *>::CallbacksHolder<mlir::LogicalResult (*)(mlir::Operation *),mlir::LogicalResult (* const)(mlir::Operation *),void>::Callbacks
     + 2;
  uint64_t v2 = (*(uint64_t (**)(uint64_t (**)(uint64_t), uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *>::CallbacksHolder<mlir::LogicalResult (*)(mlir::Operation *),mlir::LogicalResult (* const)(mlir::Operation *),void>::Callbacks
                                                                             + 2) & 0xFFFFFFFFFFFFFFF8))(v5, a2);
  char v3 = v6;
  if (v6 >= 8)
  {
    if ((v6 & 4) != 0) {
      (*(void (__cdecl **)())((v6 & 0xFFFFFFFFFFFFFFF8) + 16))();
    }
    if ((v3 & 2) == 0) {
      llvm::deallocate_buffer((llvm *)v5[0], v5[1]);
    }
  }
  return v2;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::SplatOp>::getInherentAttr(uint64_t a1, uint64_t a2, const void *a3, size_t a4)
{
  return mlir::DictionaryAttr::get(a2 + 56, a3, a4);
}

void mlir::RegisteredOperationName::Model<mlir::tensor::SplatOp>::setInherentAttr(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  v9[9] = *MEMORY[0x263EF8340];
  mlir::NamedAttrList::NamedAttrList(v8, *(void *)(a2 + 56));
  if (mlir::NamedAttrList::set((uint64_t)v8, a3, a4) != a4)
  {
    uint64_t Context = (mlir::MLIRContext *)mlir::Attribute::getContext((mlir::Attribute *)(a2 + 24));
    *(void *)(a2 + 56) = mlir::NamedAttrList::getDictionary((mlir::NamedAttrList *)v8, Context);
  }
  if (v8[0] != v9) {
    free(v8[0]);
  }
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::SplatOp>::verifyInherentAttrs()
{
  return 1;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::SplatOp>::getOpPropertyByteSize()
{
  return 0;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::SplatOp>::setPropertiesFromAttr(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, void (*a5)(void *__return_ptr, uint64_t), uint64_t a6)
{
  uint64_t v34 = *MEMORY[0x263EF8340];
  a5(v24, a6);
  if (v24[0])
  {
    int v21 = 3;
    uint64_t v22 = "this operation does not support properties";
    uint64_t v23 = 42;
    unint64_t v6 = &v21;
    uint64_t v7 = (char *)v25;
    if (v26 >= v27)
    {
      unint64_t v19 = v26 + 1;
      if (v25 <= &v21 && (char *)v25 + 24 * v26 > (char *)&v21)
      {
        int64_t v20 = (char *)&v21 - (unsigned char *)v25;
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v25, v28, v19, 24);
        uint64_t v7 = (char *)v25;
        unint64_t v6 = (int *)((char *)v25 + v20);
      }
      else
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v25, v28, v19, 24);
        unint64_t v6 = &v21;
        uint64_t v7 = (char *)v25;
      }
    }
    uint64_t v8 = &v7[24 * v26];
    long long v9 = *(_OWORD *)v6;
    *((void *)v8 + 2) = *((void *)v6 + 2);
    *(_OWORD *)uint64_t v8 = v9;
    ++v26;
    if (v24[0]) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v24);
    }
  }
  if (v33)
  {
    char v10 = __p;
    if (__p)
    {
      uint64_t v11 = v32;
      unint64_t v12 = __p;
      if (v32 != __p)
      {
        do
          uint64_t v11 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v11 - 1);
        while (v11 != v10);
        unint64_t v12 = __p;
      }
      unint64_t v32 = v10;
      operator delete(v12);
    }
    uint64_t v13 = v29;
    if (v29)
    {
      unint64_t v14 = v30;
      uint64_t v15 = v29;
      if (v30 != v29)
      {
        do
        {
          uint64_t v17 = *--v14;
          uint64_t v16 = v17;
          *unint64_t v14 = 0;
          if (v17) {
            MEMORY[0x21667D390](v16, 0x1000C8077774924);
          }
        }
        while (v14 != v13);
        uint64_t v15 = v29;
      }
      int v30 = v13;
      operator delete(v15);
    }
    if (v25 != v28) {
      free(v25);
    }
  }
  return 0;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::SplatOp>::getPropertiesAsAttr()
{
  return 0;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::SplatOp>::compareProperties()
{
  return 1;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::SplatOp>::hashProperties()
{
  return 0;
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::SplatOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(0x20uLL, 0x8004018A671A6uLL);
  *uint64_t v2 = mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::SplatOp>::getAsmResultNames;
  v2[1] = mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::SplatOp>::getAsmBlockArgumentNames;
  v2[2] = mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::SplatOp>::getAsmBlockNames;
  v2[3] = mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::SplatOp>::getDefaultDialect;
  char v3 = &unk_267771000;
  {
    unint64_t v12 = v2;
    char v3 = (void *)&unk_267771000;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpAsmOpInterface]";
      unint64_t v14 = 72;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      uint64_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::OpAsmOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      char v3 = (void *)&unk_267771000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[346], v2);
}

uint64_t mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::SplatOp>::getAsmResultNames(uint64_t a1, uint64_t a2, uint64_t (*a3)(uint64_t, uint64_t, const char *, uint64_t), uint64_t a4)
{
  uint64_t v5 = a2;
  return mlir::tensor::SplatOp::getAsmResultNames(&v5, a3, a4);
}

char *mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::SplatOp>::getDefaultDialect()
{
  return &byte_211F4AA5D;
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::ConditionallySpeculatableInterfaceTraits::Model<mlir::tensor::SplatOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(8uLL, 0x80040B8603338uLL);
  *uint64_t v2 = mlir::detail::ConditionallySpeculatableInterfaceTraits::Model<mlir::tensor::SplatOp>::getSpeculatability;
  char v3 = &unk_267771000;
  {
    unint64_t v12 = v2;
    char v3 = (void *)&unk_267771000;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ConditionallySpeculatable]";
      unint64_t v14 = 81;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      uint64_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::ConditionallySpeculatable,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      char v3 = (void *)&unk_267771000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[314], v2);
}

uint64_t mlir::detail::ConditionallySpeculatableInterfaceTraits::Model<mlir::tensor::SplatOp>::getSpeculatability()
{
  return 1;
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::MemoryEffectOpInterfaceInterfaceTraits::Model<mlir::tensor::SplatOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(8uLL, 0x80040B8603338uLL);
  *uint64_t v2 = mlir::detail::MemoryEffectOpInterfaceInterfaceTraits::Model<mlir::tensor::SplatOp>::getEffects;
  char v3 = &unk_267771000;
  {
    unint64_t v12 = v2;
    char v3 = (void *)&unk_267771000;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::MemoryEffectOpInterface]";
      unint64_t v14 = 79;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      uint64_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::MemoryEffectOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      char v3 = (void *)&unk_267771000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[11], v2);
}

void mlir::detail::MemoryEffectOpInterfaceInterfaceTraits::Model<mlir::tensor::SplatOp>::getEffects(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = a2;
  ZinIrHalH13g::~ZinIrHalH13g((ZinIrHalH13g *)&v2);
}

BOOL llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &>::CallImpl<mlir::Op<mlir::tensor::SplatOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1} const>(uint64_t a1, mlir::Operation *a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v17 = *MEMORY[0x263EF8340];
  uint64_t v13 = a2;
  mlir::tensor::detail::SplatOpGenericAdaptorBase::SplatOpGenericAdaptorBase((uint64_t)v14, a2);
  uint64_t v15 = a3;
  uint64_t v16 = a4;
  unint64_t v9 = mlir::tensor::SplatOp::fold(&v13, (uint64_t)v14);
  unint64_t v10 = v9;
  if (v9 < 8
    || (mlir::Operation *)((char *)a2 - 16) == (mlir::Operation *)(v9 & ((uint64_t)(v9 << 61) >> 63) & 0xFFFFFFFFFFFFFFF8))
  {
    return v9 > 7;
  }
  uint64_t v11 = *(unsigned int *)(a5 + 8);
  if (v11 >= *(_DWORD *)(a5 + 12))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod(a5, (void *)(a5 + 16), v11 + 1, 8);
    LODWORD(v11) = *(_DWORD *)(a5 + 8);
  }
  *(void *)(*(void *)a5 + 8 * v11) = v10;
  ++*(_DWORD *)(a5 + 8);
  return 1;
}

BOOL llvm::detail::UniqueFunctionBase<BOOL,mlir::TypeID>::CallImpl<mlir::Op<mlir::tensor::SplatOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1} const>(uint64_t a1, uint64_t a2)
{
  return mlir::op_definition_impl::hasTrait<mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>(a2);
}

BOOL mlir::op_definition_impl::hasTrait<mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>(uint64_t a1)
{
  uint64_t v1 = &unk_267771000;
  {
    uint64_t v165 = a1;
    uint64_t v1 = (void *)&unk_267771000;
    int v31 = v30;
    a1 = v165;
    if (v31)
    {
      uint64_t v175 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::ZeroRegions<Empty>]";
      unint64_t v176 = 83;
      unint64_t v32 = llvm::StringRef::find((uint64_t *)&v175, "DesiredTypeName = ", 0x12uLL, 0);
      if (v176 >= v32) {
        unint64_t v33 = v32;
      }
      else {
        unint64_t v33 = v176;
      }
      uint64_t v34 = &v175[v33];
      unint64_t v35 = v176 - v33;
      if (v176 - v33 >= 0x12) {
        uint64_t v36 = 18;
      }
      else {
        uint64_t v36 = v176 - v33;
      }
      unint64_t v37 = v35 - v36;
      if (v37 >= v37 - 1) {
        uint64_t v38 = v37 - 1;
      }
      else {
        uint64_t v38 = v37;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::ZeroRegions<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::ZeroRegions>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v34[v36], v38);
      uint64_t v1 = (void *)&unk_267771000;
      a1 = v165;
    }
  }
  uint64_t v2 = v1[23];
  char v3 = &unk_267771000;
  {
    uint64_t v156 = v2;
    uint64_t v166 = a1;
    char v3 = (void *)&unk_267771000;
    int v40 = v39;
    uint64_t v2 = v156;
    a1 = v166;
    if (v40)
    {
      uint64_t v175 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::OneResult<Empty>]";
      unint64_t v176 = 81;
      unint64_t v41 = llvm::StringRef::find((uint64_t *)&v175, "DesiredTypeName = ", 0x12uLL, 0);
      if (v176 >= v41) {
        unint64_t v42 = v41;
      }
      else {
        unint64_t v42 = v176;
      }
      int v43 = &v175[v42];
      unint64_t v44 = v176 - v42;
      if (v176 - v42 >= 0x12) {
        uint64_t v45 = 18;
      }
      else {
        uint64_t v45 = v176 - v42;
      }
      unint64_t v46 = v44 - v45;
      if (v46 >= v46 - 1) {
        uint64_t v47 = v46 - 1;
      }
      else {
        uint64_t v47 = v46;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::OneResult<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::OneResult>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v43[v45], v47);
      char v3 = (void *)&unk_267771000;
      uint64_t v2 = v156;
      a1 = v166;
    }
  }
  uint64_t v4 = v3[25];
  unint64_t v5 = &unk_267771000;
  {
    uint64_t v157 = v2;
    uint64_t v167 = a1;
    uint64_t v148 = v4;
    unint64_t v5 = (void *)&unk_267771000;
    uint64_t v4 = v148;
    int v49 = v48;
    uint64_t v2 = v157;
    a1 = v167;
    if (v49)
    {
      uint64_t v175 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl<Empty>]";
      unint64_t v176 = 116;
      unint64_t v50 = llvm::StringRef::find((uint64_t *)&v175, "DesiredTypeName = ", 0x12uLL, 0);
      if (v176 >= v50) {
        unint64_t v51 = v50;
      }
      else {
        unint64_t v51 = v176;
      }
      int v52 = &v175[v51];
      unint64_t v53 = v176 - v51;
      if (v176 - v51 >= 0x12) {
        uint64_t v54 = 18;
      }
      else {
        uint64_t v54 = v176 - v51;
      }
      unint64_t v55 = v53 - v54;
      if (v55 >= v55 - 1) {
        uint64_t v56 = v55 - 1;
      }
      else {
        uint64_t v56 = v55;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v52[v54], v56);
      unint64_t v5 = (void *)&unk_267771000;
      uint64_t v4 = v148;
      uint64_t v2 = v157;
      a1 = v167;
    }
  }
  uint64_t v6 = v5[435];
  uint64_t v7 = &unk_267770000;
  {
    uint64_t v158 = v2;
    uint64_t v168 = a1;
    uint64_t v141 = v6;
    uint64_t v149 = v4;
    uint64_t v7 = (void *)&unk_267770000;
    uint64_t v6 = v141;
    uint64_t v4 = v149;
    int v58 = v57;
    uint64_t v2 = v158;
    a1 = v168;
    if (v58)
    {
      uint64_t v175 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::ZeroSuccessors<Empty>]";
      unint64_t v176 = 86;
      unint64_t v59 = llvm::StringRef::find((uint64_t *)&v175, "DesiredTypeName = ", 0x12uLL, 0);
      if (v176 >= v59) {
        unint64_t v60 = v59;
      }
      else {
        unint64_t v60 = v176;
      }
      int v61 = &v175[v60];
      unint64_t v62 = v176 - v60;
      if (v176 - v60 >= 0x12) {
        uint64_t v63 = 18;
      }
      else {
        uint64_t v63 = v176 - v60;
      }
      unint64_t v64 = v62 - v63;
      if (v64 >= v64 - 1) {
        uint64_t v65 = v64 - 1;
      }
      else {
        uint64_t v65 = v64;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::ZeroSuccessors<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::ZeroSuccessors>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v61[v63], v65);
      uint64_t v7 = (void *)&unk_267770000;
      uint64_t v6 = v141;
      uint64_t v4 = v149;
      uint64_t v2 = v158;
      a1 = v168;
    }
  }
  uint64_t v8 = v7[431];
  unint64_t v9 = &unk_267771000;
  {
    uint64_t v159 = v2;
    uint64_t v169 = a1;
    uint64_t v142 = v6;
    uint64_t v150 = v4;
    uint64_t v135 = v8;
    unint64_t v9 = (void *)&unk_267771000;
    uint64_t v8 = v135;
    uint64_t v6 = v142;
    uint64_t v4 = v150;
    int v67 = v66;
    uint64_t v2 = v159;
    a1 = v169;
    if (v67)
    {
      uint64_t v175 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::OneOperand<Empty>]";
      unint64_t v176 = 82;
      unint64_t v68 = llvm::StringRef::find((uint64_t *)&v175, "DesiredTypeName = ", 0x12uLL, 0);
      if (v176 >= v68) {
        unint64_t v69 = v68;
      }
      else {
        unint64_t v69 = v176;
      }
      int v70 = &v175[v69];
      unint64_t v71 = v176 - v69;
      if (v176 - v69 >= 0x12) {
        uint64_t v72 = 18;
      }
      else {
        uint64_t v72 = v176 - v69;
      }
      unint64_t v73 = v71 - v72;
      if (v73 >= v73 - 1) {
        uint64_t v74 = v73 - 1;
      }
      else {
        uint64_t v74 = v73;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::OneOperand<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::OneOperand>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v70[v72], v74);
      unint64_t v9 = (void *)&unk_267771000;
      uint64_t v8 = v135;
      uint64_t v6 = v142;
      uint64_t v4 = v150;
      uint64_t v2 = v159;
      a1 = v169;
    }
  }
  uint64_t v10 = v9[29];
  uint64_t v11 = &unk_267770000;
  {
    uint64_t v160 = v2;
    uint64_t v170 = a1;
    uint64_t v143 = v6;
    uint64_t v151 = v4;
    uint64_t v130 = v10;
    uint64_t v136 = v8;
    uint64_t v11 = (void *)&unk_267770000;
    uint64_t v10 = v130;
    uint64_t v8 = v136;
    uint64_t v6 = v143;
    uint64_t v4 = v151;
    int v76 = v75;
    uint64_t v2 = v160;
    a1 = v170;
    if (v76)
    {
      uint64_t v175 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::OpInvariants<Empty>]";
      unint64_t v176 = 84;
      unint64_t v77 = llvm::StringRef::find((uint64_t *)&v175, "DesiredTypeName = ", 0x12uLL, 0);
      if (v176 >= v77) {
        unint64_t v78 = v77;
      }
      else {
        unint64_t v78 = v176;
      }
      int v79 = &v175[v78];
      unint64_t v80 = v176 - v78;
      if (v176 - v78 >= 0x12) {
        uint64_t v81 = 18;
      }
      else {
        uint64_t v81 = v176 - v78;
      }
      unint64_t v82 = v80 - v81;
      if (v82 >= v82 - 1) {
        uint64_t v83 = v82 - 1;
      }
      else {
        uint64_t v83 = v82;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::OpInvariants<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::OpInvariants>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v79[v81], v83);
      uint64_t v11 = (void *)&unk_267770000;
      uint64_t v10 = v130;
      uint64_t v8 = v136;
      uint64_t v6 = v143;
      uint64_t v4 = v151;
      uint64_t v2 = v160;
      a1 = v170;
    }
  }
  uint64_t v12 = v11[435];
  uint64_t v13 = &unk_267771000;
  {
    uint64_t v161 = v2;
    uint64_t v171 = a1;
    uint64_t v144 = v6;
    uint64_t v152 = v4;
    uint64_t v131 = v10;
    uint64_t v137 = v8;
    uint64_t v126 = v12;
    uint64_t v13 = (void *)&unk_267771000;
    uint64_t v12 = v126;
    uint64_t v10 = v131;
    uint64_t v8 = v137;
    uint64_t v6 = v144;
    uint64_t v4 = v152;
    int v85 = v84;
    uint64_t v2 = v161;
    a1 = v171;
    if (v85)
    {
      uint64_t v175 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpAsmOpInterface::Trait<Empty>]";
      unint64_t v176 = 86;
      unint64_t v86 = llvm::StringRef::find((uint64_t *)&v175, "DesiredTypeName = ", 0x12uLL, 0);
      if (v176 >= v86) {
        unint64_t v87 = v86;
      }
      else {
        unint64_t v87 = v176;
      }
      int v88 = &v175[v87];
      unint64_t v89 = v176 - v87;
      if (v176 - v87 >= 0x12) {
        uint64_t v90 = 18;
      }
      else {
        uint64_t v90 = v176 - v87;
      }
      unint64_t v91 = v89 - v90;
      if (v91 >= v91 - 1) {
        uint64_t v92 = v91 - 1;
      }
      else {
        uint64_t v92 = v91;
      }
      mlir::detail::TypeIDResolver<mlir::OpAsmOpInterface::Trait<mlir::TypeID mlir::TypeID::get<mlir::OpAsmOpInterface::Trait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v88[v90], v92);
      uint64_t v13 = (void *)&unk_267771000;
      uint64_t v12 = v126;
      uint64_t v10 = v131;
      uint64_t v8 = v137;
      uint64_t v6 = v144;
      uint64_t v4 = v152;
      uint64_t v2 = v161;
      a1 = v171;
    }
  }
  uint64_t v14 = v13[350];
  uint64_t v15 = &unk_267771000;
  {
    uint64_t v162 = v2;
    uint64_t v172 = a1;
    uint64_t v145 = v6;
    uint64_t v153 = v4;
    uint64_t v132 = v10;
    uint64_t v138 = v8;
    uint64_t v123 = v14;
    uint64_t v127 = v12;
    uint64_t v15 = (void *)&unk_267771000;
    uint64_t v14 = v123;
    uint64_t v12 = v127;
    uint64_t v10 = v132;
    uint64_t v8 = v138;
    uint64_t v6 = v145;
    uint64_t v4 = v153;
    int v94 = v93;
    uint64_t v2 = v162;
    a1 = v172;
    if (v94)
    {
      uint64_t v175 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ConditionallySpeculatable::Trait<Empty>]";
      unint64_t v176 = 95;
      unint64_t v95 = llvm::StringRef::find((uint64_t *)&v175, "DesiredTypeName = ", 0x12uLL, 0);
      if (v176 >= v95) {
        unint64_t v96 = v95;
      }
      else {
        unint64_t v96 = v176;
      }
      int v97 = &v175[v96];
      unint64_t v98 = v176 - v96;
      if (v176 - v96 >= 0x12) {
        uint64_t v99 = 18;
      }
      else {
        uint64_t v99 = v176 - v96;
      }
      unint64_t v100 = v98 - v99;
      if (v100 >= v100 - 1) {
        uint64_t v101 = v100 - 1;
      }
      else {
        uint64_t v101 = v100;
      }
      mlir::detail::TypeIDResolver<mlir::ConditionallySpeculatable::Trait<mlir::TypeID mlir::TypeID::get<mlir::ConditionallySpeculatable::Trait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v97[v99], v101);
      uint64_t v15 = (void *)&unk_267771000;
      uint64_t v14 = v123;
      uint64_t v12 = v127;
      uint64_t v10 = v132;
      uint64_t v8 = v138;
      uint64_t v6 = v145;
      uint64_t v4 = v153;
      uint64_t v2 = v162;
      a1 = v172;
    }
  }
  uint64_t v16 = v15[322];
  uint64_t v17 = &unk_267771000;
  {
    uint64_t v163 = v2;
    uint64_t v173 = a1;
    uint64_t v146 = v6;
    uint64_t v154 = v4;
    uint64_t v133 = v10;
    uint64_t v139 = v8;
    uint64_t v124 = v14;
    uint64_t v128 = v12;
    uint64_t v121 = v16;
    uint64_t v17 = (void *)&unk_267771000;
    uint64_t v16 = v121;
    uint64_t v14 = v124;
    uint64_t v12 = v128;
    uint64_t v10 = v133;
    uint64_t v8 = v139;
    uint64_t v6 = v146;
    uint64_t v4 = v154;
    int v103 = v102;
    uint64_t v2 = v163;
    a1 = v173;
    if (v103)
    {
      uint64_t v175 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::AlwaysSpeculatableImplTrait<Empty>]";
      unint64_t v176 = 99;
      unint64_t v104 = llvm::StringRef::find((uint64_t *)&v175, "DesiredTypeName = ", 0x12uLL, 0);
      if (v176 >= v104) {
        unint64_t v105 = v104;
      }
      else {
        unint64_t v105 = v176;
      }
      int v106 = &v175[v105];
      unint64_t v107 = v176 - v105;
      if (v176 - v105 >= 0x12) {
        uint64_t v108 = 18;
      }
      else {
        uint64_t v108 = v176 - v105;
      }
      unint64_t v109 = v107 - v108;
      if (v109 >= v109 - 1) {
        uint64_t v110 = v109 - 1;
      }
      else {
        uint64_t v110 = v109;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::AlwaysSpeculatableImplTrait<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::AlwaysSpeculatableImplTrait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v106[v108], v110);
      uint64_t v17 = (void *)&unk_267771000;
      uint64_t v16 = v121;
      uint64_t v14 = v124;
      uint64_t v12 = v128;
      uint64_t v10 = v133;
      uint64_t v8 = v139;
      uint64_t v6 = v146;
      uint64_t v4 = v154;
      uint64_t v2 = v163;
      a1 = v173;
    }
  }
  uint64_t v18 = v17[324];
  unint64_t v19 = &unk_267771000;
  {
    uint64_t v164 = v2;
    uint64_t v174 = a1;
    uint64_t v147 = v6;
    uint64_t v155 = v4;
    uint64_t v134 = v10;
    uint64_t v140 = v8;
    uint64_t v125 = v14;
    uint64_t v129 = v12;
    uint64_t v120 = v18;
    uint64_t v122 = v16;
    unint64_t v19 = (void *)&unk_267771000;
    uint64_t v18 = v120;
    uint64_t v16 = v122;
    uint64_t v14 = v125;
    uint64_t v12 = v129;
    uint64_t v10 = v134;
    uint64_t v8 = v140;
    uint64_t v6 = v147;
    uint64_t v4 = v155;
    int v112 = v111;
    uint64_t v2 = v164;
    a1 = v174;
    if (v112)
    {
      uint64_t v175 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::MemoryEffectOpInterface::Trait<Empty>]";
      unint64_t v176 = 93;
      unint64_t v113 = llvm::StringRef::find((uint64_t *)&v175, "DesiredTypeName = ", 0x12uLL, 0);
      if (v176 >= v113) {
        unint64_t v114 = v113;
      }
      else {
        unint64_t v114 = v176;
      }
      int v115 = &v175[v114];
      unint64_t v116 = v176 - v114;
      if (v176 - v114 >= 0x12) {
        uint64_t v117 = 18;
      }
      else {
        uint64_t v117 = v176 - v114;
      }
      unint64_t v118 = v116 - v117;
      if (v118 >= v118 - 1) {
        uint64_t v119 = v118 - 1;
      }
      else {
        uint64_t v119 = v118;
      }
      mlir::detail::TypeIDResolver<mlir::MemoryEffectOpInterface::Trait<mlir::TypeID mlir::TypeID::get<mlir::MemoryEffectOpInterface::Trait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v115[v117], v119);
      unint64_t v19 = (void *)&unk_267771000;
      uint64_t v18 = v120;
      uint64_t v16 = v122;
      uint64_t v14 = v125;
      uint64_t v12 = v129;
      uint64_t v10 = v134;
      uint64_t v8 = v140;
      uint64_t v6 = v147;
      uint64_t v4 = v155;
      uint64_t v2 = v164;
      a1 = v174;
    }
  }
  return v2 == a1
      || v4 == a1
      || v6 == a1
      || v8 == a1
      || v10 == a1
      || v12 == a1
      || v14 == a1
      || v16 == a1
      || v18 == a1
      || v19[31] == a1;
}

void llvm::detail::UniqueFunctionBase<void,mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef>::CallImpl<mlir::Op<mlir::tensor::SplatOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1} const>(uint64_t a1, mlir::Operation *a2, mlir::OpAsmPrinter *a3, uint64_t a4, uint64_t a5)
{
  mlir::OpState::printOpName((uint64_t)a2, (uint64_t)a3, a4, a5);
  uint64_t v7 = a2;
  mlir::tensor::SplatOp::print(&v7, a3);
}

BOOL mlir::Op<mlir::tensor::SplatOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::verifyInvariants(mlir::OpTrait::impl *a1, mlir::Operation *a2)
{
  if (!mlir::OpTrait::impl::verifyZeroRegions(a1, a2)
    || !mlir::OpTrait::impl::verifyOneResult(a1, v3)
    || !mlir::OpTrait::impl::verifyZeroSuccessors(a1, v4)
    || !mlir::OpTrait::impl::verifyOneOperand(a1, v5))
  {
    return 0;
  }
  uint64_t v7 = a1;
  return mlir::tensor::SplatOp::verifyInvariantsImpl((mlir::tensor::SplatOp *)&v7) != 0;
}

uint64_t mlir::Op<mlir::tensor::SplatOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::OpInvariants,mlir::OpAsmOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait>::verifyRegionInvariants()
{
  return 1;
}

void *mlir::RegisteredOperationName::Model<mlir::tensor::UnPackOp>::Model(void *a1, uint64_t a2)
{
  v11[6] = *MEMORY[0x263EF8340];
  unint64_t v9 = v11;
  uint64_t v10 = 0x300000000;
  mlir::detail::InterfaceMap::insertModel<mlir::detail::BytecodeOpInterfaceInterfaceTraits::Model<mlir::tensor::UnPackOp>>((uint64_t)&v9);
  mlir::detail::InterfaceMap::insertModel<mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::UnPackOp>>((uint64_t)&v9);
  mlir::detail::InterfaceMap::insertModel<mlir::detail::DestinationStyleOpInterfaceInterfaceTraits::Model<mlir::tensor::UnPackOp>>((uint64_t)&v9);
  mlir::detail::InterfaceMap::insertModel<mlir::detail::ConditionallySpeculatableInterfaceTraits::Model<mlir::tensor::UnPackOp>>((uint64_t)&v9);
  mlir::detail::InterfaceMap::insertModel<mlir::detail::MemoryEffectOpInterfaceInterfaceTraits::Model<mlir::tensor::UnPackOp>>((uint64_t)&v9);
  mlir::detail::InterfaceMap::insertModel<mlir::detail::ReifyRankedShapedTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::UnPackOp>>((uint64_t)&v9);
  mlir::detail::InterfaceMap::insertModel<mlir::detail::InferTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::UnPackOp>>((uint64_t)&v9);
  mlir::OperationName::Impl::Impl(a1, (uint64_t)"tensor.unpack", 13, a2, (uint64_t)&mlir::detail::TypeIDResolver<mlir::tensor::UnPackOp,void>::id, (uint64_t)&v9);
  uint64_t v4 = v9;
  if (v10)
  {
    uint64_t v5 = 16 * v10;
    uint64_t v6 = (void **)((char *)v9 + 8);
    do
    {
      uint64_t v7 = *v6;
      v6 += 2;
      free(v7);
      v5 -= 16;
    }
    while (v5);
    uint64_t v4 = v9;
  }
  if (v4 != v11) {
    free(v4);
  }
  *a1 = &unk_26C37B460;
  return a1;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::UnPackOp>::~Model(uint64_t a1)
{
  *(void *)a1 = &unk_26C361F50;
  uint64_t v2 = *(void ***)(a1 + 32);
  uint64_t v3 = *(unsigned int *)(a1 + 40);
  if (v3)
  {
    uint64_t v4 = 16 * v3;
    uint64_t v5 = v2 + 1;
    do
    {
      uint64_t v6 = *v5;
      v5 += 2;
      free(v6);
      v4 -= 16;
    }
    while (v4);
    uint64_t v2 = *(void ***)(a1 + 32);
  }
  if (v2 != (void **)(a1 + 48)) {
    free(v2);
  }
  return a1;
}

void mlir::RegisteredOperationName::Model<mlir::tensor::UnPackOp>::~Model(uint64_t a1)
{
  *(void *)a1 = &unk_26C361F50;
  uint64_t v2 = *(void ***)(a1 + 32);
  uint64_t v3 = *(unsigned int *)(a1 + 40);
  if (v3)
  {
    uint64_t v4 = 16 * v3;
    uint64_t v5 = v2 + 1;
    do
    {
      uint64_t v6 = *v5;
      v5 += 2;
      free(v6);
      v4 -= 16;
    }
    while (v4);
    uint64_t v2 = *(void ***)(a1 + 32);
  }
  if (v2 != (void **)(a1 + 48)) {
    free(v2);
  }

  JUMPOUT(0x21667D3C0);
}

BOOL mlir::RegisteredOperationName::Model<mlir::tensor::UnPackOp>::foldHook(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v15 = *MEMORY[0x263EF8340];
  unint64_t v14 = (unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &>::CallbacksHolder<mlir::Op<mlir::tensor::UnPackOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1},mlir::Op<mlir::tensor::UnPackOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1} const,void>::Callbacks
      + 2;
  BOOL v9 = (*(BOOL (**)(uint64_t, uint64_t, uint64_t, uint64_t, uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &>::CallbacksHolder<mlir::Op<mlir::tensor::UnPackOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1},mlir::Op<mlir::tensor::UnPackOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1} const,void>::Callbacks
                                                                            + 2) & 0xFFFFFFFFFFFFFFF8))((uint64_t)v13, a2, a3, a4, a5);
  char v10 = v14;
  if (v14 >= 8)
  {
    if ((v14 & 4) != 0)
    {
      if ((v14 & 2) != 0) {
        uint64_t v11 = v13;
      }
      else {
        uint64_t v11 = (llvm **)v13[0];
      }
      (*(void (**)(uint64_t, unsigned int *, uint64_t, uint64_t, uint64_t))((v14 & 0xFFFFFFFFFFFFFFF8) + 16))((uint64_t)v11, v5, v6, v7, v8);
    }
    if ((v10 & 2) == 0) {
      llvm::deallocate_buffer(v13[0], v13[1]);
    }
  }
  return v9;
}

void mlir::RegisteredOperationName::Model<mlir::tensor::UnPackOp>::getCanonicalizationPatterns()
{
}

BOOL mlir::RegisteredOperationName::Model<mlir::tensor::UnPackOp>::hasTrait(uint64_t a1, uint64_t a2)
{
  uint64_t v9 = *MEMORY[0x263EF8340];
  unint64_t v8 = (unint64_t)llvm::detail::UniqueFunctionBase<BOOL,mlir::TypeID>::CallbacksHolder<mlir::Op<mlir::tensor::UnPackOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1},mlir::Op<mlir::tensor::UnPackOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1} const,void>::Callbacks
     + 2;
  BOOL v3 = (*(BOOL (**)(uint64_t, uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<BOOL,mlir::TypeID>::CallbacksHolder<mlir::Op<mlir::tensor::UnPackOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1},mlir::Op<mlir::tensor::UnPackOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1} const,void>::Callbacks
                                                 + 2) & 0xFFFFFFFFFFFFFFF8))((uint64_t)v7, a2);
  char v4 = v8;
  if (v8 >= 8)
  {
    if ((v8 & 4) != 0)
    {
      if ((v8 & 2) != 0) {
        uint64_t v5 = v7;
      }
      else {
        uint64_t v5 = (llvm **)v7[0];
      }
      (*(void (**)(uint64_t, uint64_t))((v8 & 0xFFFFFFFFFFFFFFF8) + 16))((uint64_t)v5, v2);
    }
    if ((v4 & 2) == 0) {
      llvm::deallocate_buffer(v7[0], v7[1]);
    }
  }
  return v3;
}

void mlir::RegisteredOperationName::Model<mlir::tensor::UnPackOp>::getParseAssemblyFn(uint64_t (**a1)(uint64_t a1, uint64_t a2)@<X8>)
{
  *a1 = mlir::tensor::UnPackOp::parse;
  a1[3] = (uint64_t (*)(uint64_t, uint64_t))((char *)llvm::detail::UniqueFunctionBase<mlir::ParseResult,mlir::OpAsmParser &,mlir::OperationState &>::CallbacksHolder<mlir::ParseResult (*)(mlir::OpAsmParser &,mlir::OperationState &),mlir::ParseResult (*)(mlir::OpAsmParser &,mlir::OperationState &),void>::Callbacks
                                                   + 2);
}

void mlir::RegisteredOperationName::Model<mlir::tensor::UnPackOp>::printAssembly(uint64_t a1, uint64_t a2, mlir::OpAsmPrinter *a3, uint64_t a4, uint64_t a5)
{
  uint64_t v13 = *MEMORY[0x263EF8340];
  unint64_t v12 = (unint64_t)llvm::detail::UniqueFunctionBase<void,mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef>::CallbacksHolder<mlir::Op<mlir::tensor::UnPackOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1},mlir::Op<mlir::tensor::UnPackOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1} const,void>::Callbacks
      + 2;
  (*(void (**)(uint64_t, uint64_t, mlir::OpAsmPrinter *, uint64_t, uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<void,mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef>::CallbacksHolder<mlir::Op<mlir::tensor::UnPackOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1},mlir::Op<mlir::tensor::UnPackOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1} const,void>::Callbacks
                                                                                    + 2) & 0xFFFFFFFFFFFFFFF8))((uint64_t)v11, a2, a3, a4, a5);
  char v9 = v12;
  if (v12 >= 8)
  {
    if ((v12 & 4) != 0)
    {
      if ((v12 & 2) != 0) {
        char v10 = v11;
      }
      else {
        char v10 = (llvm **)v11[0];
      }
      (*(void (**)(uint64_t, mlir::Operation *, mlir::OpAsmPrinter *, uint64_t, uint64_t))((v12 & 0xFFFFFFFFFFFFFFF8)
                                                                                                 + 16))((uint64_t)v10, v5, v6, v7, v8);
    }
    if ((v9 & 2) == 0) {
      llvm::deallocate_buffer(v11[0], v11[1]);
    }
  }
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::UnPackOp>::verifyInvariants(uint64_t a1, uint64_t a2)
{
  uint64_t v7 = *MEMORY[0x263EF8340];
  v5[0] = (uint64_t (*)(uint64_t))mlir::Op<mlir::tensor::UnPackOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::verifyInvariants;
  unint64_t v6 = (unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *>::CallbacksHolder<mlir::LogicalResult (*)(mlir::Operation *),mlir::LogicalResult (* const)(mlir::Operation *),void>::Callbacks
     + 2;
  uint64_t v2 = (*(uint64_t (**)(uint64_t (**)(uint64_t), uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *>::CallbacksHolder<mlir::LogicalResult (*)(mlir::Operation *),mlir::LogicalResult (* const)(mlir::Operation *),void>::Callbacks
                                                                             + 2) & 0xFFFFFFFFFFFFFFF8))(v5, a2);
  char v3 = v6;
  if (v6 >= 8)
  {
    if ((v6 & 4) != 0) {
      (*(void (__cdecl **)())((v6 & 0xFFFFFFFFFFFFFFF8) + 16))();
    }
    if ((v3 & 2) == 0) {
      llvm::deallocate_buffer((llvm *)v5[0], v5[1]);
    }
  }
  return v2;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::UnPackOp>::verifyRegionInvariants(uint64_t a1, uint64_t a2)
{
  uint64_t v7 = *MEMORY[0x263EF8340];
  v5[0] = (uint64_t (*)(uint64_t))mlir::Op<mlir::tensor::UnPackOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::verifyRegionInvariants;
  unint64_t v6 = (unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *>::CallbacksHolder<mlir::LogicalResult (*)(mlir::Operation *),mlir::LogicalResult (* const)(mlir::Operation *),void>::Callbacks
     + 2;
  uint64_t v2 = (*(uint64_t (**)(uint64_t (**)(uint64_t), uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *>::CallbacksHolder<mlir::LogicalResult (*)(mlir::Operation *),mlir::LogicalResult (* const)(mlir::Operation *),void>::Callbacks
                                                                             + 2) & 0xFFFFFFFFFFFFFFF8))(v5, a2);
  char v3 = v6;
  if (v6 >= 8)
  {
    if ((v6 & 4) != 0) {
      (*(void (__cdecl **)())((v6 & 0xFFFFFFFFFFFFFFF8) + 16))();
    }
    if ((v3 & 2) == 0) {
      llvm::deallocate_buffer((llvm *)v5[0], v5[1]);
    }
  }
  return v2;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::UnPackOp>::getInherentAttr(uint64_t a1, uint64_t a2, char *a3, size_t a4)
{
  int Context = mlir::Attribute::getContext((mlir::Attribute *)(a2 + 24));
  if (HIBYTE(*(_DWORD *)(a2 + 44))) {
    uint64_t v8 = (void *)(a2 + 16 * (((unint64_t)*(unsigned int *)(a2 + 44) >> 23) & 1) + 64);
  }
  else {
    uint64_t v8 = 0;
  }

  return mlir::tensor::UnPackOp::getInherentAttr(Context, v8, a3, a4);
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::UnPackOp>::setInherentAttr(uint64_t a1, uint64_t a2, uint64_t a3, void *a4)
{
  uint64_t v9 = a3;
  if (HIBYTE(*(_DWORD *)(a2 + 44))) {
    uint64_t v5 = a2 + 16 * (((unint64_t)*(unsigned int *)(a2 + 44) >> 23) & 1) + 64;
  }
  else {
    uint64_t v5 = 0;
  }
  AttrData = (char *)mlir::OpaqueAttr::getAttrData((mlir::OpaqueAttr *)&v9);
  return mlir::tensor::UnPackOp::setInherentAttr(v5, AttrData, v7, a4);
}

void mlir::RegisteredOperationName::Model<mlir::tensor::UnPackOp>::populateInherentAttrs(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t Context = mlir::Attribute::getContext((mlir::Attribute *)(a2 + 24));
  if (HIBYTE(*(_DWORD *)(a2 + 44))) {
    unint64_t v6 = (uint64_t *)(a2 + 16 * (((unint64_t)*(unsigned int *)(a2 + 44) >> 23) & 1) + 64);
  }
  else {
    unint64_t v6 = 0;
  }

  mlir::tensor::UnPackOp::populateInherentAttrs(Context, v6, a3);
}

BOOL mlir::RegisteredOperationName::Model<mlir::tensor::UnPackOp>::verifyInherentAttrs(uint64_t a1, uint64_t a2, uint64_t a3, void (*a4)(uint64_t *__return_ptr, uint64_t), uint64_t a5)
{
  return mlir::tensor::PackOp::verifyInherentAttrs(a2, a3, a4, a5);
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::UnPackOp>::getOpPropertyByteSize()
{
  return 24;
}

void mlir::RegisteredOperationName::Model<mlir::tensor::UnPackOp>::initProperties(uint64_t a1, uint64_t a2, uint64_t a3, long long *a4)
{
  if (a4)
  {
    long long v4 = *a4;
    *(void *)(a3 + 16) = *((void *)a4 + 2);
    *(_OWORD *)a3 = v4;
  }
  else
  {
    *(void *)a3 = 0;
    *(void *)(a3 + 8) = 0;
    *(void *)(a3 + 16) = 0;
  }
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::UnPackOp>::setPropertiesFromAttr(uint64_t a1, uint64_t a2, uint64_t *a3, uint64_t a4, void (*a5)(void *__return_ptr, uint64_t), uint64_t a6)
{
  return mlir::tensor::UnPackOp::setPropertiesFromAttr(a3, a4, a5, a6);
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::UnPackOp>::getPropertiesAsAttr(uint64_t a1, uint64_t a2)
{
  uint64_t Context = (mlir::DictionaryAttr *)mlir::Attribute::getContext((mlir::Attribute *)(a2 + 24));
  if (HIBYTE(*(_DWORD *)(a2 + 44))) {
    long long v4 = (uint64_t *)(a2 + 16 * (((unint64_t)*(unsigned int *)(a2 + 44) >> 23) & 1) + 64);
  }
  else {
    long long v4 = 0;
  }

  return mlir::tensor::UnPackOp::getPropertiesAsAttr(Context, v4);
}

__n128 mlir::RegisteredOperationName::Model<mlir::tensor::UnPackOp>::copyProperties(uint64_t a1, __n128 *a2, __n128 *a3)
{
  __n128 result = *a3;
  a2[1].n128_u64[0] = a3[1].n128_u64[0];
  *a2 = result;
  return result;
}

BOOL mlir::RegisteredOperationName::Model<mlir::tensor::UnPackOp>::compareProperties(uint64_t a1, void *a2, void *a3)
{
  if (*a3 != *a2) {
    return 0;
  }
  if (a3[1] == a2[1]) {
    return a3[2] == a2[2];
  }
  return 0;
}

unint64_t mlir::RegisteredOperationName::Model<mlir::tensor::UnPackOp>::hashProperties(uint64_t a1, unint64_t *a2)
{
  return mlir::memref::PrefetchOp::computePropertiesHash(a2);
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::BytecodeOpInterfaceInterfaceTraits::Model<mlir::tensor::UnPackOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(0x10uLL, 0x80040803F642BuLL);
  *uint64_t v2 = mlir::detail::BytecodeOpInterfaceInterfaceTraits::Model<mlir::tensor::UnPackOp>::readProperties;
  v2[1] = mlir::detail::BytecodeOpInterfaceInterfaceTraits::Model<mlir::tensor::UnPackOp>::writeProperties;
  char v3 = &unk_267771000;
  {
    unint64_t v12 = v2;
    char v3 = (void *)&unk_267771000;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::BytecodeOpInterface]";
      unint64_t v14 = 75;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      uint64_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::BytecodeOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      char v3 = (void *)&unk_267771000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[312], v2);
}

uint64_t mlir::detail::BytecodeOpInterfaceInterfaceTraits::Model<mlir::tensor::UnPackOp>::writeProperties(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = a2;
  return mlir::tensor::UnPackOp::writeProperties((uint64_t)&v4, a3);
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::UnPackOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(0x20uLL, 0x8004018A671A6uLL);
  *uint64_t v2 = mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::UnPackOp>::getAsmResultNames;
  v2[1] = mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::UnPackOp>::getAsmBlockArgumentNames;
  v2[2] = mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::UnPackOp>::getAsmBlockNames;
  v2[3] = mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::UnPackOp>::getDefaultDialect;
  char v3 = &unk_267771000;
  {
    unint64_t v12 = v2;
    char v3 = (void *)&unk_267771000;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpAsmOpInterface]";
      unint64_t v14 = 72;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      uint64_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::OpAsmOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      char v3 = (void *)&unk_267771000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[346], v2);
}

uint64_t mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::UnPackOp>::getAsmResultNames(uint64_t a1, uint64_t a2, uint64_t (*a3)(uint64_t, uint64_t, const char *, uint64_t), uint64_t a4)
{
  uint64_t v5 = a2;
  return mlir::tensor::UnPackOp::getAsmResultNames((uint64_t)&v5, a3, a4);
}

char *mlir::detail::OpAsmOpInterfaceInterfaceTraits::Model<mlir::tensor::UnPackOp>::getDefaultDialect()
{
  return &byte_211F4AA5D;
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::DestinationStyleOpInterfaceInterfaceTraits::Model<mlir::tensor::UnPackOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(8uLL, 0x80040B8603338uLL);
  *uint64_t v2 = mlir::detail::DestinationStyleOpInterfaceInterfaceTraits::Model<mlir::tensor::UnPackOp>::getDpsInitsMutable;
  char v3 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
  {
    unint64_t v12 = v2;
    char v3 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::DestinationStyleOpInterface]";
      unint64_t v14 = 83;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      uint64_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::DestinationStyleOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      char v3 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[134], v2);
}

mlir::MutableOperandRange *mlir::detail::DestinationStyleOpInterfaceInterfaceTraits::Model<mlir::tensor::UnPackOp>::getDpsInitsMutable@<X0>(uint64_t a1@<X1>, mlir::MutableOperandRange *a2@<X8>)
{
  uint64_t v5 = a1;
  DestMutable = (mlir::OpOperand *)mlir::tensor::InsertOp::getDestMutable((mlir::tensor::InsertOp *)&v5);
  return mlir::MutableOperandRange::MutableOperandRange(a2, DestMutable);
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::ConditionallySpeculatableInterfaceTraits::Model<mlir::tensor::UnPackOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(8uLL, 0x80040B8603338uLL);
  *uint64_t v2 = mlir::detail::ConditionallySpeculatableInterfaceTraits::Model<mlir::tensor::UnPackOp>::getSpeculatability;
  char v3 = &unk_267771000;
  {
    unint64_t v12 = v2;
    char v3 = (void *)&unk_267771000;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ConditionallySpeculatable]";
      unint64_t v14 = 81;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      uint64_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::ConditionallySpeculatable,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      char v3 = (void *)&unk_267771000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[314], v2);
}

uint64_t mlir::detail::ConditionallySpeculatableInterfaceTraits::Model<mlir::tensor::UnPackOp>::getSpeculatability(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = a2;
  return mlir::tensor::UnPackOp::getSpeculatability((mlir::tensor::UnPackOp *)&v3);
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::MemoryEffectOpInterfaceInterfaceTraits::Model<mlir::tensor::UnPackOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(8uLL, 0x80040B8603338uLL);
  *uint64_t v2 = mlir::detail::MemoryEffectOpInterfaceInterfaceTraits::Model<mlir::tensor::UnPackOp>::getEffects;
  uint64_t v3 = &unk_267771000;
  {
    unint64_t v12 = v2;
    uint64_t v3 = (void *)&unk_267771000;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::MemoryEffectOpInterface]";
      unint64_t v14 = 79;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      uint64_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::MemoryEffectOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      uint64_t v3 = (void *)&unk_267771000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[11], v2);
}

void mlir::detail::MemoryEffectOpInterfaceInterfaceTraits::Model<mlir::tensor::UnPackOp>::getEffects(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = a2;
  ZinIrHalH13g::~ZinIrHalH13g((ZinIrHalH13g *)&v2);
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::ReifyRankedShapedTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::UnPackOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(8uLL, 0x80040B8603338uLL);
  *uint64_t v2 = mlir::detail::ReifyRankedShapedTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::UnPackOp>::reifyResultShapes;
  uint64_t v3 = &unk_267772000;
  {
    unint64_t v12 = v2;
    uint64_t v3 = (void *)&unk_267772000;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ReifyRankedShapedTypeOpInterface]";
      unint64_t v14 = 88;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      uint64_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::ReifyRankedShapedTypeOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      uint64_t v3 = (void *)&unk_267772000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[181], v2);
}

uint64_t mlir::detail::ReifyRankedShapedTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::UnPackOp>::reifyResultShapes(uint64_t a1, uint64_t a2, mlir::IndexType **a3, uint64_t a4)
{
  uint64_t v5 = a2;
  return mlir::tensor::UnPackOp::reifyResultShapes(&v5, a3, a4);
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::InferTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::UnPackOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(0x18uLL, 0x80040D6874129uLL);
  *uint64_t v2 = mlir::detail::InferTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::UnPackOp>::inferReturnTypes;
  v2[1] = mlir::detail::InferTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::UnPackOp>::refineReturnTypes;
  v2[2] = mlir::detail::InferTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::UnPackOp>::isCompatibleReturnTypes;
  uint64_t v3 = &unk_267771000;
  {
    unint64_t v12 = v2;
    uint64_t v3 = (void *)&unk_267771000;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::InferTypeOpInterface]";
      unint64_t v14 = 76;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      uint64_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::InferTypeOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      uint64_t v3 = (void *)&unk_267771000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[17], v2);
}

uint64_t mlir::detail::InferTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::UnPackOp>::inferReturnTypes(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11)
{
  return mlir::tensor::InsertOp::inferReturnTypes(a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, a11);
}

uint64_t mlir::detail::InferTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::UnPackOp>::refineReturnTypes(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11)
{
  return mlir::detail::InferTypeOpInterfaceTrait<mlir::tensor::UnPackOp>::refineReturnTypes(a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, a11);
}

BOOL mlir::detail::InferTypeOpInterfaceInterfaceTraits::Model<mlir::tensor::UnPackOp>::isCompatibleReturnTypes(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return a2 == a4
      && std::__equal_impl[abi:nn180100]<llvm::detail::indexed_accessor_range_base<mlir::TypeRange,llvm::PointerUnion<mlir::Value const*,mlir::Type const*,mlir::OpOperand *,mlir::detail::OpResultImpl *>,mlir::Type,mlir::Type,mlir::Type>::iterator,llvm::detail::indexed_accessor_range_base<mlir::TypeRange,llvm::PointerUnion<mlir::Value const*,mlir::Type const*,mlir::OpOperand *,mlir::detail::OpResultImpl *>,mlir::Type,mlir::Type,mlir::Type>::iterator,llvm::detail::indexed_accessor_range_base<mlir::TypeRange,llvm::PointerUnion<mlir::Value const*,mlir::Type const*,mlir::OpOperand *,mlir::detail::OpResultImpl *>,mlir::Type,mlir::Type,mlir::Type>::iterator,llvm::detail::indexed_accessor_range_base<mlir::TypeRange,llvm::PointerUnion<mlir::Value const*,mlir::Type const*,mlir::OpOperand *,mlir::detail::OpResultImpl *>,mlir::Type,mlir::Type,mlir::Type>::iterator,std::__equal_to,std::__identity,std::__identity>(a1, 0, a1, a2, a3, 0, a3, a2);
}

uint64_t mlir::detail::InferTypeOpInterfaceTrait<mlir::tensor::UnPackOp>::refineReturnTypes(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11)
{
  char v11 = a3;
  v22[4] = *MEMORY[0x263EF8340];
  int64_t v20 = v22;
  uint64_t v21 = 0x400000000;
  if (!mlir::tensor::InsertOp::inferReturnTypes(a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, (uint64_t)&v20))
  {
    uint64_t v13 = 0;
    unint64_t v14 = v20;
    if (v20 == v22) {
      return v13;
    }
    goto LABEL_7;
  }
  mlir::ValueRange::ValueRange((unint64_t *)&v18, (uint64_t)v20, v21);
  mlir::ValueRange::ValueRange(v17, *(void *)a11, *(unsigned int *)(a11 + 8));
  if (v19 == v17[1]
    && std::__equal_impl[abi:nn180100]<llvm::detail::indexed_accessor_range_base<mlir::TypeRange,llvm::PointerUnion<mlir::Value const*,mlir::Type const*,mlir::OpOperand *,mlir::detail::OpResultImpl *>,mlir::Type,mlir::Type,mlir::Type>::iterator,llvm::detail::indexed_accessor_range_base<mlir::TypeRange,llvm::PointerUnion<mlir::Value const*,mlir::Type const*,mlir::OpOperand *,mlir::detail::OpResultImpl *>,mlir::Type,mlir::Type,mlir::Type>::iterator,llvm::detail::indexed_accessor_range_base<mlir::TypeRange,llvm::PointerUnion<mlir::Value const*,mlir::Type const*,mlir::OpOperand *,mlir::detail::OpResultImpl *>,mlir::Type,mlir::Type,mlir::Type>::iterator,llvm::detail::indexed_accessor_range_base<mlir::TypeRange,llvm::PointerUnion<mlir::Value const*,mlir::Type const*,mlir::OpOperand *,mlir::detail::OpResultImpl *>,mlir::Type,mlir::Type,mlir::Type>::iterator,std::__equal_to,std::__identity,std::__identity>(v18, 0, v18, v19, v17[0], 0, v17[0], v19))
  {
    uint64_t v13 = 1;
    unint64_t v14 = v20;
    if (v20 == v22) {
      return v13;
    }
    goto LABEL_7;
  }
  v16[0] = "tensor.unpack";
  v16[1] = 13;
  uint64_t v13 = mlir::emitOptionalError<char const(&)[2],llvm::StringLiteral,char const(&)[23],llvm::SmallVector<mlir::Type,4u> &,char const(&)[52],llvm::SmallVectorImpl<mlir::Type> &>(a2, v11, "'", (uint64_t)v16, "' op inferred type(s) ", (uint64_t)&v20, " are incompatible with return type(s) of operation ", a11);
  unint64_t v14 = v20;
  if (v20 != v22) {
LABEL_7:
  }
    free(v14);
  return v13;
}

BOOL llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &>::CallImpl<mlir::Op<mlir::tensor::UnPackOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1} const>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v17 = *MEMORY[0x263EF8340];
  uint64_t v13 = a2;
  mlir::tensor::detail::UnPackOpGenericAdaptorBase::UnPackOpGenericAdaptorBase((uint64_t)v14, a2);
  uint64_t v15 = a3;
  uint64_t v16 = a4;
  unint64_t v9 = mlir::tensor::UnPackOp::fold((uint64_t)&v13, (uint64_t)v14);
  unint64_t v10 = v9;
  if (v9 < 8 || a2 - 16 == (v9 & ((uint64_t)(v9 << 61) >> 63) & 0xFFFFFFFFFFFFFFF8)) {
    return v9 > 7;
  }
  uint64_t v11 = *(unsigned int *)(a5 + 8);
  if (v11 >= *(_DWORD *)(a5 + 12))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod(a5, (void *)(a5 + 16), v11 + 1, 8);
    LODWORD(v11) = *(_DWORD *)(a5 + 8);
  }
  *(void *)(*(void *)a5 + 8 * v11) = v10;
  ++*(_DWORD *)(a5 + 8);
  return 1;
}

BOOL llvm::detail::UniqueFunctionBase<BOOL,mlir::TypeID>::CallImpl<mlir::Op<mlir::tensor::UnPackOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1} const>(uint64_t a1, uint64_t a2)
{
  return mlir::op_definition_impl::hasTrait<mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>(a2);
}

BOOL mlir::op_definition_impl::hasTrait<mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>(uint64_t a1)
{
  uint64_t v1 = &unk_267771000;
  {
    uint64_t v234 = a1;
    uint64_t v1 = (void *)&unk_267771000;
    int v40 = v39;
    a1 = v234;
    if (v40)
    {
      uint64_t v247 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::ZeroRegions<Empty>]";
      unint64_t v248 = 83;
      unint64_t v41 = llvm::StringRef::find((uint64_t *)&v247, "DesiredTypeName = ", 0x12uLL, 0);
      if (v248 >= v41) {
        unint64_t v42 = v41;
      }
      else {
        unint64_t v42 = v248;
      }
      int v43 = &v247[v42];
      unint64_t v44 = v248 - v42;
      if (v248 - v42 >= 0x12) {
        uint64_t v45 = 18;
      }
      else {
        uint64_t v45 = v248 - v42;
      }
      unint64_t v46 = v44 - v45;
      if (v46 >= v46 - 1) {
        uint64_t v47 = v46 - 1;
      }
      else {
        uint64_t v47 = v46;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::ZeroRegions<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::ZeroRegions>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v43[v45], v47);
      uint64_t v1 = (void *)&unk_267771000;
      a1 = v234;
    }
  }
  uint64_t v2 = v1[23];
  uint64_t v3 = &unk_267771000;
  {
    uint64_t v222 = v2;
    uint64_t v235 = a1;
    uint64_t v3 = (void *)&unk_267771000;
    int v49 = v48;
    uint64_t v2 = v222;
    a1 = v235;
    if (v49)
    {
      uint64_t v247 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::OneResult<Empty>]";
      unint64_t v248 = 81;
      unint64_t v50 = llvm::StringRef::find((uint64_t *)&v247, "DesiredTypeName = ", 0x12uLL, 0);
      if (v248 >= v50) {
        unint64_t v51 = v50;
      }
      else {
        unint64_t v51 = v248;
      }
      int v52 = &v247[v51];
      unint64_t v53 = v248 - v51;
      if (v248 - v51 >= 0x12) {
        uint64_t v54 = 18;
      }
      else {
        uint64_t v54 = v248 - v51;
      }
      unint64_t v55 = v53 - v54;
      if (v55 >= v55 - 1) {
        uint64_t v56 = v55 - 1;
      }
      else {
        uint64_t v56 = v55;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::OneResult<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::OneResult>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v52[v54], v56);
      uint64_t v3 = (void *)&unk_267771000;
      uint64_t v2 = v222;
      a1 = v235;
    }
  }
  uint64_t v4 = v3[25];
  unint64_t v5 = &unk_267771000;
  {
    uint64_t v223 = v2;
    uint64_t v236 = a1;
    uint64_t v211 = v4;
    unint64_t v5 = (void *)&unk_267771000;
    uint64_t v4 = v211;
    uint64_t v2 = v223;
    int v58 = v57;
    a1 = v236;
    if (v58)
    {
      uint64_t v247 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl<Empty>]";
      unint64_t v248 = 116;
      unint64_t v59 = llvm::StringRef::find((uint64_t *)&v247, "DesiredTypeName = ", 0x12uLL, 0);
      if (v248 >= v59) {
        unint64_t v60 = v59;
      }
      else {
        unint64_t v60 = v248;
      }
      int v61 = &v247[v60];
      unint64_t v62 = v248 - v60;
      if (v248 - v60 >= 0x12) {
        uint64_t v63 = 18;
      }
      else {
        uint64_t v63 = v248 - v60;
      }
      unint64_t v64 = v62 - v63;
      if (v64 >= v64 - 1) {
        uint64_t v65 = v64 - 1;
      }
      else {
        uint64_t v65 = v64;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v61[v63], v65);
      unint64_t v5 = (void *)&unk_267771000;
      uint64_t v4 = v211;
      uint64_t v2 = v223;
      a1 = v236;
    }
  }
  uint64_t v6 = v5[435];
  uint64_t v7 = &unk_267770000;
  {
    uint64_t v224 = v2;
    uint64_t v237 = a1;
    uint64_t v201 = v6;
    uint64_t v212 = v4;
    uint64_t v7 = (void *)&unk_267770000;
    uint64_t v6 = v201;
    uint64_t v4 = v212;
    int v67 = v66;
    uint64_t v2 = v224;
    a1 = v237;
    if (v67)
    {
      uint64_t v247 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::ZeroSuccessors<Empty>]";
      unint64_t v248 = 86;
      unint64_t v68 = llvm::StringRef::find((uint64_t *)&v247, "DesiredTypeName = ", 0x12uLL, 0);
      if (v248 >= v68) {
        unint64_t v69 = v68;
      }
      else {
        unint64_t v69 = v248;
      }
      int v70 = &v247[v69];
      unint64_t v71 = v248 - v69;
      if (v248 - v69 >= 0x12) {
        uint64_t v72 = 18;
      }
      else {
        uint64_t v72 = v248 - v69;
      }
      unint64_t v73 = v71 - v72;
      if (v73 >= v73 - 1) {
        uint64_t v74 = v73 - 1;
      }
      else {
        uint64_t v74 = v73;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::ZeroSuccessors<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::ZeroSuccessors>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v70[v72], v74);
      uint64_t v7 = (void *)&unk_267770000;
      uint64_t v6 = v201;
      uint64_t v4 = v212;
      uint64_t v2 = v224;
      a1 = v237;
    }
  }
  uint64_t v8 = v7[431];
  unint64_t v9 = &unk_267771000;
  {
    uint64_t v225 = v2;
    uint64_t v238 = a1;
    uint64_t v202 = v6;
    uint64_t v213 = v4;
    uint64_t v192 = v8;
    unint64_t v9 = (void *)&unk_267771000;
    uint64_t v8 = v192;
    uint64_t v6 = v202;
    uint64_t v4 = v213;
    int v76 = v75;
    uint64_t v2 = v225;
    a1 = v238;
    if (v76)
    {
      uint64_t v247 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::AtLeastNOperands<2>::Impl<Empty>]";
      unint64_t v248 = 97;
      unint64_t v77 = llvm::StringRef::find((uint64_t *)&v247, "DesiredTypeName = ", 0x12uLL, 0);
      if (v248 >= v77) {
        unint64_t v78 = v77;
      }
      else {
        unint64_t v78 = v248;
      }
      int v79 = &v247[v78];
      unint64_t v80 = v248 - v78;
      if (v248 - v78 >= 0x12) {
        uint64_t v81 = 18;
      }
      else {
        uint64_t v81 = v248 - v78;
      }
      unint64_t v82 = v80 - v81;
      if (v82 >= v82 - 1) {
        uint64_t v83 = v82 - 1;
      }
      else {
        uint64_t v83 = v82;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::AtLeastNOperands<2u>::Impl<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::AtLeastNOperands<2u>::Impl>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v79[v81], v83);
      unint64_t v9 = (void *)&unk_267771000;
      uint64_t v8 = v192;
      uint64_t v6 = v202;
      uint64_t v4 = v213;
      uint64_t v2 = v225;
      a1 = v238;
    }
  }
  uint64_t v10 = v9[441];
  uint64_t v11 = &unk_267770000;
  {
    uint64_t v226 = v2;
    uint64_t v239 = a1;
    uint64_t v203 = v6;
    uint64_t v214 = v4;
    uint64_t v184 = v10;
    uint64_t v193 = v8;
    uint64_t v11 = (void *)&unk_267770000;
    uint64_t v10 = v184;
    uint64_t v8 = v193;
    uint64_t v6 = v203;
    uint64_t v4 = v214;
    int v85 = v84;
    uint64_t v2 = v226;
    a1 = v239;
    if (v85)
    {
      uint64_t v247 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::OpInvariants<Empty>]";
      unint64_t v248 = 84;
      unint64_t v86 = llvm::StringRef::find((uint64_t *)&v247, "DesiredTypeName = ", 0x12uLL, 0);
      if (v248 >= v86) {
        unint64_t v87 = v86;
      }
      else {
        unint64_t v87 = v248;
      }
      int v88 = &v247[v87];
      unint64_t v89 = v248 - v87;
      if (v248 - v87 >= 0x12) {
        uint64_t v90 = 18;
      }
      else {
        uint64_t v90 = v248 - v87;
      }
      unint64_t v91 = v89 - v90;
      if (v91 >= v91 - 1) {
        uint64_t v92 = v91 - 1;
      }
      else {
        uint64_t v92 = v91;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::OpInvariants<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::OpInvariants>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v88[v90], v92);
      uint64_t v11 = (void *)&unk_267770000;
      uint64_t v10 = v184;
      uint64_t v8 = v193;
      uint64_t v6 = v203;
      uint64_t v4 = v214;
      uint64_t v2 = v226;
      a1 = v239;
    }
  }
  uint64_t v12 = v11[435];
  uint64_t v13 = &unk_267771000;
  {
    uint64_t v227 = v2;
    uint64_t v240 = a1;
    uint64_t v204 = v6;
    uint64_t v215 = v4;
    uint64_t v185 = v10;
    uint64_t v194 = v8;
    uint64_t v177 = v12;
    uint64_t v13 = (void *)&unk_267771000;
    uint64_t v12 = v177;
    uint64_t v10 = v185;
    uint64_t v8 = v194;
    uint64_t v6 = v204;
    uint64_t v4 = v215;
    int v94 = v93;
    uint64_t v2 = v227;
    a1 = v240;
    if (v94)
    {
      uint64_t v247 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::BytecodeOpInterface::Trait<Empty>]";
      unint64_t v248 = 89;
      unint64_t v95 = llvm::StringRef::find((uint64_t *)&v247, "DesiredTypeName = ", 0x12uLL, 0);
      if (v248 >= v95) {
        unint64_t v96 = v95;
      }
      else {
        unint64_t v96 = v248;
      }
      int v97 = &v247[v96];
      unint64_t v98 = v248 - v96;
      if (v248 - v96 >= 0x12) {
        uint64_t v99 = 18;
      }
      else {
        uint64_t v99 = v248 - v96;
      }
      unint64_t v100 = v98 - v99;
      if (v100 >= v100 - 1) {
        uint64_t v101 = v100 - 1;
      }
      else {
        uint64_t v101 = v100;
      }
      mlir::detail::TypeIDResolver<mlir::BytecodeOpInterface::Trait<mlir::TypeID mlir::TypeID::get<mlir::BytecodeOpInterface::Trait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v97[v99], v101);
      uint64_t v13 = (void *)&unk_267771000;
      uint64_t v12 = v177;
      uint64_t v10 = v185;
      uint64_t v8 = v194;
      uint64_t v6 = v204;
      uint64_t v4 = v215;
      uint64_t v2 = v227;
      a1 = v240;
    }
  }
  uint64_t v14 = v13[320];
  uint64_t v15 = &unk_267771000;
  {
    uint64_t v228 = v2;
    uint64_t v241 = a1;
    uint64_t v205 = v6;
    uint64_t v216 = v4;
    uint64_t v186 = v10;
    uint64_t v195 = v8;
    uint64_t v171 = v14;
    uint64_t v178 = v12;
    uint64_t v15 = (void *)&unk_267771000;
    uint64_t v14 = v171;
    uint64_t v12 = v178;
    uint64_t v10 = v186;
    uint64_t v8 = v195;
    uint64_t v6 = v205;
    uint64_t v4 = v216;
    int v103 = v102;
    uint64_t v2 = v228;
    a1 = v241;
    if (v103)
    {
      uint64_t v247 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpAsmOpInterface::Trait<Empty>]";
      unint64_t v248 = 86;
      unint64_t v104 = llvm::StringRef::find((uint64_t *)&v247, "DesiredTypeName = ", 0x12uLL, 0);
      if (v248 >= v104) {
        unint64_t v105 = v104;
      }
      else {
        unint64_t v105 = v248;
      }
      int v106 = &v247[v105];
      unint64_t v107 = v248 - v105;
      if (v248 - v105 >= 0x12) {
        uint64_t v108 = 18;
      }
      else {
        uint64_t v108 = v248 - v105;
      }
      unint64_t v109 = v107 - v108;
      if (v109 >= v109 - 1) {
        uint64_t v110 = v109 - 1;
      }
      else {
        uint64_t v110 = v109;
      }
      mlir::detail::TypeIDResolver<mlir::OpAsmOpInterface::Trait<mlir::TypeID mlir::TypeID::get<mlir::OpAsmOpInterface::Trait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v106[v108], v110);
      uint64_t v15 = (void *)&unk_267771000;
      uint64_t v14 = v171;
      uint64_t v12 = v178;
      uint64_t v10 = v186;
      uint64_t v8 = v195;
      uint64_t v6 = v205;
      uint64_t v4 = v216;
      uint64_t v2 = v228;
      a1 = v241;
    }
  }
  uint64_t v16 = v15[350];
  uint64_t v17 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
  {
    uint64_t v229 = v2;
    uint64_t v242 = a1;
    uint64_t v206 = v6;
    uint64_t v217 = v4;
    uint64_t v187 = v10;
    uint64_t v196 = v8;
    uint64_t v172 = v14;
    uint64_t v179 = v12;
    uint64_t v166 = v16;
    uint64_t v17 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
    uint64_t v16 = v166;
    uint64_t v14 = v172;
    uint64_t v12 = v179;
    uint64_t v10 = v187;
    uint64_t v8 = v196;
    uint64_t v6 = v206;
    uint64_t v4 = v217;
    int v112 = v111;
    uint64_t v2 = v229;
    a1 = v242;
    if (v112)
    {
      uint64_t v247 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::DestinationStyleOpInterface::Trait<Empty>]";
      unint64_t v248 = 97;
      unint64_t v113 = llvm::StringRef::find((uint64_t *)&v247, "DesiredTypeName = ", 0x12uLL, 0);
      if (v248 >= v113) {
        unint64_t v114 = v113;
      }
      else {
        unint64_t v114 = v248;
      }
      int v115 = &v247[v114];
      unint64_t v116 = v248 - v114;
      if (v248 - v114 >= 0x12) {
        uint64_t v117 = 18;
      }
      else {
        uint64_t v117 = v248 - v114;
      }
      unint64_t v118 = v116 - v117;
      if (v118 >= v118 - 1) {
        uint64_t v119 = v118 - 1;
      }
      else {
        uint64_t v119 = v118;
      }
      mlir::detail::TypeIDResolver<mlir::DestinationStyleOpInterface::Trait<mlir::TypeID mlir::TypeID::get<mlir::DestinationStyleOpInterface::Trait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v115[v117], v119);
      uint64_t v17 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
      uint64_t v16 = v166;
      uint64_t v14 = v172;
      uint64_t v12 = v179;
      uint64_t v10 = v187;
      uint64_t v8 = v196;
      uint64_t v6 = v206;
      uint64_t v4 = v217;
      uint64_t v2 = v229;
      a1 = v242;
    }
  }
  uint64_t v18 = v17[138];
  uint64_t v19 = &unk_267771000;
  {
    uint64_t v230 = v2;
    uint64_t v243 = a1;
    uint64_t v207 = v6;
    uint64_t v218 = v4;
    uint64_t v188 = v10;
    uint64_t v197 = v8;
    uint64_t v173 = v14;
    uint64_t v180 = v12;
    uint64_t v162 = v18;
    uint64_t v167 = v16;
    uint64_t v19 = (void *)&unk_267771000;
    uint64_t v18 = v162;
    uint64_t v16 = v167;
    uint64_t v14 = v173;
    uint64_t v12 = v180;
    uint64_t v10 = v188;
    uint64_t v8 = v197;
    uint64_t v6 = v207;
    uint64_t v4 = v218;
    int v121 = v120;
    uint64_t v2 = v230;
    a1 = v243;
    if (v121)
    {
      uint64_t v247 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ConditionallySpeculatable::Trait<Empty>]";
      unint64_t v248 = 95;
      unint64_t v122 = llvm::StringRef::find((uint64_t *)&v247, "DesiredTypeName = ", 0x12uLL, 0);
      if (v248 >= v122) {
        unint64_t v123 = v122;
      }
      else {
        unint64_t v123 = v248;
      }
      uint64_t v124 = &v247[v123];
      unint64_t v125 = v248 - v123;
      if (v248 - v123 >= 0x12) {
        uint64_t v126 = 18;
      }
      else {
        uint64_t v126 = v248 - v123;
      }
      unint64_t v127 = v125 - v126;
      if (v127 >= v127 - 1) {
        uint64_t v128 = v127 - 1;
      }
      else {
        uint64_t v128 = v127;
      }
      mlir::detail::TypeIDResolver<mlir::ConditionallySpeculatable::Trait<mlir::TypeID mlir::TypeID::get<mlir::ConditionallySpeculatable::Trait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v124[v126], v128);
      uint64_t v19 = (void *)&unk_267771000;
      uint64_t v18 = v162;
      uint64_t v16 = v167;
      uint64_t v14 = v173;
      uint64_t v12 = v180;
      uint64_t v10 = v188;
      uint64_t v8 = v197;
      uint64_t v6 = v207;
      uint64_t v4 = v218;
      uint64_t v2 = v230;
      a1 = v243;
    }
  }
  uint64_t v20 = v19[322];
  uint64_t v21 = &unk_267771000;
  {
    uint64_t v231 = v2;
    uint64_t v244 = a1;
    uint64_t v208 = v6;
    uint64_t v219 = v4;
    uint64_t v189 = v10;
    uint64_t v198 = v8;
    uint64_t v174 = v14;
    uint64_t v181 = v12;
    uint64_t v163 = v18;
    uint64_t v168 = v16;
    uint64_t v159 = v20;
    uint64_t v21 = (void *)&unk_267771000;
    uint64_t v20 = v159;
    uint64_t v18 = v163;
    uint64_t v16 = v168;
    uint64_t v14 = v174;
    uint64_t v12 = v181;
    uint64_t v10 = v189;
    uint64_t v8 = v198;
    uint64_t v6 = v208;
    uint64_t v4 = v219;
    int v130 = v129;
    uint64_t v2 = v231;
    a1 = v244;
    if (v130)
    {
      uint64_t v247 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::MemoryEffectOpInterface::Trait<Empty>]";
      unint64_t v248 = 93;
      unint64_t v131 = llvm::StringRef::find((uint64_t *)&v247, "DesiredTypeName = ", 0x12uLL, 0);
      if (v248 >= v131) {
        unint64_t v132 = v131;
      }
      else {
        unint64_t v132 = v248;
      }
      uint64_t v133 = &v247[v132];
      unint64_t v134 = v248 - v132;
      if (v248 - v132 >= 0x12) {
        uint64_t v135 = 18;
      }
      else {
        uint64_t v135 = v248 - v132;
      }
      unint64_t v136 = v134 - v135;
      if (v136 >= v136 - 1) {
        uint64_t v137 = v136 - 1;
      }
      else {
        uint64_t v137 = v136;
      }
      mlir::detail::TypeIDResolver<mlir::MemoryEffectOpInterface::Trait<mlir::TypeID mlir::TypeID::get<mlir::MemoryEffectOpInterface::Trait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v133[v135], v137);
      uint64_t v21 = (void *)&unk_267771000;
      uint64_t v20 = v159;
      uint64_t v18 = v163;
      uint64_t v16 = v168;
      uint64_t v14 = v174;
      uint64_t v12 = v181;
      uint64_t v10 = v189;
      uint64_t v8 = v198;
      uint64_t v6 = v208;
      uint64_t v4 = v219;
      uint64_t v2 = v231;
      a1 = v244;
    }
  }
  uint64_t v22 = v21[31];
  uint64_t v23 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
  {
    uint64_t v232 = v2;
    uint64_t v245 = a1;
    uint64_t v209 = v6;
    uint64_t v220 = v4;
    uint64_t v190 = v10;
    uint64_t v199 = v8;
    uint64_t v175 = v14;
    uint64_t v182 = v12;
    uint64_t v164 = v18;
    uint64_t v169 = v16;
    uint64_t v157 = v22;
    uint64_t v160 = v20;
    uint64_t v23 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
    uint64_t v22 = v157;
    uint64_t v20 = v160;
    uint64_t v18 = v164;
    uint64_t v16 = v169;
    uint64_t v14 = v175;
    uint64_t v12 = v182;
    uint64_t v10 = v190;
    uint64_t v8 = v199;
    uint64_t v6 = v209;
    uint64_t v4 = v220;
    int v139 = v138;
    uint64_t v2 = v232;
    a1 = v245;
    if (v139)
    {
      uint64_t v247 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ReifyRankedShapedTypeOpInterface::Trait<Empty>]";
      unint64_t v248 = 102;
      unint64_t v140 = llvm::StringRef::find((uint64_t *)&v247, "DesiredTypeName = ", 0x12uLL, 0);
      if (v248 >= v140) {
        unint64_t v141 = v140;
      }
      else {
        unint64_t v141 = v248;
      }
      uint64_t v142 = &v247[v141];
      unint64_t v143 = v248 - v141;
      if (v248 - v141 >= 0x12) {
        uint64_t v144 = 18;
      }
      else {
        uint64_t v144 = v248 - v141;
      }
      unint64_t v145 = v143 - v144;
      if (v145 >= v145 - 1) {
        uint64_t v146 = v145 - 1;
      }
      else {
        uint64_t v146 = v145;
      }
      mlir::detail::TypeIDResolver<mlir::ReifyRankedShapedTypeOpInterface::Trait<mlir::TypeID mlir::TypeID::get<mlir::ReifyRankedShapedTypeOpInterface::Trait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v142[v144], v146);
      uint64_t v23 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
      uint64_t v22 = v157;
      uint64_t v20 = v160;
      uint64_t v18 = v164;
      uint64_t v16 = v169;
      uint64_t v14 = v175;
      uint64_t v12 = v182;
      uint64_t v10 = v190;
      uint64_t v8 = v199;
      uint64_t v6 = v209;
      uint64_t v4 = v220;
      uint64_t v2 = v232;
      a1 = v245;
    }
  }
  uint64_t v24 = v23[178];
  int v25 = &unk_267771000;
  {
    uint64_t v233 = v2;
    uint64_t v246 = a1;
    uint64_t v210 = v6;
    uint64_t v221 = v4;
    uint64_t v191 = v10;
    uint64_t v200 = v8;
    uint64_t v176 = v14;
    uint64_t v183 = v12;
    uint64_t v165 = v18;
    uint64_t v170 = v16;
    uint64_t v158 = v22;
    uint64_t v161 = v20;
    uint64_t v156 = v24;
    int v25 = (void *)&unk_267771000;
    uint64_t v24 = v156;
    uint64_t v22 = v158;
    uint64_t v20 = v161;
    uint64_t v18 = v165;
    uint64_t v16 = v170;
    uint64_t v14 = v176;
    uint64_t v12 = v183;
    uint64_t v10 = v191;
    uint64_t v8 = v200;
    uint64_t v6 = v210;
    uint64_t v4 = v221;
    int v148 = v147;
    uint64_t v2 = v233;
    a1 = v246;
    if (v148)
    {
      uint64_t v247 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::InferTypeOpInterface::Trait<Empty>]";
      unint64_t v248 = 90;
      unint64_t v149 = llvm::StringRef::find((uint64_t *)&v247, "DesiredTypeName = ", 0x12uLL, 0);
      if (v248 >= v149) {
        unint64_t v150 = v149;
      }
      else {
        unint64_t v150 = v248;
      }
      uint64_t v151 = &v247[v150];
      unint64_t v152 = v248 - v150;
      if (v248 - v150 >= 0x12) {
        uint64_t v153 = 18;
      }
      else {
        uint64_t v153 = v248 - v150;
      }
      unint64_t v154 = v152 - v153;
      if (v154 >= v154 - 1) {
        uint64_t v155 = v154 - 1;
      }
      else {
        uint64_t v155 = v154;
      }
      mlir::detail::TypeIDResolver<mlir::InferTypeOpInterface::Trait<mlir::TypeID mlir::TypeID::get<mlir::InferTypeOpInterface::Trait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v151[v153], v155);
      int v25 = (void *)&unk_267771000;
      uint64_t v24 = v156;
      uint64_t v22 = v158;
      uint64_t v20 = v161;
      uint64_t v18 = v165;
      uint64_t v16 = v170;
      uint64_t v14 = v176;
      uint64_t v12 = v183;
      uint64_t v10 = v191;
      uint64_t v8 = v200;
      uint64_t v6 = v210;
      uint64_t v4 = v221;
      uint64_t v2 = v233;
      a1 = v246;
    }
  }
  return v2 == a1
      || v4 == a1
      || v6 == a1
      || v8 == a1
      || v10 == a1
      || v12 == a1
      || v14 == a1
      || v16 == a1
      || v18 == a1
      || v20 == a1
      || v22 == a1
      || v24 == a1
      || v25[37] == a1;
}

void llvm::detail::UniqueFunctionBase<void,mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef>::CallImpl<mlir::Op<mlir::tensor::UnPackOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1} const>(uint64_t a1, uint64_t a2, mlir::OpAsmPrinter *a3, uint64_t a4, uint64_t a5)
{
  mlir::OpState::printOpName(a2, (uint64_t)a3, a4, a5);
  uint64_t v7 = a2;
  mlir::tensor::UnPackOp::print((mlir::tensor::UnPackOp *)&v7, a3);
}

BOOL mlir::Op<mlir::tensor::UnPackOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::verifyInvariants(mlir::OpTrait::impl *a1, mlir::Operation *a2)
{
  if (!mlir::OpTrait::impl::verifyZeroRegions(a1, a2)) {
    return 0;
  }
  if (!mlir::OpTrait::impl::verifyOneResult(a1, v3)) {
    return 0;
  }
  if (!mlir::OpTrait::impl::verifyZeroSuccessors(a1, v4)) {
    return 0;
  }
  if (!mlir::OpTrait::impl::verifyAtLeastNOperands(a1, (mlir::Operation *)2)) {
    return 0;
  }
  uint64_t v6 = a1;
  if (!mlir::tensor::UnPackOp::verifyInvariantsImpl((mlir::tensor::UnPackOp *)&v6)) {
    return 0;
  }
  uint64_t v6 = a1;
  return mlir::tensor::UnPackOp::verify((mlir::tensor::UnPackOp *)&v6) != 0;
}

BOOL mlir::Op<mlir::tensor::UnPackOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::OneResult,mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::AtLeastNOperands<2u>::Impl,mlir::OpTrait::OpInvariants,mlir::BytecodeOpInterface::Trait,mlir::OpAsmOpInterface::Trait,mlir::DestinationStyleOpInterface::Trait,mlir::ConditionallySpeculatable::Trait,mlir::MemoryEffectOpInterface::Trait,mlir::ReifyRankedShapedTypeOpInterface::Trait,mlir::InferTypeOpInterface::Trait>::verifyRegionInvariants(mlir::detail *a1, mlir::Operation *a2)
{
  return mlir::detail::verifyDestinationStyleOpInterface(a1, a2)
      && mlir::detail::verifyInferredResultTypes(a1, v3) != 0;
}

void *mlir::RegisteredOperationName::Model<mlir::tensor::YieldOp>::Model(void *a1, uint64_t a2)
{
  v11[6] = *MEMORY[0x263EF8340];
  unint64_t v9 = v11;
  uint64_t v10 = 0x300000000;
  mlir::detail::InterfaceMap::insertModel<mlir::detail::ConditionallySpeculatableInterfaceTraits::Model<mlir::tensor::YieldOp>>((uint64_t)&v9);
  mlir::detail::InterfaceMap::insertModel<mlir::detail::MemoryEffectOpInterfaceInterfaceTraits::Model<mlir::tensor::YieldOp>>((uint64_t)&v9);
  mlir::detail::InterfaceMap::insertModel<mlir::detail::RegionBranchTerminatorOpInterfaceInterfaceTraits::Model<mlir::tensor::YieldOp>>((uint64_t)&v9);
  mlir::OperationName::Impl::Impl(a1, (uint64_t)"tensor.yield", 12, a2, (uint64_t)&mlir::detail::TypeIDResolver<mlir::tensor::YieldOp,void>::id, (uint64_t)&v9);
  uint64_t v4 = v9;
  if (v10)
  {
    uint64_t v5 = 16 * v10;
    uint64_t v6 = (void **)((char *)v9 + 8);
    do
    {
      uint64_t v7 = *v6;
      v6 += 2;
      free(v7);
      v5 -= 16;
    }
    while (v5);
    uint64_t v4 = v9;
  }
  if (v4 != v11) {
    free(v4);
  }
  *a1 = &unk_26C37B208;
  return a1;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::YieldOp>::~Model(uint64_t a1)
{
  *(void *)a1 = &unk_26C361F50;
  uint64_t v2 = *(void ***)(a1 + 32);
  uint64_t v3 = *(unsigned int *)(a1 + 40);
  if (v3)
  {
    uint64_t v4 = 16 * v3;
    uint64_t v5 = v2 + 1;
    do
    {
      uint64_t v6 = *v5;
      v5 += 2;
      free(v6);
      v4 -= 16;
    }
    while (v4);
    uint64_t v2 = *(void ***)(a1 + 32);
  }
  if (v2 != (void **)(a1 + 48)) {
    free(v2);
  }
  return a1;
}

void mlir::RegisteredOperationName::Model<mlir::tensor::YieldOp>::~Model(uint64_t a1)
{
  *(void *)a1 = &unk_26C361F50;
  uint64_t v2 = *(void ***)(a1 + 32);
  uint64_t v3 = *(unsigned int *)(a1 + 40);
  if (v3)
  {
    uint64_t v4 = 16 * v3;
    uint64_t v5 = v2 + 1;
    do
    {
      uint64_t v6 = *v5;
      v5 += 2;
      free(v6);
      v4 -= 16;
    }
    while (v4);
    uint64_t v2 = *(void ***)(a1 + 32);
  }
  if (v2 != (void **)(a1 + 48)) {
    free(v2);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::YieldOp>::foldHook()
{
  uint64_t v9 = *MEMORY[0x263EF8340];
  unint64_t v8 = (unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &>::CallbacksHolder<mlir::Op<mlir::tensor::YieldOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::HasParent<mlir::tensor::GenerateOp,mlir::tensor::PadOp>::Impl,mlir::OpTrait::OpInvariants,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::RegionBranchTerminatorOpInterface::Trait,mlir::OpTrait::ReturnLike,mlir::OpTrait::IsTerminator>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1},mlir::Op<mlir::tensor::YieldOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::HasParent<mlir::tensor::GenerateOp,mlir::tensor::PadOp>::Impl,mlir::OpTrait::OpInvariants,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::RegionBranchTerminatorOpInterface::Trait,mlir::OpTrait::ReturnLike,mlir::OpTrait::IsTerminator>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1} const,void>::Callbacks
     + 2;
  uint64_t v4 = (*(uint64_t (__cdecl **)())(((unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &>::CallbacksHolder<mlir::Op<mlir::tensor::YieldOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::HasParent<mlir::tensor::GenerateOp,mlir::tensor::PadOp>::Impl,mlir::OpTrait::OpInvariants,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::RegionBranchTerminatorOpInterface::Trait,mlir::OpTrait::ReturnLike,mlir::OpTrait::IsTerminator>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1},mlir::Op<mlir::tensor::YieldOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::HasParent<mlir::tensor::GenerateOp,mlir::tensor::PadOp>::Impl,mlir::OpTrait::OpInvariants,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::RegionBranchTerminatorOpInterface::Trait,mlir::OpTrait::ReturnLike,mlir::OpTrait::IsTerminator>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1} const,void>::Callbacks
                                 + 2) & 0xFFFFFFFFFFFFFFF8))();
  if ((unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &>::CallbacksHolder<mlir::Op<mlir::tensor::YieldOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::HasParent<mlir::tensor::GenerateOp,mlir::tensor::PadOp>::Impl,mlir::OpTrait::OpInvariants,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::RegionBranchTerminatorOpInterface::Trait,mlir::OpTrait::ReturnLike,mlir::OpTrait::IsTerminator>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1},mlir::Op<mlir::tensor::YieldOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::HasParent<mlir::tensor::GenerateOp,mlir::tensor::PadOp>::Impl,mlir::OpTrait::OpInvariants,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::RegionBranchTerminatorOpInterface::Trait,mlir::OpTrait::ReturnLike,mlir::OpTrait::IsTerminator>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1} const,void>::Callbacks
     + 2 >= 8)
  {
    if ((v8 & 4) != 0)
    {
      if ((v8 & 2) != 0) {
        uint64_t v5 = v7;
      }
      else {
        uint64_t v5 = (llvm **)v7[0];
      }
      (*(void (**)(uint64_t, unsigned int *, uint64_t, uint64_t, uint64_t))((v8 & 0xFFFFFFFFFFFFFFF8) + 16))((uint64_t)v5, v0, v1, v2, v3);
    }
    if (((llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &>::CallbacksHolder<mlir::Op<mlir::tensor::YieldOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::HasParent<mlir::tensor::GenerateOp,mlir::tensor::PadOp>::Impl,mlir::OpTrait::OpInvariants,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::RegionBranchTerminatorOpInterface::Trait,mlir::OpTrait::ReturnLike,mlir::OpTrait::IsTerminator>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1},mlir::Op<mlir::tensor::YieldOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::HasParent<mlir::tensor::GenerateOp,mlir::tensor::PadOp>::Impl,mlir::OpTrait::OpInvariants,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::RegionBranchTerminatorOpInterface::Trait,mlir::OpTrait::ReturnLike,mlir::OpTrait::IsTerminator>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1} const,void>::Callbacks
         + 2) & 2) == 0)
      llvm::deallocate_buffer(v7[0], v7[1]);
  }
  return v4;
}

BOOL mlir::RegisteredOperationName::Model<mlir::tensor::YieldOp>::hasTrait(uint64_t a1, uint64_t a2)
{
  uint64_t v9 = *MEMORY[0x263EF8340];
  unint64_t v8 = (unint64_t)llvm::detail::UniqueFunctionBase<BOOL,mlir::TypeID>::CallbacksHolder<mlir::Op<mlir::tensor::YieldOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::HasParent<mlir::tensor::GenerateOp,mlir::tensor::PadOp>::Impl,mlir::OpTrait::OpInvariants,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::RegionBranchTerminatorOpInterface::Trait,mlir::OpTrait::ReturnLike,mlir::OpTrait::IsTerminator>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1},mlir::Op<mlir::tensor::YieldOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::HasParent<mlir::tensor::GenerateOp,mlir::tensor::PadOp>::Impl,mlir::OpTrait::OpInvariants,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::RegionBranchTerminatorOpInterface::Trait,mlir::OpTrait::ReturnLike,mlir::OpTrait::IsTerminator>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1} const,void>::Callbacks
     + 2;
  BOOL v3 = (*(BOOL (**)(uint64_t, uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<BOOL,mlir::TypeID>::CallbacksHolder<mlir::Op<mlir::tensor::YieldOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::HasParent<mlir::tensor::GenerateOp,mlir::tensor::PadOp>::Impl,mlir::OpTrait::OpInvariants,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::RegionBranchTerminatorOpInterface::Trait,mlir::OpTrait::ReturnLike,mlir::OpTrait::IsTerminator>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1},mlir::Op<mlir::tensor::YieldOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::HasParent<mlir::tensor::GenerateOp,mlir::tensor::PadOp>::Impl,mlir::OpTrait::OpInvariants,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::RegionBranchTerminatorOpInterface::Trait,mlir::OpTrait::ReturnLike,mlir::OpTrait::IsTerminator>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1} const,void>::Callbacks
                                                 + 2) & 0xFFFFFFFFFFFFFFF8))((uint64_t)v7, a2);
  char v4 = v8;
  if (v8 >= 8)
  {
    if ((v8 & 4) != 0)
    {
      if ((v8 & 2) != 0) {
        uint64_t v5 = v7;
      }
      else {
        uint64_t v5 = (llvm **)v7[0];
      }
      (*(void (**)(uint64_t, uint64_t))((v8 & 0xFFFFFFFFFFFFFFF8) + 16))((uint64_t)v5, v2);
    }
    if ((v4 & 2) == 0) {
      llvm::deallocate_buffer(v7[0], v7[1]);
    }
  }
  return v3;
}

void mlir::RegisteredOperationName::Model<mlir::tensor::YieldOp>::getParseAssemblyFn(BOOL (**a1)(uint64_t a1, uint64_t a2)@<X8>)
{
  *a1 = mlir::tensor::YieldOp::parse;
  a1[3] = (BOOL (*)(uint64_t, uint64_t))((char *)llvm::detail::UniqueFunctionBase<mlir::ParseResult,mlir::OpAsmParser &,mlir::OperationState &>::CallbacksHolder<mlir::ParseResult (*)(mlir::OpAsmParser &,mlir::OperationState &),mlir::ParseResult (*)(mlir::OpAsmParser &,mlir::OperationState &),void>::Callbacks
                                                + 2);
}

void mlir::RegisteredOperationName::Model<mlir::tensor::YieldOp>::printAssembly(uint64_t a1, mlir::Operation *a2, mlir::OpAsmPrinter *a3, uint64_t a4, uint64_t a5)
{
  uint64_t v13 = *MEMORY[0x263EF8340];
  unint64_t v12 = (unint64_t)llvm::detail::UniqueFunctionBase<void,mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef>::CallbacksHolder<mlir::Op<mlir::tensor::YieldOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::HasParent<mlir::tensor::GenerateOp,mlir::tensor::PadOp>::Impl,mlir::OpTrait::OpInvariants,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::RegionBranchTerminatorOpInterface::Trait,mlir::OpTrait::ReturnLike,mlir::OpTrait::IsTerminator>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1},mlir::Op<mlir::tensor::YieldOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::HasParent<mlir::tensor::GenerateOp,mlir::tensor::PadOp>::Impl,mlir::OpTrait::OpInvariants,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::RegionBranchTerminatorOpInterface::Trait,mlir::OpTrait::ReturnLike,mlir::OpTrait::IsTerminator>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1} const,void>::Callbacks
      + 2;
  (*(void (**)(uint64_t, mlir::Operation *, mlir::OpAsmPrinter *, uint64_t, uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<void,mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef>::CallbacksHolder<mlir::Op<mlir::tensor::YieldOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::HasParent<mlir::tensor::GenerateOp,mlir::tensor::PadOp>::Impl,mlir::OpTrait::OpInvariants,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::RegionBranchTerminatorOpInterface::Trait,mlir::OpTrait::ReturnLike,mlir::OpTrait::IsTerminator>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1},mlir::Op<mlir::tensor::YieldOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::HasParent<mlir::tensor::GenerateOp,mlir::tensor::PadOp>::Impl,mlir::OpTrait::OpInvariants,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::RegionBranchTerminatorOpInterface::Trait,mlir::OpTrait::ReturnLike,mlir::OpTrait::IsTerminator>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1} const,void>::Callbacks
                                                                                              + 2) & 0xFFFFFFFFFFFFFFF8))((uint64_t)v11, a2, a3, a4, a5);
  char v9 = v12;
  if (v12 >= 8)
  {
    if ((v12 & 4) != 0)
    {
      if ((v12 & 2) != 0) {
        uint64_t v10 = v11;
      }
      else {
        uint64_t v10 = (llvm **)v11[0];
      }
      (*(void (**)(uint64_t, mlir::Operation *, mlir::OpAsmPrinter *, uint64_t, uint64_t))((v12 & 0xFFFFFFFFFFFFFFF8)
                                                                                                 + 16))((uint64_t)v10, v5, v6, v7, v8);
    }
    if ((v9 & 2) == 0) {
      llvm::deallocate_buffer(v11[0], v11[1]);
    }
  }
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::YieldOp>::verifyInvariants(uint64_t a1, uint64_t a2)
{
  uint64_t v7 = *MEMORY[0x263EF8340];
  v5[0] = (uint64_t (*)(uint64_t))mlir::Op<mlir::tensor::YieldOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::HasParent<mlir::tensor::GenerateOp,mlir::tensor::PadOp>::Impl,mlir::OpTrait::OpInvariants,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::RegionBranchTerminatorOpInterface::Trait,mlir::OpTrait::ReturnLike,mlir::OpTrait::IsTerminator>::verifyInvariants;
  unint64_t v6 = (unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *>::CallbacksHolder<mlir::LogicalResult (*)(mlir::Operation *),mlir::LogicalResult (* const)(mlir::Operation *),void>::Callbacks
     + 2;
  uint64_t v2 = (*(uint64_t (**)(uint64_t (**)(uint64_t), uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *>::CallbacksHolder<mlir::LogicalResult (*)(mlir::Operation *),mlir::LogicalResult (* const)(mlir::Operation *),void>::Callbacks
                                                                             + 2) & 0xFFFFFFFFFFFFFFF8))(v5, a2);
  char v3 = v6;
  if (v6 >= 8)
  {
    if ((v6 & 4) != 0) {
      (*(void (__cdecl **)())((v6 & 0xFFFFFFFFFFFFFFF8) + 16))();
    }
    if ((v3 & 2) == 0) {
      llvm::deallocate_buffer((llvm *)v5[0], v5[1]);
    }
  }
  return v2;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::YieldOp>::verifyRegionInvariants(uint64_t a1, uint64_t a2)
{
  uint64_t v7 = *MEMORY[0x263EF8340];
  v5[0] = (uint64_t (*)(uint64_t))mlir::Op<mlir::tensor::YieldOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::HasParent<mlir::tensor::GenerateOp,mlir::tensor::PadOp>::Impl,mlir::OpTrait::OpInvariants,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::RegionBranchTerminatorOpInterface::Trait,mlir::OpTrait::ReturnLike,mlir::OpTrait::IsTerminator>::verifyRegionInvariants;
  unint64_t v6 = (unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *>::CallbacksHolder<mlir::LogicalResult (*)(mlir::Operation *),mlir::LogicalResult (* const)(mlir::Operation *),void>::Callbacks
     + 2;
  uint64_t v2 = (*(uint64_t (**)(uint64_t (**)(uint64_t), uint64_t))(((unint64_t)llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *>::CallbacksHolder<mlir::LogicalResult (*)(mlir::Operation *),mlir::LogicalResult (* const)(mlir::Operation *),void>::Callbacks
                                                                             + 2) & 0xFFFFFFFFFFFFFFF8))(v5, a2);
  char v3 = v6;
  if (v6 >= 8)
  {
    if ((v6 & 4) != 0) {
      (*(void (__cdecl **)())((v6 & 0xFFFFFFFFFFFFFFF8) + 16))();
    }
    if ((v3 & 2) == 0) {
      llvm::deallocate_buffer((llvm *)v5[0], v5[1]);
    }
  }
  return v2;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::YieldOp>::getInherentAttr(uint64_t a1, uint64_t a2, const void *a3, size_t a4)
{
  return mlir::DictionaryAttr::get(a2 + 56, a3, a4);
}

void mlir::RegisteredOperationName::Model<mlir::tensor::YieldOp>::setInherentAttr(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  v9[9] = *MEMORY[0x263EF8340];
  mlir::NamedAttrList::NamedAttrList(v8, *(void *)(a2 + 56));
  if (mlir::NamedAttrList::set((uint64_t)v8, a3, a4) != a4)
  {
    uint64_t Context = (mlir::MLIRContext *)mlir::Attribute::getContext((mlir::Attribute *)(a2 + 24));
    *(void *)(a2 + 56) = mlir::NamedAttrList::getDictionary((mlir::NamedAttrList *)v8, Context);
  }
  if (v8[0] != v9) {
    free(v8[0]);
  }
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::YieldOp>::verifyInherentAttrs()
{
  return 1;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::YieldOp>::getOpPropertyByteSize()
{
  return 0;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::YieldOp>::setPropertiesFromAttr(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, void (*a5)(void *__return_ptr, uint64_t), uint64_t a6)
{
  uint64_t v34 = *MEMORY[0x263EF8340];
  a5(v24, a6);
  if (v24[0])
  {
    int v21 = 3;
    uint64_t v22 = "this operation does not support properties";
    uint64_t v23 = 42;
    unint64_t v6 = &v21;
    uint64_t v7 = (char *)v25;
    if (v26 >= v27)
    {
      unint64_t v19 = v26 + 1;
      if (v25 <= &v21 && (char *)v25 + 24 * v26 > (char *)&v21)
      {
        int64_t v20 = (char *)&v21 - (unsigned char *)v25;
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v25, v28, v19, 24);
        uint64_t v7 = (char *)v25;
        unint64_t v6 = (int *)((char *)v25 + v20);
      }
      else
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v25, v28, v19, 24);
        unint64_t v6 = &v21;
        uint64_t v7 = (char *)v25;
      }
    }
    uint64_t v8 = &v7[24 * v26];
    long long v9 = *(_OWORD *)v6;
    *((void *)v8 + 2) = *((void *)v6 + 2);
    *(_OWORD *)uint64_t v8 = v9;
    ++v26;
    if (v24[0]) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v24);
    }
  }
  if (v33)
  {
    uint64_t v10 = __p;
    if (__p)
    {
      uint64_t v11 = v32;
      unint64_t v12 = __p;
      if (v32 != __p)
      {
        do
          uint64_t v11 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v11 - 1);
        while (v11 != v10);
        unint64_t v12 = __p;
      }
      unint64_t v32 = v10;
      operator delete(v12);
    }
    uint64_t v13 = v29;
    if (v29)
    {
      uint64_t v14 = v30;
      uint64_t v15 = v29;
      if (v30 != v29)
      {
        do
        {
          uint64_t v17 = *--v14;
          uint64_t v16 = v17;
          *uint64_t v14 = 0;
          if (v17) {
            MEMORY[0x21667D390](v16, 0x1000C8077774924);
          }
        }
        while (v14 != v13);
        uint64_t v15 = v29;
      }
      int v30 = v13;
      operator delete(v15);
    }
    if (v25 != v28) {
      free(v25);
    }
  }
  return 0;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::YieldOp>::getPropertiesAsAttr()
{
  return 0;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::YieldOp>::compareProperties()
{
  return 1;
}

uint64_t mlir::RegisteredOperationName::Model<mlir::tensor::YieldOp>::hashProperties()
{
  return 0;
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::ConditionallySpeculatableInterfaceTraits::Model<mlir::tensor::YieldOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(8uLL, 0x80040B8603338uLL);
  *uint64_t v2 = mlir::detail::ConditionallySpeculatableInterfaceTraits::Model<mlir::tensor::YieldOp>::getSpeculatability;
  char v3 = &unk_267771000;
  {
    unint64_t v12 = v2;
    char v3 = (void *)&unk_267771000;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ConditionallySpeculatable]";
      unint64_t v14 = 81;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      uint64_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::ConditionallySpeculatable,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      char v3 = (void *)&unk_267771000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[314], v2);
}

uint64_t mlir::detail::ConditionallySpeculatableInterfaceTraits::Model<mlir::tensor::YieldOp>::getSpeculatability()
{
  return 1;
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::MemoryEffectOpInterfaceInterfaceTraits::Model<mlir::tensor::YieldOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(8uLL, 0x80040B8603338uLL);
  *uint64_t v2 = mlir::detail::MemoryEffectOpInterfaceInterfaceTraits::Model<mlir::tensor::YieldOp>::getEffects;
  char v3 = &unk_267771000;
  {
    unint64_t v12 = v2;
    char v3 = (void *)&unk_267771000;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::MemoryEffectOpInterface]";
      unint64_t v14 = 79;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      uint64_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::MemoryEffectOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      char v3 = (void *)&unk_267771000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[11], v2);
}

void mlir::detail::MemoryEffectOpInterfaceInterfaceTraits::Model<mlir::tensor::YieldOp>::getEffects(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = a2;
  ZinIrHalH13g::~ZinIrHalH13g((ZinIrHalH13g *)&v2);
}

void mlir::detail::InterfaceMap::insertModel<mlir::detail::RegionBranchTerminatorOpInterfaceInterfaceTraits::Model<mlir::tensor::YieldOp>>(uint64_t a1)
{
  uint64_t v2 = malloc_type_malloc(0x10uLL, 0x80040803F642BuLL);
  *uint64_t v2 = mlir::detail::RegionBranchTerminatorOpInterfaceInterfaceTraits::Model<mlir::tensor::YieldOp>::getMutableSuccessorOperands;
  v2[1] = mlir::detail::RegionBranchTerminatorOpInterfaceInterfaceTraits::Model<mlir::tensor::YieldOp>::getSuccessorRegions;
  char v3 = &unk_267770000;
  {
    unint64_t v12 = v2;
    char v3 = (void *)&unk_267770000;
    uint64_t v2 = v12;
    if (v4)
    {
      uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::RegionBranchTerminatorOpInterface]";
      unint64_t v14 = 89;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      uint64_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::RegionBranchTerminatorOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      char v3 = (void *)&unk_267770000;
      uint64_t v2 = v12;
    }
  }
  mlir::detail::InterfaceMap::insert(a1, v3[405], v2);
}

double mlir::detail::RegionBranchTerminatorOpInterfaceInterfaceTraits::Model<mlir::tensor::YieldOp>::getMutableSuccessorOperands@<D0>(mlir::Operation *a1@<X1>, mlir::MutableOperandRange *a2@<X8>)
{
  char v3 = a1;
  return mlir::memref::AllocaScopeReturnOp::getMutableSuccessorOperands(&v3, a2);
}

uint64_t mlir::detail::RegionBranchTerminatorOpInterfaceInterfaceTraits::Model<mlir::tensor::YieldOp>::getSuccessorRegions(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v6 = a2;
  return mlir::detail::RegionBranchTerminatorOpInterfaceTrait<mlir::func::ReturnOp>::getSuccessorRegions(&v6, a3, a4, a5);
}

uint64_t llvm::detail::UniqueFunctionBase<mlir::LogicalResult,mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &>::CallImpl<mlir::Op<mlir::tensor::YieldOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::HasParent<mlir::tensor::GenerateOp,mlir::tensor::PadOp>::Impl,mlir::OpTrait::OpInvariants,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::RegionBranchTerminatorOpInterface::Trait,mlir::OpTrait::ReturnLike,mlir::OpTrait::IsTerminator>::getFoldHookFn(void)::{lambda(mlir::Operation *,llvm::ArrayRef<mlir::Attribute>,llvm::SmallVectorImpl<mlir::OpFoldResult> &)#1} const>()
{
  return 0;
}

BOOL llvm::detail::UniqueFunctionBase<BOOL,mlir::TypeID>::CallImpl<mlir::Op<mlir::tensor::YieldOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::HasParent<mlir::tensor::GenerateOp,mlir::tensor::PadOp>::Impl,mlir::OpTrait::OpInvariants,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::RegionBranchTerminatorOpInterface::Trait,mlir::OpTrait::ReturnLike,mlir::OpTrait::IsTerminator>::getHasTraitFn(void)::{lambda(mlir::TypeID)#1} const>(uint64_t a1, uint64_t a2)
{
  return mlir::op_definition_impl::hasTrait<mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::HasParent<mlir::tensor::GenerateOp,mlir::tensor::PadOp>::Impl,mlir::OpTrait::OpInvariants,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::RegionBranchTerminatorOpInterface::Trait,mlir::OpTrait::ReturnLike,mlir::OpTrait::IsTerminator>(a2);
}

BOOL mlir::op_definition_impl::hasTrait<mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::HasParent<mlir::tensor::GenerateOp,mlir::tensor::PadOp>::Impl,mlir::OpTrait::OpInvariants,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::RegionBranchTerminatorOpInterface::Trait,mlir::OpTrait::ReturnLike,mlir::OpTrait::IsTerminator>(uint64_t a1)
{
  uint64_t v1 = &unk_267771000;
  {
    uint64_t v210 = a1;
    uint64_t v1 = (void *)&unk_267771000;
    int v37 = v36;
    a1 = v210;
    if (v37)
    {
      uint64_t v222 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::ZeroRegions<Empty>]";
      unint64_t v223 = 83;
      unint64_t v38 = llvm::StringRef::find((uint64_t *)&v222, "DesiredTypeName = ", 0x12uLL, 0);
      if (v223 >= v38) {
        unint64_t v39 = v38;
      }
      else {
        unint64_t v39 = v223;
      }
      int v40 = &v222[v39];
      unint64_t v41 = v223 - v39;
      if (v223 - v39 >= 0x12) {
        uint64_t v42 = 18;
      }
      else {
        uint64_t v42 = v223 - v39;
      }
      unint64_t v43 = v41 - v42;
      if (v43 >= v43 - 1) {
        uint64_t v44 = v43 - 1;
      }
      else {
        uint64_t v44 = v43;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::ZeroRegions<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::ZeroRegions>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v40[v42], v44);
      uint64_t v1 = (void *)&unk_267771000;
      a1 = v210;
    }
  }
  uint64_t v2 = v1[23];
  char v3 = &unk_267770000;
  {
    uint64_t v199 = v2;
    uint64_t v211 = a1;
    char v3 = (void *)&unk_267770000;
    int v46 = v45;
    uint64_t v2 = v199;
    a1 = v211;
    if (v46)
    {
      uint64_t v222 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::ZeroResults<Empty>]";
      unint64_t v223 = 83;
      unint64_t v47 = llvm::StringRef::find((uint64_t *)&v222, "DesiredTypeName = ", 0x12uLL, 0);
      if (v223 >= v47) {
        unint64_t v48 = v47;
      }
      else {
        unint64_t v48 = v223;
      }
      int v49 = &v222[v48];
      unint64_t v50 = v223 - v48;
      if (v223 - v48 >= 0x12) {
        uint64_t v51 = 18;
      }
      else {
        uint64_t v51 = v223 - v48;
      }
      unint64_t v52 = v50 - v51;
      if (v52 >= v52 - 1) {
        uint64_t v53 = v52 - 1;
      }
      else {
        uint64_t v53 = v52;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::ZeroResults<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::ZeroResults>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v49[v51], v53);
      char v3 = (void *)&unk_267770000;
      uint64_t v2 = v199;
      a1 = v211;
    }
  }
  uint64_t v4 = v3[429];
  unint64_t v5 = &unk_267770000;
  {
    uint64_t v200 = v2;
    uint64_t v212 = a1;
    uint64_t v189 = v4;
    unint64_t v5 = (void *)&unk_267770000;
    uint64_t v4 = v189;
    uint64_t v2 = v200;
    int v55 = v54;
    a1 = v212;
    if (v55)
    {
      uint64_t v222 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::ZeroSuccessors<Empty>]";
      unint64_t v223 = 86;
      unint64_t v56 = llvm::StringRef::find((uint64_t *)&v222, "DesiredTypeName = ", 0x12uLL, 0);
      if (v223 >= v56) {
        unint64_t v57 = v56;
      }
      else {
        unint64_t v57 = v223;
      }
      int v58 = &v222[v57];
      unint64_t v59 = v223 - v57;
      if (v223 - v57 >= 0x12) {
        uint64_t v60 = 18;
      }
      else {
        uint64_t v60 = v223 - v57;
      }
      unint64_t v61 = v59 - v60;
      if (v61 >= v61 - 1) {
        uint64_t v62 = v61 - 1;
      }
      else {
        uint64_t v62 = v61;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::ZeroSuccessors<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::ZeroSuccessors>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v58[v60], v62);
      unint64_t v5 = (void *)&unk_267770000;
      uint64_t v4 = v189;
      uint64_t v2 = v200;
      a1 = v212;
    }
  }
  uint64_t v6 = v5[431];
  uint64_t v7 = &unk_267771000;
  {
    uint64_t v201 = v2;
    uint64_t v213 = a1;
    uint64_t v190 = v4;
    uint64_t v180 = v6;
    uint64_t v7 = (void *)&unk_267771000;
    uint64_t v6 = v180;
    uint64_t v4 = v190;
    uint64_t v2 = v201;
    int v64 = v63;
    a1 = v213;
    if (v64)
    {
      uint64_t v222 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::OneOperand<Empty>]";
      unint64_t v223 = 82;
      unint64_t v65 = llvm::StringRef::find((uint64_t *)&v222, "DesiredTypeName = ", 0x12uLL, 0);
      if (v223 >= v65) {
        unint64_t v66 = v65;
      }
      else {
        unint64_t v66 = v223;
      }
      int v67 = &v222[v66];
      unint64_t v68 = v223 - v66;
      if (v223 - v66 >= 0x12) {
        uint64_t v69 = 18;
      }
      else {
        uint64_t v69 = v223 - v66;
      }
      unint64_t v70 = v68 - v69;
      if (v70 >= v70 - 1) {
        uint64_t v71 = v70 - 1;
      }
      else {
        uint64_t v71 = v70;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::OneOperand<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::OneOperand>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v67[v69], v71);
      uint64_t v7 = (void *)&unk_267771000;
      uint64_t v6 = v180;
      uint64_t v4 = v190;
      uint64_t v2 = v201;
      a1 = v213;
    }
  }
  uint64_t v8 = v7[29];
  uint64_t v9 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
  {
    uint64_t v202 = v2;
    uint64_t v214 = a1;
    uint64_t v191 = v4;
    uint64_t v172 = v8;
    uint64_t v181 = v6;
    uint64_t v9 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
    uint64_t v8 = v172;
    uint64_t v6 = v181;
    uint64_t v4 = v191;
    uint64_t v2 = v202;
    int v73 = v72;
    a1 = v214;
    if (v73)
    {
      uint64_t v222 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::HasParent<mlir::tensor::GenerateOp, mlir::t"
             "ensor::PadOp>::Impl<Empty>]";
      unint64_t v223 = 134;
      unint64_t v74 = llvm::StringRef::find((uint64_t *)&v222, "DesiredTypeName = ", 0x12uLL, 0);
      if (v223 >= v74) {
        unint64_t v75 = v74;
      }
      else {
        unint64_t v75 = v223;
      }
      int v76 = &v222[v75];
      unint64_t v77 = v223 - v75;
      if (v223 - v75 >= 0x12) {
        uint64_t v78 = 18;
      }
      else {
        uint64_t v78 = v223 - v75;
      }
      unint64_t v79 = v77 - v78;
      if (v79 >= v79 - 1) {
        uint64_t v80 = v79 - 1;
      }
      else {
        uint64_t v80 = v79;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::HasParent<mlir::tensor::GenerateOp,mlir::tensor::PadOp>::Impl<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::HasParent<mlir::tensor::GenerateOp,mlir::tensor::PadOp>::Impl>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v76[v78], v80);
      uint64_t v9 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
      uint64_t v8 = v172;
      uint64_t v6 = v181;
      uint64_t v4 = v191;
      uint64_t v2 = v202;
      a1 = v214;
    }
  }
  uint64_t v10 = v9[238];
  uint64_t v11 = &unk_267770000;
  {
    uint64_t v203 = v2;
    uint64_t v215 = a1;
    uint64_t v192 = v4;
    uint64_t v173 = v8;
    uint64_t v182 = v6;
    uint64_t v165 = v10;
    uint64_t v11 = (void *)&unk_267770000;
    uint64_t v10 = v165;
    uint64_t v8 = v173;
    uint64_t v6 = v182;
    uint64_t v4 = v192;
    uint64_t v2 = v203;
    int v82 = v81;
    a1 = v215;
    if (v82)
    {
      uint64_t v222 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::OpInvariants<Empty>]";
      unint64_t v223 = 84;
      unint64_t v83 = llvm::StringRef::find((uint64_t *)&v222, "DesiredTypeName = ", 0x12uLL, 0);
      if (v223 >= v83) {
        unint64_t v84 = v83;
      }
      else {
        unint64_t v84 = v223;
      }
      int v85 = &v222[v84];
      unint64_t v86 = v223 - v84;
      if (v223 - v84 >= 0x12) {
        uint64_t v87 = 18;
      }
      else {
        uint64_t v87 = v223 - v84;
      }
      unint64_t v88 = v86 - v87;
      if (v88 >= v88 - 1) {
        uint64_t v89 = v88 - 1;
      }
      else {
        uint64_t v89 = v88;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::OpInvariants<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::OpInvariants>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v85[v87], v89);
      uint64_t v11 = (void *)&unk_267770000;
      uint64_t v10 = v165;
      uint64_t v8 = v173;
      uint64_t v6 = v182;
      uint64_t v4 = v192;
      uint64_t v2 = v203;
      a1 = v215;
    }
  }
  uint64_t v12 = v11[435];
  uint64_t v13 = &unk_267771000;
  {
    uint64_t v204 = v2;
    uint64_t v216 = a1;
    uint64_t v193 = v4;
    uint64_t v174 = v8;
    uint64_t v183 = v6;
    uint64_t v159 = v12;
    uint64_t v166 = v10;
    uint64_t v13 = (void *)&unk_267771000;
    uint64_t v12 = v159;
    uint64_t v10 = v166;
    uint64_t v8 = v174;
    uint64_t v6 = v183;
    uint64_t v4 = v193;
    uint64_t v2 = v204;
    int v91 = v90;
    a1 = v216;
    if (v91)
    {
      uint64_t v222 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ConditionallySpeculatable::Trait<Empty>]";
      unint64_t v223 = 95;
      unint64_t v92 = llvm::StringRef::find((uint64_t *)&v222, "DesiredTypeName = ", 0x12uLL, 0);
      if (v223 >= v92) {
        unint64_t v93 = v92;
      }
      else {
        unint64_t v93 = v223;
      }
      int v94 = &v222[v93];
      unint64_t v95 = v223 - v93;
      if (v223 - v93 >= 0x12) {
        uint64_t v96 = 18;
      }
      else {
        uint64_t v96 = v223 - v93;
      }
      unint64_t v97 = v95 - v96;
      if (v97 >= v97 - 1) {
        uint64_t v98 = v97 - 1;
      }
      else {
        uint64_t v98 = v97;
      }
      mlir::detail::TypeIDResolver<mlir::ConditionallySpeculatable::Trait<mlir::TypeID mlir::TypeID::get<mlir::ConditionallySpeculatable::Trait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v94[v96], v98);
      uint64_t v13 = (void *)&unk_267771000;
      uint64_t v12 = v159;
      uint64_t v10 = v166;
      uint64_t v8 = v174;
      uint64_t v6 = v183;
      uint64_t v4 = v193;
      uint64_t v2 = v204;
      a1 = v216;
    }
  }
  uint64_t v14 = v13[322];
  uint64_t v15 = &unk_267771000;
  {
    uint64_t v205 = v2;
    uint64_t v217 = a1;
    uint64_t v194 = v4;
    uint64_t v175 = v8;
    uint64_t v184 = v6;
    uint64_t v160 = v12;
    uint64_t v167 = v10;
    uint64_t v154 = v14;
    uint64_t v15 = (void *)&unk_267771000;
    uint64_t v14 = v154;
    uint64_t v12 = v160;
    uint64_t v10 = v167;
    uint64_t v8 = v175;
    uint64_t v6 = v184;
    uint64_t v4 = v194;
    uint64_t v2 = v205;
    int v100 = v99;
    a1 = v217;
    if (v100)
    {
      uint64_t v222 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::AlwaysSpeculatableImplTrait<Empty>]";
      unint64_t v223 = 99;
      unint64_t v101 = llvm::StringRef::find((uint64_t *)&v222, "DesiredTypeName = ", 0x12uLL, 0);
      if (v223 >= v101) {
        unint64_t v102 = v101;
      }
      else {
        unint64_t v102 = v223;
      }
      int v103 = &v222[v102];
      unint64_t v104 = v223 - v102;
      if (v223 - v102 >= 0x12) {
        uint64_t v105 = 18;
      }
      else {
        uint64_t v105 = v223 - v102;
      }
      unint64_t v106 = v104 - v105;
      if (v106 >= v106 - 1) {
        uint64_t v107 = v106 - 1;
      }
      else {
        uint64_t v107 = v106;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::AlwaysSpeculatableImplTrait<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::AlwaysSpeculatableImplTrait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v103[v105], v107);
      uint64_t v15 = (void *)&unk_267771000;
      uint64_t v14 = v154;
      uint64_t v12 = v160;
      uint64_t v10 = v167;
      uint64_t v8 = v175;
      uint64_t v6 = v184;
      uint64_t v4 = v194;
      uint64_t v2 = v205;
      a1 = v217;
    }
  }
  uint64_t v16 = v15[324];
  uint64_t v17 = &unk_267771000;
  {
    uint64_t v206 = v2;
    uint64_t v218 = a1;
    uint64_t v195 = v4;
    uint64_t v176 = v8;
    uint64_t v185 = v6;
    uint64_t v161 = v12;
    uint64_t v168 = v10;
    uint64_t v150 = v16;
    uint64_t v155 = v14;
    uint64_t v17 = (void *)&unk_267771000;
    uint64_t v16 = v150;
    uint64_t v14 = v155;
    uint64_t v12 = v161;
    uint64_t v10 = v168;
    uint64_t v8 = v176;
    uint64_t v6 = v185;
    uint64_t v4 = v195;
    uint64_t v2 = v206;
    int v109 = v108;
    a1 = v218;
    if (v109)
    {
      uint64_t v222 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::MemoryEffectOpInterface::Trait<Empty>]";
      unint64_t v223 = 93;
      unint64_t v110 = llvm::StringRef::find((uint64_t *)&v222, "DesiredTypeName = ", 0x12uLL, 0);
      if (v223 >= v110) {
        unint64_t v111 = v110;
      }
      else {
        unint64_t v111 = v223;
      }
      int v112 = &v222[v111];
      unint64_t v113 = v223 - v111;
      if (v223 - v111 >= 0x12) {
        uint64_t v114 = 18;
      }
      else {
        uint64_t v114 = v223 - v111;
      }
      unint64_t v115 = v113 - v114;
      if (v115 >= v115 - 1) {
        uint64_t v116 = v115 - 1;
      }
      else {
        uint64_t v116 = v115;
      }
      mlir::detail::TypeIDResolver<mlir::MemoryEffectOpInterface::Trait<mlir::TypeID mlir::TypeID::get<mlir::MemoryEffectOpInterface::Trait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v112[v114], v116);
      uint64_t v17 = (void *)&unk_267771000;
      uint64_t v16 = v150;
      uint64_t v14 = v155;
      uint64_t v12 = v161;
      uint64_t v10 = v168;
      uint64_t v8 = v176;
      uint64_t v6 = v185;
      uint64_t v4 = v195;
      uint64_t v2 = v206;
      a1 = v218;
    }
  }
  uint64_t v18 = v17[31];
  unint64_t v19 = &unk_267772000;
  {
    uint64_t v207 = v2;
    uint64_t v219 = a1;
    uint64_t v196 = v4;
    uint64_t v177 = v8;
    uint64_t v186 = v6;
    uint64_t v162 = v12;
    uint64_t v169 = v10;
    uint64_t v151 = v16;
    uint64_t v156 = v14;
    uint64_t v147 = v18;
    unint64_t v19 = (void *)&unk_267772000;
    uint64_t v18 = v147;
    uint64_t v16 = v151;
    uint64_t v14 = v156;
    uint64_t v12 = v162;
    uint64_t v10 = v169;
    uint64_t v8 = v177;
    uint64_t v6 = v186;
    uint64_t v4 = v196;
    uint64_t v2 = v207;
    int v118 = v117;
    a1 = v219;
    if (v118)
    {
      uint64_t v222 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::RegionBranchTerminatorOpInterface::Trait<Empty>]";
      unint64_t v223 = 103;
      unint64_t v119 = llvm::StringRef::find((uint64_t *)&v222, "DesiredTypeName = ", 0x12uLL, 0);
      if (v223 >= v119) {
        unint64_t v120 = v119;
      }
      else {
        unint64_t v120 = v223;
      }
      int v121 = &v222[v120];
      unint64_t v122 = v223 - v120;
      if (v223 - v120 >= 0x12) {
        uint64_t v123 = 18;
      }
      else {
        uint64_t v123 = v223 - v120;
      }
      unint64_t v124 = v122 - v123;
      if (v124 >= v124 - 1) {
        uint64_t v125 = v124 - 1;
      }
      else {
        uint64_t v125 = v124;
      }
      mlir::detail::TypeIDResolver<mlir::RegionBranchTerminatorOpInterface::Trait<mlir::TypeID mlir::TypeID::get<mlir::RegionBranchTerminatorOpInterface::Trait>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v121[v123], v125);
      unint64_t v19 = (void *)&unk_267772000;
      uint64_t v18 = v147;
      uint64_t v16 = v151;
      uint64_t v14 = v156;
      uint64_t v12 = v162;
      uint64_t v10 = v169;
      uint64_t v8 = v177;
      uint64_t v6 = v186;
      uint64_t v4 = v196;
      uint64_t v2 = v207;
      a1 = v219;
    }
  }
  uint64_t v20 = v19[79];
  int v21 = &unk_267770000;
  {
    uint64_t v208 = v2;
    uint64_t v220 = a1;
    uint64_t v197 = v4;
    uint64_t v178 = v8;
    uint64_t v187 = v6;
    uint64_t v163 = v12;
    uint64_t v170 = v10;
    uint64_t v152 = v16;
    uint64_t v157 = v14;
    uint64_t v145 = v20;
    uint64_t v148 = v18;
    int v21 = (void *)&unk_267770000;
    uint64_t v20 = v145;
    uint64_t v18 = v148;
    uint64_t v16 = v152;
    uint64_t v14 = v157;
    uint64_t v12 = v163;
    uint64_t v10 = v170;
    uint64_t v8 = v178;
    uint64_t v6 = v187;
    uint64_t v4 = v197;
    uint64_t v2 = v208;
    int v127 = v126;
    a1 = v220;
    if (v127)
    {
      uint64_t v222 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::ReturnLike<Empty>]";
      unint64_t v223 = 82;
      unint64_t v128 = llvm::StringRef::find((uint64_t *)&v222, "DesiredTypeName = ", 0x12uLL, 0);
      if (v223 >= v128) {
        unint64_t v129 = v128;
      }
      else {
        unint64_t v129 = v223;
      }
      int v130 = &v222[v129];
      unint64_t v131 = v223 - v129;
      if (v223 - v129 >= 0x12) {
        uint64_t v132 = 18;
      }
      else {
        uint64_t v132 = v223 - v129;
      }
      unint64_t v133 = v131 - v132;
      if (v133 >= v133 - 1) {
        uint64_t v134 = v133 - 1;
      }
      else {
        uint64_t v134 = v133;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::ReturnLike<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::ReturnLike>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v130[v132], v134);
      int v21 = (void *)&unk_267770000;
      uint64_t v20 = v145;
      uint64_t v18 = v148;
      uint64_t v16 = v152;
      uint64_t v14 = v157;
      uint64_t v12 = v163;
      uint64_t v10 = v170;
      uint64_t v8 = v178;
      uint64_t v6 = v187;
      uint64_t v4 = v197;
      uint64_t v2 = v208;
      a1 = v220;
    }
  }
  uint64_t v22 = v21[413];
  uint64_t v23 = &unk_267771000;
  {
    uint64_t v209 = v2;
    uint64_t v221 = a1;
    uint64_t v198 = v4;
    uint64_t v179 = v8;
    uint64_t v188 = v6;
    uint64_t v164 = v12;
    uint64_t v171 = v10;
    uint64_t v153 = v16;
    uint64_t v158 = v14;
    uint64_t v146 = v20;
    uint64_t v149 = v18;
    uint64_t v144 = v22;
    uint64_t v23 = (void *)&unk_267771000;
    uint64_t v22 = v144;
    uint64_t v20 = v146;
    uint64_t v18 = v149;
    uint64_t v16 = v153;
    uint64_t v14 = v158;
    uint64_t v12 = v164;
    uint64_t v10 = v171;
    uint64_t v8 = v179;
    uint64_t v6 = v188;
    uint64_t v4 = v198;
    uint64_t v2 = v209;
    int v136 = v135;
    a1 = v221;
    if (v136)
    {
      uint64_t v222 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::IsTerminator<Empty>]";
      unint64_t v223 = 84;
      unint64_t v137 = llvm::StringRef::find((uint64_t *)&v222, "DesiredTypeName = ", 0x12uLL, 0);
      if (v223 >= v137) {
        unint64_t v138 = v137;
      }
      else {
        unint64_t v138 = v223;
      }
      int v139 = &v222[v138];
      unint64_t v140 = v223 - v138;
      if (v223 - v138 >= 0x12) {
        uint64_t v141 = 18;
      }
      else {
        uint64_t v141 = v223 - v138;
      }
      unint64_t v142 = v140 - v141;
      if (v142 >= v142 - 1) {
        uint64_t v143 = v142 - 1;
      }
      else {
        uint64_t v143 = v142;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::IsTerminator<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::IsTerminator>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v139[v141], v143);
      uint64_t v23 = (void *)&unk_267771000;
      uint64_t v22 = v144;
      uint64_t v20 = v146;
      uint64_t v18 = v149;
      uint64_t v16 = v153;
      uint64_t v14 = v158;
      uint64_t v12 = v164;
      uint64_t v10 = v171;
      uint64_t v8 = v179;
      uint64_t v6 = v188;
      uint64_t v4 = v198;
      uint64_t v2 = v209;
      a1 = v221;
    }
  }
  return v2 == a1
      || v4 == a1
      || v6 == a1
      || v8 == a1
      || v10 == a1
      || v12 == a1
      || v14 == a1
      || v16 == a1
      || v18 == a1
      || v20 == a1
      || v22 == a1
      || v23[233] == a1;
}

void llvm::detail::UniqueFunctionBase<void,mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef>::CallImpl<mlir::Op<mlir::tensor::YieldOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::HasParent<mlir::tensor::GenerateOp,mlir::tensor::PadOp>::Impl,mlir::OpTrait::OpInvariants,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::RegionBranchTerminatorOpInterface::Trait,mlir::OpTrait::ReturnLike,mlir::OpTrait::IsTerminator>::getPrintAssemblyFn(void)::{lambda(mlir::Operation *,mlir::OpAsmPrinter &,llvm::StringRef)#1} const>(uint64_t a1, mlir::Operation *a2, mlir::OpAsmPrinter *a3, uint64_t a4, uint64_t a5)
{
  mlir::OpState::printOpName((uint64_t)a2, (uint64_t)a3, a4, a5);
  uint64_t v7 = a2;
  mlir::memref::AtomicYieldOp::print(&v7, a3);
}

BOOL mlir::Op<mlir::tensor::YieldOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::HasParent<mlir::tensor::GenerateOp,mlir::tensor::PadOp>::Impl,mlir::OpTrait::OpInvariants,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::RegionBranchTerminatorOpInterface::Trait,mlir::OpTrait::ReturnLike,mlir::OpTrait::IsTerminator>::verifyInvariants(mlir::OpTrait::impl *a1, mlir::Operation *a2)
{
  return mlir::op_definition_impl::verifyTraits<mlir::OpTrait::ZeroRegions<mlir::tensor::YieldOp>,mlir::OpTrait::ZeroResults<mlir::tensor::YieldOp>,mlir::OpTrait::ZeroSuccessors<mlir::tensor::YieldOp>,mlir::OpTrait::OneOperand<mlir::tensor::YieldOp>,mlir::OpTrait::HasParent<mlir::tensor::GenerateOp,mlir::tensor::PadOp>::Impl<mlir::tensor::YieldOp>,mlir::OpTrait::OpInvariants<mlir::tensor::YieldOp>,mlir::ConditionallySpeculatable::Trait<mlir::tensor::YieldOp>,mlir::OpTrait::AlwaysSpeculatableImplTrait<mlir::tensor::YieldOp>,mlir::MemoryEffectOpInterface::Trait<mlir::tensor::YieldOp>,mlir::RegionBranchTerminatorOpInterface::Trait<mlir::tensor::YieldOp>,mlir::OpTrait::ReturnLike<mlir::tensor::YieldOp>,mlir::OpTrait::IsTerminator<mlir::tensor::YieldOp>>(a1, a2);
}

BOOL mlir::op_definition_impl::verifyTraits<mlir::OpTrait::ZeroRegions<mlir::tensor::YieldOp>,mlir::OpTrait::ZeroResults<mlir::tensor::YieldOp>,mlir::OpTrait::ZeroSuccessors<mlir::tensor::YieldOp>,mlir::OpTrait::OneOperand<mlir::tensor::YieldOp>,mlir::OpTrait::HasParent<mlir::tensor::GenerateOp,mlir::tensor::PadOp>::Impl<mlir::tensor::YieldOp>,mlir::OpTrait::OpInvariants<mlir::tensor::YieldOp>,mlir::ConditionallySpeculatable::Trait<mlir::tensor::YieldOp>,mlir::OpTrait::AlwaysSpeculatableImplTrait<mlir::tensor::YieldOp>,mlir::MemoryEffectOpInterface::Trait<mlir::tensor::YieldOp>,mlir::RegionBranchTerminatorOpInterface::Trait<mlir::tensor::YieldOp>,mlir::OpTrait::ReturnLike<mlir::tensor::YieldOp>,mlir::OpTrait::IsTerminator<mlir::tensor::YieldOp>>(mlir::OpTrait::impl *a1, mlir::Operation *a2)
{
  return mlir::OpTrait::impl::verifyZeroRegions(a1, a2)
      && mlir::OpTrait::impl::verifyZeroResults(a1, v3)
      && mlir::OpTrait::impl::verifyZeroSuccessors(a1, v4)
      && mlir::OpTrait::impl::verifyOneOperand(a1, v5)
      && mlir::OpTrait::HasParent<mlir::tensor::GenerateOp,mlir::tensor::PadOp>::Impl<mlir::tensor::YieldOp>::verifyTrait((uint64_t)a1)
      && ZinIrConstData_specialization<half>::prepare()
      && mlir::OpTrait::impl::verifyIsTerminator(a1, v6) != 0;
}

uint64_t mlir::OpTrait::HasParent<mlir::tensor::GenerateOp,mlir::tensor::PadOp>::Impl<mlir::tensor::YieldOp>::verifyTrait(uint64_t a1)
{
  uint64_t v50 = *MEMORY[0x263EF8340];
  uint64_t v2 = *(mlir::Block **)(a1 + 16);
  if (v2)
  {
    uint64_t ParentOp = mlir::Block::getParentOp(v2);
    if (ParentOp)
    {
      uint64_t v4 = *(void **)(*(void *)(ParentOp + 48) + 16);
      if (v4 == &mlir::detail::TypeIDResolver<mlir::tensor::GenerateOp,void>::id
        || v4 == &mlir::detail::TypeIDResolver<mlir::tensor::PadOp,void>::id)
      {
        return 1;
      }
    }
  }
  __int16 v35 = 257;
  mlir::Operation::emitOpError(a1, &v34, (uint64_t)v40);
  if (v40[0])
  {
    LODWORD(v37) = 3;
    *((void *)&v37 + 1) = "expects parent op ";
    *(void *)&long long v38 = 18;
    uint64_t v7 = &v37;
    uint64_t v8 = (char *)v41;
    if (v42 >= v43)
    {
      unint64_t v28 = v42 + 1;
      if (v41 <= &v37 && (char *)v41 + 24 * v42 > (char *)&v37)
      {
        int64_t v31 = (char *)&v37 - (unsigned char *)v41;
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v41, v44, v28, 24);
        uint64_t v8 = (char *)v41;
        uint64_t v7 = (long long *)((char *)v41 + v31);
      }
      else
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v41, v44, v28, 24);
        uint64_t v7 = &v37;
        uint64_t v8 = (char *)v41;
      }
    }
    uint64_t v9 = &v8[24 * v42];
    long long v10 = *v7;
    *((void *)v9 + 2) = *((void *)v7 + 2);
    *(_OWORD *)uint64_t v9 = v10;
    ++v42;
  }
  char v33 = "to be one of '";
  uint64_t v11 = (void *)mlir::InFlightDiagnostic::append<char const*&>((uint64_t)v40, &v33);
  uint64_t v12 = (uint64_t)v11;
  long long v37 = xmmword_26418D150;
  long long v38 = *(_OWORD *)&off_26418D160;
  if (*v11)
  {
    v36[0] = ", ";
    llvm::interleave<llvm::StringLiteral const*,mlir::Diagnostic& mlir::Diagnostic::appendRange<llvm::ArrayRef<llvm::StringLiteral>>(llvm::ArrayRef<llvm::StringLiteral> const&,char const*)::{lambda(llvm::ArrayRef<llvm::StringLiteral> const&)#1},mlir::Diagnostic& mlir::Diagnostic::appendRange<llvm::ArrayRef<llvm::StringLiteral>>(llvm::ArrayRef<llvm::StringLiteral> const&,char const*)::{lambda(void)#1},void>((uint64_t)&v37, (uint64_t)&v39, (uint64_t)(v11 + 1), (uint64_t)(v11 + 1), v36);
    if (*(void *)v12)
    {
      uint64_t v13 = v12 + 24;
      unint64_t v14 = *(void *)(v12 + 24);
      LODWORD(v36[0]) = 3;
      v36[1] = "'";
      v36[2] = (const char *)1;
      uint64_t v15 = *(unsigned int *)(v12 + 32);
      uint64_t v16 = v36;
      if (v15 >= *(_DWORD *)(v12 + 36))
      {
        unint64_t v29 = v15 + 1;
        BOOL v30 = v14 + 24 * v15 > (unint64_t)v36;
        if (v14 <= (unint64_t)v36 && v30)
        {
          unint64_t v32 = (char *)v36 - v14;
          llvm::SmallVectorBase<unsigned int>::grow_pod(v13, (void *)(v12 + 40), v29, 24);
          unint64_t v14 = *(void *)(v12 + 24);
          uint64_t v16 = (const char **)&v32[v14];
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod(v13, (void *)(v12 + 40), v29, 24);
          unint64_t v14 = *(void *)(v12 + 24);
          uint64_t v16 = v36;
        }
      }
      uint64_t v17 = v14 + 24 * *(unsigned int *)(v12 + 32);
      long long v18 = *(_OWORD *)v16;
      *(void *)(v17 + 16) = v16[2];
      *(_OWORD *)uint64_t v17 = v18;
      ++*(_DWORD *)(v12 + 32);
    }
  }
  uint64_t v6 = mlir::InFlightDiagnostic::operator mlir::LogicalResult(v12);
  if (v40[0]) {
    mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v40);
  }
  if (v49)
  {
    unint64_t v19 = __p;
    if (__p)
    {
      uint64_t v20 = v48;
      int v21 = __p;
      if (v48 != __p)
      {
        do
          uint64_t v20 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v20 - 1);
        while (v20 != v19);
        int v21 = __p;
      }
      unint64_t v48 = v19;
      operator delete(v21);
    }
    uint64_t v22 = v45;
    if (v45)
    {
      uint64_t v23 = v46;
      uint64_t v24 = v45;
      if (v46 != v45)
      {
        do
        {
          uint64_t v26 = *--v23;
          uint64_t v25 = v26;
          void *v23 = 0;
          if (v26) {
            MEMORY[0x21667D390](v25, 0x1000C8077774924);
          }
        }
        while (v23 != v22);
        uint64_t v24 = v45;
      }
      int v46 = v22;
      operator delete(v24);
    }
    if (v41 != v44) {
      free(v41);
    }
  }
  return v6;
}

uint64_t mlir::Op<mlir::tensor::YieldOp,mlir::OpTrait::ZeroRegions,mlir::OpTrait::ZeroResults,mlir::OpTrait::ZeroSuccessors,mlir::OpTrait::OneOperand,mlir::OpTrait::HasParent<mlir::tensor::GenerateOp,mlir::tensor::PadOp>::Impl,mlir::OpTrait::OpInvariants,mlir::ConditionallySpeculatable::Trait,mlir::OpTrait::AlwaysSpeculatableImplTrait,mlir::MemoryEffectOpInterface::Trait,mlir::RegionBranchTerminatorOpInterface::Trait,mlir::OpTrait::ReturnLike,mlir::OpTrait::IsTerminator>::verifyRegionInvariants()
{
  return 1;
}

void anonymous namespace'::TensorInlinerInterface::~TensorInlinerInterface(_anonymous_namespace_::TensorInlinerInterface *this)
{
  ZinIrHalH13g::~ZinIrHalH13g(this);

  JUMPOUT(0x21667D3C0);
}

uint64_t anonymous namespace'::TensorInlinerInterface::isLegalToInline()
{
  return 1;
}

{
  return 1;
}

ZinIrHalH13g *mlir::tensor::TensorDialect::materializeConstant(uint64_t a1, mlir::OpBuilder *a2, void *a3, uint64_t a4, uint64_t a5)
{
  uint64_t v11 = a4;
  __n128 result = mlir::arith::ConstantOp::materialize(a2, a3, a4, a5);
  if (!result)
  {
    if (mlir::complex::ConstantOp::isBuildableWith((uint64_t)a3, a4))
    {
      long long v10 = a3;
      return mlir::OpBuilder::create<mlir::complex::ConstantOp,mlir::Type &,mlir::ArrayAttr>(a2, a5, &v11, (uint64_t *)&v10);
    }
    else
    {
      return 0;
    }
  }
  return result;
}

unint64_t mlir::tensor::getMixedSize(mlir::IndexType **a1, uint64_t a2, uint64_t a3, mlir::MLIRContext *a4)
{
  unsigned int v4 = a4;
  v19[1] = *MEMORY[0x263EF8340];
  uint64_t v13 = a4;
  uint64_t v14 = a3;
  unint64_t v12 = *(void *)(a3 + 8) & 0xFFFFFFFFFFFFFFF8;
  uint64_t v15 = v17;
  uint64_t v16 = 0x600000000;
  if (*(void *)(mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v12) + 8 * a4) != 0x8000000000000000)
  {
    uint64_t Value = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v12);
    unint64_t v8 = mlir::Builder::getIndexAttr(a1, *(mlir::MLIRContext **)(Value + 8 * v4)) & 0xFFFFFFFFFFFFFFFBLL;
    uint64_t v9 = v15;
    if (v15 == v17) {
      return v8;
    }
LABEL_7:
    free(v9);
    return v8;
  }
  v18[0] = v19;
  v18[1] = (void *)0x100000000;
  mlir::OpBuilder::createOrFold<mlir::tensor::DimOp,mlir::Value &,long long &>((uint64_t)a1, (uint64_t)v18, a2, &v14, &v13);
  uint64_t v7 = *(void *)v18[0];
  if (v18[0] != v19) {
    free(v18[0]);
  }
  unint64_t v8 = v7 | 4;
  uint64_t v9 = v15;
  if (v15 != v17) {
    goto LABEL_7;
  }
  return v8;
}

ZinIrHalH13g *mlir::OpBuilder::create<mlir::tensor::EmptyOp,llvm::SmallVector<mlir::OpFoldResult,6u> &,mlir::Type>(mlir::OpBuilder *a1, uint64_t a2, uint64_t a3, uint64_t *a4)
{
  v20[38] = *MEMORY[0x263EF8340];
  uint64_t v15 = a2;
  uint64_t Context = (uint64_t *)mlir::Attribute::getContext((mlir::Attribute *)&v15);
  uint64_t v9 = mlir::RegisteredOperationName::lookup((int8x16_t *)"tensor.empty", (const unsigned __int8 *)0xC, Context);
  if (!v10)
  {
    __int16 v19 = 1283;
    v18[2] = (uint64_t)"tensor.empty";
    v18[3] = 12;
          " the dialect. See also https://mlir.llvm.org/getting_started/Faq/#registered-loaded-dependent-whats-up-with-di"
          "alects-management";
    __int16 v17 = 259;
    llvm::operator+(v18, (uint64_t *)&v16, (uint64_t)v20);
    llvm::report_fatal_error((llvm::Twine *)v20, 1);
  }
  mlir::OperationState::OperationState(v20, a2, v9);
  mlir::tensor::EmptyOp::build(v11, (uint64_t)v20, *(uint64_t **)a3, *(unsigned int *)(a3 + 8), *a4, 0);
  unint64_t v12 = mlir::OpBuilder::create(a1, (const mlir::OperationState *)v20);
  if (*(_UNKNOWN **)(*((void *)v12 + 6) + 16) == &mlir::detail::TypeIDResolver<mlir::tensor::EmptyOp,void>::id) {
    uint64_t v13 = v12;
  }
  else {
    uint64_t v13 = 0;
  }
  mlir::OperationState::~OperationState((mlir::OperationState *)v20);
  return v13;
}

BOOL mlir::tensor::isSameTypeWithoutEncoding(uint64_t a1, uint64_t a2)
{
  if (*(_UNKNOWN **)(*(void *)a1 + 136) == &mlir::detail::TypeIDResolver<mlir::RankedTensorType,void>::id) {
    uint64_t v2 = a1;
  }
  else {
    uint64_t v2 = 0;
  }
  uint64_t v12 = v2;
  if (!v2) {
    return a1 == a2;
  }
  if (*(_UNKNOWN **)(*(void *)a2 + 136) == &mlir::detail::TypeIDResolver<mlir::RankedTensorType,void>::id) {
    uint64_t v3 = a2;
  }
  else {
    uint64_t v3 = 0;
  }
  uint64_t v11 = v3;
  if (!v3) {
    return 0;
  }
  uint64_t Value = (const void *)mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v12);
  uint64_t v6 = v5;
  uint64_t v7 = (const void *)mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v11);
  if (v6 != v8 || memcmp(Value, v7, 8 * v6)) {
    return 0;
  }
  uint64_t RHS = mlir::AffineBinaryOpExpr::getRHS((mlir::AffineBinaryOpExpr *)&v12);
  return RHS == mlir::AffineBinaryOpExpr::getRHS((mlir::AffineBinaryOpExpr *)&v11);
}

BOOL mlir::tensor::BitcastOp::areCastCompatible(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  BOOL result = 0;
  if (a2 == 1 && a4 == 1)
  {
    v21[3] = v4;
    v21[4] = v5;
    unint64_t v9 = mlir::TypeRange::dereference_iterator(a1, 0);
    unint64_t v10 = mlir::TypeRange::dereference_iterator(a3, 0);
    uint64_t v11 = *(void **)(*(void *)v9 + 136);
    if (v11 == &mlir::detail::TypeIDResolver<mlir::UnrankedTensorType,void>::id
      || v11 == &mlir::detail::TypeIDResolver<mlir::RankedTensorType,void>::id)
    {
      uint64_t v13 = (void *)v9;
    }
    else
    {
      uint64_t v13 = 0;
    }
    uint64_t v20 = v13;
    uint64_t v14 = *(void **)(*(void *)v10 + 136);
    if (v14 == &mlir::detail::TypeIDResolver<mlir::UnrankedTensorType,void>::id
      || v14 == &mlir::detail::TypeIDResolver<mlir::RankedTensorType,void>::id)
    {
      uint64_t v16 = (void *)v10;
    }
    else
    {
      uint64_t v16 = 0;
    }
    __int16 v19 = v16;
    if (v13) {
      BOOL v17 = v16 == 0;
    }
    else {
      BOOL v17 = 1;
    }
    if (v17) {
      return 0;
    }
    v21[0] = mlir::TensorType::getElementType((mlir::TensorType *)&v20);
    int IntOrFloatBitWidth = mlir::Type::getIntOrFloatBitWidth((mlir::Type *)v21);
    v21[0] = mlir::TensorType::getElementType((mlir::TensorType *)&v19);
    return IntOrFloatBitWidth == mlir::Type::getIntOrFloatBitWidth((mlir::Type *)v21)
        && mlir::verifyCompatibleShape(v20, v19);
  }
  return result;
}

void mlir::tensor::BitcastOp::getCanonicalizationPatterns()
{
}

uint64_t mlir::tensor::preservesStaticInformation(uint64_t a1, uint64_t a2)
{
  if (*(_UNKNOWN **)(*(void *)a1 + 136) == &mlir::detail::TypeIDResolver<mlir::RankedTensorType,void>::id) {
    uint64_t v2 = a1;
  }
  else {
    uint64_t v2 = 0;
  }
  uint64_t v20 = v2;
  if (*(_UNKNOWN **)(*(void *)a2 + 136) == &mlir::detail::TypeIDResolver<mlir::RankedTensorType,void>::id) {
    uint64_t v3 = a2;
  }
  else {
    uint64_t v3 = 0;
  }
  uint64_t v19 = v3;
  if (v2) {
    BOOL v4 = v3 == 0;
  }
  else {
    BOOL v4 = 1;
  }
  if (v4) {
    return 0;
  }
  uint64_t RHS = mlir::AffineBinaryOpExpr::getRHS((mlir::AffineBinaryOpExpr *)&v20);
  if (RHS == mlir::AffineBinaryOpExpr::getRHS((mlir::AffineBinaryOpExpr *)&v19))
  {
    mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v20);
    uint64_t v9 = v8;
    mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v19);
    if (v9 == v10)
    {
      uint64_t Value = (void *)mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v20);
      uint64_t v13 = v12;
      uint64_t v14 = (void *)mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v19);
      uint64_t v5 = 1;
      if (v13 && v15)
      {
        uint64_t v16 = 8 * v15 - 8;
        uint64_t v17 = 8 * v13 - 8;
        while (*Value == 0x8000000000000000 || *v14 != 0x8000000000000000)
        {
          uint64_t v5 = 1;
          if (v17)
          {
            ++Value;
            ++v14;
            uint64_t v18 = v16;
            v16 -= 8;
            v17 -= 8;
            if (v18) {
              continue;
            }
          }
          return v5;
        }
        return 0;
      }
      return v5;
    }
  }
  return 0;
}

uint64_t mlir::tensor::foldTensorCast(mlir::tensor *this, mlir::Operation *a2)
{
  if ((*((unsigned char *)this + 46) & 0x80) != 0 && (uint64_t v2 = *((unsigned int *)this + 17), v2))
  {
    char v3 = 0;
    BOOL v4 = (uint64_t *)*((void *)this + 9);
    uint64_t v5 = 32 * v2;
    do
    {
      uint64_t v12 = v4[3];
      uint64_t DefiningOp = mlir::Value::getDefiningOp((mlir::Value *)&v12);
      if (DefiningOp)
      {
        uint64_t v7 = DefiningOp;
        if (*(_UNKNOWN **)(*(void *)(DefiningOp + 48) + 16) == &mlir::detail::TypeIDResolver<mlir::tensor::CastOp,void>::id)
        {
          if (mlir::tensor::preservesStaticInformation(*(void *)(DefiningOp - 8) & 0xFFFFFFFFFFFFFFF8, *(void *)(*(void *)(*(void *)(DefiningOp + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8))
          {
            uint64_t v8 = *(uint64_t **)(*(void *)(v7 + 72) + 24);
            uint64_t v9 = (uint64_t *)v4[1];
            if (v9)
            {
              *uint64_t v9 = *v4;
              if (*v4) {
                *(void *)(*v4 + 8) = v4[1];
              }
            }
            v4[3] = (uint64_t)v8;
            uint64_t v10 = *v8;
            *BOOL v4 = *v8;
            v4[1] = (uint64_t)v8;
            if (v10) {
              *(void *)(v10 + 8) = v4;
            }
            *uint64_t v8 = (uint64_t)v4;
            char v3 = 1;
          }
        }
      }
      v4 += 4;
      v5 -= 32;
    }
    while (v5);
  }
  else
  {
    char v3 = 0;
  }
  return v3 & 1;
}

BOOL mlir::tensor::CastOp::areCastCompatible(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  BOOL result = 0;
  if (a2 == 1 && a4 == 1)
  {
    v20[3] = v4;
    v20[4] = v5;
    unint64_t v9 = mlir::TypeRange::dereference_iterator(a1, 0);
    unint64_t v10 = mlir::TypeRange::dereference_iterator(a3, 0);
    uint64_t v11 = *(void **)(*(void *)v9 + 136);
    if (v11 == &mlir::detail::TypeIDResolver<mlir::UnrankedTensorType,void>::id
      || v11 == &mlir::detail::TypeIDResolver<mlir::RankedTensorType,void>::id)
    {
      uint64_t v13 = (void *)v9;
    }
    else
    {
      uint64_t v13 = 0;
    }
    v20[0] = v13;
    uint64_t v14 = *(void **)(*(void *)v10 + 136);
    if (v14 == &mlir::detail::TypeIDResolver<mlir::UnrankedTensorType,void>::id
      || v14 == &mlir::detail::TypeIDResolver<mlir::RankedTensorType,void>::id)
    {
      uint64_t v16 = (void *)v10;
    }
    else
    {
      uint64_t v16 = 0;
    }
    uint64_t v19 = v16;
    if (v13) {
      BOOL v17 = v16 == 0;
    }
    else {
      BOOL v17 = 1;
    }
    if (!v17
      && (uint64_t ElementType = mlir::TensorType::getElementType((mlir::TensorType *)v20),
          ElementType == mlir::TensorType::getElementType((mlir::TensorType *)&v19)))
    {
      return mlir::verifyCompatibleShape(v20[0], v19);
    }
    else
    {
      return 0;
    }
  }
  return result;
}

void mlir::tensor::CastOp::getCanonicalizationPatterns()
{
}

void mlir::tensor::DimOp::build(mlir::IndexType **a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  v22[2] = *MEMORY[0x263EF8340];
  uint64_t v15 = a4;
  uint64_t v16 = a3;
  mlir::OperationState::addOperands(a2, (uint64_t)&v16, 1);
  mlir::OperationState::addOperands(a2, (uint64_t)&v15, 1);
  __src = v22;
  uint64_t v21 = 0x200000000;
  uint64_t v6 = *a1;
  mlir::ValueRange::ValueRange(&v19, *(void *)(a2 + 16), *(unsigned int *)(a2 + 24));
  uint64_t Context = (mlir::MLIRContext *)mlir::Attribute::getContext((mlir::Attribute *)a2);
  mlir::NamedAttrList::getDictionary((mlir::NamedAttrList *)(a2 + 112), Context);
  mlir::ValueRange::ValueRange(&v18, *(void *)(a2 + 224), *(unsigned int *)(a2 + 232));
  if (v21 != 1)
  {
    if (!v21)
    {
      if (HIDWORD(v21))
      {
        unsigned int v9 = 0;
LABEL_6:
        bzero((char *)__src + 8 * v9, 8 - 8 * v9);
        goto LABEL_7;
      }
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&__src, v22, 1uLL, 8);
      unsigned int v9 = v21;
      if (v21 != 1) {
        goto LABEL_6;
      }
    }
LABEL_7:
    LODWORD(v21) = 1;
  }
  BOOL v17 = v6;
  uint64_t IndexType = mlir::Builder::getIndexType(&v17, v8);
  *(void *)__src = IndexType;
  uint64_t v11 = __src;
  uint64_t v12 = v21;
  uint64_t v13 = *(unsigned int *)(a2 + 72);
  unint64_t v14 = v13 + v21;
  if (v14 > *(unsigned int *)(a2 + 76))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod(a2 + 64, (void *)(a2 + 80), v14, 8);
    LODWORD(v13) = *(_DWORD *)(a2 + 72);
  }
  if (v12)
  {
    memcpy((void *)(*(void *)(a2 + 64) + 8 * v13), v11, 8 * v12);
    LODWORD(v13) = *(_DWORD *)(a2 + 72);
  }
  *(_DWORD *)(a2 + 72) = v13 + v12;
  if (__src != v22) {
    free(__src);
  }
}

BOOL mlir::tensor::DimOp::getSpeculatability(mlir::tensor::DimOp *this)
{
  mlir::getConstantIntValue(*(void *)(*(void *)(*(void *)this + 72) + 56) | 4);
  if (!v2) {
    return 0;
  }
  if (*(_UNKNOWN **)(*(void *)(*(void *)(*(void *)(*(void *)(*(void *)this + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8)
                    + 136) == &mlir::detail::TypeIDResolver<mlir::RankedTensorType,void>::id)
    return (*(void *)(*(void *)(*(void *)(*(void *)this + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8) != 0;
  return 0;
}

unint64_t mlir::tensor::DimOp::fold(mlir::tensor **a1, uint64_t a2)
{
  uint64_t v2 = *(void *)(*(void *)(a2 + 40) + 8);
  if (!v2) {
    return 0;
  }
  if (*(_UNKNOWN **)(*(void *)v2 + 136) != &mlir::detail::TypeIDResolver<mlir::IntegerAttr,void>::id) {
    uint64_t v2 = 0;
  }
  uint64_t v47 = v2;
  if (!v2) {
    return 0;
  }
  unint64_t v4 = *(void *)(*(void *)(*((void *)*a1 + 9) + 24) + 8) & 0xFFFFFFFFFFFFFFF8;
  if (*(_UNKNOWN **)(*(void *)v4 + 136) != &mlir::detail::TypeIDResolver<mlir::RankedTensorType,void>::id) {
    unint64_t v4 = 0;
  }
  unint64_t v46 = v4;
  if (!v4) {
    return 0;
  }
  uint64_t Int = mlir::IntegerAttr::getInt((mlir::IntegerAttr *)&v47);
  if (Int < 0) {
    return 0;
  }
  uint64_t v6 = Int;
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v46);
  if (v6 >= v7) {
    return 0;
  }
  unsigned int v8 = mlir::IntegerAttr::getInt((mlir::IntegerAttr *)&v47);
  if (*(void *)(mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v46) + 8 * v8) != 0x8000000000000000)
  {
    uint64_t Context = (mlir::IndexType *)mlir::Attribute::getContext((mlir::tensor *)((char *)*a1 + 24));
    uint64_t Value = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v46);
    uint64_t v14 = mlir::IntegerAttr::getInt((mlir::IntegerAttr *)&v47);
    return mlir::Builder::getIndexAttr(&Context, *(mlir::MLIRContext **)(Value + 8 * v14)) & 0xFFFFFFFFFFFFFFFBLL;
  }
  uint64_t Context = *(mlir::IndexType **)(*((void *)*a1 + 9) + 24);
  uint64_t DefiningOp = mlir::Value::getDefiningOp((mlir::Value *)&Context);
  uint64_t v10 = DefiningOp;
  if (DefiningOp
    && *(_UNKNOWN **)(*(void *)(DefiningOp + 48) + 16) == &mlir::detail::TypeIDResolver<mlir::tensor::GenerateOp,void>::id)
  {
    if (*(_DWORD *)(DefiningOp + 36)) {
      uint64_t v23 = DefiningOp - 16;
    }
    else {
      uint64_t v23 = 0;
    }
    uint64_t Context = (mlir::IndexType *)(*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v23, 0) + 8) & 0xFFFFFFFFFFFFFFF8);
    if ((*(unsigned char *)(v10 + 46) & 0x80) != 0) {
      uint64_t v24 = *(void *)(v10 + 72);
    }
    else {
      uint64_t v24 = 0;
    }
    uint64_t v25 = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&Context);
    unint64_t v27 = v26;
    unint64_t v28 = mlir::IntegerAttr::getInt((mlir::IntegerAttr *)&v47);
    if (v27 >= v28) {
      unint64_t v29 = v28;
    }
    else {
      unint64_t v29 = v27;
    }
    if (v29)
    {
      unint64_t v30 = (v29 - 1) & 0x1FFFFFFFFFFFFFFFLL;
      if (v30 < 3)
      {
        uint64_t v31 = 0;
        unint64_t v32 = (uint64_t *)v25;
        goto LABEL_50;
      }
      unint64_t v33 = v30 + 1;
      uint64_t v34 = (v30 + 1) & 0x3FFFFFFFFFFFFFFCLL;
      unint64_t v32 = (uint64_t *)(v25 + 8 * v34);
      __int16 v35 = (int64x2_t *)(v25 + 16);
      int64x2_t v36 = 0uLL;
      int64x2_t v37 = vdupq_n_s64(0x8000000000000000);
      uint64_t v38 = v34;
      int64x2_t v39 = 0uLL;
      do
      {
        int64x2_t v36 = vsubq_s64(v36, vceqq_s64(v35[-1], v37));
        int64x2_t v39 = vsubq_s64(v39, vceqq_s64(*v35, v37));
        v35 += 2;
        v38 -= 4;
      }
      while (v38);
      uint64_t v31 = vaddvq_s64(vaddq_s64(v39, v36));
      if (v33 != v34)
      {
LABEL_50:
        int v40 = (uint64_t *)(v25 + 8 * v29);
        do
        {
          uint64_t v41 = *v32++;
          if (v41 == 0x8000000000000000) {
            ++v31;
          }
        }
        while (v32 != v40);
      }
    }
    else
    {
      uint64_t v31 = 0;
    }
    return *(void *)(v24 + 32 * v31 + 24) | 4;
  }
  mlir::IntegerAttr::getValue((uint64_t)&v47, (llvm::APInt *)&Context);
  if (v45 > 0x40)
  {
    uint64_t v12 = *(void *)Context;
    MEMORY[0x21667D390]();
  }
  else
  {
    LODWORD(v12) = Context;
  }
  if (v10)
  {
    uint64_t v16 = *(void **)(*(void *)(v10 + 48) + 16);
    BOOL v17 = v16 == &mlir::detail::TypeIDResolver<mlir::tensor::ExtractSliceOp,void>::id;
    unint64_t v18 = v16 == &mlir::detail::TypeIDResolver<mlir::tensor::ExtractSliceOp,void>::id ? (mlir::IndexType *)v10 : 0;
    uint64_t Context = v18;
    if (v17)
    {
      uint64_t v19 = *(_DWORD *)(v10 + 36) ? v10 - 16 : 0;
      unint64_t v43 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v19, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
      mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v43);
      uint64_t v21 = v20;
      unint64_t v42 = *(void *)(*(void *)(*((void *)Context + 9) + 24) + 8) & 0xFFFFFFFFFFFFFFF8;
      mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v42);
      if (v21 == v11
        && mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::tensor::ExtractSliceOp>::isDynamicSize((uint64_t)&Context, v12))
      {
        return mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::memref::SubViewOp>::getDynamicSize((uint64_t)&Context, v12) | 4;
      }
    }
  }
  if (!mlir::tensor::foldTensorCast(*a1, v11)) {
    return 0;
  }
  if (*((_DWORD *)*a1 + 9)) {
    uint64_t v22 = (uint64_t)*a1 - 16;
  }
  else {
    uint64_t v22 = 0;
  }
  return mlir::detail::OpResultImpl::getNextResultAtOffset(v22, 0) | 4;
}

BOOL mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::tensor::ExtractSliceOp>::isDynamicSize(uint64_t a1, unsigned int a2)
{
  unint64_t v2 = *(void *)a1 + 16 * (((unint64_t)*(unsigned int *)(*(void *)a1 + 44) >> 23) & 1) + 64;
  if (!HIBYTE(*(_DWORD *)(*(void *)a1 + 44))) {
    unint64_t v2 = 0;
  }
  uint64_t v4 = *(void *)(v2 + 8);
  return *(void *)(mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)&v4)
                   + 8 * a2) == 0x8000000000000000;
}

void mlir::tensor::DimOp::getCanonicalizationPatterns()
{
}

void mlir::tensor::EmptyOp::build(uint64_t a1, uint64_t a2, uint64_t *a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  v21[6] = *MEMORY[0x263EF8340];
  uint64_t v19 = v21;
  uint64_t v20 = 0x600000000;
  uint64_t v16 = v18;
  uint64_t v17 = 0x600000000;
  mlir::dispatchIndexOpFoldResults(a3, a4, (uint64_t)&v16, (uint64_t)&v19);
  unsigned int v9 = v19;
  uint64_t v10 = v20;
  mlir::ValueRange::ValueRange(v15, (uint64_t)v16, v17);
  uint64_t v11 = v15[0];
  uint64_t v12 = v15[1];
  uint64_t v13 = mlir::RankedTensorType::get((uint64_t)v9, v10, a5, a6);
  mlir::OperationState::addOperands(a2, v11, v12);
  uint64_t v14 = *(unsigned int *)(a2 + 72);
  if (v14 >= *(_DWORD *)(a2 + 76))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod(a2 + 64, (void *)(a2 + 80), v14 + 1, 8);
    LODWORD(v14) = *(_DWORD *)(a2 + 72);
  }
  *(void *)(*(void *)(a2 + 64) + 8 * v14) = v13;
  ++*(_DWORD *)(a2 + 72);
  if (v16 != v18) {
    free(v16);
  }
  if (v19 != v21) {
    free(v19);
  }
}

uint64_t mlir::tensor::EmptyOp::verify(mlir::tensor::EmptyOp *this)
{
  uint64_t v77 = *MEMORY[0x263EF8340];
  if (*(_DWORD *)(*(void *)this + 36)) {
    uint64_t v2 = *(void *)this - 16;
  }
  else {
    uint64_t v2 = 0;
  }
  v67[0] = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v2, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
  uint64_t Value = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)v67);
  if (!v4)
  {
    uint64_t v6 = 0;
    goto LABEL_14;
  }
  unint64_t v5 = (v4 - 1) & 0x1FFFFFFFFFFFFFFFLL;
  if (v5 >= 3)
  {
    unint64_t v8 = v5 + 1;
    uint64_t v9 = (v5 + 1) & 0x3FFFFFFFFFFFFFFCLL;
    uint64_t v7 = (uint64_t *)(Value + 8 * v9);
    uint64_t v10 = (int64x2_t *)(Value + 16);
    int64x2_t v11 = 0uLL;
    int64x2_t v12 = vdupq_n_s64(0x8000000000000000);
    uint64_t v13 = v9;
    int64x2_t v14 = 0uLL;
    do
    {
      int64x2_t v11 = vsubq_s64(v11, vceqq_s64(v10[-1], v12));
      int64x2_t v14 = vsubq_s64(v14, vceqq_s64(*v10, v12));
      v10 += 2;
      v13 -= 4;
    }
    while (v13);
    uint64_t v6 = vaddvq_s64(vaddq_s64(v14, v11));
    if (v8 == v9) {
      goto LABEL_14;
    }
  }
  else
  {
    uint64_t v6 = 0;
    uint64_t v7 = (uint64_t *)Value;
  }
  do
  {
    uint64_t v15 = *v7++;
    if (v15 == 0x8000000000000000) {
      ++v6;
    }
  }
  while (v7 != (uint64_t *)(Value + 8 * v4));
LABEL_14:
  if ((*(unsigned char *)(*(void *)this + 46) & 0x80) != 0)
  {
    if (v6 == *(_DWORD *)(*(void *)this + 68)) {
      return 1;
    }
  }
  else if (!v6)
  {
    return 1;
  }
  uint64_t v62 = (void **)"incorrect number of dynamic sizes, has ";
  __int16 v63 = 259;
  mlir::OpState::emitOpError((uint64_t *)this, &v62, (uint64_t)v67);
  if ((*(unsigned char *)(*(void *)this + 46) & 0x80) != 0)
  {
    uint64_t v17 = (const char *)*(unsigned int *)(*(void *)this + 68);
    if (!v67[0]) {
      goto LABEL_24;
    }
  }
  else
  {
    uint64_t v17 = 0;
    if (!v67[0]) {
      goto LABEL_24;
    }
  }
  int v64 = 5;
  unint64_t v65 = v17;
  unint64_t v18 = &v64;
  uint64_t v19 = (char *)v68;
  if (v69 >= v70)
  {
    unint64_t v54 = v69 + 1;
    if (v68 <= &v64 && (char *)v68 + 24 * v69 > (char *)&v64)
    {
      int64_t v58 = (char *)&v64 - (unsigned char *)v68;
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v68, v71, v54, 24);
      uint64_t v19 = (char *)v68;
      unint64_t v18 = (int *)((char *)v68 + v58);
    }
    else
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v68, v71, v54, 24);
      unint64_t v18 = &v64;
      uint64_t v19 = (char *)v68;
    }
  }
  uint64_t v20 = &v19[24 * v69];
  long long v21 = *(_OWORD *)v18;
  *((void *)v20 + 2) = *((void *)v18 + 2);
  *(_OWORD *)uint64_t v20 = v21;
  uint64_t v22 = ++v69;
  if (v67[0])
  {
    int v64 = 3;
    unint64_t v65 = ", expected ";
    uint64_t v66 = 11;
    uint64_t v23 = &v64;
    uint64_t v24 = (char *)v68;
    if (v22 >= v70)
    {
      unint64_t v56 = v22 + 1;
      BOOL v57 = (char *)v68 + 24 * v22 > (char *)&v64;
      if (v68 <= &v64 && v57)
      {
        int64_t v60 = (char *)&v64 - (unsigned char *)v68;
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v68, v71, v56, 24);
        uint64_t v24 = (char *)v68;
        uint64_t v23 = (int *)((char *)v68 + v60);
      }
      else
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v68, v71, v56, 24);
        uint64_t v23 = &v64;
        uint64_t v24 = (char *)v68;
      }
    }
    uint64_t v25 = &v24[24 * v69];
    long long v26 = *(_OWORD *)v23;
    *((void *)v25 + 2) = *((void *)v23 + 2);
    *(_OWORD *)uint64_t v25 = v26;
    ++v69;
  }
LABEL_24:
  if (*(_DWORD *)(*(void *)this + 36)) {
    uint64_t v27 = *(void *)this - 16;
  }
  else {
    uint64_t v27 = 0;
  }
  unint64_t v61 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v27, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
  uint64_t v28 = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v61);
  if (v29)
  {
    unint64_t v30 = (v29 - 1) & 0x1FFFFFFFFFFFFFFFLL;
    if (v30 < 3)
    {
      uint64_t v31 = 0;
      unint64_t v32 = (uint64_t *)v28;
      goto LABEL_34;
    }
    unint64_t v33 = v30 + 1;
    uint64_t v34 = (v30 + 1) & 0x3FFFFFFFFFFFFFFCLL;
    unint64_t v32 = (uint64_t *)(v28 + 8 * v34);
    __int16 v35 = (int64x2_t *)(v28 + 16);
    int64x2_t v36 = 0uLL;
    int64x2_t v37 = vdupq_n_s64(0x8000000000000000);
    uint64_t v38 = v34;
    int64x2_t v39 = 0uLL;
    do
    {
      int64x2_t v36 = vsubq_s64(v36, vceqq_s64(v35[-1], v37));
      int64x2_t v39 = vsubq_s64(v39, vceqq_s64(*v35, v37));
      v35 += 2;
      v38 -= 4;
    }
    while (v38);
    uint64_t v31 = vaddvq_s64(vaddq_s64(v39, v36));
    if (v33 != v34)
    {
      do
      {
LABEL_34:
        uint64_t v40 = *v32++;
        if (v40 == 0x8000000000000000) {
          ++v31;
        }
      }
      while (v32 != (uint64_t *)(v28 + 8 * v29));
    }
  }
  else
  {
    uint64_t v31 = 0;
  }
  if (v67[0])
  {
    int v64 = 2;
    unint64_t v65 = (const char *)v31;
    uint64_t v41 = &v64;
    unint64_t v42 = (char *)v68;
    if (v69 >= v70)
    {
      unint64_t v55 = v69 + 1;
      if (v68 <= &v64 && (char *)v68 + 24 * v69 > (char *)&v64)
      {
        int64_t v59 = (char *)&v64 - (unsigned char *)v68;
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v68, v71, v55, 24);
        unint64_t v42 = (char *)v68;
        uint64_t v41 = (int *)((char *)v68 + v59);
      }
      else
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v68, v71, v55, 24);
        uint64_t v41 = &v64;
        unint64_t v42 = (char *)v68;
      }
    }
    unint64_t v43 = &v42[24 * v69];
    long long v44 = *(_OWORD *)v41;
    *((void *)v43 + 2) = *((void *)v41 + 2);
    *(_OWORD *)unint64_t v43 = v44;
    ++v69;
  }
  uint64_t v16 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v67);
  if (v67[0]) {
    mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v67);
  }
  if (v76)
  {
    unsigned int v45 = __p;
    if (__p)
    {
      unint64_t v46 = v75;
      uint64_t v47 = __p;
      if (v75 != __p)
      {
        do
          unint64_t v46 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v46 - 1);
        while (v46 != v45);
        uint64_t v47 = __p;
      }
      unint64_t v75 = v45;
      operator delete(v47);
    }
    unint64_t v48 = v72;
    if (v72)
    {
      char v49 = v73;
      uint64_t v50 = v72;
      if (v73 != v72)
      {
        do
        {
          uint64_t v52 = *--v49;
          uint64_t v51 = v52;
          *char v49 = 0;
          if (v52) {
            MEMORY[0x21667D390](v51, 0x1000C8077774924);
          }
        }
        while (v49 != v48);
        uint64_t v50 = v72;
      }
      int v73 = v48;
      operator delete(v50);
    }
    if (v68 != v71) {
      free(v68);
    }
  }
  return v16;
}

uint64_t mlir::tensor::EmptyOp::reifyResultShapes(uint64_t a1, mlir::IndexType **a2, uint64_t a3)
{
  v31[6] = *MEMORY[0x263EF8340];
  if (*(_DWORD *)(*(void *)a1 + 36)) {
    uint64_t v6 = *(void *)a1 - 16;
  }
  else {
    uint64_t v6 = 0;
  }
  unint64_t v28 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v6, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v28);
  uint64_t v29 = v31;
  uint64_t v30 = 0x600000000;
  if (v7)
  {
    unint64_t v8 = v7;
    if (v7 < 7)
    {
      uint64_t v9 = 0;
      unint64_t v10 = v7;
    }
    else
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v29, v31, v7, 8);
      uint64_t v9 = v30;
      unint64_t v10 = v8 - v30;
      if (v8 == v30) {
        goto LABEL_10;
      }
    }
    bzero((char *)v29 + 8 * v9, 8 * v10);
LABEL_10:
    LODWORD(v30) = v8;
  }
  uint64_t v11 = *(unsigned int *)(a3 + 8);
  if (!v11)
  {
    llvm::SmallVectorImpl<llvm::SmallVector<mlir::OpFoldResult,6u>>::append(a3, 1 - v11, (unint64_t)&v29);
LABEL_18:
    uint64_t v15 = v29;
    if (v29 == v31) {
      goto LABEL_20;
    }
    goto LABEL_19;
  }
  if (v11 == 1) {
    goto LABEL_18;
  }
  int64x2_t v12 = *(void **)a3;
  uint64_t v13 = v11 << 6;
  do
  {
    int64x2_t v14 = *(char **)((char *)v12 + v13 - 64);
    if ((char *)v12 + v13 - 48 != v14) {
      free(v14);
    }
    v13 -= 64;
  }
  while (v13 != 64);
  *(_DWORD *)(a3 + 8) = 1;
  uint64_t v15 = v29;
  if (v29 != v31) {
LABEL_19:
  }
    free(v15);
LABEL_20:
  if (*(_DWORD *)(*(void *)a1 + 36)) {
    uint64_t v16 = *(void *)a1 - 16;
  }
  else {
    uint64_t v16 = 0;
  }
  uint64_t v29 = (void *)(*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v16, 0) + 8) & 0xFFFFFFFFFFFFFFF8);
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v29);
  if (v17 >= 1)
  {
    unsigned int v18 = 0;
    uint64_t v19 = 0;
    do
    {
      if (*(_DWORD *)(*(void *)a1 + 36)) {
        uint64_t v25 = *(void *)a1 - 16;
      }
      else {
        uint64_t v25 = 0;
      }
      uint64_t v29 = (void *)(*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v25, 0) + 8) & 0xFFFFFFFFFFFFFFF8);
      if (*(void *)(mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v29) + 8 * v19) == 0x8000000000000000)
      {
        uint64_t v26 = v18++;
        unint64_t v22 = *(void *)(*(void *)(*(void *)a1 + 72) + 32 * v26 + 24) | 4;
      }
      else
      {
        if (*(_DWORD *)(*(void *)a1 + 36)) {
          uint64_t v20 = *(void *)a1 - 16;
        }
        else {
          uint64_t v20 = 0;
        }
        uint64_t v29 = (void *)(*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v20, 0) + 8) & 0xFFFFFFFFFFFFFFF8);
        uint64_t Value = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v29);
        unint64_t v22 = mlir::Builder::getIndexAttr(a2, *(mlir::MLIRContext **)(Value + 8 * v19)) & 0xFFFFFFFFFFFFFFFBLL;
      }
      *(void *)(**(void **)a3 + 8 * v19++) = v22;
      if (*(_DWORD *)(*(void *)a1 + 36)) {
        uint64_t v23 = *(void *)a1 - 16;
      }
      else {
        uint64_t v23 = 0;
      }
      uint64_t v29 = (void *)(*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v23, 0) + 8) & 0xFFFFFFFFFFFFFFF8);
      mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v29);
    }
    while (v19 < v24);
  }
  return 1;
}

uint64_t mlir::tensor::EmptyOp::getMixedSizes@<X0>(mlir::tensor::EmptyOp *this@<X0>, uint64_t a2@<X8>)
{
  uint64_t v4 = (void *)(a2 + 16);
  *(void *)a2 = a2 + 16;
  *(void *)(a2 + 8) = 0x600000000;
  v20[0] = (mlir::IndexType *)mlir::Attribute::getContext((mlir::Attribute *)(*(void *)this + 24));
  memset(&v20[1], 0, 24);
  if (*(_DWORD *)(*(void *)this + 36)) {
    uint64_t v5 = *(void *)this - 16;
  }
  else {
    uint64_t v5 = 0;
  }
  unint64_t v19 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v5, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
  uint64_t result = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v19);
  if (v7 >= 1)
  {
    unsigned int v8 = 0;
    uint64_t v9 = 0;
    do
    {
      if (*(_DWORD *)(*(void *)this + 36)) {
        uint64_t v17 = *(void *)this - 16;
      }
      else {
        uint64_t v17 = 0;
      }
      unint64_t v19 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v17, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
      if (*(void *)(mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v19) + 8 * v9) == 0x8000000000000000)
      {
        uint64_t v18 = *(void *)(*(void *)(*(void *)this + 72) + 32 * v8 + 24);
        unint64_t v13 = *(unsigned int *)(a2 + 8);
        if (v13 >= *(unsigned int *)(a2 + 12))
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod(a2, v4, v13 + 1, 8);
          unint64_t v13 = *(unsigned int *)(a2 + 8);
        }
        ++v8;
        unint64_t v14 = v18 | 4;
      }
      else
      {
        if (*(_DWORD *)(*(void *)this + 36)) {
          uint64_t v10 = *(void *)this - 16;
        }
        else {
          uint64_t v10 = 0;
        }
        unint64_t v19 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v10, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
        uint64_t Value = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v19);
        uint64_t IndexAttr = mlir::Builder::getIndexAttr(v20, *(mlir::MLIRContext **)(Value + 8 * v9));
        unint64_t v13 = *(unsigned int *)(a2 + 8);
        if (v13 >= *(unsigned int *)(a2 + 12))
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod(a2, v4, v13 + 1, 8);
          unint64_t v13 = *(unsigned int *)(a2 + 8);
        }
        unint64_t v14 = IndexAttr & 0xFFFFFFFFFFFFFFFBLL;
      }
      *(void *)(*(void *)a2 + 8 * v13) = v14;
      ++*(_DWORD *)(a2 + 8);
      ++v9;
      if (*(_DWORD *)(*(void *)this + 36)) {
        uint64_t v15 = *(void *)this - 16;
      }
      else {
        uint64_t v15 = 0;
      }
      unint64_t v19 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v15, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
      uint64_t result = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v19);
    }
    while (v9 < v16);
  }
  return result;
}

void mlir::tensor::EmptyOp::getCanonicalizationPatterns()
{
}

uint64_t mlir::tensor::ExtractOp::getAsmResultNames(uint64_t a1, uint64_t (*a2)(uint64_t, uint64_t, const char *, uint64_t), uint64_t a3)
{
  if (*(_DWORD *)(*(void *)a1 + 36)) {
    uint64_t v4 = *(void *)a1 - 16;
  }
  else {
    uint64_t v4 = 0;
  }
  uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v4, 0);

  return a2(a3, NextResultAtOffset, "extracted", 9);
}

uint64_t mlir::tensor::ExtractOp::verify(mlir::tensor::ExtractOp *this)
{
  uint64_t v24 = *MEMORY[0x263EF8340];
  unint64_t v15 = *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8;
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v15);
  if ((*(unsigned char *)(*(void *)this + 46) & 0x80) != 0)
  {
    if (v2 == *(unsigned int *)(*(void *)this + 68) - 1) {
      return 1;
    }
  }
  else if (v2 == -1)
  {
    return 1;
  }
  unint64_t v13 = (void **)"incorrect number of indices for extract_element";
  __int16 v14 = 259;
  mlir::OpState::emitOpError((uint64_t *)this, &v13, (uint64_t)v16);
  uint64_t v3 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v16);
  if (v16[0]) {
    mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v16);
  }
  if (v23)
  {
    uint64_t v4 = __p;
    if (__p)
    {
      uint64_t v5 = v22;
      uint64_t v6 = __p;
      if (v22 != __p)
      {
        do
          uint64_t v5 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v5 - 1);
        while (v5 != v4);
        uint64_t v6 = __p;
      }
      unint64_t v22 = v4;
      operator delete(v6);
    }
    uint64_t v7 = v19;
    if (v19)
    {
      unsigned int v8 = v20;
      uint64_t v9 = v19;
      if (v20 != v19)
      {
        do
        {
          uint64_t v11 = *--v8;
          uint64_t v10 = v11;
          *unsigned int v8 = 0;
          if (v11) {
            MEMORY[0x21667D390](v10, 0x1000C8077774924);
          }
        }
        while (v8 != v7);
        uint64_t v9 = v19;
      }
      uint64_t v20 = v7;
      operator delete(v9);
    }
    if (v17 != &v18) {
      free(v17);
    }
  }
  return v3;
}

unint64_t mlir::tensor::ExtractOp::fold(uint64_t a1, uint64_t a2)
{
  v50[9] = *MEMORY[0x263EF8340];
  uint64_t v4 = *(uint64_t **)(a2 + 40);
  uint64_t v5 = *v4;
  if (*v4)
  {
    if (mlir::DenseElementsAttr::classof(*v4)) {
      uint64_t v6 = (void *)v5;
    }
    else {
      uint64_t v6 = 0;
    }
    v49[0] = v6;
    if (v6)
    {
      int isSplat = mlir::DenseElementsAttr::isSplat((mlir::DenseElementsAttr *)v49);
      uint64_t v8 = isSplat ? v5 : 0;
      uint64_t v47 = v8;
      if (isSplat)
      {
        mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v47);
        ZinMirCacheTensors::ZinMirCacheTensors(v49, v47, 0);
        uint64_t v9 = v47;
        uint64_t NumElements = mlir::DenseElementsAttr::getNumElements((mlir::DenseElementsAttr *)&v47);
        ZinMirCacheTensors::ZinMirCacheTensors(&v39, v9, NumElements);
        return mlir::DenseElementsAttr::AttributeElementIterator::operator*(v49) & 0xFFFFFFFFFFFFFFFBLL;
      }
    }
    uint64_t v4 = *(uint64_t **)(a2 + 40);
  }
  v49[0] = v50;
  v49[1] = (void *)0x800000000;
  if (8 * *(void *)(a2 + 48) != 8)
  {
    int64x2_t v12 = (unint64_t *)(v4 + 1);
    uint64_t v13 = 8 * ((8 * *(void *)(a2 + 48) - 8) >> 3);
    while (*v12 && *(_UNKNOWN **)(*(void *)*v12 + 136) == &mlir::detail::TypeIDResolver<mlir::IntegerAttr,void>::id)
    {
      unint64_t v39 = *v12;
      uint64_t Int = mlir::IntegerAttr::getInt((mlir::IntegerAttr *)&v39);
      uint64_t v15 = LODWORD(v49[1]);
      if (LODWORD(v49[1]) >= (unint64_t)HIDWORD(v49[1]))
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)v49, v50, LODWORD(v49[1]) + 1, 8);
        uint64_t v15 = LODWORD(v49[1]);
      }
      *((void *)v49[0] + v15) = Int;
      ++LODWORD(v49[1]);
      ++v12;
      v13 -= 8;
      if (!v13) {
        goto LABEL_19;
      }
    }
    goto LABEL_40;
  }
LABEL_19:
  unint64_t v39 = *(void *)(*(void *)(*(void *)a1 + 72) + 24);
  uint64_t DefiningOp = mlir::Value::getDefiningOp((mlir::Value *)&v39);
  if (DefiningOp)
  {
    uint64_t v17 = *(void **)(*(void *)(DefiningOp + 48) + 16);
    uint64_t v18 = v17 == &mlir::detail::TypeIDResolver<mlir::tensor::FromElementsOp,void>::id ? DefiningOp : 0;
    if (v17 == &mlir::detail::TypeIDResolver<mlir::tensor::FromElementsOp,void>::id)
    {
      unint64_t v39 = *(void *)(DefiningOp - 8) & 0xFFFFFFFFFFFFFFF8;
      mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v39);
      unsigned int v21 = 0;
      uint64_t v22 = v20 - 1;
      if (((v20 - 1) & 0x80000000) == 0)
      {
        uint64_t v23 = (v20 - 1);
        int v24 = 1;
        do
        {
          if (v22 > v23) {
            v24 *= *(void *)(mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v39) + 8 * v23);
          }
          v21 += v24 * *((void *)v49[0] + v23);
        }
        while (v23-- > 0);
      }
      if ((*(unsigned char *)(v18 + 46) & 0x80) != 0)
      {
        uint64_t v11 = 0;
        if ((v21 & 0x80000000) == 0 && (signed int)v21 < *(_DWORD *)(v18 + 68)) {
          uint64_t v11 = (void *)(*(void *)(*(void *)(v18 + 72) + 32 * v21 + 24) | 4);
        }
        goto LABEL_41;
      }
      goto LABEL_40;
    }
  }
  uint64_t v11 = **(void ***)(a2 + 40);
  if (!v11) {
    goto LABEL_41;
  }
  if (mlir::detail::InterfaceMap::lookup<mlir::ElementsAttr>(*v11 + 8))
  {
    uint64_t v19 = mlir::detail::InterfaceMap::lookup<mlir::ElementsAttr>(*v11 + 8);
    unsigned int v45 = v11;
    uint64_t v46 = v19;
    if (mlir::ElementsAttr::isValidIndex((uint64_t)v11, v19, (void *)v49[0], LODWORD(v49[1])))
    {
      mlir::ElementsAttr::getValues<mlir::Attribute>((uint64_t *)&v45, (uint64_t)&v39);
      uint64_t FlattenedIndex = mlir::ElementsAttr::getFlattenedIndex(v44, (uint64_t)v49[0]);
      uint64_t v27 = FlattenedIndex;
      LOWORD(v47) = v39;
      int v28 = BYTE1(v39);
      if ((_BYTE)v39)
      {
        uint64_t v29 = v40;
        v48[0] = v40;
        uint64_t v30 = v41 + FlattenedIndex;
      }
      else
      {
        (*(void (**)(void *__return_ptr))(*(void *)v40 + 16))(v48);
        int v28 = BYTE1(v47);
        uint64_t v30 = v41 + v27;
        v48[1] = v41 + v27;
        if (!(_BYTE)v47)
        {
          uint64_t v36 = v48[0];
          v48[0] = 0;
          if (BYTE1(v47)) {
            uint64_t v37 = 0;
          }
          else {
            uint64_t v37 = v41 + v27;
          }
          uint64_t v33 = (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)v36 + 24))(v36, v37);
          (*(void (**)(uint64_t))(*(void *)v36 + 8))(v36);
          if (!(_BYTE)v47)
          {
            uint64_t v38 = v48[0];
            v48[0] = 0;
            if (v38) {
              (*(void (**)(uint64_t))(*(void *)v38 + 8))(v38);
            }
          }
          goto LABEL_50;
        }
        uint64_t v29 = v48[0];
      }
      if (v28) {
        uint64_t v32 = 0;
      }
      else {
        uint64_t v32 = v30;
      }
      uint64_t v33 = *(void *)(v29 + 8 * v32);
LABEL_50:
      if (!v42)
      {
        uint64_t v34 = v43;
        uint64_t v43 = 0;
        if (v34) {
          (*(void (**)(uint64_t))(*(void *)v34 + 8))(v34);
        }
      }
      uint64_t v11 = (void *)(v33 & 0xFFFFFFFFFFFFFFFBLL);
      if (!(_BYTE)v39)
      {
        uint64_t v35 = v40;
        uint64_t v40 = 0;
        if (v35) {
          (*(void (**)(uint64_t))(*(void *)v35 + 8))(v35);
        }
      }
      goto LABEL_41;
    }
  }
  else
  {
    unsigned int v45 = 0;
    uint64_t v46 = 0;
  }
LABEL_40:
  uint64_t v11 = 0;
LABEL_41:
  if (v49[0] != v50) {
    free(v49[0]);
  }
  return (unint64_t)v11;
}

void mlir::tensor::ExtractOp::getCanonicalizationPatterns()
{
}

uint64_t mlir::tensor::FromElementsOp::getAsmResultNames(uint64_t a1, uint64_t (*a2)(uint64_t, uint64_t, const char *, uint64_t), uint64_t a3)
{
  if (*(_DWORD *)(*(void *)a1 + 36)) {
    uint64_t v4 = *(void *)a1 - 16;
  }
  else {
    uint64_t v4 = 0;
  }
  uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v4, 0);

  return a2(a3, NextResultAtOffset, "from_elements", 13);
}

unint64_t mlir::tensor::FromElementsOp::fold(void *a1, uint64_t a2)
{
  unint64_t v3 = *(unsigned int *)(a2 + 48);
  uint64_t v4 = *(uint64_t **)(a2 + 40);
  if (*(_DWORD *)(a2 + 48))
  {
    uint64_t v5 = 8 * v3;
    uint64_t v6 = *(uint64_t **)(a2 + 40);
    while (*v6)
    {
      ++v6;
      v5 -= 8;
      if (!v5)
      {
        uint64_t v6 = &v4[v3];
        break;
      }
    }
    if (v3 != v6 - v4) {
      return 0;
    }
  }
  uint64_t v7 = (void *)(*(void *)(*a1 - 8) & 0xFFFFFFFFFFFFFFF8);
  if (!v7) {
    return mlir::DenseElementsAttr::get(0, 0, v4, v3) & 0xFFFFFFFFFFFFFFFBLL;
  }
  uint64_t v8 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*v7 + 8);
  return mlir::DenseElementsAttr::get((uint64_t)v7, v8, *(uint64_t **)(a2 + 40), *(unsigned int *)(a2 + 48)) & 0xFFFFFFFFFFFFFFFBLL;
}

void mlir::tensor::FromElementsOp::getCanonicalizationPatterns()
{
}

uint64_t mlir::tensor::GatherOp::getAsmResultNames(uint64_t a1, uint64_t (*a2)(uint64_t, uint64_t, const char *, uint64_t), uint64_t a3)
{
  if (*(_DWORD *)(*(void *)a1 + 36)) {
    uint64_t v4 = *(void *)a1 - 16;
  }
  else {
    uint64_t v4 = 0;
  }
  uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v4, 0);

  return a2(a3, NextResultAtOffset, "gather", 6);
}

uint64_t mlir::tensor::GatherOp::inferResultType(uint64_t a1, uint64_t a2, void *a3, uint64_t a4, char a5)
{
  v57[6] = *MEMORY[0x263EF8340];
  uint64_t v45 = a2;
  uint64_t v46 = a1;
  uint64_t Value = (const void *)mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v45);
  uint64_t v10 = v8 - 1;
  unint64_t v55 = v57;
  uint64_t v56 = 0x600000000;
  size_t v11 = 8 * (v8 - 1);
  if (v11 < 0x31)
  {
    unsigned int v12 = 0;
    if (v8 == 1) {
      goto LABEL_6;
    }
    goto LABEL_5;
  }
  llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v55, v57, (8 * v10) >> 3, 8);
  unsigned int v12 = v56;
  if (v10)
  {
LABEL_5:
    memcpy((char *)v55 + 8 * v12, Value, v11);
    unsigned int v12 = v56;
  }
LABEL_6:
  uint64_t v13 = v12 + (v11 >> 3);
  LODWORD(v56) = v13;
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v46);
  if (v14 + v13 > (unint64_t)HIDWORD(v56)) {
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v55, v57, v14 + v13, 8);
  }
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v46);
  if (v15)
  {
    uint64_t v16 = v15;
    if (a4)
    {
      uint64_t v17 = &a3[a4];
      uint64_t v18 = (8 * a4) >> 3;
      if (a5)
      {
        for (uint64_t i = 0; i != v16; ++i)
        {
          uint64_t v22 = a3;
          unint64_t v23 = v18;
          do
          {
            unint64_t v24 = v23 >> 1;
            uint64_t v25 = &v22[v23 >> 1];
            uint64_t v27 = *v25;
            uint64_t v26 = v25 + 1;
            v23 += ~(v23 >> 1);
            if (v27 < i) {
              uint64_t v22 = v26;
            }
            else {
              unint64_t v23 = v24;
            }
          }
          while (v23);
          if (v22 == v17 || i < *v22)
          {
            uint64_t v20 = *(void *)(mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v46) + 8 * i);
            uint64_t v21 = v56;
            if (v56 >= (unint64_t)HIDWORD(v56))
            {
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v55, v57, v56 + 1, 8);
              uint64_t v21 = v56;
            }
            *((void *)v55 + v21) = v20;
            LODWORD(v56) = v56 + 1;
          }
        }
        goto LABEL_42;
      }
      uint64_t v31 = 0;
      while (1)
      {
        uint64_t v32 = a3;
        unint64_t v33 = v18;
        do
        {
          unint64_t v34 = v33 >> 1;
          uint64_t v35 = &v32[v33 >> 1];
          uint64_t v37 = *v35;
          uint64_t v36 = v35 + 1;
          v33 += ~(v33 >> 1);
          if (v37 < v31) {
            uint64_t v32 = v36;
          }
          else {
            unint64_t v33 = v34;
          }
        }
        while (v33);
        if (v32 == v17 || v31 < *v32)
        {
          uint64_t v38 = *(void *)(mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v46) + 8 * v31);
          uint64_t v39 = v56;
          if (v56 >= (unint64_t)HIDWORD(v56)) {
            goto LABEL_41;
          }
        }
        else
        {
          uint64_t v39 = v56;
          uint64_t v38 = 1;
          if (v56 >= (unint64_t)HIDWORD(v56))
          {
LABEL_41:
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v55, v57, v39 + 1, 8);
            uint64_t v39 = v56;
          }
        }
        *((void *)v55 + v39) = v38;
        LODWORD(v56) = v56 + 1;
        if (++v31 == v16) {
          goto LABEL_42;
        }
      }
    }
    for (uint64_t j = 0; j != v16; ++j)
    {
      uint64_t v29 = *(void *)(mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v46) + 8 * j);
      uint64_t v30 = v56;
      if (v56 >= (unint64_t)HIDWORD(v56))
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v55, v57, v56 + 1, 8);
        uint64_t v30 = v56;
      }
      *((void *)v55 + v30) = v29;
      LODWORD(v56) = v56 + 1;
    }
  }
LABEL_42:
  uint64_t v47 = v46;
  unint64_t v48 = (void *)mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v47);
  uint64_t v49 = v40;
  uint64_t v50 = v52;
  uint64_t v51 = 0x600000000;
  uint64_t RHS = mlir::AffineBinaryOpExpr::getRHS((mlir::AffineBinaryOpExpr *)&v47);
  uint64_t Values = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)&v47);
  uint64_t v54 = Values;
  unint64_t v48 = v55;
  uint64_t v49 = v56;
  LODWORD(v51) = 0;
  if (v56) {
    char v42 = v55;
  }
  else {
    char v42 = v50;
  }
  uint64_t v43 = mlir::RankedTensorType::get((uint64_t)v42, v56, RHS, Values);
  if (v50 != v52) {
    free(v50);
  }
  if (v55 != v57) {
    free(v55);
  }
  return v43;
}

uint64_t mlir::tensor::GatherOp::verify(mlir::tensor::GatherOp *this)
{
  uint64_t v80 = *MEMORY[0x263EF8340];
  v70[0] = *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8;
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)v70);
  uint64_t v3 = v2;
  v70[0] = *(void *)(*(void *)this
                     + 16 * (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 23) & 1)
                     + 64);
  uint64_t v4 = (uint64_t *)mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)v70);
  uint64_t v6 = v5;
  if (!verifyGatherOrScatterDims(*(void *)this, v4, v5, v3, (void **)"gather", (const char *)6, (void **)"source", (const char *)6))return 0; {
  uint64_t v7 = mlir::tensor::GatherOp::inferResultType(*(void *)(*(void *)(*(void *)(*(void *)this + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8, *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 56) + 8) & 0xFFFFFFFFFFFFFFF8, v4, v6, 0);
  }
  uint64_t v8 = 1;
  uint64_t v9 = mlir::tensor::GatherOp::inferResultType(*(void *)(*(void *)(*(void *)(*(void *)this + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8, *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 56) + 8) & 0xFFFFFFFFFFFFFFF8, v4, v6, 1);
  if (*(_DWORD *)(*(void *)this + 36)) {
    uint64_t v10 = *(void *)this - 16;
  }
  else {
    uint64_t v10 = 0;
  }
  if ((*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v10, 0) + 8) & 0xFFFFFFFFFFFFFFF8) != v7)
  {
    uint64_t v11 = *(_DWORD *)(*(void *)this + 36) ? *(void *)this - 16 : 0;
    if ((*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v11, 0) + 8) & 0xFFFFFFFFFFFFFFF8) != v9)
    {
      unint64_t v65 = (void **)"result type mismatch: expected ";
      __int16 v66 = 259;
      mlir::OpState::emitOpError((uint64_t *)this, &v65, (uint64_t)v70);
      if (v70[0])
      {
        unsigned int v12 = &v67;
        mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v67, v7);
        uint64_t v13 = (char *)v71;
        if (v72 >= v73)
        {
          unint64_t v50 = v72 + 1;
          if (v71 <= &v67 && (char *)v71 + 24 * v72 > (char *)&v67)
          {
            int64_t v59 = (char *)&v67 - (unsigned char *)v71;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v71, v74, v50, 24);
            uint64_t v13 = (char *)v71;
            unsigned int v12 = (int *)((char *)v71 + v59);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v71, v74, v50, 24);
            unsigned int v12 = &v67;
            uint64_t v13 = (char *)v71;
          }
        }
        uint64_t v14 = &v13[24 * v72];
        long long v15 = *(_OWORD *)v12;
        *((void *)v14 + 2) = *((void *)v12 + 2);
        *(_OWORD *)uint64_t v14 = v15;
        uint64_t v16 = ++v72;
        if (v70[0])
        {
          int v67 = 3;
          unint64_t v68 = " or its rank-reduced variant ";
          uint64_t v69 = 29;
          uint64_t v17 = &v67;
          uint64_t v18 = (char *)v71;
          if (v16 >= v73)
          {
            unint64_t v52 = v16 + 1;
            BOOL v53 = (char *)v71 + 24 * v16 > (char *)&v67;
            if (v71 <= &v67 && v53)
            {
              int64_t v61 = (char *)&v67 - (unsigned char *)v71;
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v71, v74, v52, 24);
              uint64_t v18 = (char *)v71;
              uint64_t v17 = (int *)((char *)v71 + v61);
            }
            else
            {
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v71, v74, v52, 24);
              uint64_t v17 = &v67;
              uint64_t v18 = (char *)v71;
            }
          }
          uint64_t v19 = &v18[24 * v72];
          long long v20 = *(_OWORD *)v17;
          *((void *)v19 + 2) = *((void *)v17 + 2);
          *(_OWORD *)uint64_t v19 = v20;
          ++v72;
          if (v70[0])
          {
            uint64_t v21 = &v67;
            mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v67, v9);
            uint64_t v22 = (char *)v71;
            if (v72 >= v73)
            {
              unint64_t v56 = v72 + 1;
              if (v71 <= &v67 && (char *)v71 + 24 * v72 > (char *)&v67)
              {
                int64_t v63 = (char *)&v67 - (unsigned char *)v71;
                llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v71, v74, v56, 24);
                uint64_t v22 = (char *)v71;
                uint64_t v21 = (int *)((char *)v71 + v63);
              }
              else
              {
                llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v71, v74, v56, 24);
                uint64_t v21 = &v67;
                uint64_t v22 = (char *)v71;
              }
            }
            unint64_t v23 = &v22[24 * v72];
            long long v24 = *(_OWORD *)v21;
            *((void *)v23 + 2) = *((void *)v21 + 2);
            *(_OWORD *)unint64_t v23 = v24;
            uint64_t v25 = ++v72;
            if (v70[0])
            {
              int v67 = 3;
              unint64_t v68 = " (got: ";
              uint64_t v69 = 7;
              uint64_t v26 = &v67;
              uint64_t v27 = (char *)v71;
              if (v25 >= v73)
              {
                unint64_t v57 = v25 + 1;
                BOOL v58 = (char *)v71 + 24 * v25 > (char *)&v67;
                if (v71 <= &v67 && v58)
                {
                  int64_t v64 = (char *)&v67 - (unsigned char *)v71;
                  llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v71, v74, v57, 24);
                  uint64_t v27 = (char *)v71;
                  uint64_t v26 = (int *)((char *)v71 + v64);
                }
                else
                {
                  llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v71, v74, v57, 24);
                  uint64_t v26 = &v67;
                  uint64_t v27 = (char *)v71;
                }
              }
              int v28 = &v27[24 * v72];
              long long v29 = *(_OWORD *)v26;
              *((void *)v28 + 2) = *((void *)v26 + 2);
              *(_OWORD *)int v28 = v29;
              ++v72;
            }
          }
        }
      }
      if (*(_DWORD *)(*(void *)this + 36)) {
        uint64_t v30 = *(void *)this - 16;
      }
      else {
        uint64_t v30 = 0;
      }
      uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v30, 0);
      if (v70[0])
      {
        uint64_t v32 = &v67;
        mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v67, *(void *)(NextResultAtOffset + 8) & 0xFFFFFFFFFFFFFFF8);
        unint64_t v33 = (char *)v71;
        if (v72 >= v73)
        {
          unint64_t v51 = v72 + 1;
          if (v71 <= &v67 && (char *)v71 + 24 * v72 > (char *)&v67)
          {
            int64_t v60 = (char *)&v67 - (unsigned char *)v71;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v71, v74, v51, 24);
            unint64_t v33 = (char *)v71;
            uint64_t v32 = (int *)((char *)v71 + v60);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v71, v74, v51, 24);
            uint64_t v32 = &v67;
            unint64_t v33 = (char *)v71;
          }
        }
        unint64_t v34 = &v33[24 * v72];
        long long v35 = *(_OWORD *)v32;
        *((void *)v34 + 2) = *((void *)v32 + 2);
        *(_OWORD *)unint64_t v34 = v35;
        uint64_t v36 = ++v72;
        if (v70[0])
        {
          int v67 = 3;
          unint64_t v68 = ")";
          uint64_t v69 = 1;
          uint64_t v37 = &v67;
          uint64_t v38 = (char *)v71;
          if (v36 >= v73)
          {
            unint64_t v54 = v36 + 1;
            BOOL v55 = (char *)v71 + 24 * v36 > (char *)&v67;
            if (v71 <= &v67 && v55)
            {
              int64_t v62 = (char *)&v67 - (unsigned char *)v71;
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v71, v74, v54, 24);
              uint64_t v38 = (char *)v71;
              uint64_t v37 = (int *)((char *)v71 + v62);
            }
            else
            {
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v71, v74, v54, 24);
              uint64_t v37 = &v67;
              uint64_t v38 = (char *)v71;
            }
          }
          uint64_t v39 = &v38[24 * v72];
          long long v40 = *(_OWORD *)v37;
          *((void *)v39 + 2) = *((void *)v37 + 2);
          *(_OWORD *)uint64_t v39 = v40;
          ++v72;
        }
      }
      uint64_t v8 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v70);
      if (v70[0]) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v70);
      }
      if (v79)
      {
        uint64_t v41 = __p;
        if (__p)
        {
          char v42 = v78;
          uint64_t v43 = __p;
          if (v78 != __p)
          {
            do
              char v42 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v42 - 1);
            while (v42 != v41);
            uint64_t v43 = __p;
          }
          uint64_t v78 = v41;
          operator delete(v43);
        }
        long long v44 = v75;
        if (v75)
        {
          uint64_t v45 = v76;
          uint64_t v46 = v75;
          if (v76 != v75)
          {
            do
            {
              uint64_t v48 = *--v45;
              uint64_t v47 = v48;
              *uint64_t v45 = 0;
              if (v48) {
                MEMORY[0x21667D390](v47, 0x1000C8077774924);
              }
            }
            while (v45 != v44);
            uint64_t v46 = v75;
          }
          char v76 = v44;
          operator delete(v46);
        }
        if (v71 != v74) {
          free(v71);
        }
      }
    }
  }
  return v8;
}

uint64_t verifyGatherOrScatterDims(uint64_t a1, uint64_t *a2, uint64_t a3, uint64_t a4, void **a5, const char *a6, void **a7, const char *a8)
{
  uint64_t v113 = *MEMORY[0x263EF8340];
  if (a3)
  {
    if (a3 <= a4)
    {
      for (uint64_t i = 0; i != a3; ++i)
      {
        uint64_t v38 = a2[i];
        if (v38 < 0)
        {
          __int16 v101 = 261;
          uint64_t v98 = a5;
          int v99 = a6;
          mlir::Operation::emitOpError(a1, &v98, (uint64_t)&v102);
          if (v102)
          {
            LODWORD(v94) = 3;
            unint64_t v95 = "_dims value must be non-negative";
            uint64_t v96 = 32;
            uint64_t v45 = &v94;
            uint64_t v46 = (char *)v104;
            if (v105 >= v106)
            {
              unint64_t v83 = v105 + 1;
              if (v104 <= &v94 && (char *)v104 + 24 * v105 > (char *)&v94)
              {
                int64_t v90 = (char *)&v94 - (unsigned char *)v104;
                llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v104, v107, v83, 24);
                uint64_t v46 = (char *)v104;
                uint64_t v45 = (void ***)((char *)v104 + v90);
              }
              else
              {
                llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v104, v107, v83, 24);
                uint64_t v45 = &v94;
                uint64_t v46 = (char *)v104;
              }
            }
            uint64_t v47 = &v46[24 * v105];
            long long v48 = *(_OWORD *)v45;
            *((void *)v47 + 2) = v45[2];
            *(_OWORD *)uint64_t v47 = v48;
            ++v105;
          }
          uint64_t v18 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v102);
          if (v102) {
            mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v102);
          }
          if (!v112) {
            return v18;
          }
          uint64_t v49 = __p;
          if (__p)
          {
            unint64_t v50 = v111;
            unint64_t v51 = __p;
            if (v111 != __p)
            {
              do
                unint64_t v50 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v50 - 1);
              while (v50 != v49);
              unint64_t v51 = __p;
            }
            unint64_t v111 = v49;
            operator delete(v51);
          }
          uint64_t v22 = v108;
          if (!v108) {
            goto LABEL_106;
          }
          unint64_t v52 = v109;
          long long v24 = v108;
          if (v109 == v108) {
            goto LABEL_105;
          }
          do
          {
            uint64_t v54 = *--v52;
            uint64_t v53 = v54;
            void *v52 = 0;
            if (v54) {
              MEMORY[0x21667D390](v53, 0x1000C8077774924);
            }
          }
          while (v52 != v22);
          goto LABEL_104;
        }
        if (v38 >= a4)
        {
          __int16 v97 = 261;
          int v94 = a5;
          unint64_t v95 = a6;
          mlir::Operation::emitOpError(a1, &v94, (uint64_t)&v102);
          if (v102)
          {
            LODWORD(v98) = 3;
            int v99 = "_dims value must be smaller than ";
            uint64_t v100 = 33;
            BOOL v55 = &v98;
            unint64_t v56 = (char *)v104;
            if (v105 >= v106)
            {
              unint64_t v84 = v105 + 1;
              if (v104 <= &v98 && (char *)v104 + 24 * v105 > (char *)&v98)
              {
                int64_t v91 = (char *)&v98 - (unsigned char *)v104;
                llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v104, v107, v84, 24);
                unint64_t v56 = (char *)v104;
                BOOL v55 = (void ***)((char *)v104 + v91);
              }
              else
              {
                llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v104, v107, v84, 24);
                BOOL v55 = &v98;
                unint64_t v56 = (char *)v104;
              }
            }
            unint64_t v57 = &v56[24 * v105];
            long long v58 = *(_OWORD *)v55;
            *((void *)v57 + 2) = v55[2];
            *(_OWORD *)unint64_t v57 = v58;
            ++v105;
            if (v102)
            {
              __int16 v101 = 261;
              uint64_t v98 = a7;
              int v99 = a8;
              mlir::Diagnostic::operator<<((uint64_t)v103, &v98);
              if (v102)
              {
                LODWORD(v98) = 3;
                int v99 = " rank";
                uint64_t v100 = 5;
                int64_t v59 = &v98;
                int64_t v60 = (char *)v104;
                if (v105 >= v106)
                {
                  unint64_t v85 = v105 + 1;
                  if (v104 <= &v98 && (char *)v104 + 24 * v105 > (char *)&v98)
                  {
                    int64_t v92 = (char *)&v98 - (unsigned char *)v104;
                    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v104, v107, v85, 24);
                    int64_t v60 = (char *)v104;
                    int64_t v59 = (void ***)((char *)v104 + v92);
                  }
                  else
                  {
                    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v104, v107, v85, 24);
                    int64_t v59 = &v98;
                    int64_t v60 = (char *)v104;
                  }
                }
                int64_t v61 = &v60[24 * v105];
                long long v62 = *(_OWORD *)v59;
                *((void *)v61 + 2) = v59[2];
                *(_OWORD *)int64_t v61 = v62;
                ++v105;
              }
            }
          }
          uint64_t v18 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v102);
          if (v102) {
            mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v102);
          }
          if (!v112) {
            return v18;
          }
          int64_t v63 = __p;
          if (__p)
          {
            int64_t v64 = v111;
            unint64_t v65 = __p;
            if (v111 != __p)
            {
              do
                int64_t v64 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v64 - 1);
              while (v64 != v63);
              unint64_t v65 = __p;
            }
            unint64_t v111 = v63;
            operator delete(v65);
          }
          uint64_t v22 = v108;
          if (!v108) {
            goto LABEL_106;
          }
          __int16 v66 = v109;
          long long v24 = v108;
          if (v109 == v108) {
            goto LABEL_105;
          }
          do
          {
            uint64_t v68 = *--v66;
            uint64_t v67 = v68;
            *__int16 v66 = 0;
            if (v68) {
              MEMORY[0x21667D390](v67, 0x1000C8077774924);
            }
          }
          while (v66 != v22);
          goto LABEL_104;
        }
      }
      if (a3 < 2) {
        return 1;
      }
      uint64_t v41 = *a2;
      uint64_t v39 = a2 + 1;
      uint64_t v40 = v41;
      uint64_t v42 = a3 - 1;
      uint64_t v18 = 1;
      while (1)
      {
        uint64_t v44 = *v39++;
        uint64_t v43 = v44;
        if (v40 >= v44) {
          break;
        }
        uint64_t v40 = v43;
        if (!--v42) {
          return v18;
        }
      }
      __int16 v101 = 261;
      uint64_t v98 = a5;
      int v99 = a6;
      mlir::Operation::emitOpError(a1, &v98, (uint64_t)&v102);
      if (v102)
      {
        LODWORD(v94) = 3;
        unint64_t v95 = "_dims values must be strictly increasing";
        uint64_t v96 = 40;
        uint64_t v69 = &v94;
        unsigned int v70 = (char *)v104;
        if (v105 >= v106)
        {
          unint64_t v86 = v105 + 1;
          if (v104 <= &v94 && (char *)v104 + 24 * v105 > (char *)&v94)
          {
            int64_t v93 = (char *)&v94 - (unsigned char *)v104;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v104, v107, v86, 24);
            unsigned int v70 = (char *)v104;
            uint64_t v69 = (void ***)((char *)v104 + v93);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v104, v107, v86, 24);
            uint64_t v69 = &v94;
            unsigned int v70 = (char *)v104;
          }
        }
        uint64_t v71 = &v70[24 * v105];
        long long v72 = *(_OWORD *)v69;
        *((void *)v71 + 2) = v69[2];
        *(_OWORD *)uint64_t v71 = v72;
        ++v105;
      }
      uint64_t v18 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v102);
      if (v102) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v102);
      }
      if (!v112) {
        return v18;
      }
      unsigned int v73 = __p;
      if (__p)
      {
        unint64_t v74 = v111;
        unint64_t v75 = __p;
        if (v111 != __p)
        {
          do
            unint64_t v74 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v74 - 1);
          while (v74 != v73);
          unint64_t v75 = __p;
        }
        unint64_t v111 = v73;
        operator delete(v75);
      }
      uint64_t v22 = v108;
      if (!v108) {
        goto LABEL_106;
      }
      char v76 = v109;
      long long v24 = v108;
      if (v109 == v108) {
        goto LABEL_105;
      }
      do
      {
        uint64_t v78 = *--v76;
        uint64_t v77 = v78;
        *char v76 = 0;
        if (v78) {
          MEMORY[0x21667D390](v77, 0x1000C8077774924);
        }
      }
      while (v76 != v22);
      goto LABEL_104;
    }
    __int16 v97 = 261;
    int v94 = a5;
    unint64_t v95 = a6;
    mlir::Operation::emitOpError(a1, &v94, (uint64_t)&v102);
    if (v102)
    {
      LODWORD(v98) = 3;
      int v99 = "_dims overflow ";
      uint64_t v100 = 15;
      uint64_t v10 = &v98;
      uint64_t v11 = (char *)v104;
      if (v105 >= v106)
      {
        unint64_t v81 = v105 + 1;
        if (v104 <= &v98 && (char *)v104 + 24 * v105 > (char *)&v98)
        {
          int64_t v88 = (char *)&v98 - (unsigned char *)v104;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v104, v107, v81, 24);
          uint64_t v11 = (char *)v104;
          uint64_t v10 = (void ***)((char *)v104 + v88);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v104, v107, v81, 24);
          uint64_t v10 = &v98;
          uint64_t v11 = (char *)v104;
        }
      }
      unsigned int v12 = &v11[24 * v105];
      long long v13 = *(_OWORD *)v10;
      *((void *)v12 + 2) = v10[2];
      *(_OWORD *)unsigned int v12 = v13;
      ++v105;
      if (v102)
      {
        __int16 v101 = 261;
        uint64_t v98 = a7;
        int v99 = a8;
        mlir::Diagnostic::operator<<((uint64_t)v103, &v98);
        if (v102)
        {
          LODWORD(v98) = 3;
          int v99 = " rank";
          uint64_t v100 = 5;
          uint64_t v14 = &v98;
          long long v15 = (char *)v104;
          if (v105 >= v106)
          {
            unint64_t v82 = v105 + 1;
            if (v104 <= &v98 && (char *)v104 + 24 * v105 > (char *)&v98)
            {
              int64_t v89 = (char *)&v98 - (unsigned char *)v104;
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v104, v107, v82, 24);
              long long v15 = (char *)v104;
              uint64_t v14 = (void ***)((char *)v104 + v89);
            }
            else
            {
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v104, v107, v82, 24);
              uint64_t v14 = &v98;
              long long v15 = (char *)v104;
            }
          }
          uint64_t v16 = &v15[24 * v105];
          long long v17 = *(_OWORD *)v14;
          *((void *)v16 + 2) = v14[2];
          *(_OWORD *)uint64_t v16 = v17;
          ++v105;
        }
      }
    }
    uint64_t v18 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v102);
    if (v102) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v102);
    }
    if (v112)
    {
      uint64_t v19 = __p;
      if (__p)
      {
        long long v20 = v111;
        uint64_t v21 = __p;
        if (v111 != __p)
        {
          do
            long long v20 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v20 - 1);
          while (v20 != v19);
          uint64_t v21 = __p;
        }
        unint64_t v111 = v19;
        operator delete(v21);
      }
      uint64_t v22 = v108;
      if (!v108) {
        goto LABEL_106;
      }
      unint64_t v23 = v109;
      long long v24 = v108;
      if (v109 == v108)
      {
LABEL_105:
        int v109 = v22;
        operator delete(v24);
LABEL_106:
        if (v104 != v107) {
          free(v104);
        }
        return v18;
      }
      do
      {
        uint64_t v26 = *--v23;
        uint64_t v25 = v26;
        void *v23 = 0;
        if (v26) {
          MEMORY[0x21667D390](v25, 0x1000C8077774924);
        }
      }
      while (v23 != v22);
LABEL_104:
      long long v24 = v108;
      goto LABEL_105;
    }
  }
  else
  {
    __int16 v101 = 261;
    uint64_t v98 = a5;
    int v99 = a6;
    mlir::Operation::emitOpError(a1, &v98, (uint64_t)&v102);
    if (v102)
    {
      LODWORD(v94) = 3;
      unint64_t v95 = "_dims must be non-empty";
      uint64_t v96 = 23;
      uint64_t v27 = &v94;
      int v28 = (char *)v104;
      if (v105 >= v106)
      {
        unint64_t v80 = v105 + 1;
        if (v104 <= &v94 && (char *)v104 + 24 * v105 > (char *)&v94)
        {
          int64_t v87 = (char *)&v94 - (unsigned char *)v104;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v104, v107, v80, 24);
          int v28 = (char *)v104;
          uint64_t v27 = (void ***)((char *)v104 + v87);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v104, v107, v80, 24);
          uint64_t v27 = &v94;
          int v28 = (char *)v104;
        }
      }
      long long v29 = &v28[24 * v105];
      long long v30 = *(_OWORD *)v27;
      *((void *)v29 + 2) = v27[2];
      *(_OWORD *)long long v29 = v30;
      ++v105;
    }
    uint64_t v18 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v102);
    if (v102) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v102);
    }
    if (v112)
    {
      uint64_t v31 = __p;
      if (__p)
      {
        uint64_t v32 = v111;
        unint64_t v33 = __p;
        if (v111 != __p)
        {
          do
            uint64_t v32 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v32 - 1);
          while (v32 != v31);
          unint64_t v33 = __p;
        }
        unint64_t v111 = v31;
        operator delete(v33);
      }
      uint64_t v22 = v108;
      if (!v108) {
        goto LABEL_106;
      }
      unint64_t v34 = v109;
      long long v24 = v108;
      if (v109 == v108) {
        goto LABEL_105;
      }
      do
      {
        uint64_t v36 = *--v34;
        uint64_t v35 = v36;
        *unint64_t v34 = 0;
        if (v36) {
          MEMORY[0x21667D390](v35, 0x1000C8077774924);
        }
      }
      while (v34 != v22);
      goto LABEL_104;
    }
  }
  return v18;
}

unint64_t mlir::tensor::GatherOp::fold(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = *(uint64_t **)(a2 + 56);
  unint64_t v4 = *v3;
  if (*v3 && !mlir::DenseElementsAttr::classof(*v3)) {
    unint64_t v4 = 0;
  }
  if (*(_DWORD *)(*(void *)a1 + 36)) {
    uint64_t v5 = *(void *)a1 - 16;
  }
  else {
    uint64_t v5 = 0;
  }
  uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v5, 0);
  unint64_t result = reshapeConstantSource(v4, (void *)(*(void *)(NextResultAtOffset + 8) & 0xFFFFFFFFFFFFFFF8));
  if (result <= 7) {
    return 0;
  }
  return result;
}

unint64_t reshapeConstantSource(unint64_t result, void *a2)
{
  uint64_t v7 = a2;
  unint64_t v8 = result;
  if (result)
  {
    if (mlir::DenseElementsAttr::isSplat((mlir::DenseElementsAttr *)&v8))
    {
      if (!mlir::TensorType::hasRank((mlir::TensorType *)&v7)) {
        return 0;
      }
      uint64_t Value = (void *)mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v7);
      if (v3)
      {
        uint64_t v4 = 8 * v3;
        while (*Value != 0x8000000000000000)
        {
          ++Value;
          v4 -= 8;
          if (!v4) {
            goto LABEL_8;
          }
        }
        return 0;
      }
LABEL_8:
      uint64_t v5 = (uint64_t)v7;
      if (v7) {
        uint64_t v6 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*v7 + 8);
      }
      else {
        uint64_t v6 = 0;
      }
      return mlir::DenseElementsAttr::reshape((uint64_t *)&v8, v5, v6) & 0xFFFFFFFFFFFFFFFBLL;
    }
    else
    {
      return 0;
    }
  }
  return result;
}

uint64_t mlir::tensor::InsertOp::getAsmResultNames(uint64_t a1, uint64_t (*a2)(uint64_t, uint64_t, const char *, uint64_t), uint64_t a3)
{
  if (*(_DWORD *)(*(void *)a1 + 36)) {
    uint64_t v4 = *(void *)a1 - 16;
  }
  else {
    uint64_t v4 = 0;
  }
  uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v4, 0);

  return a2(a3, NextResultAtOffset, "inserted", 8);
}

uint64_t mlir::tensor::InsertOp::verify(mlir::tensor::InsertOp *this)
{
  uint64_t v24 = *MEMORY[0x263EF8340];
  unint64_t v15 = *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 56) + 8) & 0xFFFFFFFFFFFFFFF8;
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v15);
  if ((*(unsigned char *)(*(void *)this + 46) & 0x80) != 0)
  {
    if (v2 == *(unsigned int *)(*(void *)this + 68) - 2) {
      return 1;
    }
  }
  else if (v2 == -2)
  {
    return 1;
  }
  long long v13 = (void **)"incorrect number of indices";
  __int16 v14 = 259;
  mlir::OpState::emitOpError((uint64_t *)this, &v13, (uint64_t)v16);
  uint64_t v3 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v16);
  if (v16[0]) {
    mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v16);
  }
  if (v23)
  {
    uint64_t v4 = __p;
    if (__p)
    {
      uint64_t v5 = v22;
      uint64_t v6 = __p;
      if (v22 != __p)
      {
        do
          uint64_t v5 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v5 - 1);
        while (v5 != v4);
        uint64_t v6 = __p;
      }
      uint64_t v22 = v4;
      operator delete(v6);
    }
    uint64_t v7 = v19;
    if (v19)
    {
      unint64_t v8 = v20;
      uint64_t v9 = v19;
      if (v20 != v19)
      {
        do
        {
          uint64_t v11 = *--v8;
          uint64_t v10 = v11;
          *unint64_t v8 = 0;
          if (v11) {
            MEMORY[0x21667D390](v10, 0x1000C8077774924);
          }
        }
        while (v8 != v7);
        uint64_t v9 = v19;
      }
      long long v20 = v7;
      operator delete(v9);
    }
    if (v17 != &v18) {
      free(v17);
    }
  }
  return v3;
}

unint64_t mlir::tensor::InsertOp::fold(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = *(uint64_t **)(a2 + 40);
  uint64_t v4 = *v2;
  uint64_t v3 = v2[1];
  if (*v2) {
    BOOL v5 = v3 == 0;
  }
  else {
    BOOL v5 = 1;
  }
  if (v5) {
    return 0;
  }
  uint64_t v6 = mlir::DenseElementsAttr::classof(v2[1]) ? v3 : 0;
  *(void *)&long long v14 = v6;
  if (!v6) {
    return 0;
  }
  int isSplat = mlir::DenseElementsAttr::isSplat((mlir::DenseElementsAttr *)&v14);
  uint64_t v8 = isSplat ? v3 : 0;
  uint64_t v12 = v8;
  if (isSplat
    && (mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v12),
        ZinMirCacheTensors::ZinMirCacheTensors(&v14, v12, 0),
        uint64_t v9 = v12,
        uint64_t NumElements = mlir::DenseElementsAttr::getNumElements((mlir::DenseElementsAttr *)&v12),
        ZinMirCacheTensors::ZinMirCacheTensors(&v13, v9, NumElements),
        v4 == mlir::DenseElementsAttr::AttributeElementIterator::operator*(&v14)))
  {
    return v3 & 0xFFFFFFFFFFFFFFFBLL;
  }
  else
  {
    return 0;
  }
}

uint64_t mlir::tensor::GenerateOp::getAsmResultNames(uint64_t a1, uint64_t (*a2)(uint64_t, uint64_t, const char *, uint64_t), uint64_t a3)
{
  if (*(_DWORD *)(*(void *)a1 + 36)) {
    uint64_t v4 = *(void *)a1 - 16;
  }
  else {
    uint64_t v4 = 0;
  }
  uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v4, 0);

  return a2(a3, NextResultAtOffset, "generated", 9);
}

uint64_t mlir::tensor::GenerateOp::reifyResultShapes(uint64_t a1, mlir::IndexType **a2, uint64_t a3)
{
  v26[6] = *MEMORY[0x263EF8340];
  unint64_t v23 = *(void *)(*(void *)a1 - 8) & 0xFFFFFFFFFFFFFFF8;
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v23);
  uint64_t v24 = v26;
  uint64_t v25 = 0x600000000;
  if (v6)
  {
    unint64_t v7 = v6;
    if (v6 < 7)
    {
      uint64_t v8 = 0;
      unint64_t v9 = v6;
    }
    else
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v24, v26, v6, 8);
      uint64_t v8 = v25;
      unint64_t v9 = v7 - v25;
      if (v7 == v25) {
        goto LABEL_7;
      }
    }
    bzero((char *)v24 + 8 * v8, 8 * v9);
LABEL_7:
    LODWORD(v25) = v7;
  }
  uint64_t v10 = *(unsigned int *)(a3 + 8);
  if (!v10)
  {
    llvm::SmallVectorImpl<llvm::SmallVector<mlir::OpFoldResult,6u>>::append(a3, 1 - v10, (unint64_t)&v24);
LABEL_15:
    long long v14 = v24;
    if (v24 == v26) {
      goto LABEL_17;
    }
    goto LABEL_16;
  }
  if (v10 == 1) {
    goto LABEL_15;
  }
  uint64_t v11 = *(void **)a3;
  uint64_t v12 = v10 << 6;
  do
  {
    uint64_t v13 = *(char **)((char *)v11 + v12 - 64);
    if ((char *)v11 + v12 - 48 != v13) {
      free(v13);
    }
    v12 -= 64;
  }
  while (v12 != 64);
  *(_DWORD *)(a3 + 8) = 1;
  long long v14 = v24;
  if (v24 != v26) {
LABEL_16:
  }
    free(v14);
LABEL_17:
  uint64_t v24 = (void *)(*(void *)(*(void *)a1 - 8) & 0xFFFFFFFFFFFFFFF8);
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v24);
  if (v15)
  {
    uint64_t v16 = v15;
    unsigned int v17 = 0;
    for (uint64_t i = 0; i != v16; ++i)
    {
      uint64_t v24 = (void *)(*(void *)(*(void *)a1 - 8) & 0xFFFFFFFFFFFFFFF8);
      if (*(void *)(mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v24) + 8 * i) == 0x8000000000000000)
      {
        uint64_t v21 = v17++;
        unint64_t v20 = *(void *)(*(void *)(*(void *)a1 + 72) + 32 * v21 + 24) | 4;
      }
      else
      {
        uint64_t v24 = (void *)(*(void *)(*(void *)a1 - 8) & 0xFFFFFFFFFFFFFFF8);
        uint64_t Value = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v24);
        unint64_t v20 = mlir::Builder::getIndexAttr(a2, *(mlir::MLIRContext **)(Value + 8 * i)) & 0xFFFFFFFFFFFFFFFBLL;
      }
      *(void *)(**(void **)a3 + 8 * i) = v20;
    }
  }
  return 1;
}

uint64_t mlir::tensor::GenerateOp::verify(mlir::tensor::GenerateOp *this)
{
  uint64_t v55 = *MEMORY[0x263EF8340];
  uint64_t v2 = *(void *)this;
  unint64_t v41 = *(void *)(*(void *)this - 8) & 0xFFFFFFFFFFFFFFF8;
  if ((*(unsigned char *)(v2 + 46) & 0x80) != 0)
  {
    uint64_t v3 = *(unsigned int *)(v2 + 68);
    uint64_t Value = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v41);
    if (v5) {
      goto LABEL_3;
    }
  }
  else
  {
    uint64_t v3 = 0;
    uint64_t Value = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v41);
    if (v5)
    {
LABEL_3:
      unint64_t v6 = (v5 - 1) & 0x1FFFFFFFFFFFFFFFLL;
      if (v6 >= 3)
      {
        unint64_t v9 = v6 + 1;
        uint64_t v10 = (v6 + 1) & 0x3FFFFFFFFFFFFFFCLL;
        uint64_t v8 = (uint64_t *)(Value + 8 * v10);
        uint64_t v11 = (int64x2_t *)(Value + 16);
        int64x2_t v12 = 0uLL;
        int64x2_t v13 = vdupq_n_s64(0x8000000000000000);
        uint64_t v14 = v10;
        int64x2_t v15 = 0uLL;
        do
        {
          int64x2_t v12 = vsubq_s64(v12, vceqq_s64(v11[-1], v13));
          int64x2_t v15 = vsubq_s64(v15, vceqq_s64(*v11, v13));
          v11 += 2;
          v14 -= 4;
        }
        while (v14);
        uint64_t v7 = vaddvq_s64(vaddq_s64(v15, v12));
        if (v9 == v10) {
          goto LABEL_11;
        }
      }
      else
      {
        uint64_t v7 = 0;
        uint64_t v8 = (uint64_t *)Value;
      }
      do
      {
        uint64_t v16 = *v8++;
        if (v16 == 0x8000000000000000) {
          ++v7;
        }
      }
      while (v8 != (uint64_t *)(Value + 8 * v5));
LABEL_11:
      if (v7 == v3) {
        goto LABEL_12;
      }
      goto LABEL_42;
    }
  }
  if (!v3)
  {
LABEL_12:
    v45[0] = v46;
    v45[1] = 0x600000000;
    uint64_t v42 = v44;
    uint64_t v43 = 0x600000000;
    if ((*(unsigned char *)(*(void *)this + 46) & 0x80) != 0)
    {
      operandsAndShape(v41, *(void *)(*(void *)this + 72), *(unsigned int *)(*(void *)this + 68), (uint64_t)v45, (uint64_t)&v42);
      uint64_t v17 = v43;
      if (v43) {
        goto LABEL_14;
      }
    }
    else
    {
      operandsAndShape(v41, 0, 0, (uint64_t)v45, (uint64_t)&v42);
      uint64_t v17 = v43;
      if (v43)
      {
LABEL_14:
        uint64_t v18 = v42;
        uint64_t v19 = 8 * v17;
        while (*v18 < 0x8000000000000001)
        {
          ++v18;
          v19 -= 8;
          if (!v19) {
            goto LABEL_17;
          }
        }
        uint64_t v39 = "tensor dimensions must be non-negative";
        __int16 v40 = 259;
        mlir::OpState::emitError((uint64_t *)this, (uint64_t)&v39, (uint64_t)v47);
        uint64_t v20 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v47);
        if (v47[0]) {
          mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v47);
        }
        if (v54)
        {
          uint64_t v22 = __p;
          if (__p)
          {
            unint64_t v23 = v53;
            uint64_t v24 = __p;
            if (v53 != __p)
            {
              do
                unint64_t v23 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v23 - 1);
              while (v23 != v22);
              uint64_t v24 = __p;
            }
            uint64_t v53 = v22;
            operator delete(v24);
          }
          uint64_t v25 = v50;
          if (v50)
          {
            uint64_t v26 = v51;
            uint64_t v27 = v50;
            if (v51 != v50)
            {
              do
              {
                uint64_t v29 = *--v26;
                uint64_t v28 = v29;
                *uint64_t v26 = 0;
                if (v29) {
                  MEMORY[0x21667D390](v28, 0x1000C8077774924);
                }
              }
              while (v26 != v25);
              uint64_t v27 = v50;
            }
            unint64_t v51 = v25;
            operator delete(v27);
          }
          if (v48 != v49) {
            free(v48);
          }
        }
LABEL_18:
        if (v42 != v44) {
          free(v42);
        }
        uint64_t v21 = (void *)v45[0];
        if ((_WORD *)v45[0] == v46) {
          return v20;
        }
LABEL_59:
        free(v21);
        return v20;
      }
    }
LABEL_17:
    uint64_t v20 = 1;
    goto LABEL_18;
  }
LABEL_42:
  v45[0] = "must have as many index operands as dynamic extents in the result type";
  v46[8] = 259;
  mlir::OpState::emitError((uint64_t *)this, (uint64_t)v45, (uint64_t)v47);
  uint64_t v20 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v47);
  if (v47[0]) {
    mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v47);
  }
  if (v54)
  {
    long long v30 = __p;
    if (__p)
    {
      uint64_t v31 = v53;
      uint64_t v32 = __p;
      if (v53 != __p)
      {
        do
          uint64_t v31 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v31 - 1);
        while (v31 != v30);
        uint64_t v32 = __p;
      }
      uint64_t v53 = v30;
      operator delete(v32);
    }
    unint64_t v33 = v50;
    if (v50)
    {
      unint64_t v34 = v51;
      uint64_t v35 = v50;
      if (v51 != v50)
      {
        do
        {
          uint64_t v37 = *--v34;
          uint64_t v36 = v37;
          *unint64_t v34 = 0;
          if (v37) {
            MEMORY[0x21667D390](v36, 0x1000C8077774924);
          }
        }
        while (v34 != v33);
        uint64_t v35 = v50;
      }
      unint64_t v51 = v33;
      operator delete(v35);
    }
    uint64_t v21 = v48;
    if (v48 != v49) {
      goto LABEL_59;
    }
  }
  return v20;
}

void operandsAndShape(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  v43[1] = *MEMORY[0x263EF8340];
  uint64_t v40 = a1;
  uint64_t Value = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v40);
  if (v9)
  {
    uint64_t v10 = (uint64_t *)Value;
    uint64_t v11 = 0;
    uint64_t v35 = (void *)(a5 + 16);
    int64x2_t v12 = (_DWORD *)(a4 + 8);
    unint64_t v34 = (void *)(a4 + 16);
    for (uint64_t i = 8 * v9; i; i -= 8)
    {
      while (1)
      {
        uint64_t v14 = *v10;
        if (*v10 == 0x8000000000000000) {
          break;
        }
        unint64_t v29 = *(unsigned int *)(a5 + 8);
        if (v29 >= *(unsigned int *)(a5 + 12))
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod(a5, v35, v29 + 1, 8);
          unint64_t v29 = *(unsigned int *)(a5 + 8);
        }
        *(void *)(*(void *)a5 + 8 * v29) = v14;
        ++*(_DWORD *)(a5 + 8);
        ++v10;
        i -= 8;
        if (!i) {
          return;
        }
      }
      unsigned int v39 = 1;
      uint64_t v38 = 0;
      uint64_t v15 = a2 + 32 * v11;
      uint64_t v17 = *(void *)(v15 + 24);
      uint64_t v16 = (uint64_t *)(v15 + 24);
      uint64_t v37 = &v38;
      uint64_t v41 = v17;
      uint64_t DefiningOp = mlir::Value::getDefiningOp((mlir::Value *)&v41);
      if (!DefiningOp) {
        goto LABEL_28;
      }
      uint64_t v19 = DefiningOp;
      if (!mlir::OperationName::hasTrait<mlir::OpTrait::ConstantLike>((void *)(DefiningOp + 48))) {
        goto LABEL_28;
      }
      uint64_t v36 = v11;
      uint64_t v20 = a4;
      uint64_t v21 = v12;
      v42[0] = v43;
      v42[1] = (void *)0x100000000;
      mlir::Operation::fold(v19, 0, 0, (uint64_t)v42);
      uint64_t v22 = *(void *)v42[0];
      if (v42[0] != v43) {
        free(v42[0]);
      }
      unint64_t v23 = v22 & 0xFFFFFFFFFFFFFFF8;
      int64x2_t v12 = v21;
      a4 = v20;
      uint64_t v11 = v36;
      if (!v23) {
        goto LABEL_28;
      }
      uint64_t v24 = *(void **)(*(void *)(*(void *)(v19 - 8) & 0xFFFFFFFFFFFFFFF8) + 136);
      BOOL v25 = v24 == &mlir::detail::TypeIDResolver<mlir::IntegerType,void>::id
         || v24 == &mlir::detail::TypeIDResolver<mlir::IndexType,void>::id;
      BOOL v26 = v25 || v24 == &mlir::detail::TypeIDResolver<mlir::VectorType,void>::id;
      BOOL v27 = v26 || v24 == &mlir::detail::TypeIDResolver<mlir::RankedTensorType,void>::id;
      if (v27 && (mlir::detail::constant_int_value_binder::match((uint64_t *)&v37, v23) & 1) != 0)
      {
        if (v39 > 0x40) {
          uint64_t v28 = *v38;
        }
        else {
          uint64_t v28 = (uint64_t)((void)v38 << -(uint64_t)v39) >> -(uint64_t)v39;
        }
        unint64_t v33 = *(unsigned int *)(a5 + 8);
        if (v33 >= *(unsigned int *)(a5 + 12))
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod(a5, v35, v33 + 1, 8);
          unint64_t v33 = *(unsigned int *)(a5 + 8);
        }
        *(void *)(*(void *)a5 + 8 * v33) = v28;
        ++*(_DWORD *)(a5 + 8);
        if (v39 < 0x41) {
          goto LABEL_3;
        }
      }
      else
      {
LABEL_28:
        unint64_t v30 = *(unsigned int *)(a5 + 8);
        if (v30 >= *(unsigned int *)(a5 + 12))
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod(a5, v35, v30 + 1, 8);
          unint64_t v30 = *(unsigned int *)(a5 + 8);
        }
        *(void *)(*(void *)a5 + 8 * v30) = 0x8000000000000000;
        ++*(_DWORD *)(a5 + 8);
        uint64_t v31 = *v16;
        unint64_t v32 = *(unsigned int *)(a4 + 8);
        if (v32 >= *(unsigned int *)(a4 + 12))
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod(a4, v34, v32 + 1, 8);
          unint64_t v32 = *(unsigned int *)(a4 + 8);
        }
        *(void *)(*(void *)a4 + 8 * v32) = v31;
        ++*v12;
        if (v39 < 0x41) {
          goto LABEL_3;
        }
      }
      if (v38) {
        MEMORY[0x21667D390](v38, 0x1000C8000313F17);
      }
LABEL_3:
      ++v11;
      ++v10;
    }
  }
}

uint64_t mlir::tensor::GenerateOp::verifyRegions(mlir::tensor::GenerateOp *this)
{
  uint64_t v51 = *MEMORY[0x263EF8340];
  uint64_t v2 = *(void *)this;
  unint64_t v42 = *(void *)(*(void *)this - 8) & 0xFFFFFFFFFFFFFFF8;
  uint64_t ArgumentTypes = mlir::Region::getArgumentTypes((mlir::Region *)(((v2
                                                                  + 16
                                                                  * (((unint64_t)*(unsigned int *)(v2 + 44) >> 23) & 1)
                                                                  + (((unint64_t)*(unsigned int *)(v2 + 44) >> 21) & 0x7F8)
                                                                  + 71) & 0xFFFFFFFFFFFFFFF8)
                                                                + 32 * *(unsigned int *)(v2 + 40)));
  if (ArgumentTypes == v4)
  {
LABEL_5:
    unint64_t v7 = *(unsigned int *)(*(void *)this + 44);
    if ((v7 & 0x7FFFFF) != 0)
    {
      uint64_t v8 = (void *)(((*(void *)this + 16 * ((v7 >> 23) & 1) + ((v7 >> 21) & 0x7F8) + 71) & 0xFFFFFFFFFFFFFFF8)
                    + 32 * *(unsigned int *)(*(void *)this + 40));
      if ((void *)*v8 != v8) {
        goto LABEL_7;
      }
    }
    else
    {
      uint64_t v8 = 0;
      if (MEMORY[0])
      {
LABEL_7:
        uint64_t v9 = v8[1];
        if (v9) {
          uint64_t v10 = v9 - 8;
        }
        else {
          uint64_t v10 = 0;
        }
        uint64_t v11 = (*(void *)(v10 + 56) - *(void *)(v10 + 48)) >> 3;
        mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v42);
        if (v12 == v11) {
          goto LABEL_11;
        }
        goto LABEL_45;
      }
    }
    mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v42);
    if (!v32)
    {
LABEL_11:
      uint64_t v13 = *(void *)(((*(void *)this
                        + 16 * (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 23) & 1)
                        + (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 21) & 0x7F8)
                        + 71) & 0xFFFFFFFFFFFFFFF8)
                      + 32 * *(unsigned int *)(*(void *)this + 40)
                      + 8);
      if (v13) {
        uint64_t v14 = (ZinIrHalH13g **)(v13 - 8);
      }
      else {
        uint64_t v14 = 0;
      }
      mlir::Block::getTerminator(v14);
      unint64_t v16 = *(void *)(*(void *)(*(void *)(v15 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8;
      if (v16 == mlir::AffineBinaryOpExpr::getRHS((mlir::AffineBinaryOpExpr *)&v42)) {
        return 1;
      }
      __int16 v41 = 259;
      mlir::OpState::emitOpError((uint64_t *)this, v40, (uint64_t)v43);
      uint64_t v17 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v43);
      if (v43[0]) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v43);
      }
      if (!v50) {
        return v17;
      }
      uint64_t v18 = __p;
      if (__p)
      {
        uint64_t v19 = v49;
        uint64_t v20 = __p;
        if (v49 != __p)
        {
          do
            uint64_t v19 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v19 - 1);
          while (v19 != v18);
          uint64_t v20 = __p;
        }
        uint64_t v49 = v18;
        operator delete(v20);
      }
      uint64_t v21 = v46;
      if (!v46) {
        goto LABEL_61;
      }
      uint64_t v22 = v47;
      unint64_t v23 = v46;
      if (v47 == v46)
      {
LABEL_60:
        uint64_t v47 = v21;
        operator delete(v23);
LABEL_61:
        if (v44 != &v45) {
          free(v44);
        }
        return v17;
      }
      do
      {
        uint64_t v25 = *--v22;
        uint64_t v24 = v25;
        *uint64_t v22 = 0;
        if (v25) {
          MEMORY[0x21667D390](v24, 0x1000C8077774924);
        }
      }
      while (v22 != v21);
LABEL_59:
      unint64_t v23 = v46;
      goto LABEL_60;
    }
LABEL_45:
    v40[0] = (void **)"must have one body argument per input dimension";
    __int16 v41 = 259;
    mlir::OpState::emitError((uint64_t *)this, (uint64_t)v40, (uint64_t)v43);
    uint64_t v17 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v43);
    if (v43[0]) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v43);
    }
    if (!v50) {
      return v17;
    }
    unint64_t v33 = __p;
    if (__p)
    {
      unint64_t v34 = v49;
      uint64_t v35 = __p;
      if (v49 != __p)
      {
        do
          unint64_t v34 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v34 - 1);
        while (v34 != v33);
        uint64_t v35 = __p;
      }
      uint64_t v49 = v33;
      operator delete(v35);
    }
    uint64_t v21 = v46;
    if (!v46) {
      goto LABEL_61;
    }
    uint64_t v36 = v47;
    unint64_t v23 = v46;
    if (v47 == v46) {
      goto LABEL_60;
    }
    do
    {
      uint64_t v38 = *--v36;
      uint64_t v37 = v38;
      *uint64_t v36 = 0;
      if (v38) {
        MEMORY[0x21667D390](v37, 0x1000C8077774924);
      }
    }
    while (v36 != v21);
    goto LABEL_59;
  }
  uint64_t v5 = ArgumentTypes;
  uint64_t v6 = v4;
  while (1)
  {
    v43[0] = *(void *)(*(void *)v5 + 8) & 0xFFFFFFFFFFFFFFF8;
    if (!mlir::Type::isIndex((mlir::Type *)v43)) {
      break;
    }
    v5 += 8;
    if (v5 == v6) {
      goto LABEL_5;
    }
  }
  v40[0] = (void **)"all body arguments must be index";
  __int16 v41 = 259;
  mlir::OpState::emitError((uint64_t *)this, (uint64_t)v40, (uint64_t)v43);
  uint64_t v17 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v43);
  if (v43[0]) {
    mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v43);
  }
  if (v50)
  {
    BOOL v26 = __p;
    if (__p)
    {
      BOOL v27 = v49;
      uint64_t v28 = __p;
      if (v49 != __p)
      {
        do
          BOOL v27 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v27 - 1);
        while (v27 != v26);
        uint64_t v28 = __p;
      }
      uint64_t v49 = v26;
      operator delete(v28);
    }
    uint64_t v21 = v46;
    if (!v46) {
      goto LABEL_61;
    }
    unint64_t v29 = v47;
    unint64_t v23 = v46;
    if (v47 == v46) {
      goto LABEL_60;
    }
    do
    {
      uint64_t v31 = *--v29;
      uint64_t v30 = v31;
      void *v29 = 0;
      if (v31) {
        MEMORY[0x21667D390](v30, 0x1000C8077774924);
      }
    }
    while (v29 != v21);
    goto LABEL_59;
  }
  return v17;
}

void mlir::tensor::GenerateOp::getCanonicalizationPatterns()
{
}

uint64_t mlir::tensor::RankOp::getAsmResultNames(void *a1, uint64_t (*a2)(uint64_t, uint64_t, const char *, uint64_t), uint64_t a3)
{
  return a2(a3, *a1 - 16, "rank", 4);
}

uint64_t mlir::tensor::ReshapeOp::verify(mlir::tensor::ReshapeOp *this)
{
  uint64_t v84 = *MEMORY[0x263EF8340];
  uint64_t v2 = *(void *)this;
  unint64_t v74 = *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8;
  int v3 = *(_DWORD *)(v2 + 36);
  uint64_t v4 = v2 - 16;
  if (v3) {
    uint64_t v5 = v4;
  }
  else {
    uint64_t v5 = 0;
  }
  unint64_t v73 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v5, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
  uint64_t ElementType = mlir::TensorType::getElementType((mlir::TensorType *)&v74);
  if (ElementType != mlir::TensorType::getElementType((mlir::TensorType *)&v73))
  {
    v71[0] = (void **)"element types of source and destination tensor types should be the same";
    __int16 v72 = 259;
    mlir::OpState::emitOpError((uint64_t *)this, v71, (uint64_t)&v75);
    uint64_t v7 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v75);
    if (v75) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v75);
    }
    if (v83)
    {
      uint64_t v8 = __p;
      if (__p)
      {
        uint64_t v9 = v82;
        uint64_t v10 = __p;
        if (v82 != __p)
        {
          do
            uint64_t v9 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v9 - 1);
          while (v9 != v8);
          uint64_t v10 = __p;
        }
        unint64_t v82 = v8;
        operator delete(v10);
      }
      uint64_t v11 = v79;
      if (!v79) {
        goto LABEL_93;
      }
      uint64_t v12 = v80;
      uint64_t v13 = v79;
      if (v80 == v79)
      {
LABEL_92:
        unint64_t v80 = v11;
        operator delete(v13);
LABEL_93:
        if (v77 != &v78) {
          free(v77);
        }
        return v7;
      }
      do
      {
        uint64_t v15 = *--v12;
        uint64_t v14 = v15;
        *uint64_t v12 = 0;
        if (v15) {
          MEMORY[0x21667D390](v14, 0x1000C8077774924);
        }
      }
      while (v12 != v11);
LABEL_91:
      uint64_t v13 = v79;
      goto LABEL_92;
    }
    return v7;
  }
  unint64_t v75 = *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 56) + 8) & 0xFFFFFFFFFFFFFFF8;
  uint64_t v16 = *(void *)mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v75);
  uint64_t v17 = (void *)v73;
  uint64_t v18 = (void *)v74;
  uint64_t v19 = *(void **)(*(void *)v73 + 136);
  if (v19 != &mlir::detail::TypeIDResolver<mlir::RankedTensorType,void>::id) {
    uint64_t v17 = 0;
  }
  unsigned int v70 = v17;
  uint64_t v20 = *(void **)(*(void *)v74 + 136);
  if (v20 != &mlir::detail::TypeIDResolver<mlir::RankedTensorType,void>::id) {
    uint64_t v18 = 0;
  }
  uint64_t v69 = v18;
  if (v19 != &mlir::detail::TypeIDResolver<mlir::RankedTensorType,void>::id) {
    return 1;
  }
  if (v20 == &mlir::detail::TypeIDResolver<mlir::RankedTensorType,void>::id
    && mlir::TensorType::hasRank((mlir::TensorType *)&v70))
  {
    uint64_t Value = (void *)mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v70);
    if (v22)
    {
      uint64_t v23 = 8 * v22;
      while (*Value != 0x8000000000000000)
      {
        ++Value;
        v23 -= 8;
        if (!v23) {
          goto LABEL_31;
        }
      }
      goto LABEL_61;
    }
LABEL_31:
    if (!mlir::TensorType::hasRank((mlir::TensorType *)&v69)) {
      goto LABEL_61;
    }
    uint64_t v24 = (void *)mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v69);
    if (v25)
    {
      uint64_t v26 = 8 * v25;
      while (*v24 != 0x8000000000000000)
      {
        ++v24;
        v26 -= 8;
        if (!v26) {
          goto LABEL_36;
        }
      }
      goto LABEL_61;
    }
LABEL_36:
    BOOL v27 = v69;
    if (v69) {
      uint64_t v28 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*v69 + 8);
    }
    else {
      uint64_t v28 = 0;
    }
    unint64_t v75 = (unint64_t)v27;
    uint64_t v76 = v28;
    uint64_t Shape = mlir::ShapedType::getShape((mlir::ShapedType *)&v75);
    if (v30)
    {
      uint64_t v31 = (v30 - 1) & 0x1FFFFFFFFFFFFFFFLL;
      if (v31)
      {
        uint64_t v32 = v31 + 1;
        uint64_t v33 = (v31 + 1) & 0x3FFFFFFFFFFFFFFELL;
        unint64_t v34 = (uint64_t *)(Shape + 8 * v33);
        uint64_t v35 = (void *)(Shape + 8);
        uint64_t v36 = 1;
        uint64_t v37 = v33;
        uint64_t v38 = 1;
        do
        {
          v36 *= *(v35 - 1);
          v38 *= *v35;
          v35 += 2;
          v37 -= 2;
        }
        while (v37);
        uint64_t v39 = v38 * v36;
        if (v32 == v33) {
          goto LABEL_48;
        }
      }
      else
      {
        uint64_t v39 = 1;
        unint64_t v34 = (uint64_t *)Shape;
      }
      do
      {
        uint64_t v40 = *v34++;
        v39 *= v40;
      }
      while (v34 != (uint64_t *)(Shape + 8 * v30));
    }
    else
    {
      uint64_t v39 = 1;
    }
LABEL_48:
    __int16 v41 = v70;
    if (v70) {
      uint64_t v42 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*v70 + 8);
    }
    else {
      uint64_t v42 = 0;
    }
    unint64_t v75 = (unint64_t)v41;
    uint64_t v76 = v42;
    uint64_t v43 = mlir::ShapedType::getShape((mlir::ShapedType *)&v75);
    if (!v44)
    {
      uint64_t v53 = 1;
      goto LABEL_60;
    }
    uint64_t v45 = (v44 - 1) & 0x1FFFFFFFFFFFFFFFLL;
    if (v45)
    {
      uint64_t v46 = v45 + 1;
      uint64_t v47 = (v45 + 1) & 0x3FFFFFFFFFFFFFFELL;
      long long v48 = (uint64_t *)(v43 + 8 * v47);
      uint64_t v49 = (void *)(v43 + 8);
      uint64_t v50 = 1;
      uint64_t v51 = v47;
      uint64_t v52 = 1;
      do
      {
        v50 *= *(v49 - 1);
        v52 *= *v49;
        v49 += 2;
        v51 -= 2;
      }
      while (v51);
      uint64_t v53 = v52 * v50;
      if (v46 == v47)
      {
LABEL_60:
        if (v39 != v53)
        {
          v71[0] = (void **)"source and destination tensor should have the same number of elements";
          __int16 v72 = 259;
          mlir::OpState::emitOpError((uint64_t *)this, v71, (uint64_t)&v75);
          uint64_t v7 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v75);
          mlir::InFlightDiagnostic::~InFlightDiagnostic((mlir::InFlightDiagnostic *)&v75);
          return v7;
        }
        goto LABEL_61;
      }
    }
    else
    {
      uint64_t v53 = 1;
      long long v48 = (uint64_t *)v43;
    }
    do
    {
      uint64_t v54 = *v48++;
      v53 *= v54;
    }
    while (v48 != (uint64_t *)(v43 + 8 * v44));
    goto LABEL_60;
  }
LABEL_61:
  if (v16 != 0x8000000000000000)
  {
    mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v70);
    if (v16 != v61)
    {
      v71[0] = (void **)"length of shape operand differs from the result's tensor rank";
      __int16 v72 = 259;
      mlir::OpState::emitOpError((uint64_t *)this, v71, (uint64_t)&v75);
      uint64_t v7 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v75);
      if (v75) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v75);
      }
      if (v83)
      {
        long long v62 = __p;
        if (__p)
        {
          int64_t v63 = v82;
          int64_t v64 = __p;
          if (v82 != __p)
          {
            do
              int64_t v63 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v63 - 1);
            while (v63 != v62);
            int64_t v64 = __p;
          }
          unint64_t v82 = v62;
          operator delete(v64);
        }
        uint64_t v11 = v79;
        if (!v79) {
          goto LABEL_93;
        }
        unint64_t v65 = v80;
        uint64_t v13 = v79;
        if (v80 == v79) {
          goto LABEL_92;
        }
        do
        {
          uint64_t v67 = *--v65;
          uint64_t v66 = v67;
          *unint64_t v65 = 0;
          if (v67) {
            MEMORY[0x21667D390](v66, 0x1000C8077774924);
          }
        }
        while (v65 != v11);
        goto LABEL_91;
      }
      return v7;
    }
    return 1;
  }
  v71[0] = (void **)"cannot use shape operand with dynamic length to reshape to statically-ranked tensor type";
  __int16 v72 = 259;
  mlir::OpState::emitOpError((uint64_t *)this, v71, (uint64_t)&v75);
  uint64_t v7 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v75);
  if (v75) {
    mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v75);
  }
  if (v83)
  {
    uint64_t v55 = __p;
    if (__p)
    {
      unint64_t v56 = v82;
      unint64_t v57 = __p;
      if (v82 != __p)
      {
        do
          unint64_t v56 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v56 - 1);
        while (v56 != v55);
        unint64_t v57 = __p;
      }
      unint64_t v82 = v55;
      operator delete(v57);
    }
    uint64_t v11 = v79;
    if (!v79) {
      goto LABEL_93;
    }
    long long v58 = v80;
    uint64_t v13 = v79;
    if (v80 == v79) {
      goto LABEL_92;
    }
    do
    {
      uint64_t v60 = *--v58;
      uint64_t v59 = v60;
      *long long v58 = 0;
      if (v60) {
        MEMORY[0x21667D390](v59, 0x1000C8077774924);
      }
    }
    while (v58 != v11);
    goto LABEL_91;
  }
  return v7;
}

unint64_t mlir::tensor::ReshapeOp::fold(uint64_t a1, uint64_t a2)
{
  int v3 = *(uint64_t **)(a2 + 40);
  unint64_t v4 = *v3;
  if (*v3 && !mlir::DenseElementsAttr::classof(*v3)) {
    unint64_t v4 = 0;
  }
  if (*(_DWORD *)(*(void *)a1 + 36)) {
    uint64_t v5 = *(void *)a1 - 16;
  }
  else {
    uint64_t v5 = 0;
  }
  uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v5, 0);
  unint64_t result = reshapeConstantSource(v4, (void *)(*(void *)(NextResultAtOffset + 8) & 0xFFFFFFFFFFFFFFF8));
  if (result <= 7) {
    return 0;
  }
  return result;
}

uint64_t mlir::tensor::CollapseShapeOp::getAsmResultNames(uint64_t a1, uint64_t (*a2)(uint64_t, uint64_t, const char *, uint64_t), uint64_t a3)
{
  if (*(_DWORD *)(*(void *)a1 + 36)) {
    uint64_t v4 = *(void *)a1 - 16;
  }
  else {
    uint64_t v4 = 0;
  }
  uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v4, 0);

  return a2(a3, NextResultAtOffset, "collapsed", 9);
}

uint64_t mlir::tensor::ExpandShapeOp::getAsmResultNames(uint64_t a1, uint64_t (*a2)(uint64_t, uint64_t, const char *, uint64_t), uint64_t a3)
{
  if (*(_DWORD *)(*(void *)a1 + 36)) {
    uint64_t v4 = *(void *)a1 - 16;
  }
  else {
    uint64_t v4 = 0;
  }
  uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v4, 0);

  return a2(a3, NextResultAtOffset, "expanded", 8);
}

uint64_t mlir::tensor::ExpandShapeOp::getCorrespondingSourceDim(mlir::tensor::ExpandShapeOp *this, uint64_t a2)
{
  v21[16] = *MEMORY[0x263EF8340];
  mlir::memref::CollapseShapeOp::getReassociationIndices(this, (uint64_t)&v16);
  uint64_t v19 = v21;
  uint64_t v20 = 0x400000000;
  if (v17)
  {
    llvm::SmallVectorImpl<llvm::SmallVector<long long,2u>>::operator=((uint64_t)&v19, (uint64_t)&v16);
    int v3 = (char *)v16;
    if (!v17) {
      goto LABEL_8;
    }
    uint64_t v4 = 32 * v17;
    do
    {
      uint64_t v5 = *(char **)&v3[v4 - 32];
      if (&v3[v4 - 16] != v5) {
        free(v5);
      }
      v4 -= 32;
    }
    while (v4);
  }
  int v3 = (char *)v16;
LABEL_8:
  if (v3 != (char *)&v18) {
    free(v3);
  }
  uint64_t v6 = (char *)v19;
  if (!v20)
  {
    uint64_t v7 = 0;
    if (v19 == v21) {
      return v7;
    }
    goto LABEL_26;
  }
  uint64_t v7 = 0;
  uint64_t v8 = v19;
  while (1)
  {
    uint64_t v9 = (void *)*v8;
    uint64_t v10 = *((unsigned int *)v8 + 2);
    if (v10)
    {
      uint64_t v11 = 8 * v10;
      uint64_t v12 = (void *)*v8;
      while (*v12 != a2)
      {
        ++v12;
        v11 -= 8;
        if (!v11)
        {
          uint64_t v12 = &v9[v10];
          break;
        }
      }
    }
    else
    {
      uint64_t v12 = (void *)*v8;
    }
    if (v10 != v12 - v9) {
      break;
    }
    ++v7;
    v8 += 4;
    if (v8 == (void *)((char *)v19 + 32 * v20))
    {
      uint64_t v7 = ((v20 - 1) & 0x7FFFFFFFFFFFFFFLL) + 1;
      break;
    }
  }
  uint64_t v13 = 32 * v20;
  do
  {
    uint64_t v14 = *(char **)&v6[v13 - 32];
    if (&v6[v13 - 16] != v14) {
      free(v14);
    }
    v13 -= 32;
  }
  while (v13);
  uint64_t v6 = (char *)v19;
  if (v19 != v21) {
LABEL_26:
  }
    free(v6);
  return v7;
}

void mlir::tensor::CollapseShapeOp::getReassociationExprs(mlir::tensor::CollapseShapeOp *this@<X0>, void *a2@<X8>)
{
  v16[8] = *MEMORY[0x263EF8340];
  uint64_t Context = (mlir::MLIRContext *)mlir::Attribute::getContext((mlir::Attribute *)(*(void *)this + 24));
  mlir::memref::CollapseShapeOp::getReassociationIndices(this, (uint64_t)&v11);
  mlir::convertReassociationIndicesToExprs(Context, (unsigned int **)v11, v12, (uint64_t)&v14);
  *a2 = a2 + 2;
  a2[1] = 0x400000000;
  if (v15)
  {
    llvm::SmallVectorImpl<llvm::SmallVector<long long,2u>>::operator=((uint64_t)a2, (uint64_t)&v14);
    uint64_t v5 = v14;
    if (!v15) {
      goto LABEL_8;
    }
    uint64_t v6 = 32 * v15;
    do
    {
      uint64_t v7 = *(char **)&v5[v6 - 32];
      if (&v5[v6 - 16] != v7) {
        free(v7);
      }
      v6 -= 32;
    }
    while (v6);
  }
  uint64_t v5 = v14;
LABEL_8:
  if (v5 != (char *)v16) {
    free(v5);
  }
  uint64_t v8 = (char *)v11;
  if (v12)
  {
    uint64_t v9 = 32 * v12;
    do
    {
      uint64_t v10 = *(char **)&v8[v9 - 32];
      if (&v8[v9 - 16] != v10) {
        free(v10);
      }
      v9 -= 32;
    }
    while (v9);
    uint64_t v8 = (char *)v11;
  }
  if (v8 != (char *)&v13) {
    free(v8);
  }
}

uint64_t mlir::tensor::CollapseShapeOp::inferCollapsedType(uint64_t a1, uint64_t *a2, unint64_t a3)
{
  v32[4] = *MEMORY[0x263EF8340];
  uint64_t v29 = a1;
  uint64_t Value = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v29);
  uint64_t v30 = v32;
  uint64_t v31 = 0x400000000;
  if (a3 >= 5)
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v30, v32, a3, 8);
LABEL_4:
    unsigned int v6 = 0;
    uint64_t v7 = &a2[a3];
    while (1)
    {
      uint64_t v28 = *a2;
      unsigned int Kind = mlir::AffineExpr::getKind((mlir::AffineExpr *)&v28);
      unsigned int v9 = Kind;
      if (Kind)
      {
        uint64_t v10 = (void *)(Value + 8 * v6);
        uint64_t v11 = 8 * Kind;
        unsigned int v12 = v10;
        while (*v12 != 0x8000000000000000)
        {
          ++v12;
          v11 -= 8;
          if (!v11)
          {
            unsigned int v12 = &v10[Kind];
            break;
          }
        }
        if (Kind == v12 - v10)
        {
          if (Kind < 2)
          {
            uint64_t v13 = 0;
            goto LABEL_21;
          }
          uint64_t v13 = 0;
          if (__CFADD__(v6, Kind - 1))
          {
LABEL_21:
            unint64_t v14 = 1;
          }
          else
          {
            unint64_t v14 = 1;
            if (!(((unint64_t)Kind - 1) >> 32))
            {
              uint64_t v13 = Kind & 0xFFFFFFFE;
              unsigned int v15 = v6;
              uint64_t v16 = v13;
              uint64_t v17 = 1;
              uint64_t v18 = 1;
              do
              {
                v17 *= *(void *)(Value + 8 * v15);
                v18 *= *(void *)(Value + 8 * (v15 + 1));
                v15 += 2;
                v16 -= 2;
              }
              while (v16);
              unint64_t v14 = v18 * v17;
              if (v13 == Kind) {
                goto LABEL_24;
              }
            }
          }
          unsigned int v19 = v6 + v13;
          uint64_t v20 = Kind - v13;
          do
          {
            v14 *= *(void *)(Value + 8 * v19++);
            --v20;
          }
          while (v20);
          goto LABEL_24;
        }
        unint64_t v14 = 0x8000000000000000;
      }
      else
      {
        unint64_t v14 = 1;
      }
LABEL_24:
      uint64_t v21 = v31;
      if (v31 >= (unint64_t)HIDWORD(v31))
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v30, v32, v31 + 1, 8);
        uint64_t v21 = v31;
      }
      *((void *)v30 + v21) = v14;
      unsigned int v22 = v31 + 1;
      LODWORD(v31) = v31 + 1;
      v6 += v9;
      if (++a2 == v7) {
        goto LABEL_29;
      }
    }
  }
  if (a3) {
    goto LABEL_4;
  }
  unsigned int v22 = v31;
LABEL_29:
  uint64_t v23 = v30;
  uint64_t v24 = v22;
  uint64_t RHS = mlir::AffineBinaryOpExpr::getRHS((mlir::AffineBinaryOpExpr *)&v29);
  uint64_t v26 = mlir::RankedTensorType::get((uint64_t)v23, v24, RHS, 0);
  if (v30 != v32) {
    free(v30);
  }
  return v26;
}

uint64_t mlir::tensor::ExpandShapeOp::verify(mlir::tensor::ExpandShapeOp *this)
{
  uint64_t v291 = *MEMORY[0x263EF8340];
  uint64_t v2 = *(void *)this;
  unint64_t v260 = *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8;
  int v3 = *(_DWORD *)(v2 + 36);
  uint64_t v4 = v2 - 16;
  if (v3) {
    uint64_t v5 = v4;
  }
  else {
    uint64_t v5 = 0;
  }
  unint64_t v259 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v5, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v260);
  uint64_t v7 = v6;
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v259);
  if (v7 >= v8)
  {
    uint64_t v275 = (mlir::AffineMap *)"expected rank expansion, but found source rank ";
    __int16 v278 = 259;
    mlir::OpState::emitOpError((uint64_t *)this, (void ***)&v275, (uint64_t)&v279);
    mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v260);
    if (v279)
    {
      LODWORD(v263) = 2;
      uint64_t v264 = v38;
      uint64_t v39 = &v263;
      uint64_t v40 = (char *)v282;
      if (v283 >= v284)
      {
        unint64_t v210 = v283 + 1;
        if (v282 <= &v263 && (char *)v282 + 24 * v283 > (char *)&v263)
        {
          int64_t v239 = (char *)&v263 - (unsigned char *)v282;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v210, 24);
          uint64_t v40 = (char *)v282;
          uint64_t v39 = (void ***)((char *)v282 + v239);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v210, 24);
          uint64_t v39 = &v263;
          uint64_t v40 = (char *)v282;
        }
      }
      __int16 v41 = &v40[24 * v283];
      long long v42 = *(_OWORD *)v39;
      *((void *)v41 + 2) = v39[2];
      *(_OWORD *)__int16 v41 = v42;
      uint64_t v43 = ++v283;
      if (v279)
      {
        LODWORD(v263) = 3;
        uint64_t v264 = " >= result rank ";
        uint64_t v265 = 16;
        uint64_t v44 = &v263;
        uint64_t v45 = (char *)v282;
        if (v43 >= v284)
        {
          unint64_t v212 = v43 + 1;
          BOOL v213 = (char *)v282 + 24 * v43 > (char *)&v263;
          if (v282 <= &v263 && v213)
          {
            int64_t v241 = (char *)&v263 - (unsigned char *)v282;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v212, 24);
            uint64_t v45 = (char *)v282;
            uint64_t v44 = (void ***)((char *)v282 + v241);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v212, 24);
            uint64_t v44 = &v263;
            uint64_t v45 = (char *)v282;
          }
        }
        uint64_t v46 = &v45[24 * v283];
        long long v47 = *(_OWORD *)v44;
        *((void *)v46 + 2) = v44[2];
        *(_OWORD *)uint64_t v46 = v47;
        ++v283;
      }
    }
    mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v259);
    if (v279)
    {
      LODWORD(v263) = 2;
      uint64_t v264 = v48;
      uint64_t v49 = &v263;
      uint64_t v50 = (char *)v282;
      if (v283 >= v284)
      {
        unint64_t v211 = v283 + 1;
        if (v282 <= &v263 && (char *)v282 + 24 * v283 > (char *)&v263)
        {
          int64_t v240 = (char *)&v263 - (unsigned char *)v282;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v211, 24);
          uint64_t v50 = (char *)v282;
          uint64_t v49 = (void ***)((char *)v282 + v240);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v211, 24);
          uint64_t v49 = &v263;
          uint64_t v50 = (char *)v282;
        }
      }
      uint64_t v51 = &v50[24 * v283];
      long long v52 = *(_OWORD *)v49;
      *((void *)v51 + 2) = v49[2];
      *(_OWORD *)uint64_t v51 = v52;
      ++v283;
    }
    uint64_t v53 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v279);
    if (v279) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v279);
    }
    if (v290)
    {
      uint64_t v54 = __p;
      if (__p)
      {
        uint64_t v55 = v289;
        unint64_t v56 = __p;
        if (v289 != __p)
        {
          do
            uint64_t v55 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v55 - 1);
          while (v55 != v54);
          unint64_t v56 = __p;
        }
        uint64_t v289 = v54;
        operator delete(v56);
      }
      unint64_t v57 = v286;
      if (v286)
      {
        long long v58 = v287;
        uint64_t v59 = v286;
        if (v287 != v286)
        {
          do
          {
            uint64_t v61 = *--v58;
            uint64_t v60 = v61;
            *long long v58 = 0;
            if (v61) {
              MEMORY[0x21667D390](v60, 0x1000C8077774924);
            }
          }
          while (v58 != v57);
          uint64_t v59 = v286;
        }
        uint64_t v287 = v57;
        operator delete(v59);
      }
      uint64_t v68 = v282;
      if (v282 != v285) {
        goto LABEL_189;
      }
    }
    return v53;
  }
  uint64_t v9 = *(void *)this;
  if (*(_DWORD *)(*(void *)this + 36)) {
    uint64_t v10 = *(void *)this - 16;
  }
  else {
    uint64_t v10 = 0;
  }
  uint64_t v11 = (void *)(*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v10, 0) + 8) & 0xFFFFFFFFFFFFFFF8);
  unsigned int v12 = (void **)(*(void *)(*(void *)(*(void *)(*(void *)this + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8);
  uint64_t v261 = v9;
  uint64_t v268 = v11;
  uint64_t v269 = v9;
  uint64_t v267 = v12;
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v268);
  unsigned int v14 = v13;
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v267);
  if (v14 < v15)
  {
    uint64_t v275 = (mlir::AffineMap *)"expected the type ";
    __int16 v278 = 259;
    mlir::OpState::emitOpError(&v269, (void ***)&v275, (uint64_t)&v279);
    if (v279)
    {
      uint64_t v16 = &v263;
      mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v263, (uint64_t)v268);
      uint64_t v17 = (char *)v282;
      if (v283 >= v284)
      {
        unint64_t v214 = v283 + 1;
        if (v282 <= &v263 && (char *)v282 + 24 * v283 > (char *)&v263)
        {
          int64_t v242 = (char *)&v263 - (unsigned char *)v282;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v214, 24);
          uint64_t v17 = (char *)v282;
          uint64_t v16 = (void ***)((char *)v282 + v242);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v214, 24);
          uint64_t v16 = &v263;
          uint64_t v17 = (char *)v282;
        }
      }
      uint64_t v18 = &v17[24 * v283];
      long long v19 = *(_OWORD *)v16;
      *((void *)v18 + 2) = v16[2];
      *(_OWORD *)uint64_t v18 = v19;
      uint64_t v20 = ++v283;
      if (v279)
      {
        LODWORD(v263) = 3;
        uint64_t v264 = " to have higher rank than the type = ";
        uint64_t v265 = 37;
        uint64_t v21 = &v263;
        unsigned int v22 = (char *)v282;
        if (v20 >= v284)
        {
          unint64_t v216 = v20 + 1;
          BOOL v217 = (char *)v282 + 24 * v20 > (char *)&v263;
          if (v282 <= &v263 && v217)
          {
            int64_t v244 = (char *)&v263 - (unsigned char *)v282;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v216, 24);
            unsigned int v22 = (char *)v282;
            uint64_t v21 = (void ***)((char *)v282 + v244);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v216, 24);
            uint64_t v21 = &v263;
            unsigned int v22 = (char *)v282;
          }
        }
        uint64_t v23 = &v22[24 * v283];
        long long v24 = *(_OWORD *)v21;
        *((void *)v23 + 2) = v21[2];
        *(_OWORD *)uint64_t v23 = v24;
        ++v283;
        if (v279)
        {
          uint64_t v25 = &v263;
          mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v263, (uint64_t)v267);
          uint64_t v26 = (char *)v282;
          if (v283 >= v284)
          {
            unint64_t v220 = v283 + 1;
            if (v282 <= &v263 && (char *)v282 + 24 * v283 > (char *)&v263)
            {
              int64_t v246 = (char *)&v263 - (unsigned char *)v282;
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v220, 24);
              uint64_t v26 = (char *)v282;
              uint64_t v25 = (void ***)((char *)v282 + v246);
            }
            else
            {
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v220, 24);
              uint64_t v25 = &v263;
              uint64_t v26 = (char *)v282;
            }
          }
          BOOL v27 = &v26[24 * v283];
          long long v28 = *(_OWORD *)v25;
          *((void *)v27 + 2) = v25[2];
          *(_OWORD *)BOOL v27 = v28;
          ++v283;
        }
      }
    }
    char v29 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v279);
    if (v279) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v279);
    }
    if (v290)
    {
      uint64_t v30 = __p;
      if (__p)
      {
        uint64_t v31 = v289;
        uint64_t v32 = __p;
        if (v289 != __p)
        {
          do
            uint64_t v31 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v31 - 1);
          while (v31 != v30);
          uint64_t v32 = __p;
        }
        uint64_t v289 = v30;
        operator delete(v32);
      }
      uint64_t v33 = v286;
      if (v286)
      {
        unint64_t v34 = v287;
        uint64_t v35 = v286;
        if (v287 == v286) {
          goto LABEL_148;
        }
        do
        {
          uint64_t v37 = *--v34;
          uint64_t v36 = v37;
          *unint64_t v34 = 0;
          if (v37) {
            MEMORY[0x21667D390](v36, 0x1000C8077774924);
          }
        }
        while (v34 != v33);
LABEL_147:
        uint64_t v35 = v286;
LABEL_148:
        uint64_t v287 = v33;
        operator delete(v35);
        goto LABEL_149;
      }
      goto LABEL_149;
    }
    goto LABEL_151;
  }
  if (!v14)
  {
    uint64_t v275 = (mlir::AffineMap *)"expected non-zero memref ranks";
    __int16 v278 = 259;
    mlir::OpState::emitOpError(&v269, (void ***)&v275, (uint64_t)&v279);
    char v29 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v279);
    if (v279) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v279);
    }
    if (v290)
    {
      uint64_t v69 = __p;
      if (__p)
      {
        unsigned int v70 = v289;
        uint64_t v71 = __p;
        if (v289 != __p)
        {
          do
            unsigned int v70 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v70 - 1);
          while (v70 != v69);
          uint64_t v71 = __p;
        }
        uint64_t v289 = v69;
        operator delete(v71);
      }
      uint64_t v33 = v286;
      if (v286)
      {
        __int16 v72 = v287;
        uint64_t v35 = v286;
        if (v287 == v286) {
          goto LABEL_148;
        }
        do
        {
          uint64_t v74 = *--v72;
          uint64_t v73 = v74;
          *__int16 v72 = 0;
          if (v74) {
            MEMORY[0x21667D390](v73, 0x1000C8077774924);
          }
        }
        while (v72 != v33);
        goto LABEL_147;
      }
      goto LABEL_149;
    }
    goto LABEL_151;
  }
  if (v14 == v15)
  {
    uint64_t v275 = (mlir::AffineMap *)"expected to collapse or expand dims";
    __int16 v278 = 259;
    mlir::OpState::emitOpError(&v269, (void ***)&v275, (uint64_t)&v279);
    char v29 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v279);
    if (v279) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v279);
    }
    if (v290)
    {
      long long v62 = __p;
      if (__p)
      {
        int64_t v63 = v289;
        int64_t v64 = __p;
        if (v289 != __p)
        {
          do
            int64_t v63 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v63 - 1);
          while (v63 != v62);
          int64_t v64 = __p;
        }
        uint64_t v289 = v62;
        operator delete(v64);
      }
      uint64_t v33 = v286;
      if (v286)
      {
        unint64_t v65 = v287;
        uint64_t v35 = v286;
        if (v287 == v286) {
          goto LABEL_148;
        }
        do
        {
          uint64_t v67 = *--v65;
          uint64_t v66 = v67;
          *unint64_t v65 = 0;
          if (v67) {
            MEMORY[0x21667D390](v66, 0x1000C8077774924);
          }
        }
        while (v65 != v33);
        goto LABEL_147;
      }
      goto LABEL_149;
    }
    goto LABEL_151;
  }
  if (v15)
  {
    unint64_t v75 = (const char *)v15;
    uint64_t v279 = *(void **)(v9 + 16 * (((unint64_t)*(unsigned int *)(v9 + 44) >> 23) & 1) + 64);
    mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v279);
    if (v75 != v76)
    {
      uint64_t v275 = (mlir::AffineMap *)"expected rank of the collapsed type(";
      __int16 v278 = 259;
      mlir::OpState::emitOpError(&v269, (void ***)&v275, (uint64_t)&v279);
      if (v279)
      {
        LODWORD(v263) = 5;
        uint64_t v264 = v75;
        char v83 = &v263;
        uint64_t v84 = (char *)v282;
        if (v283 >= v284)
        {
          unint64_t v222 = v283 + 1;
          if (v282 <= &v263 && (char *)v282 + 24 * v283 > (char *)&v263)
          {
            int64_t v248 = (char *)&v263 - (unsigned char *)v282;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v222, 24);
            uint64_t v84 = (char *)v282;
            char v83 = (void ***)((char *)v282 + v248);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v222, 24);
            char v83 = &v263;
            uint64_t v84 = (char *)v282;
          }
        }
        unint64_t v85 = &v84[24 * v283];
        long long v86 = *(_OWORD *)v83;
        *((void *)v85 + 2) = v83[2];
        *(_OWORD *)unint64_t v85 = v86;
        uint64_t v87 = ++v283;
        if (v279)
        {
          LODWORD(v263) = 3;
          uint64_t v264 = ") to be the number of reassociation maps(";
          uint64_t v265 = 41;
          int64_t v88 = &v263;
          int64_t v89 = (char *)v282;
          if (v87 >= v284)
          {
            unint64_t v224 = v87 + 1;
            BOOL v225 = (char *)v282 + 24 * v87 > (char *)&v263;
            if (v282 <= &v263 && v225)
            {
              int64_t v250 = (char *)&v263 - (unsigned char *)v282;
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v224, 24);
              int64_t v89 = (char *)v282;
              int64_t v88 = (void ***)((char *)v282 + v250);
            }
            else
            {
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v224, 24);
              int64_t v88 = &v263;
              int64_t v89 = (char *)v282;
            }
          }
          int64_t v90 = &v89[24 * v283];
          long long v91 = *(_OWORD *)v88;
          *((void *)v90 + 2) = v88[2];
          *(_OWORD *)int64_t v90 = v91;
          ++v283;
        }
      }
      uint64_t v272 = *(void **)(v269 + 16 * (((unint64_t)*(unsigned int *)(v269 + 44) >> 23) & 1) + 64);
      mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v272);
      if (v279)
      {
        LODWORD(v263) = 5;
        uint64_t v264 = v92;
        int64_t v93 = &v263;
        int v94 = (char *)v282;
        if (v283 >= v284)
        {
          unint64_t v223 = v283 + 1;
          if (v282 <= &v263 && (char *)v282 + 24 * v283 > (char *)&v263)
          {
            int64_t v249 = (char *)&v263 - (unsigned char *)v282;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v223, 24);
            int v94 = (char *)v282;
            int64_t v93 = (void ***)((char *)v282 + v249);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v223, 24);
            int64_t v93 = &v263;
            int v94 = (char *)v282;
          }
        }
        unint64_t v95 = &v94[24 * v283];
        long long v96 = *(_OWORD *)v93;
        *((void *)v95 + 2) = v93[2];
        *(_OWORD *)unint64_t v95 = v96;
        uint64_t v97 = ++v283;
        if (v279)
        {
          LODWORD(v263) = 3;
          uint64_t v264 = ")";
          uint64_t v265 = 1;
          uint64_t v98 = &v263;
          int v99 = (char *)v282;
          if (v97 >= v284)
          {
            unint64_t v226 = v97 + 1;
            BOOL v227 = (char *)v282 + 24 * v97 > (char *)&v263;
            if (v282 <= &v263 && v227)
            {
              int64_t v251 = (char *)&v263 - (unsigned char *)v282;
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v226, 24);
              int v99 = (char *)v282;
              uint64_t v98 = (void ***)((char *)v282 + v251);
            }
            else
            {
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v226, 24);
              uint64_t v98 = &v263;
              int v99 = (char *)v282;
            }
          }
          uint64_t v100 = &v99[24 * v283];
          long long v101 = *(_OWORD *)v98;
          *((void *)v100 + 2) = v98[2];
          *(_OWORD *)uint64_t v100 = v101;
          ++v283;
        }
      }
      char v29 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v279);
      if (v279) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v279);
      }
      if (v290)
      {
        uint64_t v102 = __p;
        if (__p)
        {
          int v103 = v289;
          unint64_t v104 = __p;
          if (v289 != __p)
          {
            do
              int v103 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v103 - 1);
            while (v103 != v102);
            unint64_t v104 = __p;
          }
          uint64_t v289 = v102;
          operator delete(v104);
        }
        uint64_t v33 = v286;
        if (v286)
        {
          unsigned int v105 = v287;
          uint64_t v35 = v286;
          if (v287 == v286) {
            goto LABEL_148;
          }
          do
          {
            uint64_t v107 = *--v105;
            uint64_t v106 = v107;
            *unsigned int v105 = 0;
            if (v107) {
              MEMORY[0x21667D390](v106, 0x1000C8077774924);
            }
          }
          while (v105 != v33);
          goto LABEL_147;
        }
        goto LABEL_149;
      }
      goto LABEL_151;
    }
    mlir::tensor::CollapseShapeOp::getReassociationExprs((mlir::tensor::CollapseShapeOp *)&v269, &v279);
    mlir::getSymbolLessAffineMaps((uint64_t)v279, v280, (uint64_t)&v275);
    uint64_t v77 = (char *)v279;
    if (v280)
    {
      uint64_t v78 = 32 * v280;
      do
      {
        char v79 = *(char **)&v77[v78 - 32];
        if (&v77[v78 - 16] != v79) {
          free(v79);
        }
        v78 -= 32;
      }
      while (v78);
      uint64_t v77 = (char *)v279;
    }
    if (v77 != (char *)&v281) {
      free(v77);
    }
    int v108 = v275;
    unsigned int v109 = v276;
    if (v276)
    {
      unint64_t v110 = 0;
      unint64_t v111 = (const char *)v14;
      uint64_t v112 = 8 * v276;
      while (mlir::AffineMap::getNumDims(v108) == v14)
      {
        ++v110;
        int v108 = (mlir::AffineMap *)((char *)v108 + 8);
        v112 -= 8;
        if (!v112)
        {
          int v108 = v275;
          unsigned int v109 = v276;
          goto LABEL_130;
        }
      }
      uint64_t v263 = (void **)"expected reassociation map #";
      __int16 v266 = 259;
      mlir::OpState::emitOpError(&v269, &v263, (uint64_t)&v279);
      if (v279)
      {
        LODWORD(v272) = 5;
        uint64_t v273 = v110;
        uint64_t v166 = (char *)&v272;
        uint64_t v167 = (char *)v282;
        if (v283 >= v284)
        {
          unint64_t v229 = v283 + 1;
          if (v282 <= &v272 && (char *)v282 + 24 * v283 > (char *)&v272)
          {
            int64_t v253 = (char *)&v272 - (unsigned char *)v282;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v229, 24);
            uint64_t v167 = (char *)v282;
            uint64_t v166 = (char *)v282 + v253;
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v229, 24);
            uint64_t v166 = (char *)&v272;
            uint64_t v167 = (char *)v282;
          }
        }
        uint64_t v168 = &v167[24 * v283];
        long long v169 = *(_OWORD *)v166;
        *((void *)v168 + 2) = *((void *)v166 + 2);
        *(_OWORD *)uint64_t v168 = v169;
        uint64_t v170 = ++v283;
        if (v279)
        {
          LODWORD(v272) = 3;
          uint64_t v273 = " of same rank as expanded memref(";
          uint64_t v274 = 33;
          uint64_t v171 = (char *)&v272;
          uint64_t v172 = (char *)v282;
          if (v170 >= v284)
          {
            unint64_t v233 = v170 + 1;
            BOOL v234 = (char *)v282 + 24 * v170 > (char *)&v272;
            if (v282 <= &v272 && v234)
            {
              int64_t v256 = (char *)&v272 - (unsigned char *)v282;
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v233, 24);
              uint64_t v172 = (char *)v282;
              uint64_t v171 = (char *)v282 + v256;
            }
            else
            {
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v233, 24);
              uint64_t v171 = (char *)&v272;
              uint64_t v172 = (char *)v282;
            }
          }
          uint64_t v173 = &v172[24 * v283];
          long long v174 = *(_OWORD *)v171;
          *((void *)v173 + 2) = *((void *)v171 + 2);
          *(_OWORD *)uint64_t v173 = v174;
          uint64_t v175 = ++v283;
          if (v279)
          {
            LODWORD(v272) = 5;
            uint64_t v273 = v111;
            uint64_t v176 = (char *)&v272;
            uint64_t v177 = (char *)v282;
            if (v175 >= v284)
            {
              unint64_t v235 = v175 + 1;
              BOOL v236 = (char *)v282 + 24 * v175 > (char *)&v272;
              if (v282 <= &v272 && v236)
              {
                int64_t v257 = (char *)&v272 - (unsigned char *)v282;
                llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v235, 24);
                uint64_t v177 = (char *)v282;
                uint64_t v176 = (char *)v282 + v257;
              }
              else
              {
                llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v235, 24);
                uint64_t v176 = (char *)&v272;
                uint64_t v177 = (char *)v282;
              }
            }
            uint64_t v178 = &v177[24 * v283];
            long long v179 = *(_OWORD *)v176;
            *((void *)v178 + 2) = *((void *)v176 + 2);
            *(_OWORD *)uint64_t v178 = v179;
            uint64_t v180 = ++v283;
            if (v279)
            {
              LODWORD(v272) = 3;
              uint64_t v273 = "), but got ";
              uint64_t v274 = 11;
              uint64_t v181 = (char *)&v272;
              uint64_t v182 = (char *)v282;
              if (v180 >= v284)
              {
                unint64_t v237 = v180 + 1;
                BOOL v238 = (char *)v282 + 24 * v180 > (char *)&v272;
                if (v282 <= &v272 && v238)
                {
                  int64_t v258 = (char *)&v272 - (unsigned char *)v282;
                  llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v237, 24);
                  uint64_t v182 = (char *)v282;
                  uint64_t v181 = (char *)v282 + v258;
                }
                else
                {
                  llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v237, 24);
                  uint64_t v181 = (char *)&v272;
                  uint64_t v182 = (char *)v282;
                }
              }
              uint64_t v183 = &v182[24 * v283];
              long long v184 = *(_OWORD *)v181;
              *((void *)v183 + 2) = *((void *)v181 + 2);
              *(_OWORD *)uint64_t v183 = v184;
              ++v283;
            }
          }
        }
      }
      unsigned int NumDims = mlir::AffineMap::getNumDims(v108);
      if (v279)
      {
        LODWORD(v272) = 5;
        uint64_t v273 = (const char *)NumDims;
        uint64_t v186 = (char *)&v272;
        uint64_t v187 = (char *)v282;
        if (v283 >= v284)
        {
          unint64_t v230 = v283 + 1;
          if (v282 <= &v272 && (char *)v282 + 24 * v283 > (char *)&v272)
          {
            int64_t v254 = (char *)&v272 - (unsigned char *)v282;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v230, 24);
            uint64_t v187 = (char *)v282;
            uint64_t v186 = (char *)v282 + v254;
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v230, 24);
            uint64_t v186 = (char *)&v272;
            uint64_t v187 = (char *)v282;
          }
        }
        uint64_t v188 = &v187[24 * v283];
        long long v189 = *(_OWORD *)v186;
        *((void *)v188 + 2) = *((void *)v186 + 2);
        *(_OWORD *)uint64_t v188 = v189;
        ++v283;
      }
      char v29 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v279);
      if (v279) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v279);
      }
      if (!v290) {
        goto LABEL_252;
      }
      uint64_t v190 = __p;
      if (__p)
      {
        uint64_t v191 = v289;
        uint64_t v192 = __p;
        if (v289 != __p)
        {
          do
            uint64_t v191 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v191 - 1);
          while (v191 != v190);
          uint64_t v192 = __p;
        }
        uint64_t v289 = v190;
        operator delete(v192);
      }
      uint64_t v193 = v286;
      if (v286)
      {
        uint64_t v194 = v287;
        uint64_t v195 = v286;
        if (v287 != v286)
        {
          do
          {
            uint64_t v197 = *--v194;
            uint64_t v196 = v197;
            *uint64_t v194 = 0;
            if (v197) {
              MEMORY[0x21667D390](v196, 0x1000C8077774924);
            }
          }
          while (v194 != v193);
          uint64_t v195 = v286;
        }
        uint64_t v287 = v193;
        operator delete(v195);
      }
      uint64_t v209 = v282;
      if (v282 == v285)
      {
LABEL_252:
        unint64_t v122 = v275;
        if (v275 != (mlir::AffineMap *)v277)
        {
LABEL_150:
          free(v122);
          goto LABEL_151;
        }
        goto LABEL_151;
      }
    }
    else
    {
LABEL_130:
      int v262 = 0;
      if (mlir::isReassociationValid(v108, v109, &v262))
      {
        uint64_t v113 = v269;
        uint64_t v114 = v267;
        if (v267) {
          uint64_t v115 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>((uint64_t)*v267 + 8);
        }
        else {
          uint64_t v115 = 0;
        }
        uint64_t v198 = v268;
        if (v268) {
          uint64_t v199 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*v268 + 8);
        }
        else {
          uint64_t v199 = 0;
        }
        uint64_t v271 = v113;
        uint64_t v272 = v198;
        uint64_t v263 = v114;
        uint64_t v264 = (const char *)v115;
        uint64_t v273 = (const char *)v199;
        uint64_t v270 = &v271;
        uint64_t Shape = mlir::ShapedType::getShape((mlir::ShapedType *)&v263);
        uint64_t v202 = v201;
        uint64_t v203 = mlir::ShapedType::getShape((mlir::ShapedType *)&v272);
        uint64_t v205 = v204;
        mlir::memref::CollapseShapeOp::getReassociationIndices((mlir::memref::CollapseShapeOp *)&v271, (uint64_t)&v279);
        char v29 = mlir::reshapeLikeShapesAreCompatible((uint64_t (*)(uint64_t, void **))llvm::function_ref<mlir::LogicalResult ()(llvm::Twine const&)>::callback_fn<mlir::LogicalResult mlir::verifyReshapeLikeShapes<mlir::tensor::ExpandShapeOp>(mlir::tensor::ExpandShapeOp,mlir::ShapedType,mlir::ShapedType,BOOL)::{lambda(llvm::Twine const&)#1}>, (uint64_t)&v270, Shape, v202, v203, v205, (uint64_t)v279, v280, 1);
        uint64_t v206 = (uint64_t *)v279;
        if (v280)
        {
          uint64_t v207 = 4 * v280;
          do
          {
            uint64_t v208 = (uint64_t *)v206[v207 - 4];
            if (&v206[v207 - 2] != v208) {
              free(v208);
            }
            v207 -= 4;
          }
          while (v207 * 8);
          uint64_t v206 = (uint64_t *)v279;
        }
        if (v206 == &v281) {
          goto LABEL_252;
        }
        uint64_t v209 = v206;
      }
      else
      {
        uint64_t v263 = (void **)"expected reassociation map #";
        __int16 v266 = 259;
        mlir::OpState::emitOpError(&v269, &v263, (uint64_t)&v279);
        if (v279)
        {
          LODWORD(v272) = 2;
          uint64_t v273 = (const char *)v262;
          uint64_t v149 = (char *)&v272;
          uint64_t v150 = (char *)v282;
          if (v283 >= v284)
          {
            unint64_t v228 = v283 + 1;
            if (v282 <= &v272 && (char *)v282 + 24 * v283 > (char *)&v272)
            {
              int64_t v252 = (char *)&v272 - (unsigned char *)v282;
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v228, 24);
              uint64_t v150 = (char *)v282;
              uint64_t v149 = (char *)v282 + v252;
            }
            else
            {
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v228, 24);
              uint64_t v149 = (char *)&v272;
              uint64_t v150 = (char *)v282;
            }
          }
          uint64_t v151 = &v150[24 * v283];
          long long v152 = *(_OWORD *)v149;
          *((void *)v151 + 2) = *((void *)v149 + 2);
          *(_OWORD *)uint64_t v151 = v152;
          uint64_t v153 = ++v283;
          if (v279)
          {
            LODWORD(v272) = 3;
            uint64_t v273 = " to be valid and contiguous";
            uint64_t v274 = 27;
            uint64_t v154 = (char *)&v272;
            uint64_t v155 = (char *)v282;
            if (v153 >= v284)
            {
              unint64_t v231 = v153 + 1;
              BOOL v232 = (char *)v282 + 24 * v153 > (char *)&v272;
              if (v282 <= &v272 && v232)
              {
                int64_t v255 = (char *)&v272 - (unsigned char *)v282;
                llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v231, 24);
                uint64_t v155 = (char *)v282;
                uint64_t v154 = (char *)v282 + v255;
              }
              else
              {
                llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v231, 24);
                uint64_t v154 = (char *)&v272;
                uint64_t v155 = (char *)v282;
              }
            }
            uint64_t v156 = &v155[24 * v283];
            long long v157 = *(_OWORD *)v154;
            *((void *)v156 + 2) = *((void *)v154 + 2);
            *(_OWORD *)uint64_t v156 = v157;
            ++v283;
          }
        }
        char v29 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v279);
        if (v279) {
          mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v279);
        }
        if (!v290) {
          goto LABEL_252;
        }
        uint64_t v158 = __p;
        if (__p)
        {
          uint64_t v159 = v289;
          uint64_t v160 = __p;
          if (v289 != __p)
          {
            do
              uint64_t v159 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v159 - 1);
            while (v159 != v158);
            uint64_t v160 = __p;
          }
          uint64_t v289 = v158;
          operator delete(v160);
        }
        uint64_t v161 = v286;
        if (v286)
        {
          uint64_t v162 = v287;
          uint64_t v163 = v286;
          if (v287 != v286)
          {
            do
            {
              uint64_t v165 = *--v162;
              uint64_t v164 = v165;
              *uint64_t v162 = 0;
              if (v165) {
                MEMORY[0x21667D390](v164, 0x1000C8077774924);
              }
            }
            while (v162 != v161);
            uint64_t v163 = v286;
          }
          uint64_t v287 = v161;
          operator delete(v163);
        }
        uint64_t v209 = v282;
        if (v282 == v285) {
          goto LABEL_252;
        }
      }
    }
    free(v209);
    goto LABEL_252;
  }
  uint64_t Value = (void *)mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v268);
  if (v81)
  {
    uint64_t v82 = 8 * v81;
    while (*Value == 1)
    {
      ++Value;
      v82 -= 8;
      if (!v82) {
        goto LABEL_152;
      }
    }
    uint64_t v275 = (mlir::AffineMap *)"invalid to reshape tensor/memref with non-unit extent dimensions to zero-rank tensor/memref";
    __int16 v278 = 259;
    mlir::OpState::emitOpError(&v269, (void ***)&v275, (uint64_t)&v279);
    char v29 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v279);
    if (v279) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v279);
    }
    if (v290)
    {
      uint64_t v116 = __p;
      if (__p)
      {
        int v117 = v289;
        int v118 = __p;
        if (v289 != __p)
        {
          do
            int v117 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v117 - 1);
          while (v117 != v116);
          int v118 = __p;
        }
        uint64_t v289 = v116;
        operator delete(v118);
      }
      uint64_t v33 = v286;
      if (v286)
      {
        unint64_t v119 = v287;
        uint64_t v35 = v286;
        if (v287 == v286) {
          goto LABEL_148;
        }
        do
        {
          uint64_t v121 = *--v119;
          uint64_t v120 = v121;
          *unint64_t v119 = 0;
          if (v121) {
            MEMORY[0x21667D390](v120, 0x1000C8077774924);
          }
        }
        while (v119 != v33);
        goto LABEL_147;
      }
LABEL_149:
      unint64_t v122 = v282;
      if (v282 == v285) {
        goto LABEL_151;
      }
      goto LABEL_150;
    }
LABEL_151:
    if (!v29) {
      return 0;
    }
  }
LABEL_152:
  mlir::tensor::CollapseShapeOp::getReassociationExprs((mlir::tensor::CollapseShapeOp *)&v261, &v279);
  mlir::getSymbolLessAffineMaps((uint64_t)v279, v280, (uint64_t)&v275);
  uint64_t v123 = (char *)v279;
  if (v280)
  {
    uint64_t v124 = 32 * v280;
    do
    {
      uint64_t v125 = *(char **)&v123[v124 - 32];
      if (&v123[v124 - 16] != v125) {
        free(v125);
      }
      v124 -= 32;
    }
    while (v124);
    uint64_t v123 = (char *)v279;
  }
  if (v123 != (char *)&v281) {
    free(v123);
  }
  uint64_t v126 = mlir::tensor::CollapseShapeOp::inferCollapsedType((uint64_t)v11, (uint64_t *)v275, v276);
  if (mlir::tensor::isSameTypeWithoutEncoding((uint64_t)v12, v126))
  {
    uint64_t v53 = 1;
  }
  else
  {
    uint64_t v263 = (void **)"expected collapsed type to be ";
    __int16 v266 = 259;
    mlir::OpState::emitOpError(&v261, &v263, (uint64_t)&v279);
    if (v279)
    {
      int v127 = (char *)&v272;
      mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v272, v126);
      unint64_t v128 = (char *)v282;
      if (v283 >= v284)
      {
        unint64_t v215 = v283 + 1;
        if (v282 <= &v272 && (char *)v282 + 24 * v283 > (char *)&v272)
        {
          int64_t v243 = (char *)&v272 - (unsigned char *)v282;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v215, 24);
          unint64_t v128 = (char *)v282;
          int v127 = (char *)v282 + v243;
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v215, 24);
          int v127 = (char *)&v272;
          unint64_t v128 = (char *)v282;
        }
      }
      unint64_t v129 = &v128[24 * v283];
      long long v130 = *(_OWORD *)v127;
      *((void *)v129 + 2) = *((void *)v127 + 2);
      *(_OWORD *)unint64_t v129 = v130;
      uint64_t v131 = ++v283;
      if (v279)
      {
        LODWORD(v272) = 3;
        uint64_t v273 = ", but got ";
        uint64_t v274 = 10;
        uint64_t v132 = (char *)&v272;
        unint64_t v133 = (char *)v282;
        if (v131 >= v284)
        {
          unint64_t v218 = v131 + 1;
          BOOL v219 = (char *)v282 + 24 * v131 > (char *)&v272;
          if (v282 <= &v272 && v219)
          {
            int64_t v245 = (char *)&v272 - (unsigned char *)v282;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v218, 24);
            unint64_t v133 = (char *)v282;
            uint64_t v132 = (char *)v282 + v245;
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v218, 24);
            uint64_t v132 = (char *)&v272;
            unint64_t v133 = (char *)v282;
          }
        }
        uint64_t v134 = &v133[24 * v283];
        long long v135 = *(_OWORD *)v132;
        *((void *)v134 + 2) = *((void *)v132 + 2);
        *(_OWORD *)uint64_t v134 = v135;
        ++v283;
        if (v279)
        {
          int v136 = (char *)&v272;
          mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v272, (uint64_t)v12);
          unint64_t v137 = (char *)v282;
          if (v283 >= v284)
          {
            unint64_t v221 = v283 + 1;
            if (v282 <= &v272 && (char *)v282 + 24 * v283 > (char *)&v272)
            {
              int64_t v247 = (char *)&v272 - (unsigned char *)v282;
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v221, 24);
              unint64_t v137 = (char *)v282;
              int v136 = (char *)v282 + v247;
            }
            else
            {
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v221, 24);
              int v136 = (char *)&v272;
              unint64_t v137 = (char *)v282;
            }
          }
          unint64_t v138 = &v137[24 * v283];
          long long v139 = *(_OWORD *)v136;
          *((void *)v138 + 2) = *((void *)v136 + 2);
          *(_OWORD *)unint64_t v138 = v139;
          ++v283;
        }
      }
    }
    uint64_t v53 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v279);
    if (v279) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v279);
    }
    if (v290)
    {
      unint64_t v140 = __p;
      if (__p)
      {
        uint64_t v141 = v289;
        unint64_t v142 = __p;
        if (v289 != __p)
        {
          do
            uint64_t v141 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v141 - 1);
          while (v141 != v140);
          unint64_t v142 = __p;
        }
        uint64_t v289 = v140;
        operator delete(v142);
      }
      uint64_t v143 = v286;
      if (v286)
      {
        uint64_t v144 = v287;
        uint64_t v145 = v286;
        if (v287 != v286)
        {
          do
          {
            uint64_t v147 = *--v144;
            uint64_t v146 = v147;
            *uint64_t v144 = 0;
            if (v147) {
              MEMORY[0x21667D390](v146, 0x1000C8077774924);
            }
          }
          while (v144 != v143);
          uint64_t v145 = v286;
        }
        uint64_t v287 = v143;
        operator delete(v145);
      }
      if (v282 != v285) {
        free(v282);
      }
    }
  }
  uint64_t v68 = v275;
  if (v275 != (mlir::AffineMap *)v277) {
LABEL_189:
  }
    free(v68);
  return v53;
}

uint64_t mlir::tensor::CollapseShapeOp::verify(mlir::tensor::CollapseShapeOp *this)
{
  uint64_t v291 = *MEMORY[0x263EF8340];
  uint64_t v2 = *(void *)this;
  unint64_t v260 = *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8;
  int v3 = *(_DWORD *)(v2 + 36);
  uint64_t v4 = v2 - 16;
  if (v3) {
    uint64_t v5 = v4;
  }
  else {
    uint64_t v5 = 0;
  }
  unint64_t v259 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v5, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v260);
  uint64_t v7 = v6;
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v259);
  if (v7 <= v8)
  {
    uint64_t v275 = (mlir::AffineMap *)"expected rank reduction, but found source rank ";
    __int16 v278 = 259;
    mlir::OpState::emitOpError((uint64_t *)this, (void ***)&v275, (uint64_t)&v279);
    mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v260);
    if (v279)
    {
      LODWORD(v263) = 2;
      uint64_t v264 = v38;
      uint64_t v39 = &v263;
      uint64_t v40 = (char *)v282;
      if (v283 >= v284)
      {
        unint64_t v210 = v283 + 1;
        if (v282 <= &v263 && (char *)v282 + 24 * v283 > (char *)&v263)
        {
          int64_t v239 = (char *)&v263 - (unsigned char *)v282;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v210, 24);
          uint64_t v40 = (char *)v282;
          uint64_t v39 = (void ***)((char *)v282 + v239);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v210, 24);
          uint64_t v39 = &v263;
          uint64_t v40 = (char *)v282;
        }
      }
      __int16 v41 = &v40[24 * v283];
      long long v42 = *(_OWORD *)v39;
      *((void *)v41 + 2) = v39[2];
      *(_OWORD *)__int16 v41 = v42;
      uint64_t v43 = ++v283;
      if (v279)
      {
        LODWORD(v263) = 3;
        uint64_t v264 = " <= result rank ";
        uint64_t v265 = 16;
        uint64_t v44 = &v263;
        uint64_t v45 = (char *)v282;
        if (v43 >= v284)
        {
          unint64_t v212 = v43 + 1;
          BOOL v213 = (char *)v282 + 24 * v43 > (char *)&v263;
          if (v282 <= &v263 && v213)
          {
            int64_t v241 = (char *)&v263 - (unsigned char *)v282;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v212, 24);
            uint64_t v45 = (char *)v282;
            uint64_t v44 = (void ***)((char *)v282 + v241);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v212, 24);
            uint64_t v44 = &v263;
            uint64_t v45 = (char *)v282;
          }
        }
        uint64_t v46 = &v45[24 * v283];
        long long v47 = *(_OWORD *)v44;
        *((void *)v46 + 2) = v44[2];
        *(_OWORD *)uint64_t v46 = v47;
        ++v283;
      }
    }
    mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v259);
    if (v279)
    {
      LODWORD(v263) = 2;
      uint64_t v264 = v48;
      uint64_t v49 = &v263;
      uint64_t v50 = (char *)v282;
      if (v283 >= v284)
      {
        unint64_t v211 = v283 + 1;
        if (v282 <= &v263 && (char *)v282 + 24 * v283 > (char *)&v263)
        {
          int64_t v240 = (char *)&v263 - (unsigned char *)v282;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v211, 24);
          uint64_t v50 = (char *)v282;
          uint64_t v49 = (void ***)((char *)v282 + v240);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v211, 24);
          uint64_t v49 = &v263;
          uint64_t v50 = (char *)v282;
        }
      }
      uint64_t v51 = &v50[24 * v283];
      long long v52 = *(_OWORD *)v49;
      *((void *)v51 + 2) = v49[2];
      *(_OWORD *)uint64_t v51 = v52;
      ++v283;
    }
    uint64_t v53 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v279);
    if (v279) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v279);
    }
    if (v290)
    {
      uint64_t v54 = __p;
      if (__p)
      {
        uint64_t v55 = v289;
        unint64_t v56 = __p;
        if (v289 != __p)
        {
          do
            uint64_t v55 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v55 - 1);
          while (v55 != v54);
          unint64_t v56 = __p;
        }
        uint64_t v289 = v54;
        operator delete(v56);
      }
      unint64_t v57 = v286;
      if (v286)
      {
        long long v58 = v287;
        uint64_t v59 = v286;
        if (v287 != v286)
        {
          do
          {
            uint64_t v61 = *--v58;
            uint64_t v60 = v61;
            *long long v58 = 0;
            if (v61) {
              MEMORY[0x21667D390](v60, 0x1000C8077774924);
            }
          }
          while (v58 != v57);
          uint64_t v59 = v286;
        }
        uint64_t v287 = v57;
        operator delete(v59);
      }
      uint64_t v68 = v282;
      if (v282 != v285) {
        goto LABEL_189;
      }
    }
    return v53;
  }
  uint64_t v9 = *(void *)this;
  uint64_t v10 = (void *)(*(void *)(*(void *)(*(void *)(*(void *)this + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8);
  if (*(_DWORD *)(*(void *)this + 36)) {
    uint64_t v11 = *(void *)this - 16;
  }
  else {
    uint64_t v11 = 0;
  }
  unsigned int v12 = (void **)(*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v11, 0) + 8) & 0xFFFFFFFFFFFFFFF8);
  uint64_t v261 = v9;
  uint64_t v268 = v10;
  uint64_t v269 = v9;
  uint64_t v267 = v12;
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v268);
  unsigned int v14 = v13;
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v267);
  if (v14 < v15)
  {
    uint64_t v275 = (mlir::AffineMap *)"expected the type ";
    __int16 v278 = 259;
    mlir::OpState::emitOpError(&v269, (void ***)&v275, (uint64_t)&v279);
    if (v279)
    {
      uint64_t v16 = &v263;
      mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v263, (uint64_t)v268);
      uint64_t v17 = (char *)v282;
      if (v283 >= v284)
      {
        unint64_t v214 = v283 + 1;
        if (v282 <= &v263 && (char *)v282 + 24 * v283 > (char *)&v263)
        {
          int64_t v242 = (char *)&v263 - (unsigned char *)v282;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v214, 24);
          uint64_t v17 = (char *)v282;
          uint64_t v16 = (void ***)((char *)v282 + v242);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v214, 24);
          uint64_t v16 = &v263;
          uint64_t v17 = (char *)v282;
        }
      }
      uint64_t v18 = &v17[24 * v283];
      long long v19 = *(_OWORD *)v16;
      *((void *)v18 + 2) = v16[2];
      *(_OWORD *)uint64_t v18 = v19;
      uint64_t v20 = ++v283;
      if (v279)
      {
        LODWORD(v263) = 3;
        uint64_t v264 = " to have higher rank than the type = ";
        uint64_t v265 = 37;
        uint64_t v21 = &v263;
        unsigned int v22 = (char *)v282;
        if (v20 >= v284)
        {
          unint64_t v216 = v20 + 1;
          BOOL v217 = (char *)v282 + 24 * v20 > (char *)&v263;
          if (v282 <= &v263 && v217)
          {
            int64_t v244 = (char *)&v263 - (unsigned char *)v282;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v216, 24);
            unsigned int v22 = (char *)v282;
            uint64_t v21 = (void ***)((char *)v282 + v244);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v216, 24);
            uint64_t v21 = &v263;
            unsigned int v22 = (char *)v282;
          }
        }
        uint64_t v23 = &v22[24 * v283];
        long long v24 = *(_OWORD *)v21;
        *((void *)v23 + 2) = v21[2];
        *(_OWORD *)uint64_t v23 = v24;
        ++v283;
        if (v279)
        {
          uint64_t v25 = &v263;
          mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v263, (uint64_t)v267);
          uint64_t v26 = (char *)v282;
          if (v283 >= v284)
          {
            unint64_t v220 = v283 + 1;
            if (v282 <= &v263 && (char *)v282 + 24 * v283 > (char *)&v263)
            {
              int64_t v246 = (char *)&v263 - (unsigned char *)v282;
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v220, 24);
              uint64_t v26 = (char *)v282;
              uint64_t v25 = (void ***)((char *)v282 + v246);
            }
            else
            {
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v220, 24);
              uint64_t v25 = &v263;
              uint64_t v26 = (char *)v282;
            }
          }
          BOOL v27 = &v26[24 * v283];
          long long v28 = *(_OWORD *)v25;
          *((void *)v27 + 2) = v25[2];
          *(_OWORD *)BOOL v27 = v28;
          ++v283;
        }
      }
    }
    char v29 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v279);
    if (v279) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v279);
    }
    if (v290)
    {
      uint64_t v30 = __p;
      if (__p)
      {
        uint64_t v31 = v289;
        uint64_t v32 = __p;
        if (v289 != __p)
        {
          do
            uint64_t v31 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v31 - 1);
          while (v31 != v30);
          uint64_t v32 = __p;
        }
        uint64_t v289 = v30;
        operator delete(v32);
      }
      uint64_t v33 = v286;
      if (v286)
      {
        unint64_t v34 = v287;
        uint64_t v35 = v286;
        if (v287 == v286) {
          goto LABEL_148;
        }
        do
        {
          uint64_t v37 = *--v34;
          uint64_t v36 = v37;
          *unint64_t v34 = 0;
          if (v37) {
            MEMORY[0x21667D390](v36, 0x1000C8077774924);
          }
        }
        while (v34 != v33);
LABEL_147:
        uint64_t v35 = v286;
LABEL_148:
        uint64_t v287 = v33;
        operator delete(v35);
        goto LABEL_149;
      }
      goto LABEL_149;
    }
    goto LABEL_151;
  }
  if (!v14)
  {
    uint64_t v275 = (mlir::AffineMap *)"expected non-zero memref ranks";
    __int16 v278 = 259;
    mlir::OpState::emitOpError(&v269, (void ***)&v275, (uint64_t)&v279);
    char v29 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v279);
    if (v279) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v279);
    }
    if (v290)
    {
      uint64_t v69 = __p;
      if (__p)
      {
        unsigned int v70 = v289;
        uint64_t v71 = __p;
        if (v289 != __p)
        {
          do
            unsigned int v70 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v70 - 1);
          while (v70 != v69);
          uint64_t v71 = __p;
        }
        uint64_t v289 = v69;
        operator delete(v71);
      }
      uint64_t v33 = v286;
      if (v286)
      {
        __int16 v72 = v287;
        uint64_t v35 = v286;
        if (v287 == v286) {
          goto LABEL_148;
        }
        do
        {
          uint64_t v74 = *--v72;
          uint64_t v73 = v74;
          *__int16 v72 = 0;
          if (v74) {
            MEMORY[0x21667D390](v73, 0x1000C8077774924);
          }
        }
        while (v72 != v33);
        goto LABEL_147;
      }
      goto LABEL_149;
    }
    goto LABEL_151;
  }
  if (v14 == v15)
  {
    uint64_t v275 = (mlir::AffineMap *)"expected to collapse or expand dims";
    __int16 v278 = 259;
    mlir::OpState::emitOpError(&v269, (void ***)&v275, (uint64_t)&v279);
    char v29 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v279);
    if (v279) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v279);
    }
    if (v290)
    {
      long long v62 = __p;
      if (__p)
      {
        int64_t v63 = v289;
        int64_t v64 = __p;
        if (v289 != __p)
        {
          do
            int64_t v63 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v63 - 1);
          while (v63 != v62);
          int64_t v64 = __p;
        }
        uint64_t v289 = v62;
        operator delete(v64);
      }
      uint64_t v33 = v286;
      if (v286)
      {
        unint64_t v65 = v287;
        uint64_t v35 = v286;
        if (v287 == v286) {
          goto LABEL_148;
        }
        do
        {
          uint64_t v67 = *--v65;
          uint64_t v66 = v67;
          *unint64_t v65 = 0;
          if (v67) {
            MEMORY[0x21667D390](v66, 0x1000C8077774924);
          }
        }
        while (v65 != v33);
        goto LABEL_147;
      }
      goto LABEL_149;
    }
    goto LABEL_151;
  }
  if (v15)
  {
    unint64_t v75 = (const char *)v15;
    uint64_t v279 = *(void **)(v9 + 16 * (((unint64_t)*(unsigned int *)(v9 + 44) >> 23) & 1) + 64);
    mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v279);
    if (v75 != v76)
    {
      uint64_t v275 = (mlir::AffineMap *)"expected rank of the collapsed type(";
      __int16 v278 = 259;
      mlir::OpState::emitOpError(&v269, (void ***)&v275, (uint64_t)&v279);
      if (v279)
      {
        LODWORD(v263) = 5;
        uint64_t v264 = v75;
        char v83 = &v263;
        uint64_t v84 = (char *)v282;
        if (v283 >= v284)
        {
          unint64_t v222 = v283 + 1;
          if (v282 <= &v263 && (char *)v282 + 24 * v283 > (char *)&v263)
          {
            int64_t v248 = (char *)&v263 - (unsigned char *)v282;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v222, 24);
            uint64_t v84 = (char *)v282;
            char v83 = (void ***)((char *)v282 + v248);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v222, 24);
            char v83 = &v263;
            uint64_t v84 = (char *)v282;
          }
        }
        unint64_t v85 = &v84[24 * v283];
        long long v86 = *(_OWORD *)v83;
        *((void *)v85 + 2) = v83[2];
        *(_OWORD *)unint64_t v85 = v86;
        uint64_t v87 = ++v283;
        if (v279)
        {
          LODWORD(v263) = 3;
          uint64_t v264 = ") to be the number of reassociation maps(";
          uint64_t v265 = 41;
          int64_t v88 = &v263;
          int64_t v89 = (char *)v282;
          if (v87 >= v284)
          {
            unint64_t v224 = v87 + 1;
            BOOL v225 = (char *)v282 + 24 * v87 > (char *)&v263;
            if (v282 <= &v263 && v225)
            {
              int64_t v250 = (char *)&v263 - (unsigned char *)v282;
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v224, 24);
              int64_t v89 = (char *)v282;
              int64_t v88 = (void ***)((char *)v282 + v250);
            }
            else
            {
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v224, 24);
              int64_t v88 = &v263;
              int64_t v89 = (char *)v282;
            }
          }
          int64_t v90 = &v89[24 * v283];
          long long v91 = *(_OWORD *)v88;
          *((void *)v90 + 2) = v88[2];
          *(_OWORD *)int64_t v90 = v91;
          ++v283;
        }
      }
      uint64_t v272 = *(void **)(v269 + 16 * (((unint64_t)*(unsigned int *)(v269 + 44) >> 23) & 1) + 64);
      mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v272);
      if (v279)
      {
        LODWORD(v263) = 5;
        uint64_t v264 = v92;
        int64_t v93 = &v263;
        int v94 = (char *)v282;
        if (v283 >= v284)
        {
          unint64_t v223 = v283 + 1;
          if (v282 <= &v263 && (char *)v282 + 24 * v283 > (char *)&v263)
          {
            int64_t v249 = (char *)&v263 - (unsigned char *)v282;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v223, 24);
            int v94 = (char *)v282;
            int64_t v93 = (void ***)((char *)v282 + v249);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v223, 24);
            int64_t v93 = &v263;
            int v94 = (char *)v282;
          }
        }
        unint64_t v95 = &v94[24 * v283];
        long long v96 = *(_OWORD *)v93;
        *((void *)v95 + 2) = v93[2];
        *(_OWORD *)unint64_t v95 = v96;
        uint64_t v97 = ++v283;
        if (v279)
        {
          LODWORD(v263) = 3;
          uint64_t v264 = ")";
          uint64_t v265 = 1;
          uint64_t v98 = &v263;
          int v99 = (char *)v282;
          if (v97 >= v284)
          {
            unint64_t v226 = v97 + 1;
            BOOL v227 = (char *)v282 + 24 * v97 > (char *)&v263;
            if (v282 <= &v263 && v227)
            {
              int64_t v251 = (char *)&v263 - (unsigned char *)v282;
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v226, 24);
              int v99 = (char *)v282;
              uint64_t v98 = (void ***)((char *)v282 + v251);
            }
            else
            {
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v226, 24);
              uint64_t v98 = &v263;
              int v99 = (char *)v282;
            }
          }
          uint64_t v100 = &v99[24 * v283];
          long long v101 = *(_OWORD *)v98;
          *((void *)v100 + 2) = v98[2];
          *(_OWORD *)uint64_t v100 = v101;
          ++v283;
        }
      }
      char v29 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v279);
      if (v279) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v279);
      }
      if (v290)
      {
        uint64_t v102 = __p;
        if (__p)
        {
          int v103 = v289;
          unint64_t v104 = __p;
          if (v289 != __p)
          {
            do
              int v103 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v103 - 1);
            while (v103 != v102);
            unint64_t v104 = __p;
          }
          uint64_t v289 = v102;
          operator delete(v104);
        }
        uint64_t v33 = v286;
        if (v286)
        {
          unsigned int v105 = v287;
          uint64_t v35 = v286;
          if (v287 == v286) {
            goto LABEL_148;
          }
          do
          {
            uint64_t v107 = *--v105;
            uint64_t v106 = v107;
            *unsigned int v105 = 0;
            if (v107) {
              MEMORY[0x21667D390](v106, 0x1000C8077774924);
            }
          }
          while (v105 != v33);
          goto LABEL_147;
        }
        goto LABEL_149;
      }
      goto LABEL_151;
    }
    mlir::tensor::CollapseShapeOp::getReassociationExprs((mlir::tensor::CollapseShapeOp *)&v269, &v279);
    mlir::getSymbolLessAffineMaps((uint64_t)v279, v280, (uint64_t)&v275);
    uint64_t v77 = (char *)v279;
    if (v280)
    {
      uint64_t v78 = 32 * v280;
      do
      {
        char v79 = *(char **)&v77[v78 - 32];
        if (&v77[v78 - 16] != v79) {
          free(v79);
        }
        v78 -= 32;
      }
      while (v78);
      uint64_t v77 = (char *)v279;
    }
    if (v77 != (char *)&v281) {
      free(v77);
    }
    int v108 = v275;
    unsigned int v109 = v276;
    if (v276)
    {
      unint64_t v110 = 0;
      unint64_t v111 = (const char *)v14;
      uint64_t v112 = 8 * v276;
      while (mlir::AffineMap::getNumDims(v108) == v14)
      {
        ++v110;
        int v108 = (mlir::AffineMap *)((char *)v108 + 8);
        v112 -= 8;
        if (!v112)
        {
          int v108 = v275;
          unsigned int v109 = v276;
          goto LABEL_130;
        }
      }
      uint64_t v263 = (void **)"expected reassociation map #";
      __int16 v266 = 259;
      mlir::OpState::emitOpError(&v269, &v263, (uint64_t)&v279);
      if (v279)
      {
        LODWORD(v272) = 5;
        uint64_t v273 = v110;
        uint64_t v166 = (char *)&v272;
        uint64_t v167 = (char *)v282;
        if (v283 >= v284)
        {
          unint64_t v229 = v283 + 1;
          if (v282 <= &v272 && (char *)v282 + 24 * v283 > (char *)&v272)
          {
            int64_t v253 = (char *)&v272 - (unsigned char *)v282;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v229, 24);
            uint64_t v167 = (char *)v282;
            uint64_t v166 = (char *)v282 + v253;
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v229, 24);
            uint64_t v166 = (char *)&v272;
            uint64_t v167 = (char *)v282;
          }
        }
        uint64_t v168 = &v167[24 * v283];
        long long v169 = *(_OWORD *)v166;
        *((void *)v168 + 2) = *((void *)v166 + 2);
        *(_OWORD *)uint64_t v168 = v169;
        uint64_t v170 = ++v283;
        if (v279)
        {
          LODWORD(v272) = 3;
          uint64_t v273 = " of same rank as expanded memref(";
          uint64_t v274 = 33;
          uint64_t v171 = (char *)&v272;
          uint64_t v172 = (char *)v282;
          if (v170 >= v284)
          {
            unint64_t v233 = v170 + 1;
            BOOL v234 = (char *)v282 + 24 * v170 > (char *)&v272;
            if (v282 <= &v272 && v234)
            {
              int64_t v256 = (char *)&v272 - (unsigned char *)v282;
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v233, 24);
              uint64_t v172 = (char *)v282;
              uint64_t v171 = (char *)v282 + v256;
            }
            else
            {
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v233, 24);
              uint64_t v171 = (char *)&v272;
              uint64_t v172 = (char *)v282;
            }
          }
          uint64_t v173 = &v172[24 * v283];
          long long v174 = *(_OWORD *)v171;
          *((void *)v173 + 2) = *((void *)v171 + 2);
          *(_OWORD *)uint64_t v173 = v174;
          uint64_t v175 = ++v283;
          if (v279)
          {
            LODWORD(v272) = 5;
            uint64_t v273 = v111;
            uint64_t v176 = (char *)&v272;
            uint64_t v177 = (char *)v282;
            if (v175 >= v284)
            {
              unint64_t v235 = v175 + 1;
              BOOL v236 = (char *)v282 + 24 * v175 > (char *)&v272;
              if (v282 <= &v272 && v236)
              {
                int64_t v257 = (char *)&v272 - (unsigned char *)v282;
                llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v235, 24);
                uint64_t v177 = (char *)v282;
                uint64_t v176 = (char *)v282 + v257;
              }
              else
              {
                llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v235, 24);
                uint64_t v176 = (char *)&v272;
                uint64_t v177 = (char *)v282;
              }
            }
            uint64_t v178 = &v177[24 * v283];
            long long v179 = *(_OWORD *)v176;
            *((void *)v178 + 2) = *((void *)v176 + 2);
            *(_OWORD *)uint64_t v178 = v179;
            uint64_t v180 = ++v283;
            if (v279)
            {
              LODWORD(v272) = 3;
              uint64_t v273 = "), but got ";
              uint64_t v274 = 11;
              uint64_t v181 = (char *)&v272;
              uint64_t v182 = (char *)v282;
              if (v180 >= v284)
              {
                unint64_t v237 = v180 + 1;
                BOOL v238 = (char *)v282 + 24 * v180 > (char *)&v272;
                if (v282 <= &v272 && v238)
                {
                  int64_t v258 = (char *)&v272 - (unsigned char *)v282;
                  llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v237, 24);
                  uint64_t v182 = (char *)v282;
                  uint64_t v181 = (char *)v282 + v258;
                }
                else
                {
                  llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v237, 24);
                  uint64_t v181 = (char *)&v272;
                  uint64_t v182 = (char *)v282;
                }
              }
              uint64_t v183 = &v182[24 * v283];
              long long v184 = *(_OWORD *)v181;
              *((void *)v183 + 2) = *((void *)v181 + 2);
              *(_OWORD *)uint64_t v183 = v184;
              ++v283;
            }
          }
        }
      }
      unsigned int NumDims = mlir::AffineMap::getNumDims(v108);
      if (v279)
      {
        LODWORD(v272) = 5;
        uint64_t v273 = (const char *)NumDims;
        uint64_t v186 = (char *)&v272;
        uint64_t v187 = (char *)v282;
        if (v283 >= v284)
        {
          unint64_t v230 = v283 + 1;
          if (v282 <= &v272 && (char *)v282 + 24 * v283 > (char *)&v272)
          {
            int64_t v254 = (char *)&v272 - (unsigned char *)v282;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v230, 24);
            uint64_t v187 = (char *)v282;
            uint64_t v186 = (char *)v282 + v254;
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v230, 24);
            uint64_t v186 = (char *)&v272;
            uint64_t v187 = (char *)v282;
          }
        }
        uint64_t v188 = &v187[24 * v283];
        long long v189 = *(_OWORD *)v186;
        *((void *)v188 + 2) = *((void *)v186 + 2);
        *(_OWORD *)uint64_t v188 = v189;
        ++v283;
      }
      char v29 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v279);
      if (v279) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v279);
      }
      if (!v290) {
        goto LABEL_252;
      }
      uint64_t v190 = __p;
      if (__p)
      {
        uint64_t v191 = v289;
        uint64_t v192 = __p;
        if (v289 != __p)
        {
          do
            uint64_t v191 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v191 - 1);
          while (v191 != v190);
          uint64_t v192 = __p;
        }
        uint64_t v289 = v190;
        operator delete(v192);
      }
      uint64_t v193 = v286;
      if (v286)
      {
        uint64_t v194 = v287;
        uint64_t v195 = v286;
        if (v287 != v286)
        {
          do
          {
            uint64_t v197 = *--v194;
            uint64_t v196 = v197;
            *uint64_t v194 = 0;
            if (v197) {
              MEMORY[0x21667D390](v196, 0x1000C8077774924);
            }
          }
          while (v194 != v193);
          uint64_t v195 = v286;
        }
        uint64_t v287 = v193;
        operator delete(v195);
      }
      uint64_t v209 = v282;
      if (v282 == v285)
      {
LABEL_252:
        unint64_t v122 = v275;
        if (v275 != (mlir::AffineMap *)v277)
        {
LABEL_150:
          free(v122);
          goto LABEL_151;
        }
        goto LABEL_151;
      }
    }
    else
    {
LABEL_130:
      int v262 = 0;
      if (mlir::isReassociationValid(v108, v109, &v262))
      {
        uint64_t v113 = v269;
        uint64_t v114 = v267;
        if (v267) {
          uint64_t v115 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>((uint64_t)*v267 + 8);
        }
        else {
          uint64_t v115 = 0;
        }
        uint64_t v198 = v268;
        if (v268) {
          uint64_t v199 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*v268 + 8);
        }
        else {
          uint64_t v199 = 0;
        }
        uint64_t v271 = v113;
        uint64_t v272 = v198;
        uint64_t v263 = v114;
        uint64_t v264 = (const char *)v115;
        uint64_t v273 = (const char *)v199;
        uint64_t v270 = &v271;
        uint64_t Shape = mlir::ShapedType::getShape((mlir::ShapedType *)&v263);
        uint64_t v202 = v201;
        uint64_t v203 = mlir::ShapedType::getShape((mlir::ShapedType *)&v272);
        uint64_t v205 = v204;
        mlir::memref::CollapseShapeOp::getReassociationIndices((mlir::memref::CollapseShapeOp *)&v271, (uint64_t)&v279);
        char v29 = mlir::reshapeLikeShapesAreCompatible((uint64_t (*)(uint64_t, void **))llvm::function_ref<mlir::LogicalResult ()(llvm::Twine const&)>::callback_fn<mlir::LogicalResult mlir::verifyReshapeLikeShapes<mlir::tensor::CollapseShapeOp>(mlir::tensor::CollapseShapeOp,mlir::ShapedType,mlir::ShapedType,BOOL)::{lambda(llvm::Twine const&)#1}>, (uint64_t)&v270, Shape, v202, v203, v205, (uint64_t)v279, v280, 0);
        uint64_t v206 = (uint64_t *)v279;
        if (v280)
        {
          uint64_t v207 = 4 * v280;
          do
          {
            uint64_t v208 = (uint64_t *)v206[v207 - 4];
            if (&v206[v207 - 2] != v208) {
              free(v208);
            }
            v207 -= 4;
          }
          while (v207 * 8);
          uint64_t v206 = (uint64_t *)v279;
        }
        if (v206 == &v281) {
          goto LABEL_252;
        }
        uint64_t v209 = v206;
      }
      else
      {
        uint64_t v263 = (void **)"expected reassociation map #";
        __int16 v266 = 259;
        mlir::OpState::emitOpError(&v269, &v263, (uint64_t)&v279);
        if (v279)
        {
          LODWORD(v272) = 2;
          uint64_t v273 = (const char *)v262;
          uint64_t v149 = (char *)&v272;
          uint64_t v150 = (char *)v282;
          if (v283 >= v284)
          {
            unint64_t v228 = v283 + 1;
            if (v282 <= &v272 && (char *)v282 + 24 * v283 > (char *)&v272)
            {
              int64_t v252 = (char *)&v272 - (unsigned char *)v282;
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v228, 24);
              uint64_t v150 = (char *)v282;
              uint64_t v149 = (char *)v282 + v252;
            }
            else
            {
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v228, 24);
              uint64_t v149 = (char *)&v272;
              uint64_t v150 = (char *)v282;
            }
          }
          uint64_t v151 = &v150[24 * v283];
          long long v152 = *(_OWORD *)v149;
          *((void *)v151 + 2) = *((void *)v149 + 2);
          *(_OWORD *)uint64_t v151 = v152;
          uint64_t v153 = ++v283;
          if (v279)
          {
            LODWORD(v272) = 3;
            uint64_t v273 = " to be valid and contiguous";
            uint64_t v274 = 27;
            uint64_t v154 = (char *)&v272;
            uint64_t v155 = (char *)v282;
            if (v153 >= v284)
            {
              unint64_t v231 = v153 + 1;
              BOOL v232 = (char *)v282 + 24 * v153 > (char *)&v272;
              if (v282 <= &v272 && v232)
              {
                int64_t v255 = (char *)&v272 - (unsigned char *)v282;
                llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v231, 24);
                uint64_t v155 = (char *)v282;
                uint64_t v154 = (char *)v282 + v255;
              }
              else
              {
                llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v231, 24);
                uint64_t v154 = (char *)&v272;
                uint64_t v155 = (char *)v282;
              }
            }
            uint64_t v156 = &v155[24 * v283];
            long long v157 = *(_OWORD *)v154;
            *((void *)v156 + 2) = *((void *)v154 + 2);
            *(_OWORD *)uint64_t v156 = v157;
            ++v283;
          }
        }
        char v29 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v279);
        if (v279) {
          mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v279);
        }
        if (!v290) {
          goto LABEL_252;
        }
        uint64_t v158 = __p;
        if (__p)
        {
          uint64_t v159 = v289;
          uint64_t v160 = __p;
          if (v289 != __p)
          {
            do
              uint64_t v159 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v159 - 1);
            while (v159 != v158);
            uint64_t v160 = __p;
          }
          uint64_t v289 = v158;
          operator delete(v160);
        }
        uint64_t v161 = v286;
        if (v286)
        {
          uint64_t v162 = v287;
          uint64_t v163 = v286;
          if (v287 != v286)
          {
            do
            {
              uint64_t v165 = *--v162;
              uint64_t v164 = v165;
              *uint64_t v162 = 0;
              if (v165) {
                MEMORY[0x21667D390](v164, 0x1000C8077774924);
              }
            }
            while (v162 != v161);
            uint64_t v163 = v286;
          }
          uint64_t v287 = v161;
          operator delete(v163);
        }
        uint64_t v209 = v282;
        if (v282 == v285) {
          goto LABEL_252;
        }
      }
    }
    free(v209);
    goto LABEL_252;
  }
  uint64_t Value = (void *)mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v268);
  if (v81)
  {
    uint64_t v82 = 8 * v81;
    while (*Value == 1)
    {
      ++Value;
      v82 -= 8;
      if (!v82) {
        goto LABEL_152;
      }
    }
    uint64_t v275 = (mlir::AffineMap *)"invalid to reshape tensor/memref with non-unit extent dimensions to zero-rank tensor/memref";
    __int16 v278 = 259;
    mlir::OpState::emitOpError(&v269, (void ***)&v275, (uint64_t)&v279);
    char v29 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v279);
    if (v279) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v279);
    }
    if (v290)
    {
      uint64_t v116 = __p;
      if (__p)
      {
        int v117 = v289;
        int v118 = __p;
        if (v289 != __p)
        {
          do
            int v117 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v117 - 1);
          while (v117 != v116);
          int v118 = __p;
        }
        uint64_t v289 = v116;
        operator delete(v118);
      }
      uint64_t v33 = v286;
      if (v286)
      {
        unint64_t v119 = v287;
        uint64_t v35 = v286;
        if (v287 == v286) {
          goto LABEL_148;
        }
        do
        {
          uint64_t v121 = *--v119;
          uint64_t v120 = v121;
          *unint64_t v119 = 0;
          if (v121) {
            MEMORY[0x21667D390](v120, 0x1000C8077774924);
          }
        }
        while (v119 != v33);
        goto LABEL_147;
      }
LABEL_149:
      unint64_t v122 = v282;
      if (v282 == v285) {
        goto LABEL_151;
      }
      goto LABEL_150;
    }
LABEL_151:
    if (!v29) {
      return 0;
    }
  }
LABEL_152:
  mlir::tensor::CollapseShapeOp::getReassociationExprs((mlir::tensor::CollapseShapeOp *)&v261, &v279);
  mlir::getSymbolLessAffineMaps((uint64_t)v279, v280, (uint64_t)&v275);
  uint64_t v123 = (char *)v279;
  if (v280)
  {
    uint64_t v124 = 32 * v280;
    do
    {
      uint64_t v125 = *(char **)&v123[v124 - 32];
      if (&v123[v124 - 16] != v125) {
        free(v125);
      }
      v124 -= 32;
    }
    while (v124);
    uint64_t v123 = (char *)v279;
  }
  if (v123 != (char *)&v281) {
    free(v123);
  }
  uint64_t v126 = mlir::tensor::CollapseShapeOp::inferCollapsedType((uint64_t)v10, (uint64_t *)v275, v276);
  if (mlir::tensor::isSameTypeWithoutEncoding((uint64_t)v12, v126))
  {
    uint64_t v53 = 1;
  }
  else
  {
    uint64_t v263 = (void **)"expected collapsed type to be ";
    __int16 v266 = 259;
    mlir::OpState::emitOpError(&v261, &v263, (uint64_t)&v279);
    if (v279)
    {
      int v127 = (char *)&v272;
      mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v272, v126);
      unint64_t v128 = (char *)v282;
      if (v283 >= v284)
      {
        unint64_t v215 = v283 + 1;
        if (v282 <= &v272 && (char *)v282 + 24 * v283 > (char *)&v272)
        {
          int64_t v243 = (char *)&v272 - (unsigned char *)v282;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v215, 24);
          unint64_t v128 = (char *)v282;
          int v127 = (char *)v282 + v243;
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v215, 24);
          int v127 = (char *)&v272;
          unint64_t v128 = (char *)v282;
        }
      }
      unint64_t v129 = &v128[24 * v283];
      long long v130 = *(_OWORD *)v127;
      *((void *)v129 + 2) = *((void *)v127 + 2);
      *(_OWORD *)unint64_t v129 = v130;
      uint64_t v131 = ++v283;
      if (v279)
      {
        LODWORD(v272) = 3;
        uint64_t v273 = ", but got ";
        uint64_t v274 = 10;
        uint64_t v132 = (char *)&v272;
        unint64_t v133 = (char *)v282;
        if (v131 >= v284)
        {
          unint64_t v218 = v131 + 1;
          BOOL v219 = (char *)v282 + 24 * v131 > (char *)&v272;
          if (v282 <= &v272 && v219)
          {
            int64_t v245 = (char *)&v272 - (unsigned char *)v282;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v218, 24);
            unint64_t v133 = (char *)v282;
            uint64_t v132 = (char *)v282 + v245;
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v218, 24);
            uint64_t v132 = (char *)&v272;
            unint64_t v133 = (char *)v282;
          }
        }
        uint64_t v134 = &v133[24 * v283];
        long long v135 = *(_OWORD *)v132;
        *((void *)v134 + 2) = *((void *)v132 + 2);
        *(_OWORD *)uint64_t v134 = v135;
        ++v283;
        if (v279)
        {
          int v136 = (char *)&v272;
          mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v272, (uint64_t)v12);
          unint64_t v137 = (char *)v282;
          if (v283 >= v284)
          {
            unint64_t v221 = v283 + 1;
            if (v282 <= &v272 && (char *)v282 + 24 * v283 > (char *)&v272)
            {
              int64_t v247 = (char *)&v272 - (unsigned char *)v282;
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v221, 24);
              unint64_t v137 = (char *)v282;
              int v136 = (char *)v282 + v247;
            }
            else
            {
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v282, v285, v221, 24);
              int v136 = (char *)&v272;
              unint64_t v137 = (char *)v282;
            }
          }
          unint64_t v138 = &v137[24 * v283];
          long long v139 = *(_OWORD *)v136;
          *((void *)v138 + 2) = *((void *)v136 + 2);
          *(_OWORD *)unint64_t v138 = v139;
          ++v283;
        }
      }
    }
    uint64_t v53 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v279);
    if (v279) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v279);
    }
    if (v290)
    {
      unint64_t v140 = __p;
      if (__p)
      {
        uint64_t v141 = v289;
        unint64_t v142 = __p;
        if (v289 != __p)
        {
          do
            uint64_t v141 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v141 - 1);
          while (v141 != v140);
          unint64_t v142 = __p;
        }
        uint64_t v289 = v140;
        operator delete(v142);
      }
      uint64_t v143 = v286;
      if (v286)
      {
        uint64_t v144 = v287;
        uint64_t v145 = v286;
        if (v287 != v286)
        {
          do
          {
            uint64_t v147 = *--v144;
            uint64_t v146 = v147;
            *uint64_t v144 = 0;
            if (v147) {
              MEMORY[0x21667D390](v146, 0x1000C8077774924);
            }
          }
          while (v144 != v143);
          uint64_t v145 = v286;
        }
        uint64_t v287 = v143;
        operator delete(v145);
      }
      if (v282 != v285) {
        free(v282);
      }
    }
  }
  uint64_t v68 = v275;
  if (v275 != (mlir::AffineMap *)v277) {
LABEL_189:
  }
    free(v68);
  return v53;
}

void mlir::tensor::ExpandShapeOp::getCanonicalizationPatterns()
{
}

void mlir::tensor::CollapseShapeOp::getCanonicalizationPatterns()
{
}

unint64_t mlir::tensor::ExpandShapeOp::fold(uint64_t *a1, uint64_t a2)
{
  uint64_t v2 = *a1;
  int v3 = *(uint64_t **)(a2 + 48);
  uint64_t v15 = *(void *)(*(void *)(*a1 + 72) + 24);
  uint64_t DefiningOp = mlir::Value::getDefiningOp((mlir::Value *)&v15);
  if (DefiningOp)
  {
    uint64_t v5 = DefiningOp;
    if (*(_UNKNOWN **)(*(void *)(DefiningOp + 48) + 16) == &mlir::detail::TypeIDResolver<mlir::tensor::CollapseShapeOp,void>::id)
    {
      unint64_t v6 = *(void *)(*(void *)(*(void *)(DefiningOp + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8;
      uint64_t v7 = *(_DWORD *)(v2 + 36) ? v2 - 16 : 0;
      if (v6 == (*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v7, 0) + 8) & 0xFFFFFFFFFFFFFFF8)) {
        return *(void *)(*(void *)(v5 + 72) + 24) | 4;
      }
    }
  }
  uint64_t v8 = *v3;
  if (!*v3) {
    return 0;
  }
  BOOL v9 = mlir::DenseElementsAttr::classof(*v3);
  uint64_t v10 = v9 ? v8 : 0;
  uint64_t v15 = v10;
  if (!v9) {
    return 0;
  }
  if (*(_DWORD *)(v2 + 36)) {
    uint64_t v11 = v2 - 16;
  }
  else {
    uint64_t v11 = 0;
  }
  unsigned int v12 = (void *)(*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v11, 0) + 8) & 0xFFFFFFFFFFFFFFF8);
  if (v12) {
    uint64_t v13 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*v12 + 8);
  }
  else {
    uint64_t v13 = 0;
  }
  return mlir::DenseElementsAttr::reshape(&v15, (uint64_t)v12, v13) & 0xFFFFFFFFFFFFFFFBLL;
}

unint64_t mlir::tensor::CollapseShapeOp::fold(uint64_t *a1, uint64_t a2)
{
  uint64_t v2 = *a1;
  int v3 = *(uint64_t **)(a2 + 48);
  uint64_t v15 = *(void *)(*(void *)(*a1 + 72) + 24);
  uint64_t DefiningOp = mlir::Value::getDefiningOp((mlir::Value *)&v15);
  if (DefiningOp)
  {
    uint64_t v5 = DefiningOp;
    if (*(_UNKNOWN **)(*(void *)(DefiningOp + 48) + 16) == &mlir::detail::TypeIDResolver<mlir::tensor::ExpandShapeOp,void>::id)
    {
      unint64_t v6 = *(void *)(*(void *)(*(void *)(DefiningOp + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8;
      uint64_t v7 = *(_DWORD *)(v2 + 36) ? v2 - 16 : 0;
      if (v6 == (*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v7, 0) + 8) & 0xFFFFFFFFFFFFFFF8)) {
        return *(void *)(*(void *)(v5 + 72) + 24) | 4;
      }
    }
  }
  uint64_t v8 = *v3;
  if (!*v3) {
    return 0;
  }
  BOOL v9 = mlir::DenseElementsAttr::classof(*v3);
  uint64_t v10 = v9 ? v8 : 0;
  uint64_t v15 = v10;
  if (!v9) {
    return 0;
  }
  if (*(_DWORD *)(v2 + 36)) {
    uint64_t v11 = v2 - 16;
  }
  else {
    uint64_t v11 = 0;
  }
  unsigned int v12 = (void *)(*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v11, 0) + 8) & 0xFFFFFFFFFFFFFFF8);
  if (v12) {
    uint64_t v13 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*v12 + 8);
  }
  else {
    uint64_t v13 = 0;
  }
  return mlir::DenseElementsAttr::reshape(&v15, (uint64_t)v12, v13) & 0xFFFFFFFFFFFFFFFBLL;
}

uint64_t mlir::tensor::ExtractSliceOp::getAsmResultNames(uint64_t a1, uint64_t (*a2)(uint64_t, uint64_t, const char *, uint64_t), uint64_t a3)
{
  if (*(_DWORD *)(*(void *)a1 + 36)) {
    uint64_t v4 = *(void *)a1 - 16;
  }
  else {
    uint64_t v4 = 0;
  }
  uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v4, 0);

  return a2(a3, NextResultAtOffset, "extracted_slice", 15);
}

uint64_t mlir::tensor::ExtractSliceOp::inferResultType(uint64_t a1, uint64_t *a2, uint64_t a3, uint64_t *a4, uint64_t a5, uint64_t *a6, uint64_t a7)
{
  v30[6] = *MEMORY[0x263EF8340];
  v29[0] = v30;
  v29[1] = (void *)0x600000000;
  uint64_t v26 = v28;
  uint64_t v27 = 0x600000000;
  v24[0] = v25;
  v24[1] = (void *)0x600000000;
  v22[0] = v23;
  v22[1] = (void *)0x600000000;
  v20[0] = v21;
  v20[1] = (void *)0x600000000;
  v18[0] = v19;
  v18[1] = (void *)0x600000000;
  mlir::dispatchIndexOpFoldResults(a2, a3, (uint64_t)v22, (uint64_t)v29);
  mlir::dispatchIndexOpFoldResults(a4, a5, (uint64_t)v20, (uint64_t)&v26);
  mlir::dispatchIndexOpFoldResults(a6, a7, (uint64_t)v18, (uint64_t)v24);
  uint64_t v12 = (uint64_t)v26;
  uint64_t v13 = v27;
  uint64_t v17 = a1;
  uint64_t RHS = mlir::AffineBinaryOpExpr::getRHS((mlir::AffineBinaryOpExpr *)&v17);
  uint64_t v15 = mlir::RankedTensorType::get(v12, v13, RHS, 0);
  if (v18[0] != v19) {
    free(v18[0]);
  }
  if (v20[0] != v21) {
    free(v20[0]);
  }
  if (v22[0] != v23) {
    free(v22[0]);
  }
  if (v24[0] != v25) {
    free(v24[0]);
  }
  if (v26 != v28) {
    free(v26);
  }
  if (v29[0] != v30) {
    free(v29[0]);
  }
  return v15;
}

uint64_t mlir::tensor::ExtractSliceOp::inferCanonicalRankReducedResultType(int a1, void *a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  v27[6] = *MEMORY[0x263EF8340];
  uint64_t v25 = a2;
  uint64_t RHS = mlir::AffineBinaryOpExpr::getRHS((mlir::AffineBinaryOpExpr *)&v25);
  uint64_t v24 = mlir::RankedTensorType::get(a5, a6, RHS, 0);
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v24);
  uint64_t v11 = (v10 - a1);
  if ((int)v11 >= 1)
  {
    uint64_t Value = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v24);
    int v14 = v13;
    mlir::getPositionsOfShapeOne(v11, Value, v13, (unint64_t *)&v23);
    uint64_t v25 = v27;
    uint64_t v26 = 0x600000000;
    unsigned int v15 = 0;
    if (v14)
    {
      uint64_t v16 = 0;
      while (1)
      {
        if (v23)
        {
          if (((1 << v16) & ((unint64_t)v23 >> 1) & ~(-1 << ((unint64_t)v23 >> 58))) == 0)
          {
LABEL_10:
            uint64_t v17 = *(void *)(Value + 8 * v16);
            if (v15 >= HIDWORD(v26))
            {
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v25, v27, v15 + 1, 8);
              unsigned int v15 = v26;
            }
            *((void *)v25 + v15) = v17;
            unsigned int v15 = v26 + 1;
            LODWORD(v26) = v26 + 1;
          }
        }
        else if ((*((void *)*v23 + (v16 >> 6)) & (1 << v16)) == 0)
        {
          goto LABEL_10;
        }
        if (v14 == ++v16)
        {
          uint64_t v18 = v25;
          goto LABEL_14;
        }
      }
    }
    uint64_t v18 = v27;
LABEL_14:
    uint64_t v19 = v15;
    uint64_t v20 = mlir::AffineBinaryOpExpr::getRHS((mlir::AffineBinaryOpExpr *)&v24);
    uint64_t v24 = mlir::RankedTensorType::get((uint64_t)v18, v19, v20, 0);
    if (v25 != v27) {
      free(v25);
    }
    uint64_t v21 = v23;
    if ((v23 & 1) == 0 && v23)
    {
      if (*v23 != v23 + 2) {
        free(*v23);
      }
      MEMORY[0x21667D3C0](v21, 0x1080C40EF38A13ELL);
    }
  }
  return v24;
}

BOOL llvm::SmallBitVector::test(llvm::SmallBitVector *this, unsigned int a2)
{
  unint64_t v2 = *(void *)this;
  if (*(void *)this) {
    return ((1 << a2) & (v2 >> 1) & ~(-1 << (v2 >> 58))) != 0;
  }
  else {
    return (*(void *)(*(void *)v2 + 8 * (a2 >> 6)) & (1 << a2)) != 0;
  }
}

uint64_t mlir::tensor::ExtractSliceOp::inferCanonicalRankReducedResultType(int a1, void *a2, uint64_t *a3, uint64_t a4, uint64_t *a5, uint64_t a6, uint64_t *a7, uint64_t a8)
{
  v30[6] = *MEMORY[0x263EF8340];
  v29[0] = v30;
  v29[1] = (void *)0x600000000;
  uint64_t v26 = v28;
  uint64_t v27 = 0x600000000;
  v24[0] = v25;
  v24[1] = (void *)0x600000000;
  v22[0] = v23;
  v22[1] = (void *)0x600000000;
  v20[0] = v21;
  v20[1] = (void *)0x600000000;
  v18[0] = v19;
  v18[1] = (void *)0x600000000;
  mlir::dispatchIndexOpFoldResults(a3, a4, (uint64_t)v22, (uint64_t)v29);
  mlir::dispatchIndexOpFoldResults(a5, a6, (uint64_t)v20, (uint64_t)&v26);
  mlir::dispatchIndexOpFoldResults(a7, a8, (uint64_t)v18, (uint64_t)v24);
  uint64_t v16 = mlir::tensor::ExtractSliceOp::inferCanonicalRankReducedResultType(a1, a2, v14, v15, (uint64_t)v26, v27);
  if (v18[0] != v19) {
    free(v18[0]);
  }
  if (v20[0] != v21) {
    free(v20[0]);
  }
  if (v22[0] != v23) {
    free(v22[0]);
  }
  if (v24[0] != v25) {
    free(v24[0]);
  }
  if (v26 != v28) {
    free(v26);
  }
  if (v29[0] != v30) {
    free(v29[0]);
  }
  return v16;
}

void mlir::tensor::ExtractSliceOp::build(mlir::MLIRContext **a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t *a5, uint64_t a6, uint64_t *a7, uint64_t a8, uint64_t *a9, uint64_t a10, void *__src, uint64_t a12)
{
  v46[6] = *MEMORY[0x263EF8340];
  uint64_t v44 = v46;
  uint64_t v45 = 0x600000000;
  __int16 v41 = v43;
  uint64_t v42 = 0x600000000;
  uint64_t v38 = v40;
  uint64_t v39 = 0x600000000;
  uint64_t v35 = v37;
  uint64_t v36 = 0x600000000;
  uint64_t v32 = v34;
  uint64_t v33 = 0x600000000;
  char v29 = v31;
  uint64_t v30 = 0x600000000;
  mlir::dispatchIndexOpFoldResults(a5, a6, (uint64_t)&v35, (uint64_t)&v44);
  mlir::dispatchIndexOpFoldResults(a7, a8, (uint64_t)&v32, (uint64_t)&v41);
  mlir::dispatchIndexOpFoldResults(a9, a10, (uint64_t)&v29, (uint64_t)&v38);
  if (!a3)
  {
    uint64_t v18 = (uint64_t)v41;
    uint64_t v19 = v42;
    unint64_t v25 = *(void *)(a4 + 8) & 0xFFFFFFFFFFFFFFF8;
    uint64_t RHS = mlir::AffineBinaryOpExpr::getRHS((mlir::AffineBinaryOpExpr *)&v25);
    a3 = mlir::RankedTensorType::get(v18, v19, RHS, 0);
  }
  mlir::ValueRange::ValueRange(v28, (uint64_t)v35, v36);
  mlir::ValueRange::ValueRange(v27, (uint64_t)v32, v33);
  mlir::ValueRange::ValueRange(v26, (uint64_t)v29, v30);
  uint64_t DenseI64ArrayAttr = mlir::Builder::getDenseI64ArrayAttr(a1, (uint64_t)v44, v45);
  uint64_t v22 = mlir::Builder::getDenseI64ArrayAttr(a1, (uint64_t)v41, v42);
  uint64_t v23 = mlir::Builder::getDenseI64ArrayAttr(a1, (uint64_t)v38, v39);
  mlir::tensor::ExtractSliceOp::build(v23, a2, a3, a4, v28[0], v28[1], v27[0], v27[1], v26[0], v26[1], DenseI64ArrayAttr, v22, v23);
  *(void *)(a2 + 192) = 0;
  uint64_t v24 = *(unsigned int *)(a2 + 120);
  if (a12 + v24 > (unint64_t)*(unsigned int *)(a2 + 124))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod(a2 + 112, (void *)(a2 + 128), a12 + v24, 16);
    LODWORD(v24) = *(_DWORD *)(a2 + 120);
  }
  if (a12)
  {
    memcpy((void *)(*(void *)(a2 + 112) + 16 * v24), __src, 16 * a12);
    LODWORD(v24) = *(_DWORD *)(a2 + 120);
  }
  *(_DWORD *)(a2 + 120) = v24 + a12;
  if (v29 != v31) {
    free(v29);
  }
  if (v32 != v34) {
    free(v32);
  }
  if (v35 != v37) {
    free(v35);
  }
  if (v38 != v40) {
    free(v38);
  }
  if (v41 != v43) {
    free(v41);
  }
  if (v44 != v46) {
    free(v44);
  }
}

void mlir::tensor::ExtractSliceOp::build(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13)
{
  uint64_t v21 = a4;
  mlir::OperationState::addOperands(a2, (uint64_t)&v21, 1);
  mlir::OperationState::addOperands(a2, a5, a6);
  mlir::OperationState::addOperands(a2, a7, a8);
  mlir::OperationState::addOperands(a2, a9, a10);
  uint64_t v18 = (_DWORD *)mlir::OperationState::getOrAddProperties<mlir::tensor::detail::ExtractSliceOpGenericAdaptorBase::Properties>(a2);
  v18[6] = 1;
  void v18[7] = a6;
  v18[8] = a8;
  v18[9] = a10;
  *(void *)mlir::OperationState::getOrAddProperties<mlir::tensor::detail::ExtractSliceOpGenericAdaptorBase::Properties>(a2) = a11;
  *(void *)(mlir::OperationState::getOrAddProperties<mlir::tensor::detail::ExtractSliceOpGenericAdaptorBase::Properties>(a2)
            + 8) = a12;
  *(void *)(mlir::OperationState::getOrAddProperties<mlir::tensor::detail::ExtractSliceOpGenericAdaptorBase::Properties>(a2)
            + 16) = a13;
  uint64_t v19 = *(unsigned int *)(a2 + 72);
  if (v19 >= *(_DWORD *)(a2 + 76))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod(a2 + 64, (void *)(a2 + 80), v19 + 1, 8);
    LODWORD(v19) = *(_DWORD *)(a2 + 72);
  }
  *(void *)(*(void *)(a2 + 64) + 8 * v19) = a3;
  ++*(_DWORD *)(a2 + 72);
}

uint64_t mlir::tensor::ExtractSliceOp::verify(mlir::tensor::ExtractSliceOp *this)
{
  v21[4] = *MEMORY[0x263EF8340];
  unint64_t v2 = *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8;
  mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::memref::ReinterpretCastOp>::getMixedOffsets(this, (uint64_t)&v19);
  int v3 = (uint64_t *)v19;
  uint64_t v4 = v20;
  mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::memref::ReinterpretCastOp>::getMixedSizes(this, (uint64_t)&v16);
  uint64_t v5 = (uint64_t *)v16;
  uint64_t v6 = v17;
  mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::memref::ReinterpretCastOp>::getMixedStrides(this, (uint64_t)&v13);
  uint64_t v7 = (void *)mlir::tensor::ExtractSliceOp::inferResultType(v2, v3, v4, v5, v6, (uint64_t *)v13, v14);
  if (v13 != &v15) {
    free(v13);
  }
  if (v16 != &v18) {
    free(v16);
  }
  if (v19 != v21) {
    free(v19);
  }
  if (v7) {
    uint64_t v8 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*v7 + 8);
  }
  else {
    uint64_t v8 = 0;
  }
  if (*(_DWORD *)(*(void *)this + 36)) {
    uint64_t v9 = *(void *)this - 16;
  }
  else {
    uint64_t v9 = 0;
  }
  int v10 = (void *)(*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v9, 0) + 8) & 0xFFFFFFFFFFFFFFF8);
  if (v10) {
    mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*v10 + 8);
  }
  int isRankReducedType = mlir::isRankReducedType(v7, v8, v10);
  return produceSliceErrorMsg(isRankReducedType, *(void *)this, (uint64_t)v7);
}

uint64_t produceSliceErrorMsg(int a1, uint64_t a2, uint64_t a3)
{
  uint64_t v69 = *MEMORY[0x263EF8340];
  uint64_t v55 = a3;
  uint64_t v3 = 1;
  switch(a1)
  {
    case 1:
      v53[0] = "expected rank to be smaller or equal to ";
      __int16 v54 = 259;
      mlir::Operation::emitError(a2, (uint64_t)v53, (uint64_t)v59);
      if (v59[0])
      {
        int v56 = 3;
        unint64_t v57 = "the other rank. ";
        uint64_t v58 = 16;
        uint64_t v4 = &v56;
        uint64_t v5 = (char *)v60;
        if (v61 >= v62)
        {
          unint64_t v44 = v61 + 1;
          if (v60 <= &v56 && (char *)v60 + 24 * v61 > (char *)&v56)
          {
            int64_t v49 = (char *)&v56 - (unsigned char *)v60;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v60, v63, v44, 24);
            uint64_t v5 = (char *)v60;
            uint64_t v4 = (int *)((char *)v60 + v49);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v60, v63, v44, 24);
            uint64_t v4 = &v56;
            uint64_t v5 = (char *)v60;
          }
        }
        uint64_t v6 = &v5[24 * v61];
        long long v7 = *(_OWORD *)v4;
        *((void *)v6 + 2) = *((void *)v4 + 2);
        *(_OWORD *)uint64_t v6 = v7;
        ++v61;
      }
      uint64_t v3 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v59);
      if (v59[0]) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v59);
      }
      if (v68)
      {
        uint64_t v8 = __p;
        if (__p)
        {
          uint64_t v9 = v67;
          int v10 = __p;
          if (v67 != __p)
          {
            do
              uint64_t v9 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v9 - 1);
            while (v9 != v8);
            int v10 = __p;
          }
          uint64_t v67 = v8;
          operator delete(v10);
        }
        uint64_t v11 = v64;
        if (!v64) {
          goto LABEL_57;
        }
        uint64_t v12 = v65;
        uint64_t v13 = v64;
        if (v65 == v64) {
          goto LABEL_56;
        }
        do
        {
          uint64_t v15 = *--v12;
          uint64_t v14 = v15;
          *uint64_t v12 = 0;
          if (v15) {
            MEMORY[0x21667D390](v14, 0x1000C8077774924);
          }
        }
        while (v12 != v11);
        goto LABEL_55;
      }
      break;
    case 2:
      v53[0] = "expected type to be ";
      __int16 v54 = 259;
      mlir::Operation::emitError(a2, (uint64_t)v53, (uint64_t)v59);
      if (v59[0])
      {
        unsigned int v17 = &v56;
        mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v56, a3);
        uint64_t v18 = (char *)v60;
        if (v61 >= v62)
        {
          unint64_t v45 = v61 + 1;
          if (v60 <= &v56 && (char *)v60 + 24 * v61 > (char *)&v56)
          {
            int64_t v50 = (char *)&v56 - (unsigned char *)v60;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v60, v63, v45, 24);
            uint64_t v18 = (char *)v60;
            unsigned int v17 = (int *)((char *)v60 + v50);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v60, v63, v45, 24);
            unsigned int v17 = &v56;
            uint64_t v18 = (char *)v60;
          }
        }
        uint64_t v19 = &v18[24 * v61];
        long long v20 = *(_OWORD *)v17;
        *((void *)v19 + 2) = *((void *)v17 + 2);
        *(_OWORD *)uint64_t v19 = v20;
        uint64_t v21 = ++v61;
        if (v59[0])
        {
          int v56 = 3;
          unint64_t v57 = " or a rank-reduced version. (size mismatch) ";
          uint64_t v58 = 44;
          uint64_t v22 = &v56;
          uint64_t v23 = (char *)v60;
          if (v21 >= v62)
          {
            unint64_t v47 = v21 + 1;
            BOOL v48 = (char *)v60 + 24 * v21 > (char *)&v56;
            if (v60 <= &v56 && v48)
            {
              int64_t v52 = (char *)&v56 - (unsigned char *)v60;
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v60, v63, v47, 24);
              uint64_t v23 = (char *)v60;
              uint64_t v22 = (int *)((char *)v60 + v52);
            }
            else
            {
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v60, v63, v47, 24);
              uint64_t v22 = &v56;
              uint64_t v23 = (char *)v60;
            }
          }
          uint64_t v24 = &v23[24 * v61];
          long long v25 = *(_OWORD *)v22;
          *((void *)v24 + 2) = *((void *)v22 + 2);
          *(_OWORD *)uint64_t v24 = v25;
          ++v61;
        }
      }
      uint64_t v3 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v59);
      if (v59[0]) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v59);
      }
      if (v68)
      {
        uint64_t v26 = __p;
        if (__p)
        {
          uint64_t v27 = v67;
          long long v28 = __p;
          if (v67 != __p)
          {
            do
              uint64_t v27 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v27 - 1);
            while (v27 != v26);
            long long v28 = __p;
          }
          uint64_t v67 = v26;
          operator delete(v28);
        }
        uint64_t v11 = v64;
        if (!v64) {
          goto LABEL_57;
        }
        char v29 = v65;
        uint64_t v13 = v64;
        if (v65 == v64) {
          goto LABEL_56;
        }
        do
        {
          uint64_t v31 = *--v29;
          uint64_t v30 = v31;
          void *v29 = 0;
          if (v31) {
            MEMORY[0x21667D390](v30, 0x1000C8077774924);
          }
        }
        while (v29 != v11);
        goto LABEL_55;
      }
      break;
    case 3:
      v53[0] = "expected element type to be ";
      __int16 v54 = 259;
      mlir::Operation::emitError(a2, (uint64_t)v53, (uint64_t)v59);
      uint64_t RHS = mlir::AffineBinaryOpExpr::getRHS((mlir::AffineBinaryOpExpr *)&v55);
      if (v59[0])
      {
        uint64_t v33 = &v56;
        mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v56, RHS);
        unint64_t v34 = (char *)v60;
        if (v61 >= v62)
        {
          unint64_t v46 = v61 + 1;
          if (v60 <= &v56 && (char *)v60 + 24 * v61 > (char *)&v56)
          {
            int64_t v51 = (char *)&v56 - (unsigned char *)v60;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v60, v63, v46, 24);
            unint64_t v34 = (char *)v60;
            uint64_t v33 = (int *)((char *)v60 + v51);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v60, v63, v46, 24);
            uint64_t v33 = &v56;
            unint64_t v34 = (char *)v60;
          }
        }
        uint64_t v35 = &v34[24 * v61];
        long long v36 = *(_OWORD *)v33;
        *((void *)v35 + 2) = *((void *)v33 + 2);
        *(_OWORD *)uint64_t v35 = v36;
        ++v61;
      }
      uint64_t v3 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v59);
      if (v59[0]) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v59);
      }
      if (v68)
      {
        uint64_t v37 = __p;
        if (__p)
        {
          uint64_t v38 = v67;
          uint64_t v39 = __p;
          if (v67 != __p)
          {
            do
              uint64_t v38 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v38 - 1);
            while (v38 != v37);
            uint64_t v39 = __p;
          }
          uint64_t v67 = v37;
          operator delete(v39);
        }
        uint64_t v11 = v64;
        if (v64)
        {
          uint64_t v40 = v65;
          uint64_t v13 = v64;
          if (v65 != v64)
          {
            do
            {
              uint64_t v42 = *--v40;
              uint64_t v41 = v42;
              *uint64_t v40 = 0;
              if (v42) {
                MEMORY[0x21667D390](v41, 0x1000C8077774924);
              }
            }
            while (v40 != v11);
LABEL_55:
            uint64_t v13 = v64;
          }
LABEL_56:
          unint64_t v65 = v11;
          operator delete(v13);
        }
LABEL_57:
        if (v60 != v63) {
          free(v60);
        }
      }
      break;
    default:
      return v3;
  }
  return v3;
}

unint64_t *getDroppedDims(unint64_t *result, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v8 = result;
  if (a5 >= 0x3A) {
    operator new();
  }
  unint64_t v9 = (a5 << 58) | 1;
  *unint64_t result = v9;
  if (a5)
  {
    uint64_t v10 = 0;
    uint64_t v11 = 0;
    for (uint64_t i = 8 * a5; i; i -= 8)
    {
      uint64_t v13 = *(void *)(a4 + 8 * v11);
      if ((v13 & 4) != 0)
      {
        if (v10 == a3) {
          goto LABEL_14;
        }
      }
      else
      {
        unint64_t v14 = v13 & 0xFFFFFFFFFFFFFFF8;
        unint64_t result = (unint64_t *)mlir::IntegerAttr::getInt((mlir::IntegerAttr *)&v14);
        if (v10 == a3 || result == (unint64_t *)1 && *(void *)(a2 + 8 * v10) != 1)
        {
LABEL_14:
          if (v9)
          {
            unint64_t v9 = v9 & 0xFC00000000000000 | (2
                                            * (((v9 >> 1) & ~(-1 << (v9 >> 58)) | (1 << v11)) & ~(-1 << (v9 >> 58)))) | 1;
            *uint64_t v8 = v9;
          }
          else
          {
            *(void *)(*(void *)v9 + 8 * (v11 >> 6)) |= 1 << v11;
          }
          goto LABEL_7;
        }
      }
      ++v10;
LABEL_7:
      ++v11;
    }
  }
  return result;
}

uint64_t mlir::tensor::ExtractSliceOp::reifyResultShapes(mlir::memref::ReinterpretCastOp *a1, uint64_t a2, unsigned int *a3)
{
  v51[4] = *MEMORY[0x263EF8340];
  uint64_t v5 = a3[2];
  if (v5)
  {
    if (v5 == 1) {
      goto LABEL_19;
    }
    uint64_t v6 = *(void *)a3;
    uint64_t v7 = v5 << 6;
    do
    {
      uint64_t v8 = *(void **)(v6 + v7 - 64);
      if ((void *)(v6 + v7 - 48) != v8) {
        free(v8);
      }
      v7 -= 64;
    }
    while (v7 != 64);
  }
  else
  {
    if (a3[3])
    {
      uint64_t v9 = 0;
    }
    else
    {
      llvm::SmallVectorTemplateBase<llvm::SmallVector<mlir::OpFoldResult,6u>,false>::grow((uint64_t)a3, 1uLL);
      uint64_t v9 = a3[2];
      if (v9 == 1) {
        goto LABEL_18;
      }
    }
    uint64_t v10 = *(void *)a3;
    uint64_t v11 = *(void *)a3 + (v9 << 6);
    uint64_t v12 = -v9 & 0x3FFFFFFFFFFFFFFLL;
    if (v12)
    {
      uint64_t v13 = v12 + 1;
      uint64_t v14 = (v12 + 1) & 0x7FFFFFFFFFFFFFELL;
      uint64_t v15 = v11 + (v14 << 6);
      uint64_t v16 = v11 + 80;
      uint64_t v17 = v14;
      do
      {
        *(void *)(v16 - 80) = v16 - 64;
        *(void *)(v16 - 16) = v16;
        *(void *)(v16 - 72) = 0x600000000;
        *(void *)(v16 - 8) = 0x600000000;
        v16 += 128;
        v17 -= 2;
      }
      while (v17);
      if (v13 == v14) {
        goto LABEL_18;
      }
    }
    else
    {
      uint64_t v15 = v11;
    }
    uint64_t v18 = v15 + 16;
    do
    {
      uint64_t v19 = v18 - 16;
      *(void *)(v18 - 16) = v18;
      *(void *)(v18 - 8) = 0x600000000;
      v18 += 64;
    }
    while (v19 != v10);
  }
LABEL_18:
  a3[2] = 1;
LABEL_19:
  uint64_t v20 = *(void *)a3;
  if (*(_DWORD *)(*(void *)a1 + 36)) {
    uint64_t v21 = *(void *)a1 - 16;
  }
  else {
    uint64_t v21 = 0;
  }
  __dst = (void *)(*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v21, 0) + 8) & 0xFFFFFFFFFFFFFFF8);
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&__dst);
  if (v22 > *(unsigned int *)(v20 + 12)) {
    llvm::SmallVectorBase<unsigned int>::grow_pod(v20, (void *)(v20 + 16), v22, 8);
  }
  mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::memref::ReinterpretCastOp>::getMixedSizes(a1, (uint64_t)&__src);
  __dst = v48;
  uint64_t v47 = 0x600000000;
  int v23 = v50;
  uint64_t v24 = __src;
  if (v50)
  {
    if (__src == v51)
    {
      unsigned int v25 = v50;
      if (v50 < 7
        || (llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&__dst, v48, v50, 8),
            unsigned int v25 = v50,
            uint64_t v24 = __src,
            v50))
      {
        memcpy(__dst, v24, 8 * v25);
        uint64_t v24 = __src;
      }
      LODWORD(v47) = v23;
    }
    else
    {
      __dst = __src;
      uint64_t v47 = v50;
      __src = v51;
      HIDWORD(v50) = 0;
      uint64_t v24 = v51;
    }
    LODWORD(v50) = 0;
  }
  if (v24 != v51) {
    free(v24);
  }
  if (*(_DWORD *)(*(void *)a1 + 36)) {
    uint64_t v26 = *(void *)a1 - 16;
  }
  else {
    uint64_t v26 = 0;
  }
  unint64_t v45 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v26, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
  uint64_t Value = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v45);
  uint64_t v29 = v28;
  mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::memref::ReinterpretCastOp>::getMixedSizes(a1, (uint64_t)&__src);
  getDroppedDims((unint64_t *)&v44, Value, v29, (uint64_t)__src, v50);
  if (__src != v51) {
    free(__src);
  }
  uint64_t v30 = v44;
  if (!v47)
  {
    if (v44) {
      goto LABEL_52;
    }
    goto LABEL_48;
  }
  uint64_t v31 = __dst;
  if ((v44 & 1) == 0)
  {
    uint64_t v32 = 0;
    uint64_t v33 = 8 * v47;
    do
    {
      if (((*((void *)*v30 + (v32 >> 6)) >> v32) & 1) == 0)
      {
        uint64_t v34 = *(void *)a3;
        uint64_t v35 = v31[v32];
        unint64_t v36 = *(unsigned int *)(*(void *)a3 + 8);
        if (v36 >= *(unsigned int *)(*(void *)a3 + 12))
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod(*(void *)a3, (void *)(v34 + 16), v36 + 1, 8);
          unint64_t v36 = *(unsigned int *)(v34 + 8);
        }
        *(void *)(*(void *)v34 + 8 * v36) = v35;
        ++*(_DWORD *)(v34 + 8);
      }
      ++v32;
      v33 -= 8;
    }
    while (v33);
LABEL_48:
    if (v30)
    {
      if (*v30 != v30 + 2) {
        free(*v30);
      }
      MEMORY[0x21667D3C0](v30, 0x1080C40EF38A13ELL);
    }
    goto LABEL_52;
  }
  uint64_t v38 = 0;
  uint64_t v39 = 8 * v47;
  unint64_t v40 = ((unint64_t)v44 >> 1) & ~(-1 << ((unint64_t)v44 >> 58));
  do
  {
    if ((v40 & (1 << v38)) == 0)
    {
      uint64_t v41 = *(void *)a3;
      uint64_t v42 = v31[v38];
      unint64_t v43 = *(unsigned int *)(*(void *)a3 + 8);
      if (v43 >= *(unsigned int *)(*(void *)a3 + 12))
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod(*(void *)a3, (void *)(v41 + 16), v43 + 1, 8);
        unint64_t v43 = *(unsigned int *)(v41 + 8);
      }
      *(void *)(*(void *)v41 + 8 * v43) = v42;
      ++*(_DWORD *)(v41 + 8);
    }
    ++v38;
    v39 -= 8;
  }
  while (v39);
LABEL_52:
  if (__dst != v48) {
    free(__dst);
  }
  return 1;
}

void mlir::tensor::ExtractSliceOp::getCanonicalizationPatterns()
{
}

unint64_t mlir::tensor::ExtractSliceOp::fold(uint64_t *a1, uint64_t a2)
{
  uint64_t v3 = *(uint64_t **)(a2 + 80);
  unint64_t v4 = *v3;
  if (*v3)
  {
    if (mlir::DenseElementsAttr::classof(*v3)) {
      unint64_t v5 = v4;
    }
    else {
      unint64_t v5 = 0;
    }
    unint64_t v41 = v5;
    if (v5)
    {
      if (!mlir::DenseElementsAttr::isSplat((mlir::DenseElementsAttr *)&v41)) {
        unint64_t v4 = 0;
      }
    }
    else
    {
      unint64_t v4 = 0;
    }
  }
  if (*(_DWORD *)(*a1 + 36)) {
    uint64_t v6 = *a1 - 16;
  }
  else {
    uint64_t v6 = 0;
  }
  uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v6, 0);
  unint64_t result = reshapeConstantSource(v4, (void *)(*(void *)(NextResultAtOffset + 8) & 0xFFFFFFFFFFFFFFF8));
  if (result <= 7)
  {
    if (*(_DWORD *)(*a1 + 36)) {
      uint64_t v10 = *a1 - 16;
    }
    else {
      uint64_t v10 = 0;
    }
    unint64_t v9 = *(void *)(*(void *)(*(void *)(*a1 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8;
    if (v9 != (*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v10, 0) + 8) & 0xFFFFFFFFFFFFFFF8))
    {
LABEL_18:
      uint64_t v11 = *a1;
      unint64_t v41 = *(void *)(*(void *)(v11 + 72) + 24);
      uint64_t DefiningOp = mlir::Value::getDefiningOp((mlir::Value *)&v41);
      if (!DefiningOp) {
        return 0;
      }
      uint64_t v13 = *(void **)(*(void *)(DefiningOp + 48) + 16);
      BOOL v14 = v13 == &mlir::detail::TypeIDResolver<mlir::tensor::InsertSliceOp,void>::id;
      uint64_t v15 = v13 == &mlir::detail::TypeIDResolver<mlir::tensor::InsertSliceOp,void>::id ? DefiningOp : 0;
      uint64_t v40 = v15;
      if (!v14) {
        return 0;
      }
      unint64_t v16 = *(void *)(*(void *)(*(void *)(DefiningOp + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8;
      uint64_t v17 = *(_DWORD *)(v11 + 36) ? v11 - 16 : 0;
      if (v16 != (*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v17, 0) + 8) & 0xFFFFFFFFFFFFFFF8)) {
        return 0;
      }
      uint64_t v18 = *(void *)(v11 + 48);
      uint64_t v19 = *(void **)(v18 + 16);
      BOOL v20 = v19 == &mlir::detail::TypeIDResolver<void,void>::id;
      if (v19 == &mlir::detail::TypeIDResolver<void,void>::id) {
        uint64_t v21 = 0;
      }
      else {
        uint64_t v21 = *(void *)(v11 + 48);
      }
      if (v20)
      {
        unint64_t v41 = *(void *)(v18 + 8);
        uint64_t Values = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)&v41);
        if (!Values)
        {
          uint64_t v23 = 0;
LABEL_57:
          if (mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::memref::ReinterpretCastOp>::isSameAs(&v40, v11, v23, (uint64_t (*)(uint64_t, void, void))llvm::function_ref<BOOL ()(mlir::OpFoldResult,mlir::OpFoldResult)>::callback_fn<foldExtractAfterInsertSlice(mlir::tensor::ExtractSliceOp)::$_0>, (uint64_t)&v39))
          {
            uint64_t v38 = *(void *)(*(void *)(v40 + 72) + 24);
            if (v38) {
              return v38 | 4;
            }
            else {
              return 0;
            }
          }
          return 0;
        }
        uint64_t v25 = v18;
      }
      else
      {
        unint64_t v22 = v21 | v18 & 0xFFFFFFFFFFFFFF00;
        uint64_t v23 = mlir::detail::InterfaceMap::lookup<mlir::OffsetSizeAndStrideOpInterface>(v22 + 32);
        if (v23) {
          goto LABEL_57;
        }
        uint64_t Values = *(void *)(v22 + 24);
        uint64_t v25 = *(void *)(v11 + 48);
      }
      uint64_t v23 = mlir::Dialect::getRegisteredInterfaceForOp<mlir::OffsetSizeAndStrideOpInterface>(Values, v25);
      goto LABEL_57;
    }
    uint64_t v26 = *a1;
    if (*a1)
    {
      uint64_t v27 = *(void *)(v26 + 48);
      uint64_t v28 = *(void **)(v27 + 16);
      BOOL v29 = v28 == &mlir::detail::TypeIDResolver<void,void>::id;
      if (v28 == &mlir::detail::TypeIDResolver<void,void>::id) {
        uint64_t v30 = 0;
      }
      else {
        uint64_t v30 = *(void *)(v26 + 48);
      }
      if (!v29)
      {
        unint64_t v31 = v30 | v27 & 0xFFFFFFFFFFFFFF00;
        uint64_t v32 = mlir::detail::InterfaceMap::lookup<mlir::OffsetSizeAndStrideOpInterface>(v31 + 32);
        if (v32) {
          goto LABEL_45;
        }
        uint64_t v33 = *(void *)(v31 + 24);
        uint64_t v34 = *(void *)(v26 + 48);
        goto LABEL_43;
      }
      unint64_t v41 = *(void *)(v27 + 8);
      uint64_t v33 = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)&v41);
      if (v33)
      {
        uint64_t v34 = v27;
LABEL_43:
        uint64_t v32 = mlir::Dialect::getRegisteredInterfaceForOp<mlir::OffsetSizeAndStrideOpInterface>(v33, v34);
        goto LABEL_45;
      }
    }
    uint64_t v32 = 0;
LABEL_45:
    if (*(_DWORD *)(*a1 + 36)) {
      uint64_t v35 = *a1 - 16;
    }
    else {
      uint64_t v35 = 0;
    }
    unint64_t v36 = (void *)(*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v35, 0) + 8) & 0xFFFFFFFFFFFFFFF8);
    if (v36)
    {
      uint64_t v37 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*v36 + 8);
      if (!foldIdentityOffsetSizeAndStrideOpInterface(v26, v32, (uint64_t)v36, v37)) {
        goto LABEL_18;
      }
    }
    else if (!foldIdentityOffsetSizeAndStrideOpInterface(v26, v32, 0, 0))
    {
      goto LABEL_18;
    }
    return *(void *)(*(void *)(*a1 + 72) + 24) | 4;
  }
  return result;
}

uint64_t foldIdentityOffsetSizeAndStrideOpInterface(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v47 = *MEMORY[0x263EF8340];
  v39[0] = a1;
  v39[1] = a2;
  v38[0] = a3;
  v38[1] = a4;
  mlir::Attribute::getContext((mlir::Attribute *)(a1 + 24));
  mlir::OffsetSizeAndStrideOpInterface::getMixedOffsets((uint64_t *)&__dst, (mlir::OffsetSizeAndStrideOpInterface *)v39);
  unint64_t v4 = (uint64_t *)__dst;
  if (v44)
  {
    uint64_t v5 = 8 * v44 - 8;
    do
    {
      uint64_t v6 = *v4++;
      unint64_t ConstantIntValue = mlir::getConstantIntValue(v6);
      if (v8) {
        BOOL v9 = ConstantIntValue == 0;
      }
      else {
        BOOL v9 = 0;
      }
      int v10 = v9;
      BOOL v11 = v10 != 1 || v5 == 0;
      v5 -= 8;
    }
    while (!v11);
    unint64_t v4 = (uint64_t *)__dst;
    if (__dst == v45) {
      goto LABEL_16;
    }
  }
  else
  {
    int v10 = 1;
    if (__dst == v45) {
      goto LABEL_16;
    }
  }
  free(v4);
LABEL_16:
  if (!v10) {
    return 0;
  }
  v37[0] = mlir::ShapedType::getShape((mlir::ShapedType *)v38);
  v37[1] = v12;
  mlir::OffsetSizeAndStrideOpInterface::getMixedSizes((uint64_t *)&__src, (mlir::OffsetSizeAndStrideOpInterface *)v39);
  __dst = v45;
  uint64_t v44 = 0x400000000;
  unsigned int v13 = v41;
  BOOL v14 = __src;
  if (v41)
  {
    if (__src == v42)
    {
      unsigned int v15 = v41;
      if (v41 < 5
        || (llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&__dst, v45, v41, 8),
            unsigned int v15 = v41,
            BOOL v14 = __src,
            v41))
      {
        memcpy(__dst, v14, 8 * v15);
        BOOL v14 = __src;
      }
      LODWORD(v44) = v13;
    }
    else
    {
      __dst = __src;
      uint64_t v44 = v41;
      __src = v42;
      HIDWORD(v41) = 0;
      BOOL v14 = v42;
    }
    LODWORD(v41) = 0;
  }
  unint64_t v16 = v37;
  unint64_t v46 = v37;
  if (v14 != v42)
  {
    free(v14);
    unint64_t v16 = v46;
    unsigned int v13 = v44;
  }
  char v17 = 0;
  uint64_t v18 = (uint64_t *)__dst;
  if (v13)
  {
    uint64_t v19 = v16[1];
    if (v19)
    {
      BOOL v20 = (void *)*v16;
      uint64_t v21 = v13;
      uint64_t v22 = 8 * v19 - 8;
      uint64_t v23 = 8 * v21 - 8;
      do
      {
        unint64_t v24 = mlir::getConstantIntValue(*v18);
        if (v25) {
          BOOL v26 = v24 == *v20;
        }
        else {
          BOOL v26 = 0;
        }
        char v17 = !v26;
        if (!v26) {
          break;
        }
        if (!v23) {
          break;
        }
        ++v18;
        ++v20;
        uint64_t v27 = v22;
        v22 -= 8;
        v23 -= 8;
      }
      while (v27);
      uint64_t v18 = (uint64_t *)__dst;
    }
  }
  if (v18 != (uint64_t *)v45) {
    free(v18);
  }
  if (v17) {
    return 0;
  }
  mlir::OffsetSizeAndStrideOpInterface::getMixedStrides((uint64_t *)&__dst, (mlir::OffsetSizeAndStrideOpInterface *)v39);
  uint64_t v30 = (uint64_t *)__dst;
  if (!v44)
  {
    uint64_t v28 = 1;
    if (__dst == v45) {
      return v28;
    }
LABEL_64:
    free(v30);
    return v28;
  }
  uint64_t v31 = 8 * v44 - 8;
  do
  {
    uint64_t v32 = *v30++;
    unint64_t v33 = mlir::getConstantIntValue(v32);
    if (v34) {
      BOOL v35 = v33 == 1;
    }
    else {
      BOOL v35 = 0;
    }
    uint64_t v28 = v35;
    BOOL v36 = v28 != 1 || v31 == 0;
    v31 -= 8;
  }
  while (!v36);
  uint64_t v30 = (uint64_t *)__dst;
  if (__dst != v45) {
    goto LABEL_64;
  }
  return v28;
}

void *llvm::SmallVector<mlir::OpFoldResult,6u>::SmallVector(void *result, unint64_t a2, unint64_t *a3)
{
  unint64_t v4 = result;
  uint64_t v5 = result + 2;
  *unint64_t result = result + 2;
  result[1] = 0x600000000;
  unint64_t v6 = *a3;
  if (a2 >= 7)
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)result, v5, a2, 8);
    uint64_t v7 = (unint64_t *)(*(void *)v4 + 8 * (a2 & 0xFFFFFFFFFFFFFFFCLL));
    unint64_t v8 = a2 & 3;
    int64x2_t v9 = vdupq_n_s64(v6);
    int v10 = (int64x2_t *)(*(void *)v4 + 16);
    unint64_t v11 = a2 & 0xFFFFFFFFFFFFFFFCLL;
    do
    {
      v10[-1] = v9;
      *int v10 = v9;
      v10 += 2;
      v11 -= 4;
    }
    while (v11);
    if ((a2 & 0xFFFFFFFFFFFFFFFCLL) != a2)
    {
      do
      {
        *v7++ = v6;
        --v8;
      }
      while (v8);
    }
    goto LABEL_6;
  }
  if (!a2
    || (unint64_t *v5 = v6, a2 == 1)
    || (result[3] = v6, a2 == 2)
    || (result[4] = v6, a2 == 3)
    || (result[5] = v6, a2 == 4)
    || (result[6] = v6, a2 == 5))
  {
LABEL_6:
    v4[2] = a2;
    return v4;
  }
  result[7] = v6;
  *((_DWORD *)result + 2) = a2;
  return result;
}

uint64_t mlir::tensor::InsertSliceOp::getAsmResultNames(uint64_t a1, uint64_t (*a2)(uint64_t, uint64_t, const char *, uint64_t), uint64_t a3)
{
  if (*(_DWORD *)(*(void *)a1 + 36)) {
    uint64_t v4 = *(void *)a1 - 16;
  }
  else {
    uint64_t v4 = 0;
  }
  uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v4, 0);

  return a2(a3, NextResultAtOffset, "inserted_slice", 14);
}

void mlir::tensor::InsertSliceOp::build(mlir::MLIRContext **a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t *a5, uint64_t a6, uint64_t *a7, uint64_t a8, uint64_t *a9, uint64_t a10, void *__src, uint64_t a12)
{
  v44[6] = *MEMORY[0x263EF8340];
  uint64_t v42 = v44;
  uint64_t v43 = 0x600000000;
  char v39 = v41;
  uint64_t v40 = 0x600000000;
  BOOL v36 = v38;
  uint64_t v37 = 0x600000000;
  unint64_t v33 = v35;
  uint64_t v34 = 0x600000000;
  uint64_t v30 = v32;
  uint64_t v31 = 0x600000000;
  uint64_t v27 = v29;
  uint64_t v28 = 0x600000000;
  mlir::dispatchIndexOpFoldResults(a5, a6, (uint64_t)&v33, (uint64_t)&v42);
  mlir::dispatchIndexOpFoldResults(a7, a8, (uint64_t)&v30, (uint64_t)&v39);
  mlir::dispatchIndexOpFoldResults(a9, a10, (uint64_t)&v27, (uint64_t)&v36);
  unint64_t v17 = *(void *)(a4 + 8) & 0xFFFFFFFFFFFFFFF8;
  mlir::ValueRange::ValueRange(v26, (uint64_t)v33, v34);
  mlir::ValueRange::ValueRange(v25, (uint64_t)v30, v31);
  mlir::ValueRange::ValueRange(v24, (uint64_t)v27, v28);
  uint64_t DenseI64ArrayAttr = mlir::Builder::getDenseI64ArrayAttr(a1, (uint64_t)v42, v43);
  uint64_t v19 = mlir::Builder::getDenseI64ArrayAttr(a1, (uint64_t)v39, v40);
  uint64_t v20 = mlir::Builder::getDenseI64ArrayAttr(a1, (uint64_t)v36, v37);
  mlir::tensor::InsertSliceOp::build(v20, a2, v17, a3, a4, v26[0], v26[1], v21, v25[0], v25[1], v24[0], v24[1], DenseI64ArrayAttr, v19, v20);
  *(void *)(a2 + 192) = 0;
  uint64_t v22 = *(unsigned int *)(a2 + 120);
  if (a12 + v22 > (unint64_t)*(unsigned int *)(a2 + 124))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod(a2 + 112, (void *)(a2 + 128), a12 + v22, 16);
    LODWORD(v22) = *(_DWORD *)(a2 + 120);
  }
  if (a12)
  {
    memcpy((void *)(*(void *)(a2 + 112) + 16 * v22), __src, 16 * a12);
    LODWORD(v22) = *(_DWORD *)(a2 + 120);
  }
  *(_DWORD *)(a2 + 120) = v22 + a12;
  if (v27 != v29) {
    free(v27);
  }
  if (v30 != v32) {
    free(v30);
  }
  if (v33 != v35) {
    free(v33);
  }
  if (v36 != v38) {
    free(v36);
  }
  if (v39 != v41) {
    free(v39);
  }
  if (v42 != v44) {
    free(v42);
  }
}

void mlir::tensor::InsertSliceOp::build(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15)
{
  uint64_t v21 = a5;
  uint64_t v22 = a4;
  mlir::OperationState::addOperands(a2, (uint64_t)&v22, 1);
  mlir::OperationState::addOperands(a2, (uint64_t)&v21, 1);
  mlir::OperationState::addOperands(a2, a6, a7);
  mlir::OperationState::addOperands(a2, a9, a10);
  mlir::OperationState::addOperands(a2, a11, a12);
  uint64_t v18 = mlir::OperationState::getOrAddProperties<mlir::tensor::detail::InsertSliceOpGenericAdaptorBase::Properties>(a2);
  *(void *)(v18 + 24) = 0x100000001;
  *(_DWORD *)(v18 + 32) = a7;
  *(_DWORD *)(v18 + 36) = a10;
  *(_DWORD *)(v18 + 40) = a12;
  *(void *)mlir::OperationState::getOrAddProperties<mlir::tensor::detail::InsertSliceOpGenericAdaptorBase::Properties>(a2) = a13;
  *(void *)(mlir::OperationState::getOrAddProperties<mlir::tensor::detail::InsertSliceOpGenericAdaptorBase::Properties>(a2)
            + 8) = a14;
  *(void *)(mlir::OperationState::getOrAddProperties<mlir::tensor::detail::InsertSliceOpGenericAdaptorBase::Properties>(a2)
            + 16) = a15;
  uint64_t v19 = *(unsigned int *)(a2 + 72);
  if (v19 >= *(_DWORD *)(a2 + 76))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod(a2 + 64, (void *)(a2 + 80), v19 + 1, 8);
    LODWORD(v19) = *(_DWORD *)(a2 + 72);
  }
  *(void *)(*(void *)(a2 + 64) + 8 * v19) = a3;
  ++*(_DWORD *)(a2 + 72);
}

uint64_t mlir::tensor::InsertSliceOp::verify(mlir::tensor::InsertSliceOp *this)
{
  unint64_t v2 = (void *)(*(void *)(*(void *)(*(void *)(*(void *)this + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8);
  if (*(_DWORD *)(*(void *)this + 36)) {
    uint64_t v3 = *(void *)this - 16;
  }
  else {
    uint64_t v3 = 0;
  }
  unint64_t v4 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v3, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
  unint64_t v16 = *(void *)(*(void *)this + 16 * (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 23) & 1) + 64);
  mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)&v16);
  unint64_t v5 = *(void *)this + 16 * (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 23) & 1) + 64;
  if (!HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
    unint64_t v5 = 0;
  }
  unint64_t v16 = *(void *)(v5 + 8);
  uint64_t v6 = mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)&v16);
  uint64_t v8 = v7;
  unint64_t v9 = *(void *)this + 16 * (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 23) & 1) + 64;
  if (!HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
    unint64_t v9 = 0;
  }
  unint64_t v16 = *(void *)(v9 + 16);
  mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)&v16);
  unint64_t v16 = v4;
  uint64_t RHS = mlir::AffineBinaryOpExpr::getRHS((mlir::AffineBinaryOpExpr *)&v16);
  unint64_t v11 = (void *)mlir::RankedTensorType::get(v6, v8, RHS, 0);
  uint64_t v12 = v11;
  if (!v11)
  {
    uint64_t v13 = 0;
    if (!v2) {
      goto LABEL_12;
    }
    goto LABEL_10;
  }
  uint64_t v13 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*v11 + 8);
  if (v2) {
LABEL_10:
  }
    mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*v2 + 8);
LABEL_12:
  int isRankReducedType = mlir::isRankReducedType(v12, v13, v2);
  return produceSliceErrorMsg(isRankReducedType, *(void *)this, (uint64_t)v12);
}

uint64_t mlir::tensor::InsertSliceOp::fold(uint64_t *a1)
{
  unint64_t v61 = *(void *)(*(void *)(*(void *)(*a1 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8;
  if (!mlir::TensorType::hasRank((mlir::TensorType *)&v61)) {
    goto LABEL_18;
  }
  uint64_t Value = (void *)mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v61);
  if (v3)
  {
    uint64_t v4 = 8 * v3;
    while (*Value != 0x8000000000000000)
    {
      ++Value;
      v4 -= 8;
      if (!v4) {
        goto LABEL_6;
      }
    }
    goto LABEL_18;
  }
LABEL_6:
  if (*(_DWORD *)(*a1 + 36)) {
    uint64_t v5 = *a1 - 16;
  }
  else {
    uint64_t v5 = 0;
  }
  unint64_t v60 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v5, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
  if (!mlir::TensorType::hasRank((mlir::TensorType *)&v60)) {
    goto LABEL_18;
  }
  uint64_t v6 = (void *)mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v60);
  if (v7)
  {
    uint64_t v8 = 8 * v7;
    while (*v6 != 0x8000000000000000)
    {
      ++v6;
      v8 -= 8;
      if (!v8) {
        goto LABEL_14;
      }
    }
    goto LABEL_18;
  }
LABEL_14:
  if (*(_DWORD *)(*a1 + 36)) {
    uint64_t v10 = *a1 - 16;
  }
  else {
    uint64_t v10 = 0;
  }
  unint64_t v9 = *(void *)(*(void *)(*(void *)(*a1 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8;
  if (v9 != (*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v10, 0) + 8) & 0xFFFFFFFFFFFFFFF8)) {
    goto LABEL_18;
  }
  uint64_t v25 = *a1;
  if (*a1)
  {
    uint64_t v26 = *(void *)(v25 + 48);
    uint64_t v27 = *(void **)(v26 + 16);
    BOOL v28 = v27 == &mlir::detail::TypeIDResolver<void,void>::id;
    if (v27 == &mlir::detail::TypeIDResolver<void,void>::id) {
      uint64_t v29 = 0;
    }
    else {
      uint64_t v29 = *(void *)(v25 + 48);
    }
    if (!v28)
    {
      unint64_t v30 = v29 | v26 & 0xFFFFFFFFFFFFFF00;
      uint64_t v31 = mlir::detail::InterfaceMap::lookup<mlir::OffsetSizeAndStrideOpInterface>(v30 + 32);
      if (v31) {
        goto LABEL_90;
      }
      uint64_t Values = *(void *)(v30 + 24);
      uint64_t v33 = *(void *)(v25 + 48);
      goto LABEL_88;
    }
    uint64_t v62 = *(void *)(v26 + 8);
    uint64_t Values = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)&v62);
    if (Values)
    {
      uint64_t v33 = v26;
LABEL_88:
      uint64_t v31 = mlir::Dialect::getRegisteredInterfaceForOp<mlir::OffsetSizeAndStrideOpInterface>(Values, v33);
      goto LABEL_90;
    }
  }
  uint64_t v31 = 0;
LABEL_90:
  if (*(_DWORD *)(*a1 + 36)) {
    uint64_t v57 = *a1 - 16;
  }
  else {
    uint64_t v57 = 0;
  }
  uint64_t v58 = (void *)(*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v57, 0) + 8) & 0xFFFFFFFFFFFFFFF8);
  if (v58) {
    uint64_t v59 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*v58 + 8);
  }
  else {
    uint64_t v59 = 0;
  }
  if (foldIdentityOffsetSizeAndStrideOpInterface(v25, v31, (uint64_t)v58, v59)) {
    return *(void *)(*(void *)(*a1 + 72) + 24) | 4;
  }
LABEL_18:
  uint64_t v11 = *a1;
  if (*(unsigned char *)(*a1 + 47)) {
    uint64_t v12 = *a1 + 80;
  }
  else {
    uint64_t v12 = 0;
  }
  uint64_t v62 = *(void *)(*(void *)(v11 + 72) + 32 * *(unsigned int *)(v12 + 24) + 24);
  uint64_t DefiningOp = mlir::Value::getDefiningOp((mlir::Value *)&v62);
  if (!DefiningOp
    || ((BOOL v14 = *(void **)(*(void *)(DefiningOp + 48) + 16),
         BOOL v15 = v14 == &mlir::detail::TypeIDResolver<mlir::tensor::InsertSliceOp,void>::id,
         v14 != &mlir::detail::TypeIDResolver<mlir::tensor::InsertSliceOp,void>::id)
      ? (unint64_t v16 = 0)
      : (unint64_t v16 = DefiningOp),
        (unint64_t v61 = v16, !v15)
     || (*(void *)(*(void *)(*(void *)(DefiningOp + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8) != (*(void *)(*(void *)(*(void *)(v11 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8)))
  {
LABEL_61:
    uint64_t v42 = *a1;
    uint64_t v62 = *(void *)(*(void *)(v42 + 72) + 24);
    uint64_t v43 = mlir::Value::getDefiningOp((mlir::Value *)&v62);
    if (!v43) {
      return 0;
    }
    uint64_t v44 = *(void **)(*(void *)(v43 + 48) + 16);
    BOOL v45 = v44 == &mlir::detail::TypeIDResolver<mlir::tensor::ExtractSliceOp,void>::id;
    unint64_t v46 = v44 == &mlir::detail::TypeIDResolver<mlir::tensor::ExtractSliceOp,void>::id ? v43 : 0;
    unint64_t v61 = v46;
    if (!v45) {
      return 0;
    }
    uint64_t v47 = *(unsigned char *)(v42 + 47) ? v42 + 80 : 0;
    if (*(void *)(*(void *)(v43 + 72) + 24) != *(void *)(*(void *)(v42 + 72)
                                                                + 32 * *(unsigned int *)(v47 + 24)
                                                                + 24))
      return 0;
    uint64_t v48 = *(void *)(v42 + 48);
    int64_t v49 = *(void **)(v48 + 16);
    BOOL v50 = v49 == &mlir::detail::TypeIDResolver<void,void>::id;
    if (v49 == &mlir::detail::TypeIDResolver<void,void>::id) {
      uint64_t v51 = 0;
    }
    else {
      uint64_t v51 = *(void *)(v42 + 48);
    }
    if (v50)
    {
      uint64_t v62 = *(void *)(v48 + 8);
      uint64_t v54 = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)&v62);
      if (!v54)
      {
        uint64_t v53 = 0;
LABEL_81:
        if (mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::memref::ReinterpretCastOp>::isSameAs((uint64_t *)&v61, v42, v53, (uint64_t (*)(uint64_t, void, void))llvm::function_ref<BOOL ()(mlir::OpFoldResult,mlir::OpFoldResult)>::callback_fn<foldInsertAfterExtractSlice(mlir::tensor::InsertSliceOp)::$_0>, (uint64_t)&v60))
        {
          uint64_t v56 = *(void *)(*(void *)(v61 + 72) + 24);
          if (v56) {
            return v56 | 4;
          }
          else {
            return 0;
          }
        }
        return 0;
      }
      uint64_t v55 = v48;
    }
    else
    {
      unint64_t v52 = v51 | v48 & 0xFFFFFFFFFFFFFF00;
      uint64_t v53 = mlir::detail::InterfaceMap::lookup<mlir::OffsetSizeAndStrideOpInterface>(v52 + 32);
      if (v53) {
        goto LABEL_81;
      }
      uint64_t v54 = *(void *)(v52 + 24);
      uint64_t v55 = *(void *)(v42 + 48);
    }
    uint64_t v53 = mlir::Dialect::getRegisteredInterfaceForOp<mlir::OffsetSizeAndStrideOpInterface>(v54, v55);
    goto LABEL_81;
  }
  uint64_t v17 = *(void *)(v11 + 48);
  uint64_t v18 = *(void **)(v17 + 16);
  BOOL v19 = v18 == &mlir::detail::TypeIDResolver<void,void>::id;
  if (v18 == &mlir::detail::TypeIDResolver<void,void>::id) {
    uint64_t v20 = 0;
  }
  else {
    uint64_t v20 = *(void *)(v11 + 48);
  }
  if (!v19)
  {
    unint64_t v21 = v20 | v17 & 0xFFFFFFFFFFFFFF00;
    uint64_t v22 = mlir::detail::InterfaceMap::lookup<mlir::OffsetSizeAndStrideOpInterface>(v21 + 32);
    if (v22) {
      goto LABEL_45;
    }
    uint64_t v23 = *(void *)(v21 + 24);
    uint64_t v24 = *(void *)(v11 + 48);
    goto LABEL_43;
  }
  uint64_t v62 = *(void *)(v17 + 8);
  uint64_t v23 = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)&v62);
  if (v23)
  {
    uint64_t v24 = v17;
LABEL_43:
    uint64_t v22 = mlir::Dialect::getRegisteredInterfaceForOp<mlir::OffsetSizeAndStrideOpInterface>(v23, v24);
    goto LABEL_45;
  }
  uint64_t v22 = 0;
LABEL_45:
  if (!mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::memref::ReinterpretCastOp>::isSameAs((uint64_t *)&v61, v11, v22, (uint64_t (*)(uint64_t, void, void))llvm::function_ref<BOOL ()(mlir::OpFoldResult,mlir::OpFoldResult)>::callback_fn<foldInsertAfterInsertSlice(mlir::tensor::InsertSliceOp)::$_0>, (uint64_t)&v60))goto LABEL_61; {
  if (HIBYTE(*(_DWORD *)(v11 + 44)))
  }
    unint64_t v34 = v11 + 16 * (((unint64_t)*(unsigned int *)(v11 + 44) >> 23) & 1) + 64;
  else {
    unint64_t v34 = 0;
  }
  BOOL v35 = (uint64_t *)(*(void *)(v11 + 72) + 32 * *(unsigned int *)(v34 + 24));
  if (*(unsigned char *)(v61 + 47)) {
    unint64_t v36 = v61 + 80;
  }
  else {
    unint64_t v36 = 0;
  }
  uint64_t v37 = *(uint64_t **)(*(void *)(v61 + 72) + 32 * *(unsigned int *)(v36 + 24) + 24);
  uint64_t v38 = (uint64_t *)v35[1];
  if (v38)
  {
    *uint64_t v38 = *v35;
    if (*v35) {
      *(void *)(*v35 + 8) = v35[1];
    }
  }
  v35[3] = (uint64_t)v37;
  v35[1] = (uint64_t)v37;
  uint64_t v39 = *v37;
  *BOOL v35 = *v37;
  if (v39) {
    *(void *)(v39 + 8) = v35;
  }
  uint64_t *v37 = (uint64_t)v35;
  if (*(_DWORD *)(*a1 + 36)) {
    uint64_t v40 = *a1 - 16;
  }
  else {
    uint64_t v40 = 0;
  }
  return mlir::detail::OpResultImpl::getNextResultAtOffset(v40, 0) | 4;
}

uint64_t mlir::tensor::InsertSliceOp::reifyResultShapes(uint64_t a1, mlir::IndexType **a2, uint64_t a3)
{
  v33[6] = *MEMORY[0x263EF8340];
  if (*(_DWORD *)(*(void *)a1 + 36)) {
    uint64_t v6 = *(void *)a1 - 16;
  }
  else {
    uint64_t v6 = 0;
  }
  unint64_t v30 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v6, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v30);
  uint64_t v31 = v33;
  uint64_t v32 = 0x600000000;
  if (v7)
  {
    unint64_t v8 = v7;
    if (v7 < 7)
    {
      uint64_t v9 = 0;
      unint64_t v10 = v7;
    }
    else
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v31, v33, v7, 8);
      uint64_t v9 = v32;
      unint64_t v10 = v8 - v32;
      if (v8 == v32) {
        goto LABEL_10;
      }
    }
    bzero((char *)v31 + 8 * v9, 8 * v10);
LABEL_10:
    LODWORD(v32) = v8;
  }
  uint64_t v11 = *(unsigned int *)(a3 + 8);
  if (!v11)
  {
    llvm::SmallVectorImpl<llvm::SmallVector<mlir::OpFoldResult,6u>>::append(a3, 1 - v11, (unint64_t)&v31);
LABEL_18:
    BOOL v15 = v31;
    if (v31 == v33) {
      goto LABEL_20;
    }
    goto LABEL_19;
  }
  if (v11 == 1) {
    goto LABEL_18;
  }
  uint64_t v12 = *(void *)a3;
  uint64_t v13 = v11 << 6;
  do
  {
    BOOL v14 = *(void **)(v12 + v13 - 64);
    if ((void *)(v12 + v13 - 48) != v14) {
      free(v14);
    }
    v13 -= 64;
  }
  while (v13 != 64);
  *(_DWORD *)(a3 + 8) = 1;
  BOOL v15 = v31;
  if (v31 != v33) {
LABEL_19:
  }
    free(v15);
LABEL_20:
  uint64_t v16 = *(void *)(*(void *)a1 + 24);
  if (*(unsigned char *)(*(void *)a1 + 47)) {
    uint64_t v17 = *(void *)a1 + 80;
  }
  else {
    uint64_t v17 = 0;
  }
  uint64_t v18 = *(void *)(*(void *)(*(void *)a1 + 72) + 32 * *(unsigned int *)(v17 + 24) + 24);
  unint64_t v30 = *(void *)(v18 + 8) & 0xFFFFFFFFFFFFFFF8;
  uint64_t v31 = v33;
  uint64_t v32 = 0x600000000;
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v30);
  if (v19 >= 1)
  {
    for (uint64_t i = 0; (uint64_t)i < v23; uint64_t i = (mlir::MLIRContext *)((char *)i + 1))
    {
      unint64_t MixedSize = mlir::tensor::getMixedSize(a2, v16, v18, i);
      uint64_t v22 = v32;
      if (v32 >= (unint64_t)HIDWORD(v32))
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v31, v33, v32 + 1, 8);
        uint64_t v22 = v32;
      }
      *((void *)v31 + v22) = MixedSize;
      LODWORD(v32) = v32 + 1;
      mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v30);
    }
  }
  uint64_t v24 = *(void *)a3;
  uint64_t v25 = v31;
  if ((void **)v24 != &v31)
  {
    if (v31 != v33)
    {
      if (*(void *)v24 != v24 + 16)
      {
        free(*(void **)v24);
        uint64_t v25 = v31;
      }
      *(void *)uint64_t v24 = v25;
      *(void *)(v24 + 8) = v32;
      uint64_t v31 = v33;
      HIDWORD(v32) = 0;
      goto LABEL_45;
    }
    unint64_t v26 = v32;
    uint64_t v27 = *(unsigned int *)(v24 + 8);
    if (v27 >= v32)
    {
      if (v32) {
        memmove(*(void **)v24, v33, 8 * v32);
      }
      goto LABEL_44;
    }
    if (*(_DWORD *)(v24 + 12) >= v32)
    {
      if (v27)
      {
        memmove(*(void **)v24, v33, 8 * v27);
        uint64_t v28 = v32;
        if (v27 == v32)
        {
LABEL_44:
          *(_DWORD *)(v24 + 8) = v26;
LABEL_45:
          LODWORD(v32) = 0;
          uint64_t v25 = v31;
          goto LABEL_46;
        }
      }
      else
      {
        uint64_t v27 = 0;
        uint64_t v28 = v32;
        if (!v32) {
          goto LABEL_44;
        }
      }
    }
    else
    {
      *(_DWORD *)(v24 + 8) = 0;
      llvm::SmallVectorBase<unsigned int>::grow_pod(v24, (void *)(v24 + 16), v26, 8);
      uint64_t v27 = 0;
      uint64_t v28 = v32;
      if (!v32) {
        goto LABEL_44;
      }
    }
    memcpy((void *)(*(void *)v24 + 8 * v27), (char *)v31 + 8 * v27, 8 * v28 - 8 * v27);
    goto LABEL_44;
  }
LABEL_46:
  if (v25 != v33) {
    free(v25);
  }
  return 1;
}

void mlir::tensor::InsertSliceOp::getCanonicalizationPatterns()
{
}

uint64_t mlir::tensor::PadOp::getAsmResultNames(uint64_t a1, uint64_t (*a2)(uint64_t, uint64_t, const char *, uint64_t), uint64_t a3)
{
  if (*(_DWORD *)(*(void *)a1 + 36)) {
    uint64_t v4 = *(void *)a1 - 16;
  }
  else {
    uint64_t v4 = 0;
  }
  uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v4, 0);

  return a2(a3, NextResultAtOffset, "padded", 6);
}

uint64_t mlir::tensor::PadOp::verify(mlir::tensor::PadOp *this)
{
  uint64_t v121 = *MEMORY[0x263EF8340];
  uint64_t v2 = *(void *)this;
  unint64_t v3 = *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8;
  unint64_t v107 = v3;
  int v4 = *(_DWORD *)(v2 + 36);
  uint64_t v5 = v2 - 16;
  if (v4) {
    uint64_t v6 = v5;
  }
  else {
    uint64_t v6 = 0;
  }
  unint64_t v106 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v6, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
  unint64_t v7 = *(void *)this + 16 * (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 23) & 1) + 64;
  if (!HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
    unint64_t v7 = 0;
  }
  v111[0] = *(void *)(v7 + 16);
  uint64_t v8 = mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)v111);
  uint64_t v10 = v9;
  unint64_t v11 = *(void *)this + 16 * (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 23) & 1) + 64;
  if (!HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
    unint64_t v11 = 0;
  }
  v111[0] = *(void *)(v11 + 8);
  uint64_t v12 = mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)v111);
  uint64_t v105 = mlir::tensor::PadOp::inferResultType(v3, v8, v10, v12, v13, 0, 0);
  if (v105)
  {
    mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v106);
    uint64_t v15 = v14;
    mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v105);
    if (v15 == v16)
    {
      mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v107);
      if (v17 < 1) {
        return 1;
      }
      uint64_t v18 = 0;
      uint64_t v19 = 8 * v17;
      while (1)
      {
        uint64_t v20 = *(void *)(mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v106) + v18);
        if (v20 != *(void *)(mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v105) + v18)
          && *(void *)(mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v105) + v18) != 0x8000000000000000)
        {
          break;
        }
        v18 += 8;
        if (v19 == v18) {
          return 1;
        }
      }
      v103[0] = "specified type ";
      __int16 v104 = 259;
      mlir::OpState::emitError((uint64_t *)this, (uint64_t)v103, (uint64_t)v111);
      if (v111[0])
      {
        unint64_t v21 = &v108;
        mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v108, v106);
        uint64_t v22 = (char *)v112;
        if (v113 >= v114)
        {
          unint64_t v90 = v113 + 1;
          if (v112 <= &v108 && (char *)v112 + 24 * v113 > (char *)&v108)
          {
            int64_t v100 = (char *)&v108 - (unsigned char *)v112;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v112, v115, v90, 24);
            uint64_t v22 = (char *)v112;
            unint64_t v21 = (int *)((char *)v112 + v100);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v112, v115, v90, 24);
            unint64_t v21 = &v108;
            uint64_t v22 = (char *)v112;
          }
        }
        uint64_t v23 = &v22[24 * v113];
        long long v24 = *(_OWORD *)v21;
        *((void *)v23 + 2) = *((void *)v21 + 2);
        *(_OWORD *)uint64_t v23 = v24;
        uint64_t v25 = ++v113;
        if (v111[0])
        {
          int v108 = 3;
          unsigned int v109 = " does not match the inferred type ";
          uint64_t v110 = 34;
          unint64_t v26 = &v108;
          uint64_t v27 = (char *)v112;
          if (v25 >= v114)
          {
            unint64_t v91 = v25 + 1;
            BOOL v92 = (char *)v112 + 24 * v25 > (char *)&v108;
            if (v112 <= &v108 && v92)
            {
              int64_t v101 = (char *)&v108 - (unsigned char *)v112;
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v112, v115, v91, 24);
              uint64_t v27 = (char *)v112;
              unint64_t v26 = (int *)((char *)v112 + v101);
            }
            else
            {
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v112, v115, v91, 24);
              unint64_t v26 = &v108;
              uint64_t v27 = (char *)v112;
            }
          }
          uint64_t v28 = &v27[24 * v113];
          long long v29 = *(_OWORD *)v26;
          *((void *)v28 + 2) = *((void *)v26 + 2);
          *(_OWORD *)uint64_t v28 = v29;
          ++v113;
          if (v111[0])
          {
            unint64_t v30 = &v108;
            mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v108, v105);
            uint64_t v31 = (char *)v112;
            if (v113 >= v114)
            {
              unint64_t v93 = v113 + 1;
              if (v112 <= &v108 && (char *)v112 + 24 * v113 > (char *)&v108)
              {
                int64_t v102 = (char *)&v108 - (unsigned char *)v112;
                llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v112, v115, v93, 24);
                uint64_t v31 = (char *)v112;
                unint64_t v30 = (int *)((char *)v112 + v102);
              }
              else
              {
                llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v112, v115, v93, 24);
                unint64_t v30 = &v108;
                uint64_t v31 = (char *)v112;
              }
            }
            uint64_t v32 = &v31[24 * v113];
            long long v33 = *(_OWORD *)v30;
            *((void *)v32 + 2) = *((void *)v30 + 2);
            *(_OWORD *)uint64_t v32 = v33;
            ++v113;
          }
        }
      }
      uint64_t v34 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v111);
      if (v111[0]) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v111);
      }
      if (v120)
      {
        BOOL v35 = __p;
        if (__p)
        {
          unint64_t v36 = v119;
          uint64_t v37 = __p;
          if (v119 != __p)
          {
            do
              unint64_t v36 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v36 - 1);
            while (v36 != v35);
            uint64_t v37 = __p;
          }
          unint64_t v119 = v35;
          operator delete(v37);
        }
        uint64_t v38 = v116;
        if (!v116) {
          goto LABEL_81;
        }
        uint64_t v39 = v117;
        uint64_t v40 = v116;
        if (v117 == v116)
        {
LABEL_80:
          int v117 = v38;
          operator delete(v40);
LABEL_81:
          if (v112 != v115) {
            free(v112);
          }
          return v34;
        }
        do
        {
          uint64_t v42 = *--v39;
          uint64_t v41 = v42;
          *uint64_t v39 = 0;
          if (v42) {
            MEMORY[0x21667D390](v41, 0x1000C8077774924);
          }
        }
        while (v39 != v38);
LABEL_79:
        uint64_t v40 = v116;
        goto LABEL_80;
      }
    }
    else
    {
      v103[0] = "specified type ";
      __int16 v104 = 259;
      mlir::OpState::emitError((uint64_t *)this, (uint64_t)v103, (uint64_t)v111);
      if (v111[0])
      {
        uint64_t v62 = &v108;
        mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v108, v106);
        int64_t v63 = (char *)v112;
        if (v113 >= v114)
        {
          unint64_t v83 = v113 + 1;
          if (v112 <= &v108 && (char *)v112 + 24 * v113 > (char *)&v108)
          {
            int64_t v95 = (char *)&v108 - (unsigned char *)v112;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v112, v115, v83, 24);
            int64_t v63 = (char *)v112;
            uint64_t v62 = (int *)((char *)v112 + v95);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v112, v115, v83, 24);
            uint64_t v62 = &v108;
            int64_t v63 = (char *)v112;
          }
        }
        int64_t v64 = &v63[24 * v113];
        long long v65 = *(_OWORD *)v62;
        *((void *)v64 + 2) = *((void *)v62 + 2);
        *(_OWORD *)int64_t v64 = v65;
        uint64_t v66 = ++v113;
        if (v111[0])
        {
          int v108 = 3;
          unsigned int v109 = " does not match the inferred type ";
          uint64_t v110 = 34;
          uint64_t v67 = &v108;
          char v68 = (char *)v112;
          if (v66 >= v114)
          {
            unint64_t v86 = v66 + 1;
            BOOL v87 = (char *)v112 + 24 * v66 > (char *)&v108;
            if (v112 <= &v108 && v87)
            {
              int64_t v97 = (char *)&v108 - (unsigned char *)v112;
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v112, v115, v86, 24);
              char v68 = (char *)v112;
              uint64_t v67 = (int *)((char *)v112 + v97);
            }
            else
            {
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v112, v115, v86, 24);
              uint64_t v67 = &v108;
              char v68 = (char *)v112;
            }
          }
          uint64_t v69 = &v68[24 * v113];
          long long v70 = *(_OWORD *)v67;
          *((void *)v69 + 2) = *((void *)v67 + 2);
          *(_OWORD *)uint64_t v69 = v70;
          ++v113;
          if (v111[0])
          {
            uint64_t v71 = &v108;
            mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v108, v105);
            __int16 v72 = (char *)v112;
            if (v113 >= v114)
            {
              unint64_t v89 = v113 + 1;
              if (v112 <= &v108 && (char *)v112 + 24 * v113 > (char *)&v108)
              {
                int64_t v99 = (char *)&v108 - (unsigned char *)v112;
                llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v112, v115, v89, 24);
                __int16 v72 = (char *)v112;
                uint64_t v71 = (int *)((char *)v112 + v99);
              }
              else
              {
                llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v112, v115, v89, 24);
                uint64_t v71 = &v108;
                __int16 v72 = (char *)v112;
              }
            }
            uint64_t v73 = &v72[24 * v113];
            long long v74 = *(_OWORD *)v71;
            *((void *)v73 + 2) = *((void *)v71 + 2);
            *(_OWORD *)uint64_t v73 = v74;
            ++v113;
          }
        }
      }
      uint64_t v34 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v111);
      if (v111[0]) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v111);
      }
      if (v120)
      {
        unint64_t v75 = __p;
        if (__p)
        {
          uint64_t v76 = v119;
          uint64_t v77 = __p;
          if (v119 != __p)
          {
            do
              uint64_t v76 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v76 - 1);
            while (v76 != v75);
            uint64_t v77 = __p;
          }
          unint64_t v119 = v75;
          operator delete(v77);
        }
        uint64_t v38 = v116;
        if (!v116) {
          goto LABEL_81;
        }
        uint64_t v78 = v117;
        uint64_t v40 = v116;
        if (v117 == v116) {
          goto LABEL_80;
        }
        do
        {
          uint64_t v80 = *--v78;
          uint64_t v79 = v80;
          *uint64_t v78 = 0;
          if (v80) {
            MEMORY[0x21667D390](v79, 0x1000C8077774924);
          }
        }
        while (v78 != v38);
        goto LABEL_79;
      }
    }
  }
  else
  {
    v103[0] = "failed to infer expectedType from sourceType ";
    __int16 v104 = 259;
    mlir::OpState::emitError((uint64_t *)this, (uint64_t)v103, (uint64_t)v111);
    if (v111[0])
    {
      uint64_t v43 = &v108;
      mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v108, v107);
      uint64_t v44 = (char *)v112;
      if (v113 >= v114)
      {
        unint64_t v82 = v113 + 1;
        if (v112 <= &v108 && (char *)v112 + 24 * v113 > (char *)&v108)
        {
          int64_t v94 = (char *)&v108 - (unsigned char *)v112;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v112, v115, v82, 24);
          uint64_t v44 = (char *)v112;
          uint64_t v43 = (int *)((char *)v112 + v94);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v112, v115, v82, 24);
          uint64_t v43 = &v108;
          uint64_t v44 = (char *)v112;
        }
      }
      BOOL v45 = &v44[24 * v113];
      long long v46 = *(_OWORD *)v43;
      *((void *)v45 + 2) = *((void *)v43 + 2);
      *(_OWORD *)BOOL v45 = v46;
      uint64_t v47 = ++v113;
      if (v111[0])
      {
        int v108 = 3;
        unsigned int v109 = ", specified resultType is ";
        uint64_t v110 = 26;
        uint64_t v48 = &v108;
        int64_t v49 = (char *)v112;
        if (v47 >= v114)
        {
          unint64_t v84 = v47 + 1;
          BOOL v85 = (char *)v112 + 24 * v47 > (char *)&v108;
          if (v112 <= &v108 && v85)
          {
            int64_t v96 = (char *)&v108 - (unsigned char *)v112;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v112, v115, v84, 24);
            int64_t v49 = (char *)v112;
            uint64_t v48 = (int *)((char *)v112 + v96);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v112, v115, v84, 24);
            uint64_t v48 = &v108;
            int64_t v49 = (char *)v112;
          }
        }
        BOOL v50 = &v49[24 * v113];
        long long v51 = *(_OWORD *)v48;
        *((void *)v50 + 2) = *((void *)v48 + 2);
        *(_OWORD *)BOOL v50 = v51;
        ++v113;
        if (v111[0])
        {
          unint64_t v52 = &v108;
          mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v108, v106);
          uint64_t v53 = (char *)v112;
          if (v113 >= v114)
          {
            unint64_t v88 = v113 + 1;
            if (v112 <= &v108 && (char *)v112 + 24 * v113 > (char *)&v108)
            {
              int64_t v98 = (char *)&v108 - (unsigned char *)v112;
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v112, v115, v88, 24);
              uint64_t v53 = (char *)v112;
              unint64_t v52 = (int *)((char *)v112 + v98);
            }
            else
            {
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v112, v115, v88, 24);
              unint64_t v52 = &v108;
              uint64_t v53 = (char *)v112;
            }
          }
          uint64_t v54 = &v53[24 * v113];
          long long v55 = *(_OWORD *)v52;
          *((void *)v54 + 2) = *((void *)v52 + 2);
          *(_OWORD *)uint64_t v54 = v55;
          ++v113;
        }
      }
    }
    uint64_t v34 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v111);
    if (v111[0]) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v111);
    }
    if (v120)
    {
      uint64_t v56 = __p;
      if (__p)
      {
        uint64_t v57 = v119;
        uint64_t v58 = __p;
        if (v119 != __p)
        {
          do
            uint64_t v57 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v57 - 1);
          while (v57 != v56);
          uint64_t v58 = __p;
        }
        unint64_t v119 = v56;
        operator delete(v58);
      }
      uint64_t v38 = v116;
      if (!v116) {
        goto LABEL_81;
      }
      uint64_t v59 = v117;
      uint64_t v40 = v116;
      if (v117 == v116) {
        goto LABEL_80;
      }
      do
      {
        uint64_t v61 = *--v59;
        uint64_t v60 = v61;
        *uint64_t v59 = 0;
        if (v61) {
          MEMORY[0x21667D390](v60, 0x1000C8077774924);
        }
      }
      while (v59 != v38);
      goto LABEL_79;
    }
  }
  return v34;
}

uint64_t mlir::tensor::PadOp::inferResultType(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  v26[4] = *MEMORY[0x263EF8340];
  uint64_t v23 = a1;
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v23);
  BOOL v14 = a3 == v13 && a5 == v13;
  if (!v14 || a7 && a7 != a5) {
    return 0;
  }
  long long v24 = v26;
  uint64_t v25 = 0x400000000;
  if (!a5)
  {
    uint64_t v20 = 0;
    unint64_t v21 = v26;
    goto LABEL_24;
  }
  uint64_t v17 = 0;
  do
  {
    if (*(void *)(mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v23) + 8 * v17) == 0x8000000000000000
      || *(void *)(a2 + 8 * v17) == 0x8000000000000000
      || *(void *)(a4 + 8 * v17) == 0x8000000000000000)
    {
      if (a7)
      {
        unint64_t v18 = *(void *)(a6 + 8 * v17);
        uint64_t v19 = v25;
        if (v25 < (unint64_t)HIDWORD(v25)) {
          goto LABEL_19;
        }
      }
      else
      {
        unint64_t v18 = 0x8000000000000000;
        uint64_t v19 = v25;
        if (v25 < (unint64_t)HIDWORD(v25)) {
          goto LABEL_19;
        }
      }
    }
    else
    {
      unint64_t v18 = *(void *)(a2 + 8 * v17)
          + *(void *)(a4 + 8 * v17)
          + *(void *)(mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v23) + 8 * v17);
      uint64_t v19 = v25;
      if (v25 < (unint64_t)HIDWORD(v25)) {
        goto LABEL_19;
      }
    }
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v24, v26, v19 + 1, 8);
    uint64_t v19 = v25;
LABEL_19:
    *((void *)v24 + v19) = v18;
    uint64_t v20 = (v25 + 1);
    LODWORD(v25) = v25 + 1;
    ++v17;
  }
  while (a5 != v17);
  unint64_t v21 = v24;
LABEL_24:
  uint64_t RHS = mlir::AffineBinaryOpExpr::getRHS((mlir::AffineBinaryOpExpr *)&v23);
  uint64_t v15 = mlir::RankedTensorType::get((uint64_t)v21, v20, RHS, 0);
  if (v24 != v26) {
    free(v24);
  }
  return v15;
}

uint64_t mlir::tensor::PadOp::verifyRegions(mlir::tensor::PadOp *this)
{
  uint64_t v91 = *MEMORY[0x263EF8340];
  uint64_t v2 = *(void *)this;
  unint64_t v3 = *(unsigned int *)(*(void *)this + 44);
  if ((v3 & 0x7FFFFF) != 0) {
    unint64_t v4 = ((v2 + 16 * ((v3 >> 23) & 1) + ((v3 >> 21) & 0x7F8) + 71) & 0xFFFFFFFFFFFFFFF8)
  }
       + 32 * *(unsigned int *)(v2 + 40);
  else {
    unint64_t v4 = 0;
  }
  int v5 = *(_DWORD *)(v2 + 36);
  uint64_t v6 = v2 - 16;
  if (v5) {
    uint64_t v7 = v6;
  }
  else {
    uint64_t v7 = 0;
  }
  unint64_t v80 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v7, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v80);
  unsigned int v9 = v8;
  uint64_t v10 = *(void *)(v4 + 8);
  if (v10) {
    unint64_t v11 = (mlir::Block *)(v10 - 8);
  }
  else {
    unint64_t v11 = 0;
  }
  if (((*((void *)v11 + 7) - *((void *)v11 + 6)) >> 3) != v8)
  {
    v75[0] = (void **)"expected the block to have ";
    __int16 v76 = 259;
    mlir::OpState::emitError((uint64_t *)this, (uint64_t)v75, (uint64_t)&v80);
    if (v80)
    {
      int v77 = 5;
      uint64_t v78 = (const char *)v9;
      unint64_t v30 = &v77;
      uint64_t v31 = (char *)v82;
      if (v83 >= v84)
      {
        unint64_t v64 = v83 + 1;
        if (v82 <= &v77 && (char *)v82 + 24 * v83 > (char *)&v77)
        {
          int64_t v70 = (char *)&v77 - (unsigned char *)v82;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v82, v85, v64, 24);
          uint64_t v31 = (char *)v82;
          unint64_t v30 = (int *)((char *)v82 + v70);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v82, v85, v64, 24);
          unint64_t v30 = &v77;
          uint64_t v31 = (char *)v82;
        }
      }
      uint64_t v32 = &v31[24 * v83];
      long long v33 = *(_OWORD *)v30;
      *((void *)v32 + 2) = *((void *)v30 + 2);
      *(_OWORD *)uint64_t v32 = v33;
      uint64_t v34 = ++v83;
      if (v80)
      {
        int v77 = 3;
        uint64_t v78 = " arguments";
        uint64_t v79 = 10;
        BOOL v35 = &v77;
        unint64_t v36 = (char *)v82;
        if (v34 >= v84)
        {
          unint64_t v65 = v34 + 1;
          BOOL v66 = (char *)v82 + 24 * v34 > (char *)&v77;
          if (v82 <= &v77 && v66)
          {
            int64_t v71 = (char *)&v77 - (unsigned char *)v82;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v82, v85, v65, 24);
            unint64_t v36 = (char *)v82;
            BOOL v35 = (int *)((char *)v82 + v71);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v82, v85, v65, 24);
            BOOL v35 = &v77;
            unint64_t v36 = (char *)v82;
          }
        }
        uint64_t v37 = &v36[24 * v83];
        long long v38 = *(_OWORD *)v35;
        *((void *)v37 + 2) = *((void *)v35 + 2);
        *(_OWORD *)uint64_t v37 = v38;
        ++v83;
      }
    }
    uint64_t v21 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v80);
    if (v80) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v80);
    }
    if (!v90) {
      return v21;
    }
    uint64_t v39 = __p;
    if (__p)
    {
      uint64_t v40 = v89;
      uint64_t v41 = __p;
      if (v89 != __p)
      {
        do
          uint64_t v40 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v40 - 1);
        while (v40 != v39);
        uint64_t v41 = __p;
      }
      unint64_t v89 = v39;
      operator delete(v41);
    }
    uint64_t v25 = v86;
    if (!v86) {
      goto LABEL_52;
    }
    uint64_t v42 = v87;
    uint64_t v27 = v86;
    if (v87 == v86) {
      goto LABEL_51;
    }
    do
    {
      uint64_t v44 = *--v42;
      uint64_t v43 = v44;
      *uint64_t v42 = 0;
      if (v44) {
        MEMORY[0x21667D390](v43, 0x1000C8077774924);
      }
    }
    while (v42 != v25);
    goto LABEL_50;
  }
  uint64_t ArgumentTypes = mlir::Block::getArgumentTypes(v11);
  if (ArgumentTypes == v13)
  {
LABEL_15:
    mlir::Block::getTerminator((ZinIrHalH13g **)v11);
    unint64_t v18 = *(void *)(*(void *)(*(void *)(v17 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8;
    uint64_t v19 = (void *)(*(void *)(*(void *)this - 8) & 0xFFFFFFFFFFFFFFF8);
    if (v19)
    {
      uint64_t v20 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*v19 + 8);
      unint64_t v80 = (unint64_t)v19;
      uint64_t v81 = v20;
      if (v18 != mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&v80))
      {
LABEL_17:
        v75[0] = (void **)"expected yield type to match shape element type";
        __int16 v76 = 259;
        mlir::OpState::emitOpError((uint64_t *)this, v75, (uint64_t)&v80);
        uint64_t v21 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v80);
        if (v80) {
          mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v80);
        }
        if (!v90) {
          return v21;
        }
        uint64_t v22 = __p;
        if (__p)
        {
          uint64_t v23 = v89;
          long long v24 = __p;
          if (v89 != __p)
          {
            do
              uint64_t v23 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v23 - 1);
            while (v23 != v22);
            long long v24 = __p;
          }
          unint64_t v89 = v22;
          operator delete(v24);
        }
        uint64_t v25 = v86;
        if (!v86) {
          goto LABEL_52;
        }
        unint64_t v26 = v87;
        uint64_t v27 = v86;
        if (v87 == v86)
        {
LABEL_51:
          BOOL v87 = v25;
          operator delete(v27);
LABEL_52:
          BOOL v45 = v82;
          if (v82 == v85) {
            return v21;
          }
LABEL_53:
          free(v45);
          return v21;
        }
        do
        {
          uint64_t v29 = *--v26;
          uint64_t v28 = v29;
          *unint64_t v26 = 0;
          if (v29) {
            MEMORY[0x21667D390](v28, 0x1000C8077774924);
          }
        }
        while (v26 != v25);
LABEL_50:
        uint64_t v27 = v86;
        goto LABEL_51;
      }
    }
    else
    {
      unint64_t v80 = 0;
      uint64_t v81 = 0;
      if (v18 != mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&v80)) {
        goto LABEL_17;
      }
    }
    return 1;
  }
  uint64_t v14 = ArgumentTypes;
  uint64_t v15 = v13;
  uint64_t v16 = 0;
  while (1)
  {
    unint64_t v74 = *(void *)(*(void *)v14 + 8) & 0xFFFFFFFFFFFFFFF8;
    if (!mlir::Type::isIndex((mlir::Type *)&v74)) {
      break;
    }
    ++v16;
    v14 += 8;
    if (v14 == v15) {
      goto LABEL_15;
    }
  }
  v75[0] = (void **)"expected block argument ";
  __int16 v76 = 259;
  mlir::OpState::emitOpError((uint64_t *)this, v75, (uint64_t)&v80);
  if (v80)
  {
    int v77 = 5;
    uint64_t v78 = (const char *)(v16 + 1);
    long long v46 = &v77;
    uint64_t v47 = (char *)v82;
    if (v83 >= v84)
    {
      unint64_t v67 = v83 + 1;
      if (v82 <= &v77 && (char *)v82 + 24 * v83 > (char *)&v77)
      {
        int64_t v72 = (char *)&v77 - (unsigned char *)v82;
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v82, v85, v67, 24);
        uint64_t v47 = (char *)v82;
        long long v46 = (int *)((char *)v82 + v72);
      }
      else
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v82, v85, v67, 24);
        long long v46 = &v77;
        uint64_t v47 = (char *)v82;
      }
    }
    uint64_t v48 = &v47[24 * v83];
    long long v49 = *(_OWORD *)v46;
    *((void *)v48 + 2) = *((void *)v46 + 2);
    *(_OWORD *)uint64_t v48 = v49;
    uint64_t v50 = ++v83;
    if (v80)
    {
      int v77 = 3;
      uint64_t v78 = " to be an index";
      uint64_t v79 = 15;
      long long v51 = &v77;
      unint64_t v52 = (char *)v82;
      if (v50 >= v84)
      {
        unint64_t v68 = v50 + 1;
        BOOL v69 = (char *)v82 + 24 * v50 > (char *)&v77;
        if (v82 <= &v77 && v69)
        {
          int64_t v73 = (char *)&v77 - (unsigned char *)v82;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v82, v85, v68, 24);
          unint64_t v52 = (char *)v82;
          long long v51 = (int *)((char *)v82 + v73);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v82, v85, v68, 24);
          long long v51 = &v77;
          unint64_t v52 = (char *)v82;
        }
      }
      uint64_t v53 = &v52[24 * v83];
      long long v54 = *(_OWORD *)v51;
      *((void *)v53 + 2) = *((void *)v51 + 2);
      *(_OWORD *)uint64_t v53 = v54;
      ++v83;
    }
  }
  uint64_t v21 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v80);
  if (v80) {
    mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v80);
  }
  if (v90)
  {
    long long v55 = __p;
    if (__p)
    {
      uint64_t v56 = v89;
      uint64_t v57 = __p;
      if (v89 != __p)
      {
        do
          uint64_t v56 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v56 - 1);
        while (v56 != v55);
        uint64_t v57 = __p;
      }
      unint64_t v89 = v55;
      operator delete(v57);
    }
    uint64_t v58 = v86;
    if (v86)
    {
      uint64_t v59 = v87;
      uint64_t v60 = v86;
      if (v87 != v86)
      {
        do
        {
          uint64_t v62 = *--v59;
          uint64_t v61 = v62;
          *uint64_t v59 = 0;
          if (v62) {
            MEMORY[0x21667D390](v61, 0x1000C8077774924);
          }
        }
        while (v59 != v58);
        uint64_t v60 = v86;
      }
      BOOL v87 = v58;
      operator delete(v60);
    }
    BOOL v45 = v82;
    if (v82 != v85) {
      goto LABEL_53;
    }
  }
  return v21;
}

void mlir::tensor::PadOp::build(mlir::MLIRContext **a1, mlir::OperationState *a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, char a13, void *__src, uint64_t a15)
{
  uint64_t v20 = a3;
  if (!a3) {
    uint64_t v20 = mlir::tensor::PadOp::inferResultType(*(void *)(a4 + 8) & 0xFFFFFFFFFFFFFFF8, a5, a6, a7, a8, 0, 0);
  }
  uint64_t DenseI64ArrayAttr = mlir::Builder::getDenseI64ArrayAttr(a1, a5, a6);
  uint64_t v25 = mlir::Builder::getDenseI64ArrayAttr(a1, a7, a8);
  if (a13) {
    uint64_t UnitAttr = mlir::Builder::getUnitAttr(a1, v24);
  }
  else {
    uint64_t UnitAttr = 0;
  }
  mlir::tensor::PadOp::build(UnitAttr, a2, v20, a4, a9, a10, a11, a12, DenseI64ArrayAttr, v25, UnitAttr);
}

void mlir::tensor::PadOp::build(uint64_t a1, mlir::OperationState *a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11)
{
  uint64_t v17 = a4;
  mlir::OperationState::addOperands((uint64_t)a2, (uint64_t)&v17, 1);
  mlir::OperationState::addOperands((uint64_t)a2, a5, a6);
  mlir::OperationState::addOperands((uint64_t)a2, a7, a8);
  uint64_t v16 = (_DWORD *)mlir::OperationState::getOrAddProperties<mlir::tensor::detail::PadOpGenericAdaptorBase::Properties>((uint64_t)a2);
  v16[6] = 1;
  v16[7] = a6;
  v16[8] = a8;
  *(void *)(mlir::OperationState::getOrAddProperties<mlir::tensor::detail::PadOpGenericAdaptorBase::Properties>((uint64_t)a2)
            + 16) = a9;
  *(void *)(mlir::OperationState::getOrAddProperties<mlir::tensor::detail::PadOpGenericAdaptorBase::Properties>((uint64_t)a2)
            + 8) = a10;
  if (a11) {
    *(void *)mlir::OperationState::getOrAddProperties<mlir::tensor::detail::PadOpGenericAdaptorBase::Properties>((uint64_t)a2) = a11;
  }
  mlir::OperationState::addRegion(a2);
}

void mlir::tensor::PadOp::build(mlir::MLIRContext **a1, mlir::OperationState *a2, uint64_t a3, uint64_t a4, uint64_t *a5, uint64_t a6, uint64_t *a7, uint64_t a8, char a9, void *__src, uint64_t a11)
{
  v35[4] = *MEMORY[0x263EF8340];
  uint64_t v17 = *(void *)(a4 + 8);
  long long v33 = v35;
  uint64_t v34 = 0x400000000;
  unint64_t v30 = &v32;
  uint64_t v31 = 0x400000000;
  uint64_t v27 = &v29;
  uint64_t v28 = 0x400000000;
  long long v24 = &v26;
  uint64_t v25 = 0x400000000;
  mlir::dispatchIndexOpFoldResults(a5, a6, (uint64_t)&v33, (uint64_t)&v27);
  mlir::dispatchIndexOpFoldResults(a7, a8, (uint64_t)&v30, (uint64_t)&v24);
  if (!a3) {
    a3 = mlir::tensor::PadOp::inferResultType(v17 & 0xFFFFFFFFFFFFFFF8, (uint64_t)v27, v28, (uint64_t)v24, v25, 0, 0);
  }
  mlir::ValueRange::ValueRange(v23, (uint64_t)v33, v34);
  mlir::ValueRange::ValueRange(v22, (uint64_t)v30, v31);
  uint64_t DenseI64ArrayAttr = mlir::Builder::getDenseI64ArrayAttr(a1, (uint64_t)v27, v28);
  uint64_t v20 = mlir::Builder::getDenseI64ArrayAttr(a1, (uint64_t)v24, v25);
  if (a9) {
    uint64_t UnitAttr = mlir::Builder::getUnitAttr(a1, v19);
  }
  else {
    uint64_t UnitAttr = 0;
  }
  mlir::tensor::PadOp::build(UnitAttr, a2, a3, a4, v23[0], v23[1], v22[0], v22[1], DenseI64ArrayAttr, v20, UnitAttr);
}

void mlir::tensor::PadOp::getPaddedDims(mlir::tensor::PadOp *this@<X0>, unint64_t *a2@<X8>)
{
  v20[6] = *MEMORY[0x263EF8340];
  unint64_t v18 = (void *)(*(void *)(*(void *)(*(void *)(*(void *)this + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8);
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v18);
  if (v4 > 0x39) {
    operator new();
  }
  unint64_t v5 = (v4 << 58) | 1;
  *a2 = v5;
  mlir::tensor::PadOp::getMixedLowPad(this, (uint64_t)&v18);
  uint64_t v6 = v18;
  if (v19)
  {
    uint64_t v7 = 0;
    uint64_t v8 = 8 * v19;
    do
    {
      unint64_t ConstantIntValue = mlir::getConstantIntValue(v6[v7]);
      if (v10) {
        BOOL v11 = ConstantIntValue == 0;
      }
      else {
        BOOL v11 = 0;
      }
      if (!v11)
      {
        if (v5)
        {
          unint64_t v5 = v5 & 0xFC00000000000000 | (2
                                          * (((v5 >> 1) & ~(-1 << (v5 >> 58)) | (1 << v7)) & ~(-1 << (v5 >> 58)))) | 1;
          *a2 = v5;
        }
        else
        {
          *(void *)(*(void *)v5 + 8 * (v7 >> 6)) |= 1 << v7;
        }
      }
      ++v7;
      v8 -= 8;
    }
    while (v8);
    uint64_t v6 = v18;
  }
  if (v6 != v20) {
    free(v6);
  }
  mlir::tensor::PadOp::getMixedHighPad(this, (uint64_t)&v18);
  uint64_t v12 = v18;
  if (v19)
  {
    uint64_t v13 = 0;
    uint64_t v14 = 8 * v19;
    do
    {
      unint64_t v15 = mlir::getConstantIntValue(v12[v13]);
      if (v16) {
        BOOL v17 = v15 == 0;
      }
      else {
        BOOL v17 = 0;
      }
      if (!v17)
      {
        if (v5)
        {
          unint64_t v5 = v5 & 0xFC00000000000000 | (2
                                          * (((v5 >> 1) & ~(-1 << (v5 >> 58)) | (1 << v13)) & ~(-1 << (v5 >> 58)))) | 1;
          *a2 = v5;
        }
        else
        {
          *(void *)(*(void *)v5 + 8 * (v13 >> 6)) |= 1 << v13;
        }
      }
      ++v13;
      v14 -= 8;
    }
    while (v14);
    uint64_t v12 = v18;
  }
  if (v12 != v20) {
    free(v12);
  }
}

void mlir::tensor::PadOp::getMixedLowPad(mlir::tensor::PadOp *this@<X0>, uint64_t a2@<X8>)
{
  uint64_t v22 = *MEMORY[0x263EF8340];
  unint64_t v4 = *(void *)this + 16 * (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 23) & 1) + 64;
  if (!HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
    unint64_t v4 = 0;
  }
  *(void *)&long long v21 = *(void *)(v4 + 16);
  unint64_t v5 = (uint64_t *)mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)&v21);
  LODWORD(v7) = v6;
  unint64_t v8 = *(unsigned int *)(*(void *)this + 44);
  if (HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
    uint64_t v9 = *(void *)this + 16 * ((v8 >> 23) & 1) + 64;
  }
  else {
    uint64_t v9 = 0;
  }
  uint64_t v10 = *(unsigned int *)(v9 + 24);
  int v11 = *(_DWORD *)(v9 + 28);
  if ((v8 & 0x800000) != 0) {
    uint64_t v12 = *(void *)(*(void *)this + 72);
  }
  else {
    uint64_t v12 = 0;
  }
  mlir::ValueRange::ValueRange((unint64_t *)&v20, v12 + 32 * v10, (v11 + v10) - v10);
  long long v21 = v20;
  uint64_t Context = mlir::Attribute::getContext((mlir::Attribute *)(*(void *)this + 24));
  *(void *)a2 = a2 + 16;
  *(void *)(a2 + 8) = 0x600000000;
  uint64_t v7 = v7;
  if (v7)
  {
    unsigned int v13 = 0;
    do
    {
      uint64_t v15 = *v5++;
      uint64_t v14 = v15;
      if (v15 == 0x8000000000000000)
      {
        unint64_t v16 = mlir::ValueRange::dereference_iterator(&v21, v13) | 4;
        unint64_t v17 = *(unsigned int *)(a2 + 8);
        unint64_t v18 = *(unsigned int *)(a2 + 12);
        ++v13;
      }
      else
      {
        unint64_t v16 = mlir::Builder::getI64IntegerAttr((mlir::Builder *)&Context, v14) & 0xFFFFFFFFFFFFFFFBLL;
        unint64_t v17 = *(unsigned int *)(a2 + 8);
        unint64_t v18 = *(unsigned int *)(a2 + 12);
      }
      if (v17 >= v18)
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod(a2, (void *)(a2 + 16), v17 + 1, 8);
        unint64_t v17 = *(unsigned int *)(a2 + 8);
      }
      *(void *)(*(void *)a2 + 8 * v17) = v16;
      ++*(_DWORD *)(a2 + 8);
      --v7;
    }
    while (v7);
  }
}

void mlir::tensor::PadOp::getMixedHighPad(mlir::tensor::PadOp *this@<X0>, uint64_t a2@<X8>)
{
  uint64_t v23 = *MEMORY[0x263EF8340];
  unint64_t v4 = *(void *)this + 16 * (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 23) & 1) + 64;
  if (!HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
    unint64_t v4 = 0;
  }
  *(void *)&long long v22 = *(void *)(v4 + 8);
  unint64_t v5 = (uint64_t *)mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)&v22);
  LODWORD(v7) = v6;
  unint64_t v8 = *(unsigned int *)(*(void *)this + 44);
  if (HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
    uint64_t v9 = (_DWORD *)(*(void *)this + 16 * ((v8 >> 23) & 1) + 64);
  }
  else {
    uint64_t v9 = 0;
  }
  int v10 = v9[6];
  int v11 = v9[7];
  int v12 = v9[8];
  if ((v8 & 0x800000) != 0) {
    uint64_t v13 = *(void *)(*(void *)this + 72);
  }
  else {
    uint64_t v13 = 0;
  }
  mlir::ValueRange::ValueRange((unint64_t *)&v21, v13 + 32 * (v11 + v10), (v12 + v11 + v10) - (unint64_t)(v11 + v10));
  long long v22 = v21;
  uint64_t Context = mlir::Attribute::getContext((mlir::Attribute *)(*(void *)this + 24));
  *(void *)a2 = a2 + 16;
  *(void *)(a2 + 8) = 0x600000000;
  uint64_t v7 = v7;
  if (v7)
  {
    unsigned int v14 = 0;
    do
    {
      uint64_t v16 = *v5++;
      uint64_t v15 = v16;
      if (v16 == 0x8000000000000000)
      {
        unint64_t v17 = mlir::ValueRange::dereference_iterator(&v22, v14) | 4;
        unint64_t v18 = *(unsigned int *)(a2 + 8);
        unint64_t v19 = *(unsigned int *)(a2 + 12);
        ++v14;
      }
      else
      {
        unint64_t v17 = mlir::Builder::getI64IntegerAttr((mlir::Builder *)&Context, v15) & 0xFFFFFFFFFFFFFFFBLL;
        unint64_t v18 = *(unsigned int *)(a2 + 8);
        unint64_t v19 = *(unsigned int *)(a2 + 12);
      }
      if (v18 >= v19)
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod(a2, (void *)(a2 + 16), v18 + 1, 8);
        unint64_t v18 = *(unsigned int *)(a2 + 8);
      }
      *(void *)(*(void *)a2 + 8 * v18) = v17;
      ++*(_DWORD *)(a2 + 8);
      --v7;
    }
    while (v7);
  }
}

void mlir::tensor::PadOp::getCanonicalizationPatterns()
{
}

uint64_t mlir::tensor::PadOp::getConstantPaddingValue(mlir::tensor::PadOp *this)
{
  uint64_t v2 = *(void *)(((*(void *)this
                   + 16 * (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 23) & 1)
                   + (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 21) & 0x7F8)
                   + 71) & 0xFFFFFFFFFFFFFFF8)
                 + 32 * *(unsigned int *)(*(void *)this + 40)
                 + 8);
  if (v2) {
    unint64_t v3 = (ZinIrHalH13g **)(v2 - 8);
  }
  else {
    unint64_t v3 = 0;
  }
  mlir::Block::getTerminator(v3);
  uint64_t v5 = 0;
  if (v4) {
    BOOL v6 = *(void *)(*(void *)(v4 + 48) + 16) == (void)&mlir::detail::TypeIDResolver<mlir::tensor::YieldOp,void>::id;
  }
  else {
    BOOL v6 = 0;
  }
  if (!v6) {
    return v5;
  }
  uint64_t v5 = *(void *)(*(void *)(v4 + 72) + 24);
  uint64_t v12 = v5;
  uint64_t v13 = v5;
  uint64_t DefiningOp = mlir::Value::getDefiningOp((mlir::Value *)&v13);
  if (DefiningOp)
  {
    if (mlir::OperationName::hasTrait<mlir::OpTrait::ConstantLike>((void *)(DefiningOp + 48))) {
      return v5;
    }
  }
  uint64_t ParentBlock = mlir::Value::getParentBlock((mlir::Value *)&v12);
  uint64_t v9 = *(void *)(((*(void *)this
                   + 16 * (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 23) & 1)
                   + (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 21) & 0x7F8)
                   + 71) & 0xFFFFFFFFFFFFFFF8)
                 + 32 * *(unsigned int *)(*(void *)this + 40)
                 + 8);
  if (v9) {
    uint64_t v10 = v9 - 8;
  }
  else {
    uint64_t v10 = 0;
  }
  if (ParentBlock != v10) {
    return v12;
  }
  return 0;
}

uint64_t mlir::tensor::PadOp::fold(uint64_t a1)
{
  if (*(_DWORD *)(*(void *)a1 + 36)) {
    uint64_t v2 = *(void *)a1 - 16;
  }
  else {
    uint64_t v2 = 0;
  }
  unint64_t v10 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v2, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
  if (!mlir::TensorType::hasRank((mlir::TensorType *)&v10)) {
    return 0;
  }
  uint64_t Value = (void *)mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v10);
  if (v4)
  {
    uint64_t v5 = 8 * v4;
    while (*Value != 0x8000000000000000)
    {
      ++Value;
      v5 -= 8;
      if (!v5) {
        goto LABEL_9;
      }
    }
    return 0;
  }
LABEL_9:
  uint64_t v6 = *(_DWORD *)(*(void *)a1 + 36) ? *(void *)a1 - 16 : 0;
  uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v6, 0);
  uint64_t v8 = *(void *)(*(void *)(*(void *)a1 + 72) + 24);
  if ((*(void *)(NextResultAtOffset + 8) & 0xFFFFFFFFFFFFFFF8) != (*(void *)(v8 + 8) & 0xFFFFFFFFFFFFFFF8)
    || *(void *)(*(void *)a1 + 80))
  {
    return 0;
  }
  return v8 | 4;
}

void mlir::tensor::ParallelInsertSliceOp::build(mlir::MLIRContext **a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t *a5, uint64_t a6, uint64_t *a7, uint64_t a8, uint64_t *a9, uint64_t a10, void *__src, uint64_t a12)
{
  v43[6] = *MEMORY[0x263EF8340];
  uint64_t v41 = v43;
  uint64_t v42 = 0x600000000;
  long long v38 = v40;
  uint64_t v39 = 0x600000000;
  BOOL v35 = v37;
  uint64_t v36 = 0x600000000;
  uint64_t v32 = v34;
  uint64_t v33 = 0x600000000;
  uint64_t v29 = v31;
  uint64_t v30 = 0x600000000;
  uint64_t v26 = v28;
  uint64_t v27 = 0x600000000;
  mlir::dispatchIndexOpFoldResults(a5, a6, (uint64_t)&v32, (uint64_t)&v41);
  mlir::dispatchIndexOpFoldResults(a7, a8, (uint64_t)&v29, (uint64_t)&v38);
  mlir::dispatchIndexOpFoldResults(a9, a10, (uint64_t)&v26, (uint64_t)&v35);
  mlir::ValueRange::ValueRange(v25, 0, 0);
  mlir::ValueRange::ValueRange(v24, (uint64_t)v32, v33);
  mlir::ValueRange::ValueRange(v23, (uint64_t)v29, v30);
  mlir::ValueRange::ValueRange(v22, (uint64_t)v26, v27);
  uint64_t DenseI64ArrayAttr = mlir::Builder::getDenseI64ArrayAttr(a1, (uint64_t)v41, v42);
  uint64_t v17 = mlir::Builder::getDenseI64ArrayAttr(a1, (uint64_t)v38, v39);
  uint64_t v18 = mlir::Builder::getDenseI64ArrayAttr(a1, (uint64_t)v35, v36);
  mlir::tensor::ParallelInsertSliceOp::build(v18, a2, v25[0], v25[1], a3, a4, v24[0], v24[1], v23[0], v23[1], v22[0], v22[1], DenseI64ArrayAttr, v17, v18);
  *(void *)(a2 + 192) = 0;
  uint64_t v19 = *(unsigned int *)(a2 + 120);
  if (a12 + v19 > (unint64_t)*(unsigned int *)(a2 + 124))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod(a2 + 112, (void *)(a2 + 128), a12 + v19, 16);
    LODWORD(v19) = *(_DWORD *)(a2 + 120);
  }
  if (a12)
  {
    memcpy((void *)(*(void *)(a2 + 112) + 16 * v19), __src, 16 * a12);
    LODWORD(v19) = *(_DWORD *)(a2 + 120);
  }
  *(_DWORD *)(a2 + 120) = v19 + a12;
  if (v26 != v28) {
    free(v26);
  }
  if (v29 != v31) {
    free(v29);
  }
  if (v32 != v34) {
    free(v32);
  }
  if (v35 != v37) {
    free(v35);
  }
  if (v38 != v40) {
    free(v38);
  }
  if (v41 != v43) {
    free(v41);
  }
}

void mlir::tensor::ParallelInsertSliceOp::build(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15)
{
  uint64_t v24 = a6;
  uint64_t v25 = a5;
  mlir::OperationState::addOperands(a2, (uint64_t)&v25, 1);
  mlir::OperationState::addOperands(a2, (uint64_t)&v24, 1);
  mlir::OperationState::addOperands(a2, a7, a8);
  mlir::OperationState::addOperands(a2, a9, a10);
  mlir::OperationState::addOperands(a2, a11, a12);
  uint64_t v20 = mlir::OperationState::getOrAddProperties<mlir::tensor::detail::ParallelInsertSliceOpGenericAdaptorBase::Properties>(a2);
  *(void *)(v20 + 24) = 0x100000001;
  *(_DWORD *)(v20 + 32) = a8;
  *(_DWORD *)(v20 + 36) = a10;
  *(_DWORD *)(v20 + 40) = a12;
  *(void *)mlir::OperationState::getOrAddProperties<mlir::tensor::detail::ParallelInsertSliceOpGenericAdaptorBase::Properties>(a2) = a13;
  *(void *)(mlir::OperationState::getOrAddProperties<mlir::tensor::detail::ParallelInsertSliceOpGenericAdaptorBase::Properties>(a2)
            + 8) = a14;
  *(void *)(mlir::OperationState::getOrAddProperties<mlir::tensor::detail::ParallelInsertSliceOpGenericAdaptorBase::Properties>(a2)
            + 16) = a15;
  uint64_t v21 = *(unsigned int *)(a2 + 72);
  if (a4 + v21 > (unint64_t)*(unsigned int *)(a2 + 76))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod(a2 + 64, (void *)(a2 + 80), a4 + v21, 8);
    LODWORD(v21) = *(_DWORD *)(a2 + 72);
  }
  if (a4)
  {
    uint64_t v22 = 0;
    uint64_t v23 = *(void *)(a2 + 64) + 8 * v21;
    do
    {
      *(void *)(v23 + 8 * v22) = mlir::TypeRange::dereference_iterator(a3, v22);
      ++v22;
    }
    while (a4 != v22);
    LODWORD(v21) = *(_DWORD *)(a2 + 72);
  }
  *(_DWORD *)(a2 + 72) = v21 + a4;
}

uint64_t mlir::tensor::ParallelInsertSliceOp::verify(mlir::tensor::ParallelInsertSliceOp *this)
{
  uint64_t v47 = *MEMORY[0x263EF8340];
  uint64_t v2 = *(mlir::Block **)(*(void *)this + 16);
  if (v2) {
    uint64_t ParentOp = mlir::Block::getParentOp(v2);
  }
  else {
    uint64_t ParentOp = 0;
  }
  uint64_t v4 = *(void *)(ParentOp + 48);
  uint64_t v5 = *(void **)(v4 + 16);
  BOOL v6 = v5 == &mlir::detail::TypeIDResolver<void,void>::id;
  if (v5 == &mlir::detail::TypeIDResolver<void,void>::id) {
    uint64_t v7 = 0;
  }
  else {
    uint64_t v7 = *(void *)(ParentOp + 48);
  }
  if (v6)
  {
    unint64_t v38 = *(void *)(v4 + 8);
    uint64_t Values = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)&v38);
    if (!Values || !mlir::Dialect::getRegisteredInterfaceForOp<mlir::ParallelCombiningOpInterface>(Values, v4)) {
      goto LABEL_22;
    }
LABEL_13:
    uint64_t v10 = *(void *)(*(void *)this + 72);
    int v11 = (void *)(*(void *)(*(void *)(v10 + 24) + 8) & 0xFFFFFFFFFFFFFFF8);
    uint64_t v12 = *(void *)this + 80;
    if (!*(unsigned char *)(*(void *)this + 47)) {
      uint64_t v12 = 0;
    }
    unint64_t v13 = *(void *)(*(void *)(v10 + 32 * *(unsigned int *)(v12 + 24) + 24) + 8) & 0xFFFFFFFFFFFFFFF8;
    unint64_t v38 = *(void *)(*(void *)this + 80);
    mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)&v38);
    unint64_t v14 = *(void *)this + 16 * (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 23) & 1) + 64;
    if (!HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
      unint64_t v14 = 0;
    }
    unint64_t v38 = *(void *)(v14 + 8);
    uint64_t v15 = mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)&v38);
    uint64_t v17 = v16;
    unint64_t v18 = *(void *)this + 16 * (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 23) & 1) + 64;
    if (!HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
      unint64_t v18 = 0;
    }
    unint64_t v38 = *(void *)(v18 + 16);
    mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)&v38);
    unint64_t v38 = v13;
    uint64_t RHS = mlir::AffineBinaryOpExpr::getRHS((mlir::AffineBinaryOpExpr *)&v38);
    uint64_t v20 = (void *)mlir::RankedTensorType::get(v15, v17, RHS, 0);
    uint64_t v21 = v20;
    if (v20)
    {
      uint64_t v22 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*v20 + 8);
      if (!v11)
      {
LABEL_40:
        int isRankReducedType = mlir::isRankReducedType(v21, v22, v11);
        return produceSliceErrorMsg(isRankReducedType, *(void *)this, (uint64_t)v21);
      }
    }
    else
    {
      uint64_t v22 = 0;
      if (!v11) {
        goto LABEL_40;
      }
    }
    mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*v11 + 8);
    goto LABEL_40;
  }
  unint64_t v8 = v7 | v4 & 0xFFFFFFFFFFFFFF00;
  if (mlir::detail::InterfaceMap::lookup<mlir::ParallelCombiningOpInterface>(v8 + 32)
    || mlir::Dialect::getRegisteredInterfaceForOp<mlir::ParallelCombiningOpInterface>(*(void *)(v8 + 24), *(void *)(ParentOp + 48)))
  {
    goto LABEL_13;
  }
LABEL_22:
  uint64_t v36 = "expected ParallelCombiningOpInterface parent, got:";
  __int16 v37 = 259;
  mlir::OpState::emitError((uint64_t *)this, (uint64_t)&v36, (uint64_t)&v38);
  uint64_t v23 = *(mlir::Block **)(*(void *)this + 16);
  if (v23)
  {
    uint64_t v24 = (mlir::Block **)mlir::Block::getParentOp(v23);
    if (v38) {
      goto LABEL_24;
    }
  }
  else
  {
    uint64_t v24 = 0;
    if (v38) {
LABEL_24:
    }
      mlir::Diagnostic::operator<<((mlir::Diagnostic *)&v39, v24);
  }
  uint64_t v25 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v38);
  if (v38) {
    mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v38);
  }
  if (v46)
  {
    uint64_t v26 = __p;
    if (__p)
    {
      uint64_t v27 = v45;
      uint64_t v28 = __p;
      if (v45 != __p)
      {
        do
          uint64_t v27 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v27 - 1);
        while (v27 != v26);
        uint64_t v28 = __p;
      }
      BOOL v45 = v26;
      operator delete(v28);
    }
    uint64_t v29 = v42;
    if (v42)
    {
      uint64_t v30 = v43;
      uint64_t v31 = v42;
      if (v43 != v42)
      {
        do
        {
          uint64_t v33 = *--v30;
          uint64_t v32 = v33;
          *uint64_t v30 = 0;
          if (v33) {
            MEMORY[0x21667D390](v32, 0x1000C8077774924);
          }
        }
        while (v30 != v29);
        uint64_t v31 = v42;
      }
      uint64_t v43 = v29;
      operator delete(v31);
    }
    if (v40 != &v41) {
      free(v40);
    }
  }
  return v25;
}

void mlir::tensor::ParallelInsertSliceOp::getCanonicalizationPatterns()
{
}

uint64_t mlir::tensor::ScatterOp::getAsmResultNames(uint64_t a1, uint64_t (*a2)(uint64_t, uint64_t, const char *, uint64_t), uint64_t a3)
{
  if (*(_DWORD *)(*(void *)a1 + 36)) {
    uint64_t v4 = *(void *)a1 - 16;
  }
  else {
    uint64_t v4 = 0;
  }
  uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v4, 0);

  return a2(a3, NextResultAtOffset, "scatter", 7);
}

uint64_t mlir::tensor::ScatterOp::verify(mlir::tensor::ScatterOp *this)
{
  uint64_t v87 = *MEMORY[0x263EF8340];
  v77[0] = *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 56) + 8) & 0xFFFFFFFFFFFFFFF8;
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)v77);
  uint64_t v3 = v2;
  v77[0] = *(void *)(*(void *)this
                     + 16 * (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 23) & 1)
                     + 64);
  uint64_t v4 = (uint64_t *)mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)v77);
  uint64_t v6 = v5;
  if (!verifyGatherOrScatterDims(*(void *)this, v4, v5, v3, (void **)"scatter", (const char *)7, (void **)"dest", (const char *)4))return 0; {
  if (HIBYTE(*(_DWORD *)(*(void *)this + 44)))
  }
    unint64_t v7 = *(void *)this + 16 * (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 23) & 1) + 64;
  else {
    unint64_t v7 = 0;
  }
  if (*(void *)(v7 + 8))
  {
    uint64_t v8 = mlir::tensor::GatherOp::inferResultType(*(void *)(*(void *)(*(void *)(*(void *)this + 72) + 56) + 8) & 0xFFFFFFFFFFFFFFF8, *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 88) + 8) & 0xFFFFFFFFFFFFFFF8, v4, v6, 0);
    uint64_t v9 = 1;
    uint64_t v10 = mlir::tensor::GatherOp::inferResultType(*(void *)(*(void *)(*(void *)(*(void *)this + 72) + 56) + 8) & 0xFFFFFFFFFFFFFFF8, *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 88) + 8) & 0xFFFFFFFFFFFFFFF8, v4, v6, 1);
    unint64_t v11 = *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8;
    if (v11 != v8 && v11 != v10)
    {
      uint64_t v13 = v10;
      v72[0] = (void **)"source type mismatch: expected ";
      __int16 v73 = 259;
      mlir::OpState::emitOpError((uint64_t *)this, v72, (uint64_t)v77);
      if (v77[0])
      {
        unint64_t v14 = &v74;
        mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v74, v8);
        uint64_t v15 = (char *)v78;
        if (v79 >= v80)
        {
          unint64_t v57 = v79 + 1;
          if (v78 <= &v74 && (char *)v78 + 24 * v79 > (char *)&v74)
          {
            int64_t v66 = (char *)&v74 - (unsigned char *)v78;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v78, v81, v57, 24);
            uint64_t v15 = (char *)v78;
            unint64_t v14 = (int *)((char *)v78 + v66);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v78, v81, v57, 24);
            unint64_t v14 = &v74;
            uint64_t v15 = (char *)v78;
          }
        }
        uint64_t v16 = &v15[24 * v79];
        long long v17 = *(_OWORD *)v14;
        *((void *)v16 + 2) = *((void *)v14 + 2);
        *(_OWORD *)uint64_t v16 = v17;
        uint64_t v18 = ++v79;
        if (v77[0])
        {
          int v74 = 3;
          unint64_t v75 = " or its rank-reduced variant ";
          uint64_t v76 = 29;
          uint64_t v19 = &v74;
          uint64_t v20 = (char *)v78;
          if (v18 >= v80)
          {
            unint64_t v58 = v18 + 1;
            BOOL v59 = (char *)v78 + 24 * v18 > (char *)&v74;
            if (v78 <= &v74 && v59)
            {
              int64_t v67 = (char *)&v74 - (unsigned char *)v78;
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v78, v81, v58, 24);
              uint64_t v20 = (char *)v78;
              uint64_t v19 = (int *)((char *)v78 + v67);
            }
            else
            {
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v78, v81, v58, 24);
              uint64_t v19 = &v74;
              uint64_t v20 = (char *)v78;
            }
          }
          uint64_t v21 = &v20[24 * v79];
          long long v22 = *(_OWORD *)v19;
          *((void *)v21 + 2) = *((void *)v19 + 2);
          *(_OWORD *)uint64_t v21 = v22;
          ++v79;
          if (v77[0])
          {
            uint64_t v23 = &v74;
            mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v74, v13);
            uint64_t v24 = (char *)v78;
            if (v79 >= v80)
            {
              unint64_t v60 = v79 + 1;
              if (v78 <= &v74 && (char *)v78 + 24 * v79 > (char *)&v74)
              {
                int64_t v68 = (char *)&v74 - (unsigned char *)v78;
                llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v78, v81, v60, 24);
                uint64_t v24 = (char *)v78;
                uint64_t v23 = (int *)((char *)v78 + v68);
              }
              else
              {
                llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v78, v81, v60, 24);
                uint64_t v23 = &v74;
                uint64_t v24 = (char *)v78;
              }
            }
            uint64_t v25 = &v24[24 * v79];
            long long v26 = *(_OWORD *)v23;
            *((void *)v25 + 2) = *((void *)v23 + 2);
            *(_OWORD *)uint64_t v25 = v26;
            uint64_t v27 = ++v79;
            if (v77[0])
            {
              int v74 = 3;
              unint64_t v75 = " (got: ";
              uint64_t v76 = 7;
              uint64_t v28 = &v74;
              uint64_t v29 = (char *)v78;
              if (v27 >= v80)
              {
                unint64_t v61 = v27 + 1;
                BOOL v62 = (char *)v78 + 24 * v27 > (char *)&v74;
                if (v78 <= &v74 && v62)
                {
                  int64_t v69 = (char *)&v74 - (unsigned char *)v78;
                  llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v78, v81, v61, 24);
                  uint64_t v29 = (char *)v78;
                  uint64_t v28 = (int *)((char *)v78 + v69);
                }
                else
                {
                  llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v78, v81, v61, 24);
                  uint64_t v28 = &v74;
                  uint64_t v29 = (char *)v78;
                }
              }
              uint64_t v30 = &v29[24 * v79];
              long long v31 = *(_OWORD *)v28;
              *((void *)v30 + 2) = *((void *)v28 + 2);
              *(_OWORD *)uint64_t v30 = v31;
              ++v79;
              if (v77[0])
              {
                unint64_t v32 = *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8;
                uint64_t v33 = &v74;
                mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v74, v32);
                uint64_t v34 = (char *)v78;
                if (v79 >= v80)
                {
                  unint64_t v63 = v79 + 1;
                  if (v78 <= &v74 && (char *)v78 + 24 * v79 > (char *)&v74)
                  {
                    int64_t v70 = (char *)&v74 - (unsigned char *)v78;
                    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v78, v81, v63, 24);
                    uint64_t v34 = (char *)v78;
                    uint64_t v33 = (int *)((char *)v78 + v70);
                  }
                  else
                  {
                    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v78, v81, v63, 24);
                    uint64_t v33 = &v74;
                    uint64_t v34 = (char *)v78;
                  }
                }
                BOOL v35 = &v34[24 * v79];
                long long v36 = *(_OWORD *)v33;
                *((void *)v35 + 2) = *((void *)v33 + 2);
                *(_OWORD *)BOOL v35 = v36;
                uint64_t v37 = ++v79;
                if (v77[0])
                {
                  int v74 = 3;
                  unint64_t v75 = ")";
                  uint64_t v76 = 1;
                  unint64_t v38 = &v74;
                  uint64_t v39 = (char *)v78;
                  if (v37 >= v80)
                  {
                    unint64_t v64 = v37 + 1;
                    BOOL v65 = (char *)v78 + 24 * v37 > (char *)&v74;
                    if (v78 <= &v74 && v65)
                    {
                      int64_t v71 = (char *)&v74 - (unsigned char *)v78;
                      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v78, v81, v64, 24);
                      uint64_t v39 = (char *)v78;
                      unint64_t v38 = (int *)((char *)v78 + v71);
                    }
                    else
                    {
                      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v78, v81, v64, 24);
                      unint64_t v38 = &v74;
                      uint64_t v39 = (char *)v78;
                    }
                  }
                  uint64_t v40 = &v39[24 * v79];
                  long long v41 = *(_OWORD *)v38;
                  *((void *)v40 + 2) = *((void *)v38 + 2);
                  *(_OWORD *)uint64_t v40 = v41;
                  ++v79;
                }
              }
            }
          }
        }
      }
      uint64_t v9 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v77);
      if (v77[0]) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v77);
      }
      if (v86)
      {
        uint64_t v42 = __p;
        if (__p)
        {
          uint64_t v43 = v85;
          uint64_t v44 = __p;
          if (v85 != __p)
          {
            do
              uint64_t v43 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v43 - 1);
            while (v43 != v42);
            uint64_t v44 = __p;
          }
          BOOL v85 = v42;
          operator delete(v44);
        }
        BOOL v45 = v82;
        if (!v82) {
          goto LABEL_54;
        }
        char v46 = v83;
        uint64_t v47 = v82;
        if (v83 == v82)
        {
LABEL_53:
          unsigned int v83 = v45;
          operator delete(v47);
LABEL_54:
          if (v78 != v81) {
            free(v78);
          }
          return v9;
        }
        do
        {
          uint64_t v49 = *--v46;
          uint64_t v48 = v49;
          void *v46 = 0;
          if (v49) {
            MEMORY[0x21667D390](v48, 0x1000C8077774924);
          }
        }
        while (v46 != v45);
LABEL_52:
        uint64_t v47 = v82;
        goto LABEL_53;
      }
    }
  }
  else
  {
    v72[0] = (void **)"requires 'unique' attribute to be set";
    __int16 v73 = 259;
    mlir::OpState::emitOpError((uint64_t *)this, v72, (uint64_t)v77);
    uint64_t v9 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v77);
    if (v77[0]) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v77);
    }
    if (v86)
    {
      uint64_t v50 = __p;
      if (__p)
      {
        long long v51 = v85;
        unint64_t v52 = __p;
        if (v85 != __p)
        {
          do
            long long v51 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v51 - 1);
          while (v51 != v50);
          unint64_t v52 = __p;
        }
        BOOL v85 = v50;
        operator delete(v52);
      }
      BOOL v45 = v82;
      if (!v82) {
        goto LABEL_54;
      }
      uint64_t v53 = v83;
      uint64_t v47 = v82;
      if (v83 == v82) {
        goto LABEL_53;
      }
      do
      {
        uint64_t v55 = *--v53;
        uint64_t v54 = v55;
        *uint64_t v53 = 0;
        if (v55) {
          MEMORY[0x21667D390](v54, 0x1000C8077774924);
        }
      }
      while (v53 != v45);
      goto LABEL_52;
    }
  }
  return v9;
}

uint64_t mlir::tensor::SplatOp::getAsmResultNames(void *a1, uint64_t (*a2)(uint64_t, uint64_t, const char *, uint64_t), uint64_t a3)
{
  return a2(a3, *a1 - 16, "splat", 5);
}

unint64_t mlir::tensor::SplatOp::fold(void *a1, uint64_t a2)
{
  v8[1] = *MEMORY[0x263EF8340];
  uint64_t v2 = **(void **)(a2 + 40);
  if (!v2) {
    return 0;
  }
  uint64_t v3 = *(void **)(*(void *)v2 + 136);
  if (v3 != &mlir::detail::TypeIDResolver<mlir::IntegerAttr,void>::id
    && v3 != &mlir::detail::TypeIDResolver<mlir::FloatAttr,void>::id)
  {
    return 0;
  }
  uint64_t v5 = (void *)(*(void *)(*a1 - 8) & 0xFFFFFFFFFFFFFFF8);
  if (v5) {
    uint64_t v6 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*v5 + 8);
  }
  else {
    uint64_t v6 = 0;
  }
  v8[0] = v2;
  return mlir::DenseElementsAttr::get((uint64_t)v5, v6, v8, 1uLL) & 0xFFFFFFFFFFFFFFFBLL;
}

uint64_t mlir::tensor::PackOp::getAsmResultNames(uint64_t a1, uint64_t (*a2)(uint64_t, uint64_t, const char *, uint64_t), uint64_t a3)
{
  if (*(_DWORD *)(*(void *)a1 + 36)) {
    uint64_t v4 = *(void *)a1 - 16;
  }
  else {
    uint64_t v4 = 0;
  }
  uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v4, 0);

  return a2(a3, NextResultAtOffset, "pack", 4);
}

uint64_t mlir::tensor::PackOp::reifyResultShapes(uint64_t *a1, mlir::IndexType **a2, uint64_t a3)
{
  v34[6] = *MEMORY[0x263EF8340];
  uint64_t v5 = *a1;
  uint64_t v6 = *a1 + 80;
  if (*(unsigned char *)(*a1 + 47)) {
    uint64_t v7 = *a1 + 80;
  }
  else {
    uint64_t v7 = 0;
  }
  unint64_t v32 = (void *)(*(void *)(*(void *)(*(void *)(v5 + 72) + 32 * *(unsigned int *)(v7 + 24) + 24) + 8) & 0xFFFFFFFFFFFFFFF8);
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v32);
  unint64_t v32 = v34;
  uint64_t v33 = 0x600000000;
  if (v8)
  {
    unint64_t v9 = v8;
    if (v8 < 7)
    {
      uint64_t v10 = 0;
      unint64_t v11 = v8;
    }
    else
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v32, v34, v8, 8);
      uint64_t v10 = v33;
      unint64_t v11 = v9 - v33;
      if (v9 == v33) {
        goto LABEL_10;
      }
    }
    bzero((char *)v32 + 8 * v10, 8 * v11);
LABEL_10:
    LODWORD(v33) = v9;
  }
  uint64_t v12 = *(unsigned int *)(a3 + 8);
  if (!v12)
  {
    llvm::SmallVectorImpl<llvm::SmallVector<mlir::OpFoldResult,6u>>::append(a3, 1 - v12, (unint64_t)&v32);
LABEL_18:
    uint64_t v16 = v32;
    if (v32 == v34) {
      goto LABEL_20;
    }
    goto LABEL_19;
  }
  if (v12 == 1) {
    goto LABEL_18;
  }
  uint64_t v13 = *(void *)a3;
  uint64_t v14 = v12 << 6;
  do
  {
    uint64_t v15 = *(void **)(v13 + v14 - 64);
    if ((void *)(v13 + v14 - 48) != v15) {
      free(v15);
    }
    v14 -= 64;
  }
  while (v14 != 64);
  *(_DWORD *)(a3 + 8) = 1;
  uint64_t v16 = v32;
  if (v32 != v34) {
LABEL_19:
  }
    free(v16);
LABEL_20:
  uint64_t v17 = *(void *)(v5 + 24);
  if (*(unsigned char *)(v5 + 47)) {
    uint64_t v18 = v6;
  }
  else {
    uint64_t v18 = 0;
  }
  uint64_t v19 = *(void *)(*(void *)(v5 + 72) + 32 * *(unsigned int *)(v18 + 24) + 24);
  unint64_t v31 = *(void *)(v19 + 8) & 0xFFFFFFFFFFFFFFF8;
  unint64_t v32 = v34;
  uint64_t v33 = 0x600000000;
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v31);
  if (v20 >= 1)
  {
    for (uint64_t i = 0; (uint64_t)i < v24; uint64_t i = (mlir::MLIRContext *)((char *)i + 1))
    {
      unint64_t MixedSize = mlir::tensor::getMixedSize(a2, v17, v19, i);
      uint64_t v23 = v33;
      if (v33 >= (unint64_t)HIDWORD(v33))
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v32, v34, v33 + 1, 8);
        uint64_t v23 = v33;
      }
      *((void *)v32 + v23) = MixedSize;
      LODWORD(v33) = v33 + 1;
      mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v31);
    }
  }
  uint64_t v25 = *(void *)a3;
  long long v26 = v32;
  if ((void **)v25 != &v32)
  {
    if (v32 != v34)
    {
      if (*(void *)v25 != v25 + 16)
      {
        free(*(void **)v25);
        long long v26 = v32;
      }
      *(void *)uint64_t v25 = v26;
      *(void *)(v25 + 8) = v33;
      unint64_t v32 = v34;
      HIDWORD(v33) = 0;
      goto LABEL_45;
    }
    unint64_t v27 = v33;
    uint64_t v28 = *(unsigned int *)(v25 + 8);
    if (v28 >= v33)
    {
      if (v33) {
        memmove(*(void **)v25, v34, 8 * v33);
      }
      goto LABEL_44;
    }
    if (*(_DWORD *)(v25 + 12) >= v33)
    {
      if (v28)
      {
        memmove(*(void **)v25, v34, 8 * v28);
        uint64_t v29 = v33;
        if (v28 == v33)
        {
LABEL_44:
          *(_DWORD *)(v25 + 8) = v27;
LABEL_45:
          LODWORD(v33) = 0;
          long long v26 = v32;
          goto LABEL_46;
        }
      }
      else
      {
        uint64_t v28 = 0;
        uint64_t v29 = v33;
        if (!v33) {
          goto LABEL_44;
        }
      }
    }
    else
    {
      *(_DWORD *)(v25 + 8) = 0;
      llvm::SmallVectorBase<unsigned int>::grow_pod(v25, (void *)(v25 + 16), v27, 8);
      uint64_t v28 = 0;
      uint64_t v29 = v33;
      if (!v33) {
        goto LABEL_44;
      }
    }
    memcpy((void *)(*(void *)v25 + 8 * v28), (char *)v32 + 8 * v28, 8 * v29 - 8 * v28);
    goto LABEL_44;
  }
LABEL_46:
  if (v26 != v34) {
    free(v26);
  }
  return 1;
}

void mlir::tensor::PackOp::getMixedTiles(mlir::tensor::PackOp *this@<X0>, uint64_t a2@<X8>)
{
  uint64_t v3 = *(void *)this;
  uint64_t Context = mlir::Attribute::getContext((mlir::Attribute *)(*(void *)this + 24));
  *(void *)a2 = a2 + 16;
  *(void *)(a2 + 8) = 0x600000000;
  if (HIBYTE(*(_DWORD *)(v3 + 44))) {
    unint64_t v5 = v3 + 16 * (((unint64_t)*(unsigned int *)(v3 + 44) >> 23) & 1) + 64;
  }
  else {
    unint64_t v5 = 0;
  }
  uint64_t v6 = *(void *)(v5 + 16);
  uint64_t v16 = Context;
  uint64_t v17 = v6;
  uint64_t v7 = mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)&v17);
  if (v8)
  {
    unint64_t v9 = (uint64_t *)v7;
    unsigned int v10 = 0;
    uint64_t v11 = 8 * v8;
    do
    {
      if (*v9 == 0x8000000000000000)
      {
        if (*(unsigned char *)(v3 + 47)) {
          uint64_t v12 = (_DWORD *)(v3 + 80);
        }
        else {
          uint64_t v12 = 0;
        }
        uint64_t v13 = v10++;
        unint64_t v14 = *(void *)(*(void *)(v3 + 72) + 32 * (v12[7] + v12[6] + v12[8]) + 32 * v13 + 24) | 4;
      }
      else
      {
        unint64_t v14 = mlir::Builder::getI64IntegerAttr((mlir::Builder *)&v16, *v9) & 0xFFFFFFFFFFFFFFFBLL;
      }
      unint64_t v15 = *(unsigned int *)(a2 + 8);
      if (v15 >= *(unsigned int *)(a2 + 12))
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod(a2, (void *)(a2 + 16), v15 + 1, 8);
        unint64_t v15 = *(unsigned int *)(a2 + 8);
      }
      *(void *)(*(void *)a2 + 8 * v15) = v14;
      ++*(_DWORD *)(a2 + 8);
      ++v9;
      v11 -= 8;
    }
    while (v11);
  }
}

void mlir::tensor::PackOp::getStaticTiles(mlir::tensor::PackOp *this@<X0>, void *a2@<X8>)
{
  v8[6] = *MEMORY[0x263EF8340];
  uint64_t v3 = *(void *)this;
  v7[0] = v8;
  v7[1] = (void *)0x600000000;
  *a2 = a2 + 2;
  a2[1] = 0x600000000;
  mlir::tensor::PackOp::getMixedTiles((mlir::tensor::PackOp *)&v3, (uint64_t)&v4);
  mlir::dispatchIndexOpFoldResults((uint64_t *)v4, v5, (uint64_t)v7, (uint64_t)a2);
  if (v4 != &v6) {
    free(v4);
  }
  if (v7[0] != v8) {
    free(v7[0]);
  }
}

uint64_t mlir::tensor::PackOp::verify(mlir::tensor::PackOp *this)
{
  uint64_t v107 = *MEMORY[0x263EF8340];
  uint64_t v2 = *(void *)this;
  uint64_t v91 = *(void *)this;
  mlir::tensor::PackOp::getMixedTiles((mlir::tensor::PackOp *)&v91, (uint64_t)&v103);
  if (v104)
  {
    uint64_t v3 = (uint64_t *)v103;
    uint64_t v4 = 8 * v104;
    while (!mlir::isConstantIntValue(*v3, 0))
    {
      ++v3;
      v4 -= 8;
      if (!v4) {
        goto LABEL_5;
      }
    }
    uint64_t DenseI64ArrayAttr = (llvm *)"invalid zero tile factor";
    __int16 v90 = 259;
    mlir::Operation::emitError(v2, (uint64_t)&DenseI64ArrayAttr, (uint64_t)&v92);
    char v11 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v92);
    if (v92) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v92);
    }
    if (v102)
    {
      uint64_t v12 = __p;
      if (__p)
      {
        uint64_t v13 = v101;
        unint64_t v14 = __p;
        if (v101 != __p)
        {
          do
            uint64_t v13 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v13 - 1);
          while (v13 != v12);
          unint64_t v14 = __p;
        }
        int64_t v101 = v12;
        operator delete(v14);
      }
      unint64_t v15 = v98;
      if (!v98) {
        goto LABEL_53;
      }
      uint64_t v16 = v99;
      uint64_t v17 = v98;
      if (v99 == v98) {
        goto LABEL_52;
      }
      do
      {
        uint64_t v19 = *--v16;
        uint64_t v18 = v19;
        *uint64_t v16 = 0;
        if (v19) {
          MEMORY[0x21667D390](v18, 0x1000C8077774924);
        }
      }
      while (v16 != v15);
      goto LABEL_51;
    }
    goto LABEL_55;
  }
LABEL_5:
  unint64_t v86 = *(void *)(*(void *)(*(void *)(v2 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8;
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v86);
  unint64_t v6 = v5;
  BOOL v92 = *(void **)(v2 + 64 + 16 * (((unint64_t)*(unsigned int *)(v2 + 44) >> 23) & 1));
  uint64_t v7 = mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)&v92);
  unint64_t v9 = v8;
  if (HIBYTE(*(_DWORD *)(v2 + 44))) {
    unint64_t v10 = v2 + 64 + 16 * (((unint64_t)*(unsigned int *)(v2 + 44) >> 23) & 1);
  }
  else {
    unint64_t v10 = 0;
  }
  BOOL v92 = *(void **)(v10 + 8);
  if (!v92)
  {
    uint64_t Context = (mlir::MLIRContext *)mlir::Attribute::getContext((mlir::Attribute *)(v2 + 24));
    uint64_t DenseI64ArrayAttr = (llvm *)mlir::Builder::getDenseI64ArrayAttr(&Context, 0, 0);
    mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)&DenseI64ArrayAttr);
    if (v9 > v6) {
      goto LABEL_36;
    }
LABEL_26:
    uint64_t DenseI64ArrayAttr = 0;
    unint64_t v88 = 0;
    LODWORD(v89) = 0;
    if (v9)
    {
      uint64_t v20 = 8 * v9;
      uint64_t v21 = 8 * v9;
      long long v22 = (mlir::MLIRContext **)v7;
      do
      {
        uint64_t v23 = *v22++;
        uint64_t Context = v23;
        llvm::DenseMapBase<llvm::DenseMap<long long,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<long long,void>,llvm::detail::DenseSetPair<long long>>,long long,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<long long,void>,llvm::detail::DenseSetPair<long long>>::try_emplace<llvm::detail::DenseSetEmpty&>((uint64_t)&DenseI64ArrayAttr, (uint64_t *)&Context, (uint64_t)&v92);
        v21 -= 8;
      }
      while (v21);
      if (v9 == v88)
      {
        for (uint64_t i = (void *)v7; (*i & 0x8000000000000000) == 0 && *i < (int64_t)v6; ++i)
        {
          v20 -= 8;
          if (!v20) {
            llvm::deallocate_buffer(DenseI64ArrayAttr, (void *)(8 * v89));
          }
        }
      }
      llvm::deallocate_buffer(DenseI64ArrayAttr, (void *)(8 * v89));
    }
    llvm::deallocate_buffer(0, 0);
  }
  mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)&v92);
  if (v9 <= v6) {
    goto LABEL_26;
  }
LABEL_36:
  uint64_t DenseI64ArrayAttr = (llvm *)"invalid inner_dims_pos vector";
  __int16 v90 = 259;
  mlir::Operation::emitError(v2, (uint64_t)&DenseI64ArrayAttr, (uint64_t)&v92);
  char v11 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v92);
  if (v92) {
    mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v92);
  }
  if (v102)
  {
    uint64_t v25 = __p;
    if (__p)
    {
      long long v26 = v101;
      unint64_t v27 = __p;
      if (v101 != __p)
      {
        do
          long long v26 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v26 - 1);
        while (v26 != v25);
        unint64_t v27 = __p;
      }
      int64_t v101 = v25;
      operator delete(v27);
    }
    unint64_t v15 = v98;
    if (!v98) {
      goto LABEL_53;
    }
    uint64_t v28 = v99;
    uint64_t v17 = v98;
    if (v99 == v98)
    {
LABEL_52:
      int64_t v99 = v15;
      operator delete(v17);
LABEL_53:
      if (v94 != v97) {
        free(v94);
      }
      goto LABEL_55;
    }
    do
    {
      uint64_t v30 = *--v28;
      uint64_t v29 = v30;
      *uint64_t v28 = 0;
      if (v30) {
        MEMORY[0x21667D390](v29, 0x1000C8077774924);
      }
    }
    while (v28 != v15);
LABEL_51:
    uint64_t v17 = v98;
    goto LABEL_52;
  }
LABEL_55:
  if (v103 != (void **)&v105) {
    free(v103);
  }
  if (!v11) {
    return 0;
  }
  uint64_t v31 = *(void *)this;
  unint64_t v32 = *(unsigned int *)(*(void *)this + 44);
  uint64_t v33 = (_DWORD *)(*(void *)this + 16 * ((v32 >> 23) & 1) + 64);
  if (!HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
    uint64_t v33 = 0;
  }
  int v34 = v33[8];
  if ((v32 & 0x800000) != 0)
  {
    uint64_t v35 = *(void *)(v31 + 72);
    if (!v34) {
      goto LABEL_87;
    }
  }
  else
  {
    uint64_t v35 = 0;
    if (!v34) {
      goto LABEL_87;
    }
  }
  uint64_t v36 = *(void *)(v35 + 32 * (v33[7] + v33[6]) + 24);
  if (v36)
  {
    unint64_t v37 = *(void *)(v36 + 8) & 0xFFFFFFFFFFFFFFF8;
    BOOL v92 = (void *)(*(void *)(*(void *)(*(void *)(v31 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8);
    if (v37 != mlir::AffineBinaryOpExpr::getRHS((mlir::AffineBinaryOpExpr *)&v92))
    {
      int v103 = (void **)"expected padding_value has ";
      __int16 v106 = 259;
      mlir::OpState::emitOpError((uint64_t *)this, &v103, (uint64_t)&v92);
      uint64_t Context = (mlir::MLIRContext *)(*(void *)(*(void *)(*(void *)(*(void *)this + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8);
      uint64_t RHS = mlir::AffineBinaryOpExpr::getRHS((mlir::AffineBinaryOpExpr *)&Context);
      if (v92)
      {
        p_uint64_t DenseI64ArrayAttr = &DenseI64ArrayAttr;
        mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&DenseI64ArrayAttr, RHS);
        uint64_t v40 = (char *)v94;
        if (v95 >= v96)
        {
          unint64_t v78 = v95 + 1;
          if (v94 <= &DenseI64ArrayAttr && (char *)v94 + 24 * v95 > (char *)&DenseI64ArrayAttr)
          {
            int64_t v82 = (char *)&DenseI64ArrayAttr - (unsigned char *)v94;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v94, v97, v78, 24);
            uint64_t v40 = (char *)v94;
            p_uint64_t DenseI64ArrayAttr = (llvm **)((char *)v94 + v82);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v94, v97, v78, 24);
            p_uint64_t DenseI64ArrayAttr = &DenseI64ArrayAttr;
            uint64_t v40 = (char *)v94;
          }
        }
        long long v41 = &v40[24 * v95];
        long long v42 = *(_OWORD *)p_DenseI64ArrayAttr;
        *((void *)v41 + 2) = p_DenseI64ArrayAttr[2];
        *(_OWORD *)long long v41 = v42;
        uint64_t v43 = ++v95;
        if (v92)
        {
          LODWORD(DenseI64ArrayAttr) = 3;
          unint64_t v88 = " but got: ";
          uint64_t v89 = 10;
          uint64_t v44 = &DenseI64ArrayAttr;
          BOOL v45 = (char *)v94;
          if (v43 >= v96)
          {
            unint64_t v79 = v43 + 1;
            BOOL v80 = (char *)v94 + 24 * v43 > (char *)&DenseI64ArrayAttr;
            if (v94 <= &DenseI64ArrayAttr && v80)
            {
              int64_t v83 = (char *)&DenseI64ArrayAttr - (unsigned char *)v94;
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v94, v97, v79, 24);
              BOOL v45 = (char *)v94;
              uint64_t v44 = (llvm **)((char *)v94 + v83);
            }
            else
            {
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v94, v97, v79, 24);
              uint64_t v44 = &DenseI64ArrayAttr;
              BOOL v45 = (char *)v94;
            }
          }
          char v46 = &v45[24 * v95];
          long long v47 = *(_OWORD *)v44;
          *((void *)v46 + 2) = v44[2];
          *(_OWORD *)char v46 = v47;
          ++v95;
          if (v92)
          {
            unint64_t v48 = *(void *)(v36 + 8) & 0xFFFFFFFFFFFFFFF8;
            uint64_t v49 = &DenseI64ArrayAttr;
            mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&DenseI64ArrayAttr, v48);
            uint64_t v50 = (char *)v94;
            if (v95 >= v96)
            {
              unint64_t v81 = v95 + 1;
              if (v94 <= &DenseI64ArrayAttr && (char *)v94 + 24 * v95 > (char *)&DenseI64ArrayAttr)
              {
                int64_t v84 = (char *)&DenseI64ArrayAttr - (unsigned char *)v94;
                llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v94, v97, v81, 24);
                uint64_t v50 = (char *)v94;
                uint64_t v49 = (llvm **)((char *)v94 + v84);
              }
              else
              {
                llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v94, v97, v81, 24);
                uint64_t v49 = &DenseI64ArrayAttr;
                uint64_t v50 = (char *)v94;
              }
            }
            long long v51 = &v50[24 * v95];
            long long v52 = *(_OWORD *)v49;
            *((void *)v51 + 2) = v49[2];
            *(_OWORD *)long long v51 = v52;
            ++v95;
          }
        }
      }
      uint64_t v53 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v92);
      if (v92) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v92);
      }
      if (v102)
      {
        uint64_t v54 = __p;
        if (__p)
        {
          uint64_t v55 = v101;
          uint64_t v56 = __p;
          if (v101 != __p)
          {
            do
              uint64_t v55 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v55 - 1);
            while (v55 != v54);
            uint64_t v56 = __p;
          }
          int64_t v101 = v54;
          operator delete(v56);
        }
        unint64_t v57 = v98;
        if (!v98) {
          goto LABEL_117;
        }
        unint64_t v58 = v99;
        BOOL v59 = v98;
        if (v99 == v98)
        {
LABEL_116:
          int64_t v99 = v57;
          operator delete(v59);
LABEL_117:
          if (v94 != v97) {
            free(v94);
          }
          return v53;
        }
        do
        {
          uint64_t v61 = *--v58;
          uint64_t v60 = v61;
          *unint64_t v58 = 0;
          if (v61) {
            MEMORY[0x21667D390](v60, 0x1000C8077774924);
          }
        }
        while (v58 != v57);
LABEL_115:
        BOOL v59 = v98;
        goto LABEL_116;
      }
      return v53;
    }
    return 1;
  }
LABEL_87:
  int v103 = (void **)(*(void *)(*(void *)(*(void *)(v31 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8);
  uint64_t Value = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v103);
  BOOL v92 = *(void **)(*(void *)this + 16 * (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 23) & 1) + 64);
  unint64_t v63 = (void *)mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)&v92);
  uint64_t v65 = v64;
  mlir::tensor::PackOp::getMixedTiles(this, (uint64_t)&v92);
  int64_t v66 = (uint64_t *)v92;
  if (v65)
  {
    uint64_t v67 = 8 * v65;
    do
    {
      if (*(void *)(Value + 8 * *v63) != 0x8000000000000000)
      {
        int64_t ConstantIntValue = mlir::getConstantIntValue(*v66);
        if (v69)
        {
          if (*(void *)(Value + 8 * *v63) % ConstantIntValue)
          {
            int v70 = 1;
            int64_t v66 = (uint64_t *)v92;
            if (v92 != &v93) {
              goto LABEL_96;
            }
            goto LABEL_97;
          }
        }
      }
      ++v63;
      ++v66;
      v67 -= 8;
    }
    while (v67);
    int v70 = 0;
    int64_t v66 = (uint64_t *)v92;
    if (v92 == &v93) {
      goto LABEL_97;
    }
    goto LABEL_96;
  }
  int v70 = 0;
  if (v92 != &v93) {
LABEL_96:
  }
    free(v66);
LABEL_97:
  if (!v70) {
    return 1;
  }
  int v103 = (void **)"invalid tile factor provided. Only full tiles are supported when padding_value is not set";
  __int16 v106 = 259;
  mlir::OpState::emitOpError((uint64_t *)this, &v103, (uint64_t)&v92);
  uint64_t v53 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v92);
  if (v92) {
    mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v92);
  }
  if (v102)
  {
    int64_t v71 = __p;
    if (__p)
    {
      int64_t v72 = v101;
      __int16 v73 = __p;
      if (v101 != __p)
      {
        do
          int64_t v72 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v72 - 1);
        while (v72 != v71);
        __int16 v73 = __p;
      }
      int64_t v101 = v71;
      operator delete(v73);
    }
    unint64_t v57 = v98;
    if (!v98) {
      goto LABEL_117;
    }
    int v74 = v99;
    BOOL v59 = v98;
    if (v99 == v98) {
      goto LABEL_116;
    }
    do
    {
      uint64_t v76 = *--v74;
      uint64_t v75 = v76;
      *int v74 = 0;
      if (v76) {
        MEMORY[0x21667D390](v75, 0x1000C8077774924);
      }
    }
    while (v74 != v57);
    goto LABEL_115;
  }
  return v53;
}

void getPackOpResultTypeShape(uint64_t a1, const void *a2, unint64_t a3, uint64_t *a4, uint64_t a5, void *a6, uint64_t a7, uint64_t a8, uint64_t *a9, uint64_t a10)
{
  uint64_t v17 = (void *)(a1 + 16);
  *(void *)a1 = a1 + 16;
  *(void *)(a1 + 8) = 0x600000000;
  size_t v18 = 8 * a3;
  if (8 * a3 < 0x31)
  {
    unsigned int v19 = 0;
    uint64_t v20 = a10;
    if (!a3) {
      goto LABEL_6;
    }
    goto LABEL_5;
  }
  llvm::SmallVectorBase<unsigned int>::grow_pod(a1, (void *)(a1 + 16), a3, 8);
  unsigned int v19 = *(_DWORD *)(a1 + 8);
  uint64_t v20 = a10;
  if (a3)
  {
LABEL_5:
    memcpy((void *)(*(void *)a1 + 8 * v19), a2, v18);
    unsigned int v19 = *(_DWORD *)(a1 + 8);
  }
LABEL_6:
  unsigned int v21 = v19 + a3;
  *(_DWORD *)(a1 + 8) = v21;
  if (a7)
  {
    uint64_t v22 = *(void *)a1;
    uint64_t v23 = 8 * a7;
    uint64_t v24 = a4;
    do
    {
      uint64_t v26 = *(void *)(v22 + 8 * *a6);
      if (v26 != 0x8000000000000000)
      {
        uint64_t v27 = *v24;
        uint64_t v25 = 0x8000000000000000;
        if (*v24 != 0x8000000000000000)
        {
          if (v26) {
            BOOL v28 = v26 < 1 == v27 > 0;
          }
          else {
            BOOL v28 = 1;
          }
          if (v28)
          {
            uint64_t v25 = v26 / v27;
          }
          else
          {
            if (v27 <= 0) {
              uint64_t v29 = v26 + 1;
            }
            else {
              uint64_t v29 = v26 - 1;
            }
            uint64_t v25 = v29 / v27 + 1;
          }
        }
        *(void *)(v22 + 8 * *a6) = v25;
      }
      ++a6;
      ++v24;
      v23 -= 8;
    }
    while (v23);
  }
  if (v20)
  {
    mlir::applyPermutationToVector<long long,6u>(a1, a9);
    unsigned int v21 = *(_DWORD *)(a1 + 8);
  }
  unint64_t v30 = ((8 * a5) >> 3) + v21;
  if (v30 > *(unsigned int *)(a1 + 12))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod(a1, v17, v30, 8);
    unsigned int v21 = *(_DWORD *)(a1 + 8);
  }
  if (a5)
  {
    memcpy((void *)(*(void *)a1 + 8 * v21), a4, 8 * a5);
    unsigned int v21 = *(_DWORD *)(a1 + 8);
  }
  *(_DWORD *)(a1 + 8) = v21 + a5;
}

uint64_t mlir::tensor::PackOp::inferPackedType(uint64_t a1, uint64_t *a2, uint64_t a3, void *a4, uint64_t a5, uint64_t *a6, uint64_t a7)
{
  v24[6] = *MEMORY[0x263EF8340];
  uint64_t v21 = a1;
  uint64_t Value = (const void *)mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v21);
  getPackOpResultTypeShape((uint64_t)&v22, Value, v14, a2, a3, a4, a5, v15, a6, a7);
  uint64_t v16 = v22;
  uint64_t v17 = v23;
  uint64_t RHS = mlir::AffineBinaryOpExpr::getRHS((mlir::AffineBinaryOpExpr *)&v21);
  uint64_t v19 = mlir::RankedTensorType::get((uint64_t)v16, v17, RHS, 0);
  if (v22 != v24) {
    free(v22);
  }
  return v19;
}

uint64_t mlir::tensor::PackOp::getSpeculatability(mlir::tensor::PackOp *this)
{
  uint64_t v1 = *(void *)this;
  unint64_t v2 = *(unsigned int *)(v1 + 44);
  uint64_t v3 = (_DWORD *)(v1 + 16 * ((v2 >> 23) & 1) + 64);
  if (!HIBYTE(*(_DWORD *)(v1 + 44))) {
    uint64_t v3 = 0;
  }
  int v4 = v3[8];
  if ((v2 & 0x800000) != 0)
  {
    uint64_t v5 = *(void *)(v1 + 72);
    if (!v4) {
      return areTilesAndTiledDimsAllConstant<mlir::tensor::PackOp>(v1);
    }
  }
  else
  {
    uint64_t v5 = 0;
    if (!v4) {
      return areTilesAndTiledDimsAllConstant<mlir::tensor::PackOp>(v1);
    }
  }
  if (*(void *)(v5 + 32 * (v3[7] + v3[6]) + 24)) {
    return 1;
  }
  return areTilesAndTiledDimsAllConstant<mlir::tensor::PackOp>(v1);
}

uint64_t areTilesAndTiledDimsAllConstant<mlir::tensor::PackOp>(uint64_t a1)
{
  v20[6] = *MEMORY[0x263EF8340];
  uint64_t v17 = a1;
  if (*(unsigned char *)(a1 + 47)) {
    uint64_t v1 = a1 + 80;
  }
  else {
    uint64_t v1 = 0;
  }
  unint64_t v2 = (void *)(*(void *)(*(void *)(*(void *)(a1 + 72) + 32 * *(unsigned int *)(v1 + 24) + 24) + 8) & 0xFFFFFFFFFFFFFFF8);
  if (v2) {
    uint64_t v3 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*v2 + 8);
  }
  else {
    uint64_t v3 = 0;
  }
  v16[0] = v2;
  v16[1] = v3;
  mlir::tensor::PackOp::getMixedTiles((mlir::tensor::PackOp *)&v17, (uint64_t)&v18);
  uint64_t Shape = mlir::ShapedType::getShape((mlir::ShapedType *)v16);
  if (v5 <= v19) {
    unint64_t v6 = (void *)Shape;
  }
  else {
    unint64_t v6 = (void *)(Shape + 8 * (v5 - v19));
  }
  if (v5 >= v19) {
    unint64_t v7 = v19;
  }
  else {
    unint64_t v7 = v5;
  }
  unint64_t v8 = v18;
  if (v7) {
    BOOL v9 = v19 == 0;
  }
  else {
    BOOL v9 = 1;
  }
  if (v9)
  {
    uint64_t v12 = 1;
    if (v18 != v20) {
LABEL_27:
    }
      free(v8);
  }
  else
  {
    uint64_t v10 = 8 * v19 - 8;
    uint64_t v11 = 8 * v7 - 8;
    uint64_t v12 = 1;
    while (1)
    {
      mlir::getConstantIntValue(*v8);
      if (!v13)
      {
        uint64_t v12 = 0;
LABEL_26:
        unint64_t v8 = v18;
        if (v18 == v20) {
          return v12;
        }
        goto LABEL_27;
      }
      if (*v6 == 0x8000000000000000) {
        break;
      }
      if (v11)
      {
        ++v6;
        ++v8;
        uint64_t v14 = v10;
        v10 -= 8;
        v11 -= 8;
        if (v14) {
          continue;
        }
      }
      goto LABEL_26;
    }
    uint64_t v12 = 0;
    unint64_t v8 = v18;
    if (v18 != v20) {
      goto LABEL_27;
    }
  }
  return v12;
}

uint64_t mlir::tensor::PackOp::canonicalize(uint64_t a1, uint64_t a2)
{
  uint64_t v10 = *(void *)(*(void *)(a1 + 72) + 24);
  uint64_t DefiningOp = mlir::Value::getDefiningOp((mlir::Value *)&v10);
  uint64_t v5 = DefiningOp;
  if (!DefiningOp) {
    return v5;
  }
  if (*(_UNKNOWN **)(*(void *)(DefiningOp + 48) + 16) != &mlir::detail::TypeIDResolver<mlir::tensor::UnPackOp,void>::id) {
    return 0;
  }
  if (*(unsigned char *)(a1 + 47)) {
    unint64_t v7 = (unsigned int *)(a1 + 80);
  }
  else {
    unint64_t v7 = 0;
  }
  uint64_t v8 = v7[6];
  uint64_t v9 = *(void *)(a1 + 72);
  if ((*(void *)(*(void *)(*(void *)(DefiningOp + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8) != (*(void *)(*(void *)(v9 + 32 * v8 + 24) + 8) & 0xFFFFFFFFFFFFFFF8)
    || v7[8] && *(void *)(v9 + 32 * (v8 + v7[7]) + 24)
    || !hasSameInnerOuterAttribute(a1, DefiningOp)
    || !haveSameTiles(a1, v5))
  {
    return 0;
  }
  uint64_t v10 = *(void *)(*(void *)(v5 + 72) + 24);
  (*(void (**)(uint64_t, uint64_t, uint64_t *, uint64_t))(*(void *)a2 + 24))(a2, a1, &v10, 1);
  return 1;
}

BOOL hasSameInnerOuterAttribute(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = a1 + 64;
  uint64_t v22 = *(void *)(a1 + 64 + 16 * (((unint64_t)*(unsigned int *)(a1 + 44) >> 23) & 1));
  uint64_t v5 = (const void *)mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)&v22);
  uint64_t v7 = v6;
  uint64_t v22 = *(void *)(a2 + 64 + 16 * (((unint64_t)*(unsigned int *)(a2 + 44) >> 23) & 1));
  uint64_t v8 = (const void *)mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)&v22);
  if (v7 != v9 || memcmp(v5, v8, 8 * v7)) {
    return 0;
  }
  if (HIBYTE(*(_DWORD *)(a1 + 44))) {
    uint64_t v11 = v4 + 16 * (((unint64_t)*(unsigned int *)(a1 + 44) >> 23) & 1);
  }
  else {
    uint64_t v11 = 0;
  }
  uint64_t v22 = *(void *)(v11 + 8);
  if (v22)
  {
    p_uint64_t DenseI64ArrayAttr = &v22;
  }
  else
  {
    uint64_t Context = (mlir::MLIRContext *)mlir::Attribute::getContext((mlir::Attribute *)(a1 + 24));
    uint64_t DenseI64ArrayAttr = mlir::Builder::getDenseI64ArrayAttr(&Context, 0, 0);
    p_uint64_t DenseI64ArrayAttr = &DenseI64ArrayAttr;
  }
  char v13 = (const void *)mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)p_DenseI64ArrayAttr);
  uint64_t v15 = v14;
  if (HIBYTE(*(_DWORD *)(a2 + 44))) {
    unint64_t v16 = a2 + 64 + 16 * (((unint64_t)*(unsigned int *)(a2 + 44) >> 23) & 1);
  }
  else {
    unint64_t v16 = 0;
  }
  uint64_t v22 = *(void *)(v16 + 8);
  if (v22)
  {
    uint64_t v17 = (const void *)mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)&v22);
    if (v15 == v18) {
      return memcmp(v13, v17, 8 * v15) == 0;
    }
    return 0;
  }
  uint64_t Context = (mlir::MLIRContext *)mlir::Attribute::getContext((mlir::Attribute *)(a2 + 24));
  uint64_t DenseI64ArrayAttr = mlir::Builder::getDenseI64ArrayAttr(&Context, 0, 0);
  uint64_t v17 = (const void *)mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)&DenseI64ArrayAttr);
  if (v15 != v19) {
    return 0;
  }
  return memcmp(v13, v17, 8 * v15) == 0;
}

BOOL haveSameTiles(uint64_t a1, uint64_t a2)
{
  v16[6] = *MEMORY[0x263EF8340];
  uint64_t v9 = a2;
  uint64_t v10 = a1;
  mlir::tensor::PackOp::getMixedTiles((mlir::tensor::PackOp *)&v10, (uint64_t)&v14);
  mlir::tensor::UnPackOp::getMixedTiles((mlir::tensor::UnPackOp *)&v9, (uint64_t)&v11);
  unint64_t v2 = v15;
  if (v15 != v12) {
    goto LABEL_9;
  }
  if (v15)
  {
    if (mlir::isEqualConstantIntOrValue(*(void *)v14, *(void *)v11))
    {
      uint64_t v3 = 1;
      do
      {
        unint64_t v4 = v3;
        if (v2 == v3) {
          break;
        }
        isEqualConstantIntOruint64_t Value = mlir::isEqualConstantIntOrValue(*((void *)v14 + v3), *((void *)v11 + v3));
        uint64_t v3 = v4 + 1;
      }
      while ((isEqualConstantIntOrValue & 1) != 0);
      BOOL v6 = v4 >= v2;
      uint64_t v7 = v11;
      if (v11 == v13) {
        goto LABEL_11;
      }
      goto LABEL_10;
    }
LABEL_9:
    BOOL v6 = 0;
    uint64_t v7 = v11;
    if (v11 == v13) {
      goto LABEL_11;
    }
    goto LABEL_10;
  }
  BOOL v6 = 1;
  uint64_t v7 = v11;
  if (v11 != v13) {
LABEL_10:
  }
    free(v7);
LABEL_11:
  if (v14 != v16) {
    free(v14);
  }
  return v6;
}

unint64_t mlir::tensor::PackOp::fold(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = *(uint64_t **)(a2 + 80);
  unint64_t v4 = *v3;
  if (*v3 && !mlir::DenseElementsAttr::classof(*v3)) {
    unint64_t v4 = 0;
  }
  if (*(_DWORD *)(*(void *)a1 + 36)) {
    uint64_t v5 = *(void *)a1 - 16;
  }
  else {
    uint64_t v5 = 0;
  }
  uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v5, 0);
  unint64_t result = reshapeConstantSource(v4, (void *)(*(void *)(NextResultAtOffset + 8) & 0xFFFFFFFFFFFFFFF8));
  if (result <= 7) {
    return 0;
  }
  return result;
}

uint64_t mlir::tensor::UnPackOp::getAsmResultNames(uint64_t a1, uint64_t (*a2)(uint64_t, uint64_t, const char *, uint64_t), uint64_t a3)
{
  if (*(_DWORD *)(*(void *)a1 + 36)) {
    uint64_t v4 = *(void *)a1 - 16;
  }
  else {
    uint64_t v4 = 0;
  }
  uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v4, 0);

  return a2(a3, NextResultAtOffset, "unpack", 6);
}

uint64_t mlir::tensor::UnPackOp::reifyResultShapes(uint64_t *a1, mlir::IndexType **a2, uint64_t a3)
{
  v31[6] = *MEMORY[0x263EF8340];
  uint64_t v5 = *a1;
  uint64_t v29 = (void *)(*(void *)(*(void *)(*(void *)(*a1 + 72) + 56) + 8) & 0xFFFFFFFFFFFFFFF8);
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v29);
  uint64_t v29 = v31;
  uint64_t v30 = 0x600000000;
  if (v6)
  {
    unint64_t v7 = v6;
    if (v6 < 7)
    {
      uint64_t v8 = 0;
      unint64_t v9 = v6;
    }
    else
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v29, v31, v6, 8);
      uint64_t v8 = v30;
      unint64_t v9 = v7 - v30;
      if (v7 == v30) {
        goto LABEL_7;
      }
    }
    bzero((char *)v29 + 8 * v8, 8 * v9);
LABEL_7:
    LODWORD(v30) = v7;
  }
  uint64_t v10 = *(unsigned int *)(a3 + 8);
  if (!v10)
  {
    llvm::SmallVectorImpl<llvm::SmallVector<mlir::OpFoldResult,6u>>::append(a3, 1 - v10, (unint64_t)&v29);
LABEL_15:
    uint64_t v14 = v29;
    if (v29 == v31) {
      goto LABEL_17;
    }
    goto LABEL_16;
  }
  if (v10 == 1) {
    goto LABEL_15;
  }
  uint64_t v11 = *(void *)a3;
  uint64_t v12 = v10 << 6;
  do
  {
    char v13 = *(void **)(v11 + v12 - 64);
    if ((void *)(v11 + v12 - 48) != v13) {
      free(v13);
    }
    v12 -= 64;
  }
  while (v12 != 64);
  *(_DWORD *)(a3 + 8) = 1;
  uint64_t v14 = v29;
  if (v29 != v31) {
LABEL_16:
  }
    free(v14);
LABEL_17:
  uint64_t v15 = *(void *)(v5 + 24);
  uint64_t v16 = *(void *)(*(void *)(v5 + 72) + 56);
  unint64_t v28 = *(void *)(v16 + 8) & 0xFFFFFFFFFFFFFFF8;
  uint64_t v29 = v31;
  uint64_t v30 = 0x600000000;
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v28);
  if (v17 >= 1)
  {
    for (uint64_t i = 0; (uint64_t)i < v21; uint64_t i = (mlir::MLIRContext *)((char *)i + 1))
    {
      unint64_t MixedSize = mlir::tensor::getMixedSize(a2, v15, v16, i);
      uint64_t v20 = v30;
      if (v30 >= (unint64_t)HIDWORD(v30))
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v29, v31, v30 + 1, 8);
        uint64_t v20 = v30;
      }
      *((void *)v29 + v20) = MixedSize;
      LODWORD(v30) = v30 + 1;
      mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v28);
    }
  }
  uint64_t v22 = *(void *)a3;
  unsigned int v23 = v29;
  if ((void **)v22 != &v29)
  {
    if (v29 != v31)
    {
      if (*(void *)v22 != v22 + 16)
      {
        free(*(void **)v22);
        unsigned int v23 = v29;
      }
      *(void *)uint64_t v22 = v23;
      *(void *)(v22 + 8) = v30;
      uint64_t v29 = v31;
      HIDWORD(v30) = 0;
      goto LABEL_39;
    }
    unint64_t v24 = v30;
    uint64_t v25 = *(unsigned int *)(v22 + 8);
    if (v25 >= v30)
    {
      if (v30) {
        memmove(*(void **)v22, v31, 8 * v30);
      }
      goto LABEL_38;
    }
    if (*(_DWORD *)(v22 + 12) >= v30)
    {
      if (v25)
      {
        memmove(*(void **)v22, v31, 8 * v25);
        uint64_t v26 = v30;
        if (v25 == v30)
        {
LABEL_38:
          *(_DWORD *)(v22 + 8) = v24;
LABEL_39:
          LODWORD(v30) = 0;
          unsigned int v23 = v29;
          goto LABEL_40;
        }
      }
      else
      {
        uint64_t v25 = 0;
        uint64_t v26 = v30;
        if (!v30) {
          goto LABEL_38;
        }
      }
    }
    else
    {
      *(_DWORD *)(v22 + 8) = 0;
      llvm::SmallVectorBase<unsigned int>::grow_pod(v22, (void *)(v22 + 16), v24, 8);
      uint64_t v25 = 0;
      uint64_t v26 = v30;
      if (!v30) {
        goto LABEL_38;
      }
    }
    memcpy((void *)(*(void *)v22 + 8 * v25), (char *)v29 + 8 * v25, 8 * v26 - 8 * v25);
    goto LABEL_38;
  }
LABEL_40:
  if (v23 != v31) {
    free(v23);
  }
  return 1;
}

void mlir::tensor::UnPackOp::getMixedTiles(mlir::tensor::UnPackOp *this@<X0>, uint64_t a2@<X8>)
{
  uint64_t v3 = *(void *)this;
  uint64_t Context = mlir::Attribute::getContext((mlir::Attribute *)(*(void *)this + 24));
  *(void *)a2 = a2 + 16;
  *(void *)(a2 + 8) = 0x600000000;
  if (HIBYTE(*(_DWORD *)(v3 + 44))) {
    unint64_t v5 = v3 + 16 * (((unint64_t)*(unsigned int *)(v3 + 44) >> 23) & 1) + 64;
  }
  else {
    unint64_t v5 = 0;
  }
  uint64_t v6 = *(void *)(v5 + 16);
  uint64_t v15 = Context;
  uint64_t v16 = v6;
  uint64_t v7 = mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)&v16);
  if (v8)
  {
    unint64_t v9 = (uint64_t *)v7;
    unsigned int v10 = 0;
    uint64_t v11 = 8 * v8;
    do
    {
      if (*v9 == 0x8000000000000000)
      {
        uint64_t v12 = *(void *)(v3 + 72) + 32 * v10++;
        unint64_t v13 = *(void *)(v12 + 88) | 4;
      }
      else
      {
        unint64_t v13 = mlir::Builder::getI64IntegerAttr((mlir::Builder *)&v15, *v9) & 0xFFFFFFFFFFFFFFFBLL;
      }
      unint64_t v14 = *(unsigned int *)(a2 + 8);
      if (v14 >= *(unsigned int *)(a2 + 12))
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod(a2, (void *)(a2 + 16), v14 + 1, 8);
        unint64_t v14 = *(unsigned int *)(a2 + 8);
      }
      *(void *)(*(void *)a2 + 8 * v14) = v13;
      ++*(_DWORD *)(a2 + 8);
      ++v9;
      v11 -= 8;
    }
    while (v11);
  }
}

uint64_t mlir::tensor::UnPackOp::verify(mlir::tensor::UnPackOp *this)
{
  uint64_t v49 = *MEMORY[0x263EF8340];
  uint64_t v1 = *(void *)this;
  uint64_t v32 = *(void *)this;
  mlir::tensor::UnPackOp::getMixedTiles((mlir::tensor::UnPackOp *)&v32, (uint64_t)&v42);
  if (v43)
  {
    unint64_t v2 = v42;
    uint64_t v3 = 8 * v43;
    while (!mlir::isConstantIntValue(*v2, 0))
    {
      ++v2;
      v3 -= 8;
      if (!v3) {
        goto LABEL_5;
      }
    }
    uint64_t DenseI64ArrayAttr = (llvm *)"invalid zero tile factor";
    __int16 v48 = 259;
    mlir::Operation::emitError(v1, (uint64_t)&DenseI64ArrayAttr, (uint64_t)&v34);
    uint64_t v10 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v34);
    if (v34) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v34);
    }
    if (v41)
    {
      uint64_t v11 = __p;
      if (__p)
      {
        uint64_t v12 = v40;
        unint64_t v13 = __p;
        if (v40 != __p)
        {
          do
            uint64_t v12 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v12 - 1);
          while (v12 != v11);
          unint64_t v13 = __p;
        }
        uint64_t v40 = v11;
        operator delete(v13);
      }
      unint64_t v14 = v37;
      if (!v37) {
        goto LABEL_53;
      }
      uint64_t v15 = v38;
      uint64_t v16 = v37;
      if (v38 == v37) {
        goto LABEL_52;
      }
      do
      {
        uint64_t v18 = *--v15;
        uint64_t v17 = v18;
        *uint64_t v15 = 0;
        if (v18) {
          MEMORY[0x21667D390](v17, 0x1000C8077774924);
        }
      }
      while (v15 != v14);
      goto LABEL_51;
    }
    goto LABEL_55;
  }
LABEL_5:
  unint64_t v31 = *(void *)(*(void *)(*(void *)(v1 + 72) + 56) + 8) & 0xFFFFFFFFFFFFFFF8;
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v31);
  unint64_t v5 = v4;
  int v34 = *(void **)(v1 + 64 + 16 * (((unint64_t)*(unsigned int *)(v1 + 44) >> 23) & 1));
  uint64_t v6 = mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)&v34);
  unint64_t v8 = v7;
  if (HIBYTE(*(_DWORD *)(v1 + 44))) {
    unint64_t v9 = v1 + 64 + 16 * (((unint64_t)*(unsigned int *)(v1 + 44) >> 23) & 1);
  }
  else {
    unint64_t v9 = 0;
  }
  int v34 = *(void **)(v9 + 8);
  if (!v34)
  {
    uint64_t Context = (void *)mlir::Attribute::getContext((mlir::Attribute *)(v1 + 24));
    uint64_t DenseI64ArrayAttr = (llvm *)mlir::Builder::getDenseI64ArrayAttr((mlir::MLIRContext **)&Context, 0, 0);
    mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)&DenseI64ArrayAttr);
    if (v8 > v5) {
      goto LABEL_36;
    }
LABEL_26:
    uint64_t DenseI64ArrayAttr = 0;
    uint64_t v46 = 0;
    unsigned int v47 = 0;
    if (v8)
    {
      uint64_t v19 = 8 * v8;
      uint64_t v20 = 8 * v8;
      uint64_t v21 = (void **)v6;
      do
      {
        uint64_t v22 = *v21++;
        uint64_t Context = v22;
        llvm::DenseMapBase<llvm::DenseMap<long long,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<long long,void>,llvm::detail::DenseSetPair<long long>>,long long,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<long long,void>,llvm::detail::DenseSetPair<long long>>::try_emplace<llvm::detail::DenseSetEmpty&>((uint64_t)&DenseI64ArrayAttr, (uint64_t *)&Context, (uint64_t)&v34);
        v20 -= 8;
      }
      while (v20);
      if (v8 == v46)
      {
        for (uint64_t i = (void *)v6; (*i & 0x8000000000000000) == 0 && *i < (int64_t)v5; ++i)
        {
          v19 -= 8;
          if (!v19) {
            llvm::deallocate_buffer(DenseI64ArrayAttr, (void *)(8 * v47));
          }
        }
      }
      llvm::deallocate_buffer(DenseI64ArrayAttr, (void *)(8 * v47));
    }
    llvm::deallocate_buffer(0, 0);
  }
  mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)&v34);
  if (v8 <= v5) {
    goto LABEL_26;
  }
LABEL_36:
  uint64_t DenseI64ArrayAttr = (llvm *)"invalid inner_dims_pos vector";
  __int16 v48 = 259;
  mlir::Operation::emitError(v1, (uint64_t)&DenseI64ArrayAttr, (uint64_t)&v34);
  uint64_t v10 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v34);
  if (v34) {
    mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v34);
  }
  if (v41)
  {
    unint64_t v24 = __p;
    if (__p)
    {
      uint64_t v25 = v40;
      uint64_t v26 = __p;
      if (v40 != __p)
      {
        do
          uint64_t v25 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v25 - 1);
        while (v25 != v24);
        uint64_t v26 = __p;
      }
      uint64_t v40 = v24;
      operator delete(v26);
    }
    unint64_t v14 = v37;
    if (!v37) {
      goto LABEL_53;
    }
    uint64_t v27 = v38;
    uint64_t v16 = v37;
    if (v38 == v37)
    {
LABEL_52:
      unint64_t v38 = v14;
      operator delete(v16);
LABEL_53:
      if (v35 != &v36) {
        free(v35);
      }
      goto LABEL_55;
    }
    do
    {
      uint64_t v29 = *--v27;
      uint64_t v28 = v29;
      void *v27 = 0;
      if (v29) {
        MEMORY[0x21667D390](v28, 0x1000C8077774924);
      }
    }
    while (v27 != v14);
LABEL_51:
    uint64_t v16 = v37;
    goto LABEL_52;
  }
LABEL_55:
  if (v42 != &v44) {
    free(v42);
  }
  return v10;
}

uint64_t mlir::tensor::UnPackOp::getSpeculatability(mlir::tensor::UnPackOp *this)
{
  return areTilesAndTiledDimsAllConstant<mlir::tensor::UnPackOp>(*(void *)this);
}

uint64_t areTilesAndTiledDimsAllConstant<mlir::tensor::UnPackOp>(uint64_t a1)
{
  v19[6] = *MEMORY[0x263EF8340];
  uint64_t v16 = a1;
  uint64_t v1 = (void *)(*(void *)(*(void *)(*(void *)(a1 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8);
  if (v1) {
    uint64_t v2 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*v1 + 8);
  }
  else {
    uint64_t v2 = 0;
  }
  v15[0] = v1;
  v15[1] = v2;
  mlir::tensor::UnPackOp::getMixedTiles((mlir::tensor::UnPackOp *)&v16, (uint64_t)&v17);
  uint64_t Shape = mlir::ShapedType::getShape((mlir::ShapedType *)v15);
  if (v4 <= v18) {
    unint64_t v5 = (void *)Shape;
  }
  else {
    unint64_t v5 = (void *)(Shape + 8 * (v4 - v18));
  }
  if (v4 >= v18) {
    unint64_t v6 = v18;
  }
  else {
    unint64_t v6 = v4;
  }
  unint64_t v7 = v17;
  if (v6) {
    BOOL v8 = v18 == 0;
  }
  else {
    BOOL v8 = 1;
  }
  if (v8)
  {
    uint64_t v11 = 1;
    if (v17 != v19) {
LABEL_24:
    }
      free(v7);
  }
  else
  {
    uint64_t v9 = 8 * v18 - 8;
    uint64_t v10 = 8 * v6 - 8;
    uint64_t v11 = 1;
    while (1)
    {
      mlir::getConstantIntValue(*v7);
      if (!v12)
      {
        uint64_t v11 = 0;
LABEL_23:
        unint64_t v7 = v17;
        if (v17 == v19) {
          return v11;
        }
        goto LABEL_24;
      }
      if (*v5 == 0x8000000000000000) {
        break;
      }
      if (v10)
      {
        ++v5;
        ++v7;
        uint64_t v13 = v9;
        v9 -= 8;
        v10 -= 8;
        if (v13) {
          continue;
        }
      }
      goto LABEL_23;
    }
    uint64_t v11 = 0;
    unint64_t v7 = v17;
    if (v17 != v19) {
      goto LABEL_24;
    }
  }
  return v11;
}

uint64_t mlir::tensor::UnPackOp::canonicalize(uint64_t a1, uint64_t a2)
{
  v27[3] = *MEMORY[0x263EF8340];
  v25[0] = *(void *)(*(void *)(a1 + 72) + 24);
  uint64_t DefiningOp = mlir::Value::getDefiningOp((mlir::Value *)v25);
  if (DefiningOp)
  {
    uint64_t v5 = DefiningOp;
    if (*(_UNKNOWN **)(*(void *)(DefiningOp + 48) + 16) == &mlir::detail::TypeIDResolver<mlir::tensor::PackOp,void>::id)
    {
      if (*(unsigned char *)(DefiningOp + 47)) {
        uint64_t v19 = (unsigned int *)(DefiningOp + 80);
      }
      else {
        uint64_t v19 = 0;
      }
      uint64_t v20 = v19[6];
      uint64_t v21 = *(void *)(DefiningOp + 72);
      if ((*(void *)(*(void *)(v21 + 32 * v20 + 24) + 8) & 0xFFFFFFFFFFFFFFF8) == (*(void *)(*(void *)(*(void *)(a1 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8)
        && (!v19[8] || !*(void *)(v21 + 32 * (v20 + v19[7]) + 24))
        && hasSameInnerOuterAttribute(DefiningOp, a1)
        && haveSameTiles(v5, a1))
      {
        v25[0] = *(void *)(*(void *)(v5 + 72) + 24);
        uint64_t v18 = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t *, uint64_t))(*(void *)a2 + 24))(a2, a1, v25, 1);
        return v18;
      }
      return 0;
    }
  }
  v25[0] = *(void *)(*(void *)(a1 + 72) + 56);
  uint64_t v6 = mlir::Value::getDefiningOp((mlir::Value *)v25);
  if (!v6)
  {
    uint64_t v23 = 0;
    uint64_t v24 = 0;
    return 0;
  }
  uint64_t v23 = llvm::DefaultDoCastIfPossible<mlir::DestinationStyleOpInterface,mlir::Operation *,llvm::CastInfo<mlir::DestinationStyleOpInterface,mlir::Operation *,void>>::doCastIfPossible(v6);
  uint64_t v24 = v7;
  if (!v23) {
    return 0;
  }
  uint64_t v8 = *(void *)(*(void *)(a1 + 72) + 56);
  mlir::DestinationStyleOpInterface::getDpsInitsMutable(v25, (mlir::DestinationStyleOpInterface *)&v23);
  uint64_t v9 = mlir::MutableOperandRange::operator mlir::OperandRange((unsigned int *)v25);
  if (v26 != v27) {
    free(v26);
  }
  uint64_t v10 = *(void *)(v8 + 8) & 7;
  if (v8 && v10 == 6) {
    uint64_t v10 = (*(_DWORD *)(v8 + 16) + 6);
  }
  uint64_t v11 = *(uint64_t **)(v9 + 32 * v10 + 24);
  (*(void (**)(uint64_t, uint64_t))(*(void *)a2 + 72))(a2, a1);
  mlir::MutableOperandRange::MutableOperandRange((mlir::MutableOperandRange *)v25, (mlir::OpOperand *)(*(void *)(a1 + 72) + 32));
  uint64_t v12 = mlir::MutableOperandRange::operator mlir::OperandRange((unsigned int *)v25);
  uint64_t v14 = v13;
  if (v26 != v27) {
    free(v26);
  }
  v25[0] = v12;
  v25[1] = v14;
  uint64_t v15 = (uint64_t *)(*(void *)(a1 + 72)
                  + 32 * mlir::OperandRange::getBeginOperandIndex((mlir::OperandRange *)v25));
  uint64_t v16 = (uint64_t *)v15[1];
  if (v16)
  {
    *uint64_t v16 = *v15;
    if (*v15) {
      *(void *)(*v15 + 8) = v15[1];
    }
  }
  v15[3] = (uint64_t)v11;
  v15[1] = (uint64_t)v11;
  uint64_t v17 = *v11;
  *uint64_t v15 = *v11;
  if (v17) {
    *(void *)(v17 + 8) = v15;
  }
  *uint64_t v11 = (uint64_t)v15;
  (*(void (**)(uint64_t, uint64_t))(*(void *)a2 + 80))(a2, a1);
  return 1;
}

unint64_t mlir::tensor::UnPackOp::fold(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = *(uint64_t **)(a2 + 64);
  unint64_t v4 = *v3;
  if (*v3 && !mlir::DenseElementsAttr::classof(*v3)) {
    unint64_t v4 = 0;
  }
  if (*(_DWORD *)(*(void *)a1 + 36)) {
    uint64_t v5 = *(void *)a1 - 16;
  }
  else {
    uint64_t v5 = 0;
  }
  uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v5, 0);
  unint64_t result = reshapeConstantSource(v4, (void *)(*(void *)(NextResultAtOffset + 8) & 0xFFFFFFFFFFFFFFF8));
  if (result <= 7) {
    return 0;
  }
  return result;
}

void mlir::tensor::TensorDialect::getCanonicalizationPatterns()
{
}

BOOL mlir::tensor::BitcastOp::verifyInvariantsImpl(mlir::tensor::BitcastOp *this)
{
  if (!mlir::tensor::__mlir_ods_local_type_constraint_TensorOps0(*(void *)this, *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"operand", (void **)7, 0))return 0; {
  if (*(_DWORD *)(*(void *)this + 36))
  }
    uint64_t v2 = *(void *)this - 16;
  else {
    uint64_t v2 = 0;
  }
  uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v2, 0);
  return mlir::tensor::__mlir_ods_local_type_constraint_TensorOps0(*(void *)this, *(void *)(NextResultAtOffset + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"result", (void **)6, 0) != 0;
}

uint64_t mlir::tensor::__mlir_ods_local_type_constraint_TensorOps0(uint64_t a1, uint64_t a2, void **a3, void **a4, unsigned int a5)
{
  uint64_t v63 = *MEMORY[0x263EF8340];
  uint64_t v6 = *(void *)a2;
  uint64_t v7 = *(void **)(*(void *)a2 + 136);
  if (v7 == &mlir::detail::TypeIDResolver<mlir::RankedTensorType,void>::id
    || v7 == &mlir::detail::TypeIDResolver<mlir::UnrankedTensorType,void>::id)
  {
    v53[0] = a2;
    v53[1] = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(v6 + 8);
    mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)v53);
    return 1;
  }
  else
  {
    __int16 v49 = 261;
    v48[0] = a3;
    v48[1] = a4;
    mlir::Operation::emitOpError(a1, v48, (uint64_t)v53);
    if (v53[0])
    {
      int v50 = 3;
      long long v51 = " #";
      uint64_t v52 = 2;
      uint64_t v11 = &v50;
      uint64_t v12 = (char *)v54;
      if (v55 >= v56)
      {
        unint64_t v38 = v55 + 1;
        if (v54 <= &v50 && (char *)v54 + 24 * v55 > (char *)&v50)
        {
          int64_t v44 = (char *)&v50 - (unsigned char *)v54;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v54, v57, v38, 24);
          uint64_t v12 = (char *)v54;
          uint64_t v11 = (int *)((char *)v54 + v44);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v54, v57, v38, 24);
          uint64_t v11 = &v50;
          uint64_t v12 = (char *)v54;
        }
      }
      uint64_t v13 = &v12[24 * v55];
      long long v14 = *(_OWORD *)v11;
      *((void *)v13 + 2) = *((void *)v11 + 2);
      *(_OWORD *)uint64_t v13 = v14;
      uint64_t v15 = ++v55;
      if (v53[0])
      {
        int v50 = 5;
        long long v51 = (const char *)a5;
        uint64_t v16 = &v50;
        uint64_t v17 = (char *)v54;
        if (v15 >= v56)
        {
          unint64_t v39 = v15 + 1;
          BOOL v40 = (char *)v54 + 24 * v15 > (char *)&v50;
          if (v54 <= &v50 && v40)
          {
            int64_t v45 = (char *)&v50 - (unsigned char *)v54;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v54, v57, v39, 24);
            uint64_t v17 = (char *)v54;
            uint64_t v16 = (int *)((char *)v54 + v45);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v54, v57, v39, 24);
            uint64_t v16 = &v50;
            uint64_t v17 = (char *)v54;
          }
        }
        uint64_t v18 = &v17[24 * v55];
        long long v19 = *(_OWORD *)v16;
        *((void *)v18 + 2) = *((void *)v16 + 2);
        *(_OWORD *)uint64_t v18 = v19;
        uint64_t v20 = ++v55;
        if (v53[0])
        {
          int v50 = 3;
          long long v51 = " must be tensor of any type values, but got ";
          uint64_t v52 = 44;
          uint64_t v21 = &v50;
          uint64_t v22 = (char *)v54;
          if (v20 >= v56)
          {
            unint64_t v41 = v20 + 1;
            BOOL v42 = (char *)v54 + 24 * v20 > (char *)&v50;
            if (v54 <= &v50 && v42)
            {
              int64_t v46 = (char *)&v50 - (unsigned char *)v54;
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v54, v57, v41, 24);
              uint64_t v22 = (char *)v54;
              uint64_t v21 = (int *)((char *)v54 + v46);
            }
            else
            {
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v54, v57, v41, 24);
              uint64_t v21 = &v50;
              uint64_t v22 = (char *)v54;
            }
          }
          uint64_t v23 = &v22[24 * v55];
          long long v24 = *(_OWORD *)v21;
          *((void *)v23 + 2) = *((void *)v21 + 2);
          *(_OWORD *)uint64_t v23 = v24;
          ++v55;
          if (v53[0])
          {
            uint64_t v25 = &v50;
            mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v50, a2);
            uint64_t v26 = (char *)v54;
            if (v55 >= v56)
            {
              unint64_t v43 = v55 + 1;
              if (v54 <= &v50 && (char *)v54 + 24 * v55 > (char *)&v50)
              {
                int64_t v47 = (char *)&v50 - (unsigned char *)v54;
                llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v54, v57, v43, 24);
                uint64_t v26 = (char *)v54;
                uint64_t v25 = (int *)((char *)v54 + v47);
              }
              else
              {
                llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v54, v57, v43, 24);
                uint64_t v25 = &v50;
                uint64_t v26 = (char *)v54;
              }
            }
            uint64_t v27 = &v26[24 * v55];
            long long v28 = *(_OWORD *)v25;
            *((void *)v27 + 2) = *((void *)v25 + 2);
            *(_OWORD *)uint64_t v27 = v28;
            ++v55;
          }
        }
      }
    }
    uint64_t v9 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v53);
    if (v53[0]) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v53);
    }
    if (v62)
    {
      uint64_t v29 = __p;
      if (__p)
      {
        uint64_t v30 = v61;
        unint64_t v31 = __p;
        if (v61 != __p)
        {
          do
            uint64_t v30 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v30 - 1);
          while (v30 != v29);
          unint64_t v31 = __p;
        }
        uint64_t v61 = v29;
        operator delete(v31);
      }
      uint64_t v32 = v58;
      if (v58)
      {
        uint64_t v33 = v59;
        int v34 = v58;
        if (v59 != v58)
        {
          do
          {
            uint64_t v36 = *--v33;
            uint64_t v35 = v36;
            *uint64_t v33 = 0;
            if (v36) {
              MEMORY[0x21667D390](v35, 0x1000C8077774924);
            }
          }
          while (v33 != v32);
          int v34 = v58;
        }
        BOOL v59 = v32;
        operator delete(v34);
      }
      if (v54 != v57) {
        free(v54);
      }
    }
  }
  return v9;
}

BOOL mlir::tensor::BitcastOp::parse(uint64_t a1, uint64_t a2)
{
  uint64_t v13 = *MEMORY[0x263EF8340];
  memset(v10, 0, 24);
  v8[0] = (uint64_t)v10;
  v8[1] = 1;
  uint64_t v9 = 0;
  v7[0] = &v9;
  v7[1] = 1;
  uint64_t v4 = (*(uint64_t (**)(uint64_t))(*(void *)a1 + 40))(a1);
  if (!(*(unsigned __int8 (**)(uint64_t, void *, uint64_t))(*(void *)a1 + 672))(a1, v10, 1)) {
    return 0;
  }
  (*(void (**)(uint64_t))(*(void *)a1 + 40))(a1);
  if (!(*(unsigned __int8 (**)(uint64_t, uint64_t))(*(void *)a1 + 456))(a1, a2 + 112)) {
    return 0;
  }
  if (!(*(unsigned __int8 (**)(uint64_t))(*(void *)a1 + 104))(a1)) {
    return 0;
  }
  __src[0] = 0;
  if (!mlir::AsmParser::parseType<mlir::TensorType>(a1, __src)) {
    return 0;
  }
  uint64_t v9 = __src[0];
  __int16 v12 = 257;
  if (!(*(unsigned __int8 (**)(uint64_t, const char *, uint64_t, void *))(*(void *)a1 + 368))(a1, "to", 2, __src))return 0; {
  uint64_t v6 = 0;
  }
  if (!mlir::AsmParser::parseType<mlir::TensorType>(a1, &v6)) {
    return 0;
  }
  __src[0] = v6;
  mlir::OperationState::addTypes(a2, __src, 1);
  return mlir::OpAsmParser::resolveOperands<llvm::ArrayRef<mlir::OpAsmParser::UnresolvedOperand> &,llvm::ArrayRef<mlir::Type> &>(a1, v8, v7, v4, a2 + 16) != 0;
}

BOOL mlir::tensor::CastOp::parse(uint64_t a1, uint64_t a2)
{
  uint64_t v13 = *MEMORY[0x263EF8340];
  memset(v10, 0, 24);
  v8[0] = (uint64_t)v10;
  v8[1] = 1;
  uint64_t v9 = 0;
  v7[0] = &v9;
  v7[1] = 1;
  uint64_t v4 = (*(uint64_t (**)(uint64_t))(*(void *)a1 + 40))(a1);
  if (!(*(unsigned __int8 (**)(uint64_t, void *, uint64_t))(*(void *)a1 + 672))(a1, v10, 1)) {
    return 0;
  }
  (*(void (**)(uint64_t))(*(void *)a1 + 40))(a1);
  if (!(*(unsigned __int8 (**)(uint64_t, uint64_t))(*(void *)a1 + 456))(a1, a2 + 112)) {
    return 0;
  }
  if (!(*(unsigned __int8 (**)(uint64_t))(*(void *)a1 + 104))(a1)) {
    return 0;
  }
  __src[0] = 0;
  if (!mlir::AsmParser::parseType<mlir::TensorType>(a1, __src)) {
    return 0;
  }
  uint64_t v9 = __src[0];
  __int16 v12 = 257;
  if (!(*(unsigned __int8 (**)(uint64_t, const char *, uint64_t, void *))(*(void *)a1 + 368))(a1, "to", 2, __src))return 0; {
  uint64_t v6 = 0;
  }
  if (!mlir::AsmParser::parseType<mlir::TensorType>(a1, &v6)) {
    return 0;
  }
  __src[0] = v6;
  mlir::OperationState::addTypes(a2, __src, 1);
  return mlir::OpAsmParser::resolveOperands<llvm::ArrayRef<mlir::OpAsmParser::UnresolvedOperand> &,llvm::ArrayRef<mlir::Type> &>(a1, v8, v7, v4, a2 + 16) != 0;
}

uint64_t mlir::tensor::detail::CollapseShapeOpGenericAdaptorBase::CollapseShapeOpGenericAdaptorBase(uint64_t a1, uint64_t a2)
{
  uint64_t v11 = *MEMORY[0x263EF8340];
  uint64_t v3 = *(void *)(a2 + 56);
  unint64_t v4 = *(unsigned int *)(a2 + 44);
  uint64_t v5 = (void *)(a2 + 16 * ((v4 >> 23) & 1) + 64);
  unint64_t v6 = v4 & 0x7FFFFF;
  if ((v4 & 0x7FFFFF) != 0)
  {
    uint64_t v7 = (((unint64_t)v5 + ((v4 >> 21) & 0x7F8) + 7) & 0xFFFFFFFFFFFFFFF8) + 32 * *(unsigned int *)(a2 + 40);
  }
  else
  {
    uint64_t v7 = 0;
    unint64_t v6 = 0;
  }
  mlir::ValueRange::ValueRange(v10, v7, v6);
  *(unsigned char *)(a1 + 8) = 0;
  *(void *)a1 = v3;
  *(unsigned char *)(a1 + 16) = 0;
  *(void *)(a1 + 24) = *v5;
  *(_OWORD *)(a1 + 32) = *(_OWORD *)v10;
  if (v3)
  {
    uint64_t Context = mlir::Attribute::getContext((mlir::Attribute *)a1);
    if (*(unsigned char *)(a1 + 16)) {
      *(unsigned char *)(a1 + 16) = 0;
    }
    mlir::OperationName::OperationName(a1 + 8, "tensor.collapse_shape", 21, Context);
    *(unsigned char *)(a1 + 16) = 1;
  }
  return a1;
}

BOOL mlir::tensor::CollapseShapeOp::readProperties(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = (uint64_t *)mlir::OperationState::getOrAddProperties<mlir::tensor::detail::CollapseShapeOpGenericAdaptorBase::Properties>(a2);
  return mlir::DialectBytecodeReader::readAttribute<mlir::ArrayAttr>(a1, v3) != 0;
}

uint64_t mlir::OperationState::getOrAddProperties<mlir::tensor::detail::CollapseShapeOpGenericAdaptorBase::Properties>(uint64_t a1)
{
  uint64_t result = *(void *)(a1 + 256);
  if (!result) {
    operator new();
  }
  return result;
}

BOOL mlir::tensor::CollapseShapeOp::verifyInvariantsImpl(mlir::tensor::CollapseShapeOp *this)
{
  uint64_t v26 = *MEMORY[0x263EF8340];
  uint64_t v2 = *(void *)this;
  uint64_t v3 = *(void *)(*(void *)this + 16 * (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 23) & 1) + 64);
  if (v3)
  {
    v18[0] = v2;
    if (mlir::memref::__mlir_ods_local_attr_constraint_MemRefOps4(v3, (void **)"reassociation", (const char *)0xD, (void (*)(uint64_t *__return_ptr, uint64_t))llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::__mlir_ods_local_attr_constraint_TensorOps0(mlir::Operation *,mlir::Attribute,llvm::StringRef)::$_0>, (uint64_t)v18)&& mlir::tensor::__mlir_ods_local_type_constraint_TensorOps1(*(void *)this, *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"operand", (void **)7, 0))
    {
      if (*(_DWORD *)(*(void *)this + 36)) {
        uint64_t v4 = *(void *)this - 16;
      }
      else {
        uint64_t v4 = 0;
      }
      uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v4, 0);
      return mlir::tensor::__mlir_ods_local_type_constraint_TensorOps1(*(void *)this, *(void *)(NextResultAtOffset + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"result", (void **)6, 0) != 0;
    }
    else
    {
      return 0;
    }
  }
  else
  {
    uint64_t v16 = (void **)"requires attribute 'reassociation'";
    __int16 v17 = 259;
    mlir::OpState::emitOpError((uint64_t *)this, &v16, (uint64_t)v18);
    uint64_t v6 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v18);
    if (v18[0]) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v18);
    }
    if (v25)
    {
      uint64_t v7 = __p;
      if (__p)
      {
        uint64_t v8 = v24;
        uint64_t v9 = __p;
        if (v24 != __p)
        {
          do
            uint64_t v8 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v8 - 1);
          while (v8 != v7);
          uint64_t v9 = __p;
        }
        long long v24 = v7;
        operator delete(v9);
      }
      uint64_t v10 = v21;
      if (v21)
      {
        uint64_t v11 = v22;
        __int16 v12 = v21;
        if (v22 != v21)
        {
          do
          {
            uint64_t v14 = *--v11;
            uint64_t v13 = v14;
            *uint64_t v11 = 0;
            if (v14) {
              MEMORY[0x21667D390](v13, 0x1000C8077774924);
            }
          }
          while (v11 != v10);
          __int16 v12 = v21;
        }
        uint64_t v22 = v10;
        operator delete(v12);
      }
      if (v19 != &v20) {
        free(v19);
      }
    }
  }
  return v6;
}

uint64_t mlir::tensor::__mlir_ods_local_type_constraint_TensorOps1(uint64_t a1, uint64_t a2, void **a3, void **a4, unsigned int a5)
{
  uint64_t v61 = *MEMORY[0x263EF8340];
  uint64_t v6 = *(void *)a2;
  if (*(_UNKNOWN **)(*(void *)a2 + 136) == &mlir::detail::TypeIDResolver<mlir::RankedTensorType,void>::id)
  {
    v51[0] = a2;
    v51[1] = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(v6 + 8);
    mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)v51);
    return 1;
  }
  else
  {
    __int16 v47 = 261;
    v46[0] = a3;
    v46[1] = a4;
    mlir::Operation::emitOpError(a1, v46, (uint64_t)v51);
    if (v51[0])
    {
      int v48 = 3;
      __int16 v49 = " #";
      uint64_t v50 = 2;
      uint64_t v8 = &v48;
      uint64_t v9 = (char *)v52;
      if (v53 >= v54)
      {
        unint64_t v36 = v53 + 1;
        if (v52 <= &v48 && (char *)v52 + 24 * v53 > (char *)&v48)
        {
          int64_t v42 = (char *)&v48 - (unsigned char *)v52;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v52, v55, v36, 24);
          uint64_t v9 = (char *)v52;
          uint64_t v8 = (int *)((char *)v52 + v42);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v52, v55, v36, 24);
          uint64_t v8 = &v48;
          uint64_t v9 = (char *)v52;
        }
      }
      uint64_t v10 = &v9[24 * v53];
      long long v11 = *(_OWORD *)v8;
      *((void *)v10 + 2) = *((void *)v8 + 2);
      *(_OWORD *)uint64_t v10 = v11;
      uint64_t v12 = ++v53;
      if (v51[0])
      {
        int v48 = 5;
        __int16 v49 = (const char *)a5;
        uint64_t v13 = &v48;
        uint64_t v14 = (char *)v52;
        if (v12 >= v54)
        {
          unint64_t v37 = v12 + 1;
          BOOL v38 = (char *)v52 + 24 * v12 > (char *)&v48;
          if (v52 <= &v48 && v38)
          {
            int64_t v43 = (char *)&v48 - (unsigned char *)v52;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v52, v55, v37, 24);
            uint64_t v14 = (char *)v52;
            uint64_t v13 = (int *)((char *)v52 + v43);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v52, v55, v37, 24);
            uint64_t v13 = &v48;
            uint64_t v14 = (char *)v52;
          }
        }
        uint64_t v15 = &v14[24 * v53];
        long long v16 = *(_OWORD *)v13;
        *((void *)v15 + 2) = *((void *)v13 + 2);
        *(_OWORD *)uint64_t v15 = v16;
        uint64_t v17 = ++v53;
        if (v51[0])
        {
          int v48 = 3;
          __int16 v49 = " must be ranked tensor of any type values, but got ";
          uint64_t v50 = 51;
          uint64_t v18 = &v48;
          long long v19 = (char *)v52;
          if (v17 >= v54)
          {
            unint64_t v39 = v17 + 1;
            BOOL v40 = (char *)v52 + 24 * v17 > (char *)&v48;
            if (v52 <= &v48 && v40)
            {
              int64_t v44 = (char *)&v48 - (unsigned char *)v52;
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v52, v55, v39, 24);
              long long v19 = (char *)v52;
              uint64_t v18 = (int *)((char *)v52 + v44);
            }
            else
            {
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v52, v55, v39, 24);
              uint64_t v18 = &v48;
              long long v19 = (char *)v52;
            }
          }
          uint64_t v20 = &v19[24 * v53];
          long long v21 = *(_OWORD *)v18;
          *((void *)v20 + 2) = *((void *)v18 + 2);
          *(_OWORD *)uint64_t v20 = v21;
          ++v53;
          if (v51[0])
          {
            uint64_t v22 = &v48;
            mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v48, a2);
            uint64_t v23 = (char *)v52;
            if (v53 >= v54)
            {
              unint64_t v41 = v53 + 1;
              if (v52 <= &v48 && (char *)v52 + 24 * v53 > (char *)&v48)
              {
                int64_t v45 = (char *)&v48 - (unsigned char *)v52;
                llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v52, v55, v41, 24);
                uint64_t v23 = (char *)v52;
                uint64_t v22 = (int *)((char *)v52 + v45);
              }
              else
              {
                llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v52, v55, v41, 24);
                uint64_t v22 = &v48;
                uint64_t v23 = (char *)v52;
              }
            }
            long long v24 = &v23[24 * v53];
            long long v25 = *(_OWORD *)v22;
            *((void *)v24 + 2) = *((void *)v22 + 2);
            *(_OWORD *)long long v24 = v25;
            ++v53;
          }
        }
      }
    }
    uint64_t v26 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v51);
    if (v51[0]) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v51);
    }
    if (v60)
    {
      uint64_t v27 = __p;
      if (__p)
      {
        long long v28 = v59;
        uint64_t v29 = __p;
        if (v59 != __p)
        {
          do
            long long v28 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v28 - 1);
          while (v28 != v27);
          uint64_t v29 = __p;
        }
        BOOL v59 = v27;
        operator delete(v29);
      }
      uint64_t v30 = v56;
      if (v56)
      {
        unint64_t v31 = v57;
        uint64_t v32 = v56;
        if (v57 != v56)
        {
          do
          {
            uint64_t v34 = *--v31;
            uint64_t v33 = v34;
            void *v31 = 0;
            if (v34) {
              MEMORY[0x21667D390](v33, 0x1000C8077774924);
            }
          }
          while (v31 != v30);
          uint64_t v32 = v56;
        }
        unint64_t v57 = v30;
        operator delete(v32);
      }
      if (v52 != v55) {
        free(v52);
      }
    }
  }
  return v26;
}

BOOL mlir::tensor::CollapseShapeOp::parse(uint64_t a1, uint64_t a2)
{
  uint64_t v20 = *MEMORY[0x263EF8340];
  memset(v17, 0, 24);
  v15[0] = (uint64_t)v17;
  v15[1] = 1;
  v13[1] = 1;
  uint64_t v14 = 0;
  uint64_t v16 = 0;
  v13[0] = &v16;
  uint64_t v4 = (*(uint64_t (**)(uint64_t))(*(void *)a1 + 40))(a1);
  if (!(*(unsigned __int8 (**)(uint64_t, void *, uint64_t))(*(void *)a1 + 672))(a1, v17, 1)) {
    return 0;
  }
  uint64_t v5 = (mlir::NoneType **)(*(uint64_t (**)(uint64_t))(*(void *)a1 + 32))(a1);
  uint64_t v7 = mlir::NoneType::get(*v5, v6);
  if (!mlir::AsmParser::parseAttribute<mlir::ArrayAttr>(a1, &v14, v7)) {
    return 0;
  }
  if (v14)
  {
    uint64_t v8 = (void *)mlir::OperationState::getOrAddProperties<mlir::tensor::detail::CollapseShapeOpGenericAdaptorBase::Properties>(a2);
    *uint64_t v8 = v14;
  }
  uint64_t v12 = (*(uint64_t (**)(uint64_t))(*(void *)a1 + 40))(a1);
  if (!(*(unsigned __int8 (**)(uint64_t, uint64_t))(*(void *)a1 + 456))(a1, a2 + 112)) {
    return 0;
  }
  uint64_t v9 = *(void *)(a2 + 8);
  __src[0] = a1;
  __src[1] = &v12;
  __src[2] = a2;
  uint64_t v10 = mlir::NamedAttrList::get(a2 + 112, **(void **)(v9 + 96));
  if (v10)
  {
    if (!mlir::memref::__mlir_ods_local_attr_constraint_MemRefOps4(v10, (void **)"reassociation", (const char *)0xD, (void (*)(uint64_t *__return_ptr, uint64_t))llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::CollapseShapeOp::parse(mlir::OpAsmParser &,mlir::OperationState &)::$_0>, (uint64_t)__src))return 0; {
  }
    }
  if (!(*(unsigned __int8 (**)(uint64_t))(*(void *)a1 + 104))(a1)) {
    return 0;
  }
  __src[0] = 0;
  if (!mlir::AsmParser::parseType<mlir::RankedTensorType>(a1, __src)) {
    return 0;
  }
  uint64_t v16 = __src[0];
  __int16 v19 = 257;
  if (!(*(unsigned __int8 (**)(uint64_t, const char *, uint64_t, void *))(*(void *)a1 + 368))(a1, "into", 4, __src))return 0; {
  uint64_t v12 = 0;
  }
  if (!mlir::AsmParser::parseType<mlir::RankedTensorType>(a1, &v12)) {
    return 0;
  }
  __src[0] = v12;
  mlir::OperationState::addTypes(a2, __src, 1);
  return mlir::OpAsmParser::resolveOperands<llvm::ArrayRef<mlir::OpAsmParser::UnresolvedOperand> &,llvm::ArrayRef<mlir::Type> &>(a1, v15, v13, v4, a2 + 16) != 0;
}

uint64_t mlir::tensor::detail::DimOpGenericAdaptorBase::DimOpGenericAdaptorBase(uint64_t a1, unsigned int *a2)
{
  uint64_t v11 = *MEMORY[0x263EF8340];
  unint64_t AttrDictionary = mlir::Operation::getAttrDictionary((mlir::Operation *)a2);
  unint64_t v5 = a2[11];
  unint64_t v6 = v5 & 0x7FFFFF;
  if ((v5 & 0x7FFFFF) != 0)
  {
    uint64_t v7 = (((unint64_t)&a2[4 * ((v5 >> 23) & 1) + 17] + ((v5 >> 21) & 0x7F8) + 3) & 0xFFFFFFFFFFFFFFF8)
       + 32 * a2[10];
  }
  else
  {
    uint64_t v7 = 0;
    unint64_t v6 = 0;
  }
  mlir::ValueRange::ValueRange(v10, v7, v6);
  *(void *)a1 = AttrDictionary;
  *(unsigned char *)(a1 + 8) = 0;
  *(unsigned char *)(a1 + 16) = 0;
  *(_OWORD *)(a1 + 24) = *(_OWORD *)v10;
  if (AttrDictionary)
  {
    uint64_t Context = mlir::Attribute::getContext((mlir::Attribute *)a1);
    if (*(unsigned char *)(a1 + 16)) {
      *(unsigned char *)(a1 + 16) = 0;
    }
    mlir::OperationName::OperationName(a1 + 8, "tensor.dim", 10, Context);
    *(unsigned char *)(a1 + 16) = 1;
  }
  return a1;
}

uint64_t mlir::tensor::DimOp::getSourceMutable(mlir::tensor::DimOp *this)
{
  return *(void *)(*(void *)this + 72);
}

BOOL mlir::tensor::DimOp::verifyInvariantsImpl(mlir::tensor::DimOp *this)
{
  uint64_t v67 = *MEMORY[0x263EF8340];
  uint64_t v2 = *(void *)this;
  unint64_t v3 = *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8;
  uint64_t v4 = *(void *)v3;
  unint64_t v5 = *(void **)(*(void *)v3 + 136);
  if (v5 == &mlir::detail::TypeIDResolver<mlir::UnrankedTensorType,void>::id)
  {
    uint64_t v8 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(v4 + 8);
    v57[0] = v3;
    uint64_t v9 = (mlir::MemoryMapperInterface *)v57;
    goto LABEL_30;
  }
  if (v5 == &mlir::detail::TypeIDResolver<mlir::RankedTensorType,void>::id)
  {
    uint64_t v50 = (void **)(*(void *)(*(void *)(*(void *)(*(void *)this + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8);
    uint64_t v51 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(v4 + 8);
    if (mlir::CallOpInterface::getArgOperands((mlir::CallOpInterface *)&v50))
    {
      uint64_t v6 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*(void *)v3 + 8);
      unint64_t v54 = v3;
      unsigned int v55 = (const char *)v6;
      mlir::ShapedType::getShape((mlir::ShapedType *)&v54);
      if (v7 >= 1)
      {
        uint64_t v8 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*(void *)v3 + 8);
        unint64_t v53 = v3;
        uint64_t v9 = (mlir::MemoryMapperInterface *)&v53;
LABEL_30:
        *((void *)v9 + 1) = v8;
        mlir::MemoryMapperInterface::getOperandRange(v9);
        goto LABEL_36;
      }
    }
  }
  __int16 v52 = 261;
  uint64_t v50 = (void **)"operand";
  uint64_t v51 = 7;
  mlir::Operation::emitOpError(v2, &v50, (uint64_t)v57);
  if (v57[0])
  {
    LODWORD(v54) = 3;
    unsigned int v55 = " #";
    uint64_t v56 = 2;
    uint64_t v10 = &v54;
    uint64_t v11 = (char *)v58;
    if (v59 >= v60)
    {
      unint64_t v40 = v59 + 1;
      if (v58 <= &v54 && (char *)v58 + 24 * v59 > (char *)&v54)
      {
        int64_t v46 = (char *)&v54 - (unsigned char *)v58;
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v58, v61, v40, 24);
        uint64_t v11 = (char *)v58;
        uint64_t v10 = (unint64_t *)((char *)v58 + v46);
      }
      else
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v58, v61, v40, 24);
        uint64_t v10 = &v54;
        uint64_t v11 = (char *)v58;
      }
    }
    uint64_t v12 = &v11[24 * v59];
    long long v13 = *(_OWORD *)v10;
    *((void *)v12 + 2) = v10[2];
    *(_OWORD *)uint64_t v12 = v13;
    uint64_t v14 = ++v59;
    if (v57[0])
    {
      LODWORD(v54) = 5;
      unsigned int v55 = 0;
      uint64_t v15 = &v54;
      uint64_t v16 = (char *)v58;
      if (v14 >= v60)
      {
        unint64_t v41 = v14 + 1;
        BOOL v42 = (char *)v58 + 24 * v14 > (char *)&v54;
        if (v58 <= &v54 && v42)
        {
          int64_t v47 = (char *)&v54 - (unsigned char *)v58;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v58, v61, v41, 24);
          uint64_t v16 = (char *)v58;
          uint64_t v15 = (unint64_t *)((char *)v58 + v47);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v58, v61, v41, 24);
          uint64_t v15 = &v54;
          uint64_t v16 = (char *)v58;
        }
      }
      uint64_t v17 = &v16[24 * v59];
      long long v18 = *(_OWORD *)v15;
      *((void *)v17 + 2) = v15[2];
      *(_OWORD *)uint64_t v17 = v18;
      uint64_t v19 = ++v59;
      if (v57[0])
      {
        LODWORD(v54) = 3;
        unsigned int v55 = " must be non-0-ranked or unranked tensor, but got ";
        uint64_t v56 = 50;
        uint64_t v20 = &v54;
        long long v21 = (char *)v58;
        if (v19 >= v60)
        {
          unint64_t v43 = v19 + 1;
          BOOL v44 = (char *)v58 + 24 * v19 > (char *)&v54;
          if (v58 <= &v54 && v44)
          {
            int64_t v48 = (char *)&v54 - (unsigned char *)v58;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v58, v61, v43, 24);
            long long v21 = (char *)v58;
            uint64_t v20 = (unint64_t *)((char *)v58 + v48);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v58, v61, v43, 24);
            uint64_t v20 = &v54;
            long long v21 = (char *)v58;
          }
        }
        uint64_t v22 = &v21[24 * v59];
        long long v23 = *(_OWORD *)v20;
        *((void *)v22 + 2) = v20[2];
        *(_OWORD *)uint64_t v22 = v23;
        ++v59;
        if (v57[0])
        {
          long long v24 = &v54;
          mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v54, v3);
          long long v25 = (char *)v58;
          if (v59 >= v60)
          {
            unint64_t v45 = v59 + 1;
            if (v58 <= &v54 && (char *)v58 + 24 * v59 > (char *)&v54)
            {
              int64_t v49 = (char *)&v54 - (unsigned char *)v58;
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v58, v61, v45, 24);
              long long v25 = (char *)v58;
              long long v24 = (unint64_t *)((char *)v58 + v49);
            }
            else
            {
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v58, v61, v45, 24);
              long long v24 = &v54;
              long long v25 = (char *)v58;
            }
          }
          uint64_t v26 = &v25[24 * v59];
          long long v27 = *(_OWORD *)v24;
          *((void *)v26 + 2) = v24[2];
          *(_OWORD *)uint64_t v26 = v27;
          ++v59;
        }
      }
    }
  }
  char v28 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v57);
  if (v57[0]) {
    mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v57);
  }
  if (v66)
  {
    uint64_t v29 = __p;
    if (__p)
    {
      uint64_t v30 = v65;
      unint64_t v31 = __p;
      if (v65 != __p)
      {
        do
          uint64_t v30 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v30 - 1);
        while (v30 != v29);
        unint64_t v31 = __p;
      }
      uint64_t v65 = v29;
      operator delete(v31);
    }
    uint64_t v32 = v62;
    if (v62)
    {
      uint64_t v33 = v63;
      uint64_t v34 = v62;
      if (v63 != v62)
      {
        do
        {
          uint64_t v36 = *--v33;
          uint64_t v35 = v36;
          *uint64_t v33 = 0;
          if (v36) {
            MEMORY[0x21667D390](v35, 0x1000C8077774924);
          }
        }
        while (v33 != v32);
        uint64_t v34 = v62;
      }
      uint64_t v63 = v32;
      operator delete(v34);
    }
    if (v58 != v61) {
      free(v58);
    }
  }
  if (!v28) {
    return 0;
  }
LABEL_36:
  if (!mlir::memref::__mlir_ods_local_type_constraint_MemRefOps9(*(void *)this, *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 56) + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"operand", (void **)7, 1u))return 0; {
  if (*(_DWORD *)(*(void *)this + 36))
  }
    uint64_t v37 = *(void *)this - 16;
  else {
    uint64_t v37 = 0;
  }
  uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v37, 0);
  return mlir::memref::__mlir_ods_local_type_constraint_MemRefOps9(*(void *)this, *(void *)(NextResultAtOffset + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"result", (void **)6, 0) != 0;
}

BOOL mlir::tensor::DimOp::parse(uint64_t a1, uint64_t a2)
{
  v14[4] = *MEMORY[0x263EF8340];
  memset(v14, 0, 24);
  v11[0] = (uint64_t)v14;
  v11[1] = 1;
  memset(v13, 0, 24);
  uint64_t v12 = 0;
  v10[0] = &v12;
  v10[1] = 1;
  (*(void (**)(uint64_t))(*(void *)a1 + 40))(a1);
  if (!(*(unsigned __int8 (**)(uint64_t, uint64_t))(*(void *)a1 + 456))(a1, a2 + 112)) {
    return 0;
  }
  uint64_t v4 = (*(uint64_t (**)(uint64_t))(*(void *)a1 + 40))(a1);
  if (!(*(unsigned __int8 (**)(uint64_t, void *, uint64_t))(*(void *)a1 + 672))(a1, v14, 1)) {
    return 0;
  }
  if ((*(unsigned __int8 (**)(uint64_t))(*(void *)a1 + 120))(a1)
    && ((*(void (**)(uint64_t))(*(void *)a1 + 40))(a1),
        (*(unsigned __int8 (**)(uint64_t, void *, uint64_t))(*(void *)a1 + 672))(a1, v13, 1))
    && (*(unsigned __int8 (**)(uint64_t))(*(void *)a1 + 104))(a1)
    && (uint64_t __src = 0, mlir::AsmParser::parseType<mlir::TensorType>(a1, &__src))
    && (uint64_t v12 = __src,
        unint64_t v5 = (mlir::IndexType **)(*(uint64_t (**)(uint64_t))(*(void *)a1 + 32))(a1),
        uint64_t __src = mlir::Builder::getIndexType(v5, v6),
        mlir::OperationState::addTypes(a2, &__src, 1),
        uint64_t v7 = a2 + 16,
        mlir::OpAsmParser::resolveOperands<llvm::ArrayRef<mlir::OpAsmParser::UnresolvedOperand> &,llvm::ArrayRef<mlir::Type> &>(a1, v11, v10, v4, v7)))
  {
    return (*(unsigned __int8 (**)(uint64_t, void *, uint64_t, uint64_t))(*(void *)a1 + 696))(a1, v13, __src, v7) != 0;
  }
  else
  {
    return 0;
  }
}

BOOL mlir::tensor::EmptyOp::verifyInvariantsImpl(mlir::tensor::EmptyOp *this)
{
  uint64_t v2 = *(void *)this;
  if ((*(unsigned char *)(*(void *)this + 46) & 0x80) != 0 && (uint64_t v3 = *(unsigned int *)(v2 + 68), v3))
  {
    uint64_t v4 = 0;
    uint64_t v5 = *(void *)(v2 + 72) + 24;
    while (mlir::memref::__mlir_ods_local_type_constraint_MemRefOps3(*(void *)this, *(void *)(*(void *)v5 + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"operand", (void **)7, v4))
    {
      ++v4;
      v5 += 32;
      if (v3 == v4)
      {
        uint64_t v2 = *(void *)this;
        goto LABEL_7;
      }
    }
    return 0;
  }
  else
  {
LABEL_7:
    int v6 = *(_DWORD *)(v2 + 36);
    uint64_t v7 = v2 - 16;
    if (v6) {
      uint64_t v8 = v7;
    }
    else {
      uint64_t v8 = 0;
    }
    uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v8, 0);
    return mlir::tensor::__mlir_ods_local_type_constraint_TensorOps1(*(void *)this, *(void *)(NextResultAtOffset + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"result", (void **)6, 0) != 0;
  }
}

uint64_t mlir::tensor::EmptyOp::parse(uint64_t a1, uint64_t a2)
{
  v16[16] = *MEMORY[0x263EF8340];
  uint64_t v14 = v16;
  uint64_t v15 = 0x400000000;
  if ((*(unsigned __int8 (**)(void))(*(void *)a1 + 264))())
  {
    (*(void (**)(uint64_t))(*(void *)a1 + 40))(a1);
    if ((*(unsigned __int8 (**)(uint64_t, void **, void, uint64_t, uint64_t))(*(void *)a1 + 688))(a1, &v14, 0, 1, 0xFFFFFFFFLL))
    {
      if ((*(unsigned __int8 (**)(uint64_t))(*(void *)a1 + 280))(a1))
      {
        (*(void (**)(uint64_t))(*(void *)a1 + 40))(a1);
        if ((*(unsigned __int8 (**)(uint64_t, uint64_t))(*(void *)a1 + 456))(a1, a2 + 112))
        {
          if ((*(unsigned __int8 (**)(uint64_t))(*(void *)a1 + 104))(a1))
          {
            uint64_t v12 = 0;
            if (mlir::AsmParser::parseType<mlir::RankedTensorType>(a1, &v12))
            {
              uint64_t __src = v12;
              uint64_t v4 = (mlir::IndexType **)(*(uint64_t (**)(uint64_t))(*(void *)a1 + 32))(a1);
              uint64_t IndexType = mlir::Builder::getIndexType(v4, v5);
              uint64_t v7 = 1;
              mlir::OperationState::addTypes(a2, &__src, 1);
              if (!v15) {
                goto LABEL_13;
              }
              uint64_t v8 = a2 + 16;
              uint64_t v9 = (char *)v14;
              uint64_t v10 = 32 * v15;
              while ((*(unsigned __int8 (**)(uint64_t, char *, uint64_t, uint64_t))(*(void *)a1 + 696))(a1, v9, IndexType, v8))
              {
                v9 += 32;
                uint64_t v7 = 1;
                v10 -= 32;
                if (!v10) {
                  goto LABEL_13;
                }
              }
            }
          }
        }
      }
    }
  }
  uint64_t v7 = 0;
LABEL_13:
  if (v14 != v16) {
    free(v14);
  }
  return v7;
}

void mlir::tensor::EmptyOp::print(mlir::Operation **this, mlir::OpAsmPrinter *a2)
{
  void v27[4] = *MEMORY[0x263EF8340];
  uint64_t v4 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v5 = (unsigned char *)*((void *)v4 + 4);
  if (*((unsigned char **)v4 + 3) == v5)
  {
    llvm::raw_ostream::write(v4, "(", 1uLL);
    int v6 = *this;
    if ((*((unsigned char *)*this + 46) & 0x80) != 0) {
      goto LABEL_3;
    }
  }
  else
  {
    unsigned char *v5 = 40;
    ++*((void *)v4 + 4);
    int v6 = *this;
    if ((*((unsigned char *)*this + 46) & 0x80) != 0)
    {
LABEL_3:
      uint64_t v7 = *((unsigned int *)v6 + 17);
      uint64_t v8 = *((void *)v6 + 9);
      goto LABEL_4;
    }
  }
  uint64_t v8 = 0;
  uint64_t v7 = 0;
LABEL_4:
  uint64_t v9 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  long long v25 = ", ";
  uint64_t v26 = 2;
  llvm::interleave<llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator,void mlir::OpAsmPrinter::printOperands<llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator>(llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator,llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator)::{lambda(mlir::Value)#1},void llvm::interleave<llvm::iterator_range<llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator>,void mlir::OpAsmPrinter::printOperands<llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator>(llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator,llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator)::{lambda(mlir::Value)#1},llvm::raw_ostream,mlir::Value>(llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator const&,llvm::raw_ostream &,void mlir::OpAsmPrinter::printOperands<llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator>(llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator,llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator)::{lambda(mlir::Value)#1},llvm::StringRef const&)::{lambda(void)#1},void>(v8, 0, v8, v7, (uint64_t)a2, v9, (uint64_t)&v25);
  uint64_t v10 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v11 = (unsigned char *)*((void *)v10 + 4);
  if (*((unsigned char **)v10 + 3) == v11)
  {
    llvm::raw_ostream::write(v10, ")", 1uLL);
  }
  else
  {
    *uint64_t v11 = 41;
    ++*((void *)v10 + 4);
  }
  long long v25 = v27;
  uint64_t v26 = 0x200000000;
  uint64_t v12 = *this;
  if (*((unsigned char *)*this + 47))
  {
    unint64_t AttrDictionary = mlir::Operation::getAttrDictionary(v12);
    p_unint64_t AttrDictionary = (mlir::ArrayAttr *)&AttrDictionary;
  }
  else
  {
    p_unint64_t AttrDictionary = (mlir::Operation *)((char *)v12 + 56);
  }
  uint64_t Value = mlir::ArrayAttr::getValue(p_AttrDictionary);
  (*(void (**)(mlir::OpAsmPrinter *, uint64_t, uint64_t, void *, void))(*(void *)a2 + 192))(a2, Value, v15, v25, v26);
  uint64_t v16 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v17 = (unsigned char *)*((void *)v16 + 4);
  if ((unint64_t)v17 >= *((void *)v16 + 3))
  {
    llvm::raw_ostream::write(v16, 32);
  }
  else
  {
    *((void *)v16 + 4) = v17 + 1;
    *uint64_t v17 = 32;
  }
  long long v18 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v19 = (unsigned char *)*((void *)v18 + 4);
  if (*((unsigned char **)v18 + 3) == v19)
  {
    llvm::raw_ostream::write(v18, ":", 1uLL);
  }
  else
  {
    *uint64_t v19 = 58;
    ++*((void *)v18 + 4);
  }
  uint64_t v20 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  long long v21 = (unsigned char *)*((void *)v20 + 4);
  if ((unint64_t)v21 >= *((void *)v20 + 3))
  {
    llvm::raw_ostream::write(v20, 32);
  }
  else
  {
    *((void *)v20 + 4) = v21 + 1;
    *long long v21 = 32;
  }
  if (*((_DWORD *)*this + 9)) {
    uint64_t v22 = (uint64_t)*this - 16;
  }
  else {
    uint64_t v22 = 0;
  }
  uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v22, 0);
  (*(void (**)(mlir::OpAsmPrinter *, unint64_t))(*(void *)a2 + 32))(a2, *(void *)(NextResultAtOffset + 8) & 0xFFFFFFFFFFFFFFF8);
  if (v25 != v27) {
    free(v25);
  }
}

uint64_t mlir::tensor::detail::ExpandShapeOpGenericAdaptorBase::ExpandShapeOpGenericAdaptorBase(uint64_t a1, uint64_t a2)
{
  uint64_t v11 = *MEMORY[0x263EF8340];
  uint64_t v3 = *(void *)(a2 + 56);
  unint64_t v4 = *(unsigned int *)(a2 + 44);
  uint64_t v5 = (void *)(a2 + 16 * ((v4 >> 23) & 1) + 64);
  unint64_t v6 = v4 & 0x7FFFFF;
  if ((v4 & 0x7FFFFF) != 0)
  {
    uint64_t v7 = (((unint64_t)v5 + ((v4 >> 21) & 0x7F8) + 7) & 0xFFFFFFFFFFFFFFF8) + 32 * *(unsigned int *)(a2 + 40);
  }
  else
  {
    uint64_t v7 = 0;
    unint64_t v6 = 0;
  }
  mlir::ValueRange::ValueRange(v10, v7, v6);
  *(unsigned char *)(a1 + 8) = 0;
  *(void *)a1 = v3;
  *(unsigned char *)(a1 + 16) = 0;
  *(void *)(a1 + 24) = *v5;
  *(_OWORD *)(a1 + 32) = *(_OWORD *)v10;
  if (v3)
  {
    uint64_t Context = mlir::Attribute::getContext((mlir::Attribute *)a1);
    if (*(unsigned char *)(a1 + 16)) {
      *(unsigned char *)(a1 + 16) = 0;
    }
    mlir::OperationName::OperationName(a1 + 8, "tensor.expand_shape", 19, Context);
    *(unsigned char *)(a1 + 16) = 1;
  }
  return a1;
}

BOOL mlir::tensor::ExpandShapeOp::readProperties(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = (uint64_t *)mlir::OperationState::getOrAddProperties<mlir::tensor::detail::ExpandShapeOpGenericAdaptorBase::Properties>(a2);
  return mlir::DialectBytecodeReader::readAttribute<mlir::ArrayAttr>(a1, v3) != 0;
}

uint64_t mlir::OperationState::getOrAddProperties<mlir::tensor::detail::ExpandShapeOpGenericAdaptorBase::Properties>(uint64_t a1)
{
  uint64_t result = *(void *)(a1 + 256);
  if (!result) {
    operator new();
  }
  return result;
}

BOOL mlir::tensor::ExpandShapeOp::parse(uint64_t a1, uint64_t a2)
{
  uint64_t v20 = *MEMORY[0x263EF8340];
  memset(v17, 0, 24);
  v15[0] = (uint64_t)v17;
  v15[1] = 1;
  v13[1] = 1;
  uint64_t v14 = 0;
  uint64_t v16 = 0;
  v13[0] = &v16;
  uint64_t v4 = (*(uint64_t (**)(uint64_t))(*(void *)a1 + 40))(a1);
  if (!(*(unsigned __int8 (**)(uint64_t, void *, uint64_t))(*(void *)a1 + 672))(a1, v17, 1)) {
    return 0;
  }
  uint64_t v5 = (mlir::NoneType **)(*(uint64_t (**)(uint64_t))(*(void *)a1 + 32))(a1);
  uint64_t v7 = mlir::NoneType::get(*v5, v6);
  if (!mlir::AsmParser::parseAttribute<mlir::ArrayAttr>(a1, &v14, v7)) {
    return 0;
  }
  if (v14)
  {
    uint64_t v8 = (void *)mlir::OperationState::getOrAddProperties<mlir::tensor::detail::ExpandShapeOpGenericAdaptorBase::Properties>(a2);
    *uint64_t v8 = v14;
  }
  uint64_t v12 = (*(uint64_t (**)(uint64_t))(*(void *)a1 + 40))(a1);
  if (!(*(unsigned __int8 (**)(uint64_t, uint64_t))(*(void *)a1 + 456))(a1, a2 + 112)) {
    return 0;
  }
  uint64_t v9 = *(void *)(a2 + 8);
  __src[0] = a1;
  __src[1] = &v12;
  __src[2] = a2;
  uint64_t v10 = mlir::NamedAttrList::get(a2 + 112, **(void **)(v9 + 96));
  if (v10)
  {
    if (!mlir::memref::__mlir_ods_local_attr_constraint_MemRefOps4(v10, (void **)"reassociation", (const char *)0xD, (void (*)(uint64_t *__return_ptr, uint64_t))llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::ExpandShapeOp::parse(mlir::OpAsmParser &,mlir::OperationState &)::$_0>, (uint64_t)__src))return 0; {
  }
    }
  if (!(*(unsigned __int8 (**)(uint64_t))(*(void *)a1 + 104))(a1)) {
    return 0;
  }
  __src[0] = 0;
  if (!mlir::AsmParser::parseType<mlir::RankedTensorType>(a1, __src)) {
    return 0;
  }
  uint64_t v16 = __src[0];
  __int16 v19 = 257;
  if (!(*(unsigned __int8 (**)(uint64_t, const char *, uint64_t, void *))(*(void *)a1 + 368))(a1, "into", 4, __src))return 0; {
  uint64_t v12 = 0;
  }
  if (!mlir::AsmParser::parseType<mlir::RankedTensorType>(a1, &v12)) {
    return 0;
  }
  __src[0] = v12;
  mlir::OperationState::addTypes(a2, __src, 1);
  return mlir::OpAsmParser::resolveOperands<llvm::ArrayRef<mlir::OpAsmParser::UnresolvedOperand> &,llvm::ArrayRef<mlir::Type> &>(a1, v15, v13, v4, a2 + 16) != 0;
}

uint64_t mlir::tensor::detail::ExtractOpGenericAdaptorBase::ExtractOpGenericAdaptorBase(uint64_t a1, unsigned int *a2)
{
  uint64_t v11 = *MEMORY[0x263EF8340];
  unint64_t AttrDictionary = mlir::Operation::getAttrDictionary((mlir::Operation *)a2);
  unint64_t v5 = a2[11];
  unint64_t v6 = v5 & 0x7FFFFF;
  if ((v5 & 0x7FFFFF) != 0)
  {
    uint64_t v7 = (((unint64_t)&a2[4 * ((v5 >> 23) & 1) + 17] + ((v5 >> 21) & 0x7F8) + 3) & 0xFFFFFFFFFFFFFFF8)
       + 32 * a2[10];
  }
  else
  {
    uint64_t v7 = 0;
    unint64_t v6 = 0;
  }
  mlir::ValueRange::ValueRange(v10, v7, v6);
  *(void *)a1 = AttrDictionary;
  *(unsigned char *)(a1 + 8) = 0;
  *(unsigned char *)(a1 + 16) = 0;
  *(_OWORD *)(a1 + 24) = *(_OWORD *)v10;
  if (AttrDictionary)
  {
    uint64_t Context = mlir::Attribute::getContext((mlir::Attribute *)a1);
    if (*(unsigned char *)(a1 + 16)) {
      *(unsigned char *)(a1 + 16) = 0;
    }
    mlir::OperationName::OperationName(a1 + 8, "tensor.extract", 14, Context);
    *(unsigned char *)(a1 + 16) = 1;
  }
  return a1;
}

void mlir::tensor::ExtractOp::build(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  uint64_t v11 = a4;
  mlir::OperationState::addOperands(a2, (uint64_t)&v11, 1);
  mlir::OperationState::addOperands(a2, a5, a6);
  uint64_t v10 = *(unsigned int *)(a2 + 72);
  if (v10 >= *(_DWORD *)(a2 + 76))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod(a2 + 64, (void *)(a2 + 80), v10 + 1, 8);
    LODWORD(v10) = *(_DWORD *)(a2 + 72);
  }
  *(void *)(*(void *)(a2 + 64) + 8 * v10) = a3;
  ++*(_DWORD *)(a2 + 72);
}

void mlir::tensor::ExtractOp::build(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v23 = *MEMORY[0x263EF8340];
  uint64_t v15 = a3;
  mlir::OperationState::addOperands(a2, (uint64_t)&v15, 1);
  mlir::OperationState::addOperands(a2, a4, a5);
  uint64_t __src = v21;
  uint64_t v20 = 0x200000000;
  mlir::ValueRange::ValueRange((unint64_t *)&v18, *(void *)(a2 + 16), *(unsigned int *)(a2 + 24));
  uint64_t Context = (mlir::MLIRContext *)mlir::Attribute::getContext((mlir::Attribute *)a2);
  mlir::NamedAttrList::getDictionary((mlir::NamedAttrList *)(a2 + 112), Context);
  mlir::ValueRange::ValueRange(&v17, *(void *)(a2 + 224), *(unsigned int *)(a2 + 232));
  long long v22 = v18;
  if (v20 != 1)
  {
    if (!v20)
    {
      if (HIDWORD(v20))
      {
        unsigned int v9 = 0;
LABEL_6:
        bzero((char *)__src + 8 * v9, 8 - 8 * v9);
        goto LABEL_7;
      }
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&__src, v21, 1uLL, 8);
      unsigned int v9 = v20;
      if (v20 != 1) {
        goto LABEL_6;
      }
    }
LABEL_7:
    LODWORD(v20) = 1;
  }
  unint64_t v16 = *(void *)(mlir::ValueRange::dereference_iterator(&v22, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
  uint64_t ElementType = mlir::TensorType::getElementType((mlir::TensorType *)&v16);
  *(void *)uint64_t __src = ElementType;
  uint64_t v11 = __src;
  uint64_t v12 = v20;
  uint64_t v13 = *(unsigned int *)(a2 + 72);
  unint64_t v14 = v13 + v20;
  if (v14 > *(unsigned int *)(a2 + 76))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod(a2 + 64, (void *)(a2 + 80), v14, 8);
    LODWORD(v13) = *(_DWORD *)(a2 + 72);
  }
  if (v12)
  {
    memcpy((void *)(*(void *)(a2 + 64) + 8 * v13), v11, 8 * v12);
    LODWORD(v13) = *(_DWORD *)(a2 + 72);
  }
  *(_DWORD *)(a2 + 72) = v13 + v12;
  if (__src != v21) {
    free(__src);
  }
}

uint64_t mlir::tensor::ExtractOp::inferReturnTypes(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11)
{
  uint64_t v15[2] = *MEMORY[0x263EF8340];
  v15[0] = a4;
  v15[1] = a5;
  int v11 = *(_DWORD *)(a11 + 8);
  if (v11 != 1)
  {
    if (!v11)
    {
      if (*(_DWORD *)(a11 + 12))
      {
        unsigned int v12 = 0;
LABEL_6:
        bzero((void *)(*(void *)a11 + 8 * v12), 8 - 8 * v12);
        goto LABEL_7;
      }
      llvm::SmallVectorBase<unsigned int>::grow_pod(a11, (void *)(a11 + 16), 1uLL, 8);
      unsigned int v12 = *(_DWORD *)(a11 + 8);
      if (v12 != 1) {
        goto LABEL_6;
      }
    }
LABEL_7:
    *(_DWORD *)(a11 + 8) = 1;
  }
  unint64_t v14 = *(void *)(mlir::ValueRange::dereference_iterator(v15, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
  **(void **)a11 = mlir::TensorType::getElementType((mlir::TensorType *)&v14);
  return 1;
}

uint64_t mlir::tensor::ExtractOp::verifyInvariantsImpl(mlir::tensor::ExtractOp *this)
{
  uint64_t v33 = *MEMORY[0x263EF8340];
  if (!mlir::tensor::__mlir_ods_local_type_constraint_TensorOps1(*(void *)this, *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"operand", (void **)7, 0))return 0; {
  uint64_t v2 = *(void *)this;
  }
  if ((*(unsigned char *)(*(void *)this + 46) & 0x80) == 0)
  {
    uint64_t v4 = -1;
    uint64_t v5 = 32;
LABEL_5:
    uint64_t v6 = 0;
    uint64_t v7 = v5 + 24;
    while (mlir::memref::__mlir_ods_local_type_constraint_MemRefOps3(*(void *)this, *(void *)(*(void *)v7 + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"operand", (void **)7, (int)v6 + 1))
    {
      ++v6;
      v7 += 32;
      if (v4 == v6)
      {
        uint64_t v2 = *(void *)this;
        goto LABEL_9;
      }
    }
    return 0;
  }
  uint64_t v3 = *(unsigned int *)(v2 + 68);
  uint64_t v4 = v3 - 1;
  if (v3 != 1)
  {
    uint64_t v5 = *(void *)(v2 + 72) + 32;
    goto LABEL_5;
  }
LABEL_9:
  int v8 = *(_DWORD *)(v2 + 36);
  uint64_t v9 = v2 - 16;
  if (v8) {
    uint64_t v10 = v9;
  }
  else {
    uint64_t v10 = 0;
  }
  mlir::detail::OpResultImpl::getNextResultAtOffset(v10, 0);
  v25[0] = *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8;
  uint64_t ElementType = mlir::TensorType::getElementType((mlir::TensorType *)v25);
  if (*(_DWORD *)(*(void *)this + 36)) {
    uint64_t v12 = *(void *)this - 16;
  }
  else {
    uint64_t v12 = 0;
  }
  if (ElementType == (*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v12, 0) + 8) & 0xFFFFFFFFFFFFFFF8)) {
    return 1;
  }
  uint64_t v23 = (void **)"failed to verify that result type matches element type of tensor";
  __int16 v24 = 259;
  mlir::OpState::emitOpError((uint64_t *)this, &v23, (uint64_t)v25);
  uint64_t v13 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v25);
  if (v25[0]) {
    mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v25);
  }
  if (v32)
  {
    unint64_t v14 = __p;
    if (__p)
    {
      uint64_t v15 = v31;
      unint64_t v16 = __p;
      if (v31 != __p)
      {
        do
          uint64_t v15 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v15 - 1);
        while (v15 != v14);
        unint64_t v16 = __p;
      }
      unint64_t v31 = v14;
      operator delete(v16);
    }
    unint64_t v17 = v28;
    if (v28)
    {
      long long v18 = v29;
      __int16 v19 = v28;
      if (v29 != v28)
      {
        do
        {
          uint64_t v21 = *--v18;
          uint64_t v20 = v21;
          *long long v18 = 0;
          if (v21) {
            MEMORY[0x21667D390](v20, 0x1000C8077774924);
          }
        }
        while (v18 != v17);
        __int16 v19 = v28;
      }
      uint64_t v29 = v17;
      operator delete(v19);
    }
    if (v26 != &v27) {
      free(v26);
    }
  }
  return v13;
}

uint64_t mlir::tensor::ExtractOp::parse(uint64_t a1, uint64_t a2)
{
  v29[4] = *MEMORY[0x263EF8340];
  memset(v29, 0, 24);
  v23[0] = (uint64_t)v29;
  v23[1] = 1;
  uint64_t v25 = 0;
  uint64_t v26 = v28;
  uint64_t v27 = 0x400000000;
  v22[0] = &v25;
  v22[1] = 1;
  uint64_t v4 = (*(uint64_t (**)(uint64_t))(*(void *)a1 + 40))(a1);
  if ((*(unsigned __int8 (**)(uint64_t, void *, uint64_t))(*(void *)a1 + 672))(a1, v29, 1))
  {
    if ((*(unsigned __int8 (**)(uint64_t))(*(void *)a1 + 296))(a1))
    {
      (*(void (**)(uint64_t))(*(void *)a1 + 40))(a1);
      if ((*(unsigned __int8 (**)(uint64_t, unsigned char **, void, uint64_t, uint64_t))(*(void *)a1 + 688))(a1, &v26, 0, 1, 0xFFFFFFFFLL))
      {
        if ((*(unsigned __int8 (**)(uint64_t))(*(void *)a1 + 312))(a1))
        {
          (*(void (**)(uint64_t))(*(void *)a1 + 40))(a1);
          if ((*(unsigned __int8 (**)(uint64_t, uint64_t))(*(void *)a1 + 456))(a1, a2 + 112))
          {
            if ((*(unsigned __int8 (**)(uint64_t))(*(void *)a1 + 104))(a1))
            {
              __src[0] = 0;
              if (mlir::AsmParser::parseType<mlir::RankedTensorType>(a1, __src))
              {
                uint64_t v5 = __src[0];
                uint64_t v25 = __src[0];
                uint64_t v21 = __src[0];
                if (*(_UNKNOWN **)(*(void *)__src[0] + 136) != &mlir::detail::TypeIDResolver<mlir::RankedTensorType,void>::id)
                {
                  uint64_t v6 = (*(uint64_t (**)(uint64_t))(*(void *)a1 + 16))(a1);
                  __int16 v20 = 257;
                  (*(void (**)(void *__return_ptr, uint64_t, uint64_t, void *))(*(void *)a1 + 24))(__src, a1, v6, v19);
                  uint64_t v7 = mlir::InFlightDiagnostic::operator<<<char const(&)[44]>((uint64_t)__src, "'tensor' must be ranked tensor of any type values, but got ");
                  uint64_t v8 = mlir::InFlightDiagnostic::append<mlir::Type &>(v7, &v21);
                  uint64_t v9 = mlir::InFlightDiagnostic::operator mlir::LogicalResult(v8);
                  mlir::InFlightDiagnostic::~InFlightDiagnostic((mlir::InFlightDiagnostic *)__src);
                  uint64_t v10 = v26;
                  if (v26 == v28) {
                    return v9;
                  }
                  goto LABEL_19;
                }
                uint64_t v11 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*(void *)__src[0] + 8);
                __src[0] = v5;
                __src[1] = v11;
                mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)__src);
                uint64_t v12 = (mlir::IndexType **)(*(uint64_t (**)(uint64_t))(*(void *)a1 + 32))(a1);
                uint64_t IndexType = mlir::Builder::getIndexType(v12, v13);
                v19[0] = v25;
                __src[0] = mlir::TensorType::getElementType((mlir::TensorType *)v19);
                mlir::OperationState::addTypes(a2, __src, 1);
                uint64_t v15 = a2 + 16;
                if (mlir::OpAsmParser::resolveOperands<llvm::ArrayRef<mlir::OpAsmParser::UnresolvedOperand> &,llvm::ArrayRef<mlir::Type> &>(a1, v23, v22, v4, v15))
                {
                  if (!v27)
                  {
                    uint64_t v9 = 1;
                    uint64_t v10 = v26;
                    if (v26 == v28) {
                      return v9;
                    }
                    goto LABEL_19;
                  }
                  unint64_t v16 = v26;
                  uint64_t v17 = 32 * v27;
                  uint64_t v9 = 1;
                  while ((*(unsigned __int8 (**)(uint64_t, unsigned char *, uint64_t, uint64_t))(*(void *)a1 + 696))(a1, v16, IndexType, v15))
                  {
                    v16 += 32;
                    v17 -= 32;
                    if (!v17) {
                      goto LABEL_18;
                    }
                  }
                }
              }
            }
          }
        }
      }
    }
  }
  uint64_t v9 = 0;
LABEL_18:
  uint64_t v10 = v26;
  if (v26 != v28) {
LABEL_19:
  }
    free(v10);
  return v9;
}

void mlir::tensor::ExtractOp::print(mlir::Operation **this, mlir::OpAsmPrinter *a2)
{
  v29[4] = *MEMORY[0x263EF8340];
  uint64_t v4 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v5 = (unsigned char *)*((void *)v4 + 4);
  if ((unint64_t)v5 >= *((void *)v4 + 3))
  {
    llvm::raw_ostream::write(v4, 32);
  }
  else
  {
    *((void *)v4 + 4) = v5 + 1;
    unsigned char *v5 = 32;
  }
  (*(void (**)(mlir::OpAsmPrinter *, void))(*(void *)a2 + 160))(a2, *(void *)(*((void *)*this + 9) + 24));
  uint64_t v6 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v7 = (unsigned char *)*((void *)v6 + 4);
  if (*((unsigned char **)v6 + 3) == v7)
  {
    llvm::raw_ostream::write(v6, "[", 1uLL);
    uint64_t v8 = *this;
    if ((*((unsigned char *)*this + 46) & 0x80) != 0) {
      goto LABEL_6;
    }
  }
  else
  {
    *uint64_t v7 = 91;
    ++*((void *)v6 + 4);
    uint64_t v8 = *this;
    if ((*((unsigned char *)*this + 46) & 0x80) != 0)
    {
LABEL_6:
      uint64_t v9 = *((unsigned int *)v8 + 17);
      uint64_t v10 = *((void *)v8 + 9);
      uint64_t v11 = v9 - 1;
      goto LABEL_7;
    }
  }
  uint64_t v10 = 0;
  uint64_t v11 = -1;
LABEL_7:
  uint64_t v12 = v10 + 32;
  uint64_t v13 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v27 = ", ";
  uint64_t v28 = 2;
  llvm::interleave<llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator,void mlir::OpAsmPrinter::printOperands<llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator>(llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator,llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator)::{lambda(mlir::Value)#1},void llvm::interleave<llvm::iterator_range<llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator>,void mlir::OpAsmPrinter::printOperands<llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator>(llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator,llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator)::{lambda(mlir::Value)#1},llvm::raw_ostream,mlir::Value>(llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator const&,llvm::raw_ostream &,void mlir::OpAsmPrinter::printOperands<llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator>(llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator,llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator)::{lambda(mlir::Value)#1},llvm::StringRef const&)::{lambda(void)#1},void>(v12, 0, v12, v11, (uint64_t)a2, v13, (uint64_t)&v27);
  unint64_t v14 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v15 = (unsigned char *)*((void *)v14 + 4);
  if (*((unsigned char **)v14 + 3) == v15)
  {
    llvm::raw_ostream::write(v14, "]", 1uLL);
  }
  else
  {
    *uint64_t v15 = 93;
    ++*((void *)v14 + 4);
  }
  uint64_t v27 = v29;
  uint64_t v28 = 0x200000000;
  unint64_t v16 = *this;
  if (*((unsigned char *)*this + 47))
  {
    unint64_t AttrDictionary = mlir::Operation::getAttrDictionary(v16);
    p_unint64_t AttrDictionary = (mlir::ArrayAttr *)&AttrDictionary;
  }
  else
  {
    p_unint64_t AttrDictionary = (mlir::Operation *)((char *)v16 + 56);
  }
  uint64_t Value = mlir::ArrayAttr::getValue(p_AttrDictionary);
  (*(void (**)(mlir::OpAsmPrinter *, uint64_t, uint64_t, void *, void))(*(void *)a2 + 192))(a2, Value, v19, v27, v28);
  __int16 v20 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v21 = (unsigned char *)*((void *)v20 + 4);
  if ((unint64_t)v21 >= *((void *)v20 + 3))
  {
    llvm::raw_ostream::write(v20, 32);
  }
  else
  {
    *((void *)v20 + 4) = v21 + 1;
    *uint64_t v21 = 32;
  }
  long long v22 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v23 = (unsigned char *)*((void *)v22 + 4);
  if (*((unsigned char **)v22 + 3) == v23)
  {
    llvm::raw_ostream::write(v22, ":", 1uLL);
  }
  else
  {
    unsigned char *v23 = 58;
    ++*((void *)v22 + 4);
  }
  __int16 v24 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v25 = (unsigned char *)*((void *)v24 + 4);
  if ((unint64_t)v25 >= *((void *)v24 + 3))
  {
    llvm::raw_ostream::write(v24, 32);
  }
  else
  {
    *((void *)v24 + 4) = v25 + 1;
    unsigned char *v25 = 32;
  }
  (*(void (**)(mlir::OpAsmPrinter *, unint64_t))(*(void *)a2 + 32))(a2, *(void *)(*(void *)(*((void *)*this + 9) + 24) + 8) & 0xFFFFFFFFFFFFFFF8);
  if (v27 != v29) {
    free(v27);
  }
}

uint64_t mlir::tensor::detail::ExtractSliceOpGenericAdaptorBase::ExtractSliceOpGenericAdaptorBase(uint64_t a1, uint64_t a2)
{
  uint64_t v13 = *MEMORY[0x263EF8340];
  uint64_t v3 = *(void *)(a2 + 56);
  unint64_t v4 = *(unsigned int *)(a2 + 44);
  if (HIBYTE(*(_DWORD *)(a2 + 44))) {
    uint64_t v5 = a2 + 16 * ((v4 >> 23) & 1) + 64;
  }
  else {
    uint64_t v5 = 0;
  }
  unint64_t v6 = v4 & 0x7FFFFF;
  if ((v4 & 0x7FFFFF) != 0)
  {
    uint64_t v7 = ((a2 + 16 * ((v4 >> 23) & 1) + 64 + ((v4 >> 21) & 0x7F8) + 7) & 0xFFFFFFFFFFFFFFF8)
       + 32 * *(unsigned int *)(a2 + 40);
  }
  else
  {
    uint64_t v7 = 0;
    unint64_t v6 = 0;
  }
  mlir::ValueRange::ValueRange(v12, v7, v6);
  *(void *)a1 = v3;
  *(unsigned char *)(a1 + 8) = 0;
  *(unsigned char *)(a1 + 16) = 0;
  long long v8 = *(_OWORD *)v5;
  long long v9 = *(_OWORD *)(v5 + 16);
  *(void *)(a1 + 56) = *(void *)(v5 + 32);
  *(_OWORD *)(a1 + 40) = v9;
  *(_OWORD *)(a1 + 24) = v8;
  *(_OWORD *)(a1 + 64) = *(_OWORD *)v12;
  if (v3)
  {
    uint64_t Context = mlir::Attribute::getContext((mlir::Attribute *)a1);
    if (*(unsigned char *)(a1 + 16)) {
      *(unsigned char *)(a1 + 16) = 0;
    }
    mlir::OperationName::OperationName(a1 + 8, "tensor.extract_slice", 20, Context);
    *(unsigned char *)(a1 + 16) = 1;
  }
  return a1;
}

uint64_t mlir::tensor::ExtractSliceOp::getInherentAttr(mlir::MLIRContext *a1, uint64_t *a2, char *__s1, size_t __n)
{
  uint64_t result = 0;
  switch(__n)
  {
    case 0xCuLL:
      if (memcmp(__s1, "static_sizes", __n)) {
        goto LABEL_11;
      }
      return a2[1];
    case 0xDuLL:
    case 0xFuLL:
    case 0x10uLL:
    case 0x11uLL:
    case 0x12uLL:
    case 0x14uLL:
      goto LABEL_11;
    case 0xEuLL:
      if (*(void *)__s1 == 0x6F5F636974617473 && *(void *)(__s1 + 6) == 0x7374657366666F5FLL)
      {
        uint64_t result = *a2;
      }
      else if (!memcmp(__s1, "static_strides", __n))
      {
        uint64_t result = a2[2];
      }
      else
      {
LABEL_11:
        uint64_t result = 0;
      }
      break;
    case 0x13uLL:
      if (memcmp(__s1, "operandSegmentSizes", __n)) {
        goto LABEL_11;
      }
      goto LABEL_13;
    case 0x15uLL:
      if (memcmp(__s1, "operand_segment_sizes", __n)) {
        goto LABEL_11;
      }
LABEL_13:
      uint64_t result = mlir::detail::DenseArrayAttrImpl<int>::get(a1, (uint64_t)(a2 + 3), 4);
      break;
    default:
      return result;
  }
  return result;
}

uint64_t mlir::tensor::ExtractSliceOp::setInherentAttr(uint64_t result, char *__s1, size_t a3, void *a4)
{
  uint64_t v5 = (void *)result;
  switch(a3)
  {
    case 0xCuLL:
      uint64_t result = memcmp(__s1, "static_sizes", a3);
      if (!result)
      {
        if (a4)
        {
          uint64_t result = mlir::detail::DenseArrayAttrImpl<long long>::classof(a4);
          if (result) {
            uint64_t v10 = a4;
          }
          else {
            uint64_t v10 = 0;
          }
          v5[1] = v10;
        }
        else
        {
          v5[1] = 0;
        }
      }
      break;
    case 0xEuLL:
      if (*(void *)__s1 == 0x6F5F636974617473 && *(void *)(__s1 + 6) == 0x7374657366666F5FLL)
      {
        if (a4)
        {
          uint64_t result = mlir::detail::DenseArrayAttrImpl<long long>::classof(a4);
          if (result) {
            uint64_t v11 = a4;
          }
          else {
            uint64_t v11 = 0;
          }
          void *v5 = v11;
        }
        else
        {
          *(void *)uint64_t result = 0;
        }
      }
      else
      {
        uint64_t result = memcmp(__s1, "static_strides", a3);
        if (!result)
        {
          if (a4)
          {
            uint64_t result = mlir::detail::DenseArrayAttrImpl<long long>::classof(a4);
            if (result) {
              uint64_t v7 = a4;
            }
            else {
              uint64_t v7 = 0;
            }
            v5[2] = v7;
          }
          else
          {
            v5[2] = 0;
          }
        }
      }
      break;
    case 0x13uLL:
      uint64_t result = memcmp(__s1, "operandSegmentSizes", a3);
      if (!result) {
        goto LABEL_17;
      }
      break;
    case 0x15uLL:
      uint64_t result = memcmp(__s1, "operand_segment_sizes", a3);
      if (!result)
      {
LABEL_17:
        if (a4)
        {
          uint64_t result = mlir::detail::DenseArrayAttrImpl<int>::classof(a4);
          long long v8 = result ? a4 : 0;
          uint64_t v12 = v8;
          if (result)
          {
            uint64_t result = mlir::AffineBinaryOpExpr::getLHS((mlir::AffineBinaryOpExpr *)&v12);
            if (result == 4)
            {
              uint64_t result = mlir::detail::DenseArrayAttrImpl<int>::operator llvm::ArrayRef<int>((uint64_t)&v12);
              if (v9) {
                uint64_t result = (uint64_t)memmove(v5 + 3, (const void *)result, 4 * v9);
              }
            }
          }
        }
      }
      break;
    default:
      return result;
  }
  return result;
}

BOOL mlir::tensor::ExtractSliceOp::readProperties(uint64_t a1, uint64_t a2)
{
  uint64_t v26 = *MEMORY[0x263EF8340];
  uint64_t v3 = (void *)mlir::OperationState::getOrAddProperties<mlir::tensor::detail::ExtractSliceOpGenericAdaptorBase::Properties>(a2);
  if ((unint64_t)(*(uint64_t (**)(uint64_t))(*(void *)a1 + 40))(a1) <= 5)
  {
    uint64_t v17 = 0;
    if (!mlir::DialectBytecodeReader::readAttribute<mlir::detail::DenseArrayAttrImpl<int>>(a1, &v17)) {
      return 0;
    }
    if (mlir::AffineBinaryOpExpr::getLHS((mlir::AffineBinaryOpExpr *)&v17) >= 5)
    {
      uint64_t v15 = "size mismatch for operand/result_segment_size";
      __int16 v16 = 259;
      (*(void (**)(void *__return_ptr, uint64_t, const char **))(*(void *)a1 + 16))(v18, a1, &v15);
      if (v18[0]) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v18);
      }
      if (v25)
      {
        unint64_t v4 = __p;
        if (__p)
        {
          uint64_t v5 = v24;
          unint64_t v6 = __p;
          if (v24 != __p)
          {
            do
              uint64_t v5 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v5 - 1);
            while (v5 != v4);
            unint64_t v6 = __p;
          }
          __int16 v24 = v4;
          operator delete(v6);
        }
        uint64_t v7 = v21;
        if (v21)
        {
          long long v8 = v22;
          uint64_t v9 = v21;
          if (v22 != v21)
          {
            do
            {
              uint64_t v11 = *--v8;
              uint64_t v10 = v11;
              *long long v8 = 0;
              if (v11) {
                MEMORY[0x21667D390](v10, 0x1000C8077774924);
              }
            }
            while (v8 != v7);
            uint64_t v9 = v21;
          }
          long long v22 = v7;
          operator delete(v9);
        }
        if (v19 != &v20) {
          free(v19);
        }
      }
      return 0;
    }
    uint64_t v12 = (const void *)mlir::detail::DenseArrayAttrImpl<int>::operator llvm::ArrayRef<int>((uint64_t)&v17);
    if (v13) {
      memmove(v3 + 3, v12, 4 * v13);
    }
  }
  return mlir::DialectBytecodeReader::readAttribute<mlir::detail::DenseArrayAttrImpl<long long>>(a1, v3)&& mlir::DialectBytecodeReader::readAttribute<mlir::detail::DenseArrayAttrImpl<long long>>(a1, v3 + 1)&& mlir::DialectBytecodeReader::readAttribute<mlir::detail::DenseArrayAttrImpl<long long>>(a1, v3 + 2)&& ((unint64_t)(*(uint64_t (**)(uint64_t))(*(void *)a1 + 40))(a1) < 6|| mlir::DialectBytecodeReader::readSparseArray<int>(a1, (_DWORD *)v3 + 6, (const char *)4));
}

uint64_t mlir::OperationState::getOrAddProperties<mlir::tensor::detail::ExtractSliceOpGenericAdaptorBase::Properties>(uint64_t a1)
{
  uint64_t result = *(void *)(a1 + 256);
  if (!result) {
    operator new();
  }
  return result;
}

void mlir::tensor::ExtractSliceOp::build(mlir::MLIRContext **a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16)
{
  uint64_t v28 = a4;
  mlir::OperationState::addOperands(a2, (uint64_t)&v28, 1);
  mlir::OperationState::addOperands(a2, a5, a6);
  mlir::OperationState::addOperands(a2, a7, a8);
  mlir::OperationState::addOperands(a2, a9, a10);
  long long v22 = (_DWORD *)mlir::OperationState::getOrAddProperties<mlir::tensor::detail::ExtractSliceOpGenericAdaptorBase::Properties>(a2);
  v22[6] = 1;
  v22[7] = a6;
  v22[8] = a8;
  v22[9] = a10;
  uint64_t DenseI64ArrayAttr = mlir::Builder::getDenseI64ArrayAttr(a1, a11, a12);
  *(void *)mlir::OperationState::getOrAddProperties<mlir::tensor::detail::ExtractSliceOpGenericAdaptorBase::Properties>(a2) = DenseI64ArrayAttr;
  uint64_t v24 = mlir::Builder::getDenseI64ArrayAttr(a1, a13, a14);
  *(void *)(mlir::OperationState::getOrAddProperties<mlir::tensor::detail::ExtractSliceOpGenericAdaptorBase::Properties>(a2)
            + 8) = v24;
  uint64_t v25 = mlir::Builder::getDenseI64ArrayAttr(a1, a15, a16);
  *(void *)(mlir::OperationState::getOrAddProperties<mlir::tensor::detail::ExtractSliceOpGenericAdaptorBase::Properties>(a2)
            + 16) = v25;
  uint64_t v26 = *(unsigned int *)(a2 + 72);
  if (v26 >= *(_DWORD *)(a2 + 76))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod(a2 + 64, (void *)(a2 + 80), v26 + 1, 8);
    LODWORD(v26) = *(_DWORD *)(a2 + 72);
  }
  *(void *)(*(void *)(a2 + 64) + 8 * v26) = a3;
  ++*(_DWORD *)(a2 + 72);
}

BOOL mlir::tensor::ExtractSliceOp::verifyInvariantsImpl(mlir::tensor::ExtractSliceOp *this)
{
  uint64_t v59 = *MEMORY[0x263EF8340];
  uint64_t v2 = *(void *)this;
  if (HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
    unint64_t v3 = *(void *)this + 16 * (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 23) & 1) + 64;
  }
  else {
    unint64_t v3 = 0;
  }
  unint64_t v4 = *(void **)v3;
  if (!*(void *)v3)
  {
    v49[0] = (void **)"requires attribute 'static_offsets'";
    __int16 v50 = 259;
    mlir::OpState::emitOpError((uint64_t *)this, v49, (uint64_t)v51);
    uint64_t v27 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v51);
    if (v51[0]) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v51);
    }
    if (!v58) {
      return v27;
    }
    uint64_t v28 = __p;
    if (__p)
    {
      uint64_t v29 = v57;
      uint64_t v30 = __p;
      if (v57 != __p)
      {
        do
          uint64_t v29 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v29 - 1);
        while (v29 != v28);
        uint64_t v30 = __p;
      }
      unint64_t v57 = v28;
      operator delete(v30);
    }
    unint64_t v31 = v54;
    if (v54)
    {
      char v32 = v55;
      uint64_t v33 = v54;
      if (v55 == v54) {
        goto LABEL_77;
      }
      do
      {
        uint64_t v35 = *--v32;
        uint64_t v34 = v35;
        *char v32 = 0;
        if (v35) {
          MEMORY[0x21667D390](v34, 0x1000C8077774924);
        }
      }
      while (v32 != v31);
LABEL_76:
      uint64_t v33 = v54;
LABEL_77:
      unsigned int v55 = v31;
      operator delete(v33);
    }
LABEL_78:
    if (v52 != &v53) {
      free(v52);
    }
    return v27;
  }
  uint64_t v5 = *(void **)(v3 + 8);
  if (!v5)
  {
    v49[0] = (void **)"requires attribute 'static_sizes'";
    __int16 v50 = 259;
    mlir::OpState::emitOpError((uint64_t *)this, v49, (uint64_t)v51);
    uint64_t v27 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v51);
    if (v51[0]) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v51);
    }
    if (!v58) {
      return v27;
    }
    uint64_t v36 = __p;
    if (__p)
    {
      uint64_t v37 = v57;
      BOOL v38 = __p;
      if (v57 != __p)
      {
        do
          uint64_t v37 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v37 - 1);
        while (v37 != v36);
        BOOL v38 = __p;
      }
      unint64_t v57 = v36;
      operator delete(v38);
    }
    unint64_t v31 = v54;
    if (v54)
    {
      unint64_t v39 = v55;
      uint64_t v33 = v54;
      if (v55 == v54) {
        goto LABEL_77;
      }
      do
      {
        uint64_t v41 = *--v39;
        uint64_t v40 = v41;
        *unint64_t v39 = 0;
        if (v41) {
          MEMORY[0x21667D390](v40, 0x1000C8077774924);
        }
      }
      while (v39 != v31);
      goto LABEL_76;
    }
    goto LABEL_78;
  }
  unint64_t v6 = *(void **)(v3 + 16);
  if (!v6)
  {
    v49[0] = (void **)"requires attribute 'static_strides'";
    __int16 v50 = 259;
    mlir::OpState::emitOpError((uint64_t *)this, v49, (uint64_t)v51);
    uint64_t v27 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v51);
    if (v51[0]) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v51);
    }
    if (!v58) {
      return v27;
    }
    BOOL v42 = __p;
    if (__p)
    {
      unint64_t v43 = v57;
      BOOL v44 = __p;
      if (v57 != __p)
      {
        do
          unint64_t v43 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v43 - 1);
        while (v43 != v42);
        BOOL v44 = __p;
      }
      unint64_t v57 = v42;
      operator delete(v44);
    }
    unint64_t v31 = v54;
    if (v54)
    {
      unint64_t v45 = v55;
      uint64_t v33 = v54;
      if (v55 == v54) {
        goto LABEL_77;
      }
      do
      {
        uint64_t v47 = *--v45;
        uint64_t v46 = v47;
        *unint64_t v45 = 0;
        if (v47) {
          MEMORY[0x21667D390](v46, 0x1000C8077774924);
        }
      }
      while (v45 != v31);
      goto LABEL_76;
    }
    goto LABEL_78;
  }
  v51[0] = v2;
  if (!mlir::memref::__mlir_ods_local_attr_constraint_MemRefOps12(v4, (void **)"static_offsets", (const char *)0xE, (void (*)(uint64_t *__return_ptr, uint64_t))llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::__mlir_ods_local_attr_constraint_TensorOps1(mlir::Operation *,mlir::Attribute,llvm::StringRef)::$_0>, (uint64_t)v51))return 0; {
  v51[0] = *(void *)this;
  }
  if (!mlir::memref::__mlir_ods_local_attr_constraint_MemRefOps12(v5, (void **)"static_sizes", (const char *)0xC, (void (*)(uint64_t *__return_ptr, uint64_t))llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::__mlir_ods_local_attr_constraint_TensorOps1(mlir::Operation *,mlir::Attribute,llvm::StringRef)::$_0>, (uint64_t)v51))return 0; {
  v51[0] = *(void *)this;
  }
  if (!mlir::memref::__mlir_ods_local_attr_constraint_MemRefOps12(v6, (void **)"static_strides", (const char *)0xE, (void (*)(uint64_t *__return_ptr, uint64_t))llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::__mlir_ods_local_attr_constraint_TensorOps1(mlir::Operation *,mlir::Attribute,llvm::StringRef)::$_0>, (uint64_t)v51))return 0; {
  unint64_t v7 = *(unsigned int *)(*(void *)this + 44);
  }
  uint64_t v8 = *(void *)this + 16 * ((v7 >> 23) & 1) + 64;
  if (!HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
    uint64_t v8 = 0;
  }
  uint64_t v9 = *(unsigned int *)(v8 + 24);
  if ((v7 & 0x800000) != 0)
  {
    uint64_t v10 = *(void *)(*(void *)this + 72);
    if (v9) {
      goto LABEL_14;
    }
  }
  else
  {
    uint64_t v10 = 0;
    if (v9)
    {
LABEL_14:
      uint64_t v11 = 0;
      uint64_t v12 = v10 + 24;
      while (mlir::tensor::__mlir_ods_local_type_constraint_TensorOps1(*(void *)this, *(void *)(*(void *)v12 + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"operand", (void **)7, v11))
      {
        ++v11;
        v12 += 32;
        if (v9 == v11) {
          goto LABEL_17;
        }
      }
      return 0;
    }
  }
LABEL_17:
  uint64_t ODSOperands = mlir::memref::ReinterpretCastOp::getODSOperands(this, 1u);
  if (v14)
  {
    uint64_t v15 = v14;
    uint64_t v16 = ODSOperands + 24;
    while (mlir::memref::__mlir_ods_local_type_constraint_MemRefOps3(*(void *)this, *(void *)(*(void *)v16 + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"operand", (void **)7, v9))
    {
      LODWORD(v9) = v9 + 1;
      v16 += 32;
      if (!--v15) {
        goto LABEL_21;
      }
    }
    return 0;
  }
LABEL_21:
  uint64_t v17 = mlir::memref::ReinterpretCastOp::getODSOperands(this, 2u);
  if (v18)
  {
    uint64_t v19 = v18;
    uint64_t v20 = v17 + 24;
    while (mlir::memref::__mlir_ods_local_type_constraint_MemRefOps3(*(void *)this, *(void *)(*(void *)v20 + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"operand", (void **)7, v9))
    {
      LODWORD(v9) = v9 + 1;
      v20 += 32;
      if (!--v19) {
        goto LABEL_25;
      }
    }
    return 0;
  }
LABEL_25:
  uint64_t v21 = mlir::memref::ReinterpretCastOp::getODSOperands(this, 3u);
  if (v22)
  {
    uint64_t v23 = v22;
    uint64_t v24 = v21 + 24;
    while (mlir::memref::__mlir_ods_local_type_constraint_MemRefOps3(*(void *)this, *(void *)(*(void *)v24 + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"operand", (void **)7, v9))
    {
      LODWORD(v9) = v9 + 1;
      v24 += 32;
      if (!--v23) {
        goto LABEL_29;
      }
    }
    return 0;
  }
LABEL_29:
  if (*(_DWORD *)(*(void *)this + 36)) {
    uint64_t v25 = *(void *)this - 16;
  }
  else {
    uint64_t v25 = 0;
  }
  uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v25, 0);
  return mlir::tensor::__mlir_ods_local_type_constraint_TensorOps1(*(void *)this, *(void *)(NextResultAtOffset + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"result", (void **)6, 0) != 0;
}

uint64_t mlir::tensor::ExtractSliceOp::parse(uint64_t a1, uint64_t a2)
{
  uint64_t v45 = *MEMORY[0x263EF8340];
  memset(v42, 0, 24);
  v31[0] = (uint64_t)v42;
  v31[1] = 1;
  unint64_t v39 = v41;
  uint64_t v40 = 0x400000000;
  uint64_t v29 = 0;
  uint64_t v30 = 0;
  uint64_t v36 = v38;
  uint64_t v37 = 0x400000000;
  uint64_t v32 = 0;
  uint64_t v33 = v35;
  uint64_t v34 = 0x400000000;
  v27[1] = 1;
  uint64_t v28 = 0;
  v27[0] = &v32;
  uint64_t v4 = (*(uint64_t (**)(uint64_t))(*(void *)a1 + 40))(a1);
  if (!(*(unsigned __int8 (**)(uint64_t, void *, uint64_t))(*(void *)a1 + 672))(a1, v42, 1)) {
    goto LABEL_25;
  }
  (*(void (**)(uint64_t))(*(void *)a1 + 40))(a1);
  __src[0] = 0;
  if (!mlir::parseDynamicIndexList(a1, (uint64_t)&v39, &v30, __src, 0)) {
    goto LABEL_25;
  }
  uint64_t v5 = (void *)mlir::OperationState::getOrAddProperties<mlir::tensor::detail::ExtractSliceOpGenericAdaptorBase::Properties>(a2);
  void *v5 = v30;
  (*(void (**)(uint64_t))(*(void *)a1 + 40))(a1);
  __src[0] = 0;
  if (!mlir::parseDynamicIndexList(a1, (uint64_t)&v36, &v29, __src, 0)) {
    goto LABEL_25;
  }
  uint64_t v6 = mlir::OperationState::getOrAddProperties<mlir::tensor::detail::ExtractSliceOpGenericAdaptorBase::Properties>(a2);
  *(void *)(v6 + 8) = v29;
  (*(void (**)(uint64_t))(*(void *)a1 + 40))(a1);
  __src[0] = 0;
  if (!mlir::parseDynamicIndexList(a1, (uint64_t)&v33, &v28, __src, 0)) {
    goto LABEL_25;
  }
  uint64_t v7 = mlir::OperationState::getOrAddProperties<mlir::tensor::detail::ExtractSliceOpGenericAdaptorBase::Properties>(a2);
  *(void *)(v7 + 16) = v28;
  uint64_t v26 = (*(uint64_t (**)(uint64_t))(*(void *)a1 + 40))(a1);
  if (!(*(unsigned __int8 (**)(uint64_t, uint64_t))(*(void *)a1 + 456))(a1, a2 + 112)) {
    goto LABEL_25;
  }
  uint64_t v8 = *(void *)(a2 + 8);
  __src[0] = a1;
  __src[1] = (uint64_t)&v26;
  __src[2] = a2;
  if (!mlir::memref::ReinterpretCastOp::verifyInherentAttrs(v8, a2 + 112, (void (*)(uint64_t *__return_ptr, uint64_t))llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::ExtractSliceOp::parse(mlir::OpAsmParser &,mlir::OperationState &)::$_0>, (uint64_t)__src))goto LABEL_25; {
  if (!(*(unsigned __int8 (**)(uint64_t))(*(void *)a1 + 104))(a1))
  }
    goto LABEL_25;
  __src[0] = 0;
  if (!mlir::AsmParser::parseType<mlir::RankedTensorType>(a1, __src)) {
    goto LABEL_25;
  }
  uint64_t v32 = __src[0];
  __int16 v44 = 257;
  if (!(*(unsigned __int8 (**)(uint64_t, const char *, uint64_t, uint64_t *))(*(void *)a1 + 368))(a1, "to", 2, __src))goto LABEL_25; {
  uint64_t v26 = 0;
  }
  if (!mlir::AsmParser::parseType<mlir::RankedTensorType>(a1, &v26)) {
    goto LABEL_25;
  }
  __src[0] = v26;
  int v9 = v40;
  int v10 = v37;
  int v11 = v34;
  uint64_t v12 = (_DWORD *)mlir::OperationState::getOrAddProperties<mlir::tensor::detail::ExtractSliceOpGenericAdaptorBase::Properties>(a2);
  v12[6] = 1;
  v12[7] = v9;
  v12[8] = v10;
  v12[9] = v11;
  uint64_t v13 = (mlir::IndexType **)(*(uint64_t (**)(uint64_t))(*(void *)a1 + 32))(a1);
  uint64_t IndexType = mlir::Builder::getIndexType(v13, v14);
  mlir::OperationState::addTypes(a2, __src, 1);
  uint64_t v16 = a2 + 16;
  if (!mlir::OpAsmParser::resolveOperands<llvm::ArrayRef<mlir::OpAsmParser::UnresolvedOperand> &,llvm::ArrayRef<mlir::Type> &>(a1, v31, v27, v4, v16))goto LABEL_25; {
  if (v40)
  }
  {
    uint64_t v17 = (char *)v39;
    uint64_t v18 = 32 * v40;
    while ((*(unsigned __int8 (**)(uint64_t, char *, uint64_t, uint64_t))(*(void *)a1 + 696))(a1, v17, IndexType, v16))
    {
      v17 += 32;
      v18 -= 32;
      if (!v18) {
        goto LABEL_16;
      }
    }
LABEL_25:
    uint64_t v23 = 0;
LABEL_26:
    uint64_t v24 = v33;
    if (v33 != v35) {
      goto LABEL_27;
    }
    goto LABEL_28;
  }
LABEL_16:
  if (v37)
  {
    uint64_t v19 = (char *)v36;
    uint64_t v20 = 32 * v37;
    while ((*(unsigned __int8 (**)(uint64_t, char *, uint64_t, uint64_t))(*(void *)a1 + 696))(a1, v19, IndexType, v16))
    {
      v19 += 32;
      v20 -= 32;
      if (!v20) {
        goto LABEL_20;
      }
    }
    goto LABEL_25;
  }
LABEL_20:
  if (v34)
  {
    uint64_t v21 = (char *)v33;
    uint64_t v22 = 32 * v34;
    uint64_t v23 = 1;
    while ((*(unsigned __int8 (**)(uint64_t, char *, uint64_t, uint64_t))(*(void *)a1 + 696))(a1, v21, IndexType, v16))
    {
      v21 += 32;
      v22 -= 32;
      if (!v22) {
        goto LABEL_26;
      }
    }
    goto LABEL_25;
  }
  uint64_t v23 = 1;
  uint64_t v24 = v33;
  if (v33 != v35) {
LABEL_27:
  }
    free(v24);
LABEL_28:
  if (v36 != v38) {
    free(v36);
  }
  if (v39 != v41) {
    free(v39);
  }
  return v23;
}

uint64_t mlir::tensor::detail::FromElementsOpGenericAdaptorBase::FromElementsOpGenericAdaptorBase(uint64_t a1, mlir::Operation *this)
{
  uint64_t v11 = *MEMORY[0x263EF8340];
  unint64_t AttrDictionary = mlir::Operation::getAttrDictionary(this);
  unint64_t v5 = *((unsigned int *)this + 11);
  unint64_t v6 = v5 & 0x7FFFFF;
  if ((v5 & 0x7FFFFF) != 0)
  {
    uint64_t v7 = (((unint64_t)this + 16 * ((v5 >> 23) & 1) + ((v5 >> 21) & 0x7F8) + 71) & 0xFFFFFFFFFFFFFFF8)
       + 32 * *((unsigned int *)this + 10);
  }
  else
  {
    uint64_t v7 = 0;
    unint64_t v6 = 0;
  }
  mlir::ValueRange::ValueRange(v10, v7, v6);
  *(void *)a1 = AttrDictionary;
  *(unsigned char *)(a1 + 8) = 0;
  *(unsigned char *)(a1 + 16) = 0;
  *(_OWORD *)(a1 + 24) = *(_OWORD *)v10;
  if (AttrDictionary)
  {
    uint64_t Context = mlir::Attribute::getContext((mlir::Attribute *)a1);
    if (*(unsigned char *)(a1 + 16)) {
      *(unsigned char *)(a1 + 16) = 0;
    }
    mlir::OperationName::OperationName(a1 + 8, "tensor.from_elements", 20, Context);
    *(unsigned char *)(a1 + 16) = 1;
  }
  return a1;
}

uint64_t mlir::tensor::FromElementsOp::verifyInvariantsImpl(mlir::tensor::FromElementsOp *this)
{
  uint64_t v55 = *MEMORY[0x263EF8340];
  if (*(_DWORD *)(*(void *)this + 36)) {
    uint64_t v2 = *(void *)this - 16;
  }
  else {
    uint64_t v2 = 0;
  }
  uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v2, 0);
  if (!mlir::tensor::__mlir_ods_local_type_constraint_TensorOps7(*(void *)this, (void **)(*(void *)(NextResultAtOffset + 8) & 0xFFFFFFFFFFFFFFF8), (void **)"result", 6, 0))return 0; {
  if (*(_DWORD *)(*(void *)this + 36))
  }
    uint64_t v4 = *(void *)this - 16;
  else {
    uint64_t v4 = 0;
  }
  unint64_t v43 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v4, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
  uint64_t Value = (uint64_t *)mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v43);
  unint64_t NumElements = mlir::ShapedType::getNumElements(Value, v6);
  if (*(_DWORD *)(*(void *)this + 36)) {
    uint64_t v8 = *(void *)this - 16;
  }
  else {
    uint64_t v8 = 0;
  }
  unint64_t v42 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v8, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
  uint64_t RHS = (void *)mlir::AffineBinaryOpExpr::getRHS((mlir::AffineBinaryOpExpr *)&v42);
  unint64_t v10 = (unint64_t)RHS;
  __int16 v44 = &v47;
  int v46 = 2;
  if (NumElements < 3)
  {
    if (NumElements)
    {
      uint64_t v47 = RHS;
      if (NumElements != 1) {
        int64_t v48 = RHS;
      }
    }
  }
  else
  {
    unsigned int v45 = 0;
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v44, &v47, NumElements, 8);
    if (NumElements == 3)
    {
      uint64_t v11 = 3;
      uint64_t v12 = (unint64_t *)v44;
    }
    else
    {
      uint64_t v12 = (unint64_t *)((char *)v44 + 8 * (NumElements & 0xFFFFFFFFFFFFFFFCLL));
      uint64_t v11 = NumElements & 3;
      int64x2_t v14 = vdupq_n_s64(v10);
      uint64_t v15 = (int64x2_t *)((char *)v44 + 16);
      unint64_t v16 = NumElements & 0xFFFFFFFFFFFFFFFCLL;
      do
      {
        v15[-1] = v14;
        *uint64_t v15 = v14;
        v15 += 2;
        v16 -= 4;
      }
      while (v16);
      if (NumElements == (NumElements & 0xFFFFFFFFFFFFFFFCLL)) {
        goto LABEL_22;
      }
    }
    do
    {
      *v12++ = v10;
      --v11;
    }
    while (v11);
  }
LABEL_22:
  unsigned int v45 = NumElements;
  uint64_t v17 = *(void *)this;
  if ((*(unsigned char *)(*(void *)this + 46) & 0x80) != 0)
  {
    uint64_t v18 = *(unsigned int *)(v17 + 68);
    uint64_t v19 = *(void *)(v17 + 72);
  }
  else
  {
    uint64_t v19 = 0;
    uint64_t v18 = 0;
  }
  v41[0] = v19;
  v41[1] = v18;
  mlir::OperandRange::getTypes(v41, (uint64_t *)&v37);
  if (v39 - v38 != v45)
  {
    BOOL v26 = 0;
    goto LABEL_34;
  }
  if (v45)
  {
    uint64_t v20 = 8 * v45 - 8;
    uint64_t v21 = &v37[4 * v38 + 3];
    uint64_t v22 = (uint64_t *)v44;
    do
    {
      uint64_t v23 = *v21;
      v21 += 4;
      uint64_t v24 = v23[1];
      uint64_t v25 = *v22++;
      BOOL v26 = v25 == (v24 & 0xFFFFFFFFFFFFFFF8);
      BOOL v27 = v25 != (v24 & 0xFFFFFFFFFFFFFFF8) || v20 == 0;
      v20 -= 8;
    }
    while (!v27);
LABEL_34:
    if (v44 == &v47) {
      goto LABEL_36;
    }
    goto LABEL_35;
  }
  BOOL v26 = 1;
  if (v44 != &v47) {
LABEL_35:
  }
    free(v44);
LABEL_36:
  if (v26) {
    return 1;
  }
  uint64_t v37 = (void **)"failed to verify that operand types match result element type";
  __int16 v40 = 259;
  mlir::OpState::emitOpError((uint64_t *)this, &v37, (uint64_t)&v44);
  uint64_t v13 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v44);
  if (v44) {
    mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v44);
  }
  if (v54)
  {
    uint64_t v28 = __p;
    if (__p)
    {
      uint64_t v29 = v53;
      uint64_t v30 = __p;
      if (v53 != __p)
      {
        do
          uint64_t v29 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v29 - 1);
        while (v29 != v28);
        uint64_t v30 = __p;
      }
      uint64_t v53 = v28;
      operator delete(v30);
    }
    unint64_t v31 = v50;
    if (v50)
    {
      uint64_t v32 = v51;
      uint64_t v33 = v50;
      if (v51 != v50)
      {
        do
        {
          uint64_t v35 = *--v32;
          uint64_t v34 = v35;
          *uint64_t v32 = 0;
          if (v35) {
            MEMORY[0x21667D390](v34, 0x1000C8077774924);
          }
        }
        while (v32 != v31);
        uint64_t v33 = v50;
      }
      uint64_t v51 = v31;
      operator delete(v33);
    }
    if (v48 != &v49) {
      free(v48);
    }
  }
  return v13;
}

uint64_t mlir::tensor::__mlir_ods_local_type_constraint_TensorOps7(uint64_t a1, void **a2, void **a3, uint64_t a4, unsigned int a5)
{
  uint64_t v69 = *MEMORY[0x263EF8340];
  unint64_t v10 = *a2;
  if (*((_UNKNOWN **)*a2 + 17) == &mlir::detail::TypeIDResolver<mlir::RankedTensorType,void>::id)
  {
    v59[0] = a2;
    v59[1] = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>((uint64_t)v10 + 8);
    if (mlir::CallOpInterface::getArgOperands((mlir::CallOpInterface *)v59))
    {
      uint64_t Shape = (void *)mlir::ShapedType::getShape((mlir::ShapedType *)v59);
      if (!v12)
      {
LABEL_7:
        uint64_t v14 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>((uint64_t)*a2 + 8);
        uint64_t v53 = a2;
        uint64_t v54 = v14;
        mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&v53);
        return 1;
      }
      uint64_t v13 = 8 * v12;
      while (*Shape != 0x8000000000000000)
      {
        ++Shape;
        v13 -= 8;
        if (!v13) {
          goto LABEL_7;
        }
      }
    }
  }
  __int16 v55 = 261;
  uint64_t v53 = a3;
  uint64_t v54 = a4;
  mlir::Operation::emitOpError(a1, &v53, (uint64_t)v59);
  if (v59[0])
  {
    int v56 = 3;
    unint64_t v57 = " #";
    uint64_t v58 = 2;
    unint64_t v16 = &v56;
    uint64_t v17 = (char *)v60;
    if (v61 >= v62)
    {
      unint64_t v43 = v61 + 1;
      if (v60 <= &v56 && (char *)v60 + 24 * v61 > (char *)&v56)
      {
        int64_t v49 = (char *)&v56 - (unsigned char *)v60;
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v60, v63, v43, 24);
        uint64_t v17 = (char *)v60;
        unint64_t v16 = (int *)((char *)v60 + v49);
      }
      else
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v60, v63, v43, 24);
        unint64_t v16 = &v56;
        uint64_t v17 = (char *)v60;
      }
    }
    uint64_t v18 = &v17[24 * v61];
    long long v19 = *(_OWORD *)v16;
    *((void *)v18 + 2) = *((void *)v16 + 2);
    *(_OWORD *)uint64_t v18 = v19;
    uint64_t v20 = ++v61;
    if (v59[0])
    {
      int v56 = 5;
      unint64_t v57 = (const char *)a5;
      uint64_t v21 = &v56;
      uint64_t v22 = (char *)v60;
      if (v20 >= v62)
      {
        unint64_t v44 = v20 + 1;
        BOOL v45 = (char *)v60 + 24 * v20 > (char *)&v56;
        if (v60 <= &v56 && v45)
        {
          int64_t v50 = (char *)&v56 - (unsigned char *)v60;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v60, v63, v44, 24);
          uint64_t v22 = (char *)v60;
          uint64_t v21 = (int *)((char *)v60 + v50);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v60, v63, v44, 24);
          uint64_t v21 = &v56;
          uint64_t v22 = (char *)v60;
        }
      }
      uint64_t v23 = &v22[24 * v61];
      long long v24 = *(_OWORD *)v21;
      *((void *)v23 + 2) = *((void *)v21 + 2);
      *(_OWORD *)uint64_t v23 = v24;
      uint64_t v25 = ++v61;
      if (v59[0])
      {
        int v56 = 3;
        unint64_t v57 = " must be statically shaped tensor of any type values, but got ";
        uint64_t v58 = 62;
        BOOL v26 = &v56;
        BOOL v27 = (char *)v60;
        if (v25 >= v62)
        {
          unint64_t v46 = v25 + 1;
          BOOL v47 = (char *)v60 + 24 * v25 > (char *)&v56;
          if (v60 <= &v56 && v47)
          {
            int64_t v51 = (char *)&v56 - (unsigned char *)v60;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v60, v63, v46, 24);
            BOOL v27 = (char *)v60;
            BOOL v26 = (int *)((char *)v60 + v51);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v60, v63, v46, 24);
            BOOL v26 = &v56;
            BOOL v27 = (char *)v60;
          }
        }
        uint64_t v28 = &v27[24 * v61];
        long long v29 = *(_OWORD *)v26;
        *((void *)v28 + 2) = *((void *)v26 + 2);
        *(_OWORD *)uint64_t v28 = v29;
        ++v61;
        if (v59[0])
        {
          uint64_t v30 = &v56;
          mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v56, (uint64_t)a2);
          unint64_t v31 = (char *)v60;
          if (v61 >= v62)
          {
            unint64_t v48 = v61 + 1;
            if (v60 <= &v56 && (char *)v60 + 24 * v61 > (char *)&v56)
            {
              int64_t v52 = (char *)&v56 - (unsigned char *)v60;
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v60, v63, v48, 24);
              unint64_t v31 = (char *)v60;
              uint64_t v30 = (int *)((char *)v60 + v52);
            }
            else
            {
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v60, v63, v48, 24);
              uint64_t v30 = &v56;
              unint64_t v31 = (char *)v60;
            }
          }
          uint64_t v32 = &v31[24 * v61];
          long long v33 = *(_OWORD *)v30;
          *((void *)v32 + 2) = *((void *)v30 + 2);
          *(_OWORD *)uint64_t v32 = v33;
          ++v61;
        }
      }
    }
  }
  uint64_t v15 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v59);
  if (v59[0]) {
    mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v59);
  }
  if (v68)
  {
    uint64_t v34 = __p;
    if (__p)
    {
      uint64_t v35 = v67;
      uint64_t v36 = __p;
      if (v67 != __p)
      {
        do
          uint64_t v35 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v35 - 1);
        while (v35 != v34);
        uint64_t v36 = __p;
      }
      uint64_t v67 = v34;
      operator delete(v36);
    }
    uint64_t v37 = v64;
    if (v64)
    {
      uint64_t v38 = v65;
      uint64_t v39 = v64;
      if (v65 != v64)
      {
        do
        {
          uint64_t v41 = *--v38;
          uint64_t v40 = v41;
          *uint64_t v38 = 0;
          if (v41) {
            MEMORY[0x21667D390](v40, 0x1000C8077774924);
          }
        }
        while (v38 != v37);
        uint64_t v39 = v64;
      }
      uint64_t v65 = v37;
      operator delete(v39);
    }
    if (v60 != v63) {
      free(v60);
    }
  }
  return v15;
}

uint64_t mlir::tensor::FromElementsOp::parse(uint64_t a1, uint64_t a2)
{
  v63[16] = *MEMORY[0x263EF8340];
  v62[0] = (uint64_t)v63;
  v62[1] = 0x400000000;
  uint64_t v4 = (*(uint64_t (**)(uint64_t))(*(void *)a1 + 40))(a1);
  if (!(*(unsigned __int8 (**)(uint64_t, uint64_t *, void, uint64_t, uint64_t))(*(void *)a1 + 688))(a1, v62, 0, 1, 0xFFFFFFFFLL)|| ((*(void (**)(uint64_t))(*(void *)a1 + 40))(a1), !(*(unsigned __int8 (**)(uint64_t, uint64_t))(*(void *)a1 + 456))(a1, a2 + 112))|| !(*(unsigned __int8 (**)(uint64_t))(*(void *)a1 + 104))(a1)|| (int64_t v50 = 0, !mlir::AsmParser::parseType<mlir::RankedTensorType>(a1, &v50)))
  {
    uint64_t v19 = 0;
    uint64_t v20 = (void *)v62[0];
    if ((void *)v62[0] == v63) {
      return v19;
    }
    goto LABEL_42;
  }
  unint64_t v5 = v50;
  if (*(_UNKNOWN **)(*(void *)v50 + 136) != &mlir::detail::TypeIDResolver<mlir::RankedTensorType,void>::id
    || (uint64_t v6 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*(void *)v50 + 8),
        int64_t v50 = v5,
        uint64_t v51 = v6,
        !mlir::CallOpInterface::getArgOperands((mlir::CallOpInterface *)&v50)))
  {
LABEL_18:
    uint64_t v21 = (*(uint64_t (**)(uint64_t))(*(void *)a1 + 16))(a1);
    __int16 v48 = 257;
    (*(void (**)(void **__return_ptr, uint64_t, uint64_t, void *))(*(void *)a1 + 24))(&v50, a1, v21, v47);
    if (v50)
    {
      LODWORD(v49[0]) = 3;
      v49[1] = "'result' must be statically shaped tensor of any type values, but got ";
      v49[2] = 70;
      uint64_t v22 = (char *)v49;
      uint64_t v23 = (char *)v53;
      if (v54 >= v55)
      {
        unint64_t v43 = v54 + 1;
        if (v53 <= v49 && (char *)v53 + 24 * v54 > (char *)v49)
        {
          int64_t v45 = (char *)v49 - (unsigned char *)v53;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v53, v56, v43, 24);
          uint64_t v23 = (char *)v53;
          uint64_t v22 = (char *)v53 + v45;
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v53, v56, v43, 24);
          uint64_t v22 = (char *)v49;
          uint64_t v23 = (char *)v53;
        }
      }
      long long v24 = &v23[24 * v54];
      long long v25 = *(_OWORD *)v22;
      *((void *)v24 + 2) = *((void *)v22 + 2);
      *(_OWORD *)long long v24 = v25;
      ++v54;
      if (v50)
      {
        BOOL v26 = (char *)v49;
        mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)v49, (uint64_t)v5);
        BOOL v27 = (char *)v53;
        if (v54 >= v55)
        {
          unint64_t v44 = v54 + 1;
          if (v53 <= v49 && (char *)v53 + 24 * v54 > (char *)v49)
          {
            int64_t v46 = (char *)v49 - (unsigned char *)v53;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v53, v56, v44, 24);
            BOOL v27 = (char *)v53;
            BOOL v26 = (char *)v53 + v46;
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v53, v56, v44, 24);
            BOOL v26 = (char *)v49;
            BOOL v27 = (char *)v53;
          }
        }
        uint64_t v28 = &v27[24 * v54];
        long long v29 = *(_OWORD *)v26;
        *((void *)v28 + 2) = *((void *)v26 + 2);
        *(_OWORD *)uint64_t v28 = v29;
        ++v54;
      }
    }
    uint64_t v19 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v50);
    if (v50) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v50);
    }
    if (v61)
    {
      uint64_t v30 = __p;
      if (__p)
      {
        unint64_t v31 = v60;
        uint64_t v32 = __p;
        if (v60 != __p)
        {
          do
            unint64_t v31 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v31 - 1);
          while (v31 != v30);
          uint64_t v32 = __p;
        }
        unsigned int v60 = v30;
        operator delete(v32);
      }
      long long v33 = v57;
      if (v57)
      {
        uint64_t v34 = v58;
        uint64_t v35 = v57;
        if (v58 != v57)
        {
          do
          {
            uint64_t v37 = *--v34;
            uint64_t v36 = v37;
            *uint64_t v34 = 0;
            if (v37) {
              MEMORY[0x21667D390](v36, 0x1000C8077774924);
            }
          }
          while (v34 != v33);
          uint64_t v35 = v57;
        }
        uint64_t v58 = v33;
        operator delete(v35);
      }
      if (v53 != v56) {
        free(v53);
      }
    }
    uint64_t v20 = (void *)v62[0];
    if ((void *)v62[0] != v63) {
      goto LABEL_42;
    }
    return v19;
  }
  uint64_t Shape = (void *)mlir::ShapedType::getShape((mlir::ShapedType *)&v50);
  if (v8)
  {
    uint64_t v9 = 8 * v8;
    while (*Shape != 0x8000000000000000)
    {
      ++Shape;
      v9 -= 8;
      if (!v9) {
        goto LABEL_11;
      }
    }
    goto LABEL_18;
  }
LABEL_11:
  uint64_t v10 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*v5 + 8);
  v47[0] = v5;
  v47[1] = v10;
  mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)v47);
  uint64_t v11 = *(unsigned int *)(a2 + 72);
  if (v11 >= *(_DWORD *)(a2 + 76))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod(a2 + 64, (void *)(a2 + 80), v11 + 1, 8);
    LODWORD(v11) = *(_DWORD *)(a2 + 72);
  }
  *(void *)(*(void *)(a2 + 64) + 8 * v11) = v5;
  ++*(_DWORD *)(a2 + 72);
  v47[0] = v5;
  uint64_t Value = (uint64_t *)mlir::ArrayAttr::getValue((mlir::ArrayAttr *)v47);
  unint64_t NumElements = mlir::ShapedType::getNumElements(Value, v13);
  v49[0] = v5;
  uint64_t RHS = (void *)mlir::AffineBinaryOpExpr::getRHS((mlir::AffineBinaryOpExpr *)v49);
  unint64_t v16 = (unint64_t)RHS;
  int64_t v50 = &v52;
  HIDWORD(v51) = 2;
  if (NumElements < 3)
  {
    if (NumElements)
    {
      int64_t v52 = RHS;
      if (NumElements != 1) {
        uint64_t v53 = RHS;
      }
    }
  }
  else
  {
    LODWORD(v51) = 0;
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v50, &v52, NumElements, 8);
    if (NumElements == 3)
    {
      uint64_t v17 = 3;
      uint64_t v18 = (unint64_t *)v50;
      do
      {
LABEL_50:
        *v18++ = v16;
        --v17;
      }
      while (v17);
      goto LABEL_51;
    }
    uint64_t v18 = (unint64_t *)((char *)v50 + 8 * (NumElements & 0xFFFFFFFFFFFFFFFCLL));
    uint64_t v17 = NumElements & 3;
    int64x2_t v39 = vdupq_n_s64(v16);
    uint64_t v40 = (int64x2_t *)((char *)v50 + 16);
    unint64_t v41 = NumElements & 0xFFFFFFFFFFFFFFFCLL;
    do
    {
      v40[-1] = v39;
      *uint64_t v40 = v39;
      v40 += 2;
      v41 -= 4;
    }
    while (v41);
    if (NumElements != (NumElements & 0xFFFFFFFFFFFFFFFCLL)) {
      goto LABEL_50;
    }
  }
LABEL_51:
  LODWORD(v51) = NumElements;
  char v42 = mlir::OpAsmParser::resolveOperands<llvm::SmallVector<mlir::OpAsmParser::UnresolvedOperand,4u> &,llvm::SmallVector<mlir::Type,1u> &>(a1, v62, (uint64_t)&v50, v4, a2 + 16);
  if (v50 != &v52) {
    free(v50);
  }
  uint64_t v19 = v42 != 0;
  uint64_t v20 = (void *)v62[0];
  if ((void *)v62[0] != v63) {
LABEL_42:
  }
    free(v20);
  return v19;
}

void mlir::tensor::FromElementsOp::print(mlir::Operation **this, mlir::OpAsmPrinter *a2)
{
  v25[4] = *MEMORY[0x263EF8340];
  uint64_t v4 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  unint64_t v5 = (unsigned char *)*((void *)v4 + 4);
  if ((unint64_t)v5 >= *((void *)v4 + 3))
  {
    llvm::raw_ostream::write(v4, 32);
  }
  else
  {
    *((void *)v4 + 4) = v5 + 1;
    unsigned char *v5 = 32;
  }
  uint64_t v6 = *this;
  if ((*((unsigned char *)*this + 46) & 0x80) != 0)
  {
    uint64_t v7 = *((unsigned int *)v6 + 17);
    uint64_t v8 = *((void *)v6 + 9);
  }
  else
  {
    uint64_t v8 = 0;
    uint64_t v7 = 0;
  }
  uint64_t v9 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v23 = ", ";
  uint64_t v24 = 2;
  llvm::interleave<llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator,void mlir::OpAsmPrinter::printOperands<llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator>(llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator,llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator)::{lambda(mlir::Value)#1},void llvm::interleave<llvm::iterator_range<llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator>,void mlir::OpAsmPrinter::printOperands<llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator>(llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator,llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator)::{lambda(mlir::Value)#1},llvm::raw_ostream,mlir::Value>(llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator const&,llvm::raw_ostream &,void mlir::OpAsmPrinter::printOperands<llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator>(llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator,llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator)::{lambda(mlir::Value)#1},llvm::StringRef const&)::{lambda(void)#1},void>(v8, 0, v8, v7, (uint64_t)a2, v9, (uint64_t)&v23);
  uint64_t v23 = v25;
  uint64_t v24 = 0x200000000;
  uint64_t v10 = *this;
  if (*((unsigned char *)*this + 47))
  {
    unint64_t AttrDictionary = mlir::Operation::getAttrDictionary(v10);
    p_unint64_t AttrDictionary = (mlir::ArrayAttr *)&AttrDictionary;
  }
  else
  {
    p_unint64_t AttrDictionary = (mlir::Operation *)((char *)v10 + 56);
  }
  uint64_t Value = mlir::ArrayAttr::getValue(p_AttrDictionary);
  (*(void (**)(mlir::OpAsmPrinter *, uint64_t, uint64_t, void *, void))(*(void *)a2 + 192))(a2, Value, v13, v23, v24);
  uint64_t v14 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v15 = (unsigned char *)*((void *)v14 + 4);
  if ((unint64_t)v15 >= *((void *)v14 + 3))
  {
    llvm::raw_ostream::write(v14, 32);
  }
  else
  {
    *((void *)v14 + 4) = v15 + 1;
    *uint64_t v15 = 32;
  }
  unint64_t v16 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v17 = (unsigned char *)*((void *)v16 + 4);
  if (*((unsigned char **)v16 + 3) == v17)
  {
    llvm::raw_ostream::write(v16, ":", 1uLL);
  }
  else
  {
    *uint64_t v17 = 58;
    ++*((void *)v16 + 4);
  }
  uint64_t v18 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v19 = (unsigned char *)*((void *)v18 + 4);
  if ((unint64_t)v19 >= *((void *)v18 + 3))
  {
    llvm::raw_ostream::write(v18, 32);
  }
  else
  {
    *((void *)v18 + 4) = v19 + 1;
    *uint64_t v19 = 32;
  }
  if (*((_DWORD *)*this + 9)) {
    uint64_t v20 = (uint64_t)*this - 16;
  }
  else {
    uint64_t v20 = 0;
  }
  uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v20, 0);
  (*(void (**)(mlir::OpAsmPrinter *, unint64_t))(*(void *)a2 + 32))(a2, *(void *)(NextResultAtOffset + 8) & 0xFFFFFFFFFFFFFFF8);
  if (v23 != v25) {
    free(v23);
  }
}

uint64_t mlir::tensor::detail::GatherOpGenericAdaptorBase::GatherOpGenericAdaptorBase(uint64_t a1, uint64_t a2)
{
  uint64_t v12 = *MEMORY[0x263EF8340];
  uint64_t v3 = *(void *)(a2 + 56);
  unint64_t v4 = *(unsigned int *)(a2 + 44);
  if (HIBYTE(*(_DWORD *)(a2 + 44))) {
    unint64_t v5 = (_OWORD *)(a2 + 16 * ((v4 >> 23) & 1) + 64);
  }
  else {
    unint64_t v5 = 0;
  }
  unint64_t v6 = v4 & 0x7FFFFF;
  if ((v4 & 0x7FFFFF) != 0)
  {
    uint64_t v7 = ((a2 + 16 * ((v4 >> 23) & 1) + 64 + ((v4 >> 21) & 0x7F8) + 7) & 0xFFFFFFFFFFFFFFF8)
       + 32 * *(unsigned int *)(a2 + 40);
  }
  else
  {
    uint64_t v7 = 0;
    unint64_t v6 = 0;
  }
  mlir::ValueRange::ValueRange(v11, v7, v6);
  *(unsigned char *)(a1 + 8) = 0;
  *(void *)a1 = v3;
  *(unsigned char *)(a1 + 16) = 0;
  long long v8 = *(_OWORD *)v11;
  *(_OWORD *)(a1 + 24) = *v5;
  *(_OWORD *)(a1 + 40) = v8;
  if (v3)
  {
    uint64_t Context = mlir::Attribute::getContext((mlir::Attribute *)a1);
    if (*(unsigned char *)(a1 + 16)) {
      *(unsigned char *)(a1 + 16) = 0;
    }
    mlir::OperationName::OperationName(a1 + 8, "tensor.gather", 13, Context);
    *(unsigned char *)(a1 + 16) = 1;
  }
  return a1;
}

uint64_t mlir::tensor::GatherOp::setPropertiesFromAttr(uint64_t *a1, uint64_t a2, void (*a3)(void *__return_ptr, uint64_t), uint64_t a4)
{
  uint64_t v89 = *MEMORY[0x263EF8340];
  if (*(_UNKNOWN **)(*(void *)a2 + 136) == &mlir::detail::TypeIDResolver<mlir::DictionaryAttr,void>::id) {
    uint64_t v6 = a2;
  }
  else {
    uint64_t v6 = 0;
  }
  uint64_t v75 = v6;
  if (!v6)
  {
    a3(v79, a4);
    if (v79[0])
    {
      int v76 = 3;
      int v77 = "expected DictionaryAttr to set properties";
      uint64_t v78 = 41;
      uint64_t v28 = &v76;
      long long v29 = (char *)v80;
      if (v81 >= v82)
      {
        unint64_t v63 = v81 + 1;
        if (v80 <= &v76 && (char *)v80 + 24 * v81 > (char *)&v76)
        {
          int64_t v69 = (char *)&v76 - (unsigned char *)v80;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v80, v83, v63, 24);
          long long v29 = (char *)v80;
          uint64_t v28 = (int *)((char *)v80 + v69);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v80, v83, v63, 24);
          uint64_t v28 = &v76;
          long long v29 = (char *)v80;
        }
      }
      uint64_t v30 = &v29[24 * v81];
      long long v31 = *(_OWORD *)v28;
      *((void *)v30 + 2) = *((void *)v28 + 2);
      *(_OWORD *)uint64_t v30 = v31;
      ++v81;
      if (v79[0]) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v79);
      }
    }
    if (!v88) {
      return 0;
    }
    uint64_t v32 = __p;
    if (__p)
    {
      long long v33 = v87;
      uint64_t v34 = __p;
      if (v87 != __p)
      {
        do
          long long v33 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v33 - 1);
        while (v33 != v32);
        uint64_t v34 = __p;
      }
      uint64_t v87 = v32;
      operator delete(v34);
    }
    uint64_t v23 = v84;
    if (!v84) {
      goto LABEL_79;
    }
    uint64_t v35 = v85;
    long long v25 = v84;
    if (v85 == v84) {
      goto LABEL_78;
    }
    do
    {
      uint64_t v37 = *--v35;
      uint64_t v36 = v37;
      *uint64_t v35 = 0;
      if (v37) {
        MEMORY[0x21667D390](v36, 0x1000C8077774924);
      }
    }
    while (v35 != v23);
    goto LABEL_77;
  }
  long long v8 = (void *)mlir::DictionaryAttr::get((uint64_t)&v75, "gather_dims", 0xBuLL);
  if (!v8)
  {
    a3(v79, a4);
    if (v79[0])
    {
      int v76 = 3;
      int v77 = "expected key entry for gather_dims in DictionaryAttr to set Properties.";
      uint64_t v78 = 71;
      uint64_t v38 = &v76;
      int64x2_t v39 = (char *)v80;
      if (v81 >= v82)
      {
        unint64_t v64 = v81 + 1;
        if (v80 <= &v76 && (char *)v80 + 24 * v81 > (char *)&v76)
        {
          int64_t v70 = (char *)&v76 - (unsigned char *)v80;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v80, v83, v64, 24);
          int64x2_t v39 = (char *)v80;
          uint64_t v38 = (int *)((char *)v80 + v70);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v80, v83, v64, 24);
          uint64_t v38 = &v76;
          int64x2_t v39 = (char *)v80;
        }
      }
      uint64_t v40 = &v39[24 * v81];
      long long v41 = *(_OWORD *)v38;
      *((void *)v40 + 2) = *((void *)v38 + 2);
      *(_OWORD *)uint64_t v40 = v41;
      ++v81;
      if (v79[0]) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v79);
      }
    }
    if (!v88) {
      return 0;
    }
    char v42 = __p;
    if (__p)
    {
      unint64_t v43 = v87;
      unint64_t v44 = __p;
      if (v87 != __p)
      {
        do
          unint64_t v43 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v43 - 1);
        while (v43 != v42);
        unint64_t v44 = __p;
      }
      uint64_t v87 = v42;
      operator delete(v44);
    }
    uint64_t v23 = v84;
    if (!v84) {
      goto LABEL_79;
    }
    int64_t v45 = v85;
    long long v25 = v84;
    if (v85 == v84) {
      goto LABEL_78;
    }
    do
    {
      uint64_t v47 = *--v45;
      uint64_t v46 = v47;
      *int64_t v45 = 0;
      if (v47) {
        MEMORY[0x21667D390](v46, 0x1000C8077774924);
      }
    }
    while (v45 != v23);
    goto LABEL_77;
  }
  uint64_t v9 = (uint64_t)v8;
  if (!mlir::detail::DenseArrayAttrImpl<long long>::classof(v8))
  {
    a3(v79, a4);
    if (v79[0])
    {
      int v76 = 3;
      uint64_t v78 = 56;
      __int16 v48 = &v76;
      int64_t v49 = (char *)v80;
      if (v81 >= v82)
      {
        unint64_t v65 = v81 + 1;
        if (v80 <= &v76 && (char *)v80 + 24 * v81 > (char *)&v76)
        {
          int64_t v71 = (char *)&v76 - (unsigned char *)v80;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v80, v83, v65, 24);
          int64_t v49 = (char *)v80;
          __int16 v48 = (int *)((char *)v80 + v71);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v80, v83, v65, 24);
          __int16 v48 = &v76;
          int64_t v49 = (char *)v80;
        }
      }
      int64_t v50 = &v49[24 * v81];
      long long v51 = *(_OWORD *)v48;
      *((void *)v50 + 2) = *((void *)v48 + 2);
      *(_OWORD *)int64_t v50 = v51;
      ++v81;
      if (v79[0])
      {
        int64_t v52 = &v76;
        mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v76, v9);
        uint64_t v53 = (char *)v80;
        if (v81 >= v82)
        {
          unint64_t v66 = v81 + 1;
          if (v80 <= &v76 && (char *)v80 + 24 * v81 > (char *)&v76)
          {
            int64_t v72 = (char *)&v76 - (unsigned char *)v80;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v80, v83, v66, 24);
            uint64_t v53 = (char *)v80;
            int64_t v52 = (int *)((char *)v80 + v72);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v80, v83, v66, 24);
            int64_t v52 = &v76;
            uint64_t v53 = (char *)v80;
          }
        }
        unsigned int v54 = &v53[24 * v81];
        long long v55 = *(_OWORD *)v52;
        *((void *)v54 + 2) = *((void *)v52 + 2);
        *(_OWORD *)unsigned int v54 = v55;
        ++v81;
        if (v79[0]) {
          mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v79);
        }
      }
    }
    if (!v88) {
      return 0;
    }
    int v56 = __p;
    if (__p)
    {
      unint64_t v57 = v87;
      uint64_t v58 = __p;
      if (v87 != __p)
      {
        do
          unint64_t v57 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v57 - 1);
        while (v57 != v56);
        uint64_t v58 = __p;
      }
      uint64_t v87 = v56;
      operator delete(v58);
    }
    uint64_t v23 = v84;
    if (!v84) {
      goto LABEL_79;
    }
    uint64_t v59 = v85;
    long long v25 = v84;
    if (v85 == v84) {
      goto LABEL_78;
    }
    do
    {
      uint64_t v61 = *--v59;
      uint64_t v60 = v61;
      *uint64_t v59 = 0;
      if (v61) {
        MEMORY[0x21667D390](v60, 0x1000C8077774924);
      }
    }
    while (v59 != v23);
    goto LABEL_77;
  }
  *a1 = v9;
  uint64_t v10 = mlir::DictionaryAttr::get((uint64_t)&v75, "unique", 6uLL);
  if (!v10) {
    return 1;
  }
  uint64_t v11 = v10;
  if (*(_UNKNOWN **)(*(void *)v10 + 136) == &mlir::detail::TypeIDResolver<mlir::UnitAttr,void>::id)
  {
    a1[1] = v10;
    return 1;
  }
  a3(v79, a4);
  if (v79[0])
  {
    int v76 = 3;
    uint64_t v78 = 51;
    uint64_t v12 = &v76;
    uint64_t v13 = (char *)v80;
    if (v81 >= v82)
    {
      unint64_t v67 = v81 + 1;
      if (v80 <= &v76 && (char *)v80 + 24 * v81 > (char *)&v76)
      {
        int64_t v73 = (char *)&v76 - (unsigned char *)v80;
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v80, v83, v67, 24);
        uint64_t v13 = (char *)v80;
        uint64_t v12 = (int *)((char *)v80 + v73);
      }
      else
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v80, v83, v67, 24);
        uint64_t v12 = &v76;
        uint64_t v13 = (char *)v80;
      }
    }
    uint64_t v14 = &v13[24 * v81];
    long long v15 = *(_OWORD *)v12;
    *((void *)v14 + 2) = *((void *)v12 + 2);
    *(_OWORD *)uint64_t v14 = v15;
    ++v81;
    if (v79[0])
    {
      unint64_t v16 = &v76;
      mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v76, v11);
      uint64_t v17 = (char *)v80;
      if (v81 >= v82)
      {
        unint64_t v68 = v81 + 1;
        if (v80 <= &v76 && (char *)v80 + 24 * v81 > (char *)&v76)
        {
          int64_t v74 = (char *)&v76 - (unsigned char *)v80;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v80, v83, v68, 24);
          uint64_t v17 = (char *)v80;
          unint64_t v16 = (int *)((char *)v80 + v74);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v80, v83, v68, 24);
          unint64_t v16 = &v76;
          uint64_t v17 = (char *)v80;
        }
      }
      uint64_t v18 = &v17[24 * v81];
      long long v19 = *(_OWORD *)v16;
      *((void *)v18 + 2) = *((void *)v16 + 2);
      *(_OWORD *)uint64_t v18 = v19;
      ++v81;
      if (v79[0]) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v79);
      }
    }
  }
  if (v88)
  {
    uint64_t v20 = __p;
    if (__p)
    {
      uint64_t v21 = v87;
      uint64_t v22 = __p;
      if (v87 != __p)
      {
        do
          uint64_t v21 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v21 - 1);
        while (v21 != v20);
        uint64_t v22 = __p;
      }
      uint64_t v87 = v20;
      operator delete(v22);
    }
    uint64_t v23 = v84;
    if (!v84) {
      goto LABEL_79;
    }
    uint64_t v24 = v85;
    long long v25 = v84;
    if (v85 == v84)
    {
LABEL_78:
      BOOL v85 = v23;
      operator delete(v25);
LABEL_79:
      if (v80 != v83) {
        free(v80);
      }
      return 0;
    }
    do
    {
      uint64_t v27 = *--v24;
      uint64_t v26 = v27;
      *uint64_t v24 = 0;
      if (v27) {
        MEMORY[0x21667D390](v26, 0x1000C8077774924);
      }
    }
    while (v24 != v23);
LABEL_77:
    long long v25 = v84;
    goto LABEL_78;
  }
  return 0;
}

uint64_t mlir::tensor::GatherOp::getPropertiesAsAttr(mlir::DictionaryAttr *a1, uint64_t *a2)
{
  v21[6] = *MEMORY[0x263EF8340];
  uint64_t v18 = a1;
  long long v19 = v21;
  uint64_t v20 = 0x300000000;
  if (*a2)
  {
    uint64_t NamedAttr = mlir::Builder::getNamedAttr(&v18, (uint64_t)"gather_dims", 11, *a2);
    uint64_t v5 = v4;
    unsigned int v6 = v20;
    if (v20 >= HIDWORD(v20))
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v19, v21, v20 + 1, 16);
      unsigned int v6 = v20;
    }
    uint64_t v7 = (uint64_t *)((char *)v19 + 16 * v6);
    *uint64_t v7 = NamedAttr;
    v7[1] = v5;
    unsigned int v8 = v20 + 1;
    LODWORD(v20) = v20 + 1;
    uint64_t v9 = a2[1];
    if (!v9)
    {
LABEL_5:
      uint64_t v10 = (uint64_t *)v19;
      if (v8) {
        goto LABEL_6;
      }
LABEL_13:
      uint64_t DictionaryAttr = 0;
      if (v10 == v21) {
        return DictionaryAttr;
      }
      goto LABEL_7;
    }
  }
  else
  {
    unsigned int v8 = 0;
    uint64_t v9 = a2[1];
    if (!v9) {
      goto LABEL_5;
    }
  }
  uint64_t v13 = mlir::Builder::getNamedAttr(&v18, (uint64_t)"unique", 6, v9);
  uint64_t v15 = v14;
  unsigned int v16 = v20;
  if (v20 >= HIDWORD(v20))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v19, v21, v20 + 1, 16);
    unsigned int v16 = v20;
  }
  uint64_t v17 = (uint64_t *)((char *)v19 + 16 * v16);
  *uint64_t v17 = v13;
  v17[1] = v15;
  unsigned int v8 = v20 + 1;
  LODWORD(v20) = v8;
  uint64_t v10 = (uint64_t *)v19;
  if (!v8) {
    goto LABEL_13;
  }
LABEL_6:
  uint64_t DictionaryAttr = mlir::Builder::getDictionaryAttr(&v18, v10, v8);
  uint64_t v10 = (uint64_t *)v19;
  if (v19 != v21) {
LABEL_7:
  }
    free(v10);
  return DictionaryAttr;
}

uint64_t mlir::tensor::GatherOp::getInherentAttr(int a1, void *a2, char *__s1, size_t __n)
{
  if (__n == 6)
  {
    if (memcmp(__s1, "unique", 6uLL)) {
      return 0;
    }
    return a2[1];
  }
  else
  {
    if (__n != 11) {
      return 0;
    }
    if (*(void *)__s1 != 0x645F726568746167 || *(void *)(__s1 + 3) != 0x736D69645F726568) {
      return 0;
    }
    return *a2;
  }
}

uint64_t mlir::tensor::GatherOp::setInherentAttr(uint64_t result, char *__s1, uint64_t a3, void *a4)
{
  uint64_t v5 = (void *)result;
  if (a3 == 6)
  {
    uint64_t result = memcmp(__s1, "unique", 6uLL);
    if (!result)
    {
      if (a4)
      {
        if (*(_UNKNOWN **)(*a4 + 136) == &mlir::detail::TypeIDResolver<mlir::UnitAttr,void>::id) {
          uint64_t v7 = a4;
        }
        else {
          uint64_t v7 = 0;
        }
        v5[1] = v7;
      }
      else
      {
        v5[1] = 0;
      }
    }
  }
  else if (a3 == 11 && *(void *)__s1 == 0x645F726568746167 && *(void *)(__s1 + 3) == 0x736D69645F726568)
  {
    if (a4)
    {
      uint64_t result = mlir::detail::DenseArrayAttrImpl<long long>::classof(a4);
      if (result) {
        unsigned int v8 = a4;
      }
      else {
        unsigned int v8 = 0;
      }
      void *v5 = v8;
    }
    else
    {
      *(void *)uint64_t result = 0;
    }
  }
  return result;
}

void mlir::tensor::GatherOp::populateInherentAttrs(uint64_t a1, uint64_t *a2, uint64_t a3)
{
  if (*a2) {
    mlir::NamedAttrList::append(a3, (uint64_t)"gather_dims", 11, *a2);
  }
  uint64_t v5 = a2[1];
  if (v5)
  {
    mlir::NamedAttrList::append(a3, (uint64_t)"unique", 6, v5);
  }
}

BOOL mlir::tensor::GatherOp::verifyInherentAttrs(uint64_t a1, uint64_t a2, void (*a3)(uint64_t *__return_ptr, uint64_t), uint64_t a4)
{
  unsigned int v8 = (void *)mlir::NamedAttrList::get(a2, **(void **)(a1 + 96));
  BOOL result = 0;
  if (!v8
    || mlir::memref::__mlir_ods_local_attr_constraint_MemRefOps12(v8, (void **)"gather_dims", (const char *)0xB, a3, a4))
  {
    uint64_t v9 = mlir::NamedAttrList::get(a2, *(void *)(*(void *)(a1 + 96) + 8));
    if (!v9
      || mlir::memref::__mlir_ods_local_attr_constraint_MemRefOps9(v9, (void **)"unique", (const char *)6, a3, a4))
    {
      return 1;
    }
  }
  return result;
}

BOOL mlir::tensor::GatherOp::readProperties(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = (void *)mlir::OperationState::getOrAddProperties<mlir::tensor::detail::GatherOpGenericAdaptorBase::Properties>(a2);
  return mlir::DialectBytecodeReader::readAttribute<mlir::detail::DenseArrayAttrImpl<long long>>(a1, v3)&& mlir::DialectBytecodeReader::readOptionalAttribute<mlir::UnitAttr>(a1, v3 + 1) != 0;
}

uint64_t mlir::OperationState::getOrAddProperties<mlir::tensor::detail::GatherOpGenericAdaptorBase::Properties>(uint64_t a1)
{
  uint64_t result = *(void *)(a1 + 256);
  if (!result) {
    operator new();
  }
  return result;
}

uint64_t mlir::tensor::GatherOp::writeProperties(uint64_t a1, uint64_t a2)
{
  if (HIBYTE(*(_DWORD *)(*(void *)a1 + 44))) {
    uint64_t v3 = (void *)(*(void *)a1 + 16 * (((unint64_t)*(unsigned int *)(*(void *)a1 + 44) >> 23) & 1) + 64);
  }
  else {
    uint64_t v3 = 0;
  }
  (*(void (**)(uint64_t, void))(*(void *)a2 + 16))(a2, *v3);
  uint64_t v4 = v3[1];
  uint64_t v5 = *(uint64_t (**)(uint64_t, uint64_t))(*(void *)a2 + 24);

  return v5(a2, v4);
}

BOOL mlir::tensor::GatherOp::verifyInvariantsImpl(mlir::tensor::GatherOp *this)
{
  uint64_t v28 = *MEMORY[0x263EF8340];
  uint64_t v2 = *(void *)this;
  if (HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
    unint64_t v3 = *(void *)this + 16 * (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 23) & 1) + 64;
  }
  else {
    unint64_t v3 = 0;
  }
  uint64_t v4 = *(void **)v3;
  if (*(void *)v3)
  {
    uint64_t v5 = *(void *)(v3 + 8);
    v20[0] = v2;
    if (mlir::memref::__mlir_ods_local_attr_constraint_MemRefOps12(v4, (void **)"gather_dims", (const char *)0xB, (void (*)(uint64_t *__return_ptr, uint64_t))llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::__mlir_ods_local_attr_constraint_TensorOps1(mlir::Operation *,mlir::Attribute,llvm::StringRef)::$_0>, (uint64_t)v20)&& (v20[0] = *(void *)this, mlir::memref::__mlir_ods_local_attr_constraint_MemRefOps9(v5, (void **)"unique", (const char *)6, (void (*)(uint64_t *__return_ptr, uint64_t))llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::__mlir_ods_local_attr_constraint_TensorOps2(mlir::Operation *,mlir::Attribute,llvm::StringRef)::$_0>, (uint64_t)v20))&& mlir::tensor::__mlir_ods_local_type_constraint_TensorOps1(*(void *)this, *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"operand", (void **)7, 0)&& mlir::tensor::__mlir_ods_local_type_constraint_TensorOps8(
                            *(void *)this,
                            *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 56) + 8) & 0xFFFFFFFFFFFFFFF8,
                            (void **)"operand",
                            (void **)7,
                            1u))
    {
      if (*(_DWORD *)(*(void *)this + 36)) {
        uint64_t v6 = *(void *)this - 16;
      }
      else {
        uint64_t v6 = 0;
      }
      uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v6, 0);
      return mlir::tensor::__mlir_ods_local_type_constraint_TensorOps1(*(void *)this, *(void *)(NextResultAtOffset + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"result", (void **)6, 0) != 0;
    }
    else
    {
      return 0;
    }
  }
  else
  {
    uint64_t v18 = (void **)"requires attribute 'gather_dims'";
    __int16 v19 = 259;
    mlir::OpState::emitOpError((uint64_t *)this, &v18, (uint64_t)v20);
    uint64_t v8 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v20);
    if (v20[0]) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v20);
    }
    if (v27)
    {
      uint64_t v9 = __p;
      if (__p)
      {
        uint64_t v10 = v26;
        uint64_t v11 = __p;
        if (v26 != __p)
        {
          do
            uint64_t v10 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v10 - 1);
          while (v10 != v9);
          uint64_t v11 = __p;
        }
        uint64_t v26 = v9;
        operator delete(v11);
      }
      uint64_t v12 = v23;
      if (v23)
      {
        uint64_t v13 = v24;
        uint64_t v14 = v23;
        if (v24 != v23)
        {
          do
          {
            uint64_t v16 = *--v13;
            uint64_t v15 = v16;
            *uint64_t v13 = 0;
            if (v16) {
              MEMORY[0x21667D390](v15, 0x1000C8077774924);
            }
          }
          while (v13 != v12);
          uint64_t v14 = v23;
        }
        uint64_t v24 = v12;
        operator delete(v14);
      }
      if (v21 != &v22) {
        free(v21);
      }
    }
  }
  return v8;
}

uint64_t mlir::tensor::__mlir_ods_local_type_constraint_TensorOps8(uint64_t a1, uint64_t a2, void **a3, void **a4, unsigned int a5)
{
  uint64_t v64 = *MEMORY[0x263EF8340];
  uint64_t v10 = *(void *)a2;
  if (*(_UNKNOWN **)(*(void *)a2 + 136) == &mlir::detail::TypeIDResolver<mlir::RankedTensorType,void>::id)
  {
    v54[0] = a2;
    v54[1] = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(v10 + 8);
    v49[0] = (void **)mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)v54);
    if (mlir::Type::isSignlessIntOrIndex((mlir::Type *)v49)) {
      return 1;
    }
  }
  __int16 v50 = 261;
  v49[0] = a3;
  v49[1] = a4;
  mlir::Operation::emitOpError(a1, v49, (uint64_t)v54);
  if (v54[0])
  {
    int v51 = 3;
    int64_t v52 = " #";
    uint64_t v53 = 2;
    uint64_t v12 = &v51;
    uint64_t v13 = (char *)v55;
    if (v56 >= v57)
    {
      unint64_t v39 = v56 + 1;
      if (v55 <= &v51 && (char *)v55 + 24 * v56 > (char *)&v51)
      {
        int64_t v45 = (char *)&v51 - (unsigned char *)v55;
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v55, v58, v39, 24);
        uint64_t v13 = (char *)v55;
        uint64_t v12 = (int *)((char *)v55 + v45);
      }
      else
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v55, v58, v39, 24);
        uint64_t v12 = &v51;
        uint64_t v13 = (char *)v55;
      }
    }
    uint64_t v14 = &v13[24 * v56];
    long long v15 = *(_OWORD *)v12;
    *((void *)v14 + 2) = *((void *)v12 + 2);
    *(_OWORD *)uint64_t v14 = v15;
    uint64_t v16 = ++v56;
    if (v54[0])
    {
      int v51 = 5;
      int64_t v52 = (const char *)a5;
      uint64_t v17 = &v51;
      uint64_t v18 = (char *)v55;
      if (v16 >= v57)
      {
        unint64_t v40 = v16 + 1;
        BOOL v41 = (char *)v55 + 24 * v16 > (char *)&v51;
        if (v55 <= &v51 && v41)
        {
          int64_t v46 = (char *)&v51 - (unsigned char *)v55;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v55, v58, v40, 24);
          uint64_t v18 = (char *)v55;
          uint64_t v17 = (int *)((char *)v55 + v46);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v55, v58, v40, 24);
          uint64_t v17 = &v51;
          uint64_t v18 = (char *)v55;
        }
      }
      __int16 v19 = &v18[24 * v56];
      long long v20 = *(_OWORD *)v17;
      *((void *)v19 + 2) = *((void *)v17 + 2);
      *(_OWORD *)__int16 v19 = v20;
      uint64_t v21 = ++v56;
      if (v54[0])
      {
        int v51 = 3;
        int64_t v52 = " must be ranked tensor of signless integer or index values, but got ";
        uint64_t v53 = 68;
        uint64_t v22 = &v51;
        uint64_t v23 = (char *)v55;
        if (v21 >= v57)
        {
          unint64_t v42 = v21 + 1;
          BOOL v43 = (char *)v55 + 24 * v21 > (char *)&v51;
          if (v55 <= &v51 && v43)
          {
            int64_t v47 = (char *)&v51 - (unsigned char *)v55;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v55, v58, v42, 24);
            uint64_t v23 = (char *)v55;
            uint64_t v22 = (int *)((char *)v55 + v47);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v55, v58, v42, 24);
            uint64_t v22 = &v51;
            uint64_t v23 = (char *)v55;
          }
        }
        uint64_t v24 = &v23[24 * v56];
        long long v25 = *(_OWORD *)v22;
        *((void *)v24 + 2) = *((void *)v22 + 2);
        *(_OWORD *)uint64_t v24 = v25;
        ++v56;
        if (v54[0])
        {
          uint64_t v26 = &v51;
          mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v51, a2);
          char v27 = (char *)v55;
          if (v56 >= v57)
          {
            unint64_t v44 = v56 + 1;
            if (v55 <= &v51 && (char *)v55 + 24 * v56 > (char *)&v51)
            {
              int64_t v48 = (char *)&v51 - (unsigned char *)v55;
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v55, v58, v44, 24);
              char v27 = (char *)v55;
              uint64_t v26 = (int *)((char *)v55 + v48);
            }
            else
            {
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v55, v58, v44, 24);
              uint64_t v26 = &v51;
              char v27 = (char *)v55;
            }
          }
          uint64_t v28 = &v27[24 * v56];
          long long v29 = *(_OWORD *)v26;
          *((void *)v28 + 2) = *((void *)v26 + 2);
          *(_OWORD *)uint64_t v28 = v29;
          ++v56;
        }
      }
    }
  }
  uint64_t v11 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v54);
  if (v54[0]) {
    mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v54);
  }
  if (v63)
  {
    uint64_t v30 = __p;
    if (__p)
    {
      long long v31 = v62;
      uint64_t v32 = __p;
      if (v62 != __p)
      {
        do
          long long v31 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v31 - 1);
        while (v31 != v30);
        uint64_t v32 = __p;
      }
      unsigned int v62 = v30;
      operator delete(v32);
    }
    long long v33 = v59;
    if (v59)
    {
      uint64_t v34 = v60;
      uint64_t v35 = v59;
      if (v60 != v59)
      {
        do
        {
          uint64_t v37 = *--v34;
          uint64_t v36 = v37;
          *uint64_t v34 = 0;
          if (v37) {
            MEMORY[0x21667D390](v36, 0x1000C8077774924);
          }
        }
        while (v34 != v33);
        uint64_t v35 = v59;
      }
      uint64_t v60 = v33;
      operator delete(v35);
    }
    if (v55 != v58) {
      free(v55);
    }
  }
  return v11;
}

BOOL mlir::tensor::GatherOp::parse(uint64_t *a1, uint64_t a2)
{
  v25[4] = *MEMORY[0x263EF8340];
  memset(v25, 0, 24);
  v19[0] = v25;
  v19[1] = 1;
  memset(v24, 0, 24);
  v18[0] = v24;
  v18[1] = 1;
  uint64_t v16 = 0;
  uint64_t v17 = 0;
  uint64_t Inputs = 0;
  (*(void (**)(uint64_t *))(*a1 + 40))(a1);
  if (!(*(unsigned __int8 (**)(uint64_t *, void *, uint64_t))(*a1 + 672))(a1, v25, 1)) {
    return 0;
  }
  if (!(*(unsigned __int8 (**)(uint64_t *))(*a1 + 296))(a1)) {
    return 0;
  }
  (*(void (**)(uint64_t *))(*a1 + 40))(a1);
  if (!(*(unsigned __int8 (**)(uint64_t *, void *, uint64_t))(*a1 + 672))(a1, v24, 1)) {
    return 0;
  }
  if (!(*(unsigned __int8 (**)(uint64_t *))(*a1 + 312))(a1)) {
    return 0;
  }
  __int16 v23 = 257;
  if (!(*(unsigned __int8 (**)(uint64_t *, const char *, uint64_t, uint64_t **))(*a1 + 368))(a1, "gather_dims", 11, &v20)|| !(*(unsigned __int8 (**)(uint64_t *))(*a1 + 264))(a1)|| !mlir::AsmParser::parseCustomAttributeWithFallback<mlir::detail::DenseArrayAttrImpl<long long>>((uint64_t)a1, &v17, 0))
  {
    return 0;
  }
  if (v17)
  {
    uint64_t v4 = (void *)mlir::OperationState::getOrAddProperties<mlir::tensor::detail::GatherOpGenericAdaptorBase::Properties>(a2);
    *uint64_t v4 = v17;
  }
  if (!(*(unsigned __int8 (**)(uint64_t *))(*a1 + 280))(a1)) {
    return 0;
  }
  if ((*(unsigned __int8 (**)(uint64_t *, const char *, uint64_t))(*a1 + 376))(a1, "unique", 6))
  {
    uint64_t v5 = (mlir::UnitAttr **)(*(uint64_t (**)(uint64_t *))(*a1 + 32))(a1);
    uint64_t UnitAttr = mlir::Builder::getUnitAttr(v5, v6);
    *(void *)(mlir::OperationState::getOrAddProperties<mlir::tensor::detail::GatherOpGenericAdaptorBase::Properties>(a2)
              + 8) = UnitAttr;
  }
  uint64_t v14 = (*(uint64_t (**)(uint64_t *))(*a1 + 40))(a1);
  if (!(*(unsigned __int8 (**)(uint64_t *, uint64_t))(*a1 + 456))(a1, a2 + 112)) {
    return 0;
  }
  uint64_t v8 = *(void *)(a2 + 8);
  long long v20 = a1;
  uint64_t v21 = &v14;
  uint64_t v22 = a2;
  if (!mlir::tensor::GatherOp::verifyInherentAttrs(v8, a2 + 112, (void (*)(uint64_t *__return_ptr, uint64_t))llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::GatherOp::parse(mlir::OpAsmParser &,mlir::OperationState &)::$_0>, (uint64_t)&v20))return 0; {
  if (!(*(unsigned __int8 (**)(uint64_t *))(*a1 + 104))(a1))
  }
    return 0;
  uint64_t v14 = 0;
  if (!mlir::AsmParser::parseType<mlir::FunctionType>((uint64_t)a1, &v14)) {
    return 0;
  }
  uint64_t Inputs = mlir::FunctionType::getInputs((mlir::FunctionType *)&v14);
  uint64_t v16 = v9;
  Results = (void *)mlir::FunctionType::getResults((mlir::FunctionType *)&v14);
  mlir::OperationState::addTypes(a2, Results, v11);
  long long v20 = v19;
  uint64_t v21 = v18;
  uint64_t v12 = (*(uint64_t (**)(uint64_t *))(*a1 + 16))(a1);
  return mlir::OpAsmParser::resolveOperands<llvm::detail::concat_range<mlir::OpAsmParser::UnresolvedOperand const,llvm::ArrayRef<mlir::OpAsmParser::UnresolvedOperand> &,llvm::ArrayRef<mlir::OpAsmParser::UnresolvedOperand> &>,llvm::ArrayRef<mlir::Type> &>((uint64_t)a1, &v20, &Inputs, v12, a2 + 16) != 0;
}

uint64_t mlir::AsmParser::parseCustomAttributeWithFallback<mlir::detail::DenseArrayAttrImpl<long long>>(uint64_t a1, void *a2, uint64_t a3)
{
  uint64_t v30 = *MEMORY[0x263EF8340];
  uint64_t v6 = (*(uint64_t (**)(uint64_t))(*(void *)a1 + 40))(a1);
  uint64_t v21 = 0;
  v22[0] = a1;
  if (!(*(unsigned __int8 (**)(uint64_t, void **, uint64_t, BOOL (*)(mlir::AsmParser **, uint64_t *), void *))(*(void *)a1 + 416))(a1, &v21, a3, _ZN4llvm12function_refIFN4mlir11ParseResultERNS1_9AttributeENS1_4TypeEEE11callback_fnIZNS1_9AsmParser32parseCustomAttributeWithFallbackINS1_6detail18DenseArrayAttrImplIxEEEENSt3__19enable_ifIXsr23detect_has_parse_methodIT_EE5valueES2_E4typeERSG_S5_EUlS4_S5_E_EES2_lS4_S5_, v22))return 0; {
  uint64_t v7 = v21;
  }
  if (mlir::detail::DenseArrayAttrImpl<long long>::classof(v21)) {
    uint64_t v8 = v7;
  }
  else {
    uint64_t v8 = 0;
  }
  *a2 = v8;
  if (v8) {
    return 1;
  }
  __int16 v19 = "invalid kind of attribute specified";
  __int16 v20 = 259;
  (*(void (**)(void *__return_ptr, uint64_t, uint64_t, const char **))(*(void *)a1 + 24))(v22, a1, v6, &v19);
  uint64_t v9 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v22);
  if (v22[0]) {
    mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v22);
  }
  if (v29)
  {
    uint64_t v11 = __p;
    if (__p)
    {
      uint64_t v12 = v28;
      uint64_t v13 = __p;
      if (v28 != __p)
      {
        do
          uint64_t v12 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v12 - 1);
        while (v12 != v11);
        uint64_t v13 = __p;
      }
      uint64_t v28 = v11;
      operator delete(v13);
    }
    uint64_t v14 = v25;
    if (v25)
    {
      long long v15 = v26;
      uint64_t v16 = v25;
      if (v26 != v25)
      {
        do
        {
          uint64_t v18 = *--v15;
          uint64_t v17 = v18;
          *long long v15 = 0;
          if (v18) {
            MEMORY[0x21667D390](v17, 0x1000C8077774924);
          }
        }
        while (v15 != v14);
        uint64_t v16 = v25;
      }
      uint64_t v26 = v14;
      operator delete(v16);
    }
    if (v23 != &v24) {
      free(v23);
    }
  }
  return v9;
}

void mlir::tensor::GatherOp::print(mlir::Operation **this, mlir::OpAsmPrinter *a2)
{
  v45[4] = *MEMORY[0x263EF8340];
  uint64_t v4 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v5 = (unsigned char *)*((void *)v4 + 4);
  if ((unint64_t)v5 >= *((void *)v4 + 3))
  {
    llvm::raw_ostream::write(v4, 32);
  }
  else
  {
    *((void *)v4 + 4) = v5 + 1;
    unsigned char *v5 = 32;
  }
  (*(void (**)(mlir::OpAsmPrinter *, void))(*(void *)a2 + 160))(a2, *(void *)(*((void *)*this + 9) + 24));
  uint64_t v6 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v7 = (unsigned char *)*((void *)v6 + 4);
  if (*((unsigned char **)v6 + 3) == v7)
  {
    llvm::raw_ostream::write(v6, "[", 1uLL);
  }
  else
  {
    *uint64_t v7 = 91;
    ++*((void *)v6 + 4);
  }
  (*(void (**)(mlir::OpAsmPrinter *, void))(*(void *)a2 + 160))(a2, *(void *)(*((void *)*this + 9) + 56));
  uint64_t v8 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v9 = (unsigned char *)*((void *)v8 + 4);
  if (*((unsigned char **)v8 + 3) == v9)
  {
    llvm::raw_ostream::write(v8, "]", 1uLL);
  }
  else
  {
    *uint64_t v9 = 93;
    ++*((void *)v8 + 4);
  }
  uint64_t v10 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v11 = (unsigned char *)*((void *)v10 + 4);
  if ((unint64_t)v11 >= *((void *)v10 + 3))
  {
    llvm::raw_ostream::write(v10, 32);
  }
  else
  {
    *((void *)v10 + 4) = v11 + 1;
    *uint64_t v11 = 32;
  }
  uint64_t v12 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v13 = *((void *)v12 + 4);
  if ((unint64_t)(*((void *)v12 + 3) - v13) > 0xA)
  {
    *(_DWORD *)(v13 + 7) = 1936550244;
    *(void *)uint64_t v13 = *(void *)"gather_dims";
    *((void *)v12 + 4) += 11;
  }
  else
  {
    llvm::raw_ostream::write(v12, "gather_dims", 0xBuLL);
  }
  uint64_t v14 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  long long v15 = (unsigned char *)*((void *)v14 + 4);
  if (*((unsigned char **)v14 + 3) == v15)
  {
    llvm::raw_ostream::write(v14, "(", 1uLL);
  }
  else
  {
    *long long v15 = 40;
    ++*((void *)v14 + 4);
  }
  BOOL v43 = (void *)*((void *)*this + 2 * (((unint64_t)*((unsigned int *)*this + 11) >> 23) & 1) + 8);
  if (!(*(unsigned __int8 (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 104))(a2))
  {
    uint64_t v16 = (void *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
    uint64_t v17 = (*(uint64_t (**)(void *))(*v16 + 80))(v16) + v16[4] - v16[2];
    mlir::detail::DenseArrayAttrImpl<long long>::print((llvm::raw_ostream *)&v43, (uint64_t)a2);
    if (v17 == (*(uint64_t (**)(void *))(*v16 + 80))(v16) + v16[4] - v16[2]) {
      (*(void (**)(mlir::OpAsmPrinter *, void *))(*(void *)a2 + 40))(a2, v43);
    }
  }
  uint64_t v18 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  __int16 v19 = (unsigned char *)*((void *)v18 + 4);
  if (*((unsigned char **)v18 + 3) == v19)
  {
    llvm::raw_ostream::write(v18, ")", 1uLL);
  }
  else
  {
    *__int16 v19 = 41;
    ++*((void *)v18 + 4);
  }
  unint64_t v20 = (unint64_t)*this + 16 * (((unint64_t)*((unsigned int *)*this + 11) >> 23) & 1) + 64;
  if (!HIBYTE(*((_DWORD *)*this + 11))) {
    unint64_t v20 = 0;
  }
  if (*(void *)(v20 + 8))
  {
    uint64_t v21 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
    uint64_t v22 = (unsigned char *)*((void *)v21 + 4);
    if ((unint64_t)v22 >= *((void *)v21 + 3))
    {
      llvm::raw_ostream::write(v21, 32);
    }
    else
    {
      *((void *)v21 + 4) = v22 + 1;
      *uint64_t v22 = 32;
    }
    __int16 v23 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
    uint64_t v24 = *((void *)v23 + 4);
    if ((unint64_t)(*((void *)v23 + 3) - v24) > 5)
    {
      *(_WORD *)(v24 + 4) = 25973;
      *(_DWORD *)uint64_t v24 = 1902734965;
      *((void *)v23 + 4) += 6;
    }
    else
    {
      llvm::raw_ostream::write(v23, "unique", 6uLL);
    }
  }
  BOOL v43 = v45;
  v45[0] = "gather_dims";
  v45[1] = 11;
  void v45[2] = "unique";
  v45[3] = 6;
  uint64_t v44 = 0x200000002;
  mlir::Attribute::getContext((mlir::Operation *)((char *)*this + 24));
  long long v25 = *this;
  if (*((unsigned char *)*this + 47))
  {
    v41[0] = mlir::Operation::getAttrDictionary(v25);
    uint64_t v26 = (mlir::ArrayAttr *)v41;
  }
  else
  {
    uint64_t v26 = (mlir::Operation *)((char *)v25 + 56);
  }
  uint64_t Value = mlir::ArrayAttr::getValue(v26);
  (*(void (**)(mlir::OpAsmPrinter *, uint64_t, uint64_t, void *, void))(*(void *)a2 + 192))(a2, Value, v28, v43, v44);
  char v29 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v30 = (unsigned char *)*((void *)v29 + 4);
  if ((unint64_t)v30 >= *((void *)v29 + 3))
  {
    llvm::raw_ostream::write(v29, 32);
  }
  else
  {
    *((void *)v29 + 4) = v30 + 1;
    *uint64_t v30 = 32;
  }
  long long v31 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v32 = (unsigned char *)*((void *)v31 + 4);
  if (*((unsigned char **)v31 + 3) == v32)
  {
    llvm::raw_ostream::write(v31, ":", 1uLL);
  }
  else
  {
    *uint64_t v32 = 58;
    ++*((void *)v31 + 4);
  }
  long long v33 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v34 = (unsigned char *)*((void *)v33 + 4);
  if ((unint64_t)v34 >= *((void *)v33 + 3))
  {
    llvm::raw_ostream::write(v33, 32);
  }
  else
  {
    *((void *)v33 + 4) = v34 + 1;
    *uint64_t v34 = 32;
  }
  uint64_t v35 = *this;
  if ((*((unsigned char *)*this + 46) & 0x80) != 0)
  {
    uint64_t v36 = *((void *)v35 + 9);
    uint64_t v37 = *((unsigned int *)v35 + 17);
  }
  else
  {
    uint64_t v36 = 0;
    uint64_t v37 = 0;
  }
  v40[0] = v36;
  v40[1] = v37;
  mlir::OperandRange::getTypes(v40, v41);
  uint64_t v38 = *((unsigned int *)*this + 9);
  uint64_t v39 = (uint64_t)*this - 16;
  if (!v38) {
    uint64_t v39 = 0;
  }
  v42[0] = v39;
  v42[1] = v38;
  mlir::OperandRange::getTypes(v42, v40);
  mlir::AsmPrinter::printFunctionalType<mlir::ValueTypeRange<mlir::OperandRange>,mlir::ValueTypeRange<mlir::ResultRange>>((uint64_t)a2, v41, v40);
  if (v43 != v45) {
    free(v43);
  }
}

BOOL mlir::tensor::GenerateOp::verifyInvariantsImpl(mlir::tensor::GenerateOp *this)
{
  uint64_t v2 = *(void *)this;
  if ((*(unsigned char *)(*(void *)this + 46) & 0x80) != 0 && (uint64_t v3 = *(unsigned int *)(v2 + 68), v3))
  {
    uint64_t v4 = 0;
    uint64_t v5 = *(void *)(v2 + 72) + 24;
    while (mlir::memref::__mlir_ods_local_type_constraint_MemRefOps3(*(void *)this, *(void *)(*(void *)v5 + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"operand", (void **)7, v4))
    {
      ++v4;
      v5 += 32;
      if (v3 == v4)
      {
        uint64_t v2 = *(void *)this;
        goto LABEL_7;
      }
    }
  }
  else
  {
LABEL_7:
    int v6 = *(_DWORD *)(v2 + 36);
    uint64_t v7 = v2 - 16;
    if (v6) {
      uint64_t v8 = v7;
    }
    else {
      uint64_t v8 = 0;
    }
    uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v8, 0);
    if (mlir::tensor::__mlir_ods_local_type_constraint_TensorOps1(*(void *)this, *(void *)(NextResultAtOffset + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"result", (void **)6, 0))return mlir::scf::__mlir_ods_local_region_constraint_SCFOps1(*(void *)this, ((*(void *)this+ 16 * (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 23) & 1)+ (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 21) & 0x7F8)+ 71) & 0xFFFFFFFFFFFFFFF8)+ 32 * *(unsigned int *)(*(void *)this + 40), (uint64_t)"body", 4, 0) != 0; {
  }
    }
  return 0;
}

void mlir::tensor::GenerateOp::parse()
{
  v2[16] = *MEMORY[0x263EF8340];
  uint64_t v0 = v2;
  uint64_t v1 = 0x400000000;
  operator new();
}

void mlir::tensor::GenerateOp::print(mlir::Operation **this, mlir::OpAsmPrinter *a2)
{
  v36[4] = *MEMORY[0x263EF8340];
  uint64_t v4 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v5 = (unsigned char *)*((void *)v4 + 4);
  if ((unint64_t)v5 >= *((void *)v4 + 3))
  {
    llvm::raw_ostream::write(v4, 32);
  }
  else
  {
    *((void *)v4 + 4) = v5 + 1;
    unsigned char *v5 = 32;
  }
  int v6 = *this;
  if ((*((unsigned char *)*this + 46) & 0x80) != 0)
  {
    uint64_t v7 = *((unsigned int *)v6 + 17);
    uint64_t v8 = *((void *)v6 + 9);
  }
  else
  {
    uint64_t v8 = 0;
    uint64_t v7 = 0;
  }
  uint64_t v9 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  unint64_t AttrDictionary = ", ";
  uint64_t v35 = 2;
  llvm::interleave<llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator,void mlir::OpAsmPrinter::printOperands<llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator>(llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator,llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator)::{lambda(mlir::Value)#1},void llvm::interleave<llvm::iterator_range<llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator>,void mlir::OpAsmPrinter::printOperands<llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator>(llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator,llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator)::{lambda(mlir::Value)#1},llvm::raw_ostream,mlir::Value>(llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator const&,llvm::raw_ostream &,void mlir::OpAsmPrinter::printOperands<llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator>(llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator,llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator)::{lambda(mlir::Value)#1},llvm::StringRef const&)::{lambda(void)#1},void>(v8, 0, v8, v7, (uint64_t)a2, v9, (uint64_t)&AttrDictionary);
  uint64_t v10 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v11 = (unsigned char *)*((void *)v10 + 4);
  if ((unint64_t)v11 >= *((void *)v10 + 3))
  {
    llvm::raw_ostream::write(v10, 32);
  }
  else
  {
    *((void *)v10 + 4) = v11 + 1;
    *uint64_t v11 = 32;
  }
  uint64_t v12 = (void *)((((unint64_t)*this
                   + 16 * (((unint64_t)*((unsigned int *)*this + 11) >> 23) & 1)
                   + (((unint64_t)*((unsigned int *)*this + 11) >> 21) & 0x7F8)
                   + 71) & 0xFFFFFFFFFFFFFFF8)
                 + 32 * *((unsigned int *)*this + 10));
  if ((void *)*v12 == v12
    || ((v13 = v12[1]) != 0 ? (uint64_t v14 = (ZinIrHalH13g **)(v13 - 8)) : (uint64_t v14 = 0),
        (mlir::Block::getTerminator(v14), !v15)
     || (uint64_t v16 = v15,
         unint64_t AttrDictionary = (void *)mlir::Operation::getAttrDictionary(v15),
         mlir::AffineBinaryOpExpr::getLHS((mlir::AffineBinaryOpExpr *)&AttrDictionary))
     || (*((unsigned char *)v16 + 46) & 0x80) != 0 && *((_DWORD *)v16 + 17)))
  {
    BOOL v17 = 1;
    uint64_t v18 = *this;
    unint64_t v19 = *((unsigned int *)*this + 11);
    if ((v19 & 0x7FFFFF) != 0)
    {
LABEL_18:
      unint64_t v20 = (((unint64_t)v18 + 16 * ((v19 >> 23) & 1) + ((v19 >> 21) & 0x7F8) + 71) & 0xFFFFFFFFFFFFFFF8)
          + 32 * *((unsigned int *)v18 + 10);
      goto LABEL_21;
    }
  }
  else
  {
    BOOL v17 = *((_DWORD *)v16 + 9) != 0;
    uint64_t v18 = *this;
    unint64_t v19 = *((unsigned int *)*this + 11);
    if ((v19 & 0x7FFFFF) != 0) {
      goto LABEL_18;
    }
  }
  unint64_t v20 = 0;
LABEL_21:
  (*(void (**)(mlir::OpAsmPrinter *, unint64_t, uint64_t, BOOL, void))(*(void *)a2 + 224))(a2, v20, 1, v17, 0);
  unint64_t AttrDictionary = v36;
  uint64_t v35 = 0x200000000;
  uint64_t v21 = *this;
  if (*((unsigned char *)*this + 47))
  {
    unint64_t v33 = mlir::Operation::getAttrDictionary(v21);
    uint64_t v22 = (mlir::ArrayAttr *)&v33;
  }
  else
  {
    uint64_t v22 = (mlir::Operation *)((char *)v21 + 56);
  }
  uint64_t Value = mlir::ArrayAttr::getValue(v22);
  (*(void (**)(mlir::OpAsmPrinter *, uint64_t, uint64_t, void *, void))(*(void *)a2 + 192))(a2, Value, v24, AttrDictionary, v35);
  long long v25 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v26 = (unsigned char *)*((void *)v25 + 4);
  if ((unint64_t)v26 >= *((void *)v25 + 3))
  {
    llvm::raw_ostream::write(v25, 32);
  }
  else
  {
    *((void *)v25 + 4) = v26 + 1;
    *uint64_t v26 = 32;
  }
  char v27 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v28 = (unsigned char *)*((void *)v27 + 4);
  if (*((unsigned char **)v27 + 3) == v28)
  {
    llvm::raw_ostream::write(v27, ":", 1uLL);
  }
  else
  {
    *uint64_t v28 = 58;
    ++*((void *)v27 + 4);
  }
  char v29 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v30 = (unsigned char *)*((void *)v29 + 4);
  if ((unint64_t)v30 >= *((void *)v29 + 3))
  {
    llvm::raw_ostream::write(v29, 32);
  }
  else
  {
    *((void *)v29 + 4) = v30 + 1;
    *uint64_t v30 = 32;
  }
  if (*((_DWORD *)*this + 9)) {
    uint64_t v31 = (uint64_t)*this - 16;
  }
  else {
    uint64_t v31 = 0;
  }
  uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v31, 0);
  (*(void (**)(mlir::OpAsmPrinter *, unint64_t))(*(void *)a2 + 32))(a2, *(void *)(NextResultAtOffset + 8) & 0xFFFFFFFFFFFFFFF8);
  if (AttrDictionary != v36) {
    free(AttrDictionary);
  }
}

uint64_t mlir::tensor::detail::InsertOpGenericAdaptorBase::InsertOpGenericAdaptorBase(uint64_t a1, unsigned int *a2)
{
  uint64_t v11 = *MEMORY[0x263EF8340];
  unint64_t AttrDictionary = mlir::Operation::getAttrDictionary((mlir::Operation *)a2);
  unint64_t v5 = a2[11];
  unint64_t v6 = v5 & 0x7FFFFF;
  if ((v5 & 0x7FFFFF) != 0)
  {
    uint64_t v7 = (((unint64_t)&a2[4 * ((v5 >> 23) & 1) + 17] + ((v5 >> 21) & 0x7F8) + 3) & 0xFFFFFFFFFFFFFFF8)
       + 32 * a2[10];
  }
  else
  {
    uint64_t v7 = 0;
    unint64_t v6 = 0;
  }
  mlir::ValueRange::ValueRange(v10, v7, v6);
  *(void *)a1 = AttrDictionary;
  *(unsigned char *)(a1 + 8) = 0;
  *(unsigned char *)(a1 + 16) = 0;
  *(_OWORD *)(a1 + 24) = *(_OWORD *)v10;
  if (AttrDictionary)
  {
    uint64_t Context = mlir::Attribute::getContext((mlir::Attribute *)a1);
    if (*(unsigned char *)(a1 + 16)) {
      *(unsigned char *)(a1 + 16) = 0;
    }
    mlir::OperationName::OperationName(a1 + 8, "tensor.insert", 13, Context);
    *(unsigned char *)(a1 + 16) = 1;
  }
  return a1;
}

uint64_t mlir::tensor::InsertOp::getDestMutable(mlir::tensor::InsertOp *this)
{
  return *(void *)(*(void *)this + 72) + 32;
}

uint64_t mlir::tensor::InsertOp::inferReturnTypes(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11)
{
  unint64_t v14[2] = *MEMORY[0x263EF8340];
  v14[0] = a4;
  v14[1] = a5;
  int v11 = *(_DWORD *)(a11 + 8);
  if (v11 != 1)
  {
    if (!v11)
    {
      if (*(_DWORD *)(a11 + 12))
      {
        unsigned int v12 = 0;
LABEL_6:
        bzero((void *)(*(void *)a11 + 8 * v12), 8 - 8 * v12);
        goto LABEL_7;
      }
      llvm::SmallVectorBase<unsigned int>::grow_pod(a11, (void *)(a11 + 16), 1uLL, 8);
      unsigned int v12 = *(_DWORD *)(a11 + 8);
      if (v12 != 1) {
        goto LABEL_6;
      }
    }
LABEL_7:
    *(_DWORD *)(a11 + 8) = 1;
  }
  **(void **)a11 = *(void *)(mlir::ValueRange::dereference_iterator(v14, 1) + 8) & 0xFFFFFFFFFFFFFFF8;
  return 1;
}

uint64_t mlir::tensor::InsertOp::verifyInvariantsImpl(mlir::tensor::InsertOp *this)
{
  uint64_t v40 = *MEMORY[0x263EF8340];
  if (!mlir::tensor::__mlir_ods_local_type_constraint_TensorOps1(*(void *)this, *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 56) + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"operand", (void **)7, 1u))return 0; {
  uint64_t v2 = *(void *)this;
  }
  if ((*(unsigned char *)(*(void *)this + 46) & 0x80) == 0)
  {
    uint64_t v4 = -2;
    uint64_t v5 = 64;
LABEL_5:
    uint64_t v6 = 0;
    uint64_t v7 = v5 + 24;
    while (mlir::memref::__mlir_ods_local_type_constraint_MemRefOps3(*(void *)this, *(void *)(*(void *)v7 + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"operand", (void **)7, (int)v6 + 2))
    {
      ++v6;
      v7 += 32;
      if (v4 == v6)
      {
        uint64_t v2 = *(void *)this;
        goto LABEL_9;
      }
    }
    return 0;
  }
  uint64_t v3 = *(unsigned int *)(v2 + 68);
  uint64_t v4 = v3 - 2;
  if (v3 != 2)
  {
    uint64_t v5 = *(void *)(v2 + 72) + 64;
    goto LABEL_5;
  }
LABEL_9:
  int v8 = *(_DWORD *)(v2 + 36);
  uint64_t v9 = v2 - 16;
  uint64_t v10 = v8 ? v9 : 0;
  uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v10, 0);
  if (!mlir::tensor::__mlir_ods_local_type_constraint_TensorOps1(*(void *)this, *(void *)(NextResultAtOffset + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"result", (void **)6, 0))return 0; {
  if (*(_DWORD *)(*(void *)this + 36))
  }
    uint64_t v13 = *(void *)this - 16;
  else {
    uint64_t v13 = 0;
  }
  unint64_t v12 = *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 56) + 8) & 0xFFFFFFFFFFFFFFF8;
  if (v12 == (*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v13, 0) + 8) & 0xFFFFFFFFFFFFFFF8))
  {
    v32[0] = *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 56) + 8) & 0xFFFFFFFFFFFFFFF8;
    if (mlir::TensorType::getElementType((mlir::TensorType *)v32) == (*(void *)(*(void *)(*(void *)(*(void *)this + 72)
                                                                                             + 24)
                                                                                 + 8) & 0xFFFFFFFFFFFFFFF8))
      return 1;
    v30[0] = (void **)"failed to verify that scalar type matches element type of dest";
    __int16 v31 = 259;
    mlir::OpState::emitOpError((uint64_t *)this, v30, (uint64_t)v32);
    uint64_t v14 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v32);
    if (v32[0]) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v32);
    }
    if (v39)
    {
      __int16 v23 = __p;
      if (__p)
      {
        uint64_t v24 = v38;
        long long v25 = __p;
        if (v38 != __p)
        {
          do
            uint64_t v24 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v24 - 1);
          while (v24 != v23);
          long long v25 = __p;
        }
        uint64_t v38 = v23;
        operator delete(v25);
      }
      uint64_t v18 = v35;
      if (!v35) {
        goto LABEL_49;
      }
      uint64_t v26 = v36;
      unint64_t v20 = v35;
      if (v36 == v35) {
        goto LABEL_48;
      }
      do
      {
        uint64_t v28 = *--v26;
        uint64_t v27 = v28;
        *uint64_t v26 = 0;
        if (v28) {
          MEMORY[0x21667D390](v27, 0x1000C8077774924);
        }
      }
      while (v26 != v18);
      goto LABEL_47;
    }
  }
  else
  {
    v30[0] = (void **)"failed to verify that result type matches type of dest";
    __int16 v31 = 259;
    mlir::OpState::emitOpError((uint64_t *)this, v30, (uint64_t)v32);
    uint64_t v14 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v32);
    if (v32[0]) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v32);
    }
    if (v39)
    {
      long long v15 = __p;
      if (__p)
      {
        uint64_t v16 = v38;
        BOOL v17 = __p;
        if (v38 != __p)
        {
          do
            uint64_t v16 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v16 - 1);
          while (v16 != v15);
          BOOL v17 = __p;
        }
        uint64_t v38 = v15;
        operator delete(v17);
      }
      uint64_t v18 = v35;
      if (!v35) {
        goto LABEL_49;
      }
      unint64_t v19 = v36;
      unint64_t v20 = v35;
      if (v36 == v35)
      {
LABEL_48:
        uint64_t v36 = v18;
        operator delete(v20);
LABEL_49:
        if (v33 != &v34) {
          free(v33);
        }
        return v14;
      }
      do
      {
        uint64_t v22 = *--v19;
        uint64_t v21 = v22;
        *unint64_t v19 = 0;
        if (v22) {
          MEMORY[0x21667D390](v21, 0x1000C8077774924);
        }
      }
      while (v19 != v18);
LABEL_47:
      unint64_t v20 = v35;
      goto LABEL_48;
    }
  }
  return v14;
}

uint64_t mlir::tensor::InsertOp::parse(uint64_t a1, uint64_t a2)
{
  v31[4] = *MEMORY[0x263EF8340];
  memset(v31, 0, 24);
  memset(v30, 0, 24);
  v23[0] = (uint64_t)v30;
  v23[1] = 1;
  uint64_t __src = 0;
  uint64_t v27 = v29;
  uint64_t v28 = 0x400000000;
  v22[0] = &__src;
  v22[1] = 1;
  (*(void (**)(uint64_t))(*(void *)a1 + 40))(a1);
  if ((*(unsigned __int8 (**)(uint64_t, void *, uint64_t))(*(void *)a1 + 672))(a1, v31, 1))
  {
    __int16 v25 = 257;
    if ((*(unsigned __int8 (**)(uint64_t, const char *, uint64_t, void *))(*(void *)a1 + 368))(a1, "into", 4, v24))
    {
      uint64_t v4 = (*(uint64_t (**)(uint64_t))(*(void *)a1 + 40))(a1);
      if ((*(unsigned __int8 (**)(uint64_t, void *, uint64_t))(*(void *)a1 + 672))(a1, v30, 1))
      {
        if ((*(unsigned __int8 (**)(uint64_t))(*(void *)a1 + 296))(a1))
        {
          (*(void (**)(uint64_t))(*(void *)a1 + 40))(a1);
          if ((*(unsigned __int8 (**)(uint64_t, void **, void, uint64_t, uint64_t))(*(void *)a1 + 688))(a1, &v27, 0, 1, 0xFFFFFFFFLL))
          {
            if ((*(unsigned __int8 (**)(uint64_t))(*(void *)a1 + 312))(a1))
            {
              (*(void (**)(uint64_t))(*(void *)a1 + 40))(a1);
              if ((*(unsigned __int8 (**)(uint64_t, uint64_t))(*(void *)a1 + 456))(a1, a2 + 112))
              {
                if ((*(unsigned __int8 (**)(uint64_t))(*(void *)a1 + 104))(a1))
                {
                  v24[0] = 0;
                  if (mlir::AsmParser::parseType<mlir::RankedTensorType>(a1, v24))
                  {
                    uint64_t v5 = v24[0];
                    uint64_t __src = v24[0];
                    uint64_t v21 = v24[0];
                    if (*(_UNKNOWN **)(*(void *)v24[0] + 136) != &mlir::detail::TypeIDResolver<mlir::RankedTensorType,void>::id)
                    {
                      uint64_t v6 = (*(uint64_t (**)(uint64_t))(*(void *)a1 + 16))(a1);
                      v20[16] = 257;
                      (*(void (**)(void *__return_ptr, uint64_t, uint64_t, _WORD *))(*(void *)a1 + 24))(v24, a1, v6, v20);
                      uint64_t v7 = mlir::InFlightDiagnostic::operator<<<char const(&)[44]>((uint64_t)v24, "'dest' must be ranked tensor of any type values, but got ");
                      uint64_t v8 = mlir::InFlightDiagnostic::append<mlir::Type &>(v7, &v21);
                      uint64_t v9 = mlir::InFlightDiagnostic::operator mlir::LogicalResult(v8);
                      mlir::InFlightDiagnostic::~InFlightDiagnostic((mlir::InFlightDiagnostic *)v24);
                      uint64_t v10 = v27;
                      if (v27 == v29) {
                        return v9;
                      }
                      goto LABEL_22;
                    }
                    uint64_t v11 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*(void *)v24[0] + 8);
                    v24[0] = v5;
                    v24[1] = v11;
                    mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)v24);
                    unint64_t v12 = (mlir::IndexType **)(*(uint64_t (**)(uint64_t))(*(void *)a1 + 32))(a1);
                    uint64_t IndexType = mlir::Builder::getIndexType(v12, v13);
                    mlir::OperationState::addTypes(a2, &__src, 1);
                    v24[0] = __src;
                    uint64_t ElementType = mlir::TensorType::getElementType((mlir::TensorType *)v24);
                    uint64_t v16 = a2 + 16;
                    if ((*(unsigned __int8 (**)(uint64_t, void *, uint64_t, uint64_t))(*(void *)a1 + 696))(a1, v31, ElementType, v16))
                    {
                      if (mlir::OpAsmParser::resolveOperands<llvm::ArrayRef<mlir::OpAsmParser::UnresolvedOperand> &,llvm::ArrayRef<mlir::Type> &>(a1, v23, v22, v4, v16))
                      {
                        if (!v28)
                        {
                          uint64_t v9 = 1;
                          uint64_t v10 = v27;
                          if (v27 == v29) {
                            return v9;
                          }
                          goto LABEL_22;
                        }
                        BOOL v17 = (char *)v27;
                        uint64_t v18 = 32 * v28;
                        uint64_t v9 = 1;
                        while ((*(unsigned __int8 (**)(uint64_t, char *, uint64_t, uint64_t))(*(void *)a1 + 696))(a1, v17, IndexType, v16))
                        {
                          v17 += 32;
                          v18 -= 32;
                          if (!v18) {
                            goto LABEL_21;
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          }
        }
      }
    }
  }
  uint64_t v9 = 0;
LABEL_21:
  uint64_t v10 = v27;
  if (v27 != v29) {
LABEL_22:
  }
    free(v10);
  return v9;
}

void mlir::tensor::InsertOp::print(mlir::Operation **this, mlir::OpAsmPrinter *a2)
{
  v35[4] = *MEMORY[0x263EF8340];
  uint64_t v4 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v5 = (unsigned char *)*((void *)v4 + 4);
  if ((unint64_t)v5 >= *((void *)v4 + 3))
  {
    llvm::raw_ostream::write(v4, 32);
  }
  else
  {
    *((void *)v4 + 4) = v5 + 1;
    unsigned char *v5 = 32;
  }
  (*(void (**)(mlir::OpAsmPrinter *, void))(*(void *)a2 + 160))(a2, *(void *)(*((void *)*this + 9) + 24));
  uint64_t v6 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v7 = (unsigned char *)*((void *)v6 + 4);
  if ((unint64_t)v7 >= *((void *)v6 + 3))
  {
    llvm::raw_ostream::write(v6, 32);
  }
  else
  {
    *((void *)v6 + 4) = v7 + 1;
    *uint64_t v7 = 32;
  }
  uint64_t v8 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v9 = (_DWORD *)*((void *)v8 + 4);
  if (*((void *)v8 + 3) - (void)v9 > 3uLL)
  {
    *uint64_t v9 = 1869901417;
    *((void *)v8 + 4) += 4;
  }
  else
  {
    llvm::raw_ostream::write(v8, "into", 4uLL);
  }
  uint64_t v10 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v11 = (unsigned char *)*((void *)v10 + 4);
  if ((unint64_t)v11 >= *((void *)v10 + 3))
  {
    llvm::raw_ostream::write(v10, 32);
  }
  else
  {
    *((void *)v10 + 4) = v11 + 1;
    *uint64_t v11 = 32;
  }
  (*(void (**)(mlir::OpAsmPrinter *, void))(*(void *)a2 + 160))(a2, *(void *)(*((void *)*this + 9) + 56));
  unint64_t v12 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v13 = (unsigned char *)*((void *)v12 + 4);
  if (*((unsigned char **)v12 + 3) == v13)
  {
    llvm::raw_ostream::write(v12, "[", 1uLL);
    uint64_t v14 = *this;
    if ((*((unsigned char *)*this + 46) & 0x80) != 0) {
      goto LABEL_15;
    }
  }
  else
  {
    *uint64_t v13 = 91;
    ++*((void *)v12 + 4);
    uint64_t v14 = *this;
    if ((*((unsigned char *)*this + 46) & 0x80) != 0)
    {
LABEL_15:
      uint64_t v15 = *((unsigned int *)v14 + 17);
      uint64_t v16 = *((void *)v14 + 9);
      uint64_t v17 = v15 - 2;
      goto LABEL_16;
    }
  }
  uint64_t v16 = 0;
  uint64_t v17 = -2;
LABEL_16:
  uint64_t v18 = v16 + 64;
  unint64_t v19 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  unint64_t v33 = ", ";
  uint64_t v34 = 2;
  llvm::interleave<llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator,void mlir::OpAsmPrinter::printOperands<llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator>(llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator,llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator)::{lambda(mlir::Value)#1},void llvm::interleave<llvm::iterator_range<llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator>,void mlir::OpAsmPrinter::printOperands<llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator>(llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator,llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator)::{lambda(mlir::Value)#1},llvm::raw_ostream,mlir::Value>(llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator const&,llvm::raw_ostream &,void mlir::OpAsmPrinter::printOperands<llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator>(llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator,llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator)::{lambda(mlir::Value)#1},llvm::StringRef const&)::{lambda(void)#1},void>(v18, 0, v18, v17, (uint64_t)a2, v19, (uint64_t)&v33);
  unint64_t v20 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v21 = (unsigned char *)*((void *)v20 + 4);
  if (*((unsigned char **)v20 + 3) == v21)
  {
    llvm::raw_ostream::write(v20, "]", 1uLL);
  }
  else
  {
    *uint64_t v21 = 93;
    ++*((void *)v20 + 4);
  }
  unint64_t v33 = v35;
  uint64_t v34 = 0x200000000;
  uint64_t v22 = *this;
  if (*((unsigned char *)*this + 47))
  {
    unint64_t AttrDictionary = mlir::Operation::getAttrDictionary(v22);
    p_unint64_t AttrDictionary = (mlir::ArrayAttr *)&AttrDictionary;
  }
  else
  {
    p_unint64_t AttrDictionary = (mlir::Operation *)((char *)v22 + 56);
  }
  uint64_t Value = mlir::ArrayAttr::getValue(p_AttrDictionary);
  (*(void (**)(mlir::OpAsmPrinter *, uint64_t, uint64_t, void *, void))(*(void *)a2 + 192))(a2, Value, v25, v33, v34);
  uint64_t v26 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v27 = (unsigned char *)*((void *)v26 + 4);
  if ((unint64_t)v27 >= *((void *)v26 + 3))
  {
    llvm::raw_ostream::write(v26, 32);
  }
  else
  {
    *((void *)v26 + 4) = v27 + 1;
    unsigned char *v27 = 32;
  }
  uint64_t v28 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  char v29 = (unsigned char *)*((void *)v28 + 4);
  if (*((unsigned char **)v28 + 3) == v29)
  {
    llvm::raw_ostream::write(v28, ":", 1uLL);
  }
  else
  {
    unsigned char *v29 = 58;
    ++*((void *)v28 + 4);
  }
  uint64_t v30 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  __int16 v31 = (unsigned char *)*((void *)v30 + 4);
  if ((unint64_t)v31 >= *((void *)v30 + 3))
  {
    llvm::raw_ostream::write(v30, 32);
  }
  else
  {
    *((void *)v30 + 4) = v31 + 1;
    unsigned char *v31 = 32;
  }
  (*(void (**)(mlir::OpAsmPrinter *, unint64_t))(*(void *)a2 + 32))(a2, *(void *)(*(void *)(*((void *)*this + 9) + 56) + 8) & 0xFFFFFFFFFFFFFFF8);
  if (v33 != v35) {
    free(v33);
  }
}

uint64_t mlir::tensor::detail::InsertSliceOpGenericAdaptorBase::InsertSliceOpGenericAdaptorBase(uint64_t a1, uint64_t a2)
{
  uint64_t v13 = *MEMORY[0x263EF8340];
  uint64_t v3 = *(void *)(a2 + 56);
  unint64_t v4 = *(unsigned int *)(a2 + 44);
  if (HIBYTE(*(_DWORD *)(a2 + 44))) {
    uint64_t v5 = (long long *)(a2 + 16 * ((v4 >> 23) & 1) + 64);
  }
  else {
    uint64_t v5 = 0;
  }
  unint64_t v6 = v4 & 0x7FFFFF;
  if ((v4 & 0x7FFFFF) != 0)
  {
    uint64_t v7 = ((a2 + 16 * ((v4 >> 23) & 1) + 64 + ((v4 >> 21) & 0x7F8) + 7) & 0xFFFFFFFFFFFFFFF8)
       + 32 * *(unsigned int *)(a2 + 40);
  }
  else
  {
    uint64_t v7 = 0;
    unint64_t v6 = 0;
  }
  mlir::ValueRange::ValueRange(v12, v7, v6);
  *(void *)a1 = v3;
  *(unsigned char *)(a1 + 8) = 0;
  *(unsigned char *)(a1 + 16) = 0;
  long long v8 = *v5;
  long long v9 = v5[1];
  *(_OWORD *)(a1 + 56) = v5[2];
  *(_OWORD *)(a1 + 40) = v9;
  *(_OWORD *)(a1 + 24) = v8;
  *(_OWORD *)(a1 + 72) = *(_OWORD *)v12;
  if (v3)
  {
    uint64_t Context = mlir::Attribute::getContext((mlir::Attribute *)a1);
    if (*(unsigned char *)(a1 + 16)) {
      *(unsigned char *)(a1 + 16) = 0;
    }
    mlir::OperationName::OperationName(a1 + 8, "tensor.insert_slice", 19, Context);
    *(unsigned char *)(a1 + 16) = 1;
  }
  return a1;
}

uint64_t mlir::tensor::InsertSliceOp::getStrides(mlir::tensor::InsertSliceOp *this)
{
  unint64_t v1 = *(unsigned int *)(*(void *)this + 44);
  if (HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
    uint64_t v2 = (_DWORD *)(*(void *)this + 16 * ((v1 >> 23) & 1) + 64);
  }
  else {
    uint64_t v2 = 0;
  }
  if ((v1 & 0x800000) != 0) {
    uint64_t v3 = *(void *)(*(void *)this + 72);
  }
  else {
    uint64_t v3 = 0;
  }
  return v3 + 32 * (v2[9] + v2[8] + v2[7] + v2[6]);
}

uint64_t mlir::tensor::InsertSliceOp::getDestMutable(mlir::tensor::InsertSliceOp *this)
{
  if (HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
    unint64_t v1 = *(void *)this + 16 * (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 23) & 1) + 64;
  }
  else {
    unint64_t v1 = 0;
  }
  return *(void *)(*(void *)this + 72) + 32 * *(unsigned int *)(v1 + 24);
}

BOOL mlir::tensor::InsertSliceOp::setPropertiesFromAttr(uint64_t *a1, uint64_t a2, void (*a3)(uint64_t *__return_ptr, uint64_t), uint64_t a4)
{
  uint64_t v118 = *MEMORY[0x263EF8340];
  if (*(_UNKNOWN **)(*(void *)a2 + 136) == &mlir::detail::TypeIDResolver<mlir::DictionaryAttr,void>::id) {
    uint64_t v6 = a2;
  }
  else {
    uint64_t v6 = 0;
  }
  uint64_t v104 = v6;
  if (!v6)
  {
    a3(v108, a4);
    if (v108[0])
    {
      int v105 = 3;
      __int16 v106 = "expected DictionaryAttr to set properties";
      uint64_t v107 = 41;
      uint64_t v16 = &v105;
      uint64_t v17 = (char *)v109;
      if (v110 >= v111)
      {
        unint64_t v87 = v110 + 1;
        if (v109 <= &v105 && (char *)v109 + 24 * v110 > (char *)&v105)
        {
          int64_t v95 = (char *)&v105 - (unsigned char *)v109;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v109, v112, v87, 24);
          uint64_t v17 = (char *)v109;
          uint64_t v16 = (int *)((char *)v109 + v95);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v109, v112, v87, 24);
          uint64_t v16 = &v105;
          uint64_t v17 = (char *)v109;
        }
      }
      uint64_t v18 = &v17[24 * v110];
      long long v19 = *(_OWORD *)v16;
      *((void *)v18 + 2) = *((void *)v16 + 2);
      *(_OWORD *)uint64_t v18 = v19;
      ++v110;
      if (v108[0]) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v108);
      }
    }
    if (!v117) {
      return 0;
    }
    unint64_t v20 = __p;
    if (__p)
    {
      uint64_t v21 = v116;
      uint64_t v22 = __p;
      if (v116 != __p)
      {
        do
          uint64_t v21 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v21 - 1);
        while (v21 != v20);
        uint64_t v22 = __p;
      }
      uint64_t v116 = v20;
      operator delete(v22);
    }
    __int16 v23 = v113;
    if (!v113) {
      goto LABEL_117;
    }
    uint64_t v24 = v114;
    uint64_t v25 = v113;
    if (v114 == v113)
    {
LABEL_116:
      unsigned int v114 = v23;
      operator delete(v25);
LABEL_117:
      if (v109 != v112) {
        free(v109);
      }
      return 0;
    }
    do
    {
      uint64_t v27 = *--v24;
      uint64_t v26 = v27;
      *uint64_t v24 = 0;
      if (v27) {
        MEMORY[0x21667D390](v26, 0x1000C8077774924);
      }
    }
    while (v24 != v23);
LABEL_115:
    uint64_t v25 = v113;
    goto LABEL_116;
  }
  long long v8 = (void *)mlir::DictionaryAttr::get((uint64_t)&v104, "static_offsets", 0xEuLL);
  if (!v8)
  {
    a3(v108, a4);
    if (v108[0])
    {
      int v105 = 3;
      __int16 v106 = "expected key entry for static_offsets in DictionaryAttr to set Properties.";
      uint64_t v107 = 74;
      uint64_t v28 = &v105;
      char v29 = (char *)v109;
      if (v110 >= v111)
      {
        unint64_t v88 = v110 + 1;
        if (v109 <= &v105 && (char *)v109 + 24 * v110 > (char *)&v105)
        {
          int64_t v96 = (char *)&v105 - (unsigned char *)v109;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v109, v112, v88, 24);
          char v29 = (char *)v109;
          uint64_t v28 = (int *)((char *)v109 + v96);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v109, v112, v88, 24);
          uint64_t v28 = &v105;
          char v29 = (char *)v109;
        }
      }
      uint64_t v30 = &v29[24 * v110];
      long long v31 = *(_OWORD *)v28;
      *((void *)v30 + 2) = *((void *)v28 + 2);
      *(_OWORD *)uint64_t v30 = v31;
      ++v110;
      if (v108[0]) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v108);
      }
    }
    if (!v117) {
      return 0;
    }
    uint64_t v32 = __p;
    if (__p)
    {
      unint64_t v33 = v116;
      uint64_t v34 = __p;
      if (v116 != __p)
      {
        do
          unint64_t v33 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v33 - 1);
        while (v33 != v32);
        uint64_t v34 = __p;
      }
      uint64_t v116 = v32;
      operator delete(v34);
    }
    __int16 v23 = v113;
    if (!v113) {
      goto LABEL_117;
    }
    uint64_t v35 = v114;
    uint64_t v25 = v113;
    if (v114 == v113) {
      goto LABEL_116;
    }
    do
    {
      uint64_t v37 = *--v35;
      uint64_t v36 = v37;
      *uint64_t v35 = 0;
      if (v37) {
        MEMORY[0x21667D390](v36, 0x1000C8077774924);
      }
    }
    while (v35 != v23);
    goto LABEL_115;
  }
  uint64_t v9 = (uint64_t)v8;
  if (!mlir::detail::DenseArrayAttrImpl<long long>::classof(v8))
  {
    a3(v108, a4);
    if (v108[0])
    {
      int v105 = 3;
      uint64_t v107 = 59;
      uint64_t v38 = &v105;
      char v39 = (char *)v109;
      if (v110 >= v111)
      {
        unint64_t v89 = v110 + 1;
        if (v109 <= &v105 && (char *)v109 + 24 * v110 > (char *)&v105)
        {
          int64_t v97 = (char *)&v105 - (unsigned char *)v109;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v109, v112, v89, 24);
          char v39 = (char *)v109;
          uint64_t v38 = (int *)((char *)v109 + v97);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v109, v112, v89, 24);
          uint64_t v38 = &v105;
          char v39 = (char *)v109;
        }
      }
      uint64_t v40 = &v39[24 * v110];
      long long v41 = *(_OWORD *)v38;
      *((void *)v40 + 2) = *((void *)v38 + 2);
      *(_OWORD *)uint64_t v40 = v41;
      ++v110;
      if (v108[0])
      {
        unint64_t v42 = &v105;
        mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v105, v9);
        BOOL v43 = (char *)v109;
        if (v110 >= v111)
        {
          unint64_t v90 = v110 + 1;
          if (v109 <= &v105 && (char *)v109 + 24 * v110 > (char *)&v105)
          {
            int64_t v98 = (char *)&v105 - (unsigned char *)v109;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v109, v112, v90, 24);
            BOOL v43 = (char *)v109;
            unint64_t v42 = (int *)((char *)v109 + v98);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v109, v112, v90, 24);
            unint64_t v42 = &v105;
            BOOL v43 = (char *)v109;
          }
        }
        uint64_t v44 = &v43[24 * v110];
        long long v45 = *(_OWORD *)v42;
        *((void *)v44 + 2) = *((void *)v42 + 2);
        *(_OWORD *)uint64_t v44 = v45;
        ++v110;
        if (v108[0]) {
          mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v108);
        }
      }
    }
    if (!v117) {
      return 0;
    }
    int64_t v46 = __p;
    if (__p)
    {
      int64_t v47 = v116;
      int64_t v48 = __p;
      if (v116 != __p)
      {
        do
          int64_t v47 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v47 - 1);
        while (v47 != v46);
        int64_t v48 = __p;
      }
      uint64_t v116 = v46;
      operator delete(v48);
    }
    __int16 v23 = v113;
    if (!v113) {
      goto LABEL_117;
    }
    int64_t v49 = v114;
    uint64_t v25 = v113;
    if (v114 == v113) {
      goto LABEL_116;
    }
    do
    {
      uint64_t v51 = *--v49;
      uint64_t v50 = v51;
      *int64_t v49 = 0;
      if (v51) {
        MEMORY[0x21667D390](v50, 0x1000C8077774924);
      }
    }
    while (v49 != v23);
    goto LABEL_115;
  }
  *a1 = v9;
  uint64_t v10 = (void *)mlir::DictionaryAttr::get((uint64_t)&v104, "static_sizes", 0xCuLL);
  if (!v10)
  {
    a3(v108, a4);
    if (v108[0])
    {
      int v105 = 3;
      __int16 v106 = "expected key entry for static_sizes in DictionaryAttr to set Properties.";
      uint64_t v107 = 72;
      int64_t v52 = &v105;
      uint64_t v53 = (char *)v109;
      if (v110 >= v111)
      {
        unint64_t v91 = v110 + 1;
        if (v109 <= &v105 && (char *)v109 + 24 * v110 > (char *)&v105)
        {
          int64_t v99 = (char *)&v105 - (unsigned char *)v109;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v109, v112, v91, 24);
          uint64_t v53 = (char *)v109;
          int64_t v52 = (int *)((char *)v109 + v99);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v109, v112, v91, 24);
          int64_t v52 = &v105;
          uint64_t v53 = (char *)v109;
        }
      }
      unsigned int v54 = &v53[24 * v110];
      long long v55 = *(_OWORD *)v52;
      *((void *)v54 + 2) = *((void *)v52 + 2);
      *(_OWORD *)unsigned int v54 = v55;
      ++v110;
      if (v108[0]) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v108);
      }
    }
    if (!v117) {
      return 0;
    }
    unsigned int v56 = __p;
    if (__p)
    {
      unsigned int v57 = v116;
      uint64_t v58 = __p;
      if (v116 != __p)
      {
        do
          unsigned int v57 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v57 - 1);
        while (v57 != v56);
        uint64_t v58 = __p;
      }
      uint64_t v116 = v56;
      operator delete(v58);
    }
    __int16 v23 = v113;
    if (!v113) {
      goto LABEL_117;
    }
    uint64_t v59 = v114;
    uint64_t v25 = v113;
    if (v114 == v113) {
      goto LABEL_116;
    }
    do
    {
      uint64_t v61 = *--v59;
      uint64_t v60 = v61;
      *uint64_t v59 = 0;
      if (v61) {
        MEMORY[0x21667D390](v60, 0x1000C8077774924);
      }
    }
    while (v59 != v23);
    goto LABEL_115;
  }
  uint64_t v11 = (uint64_t)v10;
  if (!mlir::detail::DenseArrayAttrImpl<long long>::classof(v10))
  {
    a3(v108, a4);
    if (v108[0])
    {
      int v105 = 3;
      uint64_t v107 = 57;
      unsigned int v62 = &v105;
      char v63 = (char *)v109;
      if (v110 >= v111)
      {
        unint64_t v92 = v110 + 1;
        if (v109 <= &v105 && (char *)v109 + 24 * v110 > (char *)&v105)
        {
          int64_t v100 = (char *)&v105 - (unsigned char *)v109;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v109, v112, v92, 24);
          char v63 = (char *)v109;
          unsigned int v62 = (int *)((char *)v109 + v100);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v109, v112, v92, 24);
          unsigned int v62 = &v105;
          char v63 = (char *)v109;
        }
      }
      uint64_t v64 = &v63[24 * v110];
      long long v65 = *(_OWORD *)v62;
      *((void *)v64 + 2) = *((void *)v62 + 2);
      *(_OWORD *)uint64_t v64 = v65;
      ++v110;
      if (v108[0])
      {
        unint64_t v66 = &v105;
        mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v105, v11);
        unint64_t v67 = (char *)v109;
        if (v110 >= v111)
        {
          unint64_t v93 = v110 + 1;
          if (v109 <= &v105 && (char *)v109 + 24 * v110 > (char *)&v105)
          {
            int64_t v101 = (char *)&v105 - (unsigned char *)v109;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v109, v112, v93, 24);
            unint64_t v67 = (char *)v109;
            unint64_t v66 = (int *)((char *)v109 + v101);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v109, v112, v93, 24);
            unint64_t v66 = &v105;
            unint64_t v67 = (char *)v109;
          }
        }
        unint64_t v68 = &v67[24 * v110];
        long long v69 = *(_OWORD *)v66;
        *((void *)v68 + 2) = *((void *)v66 + 2);
        *(_OWORD *)unint64_t v68 = v69;
        ++v110;
        if (v108[0]) {
          mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v108);
        }
      }
    }
    if (!v117) {
      return 0;
    }
    int64_t v70 = __p;
    if (__p)
    {
      int64_t v71 = v116;
      int64_t v72 = __p;
      if (v116 != __p)
      {
        do
          int64_t v71 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v71 - 1);
        while (v71 != v70);
        int64_t v72 = __p;
      }
      uint64_t v116 = v70;
      operator delete(v72);
    }
    __int16 v23 = v113;
    if (!v113) {
      goto LABEL_117;
    }
    int64_t v73 = v114;
    uint64_t v25 = v113;
    if (v114 == v113) {
      goto LABEL_116;
    }
    do
    {
      uint64_t v75 = *--v73;
      uint64_t v74 = v75;
      *int64_t v73 = 0;
      if (v75) {
        MEMORY[0x21667D390](v74, 0x1000C8077774924);
      }
    }
    while (v73 != v23);
    goto LABEL_115;
  }
  a1[1] = v11;
  unint64_t v12 = (void *)mlir::DictionaryAttr::get((uint64_t)&v104, "static_strides", 0xEuLL);
  int v103 = v12;
  if (!v12)
  {
    a3(v108, a4);
    if (v108[0])
    {
      int v105 = 3;
      __int16 v106 = "expected key entry for static_strides in DictionaryAttr to set Properties.";
      uint64_t v107 = 74;
      int v76 = &v105;
      int v77 = (char *)v109;
      if (v110 >= v111)
      {
        unint64_t v94 = v110 + 1;
        if (v109 <= &v105 && (char *)v109 + 24 * v110 > (char *)&v105)
        {
          int64_t v102 = (char *)&v105 - (unsigned char *)v109;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v109, v112, v94, 24);
          int v77 = (char *)v109;
          int v76 = (int *)((char *)v109 + v102);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v109, v112, v94, 24);
          int v76 = &v105;
          int v77 = (char *)v109;
        }
      }
      uint64_t v78 = &v77[24 * v110];
      long long v79 = *(_OWORD *)v76;
      *((void *)v78 + 2) = *((void *)v76 + 2);
      *(_OWORD *)uint64_t v78 = v79;
      ++v110;
      if (v108[0]) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v108);
      }
    }
    if (!v117) {
      return 0;
    }
    BOOL v80 = __p;
    if (__p)
    {
      unsigned int v81 = v116;
      unsigned int v82 = __p;
      if (v116 != __p)
      {
        do
          unsigned int v81 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v81 - 1);
        while (v81 != v80);
        unsigned int v82 = __p;
      }
      uint64_t v116 = v80;
      operator delete(v82);
    }
    __int16 v23 = v113;
    if (!v113) {
      goto LABEL_117;
    }
    int64_t v83 = v114;
    uint64_t v25 = v113;
    if (v114 == v113) {
      goto LABEL_116;
    }
    do
    {
      uint64_t v85 = *--v83;
      uint64_t v84 = v85;
      *int64_t v83 = 0;
      if (v85) {
        MEMORY[0x21667D390](v84, 0x1000C8077774924);
      }
    }
    while (v83 != v23);
    goto LABEL_115;
  }
  uint64_t v13 = v12;
  if (!mlir::detail::DenseArrayAttrImpl<long long>::classof(v12))
  {
    a3(v108, a4);
    mlir::InFlightDiagnostic::append<mlir::Attribute>(v86, (uint64_t *)&v103);
LABEL_122:
    mlir::InFlightDiagnostic::~InFlightDiagnostic((mlir::InFlightDiagnostic *)v108);
    return 0;
  }
  a1[2] = (uint64_t)v13;
  uint64_t v14 = (void *)mlir::DictionaryAttr::get((uint64_t)&v104, "operandSegmentSizes", 0x13uLL);
  if (!v14)
  {
    uint64_t v14 = (void *)mlir::DictionaryAttr::get((uint64_t)&v104, "operand_segment_sizes", 0x15uLL);
    if (!v14)
    {
      a3(v108, a4);
      mlir::InFlightDiagnostic::operator<<<char const(&)[44]>((uint64_t)v108, "expected key entry for operandSegmentSizes in DictionaryAttr to set Properties.");
      goto LABEL_122;
    }
  }
  return mlir::convertFromAttribute(a1 + 3, (const char *)5, v14, a3, a4) != 0;
}

uint64_t mlir::tensor::InsertSliceOp::getPropertiesAsAttr(mlir::DictionaryAttr *a1, uint64_t *a2)
{
  void v35[6] = *MEMORY[0x263EF8340];
  uint64_t v32 = a1;
  unint64_t v33 = v35;
  uint64_t v34 = 0x300000000;
  if (*a2)
  {
    uint64_t NamedAttr = mlir::Builder::getNamedAttr(&v32, (uint64_t)"static_offsets", 14, *a2);
    uint64_t v6 = v5;
    unsigned int v7 = v34;
    if (v34 >= HIDWORD(v34))
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v33, v35, v34 + 1, 16);
      unsigned int v7 = v34;
    }
    long long v8 = (uint64_t *)((char *)v33 + 16 * v7);
    *long long v8 = NamedAttr;
    v8[1] = v6;
    LODWORD(v34) = v34 + 1;
  }
  uint64_t v9 = a2[1];
  if (v9)
  {
    uint64_t v10 = mlir::Builder::getNamedAttr(&v32, (uint64_t)"static_sizes", 12, v9);
    uint64_t v12 = v11;
    unsigned int v13 = v34;
    if (v34 >= HIDWORD(v34))
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v33, v35, v34 + 1, 16);
      unsigned int v13 = v34;
    }
    uint64_t v14 = (uint64_t *)((char *)v33 + 16 * v13);
    *uint64_t v14 = v10;
    v14[1] = v12;
    LODWORD(v34) = v34 + 1;
  }
  uint64_t v15 = a2[2];
  if (v15)
  {
    uint64_t v16 = mlir::Builder::getNamedAttr(&v32, (uint64_t)"static_strides", 14, v15);
    uint64_t v18 = v17;
    unsigned int v19 = v34;
    if (v34 >= HIDWORD(v34))
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v33, v35, v34 + 1, 16);
      unsigned int v19 = v34;
    }
    unint64_t v20 = (uint64_t *)((char *)v33 + 16 * v19);
    uint64_t *v20 = v16;
    v20[1] = v18;
    LODWORD(v34) = v34 + 1;
  }
  uint64_t v21 = mlir::detail::DenseArrayAttrImpl<int>::get(a1, (uint64_t)(a2 + 3), 5);
  uint64_t v22 = mlir::Builder::getNamedAttr(&v32, (uint64_t)"operandSegmentSizes", 19, v21);
  uint64_t v24 = v23;
  unsigned int v25 = v34;
  if (v34 >= HIDWORD(v34))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v33, v35, v34 + 1, 16);
    unsigned int v25 = v34;
  }
  uint64_t v26 = (uint64_t *)((char *)v33 + 16 * v25);
  *uint64_t v26 = v22;
  v26[1] = v24;
  BOOL v27 = __CFADD__(v34, 1);
  uint64_t v28 = (v34 + 1);
  LODWORD(v34) = v34 + 1;
  if (v27)
  {
    uint64_t DictionaryAttr = 0;
    uint64_t v30 = v33;
    if (v33 == v35) {
      return DictionaryAttr;
    }
    goto LABEL_20;
  }
  uint64_t DictionaryAttr = mlir::Builder::getDictionaryAttr(&v32, (uint64_t *)v33, v28);
  uint64_t v30 = v33;
  if (v33 != v35) {
LABEL_20:
  }
    free(v30);
  return DictionaryAttr;
}

unint64_t mlir::tensor::InsertSliceOp::computePropertiesHash(unint64_t *a1)
{
  unint64_t v1 = *a1;
  uint64_t v2 = &unk_267770000;
  {
    unint64_t v29 = v1;
    uint64_t v32 = a1;
    uint64_t v2 = &unk_267770000;
    int v18 = v17;
    unint64_t v1 = v29;
    a1 = v32;
    if (v18)
    {
      unint64_t v19 = llvm::hashing::detail::fixed_seed_override;
      if (!llvm::hashing::detail::fixed_seed_override) {
        unint64_t v19 = 0xFF51AFD7ED558CCDLL;
      }
      llvm::hashing::detail::get_execution_seed(void)::seed = v19;
      unint64_t v1 = v29;
      a1 = v32;
      uint64_t v2 = (void *)&unk_267770000;
    }
  }
  unint64_t v3 = HIDWORD(v1);
  unint64_t v4 = 0x9DDFEA08EB382D69 * ((v2[385] + 8 * v1) ^ HIDWORD(v1));
  unint64_t v39 = 0x9DDFEA08EB382D69
      * ((0x9DDFEA08EB382D69 * (v3 ^ (v4 >> 47) ^ v4)) ^ ((0x9DDFEA08EB382D69 * (v3 ^ (v4 >> 47) ^ v4)) >> 47));
  unint64_t v5 = a1[1];
  {
    unint64_t v30 = v5;
    unint64_t v33 = a1;
    uint64_t v2 = &unk_267770000;
    int v21 = v20;
    unint64_t v5 = v30;
    a1 = v33;
    if (v21)
    {
      unint64_t v22 = llvm::hashing::detail::fixed_seed_override;
      if (!llvm::hashing::detail::fixed_seed_override) {
        unint64_t v22 = 0xFF51AFD7ED558CCDLL;
      }
      llvm::hashing::detail::get_execution_seed(void)::seed = v22;
      unint64_t v5 = v30;
      a1 = v33;
      uint64_t v2 = (void *)&unk_267770000;
    }
  }
  unint64_t v6 = HIDWORD(v5);
  unint64_t v7 = 0x9DDFEA08EB382D69 * ((v2[385] + 8 * v5) ^ HIDWORD(v5));
  unint64_t v38 = 0x9DDFEA08EB382D69
      * ((0x9DDFEA08EB382D69 * (v6 ^ (v7 >> 47) ^ v7)) ^ ((0x9DDFEA08EB382D69 * (v6 ^ (v7 >> 47) ^ v7)) >> 47));
  unint64_t v8 = a1[2];
  {
    unint64_t v31 = v8;
    uint64_t v34 = a1;
    uint64_t v2 = &unk_267770000;
    int v24 = v23;
    unint64_t v8 = v31;
    a1 = v34;
    if (v24)
    {
      unint64_t v25 = llvm::hashing::detail::fixed_seed_override;
      if (!llvm::hashing::detail::fixed_seed_override) {
        unint64_t v25 = 0xFF51AFD7ED558CCDLL;
      }
      llvm::hashing::detail::get_execution_seed(void)::seed = v25;
      unint64_t v8 = v31;
      a1 = v34;
      uint64_t v2 = (void *)&unk_267770000;
    }
  }
  unint64_t v9 = HIDWORD(v8);
  unint64_t v10 = 0x9DDFEA08EB382D69 * ((v2[385] + 8 * v8) ^ HIDWORD(v8));
  unint64_t v37 = 0x9DDFEA08EB382D69
      * ((0x9DDFEA08EB382D69 * (v9 ^ (v10 >> 47) ^ v10)) ^ ((0x9DDFEA08EB382D69 * (v9 ^ (v10 >> 47) ^ v10)) >> 47));
  {
    uint64_t v35 = a1;
    uint64_t v2 = &unk_267770000;
    int v27 = v26;
    a1 = v35;
    if (v27)
    {
      unint64_t v28 = llvm::hashing::detail::fixed_seed_override;
      if (!llvm::hashing::detail::fixed_seed_override) {
        unint64_t v28 = 0xFF51AFD7ED558CCDLL;
      }
      llvm::hashing::detail::get_execution_seed(void)::seed = v28;
      uint64_t v2 = (void *)&unk_267770000;
      a1 = v35;
    }
  }
  uint64_t v11 = v2[385];
  unint64_t v12 = a1[4];
  unint64_t v13 = 0x9AE16A3B2F90404FLL * *(unint64_t *)((char *)a1 + 36);
  uint64_t v14 = __ROR8__(0xB492B66FBE98F273 * a1[3] - v12, 43)
      - 0x3C5A37A36834CED9 * *(unint64_t *)((char *)a1 + 28)
      + __ROR8__(v13 ^ v11, 30);
  uint64_t v15 = v11 + __ROR8__(v12 ^ 0xC949D7C7509E6557, 20) - 0x4B6D499041670D8DLL * a1[3] - v13 + 20;
  unint64_t v36 = 0x9DDFEA08EB382D69
      * ((0x9DDFEA08EB382D69
        * (v15 ^ ((0x9DDFEA08EB382D69 * (v14 ^ v15)) >> 47) ^ (0x9DDFEA08EB382D69 * (v14 ^ v15)))) ^ ((0x9DDFEA08EB382D69 * (v15 ^ ((0x9DDFEA08EB382D69 * (v14 ^ v15)) >> 47) ^ (0x9DDFEA08EB382D69 * (v14 ^ v15)))) >> 47));
  return llvm::hash_combine<llvm::hash_code,llvm::hash_code,llvm::hash_code,llvm::hash_code>(&v39, (uint64_t *)&v38, (uint64_t *)&v37, (uint64_t *)&v36);
}

uint64_t mlir::tensor::InsertSliceOp::getInherentAttr(mlir::MLIRContext *a1, uint64_t *a2, char *__s1, size_t __n)
{
  uint64_t result = 0;
  switch(__n)
  {
    case 0xCuLL:
      if (memcmp(__s1, "static_sizes", __n)) {
        goto LABEL_11;
      }
      return a2[1];
    case 0xDuLL:
    case 0xFuLL:
    case 0x10uLL:
    case 0x11uLL:
    case 0x12uLL:
    case 0x14uLL:
      goto LABEL_11;
    case 0xEuLL:
      if (*(void *)__s1 == 0x6F5F636974617473 && *(void *)(__s1 + 6) == 0x7374657366666F5FLL)
      {
        uint64_t result = *a2;
      }
      else if (!memcmp(__s1, "static_strides", __n))
      {
        uint64_t result = a2[2];
      }
      else
      {
LABEL_11:
        uint64_t result = 0;
      }
      break;
    case 0x13uLL:
      if (memcmp(__s1, "operandSegmentSizes", __n)) {
        goto LABEL_11;
      }
      goto LABEL_13;
    case 0x15uLL:
      if (memcmp(__s1, "operand_segment_sizes", __n)) {
        goto LABEL_11;
      }
LABEL_13:
      uint64_t result = mlir::detail::DenseArrayAttrImpl<int>::get(a1, (uint64_t)(a2 + 3), 5);
      break;
    default:
      return result;
  }
  return result;
}

uint64_t mlir::tensor::InsertSliceOp::setInherentAttr(uint64_t result, char *__s1, size_t a3, void *a4)
{
  unint64_t v5 = (void *)result;
  switch(a3)
  {
    case 0xCuLL:
      uint64_t result = memcmp(__s1, "static_sizes", a3);
      if (!result)
      {
        if (a4)
        {
          uint64_t result = mlir::detail::DenseArrayAttrImpl<long long>::classof(a4);
          if (result) {
            unint64_t v10 = a4;
          }
          else {
            unint64_t v10 = 0;
          }
          v5[1] = v10;
        }
        else
        {
          v5[1] = 0;
        }
      }
      break;
    case 0xEuLL:
      if (*(void *)__s1 == 0x6F5F636974617473 && *(void *)(__s1 + 6) == 0x7374657366666F5FLL)
      {
        if (a4)
        {
          uint64_t result = mlir::detail::DenseArrayAttrImpl<long long>::classof(a4);
          if (result) {
            uint64_t v11 = a4;
          }
          else {
            uint64_t v11 = 0;
          }
          void *v5 = v11;
        }
        else
        {
          *(void *)uint64_t result = 0;
        }
      }
      else
      {
        uint64_t result = memcmp(__s1, "static_strides", a3);
        if (!result)
        {
          if (a4)
          {
            uint64_t result = mlir::detail::DenseArrayAttrImpl<long long>::classof(a4);
            if (result) {
              unint64_t v7 = a4;
            }
            else {
              unint64_t v7 = 0;
            }
            v5[2] = v7;
          }
          else
          {
            v5[2] = 0;
          }
        }
      }
      break;
    case 0x13uLL:
      uint64_t result = memcmp(__s1, "operandSegmentSizes", a3);
      if (!result) {
        goto LABEL_17;
      }
      break;
    case 0x15uLL:
      uint64_t result = memcmp(__s1, "operand_segment_sizes", a3);
      if (!result)
      {
LABEL_17:
        if (a4)
        {
          uint64_t result = mlir::detail::DenseArrayAttrImpl<int>::classof(a4);
          unint64_t v8 = result ? a4 : 0;
          unint64_t v12 = v8;
          if (result)
          {
            uint64_t result = mlir::AffineBinaryOpExpr::getLHS((mlir::AffineBinaryOpExpr *)&v12);
            if (result == 5)
            {
              uint64_t result = mlir::detail::DenseArrayAttrImpl<int>::operator llvm::ArrayRef<int>((uint64_t)&v12);
              if (v9) {
                uint64_t result = (uint64_t)memmove(v5 + 3, (const void *)result, 4 * v9);
              }
            }
          }
        }
      }
      break;
    default:
      return result;
  }
  return result;
}

void mlir::tensor::InsertSliceOp::populateInherentAttrs(mlir::MLIRContext *a1, uint64_t *a2, uint64_t a3)
{
  if (*a2) {
    mlir::NamedAttrList::append(a3, (uint64_t)"static_offsets", 14, *a2);
  }
  uint64_t v6 = a2[1];
  if (v6) {
    mlir::NamedAttrList::append(a3, (uint64_t)"static_sizes", 12, v6);
  }
  uint64_t v7 = a2[2];
  if (v7) {
    mlir::NamedAttrList::append(a3, (uint64_t)"static_strides", 14, v7);
  }
  uint64_t v8 = mlir::detail::DenseArrayAttrImpl<int>::get(a1, (uint64_t)(a2 + 3), 5);

  mlir::NamedAttrList::append(a3, (uint64_t)"operandSegmentSizes", 19, v8);
}

BOOL mlir::tensor::InsertSliceOp::readProperties(uint64_t a1, uint64_t a2)
{
  uint64_t v26 = *MEMORY[0x263EF8340];
  unint64_t v3 = (void *)mlir::OperationState::getOrAddProperties<mlir::tensor::detail::InsertSliceOpGenericAdaptorBase::Properties>(a2);
  if ((unint64_t)(*(uint64_t (**)(uint64_t))(*(void *)a1 + 40))(a1) <= 5)
  {
    uint64_t v17 = 0;
    if (!mlir::DialectBytecodeReader::readAttribute<mlir::detail::DenseArrayAttrImpl<int>>(a1, &v17)) {
      return 0;
    }
    if (mlir::AffineBinaryOpExpr::getLHS((mlir::AffineBinaryOpExpr *)&v17) >= 6)
    {
      uint64_t v15 = "size mismatch for operand/result_segment_size";
      __int16 v16 = 259;
      (*(void (**)(void *__return_ptr, uint64_t, const char **))(*(void *)a1 + 16))(v18, a1, &v15);
      if (v18[0]) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v18);
      }
      if (v25)
      {
        unint64_t v4 = __p;
        if (__p)
        {
          unint64_t v5 = v24;
          uint64_t v6 = __p;
          if (v24 != __p)
          {
            do
              unint64_t v5 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v5 - 1);
            while (v5 != v4);
            uint64_t v6 = __p;
          }
          int v24 = v4;
          operator delete(v6);
        }
        uint64_t v7 = v21;
        if (v21)
        {
          uint64_t v8 = v22;
          uint64_t v9 = v21;
          if (v22 != v21)
          {
            do
            {
              uint64_t v11 = *--v8;
              uint64_t v10 = v11;
              *uint64_t v8 = 0;
              if (v11) {
                MEMORY[0x21667D390](v10, 0x1000C8077774924);
              }
            }
            while (v8 != v7);
            uint64_t v9 = v21;
          }
          unint64_t v22 = v7;
          operator delete(v9);
        }
        if (v19 != &v20) {
          free(v19);
        }
      }
      return 0;
    }
    unint64_t v12 = (const void *)mlir::detail::DenseArrayAttrImpl<int>::operator llvm::ArrayRef<int>((uint64_t)&v17);
    if (v13) {
      memmove(v3 + 3, v12, 4 * v13);
    }
  }
  return mlir::DialectBytecodeReader::readAttribute<mlir::detail::DenseArrayAttrImpl<long long>>(a1, v3)&& mlir::DialectBytecodeReader::readAttribute<mlir::detail::DenseArrayAttrImpl<long long>>(a1, v3 + 1)&& mlir::DialectBytecodeReader::readAttribute<mlir::detail::DenseArrayAttrImpl<long long>>(a1, v3 + 2)&& ((unint64_t)(*(uint64_t (**)(uint64_t))(*(void *)a1 + 40))(a1) < 6|| mlir::DialectBytecodeReader::readSparseArray<int>(a1, (_DWORD *)v3 + 6, (const char *)5));
}

uint64_t mlir::OperationState::getOrAddProperties<mlir::tensor::detail::InsertSliceOpGenericAdaptorBase::Properties>(uint64_t a1)
{
  uint64_t result = *(void *)(a1 + 256);
  if (!result) {
    operator new();
  }
  return result;
}

uint64_t mlir::tensor::InsertSliceOp::writeProperties(uint64_t a1, uint64_t a2)
{
  if (HIBYTE(*(_DWORD *)(*(void *)a1 + 44))) {
    unint64_t v4 = *(void *)a1 + 16 * (((unint64_t)*(unsigned int *)(*(void *)a1 + 44) >> 23) & 1) + 64;
  }
  else {
    unint64_t v4 = 0;
  }
  if ((*(uint64_t (**)(uint64_t))(*(void *)a2 + 104))(a2) <= 5)
  {
    uint64_t Context = (mlir::MLIRContext *)mlir::Attribute::getContext((mlir::Attribute *)(*(void *)a1 + 24));
    uint64_t v6 = mlir::detail::DenseArrayAttrImpl<int>::get(Context, v4 + 24, 5);
    (*(void (**)(uint64_t, uint64_t))(*(void *)a2 + 16))(a2, v6);
  }
  (*(void (**)(uint64_t, void))(*(void *)a2 + 16))(a2, *(void *)v4);
  (*(void (**)(uint64_t, void))(*(void *)a2 + 16))(a2, *(void *)(v4 + 8));
  (*(void (**)(uint64_t, void))(*(void *)a2 + 16))(a2, *(void *)(v4 + 16));
  uint64_t result = (*(uint64_t (**)(uint64_t))(*(void *)a2 + 104))(a2);
  if (result >= 6)
  {
    return mlir::DialectBytecodeWriter::writeSparseArray<int>(a2, (int *)(v4 + 24), 5);
  }
  return result;
}

void mlir::tensor::InsertSliceOp::build(mlir::MLIRContext **a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18)
{
  uint64_t v28 = a5;
  uint64_t v29 = a4;
  mlir::OperationState::addOperands(a2, (uint64_t)&v29, 1);
  mlir::OperationState::addOperands(a2, (uint64_t)&v28, 1);
  mlir::OperationState::addOperands(a2, a6, a7);
  mlir::OperationState::addOperands(a2, a9, a10);
  mlir::OperationState::addOperands(a2, a11, a12);
  uint64_t v22 = mlir::OperationState::getOrAddProperties<mlir::tensor::detail::InsertSliceOpGenericAdaptorBase::Properties>(a2);
  *(void *)(v22 + 24) = 0x100000001;
  *(_DWORD *)(v22 + 32) = a7;
  *(_DWORD *)(v22 + 36) = a10;
  *(_DWORD *)(v22 + 40) = a12;
  uint64_t DenseI64ArrayAttr = mlir::Builder::getDenseI64ArrayAttr(a1, a13, a14);
  *(void *)mlir::OperationState::getOrAddProperties<mlir::tensor::detail::InsertSliceOpGenericAdaptorBase::Properties>(a2) = DenseI64ArrayAttr;
  uint64_t v24 = mlir::Builder::getDenseI64ArrayAttr(a1, a15, a16);
  *(void *)(mlir::OperationState::getOrAddProperties<mlir::tensor::detail::InsertSliceOpGenericAdaptorBase::Properties>(a2)
            + 8) = v24;
  uint64_t v25 = mlir::Builder::getDenseI64ArrayAttr(a1, a17, a18);
  *(void *)(mlir::OperationState::getOrAddProperties<mlir::tensor::detail::InsertSliceOpGenericAdaptorBase::Properties>(a2)
            + 16) = v25;
  uint64_t v26 = *(unsigned int *)(a2 + 72);
  if (v26 >= *(_DWORD *)(a2 + 76))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod(a2 + 64, (void *)(a2 + 80), v26 + 1, 8);
    LODWORD(v26) = *(_DWORD *)(a2 + 72);
  }
  *(void *)(*(void *)(a2 + 64) + 8 * v26) = a3;
  ++*(_DWORD *)(a2 + 72);
}

uint64_t mlir::tensor::InsertSliceOp::verifyInvariantsImpl(mlir::tensor::InsertSliceOp *this)
{
  uint64_t v65 = *MEMORY[0x263EF8340];
  uint64_t v2 = *(void *)this;
  if (HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
    unint64_t v3 = *(void *)this + 16 * (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 23) & 1) + 64;
  }
  else {
    unint64_t v3 = 0;
  }
  unint64_t v4 = *(void **)v3;
  if (!*(void *)v3)
  {
    v55[0] = (void **)"requires attribute 'static_offsets'";
    __int16 v56 = 259;
    mlir::OpState::emitOpError((uint64_t *)this, v55, (uint64_t)v57);
    uint64_t v31 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v57);
    if (v57[0]) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v57);
    }
    if (!v64) {
      return v31;
    }
    uint64_t v34 = __p;
    if (__p)
    {
      uint64_t v35 = v63;
      unint64_t v36 = __p;
      if (v63 != __p)
      {
        do
          uint64_t v35 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v35 - 1);
        while (v35 != v34);
        unint64_t v36 = __p;
      }
      char v63 = v34;
      operator delete(v36);
    }
    unint64_t v37 = v60;
    if (v60)
    {
      unint64_t v38 = v61;
      unint64_t v39 = v60;
      if (v61 == v60) {
        goto LABEL_86;
      }
      do
      {
        uint64_t v41 = *--v38;
        uint64_t v40 = v41;
        *unint64_t v38 = 0;
        if (v41) {
          MEMORY[0x21667D390](v40, 0x1000C8077774924);
        }
      }
      while (v38 != v37);
LABEL_85:
      unint64_t v39 = v60;
LABEL_86:
      uint64_t v61 = v37;
      operator delete(v39);
    }
LABEL_87:
    if (v58 != &v59) {
      free(v58);
    }
    return v31;
  }
  unint64_t v5 = *(void **)(v3 + 8);
  if (!v5)
  {
    v55[0] = (void **)"requires attribute 'static_sizes'";
    __int16 v56 = 259;
    mlir::OpState::emitOpError((uint64_t *)this, v55, (uint64_t)v57);
    uint64_t v31 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v57);
    if (v57[0]) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v57);
    }
    if (!v64) {
      return v31;
    }
    unint64_t v42 = __p;
    if (__p)
    {
      BOOL v43 = v63;
      uint64_t v44 = __p;
      if (v63 != __p)
      {
        do
          BOOL v43 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v43 - 1);
        while (v43 != v42);
        uint64_t v44 = __p;
      }
      char v63 = v42;
      operator delete(v44);
    }
    unint64_t v37 = v60;
    if (v60)
    {
      long long v45 = v61;
      unint64_t v39 = v60;
      if (v61 == v60) {
        goto LABEL_86;
      }
      do
      {
        uint64_t v47 = *--v45;
        uint64_t v46 = v47;
        *long long v45 = 0;
        if (v47) {
          MEMORY[0x21667D390](v46, 0x1000C8077774924);
        }
      }
      while (v45 != v37);
      goto LABEL_85;
    }
    goto LABEL_87;
  }
  uint64_t v6 = *(void **)(v3 + 16);
  if (!v6)
  {
    v55[0] = (void **)"requires attribute 'static_strides'";
    __int16 v56 = 259;
    mlir::OpState::emitOpError((uint64_t *)this, v55, (uint64_t)v57);
    uint64_t v31 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v57);
    if (v57[0]) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v57);
    }
    if (!v64) {
      return v31;
    }
    int64_t v48 = __p;
    if (__p)
    {
      int64_t v49 = v63;
      uint64_t v50 = __p;
      if (v63 != __p)
      {
        do
          int64_t v49 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v49 - 1);
        while (v49 != v48);
        uint64_t v50 = __p;
      }
      char v63 = v48;
      operator delete(v50);
    }
    unint64_t v37 = v60;
    if (v60)
    {
      uint64_t v51 = v61;
      unint64_t v39 = v60;
      if (v61 == v60) {
        goto LABEL_86;
      }
      do
      {
        uint64_t v53 = *--v51;
        uint64_t v52 = v53;
        *uint64_t v51 = 0;
        if (v53) {
          MEMORY[0x21667D390](v52, 0x1000C8077774924);
        }
      }
      while (v51 != v37);
      goto LABEL_85;
    }
    goto LABEL_87;
  }
  v57[0] = v2;
  if (!mlir::memref::__mlir_ods_local_attr_constraint_MemRefOps12(v4, (void **)"static_offsets", (const char *)0xE, (void (*)(uint64_t *__return_ptr, uint64_t))llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::__mlir_ods_local_attr_constraint_TensorOps1(mlir::Operation *,mlir::Attribute,llvm::StringRef)::$_0>, (uint64_t)v57))return 0; {
  v57[0] = *(void *)this;
  }
  if (!mlir::memref::__mlir_ods_local_attr_constraint_MemRefOps12(v5, (void **)"static_sizes", (const char *)0xC, (void (*)(uint64_t *__return_ptr, uint64_t))llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::__mlir_ods_local_attr_constraint_TensorOps1(mlir::Operation *,mlir::Attribute,llvm::StringRef)::$_0>, (uint64_t)v57))return 0; {
  v57[0] = *(void *)this;
  }
  if (!mlir::memref::__mlir_ods_local_attr_constraint_MemRefOps12(v6, (void **)"static_strides", (const char *)0xE, (void (*)(uint64_t *__return_ptr, uint64_t))llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::__mlir_ods_local_attr_constraint_TensorOps1(mlir::Operation *,mlir::Attribute,llvm::StringRef)::$_0>, (uint64_t)v57))return 0; {
  unint64_t v7 = *(unsigned int *)(*(void *)this + 44);
  }
  uint64_t v8 = *(void *)this + 16 * ((v7 >> 23) & 1) + 64;
  if (!HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
    uint64_t v8 = 0;
  }
  uint64_t v9 = *(unsigned int *)(v8 + 24);
  if ((v7 & 0x800000) != 0)
  {
    uint64_t v10 = *(void *)(*(void *)this + 72);
    if (v9) {
      goto LABEL_14;
    }
  }
  else
  {
    uint64_t v10 = 0;
    if (v9)
    {
LABEL_14:
      uint64_t v11 = 0;
      uint64_t v12 = v10 + 24;
      while (mlir::tensor::__mlir_ods_local_type_constraint_TensorOps1(*(void *)this, *(void *)(*(void *)v12 + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"operand", (void **)7, v11))
      {
        ++v11;
        v12 += 32;
        if (v9 == v11) {
          goto LABEL_17;
        }
      }
      return 0;
    }
  }
LABEL_17:
  uint64_t ODSOperands = mlir::memref::ReinterpretCastOp::getODSOperands(this, 1u);
  if (v14)
  {
    uint64_t v15 = v14;
    uint64_t v16 = ODSOperands + 24;
    while (mlir::tensor::__mlir_ods_local_type_constraint_TensorOps1(*(void *)this, *(void *)(*(void *)v16 + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"operand", (void **)7, v9))
    {
      LODWORD(v9) = v9 + 1;
      v16 += 32;
      if (!--v15) {
        goto LABEL_21;
      }
    }
    return 0;
  }
LABEL_21:
  uint64_t v17 = mlir::memref::ReinterpretCastOp::getODSOperands(this, 2u);
  if (v18)
  {
    uint64_t v19 = v18;
    uint64_t v20 = v17 + 24;
    while (mlir::memref::__mlir_ods_local_type_constraint_MemRefOps3(*(void *)this, *(void *)(*(void *)v20 + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"operand", (void **)7, v9))
    {
      LODWORD(v9) = v9 + 1;
      v20 += 32;
      if (!--v19) {
        goto LABEL_25;
      }
    }
    return 0;
  }
LABEL_25:
  uint64_t v21 = mlir::memref::ReinterpretCastOp::getODSOperands(this, 3u);
  if (v22)
  {
    uint64_t v23 = v22;
    uint64_t v24 = v21 + 24;
    while (mlir::memref::__mlir_ods_local_type_constraint_MemRefOps3(*(void *)this, *(void *)(*(void *)v24 + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"operand", (void **)7, v9))
    {
      LODWORD(v9) = v9 + 1;
      v24 += 32;
      if (!--v23) {
        goto LABEL_29;
      }
    }
    return 0;
  }
LABEL_29:
  uint64_t v25 = mlir::memref::ReinterpretCastOp::getODSOperands(this, 4u);
  if (v26)
  {
    uint64_t v27 = v26;
    uint64_t v28 = v25 + 24;
    while (mlir::memref::__mlir_ods_local_type_constraint_MemRefOps3(*(void *)this, *(void *)(*(void *)v28 + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"operand", (void **)7, v9))
    {
      LODWORD(v9) = v9 + 1;
      v28 += 32;
      if (!--v27) {
        goto LABEL_33;
      }
    }
    return 0;
  }
LABEL_33:
  uint64_t v29 = *(_DWORD *)(*(void *)this + 36) ? *(void *)this - 16 : 0;
  uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v29, 0);
  if (!mlir::tensor::__mlir_ods_local_type_constraint_TensorOps1(*(void *)this, *(void *)(NextResultAtOffset + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"result", (void **)6, 0))return 0; {
  uint64_t v31 = 1;
  }
  unint64_t v32 = *(void *)(*(void *)(mlir::memref::ReinterpretCastOp::getODSOperands(this, 1u) + 24) + 8) & 0xFFFFFFFFFFFFFFF8;
  if (*(_DWORD *)(*(void *)this + 36)) {
    uint64_t v33 = *(void *)this - 16;
  }
  else {
    uint64_t v33 = 0;
  }
  if (v32 != (*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v33, 0) + 8) & 0xFFFFFFFFFFFFFFF8))
  {
    v55[0] = (void **)"failed to verify that expected result type to match dest type";
    __int16 v56 = 259;
    mlir::OpState::emitOpError((uint64_t *)this, v55, (uint64_t)v57);
    uint64_t v31 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v57);
    mlir::InFlightDiagnostic::~InFlightDiagnostic((mlir::InFlightDiagnostic *)v57);
  }
  return v31;
}

uint64_t mlir::tensor::InsertSliceOp::parse(uint64_t a1, uint64_t a2)
{
  v58[4] = *MEMORY[0x263EF8340];
  memset(v58, 0, 24);
  v41[0] = (uint64_t)v58;
  v41[1] = 1;
  memset(v57, 0, 24);
  v40[0] = (uint64_t)v57;
  v40[1] = 1;
  unsigned int v54 = v56;
  uint64_t v55 = 0x400000000;
  uint64_t v38 = 0;
  uint64_t v39 = 0;
  uint64_t v51 = v53;
  uint64_t v52 = 0x400000000;
  uint64_t v47 = 0;
  int64_t v48 = v50;
  uint64_t v49 = 0x400000000;
  v36[1] = 1;
  uint64_t v37 = 0;
  v35[1] = 1;
  v36[0] = &v47;
  uint64_t __src = 0;
  v35[0] = &__src;
  uint64_t v4 = (*(uint64_t (**)(uint64_t))(*(void *)a1 + 40))(a1);
  if (!(*(unsigned __int8 (**)(uint64_t, void *, uint64_t))(*(void *)a1 + 672))(a1, v58, 1)) {
    goto LABEL_31;
  }
  __int16 v45 = 257;
  if (!(*(unsigned __int8 (**)(uint64_t, const char *, uint64_t, uint64_t *))(*(void *)a1 + 368))(a1, "into", 4, &v42))goto LABEL_31; {
  uint64_t v5 = (*(uint64_t (**)(uint64_t))(*(void *)a1 + 40))(a1);
  }
  if (!(*(unsigned __int8 (**)(uint64_t, void *, uint64_t))(*(void *)a1 + 672))(a1, v57, 1)) {
    goto LABEL_31;
  }
  (*(void (**)(uint64_t))(*(void *)a1 + 40))(a1);
  uint64_t v42 = 0;
  if (!mlir::parseDynamicIndexList(a1, (uint64_t)&v54, &v39, &v42, 0)) {
    goto LABEL_31;
  }
  uint64_t v6 = (void *)mlir::OperationState::getOrAddProperties<mlir::tensor::detail::InsertSliceOpGenericAdaptorBase::Properties>(a2);
  void *v6 = v39;
  (*(void (**)(uint64_t))(*(void *)a1 + 40))(a1);
  uint64_t v42 = 0;
  if (!mlir::parseDynamicIndexList(a1, (uint64_t)&v51, &v38, &v42, 0)) {
    goto LABEL_31;
  }
  uint64_t v7 = mlir::OperationState::getOrAddProperties<mlir::tensor::detail::InsertSliceOpGenericAdaptorBase::Properties>(a2);
  *(void *)(v7 + 8) = v38;
  (*(void (**)(uint64_t))(*(void *)a1 + 40))(a1);
  uint64_t v42 = 0;
  if (!mlir::parseDynamicIndexList(a1, (uint64_t)&v48, &v37, &v42, 0)) {
    goto LABEL_31;
  }
  uint64_t v8 = mlir::OperationState::getOrAddProperties<mlir::tensor::detail::InsertSliceOpGenericAdaptorBase::Properties>(a2);
  *(void *)(v8 + 16) = v37;
  v32[0] = (*(uint64_t (**)(uint64_t))(*(void *)a1 + 40))(a1);
  if (!(*(unsigned __int8 (**)(uint64_t, uint64_t))(*(void *)a1 + 456))(a1, a2 + 112)) {
    goto LABEL_31;
  }
  uint64_t v9 = *(void *)(a2 + 8);
  uint64_t v42 = a1;
  BOOL v43 = v32;
  uint64_t v44 = a2;
  if (!mlir::memref::ReinterpretCastOp::verifyInherentAttrs(v9, a2 + 112, (void (*)(uint64_t *__return_ptr, uint64_t))llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::InsertSliceOp::parse(mlir::OpAsmParser &,mlir::OperationState &)::$_0>, (uint64_t)&v42))goto LABEL_31; {
  if (!(*(unsigned __int8 (**)(uint64_t))(*(void *)a1 + 104))(a1))
  }
    goto LABEL_31;
  uint64_t v42 = 0;
  if (!mlir::AsmParser::parseType<mlir::RankedTensorType>(a1, &v42)) {
    goto LABEL_31;
  }
  uint64_t v47 = v42;
  __int16 v45 = 257;
  if (!(*(unsigned __int8 (**)(uint64_t, const char *, uint64_t, uint64_t *))(*(void *)a1 + 368))(a1, "into", 4, &v42))goto LABEL_31; {
  uint64_t v42 = 0;
  }
  if (!mlir::AsmParser::parseType<mlir::RankedTensorType>(a1, &v42)) {
    goto LABEL_31;
  }
  uint64_t __src = v42;
  int v10 = v55;
  int v11 = v52;
  int v12 = v49;
  uint64_t v13 = mlir::OperationState::getOrAddProperties<mlir::tensor::detail::InsertSliceOpGenericAdaptorBase::Properties>(a2);
  *(void *)(v13 + 24) = 0x100000001;
  *(_DWORD *)(v13 + 32) = v10;
  *(_DWORD *)(v13 + 36) = v11;
  *(_DWORD *)(v13 + 40) = v12;
  uint64_t v14 = __src;
  uint64_t v34 = __src;
  if (*(_UNKNOWN **)(*(void *)__src + 136) != &mlir::detail::TypeIDResolver<mlir::RankedTensorType,void>::id)
  {
    uint64_t v15 = (*(uint64_t (**)(uint64_t))(*(void *)a1 + 16))(a1);
    __int16 v33 = 257;
    (*(void (**)(uint64_t *__return_ptr, uint64_t, uint64_t, void *))(*(void *)a1 + 24))(&v42, a1, v15, v32);
    uint64_t v16 = mlir::InFlightDiagnostic::operator<<<char const(&)[44]>((uint64_t)&v42, "'dest' must be ranked tensor of any type values, but got ");
    uint64_t v17 = mlir::InFlightDiagnostic::append<mlir::Type &>(v16, &v34);
    uint64_t v18 = mlir::InFlightDiagnostic::operator mlir::LogicalResult(v17);
    mlir::InFlightDiagnostic::~InFlightDiagnostic((mlir::InFlightDiagnostic *)&v42);
    uint64_t v19 = v48;
    if (v48 == v50) {
      goto LABEL_34;
    }
LABEL_33:
    free(v19);
    goto LABEL_34;
  }
  uint64_t v20 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*(void *)__src + 8);
  uint64_t v42 = v14;
  BOOL v43 = (void *)v20;
  mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&v42);
  uint64_t v21 = (mlir::IndexType **)(*(uint64_t (**)(uint64_t))(*(void *)a1 + 32))(a1);
  uint64_t IndexType = mlir::Builder::getIndexType(v21, v22);
  mlir::OperationState::addTypes(a2, &__src, 1);
  uint64_t v24 = a2 + 16;
  if (!mlir::OpAsmParser::resolveOperands<llvm::ArrayRef<mlir::OpAsmParser::UnresolvedOperand> &,llvm::ArrayRef<mlir::Type> &>(a1, v41, v36, v4, v24)|| !mlir::OpAsmParser::resolveOperands<llvm::ArrayRef<mlir::OpAsmParser::UnresolvedOperand> &,llvm::ArrayRef<mlir::Type> &>(a1, v40, v35, v5, v24))
  {
    goto LABEL_31;
  }
  if (v55)
  {
    uint64_t v25 = (char *)v54;
    uint64_t v26 = 32 * v55;
    while ((*(unsigned __int8 (**)(uint64_t, char *, uint64_t, uint64_t))(*(void *)a1 + 696))(a1, v25, IndexType, v24))
    {
      v25 += 32;
      v26 -= 32;
      if (!v26) {
        goto LABEL_22;
      }
    }
LABEL_31:
    uint64_t v18 = 0;
LABEL_32:
    uint64_t v19 = v48;
    if (v48 != v50) {
      goto LABEL_33;
    }
    goto LABEL_34;
  }
LABEL_22:
  if (v52)
  {
    uint64_t v27 = (char *)v51;
    uint64_t v28 = 32 * v52;
    while ((*(unsigned __int8 (**)(uint64_t, char *, uint64_t, uint64_t))(*(void *)a1 + 696))(a1, v27, IndexType, v24))
    {
      v27 += 32;
      v28 -= 32;
      if (!v28) {
        goto LABEL_26;
      }
    }
    goto LABEL_31;
  }
LABEL_26:
  if (v49)
  {
    uint64_t v29 = (char *)v48;
    uint64_t v30 = 32 * v49;
    uint64_t v18 = 1;
    while ((*(unsigned __int8 (**)(uint64_t, char *, uint64_t, uint64_t))(*(void *)a1 + 696))(a1, v29, IndexType, v24))
    {
      v29 += 32;
      v30 -= 32;
      if (!v30) {
        goto LABEL_32;
      }
    }
    goto LABEL_31;
  }
  uint64_t v18 = 1;
  uint64_t v19 = v48;
  if (v48 != v50) {
    goto LABEL_33;
  }
LABEL_34:
  if (v51 != v53) {
    free(v51);
  }
  if (v54 != v56) {
    free(v54);
  }
  return v18;
}

void mlir::tensor::InsertSliceOp::print(mlir::tensor::InsertSliceOp *this, mlir::OpAsmPrinter *a2)
{
  v77[2] = *MEMORY[0x263EF8340];
  uint64_t v4 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v5 = (unsigned char *)*((void *)v4 + 4);
  if ((unint64_t)v5 >= *((void *)v4 + 3))
  {
    llvm::raw_ostream::write(v4, 32);
  }
  else
  {
    *((void *)v4 + 4) = v5 + 1;
    unsigned char *v5 = 32;
  }
  (*(void (**)(mlir::OpAsmPrinter *, void))(*(void *)a2 + 160))(a2, *(void *)(*(void *)(*(void *)this + 72) + 24));
  uint64_t v6 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v7 = (unsigned char *)*((void *)v6 + 4);
  if ((unint64_t)v7 >= *((void *)v6 + 3))
  {
    llvm::raw_ostream::write(v6, 32);
  }
  else
  {
    *((void *)v6 + 4) = v7 + 1;
    *uint64_t v7 = 32;
  }
  uint64_t v8 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v9 = (_DWORD *)*((void *)v8 + 4);
  if (*((void *)v8 + 3) - (void)v9 > 3uLL)
  {
    *uint64_t v9 = 1869901417;
    *((void *)v8 + 4) += 4;
  }
  else
  {
    llvm::raw_ostream::write(v8, "into", 4uLL);
  }
  int v10 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  int v11 = (unsigned char *)*((void *)v10 + 4);
  if ((unint64_t)v11 >= *((void *)v10 + 3))
  {
    llvm::raw_ostream::write(v10, 32);
  }
  else
  {
    *((void *)v10 + 4) = v11 + 1;
    *int v11 = 32;
  }
  if (*(unsigned char *)(*(void *)this + 47)) {
    uint64_t v12 = *(void *)this + 80;
  }
  else {
    uint64_t v12 = 0;
  }
  (*(void (**)(mlir::OpAsmPrinter *, void))(*(void *)a2 + 160))(a2, *(void *)(*(void *)(*(void *)this + 72) + 32 * *(unsigned int *)(v12 + 24) + 24));
  uint64_t v13 = *(void *)this;
  unint64_t v14 = *(unsigned int *)(*(void *)this + 44);
  uint64_t v15 = (void **)(*(void *)this + 16 * ((v14 >> 23) & 1) + 64);
  if (HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
    uint64_t v16 = (_DWORD *)(*(void *)this + 16 * ((v14 >> 23) & 1) + 64);
  }
  else {
    uint64_t v16 = 0;
  }
  int v17 = v16[6];
  int v18 = v16[7];
  int v19 = v16[8];
  if ((v14 & 0x800000) != 0) {
    uint64_t v20 = *(void *)(v13 + 72);
  }
  else {
    uint64_t v20 = 0;
  }
  uint64_t v21 = (v18 + v17);
  uint64_t v22 = v20 + 32 * v21;
  uint64_t v23 = (v19 + v21) - v21;
  int64_t v72 = *v15;
  uint64_t v24 = (unint64_t *)mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)&v72);
  uint64_t v26 = v25;
  mlir::ValueRange::ValueRange(v77, 0, 0);
  mlir::printDynamicIndexList((uint64_t)a2, v13, v22, v23, v24, v26, v77[0], v77[1], 0, 0, 2);
  uint64_t v27 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v28 = (unsigned char *)*((void *)v27 + 4);
  if ((unint64_t)v28 >= *((void *)v27 + 3))
  {
    llvm::raw_ostream::write(v27, 32);
  }
  else
  {
    *((void *)v27 + 4) = v28 + 1;
    *uint64_t v28 = 32;
  }
  uint64_t v29 = *(void *)this;
  unint64_t v30 = *(unsigned int *)(*(void *)this + 44);
  uint64_t v31 = *(void *)this + 16 * ((v30 >> 23) & 1) + 64;
  if (!HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
    uint64_t v31 = 0;
  }
  if ((v30 & 0x800000) != 0) {
    uint64_t v32 = *(void *)(v29 + 72);
  }
  else {
    uint64_t v32 = 0;
  }
  uint64_t v33 = (*(_DWORD *)(v31 + 28) + *(_DWORD *)(v31 + 24) + *(_DWORD *)(v31 + 32));
  uint64_t v34 = v32 + 32 * v33;
  uint64_t v35 = (*(_DWORD *)(v31 + 36) + v33) - v33;
  int64_t v72 = *(void **)(v31 + 8);
  unint64_t v36 = (unint64_t *)mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)&v72);
  uint64_t v38 = v37;
  mlir::ValueRange::ValueRange(v76, 0, 0);
  mlir::printDynamicIndexList((uint64_t)a2, v29, v34, v35, v36, v38, v76[0], v76[1], 0, 0, 2);
  uint64_t v39 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v40 = (unsigned char *)*((void *)v39 + 4);
  if ((unint64_t)v40 >= *((void *)v39 + 3))
  {
    llvm::raw_ostream::write(v39, 32);
  }
  else
  {
    *((void *)v39 + 4) = v40 + 1;
    *uint64_t v40 = 32;
  }
  uint64_t v41 = *(void *)this;
  unint64_t v42 = *(unsigned int *)(*(void *)this + 44);
  uint64_t v43 = *(void *)this + 16 * ((v42 >> 23) & 1) + 64;
  if (!HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
    uint64_t v43 = 0;
  }
  if ((v42 & 0x800000) != 0) {
    uint64_t v44 = *(void *)(v41 + 72);
  }
  else {
    uint64_t v44 = 0;
  }
  uint64_t v45 = (*(_DWORD *)(v43 + 28) + *(_DWORD *)(v43 + 24) + *(_DWORD *)(v43 + 32) + *(_DWORD *)(v43 + 36));
  uint64_t v46 = v44 + 32 * v45;
  uint64_t v47 = (*(_DWORD *)(v43 + 40) + v45) - v45;
  int64_t v72 = *(void **)(v43 + 16);
  int64_t v48 = (unint64_t *)mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)&v72);
  uint64_t v50 = v49;
  mlir::ValueRange::ValueRange(v75, 0, 0);
  mlir::printDynamicIndexList((uint64_t)a2, v41, v46, v47, v48, v50, v75[0], v75[1], 0, 0, 2);
  int64_t v72 = v74;
  v74[0] = "operandSegmentSizes";
  v74[1] = 19;
  v74[2] = "static_offsets";
  v74[3] = 14;
  uint64_t v73 = 0x200000002;
  llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v72, v74, 3uLL, 16);
  uint64_t v51 = (char *)v72 + 16 * v73;
  *uint64_t v51 = "static_sizes";
  v51[1] = 12;
  uint64_t v52 = (v73 + 1);
  LODWORD(v73) = v52;
  if (v52 >= HIDWORD(v73))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v72, v74, v52 + 1, 16);
    LODWORD(v52) = v73;
  }
  uint64_t v53 = (char *)v72 + 16 * v52;
  *uint64_t v53 = "static_strides";
  v53[1] = 14;
  LODWORD(v73) = v73 + 1;
  unsigned int v54 = *(mlir::Operation **)this;
  if (*(unsigned char *)(*(void *)this + 47))
  {
    unint64_t AttrDictionary = mlir::Operation::getAttrDictionary(v54);
    p_unint64_t AttrDictionary = (mlir::ArrayAttr *)&AttrDictionary;
  }
  else
  {
    p_unint64_t AttrDictionary = (mlir::Operation *)((char *)v54 + 56);
  }
  uint64_t Value = mlir::ArrayAttr::getValue(p_AttrDictionary);
  (*(void (**)(mlir::OpAsmPrinter *, uint64_t, uint64_t, void *, void))(*(void *)a2 + 192))(a2, Value, v57, v72, v73);
  uint64_t v58 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v59 = (unsigned char *)*((void *)v58 + 4);
  if ((unint64_t)v59 >= *((void *)v58 + 3))
  {
    llvm::raw_ostream::write(v58, 32);
  }
  else
  {
    *((void *)v58 + 4) = v59 + 1;
    *uint64_t v59 = 32;
  }
  uint64_t v60 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v61 = (unsigned char *)*((void *)v60 + 4);
  if (*((unsigned char **)v60 + 3) == v61)
  {
    llvm::raw_ostream::write(v60, ":", 1uLL);
  }
  else
  {
    unsigned char *v61 = 58;
    ++*((void *)v60 + 4);
  }
  unsigned int v62 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  char v63 = (unsigned char *)*((void *)v62 + 4);
  if ((unint64_t)v63 >= *((void *)v62 + 3))
  {
    llvm::raw_ostream::write(v62, 32);
  }
  else
  {
    *((void *)v62 + 4) = v63 + 1;
    *char v63 = 32;
  }
  (*(void (**)(mlir::OpAsmPrinter *, unint64_t))(*(void *)a2 + 32))(a2, *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8);
  char v64 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v65 = (unsigned char *)*((void *)v64 + 4);
  if ((unint64_t)v65 >= *((void *)v64 + 3))
  {
    llvm::raw_ostream::write(v64, 32);
  }
  else
  {
    *((void *)v64 + 4) = v65 + 1;
    *uint64_t v65 = 32;
  }
  unint64_t v66 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  unint64_t v67 = (_DWORD *)*((void *)v66 + 4);
  if (*((void *)v66 + 3) - (void)v67 > 3uLL)
  {
    *unint64_t v67 = 1869901417;
    *((void *)v66 + 4) += 4;
  }
  else
  {
    llvm::raw_ostream::write(v66, "into", 4uLL);
  }
  unint64_t v68 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  long long v69 = (unsigned char *)*((void *)v68 + 4);
  if ((unint64_t)v69 >= *((void *)v68 + 3))
  {
    llvm::raw_ostream::write(v68, 32);
  }
  else
  {
    *((void *)v68 + 4) = v69 + 1;
    *long long v69 = 32;
  }
  if (*(unsigned char *)(*(void *)this + 47)) {
    uint64_t v70 = *(void *)this + 80;
  }
  else {
    uint64_t v70 = 0;
  }
  (*(void (**)(mlir::OpAsmPrinter *, unint64_t))(*(void *)a2 + 32))(a2, *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 32 * *(unsigned int *)(v70 + 24) + 24) + 8) & 0xFFFFFFFFFFFFFFF8);
  if (v72 != v74) {
    free(v72);
  }
}

uint64_t mlir::tensor::detail::PackOpGenericAdaptorBase::PackOpGenericAdaptorBase(uint64_t a1, uint64_t a2)
{
  uint64_t v13 = *MEMORY[0x263EF8340];
  uint64_t v3 = *(void *)(a2 + 56);
  unint64_t v4 = *(unsigned int *)(a2 + 44);
  if (HIBYTE(*(_DWORD *)(a2 + 44))) {
    uint64_t v5 = a2 + 16 * ((v4 >> 23) & 1) + 64;
  }
  else {
    uint64_t v5 = 0;
  }
  unint64_t v6 = v4 & 0x7FFFFF;
  if ((v4 & 0x7FFFFF) != 0)
  {
    uint64_t v7 = ((a2 + 16 * ((v4 >> 23) & 1) + 64 + ((v4 >> 21) & 0x7F8) + 7) & 0xFFFFFFFFFFFFFFF8)
       + 32 * *(unsigned int *)(a2 + 40);
  }
  else
  {
    uint64_t v7 = 0;
    unint64_t v6 = 0;
  }
  mlir::ValueRange::ValueRange(v12, v7, v6);
  *(void *)a1 = v3;
  *(unsigned char *)(a1 + 8) = 0;
  *(unsigned char *)(a1 + 16) = 0;
  long long v8 = *(_OWORD *)v5;
  long long v9 = *(_OWORD *)(v5 + 16);
  *(void *)(a1 + 56) = *(void *)(v5 + 32);
  *(_OWORD *)(a1 + 40) = v9;
  *(_OWORD *)(a1 + 24) = v8;
  *(_OWORD *)(a1 + 64) = *(_OWORD *)v12;
  if (v3)
  {
    uint64_t Context = mlir::Attribute::getContext((mlir::Attribute *)a1);
    if (*(unsigned char *)(a1 + 16)) {
      *(unsigned char *)(a1 + 16) = 0;
    }
    mlir::OperationName::OperationName(a1 + 8, "tensor.pack", 11, Context);
    *(unsigned char *)(a1 + 16) = 1;
  }
  return a1;
}

uint64_t mlir::tensor::PackOp::setPropertiesFromAttr(uint64_t *a1, uint64_t a2, void (*a3)(uint64_t *__return_ptr, uint64_t), uint64_t a4)
{
  uint64_t v122 = *MEMORY[0x263EF8340];
  if (*(_UNKNOWN **)(*(void *)a2 + 136) == &mlir::detail::TypeIDResolver<mlir::DictionaryAttr,void>::id) {
    uint64_t v6 = a2;
  }
  else {
    uint64_t v6 = 0;
  }
  uint64_t v108 = v6;
  if (!v6)
  {
    a3(v112, a4);
    if (v112[0])
    {
      int v109 = 3;
      unsigned int v110 = "expected DictionaryAttr to set properties";
      uint64_t v111 = 41;
      uint64_t v16 = &v109;
      int v17 = (char *)v113;
      if (v114 >= v115)
      {
        unint64_t v90 = v114 + 1;
        if (v113 <= &v109 && (char *)v113 + 24 * v114 > (char *)&v109)
        {
          int64_t v99 = (char *)&v109 - (unsigned char *)v113;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v113, v116, v90, 24);
          int v17 = (char *)v113;
          uint64_t v16 = (int *)((char *)v113 + v99);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v113, v116, v90, 24);
          uint64_t v16 = &v109;
          int v17 = (char *)v113;
        }
      }
      int v18 = &v17[24 * v114];
      long long v19 = *(_OWORD *)v16;
      *((void *)v18 + 2) = *((void *)v16 + 2);
      *(_OWORD *)int v18 = v19;
      ++v114;
      if (v112[0]) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v112);
      }
    }
    if (!v121) {
      return 0;
    }
    uint64_t v20 = __p;
    if (__p)
    {
      uint64_t v21 = v120;
      uint64_t v22 = __p;
      if (v120 != __p)
      {
        do
          uint64_t v21 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v21 - 1);
        while (v21 != v20);
        uint64_t v22 = __p;
      }
      char v120 = v20;
      operator delete(v22);
    }
    uint64_t v23 = v117;
    if (!v117) {
      goto LABEL_120;
    }
    uint64_t v24 = v118;
    uint64_t v25 = v117;
    if (v118 == v117)
    {
LABEL_119:
      uint64_t v118 = v23;
      operator delete(v25);
LABEL_120:
      if (v113 != v116) {
        free(v113);
      }
      return 0;
    }
    do
    {
      uint64_t v27 = *--v24;
      uint64_t v26 = v27;
      *uint64_t v24 = 0;
      if (v27) {
        MEMORY[0x21667D390](v26, 0x1000C8077774924);
      }
    }
    while (v24 != v23);
LABEL_118:
    uint64_t v25 = v117;
    goto LABEL_119;
  }
  long long v8 = (void *)mlir::DictionaryAttr::get((uint64_t)&v108, "inner_dims_pos", 0xEuLL);
  if (!v8)
  {
    a3(v112, a4);
    if (v112[0])
    {
      int v109 = 3;
      unsigned int v110 = "expected key entry for inner_dims_pos in DictionaryAttr to set Properties.";
      uint64_t v111 = 74;
      uint64_t v28 = &v109;
      uint64_t v29 = (char *)v113;
      if (v114 >= v115)
      {
        unint64_t v91 = v114 + 1;
        if (v113 <= &v109 && (char *)v113 + 24 * v114 > (char *)&v109)
        {
          int64_t v100 = (char *)&v109 - (unsigned char *)v113;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v113, v116, v91, 24);
          uint64_t v29 = (char *)v113;
          uint64_t v28 = (int *)((char *)v113 + v100);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v113, v116, v91, 24);
          uint64_t v28 = &v109;
          uint64_t v29 = (char *)v113;
        }
      }
      unint64_t v30 = &v29[24 * v114];
      long long v31 = *(_OWORD *)v28;
      *((void *)v30 + 2) = *((void *)v28 + 2);
      *(_OWORD *)unint64_t v30 = v31;
      ++v114;
      if (v112[0]) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v112);
      }
    }
    if (!v121) {
      return 0;
    }
    uint64_t v32 = __p;
    if (__p)
    {
      uint64_t v33 = v120;
      uint64_t v34 = __p;
      if (v120 != __p)
      {
        do
          uint64_t v33 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v33 - 1);
        while (v33 != v32);
        uint64_t v34 = __p;
      }
      char v120 = v32;
      operator delete(v34);
    }
    uint64_t v23 = v117;
    if (!v117) {
      goto LABEL_120;
    }
    uint64_t v35 = v118;
    uint64_t v25 = v117;
    if (v118 == v117) {
      goto LABEL_119;
    }
    do
    {
      uint64_t v37 = *--v35;
      uint64_t v36 = v37;
      *uint64_t v35 = 0;
      if (v37) {
        MEMORY[0x21667D390](v36, 0x1000C8077774924);
      }
    }
    while (v35 != v23);
    goto LABEL_118;
  }
  uint64_t v9 = (uint64_t)v8;
  if (!mlir::detail::DenseArrayAttrImpl<long long>::classof(v8))
  {
    a3(v112, a4);
    if (v112[0])
    {
      int v109 = 3;
      uint64_t v111 = 59;
      uint64_t v38 = &v109;
      uint64_t v39 = (char *)v113;
      if (v114 >= v115)
      {
        unint64_t v92 = v114 + 1;
        if (v113 <= &v109 && (char *)v113 + 24 * v114 > (char *)&v109)
        {
          int64_t v101 = (char *)&v109 - (unsigned char *)v113;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v113, v116, v92, 24);
          uint64_t v39 = (char *)v113;
          uint64_t v38 = (int *)((char *)v113 + v101);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v113, v116, v92, 24);
          uint64_t v38 = &v109;
          uint64_t v39 = (char *)v113;
        }
      }
      uint64_t v40 = &v39[24 * v114];
      long long v41 = *(_OWORD *)v38;
      *((void *)v40 + 2) = *((void *)v38 + 2);
      *(_OWORD *)uint64_t v40 = v41;
      ++v114;
      if (v112[0])
      {
        unint64_t v42 = &v109;
        mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v109, v9);
        uint64_t v43 = (char *)v113;
        if (v114 >= v115)
        {
          unint64_t v93 = v114 + 1;
          if (v113 <= &v109 && (char *)v113 + 24 * v114 > (char *)&v109)
          {
            int64_t v102 = (char *)&v109 - (unsigned char *)v113;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v113, v116, v93, 24);
            uint64_t v43 = (char *)v113;
            unint64_t v42 = (int *)((char *)v113 + v102);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v113, v116, v93, 24);
            unint64_t v42 = &v109;
            uint64_t v43 = (char *)v113;
          }
        }
        uint64_t v44 = &v43[24 * v114];
        long long v45 = *(_OWORD *)v42;
        *((void *)v44 + 2) = *((void *)v42 + 2);
        *(_OWORD *)uint64_t v44 = v45;
        ++v114;
        if (v112[0]) {
          mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v112);
        }
      }
    }
    if (!v121) {
      return 0;
    }
    uint64_t v46 = __p;
    if (__p)
    {
      uint64_t v47 = v120;
      int64_t v48 = __p;
      if (v120 != __p)
      {
        do
          uint64_t v47 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v47 - 1);
        while (v47 != v46);
        int64_t v48 = __p;
      }
      char v120 = v46;
      operator delete(v48);
    }
    uint64_t v23 = v117;
    if (!v117) {
      goto LABEL_120;
    }
    uint64_t v49 = v118;
    uint64_t v25 = v117;
    if (v118 == v117) {
      goto LABEL_119;
    }
    do
    {
      uint64_t v51 = *--v49;
      uint64_t v50 = v51;
      *uint64_t v49 = 0;
      if (v51) {
        MEMORY[0x21667D390](v50, 0x1000C8077774924);
      }
    }
    while (v49 != v23);
    goto LABEL_118;
  }
  *a1 = v9;
  int v10 = (void *)mlir::DictionaryAttr::get((uint64_t)&v108, "outer_dims_perm", 0xFuLL);
  if (!v10) {
    goto LABEL_10;
  }
  uint64_t v11 = (uint64_t)v10;
  if (!mlir::detail::DenseArrayAttrImpl<long long>::classof(v10))
  {
    a3(v112, a4);
    if (v112[0])
    {
      int v109 = 3;
      uint64_t v111 = 60;
      uint64_t v52 = &v109;
      uint64_t v53 = (char *)v113;
      if (v114 >= v115)
      {
        unint64_t v94 = v114 + 1;
        if (v113 <= &v109 && (char *)v113 + 24 * v114 > (char *)&v109)
        {
          int64_t v103 = (char *)&v109 - (unsigned char *)v113;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v113, v116, v94, 24);
          uint64_t v53 = (char *)v113;
          uint64_t v52 = (int *)((char *)v113 + v103);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v113, v116, v94, 24);
          uint64_t v52 = &v109;
          uint64_t v53 = (char *)v113;
        }
      }
      unsigned int v54 = &v53[24 * v114];
      long long v55 = *(_OWORD *)v52;
      *((void *)v54 + 2) = *((void *)v52 + 2);
      *(_OWORD *)unsigned int v54 = v55;
      ++v114;
      if (v112[0])
      {
        __int16 v56 = &v109;
        mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v109, v11);
        uint64_t v57 = (char *)v113;
        if (v114 >= v115)
        {
          unint64_t v97 = v114 + 1;
          if (v113 <= &v109 && (char *)v113 + 24 * v114 > (char *)&v109)
          {
            int64_t v106 = (char *)&v109 - (unsigned char *)v113;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v113, v116, v97, 24);
            uint64_t v57 = (char *)v113;
            __int16 v56 = (int *)((char *)v113 + v106);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v113, v116, v97, 24);
            __int16 v56 = &v109;
            uint64_t v57 = (char *)v113;
          }
        }
        uint64_t v58 = &v57[24 * v114];
        long long v59 = *(_OWORD *)v56;
        *((void *)v58 + 2) = *((void *)v56 + 2);
        *(_OWORD *)uint64_t v58 = v59;
        ++v114;
        if (v112[0]) {
          mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v112);
        }
      }
    }
    if (!v121) {
      return 0;
    }
    uint64_t v60 = __p;
    if (__p)
    {
      uint64_t v61 = v120;
      unsigned int v62 = __p;
      if (v120 != __p)
      {
        do
          uint64_t v61 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v61 - 1);
        while (v61 != v60);
        unsigned int v62 = __p;
      }
      char v120 = v60;
      operator delete(v62);
    }
    uint64_t v23 = v117;
    if (!v117) {
      goto LABEL_120;
    }
    char v63 = v118;
    uint64_t v25 = v117;
    if (v118 == v117) {
      goto LABEL_119;
    }
    do
    {
      uint64_t v65 = *--v63;
      uint64_t v64 = v65;
      *char v63 = 0;
      if (v65) {
        MEMORY[0x21667D390](v64, 0x1000C8077774924);
      }
    }
    while (v63 != v23);
    goto LABEL_118;
  }
  a1[1] = v11;
LABEL_10:
  uint64_t v12 = (void *)mlir::DictionaryAttr::get((uint64_t)&v108, "static_inner_tiles", 0x12uLL);
  if (!v12)
  {
    a3(v112, a4);
    if (v112[0])
    {
      int v109 = 3;
      unsigned int v110 = "expected key entry for static_inner_tiles in DictionaryAttr to set Properties.";
      uint64_t v111 = 78;
      unint64_t v66 = &v109;
      unint64_t v67 = (char *)v113;
      if (v114 >= v115)
      {
        unint64_t v95 = v114 + 1;
        if (v113 <= &v109 && (char *)v113 + 24 * v114 > (char *)&v109)
        {
          int64_t v104 = (char *)&v109 - (unsigned char *)v113;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v113, v116, v95, 24);
          unint64_t v67 = (char *)v113;
          unint64_t v66 = (int *)((char *)v113 + v104);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v113, v116, v95, 24);
          unint64_t v66 = &v109;
          unint64_t v67 = (char *)v113;
        }
      }
      unint64_t v68 = &v67[24 * v114];
      long long v69 = *(_OWORD *)v66;
      *((void *)v68 + 2) = *((void *)v66 + 2);
      *(_OWORD *)unint64_t v68 = v69;
      ++v114;
      if (v112[0]) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v112);
      }
    }
    if (!v121) {
      return 0;
    }
    uint64_t v70 = __p;
    if (__p)
    {
      int64_t v71 = v120;
      int64_t v72 = __p;
      if (v120 != __p)
      {
        do
          int64_t v71 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v71 - 1);
        while (v71 != v70);
        int64_t v72 = __p;
      }
      char v120 = v70;
      operator delete(v72);
    }
    uint64_t v23 = v117;
    if (!v117) {
      goto LABEL_120;
    }
    uint64_t v73 = v118;
    uint64_t v25 = v117;
    if (v118 == v117) {
      goto LABEL_119;
    }
    do
    {
      uint64_t v75 = *--v73;
      uint64_t v74 = v75;
      *uint64_t v73 = 0;
      if (v75) {
        MEMORY[0x21667D390](v74, 0x1000C8077774924);
      }
    }
    while (v73 != v23);
    goto LABEL_118;
  }
  uint64_t v13 = (uint64_t)v12;
  if (!mlir::detail::DenseArrayAttrImpl<long long>::classof(v12))
  {
    a3(v112, a4);
    if (v112[0])
    {
      int v109 = 3;
      uint64_t v111 = 63;
      int v76 = &v109;
      int v77 = (char *)v113;
      if (v114 >= v115)
      {
        unint64_t v96 = v114 + 1;
        if (v113 <= &v109 && (char *)v113 + 24 * v114 > (char *)&v109)
        {
          int64_t v105 = (char *)&v109 - (unsigned char *)v113;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v113, v116, v96, 24);
          int v77 = (char *)v113;
          int v76 = (int *)((char *)v113 + v105);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v113, v116, v96, 24);
          int v76 = &v109;
          int v77 = (char *)v113;
        }
      }
      uint64_t v78 = &v77[24 * v114];
      long long v79 = *(_OWORD *)v76;
      *((void *)v78 + 2) = *((void *)v76 + 2);
      *(_OWORD *)uint64_t v78 = v79;
      ++v114;
      if (v112[0])
      {
        BOOL v80 = &v109;
        mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v109, v13);
        unsigned int v81 = (char *)v113;
        if (v114 >= v115)
        {
          unint64_t v98 = v114 + 1;
          if (v113 <= &v109 && (char *)v113 + 24 * v114 > (char *)&v109)
          {
            int64_t v107 = (char *)&v109 - (unsigned char *)v113;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v113, v116, v98, 24);
            unsigned int v81 = (char *)v113;
            BOOL v80 = (int *)((char *)v113 + v107);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v113, v116, v98, 24);
            BOOL v80 = &v109;
            unsigned int v81 = (char *)v113;
          }
        }
        unsigned int v82 = &v81[24 * v114];
        long long v83 = *(_OWORD *)v80;
        *((void *)v82 + 2) = *((void *)v80 + 2);
        *(_OWORD *)unsigned int v82 = v83;
        ++v114;
        if (v112[0]) {
          mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v112);
        }
      }
    }
    if (!v121) {
      return 0;
    }
    uint64_t v84 = __p;
    if (__p)
    {
      uint64_t v85 = v120;
      uint64_t v86 = __p;
      if (v120 != __p)
      {
        do
          uint64_t v85 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v85 - 1);
        while (v85 != v84);
        uint64_t v86 = __p;
      }
      char v120 = v84;
      operator delete(v86);
    }
    uint64_t v23 = v117;
    if (!v117) {
      goto LABEL_120;
    }
    unint64_t v87 = v118;
    uint64_t v25 = v117;
    if (v118 == v117) {
      goto LABEL_119;
    }
    do
    {
      uint64_t v89 = *--v87;
      uint64_t v88 = v89;
      *unint64_t v87 = 0;
      if (v89) {
        MEMORY[0x21667D390](v88, 0x1000C8077774924);
      }
    }
    while (v87 != v23);
    goto LABEL_118;
  }
  a1[2] = v13;
  unint64_t v14 = (void *)mlir::DictionaryAttr::get((uint64_t)&v108, "operandSegmentSizes", 0x13uLL);
  if (v14 || (unint64_t v14 = (void *)mlir::DictionaryAttr::get((uint64_t)&v108, "operand_segment_sizes", 0x15uLL)) != 0)
  {
    if (mlir::convertFromAttribute(a1 + 3, (const char *)4, v14, a3, a4)) {
      return 1;
    }
  }
  else
  {
    a3(v112, a4);
    mlir::InFlightDiagnostic::operator<<<char const(&)[44]>((uint64_t)v112, "expected key entry for operandSegmentSizes in DictionaryAttr to set Properties.");
    mlir::InFlightDiagnostic::~InFlightDiagnostic((mlir::InFlightDiagnostic *)v112);
  }
  return 0;
}

uint64_t mlir::tensor::PackOp::getPropertiesAsAttr(mlir::DictionaryAttr *a1, uint64_t *a2)
{
  void v35[6] = *MEMORY[0x263EF8340];
  uint64_t v32 = a1;
  uint64_t v33 = v35;
  uint64_t v34 = 0x300000000;
  if (*a2)
  {
    uint64_t NamedAttr = mlir::Builder::getNamedAttr(&v32, (uint64_t)"inner_dims_pos", 14, *a2);
    uint64_t v6 = v5;
    unsigned int v7 = v34;
    if (v34 >= HIDWORD(v34))
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v33, v35, v34 + 1, 16);
      unsigned int v7 = v34;
    }
    long long v8 = (uint64_t *)((char *)v33 + 16 * v7);
    *long long v8 = NamedAttr;
    v8[1] = v6;
    LODWORD(v34) = v34 + 1;
  }
  uint64_t v9 = a2[1];
  if (v9)
  {
    uint64_t v10 = mlir::Builder::getNamedAttr(&v32, (uint64_t)"outer_dims_perm", 15, v9);
    uint64_t v12 = v11;
    unsigned int v13 = v34;
    if (v34 >= HIDWORD(v34))
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v33, v35, v34 + 1, 16);
      unsigned int v13 = v34;
    }
    unint64_t v14 = (uint64_t *)((char *)v33 + 16 * v13);
    *unint64_t v14 = v10;
    v14[1] = v12;
    LODWORD(v34) = v34 + 1;
  }
  uint64_t v15 = a2[2];
  if (v15)
  {
    uint64_t v16 = mlir::Builder::getNamedAttr(&v32, (uint64_t)"static_inner_tiles", 18, v15);
    uint64_t v18 = v17;
    unsigned int v19 = v34;
    if (v34 >= HIDWORD(v34))
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v33, v35, v34 + 1, 16);
      unsigned int v19 = v34;
    }
    uint64_t v20 = (uint64_t *)((char *)v33 + 16 * v19);
    uint64_t *v20 = v16;
    v20[1] = v18;
    LODWORD(v34) = v34 + 1;
  }
  uint64_t v21 = mlir::detail::DenseArrayAttrImpl<int>::get(a1, (uint64_t)(a2 + 3), 4);
  uint64_t v22 = mlir::Builder::getNamedAttr(&v32, (uint64_t)"operandSegmentSizes", 19, v21);
  uint64_t v24 = v23;
  unsigned int v25 = v34;
  if (v34 >= HIDWORD(v34))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v33, v35, v34 + 1, 16);
    unsigned int v25 = v34;
  }
  uint64_t v26 = (uint64_t *)((char *)v33 + 16 * v25);
  *uint64_t v26 = v22;
  v26[1] = v24;
  BOOL v27 = __CFADD__(v34, 1);
  uint64_t v28 = (v34 + 1);
  LODWORD(v34) = v34 + 1;
  if (v27)
  {
    uint64_t DictionaryAttr = 0;
    unint64_t v30 = v33;
    if (v33 == v35) {
      return DictionaryAttr;
    }
    goto LABEL_20;
  }
  uint64_t DictionaryAttr = mlir::Builder::getDictionaryAttr(&v32, (uint64_t *)v33, v28);
  unint64_t v30 = v33;
  if (v33 != v35) {
LABEL_20:
  }
    free(v30);
  return DictionaryAttr;
}

uint64_t mlir::tensor::PackOp::getInherentAttr(mlir::MLIRContext *a1, void *a2, void *__s1, size_t __n)
{
  uint64_t result = 0;
  switch(__n)
  {
    case 0xEuLL:
      if (*__s1 != 0x69645F72656E6E69 || *(void *)((char *)__s1 + 6) != 0x736F705F736D6964) {
        goto LABEL_13;
      }
      return *a2;
    case 0xFuLL:
      if (memcmp(__s1, "outer_dims_perm", __n)) {
        goto LABEL_13;
      }
      return a2[1];
    case 0x10uLL:
    case 0x11uLL:
    case 0x14uLL:
      goto LABEL_13;
    case 0x12uLL:
      if (memcmp(__s1, "static_inner_tiles", __n)) {
        goto LABEL_13;
      }
      uint64_t result = a2[2];
      break;
    case 0x13uLL:
      if (memcmp(__s1, "operandSegmentSizes", __n)) {
        goto LABEL_13;
      }
      goto LABEL_15;
    case 0x15uLL:
      if (!memcmp(__s1, "operand_segment_sizes", __n)) {
LABEL_15:
      }
        uint64_t result = mlir::detail::DenseArrayAttrImpl<int>::get(a1, (uint64_t)(a2 + 3), 4);
      else {
LABEL_13:
      }
        uint64_t result = 0;
      break;
    default:
      return result;
  }
  return result;
}

uint64_t mlir::tensor::PackOp::setInherentAttr(uint64_t result, void *__s1, size_t a3, void *a4)
{
  uint64_t v5 = (void *)result;
  switch(a3)
  {
    case 0xEuLL:
      if (*__s1 == 0x69645F72656E6E69 && *(void *)((char *)__s1 + 6) == 0x736F705F736D6964)
      {
        if (a4)
        {
          uint64_t result = mlir::detail::DenseArrayAttrImpl<long long>::classof(a4);
          if (result) {
            uint64_t v11 = a4;
          }
          else {
            uint64_t v11 = 0;
          }
          void *v5 = v11;
        }
        else
        {
          *(void *)uint64_t result = 0;
        }
      }
      break;
    case 0xFuLL:
      uint64_t result = memcmp(__s1, "outer_dims_perm", a3);
      if (!result)
      {
        if (a4)
        {
          uint64_t result = mlir::detail::DenseArrayAttrImpl<long long>::classof(a4);
          if (result) {
            unsigned int v7 = a4;
          }
          else {
            unsigned int v7 = 0;
          }
          v5[1] = v7;
        }
        else
        {
          v5[1] = 0;
        }
      }
      break;
    case 0x12uLL:
      uint64_t result = memcmp(__s1, "static_inner_tiles", a3);
      if (!result)
      {
        if (a4)
        {
          uint64_t result = mlir::detail::DenseArrayAttrImpl<long long>::classof(a4);
          if (result) {
            long long v8 = a4;
          }
          else {
            long long v8 = 0;
          }
          v5[2] = v8;
        }
        else
        {
          v5[2] = 0;
        }
      }
      break;
    case 0x13uLL:
      uint64_t result = memcmp(__s1, "operandSegmentSizes", a3);
      if (!result) {
        goto LABEL_22;
      }
      break;
    case 0x15uLL:
      uint64_t result = memcmp(__s1, "operand_segment_sizes", a3);
      if (!result)
      {
LABEL_22:
        if (a4)
        {
          uint64_t result = mlir::detail::DenseArrayAttrImpl<int>::classof(a4);
          uint64_t v9 = result ? a4 : 0;
          uint64_t v12 = v9;
          if (result)
          {
            uint64_t result = mlir::AffineBinaryOpExpr::getLHS((mlir::AffineBinaryOpExpr *)&v12);
            if (result == 4)
            {
              uint64_t result = mlir::detail::DenseArrayAttrImpl<int>::operator llvm::ArrayRef<int>((uint64_t)&v12);
              if (v10) {
                uint64_t result = (uint64_t)memmove(v5 + 3, (const void *)result, 4 * v10);
              }
            }
          }
        }
      }
      break;
    default:
      return result;
  }
  return result;
}

void mlir::tensor::PackOp::populateInherentAttrs(mlir::MLIRContext *a1, uint64_t *a2, uint64_t a3)
{
  if (*a2) {
    mlir::NamedAttrList::append(a3, (uint64_t)"inner_dims_pos", 14, *a2);
  }
  uint64_t v6 = a2[1];
  if (v6) {
    mlir::NamedAttrList::append(a3, (uint64_t)"outer_dims_perm", 15, v6);
  }
  uint64_t v7 = a2[2];
  if (v7) {
    mlir::NamedAttrList::append(a3, (uint64_t)"static_inner_tiles", 18, v7);
  }
  uint64_t v8 = mlir::detail::DenseArrayAttrImpl<int>::get(a1, (uint64_t)(a2 + 3), 4);

  mlir::NamedAttrList::append(a3, (uint64_t)"operandSegmentSizes", 19, v8);
}

BOOL mlir::tensor::PackOp::verifyInherentAttrs(uint64_t a1, uint64_t a2, void (*a3)(uint64_t *__return_ptr, uint64_t), uint64_t a4)
{
  uint64_t v8 = (void *)mlir::NamedAttrList::get(a2, **(void **)(a1 + 96));
  BOOL result = 0;
  if (!v8
    || mlir::memref::__mlir_ods_local_attr_constraint_MemRefOps12(v8, (void **)"inner_dims_pos", (const char *)0xE, a3, a4))
  {
    uint64_t v9 = (void *)mlir::NamedAttrList::get(a2, *(void *)(*(void *)(a1 + 96) + 8));
    if (!v9
      || mlir::memref::__mlir_ods_local_attr_constraint_MemRefOps12(v9, (void **)"outer_dims_perm", (const char *)0xF, a3, a4))
    {
      uint64_t v10 = (void *)mlir::NamedAttrList::get(a2, *(void *)(*(void *)(a1 + 96) + 16));
      if (!v10
        || mlir::memref::__mlir_ods_local_attr_constraint_MemRefOps12(v10, (void **)"static_inner_tiles", (const char *)0x12, a3, a4))
      {
        return 1;
      }
    }
  }
  return result;
}

BOOL mlir::tensor::PackOp::readProperties(uint64_t a1, uint64_t a2)
{
  uint64_t v26 = *MEMORY[0x263EF8340];
  uint64_t v3 = (void *)mlir::OperationState::getOrAddProperties<mlir::tensor::detail::PackOpGenericAdaptorBase::Properties>(a2);
  if (!mlir::DialectBytecodeReader::readAttribute<mlir::detail::DenseArrayAttrImpl<long long>>(a1, v3)) {
    return 0;
  }
  if ((unint64_t)(*(uint64_t (**)(uint64_t))(*(void *)a1 + 40))(a1) <= 5)
  {
    uint64_t v17 = 0;
    if (!mlir::DialectBytecodeReader::readAttribute<mlir::detail::DenseArrayAttrImpl<int>>(a1, &v17)) {
      return 0;
    }
    if (mlir::AffineBinaryOpExpr::getLHS((mlir::AffineBinaryOpExpr *)&v17) >= 5)
    {
      uint64_t v15 = "size mismatch for operand/result_segment_size";
      __int16 v16 = 259;
      (*(void (**)(void *__return_ptr, uint64_t, const char **))(*(void *)a1 + 16))(v18, a1, &v15);
      if (v18[0]) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v18);
      }
      if (v25)
      {
        unint64_t v4 = __p;
        if (__p)
        {
          uint64_t v5 = v24;
          uint64_t v6 = __p;
          if (v24 != __p)
          {
            do
              uint64_t v5 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v5 - 1);
            while (v5 != v4);
            uint64_t v6 = __p;
          }
          uint64_t v24 = v4;
          operator delete(v6);
        }
        uint64_t v7 = v21;
        if (v21)
        {
          uint64_t v8 = v22;
          uint64_t v9 = v21;
          if (v22 != v21)
          {
            do
            {
              uint64_t v11 = *--v8;
              uint64_t v10 = v11;
              *uint64_t v8 = 0;
              if (v11) {
                MEMORY[0x21667D390](v10, 0x1000C8077774924);
              }
            }
            while (v8 != v7);
            uint64_t v9 = v21;
          }
          uint64_t v22 = v7;
          operator delete(v9);
        }
        if (v19 != &v20) {
          free(v19);
        }
      }
      return 0;
    }
    uint64_t v12 = (const void *)mlir::detail::DenseArrayAttrImpl<int>::operator llvm::ArrayRef<int>((uint64_t)&v17);
    if (v13) {
      memmove(v3 + 3, v12, 4 * v13);
    }
  }
  return mlir::DialectBytecodeReader::readOptionalAttribute<mlir::detail::DenseArrayAttrImpl<long long>>(a1, v3 + 1)&& mlir::DialectBytecodeReader::readAttribute<mlir::detail::DenseArrayAttrImpl<long long>>(a1, v3 + 2)&& ((unint64_t)(*(uint64_t (**)(uint64_t))(*(void *)a1 + 40))(a1) < 6|| mlir::DialectBytecodeReader::readSparseArray<int>(a1, (_DWORD *)v3 + 6, (const char *)4));
}

uint64_t mlir::OperationState::getOrAddProperties<mlir::tensor::detail::PackOpGenericAdaptorBase::Properties>(uint64_t a1)
{
  uint64_t result = *(void *)(a1 + 256);
  if (!result) {
    operator new();
  }
  return result;
}

uint64_t mlir::DialectBytecodeReader::readOptionalAttribute<mlir::detail::DenseArrayAttrImpl<long long>>(uint64_t a1, void *a2)
{
  uint64_t v56 = *MEMORY[0x263EF8340];
  uint64_t v40 = 0;
  if (!(*(unsigned __int8 (**)(uint64_t, void **))(*(void *)a1 + 56))(a1, &v40)) {
    return 0;
  }
  unint64_t v4 = v40;
  if (!v40) {
    return 1;
  }
  BOOL v5 = mlir::detail::DenseArrayAttrImpl<long long>::classof(v40);
  uint64_t v6 = v5 ? v4 : 0;
  *a2 = v6;
  if (v5) {
    return 1;
  }
  v39[16] = 257;
  (*(void (**)(uint64_t *__return_ptr, uint64_t, _WORD *))(*(void *)a1 + 16))(&v45, a1, v39);
  if (v45)
  {
    LODWORD(v41) = 3;
    unint64_t v42 = (unint64_t)"expected ";
    uint64_t v43 = 9;
    uint64_t v9 = &v41;
    uint64_t v10 = (char *)v47;
    if (v48 >= v49)
    {
      unint64_t v33 = v48 + 1;
      if (v47 <= &v41 && (char *)v47 + 24 * v48 > (char *)&v41)
      {
        int64_t v36 = (char *)&v41 - (unsigned char *)v47;
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v47, v50, v33, 24);
        uint64_t v10 = (char *)v47;
        uint64_t v9 = (void ***)((char *)v47 + v36);
      }
      else
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v47, v50, v33, 24);
        uint64_t v9 = &v41;
        uint64_t v10 = (char *)v47;
      }
    }
    uint64_t v11 = &v10[24 * v48];
    long long v12 = *(_OWORD *)v9;
    *((void *)v11 + 2) = v9[2];
    *(_OWORD *)uint64_t v11 = v12;
    ++v48;
  }
  long long v41 = (void **)"StringRef llvm::getTypeName() [DesiredTypeName = mlir::detail::DenseArrayAttrImpl<int64_t>]";
  unint64_t v42 = 91;
  unint64_t v13 = llvm::StringRef::find((uint64_t *)&v41, "DesiredTypeName = ", 0x12uLL, 0);
  if (v45)
  {
    if (v42 >= v13) {
      unint64_t v14 = v13;
    }
    else {
      unint64_t v14 = v42;
    }
    uint64_t v15 = 18;
    if (v42 - v14 < 0x12) {
      uint64_t v15 = v42 - v14;
    }
    unint64_t v16 = v42 - v14 - v15;
    if (v16 >= v16 - 1) {
      --v16;
    }
    __int16 v44 = 261;
    long long v41 = (void **)((char *)v41 + v14 + v15);
    unint64_t v42 = v16;
    mlir::Diagnostic::operator<<((uint64_t)&v46, &v41);
    if (v45)
    {
      LODWORD(v41) = 3;
      unint64_t v42 = (unint64_t)", but got: ";
      uint64_t v43 = 11;
      uint64_t v17 = &v41;
      uint64_t v18 = (char *)v47;
      if (v48 >= v49)
      {
        unint64_t v34 = v48 + 1;
        if (v47 <= &v41 && (char *)v47 + 24 * v48 > (char *)&v41)
        {
          int64_t v37 = (char *)&v41 - (unsigned char *)v47;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v47, v50, v34, 24);
          uint64_t v18 = (char *)v47;
          uint64_t v17 = (void ***)((char *)v47 + v37);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v47, v50, v34, 24);
          uint64_t v17 = &v41;
          uint64_t v18 = (char *)v47;
        }
      }
      unsigned int v19 = &v18[24 * v48];
      long long v20 = *(_OWORD *)v17;
      *((void *)v19 + 2) = v17[2];
      *(_OWORD *)unsigned int v19 = v20;
      ++v48;
      if (v45)
      {
        uint64_t v21 = &v41;
        mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v41, (uint64_t)v40);
        uint64_t v22 = (char *)v47;
        if (v48 >= v49)
        {
          unint64_t v35 = v48 + 1;
          if (v47 <= &v41 && (char *)v47 + 24 * v48 > (char *)&v41)
          {
            int64_t v38 = (char *)&v41 - (unsigned char *)v47;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v47, v50, v35, 24);
            uint64_t v22 = (char *)v47;
            uint64_t v21 = (void ***)((char *)v47 + v38);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v47, v50, v35, 24);
            uint64_t v21 = &v41;
            uint64_t v22 = (char *)v47;
          }
        }
        uint64_t v23 = &v22[24 * v48];
        long long v24 = *(_OWORD *)v21;
        *((void *)v23 + 2) = v21[2];
        *(_OWORD *)uint64_t v23 = v24;
        ++v48;
      }
    }
  }
  uint64_t v7 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v45);
  if (v45) {
    mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v45);
  }
  if (v55)
  {
    char v25 = __p;
    if (__p)
    {
      uint64_t v26 = v54;
      BOOL v27 = __p;
      if (v54 != __p)
      {
        do
          uint64_t v26 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v26 - 1);
        while (v26 != v25);
        BOOL v27 = __p;
      }
      unsigned int v54 = v25;
      operator delete(v27);
    }
    uint64_t v28 = v51;
    if (v51)
    {
      uint64_t v29 = v52;
      unint64_t v30 = v51;
      if (v52 != v51)
      {
        do
        {
          uint64_t v32 = *--v29;
          uint64_t v31 = v32;
          void *v29 = 0;
          if (v32) {
            MEMORY[0x21667D390](v31, 0x1000C8077774924);
          }
        }
        while (v29 != v28);
        unint64_t v30 = v51;
      }
      uint64_t v52 = v28;
      operator delete(v30);
    }
    if (v47 != v50) {
      free(v47);
    }
  }
  return v7;
}

uint64_t mlir::tensor::PackOp::writeProperties(uint64_t a1, uint64_t a2)
{
  if (HIBYTE(*(_DWORD *)(*(void *)a1 + 44))) {
    unint64_t v4 = *(void *)a1 + 16 * (((unint64_t)*(unsigned int *)(*(void *)a1 + 44) >> 23) & 1) + 64;
  }
  else {
    unint64_t v4 = 0;
  }
  (*(void (**)(uint64_t, void))(*(void *)a2 + 16))(a2, *(void *)v4);
  if ((*(uint64_t (**)(uint64_t))(*(void *)a2 + 104))(a2) <= 5)
  {
    uint64_t Context = (mlir::MLIRContext *)mlir::Attribute::getContext((mlir::Attribute *)(*(void *)a1 + 24));
    uint64_t v6 = mlir::detail::DenseArrayAttrImpl<int>::get(Context, v4 + 24, 4);
    (*(void (**)(uint64_t, uint64_t))(*(void *)a2 + 16))(a2, v6);
  }
  (*(void (**)(uint64_t, void))(*(void *)a2 + 24))(a2, *(void *)(v4 + 8));
  (*(void (**)(uint64_t, void))(*(void *)a2 + 16))(a2, *(void *)(v4 + 16));
  uint64_t result = (*(uint64_t (**)(uint64_t))(*(void *)a2 + 104))(a2);
  if (result >= 6)
  {
    return mlir::DialectBytecodeWriter::writeSparseArray<int>(a2, (int *)(v4 + 24), 4);
  }
  return result;
}

uint64_t mlir::tensor::PackOp::verifyInvariantsImpl(mlir::tensor::PackOp *this)
{
  uint64_t v65 = *MEMORY[0x263EF8340];
  uint64_t v2 = *(void *)this;
  if (HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
    unint64_t v3 = *(void *)this + 16 * (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 23) & 1) + 64;
  }
  else {
    unint64_t v3 = 0;
  }
  unint64_t v4 = *(void **)v3;
  if (!*(void *)v3)
  {
    v55[0] = (void **)"requires attribute 'inner_dims_pos'";
    __int16 v56 = 259;
    mlir::OpState::emitOpError((uint64_t *)this, v55, (uint64_t)v57);
    uint64_t v27 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v57);
    if (v57[0]) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v57);
    }
    if (!v64) {
      return v27;
    }
    uint64_t v28 = __p;
    if (__p)
    {
      uint64_t v29 = v63;
      unint64_t v30 = __p;
      if (v63 != __p)
      {
        do
          uint64_t v29 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v29 - 1);
        while (v29 != v28);
        unint64_t v30 = __p;
      }
      char v63 = v28;
      operator delete(v30);
    }
    uint64_t v31 = v60;
    if (v60)
    {
      uint64_t v32 = v61;
      unint64_t v33 = v60;
      if (v61 == v60) {
        goto LABEL_51;
      }
      do
      {
        uint64_t v35 = *--v32;
        uint64_t v34 = v35;
        *uint64_t v32 = 0;
        if (v35) {
          MEMORY[0x21667D390](v34, 0x1000C8077774924);
        }
      }
      while (v32 != v31);
LABEL_50:
      unint64_t v33 = v60;
LABEL_51:
      uint64_t v61 = v31;
      operator delete(v33);
    }
LABEL_52:
    if (v58 != &v59) {
      free(v58);
    }
    return v27;
  }
  BOOL v5 = *(void **)(v3 + 16);
  if (!v5)
  {
    v55[0] = (void **)"requires attribute 'static_inner_tiles'";
    __int16 v56 = 259;
    mlir::OpState::emitOpError((uint64_t *)this, v55, (uint64_t)v57);
    uint64_t v27 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v57);
    if (v57[0]) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v57);
    }
    if (!v64) {
      return v27;
    }
    int64_t v36 = __p;
    if (__p)
    {
      int64_t v37 = v63;
      int64_t v38 = __p;
      if (v63 != __p)
      {
        do
          int64_t v37 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v37 - 1);
        while (v37 != v36);
        int64_t v38 = __p;
      }
      char v63 = v36;
      operator delete(v38);
    }
    uint64_t v31 = v60;
    if (v60)
    {
      uint64_t v39 = v61;
      unint64_t v33 = v60;
      if (v61 == v60) {
        goto LABEL_51;
      }
      do
      {
        uint64_t v41 = *--v39;
        uint64_t v40 = v41;
        *uint64_t v39 = 0;
        if (v41) {
          MEMORY[0x21667D390](v40, 0x1000C8077774924);
        }
      }
      while (v39 != v31);
      goto LABEL_50;
    }
    goto LABEL_52;
  }
  uint64_t v6 = *(void **)(v3 + 8);
  v57[0] = v2;
  if (!mlir::memref::__mlir_ods_local_attr_constraint_MemRefOps12(v6, (void **)"outer_dims_perm", (const char *)0xF, (void (*)(uint64_t *__return_ptr, uint64_t))llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::__mlir_ods_local_attr_constraint_TensorOps1(mlir::Operation *,mlir::Attribute,llvm::StringRef)::$_0>, (uint64_t)v57))return 0; {
  v57[0] = *(void *)this;
  }
  if (!mlir::memref::__mlir_ods_local_attr_constraint_MemRefOps12(v4, (void **)"inner_dims_pos", (const char *)0xE, (void (*)(uint64_t *__return_ptr, uint64_t))llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::__mlir_ods_local_attr_constraint_TensorOps1(mlir::Operation *,mlir::Attribute,llvm::StringRef)::$_0>, (uint64_t)v57))return 0; {
  v57[0] = *(void *)this;
  }
  if (!mlir::memref::__mlir_ods_local_attr_constraint_MemRefOps12(v5, (void **)"static_inner_tiles", (const char *)0x12, (void (*)(uint64_t *__return_ptr, uint64_t))llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::__mlir_ods_local_attr_constraint_TensorOps1(mlir::Operation *,mlir::Attribute,llvm::StringRef)::$_0>, (uint64_t)v57))return 0; {
  unsigned int v54 = 0;
  }
  unint64_t v7 = *(unsigned int *)(*(void *)this + 44);
  uint64_t v8 = *(void *)this + 16 * ((v7 >> 23) & 1) + 64;
  if (!HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
    uint64_t v8 = 0;
  }
  uint64_t v9 = *(unsigned int *)(v8 + 24);
  if ((v7 & 0x800000) != 0)
  {
    uint64_t v10 = *(void *)(*(void *)this + 72);
    if (v9) {
      goto LABEL_13;
    }
  }
  else
  {
    uint64_t v10 = 0;
    if (v9)
    {
LABEL_13:
      uint64_t v11 = 0;
      uint64_t v12 = v10 + 24;
      while (1)
      {
        uint64_t v13 = *(void *)this;
        unint64_t v14 = *(void *)(*(void *)v12 + 8) & 0xFFFFFFFFFFFFFFF8;
        unsigned int v54 = v11 + 1;
        if (!mlir::tensor::__mlir_ods_local_type_constraint_TensorOps1(v13, v14, (void **)"operand", (void **)7, v11))return 0; {
        ++v11;
        }
        v12 += 32;
        if (v9 == v11)
        {
          uint64_t ODSOperands = mlir::memref::ReinterpretCastOp::getODSOperands(this, 1u);
          if (!v16) {
            goto LABEL_56;
          }
          goto LABEL_17;
        }
      }
    }
  }
  LODWORD(v11) = 0;
  uint64_t ODSOperands = mlir::memref::ReinterpretCastOp::getODSOperands(this, 1u);
  if (v16)
  {
LABEL_17:
    uint64_t v17 = v16;
    uint64_t v18 = ODSOperands + 24;
    while (1)
    {
      uint64_t v19 = *(void *)this;
      unint64_t v20 = *(void *)(*(void *)v18 + 8) & 0xFFFFFFFFFFFFFFF8;
      int v21 = v11 + 1;
      unsigned int v54 = v11 + 1;
      if (!mlir::tensor::__mlir_ods_local_type_constraint_TensorOps1(v19, v20, (void **)"operand", (void **)7, v11))return 0; {
      v18 += 32;
      }
      LODWORD(v11) = v11 + 1;
      if (!--v17)
      {
        mlir::memref::ReinterpretCastOp::getODSOperands(this, 2u);
        uint64_t v23 = v22;
        if (v22 < 2) {
          goto LABEL_57;
        }
        goto LABEL_21;
      }
    }
  }
LABEL_56:
  int v21 = v11;
  mlir::memref::ReinterpretCastOp::getODSOperands(this, 2u);
  uint64_t v23 = v42;
  if (v42 >= 2)
  {
LABEL_21:
    v55[0] = (void **)"operand group starting at #";
    __int16 v56 = 259;
    mlir::OpState::emitOpError((uint64_t *)this, v55, (uint64_t)v57);
    uint64_t v24 = mlir::InFlightDiagnostic::operator<<<unsigned int const&>((uint64_t)v57, &v54);
    uint64_t v25 = mlir::InFlightDiagnostic::operator<<<char const(&)[44]>(v24, " requires 0 or 1 element, but found ");
    uint64_t v53 = v23;
    uint64_t v26 = (void *)mlir::InFlightDiagnostic::operator<<<unsigned long &>(v25, &v53);
LABEL_70:
    uint64_t v27 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v26);
    mlir::InFlightDiagnostic::~InFlightDiagnostic((mlir::InFlightDiagnostic *)v57);
    return v27;
  }
LABEL_57:
  uint64_t v43 = mlir::memref::ReinterpretCastOp::getODSOperands(this, 3u);
  if (v44)
  {
    uint64_t v45 = v44;
    unsigned int v46 = v21 + v23;
    uint64_t v47 = v43 + 24;
    while (mlir::memref::__mlir_ods_local_type_constraint_MemRefOps3(*(void *)this, *(void *)(*(void *)v47 + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"operand", (void **)7, v46))
    {
      ++v46;
      v47 += 32;
      if (!--v45) {
        goto LABEL_61;
      }
    }
    return 0;
  }
LABEL_61:
  uint64_t v48 = *(_DWORD *)(*(void *)this + 36) ? *(void *)this - 16 : 0;
  uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v48, 0);
  if (!mlir::tensor::__mlir_ods_local_type_constraint_TensorOps1(*(void *)this, *(void *)(NextResultAtOffset + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"result", (void **)6, 0))return 0; {
  uint64_t v27 = 1;
  }
  unint64_t v50 = *(void *)(*(void *)(mlir::memref::ReinterpretCastOp::getODSOperands(this, 1u) + 24) + 8) & 0xFFFFFFFFFFFFFFF8;
  if (*(_DWORD *)(*(void *)this + 36)) {
    uint64_t v51 = *(void *)this - 16;
  }
  else {
    uint64_t v51 = 0;
  }
  if (v50 != (*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v51, 0) + 8) & 0xFFFFFFFFFFFFFFF8))
  {
    v55[0] = (void **)"failed to verify that result type matches type of dest";
    __int16 v56 = 259;
    mlir::OpState::emitOpError((uint64_t *)this, v55, (uint64_t)v57);
    uint64_t v26 = v57;
    goto LABEL_70;
  }
  return v27;
}

void mlir::tensor::PackOp::getCanonicalizationPatterns()
{
  mlir::PatternBenefit::PatternBenefit(&v0, 1);
  operator new();
}

uint64_t mlir::tensor::PackOp::parse(uint64_t a1, uint64_t a2)
{
  v62[4] = *MEMORY[0x263EF8340];
  memset(v62, 0, 24);
  v46[0] = (uint64_t)v62;
  v46[1] = 1;
  uint64_t v59 = v61;
  uint64_t v60 = 0x400000000;
  v57[0] = &v58;
  v57[1] = (void *)0x100000000;
  uint64_t v44 = 0;
  uint64_t v45 = 0;
  unsigned int v54 = v56;
  uint64_t v55 = 0x400000000;
  v42[1] = 1;
  uint64_t v43 = 0;
  memset(v53, 0, 24);
  v41[1] = 1;
  v42[0] = (uint64_t)v53;
  uint64_t __src = 0;
  uint64_t v52 = 0;
  v40[1] = 1;
  v41[0] = &v52;
  v40[0] = &__src;
  uint64_t v4 = (*(uint64_t (**)(uint64_t))(*(void *)a1 + 40))(a1);
  if (!(*(unsigned __int8 (**)(uint64_t, void *, uint64_t))(*(void *)a1 + 672))(a1, v62, 1)) {
    goto LABEL_47;
  }
  if ((*(unsigned __int8 (**)(uint64_t, const char *, uint64_t))(*(void *)a1 + 376))(a1, "padding_value", 13))
  {
    if (!(*(unsigned __int8 (**)(uint64_t))(*(void *)a1 + 264))(a1)) {
      goto LABEL_47;
    }
    uint64_t v5 = (*(uint64_t (**)(uint64_t))(*(void *)a1 + 40))(a1);
    uint64_t v47 = 0;
    uint64_t v48 = 0;
    uint64_t v49 = 0;
    unsigned __int16 v6 = (*(uint64_t (**)(uint64_t, uint64_t *, uint64_t))(*(void *)a1 + 680))(a1, &v47, 1);
    if (v6 >= 0x100u)
    {
      if (!(_BYTE)v6) {
        goto LABEL_47;
      }
      unint64_t v7 = &v47;
      uint64_t v8 = (char *)v59;
      if (v60 >= HIDWORD(v60))
      {
        unint64_t v34 = v60 + 1;
        if (v59 <= &v47 && (char *)v59 + 32 * v60 > (char *)&v47)
        {
          int64_t v35 = (char *)&v47 - (unsigned char *)v59;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v59, v61, v34, 32);
          uint64_t v8 = (char *)v59;
          unint64_t v7 = (uint64_t *)((char *)v59 + v35);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v59, v61, v34, 32);
          unint64_t v7 = &v47;
          uint64_t v8 = (char *)v59;
        }
      }
      uint64_t v9 = &v8[32 * v60];
      long long v10 = *((_OWORD *)v7 + 1);
      *(_OWORD *)uint64_t v9 = *(_OWORD *)v7;
      *((_OWORD *)v9 + 1) = v10;
      LODWORD(v60) = v60 + 1;
    }
    if (!(*(unsigned __int8 (**)(uint64_t))(*(void *)a1 + 104))(a1)) {
      goto LABEL_47;
    }
    uint64_t v47 = 0;
    unsigned __int16 v11 = (*(uint64_t (**)(uint64_t, uint64_t *))(*(void *)a1 + 520))(a1, &v47);
    if (v11 >= 0x100u)
    {
      if (!(_BYTE)v11) {
        goto LABEL_47;
      }
      llvm::SmallVectorTemplateBase<mlir::Type,true>::push_back((uint64_t)v57, v47);
    }
    if (!(*(unsigned __int8 (**)(uint64_t))(*(void *)a1 + 280))(a1)) {
      goto LABEL_47;
    }
  }
  else
  {
    uint64_t v5 = 0;
  }
  if ((*(unsigned __int8 (**)(uint64_t, const char *, uint64_t))(*(void *)a1 + 376))(a1, "outer_dims_perm", 15))
  {
    if (!(*(unsigned __int8 (**)(uint64_t))(*(void *)a1 + 136))(a1)
      || !mlir::AsmParser::parseCustomAttributeWithFallback<mlir::detail::DenseArrayAttrImpl<long long>>(a1, &v45, 0))
    {
      goto LABEL_47;
    }
    if (v45)
    {
      uint64_t v12 = mlir::OperationState::getOrAddProperties<mlir::tensor::detail::PackOpGenericAdaptorBase::Properties>(a2);
      *(void *)(v12 + 8) = v45;
    }
  }
  __int16 v50 = 257;
  if (!(*(unsigned __int8 (**)(uint64_t, const char *, uint64_t, uint64_t *))(*(void *)a1 + 368))(a1, "inner_dims_pos", 14, &v47)|| !(*(unsigned __int8 (**)(uint64_t))(*(void *)a1 + 136))(a1)|| !mlir::AsmParser::parseCustomAttributeWithFallback<mlir::detail::DenseArrayAttrImpl<long long>>(a1, &v44, 0))
  {
    goto LABEL_47;
  }
  if (v44)
  {
    uint64_t v13 = (void *)mlir::OperationState::getOrAddProperties<mlir::tensor::detail::PackOpGenericAdaptorBase::Properties>(a2);
    *uint64_t v13 = v44;
  }
  __int16 v50 = 257;
  if (!(*(unsigned __int8 (**)(uint64_t, const char *, uint64_t, uint64_t *))(*(void *)a1 + 368))(a1, "inner_tiles", 11, &v47))goto LABEL_47; {
  if (!(*(unsigned __int8 (**)(uint64_t))(*(void *)a1 + 136))(a1))
  }
    goto LABEL_47;
  (*(void (**)(uint64_t))(*(void *)a1 + 40))(a1);
  uint64_t v47 = 0;
  if (!mlir::parseDynamicIndexList(a1, (uint64_t)&v54, &v43, &v47, 0)) {
    goto LABEL_47;
  }
  uint64_t v14 = mlir::OperationState::getOrAddProperties<mlir::tensor::detail::PackOpGenericAdaptorBase::Properties>(a2);
  *(void *)(v14 + 16) = v43;
  __int16 v50 = 257;
  if (!(*(unsigned __int8 (**)(uint64_t, const char *, uint64_t, uint64_t *))(*(void *)a1 + 368))(a1, "into", 4, &v47))goto LABEL_47; {
  uint64_t v15 = (*(uint64_t (**)(uint64_t))(*(void *)a1 + 40))(a1);
  }
  if (!(*(unsigned __int8 (**)(uint64_t, void **, uint64_t))(*(void *)a1 + 672))(a1, v53, 1)) {
    goto LABEL_47;
  }
  v37[0] = (*(uint64_t (**)(uint64_t))(*(void *)a1 + 40))(a1);
  if (!(*(unsigned __int8 (**)(uint64_t, uint64_t))(*(void *)a1 + 456))(a1, a2 + 112)) {
    goto LABEL_47;
  }
  uint64_t v16 = *(void *)(a2 + 8);
  uint64_t v47 = a1;
  uint64_t v48 = v37;
  uint64_t v49 = a2;
  if (!mlir::tensor::PackOp::verifyInherentAttrs(v16, a2 + 112, (void (*)(uint64_t *__return_ptr, uint64_t))llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::PackOp::parse(mlir::OpAsmParser &,mlir::OperationState &)::$_0>, (uint64_t)&v47))goto LABEL_47; {
  if (!(*(unsigned __int8 (**)(uint64_t))(*(void *)a1 + 104))(a1))
  }
    goto LABEL_47;
  uint64_t v47 = 0;
  if (!mlir::AsmParser::parseType<mlir::RankedTensorType>(a1, &v47)) {
    goto LABEL_47;
  }
  uint64_t v52 = v47;
  if (!(*(unsigned __int8 (**)(uint64_t))(*(void *)a1 + 56))(a1)) {
    goto LABEL_47;
  }
  uint64_t v47 = 0;
  if (!mlir::AsmParser::parseType<mlir::RankedTensorType>(a1, &v47)) {
    goto LABEL_47;
  }
  uint64_t __src = v47;
  int v17 = v60;
  int v18 = v55;
  uint64_t v19 = mlir::OperationState::getOrAddProperties<mlir::tensor::detail::PackOpGenericAdaptorBase::Properties>(a2);
  *(void *)(v19 + 24) = 0x100000001;
  *(_DWORD *)(v19 + 32) = v17;
  *(_DWORD *)(v19 + 36) = v18;
  uint64_t v20 = __src;
  uint64_t v39 = __src;
  if (*(_UNKNOWN **)(*(void *)__src + 136) != &mlir::detail::TypeIDResolver<mlir::RankedTensorType,void>::id)
  {
    uint64_t v21 = (*(uint64_t (**)(uint64_t))(*(void *)a1 + 16))(a1);
    __int16 v38 = 257;
    (*(void (**)(uint64_t *__return_ptr, uint64_t, uint64_t, void *))(*(void *)a1 + 24))(&v47, a1, v21, v37);
    uint64_t v22 = mlir::InFlightDiagnostic::operator<<<char const(&)[44]>((uint64_t)&v47, "'dest' must be ranked tensor of any type values, but got ");
    uint64_t v23 = mlir::InFlightDiagnostic::append<mlir::Type &>(v22, &v39);
    uint64_t v24 = mlir::InFlightDiagnostic::operator mlir::LogicalResult(v23);
    mlir::InFlightDiagnostic::~InFlightDiagnostic((mlir::InFlightDiagnostic *)&v47);
    uint64_t v25 = v54;
    if (v54 == v56) {
      goto LABEL_50;
    }
    goto LABEL_49;
  }
  uint64_t v26 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*(void *)__src + 8);
  uint64_t v47 = v20;
  uint64_t v48 = (void *)v26;
  mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&v47);
  uint64_t v27 = (mlir::IndexType **)(*(uint64_t (**)(uint64_t))(*(void *)a1 + 32))(a1);
  uint64_t IndexType = mlir::Builder::getIndexType(v27, v28);
  mlir::OperationState::addTypes(a2, &__src, 1);
  if (!mlir::OpAsmParser::resolveOperands<llvm::ArrayRef<mlir::OpAsmParser::UnresolvedOperand> &,llvm::ArrayRef<mlir::Type> &>(a1, v46, v41, v4, a2 + 16))goto LABEL_47; {
  uint64_t v29 = v15;
  }
  uint64_t v30 = a2 + 16;
  if (!mlir::OpAsmParser::resolveOperands<llvm::ArrayRef<mlir::OpAsmParser::UnresolvedOperand> &,llvm::ArrayRef<mlir::Type> &>(a1, v42, v40, v29, a2 + 16)|| !mlir::OpAsmParser::resolveOperands<llvm::SmallVector<mlir::OpAsmParser::UnresolvedOperand,4u> &,llvm::SmallVector<mlir::Type,1u> &>(a1, (uint64_t *)&v59, (uint64_t)v57, v5, a2 + 16))
  {
    goto LABEL_47;
  }
  if (!v55)
  {
    uint64_t v24 = 1;
    uint64_t v25 = v54;
    if (v54 == v56) {
      goto LABEL_50;
    }
LABEL_49:
    free(v25);
    goto LABEL_50;
  }
  uint64_t v31 = (char *)v54;
  uint64_t v32 = 32 * v55;
  uint64_t v24 = 1;
  while ((*(unsigned __int8 (**)(uint64_t, char *, uint64_t, uint64_t))(*(void *)a1 + 696))(a1, v31, IndexType, v30))
  {
    v31 += 32;
    v32 -= 32;
    if (!v32) {
      goto LABEL_48;
    }
  }
LABEL_47:
  uint64_t v24 = 0;
LABEL_48:
  uint64_t v25 = v54;
  if (v54 != v56) {
    goto LABEL_49;
  }
LABEL_50:
  if (v57[0] != &v58) {
    free(v57[0]);
  }
  if (v59 != v61) {
    free(v59);
  }
  return v24;
}

void mlir::tensor::PackOp::print(mlir::tensor::PackOp *this, mlir::OpAsmPrinter *a2)
{
  v115[2] = *MEMORY[0x263EF8340];
  uint64_t v4 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v5 = (unsigned char *)*((void *)v4 + 4);
  if ((unint64_t)v5 >= *((void *)v4 + 3))
  {
    llvm::raw_ostream::write(v4, 32);
  }
  else
  {
    *((void *)v4 + 4) = v5 + 1;
    unsigned char *v5 = 32;
  }
  (*(void (**)(mlir::OpAsmPrinter *, void))(*(void *)a2 + 160))(a2, *(void *)(*(void *)(*(void *)this + 72) + 24));
  unint64_t v6 = *(unsigned int *)(*(void *)this + 44);
  unint64_t v7 = (_DWORD *)(*(void *)this + 16 * ((v6 >> 23) & 1) + 64);
  if (!HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
    unint64_t v7 = 0;
  }
  int v8 = v7[8];
  if ((v6 & 0x800000) != 0)
  {
    uint64_t v9 = *(void *)(*(void *)this + 72);
    if (!v8) {
      goto LABEL_42;
    }
  }
  else
  {
    uint64_t v9 = 0;
    if (!v8) {
      goto LABEL_42;
    }
  }
  if (!*(void *)(v9 + 32 * (v7[7] + v7[6]) + 24)) {
    goto LABEL_42;
  }
  long long v10 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  unsigned __int16 v11 = (unsigned char *)*((void *)v10 + 4);
  if ((unint64_t)v11 >= *((void *)v10 + 3))
  {
    llvm::raw_ostream::write(v10, 32);
  }
  else
  {
    *((void *)v10 + 4) = v11 + 1;
    *unsigned __int16 v11 = 32;
  }
  uint64_t v12 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v13 = (void *)*((void *)v12 + 4);
  if (*((void *)v12 + 3) - (void)v13 > 0xCuLL)
  {
    qmemcpy(v13, "padding_value", 13);
    *((void *)v12 + 4) += 13;
  }
  else
  {
    llvm::raw_ostream::write(v12, "padding_value", 0xDuLL);
  }
  uint64_t v14 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v15 = (unsigned char *)*((void *)v14 + 4);
  if (*((unsigned char **)v14 + 3) == v15)
  {
    llvm::raw_ostream::write(v14, "(", 1uLL);
  }
  else
  {
    *uint64_t v15 = 40;
    ++*((void *)v14 + 4);
  }
  unint64_t v16 = *(unsigned int *)(*(void *)this + 44);
  int v17 = (_DWORD *)(*(void *)this + 16 * ((v16 >> 23) & 1) + 64);
  if (!HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
    int v17 = 0;
  }
  int v18 = v17[8];
  if ((v16 & 0x800000) != 0)
  {
    uint64_t v19 = *(void *)(*(void *)this + 72);
    if (!v18) {
      goto LABEL_24;
    }
  }
  else
  {
    uint64_t v19 = 0;
    if (!v18) {
      goto LABEL_24;
    }
  }
  if (*(void *)(v19 + 32 * (v17[7] + v17[6]) + 24)) {
    (*(void (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 160))(a2);
  }
LABEL_24:
  uint64_t v20 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v21 = (unsigned char *)*((void *)v20 + 4);
  if ((unint64_t)v21 >= *((void *)v20 + 3))
  {
    llvm::raw_ostream::write(v20, 32);
  }
  else
  {
    *((void *)v20 + 4) = v21 + 1;
    *uint64_t v21 = 32;
  }
  uint64_t v22 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v23 = (unsigned char *)*((void *)v22 + 4);
  if (*((unsigned char **)v22 + 3) == v23)
  {
    llvm::raw_ostream::write(v22, ":", 1uLL);
  }
  else
  {
    unsigned char *v23 = 58;
    ++*((void *)v22 + 4);
  }
  uint64_t v24 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v25 = (unsigned char *)*((void *)v24 + 4);
  if ((unint64_t)v25 >= *((void *)v24 + 3))
  {
    llvm::raw_ostream::write(v24, 32);
  }
  else
  {
    *((void *)v24 + 4) = v25 + 1;
    unsigned char *v25 = 32;
  }
  uint64_t v26 = *(void *)this;
  unint64_t v27 = *(unsigned int *)(*(void *)this + 44);
  uint64_t v28 = (_DWORD *)(*(void *)this + 16 * ((v27 >> 23) & 1) + 64);
  if (!HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
    uint64_t v28 = 0;
  }
  int v29 = v28[8];
  if ((v27 & 0x800000) != 0)
  {
    uint64_t v30 = *(void *)(v26 + 72);
    if (v29) {
      goto LABEL_37;
    }
  }
  else
  {
    uint64_t v30 = 0;
    if (v29)
    {
LABEL_37:
      uint64_t v31 = (v28[7] + v28[6]);
      if (*(void *)(v30 + 32 * v31 + 24)) {
        (*(void (**)(mlir::OpAsmPrinter *, unint64_t))(*(void *)a2 + 32))(a2, *(void *)(*(void *)(*(void *)(v26 + 72) + 32 * v31 + 24) + 8) & 0xFFFFFFFFFFFFFFF8);
      }
    }
  }
  uint64_t v32 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  unint64_t v33 = (unsigned char *)*((void *)v32 + 4);
  if (*((unsigned char **)v32 + 3) == v33)
  {
    llvm::raw_ostream::write(v32, ")", 1uLL);
  }
  else
  {
    *unint64_t v33 = 41;
    ++*((void *)v32 + 4);
  }
LABEL_42:
  unint64_t v34 = *(void *)this + 16 * (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 23) & 1) + 64;
  if (!HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
    unint64_t v34 = 0;
  }
  if (*(void *)(v34 + 8))
  {
    int64_t v35 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
    int64_t v36 = (unsigned char *)*((void *)v35 + 4);
    if ((unint64_t)v36 >= *((void *)v35 + 3))
    {
      llvm::raw_ostream::write(v35, 32);
    }
    else
    {
      *((void *)v35 + 4) = v36 + 1;
      *int64_t v36 = 32;
    }
    int64_t v37 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
    __int16 v38 = (void *)*((void *)v37 + 4);
    if (*((void *)v37 + 3) - (void)v38 > 0xEuLL)
    {
      qmemcpy(v38, "outer_dims_perm", 15);
      *((void *)v37 + 4) += 15;
    }
    else
    {
      llvm::raw_ostream::write(v37, "outer_dims_perm", 0xFuLL);
    }
    uint64_t v39 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
    uint64_t v40 = (unsigned char *)*((void *)v39 + 4);
    if ((unint64_t)v40 >= *((void *)v39 + 3))
    {
      llvm::raw_ostream::write(v39, 32);
    }
    else
    {
      *((void *)v39 + 4) = v40 + 1;
      *uint64_t v40 = 32;
    }
    uint64_t v41 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
    unint64_t v42 = (unsigned char *)*((void *)v41 + 4);
    if (*((unsigned char **)v41 + 3) == v42)
    {
      llvm::raw_ostream::write(v41, "=", 1uLL);
    }
    else
    {
      *unint64_t v42 = 61;
      ++*((void *)v41 + 4);
    }
    uint64_t v43 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
    uint64_t v44 = (unsigned char *)*((void *)v43 + 4);
    if ((unint64_t)v44 >= *((void *)v43 + 3))
    {
      llvm::raw_ostream::write(v43, 32);
    }
    else
    {
      *((void *)v43 + 4) = v44 + 1;
      *uint64_t v44 = 32;
    }
    unint64_t v45 = *(void *)this + 16 * (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 23) & 1) + 64;
    if (!HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
      unint64_t v45 = 0;
    }
    uint64_t v112 = *(void **)(v45 + 8);
    if (!(*(unsigned __int8 (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 104))(a2))
    {
      unsigned int v46 = (void *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
      uint64_t v47 = (*(uint64_t (**)(void *))(*v46 + 80))(v46) + v46[4] - v46[2];
      mlir::detail::DenseArrayAttrImpl<long long>::print((llvm::raw_ostream *)&v112, (uint64_t)a2);
      if (v47 == (*(uint64_t (**)(void *))(*v46 + 80))(v46) + v46[4] - v46[2]) {
        (*(void (**)(mlir::OpAsmPrinter *, void *))(*(void *)a2 + 40))(a2, v112);
      }
    }
  }
  uint64_t v48 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v49 = (unsigned char *)*((void *)v48 + 4);
  if ((unint64_t)v49 >= *((void *)v48 + 3))
  {
    llvm::raw_ostream::write(v48, 32);
  }
  else
  {
    *((void *)v48 + 4) = v49 + 1;
    *uint64_t v49 = 32;
  }
  __int16 v50 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v51 = (void *)*((void *)v50 + 4);
  if (*((void *)v50 + 3) - (void)v51 > 0xDuLL)
  {
    qmemcpy(v51, "inner_dims_pos", 14);
    *((void *)v50 + 4) += 14;
  }
  else
  {
    llvm::raw_ostream::write(v50, "inner_dims_pos", 0xEuLL);
  }
  uint64_t v52 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v53 = (unsigned char *)*((void *)v52 + 4);
  if ((unint64_t)v53 >= *((void *)v52 + 3))
  {
    llvm::raw_ostream::write(v52, 32);
  }
  else
  {
    *((void *)v52 + 4) = v53 + 1;
    *uint64_t v53 = 32;
  }
  unsigned int v54 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v55 = (unsigned char *)*((void *)v54 + 4);
  if (*((unsigned char **)v54 + 3) == v55)
  {
    llvm::raw_ostream::write(v54, "=", 1uLL);
  }
  else
  {
    *uint64_t v55 = 61;
    ++*((void *)v54 + 4);
  }
  __int16 v56 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v57 = (unsigned char *)*((void *)v56 + 4);
  if ((unint64_t)v57 >= *((void *)v56 + 3))
  {
    llvm::raw_ostream::write(v56, 32);
  }
  else
  {
    *((void *)v56 + 4) = v57 + 1;
    *uint64_t v57 = 32;
  }
  uint64_t v112 = *(void **)(*(void *)this + 16 * (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 23) & 1) + 64);
  if (!(*(unsigned __int8 (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 104))(a2))
  {
    uint64_t v58 = (void *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
    uint64_t v59 = (*(uint64_t (**)(void *))(*v58 + 80))(v58) + v58[4] - v58[2];
    mlir::detail::DenseArrayAttrImpl<long long>::print((llvm::raw_ostream *)&v112, (uint64_t)a2);
    if (v59 == (*(uint64_t (**)(void *))(*v58 + 80))(v58) + v58[4] - v58[2]) {
      (*(void (**)(mlir::OpAsmPrinter *, void *))(*(void *)a2 + 40))(a2, v112);
    }
  }
  uint64_t v60 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v61 = (unsigned char *)*((void *)v60 + 4);
  if ((unint64_t)v61 >= *((void *)v60 + 3))
  {
    llvm::raw_ostream::write(v60, 32);
  }
  else
  {
    *((void *)v60 + 4) = v61 + 1;
    unsigned char *v61 = 32;
  }
  unsigned int v62 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v63 = *((void *)v62 + 4);
  if ((unint64_t)(*((void *)v62 + 3) - v63) > 0xA)
  {
    *(_DWORD *)(v63 + 7) = 1936026729;
    *(void *)uint64_t v63 = *(void *)"inner_tiles";
    *((void *)v62 + 4) += 11;
  }
  else
  {
    llvm::raw_ostream::write(v62, "inner_tiles", 0xBuLL);
  }
  char v64 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v65 = (unsigned char *)*((void *)v64 + 4);
  if ((unint64_t)v65 >= *((void *)v64 + 3))
  {
    llvm::raw_ostream::write(v64, 32);
  }
  else
  {
    *((void *)v64 + 4) = v65 + 1;
    *uint64_t v65 = 32;
  }
  unint64_t v66 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  unint64_t v67 = (unsigned char *)*((void *)v66 + 4);
  if (*((unsigned char **)v66 + 3) == v67)
  {
    llvm::raw_ostream::write(v66, "=", 1uLL);
  }
  else
  {
    *unint64_t v67 = 61;
    ++*((void *)v66 + 4);
  }
  unint64_t v68 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  long long v69 = (unsigned char *)*((void *)v68 + 4);
  if ((unint64_t)v69 >= *((void *)v68 + 3))
  {
    llvm::raw_ostream::write(v68, 32);
  }
  else
  {
    *((void *)v68 + 4) = v69 + 1;
    *long long v69 = 32;
  }
  uint64_t v70 = *(void *)this;
  unint64_t v71 = *(unsigned int *)(*(void *)this + 44);
  uint64_t v72 = *(void *)this + 16 * ((v71 >> 23) & 1) + 64;
  if (!HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
    uint64_t v72 = 0;
  }
  if ((v71 & 0x800000) != 0) {
    uint64_t v73 = *(void *)(v70 + 72);
  }
  else {
    uint64_t v73 = 0;
  }
  uint64_t v74 = (*(_DWORD *)(v72 + 28) + *(_DWORD *)(v72 + 24) + *(_DWORD *)(v72 + 32));
  uint64_t v75 = v73 + 32 * v74;
  uint64_t v76 = (*(_DWORD *)(v72 + 36) + v74) - v74;
  uint64_t v112 = *(void **)(v72 + 16);
  int v77 = (unint64_t *)mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)&v112);
  uint64_t v79 = v78;
  mlir::ValueRange::ValueRange(v115, 0, 0);
  mlir::printDynamicIndexList((uint64_t)a2, v70, v75, v76, v77, v79, v115[0], v115[1], 0, 0, 2);
  BOOL v80 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  unsigned int v81 = (unsigned char *)*((void *)v80 + 4);
  if ((unint64_t)v81 >= *((void *)v80 + 3))
  {
    llvm::raw_ostream::write(v80, 32);
  }
  else
  {
    *((void *)v80 + 4) = v81 + 1;
    *unsigned int v81 = 32;
  }
  unsigned int v82 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  long long v83 = (_DWORD *)*((void *)v82 + 4);
  if (*((void *)v82 + 3) - (void)v83 > 3uLL)
  {
    *long long v83 = 1869901417;
    *((void *)v82 + 4) += 4;
  }
  else
  {
    llvm::raw_ostream::write(v82, "into", 4uLL);
  }
  uint64_t v84 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v85 = (unsigned char *)*((void *)v84 + 4);
  if ((unint64_t)v85 >= *((void *)v84 + 3))
  {
    llvm::raw_ostream::write(v84, 32);
  }
  else
  {
    *((void *)v84 + 4) = v85 + 1;
    *uint64_t v85 = 32;
  }
  if (*(unsigned char *)(*(void *)this + 47)) {
    uint64_t v86 = *(void *)this + 80;
  }
  else {
    uint64_t v86 = 0;
  }
  (*(void (**)(mlir::OpAsmPrinter *, void))(*(void *)a2 + 160))(a2, *(void *)(*(void *)(*(void *)this + 72) + 32 * *(unsigned int *)(v86 + 24) + 24));
  uint64_t v112 = v114;
  v114[0] = "operandSegmentSizes";
  v114[1] = 19;
  v114[2] = "outer_dims_perm";
  v114[3] = 15;
  uint64_t v113 = 0x200000002;
  llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v112, v114, 3uLL, 16);
  unint64_t v87 = (char *)v112 + 16 * v113;
  *unint64_t v87 = "inner_dims_pos";
  v87[1] = 14;
  uint64_t v88 = (v113 + 1);
  LODWORD(v113) = v88;
  if (v88 >= HIDWORD(v113))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v112, v114, v88 + 1, 16);
    LODWORD(v88) = v113;
  }
  uint64_t v89 = (char *)v112 + 16 * v88;
  *uint64_t v89 = "static_inner_tiles";
  v89[1] = 18;
  LODWORD(v113) = v113 + 1;
  uint64_t Context = (mlir::MLIRContext *)mlir::Attribute::getContext((mlir::Attribute *)(*(void *)this + 24));
  unint64_t v90 = *(void *)this + 16 * (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 23) & 1) + 64;
  if (!HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
    unint64_t v90 = 0;
  }
  uint64_t v91 = *(void *)(v90 + 8);
  if (v91 && v91 == mlir::Builder::getDenseI64ArrayAttr(&Context, 0, 0))
  {
    unsigned int v94 = v113;
    if (v113 >= HIDWORD(v113))
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v112, v114, v113 + 1, 16);
      unsigned int v94 = v113;
    }
    unint64_t v95 = (char *)v112 + 16 * v94;
    *unint64_t v95 = "outer_dims_perm";
    v95[1] = 15;
    LODWORD(v113) = v113 + 1;
    unint64_t v92 = *(mlir::Operation **)this;
    if (!*(unsigned char *)(*(void *)this + 47)) {
      goto LABEL_121;
    }
  }
  else
  {
    unint64_t v92 = *(mlir::Operation **)this;
    if (!*(unsigned char *)(*(void *)this + 47))
    {
LABEL_121:
      p_uint64_t Context = (mlir::Operation *)((char *)v92 + 56);
      goto LABEL_126;
    }
  }
  uint64_t Context = (mlir::MLIRContext *)mlir::Operation::getAttrDictionary(v92);
  p_uint64_t Context = (mlir::ArrayAttr *)&Context;
LABEL_126:
  uint64_t Value = mlir::ArrayAttr::getValue(p_Context);
  (*(void (**)(mlir::OpAsmPrinter *, uint64_t, uint64_t, void *, void))(*(void *)a2 + 192))(a2, Value, v97, v112, v113);
  unint64_t v98 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  int64_t v99 = (unsigned char *)*((void *)v98 + 4);
  if ((unint64_t)v99 >= *((void *)v98 + 3))
  {
    llvm::raw_ostream::write(v98, 32);
  }
  else
  {
    *((void *)v98 + 4) = v99 + 1;
    *int64_t v99 = 32;
  }
  int64_t v100 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  int64_t v101 = (unsigned char *)*((void *)v100 + 4);
  if (*((unsigned char **)v100 + 3) == v101)
  {
    llvm::raw_ostream::write(v100, ":", 1uLL);
  }
  else
  {
    *int64_t v101 = 58;
    ++*((void *)v100 + 4);
  }
  int64_t v102 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  int64_t v103 = (unsigned char *)*((void *)v102 + 4);
  if ((unint64_t)v103 >= *((void *)v102 + 3))
  {
    llvm::raw_ostream::write(v102, 32);
  }
  else
  {
    *((void *)v102 + 4) = v103 + 1;
    *int64_t v103 = 32;
  }
  (*(void (**)(mlir::OpAsmPrinter *, unint64_t))(*(void *)a2 + 32))(a2, *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8);
  int64_t v104 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  int64_t v105 = (unsigned char *)*((void *)v104 + 4);
  if ((unint64_t)v105 >= *((void *)v104 + 3))
  {
    llvm::raw_ostream::write(v104, 32);
  }
  else
  {
    *((void *)v104 + 4) = v105 + 1;
    *int64_t v105 = 32;
  }
  int64_t v106 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  int64_t v107 = (_WORD *)*((void *)v106 + 4);
  if (*((void *)v106 + 3) - (void)v107 > 1uLL)
  {
    *int64_t v107 = 15917;
    *((void *)v106 + 4) += 2;
  }
  else
  {
    llvm::raw_ostream::write(v106, "->", 2uLL);
  }
  uint64_t v108 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  int v109 = (unsigned char *)*((void *)v108 + 4);
  if ((unint64_t)v109 >= *((void *)v108 + 3))
  {
    llvm::raw_ostream::write(v108, 32);
  }
  else
  {
    *((void *)v108 + 4) = v109 + 1;
    *int v109 = 32;
  }
  if (*(unsigned char *)(*(void *)this + 47)) {
    uint64_t v110 = *(void *)this + 80;
  }
  else {
    uint64_t v110 = 0;
  }
  (*(void (**)(mlir::OpAsmPrinter *, unint64_t))(*(void *)a2 + 32))(a2, *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 32 * *(unsigned int *)(v110 + 24) + 24) + 8) & 0xFFFFFFFFFFFFFFF8);
  if (v112 != v114) {
    free(v112);
  }
}

uint64_t mlir::tensor::detail::PadOpGenericAdaptorBase::PadOpGenericAdaptorBase(uint64_t a1, uint64_t a2)
{
  uint64_t v13 = *MEMORY[0x263EF8340];
  uint64_t v3 = *(void *)(a2 + 56);
  unint64_t v4 = *(unsigned int *)(a2 + 44);
  if (HIBYTE(*(_DWORD *)(a2 + 44))) {
    uint64_t v5 = a2 + 16 * ((v4 >> 23) & 1) + 64;
  }
  else {
    uint64_t v5 = 0;
  }
  unint64_t v6 = v4 & 0x7FFFFF;
  if ((v4 & 0x7FFFFF) != 0)
  {
    uint64_t v7 = ((a2 + 16 * ((v4 >> 23) & 1) + 64 + ((v4 >> 21) & 0x7F8) + 7) & 0xFFFFFFFFFFFFFFF8)
       + 32 * *(unsigned int *)(a2 + 40);
  }
  else
  {
    uint64_t v7 = 0;
    unint64_t v6 = 0;
  }
  mlir::ValueRange::ValueRange(v12, v7, v6);
  *(void *)a1 = v3;
  *(unsigned char *)(a1 + 8) = 0;
  *(unsigned char *)(a1 + 16) = 0;
  long long v8 = *(_OWORD *)v5;
  long long v9 = *(_OWORD *)(v5 + 16);
  *(void *)(a1 + 56) = *(void *)(v5 + 32);
  *(_OWORD *)(a1 + 40) = v9;
  *(_OWORD *)(a1 + 24) = v8;
  *(_OWORD *)(a1 + 64) = *(_OWORD *)v12;
  if (v3)
  {
    uint64_t Context = mlir::Attribute::getContext((mlir::Attribute *)a1);
    if (*(unsigned char *)(a1 + 16)) {
      *(unsigned char *)(a1 + 16) = 0;
    }
    mlir::OperationName::OperationName(a1 + 8, "tensor.pad", 10, Context);
    *(unsigned char *)(a1 + 16) = 1;
  }
  return a1;
}

uint64_t mlir::tensor::PadOp::setPropertiesFromAttr(uint64_t *a1, uint64_t a2, void (*a3)(uint64_t *__return_ptr, uint64_t), uint64_t a4)
{
  uint64_t v122 = *MEMORY[0x263EF8340];
  if (*(_UNKNOWN **)(*(void *)a2 + 136) == &mlir::detail::TypeIDResolver<mlir::DictionaryAttr,void>::id) {
    uint64_t v6 = a2;
  }
  else {
    uint64_t v6 = 0;
  }
  uint64_t v108 = v6;
  if (!v6)
  {
    a3(v112, a4);
    if (v112[0])
    {
      int v109 = 3;
      uint64_t v110 = "expected DictionaryAttr to set properties";
      uint64_t v111 = 41;
      uint64_t v26 = &v109;
      unint64_t v27 = (char *)v113;
      if (v114 >= v115)
      {
        unint64_t v90 = v114 + 1;
        if (v113 <= &v109 && (char *)v113 + 24 * v114 > (char *)&v109)
        {
          int64_t v99 = (char *)&v109 - (unsigned char *)v113;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v113, v116, v90, 24);
          unint64_t v27 = (char *)v113;
          uint64_t v26 = (int *)((char *)v113 + v99);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v113, v116, v90, 24);
          uint64_t v26 = &v109;
          unint64_t v27 = (char *)v113;
        }
      }
      uint64_t v28 = &v27[24 * v114];
      long long v29 = *(_OWORD *)v26;
      *((void *)v28 + 2) = *((void *)v26 + 2);
      *(_OWORD *)uint64_t v28 = v29;
      ++v114;
      if (v112[0]) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v112);
      }
    }
    if (!v121) {
      return 0;
    }
    uint64_t v30 = __p;
    if (__p)
    {
      uint64_t v31 = v120;
      uint64_t v32 = __p;
      if (v120 != __p)
      {
        do
          uint64_t v31 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v31 - 1);
        while (v31 != v30);
        uint64_t v32 = __p;
      }
      char v120 = v30;
      operator delete(v32);
    }
    uint64_t v21 = v117;
    if (!v117) {
      goto LABEL_120;
    }
    unint64_t v33 = v118;
    uint64_t v23 = v117;
    if (v118 == v117)
    {
LABEL_119:
      uint64_t v118 = v21;
      operator delete(v23);
LABEL_120:
      if (v113 != v116) {
        free(v113);
      }
      return 0;
    }
    do
    {
      uint64_t v35 = *--v33;
      uint64_t v34 = v35;
      *unint64_t v33 = 0;
      if (v35) {
        MEMORY[0x21667D390](v34, 0x1000C8077774924);
      }
    }
    while (v33 != v21);
LABEL_118:
    uint64_t v23 = v117;
    goto LABEL_119;
  }
  uint64_t v8 = mlir::DictionaryAttr::get((uint64_t)&v108, "nofold", 6uLL);
  if (v8)
  {
    uint64_t v9 = v8;
    if (*(_UNKNOWN **)(*(void *)v8 + 136) != &mlir::detail::TypeIDResolver<mlir::UnitAttr,void>::id)
    {
      a3(v112, a4);
      if (v112[0])
      {
        int v109 = 3;
        uint64_t v111 = 51;
        long long v10 = &v109;
        unsigned __int16 v11 = (char *)v113;
        if (v114 >= v115)
        {
          unint64_t v91 = v114 + 1;
          if (v113 <= &v109 && (char *)v113 + 24 * v114 > (char *)&v109)
          {
            int64_t v100 = (char *)&v109 - (unsigned char *)v113;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v113, v116, v91, 24);
            unsigned __int16 v11 = (char *)v113;
            long long v10 = (int *)((char *)v113 + v100);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v113, v116, v91, 24);
            long long v10 = &v109;
            unsigned __int16 v11 = (char *)v113;
          }
        }
        uint64_t v12 = &v11[24 * v114];
        long long v13 = *(_OWORD *)v10;
        *((void *)v12 + 2) = *((void *)v10 + 2);
        *(_OWORD *)uint64_t v12 = v13;
        ++v114;
        if (v112[0])
        {
          uint64_t v14 = &v109;
          mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v109, v9);
          uint64_t v15 = (char *)v113;
          if (v114 >= v115)
          {
            unint64_t v92 = v114 + 1;
            if (v113 <= &v109 && (char *)v113 + 24 * v114 > (char *)&v109)
            {
              int64_t v101 = (char *)&v109 - (unsigned char *)v113;
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v113, v116, v92, 24);
              uint64_t v15 = (char *)v113;
              uint64_t v14 = (int *)((char *)v113 + v101);
            }
            else
            {
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v113, v116, v92, 24);
              uint64_t v14 = &v109;
              uint64_t v15 = (char *)v113;
            }
          }
          unint64_t v16 = &v15[24 * v114];
          long long v17 = *(_OWORD *)v14;
          *((void *)v16 + 2) = *((void *)v14 + 2);
          *(_OWORD *)unint64_t v16 = v17;
          ++v114;
          if (v112[0]) {
            mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v112);
          }
        }
      }
      if (!v121) {
        return 0;
      }
      int v18 = __p;
      if (__p)
      {
        uint64_t v19 = v120;
        uint64_t v20 = __p;
        if (v120 != __p)
        {
          do
            uint64_t v19 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v19 - 1);
          while (v19 != v18);
          uint64_t v20 = __p;
        }
        char v120 = v18;
        operator delete(v20);
      }
      uint64_t v21 = v117;
      if (!v117) {
        goto LABEL_120;
      }
      uint64_t v22 = v118;
      uint64_t v23 = v117;
      if (v118 == v117) {
        goto LABEL_119;
      }
      do
      {
        uint64_t v25 = *--v22;
        uint64_t v24 = v25;
        *uint64_t v22 = 0;
        if (v25) {
          MEMORY[0x21667D390](v24, 0x1000C8077774924);
        }
      }
      while (v22 != v21);
      goto LABEL_118;
    }
    *a1 = v8;
  }
  int64_t v36 = (void *)mlir::DictionaryAttr::get((uint64_t)&v108, "static_high", 0xBuLL);
  if (!v36)
  {
    a3(v112, a4);
    if (v112[0])
    {
      int v109 = 3;
      uint64_t v110 = "expected key entry for static_high in DictionaryAttr to set Properties.";
      uint64_t v111 = 71;
      unint64_t v42 = &v109;
      uint64_t v43 = (char *)v113;
      if (v114 >= v115)
      {
        unint64_t v93 = v114 + 1;
        if (v113 <= &v109 && (char *)v113 + 24 * v114 > (char *)&v109)
        {
          int64_t v102 = (char *)&v109 - (unsigned char *)v113;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v113, v116, v93, 24);
          uint64_t v43 = (char *)v113;
          unint64_t v42 = (int *)((char *)v113 + v102);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v113, v116, v93, 24);
          unint64_t v42 = &v109;
          uint64_t v43 = (char *)v113;
        }
      }
      uint64_t v44 = &v43[24 * v114];
      long long v45 = *(_OWORD *)v42;
      *((void *)v44 + 2) = *((void *)v42 + 2);
      *(_OWORD *)uint64_t v44 = v45;
      ++v114;
      if (v112[0]) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v112);
      }
    }
    if (!v121) {
      return 0;
    }
    unsigned int v46 = __p;
    if (__p)
    {
      uint64_t v47 = v120;
      uint64_t v48 = __p;
      if (v120 != __p)
      {
        do
          uint64_t v47 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v47 - 1);
        while (v47 != v46);
        uint64_t v48 = __p;
      }
      char v120 = v46;
      operator delete(v48);
    }
    uint64_t v21 = v117;
    if (!v117) {
      goto LABEL_120;
    }
    uint64_t v49 = v118;
    uint64_t v23 = v117;
    if (v118 == v117) {
      goto LABEL_119;
    }
    do
    {
      uint64_t v51 = *--v49;
      uint64_t v50 = v51;
      *uint64_t v49 = 0;
      if (v51) {
        MEMORY[0x21667D390](v50, 0x1000C8077774924);
      }
    }
    while (v49 != v21);
    goto LABEL_118;
  }
  uint64_t v37 = (uint64_t)v36;
  if (!mlir::detail::DenseArrayAttrImpl<long long>::classof(v36))
  {
    a3(v112, a4);
    if (v112[0])
    {
      int v109 = 3;
      uint64_t v111 = 56;
      uint64_t v52 = &v109;
      uint64_t v53 = (char *)v113;
      if (v114 >= v115)
      {
        unint64_t v94 = v114 + 1;
        if (v113 <= &v109 && (char *)v113 + 24 * v114 > (char *)&v109)
        {
          int64_t v103 = (char *)&v109 - (unsigned char *)v113;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v113, v116, v94, 24);
          uint64_t v53 = (char *)v113;
          uint64_t v52 = (int *)((char *)v113 + v103);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v113, v116, v94, 24);
          uint64_t v52 = &v109;
          uint64_t v53 = (char *)v113;
        }
      }
      unsigned int v54 = &v53[24 * v114];
      long long v55 = *(_OWORD *)v52;
      *((void *)v54 + 2) = *((void *)v52 + 2);
      *(_OWORD *)unsigned int v54 = v55;
      ++v114;
      if (v112[0])
      {
        __int16 v56 = &v109;
        mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v109, v37);
        uint64_t v57 = (char *)v113;
        if (v114 >= v115)
        {
          unint64_t v95 = v114 + 1;
          if (v113 <= &v109 && (char *)v113 + 24 * v114 > (char *)&v109)
          {
            int64_t v104 = (char *)&v109 - (unsigned char *)v113;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v113, v116, v95, 24);
            uint64_t v57 = (char *)v113;
            __int16 v56 = (int *)((char *)v113 + v104);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v113, v116, v95, 24);
            __int16 v56 = &v109;
            uint64_t v57 = (char *)v113;
          }
        }
        uint64_t v58 = &v57[24 * v114];
        long long v59 = *(_OWORD *)v56;
        *((void *)v58 + 2) = *((void *)v56 + 2);
        *(_OWORD *)uint64_t v58 = v59;
        ++v114;
        if (v112[0]) {
          mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v112);
        }
      }
    }
    if (!v121) {
      return 0;
    }
    uint64_t v60 = __p;
    if (__p)
    {
      uint64_t v61 = v120;
      unsigned int v62 = __p;
      if (v120 != __p)
      {
        do
          uint64_t v61 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v61 - 1);
        while (v61 != v60);
        unsigned int v62 = __p;
      }
      char v120 = v60;
      operator delete(v62);
    }
    uint64_t v21 = v117;
    if (!v117) {
      goto LABEL_120;
    }
    uint64_t v63 = v118;
    uint64_t v23 = v117;
    if (v118 == v117) {
      goto LABEL_119;
    }
    do
    {
      uint64_t v65 = *--v63;
      uint64_t v64 = v65;
      *uint64_t v63 = 0;
      if (v65) {
        MEMORY[0x21667D390](v64, 0x1000C8077774924);
      }
    }
    while (v63 != v21);
    goto LABEL_118;
  }
  a1[1] = v37;
  __int16 v38 = (void *)mlir::DictionaryAttr::get((uint64_t)&v108, "static_low", 0xAuLL);
  if (!v38)
  {
    a3(v112, a4);
    if (v112[0])
    {
      int v109 = 3;
      uint64_t v110 = "expected key entry for static_low in DictionaryAttr to set Properties.";
      uint64_t v111 = 70;
      unint64_t v66 = &v109;
      unint64_t v67 = (char *)v113;
      if (v114 >= v115)
      {
        unint64_t v96 = v114 + 1;
        if (v113 <= &v109 && (char *)v113 + 24 * v114 > (char *)&v109)
        {
          int64_t v105 = (char *)&v109 - (unsigned char *)v113;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v113, v116, v96, 24);
          unint64_t v67 = (char *)v113;
          unint64_t v66 = (int *)((char *)v113 + v105);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v113, v116, v96, 24);
          unint64_t v66 = &v109;
          unint64_t v67 = (char *)v113;
        }
      }
      unint64_t v68 = &v67[24 * v114];
      long long v69 = *(_OWORD *)v66;
      *((void *)v68 + 2) = *((void *)v66 + 2);
      *(_OWORD *)unint64_t v68 = v69;
      ++v114;
      if (v112[0]) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v112);
      }
    }
    if (!v121) {
      return 0;
    }
    uint64_t v70 = __p;
    if (__p)
    {
      unint64_t v71 = v120;
      uint64_t v72 = __p;
      if (v120 != __p)
      {
        do
          unint64_t v71 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v71 - 1);
        while (v71 != v70);
        uint64_t v72 = __p;
      }
      char v120 = v70;
      operator delete(v72);
    }
    uint64_t v21 = v117;
    if (!v117) {
      goto LABEL_120;
    }
    uint64_t v73 = v118;
    uint64_t v23 = v117;
    if (v118 == v117) {
      goto LABEL_119;
    }
    do
    {
      uint64_t v75 = *--v73;
      uint64_t v74 = v75;
      *uint64_t v73 = 0;
      if (v75) {
        MEMORY[0x21667D390](v74, 0x1000C8077774924);
      }
    }
    while (v73 != v21);
    goto LABEL_118;
  }
  uint64_t v39 = (uint64_t)v38;
  if (!mlir::detail::DenseArrayAttrImpl<long long>::classof(v38))
  {
    a3(v112, a4);
    if (v112[0])
    {
      int v109 = 3;
      uint64_t v111 = 55;
      uint64_t v76 = &v109;
      int v77 = (char *)v113;
      if (v114 >= v115)
      {
        unint64_t v97 = v114 + 1;
        if (v113 <= &v109 && (char *)v113 + 24 * v114 > (char *)&v109)
        {
          int64_t v106 = (char *)&v109 - (unsigned char *)v113;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v113, v116, v97, 24);
          int v77 = (char *)v113;
          uint64_t v76 = (int *)((char *)v113 + v106);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v113, v116, v97, 24);
          uint64_t v76 = &v109;
          int v77 = (char *)v113;
        }
      }
      uint64_t v78 = &v77[24 * v114];
      long long v79 = *(_OWORD *)v76;
      *((void *)v78 + 2) = *((void *)v76 + 2);
      *(_OWORD *)uint64_t v78 = v79;
      ++v114;
      if (v112[0])
      {
        BOOL v80 = &v109;
        mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v109, v39);
        unsigned int v81 = (char *)v113;
        if (v114 >= v115)
        {
          unint64_t v98 = v114 + 1;
          if (v113 <= &v109 && (char *)v113 + 24 * v114 > (char *)&v109)
          {
            int64_t v107 = (char *)&v109 - (unsigned char *)v113;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v113, v116, v98, 24);
            unsigned int v81 = (char *)v113;
            BOOL v80 = (int *)((char *)v113 + v107);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v113, v116, v98, 24);
            BOOL v80 = &v109;
            unsigned int v81 = (char *)v113;
          }
        }
        unsigned int v82 = &v81[24 * v114];
        long long v83 = *(_OWORD *)v80;
        *((void *)v82 + 2) = *((void *)v80 + 2);
        *(_OWORD *)unsigned int v82 = v83;
        ++v114;
        if (v112[0]) {
          mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v112);
        }
      }
    }
    if (!v121) {
      return 0;
    }
    uint64_t v84 = __p;
    if (__p)
    {
      uint64_t v85 = v120;
      uint64_t v86 = __p;
      if (v120 != __p)
      {
        do
          uint64_t v85 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v85 - 1);
        while (v85 != v84);
        uint64_t v86 = __p;
      }
      char v120 = v84;
      operator delete(v86);
    }
    uint64_t v21 = v117;
    if (!v117) {
      goto LABEL_120;
    }
    unint64_t v87 = v118;
    uint64_t v23 = v117;
    if (v118 == v117) {
      goto LABEL_119;
    }
    do
    {
      uint64_t v89 = *--v87;
      uint64_t v88 = v89;
      *unint64_t v87 = 0;
      if (v89) {
        MEMORY[0x21667D390](v88, 0x1000C8077774924);
      }
    }
    while (v87 != v21);
    goto LABEL_118;
  }
  a1[2] = v39;
  uint64_t v40 = (void *)mlir::DictionaryAttr::get((uint64_t)&v108, "operandSegmentSizes", 0x13uLL);
  if (v40 || (uint64_t v40 = (void *)mlir::DictionaryAttr::get((uint64_t)&v108, "operand_segment_sizes", 0x15uLL)) != 0)
  {
    if (mlir::convertFromAttribute(a1 + 3, (const char *)3, v40, a3, a4)) {
      return 1;
    }
  }
  else
  {
    a3(v112, a4);
    mlir::InFlightDiagnostic::operator<<<char const(&)[44]>((uint64_t)v112, "expected key entry for operandSegmentSizes in DictionaryAttr to set Properties.");
    mlir::InFlightDiagnostic::~InFlightDiagnostic((mlir::InFlightDiagnostic *)v112);
  }
  return 0;
}

uint64_t mlir::tensor::PadOp::getPropertiesAsAttr(mlir::DictionaryAttr *a1, uint64_t *a2)
{
  void v35[6] = *MEMORY[0x263EF8340];
  uint64_t v32 = a1;
  unint64_t v33 = v35;
  uint64_t v34 = 0x300000000;
  if (*a2)
  {
    uint64_t NamedAttr = mlir::Builder::getNamedAttr(&v32, (uint64_t)"nofold", 6, *a2);
    uint64_t v6 = v5;
    unsigned int v7 = v34;
    if (v34 >= HIDWORD(v34))
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v33, v35, v34 + 1, 16);
      unsigned int v7 = v34;
    }
    uint64_t v8 = (uint64_t *)((char *)v33 + 16 * v7);
    *uint64_t v8 = NamedAttr;
    v8[1] = v6;
    LODWORD(v34) = v34 + 1;
  }
  uint64_t v9 = a2[1];
  if (v9)
  {
    uint64_t v10 = mlir::Builder::getNamedAttr(&v32, (uint64_t)"static_high", 11, v9);
    uint64_t v12 = v11;
    unsigned int v13 = v34;
    if (v34 >= HIDWORD(v34))
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v33, v35, v34 + 1, 16);
      unsigned int v13 = v34;
    }
    uint64_t v14 = (uint64_t *)((char *)v33 + 16 * v13);
    *uint64_t v14 = v10;
    v14[1] = v12;
    LODWORD(v34) = v34 + 1;
  }
  uint64_t v15 = a2[2];
  if (v15)
  {
    uint64_t v16 = mlir::Builder::getNamedAttr(&v32, (uint64_t)"static_low", 10, v15);
    uint64_t v18 = v17;
    unsigned int v19 = v34;
    if (v34 >= HIDWORD(v34))
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v33, v35, v34 + 1, 16);
      unsigned int v19 = v34;
    }
    uint64_t v20 = (uint64_t *)((char *)v33 + 16 * v19);
    uint64_t *v20 = v16;
    v20[1] = v18;
    LODWORD(v34) = v34 + 1;
  }
  uint64_t v21 = mlir::detail::DenseArrayAttrImpl<int>::get(a1, (uint64_t)(a2 + 3), 3);
  uint64_t v22 = mlir::Builder::getNamedAttr(&v32, (uint64_t)"operandSegmentSizes", 19, v21);
  uint64_t v24 = v23;
  unsigned int v25 = v34;
  if (v34 >= HIDWORD(v34))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v33, v35, v34 + 1, 16);
    unsigned int v25 = v34;
  }
  uint64_t v26 = (uint64_t *)((char *)v33 + 16 * v25);
  *uint64_t v26 = v22;
  v26[1] = v24;
  BOOL v27 = __CFADD__(v34, 1);
  uint64_t v28 = (v34 + 1);
  LODWORD(v34) = v34 + 1;
  if (v27)
  {
    uint64_t DictionaryAttr = 0;
    uint64_t v30 = v33;
    if (v33 == v35) {
      return DictionaryAttr;
    }
    goto LABEL_20;
  }
  uint64_t DictionaryAttr = mlir::Builder::getDictionaryAttr(&v32, (uint64_t *)v33, v28);
  uint64_t v30 = v33;
  if (v33 != v35) {
LABEL_20:
  }
    free(v30);
  return DictionaryAttr;
}

uint64_t mlir::tensor::PadOp::getInherentAttr(mlir::MLIRContext *a1, void *a2, _WORD *__s1, size_t __n)
{
  uint64_t result = 0;
  switch(__n)
  {
    case 6uLL:
      if (*(_DWORD *)__s1 != 1868984174 || __s1[2] != 25708) {
        goto LABEL_13;
      }
      return *a2;
    case 7uLL:
    case 8uLL:
    case 9uLL:
    case 0xCuLL:
    case 0xDuLL:
    case 0xEuLL:
    case 0xFuLL:
    case 0x10uLL:
    case 0x11uLL:
    case 0x12uLL:
    case 0x14uLL:
      goto LABEL_13;
    case 0xAuLL:
      if (memcmp(__s1, "static_low", __n)) {
        goto LABEL_13;
      }
      uint64_t result = a2[2];
      break;
    case 0xBuLL:
      if (memcmp(__s1, "static_high", __n)) {
        goto LABEL_13;
      }
      uint64_t result = a2[1];
      break;
    case 0x13uLL:
      if (memcmp(__s1, "operandSegmentSizes", __n)) {
        goto LABEL_13;
      }
      goto LABEL_15;
    case 0x15uLL:
      if (!memcmp(__s1, "operand_segment_sizes", __n)) {
LABEL_15:
      }
        uint64_t result = mlir::detail::DenseArrayAttrImpl<int>::get(a1, (uint64_t)(a2 + 3), 3);
      else {
LABEL_13:
      }
        uint64_t result = 0;
      break;
    default:
      return result;
  }
  return result;
}

uint64_t mlir::tensor::PadOp::setInherentAttr(uint64_t result, _WORD *__s1, size_t a3, void *a4)
{
  uint64_t v5 = (void *)result;
  switch(a3)
  {
    case 6uLL:
      if (*(_DWORD *)__s1 == 1868984174 && __s1[2] == 25708)
      {
        if (a4)
        {
          if (*(_UNKNOWN **)(*a4 + 136) == &mlir::detail::TypeIDResolver<mlir::UnitAttr,void>::id) {
            uint64_t v11 = a4;
          }
          else {
            uint64_t v11 = 0;
          }
          *(void *)uint64_t result = v11;
        }
        else
        {
          *(void *)uint64_t result = 0;
        }
      }
      break;
    case 0xAuLL:
      uint64_t result = memcmp(__s1, "static_low", a3);
      if (!result)
      {
        if (a4)
        {
          uint64_t result = mlir::detail::DenseArrayAttrImpl<long long>::classof(a4);
          if (result) {
            unsigned int v7 = a4;
          }
          else {
            unsigned int v7 = 0;
          }
          v5[2] = v7;
        }
        else
        {
          v5[2] = 0;
        }
      }
      break;
    case 0xBuLL:
      uint64_t result = memcmp(__s1, "static_high", a3);
      if (!result)
      {
        if (a4)
        {
          uint64_t result = mlir::detail::DenseArrayAttrImpl<long long>::classof(a4);
          if (result) {
            uint64_t v8 = a4;
          }
          else {
            uint64_t v8 = 0;
          }
          v5[1] = v8;
        }
        else
        {
          v5[1] = 0;
        }
      }
      break;
    case 0x13uLL:
      uint64_t result = memcmp(__s1, "operandSegmentSizes", a3);
      if (!result) {
        goto LABEL_22;
      }
      break;
    case 0x15uLL:
      uint64_t result = memcmp(__s1, "operand_segment_sizes", a3);
      if (!result)
      {
LABEL_22:
        if (a4)
        {
          uint64_t result = mlir::detail::DenseArrayAttrImpl<int>::classof(a4);
          uint64_t v9 = result ? a4 : 0;
          uint64_t v12 = v9;
          if (result)
          {
            uint64_t result = mlir::AffineBinaryOpExpr::getLHS((mlir::AffineBinaryOpExpr *)&v12);
            if (result == 3)
            {
              uint64_t result = mlir::detail::DenseArrayAttrImpl<int>::operator llvm::ArrayRef<int>((uint64_t)&v12);
              if (v10) {
                uint64_t result = (uint64_t)memmove(v5 + 3, (const void *)result, 4 * v10);
              }
            }
          }
        }
      }
      break;
    default:
      return result;
  }
  return result;
}

void mlir::tensor::PadOp::populateInherentAttrs(mlir::MLIRContext *a1, uint64_t *a2, uint64_t a3)
{
  if (*a2) {
    mlir::NamedAttrList::append(a3, (uint64_t)"nofold", 6, *a2);
  }
  uint64_t v6 = a2[1];
  if (v6) {
    mlir::NamedAttrList::append(a3, (uint64_t)"static_high", 11, v6);
  }
  uint64_t v7 = a2[2];
  if (v7) {
    mlir::NamedAttrList::append(a3, (uint64_t)"static_low", 10, v7);
  }
  uint64_t v8 = mlir::detail::DenseArrayAttrImpl<int>::get(a1, (uint64_t)(a2 + 3), 3);

  mlir::NamedAttrList::append(a3, (uint64_t)"operandSegmentSizes", 19, v8);
}

BOOL mlir::tensor::PadOp::verifyInherentAttrs(uint64_t a1, uint64_t a2, void (*a3)(uint64_t *__return_ptr, uint64_t), uint64_t a4)
{
  uint64_t v8 = mlir::NamedAttrList::get(a2, **(void **)(a1 + 96));
  BOOL result = 0;
  if (!v8
    || mlir::memref::__mlir_ods_local_attr_constraint_MemRefOps9(v8, (void **)"nofold", (const char *)6, a3, a4))
  {
    uint64_t v9 = (void *)mlir::NamedAttrList::get(a2, *(void *)(*(void *)(a1 + 96) + 8));
    if (!v9
      || mlir::memref::__mlir_ods_local_attr_constraint_MemRefOps12(v9, (void **)"static_high", (const char *)0xB, a3, a4))
    {
      uint64_t v10 = (void *)mlir::NamedAttrList::get(a2, *(void *)(*(void *)(a1 + 96) + 16));
      if (!v10
        || mlir::memref::__mlir_ods_local_attr_constraint_MemRefOps12(v10, (void **)"static_low", (const char *)0xA, a3, a4))
      {
        return 1;
      }
    }
  }
  return result;
}

BOOL mlir::tensor::PadOp::readProperties(uint64_t a1, uint64_t a2)
{
  uint64_t v26 = *MEMORY[0x263EF8340];
  uint64_t v3 = (uint64_t *)mlir::OperationState::getOrAddProperties<mlir::tensor::detail::PadOpGenericAdaptorBase::Properties>(a2);
  if (!mlir::DialectBytecodeReader::readOptionalAttribute<mlir::UnitAttr>(a1, v3)) {
    return 0;
  }
  if ((unint64_t)(*(uint64_t (**)(uint64_t))(*(void *)a1 + 40))(a1) <= 5)
  {
    uint64_t v17 = 0;
    if (!mlir::DialectBytecodeReader::readAttribute<mlir::detail::DenseArrayAttrImpl<int>>(a1, &v17)) {
      return 0;
    }
    if (mlir::AffineBinaryOpExpr::getLHS((mlir::AffineBinaryOpExpr *)&v17) >= 4)
    {
      uint64_t v15 = "size mismatch for operand/result_segment_size";
      __int16 v16 = 259;
      (*(void (**)(void *__return_ptr, uint64_t, const char **))(*(void *)a1 + 16))(v18, a1, &v15);
      if (v18[0]) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v18);
      }
      if (v25)
      {
        unint64_t v4 = __p;
        if (__p)
        {
          uint64_t v5 = v24;
          uint64_t v6 = __p;
          if (v24 != __p)
          {
            do
              uint64_t v5 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v5 - 1);
            while (v5 != v4);
            uint64_t v6 = __p;
          }
          uint64_t v24 = v4;
          operator delete(v6);
        }
        uint64_t v7 = v21;
        if (v21)
        {
          uint64_t v8 = v22;
          uint64_t v9 = v21;
          if (v22 != v21)
          {
            do
            {
              uint64_t v11 = *--v8;
              uint64_t v10 = v11;
              *uint64_t v8 = 0;
              if (v11) {
                MEMORY[0x21667D390](v10, 0x1000C8077774924);
              }
            }
            while (v8 != v7);
            uint64_t v9 = v21;
          }
          uint64_t v22 = v7;
          operator delete(v9);
        }
        if (v19 != &v20) {
          free(v19);
        }
      }
      return 0;
    }
    uint64_t v12 = (const void *)mlir::detail::DenseArrayAttrImpl<int>::operator llvm::ArrayRef<int>((uint64_t)&v17);
    if (v13) {
      memmove(v3 + 3, v12, 4 * v13);
    }
  }
  return mlir::DialectBytecodeReader::readAttribute<mlir::detail::DenseArrayAttrImpl<long long>>(a1, v3 + 1)&& mlir::DialectBytecodeReader::readAttribute<mlir::detail::DenseArrayAttrImpl<long long>>(a1, v3 + 2)&& ((unint64_t)(*(uint64_t (**)(uint64_t))(*(void *)a1 + 40))(a1) < 6|| mlir::DialectBytecodeReader::readSparseArray<int>(a1, (_DWORD *)v3 + 6, (const char *)3));
}

uint64_t mlir::OperationState::getOrAddProperties<mlir::tensor::detail::PadOpGenericAdaptorBase::Properties>(uint64_t a1)
{
  uint64_t result = *(void *)(a1 + 256);
  if (!result) {
    operator new();
  }
  return result;
}

uint64_t mlir::tensor::PadOp::writeProperties(uint64_t a1, uint64_t a2)
{
  if (HIBYTE(*(_DWORD *)(*(void *)a1 + 44))) {
    unint64_t v4 = *(void *)a1 + 16 * (((unint64_t)*(unsigned int *)(*(void *)a1 + 44) >> 23) & 1) + 64;
  }
  else {
    unint64_t v4 = 0;
  }
  (*(void (**)(uint64_t, void))(*(void *)a2 + 24))(a2, *(void *)v4);
  if ((*(uint64_t (**)(uint64_t))(*(void *)a2 + 104))(a2) <= 5)
  {
    uint64_t Context = (mlir::MLIRContext *)mlir::Attribute::getContext((mlir::Attribute *)(*(void *)a1 + 24));
    uint64_t v6 = mlir::detail::DenseArrayAttrImpl<int>::get(Context, v4 + 24, 3);
    (*(void (**)(uint64_t, uint64_t))(*(void *)a2 + 16))(a2, v6);
  }
  (*(void (**)(uint64_t, void))(*(void *)a2 + 16))(a2, *(void *)(v4 + 8));
  (*(void (**)(uint64_t, void))(*(void *)a2 + 16))(a2, *(void *)(v4 + 16));
  uint64_t result = (*(uint64_t (**)(uint64_t))(*(void *)a2 + 104))(a2);
  if (result >= 6)
  {
    return mlir::DialectBytecodeWriter::writeSparseArray<int>(a2, (int *)(v4 + 24), 3);
  }
  return result;
}

BOOL mlir::tensor::PadOp::verifyInvariantsImpl(mlir::tensor::PadOp *this)
{
  uint64_t v49 = *MEMORY[0x263EF8340];
  uint64_t v2 = *(void *)this;
  if (HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
    uint64_t v3 = (uint64_t *)(*(void *)this
  }
                   + 16 * (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 23) & 1)
                   + 64);
  else {
    uint64_t v3 = 0;
  }
  unint64_t v4 = (void *)v3[1];
  if (!v4)
  {
    v39[0] = (void **)"requires attribute 'static_high'";
    __int16 v40 = 259;
    mlir::OpState::emitOpError((uint64_t *)this, v39, (uint64_t)v41);
    uint64_t v23 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v41);
    if (v41[0]) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v41);
    }
    if (!v48) {
      return v23;
    }
    uint64_t v24 = __p;
    if (__p)
    {
      char v25 = v47;
      uint64_t v26 = __p;
      if (v47 != __p)
      {
        do
          char v25 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v25 - 1);
        while (v25 != v24);
        uint64_t v26 = __p;
      }
      uint64_t v47 = v24;
      operator delete(v26);
    }
    BOOL v27 = v44;
    if (v44)
    {
      uint64_t v28 = v45;
      long long v29 = v44;
      if (v45 == v44) {
        goto LABEL_59;
      }
      do
      {
        uint64_t v31 = *--v28;
        uint64_t v30 = v31;
        *uint64_t v28 = 0;
        if (v31) {
          MEMORY[0x21667D390](v30, 0x1000C8077774924);
        }
      }
      while (v28 != v27);
LABEL_58:
      long long v29 = v44;
LABEL_59:
      long long v45 = v27;
      operator delete(v29);
    }
LABEL_60:
    if (v42 != &v43) {
      free(v42);
    }
    return v23;
  }
  uint64_t v5 = (void *)v3[2];
  if (!v5)
  {
    v39[0] = (void **)"requires attribute 'static_low'";
    __int16 v40 = 259;
    mlir::OpState::emitOpError((uint64_t *)this, v39, (uint64_t)v41);
    uint64_t v23 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v41);
    if (v41[0]) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v41);
    }
    if (!v48) {
      return v23;
    }
    uint64_t v32 = __p;
    if (__p)
    {
      unint64_t v33 = v47;
      uint64_t v34 = __p;
      if (v47 != __p)
      {
        do
          unint64_t v33 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v33 - 1);
        while (v33 != v32);
        uint64_t v34 = __p;
      }
      uint64_t v47 = v32;
      operator delete(v34);
    }
    BOOL v27 = v44;
    if (v44)
    {
      uint64_t v35 = v45;
      long long v29 = v44;
      if (v45 == v44) {
        goto LABEL_59;
      }
      do
      {
        uint64_t v37 = *--v35;
        uint64_t v36 = v37;
        *uint64_t v35 = 0;
        if (v37) {
          MEMORY[0x21667D390](v36, 0x1000C8077774924);
        }
      }
      while (v35 != v27);
      goto LABEL_58;
    }
    goto LABEL_60;
  }
  uint64_t v6 = *v3;
  v41[0] = v2;
  if (!mlir::memref::__mlir_ods_local_attr_constraint_MemRefOps12(v5, (void **)"static_low", (const char *)0xA, (void (*)(uint64_t *__return_ptr, uint64_t))llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::__mlir_ods_local_attr_constraint_TensorOps1(mlir::Operation *,mlir::Attribute,llvm::StringRef)::$_0>, (uint64_t)v41))return 0; {
  v41[0] = *(void *)this;
  }
  if (!mlir::memref::__mlir_ods_local_attr_constraint_MemRefOps12(v4, (void **)"static_high", (const char *)0xB, (void (*)(uint64_t *__return_ptr, uint64_t))llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::__mlir_ods_local_attr_constraint_TensorOps1(mlir::Operation *,mlir::Attribute,llvm::StringRef)::$_0>, (uint64_t)v41))return 0; {
  v41[0] = *(void *)this;
  }
  if (!mlir::memref::__mlir_ods_local_attr_constraint_MemRefOps9(v6, (void **)"nofold", (const char *)6, (void (*)(uint64_t *__return_ptr, uint64_t))llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::__mlir_ods_local_attr_constraint_TensorOps2(mlir::Operation *,mlir::Attribute,llvm::StringRef)::$_0>, (uint64_t)v41))return 0; {
  unint64_t v7 = *(unsigned int *)(*(void *)this + 44);
  }
  uint64_t v8 = *(void *)this + 16 * ((v7 >> 23) & 1) + 64;
  if (!HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
    uint64_t v8 = 0;
  }
  uint64_t v9 = *(unsigned int *)(v8 + 24);
  if ((v7 & 0x800000) != 0)
  {
    uint64_t v10 = *(void *)(*(void *)this + 72);
    if (v9) {
      goto LABEL_13;
    }
  }
  else
  {
    uint64_t v10 = 0;
    if (v9)
    {
LABEL_13:
      uint64_t v11 = 0;
      uint64_t v12 = v10 + 24;
      while (mlir::tensor::__mlir_ods_local_type_constraint_TensorOps1(*(void *)this, *(void *)(*(void *)v12 + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"operand", (void **)7, v11))
      {
        ++v11;
        v12 += 32;
        if (v9 == v11) {
          goto LABEL_16;
        }
      }
      return 0;
    }
  }
LABEL_16:
  uint64_t ODSOperands = mlir::memref::ReinterpretCastOp::getODSOperands(this, 1u);
  if (v14)
  {
    uint64_t v15 = v14;
    uint64_t v16 = ODSOperands + 24;
    while (mlir::memref::__mlir_ods_local_type_constraint_MemRefOps3(*(void *)this, *(void *)(*(void *)v16 + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"operand", (void **)7, v9))
    {
      LODWORD(v9) = v9 + 1;
      v16 += 32;
      if (!--v15) {
        goto LABEL_20;
      }
    }
    return 0;
  }
LABEL_20:
  uint64_t v17 = mlir::memref::ReinterpretCastOp::getODSOperands(this, 2u);
  if (v18)
  {
    uint64_t v19 = v18;
    uint64_t v20 = v17 + 24;
    while (mlir::memref::__mlir_ods_local_type_constraint_MemRefOps3(*(void *)this, *(void *)(*(void *)v20 + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"operand", (void **)7, v9))
    {
      LODWORD(v9) = v9 + 1;
      v20 += 32;
      if (!--v19) {
        goto LABEL_24;
      }
    }
    return 0;
  }
LABEL_24:
  uint64_t v21 = *(_DWORD *)(*(void *)this + 36) ? *(void *)this - 16 : 0;
  uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v21, 0);
  if (!mlir::tensor::__mlir_ods_local_type_constraint_TensorOps1(*(void *)this, *(void *)(NextResultAtOffset + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"result", (void **)6, 0))return 0; {
  return mlir::scf::__mlir_ods_local_region_constraint_SCFOps1(*(void *)this, ((*(void *)this+ 16 * (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 23) & 1)+ (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 21) & 0x7F8)+ 71) & 0xFFFFFFFFFFFFFFF8)+ 32 * *(unsigned int *)(*(void *)this + 40), (uint64_t)"region", 6, 0) != 0;
  }
}

void mlir::tensor::PadOp::parse()
{
  v10[9] = *MEMORY[0x263EF8340];
  memset(v10, 0, 24);
  uint64_t v2 = v10;
  uint64_t v3 = 1;
  unint64_t v7 = &v9;
  uint64_t v8 = 0x400000000;
  uint64_t v0 = 0;
  uint64_t v1 = 0;
  unint64_t v4 = &v6;
  uint64_t v5 = 0x400000000;
  operator new();
}

void mlir::tensor::PadOp::print(mlir::tensor::PadOp *this, mlir::OpAsmPrinter *a2)
{
  unint64_t v75[2] = *MEMORY[0x263EF8340];
  unint64_t v4 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v5 = (unsigned char *)*((void *)v4 + 4);
  if ((unint64_t)v5 >= *((void *)v4 + 3))
  {
    llvm::raw_ostream::write(v4, 32);
  }
  else
  {
    *((void *)v4 + 4) = v5 + 1;
    unsigned char *v5 = 32;
  }
  (*(void (**)(mlir::OpAsmPrinter *, void))(*(void *)a2 + 160))(a2, *(void *)(*(void *)(*(void *)this + 72) + 24));
  if (*(void *)(*(void *)this + 16 * (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 23) & 1) + 64))
  {
    uint64_t v6 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
    unint64_t v7 = (unsigned char *)*((void *)v6 + 4);
    if ((unint64_t)v7 >= *((void *)v6 + 3))
    {
      llvm::raw_ostream::write(v6, 32);
    }
    else
    {
      *((void *)v6 + 4) = v7 + 1;
      *unint64_t v7 = 32;
    }
    uint64_t v8 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
    uint64_t v9 = *((void *)v8 + 4);
    if ((unint64_t)(*((void *)v8 + 3) - v9) > 5)
    {
      *(_WORD *)(v9 + 4) = 25708;
      *(_DWORD *)uint64_t v9 = 1868984174;
      *((void *)v8 + 4) += 6;
    }
    else
    {
      llvm::raw_ostream::write(v8, "nofold", 6uLL);
    }
  }
  uint64_t v10 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v11 = (unsigned char *)*((void *)v10 + 4);
  if ((unint64_t)v11 >= *((void *)v10 + 3))
  {
    llvm::raw_ostream::write(v10, 32);
  }
  else
  {
    *((void *)v10 + 4) = v11 + 1;
    *uint64_t v11 = 32;
  }
  uint64_t v12 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v13 = *((void *)v12 + 4);
  if ((unint64_t)(*((void *)v12 + 3) - v13) > 2)
  {
    *(unsigned char *)(v13 + 2) = 119;
    *(_WORD *)uint64_t v13 = 28524;
    *((void *)v12 + 4) += 3;
  }
  else
  {
    llvm::raw_ostream::write(v12, "low", 3uLL);
  }
  uint64_t v14 = *(void *)this;
  unint64_t v15 = *(unsigned int *)(*(void *)this + 44);
  uint64_t v16 = *(void *)this + 16 * ((v15 >> 23) & 1) + 64;
  if (!HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
    uint64_t v16 = 0;
  }
  uint64_t v17 = *(unsigned int *)(v16 + 24);
  if ((v15 & 0x800000) != 0) {
    uint64_t v18 = *(void *)(v14 + 72);
  }
  else {
    uint64_t v18 = 0;
  }
  uint64_t v19 = v18 + 32 * v17;
  uint64_t v20 = (*(_DWORD *)(v16 + 28) + v17) - v17;
  unint64_t AttrDictionary = *(void **)(v16 + 16);
  uint64_t v21 = (unint64_t *)mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)&AttrDictionary);
  uint64_t v23 = v22;
  mlir::ValueRange::ValueRange(v75, 0, 0);
  mlir::printDynamicIndexList((uint64_t)a2, v14, v19, v20, v21, v23, v75[0], v75[1], 0, 0, 2);
  uint64_t v24 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  char v25 = (unsigned char *)*((void *)v24 + 4);
  if ((unint64_t)v25 >= *((void *)v24 + 3))
  {
    llvm::raw_ostream::write(v24, 32);
  }
  else
  {
    *((void *)v24 + 4) = v25 + 1;
    unsigned char *v25 = 32;
  }
  uint64_t v26 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  BOOL v27 = (_DWORD *)*((void *)v26 + 4);
  if (*((void *)v26 + 3) - (void)v27 > 3uLL)
  {
    _DWORD *v27 = 1751607656;
    *((void *)v26 + 4) += 4;
  }
  else
  {
    llvm::raw_ostream::write(v26, "high", 4uLL);
  }
  uint64_t v28 = *(void *)this;
  unint64_t v29 = *(unsigned int *)(*(void *)this + 44);
  uint64_t v30 = *(void *)this + 16 * ((v29 >> 23) & 1) + 64;
  if (!HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
    uint64_t v30 = 0;
  }
  if ((v29 & 0x800000) != 0) {
    uint64_t v31 = *(void *)(v28 + 72);
  }
  else {
    uint64_t v31 = 0;
  }
  uint64_t v32 = (*(_DWORD *)(v30 + 28) + *(_DWORD *)(v30 + 24));
  uint64_t v33 = v31 + 32 * v32;
  uint64_t v34 = (*(_DWORD *)(v30 + 32) + v32) - v32;
  unint64_t AttrDictionary = *(void **)(v30 + 8);
  uint64_t v35 = (unint64_t *)mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)&AttrDictionary);
  uint64_t v37 = v36;
  mlir::ValueRange::ValueRange(v74, 0, 0);
  mlir::printDynamicIndexList((uint64_t)a2, v28, v33, v34, v35, v37, v74[0], v74[1], 0, 0, 2);
  __int16 v38 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v39 = (unsigned char *)*((void *)v38 + 4);
  if ((unint64_t)v39 >= *((void *)v38 + 3))
  {
    llvm::raw_ostream::write(v38, 32);
  }
  else
  {
    *((void *)v38 + 4) = v39 + 1;
    *uint64_t v39 = 32;
  }
  __int16 v40 = (void *)(((*(void *)this
                   + 16 * (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 23) & 1)
                   + (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 21) & 0x7F8)
                   + 71) & 0xFFFFFFFFFFFFFFF8)
                 + 32 * *(unsigned int *)(*(void *)this + 40));
  if ((void *)*v40 == v40
    || ((v41 = v40[1]) != 0 ? (unint64_t v42 = (ZinIrHalH13g **)(v41 - 8)) : (unint64_t v42 = 0),
        (mlir::Block::getTerminator(v42), !v43)
     || (uint64_t v44 = v43,
         unint64_t AttrDictionary = (void *)mlir::Operation::getAttrDictionary(v43),
         mlir::AffineBinaryOpExpr::getLHS((mlir::AffineBinaryOpExpr *)&AttrDictionary))
     || (*((unsigned char *)v44 + 46) & 0x80) != 0 && *((_DWORD *)v44 + 17)))
  {
    BOOL v45 = 1;
    uint64_t v46 = *(void *)this;
    unint64_t v47 = *(unsigned int *)(*(void *)this + 44);
    if ((v47 & 0x7FFFFF) != 0)
    {
LABEL_43:
      unint64_t v48 = ((v46 + 16 * ((v47 >> 23) & 1) + ((v47 >> 21) & 0x7F8) + 71) & 0xFFFFFFFFFFFFFFF8)
          + 32 * *(unsigned int *)(v46 + 40);
      goto LABEL_46;
    }
  }
  else
  {
    BOOL v45 = *((_DWORD *)v44 + 9) != 0;
    uint64_t v46 = *(void *)this;
    unint64_t v47 = *(unsigned int *)(*(void *)this + 44);
    if ((v47 & 0x7FFFFF) != 0) {
      goto LABEL_43;
    }
  }
  unint64_t v48 = 0;
LABEL_46:
  (*(void (**)(mlir::OpAsmPrinter *, unint64_t, uint64_t, BOOL, void))(*(void *)a2 + 224))(a2, v48, 1, v45, 0);
  unint64_t AttrDictionary = v73;
  v73[0] = "operandSegmentSizes";
  v73[1] = 19;
  v73[2] = "nofold";
  v73[3] = 6;
  uint64_t v72 = 0x200000002;
  llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&AttrDictionary, v73, 3uLL, 16);
  uint64_t v49 = (char *)AttrDictionary + 16 * v72;
  *uint64_t v49 = "static_low";
  v49[1] = 10;
  uint64_t v50 = (v72 + 1);
  LODWORD(v72) = v50;
  if (v50 >= HIDWORD(v72))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&AttrDictionary, v73, v50 + 1, 16);
    LODWORD(v50) = v72;
  }
  uint64_t v51 = (char *)AttrDictionary + 16 * v50;
  *uint64_t v51 = "static_high";
  v51[1] = 11;
  LODWORD(v72) = v72 + 1;
  mlir::Attribute::getContext((mlir::Attribute *)(*(void *)this + 24));
  uint64_t v52 = *(mlir::Operation **)this;
  if (*(unsigned char *)(*(void *)this + 47))
  {
    unint64_t v70 = mlir::Operation::getAttrDictionary(v52);
    uint64_t v53 = (mlir::ArrayAttr *)&v70;
  }
  else
  {
    uint64_t v53 = (mlir::Operation *)((char *)v52 + 56);
  }
  uint64_t Value = mlir::ArrayAttr::getValue(v53);
  (*(void (**)(mlir::OpAsmPrinter *, uint64_t, uint64_t, void *, void))(*(void *)a2 + 192))(a2, Value, v55, AttrDictionary, v72);
  __int16 v56 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v57 = (unsigned char *)*((void *)v56 + 4);
  if ((unint64_t)v57 >= *((void *)v56 + 3))
  {
    llvm::raw_ostream::write(v56, 32);
  }
  else
  {
    *((void *)v56 + 4) = v57 + 1;
    *uint64_t v57 = 32;
  }
  uint64_t v58 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  long long v59 = (unsigned char *)*((void *)v58 + 4);
  if (*((unsigned char **)v58 + 3) == v59)
  {
    llvm::raw_ostream::write(v58, ":", 1uLL);
  }
  else
  {
    *long long v59 = 58;
    ++*((void *)v58 + 4);
  }
  uint64_t v60 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v61 = (unsigned char *)*((void *)v60 + 4);
  if ((unint64_t)v61 >= *((void *)v60 + 3))
  {
    llvm::raw_ostream::write(v60, 32);
  }
  else
  {
    *((void *)v60 + 4) = v61 + 1;
    unsigned char *v61 = 32;
  }
  (*(void (**)(mlir::OpAsmPrinter *, unint64_t))(*(void *)a2 + 32))(a2, *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8);
  unsigned int v62 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v63 = (unsigned char *)*((void *)v62 + 4);
  if ((unint64_t)v63 >= *((void *)v62 + 3))
  {
    llvm::raw_ostream::write(v62, 32);
  }
  else
  {
    *((void *)v62 + 4) = v63 + 1;
    *uint64_t v63 = 32;
  }
  uint64_t v64 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v65 = (_WORD *)*((void *)v64 + 4);
  if (*((void *)v64 + 3) - (void)v65 > 1uLL)
  {
    *uint64_t v65 = 28532;
    *((void *)v64 + 4) += 2;
  }
  else
  {
    llvm::raw_ostream::write(v64, "to", 2uLL);
  }
  unint64_t v66 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  unint64_t v67 = (unsigned char *)*((void *)v66 + 4);
  if ((unint64_t)v67 >= *((void *)v66 + 3))
  {
    llvm::raw_ostream::write(v66, 32);
  }
  else
  {
    *((void *)v66 + 4) = v67 + 1;
    *unint64_t v67 = 32;
  }
  if (*(_DWORD *)(*(void *)this + 36)) {
    uint64_t v68 = *(void *)this - 16;
  }
  else {
    uint64_t v68 = 0;
  }
  uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v68, 0);
  (*(void (**)(mlir::OpAsmPrinter *, unint64_t))(*(void *)a2 + 32))(a2, *(void *)(NextResultAtOffset + 8) & 0xFFFFFFFFFFFFFFF8);
  if (AttrDictionary != v73) {
    free(AttrDictionary);
  }
}

uint64_t mlir::tensor::ParallelInsertSliceOp::getDest(mlir::tensor::ParallelInsertSliceOp *this)
{
  if (*(unsigned char *)(*(void *)this + 47)) {
    uint64_t v1 = *(void *)this + 80;
  }
  else {
    uint64_t v1 = 0;
  }
  return *(void *)(*(void *)(*(void *)this + 72) + 32 * *(unsigned int *)(v1 + 24) + 24);
}

uint64_t mlir::tensor::ParallelInsertSliceOp::getInherentAttr(mlir::MLIRContext *a1, uint64_t *a2, char *__s1, size_t __n)
{
  uint64_t result = 0;
  switch(__n)
  {
    case 0xCuLL:
      if (memcmp(__s1, "static_sizes", __n)) {
        goto LABEL_11;
      }
      return a2[1];
    case 0xDuLL:
    case 0xFuLL:
    case 0x10uLL:
    case 0x11uLL:
    case 0x12uLL:
    case 0x14uLL:
      goto LABEL_11;
    case 0xEuLL:
      if (*(void *)__s1 == 0x6F5F636974617473 && *(void *)(__s1 + 6) == 0x7374657366666F5FLL)
      {
        uint64_t result = *a2;
      }
      else if (!memcmp(__s1, "static_strides", __n))
      {
        uint64_t result = a2[2];
      }
      else
      {
LABEL_11:
        uint64_t result = 0;
      }
      break;
    case 0x13uLL:
      if (memcmp(__s1, "operandSegmentSizes", __n)) {
        goto LABEL_11;
      }
      goto LABEL_13;
    case 0x15uLL:
      if (memcmp(__s1, "operand_segment_sizes", __n)) {
        goto LABEL_11;
      }
LABEL_13:
      uint64_t result = mlir::detail::DenseArrayAttrImpl<int>::get(a1, (uint64_t)(a2 + 3), 5);
      break;
    default:
      return result;
  }
  return result;
}

uint64_t mlir::tensor::ParallelInsertSliceOp::setInherentAttr(uint64_t result, char *__s1, size_t a3, void *a4)
{
  uint64_t v5 = (void *)result;
  switch(a3)
  {
    case 0xCuLL:
      uint64_t result = memcmp(__s1, "static_sizes", a3);
      if (!result)
      {
        if (a4)
        {
          uint64_t result = mlir::detail::DenseArrayAttrImpl<long long>::classof(a4);
          if (result) {
            uint64_t v10 = a4;
          }
          else {
            uint64_t v10 = 0;
          }
          v5[1] = v10;
        }
        else
        {
          v5[1] = 0;
        }
      }
      break;
    case 0xEuLL:
      if (*(void *)__s1 == 0x6F5F636974617473 && *(void *)(__s1 + 6) == 0x7374657366666F5FLL)
      {
        if (a4)
        {
          uint64_t result = mlir::detail::DenseArrayAttrImpl<long long>::classof(a4);
          if (result) {
            uint64_t v11 = a4;
          }
          else {
            uint64_t v11 = 0;
          }
          void *v5 = v11;
        }
        else
        {
          *(void *)uint64_t result = 0;
        }
      }
      else
      {
        uint64_t result = memcmp(__s1, "static_strides", a3);
        if (!result)
        {
          if (a4)
          {
            uint64_t result = mlir::detail::DenseArrayAttrImpl<long long>::classof(a4);
            if (result) {
              unint64_t v7 = a4;
            }
            else {
              unint64_t v7 = 0;
            }
            v5[2] = v7;
          }
          else
          {
            v5[2] = 0;
          }
        }
      }
      break;
    case 0x13uLL:
      uint64_t result = memcmp(__s1, "operandSegmentSizes", a3);
      if (!result) {
        goto LABEL_17;
      }
      break;
    case 0x15uLL:
      uint64_t result = memcmp(__s1, "operand_segment_sizes", a3);
      if (!result)
      {
LABEL_17:
        if (a4)
        {
          uint64_t result = mlir::detail::DenseArrayAttrImpl<int>::classof(a4);
          uint64_t v8 = result ? a4 : 0;
          uint64_t v12 = v8;
          if (result)
          {
            uint64_t result = mlir::AffineBinaryOpExpr::getLHS((mlir::AffineBinaryOpExpr *)&v12);
            if (result == 5)
            {
              uint64_t result = mlir::detail::DenseArrayAttrImpl<int>::operator llvm::ArrayRef<int>((uint64_t)&v12);
              if (v9) {
                uint64_t result = (uint64_t)memmove(v5 + 3, (const void *)result, 4 * v9);
              }
            }
          }
        }
      }
      break;
    default:
      return result;
  }
  return result;
}

BOOL mlir::tensor::ParallelInsertSliceOp::readProperties(uint64_t a1, uint64_t a2)
{
  uint64_t v26 = *MEMORY[0x263EF8340];
  uint64_t v3 = (void *)mlir::OperationState::getOrAddProperties<mlir::tensor::detail::ParallelInsertSliceOpGenericAdaptorBase::Properties>(a2);
  if ((unint64_t)(*(uint64_t (**)(uint64_t))(*(void *)a1 + 40))(a1) <= 5)
  {
    uint64_t v17 = 0;
    if (!mlir::DialectBytecodeReader::readAttribute<mlir::detail::DenseArrayAttrImpl<int>>(a1, &v17)) {
      return 0;
    }
    if (mlir::AffineBinaryOpExpr::getLHS((mlir::AffineBinaryOpExpr *)&v17) >= 6)
    {
      unint64_t v15 = "size mismatch for operand/result_segment_size";
      __int16 v16 = 259;
      (*(void (**)(void *__return_ptr, uint64_t, const char **))(*(void *)a1 + 16))(v18, a1, &v15);
      if (v18[0]) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v18);
      }
      if (v25)
      {
        unint64_t v4 = __p;
        if (__p)
        {
          uint64_t v5 = v24;
          uint64_t v6 = __p;
          if (v24 != __p)
          {
            do
              uint64_t v5 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v5 - 1);
            while (v5 != v4);
            uint64_t v6 = __p;
          }
          uint64_t v24 = v4;
          operator delete(v6);
        }
        unint64_t v7 = v21;
        if (v21)
        {
          uint64_t v8 = v22;
          uint64_t v9 = v21;
          if (v22 != v21)
          {
            do
            {
              uint64_t v11 = *--v8;
              uint64_t v10 = v11;
              *uint64_t v8 = 0;
              if (v11) {
                MEMORY[0x21667D390](v10, 0x1000C8077774924);
              }
            }
            while (v8 != v7);
            uint64_t v9 = v21;
          }
          uint64_t v22 = v7;
          operator delete(v9);
        }
        if (v19 != &v20) {
          free(v19);
        }
      }
      return 0;
    }
    uint64_t v12 = (const void *)mlir::detail::DenseArrayAttrImpl<int>::operator llvm::ArrayRef<int>((uint64_t)&v17);
    if (v13) {
      memmove(v3 + 3, v12, 4 * v13);
    }
  }
  return mlir::DialectBytecodeReader::readAttribute<mlir::detail::DenseArrayAttrImpl<long long>>(a1, v3)&& mlir::DialectBytecodeReader::readAttribute<mlir::detail::DenseArrayAttrImpl<long long>>(a1, v3 + 1)&& mlir::DialectBytecodeReader::readAttribute<mlir::detail::DenseArrayAttrImpl<long long>>(a1, v3 + 2)&& ((unint64_t)(*(uint64_t (**)(uint64_t))(*(void *)a1 + 40))(a1) < 6|| mlir::DialectBytecodeReader::readSparseArray<int>(a1, (_DWORD *)v3 + 6, (const char *)5));
}

uint64_t mlir::OperationState::getOrAddProperties<mlir::tensor::detail::ParallelInsertSliceOpGenericAdaptorBase::Properties>(uint64_t a1)
{
  uint64_t result = *(void *)(a1 + 256);
  if (!result) {
    operator new();
  }
  return result;
}

uint64_t mlir::tensor::ParallelInsertSliceOp::verifyInvariantsImpl(mlir::tensor::ParallelInsertSliceOp *this)
{
  uint64_t v61 = *MEMORY[0x263EF8340];
  uint64_t v2 = *(void *)this;
  if (HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
    unint64_t v3 = *(void *)this + 16 * (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 23) & 1) + 64;
  }
  else {
    unint64_t v3 = 0;
  }
  unint64_t v4 = *(void **)v3;
  if (*(void *)v3)
  {
    uint64_t v5 = *(void **)(v3 + 8);
    if (v5)
    {
      uint64_t v6 = *(void **)(v3 + 16);
      if (v6)
      {
        v53[0] = v2;
        if (!mlir::memref::__mlir_ods_local_attr_constraint_MemRefOps12(v4, (void **)"static_offsets", (const char *)0xE, (void (*)(uint64_t *__return_ptr, uint64_t))llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::__mlir_ods_local_attr_constraint_TensorOps1(mlir::Operation *,mlir::Attribute,llvm::StringRef)::$_0>, (uint64_t)v53))return 0; {
        v53[0] = *(void *)this;
        }
        if (!mlir::memref::__mlir_ods_local_attr_constraint_MemRefOps12(v5, (void **)"static_sizes", (const char *)0xC, (void (*)(uint64_t *__return_ptr, uint64_t))llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::__mlir_ods_local_attr_constraint_TensorOps1(mlir::Operation *,mlir::Attribute,llvm::StringRef)::$_0>, (uint64_t)v53))return 0; {
        v53[0] = *(void *)this;
        }
        if (!mlir::memref::__mlir_ods_local_attr_constraint_MemRefOps12(v6, (void **)"static_strides", (const char *)0xE, (void (*)(uint64_t *__return_ptr, uint64_t))llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::__mlir_ods_local_attr_constraint_TensorOps1(mlir::Operation *,mlir::Attribute,llvm::StringRef)::$_0>, (uint64_t)v53))return 0; {
        unint64_t v7 = *(unsigned int *)(*(void *)this + 44);
        }
        uint64_t v8 = *(void *)this + 16 * ((v7 >> 23) & 1) + 64;
        if (!HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
          uint64_t v8 = 0;
        }
        uint64_t v9 = *(unsigned int *)(v8 + 24);
        if ((v7 & 0x800000) != 0)
        {
          uint64_t v10 = *(void *)(*(void *)this + 72);
          if (v9) {
            goto LABEL_14;
          }
        }
        else
        {
          uint64_t v10 = 0;
          if (v9)
          {
LABEL_14:
            uint64_t v11 = 0;
            uint64_t v12 = v10 + 24;
            while (mlir::tensor::__mlir_ods_local_type_constraint_TensorOps1(*(void *)this, *(void *)(*(void *)v12 + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"operand", (void **)7, v11))
            {
              ++v11;
              v12 += 32;
              if (v9 == v11) {
                goto LABEL_17;
              }
            }
            return 0;
          }
        }
LABEL_17:
        uint64_t ODSOperands = mlir::memref::ReinterpretCastOp::getODSOperands(this, 1u);
        if (v14)
        {
          uint64_t v15 = v14;
          uint64_t v16 = ODSOperands + 24;
          while (mlir::tensor::__mlir_ods_local_type_constraint_TensorOps1(*(void *)this, *(void *)(*(void *)v16 + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"operand", (void **)7, v9))
          {
            LODWORD(v9) = v9 + 1;
            v16 += 32;
            if (!--v15) {
              goto LABEL_21;
            }
          }
        }
        else
        {
LABEL_21:
          uint64_t v17 = mlir::memref::ReinterpretCastOp::getODSOperands(this, 2u);
          if (v18)
          {
            uint64_t v19 = v18;
            uint64_t v20 = v17 + 24;
            while (mlir::memref::__mlir_ods_local_type_constraint_MemRefOps3(*(void *)this, *(void *)(*(void *)v20 + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"operand", (void **)7, v9))
            {
              LODWORD(v9) = v9 + 1;
              v20 += 32;
              if (!--v19) {
                goto LABEL_25;
              }
            }
          }
          else
          {
LABEL_25:
            uint64_t v21 = mlir::memref::ReinterpretCastOp::getODSOperands(this, 3u);
            if (v22)
            {
              uint64_t v23 = v22;
              uint64_t v24 = v21 + 24;
              while (mlir::memref::__mlir_ods_local_type_constraint_MemRefOps3(*(void *)this, *(void *)(*(void *)v24 + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"operand", (void **)7, v9))
              {
                LODWORD(v9) = v9 + 1;
                v24 += 32;
                if (!--v23) {
                  goto LABEL_29;
                }
              }
            }
            else
            {
LABEL_29:
              uint64_t v25 = mlir::memref::ReinterpretCastOp::getODSOperands(this, 4u);
              if (!v26) {
                return 1;
              }
              uint64_t v27 = v26;
              uint64_t v28 = v25 + 24;
              uint64_t v29 = 1;
              while (mlir::memref::__mlir_ods_local_type_constraint_MemRefOps3(*(void *)this, *(void *)(*(void *)v28 + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"operand", (void **)7, v9))
              {
                LODWORD(v9) = v9 + 1;
                v28 += 32;
                if (!--v27) {
                  return v29;
                }
              }
            }
          }
        }
        return 0;
      }
      v51[0] = (void **)"requires attribute 'static_strides'";
      __int16 v52 = 259;
      mlir::OpState::emitOpError((uint64_t *)this, v51, (uint64_t)v53);
      uint64_t v29 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v53);
      if (v53[0]) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v53);
      }
      if (v60)
      {
        uint64_t v44 = __p;
        if (__p)
        {
          BOOL v45 = v59;
          uint64_t v46 = __p;
          if (v59 != __p)
          {
            do
              BOOL v45 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v45 - 1);
            while (v45 != v44);
            uint64_t v46 = __p;
          }
          long long v59 = v44;
          operator delete(v46);
        }
        uint64_t v33 = v56;
        if (!v56) {
          goto LABEL_79;
        }
        unint64_t v47 = v57;
        uint64_t v35 = v56;
        if (v57 == v56)
        {
LABEL_78:
          uint64_t v57 = v33;
          operator delete(v35);
LABEL_79:
          if (v54 != &v55) {
            free(v54);
          }
          return v29;
        }
        do
        {
          uint64_t v49 = *--v47;
          uint64_t v48 = v49;
          *unint64_t v47 = 0;
          if (v49) {
            MEMORY[0x21667D390](v48, 0x1000C8077774924);
          }
        }
        while (v47 != v33);
LABEL_77:
        uint64_t v35 = v56;
        goto LABEL_78;
      }
    }
    else
    {
      v51[0] = (void **)"requires attribute 'static_sizes'";
      __int16 v52 = 259;
      mlir::OpState::emitOpError((uint64_t *)this, v51, (uint64_t)v53);
      uint64_t v29 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v53);
      if (v53[0]) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v53);
      }
      if (v60)
      {
        __int16 v38 = __p;
        if (__p)
        {
          uint64_t v39 = v59;
          __int16 v40 = __p;
          if (v59 != __p)
          {
            do
              uint64_t v39 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v39 - 1);
            while (v39 != v38);
            __int16 v40 = __p;
          }
          long long v59 = v38;
          operator delete(v40);
        }
        uint64_t v33 = v56;
        if (!v56) {
          goto LABEL_79;
        }
        uint64_t v41 = v57;
        uint64_t v35 = v56;
        if (v57 == v56) {
          goto LABEL_78;
        }
        do
        {
          uint64_t v43 = *--v41;
          uint64_t v42 = v43;
          *uint64_t v41 = 0;
          if (v43) {
            MEMORY[0x21667D390](v42, 0x1000C8077774924);
          }
        }
        while (v41 != v33);
        goto LABEL_77;
      }
    }
  }
  else
  {
    v51[0] = (void **)"requires attribute 'static_offsets'";
    __int16 v52 = 259;
    mlir::OpState::emitOpError((uint64_t *)this, v51, (uint64_t)v53);
    uint64_t v29 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v53);
    if (v53[0]) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v53);
    }
    if (v60)
    {
      uint64_t v30 = __p;
      if (__p)
      {
        uint64_t v31 = v59;
        uint64_t v32 = __p;
        if (v59 != __p)
        {
          do
            uint64_t v31 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v31 - 1);
          while (v31 != v30);
          uint64_t v32 = __p;
        }
        long long v59 = v30;
        operator delete(v32);
      }
      uint64_t v33 = v56;
      if (!v56) {
        goto LABEL_79;
      }
      uint64_t v34 = v57;
      uint64_t v35 = v56;
      if (v57 == v56) {
        goto LABEL_78;
      }
      do
      {
        uint64_t v37 = *--v34;
        uint64_t v36 = v37;
        *uint64_t v34 = 0;
        if (v37) {
          MEMORY[0x21667D390](v36, 0x1000C8077774924);
        }
      }
      while (v34 != v33);
      goto LABEL_77;
    }
  }
  return v29;
}

uint64_t mlir::tensor::ParallelInsertSliceOp::parse(uint64_t a1, uint64_t a2)
{
  v49[4] = *MEMORY[0x263EF8340];
  memset(v49, 0, 24);
  v34[0] = (uint64_t)v49;
  v34[1] = 1;
  memset(v48, 0, 24);
  v33[0] = (uint64_t)v48;
  v33[1] = 1;
  BOOL v45 = v47;
  uint64_t v46 = 0x400000000;
  uint64_t v31 = 0;
  uint64_t v32 = 0;
  uint64_t v42 = v44;
  uint64_t v43 = 0x400000000;
  uint64_t v38 = 0;
  uint64_t v39 = v41;
  uint64_t v40 = 0x400000000;
  v29[1] = 1;
  uint64_t v30 = 0;
  v28[1] = 1;
  v29[0] = &v38;
  uint64_t v37 = 0;
  v28[0] = &v37;
  uint64_t v4 = (*(uint64_t (**)(uint64_t))(*(void *)a1 + 40))(a1);
  if (!(*(unsigned __int8 (**)(uint64_t, void *, uint64_t))(*(void *)a1 + 672))(a1, v49, 1)) {
    goto LABEL_28;
  }
  __int16 v36 = 257;
  if (!(*(unsigned __int8 (**)(uint64_t, const char *, uint64_t, uint64_t *))(*(void *)a1 + 368))(a1, "into", 4, v35))goto LABEL_28; {
  uint64_t v5 = (*(uint64_t (**)(uint64_t))(*(void *)a1 + 40))(a1);
  }
  if (!(*(unsigned __int8 (**)(uint64_t, void *, uint64_t))(*(void *)a1 + 672))(a1, v48, 1)) {
    goto LABEL_28;
  }
  (*(void (**)(uint64_t))(*(void *)a1 + 40))(a1);
  v35[0] = 0;
  if (!mlir::parseDynamicIndexList(a1, (uint64_t)&v45, &v32, v35, 0)) {
    goto LABEL_28;
  }
  uint64_t v6 = (void *)mlir::OperationState::getOrAddProperties<mlir::tensor::detail::ParallelInsertSliceOpGenericAdaptorBase::Properties>(a2);
  void *v6 = v32;
  (*(void (**)(uint64_t))(*(void *)a1 + 40))(a1);
  v35[0] = 0;
  if (!mlir::parseDynamicIndexList(a1, (uint64_t)&v42, &v31, v35, 0)) {
    goto LABEL_28;
  }
  uint64_t v7 = mlir::OperationState::getOrAddProperties<mlir::tensor::detail::ParallelInsertSliceOpGenericAdaptorBase::Properties>(a2);
  *(void *)(v7 + 8) = v31;
  (*(void (**)(uint64_t))(*(void *)a1 + 40))(a1);
  v35[0] = 0;
  if (!mlir::parseDynamicIndexList(a1, (uint64_t)&v39, &v30, v35, 0)) {
    goto LABEL_28;
  }
  uint64_t v8 = mlir::OperationState::getOrAddProperties<mlir::tensor::detail::ParallelInsertSliceOpGenericAdaptorBase::Properties>(a2);
  *(void *)(v8 + 16) = v30;
  uint64_t v27 = (*(uint64_t (**)(uint64_t))(*(void *)a1 + 40))(a1);
  if (!(*(unsigned __int8 (**)(uint64_t, uint64_t))(*(void *)a1 + 456))(a1, a2 + 112)) {
    goto LABEL_28;
  }
  uint64_t v9 = *(void *)(a2 + 8);
  v35[0] = a1;
  v35[1] = (uint64_t)&v27;
  void v35[2] = a2;
  if (!mlir::memref::ReinterpretCastOp::verifyInherentAttrs(v9, a2 + 112, (void (*)(uint64_t *__return_ptr, uint64_t))llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::ParallelInsertSliceOp::parse(mlir::OpAsmParser &,mlir::OperationState &)::$_0>, (uint64_t)v35))goto LABEL_28; {
  if (!(*(unsigned __int8 (**)(uint64_t))(*(void *)a1 + 104))(a1))
  }
    goto LABEL_28;
  v35[0] = 0;
  if (!mlir::AsmParser::parseType<mlir::RankedTensorType>(a1, v35)) {
    goto LABEL_28;
  }
  uint64_t v38 = v35[0];
  __int16 v36 = 257;
  if (!(*(unsigned __int8 (**)(uint64_t, const char *, uint64_t, uint64_t *))(*(void *)a1 + 368))(a1, "into", 4, v35))goto LABEL_28; {
  v35[0] = 0;
  }
  if (!mlir::AsmParser::parseType<mlir::RankedTensorType>(a1, v35)) {
    goto LABEL_28;
  }
  uint64_t v37 = v35[0];
  int v10 = v46;
  int v11 = v43;
  int v12 = v40;
  uint64_t v13 = mlir::OperationState::getOrAddProperties<mlir::tensor::detail::ParallelInsertSliceOpGenericAdaptorBase::Properties>(a2);
  *(void *)(v13 + 24) = 0x100000001;
  *(_DWORD *)(v13 + 32) = v10;
  *(_DWORD *)(v13 + 36) = v11;
  *(_DWORD *)(v13 + 40) = v12;
  uint64_t v14 = (mlir::IndexType **)(*(uint64_t (**)(uint64_t))(*(void *)a1 + 32))(a1);
  uint64_t IndexType = mlir::Builder::getIndexType(v14, v15);
  uint64_t v17 = a2 + 16;
  if (!mlir::OpAsmParser::resolveOperands<llvm::ArrayRef<mlir::OpAsmParser::UnresolvedOperand> &,llvm::ArrayRef<mlir::Type> &>(a1, v34, v29, v4, v17)|| !mlir::OpAsmParser::resolveOperands<llvm::ArrayRef<mlir::OpAsmParser::UnresolvedOperand> &,llvm::ArrayRef<mlir::Type> &>(a1, v33, v28, v5, v17))
  {
    goto LABEL_28;
  }
  if (v46)
  {
    uint64_t v18 = (char *)v45;
    uint64_t v19 = 32 * v46;
    while ((*(unsigned __int8 (**)(uint64_t, char *, uint64_t, uint64_t))(*(void *)a1 + 696))(a1, v18, IndexType, v17))
    {
      v18 += 32;
      v19 -= 32;
      if (!v19) {
        goto LABEL_19;
      }
    }
LABEL_28:
    uint64_t v24 = 0;
LABEL_29:
    uint64_t v25 = v39;
    if (v39 != v41) {
      goto LABEL_30;
    }
    goto LABEL_31;
  }
LABEL_19:
  if (v43)
  {
    uint64_t v20 = (char *)v42;
    uint64_t v21 = 32 * v43;
    while ((*(unsigned __int8 (**)(uint64_t, char *, uint64_t, uint64_t))(*(void *)a1 + 696))(a1, v20, IndexType, v17))
    {
      v20 += 32;
      v21 -= 32;
      if (!v21) {
        goto LABEL_23;
      }
    }
    goto LABEL_28;
  }
LABEL_23:
  if (v40)
  {
    uint64_t v22 = (char *)v39;
    uint64_t v23 = 32 * v40;
    uint64_t v24 = 1;
    while ((*(unsigned __int8 (**)(uint64_t, char *, uint64_t, uint64_t))(*(void *)a1 + 696))(a1, v22, IndexType, v17))
    {
      v22 += 32;
      v23 -= 32;
      if (!v23) {
        goto LABEL_29;
      }
    }
    goto LABEL_28;
  }
  uint64_t v24 = 1;
  uint64_t v25 = v39;
  if (v39 != v41) {
LABEL_30:
  }
    free(v25);
LABEL_31:
  if (v42 != v44) {
    free(v42);
  }
  if (v45 != v47) {
    free(v45);
  }
  return v24;
}

uint64_t mlir::tensor::detail::RankOpGenericAdaptorBase::RankOpGenericAdaptorBase(uint64_t a1, mlir::Operation *this)
{
  uint64_t v11 = *MEMORY[0x263EF8340];
  unint64_t AttrDictionary = mlir::Operation::getAttrDictionary(this);
  unint64_t v5 = *((unsigned int *)this + 11);
  unint64_t v6 = v5 & 0x7FFFFF;
  if ((v5 & 0x7FFFFF) != 0)
  {
    uint64_t v7 = (((unint64_t)this + 16 * ((v5 >> 23) & 1) + ((v5 >> 21) & 0x7F8) + 71) & 0xFFFFFFFFFFFFFFF8)
       + 32 * *((unsigned int *)this + 10);
  }
  else
  {
    uint64_t v7 = 0;
    unint64_t v6 = 0;
  }
  mlir::ValueRange::ValueRange(v10, v7, v6);
  *(void *)a1 = AttrDictionary;
  *(unsigned char *)(a1 + 8) = 0;
  *(unsigned char *)(a1 + 16) = 0;
  *(_OWORD *)(a1 + 24) = *(_OWORD *)v10;
  if (AttrDictionary)
  {
    uint64_t Context = mlir::Attribute::getContext((mlir::Attribute *)a1);
    if (*(unsigned char *)(a1 + 16)) {
      *(unsigned char *)(a1 + 16) = 0;
    }
    mlir::OperationName::OperationName(a1 + 8, "tensor.rank", 11, Context);
    *(unsigned char *)(a1 + 16) = 1;
  }
  return a1;
}

BOOL mlir::tensor::RankOp::verifyInvariantsImpl(mlir::tensor::RankOp *this)
{
  if (!mlir::tensor::__mlir_ods_local_type_constraint_TensorOps0(*(void *)this, *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"operand", (void **)7, 0))return 0; {
  if (*(_DWORD *)(*(void *)this + 36))
  }
    uint64_t v2 = *(void *)this - 16;
  else {
    uint64_t v2 = 0;
  }
  uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v2, 0);
  return mlir::memref::__mlir_ods_local_type_constraint_MemRefOps9(*(void *)this, *(void *)(NextResultAtOffset + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"result", (void **)6, 0) != 0;
}

BOOL mlir::tensor::RankOp::parse(uint64_t a1, uint64_t a2)
{
  v14[4] = *MEMORY[0x263EF8340];
  memset(v14, 0, 24);
  v12[0] = (uint64_t)v14;
  v12[1] = 1;
  uint64_t v13 = 0;
  v11[0] = &v13;
  v11[1] = 1;
  uint64_t v4 = (*(uint64_t (**)(uint64_t))(*(void *)a1 + 40))(a1);
  if (!(*(unsigned __int8 (**)(uint64_t, void *, uint64_t))(*(void *)a1 + 672))(a1, v14, 1)) {
    return 0;
  }
  (*(void (**)(uint64_t))(*(void *)a1 + 40))(a1);
  if (!(*(unsigned __int8 (**)(uint64_t, uint64_t))(*(void *)a1 + 456))(a1, a2 + 112)) {
    return 0;
  }
  if (!(*(unsigned __int8 (**)(uint64_t))(*(void *)a1 + 104))(a1)) {
    return 0;
  }
  uint64_t v10 = 0;
  if (!mlir::AsmParser::parseType<mlir::TensorType>(a1, &v10)) {
    return 0;
  }
  uint64_t v13 = v10;
  unint64_t v5 = (mlir::IndexType **)(*(uint64_t (**)(uint64_t))(*(void *)a1 + 32))(a1);
  uint64_t IndexType = mlir::Builder::getIndexType(v5, v6);
  uint64_t v8 = *(unsigned int *)(a2 + 72);
  if (v8 >= *(_DWORD *)(a2 + 76))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod(a2 + 64, (void *)(a2 + 80), v8 + 1, 8);
    LODWORD(v8) = *(_DWORD *)(a2 + 72);
  }
  *(void *)(*(void *)(a2 + 64) + 8 * v8) = IndexType;
  ++*(_DWORD *)(a2 + 72);
  return mlir::OpAsmParser::resolveOperands<llvm::ArrayRef<mlir::OpAsmParser::UnresolvedOperand> &,llvm::ArrayRef<mlir::Type> &>(a1, v12, v11, v4, a2 + 16) != 0;
}

uint64_t mlir::tensor::detail::ReshapeOpGenericAdaptorBase::ReshapeOpGenericAdaptorBase(uint64_t a1, unsigned int *a2)
{
  uint64_t v11 = *MEMORY[0x263EF8340];
  unint64_t AttrDictionary = mlir::Operation::getAttrDictionary((mlir::Operation *)a2);
  unint64_t v5 = a2[11];
  unint64_t v6 = v5 & 0x7FFFFF;
  if ((v5 & 0x7FFFFF) != 0)
  {
    uint64_t v7 = (((unint64_t)&a2[4 * ((v5 >> 23) & 1) + 17] + ((v5 >> 21) & 0x7F8) + 3) & 0xFFFFFFFFFFFFFFF8)
       + 32 * a2[10];
  }
  else
  {
    uint64_t v7 = 0;
    unint64_t v6 = 0;
  }
  mlir::ValueRange::ValueRange(v10, v7, v6);
  *(void *)a1 = AttrDictionary;
  *(unsigned char *)(a1 + 8) = 0;
  *(unsigned char *)(a1 + 16) = 0;
  *(_OWORD *)(a1 + 24) = *(_OWORD *)v10;
  if (AttrDictionary)
  {
    uint64_t Context = mlir::Attribute::getContext((mlir::Attribute *)a1);
    if (*(unsigned char *)(a1 + 16)) {
      *(unsigned char *)(a1 + 16) = 0;
    }
    mlir::OperationName::OperationName(a1 + 8, "tensor.reshape", 14, Context);
    *(unsigned char *)(a1 + 16) = 1;
  }
  return a1;
}

BOOL mlir::tensor::ReshapeOp::verifyInvariantsImpl(mlir::tensor::ReshapeOp *this)
{
  uint64_t v65 = *MEMORY[0x263EF8340];
  if (!mlir::tensor::__mlir_ods_local_type_constraint_TensorOps0(*(void *)this, *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"operand", (void **)7, 0))return 0; {
  uint64_t v2 = *(void *)this;
  }
  unint64_t v3 = (void **)(*(void *)(*(void *)(*(void *)(*(void *)this + 72) + 56) + 8) & 0xFFFFFFFFFFFFFFF8);
  uint64_t v4 = *v3;
  if (*((_UNKNOWN **)*v3 + 17) != &mlir::detail::TypeIDResolver<mlir::RankedTensorType,void>::id) {
    goto LABEL_34;
  }
  v55[0] = *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 56) + 8) & 0xFFFFFFFFFFFFFFF8;
  v55[1] = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>((uint64_t)v4 + 8);
  if (!mlir::CallOpInterface::getArgOperands((mlir::CallOpInterface *)v55)) {
    goto LABEL_34;
  }
  uint64_t v5 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>((uint64_t)*v3 + 8);
  uint64_t v48 = v3;
  uint64_t v49 = v5;
  mlir::ShapedType::getShape((mlir::ShapedType *)&v48);
  if (v6 != 1
    || (uint64_t v7 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>((uint64_t)*v3 + 8),
        __int16 v52 = v3,
        uint64_t v53 = v7,
        uint64_t OperandRange = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&v52),
        !mlir::Type::isSignlessInteger((mlir::Type *)&OperandRange))
    && *(_UNKNOWN **)(*(void *)OperandRange + 136) != &mlir::detail::TypeIDResolver<mlir::IndexType,void>::id)
  {
LABEL_34:
    __int16 v50 = 261;
    uint64_t v48 = (void **)"operand";
    uint64_t v49 = 7;
    mlir::Operation::emitOpError(v2, &v48, (uint64_t)v55);
    if (v55[0])
    {
      LODWORD(v52) = 3;
      uint64_t v53 = (uint64_t)" #";
      uint64_t v54 = 2;
      uint64_t v8 = &v52;
      uint64_t v9 = (char *)v56;
      if (v57 >= v58)
      {
        unint64_t v38 = v57 + 1;
        if (v56 <= &v52 && (char *)v56 + 24 * v57 > (char *)&v52)
        {
          int64_t v44 = (char *)&v52 - (unsigned char *)v56;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v56, v59, v38, 24);
          uint64_t v9 = (char *)v56;
          uint64_t v8 = (void ***)((char *)v56 + v44);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v56, v59, v38, 24);
          uint64_t v8 = &v52;
          uint64_t v9 = (char *)v56;
        }
      }
      uint64_t v10 = &v9[24 * v57];
      long long v11 = *(_OWORD *)v8;
      *((void *)v10 + 2) = v8[2];
      *(_OWORD *)uint64_t v10 = v11;
      uint64_t v12 = ++v57;
      if (v55[0])
      {
        LODWORD(v52) = 5;
        uint64_t v53 = 1;
        uint64_t v13 = &v52;
        uint64_t v14 = (char *)v56;
        if (v12 >= v58)
        {
          unint64_t v39 = v12 + 1;
          BOOL v40 = (char *)v56 + 24 * v12 > (char *)&v52;
          if (v56 <= &v52 && v40)
          {
            int64_t v45 = (char *)&v52 - (unsigned char *)v56;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v56, v59, v39, 24);
            uint64_t v14 = (char *)v56;
            uint64_t v13 = (void ***)((char *)v56 + v45);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v56, v59, v39, 24);
            uint64_t v13 = &v52;
            uint64_t v14 = (char *)v56;
          }
        }
        uint64_t v15 = &v14[24 * v57];
        long long v16 = *(_OWORD *)v13;
        *((void *)v15 + 2) = v13[2];
        *(_OWORD *)uint64_t v15 = v16;
        uint64_t v17 = ++v57;
        if (v55[0])
        {
          LODWORD(v52) = 3;
          uint64_t v53 = (uint64_t)" must be 1D tensor of signless integer or index values, but got ";
          uint64_t v54 = 64;
          uint64_t v18 = &v52;
          uint64_t v19 = (char *)v56;
          if (v17 >= v58)
          {
            unint64_t v41 = v17 + 1;
            BOOL v42 = (char *)v56 + 24 * v17 > (char *)&v52;
            if (v56 <= &v52 && v42)
            {
              int64_t v46 = (char *)&v52 - (unsigned char *)v56;
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v56, v59, v41, 24);
              uint64_t v19 = (char *)v56;
              uint64_t v18 = (void ***)((char *)v56 + v46);
            }
            else
            {
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v56, v59, v41, 24);
              uint64_t v18 = &v52;
              uint64_t v19 = (char *)v56;
            }
          }
          uint64_t v20 = &v19[24 * v57];
          long long v21 = *(_OWORD *)v18;
          *((void *)v20 + 2) = v18[2];
          *(_OWORD *)uint64_t v20 = v21;
          ++v57;
          if (v55[0])
          {
            uint64_t v22 = &v52;
            mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v52, (uint64_t)v3);
            uint64_t v23 = (char *)v56;
            if (v57 >= v58)
            {
              unint64_t v43 = v57 + 1;
              if (v56 <= &v52 && (char *)v56 + 24 * v57 > (char *)&v52)
              {
                int64_t v47 = (char *)&v52 - (unsigned char *)v56;
                llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v56, v59, v43, 24);
                uint64_t v23 = (char *)v56;
                uint64_t v22 = (void ***)((char *)v56 + v47);
              }
              else
              {
                llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v56, v59, v43, 24);
                uint64_t v22 = &v52;
                uint64_t v23 = (char *)v56;
              }
            }
            uint64_t v24 = &v23[24 * v57];
            long long v25 = *(_OWORD *)v22;
            *((void *)v24 + 2) = v22[2];
            *(_OWORD *)uint64_t v24 = v25;
            ++v57;
          }
        }
      }
    }
    char v26 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v55);
    if (v55[0]) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v55);
    }
    if (v64)
    {
      uint64_t v27 = __p;
      if (__p)
      {
        uint64_t v28 = v63;
        uint64_t v29 = __p;
        if (v63 != __p)
        {
          do
            uint64_t v28 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v28 - 1);
          while (v28 != v27);
          uint64_t v29 = __p;
        }
        uint64_t v63 = v27;
        operator delete(v29);
      }
      uint64_t v30 = v60;
      if (v60)
      {
        uint64_t v31 = v61;
        uint64_t v32 = v60;
        if (v61 != v60)
        {
          do
          {
            uint64_t v34 = *--v31;
            uint64_t v33 = v34;
            void *v31 = 0;
            if (v34) {
              MEMORY[0x21667D390](v33, 0x1000C8077774924);
            }
          }
          while (v31 != v30);
          uint64_t v32 = v60;
        }
        uint64_t v61 = v30;
        operator delete(v32);
      }
      if (v56 != v59) {
        free(v56);
      }
    }
    if (!v26) {
      return 0;
    }
  }
  if (*(_DWORD *)(*(void *)this + 36)) {
    uint64_t v35 = *(void *)this - 16;
  }
  else {
    uint64_t v35 = 0;
  }
  uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v35, 0);
  return mlir::tensor::__mlir_ods_local_type_constraint_TensorOps0(*(void *)this, *(void *)(NextResultAtOffset + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"result", (void **)6, 0) != 0;
}

BOOL mlir::tensor::ReshapeOp::parse(uint64_t a1, uint64_t a2)
{
  v15[4] = *MEMORY[0x263EF8340];
  memset(v15, 0, 24);
  v13[0] = v15;
  v13[1] = 1;
  memset(v14, 0, 24);
  v12[0] = v14;
  v12[1] = 1;
  (*(void (**)(uint64_t))(*(void *)a1 + 40))(a1);
  if (!(*(unsigned __int8 (**)(uint64_t, void *, uint64_t))(*(void *)a1 + 672))(a1, v15, 1)) {
    return 0;
  }
  if (!(*(unsigned __int8 (**)(uint64_t))(*(void *)a1 + 264))(a1)) {
    return 0;
  }
  (*(void (**)(uint64_t))(*(void *)a1 + 40))(a1);
  if (!(*(unsigned __int8 (**)(uint64_t, void *, uint64_t))(*(void *)a1 + 672))(a1, v14, 1)) {
    return 0;
  }
  if (!(*(unsigned __int8 (**)(uint64_t))(*(void *)a1 + 280))(a1)) {
    return 0;
  }
  (*(void (**)(uint64_t))(*(void *)a1 + 40))(a1);
  if (!(*(unsigned __int8 (**)(uint64_t, uint64_t))(*(void *)a1 + 456))(a1, a2 + 112)) {
    return 0;
  }
  if (!(*(unsigned __int8 (**)(uint64_t))(*(void *)a1 + 104))(a1)) {
    return 0;
  }
  uint64_t v10 = 0;
  if (!mlir::AsmParser::parseType<mlir::FunctionType>(a1, &v10)) {
    return 0;
  }
  v11[0] = mlir::FunctionType::getInputs((mlir::FunctionType *)&v10);
  v11[1] = v4;
  Results = (void *)mlir::FunctionType::getResults((mlir::FunctionType *)&v10);
  mlir::OperationState::addTypes(a2, Results, v6);
  v9[0] = v13;
  v9[1] = v12;
  uint64_t v7 = (*(uint64_t (**)(uint64_t))(*(void *)a1 + 16))(a1);
  return mlir::OpAsmParser::resolveOperands<llvm::detail::concat_range<mlir::OpAsmParser::UnresolvedOperand const,llvm::ArrayRef<mlir::OpAsmParser::UnresolvedOperand> &,llvm::ArrayRef<mlir::OpAsmParser::UnresolvedOperand> &>,llvm::ArrayRef<mlir::Type> &>(a1, v9, v11, v7, a2 + 16) != 0;
}

uint64_t mlir::tensor::ScatterOp::setPropertiesFromAttr(uint64_t *a1, uint64_t a2, void (*a3)(void *__return_ptr, uint64_t), uint64_t a4)
{
  uint64_t v89 = *MEMORY[0x263EF8340];
  if (*(_UNKNOWN **)(*(void *)a2 + 136) == &mlir::detail::TypeIDResolver<mlir::DictionaryAttr,void>::id) {
    uint64_t v6 = a2;
  }
  else {
    uint64_t v6 = 0;
  }
  uint64_t v75 = v6;
  if (!v6)
  {
    a3(v79, a4);
    if (v79[0])
    {
      int v76 = 3;
      int v77 = "expected DictionaryAttr to set properties";
      uint64_t v78 = 41;
      uint64_t v28 = &v76;
      uint64_t v29 = (char *)v80;
      if (v81 >= v82)
      {
        unint64_t v63 = v81 + 1;
        if (v80 <= &v76 && (char *)v80 + 24 * v81 > (char *)&v76)
        {
          int64_t v69 = (char *)&v76 - (unsigned char *)v80;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v80, v83, v63, 24);
          uint64_t v29 = (char *)v80;
          uint64_t v28 = (int *)((char *)v80 + v69);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v80, v83, v63, 24);
          uint64_t v28 = &v76;
          uint64_t v29 = (char *)v80;
        }
      }
      uint64_t v30 = &v29[24 * v81];
      long long v31 = *(_OWORD *)v28;
      *((void *)v30 + 2) = *((void *)v28 + 2);
      *(_OWORD *)uint64_t v30 = v31;
      ++v81;
      if (v79[0]) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v79);
      }
    }
    if (!v88) {
      return 0;
    }
    uint64_t v32 = __p;
    if (__p)
    {
      uint64_t v33 = v87;
      uint64_t v34 = __p;
      if (v87 != __p)
      {
        do
          uint64_t v33 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v33 - 1);
        while (v33 != v32);
        uint64_t v34 = __p;
      }
      unint64_t v87 = v32;
      operator delete(v34);
    }
    uint64_t v23 = v84;
    if (!v84) {
      goto LABEL_79;
    }
    uint64_t v35 = v85;
    long long v25 = v84;
    if (v85 == v84) {
      goto LABEL_78;
    }
    do
    {
      uint64_t v37 = *--v35;
      uint64_t v36 = v37;
      *uint64_t v35 = 0;
      if (v37) {
        MEMORY[0x21667D390](v36, 0x1000C8077774924);
      }
    }
    while (v35 != v23);
    goto LABEL_77;
  }
  uint64_t v8 = (void *)mlir::DictionaryAttr::get((uint64_t)&v75, "scatter_dims", 0xCuLL);
  if (!v8)
  {
    a3(v79, a4);
    if (v79[0])
    {
      int v76 = 3;
      int v77 = "expected key entry for scatter_dims in DictionaryAttr to set Properties.";
      uint64_t v78 = 72;
      unint64_t v38 = &v76;
      unint64_t v39 = (char *)v80;
      if (v81 >= v82)
      {
        unint64_t v64 = v81 + 1;
        if (v80 <= &v76 && (char *)v80 + 24 * v81 > (char *)&v76)
        {
          int64_t v70 = (char *)&v76 - (unsigned char *)v80;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v80, v83, v64, 24);
          unint64_t v39 = (char *)v80;
          unint64_t v38 = (int *)((char *)v80 + v70);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v80, v83, v64, 24);
          unint64_t v38 = &v76;
          unint64_t v39 = (char *)v80;
        }
      }
      BOOL v40 = &v39[24 * v81];
      long long v41 = *(_OWORD *)v38;
      *((void *)v40 + 2) = *((void *)v38 + 2);
      *(_OWORD *)BOOL v40 = v41;
      ++v81;
      if (v79[0]) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v79);
      }
    }
    if (!v88) {
      return 0;
    }
    BOOL v42 = __p;
    if (__p)
    {
      unint64_t v43 = v87;
      int64_t v44 = __p;
      if (v87 != __p)
      {
        do
          unint64_t v43 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v43 - 1);
        while (v43 != v42);
        int64_t v44 = __p;
      }
      unint64_t v87 = v42;
      operator delete(v44);
    }
    uint64_t v23 = v84;
    if (!v84) {
      goto LABEL_79;
    }
    int64_t v45 = v85;
    long long v25 = v84;
    if (v85 == v84) {
      goto LABEL_78;
    }
    do
    {
      uint64_t v47 = *--v45;
      uint64_t v46 = v47;
      *int64_t v45 = 0;
      if (v47) {
        MEMORY[0x21667D390](v46, 0x1000C8077774924);
      }
    }
    while (v45 != v23);
    goto LABEL_77;
  }
  uint64_t v9 = (uint64_t)v8;
  if (!mlir::detail::DenseArrayAttrImpl<long long>::classof(v8))
  {
    a3(v79, a4);
    if (v79[0])
    {
      int v76 = 3;
      uint64_t v78 = 57;
      uint64_t v48 = &v76;
      uint64_t v49 = (char *)v80;
      if (v81 >= v82)
      {
        unint64_t v65 = v81 + 1;
        if (v80 <= &v76 && (char *)v80 + 24 * v81 > (char *)&v76)
        {
          int64_t v71 = (char *)&v76 - (unsigned char *)v80;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v80, v83, v65, 24);
          uint64_t v49 = (char *)v80;
          uint64_t v48 = (int *)((char *)v80 + v71);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v80, v83, v65, 24);
          uint64_t v48 = &v76;
          uint64_t v49 = (char *)v80;
        }
      }
      __int16 v50 = &v49[24 * v81];
      long long v51 = *(_OWORD *)v48;
      *((void *)v50 + 2) = *((void *)v48 + 2);
      *(_OWORD *)__int16 v50 = v51;
      ++v81;
      if (v79[0])
      {
        __int16 v52 = &v76;
        mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v76, v9);
        uint64_t v53 = (char *)v80;
        if (v81 >= v82)
        {
          unint64_t v66 = v81 + 1;
          if (v80 <= &v76 && (char *)v80 + 24 * v81 > (char *)&v76)
          {
            int64_t v72 = (char *)&v76 - (unsigned char *)v80;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v80, v83, v66, 24);
            uint64_t v53 = (char *)v80;
            __int16 v52 = (int *)((char *)v80 + v72);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v80, v83, v66, 24);
            __int16 v52 = &v76;
            uint64_t v53 = (char *)v80;
          }
        }
        uint64_t v54 = &v53[24 * v81];
        long long v55 = *(_OWORD *)v52;
        *((void *)v54 + 2) = *((void *)v52 + 2);
        *(_OWORD *)uint64_t v54 = v55;
        ++v81;
        if (v79[0]) {
          mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v79);
        }
      }
    }
    if (!v88) {
      return 0;
    }
    __int16 v56 = __p;
    if (__p)
    {
      unsigned int v57 = v87;
      unsigned int v58 = __p;
      if (v87 != __p)
      {
        do
          unsigned int v57 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v57 - 1);
        while (v57 != v56);
        unsigned int v58 = __p;
      }
      unint64_t v87 = v56;
      operator delete(v58);
    }
    uint64_t v23 = v84;
    if (!v84) {
      goto LABEL_79;
    }
    long long v59 = v85;
    long long v25 = v84;
    if (v85 == v84) {
      goto LABEL_78;
    }
    do
    {
      uint64_t v61 = *--v59;
      uint64_t v60 = v61;
      *long long v59 = 0;
      if (v61) {
        MEMORY[0x21667D390](v60, 0x1000C8077774924);
      }
    }
    while (v59 != v23);
    goto LABEL_77;
  }
  *a1 = v9;
  uint64_t v10 = mlir::DictionaryAttr::get((uint64_t)&v75, "unique", 6uLL);
  if (!v10) {
    return 1;
  }
  uint64_t v11 = v10;
  if (*(_UNKNOWN **)(*(void *)v10 + 136) == &mlir::detail::TypeIDResolver<mlir::UnitAttr,void>::id)
  {
    a1[1] = v10;
    return 1;
  }
  a3(v79, a4);
  if (v79[0])
  {
    int v76 = 3;
    uint64_t v78 = 51;
    uint64_t v12 = &v76;
    uint64_t v13 = (char *)v80;
    if (v81 >= v82)
    {
      unint64_t v67 = v81 + 1;
      if (v80 <= &v76 && (char *)v80 + 24 * v81 > (char *)&v76)
      {
        int64_t v73 = (char *)&v76 - (unsigned char *)v80;
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v80, v83, v67, 24);
        uint64_t v13 = (char *)v80;
        uint64_t v12 = (int *)((char *)v80 + v73);
      }
      else
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v80, v83, v67, 24);
        uint64_t v12 = &v76;
        uint64_t v13 = (char *)v80;
      }
    }
    uint64_t v14 = &v13[24 * v81];
    long long v15 = *(_OWORD *)v12;
    *((void *)v14 + 2) = *((void *)v12 + 2);
    *(_OWORD *)uint64_t v14 = v15;
    ++v81;
    if (v79[0])
    {
      long long v16 = &v76;
      mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v76, v11);
      uint64_t v17 = (char *)v80;
      if (v81 >= v82)
      {
        unint64_t v68 = v81 + 1;
        if (v80 <= &v76 && (char *)v80 + 24 * v81 > (char *)&v76)
        {
          int64_t v74 = (char *)&v76 - (unsigned char *)v80;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v80, v83, v68, 24);
          uint64_t v17 = (char *)v80;
          long long v16 = (int *)((char *)v80 + v74);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v80, v83, v68, 24);
          long long v16 = &v76;
          uint64_t v17 = (char *)v80;
        }
      }
      uint64_t v18 = &v17[24 * v81];
      long long v19 = *(_OWORD *)v16;
      *((void *)v18 + 2) = *((void *)v16 + 2);
      *(_OWORD *)uint64_t v18 = v19;
      ++v81;
      if (v79[0]) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v79);
      }
    }
  }
  if (v88)
  {
    uint64_t v20 = __p;
    if (__p)
    {
      long long v21 = v87;
      uint64_t v22 = __p;
      if (v87 != __p)
      {
        do
          long long v21 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v21 - 1);
        while (v21 != v20);
        uint64_t v22 = __p;
      }
      unint64_t v87 = v20;
      operator delete(v22);
    }
    uint64_t v23 = v84;
    if (!v84) {
      goto LABEL_79;
    }
    uint64_t v24 = v85;
    long long v25 = v84;
    if (v85 == v84)
    {
LABEL_78:
      uint64_t v85 = v23;
      operator delete(v25);
LABEL_79:
      if (v80 != v83) {
        free(v80);
      }
      return 0;
    }
    do
    {
      uint64_t v27 = *--v24;
      uint64_t v26 = v27;
      *uint64_t v24 = 0;
      if (v27) {
        MEMORY[0x21667D390](v26, 0x1000C8077774924);
      }
    }
    while (v24 != v23);
LABEL_77:
    long long v25 = v84;
    goto LABEL_78;
  }
  return 0;
}

uint64_t mlir::tensor::ScatterOp::getPropertiesAsAttr(mlir::DictionaryAttr *a1, uint64_t *a2)
{
  v21[6] = *MEMORY[0x263EF8340];
  uint64_t v18 = a1;
  long long v19 = v21;
  uint64_t v20 = 0x300000000;
  if (*a2)
  {
    uint64_t NamedAttr = mlir::Builder::getNamedAttr(&v18, (uint64_t)"scatter_dims", 12, *a2);
    uint64_t v5 = v4;
    unsigned int v6 = v20;
    if (v20 >= HIDWORD(v20))
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v19, v21, v20 + 1, 16);
      unsigned int v6 = v20;
    }
    uint64_t v7 = (uint64_t *)((char *)v19 + 16 * v6);
    *uint64_t v7 = NamedAttr;
    v7[1] = v5;
    unsigned int v8 = v20 + 1;
    LODWORD(v20) = v20 + 1;
    uint64_t v9 = a2[1];
    if (!v9)
    {
LABEL_5:
      uint64_t v10 = (uint64_t *)v19;
      if (v8) {
        goto LABEL_6;
      }
LABEL_13:
      uint64_t DictionaryAttr = 0;
      if (v10 == v21) {
        return DictionaryAttr;
      }
      goto LABEL_7;
    }
  }
  else
  {
    unsigned int v8 = 0;
    uint64_t v9 = a2[1];
    if (!v9) {
      goto LABEL_5;
    }
  }
  uint64_t v13 = mlir::Builder::getNamedAttr(&v18, (uint64_t)"unique", 6, v9);
  uint64_t v15 = v14;
  unsigned int v16 = v20;
  if (v20 >= HIDWORD(v20))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v19, v21, v20 + 1, 16);
    unsigned int v16 = v20;
  }
  uint64_t v17 = (uint64_t *)((char *)v19 + 16 * v16);
  *uint64_t v17 = v13;
  v17[1] = v15;
  unsigned int v8 = v20 + 1;
  LODWORD(v20) = v8;
  uint64_t v10 = (uint64_t *)v19;
  if (!v8) {
    goto LABEL_13;
  }
LABEL_6:
  uint64_t DictionaryAttr = mlir::Builder::getDictionaryAttr(&v18, v10, v8);
  uint64_t v10 = (uint64_t *)v19;
  if (v19 != v21) {
LABEL_7:
  }
    free(v10);
  return DictionaryAttr;
}

uint64_t mlir::tensor::ScatterOp::getInherentAttr(int a1, void *a2, void *__s1, size_t __n)
{
  if (__n == 6)
  {
    if (memcmp(__s1, "unique", 6uLL)) {
      return 0;
    }
    return a2[1];
  }
  else
  {
    if (__n != 12) {
      return 0;
    }
    if (*__s1 != 0x5F72657474616373 || *((_DWORD *)__s1 + 2) != 1936550244) {
      return 0;
    }
    return *a2;
  }
}

uint64_t mlir::tensor::ScatterOp::setInherentAttr(uint64_t result, void *__s1, uint64_t a3, void *a4)
{
  uint64_t v5 = (void *)result;
  if (a3 == 6)
  {
    uint64_t result = memcmp(__s1, "unique", 6uLL);
    if (!result)
    {
      if (a4)
      {
        if (*(_UNKNOWN **)(*a4 + 136) == &mlir::detail::TypeIDResolver<mlir::UnitAttr,void>::id) {
          uint64_t v7 = a4;
        }
        else {
          uint64_t v7 = 0;
        }
        v5[1] = v7;
      }
      else
      {
        v5[1] = 0;
      }
    }
  }
  else if (a3 == 12 && *__s1 == 0x5F72657474616373 && *((_DWORD *)__s1 + 2) == 1936550244)
  {
    if (a4)
    {
      uint64_t result = mlir::detail::DenseArrayAttrImpl<long long>::classof(a4);
      if (result) {
        unsigned int v8 = a4;
      }
      else {
        unsigned int v8 = 0;
      }
      void *v5 = v8;
    }
    else
    {
      *(void *)uint64_t result = 0;
    }
  }
  return result;
}

void mlir::tensor::ScatterOp::populateInherentAttrs(uint64_t a1, uint64_t *a2, uint64_t a3)
{
  if (*a2) {
    mlir::NamedAttrList::append(a3, (uint64_t)"scatter_dims", 12, *a2);
  }
  uint64_t v5 = a2[1];
  if (v5)
  {
    mlir::NamedAttrList::append(a3, (uint64_t)"unique", 6, v5);
  }
}

BOOL mlir::tensor::ScatterOp::verifyInherentAttrs(uint64_t a1, uint64_t a2, void (*a3)(uint64_t *__return_ptr, uint64_t), uint64_t a4)
{
  unsigned int v8 = (void *)mlir::NamedAttrList::get(a2, **(void **)(a1 + 96));
  BOOL result = 0;
  if (!v8
    || mlir::memref::__mlir_ods_local_attr_constraint_MemRefOps12(v8, (void **)"scatter_dims", (const char *)0xC, a3, a4))
  {
    uint64_t v9 = mlir::NamedAttrList::get(a2, *(void *)(*(void *)(a1 + 96) + 8));
    if (!v9
      || mlir::memref::__mlir_ods_local_attr_constraint_MemRefOps9(v9, (void **)"unique", (const char *)6, a3, a4))
    {
      return 1;
    }
  }
  return result;
}

BOOL mlir::tensor::ScatterOp::readProperties(uint64_t a1, uint64_t a2)
{
  unint64_t v3 = (void *)mlir::OperationState::getOrAddProperties<mlir::tensor::detail::ScatterOpGenericAdaptorBase::Properties>(a2);
  return mlir::DialectBytecodeReader::readAttribute<mlir::detail::DenseArrayAttrImpl<long long>>(a1, v3)&& mlir::DialectBytecodeReader::readOptionalAttribute<mlir::UnitAttr>(a1, v3 + 1) != 0;
}

uint64_t mlir::OperationState::getOrAddProperties<mlir::tensor::detail::ScatterOpGenericAdaptorBase::Properties>(uint64_t a1)
{
  uint64_t result = *(void *)(a1 + 256);
  if (!result) {
    operator new();
  }
  return result;
}

BOOL mlir::tensor::ScatterOp::verifyInvariantsImpl(mlir::tensor::ScatterOp *this)
{
  uint64_t v28 = *MEMORY[0x263EF8340];
  uint64_t v2 = *(void *)this;
  if (HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
    unint64_t v3 = *(void *)this + 16 * (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 23) & 1) + 64;
  }
  else {
    unint64_t v3 = 0;
  }
  uint64_t v4 = *(void **)v3;
  if (*(void *)v3)
  {
    uint64_t v5 = *(void *)(v3 + 8);
    v20[0] = v2;
    if (!mlir::memref::__mlir_ods_local_attr_constraint_MemRefOps12(v4, (void **)"scatter_dims", (const char *)0xC, (void (*)(uint64_t *__return_ptr, uint64_t))llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::__mlir_ods_local_attr_constraint_TensorOps1(mlir::Operation *,mlir::Attribute,llvm::StringRef)::$_0>, (uint64_t)v20))return 0; {
    v20[0] = *(void *)this;
    }
    if (!mlir::memref::__mlir_ods_local_attr_constraint_MemRefOps9(v5, (void **)"unique", (const char *)6, (void (*)(uint64_t *__return_ptr, uint64_t))llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::__mlir_ods_local_attr_constraint_TensorOps2(mlir::Operation *,mlir::Attribute,llvm::StringRef)::$_0>, (uint64_t)v20)|| !mlir::tensor::__mlir_ods_local_type_constraint_TensorOps1(*(void *)this, *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"operand", (void **)7, 0))
    {
      return 0;
    }
    if (!mlir::tensor::__mlir_ods_local_type_constraint_TensorOps1(*(void *)this, *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 56) + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"operand", (void **)7, 1u))return 0; {
    if (mlir::tensor::__mlir_ods_local_type_constraint_TensorOps8(*(void *)this, *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 88) + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"operand", (void **)7, 2u))
    }
    {
      if (*(_DWORD *)(*(void *)this + 36)) {
        uint64_t v6 = *(void *)this - 16;
      }
      else {
        uint64_t v6 = 0;
      }
      uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v6, 0);
      return mlir::tensor::__mlir_ods_local_type_constraint_TensorOps1(*(void *)this, *(void *)(NextResultAtOffset + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"result", (void **)6, 0) != 0;
    }
    else
    {
      return 0;
    }
  }
  else
  {
    uint64_t v18 = (void **)"requires attribute 'scatter_dims'";
    __int16 v19 = 259;
    mlir::OpState::emitOpError((uint64_t *)this, &v18, (uint64_t)v20);
    uint64_t v8 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v20);
    if (v20[0]) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v20);
    }
    if (v27)
    {
      uint64_t v9 = __p;
      if (__p)
      {
        uint64_t v10 = v26;
        uint64_t v11 = __p;
        if (v26 != __p)
        {
          do
            uint64_t v10 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v10 - 1);
          while (v10 != v9);
          uint64_t v11 = __p;
        }
        uint64_t v26 = v9;
        operator delete(v11);
      }
      uint64_t v12 = v23;
      if (v23)
      {
        uint64_t v13 = v24;
        uint64_t v14 = v23;
        if (v24 != v23)
        {
          do
          {
            uint64_t v16 = *--v13;
            uint64_t v15 = v16;
            *uint64_t v13 = 0;
            if (v16) {
              MEMORY[0x21667D390](v15, 0x1000C8077774924);
            }
          }
          while (v13 != v12);
          uint64_t v14 = v23;
        }
        uint64_t v24 = v12;
        operator delete(v14);
      }
      if (v21 != &v22) {
        free(v21);
      }
    }
  }
  return v8;
}

BOOL mlir::tensor::ScatterOp::parse(uint64_t *a1, uint64_t a2)
{
  void v27[4] = *MEMORY[0x263EF8340];
  memset(v27, 0, 24);
  v20[0] = v27;
  v20[1] = 1;
  memset(v26, 0, 24);
  v19[0] = v26;
  v19[1] = 1;
  memset(v25, 0, 24);
  v18[0] = v25;
  v18[1] = 1;
  uint64_t v16 = 0;
  uint64_t v17 = 0;
  uint64_t Inputs = 0;
  (*(void (**)(uint64_t *))(*a1 + 40))(a1);
  if (!(*(unsigned __int8 (**)(uint64_t *, void *, uint64_t))(*a1 + 672))(a1, v27, 1)) {
    return 0;
  }
  __int16 v24 = 257;
  if (!(*(unsigned __int8 (**)(uint64_t *, const char *, uint64_t, uint64_t **))(*a1 + 368))(a1, "into", 4, &v21))return 0; {
  (*(void (**)(uint64_t *))(*a1 + 40))(a1);
  }
  if (!(*(unsigned __int8 (**)(uint64_t *, void *, uint64_t))(*a1 + 672))(a1, v26, 1)) {
    return 0;
  }
  if (!(*(unsigned __int8 (**)(uint64_t *))(*a1 + 296))(a1)) {
    return 0;
  }
  (*(void (**)(uint64_t *))(*a1 + 40))(a1);
  if (!(*(unsigned __int8 (**)(uint64_t *, void *, uint64_t))(*a1 + 672))(a1, v25, 1)) {
    return 0;
  }
  if (!(*(unsigned __int8 (**)(uint64_t *))(*a1 + 312))(a1)) {
    return 0;
  }
  __int16 v24 = 257;
  if (!(*(unsigned __int8 (**)(uint64_t *, const char *, uint64_t, uint64_t **))(*a1 + 368))(a1, "scatter_dims", 12, &v21)|| !(*(unsigned __int8 (**)(uint64_t *))(*a1 + 264))(a1)|| !mlir::AsmParser::parseCustomAttributeWithFallback<mlir::detail::DenseArrayAttrImpl<long long>>((uint64_t)a1, &v17, 0))
  {
    return 0;
  }
  if (v17)
  {
    uint64_t v4 = (void *)mlir::OperationState::getOrAddProperties<mlir::tensor::detail::ScatterOpGenericAdaptorBase::Properties>(a2);
    *uint64_t v4 = v17;
  }
  if (!(*(unsigned __int8 (**)(uint64_t *))(*a1 + 280))(a1)) {
    return 0;
  }
  if ((*(unsigned __int8 (**)(uint64_t *, const char *, uint64_t))(*a1 + 376))(a1, "unique", 6))
  {
    uint64_t v5 = (mlir::UnitAttr **)(*(uint64_t (**)(uint64_t *))(*a1 + 32))(a1);
    uint64_t UnitAttr = mlir::Builder::getUnitAttr(v5, v6);
    *(void *)(mlir::OperationState::getOrAddProperties<mlir::tensor::detail::ScatterOpGenericAdaptorBase::Properties>(a2)
              + 8) = UnitAttr;
  }
  uint64_t v14 = (*(uint64_t (**)(uint64_t *))(*a1 + 40))(a1);
  if (!(*(unsigned __int8 (**)(uint64_t *, uint64_t))(*a1 + 456))(a1, a2 + 112)) {
    return 0;
  }
  uint64_t v8 = *(void *)(a2 + 8);
  long long v21 = a1;
  uint64_t v22 = &v14;
  uint64_t v23 = (void *)a2;
  if (!mlir::tensor::ScatterOp::verifyInherentAttrs(v8, a2 + 112, (void (*)(uint64_t *__return_ptr, uint64_t))llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::ScatterOp::parse(mlir::OpAsmParser &,mlir::OperationState &)::$_0>, (uint64_t)&v21))return 0; {
  if (!(*(unsigned __int8 (**)(uint64_t *))(*a1 + 104))(a1))
  }
    return 0;
  uint64_t v14 = 0;
  if (!mlir::AsmParser::parseType<mlir::FunctionType>((uint64_t)a1, &v14)) {
    return 0;
  }
  uint64_t Inputs = mlir::FunctionType::getInputs((mlir::FunctionType *)&v14);
  uint64_t v16 = v9;
  Results = (void *)mlir::FunctionType::getResults((mlir::FunctionType *)&v14);
  mlir::OperationState::addTypes(a2, Results, v11);
  long long v21 = v20;
  uint64_t v22 = v19;
  uint64_t v23 = v18;
  uint64_t v12 = (*(uint64_t (**)(uint64_t *))(*a1 + 16))(a1);
  return mlir::OpAsmParser::resolveOperands<llvm::detail::concat_range<mlir::OpAsmParser::UnresolvedOperand const,llvm::ArrayRef<mlir::OpAsmParser::UnresolvedOperand> &,llvm::ArrayRef<mlir::OpAsmParser::UnresolvedOperand> &,llvm::ArrayRef<mlir::OpAsmParser::UnresolvedOperand> &>,llvm::ArrayRef<mlir::Type> &>((uint64_t)a1, &v21, &Inputs, v12, a2 + 16) != 0;
}

uint64_t mlir::OpAsmParser::resolveOperands<llvm::detail::concat_range<mlir::OpAsmParser::UnresolvedOperand const,llvm::ArrayRef<mlir::OpAsmParser::UnresolvedOperand> &,llvm::ArrayRef<mlir::OpAsmParser::UnresolvedOperand> &,llvm::ArrayRef<mlir::OpAsmParser::UnresolvedOperand> &>,llvm::ArrayRef<mlir::Type> &>(uint64_t a1, uint64_t **a2, void *a3, uint64_t a4, uint64_t a5)
{
  uint64_t v85 = *MEMORY[0x263EF8340];
  uint64_t v6 = a2[1];
  uint64_t v7 = a2[2];
  uint64_t v9 = **a2;
  uint64_t v8 = (*a2)[1];
  uint64_t v11 = *v6;
  uint64_t v10 = v6[1];
  uint64_t v13 = *v7;
  uint64_t v12 = v7[1];
  v75[0] = v9;
  v70[0] = v11;
  uint64_t v72 = v13;
  BOOL v14 = v8 == 0;
  BOOL v15 = v10 == 0;
  uint64_t v16 = v8 | v10 | v12;
  BOOL v17 = v16 == 0;
  if (v16)
  {
    __int16 v19 = 0;
    uint64_t v20 = v9 + 32 * v8;
    uint64_t v21 = v13;
    uint64_t v22 = v11;
    uint64_t v23 = v9;
    uint64_t v24 = v11 + 32 * v10;
    uint64_t v25 = v13 + 32 * v12;
    while (v23 == v20)
    {
      if (v22 != v24)
      {
        uint64_t v26 = v70;
        uint64_t v23 = v22;
        goto LABEL_11;
      }
      uint64_t v27 = v13 + 32 * v12;
      uint64_t v22 = v24;
      uint64_t v23 = v20;
      if (v21 != v25)
      {
        uint64_t v26 = &v72;
        uint64_t v23 = v21;
        goto LABEL_11;
      }
LABEL_12:
      ++v19;
      BOOL v29 = v23 == v20 && v22 == v24 && v27 == v25;
      uint64_t v21 = v27;
      if (v29)
      {
        uint64_t v18 = (const char *)a3[1];
        if (v18 != v19) {
          goto LABEL_45;
        }
        uint64_t v30 = (void *)*a3;
        v75[0] = v9;
        v70[0] = v11;
        uint64_t v72 = v13;
        if (!v17)
        {
          while (2)
          {
            if (!v9 || (uint64_t v31 = v9, v14))
            {
              if (v13 == v25) {
                uint64_t v32 = 0;
              }
              else {
                uint64_t v32 = v13;
              }
              if (v11 != 0 && !v15) {
                uint64_t v31 = v11;
              }
              else {
                uint64_t v31 = v32;
              }
            }
            if (!(*(unsigned __int8 (**)(uint64_t, uint64_t, void, uint64_t))(*(void *)a1 + 696))(a1, v31, *v30, a5))return 0; {
            if (v14)
            }
              uint64_t v33 = v11;
            else {
              uint64_t v33 = v9;
            }
            uint64_t v34 = v75;
            if (v14) {
              uint64_t v34 = v70;
            }
            if (v14 && v15)
            {
              uint64_t v35 = v25;
              if (v13 != v25)
              {
                uint64_t v34 = &v72;
                goto LABEL_40;
              }
            }
            else
            {
              uint64_t v13 = v33;
LABEL_40:
              *uint64_t v34 = v13 + 32;
              uint64_t v9 = v75[0];
              uint64_t v11 = v70[0];
              uint64_t v35 = v72;
            }
            ++v30;
            BOOL v15 = v11 == v24;
            uint64_t v13 = v35;
            BOOL v14 = v9 == v20;
            if (v9 == v20)
            {
              uint64_t v13 = v35;
              if (v11 == v24)
              {
                uint64_t v13 = v35;
                if (v35 == v25) {
                  return 1;
                }
              }
            }
            continue;
          }
        }
        return 1;
      }
    }
    uint64_t v26 = v75;
LABEL_11:
    *uint64_t v26 = v23 + 32;
    uint64_t v23 = v75[0];
    uint64_t v22 = v70[0];
    uint64_t v27 = v72;
    goto LABEL_12;
  }
  uint64_t v18 = (const char *)a3[1];
  if (!v18) {
    return 1;
  }
  __int16 v19 = 0;
LABEL_45:
  uint64_t v37 = v18;
  __int16 v71 = 257;
  (*(void (**)(void *__return_ptr, uint64_t, uint64_t, void *))(*(void *)a1 + 24))(v75, a1, a4, v70);
  if (v75[0])
  {
    LODWORD(v72) = 5;
    int64_t v73 = v19;
    unint64_t v38 = (char *)&v72;
    unint64_t v39 = (char *)v76;
    if (v77 >= v78)
    {
      unint64_t v61 = v77 + 1;
      if (v76 <= &v72 && (char *)v76 + 24 * v77 > (char *)&v72)
      {
        int64_t v66 = (char *)&v72 - (unsigned char *)v76;
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v76, v79, v61, 24);
        unint64_t v39 = (char *)v76;
        unint64_t v38 = (char *)v76 + v66;
      }
      else
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v76, v79, v61, 24);
        unint64_t v38 = (char *)&v72;
        unint64_t v39 = (char *)v76;
      }
    }
    BOOL v40 = &v39[24 * v77];
    long long v41 = *(_OWORD *)v38;
    *((void *)v40 + 2) = *((void *)v38 + 2);
    *(_OWORD *)BOOL v40 = v41;
    uint64_t v42 = ++v77;
    if (v75[0])
    {
      LODWORD(v72) = 3;
      int64_t v73 = " operands present, but expected ";
      uint64_t v74 = 32;
      unint64_t v43 = (char *)&v72;
      int64_t v44 = (char *)v76;
      if (v42 >= v78)
      {
        unint64_t v62 = v42 + 1;
        BOOL v63 = (char *)v76 + 24 * v42 > (char *)&v72;
        if (v76 <= &v72 && v63)
        {
          int64_t v67 = (char *)&v72 - (unsigned char *)v76;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v76, v79, v62, 24);
          int64_t v44 = (char *)v76;
          unint64_t v43 = (char *)v76 + v67;
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v76, v79, v62, 24);
          unint64_t v43 = (char *)&v72;
          int64_t v44 = (char *)v76;
        }
      }
      int64_t v45 = &v44[24 * v77];
      long long v46 = *(_OWORD *)v43;
      *((void *)v45 + 2) = *((void *)v43 + 2);
      *(_OWORD *)int64_t v45 = v46;
      uint64_t v47 = ++v77;
      if (v75[0])
      {
        LODWORD(v72) = 5;
        int64_t v73 = v37;
        uint64_t v48 = (char *)&v72;
        uint64_t v49 = (char *)v76;
        if (v47 >= v78)
        {
          unint64_t v64 = v47 + 1;
          BOOL v65 = (char *)v76 + 24 * v47 > (char *)&v72;
          if (v76 <= &v72 && v65)
          {
            int64_t v68 = (char *)&v72 - (unsigned char *)v76;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v76, v79, v64, 24);
            uint64_t v49 = (char *)v76;
            uint64_t v48 = (char *)v76 + v68;
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v76, v79, v64, 24);
            uint64_t v48 = (char *)&v72;
            uint64_t v49 = (char *)v76;
          }
        }
        __int16 v50 = &v49[24 * v77];
        long long v51 = *(_OWORD *)v48;
        *((void *)v50 + 2) = *((void *)v48 + 2);
        *(_OWORD *)__int16 v50 = v51;
        ++v77;
      }
    }
  }
  uint64_t v36 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v75);
  if (v75[0]) {
    mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v75);
  }
  if (v84)
  {
    __int16 v52 = __p;
    if (__p)
    {
      uint64_t v53 = v83;
      uint64_t v54 = __p;
      if (v83 != __p)
      {
        do
          uint64_t v53 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v53 - 1);
        while (v53 != v52);
        uint64_t v54 = __p;
      }
      long long v83 = v52;
      operator delete(v54);
    }
    long long v55 = v80;
    if (v80)
    {
      __int16 v56 = v81;
      unsigned int v57 = v80;
      if (v81 != v80)
      {
        do
        {
          uint64_t v59 = *--v56;
          uint64_t v58 = v59;
          *__int16 v56 = 0;
          if (v59) {
            MEMORY[0x21667D390](v58, 0x1000C8077774924);
          }
        }
        while (v56 != v55);
        unsigned int v57 = v80;
      }
      unsigned int v81 = v55;
      operator delete(v57);
    }
    if (v76 != v79) {
      free(v76);
    }
  }
  return v36;
}

void mlir::tensor::ScatterOp::print(mlir::Operation **this, mlir::OpAsmPrinter *a2)
{
  v51[4] = *MEMORY[0x263EF8340];
  uint64_t v4 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v5 = (unsigned char *)*((void *)v4 + 4);
  if ((unint64_t)v5 >= *((void *)v4 + 3))
  {
    llvm::raw_ostream::write(v4, 32);
  }
  else
  {
    *((void *)v4 + 4) = v5 + 1;
    unsigned char *v5 = 32;
  }
  (*(void (**)(mlir::OpAsmPrinter *, void))(*(void *)a2 + 160))(a2, *(void *)(*((void *)*this + 9) + 24));
  uint64_t v6 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v7 = (unsigned char *)*((void *)v6 + 4);
  if ((unint64_t)v7 >= *((void *)v6 + 3))
  {
    llvm::raw_ostream::write(v6, 32);
  }
  else
  {
    *((void *)v6 + 4) = v7 + 1;
    *uint64_t v7 = 32;
  }
  uint64_t v8 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v9 = (_DWORD *)*((void *)v8 + 4);
  if (*((void *)v8 + 3) - (void)v9 > 3uLL)
  {
    *uint64_t v9 = 1869901417;
    *((void *)v8 + 4) += 4;
  }
  else
  {
    llvm::raw_ostream::write(v8, "into", 4uLL);
  }
  uint64_t v10 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v11 = (unsigned char *)*((void *)v10 + 4);
  if ((unint64_t)v11 >= *((void *)v10 + 3))
  {
    llvm::raw_ostream::write(v10, 32);
  }
  else
  {
    *((void *)v10 + 4) = v11 + 1;
    *uint64_t v11 = 32;
  }
  (*(void (**)(mlir::OpAsmPrinter *, void))(*(void *)a2 + 160))(a2, *(void *)(*((void *)*this + 9) + 56));
  uint64_t v12 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v13 = (unsigned char *)*((void *)v12 + 4);
  if (*((unsigned char **)v12 + 3) == v13)
  {
    llvm::raw_ostream::write(v12, "[", 1uLL);
  }
  else
  {
    *uint64_t v13 = 91;
    ++*((void *)v12 + 4);
  }
  (*(void (**)(mlir::OpAsmPrinter *, void))(*(void *)a2 + 160))(a2, *(void *)(*((void *)*this + 9) + 88));
  BOOL v14 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  BOOL v15 = (unsigned char *)*((void *)v14 + 4);
  if (*((unsigned char **)v14 + 3) == v15)
  {
    llvm::raw_ostream::write(v14, "]", 1uLL);
  }
  else
  {
    *BOOL v15 = 93;
    ++*((void *)v14 + 4);
  }
  uint64_t v16 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  BOOL v17 = (unsigned char *)*((void *)v16 + 4);
  if ((unint64_t)v17 >= *((void *)v16 + 3))
  {
    llvm::raw_ostream::write(v16, 32);
  }
  else
  {
    *((void *)v16 + 4) = v17 + 1;
    *BOOL v17 = 32;
  }
  uint64_t v18 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v19 = *((void *)v18 + 4);
  if ((unint64_t)(*((void *)v18 + 3) - v19) > 0xB)
  {
    *(_DWORD *)(v19 + 8) = 1936550244;
    *(void *)uint64_t v19 = *(void *)"scatter_dims";
    *((void *)v18 + 4) += 12;
  }
  else
  {
    llvm::raw_ostream::write(v18, "scatter_dims", 0xCuLL);
  }
  uint64_t v20 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v21 = (unsigned char *)*((void *)v20 + 4);
  if (*((unsigned char **)v20 + 3) == v21)
  {
    llvm::raw_ostream::write(v20, "(", 1uLL);
  }
  else
  {
    *uint64_t v21 = 40;
    ++*((void *)v20 + 4);
  }
  uint64_t v49 = (void *)*((void *)*this + 2 * (((unint64_t)*((unsigned int *)*this + 11) >> 23) & 1) + 8);
  if (!(*(unsigned __int8 (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 104))(a2))
  {
    uint64_t v22 = (void *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
    uint64_t v23 = (*(uint64_t (**)(void *))(*v22 + 80))(v22) + v22[4] - v22[2];
    mlir::detail::DenseArrayAttrImpl<long long>::print((llvm::raw_ostream *)&v49, (uint64_t)a2);
    if (v23 == (*(uint64_t (**)(void *))(*v22 + 80))(v22) + v22[4] - v22[2]) {
      (*(void (**)(mlir::OpAsmPrinter *, void *))(*(void *)a2 + 40))(a2, v49);
    }
  }
  uint64_t v24 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v25 = (unsigned char *)*((void *)v24 + 4);
  if (*((unsigned char **)v24 + 3) == v25)
  {
    llvm::raw_ostream::write(v24, ")", 1uLL);
  }
  else
  {
    unsigned char *v25 = 41;
    ++*((void *)v24 + 4);
  }
  unint64_t v26 = (unint64_t)*this + 16 * (((unint64_t)*((unsigned int *)*this + 11) >> 23) & 1) + 64;
  if (!HIBYTE(*((_DWORD *)*this + 11))) {
    unint64_t v26 = 0;
  }
  if (*(void *)(v26 + 8))
  {
    uint64_t v27 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
    uint64_t v28 = (unsigned char *)*((void *)v27 + 4);
    if ((unint64_t)v28 >= *((void *)v27 + 3))
    {
      llvm::raw_ostream::write(v27, 32);
    }
    else
    {
      *((void *)v27 + 4) = v28 + 1;
      *uint64_t v28 = 32;
    }
    BOOL v29 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
    uint64_t v30 = *((void *)v29 + 4);
    if ((unint64_t)(*((void *)v29 + 3) - v30) > 5)
    {
      *(_WORD *)(v30 + 4) = 25973;
      *(_DWORD *)uint64_t v30 = 1902734965;
      *((void *)v29 + 4) += 6;
    }
    else
    {
      llvm::raw_ostream::write(v29, "unique", 6uLL);
    }
  }
  uint64_t v49 = v51;
  v51[0] = "scatter_dims";
  v51[1] = 12;
  v51[2] = "unique";
  void v51[3] = 6;
  uint64_t v50 = 0x200000002;
  mlir::Attribute::getContext((mlir::Operation *)((char *)*this + 24));
  uint64_t v31 = *this;
  if (*((unsigned char *)*this + 47))
  {
    v47[0] = mlir::Operation::getAttrDictionary(v31);
    uint64_t v32 = (mlir::ArrayAttr *)v47;
  }
  else
  {
    uint64_t v32 = (mlir::Operation *)((char *)v31 + 56);
  }
  uint64_t Value = mlir::ArrayAttr::getValue(v32);
  (*(void (**)(mlir::OpAsmPrinter *, uint64_t, uint64_t, void *, void))(*(void *)a2 + 192))(a2, Value, v34, v49, v50);
  uint64_t v35 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v36 = (unsigned char *)*((void *)v35 + 4);
  if ((unint64_t)v36 >= *((void *)v35 + 3))
  {
    llvm::raw_ostream::write(v35, 32);
  }
  else
  {
    *((void *)v35 + 4) = v36 + 1;
    *uint64_t v36 = 32;
  }
  uint64_t v37 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  unint64_t v38 = (unsigned char *)*((void *)v37 + 4);
  if (*((unsigned char **)v37 + 3) == v38)
  {
    llvm::raw_ostream::write(v37, ":", 1uLL);
  }
  else
  {
    *unint64_t v38 = 58;
    ++*((void *)v37 + 4);
  }
  unint64_t v39 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  BOOL v40 = (unsigned char *)*((void *)v39 + 4);
  if ((unint64_t)v40 >= *((void *)v39 + 3))
  {
    llvm::raw_ostream::write(v39, 32);
  }
  else
  {
    *((void *)v39 + 4) = v40 + 1;
    *BOOL v40 = 32;
  }
  long long v41 = *this;
  if ((*((unsigned char *)*this + 46) & 0x80) != 0)
  {
    uint64_t v42 = *((void *)v41 + 9);
    uint64_t v43 = *((unsigned int *)v41 + 17);
  }
  else
  {
    uint64_t v42 = 0;
    uint64_t v43 = 0;
  }
  v46[0] = v42;
  v46[1] = v43;
  mlir::OperandRange::getTypes(v46, v47);
  uint64_t v44 = *((unsigned int *)*this + 9);
  uint64_t v45 = (uint64_t)*this - 16;
  if (!v44) {
    uint64_t v45 = 0;
  }
  v48[0] = v45;
  v48[1] = v44;
  mlir::OperandRange::getTypes(v48, v46);
  mlir::AsmPrinter::printFunctionalType<mlir::ValueTypeRange<mlir::OperandRange>,mlir::ValueTypeRange<mlir::ResultRange>>((uint64_t)a2, v47, v46);
  if (v49 != v51) {
    free(v49);
  }
}

uint64_t mlir::tensor::detail::SplatOpGenericAdaptorBase::SplatOpGenericAdaptorBase(uint64_t a1, mlir::Operation *this)
{
  uint64_t v11 = *MEMORY[0x263EF8340];
  unint64_t AttrDictionary = mlir::Operation::getAttrDictionary(this);
  unint64_t v5 = *((unsigned int *)this + 11);
  unint64_t v6 = v5 & 0x7FFFFF;
  if ((v5 & 0x7FFFFF) != 0)
  {
    uint64_t v7 = (((unint64_t)this + 16 * ((v5 >> 23) & 1) + ((v5 >> 21) & 0x7F8) + 71) & 0xFFFFFFFFFFFFFFF8)
       + 32 * *((unsigned int *)this + 10);
  }
  else
  {
    uint64_t v7 = 0;
    unint64_t v6 = 0;
  }
  mlir::ValueRange::ValueRange(v10, v7, v6);
  *(void *)a1 = AttrDictionary;
  *(unsigned char *)(a1 + 8) = 0;
  *(unsigned char *)(a1 + 16) = 0;
  *(_OWORD *)(a1 + 24) = *(_OWORD *)v10;
  if (AttrDictionary)
  {
    uint64_t Context = mlir::Attribute::getContext((mlir::Attribute *)a1);
    if (*(unsigned char *)(a1 + 16)) {
      *(unsigned char *)(a1 + 16) = 0;
    }
    mlir::OperationName::OperationName(a1 + 8, "tensor.splat", 12, Context);
    *(unsigned char *)(a1 + 16) = 1;
  }
  return a1;
}

uint64_t mlir::tensor::SplatOp::verifyInvariantsImpl(mlir::tensor::SplatOp *this)
{
  uint64_t v82 = *MEMORY[0x263EF8340];
  uint64_t v2 = *(void *)this;
  unint64_t v68 = *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8;
  if (!mlir::Type::isSignlessInteger((mlir::Type *)&v68))
  {
    unint64_t v3 = *(void **)(*(void *)v68 + 136);
    BOOL v4 = v3 == &mlir::detail::TypeIDResolver<mlir::IndexType,void>::id
      || v3 == &mlir::detail::TypeIDResolver<mlir::Float8E5M2Type,void>::id;
    BOOL v5 = v4 || v3 == &mlir::detail::TypeIDResolver<mlir::Float8E4M3FNType,void>::id;
    BOOL v6 = v5 || v3 == &mlir::detail::TypeIDResolver<mlir::Float8E5M2FNUZType,void>::id;
    BOOL v7 = v6 || v3 == &mlir::detail::TypeIDResolver<mlir::Float8E4M3FNUZType,void>::id;
    BOOL v8 = v7 || v3 == &mlir::detail::TypeIDResolver<mlir::Float8E4M3B11FNUZType,void>::id;
    BOOL v9 = v8 || v3 == &mlir::detail::TypeIDResolver<mlir::BFloat16Type,void>::id;
    BOOL v10 = v9 || v3 == &mlir::detail::TypeIDResolver<mlir::Float16Type,void>::id;
    BOOL v11 = v10 || v3 == &mlir::detail::TypeIDResolver<mlir::FloatTF32Type,void>::id;
    BOOL v12 = v11 || v3 == &mlir::detail::TypeIDResolver<mlir::Float32Type,void>::id;
    BOOL v13 = v12 || v3 == &mlir::detail::TypeIDResolver<mlir::Float64Type,void>::id;
    BOOL v14 = v13 || v3 == &mlir::detail::TypeIDResolver<mlir::Float80Type,void>::id;
    if (!v14 && v3 != &mlir::detail::TypeIDResolver<mlir::Float128Type,void>::id)
    {
      __int16 v67 = 261;
      v66[0] = (void **)"operand";
      v66[1] = (void **)7;
      mlir::Operation::emitOpError(v2, v66, (uint64_t)v72);
      if (v72[0])
      {
        int v69 = 3;
        int64_t v70 = " #";
        uint64_t v71 = 2;
        uint64_t v28 = &v69;
        BOOL v29 = (char *)v73;
        if (v74 >= v75)
        {
          unint64_t v56 = v74 + 1;
          if (v73 <= &v69 && (char *)v73 + 24 * v74 > (char *)&v69)
          {
            int64_t v62 = (char *)&v69 - (unsigned char *)v73;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v73, v76, v56, 24);
            BOOL v29 = (char *)v73;
            uint64_t v28 = (int *)((char *)v73 + v62);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v73, v76, v56, 24);
            uint64_t v28 = &v69;
            BOOL v29 = (char *)v73;
          }
        }
        uint64_t v30 = &v29[24 * v74];
        long long v31 = *(_OWORD *)v28;
        *((void *)v30 + 2) = *((void *)v28 + 2);
        *(_OWORD *)uint64_t v30 = v31;
        uint64_t v32 = ++v74;
        if (v72[0])
        {
          int v69 = 5;
          int64_t v70 = 0;
          uint64_t v33 = &v69;
          uint64_t v34 = (char *)v73;
          if (v32 >= v75)
          {
            unint64_t v57 = v32 + 1;
            BOOL v58 = (char *)v73 + 24 * v32 > (char *)&v69;
            if (v73 <= &v69 && v58)
            {
              int64_t v63 = (char *)&v69 - (unsigned char *)v73;
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v73, v76, v57, 24);
              uint64_t v34 = (char *)v73;
              uint64_t v33 = (int *)((char *)v73 + v63);
            }
            else
            {
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v73, v76, v57, 24);
              uint64_t v33 = &v69;
              uint64_t v34 = (char *)v73;
            }
          }
          uint64_t v35 = &v34[24 * v74];
          long long v36 = *(_OWORD *)v33;
          *((void *)v35 + 2) = *((void *)v33 + 2);
          *(_OWORD *)uint64_t v35 = v36;
          uint64_t v37 = ++v74;
          if (v72[0])
          {
            int v69 = 3;
            int64_t v70 = " must be integer/index/float type, but got ";
            uint64_t v71 = 43;
            unint64_t v38 = &v69;
            unint64_t v39 = (char *)v73;
            if (v37 >= v75)
            {
              unint64_t v59 = v37 + 1;
              BOOL v60 = (char *)v73 + 24 * v37 > (char *)&v69;
              if (v73 <= &v69 && v60)
              {
                int64_t v64 = (char *)&v69 - (unsigned char *)v73;
                llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v73, v76, v59, 24);
                unint64_t v39 = (char *)v73;
                unint64_t v38 = (int *)((char *)v73 + v64);
              }
              else
              {
                llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v73, v76, v59, 24);
                unint64_t v38 = &v69;
                unint64_t v39 = (char *)v73;
              }
            }
            BOOL v40 = &v39[24 * v74];
            long long v41 = *(_OWORD *)v38;
            *((void *)v40 + 2) = *((void *)v38 + 2);
            *(_OWORD *)BOOL v40 = v41;
            ++v74;
            if (v72[0])
            {
              uint64_t v42 = &v69;
              mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v69, v68);
              uint64_t v43 = (char *)v73;
              if (v74 >= v75)
              {
                unint64_t v61 = v74 + 1;
                if (v73 <= &v69 && (char *)v73 + 24 * v74 > (char *)&v69)
                {
                  int64_t v65 = (char *)&v69 - (unsigned char *)v73;
                  llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v73, v76, v61, 24);
                  uint64_t v43 = (char *)v73;
                  uint64_t v42 = (int *)((char *)v73 + v65);
                }
                else
                {
                  llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v73, v76, v61, 24);
                  uint64_t v42 = &v69;
                  uint64_t v43 = (char *)v73;
                }
              }
              uint64_t v44 = &v43[24 * v74];
              long long v45 = *(_OWORD *)v42;
              *((void *)v44 + 2) = *((void *)v42 + 2);
              *(_OWORD *)uint64_t v44 = v45;
              ++v74;
            }
          }
        }
      }
      char v46 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v72);
      if (v72[0]) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v72);
      }
      if (v81)
      {
        uint64_t v47 = __p;
        if (__p)
        {
          uint64_t v48 = v80;
          uint64_t v49 = __p;
          if (v80 != __p)
          {
            do
              uint64_t v48 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v48 - 1);
            while (v48 != v47);
            uint64_t v49 = __p;
          }
          BOOL v80 = v47;
          operator delete(v49);
        }
        uint64_t v50 = v77;
        if (v77)
        {
          long long v51 = v78;
          __int16 v52 = v77;
          if (v78 != v77)
          {
            do
            {
              uint64_t v54 = *--v51;
              uint64_t v53 = v54;
              *long long v51 = 0;
              if (v54) {
                MEMORY[0x21667D390](v53, 0x1000C8077774924);
              }
            }
            while (v51 != v50);
            __int16 v52 = v77;
          }
          unsigned int v78 = v50;
          operator delete(v52);
        }
        if (v73 != v76) {
          free(v73);
        }
      }
      if (!v46) {
        return 0;
      }
    }
  }
  uint64_t v16 = *(_DWORD *)(*(void *)this + 36) ? *(void *)this - 16 : 0;
  uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v16, 0);
  if (!mlir::tensor::__mlir_ods_local_type_constraint_TensorOps7(*(void *)this, (void **)(*(void *)(NextResultAtOffset + 8) & 0xFFFFFFFFFFFFFFF8), (void **)"result", 6, 0))return 0; {
  if (*(_DWORD *)(*(void *)this + 36))
  }
    uint64_t v18 = *(void *)this - 16;
  else {
    uint64_t v18 = 0;
  }
  v72[0] = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v18, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
  if (mlir::TensorType::getElementType((mlir::TensorType *)v72) == (*(void *)(*(void *)(*(void *)(*(void *)this + 72)
                                                                                           + 24)
                                                                               + 8) & 0xFFFFFFFFFFFFFFF8))
    return 1;
  v66[0] = (void **)"failed to verify that operand type matches element type of result";
  __int16 v67 = 259;
  mlir::OpState::emitOpError((uint64_t *)this, v66, (uint64_t)v72);
  uint64_t v19 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v72);
  if (v72[0]) {
    mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v72);
  }
  if (v81)
  {
    uint64_t v20 = __p;
    if (__p)
    {
      uint64_t v21 = v80;
      uint64_t v22 = __p;
      if (v80 != __p)
      {
        do
          uint64_t v21 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v21 - 1);
        while (v21 != v20);
        uint64_t v22 = __p;
      }
      BOOL v80 = v20;
      operator delete(v22);
    }
    uint64_t v23 = v77;
    if (v77)
    {
      uint64_t v24 = v78;
      uint64_t v25 = v77;
      if (v78 != v77)
      {
        do
        {
          uint64_t v27 = *--v24;
          uint64_t v26 = v27;
          *uint64_t v24 = 0;
          if (v27) {
            MEMORY[0x21667D390](v26, 0x1000C8077774924);
          }
        }
        while (v24 != v23);
        uint64_t v25 = v77;
      }
      unsigned int v78 = v23;
      operator delete(v25);
    }
    if (v73 != v76) {
      free(v73);
    }
  }
  return v19;
}

BOOL mlir::tensor::SplatOp::parse(uint64_t a1, uint64_t a2)
{
  v50[4] = *MEMORY[0x263EF8340];
  memset(v50, 0, 24);
  (*(void (**)(uint64_t))(*(void *)a1 + 40))(a1);
  if (!(*(unsigned __int8 (**)(uint64_t, void *, uint64_t))(*(void *)a1 + 672))(a1, v50, 1)) {
    return 0;
  }
  (*(void (**)(uint64_t))(*(void *)a1 + 40))(a1);
  if (!(*(unsigned __int8 (**)(uint64_t, uint64_t))(*(void *)a1 + 456))(a1, a2 + 112)) {
    return 0;
  }
  if (!(*(unsigned __int8 (**)(uint64_t))(*(void *)a1 + 104))(a1)) {
    return 0;
  }
  v40[0] = 0;
  if (!mlir::AsmParser::parseType<mlir::RankedTensorType>(a1, v40)) {
    return 0;
  }
  BOOL v4 = (void *)v40[0];
  if (*(_UNKNOWN **)(*(void *)v40[0] + 136) == &mlir::detail::TypeIDResolver<mlir::RankedTensorType,void>::id)
  {
    uint64_t v5 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*(void *)v40[0] + 8);
    v40[0] = v4;
    v40[1] = v5;
    if (mlir::CallOpInterface::getArgOperands((mlir::CallOpInterface *)v40))
    {
      uint64_t Shape = (void *)mlir::ShapedType::getShape((mlir::ShapedType *)v40);
      if (!v7)
      {
LABEL_11:
        uint64_t v9 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*v4 + 8);
        v35[0] = v4;
        v35[1] = v9;
        mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)v35);
        uint64_t v10 = *(unsigned int *)(a2 + 72);
        if (v10 >= *(_DWORD *)(a2 + 76))
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod(a2 + 64, (void *)(a2 + 80), v10 + 1, 8);
          LODWORD(v10) = *(_DWORD *)(a2 + 72);
        }
        *(void *)(*(void *)(a2 + 64) + 8 * v10) = v4;
        ++*(_DWORD *)(a2 + 72);
        v40[0] = v4;
        uint64_t ElementType = mlir::TensorType::getElementType((mlir::TensorType *)v40);
        return (*(unsigned __int8 (**)(uint64_t, void *, uint64_t, uint64_t))(*(void *)a1 + 696))(a1, v50, ElementType, a2 + 16) != 0;
      }
      uint64_t v8 = 8 * v7;
      while (*Shape != 0x8000000000000000)
      {
        ++Shape;
        v8 -= 8;
        if (!v8) {
          goto LABEL_11;
        }
      }
    }
  }
  uint64_t v14 = (*(uint64_t (**)(uint64_t))(*(void *)a1 + 16))(a1);
  __int16 v36 = 257;
  (*(void (**)(void *__return_ptr, uint64_t, uint64_t, void *))(*(void *)a1 + 24))(v40, a1, v14, v35);
  if (v40[0])
  {
    int v37 = 3;
    unint64_t v38 = "'aggregate' must be statically shaped tensor of any type values, but got ";
    uint64_t v39 = 73;
    BOOL v15 = &v37;
    uint64_t v16 = (char *)v41;
    if (v42 >= v43)
    {
      unint64_t v31 = v42 + 1;
      if (v41 <= &v37 && (char *)v41 + 24 * v42 > (char *)&v37)
      {
        int64_t v33 = (char *)&v37 - (unsigned char *)v41;
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v41, v44, v31, 24);
        uint64_t v16 = (char *)v41;
        BOOL v15 = (int *)((char *)v41 + v33);
      }
      else
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v41, v44, v31, 24);
        BOOL v15 = &v37;
        uint64_t v16 = (char *)v41;
      }
    }
    BOOL v17 = &v16[24 * v42];
    long long v18 = *(_OWORD *)v15;
    *((void *)v17 + 2) = *((void *)v15 + 2);
    *(_OWORD *)BOOL v17 = v18;
    ++v42;
    if (v40[0])
    {
      uint64_t v19 = &v37;
      mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v37, (uint64_t)v4);
      uint64_t v20 = (char *)v41;
      if (v42 >= v43)
      {
        unint64_t v32 = v42 + 1;
        if (v41 <= &v37 && (char *)v41 + 24 * v42 > (char *)&v37)
        {
          int64_t v34 = (char *)&v37 - (unsigned char *)v41;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v41, v44, v32, 24);
          uint64_t v20 = (char *)v41;
          uint64_t v19 = (int *)((char *)v41 + v34);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v41, v44, v32, 24);
          uint64_t v19 = &v37;
          uint64_t v20 = (char *)v41;
        }
      }
      uint64_t v21 = &v20[24 * v42];
      long long v22 = *(_OWORD *)v19;
      *((void *)v21 + 2) = *((void *)v19 + 2);
      *(_OWORD *)uint64_t v21 = v22;
      ++v42;
    }
  }
  uint64_t v12 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v40);
  if (v40[0]) {
    mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v40);
  }
  if (v49)
  {
    uint64_t v23 = __p;
    if (__p)
    {
      uint64_t v24 = v48;
      uint64_t v25 = __p;
      if (v48 != __p)
      {
        do
          uint64_t v24 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v24 - 1);
        while (v24 != v23);
        uint64_t v25 = __p;
      }
      uint64_t v48 = v23;
      operator delete(v25);
    }
    uint64_t v26 = v45;
    if (v45)
    {
      uint64_t v27 = v46;
      uint64_t v28 = v45;
      if (v46 != v45)
      {
        do
        {
          uint64_t v30 = *--v27;
          uint64_t v29 = v30;
          void *v27 = 0;
          if (v30) {
            MEMORY[0x21667D390](v29, 0x1000C8077774924);
          }
        }
        while (v27 != v26);
        uint64_t v28 = v45;
      }
      char v46 = v26;
      operator delete(v28);
    }
    if (v41 != v44) {
      free(v41);
    }
  }
  return v12;
}

void mlir::tensor::SplatOp::print(mlir::Operation **this, mlir::OpAsmPrinter *a2)
{
  v21[4] = *MEMORY[0x263EF8340];
  BOOL v4 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v5 = (unsigned char *)*((void *)v4 + 4);
  if ((unint64_t)v5 >= *((void *)v4 + 3))
  {
    llvm::raw_ostream::write(v4, 32);
  }
  else
  {
    *((void *)v4 + 4) = v5 + 1;
    unsigned char *v5 = 32;
  }
  (*(void (**)(mlir::OpAsmPrinter *, void))(*(void *)a2 + 160))(a2, *(void *)(*((void *)*this + 9) + 24));
  uint64_t v19 = v21;
  uint64_t v20 = 0x200000000;
  BOOL v6 = *this;
  if (*((unsigned char *)*this + 47))
  {
    unint64_t AttrDictionary = mlir::Operation::getAttrDictionary(v6);
    p_unint64_t AttrDictionary = (mlir::ArrayAttr *)&AttrDictionary;
  }
  else
  {
    p_unint64_t AttrDictionary = (mlir::Operation *)((char *)v6 + 56);
  }
  uint64_t Value = mlir::ArrayAttr::getValue(p_AttrDictionary);
  (*(void (**)(mlir::OpAsmPrinter *, uint64_t, uint64_t, void *, void))(*(void *)a2 + 192))(a2, Value, v9, v19, v20);
  uint64_t v10 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  BOOL v11 = (unsigned char *)*((void *)v10 + 4);
  if ((unint64_t)v11 >= *((void *)v10 + 3))
  {
    llvm::raw_ostream::write(v10, 32);
  }
  else
  {
    *((void *)v10 + 4) = v11 + 1;
    *BOOL v11 = 32;
  }
  uint64_t v12 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  BOOL v13 = (unsigned char *)*((void *)v12 + 4);
  if (*((unsigned char **)v12 + 3) == v13)
  {
    llvm::raw_ostream::write(v12, ":", 1uLL);
  }
  else
  {
    *BOOL v13 = 58;
    ++*((void *)v12 + 4);
  }
  uint64_t v14 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  BOOL v15 = (unsigned char *)*((void *)v14 + 4);
  if ((unint64_t)v15 >= *((void *)v14 + 3))
  {
    llvm::raw_ostream::write(v14, 32);
  }
  else
  {
    *((void *)v14 + 4) = v15 + 1;
    *BOOL v15 = 32;
  }
  if (*((_DWORD *)*this + 9)) {
    uint64_t v16 = (uint64_t)*this - 16;
  }
  else {
    uint64_t v16 = 0;
  }
  uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v16, 0);
  (*(void (**)(mlir::OpAsmPrinter *, unint64_t))(*(void *)a2 + 32))(a2, *(void *)(NextResultAtOffset + 8) & 0xFFFFFFFFFFFFFFF8);
  if (v19 != v21) {
    free(v19);
  }
}

uint64_t mlir::tensor::detail::UnPackOpGenericAdaptorBase::UnPackOpGenericAdaptorBase(uint64_t a1, uint64_t a2)
{
  uint64_t v12 = *MEMORY[0x263EF8340];
  uint64_t v3 = *(void *)(a2 + 56);
  unint64_t v4 = *(unsigned int *)(a2 + 44);
  if (HIBYTE(*(_DWORD *)(a2 + 44))) {
    uint64_t v5 = a2 + 16 * ((v4 >> 23) & 1) + 64;
  }
  else {
    uint64_t v5 = 0;
  }
  unint64_t v6 = v4 & 0x7FFFFF;
  if ((v4 & 0x7FFFFF) != 0)
  {
    uint64_t v7 = ((a2 + 16 * ((v4 >> 23) & 1) + 64 + ((v4 >> 21) & 0x7F8) + 7) & 0xFFFFFFFFFFFFFFF8)
       + 32 * *(unsigned int *)(a2 + 40);
  }
  else
  {
    uint64_t v7 = 0;
    unint64_t v6 = 0;
  }
  mlir::ValueRange::ValueRange(v11, v7, v6);
  *(void *)a1 = v3;
  *(unsigned char *)(a1 + 8) = 0;
  *(unsigned char *)(a1 + 16) = 0;
  long long v8 = *(_OWORD *)v5;
  *(void *)(a1 + 40) = *(void *)(v5 + 16);
  *(_OWORD *)(a1 + 24) = v8;
  *(_OWORD *)(a1 + 48) = *(_OWORD *)v11;
  if (v3)
  {
    uint64_t Context = mlir::Attribute::getContext((mlir::Attribute *)a1);
    if (*(unsigned char *)(a1 + 16)) {
      *(unsigned char *)(a1 + 16) = 0;
    }
    mlir::OperationName::OperationName(a1 + 8, "tensor.unpack", 13, Context);
    *(unsigned char *)(a1 + 16) = 1;
  }
  return a1;
}

uint64_t mlir::tensor::UnPackOp::getODSOperands(mlir::tensor::UnPackOp *this, unsigned int a2)
{
  if (a2)
  {
    if (a2 >= 8)
    {
      int32x4_t v4 = (int32x4_t)xmmword_211EE3A90;
      unsigned int v3 = a2 & 0xFFFFFFF8;
      int32x4_t v5 = 0uLL;
      v6.i64[0] = 0x100000001;
      v6.i64[1] = 0x100000001;
      v7.i64[0] = 0x300000003;
      v7.i64[1] = 0x300000003;
      v8.i64[0] = 0x800000008;
      v8.i64[1] = 0x800000008;
      unsigned int v9 = a2 & 0xFFFFFFF8;
      int32x4_t v10 = 0uLL;
      do
      {
        int32x4_t v5 = vsubq_s32(v5, (int32x4_t)vcgtq_u32((uint32x4_t)v4, v6));
        int32x4_t v10 = vsubq_s32(v10, (int32x4_t)vmvnq_s8((int8x16_t)vceqq_s32((int32x4_t)(*(_OWORD *)&v4 & __PAIR128__(0xFFFFFFFEFFFFFFFELL, 0xFFFFFFFEFFFFFFFELL)), v7)));
        int32x4_t v4 = vaddq_s32(v4, v8);
        v9 -= 8;
      }
      while (v9);
      int v2 = vaddvq_s32(vaddq_s32(v10, v5));
      if (v3 == a2) {
        goto LABEL_11;
      }
    }
    else
    {
      int v2 = 0;
      unsigned int v3 = 0;
    }
    do
    {
      if (v3 > 1) {
        ++v2;
      }
      ++v3;
    }
    while (a2 != v3);
  }
  else
  {
    int v2 = 0;
  }
LABEL_11:
  uint64_t v11 = *(void *)this;
  if ((*(unsigned char *)(*(void *)this + 46) & 0x80) != 0)
  {
    int v12 = *(_DWORD *)(v11 + 68);
    uint64_t v13 = *(void *)(v11 + 72);
  }
  else
  {
    int v12 = 0;
    uint64_t v13 = 0;
  }
  return v13 + 32 * (a2 + (v12 - 3) * v2);
}

uint64_t mlir::tensor::UnPackOp::setPropertiesFromAttr(uint64_t *a1, uint64_t a2, void (*a3)(void *__return_ptr, uint64_t), uint64_t a4)
{
  uint64_t v121 = *MEMORY[0x263EF8340];
  if (*(_UNKNOWN **)(*(void *)a2 + 136) == &mlir::detail::TypeIDResolver<mlir::DictionaryAttr,void>::id) {
    uint64_t v6 = a2;
  }
  else {
    uint64_t v6 = 0;
  }
  uint64_t v107 = v6;
  if (!v6)
  {
    a3(v111, a4);
    if (v111[0])
    {
      int v108 = 3;
      int v109 = "expected DictionaryAttr to set properties";
      uint64_t v110 = 41;
      BOOL v15 = &v108;
      uint64_t v16 = (char *)v112;
      if (v113 >= v114)
      {
        unint64_t v89 = v113 + 1;
        if (v112 <= &v108 && (char *)v112 + 24 * v113 > (char *)&v108)
        {
          int64_t v98 = (char *)&v108 - (unsigned char *)v112;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v112, v115, v89, 24);
          uint64_t v16 = (char *)v112;
          BOOL v15 = (int *)((char *)v112 + v98);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v112, v115, v89, 24);
          BOOL v15 = &v108;
          uint64_t v16 = (char *)v112;
        }
      }
      BOOL v17 = &v16[24 * v113];
      long long v18 = *(_OWORD *)v15;
      *((void *)v17 + 2) = *((void *)v15 + 2);
      *(_OWORD *)BOOL v17 = v18;
      ++v113;
      if (v111[0]) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v111);
      }
    }
    if (!v120) {
      return 0;
    }
    uint64_t v19 = __p;
    if (__p)
    {
      uint64_t v20 = v119;
      uint64_t v21 = __p;
      if (v119 != __p)
      {
        do
          uint64_t v20 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v20 - 1);
        while (v20 != v19);
        uint64_t v21 = __p;
      }
      unint64_t v119 = v19;
      operator delete(v21);
    }
    long long v22 = v116;
    if (!v116) {
      goto LABEL_117;
    }
    uint64_t v23 = v117;
    uint64_t v24 = v116;
    if (v117 == v116) {
      goto LABEL_116;
    }
    do
    {
      uint64_t v26 = *--v23;
      uint64_t v25 = v26;
      void *v23 = 0;
      if (v26) {
        MEMORY[0x21667D390](v25, 0x1000C8077774924);
      }
    }
    while (v23 != v22);
    goto LABEL_115;
  }
  int32x4_t v8 = (void *)mlir::DictionaryAttr::get((uint64_t)&v107, "inner_dims_pos", 0xEuLL);
  if (!v8)
  {
    a3(v111, a4);
    if (v111[0])
    {
      int v108 = 3;
      int v109 = "expected key entry for inner_dims_pos in DictionaryAttr to set Properties.";
      uint64_t v110 = 74;
      uint64_t v27 = &v108;
      uint64_t v28 = (char *)v112;
      if (v113 >= v114)
      {
        unint64_t v90 = v113 + 1;
        if (v112 <= &v108 && (char *)v112 + 24 * v113 > (char *)&v108)
        {
          int64_t v99 = (char *)&v108 - (unsigned char *)v112;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v112, v115, v90, 24);
          uint64_t v28 = (char *)v112;
          uint64_t v27 = (int *)((char *)v112 + v99);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v112, v115, v90, 24);
          uint64_t v27 = &v108;
          uint64_t v28 = (char *)v112;
        }
      }
      uint64_t v29 = &v28[24 * v113];
      long long v30 = *(_OWORD *)v27;
      *((void *)v29 + 2) = *((void *)v27 + 2);
      *(_OWORD *)uint64_t v29 = v30;
      ++v113;
      if (v111[0]) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v111);
      }
    }
    if (!v120) {
      return 0;
    }
    unint64_t v31 = __p;
    if (__p)
    {
      unint64_t v32 = v119;
      int64_t v33 = __p;
      if (v119 != __p)
      {
        do
          unint64_t v32 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v32 - 1);
        while (v32 != v31);
        int64_t v33 = __p;
      }
      unint64_t v119 = v31;
      operator delete(v33);
    }
    long long v22 = v116;
    if (!v116) {
      goto LABEL_117;
    }
    int64_t v34 = v117;
    uint64_t v24 = v116;
    if (v117 == v116) {
      goto LABEL_116;
    }
    do
    {
      uint64_t v36 = *--v34;
      uint64_t v35 = v36;
      *int64_t v34 = 0;
      if (v36) {
        MEMORY[0x21667D390](v35, 0x1000C8077774924);
      }
    }
    while (v34 != v22);
    goto LABEL_115;
  }
  uint64_t v9 = (uint64_t)v8;
  if (!mlir::detail::DenseArrayAttrImpl<long long>::classof(v8))
  {
    a3(v111, a4);
    if (v111[0])
    {
      int v108 = 3;
      uint64_t v110 = 59;
      int v37 = &v108;
      unint64_t v38 = (char *)v112;
      if (v113 >= v114)
      {
        unint64_t v91 = v113 + 1;
        if (v112 <= &v108 && (char *)v112 + 24 * v113 > (char *)&v108)
        {
          int64_t v100 = (char *)&v108 - (unsigned char *)v112;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v112, v115, v91, 24);
          unint64_t v38 = (char *)v112;
          int v37 = (int *)((char *)v112 + v100);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v112, v115, v91, 24);
          int v37 = &v108;
          unint64_t v38 = (char *)v112;
        }
      }
      uint64_t v39 = &v38[24 * v113];
      long long v40 = *(_OWORD *)v37;
      *((void *)v39 + 2) = *((void *)v37 + 2);
      *(_OWORD *)uint64_t v39 = v40;
      ++v113;
      if (v111[0])
      {
        long long v41 = &v108;
        mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v108, v9);
        unsigned int v42 = (char *)v112;
        if (v113 >= v114)
        {
          unint64_t v92 = v113 + 1;
          if (v112 <= &v108 && (char *)v112 + 24 * v113 > (char *)&v108)
          {
            int64_t v101 = (char *)&v108 - (unsigned char *)v112;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v112, v115, v92, 24);
            unsigned int v42 = (char *)v112;
            long long v41 = (int *)((char *)v112 + v101);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v112, v115, v92, 24);
            long long v41 = &v108;
            unsigned int v42 = (char *)v112;
          }
        }
        unsigned int v43 = &v42[24 * v113];
        long long v44 = *(_OWORD *)v41;
        *((void *)v43 + 2) = *((void *)v41 + 2);
        *(_OWORD *)unsigned int v43 = v44;
        ++v113;
        if (v111[0]) {
          mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v111);
        }
      }
    }
    if (!v120) {
      return 0;
    }
    long long v45 = __p;
    if (__p)
    {
      char v46 = v119;
      uint64_t v47 = __p;
      if (v119 != __p)
      {
        do
          char v46 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v46 - 1);
        while (v46 != v45);
        uint64_t v47 = __p;
      }
      unint64_t v119 = v45;
      operator delete(v47);
    }
    long long v22 = v116;
    if (!v116) {
      goto LABEL_117;
    }
    uint64_t v48 = v117;
    uint64_t v24 = v116;
    if (v117 == v116) {
      goto LABEL_116;
    }
    do
    {
      uint64_t v50 = *--v48;
      uint64_t v49 = v50;
      *uint64_t v48 = 0;
      if (v50) {
        MEMORY[0x21667D390](v49, 0x1000C8077774924);
      }
    }
    while (v48 != v22);
    goto LABEL_115;
  }
  *a1 = v9;
  int32x4_t v10 = (void *)mlir::DictionaryAttr::get((uint64_t)&v107, "outer_dims_perm", 0xFuLL);
  if (v10)
  {
    uint64_t v11 = (uint64_t)v10;
    if (!mlir::detail::DenseArrayAttrImpl<long long>::classof(v10))
    {
      a3(v111, a4);
      if (v111[0])
      {
        int v108 = 3;
        uint64_t v110 = 60;
        long long v51 = &v108;
        __int16 v52 = (char *)v112;
        if (v113 >= v114)
        {
          unint64_t v93 = v113 + 1;
          if (v112 <= &v108 && (char *)v112 + 24 * v113 > (char *)&v108)
          {
            int64_t v102 = (char *)&v108 - (unsigned char *)v112;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v112, v115, v93, 24);
            __int16 v52 = (char *)v112;
            long long v51 = (int *)((char *)v112 + v102);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v112, v115, v93, 24);
            long long v51 = &v108;
            __int16 v52 = (char *)v112;
          }
        }
        uint64_t v53 = &v52[24 * v113];
        long long v54 = *(_OWORD *)v51;
        *((void *)v53 + 2) = *((void *)v51 + 2);
        *(_OWORD *)uint64_t v53 = v54;
        ++v113;
        if (v111[0])
        {
          long long v55 = &v108;
          mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v108, v11);
          unint64_t v56 = (char *)v112;
          if (v113 >= v114)
          {
            unint64_t v96 = v113 + 1;
            if (v112 <= &v108 && (char *)v112 + 24 * v113 > (char *)&v108)
            {
              int64_t v105 = (char *)&v108 - (unsigned char *)v112;
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v112, v115, v96, 24);
              unint64_t v56 = (char *)v112;
              long long v55 = (int *)((char *)v112 + v105);
            }
            else
            {
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v112, v115, v96, 24);
              long long v55 = &v108;
              unint64_t v56 = (char *)v112;
            }
          }
          unint64_t v57 = &v56[24 * v113];
          long long v58 = *(_OWORD *)v55;
          *((void *)v57 + 2) = *((void *)v55 + 2);
          *(_OWORD *)unint64_t v57 = v58;
          ++v113;
          if (v111[0]) {
            mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v111);
          }
        }
      }
      if (!v120) {
        return 0;
      }
      unint64_t v59 = __p;
      if (__p)
      {
        BOOL v60 = v119;
        unint64_t v61 = __p;
        if (v119 != __p)
        {
          do
            BOOL v60 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v60 - 1);
          while (v60 != v59);
          unint64_t v61 = __p;
        }
        unint64_t v119 = v59;
        operator delete(v61);
      }
      long long v22 = v116;
      if (!v116) {
        goto LABEL_117;
      }
      int64_t v62 = v117;
      uint64_t v24 = v116;
      if (v117 == v116) {
        goto LABEL_116;
      }
      do
      {
        uint64_t v64 = *--v62;
        uint64_t v63 = v64;
        *int64_t v62 = 0;
        if (v64) {
          MEMORY[0x21667D390](v63, 0x1000C8077774924);
        }
      }
      while (v62 != v22);
      goto LABEL_115;
    }
    a1[1] = v11;
  }
  int v12 = (void *)mlir::DictionaryAttr::get((uint64_t)&v107, "static_inner_tiles", 0x12uLL);
  if (!v12)
  {
    a3(v111, a4);
    if (v111[0])
    {
      int v108 = 3;
      int v109 = "expected key entry for static_inner_tiles in DictionaryAttr to set Properties.";
      uint64_t v110 = 78;
      int64_t v65 = &v108;
      int64_t v66 = (char *)v112;
      if (v113 >= v114)
      {
        unint64_t v94 = v113 + 1;
        if (v112 <= &v108 && (char *)v112 + 24 * v113 > (char *)&v108)
        {
          int64_t v103 = (char *)&v108 - (unsigned char *)v112;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v112, v115, v94, 24);
          int64_t v66 = (char *)v112;
          int64_t v65 = (int *)((char *)v112 + v103);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v112, v115, v94, 24);
          int64_t v65 = &v108;
          int64_t v66 = (char *)v112;
        }
      }
      __int16 v67 = &v66[24 * v113];
      long long v68 = *(_OWORD *)v65;
      *((void *)v67 + 2) = *((void *)v65 + 2);
      *(_OWORD *)__int16 v67 = v68;
      ++v113;
      if (v111[0]) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v111);
      }
    }
    if (!v120) {
      return 0;
    }
    int v69 = __p;
    if (__p)
    {
      int64_t v70 = v119;
      uint64_t v71 = __p;
      if (v119 != __p)
      {
        do
          int64_t v70 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v70 - 1);
        while (v70 != v69);
        uint64_t v71 = __p;
      }
      unint64_t v119 = v69;
      operator delete(v71);
    }
    long long v22 = v116;
    if (!v116) {
      goto LABEL_117;
    }
    uint64_t v72 = v117;
    uint64_t v24 = v116;
    if (v117 == v116) {
      goto LABEL_116;
    }
    do
    {
      uint64_t v74 = *--v72;
      uint64_t v73 = v74;
      *uint64_t v72 = 0;
      if (v74) {
        MEMORY[0x21667D390](v73, 0x1000C8077774924);
      }
    }
    while (v72 != v22);
    goto LABEL_115;
  }
  uint64_t v13 = (uint64_t)v12;
  if (mlir::detail::DenseArrayAttrImpl<long long>::classof(v12))
  {
    a1[2] = v13;
    return 1;
  }
  a3(v111, a4);
  if (v111[0])
  {
    int v108 = 3;
    uint64_t v110 = 63;
    unsigned int v75 = &v108;
    int v76 = (char *)v112;
    if (v113 >= v114)
    {
      unint64_t v95 = v113 + 1;
      if (v112 <= &v108 && (char *)v112 + 24 * v113 > (char *)&v108)
      {
        int64_t v104 = (char *)&v108 - (unsigned char *)v112;
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v112, v115, v95, 24);
        int v76 = (char *)v112;
        unsigned int v75 = (int *)((char *)v112 + v104);
      }
      else
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v112, v115, v95, 24);
        unsigned int v75 = &v108;
        int v76 = (char *)v112;
      }
    }
    unsigned int v77 = &v76[24 * v113];
    long long v78 = *(_OWORD *)v75;
    *((void *)v77 + 2) = *((void *)v75 + 2);
    *(_OWORD *)unsigned int v77 = v78;
    ++v113;
    if (v111[0])
    {
      long long v79 = &v108;
      mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v108, v13);
      BOOL v80 = (char *)v112;
      if (v113 >= v114)
      {
        unint64_t v97 = v113 + 1;
        if (v112 <= &v108 && (char *)v112 + 24 * v113 > (char *)&v108)
        {
          int64_t v106 = (char *)&v108 - (unsigned char *)v112;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v112, v115, v97, 24);
          BOOL v80 = (char *)v112;
          long long v79 = (int *)((char *)v112 + v106);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v112, v115, v97, 24);
          long long v79 = &v108;
          BOOL v80 = (char *)v112;
        }
      }
      char v81 = &v80[24 * v113];
      long long v82 = *(_OWORD *)v79;
      *((void *)v81 + 2) = *((void *)v79 + 2);
      *(_OWORD *)char v81 = v82;
      ++v113;
      if (v111[0]) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v111);
      }
    }
  }
  if (v120)
  {
    long long v83 = __p;
    if (__p)
    {
      char v84 = v119;
      uint64_t v85 = __p;
      if (v119 != __p)
      {
        do
          char v84 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v84 - 1);
        while (v84 != v83);
        uint64_t v85 = __p;
      }
      unint64_t v119 = v83;
      operator delete(v85);
    }
    long long v22 = v116;
    if (!v116) {
      goto LABEL_117;
    }
    uint64_t v86 = v117;
    uint64_t v24 = v116;
    if (v117 == v116)
    {
LABEL_116:
      char v117 = v22;
      operator delete(v24);
LABEL_117:
      if (v112 != v115) {
        free(v112);
      }
      return 0;
    }
    do
    {
      uint64_t v88 = *--v86;
      uint64_t v87 = v88;
      *uint64_t v86 = 0;
      if (v88) {
        MEMORY[0x21667D390](v87, 0x1000C8077774924);
      }
    }
    while (v86 != v22);
LABEL_115:
    uint64_t v24 = v116;
    goto LABEL_116;
  }
  return 0;
}

uint64_t mlir::tensor::UnPackOp::getPropertiesAsAttr(mlir::DictionaryAttr *a1, uint64_t *a2)
{
  v27[6] = *MEMORY[0x263EF8340];
  uint64_t v24 = a1;
  uint64_t v25 = v27;
  uint64_t v26 = 0x300000000;
  if (!*a2)
  {
    unsigned int v8 = 0;
    uint64_t v9 = a2[1];
    if (!v9) {
      goto LABEL_10;
    }
    goto LABEL_7;
  }
  uint64_t NamedAttr = mlir::Builder::getNamedAttr(&v24, (uint64_t)"inner_dims_pos", 14, *a2);
  uint64_t v5 = v4;
  unsigned int v6 = v26;
  if (v26 >= HIDWORD(v26))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v25, v27, v26 + 1, 16);
    unsigned int v6 = v26;
  }
  int32x4_t v7 = (uint64_t *)((char *)v25 + 16 * v6);
  *int32x4_t v7 = NamedAttr;
  v7[1] = v5;
  unsigned int v8 = v26 + 1;
  LODWORD(v26) = v26 + 1;
  uint64_t v9 = a2[1];
  if (v9)
  {
LABEL_7:
    uint64_t v10 = mlir::Builder::getNamedAttr(&v24, (uint64_t)"outer_dims_perm", 15, v9);
    uint64_t v12 = v11;
    unsigned int v13 = v26;
    if (v26 >= HIDWORD(v26))
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v25, v27, v26 + 1, 16);
      unsigned int v13 = v26;
    }
    uint64_t v14 = (uint64_t *)((char *)v25 + 16 * v13);
    *uint64_t v14 = v10;
    v14[1] = v12;
    unsigned int v8 = v26 + 1;
    LODWORD(v26) = v26 + 1;
  }
LABEL_10:
  uint64_t v15 = a2[2];
  if (v15)
  {
    uint64_t v16 = mlir::Builder::getNamedAttr(&v24, (uint64_t)"static_inner_tiles", 18, v15);
    uint64_t v18 = v17;
    unsigned int v19 = v26;
    if (v26 >= HIDWORD(v26))
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v25, v27, v26 + 1, 16);
      unsigned int v19 = v26;
    }
    uint64_t v20 = (uint64_t *)((char *)v25 + 16 * v19);
    uint64_t *v20 = v16;
    v20[1] = v18;
    unsigned int v8 = v26 + 1;
    LODWORD(v26) = v26 + 1;
  }
  uint64_t v21 = v25;
  if (!v8)
  {
    uint64_t DictionaryAttr = 0;
    if (v25 == v27) {
      return DictionaryAttr;
    }
    goto LABEL_16;
  }
  uint64_t DictionaryAttr = mlir::Builder::getDictionaryAttr(&v24, (uint64_t *)v25, v8);
  uint64_t v21 = v25;
  if (v25 != v27) {
LABEL_16:
  }
    free(v21);
  return DictionaryAttr;
}

uint64_t mlir::tensor::UnPackOp::getInherentAttr(int a1, void *a2, char *__s1, size_t __n)
{
  if (__n == 18)
  {
    if (!memcmp(__s1, "static_inner_tiles", 0x12uLL)) {
      return a2[2];
    }
    return 0;
  }
  if (__n == 15)
  {
    if (!memcmp(__s1, "outer_dims_perm", 0xFuLL)) {
      return a2[1];
    }
    return 0;
  }
  if (__n != 14) {
    return 0;
  }
  if (*(void *)__s1 != 0x69645F72656E6E69 || *(void *)(__s1 + 6) != 0x736F705F736D6964) {
    return 0;
  }
  return *a2;
}

uint64_t mlir::tensor::UnPackOp::setInherentAttr(uint64_t result, char *__s1, uint64_t a3, void *a4)
{
  uint64_t v5 = (void *)result;
  if (a3 == 18)
  {
    uint64_t result = memcmp(__s1, "static_inner_tiles", 0x12uLL);
    if (!result)
    {
      if (a4)
      {
        uint64_t result = mlir::detail::DenseArrayAttrImpl<long long>::classof(a4);
        if (result) {
          int32x4_t v7 = a4;
        }
        else {
          int32x4_t v7 = 0;
        }
        v5[2] = v7;
      }
      else
      {
        v5[2] = 0;
      }
    }
  }
  else if (a3 == 15)
  {
    uint64_t result = memcmp(__s1, "outer_dims_perm", 0xFuLL);
    if (!result)
    {
      if (a4)
      {
        uint64_t result = mlir::detail::DenseArrayAttrImpl<long long>::classof(a4);
        if (result) {
          unsigned int v8 = a4;
        }
        else {
          unsigned int v8 = 0;
        }
        v5[1] = v8;
      }
      else
      {
        v5[1] = 0;
      }
    }
  }
  else if (a3 == 14 && *(void *)__s1 == 0x69645F72656E6E69 && *(void *)(__s1 + 6) == 0x736F705F736D6964)
  {
    if (a4)
    {
      uint64_t result = mlir::detail::DenseArrayAttrImpl<long long>::classof(a4);
      if (result) {
        uint64_t v9 = a4;
      }
      else {
        uint64_t v9 = 0;
      }
      void *v5 = v9;
    }
    else
    {
      *(void *)uint64_t result = 0;
    }
  }
  return result;
}

void mlir::tensor::UnPackOp::populateInherentAttrs(uint64_t a1, uint64_t *a2, uint64_t a3)
{
  if (*a2) {
    mlir::NamedAttrList::append(a3, (uint64_t)"inner_dims_pos", 14, *a2);
  }
  uint64_t v5 = a2[1];
  if (v5) {
    mlir::NamedAttrList::append(a3, (uint64_t)"outer_dims_perm", 15, v5);
  }
  uint64_t v6 = a2[2];
  if (v6)
  {
    mlir::NamedAttrList::append(a3, (uint64_t)"static_inner_tiles", 18, v6);
  }
}

BOOL mlir::tensor::UnPackOp::readProperties(uint64_t a1, uint64_t a2)
{
  unsigned int v3 = (void *)mlir::OperationState::getOrAddProperties<mlir::tensor::detail::UnPackOpGenericAdaptorBase::Properties>(a2);
  return mlir::DialectBytecodeReader::readAttribute<mlir::detail::DenseArrayAttrImpl<long long>>(a1, v3)&& mlir::DialectBytecodeReader::readOptionalAttribute<mlir::detail::DenseArrayAttrImpl<long long>>(a1, v3 + 1)&& mlir::DialectBytecodeReader::readAttribute<mlir::detail::DenseArrayAttrImpl<long long>>(a1, v3 + 2) != 0;
}

uint64_t mlir::OperationState::getOrAddProperties<mlir::tensor::detail::UnPackOpGenericAdaptorBase::Properties>(uint64_t a1)
{
  uint64_t result = *(void *)(a1 + 256);
  if (!result) {
    operator new();
  }
  return result;
}

uint64_t mlir::tensor::UnPackOp::writeProperties(uint64_t a1, uint64_t a2)
{
  if (HIBYTE(*(_DWORD *)(*(void *)a1 + 44))) {
    unsigned int v3 = (void *)(*(void *)a1 + 16 * (((unint64_t)*(unsigned int *)(*(void *)a1 + 44) >> 23) & 1) + 64);
  }
  else {
    unsigned int v3 = 0;
  }
  (*(void (**)(uint64_t, void))(*(void *)a2 + 16))(a2, *v3);
  (*(void (**)(uint64_t, void))(*(void *)a2 + 24))(a2, v3[1]);
  uint64_t v4 = v3[2];
  uint64_t v5 = *(uint64_t (**)(uint64_t, uint64_t))(*(void *)a2 + 16);

  return v5(a2, v4);
}

uint64_t mlir::tensor::UnPackOp::verifyInvariantsImpl(mlir::tensor::UnPackOp *this)
{
  uint64_t v47 = *MEMORY[0x263EF8340];
  uint64_t v2 = *(void *)this;
  if (HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
    unint64_t v3 = *(void *)this + 16 * (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 23) & 1) + 64;
  }
  else {
    unint64_t v3 = 0;
  }
  uint64_t v4 = *(void **)v3;
  if (!*(void *)v3)
  {
    v37[0] = (void **)"requires attribute 'inner_dims_pos'";
    __int16 v38 = 259;
    mlir::OpState::emitOpError((uint64_t *)this, v37, (uint64_t)v39);
    uint64_t v19 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v39);
    if (v39[0]) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v39);
    }
    if (!v46) {
      return v19;
    }
    long long v22 = __p;
    if (__p)
    {
      uint64_t v23 = v45;
      uint64_t v24 = __p;
      if (v45 != __p)
      {
        do
          uint64_t v23 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v23 - 1);
        while (v23 != v22);
        uint64_t v24 = __p;
      }
      long long v45 = v22;
      operator delete(v24);
    }
    uint64_t v25 = v42;
    if (v42)
    {
      uint64_t v26 = v43;
      uint64_t v27 = v42;
      if (v43 == v42) {
        goto LABEL_58;
      }
      do
      {
        uint64_t v29 = *--v26;
        uint64_t v28 = v29;
        *uint64_t v26 = 0;
        if (v29) {
          MEMORY[0x21667D390](v28, 0x1000C8077774924);
        }
      }
      while (v26 != v25);
LABEL_57:
      uint64_t v27 = v42;
LABEL_58:
      unsigned int v43 = v25;
      operator delete(v27);
    }
LABEL_59:
    if (v40 != &v41) {
      free(v40);
    }
    return v19;
  }
  uint64_t v5 = *(void **)(v3 + 16);
  if (!v5)
  {
    v37[0] = (void **)"requires attribute 'static_inner_tiles'";
    __int16 v38 = 259;
    mlir::OpState::emitOpError((uint64_t *)this, v37, (uint64_t)v39);
    uint64_t v19 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v39);
    if (v39[0]) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v39);
    }
    if (!v46) {
      return v19;
    }
    long long v30 = __p;
    if (__p)
    {
      unint64_t v31 = v45;
      unint64_t v32 = __p;
      if (v45 != __p)
      {
        do
          unint64_t v31 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v31 - 1);
        while (v31 != v30);
        unint64_t v32 = __p;
      }
      long long v45 = v30;
      operator delete(v32);
    }
    uint64_t v25 = v42;
    if (v42)
    {
      int64_t v33 = v43;
      uint64_t v27 = v42;
      if (v43 == v42) {
        goto LABEL_58;
      }
      do
      {
        uint64_t v35 = *--v33;
        uint64_t v34 = v35;
        *int64_t v33 = 0;
        if (v35) {
          MEMORY[0x21667D390](v34, 0x1000C8077774924);
        }
      }
      while (v33 != v25);
      goto LABEL_57;
    }
    goto LABEL_59;
  }
  uint64_t v6 = *(void **)(v3 + 8);
  v39[0] = v2;
  if (!mlir::memref::__mlir_ods_local_attr_constraint_MemRefOps12(v6, (void **)"outer_dims_perm", (const char *)0xF, (void (*)(uint64_t *__return_ptr, uint64_t))llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::__mlir_ods_local_attr_constraint_TensorOps1(mlir::Operation *,mlir::Attribute,llvm::StringRef)::$_0>, (uint64_t)v39))return 0; {
  v39[0] = *(void *)this;
  }
  if (!mlir::memref::__mlir_ods_local_attr_constraint_MemRefOps12(v4, (void **)"inner_dims_pos", (const char *)0xE, (void (*)(uint64_t *__return_ptr, uint64_t))llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::__mlir_ods_local_attr_constraint_TensorOps1(mlir::Operation *,mlir::Attribute,llvm::StringRef)::$_0>, (uint64_t)v39))return 0; {
  v39[0] = *(void *)this;
  }
  if (!mlir::memref::__mlir_ods_local_attr_constraint_MemRefOps12(v5, (void **)"static_inner_tiles", (const char *)0x12, (void (*)(uint64_t *__return_ptr, uint64_t))llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::__mlir_ods_local_attr_constraint_TensorOps1(mlir::Operation *,mlir::Attribute,llvm::StringRef)::$_0>, (uint64_t)v39)|| !mlir::tensor::__mlir_ods_local_type_constraint_TensorOps1(*(void *)this, *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"operand", (void **)7, 0))
  {
    return 0;
  }
  unsigned int v7 = 1;
  uint64_t ODSOperands = mlir::tensor::UnPackOp::getODSOperands(this, 1u);
  if (v9)
  {
    uint64_t v10 = v9;
    uint64_t v11 = 0;
    uint64_t v12 = ODSOperands + 24;
    while (mlir::tensor::__mlir_ods_local_type_constraint_TensorOps1(*(void *)this, *(void *)(*(void *)v12 + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"operand", (void **)7, (int)v11 + 1))
    {
      ++v11;
      v12 += 32;
      if (v10 == v11)
      {
        unsigned int v7 = v11 + 1;
        goto LABEL_15;
      }
    }
    return 0;
  }
LABEL_15:
  uint64_t v13 = mlir::tensor::UnPackOp::getODSOperands(this, 2u);
  if (v14)
  {
    uint64_t v15 = v14;
    uint64_t v16 = v13 + 24;
    while (mlir::memref::__mlir_ods_local_type_constraint_MemRefOps3(*(void *)this, *(void *)(*(void *)v16 + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"operand", (void **)7, v7))
    {
      ++v7;
      v16 += 32;
      if (!--v15) {
        goto LABEL_19;
      }
    }
    return 0;
  }
LABEL_19:
  uint64_t v17 = *(_DWORD *)(*(void *)this + 36) ? *(void *)this - 16 : 0;
  uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v17, 0);
  if (!mlir::tensor::__mlir_ods_local_type_constraint_TensorOps1(*(void *)this, *(void *)(NextResultAtOffset + 8) & 0xFFFFFFFFFFFFFFF8, (void **)"result", (void **)6, 0))return 0; {
  uint64_t v19 = 1;
  }
  unint64_t v20 = *(void *)(*(void *)(mlir::tensor::UnPackOp::getODSOperands(this, 1u) + 24) + 8) & 0xFFFFFFFFFFFFFFF8;
  if (*(_DWORD *)(*(void *)this + 36)) {
    uint64_t v21 = *(void *)this - 16;
  }
  else {
    uint64_t v21 = 0;
  }
  if (v20 != (*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v21, 0) + 8) & 0xFFFFFFFFFFFFFFF8))
  {
    v37[0] = (void **)"failed to verify that result type matches type of dest";
    __int16 v38 = 259;
    mlir::OpState::emitOpError((uint64_t *)this, v37, (uint64_t)v39);
    uint64_t v19 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v39);
    mlir::InFlightDiagnostic::~InFlightDiagnostic((mlir::InFlightDiagnostic *)v39);
  }
  return v19;
}

void mlir::tensor::UnPackOp::getCanonicalizationPatterns()
{
  mlir::PatternBenefit::PatternBenefit(&v0, 1);
  operator new();
}

uint64_t mlir::tensor::UnPackOp::parse(uint64_t a1, uint64_t a2)
{
  v44[4] = *MEMORY[0x263EF8340];
  memset(v44, 0, 24);
  v33[0] = (uint64_t)v44;
  v33[1] = 1;
  uint64_t v31 = 0;
  uint64_t v32 = 0;
  uint64_t v41 = v43;
  uint64_t v42 = 0x400000000;
  v29[1] = 1;
  uint64_t v30 = 0;
  memset(v40, 0, 24);
  v28[1] = 1;
  v29[0] = (uint64_t)v40;
  uint64_t __src = 0;
  uint64_t v39 = 0;
  v27[1] = 1;
  v28[0] = &v39;
  v27[0] = &__src;
  uint64_t v4 = (*(uint64_t (**)(uint64_t))(*(void *)a1 + 40))(a1);
  if (!(*(unsigned __int8 (**)(uint64_t, void *, uint64_t))(*(void *)a1 + 672))(a1, v44, 1)) {
    goto LABEL_33;
  }
  if ((*(unsigned __int8 (**)(uint64_t, const char *, uint64_t))(*(void *)a1 + 376))(a1, "outer_dims_perm", 15))
  {
    if (!(*(unsigned __int8 (**)(uint64_t))(*(void *)a1 + 136))(a1)
      || !mlir::AsmParser::parseCustomAttributeWithFallback<mlir::detail::DenseArrayAttrImpl<long long>>(a1, &v32, 0))
    {
      goto LABEL_33;
    }
    if (v32)
    {
      uint64_t v5 = mlir::OperationState::getOrAddProperties<mlir::tensor::detail::UnPackOpGenericAdaptorBase::Properties>(a2);
      *(void *)(v5 + 8) = v32;
    }
  }
  __int16 v37 = 257;
  if ((*(unsigned __int8 (**)(uint64_t, const char *, uint64_t, uint64_t *))(*(void *)a1 + 368))(a1, "inner_dims_pos", 14, &v34)&& (*(unsigned __int8 (**)(uint64_t))(*(void *)a1 + 136))(a1)&& mlir::AsmParser::parseCustomAttributeWithFallback<mlir::detail::DenseArrayAttrImpl<long long>>(a1, &v31, 0))
  {
    if (v31)
    {
      uint64_t v6 = (void *)mlir::OperationState::getOrAddProperties<mlir::tensor::detail::UnPackOpGenericAdaptorBase::Properties>(a2);
      void *v6 = v31;
    }
    __int16 v37 = 257;
    if ((*(unsigned __int8 (**)(uint64_t, const char *, uint64_t, uint64_t *))(*(void *)a1 + 368))(a1, "inner_tiles", 11, &v34))
    {
      if ((*(unsigned __int8 (**)(uint64_t))(*(void *)a1 + 136))(a1))
      {
        (*(void (**)(uint64_t))(*(void *)a1 + 40))(a1);
        uint64_t v34 = 0;
        if (mlir::parseDynamicIndexList(a1, (uint64_t)&v41, &v30, &v34, 0))
        {
          uint64_t v7 = mlir::OperationState::getOrAddProperties<mlir::tensor::detail::UnPackOpGenericAdaptorBase::Properties>(a2);
          *(void *)(v7 + 16) = v30;
          __int16 v37 = 257;
          if ((*(unsigned __int8 (**)(uint64_t, const char *, uint64_t, uint64_t *))(*(void *)a1 + 368))(a1, "into", 4, &v34))
          {
            uint64_t v8 = (*(uint64_t (**)(uint64_t))(*(void *)a1 + 40))(a1);
            if ((*(unsigned __int8 (**)(uint64_t, void *, uint64_t))(*(void *)a1 + 672))(a1, v40, 1))
            {
              v24[0] = (*(uint64_t (**)(uint64_t))(*(void *)a1 + 40))(a1);
              if ((*(unsigned __int8 (**)(uint64_t, uint64_t))(*(void *)a1 + 456))(a1, a2 + 112))
              {
                uint64_t v9 = *(void *)(a2 + 8);
                uint64_t v34 = a1;
                uint64_t v35 = v24;
                uint64_t v36 = a2;
                if (mlir::tensor::PackOp::verifyInherentAttrs(v9, a2 + 112, (void (*)(uint64_t *__return_ptr, uint64_t))llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::UnPackOp::parse(mlir::OpAsmParser &,mlir::OperationState &)::$_0>, (uint64_t)&v34))
                {
                  if ((*(unsigned __int8 (**)(uint64_t))(*(void *)a1 + 104))(a1))
                  {
                    uint64_t v34 = 0;
                    if (mlir::AsmParser::parseType<mlir::RankedTensorType>(a1, &v34))
                    {
                      uint64_t v39 = v34;
                      if ((*(unsigned __int8 (**)(uint64_t))(*(void *)a1 + 56))(a1))
                      {
                        uint64_t v34 = 0;
                        if (mlir::AsmParser::parseType<mlir::RankedTensorType>(a1, &v34))
                        {
                          uint64_t v10 = v34;
                          uint64_t __src = v34;
                          uint64_t v26 = v34;
                          if (*(_UNKNOWN **)(*(void *)v34 + 136) != &mlir::detail::TypeIDResolver<mlir::RankedTensorType,void>::id)
                          {
                            uint64_t v11 = (*(uint64_t (**)(uint64_t))(*(void *)a1 + 16))(a1);
                            __int16 v25 = 257;
                            (*(void (**)(uint64_t *__return_ptr, uint64_t, uint64_t, void *))(*(void *)a1 + 24))(&v34, a1, v11, v24);
                            uint64_t v12 = mlir::InFlightDiagnostic::operator<<<char const(&)[44]>((uint64_t)&v34, "'dest' must be ranked tensor of any type values, but got ");
                            uint64_t v13 = mlir::InFlightDiagnostic::append<mlir::Type &>(v12, &v26);
                            uint64_t v14 = mlir::InFlightDiagnostic::operator mlir::LogicalResult(v13);
                            mlir::InFlightDiagnostic::~InFlightDiagnostic((mlir::InFlightDiagnostic *)&v34);
                            uint64_t v15 = v41;
                            if (v41 == v43) {
                              return v14;
                            }
                            goto LABEL_35;
                          }
                          uint64_t v16 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*(void *)v34 + 8);
                          uint64_t v34 = v10;
                          uint64_t v35 = (void *)v16;
                          mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&v34);
                          uint64_t v17 = (mlir::IndexType **)(*(uint64_t (**)(uint64_t))(*(void *)a1 + 32))(a1);
                          uint64_t IndexType = mlir::Builder::getIndexType(v17, v18);
                          mlir::OperationState::addTypes(a2, &__src, 1);
                          uint64_t v19 = a2 + 16;
                          if (mlir::OpAsmParser::resolveOperands<llvm::ArrayRef<mlir::OpAsmParser::UnresolvedOperand> &,llvm::ArrayRef<mlir::Type> &>(a1, v33, v28, v4, v19))
                          {
                            if (mlir::OpAsmParser::resolveOperands<llvm::ArrayRef<mlir::OpAsmParser::UnresolvedOperand> &,llvm::ArrayRef<mlir::Type> &>(a1, v29, v27, v8, v19))
                            {
                              if (!v42)
                              {
                                uint64_t v14 = 1;
                                uint64_t v15 = v41;
                                if (v41 == v43) {
                                  return v14;
                                }
                                goto LABEL_35;
                              }
                              unint64_t v20 = v41;
                              uint64_t v21 = 32 * v42;
                              uint64_t v14 = 1;
                              while ((*(unsigned __int8 (**)(uint64_t, unsigned char *, uint64_t, uint64_t))(*(void *)a1 + 696))(a1, v20, IndexType, v19))
                              {
                                v20 += 32;
                                v21 -= 32;
                                if (!v21) {
                                  goto LABEL_34;
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          }
        }
      }
    }
  }
LABEL_33:
  uint64_t v14 = 0;
LABEL_34:
  uint64_t v15 = v41;
  if (v41 != v43) {
LABEL_35:
  }
    free(v15);
  return v14;
}

void mlir::tensor::UnPackOp::print(mlir::tensor::UnPackOp *this, mlir::OpAsmPrinter *a2)
{
  v82[2] = *MEMORY[0x263EF8340];
  uint64_t v4 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v5 = (unsigned char *)*((void *)v4 + 4);
  if ((unint64_t)v5 >= *((void *)v4 + 3))
  {
    llvm::raw_ostream::write(v4, 32);
  }
  else
  {
    *((void *)v4 + 4) = v5 + 1;
    unsigned char *v5 = 32;
  }
  (*(void (**)(mlir::OpAsmPrinter *, void))(*(void *)a2 + 160))(a2, *(void *)(*(void *)(*(void *)this + 72) + 24));
  unint64_t v6 = *(void *)this + 16 * (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 23) & 1) + 64;
  if (!HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
    unint64_t v6 = 0;
  }
  if (*(void *)(v6 + 8))
  {
    uint64_t v7 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
    uint64_t v8 = (unsigned char *)*((void *)v7 + 4);
    if ((unint64_t)v8 >= *((void *)v7 + 3))
    {
      llvm::raw_ostream::write(v7, 32);
    }
    else
    {
      *((void *)v7 + 4) = v8 + 1;
      *uint64_t v8 = 32;
    }
    uint64_t v9 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
    uint64_t v10 = (void *)*((void *)v9 + 4);
    if (*((void *)v9 + 3) - (void)v10 > 0xEuLL)
    {
      qmemcpy(v10, "outer_dims_perm", 15);
      *((void *)v9 + 4) += 15;
    }
    else
    {
      llvm::raw_ostream::write(v9, "outer_dims_perm", 0xFuLL);
    }
    uint64_t v11 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
    uint64_t v12 = (unsigned char *)*((void *)v11 + 4);
    if ((unint64_t)v12 >= *((void *)v11 + 3))
    {
      llvm::raw_ostream::write(v11, 32);
    }
    else
    {
      *((void *)v11 + 4) = v12 + 1;
      *uint64_t v12 = 32;
    }
    uint64_t v13 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
    uint64_t v14 = (unsigned char *)*((void *)v13 + 4);
    if (*((unsigned char **)v13 + 3) == v14)
    {
      llvm::raw_ostream::write(v13, "=", 1uLL);
    }
    else
    {
      *uint64_t v14 = 61;
      ++*((void *)v13 + 4);
    }
    uint64_t v15 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
    uint64_t v16 = (unsigned char *)*((void *)v15 + 4);
    if ((unint64_t)v16 >= *((void *)v15 + 3))
    {
      llvm::raw_ostream::write(v15, 32);
    }
    else
    {
      *((void *)v15 + 4) = v16 + 1;
      *uint64_t v16 = 32;
    }
    unint64_t v17 = *(void *)this + 16 * (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 23) & 1) + 64;
    if (!HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
      unint64_t v17 = 0;
    }
    long long v79 = *(void **)(v17 + 8);
    if (!(*(unsigned __int8 (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 104))(a2))
    {
      uint64_t v18 = (void *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
      uint64_t v19 = (*(uint64_t (**)(void *))(*v18 + 80))(v18) + v18[4] - v18[2];
      mlir::detail::DenseArrayAttrImpl<long long>::print((llvm::raw_ostream *)&v79, (uint64_t)a2);
      if (v19 == (*(uint64_t (**)(void *))(*v18 + 80))(v18) + v18[4] - v18[2]) {
        (*(void (**)(mlir::OpAsmPrinter *, void *))(*(void *)a2 + 40))(a2, v79);
      }
    }
  }
  unint64_t v20 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v21 = (unsigned char *)*((void *)v20 + 4);
  if ((unint64_t)v21 >= *((void *)v20 + 3))
  {
    llvm::raw_ostream::write(v20, 32);
  }
  else
  {
    *((void *)v20 + 4) = v21 + 1;
    *uint64_t v21 = 32;
  }
  long long v22 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v23 = (void *)*((void *)v22 + 4);
  if (*((void *)v22 + 3) - (void)v23 > 0xDuLL)
  {
    qmemcpy(v23, "inner_dims_pos", 14);
    *((void *)v22 + 4) += 14;
  }
  else
  {
    llvm::raw_ostream::write(v22, "inner_dims_pos", 0xEuLL);
  }
  uint64_t v24 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  __int16 v25 = (unsigned char *)*((void *)v24 + 4);
  if ((unint64_t)v25 >= *((void *)v24 + 3))
  {
    llvm::raw_ostream::write(v24, 32);
  }
  else
  {
    *((void *)v24 + 4) = v25 + 1;
    unsigned char *v25 = 32;
  }
  uint64_t v26 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v27 = (unsigned char *)*((void *)v26 + 4);
  if (*((unsigned char **)v26 + 3) == v27)
  {
    llvm::raw_ostream::write(v26, "=", 1uLL);
  }
  else
  {
    unsigned char *v27 = 61;
    ++*((void *)v26 + 4);
  }
  uint64_t v28 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v29 = (unsigned char *)*((void *)v28 + 4);
  if ((unint64_t)v29 >= *((void *)v28 + 3))
  {
    llvm::raw_ostream::write(v28, 32);
  }
  else
  {
    *((void *)v28 + 4) = v29 + 1;
    unsigned char *v29 = 32;
  }
  long long v79 = *(void **)(*(void *)this + 16 * (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 23) & 1) + 64);
  if (!(*(unsigned __int8 (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 104))(a2))
  {
    uint64_t v30 = (void *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
    uint64_t v31 = (*(uint64_t (**)(void *))(*v30 + 80))(v30) + v30[4] - v30[2];
    mlir::detail::DenseArrayAttrImpl<long long>::print((llvm::raw_ostream *)&v79, (uint64_t)a2);
    if (v31 == (*(uint64_t (**)(void *))(*v30 + 80))(v30) + v30[4] - v30[2]) {
      (*(void (**)(mlir::OpAsmPrinter *, void *))(*(void *)a2 + 40))(a2, v79);
    }
  }
  uint64_t v32 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  int64_t v33 = (unsigned char *)*((void *)v32 + 4);
  if ((unint64_t)v33 >= *((void *)v32 + 3))
  {
    llvm::raw_ostream::write(v32, 32);
  }
  else
  {
    *((void *)v32 + 4) = v33 + 1;
    *int64_t v33 = 32;
  }
  uint64_t v34 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v35 = *((void *)v34 + 4);
  if ((unint64_t)(*((void *)v34 + 3) - v35) > 0xA)
  {
    *(_DWORD *)(v35 + 7) = 1936026729;
    *(void *)uint64_t v35 = *(void *)"inner_tiles";
    *((void *)v34 + 4) += 11;
  }
  else
  {
    llvm::raw_ostream::write(v34, "inner_tiles", 0xBuLL);
  }
  uint64_t v36 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  __int16 v37 = (unsigned char *)*((void *)v36 + 4);
  if ((unint64_t)v37 >= *((void *)v36 + 3))
  {
    llvm::raw_ostream::write(v36, 32);
  }
  else
  {
    *((void *)v36 + 4) = v37 + 1;
    unsigned char *v37 = 32;
  }
  __int16 v38 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v39 = (unsigned char *)*((void *)v38 + 4);
  if (*((unsigned char **)v38 + 3) == v39)
  {
    llvm::raw_ostream::write(v38, "=", 1uLL);
  }
  else
  {
    *uint64_t v39 = 61;
    ++*((void *)v38 + 4);
  }
  long long v40 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v41 = (unsigned char *)*((void *)v40 + 4);
  if ((unint64_t)v41 >= *((void *)v40 + 3))
  {
    llvm::raw_ostream::write(v40, 32);
  }
  else
  {
    *((void *)v40 + 4) = v41 + 1;
    *uint64_t v41 = 32;
  }
  uint64_t v42 = *(void *)this;
  unint64_t v43 = *(unsigned int *)(*(void *)this + 44);
  if ((v43 & 0x800000) != 0)
  {
    uint64_t v44 = *(void *)(v42 + 72);
    uint64_t v45 = *(unsigned int *)(v42 + 68) - 2;
  }
  else
  {
    uint64_t v44 = 0;
    uint64_t v45 = -2;
  }
  uint64_t v46 = v44 + 64;
  if (HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
    uint64_t v47 = v42 + 16 * ((v43 >> 23) & 1) + 64;
  }
  else {
    uint64_t v47 = 0;
  }
  long long v79 = *(void **)(v47 + 16);
  uint64_t v48 = (unint64_t *)mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)&v79);
  uint64_t v50 = v49;
  mlir::ValueRange::ValueRange(v82, 0, 0);
  mlir::printDynamicIndexList((uint64_t)a2, v42, v46, v45, v48, v50, v82[0], v82[1], 0, 0, 2);
  long long v51 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  __int16 v52 = (unsigned char *)*((void *)v51 + 4);
  if ((unint64_t)v52 >= *((void *)v51 + 3))
  {
    llvm::raw_ostream::write(v51, 32);
  }
  else
  {
    *((void *)v51 + 4) = v52 + 1;
    unsigned char *v52 = 32;
  }
  uint64_t v53 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  long long v54 = (_DWORD *)*((void *)v53 + 4);
  if (*((void *)v53 + 3) - (void)v54 > 3uLL)
  {
    *long long v54 = 1869901417;
    *((void *)v53 + 4) += 4;
  }
  else
  {
    llvm::raw_ostream::write(v53, "into", 4uLL);
  }
  long long v55 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  unint64_t v56 = (unsigned char *)*((void *)v55 + 4);
  if ((unint64_t)v56 >= *((void *)v55 + 3))
  {
    llvm::raw_ostream::write(v55, 32);
  }
  else
  {
    *((void *)v55 + 4) = v56 + 1;
    *unint64_t v56 = 32;
  }
  (*(void (**)(mlir::OpAsmPrinter *, void))(*(void *)a2 + 160))(a2, *(void *)(*(void *)(*(void *)this + 72) + 56));
  long long v79 = v81;
  v81[0] = "outer_dims_perm";
  v81[1] = 15;
  v81[2] = "inner_dims_pos";
  v81[3] = 14;
  uint64_t v80 = 0x200000002;
  llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v79, v81, 3uLL, 16);
  unint64_t v57 = (char *)v79 + 16 * v80;
  *unint64_t v57 = "static_inner_tiles";
  v57[1] = 18;
  LODWORD(v80) = v80 + 1;
  uint64_t Context = (mlir::MLIRContext *)mlir::Attribute::getContext((mlir::Attribute *)(*(void *)this + 24));
  unint64_t v58 = *(void *)this + 16 * (((unint64_t)*(unsigned int *)(*(void *)this + 44) >> 23) & 1) + 64;
  if (!HIBYTE(*(_DWORD *)(*(void *)this + 44))) {
    unint64_t v58 = 0;
  }
  uint64_t v59 = *(void *)(v58 + 8);
  if (v59 && v59 == mlir::Builder::getDenseI64ArrayAttr(&Context, 0, 0))
  {
    unsigned int v62 = v80;
    if (v80 >= HIDWORD(v80))
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v79, v81, v80 + 1, 16);
      unsigned int v62 = v80;
    }
    uint64_t v63 = (char *)v79 + 16 * v62;
    *uint64_t v63 = "outer_dims_perm";
    v63[1] = 15;
    LODWORD(v80) = v80 + 1;
    BOOL v60 = *(mlir::Operation **)this;
    if (!*(unsigned char *)(*(void *)this + 47)) {
      goto LABEL_79;
    }
  }
  else
  {
    BOOL v60 = *(mlir::Operation **)this;
    if (!*(unsigned char *)(*(void *)this + 47))
    {
LABEL_79:
      p_uint64_t Context = (mlir::Operation *)((char *)v60 + 56);
      goto LABEL_84;
    }
  }
  uint64_t Context = (mlir::MLIRContext *)mlir::Operation::getAttrDictionary(v60);
  p_uint64_t Context = (mlir::ArrayAttr *)&Context;
LABEL_84:
  uint64_t Value = mlir::ArrayAttr::getValue(p_Context);
  (*(void (**)(mlir::OpAsmPrinter *, uint64_t, uint64_t, void *, void))(*(void *)a2 + 192))(a2, Value, v65, v79, v80);
  int64_t v66 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  __int16 v67 = (unsigned char *)*((void *)v66 + 4);
  if ((unint64_t)v67 >= *((void *)v66 + 3))
  {
    llvm::raw_ostream::write(v66, 32);
  }
  else
  {
    *((void *)v66 + 4) = v67 + 1;
    *__int16 v67 = 32;
  }
  long long v68 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  int v69 = (unsigned char *)*((void *)v68 + 4);
  if (*((unsigned char **)v68 + 3) == v69)
  {
    llvm::raw_ostream::write(v68, ":", 1uLL);
  }
  else
  {
    *int v69 = 58;
    ++*((void *)v68 + 4);
  }
  int64_t v70 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v71 = (unsigned char *)*((void *)v70 + 4);
  if ((unint64_t)v71 >= *((void *)v70 + 3))
  {
    llvm::raw_ostream::write(v70, 32);
  }
  else
  {
    *((void *)v70 + 4) = v71 + 1;
    *uint64_t v71 = 32;
  }
  (*(void (**)(mlir::OpAsmPrinter *, unint64_t))(*(void *)a2 + 32))(a2, *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8);
  uint64_t v72 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  uint64_t v73 = (unsigned char *)*((void *)v72 + 4);
  if ((unint64_t)v73 >= *((void *)v72 + 3))
  {
    llvm::raw_ostream::write(v72, 32);
  }
  else
  {
    *((void *)v72 + 4) = v73 + 1;
    *uint64_t v73 = 32;
  }
  uint64_t v74 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  unsigned int v75 = (_WORD *)*((void *)v74 + 4);
  if (*((void *)v74 + 3) - (void)v75 > 1uLL)
  {
    *unsigned int v75 = 15917;
    *((void *)v74 + 4) += 2;
  }
  else
  {
    llvm::raw_ostream::write(v74, "->", 2uLL);
  }
  int v76 = (llvm::raw_ostream *)(*(uint64_t (**)(mlir::OpAsmPrinter *))(*(void *)a2 + 16))(a2);
  unsigned int v77 = (unsigned char *)*((void *)v76 + 4);
  if ((unint64_t)v77 >= *((void *)v76 + 3))
  {
    llvm::raw_ostream::write(v76, 32);
  }
  else
  {
    *((void *)v76 + 4) = v77 + 1;
    *unsigned int v77 = 32;
  }
  (*(void (**)(mlir::OpAsmPrinter *, unint64_t))(*(void *)a2 + 32))(a2, *(void *)(*(void *)(*(void *)(*(void *)this + 72) + 56) + 8) & 0xFFFFFFFFFFFFFFF8);
  if (v79 != v81) {
    free(v79);
  }
}

BOOL mlir::tensor::YieldOp::parse(uint64_t a1, uint64_t a2)
{
  void v10[4] = *MEMORY[0x263EF8340];
  memset(v10, 0, 24);
  v8[0] = (uint64_t)v10;
  v8[1] = 1;
  uint64_t v9 = 0;
  v7[0] = &v9;
  v7[1] = 1;
  uint64_t v4 = (*(uint64_t (**)(uint64_t))(*(void *)a1 + 40))(a1);
  if (!(*(unsigned __int8 (**)(uint64_t, void *, uint64_t))(*(void *)a1 + 672))(a1, v10, 1)) {
    return 0;
  }
  (*(void (**)(uint64_t))(*(void *)a1 + 40))(a1);
  if (!(*(unsigned __int8 (**)(uint64_t, uint64_t))(*(void *)a1 + 456))(a1, a2 + 112)) {
    return 0;
  }
  if (!(*(unsigned __int8 (**)(uint64_t))(*(void *)a1 + 104))(a1)) {
    return 0;
  }
  uint64_t v6 = 0;
  if (!(*(unsigned __int8 (**)(uint64_t, uint64_t *))(*(void *)a1 + 504))(a1, &v6)) {
    return 0;
  }
  uint64_t v9 = v6;
  return mlir::OpAsmParser::resolveOperands<llvm::ArrayRef<mlir::OpAsmParser::UnresolvedOperand> &,llvm::ArrayRef<mlir::Type> &>(a1, v8, v7, v4, a2 + 16) != 0;
}

BOOL llvm::function_ref<BOOL ()(mlir::OpFoldResult,mlir::OpFoldResult)>::callback_fn<foldExtractAfterInsertSlice(mlir::tensor::ExtractSliceOp)::$_0>(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return a2 == a3;
}

BOOL llvm::function_ref<BOOL ()(mlir::OpFoldResult,mlir::OpFoldResult)>::callback_fn<foldInsertAfterInsertSlice(mlir::tensor::InsertSliceOp)::$_0>(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return a2 == a3;
}

BOOL llvm::function_ref<BOOL ()(mlir::OpFoldResult,mlir::OpFoldResult)>::callback_fn<foldInsertAfterExtractSlice(mlir::tensor::InsertSliceOp)::$_0>(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return a2 == a3;
}

uint64_t mlir::Dialect::getRegisteredInterfaceForOp<mlir::ParallelCombiningOpInterface>(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = a2;
  unint64_t v3 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
  {
    uint64_t v15 = a1;
    unint64_t v3 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
    int v6 = v5;
    uint64_t v2 = a2;
    a1 = v15;
    if (v6)
    {
      uint64_t v16 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ParallelCombiningOpInterface]";
      unint64_t v17 = 84;
      unint64_t v7 = llvm::StringRef::find((uint64_t *)&v16, "DesiredTypeName = ", 0x12uLL, 0);
      if (v17 >= v7) {
        unint64_t v8 = v7;
      }
      else {
        unint64_t v8 = v17;
      }
      uint64_t v9 = &v16[v8];
      unint64_t v10 = v17 - v8;
      if (v17 - v8 >= 0x12) {
        uint64_t v11 = 18;
      }
      else {
        uint64_t v11 = v17 - v8;
      }
      unint64_t v12 = v10 - v11;
      if (v12 >= v12 - 1) {
        uint64_t v13 = v12 - 1;
      }
      else {
        uint64_t v13 = v12;
      }
      mlir::detail::TypeIDResolver<mlir::ParallelCombiningOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v9[v11], v13);
      unint64_t v3 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
      uint64_t v2 = a2;
      a1 = v15;
    }
  }
  return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t))(*(void *)a1 + 104))(a1, v3[150], v2);
}

uint64_t mlir::detail::InterfaceMap::lookup<mlir::ParallelCombiningOpInterface>(uint64_t a1)
{
  uint64_t v1 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
  {
    uint64_t v20 = a1;
    uint64_t v1 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
    int v12 = v11;
    a1 = v20;
    if (v12)
    {
      uint64_t v21 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ParallelCombiningOpInterface]";
      unint64_t v22 = 84;
      unint64_t v13 = llvm::StringRef::find((uint64_t *)&v21, "DesiredTypeName = ", 0x12uLL, 0);
      if (v22 >= v13) {
        unint64_t v14 = v13;
      }
      else {
        unint64_t v14 = v22;
      }
      uint64_t v15 = &v21[v14];
      unint64_t v16 = v22 - v14;
      if (v22 - v14 >= 0x12) {
        uint64_t v17 = 18;
      }
      else {
        uint64_t v17 = v22 - v14;
      }
      unint64_t v18 = v16 - v17;
      if (v18 >= v18 - 1) {
        uint64_t v19 = v18 - 1;
      }
      else {
        uint64_t v19 = v18;
      }
      mlir::detail::TypeIDResolver<mlir::ParallelCombiningOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v15[v17], v19);
      uint64_t v1 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
      a1 = v20;
    }
  }
  unint64_t v2 = *(unsigned int *)(a1 + 8);
  if (!v2) {
    return 0;
  }
  unint64_t v3 = v1[150];
  uint64_t v4 = *(void **)a1;
  uint64_t v5 = *(void *)a1 + 16 * v2;
  do
  {
    unint64_t v6 = v2 >> 1;
    unint64_t v7 = &v4[2 * (v2 >> 1)];
    unint64_t v9 = *v7;
    unint64_t v8 = v7 + 2;
    v2 += ~(v2 >> 1);
    if (v9 < v3) {
      uint64_t v4 = v8;
    }
    else {
      unint64_t v2 = v6;
    }
  }
  while (v2);
  if (v4 != (void *)v5 && *v4 == v3) {
    return v4[1];
  }
  else {
    return 0;
  }
}

void llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::__mlir_ods_local_attr_constraint_TensorOps0(mlir::Operation *,mlir::Attribute,llvm::StringRef)::$_0>(uint64_t *a1@<X0>, uint64_t a2@<X8>)
{
  uint64_t v2 = *a1;
  __int16 v4 = 257;
  mlir::Operation::emitOpError(v2, &v3, a2);
}

void llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::__mlir_ods_local_attr_constraint_TensorOps1(mlir::Operation *,mlir::Attribute,llvm::StringRef)::$_0>(uint64_t *a1@<X0>, uint64_t a2@<X8>)
{
  uint64_t v2 = *a1;
  __int16 v4 = 257;
  mlir::Operation::emitOpError(v2, &v3, a2);
}

void llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::__mlir_ods_local_attr_constraint_TensorOps2(mlir::Operation *,mlir::Attribute,llvm::StringRef)::$_0>(uint64_t *a1@<X0>, uint64_t a2@<X8>)
{
  uint64_t v2 = *a1;
  __int16 v4 = 257;
  mlir::Operation::emitOpError(v2, &v3, a2);
}

void mlir::OpBuilder::createOrFold<mlir::tensor::DimOp,mlir::Value &,long long &>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t *a4, mlir::MLIRContext **a5)
{
  v27[38] = *MEMORY[0x263EF8340];
  uint64_t v22 = a3;
  uint64_t Context = (uint64_t *)mlir::Attribute::getContext((mlir::Attribute *)&v22);
  uint64_t v11 = mlir::RegisteredOperationName::lookup((int8x16_t *)"tensor.dim", (const unsigned __int8 *)0xA, Context);
  if (!v12)
  {
    __int16 v26 = 1283;
    uint64_t v25[2] = (mlir::MLIRContext *)"tensor.dim";
    void v25[3] = (mlir::MLIRContext *)10;
          " the dialect. See also https://mlir.llvm.org/getting_started/Faq/#registered-loaded-dependent-whats-up-with-di"
          "alects-management";
    __int16 v24 = 259;
    llvm::operator+((uint64_t *)v25, (uint64_t *)&v23, (uint64_t)v27);
    llvm::report_fatal_error((llvm::Twine *)v27, 1);
  }
  mlir::OperationState::OperationState(v27, a3, v11);
  uint64_t v13 = *a4;
  v25[0] = *a5;
  unint64_t v14 = mlir::OpBuilder::create<mlir::arith::ConstantIndexOp,long long>((mlir::IndexType **)a1, v27[0], v25);
  mlir::tensor::DimOp::build((mlir::IndexType **)a1, (uint64_t)v27, v13, (uint64_t)v14 - 16);
  unint64_t v16 = (ZinIrHalH13g *)mlir::Operation::create((mlir::Operation *)v27, v15);
  uint64_t v17 = *(void *)(a1 + 16);
  if (v17)
  {
    unint64_t v18 = *(uint64_t **)(a1 + 24);
    llvm::ilist_traits<mlir::Operation>::addNodeToList(v17 + 32, (uint64_t)v16);
    ZinIrHalH13g::~ZinIrHalH13g(v16);
    uint64_t v19 = *v18;
    uint64_t *v20 = *v18;
    v20[1] = (uint64_t)v18;
    *(void *)(v19 + 8) = v20;
    *unint64_t v18 = (uint64_t)v20;
    ZinIrHalH13g::~ZinIrHalH13g(v16);
  }
  if (mlir::OpBuilder::tryFold((void *)a1, (uint64_t)v16, a2))
  {
    mlir::Operation::erase(v16);
  }
  else
  {
    uint64_t v21 = *(void *)(a1 + 8);
    if (v21) {
      (*(void (**)(uint64_t, ZinIrHalH13g *))(*(void *)v21 + 16))(v21, v16);
    }
  }
  mlir::OperationState::~OperationState((mlir::OperationState *)v27);
}

uint64_t llvm::DefaultDoCastIfPossible<mlir::DestinationStyleOpInterface,mlir::Operation *,llvm::CastInfo<mlir::DestinationStyleOpInterface,mlir::Operation *,void>>::doCastIfPossible(uint64_t a1)
{
  uint64_t v1 = a1;
  uint64_t v2 = *(void *)(a1 + 48);
  unint64_t v3 = *(void **)(v2 + 16);
  BOOL v4 = v3 == &mlir::detail::TypeIDResolver<void,void>::id;
  if (v3 == &mlir::detail::TypeIDResolver<void,void>::id) {
    uint64_t v5 = 0;
  }
  else {
    uint64_t v5 = *(void *)(a1 + 48);
  }
  if (v4)
  {
    uint64_t v16 = *(void *)(v2 + 8);
    uint64_t Values = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)&v16);
    if (!Values || !mlir::Dialect::getRegisteredInterfaceForOp<mlir::DestinationStyleOpInterface>(Values, v2)) {
      return 0;
    }
  }
  else
  {
    unint64_t v6 = v5 | v2 & 0xFFFFFFFFFFFFFF00;
    if (!mlir::detail::InterfaceMap::lookup<mlir::DestinationStyleOpInterface>(v6 + 32)
      && !mlir::Dialect::getRegisteredInterfaceForOp<mlir::DestinationStyleOpInterface>(*(void *)(v6 + 24), *(void *)(v1 + 48)))
    {
      return 0;
    }
  }
  uint64_t v8 = *(void *)(v1 + 48);
  unint64_t v9 = *(void **)(v8 + 16);
  BOOL v10 = v9 == &mlir::detail::TypeIDResolver<void,void>::id;
  if (v9 == &mlir::detail::TypeIDResolver<void,void>::id) {
    uint64_t v11 = 0;
  }
  else {
    uint64_t v11 = *(void *)(v1 + 48);
  }
  if (v10)
  {
    uint64_t v16 = *(void *)(v8 + 8);
    uint64_t v14 = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)&v16);
    if (!v14) {
      return v1;
    }
    uint64_t v15 = v8;
  }
  else
  {
    unint64_t v12 = v11 | v8 & 0xFFFFFFFFFFFFFF00;
    if (mlir::detail::InterfaceMap::lookup<mlir::DestinationStyleOpInterface>(v12 + 32)) {
      return v1;
    }
    uint64_t v14 = *(void *)(v12 + 24);
    uint64_t v15 = *(void *)(v1 + 48);
  }
  mlir::Dialect::getRegisteredInterfaceForOp<mlir::DestinationStyleOpInterface>(v14, v15);
  return v1;
}

uint64_t mlir::Dialect::getRegisteredInterfaceForOp<mlir::DestinationStyleOpInterface>(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = a2;
  unint64_t v3 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
  {
    uint64_t v15 = a1;
    unint64_t v3 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
    int v6 = v5;
    uint64_t v2 = a2;
    a1 = v15;
    if (v6)
    {
      uint64_t v16 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::DestinationStyleOpInterface]";
      unint64_t v17 = 83;
      unint64_t v7 = llvm::StringRef::find((uint64_t *)&v16, "DesiredTypeName = ", 0x12uLL, 0);
      if (v17 >= v7) {
        unint64_t v8 = v7;
      }
      else {
        unint64_t v8 = v17;
      }
      unint64_t v9 = &v16[v8];
      unint64_t v10 = v17 - v8;
      if (v17 - v8 >= 0x12) {
        uint64_t v11 = 18;
      }
      else {
        uint64_t v11 = v17 - v8;
      }
      unint64_t v12 = v10 - v11;
      if (v12 >= v12 - 1) {
        uint64_t v13 = v12 - 1;
      }
      else {
        uint64_t v13 = v12;
      }
      mlir::detail::TypeIDResolver<mlir::DestinationStyleOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v9[v11], v13);
      unint64_t v3 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
      uint64_t v2 = a2;
      a1 = v15;
    }
  }
  return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t))(*(void *)a1 + 104))(a1, v3[134], v2);
}

uint64_t mlir::detail::InterfaceMap::lookup<mlir::DestinationStyleOpInterface>(uint64_t a1)
{
  uint64_t v1 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
  {
    uint64_t v20 = a1;
    uint64_t v1 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
    int v12 = v11;
    a1 = v20;
    if (v12)
    {
      uint64_t v21 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::DestinationStyleOpInterface]";
      unint64_t v22 = 83;
      unint64_t v13 = llvm::StringRef::find((uint64_t *)&v21, "DesiredTypeName = ", 0x12uLL, 0);
      if (v22 >= v13) {
        unint64_t v14 = v13;
      }
      else {
        unint64_t v14 = v22;
      }
      uint64_t v15 = &v21[v14];
      unint64_t v16 = v22 - v14;
      if (v22 - v14 >= 0x12) {
        uint64_t v17 = 18;
      }
      else {
        uint64_t v17 = v22 - v14;
      }
      unint64_t v18 = v16 - v17;
      if (v18 >= v18 - 1) {
        uint64_t v19 = v18 - 1;
      }
      else {
        uint64_t v19 = v18;
      }
      mlir::detail::TypeIDResolver<mlir::DestinationStyleOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v15[v17], v19);
      uint64_t v1 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
      a1 = v20;
    }
  }
  unint64_t v2 = *(unsigned int *)(a1 + 8);
  if (!v2) {
    return 0;
  }
  unint64_t v3 = v1[134];
  BOOL v4 = *(void **)a1;
  uint64_t v5 = *(void *)a1 + 16 * v2;
  do
  {
    unint64_t v6 = v2 >> 1;
    unint64_t v7 = &v4[2 * (v2 >> 1)];
    unint64_t v9 = *v7;
    unint64_t v8 = v7 + 2;
    v2 += ~(v2 >> 1);
    if (v9 < v3) {
      BOOL v4 = v8;
    }
    else {
      unint64_t v2 = v6;
    }
  }
  while (v2);
  if (v4 != (void *)v5 && *v4 == v3) {
    return v4[1];
  }
  else {
    return 0;
  }
}

void anonymous namespace'::ChainedTensorBitcast::~ChainedTensorBitcast(_anonymous_namespace_::ChainedTensorBitcast *this)
{
  unint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  unint64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }
}

{
  char *v2;
  char *v3;
  uint64_t vars8;

  unint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  unint64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::tensor::BitcastOp>::rewrite(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 48))();
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::tensor::BitcastOp>::match(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 56))();
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::tensor::BitcastOp>::matchAndRewrite(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 64))();
}

uint64_t anonymous namespace'::ChainedTensorBitcast::matchAndRewrite(uint64_t a1, uint64_t a2, uint64_t a3)
{
  unint64_t v9 = *(void *)(*(void *)(a2 + 72) + 24);
  uint64_t result = mlir::Value::getDefiningOp((mlir::Value *)&v9);
  if (result)
  {
    if (*(_UNKNOWN **)(*(void *)(result + 48) + 16) == &mlir::detail::TypeIDResolver<mlir::tensor::BitcastOp,void>::id)
    {
      unint64_t v6 = *(void *)(a2 - 8) & 0xFFFFFFFFFFFFFFF8;
      uint64_t v8 = *(void *)(*(void *)(result + 72) + 24);
      unint64_t v9 = v6;
      unint64_t v7 = mlir::OpBuilder::create<mlir::tensor::BitcastOp,mlir::TensorType &,mlir::Value>((mlir::OpBuilder *)(a3 + 8), *(void *)(a2 + 24), (uint64_t *)&v9, &v8);
      (*(void (**)(uint64_t, uint64_t, ZinIrHalH13g *))(*(void *)a3 + 32))(a3, a2, v7);
      return 1;
    }
    else
    {
      return 0;
    }
  }
  return result;
}

ZinIrHalH13g *mlir::OpBuilder::create<mlir::tensor::BitcastOp,mlir::TensorType &,mlir::Value>(mlir::OpBuilder *a1, uint64_t a2, uint64_t *a3, uint64_t *a4)
{
  v25[28] = *MEMORY[0x263EF8340];
  uint64_t v16 = a2;
  uint64_t Context = (uint64_t *)mlir::Attribute::getContext((mlir::Attribute *)&v16);
  uint64_t v9 = mlir::RegisteredOperationName::lookup((int8x16_t *)"tensor.bitcast", (const unsigned __int8 *)0xE, Context);
  if (!v10)
  {
    __int16 v20 = 1283;
    void v19[2] = (uint64_t)"tensor.bitcast";
    v19[3] = 14;
          " the dialect. See also https://mlir.llvm.org/getting_started/Faq/#registered-loaded-dependent-whats-up-with-di"
          "alects-management";
    __int16 v18 = 259;
    llvm::operator+(v19, (uint64_t *)&v17, (uint64_t)v21);
    llvm::report_fatal_error((llvm::Twine *)v21, 1);
  }
  mlir::OperationState::OperationState(v21, a2, v9);
  uint64_t v11 = *a3;
  v19[0] = *a4;
  mlir::OperationState::addOperands((uint64_t)v21, (uint64_t)v19, 1);
  unsigned int v12 = v23;
  if (v23 >= v24)
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v22, v25, v23 + 1, 8);
    unsigned int v12 = v23;
  }
  *(void *)(v22 + 8 * v12) = v11;
  ++v23;
  unint64_t v13 = mlir::OpBuilder::create(a1, (const mlir::OperationState *)v21);
  if (*(_UNKNOWN **)(*((void *)v13 + 6) + 16) == &mlir::detail::TypeIDResolver<mlir::tensor::BitcastOp,void>::id) {
    unint64_t v14 = v13;
  }
  else {
    unint64_t v14 = 0;
  }
  mlir::OperationState::~OperationState((mlir::OperationState *)v21);
  return v14;
}

void anonymous namespace'::ChainedTensorCast::~ChainedTensorCast(_anonymous_namespace_::ChainedTensorCast *this)
{
  unint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  unint64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }
}

{
  char *v2;
  char *v3;
  uint64_t vars8;

  unint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  unint64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::tensor::CastOp>::rewrite(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 48))();
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::tensor::CastOp>::match(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 56))();
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::tensor::CastOp>::matchAndRewrite(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 64))();
}

uint64_t anonymous namespace'::ChainedTensorCast::matchAndRewrite(uint64_t a1, uint64_t a2, uint64_t a3)
{
  unint64_t v13 = *(void *)(*(void *)(a2 + 72) + 24);
  uint64_t result = mlir::Value::getDefiningOp((mlir::Value *)&v13);
  if (result)
  {
    uint64_t v6 = result;
    if (*(_UNKNOWN **)(*(void *)(result + 48) + 16) == &mlir::detail::TypeIDResolver<mlir::tensor::CastOp,void>::id)
    {
      unint64_t v7 = *(void *)(*(void *)(*(void *)(result + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8;
      unint64_t v8 = *(void *)(result - 8) & 0xFFFFFFFFFFFFFFF8;
      unint64_t v13 = *(void *)(a2 - 8) & 0xFFFFFFFFFFFFFFF8;
      uint64_t v9 = v13;
      uint64_t v10 = joinShapes(v7, v8);
      uint64_t result = joinShapes(v10, v9);
      if (result)
      {
        if (result == joinShapes(v7, v9))
        {
          uint64_t v12 = *(void *)(*(void *)(v6 + 72) + 24);
          uint64_t v11 = mlir::OpBuilder::create<mlir::tensor::CastOp,mlir::TensorType &,mlir::Value>((mlir::OpBuilder *)(a3 + 8), *(void *)(a2 + 24), (uint64_t *)&v13, &v12);
          (*(void (**)(uint64_t, uint64_t, ZinIrHalH13g *))(*(void *)a3 + 32))(a3, a2, v11);
          return 1;
        }
        else
        {
          return 0;
        }
      }
    }
    else
    {
      return 0;
    }
  }
  return result;
}

uint64_t joinShapes(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = a2;
  void v24[4] = *MEMORY[0x263EF8340];
  uint64_t v20 = a2;
  uint64_t v21 = a1;
  if (!mlir::TensorType::hasRank((mlir::TensorType *)&v21)) {
    return v2;
  }
  if (!mlir::TensorType::hasRank((mlir::TensorType *)&v20)) {
    return v21;
  }
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v21);
  int64_t v4 = v3;
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v20);
  if (v4 != v5) {
    return 0;
  }
  uint64_t v22 = v24;
  uint64_t v23 = 0x400000000;
  if ((unint64_t)v4 >= 5) {
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v22, v24, v4, 8);
  }
  if (v4 < 1)
  {
    unsigned int v14 = v23;
LABEL_21:
    uint64_t v15 = v22;
    uint64_t v16 = v14;
    uint64_t ElementType = mlir::TensorType::getElementType((mlir::TensorType *)&v21);
    uint64_t v2 = mlir::RankedTensorType::get((uint64_t)v15, v16, ElementType, 0);
    __int16 v18 = v22;
    if (v22 != v24) {
      goto LABEL_22;
    }
    return v2;
  }
  uint64_t v6 = 0;
  while (1)
  {
    uint64_t v7 = 8 * v6;
    uint64_t v8 = *(void *)(mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v21) + v7);
    uint64_t v9 = *(void *)(mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v20) + v7);
    if (v8 == 0x8000000000000000) {
      goto LABEL_13;
    }
    uint64_t Value = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v21);
    if (v9 != 0x8000000000000000) {
      break;
    }
    unint64_t v12 = v23;
    unint64_t v13 = HIDWORD(v23);
    uint64_t v9 = *(void *)(Value + 8 * v6);
LABEL_14:
    if (v12 >= v13)
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v22, v24, v12 + 1, 8);
      unint64_t v12 = v23;
    }
    *((void *)v22 + v12) = v9;
    unsigned int v14 = v23 + 1;
    LODWORD(v23) = v23 + 1;
    if (v4 == ++v6) {
      goto LABEL_21;
    }
  }
  uint64_t v11 = *(void *)(Value + 8 * v6);
  if (v11 == *(void *)(mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v20) + 8 * v6))
  {
    uint64_t v9 = *(void *)(mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v21) + 8 * v6);
LABEL_13:
    unint64_t v12 = v23;
    unint64_t v13 = HIDWORD(v23);
    goto LABEL_14;
  }
  uint64_t v2 = 0;
  __int16 v18 = v22;
  if (v22 == v24) {
    return v2;
  }
LABEL_22:
  free(v18);
  return v2;
}

ZinIrHalH13g *mlir::OpBuilder::create<mlir::tensor::CastOp,mlir::TensorType &,mlir::Value>(mlir::OpBuilder *a1, uint64_t a2, uint64_t *a3, uint64_t *a4)
{
  v25[28] = *MEMORY[0x263EF8340];
  uint64_t v16 = a2;
  uint64_t Context = (uint64_t *)mlir::Attribute::getContext((mlir::Attribute *)&v16);
  uint64_t v9 = mlir::RegisteredOperationName::lookup((int8x16_t *)"tensor.cast", (const unsigned __int8 *)0xB, Context);
  if (!v10)
  {
    __int16 v20 = 1283;
    void v19[2] = (uint64_t)"tensor.cast";
    v19[3] = 11;
          " the dialect. See also https://mlir.llvm.org/getting_started/Faq/#registered-loaded-dependent-whats-up-with-di"
          "alects-management";
    __int16 v18 = 259;
    llvm::operator+(v19, (uint64_t *)&v17, (uint64_t)v21);
    llvm::report_fatal_error((llvm::Twine *)v21, 1);
  }
  mlir::OperationState::OperationState(v21, a2, v9);
  uint64_t v11 = *a3;
  v19[0] = *a4;
  mlir::OperationState::addOperands((uint64_t)v21, (uint64_t)v19, 1);
  unsigned int v12 = v23;
  if (v23 >= v24)
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v22, v25, v23 + 1, 8);
    unsigned int v12 = v23;
  }
  *(void *)(v22 + 8 * v12) = v11;
  ++v23;
  unint64_t v13 = mlir::OpBuilder::create(a1, (const mlir::OperationState *)v21);
  if (*(_UNKNOWN **)(*((void *)v13 + 6) + 16) == &mlir::detail::TypeIDResolver<mlir::tensor::CastOp,void>::id) {
    unsigned int v14 = v13;
  }
  else {
    unsigned int v14 = 0;
  }
  mlir::OperationState::~OperationState((mlir::OperationState *)v21);
  return v14;
}

void anonymous namespace'::TensorCastExtractSlice::~TensorCastExtractSlice(_anonymous_namespace_::TensorCastExtractSlice *this)
{
  uint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  int64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }
}

{
  char *v2;
  char *v3;
  uint64_t vars8;

  uint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  int64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t anonymous namespace'::TensorCastExtractSlice::matchAndRewrite(uint64_t a1, uint64_t a2, mlir::IndexType **a3)
{
  void v48[4] = *MEMORY[0x263EF8340];
  uint64_t v46 = *(void **)(*(void *)(a2 + 72) + 24);
  uint64_t DefiningOp = mlir::Value::getDefiningOp((mlir::Value *)&v46);
  if (DefiningOp)
  {
    if (*(_UNKNOWN **)(*(void *)(DefiningOp + 48) + 16) == &mlir::detail::TypeIDResolver<mlir::tensor::ExtractSliceOp,void>::id) {
      uint64_t v6 = DefiningOp;
    }
    else {
      uint64_t v6 = 0;
    }
  }
  else
  {
    uint64_t v6 = 0;
  }
  uint64_t v37 = v6;
  unint64_t v7 = *(void *)(a2 - 8) & 0xFFFFFFFFFFFFFFF8;
  if (*(_UNKNOWN **)(*(void *)v7 + 136) == &mlir::detail::TypeIDResolver<mlir::RankedTensorType,void>::id) {
    unint64_t v8 = *(void *)(a2 - 8) & 0xFFFFFFFFFFFFFFF8;
  }
  else {
    unint64_t v8 = 0;
  }
  unint64_t v36 = v8;
  if (!v8
    || !a2
    || !v6
    || !mlir::tensor::preservesStaticInformation(*(void *)(*(void *)(*(void *)(a2 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8, v7))
  {
    return 0;
  }
  uint64_t Value = (const void *)mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v36);
  uint64_t v11 = v10;
  uint64_t v46 = (void *)(*(void *)(*(void *)(*(void *)(a2 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8);
  unsigned int v12 = (const void *)mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v46);
  if (v11 != v13 || (uint64_t result = memcmp(Value, v12, 8 * v11), result))
  {
    mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::memref::ReinterpretCastOp>::getMixedSizes((mlir::memref::ReinterpretCastOp *)&v37, (uint64_t)&v46);
    unint64_t v15 = v37 + 16 * (((unint64_t)*(unsigned int *)(v37 + 44) >> 23) & 1) + 64;
    if (!HIBYTE(*(_DWORD *)(v37 + 44))) {
      unint64_t v15 = 0;
    }
    v40[0] = *(void **)(v15 + 8);
    uint64_t v16 = (char *)mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)v40);
    unint64_t v18 = v17;
    if (*(_DWORD *)(v37 + 36)) {
      uint64_t v19 = v37 - 16;
    }
    else {
      uint64_t v19 = 0;
    }
    v40[0] = (void *)(*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v19, 0) + 8) & 0xFFFFFFFFFFFFFFF8);
    uint64_t v20 = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)v40);
    mlir::computeRankReductionMask(v16, v18, v20, v21, (uint64_t)v42);
    uint64_t v22 = v47;
    if (v47)
    {
      uint64_t v23 = 0;
      for (uint64_t i = 0; i != v22; ++i)
      {
        if (!v45) {
          goto LABEL_35;
        }
        if (v42[0])
        {
          __int16 v25 = &v43;
          int v26 = 3;
          unsigned int v27 = (37 * i) & 3;
          int v28 = *((_DWORD *)&v43 + v27);
          if (v28 != i) {
            goto LABEL_31;
          }
        }
        else
        {
          if (!v44) {
            goto LABEL_35;
          }
          __int16 v25 = v43;
          int v26 = v44 - 1;
          unsigned int v27 = (v44 - 1) & (37 * i);
          int v28 = *((_DWORD *)v43 + v27);
          if (v28 != i)
          {
LABEL_31:
            int v30 = 1;
            while (v28 != -1)
            {
              unsigned int v31 = v27 + v30++;
              unsigned int v27 = v31 & v26;
              int v28 = v25[v27];
              if (v28 == i) {
                goto LABEL_25;
              }
            }
LABEL_35:
            uint64_t v29 = v23 + 1;
            uint64_t v32 = *(mlir::MLIRContext **)(mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v36) + 8 * v23);
            if (v32 != (mlir::MLIRContext *)0x8000000000000000)
            {
              uint64_t IndexAttr = mlir::Builder::getIndexAttr(a3 + 1, v32);
              v46[i] = IndexAttr & 0xFFFFFFFFFFFFFFFBLL;
            }
            goto LABEL_26;
          }
        }
LABEL_25:
        uint64_t v29 = v23;
LABEL_26:
        uint64_t v23 = v29;
      }
    }
    uint64_t v35 = *(void *)(*(void *)(v37 + 72) + 24);
    mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::memref::ReinterpretCastOp>::getMixedOffsets((mlir::memref::ReinterpretCastOp *)&v37, (uint64_t)v40);
    mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::memref::ReinterpretCastOp>::getMixedStrides((mlir::memref::ReinterpretCastOp *)&v37, (uint64_t)v38);
    uint64_t v34 = mlir::OpBuilder::create<mlir::tensor::ExtractSliceOp,mlir::RankedTensorType &,mlir::detail::TypedValue<mlir::RankedTensorType>,llvm::SmallVector<mlir::OpFoldResult,4u>,llvm::SmallVector<mlir::OpFoldResult,4u>&,llvm::SmallVector<mlir::OpFoldResult,4u>>(a3 + 1, *(void *)(a2 + 24), (uint64_t *)&v36, &v35, (uint64_t)v40, (uint64_t)&v46, (uint64_t)v38);
    (*((void (**)(mlir::IndexType **, uint64_t, ZinIrHalH13g *))*a3 + 4))(a3, a2, v34);
    if (v38[0] != &v39) {
      free(v38[0]);
    }
    if (v40[0] != &v41) {
      free(v40[0]);
    }
    if (v45 && (v42[0] & 1) == 0) {
      llvm::deallocate_buffer(v43, (void *)(4 * v44));
    }
    if (v46 != v48) {
      free(v46);
    }
    return 1;
  }
  return result;
}

ZinIrHalH13g *mlir::OpBuilder::create<mlir::tensor::ExtractSliceOp,mlir::RankedTensorType &,mlir::detail::TypedValue<mlir::RankedTensorType>,llvm::SmallVector<mlir::OpFoldResult,4u>,llvm::SmallVector<mlir::OpFoldResult,4u>&,llvm::SmallVector<mlir::OpFoldResult,4u>>(mlir::MLIRContext **a1, uint64_t a2, uint64_t *a3, uint64_t *a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  v25[38] = *MEMORY[0x263EF8340];
  uint64_t v20 = a2;
  uint64_t Context = (uint64_t *)mlir::Attribute::getContext((mlir::Attribute *)&v20);
  uint64_t v15 = mlir::RegisteredOperationName::lookup((int8x16_t *)"tensor.extract_slice", (const unsigned __int8 *)0x14, Context);
  if (!v16)
  {
    __int16 v24 = 1283;
    uint64_t v23[2] = (uint64_t)"tensor.extract_slice";
    v23[3] = 20;
          " the dialect. See also https://mlir.llvm.org/getting_started/Faq/#registered-loaded-dependent-whats-up-with-di"
          "alects-management";
    __int16 v22 = 259;
    llvm::operator+(v23, (uint64_t *)&v21, (uint64_t)v25);
    llvm::report_fatal_error((llvm::Twine *)v25, 1);
  }
  mlir::OperationState::OperationState(v25, a2, v15);
  mlir::tensor::ExtractSliceOp::build(a1, (uint64_t)v25, *a3, *a4, *(uint64_t **)a5, *(unsigned int *)(a5 + 8), *(uint64_t **)a6, *(unsigned int *)(a6 + 8), *(uint64_t **)a7, *(unsigned int *)(a7 + 8), 0, 0);
  unint64_t v17 = mlir::OpBuilder::create((mlir::OpBuilder *)a1, (const mlir::OperationState *)v25);
  if (*(_UNKNOWN **)(*((void *)v17 + 6) + 16) == &mlir::detail::TypeIDResolver<mlir::tensor::ExtractSliceOp,void>::id) {
    unint64_t v18 = v17;
  }
  else {
    unint64_t v18 = 0;
  }
  mlir::OperationState::~OperationState((mlir::OperationState *)v25);
  return v18;
}

void anonymous namespace'::DimOfCastOp::~DimOfCastOp(_anonymous_namespace_::DimOfCastOp *this)
{
  uint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  int64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }
}

{
  char *v2;
  char *v3;
  uint64_t vars8;

  uint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  int64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t anonymous namespace'::DimOfCastOp::matchAndRewrite(uint64_t a1, uint64_t a2, mlir::IndexType **a3)
{
  uint64_t v9 = *(void *)(*(void *)(a2 + 72) + 24);
  uint64_t result = mlir::Value::getDefiningOp((mlir::Value *)&v9);
  if (result)
  {
    if (*(_UNKNOWN **)(*(void *)(result + 48) + 16) == &mlir::detail::TypeIDResolver<mlir::tensor::CastOp,void>::id)
    {
      uint64_t v6 = *(void *)(*(void *)(result + 72) + 24);
      uint64_t v8 = *(void *)(*(void *)(a2 + 72) + 56);
      uint64_t v9 = v6;
      unint64_t v7 = mlir::OpBuilder::create<mlir::tensor::DimOp,mlir::Value &,mlir::detail::TypedValue<mlir::IndexType>>(a3 + 1, *(void *)(a2 + 24), &v9, &v8);
      (*((void (**)(mlir::IndexType **, uint64_t, ZinIrHalH13g *))*a3 + 4))(a3, a2, v7);
      return 1;
    }
    else
    {
      return 0;
    }
  }
  return result;
}

void anonymous namespace'::DimOfDestStyleOp::~DimOfDestStyleOp(_anonymous_namespace_::DimOfDestStyleOp *this)
{
  uint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  int64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }
}

{
  char *v2;
  char *v3;
  uint64_t vars8;

  uint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  int64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t anonymous namespace'::DimOfDestStyleOp::matchAndRewrite(uint64_t a1, uint64_t a2, uint64_t a3)
{
  void v18[3] = *MEMORY[0x263EF8340];
  uint64_t v15 = *(void *)(*(void *)(a2 + 72) + 24);
  uint64_t result = mlir::Value::getDefiningOp((mlir::Value *)&v15);
  if (result)
  {
    uint64_t result = llvm::DefaultDoCastIfPossible<mlir::DestinationStyleOpInterface,mlir::Operation *,llvm::CastInfo<mlir::DestinationStyleOpInterface,mlir::Operation *,void>>::doCastIfPossible(result);
    uint64_t v13 = result;
    uint64_t v14 = v6;
    if (result)
    {
      if (v15 && (*(void *)(v15 + 8) & 7) == 6) {
        int v7 = *(_DWORD *)(v15 + 16) + 6;
      }
      else {
        int v7 = *(void *)(v15 + 8) & 7;
      }
      mlir::DestinationStyleOpInterface::getDpsInitsMutable(v16, (mlir::DestinationStyleOpInterface *)&v13);
      uint64_t v8 = mlir::MutableOperandRange::operator[](v16, v7);
      if (v17 != v18) {
        free(v17);
      }
      (*(void (**)(uint64_t, uint64_t))(*(void *)a3 + 72))(a3, a2);
      uint64_t v9 = *(uint64_t **)(a2 + 72);
      uint64_t v10 = *(uint64_t **)(v8 + 24);
      uint64_t v11 = (uint64_t *)v9[1];
      if (v11)
      {
        *uint64_t v11 = *v9;
        if (*v9) {
          *(void *)(*v9 + 8) = v9[1];
        }
      }
      v9[3] = (uint64_t)v10;
      v9[1] = (uint64_t)v10;
      uint64_t v12 = *v10;
      *uint64_t v9 = *v10;
      if (v12) {
        *(void *)(v12 + 8) = v9;
      }
      *uint64_t v10 = (uint64_t)v9;
      (*(void (**)(uint64_t, uint64_t))(*(void *)a3 + 80))(a3, a2);
      return 1;
    }
  }
  else
  {
    uint64_t v13 = 0;
    uint64_t v14 = 0;
  }
  return result;
}

void anonymous namespace'::FoldEmptyTensorWithCastOp::~FoldEmptyTensorWithCastOp(_anonymous_namespace_::FoldEmptyTensorWithCastOp *this)
{
  uint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  int64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }
}

{
  char *v2;
  char *v3;
  uint64_t vars8;

  uint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  int64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t anonymous namespace'::FoldEmptyTensorWithCastOp::matchAndRewrite(uint64_t a1, uint64_t a2, mlir::IndexType **a3)
{
  v32[6] = *MEMORY[0x263EF8340];
  if (!a2) {
    return 0;
  }
  if (!mlir::tensor::preservesStaticInformation(*(void *)(*(void *)(*(void *)(a2 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8, *(void *)(a2 - 8) & 0xFFFFFFFFFFFFFFF8))return 0; {
  int v30 = *(void **)(*(void *)(a2 + 72) + 24);
  }
  uint64_t DefiningOp = mlir::Value::getDefiningOp((mlir::Value *)&v30);
  if (!DefiningOp) {
    return 0;
  }
  uint64_t v6 = *(void **)(*(void *)(DefiningOp + 48) + 16);
  uint64_t v7 = v6 == &mlir::detail::TypeIDResolver<mlir::tensor::EmptyOp,void>::id ? DefiningOp : 0;
  uint64_t v23 = v7;
  if (v6 != &mlir::detail::TypeIDResolver<mlir::tensor::EmptyOp,void>::id) {
    return 0;
  }
  unint64_t v22 = *(void *)(a2 - 8) & 0xFFFFFFFFFFFFFFF8;
  uint64_t Value = (mlir::MLIRContext **)mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v22);
  uint64_t v12 = v11;
  mlir::tensor::EmptyOp::getMixedSizes((mlir::tensor::EmptyOp *)&v23, (uint64_t)&v30);
  unsigned int v27 = v29;
  uint64_t v28 = 0x600000000;
  unsigned int v13 = v31;
  if (v31 >= 7)
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v27, v29, v31, 8);
    unsigned int v13 = v31;
  }
  if (!v12 || !v13)
  {
LABEL_31:
    v24[0] = mlir::AffineBinaryOpExpr::getRHS((mlir::AffineBinaryOpExpr *)&v22);
    unint64_t v21 = mlir::OpBuilder::create<mlir::tensor::EmptyOp,llvm::SmallVector<mlir::OpFoldResult,6u> &,mlir::Type>((mlir::OpBuilder *)(a3 + 1), *(void *)(a2 + 24), (uint64_t)&v27, v24);
    (*((void (**)(mlir::IndexType **, uint64_t, ZinIrHalH13g *))*a3 + 4))(a3, a2, v21);
    uint64_t v8 = 1;
    goto LABEL_32;
  }
  uint64_t v14 = (unint64_t *)v30;
  uint64_t v15 = 8 * v13 - 8;
  uint64_t v16 = 8 * v12 - 8;
  while (1)
  {
    unint64_t v17 = *Value;
    unint64_t v18 = (*v14 & 4) != 0 ? 0 : *v14 & 0xFFFFFFFFFFFFFFF8;
    if (v18) {
      break;
    }
    if (v17 == (mlir::MLIRContext *)0x8000000000000000)
    {
      uint64_t v19 = v28;
      unint64_t v18 = *v14;
      if (v28 < (unint64_t)HIDWORD(v28)) {
        goto LABEL_22;
      }
    }
    else
    {
      unint64_t v18 = mlir::Builder::getIndexAttr(a3 + 1, *Value) & 0xFFFFFFFFFFFFFFFBLL;
      uint64_t v19 = v28;
      if (v28 < (unint64_t)HIDWORD(v28))
      {
LABEL_22:
        *((void *)v27 + v19) = v18;
        LODWORD(v28) = v28 + 1;
        if (!v16) {
          goto LABEL_31;
        }
        goto LABEL_23;
      }
    }
LABEL_27:
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v27, v29, v19 + 1, 8);
    *((void *)v27 + v28) = v18;
    LODWORD(v28) = v28 + 1;
    if (!v16) {
      goto LABEL_31;
    }
LABEL_23:
    ++Value;
    ++v14;
    uint64_t v20 = v15;
    v15 -= 8;
    v16 -= 8;
    if (!v20) {
      goto LABEL_31;
    }
  }
  if (v17 != (mlir::MLIRContext *)0x8000000000000000)
  {
    v24[0] = v18;
    if (v17 == (mlir::MLIRContext *)mlir::IntegerAttr::getInt((mlir::IntegerAttr *)v24))
    {
      uint64_t v19 = v28;
      if (v28 < (unint64_t)HIDWORD(v28)) {
        goto LABEL_22;
      }
      goto LABEL_27;
    }
  }
  v24[0] = (uint64_t)"mismatch in static value of shape of empty tensor result and cast result";
  __int16 v25 = 259;
  int v26 = v24;
  uint64_t v8 = (uint64_t)a3[2];
  if (v8)
  {
    if (mlir::RewriterBase::Listener::classof(v8)) {
      uint64_t v8 = (*(uint64_t (**)(uint64_t, void, uint64_t (*)(void ****, uint64_t), uint64_t **))(*(void *)v8 + 64))(v8, *(void *)(v7 + 24), llvm::function_ref<void ()(mlir::Diagnostic &)>::callback_fn<mlir::LogicalResult mlir::RewriterBase::notifyMatchFailure<mlir::tensor::EmptyOp &>(mlir::tensor::EmptyOp &,llvm::Twine const&)::{lambda(mlir::Diagnostic &)#1}>, &v26);
    }
    else {
      uint64_t v8 = 0;
    }
  }
LABEL_32:
  if (v27 != v29) {
    free(v27);
  }
  if (v30 != v32) {
    free(v30);
  }
  return v8;
}

uint64_t llvm::function_ref<void ()(mlir::Diagnostic &)>::callback_fn<mlir::LogicalResult mlir::RewriterBase::notifyMatchFailure<mlir::tensor::EmptyOp &>(mlir::tensor::EmptyOp &,llvm::Twine const&)::{lambda(mlir::Diagnostic &)#1}>(void ****a1, uint64_t a2)
{
  return mlir::Diagnostic::operator<<(a2, *a1);
}

void anonymous namespace'::FoldEmptyTensorWithDimOp::~FoldEmptyTensorWithDimOp(_anonymous_namespace_::FoldEmptyTensorWithDimOp *this)
{
  uint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  int64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }
}

{
  char *v2;
  char *v3;
  uint64_t vars8;

  uint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  int64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t anonymous namespace'::FoldEmptyTensorWithDimOp::matchAndRewrite(uint64_t a1, uint64_t a2, uint64_t a3)
{
  unsigned int ConstantIntValue = mlir::getConstantIntValue(*(void *)(*(void *)(a2 + 72) + 56) | 4);
  char v7 = v6;
  unint64_t v20 = *(void *)(*(void *)(a2 + 72) + 24);
  uint64_t DefiningOp = mlir::Value::getDefiningOp((mlir::Value *)&v20);
  if (!DefiningOp) {
    return 0;
  }
  uint64_t v9 = *(void **)(*(void *)(DefiningOp + 48) + 16);
  uint64_t v10 = v9 == &mlir::detail::TypeIDResolver<mlir::tensor::EmptyOp,void>::id ? DefiningOp : 0;
  if (v9 != &mlir::detail::TypeIDResolver<mlir::tensor::EmptyOp,void>::id || v7 == 0) {
    return 0;
  }
  uint64_t v12 = *(_DWORD *)(v10 + 36) ? v10 - 16 : 0;
  unint64_t v20 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v12, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
  if (*(void *)(mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v20) + 8 * ConstantIntValue) != 0x8000000000000000) {
    return 0;
  }
  uint64_t v13 = ConstantIntValue;
  if (ConstantIntValue)
  {
    uint64_t v14 = 0;
    LODWORD(v15) = 0;
    uint64_t v16 = 8 * v13;
    do
    {
      if (*(_DWORD *)(v10 + 36)) {
        uint64_t v17 = v10 - 16;
      }
      else {
        uint64_t v17 = 0;
      }
      unint64_t v20 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v17, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
      if (*(void *)(mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v20) + v14) == 0x8000000000000000) {
        uint64_t v15 = (v15 + 1);
      }
      else {
        uint64_t v15 = v15;
      }
      v14 += 8;
    }
    while (v16 != v14);
  }
  else
  {
    uint64_t v15 = 0;
  }
  unint64_t v20 = *(void *)(*(void *)(v10 + 72) + 32 * v15 + 24);
  uint64_t v18 = 1;
  (*(void (**)(uint64_t, uint64_t, unint64_t *, uint64_t))(*(void *)a3 + 24))(a3, a2, &v20, 1);
  return v18;
}

void anonymous namespace'::ReplaceEmptyTensorStaticShapeDims::~ReplaceEmptyTensorStaticShapeDims(_anonymous_namespace_::ReplaceEmptyTensorStaticShapeDims *this)
{
  uint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  int64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }
}

{
  char *v2;
  char *v3;
  uint64_t vars8;

  uint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  int64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::tensor::EmptyOp>::rewrite(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 48))();
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::tensor::EmptyOp>::match(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 56))();
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::tensor::EmptyOp>::matchAndRewrite(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 64))();
}

uint64_t anonymous namespace'::ReplaceEmptyTensorStaticShapeDims::matchAndRewrite(uint64_t a1, uint64_t a2, uint64_t a3)
{
  v46[6] = *MEMORY[0x263EF8340];
  uint64_t v5 = a2 - 16;
  if (*(_DWORD *)(a2 + 36)) {
    uint64_t v6 = a2 - 16;
  }
  else {
    uint64_t v6 = 0;
  }
  uint64_t v41 = (void *)(*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v6, 0) + 8) & 0xFFFFFFFFFFFFFFF8);
  uint64_t Value = (unsigned char *)mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v41);
  if (*(_DWORD *)(a2 + 36)) {
    uint64_t v8 = v5;
  }
  else {
    uint64_t v8 = 0;
  }
  unint64_t v40 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v8, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
  uint64_t v9 = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v40);
  uint64_t v11 = (unsigned char *)(v9 + 8 * v10);
  unsigned int v44 = v46;
  uint64_t v45 = 0x600000000;
  uint64_t v12 = v11 - Value;
  if ((unint64_t)(v11 - Value) >= 0x31)
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v44, v46, v12 >> 3, 8);
    unsigned int v13 = v45;
    if (v11 == Value) {
      goto LABEL_12;
    }
    goto LABEL_11;
  }
  unsigned int v13 = 0;
  if (v11 != Value)
  {
LABEL_11:
    memcpy((char *)v44 + 8 * v13, Value, v11 - Value);
    unsigned int v13 = v45;
  }
LABEL_12:
  LODWORD(v45) = v13 + ((unint64_t)v12 >> 3);
  uint64_t v41 = v43;
  uint64_t v42 = 0x600000000;
  if (*(_DWORD *)(a2 + 36)) {
    uint64_t v14 = v5;
  }
  else {
    uint64_t v14 = 0;
  }
  unint64_t v40 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v14, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v40);
  if (v15 < 1) {
    goto LABEL_44;
  }
  uint64_t v16 = 0;
  char v17 = 0;
  uint64_t v18 = 0;
  do
  {
    if (*(_DWORD *)(a2 + 36)) {
      uint64_t v22 = v5;
    }
    else {
      uint64_t v22 = 0;
    }
    unint64_t v40 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v22, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
    if (*(void *)(mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v40) + 8 * v18) == 0x8000000000000000)
    {
      uint64_t v19 = (v16 + 1);
      uint64_t v23 = *(void *)(*(void *)(a2 + 72) + 32 * v16 + 24);
      unint64_t ConstantIntValue = mlir::getConstantIntValue(v23 | 4);
      if (v25)
      {
        if ((ConstantIntValue & 0x8000000000000000) != 0) {
          goto LABEL_44;
        }
        *((void *)v44 + v18) = ConstantIntValue;
        char v17 = 1;
      }
      else
      {
        uint64_t v26 = v42;
        if (v42 >= (unint64_t)HIDWORD(v42))
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v41, v43, v42 + 1, 8);
          uint64_t v26 = v42;
        }
        *((void *)v41 + v26) = v23;
        LODWORD(v42) = v42 + 1;
      }
    }
    else
    {
      uint64_t v19 = v16;
    }
    ++v18;
    if (*(_DWORD *)(a2 + 36)) {
      uint64_t v20 = v5;
    }
    else {
      uint64_t v20 = 0;
    }
    unint64_t v40 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v20, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
    mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v40);
    uint64_t v16 = v19;
  }
  while (v18 < v21);
  if (v17)
  {
    unsigned int v27 = v44;
    uint64_t v28 = v45;
    if (*(_DWORD *)(a2 + 36)) {
      uint64_t v29 = v5;
    }
    else {
      uint64_t v29 = 0;
    }
    unint64_t v39 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v29, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
    uint64_t RHS = mlir::AffineBinaryOpExpr::getRHS((mlir::AffineBinaryOpExpr *)&v39);
    if (*(_DWORD *)(a2 + 36)) {
      uint64_t v31 = v5;
    }
    else {
      uint64_t v31 = 0;
    }
    unint64_t v38 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v31, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
    uint64_t Values = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)&v38);
    unint64_t v40 = mlir::RankedTensorType::get((uint64_t)v27, v28, RHS, Values);
    unint64_t v39 = (unint64_t)mlir::OpBuilder::create<mlir::tensor::EmptyOp,mlir::RankedTensorType &,llvm::SmallVector<mlir::Value,6u> &>((mlir::OpBuilder *)(a3 + 8), *(void *)(a2 + 24), (uint64_t *)&v40, (uint64_t)&v41);
    if (*(_DWORD *)(a2 + 36)) {
      uint64_t v33 = v5;
    }
    else {
      uint64_t v33 = 0;
    }
    unint64_t v38 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v33, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
    uint64_t v34 = mlir::OpBuilder::create<mlir::tensor::CastOp,mlir::RankedTensorType,mlir::tensor::EmptyOp &>((mlir::OpBuilder *)(a3 + 8), *(void *)(a2 + 24), (uint64_t *)&v38, &v39);
    (*(void (**)(uint64_t, uint64_t, ZinIrHalH13g *))(*(void *)a3 + 32))(a3, a2, v34);
    uint64_t v35 = 1;
    unint64_t v36 = v41;
    if (v41 == v43) {
      goto LABEL_46;
    }
  }
  else
  {
LABEL_44:
    uint64_t v35 = 0;
    unint64_t v36 = v41;
    if (v41 == v43) {
      goto LABEL_46;
    }
  }
  free(v36);
LABEL_46:
  if (v44 != v46) {
    free(v44);
  }
  return v35;
}

ZinIrHalH13g *mlir::OpBuilder::create<mlir::tensor::EmptyOp,mlir::RankedTensorType &,llvm::SmallVector<mlir::Value,6u> &>(mlir::OpBuilder *a1, uint64_t a2, uint64_t *a3, uint64_t a4)
{
  v26[28] = *MEMORY[0x263EF8340];
  uint64_t v16 = a2;
  uint64_t Context = (uint64_t *)mlir::Attribute::getContext((mlir::Attribute *)&v16);
  uint64_t v9 = mlir::RegisteredOperationName::lookup((int8x16_t *)"tensor.empty", (const unsigned __int8 *)0xC, Context);
  if (!v10)
  {
    __int16 v20 = 1283;
    void v19[2] = (uint64_t)"tensor.empty";
    v19[3] = 12;
          " the dialect. See also https://mlir.llvm.org/getting_started/Faq/#registered-loaded-dependent-whats-up-with-di"
          "alects-management";
    __int16 v18 = 259;
    llvm::operator+(v19, (uint64_t *)&v17, (uint64_t)v22);
    llvm::report_fatal_error((llvm::Twine *)v22, 1);
  }
  mlir::OperationState::OperationState(v22, a2, v9);
  uint64_t v11 = *a3;
  mlir::ValueRange::ValueRange(v21, *(void *)a4, *(unsigned int *)(a4 + 8));
  mlir::OperationState::addOperands((uint64_t)v22, v21[0], v21[1]);
  unsigned int v12 = v24;
  if (v24 >= v25)
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v23, v26, v24 + 1, 8);
    unsigned int v12 = v24;
  }
  *(void *)(v23 + 8 * v12) = v11;
  ++v24;
  unsigned int v13 = mlir::OpBuilder::create(a1, (const mlir::OperationState *)v22);
  if (*(_UNKNOWN **)(*((void *)v13 + 6) + 16) == &mlir::detail::TypeIDResolver<mlir::tensor::EmptyOp,void>::id) {
    uint64_t v14 = v13;
  }
  else {
    uint64_t v14 = 0;
  }
  mlir::OperationState::~OperationState((mlir::OperationState *)v22);
  return v14;
}

ZinIrHalH13g *mlir::OpBuilder::create<mlir::tensor::CastOp,mlir::RankedTensorType,mlir::tensor::EmptyOp &>(mlir::OpBuilder *a1, uint64_t a2, uint64_t *a3, void *a4)
{
  v25[28] = *MEMORY[0x263EF8340];
  uint64_t v16 = a2;
  uint64_t Context = (uint64_t *)mlir::Attribute::getContext((mlir::Attribute *)&v16);
  uint64_t v9 = mlir::RegisteredOperationName::lookup((int8x16_t *)"tensor.cast", (const unsigned __int8 *)0xB, Context);
  if (!v10)
  {
    __int16 v20 = 1283;
    void v19[2] = (uint64_t)"tensor.cast";
    v19[3] = 11;
          " the dialect. See also https://mlir.llvm.org/getting_started/Faq/#registered-loaded-dependent-whats-up-with-di"
          "alects-management";
    __int16 v18 = 259;
    llvm::operator+(v19, (uint64_t *)&v17, (uint64_t)v21);
    llvm::report_fatal_error((llvm::Twine *)v21, 1);
  }
  mlir::OperationState::OperationState(v21, a2, v9);
  uint64_t v11 = *a3;
  v19[0] = *a4 - 16;
  mlir::OperationState::addOperands((uint64_t)v21, (uint64_t)v19, 1);
  unsigned int v12 = v23;
  if (v23 >= v24)
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v22, v25, v23 + 1, 8);
    unsigned int v12 = v23;
  }
  *(void *)(v22 + 8 * v12) = v11;
  ++v23;
  unsigned int v13 = mlir::OpBuilder::create(a1, (const mlir::OperationState *)v21);
  if (*(_UNKNOWN **)(*((void *)v13 + 6) + 16) == &mlir::detail::TypeIDResolver<mlir::tensor::CastOp,void>::id) {
    uint64_t v14 = v13;
  }
  else {
    uint64_t v14 = 0;
  }
  mlir::OperationState::~OperationState((mlir::OperationState *)v21);
  return v14;
}

void anonymous namespace'::ExtractFromTensorCast::~ExtractFromTensorCast(_anonymous_namespace_::ExtractFromTensorCast *this)
{
  uint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  int64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }
}

{
  char *v2;
  char *v3;
  uint64_t vars8;

  uint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  int64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::tensor::ExtractOp>::rewrite(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 48))();
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::tensor::ExtractOp>::match(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 56))();
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::tensor::ExtractOp>::matchAndRewrite(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 64))();
}

uint64_t anonymous namespace'::ExtractFromTensorCast::matchAndRewrite(uint64_t a1, uint64_t a2, uint64_t a3)
{
  v9[0] = *(void *)(*(void *)(a2 + 72) + 24);
  uint64_t result = mlir::Value::getDefiningOp((mlir::Value *)v9);
  if (result)
  {
    if (*(_UNKNOWN **)(*(void *)(result + 48) + 16) == &mlir::detail::TypeIDResolver<mlir::tensor::CastOp,void>::id)
    {
      if (*(_UNKNOWN **)(*(void *)(*(void *)(*(void *)(*(void *)(result + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8)
                        + 136) == &mlir::detail::TypeIDResolver<mlir::RankedTensorType,void>::id)
      {
        uint64_t v10 = *(void *)(*(void *)(result + 72) + 24);
        if ((*(unsigned char *)(a2 + 46) & 0x80) != 0)
        {
          uint64_t v6 = *(void *)(a2 + 72);
          uint64_t v7 = *(unsigned int *)(a2 + 68) - 1;
        }
        else
        {
          uint64_t v6 = 0;
          uint64_t v7 = -1;
        }
        v9[0] = v6 + 32;
        v9[1] = v7;
        uint64_t v8 = mlir::OpBuilder::create<mlir::tensor::ExtractOp,mlir::detail::TypedValue<mlir::TensorType>,mlir::OperandRange>((mlir::OpBuilder *)(a3 + 8), *(void *)(a2 + 24), &v10, (uint64_t)v9);
        (*(void (**)(uint64_t, uint64_t, ZinIrHalH13g *))(*(void *)a3 + 32))(a3, a2, v8);
        return 1;
      }
      else
      {
        return 0;
      }
    }
    else
    {
      return 0;
    }
  }
  return result;
}

void anonymous namespace'::ExtractElementFromIndexCast::~ExtractElementFromIndexCast(_anonymous_namespace_::ExtractElementFromIndexCast *this)
{
  uint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  int64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }
}

{
  char *v2;
  char *v3;
  uint64_t vars8;

  uint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  int64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t anonymous namespace'::ExtractElementFromIndexCast::matchAndRewrite(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v5 = *(void *)(a2 + 24);
  v14[0] = *(void *)(*(void *)(a2 + 72) + 24);
  uint64_t result = mlir::Value::getDefiningOp((mlir::Value *)v14);
  if (result)
  {
    uint64_t v7 = *(void **)(*(void *)(result + 48) + 16);
    BOOL v8 = v7 == &mlir::detail::TypeIDResolver<mlir::arith::IndexCastOp,void>::id;
    if (v7 == &mlir::detail::TypeIDResolver<mlir::arith::IndexCastOp,void>::id) {
      uint64_t v9 = result;
    }
    else {
      uint64_t v9 = 0;
    }
    uint64_t v18 = v9;
    if (v8)
    {
      uint64_t Input = mlir::anec::Deconvolution::getInput((mlir::anec::Deconvolution *)&v18);
      uint64_t ElementTypeOrSelf = mlir::getElementTypeOrSelf(Input);
      uint64_t v15 = mlir::anec::Deconvolution::getInput((mlir::anec::Deconvolution *)&v18);
      if ((*(unsigned char *)(a2 + 46) & 0x80) != 0)
      {
        uint64_t v11 = *(void *)(a2 + 72);
        uint64_t v12 = *(unsigned int *)(a2 + 68) - 1;
      }
      else
      {
        uint64_t v11 = 0;
        uint64_t v12 = -1;
      }
      v14[0] = v11 + 32;
      v14[1] = v12;
      uint64_t v16 = mlir::OpBuilder::create<mlir::tensor::ExtractOp,mlir::Type &,mlir::Value,mlir::OperandRange>((mlir::OpBuilder *)(a3 + 8), v5, &ElementTypeOrSelf, &v15, (uint64_t)v14);
      v14[0] = *(void *)(a2 - 8) & 0xFFFFFFFFFFFFFFF8;
      unsigned int v13 = mlir::OpBuilder::create<mlir::arith::IndexCastOp,mlir::Type,mlir::tensor::ExtractOp &>((mlir::OpBuilder *)(a3 + 8), *(void *)(a2 + 24), v14, &v16);
      (*(void (**)(uint64_t, uint64_t, ZinIrHalH13g *))(*(void *)a3 + 32))(a3, a2, v13);
      return 1;
    }
    else
    {
      return 0;
    }
  }
  return result;
}

ZinIrHalH13g *mlir::OpBuilder::create<mlir::tensor::ExtractOp,mlir::Type &,mlir::Value,mlir::OperandRange>(mlir::OpBuilder *a1, uint64_t a2, uint64_t *a3, uint64_t *a4, uint64_t a5)
{
  v31[28] = *MEMORY[0x263EF8340];
  uint64_t v21 = a2;
  uint64_t Context = (uint64_t *)mlir::Attribute::getContext((mlir::Attribute *)&v21);
  uint64_t v11 = mlir::RegisteredOperationName::lookup((int8x16_t *)"tensor.extract", (const unsigned __int8 *)0xE, Context);
  if (!v12)
  {
    __int16 v25 = 1283;
    unint64_t v24[2] = (uint64_t)"tensor.extract";
    void v24[3] = 14;
          " the dialect. See also https://mlir.llvm.org/getting_started/Faq/#registered-loaded-dependent-whats-up-with-di"
          "alects-management";
    __int16 v23 = 259;
    llvm::operator+(v24, (uint64_t *)&v22, (uint64_t)v27);
    llvm::report_fatal_error((llvm::Twine *)v27, 1);
  }
  mlir::OperationState::OperationState(v27, a2, v11);
  uint64_t v13 = *a3;
  uint64_t v14 = *a4;
  mlir::ValueRange::ValueRange(v26, *(void *)a5, *(void *)(a5 + 8));
  uint64_t v15 = v26[0];
  uint64_t v16 = v26[1];
  v24[0] = v14;
  mlir::OperationState::addOperands((uint64_t)v27, (uint64_t)v24, 1);
  mlir::OperationState::addOperands((uint64_t)v27, v15, v16);
  unsigned int v17 = v29;
  if (v29 >= v30)
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v28, v31, v29 + 1, 8);
    unsigned int v17 = v29;
  }
  *(void *)(v28 + 8 * v17) = v13;
  ++v29;
  uint64_t v18 = mlir::OpBuilder::create(a1, (const mlir::OperationState *)v27);
  if (*(_UNKNOWN **)(*((void *)v18 + 6) + 16) == &mlir::detail::TypeIDResolver<mlir::tensor::ExtractOp,void>::id) {
    uint64_t v19 = v18;
  }
  else {
    uint64_t v19 = 0;
  }
  mlir::OperationState::~OperationState((mlir::OperationState *)v27);
  return v19;
}

ZinIrHalH13g *mlir::OpBuilder::create<mlir::arith::IndexCastOp,mlir::Type,mlir::tensor::ExtractOp &>(mlir::OpBuilder *a1, uint64_t a2, uint64_t *a3, void *a4)
{
  v19[38] = *MEMORY[0x263EF8340];
  uint64_t v14 = a2;
  uint64_t Context = (uint64_t *)mlir::Attribute::getContext((mlir::Attribute *)&v14);
  uint64_t v9 = mlir::RegisteredOperationName::lookup((int8x16_t *)"arith.index_cast", (const unsigned __int8 *)0x10, Context);
  if (!v10)
  {
    __int16 v18 = 1283;
    unint64_t v17[2] = (uint64_t)"arith.index_cast";
    v17[3] = 16;
          " the dialect. See also https://mlir.llvm.org/getting_started/Faq/#registered-loaded-dependent-whats-up-with-di"
          "alects-management";
    __int16 v16 = 259;
    llvm::operator+(v17, (uint64_t *)&v15, (uint64_t)v19);
    llvm::report_fatal_error((llvm::Twine *)v19, 1);
  }
  mlir::OperationState::OperationState(v19, a2, v9);
  mlir::anec::Broadcast::build((uint64_t)a1, (uint64_t)v19, *a3, *a4 - 16);
  uint64_t v11 = mlir::OpBuilder::create(a1, (const mlir::OperationState *)v19);
  if (*(_UNKNOWN **)(*((void *)v11 + 6) + 16) == &mlir::detail::TypeIDResolver<mlir::arith::IndexCastOp,void>::id) {
    char v12 = v11;
  }
  else {
    char v12 = 0;
  }
  mlir::OperationState::~OperationState((mlir::OperationState *)v19);
  return v12;
}

void anonymous namespace'::ExtractFromTensorGenerate::~ExtractFromTensorGenerate(_anonymous_namespace_::ExtractFromTensorGenerate *this)
{
  uint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  int64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }
}

{
  char *v2;
  char *v3;
  uint64_t vars8;

  uint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  int64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t anonymous namespace'::ExtractFromTensorGenerate::matchAndRewrite(uint64_t a1, uint64_t a2, uint64_t **a3)
{
  v30[0] = *(llvm **)(*(void *)(a2 + 72) + 24);
  uint64_t DefiningOp = mlir::Value::getDefiningOp((mlir::Value *)v30);
  uint64_t v7 = DefiningOp;
  if (DefiningOp)
  {
    if (*(_UNKNOWN **)(*(void *)(DefiningOp + 48) + 16) == &mlir::detail::TypeIDResolver<mlir::tensor::GenerateOp,void>::id
      && mlir::wouldOpBeTriviallyDead((void ***)DefiningOp, v6))
    {
      unsigned int v31 = 0;
      v30[0] = 0;
      v30[1] = 0;
      int v34 = 0;
      uint64_t v32 = 0;
      uint64_t v33 = 0;
      unsigned int v37 = 0;
      uint64_t v35 = 0;
      uint64_t v36 = 0;
      uint64_t v8 = *(void *)(((v7
                       + 16 * (((unint64_t)*(unsigned int *)(v7 + 44) >> 23) & 1)
                       + (((unint64_t)*(unsigned int *)(v7 + 44) >> 21) & 0x7F8)
                       + 71) & 0xFFFFFFFFFFFFFFF8)
                     + 32 * *(unsigned int *)(v7 + 40)
                     + 8);
      if (v8) {
        uint64_t v9 = v8 - 8;
      }
      else {
        uint64_t v9 = 0;
      }
      uint64_t v11 = *(unint64_t **)(v9 + 48);
      char v10 = *(unint64_t **)(v9 + 56);
      if ((*(unsigned char *)(a2 + 46) & 0x80) != 0)
      {
        uint64_t v12 = *(void *)(a2 + 72);
        uint64_t v13 = *(unsigned int *)(a2 + 68) - 1;
        if (v10 == v11 || *(_DWORD *)(a2 + 68) == 1) {
          goto LABEL_20;
        }
      }
      else
      {
        uint64_t v12 = 0;
        uint64_t v13 = -1;
        if (v10 == v11) {
          goto LABEL_20;
        }
      }
      uint64_t v15 = v13 - 1;
      __int16 v16 = (uint64_t *)(v12 + 56);
      uint64_t v17 = 8 * (v10 - v11) - 8;
      do
      {
        uint64_t v18 = *v16;
        unint64_t v38 = (void *)*v11;
        unint64_t v39 = 0;
        char v19 = llvm::DenseMapBase<llvm::DenseMap<mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>,mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>::LookupBucketFor<mlir::Value>((uint64_t *)v30, (unint64_t *)&v38, &v39);
        __int16 v20 = v39;
        if ((v19 & 1) == 0)
        {
          __int16 v20 = llvm::DenseMapBase<llvm::DenseMap<mlir::Value,mlir::Value,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,mlir::Value>>,mlir::Value,mlir::Value,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,mlir::Value>>::InsertIntoBucketImpl<mlir::Value>((uint64_t)v30, (uint64_t)&v38, (unint64_t *)&v38, v39);
          void *v20 = v38;
          v20[1] = 0;
        }
        v20[1] = v18;
        BOOL v22 = v15-- != 0;
        if (!v17) {
          break;
        }
        ++v11;
        v16 += 4;
        v17 -= 8;
      }
      while (v22);
LABEL_20:
      __int16 v23 = (ZinIrHalH13g **)(v9 + 32);
      unsigned int v24 = *(ZinIrHalH13g **)(v9 + 40);
      if (v24 != (ZinIrHalH13g *)(v9 + 32))
      {
        for (i = *v23; v24 != i; unsigned int v24 = (ZinIrHalH13g *)*((void *)v24 + 1))
        {
          ZinIrHalH13g::~ZinIrHalH13g(v24);
          mlir::OpBuilder::clone(a3 + 1, v26, (mlir::IRMapping *)v30);
        }
      }
      mlir::Block::getTerminator((ZinIrHalH13g **)v9);
      uint64_t v28 = *(void **)(*(void *)(v27 + 72) + 24);
      unint64_t v38 = v28;
      unint64_t v39 = 0;
      if (llvm::DenseMapBase<llvm::DenseMap<mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>,mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>::LookupBucketFor<mlir::Value>((uint64_t *)v30, (unint64_t *)&v38, &v39))
      {
        if (v39 != (void *)v30[0] + 2 * v31) {
          uint64_t v28 = (void *)v39[1];
        }
      }
      unint64_t v39 = v28;
      ((void (*)(uint64_t **, uint64_t, void **, uint64_t))(*a3)[3])(a3, a2, &v39, 1);
      llvm::deallocate_buffer(v35, (void *)(16 * v37));
    }
    return 0;
  }
  return v7;
}

void anonymous namespace'::StaticTensorGenerate::~StaticTensorGenerate(_anonymous_namespace_::StaticTensorGenerate *this)
{
  uint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  int64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }
}

{
  char *v2;
  char *v3;
  uint64_t vars8;

  uint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  int64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::tensor::GenerateOp>::rewrite(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 48))();
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::tensor::GenerateOp>::match(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 56))();
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::tensor::GenerateOp>::matchAndRewrite(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 64))();
}

uint64_t anonymous namespace'::StaticTensorGenerate::matchAndRewrite(uint64_t a1, uint64_t a2, uint64_t a3)
{
  v24[6] = *MEMORY[0x263EF8340];
  if (*(_DWORD *)(a2 + 36)) {
    uint64_t v5 = a2 - 16;
  }
  else {
    uint64_t v5 = 0;
  }
  unint64_t v18 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v5, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
  if (mlir::TensorType::hasRank((mlir::TensorType *)&v18))
  {
    uint64_t Value = (void *)mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v18);
    if (!v7) {
      return 0;
    }
    uint64_t v8 = 8 * v7;
    while (*Value != 0x8000000000000000)
    {
      ++Value;
      v8 -= 8;
      if (!v8) {
        return 0;
      }
    }
  }
  if ((*(unsigned char *)(a2 + 46) & 0x80) != 0)
  {
    uint64_t v9 = *(unsigned int *)(a2 + 68);
    uint64_t v10 = *(void *)(a2 + 72);
  }
  else
  {
    uint64_t v10 = 0;
    uint64_t v9 = 0;
  }
  BOOL v22 = v24;
  uint64_t v23 = 0x600000000;
  char v19 = v21;
  uint64_t v20 = 0x600000000;
  operandsAndShape(v18, v10, v9, (uint64_t)&v22, (uint64_t)&v19);
  uint64_t v11 = v19;
  uint64_t v12 = v20;
  if (v20)
  {
    uint64_t v13 = 0;
    while (*(void *)((char *)v19 + v13) < 0x8000000000000001)
    {
      v13 += 8;
      if (8 * v20 == v13) {
        goto LABEL_16;
      }
    }
    goto LABEL_18;
  }
LABEL_16:
  if ((*(unsigned char *)(a2 + 46) & 0x80) == 0)
  {
    if (!v23) {
      goto LABEL_18;
    }
LABEL_25:
    uint64_t v15 = *(void *)(a2 + 24);
    uint64_t RHS = mlir::AffineBinaryOpExpr::getRHS((mlir::AffineBinaryOpExpr *)&v18);
    uint64_t v17 = mlir::RankedTensorType::get((uint64_t)v11, v12, RHS, 0);
    mlir::OpBuilder::create<mlir::tensor::GenerateOp,mlir::RankedTensorType,llvm::SmallVector<mlir::Value,6u> &>(a3 + 8, v15, (uint64_t)&v17, (uint64_t)&v22);
  }
  if (*(_DWORD *)(a2 + 68) != (unint64_t)v23) {
    goto LABEL_25;
  }
LABEL_18:
  if (v19 != v21) {
    free(v19);
  }
  if (v22 != v24) {
    free(v22);
  }
  return 0;
}

void mlir::OpBuilder::create<mlir::tensor::GenerateOp,mlir::RankedTensorType,llvm::SmallVector<mlir::Value,6u> &>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  v15[38] = *MEMORY[0x263EF8340];
  uint64_t v9 = a2;
  uint64_t Context = (uint64_t *)mlir::Attribute::getContext((mlir::Attribute *)&v9);
  uint64_t v7 = mlir::RegisteredOperationName::lookup((int8x16_t *)"tensor.generate", (const unsigned __int8 *)0xF, Context);
  if (v8)
  {
    mlir::OperationState::OperationState(v15, a2, v7);
    mlir::ValueRange::ValueRange(v14, *(void *)a4, *(unsigned int *)(a4 + 8));
    mlir::OperationState::addOperands((uint64_t)v15, v14[0], v14[1]);
    mlir::OperationState::addRegion((mlir::OperationState *)v15);
  }
  __int16 v13 = 1283;
  void v12[2] = (uint64_t)"tensor.generate";
  unint64_t v12[3] = 15;
        "he dialect. See also https://mlir.llvm.org/getting_started/Faq/#registered-loaded-dependent-whats-up-with-dialects-management";
  __int16 v11 = 259;
  llvm::operator+(v12, (uint64_t *)&v10, (uint64_t)v15);
  llvm::report_fatal_error((llvm::Twine *)v15, 1);
}

uint64_t llvm::function_ref<mlir::LogicalResult ()(llvm::Twine const&)>::callback_fn<mlir::LogicalResult mlir::verifyReshapeLikeShapes<mlir::tensor::ExpandShapeOp>(mlir::tensor::ExpandShapeOp,mlir::ShapedType,mlir::ShapedType,BOOL)::{lambda(llvm::Twine const&)#1}>(uint64_t **a1, void ***a2)
{
  uint64_t v20 = *MEMORY[0x263EF8340];
  mlir::Operation::emitOpError(**a1, a2, (uint64_t)v12);
  uint64_t v2 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v12);
  if (v12[0]) {
    mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v12);
  }
  if (v19)
  {
    int64_t v3 = __p;
    if (__p)
    {
      int64_t v4 = v18;
      uint64_t v5 = __p;
      if (v18 != __p)
      {
        do
          int64_t v4 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v4 - 1);
        while (v4 != v3);
        uint64_t v5 = __p;
      }
      unint64_t v18 = v3;
      operator delete(v5);
    }
    uint64_t v6 = v15;
    if (v15)
    {
      uint64_t v7 = v16;
      char v8 = v15;
      if (v16 != v15)
      {
        do
        {
          uint64_t v10 = *--v7;
          uint64_t v9 = v10;
          *uint64_t v7 = 0;
          if (v10) {
            MEMORY[0x21667D390](v9, 0x1000C8077774924);
          }
        }
        while (v7 != v6);
        char v8 = v15;
      }
      __int16 v16 = v6;
      operator delete(v8);
    }
    if (v13 != &v14) {
      free(v13);
    }
  }
  return v2;
}

uint64_t llvm::function_ref<mlir::LogicalResult ()(llvm::Twine const&)>::callback_fn<mlir::LogicalResult mlir::verifyReshapeLikeShapes<mlir::tensor::CollapseShapeOp>(mlir::tensor::CollapseShapeOp,mlir::ShapedType,mlir::ShapedType,BOOL)::{lambda(llvm::Twine const&)#1}>(uint64_t **a1, void ***a2)
{
  uint64_t v20 = *MEMORY[0x263EF8340];
  mlir::Operation::emitOpError(**a1, a2, (uint64_t)v12);
  uint64_t v2 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)v12);
  if (v12[0]) {
    mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)v12);
  }
  if (v19)
  {
    int64_t v3 = __p;
    if (__p)
    {
      int64_t v4 = v18;
      uint64_t v5 = __p;
      if (v18 != __p)
      {
        do
          int64_t v4 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v4 - 1);
        while (v4 != v3);
        uint64_t v5 = __p;
      }
      unint64_t v18 = v3;
      operator delete(v5);
    }
    uint64_t v6 = v15;
    if (v15)
    {
      uint64_t v7 = v16;
      char v8 = v15;
      if (v16 != v15)
      {
        do
        {
          uint64_t v10 = *--v7;
          uint64_t v9 = v10;
          *uint64_t v7 = 0;
          if (v10) {
            MEMORY[0x21667D390](v9, 0x1000C8077774924);
          }
        }
        while (v7 != v6);
        char v8 = v15;
      }
      __int16 v16 = v6;
      operator delete(v8);
    }
    if (v13 != &v14) {
      free(v13);
    }
  }
  return v2;
}

void *mlir::ComposeReassociativeReshapeOps<mlir::tensor::ExpandShapeOp>::~ComposeReassociativeReshapeOps(void *a1)
{
  uint64_t v2 = (void *)a1[10];
  if (v2 != a1 + 12) {
    free(v2);
  }
  int64_t v3 = (void *)a1[4];
  if (v3 != a1 + 6) {
    free(v3);
  }
  return a1;
}

void mlir::ComposeReassociativeReshapeOps<mlir::tensor::ExpandShapeOp>::~ComposeReassociativeReshapeOps(void *a1)
{
  uint64_t v2 = (void *)a1[10];
  if (v2 != a1 + 12) {
    free(v2);
  }
  int64_t v3 = (void *)a1[4];
  if (v3 != a1 + 6) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::tensor::ExpandShapeOp>::rewrite(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 48))();
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::tensor::ExpandShapeOp>::match(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 56))();
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::tensor::ExpandShapeOp>::matchAndRewrite(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 64))();
}

uint64_t mlir::ComposeReassociativeReshapeOps<mlir::tensor::ExpandShapeOp>::matchAndRewrite(uint64_t a1, uint64_t a2, uint64_t *a3)
{
  uint64_t v41 = *MEMORY[0x263EF8340];
  uint64_t v30 = a2;
  int v34 = *(void **)(*(void *)(a2 + 72) + 24);
  uint64_t result = mlir::Value::getDefiningOp((mlir::Value *)&v34);
  if (result)
  {
    uint64_t v6 = result;
    uint64_t v7 = *(void **)(*(void *)(result + 48) + 16);
    BOOL v8 = v7 == &mlir::detail::TypeIDResolver<mlir::tensor::ExpandShapeOp,void>::id;
    if (v7 == &mlir::detail::TypeIDResolver<mlir::tensor::ExpandShapeOp,void>::id) {
      uint64_t v9 = result;
    }
    else {
      uint64_t v9 = 0;
    }
    uint64_t v29 = v9;
    if (!v8) {
      return 0;
    }
    uint64_t v10 = *(_DWORD *)(a2 + 36) ? a2 - 16 : 0;
    __int16 v11 = (void *)(*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v10, 0) + 8) & 0xFFFFFFFFFFFFFFF8);
    uint64_t v12 = v11 ? mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*v11 + 8) : 0;
    v28[0] = (uint64_t)v11;
    v28[1] = v12;
    if ((mlir::hasNonIdentityLayout(*(void *)(*(void *)(*(void *)(v6 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8) & 1) != 0
      || (mlir::hasNonIdentityLayout(*(void *)(*(void *)(*(void *)(a2 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8) & 1) != 0)
    {
      return 0;
    }
    uint64_t v13 = *(_DWORD *)(a2 + 36) ? a2 - 16 : 0;
    uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v13, 0);
    if (mlir::hasNonIdentityLayout(*(void *)(NextResultAtOffset + 8) & 0xFFFFFFFFFFFFFFF8)) {
      return 0;
    }
    mlir::memref::CollapseShapeOp::getReassociationIndices((mlir::memref::CollapseShapeOp *)&v29, (uint64_t)&v34);
    uint64_t v15 = v34;
    unint64_t v16 = v35;
    mlir::memref::CollapseShapeOp::getReassociationIndices((mlir::memref::CollapseShapeOp *)&v30, (uint64_t)&v31);
    mlir::composeReassociationIndices((uint64_t)v15, v16, (uint64_t)v31, v32, (uint64_t)&v37);
    uint64_t v17 = (char *)v31;
    if (v32)
    {
      uint64_t v18 = 32 * v32;
      do
      {
        char v19 = *(char **)&v17[v18 - 32];
        if (&v17[v18 - 16] != v19) {
          free(v19);
        }
        v18 -= 32;
      }
      while (v18);
      uint64_t v17 = (char *)v31;
    }
    if (v17 != (char *)&v33) {
      free(v17);
    }
    uint64_t v20 = (char *)v34;
    if (v35)
    {
      uint64_t v21 = 32 * v35;
      do
      {
        BOOL v22 = *(char **)&v20[v21 - 32];
        if (&v20[v21 - 16] != v22) {
          free(v22);
        }
        v21 -= 32;
      }
      while (v21);
      uint64_t v20 = (char *)v34;
    }
    if (v20 != (char *)&v36) {
      free(v20);
    }
    if (!v40)
    {
      return 0;
    }
    else
    {
      uint64_t v23 = v30;
      int v34 = *(void **)(*(void *)(v29 + 72) + 24);
      unsigned int v24 = mlir::OpBuilder::create<mlir::tensor::ExpandShapeOp,mlir::ShapedType &,mlir::detail::TypedValue<mlir::RankedTensorType>,llvm::SmallVector<llvm::SmallVector<long long,2u>,1u> &>(a3 + 1, *(void *)(v30 + 24), v28, (uint64_t *)&v34, (uint64_t)&v37);
      (*(void (**)(uint64_t *, uint64_t, ZinIrHalH13g *))(*a3 + 32))(a3, v23, v24);
      if (v40)
      {
        __int16 v25 = v37;
        if (v38)
        {
          uint64_t v26 = 32 * v38;
          do
          {
            uint64_t v27 = *(char **)&v25[v26 - 32];
            if (&v25[v26 - 16] != v27) {
              free(v27);
            }
            v26 -= 32;
          }
          while (v26);
          __int16 v25 = v37;
        }
        if (v25 != (char *)&v39) {
          free(v25);
        }
      }
      return 1;
    }
  }
  return result;
}

ZinIrHalH13g *mlir::RewriterBase::replaceOpWithNewOp<mlir::tensor::ExpandShapeOp,mlir::ShapedType &,mlir::detail::TypedValue<mlir::RankedTensorType>,llvm::SmallVector<llvm::SmallVector<long long,2u>,1u> &>(uint64_t *a1, uint64_t a2, uint64_t *a3, uint64_t *a4, uint64_t a5)
{
  uint64_t v7 = mlir::OpBuilder::create<mlir::tensor::ExpandShapeOp,mlir::ShapedType &,mlir::detail::TypedValue<mlir::RankedTensorType>,llvm::SmallVector<llvm::SmallVector<long long,2u>,1u> &>(a1 + 1, *(void *)(a2 + 24), a3, a4, a5);
  (*(void (**)(uint64_t *, uint64_t, ZinIrHalH13g *))(*a1 + 32))(a1, a2, v7);
  return v7;
}

ZinIrHalH13g *mlir::OpBuilder::create<mlir::tensor::ExpandShapeOp,mlir::ShapedType &,mlir::detail::TypedValue<mlir::RankedTensorType>,llvm::SmallVector<llvm::SmallVector<long long,2u>,1u> &>(uint64_t *a1, uint64_t a2, uint64_t *a3, uint64_t *a4, uint64_t a5)
{
  uint64_t v33[2] = *MEMORY[0x263EF8340];
  uint64_t v24 = a2;
  uint64_t Context = (uint64_t *)mlir::Attribute::getContext((mlir::Attribute *)&v24);
  uint64_t v11 = mlir::RegisteredOperationName::lookup((int8x16_t *)"tensor.expand_shape", (const unsigned __int8 *)0x13, Context);
  if (!v12)
  {
    __int16 v30 = 1283;
    uint64_t v29[2] = (uint64_t)"tensor.expand_shape";
    v29[3] = 19;
                      "een added by the dialect. See also https://mlir.llvm.org/getting_started/Faq/#registered-loaded-de"
                      "pendent-whats-up-with-dialects-management";
    __int16 v26 = 259;
    llvm::operator+(v29, v25, (uint64_t)v31);
    llvm::report_fatal_error((llvm::Twine *)v31, 1);
  }
  mlir::OperationState::OperationState(v31, a2, v11);
  uint64_t v13 = *a3;
  uint64_t v14 = *a4;
  uint64_t v15 = *(void *)a5;
  uint64_t v16 = *(unsigned int *)(a5 + 8);
  uint64_t v27 = v14;
  uint64_t v28 = v13;
  uint64_t v17 = mlir::ValueRange::ValueRange(v33, (uint64_t)&v28, 1uLL);
  mlir::arith::CmpIOp::build((uint64_t)v17, (uint64_t)v31, v33[0], v33[1], (uint64_t)&v27, 1, 0, 0);
  uint64_t ReassociationIndicesAttribute = mlir::getReassociationIndicesAttribute(a1, v15, v16);
  char v19 = (mlir::StringAttr *)mlir::Attribute::getContext((mlir::Attribute *)v31);
  __int16 v30 = 261;
  v29[0] = (uint64_t)"reassociation";
  v29[1] = 13;
  uint64_t v20 = mlir::StringAttr::get(v19, (mlir::MLIRContext *)v29);
  ZinMirCacheTensors::ZinMirCacheTensors(v25, v20, ReassociationIndicesAttribute);
  mlir::NamedAttrList::push_back((uint64_t)&v32, v25[0], v25[1]);
  uint64_t v21 = mlir::OpBuilder::create((mlir::OpBuilder *)a1, (const mlir::OperationState *)v31);
  if (*(_UNKNOWN **)(*((void *)v21 + 6) + 16) == &mlir::detail::TypeIDResolver<mlir::tensor::ExpandShapeOp,void>::id) {
    BOOL v22 = v21;
  }
  else {
    BOOL v22 = 0;
  }
  mlir::OperationState::~OperationState((mlir::OperationState *)v31);
  return v22;
}

void *mlir::ComposeExpandOfCollapseOp<mlir::tensor::ExpandShapeOp,mlir::tensor::CollapseShapeOp>::~ComposeExpandOfCollapseOp(void *a1)
{
  uint64_t v2 = (void *)a1[10];
  if (v2 != a1 + 12) {
    free(v2);
  }
  int64_t v3 = (void *)a1[4];
  if (v3 != a1 + 6) {
    free(v3);
  }
  return a1;
}

void mlir::ComposeExpandOfCollapseOp<mlir::tensor::ExpandShapeOp,mlir::tensor::CollapseShapeOp>::~ComposeExpandOfCollapseOp(void *a1)
{
  uint64_t v2 = (void *)a1[10];
  if (v2 != a1 + 12) {
    free(v2);
  }
  int64_t v3 = (void *)a1[4];
  if (v3 != a1 + 6) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t mlir::ComposeExpandOfCollapseOp<mlir::tensor::ExpandShapeOp,mlir::tensor::CollapseShapeOp>::matchAndRewrite(uint64_t a1, uint64_t a2, uint64_t *a3)
{
  v59[16] = *MEMORY[0x263EF8340];
  uint64_t v51 = a2;
  unint64_t v57 = *(uint64_t ***)(*(void *)(a2 + 72) + 24);
  uint64_t DefiningOp = mlir::Value::getDefiningOp((mlir::Value *)&v57);
  if (!DefiningOp) {
    return 0;
  }
  uint64_t v6 = DefiningOp;
  uint64_t v7 = *(void **)(*(void *)(DefiningOp + 48) + 16);
  BOOL v8 = v7 == &mlir::detail::TypeIDResolver<mlir::tensor::CollapseShapeOp,void>::id;
  uint64_t v9 = v7 == &mlir::detail::TypeIDResolver<mlir::tensor::CollapseShapeOp,void>::id ? DefiningOp : 0;
  uint64_t v50 = v9;
  if (!v8) {
    return 0;
  }
  uint64_t v10 = (void *)(*(void *)(*(void *)(*(void *)(DefiningOp + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8);
  uint64_t v11 = v10 ? mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*v10 + 8) : 0;
  v49[0] = v10;
  v49[1] = v11;
  uint64_t v12 = *(_DWORD *)(a2 + 36) ? a2 - 16 : 0;
  uint64_t v13 = (void *)(*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v12, 0) + 8) & 0xFFFFFFFFFFFFFFF8);
  uint64_t v14 = v13 ? mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*v13 + 8) : 0;
  v48[0] = (uint64_t)v13;
  v48[1] = v14;
  if ((mlir::hasNonIdentityLayout(*(void *)(*(void *)(*(void *)(a2 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8) & 1) != 0
    || (mlir::hasNonIdentityLayout(*(void *)(*(void *)(*(void *)(v6 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8) & 1) != 0)
  {
    return 0;
  }
  uint64_t v15 = *(_DWORD *)(v6 + 36) ? v6 - 16 : 0;
  uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v15, 0);
  if (mlir::hasNonIdentityLayout(*(void *)(NextResultAtOffset + 8) & 0xFFFFFFFFFFFFFFF8)) {
    return 0;
  }
  mlir::ShapedType::getShape((mlir::ShapedType *)v49);
  uint64_t v18 = v17;
  mlir::ShapedType::getShape((mlir::ShapedType *)v48);
  if (v49[0] == v48[0]) {
    return 0;
  }
  uint64_t v20 = v19;
  mlir::memref::CollapseShapeOp::getReassociationIndices((mlir::memref::CollapseShapeOp *)&v50, (uint64_t)&v57);
  mlir::memref::CollapseShapeOp::getReassociationIndices((mlir::memref::CollapseShapeOp *)&v51, (uint64_t)&v54);
  if (v18 <= v20)
  {
    uint64_t v32 = v54;
    uint64_t v33 = v55;
    int v34 = v57;
    uint64_t v35 = v58;
    uint64_t Shape = mlir::ShapedType::getShape((mlir::ShapedType *)v48);
    unint64_t v38 = v37;
    uint64_t v39 = mlir::ShapedType::getShape((mlir::ShapedType *)v49);
    mlir::ComposeExpandOfCollapseOp<mlir::memref::ExpandShapeOp,mlir::memref::CollapseShapeOp>::findCollapsingReassociation((unint64_t)v32, v33, v34, v35, Shape, v38, (uint64_t)v52, v39, v40);
    if (v53)
    {
      uint64_t v47 = *(void *)(*(void *)(v50 + 72) + 24);
      mlir::RewriterBase::replaceOpWithNewOp<mlir::tensor::ExpandShapeOp,mlir::ShapedType &,mlir::detail::TypedValue<mlir::RankedTensorType>,llvm::SmallVector<llvm::SmallVector<long long,2u>,1u> &>(a3, v51, v48, &v47, (uint64_t)v52);
      goto LABEL_30;
    }
LABEL_31:
    uint64_t v30 = 0;
    goto LABEL_32;
  }
  unint64_t v21 = (unint64_t)v57;
  uint64_t v22 = v58;
  uint64_t v23 = (uint64_t **)v54;
  uint64_t v24 = v55;
  uint64_t v25 = mlir::ShapedType::getShape((mlir::ShapedType *)v49);
  unint64_t v27 = v26;
  uint64_t v28 = mlir::ShapedType::getShape((mlir::ShapedType *)v48);
  mlir::ComposeExpandOfCollapseOp<mlir::memref::ExpandShapeOp,mlir::memref::CollapseShapeOp>::findCollapsingReassociation(v21, v22, v23, v24, v25, v27, (uint64_t)v52, v28, v29);
  if (!v53) {
    goto LABEL_31;
  }
  uint64_t v47 = *(void *)(*(void *)(v50 + 72) + 24);
  mlir::RewriterBase::replaceOpWithNewOp<mlir::tensor::CollapseShapeOp,mlir::ShapedType &,mlir::detail::TypedValue<mlir::RankedTensorType>,llvm::SmallVector<llvm::SmallVector<long long,2u>,1u> &>(a3, v51, v48, &v47, (uint64_t)v52);
LABEL_30:
  uint64_t v30 = 1;
LABEL_32:
  std::optional<llvm::SmallVector<llvm::SmallVector<long long,2u>,1u>>::~optional(v52);
  uint64_t v41 = (char *)v54;
  if (v55)
  {
    uint64_t v42 = 32 * v55;
    do
    {
      unint64_t v43 = *(char **)&v41[v42 - 32];
      if (&v41[v42 - 16] != v43) {
        free(v43);
      }
      v42 -= 32;
    }
    while (v42);
    uint64_t v41 = (char *)v54;
  }
  if (v41 != (char *)&v56) {
    free(v41);
  }
  unsigned int v44 = v57;
  if (v58)
  {
    uint64_t v45 = 4 * v58;
    do
    {
      uint64_t v46 = (char *)v44[v45 - 4];
      if (&v44[v45 - 2] != (uint64_t **)v46) {
        free(v46);
      }
      v45 -= 4;
    }
    while (v45 * 8);
    unsigned int v44 = v57;
  }
  if (v44 != v59) {
    free(v44);
  }
  return v30;
}

ZinIrHalH13g *mlir::RewriterBase::replaceOpWithNewOp<mlir::tensor::CollapseShapeOp,mlir::ShapedType &,mlir::detail::TypedValue<mlir::RankedTensorType>,llvm::SmallVector<llvm::SmallVector<long long,2u>,1u> &>(uint64_t *a1, uint64_t a2, uint64_t *a3, uint64_t *a4, uint64_t a5)
{
  uint64_t v7 = mlir::OpBuilder::create<mlir::tensor::CollapseShapeOp,mlir::ShapedType &,mlir::detail::TypedValue<mlir::RankedTensorType>,llvm::SmallVector<llvm::SmallVector<long long,2u>,1u> &>(a1 + 1, *(void *)(a2 + 24), a3, a4, a5);
  (*(void (**)(uint64_t *, uint64_t, ZinIrHalH13g *))(*a1 + 32))(a1, a2, v7);
  return v7;
}

ZinIrHalH13g *mlir::OpBuilder::create<mlir::tensor::CollapseShapeOp,mlir::ShapedType &,mlir::detail::TypedValue<mlir::RankedTensorType>,llvm::SmallVector<llvm::SmallVector<long long,2u>,1u> &>(uint64_t *a1, uint64_t a2, uint64_t *a3, uint64_t *a4, uint64_t a5)
{
  uint64_t v33[2] = *MEMORY[0x263EF8340];
  uint64_t v24 = a2;
  uint64_t Context = (uint64_t *)mlir::Attribute::getContext((mlir::Attribute *)&v24);
  uint64_t v11 = mlir::RegisteredOperationName::lookup((int8x16_t *)"tensor.collapse_shape", (const unsigned __int8 *)0x15, Context);
  if (!v12)
  {
    __int16 v30 = 1283;
    uint64_t v29[2] = (uint64_t)"tensor.collapse_shape";
    v29[3] = 21;
                      "een added by the dialect. See also https://mlir.llvm.org/getting_started/Faq/#registered-loaded-de"
                      "pendent-whats-up-with-dialects-management";
    __int16 v26 = 259;
    llvm::operator+(v29, v25, (uint64_t)v31);
    llvm::report_fatal_error((llvm::Twine *)v31, 1);
  }
  mlir::OperationState::OperationState(v31, a2, v11);
  uint64_t v13 = *a3;
  uint64_t v14 = *a4;
  uint64_t v15 = *(void *)a5;
  uint64_t v16 = *(unsigned int *)(a5 + 8);
  uint64_t v27 = v14;
  uint64_t v28 = v13;
  uint64_t v17 = mlir::ValueRange::ValueRange(v33, (uint64_t)&v28, 1uLL);
  mlir::arith::CmpIOp::build((uint64_t)v17, (uint64_t)v31, v33[0], v33[1], (uint64_t)&v27, 1, 0, 0);
  uint64_t ReassociationIndicesAttribute = mlir::getReassociationIndicesAttribute(a1, v15, v16);
  uint64_t v19 = (mlir::StringAttr *)mlir::Attribute::getContext((mlir::Attribute *)v31);
  __int16 v30 = 261;
  v29[0] = (uint64_t)"reassociation";
  v29[1] = 13;
  uint64_t v20 = mlir::StringAttr::get(v19, (mlir::MLIRContext *)v29);
  ZinMirCacheTensors::ZinMirCacheTensors(v25, v20, ReassociationIndicesAttribute);
  mlir::NamedAttrList::push_back((uint64_t)&v32, v25[0], v25[1]);
  unint64_t v21 = mlir::OpBuilder::create((mlir::OpBuilder *)a1, (const mlir::OperationState *)v31);
  if (*(_UNKNOWN **)(*((void *)v21 + 6) + 16) == &mlir::detail::TypeIDResolver<mlir::tensor::CollapseShapeOp,void>::id) {
    uint64_t v22 = v21;
  }
  else {
    uint64_t v22 = 0;
  }
  mlir::OperationState::~OperationState((mlir::OperationState *)v31);
  return v22;
}

void *anonymous namespace'::FoldReshapeWithConstant<mlir::tensor::ExpandShapeOp>::~FoldReshapeWithConstant(void *a1)
{
  uint64_t v2 = (void *)a1[10];
  if (v2 != a1 + 12) {
    free(v2);
  }
  int64_t v3 = (void *)a1[4];
  if (v3 != a1 + 6) {
    free(v3);
  }
  return a1;
}

void anonymous namespace'::FoldReshapeWithConstant<mlir::tensor::ExpandShapeOp>::~FoldReshapeWithConstant(void *a1)
{
  uint64_t v2 = (void *)a1[10];
  if (v2 != a1 + 12) {
    free(v2);
  }
  int64_t v3 = (void *)a1[4];
  if (v3 != a1 + 6) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t anonymous namespace'::FoldReshapeWithConstant<mlir::tensor::ExpandShapeOp>::matchAndRewrite(uint64_t a1, uint64_t a2, uint64_t a3)
{
  v27[1] = *MEMORY[0x263EF8340];
  uint64_t v5 = *(void *)(*(void *)(a2 + 72) + 24);
  unint64_t v24 = 0;
  uint64_t v25 = v5;
  uint64_t DefiningOp = mlir::Value::getDefiningOp((mlir::Value *)&v25);
  if (!DefiningOp) {
    return 0;
  }
  uint64_t v7 = DefiningOp;
  if (!mlir::OperationName::hasTrait<mlir::OpTrait::ConstantLike>((void *)(DefiningOp + 48))) {
    return 0;
  }
  v26[0] = v27;
  v26[1] = (void *)0x100000000;
  mlir::Operation::fold(v7, 0, 0, (uint64_t)v26);
  uint64_t v8 = *(void *)v26[0];
  BOOL v9 = mlir::DenseElementsAttr::classof(*(void *)v26[0] & 0xFFFFFFFFFFFFFFF8);
  unint64_t v10 = 0;
  unint64_t v11 = v8 & 0xFFFFFFFFFFFFFFF8;
  char v12 = (v8 & 0xFFFFFFFFFFFFFFF8) == 0 || !v9;
  if ((v12 & 1) == 0)
  {
    unint64_t v24 = v11;
    unint64_t v10 = v11;
  }
  if (v26[0] != v27) {
    free(v26[0]);
  }
  char v13 = v10 ? v12 : 1;
  if (v13) {
    return 0;
  }
  uint64_t result = mlir::DenseElementsAttr::isSplat((mlir::DenseElementsAttr *)&v24);
  if (result)
  {
    if (*(_DWORD *)(a2 + 36)) {
      uint64_t v15 = a2 - 16;
    }
    else {
      uint64_t v15 = 0;
    }
    uint64_t v16 = (void *)(*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v15, 0) + 8) & 0xFFFFFFFFFFFFFFF8);
    if (v16) {
      uint64_t v17 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*v16 + 8);
    }
    else {
      uint64_t v17 = 0;
    }
    uint64_t RawStringData = mlir::DenseElementsAttr::getRawStringData((mlir::DenseElementsAttr *)&v24);
    v26[0] = (void *)mlir::DenseElementsAttr::getFromRawBuffer(v16, v17, RawStringData, v19, v20, v21, v22);
    uint64_t v23 = mlir::OpBuilder::create<mlir::arith::ConstantOp,mlir::DenseElementsAttr &>((mlir::OpBuilder *)(a3 + 8), *(void *)(a2 + 24), (void **)v26);
    (*(void (**)(uint64_t, uint64_t, ZinIrHalH13g *))(*(void *)a3 + 32))(a3, a2, v23);
    return 1;
  }
  return result;
}

ZinIrHalH13g *mlir::OpBuilder::create<mlir::arith::ConstantOp,mlir::DenseElementsAttr &>(mlir::OpBuilder *a1, uint64_t a2, void **a3)
{
  v19[38] = *MEMORY[0x263EF8340];
  uint64_t v14 = a2;
  uint64_t Context = (uint64_t *)mlir::Attribute::getContext((mlir::Attribute *)&v14);
  uint64_t v7 = mlir::RegisteredOperationName::lookup((int8x16_t *)"arith.constant", (const unsigned __int8 *)0xE, Context);
  if (!v8)
  {
    __int16 v18 = 1283;
    unint64_t v17[2] = (uint64_t)"arith.constant";
    v17[3] = 14;
          " the dialect. See also https://mlir.llvm.org/getting_started/Faq/#registered-loaded-dependent-whats-up-with-di"
          "alects-management";
    __int16 v16 = 259;
    llvm::operator+(v17, (uint64_t *)&v15, (uint64_t)v19);
    llvm::report_fatal_error((llvm::Twine *)v19, 1);
  }
  mlir::OperationState::OperationState(v19, a2, v7);
  BOOL v9 = *a3;
  if (v9) {
    uint64_t v10 = *(void *)(mlir::detail::InterfaceMap::lookup<mlir::ElementsAttr>(*v9 + 8) + 24);
  }
  else {
    uint64_t v10 = 0;
  }
  mlir::arith::ConstantOp::build((uint64_t)a1, (uint64_t)v19, (uint64_t)v9, v10);
  unint64_t v11 = mlir::OpBuilder::create(a1, (const mlir::OperationState *)v19);
  if (*(_UNKNOWN **)(*((void *)v11 + 6) + 16) == &mlir::detail::TypeIDResolver<mlir::arith::ConstantOp,void>::id) {
    char v12 = v11;
  }
  else {
    char v12 = 0;
  }
  mlir::OperationState::~OperationState((mlir::OperationState *)v19);
  return v12;
}

void *anonymous namespace'::FoldReshapeWithSplat<mlir::tensor::ExpandShapeOp>::~FoldReshapeWithSplat(void *a1)
{
  uint64_t v2 = (void *)a1[10];
  if (v2 != a1 + 12) {
    free(v2);
  }
  int64_t v3 = (void *)a1[4];
  if (v3 != a1 + 6) {
    free(v3);
  }
  return a1;
}

void anonymous namespace'::FoldReshapeWithSplat<mlir::tensor::ExpandShapeOp>::~FoldReshapeWithSplat(void *a1)
{
  uint64_t v2 = (void *)a1[10];
  if (v2 != a1 + 12) {
    free(v2);
  }
  int64_t v3 = (void *)a1[4];
  if (v3 != a1 + 6) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t anonymous namespace'::FoldReshapeWithSplat<mlir::tensor::ExpandShapeOp>::matchAndRewrite(uint64_t a1, uint64_t a2, uint64_t a3)
{
  unint64_t v11 = *(void *)(*(void *)(a2 + 72) + 24);
  uint64_t result = mlir::Value::getDefiningOp((mlir::Value *)&v11);
  if (result)
  {
    uint64_t v6 = result;
    if (*(_UNKNOWN **)(*(void *)(result + 48) + 16) == &mlir::detail::TypeIDResolver<mlir::tensor::SplatOp,void>::id)
    {
      if (*(_DWORD *)(a2 + 36)) {
        uint64_t v7 = a2 - 16;
      }
      else {
        uint64_t v7 = 0;
      }
      unint64_t v8 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v7, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
      uint64_t v10 = *(void *)(*(void *)(v6 + 72) + 24);
      unint64_t v11 = v8;
      BOOL v9 = mlir::OpBuilder::create<mlir::tensor::SplatOp,mlir::RankedTensorType,mlir::Value>((mlir::OpBuilder *)(a3 + 8), *(void *)(a2 + 24), (uint64_t *)&v11, &v10);
      (*(void (**)(uint64_t, uint64_t, ZinIrHalH13g *))(*(void *)a3 + 32))(a3, a2, v9);
      return 1;
    }
    else
    {
      return 0;
    }
  }
  return result;
}

ZinIrHalH13g *mlir::OpBuilder::create<mlir::tensor::SplatOp,mlir::RankedTensorType,mlir::Value>(mlir::OpBuilder *a1, uint64_t a2, uint64_t *a3, uint64_t *a4)
{
  v25[28] = *MEMORY[0x263EF8340];
  uint64_t v16 = a2;
  uint64_t Context = (uint64_t *)mlir::Attribute::getContext((mlir::Attribute *)&v16);
  uint64_t v9 = mlir::RegisteredOperationName::lookup((int8x16_t *)"tensor.splat", (const unsigned __int8 *)0xC, Context);
  if (!v10)
  {
    __int16 v20 = 1283;
    void v19[2] = (uint64_t)"tensor.splat";
    v19[3] = 12;
          " the dialect. See also https://mlir.llvm.org/getting_started/Faq/#registered-loaded-dependent-whats-up-with-di"
          "alects-management";
    __int16 v18 = 259;
    llvm::operator+(v19, (uint64_t *)&v17, (uint64_t)v21);
    llvm::report_fatal_error((llvm::Twine *)v21, 1);
  }
  mlir::OperationState::OperationState(v21, a2, v9);
  uint64_t v11 = *a3;
  v19[0] = *a4;
  mlir::OperationState::addOperands((uint64_t)v21, (uint64_t)v19, 1);
  unsigned int v12 = v23;
  if (v23 >= v24)
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v22, v25, v23 + 1, 8);
    unsigned int v12 = v23;
  }
  *(void *)(v22 + 8 * v12) = v11;
  ++v23;
  char v13 = mlir::OpBuilder::create(a1, (const mlir::OperationState *)v21);
  if (*(_UNKNOWN **)(*((void *)v13 + 6) + 16) == &mlir::detail::TypeIDResolver<mlir::tensor::SplatOp,void>::id) {
    uint64_t v14 = v13;
  }
  else {
    uint64_t v14 = 0;
  }
  mlir::OperationState::~OperationState((mlir::OperationState *)v21);
  return v14;
}

void *anonymous namespace'::FoldReshapeWithFromElements<mlir::tensor::ExpandShapeOp>::~FoldReshapeWithFromElements(void *a1)
{
  uint64_t v2 = (void *)a1[10];
  if (v2 != a1 + 12) {
    free(v2);
  }
  int64_t v3 = (void *)a1[4];
  if (v3 != a1 + 6) {
    free(v3);
  }
  return a1;
}

void anonymous namespace'::FoldReshapeWithFromElements<mlir::tensor::ExpandShapeOp>::~FoldReshapeWithFromElements(void *a1)
{
  uint64_t v2 = (void *)a1[10];
  if (v2 != a1 + 12) {
    free(v2);
  }
  int64_t v3 = (void *)a1[4];
  if (v3 != a1 + 6) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t anonymous namespace'::FoldReshapeWithFromElements<mlir::tensor::ExpandShapeOp>::matchAndRewrite(uint64_t a1, uint64_t a2, uint64_t a3)
{
  __int16 v18 = *(void **)(*(void *)(a2 + 72) + 24);
  uint64_t result = mlir::Value::getDefiningOp((mlir::Value *)&v18);
  if (result)
  {
    uint64_t v6 = *(void **)(*(void *)(result + 48) + 16);
    if (v6 == &mlir::detail::TypeIDResolver<mlir::tensor::FromElementsOp,void>::id) {
      uint64_t v7 = result;
    }
    else {
      uint64_t v7 = 0;
    }
    if (v6 != &mlir::detail::TypeIDResolver<mlir::tensor::FromElementsOp,void>::id) {
      return 0;
    }
    unint64_t v8 = (void *)(*(void *)(a2 - 8) & 0xFFFFFFFFFFFFFFF8);
    if (v8)
    {
      uint64_t v9 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*v8 + 8);
      __int16 v18 = v8;
      uint64_t v19 = v9;
      uint64_t result = mlir::CallOpInterface::getArgOperands((mlir::CallOpInterface *)&v18);
      if (!result) {
        return result;
      }
    }
    else
    {
      __int16 v18 = 0;
      uint64_t v19 = 0;
      uint64_t result = mlir::CallOpInterface::getArgOperands((mlir::CallOpInterface *)&v18);
      if (!result) {
        return result;
      }
    }
    uint64_t Shape = (void *)mlir::ShapedType::getShape((mlir::ShapedType *)&v18);
    if (v11)
    {
      uint64_t v12 = 8 * v11;
      while (*Shape != 0x8000000000000000)
      {
        ++Shape;
        v12 -= 8;
        if (!v12) {
          goto LABEL_16;
        }
      }
      return 0;
    }
    else
    {
LABEL_16:
      unint64_t v17 = *(void *)(a2 - 8) & 0xFFFFFFFFFFFFFFF8;
      if ((*(unsigned char *)(v7 + 46) & 0x80) != 0)
      {
        uint64_t v13 = *(unsigned int *)(v7 + 68);
        uint64_t v14 = *(void *)(v7 + 72);
      }
      else
      {
        uint64_t v14 = 0;
        uint64_t v13 = 0;
      }
      v16[0] = v14;
      v16[1] = v13;
      uint64_t v15 = mlir::OpBuilder::create<mlir::tensor::FromElementsOp,mlir::RankedTensorType,mlir::OperandRange>((mlir::OpBuilder *)(a3 + 8), *(void *)(a2 + 24), (uint64_t *)&v17, (uint64_t)v16);
      (*(void (**)(uint64_t, uint64_t, ZinIrHalH13g *))(*(void *)a3 + 32))(a3, a2, v15);
      return 1;
    }
  }
  return result;
}

ZinIrHalH13g *mlir::OpBuilder::create<mlir::tensor::FromElementsOp,mlir::RankedTensorType,mlir::OperandRange>(mlir::OpBuilder *a1, uint64_t a2, uint64_t *a3, uint64_t a4)
{
  v26[28] = *MEMORY[0x263EF8340];
  uint64_t v16 = a2;
  uint64_t Context = (uint64_t *)mlir::Attribute::getContext((mlir::Attribute *)&v16);
  uint64_t v9 = mlir::RegisteredOperationName::lookup((int8x16_t *)"tensor.from_elements", (const unsigned __int8 *)0x14, Context);
  if (!v10)
  {
    __int16 v20 = 1283;
    void v19[2] = (uint64_t)"tensor.from_elements";
    v19[3] = 20;
          " the dialect. See also https://mlir.llvm.org/getting_started/Faq/#registered-loaded-dependent-whats-up-with-di"
          "alects-management";
    __int16 v18 = 259;
    llvm::operator+(v19, (uint64_t *)&v17, (uint64_t)v22);
    llvm::report_fatal_error((llvm::Twine *)v22, 1);
  }
  mlir::OperationState::OperationState(v22, a2, v9);
  uint64_t v11 = *a3;
  mlir::ValueRange::ValueRange(v21, *(void *)a4, *(void *)(a4 + 8));
  mlir::OperationState::addOperands((uint64_t)v22, v21[0], v21[1]);
  unsigned int v12 = v24;
  if (v24 >= v25)
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v23, v26, v24 + 1, 8);
    unsigned int v12 = v24;
  }
  *(void *)(v23 + 8 * v12) = v11;
  ++v24;
  uint64_t v13 = mlir::OpBuilder::create(a1, (const mlir::OperationState *)v22);
  if (*(_UNKNOWN **)(*((void *)v13 + 6) + 16) == &mlir::detail::TypeIDResolver<mlir::tensor::FromElementsOp,void>::id) {
    uint64_t v14 = v13;
  }
  else {
    uint64_t v14 = 0;
  }
  mlir::OperationState::~OperationState((mlir::OperationState *)v22);
  return v14;
}

void anonymous namespace'::FoldDimOfExpandShape::~FoldDimOfExpandShape(_anonymous_namespace_::FoldDimOfExpandShape *this)
{
  uint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  int64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }
}

{
  char *v2;
  char *v3;
  uint64_t vars8;

  uint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  int64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t anonymous namespace'::FoldDimOfExpandShape::matchAndRewrite(uint64_t a1, uint64_t a2, mlir::IndexType **a3)
{
  void v40[2] = *MEMORY[0x263EF8340];
  uint64_t v35 = *(void **)(*(void *)(a2 + 72) + 24);
  uint64_t result = mlir::Value::getDefiningOp((mlir::Value *)&v35);
  if (!result) {
    return result;
  }
  uint64_t v6 = result;
  uint64_t v7 = *(void **)(*(void *)(result + 48) + 16);
  BOOL v8 = v7 == &mlir::detail::TypeIDResolver<mlir::tensor::ExpandShapeOp,void>::id;
  if (v7 == &mlir::detail::TypeIDResolver<mlir::tensor::ExpandShapeOp,void>::id) {
    uint64_t v9 = result;
  }
  else {
    uint64_t v9 = 0;
  }
  uint64_t v34 = v9;
  if (!v8) {
    return 0;
  }
  unint64_t ConstantIntValue = mlir::getConstantIntValue(*(void *)(*(void *)(a2 + 72) + 56) | 4);
  if (!v11) {
    return 0;
  }
  uint64_t v12 = ConstantIntValue;
  uint64_t v13 = *(_DWORD *)(v6 + 36) ? v6 - 16 : 0;
  unint64_t v33 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v13, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
  if (*(void *)(mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v33) + 8 * v12) != 0x8000000000000000) {
    return 0;
  }
  uint64_t CorrespondingSourceDim = mlir::tensor::ExpandShapeOp::getCorrespondingSourceDim((mlir::tensor::ExpandShapeOp *)&v34, v12);
  mlir::memref::CollapseShapeOp::getReassociationIndices((mlir::memref::CollapseShapeOp *)&v34, (uint64_t)&v35);
  uint64_t v14 = (char *)v35;
  uint64_t v15 = (char *)v35 + 32 * CorrespondingSourceDim;
  unint64_t v38 = v40;
  uint64_t v39 = 0x200000000;
  unsigned int v16 = *((_DWORD *)v15 + 2);
  if (&v38 != (void **)v15 && v16 != 0)
  {
    if (v16 < 3)
    {
      uint64_t v19 = v40;
      unsigned int v18 = *((_DWORD *)v15 + 2);
    }
    else
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v38, v40, *((unsigned int *)v15 + 2), 8);
      unsigned int v18 = *((_DWORD *)v15 + 2);
      if (!v18)
      {
LABEL_22:
        LODWORD(v39) = v16;
        uint64_t v14 = (char *)v35;
        goto LABEL_23;
      }
      uint64_t v19 = v38;
    }
    memcpy(v19, *(const void **)v15, 8 * v18);
    goto LABEL_22;
  }
LABEL_23:
  if (v36)
  {
    uint64_t v20 = 32 * v36;
    do
    {
      uint64_t v21 = *(char **)&v14[v20 - 32];
      if (&v14[v20 - 16] != v21) {
        free(v21);
      }
      v20 -= 32;
    }
    while (v20);
    uint64_t v14 = (char *)v35;
  }
  if (v14 != (char *)&v37) {
    free(v14);
  }
  if (v39)
  {
    uint64_t v22 = v38;
    uint64_t v23 = 8 * v39;
    uint64_t v24 = 1;
    do
    {
      if (*v22 != v12)
      {
        uint64_t v25 = *v22;
        v24 *= *(void *)(mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v33) + 8 * v25);
      }
      ++v22;
      v23 -= 8;
    }
    while (v23);
  }
  else
  {
    uint64_t v24 = 1;
  }
  uint64_t v26 = *(void *)(a2 + 24);
  AffineSymbolExpr = *(mlir::MLIRContext ***)(*(void *)(v34 + 72) + 24);
  uint64_t v35 = (char *)mlir::OpBuilder::create<mlir::tensor::DimOp,mlir::detail::TypedValue<mlir::RankedTensorType>,long long &>(a3 + 1, v26, (uint64_t *)&AffineSymbolExpr, (mlir::MLIRContext **)&CorrespondingSourceDim)- 16;
  uint64_t Context = (mlir::MLIRContext *)mlir::Attribute::getContext((mlir::Attribute *)(a2 + 24));
  AffineSymbolExpr = (mlir::MLIRContext **)mlir::getAffineSymbolExpr(0, Context, v28);
  uint64_t v30 = mlir::AffineExpr::floorDiv(&AffineSymbolExpr, v24);
  unint64_t v29 = mlir::OpBuilder::create<mlir::affine::AffineApplyOp,mlir::AffineExpr,mlir::Value &>(a3 + 1, *(void *)(a2 + 24), (mlir::AffineExpr *)&v30, (uint64_t)&v35);
  (*((void (**)(mlir::IndexType **, uint64_t, ZinIrHalH13g *))*a3 + 4))(a3, a2, v29);
  if (v38 != v40) {
    free(v38);
  }
  return 1;
}

ZinIrHalH13g *mlir::OpBuilder::create<mlir::tensor::DimOp,mlir::detail::TypedValue<mlir::RankedTensorType>,long long &>(mlir::IndexType **a1, uint64_t a2, uint64_t *a3, mlir::MLIRContext **a4)
{
  v21[38] = *MEMORY[0x263EF8340];
  uint64_t v16 = a2;
  uint64_t Context = (uint64_t *)mlir::Attribute::getContext((mlir::Attribute *)&v16);
  uint64_t v9 = mlir::RegisteredOperationName::lookup((int8x16_t *)"tensor.dim", (const unsigned __int8 *)0xA, Context);
  if (!v10)
  {
    __int16 v20 = 1283;
    void v19[2] = (mlir::MLIRContext *)"tensor.dim";
    v19[3] = (mlir::MLIRContext *)10;
          " the dialect. See also https://mlir.llvm.org/getting_started/Faq/#registered-loaded-dependent-whats-up-with-di"
          "alects-management";
    __int16 v18 = 259;
    llvm::operator+((uint64_t *)v19, (uint64_t *)&v17, (uint64_t)v21);
    llvm::report_fatal_error((llvm::Twine *)v21, 1);
  }
  mlir::OperationState::OperationState(v21, a2, v9);
  uint64_t v11 = *a3;
  v19[0] = *a4;
  uint64_t v12 = mlir::OpBuilder::create<mlir::arith::ConstantIndexOp,long long>(a1, v21[0], v19);
  mlir::tensor::DimOp::build(a1, (uint64_t)v21, v11, (uint64_t)v12 - 16);
  uint64_t v13 = mlir::OpBuilder::create((mlir::OpBuilder *)a1, (const mlir::OperationState *)v21);
  if (*(_UNKNOWN **)(*((void *)v13 + 6) + 16) == &mlir::detail::TypeIDResolver<mlir::tensor::DimOp,void>::id) {
    uint64_t v14 = v13;
  }
  else {
    uint64_t v14 = 0;
  }
  mlir::OperationState::~OperationState((mlir::OperationState *)v21);
  return v14;
}

ZinIrHalH13g *mlir::OpBuilder::create<mlir::affine::AffineApplyOp,mlir::AffineExpr,mlir::Value &>(mlir::IndexType **a1, uint64_t a2, mlir::AffineExpr *a3, uint64_t a4)
{
  v19[38] = *MEMORY[0x263EF8340];
  uint64_t v14 = a2;
  uint64_t Context = (uint64_t *)mlir::Attribute::getContext((mlir::Attribute *)&v14);
  uint64_t v9 = mlir::RegisteredOperationName::lookup((int8x16_t *)"affine.apply", (const unsigned __int8 *)0xC, Context);
  if (!v10)
  {
    __int16 v18 = 1283;
    unint64_t v17[2] = (uint64_t)"affine.apply";
    v17[3] = 12;
          " the dialect. See also https://mlir.llvm.org/getting_started/Faq/#registered-loaded-dependent-whats-up-with-di"
          "alects-management";
    __int16 v16 = 259;
    llvm::operator+(v17, (uint64_t *)&v15, (uint64_t)v19);
    llvm::report_fatal_error((llvm::Twine *)v19, 1);
  }
  mlir::OperationState::OperationState(v19, a2, v9);
  mlir::affine::AffineApplyOp::build(a1, (uint64_t)v19, a3, (mlir::AffineExpr *)1, a4, 1);
  uint64_t v11 = mlir::OpBuilder::create((mlir::OpBuilder *)a1, (const mlir::OperationState *)v19);
  if (*(_UNKNOWN **)(*((void *)v11 + 6) + 16) == &mlir::detail::TypeIDResolver<mlir::affine::AffineApplyOp,void>::id) {
    uint64_t v12 = v11;
  }
  else {
    uint64_t v12 = 0;
  }
  mlir::OperationState::~OperationState((mlir::OperationState *)v19);
  return v12;
}

void anonymous namespace'::FoldDimOfCollapseShape::~FoldDimOfCollapseShape(_anonymous_namespace_::FoldDimOfCollapseShape *this)
{
  uint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  int64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }
}

{
  char *v2;
  char *v3;
  uint64_t vars8;

  uint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  int64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t anonymous namespace'::FoldDimOfCollapseShape::matchAndRewrite(uint64_t a1, uint64_t a2, mlir::IndexType **a3)
{
  v44[2] = *MEMORY[0x263EF8340];
  uint64_t v39 = *(void **)(*(void *)(a2 + 72) + 24);
  uint64_t result = mlir::Value::getDefiningOp((mlir::Value *)&v39);
  if (!result) {
    return result;
  }
  uint64_t v6 = *(void **)(*(void *)(result + 48) + 16);
  BOOL v7 = v6 == &mlir::detail::TypeIDResolver<mlir::tensor::CollapseShapeOp,void>::id;
  if (v6 == &mlir::detail::TypeIDResolver<mlir::tensor::CollapseShapeOp,void>::id) {
    uint64_t v8 = result;
  }
  else {
    uint64_t v8 = 0;
  }
  uint64_t v35 = v8;
  if (!v7) {
    return 0;
  }
  unint64_t ConstantIntValue = mlir::getConstantIntValue(*(void *)(*(void *)(a2 + 72) + 56) | 4);
  if (!v10) {
    return 0;
  }
  unint64_t v11 = ConstantIntValue;
  uint64_t v12 = *(_DWORD *)(v35 + 36) ? v35 - 16 : 0;
  unint64_t v34 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v12, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
  if (*(void *)(mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v34) + 8 * v11) != 0x8000000000000000) {
    return 0;
  }
  mlir::memref::CollapseShapeOp::getReassociationIndices((mlir::memref::CollapseShapeOp *)&v35, (uint64_t)&v39);
  uint64_t v13 = (char *)v39;
  uint64_t v14 = (char *)v39 + 32 * v11;
  uint64_t v42 = v44;
  uint64_t v43 = 0x200000000;
  unsigned int v15 = *((_DWORD *)v14 + 2);
  if (&v42 != (void **)v14 && v15 != 0)
  {
    if (v15 < 3)
    {
      __int16 v18 = v44;
      unsigned int v17 = *((_DWORD *)v14 + 2);
    }
    else
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v42, v44, *((unsigned int *)v14 + 2), 8);
      unsigned int v17 = *((_DWORD *)v14 + 2);
      if (!v17)
      {
LABEL_22:
        LODWORD(v43) = v15;
        uint64_t v13 = (char *)v39;
        goto LABEL_23;
      }
      __int16 v18 = v42;
    }
    memcpy(v18, *(const void **)v14, 8 * v17);
    goto LABEL_22;
  }
LABEL_23:
  if (v40)
  {
    uint64_t v19 = 32 * v40;
    do
    {
      __int16 v20 = *(char **)&v13[v19 - 32];
      if (&v13[v19 - 16] != v20) {
        free(v20);
      }
      v19 -= 32;
    }
    while (v19);
    uint64_t v13 = (char *)v39;
  }
  if (v13 != v41) {
    free(v13);
  }
  uint64_t v39 = v41;
  uint64_t v40 = 0x600000000;
  unsigned int v36 = v38;
  uint64_t v37 = 0x600000000;
  unint64_t v33 = 0;
  if (v43)
  {
    uint64_t v21 = 0;
    uint64_t v22 = (mlir::MLIRContext **)v42;
    uint64_t v23 = 8 * v43;
    do
    {
      uint64_t v24 = *(void *)(a2 + 24);
      uint64_t v32 = *(void *)(*(void *)(v35 + 72) + 24);
      uint64_t v26 = mlir::OpBuilder::create<mlir::tensor::DimOp,mlir::detail::TypedValue<mlir::RankedTensorType>,long long &>(a3 + 1, v24, &v32, v22);
      uint64_t v27 = v40;
      if (v40 >= (unint64_t)HIDWORD(v40))
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v39, v41, v40 + 1, 8);
        uint64_t v27 = v40;
      }
      *((void *)v39 + v27) = (char *)v26 - 16;
      LODWORD(v40) = v40 + 1;
      uint64_t AffineSymbolExpr = mlir::Builder::getAffineSymbolExpr(a3 + 1, v21, v25);
      uint64_t v29 = v37;
      if (v37 >= (unint64_t)HIDWORD(v37))
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v36, v38, v37 + 1, 8);
        uint64_t v29 = v37;
      }
      *((void *)v36 + v29) = AffineSymbolExpr;
      LODWORD(v37) = v37 + 1;
      unint64_t v30 = *((void *)v36 + v37 - 1);
      if (v33) {
        unint64_t v30 = mlir::AffineExpr::operator*(&v33, v30);
      }
      unint64_t v33 = v30;
      uint64_t v21 = (mlir *)(v21 + 1);
      ++v22;
      v23 -= 8;
    }
    while (v23);
  }
  unsigned int v31 = mlir::OpBuilder::create<mlir::affine::AffineApplyOp,mlir::AffineExpr &,llvm::SmallVector<mlir::Value,6u> &>(a3 + 1, *(void *)(a2 + 24), (mlir::AffineExpr *)&v33, (uint64_t)&v39);
  (*((void (**)(mlir::IndexType **, uint64_t, ZinIrHalH13g *))*a3 + 4))(a3, a2, v31);
  if (v36 != v38) {
    free(v36);
  }
  if (v39 != v41) {
    free(v39);
  }
  if (v42 != v44) {
    free(v42);
  }
  return 1;
}

ZinIrHalH13g *mlir::OpBuilder::create<mlir::affine::AffineApplyOp,mlir::AffineExpr &,llvm::SmallVector<mlir::Value,6u> &>(mlir::IndexType **a1, uint64_t a2, mlir::AffineExpr *a3, uint64_t a4)
{
  v20[38] = *MEMORY[0x263EF8340];
  uint64_t v14 = a2;
  uint64_t Context = (uint64_t *)mlir::Attribute::getContext((mlir::Attribute *)&v14);
  uint64_t v9 = mlir::RegisteredOperationName::lookup((int8x16_t *)"affine.apply", (const unsigned __int8 *)0xC, Context);
  if (!v10)
  {
    __int16 v18 = 1283;
    unint64_t v17[2] = (uint64_t)"affine.apply";
    v17[3] = 12;
          " the dialect. See also https://mlir.llvm.org/getting_started/Faq/#registered-loaded-dependent-whats-up-with-di"
          "alects-management";
    __int16 v16 = 259;
    llvm::operator+(v17, (uint64_t *)&v15, (uint64_t)v20);
    llvm::report_fatal_error((llvm::Twine *)v20, 1);
  }
  mlir::OperationState::OperationState(v20, a2, v9);
  mlir::ValueRange::ValueRange(v19, *(void *)a4, *(unsigned int *)(a4 + 8));
  mlir::affine::AffineApplyOp::build(a1, (uint64_t)v20, a3, (mlir::AffineExpr *)1, v19[0], v19[1]);
  unint64_t v11 = mlir::OpBuilder::create((mlir::OpBuilder *)a1, (const mlir::OperationState *)v20);
  if (*(_UNKNOWN **)(*((void *)v11 + 6) + 16) == &mlir::detail::TypeIDResolver<mlir::affine::AffineApplyOp,void>::id) {
    uint64_t v12 = v11;
  }
  else {
    uint64_t v12 = 0;
  }
  mlir::OperationState::~OperationState((mlir::OperationState *)v20);
  return v12;
}

void *mlir::ComposeReassociativeReshapeOps<mlir::tensor::CollapseShapeOp>::~ComposeReassociativeReshapeOps(void *a1)
{
  uint64_t v2 = (void *)a1[10];
  if (v2 != a1 + 12) {
    free(v2);
  }
  int64_t v3 = (void *)a1[4];
  if (v3 != a1 + 6) {
    free(v3);
  }
  return a1;
}

void mlir::ComposeReassociativeReshapeOps<mlir::tensor::CollapseShapeOp>::~ComposeReassociativeReshapeOps(void *a1)
{
  uint64_t v2 = (void *)a1[10];
  if (v2 != a1 + 12) {
    free(v2);
  }
  int64_t v3 = (void *)a1[4];
  if (v3 != a1 + 6) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::tensor::CollapseShapeOp>::rewrite(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 48))();
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::tensor::CollapseShapeOp>::match(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 56))();
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::tensor::CollapseShapeOp>::matchAndRewrite(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 64))();
}

uint64_t mlir::ComposeReassociativeReshapeOps<mlir::tensor::CollapseShapeOp>::matchAndRewrite(uint64_t a1, uint64_t a2, uint64_t *a3)
{
  uint64_t v41 = *MEMORY[0x263EF8340];
  uint64_t v30 = a2;
  unint64_t v34 = *(void **)(*(void *)(a2 + 72) + 24);
  uint64_t result = mlir::Value::getDefiningOp((mlir::Value *)&v34);
  if (result)
  {
    uint64_t v6 = result;
    BOOL v7 = *(void **)(*(void *)(result + 48) + 16);
    BOOL v8 = v7 == &mlir::detail::TypeIDResolver<mlir::tensor::CollapseShapeOp,void>::id;
    if (v7 == &mlir::detail::TypeIDResolver<mlir::tensor::CollapseShapeOp,void>::id) {
      uint64_t v9 = result;
    }
    else {
      uint64_t v9 = 0;
    }
    uint64_t v29 = v9;
    if (!v8) {
      return 0;
    }
    uint64_t v10 = *(_DWORD *)(a2 + 36) ? a2 - 16 : 0;
    unint64_t v11 = (void *)(*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v10, 0) + 8) & 0xFFFFFFFFFFFFFFF8);
    uint64_t v12 = v11 ? mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*v11 + 8) : 0;
    v28[0] = (uint64_t)v11;
    v28[1] = v12;
    if ((mlir::hasNonIdentityLayout(*(void *)(*(void *)(*(void *)(v6 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8) & 1) != 0
      || (mlir::hasNonIdentityLayout(*(void *)(*(void *)(*(void *)(a2 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8) & 1) != 0)
    {
      return 0;
    }
    uint64_t v13 = *(_DWORD *)(a2 + 36) ? a2 - 16 : 0;
    uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v13, 0);
    if (mlir::hasNonIdentityLayout(*(void *)(NextResultAtOffset + 8) & 0xFFFFFFFFFFFFFFF8)) {
      return 0;
    }
    mlir::memref::CollapseShapeOp::getReassociationIndices((mlir::memref::CollapseShapeOp *)&v29, (uint64_t)&v34);
    unsigned int v15 = v34;
    unint64_t v16 = v35;
    mlir::memref::CollapseShapeOp::getReassociationIndices((mlir::memref::CollapseShapeOp *)&v30, (uint64_t)&v31);
    mlir::composeReassociationIndices((uint64_t)v15, v16, (uint64_t)v31, v32, (uint64_t)&v37);
    unsigned int v17 = (char *)v31;
    if (v32)
    {
      uint64_t v18 = 32 * v32;
      do
      {
        uint64_t v19 = *(char **)&v17[v18 - 32];
        if (&v17[v18 - 16] != v19) {
          free(v19);
        }
        v18 -= 32;
      }
      while (v18);
      unsigned int v17 = (char *)v31;
    }
    if (v17 != (char *)&v33) {
      free(v17);
    }
    __int16 v20 = (char *)v34;
    if (v35)
    {
      uint64_t v21 = 32 * v35;
      do
      {
        uint64_t v22 = *(char **)&v20[v21 - 32];
        if (&v20[v21 - 16] != v22) {
          free(v22);
        }
        v21 -= 32;
      }
      while (v21);
      __int16 v20 = (char *)v34;
    }
    if (v20 != (char *)&v36) {
      free(v20);
    }
    if (!v40)
    {
      return 0;
    }
    else
    {
      uint64_t v23 = v30;
      unint64_t v34 = *(void **)(*(void *)(v29 + 72) + 24);
      uint64_t v24 = mlir::OpBuilder::create<mlir::tensor::CollapseShapeOp,mlir::ShapedType &,mlir::detail::TypedValue<mlir::RankedTensorType>,llvm::SmallVector<llvm::SmallVector<long long,2u>,1u> &>(a3 + 1, *(void *)(v30 + 24), v28, (uint64_t *)&v34, (uint64_t)&v37);
      (*(void (**)(uint64_t *, uint64_t, ZinIrHalH13g *))(*a3 + 32))(a3, v23, v24);
      if (v40)
      {
        uint64_t v25 = v37;
        if (v38)
        {
          uint64_t v26 = 32 * v38;
          do
          {
            uint64_t v27 = *(char **)&v25[v26 - 32];
            if (&v25[v26 - 16] != v27) {
              free(v27);
            }
            v26 -= 32;
          }
          while (v26);
          uint64_t v25 = v37;
        }
        if (v25 != (char *)&v39) {
          free(v25);
        }
      }
      return 1;
    }
  }
  return result;
}

void *mlir::ComposeCollapseOfExpandOp<mlir::tensor::CollapseShapeOp,mlir::tensor::ExpandShapeOp,mlir::tensor::CastOp>::~ComposeCollapseOfExpandOp(void *a1)
{
  uint64_t v2 = (void *)a1[10];
  if (v2 != a1 + 12) {
    free(v2);
  }
  int64_t v3 = (void *)a1[4];
  if (v3 != a1 + 6) {
    free(v3);
  }
  return a1;
}

void mlir::ComposeCollapseOfExpandOp<mlir::tensor::CollapseShapeOp,mlir::tensor::ExpandShapeOp,mlir::tensor::CastOp>::~ComposeCollapseOfExpandOp(void *a1)
{
  uint64_t v2 = (void *)a1[10];
  if (v2 != a1 + 12) {
    free(v2);
  }
  int64_t v3 = (void *)a1[4];
  if (v3 != a1 + 6) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t mlir::ComposeCollapseOfExpandOp<mlir::tensor::CollapseShapeOp,mlir::tensor::ExpandShapeOp,mlir::tensor::CastOp>::matchAndRewrite(uint64_t a1, uint64_t a2, uint64_t *a3)
{
  uint64_t v4 = a2;
  v54[16] = *MEMORY[0x263EF8340];
  uint64_t v42 = a2;
  __int16 v52 = *(char **)(*(void *)(a2 + 72) + 24);
  uint64_t DefiningOp = mlir::Value::getDefiningOp((mlir::Value *)&v52);
  if (!DefiningOp) {
    return 0;
  }
  uint64_t v6 = *(void **)(*(void *)(DefiningOp + 48) + 16);
  BOOL v7 = v6 == &mlir::detail::TypeIDResolver<mlir::tensor::ExpandShapeOp,void>::id;
  uint64_t v8 = v6 == &mlir::detail::TypeIDResolver<mlir::tensor::ExpandShapeOp,void>::id ? DefiningOp : 0;
  uint64_t v41 = v8;
  if (!v7) {
    return 0;
  }
  uint64_t v9 = (void *)(*(void *)(*(void *)(*(void *)(DefiningOp + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8);
  if (v9)
  {
    uint64_t v10 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*v9 + 8);
    uint64_t v4 = v42;
  }
  else
  {
    uint64_t v10 = 0;
  }
  v40[0] = v9;
  v40[1] = v10;
  uint64_t v11 = *(_DWORD *)(v4 + 36) ? v4 - 16 : 0;
  uint64_t v12 = (void *)(*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v11, 0) + 8) & 0xFFFFFFFFFFFFFFF8);
  uint64_t v13 = v12 ? mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*v12 + 8) : 0;
  v39[0] = (uint64_t)v12;
  v39[1] = v13;
  if ((mlir::hasNonIdentityLayout(*(void *)(*(void *)(*(void *)(v42 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8) & 1) != 0
    || (mlir::hasNonIdentityLayout(*(void *)(*(void *)(*(void *)(v41 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8) & 1) != 0)
  {
    return 0;
  }
  uint64_t v14 = *(_DWORD *)(v41 + 36) ? v41 - 16 : 0;
  uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v14, 0);
  if (mlir::hasNonIdentityLayout(*(void *)(NextResultAtOffset + 8) & 0xFFFFFFFFFFFFFFF8)) {
    return 0;
  }
  mlir::ShapedType::getShape((mlir::ShapedType *)v40);
  uint64_t v17 = v16;
  mlir::ShapedType::getShape((mlir::ShapedType *)v39);
  if (v40[0] == v39[0]) {
    return 0;
  }
  uint64_t v19 = v18;
  __int16 v52 = (char *)v54;
  uint64_t v53 = 0x400000000;
  uint64_t v49 = v51;
  uint64_t v50 = 0x400000000;
  if (v17 <= v18)
  {
    mlir::memref::CollapseShapeOp::getReassociationIndices((mlir::memref::CollapseShapeOp *)&v42, (uint64_t)&v46);
    llvm::SmallVectorImpl<llvm::SmallVector<long long,2u>>::operator=((uint64_t)&v52, (uint64_t)&v46);
    llvm::SmallVector<llvm::SmallVector<long long,2u>,4u>::~SmallVector((char **)&v46);
    mlir::memref::CollapseShapeOp::getReassociationIndices((mlir::memref::CollapseShapeOp *)&v41, (uint64_t)&v46);
  }
  else
  {
    mlir::memref::CollapseShapeOp::getReassociationIndices((mlir::memref::CollapseShapeOp *)&v41, (uint64_t)&v46);
    llvm::SmallVectorImpl<llvm::SmallVector<long long,2u>>::operator=((uint64_t)&v52, (uint64_t)&v46);
    llvm::SmallVector<llvm::SmallVector<long long,2u>,4u>::~SmallVector((char **)&v46);
    mlir::memref::CollapseShapeOp::getReassociationIndices((mlir::memref::CollapseShapeOp *)&v42, (uint64_t)&v46);
  }
  llvm::SmallVectorImpl<llvm::SmallVector<long long,2u>>::operator=((uint64_t)&v49, (uint64_t)&v46);
  llvm::SmallVector<llvm::SmallVector<long long,2u>,4u>::~SmallVector((char **)&v46);
  uint64_t v46 = v48;
  uint64_t v47 = 0x400000000;
  if (v50)
  {
    unint64_t v22 = 0;
    uint64_t v23 = (char *)v49;
    uint64_t v24 = (char *)v49 + 32 * v50;
    while (1)
    {
      unsigned int v25 = 0;
      uint64_t v43 = v45;
      uint64_t v44 = 0x200000000;
      uint64_t v26 = 32 * v22;
      while (1)
      {
        if (v22 >= v53)
        {
LABEL_36:
          llvm::SmallVectorTemplateBase<llvm::SmallVector<long long,2u>,false>::push_back((uint64_t)&v46, (unint64_t)&v43);
          char v28 = 1;
          uint64_t v29 = v43;
          if (v43 == v45) {
            goto LABEL_38;
          }
LABEL_37:
          free(v29);
          goto LABEL_38;
        }
        uint64_t v27 = *(void *)(*(void *)&v52[v26] + 8 * *(unsigned int *)&v52[v26 + 8] - 8);
        if (v27 > *(void *)(*(void *)v23 + 8 * *((unsigned int *)v23 + 2) - 8)) {
          break;
        }
        if (v25 >= HIDWORD(v44))
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v43, v45, v25 + 1, 8);
          unsigned int v25 = v44;
        }
        *((void *)v43 + v25) = v22;
        unsigned int v25 = v44 + 1;
        LODWORD(v44) = v44 + 1;
        v26 += 32;
        ++v22;
        if (v27 == *(void *)(*(void *)v23 + 8 * *((unsigned int *)v23 + 2) - 8)) {
          goto LABEL_36;
        }
      }
      char v28 = 0;
      uint64_t v29 = v43;
      if (v43 != v45) {
        goto LABEL_37;
      }
LABEL_38:
      if ((v28 & 1) == 0) {
        break;
      }
      v23 += 32;
      if (v23 == v24) {
        goto LABEL_43;
      }
    }
    uint64_t v20 = 0;
  }
  else
  {
LABEL_43:
    if (v17 <= v19)
    {
      uint64_t v43 = *(void **)(*(void *)(v41 + 72) + 24);
      if (v17 < v19) {
        mlir::RewriterBase::replaceOpWithNewOp<mlir::tensor::ExpandShapeOp,mlir::ShapedType &,mlir::detail::TypedValue<mlir::RankedTensorType>,llvm::SmallVector<llvm::SmallVector<long long,2u>,1u> &>(a3, v42, v39, (uint64_t *)&v43, (uint64_t)&v46);
      }
      else {
        mlir::RewriterBase::replaceOpWithNewOp<mlir::tensor::CastOp,mlir::ShapedType &,mlir::detail::TypedValue<mlir::RankedTensorType>>((uint64_t)a3, v42, v39, (uint64_t *)&v43);
      }
    }
    else
    {
      uint64_t v43 = *(void **)(*(void *)(v41 + 72) + 24);
      mlir::RewriterBase::replaceOpWithNewOp<mlir::tensor::CollapseShapeOp,mlir::ShapedType &,mlir::detail::TypedValue<mlir::RankedTensorType>,llvm::SmallVector<llvm::SmallVector<long long,2u>,1u> &>(a3, v42, v39, (uint64_t *)&v43, (uint64_t)&v46);
    }
    uint64_t v20 = 1;
  }
  uint64_t v30 = (char *)v46;
  if (v47)
  {
    uint64_t v31 = 32 * v47;
    do
    {
      unsigned int v32 = *(char **)&v30[v31 - 32];
      if (&v30[v31 - 16] != v32) {
        free(v32);
      }
      v31 -= 32;
    }
    while (v31);
    uint64_t v30 = (char *)v46;
  }
  if (v30 != v48) {
    free(v30);
  }
  uint64_t v33 = (char *)v49;
  if (v50)
  {
    uint64_t v34 = 32 * v50;
    do
    {
      unsigned int v35 = *(char **)&v33[v34 - 32];
      if (&v33[v34 - 16] != v35) {
        free(v35);
      }
      v34 -= 32;
    }
    while (v34);
    uint64_t v33 = (char *)v49;
  }
  if (v33 != v51) {
    free(v33);
  }
  uint64_t v36 = v52;
  if (v53)
  {
    uint64_t v37 = 32 * v53;
    do
    {
      unsigned int v38 = *(char **)&v36[v37 - 32];
      if (&v36[v37 - 16] != v38) {
        free(v38);
      }
      v37 -= 32;
    }
    while (v37);
    uint64_t v36 = v52;
  }
  if (v36 != (char *)v54) {
    free(v36);
  }
  return v20;
}

ZinIrHalH13g *mlir::RewriterBase::replaceOpWithNewOp<mlir::tensor::CastOp,mlir::ShapedType &,mlir::detail::TypedValue<mlir::RankedTensorType>>(uint64_t a1, uint64_t a2, uint64_t *a3, uint64_t *a4)
{
  uint64_t v6 = mlir::OpBuilder::create<mlir::tensor::CastOp,mlir::TensorType &,mlir::Value>((mlir::OpBuilder *)(a1 + 8), *(void *)(a2 + 24), a3, a4);
  (*(void (**)(uint64_t, uint64_t, ZinIrHalH13g *))(*(void *)a1 + 32))(a1, a2, v6);
  return v6;
}

void *anonymous namespace'::FoldReshapeWithConstant<mlir::tensor::CollapseShapeOp>::~FoldReshapeWithConstant(void *a1)
{
  uint64_t v2 = (void *)a1[10];
  if (v2 != a1 + 12) {
    free(v2);
  }
  int64_t v3 = (void *)a1[4];
  if (v3 != a1 + 6) {
    free(v3);
  }
  return a1;
}

void anonymous namespace'::FoldReshapeWithConstant<mlir::tensor::CollapseShapeOp>::~FoldReshapeWithConstant(void *a1)
{
  uint64_t v2 = (void *)a1[10];
  if (v2 != a1 + 12) {
    free(v2);
  }
  int64_t v3 = (void *)a1[4];
  if (v3 != a1 + 6) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t anonymous namespace'::FoldReshapeWithConstant<mlir::tensor::CollapseShapeOp>::matchAndRewrite(uint64_t a1, uint64_t a2, uint64_t a3)
{
  v27[1] = *MEMORY[0x263EF8340];
  uint64_t v5 = *(void *)(*(void *)(a2 + 72) + 24);
  unint64_t v24 = 0;
  uint64_t v25 = v5;
  uint64_t DefiningOp = mlir::Value::getDefiningOp((mlir::Value *)&v25);
  if (!DefiningOp) {
    return 0;
  }
  uint64_t v7 = DefiningOp;
  if (!mlir::OperationName::hasTrait<mlir::OpTrait::ConstantLike>((void *)(DefiningOp + 48))) {
    return 0;
  }
  v26[0] = v27;
  v26[1] = (void *)0x100000000;
  mlir::Operation::fold(v7, 0, 0, (uint64_t)v26);
  uint64_t v8 = *(void *)v26[0];
  BOOL v9 = mlir::DenseElementsAttr::classof(*(void *)v26[0] & 0xFFFFFFFFFFFFFFF8);
  unint64_t v10 = 0;
  unint64_t v11 = v8 & 0xFFFFFFFFFFFFFFF8;
  char v12 = (v8 & 0xFFFFFFFFFFFFFFF8) == 0 || !v9;
  if ((v12 & 1) == 0)
  {
    unint64_t v24 = v11;
    unint64_t v10 = v11;
  }
  if (v26[0] != v27) {
    free(v26[0]);
  }
  char v13 = v10 ? v12 : 1;
  if (v13) {
    return 0;
  }
  uint64_t result = mlir::DenseElementsAttr::isSplat((mlir::DenseElementsAttr *)&v24);
  if (result)
  {
    if (*(_DWORD *)(a2 + 36)) {
      uint64_t v15 = a2 - 16;
    }
    else {
      uint64_t v15 = 0;
    }
    uint64_t v16 = (void *)(*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v15, 0) + 8) & 0xFFFFFFFFFFFFFFF8);
    if (v16) {
      uint64_t v17 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*v16 + 8);
    }
    else {
      uint64_t v17 = 0;
    }
    uint64_t RawStringData = mlir::DenseElementsAttr::getRawStringData((mlir::DenseElementsAttr *)&v24);
    v26[0] = (void *)mlir::DenseElementsAttr::getFromRawBuffer(v16, v17, RawStringData, v19, v20, v21, v22);
    uint64_t v23 = mlir::OpBuilder::create<mlir::arith::ConstantOp,mlir::DenseElementsAttr &>((mlir::OpBuilder *)(a3 + 8), *(void *)(a2 + 24), (void **)v26);
    (*(void (**)(uint64_t, uint64_t, ZinIrHalH13g *))(*(void *)a3 + 32))(a3, a2, v23);
    return 1;
  }
  return result;
}

void *anonymous namespace'::FoldReshapeWithSplat<mlir::tensor::CollapseShapeOp>::~FoldReshapeWithSplat(void *a1)
{
  uint64_t v2 = (void *)a1[10];
  if (v2 != a1 + 12) {
    free(v2);
  }
  int64_t v3 = (void *)a1[4];
  if (v3 != a1 + 6) {
    free(v3);
  }
  return a1;
}

void anonymous namespace'::FoldReshapeWithSplat<mlir::tensor::CollapseShapeOp>::~FoldReshapeWithSplat(void *a1)
{
  uint64_t v2 = (void *)a1[10];
  if (v2 != a1 + 12) {
    free(v2);
  }
  int64_t v3 = (void *)a1[4];
  if (v3 != a1 + 6) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t anonymous namespace'::FoldReshapeWithSplat<mlir::tensor::CollapseShapeOp>::matchAndRewrite(uint64_t a1, uint64_t a2, uint64_t a3)
{
  unint64_t v11 = *(void *)(*(void *)(a2 + 72) + 24);
  uint64_t result = mlir::Value::getDefiningOp((mlir::Value *)&v11);
  if (result)
  {
    uint64_t v6 = result;
    if (*(_UNKNOWN **)(*(void *)(result + 48) + 16) == &mlir::detail::TypeIDResolver<mlir::tensor::SplatOp,void>::id)
    {
      if (*(_DWORD *)(a2 + 36)) {
        uint64_t v7 = a2 - 16;
      }
      else {
        uint64_t v7 = 0;
      }
      unint64_t v8 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v7, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
      uint64_t v10 = *(void *)(*(void *)(v6 + 72) + 24);
      unint64_t v11 = v8;
      BOOL v9 = mlir::OpBuilder::create<mlir::tensor::SplatOp,mlir::RankedTensorType,mlir::Value>((mlir::OpBuilder *)(a3 + 8), *(void *)(a2 + 24), (uint64_t *)&v11, &v10);
      (*(void (**)(uint64_t, uint64_t, ZinIrHalH13g *))(*(void *)a3 + 32))(a3, a2, v9);
      return 1;
    }
    else
    {
      return 0;
    }
  }
  return result;
}

void *anonymous namespace'::FoldReshapeWithFromElements<mlir::tensor::CollapseShapeOp>::~FoldReshapeWithFromElements(void *a1)
{
  uint64_t v2 = (void *)a1[10];
  if (v2 != a1 + 12) {
    free(v2);
  }
  int64_t v3 = (void *)a1[4];
  if (v3 != a1 + 6) {
    free(v3);
  }
  return a1;
}

void anonymous namespace'::FoldReshapeWithFromElements<mlir::tensor::CollapseShapeOp>::~FoldReshapeWithFromElements(void *a1)
{
  uint64_t v2 = (void *)a1[10];
  if (v2 != a1 + 12) {
    free(v2);
  }
  int64_t v3 = (void *)a1[4];
  if (v3 != a1 + 6) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t anonymous namespace'::FoldReshapeWithFromElements<mlir::tensor::CollapseShapeOp>::matchAndRewrite(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v18 = *(void **)(*(void *)(a2 + 72) + 24);
  uint64_t result = mlir::Value::getDefiningOp((mlir::Value *)&v18);
  if (result)
  {
    uint64_t v6 = *(void **)(*(void *)(result + 48) + 16);
    if (v6 == &mlir::detail::TypeIDResolver<mlir::tensor::FromElementsOp,void>::id) {
      uint64_t v7 = result;
    }
    else {
      uint64_t v7 = 0;
    }
    if (v6 != &mlir::detail::TypeIDResolver<mlir::tensor::FromElementsOp,void>::id) {
      return 0;
    }
    unint64_t v8 = (void *)(*(void *)(a2 - 8) & 0xFFFFFFFFFFFFFFF8);
    if (v8)
    {
      uint64_t v9 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*v8 + 8);
      uint64_t v18 = v8;
      uint64_t v19 = v9;
      uint64_t result = mlir::CallOpInterface::getArgOperands((mlir::CallOpInterface *)&v18);
      if (!result) {
        return result;
      }
    }
    else
    {
      uint64_t v18 = 0;
      uint64_t v19 = 0;
      uint64_t result = mlir::CallOpInterface::getArgOperands((mlir::CallOpInterface *)&v18);
      if (!result) {
        return result;
      }
    }
    uint64_t Shape = (void *)mlir::ShapedType::getShape((mlir::ShapedType *)&v18);
    if (v11)
    {
      uint64_t v12 = 8 * v11;
      while (*Shape != 0x8000000000000000)
      {
        ++Shape;
        v12 -= 8;
        if (!v12) {
          goto LABEL_16;
        }
      }
      return 0;
    }
    else
    {
LABEL_16:
      unint64_t v17 = *(void *)(a2 - 8) & 0xFFFFFFFFFFFFFFF8;
      if ((*(unsigned char *)(v7 + 46) & 0x80) != 0)
      {
        uint64_t v13 = *(unsigned int *)(v7 + 68);
        uint64_t v14 = *(void *)(v7 + 72);
      }
      else
      {
        uint64_t v14 = 0;
        uint64_t v13 = 0;
      }
      v16[0] = v14;
      v16[1] = v13;
      uint64_t v15 = mlir::OpBuilder::create<mlir::tensor::FromElementsOp,mlir::RankedTensorType,mlir::OperandRange>((mlir::OpBuilder *)(a3 + 8), *(void *)(a2 + 24), (uint64_t *)&v17, (uint64_t)v16);
      (*(void (**)(uint64_t, uint64_t, ZinIrHalH13g *))(*(void *)a3 + 32))(a3, a2, v15);
      return 1;
    }
  }
  return result;
}

void anonymous namespace'::FoldCollapseOfCastOp::~FoldCollapseOfCastOp(_anonymous_namespace_::FoldCollapseOfCastOp *this)
{
  uint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  int64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }
}

{
  char *v2;
  char *v3;
  uint64_t vars8;

  uint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  int64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t anonymous namespace'::FoldCollapseOfCastOp::matchAndRewrite(uint64_t a1, uint64_t a2, uint64_t a3)
{
  v30[16] = *MEMORY[0x263EF8340];
  uint64_t v24 = a2;
  char v28 = *(void **)(*(void *)(a2 + 72) + 24);
  uint64_t DefiningOp = mlir::Value::getDefiningOp((mlir::Value *)&v28);
  if (!DefiningOp) {
    return 0;
  }
  uint64_t v5 = DefiningOp;
  if (*(_UNKNOWN **)(*(void *)(DefiningOp + 48) + 16) != &mlir::detail::TypeIDResolver<mlir::tensor::CastOp,void>::id) {
    return 0;
  }
  uint64_t result = mlir::tensor::preservesStaticInformation(*(void *)(DefiningOp - 8) & 0xFFFFFFFFFFFFFFF8, *(void *)(*(void *)(*(void *)(DefiningOp + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8);
  if (result)
  {
    unint64_t v7 = *(void *)(*(void *)(*(void *)(v5 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8;
    mlir::tensor::CollapseShapeOp::getReassociationExprs((mlir::tensor::CollapseShapeOp *)&v24, &v28);
    mlir::getSymbolLessAffineMaps((uint64_t)v28, v29, (uint64_t)&v25);
    unint64_t v8 = (char *)v28;
    if (v29)
    {
      uint64_t v9 = 32 * v29;
      do
      {
        uint64_t v10 = *(char **)&v8[v9 - 32];
        if (&v8[v9 - 16] != v10) {
          free(v10);
        }
        v9 -= 32;
      }
      while (v9);
      unint64_t v8 = (char *)v28;
    }
    if (v8 != (char *)v30) {
      free(v8);
    }
    uint64_t v11 = (void *)mlir::tensor::CollapseShapeOp::inferCollapsedType(v7, (uint64_t *)v25, v26);
    char v28 = v11;
    if (v25 != &v27) {
      free(v25);
    }
    if (*(_DWORD *)(v24 + 36)) {
      uint64_t v12 = v24 - 16;
    }
    else {
      uint64_t v12 = 0;
    }
    if (v11 == (void *)(*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v12, 0) + 8) & 0xFFFFFFFFFFFFFFF8))
    {
      uint64_t v17 = v24;
      (*(void (**)(uint64_t, uint64_t))(*(void *)a3 + 72))(a3, v24);
      uint64_t v18 = *(uint64_t **)(v24 + 72);
      uint64_t v19 = *(uint64_t **)(*(void *)(v5 + 72) + 24);
      uint64_t v20 = (uint64_t *)v18[1];
      if (v20)
      {
        uint64_t *v20 = *v18;
        if (*v18) {
          *(void *)(*v18 + 8) = v18[1];
        }
      }
      void v18[3] = (uint64_t)v19;
      v18[1] = (uint64_t)v19;
      uint64_t v21 = *v19;
      *uint64_t v18 = *v19;
      if (v21) {
        *(void *)(v21 + 8) = v18;
      }
      *uint64_t v19 = (uint64_t)v18;
      (*(void (**)(uint64_t, uint64_t))(*(void *)a3 + 80))(a3, v17);
    }
    else
    {
      uint64_t v13 = *(void *)(v24 + 24);
      unint64_t v23 = *(void *)(*(void *)(v5 + 72) + 24);
      uint64_t v22 = *(void *)(v24 + 16 * (((unint64_t)*(unsigned int *)(v24 + 44) >> 23) & 1) + 64);
      uint64_t v25 = mlir::OpBuilder::create<mlir::tensor::CollapseShapeOp,mlir::RankedTensorType &,mlir::detail::TypedValue<mlir::TensorType>,mlir::ArrayAttr>((mlir::OpBuilder *)(a3 + 8), v13, (uint64_t *)&v28, (uint64_t *)&v23, &v22);
      uint64_t v14 = v24;
      if (*(_DWORD *)(v24 + 36)) {
        uint64_t v15 = v24 - 16;
      }
      else {
        uint64_t v15 = 0;
      }
      unint64_t v23 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v15, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
      uint64_t v16 = mlir::OpBuilder::create<mlir::tensor::CastOp,mlir::RankedTensorType,mlir::tensor::EmptyOp &>((mlir::OpBuilder *)(a3 + 8), *(void *)(v14 + 24), (uint64_t *)&v23, &v25);
      (*(void (**)(uint64_t, uint64_t, ZinIrHalH13g *))(*(void *)a3 + 32))(a3, v14, v16);
    }
    return 1;
  }
  return result;
}

ZinIrHalH13g *mlir::OpBuilder::create<mlir::tensor::CollapseShapeOp,mlir::RankedTensorType &,mlir::detail::TypedValue<mlir::TensorType>,mlir::ArrayAttr>(mlir::OpBuilder *a1, uint64_t a2, uint64_t *a3, uint64_t *a4, uint64_t *a5)
{
  v28[28] = *MEMORY[0x263EF8340];
  uint64_t v19 = a2;
  uint64_t Context = (uint64_t *)mlir::Attribute::getContext((mlir::Attribute *)&v19);
  uint64_t v11 = mlir::RegisteredOperationName::lookup((int8x16_t *)"tensor.collapse_shape", (const unsigned __int8 *)0x15, Context);
  if (!v12)
  {
    __int16 v23 = 1283;
    void v22[2] = (uint64_t)"tensor.collapse_shape";
    void v22[3] = 21;
          " the dialect. See also https://mlir.llvm.org/getting_started/Faq/#registered-loaded-dependent-whats-up-with-di"
          "alects-management";
    __int16 v21 = 259;
    llvm::operator+(v22, (uint64_t *)&v20, (uint64_t)v24);
    llvm::report_fatal_error((llvm::Twine *)v24, 1);
  }
  mlir::OperationState::OperationState(v24, a2, v11);
  uint64_t v13 = *a3;
  uint64_t v14 = *a5;
  v22[0] = *a4;
  mlir::OperationState::addOperands((uint64_t)v24, (uint64_t)v22, 1);
  *(void *)mlir::OperationState::getOrAddProperties<mlir::tensor::detail::CollapseShapeOpGenericAdaptorBase::Properties>((uint64_t)v24) = v14;
  unsigned int v15 = v26;
  if (v26 >= v27)
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v25, v28, v26 + 1, 8);
    unsigned int v15 = v26;
  }
  *(void *)(v25 + 8 * v15) = v13;
  ++v26;
  uint64_t v16 = mlir::OpBuilder::create(a1, (const mlir::OperationState *)v24);
  if (*(_UNKNOWN **)(*((void *)v16 + 6) + 16) == &mlir::detail::TypeIDResolver<mlir::tensor::CollapseShapeOp,void>::id) {
    uint64_t v17 = v16;
  }
  else {
    uint64_t v17 = 0;
  }
  mlir::OperationState::~OperationState((mlir::OperationState *)v24);
  return v17;
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::tensor::ExtractSliceOp>::rewrite(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 48))();
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::tensor::ExtractSliceOp>::match(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 56))();
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::tensor::ExtractSliceOp>::matchAndRewrite(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 64))();
}

void mlir::RewritePatternSet::addImpl<mlir::OpWithOffsetSizesAndStridesConstantArgumentFolder<mlir::tensor::ExtractSliceOp,SliceReturnTypeCanonicalizer,SliceCanonicalizer>,mlir::MLIRContext *&>()
{
}

void mlir::RewritePattern::create<mlir::OpWithOffsetSizesAndStridesConstantArgumentFolder<mlir::tensor::ExtractSliceOp,SliceReturnTypeCanonicalizer,SliceCanonicalizer>,mlir::MLIRContext *&>()
{
}

void *mlir::OpWithOffsetSizesAndStridesConstantArgumentFolder<mlir::tensor::ExtractSliceOp,SliceReturnTypeCanonicalizer,SliceCanonicalizer>::~OpWithOffsetSizesAndStridesConstantArgumentFolder(void *a1)
{
  uint64_t v2 = (void *)a1[10];
  if (v2 != a1 + 12) {
    free(v2);
  }
  int64_t v3 = (void *)a1[4];
  if (v3 != a1 + 6) {
    free(v3);
  }
  return a1;
}

void mlir::OpWithOffsetSizesAndStridesConstantArgumentFolder<mlir::tensor::ExtractSliceOp,SliceReturnTypeCanonicalizer,SliceCanonicalizer>::~OpWithOffsetSizesAndStridesConstantArgumentFolder(void *a1)
{
  uint64_t v2 = (void *)a1[10];
  if (v2 != a1 + 12) {
    free(v2);
  }
  int64_t v3 = (void *)a1[4];
  if (v3 != a1 + 6) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t mlir::OpWithOffsetSizesAndStridesConstantArgumentFolder<mlir::tensor::ExtractSliceOp,SliceReturnTypeCanonicalizer,SliceCanonicalizer>::matchAndRewrite(uint64_t a1, uint64_t a2, uint64_t a3)
{
  v41[6] = *MEMORY[0x263EF8340];
  uint64_t v29 = a2;
  mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::memref::ReinterpretCastOp>::getMixedOffsets((mlir::memref::ReinterpretCastOp *)&v29, (uint64_t)&__src);
  uint64_t v39 = v41;
  uint64_t v40 = 0x600000000;
  int v4 = v37;
  uint64_t v5 = __src;
  if (v37)
  {
    if (__src == v38)
    {
      unsigned int v6 = v37;
      if (v37 < 7
        || (llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v39, v41, v37, 8),
            unsigned int v6 = v37,
            uint64_t v5 = __src,
            v37))
      {
        memcpy(v39, v5, 8 * v6);
        uint64_t v5 = __src;
      }
      LODWORD(v40) = v4;
    }
    else
    {
      uint64_t v39 = __src;
      uint64_t v40 = v37;
      uint64_t __src = v38;
      HIDWORD(v37) = 0;
      uint64_t v5 = v38;
    }
    LODWORD(v37) = 0;
  }
  if (v5 != v38) {
    free(v5);
  }
  mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::memref::ReinterpretCastOp>::getMixedSizes((mlir::memref::ReinterpretCastOp *)&v29, (uint64_t)&__dst);
  uint64_t __src = v38;
  uint64_t v37 = 0x600000000;
  int v7 = v34;
  unint64_t v8 = __dst;
  if (v34)
  {
    if (__dst == v35)
    {
      unsigned int v9 = v34;
      if (v34 < 7
        || (llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&__src, v38, v34, 8),
            unsigned int v9 = v34,
            unint64_t v8 = __dst,
            v34))
      {
        memcpy(__src, v8, 8 * v9);
        unint64_t v8 = __dst;
      }
      LODWORD(v37) = v7;
    }
    else
    {
      uint64_t __src = __dst;
      uint64_t v37 = v34;
      __dst = v35;
      HIDWORD(v34) = 0;
      unint64_t v8 = v35;
    }
    LODWORD(v34) = 0;
  }
  if (v8 != v35) {
    free(v8);
  }
  mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::memref::ReinterpretCastOp>::getMixedStrides((mlir::memref::ReinterpretCastOp *)&v29, (uint64_t)&v30);
  __dst = v35;
  uint64_t v34 = 0x600000000;
  int v10 = v31;
  uint64_t v11 = v30;
  if (v31)
  {
    if (v30 == v32)
    {
      unsigned int v12 = v31;
      if (v31 < 7
        || (llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&__dst, v35, v31, 8),
            unsigned int v12 = v31,
            uint64_t v11 = v30,
            v31))
      {
        memcpy(__dst, v11, 8 * v12);
        uint64_t v11 = v30;
      }
      LODWORD(v34) = v10;
    }
    else
    {
      __dst = v30;
      uint64_t v34 = v31;
      uint64_t v30 = v32;
      HIDWORD(v31) = 0;
      uint64_t v11 = v32;
    }
    LODWORD(v31) = 0;
  }
  if (v11 != v32) {
    free(v11);
  }
  if (mlir::foldDynamicIndexList((uint64_t)&v39, 1)
    || mlir::foldDynamicIndexList((uint64_t)&__src, 1)
    || mlir::foldDynamicIndexList((uint64_t)&__dst, 0))
  {
    uint64_t v13 = a3;
    uint64_t v14 = v29;
    unsigned int v15 = v39;
    uint64_t v16 = v40;
    uint64_t v17 = (uint64_t *)__src;
    uint64_t v18 = v37;
    uint64_t v19 = (uint64_t *)__dst;
    uint64_t v20 = v34;
    if (*(_DWORD *)(v29 + 36)) {
      uint64_t v21 = v29 - 16;
    }
    else {
      uint64_t v21 = 0;
    }
    uint64_t v30 = (void *)(*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v21, 0) + 8) & 0xFFFFFFFFFFFFFFF8);
    mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v30);
    uint64_t v30 = (void *)mlir::tensor::ExtractSliceOp::inferCanonicalRankReducedResultType(v22, (void *)(*(void *)(*(void *)(*(void *)(v14 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8), v15, v16, v17, v18, v19, v20);
    if (v30)
    {
      uint64_t v23 = *(void *)(v29 + 24);
      uint64_t v28 = *(void *)(*(void *)(v29 + 72) + 24);
      uint64_t v24 = mlir::OpBuilder::create<mlir::tensor::ExtractSliceOp,mlir::RankedTensorType &,mlir::detail::TypedValue<mlir::RankedTensorType>,llvm::SmallVector<mlir::OpFoldResult,4u>,llvm::SmallVector<mlir::OpFoldResult,4u>&,llvm::SmallVector<mlir::OpFoldResult,4u>>((mlir::MLIRContext **)(v13 + 8), v23, (uint64_t *)&v30, &v28, (uint64_t)&v39, (uint64_t)&__src, (uint64_t)&__dst);
      SliceCanonicalizer::operator()((uint64_t)&v28, v13, v29, (uint64_t)v24);
      uint64_t v25 = 1;
    }
    else
    {
      uint64_t v25 = 0;
    }
    unsigned int v26 = __dst;
    if (__dst != v35) {
      goto LABEL_41;
    }
  }
  else
  {
    uint64_t v25 = 0;
    unsigned int v26 = __dst;
    if (__dst != v35) {
LABEL_41:
    }
      free(v26);
  }
  if (__src != v38) {
    free(__src);
  }
  if (v39 != v41) {
    free(v39);
  }
  return v25;
}

uint64_t SliceCanonicalizer::operator()(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  if (*(_DWORD *)(a4 + 36)) {
    uint64_t v6 = a4 - 16;
  }
  else {
    uint64_t v6 = 0;
  }
  uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v6, 0);
  if (*(_DWORD *)(a3 + 36)) {
    uint64_t v8 = a3 - 16;
  }
  else {
    uint64_t v8 = 0;
  }
  unint64_t v7 = *(void *)(NextResultAtOffset + 8) & 0xFFFFFFFFFFFFFFF8;
  if (v7 != (*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v8, 0) + 8) & 0xFFFFFFFFFFFFFFF8))
  {
    uint64_t v9 = *(void *)(a3 + 24);
    if (*(_DWORD *)(a3 + 36)) {
      uint64_t v10 = a3 - 16;
    }
    else {
      uint64_t v10 = 0;
    }
    unint64_t v12 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v10, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
    uint64_t NextResultAtOffset = (uint64_t)mlir::OpBuilder::create<mlir::tensor::CastOp,mlir::TensorType &,mlir::Value>((mlir::OpBuilder *)(a2 + 8), v9, (uint64_t *)&v12, &NextResultAtOffset)- 16;
  }
  return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t *, uint64_t))(*(void *)a2 + 24))(a2, a3, &NextResultAtOffset, 1);
}

void anonymous namespace'::ExtractSliceOpCastFolder::~ExtractSliceOpCastFolder(_anonymous_namespace_::ExtractSliceOpCastFolder *this)
{
  uint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  int64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }
}

{
  char *v2;
  char *v3;
  uint64_t vars8;

  uint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  int64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t anonymous namespace'::ExtractSliceOpCastFolder::matchAndRewrite(uint64_t DefiningOp, uint64_t a2, mlir::MLIRContext **a3)
{
  if ((*(unsigned char *)(a2 + 46) & 0x80) != 0)
  {
    uint64_t v5 = *(unsigned int *)(a2 + 68);
    if (v5)
    {
      uint64_t v6 = (unint64_t *)(*(void *)(a2 + 72) + 24);
      do
      {
        unint64_t v7 = *v6;
        ZinIrHalH13g::~ZinIrHalH13g((ZinIrHalH13g *)DefiningOp);
        unint64_t v42 = v7;
        uint64_t DefiningOp = mlir::Value::getDefiningOp((mlir::Value *)&v42);
        if (DefiningOp)
        {
          uint64_t DefiningOp = mlir::arith::ConstantIndexOp::classof(DefiningOp, v8);
          if (DefiningOp) {
            return 0;
          }
        }
        v6 += 4;
      }
      while (--v5);
    }
  }
  unint64_t v42 = *(void *)(*(void *)(a2 + 72) + 24);
  uint64_t v9 = mlir::Value::getDefiningOp((mlir::Value *)&v42);
  if (!v9) {
    return 0;
  }
  uint64_t v10 = v9;
  if (*(_UNKNOWN **)(*(void *)(v9 + 48) + 16) != &mlir::detail::TypeIDResolver<mlir::tensor::CastOp,void>::id
    || !mlir::tensor::preservesStaticInformation(*(void *)(v9 - 8) & 0xFFFFFFFFFFFFFFF8, *(void *)(*(void *)(*(void *)(v9 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8))
  {
    return 0;
  }
  uint64_t v11 = *(void *)(a2 + 24);
  if (*(_DWORD *)(a2 + 36)) {
    uint64_t v12 = a2 - 16;
  }
  else {
    uint64_t v12 = 0;
  }
  unint64_t v13 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v12, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
  uint64_t v44 = *(void *)(*(void *)(v10 + 72) + 24);
  unint64_t v45 = v13;
  unint64_t v14 = *(unsigned int *)(a2 + 44);
  uint64_t v15 = a2 + 64;
  uint64_t v16 = (uint64_t *)(a2 + 64 + 16 * ((v14 >> 23) & 1));
  if (HIBYTE(*(_DWORD *)(a2 + 44))) {
    uint64_t v17 = (unsigned int *)(a2 + 64 + 16 * ((v14 >> 23) & 1));
  }
  else {
    uint64_t v17 = 0;
  }
  uint64_t v18 = v17[6];
  unsigned int v19 = v17[7];
  if ((v14 & 0x800000) != 0)
  {
    uint64_t v20 = v19 + v18;
    unint64_t v42 = *(void *)(a2 + 72) + 32 * v18;
    uint64_t v43 = v20 - v18;
    uint64_t v21 = v17[8] + v20;
    uint64_t v40 = *(void *)(a2 + 72) + 32 * v20;
    uint64_t v41 = v21 - v20;
    uint64_t v22 = *(void *)(a2 + 72);
  }
  else
  {
    uint64_t v22 = 0;
    uint64_t v35 = v19 + v18;
    unint64_t v42 = 32 * v18;
    uint64_t v43 = v35 - v18;
    uint64_t v21 = v17[8] + v35;
    uint64_t v40 = 32 * v35;
    uint64_t v41 = v21 - v35;
  }
  uint64_t v23 = v17[9] + v21 - v21;
  v39[0] = v22 + 32 * v21;
  v39[1] = v23;
  v38[0] = *v16;
  v38[0] = mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)v38);
  v38[1] = v24;
  if (HIBYTE(*(_DWORD *)(a2 + 44))) {
    uint64_t v25 = v15 + 16 * (((unint64_t)*(unsigned int *)(a2 + 44) >> 23) & 1);
  }
  else {
    uint64_t v25 = 0;
  }
  v37[0] = *(void *)(v25 + 8);
  v37[0] = mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)v37);
  v37[1] = v26;
  if (HIBYTE(*(_DWORD *)(a2 + 44))) {
    uint64_t v27 = v15 + 16 * (((unint64_t)*(unsigned int *)(a2 + 44) >> 23) & 1);
  }
  else {
    uint64_t v27 = 0;
  }
  v36[0] = *(void *)(v27 + 16);
  v36[0] = mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)v36);
  v36[1] = v28;
  uint64_t v29 = mlir::OpBuilder::create<mlir::tensor::ExtractSliceOp,mlir::RankedTensorType,mlir::detail::TypedValue<mlir::TensorType>,mlir::OperandRange,mlir::OperandRange,mlir::OperandRange,llvm::ArrayRef<long long>,llvm::ArrayRef<long long>,llvm::ArrayRef<long long>>(a3 + 1, v11, (uint64_t *)&v45, &v44, (uint64_t)&v42, (uint64_t)&v40, (uint64_t)v39, v38, v37, v36);
  uint64_t v46 = (uint64_t)v29 - 16;
  unint64_t v30 = *((void *)v29 - 1) & 0xFFFFFFFFFFFFFFF8;
  if (*(_DWORD *)(a2 + 36)) {
    uint64_t v31 = a2 - 16;
  }
  else {
    uint64_t v31 = 0;
  }
  if (v30 != (*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v31, 0) + 8) & 0xFFFFFFFFFFFFFFF8))
  {
    if (*(_DWORD *)(a2 + 36)) {
      uint64_t v32 = a2 - 16;
    }
    else {
      uint64_t v32 = 0;
    }
    unint64_t v42 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v32, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
    uint64_t v46 = (uint64_t)mlir::OpBuilder::create<mlir::tensor::CastOp,mlir::TensorType &,mlir::Value>((mlir::OpBuilder *)(a3 + 1), v11, (uint64_t *)&v42, &v46)- 16;
  }
  uint64_t v33 = 1;
  (*((void (**)(mlir::MLIRContext **, uint64_t, uint64_t *, uint64_t))*a3 + 3))(a3, a2, &v46, 1);
  return v33;
}

ZinIrHalH13g *mlir::OpBuilder::create<mlir::tensor::ExtractSliceOp,mlir::RankedTensorType,mlir::detail::TypedValue<mlir::TensorType>,mlir::OperandRange,mlir::OperandRange,mlir::OperandRange,llvm::ArrayRef<long long>,llvm::ArrayRef<long long>,llvm::ArrayRef<long long>>(mlir::MLIRContext **a1, uint64_t a2, uint64_t *a3, uint64_t *a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t *a8, uint64_t *a9, uint64_t *a10)
{
  v34[38] = *MEMORY[0x263EF8340];
  uint64_t v26 = a2;
  uint64_t Context = (uint64_t *)mlir::Attribute::getContext((mlir::Attribute *)&v26);
  uint64_t v19 = mlir::RegisteredOperationName::lookup((int8x16_t *)"tensor.extract_slice", (const unsigned __int8 *)0x14, Context);
  if (!v20)
  {
    __int16 v30 = 1283;
    uint64_t v29[2] = (uint64_t)"tensor.extract_slice";
    v29[3] = 20;
          " the dialect. See also https://mlir.llvm.org/getting_started/Faq/#registered-loaded-dependent-whats-up-with-di"
          "alects-management";
    __int16 v28 = 259;
    llvm::operator+(v29, (uint64_t *)&v27, (uint64_t)v34);
    llvm::report_fatal_error((llvm::Twine *)v34, 1);
  }
  mlir::OperationState::OperationState(v34, a2, v19);
  uint64_t v21 = *a3;
  uint64_t v22 = *a4;
  mlir::ValueRange::ValueRange(v33, *(void *)a5, *(void *)(a5 + 8));
  mlir::ValueRange::ValueRange(v32, *(void *)a6, *(void *)(a6 + 8));
  mlir::ValueRange::ValueRange(v31, *(void *)a7, *(void *)(a7 + 8));
  mlir::tensor::ExtractSliceOp::build(a1, (uint64_t)v34, v21, v22, v33[0], v33[1], v32[0], v32[1], v31[0], v31[1], *a8, a8[1], *a9, a9[1], *a10, a10[1]);
  uint64_t v23 = mlir::OpBuilder::create((mlir::OpBuilder *)a1, (const mlir::OperationState *)v34);
  if (*(_UNKNOWN **)(*((void *)v23 + 6) + 16) == &mlir::detail::TypeIDResolver<mlir::tensor::ExtractSliceOp,void>::id) {
    uint64_t v24 = v23;
  }
  else {
    uint64_t v24 = 0;
  }
  mlir::OperationState::~OperationState((mlir::OperationState *)v34);
  return v24;
}

void *anonymous namespace'::InsertSliceOpConstantArgumentFolder<mlir::tensor::InsertSliceOp>::~InsertSliceOpConstantArgumentFolder(void *a1)
{
  uint64_t v2 = (void *)a1[10];
  if (v2 != a1 + 12) {
    free(v2);
  }
  int64_t v3 = (void *)a1[4];
  if (v3 != a1 + 6) {
    free(v3);
  }
  return a1;
}

void anonymous namespace'::InsertSliceOpConstantArgumentFolder<mlir::tensor::InsertSliceOp>::~InsertSliceOpConstantArgumentFolder(void *a1)
{
  uint64_t v2 = (void *)a1[10];
  if (v2 != a1 + 12) {
    free(v2);
  }
  int64_t v3 = (void *)a1[4];
  if (v3 != a1 + 6) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::tensor::InsertSliceOp>::rewrite(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 48))();
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::tensor::InsertSliceOp>::match(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 56))();
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::tensor::InsertSliceOp>::matchAndRewrite(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 64))();
}

uint64_t anonymous namespace'::InsertSliceOpConstantArgumentFolder<mlir::tensor::InsertSliceOp>::matchAndRewrite(uint64_t a1, uint64_t a2, uint64_t a3)
{
  v39[6] = *MEMORY[0x263EF8340];
  uint64_t v27 = a2;
  mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::tensor::InsertSliceOp>::getMixedOffsets((mlir::memref::ReinterpretCastOp *)&v27, (uint64_t)&__src);
  uint64_t v37 = v39;
  uint64_t v38 = 0x600000000;
  int v4 = v35;
  uint64_t v5 = __src;
  if (v35)
  {
    if (__src == v36)
    {
      unsigned int v6 = v35;
      if (v35 < 7
        || (llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v37, v39, v35, 8),
            unsigned int v6 = v35,
            uint64_t v5 = __src,
            v35))
      {
        memcpy(v37, v5, 8 * v6);
        uint64_t v5 = __src;
      }
      LODWORD(v38) = v4;
    }
    else
    {
      uint64_t v37 = __src;
      uint64_t v38 = v35;
      uint64_t __src = v36;
      HIDWORD(v35) = 0;
      uint64_t v5 = v36;
    }
    LODWORD(v35) = 0;
  }
  if (v5 != v36) {
    free(v5);
  }
  mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::tensor::InsertSliceOp>::getMixedSizes((mlir::memref::ReinterpretCastOp *)&v27, (uint64_t)&__dst);
  uint64_t __src = v36;
  uint64_t v35 = 0x600000000;
  int v7 = v32;
  uint64_t v8 = __dst;
  if (v32)
  {
    if (__dst == v33)
    {
      unsigned int v9 = v32;
      if (v32 < 7
        || (llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&__src, v36, v32, 8),
            unsigned int v9 = v32,
            uint64_t v8 = __dst,
            v32))
      {
        memcpy(__src, v8, 8 * v9);
        uint64_t v8 = __dst;
      }
      LODWORD(v35) = v7;
    }
    else
    {
      uint64_t __src = __dst;
      uint64_t v35 = v32;
      __dst = v33;
      HIDWORD(v32) = 0;
      uint64_t v8 = v33;
    }
    LODWORD(v32) = 0;
  }
  if (v8 != v33) {
    free(v8);
  }
  mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::tensor::InsertSliceOp>::getMixedStrides((mlir::memref::ReinterpretCastOp *)&v27, (uint64_t)&v28);
  __dst = v33;
  uint64_t v32 = 0x600000000;
  int v10 = v29;
  uint64_t v11 = v28;
  if (v29)
  {
    if (v28 == v30)
    {
      unsigned int v12 = v29;
      if (v29 < 7
        || (llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&__dst, v33, v29, 8),
            unsigned int v12 = v29,
            uint64_t v11 = v28,
            v29))
      {
        memcpy(__dst, v11, 8 * v12);
        uint64_t v11 = v28;
      }
      LODWORD(v32) = v10;
    }
    else
    {
      __dst = v28;
      uint64_t v32 = v29;
      __int16 v28 = v30;
      HIDWORD(v29) = 0;
      uint64_t v11 = v30;
    }
    LODWORD(v29) = 0;
  }
  if (v11 != v30) {
    free(v11);
  }
  if (mlir::foldDynamicIndexList((uint64_t)&v37, 1)
    || mlir::foldDynamicIndexList((uint64_t)&__src, 1)
    || mlir::foldDynamicIndexList((uint64_t)&__dst, 0))
  {
    unint64_t v26 = *(void *)(*(void *)(*(void *)(v27 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8;
    mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v26);
    int v14 = v13;
    if (*(_DWORD *)(v27 + 36)) {
      uint64_t v15 = v27 - 16;
    }
    else {
      uint64_t v15 = 0;
    }
    uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v15, 0);
    __int16 v28 = (void *)mlir::tensor::ExtractSliceOp::inferCanonicalRankReducedResultType(v14, (void *)(*(void *)(NextResultAtOffset + 8) & 0xFFFFFFFFFFFFFFF8), v37, v38, (uint64_t *)__src, v35, (uint64_t *)__dst, v32);
    unint64_t v26 = *(void *)(*(void *)(v27 + 72) + 24);
    if (v28 != (void *)(*(void *)(v26 + 8) & 0xFFFFFFFFFFFFFFF8))
    {
      uint64_t v17 = (_OWORD *)(a3 + 24);
      long long v24 = *(_OWORD *)(a3 + 24);
      unint64_t v26 = (unint64_t)mlir::OpBuilder::create<mlir::tensor::CastOp,mlir::TensorType &,mlir::Value>((mlir::OpBuilder *)(a3 + 8), *(void *)(v27 + 24), (uint64_t *)&v28, (uint64_t *)&v26)- 16;
      if ((void)v24)
      {
        *uint64_t v17 = v24;
      }
      else
      {
        *(void *)uint64_t v17 = 0;
        *(void *)(a3 + 32) = 0;
      }
    }
    uint64_t v18 = v27;
    if (*(unsigned char *)(v27 + 47)) {
      uint64_t v19 = v27 + 80;
    }
    else {
      uint64_t v19 = 0;
    }
    uint64_t v25 = *(void *)(*(void *)(v27 + 72) + 32 * *(unsigned int *)(v19 + 24) + 24);
    char v20 = mlir::OpBuilder::create<mlir::tensor::InsertSliceOp,mlir::Value &,mlir::detail::TypedValue<mlir::RankedTensorType>,llvm::SmallVector<mlir::OpFoldResult,6u> &,llvm::SmallVector<mlir::OpFoldResult,6u> &,llvm::SmallVector<mlir::OpFoldResult,6u> &>((mlir::MLIRContext **)(a3 + 8), *(void *)(v27 + 24), (uint64_t *)&v26, &v25, (uint64_t)&v37, (uint64_t)&__src, (uint64_t)&__dst);
    (*(void (**)(uint64_t, uint64_t, ZinIrHalH13g *))(*(void *)a3 + 32))(a3, v18, v20);
    uint64_t v21 = 1;
    uint64_t v22 = __dst;
    if (__dst != v33) {
      goto LABEL_45;
    }
  }
  else
  {
    uint64_t v21 = 0;
    uint64_t v22 = __dst;
    if (__dst != v33) {
LABEL_45:
    }
      free(v22);
  }
  if (__src != v36) {
    free(__src);
  }
  if (v37 != v39) {
    free(v37);
  }
  return v21;
}

ZinIrHalH13g *mlir::OpBuilder::create<mlir::tensor::InsertSliceOp,mlir::Value &,mlir::detail::TypedValue<mlir::RankedTensorType>,llvm::SmallVector<mlir::OpFoldResult,6u> &,llvm::SmallVector<mlir::OpFoldResult,6u> &,llvm::SmallVector<mlir::OpFoldResult,6u> &>(mlir::MLIRContext **a1, uint64_t a2, uint64_t *a3, uint64_t *a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  v25[38] = *MEMORY[0x263EF8340];
  uint64_t v20 = a2;
  uint64_t Context = (uint64_t *)mlir::Attribute::getContext((mlir::Attribute *)&v20);
  uint64_t v15 = mlir::RegisteredOperationName::lookup((int8x16_t *)"tensor.insert_slice", (const unsigned __int8 *)0x13, Context);
  if (!v16)
  {
    __int16 v24 = 1283;
    uint64_t v23[2] = (uint64_t)"tensor.insert_slice";
    v23[3] = 19;
          " the dialect. See also https://mlir.llvm.org/getting_started/Faq/#registered-loaded-dependent-whats-up-with-di"
          "alects-management";
    __int16 v22 = 259;
    llvm::operator+(v23, (uint64_t *)&v21, (uint64_t)v25);
    llvm::report_fatal_error((llvm::Twine *)v25, 1);
  }
  mlir::OperationState::OperationState(v25, a2, v15);
  mlir::tensor::InsertSliceOp::build(a1, (uint64_t)v25, *a3, *a4, *(uint64_t **)a5, *(unsigned int *)(a5 + 8), *(uint64_t **)a6, *(unsigned int *)(a6 + 8), *(uint64_t **)a7, *(unsigned int *)(a7 + 8), 0, 0);
  uint64_t v17 = mlir::OpBuilder::create((mlir::OpBuilder *)a1, (const mlir::OperationState *)v25);
  if (*(_UNKNOWN **)(*((void *)v17 + 6) + 16) == &mlir::detail::TypeIDResolver<mlir::tensor::InsertSliceOp,void>::id) {
    uint64_t v18 = v17;
  }
  else {
    uint64_t v18 = 0;
  }
  mlir::OperationState::~OperationState((mlir::OperationState *)v25);
  return v18;
}

void *anonymous namespace'::InsertSliceOpCastFolder<mlir::tensor::InsertSliceOp>::~InsertSliceOpCastFolder(void *a1)
{
  uint64_t v2 = (void *)a1[10];
  if (v2 != a1 + 12) {
    free(v2);
  }
  int64_t v3 = (void *)a1[4];
  if (v3 != a1 + 6) {
    free(v3);
  }
  return a1;
}

void anonymous namespace'::InsertSliceOpCastFolder<mlir::tensor::InsertSliceOp>::~InsertSliceOpCastFolder(void *a1)
{
  uint64_t v2 = (void *)a1[10];
  if (v2 != a1 + 12) {
    free(v2);
  }
  int64_t v3 = (void *)a1[4];
  if (v3 != a1 + 6) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t anonymous namespace'::InsertSliceOpCastFolder<mlir::tensor::InsertSliceOp>::matchAndRewrite(uint64_t DefiningOp, uint64_t a2, mlir::MLIRContext **a3)
{
  v52[4] = *MEMORY[0x263EF8340];
  uint64_t v45 = a2;
  if ((*(unsigned char *)(a2 + 46) & 0x80) != 0)
  {
    uint64_t v5 = *(unsigned int *)(a2 + 68);
    if (v5)
    {
      unsigned int v6 = (void **)(*(void *)(a2 + 72) + 24);
      do
      {
        int v7 = *v6;
        ZinIrHalH13g::~ZinIrHalH13g((ZinIrHalH13g *)DefiningOp);
        v51[0] = v7;
        uint64_t DefiningOp = mlir::Value::getDefiningOp((mlir::Value *)v51);
        if (DefiningOp)
        {
          uint64_t DefiningOp = mlir::arith::ConstantIndexOp::classof(DefiningOp, v8);
          if (DefiningOp) {
            return 0;
          }
        }
        v6 += 4;
      }
      while (--v5);
    }
  }
  v51[0] = *(void **)(*(void *)(a2 + 72) + 24);
  uint64_t v9 = mlir::Value::getDefiningOp((mlir::Value *)v51);
  if (v9
    && (uint64_t v10 = v9,
        *(_UNKNOWN **)(*(void *)(v9 + 48) + 16) == &mlir::detail::TypeIDResolver<mlir::tensor::CastOp,void>::id)
    && mlir::tensor::preservesStaticInformation(*(void *)(v9 - 8) & 0xFFFFFFFFFFFFFFF8, *(void *)(*(void *)(*(void *)(v9 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8))
  {
    int v11 = 0;
    unint64_t v12 = *(void *)(*(void *)(v10 + 72) + 24) & 0xFFFFFFFFFFFFFF00;
    uint64_t v13 = *(void *)(*(void *)(v10 + 72) + 24);
  }
  else
  {
    uint64_t v13 = 0;
    unint64_t v12 = 0;
    int v11 = 1;
  }
  uint64_t v14 = v12 | v13;
  if (*(unsigned char *)(a2 + 47)) {
    uint64_t v15 = a2 + 80;
  }
  else {
    uint64_t v15 = 0;
  }
  v51[0] = *(void **)(*(void *)(a2 + 72) + 32 * *(unsigned int *)(v15 + 24) + 24);
  uint64_t v16 = mlir::Value::getDefiningOp((mlir::Value *)v51);
  if (v16
    && (uint64_t v17 = v16,
        *(_UNKNOWN **)(*(void *)(v16 + 48) + 16) == &mlir::detail::TypeIDResolver<mlir::tensor::CastOp,void>::id)
    && (mlir::tensor::preservesStaticInformation(*(void *)(v16 - 8) & 0xFFFFFFFFFFFFFFF8, *(void *)(*(void *)(*(void *)(v16 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8) & 1) != 0)
  {
    uint64_t v18 = *(void *)(*(void *)(v17 + 72) + 24);
    if (v11) {
      uint64_t v14 = *(void *)(*(void *)(a2 + 72) + 24);
    }
    uint64_t v44 = v14;
  }
  else
  {
    if (v11) {
      return 0;
    }
    uint64_t v44 = v14;
    if (*(unsigned char *)(a2 + 47)) {
      uint64_t v20 = a2 + 80;
    }
    else {
      uint64_t v20 = 0;
    }
    uint64_t v18 = *(void *)(*(void *)(a2 + 72) + 32 * *(unsigned int *)(v20 + 24) + 24);
  }
  uint64_t result = 0;
  uint64_t v43 = v18;
  if (*(_UNKNOWN **)(*(void *)(*(void *)(v14 + 8) & 0xFFFFFFFFFFFFFFF8) + 136) == &mlir::detail::TypeIDResolver<mlir::RankedTensorType,void>::id) {
    uint64_t v21 = (void *)(*(void *)(v14 + 8) & 0xFFFFFFFFFFFFFFF8);
  }
  else {
    uint64_t v21 = 0;
  }
  unint64_t v22 = *(void *)(v18 + 8) & 0xFFFFFFFFFFFFFFF8;
  if (*(_UNKNOWN **)(*(void *)v22 + 136) == &mlir::detail::TypeIDResolver<mlir::RankedTensorType,void>::id) {
    uint64_t v23 = (void *)v22;
  }
  else {
    uint64_t v23 = 0;
  }
  if (v21 && v23)
  {
    uint64_t v24 = a2 + 64;
    v51[0] = *(void **)(a2 + 64 + 16 * (((unint64_t)*(unsigned int *)(a2 + 44) >> 23) & 1));
    mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)v51);
    if (HIBYTE(*(_DWORD *)(a2 + 44))) {
      uint64_t v25 = v24 + 16 * (((unint64_t)*(unsigned int *)(a2 + 44) >> 23) & 1);
    }
    else {
      uint64_t v25 = 0;
    }
    v51[0] = *(void **)(v25 + 8);
    uint64_t v26 = mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)v51);
    uint64_t v28 = v27;
    if (HIBYTE(*(_DWORD *)(a2 + 44))) {
      uint64_t v29 = v24 + 16 * (((unint64_t)*(unsigned int *)(a2 + 44) >> 23) & 1);
    }
    else {
      uint64_t v29 = 0;
    }
    v51[0] = *(void **)(v29 + 16);
    mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)v51);
    v51[0] = v23;
    uint64_t RHS = mlir::AffineBinaryOpExpr::getRHS((mlir::AffineBinaryOpExpr *)v51);
    uint64_t v31 = (void *)mlir::RankedTensorType::get(v26, v28, RHS, 0);
    uint64_t v32 = v31;
    if (v31) {
      uint64_t v33 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*v31 + 8);
    }
    else {
      uint64_t v33 = 0;
    }
    mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*v21 + 8);
    if (mlir::isRankReducedType(v32, v33, v21))
    {
      return 0;
    }
    else
    {
      uint64_t v34 = *(void *)(a2 + 24);
      mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::tensor::InsertSliceOp>::getMixedOffsets((mlir::memref::ReinterpretCastOp *)&v45, (uint64_t)v51);
      mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::tensor::InsertSliceOp>::getMixedSizes((mlir::memref::ReinterpretCastOp *)&v45, (uint64_t)v49);
      mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::tensor::InsertSliceOp>::getMixedStrides((mlir::memref::ReinterpretCastOp *)&v45, (uint64_t)v47);
      uint64_t v35 = mlir::OpBuilder::create<mlir::tensor::InsertSliceOp,mlir::Value &,mlir::detail::TypedValue<mlir::RankedTensorType>,llvm::SmallVector<mlir::OpFoldResult,6u> &,llvm::SmallVector<mlir::OpFoldResult,6u> &,llvm::SmallVector<mlir::OpFoldResult,6u> &>(a3 + 1, v34, &v44, &v43, (uint64_t)v51, (uint64_t)v49, (uint64_t)v47);
      if (v47[0] != &v48) {
        free(v47[0]);
      }
      if (v49[0] != &v50) {
        free(v49[0]);
      }
      if (v51[0] != v52) {
        free(v51[0]);
      }
      if (*(_DWORD *)(v45 + 36)) {
        uint64_t v37 = v45 - 16;
      }
      else {
        uint64_t v37 = 0;
      }
      unint64_t v36 = *(void *)(v43 + 8) & 0xFFFFFFFFFFFFFFF8;
      if (v36 != (*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v37, 0) + 8) & 0xFFFFFFFFFFFFFFF8))
      {
        uint64_t v38 = *(void *)(v45 + 24);
        if (*(_DWORD *)(v45 + 36)) {
          uint64_t v39 = v45 - 16;
        }
        else {
          uint64_t v39 = 0;
        }
        v51[0] = (void *)(*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v39, 0) + 8) & 0xFFFFFFFFFFFFFFF8);
        v49[0] = (char *)v35 - 16;
        uint64_t v35 = mlir::OpBuilder::create<mlir::tensor::CastOp,mlir::TensorType &,mlir::Value>((mlir::OpBuilder *)(a3 + 1), v38, (uint64_t *)v51, (uint64_t *)v49);
      }
      uint64_t v40 = v45;
      unint64_t v41 = *((unsigned int *)v35 + 9);
      if (v41) {
        uint64_t v42 = (uint64_t)v35 - 16;
      }
      else {
        uint64_t v42 = 0;
      }
      mlir::ValueRange::ValueRange(v46, v42, v41);
      (*((void (**)(mlir::MLIRContext **, uint64_t, unint64_t, unint64_t))*a3 + 3))(a3, v40, v46[0], v46[1]);
      return 1;
    }
  }
  return result;
}

void *anonymous namespace'::InsertSliceOpSourceCastInserter<mlir::tensor::InsertSliceOp>::~InsertSliceOpSourceCastInserter(void *a1)
{
  uint64_t v2 = (void *)a1[10];
  if (v2 != a1 + 12) {
    free(v2);
  }
  int64_t v3 = (void *)a1[4];
  if (v3 != a1 + 6) {
    free(v3);
  }
  return a1;
}

void anonymous namespace'::InsertSliceOpSourceCastInserter<mlir::tensor::InsertSliceOp>::~InsertSliceOpSourceCastInserter(void *a1)
{
  uint64_t v2 = (void *)a1[10];
  if (v2 != a1 + 12) {
    free(v2);
  }
  int64_t v3 = (void *)a1[4];
  if (v3 != a1 + 6) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t anonymous namespace'::InsertSliceOpSourceCastInserter<mlir::tensor::InsertSliceOp>::matchAndRewrite(uint64_t a1, uint64_t a2, uint64_t a3)
{
  void v49[6] = *MEMORY[0x263EF8340];
  unint64_t v37 = *(void *)(*(void *)(*(void *)(a2 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8;
  uint64_t v38 = a2;
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v37);
  uint64_t v6 = v5;
  if (*(_DWORD *)(a2 + 36)) {
    uint64_t v7 = a2 - 16;
  }
  else {
    uint64_t v7 = 0;
  }
  uint64_t v47 = (void *)(*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v7, 0) + 8) & 0xFFFFFFFFFFFFFFF8);
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v47);
  if (v6 != v8) {
    return 0;
  }
  uint64_t Value = (unsigned char *)mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v37);
  uint64_t v10 = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v37);
  unint64_t v12 = (unsigned char *)(v10 + 8 * v11);
  uint64_t v47 = v49;
  uint64_t v48 = 0x600000000;
  uint64_t v13 = v12 - Value;
  if ((unint64_t)(v12 - Value) >= 0x31)
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v47, v49, v13 >> 3, 8);
    int v14 = v48;
    if (v12 == Value) {
      goto LABEL_11;
    }
    goto LABEL_10;
  }
  int v14 = 0;
  if (v12 != Value)
  {
LABEL_10:
    memcpy(&v47[v14], Value, v12 - Value);
    int v14 = v48;
  }
LABEL_11:
  LODWORD(v48) = v14 + ((unint64_t)v13 >> 3);
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v37);
  if (v16 >= 1)
  {
    for (uint64_t i = 0; i < v18; ++i)
    {
      mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::tensor::InsertSliceOp>::getMixedSizes((mlir::memref::ReinterpretCastOp *)&v38, (uint64_t)v45);
      unint64_t ConstantIntValue = mlir::getConstantIntValue(*((void *)v45[0] + i));
      char v21 = v20;
      if (v45[0] != v46) {
        free(v45[0]);
      }
      if (v21)
      {
        if ((ConstantIntValue & 0x8000000000000000) != 0) {
          goto LABEL_34;
        }
        v47[i] = ConstantIntValue;
      }
      mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v37);
    }
  }
  uint64_t v22 = (uint64_t)v47;
  uint64_t v23 = v48;
  uint64_t RHS = mlir::AffineBinaryOpExpr::getRHS((mlir::AffineBinaryOpExpr *)&v37);
  uint64_t v25 = mlir::RankedTensorType::get(v22, v23, RHS, 0);
  uint64_t v36 = v25;
  if (v37 != v25)
  {
    if (mlir::tensor::preservesStaticInformation(v37, v25))
    {
      mlir::ValueRange::ValueRange(v44, (uint64_t)&v37, 1uLL);
      mlir::ValueRange::ValueRange(v43, (uint64_t)&v36, 1uLL);
      if (mlir::tensor::CastOp::areCastCompatible(v44[0], v44[1], v43[0], v43[1]))
      {
        uint64_t v26 = (_OWORD *)(a3 + 24);
        long long v33 = *(_OWORD *)(a3 + 24);
        uint64_t v27 = *(void *)(v38 + 24);
        v45[0] = *(void **)(*(void *)(v38 + 72) + 24);
        uint64_t v35 = (uint64_t)mlir::OpBuilder::create<mlir::tensor::CastOp,mlir::TensorType &,mlir::Value>((mlir::OpBuilder *)(a3 + 8), v27, &v36, (uint64_t *)v45)- 16;
        uint64_t v28 = v38;
        if (*(unsigned char *)(v38 + 47)) {
          uint64_t v29 = v38 + 80;
        }
        else {
          uint64_t v29 = 0;
        }
        uint64_t v34 = *(void *)(*(void *)(v38 + 72) + 32 * *(unsigned int *)(v29 + 24) + 24);
        mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::tensor::InsertSliceOp>::getMixedOffsets((mlir::memref::ReinterpretCastOp *)&v38, (uint64_t)v45);
        mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::tensor::InsertSliceOp>::getMixedSizes((mlir::memref::ReinterpretCastOp *)&v38, (uint64_t)v41);
        mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::tensor::InsertSliceOp>::getMixedStrides((mlir::memref::ReinterpretCastOp *)&v38, (uint64_t)v39);
        __int16 v30 = mlir::OpBuilder::create<mlir::tensor::InsertSliceOp,mlir::Value &,mlir::detail::TypedValue<mlir::RankedTensorType>,llvm::SmallVector<mlir::OpFoldResult,6u> &,llvm::SmallVector<mlir::OpFoldResult,6u> &,llvm::SmallVector<mlir::OpFoldResult,6u> &>((mlir::MLIRContext **)(a3 + 8), *(void *)(v28 + 24), &v35, &v34, (uint64_t)v45, (uint64_t)v41, (uint64_t)v39);
        (*(void (**)(uint64_t, uint64_t, ZinIrHalH13g *))(*(void *)a3 + 32))(a3, v28, v30);
        if (v39[0] != &v40) {
          free(v39[0]);
        }
        if (v41[0] != &v42) {
          free(v41[0]);
        }
        if (v45[0] != v46) {
          free(v45[0]);
        }
        if ((void)v33)
        {
          *uint64_t v26 = v33;
          uint64_t v15 = 1;
          uint64_t v31 = v47;
          if (v47 == v49) {
            return v15;
          }
        }
        else
        {
          *(void *)uint64_t v26 = 0;
          *(void *)(a3 + 32) = 0;
          uint64_t v15 = 1;
          uint64_t v31 = v47;
          if (v47 == v49) {
            return v15;
          }
        }
        goto LABEL_35;
      }
    }
  }
LABEL_34:
  uint64_t v15 = 0;
  uint64_t v31 = v47;
  if (v47 != v49) {
LABEL_35:
  }
    free(v31);
  return v15;
}

void anonymous namespace'::FoldStaticZeroPadding::~FoldStaticZeroPadding(_anonymous_namespace_::FoldStaticZeroPadding *this)
{
  uint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  int64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }
}

{
  char *v2;
  char *v3;
  uint64_t vars8;

  uint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  int64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::tensor::PadOp>::rewrite(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 48))();
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::tensor::PadOp>::match(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 56))();
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::tensor::PadOp>::matchAndRewrite(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 64))();
}

uint64_t anonymous namespace'::FoldStaticZeroPadding::matchAndRewrite(uint64_t a1, uint64_t a2, uint64_t a3)
{
  v28[6] = *MEMORY[0x263EF8340];
  uint64_t v25 = a2;
  mlir::tensor::PadOp::getMixedLowPad((mlir::tensor::PadOp *)&v25, (uint64_t)&v26);
  int v4 = (uint64_t *)v26;
  if (v27)
  {
    uint64_t v5 = 8 * v27 - 8;
    do
    {
      uint64_t v6 = *v4++;
      unint64_t ConstantIntValue = mlir::getConstantIntValue(v6);
      if (v8) {
        BOOL v9 = ConstantIntValue == 0;
      }
      else {
        BOOL v9 = 0;
      }
      int v10 = v9;
      BOOL v11 = v10 != 1 || v5 == 0;
      v5 -= 8;
    }
    while (!v11);
    int v4 = (uint64_t *)v26;
    if (v26 != v28) {
      goto LABEL_15;
    }
  }
  else
  {
    int v10 = 1;
    if (v26 != v28) {
LABEL_15:
    }
      free(v4);
  }
  if (!v10) {
    return 0;
  }
  mlir::tensor::PadOp::getMixedHighPad((mlir::tensor::PadOp *)&v25, (uint64_t)&v26);
  unint64_t v12 = (uint64_t *)v26;
  if (!v27)
  {
    int v18 = 1;
    if (v26 == v28) {
      goto LABEL_32;
    }
    goto LABEL_31;
  }
  uint64_t v13 = 8 * v27 - 8;
  do
  {
    uint64_t v14 = *v12++;
    unint64_t v15 = mlir::getConstantIntValue(v14);
    if (v16) {
      BOOL v17 = v15 == 0;
    }
    else {
      BOOL v17 = 0;
    }
    int v18 = v17;
    BOOL v19 = v18 != 1 || v13 == 0;
    v13 -= 8;
  }
  while (!v19);
  unint64_t v12 = (uint64_t *)v26;
  if (v26 != v28) {
LABEL_31:
  }
    free(v12);
LABEL_32:
  if (!v18) {
    return 0;
  }
  uint64_t v20 = v25;
  if (*(void *)(v25 + 16 * (((unint64_t)*(unsigned int *)(v25 + 44) >> 23) & 1) + 64)) {
    return 0;
  }
  if (*(_DWORD *)(v25 + 36)) {
    uint64_t v22 = v25 - 16;
  }
  else {
    uint64_t v22 = 0;
  }
  uint64_t v26 = (void *)(*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v22, 0) + 8) & 0xFFFFFFFFFFFFFFF8);
  uint64_t v24 = *(void *)(*(void *)(v25 + 72) + 24);
  uint64_t v23 = mlir::OpBuilder::create<mlir::tensor::CastOp,mlir::TensorType &,mlir::Value>((mlir::OpBuilder *)(a3 + 8), *(void *)(v20 + 24), (uint64_t *)&v26, &v24);
  (*(void (**)(uint64_t, uint64_t, ZinIrHalH13g *))(*(void *)a3 + 32))(a3, v20, v23);
  return 1;
}

uint64_t mlir::tensor::PadOp::hasZeroLowPad(mlir::tensor::PadOp *this)
{
  v12[6] = *MEMORY[0x263EF8340];
  mlir::tensor::PadOp::getMixedLowPad(this, (uint64_t)&v10);
  uint64_t v1 = (uint64_t *)v10;
  if (!v11)
  {
    uint64_t v7 = 1;
    if (v10 == v12) {
      return v7;
    }
    goto LABEL_15;
  }
  uint64_t v2 = 8 * v11 - 8;
  do
  {
    uint64_t v3 = *v1++;
    unint64_t ConstantIntValue = mlir::getConstantIntValue(v3);
    if (v5) {
      BOOL v6 = ConstantIntValue == 0;
    }
    else {
      BOOL v6 = 0;
    }
    uint64_t v7 = v6;
    BOOL v8 = v7 != 1 || v2 == 0;
    v2 -= 8;
  }
  while (!v8);
  uint64_t v1 = (uint64_t *)v10;
  if (v10 != v12) {
LABEL_15:
  }
    free(v1);
  return v7;
}

void anonymous namespace'::FoldSourceTensorCast::~FoldSourceTensorCast(_anonymous_namespace_::FoldSourceTensorCast *this)
{
  uint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  uint64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }
}

{
  char *v2;
  char *v3;
  uint64_t vars8;

  uint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  uint64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t anonymous namespace'::FoldSourceTensorCast::matchAndRewrite(uint64_t a1, uint64_t a2, mlir::MLIRContext **a3)
{
  v49[9] = *(llvm **)MEMORY[0x263EF8340];
  v49[0] = *(llvm **)(*(void *)(a2 + 72) + 24);
  uint64_t DefiningOp = mlir::Value::getDefiningOp((mlir::Value *)v49);
  if (!DefiningOp) {
    return 0;
  }
  uint64_t v6 = DefiningOp;
  if (*(_UNKNOWN **)(*(void *)(DefiningOp + 48) + 16) != &mlir::detail::TypeIDResolver<mlir::tensor::CastOp,void>::id) {
    return 0;
  }
  uint64_t result = mlir::tensor::preservesStaticInformation(*(void *)(DefiningOp - 8) & 0xFFFFFFFFFFFFFFF8, *(void *)(*(void *)(*(void *)(DefiningOp + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8);
  if (result)
  {
    unint64_t v8 = *(void *)(*(void *)(*(void *)(v6 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8;
    uint64_t v9 = a2 + 64;
    if (HIBYTE(*(_DWORD *)(a2 + 44))) {
      unint64_t v10 = a2 + 64 + 16 * (((unint64_t)*(unsigned int *)(a2 + 44) >> 23) & 1);
    }
    else {
      unint64_t v10 = 0;
    }
    v49[0] = *(llvm **)(v10 + 16);
    uint64_t v11 = mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)v49);
    uint64_t v13 = v12;
    if (HIBYTE(*(_DWORD *)(a2 + 44))) {
      uint64_t v14 = v9 + 16 * (((unint64_t)*(unsigned int *)(a2 + 44) >> 23) & 1);
    }
    else {
      uint64_t v14 = 0;
    }
    v49[0] = *(llvm **)(v14 + 8);
    uint64_t v15 = mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)v49);
    uint64_t v17 = v16;
    if (*(_DWORD *)(a2 + 36)) {
      uint64_t v18 = a2 - 16;
    }
    else {
      uint64_t v18 = 0;
    }
    v49[0] = (llvm *)(*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v18, 0) + 8) & 0xFFFFFFFFFFFFFFF8);
    uint64_t Value = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)v49);
    uint64_t v21 = mlir::tensor::PadOp::inferResultType(v8, v11, v13, v15, v17, Value, v20);
    uint64_t v48 = v21;
    if (*(_DWORD *)(a2 + 36)) {
      uint64_t v22 = a2 - 16;
    }
    else {
      uint64_t v22 = 0;
    }
    if (v21 != (*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v22, 0) + 8) & 0xFFFFFFFFFFFFFFF8))
    {
      uint64_t v23 = *(void *)(a2 + 24);
      int v24 = *(unsigned __int8 *)(a2 + 47);
      uint64_t v47 = *(void *)(*(void *)(a2 + 72) + 24);
      if (v24) {
        uint64_t v25 = a2 + 80;
      }
      else {
        uint64_t v25 = 0;
      }
      v49[0] = *(llvm **)(v25 + 16);
      v46[0] = mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)v49);
      v46[1] = v26;
      if (HIBYTE(*(_DWORD *)(a2 + 44))) {
        uint64_t v27 = v9 + 16 * (((unint64_t)*(unsigned int *)(a2 + 44) >> 23) & 1);
      }
      else {
        uint64_t v27 = 0;
      }
      v49[0] = *(llvm **)(v27 + 8);
      v45[0] = mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)v49);
      v45[1] = v28;
      unint64_t v29 = *(unsigned int *)(a2 + 44);
      __int16 v30 = (void *)(v9 + 16 * ((v29 >> 23) & 1));
      if (HIBYTE(*(_DWORD *)(a2 + 44))) {
        uint64_t v31 = (unsigned int *)(v9 + 16 * ((v29 >> 23) & 1));
      }
      else {
        uint64_t v31 = 0;
      }
      uint64_t v33 = v31[6];
      unsigned int v32 = v31[7];
      if ((v29 & 0x800000) != 0)
      {
        uint64_t v34 = v32 + v33;
        uint64_t v43 = *(void *)(a2 + 72) + 32 * v33;
        uint64_t v44 = v34 - v33;
        uint64_t v35 = *(void *)(a2 + 72);
      }
      else
      {
        uint64_t v35 = 0;
        uint64_t v34 = v32 + v33;
        uint64_t v43 = 32 * v33;
        uint64_t v44 = v34 - v33;
      }
      uint64_t v36 = v31[8] + v34 - v34;
      v42[0] = v35 + 32 * v34;
      v42[1] = v36;
      BOOL v41 = *v30 != 0;
      mlir::getPrunedAttributeList((unsigned char *)a2, (uint64_t)&mlir::tensor::PadOp::getAttributeNames(void)::attrNames, 4, (uint64_t)v49);
      mlir::OpBuilder::create<mlir::tensor::PadOp,mlir::RankedTensorType &,mlir::detail::TypedValue<mlir::RankedTensorType>,llvm::ArrayRef<long long>,llvm::ArrayRef<long long>,mlir::OperandRange,mlir::OperandRange,BOOL,llvm::SmallVector<mlir::NamedAttribute,3u>>(a3 + 1, v23, &v48, &v47, v46, v45, (uint64_t)&v43, (uint64_t)v42, (char *)&v41, (uint64_t)v49);
    }
    (*((void (**)(mlir::MLIRContext **, uint64_t))*a3 + 9))(a3, a2);
    unint64_t v37 = *(uint64_t **)(a2 + 72);
    uint64_t v38 = *(uint64_t **)(*(void *)(v6 + 72) + 24);
    uint64_t v39 = (uint64_t *)v37[1];
    if (v39)
    {
      *uint64_t v39 = *v37;
      if (*v37) {
        *(void *)(*v37 + 8) = v37[1];
      }
    }
    v37[3] = (uint64_t)v38;
    v37[1] = (uint64_t)v38;
    uint64_t v40 = *v38;
    uint64_t *v37 = *v38;
    if (v40) {
      *(void *)(v40 + 8) = v37;
    }
    *uint64_t v38 = (uint64_t)v37;
    (*((void (**)(mlir::MLIRContext **, uint64_t))*a3 + 10))(a3, a2);
    return 1;
  }
  return result;
}

void mlir::OpBuilder::create<mlir::tensor::PadOp,mlir::RankedTensorType &,mlir::detail::TypedValue<mlir::RankedTensorType>,llvm::ArrayRef<long long>,llvm::ArrayRef<long long>,mlir::OperandRange,mlir::OperandRange,BOOL,llvm::SmallVector<mlir::NamedAttribute,3u>>(mlir::MLIRContext **a1, uint64_t a2, uint64_t *a3, uint64_t *a4, uint64_t *a5, uint64_t *a6, uint64_t a7, uint64_t a8, char *a9, uint64_t a10)
{
  v34[38] = *MEMORY[0x263EF8340];
  uint64_t v27 = a2;
  uint64_t Context = (uint64_t *)mlir::Attribute::getContext((mlir::Attribute *)&v27);
  uint64_t v19 = mlir::RegisteredOperationName::lookup((int8x16_t *)"tensor.pad", (const unsigned __int8 *)0xA, Context);
  if (v20)
  {
    mlir::OperationState::OperationState(v34, a2, v19);
    uint64_t v26 = *a3;
    uint64_t v21 = *a4;
    uint64_t v23 = *a5;
    uint64_t v22 = a5[1];
    uint64_t v25 = *a6;
    uint64_t v24 = a6[1];
    mlir::ValueRange::ValueRange(v33, *(void *)a7, *(void *)(a7 + 8));
    mlir::ValueRange::ValueRange(v32, *(void *)a8, *(void *)(a8 + 8));
    mlir::tensor::PadOp::build(a1, (mlir::OperationState *)v34, v26, v21, v23, v22, v25, v24, v33[0], v33[1], v32[0], v32[1], *a9, *(void **)a10, *(unsigned int *)(a10 + 8));
  }
  __int16 v31 = 1283;
  v30[2] = (uint64_t)"tensor.pad";
  v30[3] = 10;
        "he dialect. See also https://mlir.llvm.org/getting_started/Faq/#registered-loaded-dependent-whats-up-with-dialects-management";
  __int16 v29 = 259;
  llvm::operator+(v30, (uint64_t *)&v28, (uint64_t)v34);
  llvm::report_fatal_error((llvm::Twine *)v34, 1);
}

void anonymous namespace'::FoldTargetTensorCast::~FoldTargetTensorCast(_anonymous_namespace_::FoldTargetTensorCast *this)
{
  uint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  uint64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }
}

{
  char *v2;
  char *v3;
  uint64_t vars8;

  uint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  uint64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t anonymous namespace'::FoldTargetTensorCast::matchAndRewrite(uint64_t a1, uint64_t a2, uint64_t a3)
{
  void v48[6] = *MEMORY[0x263EF8340];
  uint64_t v5 = a2 - 16;
  if (*(_DWORD *)(a2 + 36)) {
    uint64_t v6 = a2 - 16;
  }
  else {
    uint64_t v6 = 0;
  }
  uint64_t NextResultAtOffset = (void *)mlir::detail::OpResultImpl::getNextResultAtOffset(v6, 0);
  if (*NextResultAtOffset && !*(void *)*NextResultAtOffset)
  {
    uint64_t v9 = (void *)*(unsigned int *)(a2 + 36);
    unint64_t v10 = v9 ? (void *)v5 : 0;
    v45[0] = v10;
    v45[1] = v9;
    mlir::ResultRange::use_begin((uint64_t *)v45, (uint64_t *)v41);
    uint64_t v11 = *(unsigned int *)(a2 + 36);
    uint64_t v12 = v11 ? v5 : 0;
    uint64_t v43 = v12;
    uint64_t v44 = v11;
    mlir::ResultRange::use_end(&v43, v48);
    uint64_t v47 = v42;
    *(_OWORD *)uint64_t v45 = v41[0];
    long long v46 = v41[1];
    uint64_t v13 = *(void *)(v42 + 16);
    if (v13)
    {
      if (*(_UNKNOWN **)(*(void *)(v13 + 48) + 16) == &mlir::detail::TypeIDResolver<mlir::tensor::CastOp,void>::id)
      {
        uint64_t v14 = *(_DWORD *)(a2 + 36) ? v5 : 0;
        unint64_t v15 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v14, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
        uint64_t v16 = *(_DWORD *)(v13 + 36) ? v13 - 16 : 0;
        uint64_t v17 = mlir::detail::OpResultImpl::getNextResultAtOffset(v16, 0);
        if (mlir::tensor::preservesStaticInformation(v15, *(void *)(v17 + 8) & 0xFFFFFFFFFFFFFFF8))
        {
          uint64_t v18 = *(void *)(a2 + 24);
          if (*(_DWORD *)(v13 + 36)) {
            uint64_t v19 = v13 - 16;
          }
          else {
            uint64_t v19 = 0;
          }
          unint64_t v20 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v19, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
          int v21 = *(unsigned __int8 *)(a2 + 47);
          uint64_t v22 = a2 + 64;
          uint64_t v39 = *(void *)(*(void *)(a2 + 72) + 24);
          unint64_t v40 = v20;
          if (v21) {
            uint64_t v23 = a2 + 80;
          }
          else {
            uint64_t v23 = 0;
          }
          v45[0] = *(void **)(v23 + 16);
          *(void *)&v41[0] = mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)v45);
          *((void *)&v41[0] + 1) = v24;
          if (HIBYTE(*(_DWORD *)(a2 + 44))) {
            uint64_t v25 = v22 + 16 * (((unint64_t)*(unsigned int *)(a2 + 44) >> 23) & 1);
          }
          else {
            uint64_t v25 = 0;
          }
          v45[0] = *(void **)(v25 + 8);
          uint64_t v43 = mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)v45);
          uint64_t v44 = v26;
          unint64_t v27 = *(unsigned int *)(a2 + 44);
          uint64_t v28 = (void *)(v22 + 16 * ((v27 >> 23) & 1));
          if (HIBYTE(*(_DWORD *)(a2 + 44))) {
            __int16 v29 = (unsigned int *)(v22 + 16 * ((v27 >> 23) & 1));
          }
          else {
            __int16 v29 = 0;
          }
          uint64_t v31 = v29[6];
          unsigned int v30 = v29[7];
          if ((v27 & 0x800000) != 0)
          {
            uint64_t v32 = v30 + v31;
            uint64_t v37 = *(void *)(a2 + 72) + 32 * v31;
            uint64_t v38 = v32 - v31;
            uint64_t v33 = *(void *)(a2 + 72);
          }
          else
          {
            uint64_t v33 = 0;
            uint64_t v32 = v30 + v31;
            uint64_t v37 = 32 * v31;
            uint64_t v38 = v32 - v31;
          }
          uint64_t v34 = v29[8] + v32 - v32;
          v36[0] = v33 + 32 * v32;
          v36[1] = v34;
          BOOL v35 = *v28 != 0;
          mlir::getPrunedAttributeList((unsigned char *)a2, (uint64_t)&mlir::tensor::PadOp::getAttributeNames(void)::attrNames, 4, (uint64_t)v45);
          mlir::OpBuilder::create<mlir::tensor::PadOp,mlir::RankedTensorType &,mlir::detail::TypedValue<mlir::RankedTensorType>,llvm::ArrayRef<long long>,llvm::ArrayRef<long long>,mlir::OperandRange,mlir::OperandRange,BOOL,llvm::SmallVector<mlir::NamedAttribute,3u>>((mlir::MLIRContext **)(a3 + 8), v18, (uint64_t *)&v40, &v39, (uint64_t *)v41, &v43, (uint64_t)&v37, (uint64_t)v36, (char *)&v35, (uint64_t)v45);
        }
      }
    }
  }
  return 0;
}

void anonymous namespace'::FoldOrthogonalPaddings::~FoldOrthogonalPaddings(_anonymous_namespace_::FoldOrthogonalPaddings *this)
{
  uint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  uint64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }
}

{
  char *v2;
  char *v3;
  uint64_t vars8;

  uint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  uint64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t anonymous namespace'::FoldOrthogonalPaddings::matchAndRewrite(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v85 = *MEMORY[0x263EF8340];
  uint64_t v71 = (unsigned char *)a2;
  char v81 = *(char **)(*(void *)(a2 + 72) + 24);
  uint64_t DefiningOp = mlir::Value::getDefiningOp((mlir::Value *)&v81);
  if (!DefiningOp) {
    return 0;
  }
  uint64_t v5 = *(void **)(*(void *)(DefiningOp + 48) + 16);
  BOOL v6 = v5 == &mlir::detail::TypeIDResolver<mlir::tensor::ExtractSliceOp,void>::id;
  uint64_t v7 = v5 == &mlir::detail::TypeIDResolver<mlir::tensor::ExtractSliceOp,void>::id ? DefiningOp : 0;
  uint64_t v70 = v7;
  if (!v6) {
    return 0;
  }
  char v81 = *(char **)(*(void *)(DefiningOp + 72) + 24);
  uint64_t v10 = mlir::Value::getDefiningOp((mlir::Value *)&v81);
  if (!v10) {
    return 0;
  }
  uint64_t v11 = *(void **)(*(void *)(v10 + 48) + 16);
  BOOL v12 = v11 == &mlir::detail::TypeIDResolver<mlir::tensor::PadOp,void>::id;
  uint64_t v13 = v11 == &mlir::detail::TypeIDResolver<mlir::tensor::PadOp,void>::id ? v10 : 0;
  uint64_t v69 = v13;
  if (!v12) {
    return 0;
  }
  if (*(void *)(v10 + 16 * (((unint64_t)*(unsigned int *)(v10 + 44) >> 23) & 1) + 64)) {
    return 0;
  }
  char v81 = *(char **)(*(void *)(v10 + 72) + 24);
  uint64_t v14 = mlir::Value::getDefiningOp((mlir::Value *)&v81);
  if (!v14) {
    return 0;
  }
  unint64_t v15 = *(void **)(*(void *)(v14 + 48) + 16);
  BOOL v16 = v15 == &mlir::detail::TypeIDResolver<mlir::tensor::ExtractSliceOp,void>::id;
  uint64_t v17 = v15 == &mlir::detail::TypeIDResolver<mlir::tensor::ExtractSliceOp,void>::id ? v14 : 0;
  uint64_t v68 = v17;
  if (!v16) {
    return 0;
  }
  char v81 = (char *)(*(void *)(*(void *)(*((void *)v71 + 9) + 24) + 8) & 0xFFFFFFFFFFFFFFF8);
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v81);
  unint64_t v19 = v18;
  char v81 = (char *)(*(void *)(*(void *)(*(void *)(v68 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8);
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v81);
  if (v20 != v19)
  {
    char v81 = "cannot fold rank-reducing chain";
    __int16 v84 = 259;
    __int16 v29 = v71;
    long long v78 = &v81;
    uint64_t v8 = *(void *)(a3 + 16);
    if (!v8) {
      return v8;
    }
LABEL_52:
    if (mlir::RewriterBase::Listener::classof(v8)) {
      return (*(uint64_t (**)(uint64_t, void, uint64_t (*)(void ****, uint64_t), char ***))(*(void *)v8 + 64))(v8, *((void *)v29 + 3), llvm::function_ref<void ()(mlir::Diagnostic &)>::callback_fn<mlir::LogicalResult mlir::RewriterBase::notifyMatchFailure<mlir::tensor::PadOp &>(mlir::tensor::PadOp &,llvm::Twine const&)::{lambda(mlir::Diagnostic &)#1}>, &v78);
    }
    return 0;
  }
  mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::memref::ReinterpretCastOp>::getMixedStrides((mlir::memref::ReinterpretCastOp *)&v70, (uint64_t)&v81);
  int v21 = (uint64_t *)v81;
  if (v82)
  {
    uint64_t v22 = 8 * v82 - 8;
    do
    {
      uint64_t v23 = *v21++;
      unint64_t ConstantIntValue = mlir::getConstantIntValue(v23);
      if (v25) {
        BOOL v26 = ConstantIntValue == 1;
      }
      else {
        BOOL v26 = 0;
      }
      int v27 = v26;
      BOOL v28 = v27 != 1 || v22 == 0;
      v22 -= 8;
    }
    while (!v28);
    int v21 = (uint64_t *)v81;
  }
  else
  {
    int v27 = 1;
  }
  if (v21 != (uint64_t *)v83) {
    free(v21);
  }
  if (!v27
    || (mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::tensor::ExtractSliceOp>::hasUnitStride((mlir::memref::ReinterpretCastOp *)&v68) & 1) == 0)
  {
    char v81 = "cannot fold non-unit stride ExtractSliceOps";
    __int16 v84 = 259;
    __int16 v29 = v71;
    long long v78 = &v81;
    uint64_t v8 = *(void *)(a3 + 16);
    if (!v8) {
      return v8;
    }
    goto LABEL_52;
  }
  if (!mlir::tensor::PadOp::hasZeroLowPad((mlir::tensor::PadOp *)&v71)
    || (mlir::tensor::PadOp::hasZeroLowPad((mlir::tensor::PadOp *)&v69) & 1) == 0)
  {
    uint64_t v33 = "cannot fold PadOps with low padding";
    return mlir::RewriterBase::notifyMatchFailure<mlir::tensor::PadOp &>(a3, (uint64_t *)&v71, v33);
  }
  uint64_t v66 = 0;
  uint64_t v67 = 0;
  ConstantPaddinguint64_t Value = mlir::tensor::PadOp::getConstantPaddingValue((mlir::tensor::PadOp *)&v71);
  uint64_t v31 = mlir::tensor::PadOp::getConstantPaddingValue((mlir::tensor::PadOp *)&v69);
  if (!ConstantPaddingValue
    || (uint64_t v32 = v31) == 0
    || (char v81 = (char *)&v67,
        !mlir::matchPattern<mlir::detail::constant_op_binder<mlir::Attribute>>(ConstantPaddingValue, (unint64_t **)&v81))|| (long long v78 = (char **)&v66, !mlir::matchPattern<mlir::detail::constant_op_binder<mlir::Attribute>>(v32, (unint64_t **)&v78))|| v67 != v66)
  {
    uint64_t v33 = "cannot fold PadOps with different padding values";
    return mlir::RewriterBase::notifyMatchFailure<mlir::tensor::PadOp &>(a3, (uint64_t *)&v71, v33);
  }
  mlir::tensor::PadOp::getPaddedDims((mlir::tensor::PadOp *)&v71, (unint64_t *)&v65);
  mlir::tensor::PadOp::getPaddedDims((mlir::tensor::PadOp *)&v69, (unint64_t *)&v64);
  if (llvm::SmallBitVector::anyCommon((llvm::SmallBitVector *)&v65, (const llvm::SmallBitVector *)&v64))
  {
    uint64_t v8 = mlir::RewriterBase::notifyMatchFailure<mlir::tensor::PadOp &>(a3, (uint64_t *)&v71, "cannot fold PadOps with common padding dimensions");
    goto LABEL_116;
  }
  BOOL v60 = (mlir::IndexType **)(a3 + 8);
  long long v78 = (char **)(mlir::Builder::getIndexAttr((mlir::IndexType **)(a3 + 8), 0) & 0xFFFFFFFFFFFFFFFBLL);
  llvm::SmallVector<mlir::OpFoldResult,6u>::SmallVector(&v81, v19, (unint64_t *)&v78);
  if (v82)
  {
    uint64_t v34 = 0;
    BOOL v35 = (unint64_t *)v81;
    uint64_t v36 = 8 * v82;
    do
    {
      mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::memref::ReinterpretCastOp>::getMixedOffsets((mlir::memref::ReinterpretCastOp *)&v70, (uint64_t)&v78);
      uint64_t v37 = (uint64_t)v78[v34];
      if (v78 != (char **)v80) {
        free(v78);
      }
      mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::memref::ReinterpretCastOp>::getMixedOffsets((mlir::memref::ReinterpretCastOp *)&v68, (uint64_t)&v78);
      uint64_t v38 = (uint64_t)v78[v34];
      if (v78 != (char **)v80) {
        free(v78);
      }
      if (!llvm::SmallBitVector::test((llvm::SmallBitVector *)&v65, v34)
        && ((unint64_t v39 = mlir::getConstantIntValue(v37), v40) ? (v41 = v39 == 0) : (v41 = 0), v41))
      {
        uint64_t v37 = v38;
      }
      else if (llvm::SmallBitVector::test((llvm::SmallBitVector *)&v64, v34) {
             || ((unint64_t v42 = mlir::getConstantIntValue(v38), v43) ? (v44 = v42 == 0) : (v44 = 0), !v44))
      }
      {
        uint64_t v8 = mlir::RewriterBase::notifyMatchFailure<mlir::tensor::PadOp &>(a3, (uint64_t *)&v71, "cannot find zero-offset and zero-padding pair");
        goto LABEL_114;
      }
      v35[v34++] = v37;
      v36 -= 8;
    }
    while (v36);
  }
  mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::memref::ReinterpretCastOp>::getMixedSizes((mlir::memref::ReinterpretCastOp *)&v70, (uint64_t)&v75);
  long long v78 = (char **)v80;
  uint64_t v79 = 0x600000000;
  if (v76) {
    llvm::SmallVectorImpl<llvm::SMLoc>::operator=((uint64_t)&v78, (uint64_t)&v75);
  }
  if (v75 != v77) {
    free(v75);
  }
  if (!v79)
  {
LABEL_94:
    v73[0] = (void *)(mlir::Builder::getIndexAttr(v60, 0) & 0xFFFFFFFFFFFFFFFBLL);
    llvm::SmallVector<mlir::OpFoldResult,6u>::SmallVector(&v75, v19, (unint64_t *)v73);
    if (v76)
    {
      uint64_t v53 = 0;
      uint64_t v54 = 8 * v76;
      do
      {
        if (llvm::SmallBitVector::test((llvm::SmallBitVector *)&v65, v53))
        {
          mlir::tensor::PadOp::getMixedHighPad((mlir::tensor::PadOp *)&v71, (uint64_t)v73);
          *(void *)&v75[8 * v53] = *((void *)v73[0] + v53);
          if (v73[0] != v74) {
            free(v73[0]);
          }
        }
        if (llvm::SmallBitVector::test((llvm::SmallBitVector *)&v64, v53))
        {
          mlir::tensor::PadOp::getMixedHighPad((mlir::tensor::PadOp *)&v69, (uint64_t)v73);
          *(void *)&v75[8 * v53] = *((void *)v73[0] + v53);
          if (v73[0] != v74) {
            free(v73[0]);
          }
        }
        ++v53;
        v54 -= 8;
      }
      while (v54);
    }
    uint64_t v55 = *((void *)v71 + 3);
    v72[0] = *(void **)(*(void *)(v68 + 72) + 24);
    mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::memref::ReinterpretCastOp>::getMixedStrides((mlir::memref::ReinterpretCastOp *)&v70, (uint64_t)v73);
    uint64_t v56 = mlir::OpBuilder::create<mlir::tensor::ExtractSliceOp,mlir::detail::TypedValue<mlir::RankedTensorType>,llvm::SmallVector<mlir::OpFoldResult,6u> &,llvm::SmallVector<mlir::OpFoldResult,6u> &,llvm::SmallVector<mlir::OpFoldResult,4u>>(v60, v55, (uint64_t *)v72, (uint64_t)&v81, (uint64_t)&v78, (uint64_t)v73);
    if (v73[0] != v74) {
      free(v73[0]);
    }
    uint64_t v57 = *((void *)v71 + 3);
    if (*((_DWORD *)v71 + 9)) {
      unsigned int v58 = v71 - 16;
    }
    else {
      unsigned int v58 = 0;
    }
    unint64_t v63 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset((uint64_t)v58, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
    if (*((_DWORD *)v56 + 9)) {
      uint64_t v59 = (uint64_t)v56 - 16;
    }
    else {
      uint64_t v59 = 0;
    }
    uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v59, 0);
    mlir::tensor::PadOp::getMixedLowPad((mlir::tensor::PadOp *)&v71, (uint64_t)v73);
    BOOL v61 = *(void *)&v71[16 * (((unint64_t)*((unsigned int *)v71 + 11) >> 23) & 1) + 64] != 0;
    mlir::getPrunedAttributeList(v71, (uint64_t)&mlir::tensor::PadOp::getAttributeNames(void)::attrNames, 4, (uint64_t)v72);
    mlir::OpBuilder::create<mlir::tensor::PadOp,mlir::RankedTensorType,mlir::detail::TypedValue<mlir::RankedTensorType>,llvm::SmallVector<mlir::OpFoldResult,6u>,llvm::SmallVector<mlir::OpFoldResult,6u>&,BOOL,llvm::SmallVector<mlir::NamedAttribute,3u>>(v60, v57, (uint64_t *)&v63, &NextResultAtOffset, (uint64_t)v73, (uint64_t)&v75, (char *)&v61, (uint64_t)v72);
  }
  uint64_t v45 = 0;
  long long v46 = (unint64_t *)v78;
  uint64_t v47 = 8 * v79;
  while (!llvm::SmallBitVector::test((llvm::SmallBitVector *)&v64, v45))
  {
LABEL_83:
    ++v45;
    v47 -= 8;
    if (!v47) {
      goto LABEL_94;
    }
  }
  mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::memref::ReinterpretCastOp>::getMixedSizes((mlir::memref::ReinterpretCastOp *)&v70, (uint64_t)&v75);
  uint64_t v48 = *(void *)&v75[8 * v45];
  if (v75 != v77) {
    free(v75);
  }
  unsigned int v75 = (unsigned char *)(*(void *)(*(void *)(*(void *)(v70 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8);
  uint64_t v49 = *(void *)(mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v75) + 8 * v45);
  unint64_t v50 = mlir::getConstantIntValue(v48);
  if (v51) {
    BOOL v52 = v50 == v49;
  }
  else {
    BOOL v52 = 0;
  }
  if (v52)
  {
    mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::memref::ReinterpretCastOp>::getMixedSizes((mlir::memref::ReinterpretCastOp *)&v68, (uint64_t)&v75);
    v46[v45] = *(void *)&v75[8 * v45];
    if (v75 != v77) {
      free(v75);
    }
    goto LABEL_83;
  }
  uint64_t v8 = mlir::RewriterBase::notifyMatchFailure<mlir::tensor::PadOp &>(a3, (uint64_t *)&v71, "cannot fold since the inner ExtractSliceOp size does not match the size of the outer padding");
  if (v78 != (char **)v80) {
    free(v78);
  }
LABEL_114:
  if (v81 != v83) {
    free(v81);
  }
LABEL_116:
  llvm::SmallBitVector::~SmallBitVector(&v64);
  llvm::SmallBitVector::~SmallBitVector(&v65);
  return v8;
}

uint64_t mlir::RewriterBase::notifyMatchFailure<mlir::tensor::PadOp &>(uint64_t a1, uint64_t *a2, unsigned char *a3)
{
  char v3 = 1;
  char v9 = 1;
  if (*a3)
  {
    uint64_t v7 = a3;
    char v3 = 3;
  }
  char v8 = v3;
  uint64_t v4 = *a2;
  uint64_t v10 = &v7;
  uint64_t v5 = *(void *)(a1 + 16);
  if (!v5) {
    return 0;
  }
  uint64_t result = mlir::RewriterBase::Listener::classof(*(void *)(a1 + 16));
  if (result) {
    return (*(uint64_t (**)(uint64_t, void, uint64_t (*)(void ****, uint64_t), void **))(*(void *)v5 + 64))(v5, *(void *)(v4 + 24), llvm::function_ref<void ()(mlir::Diagnostic &)>::callback_fn<mlir::LogicalResult mlir::RewriterBase::notifyMatchFailure<mlir::tensor::PadOp &>(mlir::tensor::PadOp &,llvm::Twine const&)::{lambda(mlir::Diagnostic &)#1}>, &v10);
  }
  return result;
}

uint64_t mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::tensor::ExtractSliceOp>::hasUnitStride(mlir::memref::ReinterpretCastOp *a1)
{
  uint64_t v12[4] = *MEMORY[0x263EF8340];
  mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::memref::ReinterpretCastOp>::getMixedStrides(a1, (uint64_t)&v10);
  uint64_t v1 = (uint64_t *)v10;
  if (!v11)
  {
    uint64_t v7 = 1;
    if (v10 == v12) {
      return v7;
    }
    goto LABEL_15;
  }
  uint64_t v2 = 8 * v11 - 8;
  do
  {
    uint64_t v3 = *v1++;
    unint64_t ConstantIntValue = mlir::getConstantIntValue(v3);
    if (v5) {
      BOOL v6 = ConstantIntValue == 1;
    }
    else {
      BOOL v6 = 0;
    }
    uint64_t v7 = v6;
    BOOL v8 = v7 != 1 || v2 == 0;
    v2 -= 8;
  }
  while (!v8);
  uint64_t v1 = (uint64_t *)v10;
  if (v10 != v12) {
LABEL_15:
  }
    free(v1);
  return v7;
}

uint64_t mlir::matchPattern<mlir::detail::constant_op_binder<mlir::Attribute>>(uint64_t a1, unint64_t **a2)
{
  v11[1] = *MEMORY[0x263EF8340];
  uint64_t v9 = a1;
  uint64_t DefiningOp = mlir::Value::getDefiningOp((mlir::Value *)&v9);
  uint64_t v5 = DefiningOp;
  if (DefiningOp)
  {
    if (mlir::OperationName::hasTrait<mlir::OpTrait::ConstantLike>((void *)(DefiningOp + 48)))
    {
      v10[0] = v11;
      v10[1] = (void *)0x100000000;
      mlir::Operation::fold(v5, 0, 0, (uint64_t)v10);
      BOOL v6 = v10[0];
      unint64_t v7 = *(void *)v10[0] & 0xFFFFFFFFFFFFFFF8;
      BOOL v2 = v7 != 0;
      if (v7 && *a2)
      {
        **a2 = v7;
        BOOL v6 = v10[0];
      }
      if (v6 != v11) {
        free(v6);
      }
    }
    else
    {
      BOOL v2 = 0;
    }
  }
  return (v5 != 0) & v2;
}

BOOL llvm::SmallBitVector::anyCommon(llvm::SmallBitVector *this, const llvm::SmallBitVector *a2)
{
  unint64_t v2 = *(void *)this;
  unint64_t v3 = *(void *)a2;
  if (*(void *)this)
  {
    unint64_t v15 = v2 >> 58;
    if (v3) {
      return (~((-1 << v15) | (-1 << (v3 >> 58))) & ((v2 & v3) >> 1)) != 0;
    }
  }
  else
  {
    if ((v3 & 1) == 0)
    {
      unsigned int v4 = *(_DWORD *)(v2 + 8);
      LODWORD(v5) = *(_DWORD *)(v3 + 8);
      if (v5 >= v4) {
        uint64_t v5 = v4;
      }
      else {
        uint64_t v5 = v5;
      }
      if (v5)
      {
        BOOL v6 = *(uint64_t **)v2;
        unint64_t v7 = *(uint64_t **)v3;
        uint64_t v8 = v5 - 1;
        do
        {
          uint64_t v10 = *v6++;
          uint64_t v9 = v10;
          uint64_t v11 = *v7++;
          uint64_t v12 = v11 & v9;
          BOOL result = v12 != 0;
          if (v12) {
            BOOL v14 = 1;
          }
          else {
            BOOL v14 = v8 == 0;
          }
          --v8;
        }
        while (!v14);
        return result;
      }
      return 0;
    }
    unint64_t v15 = *(unsigned int *)(v2 + 64);
  }
  if (v3)
  {
    if (v3 >> 58 < v15) {
      unint64_t v15 = v3 >> 58;
    }
    if (!v15) {
      return 0;
    }
  }
  else
  {
    if (*(unsigned int *)(v3 + 64) < v15) {
      unint64_t v15 = *(unsigned int *)(v3 + 64);
    }
    if (!v15) {
      return 0;
    }
  }
  unint64_t v16 = (v3 >> 1) & ~(-1 << (v3 >> 58));
  if (v2)
  {
    unint64_t v20 = (v2 >> 1) & ~(-1 << (v2 >> 58));
    if (v3)
    {
      uint64_t v23 = 0;
      do
      {
        BOOL result = (v16 & (1 << v23)) != 0 && (v20 & (1 << v23)) != 0;
        if (result) {
          break;
        }
        BOOL v14 = v15 - 1 == v23++;
      }
      while (!v14);
    }
    else
    {
      uint64_t v21 = 0;
      while (((v20 >> v21) & 1) == 0 || ((*(void *)(*(void *)v3 + 8 * (v21 >> 6)) >> v21) & 1) == 0)
      {
        if (v15 == ++v21) {
          return 0;
        }
      }
      return 1;
    }
  }
  else
  {
    uint64_t v17 = *(uint64_t **)v2;
    if (v3)
    {
      uint64_t v22 = 0;
      while ((((unint64_t)v17[v22 >> 6] >> v22) & 1) == 0 || ((v16 >> v22) & 1) == 0)
      {
        if (v15 == ++v22) {
          return 0;
        }
      }
      return 1;
    }
    else
    {
      unsigned int v18 = 0;
      while (1)
      {
        uint64_t v19 = v18 >> 6;
        if ((v17[v19] & (1 << v18)) != 0 && (*(void *)(*(void *)v3 + 8 * v19) & (1 << v18)) != 0) {
          break;
        }
        if (v15 == ++v18) {
          return 0;
        }
      }
      return 1;
    }
  }
  return result;
}

ZinIrHalH13g *mlir::OpBuilder::create<mlir::tensor::ExtractSliceOp,mlir::detail::TypedValue<mlir::RankedTensorType>,llvm::SmallVector<mlir::OpFoldResult,6u> &,llvm::SmallVector<mlir::OpFoldResult,6u> &,llvm::SmallVector<mlir::OpFoldResult,4u>>(mlir::MLIRContext **a1, uint64_t a2, uint64_t *a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  v23[38] = *MEMORY[0x263EF8340];
  uint64_t v18 = a2;
  uint64_t Context = (uint64_t *)mlir::Attribute::getContext((mlir::Attribute *)&v18);
  uint64_t v13 = mlir::RegisteredOperationName::lookup((int8x16_t *)"tensor.extract_slice", (const unsigned __int8 *)0x14, Context);
  if (!v14)
  {
    __int16 v22 = 1283;
    unint64_t v21[2] = (uint64_t)"tensor.extract_slice";
    v21[3] = 20;
          " the dialect. See also https://mlir.llvm.org/getting_started/Faq/#registered-loaded-dependent-whats-up-with-di"
          "alects-management";
    __int16 v20 = 259;
    llvm::operator+(v21, (uint64_t *)&v19, (uint64_t)v23);
    llvm::report_fatal_error((llvm::Twine *)v23, 1);
  }
  mlir::OperationState::OperationState(v23, a2, v13);
  mlir::tensor::ExtractSliceOp::build(a1, (uint64_t)v23, 0, *a3, *(uint64_t **)a4, *(unsigned int *)(a4 + 8), *(uint64_t **)a5, *(unsigned int *)(a5 + 8), *(uint64_t **)a6, *(unsigned int *)(a6 + 8), 0, 0);
  unint64_t v15 = mlir::OpBuilder::create((mlir::OpBuilder *)a1, (const mlir::OperationState *)v23);
  if (*(_UNKNOWN **)(*((void *)v15 + 6) + 16) == &mlir::detail::TypeIDResolver<mlir::tensor::ExtractSliceOp,void>::id) {
    unint64_t v16 = v15;
  }
  else {
    unint64_t v16 = 0;
  }
  mlir::OperationState::~OperationState((mlir::OperationState *)v23);
  return v16;
}

void mlir::OpBuilder::create<mlir::tensor::PadOp,mlir::RankedTensorType,mlir::detail::TypedValue<mlir::RankedTensorType>,llvm::SmallVector<mlir::OpFoldResult,6u>,llvm::SmallVector<mlir::OpFoldResult,6u>&,BOOL,llvm::SmallVector<mlir::NamedAttribute,3u>>(mlir::MLIRContext **a1, uint64_t a2, uint64_t *a3, uint64_t *a4, uint64_t a5, uint64_t a6, char *a7, uint64_t a8)
{
  v24[38] = *MEMORY[0x263EF8340];
  uint64_t v19 = a2;
  uint64_t Context = (uint64_t *)mlir::Attribute::getContext((mlir::Attribute *)&v19);
  uint64_t v17 = mlir::RegisteredOperationName::lookup((int8x16_t *)"tensor.pad", (const unsigned __int8 *)0xA, Context);
  if (v18)
  {
    mlir::OperationState::OperationState(v24, a2, v17);
    mlir::tensor::PadOp::build(a1, (mlir::OperationState *)v24, *a3, *a4, *(uint64_t **)a5, *(unsigned int *)(a5 + 8), *(uint64_t **)a6, *(unsigned int *)(a6 + 8), *a7, *(void **)a8, *(unsigned int *)(a8 + 8));
  }
  __int16 v23 = 1283;
  void v22[2] = (uint64_t)"tensor.pad";
  void v22[3] = 10;
        "he dialect. See also https://mlir.llvm.org/getting_started/Faq/#registered-loaded-dependent-whats-up-with-dialects-management";
  __int16 v21 = 259;
  llvm::operator+(v22, (uint64_t *)&v20, (uint64_t)v24);
  llvm::report_fatal_error((llvm::Twine *)v24, 1);
}

uint64_t llvm::function_ref<void ()(mlir::Diagnostic &)>::callback_fn<mlir::LogicalResult mlir::RewriterBase::notifyMatchFailure<mlir::tensor::PadOp &>(mlir::tensor::PadOp &,llvm::Twine const&)::{lambda(mlir::Diagnostic &)#1}>(void ****a1, uint64_t a2)
{
  return mlir::Diagnostic::operator<<(a2, *a1);
}

void anonymous namespace'::FoldStaticPadding::~FoldStaticPadding(_anonymous_namespace_::FoldStaticPadding *this)
{
  unint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  unint64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }
}

{
  char *v2;
  char *v3;
  uint64_t vars8;

  unint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  unint64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t anonymous namespace'::FoldStaticPadding::matchAndRewrite(uint64_t a1, uint64_t a2, uint64_t a3)
{
  v135[6] = *MEMORY[0x263EF8340];
  uint64_t v116 = *(void *)(*(void *)(a2 + 72) + 24);
  uint64_t v117 = a2;
  if (*(_UNKNOWN **)(*(void *)(*(void *)(v116 + 8) & 0xFFFFFFFFFFFFFFF8) + 136) != &mlir::detail::TypeIDResolver<mlir::RankedTensorType,void>::id) {
    return 0;
  }
  __s1 = (void *)(*(void *)(v116 + 8) & 0xFFFFFFFFFFFFFFF8);
  uint64_t Value = (void *)mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&__s1);
  uint64_t v108 = v7;
  uint64_t v8 = *(_DWORD *)(a2 + 36) ? a2 - 16 : 0;
  unint64_t v115 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v8, 0) + 8) & 0xFFFFFFFFFFFFFFF8;
  if (!v115) {
    return 0;
  }
  uint64_t v104 = a3;
  uint64_t __src = (unint64_t *)mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v115);
  uint64_t v106 = v9;
  unint64_t v133 = v135;
  uint64_t v134 = 0x600000000;
  unint64_t v10 = *(unsigned int *)(a2 + 44);
  uint64_t v11 = a2 + 64;
  uint64_t v12 = (v10 >> 23) & 1;
  if (HIBYTE(*(_DWORD *)(a2 + 44))) {
    uint64_t v13 = a2 + 64 + 16 * v12;
  }
  else {
    uint64_t v13 = 0;
  }
  int v14 = *(_DWORD *)(v13 + 28);
  if ((v10 & 0x800000) != 0)
  {
    uint64_t v15 = *(void *)(a2 + 72);
    unint64_t v16 = "gInfo29GenerateAndSerializeDebugInfoERK15ZinIrParametersP31ZinComputeProgramMutableSectionRKNSt3__112basic_stringIcNS5_11char_traitsIcEENS5_9allocatorIcEEEEP21ZinIrControlFlowGraphRK13ZinIrNameMapsRK15ZinIdentStringsE3$_0";
    uint64_t v107 = a2 + 64;
    if (v14)
    {
LABEL_12:
      uint64_t v17 = *(unsigned int *)(v13 + 24);
      uint64_t v18 = (v14 + v17) - v17;
      uint64_t v19 = (void **)(v15 + 32 * v17 + 24);
      while (1)
      {
        __int16 v20 = *v19;
        LODWORD(v131) = 1;
        long long v130 = 0;
        BYTE4(v131) = 0;
        uint64_t v124 = &v130;
        int v127 = v20;
        uint64_t DefiningOp = mlir::Value::getDefiningOp((mlir::Value *)&v127);
        if (!DefiningOp) {
          goto LABEL_37;
        }
        uint64_t v22 = DefiningOp;
        if (!mlir::OperationName::hasTrait<mlir::OpTrait::ConstantLike>((void *)(DefiningOp + 48))) {
          goto LABEL_37;
        }
        __s1 = v120;
        uint64_t v119 = 0x100000000;
        mlir::Operation::fold(v22, 0, 0, (uint64_t)&__s1);
        uint64_t v23 = *(void *)__s1;
        if (__s1 != v120) {
          free(__s1);
        }
        if ((v23 & 0xFFFFFFFFFFFFFFF8) != 0
          && ((uint64_t v24 = *(void **)(*(void *)(*(void *)(v22 - 8) & 0xFFFFFFFFFFFFFFF8) + 136),
               v24 != &mlir::detail::TypeIDResolver<mlir::IntegerType,void>::id)
            ? (BOOL v25 = v24 == &mlir::detail::TypeIDResolver<mlir::IndexType,void>::id)
            : (BOOL v25 = 1),
              !v25 ? (BOOL v26 = v24 == &mlir::detail::TypeIDResolver<mlir::VectorType,void>::id) : (BOOL v26 = 1),
              !v26 ? (BOOL v27 = v24 == &mlir::detail::TypeIDResolver<mlir::RankedTensorType,void>::id) : (BOOL v27 = 1),
              v27
           && (mlir::detail::constant_int_value_binder::match((uint64_t *)&v124, v23 & 0xFFFFFFFFFFFFFFF8) & 1) != 0))
        {
          if (BYTE4(v131))
          {
            if (v131 >= 0x41) {
              BOOL v28 = (uint64_t *)v130;
            }
            else {
              BOOL v28 = (uint64_t *)&v130;
            }
            uint64_t v29 = *v28;
            uint64_t v30 = v134;
            if (v134 < (unint64_t)HIDWORD(v134)) {
              goto LABEL_38;
            }
LABEL_36:
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v133, v135, v30 + 1, 8);
            uint64_t v30 = v134;
            goto LABEL_38;
          }
          if (v131 > 0x40)
          {
            uint64_t v29 = *(void *)v130;
            uint64_t v30 = v134;
            if (v134 >= (unint64_t)HIDWORD(v134)) {
              goto LABEL_36;
            }
          }
          else
          {
            uint64_t v29 = (uint64_t)((void)v130 << -(char)v131) >> -(char)v131;
            uint64_t v30 = v134;
            if (v134 >= (unint64_t)HIDWORD(v134)) {
              goto LABEL_36;
            }
          }
        }
        else
        {
LABEL_37:
          uint64_t v30 = v134;
          uint64_t v29 = 0x8000000000000000;
          if (v134 >= (unint64_t)HIDWORD(v134)) {
            goto LABEL_36;
          }
        }
LABEL_38:
        v133[v30] = v29;
        LODWORD(v134) = v134 + 1;
        if (v131 >= 0x41 && v130) {
          MEMORY[0x21667D390](v130, 0x1000C8000313F17);
        }
        v19 += 4;
        if (!--v18)
        {
          unint64_t v10 = *(unsigned int *)(a2 + 44);
          uint64_t v12 = (v10 >> 23) & 1;
          int v31 = v10 & 0x800000;
          uint64_t v11 = v107;
          unint64_t v16 = "ZN12ANEDebugInfo29GenerateAndSerializeDebugInfoERK15ZinIrParametersP31ZinComputeProgramMutableSectionRKN"
                "St3__112basic_stringIcNS5_11char_traitsIcEENS5_9allocatorIcEEEEP21ZinIrControlFlowGraphRK13ZinIrNameMaps"
                "RK15ZinIdentStringsE3$_0"
              + 11;
          goto LABEL_49;
        }
      }
    }
  }
  else
  {
    uint64_t v15 = 0;
    unint64_t v16 = "gInfo29GenerateAndSerializeDebugInfoERK15ZinIrParametersP31ZinComputeProgramMutableSectionRKNSt3__112basic_stringIcNS5_11char_traitsIcEENS5_9allocatorIcEEEEP21ZinIrControlFlowGraphRK13ZinIrNameMapsRK15ZinIdentStringsE3$_0";
    uint64_t v107 = a2 + 64;
    if (v14) {
      goto LABEL_12;
    }
  }
  int v31 = v10 & 0x800000;
LABEL_49:
  long long v130 = v132;
  uint64_t v131 = 0x600000000;
  if (BYTE3(v10)) {
    uint64_t v32 = (_DWORD *)(v11 + 16 * v12);
  }
  else {
    uint64_t v32 = 0;
  }
  int v33 = v32[8];
  if (v31)
  {
    uint64_t v34 = *(void *)(a2 + 72);
    if (!v33) {
      goto LABEL_89;
    }
    goto LABEL_54;
  }
  uint64_t v34 = 0;
  if (v33)
  {
LABEL_54:
    uint64_t v35 = (v32[7] + v32[6]);
    uint64_t v36 = (v33 + v35) - v35;
    uint64_t v37 = (void **)(v34 + 32 * v35 + 24);
    uint64_t v38 = *((void *)v16 + 320);
    while (1)
    {
      unint64_t v39 = (void **)*v37;
      LODWORD(v128) = 1;
      int v127 = 0;
      BYTE4(v128) = 0;
      uint64_t v121 = &v127;
      uint64_t v124 = v39;
      uint64_t v40 = mlir::Value::getDefiningOp((mlir::Value *)&v124);
      if (!v40) {
        goto LABEL_79;
      }
      uint64_t v41 = v40;
      if (!mlir::OperationName::hasTrait<mlir::OpTrait::ConstantLike>((void *)(v40 + 48))) {
        goto LABEL_79;
      }
      __s1 = v120;
      uint64_t v119 = v38;
      mlir::Operation::fold(v41, 0, 0, (uint64_t)&__s1);
      uint64_t v42 = *(void *)__s1;
      if (__s1 != v120) {
        free(__s1);
      }
      if ((v42 & 0xFFFFFFFFFFFFFFF8) != 0
        && ((char v43 = *(void **)(*(void *)(*(void *)(v41 - 8) & 0xFFFFFFFFFFFFFFF8) + 136),
             v43 != &mlir::detail::TypeIDResolver<mlir::IntegerType,void>::id)
          ? (BOOL v44 = v43 == &mlir::detail::TypeIDResolver<mlir::IndexType,void>::id)
          : (BOOL v44 = 1),
            !v44 ? (BOOL v45 = v43 == &mlir::detail::TypeIDResolver<mlir::VectorType,void>::id) : (BOOL v45 = 1),
            !v45 ? (BOOL v46 = v43 == &mlir::detail::TypeIDResolver<mlir::RankedTensorType,void>::id) : (BOOL v46 = 1),
            v46
         && (mlir::detail::constant_int_value_binder::match((uint64_t *)&v121, v42 & 0xFFFFFFFFFFFFFFF8) & 1) != 0))
      {
        if (BYTE4(v128))
        {
          if (v128 >= 0x41) {
            uint64_t v47 = (uint64_t *)v127;
          }
          else {
            uint64_t v47 = (uint64_t *)&v127;
          }
          uint64_t v48 = *v47;
          uint64_t v49 = v131;
          if (v131 < (unint64_t)HIDWORD(v131)) {
            goto LABEL_80;
          }
LABEL_78:
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v130, v132, v49 + 1, 8);
          uint64_t v49 = v131;
          goto LABEL_80;
        }
        if (v128 > 0x40)
        {
          uint64_t v48 = *(void *)v127;
          uint64_t v49 = v131;
          if (v131 >= (unint64_t)HIDWORD(v131)) {
            goto LABEL_78;
          }
        }
        else
        {
          uint64_t v48 = (uint64_t)((void)v127 << -(char)v128) >> -(char)v128;
          uint64_t v49 = v131;
          if (v131 >= (unint64_t)HIDWORD(v131)) {
            goto LABEL_78;
          }
        }
      }
      else
      {
LABEL_79:
        uint64_t v49 = v131;
        uint64_t v48 = 0x8000000000000000;
        if (v131 >= (unint64_t)HIDWORD(v131)) {
          goto LABEL_78;
        }
      }
LABEL_80:
      *((void *)v130 + v49) = v48;
      LODWORD(v131) = v131 + 1;
      if (v128 >= 0x41 && v127) {
        MEMORY[0x21667D390](v127, 0x1000C8000313F17);
      }
      v37 += 4;
      if (!--v36)
      {
        unint64_t v10 = *(unsigned int *)(a2 + 44);
        uint64_t v12 = (v10 >> 23) & 1;
        uint64_t v11 = v107;
        break;
      }
    }
  }
LABEL_89:
  uint64_t v50 = v11 + 16 * v12;
  if (!BYTE3(v10)) {
    uint64_t v50 = 0;
  }
  __s1 = *(void **)(v50 + 16);
  BOOL v52 = (const void *)mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)&__s1);
  uint64_t v53 = v51;
  int v127 = v129;
  uint64_t v128 = 0x600000000;
  size_t v54 = 8 * v51;
  if ((unint64_t)(8 * v51) < 0x31)
  {
    unsigned int v55 = 0;
    if (!v51) {
      goto LABEL_96;
    }
    goto LABEL_95;
  }
  llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v127, v129, (8 * v51) >> 3, 8);
  unsigned int v55 = v128;
  if (v53)
  {
LABEL_95:
    memcpy((char *)v127 + 8 * v55, v52, v54);
    unsigned int v55 = v128;
  }
LABEL_96:
  LODWORD(v128) = v55 + (v54 >> 3);
  if (HIBYTE(*(_DWORD *)(a2 + 44))) {
    uint64_t v56 = v11 + 16 * (((unint64_t)*(unsigned int *)(a2 + 44) >> 23) & 1);
  }
  else {
    uint64_t v56 = 0;
  }
  __s1 = *(void **)(v56 + 8);
  unsigned int v58 = (const void *)mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)&__s1);
  uint64_t v59 = v57;
  uint64_t v124 = (void **)v126;
  uint64_t v125 = 0x600000000;
  size_t v60 = 8 * v57;
  if ((unint64_t)(8 * v57) >= 0x31)
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v124, v126, (8 * v57) >> 3, 8);
    int v61 = v125;
    if (!v59) {
      goto LABEL_104;
    }
    goto LABEL_103;
  }
  int v61 = 0;
  if (v57)
  {
LABEL_103:
    memcpy(&v124[v61], v58, v60);
    int v61 = v125;
  }
LABEL_104:
  uint64_t v62 = v61 + (v60 >> 3);
  LODWORD(v125) = v62;
  uint64_t v63 = v108;
  if (v108 != v106 || v108 != v128 || v108 != v62) {
    goto LABEL_145;
  }
  uint64_t v64 = v127;
  uint64_t v65 = v124;
  if (v108)
  {
    int v66 = 0;
    int v67 = 0;
    uint64_t v68 = v133;
    uint64_t v69 = v130;
    uint64_t v70 = v124;
    uint64_t v71 = v127;
    for (uint64_t i = v108; i; --i)
    {
      if (*v71 == 0x8000000000000000)
      {
        uint64_t v73 = v68[v66++];
        *uint64_t v71 = v73;
        if (*v70 == (void *)0x8000000000000000) {
          goto LABEL_114;
        }
      }
      else if (*v70 == (void *)0x8000000000000000)
      {
LABEL_114:
        uint64_t v74 = (void *)v69[v67++];
        llvm::raw_ostream *v70 = v74;
      }
      ++v71;
      ++v70;
    }
  }
  v114[0] = (uint64_t)v64;
  v114[1] = v108;
  v113[0] = (uint64_t)v65;
  v113[1] = v108;
  uint64_t v121 = (void **)v123;
  uint64_t v122 = 0x600000000;
  if (v108)
  {
    unsigned int v75 = 0;
    unsigned int v76 = __src;
    uint64_t v77 = v108;
    do
    {
      unint64_t v79 = *v76++;
      unint64_t v78 = v79;
      if (v79 == 0x8000000000000000)
      {
        unint64_t v78 = 0x8000000000000000;
        if (*v64 != 0x8000000000000000 && *v65 != (void *)0x8000000000000000)
        {
          if (*Value == 0x8000000000000000) {
            unint64_t v78 = 0x8000000000000000;
          }
          else {
            unint64_t v78 = (unint64_t)*v65 + *v64 + *Value;
          }
        }
      }
      if (v75 >= HIDWORD(v122))
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v121, v123, v75 + 1, 8);
        uint64_t v63 = v108;
        unsigned int v75 = v122;
      }
      v121[v75] = (void *)v78;
      unsigned int v75 = v122 + 1;
      LODWORD(v122) = v122 + 1;
      ++v64;
      ++v65;
      ++Value;
      --v77;
    }
    while (v77);
  }
  __s1 = v120;
  uint64_t v119 = 0x600000000;
  size_t v80 = 8 * v63;
  if ((unint64_t)(8 * v63) >= 0x31)
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&__s1, v120, (8 * v63) >> 3, 8);
    uint64_t v81 = v107;
    unsigned int v82 = v119;
    if (!v108) {
      goto LABEL_131;
    }
    goto LABEL_130;
  }
  unsigned int v82 = 0;
  uint64_t v81 = v107;
  if (v63)
  {
LABEL_130:
    memcpy((char *)__s1 + 8 * v82, __src, v80);
    unsigned int v82 = v119;
  }
LABEL_131:
  unsigned int v83 = v82 + (v80 >> 3);
  LODWORD(v119) = v83;
  uint64_t v84 = v122;
  uint64_t v85 = v121;
  if (v83 != v122 || (uint64_t v86 = __s1, memcmp(__s1, v121, 8 * v83)))
  {
    if (v84)
    {
      uint64_t v87 = 8 * v84 - 8;
      do
      {
        uint64_t v88 = (uint64_t)*v85++;
        BOOL v89 = v88 == 0x8000000000000000;
        BOOL v90 = v88 != 0x8000000000000000 || v87 == 0;
        v87 -= 8;
      }
      while (!v90);
      unint64_t v91 = __s1;
      if (__s1 != v120) {
        goto LABEL_141;
      }
    }
    else
    {
      BOOL v89 = 1;
      unint64_t v91 = __s1;
      if (__s1 != v120) {
LABEL_141:
      }
        free(v91);
    }
    if (!v89)
    {
      unint64_t v93 = v121;
      uint64_t v94 = v122;
      __s1 = (void *)(*(void *)(a2 - 8) & 0xFFFFFFFFFFFFFFF8);
      uint64_t RHS = mlir::AffineBinaryOpExpr::getRHS((mlir::AffineBinaryOpExpr *)&__s1);
      uint64_t v112 = mlir::RankedTensorType::get((uint64_t)v93, v94, RHS, 0);
      uint64_t v96 = *(void *)(a2 + 24);
      unint64_t v97 = *(unsigned int *)(a2 + 44);
      int64_t v98 = (void *)(v81 + 16 * ((v97 >> 23) & 1));
      if (HIBYTE(*(_DWORD *)(a2 + 44))) {
        uint64_t v99 = v81 + 16 * ((v97 >> 23) & 1);
      }
      else {
        uint64_t v99 = 0;
      }
      uint64_t v100 = *(unsigned int *)(v99 + 24);
      int v101 = *(_DWORD *)(v99 + 28);
      if ((v97 & 0x800000) != 0) {
        uint64_t v102 = *(void *)(a2 + 72);
      }
      else {
        uint64_t v102 = 0;
      }
      v111[0] = v102 + 32 * v100;
      v111[1] = (v101 + v100) - v100;
      v110[0] = mlir::memref::ReinterpretCastOp::getSizes((mlir::memref::ReinterpretCastOp *)&v117);
      v110[1] = v103;
      BOOL v109 = *v98 != 0;
      mlir::getPrunedAttributeList((unsigned char *)a2, (uint64_t)&mlir::tensor::PadOp::getAttributeNames(void)::attrNames, 4, (uint64_t)&__s1);
      mlir::OpBuilder::create<mlir::tensor::PadOp,mlir::RankedTensorType &,mlir::detail::TypedValue<mlir::RankedTensorType>,llvm::ArrayRef<long long>,llvm::ArrayRef<long long>,mlir::OperandRange,mlir::OperandRange,BOOL,llvm::SmallVector<mlir::NamedAttribute,3u>>((mlir::MLIRContext **)(v104 + 8), v96, &v112, &v116, v114, v113, (uint64_t)v111, (uint64_t)v110, (char *)&v109, (uint64_t)&__s1);
    }
    goto LABEL_143;
  }
  if (v86 != v120)
  {
    free(v86);
    unint64_t v92 = v121;
    if (v121 == (void **)v123) {
      goto LABEL_145;
    }
    goto LABEL_144;
  }
LABEL_143:
  unint64_t v92 = v121;
  if (v121 != (void **)v123) {
LABEL_144:
  }
    free(v92);
LABEL_145:
  if (v124 != (void **)v126) {
    free(v124);
  }
  if (v127 != v129) {
    free(v127);
  }
  if (v130 != v132) {
    free(v130);
  }
  if (v133 != v135) {
    free(v133);
  }
  return 0;
}

ZinIrHalH13g *mlir::RewriterBase::replaceOpWithNewOp<mlir::tensor::CastOp,mlir::RankedTensorType &,mlir::tensor::PadOp &>(uint64_t a1, uint64_t a2, uint64_t *a3, void *a4)
{
  BOOL v6 = mlir::OpBuilder::create<mlir::tensor::CastOp,mlir::RankedTensorType,mlir::tensor::EmptyOp &>((mlir::OpBuilder *)(a1 + 8), *(void *)(a2 + 24), a3, a4);
  (*(void (**)(uint64_t, uint64_t, ZinIrHalH13g *))(*(void *)a1 + 32))(a1, a2, v6);
  return v6;
}

void *anonymous namespace'::InsertSliceOpConstantArgumentFolder<mlir::tensor::ParallelInsertSliceOp>::~InsertSliceOpConstantArgumentFolder(void *a1)
{
  unint64_t v2 = (void *)a1[10];
  if (v2 != a1 + 12) {
    free(v2);
  }
  unint64_t v3 = (void *)a1[4];
  if (v3 != a1 + 6) {
    free(v3);
  }
  return a1;
}

void anonymous namespace'::InsertSliceOpConstantArgumentFolder<mlir::tensor::ParallelInsertSliceOp>::~InsertSliceOpConstantArgumentFolder(void *a1)
{
  unint64_t v2 = (void *)a1[10];
  if (v2 != a1 + 12) {
    free(v2);
  }
  unint64_t v3 = (void *)a1[4];
  if (v3 != a1 + 6) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::tensor::ParallelInsertSliceOp>::rewrite(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 48))();
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::tensor::ParallelInsertSliceOp>::match(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 56))();
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::tensor::ParallelInsertSliceOp>::matchAndRewrite(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 64))();
}

uint64_t anonymous namespace'::InsertSliceOpConstantArgumentFolder<mlir::tensor::ParallelInsertSliceOp>::matchAndRewrite(uint64_t a1, uint64_t a2, uint64_t a3)
{
  v40[6] = *MEMORY[0x263EF8340];
  uint64_t v28 = a2;
  mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::tensor::InsertSliceOp>::getMixedOffsets((mlir::memref::ReinterpretCastOp *)&v28, (uint64_t)&__src);
  uint64_t v38 = v40;
  uint64_t v39 = 0x600000000;
  int v4 = v36;
  uint64_t v5 = __src;
  if (v36)
  {
    if (__src == v37)
    {
      unsigned int v6 = v36;
      if (v36 < 7
        || (llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v38, v40, v36, 8),
            unsigned int v6 = v36,
            uint64_t v5 = __src,
            v36))
      {
        memcpy(v38, v5, 8 * v6);
        uint64_t v5 = __src;
      }
      LODWORD(v39) = v4;
    }
    else
    {
      uint64_t v38 = __src;
      uint64_t v39 = v36;
      uint64_t __src = v37;
      HIDWORD(v36) = 0;
      uint64_t v5 = v37;
    }
    LODWORD(v36) = 0;
  }
  if (v5 != v37) {
    free(v5);
  }
  mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::tensor::InsertSliceOp>::getMixedSizes((mlir::memref::ReinterpretCastOp *)&v28, (uint64_t)&__dst);
  uint64_t __src = v37;
  uint64_t v36 = 0x600000000;
  int v7 = v33;
  uint64_t v8 = __dst;
  if (v33)
  {
    if (__dst == v34)
    {
      unsigned int v9 = v33;
      if (v33 < 7
        || (llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&__src, v37, v33, 8),
            unsigned int v9 = v33,
            uint64_t v8 = __dst,
            v33))
      {
        memcpy(__src, v8, 8 * v9);
        uint64_t v8 = __dst;
      }
      LODWORD(v36) = v7;
    }
    else
    {
      uint64_t __src = __dst;
      uint64_t v36 = v33;
      __dst = v34;
      HIDWORD(v33) = 0;
      uint64_t v8 = v34;
    }
    LODWORD(v33) = 0;
  }
  if (v8 != v34) {
    free(v8);
  }
  mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::tensor::InsertSliceOp>::getMixedStrides((mlir::memref::ReinterpretCastOp *)&v28, (uint64_t)&v29);
  __dst = v34;
  uint64_t v33 = 0x600000000;
  int v10 = v30;
  uint64_t v11 = v29;
  if (v30)
  {
    if (v29 == v31)
    {
      unsigned int v12 = v30;
      if (v30 < 7
        || (llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&__dst, v34, v30, 8),
            unsigned int v12 = v30,
            uint64_t v11 = v29,
            v30))
      {
        memcpy(__dst, v11, 8 * v12);
        uint64_t v11 = v29;
      }
      LODWORD(v33) = v10;
    }
    else
    {
      __dst = v29;
      uint64_t v33 = v30;
      uint64_t v29 = v31;
      HIDWORD(v30) = 0;
      uint64_t v11 = v31;
    }
    LODWORD(v30) = 0;
  }
  if (v11 != v31) {
    free(v11);
  }
  if (mlir::foldDynamicIndexList((uint64_t)&v38, 1)
    || mlir::foldDynamicIndexList((uint64_t)&__src, 1)
    || mlir::foldDynamicIndexList((uint64_t)&__dst, 0))
  {
    unint64_t v27 = *(void *)(*(void *)(*(void *)(v28 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8;
    mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v27);
    if (*(unsigned char *)(v28 + 47)) {
      uint64_t v14 = v28 + 80;
    }
    else {
      uint64_t v14 = 0;
    }
    uint64_t v29 = (void *)mlir::tensor::ExtractSliceOp::inferCanonicalRankReducedResultType(v13, (void *)(*(void *)(*(void *)(*(void *)(v28 + 72) + 32 * *(unsigned int *)(v14 + 24) + 24)+ 8) & 0xFFFFFFFFFFFFFFF8), v38, v39, (uint64_t *)__src, v36, (uint64_t *)__dst, v33);
    unint64_t v27 = *(void *)(*(void *)(v28 + 72) + 24);
    if (v29 != (void *)(*(void *)(v27 + 8) & 0xFFFFFFFFFFFFFFF8))
    {
      uint64_t v15 = (_OWORD *)(a3 + 24);
      long long v25 = *(_OWORD *)(a3 + 24);
      uint64_t ParentOp = *(mlir::Block **)(v28 + 16);
      if (ParentOp) {
        uint64_t ParentOp = (mlir::Block *)mlir::Block::getParentOp(ParentOp);
      }
      uint64_t v17 = *((void *)ParentOp + 2);
      ZinIrHalH13g::~ZinIrHalH13g(ParentOp);
      *(void *)(a3 + 24) = v17;
      *(void *)(a3 + 32) = v18;
      unint64_t v27 = (unint64_t)mlir::OpBuilder::create<mlir::tensor::CastOp,mlir::TensorType &,mlir::Value>((mlir::OpBuilder *)(a3 + 8), *(void *)(v28 + 24), (uint64_t *)&v29, (uint64_t *)&v27)- 16;
      if ((void)v25)
      {
        *uint64_t v15 = v25;
      }
      else
      {
        *(void *)uint64_t v15 = 0;
        *(void *)(a3 + 32) = 0;
      }
    }
    uint64_t v19 = v28;
    if (*(unsigned char *)(v28 + 47)) {
      uint64_t v20 = v28 + 80;
    }
    else {
      uint64_t v20 = 0;
    }
    uint64_t v26 = *(void *)(*(void *)(v28 + 72) + 32 * *(unsigned int *)(v20 + 24) + 24);
    __int16 v21 = mlir::OpBuilder::create<mlir::tensor::ParallelInsertSliceOp,mlir::Value &,mlir::detail::TypedValue<mlir::RankedTensorType>,llvm::SmallVector<mlir::OpFoldResult,6u> &,llvm::SmallVector<mlir::OpFoldResult,6u> &,llvm::SmallVector<mlir::OpFoldResult,6u> &>((mlir::MLIRContext **)(a3 + 8), *(void *)(v28 + 24), (uint64_t *)&v27, &v26, (uint64_t)&v38, (uint64_t)&__src, (uint64_t)&__dst);
    (*(void (**)(uint64_t, uint64_t, ZinIrHalH13g *))(*(void *)a3 + 32))(a3, v19, v21);
    uint64_t v22 = 1;
    uint64_t v23 = __dst;
    if (__dst != v34) {
      goto LABEL_47;
    }
  }
  else
  {
    uint64_t v22 = 0;
    uint64_t v23 = __dst;
    if (__dst != v34) {
LABEL_47:
    }
      free(v23);
  }
  if (__src != v37) {
    free(__src);
  }
  if (v38 != v40) {
    free(v38);
  }
  return v22;
}

ZinIrHalH13g *mlir::OpBuilder::create<mlir::tensor::ParallelInsertSliceOp,mlir::Value &,mlir::detail::TypedValue<mlir::RankedTensorType>,llvm::SmallVector<mlir::OpFoldResult,6u> &,llvm::SmallVector<mlir::OpFoldResult,6u> &,llvm::SmallVector<mlir::OpFoldResult,6u> &>(mlir::MLIRContext **a1, uint64_t a2, uint64_t *a3, uint64_t *a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  v25[38] = *MEMORY[0x263EF8340];
  uint64_t v20 = a2;
  uint64_t Context = (uint64_t *)mlir::Attribute::getContext((mlir::Attribute *)&v20);
  uint64_t v15 = mlir::RegisteredOperationName::lookup((int8x16_t *)"tensor.parallel_insert_slice", (const unsigned __int8 *)0x1C, Context);
  if (!v16)
  {
    __int16 v24 = 1283;
    uint64_t v23[2] = (uint64_t)"tensor.parallel_insert_slice";
    v23[3] = 28;
          " the dialect. See also https://mlir.llvm.org/getting_started/Faq/#registered-loaded-dependent-whats-up-with-di"
          "alects-management";
    __int16 v22 = 259;
    llvm::operator+(v23, (uint64_t *)&v21, (uint64_t)v25);
    llvm::report_fatal_error((llvm::Twine *)v25, 1);
  }
  mlir::OperationState::OperationState(v25, a2, v15);
  mlir::tensor::ParallelInsertSliceOp::build(a1, (uint64_t)v25, *a3, *a4, *(uint64_t **)a5, *(unsigned int *)(a5 + 8), *(uint64_t **)a6, *(unsigned int *)(a6 + 8), *(uint64_t **)a7, *(unsigned int *)(a7 + 8), 0, 0);
  uint64_t v17 = mlir::OpBuilder::create((mlir::OpBuilder *)a1, (const mlir::OperationState *)v25);
  if (*(_UNKNOWN **)(*((void *)v17 + 6) + 16) == &mlir::detail::TypeIDResolver<mlir::tensor::ParallelInsertSliceOp,void>::id) {
    uint64_t v18 = v17;
  }
  else {
    uint64_t v18 = 0;
  }
  mlir::OperationState::~OperationState((mlir::OperationState *)v25);
  return v18;
}

void *anonymous namespace'::InsertSliceOpCastFolder<mlir::tensor::ParallelInsertSliceOp>::~InsertSliceOpCastFolder(void *a1)
{
  unint64_t v2 = (void *)a1[10];
  if (v2 != a1 + 12) {
    free(v2);
  }
  unint64_t v3 = (void *)a1[4];
  if (v3 != a1 + 6) {
    free(v3);
  }
  return a1;
}

void anonymous namespace'::InsertSliceOpCastFolder<mlir::tensor::ParallelInsertSliceOp>::~InsertSliceOpCastFolder(void *a1)
{
  unint64_t v2 = (void *)a1[10];
  if (v2 != a1 + 12) {
    free(v2);
  }
  unint64_t v3 = (void *)a1[4];
  if (v3 != a1 + 6) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t anonymous namespace'::InsertSliceOpCastFolder<mlir::tensor::ParallelInsertSliceOp>::matchAndRewrite(uint64_t DefiningOp, uint64_t a2, mlir::MLIRContext **a3)
{
  void v48[4] = *MEMORY[0x263EF8340];
  uint64_t v41 = a2;
  if ((*(unsigned char *)(a2 + 46) & 0x80) != 0)
  {
    uint64_t v5 = *(unsigned int *)(a2 + 68);
    if (v5)
    {
      unsigned int v6 = (void **)(*(void *)(a2 + 72) + 24);
      do
      {
        int v7 = *v6;
        ZinIrHalH13g::~ZinIrHalH13g((ZinIrHalH13g *)DefiningOp);
        v47[0] = v7;
        uint64_t DefiningOp = mlir::Value::getDefiningOp((mlir::Value *)v47);
        if (DefiningOp)
        {
          uint64_t DefiningOp = mlir::arith::ConstantIndexOp::classof(DefiningOp, v8);
          if (DefiningOp) {
            return 0;
          }
        }
        v6 += 4;
      }
      while (--v5);
    }
  }
  v47[0] = *(void **)(*(void *)(a2 + 72) + 24);
  uint64_t v9 = mlir::Value::getDefiningOp((mlir::Value *)v47);
  if (v9
    && (uint64_t v10 = v9,
        *(_UNKNOWN **)(*(void *)(v9 + 48) + 16) == &mlir::detail::TypeIDResolver<mlir::tensor::CastOp,void>::id)
    && mlir::tensor::preservesStaticInformation(*(void *)(v9 - 8) & 0xFFFFFFFFFFFFFFF8, *(void *)(*(void *)(*(void *)(v9 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8))
  {
    int v11 = 0;
    unint64_t v12 = *(void *)(*(void *)(v10 + 72) + 24) & 0xFFFFFFFFFFFFFF00;
    uint64_t v13 = *(void *)(*(void *)(v10 + 72) + 24);
  }
  else
  {
    uint64_t v13 = 0;
    unint64_t v12 = 0;
    int v11 = 1;
  }
  uint64_t v14 = v12 | v13;
  if (*(unsigned char *)(a2 + 47)) {
    uint64_t v15 = a2 + 80;
  }
  else {
    uint64_t v15 = 0;
  }
  v47[0] = *(void **)(*(void *)(a2 + 72) + 32 * *(unsigned int *)(v15 + 24) + 24);
  uint64_t v16 = mlir::Value::getDefiningOp((mlir::Value *)v47);
  if (v16
    && (uint64_t v17 = v16,
        *(_UNKNOWN **)(*(void *)(v16 + 48) + 16) == &mlir::detail::TypeIDResolver<mlir::tensor::CastOp,void>::id)
    && (mlir::tensor::preservesStaticInformation(*(void *)(v16 - 8) & 0xFFFFFFFFFFFFFFF8, *(void *)(*(void *)(*(void *)(v16 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8) & 1) != 0)
  {
    uint64_t v18 = *(void *)(*(void *)(v17 + 72) + 24);
    if (v11) {
      uint64_t v14 = *(void *)(*(void *)(a2 + 72) + 24);
    }
    uint64_t v40 = v14;
  }
  else
  {
    if (v11) {
      return 0;
    }
    uint64_t v40 = v14;
    if (*(unsigned char *)(a2 + 47)) {
      uint64_t v20 = a2 + 80;
    }
    else {
      uint64_t v20 = 0;
    }
    uint64_t v18 = *(void *)(*(void *)(a2 + 72) + 32 * *(unsigned int *)(v20 + 24) + 24);
  }
  uint64_t result = 0;
  uint64_t v39 = v18;
  if (*(_UNKNOWN **)(*(void *)(*(void *)(v14 + 8) & 0xFFFFFFFFFFFFFFF8) + 136) == &mlir::detail::TypeIDResolver<mlir::RankedTensorType,void>::id) {
    __int16 v21 = (void *)(*(void *)(v14 + 8) & 0xFFFFFFFFFFFFFFF8);
  }
  else {
    __int16 v21 = 0;
  }
  unint64_t v22 = *(void *)(v18 + 8) & 0xFFFFFFFFFFFFFFF8;
  if (*(_UNKNOWN **)(*(void *)v22 + 136) == &mlir::detail::TypeIDResolver<mlir::RankedTensorType,void>::id) {
    uint64_t v23 = (void *)v22;
  }
  else {
    uint64_t v23 = 0;
  }
  if (v21 && v23)
  {
    uint64_t v24 = a2 + 64;
    v47[0] = *(void **)(a2 + 64 + 16 * (((unint64_t)*(unsigned int *)(a2 + 44) >> 23) & 1));
    mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)v47);
    if (HIBYTE(*(_DWORD *)(a2 + 44))) {
      uint64_t v25 = v24 + 16 * (((unint64_t)*(unsigned int *)(a2 + 44) >> 23) & 1);
    }
    else {
      uint64_t v25 = 0;
    }
    v47[0] = *(void **)(v25 + 8);
    uint64_t v26 = mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)v47);
    uint64_t v28 = v27;
    if (HIBYTE(*(_DWORD *)(a2 + 44))) {
      uint64_t v29 = v24 + 16 * (((unint64_t)*(unsigned int *)(a2 + 44) >> 23) & 1);
    }
    else {
      uint64_t v29 = 0;
    }
    v47[0] = *(void **)(v29 + 16);
    mlir::detail::DenseArrayAttrImpl<long long>::operator llvm::ArrayRef<long long>((uint64_t)v47);
    v47[0] = v23;
    uint64_t RHS = mlir::AffineBinaryOpExpr::getRHS((mlir::AffineBinaryOpExpr *)v47);
    int v31 = (void *)mlir::RankedTensorType::get(v26, v28, RHS, 0);
    uint64_t v32 = v31;
    if (v31) {
      uint64_t v33 = mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*v31 + 8);
    }
    else {
      uint64_t v33 = 0;
    }
    mlir::detail::InterfaceMap::lookup<mlir::ShapedType>(*v21 + 8);
    if (mlir::isRankReducedType(v32, v33, v21))
    {
      return 0;
    }
    else
    {
      uint64_t v34 = *(void *)(a2 + 24);
      mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::tensor::InsertSliceOp>::getMixedOffsets((mlir::memref::ReinterpretCastOp *)&v41, (uint64_t)v47);
      mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::tensor::InsertSliceOp>::getMixedSizes((mlir::memref::ReinterpretCastOp *)&v41, (uint64_t)v45);
      mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::tensor::InsertSliceOp>::getMixedStrides((mlir::memref::ReinterpretCastOp *)&v41, (uint64_t)v43);
      uint64_t v35 = mlir::OpBuilder::create<mlir::tensor::ParallelInsertSliceOp,mlir::Value &,mlir::detail::TypedValue<mlir::RankedTensorType>,llvm::SmallVector<mlir::OpFoldResult,6u> &,llvm::SmallVector<mlir::OpFoldResult,6u> &,llvm::SmallVector<mlir::OpFoldResult,6u> &>(a3 + 1, v34, &v40, &v39, (uint64_t)v47, (uint64_t)v45, (uint64_t)v43);
      if (v43[0] != &v44) {
        free(v43[0]);
      }
      if (v45[0] != &v46) {
        free(v45[0]);
      }
      if (v47[0] != v48) {
        free(v47[0]);
      }
      uint64_t v36 = v41;
      unint64_t v37 = *((unsigned int *)v35 + 9);
      if (v37) {
        uint64_t v38 = (uint64_t)v35 - 16;
      }
      else {
        uint64_t v38 = 0;
      }
      mlir::ValueRange::ValueRange(v42, v38, v37);
      (*((void (**)(mlir::MLIRContext **, uint64_t, unint64_t, unint64_t))*a3 + 3))(a3, v36, v42[0], v42[1]);
      return 1;
    }
  }
  return result;
}

void *anonymous namespace'::InsertSliceOpSourceCastInserter<mlir::tensor::ParallelInsertSliceOp>::~InsertSliceOpSourceCastInserter(void *a1)
{
  unint64_t v2 = (void *)a1[10];
  if (v2 != a1 + 12) {
    free(v2);
  }
  unint64_t v3 = (void *)a1[4];
  if (v3 != a1 + 6) {
    free(v3);
  }
  return a1;
}

void anonymous namespace'::InsertSliceOpSourceCastInserter<mlir::tensor::ParallelInsertSliceOp>::~InsertSliceOpSourceCastInserter(void *a1)
{
  unint64_t v2 = (void *)a1[10];
  if (v2 != a1 + 12) {
    free(v2);
  }
  unint64_t v3 = (void *)a1[4];
  if (v3 != a1 + 6) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t anonymous namespace'::InsertSliceOpSourceCastInserter<mlir::tensor::ParallelInsertSliceOp>::matchAndRewrite(uint64_t a1, uint64_t a2, uint64_t a3)
{
  v52[6] = *MEMORY[0x263EF8340];
  unint64_t v40 = *(void *)(*(void *)(*(void *)(a2 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8;
  uint64_t v41 = a2;
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v40);
  uint64_t v6 = v5;
  if (*(unsigned char *)(a2 + 47)) {
    uint64_t v7 = a2 + 80;
  }
  else {
    uint64_t v7 = 0;
  }
  uint64_t v50 = (void *)(*(void *)(*(void *)(*(void *)(a2 + 72) + 32 * *(unsigned int *)(v7 + 24) + 24) + 8) & 0xFFFFFFFFFFFFFFF8);
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v50);
  if (v6 != v8) {
    return 0;
  }
  uint64_t Value = (unsigned char *)mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v40);
  uint64_t v10 = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v40);
  unint64_t v12 = (unsigned char *)(v10 + 8 * v11);
  uint64_t v50 = v52;
  uint64_t v51 = 0x600000000;
  uint64_t v13 = v12 - Value;
  if ((unint64_t)(v12 - Value) >= 0x31)
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v50, v52, v13 >> 3, 8);
    int v14 = v51;
    if (v12 == Value) {
      goto LABEL_11;
    }
    goto LABEL_10;
  }
  int v14 = 0;
  if (v12 != Value)
  {
LABEL_10:
    memcpy(&v50[v14], Value, v12 - Value);
    int v14 = v51;
  }
LABEL_11:
  LODWORD(v51) = v14 + ((unint64_t)v13 >> 3);
  mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v40);
  if (v16 >= 1)
  {
    for (uint64_t i = 0; i < v18; ++i)
    {
      mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::tensor::InsertSliceOp>::getMixedSizes((mlir::memref::ReinterpretCastOp *)&v41, (uint64_t)v48);
      unint64_t ConstantIntValue = mlir::getConstantIntValue(*((void *)v48[0] + i));
      char v21 = v20;
      if (v48[0] != v49) {
        free(v48[0]);
      }
      if (v21)
      {
        if ((ConstantIntValue & 0x8000000000000000) != 0) {
          goto LABEL_36;
        }
        v50[i] = ConstantIntValue;
      }
      mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v40);
    }
  }
  uint64_t v22 = (uint64_t)v50;
  uint64_t v23 = v51;
  uint64_t RHS = mlir::AffineBinaryOpExpr::getRHS((mlir::AffineBinaryOpExpr *)&v40);
  uint64_t v25 = mlir::RankedTensorType::get(v22, v23, RHS, 0);
  uint64_t v39 = v25;
  if (v40 != v25)
  {
    if (mlir::tensor::preservesStaticInformation(v40, v25))
    {
      mlir::ValueRange::ValueRange(v47, (uint64_t)&v40, 1uLL);
      mlir::ValueRange::ValueRange(v46, (uint64_t)&v39, 1uLL);
      if (mlir::tensor::CastOp::areCastCompatible(v47[0], v47[1], v46[0], v46[1]))
      {
        uint64_t v26 = (_OWORD *)(a3 + 24);
        long long v36 = *(_OWORD *)(a3 + 24);
        uint64_t ParentOp = *(mlir::Block **)(v41 + 16);
        if (ParentOp) {
          uint64_t ParentOp = (mlir::Block *)mlir::Block::getParentOp(ParentOp);
        }
        uint64_t v28 = *((void *)ParentOp + 2);
        ZinIrHalH13g::~ZinIrHalH13g(ParentOp);
        *(void *)(a3 + 24) = v28;
        *(void *)(a3 + 32) = v29;
        uint64_t v30 = *(void *)(v41 + 24);
        v48[0] = *(void **)(*(void *)(v41 + 72) + 24);
        uint64_t v38 = (uint64_t)mlir::OpBuilder::create<mlir::tensor::CastOp,mlir::TensorType &,mlir::Value>((mlir::OpBuilder *)(a3 + 8), v30, &v39, (uint64_t *)v48)- 16;
        uint64_t v31 = v41;
        if (*(unsigned char *)(v41 + 47)) {
          uint64_t v32 = v41 + 80;
        }
        else {
          uint64_t v32 = 0;
        }
        uint64_t v37 = *(void *)(*(void *)(v41 + 72) + 32 * *(unsigned int *)(v32 + 24) + 24);
        mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::tensor::InsertSliceOp>::getMixedOffsets((mlir::memref::ReinterpretCastOp *)&v41, (uint64_t)v48);
        mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::tensor::InsertSliceOp>::getMixedSizes((mlir::memref::ReinterpretCastOp *)&v41, (uint64_t)v44);
        mlir::detail::OffsetSizeAndStrideOpInterfaceTrait<mlir::tensor::InsertSliceOp>::getMixedStrides((mlir::memref::ReinterpretCastOp *)&v41, (uint64_t)v42);
        uint64_t v33 = mlir::OpBuilder::create<mlir::tensor::ParallelInsertSliceOp,mlir::Value &,mlir::detail::TypedValue<mlir::RankedTensorType>,llvm::SmallVector<mlir::OpFoldResult,6u> &,llvm::SmallVector<mlir::OpFoldResult,6u> &,llvm::SmallVector<mlir::OpFoldResult,6u> &>((mlir::MLIRContext **)(a3 + 8), *(void *)(v31 + 24), &v38, &v37, (uint64_t)v48, (uint64_t)v44, (uint64_t)v42);
        (*(void (**)(uint64_t, uint64_t, ZinIrHalH13g *))(*(void *)a3 + 32))(a3, v31, v33);
        if (v42[0] != &v43) {
          free(v42[0]);
        }
        if (v44[0] != &v45) {
          free(v44[0]);
        }
        if (v48[0] != v49) {
          free(v48[0]);
        }
        if ((void)v36)
        {
          *uint64_t v26 = v36;
          uint64_t v15 = 1;
          uint64_t v34 = v50;
          if (v50 == v52) {
            return v15;
          }
        }
        else
        {
          *(void *)uint64_t v26 = 0;
          *(void *)(a3 + 32) = 0;
          uint64_t v15 = 1;
          uint64_t v34 = v50;
          if (v50 == v52) {
            return v15;
          }
        }
        goto LABEL_37;
      }
    }
  }
LABEL_36:
  uint64_t v15 = 0;
  uint64_t v34 = v50;
  if (v50 != v52) {
LABEL_37:
  }
    free(v34);
  return v15;
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::tensor::PackOp>::rewrite(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 48))();
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::tensor::PackOp>::match(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 56))();
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::tensor::PackOp>::matchAndRewrite(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 64))();
}

uint64_t llvm::all_of<llvm::detail::zippy<llvm::detail::zip_shortest,llvm::ArrayRef<long long>,llvm::SmallVector<mlir::OpFoldResult,6u> &>,mlir::LogicalResult commonVerifierPackAndUnPackOp<mlir::tensor::PackOp>(mlir::tensor::PackOp)::{lambda(std::tuple<long long,mlir::OpFoldResult>)#1}>(uint64_t a1)
{
  uint64_t v1 = *(void *)(a1 + 8);
  uint64_t v2 = *(void *)(a1 + 16);
  uint64_t v3 = *(unsigned int *)(v2 + 8);
  if (v1) {
    BOOL v4 = v3 == 0;
  }
  else {
    BOOL v4 = 1;
  }
  if (!v4)
  {
    uint64_t v6 = *(uint64_t **)a1;
    uint64_t v7 = *(uint64_t **)v2;
    uint64_t v8 = 8 * v3 - 8;
    uint64_t v9 = 8 * v1 - 8;
    while (1)
    {
      uint64_t v10 = *v6;
      unint64_t ConstantIntValue = mlir::getConstantIntValue(*v7);
      if (v12)
      {
        if (v10 != 0x8000000000000000 && v10 != ConstantIntValue) {
          return 0;
        }
      }
      else if (v10 != 0x8000000000000000)
      {
        return 0;
      }
      uint64_t result = 1;
      if (v9)
      {
        ++v6;
        ++v7;
        uint64_t v14 = v8;
        v8 -= 8;
        v9 -= 8;
        if (v14) {
          continue;
        }
      }
      return result;
    }
  }
  return 1;
}

void mlir::RewritePatternSet::addImpl<FoldTensorCastProducerOp,mlir::MLIRContext *>()
{
}

void *mlir::OpInterfaceRewritePattern<mlir::DestinationStyleOpInterface>::OpInterfaceRewritePattern(void *a1, uint64_t a2, __int16 a3)
{
  uint64_t v3 = a2;
  uint64_t v5 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
  {
    __int16 v15 = a3;
    uint64_t v5 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
    a3 = v15;
    uint64_t v3 = a2;
    if (v7)
    {
      uint64_t v17 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::DestinationStyleOpInterface]";
      unint64_t v18 = 83;
      unint64_t v8 = llvm::StringRef::find((uint64_t *)&v17, "DesiredTypeName = ", 0x12uLL, 0);
      if (v18 >= v8) {
        unint64_t v9 = v8;
      }
      else {
        unint64_t v9 = v18;
      }
      uint64_t v10 = &v17[v9];
      unint64_t v11 = v18 - v9;
      if (v18 - v9 >= 0x12) {
        uint64_t v12 = 18;
      }
      else {
        uint64_t v12 = v18 - v9;
      }
      unint64_t v13 = v11 - v12;
      if (v13 >= v13 - 1) {
        uint64_t v14 = v13 - 1;
      }
      else {
        uint64_t v14 = v13;
      }
      mlir::detail::TypeIDResolver<mlir::DestinationStyleOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v10[v12], v14);
      uint64_t v5 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
      a3 = v15;
      uint64_t v3 = a2;
    }
  }
  mlir::Pattern::Pattern((uint64_t)(a1 + 1), v5[134], a3, v3, 0, 0);
  *a1 = &unk_26C37D788;
  return a1;
}

void FoldTensorCastProducerOp::~FoldTensorCastProducerOp(FoldTensorCastProducerOp *this)
{
  uint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  uint64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }
}

{
  char *v2;
  char *v3;
  uint64_t vars8;

  uint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  uint64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::DestinationStyleOpInterface>::rewrite(uint64_t a1, uint64_t a2, uint64_t a3)
{
  if (!a2) {
    goto LABEL_11;
  }
  uint64_t v6 = *(void *)(a2 + 48);
  int v7 = *(void **)(v6 + 16);
  BOOL v8 = v7 == &mlir::detail::TypeIDResolver<void,void>::id;
  if (v7 == &mlir::detail::TypeIDResolver<void,void>::id) {
    uint64_t v9 = 0;
  }
  else {
    uint64_t v9 = *(void *)(a2 + 48);
  }
  if (v8)
  {
    uint64_t v15 = *(void *)(v6 + 8);
    uint64_t Values = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)&v15);
    if (Values)
    {
      uint64_t v13 = v6;
      goto LABEL_10;
    }
LABEL_11:
    uint64_t v11 = 0;
    return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t, uint64_t))(*(void *)a1 + 48))(a1, a2, v11, a3);
  }
  unint64_t v10 = v9 | v6 & 0xFFFFFFFFFFFFFF00;
  uint64_t v11 = mlir::detail::InterfaceMap::lookup<mlir::DestinationStyleOpInterface>(v10 + 32);
  if (!v11)
  {
    uint64_t Values = *(void *)(v10 + 24);
    uint64_t v13 = *(void *)(a2 + 48);
LABEL_10:
    uint64_t v11 = mlir::Dialect::getRegisteredInterfaceForOp<mlir::DestinationStyleOpInterface>(Values, v13);
  }
  return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t, uint64_t))(*(void *)a1 + 48))(a1, a2, v11, a3);
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::DestinationStyleOpInterface>::match(uint64_t a1, uint64_t a2)
{
  if (!a2) {
    goto LABEL_11;
  }
  uint64_t v4 = *(void *)(a2 + 48);
  uint64_t v5 = *(void **)(v4 + 16);
  BOOL v6 = v5 == &mlir::detail::TypeIDResolver<void,void>::id;
  if (v5 == &mlir::detail::TypeIDResolver<void,void>::id) {
    uint64_t v7 = 0;
  }
  else {
    uint64_t v7 = *(void *)(a2 + 48);
  }
  if (v6)
  {
    uint64_t v13 = *(void *)(v4 + 8);
    uint64_t Values = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)&v13);
    if (Values)
    {
      uint64_t v11 = v4;
      goto LABEL_10;
    }
LABEL_11:
    uint64_t v9 = 0;
    return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t))(*(void *)a1 + 56))(a1, a2, v9);
  }
  unint64_t v8 = v7 | v4 & 0xFFFFFFFFFFFFFF00;
  uint64_t v9 = mlir::detail::InterfaceMap::lookup<mlir::DestinationStyleOpInterface>(v8 + 32);
  if (!v9)
  {
    uint64_t Values = *(void *)(v8 + 24);
    uint64_t v11 = *(void *)(a2 + 48);
LABEL_10:
    uint64_t v9 = mlir::Dialect::getRegisteredInterfaceForOp<mlir::DestinationStyleOpInterface>(Values, v11);
  }
  return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t))(*(void *)a1 + 56))(a1, a2, v9);
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::DestinationStyleOpInterface>::matchAndRewrite(uint64_t a1, uint64_t a2, uint64_t a3)
{
  if (!a2) {
    goto LABEL_11;
  }
  uint64_t v6 = *(void *)(a2 + 48);
  uint64_t v7 = *(void **)(v6 + 16);
  BOOL v8 = v7 == &mlir::detail::TypeIDResolver<void,void>::id;
  if (v7 == &mlir::detail::TypeIDResolver<void,void>::id) {
    uint64_t v9 = 0;
  }
  else {
    uint64_t v9 = *(void *)(a2 + 48);
  }
  if (v8)
  {
    uint64_t v15 = *(void *)(v6 + 8);
    uint64_t Values = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)&v15);
    if (Values)
    {
      uint64_t v13 = v6;
      goto LABEL_10;
    }
LABEL_11:
    uint64_t v11 = 0;
    return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t, uint64_t))(*(void *)a1 + 64))(a1, a2, v11, a3);
  }
  unint64_t v10 = v9 | v6 & 0xFFFFFFFFFFFFFF00;
  uint64_t v11 = mlir::detail::InterfaceMap::lookup<mlir::DestinationStyleOpInterface>(v10 + 32);
  if (!v11)
  {
    uint64_t Values = *(void *)(v10 + 24);
    uint64_t v13 = *(void *)(a2 + 48);
LABEL_10:
    uint64_t v11 = mlir::Dialect::getRegisteredInterfaceForOp<mlir::DestinationStyleOpInterface>(Values, v13);
  }
  return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t, uint64_t))(*(void *)a1 + 64))(a1, a2, v11, a3);
}

uint64_t FoldTensorCastProducerOp::matchAndRewrite(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  void v51[3] = *MEMORY[0x263EF8340];
  uint64_t v37 = a2;
  uint64_t v38 = a3;
  uint64_t v4 = *(void *)(a2 + 48);
  uint64_t v5 = *(void **)(v4 + 16);
  if (v5 != &mlir::detail::TypeIDResolver<mlir::tensor::InsertSliceOp,void>::id)
  {
    BOOL v7 = v5 == &mlir::detail::TypeIDResolver<void,void>::id;
    if (v5 == &mlir::detail::TypeIDResolver<void,void>::id) {
      uint64_t v8 = 0;
    }
    else {
      uint64_t v8 = *(void *)(a2 + 48);
    }
    if (v7)
    {
      uint64_t v49 = *(void *)(v4 + 8);
      uint64_t Values = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)&v49);
      if (Values && mlir::Dialect::getRegisteredInterfaceForOp<mlir::LoopLikeOpInterface>(Values, v4)) {
        return 0;
      }
    }
    else
    {
      unint64_t v10 = v8 | v4 & 0xFFFFFFFFFFFFFF00;
      if (mlir::detail::InterfaceMap::lookup<mlir::LoopLikeOpInterface>(v10 + 32)
        || mlir::Dialect::getRegisteredInterfaceForOp<mlir::LoopLikeOpInterface>(*(void *)(v10 + 24), *(void *)(a2 + 48)))
      {
        return 0;
      }
    }
    if ((*(unsigned char *)(v37 + 46) & 0x80) != 0)
    {
      uint64_t v12 = *(unsigned int *)(v37 + 68);
      if (v12)
      {
        uint64_t v13 = 32 * v12;
        uint64_t v14 = *(void *)(v37 + 72) + 24;
        do
        {
          if ((~*(_DWORD *)(*(void *)v14 + 8) & 7) != 0)
          {
            uint64_t v49 = *(void *)v14;
            uint64_t DefiningOp = mlir::Value::getDefiningOp((mlir::Value *)&v49);
            if (DefiningOp)
            {
              if (*(_UNKNOWN **)(*(void *)(DefiningOp + 48) + 16) == &mlir::detail::TypeIDResolver<mlir::tensor::CastOp,void>::id
                && (mlir::tensor::preservesStaticInformation(*(void *)(DefiningOp - 8) & 0xFFFFFFFFFFFFFFF8, *(void *)(*(void *)(*(void *)(DefiningOp + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8) & 1) != 0)
              {
                uint64_t v46 = v48;
                uint64_t v47 = 0x400000000;
                uint64_t v16 = v37;
                unint64_t v17 = *(unsigned int *)(v37 + 36);
                if (v17 >= 5)
                {
                  llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v46, v48, v17, 8);
                  uint64_t v16 = v37;
                }
                uint64_t v43 = v45;
                uint64_t v44 = 0x400000000;
                if ((*(unsigned char *)(v16 + 46) & 0x80) != 0)
                {
                  unint64_t v18 = *(unsigned int *)(v16 + 68);
                  if (v18 <= 4
                    || (llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v43, v45, v18, 8),
                        uint64_t v16 = v37,
                        (*(unsigned char *)(v37 + 46) & 0x80) != 0))
                  {
                    uint64_t v19 = *(unsigned int *)(v16 + 68);
                    if (v19)
                    {
                      uint64_t v20 = 32 * v19;
                      char v21 = (uint64_t *)(*(void *)(v16 + 72) + 24);
                      do
                      {
                        uint64_t v49 = *v21;
                        uint64_t v23 = mlir::Value::getDefiningOp((mlir::Value *)&v49);
                        if (v23
                          && (uint64_t v24 = v23,
                              *(_UNKNOWN **)(*(void *)(v23 + 48) + 16) == &mlir::detail::TypeIDResolver<mlir::tensor::CastOp,void>::id))
                        {
                          int v35 = mlir::tensor::preservesStaticInformation(*(void *)(v23 - 8) & 0xFFFFFFFFFFFFFFF8, *(void *)(*(void *)(*(void *)(v23 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8);
                          uint64_t v25 = v21;
                          if (v35) {
                            uint64_t v25 = (uint64_t *)(*(void *)(v24 + 72) + 24);
                          }
                        }
                        else
                        {
                          uint64_t v25 = v21;
                        }
                        uint64_t v26 = *v25;
                        uint64_t v27 = v44;
                        if (v44 >= (unint64_t)HIDWORD(v44))
                        {
                          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v43, v45, v44 + 1, 8);
                          uint64_t v27 = v44;
                        }
                        *((void *)v43 + v27) = v26;
                        LODWORD(v44) = v44 + 1;
                        mlir::DestinationStyleOpInterface::getDpsInitsMutable(&v49, (mlir::DestinationStyleOpInterface *)&v37);
                        uint64_t v28 = mlir::MutableOperandRange::operator mlir::OperandRange((unsigned int *)&v49);
                        uint64_t v30 = v29;
                        if (v50 != v51) {
                          free(v50);
                        }
                        uint64_t v39 = v28;
                        uint64_t v40 = v30;
                        if (v30)
                        {
                          unsigned int OperandNumber = mlir::OpOperand::getOperandNumber((unint64_t)(v21 - 3));
                          if (OperandNumber >= mlir::OperandRange::getBeginOperandIndex((mlir::OperandRange *)&v39))
                          {
                            unsigned int BeginOperandIndex = mlir::OperandRange::getBeginOperandIndex((mlir::OperandRange *)&v39);
                            if (v40 + (unint64_t)BeginOperandIndex > OperandNumber)
                            {
                              unint64_t v33 = *(void *)(*((void *)v43 + v44 - 1) + 8) & 0xFFFFFFFFFFFFFFF8;
                              if (*(_UNKNOWN **)(*(void *)v33 + 136) != &mlir::detail::TypeIDResolver<mlir::MemRefType,void>::id)
                              {
                                uint64_t v34 = v47;
                                if (v47 >= (unint64_t)HIDWORD(v47))
                                {
                                  llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v46, v48, v47 + 1, 8);
                                  uint64_t v34 = v47;
                                }
                                *((void *)v46 + v34) = v33;
                                LODWORD(v47) = v47 + 1;
                              }
                            }
                          }
                        }
                        v21 += 4;
                        v20 -= 32;
                      }
                      while (v20);
                      uint64_t v16 = v37;
                    }
                  }
                }
                uint64_t v36 = v38;
                mlir::ValueRange::ValueRange(v42, (uint64_t)v46, v47);
                mlir::ValueRange::ValueRange(v41, (uint64_t)v43, v44);
                mlir::clone<mlir::DestinationStyleOpInterface>((mlir::OpBuilder *)(a4 + 8), v16, v36, v42[0], v42[1], v41[0], v41[1]);
              }
            }
          }
          v14 += 32;
          v13 -= 32;
        }
        while (v13);
      }
    }
  }
  return 0;
}

void *mlir::OpInterfaceRewritePattern<mlir::DestinationStyleOpInterface>::~OpInterfaceRewritePattern(void *a1)
{
  uint64_t v2 = (void *)a1[10];
  if (v2 != a1 + 12) {
    free(v2);
  }
  uint64_t v3 = (void *)a1[4];
  if (v3 != a1 + 6) {
    free(v3);
  }
  return a1;
}

void mlir::OpInterfaceRewritePattern<mlir::DestinationStyleOpInterface>::~OpInterfaceRewritePattern(void *a1)
{
  uint64_t v2 = (void *)a1[10];
  if (v2 != a1 + 12) {
    free(v2);
  }
  uint64_t v3 = (void *)a1[4];
  if (v3 != a1 + 6) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::DestinationStyleOpInterface>::matchAndRewrite(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  if (!(*(unsigned __int8 (**)(uint64_t))(*(void *)a1 + 56))(a1)) {
    return 0;
  }
  (*(void (**)(uint64_t, uint64_t, uint64_t, uint64_t))(*(void *)a1 + 48))(a1, a2, a3, a4);
  return 1;
}

void mlir::clone<mlir::DestinationStyleOpInterface>(mlir::OpBuilder *a1, uint64_t a2, uint64_t a3, uint64_t a4, unint64_t a5, uint64_t a6, uint64_t a7)
{
}

uint64_t sub_2118DEE1C(uint64_t a1)
{
  if (!a1) {
    return a1;
  }
  uint64_t v2 = *(void *)(a1 + 48);
  uint64_t v3 = *(void **)(v2 + 16);
  BOOL v4 = v3 == &mlir::detail::TypeIDResolver<void,void>::id;
  if (v3 == &mlir::detail::TypeIDResolver<void,void>::id) {
    uint64_t v5 = 0;
  }
  else {
    uint64_t v5 = *(void *)(a1 + 48);
  }
  if (!v4)
  {
    unint64_t v6 = v5 | v2 & 0xFFFFFFFFFFFFFF00;
    if (mlir::detail::InterfaceMap::lookup<mlir::DestinationStyleOpInterface>(v6 + 32)) {
      return a1;
    }
    uint64_t Values = *(void *)(v6 + 24);
    uint64_t v9 = *(void *)(a1 + 48);
    goto LABEL_12;
  }
  uint64_t v10 = *(void *)(v2 + 8);
  uint64_t Values = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)&v10);
  if (!Values) {
    return a1;
  }
  uint64_t v9 = v2;
LABEL_12:
  mlir::Dialect::getRegisteredInterfaceForOp<mlir::DestinationStyleOpInterface>(Values, v9);
  return a1;
}

void llvm::function_ref<void ()(mlir::OpaqueProperties)>::callback_fn<mlir::tensor::detail::CollapseShapeOpGenericAdaptorBase::Properties & mlir::OperationState::getOrAddProperties<mlir::tensor::detail::CollapseShapeOpGenericAdaptorBase::Properties>(void)::{lambda(mlir::OpaqueProperties)#1}>(uint64_t a1, uint64_t a2)
{
  if (a2) {
    JUMPOUT(0x21667D3C0);
  }
}

void llvm::function_ref<void ()(mlir::OpaqueProperties,mlir::OpaqueProperties)>::callback_fn<mlir::tensor::detail::CollapseShapeOpGenericAdaptorBase::Properties & mlir::OperationState::getOrAddProperties<mlir::tensor::detail::CollapseShapeOpGenericAdaptorBase::Properties>(void)::{lambda(mlir::OpaqueProperties,mlir::OpaqueProperties)#1}>(uint64_t a1, void *a2, void *a3)
{
  *a2 = *a3;
}

void llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::CollapseShapeOp::parse(mlir::OpAsmParser &,mlir::OperationState &)::$_0>(void *a1@<X0>, uint64_t a2@<X8>)
{
  uint64_t v49 = *MEMORY[0x263EF8340];
  (*(void (**)(uint64_t *__return_ptr))(*(void *)*a1 + 24))(&v37);
  if (v37)
  {
    LODWORD(v33) = 3;
    uint64_t v34 = "'";
    uint64_t v35 = 1;
    BOOL v4 = &v33;
    uint64_t v5 = (char *)v40;
    if (v41 >= v42)
    {
      unint64_t v29 = v41 + 1;
      if (v40 <= &v33 && (char *)v40 + 24 * v41 > (char *)&v33)
      {
        int64_t v31 = (char *)&v33 - (unsigned char *)v40;
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v40, v43, v29, 24);
        uint64_t v5 = (char *)v40;
        BOOL v4 = (void ***)((char *)v40 + v31);
      }
      else
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v40, v43, v29, 24);
        BOOL v4 = &v33;
        uint64_t v5 = (char *)v40;
      }
    }
    unint64_t v6 = &v5[24 * v41];
    long long v7 = *(_OWORD *)v4;
    *((void *)v6 + 2) = v4[2];
    *(_OWORD *)unint64_t v6 = v7;
    ++v41;
  }
  unint64_t v33 = *(void ***)(*(void *)(a1[2] + 8) + 8);
  AttrData = (void **)mlir::OpaqueAttr::getAttrData((mlir::OpaqueAttr *)&v33);
  uint64_t v10 = v37;
  if (v37)
  {
    __int16 v36 = 261;
    unint64_t v33 = AttrData;
    uint64_t v34 = v9;
    mlir::Diagnostic::operator<<((uint64_t)&v38, &v33);
    uint64_t v10 = v37;
    if (v37)
    {
      LODWORD(v33) = 3;
      uint64_t v34 = "' op ";
      uint64_t v35 = 5;
      uint64_t v11 = &v33;
      uint64_t v12 = (char *)v40;
      if (v41 >= v42)
      {
        unint64_t v30 = v41 + 1;
        if (v40 <= &v33 && (char *)v40 + 24 * v41 > (char *)&v33)
        {
          int64_t v32 = (char *)&v33 - (unsigned char *)v40;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v40, v43, v30, 24);
          uint64_t v12 = (char *)v40;
          uint64_t v11 = (void ***)((char *)v40 + v32);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v40, v43, v30, 24);
          uint64_t v11 = &v33;
          uint64_t v12 = (char *)v40;
        }
      }
      uint64_t v13 = &v12[24 * v41];
      long long v14 = *(_OWORD *)v11;
      *((void *)v13 + 2) = v11[2];
      *(_OWORD *)uint64_t v13 = v14;
      ++v41;
      uint64_t v10 = v37;
    }
  }
  *(void *)a2 = v10;
  *(unsigned char *)(a2 + 8) = 0;
  *(unsigned char *)(a2 + 184) = 0;
  if (v48)
  {
    *(void *)(a2 + 8) = v38;
    unint64_t v15 = v41;
    *(_DWORD *)(a2 + 16) = v39;
    uint64_t v16 = (void *)(a2 + 40);
    *(void *)(a2 + 24) = a2 + 40;
    *(void *)(a2 + 32) = 0x400000000;
    if (!v15 || &v37 == (uint64_t *)a2)
    {
      int v19 = 1;
      goto LABEL_21;
    }
    unint64_t v17 = v43;
    if (v40 != v43)
    {
      *(void *)(a2 + 24) = v40;
      unsigned int v18 = v42;
      *(_DWORD *)(a2 + 32) = v15;
      *(_DWORD *)(a2 + 36) = v18;
      uint64_t v40 = v43;
      unsigned int v42 = 0;
      int v19 = 1;
LABEL_20:
      unsigned int v41 = 0;
LABEL_21:
      *(_OWORD *)(a2 + 136) = *(_OWORD *)v44;
      *(void *)(a2 + 152) = v45;
      v44[0] = 0;
      v44[1] = 0;
      *(_OWORD *)(a2 + 160) = *(_OWORD *)__p;
      *(void *)(a2 + 176) = v47;
      uint64_t v45 = 0;
      __p[0] = 0;
      __p[1] = 0;
      uint64_t v47 = 0;
      *(unsigned char *)(a2 + 184) = 1;
      if (v19)
      {
        if (v40 != v43) {
          free(v40);
        }
        unsigned __int8 v48 = 0;
      }
      goto LABEL_25;
    }
    if (v15 < 5)
    {
      unint64_t v20 = v15;
    }
    else
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod(a2 + 24, (void *)(a2 + 40), v15, 24);
      unint64_t v20 = v41;
      if (!v41)
      {
LABEL_19:
        *(_DWORD *)(a2 + 32) = v15;
        int v19 = v48;
        goto LABEL_20;
      }
      unint64_t v17 = v40;
      uint64_t v16 = *(void **)(a2 + 24);
    }
    memcpy(v16, v17, 24 * v20);
    goto LABEL_19;
  }
LABEL_25:
  mlir::InFlightDiagnostic::abandon(&v37);
  if (v37) {
    mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v37);
  }
  if (v48)
  {
    char v21 = __p[0];
    if (__p[0])
    {
      uint64_t v22 = __p[1];
      uint64_t v23 = __p[0];
      if (__p[1] != __p[0])
      {
        do
          uint64_t v22 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v22 - 1);
        while (v22 != v21);
        uint64_t v23 = __p[0];
      }
      __p[1] = v21;
      operator delete(v23);
    }
    uint64_t v24 = v44[0];
    if (v44[0])
    {
      uint64_t v25 = v44[1];
      uint64_t v26 = v44[0];
      if (v44[1] != v44[0])
      {
        do
        {
          uint64_t v28 = *--v25;
          uint64_t v27 = v28;
          void *v25 = 0;
          if (v28) {
            MEMORY[0x21667D390](v27, 0x1000C8077774924);
          }
        }
        while (v25 != v24);
        uint64_t v26 = v44[0];
      }
      v44[1] = v24;
      operator delete(v26);
    }
    if (v40 != v43) {
      free(v40);
    }
  }
}

void llvm::function_ref<void ()(mlir::OpaqueProperties)>::callback_fn<mlir::tensor::detail::ExpandShapeOpGenericAdaptorBase::Properties & mlir::OperationState::getOrAddProperties<mlir::tensor::detail::ExpandShapeOpGenericAdaptorBase::Properties>(void)::{lambda(mlir::OpaqueProperties)#1}>(uint64_t a1, uint64_t a2)
{
  if (a2) {
    JUMPOUT(0x21667D3C0);
  }
}

void llvm::function_ref<void ()(mlir::OpaqueProperties,mlir::OpaqueProperties)>::callback_fn<mlir::tensor::detail::ExpandShapeOpGenericAdaptorBase::Properties & mlir::OperationState::getOrAddProperties<mlir::tensor::detail::ExpandShapeOpGenericAdaptorBase::Properties>(void)::{lambda(mlir::OpaqueProperties,mlir::OpaqueProperties)#1}>(uint64_t a1, void *a2, void *a3)
{
  *a2 = *a3;
}

void llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::ExpandShapeOp::parse(mlir::OpAsmParser &,mlir::OperationState &)::$_0>(void *a1@<X0>, uint64_t a2@<X8>)
{
  uint64_t v49 = *MEMORY[0x263EF8340];
  (*(void (**)(uint64_t *__return_ptr))(*(void *)*a1 + 24))(&v37);
  if (v37)
  {
    LODWORD(v33) = 3;
    uint64_t v34 = "'";
    uint64_t v35 = 1;
    BOOL v4 = &v33;
    uint64_t v5 = (char *)v40;
    if (v41 >= v42)
    {
      unint64_t v29 = v41 + 1;
      if (v40 <= &v33 && (char *)v40 + 24 * v41 > (char *)&v33)
      {
        int64_t v31 = (char *)&v33 - (unsigned char *)v40;
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v40, v43, v29, 24);
        uint64_t v5 = (char *)v40;
        BOOL v4 = (void ***)((char *)v40 + v31);
      }
      else
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v40, v43, v29, 24);
        BOOL v4 = &v33;
        uint64_t v5 = (char *)v40;
      }
    }
    unint64_t v6 = &v5[24 * v41];
    long long v7 = *(_OWORD *)v4;
    *((void *)v6 + 2) = v4[2];
    *(_OWORD *)unint64_t v6 = v7;
    ++v41;
  }
  unint64_t v33 = *(void ***)(*(void *)(a1[2] + 8) + 8);
  AttrData = (void **)mlir::OpaqueAttr::getAttrData((mlir::OpaqueAttr *)&v33);
  uint64_t v10 = v37;
  if (v37)
  {
    __int16 v36 = 261;
    unint64_t v33 = AttrData;
    uint64_t v34 = v9;
    mlir::Diagnostic::operator<<((uint64_t)&v38, &v33);
    uint64_t v10 = v37;
    if (v37)
    {
      LODWORD(v33) = 3;
      uint64_t v34 = "' op ";
      uint64_t v35 = 5;
      uint64_t v11 = &v33;
      uint64_t v12 = (char *)v40;
      if (v41 >= v42)
      {
        unint64_t v30 = v41 + 1;
        if (v40 <= &v33 && (char *)v40 + 24 * v41 > (char *)&v33)
        {
          int64_t v32 = (char *)&v33 - (unsigned char *)v40;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v40, v43, v30, 24);
          uint64_t v12 = (char *)v40;
          uint64_t v11 = (void ***)((char *)v40 + v32);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v40, v43, v30, 24);
          uint64_t v11 = &v33;
          uint64_t v12 = (char *)v40;
        }
      }
      uint64_t v13 = &v12[24 * v41];
      long long v14 = *(_OWORD *)v11;
      *((void *)v13 + 2) = v11[2];
      *(_OWORD *)uint64_t v13 = v14;
      ++v41;
      uint64_t v10 = v37;
    }
  }
  *(void *)a2 = v10;
  *(unsigned char *)(a2 + 8) = 0;
  *(unsigned char *)(a2 + 184) = 0;
  if (v48)
  {
    *(void *)(a2 + 8) = v38;
    unint64_t v15 = v41;
    *(_DWORD *)(a2 + 16) = v39;
    uint64_t v16 = (void *)(a2 + 40);
    *(void *)(a2 + 24) = a2 + 40;
    *(void *)(a2 + 32) = 0x400000000;
    if (!v15 || &v37 == (uint64_t *)a2)
    {
      int v19 = 1;
      goto LABEL_21;
    }
    unint64_t v17 = v43;
    if (v40 != v43)
    {
      *(void *)(a2 + 24) = v40;
      unsigned int v18 = v42;
      *(_DWORD *)(a2 + 32) = v15;
      *(_DWORD *)(a2 + 36) = v18;
      uint64_t v40 = v43;
      unsigned int v42 = 0;
      int v19 = 1;
LABEL_20:
      unsigned int v41 = 0;
LABEL_21:
      *(_OWORD *)(a2 + 136) = *(_OWORD *)v44;
      *(void *)(a2 + 152) = v45;
      v44[0] = 0;
      v44[1] = 0;
      *(_OWORD *)(a2 + 160) = *(_OWORD *)__p;
      *(void *)(a2 + 176) = v47;
      uint64_t v45 = 0;
      __p[0] = 0;
      __p[1] = 0;
      uint64_t v47 = 0;
      *(unsigned char *)(a2 + 184) = 1;
      if (v19)
      {
        if (v40 != v43) {
          free(v40);
        }
        unsigned __int8 v48 = 0;
      }
      goto LABEL_25;
    }
    if (v15 < 5)
    {
      unint64_t v20 = v15;
    }
    else
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod(a2 + 24, (void *)(a2 + 40), v15, 24);
      unint64_t v20 = v41;
      if (!v41)
      {
LABEL_19:
        *(_DWORD *)(a2 + 32) = v15;
        int v19 = v48;
        goto LABEL_20;
      }
      unint64_t v17 = v40;
      uint64_t v16 = *(void **)(a2 + 24);
    }
    memcpy(v16, v17, 24 * v20);
    goto LABEL_19;
  }
LABEL_25:
  mlir::InFlightDiagnostic::abandon(&v37);
  if (v37) {
    mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v37);
  }
  if (v48)
  {
    char v21 = __p[0];
    if (__p[0])
    {
      uint64_t v22 = __p[1];
      uint64_t v23 = __p[0];
      if (__p[1] != __p[0])
      {
        do
          uint64_t v22 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v22 - 1);
        while (v22 != v21);
        uint64_t v23 = __p[0];
      }
      __p[1] = v21;
      operator delete(v23);
    }
    uint64_t v24 = v44[0];
    if (v44[0])
    {
      uint64_t v25 = v44[1];
      uint64_t v26 = v44[0];
      if (v44[1] != v44[0])
      {
        do
        {
          uint64_t v28 = *--v25;
          uint64_t v27 = v28;
          void *v25 = 0;
          if (v28) {
            MEMORY[0x21667D390](v27, 0x1000C8077774924);
          }
        }
        while (v25 != v24);
        uint64_t v26 = v44[0];
      }
      v44[1] = v24;
      operator delete(v26);
    }
    if (v40 != v43) {
      free(v40);
    }
  }
}

void llvm::function_ref<void ()(mlir::OpaqueProperties)>::callback_fn<mlir::tensor::detail::ExtractSliceOpGenericAdaptorBase::Properties & mlir::OperationState::getOrAddProperties<mlir::tensor::detail::ExtractSliceOpGenericAdaptorBase::Properties>(void)::{lambda(mlir::OpaqueProperties)#1}>(uint64_t a1, uint64_t a2)
{
  if (a2) {
    JUMPOUT(0x21667D3C0);
  }
}

__n128 llvm::function_ref<void ()(mlir::OpaqueProperties,mlir::OpaqueProperties)>::callback_fn<mlir::tensor::detail::ExtractSliceOpGenericAdaptorBase::Properties & mlir::OperationState::getOrAddProperties<mlir::tensor::detail::ExtractSliceOpGenericAdaptorBase::Properties>(void)::{lambda(mlir::OpaqueProperties,mlir::OpaqueProperties)#1}>(uint64_t a1, uint64_t a2, uint64_t a3)
{
  __n128 result = *(__n128 *)a3;
  long long v4 = *(_OWORD *)(a3 + 16);
  *(void *)(a2 + 32) = *(void *)(a3 + 32);
  *(__n128 *)a2 = result;
  *(_OWORD *)(a2 + 16) = v4;
  return result;
}

void llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::ExtractSliceOp::parse(mlir::OpAsmParser &,mlir::OperationState &)::$_0>(void *a1@<X0>, uint64_t a2@<X8>)
{
  uint64_t v49 = *MEMORY[0x263EF8340];
  (*(void (**)(uint64_t *__return_ptr))(*(void *)*a1 + 24))(&v37);
  if (v37)
  {
    LODWORD(v33) = 3;
    uint64_t v34 = "'";
    uint64_t v35 = 1;
    long long v4 = &v33;
    uint64_t v5 = (char *)v40;
    if (v41 >= v42)
    {
      unint64_t v29 = v41 + 1;
      if (v40 <= &v33 && (char *)v40 + 24 * v41 > (char *)&v33)
      {
        int64_t v31 = (char *)&v33 - (unsigned char *)v40;
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v40, v43, v29, 24);
        uint64_t v5 = (char *)v40;
        long long v4 = (void ***)((char *)v40 + v31);
      }
      else
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v40, v43, v29, 24);
        long long v4 = &v33;
        uint64_t v5 = (char *)v40;
      }
    }
    unint64_t v6 = &v5[24 * v41];
    long long v7 = *(_OWORD *)v4;
    *((void *)v6 + 2) = v4[2];
    *(_OWORD *)unint64_t v6 = v7;
    ++v41;
  }
  unint64_t v33 = *(void ***)(*(void *)(a1[2] + 8) + 8);
  AttrData = (void **)mlir::OpaqueAttr::getAttrData((mlir::OpaqueAttr *)&v33);
  uint64_t v10 = v37;
  if (v37)
  {
    __int16 v36 = 261;
    unint64_t v33 = AttrData;
    uint64_t v34 = v9;
    mlir::Diagnostic::operator<<((uint64_t)&v38, &v33);
    uint64_t v10 = v37;
    if (v37)
    {
      LODWORD(v33) = 3;
      uint64_t v34 = "' op ";
      uint64_t v35 = 5;
      uint64_t v11 = &v33;
      uint64_t v12 = (char *)v40;
      if (v41 >= v42)
      {
        unint64_t v30 = v41 + 1;
        if (v40 <= &v33 && (char *)v40 + 24 * v41 > (char *)&v33)
        {
          int64_t v32 = (char *)&v33 - (unsigned char *)v40;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v40, v43, v30, 24);
          uint64_t v12 = (char *)v40;
          uint64_t v11 = (void ***)((char *)v40 + v32);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v40, v43, v30, 24);
          uint64_t v11 = &v33;
          uint64_t v12 = (char *)v40;
        }
      }
      uint64_t v13 = &v12[24 * v41];
      long long v14 = *(_OWORD *)v11;
      *((void *)v13 + 2) = v11[2];
      *(_OWORD *)uint64_t v13 = v14;
      ++v41;
      uint64_t v10 = v37;
    }
  }
  *(void *)a2 = v10;
  *(unsigned char *)(a2 + 8) = 0;
  *(unsigned char *)(a2 + 184) = 0;
  if (v48)
  {
    *(void *)(a2 + 8) = v38;
    unint64_t v15 = v41;
    *(_DWORD *)(a2 + 16) = v39;
    uint64_t v16 = (void *)(a2 + 40);
    *(void *)(a2 + 24) = a2 + 40;
    *(void *)(a2 + 32) = 0x400000000;
    if (!v15 || &v37 == (uint64_t *)a2)
    {
      int v19 = 1;
      goto LABEL_21;
    }
    unint64_t v17 = v43;
    if (v40 != v43)
    {
      *(void *)(a2 + 24) = v40;
      unsigned int v18 = v42;
      *(_DWORD *)(a2 + 32) = v15;
      *(_DWORD *)(a2 + 36) = v18;
      uint64_t v40 = v43;
      unsigned int v42 = 0;
      int v19 = 1;
LABEL_20:
      unsigned int v41 = 0;
LABEL_21:
      *(_OWORD *)(a2 + 136) = *(_OWORD *)v44;
      *(void *)(a2 + 152) = v45;
      v44[0] = 0;
      v44[1] = 0;
      *(_OWORD *)(a2 + 160) = *(_OWORD *)__p;
      *(void *)(a2 + 176) = v47;
      uint64_t v45 = 0;
      __p[0] = 0;
      __p[1] = 0;
      uint64_t v47 = 0;
      *(unsigned char *)(a2 + 184) = 1;
      if (v19)
      {
        if (v40 != v43) {
          free(v40);
        }
        unsigned __int8 v48 = 0;
      }
      goto LABEL_25;
    }
    if (v15 < 5)
    {
      unint64_t v20 = v15;
    }
    else
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod(a2 + 24, (void *)(a2 + 40), v15, 24);
      unint64_t v20 = v41;
      if (!v41)
      {
LABEL_19:
        *(_DWORD *)(a2 + 32) = v15;
        int v19 = v48;
        goto LABEL_20;
      }
      unint64_t v17 = v40;
      uint64_t v16 = *(void **)(a2 + 24);
    }
    memcpy(v16, v17, 24 * v20);
    goto LABEL_19;
  }
LABEL_25:
  mlir::InFlightDiagnostic::abandon(&v37);
  if (v37) {
    mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v37);
  }
  if (v48)
  {
    char v21 = __p[0];
    if (__p[0])
    {
      uint64_t v22 = __p[1];
      uint64_t v23 = __p[0];
      if (__p[1] != __p[0])
      {
        do
          uint64_t v22 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v22 - 1);
        while (v22 != v21);
        uint64_t v23 = __p[0];
      }
      __p[1] = v21;
      operator delete(v23);
    }
    uint64_t v24 = v44[0];
    if (v44[0])
    {
      uint64_t v25 = v44[1];
      uint64_t v26 = v44[0];
      if (v44[1] != v44[0])
      {
        do
        {
          uint64_t v28 = *--v25;
          uint64_t v27 = v28;
          void *v25 = 0;
          if (v28) {
            MEMORY[0x21667D390](v27, 0x1000C8077774924);
          }
        }
        while (v25 != v24);
        uint64_t v26 = v44[0];
      }
      v44[1] = v24;
      operator delete(v26);
    }
    if (v40 != v43) {
      free(v40);
    }
  }
}

void llvm::function_ref<void ()(mlir::OpaqueProperties)>::callback_fn<mlir::tensor::detail::GatherOpGenericAdaptorBase::Properties & mlir::OperationState::getOrAddProperties<mlir::tensor::detail::GatherOpGenericAdaptorBase::Properties>(void)::{lambda(mlir::OpaqueProperties)#1}>(uint64_t a1, uint64_t a2)
{
  if (a2) {
    JUMPOUT(0x21667D3C0);
  }
}

__n128 llvm::function_ref<void ()(mlir::OpaqueProperties,mlir::OpaqueProperties)>::callback_fn<mlir::tensor::detail::GatherOpGenericAdaptorBase::Properties & mlir::OperationState::getOrAddProperties<mlir::tensor::detail::GatherOpGenericAdaptorBase::Properties>(void)::{lambda(mlir::OpaqueProperties,mlir::OpaqueProperties)#1}>(uint64_t a1, __n128 *a2, __n128 *a3)
{
  __n128 result = *a3;
  *a2 = *a3;
  return result;
}

BOOL _ZN4llvm12function_refIFN4mlir11ParseResultERNS1_9AttributeENS1_4TypeEEE11callback_fnIZNS1_9AsmParser32parseCustomAttributeWithFallbackINS1_6detail18DenseArrayAttrImplIxEEEENSt3__19enable_ifIXsr23detect_has_parse_methodIT_EE5valueES2_E4typeERSG_S5_EUlS4_S5_E_EES2_lS4_S5_(mlir::AsmParser **a1, uint64_t *a2)
{
  uint64_t v3 = mlir::detail::DenseArrayAttrImpl<long long>::parse(*a1);
  *a2 = v3;
  return v3 != 0;
}

void llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::GatherOp::parse(mlir::OpAsmParser &,mlir::OperationState &)::$_0>(void *a1@<X0>, uint64_t a2@<X8>)
{
  uint64_t v49 = *MEMORY[0x263EF8340];
  (*(void (**)(uint64_t *__return_ptr))(*(void *)*a1 + 24))(&v37);
  if (v37)
  {
    LODWORD(v33) = 3;
    uint64_t v34 = "'";
    uint64_t v35 = 1;
    long long v4 = &v33;
    uint64_t v5 = (char *)v40;
    if (v41 >= v42)
    {
      unint64_t v29 = v41 + 1;
      if (v40 <= &v33 && (char *)v40 + 24 * v41 > (char *)&v33)
      {
        int64_t v31 = (char *)&v33 - (unsigned char *)v40;
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v40, v43, v29, 24);
        uint64_t v5 = (char *)v40;
        long long v4 = (void ***)((char *)v40 + v31);
      }
      else
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v40, v43, v29, 24);
        long long v4 = &v33;
        uint64_t v5 = (char *)v40;
      }
    }
    unint64_t v6 = &v5[24 * v41];
    long long v7 = *(_OWORD *)v4;
    *((void *)v6 + 2) = v4[2];
    *(_OWORD *)unint64_t v6 = v7;
    ++v41;
  }
  unint64_t v33 = *(void ***)(*(void *)(a1[2] + 8) + 8);
  AttrData = (void **)mlir::OpaqueAttr::getAttrData((mlir::OpaqueAttr *)&v33);
  uint64_t v10 = v37;
  if (v37)
  {
    __int16 v36 = 261;
    unint64_t v33 = AttrData;
    uint64_t v34 = v9;
    mlir::Diagnostic::operator<<((uint64_t)&v38, &v33);
    uint64_t v10 = v37;
    if (v37)
    {
      LODWORD(v33) = 3;
      uint64_t v34 = "' op ";
      uint64_t v35 = 5;
      uint64_t v11 = &v33;
      uint64_t v12 = (char *)v40;
      if (v41 >= v42)
      {
        unint64_t v30 = v41 + 1;
        if (v40 <= &v33 && (char *)v40 + 24 * v41 > (char *)&v33)
        {
          int64_t v32 = (char *)&v33 - (unsigned char *)v40;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v40, v43, v30, 24);
          uint64_t v12 = (char *)v40;
          uint64_t v11 = (void ***)((char *)v40 + v32);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v40, v43, v30, 24);
          uint64_t v11 = &v33;
          uint64_t v12 = (char *)v40;
        }
      }
      uint64_t v13 = &v12[24 * v41];
      long long v14 = *(_OWORD *)v11;
      *((void *)v13 + 2) = v11[2];
      *(_OWORD *)uint64_t v13 = v14;
      ++v41;
      uint64_t v10 = v37;
    }
  }
  *(void *)a2 = v10;
  *(unsigned char *)(a2 + 8) = 0;
  *(unsigned char *)(a2 + 184) = 0;
  if (v48)
  {
    *(void *)(a2 + 8) = v38;
    unint64_t v15 = v41;
    *(_DWORD *)(a2 + 16) = v39;
    uint64_t v16 = (void *)(a2 + 40);
    *(void *)(a2 + 24) = a2 + 40;
    *(void *)(a2 + 32) = 0x400000000;
    if (!v15 || &v37 == (uint64_t *)a2)
    {
      int v19 = 1;
      goto LABEL_21;
    }
    unint64_t v17 = v43;
    if (v40 != v43)
    {
      *(void *)(a2 + 24) = v40;
      unsigned int v18 = v42;
      *(_DWORD *)(a2 + 32) = v15;
      *(_DWORD *)(a2 + 36) = v18;
      uint64_t v40 = v43;
      unsigned int v42 = 0;
      int v19 = 1;
LABEL_20:
      unsigned int v41 = 0;
LABEL_21:
      *(_OWORD *)(a2 + 136) = *(_OWORD *)v44;
      *(void *)(a2 + 152) = v45;
      v44[0] = 0;
      v44[1] = 0;
      *(_OWORD *)(a2 + 160) = *(_OWORD *)__p;
      *(void *)(a2 + 176) = v47;
      uint64_t v45 = 0;
      __p[0] = 0;
      __p[1] = 0;
      uint64_t v47 = 0;
      *(unsigned char *)(a2 + 184) = 1;
      if (v19)
      {
        if (v40 != v43) {
          free(v40);
        }
        unsigned __int8 v48 = 0;
      }
      goto LABEL_25;
    }
    if (v15 < 5)
    {
      unint64_t v20 = v15;
    }
    else
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod(a2 + 24, (void *)(a2 + 40), v15, 24);
      unint64_t v20 = v41;
      if (!v41)
      {
LABEL_19:
        *(_DWORD *)(a2 + 32) = v15;
        int v19 = v48;
        goto LABEL_20;
      }
      unint64_t v17 = v40;
      uint64_t v16 = *(void **)(a2 + 24);
    }
    memcpy(v16, v17, 24 * v20);
    goto LABEL_19;
  }
LABEL_25:
  mlir::InFlightDiagnostic::abandon(&v37);
  if (v37) {
    mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v37);
  }
  if (v48)
  {
    char v21 = __p[0];
    if (__p[0])
    {
      uint64_t v22 = __p[1];
      uint64_t v23 = __p[0];
      if (__p[1] != __p[0])
      {
        do
          uint64_t v22 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v22 - 1);
        while (v22 != v21);
        uint64_t v23 = __p[0];
      }
      __p[1] = v21;
      operator delete(v23);
    }
    uint64_t v24 = v44[0];
    if (v44[0])
    {
      uint64_t v25 = v44[1];
      uint64_t v26 = v44[0];
      if (v44[1] != v44[0])
      {
        do
        {
          uint64_t v28 = *--v25;
          uint64_t v27 = v28;
          void *v25 = 0;
          if (v28) {
            MEMORY[0x21667D390](v27, 0x1000C8077774924);
          }
        }
        while (v25 != v24);
        uint64_t v26 = v44[0];
      }
      v44[1] = v24;
      operator delete(v26);
    }
    if (v40 != v43) {
      free(v40);
    }
  }
}

uint64_t mlir::OpTrait::SingleBlockImplicitTerminator<mlir::tensor::YieldOp>::Impl<mlir::tensor::GenerateOp>::buildTerminator(uint64_t a1, uint64_t a2)
{
  v5[38] = *MEMORY[0x263EF8340];
  mlir::OperationState::OperationState(v5, a2, (uint64_t)"tensor.yield", 12);
  uint64_t v3 = mlir::Operation::create((mlir::Operation *)v5, v2);
  mlir::OperationState::~OperationState((mlir::OperationState *)v5);
  return v3;
}

void llvm::function_ref<void ()(mlir::OpaqueProperties)>::callback_fn<mlir::tensor::detail::InsertSliceOpGenericAdaptorBase::Properties & mlir::OperationState::getOrAddProperties<mlir::tensor::detail::InsertSliceOpGenericAdaptorBase::Properties>(void)::{lambda(mlir::OpaqueProperties)#1}>(uint64_t a1, uint64_t a2)
{
  if (a2) {
    JUMPOUT(0x21667D3C0);
  }
}

__n128 llvm::function_ref<void ()(mlir::OpaqueProperties,mlir::OpaqueProperties)>::callback_fn<mlir::tensor::detail::InsertSliceOpGenericAdaptorBase::Properties & mlir::OperationState::getOrAddProperties<mlir::tensor::detail::InsertSliceOpGenericAdaptorBase::Properties>(void)::{lambda(mlir::OpaqueProperties,mlir::OpaqueProperties)#1}>(uint64_t a1, uint64_t a2, uint64_t a3)
{
  __n128 result = *(__n128 *)a3;
  long long v4 = *(_OWORD *)(a3 + 16);
  *(_OWORD *)(a2 + 28) = *(_OWORD *)(a3 + 28);
  *(__n128 *)a2 = result;
  *(_OWORD *)(a2 + 16) = v4;
  return result;
}

void llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::InsertSliceOp::parse(mlir::OpAsmParser &,mlir::OperationState &)::$_0>(void *a1@<X0>, uint64_t a2@<X8>)
{
  uint64_t v49 = *MEMORY[0x263EF8340];
  (*(void (**)(uint64_t *__return_ptr))(*(void *)*a1 + 24))(&v37);
  if (v37)
  {
    LODWORD(v33) = 3;
    uint64_t v34 = "'";
    uint64_t v35 = 1;
    long long v4 = &v33;
    uint64_t v5 = (char *)v40;
    if (v41 >= v42)
    {
      unint64_t v29 = v41 + 1;
      if (v40 <= &v33 && (char *)v40 + 24 * v41 > (char *)&v33)
      {
        int64_t v31 = (char *)&v33 - (unsigned char *)v40;
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v40, v43, v29, 24);
        uint64_t v5 = (char *)v40;
        long long v4 = (void ***)((char *)v40 + v31);
      }
      else
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v40, v43, v29, 24);
        long long v4 = &v33;
        uint64_t v5 = (char *)v40;
      }
    }
    unint64_t v6 = &v5[24 * v41];
    long long v7 = *(_OWORD *)v4;
    *((void *)v6 + 2) = v4[2];
    *(_OWORD *)unint64_t v6 = v7;
    ++v41;
  }
  unint64_t v33 = *(void ***)(*(void *)(a1[2] + 8) + 8);
  AttrData = (void **)mlir::OpaqueAttr::getAttrData((mlir::OpaqueAttr *)&v33);
  uint64_t v10 = v37;
  if (v37)
  {
    __int16 v36 = 261;
    unint64_t v33 = AttrData;
    uint64_t v34 = v9;
    mlir::Diagnostic::operator<<((uint64_t)&v38, &v33);
    uint64_t v10 = v37;
    if (v37)
    {
      LODWORD(v33) = 3;
      uint64_t v34 = "' op ";
      uint64_t v35 = 5;
      uint64_t v11 = &v33;
      uint64_t v12 = (char *)v40;
      if (v41 >= v42)
      {
        unint64_t v30 = v41 + 1;
        if (v40 <= &v33 && (char *)v40 + 24 * v41 > (char *)&v33)
        {
          int64_t v32 = (char *)&v33 - (unsigned char *)v40;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v40, v43, v30, 24);
          uint64_t v12 = (char *)v40;
          uint64_t v11 = (void ***)((char *)v40 + v32);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v40, v43, v30, 24);
          uint64_t v11 = &v33;
          uint64_t v12 = (char *)v40;
        }
      }
      uint64_t v13 = &v12[24 * v41];
      long long v14 = *(_OWORD *)v11;
      *((void *)v13 + 2) = v11[2];
      *(_OWORD *)uint64_t v13 = v14;
      ++v41;
      uint64_t v10 = v37;
    }
  }
  *(void *)a2 = v10;
  *(unsigned char *)(a2 + 8) = 0;
  *(unsigned char *)(a2 + 184) = 0;
  if (v48)
  {
    *(void *)(a2 + 8) = v38;
    unint64_t v15 = v41;
    *(_DWORD *)(a2 + 16) = v39;
    uint64_t v16 = (void *)(a2 + 40);
    *(void *)(a2 + 24) = a2 + 40;
    *(void *)(a2 + 32) = 0x400000000;
    if (!v15 || &v37 == (uint64_t *)a2)
    {
      int v19 = 1;
      goto LABEL_21;
    }
    unint64_t v17 = v43;
    if (v40 != v43)
    {
      *(void *)(a2 + 24) = v40;
      unsigned int v18 = v42;
      *(_DWORD *)(a2 + 32) = v15;
      *(_DWORD *)(a2 + 36) = v18;
      uint64_t v40 = v43;
      unsigned int v42 = 0;
      int v19 = 1;
LABEL_20:
      unsigned int v41 = 0;
LABEL_21:
      *(_OWORD *)(a2 + 136) = *(_OWORD *)v44;
      *(void *)(a2 + 152) = v45;
      v44[0] = 0;
      v44[1] = 0;
      *(_OWORD *)(a2 + 160) = *(_OWORD *)__p;
      *(void *)(a2 + 176) = v47;
      uint64_t v45 = 0;
      __p[0] = 0;
      __p[1] = 0;
      uint64_t v47 = 0;
      *(unsigned char *)(a2 + 184) = 1;
      if (v19)
      {
        if (v40 != v43) {
          free(v40);
        }
        unsigned __int8 v48 = 0;
      }
      goto LABEL_25;
    }
    if (v15 < 5)
    {
      unint64_t v20 = v15;
    }
    else
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod(a2 + 24, (void *)(a2 + 40), v15, 24);
      unint64_t v20 = v41;
      if (!v41)
      {
LABEL_19:
        *(_DWORD *)(a2 + 32) = v15;
        int v19 = v48;
        goto LABEL_20;
      }
      unint64_t v17 = v40;
      uint64_t v16 = *(void **)(a2 + 24);
    }
    memcpy(v16, v17, 24 * v20);
    goto LABEL_19;
  }
LABEL_25:
  mlir::InFlightDiagnostic::abandon(&v37);
  if (v37) {
    mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v37);
  }
  if (v48)
  {
    char v21 = __p[0];
    if (__p[0])
    {
      uint64_t v22 = __p[1];
      uint64_t v23 = __p[0];
      if (__p[1] != __p[0])
      {
        do
          uint64_t v22 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v22 - 1);
        while (v22 != v21);
        uint64_t v23 = __p[0];
      }
      __p[1] = v21;
      operator delete(v23);
    }
    uint64_t v24 = v44[0];
    if (v44[0])
    {
      uint64_t v25 = v44[1];
      uint64_t v26 = v44[0];
      if (v44[1] != v44[0])
      {
        do
        {
          uint64_t v28 = *--v25;
          uint64_t v27 = v28;
          void *v25 = 0;
          if (v28) {
            MEMORY[0x21667D390](v27, 0x1000C8077774924);
          }
        }
        while (v25 != v24);
        uint64_t v26 = v44[0];
      }
      v44[1] = v24;
      operator delete(v26);
    }
    if (v40 != v43) {
      free(v40);
    }
  }
}

void llvm::function_ref<void ()(mlir::OpaqueProperties)>::callback_fn<mlir::tensor::detail::PackOpGenericAdaptorBase::Properties & mlir::OperationState::getOrAddProperties<mlir::tensor::detail::PackOpGenericAdaptorBase::Properties>(void)::{lambda(mlir::OpaqueProperties)#1}>(uint64_t a1, uint64_t a2)
{
  if (a2) {
    JUMPOUT(0x21667D3C0);
  }
}

__n128 llvm::function_ref<void ()(mlir::OpaqueProperties,mlir::OpaqueProperties)>::callback_fn<mlir::tensor::detail::PackOpGenericAdaptorBase::Properties & mlir::OperationState::getOrAddProperties<mlir::tensor::detail::PackOpGenericAdaptorBase::Properties>(void)::{lambda(mlir::OpaqueProperties,mlir::OpaqueProperties)#1}>(uint64_t a1, uint64_t a2, uint64_t a3)
{
  __n128 result = *(__n128 *)a3;
  long long v4 = *(_OWORD *)(a3 + 16);
  *(void *)(a2 + 32) = *(void *)(a3 + 32);
  *(__n128 *)a2 = result;
  *(_OWORD *)(a2 + 16) = v4;
  return result;
}

void *mlir::RewritePatternSet::add<mlir::tensor::PackOp>(mlir::LogicalResult (*)(mlir::tensor::PackOp,mlir::PatternRewriter &),mlir::PatternBenefit,llvm::ArrayRef<llvm::StringRef>)::FnPattern::~FnPattern(void *a1)
{
  uint64_t v2 = (void *)a1[10];
  if (v2 != a1 + 12) {
    free(v2);
  }
  uint64_t v3 = (void *)a1[4];
  if (v3 != a1 + 6) {
    free(v3);
  }
  return a1;
}

void mlir::RewritePatternSet::add<mlir::tensor::PackOp>(mlir::LogicalResult (*)(mlir::tensor::PackOp,mlir::PatternRewriter &),mlir::PatternBenefit,llvm::ArrayRef<llvm::StringRef>)::FnPattern::~FnPattern(void *a1)
{
  uint64_t v2 = (void *)a1[10];
  if (v2 != a1 + 12) {
    free(v2);
  }
  uint64_t v3 = (void *)a1[4];
  if (v3 != a1 + 6) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t mlir::RewritePatternSet::add<mlir::tensor::PackOp>(mlir::LogicalResult (*)(mlir::tensor::PackOp,mlir::PatternRewriter &),mlir::PatternBenefit,llvm::ArrayRef<llvm::StringRef>)::FnPattern::matchAndRewrite(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return (*(uint64_t (**)(uint64_t, uint64_t))(a1 + 96))(a2, a3);
}

void llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::PackOp::parse(mlir::OpAsmParser &,mlir::OperationState &)::$_0>(void *a1@<X0>, uint64_t a2@<X8>)
{
  uint64_t v49 = *MEMORY[0x263EF8340];
  (*(void (**)(uint64_t *__return_ptr))(*(void *)*a1 + 24))(&v37);
  if (v37)
  {
    LODWORD(v33) = 3;
    uint64_t v34 = "'";
    uint64_t v35 = 1;
    long long v4 = &v33;
    uint64_t v5 = (char *)v40;
    if (v41 >= v42)
    {
      unint64_t v29 = v41 + 1;
      if (v40 <= &v33 && (char *)v40 + 24 * v41 > (char *)&v33)
      {
        int64_t v31 = (char *)&v33 - (unsigned char *)v40;
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v40, v43, v29, 24);
        uint64_t v5 = (char *)v40;
        long long v4 = (void ***)((char *)v40 + v31);
      }
      else
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v40, v43, v29, 24);
        long long v4 = &v33;
        uint64_t v5 = (char *)v40;
      }
    }
    unint64_t v6 = &v5[24 * v41];
    long long v7 = *(_OWORD *)v4;
    *((void *)v6 + 2) = v4[2];
    *(_OWORD *)unint64_t v6 = v7;
    ++v41;
  }
  unint64_t v33 = *(void ***)(*(void *)(a1[2] + 8) + 8);
  AttrData = (void **)mlir::OpaqueAttr::getAttrData((mlir::OpaqueAttr *)&v33);
  uint64_t v10 = v37;
  if (v37)
  {
    __int16 v36 = 261;
    unint64_t v33 = AttrData;
    uint64_t v34 = v9;
    mlir::Diagnostic::operator<<((uint64_t)&v38, &v33);
    uint64_t v10 = v37;
    if (v37)
    {
      LODWORD(v33) = 3;
      uint64_t v34 = "' op ";
      uint64_t v35 = 5;
      uint64_t v11 = &v33;
      uint64_t v12 = (char *)v40;
      if (v41 >= v42)
      {
        unint64_t v30 = v41 + 1;
        if (v40 <= &v33 && (char *)v40 + 24 * v41 > (char *)&v33)
        {
          int64_t v32 = (char *)&v33 - (unsigned char *)v40;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v40, v43, v30, 24);
          uint64_t v12 = (char *)v40;
          uint64_t v11 = (void ***)((char *)v40 + v32);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v40, v43, v30, 24);
          uint64_t v11 = &v33;
          uint64_t v12 = (char *)v40;
        }
      }
      uint64_t v13 = &v12[24 * v41];
      long long v14 = *(_OWORD *)v11;
      *((void *)v13 + 2) = v11[2];
      *(_OWORD *)uint64_t v13 = v14;
      ++v41;
      uint64_t v10 = v37;
    }
  }
  *(void *)a2 = v10;
  *(unsigned char *)(a2 + 8) = 0;
  *(unsigned char *)(a2 + 184) = 0;
  if (v48)
  {
    *(void *)(a2 + 8) = v38;
    unint64_t v15 = v41;
    *(_DWORD *)(a2 + 16) = v39;
    uint64_t v16 = (void *)(a2 + 40);
    *(void *)(a2 + 24) = a2 + 40;
    *(void *)(a2 + 32) = 0x400000000;
    if (!v15 || &v37 == (uint64_t *)a2)
    {
      int v19 = 1;
      goto LABEL_21;
    }
    unint64_t v17 = v43;
    if (v40 != v43)
    {
      *(void *)(a2 + 24) = v40;
      unsigned int v18 = v42;
      *(_DWORD *)(a2 + 32) = v15;
      *(_DWORD *)(a2 + 36) = v18;
      uint64_t v40 = v43;
      unsigned int v42 = 0;
      int v19 = 1;
LABEL_20:
      unsigned int v41 = 0;
LABEL_21:
      *(_OWORD *)(a2 + 136) = *(_OWORD *)v44;
      *(void *)(a2 + 152) = v45;
      v44[0] = 0;
      v44[1] = 0;
      *(_OWORD *)(a2 + 160) = *(_OWORD *)__p;
      *(void *)(a2 + 176) = v47;
      uint64_t v45 = 0;
      __p[0] = 0;
      __p[1] = 0;
      uint64_t v47 = 0;
      *(unsigned char *)(a2 + 184) = 1;
      if (v19)
      {
        if (v40 != v43) {
          free(v40);
        }
        unsigned __int8 v48 = 0;
      }
      goto LABEL_25;
    }
    if (v15 < 5)
    {
      unint64_t v20 = v15;
    }
    else
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod(a2 + 24, (void *)(a2 + 40), v15, 24);
      unint64_t v20 = v41;
      if (!v41)
      {
LABEL_19:
        *(_DWORD *)(a2 + 32) = v15;
        int v19 = v48;
        goto LABEL_20;
      }
      unint64_t v17 = v40;
      uint64_t v16 = *(void **)(a2 + 24);
    }
    memcpy(v16, v17, 24 * v20);
    goto LABEL_19;
  }
LABEL_25:
  mlir::InFlightDiagnostic::abandon(&v37);
  if (v37) {
    mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v37);
  }
  if (v48)
  {
    char v21 = __p[0];
    if (__p[0])
    {
      uint64_t v22 = __p[1];
      uint64_t v23 = __p[0];
      if (__p[1] != __p[0])
      {
        do
          uint64_t v22 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v22 - 1);
        while (v22 != v21);
        uint64_t v23 = __p[0];
      }
      __p[1] = v21;
      operator delete(v23);
    }
    uint64_t v24 = v44[0];
    if (v44[0])
    {
      uint64_t v25 = v44[1];
      uint64_t v26 = v44[0];
      if (v44[1] != v44[0])
      {
        do
        {
          uint64_t v28 = *--v25;
          uint64_t v27 = v28;
          void *v25 = 0;
          if (v28) {
            MEMORY[0x21667D390](v27, 0x1000C8077774924);
          }
        }
        while (v25 != v24);
        uint64_t v26 = v44[0];
      }
      v44[1] = v24;
      operator delete(v26);
    }
    if (v40 != v43) {
      free(v40);
    }
  }
}

void llvm::function_ref<void ()(mlir::OpaqueProperties)>::callback_fn<mlir::tensor::detail::PadOpGenericAdaptorBase::Properties & mlir::OperationState::getOrAddProperties<mlir::tensor::detail::PadOpGenericAdaptorBase::Properties>(void)::{lambda(mlir::OpaqueProperties)#1}>(uint64_t a1, uint64_t a2)
{
  if (a2) {
    JUMPOUT(0x21667D3C0);
  }
}

__n128 llvm::function_ref<void ()(mlir::OpaqueProperties,mlir::OpaqueProperties)>::callback_fn<mlir::tensor::detail::PadOpGenericAdaptorBase::Properties & mlir::OperationState::getOrAddProperties<mlir::tensor::detail::PadOpGenericAdaptorBase::Properties>(void)::{lambda(mlir::OpaqueProperties,mlir::OpaqueProperties)#1}>(uint64_t a1, uint64_t a2, uint64_t a3)
{
  __n128 result = *(__n128 *)a3;
  long long v4 = *(_OWORD *)(a3 + 16);
  *(_DWORD *)(a2 + 32) = *(_DWORD *)(a3 + 32);
  *(__n128 *)a2 = result;
  *(_OWORD *)(a2 + 16) = v4;
  return result;
}

uint64_t mlir::OpTrait::SingleBlockImplicitTerminator<mlir::tensor::YieldOp>::Impl<mlir::tensor::PadOp>::buildTerminator(uint64_t a1, uint64_t a2)
{
  v5[38] = *MEMORY[0x263EF8340];
  mlir::OperationState::OperationState(v5, a2, (uint64_t)"tensor.yield", 12);
  uint64_t v3 = mlir::Operation::create((mlir::Operation *)v5, v2);
  mlir::OperationState::~OperationState((mlir::OperationState *)v5);
  return v3;
}

void llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::PadOp::parse(mlir::OpAsmParser &,mlir::OperationState &)::$_0>(void *a1@<X0>, uint64_t a2@<X8>)
{
  uint64_t v49 = *MEMORY[0x263EF8340];
  (*(void (**)(uint64_t *__return_ptr))(*(void *)*a1 + 24))(&v37);
  if (v37)
  {
    LODWORD(v33) = 3;
    uint64_t v34 = "'";
    uint64_t v35 = 1;
    long long v4 = &v33;
    uint64_t v5 = (char *)v40;
    if (v41 >= v42)
    {
      unint64_t v29 = v41 + 1;
      if (v40 <= &v33 && (char *)v40 + 24 * v41 > (char *)&v33)
      {
        int64_t v31 = (char *)&v33 - (unsigned char *)v40;
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v40, v43, v29, 24);
        uint64_t v5 = (char *)v40;
        long long v4 = (void ***)((char *)v40 + v31);
      }
      else
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v40, v43, v29, 24);
        long long v4 = &v33;
        uint64_t v5 = (char *)v40;
      }
    }
    unint64_t v6 = &v5[24 * v41];
    long long v7 = *(_OWORD *)v4;
    *((void *)v6 + 2) = v4[2];
    *(_OWORD *)unint64_t v6 = v7;
    ++v41;
  }
  unint64_t v33 = *(void ***)(*(void *)(a1[2] + 8) + 8);
  AttrData = (void **)mlir::OpaqueAttr::getAttrData((mlir::OpaqueAttr *)&v33);
  uint64_t v10 = v37;
  if (v37)
  {
    __int16 v36 = 261;
    unint64_t v33 = AttrData;
    uint64_t v34 = v9;
    mlir::Diagnostic::operator<<((uint64_t)&v38, &v33);
    uint64_t v10 = v37;
    if (v37)
    {
      LODWORD(v33) = 3;
      uint64_t v34 = "' op ";
      uint64_t v35 = 5;
      uint64_t v11 = &v33;
      uint64_t v12 = (char *)v40;
      if (v41 >= v42)
      {
        unint64_t v30 = v41 + 1;
        if (v40 <= &v33 && (char *)v40 + 24 * v41 > (char *)&v33)
        {
          int64_t v32 = (char *)&v33 - (unsigned char *)v40;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v40, v43, v30, 24);
          uint64_t v12 = (char *)v40;
          uint64_t v11 = (void ***)((char *)v40 + v32);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v40, v43, v30, 24);
          uint64_t v11 = &v33;
          uint64_t v12 = (char *)v40;
        }
      }
      uint64_t v13 = &v12[24 * v41];
      long long v14 = *(_OWORD *)v11;
      *((void *)v13 + 2) = v11[2];
      *(_OWORD *)uint64_t v13 = v14;
      ++v41;
      uint64_t v10 = v37;
    }
  }
  *(void *)a2 = v10;
  *(unsigned char *)(a2 + 8) = 0;
  *(unsigned char *)(a2 + 184) = 0;
  if (v48)
  {
    *(void *)(a2 + 8) = v38;
    unint64_t v15 = v41;
    *(_DWORD *)(a2 + 16) = v39;
    uint64_t v16 = (void *)(a2 + 40);
    *(void *)(a2 + 24) = a2 + 40;
    *(void *)(a2 + 32) = 0x400000000;
    if (!v15 || &v37 == (uint64_t *)a2)
    {
      int v19 = 1;
      goto LABEL_21;
    }
    unint64_t v17 = v43;
    if (v40 != v43)
    {
      *(void *)(a2 + 24) = v40;
      unsigned int v18 = v42;
      *(_DWORD *)(a2 + 32) = v15;
      *(_DWORD *)(a2 + 36) = v18;
      uint64_t v40 = v43;
      unsigned int v42 = 0;
      int v19 = 1;
LABEL_20:
      unsigned int v41 = 0;
LABEL_21:
      *(_OWORD *)(a2 + 136) = *(_OWORD *)v44;
      *(void *)(a2 + 152) = v45;
      v44[0] = 0;
      v44[1] = 0;
      *(_OWORD *)(a2 + 160) = *(_OWORD *)__p;
      *(void *)(a2 + 176) = v47;
      uint64_t v45 = 0;
      __p[0] = 0;
      __p[1] = 0;
      uint64_t v47 = 0;
      *(unsigned char *)(a2 + 184) = 1;
      if (v19)
      {
        if (v40 != v43) {
          free(v40);
        }
        unsigned __int8 v48 = 0;
      }
      goto LABEL_25;
    }
    if (v15 < 5)
    {
      unint64_t v20 = v15;
    }
    else
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod(a2 + 24, (void *)(a2 + 40), v15, 24);
      unint64_t v20 = v41;
      if (!v41)
      {
LABEL_19:
        *(_DWORD *)(a2 + 32) = v15;
        int v19 = v48;
        goto LABEL_20;
      }
      unint64_t v17 = v40;
      uint64_t v16 = *(void **)(a2 + 24);
    }
    memcpy(v16, v17, 24 * v20);
    goto LABEL_19;
  }
LABEL_25:
  mlir::InFlightDiagnostic::abandon(&v37);
  if (v37) {
    mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v37);
  }
  if (v48)
  {
    char v21 = __p[0];
    if (__p[0])
    {
      uint64_t v22 = __p[1];
      uint64_t v23 = __p[0];
      if (__p[1] != __p[0])
      {
        do
          uint64_t v22 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v22 - 1);
        while (v22 != v21);
        uint64_t v23 = __p[0];
      }
      __p[1] = v21;
      operator delete(v23);
    }
    uint64_t v24 = v44[0];
    if (v44[0])
    {
      uint64_t v25 = v44[1];
      uint64_t v26 = v44[0];
      if (v44[1] != v44[0])
      {
        do
        {
          uint64_t v28 = *--v25;
          uint64_t v27 = v28;
          void *v25 = 0;
          if (v28) {
            MEMORY[0x21667D390](v27, 0x1000C8077774924);
          }
        }
        while (v25 != v24);
        uint64_t v26 = v44[0];
      }
      v44[1] = v24;
      operator delete(v26);
    }
    if (v40 != v43) {
      free(v40);
    }
  }
}

void llvm::function_ref<void ()(mlir::OpaqueProperties)>::callback_fn<mlir::tensor::detail::ParallelInsertSliceOpGenericAdaptorBase::Properties & mlir::OperationState::getOrAddProperties<mlir::tensor::detail::ParallelInsertSliceOpGenericAdaptorBase::Properties>(void)::{lambda(mlir::OpaqueProperties)#1}>(uint64_t a1, uint64_t a2)
{
  if (a2) {
    JUMPOUT(0x21667D3C0);
  }
}

__n128 llvm::function_ref<void ()(mlir::OpaqueProperties,mlir::OpaqueProperties)>::callback_fn<mlir::tensor::detail::ParallelInsertSliceOpGenericAdaptorBase::Properties & mlir::OperationState::getOrAddProperties<mlir::tensor::detail::ParallelInsertSliceOpGenericAdaptorBase::Properties>(void)::{lambda(mlir::OpaqueProperties,mlir::OpaqueProperties)#1}>(uint64_t a1, uint64_t a2, uint64_t a3)
{
  __n128 result = *(__n128 *)a3;
  long long v4 = *(_OWORD *)(a3 + 16);
  *(_OWORD *)(a2 + 28) = *(_OWORD *)(a3 + 28);
  *(__n128 *)a2 = result;
  *(_OWORD *)(a2 + 16) = v4;
  return result;
}

void llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::ParallelInsertSliceOp::parse(mlir::OpAsmParser &,mlir::OperationState &)::$_0>(void *a1@<X0>, uint64_t a2@<X8>)
{
  uint64_t v49 = *MEMORY[0x263EF8340];
  (*(void (**)(uint64_t *__return_ptr))(*(void *)*a1 + 24))(&v37);
  if (v37)
  {
    LODWORD(v33) = 3;
    uint64_t v34 = "'";
    uint64_t v35 = 1;
    long long v4 = &v33;
    uint64_t v5 = (char *)v40;
    if (v41 >= v42)
    {
      unint64_t v29 = v41 + 1;
      if (v40 <= &v33 && (char *)v40 + 24 * v41 > (char *)&v33)
      {
        int64_t v31 = (char *)&v33 - (unsigned char *)v40;
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v40, v43, v29, 24);
        uint64_t v5 = (char *)v40;
        long long v4 = (void ***)((char *)v40 + v31);
      }
      else
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v40, v43, v29, 24);
        long long v4 = &v33;
        uint64_t v5 = (char *)v40;
      }
    }
    unint64_t v6 = &v5[24 * v41];
    long long v7 = *(_OWORD *)v4;
    *((void *)v6 + 2) = v4[2];
    *(_OWORD *)unint64_t v6 = v7;
    ++v41;
  }
  unint64_t v33 = *(void ***)(*(void *)(a1[2] + 8) + 8);
  AttrData = (void **)mlir::OpaqueAttr::getAttrData((mlir::OpaqueAttr *)&v33);
  uint64_t v10 = v37;
  if (v37)
  {
    __int16 v36 = 261;
    unint64_t v33 = AttrData;
    uint64_t v34 = v9;
    mlir::Diagnostic::operator<<((uint64_t)&v38, &v33);
    uint64_t v10 = v37;
    if (v37)
    {
      LODWORD(v33) = 3;
      uint64_t v34 = "' op ";
      uint64_t v35 = 5;
      uint64_t v11 = &v33;
      uint64_t v12 = (char *)v40;
      if (v41 >= v42)
      {
        unint64_t v30 = v41 + 1;
        if (v40 <= &v33 && (char *)v40 + 24 * v41 > (char *)&v33)
        {
          int64_t v32 = (char *)&v33 - (unsigned char *)v40;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v40, v43, v30, 24);
          uint64_t v12 = (char *)v40;
          uint64_t v11 = (void ***)((char *)v40 + v32);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v40, v43, v30, 24);
          uint64_t v11 = &v33;
          uint64_t v12 = (char *)v40;
        }
      }
      uint64_t v13 = &v12[24 * v41];
      long long v14 = *(_OWORD *)v11;
      *((void *)v13 + 2) = v11[2];
      *(_OWORD *)uint64_t v13 = v14;
      ++v41;
      uint64_t v10 = v37;
    }
  }
  *(void *)a2 = v10;
  *(unsigned char *)(a2 + 8) = 0;
  *(unsigned char *)(a2 + 184) = 0;
  if (v48)
  {
    *(void *)(a2 + 8) = v38;
    unint64_t v15 = v41;
    *(_DWORD *)(a2 + 16) = v39;
    uint64_t v16 = (void *)(a2 + 40);
    *(void *)(a2 + 24) = a2 + 40;
    *(void *)(a2 + 32) = 0x400000000;
    if (!v15 || &v37 == (uint64_t *)a2)
    {
      int v19 = 1;
      goto LABEL_21;
    }
    unint64_t v17 = v43;
    if (v40 != v43)
    {
      *(void *)(a2 + 24) = v40;
      unsigned int v18 = v42;
      *(_DWORD *)(a2 + 32) = v15;
      *(_DWORD *)(a2 + 36) = v18;
      uint64_t v40 = v43;
      unsigned int v42 = 0;
      int v19 = 1;
LABEL_20:
      unsigned int v41 = 0;
LABEL_21:
      *(_OWORD *)(a2 + 136) = *(_OWORD *)v44;
      *(void *)(a2 + 152) = v45;
      v44[0] = 0;
      v44[1] = 0;
      *(_OWORD *)(a2 + 160) = *(_OWORD *)__p;
      *(void *)(a2 + 176) = v47;
      uint64_t v45 = 0;
      __p[0] = 0;
      __p[1] = 0;
      uint64_t v47 = 0;
      *(unsigned char *)(a2 + 184) = 1;
      if (v19)
      {
        if (v40 != v43) {
          free(v40);
        }
        unsigned __int8 v48 = 0;
      }
      goto LABEL_25;
    }
    if (v15 < 5)
    {
      unint64_t v20 = v15;
    }
    else
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod(a2 + 24, (void *)(a2 + 40), v15, 24);
      unint64_t v20 = v41;
      if (!v41)
      {
LABEL_19:
        *(_DWORD *)(a2 + 32) = v15;
        int v19 = v48;
        goto LABEL_20;
      }
      unint64_t v17 = v40;
      uint64_t v16 = *(void **)(a2 + 24);
    }
    memcpy(v16, v17, 24 * v20);
    goto LABEL_19;
  }
LABEL_25:
  mlir::InFlightDiagnostic::abandon(&v37);
  if (v37) {
    mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v37);
  }
  if (v48)
  {
    char v21 = __p[0];
    if (__p[0])
    {
      uint64_t v22 = __p[1];
      uint64_t v23 = __p[0];
      if (__p[1] != __p[0])
      {
        do
          uint64_t v22 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v22 - 1);
        while (v22 != v21);
        uint64_t v23 = __p[0];
      }
      __p[1] = v21;
      operator delete(v23);
    }
    uint64_t v24 = v44[0];
    if (v44[0])
    {
      uint64_t v25 = v44[1];
      uint64_t v26 = v44[0];
      if (v44[1] != v44[0])
      {
        do
        {
          uint64_t v28 = *--v25;
          uint64_t v27 = v28;
          void *v25 = 0;
          if (v28) {
            MEMORY[0x21667D390](v27, 0x1000C8077774924);
          }
        }
        while (v25 != v24);
        uint64_t v26 = v44[0];
      }
      v44[1] = v24;
      operator delete(v26);
    }
    if (v40 != v43) {
      free(v40);
    }
  }
}

void llvm::function_ref<void ()(mlir::OpaqueProperties)>::callback_fn<mlir::tensor::detail::ScatterOpGenericAdaptorBase::Properties & mlir::OperationState::getOrAddProperties<mlir::tensor::detail::ScatterOpGenericAdaptorBase::Properties>(void)::{lambda(mlir::OpaqueProperties)#1}>(uint64_t a1, uint64_t a2)
{
  if (a2) {
    JUMPOUT(0x21667D3C0);
  }
}

__n128 llvm::function_ref<void ()(mlir::OpaqueProperties,mlir::OpaqueProperties)>::callback_fn<mlir::tensor::detail::ScatterOpGenericAdaptorBase::Properties & mlir::OperationState::getOrAddProperties<mlir::tensor::detail::ScatterOpGenericAdaptorBase::Properties>(void)::{lambda(mlir::OpaqueProperties,mlir::OpaqueProperties)#1}>(uint64_t a1, __n128 *a2, __n128 *a3)
{
  __n128 result = *a3;
  *a2 = *a3;
  return result;
}

void llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::ScatterOp::parse(mlir::OpAsmParser &,mlir::OperationState &)::$_0>(void *a1@<X0>, uint64_t a2@<X8>)
{
  uint64_t v49 = *MEMORY[0x263EF8340];
  (*(void (**)(uint64_t *__return_ptr))(*(void *)*a1 + 24))(&v37);
  if (v37)
  {
    LODWORD(v33) = 3;
    uint64_t v34 = "'";
    uint64_t v35 = 1;
    long long v4 = &v33;
    uint64_t v5 = (char *)v40;
    if (v41 >= v42)
    {
      unint64_t v29 = v41 + 1;
      if (v40 <= &v33 && (char *)v40 + 24 * v41 > (char *)&v33)
      {
        int64_t v31 = (char *)&v33 - (unsigned char *)v40;
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v40, v43, v29, 24);
        uint64_t v5 = (char *)v40;
        long long v4 = (void ***)((char *)v40 + v31);
      }
      else
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v40, v43, v29, 24);
        long long v4 = &v33;
        uint64_t v5 = (char *)v40;
      }
    }
    unint64_t v6 = &v5[24 * v41];
    long long v7 = *(_OWORD *)v4;
    *((void *)v6 + 2) = v4[2];
    *(_OWORD *)unint64_t v6 = v7;
    ++v41;
  }
  unint64_t v33 = *(void ***)(*(void *)(a1[2] + 8) + 8);
  AttrData = (void **)mlir::OpaqueAttr::getAttrData((mlir::OpaqueAttr *)&v33);
  uint64_t v10 = v37;
  if (v37)
  {
    __int16 v36 = 261;
    unint64_t v33 = AttrData;
    uint64_t v34 = v9;
    mlir::Diagnostic::operator<<((uint64_t)&v38, &v33);
    uint64_t v10 = v37;
    if (v37)
    {
      LODWORD(v33) = 3;
      uint64_t v34 = "' op ";
      uint64_t v35 = 5;
      uint64_t v11 = &v33;
      uint64_t v12 = (char *)v40;
      if (v41 >= v42)
      {
        unint64_t v30 = v41 + 1;
        if (v40 <= &v33 && (char *)v40 + 24 * v41 > (char *)&v33)
        {
          int64_t v32 = (char *)&v33 - (unsigned char *)v40;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v40, v43, v30, 24);
          uint64_t v12 = (char *)v40;
          uint64_t v11 = (void ***)((char *)v40 + v32);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v40, v43, v30, 24);
          uint64_t v11 = &v33;
          uint64_t v12 = (char *)v40;
        }
      }
      uint64_t v13 = &v12[24 * v41];
      long long v14 = *(_OWORD *)v11;
      *((void *)v13 + 2) = v11[2];
      *(_OWORD *)uint64_t v13 = v14;
      ++v41;
      uint64_t v10 = v37;
    }
  }
  *(void *)a2 = v10;
  *(unsigned char *)(a2 + 8) = 0;
  *(unsigned char *)(a2 + 184) = 0;
  if (v48)
  {
    *(void *)(a2 + 8) = v38;
    unint64_t v15 = v41;
    *(_DWORD *)(a2 + 16) = v39;
    uint64_t v16 = (void *)(a2 + 40);
    *(void *)(a2 + 24) = a2 + 40;
    *(void *)(a2 + 32) = 0x400000000;
    if (!v15 || &v37 == (uint64_t *)a2)
    {
      int v19 = 1;
      goto LABEL_21;
    }
    unint64_t v17 = v43;
    if (v40 != v43)
    {
      *(void *)(a2 + 24) = v40;
      unsigned int v18 = v42;
      *(_DWORD *)(a2 + 32) = v15;
      *(_DWORD *)(a2 + 36) = v18;
      uint64_t v40 = v43;
      unsigned int v42 = 0;
      int v19 = 1;
LABEL_20:
      unsigned int v41 = 0;
LABEL_21:
      *(_OWORD *)(a2 + 136) = *(_OWORD *)v44;
      *(void *)(a2 + 152) = v45;
      v44[0] = 0;
      v44[1] = 0;
      *(_OWORD *)(a2 + 160) = *(_OWORD *)__p;
      *(void *)(a2 + 176) = v47;
      uint64_t v45 = 0;
      __p[0] = 0;
      __p[1] = 0;
      uint64_t v47 = 0;
      *(unsigned char *)(a2 + 184) = 1;
      if (v19)
      {
        if (v40 != v43) {
          free(v40);
        }
        unsigned __int8 v48 = 0;
      }
      goto LABEL_25;
    }
    if (v15 < 5)
    {
      unint64_t v20 = v15;
    }
    else
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod(a2 + 24, (void *)(a2 + 40), v15, 24);
      unint64_t v20 = v41;
      if (!v41)
      {
LABEL_19:
        *(_DWORD *)(a2 + 32) = v15;
        int v19 = v48;
        goto LABEL_20;
      }
      unint64_t v17 = v40;
      uint64_t v16 = *(void **)(a2 + 24);
    }
    memcpy(v16, v17, 24 * v20);
    goto LABEL_19;
  }
LABEL_25:
  mlir::InFlightDiagnostic::abandon(&v37);
  if (v37) {
    mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v37);
  }
  if (v48)
  {
    char v21 = __p[0];
    if (__p[0])
    {
      uint64_t v22 = __p[1];
      uint64_t v23 = __p[0];
      if (__p[1] != __p[0])
      {
        do
          uint64_t v22 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v22 - 1);
        while (v22 != v21);
        uint64_t v23 = __p[0];
      }
      __p[1] = v21;
      operator delete(v23);
    }
    uint64_t v24 = v44[0];
    if (v44[0])
    {
      uint64_t v25 = v44[1];
      uint64_t v26 = v44[0];
      if (v44[1] != v44[0])
      {
        do
        {
          uint64_t v28 = *--v25;
          uint64_t v27 = v28;
          void *v25 = 0;
          if (v28) {
            MEMORY[0x21667D390](v27, 0x1000C8077774924);
          }
        }
        while (v25 != v24);
        uint64_t v26 = v44[0];
      }
      v44[1] = v24;
      operator delete(v26);
    }
    if (v40 != v43) {
      free(v40);
    }
  }
}

void llvm::function_ref<void ()(mlir::OpaqueProperties)>::callback_fn<mlir::tensor::detail::UnPackOpGenericAdaptorBase::Properties & mlir::OperationState::getOrAddProperties<mlir::tensor::detail::UnPackOpGenericAdaptorBase::Properties>(void)::{lambda(mlir::OpaqueProperties)#1}>(uint64_t a1, uint64_t a2)
{
  if (a2) {
    JUMPOUT(0x21667D3C0);
  }
}

__n128 llvm::function_ref<void ()(mlir::OpaqueProperties,mlir::OpaqueProperties)>::callback_fn<mlir::tensor::detail::UnPackOpGenericAdaptorBase::Properties & mlir::OperationState::getOrAddProperties<mlir::tensor::detail::UnPackOpGenericAdaptorBase::Properties>(void)::{lambda(mlir::OpaqueProperties,mlir::OpaqueProperties)#1}>(uint64_t a1, __n128 *a2, __n128 *a3)
{
  __n128 result = *a3;
  a2[1].n128_u64[0] = a3[1].n128_u64[0];
  *a2 = result;
  return result;
}

void *mlir::RewritePatternSet::add<mlir::tensor::UnPackOp>(mlir::LogicalResult (*)(mlir::tensor::UnPackOp,mlir::PatternRewriter &),mlir::PatternBenefit,llvm::ArrayRef<llvm::StringRef>)::FnPattern::~FnPattern(void *a1)
{
  uint64_t v2 = (void *)a1[10];
  if (v2 != a1 + 12) {
    free(v2);
  }
  uint64_t v3 = (void *)a1[4];
  if (v3 != a1 + 6) {
    free(v3);
  }
  return a1;
}

void mlir::RewritePatternSet::add<mlir::tensor::UnPackOp>(mlir::LogicalResult (*)(mlir::tensor::UnPackOp,mlir::PatternRewriter &),mlir::PatternBenefit,llvm::ArrayRef<llvm::StringRef>)::FnPattern::~FnPattern(void *a1)
{
  uint64_t v2 = (void *)a1[10];
  if (v2 != a1 + 12) {
    free(v2);
  }
  uint64_t v3 = (void *)a1[4];
  if (v3 != a1 + 6) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::tensor::UnPackOp>::rewrite(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 48))();
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::tensor::UnPackOp>::match(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 56))();
}

uint64_t mlir::detail::OpOrInterfaceRewritePatternBase<mlir::tensor::UnPackOp>::matchAndRewrite(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 64))();
}

uint64_t mlir::RewritePatternSet::add<mlir::tensor::UnPackOp>(mlir::LogicalResult (*)(mlir::tensor::UnPackOp,mlir::PatternRewriter &),mlir::PatternBenefit,llvm::ArrayRef<llvm::StringRef>)::FnPattern::matchAndRewrite(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return (*(uint64_t (**)(uint64_t, uint64_t))(a1 + 96))(a2, a3);
}

void llvm::function_ref<mlir::InFlightDiagnostic ()(void)>::callback_fn<mlir::tensor::UnPackOp::parse(mlir::OpAsmParser &,mlir::OperationState &)::$_0>(void *a1@<X0>, uint64_t a2@<X8>)
{
  uint64_t v49 = *MEMORY[0x263EF8340];
  (*(void (**)(uint64_t *__return_ptr))(*(void *)*a1 + 24))(&v37);
  if (v37)
  {
    LODWORD(v33) = 3;
    uint64_t v34 = "'";
    uint64_t v35 = 1;
    long long v4 = &v33;
    uint64_t v5 = (char *)v40;
    if (v41 >= v42)
    {
      unint64_t v29 = v41 + 1;
      if (v40 <= &v33 && (char *)v40 + 24 * v41 > (char *)&v33)
      {
        int64_t v31 = (char *)&v33 - (unsigned char *)v40;
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v40, v43, v29, 24);
        uint64_t v5 = (char *)v40;
        long long v4 = (void ***)((char *)v40 + v31);
      }
      else
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v40, v43, v29, 24);
        long long v4 = &v33;
        uint64_t v5 = (char *)v40;
      }
    }
    unint64_t v6 = &v5[24 * v41];
    long long v7 = *(_OWORD *)v4;
    *((void *)v6 + 2) = v4[2];
    *(_OWORD *)unint64_t v6 = v7;
    ++v41;
  }
  unint64_t v33 = *(void ***)(*(void *)(a1[2] + 8) + 8);
  AttrData = (void **)mlir::OpaqueAttr::getAttrData((mlir::OpaqueAttr *)&v33);
  uint64_t v10 = v37;
  if (v37)
  {
    __int16 v36 = 261;
    unint64_t v33 = AttrData;
    uint64_t v34 = v9;
    mlir::Diagnostic::operator<<((uint64_t)&v38, &v33);
    uint64_t v10 = v37;
    if (v37)
    {
      LODWORD(v33) = 3;
      uint64_t v34 = "' op ";
      uint64_t v35 = 5;
      uint64_t v11 = &v33;
      uint64_t v12 = (char *)v40;
      if (v41 >= v42)
      {
        unint64_t v30 = v41 + 1;
        if (v40 <= &v33 && (char *)v40 + 24 * v41 > (char *)&v33)
        {
          int64_t v32 = (char *)&v33 - (unsigned char *)v40;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v40, v43, v30, 24);
          uint64_t v12 = (char *)v40;
          uint64_t v11 = (void ***)((char *)v40 + v32);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v40, v43, v30, 24);
          uint64_t v11 = &v33;
          uint64_t v12 = (char *)v40;
        }
      }
      uint64_t v13 = &v12[24 * v41];
      long long v14 = *(_OWORD *)v11;
      *((void *)v13 + 2) = v11[2];
      *(_OWORD *)uint64_t v13 = v14;
      ++v41;
      uint64_t v10 = v37;
    }
  }
  *(void *)a2 = v10;
  *(unsigned char *)(a2 + 8) = 0;
  *(unsigned char *)(a2 + 184) = 0;
  if (v48)
  {
    *(void *)(a2 + 8) = v38;
    unint64_t v15 = v41;
    *(_DWORD *)(a2 + 16) = v39;
    uint64_t v16 = (void *)(a2 + 40);
    *(void *)(a2 + 24) = a2 + 40;
    *(void *)(a2 + 32) = 0x400000000;
    if (!v15 || &v37 == (uint64_t *)a2)
    {
      int v19 = 1;
      goto LABEL_21;
    }
    unint64_t v17 = v43;
    if (v40 != v43)
    {
      *(void *)(a2 + 24) = v40;
      unsigned int v18 = v42;
      *(_DWORD *)(a2 + 32) = v15;
      *(_DWORD *)(a2 + 36) = v18;
      uint64_t v40 = v43;
      unsigned int v42 = 0;
      int v19 = 1;
LABEL_20:
      unsigned int v41 = 0;
LABEL_21:
      *(_OWORD *)(a2 + 136) = *(_OWORD *)v44;
      *(void *)(a2 + 152) = v45;
      v44[0] = 0;
      v44[1] = 0;
      *(_OWORD *)(a2 + 160) = *(_OWORD *)__p;
      *(void *)(a2 + 176) = v47;
      uint64_t v45 = 0;
      __p[0] = 0;
      __p[1] = 0;
      uint64_t v47 = 0;
      *(unsigned char *)(a2 + 184) = 1;
      if (v19)
      {
        if (v40 != v43) {
          free(v40);
        }
        unsigned __int8 v48 = 0;
      }
      goto LABEL_25;
    }
    if (v15 < 5)
    {
      unint64_t v20 = v15;
    }
    else
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod(a2 + 24, (void *)(a2 + 40), v15, 24);
      unint64_t v20 = v41;
      if (!v41)
      {
LABEL_19:
        *(_DWORD *)(a2 + 32) = v15;
        int v19 = v48;
        goto LABEL_20;
      }
      unint64_t v17 = v40;
      uint64_t v16 = *(void **)(a2 + 24);
    }
    memcpy(v16, v17, 24 * v20);
    goto LABEL_19;
  }
LABEL_25:
  mlir::InFlightDiagnostic::abandon(&v37);
  if (v37) {
    mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v37);
  }
  if (v48)
  {
    char v21 = __p[0];
    if (__p[0])
    {
      uint64_t v22 = __p[1];
      uint64_t v23 = __p[0];
      if (__p[1] != __p[0])
      {
        do
          uint64_t v22 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v22 - 1);
        while (v22 != v21);
        uint64_t v23 = __p[0];
      }
      __p[1] = v21;
      operator delete(v23);
    }
    uint64_t v24 = v44[0];
    if (v44[0])
    {
      uint64_t v25 = v44[1];
      uint64_t v26 = v44[0];
      if (v44[1] != v44[0])
      {
        do
        {
          uint64_t v28 = *--v25;
          uint64_t v27 = v28;
          void *v25 = 0;
          if (v28) {
            MEMORY[0x21667D390](v27, 0x1000C8077774924);
          }
        }
        while (v25 != v24);
        uint64_t v26 = v44[0];
      }
      v44[1] = v24;
      operator delete(v26);
    }
    if (v40 != v43) {
      free(v40);
    }
  }
}

void mlir::createCanonicalizerPass(mlir *this)
{
}

uint64_t mlir::impl::CanonicalizerBase<anonymous namespace'::Canonicalizer>::CanonicalizerBase(uint64_t a1)
{
  *(unsigned char *)(a1 + 16) = 0;
  *(unsigned char *)(a1 + 32) = 0;
  *(unsigned char *)(a1 + 40) = 0;
  *(unsigned char *)(a1 + 120) = 0;
  uint64_t v2 = (void *)(a1 + 152);
  *(_OWORD *)(a1 + 128) = 0u;
  *(_OWORD *)(a1 + 144) = 0u;
  *(_OWORD *)(a1 + 160) = 0u;
  *(void *)(a1 + 176) = 0;
  *(void *)(a1 + 184) = a1 + 200;
  *(void *)(a1 + 192) = 0x400000000;
  *(void *)(a1 + 232) = a1 + 248;
  *(void *)(a1 + 240) = 0x400000000;
  *(void *)(a1 + 280) = 0;
  *(void *)(a1 + 288) = 0;
  *(void *)(a1 + 296) = 0x1000000000;
  *(_OWORD *)(a1 + 304) = 0u;
  *(_OWORD *)(a1 + 320) = 0u;
  *(void *)(a1 + 336) = 0;
  *(void *)a1 = &unk_26C37F080;
  v6.n128_u64[0] = (unint64_t)"Seed the worklist in general top-down order";
  v6.n128_u64[1] = 43;
  LOBYTE(v4) = 1;
  uint64_t v5 = &v4;
  mlir::detail::PassOptions::Option<BOOL,llvm::cl::parser<BOOL>>::Option<llvm::cl::desc,llvm::cl::initializer<BOOL>>((void *)(a1 + 344), (void *)(a1 + 152), (uint64_t)"top-down", 8, &v6, (unsigned char **)&v5);
  *(void *)(a1 + 344) = &unk_26C37E680;
  *(void *)(a1 + 536) = &unk_26C37E700;
  v6.n128_u64[0] = (unint64_t)"Perform control flow optimizations to the region tree";
  v6.n128_u64[1] = 53;
  LOBYTE(v4) = 1;
  uint64_t v5 = &v4;
  mlir::detail::PassOptions::Option<BOOL,llvm::cl::parser<BOOL>>::Option<llvm::cl::desc,llvm::cl::initializer<BOOL>>((void *)(a1 + 552), v2, (uint64_t)"region-simplify", 15, &v6, (unsigned char **)&v5);
  *(void *)(a1 + 552) = &unk_26C37E680;
  *(void *)(a1 + 744) = &unk_26C37E700;
  v6.n128_u64[0] = (unint64_t)"Max. iterations between applying patterns / simplifying regions";
  v6.n128_u64[1] = 63;
  int v4 = 10;
  uint64_t v5 = &v4;
  mlir::detail::PassOptions::Option<long long,llvm::cl::parser<long long>>::Option<llvm::cl::desc,llvm::cl::initializer<int>>((void *)(a1 + 760), v2, (uint64_t)"max-iterations", 14, &v6, &v5);
  *(void *)(a1 + 760) = &unk_26C37E800;
  *(void *)(a1 + 960) = &unk_26C37E880;
  v6.n128_u64[0] = (unint64_t)"Max. number of pattern rewrites within an iteration";
  v6.n128_u64[1] = 51;
  int v4 = -1;
  uint64_t v5 = &v4;
  mlir::detail::PassOptions::Option<long long,llvm::cl::parser<long long>>::Option<llvm::cl::desc,llvm::cl::initializer<int>>((void *)(a1 + 976), v2, (uint64_t)"max-num-rewrites", 16, &v6, &v5);
  *(void *)(a1 + 976) = &unk_26C37E800;
  *(void *)(a1 + 1176) = &unk_26C37E880;
  v6.n128_u64[0] = (unint64_t)"Test only: Fail pass on non-convergence to detect cyclic pattern";
  v6.n128_u64[1] = 64;
  LOBYTE(v4) = 0;
  uint64_t v5 = &v4;
  mlir::detail::PassOptions::Option<BOOL,llvm::cl::parser<BOOL>>::Option<llvm::cl::desc,llvm::cl::initializer<BOOL>>((void *)(a1 + 1192), v2, (uint64_t)"test-convergence", 16, &v6, (unsigned char **)&v5);
  *(void *)(a1 + 1192) = &unk_26C37E680;
  *(void *)(a1 + 1384) = &unk_26C37E700;
  v6.n128_u64[0] = (unint64_t)"Labels of patterns that should be filtered out during application";
  v6.n128_u64[1] = 65;
  mlir::detail::PassOptions::ListOption<std::string,llvm::cl::parser<std::string>>::ListOption<llvm::cl::desc>(a1 + 1400, v2, (uint64_t)"disable-patterns", 16, &v6);
  *(void *)(a1 + 1400) = &unk_26C37E440;
  *(void *)(a1 + 1648) = &unk_26C37E4C0;
  v6.n128_u64[0] = (unint64_t)"Labels of patterns that should be used during application, all other patterns are filtered out";
  v6.n128_u64[1] = 94;
  mlir::detail::PassOptions::ListOption<std::string,llvm::cl::parser<std::string>>::ListOption<llvm::cl::desc>(a1 + 1672, v2, (uint64_t)"enable-patterns", 15, &v6);
  *(void *)(a1 + 1672) = &unk_26C37E440;
  *(void *)(a1 + 1920) = &unk_26C37E4C0;
  return a1;
}

void anonymous namespace'::Canonicalizer::~Canonicalizer(_anonymous_namespace_::Canonicalizer *this)
{
  *(void *)this = &unk_26C356600;
  uint64_t v2 = (std::__shared_weak_count *)*((void *)this + 250);
  if (v2 && !atomic_fetch_add(&v2->__shared_owners_, 0xFFFFFFFFFFFFFFFFLL))
  {
    ((void (*)(std::__shared_weak_count *))v2->__on_zero_shared)(v2);
    std::__shared_weak_count::__release_weak(v2);
  }
  *(void *)this = &unk_26C37F080;
  llvm::cl::list<std::string,BOOL,llvm::cl::parser<std::string>>::~list((void *)this + 209);
  llvm::cl::list<std::string,BOOL,llvm::cl::parser<std::string>>::~list((void *)this + 175);
  *((void *)this + 149) = &unk_26C35BE48;
  uint64_t v3 = (_anonymous_namespace_::Canonicalizer *)*((void *)this + 172);
  if (v3 == (_anonymous_namespace_::Canonicalizer *)((char *)this + 1352))
  {
    (*(void (**)(char *))(*((void *)this + 169) + 32))((char *)this + 1352);
    *((void *)this + 149) = &unk_26C35BFE8;
    int v4 = (void *)*((void *)this + 161);
    if (v4 != *((void **)this + 160)) {
LABEL_8:
    }
      free(v4);
  }
  else
  {
    if (v3) {
      (*(void (**)(_anonymous_namespace_::Canonicalizer *))(*(void *)v3 + 40))(v3);
    }
    *((void *)this + 149) = &unk_26C35BFE8;
    int v4 = (void *)*((void *)this + 161);
    if (v4 != *((void **)this + 160)) {
      goto LABEL_8;
    }
  }
  uint64_t v5 = (char *)*((void *)this + 157);
  if (v5 != (char *)this + 1272) {
    free(v5);
  }
  *((void *)this + 122) = &unk_26C35BF18;
  __n128 v6 = (_anonymous_namespace_::Canonicalizer *)*((void *)this + 146);
  if (v6 == (_anonymous_namespace_::Canonicalizer *)((char *)this + 1144))
  {
    (*(void (**)(char *))(*((void *)this + 143) + 32))((char *)this + 1144);
    *((void *)this + 122) = &unk_26C35BFE8;
    long long v7 = (void *)*((void *)this + 134);
    if (v7 != *((void **)this + 133)) {
LABEL_15:
    }
      free(v7);
  }
  else
  {
    if (v6) {
      (*(void (**)(_anonymous_namespace_::Canonicalizer *))(*(void *)v6 + 40))(v6);
    }
    *((void *)this + 122) = &unk_26C35BFE8;
    long long v7 = (void *)*((void *)this + 134);
    if (v7 != *((void **)this + 133)) {
      goto LABEL_15;
    }
  }
  uint64_t v8 = (char *)*((void *)this + 130);
  if (v8 != (char *)this + 1056) {
    free(v8);
  }
  *((void *)this + 95) = &unk_26C35BF18;
  uint64_t v9 = (_anonymous_namespace_::Canonicalizer *)*((void *)this + 119);
  if (v9 == (_anonymous_namespace_::Canonicalizer *)((char *)this + 928))
  {
    (*(void (**)(char *))(*((void *)this + 116) + 32))((char *)this + 928);
    *((void *)this + 95) = &unk_26C35BFE8;
    uint64_t v10 = (void *)*((void *)this + 107);
    if (v10 != *((void **)this + 106)) {
LABEL_22:
    }
      free(v10);
  }
  else
  {
    if (v9) {
      (*(void (**)(_anonymous_namespace_::Canonicalizer *))(*(void *)v9 + 40))(v9);
    }
    *((void *)this + 95) = &unk_26C35BFE8;
    uint64_t v10 = (void *)*((void *)this + 107);
    if (v10 != *((void **)this + 106)) {
      goto LABEL_22;
    }
  }
  uint64_t v11 = (char *)*((void *)this + 103);
  if (v11 != (char *)this + 840) {
    free(v11);
  }
  *((void *)this + 69) = &unk_26C35BE48;
  uint64_t v12 = (_anonymous_namespace_::Canonicalizer *)*((void *)this + 92);
  if (v12 == (_anonymous_namespace_::Canonicalizer *)((char *)this + 712))
  {
    (*(void (**)(char *))(*((void *)this + 89) + 32))((char *)this + 712);
    *((void *)this + 69) = &unk_26C35BFE8;
    uint64_t v13 = (void *)*((void *)this + 81);
    if (v13 != *((void **)this + 80)) {
LABEL_29:
    }
      free(v13);
  }
  else
  {
    if (v12) {
      (*(void (**)(_anonymous_namespace_::Canonicalizer *))(*(void *)v12 + 40))(v12);
    }
    *((void *)this + 69) = &unk_26C35BFE8;
    uint64_t v13 = (void *)*((void *)this + 81);
    if (v13 != *((void **)this + 80)) {
      goto LABEL_29;
    }
  }
  long long v14 = (char *)*((void *)this + 77);
  if (v14 != (char *)this + 632) {
    free(v14);
  }
  *((void *)this + 43) = &unk_26C35BE48;
  unint64_t v15 = (_anonymous_namespace_::Canonicalizer *)*((void *)this + 66);
  if (v15 == (_anonymous_namespace_::Canonicalizer *)((char *)this + 504))
  {
    (*(void (**)(char *))(*((void *)this + 63) + 32))((char *)this + 504);
    *((void *)this + 43) = &unk_26C35BFE8;
    uint64_t v16 = (void *)*((void *)this + 55);
    if (v16 != *((void **)this + 54)) {
LABEL_36:
    }
      free(v16);
  }
  else
  {
    if (v15) {
      (*(void (**)(_anonymous_namespace_::Canonicalizer *))(*(void *)v15 + 40))(v15);
    }
    *((void *)this + 43) = &unk_26C35BFE8;
    uint64_t v16 = (void *)*((void *)this + 55);
    if (v16 != *((void **)this + 54)) {
      goto LABEL_36;
    }
  }
  unint64_t v17 = (char *)*((void *)this + 51);
  if (v17 != (char *)this + 424) {
    free(v17);
  }

  mlir::Pass::~Pass(this);
}

{
  uint64_t vars8;

  JUMPOUT(0x21667D3C0);
}

const char *mlir::impl::CanonicalizerBase<anonymous namespace'::Canonicalizer>::getName()
{
  return "Canonicalizer";
}

const char *mlir::impl::CanonicalizerBase<anonymous namespace'::Canonicalizer>::getArgument()
{
  return "canonicalize";
}

const char *mlir::impl::CanonicalizerBase<anonymous namespace'::Canonicalizer>::getDescription()
{
  return "Canonicalize operations";
}

__n128 anonymous namespace'::Canonicalizer::runOnOperation(_anonymous_namespace_::Canonicalizer *this)
{
  unint64_t v1 = *((void *)this + 5) & 0xFFFFFFFFFFFFFFF8;
  uint64_t v2 = (const mlir::FrozenRewritePatternSet *)*((void *)this + 249);
  long long v6 = *(_OWORD *)((char *)this + 1944);
  long long v7 = *(_OWORD *)((char *)this + 1960);
  __n128 result = *(__n128 *)((char *)this + 1976);
  unint64_t v4 = *(unsigned int *)(v1 + 44);
  if ((v4 & 0x7FFFFF) != 0)
  {
    uint64_t v5 = (mlir::Region **)(((v1 + 16 * ((v4 >> 23) & 1) + ((v4 >> 21) & 0x7F8) + 64) & 0xFFFFFFFFFFFFFFF8)
                         + 32 * *(unsigned int *)(v1 + 40));
    BOOL v9 = 0;
    v8[0] = v6;
    v8[1] = v7;
    uint64_t v8[2] = (__int128)result;
    mlir::applyPatternsAndFoldGreedily(v5, v2, v8, &v9);
  }
  return result;
}

void anonymous namespace'::Canonicalizer::initialize(_anonymous_namespace_::Canonicalizer *this, mlir::MLIRContext *a2)
{
  uint64_t v29 = *MEMORY[0x263EF8340];
  *((unsigned char *)this + 1944) = *((unsigned char *)this + 472);
  *((unsigned char *)this + 1945) = *((unsigned char *)this + 680);
  *((void *)this + 244) = *((void *)this + 111);
  *((void *)this + 245) = *((void *)this + 138);
  uint64_t v16 = a2;
  *(_OWORD *)__p = 0u;
  long long v18 = 0u;
  int v19 = v21;
  uint64_t v20 = 0x600000000;
  v21[6] = 0;
  void v21[7] = 0;
  int v22 = 0;
  uint64_t v23 = 0;
  uint64_t v24 = 0;
  uint64_t v25 = 0x2800000000;
  uint64_t v26 = 0;
  uint64_t v27 = 0;
  uint64_t v28 = 0x2800000000;
  mlir::MLIRContext::getLoadedDialects(a2, &v14);
  unint64_t v4 = v14;
  uint64_t v5 = v15;
  if (v14 != v15)
  {
    do
    {
      uint64_t v6 = *(void *)v4;
      v4 += 8;
      (*(void (**)(uint64_t, mlir::MLIRContext **))(*(void *)v6 + 16))(v6, &v16);
    }
    while (v4 != v5);
    unint64_t v4 = v14;
  }
  if (v4)
  {
    unint64_t v15 = v4;
    operator delete(v4);
  }
  uint64_t RegisteredOperations = mlir::MLIRContext::getRegisteredOperations(a2);
  if (v8)
  {
    BOOL v9 = (uint64_t *)RegisteredOperations;
    uint64_t v10 = 8 * v8;
    do
    {
      uint64_t v11 = *v9++;
      (*(void (**)(uint64_t, mlir::MLIRContext **, mlir::MLIRContext *))(*(void *)v11 + 24))(v11, &v16, a2);
      v10 -= 8;
    }
    while (v10);
  }
  uint64_t v12 = operator new(0x28uLL);
  v12[1] = 0;
  void v12[2] = 0;
  *uint64_t v12 = &unk_26C389EA8;
  *((void *)this + 249) = mlir::FrozenRewritePatternSet::FrozenRewritePatternSet(v12 + 3, &v16, *((void *)this + 191), 0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*((void *)this + 192) - *((void *)this + 191)) >> 3), *((void *)this + 225), 0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*((void *)this + 226) - *((void *)this + 225)) >> 3));
  uint64_t v13 = (std::__shared_weak_count *)*((void *)this + 250);
  *((void *)this + 250) = v12;
  if (v13)
  {
    if (!atomic_fetch_add(&v13->__shared_owners_, 0xFFFFFFFFFFFFFFFFLL))
    {
      ((void (*)(std::__shared_weak_count *))v13->__on_zero_shared)(v13);
      std::__shared_weak_count::__release_weak(v13);
    }
  }
  mlir::PDLPatternModule::~PDLPatternModule((mlir::PDLPatternModule *)((char *)&v18 + 8));
}

void mlir::impl::CanonicalizerBase<anonymous namespace'::Canonicalizer>::clonePass()
{
}

uint64_t mlir::detail::PassOptions::ListOption<std::string,llvm::cl::parser<std::string>>::ListOption<llvm::cl::desc>(uint64_t a1, void *a2, uint64_t a3, uint64_t a4, _OWORD *a5)
{
  v32[0] = a3;
  v32[1] = a4;
  int64_t v31 = a2;
  uint64_t v7 = llvm::cl::list<std::string,BOOL,llvm::cl::parser<std::string>>::list<llvm::StringRef,llvm::cl::sub,llvm::cl::desc>(a1, (uint64_t)v32, &v31, a5);
  uint64_t v8 = v7 + 248;
  *(unsigned char *)(v7 + 256) = 0;
  *(void *)uint64_t v7 = &unk_26C37F310;
  *(void *)(v7 + 248) = &unk_26C37F390;
  *(void *)(v7 + 264) = &unk_26C35C0A0;
  uint64_t v10 = (uint64_t *)a2[21];
  unint64_t v9 = a2[22];
  uint64_t v11 = v10;
  if ((unint64_t)v10 < v9)
  {
    *uint64_t v10 = v8;
    uint64_t v12 = (uint64_t)(v10 + 1);
    goto LABEL_23;
  }
  uint64_t v13 = (char *)a2[20];
  uint64_t v14 = ((char *)v10 - v13) >> 3;
  unint64_t v15 = v14 + 1;
  if ((unint64_t)(v14 + 1) >> 61) {
    abort();
  }
  uint64_t v16 = v9 - (void)v13;
  if (v16 >> 2 > v15) {
    unint64_t v15 = v16 >> 2;
  }
  if ((unint64_t)v16 >= 0x7FFFFFFFFFFFFFF8) {
    unint64_t v17 = 0x1FFFFFFFFFFFFFFFLL;
  }
  else {
    unint64_t v17 = v15;
  }
  if (v17)
  {
    if (v17 >> 61) {
      std::__throw_bad_array_new_length[abi:nn180100]();
    }
    long long v18 = (char *)operator new(8 * v17);
    int v19 = (uint64_t *)&v18[8 * v14];
    uint64_t v20 = &v18[8 * v17];
    *int v19 = v8;
    uint64_t v12 = (uint64_t)(v19 + 1);
    char v21 = (char *)((char *)v10 - v13);
    if (v10 == (uint64_t *)v13) {
      goto LABEL_21;
    }
    goto LABEL_14;
  }
  long long v18 = 0;
  int v19 = (uint64_t *)(8 * v14);
  uint64_t v20 = 0;
  *(void *)(8 * v14) = v8;
  uint64_t v12 = 8 * v14 + 8;
  char v21 = (char *)((char *)v10 - v13);
  if (v10 != (uint64_t *)v13)
  {
LABEL_14:
    unint64_t v22 = (unint64_t)(v21 - 8);
    if (v22 < 0x58) {
      goto LABEL_28;
    }
    if ((unint64_t)(v13 - v18) < 0x20) {
      goto LABEL_28;
    }
    uint64_t v23 = (v22 >> 3) + 1;
    uint64_t v24 = 8 * (v23 & 0x3FFFFFFFFFFFFFFCLL);
    uint64_t v11 = &v10[v24 / 0xFFFFFFFFFFFFFFF8];
    int v19 = (uint64_t *)((char *)v19 - v24);
    uint64_t v25 = &v18[8 * v14 - 16];
    uint64_t v26 = v10 - 2;
    uint64_t v27 = v23 & 0x3FFFFFFFFFFFFFFCLL;
    do
    {
      long long v28 = *(_OWORD *)v26;
      *((_OWORD *)v25 - 1) = *((_OWORD *)v26 - 1);
      *(_OWORD *)uint64_t v25 = v28;
      v25 -= 32;
      v26 -= 4;
      v27 -= 4;
    }
    while (v27);
    if (v23 != (v23 & 0x3FFFFFFFFFFFFFFCLL))
    {
LABEL_28:
      do
      {
        uint64_t v29 = *--v11;
        *--int v19 = v29;
      }
      while (v11 != (uint64_t *)v13);
    }
    uint64_t v11 = (uint64_t *)a2[20];
  }
LABEL_21:
  a2[20] = v19;
  a2[21] = v12;
  a2[22] = v20;
  if (v11) {
    operator delete(v11);
  }
LABEL_23:
  a2[21] = v12;
  return a1;
}

uint64_t llvm::cl::list<std::string,BOOL,llvm::cl::parser<std::string>>::list<llvm::StringRef,llvm::cl::sub,llvm::cl::desc>(uint64_t a1, uint64_t a2, const void **a3, _OWORD *a4)
{
  *(void *)a1 = &unk_26C35BFE8;
  *(_WORD *)(a1 + 8) = 0;
  __int16 v8 = *(_WORD *)(a1 + 10);
  unint64_t v9 = (void *)(a1 + 80);
  *(void *)(a1 + 64) = a1 + 80;
  uint64_t v10 = a1 + 64;
  *(_WORD *)(a1 + 10) = v8 & 0x8000 | 1;
  *(_OWORD *)(a1 + 12) = 0u;
  *(_OWORD *)(a1 + 28) = 0u;
  *(_OWORD *)(a1 + 44) = 0u;
  *(_DWORD *)(a1 + 60) = 0;
  *(void *)(a1 + 88) = a1 + 120;
  uint64_t v11 = (llvm::SmallPtrSetImplBase *)(a1 + 88);
  *(void *)(a1 + 72) = 0x100000000;
  *(void *)(a1 + 96) = a1 + 120;
  *(void *)(a1 + 104) = 1;
  *(_DWORD *)(a1 + 112) = 0;
  GeneralCategory = llvm::cl::getGeneralCategory((llvm::cl *)a1);
  uint64_t v13 = *(unsigned int *)(a1 + 72);
  if (v13 >= *(_DWORD *)(a1 + 76))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod(v10, v9, v13 + 1, 8);
    LODWORD(v13) = *(_DWORD *)(a1 + 72);
  }
  *(void *)(*(void *)(a1 + 64) + 8 * v13) = GeneralCategory;
  ++*(_DWORD *)(a1 + 72);
  *(_OWORD *)(a1 + 128) = 0u;
  *(_OWORD *)(a1 + 144) = 0u;
  *(_OWORD *)(a1 + 160) = 0u;
  *(unsigned char *)(a1 + 176) = 0;
  *(void *)a1 = &unk_26C35BF80;
  *(void *)(a1 + 192) = 0;
  *(void *)(a1 + 200) = 0;
  *(void *)(a1 + 184) = 0;
  *(void *)(a1 + 208) = &unk_26C35C0A0;
  *(void *)(a1 + 216) = &unk_26C380E18;
  *(void *)(a1 + 240) = a1 + 216;
  llvm::cl::Option::setArgStr(a1, *(int8x16_t **)a2, *(const unsigned __int8 **)(a2 + 8));
  uint64_t v14 = *a3;
  uint64_t v15 = *(void *)(a1 + 96);
  if (v15 != *(void *)(a1 + 88))
  {
LABEL_4:
    llvm::SmallPtrSetImplBase::insert_imp_big(v11, v14);
    goto LABEL_5;
  }
  uint64_t v17 = *(unsigned int *)(a1 + 108);
  if (!v17)
  {
LABEL_14:
    if (v17 < *(_DWORD *)(a1 + 104))
    {
      *(_DWORD *)(a1 + 108) = v17 + 1;
      *(void *)(v15 + 8 * v17) = v14;
      goto LABEL_5;
    }
    goto LABEL_4;
  }
  long long v18 = 0;
  uint64_t v19 = 8 * v17;
  uint64_t v20 = *(void **)(a1 + 96);
  while ((const void *)*v20 != v14)
  {
    if (*v20 == -2) {
      long long v18 = v20;
    }
    ++v20;
    v19 -= 8;
    if (!v19)
    {
      if (!v18) {
        goto LABEL_14;
      }
      *long long v18 = v14;
      --*(_DWORD *)(a1 + 112);
      break;
    }
  }
LABEL_5:
  *(_OWORD *)(a1 + 32) = *a4;
  llvm::cl::Option::addArgument((llvm::cl::Option *)a1);
  return a1;
}

void std::__shared_ptr_emplace<mlir::FrozenRewritePatternSet>::~__shared_ptr_emplace(std::__shared_weak_count *this)
{
  this->__vftable = (std::__shared_weak_count_vtbl *)&unk_26C389EA8;
  std::__shared_weak_count::~__shared_weak_count(this);
}

void std::__shared_ptr_emplace<mlir::FrozenRewritePatternSet>::~__shared_ptr_emplace(std::__shared_weak_count *a1)
{
  a1->__vftable = (std::__shared_weak_count_vtbl *)&unk_26C389EA8;
  std::__shared_weak_count::~__shared_weak_count(a1);

  JUMPOUT(0x21667D3C0);
}

void std::__shared_ptr_emplace<mlir::FrozenRewritePatternSet>::__on_zero_shared(uint64_t a1)
{
}

void mlir::PDLPatternModule::~PDLPatternModule(mlir::PDLPatternModule *this)
{
  if (*((_DWORD *)this + 33))
  {
    uint64_t v2 = *((unsigned int *)this + 32);
    if (v2)
    {
      uint64_t v3 = 0;
      do
      {
        unint64_t v4 = *(llvm **)(*((void *)this + 15) + v3);
        if (v4 != (llvm *)-8 && v4 != 0)
        {
          uint64_t v6 = *(void *)v4;
          uint64_t v7 = (void *)*((void *)v4 + 4);
          if (v7 == (void *)((char *)v4 + 8))
          {
            (*(void (**)(void *))(*((void *)v4 + 1) + 32))((void *)v4 + 1);
          }
          else if (v7)
          {
            (*(void (**)(void *))(*v7 + 40))(v7);
          }
          llvm::deallocate_buffer(v4, (void *)(v6 + 41));
        }
        v3 += 8;
      }
      while (8 * v2 != v3);
    }
  }
  free(*((void **)this + 15));
  if (*((_DWORD *)this + 27))
  {
    uint64_t v8 = *((unsigned int *)this + 26);
    if (v8)
    {
      uint64_t v9 = 0;
      do
      {
        uint64_t v10 = *(llvm **)(*((void *)this + 12) + v9);
        if (v10 != (llvm *)-8 && v10 != 0)
        {
          uint64_t v12 = *(void *)v10;
          uint64_t v13 = (void *)*((void *)v10 + 4);
          if (v13 == (void *)((char *)v10 + 8))
          {
            (*(void (**)(void *))(*((void *)v10 + 1) + 32))((void *)v10 + 1);
          }
          else if (v13)
          {
            (*(void (**)(void *))(*v13 + 40))(v13);
          }
          llvm::deallocate_buffer(v10, (void *)(v12 + 41));
        }
        v9 += 8;
      }
      while (8 * v8 != v9);
    }
  }
  free(*((void **)this + 12));
  llvm::deallocate_buffer(*((llvm **)this + 9), (void *)(16 * *((unsigned int *)this + 22)));
}

void anonymous namespace'::CSEDriver::simplify(_anonymous_namespace_::CSEDriver *this, mlir::Operation *a2, BOOL *a3)
{
  uint64_t v18 = *MEMORY[0x263EF8340];
  memset(v11, 0, 24);
  unint64_t v11[3] = v12;
  v11[4] = 0x400000000;
  uint64_t v12[4] = v13;
  void v12[5] = 0;
  v13[0] = 0;
  v13[1] = 1;
  uint64_t v14 = 0;
  uint64_t v15 = 0;
  unsigned int v16 = 0;
  uint64_t v17 = 0;
  unint64_t v5 = *((unsigned int *)a2 + 11);
  if ((v5 & 0x7FFFFF) != 0)
  {
    uint64_t v6 = (void *)((((unint64_t)a2 + 16 * ((v5 >> 23) & 1) + ((v5 >> 21) & 0x7F8) + 71) & 0xFFFFFFFFFFFFFFF8)
                  + 32 * *((unsigned int *)a2 + 10));
    uint64_t v7 = 24 * (v5 & 0x7FFFFF);
    do
    {
      v6 += 3;
      v7 -= 24;
    }
    while (v7);
  }
  uint64_t v8 = (uint64_t *)*((void *)this + 1);
  uint64_t v9 = (uint64_t *)*((void *)this + 2);
  while (v8 != v9)
  {
    uint64_t v10 = *v8++;
    (*(void (**)(void, uint64_t))(**(void **)this + 40))(*(void *)this, v10);
  }
  if (a3) {
    *a3 = *((void *)this + 1) != *((void *)this + 2);
  }
  llvm::deallocate_buffer(v14, (void *)(16 * v16));
}

void sub_2118E3A38(int a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, void *a12, int a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, void *a18, int a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33,uint64_t a34,uint64_t a35,uint64_t a36)
{
  if (v39) {
    llvm::deallocate_buffer(*v38, (void *)0x1000);
  }
  if (v41) {
    llvm::deallocate_buffer(*(llvm **)v40, *(void **)(v40 + 8));
  }
  if (v40 != v37) {
    free((void *)v40);
  }
  if (v38 != v36) {
    free(v38);
  }
}

void mlir::createCSEPass(mlir *this)
{
}

unint64_t anonymous namespace'::CSEDriver::simplifyRegion(unint64_t result, void *a2, void *a3)
{
  if ((void *)*a3 != a3)
  {
    uint64_t v5 = result;
    __n128 result = mlir::detail::DominanceInfoBase<false>::getDominanceInfo(*(void *)(result + 32), a3, 0);
    if ((void *)*a3 != a3 && (uint64_t v6 = a3[1], *(void **)(v6 + 8) == a3))
    {
      uint64_t v7 = (void *)a2[16];
      __p[0] = a2;
      __p[1] = v7;
      a2[16] = __p;
      *(void *)&long long v9 = 0;
    }
    else if ((result & 4) != 0)
    {
      long long v9 = 0u;
      long long v10 = 0u;
      *(_OWORD *)__p = 0u;
      mlir::detail::DominanceInfoBase<false>::getDominanceInfo(*(void *)(v5 + 32), a3, 1);
      operator new();
    }
  }
  return result;
}

void anonymous namespace'::CSEDriver::simplifyBlock(uint64_t a1, uint64_t a2, uint64_t a3, int a4)
{
  uint64_t v121 = *MEMORY[0x263EF8340];
  uint64_t v5 = (ZinIrHalH13g *)(a3 + 32);
  uint64_t v6 = *(ZinIrHalH13g **)(a3 + 40);
  if (v6 != (ZinIrHalH13g *)(a3 + 32))
  {
    uint64_t v100 = a1 + 40;
    uint64_t v101 = a2 + 104;
    uint64_t v103 = (ZinIrHalH13g *)(a3 + 32);
    while (1)
    {
      ZinIrHalH13g::~ZinIrHalH13g(v6);
      uint64_t v10 = v9;
      if ((*(_DWORD *)(v9 + 44) & 0x7FFFFF) != 0)
      {
        if (mlir::OperationName::mightHaveTrait<mlir::OpTrait::IsIsolatedFromAbove>((void ***)(v9 + 48)))
        {
          BOOL v109 = 0;
          uint64_t v110 = 0;
          v111[0] = 0;
          v111[1] = &v112;
          void v111[2] = 0x400000000;
          uint64_t v115 = 0;
          v116[0] = 0;
          unsigned int v114 = v116;
          v116[1] = 1;
          uint64_t v117 = 0;
          uint64_t v118 = 0;
          unsigned int v119 = 0;
          uint64_t v120 = 0;
          unint64_t v11 = *(unsigned int *)(v10 + 44);
          if ((v11 & 0x7FFFFF) != 0)
          {
            unint64_t v12 = ((v10 + 16 * ((v11 >> 23) & 1) + ((v11 >> 21) & 0x7F8) + 71) & 0xFFFFFFFFFFFFFFF8)
                + 32 * *(unsigned int *)(v10 + 40);
            uint64_t v13 = 24 * (v11 & 0x7FFFFF);
            do
            {
              v12 += 24;
              v13 -= 24;
            }
            while (v13);
            uint64_t v14 = v117;
            uint64_t v15 = v119;
          }
          else
          {
            uint64_t v15 = 0;
            uint64_t v14 = 0;
          }
          llvm::deallocate_buffer(v14, (void *)(16 * v15));
        }
        unint64_t v16 = *(unsigned int *)(v10 + 44);
        if ((v16 & 0x7FFFFF) != 0)
        {
          unint64_t v17 = ((v10 + 16 * ((v16 >> 23) & 1) + ((v16 >> 21) & 0x7F8) + 71) & 0xFFFFFFFFFFFFFFF8)
              + 32 * *(unsigned int *)(v10 + 40);
          uint64_t v18 = 24 * (v16 & 0x7FFFFF);
          do
          {
            v17 += 24;
            v18 -= 24;
          }
          while (v18);
        }
      }
      uint64_t v105 = v10;
      if (mlir::OperationName::hasTrait<mlir::OpTrait::IsTerminator>((void *)(v10 + 48))) {
        goto LABEL_5;
      }
      if (mlir::isOpTriviallyDead((void ***)v10, v19))
      {
        unint64_t v22 = *(uint64_t **)(a1 + 16);
        unint64_t v21 = *(void *)(a1 + 24);
        if ((unint64_t)v22 < v21)
        {
          *unint64_t v22 = v10;
          uint64_t v23 = (uint64_t)(v22 + 1);
LABEL_58:
          *(void *)(a1 + 16) = v23;
          ++*(void *)(a1 + 72);
          goto LABEL_5;
        }
        uint64_t v40 = *(char **)(a1 + 8);
        uint64_t v41 = ((char *)v22 - v40) >> 3;
        unint64_t v42 = v41 + 1;
        if ((unint64_t)(v41 + 1) >> 61) {
          abort();
        }
        uint64_t v43 = v21 - (void)v40;
        if (v43 >> 2 > v42) {
          unint64_t v42 = v43 >> 2;
        }
        if ((unint64_t)v43 >= 0x7FFFFFFFFFFFFFF8) {
          unint64_t v44 = 0x1FFFFFFFFFFFFFFFLL;
        }
        else {
          unint64_t v44 = v42;
        }
        if (v44)
        {
          if (v44 >> 61) {
            std::__throw_bad_array_new_length[abi:nn180100]();
          }
          uint64_t v45 = (char *)operator new(8 * v44);
          uint64_t v46 = (uint64_t *)&v45[8 * v41];
          uint64_t *v46 = v10;
          uint64_t v23 = (uint64_t)(v46 + 1);
          if (v22 == (uint64_t *)v40) {
            goto LABEL_56;
          }
LABEL_49:
          unint64_t v47 = (char *)(v22 - 1) - v40;
          if (v47 < 0x58) {
            goto LABEL_140;
          }
          if ((unint64_t)(v40 - v45) < 0x20) {
            goto LABEL_140;
          }
          uint64_t v48 = (v47 >> 3) + 1;
          uint64_t v49 = 8 * (v48 & 0x3FFFFFFFFFFFFFFCLL);
          uint64_t v50 = &v22[v49 / 0xFFFFFFFFFFFFFFF8];
          uint64_t v46 = (uint64_t *)((char *)v46 - v49);
          uint64_t v51 = &v45[8 * v41 - 16];
          BOOL v52 = v22 - 2;
          uint64_t v53 = v48 & 0x3FFFFFFFFFFFFFFCLL;
          do
          {
            long long v54 = *(_OWORD *)v52;
            *((_OWORD *)v51 - 1) = *((_OWORD *)v52 - 1);
            *(_OWORD *)uint64_t v51 = v54;
            v51 -= 32;
            v52 -= 4;
            v53 -= 4;
          }
          while (v53);
          unint64_t v22 = v50;
          if (v48 != (v48 & 0x3FFFFFFFFFFFFFFCLL))
          {
LABEL_140:
            do
            {
              uint64_t v55 = *--v22;
              *--uint64_t v46 = v55;
            }
            while (v22 != (uint64_t *)v40);
          }
          unint64_t v22 = *(uint64_t **)(a1 + 8);
        }
        else
        {
          uint64_t v45 = 0;
          uint64_t v46 = (uint64_t *)(8 * v41);
          *(void *)(8 * v41) = v10;
          uint64_t v23 = 8 * v41 + 8;
          if (v22 != (uint64_t *)v40) {
            goto LABEL_49;
          }
        }
LABEL_56:
        *(void *)(a1 + 8) = v46;
        *(void *)(a1 + 16) = v23;
        *(void *)(a1 + 24) = &v45[8 * v44];
        uint64_t v5 = v103;
        if (v22) {
          operator delete(v22);
        }
        goto LABEL_58;
      }
      unint64_t v24 = *(unsigned int *)(v10 + 44);
      uint64_t v25 = v24 & 0x7FFFFF;
      if ((v24 & 0x7FFFFF) != 0)
      {
        uint64_t v26 = (void *)(((v10 + 16 * ((v24 >> 23) & 1) + ((v24 >> 21) & 0x7F8) + 71) & 0xFFFFFFFFFFFFFFF8)
                       + 32 * *(unsigned int *)(v10 + 40));
        uint64_t v27 = 24 * v25;
        do
        {
          if (v26 != (void *)*v26)
          {
            uint64_t v28 = v26[1];
            if (v26 == (void *)v28 || v26 != *(void **)(v28 + 8)) {
              goto LABEL_5;
            }
          }
          v26 += 3;
          v27 -= 24;
        }
        while (v27);
      }
      if (mlir::isMemoryEffectFree((mlir *)v10, v20))
      {
        if (!v8) {
          goto LABEL_37;
        }
        ++*(void *)(a1 + 64);
        goto LABEL_5;
      }
      v104[0] = llvm::DefaultDoCastIfPossible<mlir::MemoryEffectOpInterface,mlir::Operation *,llvm::CastInfo<mlir::MemoryEffectOpInterface,mlir::Operation *,void>>::doCastIfPossible(v10);
      v104[1] = v29;
      if (!v104[0]) {
        goto LABEL_5;
      }
      BOOL v109 = v111;
      uint64_t v110 = 0x400000000;
      mlir::RegionBranchOpInterface::getEntrySuccessorOperands((uint64_t)v104, (uint64_t)&v109);
      if (v110) {
        break;
      }
      BOOL v30 = 0;
      int64_t v31 = v109;
      if (v109 != v111) {
        goto LABEL_33;
      }
LABEL_34:
      if (!v30) {
        goto LABEL_5;
      }
      if (!v32) {
        goto LABEL_37;
      }
      unint64_t v33 = (void *)v32;
      uint64_t v34 = *(void *)(v32 + 16);
      if (v34 != *(void *)(v10 + 16)) {
        goto LABEL_37;
      }
      uint64_t v106 = v32;
      uint64_t v56 = *(ZinIrHalH13g **)(v32 + 8);
      if (v56 == (ZinIrHalH13g *)(v34 + 32))
      {
        unsigned int v58 = 0;
        BOOL v109 = v33;
        uint64_t v110 = 0;
        int v59 = *(_DWORD *)(a1 + 56);
        if (v59)
        {
LABEL_64:
          uint64_t v60 = *(void *)(a1 + 40);
          int v61 = v59 - 1;
          unsigned int v62 = v61 & ((v33 >> 4) ^ (v33 >> 9));
          uint64_t v63 = (uint64_t *)(v60 + 24 * v62);
          uint64_t v64 = (void *)*v63;
          if ((void *)*v63 == v33)
          {
LABEL_65:
            uint64_t v99 = v63;
            if (v58) {
              BOOL v65 = v58 == (mlir *)v10;
            }
            else {
              BOOL v65 = 1;
            }
            if (!v65) {
              goto LABEL_77;
            }
LABEL_70:
            v99[1] = v10;
            v99[2] = 0;
            goto LABEL_5;
          }
          uint64_t v84 = 0;
          int v85 = 1;
          while (v64 != (void *)-4096)
          {
            if (v84) {
              BOOL v86 = 0;
            }
            else {
              BOOL v86 = v64 == (void *)-8192;
            }
            if (v86) {
              uint64_t v84 = v63;
            }
            unsigned int v87 = v62 + v85++;
            unsigned int v62 = v87 & v61;
            uint64_t v63 = (uint64_t *)(v60 + 24 * v62);
            uint64_t v64 = (void *)*v63;
            if ((void *)*v63 == v33) {
              goto LABEL_65;
            }
          }
          if (v84) {
            uint64_t v88 = v84;
          }
          else {
            uint64_t v88 = v63;
          }
          int v66 = llvm::DenseMapBase<llvm::DenseMap<mlir::Operation *,std::pair<mlir::Operation *,mlir::MemoryEffects::Effect *>,llvm::DenseMapInfo<mlir::Operation *,void>,llvm::detail::DenseMapPair<mlir::Operation *,std::pair<mlir::Operation *,mlir::MemoryEffects::Effect *>>>,mlir::Operation *,std::pair<mlir::Operation *,mlir::MemoryEffects::Effect *>,llvm::DenseMapInfo<mlir::Operation *,void>,llvm::detail::DenseMapPair<mlir::Operation *,std::pair<mlir::Operation *,mlir::MemoryEffects::Effect *>>>::InsertIntoBucket<mlir::Operation * const&,std::pair<mlir::Operation *,decltype(nullptr)>>(v100, v88, &v106, (uint64_t *)&v109);
          if (v66[2]) {
            goto LABEL_37;
          }
          goto LABEL_73;
        }
      }
      else
      {
        ZinIrHalH13g::~ZinIrHalH13g(v56);
        unsigned int v58 = v57;
        BOOL v109 = v33;
        uint64_t v110 = 0;
        int v59 = *(_DWORD *)(a1 + 56);
        if (v59) {
          goto LABEL_64;
        }
      }
      int v66 = llvm::DenseMapBase<llvm::DenseMap<mlir::Operation *,std::pair<mlir::Operation *,mlir::MemoryEffects::Effect *>,llvm::DenseMapInfo<mlir::Operation *,void>,llvm::detail::DenseMapPair<mlir::Operation *,std::pair<mlir::Operation *,mlir::MemoryEffects::Effect *>>>,mlir::Operation *,std::pair<mlir::Operation *,mlir::MemoryEffects::Effect *>,llvm::DenseMapInfo<mlir::Operation *,void>,llvm::detail::DenseMapPair<mlir::Operation *,std::pair<mlir::Operation *,mlir::MemoryEffects::Effect *>>>::InsertIntoBucket<mlir::Operation * const&,std::pair<mlir::Operation *,decltype(nullptr)>>(v100, 0, &v106, (uint64_t *)&v109);
      if (v66[2]) {
        goto LABEL_37;
      }
LABEL_73:
      uint64_t v99 = v66;
      unsigned int v58 = (mlir *)v66[1];
      if (v58) {
        BOOL v67 = v58 == (mlir *)v10;
      }
      else {
        BOOL v67 = 1;
      }
      if (v67) {
        goto LABEL_70;
      }
LABEL_77:
      while (1)
      {
        uint64_t v68 = v58;
        mlir::getEffectsRecursively(v58, (uint64_t)&v109);
        uint64_t v69 = &unk_267771000;
        if (!v113) {
          break;
        }
        if (v110)
        {
          uint64_t v70 = (uint64_t **)v109;
          uint64_t v71 = 40 * v110;
          do
          {
            uint64_t v72 = **v70;
            {
              uint64_t v69 = (void *)&unk_267771000;
              if (v73)
              {
                uint64_t v107 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::MemoryEffects::Write]";
                unint64_t v108 = 76;
                unint64_t v74 = llvm::StringRef::find((uint64_t *)&v107, "DesiredTypeName = ", 0x12uLL, 0);
                if (v108 >= v74) {
                  unint64_t v75 = v74;
                }
                else {
                  unint64_t v75 = v108;
                }
                unsigned int v76 = &v107[v75];
                unint64_t v77 = v108 - v75;
                uint64_t v78 = 18;
                if (v77 < 0x12) {
                  uint64_t v78 = v77;
                }
                unint64_t v79 = v77 - v78;
                if (v79 >= v79 - 1) {
                  uint64_t v80 = v79 - 1;
                }
                else {
                  uint64_t v80 = v79;
                }
                mlir::detail::TypeIDResolver<mlir::MemoryEffects::Write,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v76[v78], v80);
                uint64_t v69 = (void *)&unk_267771000;
              }
            }
            if (v72 == v69[417]) {
              goto LABEL_103;
            }
            v70 += 5;
            v71 -= 40;
          }
          while (v71);
        }
        uint64_t v81 = (ZinIrHalH13g *)*((void *)v68 + 1);
        if (v81 == (ZinIrHalH13g *)(*((void *)v68 + 2) + 32))
        {
          unsigned int v58 = 0;
          if (v113)
          {
LABEL_98:
            if (v109 != v111) {
              free(v109);
            }
          }
        }
        else
        {
          ZinIrHalH13g::~ZinIrHalH13g(v81);
          unsigned int v58 = v82;
          if (v113) {
            goto LABEL_98;
          }
        }
        if (!v58 || v58 == (mlir *)v10) {
          goto LABEL_70;
        }
      }
LABEL_103:
      unsigned int v83 = mlir::SideEffects::Effect::Base<mlir::MemoryEffects::Write,mlir::MemoryEffects::Effect>::get();
      v99[1] = (uint64_t)v68;
      v99[2] = (uint64_t)v83;
      if (v113 && v109 != v111) {
        free(v109);
      }
      uint64_t v10 = v105;
LABEL_37:
      uint64_t v35 = *(void *)(a2 + 128);
      uint64_t v37 = *(void *)(v35 + 16);
      uint64_t v38 = *v36;
      int v39 = llvm::RecyclingAllocator<llvm::BumpPtrAllocatorImpl<llvm::MallocAllocator,4096ul,4096ul,128ul>,llvm::ScopedHashTableVal<mlir::Operation *,mlir::Operation *>,32ul,8ul>::Allocate<llvm::ScopedHashTableVal<mlir::Operation *,mlir::Operation *>>(a2);
      void v39[2] = v10;
      void v39[3] = v10;
      *int v39 = v37;
      v39[1] = v38;
      *__int16 v36 = (uint64_t)v39;
      *(void *)(v35 + 16) = v39;
LABEL_5:
      uint64_t v6 = (ZinIrHalH13g *)*((void *)v6 + 1);
      if (v6 == v5) {
        goto LABEL_121;
      }
    }
    BOOL v30 = llvm::all_of<llvm::SmallVector<mlir::SideEffects::EffectInstance<mlir::MemoryEffects::Effect>,4u> &,BOOL mlir::MemoryEffectOpInterface::onlyHasEffect<mlir::MemoryEffects::Read>(void)::{lambda(llvm::SmallVector<mlir::SideEffects::EffectInstance<mlir::MemoryEffects::Effect>,4u> & const&)#1}>((uint64_t)&v109);
    int64_t v31 = v109;
    if (v109 == v111) {
      goto LABEL_34;
    }
LABEL_33:
    free(v31);
    goto LABEL_34;
  }
LABEL_121:
  int v89 = *(_DWORD *)(a1 + 48);
  if (v89 || *(_DWORD *)(a1 + 52))
  {
    BOOL v90 = (void *)(a1 + 40);
    unsigned int v91 = *(_DWORD *)(a1 + 56);
    if (v91 > 4 * v89 && v91 >= 0x41)
    {
      llvm::DenseMap<mlir::Operation *,std::pair<mlir::Operation *,mlir::MemoryEffects::Effect *>,llvm::DenseMapInfo<mlir::Operation *,void>,llvm::detail::DenseMapPair<mlir::Operation *,std::pair<mlir::Operation *,mlir::MemoryEffects::Effect *>>>::shrink_and_clear((uint64_t)v90);
      return;
    }
    if (!v91) {
      goto LABEL_134;
    }
    unint64_t v92 = (void *)*v90;
    unint64_t v93 = 24 * v91 - 24;
    if (v93 >= 0x18)
    {
      unint64_t v95 = v93 / 0x18 + 1;
      uint64_t v94 = &v92[3 * (v95 & 0x1FFFFFFFFFFFFFFELL)];
      uint64_t v96 = v95 & 0x1FFFFFFFFFFFFFFELL;
      unint64_t v97 = (void *)*v90;
      do
      {
        void *v97 = -4096;
        v97[3] = -4096;
        v97 += 6;
        v96 -= 2;
      }
      while (v96);
      if (v95 == (v95 & 0x1FFFFFFFFFFFFFFELL)) {
        goto LABEL_134;
      }
    }
    else
    {
      uint64_t v94 = (void *)*v90;
    }
    int64_t v98 = &v92[3 * v91];
    do
    {
      *uint64_t v94 = -4096;
      v94 += 3;
    }
    while (v94 != v98);
LABEL_134:
    *(void *)(a1 + 48) = 0;
  }
}

int32x2_t **llvm::ScopedHashTableScope<mlir::Operation *,mlir::Operation *,anonymous namespace'::SimpleOperationInfo,llvm::RecyclingAllocator<llvm::BumpPtrAllocatorImpl<llvm::MallocAllocator,4096ul,4096ul,128ul>,llvm::ScopedHashTableVal<mlir::Operation *,mlir::Operation *>,32ul,8ul>>::~ScopedHashTableScope(int32x2_t **a1)
{
  uint64_t v2 = *a1;
  (*a1)[16] = (int32x2_t)a1[1];
  uint64_t v3 = a1[2];
  if (v3)
  {
    do
    {
      uint64_t v5 = (uint64_t *)&v3[2];
      if (v3[1])
      {
      }
      else
      {
        __int32 v6 = v2[15].i32[0];
        if (v6)
        {
          int32x2_t v7 = v2[13];
          __int32 v8 = v6 - 1;
          unsigned int v9 = v8 & mlir::OperationEquivalence::computeHash(*v5, (uint64_t (*)(uint64_t, void))llvm::function_ref<llvm::hash_code ()(mlir::Value)>::callback_fn<llvm::hash_code ()(mlir::Value)>, (uint64_t)mlir::OperationEquivalence::directHashValue, (uint64_t (*)(uint64_t, uint64_t))llvm::function_ref<llvm::hash_code ()(mlir::Value)>::callback_fn<llvm::hash_code ()(mlir::Value)>, (uint64_t)mlir::OperationEquivalence::ignoreHashValue, 1);
          uint64_t v10 = (uint64_t *)(*(void *)&v7 + 16 * v9);
          uint64_t v11 = *v5;
          uint64_t v12 = *v10;
          if (*v5 == *v10)
          {
LABEL_16:
            *uint64_t v10 = -8192;
            v2[14] = vadd_s32(v2[14], (int32x2_t)0x1FFFFFFFFLL);
          }
          else
          {
            int v13 = 1;
            while (1)
            {
              if (v12 != -4096 && v12 != -8192 && v11 != -8192 && v11 != -4096) {
                mlir::OperationEquivalence::isEquivalentTo(v11, v12, 1);
              }
              if (v12 == -4096) {
                break;
              }
              unsigned int v14 = v9 + v13++;
              unsigned int v9 = v14 & v8;
              uint64_t v10 = (uint64_t *)(*(void *)&v7 + 16 * (v14 & v8));
              uint64_t v11 = *v5;
              uint64_t v12 = *v10;
              if (*v5 == *v10) {
                goto LABEL_16;
              }
            }
          }
        }
      }
      unint64_t v4 = (int32x2_t *)*v3;
      a1[2] = (int32x2_t *)*v3;
      uint64_t v2 = *a1;
      *uint64_t v3 = **a1;
      *uint64_t v2 = (int32x2_t)v3;
      uint64_t v3 = v4;
    }
    while (v4);
  }
  return a1;
}

void std::deque<std::unique_ptr<anonymous namespace'::CSEDriver::CFGStackNode>>::emplace_back<std::unique_ptr<anonymous namespace'::CSEDriver::CFGStackNode>>(uint64_t a1, uint64_t *a2)
{
  uint64_t v2 = a2;
  unint64_t v4 = *(char **)(a1 + 16);
  uint64_t v5 = *(char **)(a1 + 8);
  uint64_t v6 = v4 - v5;
  if (v4 == v5) {
    uint64_t v7 = 0;
  }
  else {
    uint64_t v7 = ((v4 - v5) << 6) - 1;
  }
  unint64_t v8 = *(void *)(a1 + 32);
  if (v7 != *(void *)(a1 + 40) + v8) {
    goto LABEL_96;
  }
  BOOL v9 = v8 >= 0x200;
  unint64_t v10 = v8 - 512;
  if (v9)
  {
    *(void *)(a1 + 32) = v10;
    uint64_t v11 = v5 + 8;
    uint64_t v12 = *(void *)v5;
    *(void *)(a1 + 8) = v5 + 8;
    if (v4 != *(char **)(a1 + 24))
    {
LABEL_94:
      *(void *)unint64_t v4 = v12;
      goto LABEL_95;
    }
    int v13 = *(char **)a1;
    if ((unint64_t)v11 > *(void *)a1)
    {
      uint64_t v14 = (uint64_t)&v11[-*(void *)a1] >> 3;
      if (v14 >= -1) {
        uint64_t v15 = v14 + 1;
      }
      else {
        uint64_t v15 = v14 + 2;
      }
      uint64_t v16 = v15 >> 1;
      uint64_t v17 = -v16;
      uint64_t v18 = &v11[-8 * v16];
      int64_t v19 = v4 - v11;
      if (v4 != v11)
      {
        memmove(&v11[-8 * v16], v11, v4 - v11);
        unint64_t v4 = *(char **)(a1 + 8);
      }
      uint64_t v20 = &v4[8 * v17];
      unint64_t v4 = &v18[v19];
      *(void *)(a1 + 8) = v20;
      *(void *)(a1 + 16) = &v18[v19];
      goto LABEL_94;
    }
    unint64_t v39 = (v4 - v13) >> 2;
    if (v4 == v13) {
      unint64_t v39 = 1;
    }
    if (v39 >> 61) {
      goto LABEL_110;
    }
    unint64_t v40 = v39 >> 2;
    uint64_t v41 = 8 * v39;
    unint64_t v42 = (char *)operator new(8 * v39);
    uint64_t v43 = &v42[8 * v40];
    int64_t v45 = v4 - v11;
    BOOL v44 = v4 == v11;
    unint64_t v4 = v43;
    if (!v44)
    {
      unint64_t v4 = &v43[v45 & 0xFFFFFFFFFFFFFFF8];
      unint64_t v46 = v45 - 8;
      if ((unint64_t)(v45 - 8) < 0x38)
      {
        unint64_t v47 = &v42[8 * v40];
        do
        {
LABEL_91:
          uint64_t v103 = *(void *)v11;
          v11 += 8;
          *(void *)unint64_t v47 = v103;
          v47 += 8;
        }
        while (v47 != v4);
        goto LABEL_92;
      }
      uint64_t v96 = &v42[8 * v40];
      unint64_t v47 = v96;
      if ((unint64_t)(v96 - v11) < 0x20) {
        goto LABEL_91;
      }
      uint64_t v97 = (v46 >> 3) + 1;
      uint64_t v98 = 8 * (v97 & 0x3FFFFFFFFFFFFFFCLL);
      unint64_t v47 = &v43[v98];
      v11 += v98;
      uint64_t v99 = (long long *)(v5 + 24);
      uint64_t v100 = v96 + 16;
      uint64_t v101 = v97 & 0x3FFFFFFFFFFFFFFCLL;
      do
      {
        long long v102 = *v99;
        *(v100 - 1) = *(v99 - 1);
        *uint64_t v100 = v102;
        v99 += 2;
        v100 += 2;
        v101 -= 4;
      }
      while (v101);
      if (v97 != (v97 & 0x3FFFFFFFFFFFFFFCLL)) {
        goto LABEL_91;
      }
    }
LABEL_92:
    *(void *)a1 = v42;
    *(void *)(a1 + 8) = v43;
    *(void *)(a1 + 16) = v4;
    *(void *)(a1 + 24) = &v42[v41];
    if (v13)
    {
      operator delete(v13);
      unint64_t v4 = *(char **)(a1 + 16);
    }
    goto LABEL_94;
  }
  uint64_t v21 = v6 >> 3;
  unint64_t v22 = *(char **)a1;
  uint64_t v23 = *(char **)(a1 + 24);
  uint64_t v24 = (uint64_t)&v23[-*(void *)a1];
  if (v6 >> 3 < (unint64_t)(v24 >> 3))
  {
    uint64_t v25 = operator new(0x1000uLL);
    uint64_t v26 = v25;
    if (v23 != v4)
    {
      *(void *)unint64_t v4 = v25;
LABEL_95:
      *(void *)(a1 + 16) += 8;
      goto LABEL_96;
    }
    if (v5 == v22)
    {
      unint64_t v71 = (v23 - v5) >> 2;
      if (v4 == v5) {
        unint64_t v71 = 1;
      }
      if (v71 >> 61) {
        goto LABEL_110;
      }
      unint64_t v72 = (v71 + 3) >> 2;
      uint64_t v73 = 8 * v71;
      unint64_t v74 = (char *)operator new(8 * v71);
      uint64_t v48 = &v74[8 * v72];
      unint64_t v75 = v48;
      if (v4 != v5)
      {
        unint64_t v75 = &v48[8 * v21];
        unsigned int v76 = &v74[8 * v72];
        unint64_t v77 = v5;
        if ((unint64_t)(v6 - 8) < 0x38) {
          goto LABEL_113;
        }
        uint64_t v78 = &v74[8 * v72];
        unsigned int v76 = v78;
        unint64_t v77 = v5;
        if ((unint64_t)(v78 - v5) < 0x20) {
          goto LABEL_113;
        }
        unint64_t v79 = ((unint64_t)(v6 - 8) >> 3) + 1;
        uint64_t v80 = 8 * (v79 & 0x3FFFFFFFFFFFFFFCLL);
        unsigned int v76 = &v48[v80];
        unint64_t v77 = &v5[v80];
        uint64_t v81 = (long long *)(v5 + 16);
        unsigned int v82 = v78 + 16;
        uint64_t v83 = v79 & 0x3FFFFFFFFFFFFFFCLL;
        do
        {
          long long v84 = *v81;
          *(v82 - 1) = *(v81 - 1);
          *unsigned int v82 = v84;
          v81 += 2;
          v82 += 2;
          v83 -= 4;
        }
        while (v83);
        if (v79 != (v79 & 0x3FFFFFFFFFFFFFFCLL))
        {
LABEL_113:
          do
          {
            uint64_t v85 = *(void *)v77;
            v77 += 8;
            *(void *)unsigned int v76 = v85;
            v76 += 8;
          }
          while (v76 != v75);
        }
      }
      *(void *)a1 = v74;
      *(void *)(a1 + 8) = v48;
      *(void *)(a1 + 16) = v75;
      *(void *)(a1 + 24) = &v74[v73];
      if (v5)
      {
        operator delete(v5);
        uint64_t v48 = *(char **)(a1 + 8);
      }
    }
    else
    {
      uint64_t v48 = v5;
    }
    *((void *)v48 - 1) = v26;
    BOOL v86 = *(char **)(a1 + 8);
    unsigned int v87 = *(char **)(a1 + 16);
    *(void *)(a1 + 8) = v86 - 8;
    uint64_t v88 = *((void *)v86 - 1);
    *(void *)(a1 + 8) = v86;
    if (v87 != *(char **)(a1 + 24))
    {
LABEL_79:
      *(void *)unsigned int v87 = v88;
      goto LABEL_95;
    }
    int v89 = *(char **)a1;
    if ((unint64_t)v86 > *(void *)a1)
    {
      uint64_t v90 = (uint64_t)&v86[-*(void *)a1] >> 3;
      if (v90 >= -1) {
        uint64_t v91 = v90 + 1;
      }
      else {
        uint64_t v91 = v90 + 2;
      }
      uint64_t v92 = v91 >> 1;
      uint64_t v93 = -v92;
      uint64_t v94 = &v86[-8 * v92];
      int64_t v95 = v87 - v86;
      if (v87 != v86)
      {
        memmove(&v86[-8 * v92], v86, v87 - v86);
        BOOL v86 = *(char **)(a1 + 8);
      }
      *(void *)(a1 + 8) = &v86[8 * v93];
      *(void *)(a1 + 16) = &v94[v95];
      *(void *)&v94[v95] = v88;
      goto LABEL_95;
    }
    unint64_t v108 = (v87 - v89) >> 2;
    if (v87 == v89) {
      unint64_t v108 = 1;
    }
    if (!(v108 >> 61))
    {
      unint64_t v109 = v108 >> 2;
      uint64_t v110 = 8 * v108;
      uint64_t v111 = (char *)operator new(8 * v108);
      uint64_t v112 = &v111[8 * v109];
      int64_t v113 = v87 - v86;
      BOOL v44 = v87 == v86;
      unsigned int v87 = v112;
      if (v44) {
        goto LABEL_108;
      }
      unsigned int v87 = &v112[v113 & 0xFFFFFFFFFFFFFFF8];
      unint64_t v114 = v113 - 8;
      if ((unint64_t)(v113 - 8) >= 0x38)
      {
        uint64_t v116 = &v111[8 * v109];
        uint64_t v115 = v116;
        if ((unint64_t)(v116 - v86) >= 0x20)
        {
          uint64_t v117 = (v114 >> 3) + 1;
          uint64_t v118 = 8 * (v117 & 0x3FFFFFFFFFFFFFFCLL);
          uint64_t v115 = &v112[v118];
          unsigned int v119 = &v86[v118];
          uint64_t v120 = (long long *)(v86 + 16);
          uint64_t v121 = v116 + 16;
          uint64_t v122 = v117 & 0x3FFFFFFFFFFFFFFCLL;
          do
          {
            long long v123 = *v120;
            *(v121 - 1) = *(v120 - 1);
            *uint64_t v121 = v123;
            v120 += 2;
            v121 += 2;
            v122 -= 4;
          }
          while (v122);
          BOOL v86 = v119;
          if (v117 == (v117 & 0x3FFFFFFFFFFFFFFCLL))
          {
LABEL_108:
            *(void *)a1 = v111;
            *(void *)(a1 + 8) = v112;
            *(void *)(a1 + 16) = v87;
            *(void *)(a1 + 24) = &v111[v110];
            if (v89)
            {
              operator delete(v89);
              unsigned int v87 = *(char **)(a1 + 16);
            }
            goto LABEL_79;
          }
        }
      }
      else
      {
        uint64_t v115 = &v111[8 * v109];
      }
      do
      {
        uint64_t v124 = *(void *)v86;
        v86 += 8;
        *(void *)uint64_t v115 = v124;
        v115 += 8;
      }
      while (v115 != v87);
      goto LABEL_108;
    }
LABEL_110:
    std::__throw_bad_array_new_length[abi:nn180100]();
  }
  uint64_t v27 = v24 >> 2;
  if (v23 == v22) {
    unint64_t v28 = 1;
  }
  else {
    unint64_t v28 = v27;
  }
  if (v28 >> 61) {
    goto LABEL_110;
  }
  uint64_t v29 = (char *)operator new(8 * v28);
  BOOL v30 = &v29[8 * v21];
  int64_t v31 = &v29[8 * v28];
  uint64_t v32 = operator new(0x1000uLL);
  unint64_t v33 = v32;
  if (v21 == v28)
  {
    if (v6 < 1)
    {
      if (v4 == v5) {
        unint64_t v49 = 1;
      }
      else {
        unint64_t v49 = v6 >> 2;
      }
      if (v49 >> 61) {
        goto LABEL_110;
      }
      uint64_t v50 = (char *)operator new(8 * v49);
      BOOL v30 = &v50[8 * (v49 >> 2)];
      int64_t v31 = &v50[8 * v49];
      operator delete(v29);
      uint64_t v51 = *(char **)(a1 + 8);
      unint64_t v4 = *(char **)(a1 + 16);
      uint64_t v29 = v50;
      *(void *)BOOL v30 = v33;
      uint64_t v35 = v30 + 8;
      if (v4 != v51)
      {
        while (1)
        {
LABEL_47:
          if (v30 == v29)
          {
            if (v35 >= v31)
            {
              unint64_t v56 = (v31 - v30) >> 2;
              if (v31 == v30) {
                unint64_t v56 = 1;
              }
              if (v56 >> 61) {
                goto LABEL_110;
              }
              unint64_t v57 = (v56 + 3) >> 2;
              uint64_t v58 = 8 * v56;
              int v59 = (char *)operator new(8 * v56);
              uint64_t v29 = v59;
              BOOL v52 = &v59[8 * v57];
              uint64_t v37 = v52;
              int64_t v60 = v35 - v30;
              if (v35 != v30)
              {
                uint64_t v37 = &v52[v60 & 0xFFFFFFFFFFFFFFF8];
                unint64_t v61 = v60 - 8;
                unsigned int v62 = &v59[8 * v57];
                uint64_t v63 = v30;
                if (v61 < 0x38) {
                  goto LABEL_114;
                }
                unsigned int v62 = &v59[8 * v57];
                uint64_t v63 = v30;
                if ((unint64_t)(v62 - v30) < 0x20) {
                  goto LABEL_114;
                }
                uint64_t v64 = (v61 >> 3) + 1;
                uint64_t v65 = 8 * (v64 & 0x3FFFFFFFFFFFFFFCLL);
                unsigned int v62 = &v52[v65];
                uint64_t v63 = &v30[v65];
                int v66 = (long long *)(v30 + 16);
                BOOL v67 = &v59[8 * v57 + 16];
                uint64_t v68 = v64 & 0x3FFFFFFFFFFFFFFCLL;
                do
                {
                  long long v69 = *v66;
                  *((_OWORD *)v67 - 1) = *(v66 - 1);
                  *(_OWORD *)BOOL v67 = v69;
                  v66 += 2;
                  v67 += 32;
                  v68 -= 4;
                }
                while (v68);
                if (v64 != (v64 & 0x3FFFFFFFFFFFFFFCLL))
                {
LABEL_114:
                  do
                  {
                    uint64_t v70 = *(void *)v63;
                    v63 += 8;
                    *(void *)unsigned int v62 = v70;
                    v62 += 8;
                  }
                  while (v62 != v37);
                }
              }
              int64_t v31 = &v59[v58];
              operator delete(v30);
            }
            else
            {
              uint64_t v54 = (v31 - v35) >> 3;
              if (v54 >= -1) {
                unint64_t v55 = v54 + 1;
              }
              else {
                unint64_t v55 = v54 + 2;
              }
              uint64_t v37 = &v35[8 * (v55 >> 1)];
              BOOL v52 = &v30[8 * (v55 >> 1)];
              if (v35 == v30)
              {
                uint64_t v29 = v35;
              }
              else
              {
                memmove(&v30[8 * (v55 >> 1)], v30, v35 - v30);
                uint64_t v29 = v30;
              }
            }
          }
          else
          {
            BOOL v52 = v30;
            uint64_t v37 = v35;
          }
          uint64_t v53 = *((void *)v4 - 1);
          v4 -= 8;
          *((void *)v52 - 1) = v53;
          __int16 v36 = v52 - 8;
          uint64_t v35 = v37;
          BOOL v30 = v36;
          if (v4 == *(char **)(a1 + 8)) {
            goto LABEL_29;
          }
        }
      }
      goto LABEL_28;
    }
    unint64_t v34 = v21 + 2;
    if (v21 >= -1) {
      unint64_t v34 = v21 + 1;
    }
    v30 -= 8 * (v34 >> 1);
  }
  *(void *)BOOL v30 = v32;
  uint64_t v35 = v30 + 8;
  if (v4 != v5) {
    goto LABEL_47;
  }
LABEL_28:
  __int16 v36 = v30;
  uint64_t v37 = v35;
LABEL_29:
  uint64_t v38 = *(char **)a1;
  *(void *)a1 = v29;
  *(void *)(a1 + 8) = v36;
  *(void *)(a1 + 16) = v37;
  *(void *)(a1 + 24) = v31;
  uint64_t v2 = a2;
  if (v38) {
    operator delete(v38);
  }
LABEL_96:
  uint64_t v104 = *(void *)(a1 + 40);
  unint64_t v105 = v104 + *(void *)(a1 + 32);
  uint64_t v106 = *(void *)(*(void *)(a1 + 8) + ((v105 >> 6) & 0x3FFFFFFFFFFFFF8));
  uint64_t v107 = *v2;
  *uint64_t v2 = 0;
  *(void *)(v106 + 8 * (v105 & 0x1FF)) = v107;
  *(void *)(a1 + 40) = v104 + 1;
}

uint64_t mlir::OperationName::mightHaveTrait<mlir::OpTrait::IsIsolatedFromAbove>(void ***a1)
{
  {
    uint64_t v11 = a1;
    a1 = v11;
    if (v3)
    {
      uint64_t v12 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::IsIsolatedFromAbove<Empty>]";
      unint64_t v13 = 91;
      unint64_t v4 = llvm::StringRef::find((uint64_t *)&v12, "DesiredTypeName = ", 0x12uLL, 0);
      if (v13 >= v4) {
        unint64_t v5 = v4;
      }
      else {
        unint64_t v5 = v13;
      }
      uint64_t v6 = &v12[v5];
      unint64_t v7 = v13 - v5;
      if (v13 - v5 >= 0x12) {
        uint64_t v8 = 18;
      }
      else {
        uint64_t v8 = v13 - v5;
      }
      unint64_t v9 = v7 - v8;
      if (v9 >= v9 - 1) {
        uint64_t v10 = v9 - 1;
      }
      else {
        uint64_t v10 = v9;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::IsIsolatedFromAbove<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::IsIsolatedFromAbove>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v6[v8], v10);
      a1 = v11;
    }
  }
  unint64_t v1 = *a1;
  if (v1[2] == &mlir::detail::TypeIDResolver<void,void>::id) {
    return 1;
  }
  else {
    return (*((uint64_t (**)(void **, uint64_t))*v1 + 4))(v1, mlir::detail::TypeIDResolver<mlir::OpTrait::IsIsolatedFromAbove<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::IsIsolatedFromAbove>(void)::Empty>,void>::resolveTypeID(void)::id);
  }
}

uint64_t llvm::ScopedHashTable<mlir::Operation *,mlir::Operation *,anonymous namespace'::SimpleOperationInfo,llvm::RecyclingAllocator<llvm::BumpPtrAllocatorImpl<llvm::MallocAllocator,4096ul,4096ul,128ul>,llvm::ScopedHashTableVal<mlir::Operation *,mlir::Operation *>,32ul,8ul>>::lookup(uint64_t a1, uint64_t a2)
{
  int v3 = *(_DWORD *)(a1 + 120);
  if (v3)
  {
    uint64_t v5 = *(void *)(a1 + 104);
    unsigned int v6 = v3 - 1;
    LODWORD(v7) = v6 & mlir::OperationEquivalence::computeHash(a2, (uint64_t (*)(uint64_t, void))llvm::function_ref<llvm::hash_code ()(mlir::Value)>::callback_fn<llvm::hash_code ()(mlir::Value)>, (uint64_t)mlir::OperationEquivalence::directHashValue, (uint64_t (*)(uint64_t, uint64_t))llvm::function_ref<llvm::hash_code ()(mlir::Value)>::callback_fn<llvm::hash_code ()(mlir::Value)>, (uint64_t)mlir::OperationEquivalence::ignoreHashValue, 1);
    uint64_t v8 = (uint64_t *)(v5 + 16 * v7);
    uint64_t v9 = *v8;
    if (*v8 == a2) {
      goto LABEL_15;
    }
    if ((a2 | 0x1000) == 0xFFFFFFFFFFFFF000)
    {
      int v10 = 1;
      while (v9 != -4096)
      {
        int v11 = v7 + v10++;
        uint64_t v7 = v11 & v6;
        uint64_t v9 = *(void *)(v5 + 16 * v7);
        if (v9 == a2)
        {
          uint64_t v8 = (uint64_t *)(v5 + 16 * v7);
          goto LABEL_15;
        }
      }
    }
    else
    {
      int v12 = 1;
      while (1)
      {
        if ((v9 | 0x1000) != 0xFFFFFFFFFFFFF000) {
          mlir::OperationEquivalence::isEquivalentTo(a2, v9, 1);
        }
        if (v9 == -4096) {
          break;
        }
        int v13 = v7 + v12++;
        LODWORD(v7) = v13 & v6;
        uint64_t v8 = (uint64_t *)(v5 + 16 * (v13 & v6));
        uint64_t v9 = *v8;
        if (*v8 == a2) {
          goto LABEL_15;
        }
      }
    }
  }
  uint64_t v8 = (uint64_t *)(*(void *)(a1 + 104) + 16 * *(unsigned int *)(a1 + 120));
LABEL_15:
  if (v8 == (uint64_t *)(*(void *)(a1 + 104) + 16 * *(unsigned int *)(a1 + 120))) {
    return 0;
  }
  else {
    return *(void *)(v8[1] + 24);
  }
}

void anonymous namespace'::CSEDriver::replaceUsesAndDelete(uint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4, int a5)
{
  uint64_t v5 = a3;
  unsigned int v6 = a1;
  uint64_t v103 = *MEMORY[0x263EF8340];
  if (a5)
  {
    uint64_t v7 = *(void *)(*a1 + 16);
    if (v7 && mlir::RewriterBase::Listener::classof(*(void *)(*a1 + 16))) {
      (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)v7 + 40))(v7, v5, a4);
    }
    uint64_t v8 = *v6;
    unint64_t v9 = *(unsigned int *)(v5 + 36);
    if (v9) {
      uint64_t v10 = v5 - 16;
    }
    else {
      uint64_t v10 = 0;
    }
    mlir::ValueRange::ValueRange(v98, v10, v9);
    unint64_t v11 = *(unsigned int *)(a4 + 36);
    if (v11) {
      uint64_t v12 = a4 - 16;
    }
    else {
      uint64_t v12 = 0;
    }
    mlir::ValueRange::ValueRange(v97, v12, v11);
    mlir::RewriterBase::replaceAllUsesWith(v8, v98[0], v98[1], v97[0], v97[1]);
    uint64_t v14 = (char *)v6[2];
    unint64_t v13 = v6[3];
    if ((unint64_t)v14 >= v13)
    {
      uint64_t v15 = (char *)v6[1];
      uint64_t v16 = (v14 - v15) >> 3;
      unint64_t v17 = v16 + 1;
      if (!((unint64_t)(v16 + 1) >> 61))
      {
        uint64_t v18 = v13 - (void)v15;
        if (v18 >> 2 > v17) {
          unint64_t v17 = v18 >> 2;
        }
        if ((unint64_t)v18 >= 0x7FFFFFFFFFFFFFF8) {
          unint64_t v19 = 0x1FFFFFFFFFFFFFFFLL;
        }
        else {
          unint64_t v19 = v17;
        }
        if (!v19)
        {
          uint64_t v20 = 0;
          uint64_t v21 = (char *)(8 * v16);
          unint64_t v22 = 0;
          *(void *)(8 * v16) = v5;
          uint64_t v23 = 8 * v16 + 8;
          uint64_t v24 = (char *)(v14 - v15);
          if (v14 == v15) {
            goto LABEL_104;
          }
LABEL_89:
          unint64_t v69 = (unint64_t)(v24 - 8);
          if (v69 < 0x58) {
            goto LABEL_115;
          }
          if ((unint64_t)(v15 - v20) < 0x20) {
            goto LABEL_115;
          }
          uint64_t v70 = (v69 >> 3) + 1;
          uint64_t v71 = 8 * (v70 & 0x3FFFFFFFFFFFFFFCLL);
          unint64_t v72 = &v14[-v71];
          v21 -= v71;
          uint64_t v73 = &v20[8 * v16 - 16];
          unint64_t v74 = v14 - 16;
          uint64_t v75 = v70 & 0x3FFFFFFFFFFFFFFCLL;
          do
          {
            long long v76 = *(_OWORD *)v74;
            *((_OWORD *)v73 - 1) = *((_OWORD *)v74 - 1);
            *(_OWORD *)uint64_t v73 = v76;
            v73 -= 32;
            v74 -= 32;
            v75 -= 4;
          }
          while (v75);
          uint64_t v14 = v72;
          if (v70 != (v70 & 0x3FFFFFFFFFFFFFFCLL))
          {
LABEL_115:
            do
            {
              uint64_t v77 = *((void *)v14 - 1);
              v14 -= 8;
              *((void *)v21 - 1) = v77;
              v21 -= 8;
            }
            while (v14 != v15);
          }
LABEL_103:
          uint64_t v14 = (char *)v6[1];
          goto LABEL_104;
        }
        if (!(v19 >> 61))
        {
          uint64_t v20 = (char *)operator new(8 * v19);
          uint64_t v21 = &v20[8 * v16];
          unint64_t v22 = &v20[8 * v19];
          *(void *)uint64_t v21 = v5;
          uint64_t v23 = (uint64_t)(v21 + 8);
          uint64_t v24 = (char *)(v14 - v15);
          if (v14 == v15) {
            goto LABEL_104;
          }
          goto LABEL_89;
        }
LABEL_112:
        std::__throw_bad_array_new_length[abi:nn180100]();
      }
      goto LABEL_111;
    }
    goto LABEL_77;
  }
  uint64_t v93 = a2;
  uint64_t v26 = *(void *)(*a1 + 16);
  if (v26 && mlir::RewriterBase::Listener::classof(*(void *)(*a1 + 16)))
  {
    int v27 = *(_DWORD *)(a3 + 36);
    unint64_t v28 = (mlir::detail::OpResultImpl *)(a3 - 16);
    if (!v27) {
      unint64_t v28 = 0;
    }
    int v89 = v28;
    uint64_t v90 = *(unsigned int *)(a3 + 36);
    if (v27)
    {
      for (uint64_t i = 0; i != v90; ++i)
      {
        BOOL v30 = *(void **)mlir::detail::OpResultImpl::getNextResultAtOffset((uint64_t)v89, i);
        int v31 = *(_DWORD *)(a2 + 120);
        if (v30) {
          BOOL v32 = v31 == 0;
        }
        else {
          BOOL v32 = 1;
        }
        if (!v32)
        {
          if (!v31) {
            goto LABEL_47;
          }
LABEL_35:
          uint64_t v33 = v30[2];
          uint64_t v34 = *(void *)(a2 + 104);
          unsigned int v35 = v31 - 1;
          unsigned int v36 = (v31 - 1) & mlir::OperationEquivalence::computeHash(v33, (uint64_t (*)(uint64_t, void))llvm::function_ref<llvm::hash_code ()(mlir::Value)>::callback_fn<llvm::hash_code ()(mlir::Value)>, (uint64_t)mlir::OperationEquivalence::directHashValue, (uint64_t (*)(uint64_t, uint64_t))llvm::function_ref<llvm::hash_code ()(mlir::Value)>::callback_fn<llvm::hash_code ()(mlir::Value)>, (uint64_t)mlir::OperationEquivalence::ignoreHashValue, 1);
          uint64_t v37 = *(void *)(v34 + 16 * v36);
          if (v37 == v33) {
            continue;
          }
          if ((v33 | 0x1000) == 0xFFFFFFFFFFFFF000)
          {
            int v38 = 1;
            do
            {
              if (v37 == -4096) {
                goto LABEL_47;
              }
              unsigned int v39 = v36 + v38++;
              unsigned int v36 = v39 & v35;
              uint64_t v37 = *(void *)(v34 + 16 * (v39 & v35));
            }
            while (v37 != v33);
            continue;
          }
          int v40 = 1;
          while (1)
          {
            if ((v37 | 0x1000) != 0xFFFFFFFFFFFFF000) {
              mlir::OperationEquivalence::isEquivalentTo(v33, v37, 1);
            }
            if (v37 == -4096) {
              break;
            }
            unsigned int v41 = v36 + v40++;
            unsigned int v36 = v41 & v35;
            uint64_t v37 = *(void *)(v34 + 16 * (v41 & v35));
            if (v37 == v33) {
              goto LABEL_29;
            }
          }
LABEL_47:
          while (1)
          {
            BOOL v30 = (void *)*v30;
            if (!v30) {
              break;
            }
            int v31 = *(_DWORD *)(a2 + 120);
            if (v31) {
              goto LABEL_35;
            }
          }
        }
        (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)v26 + 40))(v26, a3, a4);
LABEL_29:
        ;
      }
    }
  }
  unsigned int v6 = a1;
  uint64_t v42 = *a1;
  unint64_t v43 = *(unsigned int *)(a3 + 36);
  if (v43) {
    uint64_t v44 = a3 - 16;
  }
  else {
    uint64_t v44 = 0;
  }
  mlir::ValueRange::ValueRange(&v95, v44, v43);
  unint64_t v45 = *(unsigned int *)(a4 + 36);
  if (v45) {
    uint64_t v46 = a4 - 16;
  }
  else {
    uint64_t v46 = 0;
  }
  mlir::ValueRange::ValueRange(v94, v46, v45);
  unint64_t v47 = v95;
  uint64_t v48 = v96;
  unint64_t v49 = v94[0];
  unint64_t v50 = v94[1];
  unint64_t v99 = v95;
  uint64_t v100 = 0;
  unint64_t v101 = v94[0];
  uint64_t v102 = 0;
  if (v96)
  {
    uint64_t v51 = 0;
    uint64_t v52 = 0;
    do
    {
      if (v101 == v49 && v52 == v50) {
        break;
      }
      uint64_t v54 = (uint64_t **)mlir::ValueRange::dereference_iterator(&v99, v51);
      unint64_t v55 = (uint64_t *)mlir::ValueRange::dereference_iterator(&v101, v102);
      uint64_t v51 = v100 + 1;
      uint64_t v52 = v102 + 1;
      ++v100;
      ++v102;
    }
    while (v99 != v47 || v51 != v48);
  }
  uint64_t v5 = a3;
  uint64_t v57 = *(unsigned int *)(a3 + 36);
  if (v57) {
    uint64_t v58 = a3 - 16;
  }
  else {
    uint64_t v58 = 0;
  }
  if (!v57)
  {
LABEL_76:
    uint64_t v14 = (char *)a1[2];
    unint64_t v61 = a1[3];
    if ((unint64_t)v14 >= v61)
    {
      unsigned int v62 = (char *)a1[1];
      uint64_t v63 = (v14 - v62) >> 3;
      unint64_t v64 = v63 + 1;
      if (!((unint64_t)(v63 + 1) >> 61))
      {
        uint64_t v65 = v61 - (void)v62;
        if (v65 >> 2 > v64) {
          unint64_t v64 = v65 >> 2;
        }
        if ((unint64_t)v65 >= 0x7FFFFFFFFFFFFFF8) {
          unint64_t v66 = 0x1FFFFFFFFFFFFFFFLL;
        }
        else {
          unint64_t v66 = v64;
        }
        if (v66)
        {
          if (v66 >> 61) {
            goto LABEL_112;
          }
          BOOL v67 = (char *)operator new(8 * v66);
          uint64_t v21 = &v67[8 * v63];
          unint64_t v22 = &v67[8 * v66];
          *(void *)uint64_t v21 = a3;
          uint64_t v23 = (uint64_t)(v21 + 8);
          uint64_t v68 = (char *)(v14 - v62);
          if (v14 == v62)
          {
LABEL_104:
            v6[1] = (uint64_t)v21;
            v6[2] = v23;
            v6[3] = (uint64_t)v22;
            if (v14) {
              operator delete(v14);
            }
            goto LABEL_106;
          }
        }
        else
        {
          BOOL v67 = 0;
          uint64_t v21 = (char *)(8 * v63);
          unint64_t v22 = 0;
          *(void *)(8 * v63) = a3;
          uint64_t v23 = 8 * v63 + 8;
          uint64_t v68 = (char *)(v14 - v62);
          if (v14 == v62) {
            goto LABEL_104;
          }
        }
        unint64_t v78 = (unint64_t)(v68 - 8);
        if (v78 < 0x58) {
          goto LABEL_116;
        }
        if ((unint64_t)(v62 - v67) < 0x20) {
          goto LABEL_116;
        }
        uint64_t v79 = (v78 >> 3) + 1;
        uint64_t v80 = 8 * (v79 & 0x3FFFFFFFFFFFFFFCLL);
        uint64_t v81 = &v14[-v80];
        v21 -= v80;
        unsigned int v82 = &v67[8 * v63 - 16];
        uint64_t v83 = v14 - 16;
        uint64_t v84 = v79 & 0x3FFFFFFFFFFFFFFCLL;
        do
        {
          long long v85 = *(_OWORD *)v83;
          *((_OWORD *)v82 - 1) = *((_OWORD *)v83 - 1);
          *(_OWORD *)unsigned int v82 = v85;
          v82 -= 32;
          v83 -= 32;
          v84 -= 4;
        }
        while (v84);
        uint64_t v14 = v81;
        if (v79 != (v79 & 0x3FFFFFFFFFFFFFFCLL))
        {
LABEL_116:
          do
          {
            uint64_t v86 = *((void *)v14 - 1);
            v14 -= 8;
            *((void *)v21 - 1) = v86;
            v21 -= 8;
          }
          while (v14 != v62);
        }
        goto LABEL_103;
      }
LABEL_111:
      abort();
    }
LABEL_77:
    *(void *)uint64_t v14 = v5;
    uint64_t v23 = (uint64_t)(v14 + 8);
LABEL_106:
    v6[2] = v23;
    goto LABEL_107;
  }
  if (!*(void *)mlir::detail::OpResultImpl::getNextResultAtOffset(a3 - 16, 0))
  {
    uint64_t v59 = 1;
    while (v57 != v59)
    {
      uint64_t NextResultAtOffset = (void *)mlir::detail::OpResultImpl::getNextResultAtOffset(v58, v59++);
      if (*NextResultAtOffset) {
        goto LABEL_107;
      }
    }
    goto LABEL_76;
  }
LABEL_107:
  if (*(_UNKNOWN **)(**(void **)(a4 + 24) + 136) == &mlir::detail::TypeIDResolver<mlir::UnknownLoc,void>::id)
  {
    uint64_t v87 = *(void *)(v5 + 24);
    if (*(_UNKNOWN **)(*(void *)v87 + 136) != &mlir::detail::TypeIDResolver<mlir::UnknownLoc,void>::id) {
      *(void *)(a4 + 24) = v87;
    }
  }
  ++v6[8];
}

BOOL llvm::all_of<llvm::SmallVector<mlir::SideEffects::EffectInstance<mlir::MemoryEffects::Effect>,4u> &,BOOL mlir::MemoryEffectOpInterface::onlyHasEffect<mlir::MemoryEffects::Read>(void)::{lambda(llvm::SmallVector<mlir::SideEffects::EffectInstance<mlir::MemoryEffects::Effect>,4u> & const&)#1}>(uint64_t a1)
{
  unsigned int v1 = *(_DWORD *)(a1 + 8);
  if (!v1) {
    return 1;
  }
  uint64_t v2 = 40 * v1;
  int v3 = *(uint64_t ***)a1;
  uint64_t v4 = v2 - 40;
  uint64_t v5 = &unk_267771000;
  do
  {
    uint64_t v6 = **v3;
    {
      uint64_t v20 = v4;
      uint64_t v21 = v3;
      uint64_t v19 = v6;
      uint64_t v6 = v19;
      uint64_t v4 = v20;
      uint64_t v5 = (void *)&unk_267771000;
      int v3 = v21;
      if (v10)
      {
        unint64_t v22 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::MemoryEffects::Read]";
        unint64_t v23 = 75;
        unint64_t v11 = llvm::StringRef::find((uint64_t *)&v22, "DesiredTypeName = ", 0x12uLL, 0);
        if (v23 >= v11) {
          unint64_t v12 = v11;
        }
        else {
          unint64_t v12 = v23;
        }
        unint64_t v13 = &v22[v12];
        unint64_t v14 = v23 - v12;
        uint64_t v15 = 18;
        if (v14 < 0x12) {
          uint64_t v15 = v14;
        }
        uint64_t v16 = (uint64_t)&v13[v15];
        unint64_t v17 = v14 - v15;
        if (v17 >= v17 - 1) {
          uint64_t v18 = v17 - 1;
        }
        else {
          uint64_t v18 = v17;
        }
        mlir::detail::TypeIDResolver<mlir::MemoryEffects::Read,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID(v16, v18);
        uint64_t v6 = v19;
        uint64_t v4 = v20;
        uint64_t v5 = (void *)&unk_267771000;
        int v3 = v21;
      }
    }
    uint64_t v7 = v5[408];
    BOOL result = v6 == v7;
    BOOL v9 = v6 != v7 || v4 == 0;
    v4 -= 40;
    v3 += 5;
  }
  while (!v9);
  return result;
}

unint64_t mlir::OperationEquivalence::directHashValue(unint64_t a1)
{
  unsigned int v1 = &unk_267770000;
  {
    unint64_t v8 = a1;
    unsigned int v1 = &unk_267770000;
    int v6 = v5;
    a1 = v8;
    if (v6)
    {
      unint64_t v7 = llvm::hashing::detail::fixed_seed_override;
      if (!llvm::hashing::detail::fixed_seed_override) {
        unint64_t v7 = 0xFF51AFD7ED558CCDLL;
      }
      llvm::hashing::detail::get_execution_seed(void)::seed = v7;
      unsigned int v1 = (void *)&unk_267770000;
      a1 = v8;
    }
  }
  unint64_t v2 = 0x9DDFEA08EB382D69 * ((v1[385] + 8 * a1) ^ HIDWORD(a1));
  unint64_t v3 = 0x9DDFEA08EB382D69 * (HIDWORD(a1) ^ (v2 >> 47) ^ v2);
  return 0x9DDFEA08EB382D69 * (v3 ^ (v3 >> 47));
}

uint64_t mlir::OperationEquivalence::ignoreHashValue()
{
  return 0;
}

uint64_t llvm::function_ref<llvm::hash_code ()(mlir::Value)>::callback_fn<llvm::hash_code ()(mlir::Value)>(uint64_t (*a1)(uint64_t), uint64_t a2)
{
  return a1(a2);
}

uint64_t *llvm::DenseMapBase<llvm::DenseMap<mlir::Operation *,std::pair<mlir::Operation *,mlir::MemoryEffects::Effect *>,llvm::DenseMapInfo<mlir::Operation *,void>,llvm::detail::DenseMapPair<mlir::Operation *,std::pair<mlir::Operation *,mlir::MemoryEffects::Effect *>>>,mlir::Operation *,std::pair<mlir::Operation *,mlir::MemoryEffects::Effect *>,llvm::DenseMapInfo<mlir::Operation *,void>,llvm::detail::DenseMapPair<mlir::Operation *,std::pair<mlir::Operation *,mlir::MemoryEffects::Effect *>>>::InsertIntoBucket<mlir::Operation * const&,std::pair<mlir::Operation *,decltype(nullptr)>>(uint64_t a1, uint64_t *a2, uint64_t *a3, uint64_t *a4)
{
  int v8 = *(_DWORD *)(a1 + 8);
  unsigned int v9 = *(_DWORD *)(a1 + 16);
  if (4 * v8 + 4 >= 3 * v9)
  {
    v9 *= 2;
  }
  else if (v9 + ~v8 - *(_DWORD *)(a1 + 12) > v9 >> 3)
  {
LABEL_3:
    uint64_t v10 = *a2;
    goto LABEL_4;
  }
  llvm::DenseMap<mlir::Operation *,mlir::ValueRange,llvm::DenseMapInfo<mlir::Operation *,void>,llvm::detail::DenseMapPair<mlir::Operation *,mlir::ValueRange>>::grow(a1, v9);
  uint64_t v10 = *a3;
  int v12 = *(_DWORD *)(a1 + 16) - 1;
  unsigned int v13 = ((*a3 >> 4) ^ (*a3 >> 9)) & v12;
  a2 = (uint64_t *)(*(void *)a1 + 24 * v13);
  uint64_t v14 = *a2;
  if (*a3 != *a2)
  {
    uint64_t v15 = 0;
    int v16 = 1;
    while (v14 != -4096)
    {
      if (v15) {
        BOOL v17 = 0;
      }
      else {
        BOOL v17 = v14 == -8192;
      }
      if (v17) {
        uint64_t v15 = a2;
      }
      unsigned int v18 = v13 + v16++;
      unsigned int v13 = v18 & v12;
      a2 = (uint64_t *)(*(void *)a1 + 24 * (v18 & v12));
      uint64_t v14 = *a2;
      if (v10 == *a2) {
        goto LABEL_4;
      }
    }
    if (v15) {
      a2 = v15;
    }
    goto LABEL_3;
  }
LABEL_4:
  ++*(_DWORD *)(a1 + 8);
  if (v10 != -4096) {
    --*(_DWORD *)(a1 + 12);
  }
  *a2 = *a3;
  a2[1] = *a4;
  a2[2] = 0;
  return a2;
}

BOOL llvm::function_ref<BOOL ()(mlir::OpOperand &)>::callback_fn<anonymous namespace'::CSEDriver::replaceUsesAndDelete(llvm::ScopedHashTable<mlir::Operation *,mlir::Operation *,anonymous namespace'::SimpleOperationInfo,llvm::RecyclingAllocator<llvm::BumpPtrAllocatorImpl<llvm::MallocAllocator,4096ul,4096ul,128ul>,llvm::ScopedHashTableVal<mlir::Operation *,mlir::Operation *>,32ul,8ul>> &,mlir::Operation *,mlir::Operation *,BOOL)::$_0>(uint64_t a1, uint64_t a2)
{
  int v2 = *(_DWORD *)(*(void *)a1 + 120);
  if (!v2) {
    return 1;
  }
  uint64_t v3 = *(void *)(a2 + 16);
  uint64_t v4 = *(void *)(*(void *)a1 + 104);
  unsigned int v5 = v2 - 1;
  unsigned int v6 = v5 & mlir::OperationEquivalence::computeHash(v3, (uint64_t (*)(uint64_t, void))llvm::function_ref<llvm::hash_code ()(mlir::Value)>::callback_fn<llvm::hash_code ()(mlir::Value)>, (uint64_t)mlir::OperationEquivalence::directHashValue, (uint64_t (*)(uint64_t, uint64_t))llvm::function_ref<llvm::hash_code ()(mlir::Value)>::callback_fn<llvm::hash_code ()(mlir::Value)>, (uint64_t)mlir::OperationEquivalence::ignoreHashValue, 1);
  uint64_t v7 = *(void *)(v4 + 16 * v6);
  if (v7 == v3) {
    return 0;
  }
  if ((v3 | 0x1000) == 0xFFFFFFFFFFFFF000)
  {
    int v8 = 1;
    do
    {
      BOOL result = v7 == -4096;
      if (v7 == -4096) {
        break;
      }
      BOOL result = 0;
      unsigned int v10 = v6 + v8++;
      unsigned int v6 = v10 & v5;
      uint64_t v7 = *(void *)(v4 + 16 * (v10 & v5));
    }
    while (v7 != v3);
  }
  else
  {
    int v11 = 1;
    while (1)
    {
      if ((v7 | 0x1000) != 0xFFFFFFFFFFFFF000) {
        mlir::OperationEquivalence::isEquivalentTo(v3, v7, 1);
      }
      if (v7 == -4096) {
        break;
      }
      BOOL result = 0;
      unsigned int v12 = v6 + v11++;
      unsigned int v6 = v12 & v5;
      uint64_t v7 = *(void *)(v4 + 16 * (v12 & v5));
      if (v7 == v3) {
        return result;
      }
    }
    return 1;
  }
  return result;
}

uint64_t *llvm::DenseMapBase<llvm::DenseMap<mlir::Operation *,llvm::ScopedHashTableVal<mlir::Operation *,mlir::Operation *> *,anonymous namespace'::SimpleOperationInfo,llvm::detail::DenseMapPair<mlir::Operation *,llvm::ScopedHashTableVal<mlir::Operation *,mlir::Operation *> *>>,mlir::Operation *,llvm::ScopedHashTableVal<mlir::Operation *,mlir::Operation *> *,anonymous namespace'::SimpleOperationInfo,llvm::detail::DenseMapPair<mlir::Operation *,llvm::ScopedHashTableVal<mlir::Operation *,mlir::Operation *> *>>::operator[](uint64_t a1, uint64_t *a2)
{
  int v4 = *(_DWORD *)(a1 + 16);
  if (v4)
  {
    unsigned int v5 = *(llvm **)a1;
    unsigned int v6 = v4 - 1;
    unsigned int v7 = (v4 - 1) & mlir::OperationEquivalence::computeHash(*a2, (uint64_t (*)(uint64_t, void))llvm::function_ref<llvm::hash_code ()(mlir::Value)>::callback_fn<llvm::hash_code ()(mlir::Value)>, (uint64_t)mlir::OperationEquivalence::directHashValue, (uint64_t (*)(uint64_t, uint64_t))llvm::function_ref<llvm::hash_code ()(mlir::Value)>::callback_fn<llvm::hash_code ()(mlir::Value)>, (uint64_t)mlir::OperationEquivalence::ignoreHashValue, 1);
    int v8 = (uint64_t *)((char *)v5 + 16 * v7);
    uint64_t v9 = *a2;
    uint64_t v10 = *v8;
    if (*a2 == *v8) {
      return v8 + 1;
    }
    int v11 = 0;
    int v12 = 1;
    while (1)
    {
      if (v10 != -4096 && v10 != -8192 && v9 != -8192 && v9 != -4096) {
        mlir::OperationEquivalence::isEquivalentTo(v9, v10, 1);
      }
      if (v10 == -4096) {
        break;
      }
      if (v11) {
        BOOL v13 = 0;
      }
      else {
        BOOL v13 = v10 == -8192;
      }
      if (v13) {
        int v11 = v8;
      }
      unsigned int v14 = v7 + v12++;
      unsigned int v7 = v14 & v6;
      int v8 = (uint64_t *)((char *)v5 + 16 * (v14 & v6));
      uint64_t v9 = *a2;
      uint64_t v10 = *v8;
      if (*a2 == *v8) {
        return v8 + 1;
      }
    }
    if (v11) {
      int v8 = v11;
    }
    unsigned int v15 = *(_DWORD *)(a1 + 16);
    int v20 = *(_DWORD *)(a1 + 8);
    if (4 * v20 + 4 < 3 * v15)
    {
      BOOL v16 = v15 + ~v20 - *(_DWORD *)(a1 + 12) > v15 >> 3;
      int v17 = *(_DWORD *)(a1 + 16);
      if (v16) {
        goto LABEL_20;
      }
      goto LABEL_29;
    }
  }
  else
  {
    unsigned int v15 = 0;
  }
  int v17 = 2 * v15;
LABEL_29:
  uint64_t v21 = *(llvm **)a1;
  unint64_t v22 = (v17 - 1) | ((unint64_t)(v17 - 1) >> 1);
  unint64_t v23 = v22 | (v22 >> 2) | ((v22 | (v22 >> 2)) >> 4);
  int v24 = ((v23 | (v23 >> 8)) >> 16) | v23 | (v23 >> 8);
  if ((v24 + 1) > 0x40) {
    unsigned int v25 = v24 + 1;
  }
  else {
    unsigned int v25 = 64;
  }
  *(_DWORD *)(a1 + 16) = v25;
  buffer = llvm::allocate_buffer(16 * v25, (std::align_val_t)8uLL);
  int v27 = buffer;
  *(void *)a1 = buffer;
  uint64_t v59 = v21;
  if (v21)
  {
    uint64_t v58 = v15;
    *(void *)(a1 + 8) = 0;
    uint64_t v28 = *(unsigned int *)(a1 + 16);
    if (v28)
    {
      uint64_t v29 = buffer;
      if (((v28 - 1) & 0xFFFFFFFFFFFFFFFLL) == 0) {
        goto LABEL_38;
      }
      uint64_t v30 = ((v28 - 1) & 0xFFFFFFFFFFFFFFFLL) + 1;
      uint64_t v29 = &buffer[2 * (v30 & 0x1FFFFFFFFFFFFFFELL)];
      int v31 = buffer + 2;
      uint64_t v32 = v30 & 0x1FFFFFFFFFFFFFFELL;
      do
      {
        *(v31 - 2) = -4096;
        void *v31 = -4096;
        v31 += 4;
        v32 -= 2;
      }
      while (v32);
      if (v30 != (v30 & 0x1FFFFFFFFFFFFFFELL))
      {
LABEL_38:
        uint64_t v33 = &buffer[2 * v28];
        do
        {
          void *v29 = -4096;
          v29 += 2;
        }
        while (v29 != v33);
      }
    }
    if (v15)
    {
      uint64_t v34 = (uint64_t *)v21;
      unsigned int v35 = (uint64_t *)((char *)v21 + 16 * v15);
      do
      {
        if ((*v34 | 0x1000) != 0xFFFFFFFFFFFFF000)
        {
          uint64_t v44 = *(llvm **)a1;
          int v45 = *(_DWORD *)(a1 + 16) - 1;
          unsigned int v40 = v45 & mlir::OperationEquivalence::computeHash(*v34, (uint64_t (*)(uint64_t, void))llvm::function_ref<llvm::hash_code ()(mlir::Value)>::callback_fn<llvm::hash_code ()(mlir::Value)>, (uint64_t)mlir::OperationEquivalence::directHashValue, (uint64_t (*)(uint64_t, uint64_t))llvm::function_ref<llvm::hash_code ()(mlir::Value)>::callback_fn<llvm::hash_code ()(mlir::Value)>, (uint64_t)mlir::OperationEquivalence::ignoreHashValue, 1);
          unsigned int v41 = (uint64_t *)((char *)v44 + 16 * v40);
          uint64_t v42 = *v34;
          uint64_t v43 = *v41;
          if (*v34 != *v41)
          {
            uint64_t v37 = 0;
            int v39 = 1;
            while (1)
            {
              if (v43 != -4096 && v43 != -8192 && v42 != -8192 && v42 != -4096) {
                mlir::OperationEquivalence::isEquivalentTo(v42, v43, 1);
              }
              if (v43 == -4096) {
                break;
              }
              if (v37) {
                BOOL v36 = 0;
              }
              else {
                BOOL v36 = v43 == -8192;
              }
              if (v36) {
                uint64_t v37 = v41;
              }
              unsigned int v38 = v40 + v39++;
              unsigned int v40 = v38 & v45;
              unsigned int v41 = (uint64_t *)((char *)v44 + 16 * (v38 & v45));
              uint64_t v42 = *v34;
              uint64_t v43 = *v41;
              if (*v34 == *v41) {
                goto LABEL_61;
              }
            }
            if (v37) {
              unsigned int v41 = v37;
            }
          }
LABEL_61:
          *unsigned int v41 = *v34;
          v41[1] = v34[1];
          ++*(_DWORD *)(a1 + 8);
        }
        v34 += 2;
      }
      while (v34 != v35);
    }
    llvm::deallocate_buffer(v59, (void *)(16 * v58));
  }
  *(void *)(a1 + 8) = 0;
  uint64_t v46 = *(unsigned int *)(a1 + 16);
  if (v46)
  {
    unint64_t v47 = buffer;
    if (((v46 - 1) & 0xFFFFFFFFFFFFFFFLL) == 0) {
      goto LABEL_90;
    }
    uint64_t v48 = ((v46 - 1) & 0xFFFFFFFFFFFFFFFLL) + 1;
    unint64_t v47 = &buffer[2 * (v48 & 0x1FFFFFFFFFFFFFFELL)];
    unint64_t v49 = buffer + 2;
    uint64_t v50 = v48 & 0x1FFFFFFFFFFFFFFELL;
    do
    {
      *(v49 - 2) = -4096;
      *unint64_t v49 = -4096;
      v49 += 4;
      v50 -= 2;
    }
    while (v50);
    if (v48 != (v48 & 0x1FFFFFFFFFFFFFFELL))
    {
LABEL_90:
      do
      {
        *unint64_t v47 = -4096;
        v47 += 2;
      }
      while (v47 != &buffer[2 * v46]);
    }
  }
  unsigned int v51 = v46 - 1;
  unsigned int v52 = (v46 - 1) & mlir::OperationEquivalence::computeHash(*a2, (uint64_t (*)(uint64_t, void))llvm::function_ref<llvm::hash_code ()(mlir::Value)>::callback_fn<llvm::hash_code ()(mlir::Value)>, (uint64_t)mlir::OperationEquivalence::directHashValue, (uint64_t (*)(uint64_t, uint64_t))llvm::function_ref<llvm::hash_code ()(mlir::Value)>::callback_fn<llvm::hash_code ()(mlir::Value)>, (uint64_t)mlir::OperationEquivalence::ignoreHashValue, 1);
  int v8 = &v27[2 * v52];
  uint64_t v18 = *a2;
  uint64_t v53 = *v8;
  if (*a2 == *v8) {
    goto LABEL_21;
  }
  uint64_t v54 = 0;
  int v55 = 1;
  while (1)
  {
    if (v53 != -4096 && v53 != -8192 && v18 != -8192 && v18 != -4096) {
      mlir::OperationEquivalence::isEquivalentTo(v18, v53, 1);
    }
    if (v53 == -4096) {
      break;
    }
    if (v54) {
      BOOL v56 = 0;
    }
    else {
      BOOL v56 = v53 == -8192;
    }
    if (v56) {
      uint64_t v54 = v8;
    }
    unsigned int v57 = v52 + v55++;
    unsigned int v52 = v57 & v51;
    int v8 = &v27[2 * (v57 & v51)];
    uint64_t v18 = *a2;
    uint64_t v53 = *v8;
    if (*a2 == *v8) {
      goto LABEL_21;
    }
  }
  if (v54) {
    int v8 = v54;
  }
LABEL_20:
  uint64_t v18 = *v8;
LABEL_21:
  ++*(_DWORD *)(a1 + 8);
  if (v18 != -4096) {
    --*(_DWORD *)(a1 + 12);
  }
  *int v8 = *a2;
  v8[1] = 0;
  return v8 + 1;
}

void *llvm::RecyclingAllocator<llvm::BumpPtrAllocatorImpl<llvm::MallocAllocator,4096ul,4096ul,128ul>,llvm::ScopedHashTableVal<mlir::Operation *,mlir::Operation *>,32ul,8ul>::Allocate<llvm::ScopedHashTableVal<mlir::Operation *,mlir::Operation *>>(uint64_t a1)
{
  BOOL result = *(void **)a1;
  if (result)
  {
    *(void *)a1 = *result;
  }
  else
  {
    *(void *)(a1 + 88) += 32;
    uint64_t v3 = *(void *)(a1 + 8);
    if (v3) {
      BOOL v4 = ((v3 + 7) & 0xFFFFFFFFFFFFFFF8) - v3 + 32 > *(void *)(a1 + 16) - v3;
    }
    else {
      BOOL v4 = 1;
    }
    if (v4)
    {
      unsigned int v5 = *(_DWORD *)(a1 + 32) >> 7;
      if (v5 >= 0x1E) {
        LOBYTE(v5) = 30;
      }
      uint64_t v6 = 4096 << v5;
      buffer = (char *)llvm::allocate_buffer(4096 << v5, (std::align_val_t)8uLL);
      uint64_t v8 = *(unsigned int *)(a1 + 32);
      if (v8 >= *(_DWORD *)(a1 + 36))
      {
        uint64_t v10 = buffer;
        llvm::SmallVectorBase<unsigned int>::grow_pod(a1 + 24, (void *)(a1 + 40), v8 + 1, 8);
        buffer = v10;
        LODWORD(v8) = *(_DWORD *)(a1 + 32);
      }
      *(void *)(*(void *)(a1 + 24) + 8 * v8) = buffer;
      ++*(_DWORD *)(a1 + 32);
      uint64_t v9 = &buffer[v6];
      BOOL result = (void *)((unint64_t)(buffer + 7) & 0xFFFFFFFFFFFFFFF8);
      *(void *)(a1 + 8) = result + 4;
      *(void *)(a1 + 16) = v9;
    }
    else
    {
      BOOL result = (void *)((v3 + 7) & 0xFFFFFFFFFFFFFFF8);
      *(void *)(a1 + 8) = result + 4;
    }
  }
  return result;
}

uint64_t llvm::DenseMap<mlir::Operation *,std::pair<mlir::Operation *,mlir::MemoryEffects::Effect *>,llvm::DenseMapInfo<mlir::Operation *,void>,llvm::detail::DenseMapPair<mlir::Operation *,std::pair<mlir::Operation *,mlir::MemoryEffects::Effect *>>>::shrink_and_clear(uint64_t result)
{
  uint64_t v1 = *(unsigned int *)(result + 16);
  int v2 = *(_DWORD *)(result + 8);
  int v3 = 1 << (33 - __clz(v2 - 1));
  if (v3 <= 64) {
    int v3 = 64;
  }
  if (v2) {
    int v4 = v3;
  }
  else {
    int v4 = 0;
  }
  if (v4 != v1) {
    llvm::deallocate_buffer(*(llvm **)result, (void *)(24 * v1));
  }
  *(void *)(result + 8) = 0;
  if (v1)
  {
    unsigned int v5 = *(llvm **)result;
    unint64_t v6 = 24 * v1 - 24;
    if (v6 < 0x18)
    {
      unsigned int v7 = *(llvm **)result;
LABEL_14:
      int v11 = (llvm *)((char *)v5 + 24 * v1);
      do
      {
        *(void *)unsigned int v7 = -4096;
        unsigned int v7 = (llvm *)((char *)v7 + 24);
      }
      while (v7 != v11);
      return result;
    }
    unint64_t v8 = v6 / 0x18 + 1;
    unsigned int v7 = (llvm *)((char *)v5 + 24 * (v8 & 0x1FFFFFFFFFFFFFFELL));
    uint64_t v9 = v8 & 0x1FFFFFFFFFFFFFFELL;
    uint64_t v10 = *(llvm **)result;
    do
    {
      *(void *)uint64_t v10 = -4096;
      *((void *)v10 + 3) = -4096;
      uint64_t v10 = (llvm *)((char *)v10 + 48);
      v9 -= 2;
    }
    while (v9);
    if (v8 != (v8 & 0x1FFFFFFFFFFFFFFELL)) {
      goto LABEL_14;
    }
  }
  return result;
}

void anonymous namespace'::CSE::~CSE(_anonymous_namespace_::CSE *this)
{
  mlir::Pass::~Pass(this);

  JUMPOUT(0x21667D3C0);
}

const char *mlir::impl::CSEBase<anonymous namespace'::CSE>::getName()
{
  return "CSE";
}

const char *mlir::impl::CSEBase<anonymous namespace'::CSE>::getArgument()
{
  return "cse";
}

const char *mlir::impl::CSEBase<anonymous namespace'::CSE>::getDescription()
{
  return "Eliminate common sub-expressions";
}

void anonymous namespace'::CSE::runOnOperation(_anonymous_namespace_::CSE *this)
{
  v12[1] = mlir::Attribute::getContext((mlir::Attribute *)((*((void *)this + 5) & 0xFFFFFFFFFFFFFFF8) + 24));
  memset(&v12[2], 0, 24);
  v12[0] = &unk_26C35C560;
  uint64_t v2 = *((void *)this + 6);
  v8[0] = v2;
  uint64_t v3 = *(void *)(v2 + 72);
  unint64_t v4 = v3 & 0xFFFFFFFFFFFFFFF8;
  if ((v3 & 4) == 0 && v4)
  {
    do
    {
      uint64_t v5 = *(void *)(v4 + 72);
      unint64_t v4 = v5 & 0xFFFFFFFFFFFFFFF8;
    }
    while ((v5 & 4) == 0 && v4);
  }
  v8[0] = v12;
  memset(&v8[1], 0, 24);
  v8[5] = 0;
  v8[6] = 0;
  v8[4] = mlir::detail::AnalysisMap::getAnalysisImpl<mlir::DominanceInfo,mlir::Operation *>(v2 + 24, (std::recursive_mutex **)v4);
  int v9 = 0;
  uint64_t v10 = 0;
  uint64_t v11 = 0;
  unint64_t v6 = (mlir::Operation *)(*((void *)this + 5) & 0xFFFFFFFFFFFFFFF8);
  BOOL v7 = 0;
}

void sub_2118E679C(int a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, int a9, __int16 a10, char a11, char a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, llvm *a18, uint64_t a19, unsigned int a20,int a21,int a22,int a23,int a24)
{
  ZinIrHalH13g::~ZinIrHalH13g((ZinIrHalH13g *)(v24 + 43));
  ZinIrHalH13g::~ZinIrHalH13g((ZinIrHalH13g *)((char *)v24 + 345));
  unsigned int v25 = v24 + 7;
  if (a12)
  {
    mlir::detail::PreservedAnalyses::preserve<mlir::DominanceInfo>(v25);
    mlir::detail::PreservedAnalyses::preserve<mlir::PostDominanceInfo>(v25);
  }
  else
  {
    mlir::detail::PreservedAnalyses::preserveAll(v25);
  }
  llvm::deallocate_buffer(a18, (void *)(24 * a20));
}

void sub_2118E67F4(int a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, void *__p, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28)
{
  if (v29) {
    operator delete(v29);
  }
  ZinIrHalH13g::~ZinIrHalH13g((ZinIrHalH13g *)(v28 - 56));
}

void mlir::impl::CSEBase<anonymous namespace'::CSE>::clonePass()
{
}

uint64_t mlir::detail::AnalysisMap::getAnalysisImpl<mlir::DominanceInfo,mlir::Operation *>(uint64_t a1, std::recursive_mutex **a2)
{
  {
    uint64_t v34 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::DominanceInfo]";
    unint64_t v35 = 69;
    unint64_t v27 = llvm::StringRef::find((uint64_t *)&v34, "DesiredTypeName = ", 0x12uLL, 0);
    if (v35 >= v27) {
      unint64_t v28 = v27;
    }
    else {
      unint64_t v28 = v35;
    }
    uint64_t v29 = &v34[v28];
    unint64_t v30 = v35 - v28;
    if (v35 - v28 >= 0x12) {
      uint64_t v31 = 18;
    }
    else {
      uint64_t v31 = v35 - v28;
    }
    unint64_t v32 = v30 - v31;
    if (v32 >= v32 - 1) {
      uint64_t v33 = v32 - 1;
    }
    else {
      uint64_t v33 = v32;
    }
    mlir::detail::TypeIDResolver<mlir::DominanceInfo,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v29[v31], v33);
  }
  uint64_t v4 = mlir::detail::TypeIDResolver<mlir::DominanceInfo,void>::resolveTypeID(void)::id;
  uint64_t v5 = *(void *)(a1 + 8);
  uint64_t v6 = *(unsigned int *)(a1 + 24);
  if (v6)
  {
    LODWORD(v7) = (v6 - 1) & ((mlir::detail::TypeIDResolver<mlir::DominanceInfo,void>::resolveTypeID(void)::id >> 4) ^ (mlir::detail::TypeIDResolver<mlir::DominanceInfo,void>::resolveTypeID(void)::id >> 9));
    unint64_t v8 = (void *)(v5 + 16 * v7);
    uint64_t v9 = *v8;
    if (mlir::detail::TypeIDResolver<mlir::DominanceInfo,void>::resolveTypeID(void)::id == *v8) {
      goto LABEL_9;
    }
    int v10 = 1;
    while (v9 != -4096)
    {
      int v11 = v7 + v10++;
      uint64_t v7 = v11 & (v6 - 1);
      uint64_t v9 = *(void *)(v5 + 16 * v7);
      if (mlir::detail::TypeIDResolver<mlir::DominanceInfo,void>::resolveTypeID(void)::id == v9)
      {
        unint64_t v8 = (void *)(v5 + 16 * v7);
        goto LABEL_9;
      }
    }
  }
  unint64_t v8 = (void *)(v5 + 16 * v6);
LABEL_9:
  if (v8 == (void *)(v5 + 16 * v6)) {
    int v12 = (unsigned int *)(a1 + 40);
  }
  else {
    int v12 = (unsigned int *)(v8 + 1);
  }
  uint64_t v13 = *v12;
  if (*(_DWORD *)(a1 + 40) == v13)
  {
    if (a2)
    {
      uint64_t v34 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::DominanceInfo]";
      unint64_t v35 = 69;
      unint64_t v14 = llvm::StringRef::find((uint64_t *)&v34, "DesiredTypeName = ", 0x12uLL, 0);
      if (v35 >= v14) {
        unint64_t v15 = v14;
      }
      else {
        unint64_t v15 = v35;
      }
      BOOL v16 = &v34[v15];
      unint64_t v17 = v35 - v15;
      if (v35 - v15 >= 0x12) {
        uint64_t v18 = 18;
      }
      else {
        uint64_t v18 = v35 - v15;
      }
      uint64_t v19 = (uint64_t)&v16[v18];
      unint64_t v20 = v17 - v18;
      if (v20 >= v20 - 1) {
        unint64_t v21 = v20 - 1;
      }
      else {
        unint64_t v21 = v20;
      }
      if (v21 >= 6)
      {
        if (*(_DWORD *)v19 == 1919511661 && *(_WORD *)(v19 + 4) == 14906)
        {
          v19 += 6;
          v21 -= 6;
        }
        else if (v21 >= 0x17 {
               && *(void *)v19 == 0x6F6D796E6F6E6128
        }
               && *(void *)(v19 + 8) == 0x73656D616E207375
               && *(void *)(v19 + 15) == 0x3A3A296563617073)
        {
          v19 += 23;
          v21 -= 23;
        }
      }
      mlir::PassInstrumentor::runBeforeAnalysis(a2, v19, v21, v4, *(void *)a1);
    }
    operator new();
  }
  return *(void *)(*(void *)(a1 + 32) + 16 * v13 + 8) + 8;
}

uint64_t llvm::MapVector<mlir::TypeID,std::unique_ptr<mlir::detail::AnalysisConcept>,llvm::DenseMap<mlir::TypeID,unsigned int,llvm::DenseMapInfo<mlir::TypeID,void>,llvm::detail::DenseMapPair<mlir::TypeID,unsigned int>>,llvm::SmallVector<std::pair<mlir::TypeID,std::unique_ptr<mlir::detail::AnalysisConcept>>,0u>>::try_emplace<std::unique_ptr<mlir::detail::AnalysisConcept>>(uint64_t a1, void *a2, uint64_t *a3)
{
  uint64_t v6 = *a2;
  unsigned int v7 = *(_DWORD *)(a1 + 16);
  if (!v7) {
    goto LABEL_25;
  }
  uint64_t v8 = *(void *)a1;
  uint64_t v9 = ((v6 >> 4) ^ (v6 >> 9)) & (v7 - 1);
  int v10 = (void *)(*(void *)a1 + 16 * v9);
  uint64_t v11 = *v10;
  if (*v10 == v6) {
    return *(void *)(a1 + 24) + 16 * *(unsigned int *)(v8 + 16 * v9 + 8);
  }
  uint64_t v18 = 0;
  int v19 = 1;
  while (v11 != -4096)
  {
    if (v18) {
      BOOL v20 = 0;
    }
    else {
      BOOL v20 = v11 == -8192;
    }
    if (v20) {
      uint64_t v18 = v10;
    }
    int v21 = v9 + v19++;
    uint64_t v9 = v21 & (v7 - 1);
    int v10 = (void *)(v8 + 16 * v9);
    uint64_t v11 = *v10;
    if (*v10 == v6) {
      return *(void *)(a1 + 24) + 16 * *(unsigned int *)(v8 + 16 * v9 + 8);
    }
  }
  uint64_t v22 = (uint64_t)(v18 ? v18 : v10);
  int v23 = *(_DWORD *)(a1 + 8);
  if (4 * v23 + 4 < 3 * v7)
  {
    if (v7 + ~v23 - *(_DWORD *)(a1 + 12) > v7 >> 3) {
      goto LABEL_6;
    }
  }
  else
  {
LABEL_25:
    v7 *= 2;
  }
  llvm::DenseMap<void const*,unsigned int,llvm::DenseMapInfo<void const*,void>,llvm::detail::DenseMapPair<void const*,unsigned int>>::grow(a1, v7);
  int v24 = *(_DWORD *)(a1 + 16) - 1;
  unsigned int v25 = v24 & ((v6 >> 4) ^ (v6 >> 9));
  uint64_t v22 = *(void *)a1 + 16 * v25;
  uint64_t v26 = *(void *)v22;
  if (*(void *)v22 == v6)
  {
    uint64_t v13 = v6;
    goto LABEL_7;
  }
  uint64_t v27 = 0;
  int v28 = 1;
  while (v26 != -4096)
  {
    if (v27) {
      BOOL v29 = 0;
    }
    else {
      BOOL v29 = v26 == -8192;
    }
    if (v29) {
      uint64_t v27 = v22;
    }
    unsigned int v30 = v25 + v28++;
    unsigned int v25 = v30 & v24;
    uint64_t v22 = *(void *)a1 + 16 * (v30 & v24);
    uint64_t v26 = *(void *)v22;
    uint64_t v13 = v6;
    if (*(void *)v22 == v6) {
      goto LABEL_7;
    }
  }
  if (v27) {
    uint64_t v22 = v27;
  }
LABEL_6:
  uint64_t v13 = *(void *)v22;
LABEL_7:
  ++*(_DWORD *)(a1 + 8);
  if (v13 != -4096) {
    --*(_DWORD *)(a1 + 12);
  }
  *(void *)uint64_t v22 = v6;
  *(_DWORD *)(v22 + 8) = 0;
  uint64_t v14 = *(unsigned int *)(a1 + 32);
  *(_DWORD *)(v22 + 8) = v14;
  uint64_t v31 = a3;
  unint64_t v32 = a2;
  if (v14 >= *(_DWORD *)(a1 + 36))
  {
    llvm::SmallVectorTemplateBase<std::pair<mlir::TypeID,std::unique_ptr<mlir::detail::AnalysisConcept>>,false>::growAndEmplaceBack<std::piecewise_construct_t const&,std::tuple<mlir::TypeID&&>,std::tuple<std::unique_ptr<mlir::detail::AnalysisConcept>&&>>(a1 + 24, (uint64_t)&std::piecewise_construct, &v32, &v31);
    unsigned int v17 = *(_DWORD *)(a1 + 32);
  }
  else
  {
    unint64_t v15 = (void *)(*(void *)(a1 + 24) + 16 * v14);
    *unint64_t v15 = *a2;
    uint64_t v16 = *a3;
    *a3 = 0;
    v15[1] = v16;
    unsigned int v17 = v14 + 1;
    *(_DWORD *)(a1 + 32) = v14 + 1;
  }
  return *(void *)(a1 + 24) + 16 * v17 - 16;
}

uint64_t llvm::SmallVectorTemplateBase<std::pair<mlir::TypeID,std::unique_ptr<mlir::detail::AnalysisConcept>>,false>::growAndEmplaceBack<std::piecewise_construct_t const&,std::tuple<mlir::TypeID&&>,std::tuple<std::unique_ptr<mlir::detail::AnalysisConcept>&&>>(uint64_t a1, uint64_t a2, void **a3, uint64_t **a4)
{
  unint64_t v31 = 0;
  unsigned int v7 = (double *)(a1 + 16);
  uint64_t v8 = (char *)llvm::SmallVectorBase<unsigned int>::mallocForGrow(a1, (void *)(a1 + 16), 0, 16, &v31);
  uint64_t v9 = *(unsigned int *)(a1 + 8);
  uint64_t v10 = 16 * v9;
  uint64_t v11 = &v8[16 * v9];
  int v12 = *a4;
  *(void *)uint64_t v11 = **a3;
  uint64_t v13 = *v12;
  *int v12 = 0;
  *((void *)v11 + 1) = v13;
  uint64_t v14 = *(double **)a1;
  if (!v9) {
    goto LABEL_19;
  }
  unint64_t v15 = (v9 - 1) & 0xFFFFFFFFFFFFFFFLL;
  if (v15 < 7 || (v8 < (char *)&v14[(unint64_t)v10 / 8] ? (BOOL v16 = v14 >= (double *)&v8[v10]) : (BOOL v16 = 1), !v16))
  {
    int v19 = v8;
    BOOL v20 = *(double **)a1;
    do
    {
LABEL_13:
      *(double *)int v19 = *v20;
      uint64_t v25 = *((void *)v20 + 1);
      v20[1] = 0.0;
      *((void *)v19 + 1) = v25;
      v20 += 2;
      v19 += 16;
    }
    while (v20 != &v14[(unint64_t)v10 / 8]);
    goto LABEL_14;
  }
  unint64_t v17 = v15 + 1;
  uint64_t v18 = (v15 + 1) & 0x1FFFFFFFFFFFFFFELL;
  int v19 = &v8[16 * v18];
  BOOL v20 = &v14[2 * v18];
  uint64_t v21 = v18;
  uint64_t v22 = (double *)v8;
  int v23 = *(const double **)a1;
  int v24 = *(const double **)a1;
  do
  {
    float64x2x2_t v32 = vld2q_f64(v24);
    v24 += 4;
    v23[1] = 0.0;
    v23[3] = 0.0;
    vst2q_f64(v22, v32);
    v22 += 4;
    int v23 = v24;
    v21 -= 2;
  }
  while (v21);
  if (v17 != v18) {
    goto LABEL_13;
  }
LABEL_14:
  uint64_t v26 = *(void *)a1 - 8;
  do
  {
    uint64_t v27 = *(void *)(v26 + v10);
    *(void *)(v26 + v10) = 0;
    if (v27) {
      (*(void (**)(uint64_t))(*(void *)v27 + 8))(v27);
    }
    v10 -= 16;
  }
  while (v10);
  uint64_t v14 = *(double **)a1;
LABEL_19:
  int v28 = v31;
  if (v14 != v7) {
    free(v14);
  }
  *(void *)a1 = v8;
  unsigned int v29 = *(_DWORD *)(a1 + 8) + 1;
  *(_DWORD *)(a1 + 8) = v29;
  *(_DWORD *)(a1 + 12) = v28;
  return (uint64_t)&v8[16 * v29 - 16];
}

void mlir::detail::AnalysisModel<mlir::DominanceInfo>::~AnalysisModel(void *a1)
{
  *a1 = &unk_26C37F7E0;
  mlir::detail::DominanceInfoBase<false>::~DominanceInfoBase((uint64_t)(a1 + 1));
}

{
  *a1 = &unk_26C37F7E0;
  mlir::detail::DominanceInfoBase<false>::~DominanceInfoBase((uint64_t)(a1 + 1));
}

uint64_t sub_2118E719C()
{
  return v0;
}

void sub_2118E71E0()
{
  JUMPOUT(0x21667D3C0);
}

BOOL mlir::detail::AnalysisModel<mlir::DominanceInfo>::invalidate(uint64_t a1, llvm::SmallPtrSetImplBase *a2)
{
  BOOL v3 = mlir::detail::PreservedAnalyses::isPreserved<mlir::DominanceInfo>(a2);
  if (!v3) {
    mlir::detail::PreservedAnalyses::unpreserve<mlir::DominanceInfo>(a2);
  }
  return !v3;
}

const void **mlir::detail::PreservedAnalyses::unpreserve<mlir::DominanceInfo>(llvm::SmallPtrSetImplBase *this)
{
  {
    int v19 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::DominanceInfo]";
    unint64_t v20 = 69;
    unint64_t v12 = llvm::StringRef::find((uint64_t *)&v19, "DesiredTypeName = ", 0x12uLL, 0);
    if (v20 >= v12) {
      unint64_t v13 = v12;
    }
    else {
      unint64_t v13 = v20;
    }
    uint64_t v14 = &v19[v13];
    unint64_t v15 = v20 - v13;
    if (v20 - v13 >= 0x12) {
      uint64_t v16 = 18;
    }
    else {
      uint64_t v16 = v20 - v13;
    }
    unint64_t v17 = v15 - v16;
    if (v17 >= v17 - 1) {
      uint64_t v18 = v17 - 1;
    }
    else {
      uint64_t v18 = v17;
    }
    mlir::detail::TypeIDResolver<mlir::DominanceInfo,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v14[v16], v18);
  }
  uint64_t v2 = mlir::detail::TypeIDResolver<mlir::DominanceInfo,void>::resolveTypeID(void)::id;
  uint64_t v3 = *((void *)this + 1);
  if (v3 == *(void *)this)
  {
    uint64_t v7 = *((unsigned int *)this + 5);
    BOOL result = (const void **)(v3 + 8 * v7);
    if (v7)
    {
      uint64_t v8 = 0;
      uint64_t v9 = 8 * v7;
      while (*(void *)(v3 + v8) != mlir::detail::TypeIDResolver<mlir::DominanceInfo,void>::resolveTypeID(void)::id)
      {
        v8 += 8;
        if (v9 == v8) {
          goto LABEL_13;
        }
      }
      BOOL result = (const void **)(v3 + v8);
    }
LABEL_13:
    uint64_t v5 = *((void *)this + 1);
  }
  else
  {
    BOOL result = llvm::SmallPtrSetImplBase::FindBucketFor(this, (const void *)mlir::detail::TypeIDResolver<mlir::DominanceInfo,void>::resolveTypeID(void)::id);
    uint64_t v3 = *(void *)this;
    uint64_t v5 = *((void *)this + 1);
    if (*result != (const void *)v2)
    {
      uint64_t v6 = 16;
      if (v5 == v3) {
        uint64_t v6 = 20;
      }
      BOOL result = (const void **)(v5 + 8 * *(unsigned int *)((char *)this + v6));
    }
  }
  BOOL v10 = v5 == v3;
  uint64_t v11 = 16;
  if (v10) {
    uint64_t v11 = 20;
  }
  if (result != (const void **)(v5 + 8 * *(unsigned int *)((char *)this + v11)))
  {
    *BOOL result = (const void *)-2;
    ++*((_DWORD *)this + 6);
  }
  return result;
}

BOOL mlir::detail::PreservedAnalyses::isPreserved<mlir::DominanceInfo>(llvm::SmallPtrSetImplBase *this)
{
  {
    unint64_t v20 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::DominanceInfo]";
    unint64_t v21 = 69;
    unint64_t v13 = llvm::StringRef::find((uint64_t *)&v20, "DesiredTypeName = ", 0x12uLL, 0);
    if (v21 >= v13) {
      unint64_t v14 = v13;
    }
    else {
      unint64_t v14 = v21;
    }
    unint64_t v15 = &v20[v14];
    unint64_t v16 = v21 - v14;
    if (v21 - v14 >= 0x12) {
      uint64_t v17 = 18;
    }
    else {
      uint64_t v17 = v21 - v14;
    }
    unint64_t v18 = v16 - v17;
    if (v18 >= v18 - 1) {
      uint64_t v19 = v18 - 1;
    }
    else {
      uint64_t v19 = v18;
    }
    mlir::detail::TypeIDResolver<mlir::DominanceInfo,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v15[v17], v19);
  }
  uint64_t v2 = mlir::detail::TypeIDResolver<mlir::DominanceInfo,void>::resolveTypeID(void)::id;
  uint64_t v3 = *((void *)this + 1);
  if (v3 == *(void *)this)
  {
    uint64_t v7 = *((unsigned int *)this + 5);
    BucketFor = (const void **)(v3 + 8 * v7);
    if (v7)
    {
      uint64_t v8 = 0;
      uint64_t v9 = 8 * v7;
      while (*(void *)(v3 + v8) != mlir::detail::TypeIDResolver<mlir::DominanceInfo,void>::resolveTypeID(void)::id)
      {
        v8 += 8;
        if (v9 == v8) {
          goto LABEL_13;
        }
      }
      BucketFor = (const void **)(v3 + v8);
    }
LABEL_13:
    uint64_t v5 = *((void *)this + 1);
  }
  else
  {
    BucketFor = llvm::SmallPtrSetImplBase::FindBucketFor(this, (const void *)mlir::detail::TypeIDResolver<mlir::DominanceInfo,void>::resolveTypeID(void)::id);
    uint64_t v3 = *(void *)this;
    uint64_t v5 = *((void *)this + 1);
    if (*BucketFor != (const void *)v2)
    {
      uint64_t v6 = 16;
      if (v5 == v3) {
        uint64_t v6 = 20;
      }
      BucketFor = (const void **)(v5 + 8 * *(unsigned int *)((char *)this + v6));
    }
  }
  BOOL v10 = v5 == v3;
  uint64_t v11 = 16;
  if (v10) {
    uint64_t v11 = 20;
  }
  return BucketFor != (const void **)(v5 + 8 * *(unsigned int *)((char *)this + v11));
}

const void **mlir::detail::PreservedAnalyses::preserveAll(const void **this)
{
  uint64_t v1 = &unk_267772000;
  {
    uint64_t v17 = this;
    uint64_t v1 = (void *)&unk_267772000;
    int v9 = v8;
    this = v17;
    if (v9)
    {
      unint64_t v18 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::detail::PreservedAnalyses::AllAnalysesType]";
      unint64_t v19 = 98;
      unint64_t v10 = llvm::StringRef::find((uint64_t *)&v18, "DesiredTypeName = ", 0x12uLL, 0);
      if (v19 >= v10) {
        unint64_t v11 = v10;
      }
      else {
        unint64_t v11 = v19;
      }
      unint64_t v12 = &v18[v11];
      unint64_t v13 = v19 - v11;
      if (v19 - v11 >= 0x12) {
        uint64_t v14 = 18;
      }
      else {
        uint64_t v14 = v19 - v11;
      }
      unint64_t v15 = v13 - v14;
      if (v15 >= v15 - 1) {
        uint64_t v16 = v15 - 1;
      }
      else {
        uint64_t v16 = v15;
      }
      mlir::detail::TypeIDResolver<mlir::detail::PreservedAnalyses::AllAnalysesType,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v12[v14], v16);
      uint64_t v1 = (void *)&unk_267772000;
      this = v17;
    }
  }
  uint64_t v2 = (const void *)v1[334];
  uint64_t v3 = this[1];
  if (v3 != *this) {
    return llvm::SmallPtrSetImplBase::insert_imp_big((llvm::SmallPtrSetImplBase *)this, v2);
  }
  uint64_t v4 = *((unsigned int *)this + 5);
  if (!v4)
  {
LABEL_13:
    if (v4 < *((_DWORD *)this + 4))
    {
      *((_DWORD *)this + 5) = v4 + 1;
      v3[v4] = v2;
      return this;
    }
    return llvm::SmallPtrSetImplBase::insert_imp_big((llvm::SmallPtrSetImplBase *)this, v2);
  }
  uint64_t v5 = 0;
  uint64_t v6 = 8 * v4;
  uint64_t v7 = this[1];
  while ((const void *)*v7 != v2)
  {
    if (*v7 == -2) {
      uint64_t v5 = v7;
    }
    ++v7;
    v6 -= 8;
    if (!v6)
    {
      if (!v5) {
        goto LABEL_13;
      }
      void *v5 = v2;
      --*((_DWORD *)this + 6);
      return this;
    }
  }
  return this;
}

const void **mlir::detail::PreservedAnalyses::preserve<mlir::DominanceInfo>(const void **result)
{
  uint64_t v1 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
  {
    uint64_t v17 = result;
    uint64_t v1 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
    int v9 = v8;
    BOOL result = v17;
    if (v9)
    {
      unint64_t v18 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::DominanceInfo]";
      unint64_t v19 = 69;
      unint64_t v10 = llvm::StringRef::find((uint64_t *)&v18, "DesiredTypeName = ", 0x12uLL, 0);
      if (v19 >= v10) {
        unint64_t v11 = v10;
      }
      else {
        unint64_t v11 = v19;
      }
      unint64_t v12 = &v18[v11];
      unint64_t v13 = v19 - v11;
      if (v19 - v11 >= 0x12) {
        uint64_t v14 = 18;
      }
      else {
        uint64_t v14 = v19 - v11;
      }
      unint64_t v15 = v13 - v14;
      if (v15 >= v15 - 1) {
        uint64_t v16 = v15 - 1;
      }
      else {
        uint64_t v16 = v15;
      }
      mlir::detail::TypeIDResolver<mlir::DominanceInfo,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v12[v14], v16);
      uint64_t v1 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
      BOOL result = v17;
    }
  }
  uint64_t v2 = (const void *)v1[260];
  uint64_t v3 = result[1];
  if (v3 != *result) {
    return llvm::SmallPtrSetImplBase::insert_imp_big((llvm::SmallPtrSetImplBase *)result, v2);
  }
  uint64_t v4 = *((unsigned int *)result + 5);
  if (!v4)
  {
LABEL_13:
    if (v4 < *((_DWORD *)result + 4))
    {
      *((_DWORD *)result + 5) = v4 + 1;
      v3[v4] = v2;
      return result;
    }
    return llvm::SmallPtrSetImplBase::insert_imp_big((llvm::SmallPtrSetImplBase *)result, v2);
  }
  uint64_t v5 = 0;
  uint64_t v6 = 8 * v4;
  uint64_t v7 = result[1];
  while ((const void *)*v7 != v2)
  {
    if (*v7 == -2) {
      uint64_t v5 = v7;
    }
    ++v7;
    v6 -= 8;
    if (!v6)
    {
      if (!v5) {
        goto LABEL_13;
      }
      void *v5 = v2;
      --*((_DWORD *)result + 6);
      return result;
    }
  }
  return result;
}

const void **mlir::detail::PreservedAnalyses::preserve<mlir::PostDominanceInfo>(const void **result)
{
  uint64_t v1 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
  {
    uint64_t v17 = result;
    uint64_t v1 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
    int v9 = v8;
    BOOL result = v17;
    if (v9)
    {
      unint64_t v18 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::PostDominanceInfo]";
      unint64_t v19 = 73;
      unint64_t v10 = llvm::StringRef::find((uint64_t *)&v18, "DesiredTypeName = ", 0x12uLL, 0);
      if (v19 >= v10) {
        unint64_t v11 = v10;
      }
      else {
        unint64_t v11 = v19;
      }
      unint64_t v12 = &v18[v11];
      unint64_t v13 = v19 - v11;
      if (v19 - v11 >= 0x12) {
        uint64_t v14 = 18;
      }
      else {
        uint64_t v14 = v19 - v11;
      }
      unint64_t v15 = v13 - v14;
      if (v15 >= v15 - 1) {
        uint64_t v16 = v15 - 1;
      }
      else {
        uint64_t v16 = v15;
      }
      mlir::detail::TypeIDResolver<mlir::PostDominanceInfo,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v12[v14], v16);
      uint64_t v1 = &mlir::detail::TypeIDResolver<mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties,void>::resolveTypeID(void)::id;
      BOOL result = v17;
    }
  }
  uint64_t v2 = (const void *)v1[262];
  uint64_t v3 = result[1];
  if (v3 != *result) {
    return llvm::SmallPtrSetImplBase::insert_imp_big((llvm::SmallPtrSetImplBase *)result, v2);
  }
  uint64_t v4 = *((unsigned int *)result + 5);
  if (!v4)
  {
LABEL_13:
    if (v4 < *((_DWORD *)result + 4))
    {
      *((_DWORD *)result + 5) = v4 + 1;
      v3[v4] = v2;
      return result;
    }
    return llvm::SmallPtrSetImplBase::insert_imp_big((llvm::SmallPtrSetImplBase *)result, v2);
  }
  uint64_t v5 = 0;
  uint64_t v6 = 8 * v4;
  uint64_t v7 = result[1];
  while ((const void *)*v7 != v2)
  {
    if (*v7 == -2) {
      uint64_t v5 = v7;
    }
    ++v7;
    v6 -= 8;
    if (!v6)
    {
      if (!v5) {
        goto LABEL_13;
      }
      void *v5 = v2;
      --*((_DWORD *)result + 6);
      return result;
    }
  }
  return result;
}

void anonymous namespace'::OperationTransactionState::resetOperation(_anonymous_namespace_::OperationTransactionState *this)
{
  uint64_t v9 = *MEMORY[0x263EF8340];
  *(void *)(*(void *)this + 24) = *((void *)this + 1);
  mlir::Operation::setAttrs(*(void *)this, *((void *)this + 2));
  uint64_t v2 = *(uint64_t **)this;
  mlir::ValueRange::ValueRange((unint64_t *)&v7, *((void *)this + 3), *((unsigned int *)this + 8));
  mlir::Operation::setOperands(v2, v7, v8);
  uint64_t v3 = *((unsigned int *)this + 28);
  if (v3)
  {
    uint64_t v4 = 0;
    uint64_t v5 = *((void *)this + 13);
    uint64_t v6 = 8 * v3;
    do
    {
      mlir::Operation::setSuccessor(*(mlir::Operation **)this, *(mlir::Block **)(v5 + 8 * v4), v4);
      ++v4;
      v6 -= 8;
    }
    while (v6);
  }
}

void mlir::detail::ConversionPatternRewriterImpl::undoBlockActions(int32x2_t *this, unsigned __int32 a2)
{
  unsigned __int32 v2 = this[53].u32[0];
  if (v2 != a2)
  {
    uint64_t v92 = this + 52;
    unint64_t v93 = a2;
    int32x2_t v5 = this[52];
    uint64_t v6 = *(void *)&v5 + 40 * a2;
    uint64_t v7 = *(void *)&v5 + 40 * v2;
    uint64_t v94 = this + 9;
    unint64_t v95 = this + 13;
    uint64_t v8 = v7;
    do
    {
      int v16 = *(_DWORD *)(v8 - 40);
      v8 -= 40;
      switch(v16)
      {
        case 0:
          uint64_t v17 = *(void *)(v7 - 32);
          uint64_t v18 = v17 + 32;
          if (*(void *)(v17 + 32) != v17 + 32)
          {
            do
            {
              ZinIrHalH13g::~ZinIrHalH13g(*(ZinIrHalH13g **)(v17 + 40));
              unint64_t v20 = (ZinIrHalH13g *)v19;
              llvm::ilist_traits<mlir::Operation>::removeNodeFromList(v18, v19);
              ZinIrHalH13g::~ZinIrHalH13g(v20);
              uint64_t v22 = *v21;
              int v23 = (uint64_t *)v21[1];
              uint64_t *v23 = *v21;
              *(void *)(v22 + 8) = v23;
              *unint64_t v21 = 0;
              v21[1] = 0;
            }
            while (*(void *)(v17 + 32) != v18);
            uint64_t v17 = *(void *)(v7 - 32);
          }
          int v24 = (void *)v17;
          goto LABEL_35;
        case 1:
          uint64_t v9 = *(void *)(v7 - 24);
          uint64_t v10 = *(void *)(v7 - 16);
          uint64_t v11 = *(void *)(v7 - 32);
          if (v10) {
            unint64_t v12 = (uint64_t **)(v10 + 16);
          }
          else {
            unint64_t v12 = (uint64_t **)(v9 + 8);
          }
          unint64_t v13 = *v12;
          llvm::ilist_traits<mlir::Block>::addNodeToList(v9, *(void *)(v7 - 32));
          uint64_t v14 = *v13;
          *(void *)(v11 + 8) = *v13;
          *(void *)(v11 + 16) = v13;
          uint64_t v15 = v11 + 8;
          *(void *)(v14 + 8) = v15;
          *unint64_t v13 = v15;
          goto LABEL_7;
        case 2:
          uint64_t v25 = *(ZinIrHalH13g **)(v7 - 16);
          if (v25)
          {
            uint64_t v27 = *(void *)(v7 - 32);
            uint64_t v26 = *(void *)(v7 - 24);
            int v28 = *(uint64_t **)(v26 + 40);
            ZinIrHalH13g::~ZinIrHalH13g(v25);
            unsigned int v30 = v29;
            ZinIrHalH13g::~ZinIrHalH13g(*(ZinIrHalH13g **)(v7 - 8));
            float64x2x2_t v32 = *(uint64_t **)(v31 + 8);
            BOOL v33 = v30 == v32 || v28 == v32;
            if (!v33)
            {
              llvm::ilist_traits<mlir::Operation>::transferNodesFromList(v26 + 32, v27 + 32, (uint64_t)v30, (uint64_t)v32);
              uint64_t v34 = *v32;
              uint64_t v35 = *v30;
              *(void *)(v35 + 8) = v32;
              *float64x2x2_t v32 = v35;
              uint64_t v36 = *v28;
              *(void *)(v34 + 8) = v28;
              *unsigned int v30 = v36;
              *(void *)(v36 + 8) = v30;
              *int v28 = v34;
            }
          }
          goto LABEL_7;
        case 3:
          uint64_t v38 = *(void *)(v7 - 24);
          uint64_t v37 = *(void *)(v7 - 16);
          int v39 = (uint64_t *)v38;
          if (v37) {
            int v39 = *(uint64_t **)(v37 + 16);
          }
          unint64_t Parent = mlir::Block::getParent(*(mlir::Block **)(v7 - 32));
          uint64_t v41 = *(void *)(v7 - 32);
          if (v41) {
            uint64_t v42 = (uint64_t *)(v41 + 8);
          }
          else {
            uint64_t v42 = 0;
          }
          uint64_t v43 = (uint64_t *)v42[1];
          if (v42 != v39 && v43 != v39)
          {
            llvm::ilist_traits<mlir::Block>::transferNodesFromList(v38, Parent, (uint64_t)v42, v42[1]);
            if (v43 != v42)
            {
              uint64_t v45 = *v43;
              uint64_t v46 = *v42;
              *(void *)(v46 + 8) = v43;
              *uint64_t v43 = v46;
              uint64_t v47 = *v39;
              *(void *)(v45 + 8) = v39;
              *uint64_t v42 = v47;
              *(void *)(v47 + 8) = v42;
              *int v39 = v45;
            }
          }
          goto LABEL_7;
        case 4:
          uint64_t v48 = *(void *)(v7 - 32);
          unint64_t v49 = (uint64_t *)(v48 + 32);
          if (*(void *)(v48 + 32) != v48 + 32)
          {
            uint64_t v50 = *(void *)(v7 - 24);
            if (v50 != v48)
            {
              unsigned int v51 = (uint64_t *)(v50 + 32);
              unsigned int v52 = *(uint64_t **)(v48 + 40);
              llvm::ilist_traits<mlir::Operation>::transferNodesFromList(v50 + 32, (uint64_t)v49, (uint64_t)v52, (uint64_t)v49);
              if (v52 != v49)
              {
                uint64_t v53 = *v49;
                uint64_t v54 = *v52;
                *(void *)(v54 + 8) = v49;
                *unint64_t v49 = v54;
                uint64_t v55 = *v51;
                *(void *)(v53 + 8) = v51;
                uint64_t *v52 = v55;
                *(void *)(v55 + 8) = v52;
                *unsigned int v51 = v53;
              }
            }
          }
          int v24 = *(void **)(v7 - 32);
LABEL_35:
          mlir::Block::dropAllDefinedValueUses(v24);
          mlir::Block::erase(*(mlir::Block **)(v7 - 32));
          goto LABEL_7;
        case 5:
          BOOL v56 = *(ZinIrHalH13g **)(v7 - 32);
          int32x2_t v57 = this[9];
          uint64_t v58 = this[11].u32[0];
          if (!v58) {
            goto LABEL_42;
          }
          LODWORD(v59) = ((v56 >> 4) ^ (v56 >> 9)) & (v58 - 1);
          int64_t v60 = (void *)(*(void *)&v57 + 16 * v59);
          unint64_t v61 = (ZinIrHalH13g *)*v60;
          if ((ZinIrHalH13g *)*v60 == v56) {
            goto LABEL_43;
          }
          int v62 = 1;
          break;
        default:
          goto LABEL_7;
      }
      while (v61 != (ZinIrHalH13g *)-4096)
      {
        int v63 = v59 + v62++;
        uint64_t v59 = v63 & (v58 - 1);
        unint64_t v61 = *(ZinIrHalH13g **)(*(void *)&v57 + 16 * v59);
        if (v61 == v56)
        {
          int64_t v60 = (void *)(*(void *)&v57 + 16 * v59);
          goto LABEL_43;
        }
      }
LABEL_42:
      int64_t v60 = (void *)(*(void *)&v57 + 16 * v58);
LABEL_43:
      BOOL v33 = v60 == (void *)(*(void *)&v57 + 16 * v58);
      unint64_t v64 = v95;
      if (!v33) {
        unint64_t v64 = (int32x2_t *)(v60 + 1);
      }
      uint64_t v65 = v64->u32[0];
      if (v65 != this[13].i32[0])
      {
        unint64_t v66 = (void *)(*(void *)&this[12] + (v65 << 6));
        BOOL v67 = (ZinIrHalH13g *)v66[1];
        uint64_t v68 = ((*((void *)v56 + 7) - *((void *)v56 + 6)) >> 3) - 1;
        if ((int)v68 >= 0)
        {
          do
          {
            uint64_t v70 = *(void ***)(*((void *)v56 + 6) + 8 * v68);
            while (1)
            {
              uint64_t v71 = *v70;
              if (!*v70) {
                break;
              }
              unint64_t v72 = (void *)v71[1];
              if (v72)
              {
                *unint64_t v72 = *v71;
                if (*v71) {
                  *(void *)(*v71 + 8) = v71[1];
                }
              }
              *uint64_t v71 = 0;
              v71[1] = 0;
              v71[3] = 0;
            }
          }
          while (v68-- > 0);
        }
        while (1)
        {
          uint64_t v73 = *(uint64_t **)v56;
          if (!*(void *)v56) {
            break;
          }
          unint64_t v74 = (uint64_t *)v73[1];
          if (v74)
          {
            *unint64_t v74 = *v73;
            if (*v73) {
              *(void *)(*v73 + 8) = v73[1];
            }
          }
          v73[3] = (uint64_t)v67;
          ZinIrHalH13g::~ZinIrHalH13g(v67);
          uint64_t v76 = *v75;
          *uint64_t v73 = *v75;
          v73[1] = (uint64_t)v75;
          if (v76) {
            *(void *)(v76 + 8) = v73;
          }
          *uint64_t v75 = (uint64_t)v73;
        }
        uint64_t v77 = (uint64_t *)((char *)v56 + 32);
        if (*((ZinIrHalH13g **)v56 + 4) != (ZinIrHalH13g *)((char *)v56 + 32) && v67 != v56)
        {
          unint64_t v78 = (uint64_t *)((char *)v67 + 32);
          uint64_t v79 = (uint64_t *)*((void *)v56 + 5);
          llvm::ilist_traits<mlir::Operation>::transferNodesFromList((uint64_t)v67 + 32, (uint64_t)v56 + 32, (uint64_t)v79, (uint64_t)v56 + 32);
          if (v79 != v77)
          {
            uint64_t v80 = *v77;
            uint64_t v81 = *v79;
            *(void *)(v81 + 8) = v77;
            *uint64_t v77 = v81;
            uint64_t v82 = *v78;
            *(void *)(v80 + 8) = v78;
            uint64_t *v79 = v82;
            *(void *)(v82 + 8) = v79;
            *unint64_t v78 = v80;
          }
        }
        mlir::Block::moveBefore(v67, v56);
        mlir::Block::erase(v56);
        __int32 v83 = this[16].i32[0];
        if (v83)
        {
          int32x2_t v84 = this[14];
          __int32 v85 = v83 - 1;
          LODWORD(v86) = (v83 - 1) & ((v67 >> 4) ^ (v67 >> 9));
          uint64_t v87 = (ZinIrHalH13g **)(*(void *)&v84 + 8 * v86);
          uint64_t v88 = *v87;
          if (v67 == *v87)
          {
LABEL_68:
            *uint64_t v87 = (ZinIrHalH13g *)-8192;
            this[15] = vadd_s32(this[15], (int32x2_t)0x1FFFFFFFFLL);
          }
          else
          {
            int v89 = 1;
            while (v88 != (ZinIrHalH13g *)-4096)
            {
              int v90 = v86 + v89++;
              uint64_t v86 = v90 & v85;
              uint64_t v88 = *(ZinIrHalH13g **)(*(void *)&v84 + 8 * v86);
              if (v67 == v88)
              {
                uint64_t v87 = (ZinIrHalH13g **)(*(void *)&v84 + 8 * v86);
                goto LABEL_68;
              }
            }
          }
        }
      }
LABEL_7:
      uint64_t v7 = v8;
    }
    while (v8 != v6);
    unsigned __int32 v91 = this[53].u32[0];
    if (v91 != a2)
    {
      if (v91 <= a2)
      {
        if (this[53].i32[1] < a2)
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)v92, &this[54], v93, 40);
          unsigned __int32 v91 = this[53].u32[0];
        }
        if (v91 != a2) {
          bzero((void *)(*(void *)v92 + 40 * v91), 40 * ((40 * (v93 - v91) - 40) / 0x28) + 40);
        }
      }
      this[53].i32[0] = a2;
    }
  }
}

void detachNestedAndErase(mlir::Operation *this)
{
  unint64_t v2 = *((unsigned int *)this + 11);
  if ((v2 & 0x7FFFFF) != 0)
  {
    unint64_t v3 = (((unint64_t)this + 16 * ((v2 >> 23) & 1) + ((v2 >> 21) & 0x7F8) + 71) & 0xFFFFFFFFFFFFFFF8)
       + 32 * *((unsigned int *)this + 10);
    unint64_t v4 = v3 + 24 * (v2 & 0x7FFFFF);
    do
    {
      for (uint64_t i = *(void *)(v3 + 8); i != v3; uint64_t i = *(void *)(i + 8))
      {
        if (i) {
          uint64_t v6 = i - 8;
        }
        else {
          uint64_t v6 = 0;
        }
        for (; *(void *)(v6 + 32) != v6 + 32; v9[1] = 0)
        {
          ZinIrHalH13g::~ZinIrHalH13g(*(ZinIrHalH13g **)(v6 + 40));
          uint64_t v8 = (ZinIrHalH13g *)v7;
          llvm::ilist_traits<mlir::Operation>::removeNodeFromList(v6 + 32, v7);
          ZinIrHalH13g::~ZinIrHalH13g(v8);
          uint64_t v10 = *v9;
          uint64_t v11 = (uint64_t *)v9[1];
          *uint64_t v11 = *v9;
          *(void *)(v10 + 8) = v11;
          *uint64_t v9 = 0;
        }
        mlir::Block::dropAllDefinedValueUses((void *)v6);
      }
      v3 += 24;
    }
    while (v3 != v4);
  }
  uint64_t v12 = *((unsigned int *)this + 9);
  if (v12) {
    unint64_t v13 = (char *)this - 16;
  }
  else {
    unint64_t v13 = 0;
  }
  if (v12)
  {
    for (uint64_t j = 0; j != v12; ++j)
    {
      uint64_t NextResultAtOffset = (void **)mlir::detail::OpResultImpl::getNextResultAtOffset((uint64_t)v13, j);
      while (1)
      {
        int v16 = *NextResultAtOffset;
        if (!*NextResultAtOffset) {
          break;
        }
        uint64_t v17 = (void *)v16[1];
        if (v17)
        {
          *uint64_t v17 = *v16;
          if (*v16) {
            *(void *)(*v16 + 8) = v16[1];
          }
        }
        *int v16 = 0;
        v16[1] = 0;
        void v16[3] = 0;
      }
    }
  }

  mlir::Operation::erase(this);
}

void mlir::detail::ConversionPatternRewriterImpl::applyRewrites(mlir::detail::ConversionPatternRewriterImpl *this)
{
  uint64_t v2 = *((unsigned int *)this + 90);
  if (v2)
  {
    unint64_t v3 = (mlir::Operation **)*((void *)this + 44);
    unint64_t v138 = (mlir::detail::ConversionPatternRewriterImpl *)((char *)this + 72);
    long long v139 = &v3[2 * v2];
    while (1)
    {
      unint64_t v4 = *v3;
      int v5 = *((_DWORD *)*v3 + 9);
      uint64_t v6 = (uint64_t)*v3 - 16;
      if (!v5) {
        uint64_t v6 = 0;
      }
      uint64_t v146 = (mlir::detail::OpResultImpl *)v6;
      uint64_t v151 = *((unsigned int *)*v3 + 9);
      if (v5) {
        break;
      }
LABEL_60:
      if ((*((_DWORD *)v4 + 11) & 0x7FFFFF) != 0) {
      v3 += 2;
      }
      if (v3 == v139) {
        goto LABEL_62;
      }
    }
    unint64_t v142 = v3;
    uint64_t v7 = 0;
    while (1)
    {
      uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset((uint64_t)v146, v7);
      uint64_t v9 = (void **)NextResultAtOffset;
      uint64_t v10 = *(void *)this;
      LODWORD(v11) = *((_DWORD *)this + 4);
      unint64_t v12 = *(void *)(NextResultAtOffset + 8) & 0xFFFFFFFFFFFFFFF8;
      if (v12)
      {
        unint64_t v13 = 0;
        uint64_t v14 = (void *)NextResultAtOffset;
        uint64_t v15 = &unk_267770000;
        do
        {
          unint64_t v16 = (unint64_t)v14;
          if ((v14[1] & 0xFFFFFFFFFFFFFFF8) == v12) {
            unint64_t v13 = (unint64_t)v14;
          }
          if (!v11) {
            break;
          }
          {
            uint64_t v15 = &unk_267770000;
            if (v23)
            {
              unint64_t v24 = llvm::hashing::detail::fixed_seed_override;
              if (!llvm::hashing::detail::fixed_seed_override) {
                unint64_t v24 = 0xFF51AFD7ED558CCDLL;
              }
              llvm::hashing::detail::get_execution_seed(void)::seed = v24;
              uint64_t v15 = (void *)&unk_267770000;
            }
          }
          unint64_t v17 = 0x9DDFEA08EB382D69 * ((v15[385] + 8 * v16) ^ HIDWORD(v16));
          unint64_t v18 = 0x9DDFEA08EB382D69 * (HIDWORD(v16) ^ (v17 >> 47) ^ v17);
          LODWORD(v18) = (-348639895 * ((v18 >> 47) ^ v18)) & (v11 - 1);
          uint64_t v19 = (void *)(v10 + 16 * v18);
          unint64_t v20 = (void *)*v19;
          if (v16 != *v19)
          {
            int v21 = 1;
            while (v20 != (void *)-4096)
            {
              int v22 = v18 + v21++;
              unint64_t v18 = v22 & (v11 - 1);
              unint64_t v20 = *(void **)(v10 + 16 * v18);
              if ((void *)v16 == v20)
              {
                uint64_t v19 = (void *)(v10 + 16 * v18);
                uint64_t v10 = *(void *)this;
                uint64_t v11 = *((unsigned int *)this + 4);
                if (v19 != (void *)(*(void *)this + 16 * v11)) {
                  goto LABEL_17;
                }
                goto LABEL_28;
              }
            }
            break;
          }
          uint64_t v10 = *(void *)this;
          uint64_t v11 = *((unsigned int *)this + 4);
          if (v19 == (void *)(*(void *)this + 16 * v11)) {
            break;
          }
LABEL_17:
          uint64_t v14 = (void *)v19[1];
        }
        while (v14);
LABEL_28:
        if (!v13) {
          unint64_t v13 = v16;
        }
      }
      else
      {
        uint64_t v25 = (void *)NextResultAtOffset;
        uint64_t v26 = &unk_267770000;
        do
        {
          unint64_t v13 = (unint64_t)v25;
          if (!v11) {
            break;
          }
          {
            uint64_t v26 = &unk_267770000;
            if (v33)
            {
              unint64_t v34 = llvm::hashing::detail::fixed_seed_override;
              if (!llvm::hashing::detail::fixed_seed_override) {
                unint64_t v34 = 0xFF51AFD7ED558CCDLL;
              }
              llvm::hashing::detail::get_execution_seed(void)::seed = v34;
              uint64_t v26 = (void *)&unk_267770000;
            }
          }
          unint64_t v27 = 0x9DDFEA08EB382D69 * ((v26[385] + 8 * v13) ^ HIDWORD(v13));
          unint64_t v28 = 0x9DDFEA08EB382D69 * (HIDWORD(v13) ^ (v27 >> 47) ^ v27);
          LODWORD(v28) = (-348639895 * ((v28 >> 47) ^ v28)) & (v11 - 1);
          unsigned int v29 = (void *)(v10 + 16 * v28);
          unsigned int v30 = (void *)*v29;
          if (v13 != *v29)
          {
            int v31 = 1;
            while (v30 != (void *)-4096)
            {
              int v32 = v28 + v31++;
              unint64_t v28 = v32 & (v11 - 1);
              unsigned int v30 = *(void **)(v10 + 16 * v28);
              if ((void *)v13 == v30)
              {
                unsigned int v29 = (void *)(v10 + 16 * v28);
                uint64_t v10 = *(void *)this;
                uint64_t v11 = *((unsigned int *)this + 4);
                if (v29 != (void *)(*(void *)this + 16 * v11)) {
                  goto LABEL_39;
                }
                goto LABEL_30;
              }
            }
            break;
          }
          uint64_t v10 = *(void *)this;
          uint64_t v11 = *((unsigned int *)this + 4);
          if (v29 == (void *)(*(void *)this + 16 * v11)) {
            break;
          }
LABEL_39:
          uint64_t v25 = (void *)v29[1];
        }
        while (v25);
      }
LABEL_30:
      if ((void **)v13 == v9) {
        goto LABEL_8;
      }
      if (v12)
      {
        if ((*(void *)(v13 + 8) & 0xFFFFFFFFFFFFFFF8) == v12) {
          goto LABEL_53;
        }
      }
      else if (v13)
      {
LABEL_53:
        while (1)
        {
          uint64_t v35 = *v9;
          if (!*v9) {
            break;
          }
          uint64_t v36 = (void *)v35[1];
          if (v36)
          {
            *uint64_t v36 = *v35;
            if (*v35) {
              *(void *)(*v35 + 8) = v35[1];
            }
          }
          v35[3] = v13;
          v35[1] = v13;
          uint64_t v37 = *(void *)v13;
          *uint64_t v35 = *(void *)v13;
          if (v37) {
            *(void *)(v37 + 8) = v35;
          }
          *(void *)unint64_t v13 = v35;
        }
      }
LABEL_8:
      if (++v7 == v151)
      {
        unint64_t v3 = v142;
        unint64_t v4 = *v142;
        goto LABEL_60;
      }
    }
  }
LABEL_62:
  uint64_t v38 = *((unsigned int *)this + 94);
  if (v38)
  {
    int v39 = (uint64_t ***)*((void *)this + 46);
    unsigned int v40 = &v39[v38];
    do
    {
      uint64_t v159 = *v39;
      if (v42)
      {
        uint64_t v43 = v42;
        if ((~*((_DWORD *)v42 + 2) & 7) != 0)
        {
          uint64_t v158 = 0;
          uint64_t Owner = mlir::detail::OpResultImpl::getOwner((mlir::detail::OpResultImpl *)v42);
          uint64_t v157 = *(void *)(Owner + 16);
          uint64_t v158 = Owner;
          v156[0] = &v157;
          v156[1] = &v158;
          mlir::Value::replaceUsesWithIf(&v159, v43, (uint64_t (*)(uint64_t, uint64_t *))llvm::function_ref<BOOL ()(mlir::OpOperand &)>::callback_fn<mlir::detail::ConversionPatternRewriterImpl::applyRewrites(void)::$_0>, (uint64_t)v156);
        }
        else
        {
          uint64_t v44 = v159;
          while (1)
          {
            uint64_t v45 = *v44;
            if (!*v44) {
              break;
            }
            uint64_t v46 = (uint64_t *)v45[1];
            if (v46)
            {
              uint64_t *v46 = *v45;
              if (*v45) {
                *(void *)(*v45 + 8) = v45[1];
              }
            }
            v45[3] = (uint64_t)v42;
            v45[1] = (uint64_t)v42;
            uint64_t v47 = *v42;
            *uint64_t v45 = *v42;
            if (v47) {
              *(void *)(v47 + 8) = v45;
            }
            *uint64_t v42 = (uint64_t)v45;
          }
        }
      }
      ++v39;
    }
    while (v39 != v40);
  }
  unsigned int v48 = *((_DWORD *)this + 68);
  if (v48)
  {
    unint64_t v49 = (mlir::Operation **)*((void *)this + 33);
    uint64_t v50 = &v49[3 * v48];
    do
    {
      unsigned int v51 = *v49;
      uint64_t v52 = *((unsigned int *)*v49 + 9);
      if (v52) {
        uint64_t v53 = (uint64_t)*v49 - 16;
      }
      else {
        uint64_t v53 = 0;
      }
      if (v52)
      {
        for (uint64_t i = 0; i != v52; ++i)
        {
          uint64_t v55 = (void **)mlir::detail::OpResultImpl::getNextResultAtOffset(v53, i);
          while (1)
          {
            BOOL v56 = *v55;
            if (!*v55) {
              break;
            }
            int32x2_t v57 = (void *)v56[1];
            if (v57)
            {
              *int32x2_t v57 = *v56;
              if (*v56) {
                *(void *)(*v56 + 8) = v56[1];
              }
            }
            *BOOL v56 = 0;
            v56[1] = 0;
            v56[3] = 0;
          }
        }
        unsigned int v51 = *v49;
      }
      mlir::Operation::erase(v51);
      v49 += 3;
    }
    while (v49 != v50);
  }
  uint64_t v58 = *((unsigned int *)this + 90);
  if (v58)
  {
    uint64_t v59 = (mlir::Operation **)*((void *)this + 44);
    int64_t v60 = &v59[2 * v58];
    do
    {
      int v62 = (unsigned int *)*(v60 - 2);
      v60 -= 2;
      unint64_t v61 = (mlir::Operation *)v62;
      uint64_t v63 = v62[9];
      uint64_t v64 = (uint64_t)(v62 - 4);
      if (v63) {
        uint64_t v65 = v64;
      }
      else {
        uint64_t v65 = 0;
      }
      if (v63)
      {
        for (uint64_t j = 0; j != v63; ++j)
        {
          BOOL v67 = (void **)mlir::detail::OpResultImpl::getNextResultAtOffset(v65, j);
          while (1)
          {
            uint64_t v68 = *v67;
            if (!*v67) {
              break;
            }
            unint64_t v69 = (void *)v68[1];
            if (v69)
            {
              *unint64_t v69 = *v68;
              if (*v68) {
                *(void *)(*v68 + 8) = v68[1];
              }
            }
            *uint64_t v68 = 0;
            v68[1] = 0;
            v68[3] = 0;
          }
        }
        unint64_t v61 = *v60;
      }
      mlir::Operation::erase(v61);
    }
    while (v60 != v59);
  }
  uint64_t v70 = *((unsigned int *)this + 26);
  uint64_t v71 = &unk_267770000;
  if (v70)
  {
    uint64_t v72 = *((void *)this + 12);
    uint64_t v73 = v72 + (v70 << 6);
    while (1)
    {
      uint64_t v74 = *(void *)(v72 + 8);
      unint64_t v75 = *(void *)(v74 + 56) - *(void *)(v74 + 48);
      if ((v75 & 0x7FFFFFFF8) != 0) {
        break;
      }
LABEL_110:
      v72 += 64;
      if (v72 == v73) {
        goto LABEL_210;
      }
    }
    uint64_t v76 = 0;
    uint64_t v77 = (mlir::detail::OpResultImpl *)(v75 >> 3);
    while (1)
    {
      uint64_t v78 = *(void *)(v72 + 16) + 24 * v76;
      uint64_t v79 = *(void **)(*(void *)(v74 + 48) + 8 * v76);
      if (*(unsigned char *)(v78 + 16))
      {
        if (*v79)
        {
          uint64_t v80 = *(void **)(v78 + 8);
          uint64_t v81 = *(void *)this;
          LODWORD(v82) = *((_DWORD *)this + 4);
          unint64_t v83 = v79[1] & 0xFFFFFFFFFFFFFFF8;
          if (v83)
          {
            int32x2_t v84 = 0;
            do
            {
              unint64_t v85 = (unint64_t)v80;
              if ((v80[1] & 0xFFFFFFFFFFFFFFF8) == v83) {
                int32x2_t v84 = v80;
              }
              if (!v82) {
                break;
              }
              {
                uint64_t v140 = v73;
                uint64_t v143 = v72;
                uint64_t v147 = v77;
                uint64_t v152 = v74;
                uint64_t v77 = v147;
                uint64_t v74 = v152;
                uint64_t v73 = v140;
                uint64_t v72 = v143;
                uint64_t v71 = &unk_267770000;
                if (v92)
                {
                  unint64_t v93 = llvm::hashing::detail::fixed_seed_override;
                  if (!llvm::hashing::detail::fixed_seed_override) {
                    unint64_t v93 = 0xFF51AFD7ED558CCDLL;
                  }
                  llvm::hashing::detail::get_execution_seed(void)::seed = v93;
                  uint64_t v77 = v147;
                  uint64_t v74 = v152;
                  uint64_t v73 = v140;
                  uint64_t v72 = v143;
                  uint64_t v71 = (void *)&unk_267770000;
                }
              }
              unint64_t v86 = 0x9DDFEA08EB382D69 * ((v71[385] + 8 * v85) ^ HIDWORD(v85));
              unint64_t v87 = 0x9DDFEA08EB382D69 * (HIDWORD(v85) ^ (v86 >> 47) ^ v86);
              LODWORD(v87) = (-348639895 * ((v87 >> 47) ^ v87)) & (v82 - 1);
              uint64_t v88 = (void *)(v81 + 16 * v87);
              int v89 = (void *)*v88;
              if (v85 != *v88)
              {
                int v90 = 1;
                while (v89 != (void *)-4096)
                {
                  int v91 = v87 + v90++;
                  unint64_t v87 = v91 & (v82 - 1);
                  int v89 = *(void **)(v81 + 16 * v87);
                  if ((void *)v85 == v89)
                  {
                    uint64_t v88 = (void *)(v81 + 16 * v87);
                    uint64_t v81 = *(void *)this;
                    uint64_t v82 = *((unsigned int *)this + 4);
                    if (v88 != (void *)(*(void *)this + 16 * v82)) {
                      goto LABEL_124;
                    }
                    goto LABEL_154;
                  }
                }
                break;
              }
              uint64_t v81 = *(void *)this;
              uint64_t v82 = *((unsigned int *)this + 4);
              if (v88 == (void *)(*(void *)this + 16 * v82)) {
                break;
              }
LABEL_124:
              uint64_t v80 = (void *)v88[1];
            }
            while (v80);
LABEL_154:
            if (v84) {
              unint64_t v108 = (unint64_t)v84;
            }
            else {
              unint64_t v108 = v85;
            }
          }
          else
          {
            do
            {
              unint64_t v108 = (unint64_t)v80;
              if (!v82) {
                break;
              }
              {
                uint64_t v115 = v72;
                uint64_t v116 = v73;
                uint64_t v149 = v77;
                uint64_t v154 = v74;
                uint64_t v77 = v149;
                uint64_t v74 = v154;
                uint64_t v73 = v116;
                uint64_t v72 = v115;
                uint64_t v71 = &unk_267770000;
                if (v117)
                {
                  unint64_t v118 = llvm::hashing::detail::fixed_seed_override;
                  if (!llvm::hashing::detail::fixed_seed_override) {
                    unint64_t v118 = 0xFF51AFD7ED558CCDLL;
                  }
                  llvm::hashing::detail::get_execution_seed(void)::seed = v118;
                  uint64_t v77 = v149;
                  uint64_t v74 = v154;
                  uint64_t v73 = v116;
                  uint64_t v72 = v115;
                  uint64_t v71 = (void *)&unk_267770000;
                }
              }
              unint64_t v109 = 0x9DDFEA08EB382D69 * ((v71[385] + 8 * v108) ^ HIDWORD(v108));
              unint64_t v110 = 0x9DDFEA08EB382D69 * (HIDWORD(v108) ^ (v109 >> 47) ^ v109);
              LODWORD(v110) = (-348639895 * ((v110 >> 47) ^ v110)) & (v82 - 1);
              uint64_t v111 = (void *)(v81 + 16 * v110);
              uint64_t v112 = (void *)*v111;
              if (v108 != *v111)
              {
                int v113 = 1;
                while (v112 != (void *)-4096)
                {
                  int v114 = v110 + v113++;
                  unint64_t v110 = v114 & (v82 - 1);
                  uint64_t v112 = *(void **)(v81 + 16 * v110);
                  if ((void *)v108 == v112)
                  {
                    uint64_t v111 = (void *)(v81 + 16 * v110);
                    uint64_t v81 = *(void *)this;
                    uint64_t v82 = *((unsigned int *)this + 4);
                    if (v111 != (void *)(*(void *)this + 16 * v82)) {
                      goto LABEL_167;
                    }
                    goto LABEL_179;
                  }
                }
                break;
              }
              uint64_t v81 = *(void *)this;
              uint64_t v82 = *((unsigned int *)this + 4);
              if (v111 == (void *)(*(void *)this + 16 * v82)) {
                break;
              }
LABEL_167:
              uint64_t v80 = (void *)v111[1];
            }
            while (v80);
          }
LABEL_179:
          while (1)
          {
            unsigned int v119 = (void *)*v79;
            if (!*v79) {
              break;
            }
            uint64_t v120 = (void *)v119[1];
            if (v120)
            {
              *uint64_t v120 = *v119;
              if (*v119) {
                *(void *)(*v119 + 8) = v119[1];
              }
            }
            v119[3] = v108;
            v119[1] = v108;
            uint64_t v121 = *(void *)v108;
            *unsigned int v119 = *(void *)v108;
            if (v121) {
              *(void *)(v121 + 8) = v119;
            }
            *(void *)unint64_t v108 = v119;
          }
        }
        goto LABEL_113;
      }
      uint64_t v94 = *(void *)this;
      LODWORD(v95) = *((_DWORD *)this + 4);
      unint64_t v96 = v79[1] & 0xFFFFFFFFFFFFFFF8;
      if (v96)
      {
        unint64_t v97 = 0;
        uint64_t v98 = *(void **)(*(void *)(v74 + 48) + 8 * v76);
        do
        {
          unint64_t v99 = (unint64_t)v98;
          if ((v98[1] & 0xFFFFFFFFFFFFFFF8) == v96) {
            unint64_t v97 = (unint64_t)v98;
          }
          if (!v95) {
            break;
          }
          {
            uint64_t v141 = v73;
            uint64_t v144 = v72;
            uint64_t v148 = v77;
            uint64_t v153 = v74;
            uint64_t v77 = v148;
            uint64_t v74 = v153;
            uint64_t v73 = v141;
            uint64_t v72 = v144;
            uint64_t v71 = &unk_267770000;
            if (v106)
            {
              unint64_t v107 = llvm::hashing::detail::fixed_seed_override;
              if (!llvm::hashing::detail::fixed_seed_override) {
                unint64_t v107 = 0xFF51AFD7ED558CCDLL;
              }
              llvm::hashing::detail::get_execution_seed(void)::seed = v107;
              uint64_t v77 = v148;
              uint64_t v74 = v153;
              uint64_t v73 = v141;
              uint64_t v72 = v144;
              uint64_t v71 = (void *)&unk_267770000;
            }
          }
          unint64_t v100 = 0x9DDFEA08EB382D69 * ((v71[385] + 8 * v99) ^ HIDWORD(v99));
          unint64_t v101 = 0x9DDFEA08EB382D69 * (HIDWORD(v99) ^ (v100 >> 47) ^ v100);
          LODWORD(v101) = (-348639895 * ((v101 >> 47) ^ v101)) & (v95 - 1);
          uint64_t v102 = (void *)(v94 + 16 * v101);
          uint64_t v103 = (void *)*v102;
          if (v99 != *v102)
          {
            int v104 = 1;
            while (v103 != (void *)-4096)
            {
              int v105 = v101 + v104++;
              unint64_t v101 = v105 & (v95 - 1);
              uint64_t v103 = *(void **)(v94 + 16 * v101);
              if ((void *)v99 == v103)
              {
                uint64_t v102 = (void *)(v94 + 16 * v101);
                uint64_t v94 = *(void *)this;
                uint64_t v95 = *((unsigned int *)this + 4);
                if (v102 != (void *)(*(void *)this + 16 * v95)) {
                  goto LABEL_143;
                }
                goto LABEL_157;
              }
            }
            break;
          }
          uint64_t v94 = *(void *)this;
          uint64_t v95 = *((unsigned int *)this + 4);
          if (v102 == (void *)(*(void *)this + 16 * v95)) {
            break;
          }
LABEL_143:
          uint64_t v98 = (void *)v102[1];
        }
        while (v98);
LABEL_157:
        if (!v97) {
          unint64_t v97 = v99;
        }
      }
      else
      {
        uint64_t v122 = *(void **)(*(void *)(v74 + 48) + 8 * v76);
        do
        {
          unint64_t v97 = (unint64_t)v122;
          if (!v95) {
            break;
          }
          {
            uint64_t v145 = v72;
            uint64_t v150 = v77;
            uint64_t v129 = v73;
            uint64_t v155 = v74;
            uint64_t v77 = v150;
            uint64_t v74 = v155;
            uint64_t v73 = v129;
            uint64_t v72 = v145;
            uint64_t v71 = &unk_267770000;
            if (v130)
            {
              unint64_t v131 = llvm::hashing::detail::fixed_seed_override;
              if (!llvm::hashing::detail::fixed_seed_override) {
                unint64_t v131 = 0xFF51AFD7ED558CCDLL;
              }
              llvm::hashing::detail::get_execution_seed(void)::seed = v131;
              uint64_t v77 = v150;
              uint64_t v74 = v155;
              uint64_t v73 = v129;
              uint64_t v72 = v145;
              uint64_t v71 = (void *)&unk_267770000;
            }
          }
          unint64_t v123 = 0x9DDFEA08EB382D69 * ((v71[385] + 8 * v97) ^ HIDWORD(v97));
          unint64_t v124 = 0x9DDFEA08EB382D69 * (HIDWORD(v97) ^ (v123 >> 47) ^ v123);
          LODWORD(v124) = (-348639895 * ((v124 >> 47) ^ v124)) & (v95 - 1);
          uint64_t v125 = (void *)(v94 + 16 * v124);
          uint64_t v126 = (void *)*v125;
          if (v97 != *v125)
          {
            int v127 = 1;
            while (v126 != (void *)-4096)
            {
              int v128 = v124 + v127++;
              unint64_t v124 = v128 & (v95 - 1);
              uint64_t v126 = *(void **)(v94 + 16 * v124);
              if ((void *)v97 == v126)
              {
                uint64_t v125 = (void *)(v94 + 16 * v124);
                uint64_t v94 = *(void *)this;
                uint64_t v95 = *((unsigned int *)this + 4);
                if (v125 != (void *)(*(void *)this + 16 * v95)) {
                  goto LABEL_190;
                }
                goto LABEL_159;
              }
            }
            break;
          }
          uint64_t v94 = *(void *)this;
          uint64_t v95 = *((unsigned int *)this + 4);
          if (v125 == (void *)(*(void *)this + 16 * v95)) {
            break;
          }
LABEL_190:
          uint64_t v122 = (void *)v125[1];
        }
        while (v122);
      }
LABEL_159:
      if ((void *)v97 == v79) {
        goto LABEL_113;
      }
      if (v96)
      {
        if ((*(void *)(v97 + 8) & 0xFFFFFFFFFFFFFFF8) == v96) {
          goto LABEL_204;
        }
      }
      else if (v97)
      {
LABEL_204:
        while (1)
        {
          uint64_t v132 = (void *)*v79;
          if (!*v79) {
            break;
          }
          unint64_t v133 = (void *)v132[1];
          if (v133)
          {
            void *v133 = *v132;
            if (*v132) {
              *(void *)(*v132 + 8) = v132[1];
            }
          }
          v132[3] = v97;
          v132[1] = v97;
          uint64_t v134 = *(void *)v97;
          *uint64_t v132 = *(void *)v97;
          if (v134) {
            *(void *)(v134 + 8) = v132;
          }
          *(void *)unint64_t v97 = v132;
        }
      }
LABEL_113:
      if ((mlir::detail::OpResultImpl *)++v76 == v77) {
        goto LABEL_110;
      }
    }
  }
LABEL_210:
  uint64_t v135 = *((unsigned int *)this + 106);
  if (v135)
  {
    int v136 = (mlir::Block **)(*((void *)this + 52) + 8);
    uint64_t v137 = 40 * v135;
    do
    {
      if (*((_DWORD *)v136 - 2) == 1 && *v136)
      {
        mlir::Block::~Block(*v136);
        MEMORY[0x21667D3C0]();
      }
      v136 += 5;
      v137 -= 40;
    }
    while (v137);
  }
}

unint64_t anonymous namespace'::ConversionValueMapping::lookupOrNull(uint64_t a1, unint64_t a2, uint64_t a3)
{
  if (a3)
  {
    unint64_t v6 = 0;
    unint64_t v7 = a2;
    do
    {
      unint64_t v8 = v7;
      if ((*(void *)(v7 + 8) & 0xFFFFFFFFFFFFFFF8) == a3) {
        unint64_t v6 = v7;
      }
      unint64_t v11 = v7;
      uint64_t v12 = 0;
      if (!llvm::DenseMapBase<llvm::DenseMap<mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>,mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>::LookupBucketFor<mlir::Value>((uint64_t *)a1, &v11, &v12))break; {
      if (v12 == *(void *)a1 + 16 * *(unsigned int *)(a1 + 16))
      }
        break;
      unint64_t v7 = *(void *)(v12 + 8);
    }
    while (v7);
    if (!v6) {
      unint64_t v6 = v8;
    }
  }
  else
  {
    unint64_t v9 = a2;
    do
    {
      unint64_t v6 = v9;
      unint64_t v11 = v9;
      uint64_t v12 = 0;
      if (!llvm::DenseMapBase<llvm::DenseMap<mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>,mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>::LookupBucketFor<mlir::Value>((uint64_t *)a1, &v11, &v12))break; {
      if (v12 == *(void *)a1 + 16 * *(unsigned int *)(a1 + 16))
      }
        break;
      unint64_t v9 = *(void *)(v12 + 8);
    }
    while (v9);
  }
  if (v6 == a2 || a3 && (*(void *)(v6 + 8) & 0xFFFFFFFFFFFFFFF8) != a3) {
    return 0;
  }
  return v6;
}

void anonymous namespace'::ArgConverter::notifyOpRemoved(int32x2_t *this, mlir::Operation *a2)
{
  uint64_t v2 = this + 4;
  if (this[4].i32[0])
  {
    unint64_t v3 = *((unsigned int *)a2 + 11);
    if ((v3 & 0x7FFFFF) != 0)
    {
      unint64_t v5 = (((unint64_t)a2 + 16 * ((v3 >> 23) & 1) + ((v3 >> 21) & 0x7F8) + 71) & 0xFFFFFFFFFFFFFFF8)
         + 32 * *((unsigned int *)a2 + 10);
      unint64_t v53 = v5 + 24 * (v3 & 0x7FFFFF);
      while (1)
      {
        uint64_t v6 = *(void *)(v5 + 8);
        unint64_t v54 = v5;
        if (v6 != v5) {
          break;
        }
LABEL_4:
        v5 += 24;
        if (v5 == v53) {
          return;
        }
      }
      while (1)
      {
        if (v6) {
          uint64_t v7 = v6 - 8;
        }
        else {
          uint64_t v7 = 0;
        }
        for (uint64_t i = *(ZinIrHalH13g **)(v7 + 40); i != (ZinIrHalH13g *)(v7 + 32); uint64_t i = (ZinIrHalH13g *)*((void *)i + 1))
        {
          ZinIrHalH13g::~ZinIrHalH13g(i);
          if ((*((_DWORD *)v9 + 11) & 0x7FFFFF) != 0) {
        }
          }
        int32x2_t v10 = *this;
        uint64_t v11 = this[2].u32[0];
        if (v11)
        {
          LODWORD(v12) = (v11 - 1) & ((v7 >> 4) ^ (v7 >> 9));
          unint64_t v13 = (int32x2_t *)(*(void *)&v10 + 16 * v12);
          int32x2_t v14 = *v13;
          if (*v13 == v7) {
            goto LABEL_23;
          }
          int v15 = 1;
          while (*(void *)&v14 != -4096)
          {
            int v16 = v12 + v15++;
            uint64_t v12 = v16 & (v11 - 1);
            int32x2_t v14 = *(int32x2_t *)(*(void *)&v10 + 16 * v12);
            if (*(void *)&v14 == v7)
            {
              unint64_t v13 = (int32x2_t *)(*(void *)&v10 + 16 * v12);
              goto LABEL_23;
            }
          }
        }
        unint64_t v13 = (int32x2_t *)(*(void *)&v10 + 16 * v11);
LABEL_23:
        if (v13 == (int32x2_t *)(*(void *)&v10 + 16 * v11)) {
          unint64_t v17 = v2;
        }
        else {
          unint64_t v17 = v13 + 1;
        }
        uint64_t v18 = v17->u32[0];
        if (v18 == this[4].i32[0]) {
          goto LABEL_7;
        }
        uint64_t v19 = (void *)(*(void *)&this[3] + (v18 << 6));
        uint64_t v20 = v19[1];
        int v21 = *(void ****)(v20 + 48);
        int v22 = *(void ****)(v20 + 56);
        if (v22 == v21)
        {
          if (v11) {
            goto LABEL_38;
          }
        }
        else
        {
          do
          {
            int v23 = *v21;
            while (1)
            {
              unint64_t v24 = *v23;
              if (!*v23) {
                break;
              }
              uint64_t v25 = (void *)v24[1];
              if (v25)
              {
                void *v25 = *v24;
                if (*v24) {
                  *(void *)(*v24 + 8) = v24[1];
                }
              }
              *unint64_t v24 = 0;
              v24[1] = 0;
              void v24[3] = 0;
            }
            ++v21;
          }
          while (v21 != v22);
          int32x2_t v10 = *this;
          LODWORD(v11) = this[2].i32[0];
          if (v11)
          {
LABEL_38:
            unsigned int v26 = v11 - 1;
            LODWORD(v11) = ((*v19 >> 4) ^ (*v19 >> 9)) & (v11 - 1);
            unint64_t v27 = (uint64_t *)(*(void *)&v10 + 16 * v11);
            uint64_t v28 = *v27;
            if (*v19 == *v27)
            {
LABEL_39:
              uint64_t *v27 = -8192;
              this[1] = vadd_s32(this[1], (int32x2_t)0x1FFFFFFFFLL);
            }
            else
            {
              int v51 = 1;
              while (v28 != -4096)
              {
                int v52 = v11 + v51++;
                uint64_t v11 = v52 & v26;
                uint64_t v28 = *(void *)(*(void *)&v10 + 16 * v11);
                if (*v19 == v28)
                {
                  unint64_t v27 = (uint64_t *)(*(void *)&v10 + 16 * v11);
                  goto LABEL_39;
                }
              }
            }
          }
        }
        unsigned int v29 = v19 + 8;
        int32x2_t v30 = this[3];
        uint64_t v31 = this[4].u32[0];
        int v32 = (void *)(*(void *)&v30 + (v31 << 6));
        if (v19 + 8 != v32)
        {
          int v33 = v19;
          while (1)
          {
            *(_OWORD *)int v33 = *((_OWORD *)v33 + 4);
            uint64_t v35 = (void *)v33[10];
            if (v33 + 12 != v35)
            {
              uint64_t v36 = (void *)v33[2];
              if (v33 + 4 != v36)
              {
                free(v36);
                uint64_t v35 = (void *)v33[10];
              }
              unint64_t v33[2] = v35;
              uint64_t v37 = v29 + 3;
              unint64_t v33[3] = v33[11];
              v33[10] = v33 + 12;
              *((_DWORD *)v33 + 23) = 0;
              goto LABEL_43;
            }
            uint64_t v38 = (void **)(v33 + 2);
            uint64_t v37 = v33 + 11;
            unint64_t v39 = *((unsigned int *)v33 + 22);
            uint64_t v40 = *((unsigned int *)v33 + 6);
            if (v40 >= v39)
            {
              if (v39) {
                memmove(*v38, v35, 24 * v39 - 7);
              }
              goto LABEL_42;
            }
            if (*((_DWORD *)v33 + 7) >= v39)
            {
              if (v40)
              {
                memmove(*v38, v35, 24 * v40 - 7);
                uint64_t v41 = *v37;
                if (v40 != v41) {
                  goto LABEL_58;
                }
              }
              else
              {
                uint64_t v40 = 0;
                LODWORD(v41) = *v37;
                if (*v37) {
LABEL_58:
                }
                  memcpy((void *)(v33[2] + 24 * v40), (const void *)(v33[10] + 24 * v40), 24 * v41 - 24 * v40);
              }
            }
            else
            {
              *((_DWORD *)v33 + 6) = 0;
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)v38, v33 + 4, v39, 24);
              uint64_t v40 = 0;
              LODWORD(v41) = *v37;
              if (*v37) {
                goto LABEL_58;
              }
            }
LABEL_42:
            *((_DWORD *)v33 + 6) = v39;
LABEL_43:
            _DWORD *v37 = 0;
            void v33[7] = v33[15];
            v29 += 8;
            unint64_t v34 = v33 + 16;
            v33 += 8;
            if (v34 == v32)
            {
              LODWORD(v31) = this[4].i32[0];
              int32x2_t v30 = this[3];
              unint64_t v5 = v54;
              break;
            }
          }
        }
        uint64_t v42 = (v31 - 1);
        v2->i32[0] = v42;
        uint64_t v43 = *(void *)&v30 + (v42 << 6);
        uint64_t v44 = *(void **)(v43 + 16);
        if (v44 != (void *)(v43 + 32))
        {
          free(v44);
          int32x2_t v30 = this[3];
          uint64_t v42 = this[4].u32[0];
        }
        if ((void *)(*(void *)&v30 + (v42 << 6)) != v19 && this[1].i32[0])
        {
          uint64_t v45 = this[2].u32[0];
          if (v45)
          {
            uint64_t v46 = 16 * v45;
            int32x2_t v47 = *this;
            while ((**(void **)&v47 | 0x1000) == 0xFFFFFFFFFFFFF000)
            {
              *(void *)&v47 += 16;
              v46 -= 16;
              if (!v46) {
                goto LABEL_7;
              }
            }
          }
          else
          {
            int32x2_t v47 = *this;
          }
          uint64_t v48 = *(void *)this + 16 * v45;
          if (*(void *)&v47 != v48)
          {
            unint64_t v49 = ((uint64_t)v19 - *(void *)&v30) >> 6;
LABEL_72:
            unint64_t v50 = *(unsigned int *)(*(void *)&v47 + 8);
            if (v49 < v50) {
              *(_DWORD *)(*(void *)&v47 + 8) = v50 - 1;
            }
            while (1)
            {
              *(void *)&v47 += 16;
              if (*(void *)&v47 == v48) {
                break;
              }
              if ((**(void **)&v47 | 0x1000) != 0xFFFFFFFFFFFFF000)
              {
                if (*(void *)&v47 != v48) {
                  goto LABEL_72;
                }
                break;
              }
            }
          }
        }
LABEL_7:
        uint64_t v6 = *(void *)(v6 + 8);
        if (v6 == v5) {
          goto LABEL_4;
        }
      }
    }
  }
}

uint64_t mlir::detail::ConversionPatternRewriterImpl::remapValues(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, unsigned __int8 a5, uint64_t a6, uint64_t a7, unint64_t a8, uint64_t a9)
{
  uint64_t v12 = a9;
  v64[1] = *MEMORY[0x263EF8340];
  if (a8 > *(unsigned int *)(a9 + 12)) {
    llvm::SmallVectorBase<unsigned int>::grow_pod(a9, (void *)(a9 + 16), a8, 8);
  }
  int v62 = v64;
  uint64_t v63 = 0x100000000;
  uint64_t v59 = 0;
  uint64_t v60 = a7;
  uint64_t v61 = 0;
  if (!a8)
  {
LABEL_70:
    uint64_t v50 = 1;
    int v51 = v62;
    if (v62 != v64) {
      goto LABEL_71;
    }
    return v50;
  }
  uint64_t v13 = 0;
  uint64_t v53 = a5;
  while (1)
  {
    uint64_t v14 = mlir::ValueRange::dereference_iterator(&v60, v13);
    uint64_t v56 = v14;
    uint64_t v15 = *(void *)(a1 + 1224);
    if (!v15)
    {
LABEL_27:
      unint64_t v17 = 0;
      uint64_t v18 = (ZinIrHalH13g *)v56;
LABEL_28:
      uint64_t v30 = *(void *)a1;
      LODWORD(v31) = *(_DWORD *)(a1 + 16);
      while (1)
      {
        unint64_t v32 = (unint64_t)v18;
        if (!v31) {
          goto LABEL_66;
        }
        {
          unint64_t v39 = llvm::hashing::detail::fixed_seed_override;
          if (!llvm::hashing::detail::fixed_seed_override) {
            unint64_t v39 = 0xFF51AFD7ED558CCDLL;
          }
          llvm::hashing::detail::get_execution_seed(void)::seed = v39;
        }
        unint64_t v33 = 0x9DDFEA08EB382D69
            * ((llvm::hashing::detail::get_execution_seed(void)::seed + 8 * v32) ^ HIDWORD(v32));
        unint64_t v34 = 0x9DDFEA08EB382D69 * (HIDWORD(v32) ^ (v33 >> 47) ^ v33);
        LODWORD(v34) = (-348639895 * ((v34 >> 47) ^ v34)) & (v31 - 1);
        uint64_t v35 = (uint64_t *)(v30 + 16 * v34);
        uint64_t v36 = *v35;
        if (v32 != *v35)
        {
          int v37 = 1;
          while (v36 != -4096)
          {
            int v38 = v34 + v37++;
            unint64_t v34 = v38 & (v31 - 1);
            uint64_t v36 = *(void *)(v30 + 16 * v34);
            if (v32 == v36)
            {
              uint64_t v35 = (uint64_t *)(v30 + 16 * v34);
              uint64_t v30 = *(void *)a1;
              uint64_t v31 = *(unsigned int *)(a1 + 16);
              if (v35 != (uint64_t *)(*(void *)a1 + 16 * v31)) {
                goto LABEL_33;
              }
              goto LABEL_66;
            }
          }
          goto LABEL_66;
        }
        uint64_t v30 = *(void *)a1;
        uint64_t v31 = *(unsigned int *)(a1 + 16);
        if (v35 == (uint64_t *)(*(void *)a1 + 16 * v31)) {
          goto LABEL_66;
        }
LABEL_33:
        uint64_t v18 = (ZinIrHalH13g *)v35[1];
        if (!v18) {
          goto LABEL_49;
        }
      }
    }
    int v16 = (void *)(*(void *)(v14 + 8) & 0xFFFFFFFFFFFFFFF8);
    LODWORD(v63) = 0;
    if (!mlir::TypeConverter::convertType(v15, v16, (uint64_t)&v62)) {
      break;
    }
    if (v63 != 1) {
      goto LABEL_27;
    }
    unint64_t v17 = (ZinIrHalH13g *)*v62;
    uint64_t v18 = (ZinIrHalH13g *)v56;
    if (!*v62) {
      goto LABEL_28;
    }
    unint64_t v19 = 0;
    uint64_t v20 = *(void *)a1;
    LODWORD(v21) = *(_DWORD *)(a1 + 16);
    do
    {
      unint64_t v22 = (unint64_t)v18;
      if (v17 == (ZinIrHalH13g *)(*((void *)v18 + 1) & 0xFFFFFFFFFFFFFFF8)) {
        unint64_t v19 = (unint64_t)v18;
      }
      if (!v21) {
        break;
      }
      {
        unint64_t v29 = llvm::hashing::detail::fixed_seed_override;
        if (!llvm::hashing::detail::fixed_seed_override) {
          unint64_t v29 = 0xFF51AFD7ED558CCDLL;
        }
        llvm::hashing::detail::get_execution_seed(void)::seed = v29;
      }
      unint64_t v23 = 0x9DDFEA08EB382D69
          * ((llvm::hashing::detail::get_execution_seed(void)::seed + 8 * v22) ^ HIDWORD(v22));
      unint64_t v24 = 0x9DDFEA08EB382D69 * (HIDWORD(v22) ^ (v23 >> 47) ^ v23);
      LODWORD(v24) = (-348639895 * ((v24 >> 47) ^ v24)) & (v21 - 1);
      uint64_t v25 = (uint64_t *)(v20 + 16 * v24);
      uint64_t v26 = *v25;
      if (v22 != *v25)
      {
        int v27 = 1;
        while (v26 != -4096)
        {
          int v28 = v24 + v27++;
          unint64_t v24 = v28 & (v21 - 1);
          uint64_t v26 = *(void *)(v20 + 16 * v24);
          if (v22 == v26)
          {
            uint64_t v25 = (uint64_t *)(v20 + 16 * v24);
            uint64_t v20 = *(void *)a1;
            uint64_t v21 = *(unsigned int *)(a1 + 16);
            if (v25 != (uint64_t *)(*(void *)a1 + 16 * v21)) {
              goto LABEL_16;
            }
            goto LABEL_45;
          }
        }
        break;
      }
      uint64_t v20 = *(void *)a1;
      uint64_t v21 = *(unsigned int *)(a1 + 16);
      if (v25 == (uint64_t *)(*(void *)a1 + 16 * v21)) {
        break;
      }
LABEL_16:
      uint64_t v18 = (ZinIrHalH13g *)v25[1];
    }
    while (v18);
LABEL_45:
    if (v19) {
      unint64_t v32 = v19;
    }
    else {
      unint64_t v32 = v22;
    }
    uint64_t v18 = v17;
    uint64_t v12 = a9;
LABEL_49:
    if (v18)
    {
      uint64_t v40 = *(void *)(a1 + 1224);
      if (v40 && v18 != (ZinIrHalH13g *)(*(void *)(v32 + 8) & 0xFFFFFFFFFFFFFFF8))
      {
        uint64_t Loc = a4;
        if (!v53)
        {
          uint64_t Loc = mlir::Value::getLoc((mlir::Value *)&v56);
          uint64_t v40 = *(void *)(a1 + 1224);
        }
        uint64_t v58 = (mlir::detail::OpResultImpl *)v32;
        uint64_t ParentBlock = (mlir::Block *)mlir::Value::getParentBlock((mlir::Value *)&v58);
        uint64_t v44 = (uint64_t *)((char *)ParentBlock + 40);
        if (v58 && (*((void *)v58 + 1) & 7) != 7) {
          uint64_t v44 = (uint64_t *)(mlir::detail::OpResultImpl::getOwner(v58) + 8);
        }
        uint64_t v45 = buildUnresolvedMaterialization(1u, ParentBlock, *v44, Loc, (uint64_t)&v58, 1, (uint64_t)v17, v17, v40, (uint64_t *)(a1 + 264));
        uint64_t v12 = a9;
        do
        {
          unint64_t v46 = v32;
          unint64_t v57 = v32;
          uint64_t v58 = 0;
          if (!llvm::DenseMapBase<llvm::DenseMap<mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>,mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>::LookupBucketFor<mlir::Value>((uint64_t *)a1, &v57, &v58))break; {
          if (v58 == (mlir::detail::OpResultImpl *)(*(void *)a1 + 16 * *(unsigned int *)(a1 + 16)))
          }
            break;
          unint64_t v32 = *((void *)v58 + 1);
        }
        while (v32);
        unint64_t v57 = v46;
        uint64_t v58 = 0;
        char v47 = llvm::DenseMapBase<llvm::DenseMap<mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>,mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>::LookupBucketFor<mlir::Value>((uint64_t *)a1, &v57, &v58);
        uint64_t v48 = v58;
        if ((v47 & 1) == 0)
        {
          uint64_t v48 = llvm::DenseMapBase<llvm::DenseMap<mlir::Value,mlir::Value,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,mlir::Value>>,mlir::Value,mlir::Value,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,mlir::Value>>::InsertIntoBucketImpl<mlir::Value>(a1, (uint64_t)&v57, &v57, v58);
          *uint64_t v48 = v57;
          v48[1] = 0;
        }
        v48[1] = v45;
        unint64_t v32 = v45;
      }
    }
LABEL_66:
    unint64_t v49 = *(unsigned int *)(v12 + 8);
    if (v49 >= *(unsigned int *)(v12 + 12))
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod(v12, (void *)(a9 + 16), v49 + 1, 8);
      unint64_t v49 = *(unsigned int *)(v12 + 8);
    }
    *(void *)(*(void *)v12 + 8 * v49) = v32;
    ++*(_DWORD *)(v12 + 8);
    uint64_t v13 = v61 + 1;
    ++v59;
    ++v61;
    if (v60 == a7 && v13 == a8) {
      goto LABEL_70;
    }
  }
  if (v53)
  {
    uint64_t v50 = 0;
    int v51 = v62;
    if (v62 == v64) {
      return v50;
    }
  }
  else
  {
    mlir::Value::getLoc((mlir::Value *)&v56);
    uint64_t v50 = 0;
    int v51 = v62;
    if (v62 == v64) {
      return v50;
    }
  }
LABEL_71:
  free(v51);
  return v50;
}

BOOL mlir::TypeConverter::convertType(uint64_t a1, void *a2, uint64_t a3)
{
  unint64_t v97[2] = *MEMORY[0x263EF8340];
  uint64_t v94 = a2;
  unint64_t v5 = (pthread_rwlock_t **)(a1 + 520);
  uint64_t Context = (mlir::MLIRContext *)mlir::Attribute::getContext((mlir::Attribute *)&v94);
  int isMultithreadingEnabled = mlir::MLIRContext::isMultithreadingEnabled(Context);
  if (isMultithreadingEnabled) {
    llvm::sys::RWMutexImpl::lock_shared(v5);
  }
  uint64_t v8 = *(void *)(a1 + 472);
  uint64_t v9 = *(unsigned int *)(a1 + 488);
  if (v9)
  {
    LODWORD(v10) = ((v94 >> 4) ^ (v94 >> 9)) & (v9 - 1);
    uint64_t v11 = (void **)(v8 + 16 * v10);
    uint64_t v12 = *v11;
    if (v94 == *v11) {
      goto LABEL_10;
    }
    int v13 = 1;
    while (v12 != (void *)-4096)
    {
      int v14 = v10 + v13++;
      uint64_t v10 = v14 & (v9 - 1);
      uint64_t v12 = *(void **)(v8 + 16 * v10);
      if (v94 == v12)
      {
        uint64_t v11 = (void **)(v8 + 16 * v10);
        goto LABEL_10;
      }
    }
  }
  uint64_t v11 = (void **)(v8 + 16 * v9);
LABEL_10:
  if (v11 != (void **)(v8 + 16 * v9))
  {
    uint64_t v15 = v11[1];
    if (v15)
    {
      uint64_t v16 = *(unsigned int *)(a3 + 8);
      if (v16 >= *(_DWORD *)(a3 + 12))
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod(a3, (void *)(a3 + 16), v16 + 1, 8);
        LODWORD(v16) = *(_DWORD *)(a3 + 8);
      }
      *(void *)(*(void *)a3 + 8 * v16) = v15;
      ++*(_DWORD *)(a3 + 8);
      unint64_t v17 = v11[1];
      int v18 = 0;
      BOOL v19 = v17 != 0;
      if (!isMultithreadingEnabled) {
        goto LABEL_32;
      }
    }
    else
    {
      int v18 = 0;
      BOOL v19 = 0;
      if (!isMultithreadingEnabled) {
        goto LABEL_32;
      }
    }
LABEL_31:
    llvm::sys::RWMutexImpl::unlock_shared(v5);
    goto LABEL_32;
  }
  uint64_t v20 = *(void *)(a1 + 496);
  unsigned int v21 = *(_DWORD *)(a1 + 512);
  if (v21)
  {
    unsigned int v22 = ((v94 >> 4) ^ (v94 >> 9)) & (v21 - 1);
    uint64_t v23 = v20 + 40 * v22;
    unint64_t v24 = *(void **)v23;
    if (v94 == *(void **)v23) {
      goto LABEL_25;
    }
    int v25 = 1;
    while (v24 != (void *)-4096)
    {
      unsigned int v26 = v22 + v25++;
      unsigned int v22 = v26 & (v21 - 1);
      uint64_t v23 = v20 + 40 * v22;
      unint64_t v24 = *(void **)v23;
      if (v94 == *(void **)v23) {
        goto LABEL_25;
      }
    }
  }
  uint64_t v23 = v20 + 40 * v21;
LABEL_25:
  if (v23 == v20 + 40 * v21)
  {
    int v18 = 1;
    BOOL v19 = 1;
    if (!isMultithreadingEnabled) {
      goto LABEL_32;
    }
    goto LABEL_31;
  }
  int v27 = *(const void **)(v23 + 8);
  uint64_t v28 = *(unsigned int *)(v23 + 16);
  uint64_t v29 = *(unsigned int *)(a3 + 8);
  if (v29 + v28 > (unint64_t)*(unsigned int *)(a3 + 12))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod(a3, (void *)(a3 + 16), v29 + v28, 8);
    LODWORD(v29) = *(_DWORD *)(a3 + 8);
  }
  if (v28)
  {
    memcpy((void *)(*(void *)a3 + 8 * v29), v27, 8 * v28);
    LODWORD(v29) = *(_DWORD *)(a3 + 8);
  }
  int v18 = 0;
  *(_DWORD *)(a3 + 8) = v29 + v28;
  BOOL v19 = 1;
  if (isMultithreadingEnabled) {
    goto LABEL_31;
  }
LABEL_32:
  if (!v18) {
    return v19;
  }
  uint64_t v30 = *(unsigned int *)(a3 + 8);
  uint64_t v31 = *(void *)(a1 + 8) + 32 * *(unsigned int *)(a1 + 16);
  uint64_t v32 = -32 * *(unsigned int *)(a1 + 16);
  do
  {
    if (!v32) {
      return 0;
    }
    uint64_t v95 = v94;
    uint64_t v33 = *(void *)(v31 - 8);
    if (!v33) {
      std::__throw_bad_function_call[abi:nn180100]();
    }
    v31 -= 32;
    unsigned __int16 v34 = (*(uint64_t (**)(uint64_t, void **, uint64_t))(*(void *)v33 + 48))(v33, &v95, a3);
    v32 += 32;
  }
  while (v34 < 0x100u);
  char v35 = v34;
  uint64_t v36 = (mlir::MLIRContext *)mlir::Attribute::getContext((mlir::Attribute *)&v94);
  int v37 = mlir::MLIRContext::isMultithreadingEnabled(v36);
  if (v37) {
    llvm::sys::RWMutexImpl::lock(v5);
  }
  if (!v35)
  {
    unsigned int v50 = *(_DWORD *)(a1 + 488);
    if (!v50) {
      goto LABEL_107;
    }
    uint64_t v51 = *(void *)(a1 + 472);
    unsigned int v52 = ((v94 >> 4) ^ (v94 >> 9)) & (v50 - 1);
    uint64_t v53 = (void *)(v51 + 16 * v52);
    unint64_t v54 = (void *)*v53;
    if (v94 == (void *)*v53)
    {
      BOOL v19 = 0;
      goto LABEL_91;
    }
    uint64_t v70 = 0;
    int v71 = 1;
    while (v54 != (void *)-4096)
    {
      BOOL v19 = 0;
      if (v70) {
        BOOL v72 = 0;
      }
      else {
        BOOL v72 = v54 == (void *)-8192;
      }
      if (v72) {
        uint64_t v70 = v53;
      }
      unsigned int v73 = v52 + v71++;
      unsigned int v52 = v73 & (v50 - 1);
      uint64_t v53 = (void *)(v51 + 16 * v52);
      unint64_t v54 = (void *)*v53;
      if (v94 == (void *)*v53) {
        goto LABEL_91;
      }
    }
    uint64_t v74 = v70 ? v70 : v53;
    int v75 = *(_DWORD *)(a1 + 480);
    if (4 * v75 + 4 < 3 * v50)
    {
      if (v50 + ~v75 - *(_DWORD *)(a1 + 484) > v50 >> 3) {
        goto LABEL_76;
      }
    }
    else
    {
LABEL_107:
      v50 *= 2;
    }
    llvm::DenseMap<mlir::Block *,llvm::SMLoc,llvm::DenseMapInfo<mlir::Block *,void>,llvm::detail::DenseMapPair<mlir::Block *,llvm::SMLoc>>::grow(a1 + 472, v50);
    uint64_t v76 = *(void *)(a1 + 472);
    unint64_t v66 = v94;
    int v77 = *(_DWORD *)(a1 + 488) - 1;
    unsigned int v78 = ((v94 >> 4) ^ (v94 >> 9)) & v77;
    uint64_t v74 = (void *)(v76 + 16 * v78);
    uint64_t v79 = (void *)*v74;
    if (v94 == (void *)*v74) {
      goto LABEL_77;
    }
    uint64_t v80 = 0;
    int v81 = 1;
    while (v79 != (void *)-4096)
    {
      if (v80) {
        BOOL v82 = 0;
      }
      else {
        BOOL v82 = v79 == (void *)-8192;
      }
      if (v82) {
        uint64_t v80 = v74;
      }
      unsigned int v83 = v78 + v81++;
      unsigned int v78 = v83 & v77;
      uint64_t v74 = (void *)(v76 + 16 * (v83 & v77));
      uint64_t v79 = (void *)*v74;
      if (v94 == (void *)*v74) {
        goto LABEL_77;
      }
    }
    if (v80) {
      uint64_t v74 = v80;
    }
LABEL_76:
    unint64_t v66 = (void *)*v74;
LABEL_77:
    ++*(_DWORD *)(a1 + 480);
    if (v66 != (void *)-4096) {
      --*(_DWORD *)(a1 + 484);
    }
    BOOL v19 = 0;
    *uint64_t v74 = v94;
    v74[1] = 0;
    goto LABEL_91;
  }
  uint64_t v38 = *(unsigned int *)(a3 + 8);
  uint64_t v39 = v38 - v30;
  uint64_t v40 = (void *)(*(void *)a3 + 8 * v30);
  if (v38 - v30 != 1)
  {
    uint64_t v95 = v97;
    uint64_t v96 = 0x200000000;
    if ((unint64_t)(8 * v39) < 0x11)
    {
      unsigned int v55 = 0;
    }
    else
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v95, v97, v38 - v30, 8);
      unsigned int v55 = v96;
    }
    if (v38 != v30)
    {
      memcpy((char *)v95 + 8 * v55, v40, 8 * v39);
      unsigned int v55 = v96;
    }
    LODWORD(v96) = v55 + v39;
    int v56 = *(_DWORD *)(a1 + 512);
    if (v56)
    {
      uint64_t v57 = *(void *)(a1 + 496);
      int v58 = v56 - 1;
      unsigned int v59 = ((v94 >> 4) ^ (v94 >> 9)) & v58;
      uint64_t v60 = (uint64_t *)(v57 + 40 * v59);
      uint64_t v61 = (void *)*v60;
      if (v94 == (void *)*v60) {
        goto LABEL_88;
      }
      int v62 = 0;
      int v63 = 1;
      while (v61 != (void *)-4096)
      {
        if (v62) {
          BOOL v64 = 0;
        }
        else {
          BOOL v64 = v61 == (void *)-8192;
        }
        if (v64) {
          int v62 = v60;
        }
        unsigned int v65 = v59 + v63++;
        unsigned int v59 = v65 & v58;
        uint64_t v60 = (uint64_t *)(v57 + 40 * v59);
        uint64_t v61 = (void *)*v60;
        if (v94 == (void *)*v60) {
          goto LABEL_88;
        }
      }
      if (v62) {
        uint64_t v68 = v62;
      }
      else {
        uint64_t v68 = v60;
      }
    }
    else
    {
      uint64_t v68 = 0;
    }
    llvm::DenseMapBase<llvm::DenseMap<mlir::Type,llvm::SmallVector<mlir::Type,2u>,llvm::DenseMapInfo<mlir::Type,void>,llvm::detail::DenseMapPair<mlir::Type,llvm::SmallVector<mlir::Type,2u>>>,mlir::Type,llvm::SmallVector<mlir::Type,2u>,llvm::DenseMapInfo<mlir::Type,void>,llvm::detail::DenseMapPair<mlir::Type,llvm::SmallVector<mlir::Type,2u>>>::InsertIntoBucket<mlir::Type const&,llvm::SmallVector<mlir::Type,2u>>(a1 + 496, v68, (uint64_t *)&v94, (uint64_t)&v95);
LABEL_88:
    if (v95 != v97) {
      free(v95);
    }
    goto LABEL_90;
  }
  unsigned int v41 = *(_DWORD *)(a1 + 488);
  if (!v41) {
    goto LABEL_122;
  }
  uint64_t v42 = *(void *)(a1 + 472);
  unsigned int v43 = ((v94 >> 4) ^ (v94 >> 9)) & (v41 - 1);
  uint64_t v44 = (void *)(v42 + 16 * v43);
  uint64_t v45 = (void *)*v44;
  if (v94 != (void *)*v44)
  {
    unint64_t v46 = 0;
    int v47 = 1;
    BOOL v19 = 1;
    while (v45 != (void *)-4096)
    {
      if (v46) {
        BOOL v48 = 0;
      }
      else {
        BOOL v48 = v45 == (void *)-8192;
      }
      if (v48) {
        unint64_t v46 = v44;
      }
      unsigned int v49 = v43 + v47++;
      unsigned int v43 = v49 & (v41 - 1);
      uint64_t v44 = (void *)(v42 + 16 * v43);
      uint64_t v45 = (void *)*v44;
      if (v94 == (void *)*v44) {
        goto LABEL_91;
      }
    }
    if (v46) {
      int32x2_t v84 = v46;
    }
    else {
      int32x2_t v84 = v44;
    }
    int v85 = *(_DWORD *)(a1 + 480);
    if (4 * v85 + 4 < 3 * v41)
    {
      if (v41 + ~v85 - *(_DWORD *)(a1 + 484) > v41 >> 3) {
        goto LABEL_82;
      }
      goto LABEL_123;
    }
LABEL_122:
    v41 *= 2;
LABEL_123:
    llvm::DenseMap<mlir::Block *,llvm::SMLoc,llvm::DenseMapInfo<mlir::Block *,void>,llvm::detail::DenseMapPair<mlir::Block *,llvm::SMLoc>>::grow(a1 + 472, v41);
    uint64_t v86 = *(void *)(a1 + 472);
    BOOL v67 = v94;
    int v87 = *(_DWORD *)(a1 + 488) - 1;
    unsigned int v88 = ((v94 >> 4) ^ (v94 >> 9)) & v87;
    int32x2_t v84 = (void *)(v86 + 16 * v88);
    int v89 = (void *)*v84;
    if (v94 == (void *)*v84) {
      goto LABEL_83;
    }
    int v90 = 0;
    int v91 = 1;
    while (v89 != (void *)-4096)
    {
      if (v90) {
        BOOL v92 = 0;
      }
      else {
        BOOL v92 = v89 == (void *)-8192;
      }
      if (v92) {
        int v90 = v84;
      }
      unsigned int v93 = v88 + v91++;
      unsigned int v88 = v93 & v87;
      int32x2_t v84 = (void *)(v86 + 16 * (v93 & v87));
      int v89 = (void *)*v84;
      if (v94 == (void *)*v84) {
        goto LABEL_83;
      }
    }
    if (v90) {
      int32x2_t v84 = v90;
    }
LABEL_82:
    BOOL v67 = (void *)*v84;
LABEL_83:
    ++*(_DWORD *)(a1 + 480);
    if (v67 != (void *)-4096) {
      --*(_DWORD *)(a1 + 484);
    }
    *int32x2_t v84 = v94;
    v84[1] = *v40;
  }
LABEL_90:
  BOOL v19 = 1;
LABEL_91:
  if (v37) {
    llvm::sys::RWMutexImpl::unlock_shared(v5);
  }
  return v19;
}

mlir::Block *mlir::detail::ConversionPatternRewriterImpl::convertBlockSignature(uint64_t a1, mlir::Block *this, uint64_t a3, uint64_t a4)
{
  unint64_t v4 = (mlir::TypeConverter *)a3;
  uint64_t v38 = *MEMORY[0x263EF8340];
  uint64_t v7 = a1 + 72;
  if (!a4)
  {
    uint64_t v14 = *(void *)(a1 + 72);
    uint64_t v15 = *(unsigned int *)(a1 + 88);
    if (v15)
    {
      LODWORD(v16) = (v15 - 1) & ((this >> 4) ^ (this >> 9));
      unint64_t v17 = (mlir::Block **)(v14 + 16 * v16);
      int v18 = *v17;
      if (*v17 == this) {
        goto LABEL_14;
      }
      int v19 = 1;
      while (v18 != (mlir::Block *)-4096)
      {
        int v20 = v16 + v19++;
        uint64_t v16 = v20 & (v15 - 1);
        int v18 = *(mlir::Block **)(v14 + 16 * v16);
        if (v18 == this)
        {
          unint64_t v17 = (mlir::Block **)(v14 + 16 * v16);
          goto LABEL_14;
        }
      }
    }
    unint64_t v17 = (mlir::Block **)(v14 + 16 * v15);
LABEL_14:
    if (v17 == (mlir::Block **)(v14 + 16 * v15))
    {
      int v21 = *(_DWORD *)(a1 + 128);
      if (v21)
      {
        uint64_t v22 = *(void *)(a1 + 112);
        int v23 = v21 - 1;
        unsigned int v24 = v23 & ((this >> 4) ^ (this >> 9));
        int v25 = *(mlir::Block **)(v22 + 8 * v24);
        if (v25 == this) {
          return this;
        }
        int v30 = 1;
        while (v25 != (mlir::Block *)-4096)
        {
          unsigned int v31 = v24 + v30++;
          unsigned int v24 = v31 & v23;
          int v25 = *(mlir::Block **)(v22 + 8 * v24);
          if (v25 == this) {
            return this;
          }
        }
      }
      if (mlir::Block::getParent(this))
      {
        if (!v4) {
          return v4;
        }
        mlir::TypeConverter::convertBlockSignature(v4, this, (uint64_t)v33);
        if (!v37) {
          return 0;
        }
        if (v37)
        {
          if (v35 != &v36) {
            free(v35);
          }
          if (v33[0] != v34) {
            free(v33[0]);
          }
        }
        goto LABEL_3;
      }
    }
    return this;
  }
LABEL_3:
  if (v4 && v4 != this)
  {
    LODWORD(v33[0]) = 5;
    v33[1] = v4;
    memset(v34, 0, sizeof(v34));
    uint64_t v8 = *(unsigned int *)(a1 + 424);
    unint64_t v9 = *(void *)(a1 + 416);
    uint64_t v10 = v33;
    if (v8 >= *(_DWORD *)(a1 + 428))
    {
      uint64_t v27 = a1 + 416;
      unint64_t v28 = v8 + 1;
      BOOL v29 = v9 + 40 * v8 > (unint64_t)v33;
      if (v9 <= (unint64_t)v33 && v29)
      {
        uint64_t v32 = (char *)v33 - v9;
        llvm::SmallVectorBase<unsigned int>::grow_pod(v27, (void *)(a1 + 432), v28, 40);
        unint64_t v9 = *(void *)(a1 + 416);
        uint64_t v10 = (void **)&v32[v9];
      }
      else
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod(v27, (void *)(a1 + 432), v28, 40);
        unint64_t v9 = *(void *)(a1 + 416);
        uint64_t v10 = v33;
      }
    }
    uint64_t v11 = v9 + 40 * *(unsigned int *)(a1 + 424);
    long long v12 = *(_OWORD *)v10;
    long long v13 = *((_OWORD *)v10 + 1);
    *(void *)(v11 + 32) = v10[4];
    *(_OWORD *)uint64_t v11 = v12;
    *(_OWORD *)(v11 + 16) = v13;
    ++*(_DWORD *)(a1 + 424);
  }
  return v4;
}

uint64_t anonymous namespace'::ArgConverter::applySignatureConversion(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  if (((*(void *)(a2 + 56) - *(void *)(a2 + 48)) >> 3) | *(_DWORD *)(a4 + 152)) {
    mlir::Block::splitBlock();
  }
  return a2;
}

mlir::Block *mlir::detail::ConversionPatternRewriterImpl::convertRegionTypes(uint64_t a1, void *a2, uint64_t a3, uint64_t a4)
{
  uint64_t v8 = a1 + 72;
  if ((void *)*a2 == a2) {
    return 0;
  }
  if ((void *)*a2 != a2)
  {
    unint64_t v9 = *(void **)(a2[1] + 8);
    while (v9 != a2)
    {
      uint64_t v10 = (void *)v9[1];
      if (v9) {
        uint64_t v11 = (mlir::Block *)(v9 - 1);
      }
      else {
        uint64_t v11 = 0;
      }
      mlir::detail::ConversionPatternRewriterImpl::convertBlockSignature(a1, v11, a3, 0);
      unint64_t v9 = v10;
      if (!v12) {
        return 0;
      }
    }
  }
  uint64_t v13 = a2[1];
  if (v13) {
    uint64_t v14 = (mlir::Block *)(v13 - 8);
  }
  else {
    uint64_t v14 = 0;
  }
  return mlir::detail::ConversionPatternRewriterImpl::convertBlockSignature(a1, v14, a3, a4);
}

void *anonymous namespace'::ArgConverter::setConverter(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v8 = *(void *)(a1 + 88);
  BOOL result = (void *)(a1 + 88);
  uint64_t v7 = v8;
  unsigned int v9 = *((_DWORD *)result + 4);
  if (!v9) {
    goto LABEL_21;
  }
  unsigned int v10 = v9 - 1;
  unsigned int v11 = (v9 - 1) & ((a2 >> 4) ^ (a2 >> 9));
  char v12 = (void *)(v7 + 16 * v11);
  uint64_t v13 = *v12;
  if (*v12 == a2)
  {
LABEL_3:
    v12[1] = a3;
    return result;
  }
  uint64_t v15 = 0;
  int v16 = 1;
  while (v13 != -4096)
  {
    if (v15) {
      BOOL v17 = 0;
    }
    else {
      BOOL v17 = v13 == -8192;
    }
    if (v17) {
      uint64_t v15 = v12;
    }
    unsigned int v18 = v11 + v16++;
    unsigned int v11 = v18 & v10;
    char v12 = (void *)(v7 + 16 * (v18 & v10));
    uint64_t v13 = *v12;
    if (*v12 == a2) {
      goto LABEL_3;
    }
  }
  if (v15) {
    char v12 = v15;
  }
  int v19 = *(_DWORD *)(a1 + 96);
  if (4 * v19 + 4 < 3 * v9)
  {
    if (v9 + ~v19 - *(_DWORD *)(a1 + 100) > v9 >> 3) {
      goto LABEL_6;
    }
  }
  else
  {
LABEL_21:
    v9 *= 2;
  }
  BOOL result = llvm::DenseMap<mlir::Block *,llvm::SMLoc,llvm::DenseMapInfo<mlir::Block *,void>,llvm::detail::DenseMapPair<mlir::Block *,llvm::SMLoc>>::grow((uint64_t)result, v9);
  uint64_t v20 = *(void *)(a1 + 88);
  int v21 = *(_DWORD *)(a1 + 104) - 1;
  unsigned int v22 = v21 & ((a2 >> 4) ^ (a2 >> 9));
  char v12 = (void *)(v20 + 16 * v22);
  uint64_t v23 = *v12;
  if (*v12 == a2)
  {
LABEL_23:
    ++*(_DWORD *)(a1 + 96);
    if (a2 == -4096) {
      goto LABEL_8;
    }
    goto LABEL_7;
  }
  unsigned int v24 = 0;
  int v25 = 1;
  while (v23 != -4096)
  {
    if (v24) {
      BOOL v26 = 0;
    }
    else {
      BOOL v26 = v23 == -8192;
    }
    if (v26) {
      unsigned int v24 = v12;
    }
    unsigned int v27 = v22 + v25++;
    unsigned int v22 = v27 & v21;
    char v12 = (void *)(v20 + 16 * (v27 & v21));
    uint64_t v23 = *v12;
    if (*v12 == a2) {
      goto LABEL_23;
    }
  }
  if (v24) {
    char v12 = v24;
  }
LABEL_6:
  uint64_t v14 = *v12;
  ++*(_DWORD *)(a1 + 96);
  if (v14 != -4096) {
LABEL_7:
  }
    --*(_DWORD *)(a1 + 100);
LABEL_8:
  *char v12 = a2;
  v12[1] = 0;
  v12[1] = a3;
  return result;
}

void mlir::detail::ConversionPatternRewriterImpl::notifyOpReplaced(uint64_t a1, unsigned int *a2, uint64_t a3, uint64_t a4)
{
  uint64_t v53 = *MEMORY[0x263EF8340];
  uint64_t v6 = a2[9];
  uint64_t v49 = a3;
  uint64_t v50 = 0;
  if (v6) {
    uint64_t v7 = (uint64_t)(a2 - 4);
  }
  else {
    uint64_t v7 = 0;
  }
  uint64_t v51 = v7;
  uint64_t v52 = 0;
  if (a4)
  {
    uint64_t v10 = 0;
    uint64_t v11 = 0;
    char v12 = 0;
    do
    {
      if (v51 == v7 && v11 == v6) {
        break;
      }
      uint64_t v15 = mlir::ValueRange::dereference_iterator(&v49, v10);
      uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v51, v52);
      if (v15)
      {
        uint64_t v17 = NextResultAtOffset;
        uint64_t v47 = NextResultAtOffset;
        BOOL v48 = 0;
        char v18 = llvm::DenseMapBase<llvm::DenseMap<mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>,mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>::LookupBucketFor<mlir::Value>((uint64_t *)a1, (unint64_t *)&v47, &v48);
        int v19 = v48;
        if ((v18 & 1) == 0)
        {
          int v19 = llvm::DenseMapBase<llvm::DenseMap<mlir::Value,mlir::Value,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,mlir::Value>>,mlir::Value,mlir::Value,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,mlir::Value>>::InsertIntoBucketImpl<mlir::Value>(a1, (uint64_t)&v47, (unint64_t *)&v47, v48);
          *int v19 = v47;
          v19[1] = 0;
        }
        v19[1] = v15;
        v12 |= (*(void *)(v15 + 8) & 0xFFFFFFFFFFFFFFF8) != (*(void *)(v17 + 8) & 0xFFFFFFFFFFFFFFF8);
      }
      else
      {
        char v12 = 1;
      }
      uint64_t v10 = v50 + 1;
      uint64_t v11 = v52 + 1;
      ++v50;
      ++v52;
    }
    while (v49 != a3 || v10 != a4);
    if (v12)
    {
      int v20 = *(_DWORD *)(a1 + 360);
      uint64_t v21 = *(unsigned int *)(a1 + 1200);
      if (v21 >= *(_DWORD *)(a1 + 1204))
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod(a1 + 1192, (void *)(a1 + 1208), v21 + 1, 4);
        LODWORD(v21) = *(_DWORD *)(a1 + 1200);
      }
      *(_DWORD *)(*(void *)(a1 + 1192) + 4 * v21) = v20;
      ++*(_DWORD *)(a1 + 1200);
    }
  }
  unsigned int v22 = *(unsigned int **)(a1 + 1224);
  unsigned int v23 = *(_DWORD *)(a1 + 344);
  if (!v23) {
    goto LABEL_48;
  }
  uint64_t v24 = *(void *)(a1 + 328);
  unsigned int v25 = (v23 - 1) & ((a2 >> 4) ^ (a2 >> 9));
  BOOL v26 = (unsigned int **)(v24 + 16 * v25);
  unsigned int v27 = *v26;
  if (*v26 == a2) {
    goto LABEL_41;
  }
  unint64_t v28 = 0;
  int v29 = 1;
  while (v27 != (unsigned int *)-4096)
  {
    if (v28) {
      BOOL v30 = 0;
    }
    else {
      BOOL v30 = v27 == (unsigned int *)-8192;
    }
    if (v30) {
      unint64_t v28 = v26;
    }
    unsigned int v31 = v25 + v29++;
    unsigned int v25 = v31 & (v23 - 1);
    BOOL v26 = (unsigned int **)(v24 + 16 * v25);
    unsigned int v27 = *v26;
    if (*v26 == a2) {
      goto LABEL_41;
    }
  }
  uint64_t v36 = v28 ? v28 : v26;
  int v37 = *(_DWORD *)(a1 + 336);
  if (4 * v37 + 4 < 3 * v23)
  {
    if (v23 + ~v37 - *(_DWORD *)(a1 + 340) > v23 >> 3) {
      goto LABEL_36;
    }
  }
  else
  {
LABEL_48:
    v23 *= 2;
  }
  llvm::DenseMap<void const*,unsigned int,llvm::DenseMapInfo<void const*,void>,llvm::detail::DenseMapPair<void const*,unsigned int>>::grow(a1 + 328, v23);
  uint64_t v38 = *(void *)(a1 + 328);
  int v39 = *(_DWORD *)(a1 + 344) - 1;
  unsigned int v40 = v39 & ((a2 >> 4) ^ (a2 >> 9));
  uint64_t v36 = (unsigned int **)(v38 + 16 * v40);
  unsigned int v41 = *v36;
  if (*v36 == a2)
  {
LABEL_50:
    ++*(_DWORD *)(a1 + 336);
    if (a2 == (unsigned int *)-4096) {
      goto LABEL_38;
    }
    goto LABEL_37;
  }
  unsigned int v43 = 0;
  int v44 = 1;
  while (v41 != (unsigned int *)-4096)
  {
    if (v43) {
      BOOL v45 = 0;
    }
    else {
      BOOL v45 = v41 == (unsigned int *)-8192;
    }
    if (v45) {
      unsigned int v43 = v36;
    }
    unsigned int v46 = v40 + v44++;
    unsigned int v40 = v46 & v39;
    uint64_t v36 = (unsigned int **)(v38 + 16 * (v46 & v39));
    unsigned int v41 = *v36;
    if (*v36 == a2) {
      goto LABEL_50;
    }
  }
  if (v43) {
    uint64_t v36 = v43;
  }
LABEL_36:
  uint64_t v32 = *v36;
  ++*(_DWORD *)(a1 + 336);
  if (v32 != (unsigned int *)-4096) {
LABEL_37:
  }
    --*(_DWORD *)(a1 + 340);
LABEL_38:
  *uint64_t v36 = a2;
  *((_DWORD *)v36 + 2) = 0;
  uint64_t v33 = (void *)(a1 + 352);
  uint64_t v34 = *(unsigned int *)(a1 + 360);
  *((_DWORD *)v36 + 2) = v34;
  if (v34 >= *(_DWORD *)(a1 + 364))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)v33, (void *)(a1 + 368), v34 + 1, 16);
    uint64_t v42 = (unsigned int **)(*(void *)(a1 + 352) + 16 * *(unsigned int *)(a1 + 360));
    *uint64_t v42 = a2;
    v42[1] = v22;
    LODWORD(v34) = *(_DWORD *)(a1 + 360);
  }
  else
  {
    char v35 = (unsigned int **)(*v33 + 16 * v34);
    *char v35 = a2;
    v35[1] = v22;
  }
  *(_DWORD *)(a1 + 360) = v34 + 1;
LABEL_41:
  if ((a2[11] & 0x7FFFFF) != 0)
  {
    uint64_t v49 = a1;
    mlir::detail::walk<mlir::ForwardIterator>((mlir::ForwardIterator *)a2, (mlir::Operation *)llvm::function_ref<void ()(mlir::Operation *)>::callback_fn<mlir::detail::ConversionPatternRewriterImpl::markNestedOpsIgnored(mlir::Operation *)::$_0>, (uint64_t)&v49, 1);
  }
}

__n128 mlir::detail::ConversionPatternRewriterImpl::notifyBlockIsBeingErased(mlir::detail::ConversionPatternRewriterImpl *this, mlir::Block *a2)
{
  unint64_t Parent = mlir::Block::getParent(a2);
  uint64_t v5 = *(void *)(mlir::Block::getParent(a2) + 8);
  uint64_t v6 = *((void *)a2 + 1);
  if (v6) {
    BOOL v7 = v5 == (void)a2 + 8;
  }
  else {
    BOOL v7 = 1;
  }
  if (v7) {
    uint64_t v8 = 0;
  }
  else {
    uint64_t v8 = v6 - 8;
  }
  int v19 = 1;
  int v20 = a2;
  unint64_t v21 = Parent;
  uint64_t v22 = v8;
  uint64_t v9 = *((unsigned int *)this + 106);
  unint64_t v10 = *((void *)this + 52);
  uint64_t v11 = &v19;
  if (v9 >= *((_DWORD *)this + 107))
  {
    uint64_t v15 = (char *)this + 416;
    unint64_t v16 = v9 + 1;
    BOOL v17 = v10 + 40 * v9 > (unint64_t)&v19;
    if (v10 <= (unint64_t)&v19 && v17)
    {
      char v18 = (char *)&v19 - v10;
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)v15, (char *)this + 432, v16, 40);
      unint64_t v10 = *((void *)this + 52);
      uint64_t v11 = (int *)&v18[v10];
    }
    else
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)v15, (char *)this + 432, v16, 40);
      unint64_t v10 = *((void *)this + 52);
      uint64_t v11 = &v19;
    }
  }
  uint64_t v12 = v10 + 40 * *((unsigned int *)this + 106);
  __n128 result = *(__n128 *)v11;
  long long v14 = *((_OWORD *)v11 + 1);
  *(void *)(v12 + 32) = *((void *)v11 + 4);
  *(__n128 *)uint64_t v12 = result;
  *(_OWORD *)(v12 + 16) = v14;
  ++*((_DWORD *)this + 106);
  return result;
}

__n128 mlir::detail::ConversionPatternRewriterImpl::notifyBlockBeingInlined(uint64_t a1, uint64_t a2, uint64_t a3)
{
  v20[1] = a2;
  uint64_t v5 = (ZinIrHalH13g *)(a3 + 32);
  if (*(void *)(a3 + 32) == a3 + 32)
  {
    uint64_t v7 = 0;
  }
  else
  {
    ZinIrHalH13g::~ZinIrHalH13g(*(ZinIrHalH13g **)(a3 + 40));
    uint64_t v7 = v6;
    uint64_t v8 = *(ZinIrHalH13g **)(a3 + 32);
    if (v8 != v5)
    {
      ZinIrHalH13g::~ZinIrHalH13g(v8);
      goto LABEL_6;
    }
  }
  uint64_t v9 = 0;
LABEL_6:
  v20[0] = 2;
  void v20[2] = a3;
  void v20[3] = v7;
  v20[4] = v9;
  uint64_t v10 = *(unsigned int *)(a1 + 424);
  unint64_t v11 = *(void *)(a1 + 416);
  uint64_t v12 = (char *)v20;
  if (v10 >= *(_DWORD *)(a1 + 428))
  {
    uint64_t v16 = a1 + 416;
    unint64_t v17 = v10 + 1;
    BOOL v18 = v11 + 40 * v10 > (unint64_t)v20;
    if (v11 <= (unint64_t)v20 && v18)
    {
      int v19 = (char *)v20 - v11;
      llvm::SmallVectorBase<unsigned int>::grow_pod(v16, (void *)(a1 + 432), v17, 40);
      unint64_t v11 = *(void *)(a1 + 416);
      uint64_t v12 = &v19[v11];
    }
    else
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod(v16, (void *)(a1 + 432), v17, 40);
      unint64_t v11 = *(void *)(a1 + 416);
      uint64_t v12 = (char *)v20;
    }
  }
  uint64_t v13 = v11 + 40 * *(unsigned int *)(a1 + 424);
  __n128 result = *(__n128 *)v12;
  long long v15 = *((_OWORD *)v12 + 1);
  *(void *)(v13 + 32) = *((void *)v12 + 4);
  *(__n128 *)uint64_t v13 = result;
  *(_OWORD *)(v13 + 16) = v15;
  ++*(_DWORD *)(a1 + 424);
  return result;
}

__n128 mlir::detail::ConversionPatternRewriterImpl::notifyRegionIsBeingInlinedBefore(uint64_t a1, void **a2)
{
  uint64_t v2 = *a2;
  if (*a2 != a2)
  {
    BOOL v5 = v2 == 0;
    uint64_t v8 = (void *)*v2;
    uint64_t v6 = v2 - 1;
    uint64_t v7 = v8;
    if (v5) {
      uint64_t v9 = 0;
    }
    else {
      uint64_t v9 = v6;
    }
    if (v7 != a2)
    {
      uint64_t v10 = (unint64_t *)(a1 + 416);
      unsigned int v11 = *(_DWORD *)(a1 + 424);
      while (1)
      {
        uint64_t v12 = v9;
        if (v7) {
          uint64_t v9 = v7 - 1;
        }
        else {
          uint64_t v9 = 0;
        }
        int v30 = 3;
        unsigned int v31 = v12;
        uint64_t v32 = a2;
        uint64_t v33 = v9;
        unint64_t v13 = *(void *)(a1 + 416);
        if (v11 >= *(_DWORD *)(a1 + 428))
        {
          unint64_t v18 = v11 + 1;
          BOOL v19 = v13 + 40 * v11 > (unint64_t)&v30;
          if (v13 <= (unint64_t)&v30 && v19)
          {
            int v20 = (char *)&v30 - v13;
            llvm::SmallVectorBase<unsigned int>::grow_pod(a1 + 416, (void *)(a1 + 432), v18, 40);
            unint64_t v13 = *v10;
            long long v14 = (int *)&v20[*v10];
            goto LABEL_12;
          }
          llvm::SmallVectorBase<unsigned int>::grow_pod(a1 + 416, (void *)(a1 + 432), v18, 40);
          unint64_t v13 = *v10;
        }
        long long v14 = &v30;
LABEL_12:
        uint64_t v15 = v13 + 40 * *(unsigned int *)(a1 + 424);
        long long v16 = *(_OWORD *)v14;
        long long v17 = *((_OWORD *)v14 + 1);
        *(void *)(v15 + 32) = *((void *)v14 + 4);
        *(_OWORD *)uint64_t v15 = v16;
        *(_OWORD *)(v15 + 16) = v17;
        unsigned int v11 = *(_DWORD *)(a1 + 424) + 1;
        *(_DWORD *)(a1 + 424) = v11;
        uint64_t v7 = (void *)*v7;
        if (v7 == a2) {
          goto LABEL_19;
        }
      }
    }
    unsigned int v11 = *(_DWORD *)(a1 + 424);
LABEL_19:
    int v30 = 3;
    unsigned int v31 = v9;
    uint64_t v32 = a2;
    uint64_t v33 = 0;
    unint64_t v21 = *(void *)(a1 + 416);
    uint64_t v22 = &v30;
    if (v11 >= *(_DWORD *)(a1 + 428))
    {
      uint64_t v26 = a1 + 416;
      unint64_t v27 = v11 + 1;
      BOOL v28 = v21 + 40 * v11 > (unint64_t)&v30;
      if (v21 <= (unint64_t)&v30 && v28)
      {
        int v29 = (char *)&v30 - v21;
        llvm::SmallVectorBase<unsigned int>::grow_pod(v26, (void *)(a1 + 432), v27, 40);
        unint64_t v21 = *(void *)(a1 + 416);
        uint64_t v22 = (int *)&v29[v21];
      }
      else
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod(v26, (void *)(a1 + 432), v27, 40);
        unint64_t v21 = *(void *)(a1 + 416);
        uint64_t v22 = &v30;
      }
    }
    uint64_t v23 = v21 + 40 * *(unsigned int *)(a1 + 424);
    __n128 result = *(__n128 *)v22;
    long long v25 = *((_OWORD *)v22 + 1);
    *(void *)(v23 + 32) = *((void *)v22 + 4);
    *(__n128 *)uint64_t v23 = result;
    *(_OWORD *)(v23 + 16) = v25;
    ++*(_DWORD *)(a1 + 424);
  }
  return result;
}

void mlir::ConversionPatternRewriter::~ConversionPatternRewriter(mlir::ConversionPatternRewriter *this)
{
  uint64_t v2 = (mlir::detail::ConversionPatternRewriterImpl *)*((void *)this + 7);
  *((void *)this + 7) = 0;
  if (v2) {
    mlir::detail::ConversionPatternRewriterImpl::~ConversionPatternRewriterImpl(v2);
  }

  ZinIrHalH13g::~ZinIrHalH13g(this);
}

{
  mlir::detail::ConversionPatternRewriterImpl *v2;
  uint64_t vars8;

  uint64_t v2 = (mlir::detail::ConversionPatternRewriterImpl *)*((void *)this + 7);
  *((void *)this + 7) = 0;
  if (v2) {
    mlir::detail::ConversionPatternRewriterImpl::~ConversionPatternRewriterImpl(v2);
  }
  ZinIrHalH13g::~ZinIrHalH13g(this);

  JUMPOUT(0x21667D3C0);
}

void non-virtual thunk to'mlir::ConversionPatternRewriter::~ConversionPatternRewriter(mlir::ConversionPatternRewriter *this)
{
  uint64_t v2 = (mlir::detail::ConversionPatternRewriterImpl *)*((void *)this + 2);
  *((void *)this + 2) = 0;
  if (v2) {
    mlir::detail::ConversionPatternRewriterImpl::~ConversionPatternRewriterImpl(v2);
  }

  ZinIrHalH13g::~ZinIrHalH13g((mlir::ConversionPatternRewriter *)((char *)this - 40));
}

{
  mlir::detail::ConversionPatternRewriterImpl *v2;
  uint64_t vars8;

  uint64_t v2 = (mlir::detail::ConversionPatternRewriterImpl *)*((void *)this + 2);
  *((void *)this + 2) = 0;
  if (v2) {
    mlir::detail::ConversionPatternRewriterImpl::~ConversionPatternRewriterImpl(v2);
  }
  ZinIrHalH13g::~ZinIrHalH13g((mlir::ConversionPatternRewriter *)((char *)this - 40));

  JUMPOUT(0x21667D3C0);
}

void mlir::ConversionPatternRewriter::replaceOp(mlir::ConversionPatternRewriter *this, mlir::Operation *a2, mlir::Operation *a3)
{
  v6[2] = *MEMORY[0x263EF8340];
  if (*((_DWORD *)a3 + 9)) {
    BOOL v5 = (char *)a3 - 16;
  }
  else {
    BOOL v5 = 0;
  }
  mlir::ValueRange::ValueRange(v6, (uint64_t)v5, *((unsigned int *)a3 + 9));
  mlir::detail::ConversionPatternRewriterImpl::notifyOpReplaced(*((void *)this + 7), (unsigned int *)a2, v6[0], v6[1]);
}

void mlir::ConversionPatternRewriter::replaceOp(uint64_t a1, unsigned int *a2, uint64_t a3, uint64_t a4)
{
}

void mlir::ConversionPatternRewriter::eraseOp(mlir::ConversionPatternRewriter *this, mlir::Operation *a2)
{
  v11[1] = *MEMORY[0x263EF8340];
  unint64_t v4 = *((unsigned int *)a2 + 9);
  uint64_t v8 = v11;
  int v10 = 1;
  if (v4 < 2)
  {
    if (v4 == 1) {
      v11[0] = 0;
    }
    BOOL v5 = v11;
  }
  else
  {
    int v9 = 0;
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v8, v11, v4, 8);
    bzero(v8, 8 * v4);
    BOOL v5 = v8;
  }
  int v9 = v4;
  uint64_t v6 = *((void *)this + 7);
  mlir::ValueRange::ValueRange(v7, (uint64_t)v5, v4);
  mlir::detail::ConversionPatternRewriterImpl::notifyOpReplaced(v6, (unsigned int *)a2, v7[0], v7[1]);
  if (v8 != v11) {
    free(v8);
  }
}

void mlir::ConversionPatternRewriter::eraseBlock(mlir::detail::ConversionPatternRewriterImpl **this, mlir::Block *a2)
{
  mlir::detail::ConversionPatternRewriterImpl::notifyBlockIsBeingErased(this[7], a2);
  for (uint64_t i = (ZinIrHalH13g *)*((void *)a2 + 5);
        i != (mlir::Block *)((char *)a2 + 32);
        uint64_t i = (ZinIrHalH13g *)*((void *)i + 1))
  {
    ZinIrHalH13g::~ZinIrHalH13g(i);
    mlir::ConversionPatternRewriter::eraseOp((mlir::ConversionPatternRewriter *)this, v5);
  }
  uint64_t v6 = (char *)a2 + 8;
  if (!a2) {
    uint64_t v6 = 0;
  }
  uint64_t v7 = v6 - 8;
  if (a2) {
    uint64_t v8 = (uint64_t)v7;
  }
  else {
    uint64_t v8 = 0;
  }
  unint64_t Parent = mlir::Block::getParent(a2);
  llvm::ilist_traits<mlir::Block>::removeNodeFromList(Parent, v8);
  uint64_t v10 = *(void *)(v8 + 8);
  unsigned int v11 = *(void **)(v8 + 16);
  *unsigned int v11 = v10;
  *(void *)(v10 + 8) = v11;
  *(void *)(v8 + 8) = 0;
  *(void *)(v8 + 16) = 0;
}

uint64_t mlir::ConversionPatternRewriter::replaceUsesOfBlockArgument(uint64_t a1, unint64_t a2, uint64_t a3)
{
  uint64_t v6 = *(void *)(a1 + 56);
  uint64_t v7 = *(unsigned int *)(v6 + 376);
  if (v7 >= *(_DWORD *)(v6 + 380))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod(v6 + 368, (void *)(v6 + 384), v7 + 1, 8);
    LODWORD(v7) = *(_DWORD *)(v6 + 376);
  }
  *(void *)(*(void *)(v6 + 368) + 8 * v7) = a2;
  ++*(_DWORD *)(v6 + 376);
  uint64_t v8 = *(void *)(a1 + 56);
  do
  {
    unint64_t v9 = a2;
    unint64_t v12 = a2;
    unint64_t v13 = 0;
    if (!llvm::DenseMapBase<llvm::DenseMap<mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>,mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>::LookupBucketFor<mlir::Value>((uint64_t *)v8, &v12, &v13))break; {
    if (v13 == (void *)(*(void *)v8 + 16 * *(unsigned int *)(v8 + 16)))
    }
      break;
    a2 = v13[1];
  }
  while (a2);
  unint64_t v12 = v9;
  unint64_t v13 = 0;
  uint64_t result = llvm::DenseMapBase<llvm::DenseMap<mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>,mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>::LookupBucketFor<mlir::Value>((uint64_t *)v8, &v12, &v13);
  unsigned int v11 = v13;
  if ((result & 1) == 0)
  {
    uint64_t result = (uint64_t)llvm::DenseMapBase<llvm::DenseMap<mlir::Value,mlir::Value,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,mlir::Value>>,mlir::Value,mlir::Value,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,mlir::Value>>::InsertIntoBucketImpl<mlir::Value>(v8, (uint64_t)&v12, &v12, v13);
    unsigned int v11 = (void *)result;
    *(void *)uint64_t result = v12;
    *(void *)(result + 8) = 0;
  }
  v11[1] = a3;
  return result;
}

__n128 mlir::ConversionPatternRewriter::notifyBlockCreated(mlir::ConversionPatternRewriter *this, mlir::Block *a2)
{
  uint64_t v2 = *((void *)this + 7);
  int v13 = 0;
  long long v14 = a2;
  uint64_t v15 = 0;
  uint64_t v16 = 0;
  uint64_t v17 = 0;
  uint64_t v3 = *(unsigned int *)(v2 + 424);
  unint64_t v4 = *(void *)(v2 + 416);
  BOOL v5 = (char *)&v13;
  if (v3 >= *(_DWORD *)(v2 + 428))
  {
    uint64_t v9 = v2 + 416;
    unint64_t v10 = v3 + 1;
    BOOL v11 = v4 + 40 * v3 > (unint64_t)&v13;
    if (v4 <= (unint64_t)&v13 && v11)
    {
      unint64_t v12 = (char *)&v13 - v4;
      llvm::SmallVectorBase<unsigned int>::grow_pod(v9, (void *)(v2 + 432), v10, 40);
      unint64_t v4 = *(void *)(v2 + 416);
      BOOL v5 = &v12[v4];
    }
    else
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod(v9, (void *)(v2 + 432), v10, 40);
      unint64_t v4 = *(void *)(v2 + 416);
      BOOL v5 = (char *)&v13;
    }
  }
  uint64_t v6 = v4 + 40 * *(unsigned int *)(v2 + 424);
  __n128 result = *(__n128 *)v5;
  long long v8 = *((_OWORD *)v5 + 1);
  *(void *)(v6 + 32) = *((void *)v5 + 4);
  *(__n128 *)uint64_t v6 = result;
  *(_OWORD *)(v6 + 16) = v8;
  ++*(_DWORD *)(v2 + 424);
  return result;
}

__n128 non-virtual thunk to'mlir::ConversionPatternRewriter::notifyBlockCreated(mlir::ConversionPatternRewriter *this, mlir::Block *a2)
{
  uint64_t v2 = *((void *)this + 2);
  int v13 = 0;
  long long v14 = a2;
  uint64_t v15 = 0;
  uint64_t v16 = 0;
  uint64_t v17 = 0;
  uint64_t v3 = *(unsigned int *)(v2 + 424);
  unint64_t v4 = *(void *)(v2 + 416);
  BOOL v5 = (char *)&v13;
  if (v3 >= *(_DWORD *)(v2 + 428))
  {
    uint64_t v9 = v2 + 416;
    unint64_t v10 = v3 + 1;
    BOOL v11 = v4 + 40 * v3 > (unint64_t)&v13;
    if (v4 <= (unint64_t)&v13 && v11)
    {
      unint64_t v12 = (char *)&v13 - v4;
      llvm::SmallVectorBase<unsigned int>::grow_pod(v9, (void *)(v2 + 432), v10, 40);
      unint64_t v4 = *(void *)(v2 + 416);
      BOOL v5 = &v12[v4];
    }
    else
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod(v9, (void *)(v2 + 432), v10, 40);
      unint64_t v4 = *(void *)(v2 + 416);
      BOOL v5 = (char *)&v13;
    }
  }
  uint64_t v6 = v4 + 40 * *(unsigned int *)(v2 + 424);
  __n128 result = *(__n128 *)v5;
  long long v8 = *((_OWORD *)v5 + 1);
  *(void *)(v6 + 32) = *((void *)v5 + 4);
  *(__n128 *)uint64_t v6 = result;
  *(_OWORD *)(v6 + 16) = v8;
  ++*(_DWORD *)(v2 + 424);
  return result;
}

void mlir::ConversionPatternRewriter::splitBlock()
{
}

void mlir::ConversionPatternRewriter::inlineBlockBefore(uint64_t *a1, void *a2, uint64_t a3, ZinIrHalH13g *a4, uint64_t a5, uint64_t a6)
{
  uint64_t v34 = *MEMORY[0x263EF8340];
  mlir::detail::ConversionPatternRewriterImpl::notifyBlockBeingInlined(a1[7], a3, (uint64_t)a2);
  int v13 = (unint64_t *)a2[6];
  unint64_t v12 = (unint64_t *)a2[7];
  unsigned int v31 = v13;
  uint64_t v32 = a5;
  uint64_t v33 = 0;
  if (v12 != v13)
  {
    uint64_t v14 = 0;
    do
    {
      if (v32 == a5 && v14 == a6) {
        break;
      }
      uint64_t v16 = mlir::ValueRange::dereference_iterator(&v32, v14);
      mlir::ConversionPatternRewriter::replaceUsesOfBlockArgument((uint64_t)a1, *v13, v16);
      int v13 = v31 + 1;
      uint64_t v14 = v33 + 1;
      unsigned int v31 = v13;
      ++v33;
    }
    while (v13 != v12);
  }
  uint64_t v17 = (ZinIrHalH13g *)(a2 + 4);
  if ((void *)a2[4] != a2 + 4 && v17 != a4)
  {
    uint64_t v18 = a3 + 32;
    BOOL v19 = (ZinIrHalH13g *)a2[5];
    llvm::ilist_traits<mlir::Operation>::transferNodesFromList(v18, (uint64_t)(a2 + 4), (uint64_t)v19, (uint64_t)(a2 + 4));
    if (v19 != v17)
    {
      uint64_t v20 = *(void *)v17;
      uint64_t v21 = *(void *)v19;
      *(void *)(v21 + 8) = v17;
      *(void *)uint64_t v17 = v21;
      uint64_t v22 = *(void *)a4;
      *(void *)(v20 + 8) = a4;
      *(void *)BOOL v19 = v22;
      *(void *)(v22 + 8) = v19;
      *(void *)a4 = v20;
    }
  }
  mlir::detail::ConversionPatternRewriterImpl::notifyBlockIsBeingErased((mlir::detail::ConversionPatternRewriterImpl *)a1[7], (mlir::Block *)a2);
  for (uint64_t i = (ZinIrHalH13g *)a2[5]; i != v17; uint64_t i = (ZinIrHalH13g *)*((void *)i + 1))
  {
    ZinIrHalH13g::~ZinIrHalH13g(i);
    mlir::ConversionPatternRewriter::eraseOp((mlir::ConversionPatternRewriter *)a1, v24);
  }
  long long v25 = a2 + 1;
  if (!a2) {
    long long v25 = 0;
  }
  uint64_t v26 = (uint64_t)(v25 - 1);
  if (a2) {
    uint64_t v27 = v26;
  }
  else {
    uint64_t v27 = 0;
  }
  unint64_t Parent = mlir::Block::getParent((mlir::Block *)a2);
  llvm::ilist_traits<mlir::Block>::removeNodeFromList(Parent, v27);
  uint64_t v29 = *(void *)(v27 + 8);
  int v30 = *(void **)(v27 + 16);
  *int v30 = v29;
  *(void *)(v29 + 8) = v30;
  *(void *)(v27 + 8) = 0;
  *(void *)(v27 + 16) = 0;
}

uint64_t mlir::ConversionPatternRewriter::inlineRegionBefore(uint64_t a1, uint64_t *a2, uint64_t a3, uint64_t *a4)
{
  mlir::detail::ConversionPatternRewriterImpl::notifyRegionIsBeingInlinedBefore(*(void *)(a1 + 56), (void **)a2);

  return mlir::RewriterBase::inlineRegionBefore(a1, a2, a3, a4);
}

void mlir::ConversionPatternRewriter::cloneRegionBefore(uint64_t a1, mlir::Operation::CloneOptions *a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  if (*(mlir::Operation::CloneOptions **)a2 == a2) {
    return;
  }
  mlir::RewriterBase::cloneRegionBefore(a1, a2, a3, a4, (uint64_t *)a5);
  mlir::ForwardDominanceIterator<false>::makeIterable(a2, (uint64_t)&v58);
  llvm::SmallPtrSetImplBase::SmallPtrSetImplBase((llvm::SmallPtrSetImplBase *)&v52, &v54, (const llvm::SmallPtrSetImplBase *)&v58);
  __p = 0;
  int v56 = 0;
  uint64_t v57 = 0;
  long long v8 = v60;
  uint64_t v9 = v61 - (unsigned char *)v60;
  if (v61 != v60)
  {
    if (v9 < 0) {
      goto LABEL_58;
    }
    unint64_t v10 = (char *)operator new(v61 - (unsigned char *)v60);
    __p = v10;
    int v56 = v10;
    uint64_t v57 = &v10[32 * (v9 >> 5)];
    size_t v11 = v9 & 0xFFFFFFFFFFFFFFE0;
    memcpy(v10, v8, v11);
    int v56 = &v10[v11];
  }
  llvm::SmallPtrSetImplBase::SmallPtrSetImplBase((llvm::SmallPtrSetImplBase *)&v46, &v48, (const llvm::SmallPtrSetImplBase *)&v62);
  uint64_t v49 = 0;
  uint64_t v50 = 0;
  uint64_t v51 = 0;
  unint64_t v12 = v64;
  uint64_t v13 = v65 - (unsigned char *)v64;
  if (v65 != v64)
  {
    if ((v13 & 0x8000000000000000) == 0)
    {
      uint64_t v14 = (char *)operator new(v65 - (unsigned char *)v64);
      uint64_t v49 = v14;
      uint64_t v50 = v14;
      uint64_t v51 = &v14[32 * (v13 >> 5)];
      size_t v15 = v13 & 0xFFFFFFFFFFFFFFE0;
      memcpy(v14, v12, v15);
      uint64_t i = &v14[v15];
      uint64_t v50 = &v14[v15];
      goto LABEL_10;
    }
LABEL_58:
    abort();
  }
  uint64_t v14 = 0;
  for (uint64_t i = 0; ; uint64_t i = v50)
  {
LABEL_10:
    if (v56 - (unsigned char *)__p != i - v14) {
      goto LABEL_22;
    }
    if (__p == v56) {
      break;
    }
    uint64_t v17 = v14 + 16;
    uint64_t v18 = (char *)__p + 16;
    while (1)
    {
      BOOL v19 = v18 - 16;
      if (*((void *)v18 - 2) != *((void *)v17 - 2)) {
        break;
      }
      int v20 = v17[8];
      if (v18[8]) {
        BOOL v21 = v20 == 0;
      }
      else {
        BOOL v21 = 1;
      }
      if (v21)
      {
        if ((v18[8] != 0) != (v20 != 0)) {
          break;
        }
      }
      else if (*((void *)v18 - 1) != *((void *)v17 - 1) || *(void *)v18 != *(void *)v17)
      {
        break;
      }
      v17 += 32;
      v18 += 32;
      if (v19 + 32 == v56) {
        goto LABEL_41;
      }
    }
LABEL_22:
    uint64_t v22 = *(void *)(a5 + 24);
    uint64_t v23 = *(unsigned int *)(a5 + 40);
    if (v23)
    {
      uint64_t v24 = *((void *)v56 - 4);
      LODWORD(v25) = ((v24 >> 4) ^ (v24 >> 9)) & (v23 - 1);
      uint64_t v26 = (uint64_t *)(v22 + 16 * v25);
      uint64_t v27 = *v26;
      if (*v26 == v24) {
        goto LABEL_29;
      }
      int v28 = 1;
      while (v27 != -4096)
      {
        int v29 = v25 + v28++;
        uint64_t v25 = v29 & (v23 - 1);
        uint64_t v27 = *(void *)(v22 + 16 * v25);
        if (v27 == v24)
        {
          uint64_t v26 = (uint64_t *)(v22 + 16 * v25);
          goto LABEL_29;
        }
      }
    }
    uint64_t v26 = (uint64_t *)(v22 + 16 * v23);
LABEL_29:
    if (v26 == (uint64_t *)(v22 + 16 * v23)) {
      uint64_t v30 = 0;
    }
    else {
      uint64_t v30 = v26[1];
    }
    uint64_t v31 = *(void *)(a1 + 56);
    LODWORD(v66[0]) = 0;
    v66[1] = v30;
    memset(&v66[2], 0, 24);
    uint64_t v32 = *(unsigned int *)(v31 + 424);
    unint64_t v33 = *(void *)(v31 + 416);
    if (v32 < *(_DWORD *)(v31 + 428)) {
      goto LABEL_33;
    }
    uint64_t v42 = v31 + 416;
    unint64_t v43 = v32 + 1;
    BOOL v44 = v33 + 40 * v32 > (unint64_t)v66;
    if (v33 > (unint64_t)v66 || !v44)
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod(v42, (void *)(v31 + 432), v43, 40);
      unint64_t v33 = *(void *)(v31 + 416);
LABEL_33:
      uint64_t v34 = (char *)v66;
      goto LABEL_34;
    }
    BOOL v45 = (char *)v66 - v33;
    llvm::SmallVectorBase<unsigned int>::grow_pod(v42, (void *)(v31 + 432), v43, 40);
    unint64_t v33 = *(void *)(v31 + 416);
    uint64_t v34 = &v45[v33];
LABEL_34:
    uint64_t v35 = v33 + 40 * *(unsigned int *)(v31 + 424);
    long long v36 = *(_OWORD *)v34;
    long long v37 = *((_OWORD *)v34 + 1);
    *(void *)(v35 + 32) = *((void *)v34 + 4);
    *(_OWORD *)uint64_t v35 = v36;
    *(_OWORD *)(v35 + 16) = v37;
    ++*(_DWORD *)(v31 + 424);
    v66[0] = a1;
    uint64_t v38 = (ZinIrHalH13g *)(v30 + 32);
    int v39 = *(ZinIrHalH13g **)(v30 + 40);
    if (v39 != (ZinIrHalH13g *)(v30 + 32))
    {
      do
      {
        unsigned int v40 = (ZinIrHalH13g *)*((void *)v39 + 1);
        ZinIrHalH13g::~ZinIrHalH13g(v39);
        mlir::detail::walk<mlir::ForwardDominanceIterator<false>>(v41, (mlir::Operation *)llvm::function_ref<void ()(mlir::Operation *)>::callback_fn<mlir::ConversionPatternRewriter::cloneRegionBefore(mlir::Region &,mlir::Region &,llvm::ilist_iterator<llvm::ilist_detail::node_options<mlir::Block,false,false,void,false>,false,false>,mlir::IRMapping &)::$_0>, (uint64_t)v66, 0);
        int v39 = v40;
      }
      while (v40 != v38);
    }
    llvm::df_iterator<mlir::Block *,llvm::df_iterator_default_set<mlir::Block *,8u>,false,llvm::GraphTraits<mlir::Block *>>::toNext((uint64_t)&v52);
    uint64_t v14 = v49;
  }
LABEL_41:
  if (v14)
  {
    uint64_t v50 = v14;
    operator delete(v14);
  }
  if (v47 != v46) {
    free(v47);
  }
  if (__p)
  {
    int v56 = (char *)__p;
    operator delete(__p);
  }
  if (v53 != v52) {
    free(v53);
  }
  if (v64)
  {
    unsigned int v65 = v64;
    operator delete(v64);
  }
  if (v63 != v62) {
    free(v63);
  }
  if (v60)
  {
    uint64_t v61 = v60;
    operator delete(v60);
  }
  if (v59 != v58) {
    free(v59);
  }
}

void mlir::ForwardDominanceIterator<false>::makeIterable(void *a1@<X0>, uint64_t a2@<X8>)
{
  if ((void *)*a1 == a1)
  {
    uint64_t v18 = 0;
    BOOL v19 = 0;
    memset(v17, 0, sizeof(v17));
    uint64_t v14 = &v17[8];
    size_t v15 = &v17[8];
    uint64_t v16 = 8;
    int v20 = 0;
    uint64_t v21 = 0;
    memset(v9, 0, sizeof(v9));
    uint64_t v6 = (char *)v9 + 8;
    uint64_t v7 = (char *)v9 + 8;
    uint64_t v8 = 8;
    uint64_t v10 = 0;
    __p = 0;
    unint64_t v12 = 0;
    uint64_t v13 = 0;
    llvm::make_range<llvm::df_iterator<mlir::Block *,llvm::df_iterator_default_set<mlir::Block *,8u>,false,llvm::GraphTraits<mlir::Block *>>>((uint64_t)&v14, (uint64_t)&v6, (uint64_t)&v22);
    if (__p)
    {
      unint64_t v12 = __p;
      operator delete(__p);
    }
    if (v7 != v6) {
      free(v7);
    }
    if (v19)
    {
      int v20 = v19;
      operator delete(v19);
    }
    if (v15 != v14) {
      free(v15);
    }
  }
  else
  {
    uint64_t v3 = a1[1];
    if (v3) {
      uint64_t v4 = v3 - 8;
    }
    else {
      uint64_t v4 = 0;
    }
    uint64_t v5 = v4;
    llvm::depth_first<mlir::Block *>(&v5, (uint64_t)&v22);
  }
  llvm::make_pointee_range<llvm::iterator_range<llvm::df_iterator<mlir::Block *,llvm::df_iterator_default_set<mlir::Block *,8u>,false,llvm::GraphTraits<mlir::Block *>>> &,llvm::df_iterator<mlir::Block *,llvm::df_iterator_default_set<mlir::Block *,8u>,false,llvm::GraphTraits<mlir::Block *>>>((llvm::SmallPtrSetImplBase *)&v22, a2);
  if (v28)
  {
    int v29 = v28;
    operator delete(v28);
  }
  if (v27 != v26) {
    free(v27);
  }
  if (v24)
  {
    uint64_t v25 = v24;
    operator delete(v24);
  }
  if (v23 != v22) {
    free(v23);
  }
}

void mlir::ConversionPatternRewriter::notifyOperationInserted(mlir::ConversionPatternRewriter *this, mlir::Operation *a2)
{
  uint64_t v3 = *((void *)this + 7);
  uint64_t v4 = *(unsigned int *)(v3 + 208);
  if (v4 >= *(_DWORD *)(v3 + 212))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod(v3 + 200, (void *)(v3 + 216), v4 + 1, 8);
    LODWORD(v4) = *(_DWORD *)(v3 + 208);
  }
  *(void *)(*(void *)(v3 + 200) + 8 * v4) = a2;
  ++*(_DWORD *)(v3 + 208);
}

void non-virtual thunk to'mlir::ConversionPatternRewriter::notifyOperationInserted(mlir::ConversionPatternRewriter *this, mlir::Operation *a2)
{
  uint64_t v3 = *((void *)this + 2);
  uint64_t v4 = *(unsigned int *)(v3 + 208);
  if (v4 >= *(_DWORD *)(v3 + 212))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod(v3 + 200, (void *)(v3 + 216), v4 + 1, 8);
    LODWORD(v4) = *(_DWORD *)(v3 + 208);
  }
  *(void *)(*(void *)(v3 + 200) + 8 * v4) = a2;
  ++*(_DWORD *)(v3 + 208);
}

void mlir::ConversionPatternRewriter::startRootUpdate(mlir::ConversionPatternRewriter *this, mlir::Operation *a2)
{
  uint64_t v3 = *((void *)this + 7);
  unsigned int v4 = *(_DWORD *)(v3 + 640);
  if (v4 >= *(_DWORD *)(v3 + 644))
  {
    unint64_t v8 = 0;
    uint64_t v5 = (char *)llvm::SmallVectorBase<unsigned int>::mallocForGrow(v3 + 632, (void *)(v3 + 648), 0, 136, &v8);
    int v6 = v8;
    uint64_t v7 = *(void **)(v3 + 632);
    if (v7 != (void *)(v3 + 648)) {
      free(v7);
    }
    *(void *)(v3 + 632) = v5;
    *(_DWORD *)(v3 + 644) = v6;
  }
  else
  {
  }
  ++*(_DWORD *)(v3 + 640);
}

void mlir::ConversionPatternRewriter::cancelRootUpdate(mlir::ConversionPatternRewriter *this, mlir::Operation *a2)
{
  uint64_t v2 = *((void *)this + 7);
  uint64_t v3 = *(void *)(v2 + 632);
  uint64_t v4 = 136 * *(unsigned int *)(v2 + 640);
  while (v4)
  {
    uint64_t v5 = *(mlir::Operation **)(v3 + v4 - 136);
    v4 -= 136;
    if (v5 == a2)
    {
      v3 += v4 + 136;
      break;
    }
  }
  uint64_t v6 = *(void *)(v2 + 632);
  uint64_t v7 = v6 + 136 * (int)(-252645135 * ((unint64_t)(v3 - v6 - 136) >> 3));
  unsigned int v8 = *(_DWORD *)(v2 + 640);
  uint64_t v9 = v6 + 136 * v8;
  if (v7 + 136 != v9)
  {
    do
    {
      *(_OWORD *)uint64_t v7 = *(_OWORD *)(v7 + 136);
      *(void *)(v7 + 16) = *(void *)(v7 + 152);
      llvm::SmallVectorImpl<mlir::Value>::operator=(v7 + 24, v7 + 160);
      llvm::SmallVectorImpl<llvm::SMLoc>::operator=(v7 + 104, v7 + 240);
      uint64_t v10 = v7 + 272;
      v7 += 136;
    }
    while (v10 != v9);
    unsigned int v8 = *(_DWORD *)(v2 + 640);
    uint64_t v6 = *(void *)(v2 + 632);
  }
  unsigned int v11 = v8 - 1;
  *(_DWORD *)(v2 + 640) = v8 - 1;
  uint64_t v12 = v6 + 136 * (v8 - 1);
  uint64_t v13 = *(void **)(v12 + 104);
  if (v13 != (void *)(v12 + 120)) {
    free(v13);
  }
  uint64_t v14 = v6 + 136 * v11;
  size_t v15 = *(void **)(v14 + 24);
  if (v15 != (void *)(v14 + 40))
  {
    free(v15);
  }
}

uint64_t mlir::ConversionPatternRewriter::notifyMatchFailure()
{
  return 0;
}

uint64_t non-virtual thunk to'mlir::ConversionPatternRewriter::notifyMatchFailure()
{
  return 0;
}

uint64_t mlir::ConversionPattern::matchAndRewrite(mlir::ConversionPattern *this, mlir::Operation *a2, mlir::PatternRewriter *a3)
{
  v20[4] = *MEMORY[0x263EF8340];
  uint64_t v6 = *((void *)a3 + 7);
  uint64_t v7 = *(void *)(v6 + 1224);
  *(void *)(v6 + 1224) = *((void *)this + 12);
  uint64_t v18 = v20;
  uint64_t v19 = 0x400000000;
  uint64_t v8 = *((void *)a2 + 3);
  if ((*((unsigned char *)a2 + 46) & 0x80) != 0)
  {
    uint64_t v9 = *((void *)a2 + 9);
    unint64_t v10 = *((unsigned int *)a2 + 17);
  }
  else
  {
    uint64_t v9 = 0;
    unint64_t v10 = 0;
  }
  mlir::ValueRange::ValueRange(v17, v9, v10);
  if (!mlir::detail::ConversionPatternRewriterImpl::remapValues(v6, v11, v12, v8, 1u, v13, v17[0], v17[1], (uint64_t)&v18))
  {
    uint64_t v14 = 0;
    size_t v15 = v18;
    if (v18 == v20) {
      goto LABEL_6;
    }
    goto LABEL_5;
  }
  uint64_t v14 = (*(uint64_t (**)(mlir::ConversionPattern *, mlir::Operation *, void *, void, mlir::PatternRewriter *))(*(void *)this + 56))(this, a2, v18, v19, a3);
  size_t v15 = v18;
  if (v18 != v20) {
LABEL_5:
  }
    free(v15);
LABEL_6:
  *(void *)(v6 + 1224) = v7;
  return v14;
}

uint64_t mlir::TypeConverter::convertType(uint64_t a1, void *a2)
{
  v7[1] = *MEMORY[0x263EF8340];
  uint64_t v5 = v7;
  uint64_t v6 = 0x100000000;
  if (!mlir::TypeConverter::convertType(a1, a2, (uint64_t)&v5) || v6 != 1)
  {
    uint64_t v3 = 0;
    if (v5 == v7) {
      return v3;
    }
    goto LABEL_8;
  }
  uint64_t v3 = *(void *)v5;
  if (v5 != v7) {
LABEL_8:
  }
    free(v5);
  return v3;
}

BOOL mlir::TypeConverter::isLegal(mlir::TypeConverter *this, mlir::Operation *a2)
{
  if ((*((unsigned char *)a2 + 46) & 0x80) != 0)
  {
    uint64_t v4 = (mlir::detail::OpResultImpl *)*((void *)a2 + 9);
    uint64_t v5 = *((unsigned int *)a2 + 17);
  }
  else
  {
    uint64_t v4 = 0;
    uint64_t v5 = 0;
  }
  uint64_t v9 = v4;
  uint64_t v10 = v5;
  mlir::OperandRange::getTypes((uint64_t *)&v9, v13);
  BOOL result = _ZNSt3__16all_ofB8nn180100IN4mlir17ValueTypeIteratorIN4llvm6detail27indexed_accessor_range_baseINS1_12OperandRangeEPNS1_9OpOperandENS1_5ValueES9_S9_E8iteratorEEEZNKS1_13TypeConverter7isLegalINS1_14ValueTypeRangeIS6_EEEENS_9enable_ifIXaantsr3std14is_convertibleIT_NS1_4TypeEEE5valuentsr3std14is_convertibleISI_PNS1_9OperationEEE5valueEbE4typeEOSI_EUlSJ_E_EEbSI_SI_T0_(v13[0], v13[1], v13[2], v13[3], (uint64_t)this);
  if (result)
  {
    uint64_t v7 = *((unsigned int *)a2 + 9);
    uint64_t v8 = (char *)a2 - 16;
    if (!v7) {
      uint64_t v8 = 0;
    }
    v14[0] = (uint64_t)v8;
    v14[1] = v7;
    mlir::OperandRange::getTypes(v14, (uint64_t *)&v9);
    return _ZNSt3__16all_ofB8nn180100IN4mlir17ValueTypeIteratorIN4llvm6detail27indexed_accessor_range_baseINS1_11ResultRangeEPNS1_6detail12OpResultImplENS1_8OpResultESA_SA_E8iteratorEEEZNKS1_13TypeConverter7isLegalINS1_14ValueTypeRangeIS6_EEEENS_9enable_ifIXaantsr3std14is_convertibleIT_NS1_4TypeEEE5valuentsr3std14is_convertibleISJ_PNS1_9OperationEEE5valueEbE4typeEOSJ_EUlSK_E_EEbSJ_SJ_T0_(v9, v10, v11, v12, (uint64_t)this);
  }
  return result;
}

BOOL mlir::TypeConverter::isSignatureLegal(uint64_t a1, uint64_t a2)
{
  v23[1] = *MEMORY[0x263EF8340];
  uint64_t v20 = a2;
  uint64_t Inputs = mlir::FunctionType::getInputs((mlir::FunctionType *)&v20);
  uint64_t v5 = v4;
  uint64_t Results = mlir::FunctionType::getResults((mlir::FunctionType *)&v20);
  BOOL v8 = v5 == 0;
  BOOL v9 = v7 == 0;
  if (!(v5 | v7)) {
    return 1;
  }
  uint64_t v10 = (void **)Results;
  uint64_t v11 = Inputs + 8 * v5;
  uint64_t v12 = Results + 8 * v7;
  while (1)
  {
    if (v9) {
      uint64_t v13 = 0;
    }
    else {
      uint64_t v13 = v10;
    }
    if (Inputs != 0 && !v8) {
      uint64_t v13 = (void **)Inputs;
    }
    uint64_t v14 = *v13;
    uint64_t v21 = v23;
    uint64_t v22 = 0x100000000;
    size_t v15 = 0;
    if (mlir::TypeConverter::convertType(a1, v14, (uint64_t)&v21) && v22 == 1) {
      size_t v15 = *(void **)v21;
    }
    if (v21 != v23) {
      free(v21);
    }
    BOOL result = v15 == v14;
    if (v15 != v14) {
      break;
    }
    if (v8) {
      uint64_t v18 = (uint64_t)v10;
    }
    else {
      uint64_t v18 = Inputs;
    }
    uint64_t v19 = v18 + 8;
    if (v8) {
      uint64_t v10 = (void **)v19;
    }
    else {
      uint64_t Inputs = v19;
    }
    BOOL v9 = v10 == (void **)v12;
    BOOL v8 = Inputs == v11;
    if (Inputs == v11 && v10 == (void **)v12) {
      return 1;
    }
  }
  return result;
}

uint64_t mlir::TypeConverter::convertSignatureArg(uint64_t a1, unsigned int a2, void *a3, uint64_t a4)
{
  v18[1] = *MEMORY[0x263EF8340];
  uint64_t __src = v18;
  uint64_t v17 = 0x100000000;
  if (!mlir::TypeConverter::convertType(a1, a3, (uint64_t)&__src))
  {
    uint64_t v13 = 0;
    uint64_t v14 = __src;
    if (__src == v18) {
      return v13;
    }
    goto LABEL_8;
  }
  uint64_t v6 = v17;
  if (v17)
  {
    uint64_t v7 = __src;
    uint64_t v8 = *(void *)a4 + 32 * a2;
    int v9 = *(unsigned __int8 *)(v8 + 24);
    *(void *)uint64_t v8 = *(unsigned int *)(a4 + 152);
    *(void *)(v8 + 8) = v6;
    *(void *)(v8 + 16) = 0;
    if (v9)
    {
      size_t v10 = 8 * v6;
      uint64_t v11 = *(unsigned int *)(a4 + 152);
      unint64_t v12 = v11 + v6;
      if (v11 + v6 <= (unint64_t)*(unsigned int *)(a4 + 156))
      {
LABEL_6:
        memcpy((void *)(*(void *)(a4 + 144) + 8 * v11), v7, v10);
        *(_DWORD *)(a4 + 152) += v6;
        goto LABEL_7;
      }
    }
    else
    {
      *(unsigned char *)(v8 + 24) = 1;
      size_t v10 = 8 * v6;
      uint64_t v11 = *(unsigned int *)(a4 + 152);
      unint64_t v12 = v11 + v6;
      if (v11 + v6 <= (unint64_t)*(unsigned int *)(a4 + 156)) {
        goto LABEL_6;
      }
    }
    llvm::SmallVectorBase<unsigned int>::grow_pod(a4 + 144, (void *)(a4 + 160), v12, 8);
    uint64_t v11 = *(unsigned int *)(a4 + 152);
    goto LABEL_6;
  }
LABEL_7:
  uint64_t v13 = 1;
  uint64_t v14 = __src;
  if (__src != v18) {
LABEL_8:
  }
    free(v14);
  return v13;
}

void mlir::TypeConverter::convertBlockSignature(mlir::TypeConverter *this@<X0>, mlir::Block *a2@<X1>, uint64_t a3@<X8>)
{
  void v39[2] = *MEMORY[0x263EF8340];
  unint64_t v6 = *((void *)a2 + 7) - *((void *)a2 + 6);
  unint64_t v7 = v6 >> 3;
  uint64_t __src = v35;
  uint64_t v34 = 0x400000000;
  if ((v6 >> 3))
  {
    uint64_t v8 = (v6 >> 3);
    if (v7 < 5)
    {
      uint64_t v9 = 0;
      size_t v10 = v35;
      if (!v8)
      {
LABEL_12:
        LODWORD(v34) = v7;
        goto LABEL_13;
      }
    }
    else
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&__src, v35, (v6 >> 3), 32);
      uint64_t v9 = v34;
      size_t v10 = __src;
      if (v34 == v8) {
        goto LABEL_12;
      }
    }
    uint64_t v11 = 32 * v9;
    unint64_t v12 = &v10[32 * v9];
    unint64_t v13 = 32 * v8 - 32 - v11;
    if (!v13) {
      goto LABEL_10;
    }
    uint64_t v14 = (v13 >> 5) + 1;
    v12 += 32 * (v14 & 0xFFFFFFFFFFFFFFELL);
    size_t v15 = &v10[v11 + 32];
    uint64_t v16 = v14 & 0xFFFFFFFFFFFFFFELL;
    do
    {
      *(v15 - 32) = 0;
      *size_t v15 = 0;
      *(v15 - 8) = 0;
      v15[24] = 0;
      v15 += 64;
      v16 -= 2;
    }
    while (v16);
    if (v14 != (v14 & 0xFFFFFFFFFFFFFFELL))
    {
LABEL_10:
      uint64_t v17 = &v10[32 * v8];
      do
      {
        *unint64_t v12 = 0;
        v12[24] = 0;
        v12 += 32;
      }
      while (v12 != v17);
    }
    goto LABEL_12;
  }
LABEL_13:
  long long v36 = v38;
  uint64_t v37 = 0x400000000;
  uint64_t ArgumentTypes = mlir::Block::getArgumentTypes(a2);
  mlir::ValueRange::ValueRange(v39, ArgumentTypes, (v19 - ArgumentTypes) >> 3);
  mlir::TypeRange::TypeRange((unint64_t *)&v31, v39[0], v39[1]);
  uint64_t v20 = v32;
  if (!v32)
  {
LABEL_17:
    *(void *)a3 = a3 + 16;
    *(void *)(a3 + 8) = 0x400000000;
    int v24 = v34;
    if (v34 && &__src != (void **)a3)
    {
      if (__src == v35)
      {
        unsigned int v27 = v34;
        if (v34 < 5
          || (llvm::SmallVectorBase<unsigned int>::grow_pod(a3, (void *)(a3 + 16), v34, 32),
              (unsigned int v27 = v34) != 0))
        {
          memcpy(*(void **)a3, __src, 32 * v27);
        }
        *(_DWORD *)(a3 + 8) = v24;
      }
      else
      {
        *(void *)a3 = __src;
        int v25 = HIDWORD(v34);
        *(_DWORD *)(a3 + 8) = v24;
        *(_DWORD *)(a3 + 12) = v25;
        uint64_t __src = v35;
        HIDWORD(v34) = 0;
      }
      LODWORD(v34) = 0;
    }
    *(void *)(a3 + 144) = a3 + 160;
    *(void *)(a3 + 152) = 0x400000000;
    char v26 = 1;
    if (&__src == (void **)a3) {
      goto LABEL_38;
    }
    int v28 = v37;
    if (!v37) {
      goto LABEL_38;
    }
    if (v36 != v38)
    {
      *(void *)(a3 + 144) = v36;
      int v29 = HIDWORD(v37);
      *(_DWORD *)(a3 + 152) = v28;
      *(_DWORD *)(a3 + 156) = v29;
      long long v36 = v38;
      HIDWORD(v37) = 0;
LABEL_37:
      LODWORD(v37) = 0;
      char v26 = 1;
      goto LABEL_38;
    }
    if (v37 < 5)
    {
      uint64_t v30 = v37;
    }
    else
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod(a3 + 144, (void *)(a3 + 160), v37, 8);
      uint64_t v30 = v37;
      if (!v37) {
        goto LABEL_36;
      }
    }
    memcpy(*(void **)(a3 + 144), v36, 8 * v30);
LABEL_36:
    *(_DWORD *)(a3 + 152) = v28;
    goto LABEL_37;
  }
  uint64_t v21 = 0;
  uint64_t v22 = v31;
  while (1)
  {
    uint64_t v23 = (void *)mlir::TypeRange::dereference_iterator(v22, v21);
    if (!mlir::TypeConverter::convertSignatureArg((uint64_t)this, v21, v23, (uint64_t)&__src)) {
      break;
    }
    if (v20 == ++v21) {
      goto LABEL_17;
    }
  }
  char v26 = 0;
  *(unsigned char *)a3 = 0;
LABEL_38:
  *(unsigned char *)(a3 + 192) = v26;
  if (v36 != v38) {
    free(v36);
  }
  if (__src != v35) {
    free(__src);
  }
}

void mlir::populateFunctionOpInterfaceTypeConversionPattern()
{
}

_DWORD *mlir::ConversionTarget::setOpAction(uint64_t a1, uint64_t a2, int a3)
{
  uint64_t v5 = a2;
  BOOL result = (_DWORD *)llvm::MapVector<mlir::OperationName,mlir::ConversionTarget::LegalizationInfo,llvm::DenseMap<mlir::OperationName,unsigned int,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,unsigned int>>,llvm::SmallVector<std::pair<mlir::OperationName,mlir::ConversionTarget::LegalizationInfo>,0u>>::operator[](a1 + 8, &v5);
  *BOOL result = a3;
  return result;
}

uint64_t llvm::MapVector<mlir::OperationName,mlir::ConversionTarget::LegalizationInfo,llvm::DenseMap<mlir::OperationName,unsigned int,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,unsigned int>>,llvm::SmallVector<std::pair<mlir::OperationName,mlir::ConversionTarget::LegalizationInfo>,0u>>::operator[](uint64_t a1, uint64_t *a2)
{
  uint64_t v34 = *MEMORY[0x263EF8340];
  uint64_t v4 = *a2;
  unsigned int v5 = *(_DWORD *)(a1 + 16);
  if (!v5) {
    goto LABEL_28;
  }
  uint64_t v6 = *(void *)a1;
  uint64_t v7 = ((v4 >> 4) ^ (v4 >> 9)) & (v5 - 1);
  uint64_t v8 = (void *)(*(void *)a1 + 16 * v7);
  uint64_t v9 = *v8;
  if (*v8 == v4)
  {
LABEL_3:
    unsigned int v10 = *(_DWORD *)(v6 + 16 * v7 + 8);
    return *(void *)(a1 + 24) + 48 * v10 + 8;
  }
  uint64_t v16 = 0;
  int v17 = 1;
  while (v9 != -4096)
  {
    if (v16) {
      BOOL v18 = 0;
    }
    else {
      BOOL v18 = v9 == -8192;
    }
    if (v18) {
      uint64_t v16 = v8;
    }
    int v19 = v7 + v17++;
    uint64_t v7 = v19 & (v5 - 1);
    uint64_t v8 = (void *)(v6 + 16 * v7);
    uint64_t v9 = *v8;
    if (*v8 == v4) {
      goto LABEL_3;
    }
  }
  uint64_t v20 = (uint64_t)(v16 ? v16 : v8);
  int v21 = *(_DWORD *)(a1 + 8);
  if (4 * v21 + 4 < 3 * v5)
  {
    if (v5 + ~v21 - *(_DWORD *)(a1 + 12) > v5 >> 3) {
      goto LABEL_6;
    }
  }
  else
  {
LABEL_28:
    v5 *= 2;
  }
  llvm::DenseMap<void const*,unsigned int,llvm::DenseMapInfo<void const*,void>,llvm::detail::DenseMapPair<void const*,unsigned int>>::grow(a1, v5);
  int v22 = *(_DWORD *)(a1 + 16) - 1;
  unsigned int v23 = v22 & ((v4 >> 4) ^ (v4 >> 9));
  uint64_t v20 = *(void *)a1 + 16 * v23;
  uint64_t v24 = *(void *)v20;
  if (*(void *)v20 == v4)
  {
    uint64_t v11 = v4;
    goto LABEL_7;
  }
  uint64_t v25 = 0;
  int v26 = 1;
  while (v24 != -4096)
  {
    if (v25) {
      BOOL v27 = 0;
    }
    else {
      BOOL v27 = v24 == -8192;
    }
    if (v27) {
      uint64_t v25 = v20;
    }
    unsigned int v28 = v23 + v26++;
    unsigned int v23 = v28 & v22;
    uint64_t v20 = *(void *)a1 + 16 * v23;
    uint64_t v24 = *(void *)v20;
    uint64_t v11 = v4;
    if (*(void *)v20 == v4) {
      goto LABEL_7;
    }
  }
  if (v25) {
    uint64_t v20 = v25;
  }
LABEL_6:
  uint64_t v11 = *(void *)v20;
LABEL_7:
  ++*(_DWORD *)(a1 + 8);
  if (v11 != -4096) {
    --*(_DWORD *)(a1 + 12);
  }
  *(void *)uint64_t v20 = v4;
  *(_DWORD *)(v20 + 8) = 0;
  uint64_t v29 = *a2;
  int v30 = 2;
  char v31 = 0;
  unint64_t v33 = 0;
  llvm::SmallVectorTemplateBase<std::pair<mlir::OperationName,mlir::ConversionTarget::LegalizationInfo>,false>::push_back(a1 + 24, (unint64_t)&v29);
  if (v33 == v32)
  {
    (*(void (**)(void *))(v32[0] + 32))(v32);
  }
  else if (v33)
  {
    (*(void (**)(void *, uint64_t, uint64_t, uint64_t))(*v33 + 40))(v33, v12, v13, v14);
  }
  unsigned int v10 = *(_DWORD *)(a1 + 32) - 1;
  *(_DWORD *)(v20 + 8) = v10;
  return *(void *)(a1 + 24) + 48 * v10 + 8;
}

uint64_t *mlir::ConversionTarget::setDialectAction(uint64_t *result, uint64_t a2, uint64_t a3, int a4)
{
  if (a3)
  {
    uint64_t v5 = a2;
    uint64_t v6 = a2 + 16 * a3;
    uint64_t v7 = (uint64_t)(result + 9);
    do
    {
      uint64_t v8 = *(int8x16_t **)v5;
      uint64_t v9 = *(const unsigned __int8 **)(v5 + 8);
      v5 += 16;
      BOOL result = llvm::StringMap<unsigned int,llvm::MallocAllocator>::try_emplace<>(v7, v8, v9);
      *(_DWORD *)(*result + 8) = a4;
    }
    while (v5 != v6);
  }
  return result;
}

void *mlir::ConversionTarget::getOpInfo@<X0>(uint64_t a1@<X0>, uint64_t a2@<X1>, uint64_t a3@<X8>)
{
  uint64_t v41 = *MEMORY[0x263EF8340];
  uint64_t v34 = a2;
  uint64_t v5 = *(void *)(a1 + 8);
  uint64_t v6 = *(unsigned int *)(a1 + 24);
  if (v6)
  {
    LODWORD(v7) = (v6 - 1) & ((a2 >> 4) ^ (a2 >> 9));
    uint64_t v8 = (void *)(v5 + 16 * v7);
    uint64_t v9 = *v8;
    if (*v8 == a2) {
      goto LABEL_8;
    }
    int v10 = 1;
    while (v9 != -4096)
    {
      int v11 = v7 + v10++;
      uint64_t v7 = v11 & (v6 - 1);
      uint64_t v9 = *(void *)(v5 + 16 * v7);
      if (v9 == a2)
      {
        uint64_t v8 = (void *)(v5 + 16 * v7);
        goto LABEL_8;
      }
    }
  }
  uint64_t v8 = (void *)(v5 + 16 * v6);
LABEL_8:
  BOOL v12 = v8 == (void *)(v5 + 16 * v6);
  uint64_t v13 = (unsigned int *)(a1 + 40);
  if (!v12) {
    uint64_t v13 = (unsigned int *)(v8 + 1);
  }
  unsigned int v14 = *v13;
  if (v14 != *(_DWORD *)(a1 + 40))
  {
    uint64_t v20 = *(void *)(a1 + 32);
    uint64_t v21 = v20 + 48 * v14;
    char v22 = *(unsigned char *)(v21 + 12);
    *(_DWORD *)a3 = *(_DWORD *)(v21 + 8);
    *(unsigned char *)(a3 + 4) = v22;
    uint64_t v24 = *(void **)(v21 + 40);
    uint64_t v23 = v21 + 40;
    BOOL result = v24;
    if (v24)
    {
      if (result == (void *)(v20 + 48 * v14 + 16))
      {
        *(void *)(a3 + 32) = a3 + 8;
        BOOL result = (void *)(*(uint64_t (**)(void))(**(void **)v23 + 24))();
LABEL_34:
        *(unsigned char *)(a3 + 40) = 1;
        return result;
      }
      BOOL result = (void *)(*(uint64_t (**)(void *))(*result + 16))(result);
LABEL_32:
      *(void *)(a3 + 32) = result;
      goto LABEL_34;
    }
    goto LABEL_33;
  }
  DialectNamespace = (int8x16_t *)mlir::OperationName::getDialectNamespace((mlir::OperationName *)&v34);
  int Key = llvm::StringMapImpl::FindKey((uint64_t *)(a1 + 72), DialectNamespace, v16);
  if (Key != -1)
  {
    uint64_t v18 = Key;
    if (Key != (unint64_t)*(unsigned int *)(a1 + 80))
    {
      uint64_t v25 = *(void *)(a1 + 72);
      unsigned int v40 = 0;
      int v26 = (int8x16_t *)mlir::OperationName::getDialectNamespace((mlir::OperationName *)&v34);
      int v28 = llvm::StringMapImpl::FindKey((uint64_t *)(a1 + 96), v26, v27);
      if (v28 == -1 || v28 == (unint64_t)*(unsigned int *)(a1 + 104))
      {
        LODWORD(v35) = *(_DWORD *)(*(void *)(v25 + 8 * v18) + 8);
        BYTE4(v35) = 0;
      }
      else
      {
        uint64_t v29 = *(void *)(*(void *)(a1 + 96) + 8 * v28);
        uint64_t v30 = *(void *)(v29 + 32);
        if (v30)
        {
          uint64_t v31 = v29 + 8;
          if (v30 == v31)
          {
            uint64_t v37 = &v35;
            (*(void (**)(uint64_t, uint64_t *))(*(void *)v31 + 24))(v31, &v35);
          }
          else
          {
            uint64_t v37 = (uint64_t *)(*(uint64_t (**)(uint64_t))(*(void *)v30 + 16))(v30);
          }
        }
        else
        {
          uint64_t v37 = 0;
        }
        std::__function::__value_func<std::optional<BOOL> ()(mlir::Operation *)>::swap[abi:nn180100](&v35, v39);
        if (v37 == &v35)
        {
          (*(void (**)(uint64_t *))(v35 + 32))(&v35);
        }
        else if (v37)
        {
          (*(void (**)(void))(*v37 + 40))();
        }
        LODWORD(v35) = *(_DWORD *)(*(void *)(v25 + 8 * v18) + 8);
        BYTE4(v35) = 0;
        if (v40)
        {
          if (v40 == v39)
          {
            uint64_t v38 = v36;
            (*(void (**)(void *, void *))(v39[0] + 24))(v39, v36);
            unsigned int v32 = v38;
          }
          else
          {
            unsigned int v32 = (void *)(*(uint64_t (**)(void))(*v40 + 16))();
            uint64_t v38 = v32;
          }
          *(_DWORD *)a3 = v35;
          *(unsigned char *)(a3 + 4) = BYTE4(v35);
          if (v32)
          {
            if (v32 == v36)
            {
              *(void *)(a3 + 32) = a3 + 8;
              (*(void (**)(void *))(v36[0] + 24))(v36);
              unint64_t v33 = v38;
              *(unsigned char *)(a3 + 40) = 1;
              if (v33 == v36)
              {
                (*(void (**)(void *))(v36[0] + 32))(v36);
              }
              else if (v33)
              {
                (*(void (**)(void *))(*v33 + 40))(v33);
              }
LABEL_26:
              BOOL result = v40;
              if (v40 == v39) {
                return (void *)(*(uint64_t (**)(void *))(v39[0] + 32))(v39);
              }
              goto LABEL_37;
            }
            *(void *)(a3 + 32) = v32;
LABEL_25:
            *(unsigned char *)(a3 + 40) = 1;
            goto LABEL_26;
          }
LABEL_24:
          *(void *)(a3 + 32) = 0;
          goto LABEL_25;
        }
      }
      *(_DWORD *)a3 = v35;
      *(unsigned char *)(a3 + 4) = BYTE4(v35);
      goto LABEL_24;
    }
  }
  BOOL result = *(void **)(a1 + 144);
  if (!result)
  {
    *(unsigned char *)a3 = 0;
    *(unsigned char *)(a3 + 40) = 0;
    return result;
  }
  LODWORD(v35) = 1;
  BYTE4(v35) = 0;
  if (result != (void *)(a1 + 120))
  {
    BOOL result = (void *)(*(uint64_t (**)(void *))(*result + 16))(result);
    uint64_t v38 = result;
    *(_DWORD *)a3 = v35;
    *(unsigned char *)(a3 + 4) = BYTE4(v35);
    if (!result) {
      goto LABEL_33;
    }
    goto LABEL_31;
  }
  uint64_t v38 = v36;
  (*(void (**)(void *, void *))(*result + 24))(result, v36);
  BOOL result = v38;
  *(_DWORD *)a3 = v35;
  *(unsigned char *)(a3 + 4) = BYTE4(v35);
  if (!result)
  {
LABEL_33:
    *(void *)(a3 + 32) = 0;
    goto LABEL_34;
  }
LABEL_31:
  if (result != v36) {
    goto LABEL_32;
  }
  *(void *)(a3 + 32) = a3 + 8;
  (*(void (**)(void *))(v36[0] + 24))(v36);
  BOOL result = v38;
  *(unsigned char *)(a3 + 40) = 1;
  if (result == v36) {
    return (void *)(*(uint64_t (**)(void *))(v36[0] + 32))(v36);
  }
LABEL_37:
  if (result) {
    return (void *)(*(uint64_t (**)(void *))(*result + 40))(result);
  }
  return result;
}

uint64_t mlir::ConversionTarget::isLegal(mlir::ConversionTarget *this, mlir::Operation *a2)
{
  uint64_t v28 = *MEMORY[0x263EF8340];
  mlir::ConversionTarget::getOpInfo((uint64_t)this, *((void *)a2 + 6), (uint64_t)&v23);
  if (!v27)
  {
    int v7 = 0;
    int v6 = 0;
    return v6 | (v7 << 8);
  }
  int v4 = v23;
  if (v23 != 1) {
    goto LABEL_6;
  }
  char v22 = a2;
  if (!v26) {
    goto LABEL_37;
  }
  unsigned __int16 v5 = (*(uint64_t (**)(void *, mlir::Operation **))(*v26 + 48))(v26, &v22);
  if (v5 <= 0xFFu)
  {
    int v4 = v23;
LABEL_6:
    if (v4) {
      goto LABEL_7;
    }
    goto LABEL_11;
  }
  if (!(_BYTE)v5)
  {
LABEL_7:
    int v6 = 0;
    int v7 = 0;
    if (!v27) {
      return v6 | (v7 << 8);
    }
LABEL_32:
    if (v26 == v25)
    {
      (*(void (**)(void *))(v25[0] + 32))(v25);
    }
    else if (v26)
    {
      (*(void (**)(void *))(*v26 + 40))(v26);
    }
    return v6 | (v7 << 8);
  }
LABEL_11:
  if (!v24)
  {
    int v6 = 0;
    int v7 = 1;
    if (!v27) {
      return v6 | (v7 << 8);
    }
    goto LABEL_32;
  }
  uint64_t v8 = *((void *)this + 6);
  unsigned int v9 = *((_DWORD *)this + 16);
  if (v9)
  {
    uint64_t v10 = *((void *)a2 + 6);
    unsigned int v11 = ((v10 >> 4) ^ (v10 >> 9)) & (v9 - 1);
    BOOL v12 = (uint64_t *)(v8 + 40 * v11);
    uint64_t v13 = *v12;
    if (v10 == *v12) {
      goto LABEL_21;
    }
    int v14 = 1;
    while (v13 != -4096)
    {
      unsigned int v15 = v11 + v14++;
      unsigned int v11 = v15 & (v9 - 1);
      BOOL v12 = (uint64_t *)(v8 + 40 * v11);
      uint64_t v13 = *v12;
      if (v10 == *v12) {
        goto LABEL_21;
      }
    }
  }
  BOOL v12 = (uint64_t *)(v8 + 40 * v9);
LABEL_21:
  if (v12 == (uint64_t *)(v8 + 40 * v9))
  {
    int v6 = 1;
    int v7 = 1;
    if (v27) {
      goto LABEL_32;
    }
    return v6 | (v7 << 8);
  }
  char v22 = a2;
  uint64_t v16 = v12[4];
  if (v16)
  {
    unsigned __int16 v17 = (*(uint64_t (**)(uint64_t, mlir::Operation **))(*(void *)v16 + 48))(v16, &v22);
    if ((_BYTE)v17) {
      BOOL v18 = 0;
    }
    else {
      BOOL v18 = v17 >= 0x100u;
    }
    int v6 = !v18;
    int v7 = 1;
    if (!v27) {
      return v6 | (v7 << 8);
    }
    goto LABEL_32;
  }
LABEL_37:
  uint64_t v20 = (mlir::ConversionTarget *)std::__throw_bad_function_call[abi:nn180100]();
  return mlir::ConversionTarget::isIllegal(v20, v21);
}

uint64_t mlir::ConversionTarget::isIllegal(mlir::ConversionTarget *this, mlir::Operation *a2)
{
  uint64_t v12 = *MEMORY[0x263EF8340];
  mlir::ConversionTarget::getOpInfo((uint64_t)this, *((void *)a2 + 6), (uint64_t)&v8);
  if (!v11) {
    return 0;
  }
  if (v8 != 1)
  {
    BOOL v4 = v8 == 2;
    goto LABEL_10;
  }
  int v7 = a2;
  if (v10)
  {
    unsigned __int16 v3 = (*(uint64_t (**)(void *, mlir::Operation **))(*v10 + 48))(v10, &v7);
    if (v3 < 0x100u)
    {
      BOOL v4 = 0;
      if (!v11) {
        return v4;
      }
LABEL_10:
      if (v10 == v9)
      {
        (*(void (**)(void *))(v9[0] + 32))(v9);
      }
      else if (v10)
      {
        (*(void (**)(void *))(*v10 + 40))(v10);
      }
      return v4;
    }
    BOOL v4 = v3 == 0;
    if (v11) {
      goto LABEL_10;
    }
    return v4;
  }
  uint64_t v6 = std::__throw_bad_function_call[abi:nn180100]();
  return mlir::ConversionTarget::setLegalityCallback(v6);
}

uint64_t mlir::ConversionTarget::setLegalityCallback(uint64_t a1, uint64_t a2, void *a3)
{
  uint64_t v25 = *MEMORY[0x263EF8340];
  uint64_t v4 = *(void *)(a1 + 8);
  uint64_t v5 = *(unsigned int *)(a1 + 24);
  if (v5)
  {
    LODWORD(v6) = (v5 - 1) & ((a2 >> 4) ^ (a2 >> 9));
    int v7 = (void *)(v4 + 16 * v6);
    uint64_t v8 = *v7;
    if (*v7 == a2) {
      goto LABEL_8;
    }
    int v9 = 1;
    while (v8 != -4096)
    {
      int v10 = v6 + v9++;
      uint64_t v6 = v10 & (v5 - 1);
      uint64_t v8 = *(void *)(v4 + 16 * v6);
      if (v8 == a2)
      {
        int v7 = (void *)(v4 + 16 * v6);
        goto LABEL_8;
      }
    }
  }
  int v7 = (void *)(v4 + 16 * v5);
LABEL_8:
  if (v7 == (void *)(v4 + 16 * v5)) {
    char v11 = (unsigned int *)(a1 + 40);
  }
  else {
    char v11 = (unsigned int *)(v7 + 1);
  }
  uint64_t v12 = *(void *)(a1 + 32) + 48 * *v11;
  uint64_t v13 = (void *)(v12 + 16);
  int v14 = *(void **)(v12 + 40);
  if (!v14)
  {
    char v22 = 0;
    unsigned int v15 = (void *)a3[3];
    if (v15) {
      goto LABEL_16;
    }
    goto LABEL_19;
  }
  if (v14 == v13)
  {
    char v22 = v21;
    (*(void (**)(void *, void *))(*v13 + 24))(v13, v21);
    unsigned int v15 = (void *)a3[3];
    if (v15) {
      goto LABEL_16;
    }
LABEL_19:
    uint64_t v20 = 0;
    goto LABEL_21;
  }
  char v22 = v14;
  v13[3] = 0;
  unsigned int v15 = (void *)a3[3];
  if (!v15) {
    goto LABEL_19;
  }
LABEL_16:
  if (v15 == a3)
  {
    uint64_t v20 = v19;
    (*(void (**)(void *, void *))(*a3 + 24))(a3, v19);
  }
  else
  {
    uint64_t v20 = (void *)(*(uint64_t (**)(void *))(*v15 + 16))(v15);
  }
LABEL_21:
  composeLegalityCallbacks(v23, v21, v19);
  uint64_t v16 = (void *)v13[3];
  v13[3] = 0;
  if (v16 != v13)
  {
    if (v16) {
      (*(void (**)(void *))(*v16 + 40))(v16);
    }
    unsigned __int16 v17 = v24;
    if (v24) {
      goto LABEL_25;
    }
LABEL_28:
    v13[3] = 0;
    goto LABEL_29;
  }
  (*(void (**)(void *))(*v13 + 32))(v13);
  unsigned __int16 v17 = v24;
  if (!v24) {
    goto LABEL_28;
  }
LABEL_25:
  if (v17 == v23)
  {
    v13[3] = v13;
    (*(void (**)(void *, void *))(v23[0] + 24))(v23, v13);
    if (v24 == v23)
    {
      (*(void (**)(void *))(v23[0] + 32))(v23);
    }
    else if (v24)
    {
      (*(void (**)(void))(*v24 + 40))();
    }
  }
  else
  {
    v13[3] = v17;
    char v24 = 0;
  }
LABEL_29:
  if (v20 != v19)
  {
    if (v20) {
      (*(void (**)(void))(*v20 + 40))();
    }
    uint64_t result = (uint64_t)v22;
    if (v22 != v21) {
      goto LABEL_33;
    }
    return (*(uint64_t (**)(void *))(v21[0] + 32))(v21);
  }
  (*(void (**)(void *))(v19[0] + 32))(v19);
  uint64_t result = (uint64_t)v22;
  if (v22 == v21) {
    return (*(uint64_t (**)(void *))(v21[0] + 32))(v21);
  }
LABEL_33:
  if (result) {
    return (*(uint64_t (**)(uint64_t))(*(void *)result + 40))(result);
  }
  return result;
}

void *composeLegalityCallbacks(void *result, void *a2, void *a3)
{
  uint64_t v4 = result;
  uint64_t v25 = *MEMORY[0x263EF8340];
  uint64_t v5 = (void *)a2[3];
  if (v5)
  {
    if (v5 == a2)
    {
      char v22 = v21;
      (*(void (**)(void *, void *))(*a2 + 24))(a2, v21);
      uint64_t v6 = (void *)a3[3];
      if (v6)
      {
LABEL_4:
        if (v6 == a3)
        {
          char v24 = v23;
          (*(void (**)(void *, void *))(*a3 + 24))(a3, v23);
          int v7 = v22;
          if (v22) {
            goto LABEL_6;
          }
        }
        else
        {
          char v24 = v6;
          a3[3] = 0;
          int v7 = v22;
          if (v22)
          {
LABEL_6:
            if (v7 != v21)
            {
              BOOL v18 = v7;
              char v22 = 0;
              uint64_t v8 = v24;
              if (v24) {
                goto LABEL_8;
              }
LABEL_16:
              uint64_t v20 = 0;
              goto LABEL_22;
            }
            BOOL v18 = v17;
            (*(void (**)(void *, void *))(v21[0] + 24))(v21, v17);
            uint64_t v8 = v24;
            if (!v24) {
              goto LABEL_16;
            }
LABEL_8:
            if (v8 == v23)
            {
              uint64_t v20 = v19;
              (*(void (**)(void *, void *))(v23[0] + 24))(v23, v19);
            }
            else
            {
              uint64_t v20 = v8;
              char v24 = 0;
            }
LABEL_22:
            int v10 = operator new(0x48uLL);
            char v11 = v10;
            *int v10 = &unk_26C381C68;
            uint64_t v12 = v10 + 1;
            if (v18)
            {
              if (v18 == v17)
              {
                void v10[4] = v12;
                (*(void (**)(void *))(v17[0] + 24))(v17);
                uint64_t v13 = v20;
                if (v20) {
                  goto LABEL_25;
                }
              }
              else
              {
                void v10[4] = v18;
                BOOL v18 = 0;
                uint64_t v13 = v20;
                if (v20)
                {
LABEL_25:
                  if (v13 == v19)
                  {
                    v11[8] = v11 + 5;
                    (*(void (**)(void *))(v19[0] + 24))(v19);
                    unsigned int v15 = v20;
                    v4[3] = v11;
                    if (v15 == v19)
                    {
                      (*(void (**)(void *))(v19[0] + 32))(v19);
                    }
                    else if (v15)
                    {
                      (*(void (**)(void *))(*v15 + 40))(v15);
                    }
LABEL_30:
                    if (v18 == v17)
                    {
                      (*(void (**)(void *, void *))(v17[0] + 32))(v17, v12);
                      int v14 = v24;
                      if (v24 != v23) {
                        goto LABEL_34;
                      }
                    }
                    else
                    {
                      if (v18) {
                        (*(void (**)(void))(*v18 + 40))();
                      }
                      int v14 = v24;
                      if (v24 != v23)
                      {
LABEL_34:
                        if (v14) {
                          (*(void (**)(void *, void *))(*v14 + 40))(v14, v12);
                        }
                        uint64_t result = v22;
                        if (v22 != v21) {
                          goto LABEL_37;
                        }
                        return (void *)(*(uint64_t (**)(void *, void *))(v21[0] + 32))(v21, v12);
                      }
                    }
                    (*(void (**)(void *, void *))(v23[0] + 32))(v23, v12);
                    uint64_t result = v22;
                    if (v22 != v21)
                    {
LABEL_37:
                      if (result) {
                        return (void *)(*(uint64_t (**)(void *, void *))(*result + 40))(result, v12);
                      }
                      return result;
                    }
                    return (void *)(*(uint64_t (**)(void *, void *))(v21[0] + 32))(v21, v12);
                  }
                  v11[8] = v13;
                  uint64_t v20 = 0;
LABEL_29:
                  v4[3] = v11;
                  goto LABEL_30;
                }
              }
            }
            else
            {
              void v10[4] = 0;
              uint64_t v13 = v20;
              if (v20) {
                goto LABEL_25;
              }
            }
            v11[8] = 0;
            goto LABEL_29;
          }
        }
LABEL_15:
        BOOL v18 = 0;
        uint64_t v8 = v24;
        if (!v24) {
          goto LABEL_16;
        }
        goto LABEL_8;
      }
    }
    else
    {
      char v22 = (void *)a2[3];
      a2[3] = 0;
      uint64_t v6 = (void *)a3[3];
      if (v6) {
        goto LABEL_4;
      }
    }
    char v24 = 0;
    int v7 = v22;
    if (v22) {
      goto LABEL_6;
    }
    goto LABEL_15;
  }
  int v9 = (void *)a3[3];
  if (v9)
  {
    if (v9 == a3)
    {
      result[3] = result;
      uint64_t v16 = *(uint64_t (**)(void *, void *))(*a3 + 24);
      return (void *)v16(a3, result);
    }
    else
    {
      result[3] = v9;
      a3[3] = 0;
    }
  }
  else
  {
    result[3] = 0;
  }
  return result;
}

uint64_t mlir::ConversionTarget::setLegalityCallback(uint64_t result, uint64_t a2, uint64_t a3, void *a4)
{
  uint64_t v25 = *MEMORY[0x263EF8340];
  if (a3)
  {
    uint64_t v5 = a2;
    uint64_t v6 = result + 96;
    uint64_t v7 = a2 + 16 * a3;
    do
    {
      uint64_t v8 = *(int8x16_t **)v5;
      int v9 = *(const unsigned __int8 **)(v5 + 8);
      int v10 = llvm::StringMap<std::function<std::optional<BOOL> ()(mlir::Operation *)>,llvm::MallocAllocator>::try_emplace<>(v6, *(int8x16_t **)v5, v9);
      uint64_t v11 = *v10;
      uint64_t v12 = *(void **)(*v10 + 32);
      if (v12)
      {
        if (v12 == (void *)(v11 + 8))
        {
          char v22 = v21;
          (*(void (**)(void *, void *))(*v12 + 24))(v12, v21);
          uint64_t v13 = (void *)a4[3];
          if (!v13)
          {
LABEL_13:
            uint64_t v20 = 0;
            goto LABEL_15;
          }
        }
        else
        {
          char v22 = v12;
          *(void *)(v11 + 32) = 0;
          uint64_t v13 = (void *)a4[3];
          if (!v13) {
            goto LABEL_13;
          }
        }
      }
      else
      {
        char v22 = 0;
        uint64_t v13 = (void *)a4[3];
        if (!v13) {
          goto LABEL_13;
        }
      }
      if (v13 == a4)
      {
        uint64_t v20 = v19;
        (*(void (**)(void *, void *))(*a4 + 24))(a4, v19);
      }
      else
      {
        uint64_t v20 = (void *)(*(uint64_t (**)(void *))(*v13 + 16))(v13);
      }
LABEL_15:
      composeLegalityCallbacks(v23, v21, v19);
      int v14 = llvm::StringMap<std::function<std::optional<BOOL> ()(mlir::Operation *)>,llvm::MallocAllocator>::try_emplace<>(v6, v8, v9);
      uint64_t v15 = *v14;
      uint64_t v16 = *v14 + 8;
      uint64_t v17 = *(void *)(*v14 + 32);
      *(void *)(v15 + 32) = 0;
      if (v17 == v16)
      {
        (*(void (**)(uint64_t))(*(void *)v16 + 32))(v16);
        BOOL v18 = v24;
        if (!v24) {
          goto LABEL_22;
        }
      }
      else
      {
        if (v17) {
          (*(void (**)(uint64_t))(*(void *)v17 + 40))(v17);
        }
        BOOL v18 = v24;
        if (!v24)
        {
LABEL_22:
          *(void *)(v15 + 32) = 0;
          goto LABEL_23;
        }
      }
      if (v18 == v23)
      {
        *(void *)(v15 + 32) = v16;
        (*(void (**)(void *, uint64_t))(v23[0] + 24))(v23, v16);
        if (v24 == v23)
        {
          (*(void (**)(void *))(v23[0] + 32))(v23);
        }
        else if (v24)
        {
          (*(void (**)(void))(*v24 + 40))();
        }
      }
      else
      {
        *(void *)(v15 + 32) = v18;
        char v24 = 0;
      }
LABEL_23:
      if (v20 == v19)
      {
        (*(void (**)(void *))(v19[0] + 32))(v19);
        uint64_t result = (uint64_t)v22;
        if (v22 != v21) {
          goto LABEL_29;
        }
      }
      else
      {
        if (v20) {
          (*(void (**)(void))(*v20 + 40))();
        }
        uint64_t result = (uint64_t)v22;
        if (v22 != v21)
        {
LABEL_29:
          if (result) {
            uint64_t result = (*(uint64_t (**)(uint64_t))(*(void *)result + 40))(result);
          }
          goto LABEL_4;
        }
      }
      uint64_t result = (*(uint64_t (**)(void *))(v21[0] + 32))(v21);
LABEL_4:
      v5 += 16;
    }
    while (v5 != v7);
  }
  return result;
}

void anonymous namespace'::OperationConverter::OperationConverter(uint64_t a1, uint64_t a2, mlir::FrozenRewritePatternSet *a3)
{
  uint64_t v162 = *MEMORY[0x263EF8340];
  *(void *)a1 = a1 + 32;
  *(void *)(a1 + 8) = a1 + 32;
  *(void *)(a1 + 16) = 8;
  *(_DWORD *)(a1 + 24) = 0;
  *(void *)(a1 + 96) = a2;
  v142[0] = 0;
  v142[1] = 0;
  int v143 = 0;
  uint64_t v154 = &v156;
  uint64_t v155 = 0x100000000;
  v152[0] = 0;
  v152[1] = 0;
  int v153 = 0;
  uint64_t v149 = 0;
  uint64_t v150 = 0;
  unsigned int v151 = 0;
  uint64_t v144 = 0;
  int32x2_t v145 = 0;
  unsigned int v146 = 0;
  uint64_t v147 = &v149;
  uint64_t v148 = 0;
  v157.i64[0] = (uint64_t)&v154;
  v157.i64[1] = a1;
  uint64_t v158 = &v149;
  uint64_t v159 = v152;
  uint64_t v160 = &v144;
  long long v139 = (uint64_t **)mlir::PatternApplicator::PatternApplicator(a1 + 104, a3);
  if (v155)
  {
    if (v148)
    {
      uint64_t v4 = (char *)v147;
      uint64_t v5 = (char *)v147 + 8 * v148;
      int64x2_t v140 = vdupq_n_s64(1uLL);
      while (1)
      {
        uint64_t v6 = *(uint64_t **)v4;
        int64x2_t v7 = 0uLL;
        if (*(_DWORD *)(*(void *)v4 + 8) == 1)
        {
          v7.i64[1] = v140.i64[1];
          v7.i64[0] = *v6;
        }
        int64x2_t v157 = v7;
        if (!v143) {
          break;
        }
        uint64_t v8 = (v143 - 1) & (((unsigned __int32)v7.i32[0] >> 4) ^ ((unsigned __int32)v7.i32[0] >> 9));
        int v9 = (uint64_t *)((char *)v142[0] + 32 * v8);
        uint64_t v10 = *v9;
        if (*v9 != v7.i64[0])
        {
          uint64_t v11 = 0;
          int v12 = 1;
          while (v10 != -4096)
          {
            if (v11) {
              BOOL v13 = 0;
            }
            else {
              BOOL v13 = v10 == -8192;
            }
            if (v13) {
              uint64_t v11 = v9;
            }
            int v14 = v8 + v12++;
            uint64_t v8 = v14 & (v143 - 1);
            int v9 = (uint64_t *)((char *)v142[0] + 32 * v8);
            uint64_t v10 = *v9;
            if (*v9 == v7.i64[0]) {
              goto LABEL_19;
            }
          }
          if (v11) {
            uint64_t v15 = v11;
          }
          else {
            uint64_t v15 = v9;
          }
          goto LABEL_18;
        }
LABEL_19:
        unint64_t v16 = *((unsigned int *)v9 + 4);
        if (v16 >= *((unsigned int *)v9 + 5))
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)(v9 + 1), v9 + 3, v16 + 1, 8);
          unint64_t v16 = *((unsigned int *)v9 + 4);
        }
        *(void *)(v9[1] + 8 * v16) = v6;
        ++*((_DWORD *)v9 + 4);
        v4 += 8;
        if (v4 == v5) {
          goto LABEL_250;
        }
      }
      uint64_t v15 = 0;
LABEL_18:
      int v9 = llvm::DenseMapBase<llvm::DenseMap<mlir::OperationName,llvm::SmallVector<mlir::Pattern const*,1u>,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,llvm::SmallVector<mlir::Pattern const*,1u>>>,mlir::OperationName,llvm::SmallVector<mlir::Pattern const*,1u>,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,llvm::SmallVector<mlir::Pattern const*,1u>>>::InsertIntoBucket<mlir::OperationName>((uint64_t)v142, v15, v157.i64);
      goto LABEL_19;
    }
LABEL_250:
    if (v147 != &v149) {
      free(v147);
    }
    llvm::deallocate_buffer(v144, (void *)(8 * v146));
  }
  unsigned int v17 = v148;
  if (!v148) {
    goto LABEL_250;
  }
  int64x2_t v141 = vdupq_n_s64(1uLL);
LABEL_29:
  BOOL v18 = (_DWORD *)*((void *)v147 + v17 - 1);
  if (v146)
  {
    LODWORD(v19) = ((v18 >> 4) ^ (v18 >> 9)) & (v146 - 1);
    uint64_t v20 = (char *)v144 + 8 * v19;
    uint64_t v21 = *(_DWORD **)v20;
    if (v18 != *(_DWORD **)v20)
    {
      int v137 = 1;
      do
      {
        if (v21 == (_DWORD *)-4096) {
          goto LABEL_32;
        }
        int v138 = v19 + v137++;
        uint64_t v19 = v138 & (v146 - 1);
        uint64_t v21 = (_DWORD *)*((void *)v144 + v19);
      }
      while (v18 != v21);
      uint64_t v20 = (char *)v144 + 8 * v19;
    }
    *(void *)uint64_t v20 = -8192;
    int32x2_t v145 = vadd_s32(v145, (int32x2_t)0x1FFFFFFFFLL);
  }
LABEL_32:
  LODWORD(v148) = v17 - 1;
  uint64_t v22 = v18[8];
  if (v22)
  {
    int v23 = (uint64_t *)*((void *)v18 + 3);
    char v24 = &v23[v22];
    while (1)
    {
      uint64_t v28 = *v23;
      mlir::ConversionTarget::getOpInfo(*(void *)(a1 + 96), *v23, (uint64_t)&v157);
      int v29 = v161;
      if (!v161) {
        break;
      }
      unsigned __int8 v30 = v157.i8[0];
      unsigned int v31 = (unsigned __int32)v157.i32[0] >> 8;
      if (v160 != (llvm **)&v157.u64[1])
      {
        if (v160)
        {
          (*((void (**)(void))*v160 + 5))();
          int v32 = v143;
          if (!v143) {
            goto LABEL_43;
          }
          goto LABEL_34;
        }
        goto LABEL_42;
      }
      (*(void (**)(__int8 *))(v157.i64[1] + 32))(&v157.i8[8]);
      int v32 = v143;
      if (!v143) {
        goto LABEL_43;
      }
LABEL_34:
      int v25 = v32 - 1;
      unsigned int v26 = v25 & ((v28 >> 4) ^ (v28 >> 9));
      uint64_t v27 = *((void *)v142[0] + 4 * v26);
      if (v27 != v28)
      {
        int v33 = 1;
        while (v27 != -4096)
        {
          unsigned int v34 = v26 + v33++;
          unsigned int v26 = v34 & v25;
          uint64_t v27 = *((void *)v142[0] + 4 * v26);
          if (v27 == v28) {
            goto LABEL_35;
          }
        }
LABEL_43:
        if (!v29 || (v30 | (v31 << 8)) == 2) {
          goto LABEL_28;
        }
      }
LABEL_35:
      if (++v23 == v24) {
        goto LABEL_52;
      }
    }
    unsigned int v31 = 0;
    unsigned __int8 v30 = 0;
LABEL_42:
    int v32 = v143;
    if (!v143) {
      goto LABEL_43;
    }
    goto LABEL_34;
  }
LABEL_52:
  int64x2_t v35 = 0uLL;
  if (v18[2] == 1)
  {
    v35.i64[1] = v141.i64[1];
    v35.i64[0] = *(void *)v18;
  }
  int64x2_t v157 = v35;
  if (v143)
  {
    uint64_t v36 = (v143 - 1) & (((unsigned __int32)v35.i32[0] >> 4) ^ ((unsigned __int32)v35.i32[0] >> 9));
    uint64_t v37 = (uint64_t *)((char *)v142[0] + 32 * v36);
    uint64_t v38 = *v37;
    if (*v37 == v35.i64[0]) {
      goto LABEL_67;
    }
    int v39 = 0;
    int v40 = 1;
    while (v38 != -4096)
    {
      if (v39) {
        BOOL v41 = 0;
      }
      else {
        BOOL v41 = v38 == -8192;
      }
      if (v41) {
        int v39 = v37;
      }
      int v42 = v36 + v40++;
      uint64_t v36 = v42 & (v143 - 1);
      uint64_t v37 = (uint64_t *)((char *)v142[0] + 32 * v36);
      uint64_t v38 = *v37;
      if (*v37 == v35.i64[0]) {
        goto LABEL_67;
      }
    }
    if (v39) {
      unint64_t v43 = v39;
    }
    else {
      unint64_t v43 = v37;
    }
  }
  else
  {
    unint64_t v43 = 0;
  }
  uint64_t v37 = llvm::DenseMapBase<llvm::DenseMap<mlir::OperationName,llvm::SmallVector<mlir::Pattern const*,1u>,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,llvm::SmallVector<mlir::Pattern const*,1u>>>,mlir::OperationName,llvm::SmallVector<mlir::Pattern const*,1u>,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,llvm::SmallVector<mlir::Pattern const*,1u>>>::InsertIntoBucket<mlir::OperationName>((uint64_t)v142, v43, v157.i64);
LABEL_67:
  unint64_t v44 = *((unsigned int *)v37 + 4);
  if (v44 >= *((unsigned int *)v37 + 5))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)(v37 + 1), v37 + 3, v44 + 1, 8);
    unint64_t v44 = *((unsigned int *)v37 + 4);
  }
  *(void *)(v37[1] + 8 * v44) = v18;
  ++*((_DWORD *)v37 + 4);
  int64x2_t v45 = 0uLL;
  if (v18[2] == 1)
  {
    int64x2_t v45 = vdupq_n_s64(1uLL);
    v45.i64[0] = *(void *)v18;
  }
  int64x2_t v157 = v45;
  if (v151)
  {
    unsigned int v46 = (v151 - 1) & (((unsigned __int32)v45.i32[0] >> 4) ^ ((unsigned __int32)v45.i32[0] >> 9));
    uint64_t v47 = (char *)v149 + 56 * v46;
    uint64_t v48 = *(void *)v47;
    if (*(void *)v47 == v45.i64[0]) {
      goto LABEL_84;
    }
    uint64_t v49 = 0;
    int v50 = 1;
    while (v48 != -4096)
    {
      if (v49) {
        BOOL v51 = 0;
      }
      else {
        BOOL v51 = v48 == -8192;
      }
      if (v51) {
        uint64_t v49 = v47;
      }
      unsigned int v52 = v46 + v50++;
      unsigned int v46 = v52 & (v151 - 1);
      uint64_t v47 = (char *)v149 + 56 * v46;
      uint64_t v48 = *(void *)v47;
      if (*(void *)v47 == v45.i64[0]) {
        goto LABEL_84;
      }
    }
    if (v49) {
      uint64_t v53 = v49;
    }
    else {
      uint64_t v53 = v47;
    }
  }
  else
  {
    uint64_t v53 = 0;
  }
  uint64_t v47 = llvm::DenseMapBase<llvm::DenseMap<mlir::OperationName,llvm::SmallPtrSet<mlir::OperationName,2u>,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,llvm::SmallPtrSet<mlir::OperationName,2u>>>,mlir::OperationName,llvm::SmallPtrSet<mlir::OperationName,2u>,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,llvm::SmallPtrSet<mlir::OperationName,2u>>>::InsertIntoBucket<mlir::OperationName const&>((uint64_t)&v149, v53, v157.i64);
LABEL_84:
  uint64_t v54 = *((void *)v47 + 2);
  if (v54 == *((void *)v47 + 1))
  {
    uint64_t v59 = *((unsigned int *)v47 + 7);
    BucketFor = (const void **)(v54 + 8 * v59);
    if (v59)
    {
      uint64_t v60 = 0;
      uint64_t v61 = 8 * v59;
      while (*(_DWORD **)(v54 + v60) != v18)
      {
        v60 += 8;
        if (v61 == v60) {
          goto LABEL_235;
        }
      }
      BucketFor = (const void **)(v54 + v60);
LABEL_235:
      if (BucketFor != (const void **)(*((void *)v47 + 2) + 8 * *((unsigned int *)v47 + 7))) {
        goto LABEL_104;
      }
      goto LABEL_105;
    }
    uint64_t v56 = *((void *)v47 + 2);
  }
  else
  {
    BucketFor = llvm::SmallPtrSetImplBase::FindBucketFor((llvm::SmallPtrSetImplBase *)(v47 + 8), v18);
    uint64_t v54 = *((void *)v47 + 1);
    uint64_t v56 = *((void *)v47 + 2);
    if (*BucketFor != v18)
    {
      if (v56 == v54) {
        uint64_t v57 = 28;
      }
      else {
        uint64_t v57 = 24;
      }
      BucketFor = (const void **)(v56 + 8 * *(unsigned int *)&v47[v57]);
      if (v56 == v54) {
        uint64_t v58 = 28;
      }
      else {
        uint64_t v58 = 24;
      }
      if (BucketFor == (const void **)(v56 + 8 * *(unsigned int *)&v47[v58])) {
        goto LABEL_105;
      }
LABEL_104:
      *BucketFor = (const void *)-2;
      ++*((_DWORD *)v47 + 8);
      goto LABEL_105;
    }
  }
  if (v56 == v54) {
    uint64_t v62 = 28;
  }
  else {
    uint64_t v62 = 24;
  }
  if (BucketFor != (const void **)(v56 + 8 * *(unsigned int *)&v47[v62])) {
    goto LABEL_104;
  }
LABEL_105:
  int64x2_t v63 = 0uLL;
  if (v18[2] == 1)
  {
    int64x2_t v63 = vdupq_n_s64(1uLL);
    v63.i64[0] = *(void *)v18;
  }
  int64x2_t v157 = v63;
  if (v153)
  {
    unsigned int v64 = (v153 - 1) & (((unsigned __int32)v63.i32[0] >> 4) ^ ((unsigned __int32)v63.i32[0] >> 9));
    unsigned int v65 = (char *)v152[0] + 56 * v64;
    uint64_t v66 = *(void *)v65;
    if (*(void *)v65 == v63.i64[0])
    {
LABEL_120:
      uint64_t v72 = *((void *)v65 + 2);
      if (v72 == *((void *)v65 + 1)) {
        uint64_t v73 = 28;
      }
      else {
        uint64_t v73 = 24;
      }
      uint64_t v74 = *(unsigned int *)&v65[v73];
      if (v74)
      {
        uint64_t v75 = 8 * v74;
        uint64_t v76 = (uint64_t *)*((void *)v65 + 2);
        while ((unint64_t)*v76 >= 0xFFFFFFFFFFFFFFFELL)
        {
          ++v76;
          v75 -= 8;
          if (!v75) {
            goto LABEL_28;
          }
        }
      }
      else
      {
        uint64_t v76 = (uint64_t *)*((void *)v65 + 2);
      }
      int v77 = (uint64_t *)(v72 + 8 * v74);
      if (v76 == v77) {
        goto LABEL_28;
      }
      uint64_t v78 = *v76;
      while (1)
      {
        uint64_t v79 = (uint64_t *)v149;
        uint64_t v80 = v151;
        if (!v151) {
          goto LABEL_206;
        }
        unsigned int v81 = v151 - 1;
        unsigned int v82 = ((v78 >> 4) ^ (v78 >> 9)) & (v151 - 1);
        unsigned int v83 = (char *)v149 + 56 * v82;
        uint64_t v84 = *(void *)v83;
        if (v78 != *(void *)v83) {
          break;
        }
LABEL_147:
        int v91 = (uint64_t *)*((void *)v83 + 1);
        int v90 = (uint64_t *)*((void *)v83 + 2);
        BOOL v92 = v83 + 28;
        unsigned int v93 = v83 + 24;
        if (v90 == v91) {
          unsigned int v93 = v92;
        }
        uint64_t v94 = *(unsigned int *)v93;
        if (v94)
        {
          uint64_t v95 = 8 * v94;
          uint64_t v96 = v90;
          while ((unint64_t)*v96 >= 0xFFFFFFFFFFFFFFFELL)
          {
            ++v96;
            v95 -= 8;
            if (!v95) {
              goto LABEL_199;
            }
          }
        }
        else
        {
          uint64_t v96 = v90;
        }
        unint64_t v97 = &v90[v94];
        if (v96 == v97) {
          goto LABEL_199;
        }
        uint64_t v98 = *v96;
        do
        {
          int v99 = v146;
          if (!v146) {
            goto LABEL_183;
          }
          unsigned int v100 = ((v98 >> 4) ^ (v98 >> 9)) & (v146 - 1);
          unint64_t v101 = (void *)((char *)v144 + 8 * v100);
          uint64_t v102 = *v101;
          if (v98 == *v101) {
            goto LABEL_175;
          }
          uint64_t v103 = 0;
          int v104 = 1;
          while (v102 != -4096)
          {
            if (v103) {
              BOOL v105 = 0;
            }
            else {
              BOOL v105 = v102 == -8192;
            }
            if (v105) {
              uint64_t v103 = v101;
            }
            unsigned int v106 = v100 + v104++;
            unsigned int v100 = v106 & (v146 - 1);
            unint64_t v101 = (void *)((char *)v144 + 8 * v100);
            uint64_t v102 = *v101;
            if (v98 == *v101) {
              goto LABEL_175;
            }
          }
          unint64_t v109 = (char *)(v103 ? v103 : v101);
          if (4 * v145.i32[0] + 4 < 3 * v146)
          {
            if (v146 + ~v145.i32[0] - v145.i32[1] > v146 >> 3) {
              goto LABEL_170;
            }
          }
          else
          {
LABEL_183:
            int v99 = 2 * v146;
          }
          llvm::DenseMap<mlir::Block *,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::Block *,void>,llvm::detail::DenseSetPair<mlir::Block *>>::grow((uint64_t)&v144, v99);
          unsigned int v110 = v146 - 1;
          unsigned int v111 = (v146 - 1) & ((v98 >> 4) ^ (v98 >> 9));
          unint64_t v109 = (char *)v144 + 8 * v111;
          uint64_t v112 = *(void *)v109;
          if (v98 == *(void *)v109)
          {
LABEL_185:
            ++v145.i32[0];
            if (v98 == -4096) {
              goto LABEL_172;
            }
LABEL_171:
            --v145.i32[1];
            goto LABEL_172;
          }
          int v113 = 0;
          int v114 = 1;
          while (v112 != -4096)
          {
            if (v113) {
              BOOL v115 = 0;
            }
            else {
              BOOL v115 = v112 == -8192;
            }
            if (v115) {
              int v113 = v109;
            }
            unsigned int v116 = v111 + v114++;
            unsigned int v111 = v116 & v110;
            unint64_t v109 = (char *)v144 + 8 * (v116 & v110);
            uint64_t v112 = *(void *)v109;
            if (v98 == *(void *)v109) {
              goto LABEL_185;
            }
          }
          if (v113) {
            unint64_t v109 = v113;
          }
LABEL_170:
          uint64_t v107 = *(void *)v109;
          ++v145.i32[0];
          if (v107 != -4096) {
            goto LABEL_171;
          }
LABEL_172:
          *(void *)unint64_t v109 = v98;
          uint64_t v108 = v148;
          if (v148 >= (unint64_t)HIDWORD(v148))
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v147, &v149, v148 + 1, 8);
            uint64_t v108 = v148;
          }
          *((void *)v147 + v108) = v98;
          LODWORD(v148) = v148 + 1;
          do
          {
LABEL_175:
            if (++v96 == v97) {
              goto LABEL_199;
            }
            uint64_t v98 = *v96;
          }
          while ((unint64_t)*v96 >= 0xFFFFFFFFFFFFFFFELL);
        }
        while (v96 != v97);
        do
        {
LABEL_199:
          if (++v76 == v77) {
            goto LABEL_28;
          }
          uint64_t v78 = *v76;
        }
        while ((unint64_t)*v76 >= 0xFFFFFFFFFFFFFFFELL);
        if (v76 == v77)
        {
LABEL_28:
          unsigned int v17 = v148;
          if (!v148) {
            goto LABEL_250;
          }
          goto LABEL_29;
        }
      }
      int v85 = 0;
      int v86 = 1;
      while (v84 != -4096)
      {
        if (v85) {
          BOOL v87 = 0;
        }
        else {
          BOOL v87 = v84 == -8192;
        }
        if (v87) {
          int v85 = v83;
        }
        unsigned int v88 = v82 + v86++;
        unsigned int v82 = v88 & v81;
        unsigned int v83 = (char *)v149 + 56 * (v88 & v81);
        uint64_t v84 = *(void *)v83;
        if (v78 == *(void *)v83) {
          goto LABEL_147;
        }
      }
      if (v85) {
        unsigned int v83 = v85;
      }
      if (4 * (int)v150 + 4 < 3 * v151)
      {
        if (v151 + ~v150 - HIDWORD(v150) > v151 >> 3) {
          goto LABEL_144;
        }
        int v117 = v151;
      }
      else
      {
LABEL_206:
        int v117 = 2 * v151;
      }
      unint64_t v118 = (v117 - 1) | ((unint64_t)(v117 - 1) >> 1);
      unint64_t v119 = v118 | (v118 >> 2) | ((v118 | (v118 >> 2)) >> 4);
      int v120 = ((v119 | (v119 >> 8)) >> 16) | v119 | (v119 >> 8);
      if ((v120 + 1) > 0x40) {
        unsigned int v121 = v120 + 1;
      }
      else {
        unsigned int v121 = 64;
      }
      unsigned int v151 = v121;
      buffer = (llvm *)llvm::allocate_buffer(56 * v121, (std::align_val_t)8uLL);
      uint64_t v149 = buffer;
      if (v79)
      {
        llvm::DenseMapBase<llvm::DenseMap<mlir::OperationName,llvm::SmallPtrSet<mlir::OperationName,2u>,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,llvm::SmallPtrSet<mlir::OperationName,2u>>>,mlir::OperationName,llvm::SmallPtrSet<mlir::OperationName,2u>,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,llvm::SmallPtrSet<mlir::OperationName,2u>>>::moveFromOldBuckets((uint64_t)&v149, v79, &v79[7 * v80]);
        llvm::deallocate_buffer((llvm *)v79, (void *)(56 * v80));
      }
      uint64_t v150 = 0;
      unsigned int v123 = v151;
      uint64_t v124 = 56 * v151;
      uint64_t v125 = buffer;
      if ((unint64_t)(v124 - 56) < 0x38) {
        goto LABEL_217;
      }
      unint64_t v126 = (v124 - 56) / 0x38uLL + 1;
      uint64_t v125 = (llvm *)((char *)buffer + 56 * (v126 & 0xFFFFFFFFFFFFFFELL));
      uint64_t v127 = v126 & 0xFFFFFFFFFFFFFFELL;
      int v128 = buffer;
      do
      {
        *(void *)int v128 = -4096;
        *((void *)v128 + 7) = -4096;
        int v128 = (llvm *)((char *)v128 + 112);
        v127 -= 2;
      }
      while (v127);
      if (v126 != (v126 & 0xFFFFFFFFFFFFFFELL))
      {
LABEL_217:
        uint64_t v129 = (llvm *)((char *)buffer + v124);
        do
        {
          *(void *)uint64_t v125 = -4096;
          uint64_t v125 = (llvm *)((char *)v125 + 56);
        }
        while (v125 != v129);
      }
      unsigned int v130 = v123 - 1;
      unsigned int v131 = (v123 - 1) & ((v78 >> 4) ^ (v78 >> 9));
      unsigned int v83 = (char *)buffer + 56 * v131;
      uint64_t v132 = *(void *)v83;
      if (v78 == *(void *)v83)
      {
LABEL_220:
        LODWORD(v150) = v150 + 1;
        if (v78 == -4096) {
          goto LABEL_146;
        }
        goto LABEL_145;
      }
      unint64_t v133 = 0;
      int v134 = 1;
      while (v132 != -4096)
      {
        if (v133) {
          BOOL v135 = 0;
        }
        else {
          BOOL v135 = v132 == -8192;
        }
        if (v135) {
          unint64_t v133 = v83;
        }
        unsigned int v136 = v131 + v134++;
        unsigned int v131 = v136 & v130;
        unsigned int v83 = (char *)buffer + 56 * (v136 & v130);
        uint64_t v132 = *(void *)v83;
        if (v78 == *(void *)v83) {
          goto LABEL_220;
        }
      }
      if (v133) {
        unsigned int v83 = v133;
      }
LABEL_144:
      uint64_t v89 = *(void *)v83;
      LODWORD(v150) = v150 + 1;
      if (v89 == -4096)
      {
LABEL_146:
        *(void *)unsigned int v83 = v78;
        *((void *)v83 + 1) = v83 + 40;
        *((void *)v83 + 2) = v83 + 40;
        *((void *)v83 + 3) = 2;
        *((_DWORD *)v83 + 8) = 0;
        goto LABEL_147;
      }
LABEL_145:
      --HIDWORD(v150);
      goto LABEL_146;
    }
    BOOL v67 = 0;
    int v68 = 1;
    while (v66 != -4096)
    {
      if (v67) {
        BOOL v69 = 0;
      }
      else {
        BOOL v69 = v66 == -8192;
      }
      if (v69) {
        BOOL v67 = v65;
      }
      unsigned int v70 = v64 + v68++;
      unsigned int v64 = v70 & (v153 - 1);
      unsigned int v65 = (char *)v152[0] + 56 * v64;
      uint64_t v66 = *(void *)v65;
      if (*(void *)v65 == v63.i64[0]) {
        goto LABEL_120;
      }
    }
    if (v67) {
      int v71 = v67;
    }
    else {
      int v71 = v65;
    }
  }
  else
  {
    int v71 = 0;
  }
  unsigned int v65 = llvm::DenseMapBase<llvm::DenseMap<mlir::OperationName,llvm::SmallPtrSet<mlir::OperationName,2u>,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,llvm::SmallPtrSet<mlir::OperationName,2u>>>,mlir::OperationName,llvm::SmallPtrSet<mlir::OperationName,2u>,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,llvm::SmallPtrSet<mlir::OperationName,2u>>>::InsertIntoBucket<mlir::OperationName const&>((uint64_t)v152, v71, v157.i64);
  goto LABEL_120;
}

uint64_t sub_2118F0298()
{
  *(_DWORD *)(v0 + 168) = v2;
  *(void *)(v0 + 176) = v3;
  return v0;
}

uint64_t anonymous namespace'::OperationConverter::convertOperations(uint64_t a1, uint64_t a2, uint64_t a3)
{
  v11[24] = *MEMORY[0x263EF8340];
  if (a3)
  {
    uint64_t v4 = 0;
    uint64_t v5 = *(void *)(a1 + 96);
    v9[0] = &v10;
    v9[1] = (void *)0x600000000;
    uint64_t v6 = 8 * a3;
    do
    {
      int64x2_t v7 = *(mlir::ForwardIterator **)(a2 + v4);
      v11[0] = v9;
      v11[1] = v5;
      v4 += 8;
    }
    while (v6 != v4);
    mlir::Attribute::getContext((mlir::Attribute *)(*(void *)a2 + 24));
    operator new();
  }
  return 1;
}

void mlir::applyFullConversion(mlir *this, mlir::Operation *a2, const mlir::ConversionTarget *a3, const mlir::FrozenRewritePatternSet *a4)
{
  uint64_t v5 = *MEMORY[0x263EF8340];
}

void sub_2118F1070(uint64_t a1, ...)
{
  va_start(va1, a1);
  va_start(va, a1);
  uint64_t v2 = va_arg(va1, void);
  mlir::PatternApplicator::~PatternApplicator((mlir::PatternApplicator *)(v1 + 104));
}

void mlir::applyAnalysisConversion(uint64_t a1, uint64_t a2, mlir::FrozenRewritePatternSet *a3)
{
  uint64_t v4 = *MEMORY[0x263EF8340];
}

void sub_2118F1118(uint64_t a1, ...)
{
  va_start(va1, a1);
  va_start(va, a1);
  uint64_t v2 = va_arg(va1, void);
  mlir::PatternApplicator::~PatternApplicator((mlir::PatternApplicator *)(v1 + 104));
}

uint64_t mlir::ConversionPatternRewriter::canRecoverFromRewriteFailure(mlir::ConversionPatternRewriter *this)
{
  return 1;
}

uint64_t mlir::RewriterBase::Listener::notifyOperationReplaced(mlir::RewriterBase::Listener *this, mlir::Operation *a2, mlir::Operation *a3)
{
  void v7[2] = *MEMORY[0x263EF8340];
  if (*((_DWORD *)a3 + 9)) {
    uint64_t v5 = (char *)a3 - 16;
  }
  else {
    uint64_t v5 = 0;
  }
  mlir::ValueRange::ValueRange(v7, (uint64_t)v5, *((unsigned int *)a3 + 9));
  return (*(uint64_t (**)(mlir::RewriterBase::Listener *, mlir::Operation *, unint64_t, unint64_t))(*(void *)this + 48))(this, a2, v7[0], v7[1]);
}

void *llvm::MapVector<mlir::Block *,anonymous namespace'::ArgConverter::ConvertedBlockInfo,llvm::DenseMap<mlir::Block *,unsigned int,llvm::DenseMapInfo<mlir::Block *,void>,llvm::detail::DenseMapPair<mlir::Block *,unsigned int>>,llvm::SmallVector<std::pair<mlir::Block *,anonymous namespace'::ArgConverter::ConvertedBlockInfo>,0u>>::erase(int32x2_t *a1, void *a2)
{
  __int32 v4 = a1[2].i32[0];
  if (v4)
  {
    int32x2_t v5 = *a1;
    __int32 v6 = v4 - 1;
    LODWORD(v7) = ((*a2 >> 4) ^ (*a2 >> 9)) & (v4 - 1);
    uint64_t v8 = (uint64_t *)(*(void *)a1 + 16 * v7);
    uint64_t v9 = *v8;
    if (*a2 == *v8)
    {
LABEL_3:
      *uint64_t v8 = -8192;
      a1[1] = vadd_s32(a1[1], (int32x2_t)0x1FFFFFFFFLL);
    }
    else
    {
      int v24 = 1;
      while (v9 != -4096)
      {
        int v25 = v7 + v24++;
        uint64_t v7 = v25 & v6;
        uint64_t v9 = *(void *)(*(void *)&v5 + 16 * v7);
        if (*a2 == v9)
        {
          uint64_t v8 = (uint64_t *)(*(void *)&v5 + 16 * v7);
          goto LABEL_3;
        }
      }
    }
  }
  uint64_t v10 = a2 + 8;
  int32x2_t v11 = a1[3];
  uint64_t v12 = a1[4].u32[0];
  BOOL v13 = (void *)(*(void *)&v11 + (v12 << 6));
  if (a2 + 8 != v13)
  {
    do
    {
      *((_OWORD *)v10 - 4) = *(_OWORD *)v10;
      *(v10 - 1) = v10[7];
      v10 += 8;
    }
    while (v10 != v13);
    LODWORD(v12) = a1[4].i32[0];
    int32x2_t v11 = a1[3];
  }
  uint64_t v14 = (v12 - 1);
  a1[4].i32[0] = v14;
  uint64_t v15 = *(void *)&v11 + (v14 << 6);
  unint64_t v16 = *(void **)(v15 + 16);
  if (v16 != (void *)(v15 + 32))
  {
    free(v16);
    int32x2_t v11 = a1[3];
    uint64_t v14 = a1[4].u32[0];
  }
  if ((void *)(*(void *)&v11 + (v14 << 6)) != a2 && a1[1].i32[0])
  {
    uint64_t v17 = a1[2].u32[0];
    if (v17)
    {
      uint64_t v18 = 16 * v17;
      int32x2_t v19 = *a1;
      while ((**(void **)&v19 | 0x1000) == 0xFFFFFFFFFFFFF000)
      {
        *(void *)&v19 += 16;
        v18 -= 16;
        if (!v18) {
          return a2;
        }
      }
    }
    else
    {
      int32x2_t v19 = *a1;
    }
    uint64_t v20 = *(void *)a1 + 16 * v17;
    if (*(void *)&v19 != v20)
    {
      unint64_t v21 = ((uint64_t)a2 - *(void *)&v11) >> 6;
LABEL_19:
      unint64_t v22 = *(unsigned int *)(*(void *)&v19 + 8);
      if (v21 < v22) {
        *(_DWORD *)(*(void *)&v19 + 8) = v22 - 1;
      }
      while (1)
      {
        *(void *)&v19 += 16;
        if (*(void *)&v19 == v20) {
          break;
        }
        if ((**(void **)&v19 | 0x1000) != 0xFFFFFFFFFFFFF000)
        {
          if (*(void *)&v19 != v20) {
            goto LABEL_19;
          }
          return a2;
        }
      }
    }
  }
  return a2;
}

uint64_t llvm::SmallVectorImpl<std::optional<anonymous namespace'::ArgConverter::ConvertedArgInfo>>::operator=(uint64_t a1, uint64_t a2)
{
  if (a1 != a2)
  {
    int32x2_t v5 = (const void *)(a2 + 16);
    __int32 v4 = *(const void **)a2;
    if (v4 != v5)
    {
      __int32 v6 = *(void **)a1;
      if (*(void *)a1 != a1 + 16)
      {
        free(v6);
        __int32 v4 = *(const void **)a2;
      }
      *(void *)a1 = v4;
      uint64_t v7 = (_DWORD *)(a2 + 8);
      *(void *)(a1 + 8) = *(void *)(a2 + 8);
      *(void *)a2 = v5;
      *(_DWORD *)(a2 + 12) = 0;
      goto LABEL_16;
    }
    uint64_t v7 = (_DWORD *)(a2 + 8);
    unint64_t v8 = *(unsigned int *)(a2 + 8);
    uint64_t v9 = *(unsigned int *)(a1 + 8);
    if (v9 >= v8)
    {
      if (v8) {
        memmove(*(void **)a1, v4, 24 * v8 - 7);
      }
      goto LABEL_15;
    }
    if (*(_DWORD *)(a1 + 12) >= v8)
    {
      if (v9)
      {
        memmove(*(void **)a1, v4, 24 * v9 - 7);
        uint64_t v10 = *v7;
        if (v9 == v10)
        {
LABEL_15:
          *(_DWORD *)(a1 + 8) = v8;
LABEL_16:
          *uint64_t v7 = 0;
          return a1;
        }
      }
      else
      {
        uint64_t v9 = 0;
        LODWORD(v10) = *v7;
        if (!*v7) {
          goto LABEL_15;
        }
      }
    }
    else
    {
      *(_DWORD *)(a1 + 8) = 0;
      llvm::SmallVectorBase<unsigned int>::grow_pod(a1, (void *)(a1 + 16), v8, 24);
      uint64_t v9 = 0;
      LODWORD(v10) = *v7;
      if (!*v7) {
        goto LABEL_15;
      }
    }
    memcpy((void *)(*(void *)a1 + 24 * v9), (const void *)(*(void *)a2 + 24 * v9), *(void *)a2 + 24 * v10 - (*(void *)a2 + 24 * v9));
    goto LABEL_15;
  }
  return a1;
}

uint64_t buildUnresolvedMaterialization(unsigned int a1, mlir::Block *this, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, ZinIrHalH13g *a8, uint64_t a9, uint64_t *a10)
{
  v31[3] = *MEMORY[0x263EF8340];
  v30[0] = a5;
  v30[1] = a6;
  uint64_t v29 = a7;
  if (a6 == 1 && a7 == (*(void *)(mlir::ValueRange::dereference_iterator(v30, 0) + 8) & 0xFFFFFFFFFFFFFFF8)) {
    return mlir::ValueRange::dereference_iterator(v30, 0);
  }
  unint64_t Parent = (mlir::Region *)mlir::Block::getParent(this);
  v28[0] = mlir::Region::getContext(Parent);
  v28[1] = 0;
  uint64_t v28[2] = this;
  v28[3] = a3;
  unint64_t v16 = mlir::OpBuilder::create<mlir::UnrealizedConversionCastOp,mlir::Type &,mlir::ValueRange &>((mlir::OpBuilder *)v28, a4, (uint64_t)&v29, v30);
  uint64_t v17 = v16;
  uint64_t v18 = *((unsigned int *)a10 + 2);
  if (v18 >= *((_DWORD *)a10 + 3))
  {
    v31[0] = v16;
    v31[1] = a9 & 0xFFFFFFFFFFFFFFFBLL | (4 * a1);
    unint64_t v31[2] = a8;
    unint64_t v21 = v18 + 1;
    BOOL v22 = *a10 + 24 * (unint64_t)v18 > (unint64_t)v31;
    if (*a10 <= (unint64_t)v31 && v22)
    {
      uint64_t v27 = (char *)v31 - *a10;
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)a10, a10 + 2, v21, 24);
      uint64_t v23 = *a10;
      int v24 = &v27[*a10];
    }
    else
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)a10, a10 + 2, v21, 24);
      uint64_t v23 = *a10;
      int v24 = (char *)v31;
    }
    uint64_t v25 = v23 + 24 * *((unsigned int *)a10 + 2);
    long long v26 = *(_OWORD *)v24;
    *(void *)(v25 + 16) = *((void *)v24 + 2);
    *(_OWORD *)uint64_t v25 = v26;
  }
  else
  {
    int32x2_t v19 = (ZinIrHalH13g **)(*a10 + 24 * v18);
    *int32x2_t v19 = v16;
    v19[1] = (ZinIrHalH13g *)(a9 & 0xFFFFFFFFFFFFFFFBLL | (4 * a1));
    unint64_t v19[2] = a8;
  }
  ++*((_DWORD *)a10 + 2);
  return (uint64_t)v17 - 16;
}

ZinIrHalH13g *mlir::OpBuilder::create<mlir::UnrealizedConversionCastOp,mlir::Type &,mlir::ValueRange &>(mlir::OpBuilder *a1, uint64_t a2, uint64_t a3, uint64_t *a4)
{
  v20[38] = *MEMORY[0x263EF8340];
  uint64_t v14 = a2;
  uint64_t Context = (uint64_t *)mlir::Attribute::getContext((mlir::Attribute *)&v14);
  uint64_t v9 = mlir::RegisteredOperationName::lookup((int8x16_t *)"builtin.unrealized_conversion_cast", (const unsigned __int8 *)0x22, Context);
  if (!v10)
  {
    __int16 v18 = 1283;
    unint64_t v17[2] = (uint64_t)"builtin.unrealized_conversion_cast";
    void v17[3] = 34;
          " the dialect. See also https://mlir.llvm.org/getting_started/Faq/#registered-loaded-dependent-whats-up-with-di"
          "alects-management";
    __int16 v16 = 259;
    llvm::operator+(v17, (uint64_t *)&v15, (uint64_t)v20);
    llvm::report_fatal_error((llvm::Twine *)v20, 1);
  }
  mlir::OperationState::OperationState(v20, a2, v9);
  mlir::ValueRange::ValueRange(v19, a3, 1uLL);
  mlir::arith::CmpIOp::build((uint64_t)a1, (uint64_t)v20, v19[0], v19[1], *a4, a4[1], 0, 0);
  int32x2_t v11 = mlir::OpBuilder::create(a1, (const mlir::OperationState *)v20);
  if (*(_UNKNOWN **)(*((void *)v11 + 6) + 16) == &mlir::detail::TypeIDResolver<mlir::UnrealizedConversionCastOp,void>::id) {
    uint64_t v12 = v11;
  }
  else {
    uint64_t v12 = 0;
  }
  mlir::OperationState::~OperationState((mlir::OperationState *)v20);
  return v12;
}

uint64_t *llvm::DenseMapBase<llvm::DenseMap<mlir::Region *,std::unique_ptr<mlir::Region>,llvm::DenseMapInfo<mlir::Region *,void>,llvm::detail::DenseMapPair<mlir::Region *,std::unique_ptr<mlir::Region>>>,mlir::Region *,std::unique_ptr<mlir::Region>,llvm::DenseMapInfo<mlir::Region *,void>,llvm::detail::DenseMapPair<mlir::Region *,std::unique_ptr<mlir::Region>>>::InsertIntoBucket<mlir::Region * const&>(uint64_t a1, uint64_t *a2, uint64_t *a3)
{
  int v5 = *(_DWORD *)(a1 + 8);
  uint64_t v6 = *(unsigned int *)(a1 + 16);
  if (4 * v5 + 4 >= (3 * v6))
  {
    int v9 = 2 * v6;
  }
  else
  {
    if ((int)v6 + ~v5 - *(_DWORD *)(a1 + 12) > v6 >> 3)
    {
LABEL_3:
      uint64_t v7 = *a2;
      goto LABEL_4;
    }
    int v9 = *(_DWORD *)(a1 + 16);
  }
  char v10 = *(uint64_t **)a1;
  unint64_t v11 = (v9 - 1) | ((unint64_t)(v9 - 1) >> 1);
  unint64_t v12 = v11 | (v11 >> 2) | ((v11 | (v11 >> 2)) >> 4);
  int v13 = ((v12 | (v12 >> 8)) >> 16) | v12 | (v12 >> 8);
  if ((v13 + 1) > 0x40) {
    unsigned int v14 = v13 + 1;
  }
  else {
    unsigned int v14 = 64;
  }
  *(_DWORD *)(a1 + 16) = v14;
  buffer = llvm::allocate_buffer(16 * v14, (std::align_val_t)8uLL);
  *(void *)a1 = buffer;
  if (v10)
  {
    __int16 v16 = (char *)(16 * v6);
    llvm::DenseMapBase<llvm::DenseMap<mlir::Region *,std::unique_ptr<mlir::Region>,llvm::DenseMapInfo<mlir::Region *,void>,llvm::detail::DenseMapPair<mlir::Region *,std::unique_ptr<mlir::Region>>>,mlir::Region *,std::unique_ptr<mlir::Region>,llvm::DenseMapInfo<mlir::Region *,void>,llvm::detail::DenseMapPair<mlir::Region *,std::unique_ptr<mlir::Region>>>::moveFromOldBuckets(a1, v10, (uint64_t *)&v16[(void)v10]);
    llvm::deallocate_buffer((llvm *)v10, v16);
  }
  *(void *)(a1 + 8) = 0;
  uint64_t v17 = *(unsigned int *)(a1 + 16);
  __int16 v18 = buffer;
  if (((v17 - 1) & 0xFFFFFFFFFFFFFFFLL) == 0) {
    goto LABEL_34;
  }
  uint64_t v19 = ((v17 - 1) & 0xFFFFFFFFFFFFFFFLL) + 1;
  __int16 v18 = &buffer[2 * (v19 & 0x1FFFFFFFFFFFFFFELL)];
  uint64_t v20 = buffer + 2;
  uint64_t v21 = v19 & 0x1FFFFFFFFFFFFFFELL;
  do
  {
    *(v20 - 2) = -4096;
    void *v20 = -4096;
    v20 += 4;
    v21 -= 2;
  }
  while (v21);
  if (v19 != (v19 & 0x1FFFFFFFFFFFFFFELL))
  {
LABEL_34:
    do
    {
      *__int16 v18 = -4096;
      v18 += 2;
    }
    while (v18 != &buffer[2 * v17]);
  }
  uint64_t v7 = *a3;
  int v22 = v17 - 1;
  unsigned int v23 = ((*a3 >> 4) ^ (*a3 >> 9)) & v22;
  a2 = &buffer[2 * v23];
  uint64_t v24 = *a2;
  if (*a3 != *a2)
  {
    uint64_t v25 = 0;
    int v26 = 1;
    while (v24 != -4096)
    {
      if (v25) {
        BOOL v27 = 0;
      }
      else {
        BOOL v27 = v24 == -8192;
      }
      if (v27) {
        uint64_t v25 = a2;
      }
      unsigned int v28 = v23 + v26++;
      unsigned int v23 = v28 & v22;
      a2 = &buffer[2 * v23];
      uint64_t v24 = *a2;
      if (v7 == *a2) {
        goto LABEL_4;
      }
    }
    if (v25) {
      a2 = v25;
    }
    goto LABEL_3;
  }
LABEL_4:
  ++*(_DWORD *)(a1 + 8);
  if (v7 != -4096) {
    --*(_DWORD *)(a1 + 12);
  }
  *a2 = *a3;
  a2[1] = 0;
  return a2;
}

uint64_t llvm::DenseMapBase<llvm::DenseMap<mlir::Region *,std::unique_ptr<mlir::Region>,llvm::DenseMapInfo<mlir::Region *,void>,llvm::detail::DenseMapPair<mlir::Region *,std::unique_ptr<mlir::Region>>>,mlir::Region *,std::unique_ptr<mlir::Region>,llvm::DenseMapInfo<mlir::Region *,void>,llvm::detail::DenseMapPair<mlir::Region *,std::unique_ptr<mlir::Region>>>::moveFromOldBuckets(uint64_t result, uint64_t *a2, uint64_t *a3)
{
  __int32 v4 = a2;
  uint64_t v5 = result;
  *(void *)(result + 8) = 0;
  uint64_t v6 = *(unsigned int *)(result + 16);
  if (v6)
  {
    uint64_t v7 = *(void **)result;
    uint64_t v8 = (v6 - 1) & 0xFFFFFFFFFFFFFFFLL;
    if (v8)
    {
      uint64_t v9 = v8 + 1;
      uint64_t v10 = (v8 + 1) & 0x1FFFFFFFFFFFFFFELL;
      unint64_t v11 = &v7[2 * v10];
      unint64_t v12 = v7 + 2;
      uint64_t v13 = v10;
      do
      {
        *(v12 - 2) = -4096;
        *unint64_t v12 = -4096;
        v12 += 4;
        v13 -= 2;
      }
      while (v13);
      if (v9 == v10) {
        goto LABEL_10;
      }
    }
    else
    {
      unint64_t v11 = *(void **)result;
    }
    unsigned int v14 = &v7[2 * v6];
    do
    {
      *unint64_t v11 = -4096;
      v11 += 2;
    }
    while (v11 != v14);
  }
LABEL_10:
  if (a2 != a3)
  {
    do
    {
      uint64_t v15 = *v4;
      if ((*v4 | 0x1000) != 0xFFFFFFFFFFFFF000)
      {
        int v16 = *(_DWORD *)(v5 + 16) - 1;
        unsigned int v17 = v16 & ((v15 >> 4) ^ (v15 >> 9));
        __int16 v18 = (void *)(*(void *)v5 + 16 * v17);
        uint64_t v19 = *v18;
        if (v15 != *v18)
        {
          uint64_t v21 = 0;
          int v22 = 1;
          while (v19 != -4096)
          {
            if (v21) {
              BOOL v23 = 0;
            }
            else {
              BOOL v23 = v19 == -8192;
            }
            if (v23) {
              uint64_t v21 = v18;
            }
            unsigned int v24 = v17 + v22++;
            unsigned int v17 = v24 & v16;
            __int16 v18 = (void *)(*(void *)v5 + 16 * (v24 & v16));
            uint64_t v19 = *v18;
            if (v15 == *v18) {
              goto LABEL_15;
            }
          }
          if (v21) {
            __int16 v18 = v21;
          }
        }
LABEL_15:
        *__int16 v18 = v15;
        uint64_t v20 = v4[1];
        v4[1] = 0;
        v18[1] = v20;
        ++*(_DWORD *)(v5 + 8);
        uint64_t result = v4[1];
        v4[1] = 0;
        if (result)
        {
          mlir::Region::~Region((mlir::Region *)result);
          uint64_t result = MEMORY[0x21667D3C0]();
        }
      }
      v4 += 2;
    }
    while (v4 != a3);
  }
  return result;
}

void llvm::make_range<llvm::df_iterator<mlir::Block *,llvm::df_iterator_default_set<mlir::Block *,8u>,false,llvm::GraphTraits<mlir::Block *>>>(uint64_t a1@<X0>, uint64_t a2@<X1>, uint64_t a3@<X8>)
{
  llvm::SmallPtrSetImplBase::SmallPtrSetImplBase((uint64_t)&v11, &v13, 8, (uint64_t *)a1);
  long long __p = *(_OWORD *)(a1 + 96);
  uint64_t v15 = *(void *)(a1 + 112);
  *(void *)(a1 + 104) = 0;
  *(void *)(a1 + 112) = 0;
  *(void *)(a1 + 96) = 0;
  llvm::SmallPtrSetImplBase::SmallPtrSetImplBase((uint64_t)&v6, &v8, 8, (uint64_t *)a2);
  long long v9 = *(_OWORD *)(a2 + 96);
  uint64_t v10 = *(void *)(a2 + 112);
  *(void *)(a2 + 104) = 0;
  *(void *)(a2 + 112) = 0;
  *(void *)(a2 + 96) = 0;
  llvm::SmallPtrSetImplBase::SmallPtrSetImplBase(a3, (void *)(a3 + 32), 8, (uint64_t *)&v11);
  *(_OWORD *)(a3 + 96) = __p;
  *(void *)(a3 + 112) = v15;
  uint64_t v15 = 0;
  long long __p = 0uLL;
  llvm::SmallPtrSetImplBase::SmallPtrSetImplBase(a3 + 120, (void *)(a3 + 152), 8, (uint64_t *)&v6);
  *(_OWORD *)(a3 + 216) = v9;
  *(void *)(a3 + 232) = v10;
  uint64_t v10 = 0;
  long long v9 = 0uLL;
  if (v7 != v6) {
    free(v7);
  }
  if ((void)__p)
  {
    *((void *)&__p + 1) = __p;
    operator delete((void *)__p);
  }
  if (v12 != v11) {
    free(v12);
  }
}

void llvm::depth_first<mlir::Block *>(uint64_t *a1@<X0>, uint64_t a2@<X8>)
{
  uint64_t v3 = *a1;
  uint64_t v13 = v17;
  unsigned int v14 = v17;
  int v16 = 0;
  uint64_t v15 = 0x100000008;
  v17[0] = v3;
  __int32 v4 = (char *)operator new(0x20uLL);
  *(void *)__int32 v4 = v3;
  v4[8] = 0;
  v4[24] = 0;
  uint64_t v19 = v4 + 32;
  uint64_t v20 = v4 + 32;
  __int16 v18 = v4;
  memset(v8, 0, sizeof(v8));
  uint64_t v9 = 0;
  long long __p = 0;
  uint64_t v5 = (char *)v8 + 8;
  uint64_t v6 = (char *)v8 + 8;
  uint64_t v7 = 8;
  unint64_t v11 = 0;
  uint64_t v12 = 0;
  llvm::make_range<llvm::df_iterator<mlir::Block *,llvm::df_iterator_default_set<mlir::Block *,8u>,false,llvm::GraphTraits<mlir::Block *>>>((uint64_t)&v13, (uint64_t)&v5, a2);
  if (__p)
  {
    unint64_t v11 = __p;
    operator delete(__p);
  }
  if (v6 != v5) {
    free(v6);
  }
  if (v18)
  {
    uint64_t v19 = v18;
    operator delete(v18);
  }
  if (v14 != v13) {
    free(v14);
  }
}

void llvm::make_pointee_range<llvm::iterator_range<llvm::df_iterator<mlir::Block *,llvm::df_iterator_default_set<mlir::Block *,8u>,false,llvm::GraphTraits<mlir::Block *>>> &,llvm::df_iterator<mlir::Block *,llvm::df_iterator_default_set<mlir::Block *,8u>,false,llvm::GraphTraits<mlir::Block *>>>(llvm::SmallPtrSetImplBase *a1@<X0>, uint64_t a2@<X8>)
{
  llvm::SmallPtrSetImplBase::SmallPtrSetImplBase((llvm::SmallPtrSetImplBase *)&v24, &v26, a1);
  long long v27 = 0uLL;
  unsigned int v28 = 0;
  uint64_t v5 = (unsigned char *)*((void *)a1 + 12);
  __int32 v4 = (unsigned char *)*((void *)a1 + 13);
  uint64_t v6 = v4 - v5;
  if (v4 != v5)
  {
    if (v6 < 0) {
      goto LABEL_28;
    }
    uint64_t v7 = (char *)operator new(v4 - v5);
    *(void *)&long long v27 = v7;
    *((void *)&v27 + 1) = v7;
    unsigned int v28 = &v7[32 * (v6 >> 5)];
    size_t v8 = v6 & 0xFFFFFFFFFFFFFFE0;
    memcpy(v7, v5, v8);
    *((void *)&v27 + 1) = &v7[v8];
  }
  llvm::SmallPtrSetImplBase::SmallPtrSetImplBase((uint64_t)&v34, v36, 8, (uint64_t *)&v24);
  long long v37 = v27;
  uint64_t v38 = v28;
  unsigned int v28 = 0;
  long long v27 = 0uLL;
  llvm::SmallPtrSetImplBase::SmallPtrSetImplBase((uint64_t)&v29, &v31, 8, (uint64_t *)&v34);
  long long v32 = v37;
  int v33 = v38;
  uint64_t v38 = 0;
  long long v37 = 0uLL;
  if (v35 != v34) {
    free(v35);
  }
  llvm::SmallPtrSetImplBase::SmallPtrSetImplBase((llvm::SmallPtrSetImplBase *)&v14, &v16, (llvm::SmallPtrSetImplBase *)((char *)a1 + 120));
  v17[0] = 0;
  v17[1] = 0;
  __int16 v18 = 0;
  uint64_t v10 = (unsigned char *)*((void *)a1 + 27);
  uint64_t v9 = (unsigned char *)*((void *)a1 + 28);
  uint64_t v11 = v9 - v10;
  if (v9 != v10)
  {
    if ((v11 & 0x8000000000000000) == 0)
    {
      uint64_t v12 = (char *)operator new(v9 - v10);
      v17[0] = v12;
      v17[1] = v12;
      __int16 v18 = &v12[32 * (v11 >> 5)];
      size_t v13 = v11 & 0xFFFFFFFFFFFFFFE0;
      memcpy(v12, v10, v13);
      v17[1] = &v12[v13];
      goto LABEL_9;
    }
LABEL_28:
    abort();
  }
LABEL_9:
  llvm::SmallPtrSetImplBase::SmallPtrSetImplBase((uint64_t)&v34, v36, 8, (uint64_t *)&v14);
  long long v37 = *(_OWORD *)v17;
  uint64_t v38 = v18;
  v17[1] = 0;
  __int16 v18 = 0;
  v17[0] = 0;
  llvm::SmallPtrSetImplBase::SmallPtrSetImplBase((uint64_t)&v19, &v21, 8, (uint64_t *)&v34);
  long long __p = v37;
  BOOL v23 = v38;
  uint64_t v38 = 0;
  long long v37 = 0uLL;
  if (v35 != v34) {
    free(v35);
  }
  llvm::make_range<llvm::df_iterator<mlir::Block *,llvm::df_iterator_default_set<mlir::Block *,8u>,false,llvm::GraphTraits<mlir::Block *>>>((uint64_t)&v29, (uint64_t)&v19, a2);
  if ((void)__p)
  {
    *((void *)&__p + 1) = __p;
    operator delete((void *)__p);
  }
  if (v20 != v19) {
    free(v20);
  }
  if (v17[0])
  {
    v17[1] = v17[0];
    operator delete(v17[0]);
  }
  if (v15 != v14) {
    free(v15);
  }
  if ((void)v32)
  {
    *((void *)&v32 + 1) = v32;
    operator delete((void *)v32);
  }
  if (v30 != v29) {
    free(v30);
  }
  if ((void)v27)
  {
    *((void *)&v27 + 1) = v27;
    operator delete((void *)v27);
  }
  if (v25 != v24) {
    free(v25);
  }
}

void *std::__function::__func<composeLegalityCallbacks(std::function<std::optional<BOOL> ()(mlir::Operation *)>,std::function<std::optional<BOOL> ()(mlir::Operation *)>)::$_0,std::allocator<composeLegalityCallbacks(std::function<std::optional<BOOL> ()(mlir::Operation *)>,std::function<std::optional<BOOL> ()(mlir::Operation *)>)::$_0>,std::optional<BOOL> ()(mlir::Operation *)>::~__func(void *a1)
{
  *a1 = &unk_26C381C68;
  uint64_t v2 = a1 + 1;
  uint64_t v3 = a1 + 5;
  __int32 v4 = (void *)a1[8];
  if (v4 != v3)
  {
    if (v4) {
      (*(void (**)(void *))(*v4 + 40))(v4);
    }
    uint64_t v5 = (void *)a1[4];
    if (v5 != v2) {
      goto LABEL_5;
    }
LABEL_9:
    (*(void (**)(void *))(*v2 + 32))(v2);
    return a1;
  }
  (*(void (**)(void *))(*v3 + 32))(v3);
  uint64_t v5 = (void *)a1[4];
  if (v5 == v2) {
    goto LABEL_9;
  }
LABEL_5:
  if (v5) {
    (*(void (**)(void *))(*v5 + 40))(v5);
  }
  return a1;
}

void std::__function::__func<composeLegalityCallbacks(std::function<std::optional<BOOL> ()(mlir::Operation *)>,std::function<std::optional<BOOL> ()(mlir::Operation *)>)::$_0,std::allocator<composeLegalityCallbacks(std::function<std::optional<BOOL> ()(mlir::Operation *)>,std::function<std::optional<BOOL> ()(mlir::Operation *)>)::$_0>,std::optional<BOOL> ()(mlir::Operation *)>::~__func(void *a1)
{
  *a1 = &unk_26C381C68;
  uint64_t v2 = a1 + 1;
  uint64_t v3 = a1 + 5;
  __int32 v4 = (void *)a1[8];
  if (v4 == v3)
  {
    (*(void (**)(void *))(*v3 + 32))(v3);
    uint64_t v5 = (void *)a1[4];
    if (v5 != v2)
    {
LABEL_5:
      if (v5) {
        (*(void (**)(void *))(*v5 + 40))(v5);
      }
LABEL_9:
      JUMPOUT(0x21667D3C0);
    }
  }
  else
  {
    if (v4) {
      (*(void (**)(void *))(*v4 + 40))(v4);
    }
    uint64_t v5 = (void *)a1[4];
    if (v5 != v2) {
      goto LABEL_5;
    }
  }
  (*(void (**)(void *))(*v2 + 32))(v2);
  goto LABEL_9;
}

void *std::__function::__func<composeLegalityCallbacks(std::function<std::optional<BOOL> ()(mlir::Operation *)>,std::function<std::optional<BOOL> ()(mlir::Operation *)>)::$_0,std::allocator<composeLegalityCallbacks(std::function<std::optional<BOOL> ()(mlir::Operation *)>,std::function<std::optional<BOOL> ()(mlir::Operation *)>)::$_0>,std::optional<BOOL> ()(mlir::Operation *)>::__clone(uint64_t a1)
{
  uint64_t v2 = operator new(0x48uLL);
  *uint64_t v2 = &unk_26C381C68;
  uint64_t v3 = v2 + 1;
  uint64_t v4 = *(void *)(a1 + 32);
  if (!v4)
  {
    v2[4] = 0;
    uint64_t v5 = *(void *)(a1 + 64);
    if (v5) {
      goto LABEL_6;
    }
LABEL_10:
    v2[8] = 0;
    return v2;
  }
  if (v4 == a1 + 8)
  {
    v2[4] = v3;
    (*(void (**)(uint64_t))(*(void *)v4 + 24))(v4);
    uint64_t v5 = *(void *)(a1 + 64);
    if (v5) {
      goto LABEL_6;
    }
    goto LABEL_10;
  }
  v2[4] = (*(uint64_t (**)(uint64_t, void *))(*(void *)v4 + 16))(v4, v3);
  uint64_t v5 = *(void *)(a1 + 64);
  if (!v5) {
    goto LABEL_10;
  }
LABEL_6:
  if (v5 == a1 + 40)
  {
    v2[8] = v2 + 5;
    (*(void (**)(uint64_t))(*(void *)v5 + 24))(v5);
  }
  else
  {
    v2[8] = (*(uint64_t (**)(uint64_t))(*(void *)v5 + 16))(v5);
  }
  return v2;
}

uint64_t std::__function::__func<composeLegalityCallbacks(std::function<std::optional<BOOL> ()(mlir::Operation *)>,std::function<std::optional<BOOL> ()(mlir::Operation *)>)::$_0,std::allocator<composeLegalityCallbacks(std::function<std::optional<BOOL> ()(mlir::Operation *)>,std::function<std::optional<BOOL> ()(mlir::Operation *)>)::$_0>,std::optional<BOOL> ()(mlir::Operation *)>::__clone(uint64_t a1, void *a2)
{
  *a2 = &unk_26C381C68;
  uint64_t v4 = a2 + 1;
  uint64_t v5 = *(void *)(a1 + 32);
  if (!v5)
  {
    a2[4] = 0;
    uint64_t result = *(void *)(a1 + 64);
    if (result) {
      goto LABEL_6;
    }
    goto LABEL_9;
  }
  if (v5 == a1 + 8)
  {
    a2[4] = v4;
    (*(void (**)(void))(**(void **)(a1 + 32) + 24))(*(void *)(a1 + 32));
    uint64_t result = *(void *)(a1 + 64);
    if (result) {
      goto LABEL_6;
    }
LABEL_9:
    a2[8] = 0;
    return result;
  }
  a2[4] = (*(uint64_t (**)(uint64_t, void *))(*(void *)v5 + 16))(v5, v4);
  uint64_t result = *(void *)(a1 + 64);
  if (!result) {
    goto LABEL_9;
  }
LABEL_6:
  if (result == a1 + 40)
  {
    a2[8] = a2 + 5;
    uint64_t v7 = *(uint64_t (**)(void))(**(void **)(a1 + 64) + 24);
    return v7();
  }
  else
  {
    uint64_t result = (*(uint64_t (**)(uint64_t))(*(void *)result + 16))(result);
    a2[8] = result;
  }
  return result;
}

uint64_t std::__function::__func<composeLegalityCallbacks(std::function<std::optional<BOOL> ()(mlir::Operation *)>,std::function<std::optional<BOOL> ()(mlir::Operation *)>)::$_0,std::allocator<composeLegalityCallbacks(std::function<std::optional<BOOL> ()(mlir::Operation *)>,std::function<std::optional<BOOL> ()(mlir::Operation *)>)::$_0>,std::optional<BOOL> ()(mlir::Operation *)>::destroy(uint64_t a1)
{
  uint64_t v2 = a1 + 8;
  uint64_t v3 = a1 + 40;
  uint64_t v4 = *(void *)(a1 + 64);
  if (v4 == v3)
  {
    (*(void (**)(uint64_t))(*(void *)v3 + 32))(v3);
    uint64_t result = *(void *)(a1 + 32);
    if (result != v2)
    {
LABEL_5:
      if (result)
      {
        uint64_t v6 = *(uint64_t (**)(void))(*(void *)result + 40);
        return v6();
      }
      return result;
    }
  }
  else
  {
    if (v4) {
      (*(void (**)(uint64_t))(*(void *)v4 + 40))(v4);
    }
    uint64_t result = *(void *)(a1 + 32);
    if (result != v2) {
      goto LABEL_5;
    }
  }
  uint64_t v7 = *(uint64_t (**)(uint64_t))(*(void *)v2 + 32);

  return v7(v2);
}

void std::__function::__func<composeLegalityCallbacks(std::function<std::optional<BOOL> ()(mlir::Operation *)>,std::function<std::optional<BOOL> ()(mlir::Operation *)>)::$_0,std::allocator<composeLegalityCallbacks(std::function<std::optional<BOOL> ()(mlir::Operation *)>,std::function<std::optional<BOOL> ()(mlir::Operation *)>)::$_0>,std::optional<BOOL> ()(mlir::Operation *)>::destroy_deallocate(char *__p)
{
  uint64_t v2 = __p + 8;
  uint64_t v3 = __p + 40;
  uint64_t v4 = (char *)*((void *)__p + 8);
  if (v4 == v3)
  {
    (*(void (**)(char *))(*(void *)v3 + 32))(v3);
    uint64_t v5 = (char *)*((void *)__p + 4);
    if (v5 != v2)
    {
LABEL_5:
      if (v5) {
        (*(void (**)(char *))(*(void *)v5 + 40))(v5);
      }
      uint64_t v6 = __p;
      goto LABEL_9;
    }
  }
  else
  {
    if (v4) {
      (*(void (**)(char *))(*(void *)v4 + 40))(v4);
    }
    uint64_t v5 = (char *)*((void *)__p + 4);
    if (v5 != v2) {
      goto LABEL_5;
    }
  }
  (*(void (**)(char *))(*(void *)v2 + 32))(v2);
  uint64_t v6 = __p;

LABEL_9:
  operator delete(v6);
}

uint64_t std::__function::__func<composeLegalityCallbacks(std::function<std::optional<BOOL> ()(mlir::Operation *)>,std::function<std::optional<BOOL> ()(mlir::Operation *)>)::$_0,std::allocator<composeLegalityCallbacks(std::function<std::optional<BOOL> ()(mlir::Operation *)>,std::function<std::optional<BOOL> ()(mlir::Operation *)>)::$_0>,std::optional<BOOL> ()(mlir::Operation *)>::operator()(uint64_t a1, uint64_t *a2)
{
  uint64_t v3 = *a2;
  uint64_t v10 = *a2;
  uint64_t v4 = *(void *)(a1 + 64);
  if (v4)
  {
    unsigned __int16 v5 = (*(uint64_t (**)(uint64_t, uint64_t *))(*(void *)v4 + 48))(v4, &v10);
    if (v5 > 0xFFu) {
      return v5 | 0x100u;
    }
    uint64_t v10 = v3;
    uint64_t v6 = *(void *)(a1 + 32);
    if (v6)
    {
      __int16 v7 = (*(uint64_t (**)(uint64_t, uint64_t *))(*(void *)v6 + 48))(v6, &v10);
      return v7 | (HIBYTE(v7) << 8);
    }
  }
  uint64_t v9 = std::__throw_bad_function_call[abi:nn180100]();
  return std::__function::__func<composeLegalityCallbacks(std::function<std::optional<BOOL> ()(mlir::Operation *)>,std::function<std::optional<BOOL> ()(mlir::Operation *)>)::$_0,std::allocator<composeLegalityCallbacks(std::function<std::optional<BOOL> ()(mlir::Operation *)>,std::function<std::optional<BOOL> ()(mlir::Operation *)>)::$_0>,std::optional<BOOL> ()(mlir::Operation *)>::target(v9);
}

uint64_t std::__function::__func<composeLegalityCallbacks(std::function<std::optional<BOOL> ()(mlir::Operation *)>,std::function<std::optional<BOOL> ()(mlir::Operation *)>)::$_0,std::allocator<composeLegalityCallbacks(std::function<std::optional<BOOL> ()(mlir::Operation *)>,std::function<std::optional<BOOL> ()(mlir::Operation *)>)::$_0>,std::optional<BOOL> ()(mlir::Operation *)>::target(uint64_t a1, uint64_t a2)
{
  unint64_t v3 = *(void *)(a2 + 8);
  if ((char *)v3 == "ZL24composeLegalityCallbacksNSt3__18functionIFNS_8optionalIbEEPN4mlir9OperationEEEES7_E3$_0") {
    return a1 + 8;
  }
  if (((v3 & (unint64_t)"ZL24composeLegalityCallbacksNSt3__18functionIFNS_8optionalIbEEPN4mlir9OperationEEEES7_E3$_0" & 0x8000000000000000) != 0) == __OFSUB__(v3, "ZL24composeLegalityCallbacksNSt3__18functionIFNS_8optionalIbEEPN4mlir9OperationEEEES7_E3$_0"))return 0; {
  if (!strcmp((const char *)(v3 & 0x7FFFFFFFFFFFFFFFLL), (const char *)((unint64_t)"ZL24composeLegalityCallbacksNSt3__18functionIFNS_8optionalIbEEPN4mlir9OperationEEEES7_E3$_0" & 0x7FFFFFFFFFFFFFFFLL)))return a1 + 8;
  }
  return 0;
}

void *std::__function::__func<composeLegalityCallbacks(std::function<std::optional<BOOL> ()(mlir::Operation *)>,std::function<std::optional<BOOL> ()(mlir::Operation *)>)::$_0,std::allocator<composeLegalityCallbacks(std::function<std::optional<BOOL> ()(mlir::Operation *)>,std::function<std::optional<BOOL> ()(mlir::Operation *)>)::$_0>,std::optional<BOOL> ()(mlir::Operation *)>::target_type()
{
}

void llvm::function_ref<void ()(mlir::Pattern const&)>::callback_fn<anonymous namespace'::OperationLegalizer::buildLegalizationGraph(llvm::SmallVector<mlir::Pattern const*,1u> &,llvm::DenseMap<mlir::OperationName,llvm::SmallVector<mlir::Pattern const*,1u>,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,llvm::SmallVector<mlir::Pattern const*,1u>>> &)::$_0>(uint64_t *a1, uint64_t a2)
{
  uint64_t v58 = *MEMORY[0x263EF8340];
  uint64_t v4 = a1[1];
  BOOL v5 = *(_DWORD *)(a2 + 8) == 1;
  uint64_t v6 = *(void *)a2;
  if (v5) {
    __int16 v7 = (void *)v6;
  }
  else {
    __int16 v7 = 0;
  }
  v52[0] = v7;
  v52[1] = (void *)v5;
  if (!v5)
  {
    uint64_t v9 = *a1;
    uint64_t v10 = *(unsigned int *)(*a1 + 8);
    if (v10 >= *(_DWORD *)(*a1 + 12))
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod(*a1, (void *)(v9 + 16), v10 + 1, 8);
      LODWORD(v10) = *(_DWORD *)(v9 + 8);
    }
    *(void *)(*(void *)v9 + 8 * v10) = a2;
    ++*(_DWORD *)(v9 + 8);
    return;
  }
  mlir::ConversionTarget::getOpInfo(*(void *)(v4 + 96), v6, (uint64_t)&v53);
  if (!v57)
  {
LABEL_16:
    uint64_t v11 = a1[2];
    int v12 = *(_DWORD *)(v11 + 16);
    if (v12)
    {
      int v13 = v12 - 1;
      unsigned int v14 = ((LODWORD(v52[0]) >> 4) ^ (LODWORD(v52[0]) >> 9)) & v13;
      uint64_t v15 = (char *)(*(void *)v11 + 56 * v14);
      int v16 = *(void **)v15;
      if (v52[0] == *(void **)v15)
      {
LABEL_29:
        uint64_t v22 = *((void *)v15 + 2);
        if (v22 != *((void *)v15 + 1)) {
          goto LABEL_30;
        }
        uint64_t v47 = *((unsigned int *)v15 + 7);
        if (v47)
        {
          uint64_t v48 = 0;
          uint64_t v49 = 8 * v47;
          int v50 = (uint64_t *)*((void *)v15 + 2);
          while (*v50 != a2)
          {
            if (*v50 == -2) {
              uint64_t v48 = v50;
            }
            ++v50;
            v49 -= 8;
            if (!v49)
            {
              if (!v48) {
                goto LABEL_75;
              }
              *uint64_t v48 = a2;
              --*((_DWORD *)v15 + 8);
              goto LABEL_31;
            }
          }
          goto LABEL_31;
        }
LABEL_75:
        if (v47 < *((_DWORD *)v15 + 6))
        {
          *((_DWORD *)v15 + 7) = v47 + 1;
          *(void *)(v22 + 8 * v47) = a2;
        }
        else
        {
LABEL_30:
          llvm::SmallPtrSetImplBase::insert_imp_big((llvm::SmallPtrSetImplBase *)(v15 + 8), (const void *)a2);
        }
LABEL_31:
        uint64_t v23 = *(unsigned int *)(a2 + 32);
        if (!v23)
        {
LABEL_62:
          unint64_t v44 = (int64x2_t *)a1[4];
          uint64_t v51 = a2;
          llvm::DenseMapBase<llvm::DenseMap<mlir::Block *,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::Block *,void>,llvm::detail::DenseSetPair<mlir::Block *>>,mlir::Block *,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::Block *,void>,llvm::detail::DenseSetPair<mlir::Block *>>::try_emplace<llvm::detail::DenseSetEmpty&>(v44, &v51, (uint64_t)&v53);
          if (v55)
          {
            uint64_t v45 = v51;
            uint64_t v46 = v44[2].u32[0];
            if (v46 >= v44[2].i32[1])
            {
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v44[1].i64[1], &v44[2].u64[1], v46 + 1, 8);
              LODWORD(v46) = v44[2].i32[0];
            }
            *(void *)(v44[1].i64[1] + 8 * v46) = v45;
            ++v44[2].i32[0];
          }
          return;
        }
        unsigned int v24 = *(uint64_t **)(a2 + 24);
        uint64_t v25 = &v24[v23];
        while (1)
        {
          uint64_t v26 = *v24;
          uint64_t v53 = *v24;
          uint64_t v27 = a1[3];
          int v28 = *(_DWORD *)(v27 + 16);
          if (!v28) {
            break;
          }
          int v29 = v28 - 1;
          unsigned int v30 = v29 & ((v26 >> 4) ^ (v26 >> 9));
          uint64_t v31 = (char *)(*(void *)v27 + 56 * v30);
          uint64_t v32 = *(void *)v31;
          if (*(void *)v31 != v26)
          {
            int v33 = 0;
            int v34 = 1;
            while (v32 != -4096)
            {
              if (v33) {
                BOOL v35 = 0;
              }
              else {
                BOOL v35 = v32 == -8192;
              }
              if (v35) {
                int v33 = v31;
              }
              unsigned int v36 = v30 + v34++;
              unsigned int v30 = v36 & v29;
              uint64_t v31 = (char *)(*(void *)v27 + 56 * v30);
              uint64_t v32 = *(void *)v31;
              if (*(void *)v31 == v26) {
                goto LABEL_48;
              }
            }
            if (v33) {
              long long v37 = v33;
            }
            else {
              long long v37 = v31;
            }
            goto LABEL_47;
          }
LABEL_48:
          uint64_t v38 = *((void *)v31 + 2);
          int v39 = v52[0];
          if (v38 != *((void *)v31 + 1)) {
            goto LABEL_33;
          }
          uint64_t v40 = *((unsigned int *)v31 + 7);
          if (v40)
          {
            BOOL v41 = 0;
            uint64_t v42 = 8 * v40;
            unint64_t v43 = (void **)*((void *)v31 + 2);
            while (*v43 != v52[0])
            {
              if (*v43 == (void *)-2) {
                BOOL v41 = v43;
              }
              ++v43;
              v42 -= 8;
              if (!v42)
              {
                if (!v41) {
                  goto LABEL_57;
                }
                *BOOL v41 = v52[0];
                --*((_DWORD *)v31 + 8);
                goto LABEL_34;
              }
            }
            goto LABEL_34;
          }
LABEL_57:
          if (v40 < *((_DWORD *)v31 + 6))
          {
            *((_DWORD *)v31 + 7) = v40 + 1;
            *(void *)(v38 + 8 * v40) = v39;
          }
          else
          {
LABEL_33:
            llvm::SmallPtrSetImplBase::insert_imp_big((llvm::SmallPtrSetImplBase *)(v31 + 8), v52[0]);
          }
LABEL_34:
          if (++v24 == v25) {
            goto LABEL_62;
          }
        }
        long long v37 = 0;
LABEL_47:
        uint64_t v31 = llvm::DenseMapBase<llvm::DenseMap<mlir::OperationName,llvm::SmallPtrSet<mlir::OperationName,2u>,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,llvm::SmallPtrSet<mlir::OperationName,2u>>>,mlir::OperationName,llvm::SmallPtrSet<mlir::OperationName,2u>,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,llvm::SmallPtrSet<mlir::OperationName,2u>>>::InsertIntoBucket<mlir::OperationName const&>(a1[3], v37, &v53);
        goto LABEL_48;
      }
      unsigned int v17 = 0;
      int v18 = 1;
      while (v16 != (void *)-4096)
      {
        if (v17) {
          BOOL v19 = 0;
        }
        else {
          BOOL v19 = v16 == (void *)-8192;
        }
        if (v19) {
          unsigned int v17 = v15;
        }
        unsigned int v20 = v14 + v18++;
        unsigned int v14 = v20 & v13;
        uint64_t v15 = (char *)(*(void *)v11 + 56 * v14);
        int v16 = *(void **)v15;
        if (v52[0] == *(void **)v15) {
          goto LABEL_29;
        }
      }
      if (v17) {
        uint64_t v21 = v17;
      }
      else {
        uint64_t v21 = v15;
      }
    }
    else
    {
      uint64_t v21 = 0;
    }
    uint64_t v15 = llvm::DenseMapBase<llvm::DenseMap<mlir::OperationName,llvm::SmallPtrSet<mlir::OperationName,2u>,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,llvm::SmallPtrSet<mlir::OperationName,2u>>>,mlir::OperationName,llvm::SmallPtrSet<mlir::OperationName,2u>,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,llvm::SmallPtrSet<mlir::OperationName,2u>>>::InsertIntoBucket<mlir::OperationName const&>(a1[2], v21, (uint64_t *)v52);
    goto LABEL_29;
  }
  int v8 = v53;
  if (v56 == &v54)
  {
    (*(void (**)(uint64_t *))(v54 + 32))(&v54);
    if (!v8) {
      return;
    }
    goto LABEL_16;
  }
  if (v56) {
    (*(void (**)(void))(*v56 + 40))();
  }
  if (v8) {
    goto LABEL_16;
  }
}

char *llvm::DenseMapBase<llvm::DenseMap<mlir::OperationName,llvm::SmallPtrSet<mlir::OperationName,2u>,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,llvm::SmallPtrSet<mlir::OperationName,2u>>>,mlir::OperationName,llvm::SmallPtrSet<mlir::OperationName,2u>,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,llvm::SmallPtrSet<mlir::OperationName,2u>>>::InsertIntoBucket<mlir::OperationName const&>(uint64_t a1, char *a2, uint64_t *a3)
{
  int v5 = *(_DWORD *)(a1 + 8);
  uint64_t v6 = *(unsigned int *)(a1 + 16);
  if (4 * v5 + 4 >= (3 * v6))
  {
    int v9 = 2 * v6;
  }
  else
  {
    if ((int)v6 + ~v5 - *(_DWORD *)(a1 + 12) > v6 >> 3)
    {
LABEL_3:
      uint64_t v7 = *(void *)a2;
      goto LABEL_4;
    }
    int v9 = *(_DWORD *)(a1 + 16);
  }
  uint64_t v10 = *(uint64_t **)a1;
  unint64_t v11 = (v9 - 1) | ((unint64_t)(v9 - 1) >> 1);
  unint64_t v12 = v11 | (v11 >> 2) | ((v11 | (v11 >> 2)) >> 4);
  int v13 = ((v12 | (v12 >> 8)) >> 16) | v12 | (v12 >> 8);
  if ((v13 + 1) > 0x40) {
    unsigned int v14 = v13 + 1;
  }
  else {
    unsigned int v14 = 64;
  }
  *(_DWORD *)(a1 + 16) = v14;
  buffer = llvm::allocate_buffer(56 * v14, (std::align_val_t)8uLL);
  *(void *)a1 = buffer;
  if (v10)
  {
    uint64_t v16 = 7 * v6;
    llvm::DenseMapBase<llvm::DenseMap<mlir::OperationName,llvm::SmallPtrSet<mlir::OperationName,2u>,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,llvm::SmallPtrSet<mlir::OperationName,2u>>>,mlir::OperationName,llvm::SmallPtrSet<mlir::OperationName,2u>,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,llvm::SmallPtrSet<mlir::OperationName,2u>>>::moveFromOldBuckets(a1, v10, &v10[v16]);
    llvm::deallocate_buffer((llvm *)v10, (void *)(v16 * 8));
  }
  *(void *)(a1 + 8) = 0;
  uint64_t v17 = *(unsigned int *)(a1 + 16);
  unint64_t v18 = 56 * v17 - 56;
  BOOL v19 = buffer;
  if (v18 < 0x38) {
    goto LABEL_34;
  }
  unint64_t v20 = v18 / 0x38 + 1;
  BOOL v19 = &buffer[7 * (v20 & 0xFFFFFFFFFFFFFFELL)];
  uint64_t v21 = v20 & 0xFFFFFFFFFFFFFFELL;
  uint64_t v22 = buffer;
  do
  {
    *uint64_t v22 = -4096;
    v22[7] = -4096;
    v22 += 14;
    v21 -= 2;
  }
  while (v21);
  if (v20 != (v20 & 0xFFFFFFFFFFFFFFELL))
  {
LABEL_34:
    do
    {
      *BOOL v19 = -4096;
      v19 += 7;
    }
    while (v19 != &buffer[7 * v17]);
  }
  uint64_t v7 = *a3;
  int v23 = v17 - 1;
  unsigned int v24 = ((*a3 >> 4) ^ (*a3 >> 9)) & v23;
  a2 = (char *)&buffer[7 * v24];
  uint64_t v25 = *(void *)a2;
  if (*a3 != *(void *)a2)
  {
    uint64_t v26 = 0;
    int v27 = 1;
    while (v25 != -4096)
    {
      if (v26) {
        BOOL v28 = 0;
      }
      else {
        BOOL v28 = v25 == -8192;
      }
      if (v28) {
        uint64_t v26 = a2;
      }
      unsigned int v29 = v24 + v27++;
      unsigned int v24 = v29 & v23;
      a2 = (char *)&buffer[7 * v24];
      uint64_t v25 = *(void *)a2;
      if (v7 == *(void *)a2) {
        goto LABEL_4;
      }
    }
    if (v26) {
      a2 = v26;
    }
    goto LABEL_3;
  }
LABEL_4:
  ++*(_DWORD *)(a1 + 8);
  if (v7 != -4096) {
    --*(_DWORD *)(a1 + 12);
  }
  *(void *)a2 = *a3;
  *((void *)a2 + 1) = a2 + 40;
  *((void *)a2 + 2) = a2 + 40;
  *((void *)a2 + 3) = 2;
  *((_DWORD *)a2 + 8) = 0;
  return a2;
}

void llvm::DenseMapBase<llvm::DenseMap<mlir::OperationName,llvm::SmallPtrSet<mlir::OperationName,2u>,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,llvm::SmallPtrSet<mlir::OperationName,2u>>>,mlir::OperationName,llvm::SmallPtrSet<mlir::OperationName,2u>,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,llvm::SmallPtrSet<mlir::OperationName,2u>>>::moveFromOldBuckets(uint64_t a1, uint64_t *a2, uint64_t *a3)
{
  uint64_t v4 = a2;
  *(void *)(a1 + 8) = 0;
  unsigned int v6 = *(_DWORD *)(a1 + 16);
  if (v6)
  {
    uint64_t v7 = *(void **)a1;
    unint64_t v8 = 56 * v6 - 56;
    if (v8 < 0x38)
    {
      int v9 = *(void **)a1;
LABEL_7:
      int v13 = &v7[7 * v6];
      do
      {
        *int v9 = -4096;
        v9 += 7;
      }
      while (v9 != v13);
      goto LABEL_9;
    }
    unint64_t v10 = v8 / 0x38 + 1;
    int v9 = &v7[7 * (v10 & 0xFFFFFFFFFFFFFFELL)];
    uint64_t v11 = v10 & 0xFFFFFFFFFFFFFFELL;
    unint64_t v12 = *(void **)a1;
    do
    {
      *unint64_t v12 = -4096;
      void v12[7] = -4096;
      v12 += 14;
      v11 -= 2;
    }
    while (v11);
    if (v10 != (v10 & 0xFFFFFFFFFFFFFFELL)) {
      goto LABEL_7;
    }
  }
LABEL_9:
  if (a2 != a3)
  {
    do
    {
      uint64_t v14 = *v4;
      if ((*v4 | 0x1000) != 0xFFFFFFFFFFFFF000)
      {
        int v15 = *(_DWORD *)(a1 + 16);
        if (v15)
        {
          int v16 = v15 - 1;
          unsigned int v17 = v16 & ((v14 >> 4) ^ (v14 >> 9));
          unint64_t v18 = (void *)(*(void *)a1 + 56 * v17);
          uint64_t v19 = *v18;
          if (v14 != *v18)
          {
            unint64_t v20 = 0;
            int v21 = 1;
            while (v19 != -4096)
            {
              if (v20) {
                BOOL v22 = 0;
              }
              else {
                BOOL v22 = v19 == -8192;
              }
              if (v22) {
                unint64_t v20 = v18;
              }
              unsigned int v23 = v17 + v21++;
              unsigned int v17 = v23 & v16;
              unint64_t v18 = (void *)(*(void *)a1 + 56 * v17);
              uint64_t v19 = *v18;
              if (v14 == *v18) {
                goto LABEL_25;
              }
            }
            if (v20) {
              unint64_t v18 = v20;
            }
          }
        }
        else
        {
          unint64_t v18 = 0;
        }
LABEL_25:
        *unint64_t v18 = v14;
        llvm::SmallPtrSetImplBase::SmallPtrSetImplBase((uint64_t)(v18 + 1), v18 + 5, 2, v4 + 1);
        ++*(_DWORD *)(a1 + 8);
        unsigned int v24 = (void *)v4[2];
        if (v24 != (void *)v4[1]) {
          free(v24);
        }
      }
      v4 += 7;
    }
    while (v4 != a3);
  }
}

uint64_t *llvm::DenseMapBase<llvm::DenseMap<mlir::OperationName,llvm::SmallVector<mlir::Pattern const*,1u>,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,llvm::SmallVector<mlir::Pattern const*,1u>>>,mlir::OperationName,llvm::SmallVector<mlir::Pattern const*,1u>,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,llvm::SmallVector<mlir::Pattern const*,1u>>>::InsertIntoBucket<mlir::OperationName>(uint64_t a1, uint64_t *a2, uint64_t *a3)
{
  int v5 = *(_DWORD *)(a1 + 8);
  uint64_t v6 = *(unsigned int *)(a1 + 16);
  if (4 * v5 + 4 >= (3 * v6))
  {
    int v9 = 2 * v6;
  }
  else
  {
    if ((int)v6 + ~v5 - *(_DWORD *)(a1 + 12) > v6 >> 3)
    {
LABEL_3:
      uint64_t v7 = *a2;
      goto LABEL_4;
    }
    int v9 = *(_DWORD *)(a1 + 16);
  }
  unint64_t v10 = *(uint64_t **)a1;
  unint64_t v11 = (v9 - 1) | ((unint64_t)(v9 - 1) >> 1);
  unint64_t v12 = v11 | (v11 >> 2) | ((v11 | (v11 >> 2)) >> 4);
  int v13 = ((v12 | (v12 >> 8)) >> 16) | v12 | (v12 >> 8);
  if ((v13 + 1) > 0x40) {
    unsigned int v14 = v13 + 1;
  }
  else {
    unsigned int v14 = 64;
  }
  *(_DWORD *)(a1 + 16) = v14;
  buffer = llvm::allocate_buffer(32 * v14, (std::align_val_t)8uLL);
  *(void *)a1 = buffer;
  if (v10)
  {
    int v16 = (char *)(32 * v6);
    llvm::DenseMapBase<llvm::DenseMap<mlir::OperationName,llvm::SmallVector<mlir::Pattern const*,1u>,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,llvm::SmallVector<mlir::Pattern const*,1u>>>,mlir::OperationName,llvm::SmallVector<mlir::Pattern const*,1u>,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,llvm::SmallVector<mlir::Pattern const*,1u>>>::moveFromOldBuckets(a1, v10, (uint64_t *)&v16[(void)v10]);
    llvm::deallocate_buffer((llvm *)v10, v16);
  }
  *(void *)(a1 + 8) = 0;
  uint64_t v17 = *(unsigned int *)(a1 + 16);
  unint64_t v18 = buffer;
  if (((v17 - 1) & 0x7FFFFFFFFFFFFFFLL) == 0) {
    goto LABEL_34;
  }
  uint64_t v19 = ((v17 - 1) & 0x7FFFFFFFFFFFFFFLL) + 1;
  unint64_t v18 = &buffer[4 * (v19 & 0xFFFFFFFFFFFFFFELL)];
  unint64_t v20 = buffer + 4;
  uint64_t v21 = v19 & 0xFFFFFFFFFFFFFFELL;
  do
  {
    *(v20 - 4) = -4096;
    void *v20 = -4096;
    v20 += 8;
    v21 -= 2;
  }
  while (v21);
  if (v19 != (v19 & 0xFFFFFFFFFFFFFFELL))
  {
LABEL_34:
    do
    {
      *unint64_t v18 = -4096;
      v18 += 4;
    }
    while (v18 != &buffer[4 * v17]);
  }
  uint64_t v7 = *a3;
  unsigned int v22 = v17 - 1;
  uint64_t v23 = ((*a3 >> 4) ^ (*a3 >> 9)) & v22;
  a2 = &buffer[4 * v23];
  uint64_t v24 = *a2;
  if (*a3 != *a2)
  {
    uint64_t v25 = 0;
    int v26 = 1;
    while (v24 != -4096)
    {
      if (v25) {
        BOOL v27 = 0;
      }
      else {
        BOOL v27 = v24 == -8192;
      }
      if (v27) {
        uint64_t v25 = a2;
      }
      int v28 = v23 + v26++;
      uint64_t v23 = v28 & v22;
      a2 = &buffer[4 * v23];
      uint64_t v24 = *a2;
      if (v7 == *a2) {
        goto LABEL_4;
      }
    }
    if (v25) {
      a2 = v25;
    }
    goto LABEL_3;
  }
LABEL_4:
  ++*(_DWORD *)(a1 + 8);
  if (v7 != -4096) {
    --*(_DWORD *)(a1 + 12);
  }
  *a2 = *a3;
  a2[1] = (uint64_t)(a2 + 3);
  a2[2] = 0x100000000;
  return a2;
}

void llvm::DenseMapBase<llvm::DenseMap<mlir::OperationName,llvm::SmallVector<mlir::Pattern const*,1u>,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,llvm::SmallVector<mlir::Pattern const*,1u>>>,mlir::OperationName,llvm::SmallVector<mlir::Pattern const*,1u>,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,llvm::SmallVector<mlir::Pattern const*,1u>>>::moveFromOldBuckets(uint64_t a1, uint64_t *a2, uint64_t *a3)
{
  uint64_t v4 = a2;
  *(void *)(a1 + 8) = 0;
  uint64_t v6 = *(unsigned int *)(a1 + 16);
  if (v6)
  {
    uint64_t v7 = *(void **)a1;
    uint64_t v8 = (v6 - 1) & 0x7FFFFFFFFFFFFFFLL;
    if (v8)
    {
      uint64_t v9 = v8 + 1;
      uint64_t v10 = (v8 + 1) & 0xFFFFFFFFFFFFFFELL;
      unint64_t v11 = &v7[4 * v10];
      unint64_t v12 = v7 + 4;
      uint64_t v13 = v10;
      do
      {
        *(v12 - 4) = -4096;
        *unint64_t v12 = -4096;
        v12 += 8;
        v13 -= 2;
      }
      while (v13);
      if (v9 == v10) {
        goto LABEL_10;
      }
    }
    else
    {
      unint64_t v11 = *(void **)a1;
    }
    unsigned int v14 = &v7[4 * v6];
    do
    {
      *unint64_t v11 = -4096;
      v11 += 4;
    }
    while (v11 != v14);
  }
LABEL_10:
  if (a2 != a3)
  {
    do
    {
      uint64_t v15 = *v4;
      if ((*v4 | 0x1000) != 0xFFFFFFFFFFFFF000)
      {
        int v16 = *(_DWORD *)(a1 + 16) - 1;
        uint64_t v17 = v16 & ((v15 >> 4) ^ (v15 >> 9));
        unint64_t v18 = (void *)(*(void *)a1 + 32 * v17);
        uint64_t v19 = *v18;
        if (v15 != *v18)
        {
          uint64_t v21 = 0;
          int v22 = 1;
          while (v19 != -4096)
          {
            if (v21) {
              BOOL v23 = 0;
            }
            else {
              BOOL v23 = v19 == -8192;
            }
            if (v23) {
              uint64_t v21 = v18;
            }
            int v24 = v17 + v22++;
            uint64_t v17 = v24 & v16;
            unint64_t v18 = (void *)(*(void *)a1 + 32 * v17);
            uint64_t v19 = *v18;
            if (v15 == *v18) {
              goto LABEL_15;
            }
          }
          if (v21) {
            unint64_t v18 = v21;
          }
        }
LABEL_15:
        *unint64_t v18 = v15;
        v18[1] = v18 + 3;
        void v18[2] = 0x100000000;
        if (*((_DWORD *)v4 + 4)) {
          llvm::SmallVectorImpl<llvm::SMLoc>::operator=((uint64_t)(v18 + 1), (uint64_t)(v4 + 1));
        }
        ++*(_DWORD *)(a1 + 8);
        unint64_t v20 = (uint64_t *)v4[1];
        if (v20 != v4 + 3) {
          free(v20);
        }
      }
      v4 += 4;
    }
    while (v4 != a3);
  }
}

uint64_t anonymous namespace'::OperationLegalizer::computeOpLegalizationDepth(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v5 = *(void *)a2;
  uint64_t v6 = *(unsigned int *)(a2 + 16);
  if (v6)
  {
    LODWORD(v7) = (v6 - 1) & ((a1 >> 4) ^ (a1 >> 9));
    uint64_t v8 = (uint64_t *)(v5 + 16 * v7);
    uint64_t v9 = *v8;
    if (*v8 == a1) {
      goto LABEL_8;
    }
    int v10 = 1;
    while (v9 != -4096)
    {
      int v11 = v7 + v10++;
      uint64_t v7 = v11 & (v6 - 1);
      uint64_t v9 = *(void *)(v5 + 16 * v7);
      if (v9 == a1)
      {
        uint64_t v8 = (uint64_t *)(v5 + 16 * v7);
        goto LABEL_8;
      }
    }
  }
  uint64_t v8 = (uint64_t *)(v5 + 16 * v6);
LABEL_8:
  if (v8 != (uint64_t *)(v5 + 16 * v6)) {
    return *((unsigned int *)v8 + 2);
  }
  uint64_t v13 = *(void *)a3;
  uint64_t v14 = *(unsigned int *)(a3 + 16);
  if (!v14) {
    goto LABEL_16;
  }
  unsigned int v15 = v14 - 1;
  int v16 = (uint64_t *)(v13 + 32 * ((v14 - 1) & ((a1 >> 4) ^ (a1 >> 9))));
  uint64_t v17 = *v16;
  if (*v16 != a1)
  {
    int v18 = 1;
    LODWORD(v19) = v15 & ((a1 >> 4) ^ (a1 >> 9));
    while (v17 != -4096)
    {
      int v20 = v19 + v18++;
      uint64_t v19 = v20 & v15;
      uint64_t v17 = *(void *)(v13 + 32 * v19);
      if (v17 == a1)
      {
        int v16 = (uint64_t *)(v13 + 32 * v19);
        goto LABEL_17;
      }
    }
LABEL_16:
    int v16 = (uint64_t *)(v13 + 32 * v14);
  }
LABEL_17:
  if (v16 == (uint64_t *)(v13 + 32 * v14) || !*((_DWORD *)v16 + 4)) {
    return 0;
  }
  uint64_t v21 = (uint64_t)(v16 + 1);
  if (!v6) {
    goto LABEL_59;
  }
  unsigned int v22 = (v6 - 1) & ((a1 >> 4) ^ (a1 >> 9));
  BOOL v23 = (void *)(v5 + 16 * v22);
  uint64_t v24 = *v23;
  if (*v23 != a1)
  {
    uint64_t v25 = 0;
    int v26 = 1;
    while (v24 != -4096)
    {
      if (v25) {
        BOOL v27 = 0;
      }
      else {
        BOOL v27 = v24 == -8192;
      }
      if (v27) {
        uint64_t v25 = v23;
      }
      unsigned int v28 = v22 + v26++;
      unsigned int v22 = v28 & (v6 - 1);
      BOOL v23 = (void *)(v5 + 16 * v22);
      uint64_t v24 = *v23;
      if (*v23 == a1) {
        goto LABEL_37;
      }
    }
    if (v25) {
      uint64_t v40 = (uint64_t)v25;
    }
    else {
      uint64_t v40 = (uint64_t)v23;
    }
    int v41 = *(_DWORD *)(a2 + 8);
    if (4 * v41 + 4 < (3 * v6))
    {
      if ((int)v6 + ~v41 - *(_DWORD *)(a2 + 12) > v6 >> 3) {
        goto LABEL_33;
      }
      goto LABEL_60;
    }
LABEL_59:
    LODWORD(v6) = 2 * v6;
LABEL_60:
    uint64_t v57 = a3;
    uint64_t v58 = v21;
    llvm::DenseMap<void const*,unsigned int,llvm::DenseMapInfo<void const*,void>,llvm::detail::DenseMapPair<void const*,unsigned int>>::grow(a2, v6);
    int v42 = *(_DWORD *)(a2 + 16) - 1;
    unsigned int v43 = v42 & ((a1 >> 4) ^ (a1 >> 9));
    uint64_t v40 = *(void *)a2 + 16 * v43;
    uint64_t v44 = *(void *)v40;
    if (*(void *)v40 == a1)
    {
      uint64_t v29 = a1;
      a3 = v57;
      uint64_t v21 = v58;
      goto LABEL_34;
    }
    uint64_t v49 = 0;
    int v50 = 1;
    a3 = v57;
    uint64_t v21 = v58;
    while (v44 != -4096)
    {
      if (v49) {
        BOOL v51 = 0;
      }
      else {
        BOOL v51 = v44 == -8192;
      }
      if (v51) {
        uint64_t v49 = v40;
      }
      unsigned int v52 = v43 + v50++;
      unsigned int v43 = v52 & v42;
      uint64_t v40 = *(void *)a2 + 16 * (v52 & v42);
      uint64_t v44 = *(void *)v40;
      uint64_t v29 = a1;
      if (*(void *)v40 == a1) {
        goto LABEL_34;
      }
    }
    if (v49) {
      uint64_t v40 = v49;
    }
    a3 = v57;
    uint64_t v21 = v58;
LABEL_33:
    uint64_t v29 = *(void *)v40;
LABEL_34:
    ++*(_DWORD *)(a2 + 8);
    if (v29 != -4096) {
      --*(_DWORD *)(a2 + 12);
    }
    *(void *)uint64_t v40 = a1;
    *(_DWORD *)(v40 + 8) = -1;
  }
LABEL_37:
  unsigned int v30 = *(_DWORD *)(a2 + 16);
  if (!v30) {
    goto LABEL_65;
  }
  unsigned int v31 = v30 - 1;
  unsigned int v32 = (v30 - 1) & ((a1 >> 4) ^ (a1 >> 9));
  uint64_t v33 = *(void *)a2 + 16 * v32;
  uint64_t v34 = *(void *)v33;
  if (*(void *)v33 == a1)
  {
LABEL_39:
    *(_DWORD *)(v33 + 8) = result;
    return result;
  }
  uint64_t v36 = 0;
  int v37 = 1;
  while (v34 != -4096)
  {
    if (v36) {
      BOOL v38 = 0;
    }
    else {
      BOOL v38 = v34 == -8192;
    }
    if (v38) {
      uint64_t v36 = v33;
    }
    unsigned int v39 = v32 + v37++;
    unsigned int v32 = v39 & v31;
    uint64_t v33 = *(void *)a2 + 16 * (v39 & v31);
    uint64_t v34 = *(void *)v33;
    if (*(void *)v33 == a1) {
      goto LABEL_39;
    }
  }
  if (v36) {
    uint64_t v33 = v36;
  }
  int v45 = *(_DWORD *)(a2 + 8);
  if (4 * v45 + 4 < 3 * v30)
  {
    if (v30 + ~v45 - *(_DWORD *)(a2 + 12) > v30 >> 3) {
      goto LABEL_42;
    }
    unsigned int v59 = result;
  }
  else
  {
LABEL_65:
    unsigned int v59 = result;
    v30 *= 2;
  }
  llvm::DenseMap<void const*,unsigned int,llvm::DenseMapInfo<void const*,void>,llvm::detail::DenseMapPair<void const*,unsigned int>>::grow(a2, v30);
  int v46 = *(_DWORD *)(a2 + 16) - 1;
  unsigned int v47 = v46 & ((a1 >> 4) ^ (a1 >> 9));
  uint64_t v33 = *(void *)a2 + 16 * v47;
  uint64_t v48 = *(void *)v33;
  if (*(void *)v33 == a1)
  {
    uint64_t v35 = a1;
    uint64_t result = v59;
    goto LABEL_43;
  }
  uint64_t v53 = 0;
  int v54 = 1;
  uint64_t result = v59;
  while (v48 != -4096)
  {
    if (v53) {
      BOOL v55 = 0;
    }
    else {
      BOOL v55 = v48 == -8192;
    }
    if (v55) {
      uint64_t v53 = v33;
    }
    unsigned int v56 = v47 + v54++;
    unsigned int v47 = v56 & v46;
    uint64_t v33 = *(void *)a2 + 16 * (v56 & v46);
    uint64_t v48 = *(void *)v33;
    uint64_t v35 = a1;
    if (*(void *)v33 == a1) {
      goto LABEL_43;
    }
  }
  if (v53) {
    uint64_t v33 = v53;
  }
LABEL_42:
  uint64_t v35 = *(void *)v33;
LABEL_43:
  ++*(_DWORD *)(a2 + 8);
  if (v35 != -4096) {
    --*(_DWORD *)(a2 + 12);
  }
  *(void *)uint64_t v33 = a1;
  *(_DWORD *)(v33 + 8) = 0;
  *(_DWORD *)(v33 + 8) = result;
  return result;
}

uint64_t anonymous namespace'::OperationLegalizer::applyCostModelToPatterns(uint64_t a1, uint64_t a2, uint64_t a3)
{
  v35[8] = *MEMORY[0x263EF8340];
  uint64_t v33 = v35;
  uint64_t v34 = 0x400000000;
  unint64_t v6 = *(unsigned int *)(a1 + 8);
  if (v6 >= 5)
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v33, v35, v6, 16);
    LODWORD(v6) = *(_DWORD *)(a1 + 8);
  }
  if (v6)
  {
    uint64_t v7 = *(uint64_t **)a1;
    uint64_t v8 = *(void *)a1 + 8 * v6;
    LODWORD(v9) = -1;
    do
    {
      uint64_t v10 = *v7;
      uint64_t v32 = v10;
      int v11 = 1;
      unsigned int v31 = 1;
      uint64_t v12 = *(unsigned int *)(v10 + 32);
      if (v12)
      {
        uint64_t v13 = *(uint64_t **)(v10 + 24);
        uint64_t v14 = 8 * v12;
        do
        {
          uint64_t v15 = *v13++;
          if (v31 <= v16 + 1) {
            int v11 = v16 + 1;
          }
          else {
            int v11 = v31;
          }
          unsigned int v31 = v11;
          v14 -= 8;
        }
        while (v14);
      }
      int v17 = v34;
      if (v34 >= HIDWORD(v34))
      {
        llvm::SmallVectorTemplateBase<std::pair<mlir::Pattern const*,unsigned int>,true>::growAndEmplaceBack<mlir::Pattern const*&,unsigned int &>((uint64_t)&v33, &v32, &v31);
      }
      else
      {
        int v18 = (char *)v33 + 16 * v34;
        *(void *)int v18 = v32;
        *((_DWORD *)v18 + 2) = v11;
        LODWORD(v34) = v17 + 1;
      }
      if (v31 >= v9) {
        uint64_t v9 = v9;
      }
      else {
        uint64_t v9 = v31;
      }
      ++v7;
    }
    while (v7 != (uint64_t *)v8);
  }
  else
  {
    uint64_t v9 = 0xFFFFFFFFLL;
  }
  unint64_t v19 = v34;
  int v20 = (char *)v33;
  if (v34 != 1)
  {
    if (!v34)
    {
LABEL_25:
      *(_DWORD *)(a1 + 8) = 0;
      int v20 = (char *)v33;
      uint64_t v25 = v34;
      if (!v34) {
        goto LABEL_33;
      }
      goto LABEL_28;
    }
    uint64_t v21 = (const std::nothrow_t *)MEMORY[0x263F8C180];
    unint64_t v22 = v34;
    while (1)
    {
      BOOL v23 = operator new(16 * v22, v21);
      if (v23) {
        break;
      }
      BOOL v24 = v22 > 1;
      v22 >>= 1;
      if (!v24) {
        goto LABEL_25;
      }
    }
    int v26 = v23;
    operator delete(v26);
    *(_DWORD *)(a1 + 8) = 0;
    int v20 = (char *)v33;
    uint64_t v25 = v34;
    if (v34)
    {
LABEL_28:
      unsigned int v27 = 0;
      uint64_t v28 = 16 * v25;
      do
      {
        uint64_t v29 = *(void *)v20;
        if (v27 >= *(_DWORD *)(a1 + 12))
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod(a1, (void *)(a1 + 16), v27 + 1, 8);
          unsigned int v27 = *(_DWORD *)(a1 + 8);
        }
        *(void *)(*(void *)a1 + 8 * v27) = v29;
        unsigned int v27 = *(_DWORD *)(a1 + 8) + 1;
        *(_DWORD *)(a1 + 8) = v27;
        v20 += 16;
        v28 -= 16;
      }
      while (v28);
      int v20 = (char *)v33;
    }
  }
LABEL_33:
  if (v20 != (char *)v35) {
    free(v20);
  }
  return v9;
}

uint64_t llvm::SmallVectorTemplateBase<std::pair<mlir::Pattern const*,unsigned int>,true>::growAndEmplaceBack<mlir::Pattern const*&,unsigned int &>(uint64_t a1, uint64_t *a2, unsigned int *a3)
{
  uint64_t v4 = *a2;
  uint64_t v5 = *a3;
  uint64_t v6 = *(unsigned int *)(a1 + 8);
  if (v6 >= *(_DWORD *)(a1 + 12))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod(a1, (void *)(a1 + 16), v6 + 1, 16);
    LODWORD(v6) = *(_DWORD *)(a1 + 8);
  }
  uint64_t v7 = (void *)(*(void *)a1 + 16 * v6);
  *uint64_t v7 = v4;
  v7[1] = v5;
  LODWORD(v7) = *(_DWORD *)(a1 + 8) + 1;
  *(_DWORD *)(a1 + 8) = v7;
  return *(void *)a1 + 16 * v7 - 16;
}

char *std::__stable_sort<std::_ClassicAlgPolicy,anonymous namespace'::OperationLegalizer::applyCostModelToPatterns(llvm::SmallVector<mlir::Pattern const*,1u> &,llvm::DenseMap<mlir::OperationName,unsigned int,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,unsigned int>> &,llvm::DenseMap<mlir::OperationName,llvm::SmallVector<mlir::Pattern const*,1u>,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,llvm::SmallVector<mlir::Pattern const*,1u>>> &)::$_0 &,std::pair<mlir::Pattern const*,unsigned int> *>(char *result, char *a2, unint64_t a3, _OWORD *a4, uint64_t a5)
{
  if (a3 < 2) {
    return result;
  }
  uint64_t v6 = result;
  if (a3 == 2)
  {
    uint64_t v7 = *((void *)a2 - 2);
    unsigned int v8 = *((_DWORD *)a2 - 2);
    uint64_t v9 = *(void *)result;
    unsigned int v10 = *((_DWORD *)result + 2);
    if (v8 == v10)
    {
      if (*(unsigned __int16 *)(v9 + 12) >= *(unsigned __int16 *)(v7 + 12)) {
        return result;
      }
    }
    else if (v8 >= v10)
    {
      return result;
    }
    *(void *)uint64_t result = v7;
    *((void *)a2 - 2) = v9;
    *((_DWORD *)result + 2) = v8;
    *((_DWORD *)a2 - 2) = v10;
    return result;
  }
  if ((uint64_t)a3 <= 0)
  {
    if (result == a2) {
      return result;
    }
    int v17 = result + 16;
    if (result + 16 == a2) {
      return result;
    }
    uint64_t v18 = 0;
    unint64_t v19 = result;
    while (1)
    {
      uint64_t v21 = v19;
      unint64_t v19 = v17;
      uint64_t v22 = *((void *)v21 + 2);
      unsigned int v23 = *((_DWORD *)v21 + 6);
      unsigned int v24 = *((_DWORD *)v21 + 2);
      if (v23 != v24) {
        break;
      }
      if (*(unsigned __int16 *)(*(void *)v21 + 12) >= *(unsigned __int16 *)(v22 + 12)) {
        goto LABEL_19;
      }
      *((void *)v21 + 2) = *(void *)v21;
      *((_DWORD *)v19 + 2) = v24;
      int v20 = result;
      if (v21 != result) {
        goto LABEL_26;
      }
LABEL_18:
      *(void *)int v20 = v22;
      *((_DWORD *)v20 + 2) = v23;
LABEL_19:
      int v17 = v19 + 16;
      v18 += 16;
      if (v19 + 16 == a2) {
        return result;
      }
    }
    if (v23 >= v24) {
      goto LABEL_19;
    }
    *((void *)v21 + 2) = *(void *)v21;
    *((_DWORD *)v19 + 2) = v24;
    int v20 = result;
    if (v21 == result) {
      goto LABEL_18;
    }
LABEL_26:
    uint64_t v25 = v18;
    while (1)
    {
      while (1)
      {
        uint64_t v28 = &result[v25];
        unsigned int v29 = *(_DWORD *)&result[v25 - 8];
        if (v23 == v29) {
          break;
        }
        if (v23 >= v29)
        {
          int v20 = &result[v25];
          goto LABEL_18;
        }
        v21 -= 16;
        unsigned int v30 = &result[v25];
        *(void *)unsigned int v30 = *((void *)v28 - 2);
        *((_DWORD *)v30 + 2) = v29;
        v25 -= 16;
        if (!v25)
        {
LABEL_32:
          int v20 = result;
          goto LABEL_18;
        }
      }
      uint64_t v26 = *((void *)v28 - 2);
      if (*(unsigned __int16 *)(v26 + 12) >= *(unsigned __int16 *)(v22 + 12)) {
        break;
      }
      v21 -= 16;
      unsigned int v27 = &result[v25];
      *(void *)unsigned int v27 = v26;
      *((_DWORD *)v27 + 2) = v29;
      v25 -= 16;
      if (!v25) {
        goto LABEL_32;
      }
    }
    int v20 = v21;
    goto LABEL_18;
  }
  uint64_t v13 = a4;
  unint64_t v14 = a3 >> 1;
  uint64_t v15 = &result[16 * (a3 >> 1)];
  unint64_t v16 = a3 >> 1;
  if ((uint64_t)a3 <= a5)
  {
    unsigned int v31 = &v13[v14];
    uint64_t v32 = &v13[a3];
    uint64_t v33 = v31;
    while (v33 != v32)
    {
      uint64_t v34 = *(void *)v33;
      unsigned int v35 = *((_DWORD *)v33 + 2);
      uint64_t v36 = *(void *)v13;
      unsigned int v37 = *((_DWORD *)v13 + 2);
      BOOL v38 = v35 >= v37;
      if (v35 == v37) {
        BOOL v38 = *(unsigned __int16 *)(v36 + 12) >= *(unsigned __int16 *)(v34 + 12);
      }
      if (v38)
      {
        *(void *)uint64_t v6 = v36;
        *((_DWORD *)v6 + 2) = v37;
        ++v13;
        v6 += 16;
        if (v13 == v31)
        {
LABEL_42:
          if (v33 != v32)
          {
            uint64_t v39 = 0;
            do
            {
              uint64_t v40 = &v33[v39];
              int v41 = &v6[v39 * 16];
              *(void *)int v41 = *(void *)&v33[v39];
              *((_DWORD *)v41 + 2) = DWORD2(v33[v39++]);
            }
            while (v40 + 1 != v32);
          }
          return result;
        }
      }
      else
      {
        *(void *)uint64_t v6 = v34;
        *((_DWORD *)v6 + 2) = v35;
        ++v33;
        v6 += 16;
        if (v13 == v31) {
          goto LABEL_42;
        }
      }
    }
    if (v13 != v31)
    {
      uint64_t v42 = 0;
      do
      {
        unsigned int v43 = &v6[v42 * 16];
        uint64_t v44 = &v13[v42];
        *(void *)unsigned int v43 = *(void *)&v13[v42];
        *((_DWORD *)v43 + 2) = DWORD2(v13[v42++]);
      }
      while (v44 + 1 != v31);
    }
  }
  else
  {
  }
  return result;
}

_DWORD *std::__stable_sort_move<std::_ClassicAlgPolicy,anonymous namespace'::OperationLegalizer::applyCostModelToPatterns(llvm::SmallVector<mlir::Pattern const*,1u> &,llvm::DenseMap<mlir::OperationName,unsigned int,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,unsigned int>> &,llvm::DenseMap<mlir::OperationName,llvm::SmallVector<mlir::Pattern const*,1u>,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,llvm::SmallVector<mlir::Pattern const*,1u>>> &)::$_0 &,std::pair<mlir::Pattern const*,unsigned int> *>(_DWORD *result, _DWORD *a2, unint64_t a3, _OWORD *a4)
{
  if (!a3) {
    return result;
  }
  uint64_t v4 = a4;
  uint64_t v7 = result;
  if (a3 == 2)
  {
    unsigned int v8 = a2 - 4;
    unsigned int v9 = *(a2 - 2);
    unsigned int v10 = result[2];
    if (v9 == v10)
    {
      if (*(unsigned __int16 *)(*(void *)result + 12) >= *(unsigned __int16 *)(*(void *)v8 + 12))
      {
LABEL_8:
        *a4 = *(_OWORD *)result;
        long long v11 = *(_OWORD *)v8;
LABEL_30:
        a4[1] = v11;
        return result;
      }
    }
    else if (v9 >= v10)
    {
      goto LABEL_8;
    }
    *a4 = *(_OWORD *)v8;
    long long v11 = *(_OWORD *)result;
    goto LABEL_30;
  }
  if (a3 == 1)
  {
    *a4 = *(_OWORD *)result;
    return result;
  }
  if ((uint64_t)a3 > 8)
  {
    unint64_t v25 = a3 >> 1;
    uint64_t v26 = 16 * (a3 >> 1);
    unsigned int v27 = &result[(unint64_t)v26 / 4];
    uint64_t v28 = &v7[(unint64_t)v26 / 4];
    while (v28 != a2)
    {
      unsigned int v30 = v28[2];
      unsigned int v31 = v7[2];
      BOOL v32 = v30 >= v31;
      if (v30 == v31) {
        BOOL v32 = *(unsigned __int16 *)(*(void *)v7 + 12) >= *(unsigned __int16 *)(*(void *)v28 + 12);
      }
      if (v32)
      {
        long long v33 = *(_OWORD *)v7;
        v7 += 4;
        *v4++ = v33;
        if (v7 == v27)
        {
LABEL_39:
          if (v28 != a2)
          {
            unint64_t v34 = 0;
            do
            {
              v4[v34 / 4] = *(_OWORD *)&v28[v34];
              v34 += 4;
            }
            while (&v28[v34] != a2);
          }
          return result;
        }
      }
      else
      {
        long long v29 = *(_OWORD *)v28;
        v28 += 4;
        *v4++ = v29;
        if (v7 == v27) {
          goto LABEL_39;
        }
      }
    }
    if (v7 != v27)
    {
      unint64_t v35 = 0;
      do
      {
        v4[v35 / 4] = *(_OWORD *)&v7[v35];
        v35 += 4;
      }
      while (&v7[v35] != v27);
    }
  }
  else if (result != a2)
  {
    *a4 = *(_OWORD *)result;
    uint64_t v12 = result + 4;
    if (result + 4 != a2)
    {
      uint64_t v13 = 0;
      unint64_t v14 = a4;
      while (1)
      {
        unint64_t v16 = v12;
        int v17 = v14 + 4;
        unsigned int v18 = v7[6];
        unsigned int v19 = v14[2];
        if (v18 != v19) {
          break;
        }
        if (*(unsigned __int16 *)(*(void *)v14 + 12) < *(unsigned __int16 *)(*(void *)v16 + 12))
        {
LABEL_20:
          *int v17 = *(_OWORD *)v14;
          uint64_t v15 = (char *)a4;
          if (v14 == (_DWORD *)a4) {
            goto LABEL_14;
          }
          uint64_t v20 = v13;
          while (1)
          {
            unsigned int v22 = v7[6];
            uint64_t v23 = *(void *)((char *)a4 + v20 - 16);
            unsigned int v24 = *(_DWORD *)((char *)a4 + v20 - 8);
            if (v22 != v24) {
              break;
            }
            if (*(unsigned __int16 *)(v23 + 12) >= *(unsigned __int16 *)(*(void *)v16 + 12))
            {
              uint64_t v15 = (char *)v14;
              goto LABEL_14;
            }
LABEL_23:
            v14 -= 4;
            uint64_t v21 = (char *)a4 + v20;
            *(void *)uint64_t v21 = v23;
            *((_DWORD *)v21 + 2) = v24;
            v20 -= 16;
            if (!v20)
            {
              uint64_t v15 = (char *)a4;
              goto LABEL_14;
            }
          }
          if (v22 < v24) {
            goto LABEL_23;
          }
          uint64_t v15 = (char *)a4 + v20;
LABEL_14:
          *(void *)uint64_t v15 = *(void *)v16;
          *((_DWORD *)v15 + 2) = v7[6];
          uint64_t v12 = v16 + 4;
          v13 += 16;
          unint64_t v14 = v17;
          uint64_t v7 = v16;
          if (v16 + 4 == a2) {
            return result;
          }
        }
        else
        {
LABEL_17:
          *int v17 = *(_OWORD *)v16;
          uint64_t v12 = v16 + 4;
          v13 += 16;
          v14 += 4;
          uint64_t v7 = v16;
          if (v16 + 4 == a2) {
            return result;
          }
        }
      }
      if (v18 >= v19) {
        goto LABEL_17;
      }
      goto LABEL_20;
    }
  }
  return result;
}

char *std::__inplace_merge<std::_ClassicAlgPolicy,anonymous namespace'::OperationLegalizer::applyCostModelToPatterns(llvm::SmallVector<mlir::Pattern const*,1u> &,llvm::DenseMap<mlir::OperationName,unsigned int,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,unsigned int>> &,llvm::DenseMap<mlir::OperationName,llvm::SmallVector<mlir::Pattern const*,1u>,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,llvm::SmallVector<mlir::Pattern const*,1u>>> &)::$_0 &,std::pair<mlir::Pattern const*,unsigned int> *>(char *result, char *a2, char *a3, uint64_t a4, uint64_t a5, uint64_t *a6, uint64_t a7)
{
  if (!a5) {
    return result;
  }
  while (2)
  {
    if (a5 <= a7 || a4 <= a7)
    {
      if (a4 <= a5)
      {
        if (result != a2)
        {
          unint64_t v56 = 0;
          do
          {
            *(_OWORD *)&a6[v56] = *(_OWORD *)&result[v56 * 8];
            v56 += 2;
          }
          while (&result[v56 * 8] != a2);
          if (v56 * 8)
          {
            uint64_t v57 = &a6[v56];
            uint64_t v58 = (uint64_t)&a6[v56 - 2];
            while (a2 != a3)
            {
              uint64_t v59 = *(void *)a2;
              unsigned int v60 = *((_DWORD *)a2 + 2);
              uint64_t v61 = *a6;
              unsigned int v62 = *((_DWORD *)a6 + 2);
              BOOL v63 = v60 >= v62;
              if (v60 == v62) {
                BOOL v63 = *(unsigned __int16 *)(v61 + 12) >= *(unsigned __int16 *)(v59 + 12);
              }
              if (v63)
              {
                *(void *)uint64_t result = v61;
                *((_DWORD *)result + 2) = v62;
                a6 += 2;
                result += 16;
                if (v57 == a6) {
                  return result;
                }
              }
              else
              {
                *(void *)uint64_t result = v59;
                *((_DWORD *)result + 2) = v60;
                a2 += 16;
                result += 16;
                if (v57 == a6) {
                  return result;
                }
              }
            }
            unint64_t v67 = 0;
            do
            {
              int v68 = &result[v67 * 8];
              BOOL v69 = &a6[v67];
              *(void *)int v68 = a6[v67];
              *((_DWORD *)v68 + 2) = a6[v67 + 1];
              v67 += 2;
            }
            while ((uint64_t *)v58 != v69);
          }
        }
      }
      else if (a2 != a3)
      {
        uint64_t v48 = 0;
        do
        {
          *(_OWORD *)&a6[v48] = *(_OWORD *)&a2[v48 * 8];
          v48 += 2;
        }
        while (&a2[v48 * 8] != a3);
        if (v48 * 8)
        {
          uint64_t v49 = &a6[v48];
          int v50 = (unsigned int *)(a3 - 8);
          while (a2 != result)
          {
            BOOL v51 = a2 - 16;
            uint64_t v52 = *((void *)a2 - 2);
            unsigned int v53 = *((_DWORD *)a2 - 2);
            unsigned int v54 = *((_DWORD *)v49 - 2);
            BOOL v55 = v54 >= v53;
            if (v54 == v53) {
              BOOL v55 = *(unsigned __int16 *)(v52 + 12) >= *(unsigned __int16 *)(*(v49 - 2) + 12);
            }
            if (v55)
            {
              uint64_t v52 = *(v49 - 2);
              unsigned int v53 = *((_DWORD *)v49 - 2);
              BOOL v51 = a2;
              v49 -= 2;
            }
            *((void *)v50 - 1) = v52;
            *int v50 = v53;
            v50 -= 4;
            a2 = v51;
            if (v49 == a6) {
              return result;
            }
          }
          unint64_t v65 = 0;
          do
          {
            uint64_t v66 = &v50[v65 / 4];
            *((void *)v66 - 1) = v49[v65 / 8 - 2];
            *uint64_t v66 = v49[v65 / 8 - 1];
            v65 -= 16;
          }
          while (&v49[v65 / 8] != a6);
        }
      }
      return result;
    }
    if (!a4) {
      return result;
    }
    uint64_t v10 = 0;
    uint64_t v11 = *(void *)a2;
    unsigned int v12 = *((_DWORD *)a2 + 2);
    uint64_t v13 = -a4;
    while (1)
    {
      uint64_t v14 = *(void *)&result[v10];
      unsigned int v15 = *(_DWORD *)&result[v10 + 8];
      if (v12 == v15)
      {
        if (*(unsigned __int16 *)(v14 + 12) < *(unsigned __int16 *)(v11 + 12)) {
          break;
        }
        goto LABEL_7;
      }
      if (v12 < v15) {
        break;
      }
LABEL_7:
      v10 += 16;
      BOOL v34 = __CFADD__(v13++, 1);
      if (v34) {
        return result;
      }
    }
    unint64_t v16 = &result[v10];
    if (-v13 < a5)
    {
      if (a5 >= 0) {
        uint64_t v17 = a5;
      }
      else {
        uint64_t v17 = a5 + 1;
      }
      uint64_t v18 = v17 >> 1;
      unsigned int v19 = &a2[16 * (v17 >> 1)];
      if (v16 != a2)
      {
        unsigned int v20 = *((_DWORD *)v19 + 2);
        uint64_t v21 = &result[v10];
        unint64_t v22 = (a2 - result - v10) >> 4;
        uint64_t v23 = v16;
        while (1)
        {
          unint64_t v24 = v22 >> 1;
          unint64_t v25 = &v23[16 * (v22 >> 1)];
          unsigned int v26 = *((_DWORD *)v25 + 2);
          if (v26 == v20)
          {
            if (*(unsigned __int16 *)(*(void *)v25 + 12) < *(unsigned __int16 *)(*(void *)v19 + 12)) {
              goto LABEL_17;
            }
          }
          else if (v26 > v20)
          {
            goto LABEL_17;
          }
          uint64_t v23 = v25 + 16;
          unint64_t v24 = v22 + ~v24;
LABEL_17:
          unint64_t v22 = v24;
          if (!v24) {
            goto LABEL_35;
          }
        }
      }
      uint64_t v21 = &result[v10];
      uint64_t v23 = a2;
LABEL_35:
      uint64_t v28 = (v23 - v21) >> 4;
      unint64_t v35 = v19;
      if (v23 != a2) {
        goto LABEL_39;
      }
LABEL_55:
      a4 = -(v28 + v13);
      uint64_t v45 = a5 - v18;
      if (v28 + v18 >= a5 - (v28 + v18) - v13)
      {
        a4 = v28;
        a3 = v35;
        a5 = v18;
        uint64_t result = v16;
        a2 = v23;
        if (!v18) {
          return result;
        }
      }
      else
      {
        int v46 = v16;
        unsigned int v47 = a3;
        a3 = v47;
        a5 = v45;
        uint64_t result = v35;
        a2 = v19;
        if (!v45) {
          return result;
        }
      }
      continue;
    }
    break;
  }
  if (v13 != -1)
  {
    if (v13 <= 0) {
      uint64_t v27 = -v13;
    }
    else {
      uint64_t v27 = 1 - v13;
    }
    uint64_t v28 = v27 >> 1;
    uint64_t v23 = &result[16 * (v27 >> 1) + v10];
    if (a3 == a2)
    {
      unsigned int v19 = a3;
    }
    else
    {
      unsigned int v29 = *((_DWORD *)v23 + 2);
      unint64_t v30 = (a3 - a2) >> 4;
      unsigned int v19 = a2;
      do
      {
        unint64_t v31 = v30 >> 1;
        BOOL v32 = &v19[16 * (v30 >> 1)];
        unsigned int v33 = *((_DWORD *)v32 + 2);
        BOOL v34 = v33 >= v29;
        if (v33 == v29) {
          BOOL v34 = *(unsigned __int16 *)(*(void *)v23 + 12) >= *(unsigned __int16 *)(*(void *)v32 + 12);
        }
        if (!v34)
        {
          unsigned int v19 = v32 + 16;
          unint64_t v31 = v30 + ~v31;
        }
        unint64_t v30 = v31;
      }
      while (v31);
    }
    uint64_t v18 = (v19 - a2) >> 4;
    unint64_t v35 = v19;
    if (v23 == a2) {
      goto LABEL_55;
    }
LABEL_39:
    unint64_t v35 = v23;
    if (a2 != v19)
    {
      uint64_t v36 = *(void *)v23;
      *(void *)uint64_t v23 = v11;
      *(void *)a2 = v36;
      int v37 = *((_DWORD *)v23 + 2);
      *((_DWORD *)v23 + 2) = v12;
      *((_DWORD *)a2 + 2) = v37;
      unint64_t v35 = v23 + 16;
      for (uint64_t i = a2 + 16; i != v19; i += 16)
      {
        if (v35 == a2) {
          a2 = i;
        }
        uint64_t v39 = *(void *)v35;
        *(void *)unint64_t v35 = *(void *)i;
        *(void *)uint64_t i = v39;
        LODWORD(v39) = *((_DWORD *)v35 + 2);
        *((_DWORD *)v35 + 2) = *((_DWORD *)i + 2);
        *((_DWORD *)i + 2) = v39;
        v35 += 16;
      }
      if (v35 != a2)
      {
        uint64_t v40 = v35;
        int v41 = a2;
        while (1)
        {
          uint64_t v42 = *(void *)v40;
          *(void *)uint64_t v40 = *(void *)a2;
          *(void *)a2 = v42;
          LODWORD(v42) = *((_DWORD *)v40 + 2);
          *((_DWORD *)v40 + 2) = *((_DWORD *)a2 + 2);
          *((_DWORD *)a2 + 2) = v42;
          v40 += 16;
          a2 += 16;
          BOOL v43 = v40 == v41;
          if (a2 == v19)
          {
            if (v40 == v41) {
              goto LABEL_55;
            }
            a2 = v41 + 16;
            while (1)
            {
              uint64_t v44 = *(void *)v40;
              *(void *)uint64_t v40 = *(void *)v41;
              *(void *)int v41 = v44;
              LODWORD(v44) = *((_DWORD *)v40 + 2);
              *((_DWORD *)v40 + 2) = *((_DWORD *)v41 + 2);
              *((_DWORD *)v41 + 2) = v44;
              v40 += 16;
              BOOL v43 = v40 == v41;
              if (a2 != v19) {
                break;
              }
              if (v40 == v41) {
                goto LABEL_55;
              }
            }
          }
          if (v43) {
            int v41 = a2;
          }
        }
      }
      unint64_t v35 = a2;
    }
    goto LABEL_55;
  }
  unsigned int v64 = &result[v10];
  *(void *)unsigned int v64 = v11;
  *(void *)a2 = v14;
  *((_DWORD *)v64 + 2) = v12;
  *((_DWORD *)a2 + 2) = v15;
  return result;
}

uint64_t llvm::function_ref<mlir::PatternBenefit ()(mlir::Pattern const&)>::callback_fn<anonymous namespace'::OperationLegalizer::computeLegalizationGraphBenefit(llvm::SmallVector<mlir::Pattern const*,1u> &,llvm::DenseMap<mlir::OperationName,llvm::SmallVector<mlir::Pattern const*,1u>,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,llvm::SmallVector<mlir::Pattern const*,1u>>> &)::$_0>(uint64_t *a1, uint64_t a2)
{
  BOOL v3 = *(_DWORD *)(a2 + 8) == 1;
  uint64_t v4 = *(void *)a2;
  if (*(_DWORD *)(a2 + 8) == 1) {
    uint64_t v5 = *(void *)a2;
  }
  else {
    uint64_t v5 = 0;
  }
  v26[0] = v5;
  v26[1] = v3;
  if (v3)
  {
    uint64_t v6 = *a1;
    int v7 = *(_DWORD *)(v6 + 16);
    if (v7)
    {
      unsigned int v8 = v7 - 1;
      uint64_t v9 = v8 & ((v4 >> 4) ^ (v4 >> 9));
      uint64_t v10 = (uint64_t *)(*(void *)v6 + 32 * v9);
      uint64_t v11 = *v10;
      if (*v10 == v5) {
        goto LABEL_26;
      }
      unsigned int v12 = 0;
      int v13 = 1;
      while (v11 != -4096)
      {
        if (v12) {
          BOOL v14 = 0;
        }
        else {
          BOOL v14 = v11 == -8192;
        }
        if (v14) {
          unsigned int v12 = v10;
        }
        int v15 = v9 + v13++;
        uint64_t v9 = v15 & v8;
        uint64_t v10 = (uint64_t *)(*(void *)v6 + 32 * v9);
        uint64_t v11 = *v10;
        if (*v10 == v5) {
          goto LABEL_26;
        }
      }
      if (v12) {
        unint64_t v24 = v12;
      }
      else {
        unint64_t v24 = v10;
      }
    }
    else
    {
      unint64_t v24 = 0;
    }
    uint64_t v10 = llvm::DenseMapBase<llvm::DenseMap<mlir::OperationName,llvm::SmallVector<mlir::Pattern const*,1u>,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,llvm::SmallVector<mlir::Pattern const*,1u>>>,mlir::OperationName,llvm::SmallVector<mlir::Pattern const*,1u>,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,llvm::SmallVector<mlir::Pattern const*,1u>>>::InsertIntoBucket<mlir::OperationName>(v6, v24, v26);
LABEL_26:
    unint64_t v25 = v10 + 1;
    uint64_t v17 = (void *)v10[1];
    uint64_t v18 = *((unsigned int *)v25 + 2);
    uint64_t v19 = (uint64_t)&v17[v18];
    if (v18) {
      goto LABEL_18;
    }
    return 0xFFFFLL;
  }
  uint64_t v16 = a1[1];
  uint64_t v17 = *(void **)v16;
  uint64_t v18 = *(unsigned int *)(v16 + 8);
  uint64_t v19 = *(void *)v16 + 8 * v18;
  if (!v18) {
    return 0xFFFFLL;
  }
LABEL_18:
  uint64_t v20 = 8 * v18;
  uint64_t v21 = v17;
  while (*v21 != a2)
  {
    ++v21;
    v20 -= 8;
    if (!v20)
    {
      uint64_t v21 = (void *)v19;
      break;
    }
  }
  uint64_t v22 = v21 - v17;
  if (v22 == v18) {
    return 0xFFFFLL;
  }
  mlir::PatternBenefit::PatternBenefit(v26, (unint64_t)(v19 - (void)&v17[v22]) >> 3);
  return LOWORD(v26[0]);
}

uint64_t anonymous namespace'::OperationConverter::finalize(_anonymous_namespace_::OperationConverter *this, mlir::ConversionPatternRewriter *a2)
{
  uint64_t v204 = *MEMORY[0x263EF8340];
  uint64_t v2 = (void **)*((void *)this + 7);
  if (*((_DWORD *)v2 + 68))
  {
    __dst[0] = 0;
    __dst[1] = 0;
    LODWORD(v195) = 0;
    llvm::deallocate_buffer(0, 0);
  }
  uint64_t v179 = *((void *)this + 7);
  uint64_t v3 = *((unsigned int *)v2 + 26);
  if (v3)
  {
    uint64_t v4 = v2[12];
    uint64_t v165 = &v4[8 * v3];
    int64x2_t v5 = vdupq_n_s64(1uLL);
    v5.i64[0] = (uint64_t)&v178;
    int64x2_t v168 = v5;
    while (1)
    {
      uint64_t v172 = v4;
      long long v174 = (mlir::detail::OpResultImpl *)v4[1];
      unint64_t v6 = *((void *)v174 + 7) - *((void *)v174 + 6);
      if ((v6 & 0x7FFFFFFF8) != 0) {
        break;
      }
LABEL_83:
      uint64_t v4 = v172 + 8;
      if (v172 + 8 == v165) {
        goto LABEL_84;
      }
    }
    int v7 = 0;
    uint64_t v166 = *v4;
    unint64_t v170 = (v6 >> 3);
    while (1)
    {
      unsigned int v8 = *(void **)(*((void *)v174 + 6) + 8 * (void)v7);
      uint64_t v9 = (uint64_t)*v2;
      LODWORD(v10) = *((_DWORD *)v2 + 4);
      unint64_t v11 = v8[1] & 0xFFFFFFFFFFFFFFF8;
      if (v11)
      {
        unint64_t v12 = 0;
        int v13 = *(void **)(*((void *)v174 + 6) + 8 * (void)v7);
        do
        {
          unint64_t v14 = (unint64_t)v13;
          if ((v13[1] & 0xFFFFFFFFFFFFFFF8) == v11) {
            unint64_t v12 = (unint64_t)v13;
          }
          if (!v10) {
            break;
          }
          {
            unint64_t v21 = llvm::hashing::detail::fixed_seed_override;
            if (!llvm::hashing::detail::fixed_seed_override) {
              unint64_t v21 = 0xFF51AFD7ED558CCDLL;
            }
            llvm::hashing::detail::get_execution_seed(void)::seed = v21;
          }
          unint64_t v15 = 0x9DDFEA08EB382D69
              * ((llvm::hashing::detail::get_execution_seed(void)::seed + 8 * v14) ^ HIDWORD(v14));
          unint64_t v16 = 0x9DDFEA08EB382D69 * (HIDWORD(v14) ^ (v15 >> 47) ^ v15);
          LODWORD(v16) = (-348639895 * ((v16 >> 47) ^ v16)) & (v10 - 1);
          uint64_t v17 = (void *)(v9 + 16 * v16);
          uint64_t v18 = (void *)*v17;
          if (v14 != *v17)
          {
            int v19 = 1;
            while (v18 != (void *)-4096)
            {
              int v20 = v16 + v19++;
              unint64_t v16 = v20 & (v10 - 1);
              uint64_t v18 = *(void **)(v9 + 16 * v16);
              if ((void *)v14 == v18)
              {
                uint64_t v17 = (void *)(v9 + 16 * v16);
                uint64_t v9 = (uint64_t)*v2;
                uint64_t v10 = *((unsigned int *)v2 + 4);
                if (v17 != (void *)((char *)*v2 + 16 * v10)) {
                  goto LABEL_17;
                }
                goto LABEL_28;
              }
            }
            break;
          }
          uint64_t v9 = (uint64_t)*v2;
          uint64_t v10 = *((unsigned int *)v2 + 4);
          if (v17 == (void *)((char *)*v2 + 16 * v10)) {
            break;
          }
LABEL_17:
          int v13 = (void *)v17[1];
        }
        while (v13);
LABEL_28:
        if (!v12) {
          unint64_t v12 = v14;
        }
      }
      else
      {
        uint64_t v22 = *(void **)(*((void *)v174 + 6) + 8 * (void)v7);
        do
        {
          unint64_t v12 = (unint64_t)v22;
          if (!v10) {
            break;
          }
          {
            unint64_t v29 = llvm::hashing::detail::fixed_seed_override;
            if (!llvm::hashing::detail::fixed_seed_override) {
              unint64_t v29 = 0xFF51AFD7ED558CCDLL;
            }
            llvm::hashing::detail::get_execution_seed(void)::seed = v29;
          }
          unint64_t v23 = 0x9DDFEA08EB382D69
              * ((llvm::hashing::detail::get_execution_seed(void)::seed + 8 * v12) ^ HIDWORD(v12));
          unint64_t v24 = 0x9DDFEA08EB382D69 * (HIDWORD(v12) ^ (v23 >> 47) ^ v23);
          LODWORD(v24) = (-348639895 * ((v24 >> 47) ^ v24)) & (v10 - 1);
          unint64_t v25 = (void *)(v9 + 16 * v24);
          unsigned int v26 = (void *)*v25;
          if (v12 != *v25)
          {
            int v27 = 1;
            while (v26 != (void *)-4096)
            {
              int v28 = v24 + v27++;
              unint64_t v24 = v28 & (v10 - 1);
              unsigned int v26 = *(void **)(v9 + 16 * v24);
              if ((void *)v12 == v26)
              {
                unint64_t v25 = (void *)(v9 + 16 * v24);
                uint64_t v9 = (uint64_t)*v2;
                uint64_t v10 = *((unsigned int *)v2 + 4);
                if (v25 != (void *)((char *)*v2 + 16 * v10)) {
                  goto LABEL_39;
                }
                goto LABEL_30;
              }
            }
            break;
          }
          uint64_t v9 = (uint64_t)*v2;
          uint64_t v10 = *((unsigned int *)v2 + 4);
          if (v25 == (void *)((char *)*v2 + 16 * v10)) {
            break;
          }
LABEL_39:
          uint64_t v22 = (void *)v25[1];
        }
        while (v22);
      }
LABEL_30:
      if ((void *)v12 != v8)
      {
        if (v11)
        {
          if ((*(void *)(v12 + 8) & 0xFFFFFFFFFFFFFFF8) == v11) {
            goto LABEL_8;
          }
        }
        else if (v12)
        {
          goto LABEL_8;
        }
      }
      unint64_t v30 = *v2;
      LODWORD(v31) = *((_DWORD *)v2 + 4);
      BOOL v32 = v8;
      do
      {
        unint64_t v33 = (unint64_t)v32;
        if (!v31) {
          break;
        }
        {
          unint64_t v40 = llvm::hashing::detail::fixed_seed_override;
          if (!llvm::hashing::detail::fixed_seed_override) {
            unint64_t v40 = 0xFF51AFD7ED558CCDLL;
          }
          llvm::hashing::detail::get_execution_seed(void)::seed = v40;
        }
        unint64_t v34 = 0x9DDFEA08EB382D69
            * ((llvm::hashing::detail::get_execution_seed(void)::seed + 8 * v33) ^ HIDWORD(v33));
        unint64_t v35 = 0x9DDFEA08EB382D69 * (HIDWORD(v33) ^ (v34 >> 47) ^ v34);
        LODWORD(v35) = (-348639895 * ((v35 >> 47) ^ v35)) & (v31 - 1);
        uint64_t v36 = (void **)&v30[2 * v35];
        int v37 = *v36;
        if ((void *)v33 != *v36)
        {
          int v38 = 1;
          while (v37 != (void *)-4096)
          {
            int v39 = v35 + v38++;
            unint64_t v35 = v39 & (v31 - 1);
            int v37 = (void *)v30[2 * v35];
            if ((void *)v33 == v37)
            {
              uint64_t v36 = (void **)&v30[2 * v35];
              unint64_t v30 = *v2;
              uint64_t v31 = *((unsigned int *)v2 + 4);
              if (v36 != (void **)((char *)*v2 + 16 * v31)) {
                goto LABEL_57;
              }
              goto LABEL_68;
            }
          }
          break;
        }
        unint64_t v30 = *v2;
        uint64_t v31 = *((unsigned int *)v2 + 4);
        if (v36 == (void **)((char *)*v2 + 16 * v31)) {
          break;
        }
LABEL_57:
        BOOL v32 = v36[1];
      }
      while (v32);
LABEL_68:
      unint64_t v178 = v33;
      int v41 = v2[23];
      uint64_t v176 = (llvm *)v8;
      long long v169 = v7;
      if ((void *)v33 == v8)
      {
        uint64_t v47 = *(void *)(v166 + 40);
        void v41[3] = v166;
        uint64_t v41[4] = v47;
        uint64_t v46 = v172[7];
        if (!v46) {
          break;
        }
        uint64_t v48 = (char *)v2[23];
        uint64_t v49 = *((void *)v176 + 4);
        uint64_t v50 = *((void *)v176 + 1);
        mlir::ValueRange::ValueRange((unint64_t *)v181, 0, 0);
        int64x2_t v177 = *(int64x2_t *)v181;
      }
      else
      {
        __dst[0] = (void *)v33;
        uint64_t DefiningOp = (ZinIrHalH13g *)mlir::Value::getDefiningOp((mlir::Value *)__dst);
        if (DefiningOp)
        {
          uint64_t v43 = *((void *)DefiningOp + 2);
          ZinIrHalH13g::~ZinIrHalH13g(DefiningOp);
          uint64_t v45 = *(void *)(v44 + 8);
          void v41[3] = v43;
          uint64_t v41[4] = v45;
          uint64_t v46 = v172[7];
          if (!v46) {
            break;
          }
        }
        else
        {
          uint64_t v51 = *((void *)__dst[0] + 2);
          uint64_t v52 = *(void *)(v51 + 40);
          void v41[3] = v51;
          uint64_t v41[4] = v52;
          uint64_t v46 = v172[7];
          if (!v46) {
            break;
          }
        }
        uint64_t v48 = (char *)v2[23];
        uint64_t v49 = *((void *)v176 + 4);
        uint64_t v50 = *((void *)v176 + 1);
        int64x2_t v177 = v168;
        v181[0] = (llvm *)&v178;
        v181[1] = (llvm *)1;
      }
      unsigned int v53 = v48 + 8;
      unsigned int v54 = (llvm *)(v50 & 0xFFFFFFFFFFFFFFF8);
      uint64_t v55 = *(void *)(v46 + 232) + 32 * *(unsigned int *)(v46 + 240);
      uint64_t v56 = -32 * *(unsigned int *)(v46 + 240);
      do
      {
        if (!v56) {
          goto LABEL_122;
        }
        uint64_t v183 = v54;
        *(int64x2_t *)__dst = v177;
        uint64_t v180 = v49;
        uint64_t v57 = *(void *)(v55 - 8);
        if (!v57)
        {
          std::__throw_bad_function_call[abi:nn180100]();
          goto LABEL_222;
        }
        v55 -= 32;
        uint64_t v58 = (*(uint64_t (**)(uint64_t, char *, llvm **, void **, uint64_t *))(*(void *)v57 + 48))(v57, v53, &v183, __dst, &v180);
        v56 += 32;
      }
      while (!v59);
      uint64_t v60 = v58;
      if (!v58) {
        break;
      }
      uint64_t v183 = v176;
      __dst[0] = 0;
      char v61 = llvm::DenseMapBase<llvm::DenseMap<mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>,mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>::LookupBucketFor<mlir::Value>((uint64_t *)v2, (unint64_t *)&v183, __dst);
      unsigned int v62 = __dst[0];
      if ((v61 & 1) == 0)
      {
        unsigned int v62 = llvm::DenseMapBase<llvm::DenseMap<mlir::Value,mlir::Value,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,mlir::Value>>,mlir::Value,mlir::Value,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,mlir::Value>>::InsertIntoBucketImpl<mlir::Value>((uint64_t)v2, (uint64_t)&v183, (unint64_t *)&v183, (void *)__dst[0]);
        *unsigned int v62 = v183;
        v62[1] = 0;
      }
      int v7 = v169;
      v62[1] = v60;
LABEL_8:
      int v7 = (char *)v7 + 1;
      if (v7 == (void *)v170) {
        goto LABEL_83;
      }
    }
LABEL_122:
    unint64_t v97 = v176;
    mlir::emitError(*((void *)v176 + 4), (uint64_t)&v183);
    uint64_t v98 = v183;
    if (v183)
    {
      uint64_t v56 = (uint64_t)&v186;
      LODWORD(__dst[0]) = 3;
      __dst[1] = "failed to materialize conversion for block argument #";
      uint64_t v195 = 53;
      int v99 = __dst;
      unsigned int v100 = (char *)v186;
      if (v187 >= HIDWORD(v187))
      {
        unint64_t v148 = v187 + 1;
        if (v186 <= __dst && (char *)v186 + 24 * v187 > (char *)__dst)
        {
          int64_t v158 = (char *)__dst - (unsigned char *)v186;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v186, v188, v148, 24);
          unsigned int v100 = (char *)v186;
          int v99 = (void **)((char *)v186 + v158);
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v186, v188, v148, 24);
          int v99 = __dst;
          unsigned int v100 = (char *)v186;
        }
      }
      unint64_t v101 = &v100[24 * v187];
      long long v102 = *(_OWORD *)v99;
      *((void *)v101 + 2) = v99[2];
      *(_OWORD *)unint64_t v101 = v102;
      uint64_t v103 = (v187 + 1);
      LODWORD(v187) = v187 + 1;
      uint64_t v98 = v183;
      if (v183)
      {
        LODWORD(__dst[0]) = 5;
        __dst[1] = v169;
        int v104 = __dst;
        BOOL v105 = (char *)v186;
        if (v103 >= HIDWORD(v187))
        {
          unint64_t v150 = v103 + 1;
          BOOL v151 = (char *)v186 + 24 * v103 > (char *)__dst;
          if (v186 <= __dst && v151)
          {
            int64_t v160 = (char *)__dst - (unsigned char *)v186;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v186, v188, v150, 24);
            BOOL v105 = (char *)v186;
            int v104 = (void **)((char *)v186 + v160);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v186, v188, v150, 24);
            int v104 = __dst;
            BOOL v105 = (char *)v186;
          }
        }
        unsigned int v106 = &v105[24 * v187];
        long long v107 = *(_OWORD *)v104;
        *((void *)v106 + 2) = v104[2];
        *(_OWORD *)unsigned int v106 = v107;
        uint64_t v108 = (v187 + 1);
        LODWORD(v187) = v187 + 1;
        uint64_t v98 = v183;
        if (v183)
        {
          LODWORD(__dst[0]) = 3;
          __dst[1] = " that remained live after conversion, type was ";
          uint64_t v195 = 47;
          unint64_t v109 = __dst;
          unsigned int v110 = (char *)v186;
          if (v108 >= HIDWORD(v187))
          {
            unint64_t v153 = v108 + 1;
            BOOL v154 = (char *)v186 + 24 * v108 > (char *)__dst;
            if (v186 <= __dst && v154)
            {
              int64_t v162 = (char *)__dst - (unsigned char *)v186;
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v186, v188, v153, 24);
              unsigned int v110 = (char *)v186;
              unint64_t v109 = (void **)((char *)v186 + v162);
            }
            else
            {
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v186, v188, v153, 24);
              unint64_t v109 = __dst;
              unsigned int v110 = (char *)v186;
            }
            unint64_t v97 = v176;
          }
          unsigned int v111 = &v110[24 * v187];
          long long v112 = *(_OWORD *)v109;
          *((void *)v111 + 2) = v109[2];
          *(_OWORD *)unsigned int v111 = v112;
          LODWORD(v187) = v187 + 1;
          uint64_t v98 = v183;
          if (v183)
          {
            uint64_t v2 = __dst;
            mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)__dst, *((void *)v97 + 1) & 0xFFFFFFFFFFFFFFF8);
            uint64_t v113 = v187;
            int v114 = (void **)v186;
            if (v187 >= HIDWORD(v187))
            {
LABEL_222:
              unint64_t v155 = v113 + 1;
              BOOL v156 = &v114[3 * v113] > v2;
              if (v114 <= v2 && v156)
              {
                uint64_t v163 = (char *)((char *)__dst - (char *)v114);
                llvm::SmallVectorBase<unsigned int>::grow_pod(v56, v188, v155, 24);
                int v114 = (void **)v186;
                uint64_t v2 = (void **)&v163[(void)v186];
              }
              else
              {
                llvm::SmallVectorBase<unsigned int>::grow_pod(v56, v188, v155, 24);
                uint64_t v2 = __dst;
                int v114 = (void **)v186;
              }
              unint64_t v97 = v176;
            }
            BOOL v115 = &v114[3 * v187];
            long long v116 = *(_OWORD *)v2;
            v115[2] = v2[2];
            *(_OWORD *)BOOL v115 = v116;
            LODWORD(v187) = v187 + 1;
            uint64_t v98 = v183;
          }
        }
      }
    }
    __dst[0] = v98;
    LOBYTE(__dst[1]) = 0;
    char v203 = 0;
    if (!v193)
    {
LABEL_147:
      mlir::InFlightDiagnostic::abandon(&v183);
      if (v183) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v183);
      }
      if (v193)
      {
        uint64_t v122 = __p[0];
        if (__p[0])
        {
          unsigned int v123 = __p[1];
          uint64_t v124 = __p[0];
          if (__p[1] != __p[0])
          {
            do
              unsigned int v123 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v123 - 1);
            while (v123 != v122);
            uint64_t v124 = __p[0];
          }
          __p[1] = v122;
          operator delete(v124);
        }
        uint64_t v125 = (void *)v189;
        if ((void)v189)
        {
          unint64_t v126 = (void *)*((void *)&v189 + 1);
          uint64_t v127 = (void *)v189;
          if (*((void *)&v189 + 1) != (void)v189)
          {
            do
            {
              uint64_t v129 = *--v126;
              uint64_t v128 = v129;
              *unint64_t v126 = 0;
              if (v129) {
                MEMORY[0x21667D390](v128, 0x1000C8077774924);
              }
            }
            while (v126 != v125);
            uint64_t v127 = (void *)v189;
          }
          *((void *)&v189 + 1) = v125;
          operator delete(v127);
          unint64_t v97 = v176;
        }
        if (v186 != v188) {
          free(v186);
        }
      }
      if ((llvm *)v33 != v97 && __dst[0])
      {
        LODWORD(v183) = 3;
        long long v184 = ", with target type ";
        uint64_t v185 = 19;
        unsigned int v130 = &v183;
        unsigned int v131 = (char *)v196;
        if (v197 >= HIDWORD(v197))
        {
          unint64_t v149 = v197 + 1;
          if (v196 <= &v183 && (char *)v196 + 24 * v197 > (char *)&v183)
          {
            int64_t v159 = (char *)&v183 - (unsigned char *)v196;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v196, v198, v149, 24);
            unsigned int v131 = (char *)v196;
            unsigned int v130 = (llvm **)((char *)v196 + v159);
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v196, v198, v149, 24);
            unsigned int v130 = &v183;
            unsigned int v131 = (char *)v196;
          }
        }
        uint64_t v132 = &v131[24 * v197];
        long long v133 = *(_OWORD *)v130;
        *((void *)v132 + 2) = v130[2];
        *(_OWORD *)uint64_t v132 = v133;
        LODWORD(v197) = v197 + 1;
        if (__dst[0])
        {
          int v134 = &v183;
          mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v183, *(void *)(v178 + 8) & 0xFFFFFFFFFFFFFFF8);
          BOOL v135 = (char *)v196;
          if (v197 >= HIDWORD(v197))
          {
            unint64_t v152 = v197 + 1;
            if (v196 <= &v183 && (char *)v196 + 24 * v197 > (char *)&v183)
            {
              int64_t v161 = (char *)&v183 - (unsigned char *)v196;
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v196, v198, v152, 24);
              BOOL v135 = (char *)v196;
              int v134 = (llvm **)((char *)v196 + v161);
            }
            else
            {
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v196, v198, v152, 24);
              int v134 = &v183;
              BOOL v135 = (char *)v196;
            }
          }
          unsigned int v136 = &v135[24 * v197];
          long long v137 = *(_OWORD *)v134;
          *((void *)v136 + 2) = v134[2];
          *(_OWORD *)unsigned int v136 = v137;
          LODWORD(v197) = v197 + 1;
        }
      }
      mlir::Diagnostic::attachNote();
    }
    __dst[1] = (void *)v184;
    int v117 = v187;
    LODWORD(v195) = v185;
    unint64_t v118 = v198;
    uint64_t v196 = v198;
    uint64_t v197 = 0x400000000;
    if (!v187)
    {
      int v120 = 1;
      goto LABEL_143;
    }
    unint64_t v119 = v188;
    if (v186 != v188)
    {
      uint64_t v196 = v186;
      uint64_t v197 = v187;
      uint64_t v186 = v188;
      HIDWORD(v187) = 0;
      int v120 = 1;
LABEL_142:
      LODWORD(v187) = 0;
LABEL_143:
      long long v199 = v189;
      uint64_t v200 = v190;
      long long v189 = 0uLL;
      *(_OWORD *)uint64_t v201 = *(_OWORD *)__p;
      uint64_t v202 = v192;
      uint64_t v190 = 0;
      __p[0] = 0;
      __p[1] = 0;
      uint64_t v192 = 0;
      char v203 = 1;
      unint64_t v97 = v176;
      if (v120)
      {
        if (v186 != v188) {
          free(v186);
        }
        unsigned __int8 v193 = 0;
      }
      goto LABEL_147;
    }
    if (v187 < 5)
    {
      uint64_t v121 = v187;
    }
    else
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v196, v198, v187, 24);
      uint64_t v121 = v187;
      if (!v187)
      {
LABEL_141:
        LODWORD(v197) = v117;
        int v120 = v193;
        goto LABEL_142;
      }
      unint64_t v119 = v186;
      unint64_t v118 = v196;
    }
    memcpy(v118, v119, 24 * v121);
    goto LABEL_141;
  }
LABEL_84:
  int v63 = *((_DWORD *)v2 + 300);
  if (v63)
  {
    unsigned int v64 = 0;
    while (1)
    {
      unsigned int v167 = v64;
      uint64_t v65 = (uint64_t)v2[44] + 16 * *((unsigned int *)v2[149] + v64);
      uint64_t v66 = *(unsigned int *)(*(void *)v65 + 36);
      uint64_t v67 = *(void *)v65 - 16;
      if (!v66) {
        uint64_t v67 = 0;
      }
      uint64_t v175 = (mlir::detail::OpResultImpl *)v67;
      if (v66) {
        break;
      }
LABEL_86:
      unsigned int v64 = v167 + 1;
      if (v167 + 1 == v63) {
        return 1;
      }
    }
    uint64_t v68 = 0;
    uint64_t v173 = (uint64_t *)v65;
LABEL_92:
    uint64_t NextResultAtOffset = (void *)mlir::detail::OpResultImpl::getNextResultAtOffset((uint64_t)v175, v68);
    if (v70)
    {
      if ((NextResultAtOffset[1] & 0xFFFFFFFFFFFFFFF8) != (*(void *)(v70 + 8) & 0xFFFFFFFFFFFFFFF8))
      {
        __dst[0] = 0;
        __dst[1] = 0;
        LODWORD(v195) = 0;
        llvm::deallocate_buffer(0, 0);
      }
      goto LABEL_91;
    }
    int v71 = (void *)*NextResultAtOffset;
    if (!*NextResultAtOffset) {
      goto LABEL_91;
    }
    uint64_t v171 = *v173;
    while (1)
    {
      uint64_t v76 = v71[2];
      int v77 = v2[41];
      uint64_t v78 = *((unsigned int *)v2 + 86);
      if (!v78) {
        goto LABEL_106;
      }
      LODWORD(v79) = ((v76 >> 4) ^ (v76 >> 9)) & (v78 - 1);
      uint64_t v80 = &v77[2 * v79];
      uint64_t v81 = *v80;
      if (*v80 != v76) {
        break;
      }
LABEL_107:
      if (v80 == &v77[2 * v78])
      {
        uint64_t ParentOp = *(mlir::Block **)(v76 + 16);
        if (ParentOp) {
          uint64_t ParentOp = (mlir::Block *)mlir::Block::getParentOp(ParentOp);
        }
        int v85 = *((_DWORD *)v2 + 152);
        if (!v85) {
          goto LABEL_113;
        }
        int v86 = v2[74];
        int v87 = v85 - 1;
        unsigned int v74 = ((ParentOp >> 4) ^ (ParentOp >> 9)) & v87;
        uint64_t v75 = (mlir::Block *)v86[v74];
        if (v75 != ParentOp)
        {
          int v73 = 1;
          while (v75 != (mlir::Block *)-4096)
          {
            unsigned int v72 = v74 + v73++;
            unsigned int v74 = v72 & v87;
            uint64_t v75 = (mlir::Block *)v86[v74];
            if (v75 == ParentOp) {
              goto LABEL_99;
            }
          }
LABEL_113:
          if (v71)
          {
            v181[0] = (llvm *)"failed to legalize operation '";
            LOWORD(v182) = 259;
            mlir::Operation::emitError(v171, (uint64_t)v181, (uint64_t)&v183);
            unsigned int v88 = v183;
            if (v183)
            {
              mlir::Diagnostic::operator<<((uint64_t)&v184, *(void *)(v171 + 48));
              unsigned int v88 = v183;
              if (v183)
              {
                LODWORD(__dst[0]) = 3;
                __dst[1] = "' marked as erased";
                uint64_t v195 = 18;
                uint64_t v89 = __dst;
                int v90 = (char *)v186;
                if (v187 >= HIDWORD(v187))
                {
                  unint64_t v157 = v187 + 1;
                  if (v186 <= __dst && (char *)v186 + 24 * v187 > (char *)__dst)
                  {
                    int64_t v164 = (char *)__dst - (unsigned char *)v186;
                    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v186, v188, v157, 24);
                    int v90 = (char *)v186;
                    uint64_t v89 = (void **)((char *)v186 + v164);
                  }
                  else
                  {
                    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v186, v188, v157, 24);
                    uint64_t v89 = __dst;
                    int v90 = (char *)v186;
                  }
                }
                int v91 = &v90[24 * v187];
                long long v92 = *(_OWORD *)v89;
                *((void *)v91 + 2) = v89[2];
                *(_OWORD *)int v91 = v92;
                LODWORD(v187) = v187 + 1;
                unsigned int v88 = v183;
              }
            }
            __dst[0] = v88;
            LOBYTE(__dst[1]) = 0;
            char v203 = 0;
            if (v193)
            {
              __dst[1] = (void *)v184;
              int v93 = v187;
              LODWORD(v195) = v185;
              uint64_t v94 = v198;
              uint64_t v196 = v198;
              uint64_t v197 = 0x400000000;
              if (v187)
              {
                uint64_t v95 = v188;
                if (v186 != v188)
                {
                  uint64_t v196 = v186;
                  uint64_t v197 = v187;
                  uint64_t v186 = v188;
                  HIDWORD(v187) = 0;
                  int v96 = 1;
                  goto LABEL_180;
                }
                if (v187 < 5)
                {
                  uint64_t v138 = v187;
LABEL_178:
                  memcpy(v94, v95, 24 * v138);
                }
                else
                {
                  llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v196, v198, v187, 24);
                  uint64_t v138 = v187;
                  if (v187)
                  {
                    uint64_t v95 = v186;
                    uint64_t v94 = v196;
                    goto LABEL_178;
                  }
                }
                LODWORD(v197) = v93;
                int v96 = v193;
LABEL_180:
                LODWORD(v187) = 0;
              }
              else
              {
                int v96 = 1;
              }
              long long v199 = v189;
              uint64_t v200 = v190;
              long long v189 = 0uLL;
              *(_OWORD *)uint64_t v201 = *(_OWORD *)__p;
              uint64_t v202 = v192;
              uint64_t v190 = 0;
              __p[0] = 0;
              __p[1] = 0;
              uint64_t v192 = 0;
              char v203 = 1;
              if (v96)
              {
                if (v186 != v188) {
                  free(v186);
                }
                unsigned __int8 v193 = 0;
              }
            }
            mlir::InFlightDiagnostic::abandon(&v183);
            if (v183) {
              mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v183);
            }
            if (v193)
            {
              long long v139 = __p[0];
              if (__p[0])
              {
                int64x2_t v140 = __p[1];
                int64x2_t v141 = __p[0];
                if (__p[1] != __p[0])
                {
                  do
                    int64x2_t v140 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v140 - 1);
                  while (v140 != v139);
                  int64x2_t v141 = __p[0];
                }
                __p[1] = v139;
                operator delete(v141);
              }
              unint64_t v142 = (void *)v189;
              if ((void)v189)
              {
                int v143 = (void *)*((void *)&v189 + 1);
                uint64_t v144 = (void *)v189;
                if (*((void *)&v189 + 1) != (void)v189)
                {
                  do
                  {
                    uint64_t v146 = *--v143;
                    uint64_t v145 = v146;
                    *int v143 = 0;
                    if (v146) {
                      MEMORY[0x21667D390](v145, 0x1000C8077774924);
                    }
                  }
                  while (v143 != v142);
                  uint64_t v144 = (void *)v189;
                }
                *((void *)&v189 + 1) = v142;
                operator delete(v144);
              }
              if (v186 != v188) {
                free(v186);
              }
            }
            mlir::Diagnostic::attachNote();
          }
LABEL_91:
          if (++v68 == v66) {
            goto LABEL_86;
          }
          goto LABEL_92;
        }
      }
LABEL_99:
      int v71 = (void *)*v71;
      if (!v71) {
        goto LABEL_91;
      }
    }
    int v82 = 1;
    while (v81 != -4096)
    {
      int v83 = v79 + v82++;
      uint64_t v79 = v83 & (v78 - 1);
      uint64_t v81 = v77[2 * v79];
      if (v81 == v76)
      {
        uint64_t v80 = &v77[2 * v79];
        goto LABEL_107;
      }
    }
LABEL_106:
    uint64_t v80 = &v77[2 * v78];
    goto LABEL_107;
  }
  return 1;
}

uint64_t mlir::detail::walk<mlir::ForwardDominanceIterator<false>>(mlir::ForwardIterator *a1, mlir::Operation *a2, uint64_t a3, int a4)
{
  if (!a4)
  {
    uint64_t result = ((uint64_t (*)(uint64_t, mlir::ForwardIterator *))a2)(a3, a1);
    if (!result) {
      return result;
    }
    if (result == 2) {
      return 1;
    }
  }
  uint64_t v31 = a1;
  uint64_t Iterable = mlir::ForwardIterator::makeIterable(a1, a2);
  if (!v9)
  {
LABEL_48:
    if (a4 == 1) {
      return ((uint64_t (*)(uint64_t, mlir::ForwardIterator *))a2)(a3, v31);
    }
    return 1;
  }
  uint64_t v10 = (void *)Iterable;
  BOOL v32 = (void *)(Iterable + 24 * v9);
  while (1)
  {
    mlir::ForwardDominanceIterator<false>::makeIterable(v10, (uint64_t)&v45);
    llvm::SmallPtrSetImplBase::SmallPtrSetImplBase((llvm::SmallPtrSetImplBase *)&v39, &v41, (const llvm::SmallPtrSetImplBase *)&v45);
    uint64_t v42 = 0;
    uint64_t v43 = 0;
    uint64_t v44 = 0;
    unint64_t v11 = v47;
    uint64_t v12 = v48 - (unsigned char *)v47;
    if (v48 != v47)
    {
      if (v12 < 0) {
        goto LABEL_55;
      }
      int v13 = (char *)operator new(v48 - (unsigned char *)v47);
      uint64_t v42 = v13;
      uint64_t v43 = v13;
      uint64_t v44 = &v13[32 * (v12 >> 5)];
      size_t v14 = v12 & 0xFFFFFFFFFFFFFFE0;
      memcpy(v13, v11, v14);
      uint64_t v43 = &v13[v14];
    }
    llvm::SmallPtrSetImplBase::SmallPtrSetImplBase((llvm::SmallPtrSetImplBase *)&v33, &v35, (const llvm::SmallPtrSetImplBase *)&v49);
    long long __p = 0;
    int v37 = 0;
    int v38 = 0;
    unint64_t v15 = v51;
    uint64_t v16 = v52 - (unsigned char *)v51;
    if (v52 == v51)
    {
      uint64_t v17 = 0;
      int v19 = 0;
    }
    else
    {
      if (v16 < 0) {
LABEL_55:
      }
        abort();
      uint64_t v17 = (char *)operator new(v52 - (unsigned char *)v51);
      long long __p = v17;
      int v37 = v17;
      int v38 = &v17[32 * (v16 >> 5)];
      size_t v18 = v16 & 0xFFFFFFFFFFFFFFE0;
      memcpy(v17, v15, v18);
      int v19 = &v17[v18];
      int v37 = &v17[v18];
    }
LABEL_12:
    if (v43 - (unsigned char *)v42 == v19 - v17)
    {
      if (v42 == v43)
      {
LABEL_46:
        char v29 = 1;
        if (v17) {
          goto LABEL_28;
        }
        goto LABEL_29;
      }
      uint64_t v20 = 0;
      while (1)
      {
        unint64_t v21 = (char *)v42 + v20;
        if (*(void *)((char *)v42 + v20) != *(void *)&v17[v20]) {
          break;
        }
        int v22 = v17[v20 + 24];
        if (v21[24]) {
          BOOL v23 = v22 == 0;
        }
        else {
          BOOL v23 = 1;
        }
        if (v23)
        {
          if ((v21[24] != 0) != (v22 != 0)) {
            break;
          }
        }
        else if (*(void *)((char *)v42 + v20 + 8) != *(void *)&v17[v20 + 8] {
               || *(void *)((char *)v42 + v20 + 16) != *(void *)&v17[v20 + 16])
        }
        {
          break;
        }
        v20 += 32;
        if (v21 + 32 == v43) {
          goto LABEL_46;
        }
      }
    }
    uint64_t v24 = *((void *)v43 - 4);
    unint64_t v25 = (ZinIrHalH13g *)(v24 + 32);
    unsigned int v26 = *(ZinIrHalH13g **)(v24 + 40);
    do
    {
      if (v26 == v25)
      {
        llvm::df_iterator<mlir::Block *,llvm::df_iterator_default_set<mlir::Block *,8u>,false,llvm::GraphTraits<mlir::Block *>>::toNext((uint64_t)&v39);
        uint64_t v17 = (char *)__p;
        int v19 = v37;
        goto LABEL_12;
      }
      int v27 = (ZinIrHalH13g *)*((void *)v26 + 1);
      ZinIrHalH13g::~ZinIrHalH13g(v26);
      int v28 = mlir::detail::walk<mlir::ForwardDominanceIterator<false>>();
      unsigned int v26 = v27;
    }
    while (v28);
    char v29 = 0;
    uint64_t v17 = (char *)__p;
    if (__p)
    {
LABEL_28:
      int v37 = v17;
      operator delete(v17);
    }
LABEL_29:
    if (v34 != v33) {
      free(v34);
    }
    if (v42)
    {
      uint64_t v43 = (char *)v42;
      operator delete(v42);
    }
    if (v40 != v39) {
      free(v40);
    }
    if (v51)
    {
      uint64_t v52 = v51;
      operator delete(v51);
    }
    if (v50 != v49) {
      free(v50);
    }
    if (v47)
    {
      uint64_t v48 = v47;
      operator delete(v47);
    }
    if (v46 != v45) {
      free(v46);
    }
    if ((v29 & 1) == 0) {
      return 0;
    }
    v10 += 3;
    if (v10 == v32) {
      goto LABEL_48;
    }
  }
}

uint64_t llvm::function_ref<mlir::WalkResult ()(mlir::Operation *)>::callback_fn<anonymous namespace'::OperationConverter::convertOperations(llvm::ArrayRef<mlir::Operation *>,llvm::function_ref<void ()(mlir::Diagnostic &)>)::$_0>(uint64_t *a1, mlir::Operation *a2)
{
  uint64_t v4 = *a1;
  uint64_t v5 = *(unsigned int *)(*a1 + 8);
  if (v5 >= *(_DWORD *)(*a1 + 12))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod(*a1, (void *)(v4 + 16), v5 + 1, 8);
    LODWORD(v5) = *(_DWORD *)(v4 + 8);
  }
  *(void *)(*(void *)v4 + 8 * v5) = a2;
  ++*(_DWORD *)(v4 + 8);
  unsigned __int16 isLegal = mlir::ConversionTarget::isLegal((mlir::ConversionTarget *)a1[1], a2);
  if ((_BYTE)isLegal) {
    BOOL v7 = isLegal >= 0x100u;
  }
  else {
    BOOL v7 = 0;
  }
  if (v7) {
    return 2;
  }
  else {
    return 1;
  }
}

BOOL anonymous namespace'::OperationLegalizer::legalize(mlir::ConversionTarget **this, mlir::Block **a2, mlir::ConversionPatternRewriter *a3)
{
  uint64_t v61 = *MEMORY[0x263EF8340];
  unsigned __int16 isLegal = mlir::ConversionTarget::isLegal(this[12], (mlir::Operation *)a2);
  if (isLegal < 0x100u)
  {
    uint64_t v7 = *((void *)a3 + 7);
    uint64_t v8 = *(void *)(v7 + 328);
    uint64_t v9 = *(unsigned int *)(v7 + 344);
    if (v9)
    {
      LODWORD(v10) = (v9 - 1) & ((a2 >> 4) ^ (a2 >> 9));
      unint64_t v11 = (mlir::Operation **)(v8 + 16 * v10);
      uint64_t v12 = *v11;
      if (*v11 == (mlir::Operation *)a2) {
        goto LABEL_12;
      }
      int v13 = 1;
      while (v12 != (mlir::Operation *)-4096)
      {
        int v14 = v10 + v13++;
        uint64_t v10 = v14 & (v9 - 1);
        uint64_t v12 = *(mlir::Operation **)(v8 + 16 * v10);
        if (v12 == (mlir::Operation *)a2)
        {
          unint64_t v11 = (mlir::Operation **)(v8 + 16 * v10);
          goto LABEL_12;
        }
      }
    }
    unint64_t v11 = (mlir::Operation **)(v8 + 16 * v9);
LABEL_12:
    if (v11 != (mlir::Operation **)(v8 + 16 * v9)) {
      return 1;
    }
    uint64_t ParentOp = a2[2];
    if (ParentOp) {
      uint64_t ParentOp = (mlir::Block *)mlir::Block::getParentOp(ParentOp);
    }
    int v17 = *(_DWORD *)(v7 + 608);
    if (v17)
    {
      uint64_t v18 = *(void *)(v7 + 592);
      int v19 = v17 - 1;
      unsigned int v20 = ((ParentOp >> 4) ^ (ParentOp >> 9)) & v19;
      unint64_t v21 = *(mlir::Block **)(v18 + 8 * v20);
      if (v21 == ParentOp) {
        return 1;
      }
      int v22 = 1;
      uint64_t v15 = 1;
      while (v21 != (mlir::Block *)-4096)
      {
        unsigned int v23 = v20 + v22++;
        unsigned int v20 = v23 & v19;
        unint64_t v21 = *(mlir::Block **)(v18 + 8 * v20);
        if (v21 == ParentOp) {
          return v15;
        }
      }
    }
    uint64_t v24 = (int32x2_t *)*((void *)a3 + 7);
    __int32 v25 = v24[26].i32[0];
    __int32 v26 = v24[45].i32[0];
    __int32 v27 = v24[47].i32[0];
    __int32 v44 = v24[53].i32[0];
    __int32 v45 = v24[34].i32[0];
    __int32 v42 = v24[80].i32[0];
    __int32 v43 = v24[78].i32[0];
    uint64_t v55 = v57;
    uint64_t v56 = 0x200000000;
    int v28 = a2[2];
    ZinIrHalH13g::~ZinIrHalH13g((ZinIrHalH13g *)a2);
    *((void *)a3 + 3) = v28;
    *((void *)a3 + 4) = v29;
    if (mlir::OpBuilder::tryFold((void *)a3 + 1, (uint64_t)a2, (uint64_t)&v55))
    {
      mlir::ValueRange::ValueRange((unint64_t *)&v58, (uint64_t)v55, v56);
      mlir::detail::ConversionPatternRewriterImpl::notifyOpReplaced(*((void *)a3 + 7), (unsigned int *)a2, (uint64_t)v58, (uint64_t)v59);
      __int32 v31 = v24[26].i32[0];
      if (v25 == v31)
      {
LABEL_26:
        int v33 = 0;
        goto LABEL_29;
      }
      unsigned __int32 v32 = v25;
      {
        if (v31 == ++v32) {
          goto LABEL_26;
        }
      }
      __int32 v47 = v25;
      __int32 v48 = v45;
      __int32 v49 = v26;
      __int32 v50 = v27;
      __int32 v51 = v44;
      __int32 v52 = v43;
      __int32 v53 = v42;
      mlir::detail::ConversionPatternRewriterImpl::resetState(v24, &v47);
    }
    int v33 = 1;
LABEL_29:
    if (v55 != v57) {
      free(v55);
    }
    if (v33)
    {
      unsigned int v54 = (mlir::Operation *)a2;
      unint64_t v34 = (_DWORD *)*((void *)a3 + 7);
      uint64_t v58 = (_anonymous_namespace_::OperationLegalizer *)this;
      char v59 = &v54;
      uint64_t v60 = a3;
      __int32 v35 = v34[68];
      __int32 v36 = v34[90];
      __int32 v37 = v34[94];
      __int32 v38 = v34[106];
      __int32 v39 = v34[156];
      __int32 v40 = v34[160];
      __int32 v47 = v34[52];
      __int32 v48 = v35;
      __int32 v49 = v36;
      __int32 v50 = v37;
      __int32 v51 = v38;
      __int32 v52 = v39;
      __int32 v53 = v40;
      v46[0] = v34;
      v46[1] = &v47;
      unint64_t v46[2] = this;
      uint64_t v55 = this;
      uint64_t v56 = (uint64_t)&v54;
      v57[0] = a3;
      v57[1] = &v47;
      v57[2] = v34;
    }
    return 1;
  }
  if (!(_BYTE)isLegal || (*((_DWORD *)a2 + 11) & 0x7FFFFF) == 0) {
    return 1;
  }
  uint64_t v55 = (void *)*((void *)a3 + 7);
  uint64_t v15 = 1;
  mlir::detail::walk<mlir::ForwardIterator>((mlir::ForwardIterator *)a2, (mlir::Operation *)llvm::function_ref<void ()(mlir::Operation *)>::callback_fn<mlir::detail::ConversionPatternRewriterImpl::markNestedOpsIgnored(mlir::Operation *)::$_0>, (uint64_t)&v55, 1);
  return v15;
}

void mlir::detail::ConversionPatternRewriterImpl::resetState(int32x2_t *this, _DWORD *a2)
{
  uint64_t v2 = a2;
  unsigned int v4 = a2[6];
  __int32 v5 = this[80].i32[0];
  if (v4 != v5)
  {
    unint64_t v6 = this + 79;
    do
    while (v5 != v4);
    unint64_t v7 = v2[6];
    uint64_t v8 = this[80].u32[0];
    if (v8 != v7)
    {
      if (v8 > v7)
      {
        uint64_t v9 = 136 * v8;
        uint64_t v10 = v9 + *(void *)v6 - 112;
        uint64_t v11 = 136 * v7 - v9;
        do
        {
          uint64_t v12 = *(void **)(v10 + 80);
          if ((void *)(v10 + 96) != v12) {
            free(v12);
          }
          if (v10 + 16 != *(void *)v10) {
            free(*(void **)v10);
          }
          v10 -= 136;
          v11 += 136;
        }
        while (v11);
        goto LABEL_20;
      }
      if (this[80].i32[1] >= v7)
      {
        int v13 = (char *)*v6;
        if (v8 == v7)
        {
LABEL_20:
          this[80].i32[0] = v7;
          goto LABEL_21;
        }
      }
      else
      {
        uint64_t v95 = 0;
        int v13 = (char *)llvm::SmallVectorBase<unsigned int>::mallocForGrow((uint64_t)&this[79], &this[81], v7, 136, (unint64_t *)&v95);
        __int32 v14 = (int)v95;
        uint64_t v15 = (int32x2_t *)this[79];
        if (v15 != &this[81]) {
          free(v15);
        }
        this[79] = (int32x2_t)v13;
        this[80].i32[1] = v14;
        uint64_t v8 = this[80].u32[0];
        if (v8 == v7) {
          goto LABEL_20;
        }
      }
      uint64_t v16 = &v13[136 * v8];
      do
      {
        *((_OWORD *)v16 + 6) = 0uLL;
        *((_OWORD *)v16 + 7) = 0uLL;
        *((void *)v16 + 16) = 0;
        *((_OWORD *)v16 + 4) = 0uLL;
        *((_OWORD *)v16 + 5) = 0uLL;
        *((_OWORD *)v16 + 2) = 0uLL;
        *((_OWORD *)v16 + 3) = 0uLL;
        *(_OWORD *)uint64_t v16 = 0uLL;
        *((_OWORD *)v16 + 1) = 0uLL;
        *((void *)v16 + 3) = v16 + 40;
        *((_DWORD *)v16 + 9) = 8;
        *((void *)v16 + 13) = v16 + 120;
        *((_DWORD *)v16 + 29) = 2;
        v16 += 136;
      }
      while (v16 != &v13[136 * v7]);
      goto LABEL_20;
    }
  }
LABEL_21:
  uint64_t v17 = v2[3];
  uint64_t v18 = this[47].u32[0];
  if (v17 != v18)
  {
    uint64_t v19 = 8 * v17;
    unsigned int v20 = (unint64_t *)(*(void *)&this[46] + v19);
    uint64_t v21 = 8 * v18 - v19;
    do
    {
      unint64_t v94 = *v20;
      uint64_t v95 = 0;
      if (llvm::DenseMapBase<llvm::DenseMap<mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>,mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>::LookupBucketFor<mlir::Value>((uint64_t *)this, &v94, &v95))
      {
        *uint64_t v95 = -8192;
        this[1] = vadd_s32(this[1], (int32x2_t)0x1FFFFFFFFLL);
      }
      ++v20;
      v21 -= 8;
    }
    while (v21);
    uint64_t v22 = v2[3];
    unsigned int v23 = this[47].u32[0];
    if (v23 != v22)
    {
      if (v23 <= v22)
      {
        if (this[47].i32[1] < v22)
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&this[46], &this[48], v2[3], 8);
          unsigned int v23 = this[47].u32[0];
        }
        if (v23 != v22) {
          bzero((void *)(*(void *)&this[46] + 8 * v23), 8 * (v22 - v23));
        }
      }
      this[47].i32[0] = v22;
    }
  }
  mlir::detail::ConversionPatternRewriterImpl::undoBlockActions(this, v2[4]);
  uint64_t v24 = v2[2];
  uint64_t v25 = this[45].u32[0];
  int v93 = v2;
  if (v24 != v25)
  {
    int32x2_t v26 = this[44];
    uint64_t v91 = *(void *)&v26 + 16 * v25;
    uint64_t v27 = *(void *)&v26 + 16 * v24;
    do
    {
      uint64_t v28 = *(unsigned int *)(*(void *)v27 + 36);
      if (v28) {
        uint64_t v29 = *(void *)v27 - 16;
      }
      else {
        uint64_t v29 = 0;
      }
      if (v28)
      {
        for (uint64_t i = 0; i != v28; ++i)
        {
          uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v29, i);
          __int32 v32 = this[2].i32[0];
          if (v32)
          {
            unint64_t v33 = NextResultAtOffset;
            int32x2_t v34 = *this;
            {
              unint64_t v41 = llvm::hashing::detail::fixed_seed_override;
              if (!llvm::hashing::detail::fixed_seed_override) {
                unint64_t v41 = 0xFF51AFD7ED558CCDLL;
              }
              llvm::hashing::detail::get_execution_seed(void)::seed = v41;
            }
            unint64_t v35 = 0x9DDFEA08EB382D69
                * ((llvm::hashing::detail::get_execution_seed(void)::seed + 8 * v33) ^ HIDWORD(v33));
            unint64_t v36 = 0x9DDFEA08EB382D69 * (HIDWORD(v33) ^ (v35 >> 47) ^ v35);
            LODWORD(v36) = (-348639895 * ((v36 >> 47) ^ v36)) & (v32 - 1);
            __int32 v37 = (uint64_t *)(*(void *)&v34 + 16 * v36);
            uint64_t v38 = *v37;
            if (v33 != *v37)
            {
              int v39 = 1;
              do
              {
                if (v38 == -4096) {
                  goto LABEL_42;
                }
                int v40 = v36 + v39++;
                unint64_t v36 = v40 & (v32 - 1);
                uint64_t v38 = *(void *)(*(void *)&v34 + 16 * v36);
              }
              while (v33 != v38);
              __int32 v37 = (uint64_t *)(*(void *)&v34 + 16 * v36);
            }
            uint64_t *v37 = -8192;
            this[1] = vadd_s32(this[1], (int32x2_t)0x1FFFFFFFFLL);
          }
LABEL_42:
          ;
        }
      }
      v27 += 16;
    }
    while (v27 != v91);
    __int32 v42 = v2[2];
    __int32 v43 = this[45].i32[0];
    if (v43 == v42) {
      goto LABEL_65;
    }
    uint64_t v44 = this[43].u32[0];
    unsigned int v45 = v44 - 1;
    __int32 v46 = this[42].i32[0] + v42;
    __int32 v47 = v43 + this[42].i32[1];
    unsigned __int32 v48 = this[45].u32[0];
    while (1)
    {
      int32x2_t v50 = this[41];
      if (v44)
      {
        uint64_t v51 = *(void *)(*(void *)&this[44] + 16 * v48 - 16);
        LODWORD(v52) = ((v51 >> 4) ^ (v51 >> 9)) & v45;
        __int32 v49 = (uint64_t *)(*(void *)&v50 + 16 * v52);
        uint64_t v53 = *v49;
        if (*v49 == v51) {
          goto LABEL_57;
        }
        int v54 = 1;
        while (v53 != -4096)
        {
          int v55 = v52 + v54++;
          uint64_t v52 = v55 & v45;
          uint64_t v53 = *(void *)(*(void *)&v50 + 16 * v52);
          if (v53 == v51)
          {
            __int32 v49 = (uint64_t *)(*(void *)&v50 + 16 * v52);
            goto LABEL_57;
          }
        }
      }
      __int32 v49 = (uint64_t *)(*(void *)&v50 + 16 * v44);
LABEL_57:
      *__int32 v49 = -8192;
      if (--v48 == v42)
      {
        this[45].i32[0] = v42;
        this[42].i32[0] = v46 - v43;
        this[42].i32[1] = v47 - v42;
        break;
      }
    }
  }
LABEL_65:
  unsigned __int32 v56 = this[34].u32[0];
  if (v56 != v2[1])
  {
    BOOL v69 = (void *)&unk_267770000;
    do
    {
      uint64_t v70 = *(void *)&this[33] + 24 * v56;
      uint64_t v71 = *(void *)(v70 - 24);
      uint64_t v72 = *(void *)(v70 - 16);
      this[34].i32[0] = v56 - 1;
      if ((v72 & 4) != 0 && (*(unsigned char *)(v71 + 46) & 0x80) != 0)
      {
        uint64_t v73 = *(unsigned int *)(v71 + 68);
        if (v73)
        {
          __int32 v74 = this[2].i32[0];
          if (v74)
          {
            uint64_t v75 = 0;
            uint64_t v76 = *(void *)(v71 + 72);
LABEL_86:
            unint64_t v77 = *(void *)(v76 + 32 * v75 + 24);
            int32x2_t v78 = *this;
            {
              uint64_t v92 = v71;
              BOOL v69 = &unk_267770000;
              int v86 = v85;
              uint64_t v71 = v92;
              if (v86)
              {
                unint64_t v87 = llvm::hashing::detail::fixed_seed_override;
                if (!llvm::hashing::detail::fixed_seed_override) {
                  unint64_t v87 = 0xFF51AFD7ED558CCDLL;
                }
                llvm::hashing::detail::get_execution_seed(void)::seed = v87;
                BOOL v69 = (void *)&unk_267770000;
                uint64_t v71 = v92;
              }
            }
            unint64_t v79 = 0x9DDFEA08EB382D69 * ((v69[385] + 8 * v77) ^ HIDWORD(v77));
            unint64_t v80 = 0x9DDFEA08EB382D69 * (HIDWORD(v77) ^ (v79 >> 47) ^ v79);
            LODWORD(v80) = (-348639895 * ((v80 >> 47) ^ v80)) & (v74 - 1);
            uint64_t v81 = (uint64_t *)(*(void *)&v78 + 16 * v80);
            uint64_t v82 = *v81;
            if (v77 == *v81)
            {
LABEL_88:
              *uint64_t v81 = -8192;
              this[1] = vadd_s32(this[1], (int32x2_t)0x1FFFFFFFFLL);
              goto LABEL_89;
            }
            int v83 = 1;
            while (v82 != -4096)
            {
              int v84 = v80 + v83++;
              unint64_t v80 = v84 & (v74 - 1);
              uint64_t v82 = *(void *)(*(void *)&v78 + 16 * v80);
              if (v77 == v82)
              {
                uint64_t v81 = (uint64_t *)(*(void *)&v78 + 16 * v80);
                goto LABEL_88;
              }
            }
LABEL_89:
            while (++v75 != v73)
            {
              __int32 v74 = this[2].i32[0];
              if (v74) {
                goto LABEL_86;
              }
            }
          }
        }
      }
      detachNestedAndErase((mlir::Operation *)v71);
      BOOL v69 = &unk_267770000;
      unsigned __int32 v56 = this[34].u32[0];
      uint64_t v2 = v93;
    }
    while (v56 != v93[1]);
  }
  for (unsigned int j = this[26].u32[0]; j != *v2; this[26].i32[0] = j)
  {
    detachNestedAndErase(*(mlir::Operation **)(*(void *)&this[25] + 8 * j - 8));
    unsigned int j = this[26].i32[0] - 1;
  }
  __int32 v58 = v2[5];
  unsigned __int32 v59 = this[78].u32[0];
  if (v59 != v58)
  {
    __int32 v60 = this[76].i32[0];
    if (v60)
    {
      unsigned __int32 v61 = v60 - 1;
      do
      {
        int32x2_t v62 = this[74];
        uint64_t v63 = *(void *)(*(void *)&this[77] + 8 * v59 - 8);
        LODWORD(v64) = ((v63 >> 4) ^ (v63 >> 9)) & v61;
        uint64_t v65 = (uint64_t *)(*(void *)&v62 + 8 * v64);
        uint64_t v66 = *v65;
        if (v63 == *v65)
        {
LABEL_72:
          *uint64_t v65 = -8192;
          this[75] = vadd_s32(this[75], (int32x2_t)0x1FFFFFFFFLL);
        }
        else
        {
          int v67 = 1;
          while (v66 != -4096)
          {
            int v68 = v64 + v67++;
            uint64_t v64 = v68 & v61;
            uint64_t v66 = *(void *)(*(void *)&v62 + 8 * v64);
            if (v63 == v66)
            {
              uint64_t v65 = (uint64_t *)(*(void *)&v62 + 8 * v64);
              goto LABEL_72;
            }
          }
        }
        --v59;
      }
      while (v59 != v58);
    }
    this[78].i32[0] = v58;
  }
  unsigned __int32 v88 = this[150].u32[0];
  if (v88)
  {
    uint64_t v89 = *(void *)&this[149] - 4;
    unsigned int v90 = v2[2];
    do
    {
      if (*(_DWORD *)(v89 + 4 * v88) < v90) {
        break;
      }
      this[150].i32[0] = --v88;
    }
    while (v88);
  }
}

void llvm::SmallVectorTemplateBase<anonymous namespace'::OperationTransactionState,false>::moveElementsForGrow(uint64_t *a1, uint64_t a2)
{
  unsigned int v2 = *((_DWORD *)a1 + 2);
  if (v2)
  {
    uint64_t v5 = 0;
    uint64_t v6 = *a1;
    uint64_t v7 = *a1 + 136 * v2;
    do
    {
      uint64_t v8 = v6 + v5;
      uint64_t v9 = a2 + v5;
      long long v10 = *(_OWORD *)(v6 + v5);
      *(void *)(v9 + 16) = *(void *)(v6 + v5 + 16);
      *(_OWORD *)uint64_t v9 = v10;
      *(void *)(a2 + v5 + 24) = a2 + v5 + 40;
      *(void *)(v9 + 32) = 0x800000000;
      if (*(_DWORD *)(v6 + v5 + 32)) {
        llvm::SmallVectorImpl<mlir::Value>::operator=(a2 + v5 + 24, v8 + 24);
      }
      *(void *)(v9 + 104) = v9 + 120;
      uint64_t v11 = v9 + 104;
      *(void *)(v11 + 8) = 0x200000000;
      if (*(_DWORD *)(v8 + 112)) {
        llvm::SmallVectorImpl<llvm::SMLoc>::operator=(v11, v6 + v5 + 104);
      }
      v5 += 136;
    }
    while (v8 + 136 != v7);
    uint64_t v12 = *((unsigned int *)a1 + 2);
    if (v12)
    {
      uint64_t v13 = *a1;
      uint64_t v14 = 136 * v12;
      do
      {
        uint64_t v15 = v13 + v14;
        uint64_t v16 = *(void **)(v13 + v14 - 32);
        if ((void *)(v13 + v14 - 16) != v16) {
          free(v16);
        }
        uint64_t v17 = *(void **)(v15 - 112);
        if ((void *)(v15 - 96) != v17) {
          free(v17);
        }
        v14 -= 136;
      }
      while (v14);
    }
  }
}

BOOL llvm::function_ref<BOOL ()(mlir::Pattern const&)>::callback_fn<anonymous namespace'::OperationLegalizer::legalizeWithPattern(mlir::Operation *,mlir::ConversionPatternRewriter &)::$_0>(uint64_t *a1, unsigned char *a2)
{
  if ((a2[16] & 4) != 0) {
    return 1;
  }
  uint64_t v2 = *a1;
  uint64_t v3 = *(void *)(v2 + 8);
  if (v3 != *(void *)v2) {
    goto LABEL_3;
  }
  uint64_t v6 = *(unsigned int *)(v2 + 20);
  if (v6)
  {
    uint64_t v7 = 0;
    uint64_t v8 = 8 * v6;
    uint64_t v9 = *(void **)(v2 + 8);
    while ((unsigned char *)*v9 != a2)
    {
      if (*v9 == -2) {
        uint64_t v7 = v9;
      }
      ++v9;
      v8 -= 8;
      if (!v8)
      {
        if (!v7) {
          goto LABEL_14;
        }
        *uint64_t v7 = a2;
        --*(_DWORD *)(v2 + 24);
        return 1;
      }
    }
    return 0;
  }
LABEL_14:
  if (v6 >= *(_DWORD *)(v2 + 16))
  {
LABEL_3:
    llvm::SmallPtrSetImplBase::insert_imp_big((llvm::SmallPtrSetImplBase *)v2, a2);
    return v4 != 0;
  }
  *(_DWORD *)(v2 + 20) = v6 + 1;
  *(void *)(v3 + 8 * v6) = a2;
  return 1;
}

const void **llvm::function_ref<void ()(mlir::Pattern const&)>::callback_fn<anonymous namespace'::OperationLegalizer::legalizeWithPattern(mlir::Operation *,mlir::ConversionPatternRewriter &)::$_1>(uint64_t a1, const void *a2)
{
  uint64_t v3 = *(_OWORD **)(a1 + 8);
  char v4 = *(llvm::SmallPtrSetImplBase **)(a1 + 16);
  uint64_t v5 = *(int32x2_t **)a1;
  v15[0] = *v3;
  *(_OWORD *)((char *)v15 + 12) = *(_OWORD *)((char *)v3 + 12);
  mlir::detail::ConversionPatternRewriterImpl::resetState(v5, v15);
  uint64_t v6 = *((void *)v4 + 1);
  if (v6 == *(void *)v4)
  {
    uint64_t v10 = *((unsigned int *)v4 + 5);
    uint64_t result = (const void **)(v6 + 8 * v10);
    if (v10)
    {
      uint64_t v11 = 0;
      uint64_t v12 = 8 * v10;
      while (*(const void **)(v6 + v11) != a2)
      {
        v11 += 8;
        if (v12 == v11) {
          goto LABEL_12;
        }
      }
      uint64_t result = (const void **)(v6 + v11);
    }
LABEL_12:
    uint64_t v8 = *((void *)v4 + 1);
  }
  else
  {
    uint64_t result = llvm::SmallPtrSetImplBase::FindBucketFor(v4, a2);
    uint64_t v6 = *(void *)v4;
    uint64_t v8 = *((void *)v4 + 1);
    if (*result != a2)
    {
      uint64_t v9 = 16;
      if (v8 == v6) {
        uint64_t v9 = 20;
      }
      uint64_t result = (const void **)(v8 + 8 * *(unsigned int *)((char *)v4 + v9));
    }
  }
  BOOL v13 = v8 == v6;
  uint64_t v14 = 16;
  if (v13) {
    uint64_t v14 = 20;
  }
  if (result != (const void **)(v8 + 8 * *(unsigned int *)((char *)v4 + v14)))
  {
    *uint64_t result = (const void *)-2;
    ++*((_DWORD *)v4 + 6);
  }
  return result;
}

uint64_t llvm::function_ref<mlir::LogicalResult ()(mlir::Pattern const&)>::callback_fn<anonymous namespace'::OperationLegalizer::legalizeWithPattern(mlir::Operation *,mlir::ConversionPatternRewriter &)::$_2>(uint64_t **a1, void *a2)
{
  uint64_t v2 = a2;
  uint64_t v3 = a1;
  char v4 = (_anonymous_namespace_::OperationLegalizer *)*a1;
  uint64_t v5 = *a1[1];
  uint64_t v7 = (mlir::ConversionPatternRewriter *)a1[2];
  uint64_t v6 = (unsigned int *)a1[3];
  uint64_t v8 = *((void *)v7 + 7);
  int v69 = *(_DWORD *)(v8 + 208);
  int v9 = *(_DWORD *)(v8 + 424);
  int v10 = *(_DWORD *)(v8 + 640);
  *(void *)uint64_t v71 = v72;
  *(void *)&v71[8] = v72;
  *(void *)&v71[16] = 16;
  *(_DWORD *)&v71[24] = 0;
  uint64_t v70 = v6;
  uint64_t v11 = (int)v6[4];
  if (v11 == v9)
  {
    uint64_t v12 = (int *)v6;
    uint64_t v13 = (int)v6[6];
    if (v10 == v13) {
      goto LABEL_56;
    }
LABEL_53:
    int v46 = v10 - v13;
    uint64_t v47 = 136 * v13;
    {
      v47 += 136;
      if (!--v46) {
        goto LABEL_56;
      }
    }
    uint64_t v50 = 0;
    BOOL v49 = 1;
    uint64_t v51 = *((void *)v4 + 1);
    if (v51 == *(void *)v4) {
      goto LABEL_74;
    }
    goto LABEL_67;
  }
  int v66 = v10;
  do
  {
    uint64_t v15 = *(void *)(v8 + 416);
    if ((*(_DWORD *)(v15 + 40 * v11) | 4) == 5) {
      goto LABEL_6;
    }
    uint64_t v16 = v15 + 40 * v11;
    uint64_t v18 = *(mlir::Block **)(v16 + 8);
    uint64_t v17 = (mlir::Block **)(v16 + 8);
    uint64_t ParentOp = mlir::Block::getParentOp(v18);
    BOOL v20 = !ParentOp || ParentOp == v5;
    if (v20) {
      goto LABEL_6;
    }
    uint64_t v21 = (void *)ParentOp;
    if (((*((void *)*v17 + 7) - *((void *)*v17 + 6)) & 0x7FFFFFFF8) == 0) {
      goto LABEL_6;
    }
    unint64_t Parent = mlir::Block::getParent(*v17);
    int v23 = *(_DWORD *)(v8 + 176);
    if (v23)
    {
      uint64_t v24 = *(void *)(v8 + 160);
      unsigned int v25 = v23 - 1;
      uint64_t v26 = ((Parent >> 4) ^ (Parent >> 9)) & (v23 - 1);
      uint64_t v27 = *(void *)(v24 + 16 * v26);
      if (v27 == Parent)
      {
LABEL_15:
        uint64_t v28 = *(void *)(v24 + 16 * v26 + 8);
        if (v28)
        {
          mlir::detail::ConversionPatternRewriterImpl::convertBlockSignature(v8, *v17, v28, 0);
          if (!v14) {
            goto LABEL_71;
          }
          goto LABEL_6;
        }
      }
      else
      {
        int v44 = 1;
        while (v27 != -4096)
        {
          int v45 = v26 + v44++;
          uint64_t v26 = v45 & v25;
          uint64_t v27 = *(void *)(v24 + 16 * v26);
          if (v27 == Parent) {
            goto LABEL_15;
          }
        }
      }
    }
    if (*(_DWORD *)&v71[20] == *(_DWORD *)&v71[24])
    {
      uint64_t v29 = *(unsigned int *)(v8 + 208);
      uint64_t v30 = *v70;
      if (v30 != v29)
      {
        uint64_t v36 = *(void *)(v8 + 200);
        __int32 v37 = (const void **)(v36 + 8 * v29);
        for (uint64_t i = (const void **)(v36 + 8 * v30); i != v37; ++i)
        {
          int v39 = *i;
          if (*(void *)&v71[8] != *(void *)v71) {
            goto LABEL_31;
          }
          uint64_t v40 = *(unsigned int *)&v71[20];
          if (*(_DWORD *)&v71[20])
          {
            unint64_t v41 = 0;
            uint64_t v42 = 8 * *(unsigned int *)&v71[20];
            __int32 v43 = *(void **)&v71[8];
            while ((const void *)*v43 != v39)
            {
              if (*v43 == -2) {
                unint64_t v41 = v43;
              }
              ++v43;
              v42 -= 8;
              if (!v42)
              {
                if (!v41) {
                  goto LABEL_42;
                }
                *unint64_t v41 = v39;
                --*(_DWORD *)&v71[24];
                goto LABEL_32;
              }
            }
            continue;
          }
LABEL_42:
          if (*(_DWORD *)&v71[20] < *(_DWORD *)&v71[16])
          {
            ++*(_DWORD *)&v71[20];
            *(void *)(*(void *)&v71[8] + 8 * v40) = v39;
          }
          else
          {
LABEL_31:
            llvm::SmallPtrSetImplBase::insert_imp_big((llvm::SmallPtrSetImplBase *)v71, v39);
          }
LABEL_32:
          ;
        }
      }
    }
    if (*(void *)&v71[8] != *(void *)v71) {
      goto LABEL_19;
    }
    uint64_t v32 = *(unsigned int *)&v71[20];
    if (*(_DWORD *)&v71[20])
    {
      unint64_t v33 = 0;
      uint64_t v34 = 8 * *(unsigned int *)&v71[20];
      unint64_t v35 = *(void **)&v71[8];
      while ((void *)*v35 != v21)
      {
        if (*v35 == -2) {
          unint64_t v33 = v35;
        }
        ++v35;
        v34 -= 8;
        if (!v34)
        {
          if (!v33) {
            goto LABEL_44;
          }
          *unint64_t v33 = v21;
          --*(_DWORD *)&v71[24];
          goto LABEL_20;
        }
      }
      goto LABEL_6;
    }
LABEL_44:
    if (*(_DWORD *)&v71[20] < *(_DWORD *)&v71[16])
    {
      ++*(_DWORD *)&v71[20];
      *(void *)(*(void *)&v71[8] + 8 * v32) = v21;
    }
    else
    {
LABEL_19:
      llvm::SmallPtrSetImplBase::insert_imp_big((llvm::SmallPtrSetImplBase *)v71, v21);
      if (!v31) {
        goto LABEL_6;
      }
    }
LABEL_20:
    {
LABEL_71:
      if (*(void *)&v71[8] != *(void *)v71) {
        free(*(void **)&v71[8]);
      }
      uint64_t v50 = 0;
      BOOL v49 = 1;
      uint64_t v2 = a2;
      uint64_t v3 = a1;
      uint64_t v51 = *((void *)v4 + 1);
      if (v51 == *(void *)v4) {
        goto LABEL_74;
      }
      goto LABEL_67;
    }
LABEL_6:
    ++v11;
  }
  while (v9 != v11);
  if (*(void *)&v71[8] != *(void *)v71) {
    free(*(void **)&v71[8]);
  }
  uint64_t v2 = a2;
  uint64_t v3 = a1;
  uint64_t v12 = (int *)v70;
  int v10 = v66;
  uint64_t v13 = (int)v70[6];
  if (v66 != v13) {
    goto LABEL_53;
  }
LABEL_56:
  uint64_t v48 = *v12;
  if (v69 != v48)
  {
    uint64_t v52 = v2;
    int v53 = v69 - v48;
    uint64_t v54 = 8 * v48;
    while (1)
    {
      BOOL v49 = v55 == 0;
      if (!v55) {
        break;
      }
      v54 += 8;
      if (!--v53)
      {
        BOOL v49 = 0;
        uint64_t v50 = 1;
        uint64_t v2 = v52;
        uint64_t v51 = *((void *)v4 + 1);
        if (v51 != *(void *)v4) {
          goto LABEL_67;
        }
        goto LABEL_74;
      }
    }
    uint64_t v50 = 0;
    uint64_t v2 = v52;
    uint64_t v51 = *((void *)v4 + 1);
    if (v51 == *(void *)v4) {
      goto LABEL_74;
    }
    goto LABEL_67;
  }
  BOOL v49 = 0;
  uint64_t v50 = 1;
  uint64_t v51 = *((void *)v4 + 1);
  if (v51 != *(void *)v4)
  {
LABEL_67:
    BucketFor = llvm::SmallPtrSetImplBase::FindBucketFor(v4, v2);
    uint64_t v51 = *(void *)v4;
    uint64_t v57 = *((void *)v4 + 1);
    if (*BucketFor != v2)
    {
      uint64_t v58 = 16;
      if (v57 == v51) {
        uint64_t v58 = 20;
      }
      BucketFor = (const void **)(v57 + 8 * *(unsigned int *)((char *)v4 + v58));
    }
    goto LABEL_81;
  }
LABEL_74:
  uint64_t v59 = *((unsigned int *)v4 + 5);
  BucketFor = (const void **)(v51 + 8 * v59);
  if (v59)
  {
    uint64_t v60 = 0;
    uint64_t v61 = 8 * v59;
    while (*(const void **)(v51 + v60) != v2)
    {
      v60 += 8;
      if (v61 == v60) {
        goto LABEL_80;
      }
    }
    BucketFor = (const void **)(v51 + v60);
  }
LABEL_80:
  uint64_t v57 = v51;
LABEL_81:
  BOOL v20 = v57 == v51;
  uint64_t v62 = 16;
  if (v20) {
    uint64_t v62 = 20;
  }
  if (BucketFor != (const void **)(v57 + 8 * *(unsigned int *)((char *)v4 + v62)))
  {
    *BucketFor = (const void *)-2;
    ++*((_DWORD *)v4 + 6);
  }
  if (v49)
  {
    uint64_t v64 = v3[3];
    uint64_t v63 = (int32x2_t *)v3[4];
    *(_OWORD *)uint64_t v71 = *(_OWORD *)v64;
    *(_OWORD *)&v71[12] = *(_OWORD *)((char *)v64 + 12);
    mlir::detail::ConversionPatternRewriterImpl::resetState(v63, v71);
  }
  return v50;
}

void anonymous namespace'::ConversionValueMapping::getInverse(_anonymous_namespace_::ConversionValueMapping *this, uint64_t a2)
{
  *(void *)this = 0;
  *((void *)this + 1) = 0;
  *((_DWORD *)this + 4) = 0;
  if (*(_DWORD *)(a2 + 8))
  {
    uint64_t v3 = *(unsigned int *)(a2 + 16);
    if (v3)
    {
      uint64_t v4 = 16 * v3;
      for (uint64_t i = *(void **)a2; (*i | 0x1000) == 0xFFFFFFFFFFFFF000; i += 2)
      {
        v4 -= 16;
        if (!v4) {
          return;
        }
      }
    }
    else
    {
      uint64_t i = *(void **)a2;
    }
    uint64_t v6 = *(void *)a2 + 16 * v3;
    if (i != (void *)v6)
    {
LABEL_9:
      uint64_t v13 = 0;
      if (llvm::DenseMapBase<llvm::DenseMap<mlir::Value,llvm::SmallVector<llvm::SMLoc,6u>,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,llvm::SmallVector<llvm::SMLoc,6u>>>,mlir::Value,llvm::SmallVector<llvm::SMLoc,6u>,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,llvm::SmallVector<llvm::SMLoc,6u>>>::LookupBucketFor<mlir::Value>((uint64_t *)this, i + 1, &v13))
      {
        uint64_t v8 = v13 + 2;
        unint64_t v7 = *((unsigned int *)v13 + 4);
        int v9 = v13 + 1;
        uint64_t v10 = *i;
        if (v7 >= *((unsigned int *)v13 + 5))
        {
          uint64_t v11 = v13;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)(v13 + 1), v13 + 3, v7 + 1, 8);
          unint64_t v7 = *((unsigned int *)v11 + 4);
        }
      }
      else
      {
        uint64_t v12 = llvm::DenseMapBase<llvm::DenseMap<mlir::Value,llvm::SmallVector<mlir::Value,6u>,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,llvm::SmallVector<mlir::Value,6u>>>,mlir::Value,llvm::SmallVector<mlir::Value,6u>,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,llvm::SmallVector<mlir::Value,6u>>>::InsertIntoBucketImpl<mlir::Value>((uint64_t)this, (uint64_t)(i + 1), i + 1, v13);
        unint64_t v7 = 0;
        *uint64_t v12 = i[1];
        v12[1] = v12 + 3;
        int v9 = v12 + 1;
        void v12[2] = 0x600000000;
        uint64_t v8 = v12 + 2;
        uint64_t v10 = *i;
      }
      *(void *)(*v9 + 8 * v7) = v10;
      ++*v8;
      while (1)
      {
        i += 2;
        if (i == (void *)v6) {
          break;
        }
        if ((*i | 0x1000) != 0xFFFFFFFFFFFFF000)
        {
          if (i != (void *)v6) {
            goto LABEL_9;
          }
          return;
        }
      }
    }
  }
}

uint64_t legalizeUnresolvedMaterialization(uint64_t *a1, uint64_t *a2, uint64_t a3, int64x2_t *a4, uint64_t a5)
{
  uint64_t v165 = *MEMORY[0x263EF8340];
     + 2;
  v163[0] = (llvm *)a4;
       + 2;
  uint64_t v10 = *a1;
  *(void *)&long long v141 = *a1;
  llvm::DenseMapBase<llvm::DenseMap<mlir::Block *,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::Block *,void>,llvm::detail::DenseSetPair<mlir::Block *>>,mlir::Block *,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::Block *,void>,llvm::detail::DenseSetPair<mlir::Block *>>::try_emplace<llvm::detail::DenseSetEmpty&>(a4 + 37, (uint64_t *)&v141, (uint64_t)&v151);
  if (!(_BYTE)v152)
  {
    uint64_t v38 = 1;
       + 2 >= 8)
      goto LABEL_146;
    return v38;
  }
  uint64_t v12 = v141;
  uint64_t v13 = a4[39].u32[0];
  if (v13 >= a4[39].i32[1])
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&a4[38].i64[1], &a4[39].u64[1], v13 + 1, 8);
    LODWORD(v13) = a4[39].i32[0];
  }
  *(void *)(a4[38].i64[1] + 8 * v13) = v12;
  ++a4[39].i32[0];
  uint64_t v127 = v10 - 16;
  if ((*(unsigned char *)(v10 + 46) & 0x80) != 0)
  {
    uint64_t v14 = *(void *)(v10 + 72);
    unint64_t v15 = *(unsigned int *)(v10 + 68);
    uint64_t v137 = v14;
    unint64_t v138 = v15;
    uint64_t v16 = v10;
    uint64_t v17 = *(void *)(v10 - 8);
    if (v15)
    {
      uint64_t v18 = 0;
      while (1)
      {
        *(void *)&long long v151 = *(void *)(v14 + 32 * v18 + 24);
        uint64_t DefiningOp = mlir::Value::getDefiningOp((mlir::Value *)&v151);
        if (DefiningOp)
        {
          BOOL v20 = *(void **)(*(void *)(DefiningOp + 48) + 16);
          uint64_t v21 = v20 == &mlir::detail::TypeIDResolver<mlir::UnrealizedConversionCastOp,void>::id ? DefiningOp : 0;
          if (v20 == &mlir::detail::TypeIDResolver<mlir::UnrealizedConversionCastOp,void>::id) {
            break;
          }
        }
LABEL_7:
        if (++v18 == v15) {
          goto LABEL_23;
        }
      }
      uint64_t v22 = *a2;
      uint64_t v23 = *((unsigned int *)a2 + 4);
      if (v23)
      {
        LODWORD(v24) = (v23 - 1) & ((DefiningOp >> 4) ^ (DefiningOp >> 9));
        unsigned int v25 = (uint64_t *)(v22 + 16 * v24);
        uint64_t v26 = *v25;
        if (*v25 == v21)
        {
LABEL_20:
          if (v25 != (uint64_t *)(v22 + 16 * v23)
            && !legalizeUnresolvedMaterialization(v25[1], a2, a3, a4, a5))
          {
            goto LABEL_144;
          }
          goto LABEL_7;
        }
        int v27 = 1;
        while (v26 != -4096)
        {
          int v28 = v24 + v27++;
          uint64_t v24 = v28 & (v23 - 1);
          uint64_t v26 = *(void *)(v22 + 16 * v24);
          if (v26 == v21)
          {
            unsigned int v25 = (uint64_t *)(v22 + 16 * v24);
            goto LABEL_20;
          }
        }
      }
      unsigned int v25 = (uint64_t *)(v22 + 16 * v23);
      goto LABEL_20;
    }
LABEL_23:
    unint64_t v29 = v17 & 0xFFFFFFFFFFFFFFF8;
    if (v138 == 1)
    {
      uint64_t v30 = (v164 & 2) != 0 ? (uint64_t *)v163 : (uint64_t *)v163[0];
      unint64_t v31 = (*(unint64_t (**)(uint64_t *, unint64_t, uint64_t))(v164 & 0xFFFFFFFFFFFFFFF8))(v30, *(void *)(v137 + 24), v17 & 0xFFFFFFFFFFFFFFF8);
      *(void *)&long long v151 = v31;
      if (v31 && v127 != v31)
      {
        mlir::ResultRange::ResultRange(v136, v127);
        uint64_t v38 = 1;
        replaceMaterialization((uint64_t)a4, v136[0], (uint64_t)v136[1], (uint64_t)&v151, 1, a5);
        goto LABEL_145;
      }
    }
    uint64_t v10 = v16;
    unint64_t v33 = a1[1] & 0xFFFFFFFFFFFFFFF8;
    if (!v33) {
      goto LABEL_54;
    }
  }
  else
  {
    uint64_t v137 = 0;
    unint64_t v138 = 0;
    unint64_t v29 = *(void *)(v10 - 8) & 0xFFFFFFFFFFFFFFF8;
    unint64_t v33 = a1[1] & 0xFFFFFFFFFFFFFFF8;
    if (!v33) {
      goto LABEL_54;
    }
  }
  uint64_t v126 = v10;
  if (v138 == 1)
  {
    *(void *)&long long v151 = *(void *)(v137 + 24);
    uint64_t v34 = (ZinIrHalH13g *)mlir::Value::getDefiningOp((mlir::Value *)&v151);
    if (v34)
    {
      uint64_t v35 = *((void *)v34 + 2);
      ZinIrHalH13g::~ZinIrHalH13g(v34);
      __int32 v37 = (uint64_t *)(v36 + 8);
    }
    else
    {
      uint64_t v35 = *(void *)(v151 + 16);
      __int32 v37 = (uint64_t *)(v35 + 40);
    }
    uint64_t v41 = *v37;
    *(void *)(a3 + 24) = v35;
    *(void *)(a3 + 32) = v41;
    if ((a1[1] & 4) == 0) {
      goto LABEL_42;
    }
  }
  else
  {
    uint64_t v39 = *(void *)(v10 + 16);
    ZinIrHalH13g::~ZinIrHalH13g((ZinIrHalH13g *)v10);
    *(void *)(a3 + 24) = v39;
    *(void *)(a3 + 32) = v40;
    if ((a1[1] & 4) == 0)
    {
LABEL_42:
      uint64_t v42 = *(void *)(v10 + 24);
      uint64_t v43 = a1[2];
      mlir::ValueRange::ValueRange((unint64_t *)&v162, v137, v138);
      long long v129 = v162;
      uint64_t v44 = *(void *)(v33 + 152) + 32 * *(unsigned int *)(v33 + 160);
      uint64_t v45 = -32 * *(unsigned int *)(v33 + 160);
      do
      {
        if (!v45) {
          goto LABEL_47;
        }
        *(void *)&long long v141 = v43;
        long long v151 = v129;
        *(void *)&v139[0] = v42;
        uint64_t v46 = *(void *)(v44 - 8);
        if (!v46) {
LABEL_168:
        }
          std::__throw_bad_function_call[abi:nn180100]();
        v44 -= 32;
        uint64_t v47 = (*(uint64_t (**)(uint64_t, uint64_t, long long *, long long *, _OWORD *))(*(void *)v46 + 48))(v46, a3 + 8, &v141, &v151, v139);
        v45 += 32;
      }
      while (!v48);
      uint64_t v131 = v47;
      if (v47)
      {
LABEL_52:
        mlir::ResultRange::ResultRange(v135, v127);
        uint64_t v38 = 1;
        replaceMaterialization((uint64_t)a4, v135[0], (uint64_t)v135[1], (uint64_t)&v131, 1, a5);
        goto LABEL_145;
      }
    }
  }
LABEL_47:
  uint64_t v49 = a3 + 8;
  uint64_t v50 = *(void *)(v126 + 24);
  mlir::ValueRange::ValueRange((unint64_t *)&v161, v137, v138);
  long long v130 = v161;
  uint64_t v51 = *(void *)(v33 + 312) + 32 * *(unsigned int *)(v33 + 320);
  uint64_t v52 = -32 * *(unsigned int *)(v33 + 320);
  do
  {
    if (!v52) {
      goto LABEL_53;
    }
    *(void *)&long long v141 = v29;
    long long v151 = v130;
    *(void *)&v139[0] = v50;
    uint64_t v53 = *(void *)(v51 - 8);
    if (!v53) {
      goto LABEL_168;
    }
    v51 -= 32;
    uint64_t v54 = (*(uint64_t (**)(uint64_t, uint64_t, long long *, long long *, _OWORD *))(*(void *)v53 + 48))(v53, v49, &v141, &v151, v139);
    v52 += 32;
  }
  while (!v55);
  uint64_t v131 = v54;
  if (v54) {
    goto LABEL_52;
  }
LABEL_53:
  uint64_t v10 = v126;
LABEL_54:
  LOWORD(v140) = 257;
  mlir::Operation::emitError(v10, (uint64_t)v139, (uint64_t)&v141);
  if ((void)v141)
  {
    LODWORD(v151) = 3;
    *((void *)&v151 + 1) = "failed to legalize unresolved materialization from ";
    uint64_t v152 = 51;
    unsigned __int32 v56 = (char *)&v151;
    uint64_t v57 = (char *)__src[1];
    if (v143 >= HIDWORD(v143))
    {
      unint64_t v117 = v143 + 1;
      if (__src[1] <= &v151 && (char *)__src[1] + 24 * v143 > (char *)&v151)
      {
        int64_t v122 = (char *)&v151 - (char *)__src[1];
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&__src[1], v144, v117, 24);
        uint64_t v57 = (char *)__src[1];
        unsigned __int32 v56 = (char *)__src[1] + v122;
      }
      else
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&__src[1], v144, v117, 24);
        unsigned __int32 v56 = (char *)&v151;
        uint64_t v57 = (char *)__src[1];
      }
    }
    uint64_t v58 = &v57[24 * v143];
    long long v59 = *(_OWORD *)v56;
    *((void *)v58 + 2) = *((void *)v56 + 2);
    *(_OWORD *)uint64_t v58 = v59;
    LODWORD(v143) = v143 + 1;
  }
  mlir::OperandRange::getTypes(&v137, &v131);
  uint64_t v60 = v141;
  if ((void)v141)
  {
    *(void *)&long long v151 = ", ";
    llvm::interleave<mlir::ValueTypeIterator<llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator>,mlir::Diagnostic& mlir::Diagnostic::appendRange<mlir::ValueTypeRange<mlir::OperandRange>>(mlir::ValueTypeRange<mlir::OperandRange> const&,char const*)::{lambda(mlir::ValueTypeRange<mlir::OperandRange> const&)#1},mlir::Diagnostic& mlir::Diagnostic::appendRange<mlir::ValueTypeRange<mlir::OperandRange>>(mlir::ValueTypeRange<mlir::OperandRange> const&,char const*)::{lambda(void)#1},void>(v131, v132, v133, v134, (uint64_t)&v141 + 8, (uint64_t)&v141 + 8, (const char **)&v151);
    uint64_t v60 = v141;
    if ((void)v141)
    {
      LODWORD(v151) = 3;
      *((void *)&v151 + 1) = " to ";
      uint64_t v152 = 4;
      uint64_t v61 = (char *)&v151;
      uint64_t v62 = (char *)__src[1];
      if (v143 >= HIDWORD(v143))
      {
        unint64_t v118 = v143 + 1;
        if (__src[1] <= &v151 && (char *)__src[1] + 24 * v143 > (char *)&v151)
        {
          int64_t v123 = (char *)&v151 - (char *)__src[1];
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&__src[1], v144, v118, 24);
          uint64_t v62 = (char *)__src[1];
          uint64_t v61 = (char *)__src[1] + v123;
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&__src[1], v144, v118, 24);
          uint64_t v61 = (char *)&v151;
          uint64_t v62 = (char *)__src[1];
        }
      }
      uint64_t v63 = &v62[24 * v143];
      long long v64 = *(_OWORD *)v61;
      *((void *)v63 + 2) = *((void *)v61 + 2);
      *(_OWORD *)uint64_t v63 = v64;
      LODWORD(v143) = v143 + 1;
      uint64_t v60 = v141;
      if ((void)v141)
      {
        uint64_t v65 = (char *)&v151;
        mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v151, v29);
        int v66 = (char *)__src[1];
        if (v143 >= HIDWORD(v143))
        {
          unint64_t v119 = v143 + 1;
          if (__src[1] <= &v151 && (char *)__src[1] + 24 * v143 > (char *)&v151)
          {
            int64_t v124 = (char *)&v151 - (char *)__src[1];
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&__src[1], v144, v119, 24);
            int v66 = (char *)__src[1];
            uint64_t v65 = (char *)__src[1] + v124;
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&__src[1], v144, v119, 24);
            uint64_t v65 = (char *)&v151;
            int v66 = (char *)__src[1];
          }
        }
        int v67 = &v66[24 * v143];
        long long v68 = *(_OWORD *)v65;
        *((void *)v67 + 2) = *((void *)v65 + 2);
        *(_OWORD *)int v67 = v68;
        uint64_t v69 = (v143 + 1);
        LODWORD(v143) = v143 + 1;
        uint64_t v60 = v141;
        if ((void)v141)
        {
          LODWORD(v151) = 3;
          *((void *)&v151 + 1) = " that remained live after conversion";
          uint64_t v152 = 36;
          uint64_t v70 = (char *)&v151;
          uint64_t v71 = (char *)__src[1];
          if (v69 >= HIDWORD(v143))
          {
            unint64_t v120 = v69 + 1;
            BOOL v121 = (char *)__src[1] + 24 * v69 > (char *)&v151;
            if (__src[1] <= &v151 && v121)
            {
              int64_t v125 = (char *)&v151 - (char *)__src[1];
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&__src[1], v144, v120, 24);
              uint64_t v71 = (char *)__src[1];
              uint64_t v70 = (char *)__src[1] + v125;
            }
            else
            {
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&__src[1], v144, v120, 24);
              uint64_t v70 = (char *)&v151;
              uint64_t v71 = (char *)__src[1];
            }
          }
          uint64_t v72 = &v71[24 * v143];
          long long v73 = *(_OWORD *)v70;
          *((void *)v72 + 2) = *((void *)v70 + 2);
          *(_OWORD *)uint64_t v72 = v73;
          LODWORD(v143) = v143 + 1;
          uint64_t v60 = v141;
        }
      }
    }
  }
  *(void *)&long long v151 = v60;
  BYTE8(v151) = 0;
  char v160 = 0;
  if (!v150) {
    goto LABEL_81;
  }
  *((void *)&v151 + 1) = *((void *)&v141 + 1);
  int v74 = v143;
  LODWORD(v152) = __src[0];
  __dst = v155;
  uint64_t v154 = 0x400000000;
  if (!v143)
  {
    int v75 = 1;
    goto LABEL_77;
  }
  if (__src[1] == v144)
  {
    if (v143 < 5)
    {
      uint64_t v76 = v143;
    }
    else
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&__dst, v155, v143, 24);
      uint64_t v76 = v143;
      if (!v143) {
        goto LABEL_75;
      }
    }
    memcpy(__dst, __src[1], 24 * v76);
LABEL_75:
    LODWORD(v154) = v74;
    int v75 = v150;
    goto LABEL_76;
  }
  __dst = __src[1];
  uint64_t v154 = v143;
  __src[1] = v144;
  HIDWORD(v143) = 0;
  int v75 = 1;
LABEL_76:
  LODWORD(v143) = 0;
LABEL_77:
  long long v156 = v146;
  uint64_t v157 = v147;
  long long v146 = 0uLL;
  *(_OWORD *)int64_t v158 = *(_OWORD *)__p;
  uint64_t v159 = v149;
  uint64_t v147 = 0;
  __p[0] = 0;
  __p[1] = 0;
  uint64_t v149 = 0;
  char v160 = 1;
  if (v75)
  {
    if (__src[1] != v144) {
      free(__src[1]);
    }
    unsigned __int8 v150 = 0;
  }
LABEL_81:
  mlir::InFlightDiagnostic::abandon(&v141);
  if ((void)v141) {
    mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v141);
  }
  if (v150)
  {
    unint64_t v77 = __p[0];
    if (__p[0])
    {
      int32x2_t v78 = __p[1];
      unint64_t v79 = __p[0];
      if (__p[1] != __p[0])
      {
        do
          int32x2_t v78 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v78 - 1);
        while (v78 != v77);
        unint64_t v79 = __p[0];
      }
      __p[1] = v77;
      operator delete(v79);
    }
    unint64_t v80 = (void *)v146;
    if ((void)v146)
    {
      uint64_t v81 = (void *)*((void *)&v146 + 1);
      uint64_t v82 = (void *)v146;
      if (*((void *)&v146 + 1) != (void)v146)
      {
        do
        {
          uint64_t v84 = *--v81;
          uint64_t v83 = v84;
          *uint64_t v81 = 0;
          if (v84) {
            MEMORY[0x21667D390](v83, 0x1000C8077774924);
          }
        }
        while (v81 != v80);
        uint64_t v82 = (void *)v146;
      }
      *((void *)&v146 + 1) = v80;
      operator delete(v82);
    }
    if (__src[1] != v144) {
      free(__src[1]);
    }
  }
  uint64_t v85 = *(unsigned int *)(v10 + 36);
  if (v85) {
    uint64_t v86 = v127;
  }
  else {
    uint64_t v86 = 0;
  }
  uint64_t v131 = v86;
  uint64_t v132 = v85;
  mlir::ResultRange::use_begin(&v131, (uint64_t *)v139);
  uint64_t v87 = *(unsigned int *)(v10 + 36);
  if (v87) {
    uint64_t v88 = v127;
  }
  else {
    uint64_t v88 = 0;
  }
  uint64_t v131 = v88;
  uint64_t v132 = v87;
  mlir::ResultRange::use_end(&v131, v144);
  uint64_t v89 = v140;
  uint64_t v143 = v140;
  long long v141 = v139[0];
  *(_OWORD *)uint64_t __src = v139[1];
  uint64_t v90 = v145;
  while (v89 != v90)
  {
    uint64_t v95 = *(void *)(v89 + 16);
    uint64_t v96 = a4[20].i64[1];
    uint64_t v97 = a4[21].u32[2];
    if (!v97) {
      goto LABEL_116;
    }
    LODWORD(v98) = ((v95 >> 4) ^ (v95 >> 9)) & (v97 - 1);
    int v99 = (uint64_t *)(v96 + 16 * v98);
    uint64_t v100 = *v99;
    if (*v99 != v95)
    {
      int v101 = 1;
      while (v100 != -4096)
      {
        int v102 = v98 + v101++;
        uint64_t v98 = v102 & (v97 - 1);
        uint64_t v100 = *(void *)(v96 + 16 * v98);
        if (v100 == v95)
        {
          int v99 = (uint64_t *)(v96 + 16 * v98);
          goto LABEL_117;
        }
      }
LABEL_116:
      int v99 = (uint64_t *)(v96 + 16 * v97);
    }
LABEL_117:
    if (v99 == (uint64_t *)(v96 + 16 * v97))
    {
      uint64_t ParentOp = *(mlir::Block **)(v95 + 16);
      if (ParentOp) {
        uint64_t ParentOp = (mlir::Block *)mlir::Block::getParentOp(ParentOp);
      }
      __int32 v104 = a4[38].i32[0];
      if (!v104) {
        break;
      }
      uint64_t v105 = a4[37].i64[0];
      __int32 v106 = v104 - 1;
      unsigned int v93 = ((ParentOp >> 4) ^ (ParentOp >> 9)) & v106;
      unint64_t v94 = *(mlir::Block **)(v105 + 8 * v93);
      if (v94 != ParentOp)
      {
        int v92 = 1;
        while (v94 != (mlir::Block *)-4096)
        {
          unsigned int v91 = v93 + v92++;
          unsigned int v93 = v91 & v106;
          unint64_t v94 = *(mlir::Block **)(v105 + 8 * v93);
          if (v94 == ParentOp) {
            goto LABEL_108;
          }
        }
        break;
      }
    }
LABEL_108:
    mlir::ResultRange::UseIterator::operator++((uint64_t *)v139);
    uint64_t v89 = v140;
  }
  if (v140 != v145 && *(void *)(v140 + 16)) {
    mlir::Diagnostic::attachNote();
  }
  if ((void)v151) {
    mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v151);
  }
  if (v160)
  {
    long long v107 = v158[0];
    if (v158[0])
    {
      uint64_t v108 = v158[1];
      unint64_t v109 = v158[0];
      if (v158[1] != v158[0])
      {
        do
          uint64_t v108 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v108 - 1);
        while (v108 != v107);
        unint64_t v109 = v158[0];
      }
      v158[1] = v107;
      operator delete(v109);
    }
    unsigned int v110 = (void *)v156;
    if ((void)v156)
    {
      unsigned int v111 = (void *)*((void *)&v156 + 1);
      long long v112 = (void *)v156;
      if (*((void *)&v156 + 1) != (void)v156)
      {
        do
        {
          uint64_t v114 = *--v111;
          uint64_t v113 = v114;
          *unsigned int v111 = 0;
          if (v114) {
            MEMORY[0x21667D390](v113, 0x1000C8077774924);
          }
        }
        while (v111 != v110);
        long long v112 = (void *)v156;
      }
      *((void *)&v156 + 1) = v110;
      operator delete(v112);
    }
    if (__dst != v155) {
      free(__dst);
    }
  }
LABEL_144:
  uint64_t v38 = 0;
LABEL_145:
  unint64_t v9 = v164;
  if (v164 >= 8)
  {
LABEL_146:
    if ((v9 & 4) != 0)
    {
      if ((v9 & 2) != 0) {
        BOOL v115 = (uint64_t (**)(uint64_t))v163;
      }
      else {
        BOOL v115 = (uint64_t (**)(uint64_t))v163[0];
      }
      (*(void (**)(uint64_t (**)(uint64_t), uint64_t))((v9 & 0xFFFFFFFFFFFFFFF8) + 16))(v115, v11);
    }
    if ((v9 & 2) == 0) {
      llvm::deallocate_buffer(v163[0], v163[1]);
    }
  }
  return v38;
}

uint64_t llvm::SetVector<anonymous namespace'::UnresolvedMaterialization *,llvm::SmallVector<anonymous namespace'::UnresolvedMaterialization *,0u>,llvm::DenseSet<anonymous namespace'::UnresolvedMaterialization *,llvm::DenseMapInfo<anonymous namespace'::UnresolvedMaterialization *,void>>,0u>::insert(uint64_t a1, uint64_t *a2)
{
  uint64_t v4 = *(llvm **)a1;
  uint64_t v5 = *(unsigned int *)(a1 + 16);
  if (!v5) {
    goto LABEL_27;
  }
  unsigned int v6 = ((*a2 >> 4) ^ (*a2 >> 9)) & (v5 - 1);
  unint64_t v7 = (void *)((char *)v4 + 8 * v6);
  uint64_t v8 = *v7;
  if (*v7 == *a2) {
    return 0;
  }
  unint64_t v15 = 0;
  int v16 = 1;
  while (v8 != -4096)
  {
    uint64_t result = 0;
    if (v15) {
      BOOL v17 = 0;
    }
    else {
      BOOL v17 = v8 == -8192;
    }
    if (v17) {
      unint64_t v15 = v7;
    }
    unsigned int v18 = v6 + v16++;
    unsigned int v6 = v18 & (v5 - 1);
    unint64_t v7 = (void *)((char *)v4 + 8 * v6);
    uint64_t v8 = *v7;
    if (*v7 == *a2) {
      return result;
    }
  }
  uint64_t v19 = (char *)(v15 ? v15 : v7);
  int v20 = *(_DWORD *)(a1 + 8);
  if (4 * v20 + 4 < (3 * v5))
  {
    BOOL v10 = (int)v5 + ~v20 - *(_DWORD *)(a1 + 12) > v5 >> 3;
    int v11 = v5;
    if (v10) {
      goto LABEL_8;
    }
  }
  else
  {
LABEL_27:
    int v11 = 2 * v5;
  }
  unint64_t v21 = (v11 - 1) | ((unint64_t)(v11 - 1) >> 1);
  unint64_t v22 = v21 | (v21 >> 2) | ((v21 | (v21 >> 2)) >> 4);
  int v23 = ((v22 | (v22 >> 8)) >> 16) | v22 | (v22 >> 8);
  if ((v23 + 1) > 0x40) {
    unsigned int v24 = v23 + 1;
  }
  else {
    unsigned int v24 = 64;
  }
  *(_DWORD *)(a1 + 16) = v24;
  buffer = (int64x2_t *)llvm::allocate_buffer(8 * v24, (std::align_val_t)8uLL);
  *(void *)a1 = buffer;
  if (v4)
  {
    *(void *)(a1 + 8) = 0;
    uint64_t v26 = *(unsigned int *)(a1 + 16);
    if (v26)
    {
      unint64_t v27 = (v26 - 1) & 0x1FFFFFFFFFFFFFFFLL;
      int v28 = (char *)buffer;
      if (v27 < 3) {
        goto LABEL_78;
      }
      unint64_t v29 = v27 + 1;
      int v28 = &buffer->i8[8 * (v29 & 0x3FFFFFFFFFFFFFFCLL)];
      uint64_t v30 = buffer + 1;
      int64x2_t v31 = vdupq_n_s64(0xFFFFFFFFFFFFF000);
      uint64_t v32 = v29 & 0x3FFFFFFFFFFFFFFCLL;
      do
      {
        v30[-1] = v31;
        *uint64_t v30 = v31;
        v30 += 2;
        v32 -= 4;
      }
      while (v32);
      if (v29 != (v29 & 0x3FFFFFFFFFFFFFFCLL))
      {
LABEL_78:
        do
        {
          *(void *)int v28 = -4096;
          v28 += 8;
        }
        while (v28 != (char *)buffer + 8 * v26);
      }
    }
    if (v5)
    {
      int v33 = 0;
      int v34 = v26 - 1;
      uint64_t v35 = v4;
      do
      {
        uint64_t v44 = *(void *)v35;
        if ((*(void *)v35 | 0x1000) != 0xFFFFFFFFFFFFF000)
        {
          unsigned int v45 = ((v44 >> 4) ^ (v44 >> 9)) & v34;
          uint64_t v43 = (void *)(*(void *)a1 + 8 * v45);
          uint64_t v46 = *v43;
          if (*v43 != v44)
          {
            uint64_t v47 = 0;
            int v48 = 1;
            while (v46 != -4096)
            {
              if (v47) {
                BOOL v49 = 0;
              }
              else {
                BOOL v49 = v46 == -8192;
              }
              if (v49) {
                uint64_t v47 = v43;
              }
              unsigned int v50 = v45 + v48++;
              unsigned int v45 = v50 & v34;
              uint64_t v43 = (void *)(*(void *)a1 + 8 * (v50 & v34));
              uint64_t v46 = *v43;
              if (*v43 == v44) {
                goto LABEL_49;
              }
            }
            if (v47) {
              uint64_t v43 = v47;
            }
          }
LABEL_49:
          *uint64_t v43 = v44;
          *(_DWORD *)(a1 + 8) = ++v33;
        }
        uint64_t v35 = (llvm *)((char *)v35 + 8);
      }
      while (v35 != (llvm *)((char *)v4 + 8 * v5));
    }
    llvm::deallocate_buffer(v4, (void *)(8 * v5));
  }
  *(void *)(a1 + 8) = 0;
  uint64_t v36 = *(unsigned int *)(a1 + 16);
  if (v36)
  {
    unint64_t v37 = (v36 - 1) & 0x1FFFFFFFFFFFFFFFLL;
    uint64_t v38 = (char *)buffer;
    if (v37 < 3) {
      goto LABEL_79;
    }
    unint64_t v39 = v37 + 1;
    uint64_t v38 = &buffer->i8[8 * (v39 & 0x3FFFFFFFFFFFFFFCLL)];
    uint64_t v40 = buffer + 1;
    int64x2_t v41 = vdupq_n_s64(0xFFFFFFFFFFFFF000);
    uint64_t v42 = v39 & 0x3FFFFFFFFFFFFFFCLL;
    do
    {
      v40[-1] = v41;
      *uint64_t v40 = v41;
      v40 += 2;
      v42 -= 4;
    }
    while (v42);
    if (v39 != (v39 & 0x3FFFFFFFFFFFFFFCLL))
    {
LABEL_79:
      do
      {
        *(void *)uint64_t v38 = -4096;
        v38 += 8;
      }
      while (v38 != (char *)buffer + 8 * v36);
    }
  }
  uint64_t v12 = *a2;
  int v51 = v36 - 1;
  unsigned int v52 = ((*a2 >> 4) ^ (*a2 >> 9)) & (v36 - 1);
  uint64_t v19 = &buffer->i8[8 * v52];
  uint64_t v53 = *(void *)v19;
  if (*(void *)v19 == *a2) {
    goto LABEL_9;
  }
  uint64_t v54 = 0;
  int v55 = 1;
  while (v53 != -4096)
  {
    if (v54) {
      BOOL v56 = 0;
    }
    else {
      BOOL v56 = v53 == -8192;
    }
    if (v56) {
      uint64_t v54 = v19;
    }
    unsigned int v57 = v52 + v55++;
    unsigned int v52 = v57 & v51;
    uint64_t v19 = &buffer->i8[8 * (v57 & v51)];
    uint64_t v53 = *(void *)v19;
    if (*(void *)v19 == v12) {
      goto LABEL_9;
    }
  }
  if (v54) {
    uint64_t v19 = v54;
  }
LABEL_8:
  uint64_t v12 = *(void *)v19;
LABEL_9:
  ++*(_DWORD *)(a1 + 8);
  if (v12 != -4096) {
    --*(_DWORD *)(a1 + 12);
  }
  *(void *)uint64_t v19 = *a2;
  uint64_t v13 = *a2;
  uint64_t v14 = *(unsigned int *)(a1 + 32);
  if (v14 >= *(_DWORD *)(a1 + 36))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod(a1 + 24, (void *)(a1 + 40), v14 + 1, 8);
    LODWORD(v14) = *(_DWORD *)(a1 + 32);
  }
  *(void *)(*(void *)(a1 + 24) + 8 * v14) = v13;
  ++*(_DWORD *)(a1 + 32);
  return 1;
}

void *replaceMaterialization(uint64_t a1, void *a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  uint64_t v75 = *MEMORY[0x263EF8340];
  uint64_t v65 = a2;
  uint64_t v66 = a3;
  uint64_t v73 = a4;
  uint64_t v74 = a5;
  uint64_t result = mlir::ResultRange::replaceAllUsesWith<mlir::ValueRange &>(&v65, &v73);
  uint64_t v60 = v73;
  uint64_t v61 = v65;
  uint64_t v69 = v65;
  uint64_t v70 = 0;
  uint64_t v71 = v73;
  uint64_t v72 = 0;
  uint64_t v59 = v66;
  if (v66)
  {
    uint64_t v8 = 0;
    uint64_t v9 = 0;
    uint64_t v58 = v74;
    uint64_t result = v65;
    while (1)
    {
      if (v71 == v60 && v9 == v58) {
        return result;
      }
      uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset((uint64_t)result, v8);
      uint64_t v13 = mlir::ValueRange::dereference_iterator(&v71, v72);
      uint64_t v63 = NextResultAtOffset;
      uint64_t v64 = v13;
      uint64_t v68 = 0;
      if (llvm::DenseMapBase<llvm::DenseMap<mlir::Value,llvm::SmallVector<llvm::SMLoc,6u>,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,llvm::SmallVector<llvm::SMLoc,6u>>>,mlir::Value,llvm::SmallVector<llvm::SMLoc,6u>,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,llvm::SmallVector<llvm::SMLoc,6u>>>::LookupBucketFor<mlir::Value>((uint64_t *)a6, (unint64_t *)&v63, &v68))
      {
        if (v68 != *(void *)a6 + 72 * *(unsigned int *)(a6 + 16))
        {
          uint64_t v14 = *(unsigned int *)(v68 + 16);
          if (v14) {
            break;
          }
        }
      }
LABEL_3:
      uint64_t result = v69;
      uint64_t v8 = v70 + 1;
      uint64_t v9 = v72 + 1;
      ++v70;
      ++v72;
      if (v69 == v61 && v8 == v59) {
        return result;
      }
    }
    unint64_t v15 = *(unint64_t **)(v68 + 8);
    int v16 = &v15[v14];
    while (1)
    {
      unint64_t v17 = *v15;
      uint64_t v18 = v64;
      if (v64)
      {
        unint64_t v19 = v64;
        while (1)
        {
          uint64_t v20 = *(void *)a1;
          int v21 = *(_DWORD *)(a1 + 16);
          if (v19 == v17) {
            break;
          }
          if (!v21)
          {
            unsigned int v42 = 0;
            unint64_t v67 = v17;
            goto LABEL_61;
          }
          {
            unsigned int v57 = v16;
            int v16 = v57;
            if (v29)
            {
              unint64_t v30 = llvm::hashing::detail::fixed_seed_override;
              if (!llvm::hashing::detail::fixed_seed_override) {
                unint64_t v30 = 0xFF51AFD7ED558CCDLL;
              }
              llvm::hashing::detail::get_execution_seed(void)::seed = v30;
              int v16 = v57;
            }
          }
          unint64_t v22 = 0x9DDFEA08EB382D69
              * ((llvm::hashing::detail::get_execution_seed(void)::seed + 8 * v19) ^ HIDWORD(v19));
          unint64_t v23 = 0x9DDFEA08EB382D69 * (HIDWORD(v19) ^ (v22 >> 47) ^ v22);
          LODWORD(v23) = (-348639895 * ((v23 >> 47) ^ v23)) & (v21 - 1);
          unsigned int v24 = (uint64_t *)(v20 + 16 * v23);
          uint64_t v25 = *v24;
          if (v19 != *v24)
          {
            int v27 = 1;
            while (v25 != -4096)
            {
              int v28 = v23 + v27++;
              unint64_t v23 = v28 & (v21 - 1);
              uint64_t v25 = *(void *)(v20 + 16 * v23);
              if (v19 == v25)
              {
                unsigned int v24 = (uint64_t *)(v20 + 16 * v23);
                uint64_t v26 = *(unsigned int *)(a1 + 16);
                if (v24 != (uint64_t *)(*(void *)a1 + 16 * v26)) {
                  goto LABEL_25;
                }
                goto LABEL_37;
              }
            }
            goto LABEL_36;
          }
          uint64_t v26 = *(unsigned int *)(a1 + 16);
          if (v24 == (uint64_t *)(*(void *)a1 + 16 * v26)) {
            goto LABEL_37;
          }
LABEL_25:
          unint64_t v19 = v24[1];
          if (!v19) {
            goto LABEL_36;
          }
        }
        if (v21)
        {
          {
            uint64_t v54 = v16;
            int v16 = v54;
            if (v55)
            {
              unint64_t v56 = llvm::hashing::detail::fixed_seed_override;
              if (!llvm::hashing::detail::fixed_seed_override) {
                unint64_t v56 = 0xFF51AFD7ED558CCDLL;
              }
              llvm::hashing::detail::get_execution_seed(void)::seed = v56;
              int v16 = v54;
            }
          }
          unint64_t v43 = 0x9DDFEA08EB382D69
              * ((llvm::hashing::detail::get_execution_seed(void)::seed + 8 * v17) ^ HIDWORD(v17));
          unint64_t v44 = 0x9DDFEA08EB382D69 * (HIDWORD(v17) ^ (v43 >> 47) ^ v43);
          LODWORD(v44) = (-348639895 * ((v44 >> 47) ^ v44)) & (v21 - 1);
          unsigned int v45 = (uint64_t *)(v20 + 16 * v44);
          uint64_t v46 = *v45;
          if (v17 == *v45)
          {
LABEL_53:
            *unsigned int v45 = -8192;
            *(int32x2_t *)(a1 + 8) = vadd_s32(*(int32x2_t *)(a1 + 8), (int32x2_t)0x1FFFFFFFFLL);
          }
          else
          {
            int v49 = 1;
            while (v46 != -4096)
            {
              int v50 = v44 + v49++;
              unint64_t v44 = v50 & (v21 - 1);
              uint64_t v46 = *(void *)(v20 + 16 * v44);
              if (v17 == v46)
              {
                unsigned int v45 = (uint64_t *)(v20 + 16 * v44);
                goto LABEL_53;
              }
            }
          }
        }
        goto LABEL_17;
      }
LABEL_36:
      LODWORD(v26) = *(_DWORD *)(a1 + 16);
LABEL_37:
      unint64_t v67 = v17;
      if (!v26) {
        break;
      }
      uint64_t v31 = *(void *)a1;
      {
        int v51 = v16;
        int v16 = v51;
        if (v52)
        {
          unint64_t v53 = llvm::hashing::detail::fixed_seed_override;
          if (!llvm::hashing::detail::fixed_seed_override) {
            unint64_t v53 = 0xFF51AFD7ED558CCDLL;
          }
          llvm::hashing::detail::get_execution_seed(void)::seed = v53;
          int v16 = v51;
        }
      }
      unint64_t v32 = 0x9DDFEA08EB382D69
          * ((llvm::hashing::detail::get_execution_seed(void)::seed + 8 * v17) ^ HIDWORD(v17));
      unint64_t v33 = 0x9DDFEA08EB382D69 * (HIDWORD(v17) ^ (v32 >> 47) ^ v32);
      int v34 = v26 - 1;
      unsigned int v35 = (-348639895 * ((v33 >> 47) ^ v33)) & (v26 - 1);
      uint64_t v36 = (void *)(v31 + 16 * v35);
      uint64_t v37 = *v36;
      if (v67 == *v36) {
        goto LABEL_16;
      }
      uint64_t v38 = 0;
      int v39 = 1;
      while (v37 != -4096)
      {
        if (v38) {
          BOOL v40 = 0;
        }
        else {
          BOOL v40 = v37 == -8192;
        }
        if (v40) {
          uint64_t v38 = v36;
        }
        unsigned int v41 = v35 + v39++;
        unsigned int v35 = v41 & v34;
        uint64_t v36 = (void *)(v31 + 16 * (v41 & v34));
        uint64_t v37 = *v36;
        if (v67 == *v36) {
          goto LABEL_16;
        }
      }
      if (v38) {
        uint64_t v36 = v38;
      }
      unsigned int v42 = *(_DWORD *)(a1 + 16);
      int v47 = *(_DWORD *)(a1 + 8);
      if (4 * v47 + 4 >= 3 * v42) {
        goto LABEL_61;
      }
      if (v42 + ~v47 - *(_DWORD *)(a1 + 12) <= v42 >> 3) {
        goto LABEL_62;
      }
      ++*(_DWORD *)(a1 + 8);
      if (*v36 != -4096) {
        goto LABEL_57;
      }
LABEL_15:
      *uint64_t v36 = v67;
      v36[1] = 0;
LABEL_16:
      v36[1] = v18;
LABEL_17:
      if (++v15 == v16) {
        goto LABEL_3;
      }
    }
    unsigned int v42 = 0;
LABEL_61:
    v42 *= 2;
LABEL_62:
    int v48 = v16;
    llvm::DenseMap<mlir::Value,mlir::Value,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,mlir::Value>>::grow(a1, v42);
    uint64_t v68 = 0;
    llvm::DenseMapBase<llvm::DenseMap<mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>,mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>::LookupBucketFor<mlir::Value>((uint64_t *)a1, &v67, &v68);
    int v16 = v48;
    uint64_t v36 = (void *)v68;
    ++*(_DWORD *)(a1 + 8);
    if (*v36 == -4096) {
      goto LABEL_15;
    }
LABEL_57:
    --*(_DWORD *)(a1 + 12);
    goto LABEL_15;
  }
  return result;
}

uint64_t llvm::detail::UniqueFunctionBase<mlir::Value,mlir::Value,mlir::Value,mlir::Type>::CallImpl<computeNecessaryMaterializations(llvm::DenseMap<mlir::Operation *,anonymous namespace'::UnresolvedMaterialization *,llvm::DenseMapInfo<mlir::Operation *,void>,llvm::detail::DenseMapPair<mlir::Operation *,anonymous namespace'::UnresolvedMaterialization *>> &,mlir::ConversionPatternRewriter &,mlir::detail::ConversionPatternRewriterImpl &,llvm::DenseMap<mlir::Value,llvm::SmallVector<mlir::Value,6u>,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,llvm::SmallVector<mlir::Value,6u>>> &,llvm::SetVector<anonymous namespace'::UnresolvedMaterialization *,llvm::SmallVector<anonymous namespace'::UnresolvedMaterialization *,0u>,llvm::DenseSet<anonymous namespace'::UnresolvedMaterialization *,llvm::DenseMapInfo<anonymous namespace'::UnresolvedMaterialization *,void>>,0u> &)::$_1>(uint64_t *a1, uint64_t a2, unint64_t a3, uint64_t a4)
{
  unint64_t v16 = a3;
  uint64_t v7 = *a1;
  if (a4)
  {
    unint64_t v8 = 0;
    do
    {
      unint64_t v9 = a3;
      if ((*(void *)(a3 + 8) & 0xFFFFFFFFFFFFFFF8) == a4) {
        unint64_t v8 = a3;
      }
      unint64_t v17 = a3;
      uint64_t v18 = 0;
      if (!llvm::DenseMapBase<llvm::DenseMap<mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>,mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>::LookupBucketFor<mlir::Value>((uint64_t *)v7, &v17, &v18))break; {
      if (v18 == *(void *)v7 + 16 * *(unsigned int *)(v7 + 16))
      }
        break;
      a3 = *(void *)(v18 + 8);
    }
    while (a3);
    if (!v8) {
      unint64_t v8 = v9;
    }
  }
  else
  {
    do
    {
      unint64_t v8 = a3;
      unint64_t v17 = a3;
      uint64_t v18 = 0;
      if (!llvm::DenseMapBase<llvm::DenseMap<mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>,mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>::LookupBucketFor<mlir::Value>((uint64_t *)v7, &v17, &v18))break; {
      if (v18 == *(void *)v7 + 16 * *(unsigned int *)(v7 + 16))
      }
        break;
      a3 = *(void *)(v18 + 8);
    }
    while (a3);
  }
  if ((*(void *)(v8 + 8) & 0xFFFFFFFFFFFFFFF8) != a4 || v8 == a2)
  {
    uint64_t DefiningOp = mlir::Value::getDefiningOp((mlir::Value *)&v16);
    if (DefiningOp
      && (uint64_t v12 = DefiningOp,
          *(_UNKNOWN **)(*(void *)(DefiningOp + 48) + 16) == &mlir::detail::TypeIDResolver<mlir::UnrealizedConversionCastOp,void>::id)
      && (*(unsigned char *)(DefiningOp + 46) & 0x80) != 0
      && *(_DWORD *)(DefiningOp + 68) == 1)
    {
      uint64_t v13 = (void *)a1[1];
      uint64_t v14 = v13[3];
      if ((v14 & 2) == 0) {
        uint64_t v13 = (void *)*v13;
      }
      return (*(uint64_t (**)(void *, uint64_t, void, uint64_t))(v14 & 0xFFFFFFFFFFFFFFF8))(v13, a2, *(void *)(*(void *)(v12 + 72) + 24), a4);
    }
    else
    {
      return 0;
    }
  }
  return v8;
}

void *mlir::ResultRange::replaceAllUsesWith<mlir::ValueRange &>(void *result, uint64_t *a2)
{
  uint64_t v20 = *MEMORY[0x263EF8340];
  uint64_t v2 = *a2;
  uint64_t v3 = (void *)*result;
  uint64_t v4 = result[1];
  unint64_t v16 = (void *)*result;
  uint64_t v17 = 0;
  uint64_t v18 = *a2;
  uint64_t v19 = 0;
  if (v4)
  {
    uint64_t v6 = 0;
    uint64_t v7 = 0;
    uint64_t v8 = a2[1];
    uint64_t result = v3;
    do
    {
      if (v18 == v2 && v7 == v8) {
        break;
      }
      uint64_t NextResultAtOffset = (uint64_t **)mlir::detail::OpResultImpl::getNextResultAtOffset((uint64_t)result, v6);
      for (uint64_t i = (uint64_t *)mlir::ValueRange::dereference_iterator(&v18, v19); ; *uint64_t i = (uint64_t)v13)
      {
        uint64_t v13 = *NextResultAtOffset;
        if (!*NextResultAtOffset) {
          break;
        }
        uint64_t v14 = (uint64_t *)v13[1];
        if (v14)
        {
          *uint64_t v14 = *v13;
          if (*v13) {
            *(void *)(*v13 + 8) = v13[1];
          }
        }
        v13[3] = (uint64_t)i;
        v13[1] = (uint64_t)i;
        uint64_t v15 = *i;
        *uint64_t v13 = *i;
        if (v15) {
          *(void *)(v15 + 8) = v13;
        }
      }
      uint64_t result = v16;
      uint64_t v6 = v17 + 1;
      uint64_t v7 = v19 + 1;
      ++v17;
      ++v19;
    }
    while (v16 != v3 || v6 != v4);
  }
  return result;
}

void *llvm::DenseMapBase<llvm::DenseMap<mlir::Value,llvm::SmallVector<mlir::Value,6u>,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,llvm::SmallVector<mlir::Value,6u>>>,mlir::Value,llvm::SmallVector<mlir::Value,6u>,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,llvm::SmallVector<mlir::Value,6u>>>::InsertIntoBucketImpl<mlir::Value>(uint64_t a1, uint64_t a2, unint64_t *a3, void *a4)
{
  int v6 = *(_DWORD *)(a1 + 8);
  unsigned int v7 = *(_DWORD *)(a1 + 16);
  if (4 * v6 + 4 >= 3 * v7)
  {
    v7 *= 2;
LABEL_7:
    llvm::DenseMapBase<llvm::DenseMap<mlir::Value,llvm::SmallVector<mlir::Value,6u>,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,llvm::SmallVector<mlir::Value,6u>>>,mlir::Value,llvm::SmallVector<mlir::Value,6u>,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,llvm::SmallVector<mlir::Value,6u>>>::grow(a1, v7);
    unint64_t v9 = 0;
    llvm::DenseMapBase<llvm::DenseMap<mlir::Value,llvm::SmallVector<llvm::SMLoc,6u>,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,llvm::SmallVector<llvm::SMLoc,6u>>>,mlir::Value,llvm::SmallVector<llvm::SMLoc,6u>,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,llvm::SmallVector<llvm::SMLoc,6u>>>::LookupBucketFor<mlir::Value>((uint64_t *)a1, a3, &v9);
    a4 = v9;
    ++*(_DWORD *)(a1 + 8);
    if (*a4 == -4096) {
      return a4;
    }
    goto LABEL_4;
  }
  if (v7 + ~v6 - *(_DWORD *)(a1 + 12) <= v7 >> 3) {
    goto LABEL_7;
  }
  ++*(_DWORD *)(a1 + 8);
  if (*a4 != -4096) {
LABEL_4:
  }
    --*(_DWORD *)(a1 + 12);
  return a4;
}

void *llvm::DenseMapBase<llvm::DenseMap<mlir::Value,llvm::SmallVector<mlir::Value,6u>,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,llvm::SmallVector<mlir::Value,6u>>>,mlir::Value,llvm::SmallVector<mlir::Value,6u>,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,llvm::SmallVector<mlir::Value,6u>>>::grow(uint64_t a1, int a2)
{
  uint64_t v3 = *(unsigned int *)(a1 + 16);
  uint64_t v4 = *(llvm **)a1;
  unint64_t v5 = (a2 - 1) | ((unint64_t)(a2 - 1) >> 1);
  unint64_t v6 = v5 | (v5 >> 2) | ((v5 | (v5 >> 2)) >> 4);
  int v7 = ((v6 | (v6 >> 8)) >> 16) | v6 | (v6 >> 8);
  if ((v7 + 1) > 0x40) {
    unsigned int v8 = v7 + 1;
  }
  else {
    unsigned int v8 = 64;
  }
  *(_DWORD *)(a1 + 16) = v8;
  uint64_t result = llvm::allocate_buffer(72 * v8, (std::align_val_t)8uLL);
  *(void *)a1 = result;
  if (v4)
  {
    uint64_t v10 = 72 * v3;
    llvm::DenseMapBase<llvm::DenseMap<mlir::Value,llvm::SmallVector<mlir::Value,6u>,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,llvm::SmallVector<mlir::Value,6u>>>,mlir::Value,llvm::SmallVector<mlir::Value,6u>,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,llvm::SmallVector<mlir::Value,6u>>>::moveFromOldBuckets(a1, (uint64_t)v4, (uint64_t)v4 + v10);
    llvm::deallocate_buffer(v4, (void *)v10);
  }
  *(void *)(a1 + 8) = 0;
  unsigned int v11 = *(_DWORD *)(a1 + 16);
  if (v11)
  {
    unint64_t v12 = 72 * v11 - 72;
    if (v12 < 0x48)
    {
      uint64_t v13 = result;
LABEL_14:
      uint64_t v17 = &result[9 * v11];
      do
      {
        *uint64_t v13 = -4096;
        v13 += 9;
      }
      while (v13 != v17);
      return result;
    }
    unint64_t v14 = v12 / 0x48 + 1;
    uint64_t v13 = &result[9 * (v14 & 0x7FFFFFFFFFFFFFELL)];
    uint64_t v15 = v14 & 0x7FFFFFFFFFFFFFELL;
    unint64_t v16 = result;
    do
    {
      *unint64_t v16 = -4096;
      void v16[9] = -4096;
      v16 += 18;
      v15 -= 2;
    }
    while (v15);
    if (v14 != (v14 & 0x7FFFFFFFFFFFFFELL)) {
      goto LABEL_14;
    }
  }
  return result;
}

void llvm::DenseMapBase<llvm::DenseMap<mlir::Value,llvm::SmallVector<mlir::Value,6u>,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,llvm::SmallVector<mlir::Value,6u>>>,mlir::Value,llvm::SmallVector<mlir::Value,6u>,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,llvm::SmallVector<mlir::Value,6u>>>::moveFromOldBuckets(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = a2;
  *(void *)(a1 + 8) = 0;
  unsigned int v6 = *(_DWORD *)(a1 + 16);
  if (v6)
  {
    uint64_t v7 = *(void *)a1;
    unint64_t v8 = 72 * v6 - 72;
    if (v8 < 0x48)
    {
      unint64_t v9 = *(void **)a1;
LABEL_7:
      uint64_t v13 = (void *)(v7 + 72 * v6);
      do
      {
        *unint64_t v9 = -4096;
        v9 += 9;
      }
      while (v9 != v13);
      goto LABEL_9;
    }
    unint64_t v10 = v8 / 0x48 + 1;
    unint64_t v9 = (void *)(v7 + 72 * (v10 & 0x7FFFFFFFFFFFFFELL));
    uint64_t v11 = v10 & 0x7FFFFFFFFFFFFFELL;
    unint64_t v12 = *(void **)a1;
    do
    {
      *unint64_t v12 = -4096;
      v12[9] = -4096;
      v12 += 18;
      v11 -= 2;
    }
    while (v11);
    if (v10 != (v10 & 0x7FFFFFFFFFFFFFELL)) {
      goto LABEL_7;
    }
  }
LABEL_9:
  if (a2 != a3)
  {
    do
    {
      if ((*(void *)v4 | 0x1000) != 0xFFFFFFFFFFFFF000)
      {
        uint64_t v17 = 0;
        llvm::DenseMapBase<llvm::DenseMap<mlir::Value,llvm::SmallVector<llvm::SMLoc,6u>,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,llvm::SmallVector<llvm::SMLoc,6u>>>,mlir::Value,llvm::SmallVector<llvm::SMLoc,6u>,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,llvm::SmallVector<llvm::SMLoc,6u>>>::LookupBucketFor<mlir::Value>((uint64_t *)a1, (unint64_t *)v4, &v17);
        unint64_t v14 = v17;
        *uint64_t v17 = *(void *)v4;
        uint64_t v14[2] = 0x600000000;
        v14[1] = v14 + 3;
        uint64_t v15 = (uint64_t)(v14 + 1);
        if (*(_DWORD *)(v4 + 16)) {
          llvm::SmallVectorImpl<mlir::Value>::operator=(v15, v4 + 8);
        }
        ++*(_DWORD *)(a1 + 8);
        unint64_t v16 = *(void **)(v4 + 8);
        if ((void *)(v4 + 24) != v16) {
          free(v16);
        }
      }
      v4 += 72;
    }
    while (v4 != a3);
  }
}

void *llvm::find_if_not<llvm::iterator_range<mlir::ValueUserIterator<mlir::ValueUseIterator<mlir::OpOperand>,mlir::OpOperand>>,computeNecessaryMaterializations(llvm::DenseMap<mlir::Operation *,anonymous namespace'::UnresolvedMaterialization *,llvm::DenseMapInfo<mlir::Operation *,void>,llvm::detail::DenseMapPair<mlir::Operation *,anonymous namespace'::UnresolvedMaterialization *>> &,mlir::ConversionPatternRewriter &,mlir::detail::ConversionPatternRewriterImpl &,llvm::DenseMap<mlir::Value,llvm::SmallVector<mlir::Value,6u>,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,llvm::SmallVector<mlir::Value,6u>>> &,llvm::SetVector<anonymous namespace'::UnresolvedMaterialization *,llvm::SmallVector<anonymous namespace'::UnresolvedMaterialization *,0u>,llvm::DenseSet<anonymous namespace'::UnresolvedMaterialization *,llvm::DenseMapInfo<anonymous namespace'::UnresolvedMaterialization *,void>>,0u> &)::$_0::operator() const(mlir::Value)::{lambda(mlir::Operation *)#1}>(void *a1, void *a2, uint64_t **a3)
{
  uint64_t v3 = a1;
  if (a1 == a2) {
    return v3;
  }
  unint64_t v5 = *a3;
  unsigned int v6 = a3[1];
  uint64_t v7 = a3[2];
  while (1)
  {
    uint64_t v12 = v3[2];
    uint64_t v13 = *v5;
    uint64_t v14 = *((unsigned int *)v5 + 4);
    if (v14)
    {
      LODWORD(v15) = ((v12 >> 4) ^ (v12 >> 9)) & (v14 - 1);
      unint64_t v16 = (uint64_t *)(v13 + 16 * v15);
      uint64_t v17 = *v16;
      if (*v16 == v12) {
        goto LABEL_13;
      }
      int v18 = 1;
      while (v17 != -4096)
      {
        int v19 = v15 + v18++;
        uint64_t v15 = v19 & (v14 - 1);
        uint64_t v17 = *(void *)(v13 + 16 * v15);
        if (v17 == v12)
        {
          unint64_t v16 = (uint64_t *)(v13 + 16 * v15);
          goto LABEL_13;
        }
      }
    }
    unint64_t v16 = (uint64_t *)(v13 + 16 * v14);
LABEL_13:
    if (v16 == (uint64_t *)(v13 + 16 * v14)) {
      break;
    }
    int v20 = *((_DWORD *)v6 + 4);
    if (v20)
    {
      uint64_t v21 = v16[1];
      int v22 = v20 - 1;
      unsigned int v23 = ((v21 >> 4) ^ (v21 >> 9)) & v22;
      uint64_t v24 = *(void *)(*v6 + 8 * v23);
      if (v24 == v21) {
        return v3;
      }
      int v25 = 1;
      while (v24 != -4096)
      {
        unsigned int v26 = v23 + v25++;
        unsigned int v23 = v26 & v22;
        uint64_t v24 = *(void *)(*v6 + 8 * v23);
        if (v24 == v21) {
          return v3;
        }
      }
    }
LABEL_5:
    uint64_t v3 = (void *)*v3;
    if (v3 == a2) {
      return a2;
    }
  }
  uint64_t v27 = v7[41];
  uint64_t v28 = *((unsigned int *)v7 + 86);
  if (!v28) {
    goto LABEL_26;
  }
  LODWORD(v29) = (v28 - 1) & ((v12 >> 4) ^ (v12 >> 9));
  unint64_t v30 = (uint64_t *)(v27 + 16 * v29);
  uint64_t v31 = *v30;
  if (*v30 != v12)
  {
    int v32 = 1;
    while (v31 != -4096)
    {
      int v33 = v29 + v32++;
      uint64_t v29 = v33 & (v28 - 1);
      uint64_t v31 = *(void *)(v27 + 16 * v29);
      if (v31 == v12)
      {
        unint64_t v30 = (uint64_t *)(v27 + 16 * v29);
        goto LABEL_27;
      }
    }
LABEL_26:
    unint64_t v30 = (uint64_t *)(v27 + 16 * v28);
  }
LABEL_27:
  if (v30 != (uint64_t *)(v27 + 16 * v28)) {
    goto LABEL_5;
  }
  uint64_t ParentOp = *(mlir::Block **)(v12 + 16);
  if (ParentOp) {
    uint64_t ParentOp = (mlir::Block *)mlir::Block::getParentOp(ParentOp);
  }
  int v35 = *((_DWORD *)v7 + 152);
  if (!v35) {
    return v3;
  }
  uint64_t v36 = v7[74];
  int v37 = v35 - 1;
  unsigned int v10 = ((ParentOp >> 4) ^ (ParentOp >> 9)) & v37;
  uint64_t v11 = *(mlir::Block **)(v36 + 8 * v10);
  if (v11 == ParentOp) {
    goto LABEL_5;
  }
  int v9 = 1;
  while (v11 != (mlir::Block *)-4096)
  {
    unsigned int v8 = v10 + v9++;
    unsigned int v10 = v8 & v37;
    uint64_t v11 = *(mlir::Block **)(v36 + 8 * v10);
    if (v11 == ParentOp) {
      goto LABEL_5;
    }
  }
  return v3;
}

unint64_t llvm::detail::UniqueFunctionBase<mlir::Value,mlir::Value,mlir::Type>::CallImpl<legalizeUnresolvedMaterialization(anonymous namespace'::UnresolvedMaterialization &,llvm::DenseMap<mlir::Operation *,anonymous namespace'::UnresolvedMaterialization*,llvm::DenseMapInfo<mlir::Operation *,void>,llvm::detail::DenseMapPair<mlir::Operation *,anonymous namespace'::UnresolvedMaterialization*>> &,mlir::ConversionPatternRewriter &,mlir::detail::ConversionPatternRewriterImpl &,llvm::DenseMap<mlir::Value,llvm::SmallVector<mlir::Value,6u>,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,llvm::SmallVector<mlir::Value,6u>>> &)::$_1>(uint64_t *a1, unint64_t a2, uint64_t a3)
{
  uint64_t v4 = *a1;
  if (a3)
  {
    unint64_t v5 = 0;
    do
    {
      unint64_t v6 = a2;
      if ((*(void *)(a2 + 8) & 0xFFFFFFFFFFFFFFF8) == a3) {
        unint64_t v5 = a2;
      }
      unint64_t v8 = a2;
      uint64_t v9 = 0;
      if (!llvm::DenseMapBase<llvm::DenseMap<mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>,mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>::LookupBucketFor<mlir::Value>((uint64_t *)v4, &v8, &v9))break; {
      if (v9 == *(void *)v4 + 16 * *(unsigned int *)(v4 + 16))
      }
        break;
      a2 = *(void *)(v9 + 8);
    }
    while (a2);
    if (!v5) {
      unint64_t v5 = v6;
    }
  }
  else
  {
    do
    {
      unint64_t v5 = a2;
      unint64_t v8 = a2;
      uint64_t v9 = 0;
      if (!llvm::DenseMapBase<llvm::DenseMap<mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>,mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>::LookupBucketFor<mlir::Value>((uint64_t *)v4, &v8, &v9))break; {
      if (v9 == *(void *)v4 + 16 * *(unsigned int *)(v4 + 16))
      }
        break;
      a2 = *(void *)(v9 + 8);
    }
    while (a2);
  }
  if ((*(void *)(v5 + 8) & 0xFFFFFFFFFFFFFFF8) == a3) {
    return v5;
  }
  else {
    return 0;
  }
}

void llvm::interleave<mlir::ValueTypeIterator<llvm::detail::indexed_accessor_range_base<mlir::OperandRange,mlir::OpOperand *,mlir::Value,mlir::Value,mlir::Value>::iterator>,mlir::Diagnostic& mlir::Diagnostic::appendRange<mlir::ValueTypeRange<mlir::OperandRange>>(mlir::ValueTypeRange<mlir::OperandRange> const&,char const*)::{lambda(mlir::ValueTypeRange<mlir::OperandRange> const&)#1},mlir::Diagnostic& mlir::Diagnostic::appendRange<mlir::ValueTypeRange<mlir::OperandRange>>(mlir::ValueTypeRange<mlir::OperandRange> const&,char const*)::{lambda(void)#1},void>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, const char **a7)
{
  if (a1 != a3 || a2 != a4)
  {
    uint64_t v14 = &v48;
    mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v48, *(void *)(*(void *)(a1 + 32 * a2 + 24) + 8) & 0xFFFFFFFFFFFFFFF8);
    unint64_t v15 = *(void *)(a5 + 16);
    int v47 = (unint64_t *)(a5 + 16);
    uint64_t v16 = *(unsigned int *)(a5 + 24);
    if (v16 >= *(_DWORD *)(a5 + 28))
    {
      unint64_t v39 = v16 + 1;
      BOOL v40 = v15 + 24 * v16 > (unint64_t)&v48;
      if (v15 <= (unint64_t)&v48 && v40)
      {
        unsigned int v41 = (char *)&v48 - v15;
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)v47, (void *)(a5 + 32), v39, 24);
        unint64_t v15 = *(void *)(a5 + 16);
        uint64_t v14 = (int *)&v41[v15];
      }
      else
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)v47, (void *)(a5 + 32), v39, 24);
        unint64_t v15 = *(void *)(a5 + 16);
        uint64_t v14 = &v48;
      }
    }
    uint64_t v17 = v15 + 24 * *(unsigned int *)(a5 + 24);
    long long v18 = *(_OWORD *)v14;
    *(void *)(v17 + 16) = *((void *)v14 + 2);
    *(_OWORD *)uint64_t v17 = v18;
    ++*(_DWORD *)(a5 + 24);
    if (a1 != a3 || a2 + 1 != a4)
    {
      unsigned int v45 = (void *)(a6 + 32);
      uint64_t v46 = (unint64_t *)(a6 + 16);
      unint64_t v44 = (void *)(a5 + 32);
      uint64_t v19 = a4 - a2 - 2;
      uint64_t v20 = a1 + 32 * a2 + 56;
      do
      {
        uint64_t v21 = *a7;
        if (*a7)
        {
          size_t v22 = strlen(*a7);
          int v48 = 3;
          int v49 = v21;
          size_t v50 = v22;
          uint64_t v23 = *(unsigned int *)(a6 + 24);
          unint64_t v24 = *(void *)(a6 + 16);
          if (v23 < *(_DWORD *)(a6 + 28)) {
            goto LABEL_12;
          }
        }
        else
        {
          int v48 = 3;
          int v49 = 0;
          size_t v50 = 0;
          uint64_t v23 = *(unsigned int *)(a6 + 24);
          unint64_t v24 = *(void *)(a6 + 16);
          if (v23 < *(_DWORD *)(a6 + 28)) {
            goto LABEL_12;
          }
        }
        unint64_t v35 = v23 + 1;
        BOOL v36 = v24 + 24 * v23 > (unint64_t)&v48;
        if (v24 <= (unint64_t)&v48 && v36)
        {
          unsigned int v42 = (char *)&v48 - v24;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)v46, v45, v35, 24);
          unint64_t v24 = *v46;
          int v25 = (int *)&v42[*v46];
          goto LABEL_13;
        }
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)v46, v45, v35, 24);
        unint64_t v24 = *v46;
LABEL_12:
        int v25 = &v48;
LABEL_13:
        uint64_t v26 = v24 + 24 * *(unsigned int *)(a6 + 24);
        long long v27 = *(_OWORD *)v25;
        *(void *)(v26 + 16) = *((void *)v25 + 2);
        *(_OWORD *)uint64_t v26 = v27;
        ++*(_DWORD *)(a6 + 24);
        uint64_t v28 = &v48;
        mlir::DiagnosticArgument::DiagnosticArgument((uint64_t)&v48, *(void *)(*(void *)v20 + 8) & 0xFFFFFFFFFFFFFFF8);
        uint64_t v29 = *(unsigned int *)(a5 + 24);
        unint64_t v30 = *(void *)(a5 + 16);
        if (v29 >= *(_DWORD *)(a5 + 28))
        {
          unint64_t v37 = v29 + 1;
          BOOL v38 = v30 + 24 * v29 > (unint64_t)&v48;
          if (v30 <= (unint64_t)&v48 && v38)
          {
            unint64_t v43 = (char *)&v48 - v30;
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)v47, v44, v37, 24);
            unint64_t v30 = *v47;
            uint64_t v28 = (int *)&v43[*v47];
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)v47, v44, v37, 24);
            unint64_t v30 = *v47;
            uint64_t v28 = &v48;
          }
        }
        uint64_t v31 = v30 + 24 * *(unsigned int *)(a5 + 24);
        long long v32 = *(_OWORD *)v28;
        *(void *)(v31 + 16) = *((void *)v28 + 2);
        *(_OWORD *)uint64_t v31 = v32;
        ++*(_DWORD *)(a5 + 24);
        BOOL v34 = v19-- != 0;
        v20 += 32;
      }
      while (a1 != a3 || v34);
    }
  }
}

uint64_t llvm::function_ref<mlir::Operation * ()(mlir::Value)>::callback_fn<anonymous namespace'::OperationConverter::legalizeConvertedArgumentTypes(mlir::ConversionPatternRewriter &,mlir::detail::ConversionPatternRewriterImpl &)::$_0>(uint64_t *a1, void *a2)
{
  uint64_t v2 = (void *)*a2;
  if (!*a2) {
    return 0;
  }
  uint64_t v3 = *a1;
  while (1)
  {
    uint64_t v8 = v2[2];
    uint64_t v9 = *(void *)(v3 + 328);
    uint64_t v10 = *(unsigned int *)(v3 + 344);
    if (!v10) {
      goto LABEL_12;
    }
    LODWORD(v11) = ((v8 >> 4) ^ (v8 >> 9)) & (v10 - 1);
    uint64_t v12 = (uint64_t *)(v9 + 16 * v11);
    uint64_t v13 = *v12;
    if (*v12 != v8)
    {
      int v14 = 1;
      while (v13 != -4096)
      {
        int v15 = v11 + v14++;
        uint64_t v11 = v15 & (v10 - 1);
        uint64_t v13 = *(void *)(v9 + 16 * v11);
        if (v13 == v8)
        {
          uint64_t v12 = (uint64_t *)(v9 + 16 * v11);
          goto LABEL_13;
        }
      }
LABEL_12:
      uint64_t v12 = (uint64_t *)(v9 + 16 * v10);
    }
LABEL_13:
    if (v12 == (uint64_t *)(v9 + 16 * v10))
    {
      uint64_t ParentOp = *(mlir::Block **)(v8 + 16);
      if (ParentOp) {
        uint64_t ParentOp = (mlir::Block *)mlir::Block::getParentOp(ParentOp);
      }
      int v17 = *(_DWORD *)(v3 + 608);
      if (!v17) {
        goto LABEL_19;
      }
      uint64_t v18 = *(void *)(v3 + 592);
      int v19 = v17 - 1;
      unsigned int v6 = ((ParentOp >> 4) ^ (ParentOp >> 9)) & v19;
      uint64_t v7 = *(mlir::Block **)(v18 + 8 * v6);
      if (v7 != ParentOp) {
        break;
      }
    }
LABEL_5:
    uint64_t v2 = (void *)*v2;
    if (!v2) {
      return 0;
    }
  }
  int v5 = 1;
  while (v7 != (mlir::Block *)-4096)
  {
    unsigned int v4 = v6 + v5++;
    unsigned int v6 = v4 & v19;
    uint64_t v7 = *(mlir::Block **)(v18 + 8 * v6);
    if (v7 == ParentOp) {
      goto LABEL_5;
    }
  }
LABEL_19:
  if (v2) {
    return v2[2];
  }
  return 0;
}

void anonymous namespace'::OperationConverter::legalizeChangedResultType(mlir::Operation *,mlir::OpResult,mlir::Value,mlir::TypeConverter const*,mlir::ConversionPatternRewriter &,mlir::detail::ConversionPatternRewriterImpl &,llvm::DenseMap<mlir::Value,llvm::SmallVector<mlir::Value,6u>,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,llvm::SmallVector<mlir::Value,6u>>> const&)::$_0::operator()(uint64_t **a1)
{
  uint64_t v67 = *MEMORY[0x263EF8340];
  uint64_t v2 = **a1;
  v44[16] = 257;
  mlir::Operation::emitError(v2, (uint64_t)v44, (uint64_t)&v45);
  if (v45)
  {
    LODWORD(v56) = 3;
    unsigned int v57 = "failed to materialize conversion for result #";
    uint64_t v58 = 45;
    uint64_t v3 = (char *)&v56;
    unsigned int v4 = (char *)__src;
    if (v49 >= HIDWORD(v49))
    {
      unint64_t v35 = v49 + 1;
      if (__src <= &v56 && (char *)__src + 24 * v49 > (char *)&v56)
      {
        int64_t v40 = (char *)&v56 - (unsigned char *)__src;
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&__src, v50, v35, 24);
        unsigned int v4 = (char *)__src;
        uint64_t v3 = (char *)__src + v40;
      }
      else
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&__src, v50, v35, 24);
        uint64_t v3 = (char *)&v56;
        unsigned int v4 = (char *)__src;
      }
    }
    int v5 = &v4[24 * v49];
    long long v6 = *(_OWORD *)v3;
    *((void *)v5 + 2) = *((void *)v3 + 2);
    *(_OWORD *)int v5 = v6;
    LODWORD(v49) = v49 + 1;
  }
  uint64_t v7 = *a1[1];
  uint64_t v8 = *(void *)(v7 + 8) & 7;
  if (v7) {
    BOOL v9 = v8 == 6;
  }
  else {
    BOOL v9 = 0;
  }
  if (v9) {
    uint64_t v8 = *(void *)(v7 + 16) + 6;
  }
  if (v45)
  {
    LODWORD(v56) = 5;
    unsigned int v57 = (const char *)v8;
    uint64_t v10 = (char *)&v56;
    uint64_t v11 = (char *)__src;
    if (v49 >= HIDWORD(v49))
    {
      unint64_t v36 = v49 + 1;
      if (__src <= &v56 && (char *)__src + 24 * v49 > (char *)&v56)
      {
        int64_t v41 = (char *)&v56 - (unsigned char *)__src;
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&__src, v50, v36, 24);
        uint64_t v11 = (char *)__src;
        uint64_t v10 = (char *)__src + v41;
      }
      else
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&__src, v50, v36, 24);
        uint64_t v10 = (char *)&v56;
        uint64_t v11 = (char *)__src;
      }
    }
    uint64_t v12 = &v11[24 * v49];
    long long v13 = *(_OWORD *)v10;
    *((void *)v12 + 2) = *((void *)v10 + 2);
    *(_OWORD *)uint64_t v12 = v13;
    uint64_t v14 = (v49 + 1);
    LODWORD(v49) = v49 + 1;
    uint64_t v15 = v45;
    if (v45)
    {
      LODWORD(v56) = 3;
      unsigned int v57 = " of operation '";
      uint64_t v58 = 15;
      uint64_t v16 = (char *)&v56;
      int v17 = (char *)__src;
      if (v14 >= HIDWORD(v49))
      {
        unint64_t v37 = v14 + 1;
        BOOL v38 = (char *)__src + 24 * v14 > (char *)&v56;
        if (__src <= &v56 && v38)
        {
          int64_t v42 = (char *)&v56 - (unsigned char *)__src;
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&__src, v50, v37, 24);
          int v17 = (char *)__src;
          uint64_t v16 = (char *)__src + v42;
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&__src, v50, v37, 24);
          uint64_t v16 = (char *)&v56;
          int v17 = (char *)__src;
        }
      }
      uint64_t v18 = &v17[24 * v49];
      long long v19 = *(_OWORD *)v16;
      *((void *)v18 + 2) = *((void *)v16 + 2);
      *(_OWORD *)uint64_t v18 = v19;
      LODWORD(v49) = v49 + 1;
      uint64_t v15 = v45;
      if (v45)
      {
        mlir::Diagnostic::operator<<((uint64_t)&v46, *(void *)(**a1 + 48));
        uint64_t v15 = v45;
        if (v45)
        {
          LODWORD(v56) = 3;
          unsigned int v57 = "' that remained live after conversion";
          uint64_t v58 = 37;
          uint64_t v20 = (char *)&v56;
          uint64_t v21 = (char *)__src;
          if (v49 >= HIDWORD(v49))
          {
            unint64_t v39 = v49 + 1;
            if (__src <= &v56 && (char *)__src + 24 * v49 > (char *)&v56)
            {
              int64_t v43 = (char *)&v56 - (unsigned char *)__src;
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&__src, v50, v39, 24);
              uint64_t v21 = (char *)__src;
              uint64_t v20 = (char *)__src + v43;
            }
            else
            {
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&__src, v50, v39, 24);
              uint64_t v20 = (char *)&v56;
              uint64_t v21 = (char *)__src;
            }
          }
          size_t v22 = &v21[24 * v49];
          long long v23 = *(_OWORD *)v20;
          *((void *)v22 + 2) = *((void *)v20 + 2);
          *(_OWORD *)size_t v22 = v23;
          LODWORD(v49) = v49 + 1;
          uint64_t v15 = v45;
        }
      }
    }
  }
  else
  {
    uint64_t v15 = 0;
  }
  uint64_t v56 = v15;
  LOBYTE(v57) = 0;
  char v66 = 0;
  if (!v55)
  {
LABEL_35:
    mlir::InFlightDiagnostic::abandon(&v45);
    if (v45) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v45);
    }
    if (v55)
    {
      long long v27 = (void *)__p;
      if ((void)__p)
      {
        uint64_t v28 = (void *)*((void *)&__p + 1);
        uint64_t v29 = (void *)__p;
        if (*((void *)&__p + 1) != (void)__p)
        {
          do
            uint64_t v28 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v28 - 1);
          while (v28 != v27);
          uint64_t v29 = (void *)__p;
        }
        *((void *)&__p + 1) = v27;
        operator delete(v29);
      }
      unint64_t v30 = (void *)v51;
      if ((void)v51)
      {
        uint64_t v31 = (void *)*((void *)&v51 + 1);
        long long v32 = (void *)v51;
        if (*((void *)&v51 + 1) != (void)v51)
        {
          do
          {
            uint64_t v34 = *--v31;
            uint64_t v33 = v34;
            void *v31 = 0;
            if (v34) {
              MEMORY[0x21667D390](v33, 0x1000C8077774924);
            }
          }
          while (v31 != v30);
          long long v32 = (void *)v51;
        }
        *((void *)&v51 + 1) = v30;
        operator delete(v32);
      }
      if (__src != v50) {
        free(__src);
      }
    }
    mlir::Diagnostic::attachNote();
  }
  unsigned int v57 = v46;
  int v24 = v49;
  LODWORD(v58) = v47;
  __dst = v61;
  uint64_t v60 = 0x400000000;
  if (!v49)
  {
    int v25 = 1;
    goto LABEL_31;
  }
  if (__src != v50)
  {
    __dst = __src;
    uint64_t v60 = v49;
    uint64_t __src = v50;
    HIDWORD(v49) = 0;
    int v25 = 1;
LABEL_30:
    LODWORD(v49) = 0;
LABEL_31:
    long long v62 = v51;
    long long v51 = 0uLL;
    long long v64 = __p;
    uint64_t v63 = v52;
    uint64_t v65 = v54;
    uint64_t v52 = 0;
    long long __p = 0uLL;
    uint64_t v54 = 0;
    char v66 = 1;
    if (v25)
    {
      if (__src != v50) {
        free(__src);
      }
      unsigned __int8 v55 = 0;
    }
    goto LABEL_35;
  }
  if (v49 < 5)
  {
    uint64_t v26 = v49;
  }
  else
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&__dst, v61, v49, 24);
    uint64_t v26 = v49;
    if (!v49) {
      goto LABEL_29;
    }
  }
  memcpy(__dst, __src, 24 * v26);
LABEL_29:
  LODWORD(v60) = v24;
  int v25 = v55;
  goto LABEL_30;
}

BOOL llvm::function_ref<BOOL ()(mlir::OpOperand &)>::callback_fn<mlir::detail::ConversionPatternRewriterImpl::applyRewrites(void)::$_0>(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = *(mlir::Operation **)(a2 + 16);
  return *((void *)v2 + 2) != **(void **)a1 || mlir::Operation::isBeforeInBlock(**(mlir::Block ****)(a1 + 8), v2);
}

void llvm::function_ref<void ()(mlir::Operation *)>::callback_fn<mlir::detail::ConversionPatternRewriterImpl::markNestedOpsIgnored(mlir::Operation *)::$_0>(int64x2_t **a1, uint64_t a2)
{
  uint64_t v2 = *a1;
  uint64_t v10 = a2;
  unint64_t v3 = *(unsigned int *)(a2 + 44);
  uint64_t v4 = v3 & 0x7FFFFF;
  if ((v3 & 0x7FFFFF) != 0)
  {
    int v5 = (void *)(((a2 + 16 * ((v3 >> 23) & 1) + ((v3 >> 21) & 0x7F8) + 71) & 0xFFFFFFFFFFFFFFF8)
                  + 32 * *(unsigned int *)(a2 + 40));
    uint64_t v6 = 24 * v4;
    while (v5 == (void *)*v5)
    {
      v5 += 3;
      v6 -= 24;
      if (!v6) {
        return;
      }
    }
    llvm::DenseMapBase<llvm::DenseMap<mlir::Block *,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::Block *,void>,llvm::detail::DenseSetPair<mlir::Block *>>,mlir::Block *,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::Block *,void>,llvm::detail::DenseSetPair<mlir::Block *>>::try_emplace<llvm::detail::DenseSetEmpty&>(v2 + 37, &v10, (uint64_t)v11);
    if (v11[16])
    {
      uint64_t v7 = v10;
      uint64_t v8 = v2[39].u32[0];
      if (v8 >= v2[39].i32[1])
      {
        uint64_t v9 = v10;
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v2[38].i64[1], &v2[39].u64[1], v8 + 1, 8);
        uint64_t v7 = v9;
        LODWORD(v8) = v2[39].i32[0];
      }
      *(void *)(v2[38].i64[1] + 8 * v8) = v7;
      ++v2[39].i32[0];
    }
  }
}

void mlir::detail::ConversionPatternRewriterImpl::~ConversionPatternRewriterImpl(mlir::detail::ConversionPatternRewriterImpl *this)
{
  uint64_t v2 = (char *)*((void *)this + 149);
  if (v2 != (char *)this + 1208) {
    free(v2);
  }
  unint64_t v3 = (void **)((char *)this + 632);
  uint64_t v4 = (char *)*((void *)this + 79);
  uint64_t v5 = *((unsigned int *)this + 160);
  if (v5)
  {
    uint64_t v6 = 136 * v5;
    do
    {
      uint64_t v7 = &v4[v6];
      uint64_t v8 = *(char **)&v4[v6 - 32];
      if (&v4[v6 - 16] != v8) {
        free(v8);
      }
      uint64_t v9 = (char *)*((void *)v7 - 14);
      if (v7 - 96 != v9) {
        free(v9);
      }
      v6 -= 136;
    }
    while (v6);
    uint64_t v4 = (char *)*v3;
  }
  if (v4 != (char *)this + 648) {
    free(v4);
  }
  uint64_t v10 = (void **)*((void *)this + 77);
  if (v10 != v3) {
    free(v10);
  }
  llvm::deallocate_buffer(*((llvm **)this + 74), (void *)(8 * *((unsigned int *)this + 152)));
}

void sub_2118FBF88()
{
  llvm::deallocate_buffer(*(llvm **)(v0 + 48), (void *)(16 * *(unsigned int *)(v0 + 64)));
}

void sub_2118FBF9C()
{
  llvm::deallocate_buffer(*(llvm **)(v0 + 24), (void *)(16 * *(unsigned int *)(v0 + 40)));
}

void sub_2118FBFB0()
{
  llvm::deallocate_buffer(*(llvm **)v0, (void *)(16 * *(unsigned int *)(v0 + 16)));
}

uint64_t sub_2118FBFC4()
{
  return v0;
}

void llvm::df_iterator<mlir::Block *,llvm::df_iterator_default_set<mlir::Block *,8u>,false,llvm::GraphTraits<mlir::Block *>>::toNext(uint64_t a1)
{
  uint64_t v2 = *(void *)(a1 + 104);
  while (2)
  {
    unint64_t v3 = *(mlir::Block **)(v2 - 32);
    if (!*(unsigned char *)(v2 - 8))
    {
      mlir::SuccessorRange::SuccessorRange((mlir::SuccessorRange *)v27, *(mlir::Block **)(v2 - 32));
      *(void *)(v2 - 24) = v27[0];
      *(void *)(v2 - 16) = 0;
      *(unsigned char *)(v2 - 8) = 1;
    }
    while (1)
    {
      mlir::SuccessorRange::SuccessorRange((mlir::SuccessorRange *)v27, v3);
      uint64_t v6 = *(void *)(v2 - 24);
      uint64_t v7 = *(void *)(v2 - 16);
      if (v6 == v27[0] && v7 == v27[1]) {
        break;
      }
      *(void *)(v2 - 16) = v7 + 1;
      uint64_t v9 = *(const void **)(v6 + 32 * v7 + 24);
      uint64_t v10 = *(void *)(a1 + 8);
      if (v10 != *(void *)a1) {
        goto LABEL_4;
      }
      uint64_t v11 = *(unsigned int *)(a1 + 20);
      if (v11)
      {
        uint64_t v12 = 0;
        uint64_t v13 = 8 * v11;
        uint64_t v14 = *(void **)(a1 + 8);
        do
        {
          if ((const void *)*v14 == v9)
          {
            int v5 = 0;
            goto LABEL_5;
          }
          if (*v14 == -2) {
            uint64_t v12 = v14;
          }
          ++v14;
          v13 -= 8;
        }
        while (v13);
        if (!v12) {
          goto LABEL_19;
        }
        *uint64_t v12 = v9;
        --*(_DWORD *)(a1 + 24);
        int v5 = 1;
        goto LABEL_5;
      }
LABEL_19:
      if (v11 < *(_DWORD *)(a1 + 16))
      {
        *(_DWORD *)(a1 + 20) = v11 + 1;
        *(void *)(v10 + 8 * v11) = v9;
        int v5 = 1;
      }
      else
      {
LABEL_4:
        llvm::SmallPtrSetImplBase::insert_imp_big((llvm::SmallPtrSetImplBase *)a1, v9);
        int v5 = v4;
      }
LABEL_5:
      if (v5)
      {
        int v17 = *(unsigned char **)(a1 + 104);
        unint64_t v16 = *(void *)(a1 + 112);
        if ((unint64_t)v17 >= v16)
        {
          long long v19 = *(unsigned char **)(a1 + 96);
          uint64_t v20 = (v17 - v19) >> 5;
          unint64_t v21 = v20 + 1;
          if ((unint64_t)(v20 + 1) >> 59) {
            abort();
          }
          uint64_t v22 = v16 - (void)v19;
          if (v22 >> 4 > v21) {
            unint64_t v21 = v22 >> 4;
          }
          if ((unint64_t)v22 >= 0x7FFFFFFFFFFFFFE0) {
            unint64_t v23 = 0x7FFFFFFFFFFFFFFLL;
          }
          else {
            unint64_t v23 = v21;
          }
          if (v23)
          {
            if (v23 >> 59) {
              std::__throw_bad_array_new_length[abi:nn180100]();
            }
            int v24 = (char *)operator new(32 * v23);
          }
          else
          {
            int v24 = 0;
          }
          int v25 = &v24[32 * v20];
          *(void *)int v25 = v9;
          v25[8] = 0;
          v25[24] = 0;
          uint64_t v18 = v25 + 32;
          if (v17 != v19)
          {
            do
            {
              long long v26 = *((_OWORD *)v17 - 1);
              *((_OWORD *)v25 - 2) = *((_OWORD *)v17 - 2);
              *((_OWORD *)v25 - 1) = v26;
              v25 -= 32;
              v17 -= 32;
            }
            while (v17 != v19);
            int v17 = *(unsigned char **)(a1 + 96);
          }
          *(void *)(a1 + 96) = v25;
          *(void *)(a1 + 104) = v18;
          *(void *)(a1 + 112) = &v24[32 * v23];
          if (v17) {
            operator delete(v17);
          }
        }
        else
        {
          *(void *)int v17 = v9;
          void v17[8] = 0;
          uint64_t v18 = v17 + 32;
          v17[24] = 0;
        }
        *(void *)(a1 + 104) = v18;
        return;
      }
    }
    uint64_t v15 = *(void *)(a1 + 96);
    uint64_t v2 = *(void *)(a1 + 104) - 32;
    *(void *)(a1 + 104) = v2;
    if (v15 != v2) {
      continue;
    }
    break;
  }
}

void mlir::detail::walk<mlir::ForwardDominanceIterator<false>>(mlir::ForwardIterator *a1, mlir::Operation *a2, uint64_t a3, int a4)
{
  if (!a4)
  {
    ((void (*)(uint64_t, mlir::ForwardIterator *))a2)(a3, a1);
    unint64_t v30 = a1;
    uint64_t Iterable = mlir::ForwardIterator::makeIterable(a1, v10);
    if (!v9) {
      goto LABEL_46;
    }
    goto LABEL_5;
  }
  unint64_t v30 = a1;
  uint64_t Iterable = mlir::ForwardIterator::makeIterable(a1, a2);
  if (v9)
  {
LABEL_5:
    uint64_t v11 = (void *)Iterable;
    uint64_t v31 = (void *)(Iterable + 24 * v9);
    do
    {
      mlir::ForwardDominanceIterator<false>::makeIterable(v11, (uint64_t)&v44);
      llvm::SmallPtrSetImplBase::SmallPtrSetImplBase((llvm::SmallPtrSetImplBase *)&v38, &v40, (const llvm::SmallPtrSetImplBase *)&v44);
      long long __p = 0;
      int64_t v42 = 0;
      int64_t v43 = 0;
      uint64_t v12 = v46;
      uint64_t v13 = v47 - (unsigned char *)v46;
      if (v47 != v46)
      {
        if (v13 < 0) {
          goto LABEL_49;
        }
        uint64_t v14 = (char *)operator new(v47 - (unsigned char *)v46);
        long long __p = v14;
        int64_t v42 = v14;
        int64_t v43 = &v14[32 * (v13 >> 5)];
        size_t v15 = v13 & 0xFFFFFFFFFFFFFFE0;
        memcpy(v14, v12, v15);
        int64_t v42 = &v14[v15];
      }
      llvm::SmallPtrSetImplBase::SmallPtrSetImplBase((llvm::SmallPtrSetImplBase *)&v32, &v34, (const llvm::SmallPtrSetImplBase *)&v48);
      unint64_t v35 = 0;
      unint64_t v36 = 0;
      unint64_t v37 = 0;
      unint64_t v16 = v50;
      uint64_t v17 = v51 - (unsigned char *)v50;
      if (v51 != v50)
      {
        if ((v17 & 0x8000000000000000) == 0)
        {
          uint64_t v18 = (char *)operator new(v51 - (unsigned char *)v50);
          unint64_t v35 = v18;
          unint64_t v36 = v18;
          unint64_t v37 = &v18[32 * (v17 >> 5)];
          size_t v19 = v17 & 0xFFFFFFFFFFFFFFE0;
          memcpy(v18, v16, v19);
          uint64_t i = &v18[v19];
          unint64_t v36 = &v18[v19];
          goto LABEL_15;
        }
LABEL_49:
        abort();
      }
      uint64_t v18 = 0;
      for (uint64_t i = 0; ; uint64_t i = v36)
      {
LABEL_15:
        if (v42 - (unsigned char *)__p != i - v18) {
          goto LABEL_27;
        }
        if (__p == v42) {
          break;
        }
        unint64_t v21 = v18 + 16;
        uint64_t v22 = (char *)__p + 16;
        while (1)
        {
          unint64_t v23 = v22 - 16;
          if (*((void *)v22 - 2) != *((void *)v21 - 2)) {
            break;
          }
          int v24 = v21[8];
          if (v22[8]) {
            BOOL v25 = v24 == 0;
          }
          else {
            BOOL v25 = 1;
          }
          if (v25)
          {
            if ((v22[8] != 0) != (v24 != 0)) {
              break;
            }
          }
          else if (*((void *)v22 - 1) != *((void *)v21 - 1) || *(void *)v22 != *(void *)v21)
          {
            break;
          }
          v21 += 32;
          v22 += 32;
          if (v23 + 32 == v42) {
            goto LABEL_30;
          }
        }
LABEL_27:
        uint64_t v26 = *((void *)v42 - 4);
        long long v27 = (ZinIrHalH13g *)(v26 + 32);
        uint64_t v28 = *(ZinIrHalH13g **)(v26 + 40);
        if (v28 != (ZinIrHalH13g *)(v26 + 32))
        {
          do
          {
            uint64_t v29 = (ZinIrHalH13g *)*((void *)v28 + 1);
            ZinIrHalH13g::~ZinIrHalH13g(v28);
            mlir::detail::walk<mlir::ForwardDominanceIterator<false>>();
            uint64_t v28 = v29;
          }
          while (v29 != v27);
        }
        llvm::df_iterator<mlir::Block *,llvm::df_iterator_default_set<mlir::Block *,8u>,false,llvm::GraphTraits<mlir::Block *>>::toNext((uint64_t)&v38);
        uint64_t v18 = v35;
      }
LABEL_30:
      if (v18)
      {
        unint64_t v36 = v18;
        operator delete(v18);
      }
      if (v33 != v32) {
        free(v33);
      }
      if (__p)
      {
        int64_t v42 = (char *)__p;
        operator delete(__p);
      }
      if (v39 != v38) {
        free(v39);
      }
      if (v50)
      {
        long long v51 = v50;
        operator delete(v50);
      }
      if (v49 != v48) {
        free(v49);
      }
      if (v46)
      {
        uint64_t v47 = v46;
        operator delete(v46);
      }
      if (v45 != v44) {
        free(v45);
      }
      v11 += 3;
    }
    while (v11 != v31);
  }
LABEL_46:
  if (a4 == 1) {
    ((void (*)(uint64_t, mlir::ForwardIterator *))a2)(a3, v30);
  }
}

void llvm::function_ref<void ()(mlir::Operation *)>::callback_fn<mlir::ConversionPatternRewriter::cloneRegionBefore(mlir::Region &,mlir::Region &,llvm::ilist_iterator<llvm::ilist_detail::node_options<mlir::Block,false,false,void,false>,false,false>,mlir::IRMapping &)::$_0>(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = *(void *)(*(void *)a1 + 56);
  uint64_t v4 = *(unsigned int *)(v3 + 208);
  if (v4 >= *(_DWORD *)(v3 + 212))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod(v3 + 200, (void *)(v3 + 216), v4 + 1, 8);
    LODWORD(v4) = *(_DWORD *)(v3 + 208);
  }
  *(void *)(*(void *)(v3 + 200) + 8 * v4) = a2;
  ++*(_DWORD *)(v3 + 208);
}

_anonymous_namespace_::OperationTransactionState *anonymous namespace'::OperationTransactionState::OperationTransactionState(_anonymous_namespace_::OperationTransactionState *this, mlir::Operation *a2)
{
  *(void *)this = a2;
  *((void *)this + 1) = *((void *)a2 + 3);
  *((void *)this + 2) = mlir::Operation::getAttrDictionary(a2);
  if ((*((unsigned char *)a2 + 46) & 0x80) == 0)
  {
    LODWORD(v5) = 0;
    int v21 = 0;
    *((void *)this + 3) = (char *)this + 40;
    *((_DWORD *)this + 9) = 8;
    goto LABEL_21;
  }
  uint64_t v4 = *((void *)a2 + 9);
  unint64_t v5 = *((unsigned int *)a2 + 17);
  *((void *)this + 3) = (char *)this + 40;
  *((void *)this + 4) = 0x800000000;
  if (v5 < 9)
  {
    if (!v5)
    {
      int v21 = 0;
      goto LABEL_21;
    }
    uint64_t v8 = (void *)((char *)this + 40);
  }
  else
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)this + 24, (char *)this + 40, v5, 8);
    uint64_t v6 = *((unsigned int *)this + 8);
    uint64_t v7 = *((void *)this + 3);
    uint64_t v8 = (void *)(v7 + 8 * v6);
    if (v5 >= 0xD && ((unint64_t)v8 >= v4 + 32 * v5 || v4 + 24 >= v7 + 8 * (v6 + v5)))
    {
      uint64_t v10 = v5 & 3;
      if ((v5 & 3) == 0) {
        uint64_t v10 = 4;
      }
      unint64_t v11 = v5 - v10;
      v8 += v11;
      uint64_t v12 = (const double *)(v4 + 88);
      uint64_t v13 = (unsigned long long *)(v7 + 8 * v6 + 16);
      unint64_t v14 = v11;
      do
      {
        size_t v15 = v12 - 8;
        unsigned long long v16 = (unsigned __int128)vld4q_f64(v15);
        unsigned long long v17 = (unsigned __int128)vld4q_f64(v12);
        *(v13 - 1) = v16;
        *uint64_t v13 = v17;
        v12 += 16;
        v13 += 2;
        v14 -= 4;
      }
      while (v14);
      goto LABEL_18;
    }
  }
  unint64_t v11 = 0;
LABEL_18:
  unint64_t v18 = v5 - v11;
  size_t v19 = (uint64_t *)(v4 + 32 * v11 + 24);
  do
  {
    uint64_t v20 = *v19;
    v19 += 4;
    *v8++ = v20;
    --v18;
  }
  while (v18);
  int v21 = *((_DWORD *)this + 8);
LABEL_21:
  *((_DWORD *)this + 8) = v21 + v5;
  mlir::SuccessorRange::SuccessorRange(v41, a2);
  unint64_t v22 = v41[0];
  mlir::SuccessorRange::SuccessorRange(v41, a2);
  unint64_t v24 = v41[0];
  unint64_t v23 = v41[1];
  BOOL v25 = (unsigned long long *)((char *)this + 120);
  *((void *)this + 13) = (char *)this + 120;
  *((void *)this + 14) = 0x200000000;
  if (v23 < 3)
  {
    if (!v23 && v22 == v24)
    {
      LODWORD(v26) = 0;
      goto LABEL_43;
    }
    if (v22 == v24)
    {
      LODWORD(v26) = 0;
      goto LABEL_35;
    }
LABEL_29:
    for (uint64_t i = (uint64_t *)(v22 + 24); ; i += 4)
    {
      uint64_t v28 = *i;
      *(void *)BOOL v25 = v28;
      BOOL v25 = (unsigned long long *)((char *)v25 + 8);
    }
  }
  llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)this + 104, v25, v23, 8);
  uint64_t v26 = *((unsigned int *)this + 28);
  BOOL v25 = (unsigned long long *)(*((void *)this + 13) + 8 * v26);
  if (v22 != v24) {
    goto LABEL_29;
  }
  if (v23 > 0xA && ((unint64_t)v25 >= v22 + 32 * v23 || v22 + 24 >= (unint64_t)v25 + 8 * v23))
  {
    uint64_t v30 = v23 & 3;
    if ((v23 & 3) == 0) {
      uint64_t v30 = 4;
    }
    unint64_t v29 = v23 - v30;
    uint64_t v31 = (const double *)(v22 + 88);
    long long v32 = v25 + 1;
    unint64_t v33 = v29;
    do
    {
      uint64_t v34 = v31 - 8;
      unsigned long long v35 = (unsigned __int128)vld4q_f64(v34);
      unsigned long long v36 = (unsigned __int128)vld4q_f64(v31);
      *(v32 - 1) = v35;
      *long long v32 = v36;
      v31 += 16;
      v32 += 2;
      v33 -= 4;
    }
    while (v33);
    BOOL v25 = (unsigned long long *)((char *)v25 + 8 * v29);
    goto LABEL_41;
  }
LABEL_35:
  unint64_t v29 = 0;
LABEL_41:
  unint64_t v37 = v23 - v29;
  BOOL v38 = (uint64_t *)(v22 + 32 * v29 + 24);
  do
  {
    uint64_t v39 = *v38;
    v38 += 4;
    *(void *)BOOL v25 = v39;
    BOOL v25 = (unsigned long long *)((char *)v25 + 8);
    --v37;
  }
  while (v37);
LABEL_43:
  *((_DWORD *)this + 28) = v26 + v23;
  return this;
}

uint64_t *llvm::DenseMapBase<llvm::DenseMap<mlir::Type,llvm::SmallVector<mlir::Type,2u>,llvm::DenseMapInfo<mlir::Type,void>,llvm::detail::DenseMapPair<mlir::Type,llvm::SmallVector<mlir::Type,2u>>>,mlir::Type,llvm::SmallVector<mlir::Type,2u>,llvm::DenseMapInfo<mlir::Type,void>,llvm::detail::DenseMapPair<mlir::Type,llvm::SmallVector<mlir::Type,2u>>>::InsertIntoBucket<mlir::Type const&,llvm::SmallVector<mlir::Type,2u>>(uint64_t a1, uint64_t *a2, uint64_t *a3, uint64_t a4)
{
  int v7 = *(_DWORD *)(a1 + 8);
  uint64_t v8 = *(unsigned int *)(a1 + 16);
  if (4 * v7 + 4 >= (3 * v8))
  {
    int v12 = 2 * v8;
  }
  else
  {
    if ((int)v8 + ~v7 - *(_DWORD *)(a1 + 12) > v8 >> 3)
    {
LABEL_3:
      uint64_t v10 = *a2;
      goto LABEL_4;
    }
    int v12 = *(_DWORD *)(a1 + 16);
  }
  uint64_t v13 = *(uint64_t **)a1;
  unint64_t v14 = (v12 - 1) | ((unint64_t)(v12 - 1) >> 1);
  unint64_t v15 = v14 | (v14 >> 2) | ((v14 | (v14 >> 2)) >> 4);
  int v16 = ((v15 | (v15 >> 8)) >> 16) | v15 | (v15 >> 8);
  if ((v16 + 1) > 0x40) {
    unsigned int v17 = v16 + 1;
  }
  else {
    unsigned int v17 = 64;
  }
  *(_DWORD *)(a1 + 16) = v17;
  buffer = llvm::allocate_buffer(40 * v17, (std::align_val_t)8uLL);
  *(void *)a1 = buffer;
  if (v13)
  {
    uint64_t v19 = 5 * v8;
    llvm::DenseMapBase<llvm::DenseMap<mlir::OperationName,llvm::SmallVector<mlir::RewritePattern const*,2u>,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,llvm::SmallVector<mlir::RewritePattern const*,2u>>>,mlir::OperationName,llvm::SmallVector<mlir::RewritePattern const*,2u>,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,llvm::SmallVector<mlir::RewritePattern const*,2u>>>::moveFromOldBuckets(a1, v13, &v13[v19]);
    llvm::deallocate_buffer((llvm *)v13, (void *)(v19 * 8));
  }
  *(void *)(a1 + 8) = 0;
  uint64_t v20 = *(unsigned int *)(a1 + 16);
  unint64_t v21 = 40 * v20 - 40;
  unint64_t v22 = buffer;
  if (v21 < 0x28) {
    goto LABEL_36;
  }
  unint64_t v23 = v21 / 0x28 + 1;
  unint64_t v22 = &buffer[5 * (v23 & 0xFFFFFFFFFFFFFFELL)];
  uint64_t v24 = v23 & 0xFFFFFFFFFFFFFFELL;
  BOOL v25 = buffer;
  do
  {
    void *v25 = -4096;
    void v25[5] = -4096;
    v25 += 10;
    v24 -= 2;
  }
  while (v24);
  if (v23 != (v23 & 0xFFFFFFFFFFFFFFELL))
  {
LABEL_36:
    do
    {
      *unint64_t v22 = -4096;
      v22 += 5;
    }
    while (v22 != &buffer[5 * v20]);
  }
  uint64_t v10 = *a3;
  int v26 = v20 - 1;
  unsigned int v27 = ((*a3 >> 4) ^ (*a3 >> 9)) & v26;
  a2 = &buffer[5 * v27];
  uint64_t v28 = *a2;
  if (*a3 != *a2)
  {
    unint64_t v29 = 0;
    int v30 = 1;
    while (v28 != -4096)
    {
      if (v29) {
        BOOL v31 = 0;
      }
      else {
        BOOL v31 = v28 == -8192;
      }
      if (v31) {
        unint64_t v29 = a2;
      }
      unsigned int v32 = v27 + v30++;
      unsigned int v27 = v32 & v26;
      a2 = &buffer[5 * v27];
      uint64_t v28 = *a2;
      if (v10 == *a2) {
        goto LABEL_4;
      }
    }
    if (v29) {
      a2 = v29;
    }
    goto LABEL_3;
  }
LABEL_4:
  ++*(_DWORD *)(a1 + 8);
  if (v10 != -4096) {
    --*(_DWORD *)(a1 + 12);
  }
  *a2 = *a3;
  a2[1] = (uint64_t)(a2 + 3);
  a2[2] = 0x200000000;
  if (*(_DWORD *)(a4 + 8)) {
    llvm::SmallVectorImpl<llvm::SMLoc>::operator=((uint64_t)(a2 + 1), a4);
  }
  return a2;
}

BOOL _ZNSt3__16all_ofB8nn180100IN4mlir17ValueTypeIteratorIN4llvm6detail27indexed_accessor_range_baseINS1_12OperandRangeEPNS1_9OpOperandENS1_5ValueES9_S9_E8iteratorEEEZNKS1_13TypeConverter7isLegalINS1_14ValueTypeRangeIS6_EEEENS_9enable_ifIXaantsr3std14is_convertibleIT_NS1_4TypeEEE5valuentsr3std14is_convertibleISI_PNS1_9OperationEEE5valueEbE4typeEOSI_EUlSJ_E_EEbSI_SI_T0_(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  v25[1] = *MEMORY[0x263EF8340];
  if (a1 == a3 && a2 == a4) {
    return 1;
  }
  if (a1 == a3)
  {
    uint64_t v9 = ~a2 + a4;
    uint64_t v10 = a1 + 32 * a2 + 24;
    while (1)
    {
      unint64_t v11 = (void *)(*(void *)(*(void *)v10 + 8) & 0xFFFFFFFFFFFFFFF8);
      unint64_t v23 = v25;
      uint64_t v24 = 0x100000000;
      if (!mlir::TypeConverter::convertType(a5, v11, (uint64_t)&v23) || v24 != 1) {
        break;
      }
      uint64_t v13 = *(void **)v23;
      if (v23 != v25) {
        goto LABEL_13;
      }
LABEL_14:
      BOOL v15 = v9-- != 0;
      BOOL result = v13 == v11;
      if (v13 == v11)
      {
        v10 += 32;
        if (v15) {
          continue;
        }
      }
      return result;
    }
    uint64_t v13 = 0;
    if (v23 == v25) {
      goto LABEL_14;
    }
LABEL_13:
    free(v23);
    goto LABEL_14;
  }
  int v16 = (void *)(*(void *)(*(void *)(a1 + 32 * a2 + 24) + 8) & 0xFFFFFFFFFFFFFFF8);
  unint64_t v23 = v25;
  uint64_t v24 = 0x100000000;
  if (mlir::TypeConverter::convertType(a5, v16, (uint64_t)&v23) && v24 == 1)
  {
    unint64_t v18 = *(void **)v23;
    if (v23 == v25) {
      goto LABEL_28;
    }
    goto LABEL_27;
  }
  unint64_t v18 = 0;
  if (v23 != v25) {
LABEL_27:
  }
    free(v23);
LABEL_28:
  if (v18 == v16)
  {
    for (uint64_t i = a1 + 32 * a2 + 56; ; i += 32)
    {
      uint64_t v20 = (void *)(*(void *)(*(void *)i + 8) & 0xFFFFFFFFFFFFFFF8);
      unint64_t v23 = v25;
      uint64_t v24 = 0x100000000;
      if (!mlir::TypeConverter::convertType(a5, v20, (uint64_t)&v23) || v24 != 1) {
        break;
      }
      unint64_t v22 = *(void **)v23;
      if (v23 != v25) {
        goto LABEL_40;
      }
LABEL_32:
      if (v22 != v20) {
        return 0;
      }
    }
    unint64_t v22 = 0;
    if (v23 == v25) {
      goto LABEL_32;
    }
LABEL_40:
    free(v23);
    goto LABEL_32;
  }
  return 0;
}

BOOL _ZNSt3__16all_ofB8nn180100IN4mlir17ValueTypeIteratorIN4llvm6detail27indexed_accessor_range_baseINS1_11ResultRangeEPNS1_6detail12OpResultImplENS1_8OpResultESA_SA_E8iteratorEEEZNKS1_13TypeConverter7isLegalINS1_14ValueTypeRangeIS6_EEEENS_9enable_ifIXaantsr3std14is_convertibleIT_NS1_4TypeEEE5valuentsr3std14is_convertibleISJ_PNS1_9OperationEEE5valueEbE4typeEOSJ_EUlSK_E_EEbSJ_SJ_T0_(mlir::detail::OpResultImpl *this, uint64_t a2, mlir::detail::OpResultImpl *a3, uint64_t a4, uint64_t a5)
{
  uint64_t v6 = a2;
  v23[1] = *MEMORY[0x263EF8340];
  if (this == a3 && a2 == a4) {
    return 1;
  }
  if (this == a3)
  {
    uint64_t v9 = a4 - 1;
    while (1)
    {
      unint64_t v11 = (void *)(*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset((uint64_t)this, v6) + 8) & 0xFFFFFFFFFFFFFFF8);
      unint64_t v21 = v23;
      uint64_t v22 = 0x100000000;
      if (!mlir::TypeConverter::convertType(a5, v11, (uint64_t)&v21) || v22 != 1) {
        break;
      }
      uint64_t v13 = *(void **)v21;
      if (v21 != v23) {
        goto LABEL_17;
      }
LABEL_6:
      BOOL result = v13 == v11;
      if (v13 != v11 || v9 == v6++) {
        return result;
      }
    }
    uint64_t v13 = 0;
    if (v21 == v23) {
      goto LABEL_6;
    }
LABEL_17:
    free(v21);
    goto LABEL_6;
  }
  unint64_t v14 = (void *)(*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset((uint64_t)this, a2) + 8) & 0xFFFFFFFFFFFFFFF8);
  unint64_t v21 = v23;
  uint64_t v22 = 0x100000000;
  if (mlir::TypeConverter::convertType(a5, v14, (uint64_t)&v21) && v22 == 1)
  {
    int v16 = *(void **)v21;
    if (v21 == v23) {
      goto LABEL_26;
    }
    goto LABEL_25;
  }
  int v16 = 0;
  if (v21 != v23) {
LABEL_25:
  }
    free(v21);
LABEL_26:
  if (v16 == v14)
  {
    for (uint64_t i = v6 + 1; ; ++i)
    {
      unint64_t v18 = (void *)(*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset((uint64_t)this, i) + 8) & 0xFFFFFFFFFFFFFFF8);
      unint64_t v21 = v23;
      uint64_t v22 = 0x100000000;
      if (!mlir::TypeConverter::convertType(a5, v18, (uint64_t)&v21) || v22 != 1) {
        break;
      }
      uint64_t v20 = *(void **)v21;
      if (v21 != v23) {
        goto LABEL_38;
      }
LABEL_30:
      if (v20 != v18) {
        return 0;
      }
    }
    uint64_t v20 = 0;
    if (v21 == v23) {
      goto LABEL_30;
    }
LABEL_38:
    free(v21);
    goto LABEL_30;
  }
  return 0;
}

void anonymous namespace'::FunctionOpInterfaceSignatureConversion::~FunctionOpInterfaceSignatureConversion(_anonymous_namespace_::FunctionOpInterfaceSignatureConversion *this)
{
  uint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  uint64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }
}

{
  char *v2;
  char *v3;
  uint64_t vars8;

  uint64_t v2 = (char *)*((void *)this + 10);
  if (v2 != (char *)this + 96) {
    free(v2);
  }
  uint64_t v3 = (char *)*((void *)this + 4);
  if (v3 != (char *)this + 48) {
    free(v3);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t anonymous namespace'::FunctionOpInterfaceSignatureConversion::matchAndRewrite(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, void *a5)
{
  uint64_t v6 = a2;
  if (a2)
  {
    uint64_t v8 = *(void *)(a2 + 48);
    uint64_t v9 = *(void **)(v8 + 16);
    BOOL v10 = v9 == &mlir::detail::TypeIDResolver<void,void>::id;
    if (v9 == &mlir::detail::TypeIDResolver<void,void>::id) {
      uint64_t v11 = 0;
    }
    else {
      uint64_t v11 = *(void *)(a2 + 48);
    }
    if (v10)
    {
      uint64_t v16 = *(void *)(v8 + 8);
      uint64_t Values = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)&v16);
      if (!Values)
      {
        a2 = 0;
        return convertFuncOpTypes(v6, a2, *(void *)(a1 + 96), a5);
      }
      uint64_t v14 = v8;
      goto LABEL_10;
    }
    unint64_t v12 = v11 | v8 & 0xFFFFFFFFFFFFFF00;
    a2 = mlir::detail::InterfaceMap::lookup<mlir::FunctionOpInterface>(v12 + 32);
    if (!a2)
    {
      uint64_t Values = *(void *)(v12 + 24);
      uint64_t v14 = *(void *)(v6 + 48);
LABEL_10:
      a2 = mlir::Dialect::getRegisteredInterfaceForOp<mlir::FunctionOpInterface>(Values, v14);
    }
  }
  return convertFuncOpTypes(v6, a2, *(void *)(a1 + 96), a5);
}

uint64_t convertFuncOpTypes(uint64_t a1, uint64_t a2, uint64_t a3, void *a4)
{
  v58[4] = *MEMORY[0x263EF8340];
  uint64_t v42 = a1;
  uint64_t v43 = a2;
  uint64_t canMapOperands = mlir::MemoryMapperInterface::canMapOperands((mlir::MemoryMapperInterface *)&v42);
  if (*(_UNKNOWN **)(*(void *)canMapOperands + 136) == &mlir::detail::TypeIDResolver<mlir::FunctionType,void>::id) {
    uint64_t v7 = canMapOperands;
  }
  else {
    uint64_t v7 = 0;
  }
  uint64_t v41 = v7;
  if (!v7) {
    return 0;
  }
  unsigned int Kind = mlir::AffineExpr::getKind((mlir::AffineExpr *)&v41);
  unint64_t v53 = v55;
  uint64_t v54 = 0x400000000;
  if (Kind)
  {
    unsigned int v9 = Kind;
    uint64_t v10 = Kind;
    if (Kind < 5)
    {
      uint64_t v11 = 0;
      unint64_t v12 = v55;
    }
    else
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v53, v55, Kind, 32);
      uint64_t v11 = v54;
      unint64_t v12 = v53;
      if (v54 == v10)
      {
LABEL_17:
        LODWORD(v54) = v9;
        goto LABEL_18;
      }
    }
    uint64_t v14 = 32 * v11;
    BOOL v15 = &v12[32 * v11];
    unint64_t v16 = 32 * v10 - 32 - v14;
    if (!v16) {
      goto LABEL_15;
    }
    uint64_t v17 = (v16 >> 5) + 1;
    v15 += 32 * (v17 & 0xFFFFFFFFFFFFFFELL);
    unint64_t v18 = &v12[v14 + 32];
    uint64_t v19 = v17 & 0xFFFFFFFFFFFFFFELL;
    do
    {
      *(v18 - 32) = 0;
      *unint64_t v18 = 0;
      *(v18 - 8) = 0;
      v18[24] = 0;
      v18 += 64;
      v19 -= 2;
    }
    while (v19);
    if (v17 != (v17 & 0xFFFFFFFFFFFFFFELL))
    {
LABEL_15:
      uint64_t v20 = &v12[32 * v10];
      do
      {
        *BOOL v15 = 0;
        v15[24] = 0;
        v15 += 32;
      }
      while (v15 != v20);
    }
    goto LABEL_17;
  }
LABEL_18:
  uint64_t v56 = v58;
  uint64_t v57 = 0x400000000;
  size_t v50 = &v52;
  uint64_t v51 = 0x100000000;
  uint64_t Inputs = mlir::FunctionType::getInputs((mlir::FunctionType *)&v41);
  mlir::ValueRange::ValueRange((unint64_t *)&v48, Inputs, v22);
  uint64_t v23 = v49;
  if (v49)
  {
    uint64_t v24 = 0;
    uint64_t v25 = v48;
    while (1)
    {
      int v26 = (void *)mlir::TypeRange::dereference_iterator(v25, v24);
      if (!mlir::TypeConverter::convertSignatureArg(a3, v24, v26, (uint64_t)&v53)) {
        break;
      }
      if (v23 == ++v24) {
        goto LABEL_22;
      }
    }
  }
  else
  {
LABEL_22:
    uint64_t Results = mlir::FunctionType::getResults((mlir::FunctionType *)&v41);
    mlir::ValueRange::ValueRange((unint64_t *)&v46, Results, v28);
    uint64_t v29 = v47;
    if (!v47)
    {
LABEL_26:
      unint64_t v33 = *(unsigned int *)(v42 + 44);
      if ((v33 & 0x7FFFFF) != 0)
      {
        mlir::detail::ConversionPatternRewriterImpl::convertRegionTypes(a4[7], (void *)(((v42 + 16 * ((v33 >> 23) & 1) + ((v33 >> 21) & 0x7F8) + 71) & 0xFFFFFFFFFFFFFFF8)+ 32 * *(unsigned int *)(v42 + 40)), a3, (uint64_t)&v53);
        if (!v34) {
          goto LABEL_31;
        }
      }
      else
      {
        mlir::detail::ConversionPatternRewriterImpl::convertRegionTypes(a4[7], 0, a3, (uint64_t)&v53);
        if (!v39) {
          goto LABEL_31;
        }
      }
      unsigned long long v35 = (mlir::MLIRContext *)a4[1];
      mlir::ValueRange::ValueRange(v45, (uint64_t)v56, v57);
      mlir::ValueRange::ValueRange(v44, (uint64_t)v50, v51);
      uint64_t v36 = mlir::FunctionType::get(v35, v45[0], v45[1], v44[0], v44[1]);
      uint64_t v37 = v42;
      (*(void (**)(void *, uint64_t))(*a4 + 72))(a4, v42);
      mlir::function_interface_impl::setFunctionType(v42, v43, v36);
      (*(void (**)(void *, uint64_t))(*a4 + 80))(a4, v37);
      uint64_t v13 = 1;
      BOOL v38 = v50;
      if (v50 == &v52) {
        goto LABEL_33;
      }
      goto LABEL_32;
    }
    uint64_t v30 = 0;
    uint64_t v31 = v46;
    while (1)
    {
      unsigned int v32 = (void *)mlir::TypeRange::dereference_iterator(v31, v30);
      if (!mlir::TypeConverter::convertType(a3, v32, (uint64_t)&v50)) {
        break;
      }
      if (v29 == ++v30) {
        goto LABEL_26;
      }
    }
  }
LABEL_31:
  uint64_t v13 = 0;
  BOOL v38 = v50;
  if (v50 != &v52) {
LABEL_32:
  }
    free(v38);
LABEL_33:
  if (v56 != v58) {
    free(v56);
  }
  if (v53 != v55) {
    free(v53);
  }
  return v13;
}

void llvm::SmallVectorTemplateBase<std::pair<mlir::OperationName,mlir::ConversionTarget::LegalizationInfo>,false>::push_back(uint64_t a1, unint64_t a2)
{
  uint64_t v4 = *(unsigned int *)(a1 + 8);
  unint64_t v5 = *(void *)a1;
  if (v4 >= *(_DWORD *)(a1 + 12))
  {
    unint64_t v11 = v4 + 1;
    unint64_t v12 = v5 + 48 * v4;
    if (v5 <= a2 && v12 > a2)
    {
      unint64_t v14 = a2 - v5;
      llvm::SmallVectorTemplateBase<std::pair<mlir::OperationName,mlir::ConversionTarget::LegalizationInfo>,false>::grow(a1, v11);
      unint64_t v5 = *(void *)a1;
      a2 = *(void *)a1 + v14;
    }
    else
    {
      llvm::SmallVectorTemplateBase<std::pair<mlir::OperationName,mlir::ConversionTarget::LegalizationInfo>,false>::grow(a1, v11);
      unint64_t v5 = *(void *)a1;
    }
  }
  unsigned int v6 = *(_DWORD *)(a1 + 8);
  unint64_t v7 = v5 + 48 * v6;
  *(void *)unint64_t v7 = *(void *)a2;
  int v8 = *(_DWORD *)(a2 + 8);
  *(unsigned char *)(v7 + 12) = *(unsigned char *)(a2 + 12);
  *(_DWORD *)(v7 + 8) = v8;
  uint64_t v9 = *(void *)(a2 + 40);
  if (v9)
  {
    uint64_t v10 = (void *)(v5 + 48 * v6 + 40);
    if (v9 == a2 + 16)
    {
      *uint64_t v10 = v7 + 16;
      (*(void (**)(void))(**(void **)(a2 + 40) + 24))(*(void *)(a2 + 40));
    }
    else
    {
      *uint64_t v10 = v9;
      *(void *)(a2 + 40) = 0;
    }
    ++*(_DWORD *)(a1 + 8);
  }
  else
  {
    *(void *)(v5 + 48 * v6 + 40) = 0;
    ++*(_DWORD *)(a1 + 8);
  }
}

void llvm::SmallVectorTemplateBase<std::pair<mlir::OperationName,mlir::ConversionTarget::LegalizationInfo>,false>::grow(uint64_t a1, unint64_t a2)
{
  unint64_t v17 = 0;
  uint64_t v3 = (char *)(a1 + 16);
  uint64_t v4 = (char *)llvm::SmallVectorBase<unsigned int>::mallocForGrow(a1, (void *)(a1 + 16), a2, 48, &v17);
  unint64_t v5 = *(char **)a1;
  uint64_t v6 = *(unsigned int *)(a1 + 8);
  if (v6)
  {
    unint64_t v7 = (char **)(v4 + 40);
    uint64_t v8 = 48 * v6;
    uint64_t v9 = v5 + 40;
    do
    {
      *(v7 - 5) = (char *)*((void *)v9 - 5);
      int v10 = *((_DWORD *)v9 - 8);
      *((unsigned char *)v7 - 28) = *(v9 - 28);
      *((_DWORD *)v7 - 8) = v10;
      unint64_t v11 = *(char **)v9;
      if (*(void *)v9)
      {
        if (v9 - 24 == v11)
        {
          *unint64_t v7 = (char *)(v7 - 3);
          (*(void (**)(void))(**(void **)v9 + 24))();
        }
        else
        {
          *unint64_t v7 = v11;
          *(void *)uint64_t v9 = 0;
        }
      }
      else
      {
        *unint64_t v7 = 0;
      }
      v7 += 6;
      v9 += 48;
      v8 -= 48;
    }
    while (v8);
    unint64_t v5 = *(char **)a1;
    uint64_t v12 = *(unsigned int *)(a1 + 8);
    if (v12)
    {
      uint64_t v13 = 48 * v12;
      unint64_t v14 = v5 - 32;
      do
      {
        BOOL v15 = *(char **)&v14[v13 + 24];
        if (&v14[v13] == v15)
        {
          (*(void (**)(char *))(*(void *)&v14[v13] + 32))(&v14[v13]);
        }
        else if (v15)
        {
          (*(void (**)(char *))(*(void *)v15 + 40))(v15);
        }
        v13 -= 48;
      }
      while (v13);
      unint64_t v5 = *(char **)a1;
    }
  }
  int v16 = v17;
  if (v5 != v3) {
    free(v5);
  }
  *(void *)a1 = v4;
  *(_DWORD *)(a1 + 12) = v16;
}

uint64_t *llvm::StringMap<std::function<std::optional<BOOL> ()(mlir::Operation *)>,llvm::MallocAllocator>::try_emplace<>(uint64_t a1, int8x16_t *a2, const unsigned __int8 *a3)
{
  uint64_t v6 = llvm::StringMapImpl::LookupBucketFor((uint64_t *)a1, a2, a3);
  unint64_t v7 = (uint64_t *)(*(void *)a1 + 8 * v6);
  uint64_t v8 = *v7;
  if (*v7 == -8)
  {
    --*(_DWORD *)(a1 + 16);
    buffer = llvm::allocate_buffer((size_t)(a3 + 41), (std::align_val_t)8uLL);
    int v10 = buffer + 5;
    if (a3) {
LABEL_4:
    }
      memcpy(v10, a2, (size_t)a3);
  }
  else
  {
    if (v8)
    {
      while (!v8 || v8 == -8)
      {
        uint64_t v15 = v7[1];
        ++v7;
        uint64_t v8 = v15;
      }
      return v7;
    }
    buffer = llvm::allocate_buffer((size_t)(a3 + 41), (std::align_val_t)8uLL);
    int v10 = buffer + 5;
    if (a3) {
      goto LABEL_4;
    }
  }
  a3[(void)v10] = 0;
  void *buffer = a3;
  buffer[4] = 0;
  *unint64_t v7 = (uint64_t)buffer;
  ++*(_DWORD *)(a1 + 12);
  unint64_t v7 = (uint64_t *)(*(void *)a1 + 8 * llvm::StringMapImpl::RehashTable((llvm::StringMapImpl *)a1, v6));
  if (*v7) {
    BOOL v11 = *v7 == -8;
  }
  else {
    BOOL v11 = 1;
  }
  if (v11)
  {
    do
    {
      uint64_t v13 = v7[1];
      ++v7;
      uint64_t v12 = v13;
      if (v13) {
        BOOL v14 = v12 == -8;
      }
      else {
        BOOL v14 = 1;
      }
    }
    while (v14);
  }
  return v7;
}

void *std::__function::__value_func<std::optional<BOOL> ()(mlir::Operation *)>::swap[abi:nn180100](void *result, void *a2)
{
  unint64_t v6[3] = *MEMORY[0x263EF8340];
  if (a2 != result)
  {
    uint64_t v3 = result;
    uint64_t v4 = (void *)result[3];
    unint64_t v5 = (void *)a2[3];
    if (v4 == result)
    {
      if (v5 == a2)
      {
        (*(void (**)(void *, void *))(*result + 24))(result, v6);
        (*(void (**)(void))(*(void *)v3[3] + 32))(v3[3]);
        v3[3] = 0;
        (*(void (**)(void, void *))(*(void *)a2[3] + 24))(a2[3], v3);
        (*(void (**)(void))(*(void *)a2[3] + 32))(a2[3]);
        a2[3] = 0;
        v3[3] = v3;
        (*(void (**)(void *, void *))(v6[0] + 24))(v6, a2);
        BOOL result = (void *)(*(uint64_t (**)(void *))(v6[0] + 32))(v6);
      }
      else
      {
        (*(void (**)(void *, void *))(*result + 24))(result, a2);
        BOOL result = (void *)(*(uint64_t (**)(void))(*(void *)v3[3] + 32))(v3[3]);
        v3[3] = a2[3];
      }
      a2[3] = a2;
    }
    else if (v5 == a2)
    {
      (*(void (**)(void *, void *))(*a2 + 24))(a2, result);
      BOOL result = (void *)(*(uint64_t (**)(void))(*(void *)a2[3] + 32))(a2[3]);
      a2[3] = v3[3];
      v3[3] = v3;
    }
    else
    {
      result[3] = v5;
      a2[3] = v4;
    }
  }
  return result;
}

uint64_t mlir::OperationFolder::tryToFold(int32x2_t *this, mlir::Operation *a2, BOOL *a3)
{
  v36[8] = *MEMORY[0x263EF8340];
  if (a3) {
    *a3 = 0;
  }
  __int32 v6 = this[5].i32[0];
  if (!v6) {
    goto LABEL_21;
  }
  int32x2_t v7 = this[3];
  __int32 v8 = v6 - 1;
  unsigned int v9 = v8 & ((a2 >> 4) ^ (a2 >> 9));
  int v10 = *(mlir::Operation **)(*(void *)&v7 + 40 * v9);
  if (v10 != a2)
  {
    int v23 = 1;
    while (v10 != (mlir::Operation *)-4096)
    {
      unsigned int v24 = v9 + v23++;
      unsigned int v9 = v24 & v8;
      int v10 = *(mlir::Operation **)(*(void *)&v7 + 40 * v9);
      if (v10 == a2) {
        goto LABEL_5;
      }
    }
LABEL_21:
    uint64_t v31 = v33;
    uint64_t v32 = 0x800000000;
    char v34 = v36;
    uint64_t v35 = 0x800000000;
    if (mlir::Operation::fold((uint64_t)a2, (uint64_t)&v34))
    {
      BOOL v25 = mlir::OperationFolder::processFoldResults(this, (uint64_t)a2, (uint64_t)&v31, (uint64_t)v34, v35) != 0;
      int v26 = v34;
      if (v34 == v36) {
        goto LABEL_24;
      }
    }
    else
    {
      BOOL v25 = 0;
      int v26 = v34;
      if (v34 == v36)
      {
LABEL_24:
        if (!v25)
        {
          uint64_t v20 = 0;
          unsigned int v27 = v31;
          if (v31 == v33) {
            return v20;
          }
          goto LABEL_28;
        }
        if (v32)
        {
          mlir::OperationFolder::notifyRemoval(this, a2);
          mlir::ValueRange::ValueRange(v30, (uint64_t)v31, v32);
          mlir::RewriterBase::replaceOp(&this[13], (uint64_t)a2, v30[0], v30[1]);
        }
        else
        {
          if (a3) {
            *a3 = 1;
          }
          uint64_t v29 = (uint64_t)this[15];
          if (v29 && mlir::RewriterBase::Listener::classof(v29))
          {
            (*(void (**)(uint64_t, mlir::Operation *))(*(void *)v29 + 32))(v29, a2);
            uint64_t v20 = 1;
            unsigned int v27 = v31;
            if (v31 == v33) {
              return v20;
            }
            goto LABEL_28;
          }
        }
        uint64_t v20 = 1;
        unsigned int v27 = v31;
        if (v31 == v33) {
          return v20;
        }
LABEL_28:
        free(v27);
        return v20;
      }
    }
    free(v26);
    goto LABEL_24;
  }
LABEL_5:
  uint64_t v11 = *((void *)a2 + 2);
  ZinIrHalH13g::~ZinIrHalH13g(*(ZinIrHalH13g **)(v11 + 40));
  if (v12 != a2)
  {
    if (*(mlir::Operation **)(*((void *)a2 + 2) + 40) == a2)
    {
      uint64_t v13 = 0;
      __int32 v14 = this[5].i32[0];
      if (!v14)
      {
LABEL_15:
        ZinIrHalH13g::~ZinIrHalH13g(*(ZinIrHalH13g **)(v11 + 40));
        mlir::Operation::moveBefore(a2, v22);
        return 0;
      }
    }
    else
    {
      ZinIrHalH13g::~ZinIrHalH13g(*(ZinIrHalH13g **)a2);
      __int32 v14 = this[5].i32[0];
      if (!v14) {
        goto LABEL_15;
      }
    }
    int32x2_t v15 = this[3];
    __int32 v16 = v14 - 1;
    unsigned int v17 = ((v13 >> 4) ^ (v13 >> 9)) & v16;
    uint64_t v18 = *(void *)(*(void *)&v15 + 40 * v17);
    if (v18 != v13)
    {
      int v19 = 1;
      while (v18 != -4096)
      {
        uint64_t v20 = 0;
        unsigned int v21 = v17 + v19++;
        unsigned int v17 = v21 & v16;
        uint64_t v18 = *(void *)(*(void *)&v15 + 40 * v17);
        if (v18 == v13) {
          return v20;
        }
      }
      goto LABEL_15;
    }
  }
  return 0;
}

void mlir::OperationFolder::notifyRemoval(int32x2_t *this, mlir::Operation *a2)
{
  v34[1] = *MEMORY[0x263EF8340];
  int32x2_t v4 = this[3];
  unsigned __int32 v5 = this[5].u32[0];
  if (v5)
  {
    unsigned int v6 = (v5 - 1) & ((a2 >> 4) ^ (a2 >> 9));
    uint64_t v7 = *(void *)&v4 + 40 * v6;
    __int32 v8 = *(mlir::Operation **)v7;
    if (*(mlir::Operation **)v7 == a2) {
      goto LABEL_8;
    }
    int v9 = 1;
    while (v8 != (mlir::Operation *)-4096)
    {
      unsigned int v10 = v6 + v9++;
      unsigned int v6 = v10 & (v5 - 1);
      uint64_t v7 = *(void *)&v4 + 40 * v6;
      __int32 v8 = *(mlir::Operation **)v7;
      if (*(mlir::Operation **)v7 == a2) {
        goto LABEL_8;
      }
    }
  }
  uint64_t v7 = *(void *)&v4 + 40 * v5;
LABEL_8:
  if (v7 == *(void *)&v4 + 40 * v5) {
    return;
  }
  if (mlir::OperationName::hasTrait<mlir::OpTrait::ConstantLike>((void *)a2 + 6))
  {
    uint64_t v32 = v34;
    uint64_t v33 = 0x100000000;
    mlir::Operation::fold((uint64_t)a2, 0, 0, (uint64_t)&v32);
    unint64_t v11 = *(void *)v32 & 0xFFFFFFFFFFFFFFF8;
    if (v32 != v34) {
      free(v32);
    }
  }
  else
  {
    unint64_t v11 = 0;
  }
  for (uint64_t i = (void *)mlir::Block::getParent(*((mlir::Block **)a2 + 2));
        i;
        uint64_t i = (void *)mlir::Block::getParent(*(mlir::Block **)(v13 + 16)))
  {
    uint64_t v13 = i[2];
    if (mlir::OperationName::mightHaveTrait<mlir::OpTrait::IsIsolatedFromAbove>((void ***)(v13 + 48))) {
      break;
    }
    if (!*(void *)(v13 + 16)) {
      break;
    }
    uint64_t InterfaceFor = mlir::detail::DialectInterfaceCollectionBase::getInterfaceFor((mlir::detail::DialectInterfaceCollectionBase *)&this[6], (mlir::Operation *)v13);
    if (InterfaceFor)
    {
      if ((*(uint64_t (**)(uint64_t, void *))(*(void *)InterfaceFor + 24))(InterfaceFor, i)) {
        break;
      }
    }
  }
  uint64_t v32 = i;
  __int32 v15 = this[2].i32[0];
  if (!v15)
  {
    unsigned int v24 = 0;
LABEL_32:
    uint64_t v18 = llvm::DenseMapBase<llvm::DenseMap<mlir::Region *,llvm::DenseMap<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>,llvm::DenseMapInfo<mlir::Region *,void>,llvm::detail::DenseMapPair<mlir::Region *,llvm::DenseMap<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>>>,mlir::Region *,llvm::DenseMap<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>,llvm::DenseMapInfo<mlir::Region *,void>,llvm::detail::DenseMapPair<mlir::Region *,llvm::DenseMap<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>>>::InsertIntoBucket<mlir::Region * const&>((uint64_t)this, v24, (uint64_t *)&v32);
    goto LABEL_33;
  }
  __int32 v16 = v15 - 1;
  uint64_t v17 = ((i >> 4) ^ (i >> 9)) & v16;
  uint64_t v18 = (char *)(*(void *)this + 32 * v17);
  uint64_t v19 = *(void *)v18;
  if (i != *(void **)v18)
  {
    uint64_t v20 = 0;
    int v21 = 1;
    while (v19 != -4096)
    {
      if (v20) {
        BOOL v22 = 0;
      }
      else {
        BOOL v22 = v19 == -8192;
      }
      if (v22) {
        uint64_t v20 = v18;
      }
      int v23 = v17 + v21++;
      uint64_t v17 = v23 & v16;
      uint64_t v18 = (char *)(*(void *)this + 32 * v17);
      uint64_t v19 = *(void *)v18;
      if (i == *(void **)v18) {
        goto LABEL_33;
      }
    }
    if (v20) {
      unsigned int v24 = v20;
    }
    else {
      unsigned int v24 = v18;
    }
    goto LABEL_32;
  }
LABEL_33:
  BOOL v25 = *(void ***)(v7 + 8);
  uint64_t v26 = *(unsigned int *)(v7 + 16);
  if (v26)
  {
    unint64_t v27 = *((void *)a2 - 1) & 0xFFFFFFFFFFFFFFF8;
    uint64_t v28 = 8 * v26;
    int64x2_t v30 = vdupq_n_s64(0xFFFFFFFFFFFFE000);
    do
    {
      uint64_t v32 = *v25;
      uint64_t v33 = v11;
      v34[0] = v27;
      uint64_t v31 = 0;
      if (llvm::DenseMapBase<llvm::DenseMap<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>,std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>::LookupBucketFor<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>>((uint64_t *)v18 + 1, &v32, &v31))
      {
        uint64_t v29 = v31;
        void *v31 = -8192;
        *(int64x2_t *)(v29 + 1) = v30;
        *((int32x2_t *)v18 + 2) = vadd_s32(*(int32x2_t *)(v18 + 16), (int32x2_t)0x1FFFFFFFFLL);
      }
      ++v25;
      v28 -= 8;
    }
    while (v28);
    BOOL v25 = *(void ***)(v7 + 8);
  }
  if (v25 != (void **)(v7 + 24)) {
    free(v25);
  }
  *(void *)uint64_t v7 = -8192;
  this[4] = vadd_s32(this[4], (int32x2_t)0x1FFFFFFFFLL);
}

uint64_t mlir::OperationFolder::insertKnownConstant(int32x2_t *a1, uint64_t a2, unint64_t a3)
{
  unint64_t v3 = a3;
  v88[2] = *MEMORY[0x263EF8340];
  uint64_t v83 = (mlir::Operation *)a2;
  unsigned int v6 = *(ZinIrHalH13g ***)(a2 + 16);
  uint64_t v8 = (uint64_t)&a1[3];
  int32x2_t v7 = a1[3];
  __int32 v9 = a1[5].i32[0];
  if (v9)
  {
    __int32 v10 = v9 - 1;
    unsigned int v11 = v10 & ((a2 >> 4) ^ (a2 >> 9));
    uint64_t v12 = *(void *)(*(void *)&v7 + 40 * v11);
    if (v12 == a2)
    {
LABEL_3:
      ZinIrHalH13g::~ZinIrHalH13g(v6[5]);
      if (v13 != a2)
      {
        if (*(void *)(*(void *)(a2 + 16) + 40) == a2)
        {
          uint64_t v14 = 0;
          __int32 v15 = a1[5].i32[0];
          if (!v15)
          {
LABEL_13:
            ZinIrHalH13g::~ZinIrHalH13g(v6[5]);
            mlir::Operation::moveBefore((mlir::Operation *)a2, v23);
            return 1;
          }
        }
        else
        {
          ZinIrHalH13g::~ZinIrHalH13g(*(ZinIrHalH13g **)a2);
          __int32 v15 = a1[5].i32[0];
          if (!v15) {
            goto LABEL_13;
          }
        }
        int32x2_t v16 = a1[3];
        __int32 v17 = v15 - 1;
        unsigned int v18 = ((v14 >> 4) ^ (v14 >> 9)) & (v15 - 1);
        uint64_t v19 = *(void *)(*(void *)&v16 + 40 * v18);
        if (v19 != v14)
        {
          int v20 = 1;
          while (v19 != -4096)
          {
            unsigned int v21 = v18 + v20++;
            unsigned int v18 = v21 & v17;
            uint64_t v19 = *(void *)(*(void *)&v16 + 40 * (v21 & v17));
            uint64_t v22 = 1;
            if (v19 == v14) {
              return v22;
            }
          }
          goto LABEL_13;
        }
      }
      return 1;
    }
    int v24 = 1;
    while (v12 != -4096)
    {
      unsigned int v25 = v11 + v24++;
      unsigned int v11 = v25 & v10;
      uint64_t v12 = *(void *)(*(void *)&v7 + 40 * v11);
      if (v12 == a2) {
        goto LABEL_3;
      }
    }
  }
  if (!a3 && mlir::OperationName::hasTrait<mlir::OpTrait::ConstantLike>((void *)(a2 + 48)))
  {
    uint64_t v86 = v88;
    uint64_t v87 = 0x100000000;
    mlir::Operation::fold(a2, 0, 0, (uint64_t)&v86);
    if ((*(void *)v86 & 0xFFFFFFFFFFFFFFF8) != 0) {
      unint64_t v3 = *(void *)v86 & 0xFFFFFFFFFFFFFFF8;
    }
    if (v86 != v88) {
      free(v86);
    }
  }
  unint64_t v82 = 0;
  for (unint64_t i = mlir::Block::getParent((mlir::Block *)v6); i; unint64_t i = mlir::Block::getParent(*(mlir::Block **)(v27 + 16)))
  {
    uint64_t v27 = *(void *)(i + 16);
    if (mlir::OperationName::mightHaveTrait<mlir::OpTrait::IsIsolatedFromAbove>((void ***)(v27 + 48))) {
      break;
    }
    if (!*(void *)(v27 + 16)) {
      break;
    }
    uint64_t InterfaceFor = mlir::detail::DialectInterfaceCollectionBase::getInterfaceFor((mlir::detail::DialectInterfaceCollectionBase *)&a1[6], (mlir::Operation *)v27);
    if (InterfaceFor)
    {
      if ((*(uint64_t (**)(uint64_t, unint64_t))(*(void *)InterfaceFor + 24))(InterfaceFor, i)) {
        break;
      }
    }
  }
  unint64_t v82 = i;
  __int32 v29 = a1[2].i32[0];
  if (v29)
  {
    __int32 v30 = v29 - 1;
    uint64_t v31 = ((i >> 4) ^ (i >> 9)) & v30;
    uint64_t v32 = (char *)(*(void *)a1 + 32 * v31);
    uint64_t v33 = *(void *)v32;
    if (i == *(void *)v32) {
      goto LABEL_44;
    }
    char v34 = 0;
    int v35 = 1;
    while (v33 != -4096)
    {
      if (v34) {
        BOOL v36 = 0;
      }
      else {
        BOOL v36 = v33 == -8192;
      }
      if (v36) {
        char v34 = v32;
      }
      int v37 = v31 + v35++;
      uint64_t v31 = v37 & v30;
      uint64_t v32 = (char *)(*(void *)a1 + 32 * v31);
      uint64_t v33 = *(void *)v32;
      if (i == *(void *)v32) {
        goto LABEL_44;
      }
    }
    if (v34) {
      BOOL v38 = v34;
    }
    else {
      BOOL v38 = v32;
    }
  }
  else
  {
    BOOL v38 = 0;
  }
  uint64_t v32 = llvm::DenseMapBase<llvm::DenseMap<mlir::Region *,llvm::DenseMap<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>,llvm::DenseMapInfo<mlir::Region *,void>,llvm::detail::DenseMapPair<mlir::Region *,llvm::DenseMap<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>>>,mlir::Region *,llvm::DenseMap<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>,llvm::DenseMapInfo<mlir::Region *,void>,llvm::detail::DenseMapPair<mlir::Region *,llvm::DenseMap<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>>>::InsertIntoBucket<mlir::Region * const&>((uint64_t)a1, v38, (uint64_t *)&v82);
LABEL_44:
  char v39 = (uint64_t *)(v32 + 8);
  uint64_t v40 = *(void *)(a2 + 48);
  if (*(_UNKNOWN **)(v40 + 16) == &mlir::detail::TypeIDResolver<void,void>::id)
  {
    uint64_t v86 = *(void **)(v40 + 8);
    uint64_t Values = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)&v86);
  }
  else
  {
    uint64_t Values = *(void *)(v40 + 24);
  }
  uint64_t v42 = *(unsigned int *)(a2 + 36);
  uint64_t v43 = a2 - 16;
  if (!v42) {
    uint64_t v43 = 0;
  }
  v84[0] = v43;
  v84[1] = v42;
  mlir::OperandRange::getTypes(v84, (uint64_t *)&v86);
  unint64_t v44 = *(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset((uint64_t)v86, v87) + 8) & 0xFFFFFFFFFFFFFFF8;
  uint64_t v79 = Values;
  unint64_t v80 = v3;
  unint64_t v81 = v44;
  uint64_t v86 = 0;
  if ((llvm::DenseMapBase<llvm::DenseMap<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>,std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>::LookupBucketFor<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>>(v39, &v79, &v86) & 1) == 0)
  {
    size_t v50 = llvm::DenseMapBase<llvm::DenseMap<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>,std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>::InsertIntoBucketImpl<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>>((uint64_t)v39, (uint64_t)&v79, &v79, v86);
    *size_t v50 = v79;
    v50[1] = v80;
    v50[2] = v81;
    v50[3] = 0;
    uint64_t v45 = (char *)(v50 + 3);
LABEL_56:
    uint64_t v51 = *(void *)(v82 + 8);
    if (v51) {
      uint64_t v52 = (ZinIrHalH13g **)(v51 - 8);
    }
    else {
      uint64_t v52 = 0;
    }
    if (v6 != v52)
    {
      unint64_t v53 = v83;
LABEL_61:
      ZinIrHalH13g::~ZinIrHalH13g(v52[5]);
      mlir::Operation::moveBefore(v53, v54);
      goto LABEL_62;
    }
    ZinIrHalH13g::~ZinIrHalH13g(v6[5]);
    unint64_t v53 = v83;
    if (v65 == v83)
    {
      unint64_t v53 = v65;
    }
    else
    {
      if (*(mlir::Operation **)(*((void *)v83 + 2) + 40) == v83)
      {
        uint64_t v66 = 0;
        __int32 v67 = a1[5].i32[0];
        if (!v67) {
          goto LABEL_61;
        }
      }
      else
      {
        ZinIrHalH13g::~ZinIrHalH13g(*(ZinIrHalH13g **)v83);
        __int32 v67 = a1[5].i32[0];
        if (!v67) {
          goto LABEL_61;
        }
      }
      int32x2_t v73 = a1[3];
      __int32 v74 = v67 - 1;
      unsigned int v75 = ((v66 >> 4) ^ (v66 >> 9)) & v74;
      uint64_t v76 = *(void *)(*(void *)&v73 + 40 * v75);
      if (v76 != v66)
      {
        int v77 = 1;
        while (v76 != -4096)
        {
          unsigned int v78 = v75 + v77++;
          unsigned int v75 = v78 & v74;
          uint64_t v76 = *(void *)(*(void *)&v73 + 40 * v75);
          if (v76 == v66) {
            goto LABEL_62;
          }
        }
        goto LABEL_61;
      }
    }
LABEL_62:
    *(void *)uint64_t v45 = v53;
    __int32 v55 = a1[5].i32[0];
    if (v55)
    {
      int32x2_t v56 = a1[3];
      __int32 v57 = v55 - 1;
      unsigned int v58 = ((v53 >> 4) ^ (v53 >> 9)) & v57;
      uint64_t v59 = (uint64_t *)(*(void *)&v56 + 40 * v58);
      uint64_t v60 = *v59;
      if (v53 == (mlir::Operation *)*v59) {
        goto LABEL_79;
      }
      uint64_t v61 = 0;
      int v62 = 1;
      while (v60 != -4096)
      {
        if (v61) {
          BOOL v63 = 0;
        }
        else {
          BOOL v63 = v60 == -8192;
        }
        if (v63) {
          uint64_t v61 = v59;
        }
        unsigned int v64 = v58 + v62++;
        unsigned int v58 = v64 & v57;
        uint64_t v59 = (uint64_t *)(*(void *)&v56 + 40 * v58);
        uint64_t v60 = *v59;
        if (v53 == (mlir::Operation *)*v59) {
          goto LABEL_79;
        }
      }
      if (v61) {
        uint64_t v68 = v61;
      }
      else {
        uint64_t v68 = v59;
      }
    }
    else
    {
      uint64_t v68 = 0;
    }
    uint64_t v59 = llvm::DenseMapBase<llvm::DenseMap<mlir::Operation *,llvm::SmallVector<mlir::Dialect *,2u>,llvm::DenseMapInfo<mlir::Operation *,void>,llvm::detail::DenseMapPair<mlir::Operation *,llvm::SmallVector<mlir::Dialect *,2u>>>,mlir::Operation *,llvm::SmallVector<mlir::Dialect *,2u>,llvm::DenseMapInfo<mlir::Operation *,void>,llvm::detail::DenseMapPair<mlir::Operation *,llvm::SmallVector<mlir::Dialect *,2u>>>::InsertIntoBucket<mlir::Operation * const&>(v8, v68, (uint64_t *)&v83);
    unint64_t v53 = v83;
LABEL_79:
    uint64_t v69 = *((void *)v53 + 6);
    if (*(_UNKNOWN **)(v69 + 16) == &mlir::detail::TypeIDResolver<void,void>::id)
    {
      uint64_t v86 = *(void **)(v69 + 8);
      uint64_t v70 = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)&v86);
      uint64_t v71 = *((unsigned int *)v59 + 4);
      if (v71 < *((_DWORD *)v59 + 5)) {
        goto LABEL_81;
      }
    }
    else
    {
      uint64_t v70 = *(void *)(v69 + 24);
      uint64_t v71 = *((unsigned int *)v59 + 4);
      if (v71 < *((_DWORD *)v59 + 5))
      {
LABEL_81:
        *(void *)(v59[1] + 8 * v71) = v70;
        ++*((_DWORD *)v59 + 4);
        return 1;
      }
    }
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)(v59 + 1), v59 + 3, v71 + 1, 8);
    LODWORD(v71) = *((_DWORD *)v59 + 4);
    goto LABEL_81;
  }
  uint64_t v45 = (char *)v86 + 24;
  if (!*((void *)v86 + 3)) {
    goto LABEL_56;
  }
  uint64_t v46 = v83;
  mlir::OperationFolder::notifyRemoval(a1, v83);
  uint64_t v47 = a1 + 13;
  unint64_t v48 = *(unsigned int *)(*(void *)v45 + 36);
  if (v48) {
    uint64_t v49 = *(void *)v45 - 16;
  }
  else {
    uint64_t v49 = 0;
  }
  mlir::ValueRange::ValueRange(v85, v49, v48);
  mlir::RewriterBase::replaceOp(v47, (uint64_t)v46, v85[0], v85[1]);
  return 0;
}

mlir::Operation *mlir::OperationFolder::tryGetOrCreateConstant(int32x2_t *a1, uint64_t *a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  uint64_t v70 = a3;
  uint64_t v71 = a4;
  uint64_t v72 = a5;
  *(void *)&long long v65 = 0;
  char v12 = llvm::DenseMapBase<llvm::DenseMap<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>,std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>::LookupBucketFor<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>>(a2, &v70, &v65);
  uint64_t v13 = (void *)v65;
  if (v12)
  {
    BOOL result = *(mlir::Operation **)(v65 + 24);
    if (result) {
      return result;
    }
  }
  else
  {
    uint64_t v13 = llvm::DenseMapBase<llvm::DenseMap<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>,std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>::InsertIntoBucketImpl<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>>((uint64_t)a2, (uint64_t)&v70, &v70, (void *)v65);
    *uint64_t v13 = v70;
    v13[1] = v71;
    void v13[2] = v72;
    v13[3] = 0;
  }
  BOOL result = (mlir::Operation *)(*(uint64_t (**)(uint64_t, int32x2_t *, uint64_t, uint64_t, uint64_t))(*(void *)a3 + 24))(a3, a1 + 14, a4, a5, a6);
  v13[3] = result;
  __int32 v15 = (mlir::Operation **)(v13 + 3);
  if (result)
  {
    uint64_t v16 = *((void *)result + 6);
    if (*(_UNKNOWN **)(v16 + 16) == &mlir::detail::TypeIDResolver<void,void>::id)
    {
      *(void *)&long long v65 = *(void *)(v16 + 8);
      uint64_t Values = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)&v65);
      if (Values != a3) {
        goto LABEL_8;
      }
    }
    else
    {
      uint64_t Values = *(void *)(v16 + 24);
      if (Values != a3)
      {
LABEL_8:
        *(void *)&long long v68 = Values;
        *((void *)&v68 + 1) = a4;
        uint64_t v69 = a5;
        *(void *)&long long v65 = 0;
        if (llvm::DenseMapBase<llvm::DenseMap<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>,std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>::LookupBucketFor<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>>(a2, &v68, &v65))
        {
          unsigned int v18 = *(mlir::Operation **)(v65 + 24);
          int32x2_t v73 = v18;
          if (v18)
          {
            mlir::OperationFolder::notifyRemoval(a1, *v15);
            mlir::RewriterBase::eraseOp((mlir::RewriterBase *)&a1[13], *v15);
            int32x2_t v21 = a1[3];
            uint64_t v20 = (uint64_t)&a1[3];
            int32x2_t v19 = v21;
            int v22 = *(_DWORD *)(v20 + 16);
            if (v22)
            {
              int v23 = v22 - 1;
              unsigned int v24 = ((v18 >> 4) ^ (v18 >> 9)) & v23;
              unsigned int v25 = (uint64_t *)(*(void *)&v19 + 40 * v24);
              uint64_t v26 = *v25;
              if (v18 == (mlir::Operation *)*v25)
              {
LABEL_59:
                uint64_t v64 = *((unsigned int *)v25 + 4);
                if (v64 >= *((_DWORD *)v25 + 5))
                {
                  llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)(v25 + 1), v25 + 3, v64 + 1, 8);
                  LODWORD(v64) = *((_DWORD *)v25 + 4);
                }
                *(void *)(v25[1] + 8 * v64) = a3;
                ++*((_DWORD *)v25 + 4);
                BOOL result = v73;
                *__int32 v15 = v73;
                return result;
              }
              uint64_t v27 = 0;
              int v28 = 1;
              while (v26 != -4096)
              {
                if (v27) {
                  BOOL v29 = 0;
                }
                else {
                  BOOL v29 = v26 == -8192;
                }
                if (v29) {
                  uint64_t v27 = v25;
                }
                unsigned int v30 = v24 + v28++;
                unsigned int v24 = v30 & v23;
                unsigned int v25 = (uint64_t *)(*(void *)&v19 + 40 * v24);
                uint64_t v26 = *v25;
                if (v18 == (mlir::Operation *)*v25) {
                  goto LABEL_59;
                }
              }
              if (v27) {
                BOOL v63 = v27;
              }
              else {
                BOOL v63 = v25;
              }
            }
            else
            {
              BOOL v63 = 0;
            }
            unsigned int v25 = llvm::DenseMapBase<llvm::DenseMap<mlir::Operation *,llvm::SmallVector<mlir::Dialect *,2u>,llvm::DenseMapInfo<mlir::Operation *,void>,llvm::detail::DenseMapPair<mlir::Operation *,llvm::SmallVector<mlir::Dialect *,2u>>>,mlir::Operation *,llvm::SmallVector<mlir::Dialect *,2u>,llvm::DenseMapInfo<mlir::Operation *,void>,llvm::detail::DenseMapPair<mlir::Operation *,llvm::SmallVector<mlir::Dialect *,2u>>>::InsertIntoBucket<mlir::Operation * const&>(v20, v63, (uint64_t *)&v73);
            goto LABEL_59;
          }
        }
        int32x2_t v33 = a1[3];
        uint64_t v32 = (uint64_t)&a1[3];
        int32x2_t v31 = v33;
        int v34 = *(_DWORD *)(v32 + 16);
        if (v34)
        {
          int v35 = v34 - 1;
          unsigned int v36 = ((*v15 >> 4) ^ (*v15 >> 9)) & v35;
          int v37 = (uint64_t *)(*(void *)&v31 + 40 * v36);
          uint64_t v38 = *v37;
          if (*v15 == (mlir::Operation *)*v37)
          {
LABEL_46:
            *((_DWORD *)v37 + 4) = 0;
            if (*((_DWORD *)v37 + 5) > 1u)
            {
              uint64_t v56 = 0;
            }
            else
            {
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)(v37 + 1), v37 + 3, 2uLL, 8);
              uint64_t v56 = *((unsigned int *)v37 + 4);
            }
            __int32 v57 = (void *)(v37[1] + 8 * v56);
            *__int32 v57 = a3;
            v57[1] = Values;
            *((_DWORD *)v37 + 4) += 2;
            long long v65 = v68;
            unsigned int v58 = *v15;
            uint64_t v66 = v69;
            __int32 v67 = v58;
            int32x2_t v73 = 0;
            char v59 = llvm::DenseMapBase<llvm::DenseMap<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>,std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>::LookupBucketFor<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>>(a2, &v65, &v73);
            uint64_t v60 = v73;
            if ((v59 & 1) == 0)
            {
              uint64_t v60 = llvm::DenseMapBase<llvm::DenseMap<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>,std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>::InsertIntoBucketImpl<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>>((uint64_t)a2, (uint64_t)&v65, &v65, v73);
              *(_OWORD *)uint64_t v60 = v65;
              v60[2] = v66;
              v60[3] = v67;
            }
            return (mlir::Operation *)v60[3];
          }
          char v39 = 0;
          int v40 = 1;
          while (v38 != -4096)
          {
            if (v39) {
              BOOL v41 = 0;
            }
            else {
              BOOL v41 = v38 == -8192;
            }
            if (v41) {
              char v39 = v37;
            }
            unsigned int v42 = v36 + v40++;
            unsigned int v36 = v42 & v35;
            int v37 = (uint64_t *)(*(void *)&v31 + 40 * v36);
            uint64_t v38 = *v37;
            if (*v15 == (mlir::Operation *)*v37) {
              goto LABEL_46;
            }
          }
          if (v39) {
            __int32 v55 = v39;
          }
          else {
            __int32 v55 = v37;
          }
        }
        else
        {
          __int32 v55 = 0;
        }
        int v37 = llvm::DenseMapBase<llvm::DenseMap<mlir::Operation *,llvm::SmallVector<mlir::Dialect *,2u>,llvm::DenseMapInfo<mlir::Operation *,void>,llvm::detail::DenseMapPair<mlir::Operation *,llvm::SmallVector<mlir::Dialect *,2u>>>,mlir::Operation *,llvm::SmallVector<mlir::Dialect *,2u>,llvm::DenseMapInfo<mlir::Operation *,void>,llvm::detail::DenseMapPair<mlir::Operation *,llvm::SmallVector<mlir::Dialect *,2u>>>::InsertIntoBucket<mlir::Operation * const&>(v32, v55, (uint64_t *)v15);
        goto LABEL_46;
      }
    }
    int32x2_t v45 = a1[3];
    uint64_t v44 = (uint64_t)&a1[3];
    int32x2_t v43 = v45;
    int v46 = *(_DWORD *)(v44 + 16);
    if (v46)
    {
      int v47 = v46 - 1;
      unsigned int v48 = ((*v15 >> 4) ^ (*v15 >> 9)) & v47;
      uint64_t v49 = (uint64_t *)(*(void *)&v43 + 40 * v48);
      uint64_t v50 = *v49;
      if (*v15 == (mlir::Operation *)*v49)
      {
LABEL_54:
        uint64_t v62 = *((unsigned int *)v49 + 4);
        if (v62 >= *((_DWORD *)v49 + 5))
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)(v49 + 1), v49 + 3, v62 + 1, 8);
          LODWORD(v62) = *((_DWORD *)v49 + 4);
        }
        *(void *)(v49[1] + 8 * v62) = a3;
        ++*((_DWORD *)v49 + 4);
        return *v15;
      }
      uint64_t v51 = 0;
      int v52 = 1;
      while (v50 != -4096)
      {
        if (v51) {
          BOOL v53 = 0;
        }
        else {
          BOOL v53 = v50 == -8192;
        }
        if (v53) {
          uint64_t v51 = v49;
        }
        unsigned int v54 = v48 + v52++;
        unsigned int v48 = v54 & v47;
        uint64_t v49 = (uint64_t *)(*(void *)&v43 + 40 * v48);
        uint64_t v50 = *v49;
        if (*v15 == (mlir::Operation *)*v49) {
          goto LABEL_54;
        }
      }
      if (v51) {
        uint64_t v61 = v51;
      }
      else {
        uint64_t v61 = v49;
      }
    }
    else
    {
      uint64_t v61 = 0;
    }
    uint64_t v49 = llvm::DenseMapBase<llvm::DenseMap<mlir::Operation *,llvm::SmallVector<mlir::Dialect *,2u>,llvm::DenseMapInfo<mlir::Operation *,void>,llvm::detail::DenseMapPair<mlir::Operation *,llvm::SmallVector<mlir::Dialect *,2u>>>,mlir::Operation *,llvm::SmallVector<mlir::Dialect *,2u>,llvm::DenseMapInfo<mlir::Operation *,void>,llvm::detail::DenseMapPair<mlir::Operation *,llvm::SmallVector<mlir::Dialect *,2u>>>::InsertIntoBucket<mlir::Operation * const&>(v44, v61, (uint64_t *)v15);
    goto LABEL_54;
  }
  return result;
}

uint64_t mlir::OperationFolder::processFoldResults(int32x2_t *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  if (!a5) {
    return 1;
  }
  for (unint64_t i = mlir::Block::getParent(*(mlir::Block **)(a2 + 16)); i; unint64_t i = mlir::Block::getParent(*(mlir::Block **)(v9 + 16)))
  {
    uint64_t v9 = *(void *)(i + 16);
    if (mlir::OperationName::mightHaveTrait<mlir::OpTrait::IsIsolatedFromAbove>((void ***)(v9 + 48))) {
      break;
    }
    if (!*(void *)(v9 + 16)) {
      break;
    }
    uint64_t InterfaceFor = mlir::detail::DialectInterfaceCollectionBase::getInterfaceFor((mlir::detail::DialectInterfaceCollectionBase *)&a1[6], (mlir::Operation *)v9);
    if (InterfaceFor)
    {
      if ((*(uint64_t (**)(uint64_t, unint64_t))(*(void *)InterfaceFor + 24))(InterfaceFor, i)) {
        break;
      }
    }
  }
  unint64_t v51 = i;
  uint64_t v11 = *(void *)(i + 8);
  if (v11) {
    int32x2_t v12 = (int32x2_t)(v11 - 8);
  }
  else {
    int32x2_t v12 = 0;
  }
  int32x2_t v13 = *(int32x2_t *)(*(void *)&v12 + 40);
  a1[16] = v12;
  a1[17] = v13;
  __int32 v14 = a1[2].i32[0];
  if (!v14)
  {
    int v23 = 0;
LABEL_24:
    __int32 v17 = llvm::DenseMapBase<llvm::DenseMap<mlir::Region *,llvm::DenseMap<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>,llvm::DenseMapInfo<mlir::Region *,void>,llvm::detail::DenseMapPair<mlir::Region *,llvm::DenseMap<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>>>,mlir::Region *,llvm::DenseMap<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>,llvm::DenseMapInfo<mlir::Region *,void>,llvm::detail::DenseMapPair<mlir::Region *,llvm::DenseMap<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>>>::InsertIntoBucket<mlir::Region * const&>((uint64_t)a1, v23, (uint64_t *)&v51);
    goto LABEL_25;
  }
  __int32 v15 = v14 - 1;
  uint64_t v16 = v15 & ((i >> 4) ^ (i >> 9));
  __int32 v17 = (char *)(*(void *)a1 + 32 * v16);
  uint64_t v18 = *(void *)v17;
  if (i != *(void *)v17)
  {
    int32x2_t v19 = 0;
    int v20 = 1;
    while (v18 != -4096)
    {
      if (v19) {
        BOOL v21 = 0;
      }
      else {
        BOOL v21 = v18 == -8192;
      }
      if (v21) {
        int32x2_t v19 = v17;
      }
      int v22 = v16 + v20++;
      uint64_t v16 = v22 & v15;
      __int32 v17 = (char *)(*(void *)a1 + 32 * v16);
      uint64_t v18 = *(void *)v17;
      if (i == *(void *)v17) {
        goto LABEL_25;
      }
    }
    if (v19) {
      int v23 = v19;
    }
    else {
      int v23 = v17;
    }
    goto LABEL_24;
  }
LABEL_25:
  uint64_t v24 = *(void *)(a2 + 48);
  if (*(_UNKNOWN **)(v24 + 16) == &mlir::detail::TypeIDResolver<void,void>::id)
  {
    uint64_t v52 = *(void *)(v24 + 8);
    uint64_t Values = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)&v52);
    uint64_t v25 = *(unsigned int *)(a2 + 36);
    if (!v25) {
      return 1;
    }
  }
  else
  {
    uint64_t Values = *(void *)(v24 + 24);
    uint64_t v25 = *(unsigned int *)(a2 + 36);
    if (!v25) {
      return 1;
    }
  }
  unint64_t v26 = 0;
  int32x2_t v48 = v12;
  uint64_t v27 = (uint64_t *)(v17 + 8);
  int v47 = (void *)(a3 + 16);
  uint64_t v28 = a2 - 16;
  for (uint64_t j = a2 + 24; ; j -= 24)
  {
    uint64_t v30 = *(void *)(a4 + 8 * v26);
    unint64_t v31 = v30 & 0xFFFFFFFFFFFFFFF8;
    if ((v30 & 4) == 0 || !v31) {
      break;
    }
    if (v26 >= 6) {
      uint64_t v32 = j;
    }
    else {
      uint64_t v32 = v28;
    }
    if ((*(void *)(v31 + 8) & 0xFFFFFFFFFFFFFFF8) != (*(void *)(v32 + 8) & 0xFFFFFFFFFFFFFFF8)) {
      goto LABEL_54;
    }
    uint64_t v33 = *(unsigned int *)(a3 + 8);
    if (v33 >= *(_DWORD *)(a3 + 12))
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod(a3, v47, v33 + 1, 8);
      *(void *)(*(void *)a3 + 8 * *(unsigned int *)(a3 + 8)) = v31;
LABEL_50:
      LODWORD(v33) = *(_DWORD *)(a3 + 8);
      goto LABEL_31;
    }
    *(void *)(*(void *)a3 + 8 * v33) = v31;
LABEL_31:
    *(_DWORD *)(a3 + 8) = v33 + 1;
    ++v26;
    v28 -= 16;
    if (v25 == v26) {
      return 1;
    }
  }
  if (v26 >= 6) {
    uint64_t v34 = j;
  }
  else {
    uint64_t v34 = v28;
  }
  Constant = mlir::OperationFolder::tryGetOrCreateConstant(a1, v27, Values, v31, *(void *)(v34 + 8) & 0xFFFFFFFFFFFFFFF8, *(void *)(a2 + 24));
  if (Constant)
  {
    unsigned int v36 = Constant;
    uint64_t v37 = *(void *)(a2 + 16);
    if (v37 == *((void *)Constant + 2))
    {
      ZinIrHalH13g::~ZinIrHalH13g(*(ZinIrHalH13g **)(v37 + 40));
      if (v38 != v36)
      {
        ZinIrHalH13g::~ZinIrHalH13g(*(ZinIrHalH13g **)(v37 + 40));
        mlir::Operation::moveBefore(v36, v39);
      }
    }
    unint64_t v40 = *(unsigned int *)(a3 + 8);
    if (v40 >= *(unsigned int *)(a3 + 12))
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod(a3, v47, v40 + 1, 8);
      unint64_t v40 = *(unsigned int *)(a3 + 8);
    }
    *(void *)(*(void *)a3 + 8 * v40) = (char *)v36 - 16;
    goto LABEL_50;
  }
  unsigned int v42 = *(ZinIrHalH13g **)(*(void *)&v48 + 40);
  int32x2_t v43 = (ZinIrHalH13g *)a1[17];
  if (v42 != v43)
  {
    do
    {
      uint64_t v44 = (ZinIrHalH13g *)*((void *)v42 + 1);
      ZinIrHalH13g::~ZinIrHalH13g(v42);
      int v46 = v45;
      mlir::OperationFolder::notifyRemoval(a1, v45);
      mlir::RewriterBase::eraseOp((mlir::RewriterBase *)&a1[13], v46);
      unsigned int v42 = v44;
    }
    while (v44 != v43);
  }
LABEL_54:
  uint64_t result = 0;
  *(_DWORD *)(a3 + 8) = 0;
  return result;
}

char *llvm::DenseMapBase<llvm::DenseMap<mlir::Region *,llvm::DenseMap<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>,llvm::DenseMapInfo<mlir::Region *,void>,llvm::detail::DenseMapPair<mlir::Region *,llvm::DenseMap<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>>>,mlir::Region *,llvm::DenseMap<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>,llvm::DenseMapInfo<mlir::Region *,void>,llvm::detail::DenseMapPair<mlir::Region *,llvm::DenseMap<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>>>::InsertIntoBucket<mlir::Region * const&>(uint64_t a1, char *a2, uint64_t *a3)
{
  int v5 = *(_DWORD *)(a1 + 8);
  uint64_t v6 = *(unsigned int *)(a1 + 16);
  if (4 * v5 + 4 >= (3 * v6))
  {
    int v10 = 2 * v6;
  }
  else
  {
    if ((int)v6 + ~v5 - *(_DWORD *)(a1 + 12) > v6 >> 3)
    {
LABEL_3:
      uint64_t v7 = *(void *)a2;
      goto LABEL_4;
    }
    int v10 = *(_DWORD *)(a1 + 16);
  }
  uint64_t v11 = *(uint64_t **)a1;
  unint64_t v12 = (v10 - 1) | ((unint64_t)(v10 - 1) >> 1);
  unint64_t v13 = v12 | (v12 >> 2) | ((v12 | (v12 >> 2)) >> 4);
  int v14 = ((v13 | (v13 >> 8)) >> 16) | v13 | (v13 >> 8);
  if ((v14 + 1) > 0x40) {
    unsigned int v15 = v14 + 1;
  }
  else {
    unsigned int v15 = 64;
  }
  *(_DWORD *)(a1 + 16) = v15;
  buffer = llvm::allocate_buffer(32 * v15, (std::align_val_t)8uLL);
  *(void *)a1 = buffer;
  if (v11)
  {
    __int32 v17 = (char *)(32 * v6);
    llvm::DenseMapBase<llvm::DenseMap<mlir::Region *,llvm::DenseMap<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>,llvm::DenseMapInfo<mlir::Region *,void>,llvm::detail::DenseMapPair<mlir::Region *,llvm::DenseMap<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>>>,mlir::Region *,llvm::DenseMap<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>,llvm::DenseMapInfo<mlir::Region *,void>,llvm::detail::DenseMapPair<mlir::Region *,llvm::DenseMap<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>>>::moveFromOldBuckets(a1, v11, (uint64_t *)&v17[(void)v11]);
    llvm::deallocate_buffer((llvm *)v11, v17);
  }
  *(void *)(a1 + 8) = 0;
  uint64_t v18 = *(unsigned int *)(a1 + 16);
  int32x2_t v19 = buffer;
  if (((v18 - 1) & 0x7FFFFFFFFFFFFFFLL) == 0) {
    goto LABEL_34;
  }
  uint64_t v20 = ((v18 - 1) & 0x7FFFFFFFFFFFFFFLL) + 1;
  int32x2_t v19 = &buffer[4 * (v20 & 0xFFFFFFFFFFFFFFELL)];
  BOOL v21 = buffer + 4;
  uint64_t v22 = v20 & 0xFFFFFFFFFFFFFFELL;
  do
  {
    *(v21 - 4) = -4096;
    *BOOL v21 = -4096;
    v21 += 8;
    v22 -= 2;
  }
  while (v22);
  if (v20 != (v20 & 0xFFFFFFFFFFFFFFELL))
  {
LABEL_34:
    do
    {
      *int32x2_t v19 = -4096;
      v19 += 4;
    }
    while (v19 != &buffer[4 * v18]);
  }
  uint64_t v7 = *a3;
  unsigned int v23 = v18 - 1;
  uint64_t v24 = ((*a3 >> 4) ^ (*a3 >> 9)) & v23;
  a2 = (char *)&buffer[4 * v24];
  uint64_t v25 = *(void *)a2;
  if (*a3 != *(void *)a2)
  {
    unint64_t v26 = 0;
    int v27 = 1;
    while (v25 != -4096)
    {
      if (v26) {
        BOOL v28 = 0;
      }
      else {
        BOOL v28 = v25 == -8192;
      }
      if (v28) {
        unint64_t v26 = a2;
      }
      int v29 = v24 + v27++;
      uint64_t v24 = v29 & v23;
      a2 = (char *)&buffer[4 * v24];
      uint64_t v25 = *(void *)a2;
      if (v7 == *(void *)a2) {
        goto LABEL_4;
      }
    }
    if (v26) {
      a2 = v26;
    }
    goto LABEL_3;
  }
LABEL_4:
  ++*(_DWORD *)(a1 + 8);
  if (v7 != -4096) {
    --*(_DWORD *)(a1 + 12);
  }
  uint64_t v8 = *a3;
  *((void *)a2 + 1) = 0;
  *((void *)a2 + 2) = 0;
  *(void *)a2 = v8;
  *((_DWORD *)a2 + 6) = 0;
  return a2;
}

uint64_t llvm::DenseMapBase<llvm::DenseMap<mlir::Region *,llvm::DenseMap<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>,llvm::DenseMapInfo<mlir::Region *,void>,llvm::detail::DenseMapPair<mlir::Region *,llvm::DenseMap<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>>>,mlir::Region *,llvm::DenseMap<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>,llvm::DenseMapInfo<mlir::Region *,void>,llvm::detail::DenseMapPair<mlir::Region *,llvm::DenseMap<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>>>::moveFromOldBuckets(uint64_t result, uint64_t *a2, uint64_t *a3)
{
  unint64_t v3 = a2;
  *(void *)(result + 8) = 0;
  uint64_t v4 = *(unsigned int *)(result + 16);
  if (v4)
  {
    int v5 = *(void **)result;
    uint64_t v6 = (v4 - 1) & 0x7FFFFFFFFFFFFFFLL;
    if (v6)
    {
      uint64_t v7 = v6 + 1;
      uint64_t v8 = (v6 + 1) & 0xFFFFFFFFFFFFFFELL;
      uint64_t v9 = &v5[4 * v8];
      int v10 = v5 + 4;
      uint64_t v11 = v8;
      do
      {
        *(v10 - 4) = -4096;
        *int v10 = -4096;
        v10 += 8;
        v11 -= 2;
      }
      while (v11);
      if (v7 == v8) {
        goto LABEL_10;
      }
    }
    else
    {
      uint64_t v9 = *(void **)result;
    }
    unint64_t v12 = &v5[4 * v4];
    do
    {
      *uint64_t v9 = -4096;
      v9 += 4;
    }
    while (v9 != v12);
  }
LABEL_10:
  if (a2 != a3)
  {
    do
    {
      uint64_t v16 = *v3;
      if ((*v3 | 0x1000) != 0xFFFFFFFFFFFFF000)
      {
        int v17 = *(_DWORD *)(result + 16) - 1;
        uint64_t v18 = v17 & ((v16 >> 4) ^ (v16 >> 9));
        uint64_t v13 = *(void *)result + 32 * v18;
        uint64_t v19 = *(void *)v13;
        if (v16 != *(void *)v13)
        {
          uint64_t v20 = 0;
          int v21 = 1;
          while (v19 != -4096)
          {
            if (v20) {
              BOOL v22 = 0;
            }
            else {
              BOOL v22 = v19 == -8192;
            }
            if (v22) {
              uint64_t v20 = v13;
            }
            int v23 = v18 + v21++;
            uint64_t v18 = v23 & v17;
            uint64_t v13 = *(void *)result + 32 * v18;
            uint64_t v19 = *(void *)v13;
            if (v16 == *(void *)v13) {
              goto LABEL_14;
            }
          }
          if (v20) {
            uint64_t v13 = v20;
          }
        }
LABEL_14:
        *(void *)(v13 + 8) = 0;
        *(void *)(v13 + 16) = 0;
        *(void *)uint64_t v13 = v16;
        *(_DWORD *)(v13 + 24) = 0;
        *(void *)(v13 + 8) = v3[1];
        v3[1] = 0;
        *(_DWORD *)(v13 + 16) = *((_DWORD *)v3 + 4);
        *((_DWORD *)v3 + 4) = 0;
        int v14 = *(_DWORD *)(v13 + 20);
        *(_DWORD *)(v13 + 20) = *((_DWORD *)v3 + 5);
        *((_DWORD *)v3 + 5) = v14;
        uint64_t v15 = *(unsigned int *)(v13 + 24);
        *(_DWORD *)(v13 + 24) = *((_DWORD *)v3 + 6);
        *((_DWORD *)v3 + 6) = v15;
        ++*(_DWORD *)(result + 8);
        llvm::deallocate_buffer(0, (void *)(32 * v15));
      }
      v3 += 4;
    }
    while (v3 != a3);
  }
  return result;
}

uint64_t llvm::DenseMapBase<llvm::DenseMap<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>,std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>::LookupBucketFor<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>>(uint64_t *a1, void *a2, void *a3)
{
  int v3 = *((_DWORD *)a1 + 4);
  if (!v3)
  {
    uint64_t result = 0;
    *a3 = 0;
    return result;
  }
  uint64_t v4 = 0;
  uint64_t v5 = *a1;
  uint64_t v6 = a2[1];
  uint64_t v7 = a2[2];
  unint64_t v8 = ((unint64_t)((v7 >> 4) ^ (v7 >> 9)) << 32) - 1;
  unint64_t v9 = (v8 ^ (v8 >> 22)) + ~((v8 ^ (v8 >> 22)) << 13);
  unint64_t v10 = (9 * (v9 ^ (v9 >> 8))) ^ ((9 * (v9 ^ (v9 >> 8))) >> 15);
  uint64_t v11 = ((v10 + ~(v10 << 27)) >> 31) ^ (v10 + ~(v10 << 27));
  unint64_t v12 = (v11 | ((unint64_t)((v6 >> 4) ^ (v6 >> 9)) << 32)) + ~(v11 << 32);
  unint64_t v13 = (v12 ^ (v12 >> 22)) + ~((v12 ^ (v12 >> 22)) << 13);
  unint64_t v14 = (9 * (v13 ^ (v13 >> 8))) ^ ((9 * (v13 ^ (v13 >> 8))) >> 15);
  uint64_t v15 = ((v14 + ~(v14 << 27)) >> 31) ^ (v14 + ~(v14 << 27));
  unint64_t v16 = (v15 | ((unint64_t)((*a2 >> 4) ^ (*a2 >> 9)) << 32)) + ~(v15 << 32);
  unint64_t v17 = (v16 ^ (v16 >> 22)) + ~((v16 ^ (v16 >> 22)) << 13);
  unint64_t v18 = (9 * (v17 ^ (v17 >> 8))) ^ ((9 * (v17 ^ (v17 >> 8))) >> 15);
  int v19 = v3 - 1;
  unsigned int v20 = v19 & (((v18 + ~(v18 << 27)) >> 31) ^ (v18 + ~(v18 << 27)));
  int v21 = 1;
  BOOL v22 = (void *)(*a1 + 32 * v20);
  uint64_t v23 = *v22;
  if (*a2 != *v22) {
    goto LABEL_7;
  }
LABEL_3:
  if (v6 == v22[1] && v7 == v22[2])
  {
    uint64_t result = 1;
    *a3 = v22;
    return result;
  }
  while (1)
  {
LABEL_7:
    if (v23 != -4096)
    {
      BOOL v25 = v23 == -8192 && v22[1] == -8192 && v22[2] == -8192;
      goto LABEL_19;
    }
    BOOL v25 = 0;
    if (v22[1] == -4096 && v22[2] == -4096) {
      break;
    }
LABEL_19:
    if (v25 && v4 == 0) {
      uint64_t v4 = v22;
    }
    unsigned int v27 = v20 + v21++;
    unsigned int v20 = v27 & v19;
    BOOL v22 = (void *)(v5 + 32 * v20);
    uint64_t v23 = *v22;
    if (*a2 == *v22) {
      goto LABEL_3;
    }
  }
  uint64_t result = 0;
  if (v4) {
    BOOL v22 = v4;
  }
  *a3 = v22;
  return result;
}

void *llvm::DenseMapBase<llvm::DenseMap<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>,std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>::InsertIntoBucketImpl<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>>(uint64_t a1, uint64_t a2, void *a3, void *a4)
{
  int v6 = *(_DWORD *)(a1 + 8);
  unsigned int v7 = *(_DWORD *)(a1 + 16);
  if (4 * v6 + 4 >= 3 * v7)
  {
    v7 *= 2;
LABEL_7:
    llvm::DenseMap<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>::grow(a1, v7);
    unint64_t v9 = 0;
    llvm::DenseMapBase<llvm::DenseMap<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>,std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>::LookupBucketFor<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>>((uint64_t *)a1, a3, &v9);
    a4 = v9;
    ++*(_DWORD *)(a1 + 8);
    if (*a4 != -4096) {
      goto LABEL_4;
    }
    goto LABEL_8;
  }
  if (v7 + ~v6 - *(_DWORD *)(a1 + 12) <= v7 >> 3) {
    goto LABEL_7;
  }
  ++*(_DWORD *)(a1 + 8);
  if (*a4 != -4096)
  {
LABEL_4:
    --*(_DWORD *)(a1 + 12);
    return a4;
  }
LABEL_8:
  if (a4[1] != -4096 || a4[2] != -4096) {
    goto LABEL_4;
  }
  return a4;
}

char *llvm::DenseMap<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>::grow(uint64_t a1, int a2)
{
  uint64_t v3 = *(unsigned int *)(a1 + 16);
  uint64_t v4 = *(llvm **)a1;
  unint64_t v5 = (a2 - 1) | ((unint64_t)(a2 - 1) >> 1);
  unint64_t v6 = v5 | (v5 >> 2) | ((v5 | (v5 >> 2)) >> 4);
  int v7 = ((v6 | (v6 >> 8)) >> 16) | v6 | (v6 >> 8);
  if ((v7 + 1) > 0x40) {
    unsigned int v8 = v7 + 1;
  }
  else {
    unsigned int v8 = 64;
  }
  *(_DWORD *)(a1 + 16) = v8;
  uint64_t result = (char *)llvm::allocate_buffer(32 * v8, (std::align_val_t)8uLL);
  unint64_t v10 = result;
  *(void *)a1 = result;
  if (v4)
  {
    *(void *)(a1 + 8) = 0;
    uint64_t v11 = *(unsigned int *)(a1 + 16);
    if (v11)
    {
      if (((v11 - 1) & 0x7FFFFFFFFFFFFFFLL) == 0) {
        goto LABEL_10;
      }
      uint64_t v12 = ((v11 - 1) & 0x7FFFFFFFFFFFFFFLL) + 1;
      unint64_t v10 = &result[32 * (v12 & 0xFFFFFFFFFFFFFFELL)];
      unint64_t v13 = (int64x2_t *)(result + 40);
      int64x2_t v14 = vdupq_n_s64(0xFFFFFFFFFFFFF000);
      uint64_t v15 = v12 & 0xFFFFFFFFFFFFFFELL;
      do
      {
        v13[-3].i64[1] = -4096;
        v13[-1].i64[1] = -4096;
        v13[-2] = v14;
        *unint64_t v13 = v14;
        v13 += 4;
        v15 -= 2;
      }
      while (v15);
      if (v12 != (v12 & 0xFFFFFFFFFFFFFFELL))
      {
LABEL_10:
        unint64_t v16 = &result[32 * v11];
        int64x2_t v17 = vdupq_n_s64(0xFFFFFFFFFFFFF000);
        do
        {
          *(void *)unint64_t v10 = -4096;
          *(int64x2_t *)(v10 + 8) = v17;
          v10 += 32;
        }
        while (v10 != v16);
      }
    }
    unint64_t v18 = (void *)(32 * v3);
    if (!v3) {
LABEL_24:
    }
      llvm::deallocate_buffer(v4, v18);
    uint64_t v19 = 32 * v3;
    unsigned int v20 = v4;
    while (1)
    {
      if (*(void *)v20 == -8192)
      {
        if (*((void *)v20 + 1) == -8192 && *((void *)v20 + 2) == -8192) {
          goto LABEL_15;
        }
      }
      else if (*(void *)v20 == -4096 && *((void *)v20 + 1) == -4096 && *((void *)v20 + 2) == -4096)
      {
        goto LABEL_15;
      }
      int v29 = 0;
      llvm::DenseMapBase<llvm::DenseMap<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>,std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *,llvm::DenseMapInfo<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,void>,llvm::detail::DenseMapPair<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>,mlir::Operation *>>::LookupBucketFor<std::tuple<mlir::Dialect *,mlir::Attribute,mlir::Type>>((uint64_t *)a1, v20, &v29);
      int v21 = v29;
      void *v29 = *(void *)v20;
      v21[1] = *((void *)v20 + 1);
      unint64_t v21[2] = *((void *)v20 + 2);
      void v21[3] = *((void *)v20 + 3);
      ++*(_DWORD *)(a1 + 8);
LABEL_15:
      unsigned int v20 = (llvm *)((char *)v20 + 32);
      v19 -= 32;
      if (!v19) {
        goto LABEL_24;
      }
    }
  }
  *(void *)(a1 + 8) = 0;
  uint64_t v22 = *(unsigned int *)(a1 + 16);
  if (v22)
  {
    if (((v22 - 1) & 0x7FFFFFFFFFFFFFFLL) == 0) {
      goto LABEL_30;
    }
    uint64_t v23 = ((v22 - 1) & 0x7FFFFFFFFFFFFFFLL) + 1;
    unint64_t v10 = &result[32 * (v23 & 0xFFFFFFFFFFFFFFELL)];
    uint64_t v24 = (int64x2_t *)(result + 40);
    int64x2_t v25 = vdupq_n_s64(0xFFFFFFFFFFFFF000);
    uint64_t v26 = v23 & 0xFFFFFFFFFFFFFFELL;
    do
    {
      v24[-3].i64[1] = -4096;
      v24[-1].i64[1] = -4096;
      v24[-2] = v25;
      *uint64_t v24 = v25;
      v24 += 4;
      v26 -= 2;
    }
    while (v26);
    if (v23 != (v23 & 0xFFFFFFFFFFFFFFELL))
    {
LABEL_30:
      unsigned int v27 = &result[32 * v22];
      int64x2_t v28 = vdupq_n_s64(0xFFFFFFFFFFFFF000);
      do
      {
        *(void *)unint64_t v10 = -4096;
        *(int64x2_t *)(v10 + 8) = v28;
        v10 += 32;
      }
      while (v10 != v27);
    }
  }
  return result;
}

uint64_t *llvm::DenseMapBase<llvm::DenseMap<mlir::Operation *,llvm::SmallVector<mlir::Dialect *,2u>,llvm::DenseMapInfo<mlir::Operation *,void>,llvm::detail::DenseMapPair<mlir::Operation *,llvm::SmallVector<mlir::Dialect *,2u>>>,mlir::Operation *,llvm::SmallVector<mlir::Dialect *,2u>,llvm::DenseMapInfo<mlir::Operation *,void>,llvm::detail::DenseMapPair<mlir::Operation *,llvm::SmallVector<mlir::Dialect *,2u>>>::InsertIntoBucket<mlir::Operation * const&>(uint64_t a1, uint64_t *a2, uint64_t *a3)
{
  int v5 = *(_DWORD *)(a1 + 8);
  uint64_t v6 = *(unsigned int *)(a1 + 16);
  if (4 * v5 + 4 >= (3 * v6))
  {
    int v9 = 2 * v6;
  }
  else
  {
    if ((int)v6 + ~v5 - *(_DWORD *)(a1 + 12) > v6 >> 3)
    {
LABEL_3:
      uint64_t v7 = *a2;
      goto LABEL_4;
    }
    int v9 = *(_DWORD *)(a1 + 16);
  }
  unint64_t v10 = *(uint64_t **)a1;
  unint64_t v11 = (v9 - 1) | ((unint64_t)(v9 - 1) >> 1);
  unint64_t v12 = v11 | (v11 >> 2) | ((v11 | (v11 >> 2)) >> 4);
  int v13 = ((v12 | (v12 >> 8)) >> 16) | v12 | (v12 >> 8);
  if ((v13 + 1) > 0x40) {
    unsigned int v14 = v13 + 1;
  }
  else {
    unsigned int v14 = 64;
  }
  *(_DWORD *)(a1 + 16) = v14;
  buffer = llvm::allocate_buffer(40 * v14, (std::align_val_t)8uLL);
  *(void *)a1 = buffer;
  if (v10)
  {
    uint64_t v16 = 5 * v6;
    llvm::DenseMapBase<llvm::DenseMap<mlir::OperationName,llvm::SmallVector<mlir::RewritePattern const*,2u>,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,llvm::SmallVector<mlir::RewritePattern const*,2u>>>,mlir::OperationName,llvm::SmallVector<mlir::RewritePattern const*,2u>,llvm::DenseMapInfo<mlir::OperationName,void>,llvm::detail::DenseMapPair<mlir::OperationName,llvm::SmallVector<mlir::RewritePattern const*,2u>>>::moveFromOldBuckets(a1, v10, &v10[v16]);
    llvm::deallocate_buffer((llvm *)v10, (void *)(v16 * 8));
  }
  *(void *)(a1 + 8) = 0;
  uint64_t v17 = *(unsigned int *)(a1 + 16);
  unint64_t v18 = 40 * v17 - 40;
  uint64_t v19 = buffer;
  if (v18 < 0x28) {
    goto LABEL_34;
  }
  unint64_t v20 = v18 / 0x28 + 1;
  uint64_t v19 = &buffer[5 * (v20 & 0xFFFFFFFFFFFFFFELL)];
  uint64_t v21 = v20 & 0xFFFFFFFFFFFFFFELL;
  uint64_t v22 = buffer;
  do
  {
    *uint64_t v22 = -4096;
    void v22[5] = -4096;
    v22 += 10;
    v21 -= 2;
  }
  while (v21);
  if (v20 != (v20 & 0xFFFFFFFFFFFFFFELL))
  {
LABEL_34:
    do
    {
      *uint64_t v19 = -4096;
      v19 += 5;
    }
    while (v19 != &buffer[5 * v17]);
  }
  uint64_t v7 = *a3;
  int v23 = v17 - 1;
  unsigned int v24 = ((*a3 >> 4) ^ (*a3 >> 9)) & v23;
  a2 = &buffer[5 * v24];
  uint64_t v25 = *a2;
  if (*a3 != *a2)
  {
    uint64_t v26 = 0;
    int v27 = 1;
    while (v25 != -4096)
    {
      if (v26) {
        BOOL v28 = 0;
      }
      else {
        BOOL v28 = v25 == -8192;
      }
      if (v28) {
        uint64_t v26 = a2;
      }
      unsigned int v29 = v24 + v27++;
      unsigned int v24 = v29 & v23;
      a2 = &buffer[5 * v24];
      uint64_t v25 = *a2;
      if (v7 == *a2) {
        goto LABEL_4;
      }
    }
    if (v26) {
      a2 = v26;
    }
    goto LABEL_3;
  }
LABEL_4:
  ++*(_DWORD *)(a1 + 8);
  if (v7 != -4096) {
    --*(_DWORD *)(a1 + 12);
  }
  *a2 = *a3;
  a2[1] = (uint64_t)(a2 + 3);
  a2[2] = 0x200000000;
  return a2;
}

void mlir::applyPatternsAndFoldGreedily(mlir::Region **this, const mlir::FrozenRewritePatternSet *a2, long long *a3, BOOL *a4)
{
  v121[1] = *MEMORY[0x263EF8340];
  if (!*((void *)a3 + 3)) {
    *((void *)a3 + 3) = this;
  }
  uint64_t Context = (mlir::MLIRContext *)mlir::Region::getContext((mlir::Region *)this);
  unsigned int v93 = 0;
  uint64_t v94 = 0;
  uint64_t v95 = 0;
  int v97 = 1;
  unsigned int v91 = &unk_26C358998;
  int v101 = 0;
  uint64_t v102 = 0;
  uint64_t v96 = &unk_26C358A50;
  unsigned int v103 = 0;
  uint64_t v98 = (char *)operator new(0x200uLL);
  int v99 = v98;
  uint64_t v104 = 0;
  uint64_t v105 = 0;
  uint64_t v100 = v98 + 512;
  int v106 = 0;
  uint64_t v107 = 0;
  uint64_t v108 = 0;
  int v109 = 0;
  mlir::DialectInterfaceCollection<mlir::DialectFoldInterface>::DialectInterfaceCollection(v110, Context);
  v110[8] = Context;
  v110[9] = &v96;
  v110[10] = 0;
  v110[11] = 0;
  long long v8 = a3[2];
  long long v9 = *a3;
  long long v112 = a3[1];
  long long v113 = v8;
  v110[7] = &unk_26C35C560;
  long long v111 = v9;
  uint64_t v114 = 1;
  uint64_t v115 = -4096;
  uint64_t v116 = -4096;
  uint64_t v117 = -4096;
  uint64_t v118 = -4096;
  uint64_t v86 = (uint64_t **)mlir::PatternApplicator::PatternApplicator((uint64_t)&v119, a2);
  mlir::PatternApplicator::applyCostModel(v86, llvm::function_ref<mlir::PatternBenefit ()(mlir::Pattern const&)>::callback_fn<mlir::PatternApplicator::applyDefaultCostModel(void)::{lambda(mlir::Pattern const&)#1}>, (uint64_t)&v87);
  unsigned int v93 = &v96;
  unsigned int v91 = &unk_26C358AA8;
  uint64_t v96 = &unk_26C358B60;
  unint64_t v120 = (unint64_t)this;
  if (*((_DWORD *)a3 + 8))
  {
    uint64_t v87 = &v91;
    for (unint64_t i = this[1]; i != (mlir::Region *)this; unint64_t i = (mlir::Region *)*((void *)i + 1))
    {
      unint64_t v11 = (void *)((char *)i - 8);
      if (!i) {
        unint64_t v11 = 0;
      }
      unint64_t v12 = (ZinIrHalH13g *)(v11 + 4);
      int v13 = (ZinIrHalH13g *)v11[5];
      if (v13 != (ZinIrHalH13g *)(v11 + 4))
      {
        do
        {
          unsigned int v14 = (ZinIrHalH13g *)*((void *)v13 + 1);
          ZinIrHalH13g::~ZinIrHalH13g(v13);
          int v13 = v14;
        }
        while (v14 != v12);
      }
    }
  }
  uint64_t v90 = &v91;
  char v89 = 0;
  uint64_t v16 = (uint64_t *)Context;
  if (*((uint64_t *)&v111 + 1) <= 0 && *((void *)&v111 + 1) != -1)
  {
    uint64_t v17 = 0;
    unint64_t v18 = (mlir::PatternApplicator *)v86;
    if (a4) {
      goto LABEL_117;
    }
    goto LABEL_118;
  }
  uint64_t v85 = a4;
  uint64_t v17 = 0;
  uint64_t v19 = 1;
  while (1)
  {
    uint64_t v20 = v19;
    int v99 = v98;
    if (!v102) {
      goto LABEL_45;
    }
    uint64_t v21 = v103;
    if (v103 <= 4 * (int)v102 || v103 < 0x41)
    {
      if (v103)
      {
        unint64_t v31 = v101;
        uint64_t v32 = (v103 - 1) & 0xFFFFFFFFFFFFFFFLL;
        if (v32)
        {
          uint64_t v33 = v32 + 1;
          uint64_t v34 = (v32 + 1) & 0x1FFFFFFFFFFFFFFELL;
          int v35 = (llvm *)((char *)v101 + 16 * v34);
          unsigned int v36 = (void *)((char *)v101 + 16);
          uint64_t v37 = v34;
          do
          {
            *(v36 - 2) = -4096;
            *unsigned int v36 = -4096;
            v36 += 4;
            v37 -= 2;
          }
          while (v37);
          if (v33 == v34) {
            goto LABEL_41;
          }
        }
        else
        {
          int v35 = v101;
        }
        uint64_t v38 = (llvm *)((char *)v31 + 16 * v21);
        do
        {
          *(void *)int v35 = -4096;
          int v35 = (llvm *)((char *)v35 + 16);
        }
        while (v35 != v38);
      }
LABEL_41:
      uint64_t v102 = 0;
      goto LABEL_45;
    }
    int v22 = 1 << (33 - __clz(v102 - 1));
    if (v22 <= 64) {
      int v22 = 64;
    }
    if (v102) {
      int v23 = v22;
    }
    else {
      int v23 = 0;
    }
    if (v23 != v103) {
      llvm::deallocate_buffer(v101, (void *)(16 * v103));
    }
    uint64_t v102 = 0;
    unsigned int v24 = v101;
    uint64_t v25 = (v103 - 1) & 0xFFFFFFFFFFFFFFFLL;
    if (!v25) {
      break;
    }
    uint64_t v26 = v25 + 1;
    uint64_t v27 = (v25 + 1) & 0x1FFFFFFFFFFFFFFELL;
    BOOL v28 = (llvm *)((char *)v101 + 16 * v27);
    unsigned int v29 = (void *)((char *)v101 + 16);
    uint64_t v30 = v27;
    do
    {
      *(v29 - 2) = -4096;
      void *v29 = -4096;
      v29 += 4;
      v30 -= 2;
    }
    while (v30);
    if (v26 != v27) {
      goto LABEL_43;
    }
LABEL_45:
    unint64_t v40 = v120;
    if ((_BYTE)v111)
    {
      uint64_t v87 = (void **)&v90;
      uint64_t v88 = (_anonymous_namespace_::GreedyPatternRewriteDriver *)&v91;
      BOOL v41 = *(void **)(v120 + 8);
      if (v41 != (void *)v120)
      {
        do
        {
          unsigned int v42 = v41 - 1;
          if (!v41) {
            unsigned int v42 = 0;
          }
          int32x2_t v43 = (ZinIrHalH13g *)(v42 + 4);
          uint64_t v44 = (ZinIrHalH13g *)v42[5];
          while (v44 != v43)
          {
            int32x2_t v45 = (ZinIrHalH13g *)*((void *)v44 + 1);
            ZinIrHalH13g::~ZinIrHalH13g(v44);
            uint64_t v44 = v45;
            if (!v47) {
              goto LABEL_54;
            }
          }
          BOOL v41 = (void *)v41[1];
        }
        while (v41 != (void *)v40);
      }
LABEL_54:
      int32x2_t v48 = v98;
      uint64_t v49 = v99;
      uint64_t v50 = v99 - 8;
      if (v98 != v99 && v50 > v98)
      {
        uint64_t v52 = v98 + 8;
        do
        {
          uint64_t v53 = *((void *)v52 - 1);
          *((void *)v52 - 1) = *(void *)v50;
          *(void *)uint64_t v50 = v53;
          v50 -= 8;
          BOOL v54 = v52 >= v50;
          v52 += 8;
        }
        while (!v54);
        int32x2_t v48 = v98;
        uint64_t v49 = v99;
      }
      if (v49 != v48)
      {
        uint64_t v55 = 0;
        uint64_t v56 = (v49 - v48) >> 3;
        while (1)
        {
          uint64_t v62 = v98;
          int v63 = v103;
          if (!v103) {
            goto LABEL_86;
          }
          uint64_t v57 = *(void *)&v98[8 * v55];
          unsigned int v58 = v103 - 1;
          unsigned int v59 = ((v57 >> 4) ^ (v57 >> 9)) & (v103 - 1);
          uint64_t v60 = (char *)v101 + 16 * v59;
          uint64_t v61 = *(void *)v60;
          if (v57 != *(void *)v60) {
            break;
          }
LABEL_66:
          *((_DWORD *)v60 + 2) = v55++;
          if (v55 == v56) {
            goto LABEL_108;
          }
        }
        long long v65 = 0;
        int v66 = 1;
        while (v61 != -4096)
        {
          if (v65) {
            BOOL v67 = 0;
          }
          else {
            BOOL v67 = v61 == -8192;
          }
          if (v67) {
            long long v65 = v60;
          }
          unsigned int v68 = v59 + v66++;
          unsigned int v59 = v68 & v58;
          uint64_t v60 = (char *)v101 + 16 * (v68 & v58);
          uint64_t v61 = *(void *)v60;
          if (v57 == *(void *)v60) {
            goto LABEL_66;
          }
        }
        if (v65) {
          uint64_t v60 = v65;
        }
        if (4 * (int)v102 + 4 < 3 * v103)
        {
          if (v103 + ~v102 - HIDWORD(v102) <= v103 >> 3) {
            goto LABEL_87;
          }
LABEL_70:
          uint64_t v64 = *(void *)v60;
        }
        else
        {
LABEL_86:
          int v63 = 2 * v103;
LABEL_87:
          llvm::DenseMap<void const*,unsigned int,llvm::DenseMapInfo<void const*,void>,llvm::detail::DenseMapPair<void const*,unsigned int>>::grow((uint64_t)&v101, v63);
          uint64_t v64 = *(void *)&v62[8 * v55];
          unsigned int v69 = v103 - 1;
          unsigned int v70 = ((v64 >> 4) ^ (v64 >> 9)) & (v103 - 1);
          uint64_t v60 = (char *)v101 + 16 * v70;
          uint64_t v71 = *(void *)v60;
          if (v64 != *(void *)v60)
          {
            uint64_t v72 = 0;
            int v73 = 1;
            while (v71 != -4096)
            {
              if (v72) {
                BOOL v74 = 0;
              }
              else {
                BOOL v74 = v71 == -8192;
              }
              if (v74) {
                uint64_t v72 = v60;
              }
              unsigned int v75 = v70 + v73++;
              unsigned int v70 = v75 & v69;
              uint64_t v60 = (char *)v101 + 16 * (v75 & v69);
              uint64_t v71 = *(void *)v60;
              if (v64 == *(void *)v60) {
                goto LABEL_71;
              }
            }
            if (v72) {
              uint64_t v60 = v72;
            }
            goto LABEL_70;
          }
        }
LABEL_71:
        LODWORD(v102) = v102 + 1;
        if (v64 != -4096) {
          --HIDWORD(v102);
        }
        *(void *)uint64_t v60 = *(void *)&v62[8 * v55];
        *((_DWORD *)v60 + 2) = 0;
        goto LABEL_66;
      }
    }
    else
    {
      uint64_t v87 = (void **)&v90;
      uint64_t v88 = (_anonymous_namespace_::GreedyPatternRewriteDriver *)&v91;
      for (uint64_t j = *(void *)(v120 + 8); j != v40; uint64_t j = *(void *)(j + 8))
      {
        uint64_t v77 = j - 8;
        if (!j) {
          uint64_t v77 = 0;
        }
        unsigned int v78 = (ZinIrHalH13g *)(v77 + 32);
        uint64_t v79 = *(ZinIrHalH13g **)(v77 + 40);
        if (v79 != (ZinIrHalH13g *)(v77 + 32))
        {
          do
          {
            unint64_t v80 = (ZinIrHalH13g *)*((void *)v79 + 1);
            ZinIrHalH13g::~ZinIrHalH13g(v79);
            uint64_t v79 = v80;
          }
          while (v80 != v78);
        }
      }
    }
LABEL_108:
    uint64_t v87 = (void **)&v89;
    uint64_t v88 = (_anonymous_namespace_::GreedyPatternRewriteDriver *)&v91;
    v121[0] = v120 & 0xFFFFFFFFFFFFFFF9 | 2;
    if (mlir::MLIRContext::hasActionHandler((mlir::MLIRContext *)v16))
    {
      if (!v89) {
        goto LABEL_116;
      }
    }
    else
    {
      uint64_t v83 = v88;
      *(unsigned char *)uint64_t v87 = v84;
      if (*((unsigned char *)v83 + 249)) {
        mlir::simplifyRegions((uint64_t)v83, *((void **)v83 + 50), 1uLL);
      }
      if (!v89) {
        goto LABEL_116;
      }
    }
    uint64_t v19 = v20 + 1;
    uint64_t v17 = v20;
    if (v20 >= *((uint64_t *)&v111 + 1))
    {
      uint64_t v17 = v20;
      if (*((void *)&v111 + 1) != -1)
      {
        uint64_t v17 = 1;
LABEL_116:
        a4 = v85;
        unint64_t v18 = (mlir::PatternApplicator *)v86;
        if (v85) {
LABEL_117:
        }
          *a4 = v17 != 0;
LABEL_118:
        unsigned int v91 = &unk_26C358998;
        uint64_t v96 = &unk_26C358A50;
        mlir::PatternApplicator::~PatternApplicator(v18);
      }
    }
  }
  BOOL v28 = v101;
LABEL_43:
  char v39 = (llvm *)((char *)v24 + 16 * v21);
  do
  {
    *(void *)BOOL v28 = -4096;
    BOOL v28 = (llvm *)((char *)v28 + 16);
  }
  while (v28 != v39);
  goto LABEL_45;
}

void sub_211900120(int a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33,uint64_t a34,uint64_t a35,uint64_t a36,uint64_t a37,uint64_t a38,uint64_t a39,uint64_t a40,uint64_t a41,uint64_t a42,uint64_t a43,uint64_t a44,uint64_t a45,uint64_t a46,uint64_t a47,uint64_t a48,uint64_t a49,uint64_t a50,uint64_t a51,uint64_t a52,uint64_t a53,uint64_t a54,uint64_t a55,uint64_t a56,uint64_t a57,char a58,llvm *a59,unsigned int a60)
{
  if ((a58 & 1) == 0) {
    llvm::deallocate_buffer(a59, (void *)(8 * a60));
  }
  mlir::OperationFolder::~OperationFolder(v60);
}

void sub_211900144(int a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,llvm *a31,uint64_t a32,unsigned int a33)
{
}

uint64_t sub_211900158()
{
  if (v3)
  {
    uint64_t v4 = v3;
    operator delete(v3);
  }
  ZinIrHalH13g::~ZinIrHalH13g((ZinIrHalH13g *)&v2);
  return v1;
}

void anonymous namespace'::RegionPatternRewriteDriver::~RegionPatternRewriteDriver(_anonymous_namespace_::RegionPatternRewriteDriver *this)
{
  *(void *)this = &unk_26C358998;
  *((void *)this + 5) = &unk_26C358A50;
  mlir::PatternApplicator::~PatternApplicator((_anonymous_namespace_::RegionPatternRewriteDriver *)((char *)this + 336));
}

{
  *(void *)this = &unk_26C358998;
  *((void *)this + 5) = &unk_26C358A50;
  mlir::PatternApplicator::~PatternApplicator((_anonymous_namespace_::RegionPatternRewriteDriver *)((char *)this + 336));
}

void sub_211900208()
{
  if ((*(unsigned char *)(v0 + 296) & 1) == 0) {
    llvm::deallocate_buffer(*(llvm **)(v0 + 304), (void *)(8 * *(unsigned int *)(v0 + 312)));
  }
  mlir::OperationFolder::~OperationFolder((mlir::OperationFolder *)(v0 + 104));
}

void sub_21190022C()
{
  llvm::deallocate_buffer(*(llvm **)(v0 + 80), (void *)(16 * *(unsigned int *)(v0 + 96)));
}

void sub_211900240(int a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12)
{
  int v13 = (void *)*((void *)v12 + 7);
  if (v13)
  {
    *((void *)v12 + 8) = v13;
    operator delete(v13);
  }
  ZinIrHalH13g::~ZinIrHalH13g(v12);
}

void sub_2119002C8()
{
  if ((*(unsigned char *)(v0 + 296) & 1) == 0) {
    llvm::deallocate_buffer(*(llvm **)(v0 + 304), (void *)(8 * *(unsigned int *)(v0 + 312)));
  }
  mlir::OperationFolder::~OperationFolder((mlir::OperationFolder *)(v0 + 104));
}

void sub_2119002EC()
{
  llvm::deallocate_buffer(*(llvm **)(v0 + 80), (void *)(16 * *(unsigned int *)(v0 + 96)));
}

void sub_211900300(int a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12)
{
  int v13 = (void *)*((void *)v12 + 7);
  if (v13)
  {
    *((void *)v12 + 8) = v13;
    operator delete(v13);
  }
  ZinIrHalH13g::~ZinIrHalH13g(v12);
  JUMPOUT(0x21667D3C0);
}

uint64_t mlir::PatternRewriter::canRecoverFromRewriteFailure(mlir::PatternRewriter *this)
{
  return 0;
}

void anonymous namespace'::GreedyPatternRewriteDriver::notifyOperationModified(_anonymous_namespace_::GreedyPatternRewriteDriver *this, mlir::Operation *a2)
{
  uint64_t v4 = *((void *)this + 36);
  if (v4) {
    (*(void (**)(uint64_t, mlir::Operation *))(*(void *)v4 + 32))(v4, a2);
  }
}

void anonymous namespace'::GreedyPatternRewriteDriver::notifyOperationInserted(_anonymous_namespace_::GreedyPatternRewriteDriver *this, mlir::Operation *a2)
{
  uint64_t v2 = a2;
  uint64_t v16 = a2;
  uint64_t v4 = *((void *)this + 36);
  if (v4) {
    (*(void (**)(uint64_t, mlir::Operation *))(*(void *)v4 + 16))(v4, a2);
  }
  if (*((_DWORD *)this + 70) == 1)
  {
    if (*((unsigned char *)this + 296))
    {
      uint64_t v6 = (char *)this + 304;
      int v5 = 4;
    }
    else
    {
      int v5 = *((_DWORD *)this + 78);
      if (!v5)
      {
        unint64_t v11 = 0;
        goto LABEL_11;
      }
      uint64_t v6 = (char *)*((void *)this + 38);
    }
    int v7 = v5 - 1;
    unsigned int v8 = ((v2 >> 4) ^ (v2 >> 9)) & v7;
    long long v9 = (int *)&v6[8 * v8];
    unint64_t v10 = *(mlir::Operation **)v9;
    if (*(mlir::Operation **)v9 == v2) {
      goto LABEL_9;
    }
    unint64_t v12 = 0;
    int v13 = 1;
    while (v10 != (mlir::Operation *)-4096)
    {
      if (v12) {
        BOOL v14 = 0;
      }
      else {
        BOOL v14 = v10 == (mlir::Operation *)-8192;
      }
      if (v14) {
        unint64_t v12 = v9;
      }
      unsigned int v15 = v8 + v13++;
      unsigned int v8 = v15 & v7;
      long long v9 = (int *)&v6[8 * v8];
      unint64_t v10 = *(mlir::Operation **)v9;
      if (*(mlir::Operation **)v9 == v2) {
        goto LABEL_9;
      }
    }
    if (v12) {
      unint64_t v11 = v12;
    }
    else {
      unint64_t v11 = v9;
    }
LABEL_11:
    llvm::DenseMapBase<llvm::SmallDenseMap<mlir::Operation *,llvm::detail::DenseSetEmpty,4u,llvm::DenseMapInfo<mlir::Operation *,void>,llvm::detail::DenseSetPair<mlir::Operation *>>,mlir::Operation *,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::Operation *,void>,llvm::detail::DenseSetPair<mlir::Operation *>>::InsertIntoBucket<mlir::Operation * const&,llvm::detail::DenseSetEmpty&>((int *)this + 74, v11, &v16);
    uint64_t v2 = v16;
  }
LABEL_9:
}

void anonymous namespace'::GreedyPatternRewriteDriver::notifyOperationRemoved(int32x2_t *this, mlir::Operation *a2)
{
  uint64_t v32 = *MEMORY[0x263EF8340];
  int32x2_t v4 = this[36];
  if (v4) {
    (*(void (**)(int32x2_t, mlir::Operation *))(**(void **)&v4 + 56))(v4, a2);
  }
  if ((*((unsigned char *)a2 + 46) & 0x80) != 0)
  {
    mlir::ValueRange::ValueRange(&v28, *((void *)a2 + 9), *((unsigned int *)a2 + 17));
    unint64_t v5 = v28;
    uint64_t v6 = v29;
    unint64_t v30 = v28;
    uint64_t v31 = 0;
    if (!v29) {
      goto LABEL_16;
    }
  }
  else
  {
    mlir::ValueRange::ValueRange(&v28, 0, 0);
    unint64_t v5 = v28;
    uint64_t v6 = v29;
    unint64_t v30 = v28;
    uint64_t v31 = 0;
    if (!v29) {
      goto LABEL_16;
    }
  }
  uint64_t v7 = 0;
  do
  {
    long long v9 = (void *)mlir::ValueRange::dereference_iterator(&v30, v7);
    uint64_t v27 = v9;
    if (v9 && (!*v9 || !*(void *)*v9))
    {
      uint64_t DefiningOp = (mlir::Operation *)mlir::Value::getDefiningOp((mlir::Value *)&v27);
      if (DefiningOp) {
    }
      }
    uint64_t v7 = ++v31;
  }
  while (v30 != v5 || v7 != v6);
LABEL_16:
  int32x2_t v11 = this[10];
  uint64_t v12 = this[12].u32[0];
  unsigned int v13 = a2 >> 4;
  if (v12)
  {
    LODWORD(v14) = (v12 - 1) & (v13 ^ (a2 >> 9));
    uint64_t v15 = *(void *)&v11 + 16 * v14;
    uint64_t v16 = *(mlir::Operation **)v15;
    if (*(mlir::Operation **)v15 == a2) {
      goto LABEL_23;
    }
    int v17 = 1;
    while (v16 != (mlir::Operation *)-4096)
    {
      int v18 = v14 + v17++;
      uint64_t v14 = v18 & (v12 - 1);
      uint64_t v16 = *(mlir::Operation **)(*(void *)&v11 + 16 * v14);
      if (v16 == a2)
      {
        uint64_t v15 = *(void *)&v11 + 16 * v14;
        goto LABEL_23;
      }
    }
  }
  uint64_t v15 = *(void *)&v11 + 16 * v12;
LABEL_23:
  if (v15 != *(void *)&v11 + 16 * v12)
  {
    *(void *)(*(void *)&this[7] + 8 * *(unsigned int *)(v15 + 8)) = 0;
    *(void *)uint64_t v15 = -8192;
    this[11] = vadd_s32(this[11], (int32x2_t)0x1FFFFFFFFLL);
  }
  mlir::OperationFolder::notifyRemoval(this + 13, a2);
  if (this[35].i32[0])
  {
    if (this[37].i8[0])
    {
      uint64_t v20 = this + 38;
      int v19 = 4;
    }
    else
    {
      int v19 = this[39].i32[0];
      if (!v19) {
        return;
      }
      uint64_t v20 = (int32x2_t *)this[38];
    }
    int v21 = v19 - 1;
    LODWORD(v22) = (v19 - 1) & (v13 ^ (a2 >> 9));
    int v23 = (mlir::Operation **)&v20[v22];
    unsigned int v24 = *v23;
    if (*v23 == a2)
    {
LABEL_31:
      char *v23 = (mlir::Operation *)-8192;
      this[37].i32[0] -= 2;
      ++this[37].i32[1];
    }
    else
    {
      int v25 = 1;
      while (v24 != (mlir::Operation *)-4096)
      {
        int v26 = v22 + v25++;
        uint64_t v22 = v26 & v21;
        unsigned int v24 = (mlir::Operation *)v20[v22];
        if (v24 == a2)
        {
          int v23 = (mlir::Operation **)&v20[v22];
          goto LABEL_31;
        }
      }
    }
  }
}

void anonymous namespace'::GreedyPatternRewriteDriver::notifyOperationReplaced(_anonymous_namespace_::GreedyPatternRewriteDriver *a1, uint64_t a2)
{
  v19[8] = *MEMORY[0x263EF8340];
  uint64_t v4 = *((void *)a1 + 36);
  if (v4) {
    (*(void (**)(uint64_t, uint64_t))(*(void *)v4 + 48))(v4, a2);
  }
  uint64_t v5 = *(unsigned int *)(a2 + 36);
  if (v5) {
    uint64_t v6 = a2 - 16;
  }
  else {
    uint64_t v6 = 0;
  }
  if (v5)
  {
    for (uint64_t i = 0; i != v5; ++i)
    {
      for (uint64_t j = *(void **)mlir::detail::OpResultImpl::getNextResultAtOffset(v6, i); j; uint64_t j = (void *)*j)
      {
        uint64_t v9 = j[2];
        int v17 = v19;
        uint64_t v18 = 0x800000000;
        while (1)
        {
          uint64_t v10 = v18;
          if (v18 >= (unint64_t)HIDWORD(v18))
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v17, v19, v18 + 1, 8);
            uint64_t v10 = v18;
          }
          *((void *)v17 + v10) = v9;
          unsigned int v11 = v18 + 1;
          LODWORD(v18) = v18 + 1;
          uint64_t v12 = *(mlir::Block **)(v9 + 16);
          if (!v12) {
            break;
          }
          unint64_t Parent = mlir::Block::getParent(v12);
          if (*((void *)a1 + 34) == Parent)
          {
            unsigned int v11 = v18;
            if (!v18) {
              goto LABEL_26;
            }
            goto LABEL_24;
          }
          if (Parent)
          {
            uint64_t v9 = *(void *)(Parent + 16);
            if (v9) {
              continue;
            }
          }
          goto LABEL_26;
        }
        if (!*((void *)a1 + 34) && v11)
        {
LABEL_24:
          uint64_t v14 = (mlir::Operation **)v17;
          uint64_t v15 = 8 * v11;
          do
          {
            uint64_t v16 = *v14++;
            v15 -= 8;
          }
          while (v15);
        }
LABEL_26:
        if (v17 != v19) {
          free(v17);
        }
      }
    }
  }
}

uint64_t anonymous namespace'::GreedyPatternRewriteDriver::notifyBlockCreated(_anonymous_namespace_::GreedyPatternRewriteDriver *this, mlir::Block *a2)
{
  uint64_t result = *((void *)this + 36);
  if (result) {
    return (*(uint64_t (**)(uint64_t, mlir::Block *))(*(void *)result + 24))(result, a2);
  }
  return result;
}

uint64_t anonymous namespace'::GreedyPatternRewriteDriver::notifyMatchFailure(uint64_t a1)
{
  uint64_t result = *(void *)(a1 + 288);
  if (result) {
    return (*(uint64_t (**)(void))(*(void *)result + 64))();
  }
  return result;
}

void non-virtual thunk to'anonymous namespace'::RegionPatternRewriteDriver::~RegionPatternRewriteDriver(_anonymous_namespace_::RegionPatternRewriteDriver *this)
{
  *((void *)this - 5) = &unk_26C358998;
  *(void *)this = &unk_26C358A50;
  mlir::PatternApplicator::~PatternApplicator((_anonymous_namespace_::RegionPatternRewriteDriver *)((char *)this + 296));
}

{
}

void sub_2119009A8()
{
  if ((*(unsigned char *)(v0 + 256) & 1) == 0) {
    llvm::deallocate_buffer(*(llvm **)(v0 + 264), (void *)(8 * *(unsigned int *)(v0 + 272)));
  }
  mlir::OperationFolder::~OperationFolder((mlir::OperationFolder *)(v0 + 64));
}

void sub_2119009CC()
{
  llvm::deallocate_buffer(*(llvm **)(v0 + 40), (void *)(16 * *(unsigned int *)(v0 + 56)));
}

void sub_2119009E0(int a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12)
{
  uint64_t v14 = *(void **)(v13 + 16);
  if (v14)
  {
    *(void *)(v13 + 24) = v14;
    operator delete(v14);
  }
  ZinIrHalH13g::~ZinIrHalH13g(v12);
}

void non-virtual thunk to'anonymous namespace'::GreedyPatternRewriteDriver::notifyOperationInserted(_anonymous_namespace_::GreedyPatternRewriteDriver *this, mlir::Operation *a2)
{
}

uint64_t non-virtual thunk to'anonymous namespace'::GreedyPatternRewriteDriver::notifyBlockCreated(_anonymous_namespace_::GreedyPatternRewriteDriver *this, mlir::Block *a2)
{
  uint64_t result = *((void *)this + 31);
  if (result) {
    return (*(uint64_t (**)(uint64_t, mlir::Block *))(*(void *)result + 24))(result, a2);
  }
  return result;
}

void non-virtual thunk to'anonymous namespace'::GreedyPatternRewriteDriver::notifyOperationModified(_anonymous_namespace_::GreedyPatternRewriteDriver *this, mlir::Operation *a2)
{
  uint64_t v4 = *((void *)this + 31);
  if (v4) {
    (*(void (**)(uint64_t, mlir::Operation *))(*(void *)v4 + 32))(v4, a2);
  }
}

void non-virtual thunk to'anonymous namespace'::GreedyPatternRewriteDriver::notifyOperationReplaced(uint64_t a1, uint64_t a2)
{
}

void non-virtual thunk to'anonymous namespace'::GreedyPatternRewriteDriver::notifyOperationRemoved(int32x2_t *this, mlir::Operation *a2)
{
}

uint64_t non-virtual thunk to'anonymous namespace'::GreedyPatternRewriteDriver::notifyMatchFailure(uint64_t a1)
{
  uint64_t result = *(void *)(a1 + 248);
  if (result) {
    return (*(uint64_t (**)(void))(*(void *)result + 64))();
  }
  return result;
}

void anonymous namespace'::GreedyPatternRewriteDriver::~GreedyPatternRewriteDriver(_anonymous_namespace_::GreedyPatternRewriteDriver *this)
{
  *(void *)this = &unk_26C358998;
  *((void *)this + 5) = &unk_26C358A50;
  mlir::PatternApplicator::~PatternApplicator((_anonymous_namespace_::GreedyPatternRewriteDriver *)((char *)this + 336));
}

{
  *(void *)this = &unk_26C358998;
  *((void *)this + 5) = &unk_26C358A50;
  mlir::PatternApplicator::~PatternApplicator((_anonymous_namespace_::GreedyPatternRewriteDriver *)((char *)this + 336));
}

void sub_211900B54()
{
  if ((*(unsigned char *)(v0 + 296) & 1) == 0) {
    llvm::deallocate_buffer(*(llvm **)(v0 + 304), (void *)(8 * *(unsigned int *)(v0 + 312)));
  }
  mlir::OperationFolder::~OperationFolder((mlir::OperationFolder *)(v0 + 104));
}

void sub_211900B78()
{
  llvm::deallocate_buffer(*(llvm **)(v0 + 80), (void *)(16 * *(unsigned int *)(v0 + 96)));
}

void sub_211900B8C(int a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12)
{
  uint64_t v13 = (void *)*((void *)v12 + 7);
  if (v13)
  {
    *((void *)v12 + 8) = v13;
    operator delete(v13);
  }
  ZinIrHalH13g::~ZinIrHalH13g(v12);
}

void sub_211900C14()
{
  if ((*(unsigned char *)(v0 + 296) & 1) == 0) {
    llvm::deallocate_buffer(*(llvm **)(v0 + 304), (void *)(8 * *(unsigned int *)(v0 + 312)));
  }
  mlir::OperationFolder::~OperationFolder((mlir::OperationFolder *)(v0 + 104));
}

void sub_211900C38()
{
  llvm::deallocate_buffer(*(llvm **)(v0 + 80), (void *)(16 * *(unsigned int *)(v0 + 96)));
}

void sub_211900C4C(int a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12)
{
  uint64_t v13 = (void *)*((void *)v12 + 7);
  if (v13)
  {
    *((void *)v12 + 8) = v13;
    operator delete(v13);
  }
  ZinIrHalH13g::~ZinIrHalH13g(v12);
  JUMPOUT(0x21667D3C0);
}

void non-virtual thunk to'anonymous namespace'::GreedyPatternRewriteDriver::~GreedyPatternRewriteDriver(_anonymous_namespace_::GreedyPatternRewriteDriver *this)
{
  *((void *)this - 5) = &unk_26C358998;
  *(void *)this = &unk_26C358A50;
  mlir::PatternApplicator::~PatternApplicator((_anonymous_namespace_::GreedyPatternRewriteDriver *)((char *)this + 296));
}

{
}

void sub_211900CE8()
{
  if ((*(unsigned char *)(v0 + 256) & 1) == 0) {
    llvm::deallocate_buffer(*(llvm **)(v0 + 264), (void *)(8 * *(unsigned int *)(v0 + 272)));
  }
  mlir::OperationFolder::~OperationFolder((mlir::OperationFolder *)(v0 + 64));
}

void sub_211900D0C()
{
  llvm::deallocate_buffer(*(llvm **)(v0 + 40), (void *)(16 * *(unsigned int *)(v0 + 56)));
}

void sub_211900D20(int a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12)
{
  uint64_t v14 = *(void **)(v13 + 16);
  if (v14)
  {
    *(void *)(v13 + 24) = v14;
    operator delete(v14);
  }
  ZinIrHalH13g::~ZinIrHalH13g(v12);
}

uint64_t mlir::DialectInterfaceCollection<mlir::DialectFoldInterface>::DialectInterfaceCollection(void *a1, mlir::MLIRContext *a2)
{
  {
    uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::DialectFoldInterface]";
    unint64_t v14 = 76;
    unint64_t v6 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
    if (v14 >= v6) {
      unint64_t v7 = v6;
    }
    else {
      unint64_t v7 = v14;
    }
    unsigned int v8 = &v13[v7];
    unint64_t v9 = v14 - v7;
    if (v14 - v7 >= 0x12) {
      uint64_t v10 = 18;
    }
    else {
      uint64_t v10 = v14 - v7;
    }
    unint64_t v11 = v9 - v10;
    if (v11 >= v11 - 1) {
      uint64_t v12 = v11 - 1;
    }
    else {
      uint64_t v12 = v11;
    }
    mlir::detail::TypeIDResolver<mlir::DialectFoldInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v8[v10], v12);
  }
  uint64_t v4 = mlir::detail::TypeIDResolver<mlir::DialectFoldInterface,void>::resolveTypeID(void)::id;
  uint64_t v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::DialectFoldInterface]";
  unint64_t v14 = 76;
  llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
  uint64_t result = mlir::detail::DialectInterfaceCollectionBase::DialectInterfaceCollectionBase((uint64_t)a1, a2, v4);
  *a1 = &unk_26C37D810;
  return result;
}

void mlir::DialectInterfaceCollection<mlir::DialectFoldInterface>::~DialectInterfaceCollection(mlir::detail::DialectInterfaceCollectionBase *a1)
{
}

void sub_211900ECC()
{
  JUMPOUT(0x21667D3C0);
}

uint64_t llvm::function_ref<mlir::PatternBenefit ()(mlir::Pattern const&)>::callback_fn<mlir::PatternApplicator::applyDefaultCostModel(void)::{lambda(mlir::Pattern const&)#1}>(uint64_t a1, uint64_t a2)
{
  return *(unsigned __int16 *)(a2 + 12);
}

void mlir::OperationFolder::~OperationFolder(mlir::OperationFolder *this)
{
}

uint64_t sub_211901008()
{
  return v0;
}

int *llvm::function_ref<void ()(mlir::Operation *)>::callback_fn<anonymous namespace'::RegionPatternRewriteDriver::RegionPatternRewriteDriver(mlir::MLIRContext *,mlir::FrozenRewritePatternSet const&,mlir::GreedyRewriteConfig const&,mlir::Region &)::$_0>(int *result, uint64_t a2)
{
  uint64_t v2 = *(void *)result;
  uint64_t v14 = a2;
  if (*(unsigned char *)(v2 + 296))
  {
    uint64_t v4 = v2 + 304;
    int v3 = 4;
  }
  else
  {
    int v3 = *(_DWORD *)(v2 + 312);
    if (!v3)
    {
      unint64_t v9 = 0;
      return llvm::DenseMapBase<llvm::SmallDenseMap<mlir::Operation *,llvm::detail::DenseSetEmpty,4u,llvm::DenseMapInfo<mlir::Operation *,void>,llvm::detail::DenseSetPair<mlir::Operation *>>,mlir::Operation *,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::Operation *,void>,llvm::detail::DenseSetPair<mlir::Operation *>>::InsertIntoBucket<mlir::Operation * const&,llvm::detail::DenseSetEmpty&>((int *)(v2 + 296), v9, &v14);
    }
    uint64_t v4 = *(void *)(v2 + 304);
  }
  int v5 = v3 - 1;
  unsigned int v6 = v5 & ((a2 >> 4) ^ (a2 >> 9));
  unint64_t v7 = (int *)(v4 + 8 * v6);
  uint64_t v8 = *(void *)v7;
  if (*(void *)v7 != a2)
  {
    uint64_t v10 = 0;
    int v11 = 1;
    while (v8 != -4096)
    {
      if (v10) {
        BOOL v12 = 0;
      }
      else {
        BOOL v12 = v8 == -8192;
      }
      if (v12) {
        uint64_t v10 = v7;
      }
      unsigned int v13 = v6 + v11++;
      unsigned int v6 = v13 & v5;
      unint64_t v7 = (int *)(v4 + 8 * v6);
      uint64_t v8 = *(void *)v7;
      if (*(void *)v7 == a2) {
        return result;
      }
    }
    if (v10) {
      unint64_t v9 = v10;
    }
    else {
      unint64_t v9 = v7;
    }
    return llvm::DenseMapBase<llvm::SmallDenseMap<mlir::Operation *,llvm::detail::DenseSetEmpty,4u,llvm::DenseMapInfo<mlir::Operation *,void>,llvm::detail::DenseSetPair<mlir::Operation *>>,mlir::Operation *,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::Operation *,void>,llvm::detail::DenseSetPair<mlir::Operation *>>::InsertIntoBucket<mlir::Operation * const&,llvm::detail::DenseSetEmpty&>((int *)(v2 + 296), v9, &v14);
  }
  return result;
}

int *llvm::DenseMapBase<llvm::SmallDenseMap<mlir::Operation *,llvm::detail::DenseSetEmpty,4u,llvm::DenseMapInfo<mlir::Operation *,void>,llvm::detail::DenseSetPair<mlir::Operation *>>,mlir::Operation *,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::Operation *,void>,llvm::detail::DenseSetPair<mlir::Operation *>>::InsertIntoBucket<mlir::Operation * const&,llvm::detail::DenseSetEmpty&>(int *a1, int *a2, void *a3)
{
  unsigned int v6 = *a1;
  unsigned int v7 = *a1 >> 1;
  if (*a1) {
    unsigned int v8 = 4;
  }
  else {
    unsigned int v8 = a1[4];
  }
  if (4 * v7 + 4 >= 3 * v8)
  {
    v8 *= 2;
  }
  else if (v8 + ~v7 - a1[1] > v8 >> 3)
  {
    int v9 = *a1 & 1;
    goto LABEL_7;
  }
  llvm::SmallDenseMap<mlir::Operation *,llvm::detail::DenseSetEmpty,4u,llvm::DenseMapInfo<mlir::Operation *,void>,llvm::detail::DenseSetPair<mlir::Operation *>>::grow(a1, v8);
  int v11 = a1 + 2;
  unsigned int v6 = *a1;
  if (*a1)
  {
    int v12 = 4;
  }
  else
  {
    int v12 = a1[4];
    if (!v12)
    {
      int v9 = 0;
      a2 = 0;
      goto LABEL_7;
    }
    int v11 = (int *)*((void *)a1 + 1);
  }
  int v9 = *a1 & 1;
  int v13 = v12 - 1;
  unsigned int v14 = ((*a3 >> 4) ^ (*a3 >> 9)) & (v12 - 1);
  a2 = &v11[2 * v14];
  uint64_t v15 = *(void *)a2;
  if (*a3 != *(void *)a2)
  {
    uint64_t v16 = 0;
    int v17 = 1;
    while (v15 != -4096)
    {
      if (v16) {
        BOOL v18 = 0;
      }
      else {
        BOOL v18 = v15 == -8192;
      }
      if (v18) {
        uint64_t v16 = a2;
      }
      unsigned int v19 = v14 + v17++;
      unsigned int v14 = v19 & v13;
      a2 = &v11[2 * (v19 & v13)];
      uint64_t v15 = *(void *)a2;
      if (*a3 == *(void *)a2) {
        goto LABEL_7;
      }
    }
    if (v16) {
      a2 = v16;
    }
  }
LABEL_7:
  *a1 = (v6 & 0xFFFFFFFE | v9) + 2;
  if (*(void *)a2 != -4096) {
    --a1[1];
  }
  *(void *)a2 = *a3;
  return a2;
}

void *llvm::SmallDenseMap<mlir::Operation *,llvm::detail::DenseSetEmpty,4u,llvm::DenseMapInfo<mlir::Operation *,void>,llvm::detail::DenseSetPair<mlir::Operation *>>::grow(void *result, unsigned int a2)
{
  unsigned int v2 = a2;
  int v3 = result;
  v60[3] = *MEMORY[0x263EF8340];
  if (a2 >= 5)
  {
    unint64_t v4 = (a2 - 1) | ((unint64_t)(a2 - 1) >> 1);
    unint64_t v5 = v4 | (v4 >> 2) | ((v4 | (v4 >> 2)) >> 4);
    int v6 = ((v5 | (v5 >> 8)) >> 16) | v5 | (v5 >> 8);
    if ((v6 + 1) > 0x40) {
      unsigned int v2 = v6 + 1;
    }
    else {
      unsigned int v2 = 64;
    }
  }
  if ((*(unsigned char *)result & 1) == 0)
  {
    unsigned int v8 = result + 1;
    unsigned int v7 = (llvm *)result[1];
    uint64_t v9 = *((unsigned int *)result + 4);
    if (v2 > 4)
    {
      buffer = (int64x2_t *)llvm::allocate_buffer(8 * v2, (std::align_val_t)8uLL);
      v3[1] = buffer;
      v3[2] = v2;
      int v23 = *(_DWORD *)v3;
      uint64_t v10 = (llvm *)((char *)v7 + 8 * v9);
      *int v3 = *(_DWORD *)v3 & 1;
      if ((v23 & 1) == 0)
      {
        unsigned int v24 = &buffer->i8[8 * v2];
        unint64_t v25 = 8 * v2 - 8;
        if (v25 < 0x18)
        {
          uint64_t v27 = (char *)buffer;
          goto LABEL_24;
        }
LABEL_18:
        uint64_t v26 = (v25 >> 3) + 1;
        uint64_t v27 = &buffer->i8[8 * (v26 & 0x3FFFFFFFFFFFFFFCLL)];
        unint64_t v28 = buffer + 1;
        int64x2_t v29 = vdupq_n_s64(0xFFFFFFFFFFFFF000);
        uint64_t v30 = v26 & 0x3FFFFFFFFFFFFFFCLL;
        do
        {
          v28[-1] = v29;
          *unint64_t v28 = v29;
          v28 += 2;
          v30 -= 4;
        }
        while (v30);
        if (v26 == (v26 & 0x3FFFFFFFFFFFFFFCLL))
        {
LABEL_25:
          if (v9)
          {
            uint64_t v31 = v7;
            do
            {
              uint64_t v38 = *(void *)v31;
              if ((*(void *)v31 | 0x1000) != 0xFFFFFFFFFFFFF000)
              {
                if (*(unsigned char *)v3)
                {
                  int v33 = 4;
                  uint64_t v32 = v3 + 1;
                }
                else
                {
                  uint64_t v32 = (void *)*v8;
                  int v33 = v2;
                }
                int v34 = v33 - 1;
                unsigned int v35 = (v33 - 1) & ((v38 >> 4) ^ (v38 >> 9));
                unsigned int v36 = &v32[v35];
                uint64_t v37 = *v36;
                if (v38 != *v36)
                {
                  char v39 = 0;
                  int v40 = 1;
                  while (v37 != -4096)
                  {
                    if (v39) {
                      BOOL v41 = 0;
                    }
                    else {
                      BOOL v41 = v37 == -8192;
                    }
                    if (v41) {
                      char v39 = v36;
                    }
                    unsigned int v42 = v35 + v40++;
                    unsigned int v35 = v42 & v34;
                    unsigned int v36 = &v32[v42 & v34];
                    uint64_t v37 = *v36;
                    if (v38 == *v36) {
                      goto LABEL_29;
                    }
                  }
                  if (v39) {
                    unsigned int v36 = v39;
                  }
                }
LABEL_29:
                *unsigned int v36 = v38;
                *(_DWORD *)v3 += 2;
              }
              uint64_t v31 = (llvm *)((char *)v31 + 8);
            }
            while (v31 != v10);
          }
          llvm::deallocate_buffer(v7, (void *)(8 * v9));
        }
        do
        {
LABEL_24:
          *(void *)uint64_t v27 = -4096;
          v27 += 8;
        }
        while (v27 != v24);
        goto LABEL_25;
      }
    }
    else
    {
      uint64_t v10 = (llvm *)((char *)v7 + 8 * v9);
      *uint64_t result = 1;
      unsigned int v2 = v9;
    }
    unsigned int v24 = (char *)(v3 + 5);
    buffer = (int64x2_t *)(v3 + 1);
    unint64_t v25 = 24;
    goto LABEL_18;
  }
  int v11 = (int64x2_t **)(result + 1);
  int v12 = &v59;
  if ((result[1] | 0x1000) == 0xFFFFFFFFFFFFF000)
  {
    uint64_t v13 = result[2];
    if ((v13 | 0x1000) == 0xFFFFFFFFFFFFF000) {
      goto LABEL_10;
    }
  }
  else
  {
    uint64_t v59 = result[1];
    int v12 = v60;
    uint64_t v13 = result[2];
    if ((v13 | 0x1000) == 0xFFFFFFFFFFFFF000)
    {
LABEL_10:
      uint64_t v14 = result[3];
      if ((v14 | 0x1000) == 0xFFFFFFFFFFFFF000) {
        goto LABEL_11;
      }
      goto LABEL_51;
    }
  }
  *v12++ = v13;
  uint64_t v14 = result[3];
  if ((v14 | 0x1000) == 0xFFFFFFFFFFFFF000)
  {
LABEL_11:
    uint64_t v15 = result[4];
    if ((v15 | 0x1000) == 0xFFFFFFFFFFFFF000) {
      goto LABEL_12;
    }
    goto LABEL_52;
  }
LABEL_51:
  *v12++ = v14;
  uint64_t v15 = result[4];
  if ((v15 | 0x1000) == 0xFFFFFFFFFFFFF000)
  {
LABEL_12:
    int v16 = *(_DWORD *)result;
    if (v2 >= 5) {
      goto LABEL_13;
    }
LABEL_53:
    unsigned int v2 = v13;
    *uint64_t result = v16 & 1;
    if (v16) {
      goto LABEL_14;
    }
    goto LABEL_54;
  }
LABEL_52:
  *v12++ = v15;
  int v16 = *(_DWORD *)result;
  if (v2 < 5) {
    goto LABEL_53;
  }
LABEL_13:
  *(_DWORD *)uint64_t result = v16 & 0xFFFFFFFE;
  uint64_t result = llvm::allocate_buffer(8 * v2, (std::align_val_t)8uLL);
  v3[1] = result;
  v3[2] = v2;
  int v17 = *(_DWORD *)v3;
  *int v3 = *(_DWORD *)v3 & 1;
  if (v17)
  {
LABEL_14:
    uint64_t v18 = (uint64_t)(v3 + 5);
    unsigned int v19 = (int64x2_t *)(v3 + 1);
    unint64_t v20 = 24;
    goto LABEL_56;
  }
LABEL_54:
  if (!v2) {
    goto LABEL_60;
  }
  unsigned int v19 = *v11;
  uint64_t v18 = (uint64_t)&(*v11)->i64[v2];
  unint64_t v20 = 8 * v2 - 8;
  if (v20 < 0x18)
  {
    int v21 = *v11;
    do
    {
LABEL_59:
      v21->i64[0] = -4096;
      int v21 = (int64x2_t *)((char *)v21 + 8);
    }
    while (v21 != (int64x2_t *)v18);
    goto LABEL_60;
  }
LABEL_56:
  uint64_t v43 = (v20 >> 3) + 1;
  int v21 = (int64x2_t *)((char *)v19 + 8 * (v43 & 0x3FFFFFFFFFFFFFFCLL));
  uint64_t v44 = v19 + 1;
  int64x2_t v45 = vdupq_n_s64(0xFFFFFFFFFFFFF000);
  uint64_t v46 = v43 & 0x3FFFFFFFFFFFFFFCLL;
  do
  {
    v44[-1] = v45;
    *uint64_t v44 = v45;
    v44 += 2;
    v46 -= 4;
  }
  while (v46);
  if (v43 != (v43 & 0x3FFFFFFFFFFFFFFCLL)) {
    goto LABEL_59;
  }
LABEL_60:
  if (&v59 != v12)
  {
    int v47 = &v59;
    do
    {
      uint64_t v54 = *v47;
      if ((*v47 | 0x1000) != 0xFFFFFFFFFFFFF000)
      {
        if (*(unsigned char *)v3)
        {
          int v49 = 4;
          int32x2_t v48 = (int64x2_t *)(v3 + 1);
        }
        else
        {
          int32x2_t v48 = *v11;
          int v49 = v2;
        }
        int v50 = v49 - 1;
        unsigned int v51 = (v49 - 1) & ((v54 >> 4) ^ (v54 >> 9));
        uint64_t v52 = &v48->i64[v51];
        uint64_t v53 = *v52;
        if (v54 != *v52)
        {
          uint64_t v55 = 0;
          int v56 = 1;
          while (v53 != -4096)
          {
            if (v55) {
              BOOL v57 = 0;
            }
            else {
              BOOL v57 = v53 == -8192;
            }
            if (v57) {
              uint64_t v55 = v52;
            }
            unsigned int v58 = v51 + v56++;
            unsigned int v51 = v58 & v50;
            uint64_t v52 = &v48->i64[v58 & v50];
            uint64_t v53 = *v52;
            if (v54 == *v52) {
              goto LABEL_64;
            }
          }
          if (v55) {
            uint64_t v52 = v55;
          }
        }
LABEL_64:
        uint64_t *v52 = v54;
        *(_DWORD *)v3 += 2;
      }
      ++v47;
    }
    while (v47 != v12);
  }
  return result;
}

void anonymous namespace'::GreedyPatternRewriteDriver::addToWorklist(_anonymous_namespace_::GreedyPatternRewriteDriver *this, mlir::Operation *a2)
{
  v13[8] = *MEMORY[0x263EF8340];
  int v11 = v13;
  uint64_t v12 = 0x800000000;
  while (1)
  {
    uint64_t v4 = v12;
    if (v12 >= (unint64_t)HIDWORD(v12))
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v11, v13, v12 + 1, 8);
      uint64_t v4 = v12;
    }
    *((void *)v11 + v4) = a2;
    unsigned int v5 = v12 + 1;
    LODWORD(v12) = v12 + 1;
    int v6 = (mlir::Block *)*((void *)a2 + 2);
    if (!v6) {
      break;
    }
    unint64_t Parent = mlir::Block::getParent(v6);
    if (*((void *)this + 34) == Parent)
    {
      unsigned int v5 = v12;
      if (!v12) {
        goto LABEL_15;
      }
      goto LABEL_13;
    }
    if (Parent)
    {
      a2 = *(mlir::Operation **)(Parent + 16);
      if (a2) {
        continue;
      }
    }
    goto LABEL_15;
  }
  if (!*((void *)this + 34) && v5)
  {
LABEL_13:
    unsigned int v8 = (mlir::Operation **)v11;
    uint64_t v9 = 8 * v5;
    do
    {
      uint64_t v10 = *v8++;
      v9 -= 8;
    }
    while (v9);
  }
LABEL_15:
  if (v11 != v13) {
    free(v11);
  }
}

void anonymous namespace'::GreedyPatternRewriteDriver::addSingleOpToWorklist(_anonymous_namespace_::GreedyPatternRewriteDriver *this, mlir::Operation *a2)
{
  if (!*((_DWORD *)this + 70)) {
    goto LABEL_21;
  }
  int v4 = *((_DWORD *)this + 74);
  if (v4)
  {
    unsigned int v5 = (char *)this + 304;
    int v6 = 4;
LABEL_8:
    int v9 = v6 - 1;
    LODWORD(v10) = (v6 - 1) & ((a2 >> 4) ^ (a2 >> 9));
    int v11 = (_anonymous_namespace_::GreedyPatternRewriteDriver *)&v5[8 * v10];
    uint64_t v12 = *(mlir::Operation **)v11;
    if (*(mlir::Operation **)v11 == a2)
    {
      if ((v4 & 1) == 0)
      {
LABEL_10:
        if (v11 == (_anonymous_namespace_::GreedyPatternRewriteDriver *)(*((void *)this + 38)
                                                                        + 8 * *((unsigned int *)this + 78)))
          return;
        goto LABEL_21;
      }
    }
    else
    {
      int v13 = 1;
      while (v12 != (mlir::Operation *)-4096)
      {
        int v14 = v10 + v13++;
        uint64_t v10 = v14 & v9;
        uint64_t v12 = *(mlir::Operation **)&v5[8 * v10];
        if (v12 == a2)
        {
          int v11 = (_anonymous_namespace_::GreedyPatternRewriteDriver *)&v5[8 * v10];
          if ((v4 & 1) == 0) {
            goto LABEL_10;
          }
          goto LABEL_20;
        }
      }
      if ((v4 & 1) == 0)
      {
        unsigned int v5 = (char *)*((void *)this + 38);
        unsigned int v7 = *((_DWORD *)this + 78);
        uint64_t v8 = v7;
        goto LABEL_5;
      }
      int v11 = (_anonymous_namespace_::GreedyPatternRewriteDriver *)((char *)this + 336);
    }
LABEL_20:
    if (v11 == (_anonymous_namespace_::GreedyPatternRewriteDriver *)((char *)this + 336)) {
      return;
    }
LABEL_21:
    uint64_t v15 = (char *)this + 80;
    uint64_t v16 = *((void *)this + 10);
    unsigned int v17 = *((_DWORD *)this + 24);
    if (v17)
    {
      unsigned int v18 = v17 - 1;
      unsigned int v19 = (v17 - 1) & ((a2 >> 4) ^ (a2 >> 9));
      uint64_t v20 = v16 + 16 * v19;
      int v21 = *(mlir::Operation **)v20;
      if (*(mlir::Operation **)v20 == a2) {
        return;
      }
      int v22 = 1;
      int v23 = *(mlir::Operation **)v20;
      unsigned int v24 = v18 & ((a2 >> 4) ^ (a2 >> 9));
      while (v23 != (mlir::Operation *)-4096)
      {
        unsigned int v25 = v24 + v22++;
        unsigned int v24 = v25 & v18;
        int v23 = *(mlir::Operation **)(v16 + 16 * v24);
        if (v23 == a2) {
          return;
        }
      }
      uint64_t v50 = 0;
      uint64_t v26 = (uint64_t *)((char *)this + 64);
      int64x2_t v29 = (char *)*((void *)this + 8);
      unint64_t v27 = (unint64_t)&v29[-*((void *)this + 7)] >> 3;
      int v51 = 1;
      while (v21 != (mlir::Operation *)-4096)
      {
        if (v50) {
          BOOL v52 = 0;
        }
        else {
          BOOL v52 = v21 == (mlir::Operation *)-8192;
        }
        if (v52) {
          uint64_t v50 = v20;
        }
        unsigned int v53 = v19 + v51++;
        unsigned int v19 = v53 & v18;
        uint64_t v20 = v16 + 16 * (v53 & v18);
        int v21 = *(mlir::Operation **)v20;
        if (*(mlir::Operation **)v20 == a2) {
          goto LABEL_32;
        }
      }
      if (v50) {
        uint64_t v20 = v50;
      }
      int v54 = *((_DWORD *)this + 22);
      if (4 * v54 + 4 < 3 * v17)
      {
        if (v17 + ~v54 - *((_DWORD *)this + 23) > v17 >> 3) {
          goto LABEL_29;
        }
        goto LABEL_70;
      }
    }
    else
    {
      uint64_t v26 = (uint64_t *)((char *)this + 64);
      unint64_t v27 = (*((void *)this + 8) - *((void *)this + 7)) >> 3;
    }
    v17 *= 2;
LABEL_70:
    llvm::DenseMap<void const*,unsigned int,llvm::DenseMapInfo<void const*,void>,llvm::detail::DenseMapPair<void const*,unsigned int>>::grow((uint64_t)v15, v17);
    uint64_t v55 = *((void *)this + 10);
    int v56 = *((_DWORD *)this + 24) - 1;
    unsigned int v57 = v56 & ((a2 >> 4) ^ (a2 >> 9));
    uint64_t v20 = v55 + 16 * v57;
    unsigned int v58 = *(mlir::Operation **)v20;
    if (*(mlir::Operation **)v20 == a2)
    {
LABEL_71:
      ++*((_DWORD *)this + 22);
      if (a2 == (mlir::Operation *)-4096) {
        goto LABEL_31;
      }
      goto LABEL_30;
    }
    uint64_t v59 = 0;
    int v60 = 1;
    while (v58 != (mlir::Operation *)-4096)
    {
      if (v59) {
        BOOL v61 = 0;
      }
      else {
        BOOL v61 = v58 == (mlir::Operation *)-8192;
      }
      if (v61) {
        uint64_t v59 = v20;
      }
      unsigned int v62 = v57 + v60++;
      unsigned int v57 = v62 & v56;
      uint64_t v20 = v55 + 16 * (v62 & v56);
      unsigned int v58 = *(mlir::Operation **)v20;
      if (*(mlir::Operation **)v20 == a2) {
        goto LABEL_71;
      }
    }
    if (v59) {
      uint64_t v20 = v59;
    }
LABEL_29:
    unint64_t v28 = *(mlir::Operation **)v20;
    ++*((_DWORD *)this + 22);
    if (v28 == (mlir::Operation *)-4096)
    {
LABEL_31:
      *(void *)uint64_t v20 = a2;
      *(_DWORD *)(v20 + 8) = 0;
      int64x2_t v29 = (char *)*v26;
LABEL_32:
      *(_DWORD *)(v20 + 8) = v27;
      unint64_t v30 = *((void *)this + 9);
      if ((unint64_t)v29 < v30)
      {
        *(void *)int64x2_t v29 = a2;
        uint64_t v31 = (uint64_t)(v29 + 8);
LABEL_56:
        *uint64_t v26 = v31;
        return;
      }
      uint64_t v32 = (char *)*((void *)this + 7);
      uint64_t v33 = (v29 - v32) >> 3;
      unint64_t v34 = v33 + 1;
      if ((unint64_t)(v33 + 1) >> 61) {
        abort();
      }
      uint64_t v35 = v30 - (void)v32;
      if (v35 >> 2 > v34) {
        unint64_t v34 = v35 >> 2;
      }
      if ((unint64_t)v35 >= 0x7FFFFFFFFFFFFFF8) {
        unint64_t v36 = 0x1FFFFFFFFFFFFFFFLL;
      }
      else {
        unint64_t v36 = v34;
      }
      if (v36)
      {
        if (v36 >> 61) {
          std::__throw_bad_array_new_length[abi:nn180100]();
        }
        uint64_t v37 = (char *)operator new(8 * v36);
        uint64_t v38 = &v37[8 * v33];
        char v39 = &v37[8 * v36];
        *(void *)uint64_t v38 = a2;
        uint64_t v31 = (uint64_t)(v38 + 8);
        int v40 = (char *)(v29 - v32);
        if (v29 == v32) {
          goto LABEL_54;
        }
      }
      else
      {
        uint64_t v37 = 0;
        uint64_t v38 = (char *)(8 * v33);
        char v39 = 0;
        *(void *)(8 * v33) = a2;
        uint64_t v31 = 8 * v33 + 8;
        int v40 = (char *)(v29 - v32);
        if (v29 == v32) {
          goto LABEL_54;
        }
      }
      unint64_t v41 = (unint64_t)(v40 - 8);
      if (v41 >= 0x58)
      {
        if ((unint64_t)(v32 - v37) >= 0x20)
        {
          uint64_t v43 = (v41 >> 3) + 1;
          uint64_t v44 = 8 * (v43 & 0x3FFFFFFFFFFFFFFCLL);
          unsigned int v42 = &v29[-v44];
          v38 -= v44;
          int64x2_t v45 = &v37[8 * v33 - 16];
          uint64_t v46 = v29 - 16;
          uint64_t v47 = v43 & 0x3FFFFFFFFFFFFFFCLL;
          do
          {
            long long v48 = *(_OWORD *)v46;
            *((_OWORD *)v45 - 1) = *((_OWORD *)v46 - 1);
            *(_OWORD *)int64x2_t v45 = v48;
            v45 -= 32;
            v46 -= 32;
            v47 -= 4;
          }
          while (v47);
          if (v43 == (v43 & 0x3FFFFFFFFFFFFFFCLL)) {
            goto LABEL_53;
          }
        }
        else
        {
          unsigned int v42 = v29;
        }
      }
      else
      {
        unsigned int v42 = v29;
      }
      do
      {
        uint64_t v49 = *((void *)v42 - 1);
        v42 -= 8;
        *((void *)v38 - 1) = v49;
        v38 -= 8;
      }
      while (v42 != v32);
LABEL_53:
      int64x2_t v29 = (char *)*((void *)this + 7);
LABEL_54:
      *((void *)this + 7) = v38;
      *((void *)this + 8) = v31;
      *((void *)this + 9) = v39;
      if (v29) {
        operator delete(v29);
      }
      goto LABEL_56;
    }
LABEL_30:
    --*((_DWORD *)this + 23);
    goto LABEL_31;
  }
  unsigned int v5 = (char *)*((void *)this + 38);
  int v6 = *((_DWORD *)this + 78);
  if (v6) {
    goto LABEL_8;
  }
  unsigned int v7 = 0;
  uint64_t v8 = 0;
LABEL_5:
  if (&v5[8 * v8] != &v5[8 * v7]) {
    goto LABEL_21;
  }
}

void llvm::function_ref<void ()(mlir::Operation *)>::callback_fn<anonymous namespace'::RegionPatternRewriteDriver::simplify(BOOL *)::$_0>(uint64_t a1, mlir::Operation *a2)
{
  v7[1] = *MEMORY[0x263EF8340];
  int v3 = *(_anonymous_namespace_::GreedyPatternRewriteDriver **)(a1 + 8);
  int v4 = **(int32x2_t ***)a1;
  if (!mlir::OperationName::hasTrait<mlir::OpTrait::ConstantLike>((void *)a2 + 6)) {
    goto LABEL_6;
  }
  v6[0] = v7;
  v6[1] = (void *)0x100000000;
  mlir::Operation::fold((uint64_t)a2, 0, 0, (uint64_t)v6);
  unint64_t v5 = *(void *)v6[0] & 0xFFFFFFFFFFFFFFF8;
  if (v6[0] != v7) {
    free(v6[0]);
  }
  if (!v5 || mlir::OperationFolder::insertKnownConstant(v4 + 13, (uint64_t)a2, v5)) {
LABEL_6:
  }
}

uint64_t llvm::function_ref<mlir::WalkResult ()(mlir::Operation *)>::callback_fn<anonymous namespace'::RegionPatternRewriteDriver::simplify(BOOL *)::$_1>(uint64_t a1, mlir::Operation *a2)
{
  v8[1] = *MEMORY[0x263EF8340];
  int v3 = *(_anonymous_namespace_::GreedyPatternRewriteDriver **)(a1 + 8);
  int v4 = **(int32x2_t ***)a1;
  if (mlir::OperationName::hasTrait<mlir::OpTrait::ConstantLike>((void *)a2 + 6))
  {
    v7[0] = v8;
    v7[1] = (void *)0x100000000;
    mlir::Operation::fold((uint64_t)a2, 0, 0, (uint64_t)v7);
    unint64_t v5 = *(void *)v7[0] & 0xFFFFFFFFFFFFFFF8;
    if (v7[0] != v8) {
      free(v7[0]);
    }
    if (v5 && !mlir::OperationFolder::insertKnownConstant(v4 + 13, (uint64_t)a2, v5)) {
      return 2;
    }
  }
  return 1;
}

uint64_t mlir::MLIRContext::executeActionInternal<anonymous namespace'::GreedyPatternRewriteIteration,long long &>(uint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  void v7[2] = a4;
  unint64_t v7[3] = a5;
  v7[4] = a6;
  v7[0] = &unk_26C358D98;
  return mlir::MLIRContext::executeActionInternal(a1, a2, a3, (uint64_t)v7);
}

void anonymous namespace'::GreedyPatternRewriteIteration::~GreedyPatternRewriteIteration(_anonymous_namespace_::GreedyPatternRewriteIteration *this)
{
}

const char *mlir::tracing::ActionImpl<anonymous namespace'::GreedyPatternRewriteIteration>::getTag()
{
  return "GreedyPatternRewriteIteration";
}

llvm::raw_ostream *anonymous namespace'::GreedyPatternRewriteIteration::print(_anonymous_namespace_::GreedyPatternRewriteIteration *this, llvm::raw_ostream *a2)
{
  int v3 = (void *)*((void *)a2 + 4);
  if (*((void *)a2 + 3) - (void)v3 > 0x1DuLL)
  {
    qmemcpy(v3, "GreedyPatternRewriteIteration(", 30);
    *((void *)a2 + 4) += 30;
    uint64_t result = llvm::raw_ostream::operator<<(a2, *((void *)this + 4));
    int v6 = (unsigned char *)*((void *)result + 4);
    if (*((unsigned char **)result + 3) != v6) {
      goto LABEL_3;
    }
  }
  else
  {
    int v4 = llvm::raw_ostream::write(a2, "GreedyPatternRewriteIteration(", 0x1EuLL);
    uint64_t result = llvm::raw_ostream::operator<<(v4, *((void *)this + 4));
    int v6 = (unsigned char *)*((void *)result + 4);
    if (*((unsigned char **)result + 3) != v6)
    {
LABEL_3:
      unsigned char *v6 = 41;
      ++*((void *)result + 4);
      return result;
    }
  }

  return llvm::raw_ostream::write(result, ")", 1uLL);
}

uint64_t llvm::function_ref<void ()(void)>::callback_fn<anonymous namespace'::RegionPatternRewriteDriver::simplify(BOOL *)::$_2>(uint64_t a1, mlir::Operation *a2)
{
  uint64_t v3 = *(void *)(a1 + 8);
  **(unsigned char **)a1 = result;
  if (*(unsigned char *)(v3 + 249)) {
    mlir::simplifyRegions(v3, *(void **)(v3 + 400), 1uLL);
  }
  return result;
}

uint64_t anonymous namespace'::GreedyPatternRewriteDriver::processWorklist(int32x2_t *this, mlir::Operation *a2)
{
  unsigned int v2 = (void *)this[7];
  uint64_t v3 = (void *)this[8];
  if (v2 == v3)
  {
    char v5 = 0;
  }
  else
  {
    char v5 = 0;
    uint64_t v6 = 0;
    unsigned int v7 = this + 13;
    uint64_t v8 = this + 42;
    while (1)
    {
      int v9 = v2;
      while (!*v9)
      {
        if (++v9 == v3) {
          return v5 & 1;
        }
      }
      int32x2_t v10 = this[33];
      BOOL v11 = v6 < *(void *)&v10 || *(void *)&v10 == -1;
      if (!v11) {
        break;
      }
      int v14 = (mlir::Operation *)*(v3 - 1);
      int32x2_t v12 = (int32x2_t)(v3 - 1);
      int v13 = v14;
      if (!v14)
      {
        do
        {
          this[8] = v12;
          uint64_t v15 = *(mlir::Operation **)(*(void *)&v12 - 8);
          *(void *)&v12 -= 8;
          int v13 = v15;
        }
        while (!v15);
      }
      this[8] = v12;
      __int32 v16 = this[12].i32[0];
      if (v16)
      {
        int32x2_t v17 = this[10];
        __int32 v18 = v16 - 1;
        LODWORD(v19) = (v16 - 1) & ((v13 >> 4) ^ (v13 >> 9));
        uint64_t v20 = (mlir::Operation **)(*(void *)&v17 + 16 * v19);
        int v21 = *v20;
        if (v13 == *v20)
        {
LABEL_16:
          int32x2_t *v20 = (mlir::Operation *)-8192;
          this[11] = vadd_s32(this[11], (int32x2_t)0x1FFFFFFFFLL);
          unsigned int v2 = (void *)this[7];
          int32x2_t v12 = this[8];
        }
        else
        {
          int v25 = 1;
          while (v21 != (mlir::Operation *)-4096)
          {
            int v26 = v19 + v25++;
            uint64_t v19 = v26 & v18;
            int v21 = *(mlir::Operation **)(*(void *)&v17 + 16 * v19);
            if (v13 == v21)
            {
              uint64_t v20 = (mlir::Operation **)(*(void *)&v17 + 16 * v19);
              goto LABEL_16;
            }
          }
        }
      }
      if (v2 != *(void **)&v12)
      {
        int v22 = (void *)(*(void *)&v12 - 8);
        do
        {
          if (*v22) {
            break;
          }
          this[8] = (int32x2_t)v22;
          BOOL v11 = v22-- == v2;
        }
        while (!v11);
      }
      if (mlir::isOpTriviallyDead((void ***)v13, a2))
      {
        (*(void (**)(int32x2_t *, mlir::Operation *))(*(void *)this + 40))(this, v13);
        char v5 = 1;
        unsigned int v2 = (void *)this[7];
        uint64_t v3 = (void *)this[8];
        if (v2 == v3) {
          return v5 & 1;
        }
      }
      else if (mlir::OperationFolder::tryToFold(v7, v13, 0))
      {
        char v5 = 1;
        unsigned int v2 = (void *)this[7];
        uint64_t v3 = (void *)this[8];
        if (v2 == v3) {
          return v5 & 1;
        }
      }
      else
      {
        char v24 = mlir::PatternApplicator::matchAndRewrite((uint64_t)v8, (uint64_t)v13, (uint64_t)this, 0, 0, 0, 0, v23, 0, 0);
        if (v24) {
          ++v6;
        }
        v5 |= v24 != 0;
        unsigned int v2 = (void *)this[7];
        uint64_t v3 = (void *)this[8];
        if (v2 == v3) {
          return v5 & 1;
        }
      }
    }
  }
  return v5 & 1;
}