void ANECDescToUnitInfo<ANECLinearLayerDesc,ZinIrLinearUnitInfo>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, int a5)
{
  const char *p_src;
  int v9;
  unsigned char v10[24];
  const char *__src;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;

  v14 = *MEMORY[0x263EF8340];
  ZinIrUnitStatus::ZinIrUnitStatus((ZinIrUnitStatus *)v10);
  *(_DWORD *)(a4 + 32) = 60;
  *(_DWORD *)(a4 + 68) = a5;
  *(_DWORD *)(a4 + 80) = ZinGetKernelMode(*(const __CFString **)a1);
  *(_DWORD *)(a4 + 84) = ZinGetKernelFormat(*(const __CFString **)(a1 + 8), *(const __CFString **)a1);
  v9 = 0;
  if ((CFStringToZinIrDimension(*(void *)(a1 + 24), &v9) & 1) == 0)
  {
    __src = 0;
    v12 = 0;
    v13 = 0;
    if (ZinGetString(*(CFStringRef *)(a1 + 24), (uint64_t)&__src))
    {
      p_src = (const char *)&__src;
      if (v13 < 0) {
        p_src = __src;
      }
      ZinAssertImpl("Unknown dimension for gather: %s", p_src);
    }
    ZinAssertImpl("Invalid gather dimension");
  }
  *(_DWORD *)(a4 + 240) = v9;
  LODWORD(__src) = 0;
  std::vector<int>::__assign_with_size[abi:ne180100]<int *,int *>((char *)(a4 + 128), (char *)&__src, (uint64_t)&__src + 4, 1uLL);
  __src = 0;
  std::vector<DimensionMapping>::__assign_with_size[abi:ne180100]<DimensionMapping const*,DimensionMapping const*>((char *)(a4 + 152), (char *)&__src, (uint64_t)&v12, 1uLL);
  *(_DWORD *)(a4 + 104) = 0;
  *(_DWORD *)(a4 + 88) = 0;
  *(void *)(a4 + 96) = 0;
  *(_OWORD *)(a4 + 112) = xmmword_211ED5A80;
  *(void *)(a4 + 72) = *(void *)(a1 + 16);
  *(unsigned char *)(a4 + 180) = *(unsigned char *)(a1 + 32);
  *(unsigned char *)(a4 + 184) = *(unsigned char *)(a1 + 33);
  *(unsigned char *)(a4 + 185) = *(unsigned char *)(a1 + 48);
  *(_DWORD *)(a4 + 224) = ZinGetKernelFormat(*(const __CFString **)(a1 + 40), 0);
  *(_DWORD *)(a4 + 228) = *(_DWORD *)(a1 + 36);
  *(_DWORD *)(a4 + 232) = *(_DWORD *)(a1 + 52);
  *(_DWORD *)(a4 + 176) = *(_DWORD *)(a1 + 56);
  ZinIrUnitStatus::~ZinIrUnitStatus((ZinIrUnitStatus *)v10);
}

void sub_211363078(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, char a12, uint64_t a13, uint64_t a14, void *__p, uint64_t a16, int a17, __int16 a18, char a19, char a20)
{
}

uint64_t ANECDescToUnitInfo<ANECFlattenLayerDesc,ZinIrFlattenUnitInfo>(const __CFString **a1, uint64_t a2, uint64_t a3, _DWORD *a4, int a5)
{
  a4[8] = 11;
  a4[17] = a5;
  uint64_t result = CFStringToZinIrFlattenType(*a1);
  a4[20] = result;
  return result;
}

double ANECDescToUnitInfo<ANECUnflattenLayerDesc,ZinIrUnflattenUnitInfo>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, int a5)
{
  *(_DWORD *)(a4 + 32) = 12;
  *(_DWORD *)(a4 + 68) = a5;
  *(_DWORD *)(a4 + 80) = CFStringToZinIrFlattenType(*(const __CFString **)a1);
  double result = *(double *)(a1 + 8);
  *(double *)(a4 + 84) = result;
  *(_DWORD *)(a4 + 92) = *(_DWORD *)(a1 + 16);
  return result;
}

void ANECDescToUnitInfo<ANECMinMaxNormLayerDesc,ZinIrMinMaxNormUnitInfo>(uint64_t *a1, uint64_t a2, uint64_t a3, _DWORD *a4, int a5)
{
  a4[8] = 27;
  a4[17] = a5;
  uint64_t v6 = (uint64_t)(a4 + 20);
  v7 = (CFStringRef *)(a1 + 1);
  uint64_t v8 = *a1;
  std::string::basic_string[abi:ne180100]<0>(__p, "min/max norm");
  ANECDescDimsToNormUnitInfo(v6, v7, v8, (uint64_t)__p);
  if (v10 < 0) {
    operator delete(__p[0]);
  }
  a4[30] = 730643660;
}

void sub_2113631C4(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11, int a12, __int16 a13, char a14, char a15)
{
  if (a15 < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

void *ANECDescDimsToNormUnitInfo(uint64_t a1, CFStringRef *a2, uint64_t a3, uint64_t a4)
{
  if (a3)
  {
    uint64_t v6 = a3;
    do
    {
      int v14 = 0;
      if ((CFStringToZinIrDimension(*a2, &v14) & 1) == 0)
      {
        v12[0] = 0;
        v12[1] = 0;
        uint64_t v13 = 0;
        char String = ZinGetString(*a2, (uint64_t)v12);
        if (*(char *)(a4 + 23) >= 0) {
          char v10 = (const char *)a4;
        }
        else {
          char v10 = *(const char **)a4;
        }
        if (String)
        {
          v11 = (const char *)v12;
          if (v13 < 0) {
            v11 = (const char *)v12[0];
          }
          ZinAssertImpl("Error: unknown %s axis %s", v10, v11);
        }
        ZinAssertImpl("Error: invalid %s axis", v10);
      }
      double result = std::__hash_table<ZinIrDimension,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,std::allocator<ZinIrDimension>>::__emplace_unique_key_args<ZinIrDimension,ZinIrDimension const&>(a1, &v14, &v14);
      ++a2;
      --v6;
    }
    while (v6);
  }
  else
  {
    LODWORD(v12[0]) = 3;
    std::__hash_table<ZinIrDimension,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,std::allocator<ZinIrDimension>>::__emplace_unique_key_args<ZinIrDimension,ZinIrDimension>(a1, (int *)v12, v12);
    LODWORD(v12[0]) = 4;
    std::__hash_table<ZinIrDimension,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,std::allocator<ZinIrDimension>>::__emplace_unique_key_args<ZinIrDimension,ZinIrDimension>(a1, (int *)v12, v12);
    LODWORD(v12[0]) = 1;
    return std::__hash_table<ZinIrDimension,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,std::allocator<ZinIrDimension>>::__emplace_unique_key_args<ZinIrDimension,ZinIrDimension>(a1, (int *)v12, v12);
  }
  return result;
}

void sub_211363300(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, void *__p, uint64_t a12, int a13, __int16 a14, char a15, char a16)
{
  if (a16 < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

__int16 ANECDescToUnitInfo<ANECAffineTransformLayerDesc,ZinIrAffineTransformUnitInfo>@<H0>(uint64_t a1@<X0>, uint64_t a2@<X1>, uint64_t a3@<X2>, uint64_t a4@<X3>, int a5@<W4>)
{
  *(_DWORD *)(a4 + 32) = 40;
  *(_DWORD *)(a4 + 68) = a5;
  uint64_t v7 = *(unsigned int *)(a1 + 128);
  *(void *)(a4 + 160) = *(unsigned int *)(a1 + 116);
  *(void *)(a4 + 168) = v7;
  *(_DWORD *)(a4 + 64) = GetZinTensorFormat<__CFString const*>((uint64_t *)(a1 + 136));
  ANECTextureInfoToZin(a1, 2, (void **)(a4 + 128));
  ANECTextureInfoToZin(a1 + 32, 2, (void **)(a4 + 104));
  ANECTextureInfoToZin(a1 + 64, 2, a4 + 80);
  ANECTextureInfoToZin(a1 + 144, 2, a4 + 200);
  _S0 = *(_DWORD *)(a1 + 112);
  __asm { FCVT            H0, S0 }
  *(_WORD *)(a4 + 152) = result;
  return result;
}

unsigned char *ANECDescToUnitInfo<ANECDynamicGOCLayerDesc,ZinIrDynamicGOCUnitInfo>(unsigned char *result, uint64_t a2, uint64_t a3, uint64_t a4, int a5)
{
  *(_DWORD *)(a4 + 32) = 9;
  *(_DWORD *)(a4 + 68) = a5;
  *(unsigned char *)(a4 + 210) = *result;
  *(unsigned char *)(a4 + 209) = result[1];
  return result;
}

void ANECDescToUnitInfo<ANECL2NormLayerDesc,ZinIrL2NormUnitInfo>(uint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4, int a5)
{
  *(_DWORD *)(a4 + 32) = 26;
  *(_DWORD *)(a4 + 68) = a5;
  uint64_t v5 = a4 + 80;
  uint64_t v6 = (CFStringRef *)(a1 + 1);
  uint64_t v7 = *a1;
  std::string::basic_string[abi:ne180100]<0>(__p, "L2 norm");
  ANECDescDimsToNormUnitInfo(v5, v6, v7, (uint64_t)__p);
  if (v9 < 0) {
    operator delete(__p[0]);
  }
}

void sub_211363448(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11, int a12, __int16 a13, char a14, char a15)
{
  if (a15 < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

double ANECDescToUnitInfo<ANECArgMinMaxLayerDesc,ZinIrArgMinMaxUnitInfo>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, int a5)
{
  *(_DWORD *)(a4 + 32) = 15;
  *(_DWORD *)(a4 + 68) = a5;
  uint64_t v8 = *(void *)(a1 + 8);
  uint64_t v7 = *(void *)(a1 + 16);
  CFStringRef v9 = *(const __CFString **)a1;
  *(_DWORD *)(a4 + 80) = v7;
  *(_DWORD *)(a4 + 84) = v8;
  *(int32x2_t *)(a4 + 88) = vrev64_s32(*(int32x2_t *)(a1 + 32));
  CFStringToZinArgMode(v9, (int *)(a4 + 120));
  *(_OWORD *)(a4 + 96) = *(_OWORD *)(a1 + 44);
  double result = *(double *)(a1 + 60);
  *(double *)(a4 + 112) = result;
  return result;
}

const __CFString *ANECDescToUnitInfo<ANECGlobalArgMinMaxLayerDesc,ZinIrGlobalArgMinMaxUnitInfo>(const __CFString **a1, uint64_t a2, uint64_t a3, _DWORD *a4, int a5)
{
  a4[8] = 16;
  a4[17] = a5;
  if ((CFStringToZinIrDimension(a1[1], a4 + 21) & 1) == 0)
  {
    char v10 = 0;
    uint64_t v11 = 0;
    uint64_t v12 = 0;
    if (ZinGetString(a1[1], (uint64_t)&v10))
    {
      uint64_t v8 = (const char *)&v10;
      if (v12 < 0) {
        uint64_t v8 = v10;
      }
      ZinAssertImpl("Error: Invalid dimension:%s setting in the instance norm layer descriptor", v8);
    }
    ZinAssertImpl("Error: cannot extract the dimension string from the GlobalArgMinMax Layer Descriptor");
  }
  CFStringRef result = CFStringToGlobalArgType(a1, a4 + 20);
  if ((result & 1) == 0)
  {
    char v10 = 0;
    uint64_t v11 = 0;
    uint64_t v12 = 0;
    if (ZinGetString(*a1, (uint64_t)&v10))
    {
      CFStringRef v9 = (const char *)&v10;
      if (v12 < 0) {
        CFStringRef v9 = v10;
      }
      ZinAssertImpl("Error: Invalid GlobalArgMinMax type %s", v9);
    }
    ZinAssertImpl("Error: cannot extract the dimension string from the GlobalArgMinMax Layer Descriptor");
  }
  return result;
}

void sub_2113635BC(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11, int a12, __int16 a13, char a14, char a15)
{
  if (a15 < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

__n128 ANECDescToUnitInfo<ANECRandomLayerDesc,ZinIrRandomUnitInfo>(void *a1, uint64_t a2, uint64_t a3, uint64_t a4, int a5)
{
  *(_DWORD *)(a4 + 32) = 55;
  *(_DWORD *)(a4 + 68) = a5;
  *(void *)(a4 + 120) = a1[1];
  *(void *)(a4 + 128) = a1[2];
  uint64_t v5 = *(void *)(a2 + 40);
  __n128 result = *(__n128 *)(a2 + 8);
  long long v7 = *(_OWORD *)(a2 + 24);
  *(__n128 *)(a4 + 80) = result;
  *(_OWORD *)(a4 + 96) = v7;
  *(void *)(a4 + 112) = v5;
  *(void *)(a4 + 72) = a1[3];
  return result;
}

const __CFString *ANECDescToUnitInfo<ANECNMSLayerDesc,ZinIrNMSUnitInfo>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, int a5)
{
  *(_DWORD *)(a4 + 32) = 52;
  *(_DWORD *)(a4 + 88) = *(_DWORD *)(a1 + 16);
  *(void *)(a4 + 80) = *(void *)(a1 + 8);
  *(_WORD *)(a4 + 92) = *(_WORD *)(a1 + 20);
  CFStringRef result = CFStringToNMSType((const __CFString **)a1, (int *)(a4 + 96));
  if ((result & 1) == 0) {
    ZinAssertImpl("Error: Invalid NMS type.");
  }
  if (*(_DWORD *)(a4 + 96)) {
    int v8 = a5;
  }
  else {
    int v8 = 10;
  }
  *(_DWORD *)(a4 + 68) = v8;
  return result;
}

float ANECDescToUnitInfo<ANECDropoutLayerDesc,ZinIrDropoutUnitInfo>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, int a5)
{
  *(_DWORD *)(a4 + 32) = 54;
  *(_DWORD *)(a4 + 68) = a5;
  float result = *(float *)a1;
  *(_DWORD *)(a4 + 80) = *(_DWORD *)a1;
  *(void *)(a4 + 88) = *(void *)(a1 + 8);
  *(unsigned char *)(a4 + 96) = *(unsigned char *)(a1 + 16);
  return result;
}

const __CFString *ANECDescToUnitInfo<ANECLRNLayerDesc,ZinIrLRNUnitInfo>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, int a5)
{
  *(_DWORD *)(a4 + 32) = 29;
  *(_DWORD *)(a4 + 68) = a5;
  ANECPaddingToZinIrPadding(a1 + 32, (uint64_t)&v8);
  *(__n128 *)(a4 + 112) = v8;
  *(void *)(a4 + 128) = v9;
  ANECKernelSizeToZinIrKernelSize((__n128 *)(a1 + 8), &v8);
  *(__n128 *)(a4 + 88) = v8;
  *(void *)(a4 + 104) = v9;
  CFStringRef result = CFStringToLRNType((const __CFString **)a1, (int *)(a4 + 80));
  if ((result & 1) == 0) {
    ZinAssertImpl("Error: Invalid LRN type.");
  }
  return result;
}

void ANECDescToUnitInfo<ANECCrossProductLayerDesc,ZinIrUnitInfo>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, int a5)
{
  *(_DWORD *)(a4 + 32) = 57;
  *(_DWORD *)(a4 + 68) = a5;
}

double ANECDescToUnitInfo<ANECCrossCorrelationLayerDesc,ZinIrCrossCorrelationUnitInfo>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, int a5)
{
  *(_DWORD *)(a4 + 32) = 13;
  *(_DWORD *)(a4 + 68) = a5;
  *(_OWORD *)(a4 + 72) = *(_OWORD *)a1;
  ANECPaddingToZinIrPadding(a1 + 16, (uint64_t)&v8);
  *(_OWORD *)(a4 + 88) = v8;
  *(void *)(a4 + 104) = v9;
  double result = *(double *)(a1 + 40);
  *(double *)(a4 + 112) = result;
  return result;
}

uint64_t *ANECDescToUnitInfo<ANECSortLayerDesc,ZinIrSortUnitInfo>(uint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4, int a5)
{
  *(_DWORD *)(a4 + 32) = 50;
  *(_DWORD *)(a4 + 68) = a5;
  *(unsigned char *)(a4 + 120) = a1[68] == *MEMORY[0x263EFFB40];
  *(_DWORD *)(a4 + 80) = CFStringToZinIrSortDirection(*a1);
  if ((CFStringToZinIrDimension(a1[1], a4 + 84) & 1) == 0) {
    ZinAssertImpl("Error: cannot extract sort_dimension from Sort Layer Descriptor.");
  }
  double result = (uint64_t *)CFStringToZinIrDimension(a1[2], a4 + 88);
  if (!result) {
    ZinAssertImpl("Error: cannot extract vector_dimension from Sort Layer Descriptor.");
  }
  if (a1[3])
  {
    unint64_t v8 = 0;
    uint64_t v9 = (uint64_t **)(a4 + 96);
    char v10 = (unint64_t *)(a1 + 4);
    do
    {
      double result = std::__tree<ZinIrTensor *>::__emplace_unique_key_args<ZinIrTensor *,ZinIrTensor * const&>(v9, v10, (uint64_t *)v10);
      ++v8;
      ++v10;
    }
    while (v8 < a1[3]);
  }
  return result;
}

void RetrieveAbsolutePath(char *a1)
{
  v2 = (const std::__fs::filesystem::path *)std::__fs::filesystem::path::path[abi:ne180100]<std::string,void>(&v5.__pn_, a1);
  if (!std::__fs::filesystem::path::__root_directory(v2).__size_)
  {
    std::__fs::filesystem::__absolute(&v4, &v5, 0);
    if (SHIBYTE(v4.__pn_.__r_.__value_.__r.__words[2]) < 0) {
      std::string::__init_copy_ctor_external(&pn, v4.__pn_.__r_.__value_.__l.__data_, v4.__pn_.__r_.__value_.__l.__size_);
    }
    else {
      std::string pn = v4.__pn_;
    }
    if (a1[23] < 0) {
      operator delete(*(void **)a1);
    }
    *(std::string *)a1 = pn;
    if (SHIBYTE(v4.__pn_.__r_.__value_.__r.__words[2]) < 0) {
      operator delete(v4.__pn_.__r_.__value_.__l.__data_);
    }
  }
  if (SHIBYTE(v5.__pn_.__r_.__value_.__r.__words[2]) < 0) {
    operator delete(v5.__pn_.__r_.__value_.__l.__data_);
  }
}

void sub_211363930(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, void *__p, uint64_t a14, int a15, __int16 a16, char a17, char a18)
{
  if (a18 < 0) {
    operator delete(__p);
  }
  if (*(char *)(v18 - 17) < 0) {
    operator delete(*(void **)(v18 - 40));
  }
  _Unwind_Resume(exception_object);
}

uint64_t std::function<void ()(SpatialSplitMode)>::operator()(uint64_t a1, int a2)
{
  int v4 = a2;
  uint64_t v2 = *(void *)(a1 + 24);
  if (!v2) {
    std::__throw_bad_function_call[abi:ne180100]();
  }
  return (*(uint64_t (**)(uint64_t, int *))(*(void *)v2 + 48))(v2, &v4);
}

uint64_t std::vector<ANECProcedureInfo>::__emplace_back_slow_path<ANECProcedureInfo>(uint64_t *a1, const ANECProcedureInfo *a2)
{
  uint64_t v3 = *a1;
  unint64_t v4 = 0xCF3CF3CF3CF3CF3DLL * ((a1[1] - *a1) >> 3);
  unint64_t v5 = v4 + 1;
  if (v4 + 1 > 0x186186186186186) {
    std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
  }
  uint64_t v7 = (uint64_t)(a1 + 2);
  unint64_t v8 = 0xCF3CF3CF3CF3CF3DLL * ((a1[2] - v3) >> 3);
  if (2 * v8 > v5) {
    unint64_t v5 = 2 * v8;
  }
  if (v8 >= 0xC30C30C30C30C3) {
    unint64_t v9 = 0x186186186186186;
  }
  else {
    unint64_t v9 = v5;
  }
  v17 = a1 + 2;
  if (v9) {
    char v10 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ANEDebugInfo::DebugInfoInMem>>(v7, v9);
  }
  else {
    char v10 = 0;
  }
  uint64_t v13 = v10;
  int v14 = (ANECProcedureInfo *)&v10[168 * v4];
  v16 = &v10[168 * v9];
  ANECProcedureInfo::ANECProcedureInfo(v14, a2);
  v15 = (char *)v14 + 168;
  std::vector<ANECProcedureInfo>::__swap_out_circular_buffer(a1, &v13);
  uint64_t v11 = a1[1];
  std::__split_buffer<ANECProcedureInfo>::~__split_buffer((uint64_t)&v13);
  return v11;
}

void sub_211363AC8(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::__split_buffer<ANECProcedureInfo>::~__split_buffer((uint64_t)va);
  _Unwind_Resume(a1);
}

void ANECProcedureInfo::ANECProcedureInfo(ANECProcedureInfo *this, const ANECProcedureInfo *a2)
{
  *((void *)this + 2) = 0;
  *((void *)this + 1) = (char *)this + 16;
  unint64_t v9 = (uint64_t **)((char *)this + 8);
  *(void *)this = 0;
  *((void *)this + 3) = 0;
  *((void *)this + 5) = 0;
  *((void *)this + 4) = (char *)this + 40;
  unint64_t v4 = (uint64_t **)((char *)this + 32);
  *((void *)this + 6) = 0;
  *((void *)this + 8) = 0;
  *((void *)this + 7) = (char *)this + 64;
  unint64_t v5 = (uint64_t **)((char *)this + 56);
  *((unsigned char *)this + 80) = 0;
  uint64_t v6 = (char *)this + 80;
  *((void *)this + 9) = 0;
  *((unsigned char *)this + 104) = 0;
  *((void *)this + 15) = 0;
  *((void *)this + 14) = (char *)this + 120;
  uint64_t v7 = (uint64_t **)((char *)this + 112);
  *((void *)this + 16) = 0;
  *((void *)this + 18) = 0;
  *((void *)this + 17) = (char *)this + 144;
  unint64_t v8 = (uint64_t **)((char *)this + 136);
  *((void *)this + 19) = 0;
  *((unsigned char *)this + 160) = 0;
  ANECProcedureInfo::SetANECIRDict((const void **)this, *(CFTypeRef *)a2);
  if (this != a2)
  {
    std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::__assign_multi<std::__tree_const_iterator<std::__value_type<std::string,ZinIrName>,std::__tree_node<std::__value_type<std::string,ZinIrName>,void *> *,long>>(v9, *((long long **)a2 + 1), (long long *)a2 + 1);
    std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::__assign_multi<std::__tree_const_iterator<std::__value_type<std::string,ZinIrName>,std::__tree_node<std::__value_type<std::string,ZinIrName>,void *> *,long>>(v4, *((long long **)a2 + 4), (long long *)((char *)a2 + 40));
    std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::__assign_multi<std::__tree_const_iterator<std::__value_type<std::string,ZinIrName>,std::__tree_node<std::__value_type<std::string,ZinIrName>,void *> *,long>>(v5, *((long long **)a2 + 7), (long long *)a2 + 4);
  }
  std::__optional_storage_base<std::map<std::string,std::string>,false>::__assign_from[abi:ne180100]<std::__optional_copy_assign_base<std::map<std::string,std::string>,false> const&>((uint64_t)v6, (uint64_t)a2 + 80);
  if (this != a2)
  {
    std::__tree<std::__value_type<std::string,long>,std::__map_value_compare<std::string,std::__value_type<std::string,long>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,long>>>::__assign_multi<std::__tree_const_iterator<std::__value_type<std::string,long>,std::__tree_node<std::__value_type<std::string,long>,void *> *,long>>(v7, *((void **)a2 + 14), (void *)a2 + 15);
    std::__tree<std::__value_type<std::string,long>,std::__map_value_compare<std::string,std::__value_type<std::string,long>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,long>>>::__assign_multi<std::__tree_const_iterator<std::__value_type<std::string,long>,std::__tree_node<std::__value_type<std::string,long>,void *> *,long>>(v8, *((void **)a2 + 17), (void *)a2 + 18);
  }
  *((unsigned char *)this + 160) = *((unsigned char *)a2 + 160);
}

void sub_211363C24(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10)
{
  ZinIrLiveIORankMaps::~ZinIrLiveIORankMaps(v15);
  if (*(unsigned char *)(v11 + 104)) {
    std::__tree<std::__value_type<std::string,ZinIrInputParamInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrInputParamInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrInputParamInfo>>>::destroy(v14, *(void **)(v11 + 88));
  }
  std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::destroy(v13, *v10);
  std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::destroy(v12, *v17);
  std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::destroy(a10, *v16);
  _Unwind_Resume(a1);
}

uint64_t **std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::__assign_multi<std::__tree_const_iterator<std::__value_type<std::string,ZinIrName>,std::__tree_node<std::__value_type<std::string,ZinIrName>,void *> *,long>>(uint64_t **result, long long *a2, long long *a3)
{
  unint64_t v5 = result;
  if (result[2])
  {
    uint64_t v6 = *result;
    uint64_t v7 = result[1];
    *double result = (uint64_t *)(result + 1);
    v7[2] = 0;
    result[1] = 0;
    result[2] = 0;
    if (v6[1]) {
      unint64_t v8 = (uint64_t *)v6[1];
    }
    else {
      unint64_t v8 = v6;
    }
    v15 = result;
    v16 = v8;
    v17 = v8;
    if (v8)
    {
      v16 = std::__tree<ZinIrTensor *,ZinIrIdComparator<ZinIrTensor *>,std::allocator<ZinIrTensor *>>::_DetachedTreeCache::__detach_next((uint64_t)v8);
      if (a2 != a3)
      {
        unint64_t v9 = a2;
        do
        {
          v18[0] = (std::string *)(v8 + 4);
          v18[1] = (std::string *)(v8 + 7);
          std::pair<std::string &,ZinIrName &>::operator=[abi:ne180100]<std::string const,ZinIrName,(void *)0>(v18, (const std::string *)(v9 + 2));
          leaf_high = (uint64_t **)std::__tree<std::string>::__find_leaf_high((uint64_t)v5, v18, v17 + 4);
          std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::__insert_node_at(v5, (uint64_t)v18[0], leaf_high, v17);
          v17 = v16;
          if (v16) {
            v16 = std::__tree<ZinIrTensor *,ZinIrIdComparator<ZinIrTensor *>,std::allocator<ZinIrTensor *>>::_DetachedTreeCache::__detach_next((uint64_t)v16);
          }
          uint64_t v11 = (long long *)*((void *)v9 + 1);
          if (v11)
          {
            do
            {
              a2 = v11;
              uint64_t v11 = *(long long **)v11;
            }
            while (v11);
          }
          else
          {
            do
            {
              a2 = (long long *)*((void *)v9 + 2);
              BOOL v12 = *(void *)a2 == (void)v9;
              unint64_t v9 = a2;
            }
            while (!v12);
          }
          unint64_t v8 = v17;
          if (v17) {
            BOOL v12 = a2 == a3;
          }
          else {
            BOOL v12 = 1;
          }
          unint64_t v9 = a2;
        }
        while (!v12);
      }
    }
    double result = (uint64_t **)std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::_DetachedTreeCache::~_DetachedTreeCache[abi:ne180100]((uint64_t)&v15);
  }
  if (a2 != a3)
  {
    do
    {
      double result = (uint64_t **)std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::__emplace_multi<std::pair<std::string const,ZinIrName> const&>(v5, a2 + 2);
      uint64_t v13 = (long long *)*((void *)a2 + 1);
      if (v13)
      {
        do
        {
          uint64_t v14 = v13;
          uint64_t v13 = *(long long **)v13;
        }
        while (v13);
      }
      else
      {
        do
        {
          uint64_t v14 = (long long *)*((void *)a2 + 2);
          BOOL v12 = *(void *)v14 == (void)a2;
          a2 = v14;
        }
        while (!v12);
      }
      a2 = v14;
    }
    while (v14 != a3);
  }
  return result;
}

void sub_211363DEC(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::_DetachedTreeCache::~_DetachedTreeCache[abi:ne180100]((uint64_t)va);
  _Unwind_Resume(a1);
}

std::string **std::pair<std::string &,ZinIrName &>::operator=[abi:ne180100]<std::string const,ZinIrName,(void *)0>(std::string **a1, const std::string *a2)
{
  std::string::operator=(*a1, a2);
  unint64_t v4 = a1[1];
  std::string::operator=(v4, a2 + 1);
  std::string::operator=(v4 + 1, a2 + 2);
  std::string::operator=(v4 + 2, a2 + 3);
  return a1;
}

uint64_t std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::_DetachedTreeCache::~_DetachedTreeCache[abi:ne180100](uint64_t a1)
{
  std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::destroy(*(void *)a1, *(void **)(a1 + 16));
  uint64_t v2 = *(void **)(a1 + 8);
  if (v2)
  {
    uint64_t v3 = (void *)v2[2];
    if (v3)
    {
      do
      {
        uint64_t v2 = v3;
        uint64_t v3 = (void *)v3[2];
      }
      while (v3);
      *(void *)(a1 + 8) = v2;
    }
    std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::destroy(*(void *)a1, v2);
  }
  return a1;
}

uint64_t *std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::__emplace_multi<std::pair<std::string const,ZinIrName> const&>(uint64_t **a1, long long *a2)
{
  std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::__construct_node<std::pair<std::string const,ZinIrName> const&>((uint64_t)a1, a2, (uint64_t)v7);
  leaf_high = (uint64_t **)std::__tree<std::string>::__find_leaf_high((uint64_t)a1, &v6, v7[0] + 4);
  std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::__insert_node_at(a1, v6, leaf_high, v7[0]);
  unint64_t v4 = v7[0];
  v7[0] = 0;
  std::unique_ptr<std::__tree_node<std::__value_type<std::string,ZinIrName>,void *>,std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<std::string,ZinIrName>,void *>>>>::reset[abi:ne180100]((uint64_t)v7, 0);
  return v4;
}

void sub_211363F24(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::unique_ptr<std::__tree_node<std::__value_type<std::string,ZinIrName>,void *>,std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<std::string,ZinIrName>,void *>>>>::reset[abi:ne180100]((uint64_t)va, 0);
  _Unwind_Resume(a1);
}

std::string *std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::__construct_node<std::pair<std::string const,ZinIrName> const&>@<X0>(uint64_t a1@<X0>, long long *a2@<X1>, uint64_t a3@<X8>)
{
  uint64_t v5 = a1 + 8;
  uint64_t v6 = (char *)operator new(0x80uLL);
  *(void *)a3 = v6;
  *(void *)(a3 + 8) = v5;
  *(unsigned char *)(a3 + 16) = 0;
  double result = std::pair<std::string const,ZinIrName>::pair[abi:ne180100]((std::string *)(v6 + 32), a2);
  *(unsigned char *)(a3 + 16) = 1;
  return result;
}

void sub_211363F90(_Unwind_Exception *a1)
{
  std::unique_ptr<std::__tree_node<std::__value_type<std::string,ZinIrName>,void *>,std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<std::string,ZinIrName>,void *>>>>::reset[abi:ne180100](v1, 0);
  _Unwind_Resume(a1);
}

std::string *std::pair<std::string const,ZinIrName>::pair[abi:ne180100](std::string *this, long long *a2)
{
  if (*((char *)a2 + 23) < 0)
  {
    std::string::__init_copy_ctor_external(this, *(const std::string::value_type **)a2, *((void *)a2 + 1));
  }
  else
  {
    long long v4 = *a2;
    this->__r_.__value_.__r.__words[2] = *((void *)a2 + 2);
    *(_OWORD *)&this->__r_.__value_.__l.__data_ = v4;
  }
  if (*((char *)a2 + 47) < 0)
  {
    std::string::__init_copy_ctor_external(this + 1, *((const std::string::value_type **)a2 + 3), *((void *)a2 + 4));
  }
  else
  {
    long long v5 = *(long long *)((char *)a2 + 24);
    this[1].__r_.__value_.__r.__words[2] = *((void *)a2 + 5);
    *(_OWORD *)&this[1].__r_.__value_.__l.__data_ = v5;
  }
  if (*((char *)a2 + 71) < 0)
  {
    std::string::__init_copy_ctor_external(this + 2, *((const std::string::value_type **)a2 + 6), *((void *)a2 + 7));
  }
  else
  {
    long long v6 = a2[3];
    this[2].__r_.__value_.__r.__words[2] = *((void *)a2 + 8);
    *(_OWORD *)&this[2].__r_.__value_.__l.__data_ = v6;
  }
  uint64_t v7 = this + 3;
  if (*((char *)a2 + 95) < 0)
  {
    std::string::__init_copy_ctor_external(v7, *((const std::string::value_type **)a2 + 9), *((void *)a2 + 10));
  }
  else
  {
    long long v8 = *(long long *)((char *)a2 + 72);
    this[3].__r_.__value_.__r.__words[2] = *((void *)a2 + 11);
    *(_OWORD *)&v7->__r_.__value_.__l.__data_ = v8;
  }
  return this;
}

void sub_21136408C(_Unwind_Exception *exception_object)
{
  if (*(char *)(v1 + 71) < 0) {
    operator delete(*v3);
  }
  if (*(char *)(v1 + 47) < 0) {
    operator delete(*v2);
  }
  if (*(char *)(v1 + 23) < 0) {
    operator delete(*(void **)v1);
  }
  _Unwind_Resume(exception_object);
}

void std::__optional_storage_base<std::map<std::string,std::string>,false>::__assign_from[abi:ne180100]<std::__optional_copy_assign_base<std::map<std::string,std::string>,false> const&>(uint64_t a1, uint64_t a2)
{
  if (*(unsigned __int8 *)(a1 + 24) == *(unsigned __int8 *)(a2 + 24))
  {
    if (a1 != a2 && *(unsigned char *)(a1 + 24))
    {
      long long v4 = (long long *)(a2 + 8);
      uint64_t v3 = *(long long **)a2;
      std::__tree<std::__value_type<std::string,std::string>,std::__map_value_compare<std::string,std::__value_type<std::string,std::string>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,std::string>>>::__assign_multi<std::__tree_const_iterator<std::__value_type<std::string,std::string>,std::__tree_node<std::__value_type<std::string,std::string>,void *> *,long>>((uint64_t **)a1, v3, v4);
    }
  }
  else if (*(unsigned char *)(a1 + 24))
  {
    std::__tree<std::__value_type<std::string,ZinIrInputParamInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrInputParamInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrInputParamInfo>>>::destroy(a1, *(void **)(a1 + 8));
    *(unsigned char *)(a1 + 24) = 0;
  }
  else
  {
    std::map<std::string,std::string>::map[abi:ne180100]((uint64_t *)a1, a2);
    *(unsigned char *)(a1 + 24) = 1;
  }
}

uint64_t **std::__tree<std::__value_type<std::string,std::string>,std::__map_value_compare<std::string,std::__value_type<std::string,std::string>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,std::string>>>::__assign_multi<std::__tree_const_iterator<std::__value_type<std::string,std::string>,std::__tree_node<std::__value_type<std::string,std::string>,void *> *,long>>(uint64_t **result, long long *a2, long long *a3)
{
  long long v5 = result;
  if (result[2])
  {
    long long v6 = *result;
    uint64_t v7 = result[1];
    *double result = (uint64_t *)(result + 1);
    v7[2] = 0;
    result[1] = 0;
    result[2] = 0;
    if (v6[1]) {
      long long v8 = (uint64_t *)v6[1];
    }
    else {
      long long v8 = v6;
    }
    v15 = result;
    v16 = v8;
    v17 = v8;
    if (v8)
    {
      v16 = std::__tree<ZinIrTensor *,ZinIrIdComparator<ZinIrTensor *>,std::allocator<ZinIrTensor *>>::_DetachedTreeCache::__detach_next((uint64_t)v8);
      if (a2 != a3)
      {
        unint64_t v9 = a2;
        do
        {
          std::string::operator=((std::string *)(v8 + 4), (const std::string *)(v9 + 2));
          std::string::operator=((std::string *)(v8 + 7), (const std::string *)((char *)v9 + 56));
          leaf_high = (uint64_t **)std::__tree<std::string>::__find_leaf_high((uint64_t)v5, &v18, v17 + 4);
          std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::__insert_node_at(v5, v18, leaf_high, v17);
          v17 = v16;
          if (v16) {
            v16 = std::__tree<ZinIrTensor *,ZinIrIdComparator<ZinIrTensor *>,std::allocator<ZinIrTensor *>>::_DetachedTreeCache::__detach_next((uint64_t)v16);
          }
          uint64_t v11 = (long long *)*((void *)v9 + 1);
          if (v11)
          {
            do
            {
              a2 = v11;
              uint64_t v11 = *(long long **)v11;
            }
            while (v11);
          }
          else
          {
            do
            {
              a2 = (long long *)*((void *)v9 + 2);
              BOOL v12 = *(void *)a2 == (void)v9;
              unint64_t v9 = a2;
            }
            while (!v12);
          }
          long long v8 = v17;
          if (v17) {
            BOOL v12 = a2 == a3;
          }
          else {
            BOOL v12 = 1;
          }
          unint64_t v9 = a2;
        }
        while (!v12);
      }
    }
    double result = (uint64_t **)std::__tree<std::__value_type<std::string,std::string>,std::__map_value_compare<std::string,std::__value_type<std::string,std::string>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,std::string>>>::_DetachedTreeCache::~_DetachedTreeCache[abi:ne180100]((uint64_t)&v15);
  }
  if (a2 != a3)
  {
    do
    {
      double result = (uint64_t **)std::__tree<std::__value_type<std::string,std::string>,std::__map_value_compare<std::string,std::__value_type<std::string,std::string>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,std::string>>>::__emplace_multi<std::pair<std::string const,std::string> const&>(v5, a2 + 2);
      uint64_t v13 = (long long *)*((void *)a2 + 1);
      if (v13)
      {
        do
        {
          uint64_t v14 = v13;
          uint64_t v13 = *(long long **)v13;
        }
        while (v13);
      }
      else
      {
        do
        {
          uint64_t v14 = (long long *)*((void *)a2 + 2);
          BOOL v12 = *(void *)v14 == (void)a2;
          a2 = v14;
        }
        while (!v12);
      }
      a2 = v14;
    }
    while (v14 != a3);
  }
  return result;
}

void sub_2113642E4(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
}

uint64_t std::__tree<std::__value_type<std::string,std::string>,std::__map_value_compare<std::string,std::__value_type<std::string,std::string>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,std::string>>>::_DetachedTreeCache::~_DetachedTreeCache[abi:ne180100](uint64_t a1)
{
  std::__tree<std::__value_type<std::string,ZinIrInputParamInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrInputParamInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrInputParamInfo>>>::destroy(*(void *)a1, *(void **)(a1 + 16));
  uint64_t v2 = *(void **)(a1 + 8);
  if (v2)
  {
    uint64_t v3 = (void *)v2[2];
    if (v3)
    {
      do
      {
        uint64_t v2 = v3;
        uint64_t v3 = (void *)v3[2];
      }
      while (v3);
      *(void *)(a1 + 8) = v2;
    }
    std::__tree<std::__value_type<std::string,ZinIrInputParamInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrInputParamInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrInputParamInfo>>>::destroy(*(void *)a1, v2);
  }
  return a1;
}

uint64_t *std::__tree<std::__value_type<std::string,std::string>,std::__map_value_compare<std::string,std::__value_type<std::string,std::string>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,std::string>>>::__emplace_multi<std::pair<std::string const,std::string> const&>(uint64_t **a1, long long *a2)
{
  std::__tree<std::__value_type<std::string,std::string>,std::__map_value_compare<std::string,std::__value_type<std::string,std::string>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,std::string>>>::__construct_node<std::pair<std::string const,std::string> const&>((uint64_t)a1, a2, (uint64_t)v7);
  leaf_high = (uint64_t **)std::__tree<std::string>::__find_leaf_high((uint64_t)a1, &v6, v7[0] + 4);
  std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::__insert_node_at(a1, v6, leaf_high, v7[0]);
  long long v4 = v7[0];
  v7[0] = 0;
  std::unique_ptr<std::__tree_node<std::__value_type<std::string,std::string>,void *>,std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<std::string,std::string>,void *>>>>::reset[abi:ne180100]((uint64_t)v7, 0);
  return v4;
}

void sub_2113643BC(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::unique_ptr<std::__tree_node<std::__value_type<std::string,std::string>,void *>,std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<std::string,std::string>,void *>>>>::reset[abi:ne180100]((uint64_t)va, 0);
  _Unwind_Resume(a1);
}

uint64_t std::vector<ANECProcedureInfo>::__swap_out_circular_buffer(uint64_t *a1, void *a2)
{
  uint64_t result = std::__uninitialized_allocator_move_if_noexcept[abi:ne180100]<std::allocator<ANECProcedureInfo>,std::reverse_iterator<ANECProcedureInfo*>,std::reverse_iterator<ANECProcedureInfo*>,std::reverse_iterator<ANECProcedureInfo*>>((uint64_t)(a1 + 2), a1[1], a1[1], *a1, *a1, a2[1], a2[1]);
  a2[1] = v5;
  uint64_t v6 = *a1;
  *a1 = v5;
  a2[1] = v6;
  uint64_t v7 = a1[1];
  a1[1] = a2[2];
  a2[2] = v7;
  uint64_t v8 = a1[2];
  a1[2] = a2[3];
  a2[3] = v8;
  *a2 = a2[1];
  return result;
}

uint64_t std::__uninitialized_allocator_move_if_noexcept[abi:ne180100]<std::allocator<ANECProcedureInfo>,std::reverse_iterator<ANECProcedureInfo*>,std::reverse_iterator<ANECProcedureInfo*>,std::reverse_iterator<ANECProcedureInfo*>>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  uint64_t v10 = 0;
  uint64_t v11 = a7 - 168;
  while (a3 + v10 != a5)
  {
    BOOL v12 = (ANECProcedureInfo *)(v11 + v10);
    v10 -= 168;
    ANECProcedureInfo::ANECProcedureInfo(v12, (const ANECProcedureInfo *)(v10 + a3));
  }
  return a6;
}

uint64_t std::__split_buffer<ANECProcedureInfo>::~__split_buffer(uint64_t a1)
{
  uint64_t v3 = *(void *)(a1 + 8);
  for (uint64_t i = *(void *)(a1 + 16); i != v3; uint64_t i = *(void *)(a1 + 16))
  {
    *(void *)(a1 + 16) = i - 168;
    ANECProcedureInfo::~ANECProcedureInfo((char **)(i - 168));
  }
  if (*(void *)a1) {
    operator delete(*(void **)a1);
  }
  return a1;
}

void std::__function::__func<ANECGetCompilerOptions(__CFDictionary const*,ZinIrCompilerParameters &,ZinIrPlistCompilationStatus &)::$_3,std::allocator<ANECGetCompilerOptions(__CFDictionary const*,ZinIrCompilerParameters &,ZinIrPlistCompilationStatus &)::$_3>,void ()(SpatialSplitMode)>::~__func()
{
}

void *std::__function::__func<ANECGetCompilerOptions(__CFDictionary const*,ZinIrCompilerParameters &,ZinIrPlistCompilationStatus &)::$_3,std::allocator<ANECGetCompilerOptions(__CFDictionary const*,ZinIrCompilerParameters &,ZinIrPlistCompilationStatus &)::$_3>,void ()(SpatialSplitMode)>::__clone(uint64_t a1)
{
  uint64_t result = operator new(0x10uLL);
  uint64_t v3 = *(void *)(a1 + 8);
  *uint64_t result = &unk_26C381798;
  result[1] = v3;
  return result;
}

uint64_t std::__function::__func<ANECGetCompilerOptions(__CFDictionary const*,ZinIrCompilerParameters &,ZinIrPlistCompilationStatus &)::$_3,std::allocator<ANECGetCompilerOptions(__CFDictionary const*,ZinIrCompilerParameters &,ZinIrPlistCompilationStatus &)::$_3>,void ()(SpatialSplitMode)>::__clone(uint64_t result, void *a2)
{
  uint64_t v2 = *(void *)(result + 8);
  *a2 = &unk_26C381798;
  a2[1] = v2;
  return result;
}

void std::__function::__func<ANECGetCompilerOptions(__CFDictionary const*,ZinIrCompilerParameters &,ZinIrPlistCompilationStatus &)::$_3,std::allocator<ANECGetCompilerOptions(__CFDictionary const*,ZinIrCompilerParameters &,ZinIrPlistCompilationStatus &)::$_3>,void ()(SpatialSplitMode)>::operator()(uint64_t a1, unsigned int *a2)
{
  unsigned int v2 = *a2;
  uint64_t v3 = *(void *)(a1 + 8);
  std::string::basic_string[abi:ne180100]<0>(__p, &byte_211F4AA5D);
  ZinIrCompilerParameters::setSpatialSplitMode(v3, v2, (long long *)__p);
  if (v5 < 0) {
    operator delete(__p[0]);
  }
}

void sub_211364618(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11, int a12, __int16 a13, char a14, char a15)
{
  if (a15 < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t std::__function::__func<ANECGetCompilerOptions(__CFDictionary const*,ZinIrCompilerParameters &,ZinIrPlistCompilationStatus &)::$_3,std::allocator<ANECGetCompilerOptions(__CFDictionary const*,ZinIrCompilerParameters &,ZinIrPlistCompilationStatus &)::$_3>,void ()(SpatialSplitMode)>::target(uint64_t a1, uint64_t a2)
{
  {
    return a1 + 8;
  }
  else
  {
    return 0;
  }
}

void *std::__function::__func<ANECGetCompilerOptions(__CFDictionary const*,ZinIrCompilerParameters &,ZinIrPlistCompilationStatus &)::$_3,std::allocator<ANECGetCompilerOptions(__CFDictionary const*,ZinIrCompilerParameters &,ZinIrPlistCompilationStatus &)::$_3>,void ()(SpatialSplitMode)>::target_type()
{
}

void *std::__function::__value_func<void ()(SpatialSplitMode)>::~__value_func[abi:ne180100](void *a1)
{
  unsigned int v2 = (void *)a1[3];
  if (v2 == a1)
  {
    (*(void (**)(void *))(*a1 + 32))(a1);
  }
  else if (v2)
  {
    (*(void (**)(void *))(*v2 + 40))(v2);
  }
  return a1;
}

void std::__function::__func<ANECGetCompilerOptions(__CFDictionary const*,ZinIrCompilerParameters &,ZinIrPlistCompilationStatus &)::$_0,std::allocator<ANECGetCompilerOptions(__CFDictionary const*,ZinIrCompilerParameters &,ZinIrPlistCompilationStatus &)::$_0>,void ()(SpatialSplitMode)>::~__func()
{
}

__n128 std::__function::__func<ANECGetCompilerOptions(__CFDictionary const*,ZinIrCompilerParameters &,ZinIrPlistCompilationStatus &)::$_0,std::allocator<ANECGetCompilerOptions(__CFDictionary const*,ZinIrCompilerParameters &,ZinIrPlistCompilationStatus &)::$_0>,void ()(SpatialSplitMode)>::__clone(uint64_t a1)
{
  unsigned int v2 = (char *)operator new(0x18uLL);
  *(void *)unsigned int v2 = &unk_26C381740;
  __n128 result = *(__n128 *)(a1 + 8);
  *(__n128 *)(v2 + 8) = result;
  return result;
}

__n128 std::__function::__func<ANECGetCompilerOptions(__CFDictionary const*,ZinIrCompilerParameters &,ZinIrPlistCompilationStatus &)::$_0,std::allocator<ANECGetCompilerOptions(__CFDictionary const*,ZinIrCompilerParameters &,ZinIrPlistCompilationStatus &)::$_0>,void ()(SpatialSplitMode)>::__clone(uint64_t a1, uint64_t a2)
{
  *(void *)a2 = &unk_26C381740;
  __n128 result = *(__n128 *)(a1 + 8);
  *(__n128 *)(a2 + 8) = result;
  return result;
}

uint64_t std::__function::__func<ANECGetCompilerOptions(__CFDictionary const*,ZinIrCompilerParameters &,ZinIrPlistCompilationStatus &)::$_0,std::allocator<ANECGetCompilerOptions(__CFDictionary const*,ZinIrCompilerParameters &,ZinIrPlistCompilationStatus &)::$_0>,void ()(SpatialSplitMode)>::operator()(uint64_t a1, unsigned int *a2)
{
  return ZinIrCompilerParameters::setSpatialSplitMode(*(void *)(a1 + 8), *a2, *(long long **)(a1 + 16));
}

uint64_t std::__function::__func<ANECGetCompilerOptions(__CFDictionary const*,ZinIrCompilerParameters &,ZinIrPlistCompilationStatus &)::$_0,std::allocator<ANECGetCompilerOptions(__CFDictionary const*,ZinIrCompilerParameters &,ZinIrPlistCompilationStatus &)::$_0>,void ()(SpatialSplitMode)>::target(uint64_t a1, uint64_t a2)
{
  {
    return a1 + 8;
  }
  else
  {
    return 0;
  }
}

void *std::__function::__func<ANECGetCompilerOptions(__CFDictionary const*,ZinIrCompilerParameters &,ZinIrPlistCompilationStatus &)::$_0,std::allocator<ANECGetCompilerOptions(__CFDictionary const*,ZinIrCompilerParameters &,ZinIrPlistCompilationStatus &)::$_0>,void ()(SpatialSplitMode)>::target_type()
{
}

std::string *std::__fs::filesystem::path::path[abi:ne180100]<std::string,void>(std::string *a1, char *a2)
{
  a1->__r_.__value_.__r.__words[0] = 0;
  a1->__r_.__value_.__l.__size_ = 0;
  a1->__r_.__value_.__r.__words[2] = 0;
  LODWORD(v3) = a2[23];
  BOOL v4 = (int)v3 < 0;
  uint64_t v5 = *((void *)a2 + 1);
  if ((int)v3 < 0) {
    a2 = *(char **)a2;
  }
  uint64_t v3 = v3;
  if (v4) {
    uint64_t v3 = v5;
  }
  std::string::append[abi:ne180100]<char const*,0>(a1, a2, &a2[v3]);
  return a1;
}

void sub_211364840(_Unwind_Exception *exception_object)
{
  if (*(char *)(v1 + 23) < 0) {
    operator delete(*(void **)v1);
  }
  _Unwind_Resume(exception_object);
}

std::string *std::string::append[abi:ne180100]<char const*,0>(std::string *this, char *a2, char *a3)
{
  BOOL v4 = a2;
  LODWORD(v6) = SHIBYTE(this->__r_.__value_.__r.__words[2]);
  unint64_t v7 = a3 - a2;
  if ((v6 & 0x80000000) != 0)
  {
    if (a3 == a2) {
      return this;
    }
    std::string::size_type size = this->__r_.__value_.__l.__size_;
    unint64_t v11 = this->__r_.__value_.__r.__words[2];
    std::string::size_type v9 = (v11 & 0x7FFFFFFFFFFFFFFFLL) - 1;
    uint64_t v10 = (std::string *)this->__r_.__value_.__r.__words[0];
    unint64_t v6 = HIBYTE(v11);
  }
  else
  {
    if (a3 == a2) {
      return this;
    }
    std::string::size_type size = HIBYTE(this->__r_.__value_.__r.__words[2]);
    std::string::size_type v9 = 22;
    uint64_t v10 = this;
  }
  if (v10 > (std::string *)v4 || (char *)&v10->__r_.__value_.__l.__data_ + size + 1 <= v4)
  {
    if (v9 - size < v7)
    {
      std::string::__grow_by(this, v9, size - v9 + v7, size, size, 0, 0);
      this->__r_.__value_.__l.__size_ = size;
      LOBYTE(v6) = *((unsigned char *)&this->__r_.__value_.__s + 23);
    }
    uint64_t v14 = this;
    if ((v6 & 0x80) != 0) {
      uint64_t v14 = (std::string *)this->__r_.__value_.__r.__words[0];
    }
    for (uint64_t i = (char *)v14 + size; v4 != a3; ++i)
    {
      char v16 = *v4++;
      *uint64_t i = v16;
    }
    *uint64_t i = 0;
    std::string::size_type v17 = v7 + size;
    if (SHIBYTE(this->__r_.__value_.__r.__words[2]) < 0) {
      this->__r_.__value_.__l.__size_ = v17;
    }
    else {
      *((unsigned char *)&this->__r_.__value_.__s + 23) = v17 & 0x7F;
    }
  }
  else
  {
    std::string::__init_with_size[abi:ne180100]<char const*,char const*>(__p, v4, a3, v7);
    if ((v20 & 0x80u) == 0) {
      BOOL v12 = __p;
    }
    else {
      BOOL v12 = (void **)__p[0];
    }
    if ((v20 & 0x80u) == 0) {
      std::string::size_type v13 = v20;
    }
    else {
      std::string::size_type v13 = (std::string::size_type)__p[1];
    }
    std::string::append(this, (const std::string::value_type *)v12, v13);
    if ((char)v20 < 0) {
      operator delete(__p[0]);
    }
  }
  return this;
}

void sub_2113649B8(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11, int a12, __int16 a13, char a14, char a15)
{
  if (a15 < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

void *std::string::__init_with_size[abi:ne180100]<char const*,char const*>(void *result, char *a2, char *a3, unint64_t a4)
{
  BOOL v4 = result;
  if (a4 >= 0x7FFFFFFFFFFFFFF8) {
    std::string::__throw_length_error[abi:ne180100]();
  }
  if (a4 > 0x16)
  {
    uint64_t v8 = (a4 & 0xFFFFFFFFFFFFFFF8) + 8;
    if ((a4 | 7) != 0x17) {
      uint64_t v8 = a4 | 7;
    }
    uint64_t v9 = v8 + 1;
    __n128 result = operator new(v8 + 1);
    v4[1] = a4;
    v4[2] = v9 | 0x8000000000000000;
    *BOOL v4 = result;
    BOOL v4 = result;
  }
  else
  {
    *((unsigned char *)result + 23) = a4;
  }
  while (a2 != a3)
  {
    char v10 = *a2++;
    *(unsigned char *)BOOL v4 = v10;
    BOOL v4 = (void *)((char *)v4 + 1);
  }
  *(unsigned char *)BOOL v4 = 0;
  return result;
}

void ANECCreateProcedureInfoForSingleProcedureNetwork(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "Error: Could not sanitize the ANEC IR plist.", a5, a6, a7, a8, 0);
}

void ANECCreateProcedureInfoForMultiProcedureNetwork(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void ANECCreateCompilerPlistDictionaryFromANECIR(char *a1, void *a2)
{
  uint64_t v5 = *MEMORY[0x263EF8340];
  if (*a1 >= 0) {
    unsigned int v2 = a2;
  }
  else {
    unsigned int v2 = (void *)*a2;
  }
  int v3 = 136315138;
  BOOL v4 = v2;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "Error: Could not create dictionary from file \"%s\"", (uint8_t *)&v3, 0xCu);
}

void ANECCreateFileBacking(uint64_t a1, uint8_t *buf, int a3)
{
  *(_DWORD *)buf = 67109378;
  *((_DWORD *)buf + 1) = a3;
  *((_WORD *)buf + 4) = 2080;
  *(void *)(buf + 10) = a1;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "Failed to create temporary directory. %d: %s", buf, 0x12u);
}

uint64_t ZinIrNormUnitBase::TensorDimensions(ZinIrNormUnitBase *this, const ZinIrHalParameters *a2, ZinTensorDimensions *a3, ZinIrUnitStatus *a4)
{
  uint64_t v4 = *((void *)this + 1);
  long long v5 = *(_OWORD *)(v4 + 8);
  long long v6 = *(_OWORD *)(v4 + 24);
  *((void *)a3 + 4) = *(void *)(v4 + 40);
  *(_OWORD *)a3 = v5;
  *((_OWORD *)a3 + 1) = v6;
  return 0;
}

uint64_t ZinPELayer::LowerEngineCore()
{
  return 0;
}

void ZinPELayer::GetProjectedCoreInputDims(ZinPELayer *this@<X0>, uint64_t a2@<X8>)
{
  ZinANELayer::GetTensorDimsAfterTexture(this, a2);
  if ((*(unsigned int (**)(ZinPELayer *))(*(void *)this + 640))(this))
  {
    uint64_t v4 = *(void *)(a2 + 8);
    *(void *)(a2 + 8) = *(void *)(a2 + 24);
    *(void *)(a2 + 24) = v4;
  }
  if ((*(unsigned int (**)(ZinPELayer *))(*(void *)this + 656))(this))
  {
    uint64_t v5 = (*(uint64_t (**)(ZinPELayer *))(*(void *)this + 696))(this);
    long long v6 = operator new(0x28uLL);
    uint64_t v9 = (char *)v6 + 40;
    char v10 = (char *)v6 + 40;
    long long v7 = *(_OWORD *)(a2 + 16);
    *long long v6 = *(_OWORD *)a2;
    v6[1] = v7;
    *((void *)v6 + 4) = *(void *)(a2 + 32);
    __p = v6;
    (*(void (**)(uint64_t, void **, uint64_t))(*(void *)v5 + 216))(v5, &__p, a2);
    if (__p)
    {
      uint64_t v9 = __p;
      operator delete(__p);
    }
  }
}

void sub_211364D80(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinPELayer::IsChainableProducer(ZinPELayer *this, const ZinIrHalParameters *a2)
{
  return (*(unsigned int (**)(ZinPELayer *, const ZinIrHalParameters *))(*(void *)this + 408))(this, a2) ^ 1;
}

uint64_t ZinPELayer::IsChainableConsumer(void *a1, int a2)
{
  if (a2 == 2) {
    return 0;
  }
  if (a2 == 1)
  {
    if (((*(uint64_t (**)(void *))(*a1 + 664))(a1) & 1) != 0
      || ((*(uint64_t (**)(void *))(*a1 + 648))(a1) & 1) != 0
      || a1[25] && a1[24] == 1)
    {
      return 0;
    }
  }
  else if (!a2 {
         && (((*(uint64_t (**)(void *))(*a1 + 656))(a1) & 1) != 0
  }
          || ((*(uint64_t (**)(void *))(*a1 + 640))(a1) & 1) != 0
          || a1[25] && !a1[24]))
  {
    return 0;
  }
  return 1;
}

uint64_t ZinPELayer::HasInputTranspose(ZinPELayer *this, uint64_t a2)
{
  if (a2 == 1)
  {
    unsigned int v2 = *(uint64_t (**)(void))(*(void *)this + 648);
    return v2();
  }
  if (!a2)
  {
    unsigned int v2 = *(uint64_t (**)(void))(*(void *)this + 640);
    return v2();
  }
  if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
    ZinPELayer::HasInputTranspose();
  }
  return 0;
}

uint64_t ZinPELayer::IsQualifiedForInPlace(ZinIrOpLayer *a1, unint64_t a2, int a3, ZinTensorFamilyUtil *a4)
{
  int IsQualifiedForInPlace = ZinANELayer::IsQualifiedForInPlace(a1, a2, a3, a4);
  uint64_t v7 = *(void *)a1;
  if (a2)
  {
    if (((*(uint64_t (**)(ZinIrOpLayer *))(v7 + 648))(a1) & 1) == 0
      && ((*(uint64_t (**)(ZinIrOpLayer *))(*(void *)a1 + 664))(a1) & 1) == 0)
    {
LABEL_8:
      unsigned int v8 = (*(uint64_t (**)(ZinIrOpLayer *))(*(void *)a1 + 408))(a1) ^ 1;
      return IsQualifiedForInPlace & v8;
    }
  }
  else if (((*(uint64_t (**)(ZinIrOpLayer *))(v7 + 640))(a1) & 1) == 0 {
         && ((*(uint64_t (**)(ZinIrOpLayer *))(*(void *)a1 + 656))(a1) & 1) == 0)
  }
  {
    goto LABEL_8;
  }
  unsigned int v8 = 0;
  return IsQualifiedForInPlace & v8;
}

double ZinPELayer::SetL2SrcStrides(uint64_t **this, unint64_t a2, const ZinTensorDimensions *a3, uint64_t a4)
{
  InputTensor = (ZinIrTensor *)ZinIrOpLayer::GetInputTensor((ZinIrOpLayer *)this, a2);
  uint64_t v9 = (void *)((char *)InputTensor + 48);
  int v26 = 0;
  if (ZinMemSourceIndexTranslator::GetL2SrcType(this, a2, &v26)
    && os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR))
  {
    ZinPELayer::SetL2SrcStrides();
  }
  uint64_t TileSrc = ZinMirL2Config::GetTileSrc((uint64_t)(this[33] + 15), v26);
  v22[0] = *(_OWORD *)TileSrc;
  long long v12 = *(_OWORD *)(TileSrc + 32);
  long long v11 = *(_OWORD *)(TileSrc + 48);
  long long v13 = *(_OWORD *)(TileSrc + 16);
  uint64_t v25 = *(void *)(TileSrc + 64);
  long long v23 = v12;
  long long v24 = v11;
  v22[1] = v13;
  BOOL IsResident = ZinIrTensor::IsResident(InputTensor);
  Hal = ZinIrTarget::GetHal(this[2], (ZinIrTarget *)this[2][20]);
  uint64_t v16 = (*(uint64_t (**)(uint64_t *))(*Hal + 16))(Hal);
  ZinANELayer::SetL2SrcStridesCommon((uint64_t)this, (uint64_t *)a3, a4, IsResident, v9, v16, v22);
  BOOL v17 = ZinIrTensor::IsResident(InputTensor);
  uint64_t v18 = this[33];
  if (v17)
  {
    unint64_t v19 = v18[13];
    BOOL v20 = *v9 == 1 && v19 > 1;
    if (v20 || v19 == 1) {
      *(void *)&long long v23 = 0;
    }
  }
  *(void *)&double result = ZinMirL2Config::SetTileSrc((uint64_t)(v18 + 15), (uint64_t)v22, v26).n128_u64[0];
  return result;
}

BOOL ZinPELayer::HasOutputScaleOrBias(ZinPELayer *this)
{
  return *((unsigned char *)this + 376) || *((unsigned char *)this + 388) != 0;
}

uint64_t ZinPELayer::GetOutputScale(ZinPELayer *this)
{
  return (uint64_t)this + 368;
}

uint64_t ZinPELayer::GetOutputBias(ZinPELayer *this)
{
  return (uint64_t)this + 380;
}

uint64_t ZinPELayer::Hash(ZinPELayer *this, int *a2)
{
  uint64_t v4 = ZinANELayer::Hash(this, a2);
  if (!v4) {
    return v4;
  }
  v36 = 0;
  v37 = 0;
  v38 = 0;
  unint64_t __p = 0;
  v34 = 0;
  v35 = 0;
  if (*((unsigned char *)this + 376))
  {
    uint64_t v5 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ZinIrPaddingMode>>((uint64_t)&v38, 1uLL);
    *(_DWORD *)uint64_t v5 = *((_DWORD *)this + 92);
    v36 = v5;
    v38 = &v5[4 * v6];
    v37 = v5 + 4;
    if (!*((unsigned char *)this + 376)) {
      goto LABEL_56;
    }
    uint64_t v7 = operator new(1uLL);
    unsigned char *v7 = *((unsigned char *)this + 372);
    unsigned int v8 = v7 + 1;
    unint64_t __p = (unint64_t)v7;
    v35 = v7 + 1;
    v34 = v7 + 1;
  }
  else
  {
    unsigned int v8 = 0;
  }
  if (!*((unsigned char *)this + 388)) {
    goto LABEL_43;
  }
  uint64_t v9 = v37;
  if (v37 >= v38)
  {
    long long v11 = v36;
    uint64_t v12 = (v37 - v36) >> 2;
    unint64_t v13 = v12 + 1;
    if ((unint64_t)(v12 + 1) >> 62) {
      std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
    }
    uint64_t v14 = v38 - v36;
    if ((v38 - v36) >> 1 > v13) {
      unint64_t v13 = v14 >> 1;
    }
    if ((unint64_t)v14 >= 0x7FFFFFFFFFFFFFFCLL) {
      unint64_t v15 = 0x3FFFFFFFFFFFFFFFLL;
    }
    else {
      unint64_t v15 = v13;
    }
    if (v15)
    {
      uint64_t v16 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ZinIrPaddingMode>>((uint64_t)&v38, v15);
      long long v11 = v36;
      uint64_t v9 = v37;
    }
    else
    {
      uint64_t v16 = 0;
    }
    BOOL v17 = &v16[4 * v12];
    uint64_t v18 = &v16[4 * v15];
    *(_DWORD *)BOOL v17 = *((_DWORD *)this + 95);
    char v10 = v17 + 4;
    while (v9 != v11)
    {
      int v19 = *((_DWORD *)v9 - 1);
      v9 -= 4;
      *((_DWORD *)v17 - 1) = v19;
      v17 -= 4;
    }
    v36 = v17;
    v38 = v18;
    if (v11) {
      operator delete(v11);
    }
  }
  else
  {
    *(_DWORD *)v37 = *((_DWORD *)this + 95);
    char v10 = v37 + 4;
  }
  v37 = v10;
  if (!*((unsigned char *)this + 388)) {
LABEL_56:
  }
    std::__throw_bad_optional_access[abi:ne180100]();
  BOOL v20 = v34;
  if (v34 >= v35)
  {
    v21 = &v34[-__p];
    uint64_t v22 = (uint64_t)&v34[-__p + 1];
    if (v22 < 0) {
      std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
    }
    unint64_t v23 = (unint64_t)&v35[-__p];
    if (2 * (uint64_t)&v35[-__p] > (unint64_t)v22) {
      uint64_t v22 = 2 * v23;
    }
    if (v23 >= 0x3FFFFFFFFFFFFFFFLL) {
      size_t v24 = 0x7FFFFFFFFFFFFFFFLL;
    }
    else {
      size_t v24 = v22;
    }
    if (v24) {
      unint64_t v25 = (unint64_t)operator new(v24);
    }
    else {
      unint64_t v25 = 0;
    }
    v21[v25] = *((unsigned char *)this + 384);
    unsigned int v8 = &v21[v25 + 1];
    if (v34 == (char *)__p)
    {
      v25 += (unint64_t)v21;
    }
    else
    {
      int v26 = &v34[~__p];
      do
      {
        char v27 = *--v20;
        (v26--)[v25] = v27;
      }
      while (v20 != (char *)__p);
      BOOL v20 = (char *)__p;
    }
    unint64_t __p = v25;
    if (v20) {
      operator delete(v20);
    }
  }
  else
  {
    char *v34 = *((unsigned char *)this + 384);
    unsigned int v8 = v34 + 1;
  }
  v34 = v8;
LABEL_43:
  if (v37 == v36)
  {
    unsigned int v8 = (char *)__p;
LABEL_48:
    if (!v8) {
      goto LABEL_50;
    }
    goto LABEL_49;
  }
  if (v8 == (char *)__p) {
    goto LABEL_48;
  }
  int v28 = *a2;
  int v29 = ZinHash(v36, (int)v37 - (int)v36);
  if ((char *)__p == v34) {
    int v30 = 0;
  }
  else {
    int v30 = ZinHash((const void *)__p, (int)v34 - (int)__p);
  }
  v32 = operator new(0xCuLL);
  _DWORD *v32 = v28;
  v32[1] = v29;
  v32[2] = v30;
  *a2 = ZinHash(v32, 0xCu);
  operator delete(v32);
  unsigned int v8 = (char *)__p;
  if (!__p) {
    goto LABEL_50;
  }
LABEL_49:
  operator delete(v8);
LABEL_50:
  if (v36) {
    operator delete(v36);
  }
  return v4;
}

void sub_211365664(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, void *__p, uint64_t a10, uint64_t a11, void *a12, uint64_t a13)
{
  operator delete(v13);
  if (__p) {
    operator delete(__p);
  }
  if (a12) {
    operator delete(a12);
  }
  _Unwind_Resume(a1);
}

void ZinPELayer::HasInputTranspose()
{
  *(_WORD *)v0 = 0;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "Checked for Input Transpose on invalid operand\n", v0, 2u);
}

void ZinPELayer::SetL2SrcStrides()
{
  *(_WORD *)v0 = 0;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "Error: Engine layer has a invalid L2 source.", v0, 2u);
}

void FifoMode::GetFifoModeUtil(FifoMode *this, const ZinIrHalParameters *a2)
{
  int v2 = *((_DWORD *)this + 424);
  if (v2 != 2)
  {
    if (v2 == 1) {
      operator new();
    }
    operator new();
  }
  operator new();
}

uint64_t FifoModeUtilV1::CanEnableNEOutputFIFOMode(uint64_t a1, ZinEngineLayerMirInfo **a2, unint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, int a8)
{
  uint64_t v51 = *MEMORY[0x263EF8340];
  if (!a2
    || *(unsigned char *)((*((uint64_t (**)(ZinEngineLayerMirInfo **, void, void))*a2 + 4))(a2, 0, 0) + 164)
    || a3 == 3 && *(unsigned char *)(*(void *)(a1 + 8) + 1313))
  {
    return 0;
  }
  unint64_t v49 = 0;
  BOOL v17 = (ZinMirL2Config *)(*((uint64_t (**)(ZinEngineLayerMirInfo **, void, void))*a2 + 4))(a2, 0, 0);
  char L2FormatSize = ZinMirL2Config::GetL2FormatSize(v17, v18);
  unsigned int v19 = *(_DWORD *)ZinMirL2Config::GetTileSrc((uint64_t)a2[33] + 120, 0);
  if (IsFormatDMAConvertibleToFP16(v19)) {
    int v20 = 3;
  }
  else {
    int v20 = v19;
  }
  if (ZinTensorFormatGetSizeInBytes(v20, (uint64_t *)&v49)) {
    ZinAssertImpl("Error in getting tensor format size in bytes");
  }
  unint64_t v21 = v49;
  ChannelAssignment = (MirInfoChannelAssignment *)ZinEngineLayerMirInfo::GetChannelAssignment(a2[33]);
  uint64_t NumNeededNEsNextPow2 = MirInfoChannelAssignment::GetNumNeededNEsNextPow2(ChannelAssignment);
  unint64_t v23 = (MirInfoChannelAssignment *)ZinEngineLayerMirInfo::GetChannelAssignment(a2[33]);
  uint64_t OCGSizeNextPow2 = MirInfoChannelAssignment::GetOCGSizeNextPow2(v23);
  int v24 = (*((uint64_t (**)(ZinEngineLayerMirInfo **))*a2 + 43))(a2);
  int v25 = (*((uint64_t (**)(ZinEngineLayerMirInfo **))*a2 + 51))(a2);
  int v26 = operator new(8uLL);
  unint64_t __p = v26;
  *int v26 = a6;
  v48 = v26 + 1;
  v47 = v26 + 1;
  if (*(unsigned char *)(*(void *)(a1 + 8) + 1312))
  {
    __src[0] = a5;
    __src[1] = a6;
    __src[2] = a7;
    std::vector<DimensionMapping>::__assign_with_size[abi:ne180100]<DimensionMapping const*,DimensionMapping const*>((char *)&__p, (char *)__src, (uint64_t)&v51, 3uLL);
  }
  unint64_t v27 = (*((uint64_t (**)(ZinEngineLayerMirInfo **, uint64_t))*a2 + 46))(a2, 4);
  unint64_t v28 = (*((uint64_t (**)(ZinEngineLayerMirInfo **, uint64_t))*a2 + 46))(a2, 2);
  unint64_t v29 = OCGSizeNextPow2 * NumNeededNEsNextPow2;
  int v30 = __p;
  if (__p != v47)
  {
    uint64_t v31 = *(void *)(a1 + 8);
    do
    {
      char v32 = OCGSizeNextPow2 * NumNeededNEsNextPow2;
      BOOL v33 = v28 <= v29;
      if ((v25 & 1) == 0)
      {
        unint64_t v34 = *(void *)(v31 + 592) / *v30 / v21;
        char v32 = v34 * v24;
        if (a8) {
          BOOL v35 = 0;
        }
        else {
          BOOL v35 = v27 > v34;
        }
        BOOL v33 = !v35;
      }
      uint64_t v36 = (L2FormatSize * (_BYTE)a3 * v32) & 0x3F;
      if (*(unsigned char *)(v31 + 1880))
      {
        if (!v36) {
          BOOL v33 = 1;
        }
        if (!v33) {
          goto LABEL_51;
        }
      }
      else if (v36)
      {
        goto LABEL_51;
      }
      ++v30;
    }
    while (v30 != v47);
  }
  if (!v25)
  {
    if (v28 <= v29) {
      goto LABEL_49;
    }
    if (v29 % a3 || *((_DWORD *)a2[33] + 364)) {
      goto LABEL_51;
    }
    uint64_t v40 = *(void *)(a1 + 8);
LABEL_48:
    if (!*(unsigned char *)(v40 + 1233) && v28 % a3) {
      goto LABEL_51;
    }
LABEL_49:
    uint64_t v15 = 1;
    goto LABEL_52;
  }
  unint64_t v37 = v28;
  unsigned int v38 = *((_DWORD *)a2[33] + 66);
  if (IsFormatDMAConvertibleToFP16(v38)) {
    int v39 = 3;
  }
  else {
    int v39 = v38;
  }
  unint64_t v28 = v37;
  if ((v39 - 1) >= 2)
  {
    if (v39 == 3)
    {
      if ((v29 & 7) == 0) {
        goto LABEL_43;
      }
      goto LABEL_51;
    }
    if (v39 != 12) {
      goto LABEL_51;
    }
  }
  if ((v29 & 0xF) == 0)
  {
LABEL_43:
    v41 = __p;
    uint64_t v40 = *(void *)(a1 + 8);
    if (__p != v47)
    {
      while (1)
      {
        unint64_t v42 = *(void *)(v40 + 592) / *v41 / v21;
        if (v27 > v42 && (v42 * v24 % a3 || *((_DWORD *)a2[33] + 364))) {
          goto LABEL_51;
        }
        if (++v41 == v47) {
          goto LABEL_48;
        }
      }
    }
    goto LABEL_48;
  }
LABEL_51:
  uint64_t v15 = 0;
LABEL_52:
  if (__p)
  {
    v47 = __p;
    operator delete(__p);
  }
  return v15;
}

void sub_211365C28(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, void *__p, uint64_t a14)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

BOOL FifoModeUtilV1::CanEnablePEOutputFIFOMode(uint64_t a1, uint64_t a2, uint64_t a3, unint64_t a4, uint64_t a5, int a6, uint64_t a7, int a8, int a9)
{
  if (!a2
    || ((*(uint64_t (**)(uint64_t))(*(void *)a2 + 408))(a2) & 1) != 0
    || *(unsigned char *)((*(uint64_t (**)(uint64_t, void, void))(*(void *)a2 + 32))(a2, 0, 0) + 164))
  {
    return 0;
  }
  unint64_t v15 = *(void *)(a3 + 24);
  unint64_t v16 = 0;
  if (ZinTensorFormatGetSizeInBytes(a9, (uint64_t *)&v16)) {
    ZinAssertImpl("Error in getting tensor format size in bytes");
  }
  return v15 <= a4 || ((a8 * a6 * (a4 / v16)) & 0x3FLL) == 0;
}

ZinEngineLayerMirInfo **FifoModeUtilV2::CanEnableNEOutputFIFOMode(uint64_t a1, ZinEngineLayerMirInfo **a2, unint64_t a3, uint64_t a4, unint64_t a5, unint64_t a6, uint64_t a7, int a8, char a9)
{
  char v16 = a9;
  ChannelAssignment = (MirInfoChannelAssignment *)ZinEngineLayerMirInfo::GetChannelAssignment(a2[33]);
  char NumNeededNEsNextPow2 = MirInfoChannelAssignment::GetNumNeededNEsNextPow2(ChannelAssignment);
  unsigned int v19 = (MirInfoChannelAssignment *)ZinEngineLayerMirInfo::GetChannelAssignment(a2[33]);
  char OCGSizeNextPow2 = MirInfoChannelAssignment::GetOCGSizeNextPow2(v19);
  if (!(*((unsigned int (**)(ZinEngineLayerMirInfo **))*a2 + 51))(a2)) {
    goto LABEL_11;
  }
  unint64_t v21 = a3;
  uint64_t v22 = a4;
  unint64_t v23 = a5;
  unint64_t v24 = a6;
  int v25 = a8;
  unsigned int v26 = *((_DWORD *)a2[33] + 66);
  if (IsFormatDMAConvertibleToFP16(v26)) {
    int v27 = 3;
  }
  else {
    int v27 = v26;
  }
  a8 = v25;
  a6 = v24;
  a5 = v23;
  a4 = v22;
  a3 = v21;
  char v16 = a9;
  if ((v27 - 1) >= 2)
  {
    if (v27 == 3)
    {
      if (((OCGSizeNextPow2 * NumNeededNEsNextPow2) & 7) != 0) {
        return 0;
      }
      goto LABEL_11;
    }
    if (v27 != 12) {
      return 0;
    }
  }
  if (((OCGSizeNextPow2 * NumNeededNEsNextPow2) & 0xF) != 0) {
    return 0;
  }
LABEL_11:
  unint64_t v29 = *(void **)(a1 + 8);

  return UtilCanEnableNEOutputFIFOMode(a2, a3, a4, a5, a6, a8, v16, v29);
}

ZinEngineLayerMirInfo **UtilCanEnableNEOutputFIFOMode(ZinEngineLayerMirInfo **result, unint64_t a2, uint64_t a3, unint64_t a4, unint64_t a5, int a6, char a7, void *a8)
{
  if (!result) {
    return result;
  }
  uint64_t v14 = result;
  int v49 = 0;
  uint64_t v15 = (*((uint64_t (**)(ZinEngineLayerMirInfo **, void))*result + 63))(result, 0);
  uint64_t v16 = (*(uint64_t (**)(uint64_t, void, void))(*(void *)v15 + 32))(v15, 0, 0);
  if (GetHWChannelFormat(*(_DWORD *)(v16 + 88), &v49)) {
    ZinAssertImpl("[Error] FifoModeUtil: Invalid input tensor format.");
  }
  char v17 = v49 == 2;
  ChannelAssignment = (ZinIrTarget *)ZinEngineLayerMirInfo::GetChannelAssignment(v14[33]);
  char Lut = ZinIrTarget::GetLut(ChannelAssignment);
  if (a6 == 3)
  {
    unint64_t v20 = a8[148];
    unint64_t v21 = v20 >> (a7 + v17);
    goto LABEL_7;
  }
  if (a6 == 4)
  {
    unint64_t v20 = a8[146];
    unint64_t v21 = v20 >> v17;
LABEL_7:
    a4 = a8[103] / v20;
    goto LABEL_9;
  }
  uint64_t v22 = (MirInfoChannelAssignment *)ZinEngineLayerMirInfo::GetChannelAssignment(v14[33]);
  unint64_t v21 = (a8[74] / a5) >> (a7 + v17) << MirInfoChannelAssignment::GetFatTileEnable(v22);
LABEL_9:
  unint64_t v23 = a4 << Lut;
  unint64_t v24 = (MirInfoChannelAssignment *)ZinEngineLayerMirInfo::GetChannelAssignment(v14[33]);
  uint64_t NumNeededNEsNextPow2 = MirInfoChannelAssignment::GetNumNeededNEsNextPow2(v24);
  unsigned int v26 = (MirInfoChannelAssignment *)ZinEngineLayerMirInfo::GetChannelAssignment(v14[33]);
  unint64_t v27 = MirInfoChannelAssignment::GetOCGSizeNextPow2(v26) * NumNeededNEsNextPow2;
  unint64_t v28 = (*((uint64_t (**)(ZinEngineLayerMirInfo **, uint64_t))*v14 + 46))(v14, 4);
  unint64_t v29 = (*((uint64_t (**)(ZinEngineLayerMirInfo **, uint64_t))*v14 + 46))(v14, 2);
  uint64_t v30 = (*((uint64_t (**)(ZinEngineLayerMirInfo **))*v14 + 43))(v14);
  BOOL v31 = v28 <= v21;
  BOOL v32 = v29 <= v27;
  int v33 = (*((uint64_t (**)(ZinEngineLayerMirInfo **))*v14 + 51))(v14);
  unint64_t v34 = (int)v30 * v21;
  if (v33) {
    BOOL v35 = v31;
  }
  else {
    BOOL v35 = v32;
  }
  if (v33)
  {
    unint64_t v36 = (int)v30 * v21;
  }
  else
  {
    BOOL v32 = v31;
    unint64_t v36 = v27;
  }
  if (!v33) {
    unint64_t v27 = v34;
  }
  unint64_t v37 = (*((uint64_t (**)(ZinEngineLayerMirInfo **, uint64_t))*v14 + 46))(v14, 3);
  if (!*(unsigned char *)((*((uint64_t (**)(ZinEngineLayerMirInfo **, void, void))*v14 + 4))(v14, 0, 0) + 164))
  {
    LODWORD(v48) = 0;
    uint64_t v41 = (*((uint64_t (**)(ZinEngineLayerMirInfo **, void, void))*v14 + 4))(v14, 0, 0);
    if (!GetHWDMAFormatMode(*(_DWORD *)(v41 + 88), (int *)&v48))
    {
      unint64_t v39 = GetHWDMAFormatBytes((int *)&v48, a2) * v27 % a8[66];
      BOOL v40 = 1;
      goto LABEL_23;
    }
    return 0;
  }
  unint64_t v48 = 1;
  unsigned int v38 = (const ZinIrTensor *)(*((uint64_t (**)(ZinEngineLayerMirInfo **, void, void))*v14 + 4))(v14, 0, 0);
  if (GetImbSize(v38, &v48)) {
    return 0;
  }
  unint64_t v39 = v27 % v48;
  BOOL v40 = (v30 >> 32) * v23 % v48 == 0;
LABEL_23:
  if (v36 % a2) {
    BOOL v42 = 0;
  }
  else {
    BOOL v42 = *((_DWORD *)v14[33] + 364) == 0;
  }
  double result = 0;
  int v43 = v37 <= v23 || v40;
  int v44 = v35 || v42;
  if (v39) {
    BOOL v45 = !v32;
  }
  else {
    BOOL v45 = 0;
  }
  if (!v45 && v43)
  {
    if (v44)
    {
      uint64_t v46 = (*((uint64_t (**)(ZinEngineLayerMirInfo **, void, void))*v14 + 4))(v14, 0, 0);
      return (ZinEngineLayerMirInfo **)!ZinCropOffsetUtil::HasUnalignedOutputCropX(*(_DWORD *)(v46 + 88), a3, (uint64_t)a8);
    }
  }
  return result;
}

uint64_t FifoModeUtilV2::CanEnablePEOutputFIFOMode(uint64_t a1, uint64_t a2, uint64_t a3, unint64_t a4, unint64_t a5, uint64_t a6, uint64_t a7)
{
  return UtilCanEnablePEOutputFIFOMode(a2, a4, a5, a6, a7, *(void *)(a1 + 8));
}

uint64_t UtilCanEnablePEOutputFIFOMode(uint64_t result, unint64_t a2, unint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  if (result)
  {
    long long v11 = (void *)result;
    if ((*(uint64_t (**)(uint64_t))(*(void *)result + 344))(result) == 0x200000002) {
      return 0;
    }
    if ((*(uint64_t (**)(void *))(*v11 + 408))(v11)) {
      return 0;
    }
    uint64_t v12 = (*(uint64_t (**)(void *, uint64_t))(*v11 + 368))(v11, 4);
    if (*(_DWORD *)(v11[33] + 1456)) {
      return 0;
    }
    unint64_t v13 = v12;
    if (*(_DWORD *)(v11[8] + 8) == 81 && v11[63]) {
      return 1;
    }
    if (*(unsigned char *)((*(uint64_t (**)(void *, void, void))(*v11 + 32))(v11, 0, 0) + 164))
    {
      unint64_t v24 = 1;
      uint64_t v14 = (const ZinIrTensor *)(*(uint64_t (**)(void *, void, void))(*v11 + 32))(v11, 0, 0);
      if (GetImbSize(v14, &v24)) {
        return 0;
      }
      unint64_t v15 = (*(uint64_t (**)(void *, uint64_t))(*v11 + 368))(v11, 3);
      unint64_t v16 = v15;
      unint64_t v17 = *(void *)(v11[33] + 200);
      if (v15 > v17)
      {
        if (v17 % v24) {
          return 0;
        }
      }
      if (v13 <= a2)
      {
        if (v15 <= a3) {
          return 1;
        }
        unint64_t v18 = v24;
      }
      else
      {
        unint64_t v18 = v24;
        double result = a2 % v24 == 0;
        if (v16 <= a3 || a2 % v24) {
          return result;
        }
      }
      return a3 % v18 == 0;
    }
    int v23 = 0;
    uint64_t v19 = (*(uint64_t (**)(void *, void, void))(*v11 + 32))(v11, 0, 0);
    int HWDMAFormatMode = GetHWDMAFormatMode(*(_DWORD *)(v19 + 88), &v23);
    double result = 0;
    if (!HWDMAFormatMode)
    {
      uint64_t HWDMAFormatBytes = GetHWDMAFormatBytes(&v23, a4);
      if (v13 <= a2 || !(HWDMAFormatBytes * a2 % *(void *)(a6 + 528)))
      {
        uint64_t v22 = (*(uint64_t (**)(void *, void, void))(*v11 + 32))(v11, 0, 0);
        return !ZinCropOffsetUtil::HasUnalignedOutputCropX(*(_DWORD *)(v22 + 88), a5, a6);
      }
      return 0;
    }
  }
  return result;
}

BOOL FifoModeUtilV2::CanEnableNEInputFIFOMode(FifoModeUtilV2 *this, const ZinNELayer *a2, unint64_t a3, const ZinMirL2Config::NE *a4, unint64_t a5, unint64_t a6)
{
  return UtilCanEnableNEInputFIFOMode((BOOL)a2, a3, a4, a5, a6);
}

BOOL UtilCanEnableNEInputFIFOMode(BOOL result, unint64_t a2, const ZinMirL2Config::NE *a3, unint64_t a4, unint64_t a5)
{
  if (result)
  {
    uint64_t v9 = (void *)result;
    InputTensor = (const ZinIrTensor *)ZinIrOpLayer::GetInputTensor((ZinIrOpLayer *)result, a2);
    double result = HasValidL2AndDMAGranularityConstraintForDRAMInputFIFOMode(InputTensor, a5);
    if (result)
    {
      if ((*((_DWORD *)a3 + 6) - 3) < 2) {
        return 0;
      }
      uint64_t v11 = *((void *)a3 + 2);
      ChannelAssignment = (ZinIrTarget *)ZinMirL2Config::NE::GetChannelAssignment(a3);
      if (v11 * (1 << ZinIrTarget::GetLut(ChannelAssignment)) < a4) {
        return 0;
      }
      double result = 0;
      uint64_t v13 = *((void *)a3 + 2);
      if (v13 != *(void *)a3 || v13 != *((void *)a3 + 1)) {
        return result;
      }
      uint64_t v14 = (MirInfoChannelAssignment *)ZinMirL2Config::NE::GetChannelAssignment(a3);
      uint64_t OCGSizeNextPow2 = MirInfoChannelAssignment::GetOCGSizeNextPow2(v14);
      unint64_t v16 = (MirInfoChannelAssignment *)ZinMirL2Config::NE::GetChannelAssignment(a3);
      unint64_t v17 = MirInfoChannelAssignment::GetActiveNEPerCluster(v16) * OCGSizeNextPow2;
      if (v17 < (*(uint64_t (**)(void *, uint64_t))(*v9 + 368))(v9, 2)) {
        return 0;
      }
      (*(void (**)(void *__return_ptr, void *))(*v9 + 136))(v25, v9);
      if (v26)
      {
        (*(void (**)(void *__return_ptr, void *))(*v9 + 136))(v24, v9);
        if (v24[2] != 1) {
          return 0;
        }
        (*(void (**)(void *__return_ptr, void *))(*v9 + 136))(v22, v9);
        if (v23 != 1) {
          return 0;
        }
      }
      if (*(_DWORD *)(v9[8] + 8) == 90)
      {
        uint64_t v18 = v9[33];
        if (v18)
        {
          if (a2 >= 2) {
            std::__throw_out_of_range[abi:ne180100]("array::at");
          }
          unsigned int v19 = *(_DWORD *)(v18 + 8 * a2 + 1464);
          int v20 = *(_DWORD *)(v18 + 4 * a2 + 1448);
        }
        else
        {
          unsigned int v19 = 0;
          LOBYTE(v20) = 0;
        }
        char v21 = ZinCountOnes<unsigned int>(v19);
        double result = ZinIsEven(a5 - v21);
        if (result) {
          return ZinIsEven(v20);
        }
      }
      else
      {
        return 1;
      }
    }
  }
  return result;
}

uint64_t FifoModeUtilV2::CanEnablePEInputFIFOMode(uint64_t a1, uint64_t a2, int a3, unint64_t a4, unint64_t a5, unint64_t a6)
{
  return UtilCanEnablePEInputFIFOMode(a2, a3, a4, a5, a6);
}

uint64_t UtilCanEnablePEInputFIFOMode(uint64_t result, int a2, unint64_t a3, unint64_t a4, unint64_t a5)
{
  if (result)
  {
    uint64_t v9 = (ZinIrOpLayer *)result;
    unint64_t v13 = 0;
    if (ZinMemSourceIndexTranslator::GetIncomingSrcIndexFromL2SrcType((void *)result, a2, &v13)) {
      ZinAssertImpl("L2 index translator failed.");
    }
    InputTensor = (const ZinIrTensor *)ZinIrOpLayer::GetInputTensor(v9, v13);
    BOOL valid = HasValidL2AndDMAGranularityConstraintForDRAMInputFIFOMode(InputTensor, a5);
    double result = 0;
    if (a3 >= a4 && valid)
    {
      if (a2 == 1)
      {
        if (((*(uint64_t (**)(ZinIrOpLayer *))(*(void *)v9 + 664))(v9) & 1) != 0
          || ((*(uint64_t (**)(ZinIrOpLayer *))(*(void *)v9 + 648))(v9) & 1) != 0)
        {
          return 0;
        }
        int v12 = *(_DWORD *)(*((void *)v9 + 8) + 8);
        if (v12 == 83)
        {
          if ((*(uint64_t (**)(ZinIrOpLayer *))(*(void *)v9 + 568))(v9)) {
            return 0;
          }
          int v12 = *(_DWORD *)(*((void *)v9 + 8) + 8);
        }
        if (v12 != 84) {
          return 1;
        }
      }
      else if (a2 {
             || ((*(uint64_t (**)(ZinIrOpLayer *))(*(void *)v9 + 656))(v9) & 1) == 0
      }
             && ((*(uint64_t (**)(ZinIrOpLayer *))(*(void *)v9 + 640))(v9) & 1) == 0)
      {
        return 1;
      }
      return 0;
    }
  }
  return result;
}

ZinEngineLayerMirInfo **FifoModeUtilV3::CanEnableNEOutputFIFOMode(uint64_t a1, ZinEngineLayerMirInfo **a2, unint64_t a3, uint64_t a4, unint64_t a5, unint64_t a6, uint64_t a7, int a8, char a9)
{
  return UtilCanEnableNEOutputFIFOMode(a2, a3, a4, a5, a6, a8, a9, *(void **)(a1 + 8));
}

uint64_t FifoModeUtilV3::CanEnablePEOutputFIFOMode(uint64_t a1, uint64_t a2, uint64_t a3, unint64_t a4, unint64_t a5, uint64_t a6, uint64_t a7)
{
  return UtilCanEnablePEOutputFIFOMode(a2, a4, a5, a6, a7, *(void *)(a1 + 8));
}

BOOL FifoModeUtilV3::CanEnableNEInputFIFOMode(FifoModeUtilV3 *this, const ZinNELayer *a2, unint64_t a3, const ZinMirL2Config::NE *a4, unint64_t a5, unint64_t a6)
{
  return UtilCanEnableNEInputFIFOMode((BOOL)a2, a3, a4, a5, a6);
}

uint64_t FifoModeUtilV3::CanEnablePEInputFIFOMode(uint64_t a1, uint64_t a2, int a3, unint64_t a4, unint64_t a5, unint64_t a6)
{
  return UtilCanEnablePEInputFIFOMode(a2, a3, a4, a5, a6);
}

uint64_t GetImbSize(const ZinIrTensor *a1, unint64_t *a2)
{
  *a2 = 1;
  if (!*((unsigned char *)a1 + 164)) {
    return 0;
  }
  uint64_t InterchangeDescriptor = ZinIrTensor::GetInterchangeDescriptor(a1);
  if (HIDWORD(InterchangeDescriptor))
  {
    if (HIDWORD(InterchangeDescriptor) == 1)
    {
      uint64_t result = 0;
      unint64_t v5 = 32;
      goto LABEL_11;
    }
    if (HIDWORD(InterchangeDescriptor) == 2)
    {
      uint64_t result = 0;
      unint64_t v5 = 16;
LABEL_11:
      *a2 = v5;
      return result;
    }
    return 0;
  }
  if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
    GetImbSize();
  }
  return 3;
}

BOOL HasValidL2AndDMAGranularityConstraintForDRAMInputFIFOMode(const ZinIrTensor *a1, unint64_t a2)
{
  unsigned int v4 = *((_DWORD *)a1 + 22);
  if (IsFormatDMAConvertibleToFP16(v4)) {
    int v5 = 3;
  }
  else {
    int v5 = v4;
  }
  if (!IsPrimaryFormat(v5)) {
    ZinAssertImpl("L2 format should be one of the supported primary formats.");
  }
  if ((v5 - 1) < 2 || v5 == 12)
  {
    unint64_t v7 = 16;
  }
  else
  {
    if (v5 != 3) {
      ZinAssertImpl("Invalid primary format");
    }
    unint64_t v7 = 8;
  }
  if (a2 == 3) {
    a2 = 1;
  }
  int v11 = 0;
  if (GetHWDMAFormatMode(v4, &v11)) {
    ZinAssertImpl("Invalid input DMA format");
  }
  if (*((unsigned char *)a1 + 164))
  {
    switch(v11)
    {
      case 0:
        goto LABEL_22;
      case 1:
      case 3:
        ZinAssertImpl("Invalid input DMA format for compressed tensor");
      case 2:
        unint64_t v8 = 8;
        return v8 <= v7;
      default:
        goto LABEL_21;
    }
  }
  switch(v11)
  {
    case 0:
      unint64_t v9 = 64;
      goto LABEL_25;
    case 1:
LABEL_22:
      unint64_t v8 = 16;
      return v8 <= v7;
    case 2:
      unint64_t v9 = 32;
      goto LABEL_25;
    case 3:
      unint64_t v9 = 16;
LABEL_25:
      unint64_t v8 = v9 / a2;
      break;
    default:
LABEL_21:
      unint64_t v8 = 1;
      break;
  }
  return v8 <= v7;
}

void GetImbSize()
{
  *(_WORD *)v0 = 0;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "Error: Attempting to get invalid interchange macro block size.", v0, 2u);
}

long long *ZinIrHalH13::GetParams(ZinIrHalH13 *this)
{
  uint64_t v52 = *MEMORY[0x263EF8340];
  {
    ZinIrHalH13::GetParams(void)const::ZinIrHalH13Parameters = xmmword_211ED25B0;
    dword_267775C20 = 8;
    unk_267775C28 = xmmword_211ED25C0;
    unk_267775C38 = xmmword_211ED25D0;
    unk_267775C48 = xmmword_211ED25E0;
    unk_267775C58 = xmmword_211ED25F0;
    unk_267775C68 = xmmword_211ED2600;
    unk_267775C78 = xmmword_211ED25E0;
    unk_267775C88 = xmmword_211ED2610;
    unk_267775C98 = xmmword_211ED2620;
    unk_267775CA8 = xmmword_211ED2630;
    unk_267775CB8 = xmmword_211ED2640;
    unk_267775CC8 = vdupq_n_s64(4uLL);
    qword_267775CD8 = 4;
    xmmword_267775CE0 = xmmword_211F06FF8;
    unk_267775CF0 = unk_211F07008;
    xmmword_267775D00 = xmmword_211F06FF8;
    unk_267775D10 = unk_211F07008;
    qword_267775D30 = 4;
    xmmword_267775D20 = xmmword_211F07018;
    xmmword_267775D38 = xmmword_211ED2650;
    xmmword_267775D48 = xmmword_211ED2660;
    xmmword_267775D58 = xmmword_211ED2660;
    xmmword_267775D68 = xmmword_211ED2660;
    xmmword_267775D78 = xmmword_211ED2670;
    xmmword_267775D88 = xmmword_211ED2680;
    xmmword_267775D98 = xmmword_211ED2690;
    xmmword_267775DA8 = xmmword_211ED26A0;
    xmmword_267775DB8 = xmmword_211ED26B0;
    xmmword_267775DC8 = xmmword_211ED26C0;
    xmmword_267775DD8 = xmmword_211ED26D0;
    xmmword_267775DE8 = xmmword_211ED26E0;
    xmmword_267775DF8 = xmmword_211ED26F0;
    xmmword_267775E08 = xmmword_211ED2700;
    xmmword_267775E18 = (__int128)vdupq_n_s64(0x40uLL);
    xmmword_267775E28 = xmmword_211ED27F0;
    xmmword_267775E38 = xmmword_211ED2720;
    xmmword_267775E48 = xmmword_211ED2730;
    xmmword_267775E58 = xmmword_211ED2740;
    qword_267775E68 = 64;
    xmmword_267775E70 = 0u;
    unk_267775E80 = xmmword_211ED2750;
    word_267775E90 = 256;
    xmmword_267775E98 = xmmword_211ED2760;
    xmmword_267775EA8 = xmmword_211ED2770;
    xmmword_267775EB8 = xmmword_211ED2780;
    qword_267775EC8 = 0x10000;
    byte_267775ED0 = 32;
    xmmword_267775ED8 = xmmword_211ED2790;
    dword_267775EE8 = 520097776;
    qword_267775EEC = 0xFFFFFFEB0000000BLL;
    xmmword_267775EF8 = xmmword_211ED27A0;
    xmmword_267775F08 = xmmword_211ED27B0;
    xmmword_267775F18 = xmmword_211ED27C0;
    int64x2_t v51 = vdupq_n_s64(8uLL);
    std::vector<std::pair<unsigned long,unsigned long>>::vector[abi:ne180100](&qword_267775F28, (uint64_t)&v51, 1uLL);
    xmmword_267775F40 = xmmword_211ED27D0;
    *(_OWORD *)algn_267775F50 = xmmword_211ED27E0;
    xmmword_267775F60 = (__int128)vdupq_n_s64(0x20uLL);
    unk_267775F70 = xmmword_211ED2610;
    xmmword_267775F80 = (__int128)vdupq_n_s64(8uLL);
    unk_267775F90 = xmmword_211ED27F0;
    xmmword_267775FA0 = xmmword_211ED2800;
    unk_267775FB0 = vdupq_n_s64(0x100uLL);
    xmmword_267775FC0 = (__int128)vdupq_n_s64(0x80uLL);
    unk_267775FD0 = xmmword_211ED2810;
    xmmword_267775FE0 = xmmword_211ED2820;
    unk_267775FF0 = xmmword_211ED2830;
    xmmword_267776000 = xmmword_211ED2840;
    unk_267776010 = xmmword_211ED2850;
    xmmword_267776020 = (__int128)vdupq_n_s64(2uLL);
    unk_267776030 = xmmword_211ED2660;
    xmmword_267776040 = (__int128)vdupq_n_s64(0x4000uLL);
    unk_267776050 = xmmword_211ED2860;
    word_267776060 = 257;
    byte_267776066 = 0;
    dword_267776062 = 0;
    word_267776067 = 1;
    dword_267776069 = 16843009;
    xmmword_26777606D = 0u;
    *(_DWORD *)((char *)&xmmword_26777606D + 15) = 0;
    byte_267776080 = 1;
    byte_267776085 = 0;
    dword_267776081 = 0;
    qword_267776086 = 0x101000000010101;
    word_26777608E = 0;
    xmmword_267776090 = xmmword_211ED2870;
    unk_2677760A0 = xmmword_211ED2880;
    qword_2677760B0 = 40;
    xmmword_2677760B8 = 0u;
    dword_2677760C8 = 16843009;
    *(int *)((char *)&dword_2677760C8 + 3) = 16843009;
    word_2677760CF = 0;
    qword_2677760D8 = 0;
    byte_2677760E0 = 0;
    dword_2677760E1 = 16843009;
    word_2677760E9 = 0;
    dword_2677760E5 = 0;
    dword_2677760EB = 16842753;
    qword_2677760EF = 0;
    byte_2677760F7 = 0;
    dword_2677760F8 = 65793;
    word_2677760FC = 0;
    byte_2677760FE = 1;
    dword_2677760FF = 0;
    byte_267776103 = 1;
    dword_267776104 = 0;
    word_267776108 = 0;
    qword_267776118 = -1;
    unk_267776120 = -1;
    qword_267776110 = 128;
    word_267776128 = 0;
    dword_26777612C = 0;
    word_267776130 = 1;
    byte_267776132 = 1;
    *(uint64_t *)((char *)&qword_267776133 + 6) = 0;
    qword_267776133 = 0;
    dword_267776141 = 1542;
    byte_267776145 = 1;
    dword_267776146 = 0;
    std::string::basic_string[abi:ne180100]<0>(&qword_267776150, "Simple");
    qword_267776168 = 0x1000000;
    dword_267776174 = 0;
    unk_267776178 = 0;
    dword_267776170 = 1071225242;
    unk_267776180 = xmmword_211ED2890;
    unk_267776190 = vdupq_n_s64(0x40uLL);
    unk_2677761A0 = xmmword_211ED28A0;
    qword_2677761B0 = 8;
    byte_2677761B8 = 0;
    unk_2677761BC = 0xF3E800000;
    byte_2677761C4 = 0;
    long long v50 = xmmword_211ED28B0;
    std::vector<ZinIrPaddingMode>::vector[abi:ne180100](&qword_2677761C8, &v50, 4uLL);
    v48[0] = xmmword_211F07030;
    v48[1] = unk_211F07040;
    v49[0] = xmmword_211F07050;
    *(_OWORD *)((char *)v49 + 12) = *(long long *)((char *)&xmmword_211F07050 + 12);
    std::vector<ZinIrPoolingMode>::vector[abi:ne180100](&qword_2677761E0, v48, 0xFuLL);
    int v47 = 25;
    v46[4] = xmmword_211F070AC;
    v46[5] = unk_211F070BC;
    v46[6] = xmmword_211F070CC;
    v46[0] = xmmword_211F0706C;
    v46[1] = unk_211F0707C;
    v46[2] = xmmword_211F0708C;
    v46[3] = unk_211F0709C;
    std::vector<ZinIrNeuronType>::vector[abi:ne180100](&qword_2677761F8, v46, 0x1DuLL);
    int v45 = 42;
    v44[6] = xmmword_211F07140;
    v44[7] = unk_211F07150;
    v44[8] = xmmword_211F07160;
    v44[9] = unk_211F07170;
    v44[2] = xmmword_211F07100;
    v44[3] = unk_211F07110;
    v44[4] = xmmword_211F07120;
    v44[5] = unk_211F07130;
    v44[0] = xmmword_211F070E0;
    v44[1] = unk_211F070F0;
    std::vector<ZinIrNonLinearMode>::vector[abi:ne180100](&qword_267776210, v44, 0x29uLL);
    int v33 = 2;
    long long v34 = xmmword_211ED28C0;
    uint64_t v35 = 0x1100000002;
    int v36 = 0;
    std::vector<ZinMirInterchangeInfo>::vector[abi:ne180100](&v8, &v33, 1uLL);
    unsigned int v37 = 641877825;
    memset(v38, 0, sizeof(v38));
    std::vector<ZinMirInterchangeInfo>::__init_with_size[abi:ne180100]<ZinMirInterchangeInfo*,ZinMirInterchangeInfo*>(v38, v8, (uint64_t)v9, 0xCCCCCCCCCCCCCCCDLL * ((v9 - (unsigned char *)v8) >> 3));
    int v29 = 10;
    int64x2_t v30 = vdupq_n_s64(1uLL);
    uint64_t v31 = 0x800000001;
    int v32 = 0;
    std::vector<ZinMirInterchangeInfo>::vector[abi:ne180100](&v6, &v29, 1uLL);
    int v39 = 642527542;
    memset(v40, 0, sizeof(v40));
    std::vector<ZinMirInterchangeInfo>::__init_with_size[abi:ne180100]<ZinMirInterchangeInfo*,ZinMirInterchangeInfo*>(v40, v6, (uint64_t)v7, 0xCCCCCCCCCCCCCCCDLL * ((v7 - (unsigned char *)v6) >> 3));
    int v25 = 3;
    int64x2_t v26 = vdupq_n_s64(1uLL);
    uint64_t v27 = 0x700000002;
    int v28 = 0;
    std::vector<ZinMirInterchangeInfo>::vector[abi:ne180100](&__p, &v25, 1uLL);
    int v41 = 642527336;
    v43[0] = 0;
    v43[1] = 0;
    uint64_t v42 = 0;
    std::vector<ZinMirInterchangeInfo>::__init_with_size[abi:ne180100]<ZinMirInterchangeInfo*,ZinMirInterchangeInfo*>(&v42, __p, (uint64_t)v5, 0xCCCCCCCCCCCCCCCDLL * ((v5 - (unsigned char *)__p) >> 3));
    std::map<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>::map[abi:ne180100]((uint64_t)&unk_267776228, &v37, 3);
    word_267776240 = 0;
    byte_267776242 = 1;
    *(_DWORD *)algn_267776243 = 0;
    qword_267776248 = 0;
    dword_267776250 = 0;
    unk_267776258 = 0u;
    unk_267776268 = 0u;
    word_267776278 = 257;
    qword_2677762A0 = 8;
    xmmword_267776280 = xmmword_211F07188;
    unk_267776290 = unk_211F07198;
    unk_2677762A8 = xmmword_211ED28D0;
    v24[2] = xmmword_211F071D0;
    v24[3] = unk_211F071E0;
    v24[4] = xmmword_211F071F0;
    v24[0] = xmmword_211F071B0;
    v24[1] = unk_211F071C0;
    std::vector<double>::vector[abi:ne180100](&qword_2677762B8, v24, 0xAuLL);
    long long v12 = xmmword_211F07200;
    *(void *)&long long v13 = 0x41CAD27480000000;
    std::vector<double>::vector[abi:ne180100](&qword_2677762D0, &v12, 3uLL);
    long long v22 = xmmword_211F07218;
    uint64_t v23 = 0x41DFC8BFD0000000;
    std::vector<double>::vector[abi:ne180100](&qword_2677762E8, &v22, 3uLL);
    long long v18 = xmmword_211F07290;
    long long v19 = unk_211F072A0;
    long long v20 = xmmword_211F072B0;
    long long v21 = unk_211F072C0;
    long long v14 = xmmword_211F07250;
    long long v15 = unk_211F07260;
    long long v16 = xmmword_211F07270;
    long long v17 = unk_211F07280;
    long long v12 = xmmword_211F07230;
    long long v13 = unk_211F07240;
    std::map<double,double>::map[abi:ne180100]((uint64_t)&unk_267776300, (double *)&v12, 10);
    xmmword_267776318 = xmmword_211ED28E0;
    v10[0] = xmmword_211F072D0;
    v10[1] = unk_211F072E0;
    v10[2] = xmmword_211F072F0;
    int v11 = 27;
    std::vector<ZinKernelFormat>::vector[abi:ne180100](algn_267776328, v10, 0xDuLL);
    uint64_t v2 = 0;
    xmmword_267776340 = xmmword_211ED2790;
    *(_OWORD *)algn_267776350 = xmmword_211ED28F0;
    word_267776459 = 257;
    qword_267776360 = 64;
    unk_267776368 = 0x101010101010101;
    unk_26777636D = 0x101010101010101;
    byte_267776375 = 0;
    dword_267776378 = 257;
    xmmword_267776380 = xmmword_211F07308;
    unk_267776390 = unk_211F07318;
    xmmword_2677763A0 = xmmword_211F07328;
    unk_2677763B0 = unk_211F07338;
    xmmword_2677763E0 = xmmword_211F07368;
    unk_2677763F0 = unk_211F07378;
    xmmword_2677763C0 = xmmword_211F07348;
    unk_2677763D0 = unk_211F07358;
    word_267776400 = 1;
    byte_267776402 = 0;
    byte_267776408 = 0;
    byte_267776410 = 0;
    dword_267776420 = 0;
    word_267776424 = 0;
    qword_267776440 = 0;
    byte_267776448 = 0;
    qword_267776450 = 0;
    byte_267776458 = 0;
    dword_267776418 = 0;
    word_26777641C = 0;
    qword_267776428 = 0;
    unk_267776430 = 0;
    qword_267776460 = 0x40000000;
    byte_267776438 = 0;
    do
    {
      int v3 = (void *)v43[v2 - 1];
      if (v3)
      {
        v43[v2] = v3;
        operator delete(v3);
      }
      v2 -= 4;
    }
    while (v2 != -12);
    if (__p)
    {
      int v5 = __p;
      operator delete(__p);
    }
    if (v6)
    {
      unint64_t v7 = v6;
      operator delete(v6);
    }
    if (v8)
    {
      unint64_t v9 = v8;
      operator delete(v8);
    }
    __cxa_atexit((void (*)(void *))ZinIrHalParameters::~ZinIrHalParameters, &ZinIrHalH13::GetParams(void)const::ZinIrHalH13Parameters, &dword_210C72000);
  }
  return &ZinIrHalH13::GetParams(void)const::ZinIrHalH13Parameters;
}

void sub_211367864(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, void *__p, uint64_t a19, uint64_t a20,void *a21,uint64_t a22,uint64_t a23,void *a24)
{
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy(v25, *(void **)(v25 + 8));
  if (qword_2677762E8)
  {
    qword_2677762F0 = qword_2677762E8;
    operator delete((void *)qword_2677762E8);
  }
  if (qword_2677762D0)
  {
    qword_2677762D8 = qword_2677762D0;
    operator delete((void *)qword_2677762D0);
  }
  if (qword_2677762B8)
  {
    qword_2677762C0 = qword_2677762B8;
    operator delete((void *)qword_2677762B8);
  }
  std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::destroy(v24, *(void **)(v24 + 8));
  uint64_t v27 = 0;
  while (1)
  {
    int v28 = *(void **)((char *)&STACK[0x260] + v27 + 72);
    if (v28)
    {
      *(unint64_t *)((char *)&STACK[0x260] + v27 + 80) = (unint64_t)v28;
      operator delete(v28);
    }
    v27 -= 32;
    if (v27 == -96)
    {
      if (__p) {
        operator delete(__p);
      }
      if (a21) {
        operator delete(a21);
      }
      if (a24) {
        operator delete(a24);
      }
      if (qword_267776210)
      {
        qword_267776218 = qword_267776210;
        operator delete((void *)qword_267776210);
      }
      if (qword_2677761F8)
      {
        qword_267776200 = qword_2677761F8;
        operator delete((void *)qword_2677761F8);
      }
      if (qword_2677761E0)
      {
        qword_2677761E8 = qword_2677761E0;
        operator delete((void *)qword_2677761E0);
      }
      if (qword_2677761C8)
      {
        qword_2677761D0 = qword_2677761C8;
        operator delete((void *)qword_2677761C8);
      }
      if (byte_267776167 < 0) {
        operator delete((void *)qword_267776150);
      }
      if (qword_267775F28)
      {
        qword_267775F30 = qword_267775F28;
        operator delete((void *)qword_267775F28);
      }
      _Unwind_Resume(a1);
    }
  }
}

void sub_211367A60()
{
}

void sub_211367A68()
{
}

void sub_211367A70()
{
}

void sub_211367A78()
{
}

void sub_211367A80()
{
}

void sub_211367A88()
{
}

void sub_211367A90()
{
}

uint64_t ZinIrSpaceToChannelInfo::ZinIrSpaceToChannelInfo(uint64_t a1, uint64_t *a2)
{
  uint64_t result = ZinIrOpLayerOpCode::ZinIrOpLayerOpCode(a1, 40);
  *(void *)uint64_t result = &unk_26C350218;
  uint64_t v4 = *a2;
  *(_DWORD *)(result + 20) = *((_DWORD *)a2 + 2);
  *(void *)(result + 12) = v4;
  return result;
}

void *ZinSpaceToChannelLayer::ZinSpaceToChannelLayer(void *a1, uint64_t *a2, uint64_t *a3, long long *a4)
{
  uint64_t v5 = *a2;
  *a2 = 0;
  uint64_t v6 = (std::__shared_weak_count *)a3[1];
  uint64_t v12 = *a3;
  long long v13 = v6;
  uint64_t v14 = v5;
  if (v6) {
    atomic_fetch_add_explicit(&v6->__shared_owners_, 1uLL, memory_order_relaxed);
  }
  int v11 = 0;
  ZinIrOpLayer::ZinIrOpLayer((uint64_t)a1, &v14, &v12, a4, &v11);
  unint64_t v7 = v11;
  int v11 = 0;
  if (v7)
  {
    ZinIrKernel::~ZinIrKernel(v7);
    MEMORY[0x21667D3C0](v8, 0x1032C40C25AA5B7);
  }
  if (v13) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v13);
  }
  uint64_t v9 = v14;
  uint64_t v14 = 0;
  if (v9) {
    (*(void (**)(uint64_t))(*(void *)v9 + 8))(v9);
  }
  *a1 = &unk_26C34FBB0;
  return a1;
}

void sub_211367BD0(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, ZinIrKernel *a9, uint64_t a10, std::__shared_weak_count *a11, uint64_t a12)
{
  if (a11) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a11);
  }
  ZinLayerNormLayer::ZinLayerNormLayer(&a12);
  _Unwind_Resume(a1);
}

uint64_t ZinSpaceToChannelLayer::LowerEngine(uint64_t a1, uint64_t a2, uint64_t **a3)
{
  v63[3] = *MEMORY[0x263EF8340];
  uint64_t v5 = *(void *)(a1 + 64);
  if (*(_DWORD *)(v5 + 12) == 2 && *(_DWORD *)(v5 + 16) == 2)
  {
    uint64_t v6 = (*(uint64_t (**)(void, void, void))(***(void ***)(a1 + 88) + 32))(**(void **)(a1 + 88), 0, 0);
    uint64_t v7 = (*(uint64_t (**)(uint64_t, void, void))(*(void *)a1 + 32))(a1, 0, 0);
    memset(v63, 0, 24);
    std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(v63, *(const void **)(a1 + 112), *(void *)(a1 + 120), (uint64_t)(*(void *)(a1 + 120) - *(void *)(a1 + 112)) >> 3);
    uint64_t v8 = *(int *)(v5 + 12);
    uint64_t v9 = *(int *)(v5 + 16);
    uint64_t v10 = *(void *)(v7 + 56) / ((int)v9 * (uint64_t)(int)v8);
    uint64_t v49 = *(void *)(v7 + 56);
    long long v50 = (void *)v10;
    uint64_t v51 = v9;
    uint64_t v52 = v8;
    uint64_t v53 = 1;
    ZinObjectNameFactory::ZinObjectNameFactory(&v46, a1 + 24);
    ZinObjectNameFactory::CreateName((uint64_t)&v46, 2u, &v54);
    int v11 = std::string::append(&v54, "_S2C_conv_kernel_", 0x11uLL);
    long long v12 = *(_OWORD *)&v11->__r_.__value_.__l.__data_;
    std::string::size_type v62 = v11->__r_.__value_.__r.__words[2];
    long long v61 = v12;
    v11->__r_.__value_.__l.__size_ = 0;
    v11->__r_.__value_.__r.__words[2] = 0;
    v11->__r_.__value_.__r.__words[0] = 0;
    if (SHIBYTE(v54.__r_.__value_.__r.__words[2]) < 0) {
      operator delete(v54.__r_.__value_.__l.__data_);
    }
    LODWORD(v54.__r_.__value_.__l.__data_) = 0;
    std::vector<float>::vector(&v45, (void)v50 * v49 * v51 * v52 * v53, &v54);
    uint64_t v13 = v49;
    if (v49 >= 1)
    {
      uint64_t v14 = 0;
      uint64_t v15 = 0;
      uint64_t v16 = (uint64_t)v50;
      long long v17 = v45;
      int v18 = *(_DWORD *)(v5 + 16) * *(_DWORD *)(v5 + 12);
      do
      {
        v17[v14 + v15 / v16 + (int)(v18 * (v15 % v16))] = 1065353216;
        ++v15;
        v14 += v13;
      }
      while (v13 != v15);
    }
    *(int64x2_t *)&v54.__r_.__value_.__l.__data_ = vdupq_n_s64(2uLL);
    v54.__r_.__value_.__r.__words[2] = 1;
    long long v55 = xmmword_211EF02B0;
    uint64_t v56 = 0x100000001;
    long long v57 = 0uLL;
    *(void *)&long long v19 = 0x100000001;
    *((void *)&v19 + 1) = 0x100000001;
    *(_OWORD *)&v58[1] = v19;
    v58[0] = 0;
    v58[3] = 1;
    __int16 v59 = 0;
    int v60 = 0;
    ZinIrKernel::CreateDynamicKernel((float **)&v45, 4, &v49, 2uLL, **a3, 0, &v44);
    uint64_t v20 = *(void *)(a1 + 16);
    uint64_t v21 = *(unsigned int *)(v6 + 88);
    int v43 = v44;
    int v44 = 0;
    ZinBuilder::CreateConv(v20, (uint64_t)&v46, v7 + 48, v21, v21, &v43);
  }
  if (!*(unsigned char *)((*a3)[1] + 492))
  {
    uint64_t v46 = 0;
    int v47 = 0;
    unint64_t v48 = 0;
    uint64_t v24 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)&v48, 1uLL);
    uint64_t v25 = &v24[8 * v23];
    *(void *)uint64_t v24 = 2;
    int64x2_t v26 = v24 + 8;
    int v28 = (char *)v46;
    uint64_t v27 = (char *)v47;
    int v29 = v24;
    if (v47 != v46)
    {
      do
      {
        uint64_t v30 = *((void *)v27 - 1);
        v27 -= 8;
        *((void *)v29 - 1) = v30;
        v29 -= 8;
      }
      while (v27 != v28);
      uint64_t v27 = (char *)v46;
    }
    uint64_t v46 = v29;
    int v47 = v24 + 8;
    unint64_t v48 = &v24[8 * v23];
    if (v27)
    {
      operator delete(v27);
      uint64_t v25 = v48;
    }
    int v47 = v24 + 8;
    if (v26 >= v25)
    {
      uint64_t v32 = (v26 - (unsigned char *)v46) >> 3;
      if ((unint64_t)(v32 + 1) >> 61) {
        std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
      }
      uint64_t v33 = v25 - (unsigned char *)v46;
      uint64_t v34 = v33 >> 2;
      if (v33 >> 2 <= (unint64_t)(v32 + 1)) {
        uint64_t v34 = v32 + 1;
      }
      if ((unint64_t)v33 >= 0x7FFFFFFFFFFFFFF8) {
        unint64_t v35 = 0x1FFFFFFFFFFFFFFFLL;
      }
      else {
        unint64_t v35 = v34;
      }
      if (v35) {
        int v36 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)&v48, v35);
      }
      else {
        int v36 = 0;
      }
      unsigned int v37 = &v36[8 * v32];
      unsigned int v38 = &v36[8 * v35];
      *(void *)unsigned int v37 = 0x200000000;
      uint64_t v31 = v37 + 8;
      BOOL v40 = (char *)v46;
      int v39 = (char *)v47;
      if (v47 != v46)
      {
        do
        {
          uint64_t v41 = *((void *)v39 - 1);
          v39 -= 8;
          *((void *)v37 - 1) = v41;
          v37 -= 8;
        }
        while (v39 != v40);
        int v39 = (char *)v46;
      }
      uint64_t v46 = v37;
      int v47 = v31;
      unint64_t v48 = v38;
      if (v39) {
        operator delete(v39);
      }
    }
    else
    {
      *((void *)v24 + 1) = 0x200000000;
      uint64_t v31 = v24 + 16;
    }
    int v47 = v31;
    __n128 v42 = ZinObjectNameFactory::ZinObjectNameFactory(&v49, a1 + 24);
    (*(void (**)(void, void, void, __n128))(***(void ***)(a1 + 88) + 32))(**(void **)(a1 + 88), 0, 0, v42);
    (*(void (**)(uint64_t, void, void))(*(void *)a1 + 32))(a1, 0, 0);
    ZinBuilder::CreateTranspose();
  }
  return 3;
}

void sub_21136870C(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, char a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, void *a19, void *a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,void *a25,uint64_t a26,int a27,__int16 a28,char a29,char a30,uint64_t a31,uint64_t a32,char a33,int a34,__int16 a35,char a36,char a37,void *a38,uint64_t a39,uint64_t a40,void *__p,void *a42,uint64_t a43,int a44,__int16 a45,char a46,char a47,uint64_t a48,uint64_t a49,void *a50,uint64_t a51,int a52,__int16 a53,char a54,char a55)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

void ZinSpaceToChannelLayer::Clone()
{
}

void sub_211368AC0(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12)
{
  if (v13) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v13);
  }
  if (a12) {
    (*(void (**)(uint64_t))(*(void *)a12 + 8))(a12);
  }
  MEMORY[0x21667D3C0](v12, 0x10B3C4024B96488);
  _Unwind_Resume(a1);
}

void ZinSpaceToChannelLayer::ValidateSemantics_Impl(ZinIrOpLayer *a1, uint64_t *a2, uint64_t a3)
{
  int v3 = (int *)*((void *)a1 + 8);
  if (v3[5] != 1) {
    ZinAssertImpl("SpaceToChannel in z dimension is not supported, current factor.z = %d.", v3[5]);
  }
  uint64_t v5 = *(void *)(*a2 + 32);
  uint64_t v6 = v3[3];
  uint64_t v7 = v3[4];
  if (v5 % v6 || *(void *)(*a2 + 24) % v7) {
    ZinAssertImpl("Spatial dimensions cannot be divived by the given factors. Current w=%zd, factor_x=%d, h=%zd, factor_y=%d", v5, v6, *(void *)(*a2 + 24), v7);
  }
  int v11 = 0;
  uint64_t v12 = 0;
  uint64_t v13 = 0;
  std::vector<int>::__init_with_size[abi:ne180100]<unsigned long const*,unsigned long const*>((char *)&v11, (uint64_t *)(a3 + 1656), (uint64_t *)(a3 + 1688), 4uLL);
  memset(v10, 0, sizeof(v10));
  if (!Factorize(v3[3], &v11, v10) || !Factorize(v3[4], &v11, v10)) {
    ZinAssertImpl("SpaceToChannel factor cannot be completely factorized into legal interleave factors. The legal interleaves are {1,2,3,4,8}");
  }
  ZinIrOpLayer::ValidateSemantics_Impl(a1, a2, (unsigned __int8 *)a3);
  std::deque<int>::~deque[abi:ne180100](v10);
  if (v11)
  {
    uint64_t v12 = v11;
    operator delete(v11);
  }
}

void sub_211368C5C(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, ...)
{
  va_start(va, a5);
  std::deque<int>::~deque[abi:ne180100]((uint64_t *)va);
  uint64_t v7 = *(void **)(v5 - 56);
  if (v7)
  {
    *(void *)(v5 - 48) = v7;
    operator delete(v7);
  }
  _Unwind_Resume(a1);
}

void *ZinSpaceToChannelLayer::OpCodeKindToString@<X0>(void *a1@<X8>)
{
  return std::string::basic_string[abi:ne180100]<0>(a1, "SPACE_TO_CHANNEL");
}

uint64_t ZinSpaceToChannelLayer::DebugDetailPrint@<X0>(void *a1@<X8>)
{
  std::basic_stringstream<char,std::char_traits<char>,std::allocator<char>>::basic_stringstream[abi:ne180100]((uint64_t)v5);
  std::stringbuf::str[abi:ne180100]<std::allocator<char>>((uint64_t)v6, a1);
  v5[0] = *MEMORY[0x263F8C2B8];
  uint64_t v3 = *(void *)(MEMORY[0x263F8C2B8] + 72);
  *(void *)((char *)v5 + *(void *)(v5[0] - 24)) = *(void *)(MEMORY[0x263F8C2B8] + 64);
  v5[2] = v3;
  v6[0] = MEMORY[0x263F8C318] + 16;
  if (v7 < 0) {
    operator delete((void *)v6[8]);
  }
  std::streambuf::~streambuf();
  std::iostream::~basic_iostream();
  return MEMORY[0x21667D2B0](&v8);
}

void sub_211368DEC(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
}

void ZinIrNEMatMulUnit::ZinIrNEMatMulUnit(ZinIrNEMatMulUnit *this, const ZinIrNEMatMulUnitInfo *a2)
{
  ZinIrNEUnit::ZinIrNEUnit(this, a2);
  *uint64_t v3 = &unk_26C34AA88;
  ZinIrNEMatMulUnitInfo::ZinIrNEMatMulUnitInfo((ZinIrNEMatMulUnitInfo *)(v3 + 55), a2);
}

void sub_211368E54(_Unwind_Exception *a1)
{
  ZinIrNEUnit::~ZinIrNEUnit(v1);
  _Unwind_Resume(a1);
}

void ZinIrNEMatMulUnitInfo::ZinIrNEMatMulUnitInfo(ZinIrNEMatMulUnitInfo *this, const ZinIrNEMatMulUnitInfo *a2)
{
  ZinIrNEUnitInfo::ZinIrNEUnitInfo(this, a2);
  *(void *)uint64_t v4 = &unk_26C34E748;
  *(void *)(v4 + 368) = &unk_26C345B80;
  if (*((char *)a2 + 399) < 0)
  {
    std::string::__init_copy_ctor_external((std::string *)(v4 + 376), *((const std::string::value_type **)a2 + 47), *((void *)a2 + 48));
  }
  else
  {
    long long v5 = *(_OWORD *)((char *)a2 + 376);
    *(void *)(v4 + 392) = *((void *)a2 + 49);
    *(_OWORD *)(v4 + 376) = v5;
  }
  *((_DWORD *)this + 10std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = *((_DWORD *)a2 + 100);
  *((void *)this + 52) = 0;
  *((void *)this + 53) = 0;
  *((void *)this + 51) = 0;
  std::vector<std::string>::__init_with_size[abi:ne180100]<std::string*,std::string*>((std::string *)this + 17, *((long long **)a2 + 51), *((long long **)a2 + 52), 0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*((void *)a2 + 52) - *((void *)a2 + 51)) >> 3));
  *((_OWORD *)this + 27) = *((_OWORD *)a2 + 27);
  *((void *)this + 46) = &unk_26C3500E8;
  *((_DWORD *)this + 112) = *((_DWORD *)a2 + 112);
}

void sub_211368F64(_Unwind_Exception *a1)
{
  *(void *)uint64_t v1 = &unk_26C348A60;
  if (*(unsigned char *)(v1 + 352)) {
    ZinIrUnitInfo::~ZinIrUnitInfo((void **)(v1 + 240));
  }
  if (*(unsigned char *)(v1 + 232)) {
    ZinIrUnitInfo::~ZinIrUnitInfo((void **)(v1 + 80));
  }
  ZinIrUnitInfo::~ZinIrUnitInfo((void **)v1);
  _Unwind_Resume(a1);
}

void ZinIrNEMatMulUnit::CreateLayer()
{
  uint64_t v0 = *MEMORY[0x263EF8340];
  operator new();
}

void sub_21136926C(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, std::__shared_weak_count *a16, uint64_t a17, std::__shared_weak_count *a18, void *__p, uint64_t a20,uint64_t a21,uint64_t a22)
{
  if (a16) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a16);
  }
  MEMORY[0x21667D3C0](v23, 0x10B3C402A00DFB5);
  if (a18) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a18);
  }
  (*(void (**)(uint64_t))(*(void *)v22 + 8))(v22);
  _Unwind_Resume(a1);
}

uint64_t ZinIrNEMatMulUnit::CreateKernel(ZinIrNEUnit *a1, const ZinIrHalParameters *a2, ZinIrFileManager *a3, const ZinWeightFileInfo *a4, uint64_t a5, uint64_t a6, ZinIrUnitStatus *a7)
{
  if (a5) {
    ZinAssertImpl("NEMatMul does not support Espresso weight format", a2, a3, a4, a5, a6, a7, v7, v8);
  }
  return ZinIrNEUnit::CreateSubKernels(a1, a2, a3, a4, a7);
}

uint64_t ZinIrNEMatMulUnit::TensorDimensions(ZinIrNEMatMulUnit *this, const ZinIrHalParameters *a2, ZinTensorDimensions *a3, ZinIrUnitStatus *a4)
{
  return ZinGetOutputTensorDimensionMatrixMult((const ZinTensorDimensions *)(*((void *)this + 1) + 8), (const ZinTensorDimensions *)(*((void *)this + 1) + 128), *((void *)this + 64), a3);
}

void ZinIrNEMatMulUnit::~ZinIrNEMatMulUnit(ZinIrNEMatMulUnit *this)
{
  ZinIrNEMatMulUnit::~ZinIrNEMatMulUnit(this);

  JUMPOUT(0x21667D3C0);
}

{
  void **v2;
  uint64_t vars8;

  *(void *)this = &unk_26C34AA88;
  uint64_t v2 = (void **)((char *)this + 440);
  *((void *)this + 55) = &unk_26C34E748;
  ZinIrUnitInfo::~ZinIrUnitInfo((void **)this + 101);
  *((void *)this + 55) = &unk_26C348A60;
  if (*((unsigned char *)this + 792)) {
    ZinIrUnitInfo::~ZinIrUnitInfo((void **)this + 85);
  }
  if (*((unsigned char *)this + 672)) {
    ZinIrUnitInfo::~ZinIrUnitInfo((void **)this + 65);
  }
  ZinIrUnitInfo::~ZinIrUnitInfo(v2);

  ZinIrNEUnit::~ZinIrNEUnit(this);
}

uint64_t *ZinIrBindings::GetLiveIOInfoMap(uint64_t a1, int a2)
{
  int v3 = a2;
  return std::map<ZinIrDimension,unsigned long>::at(a1, &v3);
}

__n128 ZinIrBindings::AddIO(uint64_t a1, long long *a2, int a3, uint64_t a4)
{
  int v16 = a3;
  uint64_t v6 = std::map<ZinIrDimension,unsigned long>::at(a1, &v16);
  if (v6 + 1 == (uint64_t *)std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::find<std::string>((uint64_t)v6, (void **)a2))
  {
    long long v17 = a2;
    uint64_t v8 = std::__tree<std::__value_type<std::string,ZinIrIOInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrIOInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrIOInfo>>>::__emplace_unique_key_args<std::string,std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>((uint64_t **)v6, (void **)a2, (uint64_t)&std::piecewise_construct, &v17);
    std::string::operator=((std::string *)(v8 + 7), (const std::string *)a4);
    std::string::operator=((std::string *)(v8 + 10), (const std::string *)(a4 + 24));
    long long v9 = *(_OWORD *)(a4 + 64);
    *(_OWORD *)(v8 + 13) = *(_OWORD *)(a4 + 48);
    *(_OWORD *)(v8 + 15) = v9;
    long long v10 = *(_OWORD *)(a4 + 112);
    long long v11 = *(_OWORD *)(a4 + 128);
    long long v12 = *(_OWORD *)(a4 + 96);
    *(_OWORD *)(v8 + 17) = *(_OWORD *)(a4 + 80);
    *(_OWORD *)(v8 + 23) = v11;
    *(_OWORD *)(v8 + 21) = v10;
    *(_OWORD *)(v8 + 19) = v12;
    long long v13 = *(_OWORD *)(a4 + 176);
    long long v14 = *(_OWORD *)(a4 + 192);
    long long v15 = *(_OWORD *)(a4 + 160);
    *(_OWORD *)(v8 + 25) = *(_OWORD *)(a4 + 144);
    *(_OWORD *)(v8 + 31) = v14;
    *(_OWORD *)(v8 + 29) = v13;
    *(_OWORD *)(v8 + 27) = v15;
    if (v8 + 7 != (uint64_t *)a4) {
      std::vector<LayerAndUsageInfo>::__assign_with_size[abi:ne180100]<LayerAndUsageInfo*,LayerAndUsageInfo*>((char *)v8 + 264, *(char **)(a4 + 208), *(void *)(a4 + 216), (uint64_t)(*(void *)(a4 + 216) - *(void *)(a4 + 208)) >> 4);
    }
    __n128 result = *(__n128 *)(a4 + 232);
    *((__n128 *)v8 + 18) = result;
  }
  return result;
}

__n128 ZinIrBindings::AddUncompressedMapping(uint64_t a1, long long *a2, int a3, __n128 *a4)
{
  uint64_t v7 = (uint64_t **)(a1 + 72);
  if ((void **)(a1 + 80) == std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::find<std::string>(a1 + 72, (void **)a2))
  {
    __n128 v12 = *a4;
    uint64_t v9 = a4[1].n128_i64[0];
    a4->n128_u64[1] = 0;
    a4[1].n128_u64[0] = 0;
    a4->n128_u64[0] = 0;
    long long v13 = a2;
    long long v10 = std::__tree<std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>,std::__map_value_compare<std::string,std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>>>::__emplace_unique_key_args<std::string,std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>(v7, (void **)a2, (uint64_t)&std::piecewise_construct, &v13);
    *((_DWORD *)v10 + 14) = a3;
    long long v11 = (void *)v10[8];
    if (v11)
    {
      v10[9] = (uint64_t)v11;
      operator delete(v11);
      v10[8] = 0;
      v10[9] = 0;
      v10[10] = 0;
    }
    __n128 result = v12;
    *((__n128 *)v10 + 4) = v12;
    v10[10] = v9;
  }
  return result;
}

void sub_211369688(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, long long a9)
{
  if ((void)a9) {
    operator delete((void *)a9);
  }
  _Unwind_Resume(exception_object);
}

__n128 ZinIrBindings::AddCompressedMapping(uint64_t a1, long long *a2, int a3, __n128 *a4)
{
  uint64_t v7 = (uint64_t **)(a1 + 48);
  if ((void **)(a1 + 56) == std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::find<std::string>(a1 + 48, (void **)a2))
  {
    __n128 v12 = *a4;
    uint64_t v9 = a4[1].n128_i64[0];
    a4->n128_u64[1] = 0;
    a4[1].n128_u64[0] = 0;
    a4->n128_u64[0] = 0;
    long long v13 = a2;
    long long v10 = std::__tree<std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>,std::__map_value_compare<std::string,std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>>>::__emplace_unique_key_args<std::string,std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>(v7, (void **)a2, (uint64_t)&std::piecewise_construct, &v13);
    *((_DWORD *)v10 + 14) = a3;
    long long v11 = (void *)v10[8];
    if (v11)
    {
      v10[9] = (uint64_t)v11;
      operator delete(v11);
      v10[8] = 0;
      v10[9] = 0;
      v10[10] = 0;
    }
    __n128 result = v12;
    *((__n128 *)v10 + 4) = v12;
    v10[10] = v9;
  }
  return result;
}

void sub_211369770(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, long long a9)
{
  if ((void)a9) {
    operator delete((void *)a9);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinIrBindings::IsIOCircular(uint64_t a1, int a2, void **a3, BOOL *a4)
{
  int v17 = a2;
  *a4 = 0;
  uint64_t v6 = std::map<ZinIrDimension,unsigned long>::at(a1, &v17);
  uint64_t v7 = std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::find<std::string>((uint64_t)v6, a3);
  if (v6 + 1 == (uint64_t *)v7)
  {
    if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
      ZinIrBindings::IsIOCircular((uint64_t)a3, v10, v11, v12, v13, v14, v15, v16);
    }
    return 3;
  }
  else
  {
    uint64_t v8 = v7;
    uint64_t result = 0;
    *a4 = *((_DWORD *)v8 + 72) != 5;
  }
  return result;
}

uint64_t ZinIrBindings::GetIOBarRequirement(uint64_t a1, int a2, uint64_t *a3)
{
  *a3 = 0;
  uint64_t v6 = *(void ***)(a1 + 72);
  uint64_t v7 = (void **)(a1 + 80);
  if (v6 != (void **)(a1 + 80))
  {
    uint64_t v8 = 0;
    BOOL v17 = 0;
    while (1)
    {
      if (*((_DWORD *)v6 + 14) == a2)
      {
        if (ZinIrBindings::IsIOCircular(a1, a2, v6 + 4, &v17)) {
          return 3;
        }
        if (v17) {
          char v9 = 2;
        }
        else {
          char v9 = 3;
        }
        uint64_t v8 = (((unsigned char *)v6[9] - (unsigned char *)v6[8]) >> v9) + *a3;
        *a3 = v8;
      }
      uint64_t v10 = (void **)v6[1];
      if (v10)
      {
        do
        {
          uint64_t v11 = v10;
          uint64_t v10 = (void **)*v10;
        }
        while (v10);
      }
      else
      {
        do
        {
          uint64_t v11 = (void **)v6[2];
          BOOL v12 = *v11 == v6;
          uint64_t v6 = v11;
        }
        while (!v12);
      }
      uint64_t v6 = v11;
      if (v11 == v7) {
        goto LABEL_17;
      }
    }
  }
  uint64_t v8 = 0;
LABEL_17:
  uint64_t v13 = *(void **)(a1 + 48);
  if (v13 != (void *)(a1 + 56))
  {
    do
    {
      if (*((_DWORD *)v13 + 14) == a2)
      {
        v8 += (uint64_t)(v13[9] - v13[8]) >> 2;
        *a3 = v8;
      }
      uint64_t v14 = (void *)v13[1];
      if (v14)
      {
        do
        {
          uint64_t v15 = v14;
          uint64_t v14 = (void *)*v14;
        }
        while (v14);
      }
      else
      {
        do
        {
          uint64_t v15 = (void *)v13[2];
          BOOL v12 = *v15 == (void)v13;
          uint64_t v13 = v15;
        }
        while (!v12);
      }
      uint64_t v13 = v15;
    }
    while (v15 != (void *)(a1 + 56));
  }
  return 0;
}

uint64_t ZinIrBindings::GetSinglePlaneUncompressedDescriptor(uint64_t a1, int a2, uint64_t a3, uint64_t **a4)
{
  v65[4] = *MEMORY[0x263EF8340];
  uint64_t v7 = (void *)(a3 + 8);
  std::__tree<std::__value_type<std::string,ZinSinglePlaneLinearIODescriptor>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinSinglePlaneLinearIODescriptor>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinSinglePlaneLinearIODescriptor>>>::destroy(a3, *(void **)(a3 + 8));
  *(void *)a3 = v7;
  uint64_t v49 = (uint64_t **)a3;
  *(void *)(a3 + 16) = 0;
  void *v7 = 0;
  uint64_t v8 = *(void ***)(a1 + 72);
  char v9 = (void **)(a1 + 80);
  if (v8 != (void **)(a1 + 80))
  {
    int64x2_t v48 = vdupq_n_s64(1uLL);
    long long v10 = 0uLL;
    do
    {
      if (*((_DWORD *)v8 + 14) == a2)
      {
        uint64_t v11 = (uint64_t *)v8[8];
        if ((unsigned char *)v8[9] - (unsigned char *)v11 == 8)
        {
          uint64_t v12 = *v11;
          uint64_t v13 = *(void *)(*v11 + 104);
          if (!v13 || (uint64_t v14 = *(uint64_t **)(v13 + 40), v14 == *(uint64_t **)(v13 + 48))) {
            uint64_t v15 = 0;
          }
          else {
            uint64_t v15 = *v14;
          }
          if (*(unsigned char *)(v15 + 88))
          {
            int v16 = *(_DWORD *)(v15 + 64);
            uint64_t v17 = *(void *)(v15 + 72);
            unsigned int v18 = *(unsigned __int8 *)(v15 + 80);
            *(_DWORD *)uint64_t v52 = 0;
            *(_OWORD *)&v52[8] = v10;
            *(_OWORD *)&v52[24] = v10;
            *(void *)&v52[40] = 0;
            int64x2_t v53 = vdupq_n_s64(1uLL);
            int64x2_t v54 = v53;
            *(int64x2_t *)long long v55 = v53;
            *(int64x2_t *)&v55[16] = v53;
            *(int64x2_t *)&v55[32] = v53;
            int64x2_t v56 = v53;
            int64x2_t v57 = v53;
            int64x2_t v58 = v53;
            int64x2_t v59 = v53;
            int64x2_t v60 = v53;
            long long v19 = (std::string *)std::string::basic_string[abi:ne180100]<0>(&__p, &byte_211F4AA5D);
            uint64_t v62 = 0;
            LODWORD(v63) = 5;
            *((void *)&v63 + 1) = 0;
            __int16 v64 = 0;
            *(_DWORD *)uint64_t v52 = *(_DWORD *)(v12 + 88);
            uint64_t v20 = *(void *)(v12 + 80);
            int64x2_t v21 = *(int64x2_t *)(v12 + 64);
            int64x2_t v53 = *(int64x2_t *)(v12 + 48);
            int64x2_t v54 = v21;
            *(void *)long long v55 = v20;
            memset(&v52[8], 0, 40);
            *(void *)&v55[40] = *(void *)(v15 + 328);
            long long v22 = *(_OWORD *)(v15 + 312);
            *(_OWORD *)&v55[8] = *(_OWORD *)(v15 + 296);
            *(_OWORD *)&v55[24] = v22;
            int64x2_t v23 = *(int64x2_t *)(v15 + 336);
            int64x2_t v24 = *(int64x2_t *)(v15 + 352);
            int64x2_t v25 = *(int64x2_t *)(v15 + 400);
            int64x2_t v59 = *(int64x2_t *)(v15 + 384);
            int64x2_t v60 = v25;
            int64x2_t v26 = *(int64x2_t *)(v15 + 368);
            int64x2_t v57 = v24;
            int64x2_t v58 = v26;
            int64x2_t v56 = v23;
            std::string::operator=(v19, (const std::string *)(v15 + 160));
            uint64_t v62 = *(void *)(v15 + 184);
            LODWORD(v63) = v16;
            *((void *)&v63 + 1) = v17;
            Hal = ZinIrTarget::GetHal(*(uint64_t **)(v12 + 16), *(ZinIrTarget **)(*(void *)(v12 + 16) + 160));
            __int16 v64 = v18 >> (*(_DWORD *)((*(uint64_t (**)(uint64_t *))(*Hal + 16))(Hal) + 1308) != 0);
            *(void *)&v51[0] = v8 + 4;
            int v28 = std::__tree<std::__value_type<std::string,ZinSinglePlaneCircularIODescriptor>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinSinglePlaneCircularIODescriptor>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinSinglePlaneCircularIODescriptor>>>::__emplace_unique_key_args<std::string,std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>(a4, v8 + 4, (uint64_t)&std::piecewise_construct, (long long **)v51);
            int64x2_t v30 = v59;
            int64x2_t v29 = v60;
            int64x2_t v31 = v56;
            *(int64x2_t *)(v28 + 25) = v57;
            *(int64x2_t *)(v28 + 27) = v58;
            *(int64x2_t *)(v28 + 29) = v30;
            *(int64x2_t *)(v28 + 31) = v29;
            int64x2_t v32 = v54;
            *(_OWORD *)(v28 + 17) = *(_OWORD *)v55;
            long long v33 = *(_OWORD *)&v55[32];
            *(_OWORD *)(v28 + 19) = *(_OWORD *)&v55[16];
            *(_OWORD *)(v28 + 21) = v33;
            *(int64x2_t *)(v28 + 23) = v31;
            long long v34 = *(_OWORD *)v52;
            *(_OWORD *)(v28 + 9) = *(_OWORD *)&v52[16];
            int64x2_t v35 = v53;
            *(_OWORD *)(v28 + 11) = *(_OWORD *)&v52[32];
            *(int64x2_t *)(v28 + 13) = v35;
            *(int64x2_t *)(v28 + 15) = v32;
            *(_OWORD *)(v28 + 7) = v34;
            std::string::operator=((std::string *)v28 + 11, &__p);
            v28[36] = v62;
            *(_OWORD *)(v28 + 37) = v63;
            *((_WORD *)v28 + 156) = v64;
          }
          else
          {
            *(_DWORD *)uint64_t v52 = 0;
            *(_OWORD *)&v52[8] = v10;
            *(_OWORD *)&v52[24] = v10;
            *(void *)&v52[40] = 0;
            int64x2_t v53 = v48;
            int64x2_t v54 = v48;
            *(int64x2_t *)long long v55 = v48;
            *(int64x2_t *)&v55[16] = v48;
            *(int64x2_t *)&v55[32] = v48;
            int64x2_t v56 = v48;
            int64x2_t v57 = v48;
            int64x2_t v58 = v48;
            int64x2_t v59 = v48;
            int64x2_t v60 = v48;
            std::string::basic_string[abi:ne180100]<0>(&__p, &byte_211F4AA5D);
            uint64_t v62 = 0;
            v65[3] = 0;
            ZinIrTensor::InferDescriptor((ZinIrTensor *)v12, (uint64_t)v65, (uint64_t)v51);
            int64x2_t v58 = (int64x2_t)v51[10];
            int64x2_t v59 = (int64x2_t)v51[11];
            int64x2_t v60 = (int64x2_t)v51[12];
            *(_OWORD *)&v55[16] = v51[6];
            *(_OWORD *)&v55[32] = v51[7];
            int64x2_t v56 = (int64x2_t)v51[8];
            int64x2_t v57 = (int64x2_t)v51[9];
            *(_OWORD *)&v52[32] = v51[2];
            int64x2_t v53 = (int64x2_t)v51[3];
            int64x2_t v54 = (int64x2_t)v51[4];
            *(_OWORD *)long long v55 = v51[5];
            *(_OWORD *)uint64_t v52 = v51[0];
            *(_OWORD *)&v52[16] = v51[1];
            std::__function::__value_func<void ()(ZinTensorDescriptor const&,ZinTensorDescriptor const&,ZinIrTensor const*)>::~__value_func[abi:ne180100](v65);
            std::string::operator=(&__p, (const std::string *)(v15 + 160));
            uint64_t v62 = *(void *)(v15 + 184);
            *(void *)&v51[0] = v8 + 4;
            int v36 = std::__tree<std::__value_type<std::string,ZinSinglePlaneLinearIODescriptor>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinSinglePlaneLinearIODescriptor>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinSinglePlaneLinearIODescriptor>>>::__emplace_unique_key_args<std::string,std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>(v49, v8 + 4, (uint64_t)&std::piecewise_construct, (long long **)v51);
            int64x2_t v38 = v59;
            int64x2_t v37 = v60;
            int64x2_t v39 = v56;
            *(int64x2_t *)(v36 + 25) = v57;
            *(int64x2_t *)(v36 + 27) = v58;
            *(int64x2_t *)(v36 + 29) = v38;
            *(int64x2_t *)(v36 + 31) = v37;
            int64x2_t v40 = v54;
            *(_OWORD *)(v36 + 17) = *(_OWORD *)v55;
            long long v41 = *(_OWORD *)&v55[32];
            *(_OWORD *)(v36 + 19) = *(_OWORD *)&v55[16];
            *(_OWORD *)(v36 + 21) = v41;
            *(int64x2_t *)(v36 + 23) = v39;
            long long v42 = *(_OWORD *)v52;
            *(_OWORD *)(v36 + 9) = *(_OWORD *)&v52[16];
            int64x2_t v43 = v53;
            *(_OWORD *)(v36 + 11) = *(_OWORD *)&v52[32];
            *(int64x2_t *)(v36 + 13) = v43;
            *(int64x2_t *)(v36 + 15) = v40;
            *(_OWORD *)(v36 + 7) = v42;
            std::string::operator=((std::string *)v36 + 11, &__p);
            v36[36] = v62;
          }
          if (SHIBYTE(__p.__r_.__value_.__r.__words[2]) < 0) {
            operator delete(__p.__r_.__value_.__l.__data_);
          }
          long long v10 = 0uLL;
        }
      }
      int v44 = (void **)v8[1];
      if (v44)
      {
        do
        {
          int v45 = v44;
          int v44 = (void **)*v44;
        }
        while (v44);
      }
      else
      {
        do
        {
          int v45 = (void **)v8[2];
          BOOL v46 = *v45 == v8;
          uint64_t v8 = v45;
        }
        while (!v46);
      }
      uint64_t v8 = v45;
    }
    while (v45 != v9);
  }
  return 0;
}

void sub_211369DE4(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33,uint64_t a34,uint64_t a35,uint64_t a36,uint64_t a37,uint64_t a38,uint64_t a39,uint64_t a40,uint64_t a41,uint64_t a42,uint64_t a43,uint64_t a44,uint64_t a45,uint64_t a46,uint64_t a47,uint64_t a48,uint64_t a49,uint64_t a50,uint64_t a51,uint64_t a52,uint64_t a53,uint64_t a54,uint64_t a55,uint64_t a56,uint64_t a57,uint64_t a58,uint64_t a59,uint64_t a60,uint64_t a61,uint64_t a62,uint64_t a63)
{
  std::__function::__value_func<void ()(ZinTensorDescriptor const&,ZinTensorDescriptor const&,ZinIrTensor const*)>::~__value_func[abi:ne180100]((void *)(v71 - 128));
  if (SLOBYTE(STACK[0x207]) < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(a1);
}

uint64_t ZinIrBindings::GetMultiPlaneUncompressedDescriptor(uint64_t a1, int a2, uint64_t a3)
{
  *(void *)((char *)&v65[1] + 4) = *MEMORY[0x263EF8340];
  int v62 = a2;
  int v36 = std::map<ZinIrDimension,unsigned long>::at(a1, &v62);
  std::__tree<std::__value_type<std::string,ZinMultiPlaneLinearIODescriptor>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinMultiPlaneLinearIODescriptor>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinMultiPlaneLinearIODescriptor>>>::destroy(a3, *(void **)(a3 + 8));
  *(void *)a3 = a3 + 8;
  *(void *)(a3 + 16) = 0;
  *(void *)(a3 + 8) = 0;
  uint64_t v4 = *(void *)(a1 + 72);
  if (v4 == a1 + 80) {
    return 0;
  }
  int64x2_t v37 = vdupq_n_s64(1uLL);
  while (1)
  {
    if (*(_DWORD *)(v4 + 56) != v62 || *(void *)(v4 + 72) - *(void *)(v4 + 64) < 9uLL) {
      goto LABEL_36;
    }
    long long v5 = std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::find<std::string>((uint64_t)v36, (void **)(v4 + 32));
    uint64_t v6 = v5;
    if (v36 + 1 == (uint64_t *)v5) {
      break;
    }
    ZinIr4CCInfo::ZinIr4CCInfo(v59, *((unsigned int *)v5 + 65));
    uint64_t v57 = 0;
    uint64_t v58 = 0;
    uint64_t v8 = *(void *)(v4 + 64);
    uint64_t v7 = *(void *)(v4 + 72);
    uint64_t v9 = v7 - v8;
    if (v7 == v8)
    {
      uint64_t v13 = 0;
      uint64_t v14 = *(void *)(v4 + 72);
      goto LABEL_15;
    }
    uint64_t v10 = 0;
    unint64_t v11 = v9 >> 3;
    if (v11 <= 1) {
      unint64_t v11 = 1;
    }
    while (1)
    {
      uint64_t v12 = *(void *)(v8 + 8 * v10);
      if (v12) {
        break;
      }
      if (v11 == ++v10)
      {
        uint64_t v13 = 0;
        uint64_t v9 = 0;
        uint64_t v14 = *(void *)(v4 + 72);
        uint64_t v7 = *(void *)(v4 + 64);
        goto LABEL_15;
      }
    }
    if (ZinIr4CCInfo::GetBaseDimensions((ZinIr4CCInfo *)v59, v10, *(void *)(v12 + 72), *(void *)(v12 + 64), &v58, &v57))
    {
      uint64_t v13 = v57;
      uint64_t v9 = v58;
      uint64_t v7 = *(void *)(v4 + 64);
      uint64_t v14 = *(void *)(v4 + 72);
LABEL_15:
      uint64_t v54 = 0;
      uint64_t v55 = 0;
      uint64_t v56 = 0;
      int v53 = *((_DWORD *)v6 + 65);
      *(void *)&long long v52 = v9;
      *((void *)&v52 + 1) = v13;
      std::vector<ZinPlaneDescriptor>::reserve(&v54, (v14 - v7) >> 3);
      int v16 = *(ZinIrTensor ***)(v4 + 64);
      uint64_t v15 = *(ZinIrTensor ***)(v4 + 72);
      while (v16 != v15)
      {
        uint64_t v17 = *v16;
        LODWORD(v39[0]) = 0;
        memset((char *)v39 + 8, 0, 40);
        int64x2_t v40 = v37;
        int64x2_t v41 = v37;
        int64x2_t v42 = v37;
        int64x2_t v43 = v37;
        int64x2_t v44 = v37;
        int64x2_t v45 = v37;
        int64x2_t v46 = v37;
        int64x2_t v47 = v37;
        int64x2_t v48 = v37;
        int64x2_t v49 = v37;
        std::string::basic_string[abi:ne180100]<0>(&__p, &byte_211F4AA5D);
        uint64_t v51 = 0;
        if (v17)
        {
          v63[3] = 0;
          ZinIrTensor::InferDescriptor(v17, (uint64_t)v63, (uint64_t)v38);
          int64x2_t v47 = (int64x2_t)v38[10];
          int64x2_t v48 = (int64x2_t)v38[11];
          int64x2_t v49 = (int64x2_t)v38[12];
          int64x2_t v43 = (int64x2_t)v38[6];
          int64x2_t v44 = (int64x2_t)v38[7];
          int64x2_t v45 = (int64x2_t)v38[8];
          int64x2_t v46 = (int64x2_t)v38[9];
          v39[2] = v38[2];
          int64x2_t v40 = (int64x2_t)v38[3];
          int64x2_t v41 = (int64x2_t)v38[4];
          int64x2_t v42 = (int64x2_t)v38[5];
          v39[0] = v38[0];
          v39[1] = v38[1];
          std::__function::__value_func<void ()(ZinTensorDescriptor const&,ZinTensorDescriptor const&,ZinIrTensor const*)>::~__value_func[abi:ne180100](v63);
          uint64_t v18 = *((void *)v17 + 13);
          if (!v18 || (long long v19 = *(uint64_t **)(v18 + 40), v19 == *(uint64_t **)(v18 + 48))) {
            uint64_t v20 = 0;
          }
          else {
            uint64_t v20 = *v19;
          }
          std::string::operator=(&__p, (const std::string *)(v20 + 160));
          uint64_t v21 = *(void *)(**(void **)(*((void *)v17 + 13) + 40) + 184);
        }
        else
        {
          int64x2_t v48 = 0u;
          int64x2_t v49 = 0u;
          int64x2_t v46 = 0u;
          int64x2_t v47 = 0u;
          int64x2_t v44 = 0u;
          int64x2_t v45 = 0u;
          int64x2_t v42 = 0u;
          int64x2_t v43 = 0u;
          int64x2_t v40 = 0u;
          int64x2_t v41 = 0u;
          memset(v39, 0, sizeof(v39));
          if (SHIBYTE(__p.__r_.__value_.__r.__words[2]) < 0)
          {
            __p.__r_.__value_.__l.__size_ = 0;
            p_p = (std::string *)__p.__r_.__value_.__r.__words[0];
          }
          else
          {
            *((unsigned char *)&__p.__r_.__value_.__s + 23) = 0;
            p_p = &__p;
          }
          uint64_t v21 = 0;
          p_p->__r_.__value_.__s.__data_[0] = 0;
        }
        uint64_t v51 = v21;
        std::vector<ZinPlaneDescriptor>::emplace_back<ZinPlaneDescriptor>(&v54, (uint64_t)v39);
        if (SHIBYTE(__p.__r_.__value_.__r.__words[2]) < 0) {
          operator delete(__p.__r_.__value_.__l.__data_);
        }
        ++v16;
      }
      *(void *)&v38[0] = v4 + 32;
      int64x2_t v23 = std::__tree<std::__value_type<std::string,ZinMultiPlaneLinearIODescriptor>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinMultiPlaneLinearIODescriptor>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinMultiPlaneLinearIODescriptor>>>::__emplace_unique_key_args<std::string,std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>((uint64_t **)a3, (void **)(v4 + 32), (uint64_t)&std::piecewise_construct, (long long **)v38);
      *(_OWORD *)(v23 + 7) = v52;
      *((_DWORD *)v23 + 18) = v53;
      if (v23 + 7 != (uint64_t *)&v52) {
        std::vector<ZinPlaneDescriptor>::__assign_with_size[abi:ne180100]<ZinPlaneDescriptor*,ZinPlaneDescriptor*>(v23 + 10, v54, v55, 0xEEEEEEEEEEEEEEEFLL * ((v55 - v54) >> 4));
      }
      *(void *)&v39[0] = &v54;
      std::vector<ZinPlaneDescriptor>::__destroy_vector::operator()[abi:ne180100]((void ***)v39);
      char v24 = 1;
      goto LABEL_33;
    }
    if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
      ZinIrBindings::GetMultiPlaneUncompressedDescriptor(buf, v4, (void *)(v4 + 32), v65);
    }
    char v24 = 0;
LABEL_33:
    if (v60)
    {
      long long v61 = v60;
      operator delete(v60);
    }
    if ((v24 & 1) == 0) {
      return 3;
    }
LABEL_36:
    int64x2_t v25 = *(void **)(v4 + 8);
    if (v25)
    {
      do
      {
        int64x2_t v26 = v25;
        int64x2_t v25 = (void *)*v25;
      }
      while (v25);
    }
    else
    {
      do
      {
        int64x2_t v26 = *(void **)(v4 + 16);
        BOOL v27 = *v26 == v4;
        uint64_t v4 = (uint64_t)v26;
      }
      while (!v27);
    }
    uint64_t v4 = (uint64_t)v26;
    if (v26 == (void *)(a1 + 80)) {
      return 0;
    }
  }
  if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
    ZinIrBindings::GetMultiPlaneUncompressedDescriptor(v4, v4 + 32, v29, v30, v31, v32, v33, v34);
  }
  return 3;
}

void sub_21136A264(_Unwind_Exception *a1)
{
  int v3 = *(void **)(v1 - 176);
  if (v3)
  {
    *(void *)(v1 - 168) = v3;
    operator delete(v3);
  }
  _Unwind_Resume(a1);
}

uint64_t std::vector<ZinPlaneDescriptor>::reserve(uint64_t *a1, unint64_t a2)
{
  uint64_t v4 = a1[2];
  uint64_t result = (uint64_t)(a1 + 2);
  if (0xEEEEEEEEEEEEEEEFLL * ((v4 - *a1) >> 4) < a2)
  {
    if (a2 >= 0x111111111111112) {
      std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
    }
    uint64_t v5 = a1[1] - *a1;
    v7[4] = result;
    v7[0] = std::__allocate_at_least[abi:ne180100]<std::allocator<ZinPlaneDescriptor>>(result, a2);
    v7[1] = v7[0] + v5;
    v7[2] = v7[0] + v5;
    v7[3] = v7[0] + 240 * v6;
    std::vector<ZinPlaneDescriptor>::__swap_out_circular_buffer(a1, v7);
    return std::__split_buffer<ZinPlaneDescriptor>::~__split_buffer((uint64_t)v7);
  }
  return result;
}

void sub_21136A368(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::__split_buffer<ZinPlaneDescriptor>::~__split_buffer((uint64_t)va);
  _Unwind_Resume(a1);
}

uint64_t std::vector<ZinPlaneDescriptor>::emplace_back<ZinPlaneDescriptor>(uint64_t *a1, uint64_t a2)
{
  unint64_t v6 = a1[2];
  uint64_t v4 = (uint64_t)(a1 + 2);
  unint64_t v5 = v6;
  unint64_t v7 = *(void *)(v4 - 8);
  if (v7 >= v6)
  {
    unint64_t v19 = 0xEEEEEEEEEEEEEEEFLL * ((uint64_t)(v7 - *a1) >> 4);
    unint64_t v20 = v19 + 1;
    if (v19 + 1 > 0x111111111111111) {
      std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
    }
    unint64_t v21 = 0xEEEEEEEEEEEEEEEFLL * ((uint64_t)(v5 - *a1) >> 4);
    if (2 * v21 > v20) {
      unint64_t v20 = 2 * v21;
    }
    if (v21 >= 0x88888888888888) {
      unint64_t v22 = 0x111111111111111;
    }
    else {
      unint64_t v22 = v20;
    }
    v37[4] = v4;
    int64x2_t v23 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ZinPlaneDescriptor>>(v4, v22);
    char v24 = &v23[240 * v19];
    v37[0] = v23;
    v37[1] = v24;
    v37[3] = &v23[240 * v25];
    long long v26 = *(_OWORD *)(a2 + 16);
    long long v27 = *(_OWORD *)(a2 + 32);
    long long v28 = *(_OWORD *)(a2 + 64);
    *((_OWORD *)v24 + 3) = *(_OWORD *)(a2 + 48);
    *((_OWORD *)v24 + 4) = v28;
    *((_OWORD *)v24 + 2) = v27;
    long long v29 = *(_OWORD *)(a2 + 128);
    long long v31 = *(_OWORD *)(a2 + 80);
    long long v30 = *(_OWORD *)(a2 + 96);
    *((_OWORD *)v24 + 7) = *(_OWORD *)(a2 + 112);
    *((_OWORD *)v24 + 8) = v29;
    *((_OWORD *)v24 + 5) = v31;
    *((_OWORD *)v24 + 6) = v30;
    long long v32 = *(_OWORD *)(a2 + 192);
    long long v34 = *(_OWORD *)(a2 + 144);
    long long v33 = *(_OWORD *)(a2 + 160);
    *((_OWORD *)v24 + 11) = *(_OWORD *)(a2 + 176);
    *((_OWORD *)v24 + 12) = v32;
    *((_OWORD *)v24 + 9) = v34;
    *((_OWORD *)v24 + 1std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v33;
    *((_OWORD *)v24 + 1) = v26;
    *(_OWORD *)char v24 = *(_OWORD *)a2;
    long long v35 = *(_OWORD *)(a2 + 208);
    *((void *)v24 + 28) = *(void *)(a2 + 224);
    *((_OWORD *)v24 + 13) = v35;
    *(void *)(a2 + 216) = 0;
    *(void *)(a2 + 224) = 0;
    *(void *)(a2 + 208) = 0;
    *((void *)v24 + 29) = *(void *)(a2 + 232);
    v37[2] = v24 + 240;
    std::vector<ZinPlaneDescriptor>::__swap_out_circular_buffer(a1, v37);
    uint64_t v18 = a1[1];
    std::__split_buffer<ZinPlaneDescriptor>::~__split_buffer((uint64_t)v37);
  }
  else
  {
    *(_OWORD *)unint64_t v7 = *(_OWORD *)a2;
    long long v8 = *(_OWORD *)(a2 + 16);
    long long v9 = *(_OWORD *)(a2 + 32);
    long long v10 = *(_OWORD *)(a2 + 64);
    *(_OWORD *)(v7 + 48) = *(_OWORD *)(a2 + 48);
    *(_OWORD *)(v7 + 64) = v10;
    *(_OWORD *)(v7 + 16) = v8;
    *(_OWORD *)(v7 + 32) = v9;
    long long v11 = *(_OWORD *)(a2 + 80);
    long long v12 = *(_OWORD *)(a2 + 96);
    long long v13 = *(_OWORD *)(a2 + 128);
    *(_OWORD *)(v7 + 112) = *(_OWORD *)(a2 + 112);
    *(_OWORD *)(v7 + 128) = v13;
    *(_OWORD *)(v7 + 8std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v11;
    *(_OWORD *)(v7 + 96) = v12;
    long long v14 = *(_OWORD *)(a2 + 144);
    long long v15 = *(_OWORD *)(a2 + 160);
    long long v16 = *(_OWORD *)(a2 + 192);
    *(_OWORD *)(v7 + 176) = *(_OWORD *)(a2 + 176);
    *(_OWORD *)(v7 + 192) = v16;
    *(_OWORD *)(v7 + 144) = v14;
    *(_OWORD *)(v7 + 16std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v15;
    long long v17 = *(_OWORD *)(a2 + 208);
    *(void *)(v7 + 224) = *(void *)(a2 + 224);
    *(_OWORD *)(v7 + 208) = v17;
    *(void *)(a2 + 216) = 0;
    *(void *)(a2 + 224) = 0;
    *(void *)(a2 + 208) = 0;
    *(void *)(v7 + 232) = *(void *)(a2 + 232);
    uint64_t v18 = v7 + 240;
    a1[1] = v7 + 240;
  }
  a1[1] = v18;
  return v18 - 240;
}

void sub_21136A520(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::__split_buffer<ZinPlaneDescriptor>::~__split_buffer((uint64_t)va);
  _Unwind_Resume(a1);
}

uint64_t ZinIrBindings::GetCompressedDescriptor(uint64_t a1, int a2, uint64_t a3)
{
  int v39 = a2;
  unint64_t v5 = std::map<ZinIrDimension,unsigned long>::at(a1, &v39);
  std::__tree<std::__value_type<std::string,ZinTiledCompressedIODescriptor>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinTiledCompressedIODescriptor>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinTiledCompressedIODescriptor>>>::destroy(a3, *(void **)(a3 + 8));
  *(void *)a3 = a3 + 8;
  long long v30 = (uint64_t **)a3;
  *(void *)(a3 + 16) = 0;
  *(void *)(a3 + 8) = 0;
  uint64_t v6 = *(void *)(a1 + 48);
  unint64_t v7 = (void *)(a1 + 56);
  if (v6 == a1 + 56) {
    return 0;
  }
  while (*(_DWORD *)(v6 + 56) != v39)
  {
LABEL_21:
    unint64_t v20 = *(void **)(v6 + 8);
    if (v20)
    {
      do
      {
        unint64_t v21 = v20;
        unint64_t v20 = (void *)*v20;
      }
      while (v20);
    }
    else
    {
      do
      {
        unint64_t v21 = *(void **)(v6 + 16);
        BOOL v22 = *v21 == v6;
        uint64_t v6 = (uint64_t)v21;
      }
      while (!v22);
    }
    uint64_t v6 = (uint64_t)v21;
    if (v21 == v7) {
      return 0;
    }
  }
  long long v8 = std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::find<std::string>((uint64_t)v5, (void **)(v6 + 32));
  if (v5 + 1 != (uint64_t *)v8)
  {
    int v36 = 0;
    int64x2_t v37 = 0;
    uint64_t v38 = 0;
    *(void *)&v35[16] = 0;
    *(_OWORD *)long long v35 = 0uLL;
    *(_DWORD *)&v35[24] = *((_DWORD *)v8 + 65);
    long long v9 = *(int8x16_t ***)(v6 + 64);
    uint64_t v10 = *(void *)(v6 + 72);
    int8x16_t v11 = (*v9)[4];
    *(void *)&v35[16] = (*v9)[3].i64[1];
    *(int8x16_t *)long long v35 = vextq_s8(v11, v11, 8uLL);
    std::vector<ZinTiledCompressedPlaneDescriptor>::reserve((uint64_t *)&v36, (v10 - (uint64_t)v9) >> 3);
    long long v12 = *(ZinIrTensor ***)(v6 + 64);
    long long v13 = *(ZinIrTensor ***)(v6 + 72);
    while (v12 != v13)
    {
      uint64_t v14 = *((void *)*v12 + 13);
      if (!v14 || (long long v15 = *(uint64_t **)(v14 + 40), v15 == *(uint64_t **)(v14 + 48))) {
        uint64_t v16 = 0;
      }
      else {
        uint64_t v16 = *v15;
      }
      uint64_t v17 = *((void *)ZinIrTensor::GetRootTensor(*v12) + 13);
      if (v17) {
        uint64_t v18 = *(void *)(v17 + 64);
      }
      else {
        uint64_t v18 = 0;
      }
      std::string::basic_string[abi:ne180100]<0>(&v31, &byte_211F4AA5D);
      uint64_t v32 = 0;
      std::string::basic_string[abi:ne180100]<0>(&__p, &byte_211F4AA5D);
      uint64_t v34 = 0;
      std::string::operator=(&v31, (const std::string *)(v16 + 160));
      uint64_t v32 = *(void *)(v16 + 184);
      std::string::operator=(&__p, (const std::string *)(v18 + 160));
      uint64_t v34 = *(void *)(v18 + 184);
      std::vector<ZinTiledCompressedPlaneDescriptor>::emplace_back<ZinTiledCompressedPlaneDescriptor>((uint64_t *)&v36, (long long *)&v31);
      if (SHIBYTE(__p.__r_.__value_.__r.__words[2]) < 0) {
        operator delete(__p.__r_.__value_.__l.__data_);
      }
      if (SHIBYTE(v31.__r_.__value_.__r.__words[2]) < 0) {
        operator delete(v31.__r_.__value_.__l.__data_);
      }
      ++v12;
    }
    int64x2_t v40 = (long long *)(v6 + 32);
    unint64_t v19 = std::__tree<std::__value_type<std::string,ZinTiledCompressedIODescriptor>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinTiledCompressedIODescriptor>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinTiledCompressedIODescriptor>>>::__emplace_unique_key_args<std::string,std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>(v30, (void **)(v6 + 32), (uint64_t)&std::piecewise_construct, &v40);
    *(_OWORD *)(v19 + 7) = *(_OWORD *)v35;
    *(_OWORD *)((char *)v19 + 68) = *(_OWORD *)&v35[12];
    if (v19 + 7 != (uint64_t *)v35) {
      std::vector<ZinTiledCompressedPlaneDescriptor>::__assign_with_size[abi:ne180100]<ZinTiledCompressedPlaneDescriptor*,ZinTiledCompressedPlaneDescriptor*>((uint64_t)(v19 + 11), v36, v37, ((char *)v37 - (char *)v36) >> 6);
    }
    v31.__r_.__value_.__r.__words[0] = (std::string::size_type)&v36;
    std::vector<ZinTiledCompressedPlaneDescriptor>::__destroy_vector::operator()[abi:ne180100]((void ***)&v31);
    unint64_t v7 = (void *)(a1 + 56);
    goto LABEL_21;
  }
  if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
    ZinIrBindings::GetMultiPlaneUncompressedDescriptor(v6, v6 + 32, v24, v25, v26, v27, v28, v29);
  }
  return 3;
}

void sub_21136A7E0(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, void *__p, uint64_t a14, int a15, __int16 a16, char a17, char a18)
{
}

uint64_t std::vector<ZinTiledCompressedPlaneDescriptor>::reserve(uint64_t *a1, unint64_t a2)
{
  uint64_t v4 = a1[2];
  uint64_t result = (uint64_t)(a1 + 2);
  if (a2 > (v4 - *a1) >> 6)
  {
    if (a2 >> 58) {
      std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
    }
    uint64_t v5 = a1[1] - *a1;
    v7[4] = result;
    v7[0] = std::__allocate_at_least[abi:ne180100]<std::allocator<ZinDynamicOffsetCustomBarCmd>>(result, a2);
    v7[1] = v7[0] + v5;
    v7[2] = v7[0] + v5;
    v7[3] = v7[0] + (v6 << 6);
    std::vector<ZinTiledCompressedPlaneDescriptor>::__swap_out_circular_buffer(a1, v7);
    return std::__split_buffer<ZinTiledCompressedPlaneDescriptor>::~__split_buffer((uint64_t)v7);
  }
  return result;
}

void sub_21136A8A8(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::__split_buffer<ZinTiledCompressedPlaneDescriptor>::~__split_buffer((uint64_t)va);
  _Unwind_Resume(a1);
}

uint64_t std::vector<ZinTiledCompressedPlaneDescriptor>::emplace_back<ZinTiledCompressedPlaneDescriptor>(uint64_t *a1, long long *a2)
{
  unint64_t v6 = a1[2];
  uint64_t v4 = (uint64_t)(a1 + 2);
  unint64_t v5 = v6;
  unint64_t v7 = *(void *)(v4 - 8);
  if (v7 >= v6)
  {
    uint64_t v11 = (uint64_t)(v7 - *a1) >> 6;
    unint64_t v12 = v11 + 1;
    if ((unint64_t)(v11 + 1) >> 58) {
      std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
    }
    uint64_t v13 = v5 - *a1;
    if (v13 >> 5 > v12) {
      unint64_t v12 = v13 >> 5;
    }
    if ((unint64_t)v13 >= 0x7FFFFFFFFFFFFFC0) {
      unint64_t v14 = 0x3FFFFFFFFFFFFFFLL;
    }
    else {
      unint64_t v14 = v12;
    }
    v21[4] = v4;
    long long v15 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ZinDynamicOffsetCustomBarCmd>>(v4, v14);
    uint64_t v16 = &v15[64 * v11];
    v21[0] = v15;
    v21[1] = v16;
    v21[3] = &v15[64 * v17];
    uint64_t v18 = *((void *)a2 + 2);
    *(_OWORD *)uint64_t v16 = *a2;
    *((void *)v16 + 2) = v18;
    *((void *)a2 + 1) = 0;
    *((void *)a2 + 2) = 0;
    *(void *)a2 = 0;
    *((void *)v16 + 3) = *((void *)a2 + 3);
    long long v19 = a2[2];
    *((void *)v16 + 6) = *((void *)a2 + 6);
    *((_OWORD *)v16 + 2) = v19;
    *((void *)a2 + 5) = 0;
    *((void *)a2 + 6) = 0;
    *((void *)a2 + 4) = 0;
    *((void *)v16 + 7) = *((void *)a2 + 7);
    v21[2] = v16 + 64;
    std::vector<ZinTiledCompressedPlaneDescriptor>::__swap_out_circular_buffer(a1, v21);
    uint64_t v10 = a1[1];
    std::__split_buffer<ZinTiledCompressedPlaneDescriptor>::~__split_buffer((uint64_t)v21);
  }
  else
  {
    long long v8 = *a2;
    *(void *)(v7 + 16) = *((void *)a2 + 2);
    *(_OWORD *)unint64_t v7 = v8;
    *((void *)a2 + 1) = 0;
    *((void *)a2 + 2) = 0;
    *(void *)a2 = 0;
    *(void *)(v7 + 24) = *((void *)a2 + 3);
    long long v9 = a2[2];
    *(void *)(v7 + 48) = *((void *)a2 + 6);
    *(_OWORD *)(v7 + 32) = v9;
    *((void *)a2 + 5) = 0;
    *((void *)a2 + 6) = 0;
    *((void *)a2 + 4) = 0;
    *(void *)(v7 + 56) = *((void *)a2 + 7);
    uint64_t v10 = v7 + 64;
    a1[1] = v7 + 64;
  }
  a1[1] = v10;
  return v10 - 64;
}

void sub_21136AA0C(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::__split_buffer<ZinTiledCompressedPlaneDescriptor>::~__split_buffer((uint64_t)va);
  _Unwind_Resume(a1);
}

uint64_t ZinIrBindings::AddLiveInParam(uint64_t a1, void **a2, uint64_t a3)
{
  unint64_t v5 = (uint64_t **)(a1 + 24);
  if ((void **)(a1 + 32) != std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::find<std::string>(a1 + 24, a2))return 3; {
  long long v8 = a2;
  }
  unint64_t v7 = std::__tree<std::__value_type<std::string,ZinIrInputParamInfo>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrInputParamInfo>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrInputParamInfo>>>::__emplace_unique_key_args<std::string,std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>(v5, a2, (uint64_t)&std::piecewise_construct, (long long **)&v8);
  std::string::operator=((std::string *)(v7 + 7), (const std::string *)a3);
  uint64_t result = 0;
  *((_DWORD *)v7 + 2std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = *(_DWORD *)(a3 + 24);
  return result;
}

uint64_t ZinIrBindings::GetLiveInParamDescriptor(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = (void *)(a2 + 8);
  std::__tree<std::__value_type<std::string,WeightFileProperties>,std::__map_value_compare<std::string,std::__value_type<std::string,WeightFileProperties>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,WeightFileProperties>>>::destroy(a2, *(void **)(a2 + 8));
  *(void *)a2 = v4;
  *(void *)(a2 + 16) = 0;
  *uint64_t v4 = 0;
  unint64_t v5 = *(void **)(a1 + 24);
  if (v5 == (void *)(a1 + 32)) {
    return 0;
  }
  while (1)
  {
    std::string::basic_string[abi:ne180100]<0>(&__p, &byte_211F4AA5D);
    uint64_t v14 = 0;
    uint64_t v11 = 0;
    if (ZinTensorFormatGetSizeInBytes(*((_DWORD *)v5 + 20), &v11)) {
      break;
    }
    int v12 = *((_DWORD *)v5 + 20);
    std::string::operator=(&__p, (const std::string *)(v5 + 7));
    uint64_t v14 = v11;
    long long v15 = (long long *)(v5 + 7);
    unint64_t v6 = std::__tree<std::__value_type<std::string,ZinLiveInputParamDescriptor>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinLiveInputParamDescriptor>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinLiveInputParamDescriptor>>>::__emplace_unique_key_args<std::string,std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>((uint64_t **)a2, (void **)v5 + 7, (uint64_t)&std::piecewise_construct, &v15);
    *((_DWORD *)v6 + 14) = v12;
    std::string::operator=((std::string *)(v6 + 8), &__p);
    v6[11] = v14;
    if (SHIBYTE(__p.__r_.__value_.__r.__words[2]) < 0) {
      operator delete(__p.__r_.__value_.__l.__data_);
    }
    unint64_t v7 = (void *)v5[1];
    if (v7)
    {
      do
      {
        long long v8 = v7;
        unint64_t v7 = (void *)*v7;
      }
      while (v7);
    }
    else
    {
      do
      {
        long long v8 = (void *)v5[2];
        BOOL v9 = *v8 == (void)v5;
        unint64_t v5 = v8;
      }
      while (!v9);
    }
    unint64_t v5 = v8;
    if (v8 == (void *)(a1 + 32)) {
      return 0;
    }
  }
  if (SHIBYTE(__p.__r_.__value_.__r.__words[2]) < 0) {
    operator delete(__p.__r_.__value_.__l.__data_);
  }
  return 3;
}

void sub_21136AC20(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, void *__p, uint64_t a12, int a13, __int16 a14, char a15, char a16)
{
  if (a16 < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

void std::vector<ZinPlaneDescriptor>::__assign_with_size[abi:ne180100]<ZinPlaneDescriptor*,ZinPlaneDescriptor*>(uint64_t *a1, uint64_t a2, uint64_t a3, unint64_t a4)
{
  uint64_t v8 = (uint64_t)(a1 + 2);
  uint64_t v9 = *a1;
  if (0xEEEEEEEEEEEEEEEFLL * ((a1[2] - *a1) >> 4) < a4)
  {
    std::vector<ZinPlaneDescriptor>::__vdeallocate(a1);
    if (a4 > 0x111111111111111) {
      std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
    }
    unint64_t v10 = 0xDDDDDDDDDDDDDDDELL * ((a1[2] - *a1) >> 4);
    if (v10 <= a4) {
      unint64_t v10 = a4;
    }
    if (0xEEEEEEEEEEEEEEEFLL * ((a1[2] - *a1) >> 4) >= 0x88888888888888) {
      unint64_t v11 = 0x111111111111111;
    }
    else {
      unint64_t v11 = v10;
    }
    std::vector<ZinPlaneDescriptor>::__vallocate[abi:ne180100](a1, v11);
    uint64_t v12 = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<ZinPlaneDescriptor>,ZinPlaneDescriptor*,ZinPlaneDescriptor*,ZinPlaneDescriptor*>(v8, a2, a3, a1[1]);
    goto LABEL_11;
  }
  if (0xEEEEEEEEEEEEEEEFLL * ((a1[1] - v9) >> 4) < a4)
  {
    uint64_t v13 = a2 + 16 * ((a1[1] - v9) >> 4);
    std::__unwrap_and_dispatch[abi:ne180100]<std::__overload<std::__copy_loop<std::_ClassicAlgPolicy>,std::__copy_trivial>,ZinPlaneDescriptor *,ZinPlaneDescriptor *,ZinPlaneDescriptor *,0>(a2, v13, v9);
    uint64_t v12 = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<ZinPlaneDescriptor>,ZinPlaneDescriptor*,ZinPlaneDescriptor*,ZinPlaneDescriptor*>(v8, v13, a3, a1[1]);
LABEL_11:
    a1[1] = v12;
    return;
  }
  std::__unwrap_and_dispatch[abi:ne180100]<std::__overload<std::__copy_loop<std::_ClassicAlgPolicy>,std::__copy_trivial>,ZinPlaneDescriptor *,ZinPlaneDescriptor *,ZinPlaneDescriptor *,0>(a2, a3, v9);
  uint64_t v15 = v14;
  uint64_t v16 = a1[1];
  if (v16 != v14)
  {
    do
    {
      if (*(char *)(v16 - 9) < 0) {
        operator delete(*(void **)(v16 - 32));
      }
      v16 -= 240;
    }
    while (v16 != v15);
  }
  a1[1] = v15;
}

void sub_21136ADA4(_Unwind_Exception *a1)
{
  *(void *)(v1 + 8) = v2;
  _Unwind_Resume(a1);
}

void sub_21136ADAC(_Unwind_Exception *a1)
{
  *(void *)(v1 + 8) = v2;
  _Unwind_Resume(a1);
}

void std::vector<ZinPlaneDescriptor>::__vdeallocate(uint64_t *a1)
{
  if (*a1)
  {
    std::vector<ZinPlaneDescriptor>::__clear[abi:ne180100](a1);
    operator delete((void *)*a1);
    *a1 = 0;
    a1[1] = 0;
    a1[2] = 0;
  }
}

uint64_t std::__unwrap_and_dispatch[abi:ne180100]<std::__overload<std::__copy_loop<std::_ClassicAlgPolicy>,std::__copy_trivial>,ZinPlaneDescriptor *,ZinPlaneDescriptor *,ZinPlaneDescriptor *,0>(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = a1;
  if (a1 == a2) {
    return a1;
  }
  uint64_t v5 = a2;
  do
  {
    *(_OWORD *)a3 = *(_OWORD *)v4;
    long long v6 = *(_OWORD *)(v4 + 16);
    long long v7 = *(_OWORD *)(v4 + 32);
    long long v8 = *(_OWORD *)(v4 + 64);
    *(_OWORD *)(a3 + 48) = *(_OWORD *)(v4 + 48);
    *(_OWORD *)(a3 + 64) = v8;
    *(_OWORD *)(a3 + 16) = v6;
    *(_OWORD *)(a3 + 32) = v7;
    long long v9 = *(_OWORD *)(v4 + 80);
    long long v10 = *(_OWORD *)(v4 + 96);
    long long v11 = *(_OWORD *)(v4 + 128);
    *(_OWORD *)(a3 + 112) = *(_OWORD *)(v4 + 112);
    *(_OWORD *)(a3 + 128) = v11;
    *(_OWORD *)(a3 + 8std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v9;
    *(_OWORD *)(a3 + 96) = v10;
    long long v12 = *(_OWORD *)(v4 + 144);
    long long v13 = *(_OWORD *)(v4 + 160);
    long long v14 = *(_OWORD *)(v4 + 192);
    *(_OWORD *)(a3 + 176) = *(_OWORD *)(v4 + 176);
    *(_OWORD *)(a3 + 192) = v14;
    *(_OWORD *)(a3 + 144) = v12;
    *(_OWORD *)(a3 + 16std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v13;
    std::string::operator=((std::string *)(a3 + 208), (const std::string *)(v4 + 208));
    *(void *)(a3 + 232) = *(void *)(v4 + 232);
    a3 += 240;
    v4 += 240;
  }
  while (v4 != v5);
  return v5;
}

uint64_t *std::vector<ZinTiledCompressedPlaneDescriptor>::__swap_out_circular_buffer(uint64_t *result, void *a2)
{
  uint64_t v3 = *result;
  uint64_t v2 = result[1];
  uint64_t v4 = a2[1];
  if (v2 != *result)
  {
    uint64_t v5 = 0;
    do
    {
      uint64_t v6 = v4 + v5;
      uint64_t v7 = v2 + v5;
      long long v8 = *(_OWORD *)(v2 + v5 - 64);
      *(void *)(v6 - 48) = *(void *)(v2 + v5 - 48);
      *(_OWORD *)(v6 - 64) = v8;
      *(void *)(v7 - 56) = 0;
      *(void *)(v7 - 48) = 0;
      *(void *)(v7 - 64) = 0;
      *(void *)(v6 - 4std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = *(void *)(v2 + v5 - 40);
      long long v9 = *(_OWORD *)(v2 + v5 - 32);
      *(void *)(v6 - 16) = *(void *)(v2 + v5 - 16);
      *(_OWORD *)(v6 - 32) = v9;
      *(void *)(v7 - 24) = 0;
      *(void *)(v7 - 16) = 0;
      *(void *)(v7 - 32) = 0;
      *(void *)(v6 - 8) = *(void *)(v2 + v5 - 8);
      v5 -= 64;
    }
    while (v2 + v5 != v3);
    v4 += v5;
  }
  a2[1] = v4;
  uint64_t v10 = *result;
  *uint64_t result = v4;
  a2[1] = v10;
  uint64_t v11 = result[1];
  result[1] = a2[2];
  a2[2] = v11;
  uint64_t v12 = result[2];
  result[2] = a2[3];
  a2[3] = v12;
  *a2 = a2[1];
  return result;
}

uint64_t std::__split_buffer<ZinTiledCompressedPlaneDescriptor>::~__split_buffer(uint64_t a1)
{
  uint64_t v3 = *(void *)(a1 + 8);
  for (uint64_t i = *(void *)(a1 + 16); i != v3; uint64_t i = *(void *)(a1 + 16))
  {
    *(void *)(a1 + 16) = i - 64;
    std::__destroy_at[abi:ne180100]<std::pair<std::string const,WeightFileProperties>,0>(i - 64);
  }
  if (*(void *)a1) {
    operator delete(*(void **)a1);
  }
  return a1;
}

void std::vector<ZinTiledCompressedPlaneDescriptor>::__assign_with_size[abi:ne180100]<ZinTiledCompressedPlaneDescriptor*,ZinTiledCompressedPlaneDescriptor*>(uint64_t a1, std::string *__str, std::string *a3, unint64_t a4)
{
  uint64_t v8 = a1 + 16;
  long long v9 = *(std::string **)a1;
  if (a4 > (uint64_t)(*(void *)(a1 + 16) - *(void *)a1) >> 6)
  {
    std::vector<ZinTiledCompressedPlaneDescriptor>::__vdeallocate((void **)a1);
    if (a4 >> 58) {
      std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
    }
    uint64_t v10 = *(void *)(a1 + 16) - *(void *)a1;
    uint64_t v11 = v10 >> 5;
    if (v10 >> 5 <= a4) {
      uint64_t v11 = a4;
    }
    if ((unint64_t)v10 >= 0x7FFFFFFFFFFFFFC0) {
      unint64_t v12 = 0x3FFFFFFFFFFFFFFLL;
    }
    else {
      unint64_t v12 = v11;
    }
    std::vector<ZinDynamicOffsetCustomBarCmd>::__vallocate[abi:ne180100]((void *)a1, v12);
    uint64_t v13 = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<ZinTiledCompressedPlaneDescriptor>,ZinTiledCompressedPlaneDescriptor*,ZinTiledCompressedPlaneDescriptor*,ZinTiledCompressedPlaneDescriptor*>(v8, (uint64_t)__str, (uint64_t)a3, *(void *)(a1 + 8));
    goto LABEL_11;
  }
  unint64_t v14 = (uint64_t)(*(void *)(a1 + 8) - (void)v9) >> 6;
  if (v14 < a4)
  {
    uint64_t v15 = (std::string *)((char *)__str + 64 * v14);
    std::__copy_loop<std::_ClassicAlgPolicy>::operator()[abi:ne180100]<ZinTiledCompressedPlaneDescriptor *,ZinTiledCompressedPlaneDescriptor *,ZinTiledCompressedPlaneDescriptor *>((int)&v19, __str, v15, v9);
    uint64_t v13 = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<ZinTiledCompressedPlaneDescriptor>,ZinTiledCompressedPlaneDescriptor*,ZinTiledCompressedPlaneDescriptor*,ZinTiledCompressedPlaneDescriptor*>(v8, (uint64_t)v15, (uint64_t)a3, *(void *)(a1 + 8));
LABEL_11:
    *(void *)(a1 + 8) = v13;
    return;
  }
  std::__copy_loop<std::_ClassicAlgPolicy>::operator()[abi:ne180100]<ZinTiledCompressedPlaneDescriptor *,ZinTiledCompressedPlaneDescriptor *,ZinTiledCompressedPlaneDescriptor *>((int)&v20, __str, a3, v9);
  uint64_t v17 = v16;
  uint64_t v18 = *(void *)(a1 + 8);
  if (v18 != v16)
  {
    do
    {
      v18 -= 64;
      std::__destroy_at[abi:ne180100]<std::pair<std::string const,WeightFileProperties>,0>(v18);
    }
    while (v18 != v17);
  }
  *(void *)(a1 + 8) = v17;
}

void sub_21136B0D0(_Unwind_Exception *a1)
{
  *(void *)(v1 + 8) = v2;
  _Unwind_Resume(a1);
}

void sub_21136B0D8(_Unwind_Exception *a1)
{
  *(void *)(v1 + 8) = v2;
  _Unwind_Resume(a1);
}

void std::vector<ZinTiledCompressedPlaneDescriptor>::__vdeallocate(void **a1)
{
  uint64_t v1 = *a1;
  if (*a1)
  {
    uint64_t v3 = (uint64_t)a1[1];
    uint64_t v4 = *a1;
    if ((void *)v3 != v1)
    {
      do
      {
        v3 -= 64;
        std::__destroy_at[abi:ne180100]<std::pair<std::string const,WeightFileProperties>,0>(v3);
      }
      while ((void *)v3 != v1);
      uint64_t v4 = *a1;
    }
    a1[1] = v1;
    operator delete(v4);
    *a1 = 0;
    a1[1] = 0;
    a1[2] = 0;
  }
}

uint64_t std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<ZinTiledCompressedPlaneDescriptor>,ZinTiledCompressedPlaneDescriptor*,ZinTiledCompressedPlaneDescriptor*,ZinTiledCompressedPlaneDescriptor*>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  if (a2 != a3)
  {
    uint64_t v7 = 0;
    do
    {
      std::construct_at[abi:ne180100]<ZinTiledCompressedPlaneDescriptor,ZinTiledCompressedPlaneDescriptor&,ZinTiledCompressedPlaneDescriptor*>((std::string *)(a4 + v7), (long long *)(a2 + v7));
      v7 += 64;
    }
    while (a2 + v7 != a3);
    a4 += v7;
  }
  return a4;
}

void sub_21136B1A8(_Unwind_Exception *exception_object)
{
  if (v2)
  {
    uint64_t v4 = v1 - 64;
    do
    {
      std::__destroy_at[abi:ne180100]<std::pair<std::string const,WeightFileProperties>,0>(v4 + v2);
      v2 -= 64;
    }
    while (v2);
  }
  _Unwind_Resume(exception_object);
}

std::string *std::construct_at[abi:ne180100]<ZinTiledCompressedPlaneDescriptor,ZinTiledCompressedPlaneDescriptor&,ZinTiledCompressedPlaneDescriptor*>(std::string *this, long long *a2)
{
  if (*((char *)a2 + 23) < 0)
  {
    std::string::__init_copy_ctor_external(this, *(const std::string::value_type **)a2, *((void *)a2 + 1));
  }
  else
  {
    long long v4 = *a2;
    this->__r_.__value_.__r.__words[2] = *((void *)a2 + 2);
    *(_OWORD *)&this->__r_.__value_.__l.__data_ = v4;
  }
  this[1].__r_.__value_.__r.__words[0] = *((void *)a2 + 3);
  uint64_t v5 = (std::string *)((char *)this + 32);
  if (*((char *)a2 + 55) < 0)
  {
    std::string::__init_copy_ctor_external(v5, *((const std::string::value_type **)a2 + 4), *((void *)a2 + 5));
  }
  else
  {
    long long v6 = a2[2];
    this[2].__r_.__value_.__r.__words[0] = *((void *)a2 + 6);
    *(_OWORD *)&v5->__r_.__value_.__l.__data_ = v6;
  }
  this[2].__r_.__value_.__l.__size_ = *((void *)a2 + 7);
  return this;
}

void sub_21136B258(_Unwind_Exception *exception_object)
{
  if (*(char *)(v1 + 23) < 0) {
    operator delete(*(void **)v1);
  }
  _Unwind_Resume(exception_object);
}

std::string *std::__copy_loop<std::_ClassicAlgPolicy>::operator()[abi:ne180100]<ZinTiledCompressedPlaneDescriptor *,ZinTiledCompressedPlaneDescriptor *,ZinTiledCompressedPlaneDescriptor *>(int a1, std::string *__str, std::string *a3, std::string *this)
{
  uint64_t v5 = __str;
  if (__str == a3) {
    return __str;
  }
  long long v6 = a3;
  do
  {
    std::string::operator=(this, v5);
    this[1].__r_.__value_.__r.__words[0] = v5[1].__r_.__value_.__r.__words[0];
    std::string::operator=((std::string *)((char *)this + 32), (std::string *)((char *)v5 + 32));
    this[2].__r_.__value_.__l.__size_ = v5[2].__r_.__value_.__l.__size_;
    this = (std::string *)((char *)this + 64);
    uint64_t v5 = (std::string *)((char *)v5 + 64);
  }
  while (v5 != v6);
  return v6;
}

uint64_t *std::__tree<std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>,std::__map_value_compare<std::string,std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>>>::__emplace_unique_key_args<std::string,std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>(uint64_t **a1, void **a2, uint64_t a3, long long **a4)
{
  long long v6 = (uint64_t **)std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::__find_equal<std::string>((uint64_t)a1, &v11, a2);
  uint64_t v7 = *v6;
  if (!*v6)
  {
    uint64_t v8 = v6;
    std::__tree<std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>,std::__map_value_compare<std::string,std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>>>::__construct_node<std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>((uint64_t)a1, a4, (uint64_t)v10);
    std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::__insert_node_at(a1, v11, v8, v10[0]);
    uint64_t v7 = v10[0];
    v10[0] = 0;
    std::unique_ptr<std::__tree_node<std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>,void *>,std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>,void *>>>>::reset[abi:ne180100]((uint64_t)v10, 0);
  }
  return v7;
}

void std::__tree<std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>,std::__map_value_compare<std::string,std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>>>::__construct_node<std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>(uint64_t a1@<X0>, long long **a2@<X2>, uint64_t a3@<X8>)
{
  uint64_t v5 = a1 + 8;
  long long v6 = (char *)operator new(0x58uLL);
  *(void *)a3 = v6;
  *(void *)(a3 + 8) = v5;
  *(unsigned char *)(a3 + 16) = 0;
  uint64_t v7 = (std::string *)(v6 + 32);
  uint64_t v8 = *a2;
  if (*((char *)*a2 + 23) < 0)
  {
    std::string::__init_copy_ctor_external(v7, *(const std::string::value_type **)v8, *((void *)v8 + 1));
  }
  else
  {
    long long v9 = *v8;
    *((void *)v6 + 6) = *((void *)v8 + 2);
    *(_OWORD *)&v7->__r_.__value_.__l.__data_ = v9;
  }
  *((_DWORD *)v6 + 14) = 0;
  *((void *)v6 + 9) = 0;
  *((void *)v6 + 1std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  *((void *)v6 + 8) = 0;
  *(unsigned char *)(a3 + 16) = 1;
}

void sub_21136B424(_Unwind_Exception *a1)
{
  std::unique_ptr<std::__tree_node<std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>,void *>,std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<std::string,std::pair<IOType,std::vector<ZinIrTensor *>>>,void *>>>>::reset[abi:ne180100](v1, 0);
  _Unwind_Resume(a1);
}

uint64_t *std::__tree<std::__value_type<std::string,ZinSinglePlaneCircularIODescriptor>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinSinglePlaneCircularIODescriptor>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinSinglePlaneCircularIODescriptor>>>::__emplace_unique_key_args<std::string,std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>(uint64_t **a1, void **a2, uint64_t a3, long long **a4)
{
  long long v6 = (uint64_t **)std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::__find_equal<std::string>((uint64_t)a1, &v11, a2);
  uint64_t v7 = *v6;
  if (!*v6)
  {
    uint64_t v8 = v6;
    std::__tree<std::__value_type<std::string,ZinSinglePlaneCircularIODescriptor>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinSinglePlaneCircularIODescriptor>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinSinglePlaneCircularIODescriptor>>>::__construct_node<std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>((uint64_t)a1, a4, (uint64_t)v10);
    std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::__insert_node_at(a1, v11, v8, v10[0]);
    uint64_t v7 = v10[0];
    v10[0] = 0;
    std::unique_ptr<std::__tree_node<std::__value_type<std::string,ZinSinglePlaneCircularIODescriptor>,void *>,std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<std::string,ZinSinglePlaneCircularIODescriptor>,void *>>>>::reset[abi:ne180100]((uint64_t)v10, 0);
  }
  return v7;
}

std::string *std::__tree<std::__value_type<std::string,ZinSinglePlaneCircularIODescriptor>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinSinglePlaneCircularIODescriptor>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinSinglePlaneCircularIODescriptor>>>::__construct_node<std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>@<X0>(uint64_t a1@<X0>, long long **a2@<X2>, uint64_t a3@<X8>)
{
  uint64_t v5 = a1 + 8;
  long long v6 = (char *)operator new(0x140uLL);
  *(void *)a3 = v6;
  *(void *)(a3 + 8) = v5;
  *(unsigned char *)(a3 + 16) = 0;
  uint64_t result = std::pair<std::string const,ZinSinglePlaneCircularIODescriptor>::pair[abi:ne180100]<std::string const&>((std::string *)(v6 + 32), *a2);
  *(unsigned char *)(a3 + 16) = 1;
  return result;
}

void sub_21136B53C(_Unwind_Exception *a1)
{
  std::unique_ptr<std::__tree_node<std::__value_type<std::string,ZinSinglePlaneCircularIODescriptor>,void *>,std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<std::string,ZinSinglePlaneCircularIODescriptor>,void *>>>>::reset[abi:ne180100](v1, 0);
  _Unwind_Resume(a1);
}

std::string *std::pair<std::string const,ZinSinglePlaneCircularIODescriptor>::pair[abi:ne180100]<std::string const&>(std::string *this, long long *a2)
{
  if (*((char *)a2 + 23) < 0)
  {
    std::string::__init_copy_ctor_external(this, *(const std::string::value_type **)a2, *((void *)a2 + 1));
  }
  else
  {
    long long v3 = *a2;
    this->__r_.__value_.__r.__words[2] = *((void *)a2 + 2);
    *(_OWORD *)&this->__r_.__value_.__l.__data_ = v3;
  }
  *(_OWORD *)&this[1].__r_.__value_.__l.__data_ = 0u;
  *(_OWORD *)&this[9].__r_.__value_.__r.__words[2] = 0u;
  this[11].__r_.__value_.__r.__words[2] = 0;
  *(_OWORD *)&this[10].__r_.__value_.__r.__words[1] = 0u;
  *(_OWORD *)&this[11].__r_.__value_.__l.__data_ = 0u;
  *(_OWORD *)&this[8].__r_.__value_.__r.__words[1] = 0u;
  *(_OWORD *)&this[9].__r_.__value_.__l.__data_ = 0u;
  *(_OWORD *)&this[7].__r_.__value_.__l.__data_ = 0u;
  *(_OWORD *)&this[7].__r_.__value_.__r.__words[2] = 0u;
  *(_OWORD *)&this[5].__r_.__value_.__r.__words[2] = 0u;
  *(_OWORD *)&this[6].__r_.__value_.__r.__words[1] = 0u;
  *(_OWORD *)&this[4].__r_.__value_.__r.__words[1] = 0u;
  *(_OWORD *)&this[5].__r_.__value_.__l.__data_ = 0u;
  *(_OWORD *)&this[3].__r_.__value_.__l.__data_ = 0u;
  *(_OWORD *)&this[3].__r_.__value_.__r.__words[2] = 0u;
  *(_OWORD *)&this[1].__r_.__value_.__r.__words[2] = 0u;
  *(_OWORD *)&this[2].__r_.__value_.__r.__words[1] = 0u;
  int64x2_t v4 = vdupq_n_s64(1uLL);
  *(int64x2_t *)&this[3].__r_.__value_.__l.__data_ = v4;
  *(int64x2_t *)&this[3].__r_.__value_.__r.__words[2] = v4;
  *(int64x2_t *)&this[4].__r_.__value_.__r.__words[1] = v4;
  *(int64x2_t *)&this[5].__r_.__value_.__l.__data_ = v4;
  *(int64x2_t *)&this[5].__r_.__value_.__r.__words[2] = v4;
  *(int64x2_t *)&this[6].__r_.__value_.__r.__words[1] = v4;
  *(int64x2_t *)&this[7].__r_.__value_.__l.__data_ = v4;
  *(int64x2_t *)&this[7].__r_.__value_.__r.__words[2] = v4;
  *(int64x2_t *)&this[8].__r_.__value_.__r.__words[1] = v4;
  *(int64x2_t *)&this[9].__r_.__value_.__l.__data_ = v4;
  std::string::basic_string[abi:ne180100]<0>(&this[9].__r_.__value_.__r.__words[2], &byte_211F4AA5D);
  this[10].__r_.__value_.__r.__words[2] = 0;
  LODWORD(this[11].__r_.__value_.__l.__data_) = 5;
  this[11].__r_.__value_.__l.__size_ = 0;
  LOWORD(this[11].__r_.__value_.__r.__words[2]) = 0;
  return this;
}

void sub_21136B610(_Unwind_Exception *exception_object)
{
  if (*(char *)(v1 + 23) < 0) {
    operator delete(*(void **)v1);
  }
  _Unwind_Resume(exception_object);
}

void std::unique_ptr<std::__tree_node<std::__value_type<std::string,ZinSinglePlaneCircularIODescriptor>,void *>,std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<std::string,ZinSinglePlaneCircularIODescriptor>,void *>>>>::reset[abi:ne180100](uint64_t a1, uint64_t a2)
{
  uint64_t v2 = *(void **)a1;
  *(void *)a1 = a2;
  if (v2)
  {
    if (*(unsigned char *)(a1 + 16)) {
      std::__destroy_at[abi:ne180100]<std::pair<std::string const,ZinSinglePlaneLinearIODescriptor>,0>((uint64_t)v2 + 32);
    }
    operator delete(v2);
  }
}

uint64_t *std::__tree<std::__value_type<std::string,ZinSinglePlaneLinearIODescriptor>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinSinglePlaneLinearIODescriptor>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinSinglePlaneLinearIODescriptor>>>::__emplace_unique_key_args<std::string,std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>(uint64_t **a1, void **a2, uint64_t a3, long long **a4)
{
  long long v6 = (uint64_t **)std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::__find_equal<std::string>((uint64_t)a1, &v11, a2);
  uint64_t v7 = *v6;
  if (!*v6)
  {
    uint64_t v8 = v6;
    std::__tree<std::__value_type<std::string,ZinSinglePlaneLinearIODescriptor>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinSinglePlaneLinearIODescriptor>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinSinglePlaneLinearIODescriptor>>>::__construct_node<std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>((uint64_t)a1, a4, (uint64_t)v10);
    std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::__insert_node_at(a1, v11, v8, v10[0]);
    uint64_t v7 = v10[0];
    v10[0] = 0;
    std::unique_ptr<std::__tree_node<std::__value_type<std::string,ZinSinglePlaneCircularIODescriptor>,void *>,std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<std::string,ZinSinglePlaneCircularIODescriptor>,void *>>>>::reset[abi:ne180100]((uint64_t)v10, 0);
  }
  return v7;
}

std::string *std::__tree<std::__value_type<std::string,ZinSinglePlaneLinearIODescriptor>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinSinglePlaneLinearIODescriptor>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinSinglePlaneLinearIODescriptor>>>::__construct_node<std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>@<X0>(uint64_t a1@<X0>, long long **a2@<X2>, uint64_t a3@<X8>)
{
  uint64_t v5 = a1 + 8;
  long long v6 = (char *)operator new(0x128uLL);
  *(void *)a3 = v6;
  *(void *)(a3 + 8) = v5;
  *(unsigned char *)(a3 + 16) = 0;
  uint64_t result = std::pair<std::string const,ZinSinglePlaneLinearIODescriptor>::pair[abi:ne180100]<std::string const&>((std::string *)(v6 + 32), *a2);
  *(unsigned char *)(a3 + 16) = 1;
  return result;
}

void sub_21136B784(_Unwind_Exception *a1)
{
  std::unique_ptr<std::__tree_node<std::__value_type<std::string,ZinSinglePlaneCircularIODescriptor>,void *>,std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<std::string,ZinSinglePlaneCircularIODescriptor>,void *>>>>::reset[abi:ne180100](v1, 0);
  _Unwind_Resume(a1);
}

std::string *std::pair<std::string const,ZinSinglePlaneLinearIODescriptor>::pair[abi:ne180100]<std::string const&>(std::string *this, long long *a2)
{
  if (*((char *)a2 + 23) < 0)
  {
    std::string::__init_copy_ctor_external(this, *(const std::string::value_type **)a2, *((void *)a2 + 1));
  }
  else
  {
    long long v3 = *a2;
    this->__r_.__value_.__r.__words[2] = *((void *)a2 + 2);
    *(_OWORD *)&this->__r_.__value_.__l.__data_ = v3;
  }
  *(_OWORD *)&this[9].__r_.__value_.__r.__words[2] = 0u;
  *(_OWORD *)&this[10].__r_.__value_.__r.__words[1] = 0u;
  int64x2_t v4 = vdupq_n_s64(1uLL);
  *(_OWORD *)&this[1].__r_.__value_.__l.__data_ = 0u;
  *(_OWORD *)&this[1].__r_.__value_.__r.__words[2] = 0u;
  *(_OWORD *)&this[2].__r_.__value_.__r.__words[1] = 0u;
  *(int64x2_t *)&this[3].__r_.__value_.__l.__data_ = v4;
  *(int64x2_t *)&this[3].__r_.__value_.__r.__words[2] = v4;
  *(int64x2_t *)&this[4].__r_.__value_.__r.__words[1] = v4;
  *(int64x2_t *)&this[5].__r_.__value_.__l.__data_ = v4;
  *(int64x2_t *)&this[5].__r_.__value_.__r.__words[2] = v4;
  *(int64x2_t *)&this[6].__r_.__value_.__r.__words[1] = v4;
  *(int64x2_t *)&this[7].__r_.__value_.__l.__data_ = v4;
  *(int64x2_t *)&this[7].__r_.__value_.__r.__words[2] = v4;
  *(int64x2_t *)&this[8].__r_.__value_.__r.__words[1] = v4;
  *(int64x2_t *)&this[9].__r_.__value_.__l.__data_ = v4;
  std::string::basic_string[abi:ne180100]<0>(&this[9].__r_.__value_.__r.__words[2], &byte_211F4AA5D);
  this[10].__r_.__value_.__r.__words[2] = 0;
  return this;
}

void sub_21136B830(_Unwind_Exception *exception_object)
{
  if (*(char *)(v1 + 23) < 0) {
    operator delete(*(void **)v1);
  }
  _Unwind_Resume(exception_object);
}

uint64_t *std::__tree<std::__value_type<std::string,ZinMultiPlaneLinearIODescriptor>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinMultiPlaneLinearIODescriptor>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinMultiPlaneLinearIODescriptor>>>::__emplace_unique_key_args<std::string,std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>(uint64_t **a1, void **a2, uint64_t a3, long long **a4)
{
  long long v6 = (uint64_t **)std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::__find_equal<std::string>((uint64_t)a1, &v11, a2);
  uint64_t v7 = *v6;
  if (!*v6)
  {
    uint64_t v8 = v6;
    std::__tree<std::__value_type<std::string,ZinMultiPlaneLinearIODescriptor>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinMultiPlaneLinearIODescriptor>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinMultiPlaneLinearIODescriptor>>>::__construct_node<std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>((uint64_t)a1, a4, (uint64_t)v10);
    std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::__insert_node_at(a1, v11, v8, v10[0]);
    uint64_t v7 = v10[0];
    v10[0] = 0;
    std::unique_ptr<std::__tree_node<std::__value_type<std::string,ZinMultiPlaneLinearIODescriptor>,void *>,std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<std::string,ZinMultiPlaneLinearIODescriptor>,void *>>>>::reset[abi:ne180100]((uint64_t)v10, 0);
  }
  return v7;
}

double std::__tree<std::__value_type<std::string,ZinMultiPlaneLinearIODescriptor>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinMultiPlaneLinearIODescriptor>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinMultiPlaneLinearIODescriptor>>>::__construct_node<std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>@<D0>(uint64_t a1@<X0>, long long **a2@<X2>, uint64_t a3@<X8>)
{
  uint64_t v5 = a1 + 8;
  long long v6 = (char *)operator new(0x68uLL);
  *(void *)a3 = v6;
  *(void *)(a3 + 8) = v5;
  *(unsigned char *)(a3 + 16) = 0;
  uint64_t v7 = (std::string *)(v6 + 32);
  uint64_t v8 = *a2;
  if (*((char *)*a2 + 23) < 0)
  {
    std::string::__init_copy_ctor_external(v7, *(const std::string::value_type **)v8, *((void *)v8 + 1));
  }
  else
  {
    long long v9 = *v8;
    *((void *)v6 + 6) = *((void *)v8 + 2);
    *(_OWORD *)&v7->__r_.__value_.__l.__data_ = v9;
  }
  double result = 0.0;
  *(_OWORD *)(v6 + 88) = 0u;
  *(_OWORD *)(v6 + 72) = 0u;
  *(_OWORD *)(v6 + 56) = 0u;
  *(unsigned char *)(a3 + 16) = 1;
  return result;
}

void sub_21136B980(_Unwind_Exception *a1)
{
  std::unique_ptr<std::__tree_node<std::__value_type<std::string,ZinMultiPlaneLinearIODescriptor>,void *>,std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<std::string,ZinMultiPlaneLinearIODescriptor>,void *>>>>::reset[abi:ne180100](v1, 0);
  _Unwind_Resume(a1);
}

void std::unique_ptr<std::__tree_node<std::__value_type<std::string,ZinMultiPlaneLinearIODescriptor>,void *>,std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<std::string,ZinMultiPlaneLinearIODescriptor>,void *>>>>::reset[abi:ne180100](uint64_t a1, uint64_t a2)
{
  uint64_t v2 = *(void **)a1;
  *(void *)a1 = a2;
  if (v2)
  {
    if (*(unsigned char *)(a1 + 16)) {
      std::__destroy_at[abi:ne180100]<std::pair<std::string const,ZinMultiPlaneLinearIODescriptor>,0>((uint64_t)v2 + 32);
    }
    operator delete(v2);
  }
}

uint64_t *std::__tree<std::__value_type<std::string,ZinTiledCompressedIODescriptor>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinTiledCompressedIODescriptor>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinTiledCompressedIODescriptor>>>::__emplace_unique_key_args<std::string,std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>(uint64_t **a1, void **a2, uint64_t a3, long long **a4)
{
  long long v6 = (uint64_t **)std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::__find_equal<std::string>((uint64_t)a1, &v11, a2);
  uint64_t v7 = *v6;
  if (!*v6)
  {
    uint64_t v8 = v6;
    std::__tree<std::__value_type<std::string,ZinTiledCompressedIODescriptor>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinTiledCompressedIODescriptor>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinTiledCompressedIODescriptor>>>::__construct_node<std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>((uint64_t)a1, a4, (uint64_t)v10);
    std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::__insert_node_at(a1, v11, v8, v10[0]);
    uint64_t v7 = v10[0];
    v10[0] = 0;
    std::unique_ptr<std::__tree_node<std::__value_type<std::string,ZinTiledCompressedIODescriptor>,void *>,std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<std::string,ZinTiledCompressedIODescriptor>,void *>>>>::reset[abi:ne180100]((uint64_t)v10, 0);
  }
  return v7;
}

double std::__tree<std::__value_type<std::string,ZinTiledCompressedIODescriptor>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinTiledCompressedIODescriptor>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinTiledCompressedIODescriptor>>>::__construct_node<std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>@<D0>(uint64_t a1@<X0>, long long **a2@<X2>, uint64_t a3@<X8>)
{
  uint64_t v5 = a1 + 8;
  long long v6 = (char *)operator new(0x70uLL);
  *(void *)a3 = v6;
  *(void *)(a3 + 8) = v5;
  *(unsigned char *)(a3 + 16) = 0;
  uint64_t v7 = (std::string *)(v6 + 32);
  uint64_t v8 = *a2;
  if (*((char *)*a2 + 23) < 0)
  {
    std::string::__init_copy_ctor_external(v7, *(const std::string::value_type **)v8, *((void *)v8 + 1));
  }
  else
  {
    long long v9 = *v8;
    *((void *)v6 + 6) = *((void *)v8 + 2);
    *(_OWORD *)&v7->__r_.__value_.__l.__data_ = v9;
  }
  *((void *)v6 + 13) = 0;
  double result = 0.0;
  *(_OWORD *)(v6 + 88) = 0u;
  *(_OWORD *)(v6 + 72) = 0u;
  *(_OWORD *)(v6 + 56) = 0u;
  *(unsigned char *)(a3 + 16) = 1;
  return result;
}

void sub_21136BB28(_Unwind_Exception *a1)
{
  std::unique_ptr<std::__tree_node<std::__value_type<std::string,ZinTiledCompressedIODescriptor>,void *>,std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<std::string,ZinTiledCompressedIODescriptor>,void *>>>>::reset[abi:ne180100](v1, 0);
  _Unwind_Resume(a1);
}

void std::unique_ptr<std::__tree_node<std::__value_type<std::string,ZinTiledCompressedIODescriptor>,void *>,std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<std::string,ZinTiledCompressedIODescriptor>,void *>>>>::reset[abi:ne180100](uint64_t a1, uint64_t a2)
{
  uint64_t v2 = *(void **)a1;
  *(void *)a1 = a2;
  if (v2)
  {
    if (*(unsigned char *)(a1 + 16)) {
      std::__destroy_at[abi:ne180100]<std::pair<std::string const,ZinTiledCompressedIODescriptor>,0>((uint64_t)v2 + 32);
    }
    operator delete(v2);
  }
}

uint64_t *std::__tree<std::__value_type<std::string,ZinLiveInputParamDescriptor>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinLiveInputParamDescriptor>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinLiveInputParamDescriptor>>>::__emplace_unique_key_args<std::string,std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>(uint64_t **a1, void **a2, uint64_t a3, long long **a4)
{
  long long v6 = (uint64_t **)std::__tree<std::__value_type<std::string,ZinIrName>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinIrName>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinIrName>>>::__find_equal<std::string>((uint64_t)a1, &v11, a2);
  uint64_t v7 = *v6;
  if (!*v6)
  {
    uint64_t v8 = v6;
    std::__tree<std::__value_type<std::string,ZinLiveInputParamDescriptor>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinLiveInputParamDescriptor>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinLiveInputParamDescriptor>>>::__construct_node<std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>((uint64_t)a1, a4, (uint64_t)v10);
    std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::__insert_node_at(a1, v11, v8, v10[0]);
    uint64_t v7 = v10[0];
    v10[0] = 0;
    std::unique_ptr<std::__tree_node<std::__value_type<std::string,WeightFileProperties>,void *>,std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<std::string,WeightFileProperties>,void *>>>>::reset[abi:ne180100]((uint64_t)v10, 0);
  }
  return v7;
}

std::string *std::__tree<std::__value_type<std::string,ZinLiveInputParamDescriptor>,std::__map_value_compare<std::string,std::__value_type<std::string,ZinLiveInputParamDescriptor>,std::less<std::string>,true>,std::allocator<std::__value_type<std::string,ZinLiveInputParamDescriptor>>>::__construct_node<std::piecewise_construct_t const&,std::tuple<std::string const&>,std::tuple<>>@<X0>(uint64_t a1@<X0>, long long **a2@<X2>, uint64_t a3@<X8>)
{
  uint64_t v5 = a1 + 8;
  long long v6 = (char *)operator new(0x60uLL);
  *(void *)a3 = v6;
  *(void *)(a3 + 8) = v5;
  *(unsigned char *)(a3 + 16) = 0;
  double result = std::pair<std::string const,ZinLiveInputParamDescriptor>::pair[abi:ne180100]<std::string const&>((std::string *)(v6 + 32), *a2);
  *(unsigned char *)(a3 + 16) = 1;
  return result;
}

void sub_21136BC98(_Unwind_Exception *a1)
{
  std::unique_ptr<std::__tree_node<std::__value_type<std::string,WeightFileProperties>,void *>,std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<std::string,WeightFileProperties>,void *>>>>::reset[abi:ne180100](v1, 0);
  _Unwind_Resume(a1);
}

std::string *std::pair<std::string const,ZinLiveInputParamDescriptor>::pair[abi:ne180100]<std::string const&>(std::string *this, long long *a2)
{
  if (*((char *)a2 + 23) < 0)
  {
    std::string::__init_copy_ctor_external(this, *(const std::string::value_type **)a2, *((void *)a2 + 1));
  }
  else
  {
    long long v3 = *a2;
    this->__r_.__value_.__r.__words[2] = *((void *)a2 + 2);
    *(_OWORD *)&this->__r_.__value_.__l.__data_ = v3;
  }
  this[2].__r_.__value_.__l.__size_ = 0;
  *(_OWORD *)&this[1].__r_.__value_.__r.__words[2] = 0u;
  *(_OWORD *)&this[1].__r_.__value_.__l.__data_ = 0u;
  std::string::basic_string[abi:ne180100]<0>(&this[1].__r_.__value_.__l.__size_, &byte_211F4AA5D);
  this[2].__r_.__value_.__l.__size_ = 0;
  return this;
}

void sub_21136BD24(_Unwind_Exception *exception_object)
{
  if (*(char *)(v1 + 23) < 0) {
    operator delete(*(void **)v1);
  }
  _Unwind_Resume(exception_object);
}

void ZinIrBindings::IsIOCircular(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void ZinIrBindings::GetMultiPlaneUncompressedDescriptor(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void ZinIrBindings::GetMultiPlaneUncompressedDescriptor(uint8_t *buf, uint64_t a2, void *a3, void *a4)
{
  if (*(char *)(a2 + 55) < 0) {
    a3 = (void *)*a3;
  }
  *(_DWORD *)buf = 136315138;
  *a4 = a3;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "Unable to retrieve base dimension for 4cc IO %s", buf, 0xCu);
}

uint64_t ZinParseNeuronUnit(const __CFDictionary *a1, uint64_t a2, CFArrayRef *a3)
{
  CFDictionaryRef Value = (const __CFDictionary *)CFDictionaryGetValue(a1, @"Params");
  if (!Value || (CFDictionaryRef v6 = Value, v7 = CFGetTypeID(Value), v7 != CFDictionaryGetTypeID()))
  {
    CFStringRef v14 = @"InvalidParamSyntax";
LABEL_36:
    ZinIrUnitStatus::SetError(a3, v14);
    return 3;
  }
  uint64_t v8 = CFDictionaryGetValue(v6, @"Type");
  if (!v8 || (v9 = (BOOL)v8, CFTypeID v10 = CFGetTypeID(v8), v10 != CFStringGetTypeID()))
  {
    if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
      ZinParseNeuronUnit();
    }
    CFStringRef v14 = @"InvalidUnitNeuronType";
    goto LABEL_36;
  }
  uint64_t v11 = (int *)(a2 + 80);
  if (!CFStringToZinIrNeuronType(v9, (int *)(a2 + 80))) {
    return 3;
  }
  int v12 = *v11;
  if (*v11 == 3)
  {
    uint64_t result = ZinParseFP16Token(v6, @"ReluMin", @"InvalidReluMinValSyntax", (float *)(a2 + 92), a3, 0);
    if (result) {
      return result;
    }
    uint64_t result = ZinParseFP16Token(v6, @"ReluMax", @"InvalidReluMaxValSyntax", (float *)(a2 + 96), a3, 0);
    if (result) {
      return result;
    }
    if (*(float *)(a2 + 92) < *(float *)(a2 + 96))
    {
      int v12 = *v11;
      goto LABEL_11;
    }
    if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
      ZinParseNeuronUnit();
    }
    CFStringRef v14 = @"InvalidReluMinMaxVal";
    goto LABEL_36;
  }
LABEL_11:
  if (v12 == 2)
  {
    uint64_t result = ZinParseFP16Token(v6, @"ReluOffset", @"InvalidReluOffsetSyntax", (float *)(a2 + 84), a3, 0);
    if (result) {
      return result;
    }
    uint64_t result = ZinParseFP16Token(v6, @"ReluSlope", @"InvalidReluSlopeSyntax", (float *)(a2 + 88), a3, 0);
    if (result) {
      return result;
    }
    int v12 = *v11;
  }
  if (v12 == 4)
  {
    uint64_t result = ZinParseFP16Token(v6, @"ReluSlope", @"InvalidReluSlopeSyntax", (float *)(a2 + 88), a3, 0);
    if (result) {
      return result;
    }
    uint64_t result = ZinParseFP16Token(v6, @"ReluMax", @"InvalidReluMaxValSyntax", (float *)(a2 + 96), a3, 0);
    if (result) {
      return result;
    }
    int v12 = *v11;
  }
  if (v12 == 18
    && ZinParseFP16Token(v6, @"EluAlpha", @"InvalidEluAlpha", (float *)(a2 + 100), a3, 0))
  {
    if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_INFO))
    {
      *(_WORD *)uint64_t v15 = 0;
      _os_log_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_INFO, "Missing Elu alpha inferred to 1.0f\n", v15, 2u);
    }
    *(_DWORD *)(a2 + 10std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 1065353216;
  }
  if (*v11 == 31
    && ZinParseFP16Token(v6, @"Alpha", @"InvalidAlpha", (float *)(a2 + 104), a3, 0))
  {
    if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_INFO))
    {
      *(_WORD *)buf = 0;
      _os_log_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_INFO, "Missing alpha inferred to 1.0f\n", buf, 2u);
    }
    *(_DWORD *)(a2 + 104) = 1065353216;
  }
  if ((*v11 - 13) > 2) {
    return 0;
  }
  *(_DWORD *)(a2 + 108) = 0;
  uint64_t result = ZinParseFP16Token(v6, @"Epsilon", @"InvalidEpsilon", (float *)(a2 + 108), a3, 1);
  if (!result) {
    return 0;
  }
  return result;
}

void ZinParseNeuronUnit()
{
  *(_WORD *)uint64_t v0 = 0;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "Missing required type in neuron parameter dictionary.\n", v0, 2u);
}

{
  uint8_t v0[16];

  *(_WORD *)uint64_t v0 = 0;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "ReluMax should be larger than ReluMin.\n", v0, 2u);
}

long long *ZinIrHalH16c::GetParams(ZinIrHalH16c *this)
{
  uint64_t v131 = *MEMORY[0x263EF8340];
  {
    ZinIrHalH16c::GetParams(void)const::ZinIrHalH16cParameters = xmmword_211ED32D0;
    dword_26777FDF0 = 8;
    unk_26777FDF8 = xmmword_211ED25C0;
    unk_26777FE08 = xmmword_211ED32E0;
    unk_26777FE18 = xmmword_211ED32F0;
    unk_26777FE28 = xmmword_211ED2760;
    unk_26777FE38 = xmmword_211ED3300;
    unk_26777FE48 = xmmword_211ED32F0;
    unk_26777FE58 = xmmword_211ED2610;
    unk_26777FE68 = xmmword_211ED3310;
    unk_26777FE78 = xmmword_211ED3320;
    unk_26777FE88 = xmmword_211ED2640;
    unk_26777FE98 = vdupq_n_s64(4uLL);
    qword_26777FEA8 = 4;
    xmmword_26777FEB0 = xmmword_211F073E0;
    unk_26777FEC0 = unk_211F073F0;
    xmmword_26777FED0 = xmmword_211F073E0;
    unk_26777FEE0 = unk_211F073F0;
    qword_26777FF00 = 4;
    xmmword_26777FEF0 = xmmword_211F07400;
    xmmword_26777FF08 = xmmword_211ED2650;
    xmmword_26777FF18 = xmmword_211ED2670;
    xmmword_26777FF28 = xmmword_211ED2670;
    xmmword_26777FF38 = xmmword_211ED2670;
    xmmword_26777FF48 = xmmword_211ED2670;
    xmmword_26777FF58 = xmmword_211ED2670;
    xmmword_26777FF68 = xmmword_211ED2690;
    xmmword_26777FF78 = xmmword_211ED26A0;
    xmmword_26777FF88 = xmmword_211ED26B0;
    xmmword_26777FF98 = xmmword_211ED2780;
    xmmword_26777FFA8 = xmmword_211ED3330;
    xmmword_26777FFB8 = xmmword_211ED26E0;
    xmmword_26777FFC8 = xmmword_211ED26F0;
    xmmword_26777FFD8 = xmmword_211ED3340;
    xmmword_26777FFE8 = (__int128)vdupq_n_s64(0x40uLL);
    xmmword_26777FFF8 = xmmword_211ED3390;
    xmmword_267780008 = xmmword_211ED2720;
    xmmword_267780018 = xmmword_211ED2730;
    xmmword_267780028 = xmmword_211ED2740;
    xmmword_267780038 = xmmword_211ED3350;
    xmmword_267780048 = xmmword_211ED3360;
    qword_267780058 = 0;
    word_267780060 = 256;
    xmmword_267780068 = xmmword_211ED2760;
    xmmword_267780078 = xmmword_211ED2770;
    xmmword_267780088 = xmmword_211ED2780;
    qword_267780098 = 0x10000;
    byte_2677800A0 = 122;
    xmmword_2677800A8 = xmmword_211ED3370;
    dword_2677800B8 = 520097776;
    qword_2677800BC = 0xFFFFFFEB0000000BLL;
    xmmword_2677800C8 = xmmword_211ED27A0;
    xmmword_2677800D8 = xmmword_211ED27B0;
    xmmword_2677800E8 = xmmword_211ED27C0;
    int64x2_t v95 = vdupq_n_s64(8uLL);
    long long v96 = xmmword_211ED3380;
    long long v97 = xmmword_211ED3390;
    long long v98 = xmmword_211ED2730;
    std::vector<std::pair<unsigned long,unsigned long>>::vector[abi:ne180100](&qword_2677800F8, (uint64_t)&v95, 4uLL);
    xmmword_267780110 = xmmword_211ED33A0;
    unk_267780120 = xmmword_211ED27E0;
    xmmword_267780130 = (__int128)vdupq_n_s64(0x20uLL);
    unk_267780140 = xmmword_211ED2610;
    xmmword_267780150 = (__int128)vdupq_n_s64(8uLL);
    unk_267780160 = xmmword_211ED27F0;
    xmmword_267780170 = xmmword_211ED2800;
    unk_267780180 = vdupq_n_s64(0x100uLL);
    xmmword_267780190 = (__int128)vdupq_n_s64(0x80uLL);
    unk_2677801A0 = xmmword_211ED33B0;
    xmmword_2677801B0 = xmmword_211ED33C0;
    unk_2677801C0 = xmmword_211ED33D0;
    xmmword_2677801D0 = xmmword_211ED2840;
    unk_2677801E0 = xmmword_211ED2850;
    xmmword_2677801F0 = (__int128)vdupq_n_s64(2uLL);
    unk_267780200 = xmmword_211ED2670;
    xmmword_267780210 = (__int128)vdupq_n_s64(0x10000uLL);
    unk_267780220 = xmmword_211ED33E0;
    word_267780230 = 257;
    byte_267780236 = 0;
    dword_267780232 = 0;
    word_267780237 = 1;
    dword_267780249 = 16843009;
    qword_267780239 = 0x101010101010101;
    unk_267780241 = 0x101010101010101;
    word_26778024D = 0;
    byte_26778024F = 0;
    dword_267780250 = 16843009;
    word_267780254 = 1;
    qword_267780256 = 0x101010101010101;
    word_26778025E = 0;
    xmmword_267780260 = xmmword_211ED2760;
    unk_267780270 = xmmword_211ED2880;
    qword_267780288 = 0;
    unk_267780290 = 0;
    qword_267780280 = 40;
    word_267780298 = 1;
    *(int *)((char *)&dword_26778029A + 3) = 16843009;
    dword_26778029A = 16843009;
    qword_2677802A8 = 16;
    byte_2677802B0 = 0;
    dword_2677802B1 = 16843009;
    qword_2677802B5 = 0x1000000000000;
    dword_2677802BD = 16843009;
    word_2677802C1 = 2056;
    qword_2677802C3 = 0x101010101010101;
    byte_2677802CB = 1;
    qword_2677802CC = 0x1010100010000;
    dword_2677802D4 = 16777473;
    word_2677802D8 = 2056;
    xmmword_2677802E0 = xmmword_211ED33F0;
    qword_2677802F0 = 4;
    word_2677802F8 = 0;
    dword_2677802FC = 1;
    dword_267780300 = 0x10000;
    word_267780308 = 257;
    dword_267780304 = 16843009;
    byte_26778030A = 0;
    word_26778030F = 257;
    dword_26778030B = 16843009;
    qword_267780311 = 0x101000100000606;
    byte_267780319 = 1;
    std::string::basic_string[abi:ne180100]<0>(&qword_267780320, "Simple");
    qword_267780338 = 50331648;
    dword_267780340 = 1071225242;
    *(void *)algn_267780344 = 0x230000000ELL;
    *(_OWORD *)&algn_267780344[12] = xmmword_211ED2890;
    *(int64x2_t *)&algn_267780344[28] = vdupq_n_s64(0x40uLL);
    *(_OWORD *)&algn_267780344[44] = xmmword_211ED27D0;
    qword_267780380 = 8;
    byte_267780388 = 0;
    unk_26778038C = 0xF3E800000;
    byte_267780394 = 1;
    long long v129 = xmmword_211F07418;
    int v130 = 9;
    std::vector<ZinIrPaddingMode>::vector[abi:ne180100](&qword_267780398, &v129, 5uLL);
    v127[0] = xmmword_211F0742C;
    v127[1] = unk_211F0743C;
    v128[0] = xmmword_211F0744C;
    *(_OWORD *)((char *)v128 + 12) = *(long long *)((char *)&xmmword_211F0744C + 12);
    std::vector<ZinIrPoolingMode>::vector[abi:ne180100](&qword_2677803B0, v127, 0xFuLL);
    v125[4] = xmmword_211F074A8;
    v125[5] = unk_211F074B8;
    v126[0] = xmmword_211F074C8;
    *(_OWORD *)((char *)v126 + 12) = *(long long *)((char *)&xmmword_211F074C8 + 12);
    v125[0] = xmmword_211F07468;
    v125[1] = unk_211F07478;
    v125[2] = xmmword_211F07488;
    v125[3] = unk_211F07498;
    std::vector<ZinIrNeuronType>::vector[abi:ne180100](&qword_2677803C8, v125, 0x1FuLL);
    v123[7] = unk_211F07554;
    v123[8] = xmmword_211F07564;
    v124[0] = unk_211F07574;
    *(_OWORD *)((char *)v124 + 12) = unk_211F07580;
    v123[4] = xmmword_211F07524;
    v123[5] = unk_211F07534;
    v123[6] = xmmword_211F07544;
    v123[0] = xmmword_211F074E4;
    v123[1] = unk_211F074F4;
    v123[2] = xmmword_211F07504;
    v123[3] = unk_211F07514;
    std::vector<ZinIrNonLinearMode>::vector[abi:ne180100](&qword_2677803E0, v123, 0x2BuLL);
    int v91 = 2;
    long long v92 = xmmword_211ED28C0;
    uint64_t v93 = 0x1100000002;
    int v94 = 0;
    std::vector<ZinMirInterchangeInfo>::vector[abi:ne180100](&v30, &v91, 1uLL);
    v95.i32[0] = 641877825;
    long long v96 = 0uLL;
    v95.i64[1] = 0;
    std::vector<ZinMirInterchangeInfo>::__init_with_size[abi:ne180100]<ZinMirInterchangeInfo*,ZinMirInterchangeInfo*>(&v95.i64[1], v30, (uint64_t)v31, 0xCCCCCCCCCCCCCCCDLL * ((v31 - (unsigned char *)v30) >> 3));
    int v87 = 2;
    long long v88 = xmmword_211ED28C0;
    uint64_t v89 = 0x1100000002;
    int v90 = 1;
    std::vector<ZinMirInterchangeInfo>::vector[abi:ne180100](&v28, &v87, 1uLL);
    LODWORD(v97) = 759318337;
    long long v98 = 0uLL;
    *((void *)&v97 + 1) = 0;
    std::vector<ZinMirInterchangeInfo>::__init_with_size[abi:ne180100]<ZinMirInterchangeInfo*,ZinMirInterchangeInfo*>((void *)&v97 + 1, v28, (uint64_t)v29, 0xCCCCCCCCCCCCCCCDLL * ((v29 - (unsigned char *)v28) >> 3));
    int v83 = 2;
    long long v84 = xmmword_211ED28C0;
    uint64_t v85 = 0x1100000002;
    int v86 = 2;
    std::vector<ZinMirInterchangeInfo>::vector[abi:ne180100](&v26, &v83, 1uLL);
    int v99 = 792872769;
    memset(v100, 0, sizeof(v100));
    std::vector<ZinMirInterchangeInfo>::__init_with_size[abi:ne180100]<ZinMirInterchangeInfo*,ZinMirInterchangeInfo*>(v100, v26, (uint64_t)v27, 0xCCCCCCCCCCCCCCCDLL * ((v27 - (unsigned char *)v26) >> 3));
    int v79 = 2;
    long long v80 = xmmword_211ED28C0;
    uint64_t v81 = 0x1100000002;
    int v82 = 3;
    std::vector<ZinMirInterchangeInfo>::vector[abi:ne180100](&v24, &v79, 1uLL);
    int v101 = 2084718401;
    memset(v102, 0, sizeof(v102));
    std::vector<ZinMirInterchangeInfo>::__init_with_size[abi:ne180100]<ZinMirInterchangeInfo*,ZinMirInterchangeInfo*>(v102, v24, (uint64_t)v25, 0xCCCCCCCCCCCCCCCDLL * ((v25 - (unsigned char *)v24) >> 3));
    int v75 = 10;
    int64x2_t v76 = vdupq_n_s64(1uLL);
    uint64_t v77 = 0x800000001;
    int v78 = 0;
    std::vector<ZinMirInterchangeInfo>::vector[abi:ne180100](&v22, &v75, 1uLL);
    int v103 = 642527542;
    memset(v104, 0, sizeof(v104));
    std::vector<ZinMirInterchangeInfo>::__init_with_size[abi:ne180100]<ZinMirInterchangeInfo*,ZinMirInterchangeInfo*>(v104, v22, (uint64_t)v23, 0xCCCCCCCCCCCCCCCDLL * ((v23 - (unsigned char *)v22) >> 3));
    int v71 = 3;
    int64x2_t v72 = vdupq_n_s64(1uLL);
    uint64_t v73 = 0x700000002;
    int v74 = 0;
    std::vector<ZinMirInterchangeInfo>::vector[abi:ne180100](&v20, &v71, 1uLL);
    int v105 = 642527336;
    memset(v106, 0, sizeof(v106));
    std::vector<ZinMirInterchangeInfo>::__init_with_size[abi:ne180100]<ZinMirInterchangeInfo*,ZinMirInterchangeInfo*>(v106, v20, (uint64_t)v21, 0xCCCCCCCCCCCCCCCDLL * ((v21 - (unsigned char *)v20) >> 3));
    int v67 = 3;
    int64x2_t v68 = vdupq_n_s64(1uLL);
    uint64_t v69 = 0x700000002;
    int v70 = 1;
    std::vector<ZinMirInterchangeInfo>::vector[abi:ne180100](&v18, &v67, 1uLL);
    int v107 = 759967848;
    memset(v108, 0, sizeof(v108));
    std::vector<ZinMirInterchangeInfo>::__init_with_size[abi:ne180100]<ZinMirInterchangeInfo*,ZinMirInterchangeInfo*>(v108, v18, (uint64_t)v19, 0xCCCCCCCCCCCCCCCDLL * ((v19 - (unsigned char *)v18) >> 3));
    int v63 = 3;
    int64x2_t v64 = vdupq_n_s64(1uLL);
    uint64_t v65 = 0x700000002;
    int v66 = 2;
    std::vector<ZinMirInterchangeInfo>::vector[abi:ne180100](&v16, &v63, 1uLL);
    int v109 = 793522280;
    memset(v110, 0, sizeof(v110));
    std::vector<ZinMirInterchangeInfo>::__init_with_size[abi:ne180100]<ZinMirInterchangeInfo*,ZinMirInterchangeInfo*>(v110, v16, (uint64_t)v17, 0xCCCCCCCCCCCCCCCDLL * ((v17 - (unsigned char *)v16) >> 3));
    int v59 = 3;
    int64x2_t v60 = vdupq_n_s64(1uLL);
    uint64_t v61 = 0x700000002;
    int v62 = 3;
    std::vector<ZinMirInterchangeInfo>::vector[abi:ne180100](&v14, &v59, 1uLL);
    int v111 = 2085367912;
    memset(v112, 0, sizeof(v112));
    std::vector<ZinMirInterchangeInfo>::__init_with_size[abi:ne180100]<ZinMirInterchangeInfo*,ZinMirInterchangeInfo*>(v112, v14, (uint64_t)v15, 0xCCCCCCCCCCCCCCCDLL * ((v15 - (unsigned char *)v14) >> 3));
    int v55 = 3;
    long long v56 = xmmword_211ED28C0;
    uint64_t v57 = 0x1300000002;
    int v58 = 0;
    std::vector<ZinMirInterchangeInfo>::vector[abi:ne180100](&v12, &v55, 1uLL);
    int v113 = 642934849;
    memset(v114, 0, sizeof(v114));
    std::vector<ZinMirInterchangeInfo>::__init_with_size[abi:ne180100]<ZinMirInterchangeInfo*,ZinMirInterchangeInfo*>(v114, v12, (uint64_t)v13, 0xCCCCCCCCCCCCCCCDLL * ((v13 - (unsigned char *)v12) >> 3));
    int v51 = 3;
    long long v52 = xmmword_211ED28C0;
    uint64_t v53 = 0x1300000002;
    int v54 = 1;
    std::vector<ZinMirInterchangeInfo>::vector[abi:ne180100](&v10, &v51, 1uLL);
    int v115 = 760375361;
    memset(v116, 0, sizeof(v116));
    std::vector<ZinMirInterchangeInfo>::__init_with_size[abi:ne180100]<ZinMirInterchangeInfo*,ZinMirInterchangeInfo*>(v116, v10, (uint64_t)v11, 0xCCCCCCCCCCCCCCCDLL * ((v11 - (unsigned char *)v10) >> 3));
    int v47 = 3;
    long long v48 = xmmword_211ED28C0;
    uint64_t v49 = 0x1300000002;
    int v50 = 2;
    std::vector<ZinMirInterchangeInfo>::vector[abi:ne180100](&v8, &v47, 1uLL);
    int v117 = 793929793;
    memset(v118, 0, sizeof(v118));
    std::vector<ZinMirInterchangeInfo>::__init_with_size[abi:ne180100]<ZinMirInterchangeInfo*,ZinMirInterchangeInfo*>(v118, v8, (uint64_t)v9, 0xCCCCCCCCCCCCCCCDLL * ((v9 - (unsigned char *)v8) >> 3));
    int v43 = 3;
    long long v44 = xmmword_211ED28C0;
    uint64_t v45 = 0x1300000002;
    int v46 = 3;
    std::vector<ZinMirInterchangeInfo>::vector[abi:ne180100](&v6, &v43, 1uLL);
    int v119 = 2085775425;
    memset(v120, 0, sizeof(v120));
    std::vector<ZinMirInterchangeInfo>::__init_with_size[abi:ne180100]<ZinMirInterchangeInfo*,ZinMirInterchangeInfo*>(v120, v6, (uint64_t)v7, 0xCCCCCCCCCCCCCCCDLL * ((v7 - (unsigned char *)v6) >> 3));
    int v39 = 3;
    int64x2_t v40 = vdupq_n_s64(1uLL);
    uint64_t v41 = 0x700000002;
    int v42 = 0;
    std::vector<ZinMirInterchangeInfo>::vector[abi:ne180100](&__p, &v39, 1uLL);
    int v121 = 707153000;
    memset(v122, 0, sizeof(v122));
    std::vector<ZinMirInterchangeInfo>::__init_with_size[abi:ne180100]<ZinMirInterchangeInfo*,ZinMirInterchangeInfo*>(v122, __p, (uint64_t)v5, 0xCCCCCCCCCCCCCCCDLL * ((v5 - (unsigned char *)__p) >> 3));
    std::map<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>::map[abi:ne180100]((uint64_t)&unk_2677803F8, (unsigned int *)&v95, 14);
    dword_267780410 = 65793;
    word_267780414 = 256;
    byte_267780416 = 0;
    qword_267780418 = 0;
    dword_267780420 = 0;
    unk_267780428 = 0u;
    unk_267780438 = 0u;
    word_267780448 = 257;
    qword_267780470 = 8;
    xmmword_267780450 = xmmword_211F07590;
    unk_267780460 = unk_211F075A0;
    unk_267780478 = xmmword_211ED3400;
    v37[10] = xmmword_211F07658;
    v37[11] = unk_211F07668;
    uint64_t v38 = 0x41E19CF8E0000000;
    v37[6] = xmmword_211F07618;
    v37[7] = unk_211F07628;
    v37[8] = xmmword_211F07638;
    v37[9] = unk_211F07648;
    v37[2] = xmmword_211F075D8;
    v37[3] = unk_211F075E8;
    v37[4] = xmmword_211F075F8;
    void v37[5] = unk_211F07608;
    v37[0] = xmmword_211F075B8;
    v37[1] = unk_211F075C8;
    std::vector<double>::vector[abi:ne180100](&qword_267780488, v37, 0x19uLL);
    v36[0] = xmmword_211F07680;
    v36[1] = unk_211F07690;
    std::vector<double>::vector[abi:ne180100](&qword_2677804A0, v36, 4uLL);
    v35[0] = xmmword_211F076A0;
    v35[1] = unk_211F076B0;
    v35[2] = xmmword_211F076C0;
    std::vector<double>::vector[abi:ne180100](&qword_2677804B8, v35, 6uLL);
    memcpy(__dst, &unk_211F076D0, sizeof(__dst));
    std::map<double,double>::map[abi:ne180100]((uint64_t)&unk_2677804D0, __dst, 25);
    xmmword_2677804E8 = xmmword_211ED28E0;
    v32[0] = xmmword_211F07860;
    v32[1] = unk_211F07870;
    v32[2] = xmmword_211F07880;
    int v33 = 27;
    std::vector<ZinKernelFormat>::vector[abi:ne180100](qword_2677804F8, v32, 0xDuLL);
    xmmword_267780510 = xmmword_211ED3410;
    unk_267780520 = xmmword_211ED28F0;
    qword_267780530 = 64;
    unk_267780538 = 0x101010101010101;
    unk_26778053E = 0x101010101010101;
    unk_2677805C8 = 0u;
    *(_OWORD *)&qword_2677805D8 = 0u;
    unk_267780548 = 0u;
    unk_267780558 = 0u;
    unk_267780568 = 0u;
    unk_267780578 = 0u;
    unk_267780588 = 0u;
    unk_267780598 = 0u;
    unk_2677805A8 = 0u;
    unk_2677805B8 = 0u;
    byte_2677805D2 = 1;
    qword_2677805D8 = 65504;
    byte_2677805E0 = 1;
    dword_2677805E8 = 0;
    word_2677805EC = 257;
    dword_2677805F0 = 0;
    word_2677805F4 = 256;
    unk_2677805F8 = vdupq_n_s64(0x10uLL);
    byte_267780608 = 1;
    qword_267780610 = 0xFFFFLL;
    byte_267780618 = 0;
    qword_267780620 = 3;
    word_267780628 = 257;
    byte_26778062A = 1;
    uint64_t v2 = 448;
    qword_267780630 = 0x80000000;
    do
    {
      long long v3 = *(void **)((char *)&v92 + v2 + 8);
      if (v3)
      {
        *(uint64_t *)((char *)&v93 + v2) = (uint64_t)v3;
        operator delete(v3);
      }
      v2 -= 32;
    }
    while (v2);
    if (__p)
    {
      uint64_t v5 = __p;
      operator delete(__p);
    }
    if (v6)
    {
      CFTypeID v7 = v6;
      operator delete(v6);
    }
    if (v8)
    {
      BOOL v9 = v8;
      operator delete(v8);
    }
    if (v10)
    {
      uint64_t v11 = v10;
      operator delete(v10);
    }
    if (v12)
    {
      uint64_t v13 = v12;
      operator delete(v12);
    }
    if (v14)
    {
      uint64_t v15 = v14;
      operator delete(v14);
    }
    if (v16)
    {
      uint64_t v17 = v16;
      operator delete(v16);
    }
    if (v18)
    {
      char v19 = v18;
      operator delete(v18);
    }
    if (v20)
    {
      unint64_t v21 = v20;
      operator delete(v20);
    }
    if (v22)
    {
      int64x2_t v23 = v22;
      operator delete(v22);
    }
    if (v24)
    {
      uint64_t v25 = v24;
      operator delete(v24);
    }
    if (v26)
    {
      uint64_t v27 = v26;
      operator delete(v26);
    }
    if (v28)
    {
      uint64_t v29 = v28;
      operator delete(v28);
    }
    if (v30)
    {
      std::string v31 = v30;
      operator delete(v30);
    }
    __cxa_atexit((void (*)(void *))ZinIrHalParameters::~ZinIrHalParameters, &ZinIrHalH16c::GetParams(void)const::ZinIrHalH16cParameters, &dword_210C72000);
  }
  return &ZinIrHalH16c::GetParams(void)const::ZinIrHalH16cParameters;
}

void sub_21136D2A4(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, void *__p, uint64_t a18, uint64_t a19, void *a20,uint64_t a21,uint64_t a22,void *a23,uint64_t a24,uint64_t a25,void *a26,uint64_t a27,uint64_t a28,void *a29,uint64_t a30,uint64_t a31,void *a32)
{
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy(v33, *(void **)(v33 + 8));
  if (qword_2677804B8)
  {
    qword_2677804C0 = qword_2677804B8;
    operator delete((void *)qword_2677804B8);
  }
  if (qword_2677804A0)
  {
    qword_2677804A8 = qword_2677804A0;
    operator delete((void *)qword_2677804A0);
  }
  if (qword_267780488)
  {
    qword_267780490 = qword_267780488;
    operator delete((void *)qword_267780488);
  }
  std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::destroy(v32, *(void **)(v32 + 8));
  uint64_t v36 = 448;
  while (1)
  {
    int64x2_t v37 = *(void **)((char *)&STACK[0x6B0] + v36 - 24);
    if (v37)
    {
      *(unint64_t *)((char *)&STACK[0x6B0] + v36 - 16) = (unint64_t)v37;
      operator delete(v37);
    }
    v36 -= 32;
    if (!v36)
    {
      if (__p) {
        operator delete(__p);
      }
      if (a20) {
        operator delete(a20);
      }
      if (a23) {
        operator delete(a23);
      }
      if (a26) {
        operator delete(a26);
      }
      if (a29) {
        operator delete(a29);
      }
      if (a32)
      {
        v34[1] = a32;
        operator delete(a32);
      }
      uint64_t v38 = (void *)v34[3];
      if (v38)
      {
        v34[4] = v38;
        operator delete(v38);
      }
      int v39 = (void *)v34[6];
      if (v39)
      {
        v34[7] = v39;
        operator delete(v39);
      }
      int64x2_t v40 = (void *)v34[9];
      if (v40)
      {
        v34[10] = v40;
        operator delete(v40);
      }
      uint64_t v41 = (void *)v34[12];
      if (v41)
      {
        v34[13] = v41;
        operator delete(v41);
      }
      int v42 = (void *)v34[15];
      if (v42)
      {
        v34[16] = v42;
        operator delete(v42);
      }
      int v43 = (void *)v34[18];
      if (v43)
      {
        v34[19] = v43;
        operator delete(v43);
      }
      long long v44 = (void *)v34[21];
      if (v44)
      {
        v34[22] = v44;
        operator delete(v44);
      }
      uint64_t v45 = (void *)v34[24];
      if (v45)
      {
        v34[25] = v45;
        operator delete(v45);
      }
      if (qword_2677803E0)
      {
        qword_2677803E8 = qword_2677803E0;
        operator delete((void *)qword_2677803E0);
      }
      if (qword_2677803C8)
      {
        qword_2677803D0 = qword_2677803C8;
        operator delete((void *)qword_2677803C8);
      }
      if (qword_2677803B0)
      {
        qword_2677803B8 = qword_2677803B0;
        operator delete((void *)qword_2677803B0);
      }
      if (qword_267780398)
      {
        qword_2677803A0 = qword_267780398;
        operator delete((void *)qword_267780398);
      }
      if (byte_267780337 < 0) {
        operator delete((void *)qword_267780320);
      }
      if (qword_2677800F8)
      {
        qword_267780100 = qword_2677800F8;
        operator delete((void *)qword_2677800F8);
      }
      _Unwind_Resume(a1);
    }
  }
}

void sub_21136D574()
{
}

void sub_21136D584()
{
}

void sub_21136D594()
{
}

void sub_21136D5A4()
{
}

void sub_21136D5B4()
{
}

void sub_21136D5C4()
{
}

void sub_21136D5D4()
{
}

void sub_21136D5E4()
{
}

void sub_21136D5FC()
{
}

void sub_21136D604()
{
}

void sub_21136D60C()
{
}

void sub_21136D614()
{
}

void sub_21136D61C()
{
}

void sub_21136D624()
{
}

void sub_21136D62C()
{
}

uint64_t ZinIrVector::ZinIrVector(uint64_t a1, uint64_t *a2, uint64_t a3, int a4, uint64_t a5, char a6, char a7)
{
  int v12 = (std::__shared_weak_count *)a2[1];
  uint64_t v18 = *a2;
  char v19 = v12;
  if (v12) {
    atomic_fetch_add_explicit(&v12->__shared_owners_, 1uLL, memory_order_relaxed);
  }
  uint64_t v15 = a3;
  int64x2_t v16 = vdupq_n_s64(1uLL);
  int64x2_t v17 = v16;
  ZinIrWeightBase::ZinIrWeightBase(a1, &v18, a4, (int64x2_t *)&v15, a5, 1262703187, a7);
  if (v19) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v19);
  }
  *(void *)a1 = &unk_26C343C60;
  *(unsigned char *)(a1 + 28std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = a6;
  *(_DWORD *)(a1 + 284) = 0;
  *(unsigned char *)(a1 + 288) = 0;
  if (a3 == 1 && (a7 & 1) == 0)
  {
    ZinIrVector::GetValueAsFloat(a1, a5);
    *(_DWORD *)(a1 + 284) = v13;
    *(unsigned char *)(a1 + 288) = 1;
  }
  return a1;
}

void sub_21136D728(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16)
{
  ZinIrWeightBase::~ZinIrWeightBase(v16);
  _Unwind_Resume(a1);
}

uint64_t ZinIrVector::GetValueAsFloat(uint64_t this, uint64_t a2)
{
  switch(*(_DWORD *)(this + 8))
  {
    case 0:
    case 3:
    case 7:
    case 8:
    case 9:
    case 0xA:
    case 0xB:
    case 0xC:
    case 0xD:
    case 0xE:
    case 0xF:
    case 0x10:
    case 0x11:
    case 0x12:
    case 0x13:
    case 0x14:
    case 0x15:
    case 0x16:
    case 0x17:
    case 0x18:
    case 0x19:
    case 0x1A:
    case 0x1B:
    case 0x1C:
    case 0x1D:
    case 0x1E:
    case 0x1F:
    case 0x20:
      ZinAssertImpl("Unsupported kernel format in GetValueAsFloat.");
    case 1:
      this = ZinIrVector::GetAt<signed char>(this, a2);
      break;
    case 2:
      this = ZinIrVector::GetAt<unsigned char>(this, a2);
      break;
    case 4:
      this = ZinIrVector::GetAt<half>(this, a2);
      __asm { FCVT            S0, H0 }
      break;
    case 5:
      this = ZinIrVector::GetAt<e4m3_t>(this, a2);
      break;
    case 6:
      this = ZinIrVector::GetAt<float>(this, a2);
      break;
    default:
      return this;
  }
  return this;
}

uint64_t ZinIrVector::GetAt<half>(uint64_t result, uint64_t a2)
{
  if (*(unsigned char *)(result + 288))
  {
    _S0 = *(_DWORD *)(result + 284);
    __asm { FCVT            H0, S0 }
  }
  else
  {
    uint64_t v7 = *(void *)(result + 136);
    if (!v7) {
      ZinAssertImpl("Const data is null for GetAt call");
    }
    uint64_t v8 = *(void *)(result + 16) + a2;
    BOOL v9 = *(uint64_t (**)(uint64_t, uint64_t))(*(void *)v7 + 56);
    uint64_t v10 = *(void *)(result + 136);
    return v9(v10, v8);
  }
  return result;
}

uint64_t ZinIrVector::GetAt<float>(uint64_t result, uint64_t a2)
{
  if (!*(unsigned char *)(result + 288))
  {
    uint64_t v2 = *(void *)(result + 136);
    if (!v2) {
      ZinAssertImpl("Const data is null for GetAt call");
    }
    uint64_t v3 = *(void *)(result + 16) + a2;
    int64x2_t v4 = *(uint64_t (**)(uint64_t, uint64_t))(*(void *)v2 + 40);
    uint64_t v5 = *(void *)(result + 136);
    return v4(v5, v3);
  }
  return result;
}

uint64_t ZinIrVector::GetAt<e4m3_t>(uint64_t a1, uint64_t a2)
{
  if (*(unsigned char *)(a1 + 288))
  {
    float v2 = *(float *)(a1 + 284);
    return ZinF32ToE4M3(v2, 1, 0);
  }
  else
  {
    uint64_t v4 = *(void *)(a1 + 136);
    if (!v4) {
      ZinAssertImpl("Const data is null for GetAt call");
    }
    uint64_t v5 = *(void *)(a1 + 16) + a2;
    CFDictionaryRef v6 = *(uint64_t (**)(uint64_t, uint64_t))(*(void *)v4 + 88);
    uint64_t v7 = *(void *)(a1 + 136);
    return v6(v7, v5);
  }
}

uint64_t ZinIrVector::GetAt<signed char>(uint64_t a1, uint64_t a2)
{
  if (*(unsigned char *)(a1 + 288)) {
    return (int)*(float *)(a1 + 284);
  }
  uint64_t v3 = *(void *)(a1 + 136);
  if (!v3) {
    ZinAssertImpl("Const data is null for GetAt call");
  }
  uint64_t v4 = *(void *)(a1 + 16) + a2;
  uint64_t v5 = *(uint64_t (**)(uint64_t, uint64_t))(*(void *)v3 + 72);
  uint64_t v6 = *(void *)(a1 + 136);

  return v5(v6, v4);
}

uint64_t ZinIrVector::GetAt<unsigned char>(uint64_t a1, uint64_t a2)
{
  if (*(unsigned char *)(a1 + 288)) {
    return (int)*(float *)(a1 + 284);
  }
  uint64_t v3 = *(void *)(a1 + 136);
  if (!v3) {
    ZinAssertImpl("Const data is null for GetAt call");
  }
  uint64_t v4 = *(void *)(a1 + 16) + a2;
  uint64_t v5 = *(uint64_t (**)(uint64_t, uint64_t))(*(void *)v3 + 120);
  uint64_t v6 = *(void *)(a1 + 136);

  return v5(v6, v4);
}

uint64_t ZinIrVector::GetValueAsInt32(ZinIrVector *this, uint64_t a2)
{
  int v2 = *((_DWORD *)this + 2);
  if (v2 == 1) {
    return ZinIrVector::GetAt<signed char>((uint64_t)this, a2);
  }
  if (v2 == 2) {
    return ZinIrVector::GetAt<unsigned char>((uint64_t)this, a2);
  }
  return 0;
}

void ZinIrVector::StdvectorToVector<float>(uint64_t a1)
{
  std::allocate_shared[abi:ne180100]<ZinIrConstData_specialization<float>,std::allocator<ZinIrConstData_specialization<float>>,std::vector<float>,void>(a1, &v1);
  operator new();
}

void sub_21136DBF4(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, std::__shared_weak_count *a10)
{
  if (v11) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v11);
  }
  MEMORY[0x21667D3C0](v10, 0x10B3C400A1ACBE3);
  if (a10) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a10);
  }
  _Unwind_Resume(a1);
}

void ZinIrVector::StdvectorToVector<signed char>(uint64_t a1)
{
  std::allocate_shared[abi:ne180100]<ZinIrConstData_specialization<signed char>,std::allocator<ZinIrConstData_specialization<signed char>>,std::vector<signed char>,void>(a1, &v1);
  operator new();
}

void sub_21136DCFC(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, std::__shared_weak_count *a10)
{
  if (v11) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v11);
  }
  MEMORY[0x21667D3C0](v10, 0x10B3C400A1ACBE3);
  if (a10) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a10);
  }
  _Unwind_Resume(a1);
}

void ZinIrVector::StdvectorToVector<unsigned char>(uint64_t a1)
{
  std::allocate_shared[abi:ne180100]<ZinIrConstData_specialization<unsigned char>,std::allocator<ZinIrConstData_specialization<unsigned char>>,std::vector<unsigned char>,void>(a1, &v1);
  operator new();
}

void sub_21136DE04(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, std::__shared_weak_count *a10)
{
  if (v11) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v11);
  }
  MEMORY[0x21667D3C0](v10, 0x10B3C400A1ACBE3);
  if (a10) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a10);
  }
  _Unwind_Resume(a1);
}

void ZinIrVector::GetValuesAsVector<float>(uint64_t a1@<X0>, unint64_t a2@<X1>, int a3@<W2>, uint64_t a4@<X8>)
{
  *(void *)a4 = 0;
  *(void *)(a4 + 8) = 0;
  *(void *)(a4 + 16) = 0;
  std::vector<float>::reserve((void **)a4, a2);
  float v8 = 1.0;
  if (a3) {
    float v8 = ldexpf(1.0, *(char *)(a1 + 280));
  }
  if (a2)
  {
    uint64_t v9 = 0;
    do
    {
      ZinIrVector::GetValueAsFloat(a1, v9);
      float v11 = v8 * v10;
      int v13 = *(float **)(a4 + 8);
      unint64_t v12 = *(void *)(a4 + 16);
      if ((unint64_t)v13 >= v12)
      {
        uint64_t v15 = *(float **)a4;
        uint64_t v16 = ((uint64_t)v13 - *(void *)a4) >> 2;
        unint64_t v17 = v16 + 1;
        if ((unint64_t)(v16 + 1) >> 62) {
          std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
        }
        uint64_t v18 = v12 - (void)v15;
        if (v18 >> 1 > v17) {
          unint64_t v17 = v18 >> 1;
        }
        if ((unint64_t)v18 >= 0x7FFFFFFFFFFFFFFCLL) {
          unint64_t v19 = 0x3FFFFFFFFFFFFFFFLL;
        }
        else {
          unint64_t v19 = v17;
        }
        if (v19)
        {
          char v20 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ZinIrPaddingMode>>(a4 + 16, v19);
          uint64_t v15 = *(float **)a4;
          int v13 = *(float **)(a4 + 8);
        }
        else
        {
          char v20 = 0;
        }
        unint64_t v21 = (float *)&v20[4 * v16];
        float *v21 = v11;
        CFStringRef v14 = v21 + 1;
        while (v13 != v15)
        {
          int v22 = *((_DWORD *)v13-- - 1);
          *((_DWORD *)v21-- - 1) = v22;
        }
        *(void *)a4 = v21;
        *(void *)(a4 + 8) = v14;
        *(void *)(a4 + 16) = &v20[4 * v19];
        if (v15) {
          operator delete(v15);
        }
      }
      else
      {
        *int v13 = v11;
        CFStringRef v14 = v13 + 1;
      }
      *(void *)(a4 + 8) = v14;
      ++v9;
    }
    while (v9 != a2);
  }
}

void sub_21136DF94(_Unwind_Exception *exception_object)
{
  uint64_t v3 = *(void **)v1;
  if (*(void *)v1)
  {
    *(void *)(v1 + 8) = v3;
    operator delete(v3);
  }
  _Unwind_Resume(exception_object);
}

void ZinIrVector::GetValuesAsVector<signed char>(uint64_t a1@<X0>, size_t a2@<X1>, unint64_t *a3@<X8>)
{
  *a3 = 0;
  a3[1] = 0;
  a3[2] = 0;
  std::vector<unsigned char>::reserve(a3, a2);
  if (a2)
  {
    uint64_t v6 = 0;
    do
    {
      char v7 = ZinIrVector::GetAt<signed char>(a1, v6);
      char v8 = v7;
      float v10 = (unsigned char *)a3[1];
      unint64_t v9 = a3[2];
      if ((unint64_t)v10 >= v9)
      {
        unint64_t v12 = *a3;
        int v13 = &v10[-*a3];
        unint64_t v14 = (unint64_t)(v13 + 1);
        if ((uint64_t)(v13 + 1) < 0) {
          std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
        }
        unint64_t v15 = v9 - v12;
        if (2 * v15 > v14) {
          unint64_t v14 = 2 * v15;
        }
        if (v15 >= 0x3FFFFFFFFFFFFFFFLL) {
          size_t v16 = 0x7FFFFFFFFFFFFFFFLL;
        }
        else {
          size_t v16 = v14;
        }
        if (v16) {
          unint64_t v17 = (char *)operator new(v16);
        }
        else {
          unint64_t v17 = 0;
        }
        uint64_t v18 = &v13[(void)v17];
        unint64_t v19 = &v13[(void)v17];
        *unint64_t v19 = v8;
        float v11 = v19 + 1;
        if (v10 != (unsigned char *)v12)
        {
          char v20 = &v10[~v12];
          do
          {
            char v21 = *--v10;
            (v20--)[(void)v17] = v21;
          }
          while (v10 != (unsigned char *)v12);
          float v10 = (unsigned char *)*a3;
          uint64_t v18 = v17;
        }
        *a3 = (unint64_t)v18;
        a3[1] = (unint64_t)v11;
        a3[2] = (unint64_t)&v17[v16];
        if (v10) {
          operator delete(v10);
        }
      }
      else
      {
        *float v10 = v7;
        float v11 = v10 + 1;
      }
      a3[1] = (unint64_t)v11;
      ++v6;
    }
    while (v6 != a2);
  }
}

void sub_21136E0F0(_Unwind_Exception *exception_object)
{
  uint64_t v3 = *(void **)v1;
  if (*(void *)v1)
  {
    *(void *)(v1 + 8) = v3;
    operator delete(v3);
  }
  _Unwind_Resume(exception_object);
}

void ZinIrVector::GetValuesAsVector<unsigned char>(uint64_t a1@<X0>, size_t a2@<X1>, unint64_t *a3@<X8>)
{
  *a3 = 0;
  a3[1] = 0;
  a3[2] = 0;
  std::vector<unsigned char>::reserve(a3, a2);
  if (a2)
  {
    uint64_t v6 = 0;
    do
    {
      char v7 = ZinIrVector::GetAt<unsigned char>(a1, v6);
      char v8 = v7;
      float v10 = (unsigned char *)a3[1];
      unint64_t v9 = a3[2];
      if ((unint64_t)v10 >= v9)
      {
        unint64_t v12 = *a3;
        int v13 = &v10[-*a3];
        unint64_t v14 = (unint64_t)(v13 + 1);
        if ((uint64_t)(v13 + 1) < 0) {
          std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
        }
        unint64_t v15 = v9 - v12;
        if (2 * v15 > v14) {
          unint64_t v14 = 2 * v15;
        }
        if (v15 >= 0x3FFFFFFFFFFFFFFFLL) {
          size_t v16 = 0x7FFFFFFFFFFFFFFFLL;
        }
        else {
          size_t v16 = v14;
        }
        if (v16) {
          unint64_t v17 = (char *)operator new(v16);
        }
        else {
          unint64_t v17 = 0;
        }
        uint64_t v18 = &v13[(void)v17];
        unint64_t v19 = &v13[(void)v17];
        *unint64_t v19 = v8;
        float v11 = v19 + 1;
        if (v10 != (unsigned char *)v12)
        {
          char v20 = &v10[~v12];
          do
          {
            char v21 = *--v10;
            (v20--)[(void)v17] = v21;
          }
          while (v10 != (unsigned char *)v12);
          float v10 = (unsigned char *)*a3;
          uint64_t v18 = v17;
        }
        *a3 = (unint64_t)v18;
        a3[1] = (unint64_t)v11;
        a3[2] = (unint64_t)&v17[v16];
        if (v10) {
          operator delete(v10);
        }
      }
      else
      {
        *float v10 = v7;
        float v11 = v10 + 1;
      }
      a3[1] = (unint64_t)v11;
      ++v6;
    }
    while (v6 != a2);
  }
}

void sub_21136E24C(_Unwind_Exception *exception_object)
{
  uint64_t v3 = *(void **)v1;
  if (*(void *)v1)
  {
    *(void *)(v1 + 8) = v3;
    operator delete(v3);
  }
  _Unwind_Resume(exception_object);
}

void ZinIrTransformRemap::ZinIrTransformRemap(ZinIrTransformRemap *this, const ZinTensorDimensions *a2)
{
  *(void *)this = &unk_26C34CF70;
  *((void *)this + 1) = &unk_26C34CFB0;
  long long v2 = *(_OWORD *)a2;
  long long v3 = *((_OWORD *)a2 + 1);
  *((void *)this + 6) = *((void *)a2 + 4);
  *((_OWORD *)this + 1) = v2;
  *((_OWORD *)this + 2) = v3;
}

uint64_t ZinIrTransformRemap::Apply(uint64_t a1, uint64_t a2)
{
  switch(*(_DWORD *)(a2 + 8))
  {
    case 1:
      ZinIrWeightBase::RemapData<std::vector<signed char>,ZinIrConstData_specialization<signed char>>(a2, (void *)(a1 + 16), &v11);
      break;
    case 2:
      ZinIrWeightBase::RemapData<std::vector<unsigned char>,ZinIrConstData_specialization<unsigned char>>(a2, (void *)(a1 + 16), &v11);
      break;
    case 4:
      ZinIrWeightBase::RemapData<std::vector<half>,ZinIrConstData_specialization<half>>(a2, (void *)(a1 + 16), &v11);
      break;
    case 6:
      ZinIrWeightBase::RemapData<std::vector<float>,ZinIrConstData_specialization<float>>(a2, (void *)(a1 + 16), &v11);
      break;
    default:
      BOOL v2 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v2) {
        ZinIrTransformRemap::Apply(v2, v3, v4, v5, v6, v7, v8, v9);
      }
      return 3;
  }
  operator new();
}

void sub_21136E448(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, std::__shared_weak_count *a10)
{
  if (v11) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v11);
  }
  MEMORY[0x21667D3C0](v10, 0x10B3C400A1ACBE3);
  if (a10) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a10);
  }
  _Unwind_Resume(a1);
}

uint64_t ZinIrTransformRemap::Serialize(ZinIrTransformRemap *this, ZinIrSerializer *a2)
{
  uint64_t v4 = ZinIrSerializer::WriteUint8(a2, 2);
  uint64_t v5 = ZinIrSerializer::WriteUint64(a2, *((void *)this + 2)) + v4;
  uint64_t v6 = ZinIrSerializer::WriteUint64(a2, *((void *)this + 3));
  uint64_t v7 = v5 + v6 + ZinIrSerializer::WriteUint64(a2, *((void *)this + 4));
  return v7 + ZinIrSerializer::WriteUint64(a2, *((void *)this + 5));
}

uint64_t non-virtual thunk to'ZinIrTransformRemap::Serialize(ZinIrTransformRemap *this, ZinIrSerializer *a2)
{
  return ZinIrTransformRemap::Serialize((ZinIrTransformRemap *)((char *)this - 8), a2);
}

uint64_t ZinIrTransformRemap::DebugPrint@<X0>(void *a1@<X8>)
{
  std::basic_stringstream<char,std::char_traits<char>,std::allocator<char>>::basic_stringstream[abi:ne180100]((uint64_t)v5);
  std::stringbuf::str[abi:ne180100]<std::allocator<char>>((uint64_t)v6, a1);
  v5[0] = *MEMORY[0x263F8C2B8];
  uint64_t v3 = *(void *)(MEMORY[0x263F8C2B8] + 72);
  *(void *)((char *)v5 + *(void *)(v5[0] - 24)) = *(void *)(MEMORY[0x263F8C2B8] + 64);
  v5[2] = v3;
  v6[0] = MEMORY[0x263F8C318] + 16;
  if (v7 < 0) {
    operator delete((void *)v6[8]);
  }
  std::streambuf::~streambuf();
  std::iostream::~basic_iostream();
  return MEMORY[0x21667D2B0](&v8);
}

void sub_21136E68C(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
}

void ZinIrTransformDuplicate::ZinIrTransformDuplicate(ZinIrTransformDuplicate *this, uint64_t a2, char a3)
{
  *(void *)this = &unk_26C3502E8;
  *((void *)this + 1) = a2;
  *((unsigned char *)this + 16) = a3;
}

uint64_t ZinIrTransformDuplicate::Apply(uint64_t a1, uint64_t a2)
{
  size_t v4 = *(void *)(a1 + 8) * *(void *)(a2 + 56);
  switch(*(_DWORD *)(a2 + 8))
  {
    case 1:
      std::string __p = 0;
      uint64_t v15 = 0;
      uint64_t v16 = 0;
      std::vector<unsigned char>::reserve((unint64_t *)&__p, v4);
      ZinIrTransformDuplicate::Duplicate<signed char>(a1, a2, (unint64_t *)&__p);
      std::allocate_shared[abi:ne180100]<ZinIrConstData_specialization<signed char>,std::allocator<ZinIrConstData_specialization<signed char>>,std::vector<signed char>,void>((uint64_t)&__p, &v17);
      operator new();
    case 2:
      std::string __p = 0;
      uint64_t v15 = 0;
      uint64_t v16 = 0;
      std::vector<unsigned char>::reserve((unint64_t *)&__p, v4);
      ZinIrTransformDuplicate::Duplicate<unsigned char>(a1, a2, (unint64_t *)&__p);
      std::allocate_shared[abi:ne180100]<ZinIrConstData_specialization<unsigned char>,std::allocator<ZinIrConstData_specialization<unsigned char>>,std::vector<unsigned char>,void>((uint64_t)&__p, &v17);
      operator new();
    case 4:
      std::string __p = 0;
      uint64_t v15 = 0;
      uint64_t v16 = 0;
      std::vector<half>::reserve(&__p, v4);
      ZinIrTransformDuplicate::Duplicate<half>(a1, a2, (uint64_t)&__p);
      std::allocate_shared[abi:ne180100]<ZinIrConstData_specialization<half>,std::allocator<ZinIrConstData_specialization<half>>,std::vector<half>,void>((uint64_t)&__p, &v17);
      operator new();
    case 6:
      std::string __p = 0;
      uint64_t v15 = 0;
      uint64_t v16 = 0;
      std::vector<float>::reserve(&__p, v4);
      ZinIrTransformDuplicate::Duplicate<float>(a1, a2, (uint64_t)&__p);
      std::allocate_shared[abi:ne180100]<ZinIrConstData_specialization<float>,std::allocator<ZinIrConstData_specialization<float>>,std::vector<float>,void>((uint64_t)&__p, &v17);
      operator new();
    default:
      BOOL v5 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v5) {
        ZinIrTransformDuplicate::Apply(v5, v6, v7, v8, v9, v10, v11, v12);
      }
      return 3;
  }
}

void sub_21136E9FC(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, void *__p, uint64_t a10)
{
  if (v10) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v10);
  }
  MEMORY[0x21667D3C0](v11, 0x10B3C400A1ACBE3);
  if (v10) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v10);
  }
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(a1);
}

void ZinIrTransformDuplicate::Duplicate<float>(uint64_t a1, uint64_t a2, uint64_t a3)
{
  if (*(unsigned char *)(a1 + 16))
  {
    unint64_t v6 = *(void *)(a2 + 56);
    if (v6)
    {
      unint64_t v7 = 0;
      unint64_t v8 = *(void *)(a1 + 8);
      do
      {
        if (v8)
        {
          for (unint64_t i = 0; i < v8; ++i)
          {
            ZinIrVector::GetAt<float>(a2, v7);
            int v11 = v10;
            int v13 = *(_DWORD **)(a3 + 8);
            unint64_t v12 = *(void *)(a3 + 16);
            if ((unint64_t)v13 >= v12)
            {
              uint64_t v15 = *(_DWORD **)a3;
              uint64_t v16 = ((uint64_t)v13 - *(void *)a3) >> 2;
              unint64_t v17 = v16 + 1;
              if ((unint64_t)(v16 + 1) >> 62) {
                goto LABEL_50;
              }
              uint64_t v18 = v12 - (void)v15;
              if (v18 >> 1 > v17) {
                unint64_t v17 = v18 >> 1;
              }
              if ((unint64_t)v18 >= 0x7FFFFFFFFFFFFFFCLL) {
                unint64_t v19 = 0x3FFFFFFFFFFFFFFFLL;
              }
              else {
                unint64_t v19 = v17;
              }
              if (v19)
              {
                char v20 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ZinIrPaddingMode>>(a3 + 16, v19);
                uint64_t v15 = *(_DWORD **)a3;
                int v13 = *(_DWORD **)(a3 + 8);
              }
              else
              {
                char v20 = 0;
              }
              char v21 = &v20[4 * v16];
              *(_DWORD *)char v21 = v11;
              unint64_t v14 = v21 + 4;
              while (v13 != v15)
              {
                int v22 = *--v13;
                *((_DWORD *)v21 - 1) = v22;
                v21 -= 4;
              }
              *(void *)a3 = v21;
              *(void *)(a3 + 8) = v14;
              *(void *)(a3 + 16) = &v20[4 * v19];
              if (v15) {
                operator delete(v15);
              }
            }
            else
            {
              *int v13 = v10;
              unint64_t v14 = v13 + 1;
            }
            *(void *)(a3 + 8) = v14;
            unint64_t v8 = *(void *)(a1 + 8);
          }
          unint64_t v6 = *(void *)(a2 + 56);
        }
        ++v7;
      }
      while (v6 > v7);
    }
  }
  else
  {
    unint64_t v23 = *(void *)(a1 + 8);
    if (v23)
    {
      unint64_t v24 = 0;
      unint64_t v25 = *(void *)(a2 + 56);
      do
      {
        if (v25)
        {
          for (unint64_t j = 0; j < v25; ++j)
          {
            ZinIrVector::GetAt<float>(a2, j);
            int v28 = v27;
            long long v30 = *(_DWORD **)(a3 + 8);
            unint64_t v29 = *(void *)(a3 + 16);
            if ((unint64_t)v30 >= v29)
            {
              uint64_t v32 = *(_DWORD **)a3;
              uint64_t v33 = ((uint64_t)v30 - *(void *)a3) >> 2;
              unint64_t v34 = v33 + 1;
              if ((unint64_t)(v33 + 1) >> 62) {
LABEL_50:
              }
                std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
              uint64_t v35 = v29 - (void)v32;
              if (v35 >> 1 > v34) {
                unint64_t v34 = v35 >> 1;
              }
              if ((unint64_t)v35 >= 0x7FFFFFFFFFFFFFFCLL) {
                unint64_t v36 = 0x3FFFFFFFFFFFFFFFLL;
              }
              else {
                unint64_t v36 = v34;
              }
              if (v36)
              {
                int64x2_t v37 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ZinIrPaddingMode>>(a3 + 16, v36);
                uint64_t v32 = *(_DWORD **)a3;
                long long v30 = *(_DWORD **)(a3 + 8);
              }
              else
              {
                int64x2_t v37 = 0;
              }
              uint64_t v38 = &v37[4 * v33];
              *(_DWORD *)uint64_t v38 = v28;
              std::string v31 = v38 + 4;
              while (v30 != v32)
              {
                int v39 = *--v30;
                *((_DWORD *)v38 - 1) = v39;
                v38 -= 4;
              }
              *(void *)a3 = v38;
              *(void *)(a3 + 8) = v31;
              *(void *)(a3 + 16) = &v37[4 * v36];
              if (v32) {
                operator delete(v32);
              }
            }
            else
            {
              *long long v30 = v27;
              std::string v31 = v30 + 1;
            }
            *(void *)(a3 + 8) = v31;
            unint64_t v25 = *(void *)(a2 + 56);
          }
          unint64_t v23 = *(void *)(a1 + 8);
        }
        ++v24;
      }
      while (v23 > v24);
    }
  }
}

void ZinIrTransformDuplicate::Duplicate<half>(uint64_t a1, uint64_t a2, uint64_t a3)
{
  if (*(unsigned char *)(a1 + 16))
  {
    unint64_t v6 = *(void *)(a2 + 56);
    if (v6)
    {
      unint64_t v7 = 0;
      unint64_t v8 = *(void *)(a1 + 8);
      do
      {
        if (v8)
        {
          for (unint64_t i = 0; i < v8; ++i)
          {
            ZinIrVector::GetAt<half>(a2, v7);
            __int16 v11 = v10;
            int v13 = *(_WORD **)(a3 + 8);
            unint64_t v12 = *(void *)(a3 + 16);
            if ((unint64_t)v13 >= v12)
            {
              uint64_t v15 = *(_WORD **)a3;
              uint64_t v16 = (uint64_t)v13 - *(void *)a3;
              if (v16 <= -3) {
                goto LABEL_52;
              }
              uint64_t v17 = v16 >> 1;
              unint64_t v18 = v12 - (void)v15;
              if (v18 <= (v16 >> 1) + 1) {
                unint64_t v19 = v17 + 1;
              }
              else {
                unint64_t v19 = v18;
              }
              if (v18 >= 0x7FFFFFFFFFFFFFFELL) {
                uint64_t v20 = 0x7FFFFFFFFFFFFFFFLL;
              }
              else {
                uint64_t v20 = v19;
              }
              if (v20)
              {
                char v21 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<half>>(a3 + 16, v20);
                uint64_t v15 = *(_WORD **)a3;
                int v13 = *(_WORD **)(a3 + 8);
              }
              else
              {
                char v21 = 0;
              }
              int v22 = &v21[2 * v17];
              *(_WORD *)int v22 = v11;
              unint64_t v14 = v22 + 2;
              while (v13 != v15)
              {
                __int16 v23 = *--v13;
                *((_WORD *)v22 - 1) = v23;
                v22 -= 2;
              }
              *(void *)a3 = v22;
              *(void *)(a3 + 8) = v14;
              *(void *)(a3 + 16) = &v21[2 * v20];
              if (v15) {
                operator delete(v15);
              }
            }
            else
            {
              *int v13 = v10;
              unint64_t v14 = v13 + 1;
            }
            *(void *)(a3 + 8) = v14;
            unint64_t v8 = *(void *)(a1 + 8);
          }
          unint64_t v6 = *(void *)(a2 + 56);
        }
        ++v7;
      }
      while (v6 > v7);
    }
  }
  else
  {
    unint64_t v24 = *(void *)(a1 + 8);
    if (v24)
    {
      unint64_t v25 = 0;
      unint64_t v26 = *(void *)(a2 + 56);
      do
      {
        if (v26)
        {
          for (unint64_t j = 0; j < v26; ++j)
          {
            ZinIrVector::GetAt<half>(a2, j);
            __int16 v29 = v28;
            std::string v31 = *(_WORD **)(a3 + 8);
            unint64_t v30 = *(void *)(a3 + 16);
            if ((unint64_t)v31 >= v30)
            {
              uint64_t v33 = *(_WORD **)a3;
              uint64_t v34 = (uint64_t)v31 - *(void *)a3;
              if (v34 <= -3) {
LABEL_52:
              }
                std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
              uint64_t v35 = v34 >> 1;
              unint64_t v36 = v30 - (void)v33;
              if (v36 <= (v34 >> 1) + 1) {
                unint64_t v37 = v35 + 1;
              }
              else {
                unint64_t v37 = v36;
              }
              if (v36 >= 0x7FFFFFFFFFFFFFFELL) {
                uint64_t v38 = 0x7FFFFFFFFFFFFFFFLL;
              }
              else {
                uint64_t v38 = v37;
              }
              if (v38)
              {
                int v39 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<half>>(a3 + 16, v38);
                uint64_t v33 = *(_WORD **)a3;
                std::string v31 = *(_WORD **)(a3 + 8);
              }
              else
              {
                int v39 = 0;
              }
              int64x2_t v40 = &v39[2 * v35];
              *(_WORD *)int64x2_t v40 = v29;
              uint64_t v32 = v40 + 2;
              while (v31 != v33)
              {
                __int16 v41 = *--v31;
                *((_WORD *)v40 - 1) = v41;
                v40 -= 2;
              }
              *(void *)a3 = v40;
              *(void *)(a3 + 8) = v32;
              *(void *)(a3 + 16) = &v39[2 * v38];
              if (v33) {
                operator delete(v33);
              }
            }
            else
            {
              *std::string v31 = v28;
              uint64_t v32 = v31 + 1;
            }
            *(void *)(a3 + 8) = v32;
            unint64_t v26 = *(void *)(a2 + 56);
          }
          unint64_t v24 = *(void *)(a1 + 8);
        }
        ++v25;
      }
      while (v24 > v25);
    }
  }
}

void ZinIrTransformDuplicate::Duplicate<signed char>(uint64_t a1, uint64_t a2, unint64_t *a3)
{
  if (*(unsigned char *)(a1 + 16))
  {
    unint64_t v6 = *(void *)(a2 + 56);
    if (v6)
    {
      unint64_t v7 = 0;
      unint64_t v8 = *(void *)(a1 + 8);
      do
      {
        if (v8)
        {
          for (unint64_t i = 0; i < v8; ++i)
          {
            char v10 = ZinIrVector::GetAt<signed char>(a2, v7);
            char v11 = v10;
            int v13 = (unsigned char *)a3[1];
            unint64_t v12 = a3[2];
            if ((unint64_t)v13 >= v12)
            {
              unint64_t v15 = *a3;
              uint64_t v16 = &v13[-*a3];
              unint64_t v17 = (unint64_t)(v16 + 1);
              if ((uint64_t)(v16 + 1) < 0) {
                goto LABEL_52;
              }
              unint64_t v18 = v12 - v15;
              if (2 * v18 > v17) {
                unint64_t v17 = 2 * v18;
              }
              if (v18 >= 0x3FFFFFFFFFFFFFFFLL) {
                size_t v19 = 0x7FFFFFFFFFFFFFFFLL;
              }
              else {
                size_t v19 = v17;
              }
              if (v19) {
                uint64_t v20 = (char *)operator new(v19);
              }
              else {
                uint64_t v20 = 0;
              }
              char v21 = &v16[(void)v20];
              int v22 = &v16[(void)v20];
              *int v22 = v11;
              unint64_t v14 = v22 + 1;
              if (v13 != (unsigned char *)v15)
              {
                __int16 v23 = &v13[~v15];
                do
                {
                  char v24 = *--v13;
                  (v23--)[(void)v20] = v24;
                }
                while (v13 != (unsigned char *)v15);
                int v13 = (unsigned char *)*a3;
                char v21 = v20;
              }
              *a3 = (unint64_t)v21;
              a3[1] = (unint64_t)v14;
              a3[2] = (unint64_t)&v20[v19];
              if (v13) {
                operator delete(v13);
              }
            }
            else
            {
              *int v13 = v10;
              unint64_t v14 = v13 + 1;
            }
            a3[1] = (unint64_t)v14;
            unint64_t v8 = *(void *)(a1 + 8);
          }
          unint64_t v6 = *(void *)(a2 + 56);
        }
        ++v7;
      }
      while (v6 > v7);
    }
  }
  else
  {
    unint64_t v25 = *(void *)(a1 + 8);
    if (v25)
    {
      unint64_t v26 = 0;
      unint64_t v27 = *(void *)(a2 + 56);
      do
      {
        if (v27)
        {
          for (unint64_t j = 0; j < v27; ++j)
          {
            char v29 = ZinIrVector::GetAt<signed char>(a2, j);
            char v30 = v29;
            uint64_t v32 = (unsigned char *)a3[1];
            unint64_t v31 = a3[2];
            if ((unint64_t)v32 >= v31)
            {
              unint64_t v34 = *a3;
              uint64_t v35 = &v32[-*a3];
              unint64_t v36 = (unint64_t)(v35 + 1);
              if ((uint64_t)(v35 + 1) < 0) {
LABEL_52:
              }
                std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
              unint64_t v37 = v31 - v34;
              if (2 * v37 > v36) {
                unint64_t v36 = 2 * v37;
              }
              if (v37 >= 0x3FFFFFFFFFFFFFFFLL) {
                size_t v38 = 0x7FFFFFFFFFFFFFFFLL;
              }
              else {
                size_t v38 = v36;
              }
              if (v38) {
                int v39 = (char *)operator new(v38);
              }
              else {
                int v39 = 0;
              }
              int64x2_t v40 = &v35[(void)v39];
              __int16 v41 = &v35[(void)v39];
              unsigned char *v41 = v30;
              uint64_t v33 = v41 + 1;
              if (v32 != (unsigned char *)v34)
              {
                int v42 = &v32[~v34];
                do
                {
                  char v43 = *--v32;
                  (v42--)[(void)v39] = v43;
                }
                while (v32 != (unsigned char *)v34);
                uint64_t v32 = (unsigned char *)*a3;
                int64x2_t v40 = v39;
              }
              *a3 = (unint64_t)v40;
              a3[1] = (unint64_t)v33;
              a3[2] = (unint64_t)&v39[v38];
              if (v32) {
                operator delete(v32);
              }
            }
            else
            {
              unsigned char *v32 = v29;
              uint64_t v33 = v32 + 1;
            }
            a3[1] = (unint64_t)v33;
            unint64_t v27 = *(void *)(a2 + 56);
          }
          unint64_t v25 = *(void *)(a1 + 8);
        }
        ++v26;
      }
      while (v25 > v26);
    }
  }
}

void ZinIrTransformDuplicate::Duplicate<unsigned char>(uint64_t a1, uint64_t a2, unint64_t *a3)
{
  if (*(unsigned char *)(a1 + 16))
  {
    unint64_t v6 = *(void *)(a2 + 56);
    if (v6)
    {
      unint64_t v7 = 0;
      unint64_t v8 = *(void *)(a1 + 8);
      do
      {
        if (v8)
        {
          for (unint64_t i = 0; i < v8; ++i)
          {
            char v10 = ZinIrVector::GetAt<unsigned char>(a2, v7);
            char v11 = v10;
            int v13 = (unsigned char *)a3[1];
            unint64_t v12 = a3[2];
            if ((unint64_t)v13 >= v12)
            {
              unint64_t v15 = *a3;
              uint64_t v16 = &v13[-*a3];
              unint64_t v17 = (unint64_t)(v16 + 1);
              if ((uint64_t)(v16 + 1) < 0) {
                goto LABEL_52;
              }
              unint64_t v18 = v12 - v15;
              if (2 * v18 > v17) {
                unint64_t v17 = 2 * v18;
              }
              if (v18 >= 0x3FFFFFFFFFFFFFFFLL) {
                size_t v19 = 0x7FFFFFFFFFFFFFFFLL;
              }
              else {
                size_t v19 = v17;
              }
              if (v19) {
                uint64_t v20 = (char *)operator new(v19);
              }
              else {
                uint64_t v20 = 0;
              }
              char v21 = &v16[(void)v20];
              int v22 = &v16[(void)v20];
              *int v22 = v11;
              unint64_t v14 = v22 + 1;
              if (v13 != (unsigned char *)v15)
              {
                __int16 v23 = &v13[~v15];
                do
                {
                  char v24 = *--v13;
                  (v23--)[(void)v20] = v24;
                }
                while (v13 != (unsigned char *)v15);
                int v13 = (unsigned char *)*a3;
                char v21 = v20;
              }
              *a3 = (unint64_t)v21;
              a3[1] = (unint64_t)v14;
              a3[2] = (unint64_t)&v20[v19];
              if (v13) {
                operator delete(v13);
              }
            }
            else
            {
              *int v13 = v10;
              unint64_t v14 = v13 + 1;
            }
            a3[1] = (unint64_t)v14;
            unint64_t v8 = *(void *)(a1 + 8);
          }
          unint64_t v6 = *(void *)(a2 + 56);
        }
        ++v7;
      }
      while (v6 > v7);
    }
  }
  else
  {
    unint64_t v25 = *(void *)(a1 + 8);
    if (v25)
    {
      unint64_t v26 = 0;
      unint64_t v27 = *(void *)(a2 + 56);
      do
      {
        if (v27)
        {
          for (unint64_t j = 0; j < v27; ++j)
          {
            char v29 = ZinIrVector::GetAt<unsigned char>(a2, j);
            char v30 = v29;
            uint64_t v32 = (unsigned char *)a3[1];
            unint64_t v31 = a3[2];
            if ((unint64_t)v32 >= v31)
            {
              unint64_t v34 = *a3;
              uint64_t v35 = &v32[-*a3];
              unint64_t v36 = (unint64_t)(v35 + 1);
              if ((uint64_t)(v35 + 1) < 0) {
LABEL_52:
              }
                std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
              unint64_t v37 = v31 - v34;
              if (2 * v37 > v36) {
                unint64_t v36 = 2 * v37;
              }
              if (v37 >= 0x3FFFFFFFFFFFFFFFLL) {
                size_t v38 = 0x7FFFFFFFFFFFFFFFLL;
              }
              else {
                size_t v38 = v36;
              }
              if (v38) {
                int v39 = (char *)operator new(v38);
              }
              else {
                int v39 = 0;
              }
              int64x2_t v40 = &v35[(void)v39];
              __int16 v41 = &v35[(void)v39];
              unsigned char *v41 = v30;
              uint64_t v33 = v41 + 1;
              if (v32 != (unsigned char *)v34)
              {
                int v42 = &v32[~v34];
                do
                {
                  char v43 = *--v32;
                  (v42--)[(void)v39] = v43;
                }
                while (v32 != (unsigned char *)v34);
                uint64_t v32 = (unsigned char *)*a3;
                int64x2_t v40 = v39;
              }
              *a3 = (unint64_t)v40;
              a3[1] = (unint64_t)v33;
              a3[2] = (unint64_t)&v39[v38];
              if (v32) {
                operator delete(v32);
              }
            }
            else
            {
              unsigned char *v32 = v29;
              uint64_t v33 = v32 + 1;
            }
            a3[1] = (unint64_t)v33;
            unint64_t v27 = *(void *)(a2 + 56);
          }
          unint64_t v25 = *(void *)(a1 + 8);
        }
        ++v26;
      }
      while (v25 > v26);
    }
  }
}

uint64_t ZinIrTransformDuplicate::Serialize(ZinIrTransformDuplicate *this, ZinIrSerializer *a2)
{
  uint64_t v4 = ZinIrSerializer::WriteUint8(a2, 11);
  return ZinIrSerializer::WriteUint64(a2, *((void *)this + 1)) + v4;
}

uint64_t ZinIrTransformDuplicate::DebugPrint@<X0>(void *a1@<X8>)
{
  std::basic_stringstream<char,std::char_traits<char>,std::allocator<char>>::basic_stringstream[abi:ne180100]((uint64_t)v5);
  std::stringbuf::str[abi:ne180100]<std::allocator<char>>((uint64_t)v6, a1);
  v5[0] = *MEMORY[0x263F8C2B8];
  uint64_t v3 = *(void *)(MEMORY[0x263F8C2B8] + 72);
  *(void *)((char *)v5 + *(void *)(v5[0] - 24)) = *(void *)(MEMORY[0x263F8C2B8] + 64);
  v5[2] = v3;
  v6[0] = MEMORY[0x263F8C318] + 16;
  if (v7 < 0) {
    operator delete((void *)v6[8]);
  }
  std::streambuf::~streambuf();
  std::iostream::~basic_iostream();
  return MEMORY[0x21667D2B0](&v8);
}

void sub_21136F564(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
}

__n128 ZinIrTransformShuffle::ZinIrTransformShuffle(__n128 *a1, __n128 *a2, unint64_t a3)
{
  a1->n128_u64[0] = (unint64_t)&unk_26C34EB18;
  a1->n128_u64[1] = (unint64_t)&unk_26C34EB58;
  a1[1].n128_u64[0] = 0;
  a1[1].n128_u64[1] = 0;
  a1[2].n128_u64[0] = 0;
  __n128 result = *a2;
  a1[1] = *a2;
  a1[2].n128_u64[0] = a2[1].n128_u64[0];
  a2->n128_u64[0] = 0;
  a2->n128_u64[1] = 0;
  a2[1].n128_u64[0] = 0;
  a1[2].n128_u64[1] = a3;
  return result;
}

uint64_t ZinIrTransformShuffle::Apply(uint64_t a1, uint64_t a2)
{
  switch(*(_DWORD *)(a2 + 8))
  {
    case 1:
      ZinIrWeightBase::ShuffleChannelData<std::vector<signed char>,ZinIrConstData_specialization<signed char>>(a2, (uint64_t *)(a1 + 16), *(void *)(a1 + 40), 1, &v11);
      break;
    case 2:
      ZinIrWeightBase::ShuffleChannelData<std::vector<unsigned char>,ZinIrConstData_specialization<unsigned char>>(a2, (uint64_t *)(a1 + 16), *(void *)(a1 + 40), 1, &v11);
      break;
    case 4:
      ZinIrWeightBase::ShuffleChannelData<std::vector<half>,ZinIrConstData_specialization<half>>(a2, (uint64_t *)(a1 + 16), *(void *)(a1 + 40), 1, &v11);
      break;
    case 6:
      ZinIrWeightBase::ShuffleChannelData<std::vector<float>,ZinIrConstData_specialization<float>>(a2, (uint64_t *)(a1 + 16), *(void *)(a1 + 40), 1, &v11);
      break;
    default:
      BOOL v2 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v2) {
        ZinIrTransformShuffle::Apply(v2, v3, v4, v5, v6, v7, v8, v9);
      }
      return 3;
  }
  (*(void (**)(unint64_t, __n128))(*(void *)v11.n128_u64[0] + 24))(v11.n128_u64[0], v11);
  operator new();
}

void sub_21136F7A8(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, std::__shared_weak_count *a10)
{
  if (v11) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v11);
  }
  MEMORY[0x21667D3C0](v10, 0x10B3C400A1ACBE3);
  if (a10) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a10);
  }
  _Unwind_Resume(a1);
}

uint64_t ZinIrTransformShuffle::Serialize(ZinIrTransformShuffle *this, ZinIrSerializer *a2)
{
  uint64_t v4 = (uint64_t)(*((void *)this + 3) - *((void *)this + 2)) >> 3;
  uint64_t v5 = ZinIrSerializer::WriteUint8(a2, 3);
  uint64_t v6 = ZinIrSerializer::WriteUint64(a2, v4) + v5;
  uint64_t v8 = (uint64_t *)*((void *)this + 2);
  uint64_t v7 = (uint64_t *)*((void *)this + 3);
  while (v8 != v7)
  {
    uint64_t v9 = *v8++;
    v6 += ZinIrSerializer::WriteUint64(a2, v9);
  }
  return v6;
}

uint64_t non-virtual thunk to'ZinIrTransformShuffle::Serialize(ZinIrTransformShuffle *this, ZinIrSerializer *a2)
{
  return ZinIrTransformShuffle::Serialize((ZinIrTransformShuffle *)((char *)this - 8), a2);
}

uint64_t ZinIrTransformShuffle::DebugPrint@<X0>(void *a1@<X8>)
{
  std::basic_stringstream<char,std::char_traits<char>,std::allocator<char>>::basic_stringstream[abi:ne180100]((uint64_t)v5);
  std::stringbuf::str[abi:ne180100]<std::allocator<char>>((uint64_t)v6, a1);
  v5[0] = *MEMORY[0x263F8C2B8];
  uint64_t v3 = *(void *)(MEMORY[0x263F8C2B8] + 72);
  *(void *)((char *)v5 + *(void *)(v5[0] - 24)) = *(void *)(MEMORY[0x263F8C2B8] + 64);
  v5[2] = v3;
  v6[0] = MEMORY[0x263F8C318] + 16;
  if (v7 < 0) {
    operator delete((void *)v6[8]);
  }
  std::streambuf::~streambuf();
  std::iostream::~basic_iostream();
  return MEMORY[0x21667D2B0](&v8);
}

void sub_21136F9EC(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
}

void *ZinIrVectorEWMultiply::ZinIrVectorEWMultiply(void *result, uint64_t *a2)
{
  uint64_t v3 = *a2;
  uint64_t v2 = a2[1];
  *__n128 result = &unk_26C34EB90;
  result[1] = v3;
  result[2] = v2;
  if (v2) {
    atomic_fetch_add_explicit((atomic_ullong *volatile)(v2 + 8), 1uLL, memory_order_relaxed);
  }
  return result;
}

void ZinIrVectorEWMultiply::Apply(uint64_t a1, uint64_t a2)
{
  if (*(void *)(a2 + 56) == 1) {
    unint64_t v4 = *(void *)(*(void *)(a1 + 8) + 56);
  }
  else {
    unint64_t v4 = *(void *)(a2 + 56);
  }
  std::string __p = 0;
  unint64_t v25 = 0;
  unint64_t v26 = 0;
  std::vector<float>::reserve(&__p, v4);
  if (v4)
  {
    for (uint64_t i = 0; i != v4; ++i)
    {
      ZinIrVector::GetAt<float>(a2, i);
      float v7 = v6;
      if (*(char *)(a2 + 280) >= 1) {
        float v8 = (float)(1 << *(unsigned char *)(a2 + 280));
      }
      else {
        float v8 = 1.0 / (float)(1 << -*(unsigned char *)(a2 + 280));
      }
      ZinIrVector::GetAt<float>(*(void *)(a1 + 8), i);
      float v10 = 1.0 / (float)(1 << -*(unsigned char *)(*(void *)(a1 + 8) + 280));
      if (*(char *)(*(void *)(a1 + 8) + 280) >= 1) {
        float v10 = (float)(1 << *(unsigned char *)(*(void *)(a1 + 8) + 280));
      }
      float v11 = (float)(v7 * v8) * (float)(v9 * v10);
      unint64_t v12 = v25;
      if (v25 >= v26)
      {
        unint64_t v14 = (float *)__p;
        uint64_t v15 = ((char *)v25 - (unsigned char *)__p) >> 2;
        unint64_t v16 = v15 + 1;
        if ((unint64_t)(v15 + 1) >> 62) {
          std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
        }
        uint64_t v17 = (char *)v26 - (unsigned char *)__p;
        if (((char *)v26 - (unsigned char *)__p) >> 1 > v16) {
          unint64_t v16 = v17 >> 1;
        }
        if ((unint64_t)v17 >= 0x7FFFFFFFFFFFFFFCLL) {
          unint64_t v18 = 0x3FFFFFFFFFFFFFFFLL;
        }
        else {
          unint64_t v18 = v16;
        }
        if (v18)
        {
          size_t v19 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ZinIrPaddingMode>>((uint64_t)&v26, v18);
          unint64_t v14 = (float *)__p;
          unint64_t v12 = v25;
        }
        else
        {
          size_t v19 = 0;
        }
        uint64_t v20 = (float *)&v19[4 * v15];
        *uint64_t v20 = v11;
        int v13 = v20 + 1;
        while (v12 != v14)
        {
          int v21 = *((_DWORD *)v12-- - 1);
          *((_DWORD *)v20-- - 1) = v21;
        }
        std::string __p = v20;
        unint64_t v25 = v13;
        unint64_t v26 = (float *)&v19[4 * v18];
        if (v14) {
          operator delete(v14);
        }
      }
      else
      {
        *unint64_t v25 = v11;
        int v13 = v12 + 1;
      }
      unint64_t v25 = v13;
    }
  }
  ZinDynamicRange::ZinConvertToFP32WithShift((float **)&__p, -31, 0, (uint64_t)v22);
  ZinIrVector::StdvectorToVector<float>((uint64_t)&v23);
}

void sub_21136FCA4(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, void *__p, uint64_t a12, uint64_t a13, void *a14, uint64_t a15)
{
  if (__p) {
    operator delete(__p);
  }
  if (a14) {
    operator delete(a14);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinIrVectorEWMultiply::Serialize(ZinIrVector **this, ZinIrSerializer *a2)
{
  uint64_t v4 = ZinIrSerializer::WriteUint8(a2, 4);
  return ZinIrVector::Serialize(this[1], a2) + v4;
}

uint64_t ZinIrVector::Serialize(ZinIrVector *this, ZinIrSerializer *a2)
{
  if (*((unsigned char *)this + 152))
  {
    uint64_t v4 = ZinIrSerializer::WriteUint8(a2, 1);
    uint64_t SourceFileInfo = ZinIrWeightBase::GetSourceFileInfo(this);
    uint64_t v6 = SourceFileInfo;
    if (*(char *)(SourceFileInfo + 23) < 0)
    {
      std::string::__init_copy_ctor_external(&__p, *(const std::string::value_type **)SourceFileInfo, *(void *)(SourceFileInfo + 8));
    }
    else
    {
      long long v7 = *(_OWORD *)SourceFileInfo;
      __p.__r_.__value_.__r.__words[2] = *(void *)(SourceFileInfo + 16);
      *(_OWORD *)&__p.__r_.__value_.__l.__data_ = v7;
    }
    long long v10 = *(_OWORD *)(v6 + 24);
    int v29 = *(_DWORD *)(v6 + 40);
    *(_OWORD *)__int16 v28 = v10;
    uint64_t v11 = ZinIrSerializer::WriteUint32(a2, 0);
    uint64_t v12 = ZinIrSerializer::WriteUint64(a2, v28[0]);
    uint64_t v13 = ZinIrSerializer::WriteUint64(a2, v28[1]);
    unint64_t v14 = (ZinIrVector *)((char *)this + 160);
    ZinIrHalH13g::~ZinIrHalH13g(v14);
    uint64_t v16 = ZinIrSerializer::WriteUint64(a2, (uint64_t)(v15[1] - *v15) >> 4);
    ZinIrHalH13g::~ZinIrHalH13g(v14);
    uint64_t v9 = v11 + v4 + v12 + v13 + v16;
    unint64_t v18 = *(void **)v17;
    size_t v19 = *(void **)(v17 + 8);
    while (v18 != v19)
    {
      v9 += (*(uint64_t (**)(void, ZinIrSerializer *))(*(void *)*v18 + 16))(*v18, a2);
      v18 += 2;
    }
    if (SHIBYTE(__p.__r_.__value_.__r.__words[2]) < 0) {
      operator delete(__p.__r_.__value_.__l.__data_);
    }
  }
  else if (*((unsigned char *)this + 288))
  {
    uint64_t v8 = ZinIrSerializer::WriteUint8(a2, 2);
    if (!*((unsigned char *)this + 288)) {
      ZinAssertImpl("Trying to get singular value of a non-singular vector");
    }
    return ZinIrSerializer::WriteFloat32(a2, *((float *)this + 71)) + v8;
  }
  else
  {
    uint64_t v20 = ZinIrSerializer::WriteUint8(a2, 3);
    uint64_t v21 = *((void *)this + 17);
    int v22 = (std::__shared_weak_count *)*((void *)this + 18);
    if (v22) {
      atomic_fetch_add_explicit(&v22->__shared_owners_, 1uLL, memory_order_relaxed);
    }
    uint64_t v23 = (*(uint64_t (**)(uint64_t))(*(void *)v21 + 24))(v21);
    uint64_t v9 = ZinIrSerializer::WriteUint64(a2, v23) + v20;
    if (v23)
    {
      for (uint64_t i = 0; i != v23; ++i)
      {
        ZinIrVector::GetAt<float>((uint64_t)this, i);
        v9 += ZinIrSerializer::WriteFloat32(a2, v25);
      }
    }
    if (v22) {
      std::__shared_weak_count::__release_shared[abi:ne180100](v22);
    }
  }
  return v9;
}

void sub_21136FF74(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, void *__p, uint64_t a10, int a11, __int16 a12, char a13, char a14)
{
  if (v14) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v14);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinIrVectorEWMultiply::DebugPrint@<X0>(void *a1@<X8>)
{
  std::basic_stringstream<char,std::char_traits<char>,std::allocator<char>>::basic_stringstream[abi:ne180100]((uint64_t)v5);
  std::stringbuf::str[abi:ne180100]<std::allocator<char>>((uint64_t)v6, a1);
  v5[0] = *MEMORY[0x263F8C2B8];
  uint64_t v3 = *(void *)(MEMORY[0x263F8C2B8] + 72);
  *(void *)((char *)v5 + *(void *)(v5[0] - 24)) = *(void *)(MEMORY[0x263F8C2B8] + 64);
  v5[2] = v3;
  v6[0] = MEMORY[0x263F8C318] + 16;
  if (v7 < 0) {
    operator delete((void *)v6[8]);
  }
  std::streambuf::~streambuf();
  std::iostream::~basic_iostream();
  return MEMORY[0x21667D2B0](&v8);
}

void sub_211370110(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
}

void *ZinIrVectorFoldBiasWithBotScaleBotBias::ZinIrVectorFoldBiasWithBotScaleBotBias(void *result, uint64_t *a2, void *a3)
{
  uint64_t v4 = *a2;
  uint64_t v3 = a2[1];
  *__n128 result = &unk_26C353EA0;
  result[1] = v4;
  result[2] = v3;
  if (v3) {
    atomic_fetch_add_explicit((atomic_ullong *volatile)(v3 + 8), 1uLL, memory_order_relaxed);
  }
  uint64_t v5 = a3[1];
  result[3] = *a3;
  result[4] = v5;
  if (v5) {
    atomic_fetch_add_explicit((atomic_ullong *volatile)(v5 + 8), 1uLL, memory_order_relaxed);
  }
  return result;
}

void ZinIrVectorFoldBiasWithBotScaleBotBias::Apply(void *a1, uint64_t a2, uint64_t a3)
{
  uint64_t v5 = a1[1];
  v7 = (!v5 || !*(unsigned char *)(v5 + 152)) && ((uint64_t v6 = a1[3]) == 0 || !*(unsigned char *)(v6 + 152)) && *(unsigned char *)(a2 + 152) == 0;
  std::allocate_shared[abi:ne180100]<ZinIrVector,std::allocator<ZinIrVector>,ZinIrVector const&,void>(a2, &v13);
  uint64_t v8 = a1[2];
  v12[0] = a1[1];
  v12[1] = v8;
  if (v8) {
    atomic_fetch_add_explicit((atomic_ullong *volatile)(v8 + 8), 1uLL, memory_order_relaxed);
  }
  uint64_t v9 = a1[3];
  uint64_t v10 = a1[4];
  v11[0] = v9;
  v11[1] = v10;
  if (v10) {
    atomic_fetch_add_explicit((atomic_ullong *volatile)(v10 + 8), 1uLL, memory_order_relaxed);
  }
  ZinIrVectorMergeBiasAndScale(&v13, a3, v12, v11, v7);
}

void sub_21137025C(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, std::__shared_weak_count *a15)
{
  if (v16) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v16);
  }
  if (v15) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v15);
  }
  if (a15) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a15);
  }
  _Unwind_Resume(exception_object);
}

void ZinIrVectorMergeBiasAndScale(uint64_t *a1, uint64_t a2, uint64_t *a3, uint64_t *a4, char a5)
{
  uint64_t v8 = *a1;
  uint64_t v9 = (std::__shared_weak_count *)a1[1];
  if (v9) {
    atomic_fetch_add_explicit(&v9->__shared_owners_, 1uLL, memory_order_relaxed);
  }
  uint64_t v10 = *a3;
  uint64_t v11 = (std::__shared_weak_count *)a3[1];
  if (v11) {
    atomic_fetch_add_explicit(&v11->__shared_owners_, 1uLL, memory_order_relaxed);
  }
  uint64_t v13 = *a4;
  uint64_t v12 = (std::__shared_weak_count *)a4[1];
  if (v12) {
    atomic_fetch_add_explicit(&v12->__shared_owners_, 1uLL, memory_order_relaxed);
  }
  if (v10) {
    unint64_t v14 = *(void *)(v10 + 56);
  }
  else {
    unint64_t v14 = 1;
  }
  unint64_t v15 = *(void *)(v8 + 56);
  if (v13) {
    unint64_t v16 = *(void *)(v13 + 56);
  }
  else {
    unint64_t v16 = 1;
  }
  if (v15 <= v14) {
    unint64_t v15 = v14;
  }
  if (v16 <= v15) {
    unint64_t v17 = v15;
  }
  else {
    unint64_t v17 = v16;
  }
  if (v12) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v12);
  }
  if (v11) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v11);
  }
  if (v9) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v9);
  }
  std::string __p = 0;
  uint64_t v45 = 0;
  int v46 = 0;
  if (*a4) {
    char v18 = *(unsigned char *)(*a4 + 280);
  }
  else {
    char v18 = 0;
  }
  if (*a3) {
    char v19 = *(unsigned char *)(*a3 + 280);
  }
  else {
    char v19 = 0;
  }
  std::vector<float>::reserve(&__p, v17);
  if (v17)
  {
    uint64_t v20 = 0;
    if (v18 <= 0) {
      float v21 = 1.0 / (float)(1 << -v18);
    }
    else {
      float v21 = (float)(1 << v18);
    }
    if (v19 <= 0) {
      float v22 = 1.0 / (float)(1 << -v19);
    }
    else {
      float v22 = (float)(1 << v19);
    }
    do
    {
      ZinIrVector::GetAt<float>(*a1, v20);
      float v24 = v23;
      if (*a4)
      {
        ZinIrVector::GetAt<float>(*a4, v20);
        float v26 = v25;
      }
      else
      {
        float v26 = 0.0;
      }
      if (*a3) {
        ZinIrVector::GetAt<float>(*a3, v20);
      }
      else {
        float v27 = 1.0;
      }
      float v28 = v27 * v22;
      float v29 = 1.0 / (float)(1 << -*(unsigned char *)(*a1 + 280));
      if (*(char *)(*a1 + 280) >= 1) {
        float v29 = (float)(1 << *(unsigned char *)(*a1 + 280));
      }
      float v30 = (float)(v26 * v21) + (float)((float)(v24 * v29) / v28);
      unint64_t v31 = v45;
      if (v45 >= v46)
      {
        uint64_t v33 = (float *)__p;
        uint64_t v34 = ((char *)v45 - (unsigned char *)__p) >> 2;
        unint64_t v35 = v34 + 1;
        if ((unint64_t)(v34 + 1) >> 62) {
          std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
        }
        uint64_t v36 = (char *)v46 - (unsigned char *)__p;
        if (((char *)v46 - (unsigned char *)__p) >> 1 > v35) {
          unint64_t v35 = v36 >> 1;
        }
        if ((unint64_t)v36 >= 0x7FFFFFFFFFFFFFFCLL) {
          unint64_t v37 = 0x3FFFFFFFFFFFFFFFLL;
        }
        else {
          unint64_t v37 = v35;
        }
        if (v37)
        {
          size_t v38 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ZinIrPaddingMode>>((uint64_t)&v46, v37);
          uint64_t v33 = (float *)__p;
          unint64_t v31 = v45;
        }
        else
        {
          size_t v38 = 0;
        }
        int v39 = (float *)&v38[4 * v34];
        *int v39 = v30;
        uint64_t v32 = v39 + 1;
        while (v31 != v33)
        {
          int v40 = *((_DWORD *)v31-- - 1);
          *((_DWORD *)v39-- - 1) = v40;
        }
        std::string __p = v39;
        uint64_t v45 = v32;
        int v46 = (float *)&v38[4 * v37];
        if (v33) {
          operator delete(v33);
        }
      }
      else
      {
        *uint64_t v45 = v30;
        uint64_t v32 = v31 + 1;
      }
      uint64_t v45 = v32;
      ++v20;
    }
    while (v20 != v17);
  }
  if (a5)
  {
    ZinDynamicRange::ZinConvertToFP32WithShift((float **)&__p, -16, 15, (uint64_t)&v42);
    ZinIrVector::StdvectorToVector<float>((uint64_t)&v43);
  }
  ZinIrVector::StdvectorToVector<float>((uint64_t)&__p);
}

void sub_211370648(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, void *__p, uint64_t a14, uint64_t a15, void *a16, uint64_t a17)
{
  if (__p) {
    operator delete(__p);
  }
  if (a16) {
    operator delete(a16);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinIrVectorFoldBiasWithBotScaleBotBias::Serialize(ZinIrVectorFoldBiasWithBotScaleBotBias *this, ZinIrSerializer *a2)
{
  uint64_t v4 = ZinIrSerializer::WriteUint8(a2, 5);
  char v5 = *((void *)this + 3) != 0;
  uint64_t v6 = ZinIrSerializer::WriteUint8(a2, *((void *)this + 1) != 0) + v4;
  uint64_t v7 = v6 + ZinIrSerializer::WriteUint8(a2, v5);
  uint64_t v8 = (ZinIrVector *)*((void *)this + 1);
  if (v8) {
    v7 += ZinIrVector::Serialize(v8, a2);
  }
  uint64_t v9 = (ZinIrVector *)*((void *)this + 3);
  if (v9) {
    v7 += ZinIrVector::Serialize(v9, a2);
  }
  return v7;
}

uint64_t ZinIrVectorFoldBiasWithBotScaleBotBias::DebugPrint@<X0>(void *a1@<X8>)
{
  std::basic_stringstream<char,std::char_traits<char>,std::allocator<char>>::basic_stringstream[abi:ne180100]((uint64_t)v5);
  std::stringbuf::str[abi:ne180100]<std::allocator<char>>((uint64_t)v6, a1);
  v5[0] = *MEMORY[0x263F8C2B8];
  uint64_t v3 = *(void *)(MEMORY[0x263F8C2B8] + 72);
  *(void *)((char *)v5 + *(void *)(v5[0] - 24)) = *(void *)(MEMORY[0x263F8C2B8] + 64);
  v5[2] = v3;
  v6[0] = MEMORY[0x263F8C318] + 16;
  if (v7 < 0) {
    operator delete((void *)v6[8]);
  }
  std::streambuf::~streambuf();
  std::iostream::~basic_iostream();
  return MEMORY[0x21667D2B0](&v8);
}

void sub_211370890(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
}

void *ZinIrVectorFoldBotBiasWithBotScaleBias::ZinIrVectorFoldBotBiasWithBotScaleBias(void *result, uint64_t *a2, void *a3)
{
  uint64_t v4 = *a2;
  uint64_t v3 = a2[1];
  *__n128 result = &unk_26C353ED8;
  result[1] = v4;
  result[2] = v3;
  if (v3) {
    atomic_fetch_add_explicit((atomic_ullong *volatile)(v3 + 8), 1uLL, memory_order_relaxed);
  }
  uint64_t v5 = a3[1];
  result[3] = *a3;
  result[4] = v5;
  if (v5) {
    atomic_fetch_add_explicit((atomic_ullong *volatile)(v5 + 8), 1uLL, memory_order_relaxed);
  }
  return result;
}

void ZinIrVectorFoldBotBiasWithBotScaleBias::Apply(void *a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = a1[3];
  char v6 = (!v4 || !*(unsigned char *)(v4 + 152)) && ((v5 = a1[1]) == 0 || !*(unsigned char *)(v5 + 152)) && *(unsigned char *)(a2 + 152) == 0;
  uint64_t v7 = a1[4];
  v11[0] = a1[3];
  v11[1] = v7;
  if (v7) {
    atomic_fetch_add_explicit((atomic_ullong *volatile)(v7 + 8), 1uLL, memory_order_relaxed);
  }
  uint64_t v8 = a1[2];
  v10[0] = a1[1];
  v10[1] = v8;
  if (v8) {
    atomic_fetch_add_explicit((atomic_ullong *volatile)(v8 + 8), 1uLL, memory_order_relaxed);
  }
  std::allocate_shared[abi:ne180100]<ZinIrVector,std::allocator<ZinIrVector>,ZinIrVector const&,void>(a2, &v9);
  ZinIrVectorMergeBiasAndScale(v11, a3, v10, &v9, v6);
}

void sub_2113709D8(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, std::__shared_weak_count *a11)
{
  if (a11)
  {
    std::__shared_weak_count::__release_shared[abi:ne180100](a11);
    if (!v12)
    {
LABEL_3:
      if (!v11) {
        goto LABEL_5;
      }
      goto LABEL_4;
    }
  }
  else if (!v12)
  {
    goto LABEL_3;
  }
  std::__shared_weak_count::__release_shared[abi:ne180100](v12);
  if (!v11) {
LABEL_5:
  }
    _Unwind_Resume(exception_object);
LABEL_4:
  std::__shared_weak_count::__release_shared[abi:ne180100](v11);
  goto LABEL_5;
}

uint64_t ZinIrVectorFoldBotBiasWithBotScaleBias::Serialize(ZinIrVectorFoldBotBiasWithBotScaleBias *this, ZinIrSerializer *a2)
{
  uint64_t v4 = ZinIrSerializer::WriteUint8(a2, 6);
  char v5 = *((void *)this + 3) != 0;
  uint64_t v6 = ZinIrSerializer::WriteUint8(a2, *((void *)this + 1) != 0) + v4;
  uint64_t v7 = v6 + ZinIrSerializer::WriteUint8(a2, v5);
  uint64_t v8 = (ZinIrVector *)*((void *)this + 1);
  if (v8) {
    v7 += ZinIrVector::Serialize(v8, a2);
  }
  uint64_t v9 = (ZinIrVector *)*((void *)this + 3);
  if (v9) {
    v7 += ZinIrVector::Serialize(v9, a2);
  }
  return v7;
}

uint64_t ZinIrVectorFoldBotBiasWithBotScaleBias::DebugPrint@<X0>(void *a1@<X8>)
{
  std::basic_stringstream<char,std::char_traits<char>,std::allocator<char>>::basic_stringstream[abi:ne180100]((uint64_t)v5);
  std::stringbuf::str[abi:ne180100]<std::allocator<char>>((uint64_t)v6, a1);
  v5[0] = *MEMORY[0x263F8C2B8];
  uint64_t v3 = *(void *)(MEMORY[0x263F8C2B8] + 72);
  *(void *)((char *)v5 + *(void *)(v5[0] - 24)) = *(void *)(MEMORY[0x263F8C2B8] + 64);
  v5[2] = v3;
  v6[0] = MEMORY[0x263F8C318] + 16;
  if (v7 < 0) {
    operator delete((void *)v6[8]);
  }
  std::streambuf::~streambuf();
  std::iostream::~basic_iostream();
  return MEMORY[0x21667D2B0](&v8);
}

void sub_211370C18(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
}

void *ZinIrVectorFoldBotScaleWithBotBiasBias::ZinIrVectorFoldBotScaleWithBotBiasBias(void *result, uint64_t *a2, void *a3)
{
  uint64_t v4 = *a2;
  uint64_t v3 = a2[1];
  *__n128 result = &unk_26C353F10;
  result[1] = v4;
  result[2] = v3;
  if (v3) {
    atomic_fetch_add_explicit((atomic_ullong *volatile)(v3 + 8), 1uLL, memory_order_relaxed);
  }
  uint64_t v5 = a3[1];
  result[3] = *a3;
  result[4] = v5;
  if (v5) {
    atomic_fetch_add_explicit((atomic_ullong *volatile)(v5 + 8), 1uLL, memory_order_relaxed);
  }
  return result;
}

void ZinIrVectorFoldBotScaleWithBotBiasBias::Apply(void *a1, uint64_t a2, uint64_t a3)
{
  uint64_t v5 = a1[3];
  v7 = (!v5 || !*(unsigned char *)(v5 + 152)) && ((uint64_t v6 = a1[1]) == 0 || !*(unsigned char *)(v6 + 152)) && *(unsigned char *)(a2 + 152) == 0;
  uint64_t v8 = a1[4];
  v13[0] = a1[3];
  v13[1] = v8;
  if (v8) {
    atomic_fetch_add_explicit((atomic_ullong *volatile)(v8 + 8), 1uLL, memory_order_relaxed);
  }
  std::allocate_shared[abi:ne180100]<ZinIrVector,std::allocator<ZinIrVector>,ZinIrVector const&,void>(a2, &v12);
  uint64_t v9 = a1[1];
  uint64_t v10 = a1[2];
  v11[0] = v9;
  v11[1] = v10;
  if (v10) {
    atomic_fetch_add_explicit((atomic_ullong *volatile)(v10 + 8), 1uLL, memory_order_relaxed);
  }
  ZinIrVectorMergeBiasAndScale(v13, a3, &v12, v11, v7);
}

void sub_211370D64(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, std::__shared_weak_count *a13)
{
  if (v14) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v14);
  }
  if (a13) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a13);
  }
  if (v13) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v13);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinIrVectorFoldBotScaleWithBotBiasBias::Serialize(ZinIrVectorFoldBotScaleWithBotBiasBias *this, ZinIrSerializer *a2)
{
  uint64_t v4 = ZinIrSerializer::WriteUint8(a2, 7);
  char v5 = *((void *)this + 3) != 0;
  uint64_t v6 = ZinIrSerializer::WriteUint8(a2, *((void *)this + 1) != 0) + v4;
  uint64_t v7 = v6 + ZinIrSerializer::WriteUint8(a2, v5);
  uint64_t v8 = (ZinIrVector *)*((void *)this + 1);
  if (v8) {
    v7 += ZinIrVector::Serialize(v8, a2);
  }
  uint64_t v9 = (ZinIrVector *)*((void *)this + 3);
  if (v9) {
    v7 += ZinIrVector::Serialize(v9, a2);
  }
  return v7;
}

uint64_t ZinIrVectorFoldBotScaleWithBotBiasBias::DebugPrint@<X0>(void *a1@<X8>)
{
  std::basic_stringstream<char,std::char_traits<char>,std::allocator<char>>::basic_stringstream[abi:ne180100]((uint64_t)v5);
  std::stringbuf::str[abi:ne180100]<std::allocator<char>>((uint64_t)v6, a1);
  v5[0] = *MEMORY[0x263F8C2B8];
  uint64_t v3 = *(void *)(MEMORY[0x263F8C2B8] + 72);
  *(void *)((char *)v5 + *(void *)(v5[0] - 24)) = *(void *)(MEMORY[0x263F8C2B8] + 64);
  v5[2] = v3;
  v6[0] = MEMORY[0x263F8C318] + 16;
  if (v7 < 0) {
    operator delete((void *)v6[8]);
  }
  std::streambuf::~streambuf();
  std::iostream::~basic_iostream();
  return MEMORY[0x21667D2B0](&v8);
}

void sub_211370F94(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
}

BOOL ZinIrVector::IsQualifiedToConvertPerCoutVectorToSingularVector(ZinIrVector *this, int a2, int a3)
{
  BOOL result = 0;
  if (!*((unsigned char *)this + 152) && !*((unsigned char *)this + 288))
  {
    int v6 = *((char *)this + 280);
    if (ZinIrVector::HasSingleUniqueValue(this) && v6 >= a2 && v6 <= a3) {
      return 1;
    }
  }
  return result;
}

BOOL ZinIrVector::HasSingleUniqueValue(ZinIrVector *this)
{
  if (!*((void *)this + 7)) {
    return 0;
  }
  switch(*((_DWORD *)this + 2))
  {
    case 1:
      int v2 = ZinIrVector::GetAt<signed char>((uint64_t)this, 0);
      if (*((void *)this + 7) < 2uLL) {
        goto LABEL_33;
      }
      int v3 = v2;
      unsigned int v4 = 2;
      uint64_t v5 = 1;
      do
      {
        BOOL v6 = ZinIrVector::GetAt<signed char>((uint64_t)this, v5) == v3;
        BOOL result = v6;
        if (!v6) {
          break;
        }
        uint64_t v5 = v4;
        BOOL v8 = *((void *)this + 7) > (unint64_t)v4++;
      }
      while (v8);
      break;
    case 2:
      int v9 = ZinIrVector::GetAt<unsigned char>((uint64_t)this, 0);
      if (*((void *)this + 7) < 2uLL) {
        goto LABEL_33;
      }
      int v10 = v9;
      unsigned int v11 = 2;
      uint64_t v12 = 1;
      do
      {
        BOOL v6 = ZinIrVector::GetAt<unsigned char>((uint64_t)this, v12) == v10;
        BOOL result = v6;
        if (!v6) {
          break;
        }
        uint64_t v12 = v11;
        BOOL v8 = *((void *)this + 7) > (unint64_t)v11++;
      }
      while (v8);
      break;
    case 4:
      ZinIrVector::GetAt<half>((uint64_t)this, 0);
      if (*((void *)this + 7) < 2uLL) {
        goto LABEL_33;
      }
      short float v21 = v20;
      unsigned int v22 = 2;
      uint64_t v23 = 1;
      do
      {
        ZinIrVector::GetAt<half>((uint64_t)this, v23);
        BOOL result = v24 == v21;
        if (v24 != v21) {
          break;
        }
        uint64_t v23 = v22;
        BOOL v8 = *((void *)this + 7) > (unint64_t)v22++;
      }
      while (v8);
      break;
    case 5:
      unsigned __int8 v25 = ZinIrVector::GetAt<e4m3_t>((uint64_t)this, 0);
      if (*((void *)this + 7) < 2uLL) {
        goto LABEL_33;
      }
      unsigned __int8 v26 = v25;
      unsigned int v27 = 2;
      uint64_t v28 = 1;
      do
      {
        int v29 = ZinIrVector::GetAt<e4m3_t>((uint64_t)this, v28);
        BOOL result = v29 == v26;
        if (v29 != v26) {
          break;
        }
        uint64_t v28 = v27;
        BOOL v8 = *((void *)this + 7) > (unint64_t)v27++;
      }
      while (v8);
      break;
    case 6:
      ZinIrVector::GetAt<float>((uint64_t)this, 0);
      if (*((void *)this + 7) < 2uLL)
      {
LABEL_33:
        BOOL result = 1;
      }
      else
      {
        float v31 = v30;
        unsigned int v32 = 2;
        uint64_t v33 = 1;
        do
        {
          ZinIrVector::GetAt<float>((uint64_t)this, v33);
          BOOL result = v34 == v31;
          if (v34 != v31) {
            break;
          }
          uint64_t v33 = v32;
          BOOL v8 = *((void *)this + 7) > (unint64_t)v32++;
        }
        while (v8);
      }
      break;
    default:
      BOOL result = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (result)
      {
        ZinIrVector::HasSingleUniqueValue(result, v13, v14, v15, v16, v17, v18, v19);
        return 0;
      }
      break;
  }
  return result;
}

void ZinIrVector::ConvertPerCoutVectorToSingularVector(ZinIrVector *this, int a2, int a3)
{
  ZinIrVector::GetValuesAsVector<float>((uint64_t)this, *((void *)this + 7), 1, (uint64_t)&v7);
  std::vector<float>::resize((uint64_t)&v7, 1uLL);
  ZinDynamicRange::ZinConvertToFP32WithShift((float **)&v7, a2, a3, (uint64_t)v5);
  ZinIrVector::StdvectorToVector<float>((uint64_t)&__p);
}

void sub_2113712E4(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, void *__p, uint64_t a12, uint64_t a13, void *a14, uint64_t a15)
{
  if (__p) {
    operator delete(__p);
  }
  if (a14) {
    operator delete(a14);
  }
  _Unwind_Resume(exception_object);
}

void ZinIrVector::ConvertSingularVectorToPerCoutVector(ZinIrVector *this@<X0>, size_t a2@<X1>, void *a3@<X8>)
{
  if (!*((unsigned char *)this + 288)) {
    ZinAssertImpl("This function should only be called for singular vectors.");
  }
  int v4 = *((_DWORD *)this + 2);
  if (v4 == 2)
  {
    char v13 = (int)*((float *)this + 71);
    std::vector<unsigned char>::vector(&__p, a2, &v13);
    std::allocate_shared[abi:ne180100]<ZinIrConstData_specialization<unsigned char>,std::allocator<ZinIrConstData_specialization<unsigned char>>,std::vector<unsigned char>,void>((uint64_t)&__p, &v15);
    operator new();
  }
  if (v4 == 1)
  {
    char v13 = (int)*((float *)this + 71);
    std::vector<signed char>::vector(&__p, a2, &v13);
    std::allocate_shared[abi:ne180100]<ZinIrConstData_specialization<signed char>,std::allocator<ZinIrConstData_specialization<signed char>>,std::vector<signed char>,void>((uint64_t)&__p, &v15);
    operator new();
  }
  BOOL v5 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
  if (v5) {
    ZinIrVector::ConvertSingularVectorToPerCoutVector(v5, v6, v7, v8, v9, v10, v11, v12);
  }
  *a3 = 0;
}

void sub_2113714AC(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11, uint64_t a12, uint64_t a13, std::__shared_weak_count *a14)
{
  if (v15) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v15);
  }
  MEMORY[0x21667D3C0](v14, 0x10B3C400A1ACBE3);
  if (a14) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a14);
  }
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(a1);
}

uint64_t ZinIrVector::Transform(uint64_t a1, uint64_t a2, uint64_t *a3)
{
  uint64_t v28 = 0;
  uint64_t v6 = *(void **)a2;
  uint64_t v7 = *(void **)(a2 + 8);
  if (*(void **)a2 == v7)
  {
    uint64_t v8 = 0;
LABEL_7:
    uint64_t v28 = 0;
    uint64_t v10 = *a3;
    *a3 = v8;
    if (v10) {
      std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)a3, v10);
    }
    if (*(unsigned char *)(a1 + 152))
    {
      unsigned __int8 v25 = 0;
      unsigned __int8 v26 = 0;
      unint64_t v27 = 0;
      uint64_t v11 = *(void **)a2;
      uint64_t v12 = *(void **)(a2 + 8);
      if (*(void **)a2 != v12)
      {
        char v13 = 0;
        do
        {
          long long v14 = *(_OWORD *)v11;
          uint64_t v15 = v11[1];
          if (v15)
          {
            atomic_fetch_add_explicit((atomic_ullong *volatile)(v15 + 8), 1uLL, memory_order_relaxed);
            char v13 = v26;
          }
          if ((unint64_t)v13 >= v27)
          {
            long long v24 = v14;
            uint64_t v16 = (v13 - v25) >> 4;
            if ((unint64_t)(v16 + 1) >> 60) {
              std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
            }
            unint64_t v17 = (uint64_t)(v27 - (void)v25) >> 3;
            if (v17 <= v16 + 1) {
              unint64_t v17 = v16 + 1;
            }
            if (v27 - (unint64_t)v25 >= 0x7FFFFFFFFFFFFFF0) {
              unint64_t v18 = 0xFFFFFFFFFFFFFFFLL;
            }
            else {
              unint64_t v18 = v17;
            }
            v29[4] = &v27;
            uint64_t v19 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<std::pair<unsigned long,unsigned long>>>((uint64_t)&v27, v18);
            short float v20 = &v19[16 * v16];
            v29[0] = v19;
            v29[1] = v20;
            v29[3] = &v19[16 * v21];
            *(_OWORD *)short float v20 = v24;
            v29[2] = v20 + 16;
            std::vector<std::shared_ptr<ZinIrTransform>>::__swap_out_circular_buffer((uint64_t *)&v25, v29);
            char v13 = v26;
            std::__split_buffer<std::shared_ptr<ZinIrConstData>>::~__split_buffer(v29);
          }
          else
          {
            *(void *)char v13 = v14;
            *((void *)v13 + 1) = v15;
            v13 += 16;
          }
          unsigned __int8 v26 = v13;
          v11 += 2;
        }
        while (v11 != v12);
      }
      ZinIrWeightBase::SetupMutableHistory(a1, *a3, (long long **)&v25);
      v29[0] = &v25;
      std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100]((void ***)v29);
    }
    uint64_t v9 = 0;
  }
  else
  {
    uint64_t v8 = a1;
    while (1)
    {
      uint64_t v9 = (*(uint64_t (**)(void, uint64_t, uint64_t *))(*(void *)*v6 + 32))(*v6, v8, &v28);
      if (v9) {
        break;
      }
      uint64_t v8 = v28;
      v6 += 2;
      if (v6 == v7) {
        goto LABEL_7;
      }
    }
  }
  uint64_t v22 = v28;
  uint64_t v28 = 0;
  if (v22) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&v28, v22);
  }
  return v9;
}

void sub_211371714(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, char a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, void **a20)
{
  a20 = (void **)&a11;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100](&a20);
  uint64_t v21 = a14;
  a14 = 0;
  if (v21) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&a14, v21);
  }
  _Unwind_Resume(a1);
}

BOOL ZinIrVector::operator==(uint64_t a1, uint64_t a2)
{
  unint64_t v2 = *(void *)(a1 + 56);
  if (v2 != *(void *)(a2 + 56)) {
    return 0;
  }
  int v5 = *(_DWORD *)(a1 + 8);
  if (v5 != *(_DWORD *)(a2 + 8)) {
    return 0;
  }
  if (v5 != 4)
  {
    if (v5 == 6)
    {
      if (v2 >= 2)
      {
        unsigned int v6 = 2;
        uint64_t v7 = 1;
        do
        {
          ZinIrVector::GetAt<float>(a1, v7);
          float v9 = v8;
          ZinIrVector::GetAt<float>(a2, v7);
          BOOL result = v9 == v10;
          if (v9 != v10) {
            break;
          }
          uint64_t v7 = v6;
          BOOL v12 = *(void *)(a1 + 56) > (unint64_t)v6++;
        }
        while (v12);
        return result;
      }
      return 1;
    }
    BOOL result = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (!result) {
      return result;
    }
    ZinIrVector::operator==(result, v18, v19, v20, v21, v22, v23, v24);
    return 0;
  }
  if (v2 < 2) {
    return 1;
  }
  unsigned int v13 = 2;
  uint64_t v14 = 1;
  do
  {
    ZinIrVector::GetAt<half>(a1, v14);
    short float v16 = v15;
    ZinIrVector::GetAt<half>(a2, v14);
    BOOL result = v16 == v17;
    if (v16 != v17) {
      break;
    }
    uint64_t v14 = v13;
    BOOL v12 = *(void *)(a1 + 56) > (unint64_t)v13++;
  }
  while (v12);
  return result;
}

void ZinIrVector::CreatePartial(ZinIrVector *this)
{
}

void sub_21137190C(_Unwind_Exception *exception_object)
{
  uint64_t v3 = *v1;
  *uint64_t v1 = 0;
  if (v3) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)v1, v3);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinIrVector::GetElementIndex(uint64_t a1, void *a2)
{
  return (*a2 + *(void *)(a1 + 16)) * *(void *)(a1 + 96);
}

void ZinIrVector::Clone(ZinIrVector *this@<X0>, uint64_t *a2@<X8>)
{
  uint64_t v20 = *MEMORY[0x263EF8340];
  if (*((unsigned char *)this + 288))
  {
    switch(*((_DWORD *)this + 2))
    {
      case 1:
        operator new();
      case 2:
        operator new();
      case 4:
      case 6:
        operator new();
      default:
        BOOL v5 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
        if (v5) {
          ZinIrVector::Clone(v5, v6, v7, v8, v9, v10, v11, v12);
        }
        *a2 = 0;
        break;
    }
  }
  else
  {
    int v4 = (std::__shared_weak_count *)operator new(0x30uLL);
    v4->__shared_owners_ = 0;
    v4->__vftable = (std::__shared_weak_count_vtbl *)&unk_26C389118;
    v4->__shared_weak_owners_ = 0;
    v4[1].__vftable = (std::__shared_weak_count_vtbl *)&unk_26C3502E8;
    v4[1].__shared_owners_ = 1;
    LOBYTE(v4[1].__shared_weak_owners_) = 1;
    *a2 = 0;
    uint64_t v18 = v4 + 1;
    uint64_t v19 = v4;
    atomic_fetch_add_explicit(&v4->__shared_owners_, 1uLL, memory_order_relaxed);
    unsigned int v13 = 0;
    uint64_t v14 = 0;
    short float v15 = 0;
    short float v16 = (void **)&v13;
    char v17 = 0;
    unsigned int v13 = operator new(0x10uLL);
    uint64_t v14 = v13;
    short float v15 = v13 + 2;
    uint64_t v14 = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::shared_ptr<ZinIrVectorTransform>>,std::shared_ptr<ZinIrVectorTransform> const*,std::shared_ptr<ZinIrVectorTransform> const*,std::shared_ptr<ZinIrVectorTransform>*>((uint64_t)&v15, &v18, &v20, v13);
    ZinIrVector::Transform((uint64_t)this, (uint64_t)&v13, a2);
    short float v16 = (void **)&v13;
    std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100](&v16);
    if (v19) {
      std::__shared_weak_count::__release_shared[abi:ne180100](v19);
    }
    if (!*a2) {
      ZinAssertImpl("Failed to clone scale");
    }
    std::__shared_weak_count::__release_shared[abi:ne180100](v4);
  }
}

void sub_211371BA0(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15)
{
}

BOOL ZinIrVector::HasAllZero(ZinIrVector *this)
{
  if (*((unsigned char *)this + 288)) {
    return *((float *)this + 71) == 0.0;
  }
  uint64_t v3 = (ZinIrConstData *)*((void *)this + 17);
  int v4 = (std::__shared_weak_count *)*((void *)this + 18);
  if (v4) {
    atomic_fetch_add_explicit(&v4->__shared_owners_, 1uLL, memory_order_relaxed);
  }
  uint64_t HasAllZero = ZinIrConstData::HasAllZero(v3);
  if (v4) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v4);
  }
  return HasAllZero;
}

void sub_211371CA8(_Unwind_Exception *exception_object)
{
  if (v1) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v1);
  }
  _Unwind_Resume(exception_object);
}

void ZinIrTransformRemap::~ZinIrTransformRemap(ZinIrTransformRemap *this)
{
}

void non-virtual thunk to'ZinIrTransformRemap::~ZinIrTransformRemap(ZinIrTransformRemap *this)
{
}

void ZinIrTransformDuplicate::~ZinIrTransformDuplicate(ZinIrTransformDuplicate *this)
{
}

void ZinIrTransformShuffle::~ZinIrTransformShuffle(ZinIrTransformShuffle *this)
{
  *(void *)this = &unk_26C34EB18;
  *((void *)this + 1) = &unk_26C34EB58;
  unint64_t v2 = (void *)*((void *)this + 2);
  if (v2)
  {
    *((void *)this + 3) = v2;
    operator delete(v2);
  }
}

{
  void *v2;
  uint64_t vars8;

  *(void *)this = &unk_26C34EB18;
  *((void *)this + 1) = &unk_26C34EB58;
  unint64_t v2 = (void *)*((void *)this + 2);
  if (v2)
  {
    *((void *)this + 3) = v2;
    operator delete(v2);
  }

  JUMPOUT(0x21667D3C0);
}

void non-virtual thunk to'ZinIrTransformShuffle::~ZinIrTransformShuffle(ZinIrTransformShuffle *this)
{
  *((void *)this - 1) = &unk_26C34EB18;
  *(void *)this = &unk_26C34EB58;
  uint64_t v1 = (void *)*((void *)this + 1);
  if (v1)
  {
    *((void *)this + 2) = v1;
    operator delete(v1);
  }
}

{
  void *v1;
  uint64_t vars8;

  *((void *)this - 1) = &unk_26C34EB18;
  *(void *)this = &unk_26C34EB58;
  uint64_t v1 = (void *)*((void *)this + 1);
  if (v1)
  {
    *((void *)this + 2) = v1;
    operator delete(v1);
  }

  JUMPOUT(0x21667D3C0);
}

void ZinIrVectorEWMultiply::~ZinIrVectorEWMultiply(ZinIrVectorEWMultiply *this)
{
  *(void *)this = &unk_26C34EB90;
  uint64_t v1 = (std::__shared_weak_count *)*((void *)this + 2);
  if (v1) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v1);
  }
}

{
  std::__shared_weak_count *v1;
  uint64_t vars8;

  *(void *)this = &unk_26C34EB90;
  uint64_t v1 = (std::__shared_weak_count *)*((void *)this + 2);
  if (v1) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v1);
  }

  JUMPOUT(0x21667D3C0);
}

void ZinIrVectorFoldBiasWithBotScaleBotBias::~ZinIrVectorFoldBiasWithBotScaleBotBias(ZinIrVectorFoldBiasWithBotScaleBotBias *this)
{
  *(void *)this = &unk_26C353EA0;
  unint64_t v2 = (std::__shared_weak_count *)*((void *)this + 4);
  if (v2) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v2);
  }
  uint64_t v3 = (std::__shared_weak_count *)*((void *)this + 2);
  if (v3) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v3);
  }
}

{
  std::__shared_weak_count *v2;
  std::__shared_weak_count *v3;
  uint64_t vars8;

  *(void *)this = &unk_26C353EA0;
  unint64_t v2 = (std::__shared_weak_count *)*((void *)this + 4);
  if (v2) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v2);
  }
  uint64_t v3 = (std::__shared_weak_count *)*((void *)this + 2);
  if (v3) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v3);
  }

  JUMPOUT(0x21667D3C0);
}

void ZinIrVectorFoldBotBiasWithBotScaleBias::~ZinIrVectorFoldBotBiasWithBotScaleBias(ZinIrVectorFoldBotBiasWithBotScaleBias *this)
{
  *(void *)this = &unk_26C353ED8;
  unint64_t v2 = (std::__shared_weak_count *)*((void *)this + 4);
  if (v2) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v2);
  }
  uint64_t v3 = (std::__shared_weak_count *)*((void *)this + 2);
  if (v3) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v3);
  }
}

{
  std::__shared_weak_count *v2;
  std::__shared_weak_count *v3;
  uint64_t vars8;

  *(void *)this = &unk_26C353ED8;
  unint64_t v2 = (std::__shared_weak_count *)*((void *)this + 4);
  if (v2) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v2);
  }
  uint64_t v3 = (std::__shared_weak_count *)*((void *)this + 2);
  if (v3) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v3);
  }

  JUMPOUT(0x21667D3C0);
}

void ZinIrVectorFoldBotScaleWithBotBiasBias::~ZinIrVectorFoldBotScaleWithBotBiasBias(ZinIrVectorFoldBotScaleWithBotBiasBias *this)
{
  *(void *)this = &unk_26C353F10;
  unint64_t v2 = (std::__shared_weak_count *)*((void *)this + 4);
  if (v2) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v2);
  }
  uint64_t v3 = (std::__shared_weak_count *)*((void *)this + 2);
  if (v3) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v3);
  }
}

{
  std::__shared_weak_count *v2;
  std::__shared_weak_count *v3;
  uint64_t vars8;

  *(void *)this = &unk_26C353F10;
  unint64_t v2 = (std::__shared_weak_count *)*((void *)this + 4);
  if (v2) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v2);
  }
  uint64_t v3 = (std::__shared_weak_count *)*((void *)this + 2);
  if (v3) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v3);
  }

  JUMPOUT(0x21667D3C0);
}

void *std::allocate_shared[abi:ne180100]<ZinIrVector,std::allocator<ZinIrVector>,ZinIrVector const&,void>@<X0>(uint64_t a1@<X1>, void *a2@<X8>)
{
  int v4 = operator new(0x140uLL);
  BOOL result = std::__shared_ptr_emplace<ZinIrVector>::__shared_ptr_emplace[abi:ne180100]<ZinIrVector const&,std::allocator<ZinIrVector>,0>(v4, a1);
  *a2 = v4 + 3;
  a2[1] = v4;
  return result;
}

void sub_211372264(_Unwind_Exception *a1)
{
  operator delete(v1);
  _Unwind_Resume(a1);
}

void *std::__shared_ptr_emplace<ZinIrVector>::__shared_ptr_emplace[abi:ne180100]<ZinIrVector const&,std::allocator<ZinIrVector>,0>(void *a1, uint64_t a2)
{
  a1[1] = 0;
  a1[2] = 0;
  *a1 = &unk_26C388970;
  std::construct_at[abi:ne180100]<ZinIrVector,ZinIrVector const&,ZinIrVector*>((uint64_t)(a1 + 3), a2);
  return a1;
}

void sub_2113722C0(_Unwind_Exception *a1)
{
  std::__shared_weak_count::~__shared_weak_count(v1);
  _Unwind_Resume(a1);
}

void std::__shared_ptr_emplace<ZinIrVector>::~__shared_ptr_emplace(std::__shared_weak_count *this)
{
  this->__vftable = (std::__shared_weak_count_vtbl *)&unk_26C388970;
  std::__shared_weak_count::~__shared_weak_count(this);
}

void std::__shared_ptr_emplace<ZinIrVector>::~__shared_ptr_emplace(std::__shared_weak_count *a1)
{
  a1->__vftable = (std::__shared_weak_count_vtbl *)&unk_26C388970;
  std::__shared_weak_count::~__shared_weak_count(a1);

  JUMPOUT(0x21667D3C0);
}

void std::__shared_ptr_emplace<ZinIrVector>::__on_zero_shared(uint64_t a1)
{
}

uint64_t std::construct_at[abi:ne180100]<ZinIrVector,ZinIrVector const&,ZinIrVector*>(uint64_t a1, uint64_t a2)
{
  *(void *)a1 = &unk_26C348E90;
  long long v4 = *(_OWORD *)(a2 + 8);
  long long v5 = *(_OWORD *)(a2 + 24);
  long long v6 = *(_OWORD *)(a2 + 40);
  *(_OWORD *)(a1 + 56) = *(_OWORD *)(a2 + 56);
  *(_OWORD *)(a1 + 4std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v6;
  *(_OWORD *)(a1 + 24) = v5;
  *(_OWORD *)(a1 + 8) = v4;
  long long v7 = *(_OWORD *)(a2 + 72);
  long long v8 = *(_OWORD *)(a2 + 88);
  long long v9 = *(_OWORD *)(a2 + 104);
  *(_OWORD *)(a1 + 12std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = *(_OWORD *)(a2 + 120);
  *(_OWORD *)(a1 + 104) = v9;
  *(_OWORD *)(a1 + 88) = v8;
  *(_OWORD *)(a1 + 72) = v7;
  uint64_t v10 = *(void *)(a2 + 144);
  *(void *)(a1 + 136) = *(void *)(a2 + 136);
  *(void *)(a1 + 144) = v10;
  if (v10) {
    atomic_fetch_add_explicit((atomic_ullong *volatile)(v10 + 8), 1uLL, memory_order_relaxed);
  }
  uint64_t v11 = *(void *)(a2 + 152);
  *(void *)(a1 + 16std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  *(void *)(a1 + 152) = v11;
  *(void *)(a1 + 168) = 0;
  *(void *)(a1 + 176) = 0;
  std::vector<std::shared_ptr<ZinIrTransform>>::__init_with_size[abi:ne180100]<std::shared_ptr<ZinIrTransform>*,std::shared_ptr<ZinIrTransform>*>((void *)(a1 + 160), *(void **)(a2 + 160), *(void **)(a2 + 168), (uint64_t)(*(void *)(a2 + 168) - *(void *)(a2 + 160)) >> 4);
  uint64_t v12 = (std::string *)(a1 + 184);
  if (*(char *)(a2 + 207) < 0)
  {
    std::string::__init_copy_ctor_external(v12, *(const std::string::value_type **)(a2 + 184), *(void *)(a2 + 192));
  }
  else
  {
    long long v13 = *(_OWORD *)(a2 + 184);
    *(void *)(a1 + 20std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = *(void *)(a2 + 200);
    *(_OWORD *)&v12->__r_.__value_.__l.__data_ = v13;
  }
  long long v14 = *(_OWORD *)(a2 + 208);
  *(_DWORD *)(a1 + 224) = *(_DWORD *)(a2 + 224);
  *(_OWORD *)(a1 + 208) = v14;
  long long v15 = *(_OWORD *)(a2 + 232);
  long long v16 = *(_OWORD *)(a2 + 248);
  *(_OWORD *)(a1 + 26std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = *(_OWORD *)(a2 + 260);
  *(_OWORD *)(a1 + 248) = v16;
  *(_OWORD *)(a1 + 232) = v15;
  *(void *)a1 = &unk_26C343C60;
  uint64_t v17 = *(void *)(a2 + 280);
  *(unsigned char *)(a1 + 288) = *(unsigned char *)(a2 + 288);
  *(void *)(a1 + 28std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v17;
  return a1;
}

void sub_2113724B0(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100]((void ***)va);
  long long v4 = *(std::__shared_weak_count **)(v2 + 144);
  if (v4) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v4);
  }
  _Unwind_Resume(a1);
}

void std::__destroy_at[abi:ne180100]<ZinIrVector,0>(uint64_t a1)
{
  *(void *)a1 = &unk_26C348E90;
  uint64_t v2 = (void **)(a1 + 160);
  if (*(char *)(a1 + 207) < 0) {
    operator delete(*(void **)(a1 + 184));
  }
  long long v4 = v2;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100](&v4);
  uint64_t v3 = *(std::__shared_weak_count **)(a1 + 144);
  if (v3) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v3);
  }
}

void ZinIrTransformRemap::Apply(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void ZinIrTransformDuplicate::Apply(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void ZinIrTransformShuffle::Apply(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void ZinIrVectorEWMultiply::Apply(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void ZinIrVector::HasSingleUniqueValue(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void ZinIrVector::ConvertSingularVectorToPerCoutVector(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void ZinIrVector::operator==(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void ZinIrVector::Clone(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void ZinCpBasedAllocator::ZinCpBasedAllocator(uint64_t a1)
{
  *(void *)a1 = 0;
  *(void *)(a1 + 8) = 0;
  *(void *)(a1 + 32) = 0;
  *(void *)(a1 + 24) = a1 + 32;
  *(void *)(a1 + 16) = 0;
  *(void *)(a1 + 4std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  *(void *)(a1 + 56) = 0;
  *(void *)(a1 + 48) = a1 + 56;
  *(_OWORD *)(a1 + 72) = 0u;
  *(void *)(a1 + 64) = 0;
  *(_OWORD *)(a1 + 88) = 0u;
  *(_OWORD *)(a1 + 112) = 0u;
  *(_DWORD *)(a1 + 104) = 1065353216;
  *(_OWORD *)(a1 + 128) = 0u;
  *(_DWORD *)(a1 + 144) = 1065353216;
  *(_OWORD *)(a1 + 152) = 0u;
  *(_OWORD *)(a1 + 168) = 0u;
  *(_OWORD *)(a1 + 232) = 0u;
  *(_DWORD *)(a1 + 184) = 1065353216;
  *(_OWORD *)(a1 + 192) = 0u;
  *(_OWORD *)(a1 + 208) = 0u;
  *(_DWORD *)(a1 + 224) = 1065353216;
  *(_OWORD *)(a1 + 248) = 0u;
  *(_DWORD *)(a1 + 264) = 1065353216;
  operator new();
}

void sub_211372BF0(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, void *__p, uint64_t a18, int a19, __int16 a20,char a21,char a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,int a27,__int16 a28,char a29,char a30,void *a31,uint64_t a32,int a33,__int16 a34,char a35,char a36)
{
  std::__optional_destruct_base<ZinTensorFamilyUtil,false>::~__optional_destruct_base[abi:ne180100](v38);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy(v36 + 1024, *(void **)(v36 + 1032));
  std::unique_ptr<ZinIrInPlaceUpdate>::reset[abi:ne180100]((uint64_t *)(v36 + 1016), 0);
  if (*(char *)(v36 + 967) < 0) {
    operator delete(*v37);
  }
  std::ofstream::~ofstream(v40);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table(a9);
  std::unique_ptr<ZinL2FootprintCalculator>::reset[abi:ne180100]((ZinL2FootprintCalculator **)(v39 + 40), 0);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table(v39);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table(a10);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table(a11);
  std::__hash_table<std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>>>::~__hash_table(a12);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table(a13);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy(a14, *(void **)(v36 + 56));
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy(a15, *(void **)(v36 + 32));
  std::string __p = (void *)v36;
  std::vector<std::vector<ZinIrOpLayer *>>::__destroy_vector::operator()[abi:ne180100]((void ***)&__p);
  _Unwind_Resume(a1);
}

void sub_211372D3C()
{
  MEMORY[0x21667D3C0](v0, 0x10E0C4067EF369CLL);
  JUMPOUT(0x211372CE8);
}

void sub_211372D5C()
{
}

void ZinCpBasedAllocator::Initialize(ZinCpBasedAllocator *this@<X0>, uint64_t *a2@<X8>)
{
  uint64_t v3 = (void *)*((void *)this + 41);
  long long v6 = (uint64_t *)*v3;
  long long v4 = v3 + 1;
  long long v5 = v6;
  if (v6 != v4)
  {
    do
    {
      Hal = ZinIrTarget::GetHal(a2, (ZinIrTarget *)v5[4]);
      long long v8 = Hal + 1;
      long long v9 = (void *)*Hal;
      if ((uint64_t *)*Hal != Hal + 1)
      {
        do
        {
          uint64_t v10 = (void *)v9[4];
          uint64_t RootTensor = 0;
          uint64_t v11 = (const ZinIrTensor *)(*(uint64_t (**)(void *, void, void))(*v10 + 32))(v10, 0, 0);
          uint64_t RootTensor = ZinTensorFamilyUtil::GetRootTensor((ZinCpBasedAllocator *)((char *)this + 1048), v11);
          std::__tree<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const*>((uint64_t **)this + 3, &RootTensor, &RootTensor);
          v10[7] = 0;
          uint64_t v12 = (uint64_t *)v9[1];
          if (v12)
          {
            do
            {
              long long v13 = v12;
              uint64_t v12 = (uint64_t *)*v12;
            }
            while (v12);
          }
          else
          {
            do
            {
              long long v13 = (uint64_t *)v9[2];
              BOOL v14 = *v13 == (void)v9;
              long long v9 = v13;
            }
            while (!v14);
          }
          long long v9 = v13;
        }
        while (v13 != v8);
      }
      long long v15 = (uint64_t *)v5[1];
      if (v15)
      {
        do
        {
          a2 = v15;
          long long v15 = (uint64_t *)*v15;
        }
        while (v15);
      }
      else
      {
        do
        {
          a2 = (uint64_t *)v5[2];
          BOOL v14 = *a2 == (void)v5;
          long long v5 = a2;
        }
        while (!v14);
      }
      long long v5 = a2;
    }
    while (a2 != v4);
  }
  ZinLiveRangeUtils<ZinIrOpLayer,ZinIrTensor>::ZinIrComputeLiveRanges(*((ZinIrOpLayer ****)this + 40), (void *)this + 35);
  ZinCpBasedAllocator::InitializeWorkUnit(this);
  ZinCpBasedAllocator::InitializeTileHeight((uint64_t)this);
  ZinMirInterleaveInitializer::Run(*((uint64_t ***)this + 40), *((ZinIrTensor **)this + 42), 0, (void *)this + 19);
  if (!ZinMirInputCropOffsetXLsbsInitializer::Run(*((ZinIrOpLayer ****)this + 40), *((void *)this + 42), (uint64_t)this + 192))
  {
    ZinMirOutputCropOffsetXLsbsInitializer::Run(*((ZinIrOpLayer ****)this + 40), *((void *)this + 42), (uint64_t)this + 232);
    ZinCpBasedAllocator::InitializeEarlyAllocationDecision(this);
    *((unsigned char *)this + 968) = 0;
    operator new();
  }
  ZinAssertImpl("Internal CP Allocation Error");
}

void sub_211372F40(_Unwind_Exception *a1)
{
  MEMORY[0x21667D3C0](v1, 0x10A2C406C64BEB0);
  _Unwind_Resume(a1);
}

void ZinCpBasedAllocator::~ZinCpBasedAllocator(ZinCpBasedAllocator *this)
{
  std::__optional_destruct_base<ZinTensorFamilyUtil,false>::~__optional_destruct_base[abi:ne180100]((uint64_t)this + 1048);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)this + 1024, *((void **)this + 129));
  std::unique_ptr<ZinIrInPlaceUpdate>::reset[abi:ne180100]((uint64_t *)this + 127, 0);
  if (*((char *)this + 967) < 0) {
    operator delete(*((void **)this + 118));
  }
  uint64_t v2 = MEMORY[0x263F8C2B0];
  uint64_t v3 = *MEMORY[0x263F8C2B0];
  *((void *)this + 47) = *MEMORY[0x263F8C2B0];
  *(void *)((char *)this + *(void *)(v3 - 24) + 376) = *(void *)(v2 + 24);
  MEMORY[0x21667CDE0]((char *)this + 384);
  std::ostream::~ostream();
  MEMORY[0x21667D2B0]((char *)this + 792);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)this + 280);
  std::unique_ptr<ZinL2FootprintCalculator>::reset[abi:ne180100]((ZinL2FootprintCalculator **)this + 34, 0);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)this + 232);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)this + 192);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)this + 152);
  std::__hash_table<std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>>>::~__hash_table((uint64_t)this + 112);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)this + 72);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)this + 48, *((void **)this + 7));
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)this + 24, *((void **)this + 4));
  long long v4 = (void **)this;
  std::vector<std::vector<ZinIrOpLayer *>>::__destroy_vector::operator()[abi:ne180100](&v4);
}

uint64_t ZinCpBasedAllocator::Execute(ZinCpBasedAllocator *this)
{
  v48[19] = *MEMORY[0x263EF8340];
  if (!*(unsigned char *)(*((void *)this + 42) + 1105)) {
    return 0;
  }
  uint64_t ExecutionBehavior = ZinCpBasedAllocator::CreateExecutionBehavior(this);
  if (!ExecutionBehavior)
  {
    ZinCpBasedAllocator::CreateRegions(this);
    uint64_t v42 = this;
    unsigned int v3 = std::thread::hardware_concurrency();
    uint64_t v4 = *((void *)this + 43);
    if (*(unsigned char *)(v4 + 386))
    {
      uint64_t v5 = *(void *)this;
      if (*(unsigned char *)(v4 + 385))
      {
        uint64_t v6 = *((void *)this + 1);
        unint64_t v7 = 0xAAAAAAAAAAAAAAABLL * ((v6 - v5) >> 3);
        if (v7 >= 2 && v3 > 1)
        {
          __p[0] = 0;
          __p[1] = 0;
          std::string::size_type v41 = 0;
          unint64_t v9 = v7 / v3;
          if (v9 >= 4) {
            unint64_t v9 = 4;
          }
          if (v7 < v3) {
            unint64_t v10 = 1;
          }
          else {
            unint64_t v10 = v9;
          }
          if (v6 != v5)
          {
            uint64_t v11 = v42;
            __lk.__m_ = 0;
            *(void *)&__lk.__owns_ = 0;
            uint64_t v36 = 0;
            std::vector<std::vector<ZinANELayer const*>>::__init_with_size[abi:ne180100]<std::vector<ZinANELayer const*>*,std::vector<ZinANELayer const*>*>(&__lk, v5, v6, v7);
            if (v10 >= v7) {
              unint64_t v12 = v7;
            }
            else {
              unint64_t v12 = v10;
            }
            *(std::unique_lock<std::mutex> *)&v43.__r_.__value_.__r.__words[1] = __lk;
            v43.__r_.__value_.__r.__words[0] = (std::string::size_type)v11;
            uint64_t v44 = v36;
            uint64_t v45 = 0;
            __lk.__m_ = 0;
            *(void *)&__lk.__owns_ = 0;
            uint64_t v36 = 0;
            unint64_t v46 = v12;
            char v47 = 1;
            operator new();
          }
          std::vector<std::future<ZinCpBasedAllocator::Execute(void)::CpRegionAllocationResult>>::~vector[abi:ne180100](__p);
          goto LABEL_31;
        }
      }
    }
    else
    {
      uint64_t v5 = *(void *)this;
    }
    if (*((void *)this + 1) != v5)
    {
      unint64_t v13 = 0;
      while (1)
      {
        unint64_t v14 = v13 + 1;
        ZinCpBasedAllocator::Execute(void)::$_0::operator()(v13, &v42, v13 + 1, (uint64_t)&v43);
        uint64_t ExecutionBehavior = v46;
        if (v46) {
          break;
        }
        if (!BYTE4(v46))
        {
          *((unsigned char *)this + 968) = 0;
          std::__hash_table<std::__hash_value_type<ZinIrDimension,unsigned long>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,unsigned long>>>::clear((void *)this + 9);
          ZinCpBasedAllocator::UndoParallelPairSchedules(this, v15);
          break;
        }
        std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&v43);
        unint64_t v13 = v14;
        if (v14 >= 0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*((void *)this + 1) - *(void *)this) >> 3)) {
          goto LABEL_31;
        }
      }
      std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&v43);
      return ExecutionBehavior;
    }
LABEL_31:
    ZinCpBasedAllocator::PropagateDimOrderForL2Inplace(this);
    ZinCpBasedAllocator::DemoteL2CircularDepToL2Circular(this);
    ZinCpBasedAllocator::UpdateScheduleForPipelineRunPair(this);
    *(void *)&__lk.__owns_ = 0;
    uint64_t v36 = 0;
    char v37 = 0;
    __lk.__m_ = (std::unique_lock<std::mutex>::mutex_type *)&__lk.__owns_;
    memset(v38, 0, sizeof(v38));
    int v39 = 1065353216;
    ZinCpBasedAllocator::SetMemoryPressure(this, (ZinIrMemoryPressureAnalyzer *)&__lk);
    if (*((void *)this + 63))
    {
      uint64_t v16 = *(void *)(***((void ***)this + 40) + 16);
      if (*((char *)this + 967) >= 0) {
        size_t v17 = *((unsigned __int8 *)this + 967);
      }
      else {
        size_t v17 = *((void *)this + 119);
      }
      uint64_t v18 = &v34;
      std::string::basic_string[abi:ne180100]((uint64_t)&v34, v17 + 35);
      if ((v34.__r_.__value_.__r.__words[2] & 0x8000000000000000) != 0) {
        uint64_t v18 = (std::string *)v34.__r_.__value_.__r.__words[0];
      }
      if (v17)
      {
        if (*((char *)this + 967) >= 0) {
          uint64_t v19 = (char *)this + 944;
        }
        else {
          uint64_t v19 = (char *)*((void *)this + 118);
        }
        memmove(v18, v19, v17);
      }
      strcpy((char *)v18 + v17, ".CpAllocationBeforePromotion.debug.");
      int v20 = *(char *)(v16 + 47);
      if (v20 >= 0) {
        uint64_t v21 = (const std::string::value_type *)(v16 + 24);
      }
      else {
        uint64_t v21 = *(const std::string::value_type **)(v16 + 24);
      }
      if (v20 >= 0) {
        std::string::size_type v22 = *(unsigned __int8 *)(v16 + 47);
      }
      else {
        std::string::size_type v22 = *(void *)(v16 + 32);
      }
      uint64_t v23 = std::string::append(&v34, v21, v22);
      long long v24 = *(_OWORD *)&v23->__r_.__value_.__l.__data_;
      v43.__r_.__value_.__r.__words[2] = v23->__r_.__value_.__r.__words[2];
      *(_OWORD *)&v43.__r_.__value_.__l.__data_ = v24;
      v23->__r_.__value_.__l.__size_ = 0;
      v23->__r_.__value_.__r.__words[2] = 0;
      v23->__r_.__value_.__r.__words[0] = 0;
      unsigned __int8 v25 = std::string::append(&v43, ".txt", 4uLL);
      long long v26 = *(_OWORD *)&v25->__r_.__value_.__l.__data_;
      std::string::size_type v41 = v25->__r_.__value_.__r.__words[2];
      *(_OWORD *)std::string __p = v26;
      v25->__r_.__value_.__l.__size_ = 0;
      v25->__r_.__value_.__r.__words[2] = 0;
      v25->__r_.__value_.__r.__words[0] = 0;
      if (SHIBYTE(v43.__r_.__value_.__r.__words[2]) < 0) {
        operator delete(v43.__r_.__value_.__l.__data_);
      }
      if (SHIBYTE(v34.__r_.__value_.__r.__words[2]) < 0) {
        operator delete(v34.__r_.__value_.__l.__data_);
      }
      uint64_t v27 = MEMORY[0x263F8C310] + 64;
      v48[0] = MEMORY[0x263F8C310] + 64;
      uint64_t v28 = (std::string::size_type *)MEMORY[0x263F8C2B0];
      std::string::size_type v29 = *(void *)(MEMORY[0x263F8C2B0] + 16);
      v43.__r_.__value_.__r.__words[0] = *(void *)(MEMORY[0x263F8C2B0] + 8);
      *(std::string::size_type *)((char *)v43.__r_.__value_.__r.__words
                                + *(void *)(v43.__r_.__value_.__r.__words[0] - 24)) = v29;
      float v30 = (std::ios_base *)((char *)&v43 + *(void *)(v43.__r_.__value_.__r.__words[0] - 24));
      std::ios_base::init(v30, &v43.__r_.__value_.__r.__words[1]);
      uint64_t v31 = MEMORY[0x263F8C310] + 24;
      v30[1].__vftable = 0;
      v30[1].__fmtflags_ = -1;
      v43.__r_.__value_.__r.__words[0] = v31;
      v48[0] = v27;
      MEMORY[0x21667CDD0](&v43.__r_.__value_.__r.__words[1]);
      std::ofstream::open();
      ZinCpBasedAllocatorUtil::PrintAllocationDecision(&v43, (uint64_t)this + 24, (void *)this + 9);
      if (!std::filebuf::close()) {
        std::ios_base::clear((std::ios_base *)((char *)&v43 + *(void *)(v43.__r_.__value_.__r.__words[0] - 24)), *(_DWORD *)((char *)&v45 + *(void *)(v43.__r_.__value_.__r.__words[0] - 24)) | 4);
      }
      v43.__r_.__value_.__r.__words[0] = *v28;
      *(std::string::size_type *)((char *)v43.__r_.__value_.__r.__words
                                + *(void *)(v43.__r_.__value_.__r.__words[0] - 24)) = v28[3];
      MEMORY[0x21667CDE0](&v43.__r_.__value_.__r.__words[1]);
      std::ostream::~ostream();
      MEMORY[0x21667D2B0](v48);
      if (SHIBYTE(v41) < 0) {
        operator delete(__p[0]);
      }
    }
    while (1)
    {
      v43.__r_.__value_.__s.__data_[0] = 0;
      ZinCpBasedAllocator::PromoteResidentToInplace(this, (ZinIrMemoryPressureAnalyzer *)&__lk, (BOOL *)&v43);
      ZinCpBasedAllocator::PromoteNonResidentToResident(this, (ZinIrMemoryPressureAnalyzer *)&__lk, (BOOL *)&v43);
      uint64_t ExecutionBehavior = ZinCpBasedAllocator::PromoteChainToL2Dependent(this, (ZinIrMemoryPressureAnalyzer *)&__lk, (BOOL *)&v43);
      if (ExecutionBehavior) {
        break;
      }
      if (!v43.__r_.__value_.__s.__data_[0])
      {
        ZinCpBasedAllocator::PromoteResidentToL2Dependent(this, (ZinIrMemoryPressureAnalyzer *)&__lk);
        ZinCpBasedAllocator::PromoteParallelExecutionBetweenSplitBranches((ZinIrOpLayer ****)this, (ZinIrMemoryPressureAnalyzer *)&__lk);
        uint64_t ExecutionBehavior = ZinCpBasedAllocator::VerifyAllocationDecision(this, (ZinIrMemoryPressureAnalyzer *)&__lk);
        if (!ExecutionBehavior)
        {
          if (*((unsigned char *)this + 968))
          {
            ZinCpBasedAllocatorUtil::PrintAllocationDecision((void *)this + 47, (uint64_t)this + 24, (void *)this + 9);
          }
          else
          {
            std::__hash_table<std::__hash_value_type<ZinIrDimension,unsigned long>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,unsigned long>>>::clear((void *)this + 9);
            ZinCpBasedAllocator::UndoParallelPairSchedules(this, v32);
          }
          if (*((void *)this + 63)) {
            std::ofstream::close((void *)this + 47);
          }
          uint64_t ExecutionBehavior = 0;
        }
        break;
      }
    }
    std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)v38);
    std::__tree<std::unique_ptr<ZinIrMemoryPressureAnalyzer::Allocation const>,ZinIrMemoryPressureAnalyzer::PointerComparator,std::allocator<std::unique_ptr<ZinIrMemoryPressureAnalyzer::Allocation const>>>::destroy((uint64_t)&__lk, *(void **)&__lk.__owns_);
  }
  return ExecutionBehavior;
}

void sub_211373DE0()
{
}

void sub_211373DF8()
{
}

void sub_211373E0C(void *a1, int a2)
{
  if (a2) {
    __clang_call_terminate(a1);
  }
  JUMPOUT(0x211373E28);
}

uint64_t ZinCpBasedAllocator::CreateExecutionBehavior(ZinCpBasedAllocator *this)
{
  uint64_t v2 = (ZinIrOpLayer ***)*((void *)this + 40);
  unsigned int v3 = *v2;
  uint64_t v4 = v2[1];
  if (*v2 != v4)
  {
    do
    {
      uint64_t v5 = *v3;
      if (ZinIrOpLayer::IsANELayer(*v3) && ZinCpBasedAllocator::SetLayerExecutionBehavior(this, v5)) {
        return 3;
      }
      ++v3;
    }
    while (v3 != v4);
    uint64_t v6 = (const ZinIrOpLayerGraph ****)*((void *)this + 40);
    unint64_t v7 = *v6;
    long long v8 = v6[1];
    if (*v6 != v8)
    {
      uint64_t v65 = v6[1];
      while (1)
      {
        unint64_t v9 = *v7;
        unint64_t v10 = (ZinIrRegAllocUtil *)(*((uint64_t (**)(const ZinIrOpLayerGraph **, void, void))**v7 + 4))(*v7, 0, 0);
        if (!*((unsigned char *)this + 969))
        {
          unint64_t v12 = v10;
          if (ZinIrRegAllocUtil::IsChainable(v10, *((const ZinIrTensor **)this + 42), v11))
          {
            unint64_t v13 = (const ZinNELayer *)*((void *)v12 + 12);
            unint64_t v14 = (const ZinPELayer *)**((void **)v13 + 14);
            if (ZinIrOpLayer::IsNELayer(v13))
            {
              if (ZinCpBasedAllocator::SetNPChainExecutionBehavior(this, v13, v14, 0, 0)
                || ZinCpBasedAllocator::SetNPChainExecutionBehavior(this, v13, v14, 1, 1))
              {
                return 3;
              }
            }
            else if (ZinCpBasedAllocator::SetPNChainExecutionBehavior(this, v13, v14, 0, 0) {
                   || ZinCpBasedAllocator::SetPNChainExecutionBehavior(this, v13, v14, 1, 1))
            }
            {
              return 3;
            }
          }
        }
        ZinIrInPlaceUpdate::IsInPlaceable(*((ZinIrTensor **)this + 127), (const ZinANELayer *)v9, v9[19], 2, *(unsigned char *)(*((void *)this + 42) + 1115), &v72);
        long long v15 = v73;
        if (v73 != v72)
        {
          int v67 = (char *)v9;
          std::string __p = &v67;
          uint64_t v16 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>>>::__emplace_unique_key_args<ZinANELayer const*,std::piecewise_construct_t const&,std::tuple<ZinANELayer const*&&>,std::tuple<>>((uint64_t)this + 112, &v67, (uint64_t)&std::piecewise_construct, (void **)&__p);
          unint64_t v17 = *(void *)(*(void *)(v16[3] + 32) + 8);
          uint64_t v18 = (*((uint64_t (**)(const ZinIrOpLayerGraph **, void, void))*v9 + 4))(v9, 0, 0);
          long long v15 = v72;
          uint64_t v19 = v73;
          if (v72 != v73) {
            break;
          }
        }
LABEL_48:
        if (v15)
        {
          uint64_t v73 = v15;
          operator delete(v15);
        }
        if (++v7 == v8) {
          goto LABEL_51;
        }
      }
      int v20 = (ZinIrTensor *)v18;
      int v66 = v7;
      while (2)
      {
        unint64_t v21 = *v15;
        uint64_t v22 = *((void *)v9[11] + *v15);
        uint64_t v23 = (ZinIrTensor *)(*(uint64_t (**)(uint64_t, void, void))(*(void *)v22 + 32))(v22, 0, 0);
        ZinIrTensor::GetDimensionOrderHint(v23, (uint64_t)&__p);
        ZinIrTensor::GetDimensionOrderHint(v20, (uint64_t)&v67);
        long long v24 = __p;
        if (v68 - v67 != v70 - (unsigned char *)__p)
        {
          BOOL v28 = 0;
          goto LABEL_28;
        }
        if (v67 == v68)
        {
          BOOL v28 = 1;
          if (v67) {
            goto LABEL_29;
          }
        }
        else
        {
          unsigned __int8 v25 = v67 + 4;
          long long v26 = (int *)__p;
          do
          {
            int v27 = *v26++;
            BOOL v28 = *((_DWORD *)v25 - 1) == v27;
            BOOL v29 = *((_DWORD *)v25 - 1) != v27 || v25 == v68;
            v25 += 4;
          }
          while (!v29);
LABEL_28:
          if (v67)
          {
LABEL_29:
            int64x2_t v68 = v67;
            operator delete(v67);
            long long v24 = __p;
          }
        }
        if (v24)
        {
          int v70 = v24;
          operator delete(v24);
        }
        uint64_t v30 = *((void *)v23 + 13);
        if (v30) {
          LODWORD(v3std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = *(_DWORD *)(v30 + 96);
        }
        uint64_t v31 = *((void *)v20 + 13);
        if (v31) {
          LODWORD(v31) = *(_DWORD *)(v31 + 96);
        }
        if (v30 == v31 && v28)
        {
          LayerCycleAndFootprintEstimator::GetReadBehaviors((uint64_t **)v16[3], (char **)&__p);
          uint64_t v33 = *((void *)__p + v21);
          int v70 = __p;
          operator delete(__p);
          unint64_t v34 = *(void *)(v33 + 8);
          LayerCycleAndFootprintEstimator::GetReadBehaviors((uint64_t **)v16[3], (char **)&__p);
          uint64_t v35 = *((void *)__p + v21);
          int v70 = __p;
          operator delete(__p);
          if (v34 <= v17) {
            unint64_t v36 = v17;
          }
          else {
            unint64_t v36 = v34;
          }
          *(void *)(v35 + 112) = v36;
        }
        if (++v15 == v19)
        {
          long long v15 = v72;
          unint64_t v7 = v66;
          long long v8 = v65;
          goto LABEL_48;
        }
        continue;
      }
    }
  }
LABEL_51:
  char v37 = (ZinCpBasedAllocator *)*((void *)this + 3);
  if (v37 != (ZinCpBasedAllocator *)((char *)this + 32))
  {
    do
    {
      uint64_t v38 = (ZinIrTensor *)*((void *)v37 + 4);
      std::string __p = 0;
      int v70 = 0;
      uint64_t v71 = 0;
      int ShouldUseL2Dependent = ZinIrRegAllocUtil::ShouldUseL2Dependent(v38, *((const ZinIrTensor **)this + 42), (char **)&__p);
      int v40 = (char *)__p;
      if (v70 == __p) {
        int ShouldUseL2Dependent = 0;
      }
      if (ShouldUseL2Dependent == 1)
      {
        uint64_t v41 = 0;
        unint64_t v42 = 0;
        do
        {
          uint64_t v44 = *(const ZinNELayer **)&v40[v41];
          std::string v43 = *(const ZinPELayer **)&v40[v41 + 8];
          if (ZinIrOpLayer::IsNELayer(v44))
          {
            ZinCpBasedAllocator::SetNPL2DepExecutionBehavior(this, v44, v43, 0, 0, 0);
            ZinCpBasedAllocator::SetNPL2DepExecutionBehavior(this, v44, v43, 1u, 1, 1);
          }
          else
          {
            ZinCpBasedAllocator::SetPNL2DepExecutionBehavior(this, v44, v43, 0, 0);
            ZinCpBasedAllocator::SetPNL2DepExecutionBehavior(this, v44, v43, 1, 1u);
          }
          ++v42;
          int v40 = (char *)__p;
          v41 += 16;
        }
        while (v42 < (v70 - (unsigned char *)__p) >> 4);
      }
      if (v40)
      {
        int v70 = v40;
        operator delete(v40);
      }
      uint64_t v45 = (ZinCpBasedAllocator *)*((void *)v37 + 1);
      if (v45)
      {
        do
        {
          unint64_t v46 = v45;
          uint64_t v45 = *(ZinCpBasedAllocator **)v45;
        }
        while (v45);
      }
      else
      {
        do
        {
          unint64_t v46 = (ZinCpBasedAllocator *)*((void *)v37 + 2);
          BOOL v29 = *(void *)v46 == (void)v37;
          char v37 = v46;
        }
        while (!v29);
      }
      char v37 = v46;
    }
    while (v46 != (ZinCpBasedAllocator *)((char *)this + 32));
  }
  char v47 = (ZinIrOpLayer ***)*((void *)this + 40);
  long long v48 = *v47;
  uint64_t v49 = v47[1];
  if (*v47 != v49)
  {
    do
    {
      int v50 = *v48;
      if (ZinIrOpLayer::IsANELayer(*v48))
      {
        int v67 = (char *)v50;
        int v51 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::find<ZinIrTensor *>((void *)this + 14, &v67);
        if (v51)
        {
          uint64_t v52 = v51[3];
          uint64_t v53 = *(void **)(v52 + 32);
          if (v53[5]) {
            BOOL v54 = v53[9] == 0;
          }
          else {
            BOOL v54 = 1;
          }
          if (!v54 || ((uint64_t v55 = v53[7], v56 = v53[11], v55) ? (v57 = v56 == 0) : (v57 = 1), !v57)) {
LABEL_98:
          }
            ZinAssertImpl("Either chain or l2-dep cost should be set, not both.");
          unint64_t v58 = 0;
          while (1)
          {
            (*(void (**)(void **__return_ptr))(*(void *)v67 + 512))(&__p);
            int v59 = __p;
            int64x2_t v60 = v70;
            if (__p)
            {
              int v70 = __p;
              operator delete(__p);
            }
            if (v58 >= (v60 - v59) >> 3) {
              break;
            }
            LayerCycleAndFootprintEstimator::GetReadBehaviors((uint64_t **)v52, (char **)&__p);
            uint64_t v61 = (void *)*((void *)__p + v58);
            int v70 = __p;
            operator delete(__p);
            if (v61[5]) {
              BOOL v62 = v61[9] == 0;
            }
            else {
              BOOL v62 = 1;
            }
            if (v62)
            {
              ++v58;
              if (!v61[7] || v61[11] == 0) {
                continue;
              }
            }
            goto LABEL_98;
          }
        }
      }
      ++v48;
    }
    while (v48 != v49);
  }
  ZinCpBasedAllocator::NormalizeCycles(this);
  return 0;
}

void sub_21137441C(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, void *a17, uint64_t a18, uint64_t a19, uint64_t a20,void *__p,uint64_t a22)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinCpBasedAllocator::CreateRegions(ZinCpBasedAllocator *this)
{
  uint64_t v1 = *((void *)this + 41);
  uint64_t v2 = *((void *)this + 42);
  BOOL v3 = *(unsigned char *)(v2 + 1114) == 0;
  uint64_t v4 = 3000;
  if (!*(unsigned char *)(v2 + 1114)) {
    uint64_t v4 = 10500;
  }
  unint64_t v93 = v4;
  uint64_t v5 = 70;
  int v6 = *(_DWORD *)(v2 + 8);
  if (v3) {
    uint64_t v5 = 150;
  }
  unint64_t v96 = v5;
  uint64_t v7 = 20;
  if (v3) {
    uint64_t v7 = 100;
  }
  unint64_t v92 = v7;
  uint64_t v131 = 0;
  v132 = 0;
  BOOL v8 = v6 < 16;
  uint64_t v9 = 12;
  v133 = 0;
  if (v8) {
    uint64_t v9 = 10;
  }
  unint64_t v103 = v9;
  long long v129 = 0;
  unint64_t v130 = 0;
  unint64_t v127 = 0;
  v128 = (uint64_t *)&v129;
  v125 = (uint64_t *)&v126;
  v126 = 0;
  v123 = 0;
  unint64_t v124 = 0;
  unint64_t v121 = 0;
  v122 = &v123;
  int v119 = (uint64_t *)&v120;
  v120 = 0;
  memset(v117, 0, sizeof(v117));
  int v118 = 1065353216;
  if (!*(void *)(v1 + 344)) {
    ZinAssertImpl("Must run scheduler first");
  }
  unint64_t v10 = this;
  std::map<ZinIrBasicBlock *,std::vector<ZinIrOpLayer *>,ScheduleComparator,std::allocator<std::pair<ZinIrBasicBlock * const,std::vector<ZinIrOpLayer *>>>>::map[abi:ne180100]((uint64_t *)&v115, v1 + 328);
  uint64_t v11 = v115;
  v102 = v10;
  if (v115 != v116)
  {
    char v98 = 0;
    unint64_t v12 = 0;
    unint64_t v13 = 0;
    uint64_t v100 = 0;
    int v105 = (ZinCpBasedAllocator *)((char *)v10 + 1048);
    int v94 = (void *)((char *)v10 + 72);
    int64x2_t v95 = (void *)((char *)v10 + 112);
    do
    {
      unint64_t v106 = v13;
      unint64_t v14 = (char *)v11[5];
      uint64_t v15 = (char *)v11[6] - v14;
      if (!v15) {
        goto LABEL_109;
      }
      uint64_t v16 = 0;
      unint64_t v17 = v15 >> 3;
      do
      {
        unint64_t v18 = v16 + 1;
        if (v16 + 1 >= v17) {
          uint64_t v19 = 0;
        }
        else {
          uint64_t v19 = *(ZinIrOpLayer **)&v14[8 * v18];
        }
        int v20 = *(ZinIrOpLayer **)&v14[8 * v16];
        if (!ZinIrOpLayer::IsANELayer(v20)) {
          goto LABEL_100;
        }
        int v109 = v20;
        uint64_t v22 = *(void *)v10;
        uint64_t v21 = *((void *)v10 + 1);
        std::string __p = &v109;
        std::__hash_table<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::__unordered_map_hasher<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,true>,std::__unordered_map_equal<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::equal_to<ZinIrOpLayer *>,std::hash<ZinIrOpLayer *>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer * const&>,std::tuple<>>((uint64_t)v117, &v109, (uint64_t)&std::piecewise_construct, (void **)&__p)[3] = 0xAAAAAAAAAAAAAAABLL * ((v21 - v22) >> 3);
        uint64_t v23 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::find<ZinIrTensor *>(v95, &v109);
        v108[0] = 0;
        BOOL v134 = 0;
        ZinCpBasedAllocator::GetEarlyAllocationDecision(v10, v109, v108, &v134);
        unint64_t MaxCycle = LayerCycleAndFootprintEstimator::GetMaxCycle((LayerCycleAndFootprintEstimator *)v23[3], v108[0], v134);
        if (*(unsigned char *)((*(uint64_t (**)(ZinANELayer *, void, void))(*(void *)v109 + 32))(v109, 0, 0)+ 144))
        {
          uint64_t v25 = (*(uint64_t (**)(ZinANELayer *, void, void))(*(void *)v109 + 32))(v109, 0, 0);
          if (!*(unsigned char *)(v25 + 144)) {
            std::__throw_bad_optional_access[abi:ne180100]();
          }
          uint64_t v26 = *(unsigned __int16 *)(v25 + 128);
        }
        else
        {
          uint64_t v26 = -1;
        }
        long long v97 = v19;
        int v27 = v11[5];
        unint64_t v28 = v16 + 1;
        if (v18 >= v11[6] - v27) {
          goto LABEL_29;
        }
        while (1)
        {
          BOOL v29 = (ZinIrOpLayer *)v27[v28];
          if (ZinIrOpLayer::IsEngineLayer(v29)) {
            break;
          }
          ++v28;
          int v27 = v11[5];
          if (v28 >= v11[6] - v27) {
            goto LABEL_29;
          }
        }
        if (*(unsigned char *)((*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)v29 + 32))(v29, 0, 0)+ 144))
        {
          uint64_t v30 = (*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)v29 + 32))(v29, 0, 0);
          if (!*(unsigned char *)(v30 + 144)) {
            std::__throw_bad_optional_access[abi:ne180100]();
          }
          uint64_t v31 = *(unsigned __int16 *)(v30 + 128);
        }
        else
        {
LABEL_29:
          uint64_t v31 = -1;
        }
        v135[0] = 0;
        unsigned int v32 = (const ZinIrTensor *)(*(uint64_t (**)(ZinANELayer *, void, void))(*(void *)v109 + 32))(v109, 0, 0);
        uint64_t RootTensor = (void *)ZinTensorFamilyUtil::GetRootTensor(v105, v32);
        v135[0] = RootTensor;
        if (*((unsigned char *)v10 + 969)
          || (IsChainable = ZinIrRegAllocUtil::IsChainable((ZinIrRegAllocUtil *)RootTensor, *((const ZinIrTensor **)v10 + 42), v34), uint64_t RootTensor = v135[0], !IsChainable))
        {
          uint64_t v100 = v16;
          goto LABEL_45;
        }
        uint64_t v36 = v135[0][12];
        char v37 = **(char ****)(v36 + 112);
        std::string __p = 0;
        __dst = 0;
        unint64_t v114 = 0;
        std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(&__p, *(const void **)(v36 + 88), *(void *)(v36 + 96), (uint64_t)(*(void *)(v36 + 96) - *(void *)(v36 + 88)) >> 3);
        std::vector<ZinGOCLayer const*>::__insert_with_size[abi:ne180100]<std::__wrap_iter<ZinGOCLayer const**>,std::__wrap_iter<ZinGOCLayer const**>>((uint64_t)&__p, (uint64_t)__dst, v37[11], v37[12], (v37[12] - v37[11]) >> 3);
        uint64_t v38 = (unint64_t *)__p;
        if (__p == __dst) {
          goto LABEL_103;
        }
        char v39 = 0;
        do
        {
          while (!v120)
          {
LABEL_40:
            if (++v38 == __dst)
            {
              if (v39) {
                goto LABEL_104;
              }
LABEL_103:
              std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v119, v120);
              v120 = 0;
              unint64_t v121 = 0;
              int v119 = (uint64_t *)&v120;
              goto LABEL_104;
            }
          }
          unint64_t v40 = *v38;
          uint64_t v41 = v120;
          while (1)
          {
            unint64_t v42 = v41[4];
            if (v40 >= v42) {
              break;
            }
LABEL_39:
            uint64_t v41 = (void *)*v41;
            if (!v41) {
              goto LABEL_40;
            }
          }
          if (v42 < v40)
          {
            ++v41;
            goto LABEL_39;
          }
          ++v38;
          char v39 = 1;
        }
        while (v38 != __dst);
LABEL_104:
        int v111 = (ZinIrTensor *)v36;
        std::__tree<ZinIrTensor *>::__emplace_unique_key_args<ZinIrTensor *,ZinIrTensor * const&>(&v119, (unint64_t *)&v111, (uint64_t *)&v111);
        int v111 = (ZinIrTensor *)v37;
        std::__tree<ZinIrTensor *>::__emplace_unique_key_args<ZinIrTensor *,ZinIrTensor * const&>(&v119, (unint64_t *)&v111, (uint64_t *)&v111);
        unint64_t v10 = v102;
        if (v121 >= 4) {
          std::set<unsigned long>::insert[abi:ne180100]<std::__tree_const_iterator<unsigned long,std::__tree_node<unsigned long,void *> *,long>>((uint64_t *)&v122, v119, &v120);
        }
        std::__tree<ZinIrTensor *>::__emplace_unique_key_args<ZinIrTensor *,ZinIrTensor * const&>(&v125, (unint64_t *)v135, (uint64_t *)v135);
        if (__p)
        {
          __dst = __p;
          operator delete(__p);
        }
        uint64_t RootTensor = v135[0];
LABEL_45:
        int v43 = *((unsigned __int8 *)RootTensor + 144);
        if (!std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::find<ZinIrTensor *>(v94, v135))goto LABEL_49; {
        int v45 = ZinIrRegAllocUtil::IsPipelinable((ZinIrTensor *)v135[0], *((const ZinIrTensor **)v10 + 42), v105) ^ 1;
        }
        if (v43) {
          LOBYTE(v45) = 0;
        }
        if ((v45 & 1) == 0)
        {
LABEL_49:
          std::__tree<ZinIrTensor *>::__emplace_unique_key_args<ZinIrTensor *,ZinIrTensor * const&>(&v128, (unint64_t *)v135, (uint64_t *)v135);
          goto LABEL_50;
        }
        if (v98)
        {
LABEL_50:
          unint64_t v46 = v132;
          if (v132 >= v133)
          {
            uint64_t v48 = (v132 - v131) >> 3;
            if ((unint64_t)(v48 + 1) >> 61) {
              std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
            }
            unint64_t v49 = (v133 - v131) >> 2;
            if (v49 <= v48 + 1) {
              unint64_t v49 = v48 + 1;
            }
            if ((unint64_t)(v133 - v131) >= 0x7FFFFFFFFFFFFFF8) {
              unint64_t v50 = 0x1FFFFFFFFFFFFFFFLL;
            }
            else {
              unint64_t v50 = v49;
            }
            if (v50) {
              int v51 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)&v133, v50);
            }
            else {
              int v51 = 0;
            }
            uint64_t v53 = (ZinANELayer **)&v51[8 * v48];
            *uint64_t v53 = v109;
            char v47 = (char *)(v53 + 1);
            uint64_t v55 = v131;
            BOOL v54 = v132;
            if (v132 != v131)
            {
              do
              {
                uint64_t v56 = (ZinANELayer *)*((void *)v54 - 1);
                v54 -= 8;
                *--uint64_t v53 = v56;
              }
              while (v54 != v55);
              BOOL v54 = v131;
            }
            uint64_t v131 = (char *)v53;
            v132 = v47;
            v133 = &v51[8 * v50];
            if (v54) {
              operator delete(v54);
            }
          }
          else
          {
            *(void *)v132 = v109;
            char v47 = v46 + 8;
          }
          v132 = v47;
          unint64_t v52 = v106 + 1;
          char v98 = 1;
          unint64_t v10 = v102;
        }
        else
        {
          char v98 = 0;
          unint64_t v52 = v106;
        }
        v12 += MaxCycle;
        char v57 = 1;
        unint64_t v106 = v52;
        if (v52 <= v96 && v12 <= v93 && v130 < v92 && v127 < v103 && v124 <= 0xB) {
          char v57 = ZinCpBasedAllocator::NeedSplitForInplaceAllocation(v10, v97);
        }
        if (v26 == v31) {
          char v58 = 0;
        }
        else {
          char v58 = v57;
        }
        if (!v43) {
          char v58 = v57;
        }
        if (v58) {
          int v59 = ZinIrRegAllocUtil::IsPipelinable((ZinIrTensor *)v135[0], *((const ZinIrTensor **)v10 + 42), v105) ^ 1;
        }
        else {
          LOBYTE(v59) = 0;
        }
        if (v127 <= v103)
        {
          int v61 = 0;
        }
        else
        {
          if (*((unsigned char *)v10 + 969)) {
            int v60 = 0;
          }
          else {
            int v60 = ZinIrRegAllocUtil::IsChainable((ZinIrRegAllocUtil *)v135[0], *((const ZinIrTensor **)v10 + 42), v44);
          }
          int v61 = v60 ^ 1;
          if ((unint64_t)(v16 - v100) > 2) {
            int v61 = 1;
          }
        }
        if (v26 == v31) {
          char v62 = v59;
        }
        else {
          char v62 = 1;
        }
        if (((v62 & 1) != 0 || v61) && v132 != v131)
        {
          unint64_t v63 = *((void *)v10 + 1);
          if (v63 >= *((void *)v10 + 2))
          {
            uint64_t v64 = std::vector<std::vector<ZinANELayer const*>>::__push_back_slow_path<std::vector<ZinANELayer const*> const&>((uint64_t *)v10, (uint64_t)&v131);
          }
          else
          {
            std::vector<std::vector<DimensionMapping>>::__construct_one_at_end[abi:ne180100]<std::vector<DimensionMapping> const&>((uint64_t)v10, (uint64_t)&v131);
            uint64_t v64 = v63 + 24;
          }
          *((void *)v10 + 1) = v64;
          std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v128, v129);
          long long v129 = 0;
          unint64_t v130 = 0;
          v128 = (uint64_t *)&v129;
          std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v125, v126);
          v126 = 0;
          unint64_t v127 = 0;
          v125 = (uint64_t *)&v126;
          std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v119, v120);
          v120 = 0;
          unint64_t v121 = 0;
          int v119 = (uint64_t *)&v120;
          std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v122, v123);
          unint64_t v106 = 0;
          unint64_t v12 = 0;
          char v98 = 0;
          v123 = 0;
          unint64_t v124 = 0;
          v122 = &v123;
          v132 = v131;
          uint64_t v100 = v16;
        }
LABEL_100:
        unint64_t v14 = (char *)v11[5];
        unint64_t v17 = ((char *)v11[6] - v14) >> 3;
        ++v16;
      }
      while (v18 < v17);
LABEL_109:
      uint64_t v65 = v11[1];
      if (v65)
      {
        do
        {
          int v66 = (void **)v65;
          uint64_t v65 = (void *)*v65;
        }
        while (v65);
      }
      else
      {
        do
        {
          int v66 = (void **)v11[2];
          BOOL v3 = *v66 == v11;
          uint64_t v11 = v66;
        }
        while (!v3);
      }
      uint64_t v11 = v66;
      unint64_t v13 = v106;
    }
    while (v66 != v116);
  }
  if (v132 != v131)
  {
    unint64_t v67 = *((void *)v10 + 1);
    if (v67 >= *((void *)v10 + 2))
    {
      uint64_t v68 = std::vector<std::vector<ZinANELayer const*>>::__push_back_slow_path<std::vector<ZinANELayer const*> const&>((uint64_t *)v10, (uint64_t)&v131);
    }
    else
    {
      std::vector<std::vector<DimensionMapping>>::__construct_one_at_end[abi:ne180100]<std::vector<DimensionMapping> const&>((uint64_t)v10, (uint64_t)&v131);
      uint64_t v68 = v67 + 24;
    }
    *((void *)v10 + 1) = v68;
  }
  uint64_t v69 = (uint64_t **)((char *)v10 + 48);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v10 + 48, *((void **)v10 + 7));
  *((void *)v10 + 6) = (char *)v10 + 56;
  *((void *)v10 + 7) = 0;
  *((void *)v10 + 8) = 0;
  int v70 = (void *)*((void *)v10 + 41);
  uint64_t v71 = (uint64_t *)*v70;
  int v99 = v70 + 1;
  if ((void *)*v70 != v70 + 1)
  {
    int64x2_t v72 = (ZinCpBasedAllocator *)((char *)v10 + 1048);
    uint64_t v73 = (uint64_t *)((char *)v10 + 72);
    int v101 = (void *)((char *)v10 + 72);
    v104 = (ZinCpBasedAllocator *)((char *)v10 + 1048);
    do
    {
      Hal = ZinIrTarget::GetHal(v73, (ZinIrTarget *)v71[4]);
      int64x2_t v76 = Hal + 1;
      int v75 = (void *)*Hal;
      int v107 = Hal + 1;
      if ((uint64_t *)*Hal != Hal + 1)
      {
        do
        {
          uint64_t v77 = v75[4];
          int v111 = 0;
          int v78 = (const ZinIrTensor *)(*(uint64_t (**)(uint64_t, void, void))(*(void *)v77 + 32))(v77, 0, 0);
          int v111 = (ZinIrTensor *)ZinTensorFamilyUtil::GetRootTensor(v72, v78);
          if (!std::__tree<ZinIrOpLayer *,ZinIrIdComparator<ZinIrOpLayer *>,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)v69, (uint64_t *)&v111))
          {
            int v79 = v69;
            __dst = 0;
            unint64_t v114 = 0;
            std::string __p = &__dst;
            ZinIrTensor::GetTensorFamily(v111, (uint64_t)&v109);
            uint64_t v81 = v109;
            long long v80 = v110;
            if (v109 != v110)
            {
              do
              {
                int v82 = *(ZinIrOpLayer **)(*(void *)v81 + 96);
                if (ZinIrOpLayer::IsANELayer(v82))
                {
                  *(void *)v108 = v82;
                  v135[0] = v108;
                  int v83 = std::__hash_table<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::__unordered_map_hasher<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,true>,std::__unordered_map_equal<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::equal_to<ZinIrOpLayer *>,std::hash<ZinIrOpLayer *>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer * const&>,std::tuple<>>((uint64_t)v117, v108, (uint64_t)&std::piecewise_construct, v135);
                  std::__tree<ZinIrTensor *>::__emplace_unique_key_args<ZinIrTensor *,ZinIrTensor * const&>((uint64_t **)&__p, v83 + 3, v83 + 3);
                }
                uint64_t v85 = (ZinIrOpLayer **)*((void *)v82 + 14);
                long long v84 = (ZinIrOpLayer **)*((void *)v82 + 15);
                while (v85 != v84)
                {
                  int v86 = *v85;
                  if (ZinIrOpLayer::IsANELayer(*v85))
                  {
                    *(void *)v108 = v86;
                    v135[0] = v108;
                    int v87 = std::__hash_table<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::__unordered_map_hasher<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,true>,std::__unordered_map_equal<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::equal_to<ZinIrOpLayer *>,std::hash<ZinIrOpLayer *>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer * const&>,std::tuple<>>((uint64_t)v117, v108, (uint64_t)&std::piecewise_construct, v135);
                    std::__tree<ZinIrTensor *>::__emplace_unique_key_args<ZinIrTensor *,ZinIrTensor * const&>((uint64_t **)&__p, v87 + 3, v87 + 3);
                  }
                  ++v85;
                }
                uint64_t v81 = (ZinANELayer *)((char *)v81 + 8);
              }
              while (v81 != v80);
              uint64_t v81 = v109;
            }
            uint64_t v69 = v79;
            if (v81)
            {
              v110 = v81;
              operator delete(v81);
            }
            unint64_t v10 = v102;
            int64x2_t v72 = v104;
            int64x2_t v76 = v107;
            if (v114 > 1)
            {
              if (!std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::find<ZinIrTensor *>(v101, &v111))
              {
                v135[0] = v111;
                int v109 = (ZinANELayer *)v135;
                *((_DWORD *)std::__hash_table<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::__unordered_map_hasher<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,true>,std::__unordered_map_equal<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::equal_to<ZinIrTensor const*>,std::hash<ZinIrTensor const*>,true>,std::allocator<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>>>::__emplace_unique_key_args<ZinIrTensor const*,std::piecewise_construct_t const&,std::tuple<ZinIrTensor const* const&>,std::tuple<>>((uint64_t)v101, v135, (uint64_t)&std::piecewise_construct, (void **)&v109)+ 6) = 1;
              }
              std::__tree<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const*>(v69, (uint64_t *)&v111, (uint64_t *)&v111);
            }
            std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&__p, __dst);
          }
          long long v88 = (uint64_t *)v75[1];
          if (v88)
          {
            do
            {
              uint64_t v89 = v88;
              long long v88 = (uint64_t *)*v88;
            }
            while (v88);
          }
          else
          {
            do
            {
              uint64_t v89 = (uint64_t *)v75[2];
              BOOL v3 = *v89 == (void)v75;
              int v75 = v89;
            }
            while (!v3);
          }
          int v75 = v89;
        }
        while (v89 != v76);
      }
      int v90 = (uint64_t *)v71[1];
      if (v90)
      {
        do
        {
          uint64_t v73 = v90;
          int v90 = (uint64_t *)*v90;
        }
        while (v90);
      }
      else
      {
        do
        {
          uint64_t v73 = (uint64_t *)v71[2];
          BOOL v3 = *v73 == (void)v71;
          uint64_t v71 = v73;
        }
        while (!v3);
      }
      uint64_t v71 = v73;
    }
    while (v73 != v99);
  }
  ZinCpBasedAllocatorUtil::PrintRegionInformation((void *)v10 + 47, (uint64_t *)v10, v69);
  std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::destroy((uint64_t)&v115, v116[0]);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v117);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v119, v120);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v122, v123);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v125, v126);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v128, v129);
  if (v131)
  {
    v132 = v131;
    operator delete(v131);
  }
  return 0;
}

void sub_211374FD8(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,void *a29,uint64_t a30,uint64_t a31,uint64_t a32,void *__p,uint64_t a34,uint64_t a35,char a36,void *a37,uint64_t a38,char a39)
{
  std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::destroy((uint64_t)&a36, a37);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&a39);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy(v39 - 224, *(void **)(v39 - 216));
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy(v39 - 200, *(void **)(v39 - 192));
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy(v39 - 176, *(void **)(v39 - 168));
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy(v39 - 152, *(void **)(v39 - 144));
  uint64_t v41 = *(void **)(v39 - 128);
  if (v41)
  {
    *(void *)(v39 - 12std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v41;
    operator delete(v41);
  }
  _Unwind_Resume(a1);
}

double ZinCpBasedAllocator::Execute(void)::$_0::operator()@<D0>(unint64_t __val@<X1>, _DWORD **a2@<X0>, unint64_t a3@<X2>, uint64_t a4@<X8>)
{
  uint64_t v4 = *a2;
  double result = 0.0;
  *(_OWORD *)a4 = 0u;
  *(_OWORD *)(a4 + 16) = 0u;
  *(_DWORD *)(a4 + 32) = 1065353216;
  *(_DWORD *)(a4 + 4std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  *(unsigned char *)(a4 + 44) = 1;
  if (__val < a3) {
    ZinORToolsConversionUtils::CreateORToolsGraph(*v4 + 24 * __val, __val);
  }
  return result;
}

void sub_2113754C8(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, void *a15, uint64_t a16, int a17, __int16 a18, char a19, char a20,void *__p,uint64_t a22,int a23,__int16 a24,char a25,char a26,void *a27,uint64_t a28,int a29,__int16 a30,char a31,char a32,uint64_t a33,void *a34,uint64_t a35,int a36,__int16 a37,char a38,char a39,uint64_t a40,uint64_t a41,uint64_t a42,int a43,__int16 a44,char a45,char a46,uint64_t a47,char a48)
{
  if (a26 < 0) {
    operator delete(__p);
  }
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&a48);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table(v48 - 144);
  std::unique_ptr<CpAllocGraph>::reset[abi:ne180100]((CpAllocGraph **)(v48 - 96), 0);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table(a11);
  _Unwind_Resume(a1);
}

void ZinCpBasedAllocator::UndoParallelPairSchedules(ZinCpBasedAllocator *this@<X0>, uint64_t *a2@<X8>)
{
  uint64_t v2 = (void *)*((void *)this + 41);
  uint64_t v5 = (uint64_t *)*v2;
  BOOL v3 = v2 + 1;
  uint64_t v4 = v5;
  if (v5 != v3)
  {
    do
    {
      Hal = (ZinIrScheduleUtil *)ZinIrTarget::GetHal(a2, (ZinIrTarget *)v4[4]);
      ZinIrScheduleUtil::GetEngineScheduledLayerGroups(Hal, v28);
      uint64_t v7 = v28[0];
      uint64_t v8 = v28[1];
      while (v7 != v8)
      {
        uint64_t v25 = 0;
        uint64_t v26 = 0;
        uint64_t v27 = 0;
        std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(&v25, *(const void **)v7, *(void *)(v7 + 8), (uint64_t)(*(void *)(v7 + 8) - *(void *)v7) >> 3);
        uint64_t v9 = v25;
        if (v26 - (unsigned char *)v25 == 16)
        {
          uint64_t v10 = *(void *)v25;
          uint64_t v11 = (ZinIrOpLayer *)*((void *)v25 + 1);
          uint64_t v12 = *(void *)(*(void *)v25 + 48);
          std::string __p = 0;
          uint64_t v23 = 0;
          uint64_t v24 = 0;
          int IntermediateLayers = ZinTensorFamilyUtil::GetIntermediateLayers(v10, v11, 0, 0, &__p);
          uint64_t v14 = v12 + 1;
          uint64_t v15 = (uint64_t *)__p;
          if (IntermediateLayers)
          {
            uint64_t v16 = v12 + 1;
          }
          else
          {
            unint64_t v17 = v23;
            unint64_t v18 = (uint64_t *)__p;
            uint64_t v16 = v12 + 1;
            if (__p != v23)
            {
              do
              {
                uint64_t v19 = *v18++;
                uint64_t v16 = v14 + 1;
                *(void *)(v19 + 48) = v14++;
              }
              while (v18 != v17);
            }
          }
          *((void *)v11 + 6) = v16;
          *((void *)v11 + 7) = 0;
          if (v15)
          {
            uint64_t v23 = v15;
            operator delete(v15);
          }
          uint64_t v9 = v25;
        }
        if (v9)
        {
          uint64_t v26 = v9;
          operator delete(v9);
        }
        v7 += 24;
      }
      uint64_t v25 = v28;
      std::vector<std::vector<ZinIrOpLayer *>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v25);
      int v20 = (uint64_t *)v4[1];
      if (v20)
      {
        do
        {
          a2 = v20;
          int v20 = (uint64_t *)*v20;
        }
        while (v20);
      }
      else
      {
        do
        {
          a2 = (uint64_t *)v4[2];
          BOOL v21 = *a2 == (void)v4;
          uint64_t v4 = a2;
        }
        while (!v21);
      }
      uint64_t v4 = a2;
    }
    while (a2 != v3);
  }
}

void sub_2113756F8(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11, uint64_t a12, char *a13, char *a14, uint64_t a15, char a16)
{
  if (__p) {
    operator delete(__p);
  }
  if (a13)
  {
    a14 = a13;
    operator delete(a13);
  }
  a13 = &a16;
  std::vector<std::vector<ZinIrOpLayer *>>::__destroy_vector::operator()[abi:ne180100]((void ***)&a13);
  _Unwind_Resume(a1);
}

void **std::vector<std::future<ZinCpBasedAllocator::Execute(void)::CpRegionAllocationResult>>::~vector[abi:ne180100](void **a1)
{
  uint64_t v2 = (char *)*a1;
  if (*a1)
  {
    BOOL v3 = (char *)a1[1];
    uint64_t v4 = *a1;
    if (v3 != v2)
    {
      do
      {
        int v6 = (atomic_ullong *)*((void *)v3 - 1);
        v3 -= 8;
        uint64_t v5 = v6;
        if (v6 && !atomic_fetch_add(v5 + 1, 0xFFFFFFFFFFFFFFFFLL)) {
          (*(void (**)(atomic_ullong *))(*v5 + 16))(v5);
        }
      }
      while (v3 != v2);
      uint64_t v4 = *a1;
    }
    a1[1] = v2;
    operator delete(v4);
  }
  return a1;
}

uint64_t ZinCpBasedAllocator::PropagateDimOrderForL2Inplace(ZinCpBasedAllocator *this)
{
  uint64_t v1 = (char *)*((void *)this + 3);
  uint64_t v2 = (char *)this + 32;
  if (v1 != (char *)this + 32)
  {
    BOOL v3 = (void *)((char *)this + 72);
    uint64_t v4 = (ZinCpBasedAllocator *)((char *)this + 1048);
    uint64_t v5 = (uint64_t **)((char *)this + 1024);
    int v6 = (void *)((char *)this + 1032);
    do
    {
      uint64_t v27 = (ZinIrTensor *)*((void *)v1 + 4);
      std::string __p = &v27;
      uint64_t v7 = std::__hash_table<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::__unordered_map_hasher<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,true>,std::__unordered_map_equal<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::equal_to<ZinIrTensor const*>,std::hash<ZinIrTensor const*>,true>,std::allocator<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>>>::__emplace_unique_key_args<ZinIrTensor const*,std::piecewise_construct_t const&,std::tuple<ZinIrTensor const* const&>,std::tuple<>>((uint64_t)v3, &v27, (uint64_t)&std::piecewise_construct, (void **)&__p);
      if (CpAllocUtils::IsL2Inplace(*((_DWORD *)v7 + 6)))
      {
        LastConsumer = (void *)ZinIrRegAllocUtil::GetLastConsumer(v27, v8);
        uint64_t v10 = (*(uint64_t (**)(void *, void, void))(*LastConsumer + 32))(LastConsumer, 0, 0);
        uint64_t v11 = LastConsumer[11];
        if (LastConsumer[12] == v11) {
          goto LABEL_33;
        }
        uint64_t v12 = (uint64_t *)v10;
        unint64_t v13 = 0;
        while (1)
        {
          uint64_t v14 = (const ZinIrTensor *)(*(uint64_t (**)(void, void, void))(**(void **)(v11 + 8 * v13)
                                                                                       + 32))(*(void *)(v11 + 8 * v13), 0, 0);
          uint64_t RootTensor = (ZinIrTensor *)ZinTensorFamilyUtil::GetRootTensor(v4, v14);
          if (RootTensor == v27) {
            break;
          }
          ++v13;
          uint64_t v11 = LastConsumer[11];
          if (v13 >= (LastConsumer[12] - v11) >> 3) {
            goto LABEL_33;
          }
        }
        uint64_t v16 = (void *)*v6;
        if (*v6)
        {
          unint64_t v17 = v6;
          do
          {
            unint64_t v18 = v16[4];
            BOOL v19 = v18 >= (unint64_t)v12;
            if (v18 >= (unint64_t)v12) {
              int v20 = v16;
            }
            else {
              int v20 = v16 + 1;
            }
            if (v19) {
              unint64_t v17 = v16;
            }
            uint64_t v16 = (void *)*v20;
          }
          while (*v20);
          if (v17 != v6 && (unint64_t)v12 >= v17[4]) {
LABEL_33:
          }
            ZinAssertImpl("internal error: PropagateDimOrderForL2Inplace");
        }
        if (ZinIrTensor::HasFlexDimensionOrderHint(RootTensor)
          && ZinTensorFamilyUtil::HasReshapeInTensorFamily(v4, v27))
        {
          DimensionOrderHint::DimensionOrderHint(&__p, 1);
          if (ZinIrTensor::SetDimensionOrderHint(v27, (const DimensionOrderHint *)&__p, 1)) {
            ZinAssertImpl("fail to set dim order in PropagateDimOrderForL2Inplace.");
          }
          if (__p)
          {
            unint64_t v26 = (unint64_t)__p;
            operator delete(__p);
          }
        }
        std::string __p = v12;
        unint64_t v26 = v13;
        std::__tree<std::__value_type<ZinIrTensor *,unsigned long>,std::__map_value_compare<ZinIrTensor *,std::__value_type<ZinIrTensor *,unsigned long>,std::less<ZinIrTensor *>,true>,std::allocator<std::__value_type<ZinIrTensor *,unsigned long>>>::__emplace_unique_key_args<ZinIrTensor *,std::pair<ZinIrTensor *,unsigned long>>(v5, (unint64_t *)&__p, (uint64_t *)&__p);
        if ((ZinIrRegAllocUtil::AdjustDimOrderForInplace(v12[12], (uint64_t)v5, v3, v4) & 1) == 0) {
          ZinAssertImpl("failed to post-process in PropagateDimOrderForL2Inplace.");
        }
      }
      BOOL v21 = (char *)*((void *)v1 + 1);
      if (v21)
      {
        do
        {
          uint64_t v22 = v21;
          BOOL v21 = *(char **)v21;
        }
        while (v21);
      }
      else
      {
        do
        {
          uint64_t v22 = (char *)*((void *)v1 + 2);
          BOOL v23 = *(void *)v22 == (void)v1;
          uint64_t v1 = v22;
        }
        while (!v23);
      }
      uint64_t v1 = v22;
    }
    while (v22 != v2);
  }
  return 0;
}

void sub_211375A34(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, void *__p, uint64_t a10)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinCpBasedAllocator::DemoteL2CircularDepToL2Circular(ZinCpBasedAllocator *this)
{
  uint64_t v1 = this;
  uint64_t v52 = *MEMORY[0x263EF8340];
  v46[0] = 0;
  v46[1] = 0;
  char v47 = 0;
  int v45 = v46;
  memset(v48, 0, sizeof(v48));
  int v49 = 1065353216;
  ZinCpBasedAllocator::SetMemoryPressure(this, (ZinIrMemoryPressureAnalyzer *)&v45);
  uint64_t v2 = (void *)*((void *)v1 + 3);
  BOOL v3 = (void *)((char *)v1 + 32);
  if (v2 != (void *)((char *)v1 + 32))
  {
    uint64_t v4 = (void *)((char *)v1 + 72);
    uint64_t v5 = (ZinCpBasedAllocator *)((char *)v1 + 1048);
    uint64_t v33 = v1;
    uint64_t v31 = (char *)v1 + 32;
    do
    {
      uint64_t v44 = (ZinIrTensor *)v2[4];
      *(void *)buf = &v44;
      if (*((_DWORD *)std::__hash_table<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::__unordered_map_hasher<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,true>,std::__unordered_map_equal<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::equal_to<ZinIrTensor const*>,std::hash<ZinIrTensor const*>,true>,std::allocator<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>>>::__emplace_unique_key_args<ZinIrTensor const*,std::piecewise_construct_t const&,std::tuple<ZinIrTensor const* const&>,std::tuple<>>((uint64_t)v4, &v44, (uint64_t)&std::piecewise_construct, (void **)buf)+ 6) == 7)
      {
        uint64_t v41 = 0;
        unint64_t v42 = 0;
        uint64_t v43 = 0;
        unsigned int v32 = v2;
        if ((ZinIrRegAllocUtil::IsL2Dependentable(v44, *((const ZinIrTensor **)v1 + 42), &v41, v5) & 1) == 0) {
          ZinAssertImpl("Unsuccesfull CP result");
        }
        int v6 = v41;
        unint64_t v34 = v42;
        if (v41 != v42)
        {
          char v35 = 1;
          do
          {
            uint64_t v7 = *(void *)v6;
            uint64_t v8 = (void *)*((void *)v6 + 1);
            *(void *)&buf[8] = 0;
            *(void *)&uint8_t buf[16] = 0;
            LOBYTE(v51) = 0;
            *(void *)buf = &buf[8];
            unint64_t v9 = *(void *)(v7 + 48);
            if (v9 <= v8[7] + v8[6])
            {
              do
              {
                uint64_t v38 = 0;
                uint64_t v39 = 0;
                char v40 = 0;
                v36[1] = v9;
                std::string __p = &v38;
                v36[0] = v9;
                ZinIrMemoryPressureAnalyzer::GetPeakPressure((uint64_t)&v45, v36, (uint64_t)&__p);
                std::set<ZinIrMemoryPressureAnalyzer::Allocation const*,ZinIrMemoryPressureAnalyzer::PointerComparator,std::allocator<ZinIrMemoryPressureAnalyzer::Allocation const*>>::insert[abi:ne180100]<std::__tree_const_iterator<ZinIrMemoryPressureAnalyzer::Allocation const*,std::__tree_node<ZinIrMemoryPressureAnalyzer::Allocation const*,void *> *,long>>((uint64_t *)buf, __p, &v38);
                std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&__p, v38);
                ++v9;
              }
              while (v9 <= v8[7] + v8[6]);
              uint64_t v10 = *(void **)buf;
              if (*(unsigned char **)buf != &buf[8])
              {
                unint64_t v11 = 0;
                do
                {
                  uint64_t v12 = (void *)v10[4];
                  if ((*(unsigned int (**)(void *))(*v12 + 24))(v12) == 1) {
                    goto LABEL_12;
                  }
                  if (!(*(unsigned int (**)(void *))(*v12 + 24))(v12))
                  {
                    unint64_t v13 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::find<ZinIrTensor *>(v4, v12 + 4);
                    if (!v13) {
                      std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
                    }
                    if (CpAllocUtils::IsResident(*((_DWORD *)v13 + 6))) {
LABEL_12:
                    }
                      v11 += v12[1];
                  }
                  uint64_t v14 = (void *)v10[1];
                  if (v14)
                  {
                    do
                    {
                      uint64_t v15 = v14;
                      uint64_t v14 = (void *)*v14;
                    }
                    while (v14);
                  }
                  else
                  {
                    do
                    {
                      uint64_t v15 = (unsigned char *)v10[2];
                      BOOL v16 = *(void *)v15 == (void)v10;
                      uint64_t v10 = v15;
                    }
                    while (!v16);
                  }
                  uint64_t v10 = v15;
                }
                while (v15 != &buf[8]);
                if (v11 > *(void *)(*((void *)v33 + 42) + 408))
                {
                  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)buf, *(void **)&buf[8]);
                  uint64_t v1 = v33;
                  goto LABEL_44;
                }
              }
            }
            std::string __p = 0;
            uint64_t v38 = 0;
            uint64_t v39 = 0;
            std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(&__p, *(const void **)(v7 + 88), *(void *)(v7 + 96), (uint64_t)(*(void *)(v7 + 96) - *(void *)(v7 + 88)) >> 3);
            unint64_t v17 = (uint64_t *)__p;
            unint64_t v18 = v38;
            while (v17 != v18)
            {
              uint64_t v19 = *v17;
              v36[0] = 0;
              int v20 = (const ZinIrTensor *)(*(uint64_t (**)(uint64_t, void, void))(*(void *)v19 + 32))(v19, 0, 0);
              v36[0] = ZinTensorFamilyUtil::GetRootTensor(v5, v20);
              BOOL v21 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::find<ZinIrTensor *>(v4, v36);
              uint64_t v22 = v21;
              if (v21
                && ((CpAllocUtils::IsL2Dependent(*((_DWORD *)v21 + 6)) & 1) != 0
                 || CpAllocUtils::IsChain(*((_DWORD *)v22 + 6))))
              {
                char v35 = 0;
                break;
              }
              ++v17;
            }
            BOOL v23 = (const ZinIrTensor *)(*(uint64_t (**)(void *, void, void))(*v8 + 32))(v8, 0, 0);
            v36[0] = ZinTensorFamilyUtil::GetRootTensor(v5, v23);
            uint64_t v24 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::find<ZinIrTensor *>(v4, v36);
            uint64_t v25 = v24;
            if (v24
              && ((CpAllocUtils::IsL2Dependent(*((_DWORD *)v24 + 6)) & 1) != 0
               || CpAllocUtils::IsChain(*((_DWORD *)v25 + 6))))
            {
              char v35 = 0;
              int v26 = 6;
            }
            else if (v35)
            {
              int v26 = 0;
            }
            else
            {
              int v26 = 6;
            }
            if (__p)
            {
              uint64_t v38 = (uint64_t *)__p;
              operator delete(__p);
            }
            std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)buf, *(void **)&buf[8]);
            if (v26) {
              break;
            }
            v6 += 16;
          }
          while (v6 != v34);
          uint64_t v1 = v33;
          if (v35) {
            goto LABEL_49;
          }
LABEL_44:
          *(void *)buf = &v44;
          *((_DWORD *)std::__hash_table<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::__unordered_map_hasher<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,true>,std::__unordered_map_equal<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::equal_to<ZinIrTensor const*>,std::hash<ZinIrTensor const*>,true>,std::allocator<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>>>::__emplace_unique_key_args<ZinIrTensor const*,std::piecewise_construct_t const&,std::tuple<ZinIrTensor const* const&>,std::tuple<>>((uint64_t)v4, &v44, (uint64_t)&std::piecewise_construct, (void **)buf)+ 6) = 6;
          if ((*(unsigned char *)(*((void *)v1 + 43) + 96) & 0x10) != 0
            && os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_INFO))
          {
            uint64_t v27 = (void *)((char *)v44 + 24);
            if (*((char *)v44 + 47) < 0) {
              uint64_t v27 = (void *)*v27;
            }
            *(_DWORD *)buf = 136315650;
            *(void *)&uint8_t buf[4] = v27;
            *(_WORD *)&buf[12] = 2080;
            *(void *)&buf[14] = "/Library/Caches/com.apple.xbs/Sources/ANECompiler/libs/inference/compiler/ZinIrSchedul"
                                  "e/src/ZinCpBasedAllocator.cpp";
            *(_WORD *)&buf[22] = 1024;
            int v51 = 3356;
            _os_log_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_INFO, "INFO: Tensor %s is demoted from kL2DependentAndCircular to kL2Circular (file %s, line %d)\n", buf, 0x1Cu);
          }
LABEL_49:
          int v6 = v41;
        }
        if (v6)
        {
          unint64_t v42 = v6;
          operator delete(v6);
        }
        BOOL v3 = v31;
        uint64_t v2 = v32;
      }
      unint64_t v28 = (void *)v2[1];
      if (v28)
      {
        do
        {
          BOOL v29 = v28;
          unint64_t v28 = (void *)*v28;
        }
        while (v28);
      }
      else
      {
        do
        {
          BOOL v29 = (void *)v2[2];
          BOOL v16 = *v29 == (void)v2;
          uint64_t v2 = v29;
        }
        while (!v16);
      }
      uint64_t v2 = v29;
    }
    while (v29 != v3);
  }
  std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)v48);
  std::__tree<std::unique_ptr<ZinIrMemoryPressureAnalyzer::Allocation const>,ZinIrMemoryPressureAnalyzer::PointerComparator,std::allocator<std::unique_ptr<ZinIrMemoryPressureAnalyzer::Allocation const>>>::destroy((uint64_t)&v45, v46[0]);
  return 0;
}

void sub_211375FC8(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, void *a20,uint64_t a21,uint64_t a22,uint64_t a23,void *__p,uint64_t a25,uint64_t a26,uint64_t a27,char a28,void *a29)
{
}

void ZinCpBasedAllocator::UpdateScheduleForPipelineRunPair(ZinCpBasedAllocator *this)
{
  uint64_t v2 = (char *)*((void *)this + 3);
  BOOL v3 = (char *)this + 32;
  if (v2 != (char *)this + 32)
  {
    do
    {
      unint64_t v28 = (ZinIrTensor *)*((void *)v2 + 4);
      uint64_t v4 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::find<ZinIrTensor *>((void *)this + 9, &v28);
      if (v4)
      {
        uint64_t v5 = v4;
        if (CpAllocUtils::IsChain(*((_DWORD *)v4 + 6)))
        {
          uint64_t v6 = *((void *)v28 + 12);
          uint64_t v7 = **(void **)(v6 + 112);
          *(void *)(v7 + 48) = *(void *)(v6 + 48);
          *(void *)(v7 + 56) = 1;
        }
        if (CpAllocUtils::IsL2Dependent(*((_DWORD *)v5 + 6)))
        {
          uint64_t v25 = 0;
          int v26 = 0;
          uint64_t v27 = 0;
          int ShouldUseL2Dependent = ZinIrRegAllocUtil::ShouldUseL2Dependent(v28, *((const ZinIrTensor **)this + 42), &v25);
          unint64_t v9 = v25;
          if (v26 == v25) {
            int ShouldUseL2Dependent = 0;
          }
          if (ShouldUseL2Dependent == 1)
          {
            unint64_t v10 = 0;
            do
            {
              unint64_t v11 = (uint64_t *)&v9[16 * v10];
              uint64_t v13 = *v11;
              uint64_t v12 = (ZinIrOpLayer *)v11[1];
              *((void *)v12 + 6) = *(void *)(*v11 + 48);
              *((void *)v12 + 7) = 1;
              std::string __p = 0;
              BOOL v23 = 0;
              uint64_t v24 = 0;
              int IntermediateLayers = ZinTensorFamilyUtil::GetIntermediateLayers(v13, v12, 0, 0, &__p);
              uint64_t v15 = (uint64_t *)__p;
              if (!IntermediateLayers)
              {
                BOOL v16 = v23;
                unint64_t v17 = (uint64_t *)__p;
                if (__p != v23)
                {
                  do
                  {
                    uint64_t v18 = *v17++;
                    *(void *)(v18 + 48) = *(void *)(v13 + 48);
                  }
                  while (v17 != v16);
                }
              }
              if (v15)
              {
                BOOL v23 = v15;
                operator delete(v15);
              }
              ++v10;
              unint64_t v9 = v25;
            }
            while (v10 < (v26 - v25) >> 4);
          }
          if (v9)
          {
            int v26 = v9;
            operator delete(v9);
          }
        }
      }
      uint64_t v19 = (char *)*((void *)v2 + 1);
      if (v19)
      {
        do
        {
          int v20 = v19;
          uint64_t v19 = *(char **)v19;
        }
        while (v19);
      }
      else
      {
        do
        {
          int v20 = (char *)*((void *)v2 + 2);
          BOOL v21 = *(void *)v20 == (void)v2;
          uint64_t v2 = v20;
        }
        while (!v21);
      }
      uint64_t v2 = v20;
    }
    while (v20 != v3);
  }
  std::__hash_table<std::__hash_value_type<ZinIrDimension,unsigned long>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,unsigned long>>>::clear((void *)this + 35);
  ZinLiveRangeUtils<ZinIrOpLayer,ZinIrTensor>::ZinIrComputeLiveRanges(*((ZinIrOpLayer ****)this + 40), (void *)this + 35);
}

void sub_21137621C(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *a10, uint64_t a11, uint64_t a12, void *__p, uint64_t a14)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

void ZinCpBasedAllocator::SetMemoryPressure(ZinCpBasedAllocator *this, ZinIrMemoryPressureAnalyzer *a2)
{
  uint64_t v4 = (void *)((char *)a2 + 8);
  std::__tree<std::unique_ptr<ZinIrMemoryPressureAnalyzer::Allocation const>,ZinIrMemoryPressureAnalyzer::PointerComparator,std::allocator<std::unique_ptr<ZinIrMemoryPressureAnalyzer::Allocation const>>>::destroy((uint64_t)a2, *((void **)a2 + 1));
  *(void *)a2 = v4;
  *((void *)a2 + 2) = 0;
  *uint64_t v4 = 0;
  std::__hash_table<std::__hash_value_type<ZinIrOpLayer *,std::map<ZinIrOpLayer *,float,ZinIrIdComparator<ZinIrOpLayer *>,std::allocator<std::pair<ZinIrOpLayer * const,float>>>>,std::__unordered_map_hasher<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,std::map<ZinIrOpLayer *,float,ZinIrIdComparator<ZinIrOpLayer *>,std::allocator<std::pair<ZinIrOpLayer * const,float>>>>,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,true>,std::__unordered_map_equal<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,std::map<ZinIrOpLayer *,float,ZinIrIdComparator<ZinIrOpLayer *>,std::allocator<std::pair<ZinIrOpLayer * const,float>>>>,std::equal_to<ZinIrOpLayer *>,std::hash<ZinIrOpLayer *>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer *,std::map<ZinIrOpLayer *,float,ZinIrIdComparator<ZinIrOpLayer *>,std::allocator<std::pair<ZinIrOpLayer * const,float>>>>>>::clear((uint64_t)a2 + 32);
  uint64_t v5 = (ZinCpBasedAllocator *)*((void *)this + 3);
  if (v5 != (ZinCpBasedAllocator *)((char *)this + 32))
  {
    do
    {
      uint64_t v15 = (ZinIrTensor *)*((void *)v5 + 4);
      uint64_t v6 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)this + 9, &v15);
      if (v6)
      {
        uint64_t v7 = v6;
        uint64_t v8 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)this + 35, &v15);
        if (v8)
        {
          long long v14 = *(_OWORD *)(v8 + 3);
          switch(*((_DWORD *)v7 + 6))
          {
            case 0:
            case 3:
            case 6:
            case 7:
              goto LABEL_7;
            case 1:
            case 8:
              ZinCpBasedAllocator::AddDMABufferToPressureAnalyzer(this, v15, a2);
              break;
            case 2:
              unint64_t ChainBufferSize = ZinL2FootprintCalculator::GetChainBufferSize(*((const ZinIrTensor ***)this + 34), (ZinIrRegAllocUtil **)v15);
              goto LABEL_8;
            case 4:
            case 5:
              *((void *)&v14 + 1) = *(void *)(ZinIrRegAllocUtil::GetLastConsumer(v15, v9) + 48) - 1;
LABEL_7:
              ZinL2FootprintCalculator::GetResidentBufferSize(*((ZinL2FootprintCalculator **)this + 34), v15);
LABEL_8:
              ZinIrMemoryPressureAnalyzer::AddTensorAllocation(a2, ChainBufferSize, (const ZinLiveRange *)&v14, v15);
            default:
              break;
          }
        }
      }
      unint64_t v11 = (ZinCpBasedAllocator *)*((void *)v5 + 1);
      if (v11)
      {
        do
        {
          uint64_t v12 = v11;
          unint64_t v11 = *(ZinCpBasedAllocator **)v11;
        }
        while (v11);
      }
      else
      {
        do
        {
          uint64_t v12 = (ZinCpBasedAllocator *)*((void *)v5 + 2);
          BOOL v13 = *(void *)v12 == (void)v5;
          uint64_t v5 = v12;
        }
        while (!v13);
      }
      uint64_t v5 = v12;
    }
    while (v12 != (ZinCpBasedAllocator *)((char *)this + 32));
  }
}

uint64_t ZinCpBasedAllocator::PromoteResidentToInplace(ZinCpBasedAllocator *this, ZinIrMemoryPressureAnalyzer *a2, BOOL *a3)
{
  uint64_t v6 = *((void *)this + 40);
  uint64_t v7 = *(const void **)v6;
  uint64_t v8 = *(void *)(v6 + 8);
  unint64_t v9 = (v8 - *(void *)v6) >> 3;
  uint64_t v25 = 0;
  uint64_t v26 = 0;
  uint64_t v24 = 0;
  std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(&v24, v7, v8, v9);
  unint64_t v11 = v24;
  unint64_t v10 = v25;
  uint64_t v12 = v25 - 1;
  if (v24 != v25 && v12 > v24)
  {
    unint64_t v14 = (unint64_t)(v24 + 1);
    do
    {
      uint64_t v15 = *(void *)(v14 - 8);
      *(void *)(v14 - 8) = *v12;
      *v12-- = v15;
      BOOL v16 = v14 >= (unint64_t)v12;
      v14 += 8;
    }
    while (!v16);
    unint64_t v11 = v24;
    unint64_t v10 = v25;
  }
  if (v11 != v10)
  {
    do
    {
      uint64_t v17 = *v11;
      BOOL v23 = 0;
      BOOL v23 = (ZinIrTensor *)(*(uint64_t (**)(uint64_t, void, void))(*(void *)v17 + 32))(v17, 0, 0);
      uint64_t RootTensor = (const ZinIrTensor *)ZinTensorFamilyUtil::GetRootTensor((ZinCpBasedAllocator *)((char *)this + 1048), v23);
      if (RootTensor == v23)
      {
        Usages = ZinTensorFamilyUtil::GetReadUsages((ZinCpBasedAllocator *)((char *)this + 1048), RootTensor);
        if (Usages[1] != *Usages)
        {
          int v20 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::find<ZinIrTensor *>((void *)this + 9, &v23);
          BOOL v21 = v20;
          if (!v20) {
            ZinAssertImpl("The decision must exist");
          }
          if (CpAllocUtils::IsNonChainResident(*((_DWORD *)v20 + 6))
            && !CpAllocUtils::IsL2Inplace(*((_DWORD *)v21 + 6))
            && !ZinCpBasedAllocator::IsDisqualifiedForInplacePromotion(this, v23)
            && ZinCpBasedAllocator::PromoteToInplace((ZinIrTensor **)this, v23, a2))
          {
            *a3 = 1;
          }
        }
      }
      ++v11;
    }
    while (v11 != v10);
    unint64_t v10 = v24;
  }
  if (v10)
  {
    uint64_t v25 = v10;
    operator delete(v10);
  }
  return 0;
}

void sub_2113765A0(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinCpBasedAllocator::PromoteNonResidentToResident(ZinCpBasedAllocator *this, ZinIrMemoryPressureAnalyzer *a2, BOOL *a3)
{
  unint64_t v6 = *(void *)(*((void *)this + 42) + 408);
  uint64_t v7 = (uint64_t)(*(void *)(*((void *)this + 40) + 8) - **((void **)this + 40)) >> 3;
  uint64_t v15 = 0;
  uint64_t v16 = v7;
  ZinIrMemoryPressureAnalyzer::GetTensorsBeyondBudget(a2, v6, (uint64_t *)&v15, (uint64_t)v17);
  if (!v19)
  {
    ZinCpBasedAllocator::GetSortedNonResidentTensors(this, &v15);
    uint64_t v8 = v15;
    unint64_t v9 = (ZinIrTensor **)v16;
    if (v15 != (void *)v16)
    {
      for (uint64_t i = (ZinIrTensor **)v15; i != v9; ++i)
      {
        unint64_t v14 = *i;
        int v20 = &v14;
        if (*((_DWORD *)std::__hash_table<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::__unordered_map_hasher<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,true>,std::__unordered_map_equal<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::equal_to<ZinIrTensor const*>,std::hash<ZinIrTensor const*>,true>,std::allocator<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>>>::__emplace_unique_key_args<ZinIrTensor const*,std::piecewise_construct_t const&,std::tuple<ZinIrTensor const* const&>,std::tuple<>>((uint64_t)this + 72, &v14, (uint64_t)&std::piecewise_construct, &v20)+ 6) == 1)
        {
          BOOL IsDisqualifiedForInplacePromotion = ZinCpBasedAllocator::IsDisqualifiedForInplacePromotion(this, v14);
          uint64_t v12 = v14;
          if (!IsDisqualifiedForInplacePromotion)
          {
            if (ZinCpBasedAllocator::PromoteToInplace((ZinIrTensor **)this, v14, a2)) {
              goto LABEL_9;
            }
            uint64_t v12 = v14;
          }
          if (ZinCpBasedAllocator::PromoteToResident((ZinL2FootprintCalculator **)this, v12, a2)) {
LABEL_9:
          }
            *a3 = 1;
        }
      }
    }
    if (v8) {
      operator delete(v8);
    }
  }
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v17, v18);
  return 0;
}

void sub_211376710(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, char a14, void *a15)
{
}

uint64_t ZinCpBasedAllocator::PromoteChainToL2Dependent(ZinCpBasedAllocator *this, ZinIrMemoryPressureAnalyzer *a2, BOOL *a3)
{
  unint64_t v6 = *(void *)(*((void *)this + 42) + 408);
  uint64_t v7 = (uint64_t)(*(void *)(*((void *)this + 40) + 8) - **((void **)this + 40)) >> 3;
  v116 = 0;
  int v117 = (ZinIrRegAllocUtil ***)v7;
  ZinIrMemoryPressureAnalyzer::GetTensorsBeyondBudget(a2, v6, (uint64_t *)&v116, (uint64_t)v121);
  if (v123 || (unint64_t v10 = (ZinCpBasedAllocator *)*((void *)this + 3), v10 == (ZinCpBasedAllocator *)((char *)this + 32)))
  {
LABEL_2:
    uint64_t v8 = 0;
    goto LABEL_3;
  }
  unint64_t v11 = (void *)((char *)this + 72);
  unint64_t v96 = (void *)((char *)this + 192);
  long long v97 = (void *)((char *)this + 152);
  int v94 = a3;
  int64x2_t v95 = (void *)((char *)this + 232);
  int v91 = (uint64_t **)((char *)this + 1024);
  int v99 = (void *)((char *)this + 72);
  while (1)
  {
    v120 = (ZinIrRegAllocUtil **)*((void *)v10 + 4);
    v116 = &v120;
    if (*((_DWORD *)std::__hash_table<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::__unordered_map_hasher<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,true>,std::__unordered_map_equal<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::equal_to<ZinIrTensor const*>,std::hash<ZinIrTensor const*>,true>,std::allocator<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>>>::__emplace_unique_key_args<ZinIrTensor const*,std::piecewise_construct_t const&,std::tuple<ZinIrTensor const* const&>,std::tuple<>>((uint64_t)v11, &v120, (uint64_t)&std::piecewise_construct, &v116)+ 6) != 2)goto LABEL_99; {
    v116 = &v120;
    }
    long long v119 = *(_OWORD *)(std::__hash_table<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>>>::__emplace_unique_key_args<ZinIrTensor *,std::piecewise_construct_t const&,std::tuple<ZinIrTensor * const&>,std::tuple<>>((uint64_t)this + 280, &v120, (uint64_t)&std::piecewise_construct, &v116)+ 3);
    ZinIrMemoryPressureAnalyzer::GetPeakPressure(a2, (const ZinLiveRange *)&v119);
    if ((ZinIrRegAllocUtil::IsChainable((ZinIrRegAllocUtil *)v120, *((const ZinIrTensor **)this + 42), v12) & 1) == 0) {
      break;
    }
    if ((ZinIrRegAllocUtil::IsL2Dependentable((ZinIrTensor *)v120, *((const ZinIrTensor **)this + 42), (ZinCpBasedAllocator *)((char *)this + 1048)) & 1) == 0)goto LABEL_99; {
    BOOL v13 = v120[12];
    }
    unint64_t v14 = (ZinIrOpLayer *)**((void **)v13 + 14);
    int v105 = v13;
    uint64_t v15 = *((void *)v13 + 33);
    uint64_t v16 = *((void *)v14 + 33);
    unint64_t v102 = v15 + 120;
    uint64_t v17 = v16 + 120;
    if (ZinIrOpLayer::IsNELayer(v14) && ZinIrOpLayer::IsPELayer(v105))
    {
      unsigned int v18 = *(_DWORD *)(ZinIrOpLayer::GetInputTensor(v14, 0) + 88);
      ZinIrOpLayer::GetInputTensorDimensions(v14, (void **)&v116);
      v93 &= 0xFFFFFFFFFF000000;
      ZinMirL2Config::SetL2DependentBufferNEWorkUnit(v16 + 120, v14, v18, (uint64_t)v116, v93, 0);
      if (v116)
      {
        int v117 = v116;
        operator delete(v116);
      }
      v116 = 0;
      int v117 = 0;
      uint64_t v118 = 0;
      uint64_t RootTensor = 0;
      unint64_t v114 = 0;
      uint64_t v115 = 0;
      *(void *)&long long v108 = 0;
      v107[0] = 0;
      ZinL2FootprintCalculator::GetInterleavesAndCropOffset(v97, v96, v95, (uint64_t)v105, (uint64_t)&v116, (uint64_t)&RootTensor, &v108, v107);
      ZinMirL2Config::SetL2DependentBufferPEWorkUnit(v102, *((void *)this + 42), v105, v14, &v116, &RootTensor, v108, (unint64_t)v107[0], 1u, 0);
      uint64_t v17 = v16 + 120;
      if (RootTensor)
      {
        unint64_t v114 = RootTensor;
        operator delete(RootTensor);
      }
      if (v116)
      {
        int v117 = v116;
        operator delete(v116);
      }
    }
    v104 = v14;
    if (ZinIrOpLayer::IsNELayer(v105) && ZinIrOpLayer::IsPELayer(v14))
    {
      uint64_t v100 = v16;
      uint64_t v19 = v17;
      unsigned int v20 = *(_DWORD *)(ZinIrOpLayer::GetInputTensor(v105, 0) + 88);
      ZinIrOpLayer::GetInputTensorDimensions(v105, (void **)&v116);
      v92 &= 0xFFFFFFFFFF000000;
      ZinMirL2Config::SetL2DependentBufferNEWorkUnit(v102, v105, v20, (uint64_t)v116, v92, 0);
      uint64_t v21 = v19;
      if (v116)
      {
        int v117 = v116;
        operator delete(v116);
      }
      v116 = 0;
      int v117 = 0;
      uint64_t v118 = 0;
      uint64_t RootTensor = 0;
      unint64_t v114 = 0;
      uint64_t v115 = 0;
      *(void *)&long long v108 = 0;
      v107[0] = 0;
      ZinL2FootprintCalculator::GetInterleavesAndCropOffset(v97, v96, v95, (uint64_t)v14, (uint64_t)&v116, (uint64_t)&RootTensor, &v108, v107);
      uint64_t v16 = v100;
      ZinMirL2Config::SetL2DependentBufferPEWorkUnit(v21, *((void *)this + 42), v105, v14, &v116, &RootTensor, v108, (unint64_t)v107[0], 1u, 0);
      if (RootTensor)
      {
        unint64_t v114 = RootTensor;
        operator delete(RootTensor);
      }
      if (v116)
      {
        int v117 = v116;
        operator delete(v116);
      }
    }
    uint64_t v22 = (*(uint64_t (**)(ZinIrOpLayer *, uint64_t))(*(void *)v105 + 368))(v105, 3);
    if (!*(unsigned char *)(v15 + 233)) {
      *(void *)(v15 + 20std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v22;
    }
    uint64_t v23 = (*(uint64_t (**)(ZinIrOpLayer *, uint64_t))(*(void *)v14 + 368))(v14, 3);
    if (!*(unsigned char *)(v16 + 233)) {
      *(void *)(v16 + 20std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v23;
    }
    if (!*(unsigned char *)(*((void *)this + 42) + 1117))
    {
      uint64_t v29 = (*(uint64_t (**)(ZinIrOpLayer *, uint64_t))(*(void *)v105 + 368))(v105, 3);
      if (!*(unsigned char *)(v15 + 233)) {
        *(void *)(v15 + 20std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v29;
      }
      uint64_t v28 = (*(uint64_t (**)(ZinIrOpLayer *, uint64_t))(*(void *)v14 + 368))(v14, 3);
LABEL_44:
      if (*(unsigned char *)(v16 + 233)) {
        goto LABEL_46;
      }
LABEL_45:
      *(void *)(v16 + 20std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v28;
      goto LABEL_46;
    }
    if (ZinIrOpLayer::IsNELayer(v105)) {
      uint64_t v24 = v105;
    }
    else {
      uint64_t v24 = v14;
    }
    unint64_t v25 = *(void *)(*((void *)v24 + 33) + 128);
    if (v25 <= (*(uint64_t (**)(void))(*(void *)v105 + 368))())
    {
      unint64_t v26 = *(void *)(*((void *)v24 + 33) + 128);
      if (v26 <= (*(uint64_t (**)(ZinIrOpLayer *, uint64_t))(*(void *)v14 + 368))(v14, 3))
      {
        uint64_t v28 = *(void *)(*((void *)v24 + 33) + 128);
        unint64_t v11 = (void *)((char *)this + 72);
        if (!*(unsigned char *)(v15 + 233)) {
          *(void *)(v15 + 20std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v28;
        }
        goto LABEL_44;
      }
    }
    uint64_t v27 = (*(uint64_t (**)(ZinIrOpLayer *, uint64_t))(*(void *)v105 + 368))(v105, 3);
    if (!*(unsigned char *)(v15 + 233)) {
      *(void *)(v15 + 20std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v27;
    }
    uint64_t v28 = (*(uint64_t (**)(ZinIrOpLayer *, uint64_t))(*(void *)v14 + 368))(v14, 3);
    unint64_t v11 = (void *)((char *)this + 72);
    if (!*(unsigned char *)(v16 + 233)) {
      goto LABEL_45;
    }
LABEL_46:
    uint64_t v30 = v120[12];
    uint64_t v31 = (const ZinIrOpLayerGraph *)*((void *)v30 + 19);
    ZinIrInPlaceUpdate::IsInPlaceable(*((ZinIrTensor **)this + 127), v30, v31, 2, *(unsigned char *)(*((void *)this + 42) + 1115), (unint64_t **)&v116);
    ZinL2FootprintCalculator::GetResidentBufferSize(*((ZinL2FootprintCalculator **)this + 34), (const ZinIrTensor *)v120);
    unsigned int v32 = (unint64_t *)v116;
    unint64_t v103 = v33;
    if (v33 > *(void *)(*((void *)this + 42) + 408))
    {
LABEL_53:
      int v117 = (ZinIrRegAllocUtil ***)v32;
    }
    else
    {
      unint64_t v34 = (unint64_t *)v117;
      while (v32 != v34)
      {
        InputTensor = (const ZinIrTensor *)ZinIrOpLayer::GetInputTensor(v120[12], *v32);
        uint64_t RootTensor = (unint64_t *)ZinTensorFamilyUtil::GetRootTensor((ZinCpBasedAllocator *)((char *)this + 1048), InputTensor);
        uint64_t v36 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::find<ZinIrTensor *>(v11, &RootTensor);
        if (!v36) {
          std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
        }
        if (CpAllocUtils::IsL2Inplace(*((_DWORD *)v36 + 6)))
        {
          unsigned int v32 = (unint64_t *)v116;
          goto LABEL_53;
        }
        ++v32;
      }
    }
    ZinIrInPlaceUpdate::IsInPlaceable(*((ZinIrTensor **)this + 127), v14, v31, 2, *(unsigned char *)(*((void *)this + 42) + 1115), &RootTensor);
    if (v103 >= *(void *)(*((void *)this + 42) + 408)
      || (char v37 = (ZinIrTensor *)(*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)v14 + 32))(v14, 0, 0), v107[0] = ZinIrTensor::GetRootTensor(v37), *(void *)&v108 = v107, *((_DWORD *)std::__hash_table<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::__unordered_map_hasher<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,true>,std::__unordered_map_equal<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::equal_to<ZinIrTensor const*>,std::hash<ZinIrTensor const*>,true>,std::allocator<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>>>::__emplace_unique_key_args<ZinIrTensor const*,std::piecewise_construct_t const&,std::tuple<ZinIrTensor const* const&>,std::tuple<>>((uint64_t)v11, v107, (uint64_t)&std::piecewise_construct, (void **)&v108)+ 6))|| (v74 = RootTensor, v75 = v114, RootTensor == v114))
    {
      LOBYTE(v101) = 0;
      int v38 = 3;
    }
    else
    {
      while (1)
      {
        int64x2_t v76 = (ZinIrRegAllocUtil **)ZinIrOpLayer::GetInputTensor(v14, *v74);
        if (v76 == v120) {
          break;
        }
        if (++v74 == v75)
        {
          int v101 = 0;
          goto LABEL_111;
        }
      }
      int v101 = 1;
LABEL_111:
      uint64_t v77 = RootTensor;
      int v78 = v114;
      while (v77 != v78)
      {
        int v79 = (ZinIrTensor *)ZinIrOpLayer::GetInputTensor(v14, *v77);
        if (v79 != (ZinIrTensor *)v120)
        {
          v107[0] = ZinIrTensor::GetRootTensor(v79);
          *(void *)&long long v108 = v107;
          long long v80 = std::__hash_table<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::__unordered_map_hasher<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,true>,std::__unordered_map_equal<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::equal_to<ZinIrTensor const*>,std::hash<ZinIrTensor const*>,true>,std::allocator<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>>>::__emplace_unique_key_args<ZinIrTensor const*,std::piecewise_construct_t const&,std::tuple<ZinIrTensor const* const&>,std::tuple<>>((uint64_t)v11, v107, (uint64_t)&std::piecewise_construct, (void **)&v108);
          BOOL IsL2Inplace = CpAllocUtils::IsL2Inplace(*((_DWORD *)v80 + 6));
          int v82 = v101;
          if (IsL2Inplace) {
            int v82 = 0;
          }
          int v101 = v82;
          break;
        }
        ++v77;
      }
      if (v101) {
        int v38 = 5;
      }
      else {
        int v38 = 3;
      }
    }
    int v98 = v38;
    while (1)
    {
      char v40 = v116;
      uint64_t v39 = v117;
      v112 = 0;
      if (v117 == v116) {
        break;
      }
      uint64_t v41 = *v116;
      if (v117 != v116 + 1) {
        memmove(v116, v116 + 1, (char *)v117 - (char *)(v116 + 1));
      }
      int v117 = v39 - 1;
      unint64_t v42 = (const ZinIrTensor *)ZinIrOpLayer::GetInputTensor(v120[12], (unint64_t)v41);
      v112 = (ZinIrTensor *)ZinTensorFamilyUtil::GetRootTensor((ZinCpBasedAllocator *)((char *)this + 1048), v42);
      uint64_t v43 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::find<ZinIrTensor *>(v11, &v112);
      if (!v43)
      {
        int v66 = 0;
        goto LABEL_94;
      }
      unsigned int v44 = *((_DWORD *)v43 + 6);
      if ((CpAllocUtils::IsL2Dependent(v44) & 1) == 0
        && !CpAllocUtils::IsChain(v44)
        && !std::__tree<ZinIrOpLayer *,ZinIrIdComparator<ZinIrOpLayer *>,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)this + 48, (uint64_t *)&v112))
      {
        goto LABEL_67;
      }
    }
    uint64_t v41 = 0;
LABEL_67:
    int v45 = (const ZinIrTensor *)v120;
    *(void *)&long long v108 = &v120;
    unint64_t v46 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>>>::__emplace_unique_key_args<ZinIrTensor *,std::piecewise_construct_t const&,std::tuple<ZinIrTensor * const&>,std::tuple<>>((uint64_t)this + 280, &v120, (uint64_t)&std::piecewise_construct, (void **)&v108);
    ZinIrMemoryPressureAnalyzer::RemoveTensorAllocation(a2, v45, (const ZinLiveRange *)(v46 + 3));
    ZinCpBasedAllocator::RemoveDMABufferFromPressureAnalyzer(this, v105, a2);
    ZinCpBasedAllocator::RemoveDMABufferFromPressureAnalyzer(this, v104, a2);
    if (v39 != v40)
    {
      if (v112)
      {
        char v47 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::find<ZinIrTensor *>(v11, &v112);
        if (v47)
        {
          if (CpAllocUtils::IsNonChainResident(*((_DWORD *)v47 + 6)))
          {
            uint64_t v48 = v112;
            *(void *)&long long v108 = &v112;
            int v49 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>>>::__emplace_unique_key_args<ZinIrTensor *,std::piecewise_construct_t const&,std::tuple<ZinIrTensor * const&>,std::tuple<>>((uint64_t)this + 280, &v112, (uint64_t)&std::piecewise_construct, (void **)&v108);
            ZinIrMemoryPressureAnalyzer::RemoveTensorAllocation(a2, v48, (const ZinLiveRange *)(v49 + 3));
          }
          v107[0] = &v112;
          long long v108 = *(_OWORD *)(std::__hash_table<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>>>::__emplace_unique_key_args<ZinIrTensor *,std::piecewise_construct_t const&,std::tuple<ZinIrTensor * const&>,std::tuple<>>((uint64_t)this + 280, &v112, (uint64_t)&std::piecewise_construct, v107)+ 3);
          *((void *)&v108 + 1) = *(void *)(ZinIrRegAllocUtil::GetLastConsumer(v112, v50) + 48) - 1;
          ZinIrMemoryPressureAnalyzer::AddTensorAllocation(a2, v103, (const ZinLiveRange *)&v108, v112);
        }
        std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
      }
      ZinAssertImpl("Invalid inplaceable tensor");
    }
    if ((v101 & 1) == 0)
    {
      *(void *)&long long v108 = &v120;
      int v51 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>>>::__emplace_unique_key_args<ZinIrTensor *,std::piecewise_construct_t const&,std::tuple<ZinIrTensor * const&>,std::tuple<>>((uint64_t)this + 280, &v120, (uint64_t)&std::piecewise_construct, (void **)&v108);
      ZinIrMemoryPressureAnalyzer::AddTensorAllocation(a2, v103, (const ZinLiveRange *)(v51 + 3), (const ZinIrTensor *)v120);
    }
    v107[0] = v120;
    *(void *)&long long v108 = v107;
    *((_DWORD *)std::__hash_table<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::__unordered_map_hasher<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,true>,std::__unordered_map_equal<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::equal_to<ZinIrTensor const*>,std::hash<ZinIrTensor const*>,true>,std::allocator<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>>>::__emplace_unique_key_args<ZinIrTensor const*,std::piecewise_construct_t const&,std::tuple<ZinIrTensor const* const&>,std::tuple<>>((uint64_t)v11, v107, (uint64_t)&std::piecewise_construct, (void **)&v108)+ 6) = 3;
    ZinCpBasedAllocator::AddDMABufferToPressureAnalyzer(this, v105, a2);
    ZinCpBasedAllocator::AddDMABufferToPressureAnalyzer(this, v104, a2);
    v107[0] = v120;
    *(void *)&long long v108 = v107;
    *((_DWORD *)std::__hash_table<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::__unordered_map_hasher<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,true>,std::__unordered_map_equal<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::equal_to<ZinIrTensor const*>,std::hash<ZinIrTensor const*>,true>,std::allocator<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>>>::__emplace_unique_key_args<ZinIrTensor const*,std::piecewise_construct_t const&,std::tuple<ZinIrTensor const* const&>,std::tuple<>>((uint64_t)v11, v107, (uint64_t)&std::piecewise_construct, (void **)&v108)+ 6) = 2;
    if (v39 == v40)
    {
      uint64_t v58 = *((void *)v104 + 7) + *((void *)v104 + 6);
      uint64_t v110 = *((void *)v105 + 6);
      uint64_t v111 = v58;
    }
    else
    {
      v107[0] = v112;
      *(void *)&long long v108 = v107;
      *((_DWORD *)std::__hash_table<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::__unordered_map_hasher<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,true>,std::__unordered_map_equal<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::equal_to<ZinIrTensor const*>,std::hash<ZinIrTensor const*>,true>,std::allocator<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>>>::__emplace_unique_key_args<ZinIrTensor const*,std::piecewise_construct_t const&,std::tuple<ZinIrTensor const* const&>,std::tuple<>>((uint64_t)v11, v107, (uint64_t)&std::piecewise_construct, (void **)&v108)+ 6) = 0;
      uint64_t v52 = *((void *)v104 + 7) + *((void *)v104 + 6);
      uint64_t v110 = *((void *)v105 + 6);
      uint64_t v111 = v52;
      uint64_t v53 = (uint64_t *)*((void *)v105 + 11);
      BOOL v54 = (uint64_t *)*((void *)v105 + 12);
      while (v53 != v54)
      {
        uint64_t v55 = *v53;
        v107[0] = 0;
        uint64_t v56 = (const ZinIrTensor *)(*(uint64_t (**)(uint64_t, void, void))(*(void *)v55 + 32))(v55, 0, 0);
        v107[0] = (void *)ZinTensorFamilyUtil::GetRootTensor((ZinCpBasedAllocator *)((char *)this + 1048), v56);
        *(void *)&long long v108 = v107;
        uint64_t v57 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>>>::__emplace_unique_key_args<ZinIrTensor *,std::piecewise_construct_t const&,std::tuple<ZinIrTensor * const&>,std::tuple<>>((uint64_t)this + 280, v107, (uint64_t)&std::piecewise_construct, (void **)&v108)[3];
        if (v57 >= v110) {
          uint64_t v57 = v110;
        }
        uint64_t v110 = v57;
        ++v53;
      }
    }
    ZinIrMemoryPressureAnalyzer::GetTensorsBeyondBudget(a2, *(void *)(*((void *)this + 42) + 408), &v110, (uint64_t)&v108);
    unint64_t v11 = (void *)((char *)this + 72);
    if (v109)
    {
      if (v39 != v40)
      {
        int v59 = v112;
        if (!v112) {
          ZinAssertImpl("Invalid inplaceable tensor");
        }
        v107[0] = &v112;
        int v60 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>>>::__emplace_unique_key_args<ZinIrTensor *,std::piecewise_construct_t const&,std::tuple<ZinIrTensor * const&>,std::tuple<>>((uint64_t)this + 280, &v112, (uint64_t)&std::piecewise_construct, v107);
        ZinIrMemoryPressureAnalyzer::RemoveTensorAllocation(a2, v59, (const ZinLiveRange *)(v60 + 3));
        int v61 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::find<ZinIrTensor *>(v99, &v112);
        if (!v61) {
          std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
        }
        if (CpAllocUtils::IsNonChainResident(*((_DWORD *)v61 + 6))) {
          ZinCpBasedAllocator::AddL2BufferToPressureAnalyzer(this, v112, a2);
        }
      }
      char v62 = (const ZinIrTensor *)v120;
      v107[0] = &v120;
      unint64_t v63 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>>>::__emplace_unique_key_args<ZinIrTensor *,std::piecewise_construct_t const&,std::tuple<ZinIrTensor * const&>,std::tuple<>>((uint64_t)this + 280, &v120, (uint64_t)&std::piecewise_construct, v107);
      ZinIrMemoryPressureAnalyzer::RemoveTensorAllocation(a2, v62, (const ZinLiveRange *)(v63 + 3));
      unint64_t ChainBufferSize = ZinL2FootprintCalculator::GetChainBufferSize(*((const ZinIrTensor ***)this + 34), v120);
      v107[0] = &v120;
      uint64_t v65 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>>>::__emplace_unique_key_args<ZinIrTensor *,std::piecewise_construct_t const&,std::tuple<ZinIrTensor * const&>,std::tuple<>>((uint64_t)this + 280, &v120, (uint64_t)&std::piecewise_construct, v107);
      ZinIrMemoryPressureAnalyzer::AddTensorAllocation(a2, ChainBufferSize, (const ZinLiveRange *)(v65 + 3), (const ZinIrTensor *)v120);
    }
    if (v39 != v40)
    {
      *(void *)&long long v106 = v112;
      v107[0] = &v106;
      *((_DWORD *)std::__hash_table<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::__unordered_map_hasher<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,true>,std::__unordered_map_equal<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::equal_to<ZinIrTensor const*>,std::hash<ZinIrTensor const*>,true>,std::allocator<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>>>::__emplace_unique_key_args<ZinIrTensor const*,std::piecewise_construct_t const&,std::tuple<ZinIrTensor const* const&>,std::tuple<>>((uint64_t)v99, &v106, (uint64_t)&std::piecewise_construct, v107)+ 6) = 4;
      v107[0] = v120;
      v107[1] = v41;
      std::__tree<std::__value_type<ZinIrTensor *,unsigned long>,std::__map_value_compare<ZinIrTensor *,std::__value_type<ZinIrTensor *,unsigned long>,std::less<ZinIrTensor *>,true>,std::allocator<std::__value_type<ZinIrTensor *,unsigned long>>>::__emplace_unique_key_args<ZinIrTensor *,std::pair<ZinIrTensor *,unsigned long>>(v91, (unint64_t *)v107, (uint64_t *)v107);
      if ((ZinIrRegAllocUtil::AdjustDimOrderForInplace((uint64_t)v120[12], (uint64_t)v91, v99, (ZinCpBasedAllocator *)((char *)this + 1048)) & 1) == 0)ZinAssertImpl("failed to propagate dim order for inplace"); {
      v107[0] = &v112;
      }
      uint64_t v67 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>>>::__emplace_unique_key_args<ZinIrTensor *,std::piecewise_construct_t const&,std::tuple<ZinIrTensor * const&>,std::tuple<>>((uint64_t)this + 280, &v112, (uint64_t)&std::piecewise_construct, v107)[3];
      uint64_t v69 = *(void *)(ZinIrRegAllocUtil::GetLastConsumer(v112, v68) + 48);
      v107[0] = &v112;
      int v70 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>>>::__emplace_unique_key_args<ZinIrTensor *,std::piecewise_construct_t const&,std::tuple<ZinIrTensor * const&>,std::tuple<>>((uint64_t)this + 280, &v112, (uint64_t)&std::piecewise_construct, v107);
      v70[3] = v67;
      v70[4] = v69 - 1;
    }
    *(void *)&long long v106 = v120;
    v107[0] = &v106;
    *((_DWORD *)std::__hash_table<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::__unordered_map_hasher<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,true>,std::__unordered_map_equal<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::equal_to<ZinIrTensor const*>,std::hash<ZinIrTensor const*>,true>,std::allocator<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>>>::__emplace_unique_key_args<ZinIrTensor const*,std::piecewise_construct_t const&,std::tuple<ZinIrTensor const* const&>,std::tuple<>>((uint64_t)v99, &v106, (uint64_t)&std::piecewise_construct, v107)+ 6) = v98;
    *int v94 = 1;
    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v108, *((void **)&v108 + 1));
    int v66 = 1;
LABEL_94:
    if (RootTensor)
    {
      unint64_t v114 = RootTensor;
      operator delete(RootTensor);
    }
    if (v116)
    {
      int v117 = v116;
      operator delete(v116);
    }
    if (!v66) {
      goto LABEL_123;
    }
LABEL_99:
    uint64_t v71 = (ZinCpBasedAllocator *)*((void *)v10 + 1);
    if (v71)
    {
      do
      {
        int64x2_t v72 = v71;
        uint64_t v71 = *(ZinCpBasedAllocator **)v71;
      }
      while (v71);
    }
    else
    {
      do
      {
        int64x2_t v72 = (ZinCpBasedAllocator *)*((void *)v10 + 2);
        BOOL v73 = *(void *)v72 == (void)v10;
        unint64_t v10 = v72;
      }
      while (!v73);
    }
    unint64_t v10 = v72;
    if (v72 == (ZinCpBasedAllocator *)((char *)this + 32)) {
      goto LABEL_2;
    }
  }
  BOOL v83 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
  if (v83) {
    ZinCpBasedAllocator::PromoteChainToL2Dependent(v83, v84, v85, v86, v87, v88, v89, v90);
  }
LABEL_123:
  uint64_t v8 = 3;
LABEL_3:
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v121, v122);
  return v8;
}

void sub_2113777D0(_Unwind_Exception *a1)
{
  BOOL v3 = *(void **)(v1 - 192);
  if (v3)
  {
    *(void *)(v1 - 184) = v3;
    operator delete(v3);
  }
  uint64_t v4 = *(void **)(v1 - 168);
  if (v4)
  {
    *(void *)(v1 - 16std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v4;
    operator delete(v4);
  }
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy(v1 - 120, *(void **)(v1 - 112));
  _Unwind_Resume(a1);
}

uint64_t ZinCpBasedAllocator::PromoteResidentToL2Dependent(ZinCpBasedAllocator *this, ZinIrMemoryPressureAnalyzer *a2)
{
  unint64_t v4 = *(void *)(*((void *)this + 42) + 408);
  uint64_t v5 = (uint64_t)(*(void *)(*((void *)this + 40) + 8) - **((void **)this + 40)) >> 3;
  p_uint64_t RootTensor = 0;
  uint64_t v23 = (void *)v5;
  uint64_t v21 = a2;
  ZinIrMemoryPressureAnalyzer::GetTensorsBeyondBudget(a2, v4, (uint64_t *)&p_RootTensor, (uint64_t)v28);
  if (!v30)
  {
    unint64_t v6 = (ZinCpBasedAllocator *)*((void *)this + 3);
    if (v6 != (ZinCpBasedAllocator *)((char *)this + 32))
    {
      do
      {
        uint64_t v27 = (ZinIrRegAllocUtil *)*((void *)v6 + 4);
        p_uint64_t RootTensor = &v27;
        if (*((_DWORD *)std::__hash_table<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::__unordered_map_hasher<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,true>,std::__unordered_map_equal<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::equal_to<ZinIrTensor const*>,std::hash<ZinIrTensor const*>,true>,std::allocator<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>>>::__emplace_unique_key_args<ZinIrTensor const*,std::piecewise_construct_t const&,std::tuple<ZinIrTensor const* const&>,std::tuple<>>((uint64_t)this + 72, &v27, (uint64_t)&std::piecewise_construct, &p_RootTensor)+ 6) == 4|| (p_uint64_t RootTensor = &v27, !*((_DWORD *)std::__hash_table<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::__unordered_map_hasher<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,true>,std::__unordered_map_equal<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::equal_to<ZinIrTensor const*>,std::hash<ZinIrTensor const*>,true>,std::allocator<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>>>::__emplace_unique_key_args<ZinIrTensor const*,std::piecewise_construct_t const&,std::tuple<ZinIrTensor const* const&>,std::tuple<>>((uint64_t)this + 72, &v27, (uint64_t)&std::piecewise_construct, &p_RootTensor)+ 6)))
        {
          if (ZinIrRegAllocUtil::IsChainable(v27, *((const ZinIrTensor **)this + 42), v7))
          {
            uint64_t v8 = *((void *)v27 + 12);
            unint64_t v9 = **(const ZinANELayer ***)(v8 + 112);
            if (*((void *)v9 + 12) - *((void *)v9 + 11) < 9uLL
              || !ZinIrOpLayer::IsPELayer(**(ZinIrOpLayer ***)(v8 + 112)))
            {
              unint64_t v10 = *(uint64_t **)(v8 + 88);
              unint64_t v11 = *(uint64_t **)(v8 + 96);
              while (v10 != v11)
              {
                uint64_t v12 = *v10;
                v25[0] = 0;
                BOOL v13 = (ZinIrTensor *)(*(uint64_t (**)(uint64_t, void, void))(*(void *)v12 + 32))(v12, 0, 0);
                v25[0] = (uint64_t)ZinIrTensor::GetRootTensor(v13);
                p_uint64_t RootTensor = (ZinIrRegAllocUtil **)v25;
                if (*((_DWORD *)std::__hash_table<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::__unordered_map_hasher<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,true>,std::__unordered_map_equal<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::equal_to<ZinIrTensor const*>,std::hash<ZinIrTensor const*>,true>,std::allocator<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>>>::__emplace_unique_key_args<ZinIrTensor const*,std::piecewise_construct_t const&,std::tuple<ZinIrTensor const* const&>,std::tuple<>>((uint64_t)this + 72, v25, (uint64_t)&std::piecewise_construct, &p_RootTensor)+ 6) == 4)
                {
                  uint64_t RootTensor = 0;
                  unint64_t v14 = (ZinIrTensor *)(*(uint64_t (**)(const ZinANELayer *, void, void))(*(void *)v9 + 32))(v9, 0, 0);
                  uint64_t RootTensor = ZinIrTensor::GetRootTensor(v14);
                  p_uint64_t RootTensor = &RootTensor;
                  uint64_t v15 = std::__hash_table<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::__unordered_map_hasher<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,true>,std::__unordered_map_equal<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::equal_to<ZinIrTensor const*>,std::hash<ZinIrTensor const*>,true>,std::allocator<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>>>::__emplace_unique_key_args<ZinIrTensor const*,std::piecewise_construct_t const&,std::tuple<ZinIrTensor const* const&>,std::tuple<>>((uint64_t)this + 72, &RootTensor, (uint64_t)&std::piecewise_construct, &p_RootTensor);
                  if (CpAllocUtils::IsNonResident(*((_DWORD *)v15 + 6)))
                  {
                    *((void *)v9 + 6) = *(void *)(v8 + 48);
                    *((void *)v9 + 7) = 1;
                    p_uint64_t RootTensor = &v27;
                    if (*((_DWORD *)std::__hash_table<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::__unordered_map_hasher<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,true>,std::__unordered_map_equal<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::equal_to<ZinIrTensor const*>,std::hash<ZinIrTensor const*>,true>,std::allocator<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>>>::__emplace_unique_key_args<ZinIrTensor const*,std::piecewise_construct_t const&,std::tuple<ZinIrTensor const* const&>,std::tuple<>>((uint64_t)this + 72, &v27, (uint64_t)&std::piecewise_construct, &p_RootTensor)+ 6) == 4)
                    {
                      p_uint64_t RootTensor = &v27;
                      *((_DWORD *)std::__hash_table<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::__unordered_map_hasher<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,true>,std::__unordered_map_equal<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::equal_to<ZinIrTensor const*>,std::hash<ZinIrTensor const*>,true>,std::allocator<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>>>::__emplace_unique_key_args<ZinIrTensor const*,std::piecewise_construct_t const&,std::tuple<ZinIrTensor const* const&>,std::tuple<>>((uint64_t)this + 72, &v27, (uint64_t)&std::piecewise_construct, &p_RootTensor)+ 6) = 5;
                    }
                    else
                    {
                      p_uint64_t RootTensor = &v27;
                      if (!*((_DWORD *)std::__hash_table<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::__unordered_map_hasher<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,true>,std::__unordered_map_equal<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::equal_to<ZinIrTensor const*>,std::hash<ZinIrTensor const*>,true>,std::allocator<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>>>::__emplace_unique_key_args<ZinIrTensor const*,std::piecewise_construct_t const&,std::tuple<ZinIrTensor const* const&>,std::tuple<>>((uint64_t)this + 72, &v27, (uint64_t)&std::piecewise_construct, &p_RootTensor)+ 6))
                      {
                        p_uint64_t RootTensor = &RootTensor;
                        std::__hash_table<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>>>::__emplace_unique_key_args<ZinIrTensor *,std::piecewise_construct_t const&,std::tuple<ZinIrTensor * const&>,std::tuple<>>((uint64_t)this + 280, &RootTensor, (uint64_t)&std::piecewise_construct, &p_RootTensor);
                        ZinCpBasedAllocator::RemoveDMABufferFromPressureAnalyzer(this, v9, v21);
                        ZinCpBasedAllocator::AddDMABufferToPressureAnalyzer(this, v9, v21);
                        uint64_t v16 = *(void *)(v8 + 48) + 1;
                        v25[0] = *(void *)(v8 + 48);
                        v25[1] = v16;
                        ZinIrMemoryPressureAnalyzer::GetTensorsBeyondBudget(v21, *(void *)(*((void *)this + 42) + 408), v25, (uint64_t)&p_RootTensor);
                        if (v24)
                        {
                          ZinCpBasedAllocator::RemoveDMABufferFromPressureAnalyzer(this, v9, v21);
                          *((void *)v9 + 6) = *(void *)(v8 + 48) + 1;
                          *((void *)v9 + 7) = 0;
                          ZinCpBasedAllocator::AddDMABufferToPressureAnalyzer(this, v9, v21);
                        }
                        else
                        {
                          uint64_t v31 = &v27;
                          *((_DWORD *)std::__hash_table<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::__unordered_map_hasher<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,true>,std::__unordered_map_equal<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::equal_to<ZinIrTensor const*>,std::hash<ZinIrTensor const*>,true>,std::allocator<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>>>::__emplace_unique_key_args<ZinIrTensor const*,std::piecewise_construct_t const&,std::tuple<ZinIrTensor const* const&>,std::tuple<>>((uint64_t)this + 72, &v27, (uint64_t)&std::piecewise_construct, &v31)+ 6) = 3;
                        }
                        std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&p_RootTensor, v23);
                      }
                    }
                  }
                  break;
                }
                ++v10;
              }
            }
          }
        }
        uint64_t v17 = (ZinCpBasedAllocator *)*((void *)v6 + 1);
        if (v17)
        {
          do
          {
            unsigned int v18 = v17;
            uint64_t v17 = *(ZinCpBasedAllocator **)v17;
          }
          while (v17);
        }
        else
        {
          do
          {
            unsigned int v18 = (ZinCpBasedAllocator *)*((void *)v6 + 2);
            BOOL v19 = *(void *)v18 == (void)v6;
            unint64_t v6 = v18;
          }
          while (!v19);
        }
        unint64_t v6 = v18;
      }
      while (v18 != (ZinCpBasedAllocator *)((char *)this + 32));
    }
  }
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v28, v29);
  return 0;
}

void sub_211377CA8(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, char a18, void *a19)
{
}

uint64_t ZinCpBasedAllocator::PromoteParallelExecutionBetweenSplitBranches(ZinIrOpLayer ****this, ZinIrMemoryPressureAnalyzer *a2)
{
  uint64_t v2 = (ZinCpBasedAllocator *)this;
  int64x2_t v95 = 0;
  unint64_t v96 = 0;
  long long v97 = 0;
  BOOL v3 = this[40];
  unint64_t v4 = *v3;
  uint64_t v5 = v3[1];
  if (*v3 == v5)
  {
    uint64_t v17 = 0;
    unsigned int v18 = 0;
  }
  else
  {
    do
    {
      unint64_t v6 = *v4;
      if (ZinIrOpLayer::IsANELayer(*v4))
      {
        uint64_t v7 = v96;
        if (v96 >= v97)
        {
          uint64_t v9 = v96 - v95;
          if ((unint64_t)(v9 + 1) >> 61) {
            std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
          }
          unint64_t v10 = ((char *)v97 - (char *)v95) >> 2;
          if (v10 <= v9 + 1) {
            unint64_t v10 = v9 + 1;
          }
          if ((unint64_t)((char *)v97 - (char *)v95) >= 0x7FFFFFFFFFFFFFF8) {
            unint64_t v11 = 0x1FFFFFFFFFFFFFFFLL;
          }
          else {
            unint64_t v11 = v10;
          }
          if (v11) {
            uint64_t v12 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)&v97, v11);
          }
          else {
            uint64_t v12 = 0;
          }
          BOOL v13 = (ZinIrOpLayer **)&v12[8 * v9];
          *BOOL v13 = v6;
          uint64_t v8 = v13 + 1;
          uint64_t v15 = v95;
          unint64_t v14 = v96;
          if (v96 != v95)
          {
            do
            {
              uint64_t v16 = *--v14;
              *--BOOL v13 = v16;
            }
            while (v14 != v15);
            unint64_t v14 = v95;
          }
          int64x2_t v95 = v13;
          unint64_t v96 = v8;
          long long v97 = (ZinIrOpLayer **)&v12[8 * v11];
          if (v14) {
            operator delete(v14);
          }
        }
        else
        {
          *unint64_t v96 = v6;
          uint64_t v8 = v7 + 1;
        }
        unint64_t v96 = v8;
      }
      ++v4;
    }
    while (v4 != v5);
    uint64_t v17 = (char *)v95;
    unsigned int v18 = v96;
  }
  if ((unint64_t)((char *)v18 - v17) >= 9)
  {
    BOOL v19 = (ZinCpBasedAllocator *)((char *)v2 + 1048);
    uint64_t v80 = (uint64_t)v2 + 280;
    uint64_t v81 = (void *)((char *)v2 + 72);
    unint64_t v20 = 1;
    uint64_t v21 = a2;
    int v78 = (ZinCpBasedAllocator *)((char *)v2 + 1048);
    int v79 = v2;
    do
    {
      uint64_t v22 = (ZinANELayer **)&v17[8 * v20];
      uint64_t v23 = *(v22 - 1);
      uint64_t v24 = *v22;
      uint64_t RootTensor = 0;
      unint64_t v25 = (const ZinIrTensor *)(*(uint64_t (**)(const ZinANELayer *, void, void))(*(void *)v23 + 32))(v23, 0, 0);
      uint64_t RootTensor = (const ZinIrTensor *)ZinTensorFamilyUtil::GetRootTensor(v19, v25);
      if ((ZinCpBasedAllocator::IsDisqualifiedForParallelExecution(v2, v23, v24) & 1) == 0
        && *(unsigned char *)((*(uint64_t (**)(const ZinANELayer *, void, void))(*(void *)v23 + 32))(v23, 0, 0)+ 144)&& *(unsigned char *)((*(uint64_t (**)(ZinANELayer *, void, void))(*(void *)v24 + 32))(v24, 0, 0)+ 144))
      {
        uint64_t v26 = (*(uint64_t (**)(const ZinANELayer *, void, void))(*(void *)v23 + 32))(v23, 0, 0);
        if (!*(unsigned char *)(v26 + 144)) {
          std::__throw_bad_optional_access[abi:ne180100]();
        }
        int v27 = *(unsigned __int16 *)(v26 + 128);
        uint64_t v28 = (*(uint64_t (**)(ZinANELayer *, void, void))(*(void *)v24 + 32))(v24, 0, 0);
        if (!*(unsigned char *)(v28 + 144)) {
          std::__throw_bad_optional_access[abi:ne180100]();
        }
        if (v27 != *(unsigned __int16 *)(v28 + 128))
        {
          uint64_t v29 = *((void *)v24 + 7) + *((void *)v24 + 6);
          v93[0] = *((void *)v23 + 6);
          v93[1] = v29;
          unint64_t PeakPressure = ZinIrMemoryPressureAnalyzer::GetPeakPressure(v21, (const ZinLiveRange *)v93);
          if (PeakPressure <= *(void *)(*((void *)v2 + 42) + 408))
          {
            unint64_t v72 = PeakPressure;
            *(void *)&v90[0] = &RootTensor;
            long long v92 = *(_OWORD *)(std::__hash_table<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>>>::__emplace_unique_key_args<ZinIrTensor *,std::piecewise_construct_t const&,std::tuple<ZinIrTensor * const&>,std::tuple<>>(v80, &RootTensor, (uint64_t)&std::piecewise_construct, (void **)v90)+ 3);
            uint64_t v31 = *((void *)v23 + 6);
            uint64_t v73 = *((void *)v23 + 7);
            uint64_t v32 = *((void *)v24 + 6);
            uint64_t v33 = *((void *)v24 + 7);
            ZinCpBasedAllocator::RemoveDMABufferFromPressureAnalyzer(v79, v23, v21);
            *((void *)v23 + 7) = v32 - v31 + v33;
            ZinCpBasedAllocator::AddDMABufferToPressureAnalyzer(v79, v23, v21);
            memset(v90, 0, sizeof(v90));
            int v91 = 1065353216;
            memset(v88, 0, sizeof(v88));
            int v89 = 1065353216;
            unint64_t v34 = (uint64_t *)*((void *)v23 + 11);
            char v35 = (uint64_t *)*((void *)v23 + 12);
            while (v34 != v35)
            {
              uint64_t v36 = *v34;
              v98[0] = 0;
              char v37 = (const ZinIrTensor *)(*(uint64_t (**)(uint64_t, void, void))(*(void *)v36 + 32))(v36, 0, 0);
              v98[0] = (void *)ZinTensorFamilyUtil::GetRootTensor(v78, v37);
              int v38 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::find<ZinIrTensor *>(v81, v98);
              if (!v38) {
                std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
              }
              int v39 = *((_DWORD *)v38 + 6);
              *(void *)&long long v82 = v98;
              long long v85 = *(_OWORD *)(std::__hash_table<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>>>::__emplace_unique_key_args<ZinIrTensor *,std::piecewise_construct_t const&,std::tuple<ZinIrTensor * const&>,std::tuple<>>(v80, v98, (uint64_t)&std::piecewise_construct, (void **)&v82)+ 3);
              ZinL2FootprintCalculator::GetResidentBufferSize(*((ZinL2FootprintCalculator **)v79 + 34), (const ZinIrTensor *)v98[0]);
              unint64_t v41 = v40;
              uint64_t v42 = *((void *)&v85 + 1);
              uint64_t v43 = *((void *)v24 + 6);
              uint64_t v44 = *((void *)v24 + 7);
              *(void *)&long long v82 = v98;
              *((unsigned char *)std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,BOOL>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,BOOL>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,BOOL>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,BOOL>>>::__emplace_unique_key_args<ZinIrOpLayer const*,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer const* const&>,std::tuple<>>((uint64_t)v88, v98, (uint64_t)&std::piecewise_construct, (void **)&v82)+ 24) = v42 < v44 + v43;
              if (CpAllocUtils::IsResident(v39))
              {
                *(void *)&long long v82 = v98;
                if (*((unsigned char *)std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,BOOL>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,BOOL>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,BOOL>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,BOOL>>>::__emplace_unique_key_args<ZinIrOpLayer const*,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer const* const&>,std::tuple<>>((uint64_t)v88, v98, (uint64_t)&std::piecewise_construct, (void **)&v82)+ 24))
                {
                  ZinIrMemoryPressureAnalyzer::RemoveTensorAllocation(a2, (const ZinIrTensor *)v98[0], (const ZinLiveRange *)&v85);
                  *((void *)&v85 + 1) = *((void *)v24 + 7) + *((void *)v24 + 6);
                  ZinIrMemoryPressureAnalyzer::AddTensorAllocation(a2, v41, (const ZinLiveRange *)&v85, (const ZinIrTensor *)v98[0]);
                }
              }
              ++v34;
            }
            uint64_t v87 = 0;
            int v45 = (const ZinIrTensor *)(*(uint64_t (**)(const ZinANELayer *, void, void))(*(void *)v23 + 32))(v23, 0, 0);
            uint64_t v87 = ZinTensorFamilyUtil::GetRootTensor(v78, v45);
            unint64_t v46 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::find<ZinIrTensor *>(v81, &v87);
            uint64_t v21 = a2;
            if (!v46) {
              std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
            }
            int v47 = *((_DWORD *)v46 + 6);
            ZinL2FootprintCalculator::GetResidentBufferSize(*((ZinL2FootprintCalculator **)v79 + 34), RootTensor);
            unint64_t v76 = v48;
            uint64_t v49 = *((void *)&v92 + 1);
            uint64_t v50 = *((void *)v24 + 7) + *((void *)v24 + 6);
            if (CpAllocUtils::IsResident(v47) && v49 < v50)
            {
              ZinIrMemoryPressureAnalyzer::RemoveTensorAllocation(a2, RootTensor, (const ZinLiveRange *)&v92);
              *((void *)&v92 + 1) = *((void *)v24 + 7) + *((void *)v24 + 6);
              ZinIrMemoryPressureAnalyzer::AddTensorAllocation(a2, v76, (const ZinLiveRange *)&v92, RootTensor);
            }
            uint64_t v2 = v79;
            ZinIrMemoryPressureAnalyzer::GetTensorsBeyondBudget(a2, *(void *)(*((void *)v79 + 42) + 408), v93, (uint64_t)&v85);
            BOOL v19 = v78;
            uint64_t v74 = v50;
            uint64_t v75 = v49;
            if (v86)
            {
              ZinCpBasedAllocator::RemoveDMABufferFromPressureAnalyzer(v79, v23, a2);
              *((void *)v23 + 7) = v73;
              ZinCpBasedAllocator::AddDMABufferToPressureAnalyzer(v79, v23, a2);
              int v51 = (uint64_t *)*((void *)v23 + 11);
              uint64_t v52 = (uint64_t *)*((void *)v23 + 12);
              while (v51 != v52)
              {
                uint64_t v53 = *v51;
                uint64_t v84 = 0;
                BOOL v54 = (const ZinIrTensor *)(*(uint64_t (**)(uint64_t, void, void))(*(void *)v53 + 32))(v53, 0, 0);
                uint64_t v84 = (ZinIrTensor *)ZinTensorFamilyUtil::GetRootTensor(v78, v54);
                uint64_t v55 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::find<ZinIrTensor *>(v81, &v84);
                if (!v55) {
                  std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
                }
                int v56 = *((_DWORD *)v55 + 6);
                v98[0] = &v84;
                long long v82 = *(_OWORD *)(std::__hash_table<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>>>::__emplace_unique_key_args<ZinIrTensor *,std::piecewise_construct_t const&,std::tuple<ZinIrTensor * const&>,std::tuple<>>((uint64_t)v90, &v84, (uint64_t)&std::piecewise_construct, v98)+ 3);
                ZinL2FootprintCalculator::GetResidentBufferSize(*((ZinL2FootprintCalculator **)v79 + 34), v84);
                unint64_t v58 = v57;
                if (CpAllocUtils::IsResident(v56))
                {
                  v98[0] = &v84;
                  if (*((unsigned char *)std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,BOOL>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,BOOL>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,BOOL>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,BOOL>>>::__emplace_unique_key_args<ZinIrOpLayer const*,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer const* const&>,std::tuple<>>((uint64_t)v88, &v84, (uint64_t)&std::piecewise_construct, v98)+ 24))
                  {
                    ZinIrMemoryPressureAnalyzer::RemoveTensorAllocation(a2, v84, (const ZinLiveRange *)&v82);
                    v98[0] = &v84;
                    int v59 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>>>::__emplace_unique_key_args<ZinIrTensor *,std::piecewise_construct_t const&,std::tuple<ZinIrTensor * const&>,std::tuple<>>(v80, &v84, (uint64_t)&std::piecewise_construct, v98);
                    ZinIrMemoryPressureAnalyzer::AddTensorAllocation(a2, v58, (const ZinLiveRange *)(v59 + 3), v84);
                  }
                }
                ++v51;
              }
              if (CpAllocUtils::IsResident(v47) && v75 < v74)
              {
                ZinIrMemoryPressureAnalyzer::RemoveTensorAllocation(a2, RootTensor, (const ZinLiveRange *)&v92);
                *(void *)&long long v82 = &RootTensor;
                int v60 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>>>::__emplace_unique_key_args<ZinIrTensor *,std::piecewise_construct_t const&,std::tuple<ZinIrTensor * const&>,std::tuple<>>(v80, &RootTensor, (uint64_t)&std::piecewise_construct, (void **)&v82);
                ZinIrMemoryPressureAnalyzer::AddTensorAllocation(a2, v76, (const ZinLiveRange *)(v60 + 3), RootTensor);
              }
              ZinIrMemoryPressureAnalyzer::GetTensorsBeyondBudget(a2, *(void *)(*((void *)v79 + 42) + 408), v93, (uint64_t)&v82);
              std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v85, *((void **)&v85 + 1));
              int v61 = (void *)*((void *)&v82 + 1);
              long long v85 = v82;
              uint64_t v86 = v83;
              if (v83)
              {
                *(void *)(*((void *)&v82 + 1) + 16) = (char *)&v85 + 8;
                *(void *)&long long v82 = (char *)&v82 + 8;
                *((void *)&v82 + 1) = 0;
                uint64_t v83 = 0;
                int v61 = 0;
              }
              else
              {
                *(void *)&long long v85 = (char *)&v85 + 8;
              }
              std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v82, v61);
              if (v72 != ZinIrMemoryPressureAnalyzer::GetPeakPressure(a2, (const ZinLiveRange *)v93))
              {
                int v70 = (void *)((char *)RootTensor + 24);
                uint64_t v71 = "Invalid memory pressure analyzer while parallel execution between tiles update in %s";
                if (*((char *)RootTensor + 47) < 0) {
                  goto LABEL_82;
                }
                goto LABEL_83;
              }
              if (v86)
              {
                int v70 = (void *)((char *)RootTensor + 24);
                uint64_t v71 = "Invalid parallel execution between tiles update in %s";
                if (*((char *)RootTensor + 47) < 0) {
LABEL_82:
                }
                  int v70 = (void *)*v70;
LABEL_83:
                ZinAssertImpl(v71, v70);
              }
            }
            else
            {
              char v62 = (uint64_t *)*((void *)v23 + 11);
              unint64_t v63 = (uint64_t *)*((void *)v23 + 12);
              while (v62 != v63)
              {
                uint64_t v64 = *v62;
                v98[0] = 0;
                uint64_t v65 = (const ZinIrTensor *)(*(uint64_t (**)(uint64_t, void, void))(*(void *)v64 + 32))(v64, 0, 0);
                v98[0] = (void *)ZinTensorFamilyUtil::GetRootTensor(v78, v65);
                int v66 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::find<ZinIrTensor *>(v81, v98);
                if (!v66) {
                  std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
                }
                if (CpAllocUtils::IsResident(*((_DWORD *)v66 + 6)))
                {
                  *(void *)&long long v82 = v98;
                  if (*((unsigned char *)std::__hash_table<std::__hash_value_type<ZinIrOpLayer const*,BOOL>,std::__unordered_map_hasher<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,BOOL>,std::hash<ZinIrOpLayer const*>,std::equal_to<ZinIrOpLayer const*>,true>,std::__unordered_map_equal<ZinIrOpLayer const*,std::__hash_value_type<ZinIrOpLayer const*,BOOL>,std::equal_to<ZinIrOpLayer const*>,std::hash<ZinIrOpLayer const*>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer const*,BOOL>>>::__emplace_unique_key_args<ZinIrOpLayer const*,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer const* const&>,std::tuple<>>((uint64_t)v88, v98, (uint64_t)&std::piecewise_construct, (void **)&v82)+ 24))
                  {
                    *(void *)&long long v82 = v98;
                    uint64_t v67 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>>>::__emplace_unique_key_args<ZinIrTensor *,std::piecewise_construct_t const&,std::tuple<ZinIrTensor * const&>,std::tuple<>>((uint64_t)v90, v98, (uint64_t)&std::piecewise_construct, (void **)&v82);
                    *(void *)&long long v82 = v98;
                    *(_OWORD *)(std::__hash_table<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>>>::__emplace_unique_key_args<ZinIrTensor *,std::piecewise_construct_t const&,std::tuple<ZinIrTensor * const&>,std::tuple<>>(v80, v98, (uint64_t)&std::piecewise_construct, (void **)&v82)+ 3) = *(_OWORD *)(v67 + 3);
                  }
                }
                ++v62;
              }
              if (CpAllocUtils::IsResident(v47) && v75 < v74)
              {
                *(void *)&long long v82 = &RootTensor;
                uint64_t v68 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>>>::__emplace_unique_key_args<ZinIrTensor *,std::piecewise_construct_t const&,std::tuple<ZinIrTensor * const&>,std::tuple<>>(v80, &RootTensor, (uint64_t)&std::piecewise_construct, (void **)&v82);
                *(_OWORD *)(v68 + 3) = v92;
              }
            }
            std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v85, *((void **)&v85 + 1));
            std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v88);
            std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v90);
          }
        }
      }
      ++v20;
      uint64_t v17 = (char *)v95;
    }
    while (v20 < v96 - v95);
  }
  if (v17)
  {
    unint64_t v96 = (ZinIrOpLayer **)v17;
    operator delete(v17);
  }
  return 0;
}

void sub_21137871C(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,char a27,void *a28,uint64_t a29,uint64_t a30,char a31,uint64_t a32,uint64_t a33,uint64_t a34,uint64_t a35,uint64_t a36,char a37)
{
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&a27, a28);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&a31);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&a37);
  int v39 = *(void **)(v37 - 128);
  if (v39)
  {
    *(void *)(v37 - 12std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v39;
    operator delete(v39);
  }
  _Unwind_Resume(a1);
}

uint64_t ZinCpBasedAllocator::VerifyAllocationDecision(ZinCpBasedAllocator *this, ZinIrMemoryPressureAnalyzer *a2)
{
  uint64_t v28 = *MEMORY[0x263EF8340];
  unint64_t v4 = (char *)*((void *)this + 3);
  uint64_t v5 = (char *)this + 32;
  if (v4 == (char *)this + 32)
  {
LABEL_9:
    unint64_t v9 = *(void *)(*((void *)this + 42) + 408);
    uint64_t v10 = *(void *)(*(void *)(*((void *)this + 40) + 8) - 8);
    uint64_t v11 = *(void *)(v10 + 56) + *(void *)(v10 + 48);
    *(void *)std::string __p = 0;
    *(void *)&__p[8] = v11;
    ZinIrMemoryPressureAnalyzer::GetTensorsBeyondBudget(a2, v9, (uint64_t *)__p, (uint64_t)&v22);
    uint64_t v12 = v24;
    *((unsigned char *)this + 968) = v24 == 0;
    if (v12)
    {
      if (*((void *)this + 63))
      {
        ZinIrMemoryPressureAnalyzer::GetDebugString(a2, *(void *)(*((void *)this + 42) + 408), __p);
        BOOL v13 = v26 >= 0 ? __p : *(unsigned char **)__p;
        uint64_t v14 = v26 >= 0 ? HIBYTE(v26) : *(void *)&__p[8];
        std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>((void *)this + 47, (uint64_t)v13, v14);
        if (SHIBYTE(v26) < 0) {
          operator delete(*(void **)__p);
        }
      }
      std::__hash_table<std::__hash_value_type<ZinIrDimension,unsigned long>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,unsigned long>>>::clear((void *)this + 9);
      uint64_t v15 = v22;
      if (v22 != &v23)
      {
        uint64_t v16 = &_os_log_internal;
        do
        {
          if (os_log_type_enabled(v16, OS_LOG_TYPE_INFO))
          {
            uint64_t v17 = v15[4];
            unsigned int v18 = (void *)(v17 + 24);
            if (*(char *)(v17 + 47) < 0) {
              unsigned int v18 = (void *)*v18;
            }
            *(_DWORD *)std::string __p = 136315650;
            *(void *)&__p[4] = v18;
            *(_WORD *)&__p[12] = 2080;
            *(void *)&__p[14] = "/Library/Caches/com.apple.xbs/Sources/ANECompiler/libs/inference/compiler/ZinIrSchedul"
                                  "e/src/ZinCpBasedAllocator.cpp";
            __int16 v26 = 1024;
            int v27 = 2238;
            _os_log_impl(&dword_210C72000, v16, OS_LOG_TYPE_INFO, "INFO: Allocation decision in %s is beyond budget (file %s, line %d)\n", __p, 0x1Cu);
          }
          BOOL v19 = (void *)v15[1];
          if (v19)
          {
            do
            {
              unint64_t v20 = (void **)v19;
              BOOL v19 = (void *)*v19;
            }
            while (v19);
          }
          else
          {
            do
            {
              unint64_t v20 = (void **)v15[2];
              BOOL v8 = *v20 == v15;
              uint64_t v15 = v20;
            }
            while (!v8);
          }
          uint64_t v15 = v20;
        }
        while (v20 != &v23);
      }
    }
    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v22, v23);
    return 0;
  }
  else
  {
    while (1)
    {
      *(void *)std::string __p = *((void *)v4 + 4);
      if (!std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::find<ZinIrTensor *>((void *)this + 9, __p))break; {
      unint64_t v6 = (char *)*((void *)v4 + 1);
      }
      if (v6)
      {
        do
        {
          uint64_t v7 = v6;
          unint64_t v6 = *(char **)v6;
        }
        while (v6);
      }
      else
      {
        do
        {
          uint64_t v7 = (char *)*((void *)v4 + 2);
          BOOL v8 = *(void *)v7 == (void)v4;
          unint64_t v4 = v7;
        }
        while (!v8);
      }
      unint64_t v4 = v7;
      if (v7 == v5) {
        goto LABEL_9;
      }
    }
    if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
      ZinCpBasedAllocator::VerifyAllocationDecision((uint64_t)__p);
    }
    return 3;
  }
}

void sub_211378A6C(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, char a12, void *a13, uint64_t a14, void *__p, uint64_t a16, int a17, __int16 a18, char a19, char a20)
{
  if (a20 < 0) {
    operator delete(__p);
  }
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&a12, a13);
  _Unwind_Resume(a1);
}

uint64_t ZinCpBasedAllocator::CalculatePerf(uint64_t a1, ZinANELayer *a2, uint64_t a3, void *a4, char a5, ZinPerfDescriptor *a6)
{
  ZinIrHalParameters::GetOperationCondition(*(ZinIrHalParameters **)(a1 + 336), *(double *)(*(void *)(a1 + 344) + 104), *(_DWORD *)(*(void *)(a1 + 344) + 112), *(_DWORD *)(*(void *)(a1 + 344) + 116), (uint64_t)v72);
  uint64_t v12 = *(void *)(a1 + 336);
  *(_WORD *)uint64_t v15 = 257;
  v15[2] = 1;
  *(_DWORD *)&v15[3] = 0;
  *(_DWORD *)&v15[6] = 0;
  char v16 = 1;
  int v17 = 0;
  ZinIrPerf::ZinIrPerf((uint64_t)v71, v12, v72, (uint64_t *)v15);
  if (ZinIrOpLayer::IsNELayer(a2))
  {
    v15[8] = 0;
    char v18 = 0;
    char v19 = 0;
    char v20 = 0;
    char v21 = 0;
    char v22 = 0;
    char v23 = 0;
    char v24 = 0;
    char v25 = 0;
    char v26 = 0;
    char v27 = 0;
    char v28 = 0;
    char v29 = 0;
    char v30 = 0;
    char v31 = 0;
    char v32 = 0;
    char v33 = 0;
    char v34 = 0;
    char v35 = 0;
    char v36 = 0;
    char v37 = 0;
    char v38 = 0;
    char v39 = 0;
    char v40 = 0;
    char v41 = 0;
    char v42 = 0;
    *(void *)uint64_t v15 = &unk_26C34D080;
    __int16 v43 = 0;
    char v47 = 0;
    char v48 = 0;
    __int16 v49 = 256;
    long long __p = 0u;
    uint64_t v45 = 0;
    __int16 v46 = 0;
    char v50 = 0;
    char v51 = 0;
    __int16 v52 = 0;
    char v53 = 0;
    char v54 = 0;
    char v55 = 0;
    char v56 = 0;
    char v57 = 0;
    char v58 = 0;
    char v59 = 0;
    char v60 = 0;
    char v61 = 0;
    char v62 = 0;
    char v63 = 0;
    char v64 = 0;
    char v65 = 0;
    char v66 = 0;
    __int16 v67 = 0;
    char v68 = 0;
    char v69 = 0;
    int v70 = 0;
    ZinCpBasedAllocator::GetCustomPerfInfo(a1, (uint64_t)a2, a4, a5, a3, (uint64_t)v15);
    uint64_t v13 = ZinANELayer::CalculatePerf(a2, (ZinIrPerf *)v71, (const ZinCustomPerfInfo *)v15, a6);
    *(void *)uint64_t v15 = &unk_26C34D080;
    if ((void)__p)
    {
      *((void *)&__p + 1) = __p;
      operator delete((void *)__p);
    }
  }
  else
  {
    v15[8] = 0;
    char v18 = 0;
    char v19 = 0;
    char v20 = 0;
    char v21 = 0;
    char v22 = 0;
    char v23 = 0;
    char v24 = 0;
    char v25 = 0;
    char v26 = 0;
    char v27 = 0;
    char v28 = 0;
    char v29 = 0;
    char v30 = 0;
    char v31 = 0;
    char v32 = 0;
    char v33 = 0;
    char v34 = 0;
    char v35 = 0;
    char v36 = 0;
    char v37 = 0;
    char v38 = 0;
    char v39 = 0;
    char v40 = 0;
    char v41 = 0;
    char v42 = 0;
    *(void *)uint64_t v15 = &unk_26C34D0D8;
    LOBYTE(v43) = 0;
    LOBYTE(__p) = 0;
    BYTE8(__p) = 0;
    LOBYTE(v45) = 0;
    ZinCpBasedAllocator::GetCustomPerfInfo(a1, (uint64_t)a2, a4, a5, a3, (uint64_t)v15);
    uint64_t v13 = ZinANELayer::CalculatePerf(a2, (ZinIrPerf *)v71, (const ZinCustomPerfInfo *)v15, a6);
  }
  ZinIrHalH13g::~ZinIrHalH13g((ZinIrHalH13g *)v15);
  if (v13)
  {
    if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
      ZinCpBasedAllocator::CalculatePerf();
    }
    uint64_t v13 = 3;
  }
  ZinIrPerf::~ZinIrPerf((ZinIrPerf *)v71);
  return v13;
}

void sub_211378DA8(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  ZinIrHalH13g::~ZinIrHalH13g((ZinIrHalH13g *)va);
  ZinIrPerf::~ZinIrPerf((ZinIrPerf *)&STACK[0x2E0]);
  _Unwind_Resume(a1);
}

void ZinCpBasedAllocator::GetCustomPerfInfo(uint64_t a1, uint64_t a2, void *a3, char a4, uint64_t a5, uint64_t a6)
{
  uint64_t v37 = *MEMORY[0x263EF8340];
  (*(void (**)(void **__return_ptr, uint64_t))(*(void *)a2 + 512))(&__p, a2);
  BOOL v8 = __p;
  if (v34 != __p)
  {
    unint64_t v9 = 0;
    unint64_t v10 = 0;
    uint64_t v11 = a6 + 56;
    do
    {
      uint64_t v32 = 0;
      uint64_t v32 = v8[v9];
      char v12 = *(unsigned char *)(v32 + 48);
      long long v13 = *(_OWORD *)(v32 + 65);
      long long v35 = *(_OWORD *)(v32 + 49);
      *(_OWORD *)char v36 = v13;
      *(void *)&v36[15] = *(void *)(v32 + 80);
      int v14 = *(_DWORD *)(v32 + 88);
      unint64_t v15 = *(void *)(*a3 + ((v9 >> 3) & 0x1FFFFFFFFFFFFFF8));
      char v16 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)(a1 + 152), &v32);
      if (v16)
      {
        unint64_t v17 = v16[3];
        unint64_t v10 = v17 >> 8;
        char v18 = 1;
      }
      else
      {
        char v18 = 0;
        LOBYTE(v17) = 0;
      }
      long long v19 = *(_OWORD *)v36;
      *(_OWORD *)(v11 - 47) = v35;
      int v20 = *(unsigned __int8 *)(v11 + 56);
      *(unsigned char *)(v11 - 48) = v12;
      *(_OWORD *)(v11 - 31) = v19;
      *(void *)(v11 - 16) = *(void *)&v36[15];
      *(unsigned char *)(v11 - 8) = 1;
      *(_DWORD *)uint64_t v11 = v14;
      *(unsigned char *)(v11 + 4) = 1;
      *(unsigned char *)(v11 + 8) = (v15 >> v9) & 1;
      *(unsigned char *)(v11 + 9) = 1;
      *(void *)(v11 + 16) = v17 | (v10 << 8);
      if (!v20) {
        *(unsigned char *)(v11 + 56) = 1;
      }
      *(unsigned char *)(v11 + 24) = v18;
      *(unsigned char *)(v11 + 32) = 0;
      *(unsigned char *)(v11 + 48) = 0;
      ++v9;
      BOOL v8 = __p;
      v11 += 112;
    }
    while (v9 < (v34 - (unsigned char *)__p) >> 3);
  }
  uint64_t v21 = (*(uint64_t (**)(uint64_t, void, void))(*(void *)a2 + 32))(a2, 0, 0);
  long long v22 = *(_OWORD *)(v21 + 64);
  long long v35 = *(_OWORD *)(v21 + 48);
  *(_OWORD *)char v36 = v22;
  *(void *)&v36[16] = *(void *)(v21 + 80);
  int v23 = *(_DWORD *)((*(uint64_t (**)(uint64_t, void, void))(*(void *)a2 + 32))(a2, 0, 0) + 88);
  long long v24 = *(_OWORD *)v36;
  *(_OWORD *)(a6 + 232) = v35;
  int v25 = *(unsigned __int8 *)(a6 + 336);
  *(_OWORD *)(a6 + 248) = v24;
  *(void *)(a6 + 264) = *(void *)&v36[16];
  *(unsigned char *)(a6 + 272) = 1;
  *(_DWORD *)(a6 + 28std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v23;
  *(unsigned char *)(a6 + 284) = 1;
  *(unsigned char *)(a6 + 288) = a4;
  *(unsigned char *)(a6 + 289) = 1;
  *(unsigned char *)(a6 + 296) = 0;
  if (!v25) {
    *(unsigned char *)(a6 + 336) = 1;
  }
  *(unsigned char *)(a6 + 304) = 0;
  *(unsigned char *)(a6 + 312) = 0;
  *(unsigned char *)(a6 + 328) = 0;
  *(void *)&long long v35 = (*(uint64_t (**)(uint64_t, void, void))(*(void *)a2 + 32))(a2, 0, 0);
  char v26 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)(a1 + 152), &v35);
  if (v26)
  {
    uint64_t v27 = v26[3];
    if (!*(unsigned char *)(a6 + 304)) {
      *(unsigned char *)(a6 + 304) = 1;
    }
    *(void *)(a6 + 296) = v27;
  }
  if ((**(unsigned int (***)(uint64_t, uint64_t))a6)(a6, a5)) {
    ZinAssertImpl("Error: Failed to set custom perf info");
  }
  if (__p)
  {
    char v34 = __p;
    operator delete(__p);
  }
}

void sub_211379100(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, void *__p, uint64_t a15)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinCpBasedAllocator::CollectNEPerfNumbers(uint64_t a1, ZinEnginePerf ***this, int a3, uint64_t a4, void *a5, unint64_t *a6, uint64_t a7)
{
  ZinANELayer::CopyMirInfo((uint64_t)this, &v138);
  if (!a3)
  {
    uint64_t v124 = a4;
    uint64_t v17 = a7;
    char v18 = a5;
    long long v19 = a6;
    ZinL2FootprintCalculator::ComputeNonResidentWU(*(ZinL2FootprintCalculator **)(a1 + 272), (const ZinIrOpLayer *)this, (uint64_t)__p);
    int v20 = v138;
    memcpy(v138 + 30, __p, 0x1C0uLL);
    v20[142] = v132;
    std::__hash_table<std::__hash_value_type<ZinDependencyOffsetDim,long>,std::__unordered_map_hasher<ZinDependencyOffsetDim,std::__hash_value_type<ZinDependencyOffsetDim,long>,std::hash<ZinDependencyOffsetDim>,std::equal_to<ZinDependencyOffsetDim>,true>,std::__unordered_map_equal<ZinDependencyOffsetDim,std::__hash_value_type<ZinDependencyOffsetDim,long>,std::equal_to<ZinDependencyOffsetDim>,std::hash<ZinDependencyOffsetDim>,true>,std::allocator<std::__hash_value_type<ZinDependencyOffsetDim,long>>>::__move_assign((uint64_t)(v20 + 144), v133);
    v20[154] = v134;
    std::__hash_table<std::__hash_value_type<ZinDependencyOffsetDim,long>,std::__unordered_map_hasher<ZinDependencyOffsetDim,std::__hash_value_type<ZinDependencyOffsetDim,long>,std::hash<ZinDependencyOffsetDim>,std::equal_to<ZinDependencyOffsetDim>,true>,std::__unordered_map_equal<ZinDependencyOffsetDim,std::__hash_value_type<ZinDependencyOffsetDim,long>,std::equal_to<ZinDependencyOffsetDim>,std::hash<ZinDependencyOffsetDim>,true>,std::allocator<std::__hash_value_type<ZinDependencyOffsetDim,long>>>::__move_assign((uint64_t)(v20 + 156), v135);
    v20[166] = v136;
    std::__hash_table<std::__hash_value_type<ZinDependencyOffsetDim,long>,std::__unordered_map_hasher<ZinDependencyOffsetDim,std::__hash_value_type<ZinDependencyOffsetDim,long>,std::hash<ZinDependencyOffsetDim>,std::equal_to<ZinDependencyOffsetDim>,true>,std::__unordered_map_equal<ZinDependencyOffsetDim,std::__hash_value_type<ZinDependencyOffsetDim,long>,std::equal_to<ZinDependencyOffsetDim>,std::hash<ZinDependencyOffsetDim>,true>,std::allocator<std::__hash_value_type<ZinDependencyOffsetDim,long>>>::__move_assign((uint64_t)(v20 + 168), v137);
    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v137);
    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v135);
    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v133);
    a6 = v19;
    a5 = v18;
    a7 = v17;
    a4 = v124;
    goto LABEL_7;
  }
  ZinMirL2Config::ZinMirSetTileHeight((ZinMirL2Config *)(v138 + 30), (const ZinANELayer *)this, 1);
  LODWORD(v129) = 65793;
  BYTE4(v129) = 0;
  int v14 = v138;
  unsigned int v15 = *(_DWORD *)(ZinIrOpLayer::GetInputTensor((ZinIrOpLayer *)this, 0) + 88);
  ZinIrOpLayer::GetInputTensorDimensions((ZinIrOpLayer *)this, __p);
  char v16 = ZinMirL2Config::ZinMirSetWorkUnitShape((uint64_t)(v14 + 30), (uint64_t)this, v15);
  if (__p[0])
  {
    __p[1] = __p[0];
    operator delete(__p[0]);
  }
  if (v16)
  {
    ZinMirL2Config::ZinMirSetFormats((ZinMirL2Config *)(v138 + 30), (const ZinIrOpLayer *)this);
LABEL_7:
    memset(__p, 0, 200);
    uint64_t v21 = operator new(8uLL);
    __p[25] = v21;
    void *v21 = 0;
    __p[26] = v21 + 1;
    __p[27] = v21 + 1;
    __p[28] = 0;
    __p[29] = 0;
    __asm { FMOV            V0.2D, #-1.0 }
    *(_OWORD *)&__p[30] = _Q0;
    *(_OWORD *)&__p[32] = _Q0;
    *(_OWORD *)&__p[34] = _Q0;
    *(_OWORD *)&__p[36] = _Q0;
    __p[38] = 0;
    LOBYTE(__p[39]) = 0;
    __p[40] = 0;
    uint64_t v27 = (uint64_t)v138;
    char v128 = a3;
    std::vector<BOOL>::vector(&v129, &v128, 1);
    int v28 = ZinCpBasedAllocator::CalculatePerf(a1, (ZinANELayer *)this, v27, &v129, a3, (ZinPerfDescriptor *)__p);
    if (v129) {
      operator delete(v129);
    }
    if (v28)
    {
      uint64_t v29 = 3;
    }
    else
    {
      ((void (*)(void **__return_ptr, ZinEnginePerf ***))(*this)[64])(&v129, this);
      if (a3)
      {
        unint64_t v30 = (unint64_t)((double)(unint64_t)__p[17] / *(double *)(a1 + 984) * 1000.0 * 1000.0 * 1000.0);
        uint64_t v32 = (void *)(a4 + 16);
        unint64_t v31 = *(void *)(a4 + 16);
        char v33 = *(unint64_t **)(a4 + 8);
        if ((unint64_t)v33 >= v31)
        {
          __int16 v43 = *(unint64_t **)a4;
          uint64_t v44 = ((uint64_t)v33 - *(void *)a4) >> 3;
          unint64_t v45 = v44 + 1;
          if ((unint64_t)(v44 + 1) >> 61) {
            std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
          }
          uint64_t v46 = v31 - (void)v43;
          if (v46 >> 2 > v45) {
            unint64_t v45 = v46 >> 2;
          }
          if ((unint64_t)v46 >= 0x7FFFFFFFFFFFFFF8) {
            unint64_t v47 = 0x1FFFFFFFFFFFFFFFLL;
          }
          else {
            unint64_t v47 = v45;
          }
          if (v47)
          {
            char v48 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>(a4 + 16, v47);
            __int16 v43 = *(unint64_t **)a4;
            char v33 = *(unint64_t **)(a4 + 8);
          }
          else
          {
            char v48 = 0;
          }
          char v55 = (unint64_t *)&v48[8 * v44];
          char v56 = &v48[8 * v47];
          *char v55 = v30;
          char v34 = v55 + 1;
          while (v33 != v43)
          {
            unint64_t v57 = *--v33;
            *--char v55 = v57;
          }
          *(void *)a4 = v55;
          *(void *)(a4 + 8) = v34;
          *(void *)(a4 + 16) = v56;
          if (v43) {
            operator delete(v43);
          }
        }
        else
        {
          *char v33 = v30;
          char v34 = v33 + 1;
        }
        *(void *)(a4 + 8) = v34;
        double v58 = *(double *)(a1 + 984);
        if ((unint64_t)(v130 - (unsigned char *)v129) >= 9)
        {
          unint64_t v59 = (unint64_t)((double)(unint64_t)__p[17] / v58 * 1000.0 * 1000.0 * 1000.0);
          if ((unint64_t)v34 >= *v32)
          {
            char v61 = *(unint64_t **)a4;
            uint64_t v62 = ((uint64_t)v34 - *(void *)a4) >> 3;
            unint64_t v63 = v62 + 1;
            if ((unint64_t)(v62 + 1) >> 61) {
              std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
            }
            uint64_t v64 = *v32 - (void)v61;
            if (v64 >> 2 > v63) {
              unint64_t v63 = v64 >> 2;
            }
            if ((unint64_t)v64 >= 0x7FFFFFFFFFFFFFF8) {
              unint64_t v65 = 0x1FFFFFFFFFFFFFFFLL;
            }
            else {
              unint64_t v65 = v63;
            }
            if (v65)
            {
              char v66 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>(a4 + 16, v65);
              char v61 = *(unint64_t **)a4;
              char v34 = *(unint64_t **)(a4 + 8);
            }
            else
            {
              char v66 = 0;
            }
            uint64_t v100 = (unint64_t *)&v66[8 * v62];
            int v101 = &v66[8 * v65];
            *uint64_t v100 = v59;
            char v60 = v100 + 1;
            while (v34 != v61)
            {
              unint64_t v102 = *--v34;
              *--uint64_t v100 = v102;
            }
            *(void *)a4 = v100;
            *(void *)(a4 + 8) = v60;
            *(void *)(a4 + 16) = v101;
            if (v61) {
              operator delete(v61);
            }
          }
          else
          {
            unint64_t *v34 = v59;
            char v60 = v34 + 1;
          }
          *(void *)(a4 + 8) = v60;
          double v58 = *(double *)(a1 + 984);
        }
        unint64_t v103 = __p[19];
        *a5 = (unint64_t)((double)(unint64_t)__p[10] / *(double *)(a1 + 976) * 1000.0 * 1000.0 * 1000.0);
        unint64_t v104 = (unint64_t)((double)(unint64_t)v103 / v58 * 1000.0 * 1000.0 * 1000.0);
      }
      else
      {
        long long v35 = *this[11];
        long long v36 = *(_OWORD *)(a1 + 992);
        v126[0] = *(_OWORD *)(a1 + 976);
        v126[1] = v36;
        uint64_t v127 = *(void *)(a1 + 1008);
        BOOL HasDMAReadStall = ZinEnginePerf::HasDMAReadStall(v35, (const ZinANELayer *)this, (uint64_t)__p, (uint64_t)v126, 0);
        double v38 = (double)(unint64_t)((unint64_t)__p[13] / *(void *)(*(void *)(a1 + 336) + 520))
            / *(double *)(a1 + 992)
            * 1000.0
            * 1000.0
            * 1000.0;
        if ((unint64_t)((double)(unint64_t)__p[17] / *(double *)(a1 + 984) * 1000.0 * 1000.0 * 1000.0) <= (unint64_t)v38) {
          unint64_t v39 = (unint64_t)v38;
        }
        else {
          unint64_t v39 = (unint64_t)((double)(unint64_t)__p[17] / *(double *)(a1 + 984) * 1000.0 * 1000.0 * 1000.0);
        }
        unint64_t v40 = *(void *)(a4 + 16);
        char v41 = *(unint64_t **)(a4 + 8);
        if ((unint64_t)v41 >= v40)
        {
          __int16 v49 = *(unint64_t **)a4;
          uint64_t v50 = ((uint64_t)v41 - *(void *)a4) >> 3;
          unint64_t v51 = v50 + 1;
          if ((unint64_t)(v50 + 1) >> 61) {
            std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
          }
          uint64_t v52 = v40 - (void)v49;
          if (v52 >> 2 > v51) {
            unint64_t v51 = v52 >> 2;
          }
          if ((unint64_t)v52 >= 0x7FFFFFFFFFFFFFF8) {
            unint64_t v53 = 0x1FFFFFFFFFFFFFFFLL;
          }
          else {
            unint64_t v53 = v51;
          }
          if (v53)
          {
            char v54 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>(a4 + 16, v53);
            __int16 v49 = *(unint64_t **)a4;
            char v41 = *(unint64_t **)(a4 + 8);
          }
          else
          {
            char v54 = 0;
          }
          __int16 v67 = (unint64_t *)&v54[8 * v50];
          char v68 = &v54[8 * v53];
          *__int16 v67 = v39;
          char v42 = v67 + 1;
          while (v41 != v49)
          {
            unint64_t v69 = *--v41;
            *--__int16 v67 = v69;
          }
          *(void *)a4 = v67;
          *(void *)(a4 + 8) = v42;
          *(void *)(a4 + 16) = v68;
          if (v49) {
            operator delete(v49);
          }
        }
        else
        {
          unint64_t *v41 = v39;
          char v42 = v41 + 1;
        }
        *(void *)(a4 + 8) = v42;
        if (HasDMAReadStall)
        {
          double v70 = (double)(unint64_t)((unint64_t)__p[13] / *(void *)(*(void *)(a1 + 336) + 520))
              / *(double *)(a1 + 992)
              * 1000.0
              * 1000.0
              * 1000.0;
          if ((unint64_t)v70 >= (unint64_t)((double)(unint64_t)__p[17]
                                                         / *(double *)(a1 + 984)
                                                         * 1000.0
                                                         * 1000.0
                                                         * 1000.0))
            unint64_t v71 = (unint64_t)((double)(unint64_t)__p[17] / *(double *)(a1 + 984) * 1000.0 * 1000.0 * 1000.0);
          else {
            unint64_t v71 = (unint64_t)v70;
          }
        }
        else
        {
          unint64_t v71 = 0;
        }
        uint64_t v72 = a1;
        unint64_t v73 = *(void *)(a7 + 16);
        uint64_t v74 = *(unint64_t **)(a7 + 8);
        BOOL v125 = HasDMAReadStall;
        if ((unint64_t)v74 >= v73)
        {
          unint64_t v76 = *(unint64_t **)a7;
          uint64_t v77 = ((uint64_t)v74 - *(void *)a7) >> 3;
          unint64_t v78 = v77 + 1;
          if ((unint64_t)(v77 + 1) >> 61) {
            std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
          }
          uint64_t v79 = v73 - (void)v76;
          if (v79 >> 2 > v78) {
            unint64_t v78 = v79 >> 2;
          }
          if ((unint64_t)v79 >= 0x7FFFFFFFFFFFFFF8) {
            unint64_t v80 = 0x1FFFFFFFFFFFFFFFLL;
          }
          else {
            unint64_t v80 = v78;
          }
          if (v80)
          {
            uint64_t v81 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>(a7 + 16, v80);
            unint64_t v76 = *(unint64_t **)a7;
            uint64_t v74 = *(unint64_t **)(a7 + 8);
          }
          else
          {
            uint64_t v81 = 0;
          }
          long long v82 = (unint64_t *)&v81[8 * v77];
          uint64_t v83 = &v81[8 * v80];
          *long long v82 = v71;
          uint64_t v75 = v82 + 1;
          while (v74 != v76)
          {
            unint64_t v84 = *--v74;
            *--long long v82 = v84;
          }
          *(void *)a7 = v82;
          *(void *)(a7 + 8) = v75;
          *(void *)(a7 + 16) = v83;
          if (v76) {
            operator delete(v76);
          }
        }
        else
        {
          *uint64_t v74 = v71;
          uint64_t v75 = v74 + 1;
        }
        *(void *)(a7 + 8) = v75;
        uint64_t v85 = v72;
        double v86 = *(double *)(v72 + 984);
        uint64_t v87 = *(void *)(v72 + 336);
        double v88 = *(double *)(v72 + 992);
        if ((unint64_t)(v130 - (unsigned char *)v129) >= 9)
        {
          double v89 = (double)(unint64_t)((unint64_t)__p[14] / *(void *)(v87 + 520))
              / v88
              * 1000.0
              * 1000.0
              * 1000.0;
          if ((unint64_t)((double)(unint64_t)__p[17] / v86 * 1000.0 * 1000.0 * 1000.0) <= (unint64_t)v89) {
            unint64_t v90 = (unint64_t)v89;
          }
          else {
            unint64_t v90 = (unint64_t)((double)(unint64_t)__p[17] / v86 * 1000.0 * 1000.0 * 1000.0);
          }
          long long v92 = *(unint64_t **)(a4 + 8);
          unint64_t v91 = *(void *)(a4 + 16);
          if ((unint64_t)v92 >= v91)
          {
            int v94 = *(unint64_t **)a4;
            uint64_t v95 = ((uint64_t)v92 - *(void *)a4) >> 3;
            unint64_t v96 = v95 + 1;
            if ((unint64_t)(v95 + 1) >> 61) {
              std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
            }
            uint64_t v97 = v91 - (void)v94;
            if (v97 >> 2 > v96) {
              unint64_t v96 = v97 >> 2;
            }
            if ((unint64_t)v97 >= 0x7FFFFFFFFFFFFFF8) {
              unint64_t v98 = 0x1FFFFFFFFFFFFFFFLL;
            }
            else {
              unint64_t v98 = v96;
            }
            if (v98)
            {
              int v99 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>(a4 + 16, v98);
              int v94 = *(unint64_t **)a4;
              long long v92 = *(unint64_t **)(a4 + 8);
            }
            else
            {
              int v99 = 0;
            }
            int v105 = (unint64_t *)&v99[8 * v95];
            long long v106 = &v99[8 * v98];
            *int v105 = v90;
            uint64_t v93 = v105 + 1;
            uint64_t v85 = v72;
            while (v92 != v94)
            {
              unint64_t v107 = *--v92;
              *--int v105 = v107;
            }
            *(void *)a4 = v105;
            *(void *)(a4 + 8) = v93;
            *(void *)(a4 + 16) = v106;
            if (v94) {
              operator delete(v94);
            }
          }
          else
          {
            *long long v92 = v90;
            uint64_t v93 = v92 + 1;
          }
          *(void *)(a4 + 8) = v93;
          if (v125)
          {
            double v108 = (double)(unint64_t)((unint64_t)__p[14] / *(void *)(*(void *)(v85 + 336) + 520))
                 / *(double *)(v85 + 992)
                 * 1000.0
                 * 1000.0
                 * 1000.0;
            if ((unint64_t)v108 >= (unint64_t)((double)(unint64_t)__p[17]
                                                            / *(double *)(v85 + 984)
                                                            * 1000.0
                                                            * 1000.0
                                                            * 1000.0))
              unint64_t v109 = (unint64_t)((double)(unint64_t)__p[17]
                                      / *(double *)(v85 + 984)
                                      * 1000.0
                                      * 1000.0
                                      * 1000.0);
            else {
              unint64_t v109 = (unint64_t)v108;
            }
          }
          else
          {
            unint64_t v109 = 0;
          }
          uint64_t v111 = *(unint64_t **)(a7 + 8);
          unint64_t v110 = *(void *)(a7 + 16);
          if ((unint64_t)v111 >= v110)
          {
            int v113 = *(unint64_t **)a7;
            uint64_t v114 = ((uint64_t)v111 - *(void *)a7) >> 3;
            unint64_t v115 = v114 + 1;
            if ((unint64_t)(v114 + 1) >> 61) {
              std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
            }
            uint64_t v116 = v110 - (void)v113;
            if (v116 >> 2 > v115) {
              unint64_t v115 = v116 >> 2;
            }
            if ((unint64_t)v116 >= 0x7FFFFFFFFFFFFFF8) {
              unint64_t v117 = 0x1FFFFFFFFFFFFFFFLL;
            }
            else {
              unint64_t v117 = v115;
            }
            if (v117)
            {
              uint64_t v118 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>(a7 + 16, v117);
              int v113 = *(unint64_t **)a7;
              uint64_t v111 = *(unint64_t **)(a7 + 8);
            }
            else
            {
              uint64_t v118 = 0;
            }
            long long v119 = (unint64_t *)&v118[8 * v114];
            v120 = &v118[8 * v117];
            *long long v119 = v109;
            v112 = v119 + 1;
            while (v111 != v113)
            {
              unint64_t v121 = *--v111;
              *--long long v119 = v121;
            }
            *(void *)a7 = v119;
            *(void *)(a7 + 8) = v112;
            *(void *)(a7 + 16) = v120;
            if (v113) {
              operator delete(v113);
            }
          }
          else
          {
            *uint64_t v111 = v109;
            v112 = v111 + 1;
          }
          *(void *)(a7 + 8) = v112;
          double v86 = *(double *)(v85 + 984);
          uint64_t v87 = *(void *)(v85 + 336);
          double v88 = *(double *)(v85 + 992);
        }
        *a5 = (unint64_t)((double)(unint64_t)__p[10] / *(double *)(v85 + 976) * 1000.0 * 1000.0 * 1000.0);
        unint64_t v104 = (unint64_t)((double)(unint64_t)((unint64_t)__p[15] / *(void *)(v87 + 520))
                                / v88
                                * 1000.0
                                * 1000.0
                                * 1000.0);
        if ((unint64_t)((double)(unint64_t)__p[19] / v86 * 1000.0 * 1000.0 * 1000.0) > v104) {
          unint64_t v104 = (unint64_t)((double)(unint64_t)__p[19] / v86 * 1000.0 * 1000.0 * 1000.0);
        }
      }
      *a6 = v104;
      if (v129)
      {
        unint64_t v130 = v129;
        operator delete(v129);
      }
      uint64_t v29 = 0;
    }
    if (__p[25])
    {
      __p[26] = __p[25];
      operator delete(__p[25]);
    }
    goto LABEL_139;
  }
  if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
    ZinCpBasedAllocator::CollectNEPerfNumbers();
  }
  uint64_t v29 = 3;
LABEL_139:
  v122 = (ZinEngineLayerMirInfo *)v138;
  v138 = 0;
  if (v122)
  {
    ZinEngineLayerMirInfo::~ZinEngineLayerMirInfo(v122);
    MEMORY[0x21667D3C0]();
  }
  return v29;
}

void sub_211379B48(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, void *__p, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33,uint64_t a34,uint64_t a35,uint64_t a36,uint64_t a37,uint64_t a38,uint64_t a39,uint64_t a40,uint64_t a41,uint64_t a42,uint64_t a43,uint64_t a44,uint64_t a45,void *a46,uint64_t a47)
{
  if (__p) {
    operator delete(__p);
  }
  if (a46) {
    operator delete(a46);
  }
  std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)(v47 - 112), 0);
  _Unwind_Resume(a1);
}

uint64_t ZinCpBasedAllocator::CollectPEPerfNumbers(uint64_t a1, ZinANELayer *this, int a3, uint64_t a4, void *a5, unint64_t *a6, uint64_t a7)
{
  ZinANELayer::CopyMirInfo((uint64_t)this, &v93);
  if (a3)
  {
    ZinMirL2Config::ZinMirSetTileHeight((ZinMirL2Config *)(v93 + 30), this, 1);
    ZinMirL2Config::SetPatchShape((uint64_t)(v93 + 30), this, 1, 1, *(const ZinIrHalParameters **)(a1 + 336));
  }
  else
  {
    uint64_t v81 = a5;
    ZinL2FootprintCalculator::ComputeNonResidentWU(*(ZinL2FootprintCalculator **)(a1 + 272), this, (uint64_t)__src);
    int v14 = v93;
    memcpy(v93 + 30, __src, 0x1C0uLL);
    v14[142] = v87;
    std::__hash_table<std::__hash_value_type<ZinDependencyOffsetDim,long>,std::__unordered_map_hasher<ZinDependencyOffsetDim,std::__hash_value_type<ZinDependencyOffsetDim,long>,std::hash<ZinDependencyOffsetDim>,std::equal_to<ZinDependencyOffsetDim>,true>,std::__unordered_map_equal<ZinDependencyOffsetDim,std::__hash_value_type<ZinDependencyOffsetDim,long>,std::equal_to<ZinDependencyOffsetDim>,std::hash<ZinDependencyOffsetDim>,true>,std::allocator<std::__hash_value_type<ZinDependencyOffsetDim,long>>>::__move_assign((uint64_t)(v14 + 144), v88);
    v14[154] = v89;
    std::__hash_table<std::__hash_value_type<ZinDependencyOffsetDim,long>,std::__unordered_map_hasher<ZinDependencyOffsetDim,std::__hash_value_type<ZinDependencyOffsetDim,long>,std::hash<ZinDependencyOffsetDim>,std::equal_to<ZinDependencyOffsetDim>,true>,std::__unordered_map_equal<ZinDependencyOffsetDim,std::__hash_value_type<ZinDependencyOffsetDim,long>,std::equal_to<ZinDependencyOffsetDim>,std::hash<ZinDependencyOffsetDim>,true>,std::allocator<std::__hash_value_type<ZinDependencyOffsetDim,long>>>::__move_assign((uint64_t)(v14 + 156), v90);
    v14[166] = v91;
    std::__hash_table<std::__hash_value_type<ZinDependencyOffsetDim,long>,std::__unordered_map_hasher<ZinDependencyOffsetDim,std::__hash_value_type<ZinDependencyOffsetDim,long>,std::hash<ZinDependencyOffsetDim>,std::equal_to<ZinDependencyOffsetDim>,true>,std::__unordered_map_equal<ZinDependencyOffsetDim,std::__hash_value_type<ZinDependencyOffsetDim,long>,std::equal_to<ZinDependencyOffsetDim>,std::hash<ZinDependencyOffsetDim>,true>,std::allocator<std::__hash_value_type<ZinDependencyOffsetDim,long>>>::__move_assign((uint64_t)(v14 + 168), v92);
    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v92);
    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v90);
    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v88);
    a5 = v81;
  }
  memset(__src, 0, 200);
  unsigned int v15 = operator new(8uLL);
  *((void *)&__src[12] + 1) = v15;
  void *v15 = 0;
  *(void *)&__src[13] = v15 + 1;
  *((void *)&__src[13] + 1) = v15 + 1;
  __src[14] = 0uLL;
  __asm { FMOV            V0.2D, #-1.0 }
  __src[15] = _Q0;
  __src[16] = _Q0;
  __src[17] = _Q0;
  __src[18] = _Q0;
  *(void *)&__src[19] = 0;
  BYTE8(__src[19]) = 0;
  *(void *)&__src[20] = 0;
  uint64_t v21 = (uint64_t)v93;
  v83[0] = a3;
  v83[1] = a3;
  std::vector<BOOL>::vector(&__p, v83, 2);
  int v22 = ZinCpBasedAllocator::CalculatePerf(a1, this, v21, &__p, a3, (ZinPerfDescriptor *)__src);
  if (__p) {
    operator delete(__p);
  }
  if (v22)
  {
    uint64_t v23 = 3;
    goto LABEL_94;
  }
  (*(void (**)(void **__return_ptr, ZinANELayer *))(*(void *)this + 512))(&__p, this);
  if ((a3 & 1) == 0)
  {
    uint64_t v29 = v85;
    if (v85 == __p)
    {
LABEL_55:
      double v55 = *(double *)(a1 + 984);
      *a5 = (unint64_t)((double)*(unint64_t *)&__src[6] / v55 * 1000.0 * 1000.0 * 1000.0);
      unint64_t v56 = (unint64_t)((double)*((unint64_t *)&__src[9] + 1) / v55 * 1000.0 * 1000.0 * 1000.0);
      double v57 = (double)(unint64_t)(*((void *)&__src[7] + 1) / *(void *)(*(void *)(a1 + 336) + 520))
          / *(double *)(a1 + 992)
          * 1000.0
          * 1000.0
          * 1000.0;
      if (v56 <= (unint64_t)v57) {
        unint64_t v56 = (unint64_t)v57;
      }
      goto LABEL_91;
    }
    long long v82 = a5;
    unint64_t v30 = 0;
    while (1)
    {
      if (v30 == 1)
      {
        if (((*(uint64_t (**)(ZinANELayer *))(*(void *)this + 664))(this) & 1) == 0) {
          goto LABEL_18;
        }
      }
      else if (v30 || ((*(uint64_t (**)(ZinANELayer *))(*(void *)this + 656))(this) & 1) == 0)
      {
LABEL_18:
        double v32 = (double)(unint64_t)(*((void *)&__src[6] + v30 + 1) / *(void *)(*(void *)(a1 + 336) + 520))
            / *(double *)(a1 + 992)
            * 1000.0
            * 1000.0
            * 1000.0;
        if ((unint64_t)((double)*((unint64_t *)&__src[8] + 1)
                              / *(double *)(a1 + 984)
                              * 1000.0
                              * 1000.0
                              * 1000.0) <= (unint64_t)v32)
          unint64_t v31 = (unint64_t)v32;
        else {
          unint64_t v31 = (unint64_t)((double)*((unint64_t *)&__src[8] + 1)
        }
                                 / *(double *)(a1 + 984)
                                 * 1000.0
                                 * 1000.0
                                 * 1000.0);
        goto LABEL_21;
      }
      unint64_t v31 = 1;
LABEL_21:
      char v34 = *(unint64_t **)(a4 + 8);
      unint64_t v33 = *(void *)(a4 + 16);
      if ((unint64_t)v34 >= v33)
      {
        long long v36 = *(unint64_t **)a4;
        uint64_t v37 = ((uint64_t)v34 - *(void *)a4) >> 3;
        unint64_t v38 = v37 + 1;
        if ((unint64_t)(v37 + 1) >> 61) {
          std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
        }
        uint64_t v39 = v33 - (void)v36;
        if (v39 >> 2 > v38) {
          unint64_t v38 = v39 >> 2;
        }
        if ((unint64_t)v39 >= 0x7FFFFFFFFFFFFFF8) {
          unint64_t v40 = 0x1FFFFFFFFFFFFFFFLL;
        }
        else {
          unint64_t v40 = v38;
        }
        if (v40)
        {
          char v41 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>(a4 + 16, v40);
          long long v36 = *(unint64_t **)a4;
          char v34 = *(unint64_t **)(a4 + 8);
        }
        else
        {
          char v41 = 0;
        }
        char v42 = (unint64_t *)&v41[8 * v37];
        *char v42 = v31;
        long long v35 = v42 + 1;
        while (v34 != v36)
        {
          unint64_t v43 = *--v34;
          *--char v42 = v43;
        }
        *(void *)a4 = v42;
        *(void *)(a4 + 8) = v35;
        *(void *)(a4 + 16) = &v41[8 * v40];
        if (v36) {
          operator delete(v36);
        }
      }
      else
      {
        unint64_t *v34 = v31;
        long long v35 = v34 + 1;
      }
      *(void *)(a4 + 8) = v35;
      unint64_t v45 = *(void **)(a7 + 8);
      unint64_t v44 = *(void *)(a7 + 16);
      if ((unint64_t)v45 >= v44)
      {
        uint64_t v47 = *(void **)a7;
        uint64_t v48 = ((uint64_t)v45 - *(void *)a7) >> 3;
        unint64_t v49 = v48 + 1;
        if ((unint64_t)(v48 + 1) >> 61) {
          std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
        }
        uint64_t v50 = v44 - (void)v47;
        if (v50 >> 2 > v49) {
          unint64_t v49 = v50 >> 2;
        }
        if ((unint64_t)v50 >= 0x7FFFFFFFFFFFFFF8) {
          unint64_t v51 = 0x1FFFFFFFFFFFFFFFLL;
        }
        else {
          unint64_t v51 = v49;
        }
        if (v51)
        {
          uint64_t v52 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>(a7 + 16, v51);
          uint64_t v47 = *(void **)a7;
          unint64_t v45 = *(void **)(a7 + 8);
        }
        else
        {
          uint64_t v52 = 0;
        }
        unint64_t v53 = &v52[8 * v48];
        *(void *)unint64_t v53 = 0;
        uint64_t v46 = v53 + 8;
        while (v45 != v47)
        {
          uint64_t v54 = *--v45;
          *((void *)v53 - 1) = v54;
          v53 -= 8;
        }
        *(void *)a7 = v53;
        *(void *)(a7 + 8) = v46;
        *(void *)(a7 + 16) = &v52[8 * v51];
        if (v47) {
          operator delete(v47);
        }
      }
      else
      {
        *unint64_t v45 = 0;
        uint64_t v46 = v45 + 1;
      }
      *(void *)(a7 + 8) = v46;
      ++v30;
      uint64_t v29 = __p;
      if (v30 >= ((unsigned char *)v85 - (unsigned char *)__p) >> 3)
      {
        a5 = v82;
        goto LABEL_55;
      }
    }
  }
  unint64_t v24 = (unint64_t)((double)*((unint64_t *)&__src[8] + 1)
                         / *(double *)(a1 + 984)
                         * 1000.0
                         * 1000.0
                         * 1000.0);
  char v26 = (void *)(a4 + 16);
  unint64_t v25 = *(void *)(a4 + 16);
  uint64_t v27 = *(unint64_t **)(a4 + 8);
  if ((unint64_t)v27 >= v25)
  {
    double v58 = *(unint64_t **)a4;
    uint64_t v59 = ((uint64_t)v27 - *(void *)a4) >> 3;
    unint64_t v60 = v59 + 1;
    if ((unint64_t)(v59 + 1) >> 61) {
      std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
    }
    uint64_t v61 = v25 - (void)v58;
    if (v61 >> 2 > v60) {
      unint64_t v60 = v61 >> 2;
    }
    if ((unint64_t)v61 >= 0x7FFFFFFFFFFFFFF8) {
      unint64_t v62 = 0x1FFFFFFFFFFFFFFFLL;
    }
    else {
      unint64_t v62 = v60;
    }
    if (v62)
    {
      unint64_t v63 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>(a4 + 16, v62);
      double v58 = *(unint64_t **)a4;
      uint64_t v27 = *(unint64_t **)(a4 + 8);
    }
    else
    {
      unint64_t v63 = 0;
    }
    uint64_t v64 = (unint64_t *)&v63[8 * v59];
    unint64_t v65 = &v63[8 * v62];
    *uint64_t v64 = v24;
    int v28 = v64 + 1;
    while (v27 != v58)
    {
      unint64_t v66 = *--v27;
      *--uint64_t v64 = v66;
    }
    *(void *)a4 = v64;
    *(void *)(a4 + 8) = v28;
    *(void *)(a4 + 16) = v65;
    if (v58) {
      operator delete(v58);
    }
  }
  else
  {
    *uint64_t v27 = v24;
    int v28 = v27 + 1;
  }
  *(void *)(a4 + 8) = v28;
  uint64_t v29 = __p;
  double v67 = *(double *)(a1 + 984);
  if ((unint64_t)((unsigned char *)v85 - (unsigned char *)__p) >= 9)
  {
    unint64_t v68 = (unint64_t)((double)*((unint64_t *)&__src[8] + 1) / v67 * 1000.0 * 1000.0 * 1000.0);
    if ((unint64_t)v28 >= *v26)
    {
      double v70 = *(unint64_t **)a4;
      uint64_t v71 = ((uint64_t)v28 - *(void *)a4) >> 3;
      unint64_t v72 = v71 + 1;
      if ((unint64_t)(v71 + 1) >> 61) {
        std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
      }
      uint64_t v73 = *v26 - (void)v70;
      if (v73 >> 2 > v72) {
        unint64_t v72 = v73 >> 2;
      }
      if ((unint64_t)v73 >= 0x7FFFFFFFFFFFFFF8) {
        unint64_t v74 = 0x1FFFFFFFFFFFFFFFLL;
      }
      else {
        unint64_t v74 = v72;
      }
      if (v74)
      {
        uint64_t v75 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>(a4 + 16, v74);
        double v70 = *(unint64_t **)a4;
        int v28 = *(unint64_t **)(a4 + 8);
      }
      else
      {
        uint64_t v75 = 0;
      }
      unint64_t v76 = (unint64_t *)&v75[8 * v71];
      uint64_t v77 = &v75[8 * v74];
      *unint64_t v76 = v68;
      unint64_t v69 = v76 + 1;
      while (v28 != v70)
      {
        unint64_t v78 = *--v28;
        *--unint64_t v76 = v78;
      }
      *(void *)a4 = v76;
      *(void *)(a4 + 8) = v69;
      *(void *)(a4 + 16) = v77;
      if (v70) {
        operator delete(v70);
      }
    }
    else
    {
      *int v28 = v68;
      unint64_t v69 = v28 + 1;
    }
    *(void *)(a4 + 8) = v69;
    double v67 = *(double *)(a1 + 984);
    uint64_t v29 = __p;
  }
  *a5 = (unint64_t)((double)*(unint64_t *)&__src[6] / v67 * 1000.0 * 1000.0 * 1000.0);
  unint64_t v56 = (unint64_t)((double)*((unint64_t *)&__src[9] + 1) / v67 * 1000.0 * 1000.0 * 1000.0);
LABEL_91:
  *a6 = v56;
  if (v29)
  {
    uint64_t v85 = v29;
    operator delete(v29);
  }
  uint64_t v23 = 0;
LABEL_94:
  if (*((void *)&__src[12] + 1))
  {
    *(void *)&__src[13] = *((void *)&__src[12] + 1);
    operator delete(*((void **)&__src[12] + 1));
  }
  uint64_t v79 = (ZinEngineLayerMirInfo *)v93;
  uint64_t v93 = 0;
  if (v79)
  {
    ZinEngineLayerMirInfo::~ZinEngineLayerMirInfo(v79);
    MEMORY[0x21667D3C0]();
  }
  return v23;
}

void sub_21137A344(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, void *__p, uint64_t a15)
{
  if (__p) {
    operator delete(__p);
  }
  char v18 = *(void **)(v15 + 200);
  if (v18)
  {
    *(void *)(v15 + 208) = v18;
    operator delete(v18);
  }
  std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)(v16 - 120), 0);
  _Unwind_Resume(a1);
}

uint64_t ZinCpBasedAllocator::CollectEngineCycleBehavior(uint64_t a1, ZinEnginePerf ***this, uint64_t a3, uint64_t a4, void *a5, void *a6, unint64_t *a7, unint64_t *a8, uint64_t a9)
{
  if (ZinIrOpLayer::IsNELayer((ZinIrOpLayer *)this))
  {
    if (!ZinCpBasedAllocator::CollectNEPerfNumbers(a1, this, 1, a3, a5, a7, a9))
    {
      uint64_t result = ZinCpBasedAllocator::CollectNEPerfNumbers(a1, this, 0, a4, a6, a8, a9);
      if (!result) {
        return result;
      }
    }
    return 3;
  }
  if (ZinCpBasedAllocator::CollectPEPerfNumbers(a1, (ZinANELayer *)this, 1, a3, a5, a7, a9)) {
    return 3;
  }
  uint64_t result = ZinCpBasedAllocator::CollectPEPerfNumbers(a1, (ZinANELayer *)this, 0, a4, a6, a8, a9);
  if (result) {
    return 3;
  }
  return result;
}

uint64_t ZinCpBasedAllocator::SetNPChainExecutionBehavior(ZinCpBasedAllocator *this, const ZinNELayer *a2, const ZinPELayer *a3, uint64_t a4, uint64_t a5)
{
  uint64_t v5 = MEMORY[0x270FA5388](this, a2, a3, a4, a5);
  char v82 = v6;
  char v8 = v7;
  uint64_t v10 = v9;
  char v12 = (const ZinIrOpLayer *)v11;
  uint64_t v13 = v5;
  ZinANELayer::CopyMirInfo(v11, &v263);
  uint64_t v83 = (ZinIrOpLayer *)v10;
  ZinANELayer::CopyMirInfo(v10, &v262);
  int v14 = (ZinIrOpLayerGraph *)*((void *)v12 + 19);
  v249[0] = vdupq_n_s64(1uLL);
  BYTE8(v249[4]) = 0;
  *(void *)&v249[3] = 0;
  *((void *)&v249[2] + 1) = 0;
  BYTE8(v249[3]) = 0;
  v249[1] = 1uLL;
  LOBYTE(v249[2]) = 0;
  *(void *)&v249[4] = 0;
  v249[5] = 1uLL;
  memset(&v249[6], 0, 18);
  *(_OWORD *)((char *)&v249[7] + 8) = xmmword_211ED33C0;
  BYTE8(v249[8]) = 0;
  DWORD2(v249[14]) = 0;
  *((void *)&v249[18] + 1) = 0;
  memset(&v249[15], 0, 49);
  LODWORD(v249[19]) = 0;
  *(void *)&v249[23] = 0;
  *(_OWORD *)((char *)&v249[19] + 8) = 0u;
  *(_OWORD *)((char *)&v249[20] + 8) = 0u;
  *(_OWORD *)((char *)&v249[21] + 8) = 0u;
  BYTE8(v249[22]) = 0;
  DWORD2(v249[23]) = 0;
  *((void *)&v249[27] + 1) = 0;
  memset(&v249[24], 0, 49);
  int v250 = 0;
  long long v251 = 0u;
  long long v252 = 0u;
  *(_OWORD *)((char *)&v249[9] + 8) = 0u;
  *(_OWORD *)((char *)&v249[10] + 8) = 0u;
  *(_OWORD *)((char *)&v249[11] + 1) = 0u;
  memset(&v249[13], 0, 17);
  *((void *)&v249[12] + 1) = 0;
  int v253 = 1065353216;
  int v254 = 0;
  long long v255 = 0u;
  long long v256 = 0u;
  int v257 = 1065353216;
  int v258 = 0;
  long long v259 = 0u;
  long long v260 = 0u;
  int v261 = 1065353216;
  v236[0] = v249[0];
  BYTE8(v236[4]) = 0;
  *(void *)&v236[3] = 0;
  *((void *)&v236[2] + 1) = 0;
  BYTE8(v236[3]) = 0;
  v236[1] = 1uLL;
  LOBYTE(v236[2]) = 0;
  *(void *)&v236[4] = 0;
  v236[5] = 1uLL;
  memset(&v236[6], 0, 18);
  *(_OWORD *)((char *)&v236[7] + 8) = xmmword_211ED33C0;
  BYTE8(v236[8]) = 0;
  DWORD2(v236[14]) = 0;
  *((void *)&v236[18] + 1) = 0;
  memset(&v236[15], 0, 49);
  LODWORD(v236[19]) = 0;
  *(void *)&v236[23] = 0;
  *(_OWORD *)((char *)&v236[19] + 8) = 0u;
  *(_OWORD *)((char *)&v236[20] + 8) = 0u;
  *(_OWORD *)((char *)&v236[21] + 8) = 0u;
  BYTE8(v236[22]) = 0;
  DWORD2(v236[23]) = 0;
  *((void *)&v236[27] + 1) = 0;
  memset(&v236[24], 0, 49);
  int v237 = 0;
  long long v238 = 0u;
  long long v239 = 0u;
  *(_OWORD *)((char *)&v236[9] + 8) = 0u;
  *(_OWORD *)((char *)&v236[10] + 8) = 0u;
  *(_OWORD *)((char *)&v236[11] + 1) = 0u;
  memset(&v236[13], 0, 17);
  *((void *)&v236[12] + 1) = 0;
  int v240 = 1065353216;
  int v241 = 0;
  long long v242 = 0u;
  long long v243 = 0u;
  int v244 = 1065353216;
  int v245 = 0;
  long long v246 = 0u;
  long long v247 = 0u;
  int v248 = 1065353216;
  uint64_t v15 = *(const ZinIrTensor ***)(v13 + 272);
  uint64_t v16 = (ZinIrRegAllocUtil **)(*(uint64_t (**)(const ZinIrOpLayer *, void, void))(*(void *)v12 + 32))(v12, 0, 0);
  uint64_t ChainBufferSize = ZinL2FootprintCalculator::GetChainBufferSize(v15, v16, (ZinMirL2Config *)v249, (ZinMirL2Config *)v236);
  uint64_t v17 = v263;
  char v18 = (_OWORD *)(v263 + 120);
  memcpy((void *)(v263 + 120), v249, 0x1C0uLL);
  *(_DWORD *)(v17 + 568) = v250;
  if (v18 == v249)
  {
    *(_DWORD *)(v17 + 616) = v254;
    *(_DWORD *)(v17 + 664) = v258;
  }
  else
  {
    *(_DWORD *)(v17 + 608) = v253;
    std::__hash_table<std::__hash_value_type<ZinIrDimension,unsigned long>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,unsigned long>>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<std::__hash_value_type<ZinIrDimension,unsigned long>,void *> *>>((void *)(v17 + 576), (uint64_t *)v252, 0);
    *(_DWORD *)(v17 + 616) = v254;
    *(_DWORD *)(v17 + 656) = v257;
    std::__hash_table<std::__hash_value_type<ZinIrDimension,unsigned long>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,unsigned long>>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<std::__hash_value_type<ZinIrDimension,unsigned long>,void *> *>>((void *)(v17 + 624), (uint64_t *)v256, 0);
    *(_DWORD *)(v17 + 664) = v258;
    *(_DWORD *)(v17 + 704) = v261;
    std::__hash_table<std::__hash_value_type<ZinIrDimension,unsigned long>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,unsigned long>>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<std::__hash_value_type<ZinIrDimension,unsigned long>,void *> *>>((void *)(v17 + 672), (uint64_t *)v260, 0);
  }
  uint64_t v19 = v262;
  int v20 = (_OWORD *)(v262 + 120);
  memcpy((void *)(v262 + 120), v236, 0x1C0uLL);
  *(_DWORD *)(v19 + 568) = v237;
  if (v20 == v236)
  {
    *(_DWORD *)(v19 + 616) = v241;
    *(_DWORD *)(v19 + 664) = v245;
  }
  else
  {
    *(_DWORD *)(v19 + 608) = v240;
    std::__hash_table<std::__hash_value_type<ZinIrDimension,unsigned long>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,unsigned long>>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<std::__hash_value_type<ZinIrDimension,unsigned long>,void *> *>>((void *)(v19 + 576), (uint64_t *)v239, 0);
    *(_DWORD *)(v19 + 616) = v241;
    *(_DWORD *)(v19 + 656) = v244;
    std::__hash_table<std::__hash_value_type<ZinIrDimension,unsigned long>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,unsigned long>>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<std::__hash_value_type<ZinIrDimension,unsigned long>,void *> *>>((void *)(v19 + 624), (uint64_t *)v243, 0);
    *(_DWORD *)(v19 + 664) = v245;
    *(_DWORD *)(v19 + 704) = v248;
    std::__hash_table<std::__hash_value_type<ZinIrDimension,unsigned long>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,unsigned long>>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<std::__hash_value_type<ZinIrDimension,unsigned long>,void *> *>>((void *)(v19 + 672), (uint64_t *)v247, 0);
  }
  char v180 = 0;
  char v181 = 0;
  char v182 = 0;
  char v183 = 0;
  char v184 = 0;
  char v185 = 0;
  char v186 = 0;
  char v187 = 0;
  char v188 = 0;
  char v189 = 0;
  LOBYTE(v19std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  char v193 = 0;
  char v194 = 0;
  char v195 = 0;
  char v196 = 0;
  char v197 = 0;
  char v198 = 0;
  char v199 = 0;
  char v200 = 0;
  char v201 = 0;
  char v202 = 0;
  char v203 = 0;
  char v204 = 0;
  char v205 = 0;
  char v206 = 0;
  char v207 = 0;
  v179 = &unk_26C34D080;
  __int16 v208 = 0;
  char v212 = 0;
  char v213 = 0;
  __int16 v214 = 256;
  long long v209 = 0u;
  uint64_t v210 = 0;
  __int16 v211 = 0;
  char v215 = 0;
  char v216 = 0;
  __int16 v217 = 0;
  char v218 = 0;
  char v219 = 0;
  char v220 = 0;
  char v221 = 0;
  char v222 = 0;
  char v223 = 0;
  char v224 = 0;
  char v225 = 0;
  char v226 = 0;
  char v227 = 0;
  char v228 = 0;
  char v229 = 0;
  char v230 = 0;
  char v231 = 0;
  __int16 v232 = 0;
  char v233 = 0;
  char v234 = 0;
  int v235 = 0;
  LOBYTE(v118) = v8;
  std::vector<BOOL>::vector(__p, &v118, 1);
  ZinCpBasedAllocator::GetCustomPerfInfo(v13, (uint64_t)v12, __p, v82, v263, (uint64_t)&v179);
  if (__p[0]) {
    operator delete(__p[0]);
  }
  LOBYTE(__p[0]) = v8;
  BYTE1(__p[0]) = v8;
  std::vector<BOOL>::vector(v178, __p, 2);
  unint64_t IndexOfMatchedIncomingLayer = ZinIrOpLayerGraph::GetIndexOfMatchedIncomingLayer(v14, v83, v12);
  *(void *)((char *)v178[0] + ((IndexOfMatchedIncomingLayer >> 3) & 0x1FFFFFFFFFFFFFF8)) |= 1 << IndexOfMatchedIncomingLayer;
  char v146 = 0;
  char v147 = 0;
  char v148 = 0;
  char v149 = 0;
  char v150 = 0;
  char v151 = 0;
  char v152 = 0;
  char v153 = 0;
  char v154 = 0;
  char v155 = 0;
  LOBYTE(v156) = 0;
  char v159 = 0;
  char v160 = 0;
  char v161 = 0;
  char v162 = 0;
  char v163 = 0;
  char v164 = 0;
  char v165 = 0;
  char v166 = 0;
  char v167 = 0;
  char v168 = 0;
  char v169 = 0;
  char v170 = 0;
  char v171 = 0;
  char v172 = 0;
  char v173 = 0;
  v145 = &unk_26C34D0D8;
  char v174 = 0;
  char v175 = 0;
  char v176 = 0;
  char v177 = 0;
  ZinCpBasedAllocator::GetCustomPerfInfo(v13, (uint64_t)v83, v178, v82, v262, (uint64_t)&v145);
  v156 = v12;
  int v157 = 1;
  v158 = &v179;
  if (!v159) {
    char v159 = 1;
  }
  v190 = v83;
  int v191 = 1;
  v192 = &v145;
  if (!v193) {
    char v193 = 1;
  }
  ZinIrHalParameters::GetOperationCondition(*(ZinIrHalParameters **)(v13 + 336), *(double *)(*(void *)(v13 + 344) + 104), *(_DWORD *)(*(void *)(v13 + 344) + 112), *(_DWORD *)(*(void *)(v13 + 344) + 116), (uint64_t)v144);
  uint64_t v22 = *(void *)(v13 + 336);
  uint64_t v118 = 0x1000000010101;
  __int16 v119 = 0;
  char v120 = 1;
  int v121 = 0;
  ZinIrPerf::ZinIrPerf((uint64_t)__p, v22, v144, &v118);
  uint64_t v130 = 0;
  long long v129 = 0u;
  long long v128 = 0u;
  long long v127 = 0u;
  long long v126 = 0u;
  long long v125 = 0u;
  long long v124 = 0u;
  long long v123 = 0u;
  memset(v122, 0, sizeof(v122));
  uint64_t v23 = operator new(8uLL);
  uint64_t v131 = v23;
  *uint64_t v23 = 0;
  v133 = v23 + 1;
  int v132 = v23 + 1;
  uint64_t v135 = 0;
  uint64_t v134 = 0;
  __asm { FMOV            V0.2D, #-1.0 }
  long long v136 = _Q0;
  long long v137 = _Q0;
  long long v138 = _Q0;
  long long v80 = _Q0;
  long long v139 = _Q0;
  uint64_t v140 = 0;
  char v141 = 0;
  uint64_t v142 = 0;
  if (ZinANELayer::CalculatePerf(v12, (ZinIrPerf *)__p, (const ZinCustomPerfInfo *)&v179, (ZinPerfDescriptor *)v122))
  {
    if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
      ZinCpBasedAllocator::SetNPChainExecutionBehavior();
    }
    uint64_t v29 = 3;
  }
  else
  {
    uint64_t v30 = *(void *)(v13 + 336);
    *(void *)&v98[0] = 0x1000000010101;
    WORD4(v98[0]) = 0;
    BYTE10(v98[0]) = 1;
    *(_DWORD *)((char *)v98 + 11) = 0;
    ZinIrPerf::ZinIrPerf((uint64_t)&v118, v30, v144, (uint64_t *)v98);
    uint64_t v105 = 0;
    long long v103 = 0u;
    long long v104 = 0u;
    long long v101 = 0u;
    long long v102 = 0u;
    long long v99 = 0u;
    long long v100 = 0u;
    memset(v98, 0, sizeof(v98));
    unint64_t v31 = operator new(8uLL);
    long long v106 = v31;
    *unint64_t v31 = 0;
    double v108 = v31 + 1;
    unint64_t v107 = v31 + 1;
    uint64_t v110 = 0;
    uint64_t v109 = 0;
    long long v111 = v80;
    long long v112 = v80;
    long long v113 = v80;
    long long v114 = v80;
    uint64_t v115 = 0;
    char v116 = 0;
    uint64_t v117 = 0;
    if (ZinANELayer::CalculatePerf(v83, (ZinIrPerf *)&v118, (const ZinCustomPerfInfo *)&v145, (ZinPerfDescriptor *)v98))
    {
      if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
        ZinCpBasedAllocator::SetNPChainExecutionBehavior();
      }
      uint64_t v29 = 3;
    }
    else
    {
      unint64_t v96 = v12;
      v264 = &v96;
      double v32 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>>>::__emplace_unique_key_args<ZinANELayer const*,std::piecewise_construct_t const&,std::tuple<ZinANELayer const*&&>,std::tuple<>>(v13 + 112, &v96, (uint64_t)&std::piecewise_construct, &v264);
      (*(void (**)(void **__return_ptr, const ZinIrOpLayer *))(*(void *)v12 + 512))(&v96, v12);
      unint64_t v33 = (uint64_t ***)(v32 + 3);
      char v34 = v96;
      long long v35 = v97;
      if (v97 != v96)
      {
        unint64_t v36 = 0;
        do
        {
          if ((v8 & 1) == 0)
          {
            uint64_t v86 = 0;
            uint64_t v86 = v34[v36];
            LayerCycleAndFootprintEstimator::GetReadBehaviors(*v33, (char **)&v264);
            uint64_t v37 = v264[v36];
            v265 = v264;
            operator delete(v264);
            unint64_t v38 = (unint64_t)((double)*((unint64_t *)&v126 + 1)
                                   / *(double *)(v13 + 984)
                                   * 1000.0
                                   * 1000.0
                                   * 1000.0);
            uint64_t v39 = (char *)v122 + 8 * v36;
            if (v38 <= (unint64_t)((double)(unint64_t)(*((void *)v39 + 13)
                                                                    / *(void *)(*(void *)(v13 + 336) + 520))
                                         / *(double *)(v13 + 992)
                                         * 1000.0
                                         * 1000.0
                                         * 1000.0))
              unint64_t v38 = (unint64_t)((double)(unint64_t)(*((void *)v39 + 13)
                                                                / *(void *)(*(void *)(v13 + 336) + 520))
                                     / *(double *)(v13 + 992)
                                     * 1000.0
                                     * 1000.0
                                     * 1000.0);
            v37[4] = v38;
            unint64_t v40 = *(ZinEnginePerf **)(v86 + 96);
            uint64_t v95 = *(void *)(v13 + 1008);
            long long v41 = *(_OWORD *)(v13 + 992);
            v94[0] = *(_OWORD *)(v13 + 976);
            v94[1] = v41;
            if (ZinEnginePerf::HasDMAReadStall(v40, v12, (uint64_t)v122, (uint64_t)v94, 0))
            {
              double v42 = (double)(unint64_t)(*((void *)v39 + 13) / *(void *)(*(void *)(v13 + 336) + 520))
                  / *(double *)(v13 + 992)
                  * 1000.0
                  * 1000.0
                  * 1000.0;
              if ((unint64_t)v42 >= (unint64_t)((double)*((unint64_t *)&v126 + 1)
                                                             / *(double *)(v13 + 984)
                                                             * 1000.0
                                                             * 1000.0
                                                             * 1000.0))
                unint64_t v43 = (unint64_t)((double)*((unint64_t *)&v126 + 1)
                                       / *(double *)(v13 + 984)
                                       * 1000.0
                                       * 1000.0
                                       * 1000.0);
              else {
                unint64_t v43 = (unint64_t)v42;
              }
            }
            else
            {
              unint64_t v43 = 0;
            }
            LayerCycleAndFootprintEstimator::GetReadBehaviors(*v33, (char **)&v264);
            unint64_t v44 = v264[v36];
            v265 = v264;
            operator delete(v264);
            v44[15] = v43;
            long long v92 = v12;
            unint64_t v93 = v36 != 0;
            LayerCycleAndFootprintEstimator::GetReadBehaviors(*v33, (char **)&v264);
            unint64_t v45 = v264[v36];
            v265 = v264;
            operator delete(v264);
            v264 = (void **)&v86;
            uint64_t v46 = (l2a *)std::__hash_table<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::__unordered_map_hasher<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,true>,std::__unordered_map_equal<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::equal_to<ZinIrOpLayer *>,std::hash<ZinIrOpLayer *>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer * const&>,std::tuple<>>(v13 + 152, &v86, (uint64_t)&std::piecewise_construct, &v264)[3];
            uint64_t v47 = std::__hash_table<std::__hash_value_type<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,unsigned long>,std::__unordered_map_hasher<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,std::__hash_value_type<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,unsigned long>,ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKeyHasher,std::equal_to<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey>,true>,std::__unordered_map_equal<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,std::__hash_value_type<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,unsigned long>,std::equal_to<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey>,ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKeyHasher,true>,std::allocator<std::__hash_value_type<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,unsigned long>>>::find<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey>((void *)(v13 + 192), (int *)&v92);
            if (!v47) {
              std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
            }
            v45[5] = DMABuffer::CalculateSrcSize((uint64_t)v12, v36 != 0, v46, v47[4], 0, *(unsigned __int8 **)(v13 + 336), (uint64_t)v249);
            char v34 = v96;
            long long v35 = v97;
          }
          ++v36;
        }
        while (v36 < (v35 - (unsigned char *)v34) >> 3);
      }
      uint64_t v48 = *v33;
      (*v33)[3][5] = (unint64_t)((double)(unint64_t)v123
                                      / *(double *)(v13 + 976)
                                      * 1000.0
                                      * 1000.0
                                      * 1000.0);
      unint64_t v49 = v48[4];
      v49[12] = (unint64_t)((double)*((unint64_t *)&v127 + 1)
                                 / *(double *)(v13 + 984)
                                 * 1000.0
                                 * 1000.0
                                 * 1000.0);
      v49[13] = ChainBufferSize;
      long long v92 = v83;
      v264 = &v92;
      uint64_t v50 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>>>::__emplace_unique_key_args<ZinANELayer const*,std::piecewise_construct_t const&,std::tuple<ZinANELayer const*&&>,std::tuple<>>(v13 + 112, &v92, (uint64_t)&std::piecewise_construct, &v264);
      (*(void (**)(void **__return_ptr, ZinIrOpLayer *))(*(void *)v83 + 512))(&v92, v83);
      unint64_t v51 = (_OWORD *)(v13 + 976);
      uint64_t v52 = (uint64_t ***)(v50 + 3);
      unint64_t v53 = v92;
      if ((void *)v93 == v92)
      {
        uint64_t v79 = 0;
      }
      else
      {
        unint64_t v54 = 0;
        uint64_t v79 = 0;
        do
        {
          uint64_t v91 = 0;
          uint64_t v91 = v53[v54];
          if (*(const ZinIrOpLayer **)(v91 + 96) == v12)
          {
            LayerCycleAndFootprintEstimator::GetReadBehaviors(*v52, (char **)&v264);
            unint64_t v60 = v264[v54];
            v265 = v264;
            operator delete(v264);
            v60[12] = (unint64_t)((double)*((unint64_t *)&v101 + 1)
                                       / *(double *)(v13 + 984)
                                       * 1000.0
                                       * 1000.0
                                       * 1000.0);
            LayerCycleAndFootprintEstimator::GetReadBehaviors(*v52, (char **)&v264);
            uint64_t v61 = v264[v54];
            v265 = v264;
            operator delete(v264);
            v61[13] = ChainBufferSize;
            uint64_t v79 = v54;
          }
          else if ((v8 & 1) == 0)
          {
            LayerCycleAndFootprintEstimator::GetReadBehaviors(*v52, (char **)&v264);
            double v55 = v264[v54];
            v265 = v264;
            operator delete(v264);
            unint64_t v56 = (unint64_t)((double)*((unint64_t *)&v101 + 1)
                                   / *(double *)(v13 + 984)
                                   * 1000.0
                                   * 1000.0
                                   * 1000.0);
            if (v56 <= (unint64_t)((double)(unint64_t)(*((void *)&v99 + v54 + 1)
                                                                    / *(void *)(*(void *)(v13 + 336) + 520))
                                         / *(double *)(v13 + 992)
                                         * 1000.0
                                         * 1000.0
                                         * 1000.0))
              unint64_t v56 = (unint64_t)((double)(unint64_t)(*((void *)&v99 + v54 + 1)
                                                                / *(void *)(*(void *)(v13 + 336) + 520))
                                     / *(double *)(v13 + 992)
                                     * 1000.0
                                     * 1000.0
                                     * 1000.0);
            v55[6] = v56;
            long long v57 = *(_OWORD *)(v13 + 992);
            v89[0] = *v51;
            v89[1] = v57;
            uint64_t v90 = *(void *)(v13 + 1008);
            if (ZinEnginePerf::HasDMAReadStall(v12, v83, (uint64_t)v98, (uint64_t)v89, 0))
            {
              double v58 = (double)(unint64_t)(*((void *)&v99 + v54 + 1) / *(void *)(*(void *)(v13 + 336) + 520))
                  / *(double *)(v13 + 992)
                  * 1000.0
                  * 1000.0
                  * 1000.0;
              if ((unint64_t)v58 >= (unint64_t)((double)*((unint64_t *)&v101 + 1)
                                                             / *(double *)(v13 + 984)
                                                             * 1000.0
                                                             * 1000.0
                                                             * 1000.0))
                unint64_t v59 = (unint64_t)((double)*((unint64_t *)&v101 + 1)
                                       / *(double *)(v13 + 984)
                                       * 1000.0
                                       * 1000.0
                                       * 1000.0);
              else {
                unint64_t v59 = (unint64_t)v58;
              }
            }
            else
            {
              unint64_t v59 = 0;
            }
            LayerCycleAndFootprintEstimator::GetReadBehaviors(*v52, (char **)&v264);
            unint64_t v62 = v264[v54];
            v265 = v264;
            operator delete(v264);
            v62[15] = v59 != 0;
            uint64_t v86 = (uint64_t)v83;
            BOOL v87 = v54 != 0;
            int v88 = 0;
            LayerCycleAndFootprintEstimator::GetReadBehaviors(*v52, (char **)&v264);
            unint64_t v63 = v264[v54];
            v265 = v264;
            operator delete(v264);
            v264 = (void **)&v91;
            uint64_t v64 = (l2a *)std::__hash_table<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::__unordered_map_hasher<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,true>,std::__unordered_map_equal<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::equal_to<ZinIrOpLayer *>,std::hash<ZinIrOpLayer *>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer * const&>,std::tuple<>>(v13 + 152, &v91, (uint64_t)&std::piecewise_construct, &v264)[3];
            unint64_t v65 = std::__hash_table<std::__hash_value_type<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,unsigned long>,std::__unordered_map_hasher<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,std::__hash_value_type<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,unsigned long>,ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKeyHasher,std::equal_to<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey>,true>,std::__unordered_map_equal<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,std::__hash_value_type<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,unsigned long>,std::equal_to<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey>,ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKeyHasher,true>,std::allocator<std::__hash_value_type<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,unsigned long>>>::find<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey>((void *)(v13 + 192), (int *)&v86);
            if (!v65) {
              std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
            }
            v63[7] = DMABuffer::CalculateSrcSize((uint64_t)v83, v54 != 0, v64, v65[4], 0, *(unsigned __int8 **)(v13 + 336), (uint64_t)v236);
          }
          ++v54;
          unint64_t v53 = v92;
        }
        while (v54 < (uint64_t)(v93 - (void)v92) >> 3);
      }
      *(void *)((*v52)[3][2] + 8 * v79) = (unint64_t)((double)(unint64_t)v99
                                                             / *(double *)(v13 + 984)
                                                             * 1000.0
                                                             * 1000.0
                                                             * 1000.0);
      long long v66 = *(_OWORD *)(v13 + 992);
      v84[0] = *v51;
      v84[1] = v66;
      uint64_t v85 = *(void *)(v13 + 1008);
      BOOL HasDMAReadStall = ZinEnginePerf::HasDMAReadStall(v12, v83, (uint64_t)v98, (uint64_t)v84, 1);
      if (HasDMAReadStall)
      {
        unint64_t ChainedOverheadCycleCount = ZinCpBasedAllocator::GetChainedOverheadCycleCount(HasDMAReadStall, (uint64_t)v33, v52, v79);
        (*v33)[4][16] = ChainedOverheadCycleCount;
        LayerCycleAndFootprintEstimator::GetReadBehaviors(*v52, (char **)&v264);
        unint64_t v69 = v264[v79];
        v265 = v264;
        operator delete(v264);
        v69[16] = ChainedOverheadCycleCount;
      }
      if ((v82 & 1) == 0)
      {
        v264 = (void **)v83;
        double v70 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::find<ZinIrTensor *>((void *)(v13 + 232), &v264);
        if (v70)
        {
          unint64_t v71 = v70[3];
          unint64_t v72 = (unint64_t)((double)*((unint64_t *)&v102 + 1)
                                 / *(double *)(v13 + 984)
                                 * 1000.0
                                 * 1000.0
                                 * 1000.0);
          double v73 = (double)(unint64_t)(*((void *)&v100 + 1) / *(void *)(*(void *)(v13 + 336) + 520))
              / *(double *)(v13 + 992)
              * 1000.0
              * 1000.0
              * 1000.0;
          if (v72 <= (unint64_t)v73) {
            unint64_t v72 = (unint64_t)v73;
          }
          (*v52)[4][6] = v72;
          uint64_t v86 = 0;
          uint64_t v86 = (*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)v83 + 32))(v83, 0, 0);
          v264 = (void **)&v86;
          unint64_t v74 = std::__hash_table<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::__unordered_map_hasher<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,true>,std::__unordered_map_equal<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::equal_to<ZinIrOpLayer *>,std::hash<ZinIrOpLayer *>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer * const&>,std::tuple<>>(v13 + 152, &v86, (uint64_t)&std::piecewise_construct, &v264);
          DMABuffer::CalculateDstSize(v83, (const ZinANELayer *)v74[3], v71, 0, *(ZinIrHalParameters **)(v13 + 336), (const ZinIrHalParameters *)v236, v75);
        }
        std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
      }
      if (v92)
      {
        unint64_t v93 = (unint64_t)v92;
        operator delete(v92);
      }
      if (v96)
      {
        uint64_t v97 = v96;
        operator delete(v96);
      }
      uint64_t v29 = 0;
    }
    if (v106)
    {
      unint64_t v107 = v106;
      operator delete(v106);
    }
    ZinIrPerf::~ZinIrPerf((ZinIrPerf *)&v118);
  }
  if (v131)
  {
    int v132 = v131;
    operator delete(v131);
  }
  ZinIrPerf::~ZinIrPerf((ZinIrPerf *)__p);
  ZinIrHalH13g::~ZinIrHalH13g((ZinIrHalH13g *)&v145);
  if (v178[0]) {
    operator delete(v178[0]);
  }
  v179 = &unk_26C34D080;
  if ((void)v209)
  {
    *((void *)&v209 + 1) = v209;
    operator delete((void *)v209);
  }
  ZinIrHalH13g::~ZinIrHalH13g((ZinIrHalH13g *)&v179);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&v246);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&v242);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&v238);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&v259);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&v255);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&v251);
  unint64_t v76 = (ZinEngineLayerMirInfo *)v262;
  uint64_t v262 = 0;
  if (v76)
  {
    ZinEngineLayerMirInfo::~ZinEngineLayerMirInfo(v76);
    MEMORY[0x21667D3C0]();
  }
  uint64_t v77 = (ZinEngineLayerMirInfo *)v263;
  uint64_t v263 = 0;
  if (v77)
  {
    ZinEngineLayerMirInfo::~ZinEngineLayerMirInfo(v77);
    MEMORY[0x21667D3C0]();
  }
  return v29;
}

void sub_21137B5F8(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33,uint64_t a34,uint64_t a35,uint64_t a36,uint64_t a37,uint64_t a38,uint64_t a39,void *__p,uint64_t a41,uint64_t a42,uint64_t a43,uint64_t a44,uint64_t a45,uint64_t a46,uint64_t a47,void *a48)
{
  if (__p) {
    operator delete(__p);
  }
  if (a48) {
    operator delete(a48);
  }
  uint64_t v50 = (void *)STACK[0x218];
  if (STACK[0x218])
  {
    STACK[0x220] = (unint64_t)v50;
    operator delete(v50);
  }
  ZinIrPerf::~ZinIrPerf((ZinIrPerf *)&STACK[0x298]);
  unint64_t v51 = (void *)STACK[0x6C8];
  if (STACK[0x6C8])
  {
    STACK[0x6D0] = (unint64_t)v51;
    operator delete(v51);
  }
  ZinIrPerf::~ZinIrPerf((ZinIrPerf *)&STACK[0x750]);
  ZinIrHalH13g::~ZinIrHalH13g((ZinIrHalH13g *)&STACK[0xAE0]);
  if (STACK[0xD10]) {
    operator delete((void *)STACK[0xD10]);
  }
  ZinNECustomPerfInfo::~ZinNECustomPerfInfo((ZinNECustomPerfInfo *)&STACK[0xD28]);
  ZinMirL2Config::~ZinMirL2Config((ZinMirL2Config *)&STACK[0x1000]);
  ZinMirL2Config::~ZinMirL2Config((ZinMirL2Config *)&STACK[0x1250]);
  std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)(v48 - 160), 0);
  std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)(v48 - 152), 0);
  _Unwind_Resume(a1);
}

void sub_21137B744()
{
}

unint64_t ZinCpBasedAllocator::GetChainedOverheadCycleCount(uint64_t a1, uint64_t a2, uint64_t ***a3, uint64_t a4)
{
  if (**(void **)(*(void *)a2 + 24) > (unint64_t)*(*a3)[3]) {
    return 0;
  }
  unint64_t v6 = *(void *)(*(void *)(*(void *)a2 + 32) + 96);
  LayerCycleAndFootprintEstimator::GetReadBehaviors(*a3, (char **)__p);
  uint64_t v7 = *((void *)__p[0] + a4);
  __p[1] = __p[0];
  operator delete(__p[0]);
  if (*(void *)(v7 + 96) >= v6) {
    return v6;
  }
  else {
    return *(void *)(v7 + 96);
  }
}

uint64_t ZinCpBasedAllocator::SetPNChainExecutionBehavior(ZinCpBasedAllocator *this, const ZinPELayer *a2, const ZinNELayer *a3, uint64_t a4, uint64_t a5)
{
  uint64_t v5 = MEMORY[0x270FA5388](this, a2, a3, a4, a5);
  char v82 = v6;
  char v8 = v7;
  uint64_t v10 = v9;
  char v12 = (void *)v11;
  uint64_t v13 = v5;
  ZinANELayer::CopyMirInfo(v11, &v264);
  ZinANELayer::CopyMirInfo((uint64_t)v10, &v263);
  v250[0] = vdupq_n_s64(1uLL);
  BYTE8(v250[4]) = 0;
  *(void *)&v250[3] = 0;
  *((void *)&v250[2] + 1) = 0;
  BYTE8(v250[3]) = 0;
  v250[1] = 1uLL;
  LOBYTE(v250[2]) = 0;
  *(void *)&v250[4] = 0;
  v250[5] = 1uLL;
  memset(&v250[6], 0, 18);
  *(_OWORD *)((char *)&v250[7] + 8) = xmmword_211ED33C0;
  BYTE8(v250[8]) = 0;
  DWORD2(v250[14]) = 0;
  *((void *)&v250[18] + 1) = 0;
  memset(&v250[15], 0, 49);
  LODWORD(v250[19]) = 0;
  *(void *)&v250[23] = 0;
  *(_OWORD *)((char *)&v250[19] + 8) = 0u;
  *(_OWORD *)((char *)&v250[20] + 8) = 0u;
  *(_OWORD *)((char *)&v250[21] + 8) = 0u;
  BYTE8(v250[22]) = 0;
  DWORD2(v250[23]) = 0;
  *((void *)&v250[27] + 1) = 0;
  memset(&v250[24], 0, 49);
  int v251 = 0;
  long long v252 = 0u;
  long long v253 = 0u;
  *(_OWORD *)((char *)&v250[9] + 8) = 0u;
  *(_OWORD *)((char *)&v250[10] + 8) = 0u;
  *(_OWORD *)((char *)&v250[11] + 1) = 0u;
  memset(&v250[13], 0, 17);
  *((void *)&v250[12] + 1) = 0;
  int v254 = 1065353216;
  int v255 = 0;
  long long v256 = 0u;
  long long v257 = 0u;
  int v258 = 1065353216;
  int v259 = 0;
  long long v260 = 0u;
  long long v261 = 0u;
  int v262 = 1065353216;
  __src[0] = v250[0];
  BYTE8(__src[4]) = 0;
  *(void *)&void __src[3] = 0;
  *((void *)&__src[2] + 1) = 0;
  BYTE8(__src[3]) = 0;
  __src[1] = 1uLL;
  LOBYTE(__src[2]) = 0;
  *(void *)&__src[4] = 0;
  __src[5] = 1uLL;
  memset(&__src[6], 0, 18);
  *(_OWORD *)((char *)&__src[7] + 8) = xmmword_211ED33C0;
  BYTE8(__src[8]) = 0;
  DWORD2(__src[14]) = 0;
  *((void *)&__src[18] + 1) = 0;
  memset(&__src[15], 0, 49);
  LODWORD(__src[19]) = 0;
  *(void *)&__src[23] = 0;
  *(_OWORD *)((char *)&__src[19] + 8) = 0u;
  *(_OWORD *)((char *)&__src[20] + 8) = 0u;
  *(_OWORD *)((char *)&__src[21] + 8) = 0u;
  BYTE8(__src[22]) = 0;
  DWORD2(__src[23]) = 0;
  *((void *)&__src[27] + 1) = 0;
  memset(&__src[24], 0, 49);
  int v238 = 0;
  long long v239 = 0u;
  long long v240 = 0u;
  *(_OWORD *)((char *)&__src[9] + 8) = 0u;
  *(_OWORD *)((char *)&__src[10] + 8) = 0u;
  *(_OWORD *)((char *)&__src[11] + 1) = 0u;
  memset(&__src[13], 0, 17);
  *((void *)&__src[12] + 1) = 0;
  int v241 = 1065353216;
  int v242 = 0;
  long long v243 = 0u;
  long long v244 = 0u;
  int v245 = 1065353216;
  int v246 = 0;
  long long v247 = 0u;
  long long v248 = 0u;
  int v249 = 1065353216;
  int v14 = *(const ZinIrTensor ***)(v13 + 272);
  uint64_t v15 = (ZinIrRegAllocUtil **)(*(uint64_t (**)(void *, void, void))(*(void *)v12 + 32))(v12, 0, 0);
  uint64_t ChainBufferSize = ZinL2FootprintCalculator::GetChainBufferSize(v14, v15, (ZinMirL2Config *)v250, (ZinMirL2Config *)__src);
  if (ChainBufferSize)
  {
    uint64_t v16 = v264;
    uint64_t v17 = (_OWORD *)(v264 + 120);
    memcpy((void *)(v264 + 120), v250, 0x1C0uLL);
    *(_DWORD *)(v16 + 568) = v251;
    if (v17 == v250)
    {
      *(_DWORD *)(v16 + 616) = v255;
      *(_DWORD *)(v16 + 664) = v259;
    }
    else
    {
      *(_DWORD *)(v16 + 608) = v254;
      std::__hash_table<std::__hash_value_type<ZinIrDimension,unsigned long>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,unsigned long>>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<std::__hash_value_type<ZinIrDimension,unsigned long>,void *> *>>((void *)(v16 + 576), (uint64_t *)v253, 0);
      *(_DWORD *)(v16 + 616) = v255;
      *(_DWORD *)(v16 + 656) = v258;
      std::__hash_table<std::__hash_value_type<ZinIrDimension,unsigned long>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,unsigned long>>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<std::__hash_value_type<ZinIrDimension,unsigned long>,void *> *>>((void *)(v16 + 624), (uint64_t *)v257, 0);
      *(_DWORD *)(v16 + 664) = v259;
      *(_DWORD *)(v16 + 704) = v262;
      std::__hash_table<std::__hash_value_type<ZinIrDimension,unsigned long>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,unsigned long>>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<std::__hash_value_type<ZinIrDimension,unsigned long>,void *> *>>((void *)(v16 + 672), (uint64_t *)v261, 0);
    }
    uint64_t v19 = v263;
    int v20 = (_OWORD *)(v263 + 120);
    memcpy((void *)(v263 + 120), __src, 0x1C0uLL);
    *(_DWORD *)(v19 + 568) = v238;
    if (v20 == __src)
    {
      *(_DWORD *)(v19 + 616) = v242;
      *(_DWORD *)(v19 + 664) = v246;
    }
    else
    {
      *(_DWORD *)(v19 + 608) = v241;
      std::__hash_table<std::__hash_value_type<ZinIrDimension,unsigned long>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,unsigned long>>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<std::__hash_value_type<ZinIrDimension,unsigned long>,void *> *>>((void *)(v19 + 576), (uint64_t *)v240, 0);
      *(_DWORD *)(v19 + 616) = v242;
      *(_DWORD *)(v19 + 656) = v245;
      std::__hash_table<std::__hash_value_type<ZinIrDimension,unsigned long>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,unsigned long>>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<std::__hash_value_type<ZinIrDimension,unsigned long>,void *> *>>((void *)(v19 + 624), (uint64_t *)v244, 0);
      *(_DWORD *)(v19 + 664) = v246;
      *(_DWORD *)(v19 + 704) = v249;
      std::__hash_table<std::__hash_value_type<ZinIrDimension,unsigned long>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,unsigned long>>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<std::__hash_value_type<ZinIrDimension,unsigned long>,void *> *>>((void *)(v19 + 672), (uint64_t *)v248, 0);
    }
    char v205 = 0;
    char v206 = 0;
    char v207 = 0;
    char v208 = 0;
    char v209 = 0;
    char v210 = 0;
    char v211 = 0;
    char v212 = 0;
    char v213 = 0;
    char v214 = 0;
    LOBYTE(v215) = 0;
    char v218 = 0;
    char v219 = 0;
    char v220 = 0;
    char v221 = 0;
    char v222 = 0;
    char v223 = 0;
    char v224 = 0;
    char v225 = 0;
    char v226 = 0;
    char v227 = 0;
    char v228 = 0;
    char v229 = 0;
    char v230 = 0;
    char v231 = 0;
    char v232 = 0;
    char v204 = &unk_26C34D0D8;
    char v233 = 0;
    char v234 = 0;
    char v235 = 0;
    char v236 = 0;
    LOBYTE(v121) = v8;
    BYTE1(v121) = v8;
    std::vector<BOOL>::vector(__p, &v121, 2);
    ZinCpBasedAllocator::GetCustomPerfInfo(v13, (uint64_t)v12, __p, 1, v264, (uint64_t)&v204);
    if (__p[0]) {
      operator delete(__p[0]);
    }
    char v148 = 0;
    char v149 = 0;
    char v150 = 0;
    char v151 = 0;
    char v152 = 0;
    char v153 = 0;
    char v154 = 0;
    char v155 = 0;
    char v156 = 0;
    char v157 = 0;
    LOBYTE(v158) = 0;
    char v161 = 0;
    char v162 = 0;
    char v163 = 0;
    char v164 = 0;
    char v165 = 0;
    char v166 = 0;
    char v167 = 0;
    char v168 = 0;
    char v169 = 0;
    char v170 = 0;
    char v171 = 0;
    char v172 = 0;
    char v173 = 0;
    char v174 = 0;
    char v175 = 0;
    char v147 = &unk_26C34D080;
    __int16 v176 = 0;
    char v180 = 0;
    char v181 = 0;
    __int16 v182 = 256;
    long long v177 = 0u;
    uint64_t v178 = 0;
    __int16 v179 = 0;
    char v183 = 0;
    char v184 = 0;
    __int16 v185 = 0;
    char v186 = 0;
    char v187 = 0;
    char v188 = 0;
    char v189 = 0;
    char v190 = 0;
    char v191 = 0;
    char v192 = 0;
    char v193 = 0;
    char v194 = 0;
    char v195 = 0;
    char v196 = 0;
    char v197 = 0;
    char v198 = 0;
    char v199 = 0;
    __int16 v200 = 0;
    char v201 = 0;
    char v202 = 0;
    int v203 = 0;
    LOBYTE(v121) = 1;
    std::vector<BOOL>::vector(__p, &v121, 1);
    ZinCpBasedAllocator::GetCustomPerfInfo(v13, (uint64_t)v10, __p, v82, v263, (uint64_t)&v147);
    if (__p[0]) {
      operator delete(__p[0]);
    }
    char v215 = v10;
    int v216 = 1;
    __int16 v217 = &v147;
    if (!v218) {
      char v218 = 1;
    }
    v158 = v12;
    int v159 = 0;
    char v160 = &v204;
    if (!v161) {
      char v161 = 1;
    }
    ZinIrHalParameters::GetOperationCondition(*(ZinIrHalParameters **)(v13 + 336), *(double *)(*(void *)(v13 + 344) + 104), *(_DWORD *)(*(void *)(v13 + 344) + 112), *(_DWORD *)(*(void *)(v13 + 344) + 116), (uint64_t)v146);
    uint64_t v21 = *(void *)(v13 + 336);
    uint64_t v121 = 0x1000000010101;
    __int16 v122 = 0;
    char v123 = 1;
    int v124 = 0;
    ZinIrPerf::ZinIrPerf((uint64_t)__p, v21, v146, &v121);
    uint64_t v132 = 0;
    long long v131 = 0u;
    long long v130 = 0u;
    long long v129 = 0u;
    long long v128 = 0u;
    long long v127 = 0u;
    long long v126 = 0u;
    memset(v125, 0, sizeof(v125));
    uint64_t v22 = operator new(8uLL);
    v133 = v22;
    *uint64_t v22 = 0;
    uint64_t v135 = v22 + 1;
    uint64_t v134 = v22 + 1;
    uint64_t v137 = 0;
    uint64_t v136 = 0;
    __asm { FMOV            V0.2D, #-1.0 }
    long long v138 = _Q0;
    long long v139 = _Q0;
    long long v140 = _Q0;
    long long v83 = _Q0;
    long long v141 = _Q0;
    uint64_t v142 = 0;
    char v143 = 0;
    uint64_t v144 = 0;
    if (ZinANELayer::CalculatePerf((ZinANELayer *)v12, (ZinIrPerf *)__p, (const ZinCustomPerfInfo *)&v204, (ZinPerfDescriptor *)v125))
    {
      if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
        ZinCpBasedAllocator::SetPNChainExecutionBehavior();
      }
      uint64_t v18 = 3;
    }
    else
    {
      uint64_t v28 = *(void *)(v13 + 336);
      *(void *)&v100[0] = 0x1000000010101;
      WORD4(v100[0]) = 0;
      BYTE10(v100[0]) = 1;
      *(_DWORD *)((char *)v100 + 11) = 0;
      ZinIrPerf::ZinIrPerf((uint64_t)&v121, v28, v146, (uint64_t *)v100);
      uint64_t v108 = 0;
      long long v106 = 0u;
      long long v107 = 0u;
      long long v104 = 0u;
      long long v105 = 0u;
      long long v102 = 0u;
      long long v103 = 0u;
      long long v101 = 0u;
      memset(v100, 0, sizeof(v100));
      uint64_t v29 = operator new(8uLL);
      uint64_t v109 = v29;
      *uint64_t v29 = 0;
      long long v111 = v29 + 1;
      uint64_t v110 = v29 + 1;
      uint64_t v113 = 0;
      uint64_t v112 = 0;
      long long v114 = v83;
      long long v115 = v83;
      long long v116 = v83;
      long long v117 = v83;
      uint64_t v118 = 0;
      char v119 = 0;
      uint64_t v120 = 0;
      if (ZinANELayer::CalculatePerf(v10, (ZinIrPerf *)&v121, (const ZinCustomPerfInfo *)&v147, (ZinPerfDescriptor *)v100))
      {
        if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
          ZinCpBasedAllocator::SetPNChainExecutionBehavior();
        }
        uint64_t v18 = 3;
      }
      else
      {
        unint64_t v84 = v10;
        unint64_t v98 = v12;
        v265 = &v98;
        uint64_t v30 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>>>::__emplace_unique_key_args<ZinANELayer const*,std::piecewise_construct_t const&,std::tuple<ZinANELayer const*&&>,std::tuple<>>(v13 + 112, &v98, (uint64_t)&std::piecewise_construct, &v265);
        (*(void (**)(void **__return_ptr, void *))(*(void *)v12 + 512))(&v98, v12);
        unint64_t v31 = v98;
        double v32 = v99;
        if (v99 != v98)
        {
          unint64_t v33 = 0;
          do
          {
            if ((v8 & 1) == 0)
            {
              uint64_t v88 = 0;
              uint64_t v88 = v31[v33];
              LayerCycleAndFootprintEstimator::GetReadBehaviors((uint64_t **)v30[3], (char **)&v265);
              char v34 = v265[v33];
              v266 = v265;
              operator delete(v265);
              unint64_t v35 = (unint64_t)((double)*((unint64_t *)&v128 + 1)
                                     / *(double *)(v13 + 984)
                                     * 1000.0
                                     * 1000.0
                                     * 1000.0);
              unint64_t v36 = (char *)v125 + 8 * v33;
              if (v35 <= (unint64_t)((double)(unint64_t)(*((void *)v36 + 13)
                                                                      / *(void *)(*(void *)(v13 + 336) + 520))
                                           / *(double *)(v13 + 992)
                                           * 1000.0
                                           * 1000.0
                                           * 1000.0))
                unint64_t v35 = (unint64_t)((double)(unint64_t)(*((void *)v36 + 13)
                                                                  / *(void *)(*(void *)(v13 + 336) + 520))
                                       / *(double *)(v13 + 992)
                                       * 1000.0
                                       * 1000.0
                                       * 1000.0);
              v34[4] = v35;
              uint64_t v37 = *(ZinEnginePerf **)(v88 + 96);
              uint64_t v97 = *(void *)(v13 + 1008);
              long long v38 = *(_OWORD *)(v13 + 992);
              v96[0] = *(_OWORD *)(v13 + 976);
              v96[1] = v38;
              if (ZinEnginePerf::HasDMAReadStall(v37, (const ZinANELayer *)v12, (uint64_t)v125, (uint64_t)v96, 0))
              {
                double v39 = (double)(unint64_t)(*((void *)v36 + 13) / *(void *)(*(void *)(v13 + 336) + 520))
                    / *(double *)(v13 + 992)
                    * 1000.0
                    * 1000.0
                    * 1000.0;
                if ((unint64_t)v39 >= (unint64_t)((double)*((unint64_t *)&v128 + 1)
                                                               / *(double *)(v13 + 984)
                                                               * 1000.0
                                                               * 1000.0
                                                               * 1000.0))
                  unint64_t v40 = (unint64_t)((double)*((unint64_t *)&v128 + 1)
                                         / *(double *)(v13 + 984)
                                         * 1000.0
                                         * 1000.0
                                         * 1000.0);
                else {
                  unint64_t v40 = (unint64_t)v39;
                }
              }
              else
              {
                unint64_t v40 = 0;
              }
              LayerCycleAndFootprintEstimator::GetReadBehaviors((uint64_t **)v30[3], (char **)&v265);
              long long v41 = v265[v33];
              v266 = v265;
              operator delete(v265);
              v41[15] = v40;
              int v94 = v12;
              unint64_t v95 = v33 != 0;
              LayerCycleAndFootprintEstimator::GetReadBehaviors((uint64_t **)v30[3], (char **)&v265);
              double v42 = v265[v33];
              v266 = v265;
              operator delete(v265);
              v265 = (void **)&v88;
              unint64_t v43 = (l2a *)std::__hash_table<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::__unordered_map_hasher<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,true>,std::__unordered_map_equal<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::equal_to<ZinIrOpLayer *>,std::hash<ZinIrOpLayer *>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer * const&>,std::tuple<>>(v13 + 152, &v88, (uint64_t)&std::piecewise_construct, &v265)[3];
              unint64_t v44 = std::__hash_table<std::__hash_value_type<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,unsigned long>,std::__unordered_map_hasher<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,std::__hash_value_type<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,unsigned long>,ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKeyHasher,std::equal_to<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey>,true>,std::__unordered_map_equal<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,std::__hash_value_type<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,unsigned long>,std::equal_to<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey>,ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKeyHasher,true>,std::allocator<std::__hash_value_type<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,unsigned long>>>::find<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey>((void *)(v13 + 192), (int *)&v94);
              if (!v44) {
                std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
              }
              v42[5] = DMABuffer::CalculateSrcSize((uint64_t)v12, v33 != 0, v43, v44[4], 0, *(unsigned __int8 **)(v13 + 336), (uint64_t)v250);
              unint64_t v31 = v98;
              double v32 = v99;
            }
            ++v33;
          }
          while (v33 < (v32 - (unsigned char *)v31) >> 3);
        }
        uint64_t v45 = v30[3];
        double v46 = *(double *)(v13 + 984);
        *(void *)(*(void *)(v45 + 24) + 4std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = (unint64_t)((double)(unint64_t)v126
                                                                     / v46
                                                                     * 1000.0
                                                                     * 1000.0
                                                                     * 1000.0);
        uint64_t v47 = *(void *)(v45 + 32);
        *(void *)(v47 + 96) = (unint64_t)((double)*((unint64_t *)&v129 + 1)
                                                 / v46
                                                 * 1000.0
                                                 * 1000.0
                                                 * 1000.0);
        *(void *)(v47 + 104) = ChainBufferSize;
        int v94 = v84;
        v265 = &v94;
        uint64_t v48 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>>>::__emplace_unique_key_args<ZinANELayer const*,std::piecewise_construct_t const&,std::tuple<ZinANELayer const*&&>,std::tuple<>>(v13 + 112, &v94, (uint64_t)&std::piecewise_construct, &v265);
        (*(void (**)(void **__return_ptr, ZinANELayer *))(*(void *)v84 + 512))(&v94, v84);
        unint64_t v49 = v94;
        if ((void *)v95 == v94)
        {
          unint64_t v81 = 0;
        }
        else
        {
          unint64_t v50 = 0;
          unint64_t v81 = 0;
          do
          {
            uint64_t v93 = 0;
            uint64_t v93 = v49[v50];
            if (*(void **)(v93 + 96) == v12)
            {
              LayerCycleAndFootprintEstimator::GetReadBehaviors((uint64_t **)v48[3], (char **)&v265);
              unint64_t v56 = v265[v50];
              v266 = v265;
              operator delete(v265);
              v56[12] = (unint64_t)((double)*((unint64_t *)&v104 + 1)
                                         / *(double *)(v13 + 984)
                                         * 1000.0
                                         * 1000.0
                                         * 1000.0);
              LayerCycleAndFootprintEstimator::GetReadBehaviors((uint64_t **)v48[3], (char **)&v265);
              long long v57 = v265[v50];
              v266 = v265;
              operator delete(v265);
              v57[13] = ChainBufferSize;
              unint64_t v81 = v50;
            }
            else if ((v8 & 1) == 0)
            {
              LayerCycleAndFootprintEstimator::GetReadBehaviors((uint64_t **)v48[3], (char **)&v265);
              unint64_t v51 = v265[v50];
              v266 = v265;
              operator delete(v265);
              unint64_t v52 = (unint64_t)((double)*((unint64_t *)&v104 + 1)
                                     / *(double *)(v13 + 984)
                                     * 1000.0
                                     * 1000.0
                                     * 1000.0);
              if (v52 <= (unint64_t)((double)(unint64_t)(*((void *)&v102 + v50 + 1)
                                                                      / *(void *)(*(void *)(v13 + 336) + 520))
                                           / *(double *)(v13 + 992)
                                           * 1000.0
                                           * 1000.0
                                           * 1000.0))
                unint64_t v52 = (unint64_t)((double)(unint64_t)(*((void *)&v102 + v50 + 1)
                                                                  / *(void *)(*(void *)(v13 + 336) + 520))
                                       / *(double *)(v13 + 992)
                                       * 1000.0
                                       * 1000.0
                                       * 1000.0);
              v51[6] = v52;
              long long v53 = *(_OWORD *)(v13 + 992);
              v91[0] = *(_OWORD *)(v13 + 976);
              v91[1] = v53;
              uint64_t v92 = *(void *)(v13 + 1008);
              if (ZinEnginePerf::HasDMAReadStall((ZinEnginePerf *)v12, v84, (uint64_t)v100, (uint64_t)v91, 0))
              {
                double v54 = (double)(unint64_t)(*((void *)&v102 + v50 + 1)
                                               / *(void *)(*(void *)(v13 + 336) + 520))
                    / *(double *)(v13 + 992)
                    * 1000.0
                    * 1000.0
                    * 1000.0;
                if ((unint64_t)v54 >= (unint64_t)((double)*((unint64_t *)&v104 + 1)
                                                               / *(double *)(v13 + 984)
                                                               * 1000.0
                                                               * 1000.0
                                                               * 1000.0))
                  unint64_t v55 = (unint64_t)((double)*((unint64_t *)&v104 + 1)
                                         / *(double *)(v13 + 984)
                                         * 1000.0
                                         * 1000.0
                                         * 1000.0);
                else {
                  unint64_t v55 = (unint64_t)v54;
                }
              }
              else
              {
                unint64_t v55 = 0;
              }
              LayerCycleAndFootprintEstimator::GetReadBehaviors((uint64_t **)v48[3], (char **)&v265);
              double v58 = v265[v50];
              v266 = v265;
              operator delete(v265);
              v58[15] = v55;
              uint64_t v88 = (uint64_t)v84;
              BOOL v89 = v50 != 0;
              int v90 = 0;
              LayerCycleAndFootprintEstimator::GetReadBehaviors((uint64_t **)v48[3], (char **)&v265);
              unint64_t v59 = v265[v50];
              v266 = v265;
              operator delete(v265);
              v265 = (void **)&v93;
              unint64_t v60 = (l2a *)std::__hash_table<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::__unordered_map_hasher<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,true>,std::__unordered_map_equal<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::equal_to<ZinIrOpLayer *>,std::hash<ZinIrOpLayer *>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer * const&>,std::tuple<>>(v13 + 152, &v93, (uint64_t)&std::piecewise_construct, &v265)[3];
              uint64_t v61 = std::__hash_table<std::__hash_value_type<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,unsigned long>,std::__unordered_map_hasher<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,std::__hash_value_type<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,unsigned long>,ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKeyHasher,std::equal_to<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey>,true>,std::__unordered_map_equal<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,std::__hash_value_type<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,unsigned long>,std::equal_to<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey>,ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKeyHasher,true>,std::allocator<std::__hash_value_type<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,unsigned long>>>::find<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey>((void *)(v13 + 192), (int *)&v88);
              if (!v61) {
                std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
              }
              v59[7] = DMABuffer::CalculateSrcSize((uint64_t)v84, v50 != 0, v60, v61[4], 0, *(unsigned __int8 **)(v13 + 336), (uint64_t)__src);
            }
            ++v50;
            unint64_t v49 = v94;
          }
          while (v50 < (uint64_t)(v95 - (void)v94) >> 3);
        }
        *(void *)(*(void *)(*(void *)(v48[3] + 24) + 16) + 8 * v81) = (unint64_t)((double)(unint64_t)v101
                                                                                                 / *(double *)(v13 + 976)
                                                                                                 * 1000.0
                                                                                                 * 1000.0
                                                                                                 * 1000.0);
        long long v62 = *(_OWORD *)(v13 + 992);
        v86[0] = *(_OWORD *)(v13 + 976);
        v86[1] = v62;
        uint64_t v87 = *(void *)(v13 + 1008);
        if (ZinEnginePerf::HasDMAReadStall((ZinEnginePerf *)v12, v84, (uint64_t)v100, (uint64_t)v86, 1))
        {
          uint64_t v64 = v30[3];
          unint64_t v65 = (uint64_t **)v48[3];
          if (**(void **)(v64 + 24) <= (unint64_t)*v65[3])
          {
            unint64_t v66 = *(void *)(*(void *)(v64 + 32) + 96);
            LayerCycleAndFootprintEstimator::GetReadBehaviors(v65, (char **)&v265);
            double v67 = v265[v81];
            v266 = v265;
            operator delete(v265);
            if (v67[12] < v66) {
              unint64_t v66 = v67[12];
            }
          }
          else
          {
            unint64_t v66 = 0;
          }
          BOOL IsLowThroughputPEPool = ZinEnginePerf::IsLowThroughputPEPool((ZinEnginePerf *)v12, v63);
          uint64_t v69 = v30[3];
          unint64_t v70 = v66;
          if (IsLowThroughputPEPool) {
            unint64_t v70 = **(void **)(v69 + 24) + v66;
          }
          *(void *)(*(void *)(v69 + 32) + 128) = v70;
          LayerCycleAndFootprintEstimator::GetReadBehaviors((uint64_t **)v48[3], (char **)&v265);
          unint64_t v71 = v265[v81];
          v266 = v265;
          operator delete(v265);
          v71[16] = v66;
        }
        if ((v82 & 1) == 0)
        {
          v265 = (void **)v84;
          unint64_t v72 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::find<ZinIrTensor *>((void *)(v13 + 232), &v265);
          if (v72)
          {
            unint64_t v73 = v72[3];
            unint64_t v74 = (unint64_t)((double)*((unint64_t *)&v105 + 1)
                                   / *(double *)(v13 + 984)
                                   * 1000.0
                                   * 1000.0
                                   * 1000.0);
            double v75 = (double)(unint64_t)(*((void *)&v103 + 1) / *(void *)(*(void *)(v13 + 336) + 520))
                / *(double *)(v13 + 992)
                * 1000.0
                * 1000.0
                * 1000.0;
            if (v74 <= (unint64_t)v75) {
              unint64_t v74 = (unint64_t)v75;
            }
            *(void *)(*(void *)(v48[3] + 32) + 48) = v74;
            uint64_t v88 = 0;
            uint64_t v88 = (*(uint64_t (**)(ZinANELayer *, void, void))(*(void *)v84 + 32))(v84, 0, 0);
            v265 = (void **)&v88;
            unint64_t v76 = std::__hash_table<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::__unordered_map_hasher<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,true>,std::__unordered_map_equal<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::equal_to<ZinIrOpLayer *>,std::hash<ZinIrOpLayer *>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer * const&>,std::tuple<>>(v13 + 152, &v88, (uint64_t)&std::piecewise_construct, &v265);
            DMABuffer::CalculateDstSize(v84, (const ZinANELayer *)v76[3], v73, 0, *(ZinIrHalParameters **)(v13 + 336), (const ZinIrHalParameters *)(*((void *)v84 + 33) + 120), v77);
          }
          std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
        }
        if (v94)
        {
          unint64_t v95 = (unint64_t)v94;
          operator delete(v94);
        }
        if (v98)
        {
          long long v99 = v98;
          operator delete(v98);
        }
        uint64_t v18 = 0;
      }
      if (v109)
      {
        uint64_t v110 = v109;
        operator delete(v109);
      }
      ZinIrPerf::~ZinIrPerf((ZinIrPerf *)&v121);
    }
    if (v133)
    {
      uint64_t v134 = v133;
      operator delete(v133);
    }
    ZinIrPerf::~ZinIrPerf((ZinIrPerf *)__p);
    char v147 = &unk_26C34D080;
    if ((void)v177)
    {
      *((void *)&v177 + 1) = v177;
      operator delete((void *)v177);
    }
    ZinIrHalH13g::~ZinIrHalH13g((ZinIrHalH13g *)&v147);
    ZinIrHalH13g::~ZinIrHalH13g((ZinIrHalH13g *)&v204);
  }
  else
  {
    uint64_t v18 = 0;
  }
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&v247);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&v243);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&v239);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&v260);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&v256);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&v252);
  unint64_t v78 = (ZinEngineLayerMirInfo *)v263;
  uint64_t v263 = 0;
  if (v78)
  {
    ZinEngineLayerMirInfo::~ZinEngineLayerMirInfo(v78);
    MEMORY[0x21667D3C0]();
  }
  uint64_t v79 = (ZinEngineLayerMirInfo *)v264;
  uint64_t v264 = 0;
  if (v79)
  {
    ZinEngineLayerMirInfo::~ZinEngineLayerMirInfo(v79);
    MEMORY[0x21667D3C0]();
  }
  return v18;
}

void sub_21137C920(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33,uint64_t a34,uint64_t a35,uint64_t a36,uint64_t a37,uint64_t a38,uint64_t a39,void *__p,uint64_t a41,uint64_t a42,uint64_t a43,uint64_t a44,uint64_t a45,uint64_t a46,uint64_t a47,void *a48)
{
  if (__p) {
    operator delete(__p);
  }
  if (a48) {
    operator delete(a48);
  }
  unint64_t v50 = (void *)STACK[0x218];
  if (STACK[0x218])
  {
    STACK[0x220] = (unint64_t)v50;
    operator delete(v50);
  }
  ZinIrPerf::~ZinIrPerf((ZinIrPerf *)&STACK[0x298]);
  unint64_t v51 = (void *)STACK[0x6C8];
  if (STACK[0x6C8])
  {
    STACK[0x6D0] = (unint64_t)v51;
    operator delete(v51);
  }
  ZinIrPerf::~ZinIrPerf((ZinIrPerf *)&STACK[0x748]);
  ZinNECustomPerfInfo::~ZinNECustomPerfInfo((ZinNECustomPerfInfo *)&STACK[0xAD8]);
  ZinIrHalH13g::~ZinIrHalH13g((ZinIrHalH13g *)&STACK[0xDB0]);
  ZinMirL2Config::~ZinMirL2Config((ZinMirL2Config *)&STACK[0xFE0]);
  ZinMirL2Config::~ZinMirL2Config((ZinMirL2Config *)&STACK[0x1230]);
  std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)(v48 - 160), 0);
  std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)(v48 - 152), 0);
  _Unwind_Resume(a1);
}

void sub_21137CA70()
{
}

uint64_t ZinCpBasedAllocator::GetNPL2DepPerfDescriptor(ZinCpBasedAllocator *this, const ZinNELayer *a2, const ZinPELayer *a3, unsigned int a4, char a5, char a6, uint64_t a7, ZinPerfDescriptor *a8, ZinPerfDescriptor *a9)
{
  uint64_t v17 = *((void *)a2 + 33);
  unsigned int v18 = *(_DWORD *)(ZinIrOpLayer::GetInputTensor(a2, 0) + 88);
  ZinIrOpLayer::GetInputTensorDimensions(a2, &__p);
  ZinMirL2Config::SetL2DependentBufferNEWorkUnit(v17 + 120, a2, v18, (uint64_t)__p, a4 | 0x10100, 0);
  if (__p)
  {
    unint64_t v36 = __p;
    operator delete(__p);
  }
  uint64_t v19 = *((void *)a2 + 33);
  if (!*(unsigned char *)(v19 + 233)) {
    *(void *)(v19 + 20std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = a7;
  }
  int v20 = (ZinIrOpLayerGraph *)*((void *)a2 + 19);
  long long __p = 0;
  unint64_t v36 = 0;
  uint64_t v37 = 0;
  double v32 = 0;
  unint64_t v33 = 0;
  uint64_t v34 = 0;
  unint64_t v30 = 0;
  unint64_t v31 = 0;
  ZinL2FootprintCalculator::GetInterleavesAndCropOffset((void *)this + 19, (void *)this + 24, (void *)this + 29, (uint64_t)a3, (uint64_t)&__p, (uint64_t)&v32, &v31, &v30);
  ZinMirL2Config::SetL2DependentBufferPEWorkUnit(*((void *)a3 + 33) + 120, *((void *)this + 42), a2, a3, &__p, &v32, v31, v30, 1u, 0);
  uint64_t v21 = *((void *)a3 + 33);
  if (!*(unsigned char *)(v21 + 233)) {
    *(void *)(v21 + 20std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = a7;
  }
  uint64_t IndexOfMatchedIncomingLayer = ZinIrOpLayerGraph::GetIndexOfMatchedIncomingLayer(v20, a3, a2);
  uint64_t v23 = *((void *)a2 + 33);
  char v27 = a4;
  std::vector<BOOL>::vector(v29, &v27, 1);
  int v24 = ZinCpBasedAllocator::CalculatePerf((uint64_t)this, a2, v23, v29, 1, a8);
  if (v29[0]) {
    operator delete(v29[0]);
  }
  if (v24)
  {
    uint64_t v25 = 3;
  }
  else
  {
    char v27 = 1;
    char v28 = a5;
    std::vector<BOOL>::vector(v29, &v27, 2);
    if (IndexOfMatchedIncomingLayer == 1)
    {
      char v27 = a5;
      char v28 = 1;
      std::vector<BOOL>::__assign_with_size[abi:ne180100]<BOOL const*,BOOL const*>(v29, &v27, v29, 2uLL);
    }
    if (ZinCpBasedAllocator::CalculatePerf((uint64_t)this, a3, *((void *)a3 + 33), v29, a6, a9)) {
      uint64_t v25 = 3;
    }
    else {
      uint64_t v25 = 0;
    }
    if (v29[0]) {
      operator delete(v29[0]);
    }
  }
  if (v32)
  {
    unint64_t v33 = v32;
    operator delete(v32);
  }
  if (__p)
  {
    unint64_t v36 = __p;
    operator delete(__p);
  }
  return v25;
}

void sub_21137CCC0(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, void *a15, uint64_t a16, uint64_t a17, void *a18, uint64_t a19)
{
  if (__p) {
    operator delete(__p);
  }
  if (a15) {
    operator delete(a15);
  }
  if (a18) {
    operator delete(a18);
  }
  _Unwind_Resume(exception_object);
}

void ZinCpBasedAllocator::GetNPL2DepCircularBufferMemoryFootprint(ZinCpBasedAllocator *this, const ZinNELayer *a2, const ZinPELayer *a3, const ZinPerfDescriptor *a4, const ZinPerfDescriptor *a5)
{
  (*(void (**)(void **__return_ptr, const ZinNELayer *))(*(void *)a2 + 512))(&__p, a2);
  uint64_t v8 = *(void *)__p;
  unint64_t v30 = __p;
  operator delete(__p);
  uint64_t v31 = v8;
  v28[0] = a2;
  v28[1] = 0;
  long long __p = &v31;
  uint64_t v9 = (l2a *)std::__hash_table<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::__unordered_map_hasher<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,true>,std::__unordered_map_equal<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::equal_to<ZinIrOpLayer *>,std::hash<ZinIrOpLayer *>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer * const&>,std::tuple<>>((uint64_t)this + 152, &v31, (uint64_t)&std::piecewise_construct, (void **)&__p)[3];
  uint64_t v10 = std::__hash_table<std::__hash_value_type<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,unsigned long>,std::__unordered_map_hasher<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,std::__hash_value_type<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,unsigned long>,ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKeyHasher,std::equal_to<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey>,true>,std::__unordered_map_equal<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,std::__hash_value_type<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,unsigned long>,std::equal_to<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey>,ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKeyHasher,true>,std::allocator<std::__hash_value_type<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,unsigned long>>>::find<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey>((void *)this + 24, (int *)v28);
  if (v10)
  {
    unint64_t v11 = DMABuffer::CalculateSrcSize((uint64_t)a2, 0, v9, v10[4], 0, *((unsigned __int8 **)this + 42), *((void *)a2 + 33) + 120);
    long long __p = a2;
    char v12 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::find<ZinIrTensor *>((void *)this + 14, &__p);
    if (v12)
    {
      unint64_t v13 = *(void *)(*(void *)(v12[3] + 32) + 8) + v11;
      (*(void (**)(void **__return_ptr, const ZinPELayer *))(*(void *)a3 + 512))(&__p, a3);
      int v14 = __p;
      if (v30 != __p)
      {
        unint64_t v15 = 0;
        do
        {
          char v27 = 0;
          char v27 = (const ZinIrTensor *)v14[v15];
          uint64_t RootTensor = ZinTensorFamilyUtil::GetRootTensor((ZinCpBasedAllocator *)((char *)this + 1048), v27);
          uint64_t v17 = (const ZinIrTensor *)(*(uint64_t (**)(const ZinNELayer *, void, void))(*(void *)a2 + 32))(a2, 0, 0);
          if (RootTensor != ZinTensorFamilyUtil::GetRootTensor((ZinCpBasedAllocator *)((char *)this + 1048), v17))
          {
            int v24 = (const ZinIrTensor ***)a3;
            BOOL v25 = v15 != 0;
            int v26 = 0;
            double v32 = &v27;
            unsigned int v18 = (l2a *)std::__hash_table<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::__unordered_map_hasher<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,true>,std::__unordered_map_equal<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::equal_to<ZinIrOpLayer *>,std::hash<ZinIrOpLayer *>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer * const&>,std::tuple<>>((uint64_t)this + 152, &v27, (uint64_t)&std::piecewise_construct, &v32)[3];
            uint64_t v19 = std::__hash_table<std::__hash_value_type<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,unsigned long>,std::__unordered_map_hasher<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,std::__hash_value_type<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,unsigned long>,ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKeyHasher,std::equal_to<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey>,true>,std::__unordered_map_equal<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,std::__hash_value_type<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,unsigned long>,std::equal_to<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey>,ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKeyHasher,true>,std::allocator<std::__hash_value_type<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,unsigned long>>>::find<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey>((void *)this + 24, (int *)&v24);
            if (!v19) {
              std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
            }
            v13 += DMABuffer::CalculateSrcSize((uint64_t)a3, v15 != 0, v18, v19[4], 0, *((unsigned __int8 **)this + 42), *((void *)a3 + 33) + 120);
          }
          ++v15;
          int v14 = __p;
        }
        while (v15 < (v30 - (unsigned char *)__p) >> 3);
      }
      double v32 = (const ZinIrTensor **)(*(uint64_t (**)(const ZinPELayer *, void, void))(*(void *)a3 + 32))(a3, 0, 0);
      int v24 = (const ZinIrTensor ***)a3;
      int v20 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::find<ZinIrTensor *>((void *)this + 29, &v24);
      if (v20)
      {
        unint64_t v21 = v20[3];
        int v24 = &v32;
        uint64_t v22 = std::__hash_table<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::__unordered_map_hasher<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,true>,std::__unordered_map_equal<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::equal_to<ZinIrOpLayer *>,std::hash<ZinIrOpLayer *>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer * const&>,std::tuple<>>((uint64_t)this + 152, &v32, (uint64_t)&std::piecewise_construct, &v24);
        DMABuffer::CalculateDstSize(a3, (const ZinANELayer *)v22[3], v21, 0, *((ZinIrHalParameters **)this + 42), (const ZinIrHalParameters *)(*((void *)a3 + 33) + 120), v23);
      }
      std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
    }
  }
  std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
}

void sub_21137D044(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, void *__p, uint64_t a16)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinCpBasedAllocator::SetNPL2DepExecutionBehavior(ZinCpBasedAllocator *this, const ZinNELayer *a2, const ZinPELayer *a3, unsigned __int8 a4, char a5, char a6)
{
  uint64_t v150 = *MEMORY[0x263EF8340];
  uint64_t v144 = a3;
  v145 = a2;
  unsigned __int8 v143 = a4;
  char v142 = a5;
  char v141 = a6;
  char v7 = (_DWORD *)*((void *)a2 + 33);
  memcpy(__dst, v7 + 30, sizeof(__dst));
  std::unordered_map<ZinDependencyOffsetDim,long>::unordered_map((uint64_t)v133, (uint64_t)(v7 + 144));
  int v135 = v7[154];
  std::unordered_map<ZinDependencyOffsetDim,long>::unordered_map((uint64_t)v136, (uint64_t)(v7 + 156));
  int v138 = v7[166];
  std::unordered_map<ZinDependencyOffsetDim,long>::unordered_map((uint64_t)v139, (uint64_t)(v7 + 168));
  uint64_t v8 = (_DWORD *)*((void *)v144 + 33);
  memcpy(__src, v8 + 30, sizeof(__src));
  std::unordered_map<ZinDependencyOffsetDim,long>::unordered_map((uint64_t)v124, (uint64_t)(v8 + 144));
  int v126 = v8[154];
  std::unordered_map<ZinDependencyOffsetDim,long>::unordered_map((uint64_t)v127, (uint64_t)(v8 + 156));
  int v129 = v8[166];
  std::unordered_map<ZinDependencyOffsetDim,long>::unordered_map((uint64_t)v130, (uint64_t)(v8 + 168));
  uint64_t v9 = (*(uint64_t (**)(ZinEnginePerf *, uint64_t))(*(void *)v145 + 368))(v145, 3);
  uint64_t v10 = *((void *)this + 42);
  if (*(unsigned char *)(v10 + 1117)) {
    unint64_t v11 = *(const ZinANELayer ***)(v10 + 656);
  }
  else {
    unint64_t v11 = (const ZinANELayer **)v9;
  }
  uint64_t v110 = 0;
  long long v108 = 0u;
  long long v109 = 0u;
  long long v106 = 0u;
  long long v107 = 0u;
  memset(v105, 0, sizeof(v105));
  char v12 = operator new(8uLL);
  long long v111 = v12;
  *char v12 = 0;
  uint64_t v113 = v12 + 1;
  uint64_t v112 = v12 + 1;
  uint64_t v115 = 0;
  uint64_t v114 = 0;
  __asm { FMOV            V0.2D, #-1.0 }
  long long v116 = _Q0;
  long long v117 = _Q0;
  long long v118 = _Q0;
  long long v119 = _Q0;
  long long v72 = _Q0;
  uint64_t v120 = 0;
  char v121 = 0;
  uint64_t v122 = 0;
  uint64_t v92 = 0;
  long long v90 = 0u;
  long long v91 = 0u;
  long long v88 = 0u;
  long long v89 = 0u;
  long long v87 = 0u;
  memset(v86, 0, sizeof(v86));
  uint64_t v17 = operator new(8uLL);
  uint64_t v93 = v17;
  void *v17 = 0;
  int v94 = v17 + 1;
  unint64_t v95 = v17 + 1;
  uint64_t v96 = 0;
  uint64_t v97 = 0;
  long long v98 = v72;
  long long v99 = v72;
  long long v100 = v72;
  long long v101 = v72;
  uint64_t v102 = 0;
  char v103 = 0;
  uint64_t v104 = 0;
  unsigned int v18 = (const ZinIrTensor *)(*(uint64_t (**)(ZinEnginePerf *, void, void))(*(void *)v145 + 32))(v145, 0, 0);
  uint64_t RootTensor = (ZinIrCircularBufferUtil *)ZinTensorFamilyUtil::GetRootTensor((ZinCpBasedAllocator *)((char *)this + 1048), v18);
  int v22 = ZinIrCircularBufferUtil::QualifyForCircularBuffer(RootTensor, *((const ZinIrTensor **)this + 42), v20, v21);
  if (v143) {
    _ZF = v141 == 0;
  }
  else {
    _ZF = 1;
  }
  if (_ZF || v142 == 0) {
    int v25 = v22;
  }
  else {
    int v25 = 0;
  }
  uint64_t v85 = (uint64_t)v11;
  int v26 = v11;
  if (v25 == 1) {
    int v26 = *(const ZinANELayer ***)(*((void *)this + 42) + 648);
  }
  p_p = v26;
  long long v83 = v11;
  char v149 = 0;
  char v27 = operator new(0x58uLL);
  *char v27 = &unk_26C32F228;
  v27[1] = this;
  v27[2] = &v145;
  v27[3] = &v144;
  v27[4] = &v143;
  v27[5] = &v142;
  v27[6] = &v141;
  v27[7] = v105;
  v27[8] = v86;
  v27[9] = __dst;
  v27[10] = __src;
  char v149 = v27;
  int v28 = BinarySearch((unint64_t *)&p_p, (uint64_t *)&v83, &v85, (uint64_t)v148);
  std::__function::__value_func<BOOL ()(unsigned long)>::~__value_func[abi:ne180100](v148);
  if ((v25 ^ 1 | v28))
  {
    if (ZinCpBasedAllocator::GetNPL2DepPerfDescriptor(this, v145, v144, v143, v142, v141, v85, (ZinPerfDescriptor *)v105, (ZinPerfDescriptor *)v86))ZinAssertImpl("Perf descriptor must be valid"); {
    long long v83 = v145;
    }
    p_p = (const ZinANELayer **)&v83;
    uint64_t v29 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>>>::__emplace_unique_key_args<ZinANELayer const*,std::piecewise_construct_t const&,std::tuple<ZinANELayer const*&&>,std::tuple<>>((uint64_t)this + 112, &v83, (uint64_t)&std::piecewise_construct, &p_p);
    (*(void (**)(void **__return_ptr))(*(void *)v145 + 512))(&v83);
    unint64_t v30 = v83;
    uint64_t v31 = v84;
    if (v84 != v83)
    {
      unint64_t v32 = 0;
      do
      {
        if (!v143)
        {
          unint64_t v73 = 0;
          unint64_t v73 = (const ZinANELayer *)v30[v32];
          LayerCycleAndFootprintEstimator::GetReadBehaviors((uint64_t **)v29[3], (char **)&p_p);
          unint64_t v33 = p_p[v32];
          char v147 = p_p;
          operator delete(p_p);
          unint64_t v34 = (unint64_t)((double)*((unint64_t *)&v106 + 1)
                                 / *((double *)this + 123)
                                 * 1000.0
                                 * 1000.0
                                 * 1000.0);
          unint64_t v35 = (char *)v105 + 8 * v32;
          if (v34 <= (unint64_t)((double)(unint64_t)(*((void *)v35 + 13)
                                                                  / *(void *)(*((void *)this + 42) + 520))
                                       / *((double *)this + 124)
                                       * 1000.0
                                       * 1000.0
                                       * 1000.0))
            unint64_t v34 = (unint64_t)((double)(unint64_t)(*((void *)v35 + 13)
                                                              / *(void *)(*((void *)this + 42) + 520))
                                   / *((double *)this + 124)
                                   * 1000.0
                                   * 1000.0
                                   * 1000.0);
          *((void *)v33 + 8) = v34;
          unint64_t v36 = (ZinEnginePerf *)*((void *)v73 + 12);
          long long v37 = *((_OWORD *)this + 62);
          v81[0] = *((_OWORD *)this + 61);
          v81[1] = v37;
          uint64_t v82 = *((void *)this + 126);
          if (ZinEnginePerf::HasDMAReadStall(v36, v145, (uint64_t)v105, (uint64_t)v81, 0))
          {
            double v38 = (double)(unint64_t)(*((void *)v35 + 13) / *(void *)(*((void *)this + 42) + 520))
                / *((double *)this + 124)
                * 1000.0
                * 1000.0
                * 1000.0;
            if ((unint64_t)v38 >= (unint64_t)((double)*((unint64_t *)&v106 + 1)
                                                           / *((double *)this + 123)
                                                           * 1000.0
                                                           * 1000.0
                                                           * 1000.0))
              unint64_t v39 = (unint64_t)((double)*((unint64_t *)&v106 + 1)
                                     / *((double *)this + 123)
                                     * 1000.0
                                     * 1000.0
                                     * 1000.0);
            else {
              unint64_t v39 = (unint64_t)v38;
            }
          }
          else
          {
            unint64_t v39 = 0;
          }
          LayerCycleAndFootprintEstimator::GetReadBehaviors((uint64_t **)v29[3], (char **)&p_p);
          unint64_t v40 = p_p[v32];
          char v147 = p_p;
          operator delete(p_p);
          *((void *)v40 + 15) = v39;
          long long __p = v145;
          unint64_t v80 = v32 != 0;
          LayerCycleAndFootprintEstimator::GetReadBehaviors((uint64_t **)v29[3], (char **)&p_p);
          long long v41 = p_p[v32];
          char v147 = p_p;
          operator delete(p_p);
          double v42 = v145;
          p_p = &v73;
          unint64_t v43 = (l2a *)std::__hash_table<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::__unordered_map_hasher<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,true>,std::__unordered_map_equal<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::equal_to<ZinIrOpLayer *>,std::hash<ZinIrOpLayer *>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer * const&>,std::tuple<>>((uint64_t)this + 152, &v73, (uint64_t)&std::piecewise_construct, &p_p)[3];
          unint64_t v44 = std::__hash_table<std::__hash_value_type<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,unsigned long>,std::__unordered_map_hasher<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,std::__hash_value_type<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,unsigned long>,ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKeyHasher,std::equal_to<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey>,true>,std::__unordered_map_equal<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,std::__hash_value_type<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,unsigned long>,std::equal_to<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey>,ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKeyHasher,true>,std::allocator<std::__hash_value_type<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,unsigned long>>>::find<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey>((void *)this + 24, (int *)&__p);
          if (!v44) {
            std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
          }
          *((void *)v41 + 9) = DMABuffer::CalculateSrcSize((uint64_t)v42, v32 != 0, v43, v44[4], 0, *((unsigned __int8 **)this + 42), *((void *)v145 + 33) + 120);
          unint64_t v30 = v83;
          uint64_t v31 = v84;
        }
        ++v32;
      }
      while (v32 < (v31 - (unsigned char *)v30) >> 3);
    }
    long long __p = v144;
    p_p = (const ZinANELayer **)&__p;
    uint64_t v45 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>>>::__emplace_unique_key_args<ZinANELayer const*,std::piecewise_construct_t const&,std::tuple<ZinANELayer const*&&>,std::tuple<>>((uint64_t)this + 112, &__p, (uint64_t)&std::piecewise_construct, &p_p);
    (*(void (**)(void **__return_ptr))(*(void *)v144 + 512))(&__p);
    double v46 = __p;
    if ((void *)v80 != __p)
    {
      unint64_t v47 = 0;
      do
      {
        unint64_t v78 = 0;
        unint64_t v78 = (const ZinIrTensor *)v46[v47];
        uint64_t v48 = ZinTensorFamilyUtil::GetRootTensor((ZinCpBasedAllocator *)((char *)this + 1048), v78);
        unint64_t v49 = (const ZinIrTensor *)(*(uint64_t (**)(ZinEnginePerf *, void, void))(*(void *)v145 + 32))(v145, 0, 0);
        if (v48 != ZinTensorFamilyUtil::GetRootTensor((ZinCpBasedAllocator *)((char *)this + 1048), v49) && v142 == 0)
        {
          LayerCycleAndFootprintEstimator::GetReadBehaviors((uint64_t **)v45[3], (char **)&p_p);
          unint64_t v51 = p_p[v47];
          char v147 = p_p;
          operator delete(p_p);
          unint64_t v52 = (unint64_t)((double)*((unint64_t *)&v88 + 1)
                                 / *((double *)this + 123)
                                 * 1000.0
                                 * 1000.0
                                 * 1000.0);
          long long v53 = (char *)v86 + 8 * v47;
          if (v52 <= (unint64_t)((double)(unint64_t)(*((void *)v53 + 13)
                                                                  / *(void *)(*((void *)this + 42) + 520))
                                       / *((double *)this + 124)
                                       * 1000.0
                                       * 1000.0
                                       * 1000.0))
            unint64_t v52 = (unint64_t)((double)(unint64_t)(*((void *)v53 + 13)
                                                              / *(void *)(*((void *)this + 42) + 520))
                                   / *((double *)this + 124)
                                   * 1000.0
                                   * 1000.0
                                   * 1000.0);
          *((void *)v51 + 1std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v52;
          long long v54 = *((_OWORD *)this + 62);
          v76[0] = *((_OWORD *)this + 61);
          v76[1] = v54;
          uint64_t v77 = *((void *)this + 126);
          if (ZinEnginePerf::HasDMAReadStall(v145, v144, (uint64_t)v86, (uint64_t)v76, 0))
          {
            double v55 = (double)(unint64_t)(*((void *)v53 + 13) / *(void *)(*((void *)this + 42) + 520))
                / *((double *)this + 124)
                * 1000.0
                * 1000.0
                * 1000.0;
            if ((unint64_t)v55 >= (unint64_t)((double)*((unint64_t *)&v88 + 1)
                                                           / *((double *)this + 123)
                                                           * 1000.0
                                                           * 1000.0
                                                           * 1000.0))
              unint64_t v56 = (unint64_t)((double)*((unint64_t *)&v88 + 1)
                                     / *((double *)this + 123)
                                     * 1000.0
                                     * 1000.0
                                     * 1000.0);
            else {
              unint64_t v56 = (unint64_t)v55;
            }
          }
          else
          {
            unint64_t v56 = 0;
          }
          LayerCycleAndFootprintEstimator::GetReadBehaviors((uint64_t **)v45[3], (char **)&p_p);
          long long v57 = p_p[v47];
          char v147 = p_p;
          operator delete(p_p);
          *((void *)v57 + 15) = v56;
          unint64_t v73 = v144;
          BOOL v74 = v47 != 0;
          int v75 = 0;
          LayerCycleAndFootprintEstimator::GetReadBehaviors((uint64_t **)v45[3], (char **)&p_p);
          double v58 = p_p[v47];
          char v147 = p_p;
          operator delete(p_p);
          unint64_t v59 = v144;
          p_p = &v78;
          unint64_t v60 = (l2a *)std::__hash_table<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::__unordered_map_hasher<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,true>,std::__unordered_map_equal<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::equal_to<ZinIrOpLayer *>,std::hash<ZinIrOpLayer *>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer * const&>,std::tuple<>>((uint64_t)this + 152, &v78, (uint64_t)&std::piecewise_construct, &p_p)[3];
          uint64_t v61 = std::__hash_table<std::__hash_value_type<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,unsigned long>,std::__unordered_map_hasher<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,std::__hash_value_type<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,unsigned long>,ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKeyHasher,std::equal_to<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey>,true>,std::__unordered_map_equal<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,std::__hash_value_type<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,unsigned long>,std::equal_to<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey>,ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKeyHasher,true>,std::allocator<std::__hash_value_type<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,unsigned long>>>::find<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey>((void *)this + 24, (int *)&v73);
          if (!v61) {
            std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
          }
          *((void *)v58 + 11) = DMABuffer::CalculateSrcSize((uint64_t)v59, v47 != 0, v60, v61[4], 0, *((unsigned __int8 **)this + 42), *((void *)v144 + 33) + 120);
        }
        ++v47;
        double v46 = __p;
      }
      while (v47 < (uint64_t)(v80 - (void)__p) >> 3);
    }
    if (!v141)
    {
      p_p = (const ZinANELayer **)v144;
      long long v62 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::find<ZinIrTensor *>((void *)this + 29, &p_p);
      if (v62)
      {
        unint64_t v63 = v62[3];
        unint64_t v64 = (unint64_t)((double)*((unint64_t *)&v89 + 1)
                               / *((double *)this + 123)
                               * 1000.0
                               * 1000.0
                               * 1000.0);
        double v65 = (double)(unint64_t)(*((void *)&v87 + 1) / *(void *)(*((void *)this + 42) + 520))
            / *((double *)this + 124)
            * 1000.0
            * 1000.0
            * 1000.0;
        if (v64 <= (unint64_t)v65) {
          unint64_t v64 = (unint64_t)v65;
        }
        *(void *)(*(void *)(v45[3] + 32) + 8std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v64;
        unint64_t v73 = 0;
        unint64_t v73 = (const ZinANELayer *)(*(uint64_t (**)(const ZinANELayer *, void, void))(*(void *)v144
                                                                                                  + 32))(v144, 0, 0);
        unint64_t v66 = v144;
        p_p = &v73;
        double v67 = std::__hash_table<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::__unordered_map_hasher<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,true>,std::__unordered_map_equal<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::equal_to<ZinIrOpLayer *>,std::hash<ZinIrOpLayer *>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer * const&>,std::tuple<>>((uint64_t)this + 152, &v73, (uint64_t)&std::piecewise_construct, &p_p);
        DMABuffer::CalculateDstSize(v66, (const ZinANELayer *)v67[3], v63, 0, *((ZinIrHalParameters **)this + 42), (const ZinIrHalParameters *)(*((void *)v144 + 33) + 120), v68);
      }
      std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
    }
    uint64_t v69 = *((void *)v145 + 33);
    memcpy((void *)(v69 + 120), __dst, 0x1C0uLL);
    *(_DWORD *)(v69 + 568) = __dst[112];
    if ((_DWORD *)(v69 + 120) == __dst)
    {
      *(_DWORD *)(v69 + 616) = v135;
      *(_DWORD *)(v69 + 664) = v138;
    }
    else
    {
      *(_DWORD *)(v69 + 608) = v134;
      std::__hash_table<std::__hash_value_type<ZinIrDimension,unsigned long>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,unsigned long>>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<std::__hash_value_type<ZinIrDimension,unsigned long>,void *> *>>((void *)(v69 + 576), v133[2], 0);
      *(_DWORD *)(v69 + 616) = v135;
      *(_DWORD *)(v69 + 656) = v137;
      std::__hash_table<std::__hash_value_type<ZinIrDimension,unsigned long>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,unsigned long>>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<std::__hash_value_type<ZinIrDimension,unsigned long>,void *> *>>((void *)(v69 + 624), v136[2], 0);
      *(_DWORD *)(v69 + 664) = v138;
      *(_DWORD *)(v69 + 704) = v140;
      std::__hash_table<std::__hash_value_type<ZinIrDimension,unsigned long>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,unsigned long>>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<std::__hash_value_type<ZinIrDimension,unsigned long>,void *> *>>((void *)(v69 + 672), v139[2], 0);
    }
    uint64_t v70 = *((void *)v144 + 33);
    memcpy((void *)(v70 + 120), __src, 0x1C0uLL);
    *(_DWORD *)(v70 + 568) = __src[112];
    if ((_DWORD *)(v70 + 120) == __src)
    {
      *(_DWORD *)(v70 + 616) = v126;
      *(_DWORD *)(v70 + 664) = v129;
    }
    else
    {
      *(_DWORD *)(v70 + 608) = v125;
      std::__hash_table<std::__hash_value_type<ZinIrDimension,unsigned long>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,unsigned long>>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<std::__hash_value_type<ZinIrDimension,unsigned long>,void *> *>>((void *)(v70 + 576), v124[2], 0);
      *(_DWORD *)(v70 + 616) = v126;
      *(_DWORD *)(v70 + 656) = v128;
      std::__hash_table<std::__hash_value_type<ZinIrDimension,unsigned long>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,unsigned long>>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<std::__hash_value_type<ZinIrDimension,unsigned long>,void *> *>>((void *)(v70 + 624), v127[2], 0);
      *(_DWORD *)(v70 + 664) = v129;
      *(_DWORD *)(v70 + 704) = v131;
      std::__hash_table<std::__hash_value_type<ZinIrDimension,unsigned long>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,unsigned long>>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<std::__hash_value_type<ZinIrDimension,unsigned long>,void *> *>>((void *)(v70 + 672), v130[2], 0);
    }
    if (__p)
    {
      unint64_t v80 = (unint64_t)__p;
      operator delete(__p);
    }
    if (v83)
    {
      unint64_t v84 = v83;
      operator delete(v83);
    }
  }
  if (v93)
  {
    int v94 = v93;
    operator delete(v93);
  }
  if (v111)
  {
    uint64_t v112 = v111;
    operator delete(v111);
  }
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v130);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v127);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v124);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v139);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v136);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v133);
  return 0;
}

void sub_21137DC64(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,void *__p,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33,uint64_t a34,uint64_t a35,uint64_t a36,void *a37,uint64_t a38,uint64_t a39,uint64_t a40,uint64_t a41,uint64_t a42,uint64_t a43,uint64_t a44,uint64_t a45,uint64_t a46,uint64_t a47,uint64_t a48,uint64_t a49,uint64_t a50,uint64_t a51,uint64_t a52,uint64_t a53,uint64_t a54,uint64_t a55,uint64_t a56,uint64_t a57,uint64_t a58,uint64_t a59,uint64_t a60,uint64_t a61,uint64_t a62,uint64_t a63)
{
  if (__p) {
    operator delete(__p);
  }
  if (a37) {
    operator delete(a37);
  }
  if (a66) {
    operator delete(a66);
  }
  double v67 = (void *)STACK[0x318];
  if (STACK[0x318])
  {
    STACK[0x320] = (unint64_t)v67;
    operator delete(v67);
  }
  ZinMirL2Config::~ZinMirL2Config((ZinMirL2Config *)&STACK[0x398]);
  ZinMirL2Config::~ZinMirL2Config((ZinMirL2Config *)&STACK[0x5E8]);
  _Unwind_Resume(a1);
}

uint64_t BinarySearch(unint64_t *a1, uint64_t *a2, void *a3, uint64_t a4)
{
  unint64_t v8 = *a1;
  unint64_t v9 = *a2;
  if (std::function<BOOL ()(unsigned long)>::operator()(a4, *a2))
  {
    *a3 = v9;
    return 1;
  }
  if (*a1 == *a2) {
    return 0;
  }
  uint64_t result = std::function<BOOL ()(unsigned long)>::operator()(a4, v8);
  if (result)
  {
    while (v8 < v9)
    {
      uint64_t v11 = v8 + ((v9 - v8) >> 1);
      if (std::function<BOOL ()(unsigned long)>::operator()(a4, v11))
      {
        *a3 = v11;
        unint64_t v8 = v11 + 1;
      }
      else
      {
        unint64_t v9 = v8 + ((v9 - v8) >> 1);
      }
    }
    return 1;
  }
  return result;
}

uint64_t ZinCpBasedAllocator::GetPNL2DepPerfDescriptor(ZinCpBasedAllocator *this, const ZinPELayer *a2, const ZinNELayer *a3, char a4, int a5, uint64_t a6, ZinPerfDescriptor *a7, ZinPerfDescriptor *a8)
{
  uint64_t v16 = *((void *)a3 + 33);
  unsigned int v17 = *(_DWORD *)(ZinIrOpLayer::GetInputTensor(a3, 0) + 88);
  ZinIrOpLayer::GetInputTensorDimensions(a3, &__p);
  if (a5) {
    uint64_t v18 = 65793;
  }
  else {
    uint64_t v18 = 65537;
  }
  ZinMirL2Config::SetL2DependentBufferNEWorkUnit(v16 + 120, a3, v17, (uint64_t)__p, v18, 0);
  if (__p)
  {
    unint64_t v34 = __p;
    operator delete(__p);
  }
  uint64_t v19 = *((void *)a3 + 33);
  if (!*(unsigned char *)(v19 + 233)) {
    *(void *)(v19 + 20std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = a6;
  }
  long long __p = 0;
  unint64_t v34 = 0;
  uint64_t v35 = 0;
  unint64_t v30 = 0;
  uint64_t v31 = 0;
  uint64_t v32 = 0;
  unint64_t v28 = 0;
  unint64_t v29 = 0;
  ZinL2FootprintCalculator::GetInterleavesAndCropOffset((void *)this + 19, (void *)this + 24, (void *)this + 29, (uint64_t)a2, (uint64_t)&__p, (uint64_t)&v30, &v29, &v28);
  ZinMirL2Config::SetL2DependentBufferPEWorkUnit(*((void *)a2 + 33) + 120, *((void *)this + 42), a2, a3, &__p, &v30, v29, v28, 1u, 0);
  uint64_t v20 = *((void *)a2 + 33);
  if (!*(unsigned char *)(v20 + 233)) {
    *(void *)(v20 + 20std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = a6;
  }
  v26[0] = a4;
  v26[1] = a4;
  std::vector<BOOL>::vector(v27, v26, 2);
  int v21 = ZinCpBasedAllocator::CalculatePerf((uint64_t)this, a2, v20, v27, 1, a7);
  if (v27[0]) {
    operator delete(v27[0]);
  }
  if (v21)
  {
    uint64_t v22 = 3;
  }
  else
  {
    uint64_t v23 = *((void *)a3 + 33);
    v26[0] = 1;
    std::vector<BOOL>::vector(v27, v26, 1);
    int v24 = ZinCpBasedAllocator::CalculatePerf((uint64_t)this, a3, v23, v27, a5, a8);
    if (v27[0]) {
      operator delete(v27[0]);
    }
    if (v24) {
      uint64_t v22 = 3;
    }
    else {
      uint64_t v22 = 0;
    }
  }
  if (v30)
  {
    uint64_t v31 = v30;
    operator delete(v30);
  }
  if (__p)
  {
    unint64_t v34 = __p;
    operator delete(__p);
  }
  return v22;
}

void sub_21137E04C(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, void *a15, uint64_t a16, uint64_t a17, void *a18, uint64_t a19)
{
  if (__p) {
    operator delete(__p);
  }
  if (a15) {
    operator delete(a15);
  }
  if (a18) {
    operator delete(a18);
  }
  _Unwind_Resume(exception_object);
}

void ZinCpBasedAllocator::GetPNL2DepCircularBufferMemoryFootprint(ZinCpBasedAllocator *this, uint64_t **a2, uint64_t **a3, const ZinPerfDescriptor *a4, const ZinPerfDescriptor *a5)
{
  ((void (*)(void **__return_ptr, uint64_t **))(*a2)[64])(&__p, a2);
  char v7 = __p;
  if (v22 != __p)
  {
    unint64_t v8 = 0;
    uint64_t v9 = 0;
    do
    {
      uint64_t v20 = 0;
      uint64_t v20 = v7[v8];
      unsigned int v17 = a2;
      BOOL v18 = v8 != 0;
      int v19 = 0;
      uint64_t v23 = &v20;
      uint64_t v10 = (l2a *)std::__hash_table<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::__unordered_map_hasher<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,true>,std::__unordered_map_equal<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::equal_to<ZinIrOpLayer *>,std::hash<ZinIrOpLayer *>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer * const&>,std::tuple<>>((uint64_t)this + 152, &v20, (uint64_t)&std::piecewise_construct, &v23)[3];
      uint64_t v11 = std::__hash_table<std::__hash_value_type<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,unsigned long>,std::__unordered_map_hasher<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,std::__hash_value_type<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,unsigned long>,ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKeyHasher,std::equal_to<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey>,true>,std::__unordered_map_equal<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,std::__hash_value_type<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,unsigned long>,std::equal_to<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey>,ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKeyHasher,true>,std::allocator<std::__hash_value_type<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,unsigned long>>>::find<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey>((void *)this + 24, (int *)&v17);
      if (!v11) {
        std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
      }
      v9 += DMABuffer::CalculateSrcSize((uint64_t)a2, v8++ != 0, v10, v11[4], 0, *((unsigned __int8 **)this + 42), (uint64_t)(a2[33] + 15));
      char v7 = __p;
    }
    while (v8 < (v22 - (unsigned char *)__p) >> 3);
  }
  unsigned int v17 = a2;
  if (std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::find<ZinIrTensor *>((void *)this + 14, &v17))
  {
    uint64_t v23 = (uint64_t *)((uint64_t (*)(uint64_t **, void, void))(*a3)[4])(a3, 0, 0);
    unsigned int v17 = a3;
    char v12 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::find<ZinIrTensor *>((void *)this + 29, &v17);
    if (v12)
    {
      unint64_t v13 = v12[3];
      unsigned int v17 = &v23;
      int v14 = std::__hash_table<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::__unordered_map_hasher<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,true>,std::__unordered_map_equal<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::equal_to<ZinIrOpLayer *>,std::hash<ZinIrOpLayer *>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer * const&>,std::tuple<>>((uint64_t)this + 152, &v23, (uint64_t)&std::piecewise_construct, &v17);
      DMABuffer::CalculateDstSize((DMABuffer *)a3, (const ZinANELayer *)v14[3], v13, 0, *((ZinIrHalParameters **)this + 42), (const ZinIrHalParameters *)(a3[33] + 15), v15);
    }
    std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
  }
  std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
}

void sub_21137E2E0(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, void *__p, uint64_t a15)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinCpBasedAllocator::SetPNL2DepExecutionBehavior(ZinCpBasedAllocator *this, const ZinPELayer *a2, const ZinNELayer *a3, char a4, unsigned __int8 a5)
{
  uint64_t v128 = *MEMORY[0x263EF8340];
  uint64_t v122 = a3;
  char v123 = a2;
  char v121 = a4;
  unsigned __int8 v120 = a5;
  char v6 = (_DWORD *)*((void *)a2 + 33);
  memcpy(__dst, v6 + 30, sizeof(__dst));
  std::unordered_map<ZinDependencyOffsetDim,long>::unordered_map((uint64_t)v112, (uint64_t)(v6 + 144));
  int v114 = v6[154];
  std::unordered_map<ZinDependencyOffsetDim,long>::unordered_map((uint64_t)v115, (uint64_t)(v6 + 156));
  int v117 = v6[166];
  std::unordered_map<ZinDependencyOffsetDim,long>::unordered_map((uint64_t)v118, (uint64_t)(v6 + 168));
  char v7 = (_DWORD *)*((void *)v122 + 33);
  memcpy(__src, v7 + 30, sizeof(__src));
  std::unordered_map<ZinDependencyOffsetDim,long>::unordered_map((uint64_t)v103, (uint64_t)(v7 + 144));
  int v105 = v7[154];
  std::unordered_map<ZinDependencyOffsetDim,long>::unordered_map((uint64_t)v106, (uint64_t)(v7 + 156));
  int v108 = v7[166];
  std::unordered_map<ZinDependencyOffsetDim,long>::unordered_map((uint64_t)v109, (uint64_t)(v7 + 168));
  uint64_t v8 = (*(uint64_t (**)(const ZinANELayer *, uint64_t))(*(void *)v123 + 368))(v123, 3);
  uint64_t v9 = *((void *)this + 42);
  if (*(unsigned char *)(v9 + 1117)) {
    uint64_t v10 = *(void ***)(v9 + 656);
  }
  else {
    uint64_t v10 = (void **)v8;
  }
  uint64_t v89 = 0;
  long long v87 = 0u;
  long long v88 = 0u;
  long long v85 = 0u;
  long long v86 = 0u;
  memset(v84, 0, sizeof(v84));
  uint64_t v11 = operator new(8uLL);
  long long v90 = v11;
  void *v11 = 0;
  uint64_t v92 = v11 + 1;
  long long v91 = v11 + 1;
  uint64_t v94 = 0;
  uint64_t v93 = 0;
  __asm { FMOV            V0.2D, #-1.0 }
  long long v95 = _Q0;
  long long v96 = _Q0;
  long long v97 = _Q0;
  long long v98 = _Q0;
  long long v55 = _Q0;
  uint64_t v99 = 0;
  char v100 = 0;
  uint64_t v101 = 0;
  uint64_t v71 = 0;
  long long v69 = 0u;
  long long v70 = 0u;
  long long v67 = 0u;
  long long v68 = 0u;
  long long v66 = 0u;
  memset(v65, 0, sizeof(v65));
  uint64_t v16 = operator new(8uLL);
  long long v72 = v16;
  void *v16 = 0;
  unint64_t v73 = v16 + 1;
  BOOL v74 = v16 + 1;
  uint64_t v75 = 0;
  uint64_t v76 = 0;
  long long v77 = v55;
  long long v78 = v55;
  long long v79 = v55;
  long long v80 = v55;
  uint64_t v81 = 0;
  char v82 = 0;
  uint64_t v83 = 0;
  unsigned int v17 = (const ZinIrTensor *)(*(uint64_t (**)(const ZinANELayer *, void, void))(*(void *)v123 + 32))(v123, 0, 0);
  uint64_t RootTensor = (ZinIrCircularBufferUtil *)ZinTensorFamilyUtil::GetRootTensor((ZinCpBasedAllocator *)((char *)this + 1048), v17);
  int v21 = ZinIrCircularBufferUtil::QualifyForCircularBuffer(RootTensor, *((const ZinIrTensor **)this + 42), v19, v20);
  if (v121) {
    _ZF = v120 == 0;
  }
  else {
    _ZF = 1;
  }
  if (_ZF) {
    int v23 = v21;
  }
  else {
    int v23 = 0;
  }
  uint64_t v64 = (uint64_t)v10;
  int v24 = v10;
  if (v23 == 1) {
    int v24 = *(void ***)(*((void *)this + 42) + 648);
  }
  p_p = v24;
  long long __p = v10;
  long long v127 = 0;
  int v25 = operator new(0x50uLL);
  *int v25 = &unk_26C32F280;
  v25[1] = this;
  uint64_t v25[2] = &v123;
  v25[3] = &v122;
  v25[4] = &v121;
  v25[5] = &v120;
  v25[6] = v84;
  v25[7] = v65;
  v25[8] = __dst;
  v25[9] = __src;
  long long v127 = v25;
  int v26 = BinarySearch((unint64_t *)&p_p, (uint64_t *)&__p, &v64, (uint64_t)v126);
  std::__function::__value_func<BOOL ()(unsigned long)>::~__value_func[abi:ne180100](v126);
  if ((v23 ^ 1 | v26))
  {
    if (ZinCpBasedAllocator::GetPNL2DepPerfDescriptor(this, v123, v122, v121, v120, v64, (ZinPerfDescriptor *)v84, (ZinPerfDescriptor *)v65))ZinAssertImpl("Perf descriptor must be valid"); {
    long long __p = v123;
    }
    p_p = &__p;
    char v27 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>>>::__emplace_unique_key_args<ZinANELayer const*,std::piecewise_construct_t const&,std::tuple<ZinANELayer const*&&>,std::tuple<>>((uint64_t)this + 112, &__p, (uint64_t)&std::piecewise_construct, &p_p);
    (*(void (**)(void **__return_ptr))(*(void *)v123 + 512))(&__p);
    unint64_t v28 = __p;
    unint64_t v29 = v63;
    if (v63 != __p)
    {
      unint64_t v30 = 0;
      do
      {
        if (!v121)
        {
          uint64_t v61 = 0;
          uint64_t v61 = v28[v30];
          LayerCycleAndFootprintEstimator::GetReadBehaviors((uint64_t **)v27[3], (char **)&p_p);
          uint64_t v31 = p_p[v30];
          int v125 = p_p;
          operator delete(p_p);
          unint64_t v32 = (unint64_t)((double)*((unint64_t *)&v85 + 1)
                                 / *((double *)this + 123)
                                 * 1000.0
                                 * 1000.0
                                 * 1000.0);
          unint64_t v33 = (char *)v84 + 8 * v30;
          if (v32 <= (unint64_t)((double)(unint64_t)(*((void *)v33 + 13)
                                                                  / *(void *)(*((void *)this + 42) + 520))
                                       / *((double *)this + 124)
                                       * 1000.0
                                       * 1000.0
                                       * 1000.0))
            unint64_t v32 = (unint64_t)((double)(unint64_t)(*((void *)v33 + 13)
                                                              / *(void *)(*((void *)this + 42) + 520))
                                   / *((double *)this + 124)
                                   * 1000.0
                                   * 1000.0
                                   * 1000.0);
          v31[8] = v32;
          unint64_t v34 = *(ZinEnginePerf **)(v61 + 96);
          long long v35 = *((_OWORD *)this + 62);
          v59[0] = *((_OWORD *)this + 61);
          v59[1] = v35;
          uint64_t v60 = *((void *)this + 126);
          if (ZinEnginePerf::HasDMAReadStall(v34, v123, (uint64_t)v84, (uint64_t)v59, 0))
          {
            double v36 = (double)(unint64_t)(*((void *)v33 + 13) / *(void *)(*((void *)this + 42) + 520))
                / *((double *)this + 124)
                * 1000.0
                * 1000.0
                * 1000.0;
            if ((unint64_t)v36 >= (unint64_t)((double)*((unint64_t *)&v85 + 1)
                                                           / *((double *)this + 123)
                                                           * 1000.0
                                                           * 1000.0
                                                           * 1000.0))
              unint64_t v37 = (unint64_t)((double)*((unint64_t *)&v85 + 1)
                                     / *((double *)this + 123)
                                     * 1000.0
                                     * 1000.0
                                     * 1000.0);
            else {
              unint64_t v37 = (unint64_t)v36;
            }
          }
          else
          {
            unint64_t v37 = 0;
          }
          LayerCycleAndFootprintEstimator::GetReadBehaviors((uint64_t **)v27[3], (char **)&p_p);
          double v38 = p_p[v30];
          int v125 = p_p;
          operator delete(p_p);
          v38[15] = v37;
          unint64_t v56 = v123;
          BOOL v57 = v30 != 0;
          int v58 = 0;
          LayerCycleAndFootprintEstimator::GetReadBehaviors((uint64_t **)v27[3], (char **)&p_p);
          unint64_t v39 = p_p[v30];
          int v125 = p_p;
          operator delete(p_p);
          unint64_t v40 = v123;
          p_p = (void **)&v61;
          long long v41 = (l2a *)std::__hash_table<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::__unordered_map_hasher<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,true>,std::__unordered_map_equal<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::equal_to<ZinIrOpLayer *>,std::hash<ZinIrOpLayer *>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer * const&>,std::tuple<>>((uint64_t)this + 152, &v61, (uint64_t)&std::piecewise_construct, &p_p)[3];
          double v42 = std::__hash_table<std::__hash_value_type<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,unsigned long>,std::__unordered_map_hasher<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,std::__hash_value_type<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,unsigned long>,ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKeyHasher,std::equal_to<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey>,true>,std::__unordered_map_equal<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,std::__hash_value_type<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,unsigned long>,std::equal_to<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey>,ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKeyHasher,true>,std::allocator<std::__hash_value_type<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey,unsigned long>>>::find<ZinMirInputCropOffsetXLsbsInitializer::InputCropOffsetXLsbsKey>((void *)this + 24, (int *)&v56);
          if (!v42) {
            std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
          }
          v39[9] = DMABuffer::CalculateSrcSize((uint64_t)v40, v30 != 0, v41, v42[4], 0, *((unsigned __int8 **)this + 42), *((void *)v123 + 33) + 120);
          unint64_t v28 = __p;
          unint64_t v29 = v63;
        }
        ++v30;
      }
      while (v30 < (v29 - (unsigned char *)v28) >> 3);
    }
    unint64_t v56 = v122;
    p_p = (void **)&v56;
    unint64_t v43 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>>>::__emplace_unique_key_args<ZinANELayer const*,std::piecewise_construct_t const&,std::tuple<ZinANELayer const*&&>,std::tuple<>>((uint64_t)this + 112, &v56, (uint64_t)&std::piecewise_construct, &p_p);
    if (!v120)
    {
      unint64_t v44 = v43;
      p_p = (void **)v122;
      uint64_t v45 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::find<ZinIrTensor *>((void *)this + 29, &p_p);
      if (v45)
      {
        unint64_t v46 = v45[3];
        unint64_t v47 = (unint64_t)((double)*((unint64_t *)&v68 + 1)
                               / *((double *)this + 123)
                               * 1000.0
                               * 1000.0
                               * 1000.0);
        double v48 = (double)(unint64_t)(*((void *)&v66 + 1) / *(void *)(*((void *)this + 42) + 520))
            / *((double *)this + 124)
            * 1000.0
            * 1000.0
            * 1000.0;
        if (v47 <= (unint64_t)v48) {
          unint64_t v47 = (unint64_t)v48;
        }
        *(void *)(*(void *)(v44[3] + 32) + 8std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v47;
        unint64_t v56 = 0;
        unint64_t v56 = (const ZinANELayer *)(*(uint64_t (**)(const ZinNELayer *, void, void))(*(void *)v122 + 32))(v122, 0, 0);
        unint64_t v49 = v122;
        p_p = (void **)&v56;
        unint64_t v50 = std::__hash_table<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::__unordered_map_hasher<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::hash<ZinIrOpLayer *>,std::equal_to<ZinIrOpLayer *>,true>,std::__unordered_map_equal<ZinIrOpLayer *,std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>,std::equal_to<ZinIrOpLayer *>,std::hash<ZinIrOpLayer *>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayer *,ZinAneInstruction *>>>::__emplace_unique_key_args<ZinIrOpLayer *,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayer * const&>,std::tuple<>>((uint64_t)this + 152, &v56, (uint64_t)&std::piecewise_construct, &p_p);
        DMABuffer::CalculateDstSize(v49, (const ZinANELayer *)v50[3], v46, 0, *((ZinIrHalParameters **)this + 42), (const ZinIrHalParameters *)(*((void *)v122 + 33) + 120), v51);
      }
      std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
    }
    uint64_t v52 = *((void *)v123 + 33);
    memcpy((void *)(v52 + 120), __dst, 0x1C0uLL);
    *(_DWORD *)(v52 + 568) = __dst[112];
    if ((_DWORD *)(v52 + 120) == __dst)
    {
      *(_DWORD *)(v52 + 616) = v114;
      *(_DWORD *)(v52 + 664) = v117;
    }
    else
    {
      *(_DWORD *)(v52 + 608) = v113;
      std::__hash_table<std::__hash_value_type<ZinIrDimension,unsigned long>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,unsigned long>>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<std::__hash_value_type<ZinIrDimension,unsigned long>,void *> *>>((void *)(v52 + 576), v112[2], 0);
      *(_DWORD *)(v52 + 616) = v114;
      *(_DWORD *)(v52 + 656) = v116;
      std::__hash_table<std::__hash_value_type<ZinIrDimension,unsigned long>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,unsigned long>>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<std::__hash_value_type<ZinIrDimension,unsigned long>,void *> *>>((void *)(v52 + 624), v115[2], 0);
      *(_DWORD *)(v52 + 664) = v117;
      *(_DWORD *)(v52 + 704) = v119;
      std::__hash_table<std::__hash_value_type<ZinIrDimension,unsigned long>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,unsigned long>>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<std::__hash_value_type<ZinIrDimension,unsigned long>,void *> *>>((void *)(v52 + 672), v118[2], 0);
    }
    uint64_t v53 = *((void *)v122 + 33);
    memcpy((void *)(v53 + 120), __src, 0x1C0uLL);
    *(_DWORD *)(v53 + 568) = __src[112];
    if ((_DWORD *)(v53 + 120) == __src)
    {
      *(_DWORD *)(v53 + 616) = v105;
      *(_DWORD *)(v53 + 664) = v108;
    }
    else
    {
      *(_DWORD *)(v53 + 608) = v104;
      std::__hash_table<std::__hash_value_type<ZinIrDimension,unsigned long>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,unsigned long>>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<std::__hash_value_type<ZinIrDimension,unsigned long>,void *> *>>((void *)(v53 + 576), v103[2], 0);
      *(_DWORD *)(v53 + 616) = v105;
      *(_DWORD *)(v53 + 656) = v107;
      std::__hash_table<std::__hash_value_type<ZinIrDimension,unsigned long>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,unsigned long>>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<std::__hash_value_type<ZinIrDimension,unsigned long>,void *> *>>((void *)(v53 + 624), v106[2], 0);
      *(_DWORD *)(v53 + 664) = v108;
      *(_DWORD *)(v53 + 704) = v110;
      std::__hash_table<std::__hash_value_type<ZinIrDimension,unsigned long>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,unsigned long>>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<std::__hash_value_type<ZinIrDimension,unsigned long>,void *> *>>((void *)(v53 + 672), v109[2], 0);
    }
    if (__p)
    {
      unint64_t v63 = __p;
      operator delete(__p);
    }
  }
  if (v72)
  {
    unint64_t v73 = v72;
    operator delete(v72);
  }
  if (v90)
  {
    long long v91 = v90;
    operator delete(v90);
  }
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v109);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v106);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v103);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v118);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v115);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v112);
  return 0;
}

void sub_21137EC2C(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,void *__p,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33,uint64_t a34,uint64_t a35,uint64_t a36,uint64_t a37,uint64_t a38,uint64_t a39,uint64_t a40,uint64_t a41,uint64_t a42,uint64_t a43,uint64_t a44,uint64_t a45,uint64_t a46,uint64_t a47,uint64_t a48,uint64_t a49,uint64_t a50,uint64_t a51,uint64_t a52,uint64_t a53,void *a54)
{
  if (__p) {
    operator delete(__p);
  }
  if (a54) {
    operator delete(a54);
  }
  long long v55 = (void *)STACK[0x2B8];
  if (STACK[0x2B8])
  {
    STACK[0x2C0] = (unint64_t)v55;
    operator delete(v55);
  }
  ZinMirL2Config::~ZinMirL2Config((ZinMirL2Config *)&STACK[0x338]);
  ZinMirL2Config::~ZinMirL2Config((ZinMirL2Config *)&STACK[0x588]);
  _Unwind_Resume(a1);
}

void ZinCpBasedAllocator::CreateCpAllocGraphDotFile(ZinCpBasedAllocator *this, const CpAllocGraph *a2)
{
  v25[19] = *MEMORY[0x263EF8340];
  if (*((void *)this + 63))
  {
    if (*((char *)this + 967) >= 0) {
      size_t v4 = *((unsigned __int8 *)this + 967);
    }
    else {
      size_t v4 = *((void *)this + 119);
    }
    uint64_t v5 = &v21;
    std::string::basic_string[abi:ne180100]((uint64_t)&v21, v4 + 9);
    if ((v21.__r_.__value_.__r.__words[2] & 0x8000000000000000) != 0) {
      uint64_t v5 = (std::string *)v21.__r_.__value_.__r.__words[0];
    }
    if (v4)
    {
      if (*((char *)this + 967) >= 0) {
        char v6 = (char *)this + 944;
      }
      else {
        char v6 = (char *)*((void *)this + 118);
      }
      memmove(v5, v6, v4);
    }
    strcpy((char *)v5 + v4, ".CpGraph.");
    if (*((char *)a2 + 255) < 0) {
      std::string::__init_copy_ctor_external(&__p, *((const std::string::value_type **)a2 + 29), *((void *)a2 + 30));
    }
    else {
      std::string __p = *(std::string *)((char *)a2 + 232);
    }
    if ((__p.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
      p_p = &__p;
    }
    else {
      p_p = (std::string *)__p.__r_.__value_.__r.__words[0];
    }
    if ((__p.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
      std::string::size_type size = HIBYTE(__p.__r_.__value_.__r.__words[2]);
    }
    else {
      std::string::size_type size = __p.__r_.__value_.__l.__size_;
    }
    uint64_t v9 = std::string::append(&v21, (const std::string::value_type *)p_p, size);
    long long v10 = *(_OWORD *)&v9->__r_.__value_.__l.__data_;
    v24.__r_.__value_.__r.__words[2] = v9->__r_.__value_.__r.__words[2];
    *(_OWORD *)&v24.__r_.__value_.__l.__data_ = v10;
    v9->__r_.__value_.__l.__size_ = 0;
    v9->__r_.__value_.__r.__words[2] = 0;
    v9->__r_.__value_.__r.__words[0] = 0;
    uint64_t v11 = std::string::append(&v24, ".dot", 4uLL);
    long long v12 = *(_OWORD *)&v11->__r_.__value_.__l.__data_;
    std::string::size_type v23 = v11->__r_.__value_.__r.__words[2];
    *(_OWORD *)uint64_t v22 = v12;
    v11->__r_.__value_.__l.__size_ = 0;
    v11->__r_.__value_.__r.__words[2] = 0;
    v11->__r_.__value_.__r.__words[0] = 0;
    if (SHIBYTE(v24.__r_.__value_.__r.__words[2]) < 0) {
      operator delete(v24.__r_.__value_.__l.__data_);
    }
    if (SHIBYTE(__p.__r_.__value_.__r.__words[2]) < 0) {
      operator delete(__p.__r_.__value_.__l.__data_);
    }
    if (SHIBYTE(v21.__r_.__value_.__r.__words[2]) < 0) {
      operator delete(v21.__r_.__value_.__l.__data_);
    }
    uint64_t v13 = MEMORY[0x263F8C310] + 64;
    v25[0] = MEMORY[0x263F8C310] + 64;
    int v14 = (std::string::size_type *)MEMORY[0x263F8C2B0];
    std::string::size_type v15 = *(void *)(MEMORY[0x263F8C2B0] + 16);
    v24.__r_.__value_.__r.__words[0] = *(void *)(MEMORY[0x263F8C2B0] + 8);
    *(std::string::size_type *)((char *)v24.__r_.__value_.__r.__words
                              + *(void *)(v24.__r_.__value_.__r.__words[0] - 24)) = v15;
    uint64_t v16 = (std::ios_base *)((char *)&v24 + *(void *)(v24.__r_.__value_.__r.__words[0] - 24));
    std::ios_base::init(v16, &v24.__r_.__value_.__r.__words[1]);
    uint64_t v17 = MEMORY[0x263F8C310] + 24;
    v16[1].__vftable = 0;
    v16[1].__fmtflags_ = -1;
    v24.__r_.__value_.__r.__words[0] = v17;
    v25[0] = v13;
    MEMORY[0x21667CDD0](&v24.__r_.__value_.__r.__words[1]);
    std::ofstream::open();
    CpGraph::CreateDotString((CpGraph **)a2, &v21);
    if ((v21.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
      BOOL v18 = &v21;
    }
    else {
      BOOL v18 = (std::string *)v21.__r_.__value_.__r.__words[0];
    }
    if ((v21.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
      std::string::size_type v19 = HIBYTE(v21.__r_.__value_.__r.__words[2]);
    }
    else {
      std::string::size_type v19 = v21.__r_.__value_.__l.__size_;
    }
    std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v24, (uint64_t)v18, v19);
    if (SHIBYTE(v21.__r_.__value_.__r.__words[2]) < 0) {
      operator delete(v21.__r_.__value_.__l.__data_);
    }
    if (!std::filebuf::close()) {
      std::ios_base::clear((std::ios_base *)((char *)&v24 + *(void *)(v24.__r_.__value_.__r.__words[0] - 24)), *(_DWORD *)((char *)&v24 + *(void *)(v24.__r_.__value_.__r.__words[0] - 24) + 32) | 4);
    }
    v24.__r_.__value_.__r.__words[0] = *v14;
    *(std::string::size_type *)((char *)v24.__r_.__value_.__r.__words
                              + *(void *)(v24.__r_.__value_.__r.__words[0] - 24)) = v14[3];
    MEMORY[0x21667CDE0](&v24.__r_.__value_.__r.__words[1]);
    std::ostream::~ostream();
    MEMORY[0x21667D2B0](v25);
    if (SHIBYTE(v23) < 0) {
      operator delete(v22[0]);
    }
  }
}

void sub_21137F130(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, void *a9, uint64_t a10, int a11, __int16 a12, char a13, char a14, void *__p, uint64_t a16, int a17, __int16 a18, char a19, char a20,uint64_t a21,uint64_t a22,int a23,__int16 a24,char a25,char a26,uint64_t a27,void *a28,uint64_t a29,int a30,__int16 a31,char a32,char a33)
{
  if (a20 < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

BOOL ZinCpBasedAllocator::CalculatesL2BudgetPerRegion(uint64_t a1, uint64_t *a2, unint64_t a3, void *a4)
{
  memset(v36, 0, sizeof(v36));
  int v37 = 1065353216;
  uint64_t v5 = (uint64_t *)*a2;
  char v6 = (uint64_t *)a2[1];
  if ((uint64_t *)*a2 == v6)
  {
    uint64_t v13 = *a2;
  }
  else
  {
    do
    {
      uint64_t v8 = *v5;
      uint64_t v9 = *(void **)(*v5 + 88);
      long long v10 = *(void **)(*v5 + 96);
      while (v9 != v10)
      {
        uint64_t v11 = (const ZinIrTensor *)(*(uint64_t (**)(void, void, void))(*(void *)*v9 + 32))(*v9, 0, 0);
        uint64_t RootTensor = ZinTensorFamilyUtil::GetRootTensor((ZinTensorFamilyUtil *)(a1 + 1048), v11);
        std::__hash_table<ZinIrTensor const*,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const* const&>((uint64_t)v36, &RootTensor, &RootTensor);
        ++v9;
      }
      long long v12 = (const ZinIrTensor *)(*(uint64_t (**)(uint64_t, void, void))(*(void *)v8 + 32))(v8, 0, 0);
      uint64_t RootTensor = ZinTensorFamilyUtil::GetRootTensor((ZinTensorFamilyUtil *)(a1 + 1048), v12);
      std::__hash_table<ZinIrTensor const*,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const* const&>((uint64_t)v36, &RootTensor, &RootTensor);
      ++v5;
    }
    while (v5 != v6);
    uint64_t v13 = *a2;
    uint64_t v5 = (uint64_t *)a2[1];
  }
  unint64_t v14 = *(void *)(*(void *)v13 + 48);
  uint64_t v15 = *(v5 - 1);
  uint64_t v16 = *(void *)(v15 + 48);
  uint64_t v17 = *(void *)(v15 + 56);
  RootTensors = (void *)ZinTensorFamilyUtil::GetRootTensors((ZinTensorFamilyUtil *)(a1 + 1048));
  uint64_t v20 = RootTensors + 1;
  std::string::size_type v19 = (void *)*RootTensors;
  if ((void *)*RootTensors == RootTensors + 1)
  {
    unint64_t v21 = 0;
  }
  else
  {
    unint64_t v21 = 0;
    unint64_t v22 = v17 + v16;
    do
    {
      std::string::size_type v23 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)(a1 + 280), v19 + 4);
      if (!v23) {
        std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
      }
      if (!std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(v36, v19 + 4))
      {
        unint64_t v27 = v23[3];
        if ((v27 & 0x8000000000000000) == 0)
        {
          unint64_t v28 = v23[4];
          if ((v28 & 0x8000000000000000) == 0
            && (v14 & 0x8000000000000000) == 0
            && (v22 & 0x8000000000000000) == 0
            && v27 <= v14
            && v28 >= v22)
          {
            unint64_t v29 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)(a1 + 72), v19 + 4);
            if (v29)
            {
              unsigned int v30 = *((_DWORD *)v29 + 6);
              if (v30 <= 7 && ((1 << v30) & 0xC1) != 0)
              {
                ZinL2FootprintCalculator::GetResidentBufferSize(*(ZinL2FootprintCalculator **)(a1 + 272), (const ZinIrTensor *)v19[4]);
                v21 += v31;
              }
            }
          }
        }
      }
      std::string v24 = (void *)v19[1];
      if (v24)
      {
        do
        {
          int v25 = v24;
          std::string v24 = (void *)*v24;
        }
        while (v24);
      }
      else
      {
        do
        {
          int v25 = (void *)v19[2];
          BOOL v26 = *v25 == (void)v19;
          std::string::size_type v19 = v25;
        }
        while (!v26);
      }
      std::string::size_type v19 = v25;
    }
    while (v25 != v20);
  }
  if (a3 <= v21)
  {
    *a4 = 0;
    if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_DEBUG)) {
      ZinCpBasedAllocator::CalculatesL2BudgetPerRegion();
    }
  }
  else
  {
    *a4 = a3 - v21;
  }
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v36);
  return a3 > v21;
}

void sub_21137F494(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, ...)
{
  va_start(va, a5);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)va);
  _Unwind_Resume(a1);
}

void ZinCpBasedAllocator::InitializeWorkUnit(ZinCpBasedAllocator *this)
{
  uint64_t v11[2] = *MEMORY[0x263EF8340];
  uint64_t v1 = (ZinIrOpLayer ***)*((void *)this + 40);
  uint64_t v2 = *v1;
  BOOL v3 = v1[1];
  if (*v1 != v3)
  {
    size_t v4 = &_os_log_internal;
    do
    {
      uint64_t v5 = *v2;
      if (ZinIrOpLayer::IsANELayer(*v2))
      {
        BOOL IsNELayer = ZinIrOpLayer::IsNELayer(v5);
        uint64_t v7 = *((void *)v5 + 33);
        if (IsNELayer)
        {
          unsigned int v8 = *(_DWORD *)(ZinIrOpLayer::GetInputTensor(v5, 0) + 88);
          ZinIrOpLayer::GetInputTensorDimensions(v5, &__p);
          char v9 = ZinMirL2Config::ZinMirSetWorkUnitShape(v7 + 120, (uint64_t)v5, v8);
          if (__p)
          {
            v11[0] = __p;
            operator delete(__p);
          }
          if ((v9 & 1) == 0 && os_log_type_enabled(v4, OS_LOG_TYPE_ERROR))
          {
            std::string __p = (void *)0x65904000202;
            LOWORD(v11[0]) = 2080;
            *(void *)((char *)v11 + 2) = "/Library/Caches/com.apple.xbs/Sources/ANECompiler/libs/inference/compiler/Zin"
                                           "IrSchedule/src/ZinCpBasedAllocator.cpp";
            _os_log_error_impl(&dword_210C72000, v4, OS_LOG_TYPE_ERROR, "Error: failed workunit selection, line: %d, file: %s", (uint8_t *)&__p, 0x12u);
          }
        }
        else if (!*(unsigned char *)(v7 + 256))
        {
          *(_OWORD *)(v7 + 24std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = xmmword_211ED33C0;
        }
      }
      ++v2;
    }
    while (v2 != v3);
  }
}

void sub_21137F654(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, void *__p, uint64_t a16)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinCpBasedAllocator::InitializeTileHeight(uint64_t this)
{
  uint64_t v1 = *(ZinIrOpLayer ****)(this + 320);
  uint64_t v2 = *v1;
  BOOL v3 = v1[1];
  while (v2 != v3)
  {
    size_t v4 = *v2;
    this = ZinIrOpLayer::IsANELayer(*v2);
    if (this) {
      this = ZinMirL2Config::ZinMirSetTileHeight((ZinMirL2Config *)(*((void *)v4 + 33) + 120), v4, 1);
    }
    ++v2;
  }
  return this;
}

void ZinCpBasedAllocator::InitializeEarlyAllocationDecision(ZinCpBasedAllocator *this)
{
  v43[0] = 0;
  v43[1] = 0;
  char v44 = 0;
  double v42 = v43;
  memset(v45, 0, sizeof(v45));
  int v46 = 1065353216;
  uint64_t v2 = (ZinIrRegAllocUtil **)*((void *)this + 3);
  unint64_t v39 = (char **)((char *)this + 24);
  BOOL v3 = (char *)this + 32;
  if (v2 != (ZinIrRegAllocUtil **)((char *)this + 32))
  {
    v50[0] = v2[4];
    ZinL2FootprintCalculator::GetResidentBufferSize(*((ZinL2FootprintCalculator **)this + 34), v50[0]);
    unint64_t v6 = v5;
    uint64_t v7 = (const ZinIrTensor *)*((void *)this + 42);
    if (v5 <= *((void *)v7 + 51))
    {
      uint64_t v9 = *((void *)v50[0] + 13);
      if (!v9) {
        goto LABEL_16;
      }
      int v10 = 0;
    }
    else
    {
      if (*((unsigned char *)this + 969)) {
        goto LABEL_12;
      }
      int IsChainable = ZinIrRegAllocUtil::IsChainable(v50[0], v7, v4);
      uint64_t v9 = *((void *)v50[0] + 13);
      if (!v9)
      {
        if ((IsChainable & 1) == 0) {
          goto LABEL_12;
        }
        goto LABEL_16;
      }
      int v10 = IsChainable ^ 1;
    }
    int v11 = *(_DWORD *)(v9 + 96);
    BOOL v12 = v11 != 2 && v10 == 0;
    if (!v12)
    {
LABEL_12:
      *(void *)&long long v47 = v50;
      uint64_t v13 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>>>::__emplace_unique_key_args<ZinIrTensor *,std::piecewise_construct_t const&,std::tuple<ZinIrTensor * const&>,std::tuple<>>((uint64_t)this + 280, v50, (uint64_t)&std::piecewise_construct, (void **)&v47);
      ZinIrMemoryPressureAnalyzer::AddTensorAllocation((ZinIrMemoryPressureAnalyzer *)&v42, v6, (const ZinLiveRange *)(v13 + 3), v50[0]);
    }
    if (v11 == 1)
    {
      *(void *)&long long v47 = v50;
      unint64_t v14 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>>>::__emplace_unique_key_args<ZinIrTensor *,std::piecewise_construct_t const&,std::tuple<ZinIrTensor * const&>,std::tuple<>>((uint64_t)this + 280, v50, (uint64_t)&std::piecewise_construct, (void **)&v47);
      ZinIrMemoryPressureAnalyzer::AddTensorAllocation((ZinIrMemoryPressureAnalyzer *)&v42, v6, (const ZinLiveRange *)(v14 + 3), v50[0]);
    }
LABEL_16:
    *(void *)&long long v47 = v50;
    uint64_t v15 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>>>::__emplace_unique_key_args<ZinIrTensor *,std::piecewise_construct_t const&,std::tuple<ZinIrTensor * const&>,std::tuple<>>((uint64_t)this + 280, v50, (uint64_t)&std::piecewise_construct, (void **)&v47);
    ZinIrMemoryPressureAnalyzer::AddTensorAllocation((ZinIrMemoryPressureAnalyzer *)&v42, v6, (const ZinLiveRange *)(v15 + 3), v50[0]);
  }
  unint64_t v16 = *(void *)(*((void *)this + 42) + 408);
  uint64_t v17 = (uint64_t)(*(void *)(*((void *)this + 40) + 8) - **((void **)this + 40)) >> 3;
  *(void *)&long long v47 = 0;
  *((void *)&v47 + 1) = v17;
  ZinIrMemoryPressureAnalyzer::GetTensorsBeyondBudget(&v42, v16, (uint64_t *)&v47, (uint64_t)v41);
  BOOL v18 = *v39;
  if (*v39 != v3)
  {
    do
    {
      unint64_t v40 = (ZinIrTensor *)*((void *)v18 + 4);
      if (!std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::find<ZinIrTensor *>((void *)this + 9, &v40))
      {
        std::string::size_type v23 = (ZinCpBasedAllocator *)ZinIrCircularBufferUtil::QualifyForCircularBuffer(v40, *((const ZinIrTensor **)this + 42), v19, v20);
        if (v23 && ZinCpBasedAllocator::IsBoundaryForTiledRegions(v23, v40))
        {
          v50[0] = v40;
          *(void *)&long long v47 = v50;
          *((_DWORD *)std::__hash_table<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::__unordered_map_hasher<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,true>,std::__unordered_map_equal<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::equal_to<ZinIrTensor const*>,std::hash<ZinIrTensor const*>,true>,std::allocator<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>>>::__emplace_unique_key_args<ZinIrTensor const*,std::piecewise_construct_t const&,std::tuple<ZinIrTensor const* const&>,std::tuple<>>((uint64_t)this + 72, v50, (uint64_t)&std::piecewise_construct, (void **)&v47)+ 6) = 6;
        }
        else if (std::__tree<ZinIrOpLayer *,ZinIrIdComparator<ZinIrOpLayer *>,std::allocator<ZinIrOpLayer *>>::__count_unique<ZinIrOpLayer *>((uint64_t)v41, (uint64_t *)&v40))
        {
          ZinL2FootprintCalculator::GetResidentBufferSize(*((ZinL2FootprintCalculator **)this + 34), v40);
          unint64_t v27 = v26;
          if ((*((unsigned char *)this + 969)
             || (ZinIrRegAllocUtil::IsChainable(v40, *((const ZinIrTensor **)this + 42), v25) & 1) == 0)
            && v27 > *(void *)(*((void *)this + 42) + 408))
          {
            v50[0] = v40;
            *(void *)&long long v47 = v50;
            *((_DWORD *)std::__hash_table<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::__unordered_map_hasher<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,true>,std::__unordered_map_equal<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::equal_to<ZinIrTensor const*>,std::hash<ZinIrTensor const*>,true>,std::allocator<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>>>::__emplace_unique_key_args<ZinIrTensor const*,std::piecewise_construct_t const&,std::tuple<ZinIrTensor const* const&>,std::tuple<>>((uint64_t)this + 72, v50, (uint64_t)&std::piecewise_construct, (void **)&v47)+ 6) = 1;
          }
        }
        else if (*((unsigned char *)this + 969) {
               || (ZinIrRegAllocUtil::IsChainable(v40, *((const ZinIrTensor **)this + 42), v24) & 1) == 0)
        }
        {
          v50[0] = v40;
          *(void *)&long long v47 = v50;
          *((_DWORD *)std::__hash_table<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::__unordered_map_hasher<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,true>,std::__unordered_map_equal<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::equal_to<ZinIrTensor const*>,std::hash<ZinIrTensor const*>,true>,std::allocator<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>>>::__emplace_unique_key_args<ZinIrTensor const*,std::piecewise_construct_t const&,std::tuple<ZinIrTensor const* const&>,std::tuple<>>((uint64_t)this + 72, v50, (uint64_t)&std::piecewise_construct, (void **)&v47)+ 6) = 0;
        }
      }
      unint64_t v21 = (char *)*((void *)v18 + 1);
      if (v21)
      {
        do
        {
          unint64_t v22 = v21;
          unint64_t v21 = *(char **)v21;
        }
        while (v21);
      }
      else
      {
        do
        {
          unint64_t v22 = (char *)*((void *)v18 + 2);
          BOOL v12 = *(void *)v22 == (void)v18;
          BOOL v18 = v22;
        }
        while (!v12);
      }
      BOOL v18 = v22;
    }
    while (v22 != v3);
    unint64_t v28 = *v39;
    if (*v39 != v3)
    {
      do
      {
        unint64_t v29 = (ZinIrRegAllocUtil *)*((void *)v28 + 4);
        unsigned int v30 = (void *)*((void *)v29 + 12);
        if (*(_DWORD *)(v30[8] + 8) == 7)
        {
          uint64_t v31 = (ZinIrOpLayer **)v30[11];
          unint64_t v32 = (ZinIrOpLayer **)v30[12];
          unint64_t v33 = (char *)v32 - (char *)v31;
          if ((unint64_t)((char *)v32 - (char *)v31) >= 0x80)
          {
            long long v47 = 0u;
            long long v48 = 0u;
            int v49 = 1065353216;
            if (v31 != v32)
            {
              while (1)
              {
                unint64_t v34 = *v31;
                if (*((void *)*v31 + 12) - *((void *)*v31 + 11) != 8
                  || *((void *)v34 + 15) - *((void *)v34 + 14) != 8)
                {
                  break;
                }
                v50[0] = (ZinIrRegAllocUtil *)ZinIrOpLayer::GetInputTensor(v34, 0);
                std::__hash_table<ZinIrTensor const*,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const* const&>((uint64_t)&v47, v50, v50);
                if (++v31 == v32)
                {
                  if (*((void *)&v48 + 1) != 1) {
                    break;
                  }
                  unint64_t v35 = *(void *)(*(void *)(*(void *)(v48 + 16) + 96) + 120)
                      - *(void *)(*(void *)(*(void *)(v48 + 16) + 96) + 112);
                  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&v47);
                  if (v35 >= 0xF9 && v35 > v33)
                  {
                    v50[0] = v29;
                    *(void *)&long long v47 = v50;
                    *((_DWORD *)std::__hash_table<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::__unordered_map_hasher<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,true>,std::__unordered_map_equal<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::equal_to<ZinIrTensor const*>,std::hash<ZinIrTensor const*>,true>,std::allocator<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>>>::__emplace_unique_key_args<ZinIrTensor const*,std::piecewise_construct_t const&,std::tuple<ZinIrTensor const* const&>,std::tuple<>>((uint64_t)this + 72, v50, (uint64_t)&std::piecewise_construct, (void **)&v47)+ 6) = 1;
                  }
                  goto LABEL_52;
                }
              }
            }
            std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&v47);
          }
        }
LABEL_52:
        int v37 = (char *)*((void *)v28 + 1);
        if (v37)
        {
          do
          {
            double v38 = v37;
            int v37 = *(char **)v37;
          }
          while (v37);
        }
        else
        {
          do
          {
            double v38 = (char *)*((void *)v28 + 2);
            BOOL v12 = *(void *)v38 == (void)v28;
            unint64_t v28 = v38;
          }
          while (!v12);
        }
        unint64_t v28 = v38;
      }
      while (v38 != v3);
    }
  }
  ZinCpBasedAllocatorUtil::PrintEarlyAllocationDecision((void *)this + 47, v39, (ZinCpBasedAllocator *)((char *)this + 72), *((ZinIrTensor **)this + 42));
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)v41, (void *)v41[1]);
  std::__hash_table<std::__hash_value_type<ZinIrDimension,std::set<long>>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,std::set<long>>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,std::set<long>>>>::~__hash_table((uint64_t)v45);
  std::__tree<std::unique_ptr<ZinIrMemoryPressureAnalyzer::Allocation const>,ZinIrMemoryPressureAnalyzer::PointerComparator,std::allocator<std::unique_ptr<ZinIrMemoryPressureAnalyzer::Allocation const>>>::destroy((uint64_t)&v42, v43[0]);
}

void sub_21137FC44(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, ...)
{
  va_start(va1, a4);
  va_start(va, a4);
  uint64_t v5 = va_arg(va1, void);
  uint64_t v7 = va_arg(va1, void *);
  uint64_t v8 = va_arg(va1, void);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)va, v7);
  ZinIrMemoryPressureAnalyzer::~ZinIrMemoryPressureAnalyzer((ZinIrMemoryPressureAnalyzer *)va1);
  _Unwind_Resume(a1);
}

void ZinCpBasedAllocator::AddDMABufferToPressureAnalyzer(ZinCpBasedAllocator *this, const ZinIrTensor *a2, ZinIrMemoryPressureAnalyzer *a3)
{
  ZinIrTensor::GetTensorFamily(a2, (uint64_t)&v22);
  uint64_t v5 = v22;
  unint64_t v6 = v23;
  if (v22 != v23)
  {
    do
    {
      uint64_t v7 = *(const ZinANELayer **)(*(void *)v5 + 96);
      if (ZinIrOpLayer::IsANELayer(v7)) {
        ZinCpBasedAllocator::AddOutputDMABufferToPressureAnalyzer(this, v7, a3);
      }
      v21[0] = 0;
      v21[1] = 0;
      uint64_t v20 = (uint64_t *)v21;
      uint64_t v8 = (uint64_t *)*((void *)v7 + 14);
      uint64_t v9 = (uint64_t *)*((void *)v7 + 15);
      if (v8 != v9)
      {
        do
        {
          std::__tree<ZinIrTensor *,ZinIrIdComparator<ZinIrTensor *>,std::allocator<ZinIrTensor *>>::__emplace_hint_unique_key_args<ZinIrTensor *,ZinIrTensor * const&>(&v20, v21, v8, v8);
          ++v8;
        }
        while (v8 != v9);
        int v10 = v20;
        if (v20 != (uint64_t *)v21)
        {
          do
          {
            int v11 = (const ZinANELayer *)v10[4];
            if (ZinIrOpLayer::IsANELayer(v11))
            {
              (*(void (**)(void **__return_ptr, const ZinANELayer *))(*(void *)v11 + 512))(&v18, v11);
              BOOL v12 = v18;
              uint64_t v13 = v19;
              if (v19 == v18)
              {
                BOOL v12 = v19;
                if (!v19) {
                  goto LABEL_15;
                }
              }
              else
              {
                unint64_t v14 = 0;
                do
                {
                  if (*(const ZinANELayer **)(v12[v14] + 96) == v7)
                  {
                    ZinCpBasedAllocator::AddInputDMABufferToPressureAnalyzer(this, v11, v14, a3);
                    BOOL v12 = v18;
                    uint64_t v13 = v19;
                  }
                  ++v14;
                }
                while (v14 < v13 - v12);
                if (!v12) {
                  goto LABEL_15;
                }
              }
              std::string::size_type v19 = v12;
              operator delete(v12);
            }
LABEL_15:
            uint64_t v15 = (uint64_t *)v10[1];
            if (v15)
            {
              do
              {
                unint64_t v16 = v15;
                uint64_t v15 = (uint64_t *)*v15;
              }
              while (v15);
            }
            else
            {
              do
              {
                unint64_t v16 = (uint64_t *)v10[2];
                BOOL v17 = *v16 == (void)v10;
                int v10 = v16;
              }
              while (!v17);
            }
            int v10 = v16;
          }
          while (v16 != (uint64_t *)v21);
        }
      }
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v20, v21[0]);
      v5 += 8;
    }
    while (v5 != v6);
    uint64_t v5 = v22;
  }
  if (v5)
  {
    std::string::size_type v23 = v5;
    operator delete(v5);
  }
}

void sub_21137FE70(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *a10, uint64_t a11, uint64_t a12, char a13, uint64_t a14, uint64_t a15, void *__p, uint64_t a17)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

BOOL ZinCpBasedAllocator::IsBoundaryForTiledRegions(ZinCpBasedAllocator *this, ZinIrTensor *a2)
{
  unint64_t v16 = 0;
  uint64_t v17 = 0;
  uint64_t v15 = (uint64_t *)&v16;
  ZinIrTensor::GetTensorFamily(a2, (uint64_t)&v13);
  uint64_t v2 = v13;
  BOOL v3 = v14;
  if (v13 != v14)
  {
    do
    {
      uint64_t v4 = *(void *)v2;
      uint64_t v5 = *(ZinIrOpLayer **)(*(void *)v2 + 96);
      if (ZinIrOpLayer::IsANELayer(v5) && *(unsigned char *)(v4 + 144))
      {
        uint64_t v12 = *(unsigned __int16 *)(v4 + 128);
        std::__tree<ZinIrTensor *>::__emplace_unique_key_args<ZinIrTensor *,ZinIrTensor * const&>(&v15, (unint64_t *)&v12, &v12);
      }
      unint64_t v6 = (ZinIrOpLayer **)*((void *)v5 + 14);
      uint64_t v7 = (ZinIrOpLayer **)*((void *)v5 + 15);
      while (v6 != v7)
      {
        uint64_t v8 = *v6;
        if (ZinIrOpLayer::IsANELayer(*v6)
          && *(unsigned char *)((*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)v8 + 32))(v8, 0, 0)
                      + 144))
        {
          uint64_t v9 = (*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)v8 + 32))(v8, 0, 0);
          if (!*(unsigned char *)(v9 + 144)) {
            std::__throw_bad_optional_access[abi:ne180100]();
          }
          uint64_t v12 = *(unsigned __int16 *)(v9 + 128);
          std::__tree<ZinIrTensor *>::__emplace_unique_key_args<ZinIrTensor *,ZinIrTensor * const&>(&v15, (unint64_t *)&v12, &v12);
        }
        ++v6;
      }
      v2 += 8;
    }
    while (v2 != v3);
    uint64_t v2 = v13;
  }
  if (v2)
  {
    unint64_t v14 = v2;
    operator delete(v2);
  }
  BOOL v10 = v17 != 0;
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v15, v16);
  return v10;
}

void sub_211380040(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, void *__p, uint64_t a12, uint64_t a13, char a14, void *a15)
{
}

uint64_t ZinCpBasedAllocator::NeedSplitForInplaceAllocation(ZinCpBasedAllocator *this, ZinIrOpLayer *a2)
{
  if (!a2) {
    return 0;
  }
  uint64_t v4 = (const ZinIrOpLayerGraph *)*((void *)a2 + 19);
  uint64_t v5 = (ZinIrTensor *)(*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)a2 + 32))(a2, 0, 0);
  ZinIrTensor::GetTensorSizeInBytes(v5);
  unint64_t v7 = v6;
  if (*((unsigned char *)this + 1152))
  {
    uint64_t v8 = (const ZinIrTensor *)(*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)a2 + 32))(a2, 0, 0);
    ZinTensorFamilyUtil::GetLastReadUsage((ZinCpBasedAllocator *)((char *)this + 1048), v8, v23);
    if (v24)
    {
      LastConsumer = (const ZinANELayer *)v23[0];
      if (v23[0]) {
        goto LABEL_5;
      }
    }
LABEL_8:
    int v11 = 0;
    BOOL v10 = 0;
    goto LABEL_9;
  }
  uint64_t v13 = (ZinIrRegAllocUtil *)(*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)a2 + 32))(a2, 0, 0);
  LastConsumer = (const ZinANELayer *)ZinIrRegAllocUtil::GetLastConsumer(v13, v14);
  if (!LastConsumer) {
    goto LABEL_8;
  }
LABEL_5:
  ZinIrInPlaceUpdate::IsInPlaceable(*((ZinIrTensor **)this + 127), LastConsumer, v4, 2, *(unsigned char *)(*((void *)this + 42) + 1115), v23);
  BOOL v10 = v23[0];
  int v11 = v23[1];
LABEL_9:
  if (!ZinIrOpLayer::IsPELayer(a2)
    || (v15 = *((void *)a2 + 11), uint64_t v16 = *((void *)a2 + 12), (unint64_t)(v16 - v15) < 9))
  {
LABEL_15:
    uint64_t v12 = 0;
    goto LABEL_16;
  }
  uint64_t v12 = 0;
  if (*((void *)a2 + 15) - *((void *)a2 + 14) >= 9uLL && v11 != v10)
  {
    if (v7 >= *((void *)this + 45) && v7 <= *((void *)this + 46))
    {
      if (v15 == v16)
      {
        uint64_t v12 = 1;
      }
      else
      {
        uint64_t v18 = v15 + 8;
        do
        {
          std::string::size_type v19 = (const ZinIrTensor *)(*(uint64_t (**)(void, void, void))(**(void **)(v18 - 8) + 32))(*(void *)(v18 - 8), 0, 0);
          uint64_t RootTensor = (ZinIrTensor *)ZinTensorFamilyUtil::GetRootTensor((ZinCpBasedAllocator *)((char *)this + 1048), v19);
          int IsPipelinable = ZinIrRegAllocUtil::IsPipelinable(RootTensor, *((const ZinIrTensor **)this + 42), (ZinCpBasedAllocator *)((char *)this + 1048));
          if (v18 == v16) {
            char v22 = 1;
          }
          else {
            char v22 = IsPipelinable;
          }
          v18 += 8;
        }
        while ((v22 & 1) == 0);
        uint64_t v12 = IsPipelinable ^ 1u;
      }
      goto LABEL_16;
    }
    goto LABEL_15;
  }
LABEL_16:
  if (v10) {
    operator delete(v10);
  }
  return v12;
}

void sub_2113802AC(_Unwind_Exception *exception_object)
{
  if (v1) {
    operator delete(v1);
  }
  _Unwind_Resume(exception_object);
}

void ZinCpBasedAllocator::GetEarlyAllocationDecision(ZinCpBasedAllocator *this, const ZinANELayer *a2, BOOL *a3, BOOL *a4)
{
  *a3 = 1;
  (*(void (**)(void **__return_ptr, const ZinANELayer *))(*(void *)a2 + 512))(&__p, a2);
  uint64_t v8 = (const ZinIrTensor **)__p;
  if (v16 != __p)
  {
    unint64_t v9 = 0;
    while (1)
    {
      uint64_t RootTensor = 0;
      uint64_t RootTensor = ZinTensorFamilyUtil::GetRootTensor((ZinCpBasedAllocator *)((char *)this + 1048), v8[v9]);
      BOOL v10 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)this + 9, &RootTensor);
      if (!v10 || *((_DWORD *)v10 + 6)) {
        break;
      }
      ++v9;
      uint64_t v8 = (const ZinIrTensor **)__p;
      if (v9 >= (v16 - (unsigned char *)__p) >> 3) {
        goto LABEL_8;
      }
    }
    *a3 = 0;
  }
LABEL_8:
  int v11 = (const ZinIrTensor *)(*(uint64_t (**)(const ZinANELayer *, void, void))(*(void *)a2 + 32))(a2, 0, 0);
  uint64_t RootTensor = ZinTensorFamilyUtil::GetRootTensor((ZinCpBasedAllocator *)((char *)this + 1048), v11);
  uint64_t v12 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)this + 9, &RootTensor);
  if (v12) {
    BOOL v13 = *((_DWORD *)v12 + 6) == 0;
  }
  else {
    BOOL v13 = 0;
  }
  *a4 = v13;
  if (__p)
  {
    uint64_t v16 = __p;
    operator delete(__p);
  }
}

void sub_211380428(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

void *ZinCpBasedAllocator::RemoveDMABufferFromPressureAnalyzer(ZinCpBasedAllocator *this, const ZinANELayer *a2, ZinIrMemoryPressureAnalyzer *a3)
{
  for (unint64_t i = 0; ; ++i)
  {
    (*(void (**)(unsigned char **__return_ptr, const ZinANELayer *))(*(void *)a2 + 512))(&v10, a2);
    unint64_t v7 = v10;
    uint64_t v8 = v11;
    if (v10)
    {
      int v11 = v10;
      operator delete(v10);
    }
    if (i >= (v8 - v7) >> 3) {
      break;
    }
    ZinCpBasedAllocator::RemoveInputDMABufferFromPressureAnalyzer(this, a2, i, a3);
  }
  return ZinCpBasedAllocator::RemoveOutputDMABufferFromPressureAnalyzer(this, a2, a3);
}

void *ZinCpBasedAllocator::AddDMABufferToPressureAnalyzer(ZinCpBasedAllocator *this, const ZinANELayer *a2, ZinIrMemoryPressureAnalyzer *a3)
{
  for (unint64_t i = 0; ; ++i)
  {
    (*(void (**)(unsigned char **__return_ptr, const ZinANELayer *))(*(void *)a2 + 512))(&v10, a2);
    unint64_t v7 = v10;
    uint64_t v8 = v11;
    if (v10)
    {
      int v11 = v10;
      operator delete(v10);
    }
    if (i >= (v8 - v7) >> 3) {
      break;
    }
    ZinCpBasedAllocator::AddInputDMABufferToPressureAnalyzer(this, a2, i, a3);
  }
  return ZinCpBasedAllocator::AddOutputDMABufferToPressureAnalyzer(this, a2, a3);
}

void ZinCpBasedAllocator::AddL2BufferToPressureAnalyzer(ZinCpBasedAllocator *this, ZinIrTensor *a2, ZinIrMemoryPressureAnalyzer *a3)
{
  BOOL v10 = a2;
  uint64_t v5 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)this + 9, &v10);
  if (v5 && !*((_DWORD *)v5 + 6))
  {
    unint64_t v6 = (ZinIrOpLayer *)*((void *)v10 + 12);
    if (ZinIrOpLayer::IsANELayer(v6))
    {
      int v11 = v6;
      unint64_t v7 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)this + 14, &v11);
      if (v7) {
        unint64_t v8 = *(void *)(*(void *)(v7[3] + 32) + 8);
      }
      else {
        unint64_t v8 = 0;
      }
      unint64_t v9 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)this + 35, &v10);
      if (v9) {
        ZinIrMemoryPressureAnalyzer::AddTensorAllocation(a3, v8, (const ZinLiveRange *)(v9 + 3), v10);
      }
      ZinAssertImpl("Liverange must exist.");
    }
    ZinAssertImpl("Producer must be engine layer.");
  }
  ZinAssertImpl("Allocation decision must exist.");
}

uint64_t ZinCpBasedAllocator::IsDisqualifiedForParallelExecution(ZinCpBasedAllocator *this, ZinANELayer *a2, ZinANELayer *a3)
{
  uint64_t v3 = *((void *)a2 + 45);
  uint64_t v4 = *((void *)a3 + 45);
  BOOL v5 = v3 == -1 || v4 == -1;
  if (v5 || v4 - v3 != 1) {
    return 1;
  }
  BOOL IsNELayer = ZinIrOpLayer::IsNELayer(a2);
  if (IsNELayer == ZinIrOpLayer::IsNELayer(a3)) {
    return 1;
  }
  int v11 = (const ZinIrTensor *)(*(uint64_t (**)(ZinANELayer *, void, void))(*(void *)a2 + 32))(a2, 0, 0);
  uint64_t RootTensor = (ZinIrTensor *)ZinTensorFamilyUtil::GetRootTensor((ZinCpBasedAllocator *)((char *)this + 1048), v11);
  int v46 = RootTensor;
  BOOL v13 = (const ZinIrTensor *)(*(uint64_t (**)(ZinANELayer *, void, void))(*(void *)a3 + 32))(a3, 0, 0);
  uint64_t v45 = (ZinIrTensor *)ZinTensorFamilyUtil::GetRootTensor((ZinCpBasedAllocator *)((char *)this + 1048), v13);
  unint64_t v14 = (void *)*((void *)a3 + 11);
  uint64_t v15 = (void *)*((void *)a3 + 12);
  while (v14 != v15)
  {
    uint64_t v16 = (const ZinIrTensor *)(*(uint64_t (**)(void, void, void))(*(void *)*v14 + 32))(*v14, 0, 0);
    if (RootTensor == (ZinIrTensor *)ZinTensorFamilyUtil::GetRootTensor((ZinCpBasedAllocator *)((char *)this + 1048), v16))return 1; {
    ++v14;
    }
  }
  uint64_t v17 = (uint64_t *)*((void *)a2 + 11);
  uint64_t v18 = (uint64_t *)*((void *)a2 + 12);
  if (v17 != v18)
  {
    while (1)
    {
      uint64_t v19 = *v17;
      uint64_t v47 = 0;
      uint64_t v20 = (const ZinIrTensor *)(*(uint64_t (**)(uint64_t, void, void))(*(void *)v19 + 32))(v19, 0, 0);
      uint64_t v47 = ZinTensorFamilyUtil::GetRootTensor((ZinCpBasedAllocator *)((char *)this + 1048), v20);
      unint64_t v21 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)this + 9, &v47);
      if (!v21) {
        break;
      }
      unsigned int v22 = *((_DWORD *)v21 + 6);
      if ((CpAllocUtils::IsL2Dependent(v22) & 1) != 0 || CpAllocUtils::IsChain(v22)) {
        return 1;
      }
      if (++v17 == v18) {
        goto LABEL_19;
      }
    }
LABEL_47:
    std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
  }
LABEL_19:
  std::string::size_type v23 = (const ZinIrTensor *)(*(uint64_t (**)(ZinANELayer *, void, void))(*(void *)a3 + 32))(a3, 0, 0);
  uint64_t v44 = ZinTensorFamilyUtil::GetRootTensor((ZinCpBasedAllocator *)((char *)this + 1048), v23);
  char v24 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)this + 9, &v44);
  if (!v24) {
    goto LABEL_47;
  }
  unsigned int v25 = *((_DWORD *)v24 + 6);
  if ((CpAllocUtils::IsL2Dependent(v25) & 1) != 0 || CpAllocUtils::IsChain(v25)) {
    return 1;
  }
  unint64_t v27 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)this + 9, &v46);
  if (!v27) {
    goto LABEL_47;
  }
  int v28 = *((_DWORD *)v27 + 6);
  unint64_t v29 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)this + 9, &v45);
  if (!v29) {
    goto LABEL_47;
  }
  int v30 = *((_DWORD *)v29 + 6);
  if (CpAllocUtils::IsNonResident(v28) && CpAllocUtils::IsNonResident(v30)) {
    return 1;
  }
  uint64_t v31 = *((void *)a2 + 11);
  uint64_t v32 = *((void *)a2 + 12);
  if (v31 == v32)
  {
    int v37 = 1;
  }
  else
  {
    uint64_t v33 = v31 + 8;
    do
    {
      unint64_t v34 = (const ZinIrTensor *)(*(uint64_t (**)(void, void, void))(**(void **)(v33 - 8) + 32))(*(void *)(v33 - 8), 0, 0);
      uint64_t v47 = ZinTensorFamilyUtil::GetRootTensor((ZinCpBasedAllocator *)((char *)this + 1048), v34);
      unint64_t v35 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)this + 9, &v47);
      if (!v35) {
        goto LABEL_47;
      }
      BOOL IsNonResident = CpAllocUtils::IsNonResident(*((_DWORD *)v35 + 6));
      if (IsNonResident) {
        break;
      }
      BOOL v5 = v33 == v32;
      v33 += 8;
    }
    while (!v5);
    int v37 = !IsNonResident;
  }
  unint64_t v39 = (void *)*((void *)a3 + 11);
  double v38 = (void *)*((void *)a3 + 12);
  while (v39 != v38)
  {
    unint64_t v40 = (const ZinIrTensor *)(*(uint64_t (**)(void, void, void))(*(void *)*v39 + 32))(*v39, 0, 0);
    uint64_t v47 = ZinTensorFamilyUtil::GetRootTensor((ZinCpBasedAllocator *)((char *)this + 1048), v40);
    long long v41 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)this + 9, &v47);
    if (!v41) {
      goto LABEL_47;
    }
    if (CpAllocUtils::IsNonResident(*((_DWORD *)v41 + 6)))
    {
      if (!v37) {
        return 1;
      }
      break;
    }
    ++v39;
  }
  if (CpAllocUtils::IsResident(v30))
  {
    ZinL2FootprintCalculator::GetResidentBufferSize(*((ZinL2FootprintCalculator **)this + 34), v45);
    if ((double)*(unint64_t *)(*((void *)this + 42) + 408) * 0.5 < (double)v42) {
      return 1;
    }
  }
  if (CpAllocUtils::IsResident(v28)
    && (ZinL2FootprintCalculator::GetResidentBufferSize(*((ZinL2FootprintCalculator **)this + 34), v46),
        (double)*(unint64_t *)(*((void *)this + 42) + 408) * 0.5 < (double)v43))
  {
    return 1;
  }
  else
  {
    return 0;
  }
}

uint64_t ZinCpBasedAllocator::PromoteDecisionToInplace(ZinCpBasedAllocator *this, ZinIrTensor *a2)
{
  unint64_t v7 = a2;
  uint64_t v2 = (char *)this + 72;
  unint64_t v9 = &v7;
  unsigned int v3 = *((_DWORD *)std::__hash_table<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::__unordered_map_hasher<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,true>,std::__unordered_map_equal<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::equal_to<ZinIrTensor const*>,std::hash<ZinIrTensor const*>,true>,std::allocator<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>>>::__emplace_unique_key_args<ZinIrTensor const*,std::piecewise_construct_t const&,std::tuple<ZinIrTensor const* const&>,std::tuple<>>((uint64_t)this + 72, &v7, (uint64_t)&std::piecewise_construct, &v9)+ 6);
  if (v3 < 2)
  {
    unint64_t v8 = v7;
    unint64_t v9 = &v8;
    uint64_t v4 = std::__hash_table<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::__unordered_map_hasher<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,true>,std::__unordered_map_equal<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::equal_to<ZinIrTensor const*>,std::hash<ZinIrTensor const*>,true>,std::allocator<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>>>::__emplace_unique_key_args<ZinIrTensor const*,std::piecewise_construct_t const&,std::tuple<ZinIrTensor const* const&>,std::tuple<>>((uint64_t)v2, &v8, (uint64_t)&std::piecewise_construct, &v9);
    int v5 = 4;
    goto LABEL_6;
  }
  if (v3 == 4) {
    return 1;
  }
  if (v3 == 3)
  {
    unint64_t v8 = v7;
    unint64_t v9 = &v8;
    uint64_t v4 = std::__hash_table<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::__unordered_map_hasher<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,true>,std::__unordered_map_equal<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::equal_to<ZinIrTensor const*>,std::hash<ZinIrTensor const*>,true>,std::allocator<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>>>::__emplace_unique_key_args<ZinIrTensor const*,std::piecewise_construct_t const&,std::tuple<ZinIrTensor const* const&>,std::tuple<>>((uint64_t)v2, &v8, (uint64_t)&std::piecewise_construct, &v9);
    int v5 = 5;
LABEL_6:
    *((_DWORD *)v4 + 6) = v5;
    return 1;
  }
  return 0;
}

void ZinCpBasedAllocator::GetSortedNonResidentTensors(ZinCpBasedAllocator *this@<X0>, void *a2@<X8>)
{
  *a2 = 0;
  a2[1] = 0;
  a2[2] = 0;
  unsigned int v3 = (ZinCpBasedAllocator *)((char *)this + 1048);
  uint64_t v4 = *(void **)ZinTensorFamilyUtil::GetRootTensors((ZinCpBasedAllocator *)((char *)this + 1048));
  uint64_t RootTensors = ZinTensorFamilyUtil::GetRootTensors(v3);
  std::vector<ZinIrSymbol *>::vector<std::__tree_const_iterator<ZinIrSymbol *,std::__tree_node<ZinIrSymbol *,void *> *,long>,0>(&v25, v4, (void *)(RootTensors + 8));
  unint64_t v6 = v25;
  *a2 = v25;
  unint64_t v7 = (unint64_t *)v26;
  unint64_t v21 = (unint64_t *)v6;
  *(_OWORD *)(a2 + 1) = v26;
  long long v26 = 0uLL;
  unsigned int v25 = (uint64_t *)&v26;
  unint64_t v8 = v7;
  if (v6 != (uint64_t *)v7)
  {
    for (unint64_t i = (ZinIrTensor **)v6; i != (ZinIrTensor **)v8; ++i)
    {
      char v24 = *i;
      ZinIrTensor::GetTensorFamily(v24, (uint64_t)&__p);
      BOOL v10 = (char *)__p;
      int v11 = v23;
      if (__p == v23)
      {
        uint64_t v12 = 0;
        if (!__p) {
          goto LABEL_14;
        }
      }
      else
      {
        uint64_t v12 = 0;
        do
        {
          uint64_t v13 = *(void *)v10;
          unint64_t v14 = *(void **)(*(void *)v10 + 96);
          uint64_t v15 = (ZinIrOpLayer **)v14[14];
          uint64_t v16 = (ZinIrOpLayer **)v14[15];
          if (v15 != v16)
          {
            do
              v12 += ZinIrOpLayer::IsANELayer(*v15++);
            while (v15 != v16);
            unint64_t v14 = *(void **)(v13 + 96);
          }
          uint64_t v17 = (ZinIrOpLayer **)v14[11];
          uint64_t v18 = (ZinIrOpLayer **)v14[12];
          while (v17 != v18)
            v12 += ZinIrOpLayer::IsANELayer(*v17++);
          v10 += 8;
        }
        while (v10 != v11);
        BOOL v10 = (char *)__p;
        if (!__p) {
          goto LABEL_14;
        }
      }
      std::string::size_type v23 = v10;
      operator delete(v10);
LABEL_14:
      std::string __p = &v24;
      std::__tree<std::__value_type<unsigned long,ZinIrOpLayer *>,std::__map_value_compare<unsigned long,std::__value_type<unsigned long,ZinIrOpLayer *>,std::less<unsigned long>,true>,std::allocator<std::__value_type<unsigned long,ZinIrOpLayer *>>>::__emplace_unique_key_args<unsigned long,std::piecewise_construct_t const&,std::tuple<unsigned long const&>,std::tuple<>>(&v25, (unint64_t *)&v24, (uint64_t)&std::piecewise_construct, (uint64_t **)&__p)[5] = v12;
    }
  }
  unint64_t v19 = 126 - 2 * __clz(v8 - v21);
  std::string __p = &v25;
  if (v8 == v21) {
    uint64_t v20 = 0;
  }
  else {
    uint64_t v20 = v19;
  }
  std::__introsort<std::_ClassicAlgPolicy,ZinCpBasedAllocator::GetSortedNonResidentTensors(void)::$_0 &,ZinIrTensor **,false>(v21, v8, &__p, v20, 1);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v25, (void *)v26);
}

void sub_211380D7C(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, void *a11, uint64_t a12, uint64_t a13, uint64_t a14, char a15, void *a16)
{
  if (__p)
  {
    *(void *)(a9 + 8) = __p;
    operator delete(__p);
  }
  _Unwind_Resume(a1);
}

uint64_t ZinCpBasedAllocator::TryInplaceAllocationWithProducer(ZinIrTensor **this, ZinIrTensor *a2, ZinIrMemoryPressureAnalyzer *a3)
{
  unint64_t v63 = a2;
  uint64_t v4 = *((void *)a2 + 12);
  ZinIrInPlaceUpdate::IsInPlaceable(this[127], (const ZinANELayer *)v4, *(const ZinIrOpLayerGraph **)(v4 + 152), 2, *((unsigned char *)this[42] + 1115), &v61);
  unint64_t v6 = v61;
  int v5 = v62;
  if (v62 == v61)
  {
    if (!v61) {
      return 0;
    }
    goto LABEL_44;
  }
  unint64_t v7 = (ZinTensorFamilyUtil *)(this + 131);
  uint64_t v47 = this;
  unint64_t v8 = this + 9;
  unint64_t v49 = -1;
  do
  {
    unint64_t v9 = *v6;
    uint64_t InputTensor = ZinIrOpLayer::GetInputTensor((ZinIrOpLayer *)v4, *v6);
    std::string __p = 0;
    std::string __p = (void *)ZinTensorFamilyUtil::GetRootTensor(v7, (const ZinIrTensor *)InputTensor);
    v58[0] = &__p;
    unsigned int v11 = *((_DWORD *)std::__hash_table<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::__unordered_map_hasher<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,true>,std::__unordered_map_equal<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::equal_to<ZinIrTensor const*>,std::hash<ZinIrTensor const*>,true>,std::allocator<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>>>::__emplace_unique_key_args<ZinIrTensor const*,std::piecewise_construct_t const&,std::tuple<ZinIrTensor const* const&>,std::tuple<>>((uint64_t)v8, &__p, (uint64_t)&std::piecewise_construct, (void **)v58)+ 6);
    if (CpAllocUtils::IsL2Inplace(v11)) {
      goto LABEL_43;
    }
    long long v12 = *(_OWORD *)(InputTensor + 64);
    *(_OWORD *)int v58 = *(_OWORD *)(InputTensor + 48);
    long long v59 = v12;
    uint64_t v60 = *(void *)(InputTensor + 80);
    long long v13 = *((_OWORD *)v63 + 4);
    *(_OWORD *)long long v55 = *((_OWORD *)v63 + 3);
    long long v56 = v13;
    uint64_t v57 = *((void *)v63 + 10);
    if (ZinTensorDimensionsEqual(v58, v55) && CpAllocUtils::IsNonChainResident(v11))
    {
      BOOL IsL2Inplace = CpAllocUtils::IsL2Inplace(v11);
      unint64_t v15 = v49;
      if (!IsL2Inplace) {
        unint64_t v15 = v9;
      }
      unint64_t v49 = v15;
    }
    ++v6;
  }
  while (v6 != v5);
  if (v49 != -1)
  {
    uint64_t v16 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::find<ZinIrTensor *>(v8, &v63);
    uint64_t v17 = v47;
    if (!v16) {
      ZinAssertImpl("The decision is missing.");
    }
    BOOL IsResident = CpAllocUtils::IsResident(*((_DWORD *)v16 + 6));
    v58[0] = &v63;
    long long v54 = *(_OWORD *)(std::__hash_table<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>>>::__emplace_unique_key_args<ZinIrTensor *,std::piecewise_construct_t const&,std::tuple<ZinIrTensor * const&>,std::tuple<>>((uint64_t)(v47 + 35), &v63, (uint64_t)&std::piecewise_construct, (void **)v58)+ 3);
    ZinIrMemoryPressureAnalyzer::GetPeakPressure(a3, (const ZinLiveRange *)&v54);
    if (IsResident) {
      ZinIrMemoryPressureAnalyzer::RemoveTensorAllocation(a3, v63, (const ZinLiveRange *)&v54);
    }
    ZinCpBasedAllocator::RemoveDMABufferFromPressureAnalyzer((ZinCpBasedAllocator *)v47, v63, a3);
    long long v53 = v54;
    *(void *)&long long v53 = *(void *)(v4 + 48) + *(void *)(v4 + 56) + 1;
    LastConsumer = (ZinIrOpLayer *)ZinIrRegAllocUtil::GetLastConsumer(v63, v19);
    unint64_t v21 = (ZinIrOpLayerGraph *)*((void *)LastConsumer + 19);
    uint64_t IndexOfMatchedIncomingLayer = ZinIrOpLayerGraph::GetIndexOfMatchedIncomingLayer(v21, LastConsumer, (const ZinIrOpLayer *)v4);
    ZinIrInPlaceUpdate::IsInPlaceable(v47[127], LastConsumer, v21, 2, *((unsigned char *)v47[42] + 1115), (unint64_t **)&__p);
    uint64_t v23 = *((void *)LastConsumer + 11);
    uint64_t v24 = *((void *)LastConsumer + 12);
    if (v23 == v24)
    {
      int v31 = 1;
    }
    else
    {
      uint64_t v25 = v23 + 8;
      do
      {
        uint64_t v26 = *(void *)(v25 - 8);
        v55[0] = 0;
        unint64_t v27 = (const ZinIrTensor *)(*(uint64_t (**)(uint64_t, void, void))(*(void *)v26 + 32))(v26, 0, 0);
        v55[0] = (void *)ZinTensorFamilyUtil::GetRootTensor(v7, v27);
        v58[0] = v55;
        int v28 = std::__hash_table<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::__unordered_map_hasher<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,true>,std::__unordered_map_equal<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::equal_to<ZinIrTensor const*>,std::hash<ZinIrTensor const*>,true>,std::allocator<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>>>::__emplace_unique_key_args<ZinIrTensor const*,std::piecewise_construct_t const&,std::tuple<ZinIrTensor const* const&>,std::tuple<>>((uint64_t)v8, v55, (uint64_t)&std::piecewise_construct, (void **)v58);
        BOOL v29 = CpAllocUtils::IsL2Inplace(*((_DWORD *)v28 + 6));
        char v30 = v25 == v24 || v29;
        v25 += 8;
      }
      while ((v30 & 1) == 0);
      int v31 = !v29;
      uint64_t v17 = v47;
    }
    uint64_t RootTensor = 0;
    uint64_t v32 = (const ZinIrTensor *)(*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)LastConsumer + 32))(LastConsumer, 0, 0);
    uint64_t RootTensor = (ZinIrTensor *)ZinTensorFamilyUtil::GetRootTensor(v7, v32);
    v58[0] = &RootTensor;
    uint64_t v33 = std::__hash_table<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::__unordered_map_hasher<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,true>,std::__unordered_map_equal<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::equal_to<ZinIrTensor const*>,std::hash<ZinIrTensor const*>,true>,std::allocator<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>>>::__emplace_unique_key_args<ZinIrTensor const*,std::piecewise_construct_t const&,std::tuple<ZinIrTensor const* const&>,std::tuple<>>((uint64_t)v8, &RootTensor, (uint64_t)&std::piecewise_construct, (void **)v58);
    unint64_t v34 = __p;
    if (__p != v52)
    {
      do
      {
        if (*v34 == IndexOfMatchedIncomingLayer) {
          goto LABEL_29;
        }
        ++v34;
      }
      while (v34 != v52);
      unint64_t v34 = v52;
    }
LABEL_29:
    if (v34 == v52 || (v31 & CpAllocUtils::IsNonChainResident(*((_DWORD *)v33 + 6))) != 1)
    {
LABEL_42:
      ZinL2FootprintCalculator::GetResidentBufferSize(v17[34], v63);
      ZinIrMemoryPressureAnalyzer::AddTensorAllocation(a3, v45, (const ZinLiveRange *)&v53, v63);
    }
    unint64_t v35 = (const ZinIrTensor *)ZinIrOpLayer::GetInputTensor((ZinIrOpLayer *)v4, v49);
    double v36 = (ZinIrTensor *)ZinTensorFamilyUtil::GetRootTensor(v7, v35);
    ZinIrTensor::GetDimensionOrderHint(v36, (uint64_t)v58);
    ZinIrTensor::GetDimensionOrderHint(RootTensor, (uint64_t)v55);
    if (DimensionOrderHint::IsSet((DimensionOrderHint *)v58))
    {
      BOOL IsSet = DimensionOrderHint::IsSet((DimensionOrderHint *)v55);
      double v38 = v55[0];
      if (IsSet)
      {
        if ((char *)v55[1] - (char *)v55[0] != (char *)v58[1] - (char *)v58[0])
        {
          BOOL v43 = 0;
          goto LABEL_49;
        }
        if (v55[0] != v55[1])
        {
          uint64_t v39 = 0;
          do
          {
            unint64_t v40 = (char *)v55[0] + v39 + 4;
            int v41 = *(_DWORD *)((char *)v55[0] + v39);
            int v42 = *(_DWORD *)((char *)v58[0] + v39);
            BOOL v43 = v41 == v42;
            v39 += 4;
          }
          while (v41 == v42 && v40 != v55[1]);
          goto LABEL_49;
        }
      }
      BOOL v43 = 1;
    }
    else
    {
      BOOL v43 = 1;
      double v38 = v55[0];
    }
LABEL_49:
    if (v38)
    {
      v55[1] = v38;
      operator delete(v38);
    }
    if (v58[0])
    {
      v58[1] = v58[0];
      operator delete(v58[0]);
    }
    if (v43) {
      *((void *)&v53 + 1) = *((void *)LastConsumer + 6) - 1;
    }
    goto LABEL_42;
  }
LABEL_43:
  unint64_t v6 = v61;
  if (v61)
  {
LABEL_44:
    long long v62 = v6;
    operator delete(v6);
  }
  return 0;
}

void sub_21138158C(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, void *__p, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,void *a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,void *a31,void *a32)
{
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&a31, a32);
  if (__p) {
    operator delete(__p);
  }
  unint64_t v34 = *(void **)(v32 - 136);
  if (v34)
  {
    *(void *)(v32 - 128) = v34;
    operator delete(v34);
  }
  _Unwind_Resume(a1);
}

void ZinCpBasedAllocator::RemoveDMABufferFromPressureAnalyzer(ZinCpBasedAllocator *this, const ZinIrTensor *a2, ZinIrMemoryPressureAnalyzer *a3)
{
  ZinIrTensor::GetTensorFamily(a2, (uint64_t)&v22);
  int v5 = v22;
  unint64_t v6 = v23;
  if (v22 != v23)
  {
    do
    {
      unint64_t v7 = *(const ZinANELayer **)(*(void *)v5 + 96);
      if (ZinIrOpLayer::IsANELayer(v7)) {
        ZinCpBasedAllocator::RemoveOutputDMABufferFromPressureAnalyzer(this, v7, a3);
      }
      v21[0] = 0;
      v21[1] = 0;
      uint64_t v20 = (uint64_t *)v21;
      unint64_t v8 = (uint64_t *)*((void *)v7 + 14);
      unint64_t v9 = (uint64_t *)*((void *)v7 + 15);
      if (v8 != v9)
      {
        do
        {
          std::__tree<ZinIrTensor *,ZinIrIdComparator<ZinIrTensor *>,std::allocator<ZinIrTensor *>>::__emplace_hint_unique_key_args<ZinIrTensor *,ZinIrTensor * const&>(&v20, v21, v8, v8);
          ++v8;
        }
        while (v8 != v9);
        BOOL v10 = v20;
        if (v20 != (uint64_t *)v21)
        {
          do
          {
            unsigned int v11 = (const ZinANELayer *)v10[4];
            if (ZinIrOpLayer::IsANELayer(v11))
            {
              (*(void (**)(void **__return_ptr, const ZinANELayer *))(*(void *)v11 + 512))(&v18, v11);
              long long v12 = v18;
              long long v13 = v19;
              if (v19 == v18)
              {
                long long v12 = v19;
                if (!v19) {
                  goto LABEL_15;
                }
              }
              else
              {
                unint64_t v14 = 0;
                do
                {
                  if (*(const ZinANELayer **)(v12[v14] + 96) == v7)
                  {
                    ZinCpBasedAllocator::RemoveInputDMABufferFromPressureAnalyzer(this, v11, v14, a3);
                    long long v12 = v18;
                    long long v13 = v19;
                  }
                  ++v14;
                }
                while (v14 < v13 - v12);
                if (!v12) {
                  goto LABEL_15;
                }
              }
              unint64_t v19 = v12;
              operator delete(v12);
            }
LABEL_15:
            unint64_t v15 = (uint64_t *)v10[1];
            if (v15)
            {
              do
              {
                uint64_t v16 = v15;
                unint64_t v15 = (uint64_t *)*v15;
              }
              while (v15);
            }
            else
            {
              do
              {
                uint64_t v16 = (uint64_t *)v10[2];
                BOOL v17 = *v16 == (void)v10;
                BOOL v10 = v16;
              }
              while (!v17);
            }
            BOOL v10 = v16;
          }
          while (v16 != (uint64_t *)v21);
        }
      }
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v20, v21[0]);
      v5 += 8;
    }
    while (v5 != v6);
    int v5 = v22;
  }
  if (v5)
  {
    uint64_t v23 = v5;
    operator delete(v5);
  }
}

void sub_211381838(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *a10, uint64_t a11, uint64_t a12, char a13, uint64_t a14, uint64_t a15, void *__p, uint64_t a17)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinCpBasedAllocator::PromoteToInplace(ZinIrTensor **this, ZinIrTensor *a2, ZinIrMemoryPressureAnalyzer *a3)
{
  if (ZinCpBasedAllocator::TryInplaceAllocationWithProducer(this, a2, a3)) {
    return 1;
  }

  return ZinCpBasedAllocator::TryInplaceAllocationWithConsumer((ZinCpBasedAllocator *)this, a2, a3);
}

uint64_t ZinCpBasedAllocator::TryInplaceAllocationWithConsumer(ZinCpBasedAllocator *this, ZinIrTensor *a2, ZinIrMemoryPressureAnalyzer *a3)
{
  uint64_t v32 = a2;
  unint64_t v6 = (ZinCpBasedAllocator *)((char *)this + 1048);
  if ((ZinIrTensor *)ZinTensorFamilyUtil::GetRootTensor((ZinCpBasedAllocator *)((char *)this + 1048), a2) != a2) {
    return 0;
  }
  uint64_t LastConsumer = ZinIrRegAllocUtil::GetLastConsumer(a2, v7);
  if (!LastConsumer) {
    return LastConsumer;
  }
  BOOL v10 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::find<ZinIrTensor *>((void *)this + 9, &v32);
  if (!v10
    || (BOOL IsResident = CpAllocUtils::IsResident(*((_DWORD *)v10 + 6)),
        uint64_t RootTensor = 0,
        v12 = (const ZinIrTensor *)(*(uint64_t (**)(uint64_t, void, void))(*(void *)LastConsumer + 32))(LastConsumer, 0, 0), RootTensor = ZinTensorFamilyUtil::GetRootTensor(v6, v12), (long long v13 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::find<ZinIrTensor *>((void *)this + 9, &RootTensor)) == 0))
  {
    ZinAssertImpl("The decision is missing.");
  }
  unint64_t v14 = v13;
  if (!CpAllocUtils::IsResident(*((_DWORD *)v13 + 6))) {
    return 0;
  }
  CpAllocUtils::IsChain(*((_DWORD *)v14 + 6));
  ZinIrInPlaceUpdate::IsInPlaceable(*((ZinIrTensor **)this + 127), (const ZinANELayer *)LastConsumer, *(const ZinIrOpLayerGraph **)(LastConsumer + 152), 2, *(unsigned char *)(*((void *)this + 42) + 1115), &v29);
  unint64_t v15 = v29;
  uint64_t v16 = v30;
  if (v30 == v29)
  {
    uint64_t LastConsumer = 0;
  }
  else
  {
    uint64_t v24 = a3;
    uint64_t v17 = -1;
    while (1)
    {
      unint64_t v18 = *v15;
      uint64_t v19 = *(void *)(*(void *)(LastConsumer + 88) + 8 * *v15);
      v25[0] = 0;
      uint64_t v20 = (const ZinIrTensor *)(*(uint64_t (**)(uint64_t, void, void))(*(void *)v19 + 32))(v19, 0, 0);
      v25[0] = ZinTensorFamilyUtil::GetRootTensor(v6, v20);
      uint64_t v26 = (const ZinIrTensor **)v25;
      unint64_t v21 = std::__hash_table<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::__unordered_map_hasher<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,true>,std::__unordered_map_equal<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::equal_to<ZinIrTensor const*>,std::hash<ZinIrTensor const*>,true>,std::allocator<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>>>::__emplace_unique_key_args<ZinIrTensor const*,std::piecewise_construct_t const&,std::tuple<ZinIrTensor const* const&>,std::tuple<>>((uint64_t)this + 72, v25, (uint64_t)&std::piecewise_construct, &v26);
      if (CpAllocUtils::IsL2Inplace(*((_DWORD *)v21 + 6))) {
        break;
      }
      if ((const ZinIrTensor *)v25[0] == v32) {
        uint64_t v17 = v18;
      }
      if (++v15 == v16)
      {
        if (v17 != -1)
        {
          uint64_t v26 = &v32;
          long long v28 = *(_OWORD *)(std::__hash_table<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>>>::__emplace_unique_key_args<ZinIrTensor *,std::piecewise_construct_t const&,std::tuple<ZinIrTensor * const&>,std::tuple<>>((uint64_t)this + 280, &v32, (uint64_t)&std::piecewise_construct, &v26)+ 3);
          ZinIrMemoryPressureAnalyzer::GetPeakPressure(v24, (const ZinLiveRange *)&v28);
          if (IsResident) {
            ZinIrMemoryPressureAnalyzer::RemoveTensorAllocation(v24, v32, (const ZinLiveRange *)&v28);
          }
          ZinCpBasedAllocator::RemoveDMABufferFromPressureAnalyzer(this, v32, v24);
          uint64_t v22 = *(void *)(LastConsumer + 48) - 1;
          v27[0] = v28;
          v27[1] = v22;
          ZinL2FootprintCalculator::GetResidentBufferSize(*((ZinL2FootprintCalculator **)this + 34), v32);
          ZinIrMemoryPressureAnalyzer::AddTensorAllocation(v24, v23, (const ZinLiveRange *)v27, v32);
        }
        break;
      }
    }
    uint64_t LastConsumer = 0;
    unint64_t v15 = v29;
  }
  if (v15)
  {
    char v30 = v15;
    operator delete(v15);
  }
  return LastConsumer;
}

void sub_211381DDC(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, char a18, void *a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,void *__p,uint64_t a26)
{
  if (__p)
  {
    a26 = (uint64_t)__p;
    operator delete(__p);
  }
  _Unwind_Resume(a1);
}

uint64_t ZinCpBasedAllocator::PromoteToResident(ZinL2FootprintCalculator **this, ZinIrTensor *a2, ZinIrMemoryPressureAnalyzer *a3)
{
  BOOL v10 = a2;
  *(void *)&long long v8 = &v10;
  if (*((_DWORD *)std::__hash_table<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::__unordered_map_hasher<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,true>,std::__unordered_map_equal<ZinIrTensor const*,std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>,std::equal_to<ZinIrTensor const*>,std::hash<ZinIrTensor const*>,true>,std::allocator<std::__hash_value_type<ZinIrTensor const*,CpAllocUtils::AllocationType>>>::__emplace_unique_key_args<ZinIrTensor const*,std::piecewise_construct_t const&,std::tuple<ZinIrTensor const* const&>,std::tuple<>>((uint64_t)(this + 9), &v10, (uint64_t)&std::piecewise_construct, (void **)&v8)+ 6) == 1)
  {
    uint64_t v5 = *((void *)v10 + 13);
    if (!v5 || *(_DWORD *)(v5 + 96) != 2)
    {
      *(void *)&long long v8 = &v10;
      long long v9 = *(_OWORD *)(std::__hash_table<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,ZinLiveRange>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,ZinLiveRange>>>::__emplace_unique_key_args<ZinIrTensor *,std::piecewise_construct_t const&,std::tuple<ZinIrTensor * const&>,std::tuple<>>((uint64_t)(this + 35), &v10, (uint64_t)&std::piecewise_construct, (void **)&v8)+ 3);
      ZinIrMemoryPressureAnalyzer::GetPeakPressure(a3, (const ZinLiveRange *)&v9);
      ZinCpBasedAllocator::RemoveDMABufferFromPressureAnalyzer((ZinCpBasedAllocator *)this, v10, a3);
      ZinL2FootprintCalculator::GetResidentBufferSize(this[34], v10);
      ZinIrMemoryPressureAnalyzer::AddTensorAllocation(a3, v6, (const ZinLiveRange *)&v9, v10);
    }
  }
  return 0;
}

void sub_21138208C(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, char a16, void *a17)
{
}

BOOL ZinCpBasedAllocator::IsDisqualifiedForInplacePromotion(ZinCpBasedAllocator *this, ZinIrTensor *a2)
{
  unint64_t v14 = a2;
  ZinIrTensor::GetTensorFamily(a2, (uint64_t)&v12);
  uint64_t v4 = v12;
  uint64_t v5 = v13;
  if (v12)
  {
    long long v13 = v12;
    operator delete(v12);
  }
  uint64_t v6 = *((void *)a2 + 12);
  uint64_t v8 = *(void *)(v6 + 112);
  uint64_t v7 = *(void *)(v6 + 120);
  long long v9 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)this + 35, &v14);
  if (!v9) {
    ZinAssertImpl("The liverange must exist");
  }
  if (v5 - v4 != 8) {
    return 0;
  }
  return (float)((float)(unint64_t)(v9[4] - v9[3] + 1)
               / (float)(unint64_t)((uint64_t)(*(void *)(*((void *)this + 40) + 8) - **((void **)this + 40)) >> 3)) > 0.2
      && (unint64_t)(v7 - v8) < 0x18;
}

void *ZinCpBasedAllocator::RemoveInputDMABufferFromPressureAnalyzer(ZinCpBasedAllocator *this, const ZinANELayer *a2, uint64_t a3, ZinIrMemoryPressureAnalyzer *a4)
{
  (*(void (**)(void **__return_ptr, const ZinANELayer *))(*(void *)a2 + 512))(&__p, a2);
  uint64_t v8 = (const ZinIrTensor *)*((void *)__p + a3);
  long long v12 = __p;
  operator delete(__p);
  std::string __p = (void *)ZinTensorFamilyUtil::GetRootTensor((ZinCpBasedAllocator *)((char *)this + 1048), v8);
  uint64_t result = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)this + 9, &__p);
  if (!result) {
    std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
  }
  if (*((_DWORD *)result + 6) == 1)
  {
    BOOL v10 = (void *)(*((void *)a2 + 7) + *((void *)a2 + 6));
    std::string __p = (void *)*((void *)a2 + 6);
    long long v12 = v10;
    return (void *)ZinIrMemoryPressureAnalyzer::RemoveLayerInDmaAllocation(a4, a2, (const ZinLiveRange *)&__p, a3);
  }
  return result;
}

void *ZinCpBasedAllocator::RemoveOutputDMABufferFromPressureAnalyzer(ZinCpBasedAllocator *this, const ZinANELayer *a2, ZinIrMemoryPressureAnalyzer *a3)
{
  uint64_t v6 = (const ZinIrTensor *)(*(uint64_t (**)(const ZinANELayer *, void, void))(*(void *)a2 + 32))(a2, 0, 0);
  v9[0] = ZinTensorFamilyUtil::GetRootTensor((ZinCpBasedAllocator *)((char *)this + 1048), v6);
  uint64_t result = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)this + 9, v9);
  if (!result) {
    std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
  }
  if (*((_DWORD *)result + 6) == 1)
  {
    uint64_t v8 = *((void *)a2 + 7) + *((void *)a2 + 6);
    v9[0] = *((void *)a2 + 6);
    v9[1] = v8;
    return (void *)ZinIrMemoryPressureAnalyzer::RemoveLayerOutDmaAllocation(a3, a2, (const ZinLiveRange *)v9);
  }
  return result;
}

void *ZinCpBasedAllocator::AddInputDMABufferToPressureAnalyzer(ZinCpBasedAllocator *this, const ZinANELayer *a2, unint64_t a3, ZinIrMemoryPressureAnalyzer *a4)
{
  unsigned int v15 = 0;
  if (ZinMemSourceIndexTranslator::GetL2SrcType(a2, a3, (int *)&v15)) {
    ZinAssertImpl("Internal CP Allocation error");
  }
  uint64_t v8 = *((void *)a2 + 7) + *((void *)a2 + 6);
  v14[0] = *((void *)a2 + 6);
  v14[1] = v8;
  uint64_t v9 = (*(uint64_t (**)(const ZinANELayer *, void))(*(void *)a2 + 504))(a2, v15);
  BOOL v10 = (const ZinIrTensor *)(*(uint64_t (**)(uint64_t, void, void))(*(void *)v9 + 32))(v9, 0, 0);
  uint64_t RootTensor = ZinTensorFamilyUtil::GetRootTensor((ZinCpBasedAllocator *)((char *)this + 1048), v10);
  uint64_t result = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)this + 9, &RootTensor);
  if (!result) {
    std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
  }
  if (*((_DWORD *)result + 6) == 1)
  {
    if (ZinCpBasedAllocator::HasChainProducerDecision(this, a2))
    {
      Size = ZinCpBasedAllocator::GetChainProducerDmaReadSize(this, a2, a3);
    }
    else if (ZinCpBasedAllocator::HasL2DepProducerDecision(this, a2))
    {
      Size = ZinCpBasedAllocator::GetL2DepProducerDmaReadSize(this, a2, a3);
    }
    else if (ZinCpBasedAllocator::HasChainConsumerDecision(this, a2))
    {
      Size = ZinCpBasedAllocator::GetChainConsumerDmaReadSize(this, a2, a3);
    }
    else if (ZinCpBasedAllocator::HasL2DepConsumerDecision(this, a2))
    {
      Size = ZinCpBasedAllocator::GetL2DepConsumerDmaReadSize(this, a2, a3);
    }
    else
    {
      Size = ZinCpBasedAllocator::GetDmaReadSize(this, a2, a3);
    }
    ZinIrMemoryPressureAnalyzer::AddLayerInDmaAllocation(a4, (unint64_t)Size, (const ZinLiveRange *)v14, a2);
  }
  return result;
}

BOOL ZinCpBasedAllocator::HasChainProducerDecision(ZinCpBasedAllocator *this, const ZinANELayer *a2)
{
  unsigned int v3 = (ZinCpBasedAllocator *)((char *)this + 1048);
  uint64_t v4 = (const ZinIrTensor *)(*(uint64_t (**)(const ZinANELayer *, void, void))(*(void *)a2 + 32))(a2, 0, 0);
  uint64_t RootTensor = ZinTensorFamilyUtil::GetRootTensor(v3, v4);
  uint64_t v5 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)this + 9, &RootTensor);
  return v5 && CpAllocUtils::IsChain(*((_DWORD *)v5 + 6));
}

void *ZinCpBasedAllocator::GetChainProducerDmaReadSize(ZinCpBasedAllocator *this, const ZinANELayer *a2, uint64_t a3)
{
  uint64_t v6 = a2;
  uint64_t result = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)this + 14, &v6);
  if (result)
  {
    LayerCycleAndFootprintEstimator::GetReadBehaviors((uint64_t **)result[3], (char **)__p);
    uint64_t v5 = *((void *)__p[0] + a3);
    __p[1] = __p[0];
    operator delete(__p[0]);
    return *(void **)(v5 + 40);
  }
  return result;
}

BOOL ZinCpBasedAllocator::HasL2DepProducerDecision(ZinCpBasedAllocator *this, const ZinANELayer *a2)
{
  unsigned int v3 = (ZinCpBasedAllocator *)((char *)this + 1048);
  uint64_t v4 = (const ZinIrTensor *)(*(uint64_t (**)(const ZinANELayer *, void, void))(*(void *)a2 + 32))(a2, 0, 0);
  uint64_t RootTensor = ZinTensorFamilyUtil::GetRootTensor(v3, v4);
  uint64_t v5 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)this + 9, &RootTensor);
  return v5 && (CpAllocUtils::IsL2Dependent(*((_DWORD *)v5 + 6)) & 1) != 0;
}

void *ZinCpBasedAllocator::GetL2DepProducerDmaReadSize(ZinCpBasedAllocator *this, const ZinANELayer *a2, uint64_t a3)
{
  uint64_t v6 = a2;
  uint64_t result = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)this + 14, &v6);
  if (result)
  {
    LayerCycleAndFootprintEstimator::GetReadBehaviors((uint64_t **)result[3], (char **)__p);
    uint64_t v5 = *((void *)__p[0] + a3);
    __p[1] = __p[0];
    operator delete(__p[0]);
    uint64_t result = *(void **)(v5 + 72);
    if (!result) {
      return *(void **)(v5 + 40);
    }
  }
  return result;
}

uint64_t ZinCpBasedAllocator::HasChainConsumerDecision(ZinCpBasedAllocator *this, const ZinANELayer *a2)
{
  (*(void (**)(const ZinIrTensor ***__return_ptr, const ZinANELayer *))(*(void *)a2 + 512))(&v12, a2);
  unsigned int v3 = v12;
  uint64_t v4 = v13;
  if (v12 == v13)
  {
    uint64_t v9 = 0;
    if (!v12) {
      return v9;
    }
    goto LABEL_11;
  }
  uint64_t v5 = (ZinCpBasedAllocator *)((char *)this + 1048);
  uint64_t v6 = (void *)((char *)this + 72);
  while (1)
  {
    uint64_t v7 = *v3;
    uint64_t RootTensor = 0;
    uint64_t RootTensor = ZinTensorFamilyUtil::GetRootTensor(v5, v7);
    uint64_t v8 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(v6, &RootTensor);
    if (v8)
    {
      if (CpAllocUtils::IsChain(*((_DWORD *)v8 + 6))) {
        break;
      }
    }
    if (++v3 == v4)
    {
      uint64_t v9 = 0;
      goto LABEL_10;
    }
  }
  uint64_t v9 = 1;
LABEL_10:
  unsigned int v3 = v12;
  if (v12)
  {
LABEL_11:
    long long v13 = v3;
    operator delete(v3);
  }
  return v9;
}

void sub_2113827BC(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

void *ZinCpBasedAllocator::GetChainConsumerDmaReadSize(ZinCpBasedAllocator *this, const ZinANELayer *a2, uint64_t a3)
{
  uint64_t v6 = a2;
  uint64_t result = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)this + 14, &v6);
  if (result)
  {
    LayerCycleAndFootprintEstimator::GetReadBehaviors((uint64_t **)result[3], (char **)__p);
    uint64_t v5 = *((void *)__p[0] + a3);
    __p[1] = __p[0];
    operator delete(__p[0]);
    return *(void **)(v5 + 56);
  }
  return result;
}

uint64_t ZinCpBasedAllocator::HasL2DepConsumerDecision(ZinCpBasedAllocator *this, const ZinANELayer *a2)
{
  uint64_t v3 = *((void *)a2 + 6);
  (*(void (**)(void **__return_ptr, const ZinANELayer *))(*(void *)a2 + 512))(&__p, a2);
  uint64_t v4 = __p;
  uint64_t v5 = v16;
  if (__p == v16)
  {
LABEL_10:
    if (v4)
    {
      uint64_t v16 = v4;
      operator delete(v4);
    }
    return 0;
  }
  else
  {
    uint64_t v6 = (ZinCpBasedAllocator *)((char *)this + 1048);
    uint64_t v7 = (void *)((char *)this + 72);
    while (1)
    {
      uint64_t v8 = (const ZinIrTensor *)*v4;
      uint64_t RootTensor = 0;
      uint64_t RootTensor = ZinTensorFamilyUtil::GetRootTensor(v6, v8);
      uint64_t v9 = *(void *)(*(void *)(RootTensor + 96) + 48);
      BOOL v10 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(v7, &RootTensor);
      if (v10)
      {
        char IsL2Dependent = CpAllocUtils::IsL2Dependent(*((_DWORD *)v10 + 6));
        char v12 = v9 == v3 ? IsL2Dependent : 0;
        if (v12) {
          break;
        }
      }
      if (++v4 == v5)
      {
        uint64_t v4 = __p;
        goto LABEL_10;
      }
    }
    if (__p)
    {
      uint64_t v16 = __p;
      operator delete(__p);
    }
    return 1;
  }
}

void sub_211382938(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

void *ZinCpBasedAllocator::GetL2DepConsumerDmaReadSize(ZinCpBasedAllocator *this, const ZinANELayer *a2, uint64_t a3)
{
  uint64_t v6 = a2;
  uint64_t result = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)this + 14, &v6);
  if (result)
  {
    LayerCycleAndFootprintEstimator::GetReadBehaviors((uint64_t **)result[3], (char **)__p);
    uint64_t v5 = *((void *)__p[0] + a3);
    __p[1] = __p[0];
    operator delete(__p[0]);
    uint64_t result = *(void **)(v5 + 88);
    if (!result) {
      return *(void **)(v5 + 56);
    }
  }
  return result;
}

void *ZinCpBasedAllocator::GetDmaReadSize(ZinCpBasedAllocator *this, const ZinANELayer *a2, uint64_t a3)
{
  uint64_t v6 = a2;
  uint64_t result = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)this + 14, &v6);
  if (result)
  {
    LayerCycleAndFootprintEstimator::GetReadBehaviors((uint64_t **)result[3], (char **)__p);
    uint64_t v5 = *((void *)__p[0] + a3);
    __p[1] = __p[0];
    operator delete(__p[0]);
    return *(void **)(v5 + 24);
  }
  return result;
}

void *ZinCpBasedAllocator::AddOutputDMABufferToPressureAnalyzer(ZinCpBasedAllocator *this, const ZinANELayer *a2, ZinIrMemoryPressureAnalyzer *a3)
{
  uint64_t v6 = (const ZinIrTensor *)(*(uint64_t (**)(const ZinANELayer *, void, void))(*(void *)a2 + 32))(a2, 0, 0);
  uint64_t v7 = *((void *)a2 + 7) + *((void *)a2 + 6);
  v12[0] = *((void *)a2 + 6);
  v12[1] = v7;
  uint64_t RootTensor = (const ZinANELayer *)ZinTensorFamilyUtil::GetRootTensor((ZinCpBasedAllocator *)((char *)this + 1048), v6);
  uint64_t result = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)this + 9, &RootTensor);
  if (!result) {
    std::__throw_out_of_range[abi:ne180100]("unordered_map::at: key not found");
  }
  if (*((_DWORD *)result + 6) == 1)
  {
    if (ZinCpBasedAllocator::HasChainConsumerDecision(this, a2))
    {
      uint64_t RootTensor = a2;
      uint64_t v9 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)this + 14, &RootTensor);
      if (v9)
      {
        BOOL v10 = *(void **)(*(void *)(v9[3] + 32) + 56);
        goto LABEL_11;
      }
    }
    else
    {
      if (ZinCpBasedAllocator::HasL2DepConsumerDecision(this, a2))
      {
        BOOL v10 = ZinCpBasedAllocator::GetL2DepConsumerDmaWriteSize(this, a2);
        goto LABEL_11;
      }
      uint64_t RootTensor = a2;
      unsigned int v11 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)this + 14, &RootTensor);
      if (v11)
      {
        BOOL v10 = *(void **)(*(void *)(v11[3] + 32) + 24);
        goto LABEL_11;
      }
    }
    BOOL v10 = 0;
LABEL_11:
    ZinIrMemoryPressureAnalyzer::AddLayerOutDmaAllocation(a3, (unint64_t)v10, (const ZinLiveRange *)v12, a2);
  }
  return result;
}

void *ZinCpBasedAllocator::GetL2DepConsumerDmaWriteSize(ZinCpBasedAllocator *this, const ZinANELayer *a2)
{
  uint64_t v4 = a2;
  uint64_t result = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)this + 14, &v4);
  if (result)
  {
    uint64_t v3 = *(void *)(result[3] + 32);
    uint64_t result = *(void **)(v3 + 88);
    if (!result) {
      return *(void **)(v3 + 56);
    }
  }
  return result;
}

void ZinCpBasedAllocator::NormalizeCycles(ZinCpBasedAllocator *this)
{
  uint64_t v1 = (ZinIrOpLayer ***)*((void *)this + 40);
  uint64_t v2 = *v1;
  uint64_t v3 = v1[1];
  if (*v1 != v3)
  {
    uint64_t v5 = (char *)this + 112;
    unint64_t v6 = -1;
    do
    {
      uint64_t v7 = *v2;
      if (ZinIrOpLayer::IsANELayer(*v2))
      {
        unint64_t v35 = v7;
        std::string __p = &v35;
        uint64_t v8 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>>>::__emplace_unique_key_args<ZinANELayer const*,std::piecewise_construct_t const&,std::tuple<ZinANELayer const*&&>,std::tuple<>>((uint64_t)v5, &v35, (uint64_t)&std::piecewise_construct, (void **)&__p);
        LayerCycleAndFootprintEstimator::GetReadBehaviors((uint64_t **)v8[3], (char **)&__p);
        uint64_t v9 = __p;
        BOOL v10 = v37;
        if (__p)
        {
          int v37 = __p;
          operator delete(__p);
        }
        if (v10 == v9)
        {
          unint64_t v12 = -1;
        }
        else
        {
          LayerCycleAndFootprintEstimator::GetReadBehaviors((uint64_t **)v8[3], (char **)&__p);
          unsigned int v11 = *(unint64_t **)__p;
          int v37 = __p;
          operator delete(__p);
          unint64_t v12 = *v11;
          LayerCycleAndFootprintEstimator::GetReadBehaviors((uint64_t **)v8[3], (char **)&__p);
          long long v13 = *(unint64_t **)__p;
          int v37 = __p;
          operator delete(__p);
          if (v13[2] < v12) {
            unint64_t v12 = v13[2];
          }
          if (ZinIrOpLayer::IsANELayer(v7))
          {
            (*(void (**)(void **__return_ptr, ZinIrOpLayer *))(*(void *)v7 + 512))(&__p, v7);
            unint64_t v14 = __p;
            unsigned int v15 = v37;
            if (__p)
            {
              int v37 = __p;
              operator delete(__p);
            }
            if ((unint64_t)(v15 - v14) >= 9)
            {
              LayerCycleAndFootprintEstimator::GetReadBehaviors((uint64_t **)v8[3], (char **)&__p);
              uint64_t v16 = (unint64_t *)*((void *)__p + 1);
              int v37 = __p;
              operator delete(__p);
              if (*v16 >= v12) {
                unint64_t v17 = v12;
              }
              else {
                unint64_t v17 = *v16;
              }
              LayerCycleAndFootprintEstimator::GetReadBehaviors((uint64_t **)v8[3], (char **)&__p);
              uint64_t v18 = *((void *)__p + 1);
              int v37 = __p;
              operator delete(__p);
              if (*(void *)(v18 + 16) >= v17) {
                unint64_t v12 = v17;
              }
              else {
                unint64_t v12 = *(void *)(v18 + 16);
              }
            }
          }
        }
        uint64_t v19 = v8[3];
        unint64_t v21 = *(unint64_t **)(v19 + 24);
        uint64_t v20 = *(unint64_t **)(v19 + 32);
        unint64_t v23 = *v21;
        unint64_t v22 = v21[1];
        if (v23 >= v12) {
          unint64_t v23 = v12;
        }
        if (v22 >= v23) {
          unint64_t v22 = v23;
        }
        if (*v20 < v22) {
          unint64_t v22 = *v20;
        }
        unint64_t v24 = v20[2];
        if (v24 >= v22) {
          unint64_t v24 = v22;
        }
        if (v24 >= v6) {
          unint64_t v25 = v6;
        }
        else {
          unint64_t v25 = v24;
        }
        if (v24 >= *((void *)this + 44)) {
          unint64_t v6 = v25;
        }
      }
      ++v2;
    }
    while (v2 != v3);
    uint64_t v26 = (ZinIrOpLayer ***)*((void *)this + 40);
    unint64_t v27 = *v26;
    long long v28 = v26[1];
    if (*v26 != v28)
    {
      BOOL v29 = (char *)this + 376;
      do
      {
        char v30 = *v27;
        if (ZinIrOpLayer::IsANELayer(*v27))
        {
          unint64_t v35 = v30;
          std::string __p = &v35;
          int v31 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>>>::__emplace_unique_key_args<ZinANELayer const*,std::piecewise_construct_t const&,std::tuple<ZinANELayer const*&&>,std::tuple<>>((uint64_t)v5, &v35, (uint64_t)&std::piecewise_construct, (void **)&__p);
          uint64_t v32 = v31;
          if (v6 != -1) {
            LayerCycleAndFootprintEstimator::NormalizeCycles((LayerCycleAndFootprintEstimator *)v31[3], (double)v6);
          }
          ++*(void *)(*(void *)(v32[3] + 24) + 8);
          uint64_t v33 = v35;
          std::string __p = &v35;
          unint64_t v34 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>>>::__emplace_unique_key_args<ZinANELayer const*,std::piecewise_construct_t const&,std::tuple<ZinANELayer const*&&>,std::tuple<>>((uint64_t)v5, &v35, (uint64_t)&std::piecewise_construct, (void **)&__p);
          ZinCpBasedAllocatorUtil::PrintExecutionBehavior((uint64_t)v29, v33, (uint64_t **)v34[3]);
        }
        ++v27;
      }
      while (v27 != v28);
    }
  }
}

uint64_t ZinCpBasedAllocator::SetLayerExecutionBehavior(ZinCpBasedAllocator *this, const ZinANELayer *a2)
{
  uint64_t v19 = 0;
  uint64_t v20 = 0;
  uint64_t v21 = 0;
  unint64_t v22 = a2;
  unint64_t v17 = 0;
  uint64_t v18 = 0;
  uint64_t v15 = 0;
  uint64_t v16 = 0;
  unint64_t v13 = 0;
  uint64_t v14 = 0;
  uint64_t v9 = 0;
  BOOL v10 = 0;
  uint64_t v11 = 0;
  unint64_t v12 = 0;
  if (!ZinCpBasedAllocator::CollectEngineCycleBehavior((uint64_t)this, (ZinEnginePerf ***)a2, (uint64_t)&v19, (uint64_t)&v16, &v15, &v14, &v13, &v12, (uint64_t)&v9))
  {
    memset(v8, 0, sizeof(v8));
    memset(__p, 0, sizeof(__p));
    uint64_t v5 = 0;
    uint64_t v6 = 0;
    ZinCpBasedAllocator::CollectMemorySize((uint64_t)this, a2, v8, __p, &v6, &v5);
    if (v20 != v19) {
      operator new();
    }
    operator new();
  }
  if (v9)
  {
    BOOL v10 = v9;
    operator delete(v9);
  }
  if (v16)
  {
    unint64_t v17 = v16;
    operator delete(v16);
  }
  if (v19)
  {
    uint64_t v20 = v19;
    operator delete(v19);
  }
  return 3;
}

void sub_211383504(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, void *a12, uint64_t a13, int a14, __int16 a15, char a16, char a17, __int16 *a18, uint64_t a19, int a20,__int16 a21,char a22,char a23,LayerCycleAndFootprintEstimator *a24,__int16 a25,char a26,char a27,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,void *__p,uint64_t a34)
{
  std::unique_ptr<LayerCycleAndFootprintEstimator>::reset[abi:ne180100](&a24, 0);
  std::unique_ptr<L2CycleEstimator>::reset[abi:ne180100]((void ***)&a12, 0);
  std::unique_ptr<ComputeCycleEstimator>::reset[abi:ne180100]((ComputeCycleEstimator **)&a18, 0);
  a18 = &a25;
  std::vector<std::unique_ptr<L2CycleEstimator>>::__destroy_vector::operator()[abi:ne180100]((void ***)&a18);
  if (__p)
  {
    a34 = (uint64_t)__p;
    operator delete(__p);
  }
  double v36 = *(void **)v34;
  if (*(void *)v34)
  {
    *(void *)(v34 + 8) = v36;
    operator delete(v36);
  }
  int v37 = *(void **)(v34 + 24);
  if (v37)
  {
    *(void *)(v34 + 32) = v37;
    operator delete(v37);
  }
  double v38 = *(void **)(v34 + 80);
  if (v38)
  {
    *(void *)(v34 + 88) = v38;
    operator delete(v38);
  }
  uint64_t v39 = *(void **)(v34 + 104);
  if (v39)
  {
    *(void *)(v34 + 112) = v39;
    operator delete(v39);
  }
  _Unwind_Resume(a1);
}

uint64_t ZinCpBasedAllocator::CollectMemorySize(uint64_t a1, ZinIrOpLayer *a2, char **a3, void *a4, void *a5, void *a6)
{
  a3[1] = *a3;
  a4[1] = *a4;
  int64x2_t v31 = vdupq_n_s64(1uLL);
  uint64_t v38 = 0;
  char v39 = 0;
  uint64_t v35 = 0;
  uint64_t v36 = 0;
  char v37 = 0;
  uint64_t v32 = 1;
  uint64_t v33 = 0;
  char v34 = 0;
  uint64_t v40 = 1;
  uint64_t v41 = 0;
  uint64_t v42 = 0;
  uint64_t v43 = 0;
  __int16 v44 = 0;
  long long v45 = xmmword_211ED33C0;
  char v46 = 0;
  int v53 = 0;
  uint64_t v58 = 0;
  char v57 = 0;
  long long v55 = 0u;
  long long v56 = 0u;
  long long v54 = 0u;
  int v59 = 0;
  uint64_t v64 = 0;
  long long v60 = 0u;
  long long v61 = 0u;
  long long v62 = 0u;
  char v63 = 0;
  int v65 = 0;
  uint64_t v70 = 0;
  long long v66 = 0u;
  long long v67 = 0u;
  long long v68 = 0u;
  char v69 = 0;
  int v71 = 0;
  memset(v72, 0, sizeof(v72));
  long long v47 = 0u;
  memset(v48, 0, sizeof(v48));
  uint64_t v49 = 0;
  uint64_t v50 = 0;
  char v52 = 0;
  uint64_t v51 = 0;
  int v73 = 1065353216;
  int v74 = 0;
  memset(v75, 0, sizeof(v75));
  int v76 = 1065353216;
  int v77 = 0;
  memset(v78, 0, sizeof(v78));
  int v79 = 1065353216;
  ZinL2FootprintCalculator::GetDmaBufferSizes(*(void *)(a1 + 272), a2, (uint64_t)a4, a6, (uint64_t)&v31);
  (*(void (**)(void **__return_ptr, ZinIrOpLayer *))(*(void *)a2 + 512))(&__p, a2);
  BOOL v10 = (const ZinIrTensor **)__p;
  if (v30 != __p)
  {
    unint64_t v11 = 0;
    do
    {
      ZinL2FootprintCalculator::GetResidentBufferSize(*(ZinL2FootprintCalculator **)(a1 + 272), v10[v11]);
      uint64_t v13 = v12;
      uint64_t v15 = a3[1];
      unint64_t v14 = (unint64_t)a3[2];
      if ((unint64_t)v15 >= v14)
      {
        unint64_t v17 = *a3;
        uint64_t v18 = (v15 - *a3) >> 3;
        unint64_t v19 = v18 + 1;
        if ((unint64_t)(v18 + 1) >> 61) {
          std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
        }
        uint64_t v20 = v14 - (void)v17;
        if (v20 >> 2 > v19) {
          unint64_t v19 = v20 >> 2;
        }
        if ((unint64_t)v20 >= 0x7FFFFFFFFFFFFFF8) {
          unint64_t v21 = 0x1FFFFFFFFFFFFFFFLL;
        }
        else {
          unint64_t v21 = v19;
        }
        if (v21)
        {
          unint64_t v22 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)(a3 + 2), v21);
          unint64_t v17 = *a3;
          uint64_t v15 = a3[1];
        }
        else
        {
          unint64_t v22 = 0;
        }
        unint64_t v23 = &v22[8 * v18];
        *(void *)unint64_t v23 = v13;
        uint64_t v16 = v23 + 8;
        while (v15 != v17)
        {
          uint64_t v24 = *((void *)v15 - 1);
          v15 -= 8;
          *((void *)v23 - 1) = v24;
          v23 -= 8;
        }
        *a3 = v23;
        a3[1] = v16;
        a3[2] = &v22[8 * v21];
        if (v17) {
          operator delete(v17);
        }
      }
      else
      {
        *(void *)uint64_t v15 = v12;
        uint64_t v16 = v15 + 8;
      }
      a3[1] = v16;
      ++v11;
      BOOL v10 = (const ZinIrTensor **)__p;
    }
    while (v11 < (v30 - (unsigned char *)__p) >> 3);
  }
  unint64_t v25 = *(ZinL2FootprintCalculator **)(a1 + 272);
  uint64_t v26 = (const ZinIrTensor *)(*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)a2 + 32))(a2, 0, 0);
  ZinL2FootprintCalculator::GetResidentBufferSize(v25, v26);
  *a5 = v27;
  if (__p)
  {
    char v30 = __p;
    operator delete(__p);
  }
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v78);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v75);
  return std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v72);
}

void sub_211383984(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, void *__p, uint64_t a13, uint64_t a14, char a15)
{
}

void std::make_unique[abi:ne180100]<LayerCycleAndFootprintEstimator,std::vector<std::unique_ptr<L2CycleEstimator>>,std::unique_ptr<ComputeCycleEstimator>,std::unique_ptr<L2CycleEstimator>,BOOL &>()
{
}

void sub_211383AC0(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, void **a9, ComputeCycleEstimator *a10, uint64_t a11, uint64_t a12, uint64_t a13, void **a14)
{
  std::unique_ptr<L2CycleEstimator>::reset[abi:ne180100](&a9, 0);
  std::unique_ptr<ComputeCycleEstimator>::reset[abi:ne180100](&a10, 0);
  std::vector<std::unique_ptr<L2CycleEstimator>>::__destroy_vector::operator()[abi:ne180100](&a14);
  MEMORY[0x21667D3C0](v14, 0x20C40A759441BLL);
  _Unwind_Resume(a1);
}

void *std::vector<BOOL>::__assign_with_size[abi:ne180100]<BOOL const*,BOOL const*>(void *result, unsigned char *a2, unsigned char *a3, unint64_t a4)
{
  result[1] = 0;
  if (a4)
  {
    uint64_t v7 = result;
    if (a4 > result[2] << 6)
    {
      uint64_t v8 = (void *)*result;
      if (*v7)
      {
        operator delete(v8);
        void *v7 = 0;
        v7[1] = 0;
        v7[2] = 0;
      }
      std::vector<BOOL>::__vallocate[abi:ne180100](v7, a4);
    }
    return std::vector<BOOL>::__construct_at_end<BOOL const*,BOOL const*>(v7, a2, a3, a4);
  }
  return result;
}

uint64_t std::function<BOOL ()(unsigned long)>::operator()(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = a2;
  uint64_t v2 = *(void *)(a1 + 24);
  if (!v2) {
    std::__throw_bad_function_call[abi:ne180100]();
  }
  return (*(uint64_t (**)(uint64_t, uint64_t *))(*(void *)v2 + 48))(v2, &v4);
}

uint64_t std::vector<std::vector<ZinANELayer const*>>::__push_back_slow_path<std::vector<ZinANELayer const*> const&>(uint64_t *a1, uint64_t a2)
{
  uint64_t v3 = *a1;
  unint64_t v4 = 0xAAAAAAAAAAAAAAABLL * ((a1[1] - *a1) >> 3);
  unint64_t v5 = v4 + 1;
  if (v4 + 1 > 0xAAAAAAAAAAAAAAALL) {
    std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
  }
  uint64_t v7 = (uint64_t)(a1 + 2);
  unint64_t v8 = 0xAAAAAAAAAAAAAAABLL * ((a1[2] - v3) >> 3);
  if (2 * v8 > v5) {
    unint64_t v5 = 2 * v8;
  }
  if (v8 >= 0x555555555555555) {
    unint64_t v9 = 0xAAAAAAAAAAAAAAALL;
  }
  else {
    unint64_t v9 = v5;
  }
  unint64_t v17 = a1 + 2;
  if (v9) {
    BOOL v10 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<std::string>>(v7, v9);
  }
  else {
    BOOL v10 = 0;
  }
  unint64_t v11 = &v10[24 * v4];
  v14[0] = v10;
  v14[1] = v11;
  uint64_t v15 = v11;
  uint64_t v16 = &v10[24 * v9];
  *(void *)unint64_t v11 = 0;
  *((void *)v11 + 1) = 0;
  *((void *)v11 + 2) = 0;
  std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(v11, *(const void **)a2, *(void *)(a2 + 8), (uint64_t)(*(void *)(a2 + 8) - *(void *)a2) >> 3);
  v15 += 24;
  std::vector<std::vector<ZinANELayer const*>>::__swap_out_circular_buffer(a1, v14);
  uint64_t v12 = a1[1];
  std::__split_buffer<std::vector<ZinIrOpLayer *>>::~__split_buffer((uint64_t)v14);
  return v12;
}

void sub_211383CF8(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::__split_buffer<std::vector<ZinIrOpLayer *>>::~__split_buffer((uint64_t)va);
  _Unwind_Resume(a1);
}

uint64_t std::vector<std::vector<ZinANELayer const*>>::__swap_out_circular_buffer(uint64_t *a1, void *a2)
{
  uint64_t result = std::__uninitialized_allocator_move_if_noexcept[abi:ne180100]<std::allocator<std::vector<ZinANELayer const*>>,std::reverse_iterator<std::vector<ZinANELayer const*>*>,std::reverse_iterator<std::vector<ZinANELayer const*>*>,std::reverse_iterator<std::vector<ZinANELayer const*>*>>((uint64_t)(a1 + 2), a1[1], (void *)a1[1], *a1, (void *)*a1, a2[1], a2[1]);
  a2[1] = v5;
  uint64_t v6 = *a1;
  *a1 = v5;
  a2[1] = v6;
  uint64_t v7 = a1[1];
  a1[1] = a2[2];
  a2[2] = v7;
  uint64_t v8 = a1[2];
  a1[2] = a2[3];
  a2[3] = v8;
  *a2 = a2[1];
  return result;
}

uint64_t std::__uninitialized_allocator_move_if_noexcept[abi:ne180100]<std::allocator<std::vector<ZinANELayer const*>>,std::reverse_iterator<std::vector<ZinANELayer const*>*>,std::reverse_iterator<std::vector<ZinANELayer const*>*>,std::reverse_iterator<std::vector<ZinANELayer const*>*>>(uint64_t a1, uint64_t a2, void *a3, uint64_t a4, void *a5, uint64_t a6, uint64_t a7)
{
  uint64_t v7 = a7;
  *(void *)&long long v14 = a6;
  *((void *)&v14 + 1) = a7;
  long long v13 = v14;
  v11[0] = a1;
  v11[1] = &v13;
  uint64_t v11[2] = &v14;
  if (a3 == a5)
  {
    uint64_t v9 = a6;
  }
  else
  {
    do
    {
      *(void *)(v7 - 24) = 0;
      *(void *)(v7 - 16) = 0;
      *(void *)(v7 - 8) = 0;
      long long v8 = *(_OWORD *)(a3 - 3);
      a3 -= 3;
      *(_OWORD *)(v7 - 24) = v8;
      *(void *)(v7 - 8) = a3[2];
      *a3 = 0;
      a3[1] = 0;
      a3[2] = 0;
      uint64_t v7 = *((void *)&v14 + 1) - 24;
      *((void *)&v14 + 1) -= 24;
    }
    while (a3 != a5);
    uint64_t v9 = v14;
  }
  char v12 = 1;
  std::__exception_guard_exceptions<std::_AllocatorDestroyRangeReverse<std::allocator<std::vector<ZinANELayer const*>>,std::reverse_iterator<std::vector<ZinANELayer const*>*>>>::~__exception_guard_exceptions[abi:ne180100]((uint64_t)v11);
  return v9;
}

uint64_t std::__exception_guard_exceptions<std::_AllocatorDestroyRangeReverse<std::allocator<std::vector<ZinANELayer const*>>,std::reverse_iterator<std::vector<ZinANELayer const*>*>>>::~__exception_guard_exceptions[abi:ne180100](uint64_t a1)
{
  if (!*(unsigned char *)(a1 + 24)) {
    std::_AllocatorDestroyRangeReverse<std::allocator<std::vector<ZinIrOpLayer *>>,std::reverse_iterator<std::vector<ZinIrOpLayer *>*>>::operator()[abi:ne180100](a1);
  }
  return a1;
}

unint64_t *std::__introsort<std::_ClassicAlgPolicy,ZinCpBasedAllocator::GetSortedNonResidentTensors(void)::$_0 &,ZinIrTensor **,false>(unint64_t *result, unint64_t *a2, void *a3, uint64_t a4, char a5)
{
  unint64_t v11 = result;
LABEL_2:
  unint64_t i = v11;
  while (1)
  {
    unint64_t v11 = i;
    uint64_t v13 = (char *)a2 - (char *)i;
    unint64_t v14 = a2 - i;
    if (v6 || !v5)
    {
      switch(v14)
      {
        case 0uLL:
        case 1uLL:
          return result;
        case 2uLL:
          unint64_t v207 = *(a2 - 1);
          char v208 = (void *)(*a3 + 8);
          char v209 = (void *)*v208;
          if (!*v208) {
            goto LABEL_421;
          }
          char v210 = (void *)(*a3 + 8);
          char v211 = (void *)*v210;
          do
          {
            unint64_t v212 = v211[4];
            BOOL v213 = v212 >= v207;
            if (v212 >= v207) {
              char v214 = v211;
            }
            else {
              char v214 = v211 + 1;
            }
            if (v213) {
              char v210 = v211;
            }
            char v211 = (void *)*v214;
          }
          while (*v214);
          if (v210 == v208 || v210[4] > v207) {
LABEL_421:
          }
            char v210 = (void *)(*a3 + 8);
          unint64_t v215 = *i;
          if (!v209) {
            goto LABEL_433;
          }
          uint64_t v216 = *a3 + 8;
          do
          {
            unint64_t v217 = v209[4];
            BOOL v218 = v217 >= v215;
            if (v217 >= v215) {
              char v219 = v209;
            }
            else {
              char v219 = v209 + 1;
            }
            if (v218) {
              uint64_t v216 = (uint64_t)v209;
            }
            char v209 = (void *)*v219;
          }
          while (*v219);
          if ((void *)v216 == v208 || *(void *)(v216 + 32) > v215) {
LABEL_433:
          }
            uint64_t v216 = *a3 + 8;
          unint64_t v220 = v210[5];
          unint64_t v221 = *(void *)(v216 + 40);
          if (v207 == v215 || v220 != v221)
          {
            if (v220 <= v221) {
              return result;
            }
          }
          else if (*(void *)(*(void *)(v207 + 96) + 48) >= *(void *)(*(void *)(v215 + 96) + 48))
          {
            return result;
          }
          *unint64_t i = v207;
          *(a2 - 1) = v215;
          break;
        case 3uLL:
          return std::__sort3[abi:ne180100]<std::_ClassicAlgPolicy,ZinCpBasedAllocator::GetSortedNonResidentTensors(void)::$_0 &,ZinIrTensor **>(i, i + 1, a2 - 1, a3);
        case 4uLL:
          return std::__sort4[abi:ne180100]<std::_ClassicAlgPolicy,ZinCpBasedAllocator::GetSortedNonResidentTensors(void)::$_0 &,ZinIrTensor **>(i, i + 1, i + 2, a2 - 1, a3);
        case 5uLL:
          return std::__sort5_maybe_branchless[abi:ne180100]<std::_ClassicAlgPolicy,ZinCpBasedAllocator::GetSortedNonResidentTensors(void)::$_0 &,ZinIrTensor **,0>(i, i + 1, i + 2, i + 3, a2 - 1, a3);
        default:
          JUMPOUT(0);
      }
      return result;
    }
    if (v13 <= 191) {
      break;
    }
    if (!a4)
    {
      if (i == a2) {
        return result;
      }
      int64_t v261 = (v14 - 2) >> 1;
      int64_t v262 = v261;
      while (2)
      {
        int64_t v263 = v262;
        if (v261 >= v262)
        {
          uint64_t v264 = (2 * v262) | 1;
          v265 = &i[v264];
          uint64_t v266 = *a3;
          if (2 * v263 + 2 < (uint64_t)v14)
          {
            unint64_t v267 = *v265;
            v268 = (void *)(v266 + 8);
            v282 = *(void **)(v266 + 8);
            if (!v282) {
              goto LABEL_541;
            }
            v269 = (void *)(v266 + 8);
            v270 = *(void **)(v266 + 8);
            do
            {
              unint64_t v271 = v270[4];
              BOOL v272 = v271 >= v267;
              if (v271 >= v267) {
                v273 = v270;
              }
              else {
                v273 = v270 + 1;
              }
              if (v272) {
                v269 = v270;
              }
              v270 = (void *)*v273;
            }
            while (*v273);
            if (v269 == v268 || v269[4] > v267) {
LABEL_541:
            }
              v269 = (void *)(v266 + 8);
            unint64_t v274 = v265[1];
            if (!v282) {
              goto LABEL_553;
            }
            v275 = (void *)(v266 + 8);
            v276 = *(void **)(v266 + 8);
            do
            {
              unint64_t v277 = v276[4];
              BOOL v278 = v277 >= v274;
              if (v277 >= v274) {
                v279 = v276;
              }
              else {
                v279 = v276 + 1;
              }
              if (v278) {
                v275 = v276;
              }
              v276 = (void *)*v279;
            }
            while (*v279);
            if (v275 == v268 || v275[4] > v274) {
LABEL_553:
            }
              v275 = (void *)(v266 + 8);
            unint64_t v280 = v269[5];
            unint64_t v281 = v275[5];
            if (v267 == v274 || v280 != v281)
            {
              if (v280 <= v281) {
                goto LABEL_560;
              }
            }
            else if (*(void *)(*(void *)(v267 + 96) + 48) >= *(void *)(*(void *)(v274 + 96) + 48))
            {
              goto LABEL_560;
            }
            ++v265;
            uint64_t v264 = 2 * v263 + 2;
            goto LABEL_560;
          }
          v282 = *(void **)(v266 + 8);
LABEL_560:
          unint64_t v283 = *v265;
          v284 = (unint64_t *)i[v263];
          v285 = (unint64_t *)(v266 + 8);
          if (!v282) {
            goto LABEL_571;
          }
          uint64_t result = v285;
          v286 = v282;
          do
          {
            unint64_t v287 = v286[4];
            BOOL v288 = v287 >= v283;
            if (v287 >= v283) {
              v289 = v286;
            }
            else {
              v289 = v286 + 1;
            }
            if (v288) {
              uint64_t result = v286;
            }
            v286 = (void *)*v289;
          }
          while (*v289);
          if (result == v285 || result[4] > v283) {
LABEL_571:
          }
            uint64_t result = v285;
          if (!v282) {
            goto LABEL_583;
          }
          v290 = v285;
          do
          {
            unint64_t v291 = v282[4];
            BOOL v292 = v291 >= (unint64_t)v284;
            if (v291 >= (unint64_t)v284) {
              v293 = v282;
            }
            else {
              v293 = v282 + 1;
            }
            if (v292) {
              v290 = v282;
            }
            v282 = (void *)*v293;
          }
          while (*v293);
          if (v290 == v285 || v290[4] > (unint64_t)v284) {
LABEL_583:
          }
            v290 = v285;
          unint64_t v294 = result[5];
          unint64_t v295 = v290[5];
          if ((unint64_t *)v283 == v284 || v294 != v295)
          {
            if (v294 > v295) {
              goto LABEL_654;
            }
          }
          else if (*(void *)(*(void *)(v283 + 96) + 48) < *(void *)(v284[12] + 48))
          {
            goto LABEL_654;
          }
          i[v263] = v283;
          if (v261 < v264)
          {
LABEL_590:
            v296 = v265;
LABEL_653:
            unint64_t *v296 = (unint64_t)v284;
            goto LABEL_654;
          }
          while (2)
          {
            uint64_t v297 = 2 * v264;
            uint64_t v264 = (2 * v264) | 1;
            v296 = &i[v264];
            uint64_t v298 = v297 + 2;
            uint64_t v299 = *a3;
            if (v297 + 2 >= (uint64_t)v14)
            {
              v315 = *(void **)(v299 + 8);
LABEL_623:
              uint64_t result = (unint64_t *)*v296;
              v316 = (void *)(v299 + 8);
              if (!v315) {
                goto LABEL_634;
              }
              v317 = v316;
              v318 = v315;
              do
              {
                unint64_t v319 = v318[4];
                BOOL v320 = v319 >= (unint64_t)result;
                if (v319 >= (unint64_t)result) {
                  v321 = v318;
                }
                else {
                  v321 = v318 + 1;
                }
                if (v320) {
                  v317 = v318;
                }
                v318 = (void *)*v321;
              }
              while (*v321);
              if (v317 == v316 || v317[4] > (unint64_t)result) {
LABEL_634:
              }
                v317 = v316;
              if (!v315) {
                goto LABEL_646;
              }
              v322 = v316;
              do
              {
                unint64_t v323 = v315[4];
                BOOL v324 = v323 >= (unint64_t)v284;
                if (v323 >= (unint64_t)v284) {
                  v325 = v315;
                }
                else {
                  v325 = v315 + 1;
                }
                if (v324) {
                  v322 = v315;
                }
                v315 = (void *)*v325;
              }
              while (*v325);
              if (v322 == v316 || v322[4] > (unint64_t)v284) {
LABEL_646:
              }
                v322 = v316;
              unint64_t v326 = v317[5];
              unint64_t v327 = v322[5];
              if (result == v284 || v326 != v327)
              {
                if (v326 > v327) {
                  goto LABEL_590;
                }
              }
              else if (*(void *)(result[12] + 48) < *(void *)(v284[12] + 48))
              {
                goto LABEL_590;
              }
              unint64_t *v265 = (unint64_t)result;
              v265 = v296;
              if (v261 < v264) {
                goto LABEL_653;
              }
              continue;
            }
            break;
          }
          unint64_t v300 = *v296;
          v301 = (void *)(v299 + 8);
          v315 = *(void **)(v299 + 8);
          if (!v315) {
            goto LABEL_604;
          }
          v302 = (void *)(v299 + 8);
          v303 = *(void **)(v299 + 8);
          do
          {
            unint64_t v304 = v303[4];
            BOOL v305 = v304 >= v300;
            if (v304 >= v300) {
              v306 = v303;
            }
            else {
              v306 = v303 + 1;
            }
            if (v305) {
              v302 = v303;
            }
            v303 = (void *)*v306;
          }
          while (*v306);
          if (v302 == v301 || v302[4] > v300) {
LABEL_604:
          }
            v302 = (void *)(v299 + 8);
          unint64_t v307 = v296[1];
          if (!v315) {
            goto LABEL_616;
          }
          v308 = (void *)(v299 + 8);
          v309 = *(void **)(v299 + 8);
          do
          {
            unint64_t v310 = v309[4];
            BOOL v311 = v310 >= v307;
            if (v310 >= v307) {
              v312 = v309;
            }
            else {
              v312 = v309 + 1;
            }
            if (v311) {
              v308 = v309;
            }
            v309 = (void *)*v312;
          }
          while (*v312);
          if (v308 == v301 || v308[4] > v307) {
LABEL_616:
          }
            v308 = (void *)(v299 + 8);
          unint64_t v313 = v302[5];
          unint64_t v314 = v308[5];
          if (v300 == v307 || v313 != v314)
          {
            if (v313 <= v314) {
              goto LABEL_623;
            }
          }
          else if (*(void *)(*(void *)(v300 + 96) + 48) >= *(void *)(*(void *)(v307 + 96) + 48))
          {
            goto LABEL_623;
          }
          ++v296;
          uint64_t v264 = v298;
          goto LABEL_623;
        }
LABEL_654:
        int64_t v262 = v263 - 1;
        if (v263) {
          continue;
        }
        break;
      }
      uint64_t v328 = (unint64_t)v13 >> 3;
      while (2)
      {
        uint64_t v329 = 0;
        unint64_t v330 = *i;
        v331 = i;
LABEL_657:
        v332 = v331;
        v331 += v329 + 1;
        uint64_t v333 = 2 * v329;
        uint64_t v329 = (2 * v329) | 1;
        uint64_t v334 = v333 + 2;
        if (v334 < v328)
        {
          unint64_t v335 = *v331;
          v337 = (void *)(*a3 + 8);
          v336 = (void *)*v337;
          if (!*v337) {
            goto LABEL_669;
          }
          v338 = (void *)(*a3 + 8);
          v339 = (void *)*v338;
          do
          {
            unint64_t v340 = v339[4];
            BOOL v341 = v340 >= v335;
            if (v340 >= v335) {
              v342 = v339;
            }
            else {
              v342 = v339 + 1;
            }
            if (v341) {
              v338 = v339;
            }
            v339 = (void *)*v342;
          }
          while (*v342);
          if (v338 == v337 || v338[4] > v335) {
LABEL_669:
          }
            v338 = (void *)(*a3 + 8);
          unint64_t v343 = v331[1];
          if (!v336) {
            goto LABEL_681;
          }
          uint64_t v344 = *a3 + 8;
          do
          {
            unint64_t v345 = v336[4];
            BOOL v346 = v345 >= v343;
            if (v345 >= v343) {
              v347 = v336;
            }
            else {
              v347 = v336 + 1;
            }
            if (v346) {
              uint64_t v344 = (uint64_t)v336;
            }
            v336 = (void *)*v347;
          }
          while (*v347);
          if ((void *)v344 == v337 || *(void *)(v344 + 32) > v343) {
LABEL_681:
          }
            uint64_t v344 = *a3 + 8;
          v348 = (unint64_t *)v338[5];
          uint64_t result = *(unint64_t **)(v344 + 40);
          if (v335 == v343 || v348 != result)
          {
            if (v348 > result)
            {
LABEL_685:
              ++v331;
              uint64_t v329 = v334;
            }
          }
          else if (*(void *)(*(void *)(v335 + 96) + 48) < *(void *)(*(void *)(v343 + 96) + 48))
          {
            goto LABEL_685;
          }
        }
        unint64_t *v332 = *v331;
        if (v329 > (uint64_t)((unint64_t)(v328 - 2) >> 1))
        {
          if (v331 == --a2)
          {
            unint64_t *v331 = v330;
            goto LABEL_757;
          }
          unint64_t *v331 = *a2;
          *a2 = v330;
          uint64_t v349 = (char *)v331 - (char *)i + 8;
          if (v349 >= 9)
          {
            unint64_t v350 = ((unint64_t)v349 >> 3) - 2;
            unint64_t v351 = v350 >> 1;
            v352 = &i[v350 >> 1];
            unint64_t v353 = *v352;
            v354 = (unint64_t *)(*a3 + 8);
            v355 = (void *)*v354;
            if (!*v354) {
              goto LABEL_704;
            }
            v356 = (unint64_t *)(*a3 + 8);
            v357 = (void *)*v356;
            do
            {
              unint64_t v358 = v357[4];
              BOOL v359 = v358 >= v353;
              if (v358 >= v353) {
                v360 = v357;
              }
              else {
                v360 = v357 + 1;
              }
              if (v359) {
                v356 = v357;
              }
              v357 = (void *)*v360;
            }
            while (*v360);
            if (v356 == v354 || v356[4] > v353) {
LABEL_704:
            }
              v356 = (unint64_t *)(*a3 + 8);
            unint64_t v361 = *v331;
            if (!v355) {
              goto LABEL_716;
            }
            uint64_t result = (unint64_t *)(*a3 + 8);
            do
            {
              unint64_t v362 = v355[4];
              BOOL v363 = v362 >= v361;
              if (v362 >= v361) {
                v364 = v355;
              }
              else {
                v364 = v355 + 1;
              }
              if (v363) {
                uint64_t result = v355;
              }
              v355 = (void *)*v364;
            }
            while (*v364);
            if (result == v354 || result[4] > v361) {
LABEL_716:
            }
              uint64_t result = (unint64_t *)(*a3 + 8);
            unint64_t v365 = v356[5];
            unint64_t v366 = result[5];
            if (v353 == v361 || v365 != v366)
            {
              if (v365 <= v366) {
                goto LABEL_757;
              }
            }
            else if (*(void *)(*(void *)(v353 + 96) + 48) >= *(void *)(*(void *)(v361 + 96) + 48))
            {
              goto LABEL_757;
            }
            unint64_t *v331 = v353;
            if (v350 >= 2)
            {
              do
              {
                unint64_t v368 = v351 - 1;
                unint64_t v351 = (v351 - 1) >> 1;
                v367 = &i[v351];
                unint64_t v369 = *v367;
                v370 = (unint64_t *)(*a3 + 8);
                v371 = (void *)*v370;
                if (!*v370) {
                  goto LABEL_735;
                }
                v372 = (unint64_t *)(*a3 + 8);
                v373 = (void *)*v372;
                do
                {
                  unint64_t v374 = v373[4];
                  BOOL v375 = v374 >= v369;
                  if (v374 >= v369) {
                    v376 = v373;
                  }
                  else {
                    v376 = v373 + 1;
                  }
                  if (v375) {
                    v372 = v373;
                  }
                  v373 = (void *)*v376;
                }
                while (*v376);
                if (v372 == v370 || v372[4] > v369) {
LABEL_735:
                }
                  v372 = (unint64_t *)(*a3 + 8);
                if (!v371) {
                  goto LABEL_747;
                }
                uint64_t result = (unint64_t *)(*a3 + 8);
                do
                {
                  unint64_t v377 = v371[4];
                  BOOL v378 = v377 >= v361;
                  if (v377 >= v361) {
                    v379 = v371;
                  }
                  else {
                    v379 = v371 + 1;
                  }
                  if (v378) {
                    uint64_t result = v371;
                  }
                  v371 = (void *)*v379;
                }
                while (*v379);
                if (result == v370 || result[4] > v361) {
LABEL_747:
                }
                  uint64_t result = (unint64_t *)(*a3 + 8);
                unint64_t v380 = v372[5];
                unint64_t v381 = result[5];
                if (v369 != v361 && v380 == v381)
                {
                  if (*(void *)(*(void *)(v369 + 96) + 48) >= *(void *)(*(void *)(v361 + 96) + 48)) {
                    goto LABEL_723;
                  }
                }
                else if (v380 <= v381)
                {
                  goto LABEL_723;
                }
                unint64_t *v352 = v369;
                v352 = &i[v351];
              }
              while (v368 > 1);
            }
            else
            {
LABEL_723:
              v367 = v352;
            }
            unint64_t *v367 = v361;
          }
LABEL_757:
          if (v328-- <= 2) {
            return result;
          }
          continue;
        }
        goto LABEL_657;
      }
    }
    unint64_t v15 = v14 >> 1;
    uint64_t v16 = &i[v14 >> 1];
    if ((unint64_t)v13 >= 0x401)
    {
      std::__sort3[abi:ne180100]<std::_ClassicAlgPolicy,ZinCpBasedAllocator::GetSortedNonResidentTensors(void)::$_0 &,ZinIrTensor **>(v11, &v11[v14 >> 1], a2 - 1, a3);
      std::__sort3[abi:ne180100]<std::_ClassicAlgPolicy,ZinCpBasedAllocator::GetSortedNonResidentTensors(void)::$_0 &,ZinIrTensor **>(v11 + 1, v16 - 1, a2 - 2, a3);
      std::__sort3[abi:ne180100]<std::_ClassicAlgPolicy,ZinCpBasedAllocator::GetSortedNonResidentTensors(void)::$_0 &,ZinIrTensor **>(v11 + 2, &v11[v15 + 1], a2 - 3, a3);
      uint64_t result = std::__sort3[abi:ne180100]<std::_ClassicAlgPolicy,ZinCpBasedAllocator::GetSortedNonResidentTensors(void)::$_0 &,ZinIrTensor **>(v16 - 1, v16, &v11[v15 + 1], a3);
      unint64_t v17 = *v11;
      unint64_t *v11 = *v16;
      unint64_t *v16 = v17;
    }
    else
    {
      uint64_t result = std::__sort3[abi:ne180100]<std::_ClassicAlgPolicy,ZinCpBasedAllocator::GetSortedNonResidentTensors(void)::$_0 &,ZinIrTensor **>(&v11[v14 >> 1], v11, a2 - 1, a3);
    }
    --a4;
    unint64_t v18 = *v11;
    uint64_t v19 = *a3;
    if (a5)
    {
      uint64_t v20 = *(void **)(v19 + 8);
LABEL_39:
      uint64_t v35 = (void *)(v19 + 8);
      uint64_t v36 = v11;
      do
      {
        while (1)
        {
          char v37 = v36;
          unint64_t v39 = v36[1];
          ++v36;
          unint64_t v38 = v39;
          if (!v20) {
            goto LABEL_51;
          }
          uint64_t v40 = v35;
          uint64_t v41 = v20;
          do
          {
            unint64_t v42 = v41[4];
            BOOL v43 = v42 >= v38;
            if (v42 >= v38) {
              __int16 v44 = v41;
            }
            else {
              __int16 v44 = v41 + 1;
            }
            if (v43) {
              uint64_t v40 = v41;
            }
            uint64_t v41 = (void *)*v44;
          }
          while (*v44);
          if (v40 == v35 || v40[4] > v38) {
LABEL_51:
          }
            uint64_t v40 = v35;
          if (!v20) {
            goto LABEL_63;
          }
          long long v45 = v35;
          char v46 = v20;
          do
          {
            unint64_t v47 = v46[4];
            BOOL v48 = v47 >= v18;
            if (v47 >= v18) {
              uint64_t v49 = v46;
            }
            else {
              uint64_t v49 = v46 + 1;
            }
            if (v48) {
              long long v45 = v46;
            }
            char v46 = (void *)*v49;
          }
          while (*v49);
          if (v45 == v35 || v45[4] > v18) {
LABEL_63:
          }
            long long v45 = v35;
          unint64_t v50 = v40[5];
          unint64_t v51 = v45[5];
          if (v38 != v18 && v50 == v51) {
            break;
          }
          if (v50 <= v51) {
            goto LABEL_71;
          }
        }
      }
      while (*(void *)(*(void *)(v38 + 96) + 48) < *(void *)(*(void *)(v18 + 96) + 48));
LABEL_71:
      int v53 = a2;
      if (v37 == v11)
      {
        int v53 = a2;
        if (v36 < a2)
        {
          int v53 = a2;
          do
          {
            while (1)
            {
              unint64_t v70 = *--v53;
              unint64_t v69 = v70;
              if (!v20) {
                goto LABEL_117;
              }
              int v71 = v35;
              long long v72 = v20;
              do
              {
                unint64_t v73 = v72[4];
                BOOL v74 = v73 >= v69;
                if (v73 >= v69) {
                  uint64_t v75 = v72;
                }
                else {
                  uint64_t v75 = v72 + 1;
                }
                if (v74) {
                  int v71 = v72;
                }
                long long v72 = (void *)*v75;
              }
              while (*v75);
              if (v71 == v35 || v71[4] > v69) {
LABEL_117:
              }
                int v71 = v35;
              if (!v20) {
                goto LABEL_129;
              }
              int v76 = v35;
              int v77 = v20;
              do
              {
                unint64_t v78 = v77[4];
                BOOL v79 = v78 >= v18;
                if (v78 >= v18) {
                  long long v80 = v77;
                }
                else {
                  long long v80 = v77 + 1;
                }
                if (v79) {
                  int v76 = v77;
                }
                int v77 = (void *)*v80;
              }
              while (*v80);
              if (v76 == v35 || v76[4] > v18) {
LABEL_129:
              }
                int v76 = v35;
              unint64_t v81 = v71[5];
              unint64_t v82 = v76[5];
              if (v69 != v18 && v81 == v82) {
                break;
              }
              if (v36 >= v53 || v81 > v82) {
                goto LABEL_139;
              }
            }
          }
          while (v36 < v53 && *(void *)(*(void *)(v69 + 96) + 48) >= *(void *)(*(void *)(v18 + 96) + 48));
        }
      }
      else
      {
        do
        {
          while (1)
          {
            unint64_t v55 = *--v53;
            unint64_t v54 = v55;
            if (!v20) {
              goto LABEL_83;
            }
            long long v56 = v35;
            char v57 = v20;
            do
            {
              unint64_t v58 = v57[4];
              BOOL v59 = v58 >= v54;
              if (v58 >= v54) {
                long long v60 = v57;
              }
              else {
                long long v60 = v57 + 1;
              }
              if (v59) {
                long long v56 = v57;
              }
              char v57 = (void *)*v60;
            }
            while (*v60);
            if (v56 == v35 || v56[4] > v54) {
LABEL_83:
            }
              long long v56 = v35;
            if (!v20) {
              goto LABEL_95;
            }
            long long v61 = v35;
            long long v62 = v20;
            do
            {
              unint64_t v63 = v62[4];
              BOOL v64 = v63 >= v18;
              if (v63 >= v18) {
                int v65 = v62;
              }
              else {
                int v65 = v62 + 1;
              }
              if (v64) {
                long long v61 = v62;
              }
              long long v62 = (void *)*v65;
            }
            while (*v65);
            if (v61 == v35 || v61[4] > v18) {
LABEL_95:
            }
              long long v61 = v35;
            unint64_t v66 = v56[5];
            unint64_t v67 = v61[5];
            if (v54 != v18 && v66 == v67) {
              break;
            }
            if (v66 > v67) {
              goto LABEL_139;
            }
          }
        }
        while (*(void *)(*(void *)(v54 + 96) + 48) >= *(void *)(*(void *)(v18 + 96) + 48));
      }
LABEL_139:
      if (v36 < v53)
      {
        unint64_t v84 = *v53;
        long long v85 = v36;
        long long v86 = v53;
        do
        {
          *long long v85 = v84;
          *long long v86 = v38;
          long long v87 = (uint64_t *)(*a3 + 8);
          uint64_t v88 = *v87;
          do
          {
            while (1)
            {
              char v37 = v85;
              unint64_t v89 = v85[1];
              ++v85;
              unint64_t v38 = v89;
              if (!v88) {
                goto LABEL_153;
              }
              long long v90 = (uint64_t *)(*a3 + 8);
              long long v91 = (void *)*v90;
              do
              {
                unint64_t v92 = v91[4];
                BOOL v93 = v92 >= v38;
                if (v92 >= v38) {
                  uint64_t v94 = v91;
                }
                else {
                  uint64_t v94 = v91 + 1;
                }
                if (v93) {
                  long long v90 = v91;
                }
                long long v91 = (void *)*v94;
              }
              while (*v94);
              if (v90 == v87 || v90[4] > v38) {
LABEL_153:
              }
                long long v90 = (uint64_t *)(*a3 + 8);
              if (!v88) {
                goto LABEL_165;
              }
              long long v95 = (uint64_t *)(*a3 + 8);
              long long v96 = (void *)*v95;
              do
              {
                unint64_t v97 = v96[4];
                BOOL v98 = v97 >= v18;
                if (v97 >= v18) {
                  uint64_t v99 = v96;
                }
                else {
                  uint64_t v99 = v96 + 1;
                }
                if (v98) {
                  long long v95 = v96;
                }
                long long v96 = (void *)*v99;
              }
              while (*v99);
              if (v95 == v87 || v95[4] > v18) {
LABEL_165:
              }
                long long v95 = (uint64_t *)(*a3 + 8);
              unint64_t v100 = v90[5];
              unint64_t v101 = v95[5];
              if (v38 == v18 || v100 != v101) {
                break;
              }
              if (*(void *)(*(void *)(v38 + 96) + 48) >= *(void *)(*(void *)(v18 + 96) + 48)) {
                goto LABEL_175;
              }
            }
          }
          while (v100 > v101);
          do
          {
            while (1)
            {
LABEL_175:
              unint64_t v103 = *--v86;
              unint64_t v84 = v103;
              if (!v88) {
                goto LABEL_186;
              }
              int v104 = (uint64_t *)(*a3 + 8);
              int v105 = (void *)*v104;
              do
              {
                unint64_t v106 = v105[4];
                BOOL v107 = v106 >= v84;
                if (v106 >= v84) {
                  int v108 = v105;
                }
                else {
                  int v108 = v105 + 1;
                }
                if (v107) {
                  int v104 = v105;
                }
                int v105 = (void *)*v108;
              }
              while (*v108);
              if (v104 == v87 || v104[4] > v84) {
LABEL_186:
              }
                int v104 = (uint64_t *)(*a3 + 8);
              if (!v88) {
                goto LABEL_198;
              }
              long long v109 = (uint64_t *)(*a3 + 8);
              int v110 = (void *)*v109;
              do
              {
                unint64_t v111 = v110[4];
                BOOL v112 = v111 >= v18;
                if (v111 >= v18) {
                  int v113 = v110;
                }
                else {
                  int v113 = v110 + 1;
                }
                if (v112) {
                  long long v109 = v110;
                }
                int v110 = (void *)*v113;
              }
              while (*v113);
              if (v109 == v87 || v109[4] > v18) {
LABEL_198:
              }
                long long v109 = (uint64_t *)(*a3 + 8);
              unint64_t v114 = v104[5];
              unint64_t v115 = v109[5];
              if (v84 == v18 || v114 != v115) {
                break;
              }
              if (*(void *)(*(void *)(v84 + 96) + 48) < *(void *)(*(void *)(v18 + 96) + 48)) {
                goto LABEL_204;
              }
            }
          }
          while (v114 <= v115);
LABEL_204:
          ;
        }
        while (v85 < v86);
      }
      if (v37 != v11) {
        unint64_t *v11 = *v37;
      }
      unint64_t *v37 = v18;
      if (v36 < v53) {
        goto LABEL_210;
      }
      BOOL v117 = std::__insertion_sort_incomplete[abi:ne180100]<std::_ClassicAlgPolicy,ZinCpBasedAllocator::GetSortedNonResidentTensors(void)::$_0 &,ZinIrTensor **>(v11, v37, a3);
      unint64_t i = v37 + 1;
      uint64_t result = (unint64_t *)std::__insertion_sort_incomplete[abi:ne180100]<std::_ClassicAlgPolicy,ZinCpBasedAllocator::GetSortedNonResidentTensors(void)::$_0 &,ZinIrTensor **>(v37 + 1, a2, a3);
      if (result)
      {
        a2 = v37;
        if (v117) {
          return result;
        }
        goto LABEL_2;
      }
      if (!v117)
      {
LABEL_210:
        uint64_t result = (unint64_t *)std::__introsort<std::_ClassicAlgPolicy,ZinCpBasedAllocator::GetSortedNonResidentTensors(void)::$_0 &,ZinIrTensor **,false>(v11, v37, a3, a4, a5 & 1);
        a5 = 0;
        unint64_t i = v37 + 1;
      }
    }
    else
    {
      unint64_t v21 = *(v11 - 1);
      unint64_t v22 = (void *)(v19 + 8);
      uint64_t v20 = *(void **)(v19 + 8);
      if (!v20) {
        goto LABEL_23;
      }
      unint64_t v23 = (void *)(v19 + 8);
      uint64_t v24 = *(void **)(v19 + 8);
      do
      {
        unint64_t v25 = v24[4];
        BOOL v26 = v25 >= v21;
        if (v25 >= v21) {
          uint64_t v27 = v24;
        }
        else {
          uint64_t v27 = v24 + 1;
        }
        if (v26) {
          unint64_t v23 = v24;
        }
        uint64_t v24 = (void *)*v27;
      }
      while (*v27);
      if (v23 == v22 || v23[4] > v21) {
LABEL_23:
      }
        unint64_t v23 = (void *)(v19 + 8);
      if (!v20) {
        goto LABEL_35;
      }
      long long v28 = (void *)(v19 + 8);
      BOOL v29 = *(void **)(v19 + 8);
      do
      {
        unint64_t v30 = v29[4];
        BOOL v31 = v30 >= v18;
        if (v30 >= v18) {
          uint64_t v32 = v29;
        }
        else {
          uint64_t v32 = v29 + 1;
        }
        if (v31) {
          long long v28 = v29;
        }
        BOOL v29 = (void *)*v32;
      }
      while (*v32);
      if (v28 == v22 || v28[4] > v18) {
LABEL_35:
      }
        long long v28 = (void *)(v19 + 8);
      unint64_t v33 = v23[5];
      unint64_t v34 = v28[5];
      if (v21 == v18 || v33 != v34)
      {
        if (v33 > v34) {
          goto LABEL_39;
        }
      }
      else if (*(void *)(*(void *)(v21 + 96) + 48) < *(void *)(*(void *)(v18 + 96) + 48))
      {
        goto LABEL_39;
      }
      if (!v20) {
        goto LABEL_223;
      }
      long long v118 = (void *)(v19 + 8);
      int v119 = *(void **)(v19 + 8);
      do
      {
        unint64_t v120 = v119[4];
        BOOL v121 = v120 >= v18;
        if (v120 >= v18) {
          uint64_t v122 = v119;
        }
        else {
          uint64_t v122 = v119 + 1;
        }
        if (v121) {
          long long v118 = v119;
        }
        int v119 = (void *)*v122;
      }
      while (*v122);
      if (v118 == v22 || v118[4] > v18) {
LABEL_223:
      }
        long long v118 = v22;
      unint64_t v123 = *(a2 - 1);
      if (!v20) {
        goto LABEL_235;
      }
      int v124 = v22;
      int v125 = v20;
      do
      {
        unint64_t v126 = v125[4];
        BOOL v127 = v126 >= v123;
        if (v126 >= v123) {
          uint64_t v128 = v125;
        }
        else {
          uint64_t v128 = v125 + 1;
        }
        if (v127) {
          int v124 = v125;
        }
        int v125 = (void *)*v128;
      }
      while (*v128);
      if (v124 == v22 || v124[4] > v123) {
LABEL_235:
      }
        int v124 = v22;
      unint64_t v129 = v118[5];
      unint64_t v130 = v124[5];
      if (v18 == v123 || v129 != v130)
      {
        if (v129 > v130)
        {
LABEL_239:
          unint64_t i = v11;
          do
          {
            while (1)
            {
              if (!v20) {
                goto LABEL_251;
              }
              int v131 = v22;
              uint64_t v132 = v20;
              do
              {
                unint64_t v133 = v132[4];
                BOOL v134 = v133 >= v18;
                if (v133 >= v18) {
                  int v135 = v132;
                }
                else {
                  int v135 = v132 + 1;
                }
                if (v134) {
                  int v131 = v132;
                }
                uint64_t v132 = (void *)*v135;
              }
              while (*v135);
              if (v131 == v22 || v131[4] > v18) {
LABEL_251:
              }
                int v131 = v22;
              unint64_t v137 = i[1];
              ++i;
              unint64_t v136 = v137;
              if (!v20) {
                goto LABEL_263;
              }
              int v138 = v22;
              long long v139 = v20;
              do
              {
                unint64_t v140 = v139[4];
                BOOL v141 = v140 >= v136;
                if (v140 >= v136) {
                  char v142 = v139;
                }
                else {
                  char v142 = v139 + 1;
                }
                if (v141) {
                  int v138 = v139;
                }
                long long v139 = (void *)*v142;
              }
              while (*v142);
              if (v138 == v22 || v138[4] > v136) {
LABEL_263:
              }
                int v138 = v22;
              unint64_t v143 = v131[5];
              unint64_t v144 = v138[5];
              if (v18 != v136 && v143 == v144) {
                break;
              }
              if (v143 > v144) {
                goto LABEL_271;
              }
            }
          }
          while (*(void *)(*(void *)(v18 + 96) + 48) >= *(void *)(*(void *)(v136 + 96) + 48));
          goto LABEL_271;
        }
      }
      else if (*(void *)(*(void *)(v18 + 96) + 48) < *(void *)(*(void *)(v123 + 96) + 48))
      {
        goto LABEL_239;
      }
      for (unint64_t i = v11 + 1; i < a2; ++i)
      {
        if (!v20) {
          goto LABEL_386;
        }
        char v193 = v22;
        char v194 = v20;
        do
        {
          unint64_t v195 = v194[4];
          BOOL v196 = v195 >= v18;
          if (v195 >= v18) {
            char v197 = v194;
          }
          else {
            char v197 = v194 + 1;
          }
          if (v196) {
            char v193 = v194;
          }
          char v194 = (void *)*v197;
        }
        while (*v197);
        if (v193 == v22 || v193[4] > v18) {
LABEL_386:
        }
          char v193 = v22;
        unint64_t v198 = *i;
        if (!v20) {
          goto LABEL_398;
        }
        char v199 = v22;
        __int16 v200 = v20;
        do
        {
          unint64_t v201 = v200[4];
          BOOL v202 = v201 >= v198;
          if (v201 >= v198) {
            int v203 = v200;
          }
          else {
            int v203 = v200 + 1;
          }
          if (v202) {
            char v199 = v200;
          }
          __int16 v200 = (void *)*v203;
        }
        while (*v203);
        if (v199 == v22 || v199[4] > v198) {
LABEL_398:
        }
          char v199 = v22;
        unint64_t v204 = v193[5];
        unint64_t v205 = v199[5];
        if (v18 != v198 && v204 == v205)
        {
          if (*(void *)(*(void *)(v18 + 96) + 48) < *(void *)(*(void *)(v198 + 96) + 48)) {
            break;
          }
        }
        else if (v204 > v205)
        {
          break;
        }
      }
LABEL_271:
      char v146 = a2;
      if (i >= a2) {
        goto LABEL_303;
      }
      char v147 = a2;
      if (!v20)
      {
LABEL_283:
        char v148 = v22;
        goto LABEL_284;
      }
      while (1)
      {
        char v148 = v22;
        char v149 = v20;
        do
        {
          unint64_t v150 = v149[4];
          BOOL v151 = v150 >= v18;
          if (v150 >= v18) {
            char v152 = v149;
          }
          else {
            char v152 = v149 + 1;
          }
          if (v151) {
            char v148 = v149;
          }
          char v149 = (void *)*v152;
        }
        while (*v152);
        if (v148 == v22 || v148[4] > v18) {
          goto LABEL_283;
        }
LABEL_284:
        if (!v20) {
          goto LABEL_295;
        }
        char v153 = v22;
        char v154 = v20;
        do
        {
          unint64_t v155 = v154[4];
          BOOL v156 = v155 >= v123;
          if (v155 >= v123) {
            char v157 = v154;
          }
          else {
            char v157 = v154 + 1;
          }
          if (v156) {
            char v153 = v154;
          }
          char v154 = (void *)*v157;
        }
        while (*v157);
        if (v153 == v22 || v153[4] > v123) {
LABEL_295:
        }
          char v153 = v22;
        char v146 = v147 - 1;
        unint64_t v158 = v148[5];
        unint64_t v159 = v153[5];
        if (v18 != v123 && v158 == v159) {
          break;
        }
        if (v158 <= v159) {
          goto LABEL_303;
        }
LABEL_301:
        unint64_t v123 = *(v147 - 2);
        --v147;
        if (!v20) {
          goto LABEL_283;
        }
      }
      if (*(void *)(*(void *)(v18 + 96) + 48) < *(void *)(*(void *)(v123 + 96) + 48)) {
        goto LABEL_301;
      }
LABEL_303:
      if (i < v146)
      {
        unint64_t v160 = *i;
        unint64_t v161 = *v146;
        do
        {
          *unint64_t i = v161;
          *char v146 = v160;
          char v162 = (uint64_t *)(*a3 + 8);
          uint64_t v163 = *v162;
          do
          {
            while (1)
            {
              unint64_t v164 = i[1];
              ++i;
              unint64_t v160 = v164;
              if (!v163) {
                goto LABEL_317;
              }
              char v165 = (uint64_t *)(*a3 + 8);
              char v166 = (void *)*v165;
              do
              {
                unint64_t v167 = v166[4];
                BOOL v168 = v167 >= v18;
                if (v167 >= v18) {
                  char v169 = v166;
                }
                else {
                  char v169 = v166 + 1;
                }
                if (v168) {
                  char v165 = v166;
                }
                char v166 = (void *)*v169;
              }
              while (*v169);
              if (v165 == v162 || v165[4] > v18) {
LABEL_317:
              }
                char v165 = (uint64_t *)(*a3 + 8);
              if (!v163) {
                goto LABEL_329;
              }
              char v170 = (uint64_t *)(*a3 + 8);
              char v171 = (void *)*v170;
              do
              {
                unint64_t v172 = v171[4];
                BOOL v173 = v172 >= v160;
                if (v172 >= v160) {
                  char v174 = v171;
                }
                else {
                  char v174 = v171 + 1;
                }
                if (v173) {
                  char v170 = v171;
                }
                char v171 = (void *)*v174;
              }
              while (*v174);
              if (v170 == v162 || v170[4] > v160) {
LABEL_329:
              }
                char v170 = (uint64_t *)(*a3 + 8);
              unint64_t v175 = v165[5];
              unint64_t v176 = v170[5];
              if (v18 == v160 || v175 != v176) {
                break;
              }
              if (*(void *)(*(void *)(v18 + 96) + 48) < *(void *)(*(void *)(v160 + 96) + 48)) {
                goto LABEL_339;
              }
            }
          }
          while (v175 <= v176);
          do
          {
            while (1)
            {
LABEL_339:
              unint64_t v178 = *--v146;
              unint64_t v161 = v178;
              if (!v163) {
                goto LABEL_350;
              }
              __int16 v179 = (uint64_t *)(*a3 + 8);
              char v180 = (void *)*v179;
              do
              {
                unint64_t v181 = v180[4];
                BOOL v182 = v181 >= v18;
                if (v181 >= v18) {
                  char v183 = v180;
                }
                else {
                  char v183 = v180 + 1;
                }
                if (v182) {
                  __int16 v179 = v180;
                }
                char v180 = (void *)*v183;
              }
              while (*v183);
              if (v179 == v162 || v179[4] > v18) {
LABEL_350:
              }
                __int16 v179 = (uint64_t *)(*a3 + 8);
              if (!v163) {
                goto LABEL_362;
              }
              char v184 = (uint64_t *)(*a3 + 8);
              __int16 v185 = (void *)*v184;
              do
              {
                unint64_t v186 = v185[4];
                uint64_t result = v185 + 1;
                BOOL v187 = v186 >= v161;
                if (v186 >= v161) {
                  char v188 = v185;
                }
                else {
                  char v188 = v185 + 1;
                }
                if (v187) {
                  char v184 = v185;
                }
                __int16 v185 = (void *)*v188;
              }
              while (*v188);
              if (v184 == v162 || v184[4] > v161) {
LABEL_362:
              }
                char v184 = (uint64_t *)(*a3 + 8);
              unint64_t v189 = v179[5];
              unint64_t v190 = v184[5];
              if (v18 == v161 || v189 != v190) {
                break;
              }
              if (*(void *)(*(void *)(v18 + 96) + 48) >= *(void *)(*(void *)(v161 + 96) + 48)) {
                goto LABEL_368;
              }
            }
          }
          while (v189 > v190);
LABEL_368:
          ;
        }
        while (i < v146);
      }
      char v192 = i - 1;
      BOOL v5 = i - 1 >= v11;
      BOOL v6 = i - 1 == v11;
      if (i - 1 != v11) {
        unint64_t *v11 = *v192;
      }
      a5 = 0;
      *char v192 = v18;
    }
  }
  char v222 = i + 1;
  BOOL v224 = i == a2 || v222 == a2;
  if ((a5 & 1) == 0)
  {
    if (v224) {
      return result;
    }
    uint64_t v384 = *a3;
    while (1)
    {
      v385 = v11;
      unint64_t v11 = v222;
      unint64_t v386 = v385[1];
      v387 = (void *)(v384 + 8);
      v388 = *(void **)(v384 + 8);
      if (!v388) {
        goto LABEL_775;
      }
      v389 = (void *)(v384 + 8);
      v390 = *(void **)(v384 + 8);
      do
      {
        unint64_t v391 = v390[4];
        BOOL v392 = v391 >= v386;
        if (v391 >= v386) {
          v393 = v390;
        }
        else {
          v393 = v390 + 1;
        }
        if (v392) {
          v389 = v390;
        }
        v390 = (void *)*v393;
      }
      while (*v393);
      if (v389 == v387 || v389[4] > v386) {
LABEL_775:
      }
        v389 = (void *)(v384 + 8);
      unint64_t v394 = *v385;
      if (!v388) {
        goto LABEL_787;
      }
      v395 = (void *)(v384 + 8);
      do
      {
        unint64_t v396 = v388[4];
        BOOL v397 = v396 >= v394;
        if (v396 >= v394) {
          v398 = v388;
        }
        else {
          v398 = v388 + 1;
        }
        if (v397) {
          v395 = v388;
        }
        v388 = (void *)*v398;
      }
      while (*v398);
      if (v395 == v387 || v395[4] > v394) {
LABEL_787:
      }
        v395 = (void *)(v384 + 8);
      unint64_t v399 = v389[5];
      unint64_t v400 = v395[5];
      if (v386 != v394 && v399 == v400)
      {
        if (*(void *)(*(void *)(v386 + 96) + 48) >= *(void *)(*(void *)(v394 + 96) + 48)) {
          goto LABEL_828;
        }
      }
      else if (v399 <= v400)
      {
        goto LABEL_828;
      }
      v402 = v11;
      do
      {
        while (1)
        {
          unint64_t *v402 = v394;
          v402 = v385;
          v403 = (void *)(*a3 + 8);
          v404 = (void *)*v403;
          if (!*v403) {
            goto LABEL_807;
          }
          v405 = (void *)(*a3 + 8);
          v406 = (void *)*v405;
          do
          {
            unint64_t v407 = v406[4];
            BOOL v408 = v407 >= v386;
            if (v407 >= v386) {
              v409 = v406;
            }
            else {
              v409 = v406 + 1;
            }
            if (v408) {
              v405 = v406;
            }
            v406 = (void *)*v409;
          }
          while (*v409);
          if (v405 == v403 || v405[4] > v386) {
LABEL_807:
          }
            v405 = (void *)(*a3 + 8);
          v385 = v402 - 1;
          unint64_t v394 = *(v402 - 1);
          if (!v404) {
            goto LABEL_819;
          }
          uint64_t v410 = *a3 + 8;
          do
          {
            unint64_t v411 = v404[4];
            BOOL v412 = v411 >= v394;
            if (v411 >= v394) {
              v413 = v404;
            }
            else {
              v413 = v404 + 1;
            }
            if (v412) {
              uint64_t v410 = (uint64_t)v404;
            }
            v404 = (void *)*v413;
          }
          while (*v413);
          if ((void *)v410 == v403 || *(void *)(v410 + 32) > v394) {
LABEL_819:
          }
            uint64_t v410 = *a3 + 8;
          unint64_t v414 = v405[5];
          unint64_t v415 = *(void *)(v410 + 40);
          if (v386 != v394 && v414 == v415) {
            break;
          }
          if (v414 <= v415) {
            goto LABEL_827;
          }
        }
      }
      while (*(void *)(*(void *)(v386 + 96) + 48) < *(void *)(*(void *)(v394 + 96) + 48));
LABEL_827:
      unint64_t *v402 = v386;
      uint64_t v384 = *a3;
LABEL_828:
      char v222 = v11 + 1;
      if (v11 + 1 == a2) {
        return result;
      }
    }
  }
  if (v224) {
    return result;
  }
  uint64_t v225 = *a3;
  char v226 = i;
  while (2)
  {
    char v227 = v226;
    char v226 = v222;
    unint64_t v228 = v227[1];
    char v229 = (void *)(v225 + 8);
    char v230 = *(void **)(v225 + 8);
    if (!v230) {
      goto LABEL_467;
    }
    char v231 = (void *)(v225 + 8);
    char v232 = *(void **)(v225 + 8);
    do
    {
      unint64_t v233 = v232[4];
      BOOL v234 = v233 >= v228;
      if (v233 >= v228) {
        char v235 = v232;
      }
      else {
        char v235 = v232 + 1;
      }
      if (v234) {
        char v231 = v232;
      }
      char v232 = (void *)*v235;
    }
    while (*v235);
    if (v231 == v229 || v231[4] > v228) {
LABEL_467:
    }
      char v231 = (void *)(v225 + 8);
    unint64_t v236 = *v227;
    if (!v230) {
      goto LABEL_479;
    }
    int v237 = (void *)(v225 + 8);
    do
    {
      unint64_t v238 = v230[4];
      uint64_t result = v230 + 1;
      BOOL v239 = v238 >= v236;
      if (v238 >= v236) {
        long long v240 = v230;
      }
      else {
        long long v240 = v230 + 1;
      }
      if (v239) {
        int v237 = v230;
      }
      char v230 = (void *)*v240;
    }
    while (*v240);
    if (v237 == v229 || v237[4] > v236) {
LABEL_479:
    }
      int v237 = (void *)(v225 + 8);
    unint64_t v241 = v231[5];
    unint64_t v242 = v237[5];
    if (v228 != v236 && v241 == v242)
    {
      if (*(void *)(*(void *)(v228 + 96) + 48) >= *(void *)(*(void *)(v236 + 96) + 48)) {
        goto LABEL_523;
      }
    }
    else if (v241 <= v242)
    {
      goto LABEL_523;
    }
    v227[1] = v236;
    long long v244 = i;
    if (v227 == i) {
      goto LABEL_522;
    }
    while (2)
    {
      int v245 = (void *)(*a3 + 8);
      int v246 = (void *)*v245;
      if (!*v245) {
        goto LABEL_499;
      }
      long long v247 = (void *)(*a3 + 8);
      long long v248 = (void *)*v247;
      do
      {
        unint64_t v249 = v248[4];
        BOOL v250 = v249 >= v228;
        if (v249 >= v228) {
          int v251 = v248;
        }
        else {
          int v251 = v248 + 1;
        }
        if (v250) {
          long long v247 = v248;
        }
        long long v248 = (void *)*v251;
      }
      while (*v251);
      if (v247 == v245 || v247[4] > v228) {
LABEL_499:
      }
        long long v247 = (void *)(*a3 + 8);
      long long v252 = v227 - 1;
      unint64_t v253 = *(v227 - 1);
      if (!v246) {
        goto LABEL_511;
      }
      uint64_t v254 = *a3 + 8;
      do
      {
        unint64_t v255 = v246[4];
        uint64_t result = v246 + 1;
        BOOL v256 = v255 >= v253;
        if (v255 >= v253) {
          long long v257 = v246;
        }
        else {
          long long v257 = v246 + 1;
        }
        if (v256) {
          uint64_t v254 = (uint64_t)v246;
        }
        int v246 = (void *)*v257;
      }
      while (*v257);
      if ((void *)v254 == v245 || *(void *)(v254 + 32) > v253) {
LABEL_511:
      }
        uint64_t v254 = *a3 + 8;
      unint64_t v258 = v247[5];
      unint64_t v259 = *(void *)(v254 + 40);
      if (v228 == v253 || v258 != v259)
      {
        if (v258 <= v259) {
          break;
        }
        goto LABEL_519;
      }
      if (*(void *)(*(void *)(v228 + 96) + 48) < *(void *)(*(void *)(v253 + 96) + 48))
      {
LABEL_519:
        *v227-- = v253;
        if (v252 == i)
        {
          long long v244 = i;
          goto LABEL_522;
        }
        continue;
      }
      break;
    }
    long long v244 = v227;
LABEL_522:
    *long long v244 = v228;
    uint64_t v225 = *a3;
LABEL_523:
    char v222 = v226 + 1;
    if (v226 + 1 != a2) {
      continue;
    }
    return result;
  }
}

unint64_t *std::__sort5_maybe_branchless[abi:ne180100]<std::_ClassicAlgPolicy,ZinCpBasedAllocator::GetSortedNonResidentTensors(void)::$_0 &,ZinIrTensor **,0>(unint64_t *a1, unint64_t *a2, unint64_t *a3, unint64_t *a4, unint64_t *a5, void *a6)
{
  uint64_t result = std::__sort4[abi:ne180100]<std::_ClassicAlgPolicy,ZinCpBasedAllocator::GetSortedNonResidentTensors(void)::$_0 &,ZinIrTensor **>(a1, a2, a3, a4, a6);
  unint64_t v13 = *a5;
  unint64_t v14 = (void *)(*a6 + 8);
  unint64_t v15 = (void *)*v14;
  if (!*v14) {
    goto LABEL_12;
  }
  uint64_t v16 = (void *)(*a6 + 8);
  unint64_t v17 = (void *)*v16;
  do
  {
    unint64_t v18 = v17[4];
    BOOL v19 = v18 >= v13;
    if (v18 >= v13) {
      uint64_t v20 = v17;
    }
    else {
      uint64_t v20 = v17 + 1;
    }
    if (v19) {
      uint64_t v16 = v17;
    }
    unint64_t v17 = (void *)*v20;
  }
  while (*v20);
  if (v16 == v14 || v16[4] > v13) {
LABEL_12:
  }
    uint64_t v16 = (void *)(*a6 + 8);
  unint64_t v21 = *a4;
  if (!v15) {
    goto LABEL_24;
  }
  uint64_t v22 = *a6 + 8;
  do
  {
    unint64_t v23 = v15[4];
    BOOL v24 = v23 >= v21;
    if (v23 >= v21) {
      unint64_t v25 = v15;
    }
    else {
      unint64_t v25 = v15 + 1;
    }
    if (v24) {
      uint64_t v22 = (uint64_t)v15;
    }
    unint64_t v15 = (void *)*v25;
  }
  while (*v25);
  if ((void *)v22 == v14 || *(void *)(v22 + 32) > v21) {
LABEL_24:
  }
    uint64_t v22 = *a6 + 8;
  unint64_t v26 = v16[5];
  unint64_t v27 = *(void *)(v22 + 40);
  if (v13 == v21 || v26 != v27)
  {
    if (v26 <= v27) {
      return result;
    }
  }
  else if (*(void *)(*(void *)(v13 + 96) + 48) >= *(void *)(*(void *)(v21 + 96) + 48))
  {
    return result;
  }
  *a4 = v13;
  *a5 = v21;
  unint64_t v28 = *a4;
  BOOL v29 = (void *)(*a6 + 8);
  unint64_t v30 = (void *)*v29;
  if (!*v29) {
    goto LABEL_41;
  }
  BOOL v31 = (void *)(*a6 + 8);
  uint64_t v32 = (void *)*v31;
  do
  {
    unint64_t v33 = v32[4];
    BOOL v34 = v33 >= v28;
    if (v33 >= v28) {
      uint64_t v35 = v32;
    }
    else {
      uint64_t v35 = v32 + 1;
    }
    if (v34) {
      BOOL v31 = v32;
    }
    uint64_t v32 = (void *)*v35;
  }
  while (*v35);
  if (v31 == v29 || v31[4] > v28) {
LABEL_41:
  }
    BOOL v31 = (void *)(*a6 + 8);
  unint64_t v36 = *a3;
  if (!v30) {
    goto LABEL_53;
  }
  uint64_t v37 = *a6 + 8;
  do
  {
    unint64_t v38 = v30[4];
    BOOL v39 = v38 >= v36;
    if (v38 >= v36) {
      uint64_t v40 = v30;
    }
    else {
      uint64_t v40 = v30 + 1;
    }
    if (v39) {
      uint64_t v37 = (uint64_t)v30;
    }
    unint64_t v30 = (void *)*v40;
  }
  while (*v40);
  if ((void *)v37 == v29 || *(void *)(v37 + 32) > v36) {
LABEL_53:
  }
    uint64_t v37 = *a6 + 8;
  unint64_t v41 = v31[5];
  unint64_t v42 = *(void *)(v37 + 40);
  if (v28 == v36 || v41 != v42)
  {
    if (v41 <= v42) {
      return result;
    }
  }
  else if (*(void *)(*(void *)(v28 + 96) + 48) >= *(void *)(*(void *)(v36 + 96) + 48))
  {
    return result;
  }
  *a3 = v28;
  *a4 = v36;
  unint64_t v43 = *a3;
  __int16 v44 = (void *)(*a6 + 8);
  long long v45 = (void *)*v44;
  if (!*v44) {
    goto LABEL_70;
  }
  char v46 = (void *)(*a6 + 8);
  unint64_t v47 = (void *)*v46;
  do
  {
    unint64_t v48 = v47[4];
    BOOL v49 = v48 >= v43;
    if (v48 >= v43) {
      unint64_t v50 = v47;
    }
    else {
      unint64_t v50 = v47 + 1;
    }
    if (v49) {
      char v46 = v47;
    }
    unint64_t v47 = (void *)*v50;
  }
  while (*v50);
  if (v46 == v44 || v46[4] > v43) {
LABEL_70:
  }
    char v46 = (void *)(*a6 + 8);
  unint64_t v51 = *a2;
  if (!v45) {
    goto LABEL_82;
  }
  uint64_t v52 = *a6 + 8;
  do
  {
    unint64_t v53 = v45[4];
    BOOL v54 = v53 >= v51;
    if (v53 >= v51) {
      unint64_t v55 = v45;
    }
    else {
      unint64_t v55 = v45 + 1;
    }
    if (v54) {
      uint64_t v52 = (uint64_t)v45;
    }
    long long v45 = (void *)*v55;
  }
  while (*v55);
  if ((void *)v52 == v44 || *(void *)(v52 + 32) > v51) {
LABEL_82:
  }
    uint64_t v52 = *a6 + 8;
  unint64_t v56 = v46[5];
  unint64_t v57 = *(void *)(v52 + 40);
  if (v43 == v51 || v56 != v57)
  {
    if (v56 <= v57) {
      return result;
    }
  }
  else if (*(void *)(*(void *)(v43 + 96) + 48) >= *(void *)(*(void *)(v51 + 96) + 48))
  {
    return result;
  }
  *a2 = v43;
  *a3 = v51;
  unint64_t v58 = *a2;
  BOOL v59 = (void *)(*a6 + 8);
  long long v60 = (void *)*v59;
  if (!*v59) {
    goto LABEL_99;
  }
  long long v61 = (void *)(*a6 + 8);
  long long v62 = (void *)*v61;
  do
  {
    unint64_t v63 = v62[4];
    BOOL v64 = v63 >= v58;
    if (v63 >= v58) {
      int v65 = v62;
    }
    else {
      int v65 = v62 + 1;
    }
    if (v64) {
      long long v61 = v62;
    }
    long long v62 = (void *)*v65;
  }
  while (*v65);
  if (v61 == v59 || v61[4] > v58) {
LABEL_99:
  }
    long long v61 = (void *)(*a6 + 8);
  unint64_t v66 = *a1;
  if (!v60) {
    goto LABEL_111;
  }
  uint64_t v67 = *a6 + 8;
  do
  {
    unint64_t v68 = v60[4];
    BOOL v69 = v68 >= v66;
    if (v68 >= v66) {
      unint64_t v70 = v60;
    }
    else {
      unint64_t v70 = v60 + 1;
    }
    if (v69) {
      uint64_t v67 = (uint64_t)v60;
    }
    long long v60 = (void *)*v70;
  }
  while (*v70);
  if ((void *)v67 == v59 || *(void *)(v67 + 32) > v66) {
LABEL_111:
  }
    uint64_t v67 = *a6 + 8;
  unint64_t v71 = v61[5];
  unint64_t v72 = *(void *)(v67 + 40);
  if (v58 == v66 || v71 != v72)
  {
    if (v71 <= v72) {
      return result;
    }
  }
  else if (*(void *)(*(void *)(v58 + 96) + 48) >= *(void *)(*(void *)(v66 + 96) + 48))
  {
    return result;
  }
  *a1 = v58;
  *a2 = v66;
  return result;
}

unint64_t *std::__sort3[abi:ne180100]<std::_ClassicAlgPolicy,ZinCpBasedAllocator::GetSortedNonResidentTensors(void)::$_0 &,ZinIrTensor **>(unint64_t *result, unint64_t *a2, unint64_t *a3, void *a4)
{
  unint64_t v4 = *a2;
  BOOL v5 = (void *)(*a4 + 8);
  BOOL v6 = (void *)*v5;
  if (!*v5) {
    goto LABEL_12;
  }
  uint64_t v7 = (void *)(*a4 + 8);
  long long v8 = (void *)*v7;
  do
  {
    unint64_t v9 = v8[4];
    BOOL v10 = v9 >= v4;
    if (v9 >= v4) {
      unint64_t v11 = v8;
    }
    else {
      unint64_t v11 = v8 + 1;
    }
    if (v10) {
      uint64_t v7 = v8;
    }
    long long v8 = (void *)*v11;
  }
  while (*v11);
  if (v7 == v5 || v7[4] > v4) {
LABEL_12:
  }
    uint64_t v7 = (void *)(*a4 + 8);
  unint64_t v12 = *result;
  if (!v6) {
    goto LABEL_24;
  }
  unint64_t v13 = (void *)(*a4 + 8);
  unint64_t v14 = (void *)*v13;
  do
  {
    unint64_t v15 = v14[4];
    BOOL v16 = v15 >= v12;
    if (v15 >= v12) {
      unint64_t v17 = v14;
    }
    else {
      unint64_t v17 = v14 + 1;
    }
    if (v16) {
      unint64_t v13 = v14;
    }
    unint64_t v14 = (void *)*v17;
  }
  while (*v17);
  if (v13 == v5 || v13[4] > v12) {
LABEL_24:
  }
    unint64_t v13 = (void *)(*a4 + 8);
  unint64_t v18 = v7[5];
  unint64_t v19 = v13[5];
  if (v4 == v12 || v18 != v19)
  {
    if (v18 <= v19) {
      goto LABEL_30;
    }
LABEL_59:
    unint64_t v33 = *a3;
    if (!v6) {
      goto LABEL_70;
    }
    BOOL v34 = (void *)(*a4 + 8);
    uint64_t v35 = (void *)*v34;
    do
    {
      unint64_t v36 = v35[4];
      BOOL v37 = v36 >= v33;
      if (v36 >= v33) {
        unint64_t v38 = v35;
      }
      else {
        unint64_t v38 = v35 + 1;
      }
      if (v37) {
        BOOL v34 = v35;
      }
      uint64_t v35 = (void *)*v38;
    }
    while (*v38);
    if (v34 == v5 || v34[4] > v33) {
LABEL_70:
    }
      BOOL v34 = (void *)(*a4 + 8);
    if (!v6) {
      goto LABEL_82;
    }
    uint64_t v39 = *a4 + 8;
    do
    {
      unint64_t v40 = v6[4];
      BOOL v41 = v40 >= v4;
      if (v40 >= v4) {
        unint64_t v42 = v6;
      }
      else {
        unint64_t v42 = v6 + 1;
      }
      if (v41) {
        uint64_t v39 = (uint64_t)v6;
      }
      BOOL v6 = (void *)*v42;
    }
    while (*v42);
    if ((void *)v39 == v5 || *(void *)(v39 + 32) > v4) {
LABEL_82:
    }
      uint64_t v39 = *a4 + 8;
    unint64_t v43 = v34[5];
    unint64_t v44 = *(void *)(v39 + 40);
    if (v33 == v4 || v43 != v44)
    {
      if (v43 > v44) {
        goto LABEL_86;
      }
    }
    else if (*(void *)(*(void *)(v33 + 96) + 48) < *(void *)(*(void *)(v4 + 96) + 48))
    {
LABEL_86:
      *uint64_t result = v33;
      goto LABEL_149;
    }
    *uint64_t result = v4;
    *a2 = v12;
    unint64_t v60 = *a3;
    long long v61 = (void *)(*a4 + 8);
    long long v62 = (void *)*v61;
    if (!*v61) {
      goto LABEL_128;
    }
    unint64_t v63 = (void *)(*a4 + 8);
    BOOL v64 = (void *)*v63;
    do
    {
      unint64_t v65 = v64[4];
      BOOL v66 = v65 >= v60;
      if (v65 >= v60) {
        uint64_t v67 = v64;
      }
      else {
        uint64_t v67 = v64 + 1;
      }
      if (v66) {
        unint64_t v63 = v64;
      }
      BOOL v64 = (void *)*v67;
    }
    while (*v67);
    if (v63 == v61 || v63[4] > v60) {
LABEL_128:
    }
      unint64_t v63 = (void *)(*a4 + 8);
    if (!v62) {
      goto LABEL_140;
    }
    uint64_t v68 = *a4 + 8;
    do
    {
      unint64_t v69 = v62[4];
      BOOL v70 = v69 >= v12;
      if (v69 >= v12) {
        unint64_t v71 = v62;
      }
      else {
        unint64_t v71 = v62 + 1;
      }
      if (v70) {
        uint64_t v68 = (uint64_t)v62;
      }
      long long v62 = (void *)*v71;
    }
    while (*v71);
    if ((void *)v68 == v61 || *(void *)(v68 + 32) > v12) {
LABEL_140:
    }
      uint64_t v68 = *a4 + 8;
    unint64_t v72 = v63[5];
    unint64_t v73 = *(void *)(v68 + 40);
    if (v60 == v12 || v72 != v73)
    {
      if (v72 <= v73) {
        return result;
      }
    }
    else if (*(void *)(*(void *)(v60 + 96) + 48) >= *(void *)(*(void *)(v12 + 96) + 48))
    {
      return result;
    }
    *a2 = v60;
LABEL_149:
    *a3 = v12;
    return result;
  }
  if (*(void *)(*(void *)(v4 + 96) + 48) < *(void *)(*(void *)(v12 + 96) + 48)) {
    goto LABEL_59;
  }
LABEL_30:
  unint64_t v21 = *a3;
  if (!v6) {
    goto LABEL_41;
  }
  uint64_t v22 = (void *)(*a4 + 8);
  unint64_t v23 = (void *)*v22;
  do
  {
    unint64_t v24 = v23[4];
    BOOL v25 = v24 >= v21;
    if (v24 >= v21) {
      unint64_t v26 = v23;
    }
    else {
      unint64_t v26 = v23 + 1;
    }
    if (v25) {
      uint64_t v22 = v23;
    }
    unint64_t v23 = (void *)*v26;
  }
  while (*v26);
  if (v22 == v5 || v22[4] > v21) {
LABEL_41:
  }
    uint64_t v22 = (void *)(*a4 + 8);
  if (!v6) {
    goto LABEL_53;
  }
  uint64_t v27 = *a4 + 8;
  do
  {
    unint64_t v28 = v6[4];
    BOOL v29 = v28 >= v4;
    if (v28 >= v4) {
      unint64_t v30 = v6;
    }
    else {
      unint64_t v30 = v6 + 1;
    }
    if (v29) {
      uint64_t v27 = (uint64_t)v6;
    }
    BOOL v6 = (void *)*v30;
  }
  while (*v30);
  if ((void *)v27 == v5 || *(void *)(v27 + 32) > v4) {
LABEL_53:
  }
    uint64_t v27 = *a4 + 8;
  unint64_t v31 = v22[5];
  unint64_t v32 = *(void *)(v27 + 40);
  if (v21 == v4 || v31 != v32)
  {
    if (v31 <= v32) {
      return result;
    }
  }
  else if (*(void *)(*(void *)(v21 + 96) + 48) >= *(void *)(*(void *)(v4 + 96) + 48))
  {
    return result;
  }
  *a2 = v21;
  *a3 = v4;
  unint64_t v45 = *a2;
  char v46 = (void *)(*a4 + 8);
  unint64_t v47 = (void *)*v46;
  if (!*v46) {
    goto LABEL_99;
  }
  unint64_t v48 = (void *)(*a4 + 8);
  BOOL v49 = (void *)*v48;
  do
  {
    unint64_t v50 = v49[4];
    BOOL v51 = v50 >= v45;
    if (v50 >= v45) {
      uint64_t v52 = v49;
    }
    else {
      uint64_t v52 = v49 + 1;
    }
    if (v51) {
      unint64_t v48 = v49;
    }
    BOOL v49 = (void *)*v52;
  }
  while (*v52);
  if (v48 == v46 || v48[4] > v45) {
LABEL_99:
  }
    unint64_t v48 = (void *)(*a4 + 8);
  unint64_t v53 = *result;
  if (!v47) {
    goto LABEL_111;
  }
  uint64_t v54 = *a4 + 8;
  do
  {
    unint64_t v55 = v47[4];
    BOOL v56 = v55 >= v53;
    if (v55 >= v53) {
      unint64_t v57 = v47;
    }
    else {
      unint64_t v57 = v47 + 1;
    }
    if (v56) {
      uint64_t v54 = (uint64_t)v47;
    }
    unint64_t v47 = (void *)*v57;
  }
  while (*v57);
  if ((void *)v54 == v46 || *(void *)(v54 + 32) > v53) {
LABEL_111:
  }
    uint64_t v54 = *a4 + 8;
  unint64_t v58 = v48[5];
  unint64_t v59 = *(void *)(v54 + 40);
  if (v45 == v53 || v58 != v59)
  {
    if (v58 > v59)
    {
LABEL_146:
      *uint64_t result = v45;
      *a2 = v53;
    }
  }
  else if (*(void *)(*(void *)(v45 + 96) + 48) < *(void *)(*(void *)(v53 + 96) + 48))
  {
    goto LABEL_146;
  }
  return result;
}

BOOL std::__insertion_sort_incomplete[abi:ne180100]<std::_ClassicAlgPolicy,ZinCpBasedAllocator::GetSortedNonResidentTensors(void)::$_0 &,ZinIrTensor **>(unint64_t *a1, unint64_t *a2, void *a3)
{
  uint64_t v6 = a2 - a1;
  BOOL result = 1;
  switch(v6)
  {
    case 0:
    case 1:
      return result;
    case 2:
      unint64_t v8 = *(a2 - 1);
      unint64_t v9 = (void *)(*a3 + 8);
      BOOL v10 = (void *)*v9;
      if (!*v9) {
        goto LABEL_13;
      }
      unint64_t v11 = (void *)(*a3 + 8);
      unint64_t v12 = (void *)*v11;
      do
      {
        unint64_t v13 = v12[4];
        BOOL v14 = v13 >= v8;
        if (v13 >= v8) {
          unint64_t v15 = v12;
        }
        else {
          unint64_t v15 = v12 + 1;
        }
        if (v14) {
          unint64_t v11 = v12;
        }
        unint64_t v12 = (void *)*v15;
      }
      while (*v15);
      if (v11 == v9 || v11[4] > v8) {
LABEL_13:
      }
        unint64_t v11 = (void *)(*a3 + 8);
      unint64_t v16 = *a1;
      if (!v10) {
        goto LABEL_25;
      }
      uint64_t v17 = *a3 + 8;
      do
      {
        unint64_t v18 = v10[4];
        BOOL v19 = v18 >= v16;
        if (v18 >= v16) {
          uint64_t v20 = v10;
        }
        else {
          uint64_t v20 = v10 + 1;
        }
        if (v19) {
          uint64_t v17 = (uint64_t)v10;
        }
        BOOL v10 = (void *)*v20;
      }
      while (*v20);
      if ((void *)v17 == v9 || *(void *)(v17 + 32) > v16) {
LABEL_25:
      }
        uint64_t v17 = *a3 + 8;
      unint64_t v21 = v11[5];
      unint64_t v22 = *(void *)(v17 + 40);
      if (v8 == v16 || v21 != v22)
      {
        if (v21 <= v22) {
          return 1;
        }
      }
      else if (*(void *)(*(void *)(v8 + 96) + 48) >= *(void *)(*(void *)(v16 + 96) + 48))
      {
        return 1;
      }
      *a1 = v8;
      *(a2 - 1) = v16;
      return 1;
    case 3:
      std::__sort3[abi:ne180100]<std::_ClassicAlgPolicy,ZinCpBasedAllocator::GetSortedNonResidentTensors(void)::$_0 &,ZinIrTensor **>(a1, a1 + 1, a2 - 1, a3);
      return 1;
    case 4:
      std::__sort4[abi:ne180100]<std::_ClassicAlgPolicy,ZinCpBasedAllocator::GetSortedNonResidentTensors(void)::$_0 &,ZinIrTensor **>(a1, a1 + 1, a1 + 2, a2 - 1, a3);
      return 1;
    case 5:
      std::__sort5_maybe_branchless[abi:ne180100]<std::_ClassicAlgPolicy,ZinCpBasedAllocator::GetSortedNonResidentTensors(void)::$_0 &,ZinIrTensor **,0>(a1, a1 + 1, a1 + 2, a1 + 3, a2 - 1, a3);
      return 1;
    default:
      unint64_t v23 = a1 + 2;
      std::__sort3[abi:ne180100]<std::_ClassicAlgPolicy,ZinCpBasedAllocator::GetSortedNonResidentTensors(void)::$_0 &,ZinIrTensor **>(a1, a1 + 1, a1 + 2, a3);
      unint64_t v24 = a1 + 3;
      if (a1 + 3 == a2) {
        return 1;
      }
      int v25 = 0;
      break;
  }
  while (2)
  {
    unint64_t v26 = *v24;
    uint64_t v27 = (void *)(*a3 + 8);
    unint64_t v28 = (void *)*v27;
    if (!*v27) {
      goto LABEL_43;
    }
    BOOL v29 = (void *)(*a3 + 8);
    unint64_t v30 = (void *)*v29;
    do
    {
      unint64_t v31 = v30[4];
      BOOL v32 = v31 >= v26;
      if (v31 >= v26) {
        unint64_t v33 = v30;
      }
      else {
        unint64_t v33 = v30 + 1;
      }
      if (v32) {
        BOOL v29 = v30;
      }
      unint64_t v30 = (void *)*v33;
    }
    while (*v33);
    if (v29 == v27 || v29[4] > v26) {
LABEL_43:
    }
      BOOL v29 = (void *)(*a3 + 8);
    unint64_t v34 = *v23;
    if (!v28) {
      goto LABEL_55;
    }
    uint64_t v35 = *a3 + 8;
    do
    {
      unint64_t v36 = v28[4];
      BOOL v37 = v36 >= v34;
      if (v36 >= v34) {
        unint64_t v38 = v28;
      }
      else {
        unint64_t v38 = v28 + 1;
      }
      if (v37) {
        uint64_t v35 = (uint64_t)v28;
      }
      unint64_t v28 = (void *)*v38;
    }
    while (*v38);
    if ((void *)v35 == v27 || *(void *)(v35 + 32) > v34) {
LABEL_55:
    }
      uint64_t v35 = *a3 + 8;
    unint64_t v39 = v29[5];
    unint64_t v40 = *(void *)(v35 + 40);
    if (v26 != v34 && v39 == v40)
    {
      if (*(void *)(*(void *)(v26 + 96) + 48) >= *(void *)(*(void *)(v34 + 96) + 48)) {
        goto LABEL_99;
      }
    }
    else if (v39 <= v40)
    {
      goto LABEL_99;
    }
    *unint64_t v24 = v34;
    unint64_t v42 = a1;
    if (v23 == a1) {
      goto LABEL_98;
    }
    while (1)
    {
      unint64_t v43 = (void *)(*a3 + 8);
      unint64_t v44 = (void *)*v43;
      if (!*v43) {
        goto LABEL_75;
      }
      unint64_t v45 = (void *)(*a3 + 8);
      char v46 = (void *)*v45;
      do
      {
        unint64_t v47 = v46[4];
        BOOL v48 = v47 >= v26;
        if (v47 >= v26) {
          BOOL v49 = v46;
        }
        else {
          BOOL v49 = v46 + 1;
        }
        if (v48) {
          unint64_t v45 = v46;
        }
        char v46 = (void *)*v49;
      }
      while (*v49);
      if (v45 == v43 || v45[4] > v26) {
LABEL_75:
      }
        unint64_t v45 = (void *)(*a3 + 8);
      unint64_t v50 = v23 - 1;
      unint64_t v51 = *(v23 - 1);
      if (!v44) {
        goto LABEL_87;
      }
      uint64_t v52 = *a3 + 8;
      do
      {
        unint64_t v53 = v44[4];
        BOOL v54 = v53 >= v51;
        if (v53 >= v51) {
          unint64_t v55 = v44;
        }
        else {
          unint64_t v55 = v44 + 1;
        }
        if (v54) {
          uint64_t v52 = (uint64_t)v44;
        }
        unint64_t v44 = (void *)*v55;
      }
      while (*v55);
      if ((void *)v52 == v43 || *(void *)(v52 + 32) > v51) {
LABEL_87:
      }
        uint64_t v52 = *a3 + 8;
      unint64_t v56 = v45[5];
      unint64_t v57 = *(void *)(v52 + 40);
      if (v26 != v51 && v56 == v57) {
        break;
      }
      if (v56 <= v57) {
        goto LABEL_97;
      }
LABEL_95:
      *v23-- = v51;
      if (v50 == a1)
      {
        unint64_t v42 = a1;
        goto LABEL_98;
      }
    }
    if (*(void *)(*(void *)(v26 + 96) + 48) < *(void *)(*(void *)(v51 + 96) + 48)) {
      goto LABEL_95;
    }
LABEL_97:
    unint64_t v42 = v23;
LABEL_98:
    *unint64_t v42 = v26;
    if (++v25 != 8)
    {
LABEL_99:
      unint64_t v23 = v24++;
      if (v24 == a2) {
        return 1;
      }
      continue;
    }
    return v24 + 1 == a2;
  }
}

unint64_t *std::__sort4[abi:ne180100]<std::_ClassicAlgPolicy,ZinCpBasedAllocator::GetSortedNonResidentTensors(void)::$_0 &,ZinIrTensor **>(unint64_t *a1, unint64_t *a2, unint64_t *a3, unint64_t *a4, void *a5)
{
  BOOL result = std::__sort3[abi:ne180100]<std::_ClassicAlgPolicy,ZinCpBasedAllocator::GetSortedNonResidentTensors(void)::$_0 &,ZinIrTensor **>(a1, a2, a3, a5);
  unint64_t v11 = *a4;
  unint64_t v12 = (void *)(*a5 + 8);
  unint64_t v13 = (void *)*v12;
  if (!*v12) {
    goto LABEL_12;
  }
  BOOL v14 = (void *)(*a5 + 8);
  unint64_t v15 = (void *)*v14;
  do
  {
    unint64_t v16 = v15[4];
    BOOL v17 = v16 >= v11;
    if (v16 >= v11) {
      unint64_t v18 = v15;
    }
    else {
      unint64_t v18 = v15 + 1;
    }
    if (v17) {
      BOOL v14 = v15;
    }
    unint64_t v15 = (void *)*v18;
  }
  while (*v18);
  if (v14 == v12 || v14[4] > v11) {
LABEL_12:
  }
    BOOL v14 = (void *)(*a5 + 8);
  unint64_t v19 = *a3;
  if (!v13) {
    goto LABEL_24;
  }
  uint64_t v20 = *a5 + 8;
  do
  {
    unint64_t v21 = v13[4];
    BOOL v22 = v21 >= v19;
    if (v21 >= v19) {
      unint64_t v23 = v13;
    }
    else {
      unint64_t v23 = v13 + 1;
    }
    if (v22) {
      uint64_t v20 = (uint64_t)v13;
    }
    unint64_t v13 = (void *)*v23;
  }
  while (*v23);
  if ((void *)v20 == v12 || *(void *)(v20 + 32) > v19) {
LABEL_24:
  }
    uint64_t v20 = *a5 + 8;
  unint64_t v24 = v14[5];
  unint64_t v25 = *(void *)(v20 + 40);
  if (v11 == v19 || v24 != v25)
  {
    if (v24 <= v25) {
      return result;
    }
  }
  else if (*(void *)(*(void *)(v11 + 96) + 48) >= *(void *)(*(void *)(v19 + 96) + 48))
  {
    return result;
  }
  *a3 = v11;
  *a4 = v19;
  unint64_t v26 = *a3;
  uint64_t v27 = (void *)(*a5 + 8);
  unint64_t v28 = (void *)*v27;
  if (!*v27) {
    goto LABEL_41;
  }
  BOOL v29 = (void *)(*a5 + 8);
  unint64_t v30 = (void *)*v29;
  do
  {
    unint64_t v31 = v30[4];
    BOOL v32 = v31 >= v26;
    if (v31 >= v26) {
      unint64_t v33 = v30;
    }
    else {
      unint64_t v33 = v30 + 1;
    }
    if (v32) {
      BOOL v29 = v30;
    }
    unint64_t v30 = (void *)*v33;
  }
  while (*v33);
  if (v29 == v27 || v29[4] > v26) {
LABEL_41:
  }
    BOOL v29 = (void *)(*a5 + 8);
  unint64_t v34 = *a2;
  if (!v28) {
    goto LABEL_53;
  }
  uint64_t v35 = *a5 + 8;
  do
  {
    unint64_t v36 = v28[4];
    BOOL v37 = v36 >= v34;
    if (v36 >= v34) {
      unint64_t v38 = v28;
    }
    else {
      unint64_t v38 = v28 + 1;
    }
    if (v37) {
      uint64_t v35 = (uint64_t)v28;
    }
    unint64_t v28 = (void *)*v38;
  }
  while (*v38);
  if ((void *)v35 == v27 || *(void *)(v35 + 32) > v34) {
LABEL_53:
  }
    uint64_t v35 = *a5 + 8;
  unint64_t v39 = v29[5];
  unint64_t v40 = *(void *)(v35 + 40);
  if (v26 == v34 || v39 != v40)
  {
    if (v39 <= v40) {
      return result;
    }
  }
  else if (*(void *)(*(void *)(v26 + 96) + 48) >= *(void *)(*(void *)(v34 + 96) + 48))
  {
    return result;
  }
  *a2 = v26;
  *a3 = v34;
  unint64_t v41 = *a2;
  unint64_t v42 = (void *)(*a5 + 8);
  unint64_t v43 = (void *)*v42;
  if (!*v42) {
    goto LABEL_70;
  }
  unint64_t v44 = (void *)(*a5 + 8);
  unint64_t v45 = (void *)*v44;
  do
  {
    unint64_t v46 = v45[4];
    BOOL v47 = v46 >= v41;
    if (v46 >= v41) {
      BOOL v48 = v45;
    }
    else {
      BOOL v48 = v45 + 1;
    }
    if (v47) {
      unint64_t v44 = v45;
    }
    unint64_t v45 = (void *)*v48;
  }
  while (*v48);
  if (v44 == v42 || v44[4] > v41) {
LABEL_70:
  }
    unint64_t v44 = (void *)(*a5 + 8);
  unint64_t v49 = *a1;
  if (!v43) {
    goto LABEL_82;
  }
  uint64_t v50 = *a5 + 8;
  do
  {
    unint64_t v51 = v43[4];
    BOOL v52 = v51 >= v49;
    if (v51 >= v49) {
      unint64_t v53 = v43;
    }
    else {
      unint64_t v53 = v43 + 1;
    }
    if (v52) {
      uint64_t v50 = (uint64_t)v43;
    }
    unint64_t v43 = (void *)*v53;
  }
  while (*v53);
  if ((void *)v50 == v42 || *(void *)(v50 + 32) > v49) {
LABEL_82:
  }
    uint64_t v50 = *a5 + 8;
  unint64_t v54 = v44[5];
  unint64_t v55 = *(void *)(v50 + 40);
  if (v41 == v49 || v54 != v55)
  {
    if (v54 <= v55) {
      return result;
    }
  }
  else if (*(void *)(*(void *)(v41 + 96) + 48) >= *(void *)(*(void *)(v49 + 96) + 48))
  {
    return result;
  }
  *a1 = v41;
  *a2 = v49;
  return result;
}

uint64_t std::__split_buffer<std::unique_ptr<L2CycleEstimator>>::~__split_buffer(uint64_t a1)
{
  uint64_t v3 = *(void *)(a1 + 8);
  for (uint64_t i = *(void *)(a1 + 16); i != v3; uint64_t i = *(void *)(a1 + 16))
  {
    *(void *)(a1 + 16) = i - 8;
    std::unique_ptr<L2CycleEstimator>::reset[abi:ne180100]((void ***)(i - 8), 0);
  }
  if (*(void *)a1) {
    operator delete(*(void **)a1);
  }
  return a1;
}

uint64_t std::__hash_table<std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>>>::~__hash_table(uint64_t a1)
{
  std::__hash_table<std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>>>::__deallocate_node(a1, *(LayerCycleAndFootprintEstimator ***)(a1 + 16));
  uint64_t v2 = *(void **)a1;
  *(void *)a1 = 0;
  if (v2) {
    operator delete(v2);
  }
  return a1;
}

void std::__hash_table<std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>>>::__deallocate_node(uint64_t a1, LayerCycleAndFootprintEstimator **a2)
{
  if (a2)
  {
    uint64_t v2 = a2;
    do
    {
      uint64_t v3 = *v2;
      std::unique_ptr<LayerCycleAndFootprintEstimator>::reset[abi:ne180100](v2 + 3, 0);
      operator delete(v2);
      uint64_t v2 = (LayerCycleAndFootprintEstimator **)v3;
    }
    while (v3);
  }
}

uint64_t std::__assoc_sub_state::__execute(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 24))();
}

void std::__async_assoc_state<ZinCpBasedAllocator::Execute(void)::CpRegionAllocationResult,std::__async_func<ZinCpBasedAllocator::Execute(void)::$_0,std::vector<std::vector<ZinANELayer const*>>,unsigned long,unsigned long,BOOL>>::~__async_assoc_state(uint64_t a1)
{
  *(void *)a1 = &unk_26C333AA0;
  uint64_t v2 = (void **)(a1 + 200);
  std::vector<std::vector<ZinIrOpLayer *>>::__destroy_vector::operator()[abi:ne180100](&v2);
  *(void *)a1 = MEMORY[0x263F8C320] + 16;
  std::condition_variable::~condition_variable((std::condition_variable *)(a1 + 88));
  std::mutex::~mutex((std::mutex *)(a1 + 24));
  std::exception_ptr::~exception_ptr((std::exception_ptr *)(a1 + 16));
  std::__shared_count::~__shared_count((std::__shared_count *)a1);
}

uint64_t std::__async_assoc_state<ZinCpBasedAllocator::Execute(void)::CpRegionAllocationResult,std::__async_func<ZinCpBasedAllocator::Execute(void)::$_0,std::vector<std::vector<ZinANELayer const*>>,unsigned long,unsigned long,BOOL>>::~__async_assoc_state(uint64_t a1)
{
  *(void *)a1 = &unk_26C333AA0;
  uint64_t v3 = (void **)(a1 + 200);
  std::vector<std::vector<ZinIrOpLayer *>>::__destroy_vector::operator()[abi:ne180100](&v3);
  *(void *)a1 = MEMORY[0x263F8C320] + 16;
  std::condition_variable::~condition_variable((std::condition_variable *)(a1 + 88));
  std::mutex::~mutex((std::mutex *)(a1 + 24));
  std::exception_ptr::~exception_ptr((std::exception_ptr *)(a1 + 16));
  std::__shared_count::~__shared_count((std::__shared_count *)a1);
  return MEMORY[0x21667D3C0]();
}

uint64_t std::__async_assoc_state<ZinCpBasedAllocator::Execute(void)::CpRegionAllocationResult,std::__async_func<ZinCpBasedAllocator::Execute(void)::$_0,std::vector<std::vector<ZinANELayer const*>>,unsigned long,unsigned long,BOOL>>::__on_zero_shared(std::__assoc_sub_state *a1)
{
  std::__assoc_sub_state::wait(a1);

  return std::__assoc_state<ZinCpBasedAllocator::Execute(void)::CpRegionAllocationResult>::__on_zero_shared(a1);
}

uint64_t std::__async_assoc_state<ZinCpBasedAllocator::Execute(void)::CpRegionAllocationResult,std::__async_func<ZinCpBasedAllocator::Execute(void)::$_0,std::vector<std::vector<ZinANELayer const*>>,unsigned long,unsigned long,BOOL>>::__execute(uint64_t a1)
{
  ZinCpBasedAllocator::Execute(void)::$_0::operator()(*(void *)(a1 + 224), (_DWORD **)(a1 + 192), *(void *)(a1 + 232), (uint64_t)v3);
  std::__assoc_state<ZinCpBasedAllocator::Execute(void)::CpRegionAllocationResult>::set_value<ZinCpBasedAllocator::Execute(void)::CpRegionAllocationResult>(a1, (uint64_t)v3);
  return std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v3);
}

void sub_211386724(void *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, std::exception_ptr a10, char a11)
{
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&a11);
  __cxa_begin_catch(a1);
  std::current_exception();
  v13.__ptr_ = &a10;
  std::__assoc_sub_state::set_exception(v11, v13);
  std::exception_ptr::~exception_ptr(&a10);
  __cxa_end_catch();
  JUMPOUT(0x211386714);
}

void sub_211386764(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, std::exception_ptr a10)
{
}

uint64_t std::__assoc_state<ZinCpBasedAllocator::Execute(void)::CpRegionAllocationResult>::__on_zero_shared(unsigned char *a1)
{
  if (a1[136]) {
    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)(a1 + 144));
  }
  uint64_t v2 = *(uint64_t (**)(unsigned char *))(*(void *)a1 + 8);

  return v2(a1);
}

void std::__assoc_state<ZinCpBasedAllocator::Execute(void)::CpRegionAllocationResult>::set_value<ZinCpBasedAllocator::Execute(void)::CpRegionAllocationResult>(uint64_t a1, uint64_t a2)
{
  unint64_t v4 = (std::mutex *)(a1 + 24);
  std::mutex::lock((std::mutex *)(a1 + 24));
  if ((*(unsigned char *)(a1 + 136) & 1) != 0
    || (v7.__ptr_ = 0, uint64_t v5 = *(void *)(a1 + 16), std::exception_ptr::~exception_ptr(&v7), v5))
  {
    std::__throw_future_error[abi:ne180100](2u);
  }
  std::__hash_table<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::__unordered_map_hasher<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::hash<long>,std::equal_to<long>,true>,std::__unordered_map_equal<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::equal_to<long>,std::hash<long>,true>,std::allocator<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>>>::__hash_table(a1 + 144, (uint64_t *)a2);
  int v6 = *(_DWORD *)(a2 + 40);
  *(unsigned char *)(a1 + 188) = *(unsigned char *)(a2 + 44);
  *(_DWORD *)(a1 + 184) = v6;
  *(_DWORD *)(a1 + 136) |= 5u;
  std::condition_variable::notify_all((std::condition_variable *)(a1 + 88));
  std::mutex::unlock(v4);
}

void sub_211386888(_Unwind_Exception *a1)
{
  std::mutex::unlock(v1);
  _Unwind_Resume(a1);
}

void std::__throw_future_error[abi:ne180100](unsigned int a1)
{
  exception = __cxa_allocate_exception(0x20uLL);
  uint64_t v3 = std::future_category();
  MEMORY[0x21667CDA0](exception, a1, v3);
  __cxa_throw(exception, MEMORY[0x263F8C1A0], MEMORY[0x263F8C0C0]);
}

void sub_2113868F0(_Unwind_Exception *a1)
{
  __cxa_free_exception(v1);
  _Unwind_Resume(a1);
}

uint64_t std::__thread_proxy[abi:ne180100]<std::tuple<std::unique_ptr<std::__thread_struct>,void (std::__async_assoc_state<ZinCpBasedAllocator::Execute(void)::CpRegionAllocationResult,std::__async_func<ZinCpBasedAllocator::Execute(void)::$_0,std::vector<std::vector<ZinANELayer const*>>,unsigned long,unsigned long,BOOL>>::*)(void),std::__async_assoc_state<ZinCpBasedAllocator::Execute(void)::CpRegionAllocationResult,std::__async_func<ZinCpBasedAllocator::Execute(void)::$_0,std::vector<std::vector<ZinANELayer const*>>,unsigned long,unsigned long,BOOL>>*>>(uint64_t *a1)
{
  std::exception_ptr v7 = (const void **)a1;
  uint64_t v1 = std::__thread_local_data();
  uint64_t v2 = *v7;
  void *v7 = 0;
  pthread_setspecific(v1->__key_, v2);
  uint64_t v3 = (void (*)(void *))v7[1];
  uint64_t v4 = (uint64_t)v7[2];
  uint64_t v5 = (char *)v7[3] + (v4 >> 1);
  if (v4) {
    uint64_t v3 = *(void (**)(void *))(*v5 + v3);
  }
  v3(v5);
  std::unique_ptr<std::tuple<std::unique_ptr<std::__thread_struct>,void (std::__async_assoc_state<ZinCpBasedAllocator::Execute(void)::CpRegionAllocationResult,std::__async_func<ZinCpBasedAllocator::Execute(void)::$_0,std::vector<std::vector<ZinANELayer const*>>,unsigned long,unsigned long,BOOL>>::*)(void),std::__async_assoc_state<ZinCpBasedAllocator::Execute(void)::CpRegionAllocationResult,std::__async_func<ZinCpBasedAllocator::Execute(void)::$_0,std::vector<std::vector<ZinANELayer const*>>,unsigned long,unsigned long,BOOL>>*>>::~unique_ptr[abi:ne180100]((uint64_t **)&v7);
  return 0;
}

void sub_21138699C(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::unique_ptr<std::tuple<std::unique_ptr<std::__thread_struct>,void (std::__async_assoc_state<ZinCpBasedAllocator::Execute(void)::CpRegionAllocationResult,std::__async_func<ZinCpBasedAllocator::Execute(void)::$_0,std::vector<std::vector<ZinANELayer const*>>,unsigned long,unsigned long,BOOL>>::*)(void),std::__async_assoc_state<ZinCpBasedAllocator::Execute(void)::CpRegionAllocationResult,std::__async_func<ZinCpBasedAllocator::Execute(void)::$_0,std::vector<std::vector<ZinANELayer const*>>,unsigned long,unsigned long,BOOL>>*>>::~unique_ptr[abi:ne180100]((uint64_t **)va);
  _Unwind_Resume(a1);
}

uint64_t **std::unique_ptr<std::tuple<std::unique_ptr<std::__thread_struct>,void (std::__async_assoc_state<ZinCpBasedAllocator::Execute(void)::CpRegionAllocationResult,std::__async_func<ZinCpBasedAllocator::Execute(void)::$_0,std::vector<std::vector<ZinANELayer const*>>,unsigned long,unsigned long,BOOL>>::*)(void),std::__async_assoc_state<ZinCpBasedAllocator::Execute(void)::CpRegionAllocationResult,std::__async_func<ZinCpBasedAllocator::Execute(void)::$_0,std::vector<std::vector<ZinANELayer const*>>,unsigned long,unsigned long,BOOL>>*>>::~unique_ptr[abi:ne180100](uint64_t **a1)
{
  uint64_t v2 = *a1;
  *a1 = 0;
  if (v2)
  {
    std::unique_ptr<std::__thread_struct>::reset[abi:ne180100](v2, 0);
    MEMORY[0x21667D3C0](v2, 0xA0C40F20CD8FBLL);
  }
  return a1;
}

uint64_t std::unique_ptr<std::__thread_struct>::reset[abi:ne180100](uint64_t *a1, uint64_t a2)
{
  uint64_t result = *a1;
  *a1 = a2;
  if (result)
  {
    MEMORY[0x21667CF80]();
    JUMPOUT(0x21667D3C0);
  }
  return result;
}

void std::__assoc_sub_state::__attach_future[abi:ne180100](uint64_t a1)
{
  uint64_t v2 = (std::mutex *)(a1 + 24);
  std::mutex::lock((std::mutex *)(a1 + 24));
  int v3 = *(_DWORD *)(a1 + 136);
  if ((v3 & 2) != 0) {
    std::__throw_future_error[abi:ne180100](1u);
  }
  atomic_fetch_add_explicit((atomic_ullong *volatile)(a1 + 8), 1uLL, memory_order_relaxed);
  *(_DWORD *)(a1 + 136) = v3 | 2;

  std::mutex::unlock(v2);
}

void sub_211386ABC(_Unwind_Exception *a1)
{
  std::mutex::unlock(v1);
  _Unwind_Resume(a1);
}

void *std::vector<std::vector<ZinANELayer const*>>::__init_with_size[abi:ne180100]<std::vector<ZinANELayer const*>*,std::vector<ZinANELayer const*>*>(void *result, uint64_t a2, uint64_t a3, unint64_t a4)
{
  if (a4)
  {
    int v6 = result;
    std::vector<std::string>::__vallocate[abi:ne180100](result, a4);
    uint64_t result = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::vector<ZinANELayer const*>>,std::vector<ZinANELayer const*>*,std::vector<ZinANELayer const*>*,std::vector<ZinANELayer const*>*>((uint64_t)(v6 + 2), a2, a3, (void *)v6[1]);
    v6[1] = result;
  }
  return result;
}

void sub_211386B38(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, void **a9)
{
  *(void *)(v9 + 8) = v10;
  std::vector<std::vector<ZinIrOpLayer *>>::__destroy_vector::operator()[abi:ne180100](&a9);
  _Unwind_Resume(a1);
}

void *std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::vector<ZinANELayer const*>>,std::vector<ZinANELayer const*>*,std::vector<ZinANELayer const*>*,std::vector<ZinANELayer const*>*>(uint64_t a1, uint64_t a2, uint64_t a3, void *a4)
{
  uint64_t v4 = a4;
  uint64_t v10 = a4;
  unint64_t v11 = a4;
  v8[0] = a1;
  v8[1] = &v10;
  v8[2] = &v11;
  char v9 = 0;
  if (a2 != a3)
  {
    uint64_t v6 = a2;
    do
    {
      *uint64_t v4 = 0;
      v4[1] = 0;
      v4[2] = 0;
      std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(v4, *(const void **)v6, *(void *)(v6 + 8), (uint64_t)(*(void *)(v6 + 8) - *(void *)v6) >> 3);
      uint64_t v4 = v11 + 3;
      v11 += 3;
      v6 += 24;
    }
    while (v6 != a3);
  }
  char v9 = 1;
  std::__exception_guard_exceptions<std::_AllocatorDestroyRangeReverse<std::allocator<std::vector<ZinANELayer const*>>,std::vector<ZinANELayer const*>*>>::~__exception_guard_exceptions[abi:ne180100]((uint64_t)v8);
  return v4;
}

void sub_211386BF8(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
}

uint64_t std::__exception_guard_exceptions<std::_AllocatorDestroyRangeReverse<std::allocator<std::vector<ZinANELayer const*>>,std::vector<ZinANELayer const*>*>>::~__exception_guard_exceptions[abi:ne180100](uint64_t a1)
{
  if (!*(unsigned char *)(a1 + 24)) {
    std::_AllocatorDestroyRangeReverse<std::allocator<std::vector<ZinIrOpLayer *>>,std::vector<ZinIrOpLayer *>*>::operator()[abi:ne180100](a1);
  }
  return a1;
}

void *std::__hash_table<std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>>>::__emplace_unique_key_args<ZinANELayer const*,std::piecewise_construct_t const&,std::tuple<ZinANELayer const*&&>,std::tuple<>>(uint64_t a1, void *a2, uint64_t a3, void **a4)
{
  unint64_t v7 = 0x9DDFEA08EB382D69 * ((8 * *a2 + 8) ^ HIDWORD(*a2));
  unint64_t v8 = 0x9DDFEA08EB382D69 * (HIDWORD(*a2) ^ (v7 >> 47) ^ v7);
  unint64_t v9 = 0x9DDFEA08EB382D69 * (v8 ^ (v8 >> 47));
  unint64_t v10 = *(void *)(a1 + 8);
  if (v10)
  {
    uint8x8_t v11 = (uint8x8_t)vcnt_s8((int8x8_t)v10);
    v11.i16[0] = vaddlv_u8(v11);
    if (v11.u32[0] > 1uLL)
    {
      unint64_t v4 = 0x9DDFEA08EB382D69 * (v8 ^ (v8 >> 47));
      if (v9 >= v10) {
        unint64_t v4 = v9 % v10;
      }
    }
    else
    {
      unint64_t v4 = v9 & (v10 - 1);
    }
    unint64_t v12 = *(void ***)(*(void *)a1 + 8 * v4);
    if (v12)
    {
      for (uint64_t i = *v12; i; uint64_t i = (void *)*i)
      {
        unint64_t v14 = i[1];
        if (v14 == v9)
        {
          if (i[2] == *a2) {
            return i;
          }
        }
        else
        {
          if (v11.u32[0] > 1uLL)
          {
            if (v14 >= v10) {
              v14 %= v10;
            }
          }
          else
          {
            v14 &= v10 - 1;
          }
          if (v14 != v4) {
            break;
          }
        }
      }
    }
  }
  unint64_t v15 = (void *)(a1 + 16);
  uint64_t i = operator new(0x20uLL);
  *uint64_t i = 0;
  i[1] = v9;
  i[2] = **a4;
  i[3] = 0;
  float v16 = (float)(unint64_t)(*(void *)(a1 + 24) + 1);
  float v17 = *(float *)(a1 + 32);
  if (!v10 || (float)(v17 * (float)v10) < v16)
  {
    BOOL v18 = 1;
    if (v10 >= 3) {
      BOOL v18 = (v10 & (v10 - 1)) != 0;
    }
    unint64_t v19 = v18 | (2 * v10);
    unint64_t v20 = vcvtps_u32_f32(v16 / v17);
    if (v19 <= v20) {
      size_t v21 = v20;
    }
    else {
      size_t v21 = v19;
    }
    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::__rehash<true>(a1, v21);
    unint64_t v10 = *(void *)(a1 + 8);
    if ((v10 & (v10 - 1)) != 0)
    {
      if (v9 >= v10) {
        unint64_t v4 = v9 % v10;
      }
      else {
        unint64_t v4 = v9;
      }
    }
    else
    {
      unint64_t v4 = (v10 - 1) & v9;
    }
  }
  uint64_t v22 = *(void *)a1;
  unint64_t v23 = *(void **)(*(void *)a1 + 8 * v4);
  if (v23)
  {
    *uint64_t i = *v23;
LABEL_38:
    *unint64_t v23 = i;
    goto LABEL_39;
  }
  *uint64_t i = *v15;
  void *v15 = i;
  *(void *)(v22 + 8 * v4) = v15;
  if (*i)
  {
    unint64_t v24 = *(void *)(*i + 8);
    if ((v10 & (v10 - 1)) != 0)
    {
      if (v24 >= v10) {
        v24 %= v10;
      }
    }
    else
    {
      v24 &= v10 - 1;
    }
    unint64_t v23 = (void *)(*(void *)a1 + 8 * v24);
    goto LABEL_38;
  }
LABEL_39:
  ++*(void *)(a1 + 24);
  return i;
}

void sub_211386EAC(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10)
{
  std::__hash_node_destructor<std::allocator<std::__hash_node<std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,void *>>>::operator()[abi:ne180100](v11, v10);
  _Unwind_Resume(a1);
}

void std::__hash_node_destructor<std::allocator<std::__hash_node<std::__hash_value_type<ZinANELayer const*,std::unique_ptr<LayerCycleAndFootprintEstimator>>,void *>>>::operator()[abi:ne180100](uint64_t a1, LayerCycleAndFootprintEstimator **__p)
{
  if (*(unsigned char *)(a1 + 8)) {
    std::unique_ptr<LayerCycleAndFootprintEstimator>::reset[abi:ne180100](__p + 3, 0);
  }
  if (__p)
  {
    operator delete(__p);
  }
}

void std::__function::__func<ZinCpBasedAllocator::SetNPL2DepExecutionBehavior(ZinNELayer const*,ZinPELayer const*,BOOL,BOOL,BOOL)::$_0,std::allocator<ZinCpBasedAllocator::SetNPL2DepExecutionBehavior(ZinNELayer const*,ZinPELayer const*,BOOL,BOOL,BOOL)::$_0>,BOOL ()(unsigned long)>::~__func()
{
}

__n128 std::__function::__func<ZinCpBasedAllocator::SetNPL2DepExecutionBehavior(ZinNELayer const*,ZinPELayer const*,BOOL,BOOL,BOOL)::$_0,std::allocator<ZinCpBasedAllocator::SetNPL2DepExecutionBehavior(ZinNELayer const*,ZinPELayer const*,BOOL,BOOL,BOOL)::$_0>,BOOL ()(unsigned long)>::__clone(uint64_t a1)
{
  uint64_t v2 = (char *)operator new(0x58uLL);
  *(void *)uint64_t v2 = &unk_26C32F228;
  *(_OWORD *)(v2 + 24) = *(_OWORD *)(a1 + 24);
  *(_OWORD *)(v2 + 4std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = *(_OWORD *)(a1 + 40);
  *(_OWORD *)(v2 + 56) = *(_OWORD *)(a1 + 56);
  *(_OWORD *)(v2 + 72) = *(_OWORD *)(a1 + 72);
  __n128 result = *(__n128 *)(a1 + 8);
  *(__n128 *)(v2 + 8) = result;
  return result;
}

__n128 std::__function::__func<ZinCpBasedAllocator::SetNPL2DepExecutionBehavior(ZinNELayer const*,ZinPELayer const*,BOOL,BOOL,BOOL)::$_0,std::allocator<ZinCpBasedAllocator::SetNPL2DepExecutionBehavior(ZinNELayer const*,ZinPELayer const*,BOOL,BOOL,BOOL)::$_0>,BOOL ()(unsigned long)>::__clone(uint64_t a1, uint64_t a2)
{
  *(void *)a2 = &unk_26C32F228;
  *(_OWORD *)(a2 + 8) = *(_OWORD *)(a1 + 8);
  __n128 result = *(__n128 *)(a1 + 24);
  long long v3 = *(_OWORD *)(a1 + 40);
  long long v4 = *(_OWORD *)(a1 + 56);
  *(_OWORD *)(a2 + 72) = *(_OWORD *)(a1 + 72);
  *(_OWORD *)(a2 + 56) = v4;
  *(_OWORD *)(a2 + 4std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v3;
  *(__n128 *)(a2 + 24) = result;
  return result;
}

void std::__function::__func<ZinCpBasedAllocator::SetNPL2DepExecutionBehavior(ZinNELayer const*,ZinPELayer const*,BOOL,BOOL,BOOL)::$_0,std::allocator<ZinCpBasedAllocator::SetNPL2DepExecutionBehavior(ZinNELayer const*,ZinPELayer const*,BOOL,BOOL,BOOL)::$_0>,BOOL ()(unsigned long)>::operator()(uint64_t a1, uint64_t *a2)
{
  long long v3 = *(ZinCpBasedAllocator **)(a1 + 8);
  if (!ZinCpBasedAllocator::GetNPL2DepPerfDescriptor(v3, **(const ZinNELayer ***)(a1 + 16), **(const ZinPELayer ***)(a1 + 24), **(unsigned __int8 **)(a1 + 32), **(unsigned char **)(a1 + 40), **(unsigned char **)(a1 + 48), *a2, *(ZinPerfDescriptor **)(a1 + 56), *(ZinPerfDescriptor **)(a1 + 64)))ZinCpBasedAllocator::GetNPL2DepCircularBufferMemoryFootprint(v3, **(const ZinNELayer ***)(a1 + 16), **(const ZinPELayer ***)(a1 + 24), v4, v5); {
  ZinAssertImpl("Perf descriptor must be valid");
  }
}

uint64_t std::__function::__func<ZinCpBasedAllocator::SetNPL2DepExecutionBehavior(ZinNELayer const*,ZinPELayer const*,BOOL,BOOL,BOOL)::$_0,std::allocator<ZinCpBasedAllocator::SetNPL2DepExecutionBehavior(ZinNELayer const*,ZinPELayer const*,BOOL,BOOL,BOOL)::$_0>,BOOL ()(unsigned long)>::target(uint64_t a1, uint64_t a2)
{
  {
    return a1 + 8;
  }
  else
  {
    return 0;
  }
}

void *std::__function::__func<ZinCpBasedAllocator::SetNPL2DepExecutionBehavior(ZinNELayer const*,ZinPELayer const*,BOOL,BOOL,BOOL)::$_0,std::allocator<ZinCpBasedAllocator::SetNPL2DepExecutionBehavior(ZinNELayer const*,ZinPELayer const*,BOOL,BOOL,BOOL)::$_0>,BOOL ()(unsigned long)>::target_type()
{
}

void *std::__function::__value_func<BOOL ()(unsigned long)>::~__value_func[abi:ne180100](void *a1)
{
  uint64_t v2 = (void *)a1[3];
  if (v2 == a1)
  {
    (*(void (**)(void *))(*a1 + 32))(a1);
  }
  else if (v2)
  {
    (*(void (**)(void *))(*v2 + 40))(v2);
  }
  return a1;
}

void std::__function::__func<ZinCpBasedAllocator::SetPNL2DepExecutionBehavior(ZinPELayer const*,ZinNELayer const*,BOOL,BOOL)::$_0,std::allocator<ZinCpBasedAllocator::SetPNL2DepExecutionBehavior(ZinPELayer const*,ZinNELayer const*,BOOL,BOOL)::$_0>,BOOL ()(unsigned long)>::~__func()
{
}

__n128 std::__function::__func<ZinCpBasedAllocator::SetPNL2DepExecutionBehavior(ZinPELayer const*,ZinNELayer const*,BOOL,BOOL)::$_0,std::allocator<ZinCpBasedAllocator::SetPNL2DepExecutionBehavior(ZinPELayer const*,ZinNELayer const*,BOOL,BOOL)::$_0>,BOOL ()(unsigned long)>::__clone(uint64_t a1)
{
  uint64_t v2 = (char *)operator new(0x50uLL);
  *(void *)uint64_t v2 = &unk_26C32F280;
  *(_OWORD *)(v2 + 24) = *(_OWORD *)(a1 + 24);
  *(_OWORD *)(v2 + 4std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = *(_OWORD *)(a1 + 40);
  *(_OWORD *)(v2 + 56) = *(_OWORD *)(a1 + 56);
  *((void *)v2 + 9) = *(void *)(a1 + 72);
  __n128 result = *(__n128 *)(a1 + 8);
  *(__n128 *)(v2 + 8) = result;
  return result;
}

__n128 std::__function::__func<ZinCpBasedAllocator::SetPNL2DepExecutionBehavior(ZinPELayer const*,ZinNELayer const*,BOOL,BOOL)::$_0,std::allocator<ZinCpBasedAllocator::SetPNL2DepExecutionBehavior(ZinPELayer const*,ZinNELayer const*,BOOL,BOOL)::$_0>,BOOL ()(unsigned long)>::__clone(uint64_t a1, uint64_t a2)
{
  *(void *)a2 = &unk_26C32F280;
  *(_OWORD *)(a2 + 8) = *(_OWORD *)(a1 + 8);
  __n128 result = *(__n128 *)(a1 + 24);
  long long v3 = *(_OWORD *)(a1 + 40);
  long long v4 = *(_OWORD *)(a1 + 56);
  *(void *)(a2 + 72) = *(void *)(a1 + 72);
  *(_OWORD *)(a2 + 56) = v4;
  *(_OWORD *)(a2 + 4std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v3;
  *(__n128 *)(a2 + 24) = result;
  return result;
}

void std::__function::__func<ZinCpBasedAllocator::SetPNL2DepExecutionBehavior(ZinPELayer const*,ZinNELayer const*,BOOL,BOOL)::$_0,std::allocator<ZinCpBasedAllocator::SetPNL2DepExecutionBehavior(ZinPELayer const*,ZinNELayer const*,BOOL,BOOL)::$_0>,BOOL ()(unsigned long)>::operator()(uint64_t a1, uint64_t *a2)
{
  long long v3 = *(ZinCpBasedAllocator **)(a1 + 8);
  if (!ZinCpBasedAllocator::GetPNL2DepPerfDescriptor(v3, **(const ZinPELayer ***)(a1 + 16), **(const ZinNELayer ***)(a1 + 24), **(unsigned char **)(a1 + 32), **(unsigned __int8 **)(a1 + 40), *a2, *(ZinPerfDescriptor **)(a1 + 48), *(ZinPerfDescriptor **)(a1 + 56)))ZinCpBasedAllocator::GetPNL2DepCircularBufferMemoryFootprint(v3, **(uint64_t ****)(a1 + 16), **(uint64_t ****)(a1 + 24), v4, v5); {
  ZinAssertImpl("Perf descriptor must be valid");
  }
}

uint64_t std::__function::__func<ZinCpBasedAllocator::SetPNL2DepExecutionBehavior(ZinPELayer const*,ZinNELayer const*,BOOL,BOOL)::$_0,std::allocator<ZinCpBasedAllocator::SetPNL2DepExecutionBehavior(ZinPELayer const*,ZinNELayer const*,BOOL,BOOL)::$_0>,BOOL ()(unsigned long)>::target(uint64_t a1, uint64_t a2)
{
  {
    return a1 + 8;
  }
  else
  {
    return 0;
  }
}

void *std::__function::__func<ZinCpBasedAllocator::SetPNL2DepExecutionBehavior(ZinPELayer const*,ZinNELayer const*,BOOL,BOOL)::$_0,std::allocator<ZinCpBasedAllocator::SetPNL2DepExecutionBehavior(ZinPELayer const*,ZinNELayer const*,BOOL,BOOL)::$_0>,BOOL ()(unsigned long)>::target_type()
{
}

uint64_t *std::__tree<std::__value_type<ZinIrTensor *,unsigned long>,std::__map_value_compare<ZinIrTensor *,std::__value_type<ZinIrTensor *,unsigned long>,std::less<ZinIrTensor *>,true>,std::allocator<std::__value_type<ZinIrTensor *,unsigned long>>>::__emplace_unique_key_args<ZinIrTensor *,std::pair<ZinIrTensor *,unsigned long>>(uint64_t **a1, unint64_t *a2, uint64_t *a3)
{
  uint64_t v6 = a1 + 1;
  uint64_t v5 = a1[1];
  if (v5)
  {
    unint64_t v7 = *a2;
    while (1)
    {
      while (1)
      {
        unint64_t v8 = (uint64_t **)v5;
        unint64_t v9 = v5[4];
        if (v7 >= v9) {
          break;
        }
        uint64_t v5 = *v8;
        uint64_t v6 = v8;
        if (!*v8) {
          goto LABEL_10;
        }
      }
      if (v9 >= v7) {
        break;
      }
      uint64_t v5 = v8[1];
      if (!v5)
      {
        uint64_t v6 = v8 + 1;
        goto LABEL_10;
      }
    }
  }
  else
  {
    unint64_t v8 = a1 + 1;
LABEL_10:
    unint64_t v10 = (uint64_t *)operator new(0x30uLL);
    uint64_t v11 = a3[1];
    v10[4] = *a3;
    v10[5] = v11;
    std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::__insert_node_at(a1, (uint64_t)v8, v6, v10);
    return v10;
  }
  return (uint64_t *)v8;
}

LayerCycleAndFootprintEstimator *std::unique_ptr<LayerCycleAndFootprintEstimator>::reset[abi:ne180100](LayerCycleAndFootprintEstimator **a1, LayerCycleAndFootprintEstimator *a2)
{
  __n128 result = *a1;
  *a1 = a2;
  if (result)
  {
    LayerCycleAndFootprintEstimator::~LayerCycleAndFootprintEstimator(result);
    JUMPOUT(0x21667D3C0);
  }
  return result;
}

void ZinCpBasedAllocator::PromoteChainToL2Dependent(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void ZinCpBasedAllocator::VerifyAllocationDecision(uint64_t a1)
{
  uint64_t v8 = *MEMORY[0x263EF8340];
  uint64_t v1 = (void *)(*(void *)a1 + 24);
  if (*(char *)(*(void *)a1 + 47) < 0) {
    uint64_t v1 = (void *)*v1;
  }
  int v2 = 136315650;
  long long v3 = v1;
  __int16 v4 = 2080;
  uint64_t v5 = "/Library/Caches/com.apple.xbs/Sources/ANECompiler/libs/inference/compiler/ZinIrSchedule/src/ZinCpBasedAllocator.cpp";
  __int16 v6 = 1024;
  int v7 = 2221;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "Error: Missing allocation decision in %s (file %s, line %d)\n", (uint8_t *)&v2, 0x1Cu);
}

void ZinCpBasedAllocator::CalculatePerf()
{
  OUTLINED_FUNCTION_1_7();
  OUTLINED_FUNCTION_4_1(&dword_210C72000, &_os_log_internal, v0, "Perf model isn't successful, line: %d, file: %s", v1, v2, v3, v4, 2u);
}

void ZinCpBasedAllocator::CollectNEPerfNumbers()
{
  OUTLINED_FUNCTION_1_7();
  OUTLINED_FUNCTION_4_1(&dword_210C72000, &_os_log_internal, v0, "Error: failed workunit selection, line: %d, file: %s", v1, v2, v3, v4, 2u);
}

void ZinCpBasedAllocator::SetNPChainExecutionBehavior()
{
  OUTLINED_FUNCTION_1_7();
  OUTLINED_FUNCTION_4_1(&dword_210C72000, &_os_log_internal, v0, "ERROR: Perf model call isn't successful, line: %d, file: %s", v1, v2, v3, v4, 2u);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;

  OUTLINED_FUNCTION_1_7();
  OUTLINED_FUNCTION_4_1(&dword_210C72000, &_os_log_internal, v0, "ERROR: Perf model call isn't successful, line: %d, file: %s", v1, v2, v3, v4, 2u);
}

void ZinCpBasedAllocator::SetPNChainExecutionBehavior()
{
  OUTLINED_FUNCTION_1_7();
  OUTLINED_FUNCTION_4_1(&dword_210C72000, &_os_log_internal, v0, "ERROR: Perf model call isn't successful, line: %d, file: %s", v1, v2, v3, v4, 2u);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;

  OUTLINED_FUNCTION_1_7();
  OUTLINED_FUNCTION_4_1(&dword_210C72000, &_os_log_internal, v0, "ERROR: Perf model call isn't successful, line: %d, file: %s", v1, v2, v3, v4, 2u);
}

void ZinCpBasedAllocator::CalculatesL2BudgetPerRegion()
{
  *(_WORD *)uint64_t v0 = 0;
  _os_log_debug_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_DEBUG, "[CPAllocator] No available L2-budget for a given region.\n", v0, 2u);
}

__CFDictionary *ZinCreateBatchToSpaceUnit(const ZinIrBatchToSpaceUnitInfo *a1)
{
  Unit = ZinCreateUnit(a1);
  Mutable = CFDictionaryCreateMutable((CFAllocatorRef)*MEMORY[0x263EFFB08], 0, MEMORY[0x263EFFF88], MEMORY[0x263EFFF90]);
  int v5 = 35;
  ZinAddSpaceTransformFactorToParamsDict(Mutable, &v5, (uint64_t)a1 + 80);
  CFDictionaryAddValue(Unit, @"Params", Mutable);
  CFRelease(Mutable);
  return Unit;
}

uint64_t ZinBarIdManager::GetNextAvailableBarId(ZinBarIdManager *this)
{
  unint64_t v1 = *((void *)this + 1);
  if (v1)
  {
    unsigned int v2 = 0;
    int v3 = *((_DWORD *)this + 6);
    while (1)
    {
      unsigned int v4 = v3 + v2;
      if (v4 <= v2) {
        break;
      }
      char v5 = 1;
      unsigned int v6 = v2;
      do
      {
        v5 &= ((*(void *)(*(void *)this + ((v6 >> 3) & 0x18)) >> v6) & 1) == 0;
        ++v6;
      }
      while (v4 > v6);
      if (v5) {
        break;
      }
      v2 += v3;
      if (v1 <= v2) {
        goto LABEL_8;
      }
    }
    int v7 = 1;
  }
  else
  {
LABEL_8:
    if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
      ZinBarIdManager::GetNextAvailableBarId();
    }
    LOBYTE(v2) = 0;
    int v7 = 0;
  }
  return v2 | (v7 << 8);
}

uint64_t ZinBarIdManager::GetAndAssignNextAvailableBarId(ZinBarIdManager *this)
{
  uint64_t result = ZinBarIdManager::GetNextAvailableBarId(this);
  if ((unsigned __int16)result >= 0x100u)
  {
    unsigned int v3 = *((_DWORD *)this + 6) + result;
    if (v3 > result)
    {
      uint64_t v4 = *(void *)this;
      unsigned int v5 = result;
      do
      {
        *(void *)(v4 + ((v5 >> 3) & 0x18)) |= 1 << v5;
        ++v5;
      }
      while (v3 > v5);
    }
  }
  return result;
}

uint64_t ZinBarIdManager::ReserveBarIds(uint64_t *a1, unsigned __int8 **a2)
{
  unsigned int v2 = *a2;
  unsigned int v3 = a2[1];
  if (*a2 == v3) {
    return 1;
  }
  unsigned int v4 = *((_DWORD *)a1 + 6);
  while (1)
  {
    unsigned int v5 = *v2;
    unint64_t v6 = v4 + v5;
    if (a1[1] < v6 || v5 % v4) {
      break;
    }
    if (v6 > v5)
    {
      uint64_t v7 = *a1;
      do
      {
        *(void *)(v7 + ((v5 >> 3) & 0x18)) |= 1 << v5;
        ++v5;
      }
      while (v6 > v5);
    }
    if (++v2 == v3) {
      return 1;
    }
  }
  return 0;
}

uint64_t ZinBarIdManager::GetNumberOfAvailableBars(uint64_t this)
{
  unint64_t v1 = *(void *)(this + 8);
  if (!v1) {
    return 0;
  }
  uint64_t v2 = this;
  unsigned int v3 = 0;
  LODWORD(this) = 0;
  do
  {
    unsigned int v4 = v3 + *(_DWORD *)(v2 + 24);
    if (v3 >= v4)
    {
      unsigned int v3 = 1;
    }
    else
    {
      unint64_t v5 = v3;
      LOBYTE(v3) = 1;
      int v6 = *(_DWORD *)(v2 + 24);
      do
      {
        unsigned int v3 = v3 & (((*(void *)(*(void *)v2 + ((v5 >> 3) & 0x1FFFFFFFFFFFFFF8)) >> v5) & 1) == 0);
        ++v5;
        --v6;
      }
      while (v6);
    }
    this = this + v3;
    unsigned int v3 = v4;
  }
  while (v1 > v4);
  return this;
}

void ZinBarIdManager::GetNextAvailableBarId()
{
  *(_WORD *)uint64_t v0 = 0;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "GetNextAvailableBarId: unable to allocate free BAR\n", v0, 2u);
}

__CFDictionary *CreateANECIRDict(const ZinIrUnitInfo *a1)
{
  switch(*((_DWORD *)a1 + 8))
  {
    case 1:
      uint64_t result = ZinCreateConvUnit(a1);
      break;
    case 2:
      uint64_t result = ZinCreatePoolUnit(a1);
      break;
    case 3:
      uint64_t result = ZinCreateConcatUnit(a1);
      break;
    case 4:
      uint64_t result = ZinCreateEWUnit(a1);
      break;
    case 5:
      uint64_t result = ZinCreateScaledEWUnit(a1);
      break;
    case 6:
      uint64_t result = ZinCreateNeuronUnit(a1);
      break;
    case 7:
    case 0xA:
    case 0x26:
    case 0x38:
    case 0x39:
    case 0x3F:
    case 0x40:
      uint64_t result = ZinCreateUnit(a1);
      break;
    case 8:
      uint64_t result = ZinCreateGOCUnit(a1);
      break;
    case 9:
      uint64_t result = ZinCreateDynamicGOCUnit(a1);
      break;
    case 0xB:
      uint64_t result = ZinCreateFlattenUnit(a1);
      break;
    case 0xC:
      uint64_t result = ZinCreateUnflattenUnit(a1);
      break;
    case 0xD:
      uint64_t result = ZinCreateCrossCorrelationUnit((uint64_t)a1);
      break;
    case 0xE:
      uint64_t result = ZinCreateKernelRasterizerUnit((uint64_t)a1);
      break;
    case 0xF:
      uint64_t result = ZinCreateArgMinMaxUnit(a1);
      break;
    case 0x10:
      uint64_t result = ZinCreateGlobalArgMinMaxUnit(a1);
      break;
    case 0x11:
      uint64_t result = ZinCreateInputViewUnit(a1);
      break;
    case 0x12:
      uint64_t result = ZinCreateMatrixMultUnit(a1);
      break;
    case 0x13:
      uint64_t result = ZinCreateBroadcastUnit(a1);
      break;
    case 0x14:
      uint64_t result = ZinCreateReductionUnit(a1);
      break;
    case 0x15:
      uint64_t result = ZinCreateTransposeUnit((int **)a1);
      break;
    case 0x16:
      uint64_t result = ZinCreateReshapeUnit((int **)a1);
      break;
    case 0x17:
      uint64_t result = ZinCreateShapeUnit(a1);
      break;
    case 0x18:
      uint64_t result = ZinCreateSoftmaxUnit(a1);
      break;
    case 0x19:
      uint64_t result = ZinCreateInstanceNormUnit(a1);
      break;
    case 0x1A:
    case 0x1B:
    case 0x1C:
      uint64_t result = ZinCreateMinMaxNormUnit(a1);
      break;
    case 0x1D:
      uint64_t result = ZinCreateLRNUnit((uint64_t)a1);
      break;
    case 0x1E:
      uint64_t result = ZinCreateCostVolumeUnit(a1);
      break;
    case 0x1F:
      uint64_t result = ZinCreatePixelShuffleUnit(a1);
      break;
    case 0x20:
      uint64_t result = ZinCreatePixelUnshuffleUnit(a1);
      break;
    case 0x21:
      uint64_t result = ZinCreateFurthestPointSamplingUnit((int *)a1);
      break;
    case 0x22:
      uint64_t result = ZinCreateSpaceToBatchUnit(a1);
      break;
    case 0x23:
      uint64_t result = ZinCreateBatchToSpaceUnit(a1);
      break;
    case 0x24:
      uint64_t result = ZinCreateSpaceToChannelUnit(a1);
      break;
    case 0x25:
      uint64_t result = ZinCreateChannelToSpaceUnit(a1);
      break;
    case 0x27:
      uint64_t result = ZinCreateGatherUnit(a1);
      break;
    case 0x28:
      uint64_t result = ZinCreateAffineTransformUnit(a1);
      break;
    case 0x29:
      uint64_t result = ZinCreateResizeUnit(a1);
      break;
    case 0x2A:
      uint64_t result = ZinCreateResizeAsUnit(a1);
      break;
    case 0x2B:
      uint64_t result = ZinCreateResampleUnit(a1);
      break;
    case 0x2C:
      uint64_t result = ZinCreatePadUnit(a1);
      break;
    case 0x2D:
      uint64_t result = ZinCreateTileUnit(a1);
      break;
    case 0x2E:
      uint64_t result = ZinCreateCropResizeUnit(a1);
      break;
    case 0x2F:
      uint64_t result = ZinCreateDynamicSliceUnit(a1);
      break;
    case 0x30:
      uint64_t result = ZinCreatePlaneReaderUnit((uint64_t)a1);
      break;
    case 0x31:
      uint64_t result = ZinCreatePlaneWriterUnit((uint64_t)a1);
      break;
    case 0x32:
      uint64_t result = ZinCreateSortUnit((uint64_t)a1);
      break;
    case 0x33:
      uint64_t result = ZinCreateTopKUnit((uint64_t)a1);
      break;
    case 0x34:
      uint64_t result = ZinCreateNMSUnit((uint64_t)a1);
      break;
    case 0x35:
      uint64_t result = ZinCreateMatrixDecompositionUnit(a1);
      break;
    case 0x36:
      uint64_t result = ZinCreateDropoutUnit(a1);
      break;
    case 0x37:
      uint64_t result = ZinCreateRandomUnit(a1);
      break;
    case 0x3A:
      uint64_t result = ZinCreateQuantUnit(a1);
      break;
    case 0x3B:
      uint64_t result = ZinCreateDeQuantUnit(a1);
      break;
    case 0x3C:
      uint64_t result = ZinCreateLinearUnit(a1);
      break;
    case 0x3D:
      uint64_t result = ZinCreateRingBufferWriterUnit(a1);
      break;
    case 0x3E:
      uint64_t result = ZinCreateRingBufferReaderUnit(a1);
      break;
    case 0x41:
      uint64_t result = ZinCreateNEConvUnit((void **)a1);
      break;
    case 0x42:
      uint64_t result = ZinCreateNEMatMulUnit((void **)a1);
      break;
    case 0x43:
      uint64_t result = ZinCreateNEPoolUnit((void **)a1);
      break;
    case 0x44:
      uint64_t result = ZinCreateNEBypassUnit((long long **)a1);
      break;
    case 0x45:
      uint64_t result = ZinCreatePEPoolUnit(a1);
      break;
    case 0x46:
      uint64_t result = ZinCreatePEElementWiseUnit(a1);
      break;
    case 0x47:
      uint64_t result = ZinCreatePEGOCUnit(a1);
      break;
    default:
      uint64_t result = 0;
      break;
  }
  return result;
}

void ZinLargeStridePoolTransform::ZinLargeStridePoolTransform(ZinLargeStridePoolTransform *this)
{
  *(void *)this = &unk_26C3523D8;
  *((void *)this + 3) = 0;
  *((void *)this + 4) = 0;
  *((_OWORD *)this + 3) = 0u;
  *((_OWORD *)this + 4) = 0u;
  *((void *)this + 1std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = -1;
  *((void *)this + 1) = &unk_26C34AB58;
  *((void *)this + 2) = 0;
  *((_DWORD *)this + 22) = 1;
  *((int64x2_t *)this + 6) = vdupq_n_s64(1uLL);
  *((void *)this + 14) = 1;
  *((void *)this + 15) = 0x100000001;
  *((_DWORD *)this + 32) = 1;
  *(void *)((char *)this + 132) = 0;
  *(void *)((char *)this + 148) = 0;
  *(void *)((char *)this + 14std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  *((unsigned char *)this + 156) = 0;
  *((void *)this + 2std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0x3F80000000000001;
  *((_DWORD *)this + 42) = 0;
  *((_DWORD *)this + 1std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 2;
  *((unsigned char *)this + 176) = 0;
  *(_OWORD *)((char *)this + 184) = 0u;
  *(_OWORD *)((char *)this + 20std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0u;
  *(_OWORD *)((char *)this + 216) = 0u;
}

void ZinLargeStridePoolTransform::ZinLargeStridePoolTransform(ZinLargeStridePoolTransform *this, char a2, const ZinIrPoolUnitInfo *a3)
{
  *(void *)this = &unk_26C3523D8;
  *((void *)this + 1) = &unk_26C345B80;
  if (*((char *)a3 + 31) < 0)
  {
    std::string::__init_copy_ctor_external((std::string *)((char *)this + 16), *((const std::string::value_type **)a3 + 1), *((void *)a3 + 2));
  }
  else
  {
    long long v6 = *(_OWORD *)((char *)a3 + 8);
    *((void *)this + 4) = *((void *)a3 + 3);
    *((_OWORD *)this + 1) = v6;
  }
  int v7 = *((_DWORD *)a3 + 8);
  *((void *)this + 6) = 0;
  *((_DWORD *)this + 1std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v7;
  *((void *)this + 7) = 0;
  *((void *)this + 8) = 0;
  std::vector<std::string>::__init_with_size[abi:ne180100]<std::string*,std::string*>((std::string *)this + 2, *((long long **)a3 + 5), *((long long **)a3 + 6), 0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*((void *)a3 + 6) - *((void *)a3 + 5)) >> 3));
  *(_OWORD *)((char *)this + 72) = *((_OWORD *)a3 + 4);
  *((void *)this + 1) = &unk_26C34AB58;
  long long v8 = *((_OWORD *)a3 + 5);
  *(_OWORD *)((char *)this + 104) = *((_OWORD *)a3 + 6);
  *(_OWORD *)((char *)this + 88) = v8;
  long long v9 = *((_OWORD *)a3 + 7);
  long long v10 = *((_OWORD *)a3 + 8);
  long long v11 = *((_OWORD *)a3 + 9);
  *((_DWORD *)this + 42) = *((_DWORD *)a3 + 40);
  *(_OWORD *)((char *)this + 152) = v11;
  *(_OWORD *)((char *)this + 136) = v10;
  *(_OWORD *)((char *)this + 12std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v9;
  *((unsigned char *)this + 176) = a2;
  *(_OWORD *)((char *)this + 184) = 0u;
  *(_OWORD *)((char *)this + 20std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0u;
  *(_OWORD *)((char *)this + 216) = 0u;
}

void sub_211388384(_Unwind_Exception *exception_object)
{
  if (*(char *)(v1 + 39) < 0) {
    operator delete(*v2);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinLargeStridePoolTransform::GetTransformType(ZinLargeStridePoolTransform *this)
{
  return 0;
}

uint64_t ZinLargeStridePoolTransform::RunLargeStridePool(uint64_t a1, uint64_t a2, uint64_t a3, ZinSpatialSplitTransform **a4)
{
  if (*(_DWORD *)ZinSpatialSplitTransform::GetPaddingInfo(*a4) != 36) {
    return 0;
  }
  v8[0] = vdupq_n_s64(1uLL);
  v8[1] = v8[0];
  uint64_t v9 = 1;
  uint64_t result = (*(uint64_t (**)(ZinSpatialSplitTransform *, uint64_t, _OWORD *))(*(void *)*a4 + 16))(*a4, a3, v8);
  if (result)
  {
    if (ZinMirUnitGraph::RemoveNode(a2, a4)) {
      return 0;
    }
    else {
      return 3;
    }
  }
  return result;
}

uint64_t ZinLargeStridePoolTransform::RunLargeStridePoolExcludePadding(uint64_t a1, uint64_t a2, void **a3, unint64_t *a4)
{
  unint64_t v28 = a4;
  long long v8 = std::__hash_table<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::__unordered_map_hasher<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::__unordered_map_equal<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>>>::find<std::reference_wrapper<ZinIrOpLayer * const>>((void *)(a2 + 64), &v28);
  uint64_t v9 = (void *)(a2 + 104);
  if (v8) {
    uint64_t v9 = v8 + 3;
  }
  long long v11 = v9;
  uint64_t v10 = *v9;
  if (v11[1] == v10) {
    return 3;
  }
  if (*(void *)(*a4 + 88) != *(void *)(**(void **)v10 + 88))
  {
    int v12 = ZinMirUnit::Format((ZinMirUnit *)*a4);
    if (ZinConvPoolLargeStride::DecomposeLargeStridePoolNoSeparatePaddingLayer(v12, a1 + 8, *a3, (uint64_t **)(a1 + 184), (uint64_t *)(a1 + 208)))return 3; {
  }
    }
  if (*(void *)(a1 + 216) == *(void *)(a1 + 208)) {
    return 3;
  }
  if (*(_DWORD *)ZinSpatialSplitTransform::GetPaddingInfo((ZinSpatialSplitTransform *)*a4) != 36) {
    return 0;
  }
  BondedInfo = (uint64_t **)ZinANELayer::GetBondedInfo((ZinANELayer *)*a4);
  unint64_t v14 = *BondedInfo;
  unint64_t v15 = BondedInfo[1];
  if (*BondedInfo == v15) {
    goto LABEL_35;
  }
  char v16 = 0;
  float v17 = *(_DWORD **)(a1 + 208);
  BOOL v18 = *(_DWORD **)(a1 + 216);
  do
  {
    while (1)
    {
      unint64_t v19 = v17;
      if (v17 != v18)
      {
        unint64_t v19 = v17;
        while (1)
        {
          if (*v19 == 17)
          {
            uint64_t v20 = *v14;
            if (v19[22] == *(_DWORD *)(*v14 + 80) && v19[24] == *(_DWORD *)(v20 + 88))
            {
              int v21 = v19[25];
              int v22 = *(_DWORD *)(v20 + 92);
              if (v21 == v22 || v21 == 4 && v22 == 2) {
                break;
              }
            }
          }
          v19 += 86;
          if (v19 == v18) {
            goto LABEL_21;
          }
        }
      }
      if (v19 == v18) {
        break;
      }
      uint64_t result = 0;
      uint64_t v25 = *v14++;
      uint64_t v24 = v25;
      int v26 = v19[23];
      int v27 = *(_DWORD *)(v25 + 84);
      if (v26 >= v27) {
        int v26 = v27;
      }
      *(_DWORD *)(v24 + 84) = v26;
      char v16 = 1;
      if (v14 == v15) {
        return result;
      }
    }
LABEL_21:
    ++v14;
  }
  while (v14 != v15);
  if (v16) {
    return 0;
  }
LABEL_35:
  if (ZinMirUnitGraph::RemoveNode(a2, a4)) {
    return 0;
  }
  return 3;
}

uint64_t ZinLargeStridePoolTransform::Run(uint64_t a1, uint64_t a2, unint64_t *a3, void **a4)
{
  if (*(unsigned char *)(a1 + 176)) {
    return ZinLargeStridePoolTransform::RunLargeStridePoolExcludePadding(a1, a2, a4, a3);
  }
  else {
    return ZinLargeStridePoolTransform::RunLargeStridePool(a1, a2, (uint64_t)a4, (ZinSpatialSplitTransform **)a3);
  }
}

BOOL ZinLargeStridePoolTransform::operator==(unsigned char *a1, unsigned char *a2)
{
  int v4 = (*(uint64_t (**)(unsigned char *))(*(void *)a1 + 40))(a1);
  if (v4 != (*(unsigned int (**)(unsigned char *))(*(void *)a2 + 40))(a2)) {
    return 0;
  }
  BOOL result = ZinIrPoolUnitInfo::operator==((uint64_t)(a1 + 8), (uint64_t)(a2 + 8));
  if (result) {
    return (a1[176] == 0) ^ (a2[176] != 0);
  }
  return result;
}

BOOL ZinIrPoolUnitInfo::operator==(uint64_t a1, uint64_t a2)
{
  if (*(_DWORD *)(a1 + 80) != *(_DWORD *)(a2 + 80)
    || *(void *)(a1 + 88) != *(void *)(a2 + 88)
    || *(void *)(a1 + 96) != *(void *)(a2 + 96)
    || *(void *)(a1 + 104) != *(void *)(a2 + 104)
    || *(_DWORD *)(a1 + 112) != *(_DWORD *)(a2 + 112)
    || *(_DWORD *)(a1 + 116) != *(_DWORD *)(a2 + 116)
    || *(_DWORD *)(a1 + 120) != *(_DWORD *)(a2 + 120))
  {
    return 0;
  }
  BOOL result = ZinIrPadding::operator==((_DWORD *)(a1 + 124), (_DWORD *)(a2 + 124));
  if (!result) {
    return result;
  }
  return *(unsigned __int8 *)(a1 + 148) == *(unsigned __int8 *)(a2 + 148)
      && *(_DWORD *)(a1 + 152) == *(_DWORD *)(a2 + 152)
      && *(float *)(a1 + 156) == *(float *)(a2 + 156)
      && *(_DWORD *)(a1 + 160) == *(_DWORD *)(a2 + 160)
      && *(void *)(a1 + 72) == *(void *)(a2 + 72);
}

uint64_t ZinIrPerf::IsValidPerfInfo(ZinIrPerf *this, const ZinANELayer *a2)
{
  if (*((double *)this + 8) >= 0.0
    && *((double *)this + 7) >= 0.0
    && *((double *)this + 9) >= 0.0
    && *((double *)this + 10) >= 0.0
    && *((double *)this + 11) >= 0.0)
  {
    uint64_t v11 = *((void *)this + 4);
    if (!*(void *)(v11 + 520) || !*(void *)(v11 + 440))
    {
      BOOL v34 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v34) {
        ZinIrPerf::IsValidPerfInfo(v34, v35, v36, v37, v38, v39, v40, v41);
      }
      return 3;
    }
    int v12 = (int64x2_t *)*((void *)this + 29);
    std::exception_ptr v13 = (int64x2_t *)*((void *)this + 30);
    if (v12 == v13)
    {
      BOOL v42 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v42) {
        ZinIrPerf::IsValidPerfInfo(v42, v43, v44, v45, v46, v47, v48, v49);
      }
      return 3;
    }
    unint64_t v14 = (int64x2_t *)*((void *)this + 35);
    unint64_t v15 = (int64x2_t *)*((void *)this + 36);
    if (v14 == v15)
    {
      BOOL v50 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v50) {
        ZinIrPerf::IsValidPerfInfo(v50, v51, v52, v53, v54, v55, v56, v57);
      }
      return 3;
    }
    char v16 = (int64x2_t *)*((void *)this + 29);
    do
    {
      if ((vmaxv_u16((uint16x4_t)vmovn_s32(vuzp1q_s32((int32x4_t)vceqzq_s64(*v16), (int32x4_t)vceqzq_s64(v16[1])))) & 1) != 0
        || !v16[2].i64[0])
      {
        BOOL v58 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
        if (v58) {
          ZinIrPerf::IsValidPerfInfo(v58, v59, v60, v61, v62, v63, v64, v65);
        }
        return 3;
      }
      char v16 = (int64x2_t *)((char *)v16 + 40);
    }
    while (v16 != v13);
    float v17 = (_DWORD *)*((void *)this + 32);
    BOOL v18 = (_DWORD *)*((void *)this + 33);
    if (v17 == v18)
    {
      BOOL v66 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v66) {
        ZinIrPerf::IsValidPerfInfo(v66, v67, v68, v69, v70, v71, v72, v73);
      }
      return 3;
    }
    unint64_t v19 = (_DWORD *)*((void *)this + 32);
    do
    {
      if (!*v19)
      {
        BOOL v74 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
        if (v74) {
          ZinIrPerf::IsValidPerfInfo(v74, v75, v76, v77, v78, v79, v80, v81);
        }
        return 3;
      }
      ++v19;
    }
    while (v19 != v18);
    if (0xCCCCCCCCCCCCCCCDLL * (((char *)v13 - (char *)v12) >> 3) != v18 - v17)
    {
      BOOL v82 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v82) {
        ZinIrPerf::IsValidPerfInfo(v82, v83, v84, v85, v86, v87, v88, v89);
      }
      return 3;
    }
    uint64_t v20 = (int64x2_t *)*((void *)this + 35);
    do
    {
      if ((vmaxv_u16((uint16x4_t)vmovn_s32(vuzp1q_s32((int32x4_t)vceqzq_s64(*v20), (int32x4_t)vceqzq_s64(v20[1])))) & 1) != 0
        || !v20[2].i64[0])
      {
        BOOL v90 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
        if (v90) {
          ZinIrPerf::IsValidPerfInfo(v90, v91, v92, v93, v94, v95, v96, v97);
        }
        return 3;
      }
      uint64_t v20 = (int64x2_t *)((char *)v20 + 40);
    }
    while (v20 != v15);
    uint64_t v21 = *((void *)this + 38);
    uint64_t v22 = *((void *)this + 39);
    if (v21 == v22)
    {
      BOOL v98 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v98) {
        ZinIrPerf::IsValidPerfInfo(v98, v99, v100, v101, v102, v103, v104, v105);
      }
      return 3;
    }
    uint64_t v23 = (unsigned __int128)(((char *)v15 - (char *)v14) * (__int128)0x6666666666666667) >> 64;
    unint64_t v24 = (v23 >> 4) + ((unint64_t)v23 >> 63);
    if (v24 != *((void *)this + 13))
    {
      BOOL v106 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v106) {
        ZinIrPerf::IsValidPerfInfo(v106, v107, v108, v109, v110, v111, v112, v113);
      }
      return 3;
    }
    if (v24 != (v22 - v21) >> 2)
    {
      BOOL v114 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v114) {
        ZinIrPerf::IsValidPerfInfo(v114, v115, v116, v117, v118, v119, v120, v121);
      }
      return 3;
    }
    if (!*((void *)this + 42)
      || !*((void *)this + 45)
      || !*((void *)this + 43)
      || !*((void *)this + 41)
      || !*((void *)this + 44))
    {
      BOOL v122 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v122) {
        ZinIrPerf::IsValidPerfInfo(v122, v123, v124, v125, v126, v127, v128, v129);
      }
      return 3;
    }
    if (!*((void *)this + 26))
    {
      BOOL v130 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v130) {
        ZinIrPerf::IsValidPerfInfo(v130, v131, v132, v133, v134, v135, v136, v137);
      }
      return 3;
    }
    if (!*((void *)this + 27))
    {
      BOOL v138 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v138) {
        ZinIrPerf::IsValidPerfInfo(v138, v139, v140, v141, v142, v143, v144, v145);
      }
      return 3;
    }
    if (!*((void *)this + 28))
    {
      BOOL v146 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v146) {
        ZinIrPerf::IsValidPerfInfo(v146, v147, v148, v149, v150, v151, v152, v153);
      }
      return 3;
    }
    if (!*((void *)this + 23))
    {
      BOOL v154 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v154) {
        ZinIrPerf::IsValidPerfInfo(v154, v155, v156, v157, v158, v159, v160, v161);
      }
      return 3;
    }
    if (!*((void *)this + 24))
    {
      BOOL v162 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v162) {
        ZinIrPerf::IsValidPerfInfo(v162, v163, v164, v165, v166, v167, v168, v169);
      }
      return 3;
    }
    if (!*((void *)this + 25))
    {
      BOOL v170 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v170) {
        ZinIrPerf::IsValidPerfInfo(v170, v171, v172, v173, v174, v175, v176, v177);
      }
      return 3;
    }
    if (!*((void *)this + 19))
    {
      BOOL v178 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v178) {
        ZinIrPerf::IsValidPerfInfo(v178, v179, v180, v181, v182, v183, v184, v185);
      }
      return 3;
    }
    if (!*((_DWORD *)this + 92))
    {
      BOOL v186 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v186) {
        ZinIrPerf::IsValidPerfInfo(v186, v187, v188, v189, v190, v191, v192, v193);
      }
      return 3;
    }
    unint64_t v25 = 0;
    if (v24 <= 1) {
      unint64_t v24 = 1;
    }
    do
    {
      if (!(*(void *)(*((void *)this + 12) + ((v25 >> 3) & 0x1FFFFFFFFFFFFFF8)) & (1 << v25) | *((void *)this + v25 + 16)))
      {
        BOOL v194 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
        if (v194) {
          ZinIrPerf::IsValidPerfInfo(v194, v195, v196, v197, v198, v199, v200, v201);
        }
        return 3;
      }
      ++v25;
    }
    while (v24 != v25);
    if (!*((unsigned char *)this + 120) && !*((void *)this + 18))
    {
      BOOL v227 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v227) {
        ZinIrPerf::IsValidPerfInfo(v227, v228, v229, v230, v231, v232, v233, v234);
      }
      return 3;
    }
    if (ZinIrOpLayer::IsNELayer(a2))
    {
      if (*((void *)this + 93))
      {
        if (*((void *)this + 96)) {
          goto LABEL_51;
        }
        BOOL v243 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
        if (v243) {
          ZinIrPerf::IsValidPerfInfo(v243, v244, v245, v246, v247, v248, v249, v250);
        }
      }
      else
      {
        BOOL v219 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
        if (v219) {
          ZinIrPerf::IsValidPerfInfo(v219, v220, v221, v222, v223, v224, v225, v226);
        }
      }
    }
    else
    {
LABEL_51:
      if (*((unsigned char *)this + 536) && !*((void *)this + 64))
      {
        BOOL v235 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
        if (v235) {
          ZinIrPerf::IsValidPerfInfo(v235, v236, v237, v238, v239, v240, v241, v242);
        }
        return 3;
      }
      if (*((void *)this + 21) < 2uLL || *((void *)this + 20) < 2uLL)
      {
        if (!*((unsigned char *)this + 628) || !*((unsigned char *)this + 648))
        {
          unint64_t v210 = *((void *)this + 103);
          if (*(unsigned char *)(*((void *)this + 4) + 1585))
          {
            if (v210 >= 4)
            {
              BOOL v211 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
              if (v211) {
                ZinIrPerf::IsValidPerfInfo(v211, v212, v213, v214, v215, v216, v217, v218);
              }
              return 3;
            }
            if (v210 || *((unsigned char *)this + 832))
            {
              ZinChannelAssignment::ZinChannelAssignment((ZinChannelAssignment *)v269, *((void *)this + 93) << (v210 + *((unsigned char *)this + 832)), *((void *)this + 96), *((void *)this + 42) / *((void *)this + 20), (1 << (v210 + *((unsigned char *)this + 832))));
              unint64_t v259 = v271 == 0 ? v270 : v270 + 1;
              if (v259 >= 2)
              {
                BOOL v260 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
                if (v260) {
                  ZinIrPerf::IsValidPerfInfo(v260, v261, v262, v263, v264, v265, v266, v267);
                }
                return 3;
              }
            }
          }
          else if (v210 || *((unsigned char *)this + 832))
          {
            BOOL v251 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
            if (v251) {
              ZinIrPerf::IsValidPerfInfo(v251, v252, v253, v254, v255, v256, v257, v258);
            }
            return 3;
          }
          return 0;
        }
        BOOL v202 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
        if (v202) {
          ZinIrPerf::IsValidPerfInfo(v202, v203, v204, v205, v206, v207, v208, v209);
        }
      }
      else
      {
        BOOL v26 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
        if (v26) {
          ZinIrPerf::IsValidPerfInfo(v26, v27, v28, v29, v30, v31, v32, v33);
        }
      }
    }
  }
  else
  {
    BOOL v2 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (v2) {
      ZinIrPerf::IsValidPerfInfo(v2, v3, v4, v5, v6, v7, v8, v9);
    }
  }
  return 3;
}

uint64_t ZinNEPerfInfo::GetTotalNumberOfActiveNEs(ZinNEPerfInfo *this)
{
  return *((void *)this + 9) * (1 << (*((_DWORD *)this + 38) + *((unsigned char *)this + 160)));
}

uint64_t ZinNEPerfInfo::GetNumClusters(ZinNEPerfInfo *this)
{
  return 1 << (*((_DWORD *)this + 38) + *((unsigned char *)this + 160));
}

uint64_t ZinIrPerf::CalculatePerfDescriptor(ZinIrPerf *this, ZinPerfDescriptor *a2)
{
  uint64_t v3 = 0;
  switch(*((_DWORD *)this + 44))
  {
    case 0:
      ZinEnginePerf::ZinEnginePerf((ZinEnginePerf *)v14, this);
      uint64_t v15 = 0;
      v14[0] = &unk_26C34DAC0;
      ZinPEPerf::CalculatePerf((ZinPEPerf *)v14, a2);
      goto LABEL_14;
    case 1:
      ZinEnginePerf::ZinEnginePerf((ZinEnginePerf *)v14, this);
      uint64_t v15 = 0;
      v14[0] = &unk_26C34DB70;
      ZinPEPerf::CalculatePerf((ZinPEPerf *)v14, a2);
      goto LABEL_14;
    case 2:
      ZinEnginePerf::ZinEnginePerf((ZinEnginePerf *)v14, this);
      uint64_t v15 = 0;
      v14[0] = &unk_26C3460C8;
      ZinPEPerf::CalculatePerf((ZinPEPerf *)v14, a2);
      goto LABEL_14;
    case 3:
      ZinEnginePerf::ZinEnginePerf((ZinEnginePerf *)v14, this);
      uint64_t v15 = 0;
      v14[0] = &unk_26C344A28;
      ZinPEPerf::CalculatePerf((ZinPEPerf *)v14, a2);
      goto LABEL_14;
    case 4:
      ZinEnginePerf::ZinEnginePerf((ZinEnginePerf *)v14, this);
      v14[0] = &unk_26C345BC0;
      ZinNEPerf::CalculatePerf((ZinNEPerf *)v14, a2);
      goto LABEL_14;
    case 5:
      ZinEnginePerf::ZinEnginePerf((ZinEnginePerf *)v14, this);
      v14[0] = &unk_26C345C50;
      ZinNEPerf::CalculatePerf((ZinNEPerf *)v14, a2);
      goto LABEL_14;
    case 6:
      ZinEnginePerf::ZinEnginePerf((ZinEnginePerf *)v14, this);
      v14[0] = &unk_26C34DA08;
      ZinNEPerf::CalculatePerf((ZinNEPerf *)v14, a2);
      goto LABEL_14;
    case 7:
      return v3;
    case 8:
      ZinEnginePerf::ZinEnginePerf((ZinEnginePerf *)v14, this);
      v14[0] = &unk_26C349090;
      ZinNEPerf::CalculatePerf((ZinNEPerf *)v14, a2);
      goto LABEL_14;
    case 9:
      ZinEnginePerf::ZinEnginePerf((ZinEnginePerf *)v14, this);
      v14[0] = &unk_26C345CE0;
      ZinNEPerf::CalculatePerf((ZinNEPerf *)v14, a2);
LABEL_14:
      uint64_t v3 = v4;
      ZinEnginePerf::~ZinEnginePerf((ZinEnginePerf *)v14);
      break;
    default:
      BOOL v5 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v5) {
        ZinIrPerf::CalculatePerfDescriptor(v5, v6, v7, v8, v9, v10, v11, v12);
      }
      uint64_t v3 = 3;
      break;
  }
  return v3;
}

void sub_21138922C(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
}

uint64_t ZinIrPerf::TranslateOpcode(uint64_t a1, int a2)
{
  int v2 = a2 - 81;
  if ((a2 - 81) > 0xC || ((0x1F1Fu >> v2) & 1) == 0) {
    return 3;
  }
  uint64_t result = 0;
  *(_DWORD *)(a1 + 176) = dword_211F07D84[v2];
  return result;
}

uint64_t ZinIrPerf::ValidatePerfAnalysisMode(ZinIrPerf *this, const ZinANELayer *a2, char a3)
{
  if ((*((unsigned char *)this + 46) & 1) != 0
    && (a3 & 1) == 0
    && (*((void *)a2 + 11) == *((void *)a2 + 12)
     || *(_DWORD *)(*((void *)a2 + 8) + 8) != 82 && *((void *)a2 + 14) == *((void *)a2 + 15)))
  {
    BOOL v4 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (v4) {
      ZinIrPerf::ValidatePerfAnalysisMode(v4, v5, v6, v7, v8, v9, v10, v11);
    }
    return 3;
  }
  if (*((unsigned char *)this + 47))
  {
    if (*((void *)a2 + 11) == *((void *)a2 + 12)
      || *(_DWORD *)(*((void *)a2 + 8) + 8) != 82 && *((void *)a2 + 14) == *((void *)a2 + 15))
    {
      BOOL v20 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v20) {
        ZinIrPerf::ValidatePerfAnalysisMode(v20, v21, v22, v23, v24, v25, v26, v27);
      }
      return 3;
    }
  }
  else if ((*((unsigned char *)this + 46) & 1) == 0)
  {
    goto LABEL_15;
  }
  if ((*((unsigned char *)this + 42) & 1) == 0 || (*((unsigned char *)this + 41) & 1) == 0 || (*((unsigned char *)this + 40) & 1) == 0)
  {
    BOOL v12 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (v12) {
      ZinIrPerf::ValidatePerfAnalysisMode(v12, v13, v14, v15, v16, v17, v18, v19);
    }
    return 3;
  }
LABEL_15:
  if ((*((unsigned char *)this + 49) & 1) == 0 || *((void *)a2 + 11) != *((void *)a2 + 12)) {
    return 0;
  }
  BOOL v28 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
  if (v28) {
    ZinIrPerf::ValidatePerfAnalysisMode(v28, v29, v30, v31, v32, v33, v34, v35);
  }
  return 3;
}

uint64_t ZinIrPerf::ValidateDefaultPerfInfo(ZinIrPerf *this, const ZinANELayer *a2)
{
  uint64_t v4 = ZinIrPerf::ValidatePerfInfo(this, a2);
  if (v4)
  {
    uint64_t v5 = v4;
    BOOL v6 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (v6) {
      ZinIrPerf::ValidateDefaultPerfInfo(v6, v7, v8, v9, v10, v11, v12, v13);
    }
    return v5;
  }
  if (ZinIrPerf::IsValidPerfInfo(this, a2)) {
    return 3;
  }
  if (!ZinIrOpLayer::IsNELayer(a2)) {
    return 0;
  }

  return ZinIrPerf::GetNEWorkUnitShapes(this);
}

uint64_t ZinIrPerf::ValidatePerfInfo(ZinIrPerf *this, const ZinANELayer *a2)
{
  uint64_t v4 = ZinIrPerf::TranslateOpcode((uint64_t)this, *(_DWORD *)(*((void *)a2 + 8) + 8));
  if (v4)
  {
    uint64_t v5 = v4;
    BOOL v6 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (v6) {
      ZinIrPerf::ValidatePerfInfo(v6, v7, v8, v9, v10, v11, v12, v13);
    }
  }
  else
  {
    uint64_t v34 = &v35;
    uint64_t v35 = 0;
    uint64_t v36 = 0;
    long long v37 = 0uLL;
    uint64_t v38 = 0;
    LOBYTE(v4std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
    *(void *)((char *)&v40 + 4) = 3212836864;
    WORD6(v4std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
    *(void *)&long long v41 = 1;
    BYTE8(v41) = 0;
    int64x2_t v42 = vdupq_n_s64(1uLL);
    *(int64x2_t *)&v43[8] = v42;
    *(void *)&v43[24] = 1;
    *(_DWORD *)uint64_t v44 = 0;
    *(_OWORD *)&v44[8] = xmmword_211ED51B0;
    *(_WORD *)&v44[24] = 0;
    uint64_t v45 = (char *)this + 56;
    uint64_t v14 = (char *)this + 680;
    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)this + 672, *((void **)this + 85));
    uint64_t v15 = v35;
    *((void *)this + 84) = &v35;
    *((void *)this + 85) = v15;
    uint64_t v16 = v36;
    *((void *)this + 86) = v36;
    if (v16)
    {
      v15[2] = v14;
      uint64_t v34 = &v35;
      uint64_t v35 = 0;
      uint64_t v36 = 0;
    }
    else
    {
      *((void *)this + 84) = v14;
    }
    uint64_t v17 = (void *)*((void *)this + 87);
    if (v17)
    {
      *((void *)this + 88) = v17;
      operator delete(v17);
    }
    *(_OWORD *)((char *)this + 696) = v37;
    long long v18 = *(_OWORD *)v44;
    *(_OWORD *)((char *)this + 792) = *(_OWORD *)&v43[16];
    *(_OWORD *)((char *)this + 808) = v18;
    *(_OWORD *)((char *)this + 824) = *(_OWORD *)&v44[16];
    long long v19 = v41;
    *(_OWORD *)((char *)this + 728) = v40;
    *(_OWORD *)((char *)this + 744) = v19;
    long long v20 = *(_OWORD *)v43;
    *(int64x2_t *)((char *)this + 76std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v42;
    uint64_t v21 = v39;
    *((void *)this + 89) = v38;
    uint64_t v38 = 0;
    long long v37 = 0uLL;
    *((void *)this + 9std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v21;
    *((void *)this + 105) = v45;
    *(_OWORD *)((char *)this + 776) = v20;
    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v34, v35);
    *((int64x2_t *)this + 53) = vdupq_n_s64(1uLL);
    *((void *)this + 108) = (char *)this + 56;
    ZinIrPerf::ConfigureOutputTensorInfo(this, a2);
    ZinIrPerf::ConfigureInputTensorInfo(this, a2);
    ZinIrPerf::ConfigurePerfInfoKernel(this, a2);
    ZinIrPerf::ConfigurePerfInfo(this, (ZinEngineLayerMirInfo **)a2, v22, v23);
    uint64_t v5 = v24;
    if (v24)
    {
      BOOL v25 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v25) {
        ZinIrPerf::ValidatePerfInfo(v25, v26, v27, v28, v29, v30, v31, v32);
      }
    }
    else
    {
      ZinIrPerf::ValidateTexturePerfInfo(this, a2);
    }
  }
  return v5;
}

uint64_t ZinIrPerf::GetNEWorkUnitShapes(ZinIrPerf *this)
{
  uint64_t v12 = 0;
  uint64_t v13 = 0;
  uint64_t v11 = &v12;
  int v2 = (void *)((char *)this + 672);
  uint64_t v3 = (char *)this + 680;
  long long v14 = 0u;
  long long v15 = 0u;
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)this + 672, *((void **)this + 85));
  uint64_t v4 = v12;
  *((void *)this + 84) = &v12;
  *((void *)this + 85) = v4;
  uint64_t v5 = v13;
  *((void *)this + 86) = v13;
  if (v5)
  {
    v4[2] = v3;
    uint64_t v11 = &v12;
    uint64_t v12 = 0;
    uint64_t v13 = 0;
    uint64_t v4 = 0;
  }
  else
  {
    void *v2 = v3;
  }
  BOOL v6 = (void *)*((void *)this + 87);
  if (v6)
  {
    *((void *)this + 88) = v6;
    operator delete(v6);
    uint64_t v4 = v12;
  }
  *(_OWORD *)((char *)this + 696) = v14;
  uint64_t v7 = *((void *)&v15 + 1);
  *((void *)this + 89) = v15;
  *(void *)&long long v15 = 0;
  long long v14 = 0uLL;
  *((void *)this + 9std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v7;
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v11, v4);
  unsigned __int8 v8 = 1;
  if (!*((unsigned char *)this + 52)) {
    unsigned __int8 v8 = *((unsigned char *)this + 48) || *((unsigned char *)this + 54) || *((unsigned char *)this + 53) != 0;
  }
  if (NERasterization::RasterizeWorkUnit((uint64_t)v2, (void **)this + 87, (void *)this + 90, *((void *)this + 98), *((void *)this + 100), *((void *)this + 99), *((void *)this + 19), *((_DWORD *)this + 184), *((void *)this + 63), *((void *)this + 62), **((_DWORD **)this + 32), v10, *((unsigned char *)this + 740), *((void *)this + 103), *((unsigned char *)this + 832), *((void *)this + 4), *((void *)this + 71), *((void *)this + 70), *((void *)this + 72),
                       v8,
                       1))
    return 3;
  else {
    return 0;
  }
}

uint64_t ZinIrPerf::ConfigureOutputTensorInfo(ZinIrPerf *this, const ZinANELayer *a2)
{
  uint64_t result = (*(uint64_t (**)(const ZinANELayer *, void, void))(*(void *)a2 + 32))(a2, 0, 0);
  uint64_t v5 = (ZinIrTensor *)result;
  if (*((unsigned char *)this + 668)) {
    *((unsigned char *)this + 668) = 0;
  }
  if (result)
  {
    long long v6 = *(_OWORD *)(result + 48);
    long long v7 = *(_OWORD *)(result + 64);
    *((void *)this + 45) = *(void *)(result + 80);
    *(_OWORD *)((char *)this + 328) = v6;
    *(_OWORD *)((char *)this + 344) = v7;
    *((_DWORD *)this + 92) = *(_DWORD *)(result + 88);
    *((void *)this + 58) = (*(uint64_t (**)(const ZinANELayer *, void))(*(void *)a2 + 368))(a2, 0);
    *((void *)this + 61) = (*(uint64_t (**)(const ZinANELayer *, uint64_t))(*(void *)a2 + 368))(a2, 1);
    *((void *)this + 62) = (*(uint64_t (**)(const ZinANELayer *, uint64_t))(*(void *)a2 + 368))(a2, 3);
    *((void *)this + 63) = (*(uint64_t (**)(const ZinANELayer *, uint64_t))(*(void *)a2 + 368))(a2, 4);
    if (ZinIrOpLayer::IsPELayer(a2) || *((void *)a2 + 33))
    {
      *((void *)this + 59) = (*(uint64_t (**)(const ZinANELayer *, uint64_t))(*(void *)a2 + 368))(a2, 2);
      *((unsigned char *)this + 48std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 1;
    }
    uint64_t v8 = *((void *)v5 + 13);
    if (v8)
    {
      uint64_t v9 = *(ZinIrSymbol ***)(v8 + 40);
      if (v9 != *(ZinIrSymbol ***)(v8 + 48))
      {
        if (*v9) {
          *((unsigned char *)this + 12std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = ZinIrSymbol::GetMemType(*v9) == 2;
        }
      }
    }
    uint64_t result = ZinIrTensor::GetInterchangeDescriptor(v5);
    if ((v10 & 0xFF00000000) != 0)
    {
      int v11 = *((unsigned __int8 *)this + 668);
      *(void *)((char *)this + 652) = result;
      *((_DWORD *)this + 165) = v10;
      *((_DWORD *)this + 166) = 1061158912;
      if (!v11) {
        *((unsigned char *)this + 668) = 1;
      }
    }
  }
  return result;
}

void ZinIrPerf::ConfigureInputTensorInfo(ZinIrPerf *this, const ZinANELayer *a2)
{
  if (*((void *)a2 + 12) != *((void *)a2 + 11))
  {
    ZinIrPerf::InitializeDMASrcInfo(this, a2);
    ZinIrPerf::InitializeL2SrcInfo(this, a2);
    long long v57 = 0uLL;
    *(void *)&long long v58 = 0;
    uint64_t v4 = (void *)*((void *)a2 + 11);
    uint64_t v5 = (void *)*((void *)a2 + 12);
    if (v4 == v5)
    {
      *(void *)((char *)this + 644) = 0;
      *(_OWORD *)((char *)this + 612) = 0u;
      *(_OWORD *)((char *)this + 628) = 0u;
    }
    else
    {
      do
      {
        if (!(*(unsigned int (**)(const ZinANELayer *))(*(void *)a2 + 120))(a2)
          || (uint64_t v7 = (*(uint64_t (**)(void, void, void))(*(void *)*v4 + 32))(*v4, 0, 0),
              ((*(uint64_t (**)(const ZinANELayer *, uint64_t))(*(void *)a2 + 200))(a2, v7) & 1) == 0))
        {
          uint64_t v8 = *((void *)&v57 + 1);
          if (*((void *)&v57 + 1) >= (unint64_t)v58)
          {
            uint64_t v10 = (uint64_t)(*((void *)&v57 + 1) - v57) >> 3;
            if ((unint64_t)(v10 + 1) >> 61) {
              std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
            }
            unint64_t v11 = (uint64_t)(v58 - v57) >> 2;
            if (v11 <= v10 + 1) {
              unint64_t v11 = v10 + 1;
            }
            if ((void)v58 - (void)v57 >= 0x7FFFFFFFFFFFFFF8uLL) {
              unint64_t v12 = 0x1FFFFFFFFFFFFFFFLL;
            }
            else {
              unint64_t v12 = v11;
            }
            if (v12) {
              uint64_t v13 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)&v58, v12);
            }
            else {
              uint64_t v13 = 0;
            }
            long long v14 = &v13[8 * v10];
            *(void *)long long v14 = *v4;
            uint64_t v9 = v14 + 8;
            long long v15 = (char *)*((void *)&v57 + 1);
            uint64_t v16 = (char *)v57;
            if (*((void *)&v57 + 1) != (void)v57)
            {
              do
              {
                uint64_t v17 = *((void *)v15 - 1);
                v15 -= 8;
                *((void *)v14 - 1) = v17;
                v14 -= 8;
              }
              while (v15 != v16);
              long long v15 = (char *)v57;
            }
            *(void *)&long long v57 = v14;
            *((void *)&v57 + 1) = v9;
            *(void *)&long long v58 = &v13[8 * v12];
            if (v15) {
              operator delete(v15);
            }
          }
          else
          {
            **((void **)&v57 + 1) = *v4;
            uint64_t v9 = (void *)(v8 + 8);
          }
          *((void *)&v57 + 1) = v9;
        }
        ++v4;
      }
      while (v4 != v5);
      long long v18 = (void *)*((void *)&v57 + 1);
      long long v19 = (void *)v57;
      *(_OWORD *)((char *)this + 612) = 0u;
      *(_OWORD *)((char *)this + 628) = 0u;
      *(void *)((char *)this + 644) = 0;
      if (v18 != v19)
      {
        unint64_t v20 = 0;
        unsigned int v21 = 1;
        while (1)
        {
          unint64_t v56 = 0;
          if (!ZinMemSourceIndexTranslator::GetDMASrcIndex(a2, (const ZinANELayer *)v20, (uint64_t *)&v56, v6))break; {
LABEL_26:
          }
          unint64_t v20 = v21;
          long long v18 = (void *)v57;
          ++v21;
          if (v20 >= (uint64_t)(*((void *)&v57 + 1) - v57) >> 3) {
            goto LABEL_42;
          }
        }
        uint64_t v22 = *(void *)(*((void *)a2 + 11) + 8 * v20);
        uint64_t v23 = (*(uint64_t (**)(uint64_t, void, void))(*(void *)v22 + 32))(v22, 0, 0);
        uint64_t v24 = *(void *)(*((void *)a2 + 11) + 8 * v20);
        if (v24 == ZinANELayer::GetTextureDataInput(a2))
        {
          uint64_t v30 = (*(uint64_t (**)(void, void, void))(**((void **)a2 + 25) + 32))(*((void *)a2 + 25), 0, 0);
          uint64_t v31 = *((void *)this + 35) + 40 * v56;
          uint64_t v32 = *(void *)(v30 + 80);
          long long v33 = *(_OWORD *)(v30 + 64);
          *(_OWORD *)uint64_t v31 = *(_OWORD *)(v30 + 48);
          *(_OWORD *)(v31 + 16) = v33;
          *(void *)(v31 + 32) = v32;
          uint64_t v29 = (*(uint64_t (**)(void, void, void))(**((void **)a2 + 25) + 32))(*((void *)a2 + 25), 0, 0);
          unint64_t v25 = v56;
        }
        else
        {
          unint64_t v25 = v56;
          uint64_t v26 = *((void *)this + 35) + 40 * v56;
          uint64_t v27 = *(void *)(v23 + 80);
          long long v28 = *(_OWORD *)(v23 + 64);
          *(_OWORD *)uint64_t v26 = *(_OWORD *)(v23 + 48);
          *(_OWORD *)(v26 + 16) = v28;
          *(void *)(v26 + 32) = v27;
          uint64_t v29 = v23;
        }
        *(_DWORD *)(*((void *)this + 38) + 4 * v25) = *(_DWORD *)(v29 + 88);
        uint64_t v34 = *(void *)(v23 + 104);
        if (v34 && (uint64_t v35 = *(ZinIrSymbol ***)(v34 + 40), v35 != *(ZinIrSymbol ***)(v34 + 48)) && *v35)
        {
          int MemType = ZinIrSymbol::GetMemType(*v35);
          long long v37 = (uint64_t *)(*((void *)this + 12) + 8 * (v56 >> 6));
          uint64_t v38 = 1 << v56;
          if (MemType == 2)
          {
            uint64_t v39 = *v37 | v38;
            goto LABEL_38;
          }
        }
        else
        {
          long long v37 = (uint64_t *)(*((void *)this + 12) + 8 * (v25 >> 6));
          uint64_t v38 = 1 << v25;
        }
        uint64_t v39 = *v37 & ~v38;
LABEL_38:
        uint64_t *v37 = v39;
        uint64_t InterchangeDescriptor = ZinIrTensor::GetInterchangeDescriptor((ZinIrTensor *)v23);
        if ((v41 & 0xFF00000000) != 0)
        {
          if (v56 >= 2) {
            std::__throw_out_of_range[abi:ne180100]("array::at");
          }
          int64x2_t v42 = (char *)this + 20 * v56 + 612;
          int v43 = v42[16];
          *(void *)int64x2_t v42 = InterchangeDescriptor;
          *((_DWORD *)v42 + 2) = v41;
          *((_DWORD *)v42 + 3) = 1061158912;
          if (!v43) {
            v42[16] = 1;
          }
        }
        goto LABEL_26;
      }
LABEL_42:
      if (v18)
      {
        *((void *)&v57 + 1) = v18;
        operator delete(v18);
      }
    }
    if (*((void *)a2 + 12) != *((void *)a2 + 11))
    {
      unint64_t v44 = 0;
      unsigned int v45 = 1;
      uint64_t v46 = &_os_log_internal;
      do
      {
        LODWORD(v56) = 0;
        if (ZinMemSourceIndexTranslator::GetL2SrcType(a2, v44, (int *)&v56)
          && os_log_type_enabled(v46, OS_LOG_TYPE_ERROR))
        {
          ZinIrPerf::ConfigureInputTensorInfo(&buf, v61);
        }
        int v47 = v56;
        if (v56 != 2)
        {
          uint64_t v48 = v56 != 0;
          *(_DWORD *)(*((void *)this + 32) + 4 * (v47 != 0)) = ZinMemSourceIndexTranslator::GetL2SourceFormat(a2, (const ZinANELayer *)v44);
          uint64_t v49 = *(void *)(*((void *)a2 + 11) + 8 * v44);
          uint64_t v50 = (*(uint64_t (**)(uint64_t, void, void))(*(void *)v49 + 32))(v49, 0, 0);
          long long v51 = *(_OWORD *)(v50 + 64);
          long long v57 = *(_OWORD *)(v50 + 48);
          long long v58 = v51;
          uint64_t v59 = *(void *)(v50 + 80);
          uint64_t v52 = *((void *)a2 + 25);
          if (v52 && *((void *)a2 + 24) == v48
            || !v47 && *(_DWORD *)(*((void *)a2 + 8) + 8) == 81 && (uint64_t v52 = *((void *)a2 + 57)) != 0)
          {
            uint64_t v53 = (*(uint64_t (**)(uint64_t, void, void))(*(void *)v52 + 32))(v52, 0, 0);
            long long v54 = *(_OWORD *)(v53 + 64);
            long long v57 = *(_OWORD *)(v53 + 48);
            long long v58 = v54;
            uint64_t v59 = *(void *)(v53 + 80);
          }
          uint64_t v55 = *((void *)this + 29) + 40 * v48;
          *(_OWORD *)uint64_t v55 = v57;
          *(_OWORD *)(v55 + 16) = v58;
          *(void *)(v55 + 32) = v59;
        }
        unint64_t v44 = v45++;
      }
      while (v44 < (uint64_t)(*((void *)a2 + 12) - *((void *)a2 + 11)) >> 3);
    }
  }
}

void sub_211389FEC(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, void *__p, uint64_t a12)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinIrPerf::ConfigurePerfInfoKernel(ZinIrPerf *this, const ZinANELayer *a2)
{
  *((unsigned char *)this + 396) = 0;
  int v4 = *((_DWORD *)this + 44);
  if (v4 == 5 || v4 == 2)
  {
    if (ZinIrOpLayer::IsNELayer(a2))
    {
      (*(void (**)(ZinIrKernel **__return_ptr, const ZinANELayer *, void))(*(void *)a2 + 568))(&v28, a2, 0);
      BOOL v6 = v28 != 0;
    }
    else
    {
      BOOL v6 = 0;
      long long v28 = 0;
    }
    *((unsigned char *)this + 396) = v6;
    ZinIrOpLayer::IsNELayer(a2);
    uint64_t v7 = *(void *)(*((void *)a2 + 54) + 64);
    uint64_t v8 = *(void *)(v7 + 16);
    uint64_t v9 = *(void *)(v7 + 24);
    uint64_t v10 = *(void *)(v7 + 32);
    long long v26 = *(_OWORD *)(v7 + 64);
    uint64_t v11 = *(void *)(v7 + 80);
    *((void *)this + 52) = v9;
    *((void *)this + 53) = v8;
    *((void *)this + 54) = v10;
    uint64_t v12 = *(void *)(v7 + 40);
    *(void *)&long long v13 = (int)v12;
    *((void *)&v13 + 1) = SHIDWORD(v12);
    *(_OWORD *)((char *)this + 184) = v13;
    uint64_t v14 = *(void *)(v7 + 48);
    *(void *)&long long v13 = (int)v14;
    *((void *)&v13 + 1) = SHIDWORD(v14);
    *(_OWORD *)((char *)this + 20std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v13;
    uint64_t v15 = *(void *)(v7 + 56);
    *(void *)&long long v13 = (int)v15;
    *((void *)&v13 + 1) = SHIDWORD(v15);
    *(_OWORD *)((char *)this + 216) = v13;
    *(void *)((char *)this + 388) = v11;
    *(_OWORD *)((char *)this + 372) = v26;
    uint64_t v16 = v28;
    uint64_t v27 = v11;
    long long v28 = 0;
    if (!v16) {
      goto LABEL_17;
    }
LABEL_10:
    ZinIrKernel::~ZinIrKernel(v16);
    MEMORY[0x21667D3C0](v17, 0x1032C40C25AA5B7, v18, v19);
    goto LABEL_17;
  }
  if (!ZinIrOpLayer::IsNELayer(a2))
  {
    int64x2_t v23 = vdupq_n_s64(1uLL);
    *((int64x2_t *)this + 25) = v23;
    *((int64x2_t *)this + 26) = v23;
    *((void *)this + 54) = 1;
    *((void *)this + 55) = 0x3FF0000000000000;
    *(int64x2_t *)((char *)this + 184) = v23;
    *(int64x2_t *)((char *)this + 20std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v23;
    *(int64x2_t *)((char *)this + 216) = v23;
    *(void *)((char *)this + 38std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
    *(void *)((char *)this + 388) = 0;
    *(void *)((char *)this + 372) = 0;
    goto LABEL_17;
  }
  if (*((_DWORD *)this + 44) != 4)
  {
    if (ZinIrOpLayer::IsNELayer(a2))
    {
      (*(void (**)(long long *__return_ptr, const ZinANELayer *, void))(*(void *)a2 + 568))(&v26, a2, 0);
      unint64_t v25 = (const ZinIrKernel *)v26;
    }
    else
    {
      unint64_t v25 = 0;
      *(void *)&long long v26 = 0;
    }
    ZinIrPerf::ConfigurePerfInfoNEKernel((uint64_t)this, v25);
    uint64_t v16 = (ZinIrKernel *)v26;
    *(void *)&long long v26 = 0;
    if (!v16) {
      goto LABEL_17;
    }
    goto LABEL_10;
  }
  uint64_t v21 = *((void *)a2 + 54);
  if (v21)
  {
    uint64_t v22 = *(const ZinIrKernel **)(v21 + 136);
    if (v22) {
      ZinIrPerf::ConfigurePerfInfoNEKernel((uint64_t)this, v22);
    }
  }
LABEL_17:
  uint64_t result = ZinIrOpLayer::IsNELayer(a2);
  if (result)
  {
    if (*((unsigned char *)this + 43))
    {
      ZinIrPerf::AddKerneltoKernelNameSet(this, (ZinEngineLayerMirInfo **)a2, *(int *)(*((void *)this + 4) + 8));
      uint64_t result = ZinIrPerf::HasRewoundKernel(this, (ZinEngineLayerMirInfo **)a2, *(int *)(*((void *)this + 4) + 8));
      *((unsigned char *)this + 728) = result;
    }
  }
  return result;
}

void sub_21138A254(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, ZinIrKernel *a9)
{
}

__n128 ZinIrPerf::ConfigurePerfInfo(ZinIrPerf *this, ZinEngineLayerMirInfo **a2, uint64_t a3, unint64_t *a4)
{
  if (a2[33])
  {
    ZinIrPerf::ConfigureMcacheInfo(this, (const ZinANELayer *)a2, a3, a4);
    uint64_t v7 = a2[33];
    if (v7 && a2[11] != a2[12])
    {
      unint64_t v8 = 0;
      do
      {
        __p[0] = 0;
        if (!ZinMemSourceIndexTranslator::GetDMASrcIndex((ZinMemSourceIndexTranslator *)a2, (const ZinANELayer *)v8, (uint64_t *)__p, v6)&& ((*(void *)(*((void *)this + 12) + (((unint64_t)__p[0] >> 3) & 0x1FFFFFFFFFFFFFF8)) >> SLOBYTE(__p[0])) & 1) == 0)
        {
          uint64_t v9 = *((void *)a2[33] + 12 * (uint64_t)__p[0] + 94);
          if (v9)
          {
            uint64_t v10 = ZinTensorDescriptorDmaInterleave(v9 + 208);
            *((void *)this + (uint64_t)__p[0] + 16) = v10;
          }
        }
        ++v8;
      }
      while (v8 < (a2[12] - a2[11]) >> 3);
      uint64_t v7 = a2[33];
    }
    if (!*((unsigned char *)this + 120))
    {
      uint64_t v11 = *((void *)v7 + 118);
      if (v11)
      {
        *((void *)this + 18) = ZinTensorDescriptorDmaInterleave(v11 + 208);
        uint64_t v7 = a2[33];
      }
    }
    uint64_t v12 = *((void *)v7 + 25);
    if (v12) {
      *((void *)this + 19) = v12;
    }
    long long v13 = (void *)*((void *)this + 3);
    if (*((unsigned char *)this + 536)) {
      *((unsigned char *)this + 536) = 0;
    }
    if (v13[11] == v13[12] || !*((unsigned char *)this + 46) || (uint64_t v14 = (void *)v13[14], v14 == (void *)v13[15]))
    {
      *((void *)this + 71) = 0;
      *((void *)this + 7std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
      *((void *)this + 72) = 0;
    }
    else
    {
      uint64_t v15 = (_DWORD *)v13[33];
      if (v15[408] == 4)
      {
        *((void *)this + 64) = *v14;
        *((_DWORD *)this + 13std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 1;
        *((void *)this + 66) = 0;
        *((unsigned char *)this + 536) = 1;
        uint64_t v15 = (_DWORD *)v13[33];
      }
      int v41 = 0;
      if (ZinEngineLayerMirInfo::HasChainRead(v15, &v41))
      {
        BOOL v16 = v41 != 0;
        (*(void (**)(void **__return_ptr, void *))(*v13 + 512))(__p, v13);
        uint64_t v17 = *(void *)(*((void *)__p[0] + v16) + 96);
        __p[1] = __p[0];
        operator delete(__p[0]);
        int v18 = *((unsigned __int8 *)this + 536);
        *((void *)this + 64) = v17;
        *((_DWORD *)this + 13std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
        *((void *)this + 66) = 0;
        if (!v18) {
          *((unsigned char *)this + 536) = 1;
        }
      }
      uint64_t v19 = (void *)v13[33];
      *((void *)this + 7std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v19[27];
      *((void *)this + 71) = v19[26];
      *((void *)this + 72) = v19[28];
    }
    unint64_t v20 = a2[33];
    if (v20)
    {
      if (*((_DWORD *)this + 44) == 4
        && *((unsigned char *)this + 396)
        && *((void *)this + 56) >= 2uLL
        && *((_DWORD *)v20 + 28) != 2)
      {
        *((void *)this + 2std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = *((void *)v20 + 13);
        uint64_t v21 = 1;
      }
      else
      {
        *((void *)this + 2std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 1;
        uint64_t v21 = *((void *)v20 + 13);
      }
      *((void *)this + 21) = v21;
      BOOL IsNELayer = ZinIrOpLayer::IsNELayer((ZinIrOpLayer *)a2);
      uint64_t v32 = (__n128 *)a2[33];
      if (IsNELayer)
      {
        *((_DWORD *)this + 184) = v32[9].n128_u32[0];
        *((unsigned char *)this + 74std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v32[9].n128_u8[5];
        *((unsigned char *)this + 741) = v32->n128_u8[1];
        ChannelAssignment = (MirInfoChannelAssignment *)ZinEngineLayerMirInfo::GetChannelAssignment((ZinEngineLayerMirInfo *)v32);
        *((void *)this + 93) = MirInfoChannelAssignment::GetActiveNEPerCluster(ChannelAssignment);
        uint64_t v34 = a2[33];
        *((unsigned char *)this + 752) = *(unsigned char *)v34;
        *((void *)this + 95) = *((void *)v34 + 12);
        uint64_t v35 = (MirInfoChannelAssignment *)ZinEngineLayerMirInfo::GetChannelAssignment(v34);
        *((void *)this + 96) = MirInfoChannelAssignment::GetOCGSize(v35);
        uint64_t v36 = a2[33];
        *((_DWORD *)this + 194) = *((_DWORD *)v36 + 28);
        *((void *)this + 98) = *((void *)v36 + 17);
        *(int8x16_t *)((char *)this + 792) = vextq_s8(*(int8x16_t *)((char *)v36 + 120), *(int8x16_t *)((char *)v36 + 120), 8uLL);
        long long v37 = (MirInfoChannelAssignment *)ZinEngineLayerMirInfo::GetChannelAssignment(v36);
        *((unsigned char *)this + 832) = MirInfoChannelAssignment::GetFatTileEnable(v37);
        uint64_t v38 = (ZinIrTarget *)ZinEngineLayerMirInfo::GetChannelAssignment(a2[33]);
        *((void *)this + 103) = ZinIrTarget::GetLut(v38);
        uint64_t v39 = a2[33];
        *((unsigned char *)this + 833) = *((unsigned char *)v39 + 148);
        *((unsigned char *)this + 74std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = *((unsigned char *)v39 + 149);
      }
      else
      {
        __n128 result = v32[15];
        *((__n128 *)this + 53) = result;
      }
    }
    else
    {
      BOOL v22 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v22) {
        ZinIrPerf::ConfigurePerfInfo(v22, v23, v24, v25, v26, v27, v28, v29);
      }
    }
  }
  return result;
}

uint64_t ZinIrPerf::ValidateTexturePerfInfo(ZinIrPerf *this, const ZinANELayer *a2)
{
  ZinTextureLayerUtils::GetPassthroughAxes(a2, (char **)&__p);
  if (!*((void *)a2 + 25))
  {
    uint64_t v5 = __p;
    if (!__p) {
      return 0;
    }
    goto LABEL_19;
  }
  uint64_t v4 = *((void *)a2 + 30);
  uint64_t v5 = __p;
  if (v4)
  {
    if (__p == v20)
    {
      BOOL v12 = 0;
      BOOL v13 = 0;
    }
    else
    {
      uint64_t v6 = 0;
      uint64_t v7 = (int *)__p;
      do
      {
        int v8 = *v7++;
        if (v8 == 2) {
          ++v6;
        }
      }
      while (v7 != v20);
      uint64_t v9 = 0;
      uint64_t v10 = (int *)__p;
      do
      {
        int v11 = *v10++;
        if (v11 == 4) {
          ++v9;
        }
      }
      while (v10 != v20);
      BOOL v12 = v6 != 0;
      BOOL v13 = v9 != 0;
    }
    uint64_t v14 = *(unsigned int *)(v4 + 192);
    if (!*((unsigned char *)this + 552))
    {
      BOOL v16 = !v13;
      uint64_t v17 = 0x10000000000;
      if (v16) {
        uint64_t v17 = 0;
      }
      BOOL v16 = !v12;
      uint64_t v18 = 0x100000000;
      if (v16) {
        uint64_t v18 = 0;
      }
      *((void *)this + 68) = v17 | v18 | v14;
      *((unsigned char *)this + 552) = 1;
      if (v5) {
        goto LABEL_19;
      }
      return 0;
    }
    *((_DWORD *)this + 136) = v14;
    *((unsigned char *)this + 548) = v12;
    *((unsigned char *)this + 549) = v13;
  }
  if (v5)
  {
LABEL_19:
    unint64_t v20 = v5;
    operator delete(v5);
  }
  return 0;
}

uint64_t ZinIrPerf::ValidatePerfInfo(ZinIrPerf *this, const ZinANELayer *a2, const ZinCustomPerfInfo *a3)
{
  if (a2)
  {
    *((void *)this + 3) = a2;
    if (a3)
    {
      if (ZinIrOpLayer::IsNELayer(a2))
      {
        return ZinIrPerf::ValidateNEPerfInfo(this, a2, a3);
      }
      else
      {
        return ZinIrPerf::ValidatePEPerfInfo(this, a2, a3);
      }
    }
    else
    {
      return ZinIrPerf::ValidateDefaultPerfInfo(this, a2);
    }
  }
  else
  {
    BOOL v7 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (v7) {
      ZinIrPerf::ValidatePerfInfo(v7, v8, v9, v10, v11, v12, v13, v14);
    }
    return 3;
  }
}

uint64_t ZinIrPerf::ValidateNEPerfInfo(ZinIrPerf *this, const ZinANELayer *a2, const ZinNECustomPerfInfo *a3)
{
  uint64_t v6 = ZinIrPerf::ValidatePerfInfo(this, a2);
  if (v6)
  {
    uint64_t v7 = v6;
    BOOL v8 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (v8) {
      ZinIrPerf::ValidateNEPerfInfo(v8, v9, v10, v11, v12, v13, v14, v15);
    }
    return v7;
  }
  ZinCommonPerfInfo::SetCommonPerfInfo((ZinIrPerf *)((char *)this + 56), a3);
  ZinNEPerfInfo::SetNEPerfInfo((ZinIrPerf *)((char *)this + 672), a3);
  if (ZinIrPerf::IsValidPerfInfo(this, a2)) {
    return 3;
  }

  return ZinIrPerf::GetNEWorkUnitShapes(this);
}

uint64_t ZinIrPerf::ValidatePEPerfInfo(ZinIrPerf *this, const ZinANELayer *a2, const ZinPECustomPerfInfo *a3)
{
  ZinIrPerf::ValidatePerfInfo(this, a2);
  ZinCommonPerfInfo::SetCommonPerfInfo((ZinIrPerf *)((char *)this + 56), a3);
  if (*((unsigned char *)a3 + 536)) {
    *((void *)this + 106) = *((void *)a3 + 66);
  }
  if (*((unsigned char *)a3 + 552)) {
    *((void *)this + 107) = *((void *)a3 + 68);
  }

  return ZinIrPerf::IsValidPerfInfo(this, a2);
}

void ZinCommonPerfInfo::SetCommonPerfInfo(ZinCommonPerfInfo *this, const ZinCustomPerfInfo *a2)
{
  if (*((unsigned char *)a2 + 112))
  {
    if (*((unsigned char *)a2 + 224)) {
      unint64_t v3 = 2;
    }
    else {
      unint64_t v3 = 1;
    }
    uint64_t v30 = (uint64_t *)((char *)this + 40);
    std::vector<BOOL>::resize((uint64_t)this + 40, v3, 0);
    std::vector<ZinTensorDimensions>::resize((uint64_t)this + 224, v3);
    std::vector<unsigned int>::resize((std::vector<int> *)((char *)this + 248), v3);
    std::vector<ZinTensorDimensions>::resize((uint64_t)this + 176, v3);
    std::vector<unsigned int>::resize((std::vector<int> *)((char *)this + 200), v3);
    uint64_t v4 = 0;
    unint64_t v5 = 0;
    uint64_t v6 = (char *)this + 556;
    uint64_t v7 = (char *)a2 + 104;
    do
    {
      if (*(v7 - 56))
      {
        uint64_t v8 = *((void *)this + 22) + v4;
        long long v9 = *((_OWORD *)v7 - 6);
        long long v10 = *((_OWORD *)v7 - 5);
        *(void *)(v8 + 32) = *((void *)v7 - 8);
        *(_OWORD *)uint64_t v8 = v9;
        *(_OWORD *)(v8 + 16) = v10;
        uint64_t v11 = *((void *)this + 28) + v4;
        long long v12 = *((_OWORD *)v7 - 6);
        long long v13 = *((_OWORD *)v7 - 5);
        *(void *)(v11 + 32) = *((void *)v7 - 8);
        *(_OWORD *)uint64_t v11 = v12;
        *(_OWORD *)(v11 + 16) = v13;
      }
      if (*(v7 - 44))
      {
        unsigned int v14 = *((_DWORD *)v7 - 12);
        if (IsFormatDMAConvertibleToFP16(v14)) {
          int v15 = 3;
        }
        else {
          int v15 = v14;
        }
        *(_DWORD *)(*((void *)this + 25) + 4 * v5) = v15;
        *(_DWORD *)(*((void *)this + 31) + 4 * v5) = *((_DWORD *)v7 - 12);
      }
      if (*(v7 - 39))
      {
        uint64_t v16 = *v30;
        unint64_t v17 = v5 >> 6;
        uint64_t v18 = 1 << v5;
        if (*(v7 - 40)) {
          uint64_t v19 = *(void *)(v16 + 8 * v17) | v18;
        }
        else {
          uint64_t v19 = *(void *)(v16 + 8 * v17) & ~v18;
        }
        *(void *)(v16 + 8 * v17) = v19;
      }
      if (*(v7 - 24)) {
        *((void *)this + v5 + 9) = *((void *)v7 - 4);
      }
      if (*v7)
      {
        int v20 = v6[16];
        *(_OWORD *)uint64_t v6 = *((_OWORD *)v7 - 1);
        if (!v20) {
          v6[16] = 1;
        }
      }
      ++v5;
      v6 += 20;
      v4 += 40;
      v7 += 112;
    }
    while (v3 != v5);
  }
  if (*((unsigned char *)a2 + 336))
  {
    if (*((unsigned char *)a2 + 272))
    {
      long long v21 = *(_OWORD *)((char *)a2 + 232);
      long long v22 = *(_OWORD *)((char *)a2 + 248);
      *((void *)this + 38) = *((void *)a2 + 33);
      *((_OWORD *)this + 17) = v21;
      *((_OWORD *)this + 18) = v22;
    }
    if (*((unsigned char *)a2 + 284)) {
      *((_DWORD *)this + 78) = *((_DWORD *)a2 + 70);
    }
    if (*((unsigned char *)a2 + 289)) {
      *((unsigned char *)this + 64) = *((unsigned char *)a2 + 288);
    }
    if (*((unsigned char *)a2 + 304)) {
      *((void *)this + 11) = *((void *)a2 + 37);
    }
    if (*((unsigned char *)a2 + 328))
    {
      int v23 = *((unsigned __int8 *)this + 612);
      *(_OWORD *)((char *)this + 596) = *(_OWORD *)((char *)a2 + 312);
      if (!v23) {
        *((unsigned char *)this + 612) = 1;
      }
    }
  }
  if (*((unsigned char *)a2 + 352)) {
    *((void *)this + 12) = *((void *)a2 + 43);
  }
  if (*((unsigned char *)a2 + 368))
  {
    uint64_t v24 = (int *)((char *)a2 + 360);
    if (*((unsigned char *)this + 496))
    {
      int v25 = *v24;
      *((_WORD *)this + 246) = *((_WORD *)a2 + 182);
      *((_DWORD *)this + 122) = v25;
    }
    else
    {
      *((void *)this + 61) = *(void *)v24;
      *((unsigned char *)this + 496) = 1;
    }
  }
  if (*((unsigned char *)a2 + 400))
  {
    int v26 = *((unsigned __int8 *)this + 480);
    uint64_t v27 = *((void *)a2 + 49);
    *(_OWORD *)((char *)this + 456) = *(_OWORD *)((char *)a2 + 376);
    *((void *)this + 59) = v27;
    if (!v26) {
      *((unsigned char *)this + 48std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 1;
    }
  }
  if (*((unsigned char *)a2 + 424)) {
    *((void *)this + 63) = *((void *)a2 + 52);
  }
  if (*((unsigned char *)a2 + 440)) {
    *((void *)this + 64) = *((void *)a2 + 54);
  }
  if (*((unsigned char *)a2 + 456)) {
    *((void *)this + 65) = *((void *)a2 + 56);
  }
  if (*((unsigned char *)a2 + 488))
  {
    long long v28 = *((_OWORD *)a2 + 29);
    *((void *)this + 68) = *((void *)a2 + 60);
    *((_OWORD *)this + 33) = v28;
  }
  if (*((unsigned char *)a2 + 504)) {
    *((void *)this + 14) = *((void *)a2 + 62);
  }
  if (*((unsigned char *)a2 + 520)) {
    *((void *)this + 13) = *((void *)a2 + 64);
  }
  if (*((unsigned char *)a2 + 412)) {
    *((_DWORD *)this + 138) = *((_DWORD *)a2 + 102);
  }
}

void std::vector<BOOL>::resize(uint64_t a1, unint64_t a2, int a3)
{
  unint64_t v5 = *(void *)(a1 + 8);
  unint64_t v6 = a2 - v5;
  if (a2 <= v5)
  {
    *(void *)(a1 + 8) = a2;
  }
  else
  {
    uint64_t v8 = *(void *)(a1 + 16);
    unint64_t v9 = v8 << 6;
    if (v8 << 6 < v6 || v5 > (v8 << 6) - v6)
    {
      long long v21 = 0;
      long long v22 = 0uLL;
      if ((a2 & 0x8000000000000000) != 0) {
        std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
      }
      unint64_t v11 = v8 << 7;
      if (v11 <= ((a2 + 63) & 0xFFFFFFFFFFFFFFC0)) {
        unint64_t v11 = (a2 + 63) & 0xFFFFFFFFFFFFFFC0;
      }
      if (v9 <= 0x3FFFFFFFFFFFFFFELL) {
        unint64_t v12 = v11;
      }
      else {
        unint64_t v12 = 0x7FFFFFFFFFFFFFFFLL;
      }
      std::vector<BOOL>::reserve(&v21, v12);
      long long v13 = *(unint64_t **)a1;
      unint64_t v14 = *(void *)(a1 + 8);
      *(void *)&long long v22 = v14 + v6;
      int v23 = v21;
      int v24 = 0;
      std::__copy_aligned[abi:ne180100]<std::vector<BOOL>,true>(v13, 0, (uint64_t)&v13[v14 >> 6], v14 & 0x3F, (uint64_t)&v23, (uint64_t)&v19);
      unint64_t v17 = v19;
      LODWORD(v18) = v20;
      int v15 = *(char **)a1;
      *(void *)a1 = v21;
      long long v21 = v15;
      long long v16 = *(_OWORD *)(a1 + 8);
      *(_OWORD *)(a1 + 8) = v22;
      long long v22 = v16;
      if (v15) {
        operator delete(v15);
      }
    }
    else
    {
      unint64_t v17 = (char *)(*(void *)a1 + 8 * (v5 >> 6));
      uint64_t v18 = *(void *)(a1 + 8) & 0x3FLL;
      *(void *)(a1 + 8) = a2;
    }
    if (a2 != v5)
    {
      if (a3)
      {
        long long v21 = v17;
        LODWORD(v22) = v18;
        std::__fill_n[abi:ne180100]<true,std::vector<BOOL>>(&v21, v6);
      }
      else
      {
        long long v21 = v17;
        LODWORD(v22) = v18;
        std::__fill_n[abi:ne180100]<false,std::vector<BOOL>>((uint64_t)&v21, v6);
      }
    }
  }
}

void sub_21138AD84(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, void *__p)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

void std::vector<ZinTensorDimensions>::resize(uint64_t a1, unint64_t a2)
{
  unint64_t v2 = 0xCCCCCCCCCCCCCCCDLL * ((uint64_t)(*(void *)(a1 + 8) - *(void *)a1) >> 3);
  BOOL v3 = a2 >= v2;
  unint64_t v4 = a2 - v2;
  if (v4 != 0 && v3)
  {
    std::vector<ZinTensorDimensions>::__append((void **)a1, v4);
  }
  else if (!v3)
  {
    *(void *)(a1 + 8) = *(void *)a1 + 40 * a2;
  }
}

void ZinNEPerfInfo::SetNEPerfInfo(ZinNEPerfInfo *this, const ZinNECustomPerfInfo *a2)
{
  if (*((unsigned char *)a2 + 561)) {
    *((unsigned char *)this + 56) = *((unsigned char *)a2 + 560);
  }
  if (*((unsigned char *)a2 + 568)) {
    *((_DWORD *)this + 16) = *((_DWORD *)a2 + 141);
  }
  if (*((unsigned char *)a2 + 573)) {
    *((unsigned char *)this + 68) = *((unsigned char *)a2 + 572);
  }
  if (*((unsigned char *)a2 + 584)) {
    *((void *)this + 9) = *((void *)a2 + 72);
  }
  if (*((unsigned char *)a2 + 593)) {
    *((unsigned char *)this + 8std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = *((unsigned char *)a2 + 592);
  }
  if (*((unsigned char *)a2 + 608)) {
    *((void *)this + 11) = *((void *)a2 + 75);
  }
  if (*((unsigned char *)a2 + 624)) {
    *((void *)this + 12) = *((void *)a2 + 77);
  }
  if (*((unsigned char *)a2 + 640)) {
    *((void *)this + 14) = *((void *)a2 + 79);
  }
  if (*((unsigned char *)a2 + 656)) {
    *((void *)this + 15) = *((void *)a2 + 81);
  }
  if (*((unsigned char *)a2 + 672)) {
    *((void *)this + 16) = *((void *)a2 + 83);
  }
  if (*((unsigned char *)a2 + 684)) {
    *((_DWORD *)this + 15) = *((_DWORD *)a2 + 170);
  }
  if (*((unsigned char *)a2 + 692))
  {
    *(unsigned char *)(*((void *)this + 21) + 341) = 1;
    *(double *)(*((void *)this + 21) + 384) = ZinGetWeightElementSizeInBytes(*((_DWORD *)a2 + 172));
    *((_DWORD *)this + 34) = *((_DWORD *)a2 + 172);
  }
  if (*((unsigned char *)a2 + 697)) {
    *((unsigned char *)this + 69) = *((unsigned char *)a2 + 696);
  }
  if (*((unsigned char *)a2 + 712)) {
    *((void *)this + 19) = *((void *)a2 + 88);
  }
  if (*((unsigned char *)a2 + 721)) {
    *((unsigned char *)this + 16std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = *((unsigned char *)a2 + 720);
  }
  if (*((unsigned char *)a2 + 723)) {
    *((unsigned char *)this + 161) = *((unsigned char *)a2 + 722);
  }
  if (*((unsigned char *)a2 + 529))
  {
    uint64_t v4 = *((void *)a2 + 68);
    unint64_t v5 = (char *)*((void *)a2 + 67);
    if ((char *)v4 != v5 && (char *)this + 24 != (char *)a2 + 536)
    {
      std::vector<WorkUnit>::__assign_with_size[abi:ne180100]<WorkUnit*,WorkUnit*>((char *)this + 24, v5, v4, 0xCCCCCCCCCCCCCCCDLL * ((v4 - (uint64_t)v5) >> 4));
    }
  }
}

void ZinIrPerf::InitializeL2SrcInfo(ZinIrPerf *this, const ZinANELayer *a2)
{
  (*(void (**)(unsigned char **__return_ptr, const ZinANELayer *))(*(void *)a2 + 512))(&v8, a2);
  BOOL v3 = v8;
  uint64_t v4 = v9;
  if (v8)
  {
    unint64_t v9 = v8;
    operator delete(v8);
  }
  unint64_t v5 = (v4 - v3) >> 3;
  uint64_t v7 = (int *)*((void *)this + 29);
  unint64_t v6 = (std::vector<int> *)((char *)this + 232);
  v6->__end_ = v7;
  v6[1].__end_ = v6[1].__begin_;
  std::vector<ZinTensorDimensions>::resize((uint64_t)v6, v5);
  std::vector<unsigned int>::resize(v6 + 1, v5);
}

void ZinIrPerf::InitializeDMASrcInfo(ZinIrPerf *this, const ZinANELayer *a2)
{
  unint64_t DMAInputCount = ZinMemSourceIndexTranslator::GetDMAInputCount(a2, a2);
  *((void *)this + 36) = *((void *)this + 35);
  *((void *)this + 39) = *((void *)this + 38);
  *((void *)this + 13) = 0;
  std::vector<ZinTensorDimensions>::resize((uint64_t)this + 280, DMAInputCount);
  std::vector<unsigned int>::resize((std::vector<int> *)((char *)this + 304), DMAInputCount);

  std::vector<BOOL>::resize((uint64_t)this + 96, DMAInputCount, 0);
}

uint64_t ZinIrPerf::GetEngineLayerFusedKernel@<X0>(const ZinANELayer *a1@<X1>, void *a2@<X8>)
{
  uint64_t result = ZinIrOpLayer::IsNELayer(a1);
  if (result)
  {
    unint64_t v6 = *(uint64_t (**)(const ZinANELayer *, void))(*(void *)a1 + 568);
    return v6(a1, 0);
  }
  else
  {
    *a2 = 0;
  }
  return result;
}

uint64_t ZinIrPerf::ConfigurePerfInfoNEKernel(uint64_t this, const ZinIrKernel *a2)
{
  *(unsigned char *)(this + 396) = a2 != 0;
  if (a2)
  {
    uint64_t v3 = this;
    *(double *)(this + 44std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = ZinIrKernel::GetWeightElementSizeInBytes(a2);
    long long v4 = *(_OWORD *)((char *)a2 + 248);
    long long v5 = *(_OWORD *)((char *)a2 + 264);
    *(void *)(v3 + 432) = *((void *)a2 + 35);
    *(_OWORD *)(v3 + 40std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v4;
    *(_OWORD *)(v3 + 416) = v5;
    *(void *)&long long v4 = *((void *)a2 + 41);
    *(void *)&long long v5 = *((void *)a2 + 42);
    *(void *)&long long v6 = (int)v4;
    *((void *)&v6 + 1) = SDWORD1(v4);
    *(_OWORD *)(v3 + 184) = v6;
    *(void *)&long long v6 = (int)v5;
    *((void *)&v6 + 1) = SDWORD1(v5);
    *(_OWORD *)(v3 + 20std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v6;
    *(void *)&long long v4 = *((void *)a2 + 43);
    *(void *)&long long v6 = (int)v4;
    *((void *)&v6 + 1) = SDWORD1(v4);
    *(_OWORD *)(v3 + 216) = v6;
    long long v7 = *((_OWORD *)a2 + 22);
    *(void *)(v3 + 388) = *((void *)a2 + 46);
    *(_OWORD *)(v3 + 372) = v7;
    *(_DWORD *)(v3 + 808) = ZinIrKernel::GetWeightFormat(a2);
    this = ZinIrKernel::HasVectorPalettizedWeight(a2);
    if (this) {
      *(void *)(v3 + 816) = *((void *)a2 + 52);
    }
    *(void *)(v3 + 448) = *((void *)a2 + 50);
    *(_DWORD *)(v3 + 456) = *((_DWORD *)a2 + 94);
  }
  return this;
}

void ZinIrPerf::AddKerneltoKernelNameSet(ZinIrPerf *this, ZinEngineLayerMirInfo **a2, uint64_t a3)
{
  if (ZinIrOpLayer::IsNELayer((ZinIrOpLayer *)a2))
  {
    ZinIrPerf::GetKernelSymbolNamesForActiveNE(a2, a3, (uint64_t)v6);
    std::vector<std::vector<std::string>>::push_back[abi:ne180100]((uint64_t *)this, (uint64_t)v6);
    long long v7 = (void **)v6;
    std::vector<std::string>::__destroy_vector::operator()[abi:ne180100](&v7);
  }
}

void sub_21138B250(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, ...)
{
  va_start(va, a4);
  std::vector<std::string>::__destroy_vector::operator()[abi:ne180100]((void ***)va);
  _Unwind_Resume(a1);
}

uint64_t ZinIrPerf::HasRewoundKernel(ZinIrPerf *this, ZinEngineLayerMirInfo **a2, uint64_t a3)
{
  ZinIrPerf::GetKernelSymbolNamesForActiveNE(a2, a3, (uint64_t)&v15);
  if (v15 == v16
    || (uint64_t v5 = *(void *)this, v4 = *((void *)this + 1), v4 - *(void *)this == 24)
    || (uint64_t v6 = v4 - 24, v4 - 24 == v5))
  {
    uint64_t v12 = 0;
  }
  else
  {
    while (1)
    {
      memset(&v14, 0, sizeof(v14));
      long long v7 = *(long long **)(v6 - 24);
      uint64_t v8 = *(long long **)(v6 - 16);
      v6 -= 24;
      std::vector<std::string>::__init_with_size[abi:ne180100]<std::string*,std::string*>(&v14, v7, v8, 0xAAAAAAAAAAAAAAABLL * (((char *)v8 - (char *)v7) >> 3));
      std::string::size_type size = v14.__r_.__value_.__l.__size_;
      unint64_t v9 = (unsigned __int8 *)v14.__r_.__value_.__r.__words[0];
      unint64_t v11 = v15;
      if (v14.__r_.__value_.__l.__size_ - v14.__r_.__value_.__r.__words[0] == v16 - v15) {
        break;
      }
LABEL_8:
      unint64_t v17 = &v14;
      std::vector<std::string>::__destroy_vector::operator()[abi:ne180100]((void ***)&v17);
      uint64_t v12 = 0;
      if (v6 == v5) {
        goto LABEL_11;
      }
    }
    while (v9 != (unsigned __int8 *)size)
    {
      if (!std::equal_to<std::string>::operator()[abi:ne180100]((uint64_t)&v17, v9, v11)) {
        goto LABEL_8;
      }
      v9 += 24;
      v11 += 24;
    }
    unint64_t v17 = &v14;
    std::vector<std::string>::__destroy_vector::operator()[abi:ne180100]((void ***)&v17);
    uint64_t v12 = 1;
  }
LABEL_11:
  v14.__r_.__value_.__r.__words[0] = (std::string::size_type)&v15;
  std::vector<std::string>::__destroy_vector::operator()[abi:ne180100]((void ***)&v14);
  return v12;
}

void sub_21138B390(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, void **a10, uint64_t a11, uint64_t a12, char a13)
{
  a10 = (void **)&a13;
  std::vector<std::string>::__destroy_vector::operator()[abi:ne180100](&a10);
  _Unwind_Resume(a1);
}

void ZinIrPerf::ConfigureCacheHintKernelInfo(ZinIrPerf *this, const ZinANELayer *a2)
{
  if (!*((void *)a2 + 33)) {
    ZinAssertImpl("Perf model internal error: missing mir_info");
  }
  (*(void (**)(ZinIrTensor **__return_ptr, const ZinANELayer *))(*(void *)a2 + 128))(&v16, a2);
  uint64_t v4 = v16;
  if (v17) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v17);
  }
  if (v4)
  {
    long long v22 = 0;
    int v23 = 0;
    uint64_t v24 = 0;
    uint64_t v19 = 0;
    int v20 = 0;
    uint64_t v21 = 0;
    LOBYTE(v16) = 0;
    char v18 = 0;
    ZinIrRegAllocUtil::FindSortedConsumersAndProducers(v4, (uint64_t *)&v22, (uint64_t *)&v19, (ZinTensorFamilyUtil *)&v16);
    std::__optional_destruct_base<ZinTensorFamilyUtil,false>::~__optional_destruct_base[abi:ne180100]((uint64_t)&v16);
    uint64_t v5 = v22;
    uint64_t v6 = v23 - v22;
    if (v23 != v22)
    {
      uint64_t v7 = 0;
      unint64_t v8 = v6 >> 3;
      if ((unint64_t)(v6 >> 3) <= 1) {
        uint64_t v9 = 1;
      }
      else {
        uint64_t v9 = v6 >> 3;
      }
      LOBYTE(v6) = 1;
      do
      {
        uint64_t v10 = *(void *)(*(void *)&v22[8 * v7] + 264);
        if (v10 && !*(_DWORD *)(v10 + 1412)) {
          break;
        }
        LOBYTE(v6) = v8 > ++v7;
      }
      while (v9 != v7);
    }
    unint64_t v11 = v19;
    if (v20 != v19)
    {
      unint64_t v12 = (v20 - v19) >> 3;
      if (v12 <= 1) {
        unint64_t v12 = 1;
      }
      uint64_t v13 = (uint64_t)v19;
      do
      {
        if (*(const ZinANELayer **)v13 == a2) {
          break;
        }
        uint64_t v14 = *(void *)(*(void *)v13 + 264);
        if (!v14) {
          ZinAssertImpl("MirInfo must exist for MemCache analysis in perf model.");
        }
        int v15 = *(_DWORD *)(v14 + 1416);
        LOBYTE(v6) = !v15 || (v15 != 2) & v6;
        v13 += 8;
        --v12;
      }
      while (v12);
    }
    if (v6) {
      *((unsigned char *)this + 611) = 1;
    }
    if (v11)
    {
      int v20 = v11;
      operator delete(v11);
      uint64_t v5 = v22;
    }
    if (v5)
    {
      int v23 = v5;
      operator delete(v5);
    }
  }
}

void sub_21138B540(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
  std::__optional_destruct_base<ZinTensorFamilyUtil,false>::~__optional_destruct_base[abi:ne180100]((uint64_t)&a9);
  unint64_t v11 = *(void **)(v9 - 80);
  if (v11)
  {
    *(void *)(v9 - 72) = v11;
    operator delete(v11);
  }
  unint64_t v12 = *(void **)(v9 - 56);
  if (v12)
  {
    *(void *)(v9 - 48) = v12;
    operator delete(v12);
  }
  _Unwind_Resume(a1);
}

void ZinIrPerf::ConfigureMcacheInfo(ZinIrPerf *this, const ZinANELayer *a2, uint64_t a3, unint64_t *a4)
{
  *((_DWORD *)this + 152) = 0;
  if (!*((unsigned char *)this + 49)) {
    return;
  }
  if (*((void *)a2 + 33))
  {
    if (*((void *)a2 + 11) != *((void *)a2 + 12))
    {
      unint64_t v6 = 0;
      unsigned int v7 = 0;
      unint64_t v8 = (char *)this + 608;
      while (1)
      {
        uint64_t v22 = 0;
        if (!ZinMemSourceIndexTranslator::GetDMASrcIndex(a2, (const ZinANELayer *)v6, &v22, a4)) {
          break;
        }
LABEL_35:
        unint64_t v6 = ++v7;
        if (v7 >= (unint64_t)((uint64_t)(*((void *)a2 + 12) - *((void *)a2 + 11)) >> 3))
        {
          if (!*(_DWORD *)(*((void *)a2 + 33) + 1412)) {
            *((unsigned char *)this + 61std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 1;
          }
          ZinIrPerf::ConfigureCacheHintKernelInfo(this, a2);
          return;
        }
      }
      if (v22) {
        uint64_t v9 = 1420;
      }
      else {
        uint64_t v9 = 1400;
      }
      int v10 = *(_DWORD *)(*((void *)a2 + 33) + v9);
      uint64_t InputTensor = (const ZinIrTensor *)ZinIrOpLayer::GetInputTensor(a2, v6);
      if (v10 || *((uint64_t *)a2 + 6) < 1) {
        goto LABEL_10;
      }
      int v15 = *(void **)(*((void *)a2 + 11) + 8 * v6);
      if ((*(_DWORD *)(v15[8] + 8) - 28) > 2)
      {
LABEL_34:
        v8[v22] = 1;
        goto LABEL_35;
      }
      long long v16 = (ZinIrTensor *)(*(uint64_t (**)(void *, void, void))(*v15 + 32))(v15, 0, 0);
      ZinIrTensor::GetTensorFamily(v16, (uint64_t)&v23);
      if (v23 == v24)
      {
LABEL_27:
        int v21 = 1;
        if (v23)
        {
LABEL_32:
          uint64_t v24 = v23;
          operator delete(v23);
        }
      }
      else
      {
        unint64_t v17 = v23;
        while (1)
        {
          uint64_t v18 = *(void *)(*(void *)v17 + 96);
          uint64_t v19 = *(void *)(v18 + 112);
          uint64_t v20 = *(void *)(v18 + 120);
          if (v19 != v20) {
            break;
          }
LABEL_26:
          v17 += 8;
          if (v17 == v24) {
            goto LABEL_27;
          }
        }
        while (*(void *)(*(void *)v19 + 48) >= *((void *)a2 + 6))
        {
          v19 += 8;
          if (v19 == v20) {
            goto LABEL_26;
          }
        }
        int v21 = 0;
        if (v23) {
          goto LABEL_32;
        }
      }
      if (!v21) {
        goto LABEL_34;
      }
LABEL_10:
      ContributingEngineLayer(InputTensor, (void **)&v23);
      if (v23 == v24)
      {
LABEL_15:
        int v14 = 0;
        if (!v23) {
          goto LABEL_17;
        }
      }
      else
      {
        unint64_t v12 = v23;
        while (1)
        {
          uint64_t v13 = *(void *)(*(void *)v12 + 264);
          if (v13)
          {
            if (!*(_DWORD *)(v13 + 1412)) {
              break;
            }
          }
          v12 += 8;
          if (v12 == v24) {
            goto LABEL_15;
          }
        }
        int v14 = 1;
        if (!v23)
        {
LABEL_17:
          if (!v14) {
            goto LABEL_35;
          }
          goto LABEL_34;
        }
      }
      uint64_t v24 = v23;
      operator delete(v23);
      goto LABEL_17;
    }
    if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_DEBUG)) {
      ZinIrPerf::ConfigureMcacheInfo();
    }
  }
  else if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_DEBUG))
  {
    ZinIrPerf::ConfigureMcacheInfo();
  }
}

void **std::vector<std::vector<std::string>>::push_back[abi:ne180100](uint64_t *a1, uint64_t a2)
{
  unint64_t v6 = a1[2];
  uint64_t result = (void **)(a1 + 2);
  unint64_t v5 = v6;
  unsigned int v7 = *(result - 1);
  if ((unint64_t)v7 >= v6)
  {
    unint64_t v9 = 0xAAAAAAAAAAAAAAABLL * (((uint64_t)v7 - *a1) >> 3);
    unint64_t v10 = v9 + 1;
    if (v9 + 1 > 0xAAAAAAAAAAAAAAALL) {
      std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
    }
    unint64_t v11 = 0xAAAAAAAAAAAAAAABLL * ((uint64_t)(v5 - *a1) >> 3);
    if (2 * v11 > v10) {
      unint64_t v10 = 2 * v11;
    }
    if (v11 >= 0x555555555555555) {
      unint64_t v12 = 0xAAAAAAAAAAAAAAALL;
    }
    else {
      unint64_t v12 = v10;
    }
    v16[4] = result;
    uint64_t v13 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<std::string>>((uint64_t)result, v12);
    int v14 = &v13[24 * v9];
    v16[0] = v13;
    v16[1] = v14;
    v16[3] = &v13[24 * v15];
    *((void *)v14 + 1) = 0;
    *((void *)v14 + 2) = 0;
    *(void *)int v14 = 0;
    *(_OWORD *)int v14 = *(_OWORD *)a2;
    *((void *)v14 + 2) = *(void *)(a2 + 16);
    *(void *)a2 = 0;
    *(void *)(a2 + 8) = 0;
    *(void *)(a2 + 16) = 0;
    v16[2] = v14 + 24;
    std::vector<std::vector<std::string>>::__swap_out_circular_buffer(a1, v16);
    unint64_t v8 = (void *)a1[1];
    uint64_t result = std::__split_buffer<std::vector<std::string>>::~__split_buffer(v16);
  }
  else
  {
    void *v7 = 0;
    v7[1] = 0;
    v7[2] = 0;
    *(_OWORD *)unsigned int v7 = *(_OWORD *)a2;
    v7[2] = *(void *)(a2 + 16);
    *(void *)a2 = 0;
    *(void *)(a2 + 8) = 0;
    *(void *)(a2 + 16) = 0;
    unint64_t v8 = v7 + 3;
    a1[1] = (uint64_t)(v7 + 3);
  }
  a1[1] = (uint64_t)v8;
  return result;
}

void sub_21138B914(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::__split_buffer<std::vector<std::string>>::~__split_buffer((void **)va);
  _Unwind_Resume(a1);
}

void ZinIrPerf::GetKernelSymbolNamesForActiveNE(ZinEngineLayerMirInfo **a1@<X1>, uint64_t a2@<X2>, uint64_t a3@<X8>)
{
  if (ZinIrOpLayer::IsPELayer((ZinIrOpLayer *)a1) || (unsigned int v7 = (char *)(a1 + 17), !a1[17]))
  {
    *(void *)a3 = 0;
    *(void *)(a3 + 8) = 0;
    *(void *)(a3 + 16) = 0;
  }
  else
  {
    *(void *)a3 = 0;
    *(void *)(a3 + 8) = 0;
    *(void *)(a3 + 16) = 0;
    ChannelAssignment = (MirInfoChannelAssignment *)ZinEngineLayerMirInfo::GetChannelAssignment(a1[33]);
    std::vector<std::string>::size_type NumNeededNEs = MirInfoChannelAssignment::GetNumNeededNEs(ChannelAssignment);
    std::vector<std::string>::reserve((std::vector<std::string> *)a3, NumNeededNEs);
    if (a2)
    {
      for (unint64_t i = 0; a2 != i; ++i)
      {
        if (!*(void *)v7) {
          continue;
        }
        if (!*(void *)(*(void *)v7 + 800)) {
          continue;
        }
        unint64_t v11 = (MirInfoChannelAssignment *)ZinEngineLayerMirInfo::GetChannelAssignment(a1[33]);
        if (i >= MirInfoChannelAssignment::GetNumNeededNEs(v11)) {
          continue;
        }
        if ((*((unsigned int (**)(ZinEngineLayerMirInfo **))*a1 + 15))(a1))
        {
          GetTensorKernelSymbolName((uint64_t)(a1 + 17), i, &__p);
          unint64_t v13 = *(void *)(a3 + 8);
          unint64_t v12 = *(void *)(a3 + 16);
          if (v13 >= v12)
          {
            unint64_t v14 = 0xAAAAAAAAAAAAAAABLL * ((uint64_t)(v13 - *(void *)a3) >> 3);
            unint64_t v15 = v14 + 1;
            if (v14 + 1 > 0xAAAAAAAAAAAAAAALL) {
              std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
            }
            unint64_t v16 = 0xAAAAAAAAAAAAAAABLL * ((uint64_t)(v12 - *(void *)a3) >> 3);
            if (2 * v16 > v15) {
              unint64_t v15 = 2 * v16;
            }
            if (v16 >= 0x555555555555555) {
              unint64_t v17 = 0xAAAAAAAAAAAAAAALL;
            }
            else {
              unint64_t v17 = v15;
            }
            v35.__end_cap_.__value_ = (std::allocator<std::string> *)(a3 + 16);
            if (v17) {
              goto LABEL_44;
            }
            int v25 = 0;
            goto LABEL_47;
          }
        }
        else
        {
          uint64_t v18 = a1[17];
          if (*(unsigned char *)(*((void *)v18 + 100) + 1))
          {
            if (*((unsigned char *)a1[2] + 308))
            {
              if (*((char *)v18 + 23) < 0)
              {
                std::string::__init_copy_ctor_external(&__p, *(const std::string::value_type **)v18, *((void *)v18 + 1));
              }
              else
              {
                long long v19 = *(_OWORD *)v18;
                __p.__r_.__value_.__r.__words[2] = *((void *)v18 + 2);
                *(_OWORD *)&__p.__r_.__value_.__l.__data_ = v19;
              }
            }
            else
            {
              ZinIrKernel::GetFinalHash(v18, (std::string *)&v35);
              int v23 = std::string::insert((std::string *)&v35, 0, "K", 1uLL);
              long long v24 = *(_OWORD *)&v23->__r_.__value_.__l.__data_;
              __p.__r_.__value_.__r.__words[2] = v23->__r_.__value_.__r.__words[2];
              *(_OWORD *)&__p.__r_.__value_.__l.__data_ = v24;
              v23->__r_.__value_.__l.__size_ = 0;
              v23->__r_.__value_.__r.__words[2] = 0;
              v23->__r_.__value_.__r.__words[0] = 0;
              if (SHIBYTE(v35.__end_) < 0) {
                operator delete(v35.__first_);
              }
            }
            unint64_t v13 = *(void *)(a3 + 8);
            unint64_t v26 = *(void *)(a3 + 16);
            if (v13 >= v26)
            {
              unint64_t v14 = 0xAAAAAAAAAAAAAAABLL * ((uint64_t)(v13 - *(void *)a3) >> 3);
              unint64_t v28 = v14 + 1;
              if (v14 + 1 > 0xAAAAAAAAAAAAAAALL) {
                std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
              }
              unint64_t v29 = 0xAAAAAAAAAAAAAAABLL * ((uint64_t)(v26 - *(void *)a3) >> 3);
              if (2 * v29 > v28) {
                unint64_t v28 = 2 * v29;
              }
              if (v29 >= 0x555555555555555) {
                unint64_t v17 = 0xAAAAAAAAAAAAAAALL;
              }
              else {
                unint64_t v17 = v28;
              }
              v35.__end_cap_.__value_ = (std::allocator<std::string> *)(a3 + 16);
              if (v17) {
                goto LABEL_44;
              }
              int v25 = 0;
              goto LABEL_47;
            }
          }
          else
          {
            GetKernelSymbolName(v18, i, *((unsigned __int8 *)a1[2] + 308) != 0, &__p);
            unint64_t v13 = *(void *)(a3 + 8);
            unint64_t v20 = *(void *)(a3 + 16);
            if (v13 >= v20)
            {
              unint64_t v14 = 0xAAAAAAAAAAAAAAABLL * ((uint64_t)(v13 - *(void *)a3) >> 3);
              unint64_t v21 = v14 + 1;
              if (v14 + 1 > 0xAAAAAAAAAAAAAAALL) {
                std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
              }
              unint64_t v22 = 0xAAAAAAAAAAAAAAABLL * ((uint64_t)(v20 - *(void *)a3) >> 3);
              if (2 * v22 > v21) {
                unint64_t v21 = 2 * v22;
              }
              if (v22 >= 0x555555555555555) {
                unint64_t v17 = 0xAAAAAAAAAAAAAAALL;
              }
              else {
                unint64_t v17 = v21;
              }
              v35.__end_cap_.__value_ = (std::allocator<std::string> *)(a3 + 16);
              if (v17) {
LABEL_44:
              }
                int v25 = (std::string *)std::__allocate_at_least[abi:ne180100]<std::allocator<std::string>>(a3 + 16, v17);
              else {
                int v25 = 0;
              }
LABEL_47:
              uint64_t v30 = v25 + v14;
              v35.__first_ = v25;
              v35.__begin_ = v30;
              v35.__end_cap_.__value_ = &v25[v17];
              long long v31 = *(_OWORD *)&__p.__r_.__value_.__l.__data_;
              v30->__r_.__value_.__r.__words[2] = __p.__r_.__value_.__r.__words[2];
              *(_OWORD *)&v30->__r_.__value_.__l.__data_ = v31;
              memset(&__p, 0, sizeof(__p));
              v35.__end_ = v30 + 1;
              std::vector<std::string>::__swap_out_circular_buffer((std::vector<std::string> *)a3, &v35);
              uint64_t v32 = *(void *)(a3 + 8);
              std::__split_buffer<std::string>::~__split_buffer(&v35);
              int v33 = SHIBYTE(__p.__r_.__value_.__r.__words[2]);
              *(void *)(a3 + 8) = v32;
              if (v33 < 0) {
                operator delete(__p.__r_.__value_.__l.__data_);
              }
              continue;
            }
          }
        }
        long long v27 = *(_OWORD *)&__p.__r_.__value_.__l.__data_;
        *(void *)(v13 + 16) = *((void *)&__p.__r_.__value_.__l + 2);
        *(_OWORD *)unint64_t v13 = v27;
        *(void *)(a3 + 8) = v13 + 24;
      }
    }
  }
}

void sub_21138BD4C(_Unwind_Exception *__p, uint64_t a2, int a3, __int16 a4, char a5, char a6, std::__split_buffer<std::string> *a7, uint64_t a8, void *__pa, uint64_t a10, int a11, __int16 a12, char a13, char a14)
{
  if (a14 < 0) {
    operator delete(__pa);
  }
  std::vector<std::string>::__destroy_vector::operator()[abi:ne180100]((void ***)&__pa);
  _Unwind_Resume(__p);
}

uint64_t ZinIrPerf::DebugPrint@<X0>(ZinIrPerf *this@<X0>, void *a2@<X8>)
{
  std::basic_stringstream<char,std::char_traits<char>,std::allocator<char>>::basic_stringstream[abi:ne180100]((uint64_t)v62);
  std::string::basic_string[abi:ne180100]<0>(&v59, &byte_211F4AA5D);
  std::string::basic_string[abi:ne180100]<0>(&__p, "\n");
  if (v61 < 0)
  {
    uint64_t v60 = 2;
    uint64_t v4 = (char *)v59;
  }
  else
  {
    char v61 = 2;
    uint64_t v4 = (char *)&v59;
  }
  strcpy(v4, ", ");
  uint64_t v5 = *((void *)this + 29);
  if (v5 != *((void *)this + 30))
  {
    uint64_t v6 = 0;
    do
    {
      std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v63, (uint64_t)"L2Src", 5);
      unsigned int v7 = (void *)std::ostream::operator<<();
      std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v7, (uint64_t)" Dims: ", 7);
      ZinIrHalH13g::~ZinIrHalH13g((ZinIrHalH13g *)v62);
      uint64_t v8 = v5;
      if (v5 != *((void *)this + 30))
      {
        if (v61 >= 0) {
          unint64_t v9 = &v59;
        }
        else {
          unint64_t v9 = v59;
        }
        if (v61 >= 0) {
          uint64_t v10 = v61;
        }
        else {
          uint64_t v10 = v60;
        }
        std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v63, (uint64_t)v9, v10);
        uint64_t v8 = *((void *)this + 30);
      }
      ++v6;
      v5 += 40;
    }
    while (v5 != v8);
  }
  if ((v58 & 0x80u) == 0) {
    p_p = &__p;
  }
  else {
    p_p = __p;
  }
  if ((v58 & 0x80u) == 0) {
    uint64_t v12 = v58;
  }
  else {
    uint64_t v12 = v57;
  }
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v63, (uint64_t)p_p, v12);
  uint64_t v13 = *((void *)this + 35);
  if (v13 != *((void *)this + 36))
  {
    uint64_t v14 = 0;
    do
    {
      std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v63, (uint64_t)"DMASrc", 6);
      unint64_t v15 = (void *)std::ostream::operator<<();
      std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v15, (uint64_t)" Dims: ", 7);
      ZinIrHalH13g::~ZinIrHalH13g((ZinIrHalH13g *)v62);
      uint64_t v16 = v13;
      if (v13 != *((void *)this + 36))
      {
        if (v61 >= 0) {
          unint64_t v17 = &v59;
        }
        else {
          unint64_t v17 = v59;
        }
        if (v61 >= 0) {
          uint64_t v18 = v61;
        }
        else {
          uint64_t v18 = v60;
        }
        std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v63, (uint64_t)v17, v18);
        uint64_t v16 = *((void *)this + 36);
      }
      ++v14;
      v13 += 40;
    }
    while (v13 != v16);
  }
  if ((v58 & 0x80u) == 0) {
    long long v19 = &__p;
  }
  else {
    long long v19 = __p;
  }
  if ((v58 & 0x80u) == 0) {
    uint64_t v20 = v58;
  }
  else {
    uint64_t v20 = v57;
  }
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v63, (uint64_t)v19, v20);
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v63, (uint64_t)"OutputDims: ", 12);
  ZinIrHalH13g::~ZinIrHalH13g((ZinIrHalH13g *)v62);
  if ((v58 & 0x80u) == 0) {
    unint64_t v21 = &__p;
  }
  else {
    unint64_t v21 = __p;
  }
  if ((v58 & 0x80u) == 0) {
    uint64_t v22 = v58;
  }
  else {
    uint64_t v22 = v57;
  }
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v63, (uint64_t)v21, v22);
  if (v61 < 0)
  {
    uint64_t v60 = 16;
    int v23 = (char *)v59;
  }
  else
  {
    char v61 = 16;
    int v23 = (char *)&v59;
  }
  strcpy(v23, "InputResidency: ");
  uint64_t v25 = *((void *)this + 12);
  unint64_t v24 = *((void *)this + 13);
  int v26 = v24 & 0x3F;
  if (v24 > 0x3F || (v24 & 0x3F) != 0)
  {
    int v27 = 0;
    int v28 = 0;
    uint64_t v29 = v25 + 8 * (v24 >> 6);
    do
    {
      if (v61 >= 0) {
        uint64_t v30 = &v59;
      }
      else {
        uint64_t v30 = v59;
      }
      if (v61 >= 0) {
        uint64_t v31 = v61;
      }
      else {
        uint64_t v31 = v60;
      }
      uint64_t v32 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v63, (uint64_t)v30, v31);
      *(_DWORD *)((char *)v32 + *(void *)(*v32 - 24) + 8) |= 1u;
      std::ostream::operator<<();
      if (v61 < 0)
      {
        uint64_t v60 = 2;
        int v33 = (char *)v59;
      }
      else
      {
        char v61 = 2;
        int v33 = (char *)&v59;
      }
      strcpy(v33, ", ");
      v25 += 8 * (v27 == 63);
      if (v27 == 63) {
        int v28 = 0;
      }
      else {
        ++v28;
      }
      int v27 = v28;
    }
    while (v25 != v29 || v26 != v28);
  }
  if ((v58 & 0x80u) == 0) {
    uint64_t v34 = &__p;
  }
  else {
    uint64_t v34 = __p;
  }
  if ((v58 & 0x80u) == 0) {
    uint64_t v35 = v58;
  }
  else {
    uint64_t v35 = v57;
  }
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v63, (uint64_t)v34, v35);
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v63, (uint64_t)"OutputResidency: ", 17);
  *(_DWORD *)((char *)v64 + *(void *)(v63 - 24)) |= 1u;
  std::ostream::operator<<();
  if ((v58 & 0x80u) == 0) {
    uint64_t v36 = &__p;
  }
  else {
    uint64_t v36 = __p;
  }
  if ((v58 & 0x80u) == 0) {
    uint64_t v37 = v58;
  }
  else {
    uint64_t v37 = v57;
  }
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v63, (uint64_t)v36, v37);
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v63, (uint64_t)"active_ne: ", 11);
  std::ostream::operator<<();
  if ((v58 & 0x80u) == 0) {
    uint64_t v38 = &__p;
  }
  else {
    uint64_t v38 = __p;
  }
  if ((v58 & 0x80u) == 0) {
    uint64_t v39 = v58;
  }
  else {
    uint64_t v39 = v57;
  }
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v63, (uint64_t)v38, v39);
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v63, (uint64_t)"sh_min/sh_pref/sh_max: ", 23);
  long long v40 = (void *)std::ostream::operator<<();
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v40, (uint64_t)", ", 2);
  int v41 = (void *)std::ostream::operator<<();
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v41, (uint64_t)", ", 2);
  int64x2_t v42 = (void *)std::ostream::operator<<();
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v42, (uint64_t)", ", 2);
  if ((v58 & 0x80u) == 0) {
    int v43 = &__p;
  }
  else {
    int v43 = __p;
  }
  if ((v58 & 0x80u) == 0) {
    uint64_t v44 = v58;
  }
  else {
    uint64_t v44 = v57;
  }
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v63, (uint64_t)v43, v44);
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v63, (uint64_t)"ocg_size: ", 10);
  unsigned int v45 = (void *)std::ostream::operator<<();
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v45, (uint64_t)", ", 2);
  if ((v58 & 0x80u) == 0) {
    uint64_t v46 = &__p;
  }
  else {
    uint64_t v46 = __p;
  }
  if ((v58 & 0x80u) == 0) {
    uint64_t v47 = v58;
  }
  else {
    uint64_t v47 = v57;
  }
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v63, (uint64_t)v46, v47);
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v63, (uint64_t)"tile_height: ", 13);
  uint64_t v48 = (void *)std::ostream::operator<<();
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v48, (uint64_t)", ", 2);
  if ((v58 & 0x80u) == 0) {
    uint64_t v49 = &__p;
  }
  else {
    uint64_t v49 = __p;
  }
  if ((v58 & 0x80u) == 0) {
    uint64_t v50 = v58;
  }
  else {
    uint64_t v50 = v57;
  }
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v63, (uint64_t)v49, v50);
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v63, (uint64_t)"num_workunits: ", 15);
  long long v51 = (void *)std::ostream::operator<<();
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v51, (uint64_t)", ", 2);
  if ((v58 & 0x80u) == 0) {
    uint64_t v52 = &__p;
  }
  else {
    uint64_t v52 = __p;
  }
  if ((v58 & 0x80u) == 0) {
    uint64_t v53 = v58;
  }
  else {
    uint64_t v53 = v57;
  }
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v63, (uint64_t)v52, v53);
  std::stringbuf::str[abi:ne180100]<std::allocator<char>>((uint64_t)v64, a2);
  if ((char)v58 < 0) {
    operator delete(__p);
  }
  if (v61 < 0) {
    operator delete(v59);
  }
  v62[0] = *MEMORY[0x263F8C2B8];
  uint64_t v54 = *(void *)(MEMORY[0x263F8C2B8] + 72);
  *(void *)((char *)v62 + *(void *)(v62[0] - 24)) = *(void *)(MEMORY[0x263F8C2B8] + 64);
  uint64_t v63 = v54;
  v64[0] = MEMORY[0x263F8C318] + 16;
  if (v65 < 0) {
    operator delete((void *)v64[8]);
  }
  std::streambuf::~streambuf();
  std::iostream::~basic_iostream();
  return MEMORY[0x21667D2B0](&v66);
}

void sub_21138C4DC(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11, int a12, __int16 a13, char a14, char a15, void *a16, uint64_t a17, int a18, __int16 a19, char a20,char a21,char a22)
{
  if (a15 < 0) {
    operator delete(__p);
  }
  if (a21 < 0) {
    operator delete(a16);
  }
  std::basic_stringstream<char,std::char_traits<char>,std::allocator<char>>::~basic_stringstream((uint64_t)&a22);
  _Unwind_Resume(a1);
}

uint64_t ZinNEPerfInfo::GetNumWorkunits(ZinNEPerfInfo *this)
{
  return *((void *)this + 6);
}

uint64_t ZinCustomPerfInfo::SetCustomPerfInfo(ZinCustomPerfInfo *this, const ZinEngineLayerMirInfo *a2)
{
  if (!a2) {
    return 3;
  }
  *((void *)this + 43) = *((void *)a2 + 25);
  *((unsigned char *)this + 352) = 1;
  uint64_t v2 = *((void *)a2 + 27);
  if (!*((unsigned char *)this + 424)) {
    *((unsigned char *)this + 424) = 1;
  }
  *((void *)this + 52) = v2;
  uint64_t v3 = *((void *)a2 + 26);
  if (!*((unsigned char *)this + 440)) {
    *((unsigned char *)this + 44std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 1;
  }
  *((void *)this + 54) = v3;
  uint64_t v4 = *((void *)a2 + 28);
  if (!*((unsigned char *)this + 456)) {
    *((unsigned char *)this + 456) = 1;
  }
  uint64_t v5 = 0;
  *((void *)this + 56) = v4;
  return v5;
}

uint64_t ZinNECustomPerfInfo::SetCustomPerfInfo(ZinNECustomPerfInfo *this, const ZinEngineLayerMirInfo *a2)
{
  uint64_t v4 = ZinCustomPerfInfo::SetCustomPerfInfo(this, a2);
  if (!v4)
  {
    ChannelAssignment = (ZinIrTarget *)ZinEngineLayerMirInfo::GetChannelAssignment(a2);
    *((void *)this + 88) = ZinIrTarget::GetLut(ChannelAssignment);
    *((unsigned char *)this + 712) = 1;
    uint64_t v6 = (MirInfoChannelAssignment *)ZinEngineLayerMirInfo::GetChannelAssignment(a2);
    *((_WORD *)this + 36std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = MirInfoChannelAssignment::GetFatTileEnable(v6) | 0x100;
    unsigned int v7 = (MirInfoChannelAssignment *)ZinEngineLayerMirInfo::GetChannelAssignment(a2);
    *((void *)this + 72) = MirInfoChannelAssignment::GetActiveNEPerCluster(v7);
    *((unsigned char *)this + 584) = 1;
    *((_DWORD *)this + 141) = *((_DWORD *)a2 + 36);
    *((unsigned char *)this + 568) = 1;
    char v8 = *((unsigned char *)a2 + 149);
    if (!*((unsigned char *)this + 573)) {
      *((unsigned char *)this + 573) = 1;
    }
    *((unsigned char *)this + 572) = v8;
    *((_WORD *)this + 296) = *(unsigned __int8 *)a2 | 0x100;
    *((void *)this + 75) = *((void *)a2 + 12);
    *((unsigned char *)this + 608) = 1;
    unint64_t v9 = (MirInfoChannelAssignment *)ZinEngineLayerMirInfo::GetChannelAssignment(a2);
    *((void *)this + 77) = MirInfoChannelAssignment::GetOCGSize(v9);
    *((unsigned char *)this + 624) = 1;
    *((void *)this + 79) = *((void *)a2 + 17);
    *((unsigned char *)this + 64std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 1;
    *((void *)this + 83) = *((void *)a2 + 15);
    *((unsigned char *)this + 672) = 1;
    *((void *)this + 81) = *((void *)a2 + 16);
    *((unsigned char *)this + 656) = 1;
    *((_WORD *)this + 348) = *((unsigned __int8 *)a2 + 1) | 0x100;
    *((_WORD *)this + 361) = *((unsigned __int8 *)a2 + 148) | 0x100;
  }
  return v4;
}

uint64_t ZinPECustomPerfInfo::SetCustomPerfInfo(ZinPECustomPerfInfo *this, const ZinEngineLayerMirInfo *a2)
{
  uint64_t result = ZinCustomPerfInfo::SetCustomPerfInfo(this, a2);
  if (!result)
  {
    *((void *)this + 68) = *((void *)a2 + 31);
    *((unsigned char *)this + 552) = 1;
    *((void *)this + 66) = *((void *)a2 + 30);
    *((unsigned char *)this + 536) = 1;
  }
  return result;
}

void ZinPECustomPerfInfo::~ZinPECustomPerfInfo(ZinPECustomPerfInfo *this)
{
}

void ZinEnginePerf::ZinEnginePerf(ZinEnginePerf *this, const ZinIrPerf *a2)
{
  *(void *)this = &unk_26C3453B8;
  ZinPerfDescriptor::ZinPerfDescriptor((ZinEnginePerf *)((char *)this + 8));
  *((void *)this + 42) = a2;
  ZinDMAPerf::ZinDMAPerf((ZinEnginePerf *)((char *)this + 344), a2);
}

void sub_21138C7CC(_Unwind_Exception *exception_object)
{
  uint64_t v3 = *(void **)(v1 + 208);
  if (v3)
  {
    *(void *)(v1 + 216) = v3;
    operator delete(v3);
  }
  _Unwind_Resume(exception_object);
}

void ZinPerfDescriptor::ZinPerfDescriptor(ZinPerfDescriptor *this)
{
  *((_OWORD *)this + 12) = 0u;
  *((_OWORD *)this + 13) = 0u;
  *((_OWORD *)this + 1std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0u;
  *((_OWORD *)this + 11) = 0u;
  *((_OWORD *)this + 8) = 0u;
  *((_OWORD *)this + 9) = 0u;
  *((_OWORD *)this + 6) = 0u;
  *((_OWORD *)this + 7) = 0u;
  *((_OWORD *)this + 4) = 0u;
  *((_OWORD *)this + 5) = 0u;
  *((_OWORD *)this + 2) = 0u;
  *((_OWORD *)this + 3) = 0u;
  *(_OWORD *)this = 0u;
  *((_OWORD *)this + 1) = 0u;
  uint64_t v2 = operator new(8uLL);
  *((void *)this + 25) = v2;
  *v2++ = 0;
  *((void *)this + 26) = v2;
  *((void *)this + 27) = v2;
  *((void *)this + 28) = 0;
  *((void *)this + 29) = 0;
  __asm { FMOV            V0.2D, #-1.0 }
  *((_OWORD *)this + 15) = _Q0;
  *((_OWORD *)this + 16) = _Q0;
  *((_OWORD *)this + 17) = _Q0;
  *((_OWORD *)this + 18) = _Q0;
  *((void *)this + 38) = 0;
  *((unsigned char *)this + 312) = 0;
  *((void *)this + 4std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
}

unint64_t *std::__copy_aligned[abi:ne180100]<std::vector<BOOL>,true>@<X0>(unint64_t *__src@<X0>, unsigned int a2@<W1>, uint64_t a3@<X2>, unsigned int a4@<W3>, uint64_t a5@<X4>, uint64_t a6@<X8>)
{
  int64_t v8 = a4 - (unint64_t)a2 + 8 * (a3 - (void)__src);
  if (v8 <= 0)
  {
    uint64_t v16 = *(unint64_t **)a5;
  }
  else
  {
    unint64_t v9 = __src;
    __src = *(unint64_t **)a5;
    if (a2)
    {
      if (v8 >= (unint64_t)(64 - a2)) {
        int64_t v10 = 64 - a2;
      }
      else {
        int64_t v10 = v8;
      }
      v8 -= v10;
      uint64_t v11 = *v9++;
      *__src = *__src & ~((0xFFFFFFFFFFFFFFFFLL >> (64 - a2 - v10)) & (-1 << a2)) | v11 & (0xFFFFFFFFFFFFFFFFLL >> (64 - a2 - v10)) & (-1 << a2);
      unint64_t v12 = v10 + *(unsigned int *)(a5 + 8);
      __src = (unint64_t *)((char *)__src + ((v12 >> 3) & 0x3FFFFFF8));
      *(void *)a5 = __src;
      *(_DWORD *)(a5 + 8) = v12 & 0x3F;
    }
    if (v8 >= 0) {
      uint64_t v13 = v8;
    }
    else {
      uint64_t v13 = v8 + 63;
    }
    uint64_t v14 = v13 >> 6;
    if ((unint64_t)(v8 + 63) >= 0x7F)
    {
      memmove(__src, v9, 8 * v14);
      __src = *(unint64_t **)a5;
    }
    uint64_t v15 = v8 - (v14 << 6);
    uint64_t v16 = &__src[v14];
    *(void *)a5 = v16;
    if (v15 >= 1)
    {
      unint64_t *v16 = *v16 & ~(0xFFFFFFFFFFFFFFFFLL >> (((_BYTE)v14 << 6) - v8)) | v9[v14] & (0xFFFFFFFFFFFFFFFFLL >> (((_BYTE)v14 << 6) - v8));
      *(_DWORD *)(a5 + 8) = v15;
    }
  }
  *(void *)a6 = v16;
  *(_DWORD *)(a6 + 8) = *(_DWORD *)(a5 + 8);
  return __src;
}

void std::vector<ZinTensorDimensions>::__append(void **a1, unint64_t a2)
{
  uint64_t v6 = a1[2];
  uint64_t v4 = (uint64_t)(a1 + 2);
  uint64_t v5 = v6;
  unsigned int v7 = *(unsigned char **)(v4 - 8);
  if (0xCCCCCCCCCCCCCCCDLL * ((v6 - v7) >> 3) >= a2)
  {
    std::vector<ZinTensorDimensions>::__construct_at_end((uint64_t)a1, a2);
  }
  else
  {
    int64_t v8 = *a1;
    unint64_t v9 = 0xCCCCCCCCCCCCCCCDLL * ((v7 - (unsigned char *)*a1) >> 3);
    unint64_t v10 = v9 + a2;
    if (v9 + a2 > 0x666666666666666) {
      std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
    }
    unint64_t v11 = 0xCCCCCCCCCCCCCCCDLL * ((v5 - v8) >> 3);
    if (2 * v11 > v10) {
      unint64_t v10 = 2 * v11;
    }
    if (v11 >= 0x333333333333333) {
      unint64_t v12 = 0x666666666666666;
    }
    else {
      unint64_t v12 = v10;
    }
    if (v12)
    {
      uint64_t v13 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ZinMirInterchangeInfo>>(v4, v12);
      int64_t v8 = *a1;
      unsigned int v7 = a1[1];
    }
    else
    {
      uint64_t v13 = 0;
    }
    uint64_t v14 = &v13[40 * v9];
    uint64_t v15 = &v13[40 * v12];
    size_t v16 = 40 * ((40 * a2 - 40) / 0x28) + 40;
    memset_pattern16(v14, &unk_211ED5510, v16);
    unint64_t v17 = &v14[v16];
    if (v7 != v8)
    {
      do
      {
        long long v18 = *(_OWORD *)(v7 - 40);
        long long v19 = *(_OWORD *)(v7 - 24);
        *((void *)v14 - 1) = *((void *)v7 - 1);
        *(_OWORD *)(v14 - 24) = v19;
        *(_OWORD *)(v14 - 4std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v18;
        v14 -= 40;
        v7 -= 40;
      }
      while (v7 != v8);
      int64_t v8 = *a1;
    }
    *a1 = v14;
    a1[1] = v17;
    a1[2] = v15;
    if (v8)
    {
      operator delete(v8);
    }
  }
}

void ContributingEngineLayer(const ZinIrTensor *a1@<X0>, void **a2@<X8>)
{
  *a2 = 0;
  a2[1] = 0;
  a2[2] = 0;
  uint64_t v3 = (ZinIrOpLayer *)*((void *)a1 + 12);
  if (ZinIrOpLayer::IsANELayer(v3))
  {
    uint64_t v4 = std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)(a2 + 2), 1uLL);
    uint64_t v6 = &v4[v5];
    *uint64_t v4 = v3;
    unsigned int v7 = v4 + 1;
    unint64_t v9 = (char *)*a2;
    int64_t v8 = (char *)a2[1];
    if (v8 != *a2)
    {
      do
      {
        uint64_t v10 = *((void *)v8 - 1);
        v8 -= 8;
        *--uint64_t v4 = v10;
      }
      while (v8 != v9);
      int64_t v8 = (char *)*a2;
    }
    *a2 = v4;
    a2[1] = v7;
    a2[2] = v6;
    if (v8) {
      operator delete(v8);
    }
    a2[1] = v7;
  }
  else
  {
    unint64_t v11 = (ZinIrOpLayer **)*((void *)v3 + 11);
    for (unint64_t i = (ZinIrOpLayer **)*((void *)v3 + 12); v11 != i; ++v11)
    {
      uint64_t v13 = *v11;
      if (ZinIrOpLayer::IsANELayer(*v11))
      {
        uint64_t v15 = (ZinIrOpLayer **)a2[1];
        unint64_t v14 = (unint64_t)a2[2];
        if ((unint64_t)v15 >= v14)
        {
          uint64_t v18 = ((char *)v15 - (unsigned char *)*a2) >> 3;
          if ((unint64_t)(v18 + 1) >> 61) {
            std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
          }
          uint64_t v19 = v14 - (void)*a2;
          uint64_t v20 = v19 >> 2;
          if (v19 >> 2 <= (unint64_t)(v18 + 1)) {
            uint64_t v20 = v18 + 1;
          }
          if ((unint64_t)v19 >= 0x7FFFFFFFFFFFFFF8) {
            unint64_t v21 = 0x1FFFFFFFFFFFFFFFLL;
          }
          else {
            unint64_t v21 = v20;
          }
          if (v21) {
            uint64_t v22 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)(a2 + 2), v21);
          }
          else {
            uint64_t v22 = 0;
          }
          int v23 = (ZinIrOpLayer **)&v22[8 * v18];
          *int v23 = v13;
          size_t v16 = v23 + 1;
          uint64_t v25 = (char *)*a2;
          unint64_t v24 = (char *)a2[1];
          if (v24 != *a2)
          {
            do
            {
              int v26 = (ZinIrOpLayer *)*((void *)v24 - 1);
              v24 -= 8;
              *--int v23 = v26;
            }
            while (v24 != v25);
            unint64_t v24 = (char *)*a2;
          }
          *a2 = v23;
          a2[1] = v16;
          a2[2] = &v22[8 * v21];
          if (v24) {
            operator delete(v24);
          }
        }
        else
        {
          char *v15 = v13;
          size_t v16 = v15 + 1;
        }
        a2[1] = v16;
      }
      else
      {
        unint64_t v17 = (const ZinIrTensor *)(*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)v13 + 32))(v13, 0, 0);
        ContributingEngineLayer((uint64_t *)&__p, v17);
        std::vector<ZinGOCLayer const*>::__insert_with_size[abi:ne180100]<std::__wrap_iter<ZinGOCLayer const**>,std::__wrap_iter<ZinGOCLayer const**>>((uint64_t)a2, (uint64_t)a2[1], (char *)__p, v28, (v28 - (unsigned char *)__p) >> 3);
        if (__p)
        {
          int v28 = (char *)__p;
          operator delete(__p);
        }
      }
    }
  }
}

void sub_21138CD2C(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11)
{
  uint64_t v13 = *(void **)v11;
  if (*(void *)v11)
  {
    *(void *)(v11 + 8) = v13;
    operator delete(v13);
  }
  _Unwind_Resume(exception_object);
}

uint64_t std::vector<std::vector<std::string>>::__swap_out_circular_buffer(uint64_t *a1, void *a2)
{
  uint64_t result = std::__uninitialized_allocator_move_if_noexcept[abi:ne180100]<std::allocator<std::vector<std::string>>,std::reverse_iterator<std::vector<std::string>*>,std::reverse_iterator<std::vector<std::string>*>,std::reverse_iterator<std::vector<std::string>*>>((uint64_t)(a1 + 2), a1[1], (void *)a1[1], *a1, (void *)*a1, a2[1], a2[1]);
  a2[1] = v5;
  uint64_t v6 = *a1;
  *a1 = v5;
  a2[1] = v6;
  uint64_t v7 = a1[1];
  a1[1] = a2[2];
  a2[2] = v7;
  uint64_t v8 = a1[2];
  a1[2] = a2[3];
  a2[3] = v8;
  *a2 = a2[1];
  return result;
}

uint64_t std::__uninitialized_allocator_move_if_noexcept[abi:ne180100]<std::allocator<std::vector<std::string>>,std::reverse_iterator<std::vector<std::string>*>,std::reverse_iterator<std::vector<std::string>*>,std::reverse_iterator<std::vector<std::string>*>>(uint64_t a1, uint64_t a2, void *a3, uint64_t a4, void *a5, uint64_t a6, uint64_t a7)
{
  uint64_t v7 = a7;
  *(void *)&long long v14 = a6;
  *((void *)&v14 + 1) = a7;
  long long v13 = v14;
  v11[0] = a1;
  v11[1] = &v13;
  uint64_t v11[2] = &v14;
  if (a3 == a5)
  {
    uint64_t v9 = a6;
  }
  else
  {
    do
    {
      *(void *)(v7 - 24) = 0;
      *(void *)(v7 - 16) = 0;
      *(void *)(v7 - 8) = 0;
      long long v8 = *(_OWORD *)(a3 - 3);
      a3 -= 3;
      *(_OWORD *)(v7 - 24) = v8;
      *(void *)(v7 - 8) = a3[2];
      *a3 = 0;
      a3[1] = 0;
      a3[2] = 0;
      uint64_t v7 = *((void *)&v14 + 1) - 24;
      *((void *)&v14 + 1) -= 24;
    }
    while (a3 != a5);
    uint64_t v9 = v14;
  }
  char v12 = 1;
  std::__exception_guard_exceptions<std::_AllocatorDestroyRangeReverse<std::allocator<std::vector<std::string>>,std::reverse_iterator<std::vector<std::string>*>>>::~__exception_guard_exceptions[abi:ne180100]((uint64_t)v11);
  return v9;
}

uint64_t std::__exception_guard_exceptions<std::_AllocatorDestroyRangeReverse<std::allocator<std::vector<std::string>>,std::reverse_iterator<std::vector<std::string>*>>>::~__exception_guard_exceptions[abi:ne180100](uint64_t a1)
{
  if (!*(unsigned char *)(a1 + 24)) {
    std::_AllocatorDestroyRangeReverse<std::allocator<std::vector<std::string>>,std::reverse_iterator<std::vector<std::string>*>>::operator()[abi:ne180100](a1);
  }
  return a1;
}

void std::_AllocatorDestroyRangeReverse<std::allocator<std::vector<std::string>>,std::reverse_iterator<std::vector<std::string>*>>::operator()[abi:ne180100](uint64_t a1)
{
  uint64_t v1 = *(void ***)(*(void *)(a1 + 16) + 8);
  uint64_t v2 = *(void ***)(*(void *)(a1 + 8) + 8);
  while (v1 != v2)
  {
    uint64_t v3 = v1;
    std::vector<std::string>::__destroy_vector::operator()[abi:ne180100](&v3);
    v1 += 3;
  }
}

void **std::__split_buffer<std::vector<std::string>>::~__split_buffer(void **a1)
{
  if (*a1) {
    operator delete(*a1);
  }
  return a1;
}

void std::__split_buffer<std::vector<std::string>>::clear[abi:ne180100](uint64_t a1)
{
  uint64_t v2 = *(void *)(a1 + 8);
  for (uint64_t i = *(void *)(a1 + 16); i != v2; uint64_t i = *(void *)(a1 + 16))
  {
    uint64_t v4 = (void **)(i - 24);
    *(void *)(a1 + 16) = v4;
    uint64_t v5 = v4;
    std::vector<std::string>::__destroy_vector::operator()[abi:ne180100](&v5);
  }
}

void ZinIrPerf::IsValidPerfInfo(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "Invalid Hal Params\n", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "Empty L2 source dimension\n", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "Empty DMA source dimension\n", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "L2 src dimensions shouldn not be zero\n", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "Empty L2 source format\n", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "l2 src fmt is invalid\n", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "DMA src dimensions should not be zero\n", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "Empty DMA src format\n", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "Output tensor dimension must not have zero dimension\n", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "common_info_.stride.ox cannot be zero\n", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "common_info_.stride.oy cannot be zero\n", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "common_info_.stride.oz cannot be zero\n", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "common_info_.stride.sx cannot be zero\n", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "common_info_.stride.sy cannot be zero\n", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "common_info_.stride.sz cannot be zero\n", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "common_info_.tile_height cannot be zero\n", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "output fmt is invalid\n", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "common_info_.wdma_interleave cannot be zero\n", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "ne_info_.active_ne cannot be zero\n", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "ne_info_.ocg_size cannot be zero\n", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "Num groups and batch cannot be bigger than 1 at the same time.\n", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "Invalid NE perf info for multicast.", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "Invalid workunit stacking configuration.", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "The number of output channel groups must be 1 with multicast.", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "More than one tileSrc compression is not allowed.\n", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "Chained task must not be nullptr, if chain_analysis is enabled.\n", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "Interleave should not be less than 1", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "RDMA input dimension and input format should have the same size\n", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "common_info_.dma_src_dims and common_info_.input_is_resident should have same size\n", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "common_info_.l2_src_dims and common_info_.l2_src_fmt should have same size\n", a5, a6, a7, a8, 0);
}

void ZinIrPerf::CalculatePerfDescriptor(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void ZinIrPerf::ValidatePerfAnalysisMode(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "[ZinPerfModel] Chain/L2-dependent analysis require entire perf domain analysis.\n", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "[ZinPerfModel] L2 Dep analysis mode requires graph info", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "[ZinPerfModel] Chain analysis mode requires graph info", a5, a6, a7, a8, 0);
}

void ZinIrPerf::ValidateDefaultPerfInfo(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void ZinIrPerf::ValidatePerfInfo(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "[ZinPerfModel] Invalid Opcode for perf model", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "[ZinPerfModel] Requires an ZinANELayer", a5, a6, a7, a8, 0);
}

void ZinIrPerf::ConfigureInputTensorInfo(uint8_t *buf, unsigned char *a2)
{
  *uint8_t buf = 0;
  *a2 = 0;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "Error: Attempting to configure invalid L2 source info", buf, 2u);
}

void ZinIrPerf::ConfigurePerfInfo(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void ZinIrPerf::ValidateNEPerfInfo(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void ZinIrPerf::ConfigureMcacheInfo()
{
  *(_WORD *)uint64_t v0 = 0;
  _os_log_debug_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_DEBUG, "[Perf model] Mcache analysis will be skipped due to missing mir-info.\n", v0, 2u);
}

{
  uint8_t v0[16];

  *(_WORD *)uint64_t v0 = 0;
  _os_log_debug_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_DEBUG, "[Perf model] Mcache analysis will be skipped due to missing graph information.\n", v0, 2u);
}

uint64_t ZinGetRegisterProgramming<7u>::GetWin(uint64_t a1)
{
  return *(_DWORD *)(a1 + 460) & 0x7FFF;
}

uint64_t ZinGetRegisterProgramming<7u>::GetHin(uint64_t a1)
{
  return *(_WORD *)(a1 + 462) & 0x7FFF;
}

uint64_t ZinGetRegisterProgramming<7u>::GetDin(uint64_t a1)
{
  return *(_DWORD *)(a1 + 464) & 0x7FFF;
}

uint64_t ZinGetRegisterProgramming<7u>::GetCin(uint64_t a1)
{
  return *(_DWORD *)(a1 + 472) & 0x1FFFF;
}

uint64_t ZinGetRegisterProgramming<7u>::GetWout(uint64_t a1)
{
  return *(_DWORD *)(a1 + 480) & 0x7FFF;
}

uint64_t ZinGetRegisterProgramming<7u>::GetHout(uint64_t a1)
{
  return *(_WORD *)(a1 + 482) & 0x7FFF;
}

uint64_t ZinGetRegisterProgramming<7u>::GetDout(uint64_t a1)
{
  return *(_DWORD *)(a1 + 484) & 0x7FFF;
}

uint64_t ZinGetRegisterProgramming<7u>::GetCout(uint64_t a1)
{
  return *(_DWORD *)(a1 + 476) & 0x1FFFF;
}

uint64_t ZinGetRegisterProgramming<8u>::GetWin(uint64_t a1)
{
  return *(_DWORD *)(a1 + 492) & 0x7FFF;
}

uint64_t ZinGetRegisterProgramming<8u>::GetHin(uint64_t a1)
{
  return *(_WORD *)(a1 + 494) & 0x7FFF;
}

uint64_t ZinGetRegisterProgramming<8u>::GetDin(uint64_t a1)
{
  return *(_DWORD *)(a1 + 496) & 0x7FFF;
}

uint64_t ZinGetRegisterProgramming<8u>::GetCin(uint64_t a1)
{
  return *(_DWORD *)(a1 + 504) & 0x1FFFF;
}

uint64_t ZinGetRegisterProgramming<8u>::GetWout(uint64_t a1)
{
  return *(_DWORD *)(a1 + 512) & 0x7FFF;
}

uint64_t ZinGetRegisterProgramming<8u>::GetHout(uint64_t a1)
{
  return *(_WORD *)(a1 + 514) & 0x7FFF;
}

uint64_t ZinGetRegisterProgramming<8u>::GetDout(uint64_t a1)
{
  return *(_DWORD *)(a1 + 516) & 0x7FFF;
}

uint64_t ZinGetRegisterProgramming<8u>::GetCout(uint64_t a1)
{
  return *(_DWORD *)(a1 + 508) & 0x1FFFF;
}

uint64_t ZinGetRegisterProgramming<8u>::GetNumGroups(uint64_t a1)
{
  return *(_DWORD *)(a1 + 532) & 0x1FFF;
}

uint64_t ZinGetRegisterProgramming<8u>::GetCommonTaskType(uint64_t a1)
{
  uint64_t v1 = *(_DWORD *)(a1 + 548) >> 4;
  if (v1 >= 9 || ((0x17Fu >> v1) & 1) == 0) {
    ZinAssertImpl("Error: Invalid Task Type");
  }
  return qword_211F07DF0[v1];
}

BOOL ZinGetRegisterProgramming<8u>::IsTexModeEnabled(uint64_t a1)
{
  return (*(unsigned char *)(a1 + 776) & 7) != 0;
}

BOOL ZinGetRegisterProgramming<8u>::IsPEIndexingEnabled(uint64_t a1)
{
  return (*(unsigned char *)(a1 + 966) & 7) != 0;
}

uint64_t ZinGetRegisterProgramming<8u>::IsSource1Ephemeral(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 864) >> 1) & 1;
}

uint64_t ZinGetRegisterProgramming<8u>::IsSource2Ephemeral(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 868) >> 1) & 1;
}

uint64_t ZinGetRegisterProgramming<8u>::IsResultEphemeral(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 912) >> 1) & 1;
}

uint64_t ZinGetRegisterProgramming<8u>::GetCircularBufferSrc1(uint64_t a1)
{
  if ((*(_DWORD *)(a1 + 940) & 7u) >= 5) {
    ZinAssertImpl("Invalid circular buffer option");
  }
  return qword_211F07E60[*(_DWORD *)(a1 + 940) & 7] | qword_211F07E38[*(_DWORD *)(a1 + 940) & 7];
}

uint64_t ZinGetRegisterProgramming<8u>::GetCircularBufferSrc2(uint64_t a1)
{
  unint64_t v1 = ((unint64_t)*(unsigned int *)(a1 + 940) >> 4) & 7;
  if (v1 >= 5) {
    ZinAssertImpl("Invalid circular buffer option");
  }
  return qword_211F07E60[v1] | qword_211F07E38[v1];
}

uint64_t ZinGetRegisterProgramming<8u>::GetCircularBufferResult(uint64_t a1)
{
  unint64_t v1 = ((unint64_t)*(unsigned int *)(a1 + 940) >> 8) & 7;
  if (v1 >= 5) {
    ZinAssertImpl("Invalid circular buffer option");
  }
  return qword_211F07E60[v1] | qword_211F07E38[v1];
}

BOOL ZinGetRegisterProgramming<8u>::HasReduction(uint64_t a1)
{
  uint64_t CommonTaskType = ZinGetRegisterProgramming<8u>::GetCommonTaskType(a1);
  if ((CommonTaskType & 0xFF00000000) == 0) {
    std::__throw_bad_optional_access[abi:ne180100]();
  }
  return (CommonTaskType - 3) < 2;
}

uint64_t ZinGetRegisterProgramming<8u>::HasSrc1Transpose(uint64_t a1)
{
  return *(unsigned char *)(a1 + 545) & 1;
}

uint64_t ZinGetRegisterProgramming<8u>::GetSrc1Interleave(uint64_t a1)
{
  return *(unsigned char *)(a1 + 683) & 0xF;
}

uint64_t ZinGetRegisterProgramming<8u>::HasSrc1HBroadcast(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 544) >> 1) & 1;
}

uint64_t ZinGetRegisterProgramming<8u>::HasSrc1DBroadcast(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 544) >> 2) & 1;
}

uint64_t ZinGetRegisterProgramming<8u>::HasSrc1CBroadcast(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 544) >> 3) & 1;
}

uint64_t ZinGetRegisterProgramming<8u>::HasSrc1WBroadcast(uint64_t a1)
{
  return *(_DWORD *)(a1 + 544) & 1;
}

uint64_t ZinGetRegisterProgramming<8u>::IsTileDmaSrc1Compressed(uint64_t a1)
{
  return *(_DWORD *)(a1 + 696) & 1;
}

uint64_t ZinGetRegisterProgramming<8u>::HasSrc2Transpose(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 545) >> 1) & 1;
}

uint64_t ZinGetRegisterProgramming<8u>::GetSrc2Interleave(uint64_t a1)
{
  return *(unsigned char *)(a1 + 687) & 0xF;
}

uint64_t ZinGetRegisterProgramming<8u>::HasSrc2HBroadcast(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 544) >> 5) & 1;
}

uint64_t ZinGetRegisterProgramming<8u>::HasSrc2DBroadcast(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 544) >> 6) & 1;
}

uint64_t ZinGetRegisterProgramming<8u>::HasSrc2CBroadcast(uint64_t a1)
{
  return *(unsigned __int8 *)(a1 + 544) >> 7;
}

uint64_t ZinGetRegisterProgramming<8u>::HasSrc2WBroadcast(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 544) >> 4) & 1;
}

uint64_t ZinGetRegisterProgramming<8u>::IsTileDmaSrc2Compressed(uint64_t a1)
{
  return *(_DWORD *)(a1 + 712) & 1;
}

BOOL ZinGetRegisterProgramming<8u>::HasOutputTranspose(uint64_t a1)
{
  return (*(_DWORD *)(a1 + 544) & 0x400 | *(_DWORD *)(a1 + 548) & 0x10000000) != 0;
}

uint64_t ZinGetRegisterProgramming<8u>::GetOutputInterleave(uint64_t a1)
{
  return *(unsigned char *)(a1 + 1163) & 0xF;
}

uint64_t ZinGetRegisterProgramming<8u>::IsTileDmaDstCompressed(uint64_t a1)
{
  return *(_DWORD *)(a1 + 1168) & 1;
}

uint64_t ZinGetRegisterProgramming<8u>::GetTextureMode(uint64_t a1)
{
  if ((*(_DWORD *)(a1 + 776) & 7u) >= 5) {
    ZinAssertImpl("Invalid texture mode");
  }
  return dword_211F07E88[*(_DWORD *)(a1 + 776) & 7];
}

uint64_t ZinGetRegisterProgramming<8u>::GetTextureSourceDimensions@<X0>(uint64_t result@<X0>, void *a2@<X8>)
{
  unint64_t v2 = (unint64_t)*(unsigned int *)(result + 796) >> 16;
  uint64_t v3 = *(unsigned __int16 *)(result + 800);
  unint64_t v4 = (unint64_t)*(unsigned int *)(result + 792) >> 16;
  uint64_t v5 = (unsigned __int16)*(_DWORD *)(result + 796);
  *a2 = (unsigned __int16)*(_DWORD *)(result + 792);
  a2[1] = v3;
  a2[2] = v2;
  a2[3] = v5;
  a2[4] = v4;
  return result;
}

uint64_t ZinGetRegisterProgramming<8u>::GetGatherModeIndexGroupDimension(uint64_t a1)
{
  switch((*(_DWORD *)(a1 + 780) >> 12) & 7)
  {
    case 0:
      return *(_DWORD *)(a1 + 504) & 0x1FFFF;
    case 1:
      int v2 = *(_DWORD *)(a1 + 492);
      goto LABEL_7;
    case 2:
      LOWORD(v2) = *(_WORD *)(a1 + 494);
      goto LABEL_7;
    case 3:
      int v2 = *(_DWORD *)(a1 + 496);
LABEL_7:
      uint64_t result = v2 & 0x7FFF;
      break;
    case 4:
      uint64_t result = *(_DWORD *)(a1 + 532) & 0x1FFF;
      break;
    case 5:
      uint64_t result = 1;
      break;
    default:
      uint64_t result = 0;
      break;
  }
  return result;
}

uint64_t ZinGetRegisterProgramming<8u>::GetGatherModeIndexDepthDimension(uint64_t a1)
{
  switch((*(_DWORD *)(a1 + 780) >> 9) & 7)
  {
    case 0:
      return *(_DWORD *)(a1 + 504) & 0x1FFFF;
    case 1:
      int v2 = *(_DWORD *)(a1 + 492);
      goto LABEL_7;
    case 2:
      LOWORD(v2) = *(_WORD *)(a1 + 494);
      goto LABEL_7;
    case 3:
      int v2 = *(_DWORD *)(a1 + 496);
LABEL_7:
      uint64_t result = v2 & 0x7FFF;
      break;
    case 4:
      uint64_t result = *(_DWORD *)(a1 + 532) & 0x1FFF;
      break;
    case 5:
      uint64_t result = 1;
      break;
    default:
      uint64_t result = 0;
      break;
  }
  return result;
}

uint64_t ZinGetRegisterProgramming<8u>::GetGatherModeIndexPlaneDimension(uint64_t a1)
{
  switch((*(_DWORD *)(a1 + 780) >> 6) & 7)
  {
    case 0:
      return *(_DWORD *)(a1 + 504) & 0x1FFFF;
    case 1:
      int v2 = *(_DWORD *)(a1 + 492);
      goto LABEL_7;
    case 2:
      LOWORD(v2) = *(_WORD *)(a1 + 494);
      goto LABEL_7;
    case 3:
      int v2 = *(_DWORD *)(a1 + 496);
LABEL_7:
      uint64_t result = v2 & 0x7FFF;
      break;
    case 4:
      uint64_t result = *(_DWORD *)(a1 + 532) & 0x1FFF;
      break;
    case 5:
      uint64_t result = 1;
      break;
    default:
      uint64_t result = 0;
      break;
  }
  return result;
}

uint64_t ZinGetRegisterProgramming<8u>::GetGatherModeIndexHeightDimension(uint64_t a1)
{
  switch((*(_DWORD *)(a1 + 780) >> 3) & 7)
  {
    case 0:
      return *(_DWORD *)(a1 + 504) & 0x1FFFF;
    case 1:
      int v2 = *(_DWORD *)(a1 + 492);
      goto LABEL_7;
    case 2:
      LOWORD(v2) = *(_WORD *)(a1 + 494);
      goto LABEL_7;
    case 3:
      int v2 = *(_DWORD *)(a1 + 496);
LABEL_7:
      uint64_t result = v2 & 0x7FFF;
      break;
    case 4:
      uint64_t result = *(_DWORD *)(a1 + 532) & 0x1FFF;
      break;
    case 5:
      uint64_t result = 1;
      break;
    default:
      uint64_t result = 0;
      break;
  }
  return result;
}

uint64_t ZinGetRegisterProgramming<8u>::GetGatherModeIndexWidthDimension(uint64_t a1)
{
  switch(*(_DWORD *)(a1 + 780) & 7)
  {
    case 0:
      return *(_DWORD *)(a1 + 504) & 0x1FFFF;
    case 1:
      int v2 = *(_DWORD *)(a1 + 492);
      goto LABEL_7;
    case 2:
      LOWORD(v2) = *(_WORD *)(a1 + 494);
      goto LABEL_7;
    case 3:
      int v2 = *(_DWORD *)(a1 + 496);
LABEL_7:
      uint64_t result = v2 & 0x7FFF;
      break;
    case 4:
      uint64_t result = *(_DWORD *)(a1 + 532) & 0x1FFF;
      break;
    case 5:
      uint64_t result = 1;
      break;
    default:
      uint64_t result = 0;
      break;
  }
  return result;
}

uint64_t ZinGetRegisterProgramming<8u>::GetDmaSrc1FormatMode(uint64_t a1, _DWORD *a2)
{
  *a2 = *((_DWORD *)&xmmword_211F06300 + (*(_DWORD *)(a1 + 680) & 3));
  return 0;
}

uint64_t ZinGetRegisterProgramming<8u>::GetDmaSrc2FormatMode(uint64_t a1, _DWORD *a2)
{
  *a2 = *((_DWORD *)&xmmword_211F06300 + (*(_DWORD *)(a1 + 684) & 3));
  return 0;
}

uint64_t ZinGetRegisterProgramming<8u>::GetDmaDstFormatMode(uint64_t a1, _DWORD *a2)
{
  *a2 = *((_DWORD *)&xmmword_211F06300 + (*(_DWORD *)(a1 + 1160) & 3));
  return 0;
}

uint64_t ZinGetRegisterProgramming<10u>::GetWin(uint64_t a1)
{
  return *(_DWORD *)(a1 + 244) & 0x7FFF;
}

uint64_t ZinGetRegisterProgramming<10u>::GetHin(uint64_t a1)
{
  return *(_WORD *)(a1 + 246) & 0x7FFF;
}

uint64_t ZinGetRegisterProgramming<10u>::GetDin(uint64_t a1)
{
  return *(_DWORD *)(a1 + 248) & 0x7FFF;
}

uint64_t ZinGetRegisterProgramming<10u>::GetCin(uint64_t a1)
{
  return *(_DWORD *)(a1 + 256) & 0x1FFFF;
}

uint64_t ZinGetRegisterProgramming<10u>::GetWout(uint64_t a1)
{
  return *(_DWORD *)(a1 + 264) & 0x7FFF;
}

uint64_t ZinGetRegisterProgramming<10u>::GetHout(uint64_t a1)
{
  return *(_WORD *)(a1 + 266) & 0x7FFF;
}

uint64_t ZinGetRegisterProgramming<10u>::GetDout(uint64_t a1)
{
  return *(_DWORD *)(a1 + 268) & 0x7FFF;
}

uint64_t ZinGetRegisterProgramming<10u>::GetCout(uint64_t a1)
{
  return *(_DWORD *)(a1 + 260) & 0x1FFFF;
}

uint64_t ZinGetRegisterProgramming<10u>::GetNumGroups(uint64_t a1)
{
  return *(_DWORD *)(a1 + 284) & 0x1FFF;
}

uint64_t ZinGetRegisterProgramming<10u>::GetCommonTaskType(uint64_t a1)
{
  uint64_t v1 = *(_DWORD *)(a1 + 300) >> 4;
  if (v1 >= 9 || ((0x17Fu >> v1) & 1) == 0) {
    ZinAssertImpl("Error: Invalid Task Type");
  }
  return qword_211F07DF0[v1];
}

BOOL ZinGetRegisterProgramming<10u>::IsTexModeEnabled(uint64_t a1)
{
  return (*(unsigned char *)(a1 + 528) & 7) != 0;
}

BOOL ZinGetRegisterProgramming<10u>::IsPEIndexingEnabled(uint64_t a1)
{
  return (*(unsigned char *)(a1 + 718) & 7) != 0;
}

uint64_t ZinGetRegisterProgramming<10u>::IsSource1Ephemeral(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 616) >> 1) & 1;
}

uint64_t ZinGetRegisterProgramming<10u>::IsSource2Ephemeral(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 620) >> 1) & 1;
}

uint64_t ZinGetRegisterProgramming<10u>::IsResultEphemeral(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 664) >> 1) & 1;
}

uint64_t ZinGetRegisterProgramming<10u>::GetCircularBufferSrc1(uint64_t a1)
{
  if ((*(_DWORD *)(a1 + 692) & 7u) >= 5) {
    ZinAssertImpl("Invalid circular buffer option");
  }
  return qword_211F07E60[*(_DWORD *)(a1 + 692) & 7] | qword_211F07E38[*(_DWORD *)(a1 + 692) & 7];
}

uint64_t ZinGetRegisterProgramming<10u>::GetCircularBufferSrc2(uint64_t a1)
{
  unint64_t v1 = ((unint64_t)*(unsigned int *)(a1 + 692) >> 4) & 7;
  if (v1 >= 5) {
    ZinAssertImpl("Invalid circular buffer option");
  }
  return qword_211F07E60[v1] | qword_211F07E38[v1];
}

uint64_t ZinGetRegisterProgramming<10u>::GetCircularBufferResult(uint64_t a1)
{
  unint64_t v1 = ((unint64_t)*(unsigned int *)(a1 + 692) >> 8) & 7;
  if (v1 >= 5) {
    ZinAssertImpl("Invalid circular buffer option");
  }
  return qword_211F07E60[v1] | qword_211F07E38[v1];
}

BOOL ZinGetRegisterProgramming<10u>::HasReduction(uint64_t a1)
{
  uint64_t CommonTaskType = ZinGetRegisterProgramming<10u>::GetCommonTaskType(a1);
  if ((CommonTaskType & 0xFF00000000) == 0) {
    std::__throw_bad_optional_access[abi:ne180100]();
  }
  return (CommonTaskType - 3) < 2;
}

uint64_t ZinGetRegisterProgramming<10u>::HasSrc1Transpose(uint64_t a1)
{
  return *(unsigned char *)(a1 + 297) & 1;
}

uint64_t ZinGetRegisterProgramming<10u>::GetSrc1Interleave(uint64_t a1)
{
  return *(unsigned char *)(a1 + 435) & 0xF;
}

uint64_t ZinGetRegisterProgramming<10u>::HasSrc1HBroadcast(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 296) >> 1) & 1;
}

uint64_t ZinGetRegisterProgramming<10u>::HasSrc1DBroadcast(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 296) >> 2) & 1;
}

uint64_t ZinGetRegisterProgramming<10u>::HasSrc1CBroadcast(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 296) >> 3) & 1;
}

uint64_t ZinGetRegisterProgramming<10u>::HasSrc1WBroadcast(uint64_t a1)
{
  return *(_DWORD *)(a1 + 296) & 1;
}

uint64_t ZinGetRegisterProgramming<10u>::IsTileDmaSrc1Compressed(uint64_t a1)
{
  return *(_DWORD *)(a1 + 448) & 1;
}

uint64_t ZinGetRegisterProgramming<10u>::HasSrc2Transpose(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 297) >> 1) & 1;
}

uint64_t ZinGetRegisterProgramming<10u>::GetSrc2Interleave(uint64_t a1)
{
  return *(unsigned char *)(a1 + 439) & 0xF;
}

uint64_t ZinGetRegisterProgramming<10u>::HasSrc2HBroadcast(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 296) >> 5) & 1;
}

uint64_t ZinGetRegisterProgramming<10u>::HasSrc2DBroadcast(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 296) >> 6) & 1;
}

uint64_t ZinGetRegisterProgramming<10u>::HasSrc2CBroadcast(uint64_t a1)
{
  return *(unsigned __int8 *)(a1 + 296) >> 7;
}

uint64_t ZinGetRegisterProgramming<10u>::HasSrc2WBroadcast(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 296) >> 4) & 1;
}

uint64_t ZinGetRegisterProgramming<10u>::IsTileDmaSrc2Compressed(uint64_t a1)
{
  return *(_DWORD *)(a1 + 464) & 1;
}

BOOL ZinGetRegisterProgramming<10u>::HasOutputTranspose(uint64_t a1)
{
  return (*(_DWORD *)(a1 + 296) & 0x400 | *(_DWORD *)(a1 + 300) & 0x10000000) != 0;
}

uint64_t ZinGetRegisterProgramming<10u>::GetOutputInterleave(uint64_t a1)
{
  return *(unsigned char *)(a1 + 915) & 0xF;
}

uint64_t ZinGetRegisterProgramming<10u>::GetTextureMode(uint64_t a1)
{
  if ((*(_DWORD *)(a1 + 528) & 7u) >= 5) {
    ZinAssertImpl("Invalid texture mode");
  }
  return dword_211F07E88[*(_DWORD *)(a1 + 528) & 7];
}

uint64_t ZinGetRegisterProgramming<10u>::GetTextureSourceDimensions@<X0>(uint64_t result@<X0>, void *a2@<X8>)
{
  unint64_t v2 = (unint64_t)*(unsigned int *)(result + 548) >> 16;
  uint64_t v3 = *(unsigned __int16 *)(result + 552);
  unint64_t v4 = (unint64_t)*(unsigned int *)(result + 544) >> 16;
  uint64_t v5 = (unsigned __int16)*(_DWORD *)(result + 548);
  *a2 = (unsigned __int16)*(_DWORD *)(result + 544);
  a2[1] = v3;
  a2[2] = v2;
  a2[3] = v5;
  a2[4] = v4;
  return result;
}

uint64_t ZinGetRegisterProgramming<10u>::GetGatherModeIndexGroupDimension(uint64_t a1)
{
  switch((*(_DWORD *)(a1 + 532) >> 12) & 7)
  {
    case 0:
      return *(_DWORD *)(a1 + 256) & 0x1FFFF;
    case 1:
      int v2 = *(_DWORD *)(a1 + 244);
      goto LABEL_7;
    case 2:
      LOWORD(v2) = *(_WORD *)(a1 + 246);
      goto LABEL_7;
    case 3:
      int v2 = *(_DWORD *)(a1 + 248);
LABEL_7:
      uint64_t result = v2 & 0x7FFF;
      break;
    case 4:
      uint64_t result = *(_DWORD *)(a1 + 284) & 0x1FFF;
      break;
    case 5:
      uint64_t result = 1;
      break;
    default:
      uint64_t result = 0;
      break;
  }
  return result;
}

uint64_t ZinGetRegisterProgramming<10u>::GetGatherModeIndexDepthDimension(uint64_t a1)
{
  switch((*(_DWORD *)(a1 + 532) >> 9) & 7)
  {
    case 0:
      return *(_DWORD *)(a1 + 256) & 0x1FFFF;
    case 1:
      int v2 = *(_DWORD *)(a1 + 244);
      goto LABEL_7;
    case 2:
      LOWORD(v2) = *(_WORD *)(a1 + 246);
      goto LABEL_7;
    case 3:
      int v2 = *(_DWORD *)(a1 + 248);
LABEL_7:
      uint64_t result = v2 & 0x7FFF;
      break;
    case 4:
      uint64_t result = *(_DWORD *)(a1 + 284) & 0x1FFF;
      break;
    case 5:
      uint64_t result = 1;
      break;
    default:
      uint64_t result = 0;
      break;
  }
  return result;
}

uint64_t ZinGetRegisterProgramming<10u>::GetGatherModeIndexPlaneDimension(uint64_t a1)
{
  switch((*(_DWORD *)(a1 + 532) >> 6) & 7)
  {
    case 0:
      return *(_DWORD *)(a1 + 256) & 0x1FFFF;
    case 1:
      int v2 = *(_DWORD *)(a1 + 244);
      goto LABEL_7;
    case 2:
      LOWORD(v2) = *(_WORD *)(a1 + 246);
      goto LABEL_7;
    case 3:
      int v2 = *(_DWORD *)(a1 + 248);
LABEL_7:
      uint64_t result = v2 & 0x7FFF;
      break;
    case 4:
      uint64_t result = *(_DWORD *)(a1 + 284) & 0x1FFF;
      break;
    case 5:
      uint64_t result = 1;
      break;
    default:
      uint64_t result = 0;
      break;
  }
  return result;
}

uint64_t ZinGetRegisterProgramming<10u>::GetGatherModeIndexHeightDimension(uint64_t a1)
{
  switch((*(_DWORD *)(a1 + 532) >> 3) & 7)
  {
    case 0:
      return *(_DWORD *)(a1 + 256) & 0x1FFFF;
    case 1:
      int v2 = *(_DWORD *)(a1 + 244);
      goto LABEL_7;
    case 2:
      LOWORD(v2) = *(_WORD *)(a1 + 246);
      goto LABEL_7;
    case 3:
      int v2 = *(_DWORD *)(a1 + 248);
LABEL_7:
      uint64_t result = v2 & 0x7FFF;
      break;
    case 4:
      uint64_t result = *(_DWORD *)(a1 + 284) & 0x1FFF;
      break;
    case 5:
      uint64_t result = 1;
      break;
    default:
      uint64_t result = 0;
      break;
  }
  return result;
}

uint64_t ZinGetRegisterProgramming<10u>::GetGatherModeIndexWidthDimension(uint64_t a1)
{
  switch(*(_DWORD *)(a1 + 532) & 7)
  {
    case 0:
      return *(_DWORD *)(a1 + 256) & 0x1FFFF;
    case 1:
      int v2 = *(_DWORD *)(a1 + 244);
      goto LABEL_7;
    case 2:
      LOWORD(v2) = *(_WORD *)(a1 + 246);
      goto LABEL_7;
    case 3:
      int v2 = *(_DWORD *)(a1 + 248);
LABEL_7:
      uint64_t result = v2 & 0x7FFF;
      break;
    case 4:
      uint64_t result = *(_DWORD *)(a1 + 284) & 0x1FFF;
      break;
    case 5:
      uint64_t result = 1;
      break;
    default:
      uint64_t result = 0;
      break;
  }
  return result;
}

uint64_t ZinGetRegisterProgramming<10u>::GetDmaSrc1FormatMode(uint64_t a1, _DWORD *a2)
{
  *a2 = *((_DWORD *)&xmmword_211F06300 + (*(_DWORD *)(a1 + 432) & 3));
  return 0;
}

uint64_t ZinGetRegisterProgramming<10u>::GetDmaSrc2FormatMode(uint64_t a1, _DWORD *a2)
{
  *a2 = *((_DWORD *)&xmmword_211F06300 + (*(_DWORD *)(a1 + 436) & 3));
  return 0;
}

uint64_t ZinGetRegisterProgramming<10u>::GetDmaDstFormatMode(uint64_t a1, _DWORD *a2)
{
  *a2 = *((_DWORD *)&xmmword_211F06300 + (*(_DWORD *)(a1 + 912) & 3));
  return 0;
}

uint64_t ZinGetRegisterProgramming<11u>::GetHin(uint64_t a1)
{
  return *(_WORD *)(a1 + 486) & 0x7FFF;
}

uint64_t ZinGetRegisterProgramming<11u>::GetDin(uint64_t a1)
{
  return *(_DWORD *)(a1 + 488) & 0x7FFF;
}

uint64_t ZinGetRegisterProgramming<11u>::GetCin(uint64_t a1)
{
  return *(_DWORD *)(a1 + 496) & 0x1FFFF;
}

uint64_t ZinGetRegisterProgramming<11u>::GetWout(uint64_t a1)
{
  return *(_DWORD *)(a1 + 504) & 0x7FFF;
}

uint64_t ZinGetRegisterProgramming<11u>::GetHout(uint64_t a1)
{
  return *(_WORD *)(a1 + 506) & 0x7FFF;
}

uint64_t ZinGetRegisterProgramming<11u>::GetDout(uint64_t a1)
{
  return *(_DWORD *)(a1 + 508) & 0x7FFF;
}

uint64_t ZinGetRegisterProgramming<11u>::GetCout(uint64_t a1)
{
  return *(_DWORD *)(a1 + 500) & 0x1FFFF;
}

uint64_t ZinGetRegisterProgramming<11u>::GetNumGroups(uint64_t a1)
{
  return *(_DWORD *)(a1 + 524) & 0x1FFF;
}

uint64_t ZinGetRegisterProgramming<11u>::GetCommonTaskType(uint64_t a1)
{
  unint64_t v1 = ((unint64_t)*(unsigned int *)(a1 + 540) >> 4) & 7;
  if (v1 == 7) {
    ZinAssertImpl("Error: Invalid Task Type");
  }
  return qword_211F07DB8[v1];
}

BOOL ZinGetRegisterProgramming<11u>::IsTexModeEnabled(uint64_t a1)
{
  return (*(unsigned char *)(a1 + 704) & 7) != 0;
}

uint64_t ZinGetRegisterProgramming<11u>::IsSource1Ephemeral(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 792) >> 1) & 1;
}

uint64_t ZinGetRegisterProgramming<11u>::IsSource2Ephemeral(uint64_t a1)
{
  return *(unsigned char *)(a1 + 795) & 1;
}

uint64_t ZinGetRegisterProgramming<11u>::IsResultEphemeral(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 836) >> 1) & 1;
}

uint64_t ZinGetRegisterProgramming<11u>::GetCircularBufferSrc1(uint64_t a1)
{
  if ((*(_DWORD *)(a1 + 864) & 7u) >= 5) {
    ZinAssertImpl("Invalid circular buffer option");
  }
  return qword_211F07E60[*(_DWORD *)(a1 + 864) & 7] | qword_211F07E38[*(_DWORD *)(a1 + 864) & 7];
}

uint64_t ZinGetRegisterProgramming<11u>::GetCircularBufferSrc2(uint64_t a1)
{
  unint64_t v1 = ((unint64_t)*(unsigned int *)(a1 + 864) >> 4) & 7;
  if (v1 >= 5) {
    ZinAssertImpl("Invalid circular buffer option");
  }
  return qword_211F07E60[v1] | qword_211F07E38[v1];
}

uint64_t ZinGetRegisterProgramming<11u>::GetCircularBufferResult(uint64_t a1)
{
  unint64_t v1 = ((unint64_t)*(unsigned int *)(a1 + 864) >> 8) & 7;
  if (v1 >= 5) {
    ZinAssertImpl("Invalid circular buffer option");
  }
  return qword_211F07E60[v1] | qword_211F07E38[v1];
}

BOOL ZinGetRegisterProgramming<11u>::HasReduction(uint64_t a1)
{
  uint64_t CommonTaskType = ZinGetRegisterProgramming<11u>::GetCommonTaskType(a1);
  if ((CommonTaskType & 0xFF00000000) == 0) {
    std::__throw_bad_optional_access[abi:ne180100]();
  }
  return (CommonTaskType - 3) < 2;
}

uint64_t ZinGetRegisterProgramming<11u>::HasSrc1Transpose(uint64_t a1)
{
  return *(unsigned char *)(a1 + 537) & 1;
}

uint64_t ZinGetRegisterProgramming<11u>::GetSrc1Interleave(uint64_t a1)
{
  return *(unsigned char *)(a1 + 651) & 0xF;
}

uint64_t ZinGetRegisterProgramming<11u>::HasSrc1HBroadcast(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 536) >> 1) & 1;
}

uint64_t ZinGetRegisterProgramming<11u>::HasSrc1DBroadcast(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 536) >> 2) & 1;
}

uint64_t ZinGetRegisterProgramming<11u>::HasSrc1CBroadcast(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 536) >> 3) & 1;
}

uint64_t ZinGetRegisterProgramming<11u>::HasSrc1WBroadcast(uint64_t a1)
{
  return *(_DWORD *)(a1 + 536) & 1;
}

uint64_t ZinGetRegisterProgramming<11u>::HasSrc2Transpose(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 537) >> 1) & 1;
}

uint64_t ZinGetRegisterProgramming<11u>::GetSrc2Interleave(uint64_t a1)
{
  return *(unsigned char *)(a1 + 655) & 0xF;
}

uint64_t ZinGetRegisterProgramming<11u>::HasSrc2HBroadcast(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 536) >> 5) & 1;
}

uint64_t ZinGetRegisterProgramming<11u>::HasSrc2DBroadcast(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 536) >> 6) & 1;
}

uint64_t ZinGetRegisterProgramming<11u>::HasSrc2CBroadcast(uint64_t a1)
{
  return *(unsigned __int8 *)(a1 + 536) >> 7;
}

uint64_t ZinGetRegisterProgramming<11u>::HasSrc2WBroadcast(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 536) >> 4) & 1;
}

BOOL ZinGetRegisterProgramming<11u>::HasOutputTranspose(uint64_t a1)
{
  return (*(_DWORD *)(a1 + 536) & 0x400 | *(_DWORD *)(a1 + 540) & 0x10000000) != 0;
}

uint64_t ZinGetRegisterProgramming<11u>::GetOutputInterleave(uint64_t a1)
{
  return *(unsigned char *)(a1 + 987) & 0xF;
}

uint64_t ZinGetRegisterProgramming<11u>::GetTextureMode(uint64_t a1)
{
  if ((*(_DWORD *)(a1 + 704) & 7u) >= 5) {
    ZinAssertImpl("Invalid texture mode");
  }
  return dword_211F07E88[*(_DWORD *)(a1 + 704) & 7];
}

uint64_t ZinGetRegisterProgramming<11u>::GetTextureSourceDimensions@<X0>(uint64_t result@<X0>, void *a2@<X8>)
{
  unint64_t v2 = (unint64_t)*(unsigned int *)(result + 724) >> 16;
  uint64_t v3 = *(unsigned __int16 *)(result + 728);
  unint64_t v4 = (unint64_t)*(unsigned int *)(result + 720) >> 16;
  uint64_t v5 = (unsigned __int16)*(_DWORD *)(result + 724);
  *a2 = (unsigned __int16)*(_DWORD *)(result + 720);
  a2[1] = v3;
  a2[2] = v2;
  a2[3] = v5;
  a2[4] = v4;
  return result;
}

uint64_t ZinGetRegisterProgramming<11u>::GetGatherModeIndexGroupDimension(uint64_t a1)
{
  switch((*(_DWORD *)(a1 + 708) >> 12) & 7)
  {
    case 0:
      return *(_DWORD *)(a1 + 496) & 0x1FFFF;
    case 1:
      int v2 = *(_DWORD *)(a1 + 484);
      goto LABEL_7;
    case 2:
      LOWORD(v2) = *(_WORD *)(a1 + 486);
      goto LABEL_7;
    case 3:
      int v2 = *(_DWORD *)(a1 + 488);
LABEL_7:
      uint64_t result = v2 & 0x7FFF;
      break;
    case 4:
      uint64_t result = *(_DWORD *)(a1 + 524) & 0x1FFF;
      break;
    case 5:
      uint64_t result = 1;
      break;
    default:
      uint64_t result = 0;
      break;
  }
  return result;
}

uint64_t ZinGetRegisterProgramming<11u>::GetGatherModeIndexDepthDimension(uint64_t a1)
{
  switch((*(_DWORD *)(a1 + 708) >> 9) & 7)
  {
    case 0:
      return *(_DWORD *)(a1 + 496) & 0x1FFFF;
    case 1:
      int v2 = *(_DWORD *)(a1 + 484);
      goto LABEL_7;
    case 2:
      LOWORD(v2) = *(_WORD *)(a1 + 486);
      goto LABEL_7;
    case 3:
      int v2 = *(_DWORD *)(a1 + 488);
LABEL_7:
      uint64_t result = v2 & 0x7FFF;
      break;
    case 4:
      uint64_t result = *(_DWORD *)(a1 + 524) & 0x1FFF;
      break;
    case 5:
      uint64_t result = 1;
      break;
    default:
      uint64_t result = 0;
      break;
  }
  return result;
}

uint64_t ZinGetRegisterProgramming<11u>::GetGatherModeIndexPlaneDimension(uint64_t a1)
{
  switch((*(_DWORD *)(a1 + 708) >> 6) & 7)
  {
    case 0:
      return *(_DWORD *)(a1 + 496) & 0x1FFFF;
    case 1:
      int v2 = *(_DWORD *)(a1 + 484);
      goto LABEL_7;
    case 2:
      LOWORD(v2) = *(_WORD *)(a1 + 486);
      goto LABEL_7;
    case 3:
      int v2 = *(_DWORD *)(a1 + 488);
LABEL_7:
      uint64_t result = v2 & 0x7FFF;
      break;
    case 4:
      uint64_t result = *(_DWORD *)(a1 + 524) & 0x1FFF;
      break;
    case 5:
      uint64_t result = 1;
      break;
    default:
      uint64_t result = 0;
      break;
  }
  return result;
}

uint64_t ZinGetRegisterProgramming<11u>::GetGatherModeIndexHeightDimension(uint64_t a1)
{
  switch((*(_DWORD *)(a1 + 708) >> 3) & 7)
  {
    case 0:
      return *(_DWORD *)(a1 + 496) & 0x1FFFF;
    case 1:
      int v2 = *(_DWORD *)(a1 + 484);
      goto LABEL_7;
    case 2:
      LOWORD(v2) = *(_WORD *)(a1 + 486);
      goto LABEL_7;
    case 3:
      int v2 = *(_DWORD *)(a1 + 488);
LABEL_7:
      uint64_t result = v2 & 0x7FFF;
      break;
    case 4:
      uint64_t result = *(_DWORD *)(a1 + 524) & 0x1FFF;
      break;
    case 5:
      uint64_t result = 1;
      break;
    default:
      uint64_t result = 0;
      break;
  }
  return result;
}

uint64_t ZinGetRegisterProgramming<11u>::GetGatherModeIndexWidthDimension(uint64_t a1)
{
  switch(*(_DWORD *)(a1 + 708) & 7)
  {
    case 0:
      return *(_DWORD *)(a1 + 496) & 0x1FFFF;
    case 1:
      int v2 = *(_DWORD *)(a1 + 484);
      goto LABEL_7;
    case 2:
      LOWORD(v2) = *(_WORD *)(a1 + 486);
      goto LABEL_7;
    case 3:
      int v2 = *(_DWORD *)(a1 + 488);
LABEL_7:
      uint64_t result = v2 & 0x7FFF;
      break;
    case 4:
      uint64_t result = *(_DWORD *)(a1 + 524) & 0x1FFF;
      break;
    case 5:
      uint64_t result = 1;
      break;
    default:
      uint64_t result = 0;
      break;
  }
  return result;
}

uint64_t ZinGetRegisterProgramming<17u>::GetDin(uint64_t a1)
{
  return *(_DWORD *)(a1 + 512) & 0x1FFFF;
}

uint64_t ZinGetRegisterProgramming<17u>::GetWout(uint64_t a1)
{
  return *(_DWORD *)(a1 + 516) & 0x1FFFF;
}

uint64_t ZinGetRegisterProgramming<17u>::GetHout(uint64_t a1)
{
  return *(_DWORD *)(a1 + 520) & 0x1FFFF;
}

uint64_t ZinGetRegisterProgramming<17u>::GetDout(uint64_t a1)
{
  return *(_DWORD *)(a1 + 528) & 0x1FFFF;
}

uint64_t ZinGetRegisterProgramming<17u>::GetCout(uint64_t a1)
{
  return *(_DWORD *)(a1 + 524) & 0x1FFFF;
}

uint64_t ZinGetRegisterProgramming<17u>::GetNumGroups(uint64_t a1)
{
  return *(_DWORD *)(a1 + 532) & 0x1FFFF;
}

uint64_t ZinGetRegisterProgramming<17u>::GetCommonTaskType(uint64_t a1)
{
  uint64_t v1 = *(_DWORD *)(a1 + 556) >> 4;
  if (v1 >= 9 || ((0x17Fu >> v1) & 1) == 0) {
    ZinAssertImpl("Error: Invalid Task Type");
  }
  return qword_211F07DF0[v1];
}

BOOL ZinGetRegisterProgramming<17u>::IsTexModeEnabled(uint64_t a1)
{
  return (*(unsigned char *)(a1 + 796) & 7) != 0;
}

BOOL ZinGetRegisterProgramming<17u>::IsPEIndexingEnabled(uint64_t a1)
{
  return (*(unsigned char *)(a1 + 1070) & 7) != 0;
}

uint64_t ZinGetRegisterProgramming<17u>::IsSource1Ephemeral(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 932) >> 1) & 1;
}

uint64_t ZinGetRegisterProgramming<17u>::IsSource2Ephemeral(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 936) >> 1) & 1;
}

uint64_t ZinGetRegisterProgramming<17u>::IsResultEphemeral(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 1000) >> 1) & 1;
}

uint64_t ZinGetRegisterProgramming<17u>::GetCircularBufferSrc1(uint64_t a1)
{
  if ((*(_DWORD *)(a1 + 1028) & 7u) >= 5) {
    ZinAssertImpl("Invalid circular buffer option");
  }
  return qword_211F07E60[*(_DWORD *)(a1 + 1028) & 7] | qword_211F07E38[*(_DWORD *)(a1 + 1028) & 7];
}

uint64_t ZinGetRegisterProgramming<17u>::GetCircularBufferSrc2(uint64_t a1)
{
  unint64_t v1 = ((unint64_t)*(unsigned int *)(a1 + 1028) >> 4) & 7;
  if (v1 >= 5) {
    ZinAssertImpl("Invalid circular buffer option");
  }
  return qword_211F07E60[v1] | qword_211F07E38[v1];
}

uint64_t ZinGetRegisterProgramming<17u>::GetCircularBufferResult(uint64_t a1)
{
  unint64_t v1 = ((unint64_t)*(unsigned int *)(a1 + 1028) >> 8) & 7;
  if (v1 >= 5) {
    ZinAssertImpl("Invalid circular buffer option");
  }
  return qword_211F07E60[v1] | qword_211F07E38[v1];
}

BOOL ZinGetRegisterProgramming<17u>::HasReduction(uint64_t a1)
{
  uint64_t CommonTaskType = ZinGetRegisterProgramming<17u>::GetCommonTaskType(a1);
  if ((CommonTaskType & 0xFF00000000) == 0) {
    std::__throw_bad_optional_access[abi:ne180100]();
  }
  return (CommonTaskType - 3) < 2;
}

uint64_t ZinGetRegisterProgramming<17u>::HasSrc1Transpose(uint64_t a1)
{
  return *(unsigned char *)(a1 + 569) & 1;
}

uint64_t ZinGetRegisterProgramming<17u>::GetSrc1Interleave(uint64_t a1)
{
  return *(unsigned char *)(a1 + 703) & 0xF;
}

uint64_t ZinGetRegisterProgramming<17u>::HasSrc1HBroadcast(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 568) >> 1) & 1;
}

uint64_t ZinGetRegisterProgramming<17u>::HasSrc1DBroadcast(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 568) >> 2) & 1;
}

uint64_t ZinGetRegisterProgramming<17u>::HasSrc1CBroadcast(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 568) >> 3) & 1;
}

uint64_t ZinGetRegisterProgramming<17u>::HasSrc1WBroadcast(uint64_t a1)
{
  return *(_DWORD *)(a1 + 568) & 1;
}

uint64_t ZinGetRegisterProgramming<17u>::IsTileDmaSrc1Compressed(uint64_t a1)
{
  return *(_DWORD *)(a1 + 716) & 1;
}

uint64_t ZinGetRegisterProgramming<17u>::HasSrc2Transpose(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 569) >> 1) & 1;
}

uint64_t ZinGetRegisterProgramming<17u>::GetSrc2Interleave(uint64_t a1)
{
  return *(unsigned char *)(a1 + 707) & 0xF;
}

uint64_t ZinGetRegisterProgramming<17u>::HasSrc2HBroadcast(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 568) >> 5) & 1;
}

uint64_t ZinGetRegisterProgramming<17u>::HasSrc2DBroadcast(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 568) >> 6) & 1;
}

uint64_t ZinGetRegisterProgramming<17u>::HasSrc2CBroadcast(uint64_t a1)
{
  return *(unsigned __int8 *)(a1 + 568) >> 7;
}

uint64_t ZinGetRegisterProgramming<17u>::HasSrc2WBroadcast(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 568) >> 4) & 1;
}

uint64_t ZinGetRegisterProgramming<17u>::IsTileDmaSrc2Compressed(uint64_t a1)
{
  return *(_DWORD *)(a1 + 732) & 1;
}

BOOL ZinGetRegisterProgramming<17u>::HasOutputTranspose(uint64_t a1)
{
  return (*(_DWORD *)(a1 + 568) & 0x400 | *(_DWORD *)(a1 + 556) & 0x10000000) != 0;
}

uint64_t ZinGetRegisterProgramming<17u>::GetOutputInterleave(uint64_t a1)
{
  return *(unsigned char *)(a1 + 1283) & 0xF;
}

uint64_t ZinGetRegisterProgramming<17u>::IsTileDmaDstCompressed(uint64_t a1)
{
  return *(_DWORD *)(a1 + 1288) & 1;
}

uint64_t ZinGetRegisterProgramming<17u>::GetTextureMode(uint64_t a1)
{
  if ((*(_DWORD *)(a1 + 796) & 7u) >= 5) {
    ZinAssertImpl("Invalid texture mode");
  }
  return dword_211F07E88[*(_DWORD *)(a1 + 796) & 7];
}

float ZinGetRegisterProgramming<17u>::GetTextureSourceDimensions@<S0>(int8x8_t *a1@<X0>, uint64_t a2@<X8>)
{
  unint64_t v2 = (unint64_t)a1[101].u32[1] >> 16;
  *(void *)a2 = (unsigned __int16)a1[101].i32[1];
  int8x8_t v3 = a1[102];
  int8x8_t v4 = (int8x8_t)vshr_n_u32((uint32x2_t)v3, 0x10uLL);
  unsigned __int16 v5 = v3.i16[0];
  v3.i16[3] = 0;
  int8x8_t v6 = vext_s8(v3, v4, 4uLL);
  *(void *)&long long v7 = v6.u32[0];
  *((void *)&v7 + 1) = v6.u32[1];
  *(_OWORD *)(a2 + 8) = v7;
  *(void *)(a2 + 24) = v5;
  *(void *)(a2 + 32) = v2;
  return *(float *)v6.i32;
}

uint64_t ZinGetRegisterProgramming<17u>::GetGatherModeIndexGroupDimension(_DWORD *a1)
{
  switch((a1[200] >> 12) & 7)
  {
    case 0:
      int v1 = a1[127];
      goto LABEL_8;
    case 1:
      int v1 = a1[125];
      goto LABEL_8;
    case 2:
      int v1 = a1[126];
      goto LABEL_8;
    case 3:
      int v1 = a1[128];
      goto LABEL_8;
    case 4:
      int v1 = a1[133];
LABEL_8:
      uint64_t result = v1 & 0x1FFFF;
      break;
    case 5:
      uint64_t result = 1;
      break;
    default:
      uint64_t result = 0;
      break;
  }
  return result;
}

uint64_t ZinGetRegisterProgramming<17u>::GetGatherModeIndexDepthDimension(_DWORD *a1)
{
  switch((a1[200] >> 9) & 7)
  {
    case 0:
      int v1 = a1[127];
      goto LABEL_8;
    case 1:
      int v1 = a1[125];
      goto LABEL_8;
    case 2:
      int v1 = a1[126];
      goto LABEL_8;
    case 3:
      int v1 = a1[128];
      goto LABEL_8;
    case 4:
      int v1 = a1[133];
LABEL_8:
      uint64_t result = v1 & 0x1FFFF;
      break;
    case 5:
      uint64_t result = 1;
      break;
    default:
      uint64_t result = 0;
      break;
  }
  return result;
}

uint64_t ZinGetRegisterProgramming<17u>::GetGatherModeIndexPlaneDimension(_DWORD *a1)
{
  switch((a1[200] >> 6) & 7)
  {
    case 0:
      int v1 = a1[127];
      goto LABEL_8;
    case 1:
      int v1 = a1[125];
      goto LABEL_8;
    case 2:
      int v1 = a1[126];
      goto LABEL_8;
    case 3:
      int v1 = a1[128];
      goto LABEL_8;
    case 4:
      int v1 = a1[133];
LABEL_8:
      uint64_t result = v1 & 0x1FFFF;
      break;
    case 5:
      uint64_t result = 1;
      break;
    default:
      uint64_t result = 0;
      break;
  }
  return result;
}

uint64_t ZinGetRegisterProgramming<17u>::GetGatherModeIndexHeightDimension(_DWORD *a1)
{
  switch((a1[200] >> 3) & 7)
  {
    case 0:
      int v1 = a1[127];
      goto LABEL_8;
    case 1:
      int v1 = a1[125];
      goto LABEL_8;
    case 2:
      int v1 = a1[126];
      goto LABEL_8;
    case 3:
      int v1 = a1[128];
      goto LABEL_8;
    case 4:
      int v1 = a1[133];
LABEL_8:
      uint64_t result = v1 & 0x1FFFF;
      break;
    case 5:
      uint64_t result = 1;
      break;
    default:
      uint64_t result = 0;
      break;
  }
  return result;
}

uint64_t ZinGetRegisterProgramming<17u>::GetGatherModeIndexWidthDimension(_DWORD *a1)
{
  switch(a1[200] & 7)
  {
    case 0:
      int v1 = a1[127];
      goto LABEL_8;
    case 1:
      int v1 = a1[125];
      goto LABEL_8;
    case 2:
      int v1 = a1[126];
      goto LABEL_8;
    case 3:
      int v1 = a1[128];
      goto LABEL_8;
    case 4:
      int v1 = a1[133];
LABEL_8:
      uint64_t result = v1 & 0x1FFFF;
      break;
    case 5:
      uint64_t result = 1;
      break;
    default:
      uint64_t result = 0;
      break;
  }
  return result;
}

uint64_t ZinGetRegisterProgramming<17u>::GetDmaSrc1FormatMode(uint64_t a1, _DWORD *a2)
{
  *a2 = *((_DWORD *)&xmmword_211F06300 + (*(_DWORD *)(a1 + 700) & 3));
  return 0;
}

uint64_t ZinGetRegisterProgramming<17u>::GetDmaSrc2FormatMode(uint64_t a1, _DWORD *a2)
{
  *a2 = *((_DWORD *)&xmmword_211F06300 + (*(_DWORD *)(a1 + 704) & 3));
  return 0;
}

uint64_t ZinGetRegisterProgramming<17u>::GetDmaDstFormatMode(uint64_t a1, _DWORD *a2)
{
  *a2 = *((_DWORD *)&xmmword_211F06300 + (*(_DWORD *)(a1 + 1280) & 3));
  return 0;
}

uint64_t ZinGetRegisterProgramming<17u>::GetCropOffsetSrc1Y(uint64_t a1)
{
  return *(unsigned __int16 *)(a1 + 728);
}

uint64_t ZinGetRegisterProgramming<17u>::GetCropOffsetSrc2Y(uint64_t a1)
{
  return *(unsigned __int16 *)(a1 + 744);
}

uint64_t ZinGetRegisterProgramming<17u>::GetCropOffsetDstY(uint64_t a1)
{
  return *(unsigned __int16 *)(a1 + 1304);
}

uint64_t ZinGetRegisterProgramming<19u>::GetDout(uint64_t a1)
{
  return *(_DWORD *)(a1 + 540) & 0x1FFFF;
}

uint64_t ZinGetRegisterProgramming<19u>::GetCout(uint64_t a1)
{
  return *(_DWORD *)(a1 + 536) & 0x1FFFF;
}

uint64_t ZinGetRegisterProgramming<19u>::GetNumGroups(uint64_t a1)
{
  return *(_DWORD *)(a1 + 544) & 0x1FFFF;
}

uint64_t ZinGetRegisterProgramming<19u>::GetCommonTaskType(uint64_t a1)
{
  uint64_t v1 = *(_DWORD *)(a1 + 568) >> 4;
  if (v1 >= 9 || ((0x17Fu >> v1) & 1) == 0) {
    ZinAssertImpl("Error: Invalid Task Type");
  }
  return qword_211F07DF0[v1];
}

BOOL ZinGetRegisterProgramming<19u>::IsTexModeEnabled(uint64_t a1)
{
  return (*(unsigned char *)(a1 + 808) & 7) != 0;
}

BOOL ZinGetRegisterProgramming<19u>::IsPEIndexingEnabled(uint64_t a1)
{
  return (*(unsigned char *)(a1 + 1090) & 7) != 0;
}

uint64_t ZinGetRegisterProgramming<19u>::IsSource1Ephemeral(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 952) >> 1) & 1;
}

uint64_t ZinGetRegisterProgramming<19u>::IsSource2Ephemeral(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 956) >> 1) & 1;
}

uint64_t ZinGetRegisterProgramming<19u>::IsResultEphemeral(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 1020) >> 1) & 1;
}

uint64_t ZinGetRegisterProgramming<19u>::GetCircularBufferSrc1(uint64_t a1)
{
  if ((*(_DWORD *)(a1 + 1048) & 7u) >= 5) {
    ZinAssertImpl("Invalid circular buffer option");
  }
  return qword_211F07E60[*(_DWORD *)(a1 + 1048) & 7] | qword_211F07E38[*(_DWORD *)(a1 + 1048) & 7];
}

uint64_t ZinGetRegisterProgramming<19u>::GetCircularBufferSrc2(uint64_t a1)
{
  unint64_t v1 = ((unint64_t)*(unsigned int *)(a1 + 1048) >> 4) & 7;
  if (v1 >= 5) {
    ZinAssertImpl("Invalid circular buffer option");
  }
  return qword_211F07E60[v1] | qword_211F07E38[v1];
}

uint64_t ZinGetRegisterProgramming<19u>::GetCircularBufferResult(uint64_t a1)
{
  unint64_t v1 = ((unint64_t)*(unsigned int *)(a1 + 1048) >> 8) & 7;
  if (v1 >= 5) {
    ZinAssertImpl("Invalid circular buffer option");
  }
  return qword_211F07E60[v1] | qword_211F07E38[v1];
}

BOOL ZinGetRegisterProgramming<19u>::HasReduction(uint64_t a1)
{
  uint64_t CommonTaskType = ZinGetRegisterProgramming<19u>::GetCommonTaskType(a1);
  if ((CommonTaskType & 0xFF00000000) == 0) {
    std::__throw_bad_optional_access[abi:ne180100]();
  }
  return (CommonTaskType - 3) < 2;
}

uint64_t ZinGetRegisterProgramming<19u>::HasSrc1Transpose(uint64_t a1)
{
  return *(unsigned char *)(a1 + 581) & 1;
}

uint64_t ZinGetRegisterProgramming<19u>::GetSrc1Interleave(uint64_t a1)
{
  return *(unsigned char *)(a1 + 715) & 0xF;
}

uint64_t ZinGetRegisterProgramming<19u>::HasSrc1HBroadcast(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 580) >> 1) & 1;
}

uint64_t ZinGetRegisterProgramming<19u>::HasSrc1DBroadcast(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 580) >> 2) & 1;
}

uint64_t ZinGetRegisterProgramming<19u>::HasSrc1CBroadcast(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 580) >> 3) & 1;
}

uint64_t ZinGetRegisterProgramming<19u>::HasSrc1WBroadcast(uint64_t a1)
{
  return *(_DWORD *)(a1 + 580) & 1;
}

uint64_t ZinGetRegisterProgramming<19u>::IsTileDmaSrc1Compressed(uint64_t a1)
{
  return *(_DWORD *)(a1 + 728) & 1;
}

uint64_t ZinGetRegisterProgramming<19u>::HasSrc2Transpose(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 581) >> 1) & 1;
}

uint64_t ZinGetRegisterProgramming<19u>::GetSrc2Interleave(uint64_t a1)
{
  return *(unsigned char *)(a1 + 719) & 0xF;
}

uint64_t ZinGetRegisterProgramming<19u>::HasSrc2HBroadcast(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 580) >> 5) & 1;
}

uint64_t ZinGetRegisterProgramming<19u>::HasSrc2DBroadcast(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 580) >> 6) & 1;
}

uint64_t ZinGetRegisterProgramming<19u>::HasSrc2CBroadcast(uint64_t a1)
{
  return *(unsigned __int8 *)(a1 + 580) >> 7;
}

uint64_t ZinGetRegisterProgramming<19u>::HasSrc2WBroadcast(uint64_t a1)
{
  return (*(unsigned __int8 *)(a1 + 580) >> 4) & 1;
}

uint64_t ZinGetRegisterProgramming<19u>::IsTileDmaSrc2Compressed(uint64_t a1)
{
  return *(_DWORD *)(a1 + 744) & 1;
}

BOOL ZinGetRegisterProgramming<19u>::HasOutputTranspose(uint64_t a1)
{
  return (*(_DWORD *)(a1 + 580) & 0x400 | *(_DWORD *)(a1 + 568) & 0x10000000) != 0;
}

uint64_t ZinGetRegisterProgramming<19u>::GetOutputInterleave(uint64_t a1)
{
  return *(unsigned char *)(a1 + 1315) & 0xF;
}

uint64_t ZinGetRegisterProgramming<19u>::IsTileDmaDstCompressed(uint64_t a1)
{
  return *(_DWORD *)(a1 + 1320) & 1;
}

uint64_t ZinGetRegisterProgramming<19u>::GetTextureMode(uint64_t a1)
{
  if ((*(_DWORD *)(a1 + 808) & 7u) >= 5) {
    ZinAssertImpl("Invalid texture mode");
  }
  return dword_211F07E88[*(_DWORD *)(a1 + 808) & 7];
}

uint64_t ZinGetRegisterProgramming<19u>::GetTextureSourceDimensions@<X0>(uint64_t result@<X0>, void *a2@<X8>)
{
  unint64_t v2 = (unint64_t)*(unsigned int *)(result + 828) >> 16;
  uint64_t v3 = *(unsigned __int16 *)(result + 832);
  unint64_t v4 = (unint64_t)*(unsigned int *)(result + 824) >> 16;
  uint64_t v5 = (unsigned __int16)*(_DWORD *)(result + 828);
  *a2 = (unsigned __int16)*(_DWORD *)(result + 824);
  a2[1] = v3;
  a2[2] = v2;
  a2[3] = v5;
  a2[4] = v4;
  return result;
}

uint64_t ZinGetRegisterProgramming<19u>::GetGatherModeIndexGroupDimension(_DWORD *a1)
{
  switch((a1[203] >> 12) & 7)
  {
    case 0:
      int v1 = a1[130];
      goto LABEL_8;
    case 1:
      int v1 = a1[128];
      goto LABEL_8;
    case 2:
      int v1 = a1[129];
      goto LABEL_8;
    case 3:
      int v1 = a1[131];
      goto LABEL_8;
    case 4:
      int v1 = a1[136];
LABEL_8:
      uint64_t result = v1 & 0x1FFFF;
      break;
    case 5:
      uint64_t result = 1;
      break;
    default:
      uint64_t result = 0;
      break;
  }
  return result;
}

uint64_t ZinGetRegisterProgramming<19u>::GetGatherModeIndexDepthDimension(_DWORD *a1)
{
  switch((a1[203] >> 9) & 7)
  {
    case 0:
      int v1 = a1[130];
      goto LABEL_8;
    case 1:
      int v1 = a1[128];
      goto LABEL_8;
    case 2:
      int v1 = a1[129];
      goto LABEL_8;
    case 3:
      int v1 = a1[131];
      goto LABEL_8;
    case 4:
      int v1 = a1[136];
LABEL_8:
      uint64_t result = v1 & 0x1FFFF;
      break;
    case 5:
      uint64_t result = 1;
      break;
    default:
      uint64_t result = 0;
      break;
  }
  return result;
}

uint64_t ZinGetRegisterProgramming<19u>::GetGatherModeIndexPlaneDimension(_DWORD *a1)
{
  switch((a1[203] >> 6) & 7)
  {
    case 0:
      int v1 = a1[130];
      goto LABEL_8;
    case 1:
      int v1 = a1[128];
      goto LABEL_8;
    case 2:
      int v1 = a1[129];
      goto LABEL_8;
    case 3:
      int v1 = a1[131];
      goto LABEL_8;
    case 4:
      int v1 = a1[136];
LABEL_8:
      uint64_t result = v1 & 0x1FFFF;
      break;
    case 5:
      uint64_t result = 1;
      break;
    default:
      uint64_t result = 0;
      break;
  }
  return result;
}

uint64_t ZinGetRegisterProgramming<19u>::GetGatherModeIndexHeightDimension(_DWORD *a1)
{
  switch((a1[203] >> 3) & 7)
  {
    case 0:
      int v1 = a1[130];
      goto LABEL_8;
    case 1:
      int v1 = a1[128];
      goto LABEL_8;
    case 2:
      int v1 = a1[129];
      goto LABEL_8;
    case 3:
      int v1 = a1[131];
      goto LABEL_8;
    case 4:
      int v1 = a1[136];
LABEL_8:
      uint64_t result = v1 & 0x1FFFF;
      break;
    case 5:
      uint64_t result = 1;
      break;
    default:
      uint64_t result = 0;
      break;
  }
  return result;
}

uint64_t ZinGetRegisterProgramming<19u>::GetGatherModeIndexWidthDimension(_DWORD *a1)
{
  switch(a1[203] & 7)
  {
    case 0:
      int v1 = a1[130];
      goto LABEL_8;
    case 1:
      int v1 = a1[128];
      goto LABEL_8;
    case 2:
      int v1 = a1[129];
      goto LABEL_8;
    case 3:
      int v1 = a1[131];
      goto LABEL_8;
    case 4:
      int v1 = a1[136];
LABEL_8:
      uint64_t result = v1 & 0x1FFFF;
      break;
    case 5:
      uint64_t result = 1;
      break;
    default:
      uint64_t result = 0;
      break;
  }
  return result;
}

uint64_t ZinGetRegisterProgramming<19u>::GetDmaSrc1FormatMode(uint64_t a1, _DWORD *a2)
{
  *a2 = *((_DWORD *)&xmmword_211F06300 + (*(_DWORD *)(a1 + 712) & 3));
  return 0;
}

uint64_t ZinGetRegisterProgramming<19u>::GetDmaSrc2FormatMode(uint64_t a1, _DWORD *a2)
{
  *a2 = *((_DWORD *)&xmmword_211F06300 + (*(_DWORD *)(a1 + 716) & 3));
  return 0;
}

uint64_t ZinGetRegisterProgramming<19u>::GetDmaDstFormatMode(uint64_t a1, _DWORD *a2)
{
  *a2 = *((_DWORD *)&xmmword_211F06300 + (*(_DWORD *)(a1 + 1312) & 3));
  return 0;
}

uint64_t ZinGetRegisterProgramming<19u>::GetCropOffsetSrc1Y(uint64_t a1)
{
  return *(unsigned __int16 *)(a1 + 740);
}

uint64_t ZinGetRegisterProgramming<19u>::GetCropOffsetSrc2Y(uint64_t a1)
{
  return *(unsigned __int16 *)(a1 + 756);
}

uint64_t ZinGetRegisterProgramming<19u>::GetCropOffsetDstY(uint64_t a1)
{
  return *(unsigned __int16 *)(a1 + 1336);
}

uint64_t *ZinMirL2HazardAnalysis::SymbolEventTable::AddSymbolToEventTable(ZinMirL2HazardAnalysis::SymbolEventTable *this, uint64_t a2, uint64_t a3, ZinIrSymbol *a4)
{
  uint64_t v38 = a3;
  unint64_t v39 = a2;
  long long v40 = (uint64_t *)&v39;
  int8x8_t v6 = std::__hash_table<std::__hash_value_type<long,std::vector<ZinANELayer *>>,std::__unordered_map_hasher<long,std::__hash_value_type<long,std::vector<ZinANELayer *>>,std::hash<long>,std::equal_to<long>,true>,std::__unordered_map_equal<long,std::__hash_value_type<long,std::vector<ZinANELayer *>>,std::equal_to<long>,std::hash<long>,true>,std::allocator<std::__hash_value_type<long,std::vector<ZinANELayer *>>>>::__emplace_unique_key_args<long,std::piecewise_construct_t const&,std::tuple<long const&>,std::tuple<>>((uint64_t)this + 40, &v39, (uint64_t)&std::piecewise_construct, &v40);
  long long v7 = (void *)v6[4];
  unint64_t v8 = v6[5];
  if ((unint64_t)v7 >= v8)
  {
    uint64_t v10 = v6[3];
    uint64_t v11 = ((uint64_t)v7 - v10) >> 3;
    if ((unint64_t)(v11 + 1) >> 61) {
      goto LABEL_34;
    }
    uint64_t v12 = v8 - v10;
    uint64_t v13 = v12 >> 2;
    if (v12 >> 2 <= (unint64_t)(v11 + 1)) {
      uint64_t v13 = v11 + 1;
    }
    if ((unint64_t)v12 >= 0x7FFFFFFFFFFFFFF8) {
      unint64_t v14 = 0x1FFFFFFFFFFFFFFFLL;
    }
    else {
      unint64_t v14 = v13;
    }
    if (v14) {
      uint64_t v15 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)(v6 + 5), v14);
    }
    else {
      uint64_t v15 = 0;
    }
    size_t v16 = &v15[8 * v11];
    unint64_t v17 = &v15[8 * v14];
    *(void *)size_t v16 = a4;
    uint64_t v9 = v16 + 8;
    uint64_t v19 = (char *)v6[3];
    uint64_t v18 = (char *)v6[4];
    if (v18 != v19)
    {
      do
      {
        uint64_t v20 = *((void *)v18 - 1);
        v18 -= 8;
        *((void *)v16 - 1) = v20;
        v16 -= 8;
      }
      while (v18 != v19);
      uint64_t v18 = (char *)v6[3];
    }
    v6[3] = v16;
    v6[4] = v9;
    v6[5] = v17;
    if (v18) {
      operator delete(v18);
    }
  }
  else
  {
    void *v7 = a4;
    uint64_t v9 = v7 + 1;
  }
  v6[4] = v9;
  long long v40 = &v38;
  unint64_t v21 = std::__hash_table<std::__hash_value_type<long,std::vector<ZinANELayer *>>,std::__unordered_map_hasher<long,std::__hash_value_type<long,std::vector<ZinANELayer *>>,std::hash<long>,std::equal_to<long>,true>,std::__unordered_map_equal<long,std::__hash_value_type<long,std::vector<ZinANELayer *>>,std::equal_to<long>,std::hash<long>,true>,std::allocator<std::__hash_value_type<long,std::vector<ZinANELayer *>>>>::__emplace_unique_key_args<long,std::piecewise_construct_t const&,std::tuple<long const&>,std::tuple<>>((uint64_t)this + 80, (unint64_t *)&v38, (uint64_t)&std::piecewise_construct, &v40);
  uint64_t v22 = (void *)v21[4];
  unint64_t v23 = v21[5];
  if ((unint64_t)v22 < v23)
  {
    *uint64_t v22 = a4;
    unint64_t v24 = v22 + 1;
    goto LABEL_33;
  }
  uint64_t v25 = v21[3];
  uint64_t v26 = ((uint64_t)v22 - v25) >> 3;
  if ((unint64_t)(v26 + 1) >> 61) {
LABEL_34:
  }
    std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
  uint64_t v27 = v23 - v25;
  uint64_t v28 = v27 >> 2;
  if (v27 >> 2 <= (unint64_t)(v26 + 1)) {
    uint64_t v28 = v26 + 1;
  }
  if ((unint64_t)v27 >= 0x7FFFFFFFFFFFFFF8) {
    unint64_t v29 = 0x1FFFFFFFFFFFFFFFLL;
  }
  else {
    unint64_t v29 = v28;
  }
  if (v29) {
    uint64_t v30 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)(v21 + 5), v29);
  }
  else {
    uint64_t v30 = 0;
  }
  uint64_t v31 = &v30[8 * v26];
  uint64_t v32 = &v30[8 * v29];
  *(void *)uint64_t v31 = a4;
  unint64_t v24 = v31 + 8;
  uint64_t v34 = (char *)v21[3];
  int v33 = (char *)v21[4];
  if (v33 != v34)
  {
    do
    {
      uint64_t v35 = *((void *)v33 - 1);
      v33 -= 8;
      *((void *)v31 - 1) = v35;
      v31 -= 8;
    }
    while (v33 != v34);
    int v33 = (char *)v21[3];
  }
  v21[3] = v31;
  v21[4] = v24;
  void v21[5] = v32;
  if (v33) {
    operator delete(v33);
  }
LABEL_33:
  v21[4] = v24;
  uint64_t v36 = (uint64_t **)((char *)this + 120);
  std::__tree<ZinIrTensor *>::__emplace_unique_key_args<ZinIrTensor *,ZinIrTensor * const&>(v36, &v39, (uint64_t *)&v39);
  return std::__tree<ZinIrTensor *>::__emplace_unique_key_args<ZinIrTensor *,ZinIrTensor * const&>(v36, (unint64_t *)&v38, &v38);
}

uint64_t *ZinMirL2HazardAnalysis::SymbolTimeEventTable::AddSymbol(ZinMirL2HazardAnalysis::SymbolTimeEventTable *this, ZinIrSymbol *a2)
{
  unint64_t v4 = a2;
  uint64_t result = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(this, &v4);
  if (!result)
  {
    std::__hash_table<ZinIrTensor const*,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const* const&>((uint64_t)this, &v4, &v4);
    return ZinMirL2HazardAnalysis::SymbolEventTable::AddSymbolToEventTable(this, *((void *)v4 + 24), *((void *)v4 + 25), v4);
  }
  return result;
}

void *ZinMirL2HazardAnalysis::SymbolSpaceEventTable::AddSymbol(ZinMirL2HazardAnalysis::SymbolSpaceEventTable *this, ZinIrSymbol *a2, char a3)
{
  unint64_t v8 = a2;
  uint64_t result = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(this, &v8);
  if (!result)
  {
    std::__hash_table<ZinIrTensor const*,std::hash<ZinIrTensor const*>,std::equal_to<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const* const&>((uint64_t)this, &v8, &v8);
    ZinIrSymbol::GetSpaceRanges(v8, a3, v7);
    for (uint64_t i = (uint64_t *)v7[1]; i != v7; uint64_t i = (uint64_t *)i[1])
      ZinMirL2HazardAnalysis::SymbolEventTable::AddSymbolToEventTable(this, i[2], i[3], v8);
    return std::__list_imp<ZinIrSection *>::clear(v7);
  }
  return result;
}

void sub_21138FC98(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
}

void *ZinMirL2HazardAnalysis::SymbolEventTable::GetBeginSymbols@<X0>(ZinMirL2HazardAnalysis::SymbolEventTable *this@<X0>, unint64_t a2@<X1>, void *a3@<X8>)
{
  unint64_t v5 = a2;
  uint64_t result = std::__hash_table<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::__unordered_map_hasher<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::hash<long>,std::equal_to<long>,true>,std::__unordered_map_equal<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::equal_to<long>,std::hash<long>,true>,std::allocator<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>>>::find<long>((void *)this + 5, &v5);
  *a3 = 0;
  a3[1] = 0;
  a3[2] = 0;
  if (result) {
    return std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(a3, (const void *)result[3], result[4], (uint64_t)(result[4] - result[3]) >> 3);
  }
  return result;
}

void *ZinMirL2HazardAnalysis::SymbolEventTable::GetEndSymbols@<X0>(ZinMirL2HazardAnalysis::SymbolEventTable *this@<X0>, unint64_t a2@<X1>, void *a3@<X8>)
{
  unint64_t v5 = a2;
  uint64_t result = std::__hash_table<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::__unordered_map_hasher<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::hash<long>,std::equal_to<long>,true>,std::__unordered_map_equal<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::equal_to<long>,std::hash<long>,true>,std::allocator<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>>>::find<long>((void *)this + 10, &v5);
  *a3 = 0;
  a3[1] = 0;
  a3[2] = 0;
  if (result) {
    return std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(a3, (const void *)result[3], result[4], (uint64_t)(result[4] - result[3]) >> 3);
  }
  return result;
}

void ZinMirL2HazardAnalysis::ZinMirL2HazardAnalysis()
{
}

void sub_211390074(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, void *__p, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15)
{
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table(v18);
  a15 = a9;
  std::vector<std::vector<std::vector<ZinKernelPosition>>>::__destroy_vector::operator()[abi:ne180100]((void ***)&a15);
  std::__hash_table<std::__hash_value_type<unsigned long,std::vector<std::shared_ptr<MirOpt::ZinReassignEngine>>>,std::__unordered_map_hasher<unsigned long,std::__hash_value_type<unsigned long,std::vector<std::shared_ptr<MirOpt::ZinReassignEngine>>>,std::hash<unsigned long>,std::equal_to<unsigned long>,true>,std::__unordered_map_equal<unsigned long,std::__hash_value_type<unsigned long,std::vector<std::shared_ptr<MirOpt::ZinReassignEngine>>>,std::equal_to<unsigned long>,std::hash<unsigned long>,true>,std::allocator<std::__hash_value_type<unsigned long,std::vector<std::shared_ptr<MirOpt::ZinReassignEngine>>>>>::~__hash_table((uint64_t)v17 + 152);
  ZinMirL2HazardAnalysis::SymbolSpaceEventTable::~SymbolSpaceEventTable(v17);
  ZinMirL2HazardAnalysis::SymbolSpaceEventTable::~SymbolSpaceEventTable(v16);
  std::unique_ptr<ZinIrHazardGraph>::reset[abi:ne180100](v15, 0);
  _Unwind_Resume(a1);
}

void ZinMirL2HazardAnalysis::SymbolSpaceEventTable::~SymbolSpaceEventTable(ZinMirL2HazardAnalysis::SymbolSpaceEventTable *this)
{
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)this + 120, *((void **)this + 16));
  std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::~__hash_table((uint64_t)this + 80);
  std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::~__hash_table((uint64_t)this + 40);

  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)this);
}

void ZinMirL2HazardAnalysis::~ZinMirL2HazardAnalysis(ZinMirL2HazardAnalysis *this)
{
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)this + 408);
  unint64_t v2 = (void **)((char *)this + 384);
  std::vector<std::vector<std::vector<ZinKernelPosition>>>::__destroy_vector::operator()[abi:ne180100](&v2);
  std::__hash_table<std::__hash_value_type<unsigned long,std::vector<std::shared_ptr<MirOpt::ZinReassignEngine>>>,std::__unordered_map_hasher<unsigned long,std::__hash_value_type<unsigned long,std::vector<std::shared_ptr<MirOpt::ZinReassignEngine>>>,std::hash<unsigned long>,std::equal_to<unsigned long>,true>,std::__unordered_map_equal<unsigned long,std::__hash_value_type<unsigned long,std::vector<std::shared_ptr<MirOpt::ZinReassignEngine>>>,std::equal_to<unsigned long>,std::hash<unsigned long>,true>,std::allocator<std::__hash_value_type<unsigned long,std::vector<std::shared_ptr<MirOpt::ZinReassignEngine>>>>>::~__hash_table((uint64_t)this + 328);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)this + 296, *((void **)this + 38));
  std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::~__hash_table((uint64_t)this + 256);
  std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::~__hash_table((uint64_t)this + 216);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)this + 176);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)this + 152, *((void **)this + 20));
  std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::~__hash_table((uint64_t)this + 112);
  std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::~__hash_table((uint64_t)this + 72);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)this + 32);
  std::unique_ptr<ZinIrHazardGraph>::reset[abi:ne180100]((ZinIrHazardGraph **)this, 0);
}

uint64_t ZinMirL2HazardAnalysis::Run(ZinMirL2HazardAnalysis *this)
{
  return 0;
}

void ZinMirL2HazardAnalysis::CreateHazardNodes(ZinMirL2HazardAnalysis *this)
{
  *(void *)((char *)&v128[1] + 4) = *MEMORY[0x263EF8340];
  memset(v123, 0, sizeof(v123));
  memset(v122, 0, sizeof(v122));
  memset(v121, 0, sizeof(v121));
  memset(v120, 0, sizeof(v120));
  uint64_t v1 = **((void **)this + 3);
  if (*(int *)(v1 + 4) < 1)
  {
    unint64_t v4 = 0;
    uint64_t v76 = 0;
    goto LABEL_167;
  }
  uint64_t v3 = 0;
  uint64_t v75 = 0;
  uint64_t v76 = 0;
  uint64_t v73 = 0;
  uint64_t v74 = 0;
  unint64_t v4 = 0;
  unint64_t v5 = 0;
  uint64_t v80 = (ZinMirL2HazardAnalysis *)((char *)this + 176);
  uint64_t v81 = (ZinMirL2HazardAnalysis *)((char *)this + 32);
  int8x8_t v6 = (void *)((char *)this + 408);
  uint64_t v83 = (char *)this + 328;
  uint64_t v84 = (char *)this + 408;
  do
  {
    uint64_t v70 = v3;
    long long v7 = (uint64_t *)(*((void *)this + 48) + 24 * v3);
    uint64_t v8 = *v7;
    uint64_t v71 = v7[1];
    if (*v7 == v71) {
      goto LABEL_161;
    }
    do
    {
      std::string __p = 0;
      uint64_t v118 = 0;
      uint64_t v119 = 0;
      uint64_t v72 = v8;
      std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(&__p, *(const void **)v8, *(void *)(v8 + 8), (uint64_t)(*(void *)(v8 + 8) - *(void *)v8) >> 3);
      uint64_t v9 = (ZinANELayer **)__p;
      uint64_t v77 = v118;
      if (__p == v118) {
        goto LABEL_157;
      }
      do
      {
        uint64_t v116 = 0;
        uint64_t v78 = v9;
        uint64_t v10 = *v9;
        uint64_t v115 = 0;
        uint64_t v116 = v10;
        uint64_t v113 = 0;
        BOOL v114 = 0;
        uint64_t v110 = 0;
        uint64_t v111 = 0;
        uint64_t v112 = 0;
        uint64_t v11 = *((void *)v10 + 11);
        BOOL v82 = v5;
        if (*((void *)v10 + 12) != v11)
        {
          unint64_t v12 = 0;
          do
          {
            uint64_t v13 = (*(uint64_t (**)(void, void, void))(**(void **)(v11 + 8 * v12) + 32))(*(void *)(v11 + 8 * v12), 0, 0);
            if (((*(uint64_t (**)(ZinANELayer *, uint64_t))(*(void *)v116 + 200))(v116, v13) & 1) == 0)
            {
              unsigned int v109 = 0;
              uint64_t v108 = 0;
              int v107 = 0;
              if (ZinMemSourceIndexTranslator::GetL2SrcType(v116, v12, &v107)
                && os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR))
              {
                ZinMirL2HazardAnalysis::CreateHazardNodes(buf, (uint64_t)&v116, v128);
              }
              L2RdSymbol = (ZinIrSymbol *)ZinEngineLayerMirInfo::GetL2RdSymbol(*((void *)v116 + 33), v107);
              uint64_t v108 = L2RdSymbol;
              switch(v107)
              {
                case 2:
                  unsigned int v109 = 2;
                  break;
                case 1:
                  unsigned int v109 = 1;
                  break;
                case 0:
                  unsigned int v109 = 0;
                  break;
              }
              ZinMirL2HazardAnalysis::SymbolTimeEventTable::AddSymbol(v81, L2RdSymbol);
              ZinMirL2HazardAnalysis::SymbolSpaceEventTable::AddSymbol(v80, L2RdSymbol, 1);
              LODWORD(v103) = 0;
              uint64_t v15 = *((void *)this + 46);
              *((void *)this + 46) = v15 + 1;
              *(void *)&long long v125 = v15;
              std::allocate_shared[abi:ne180100]<ZinIrHazardNode,std::allocator<ZinIrHazardNode>,ZinIrSymbol *&,ZinANELayer *&,ZinIrHazardNode::OperandType &,ZinIrHazardNode::ExecutionType,long,void>(&v108, &v116, &v109, (unsigned int *)&v103, &v125, &v106);
              ZinIrNgraph<std::shared_ptr<ZinIrHazardNode>,HazardNodeCompare>::AddNode(*(uint64_t ***)this, (uint64_t *)&v106);
              ZinMirL2HazardAnalysis::UpdateSymbolToHazardNodeMap((uint64_t)this, (uint64_t)v108, &v106);
              LODWORD(v103) = 1;
              uint64_t v16 = *((void *)this + 46);
              *((void *)this + 46) = v16 + 1;
              *(void *)&long long v125 = v16;
              std::allocate_shared[abi:ne180100]<ZinIrHazardNode,std::allocator<ZinIrHazardNode>,ZinIrSymbol *&,ZinANELayer *&,ZinIrHazardNode::OperandType &,ZinIrHazardNode::ExecutionType,long,void>(&v108, &v116, &v109, (unsigned int *)&v103, &v125, &v105);
              ZinIrNgraph<std::shared_ptr<ZinIrHazardNode>,HazardNodeCompare>::AddNode(*(uint64_t ***)this, (uint64_t *)&v105);
              ZinMirL2HazardAnalysis::UpdateSymbolToHazardNodeMap((uint64_t)this, (uint64_t)v108, &v105);
              std::vector<std::shared_ptr<ZinIrHazardNode>>::push_back[abi:ne180100]((uint64_t *)&v113, &v106);
              std::vector<std::shared_ptr<ZinIrHazardNode>>::push_back[abi:ne180100]((uint64_t *)&v110, &v105);
              ZinIrOpLayerGraphUtil::FindAllBottomANELayers(v116, (void **)&v125);
              uint64_t v19 = (ZinBondedUtils **)*((void *)&v125 + 1);
              uint64_t v18 = (ZinBondedUtils **)v125;
              if ((void)v125 != *((void *)&v125 + 1))
              {
                while (1)
                {
                  uint64_t v20 = *v18;
                  if (!ZinBondedUtils::AreAssignedToSameANE(*v18, v116, v17)) {
                    goto LABEL_42;
                  }
                  *(void *)&long long v103 = (*(uint64_t (**)(ZinBondedUtils *, void, void))(*(void *)v20 + 32))(v20, 0, 0);
                  if (std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(v6, &v103))
                  {
                    goto LABEL_42;
                  }
                  uint64_t L2WrSymbol = ZinEngineLayerMirInfo::GetL2WrSymbol(*((ZinEngineLayerMirInfo **)v20 + 33));
                  p_uint64_t L2WrSymbol = (long long *)&L2WrSymbol;
                  unint64_t v21 = std::__hash_table<std::__hash_value_type<ZinIrOpLayerGraph *,std::vector<std::shared_ptr<ZinPattern>>>,std::__unordered_map_hasher<ZinIrOpLayerGraph *,std::__hash_value_type<ZinIrOpLayerGraph *,std::vector<std::shared_ptr<ZinPattern>>>,std::hash<ZinIrOpLayerGraph *>,std::equal_to<ZinIrOpLayerGraph *>,true>,std::__unordered_map_equal<ZinIrOpLayerGraph *,std::__hash_value_type<ZinIrOpLayerGraph *,std::vector<std::shared_ptr<ZinPattern>>>,std::equal_to<ZinIrOpLayerGraph *>,std::hash<ZinIrOpLayerGraph *>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayerGraph *,std::vector<std::shared_ptr<ZinPattern>>>>>::__emplace_unique_key_args<ZinIrOpLayerGraph *,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayerGraph * const&>,std::tuple<>>((uint64_t)v83, &L2WrSymbol, (uint64_t)&std::piecewise_construct, (void **)&p_L2WrSymbol);
                  uint64_t v104 = 0;
                  long long v103 = 0uLL;
                  std::vector<std::shared_ptr<ZinIrHazardNode>>::__init_with_size[abi:ne180100]<std::shared_ptr<ZinIrHazardNode>*,std::shared_ptr<ZinIrHazardNode>*>(&v103, (void *)v21[3], (void *)v21[4], (uint64_t)(v21[4] - v21[3]) >> 4);
                  unint64_t v23 = (uint64_t *)*((void *)&v103 + 1);
                  uint64_t v22 = (uint64_t *)v103;
                  if ((void)v103 == *((void *)&v103 + 1)) {
                    goto LABEL_32;
                  }
                  do
                  {
                    uint64_t v25 = *v22;
                    unint64_t v24 = (std::__shared_weak_count *)v22[1];
                    if (v24) {
                      atomic_fetch_add_explicit(&v24->__shared_owners_, 1uLL, memory_order_relaxed);
                    }
                    if (*(_DWORD *)(v25 + 20) != 1 || *(_DWORD *)(v25 + 16) != 3)
                    {
                      BOOL v26 = 0;
                      if (!v24) {
                        goto LABEL_29;
                      }
LABEL_28:
                      std::__shared_weak_count::__release_shared[abi:ne180100](v24);
                      goto LABEL_29;
                    }
                    BOOL v26 = *(void *)v25 == (void)v20;
                    if (v24) {
                      goto LABEL_28;
                    }
LABEL_29:
                    if (v26) {
                      goto LABEL_32;
                    }
                    v22 += 2;
                  }
                  while (v22 != v23);
                  uint64_t v22 = v23;
LABEL_32:
                  uint64_t v27 = v108;
                  uint64_t v28 = (const ZinIrSymbol *)ZinEngineLayerMirInfo::GetL2WrSymbol(*((ZinEngineLayerMirInfo **)v20 + 33));
                  if (ZinIrSymbol::SpaceContains(v27, v28))
                  {
                    unint64_t v29 = *(void **)this;
                    uint64_t v30 = (std::__shared_weak_count *)v22[1];
                    uint64_t v100 = *v22;
                    uint64_t v101 = v30;
                    if (v30) {
                      atomic_fetch_add_explicit(&v30->__shared_owners_, 1uLL, memory_order_relaxed);
                    }
                    long long v99 = v105;
                    if (*((void *)&v105 + 1)) {
                      atomic_fetch_add_explicit((atomic_ullong *volatile)(*((void *)&v105 + 1) + 8), 1uLL, memory_order_relaxed);
                    }
                    ZinIrHazardGraph::AddInvariantEdge((uint64_t)v29, &v100, (uint64_t *)&v99);
                    if (*((void *)&v99 + 1)) {
                      std::__shared_weak_count::__release_shared[abi:ne180100](*((std::__shared_weak_count **)&v99 + 1));
                    }
                    if (v101) {
                      std::__shared_weak_count::__release_shared[abi:ne180100](v101);
                    }
                  }
                  p_uint64_t L2WrSymbol = &v103;
                  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100]((void ***)&p_L2WrSymbol);
                  int8x8_t v6 = v84;
LABEL_42:
                  if (++v18 == v19)
                  {
                    uint64_t v18 = (ZinBondedUtils **)v125;
                    break;
                  }
                }
              }
              if (v18)
              {
                *((void *)&v125 + 1) = v18;
                operator delete(v18);
              }
              unint64_t v5 = v82;
              if (*((void *)&v105 + 1)) {
                std::__shared_weak_count::__release_shared[abi:ne180100](*((std::__shared_weak_count **)&v105 + 1));
              }
              if (*((void *)&v106 + 1)) {
                std::__shared_weak_count::__release_shared[abi:ne180100](*((std::__shared_weak_count **)&v106 + 1));
              }
            }
            ++v12;
            uint64_t v10 = v116;
            uint64_t v11 = *((void *)v116 + 11);
          }
          while (v12 < (*((void *)v116 + 12) - v11) >> 3);
        }
        *(void *)&long long v106 = 0;
        uint64_t v31 = (ZinIrSymbol *)ZinEngineLayerMirInfo::GetL2WrSymbol(*((ZinEngineLayerMirInfo **)v10 + 33));
        *(void *)&long long v106 = v31;
        uint64_t v79 = v4;
        if (*(unsigned char *)(*(void *)(*((void *)this + 3) + 8) + 526))
        {
          uint64_t v32 = (uint64_t *)*((void *)v116 + 14);
          int v33 = (uint64_t *)*((void *)v116 + 15);
          if (v32 == v33)
          {
            char v54 = 1;
          }
          else
          {
            do
            {
              uint64_t v34 = *v32;
              if (*(_DWORD *)(*(void *)(*v32 + 64) + 8) == 7)
              {
                uint64_t v35 = *(void *)(v34 + 88);
                uint64_t v36 = *(void *)(v34 + 96);
                if (v36 != v35 && v36 - v35 == 16)
                {
                  uint64_t v38 = v35 + 8;
                  do
                  {
                    unint64_t v39 = *(ZinIrOpLayer **)(v38 - 8);
                    long long v125 = 0uLL;
                    uint64_t v126 = 0;
                    int IsNoOp = ZinIrOpLayer::IsNoOp(v39, (uint64_t *)&v125);
                    if ((void)v125)
                    {
                      *((void *)&v125 + 1) = v125;
                      operator delete((void *)v125);
                    }
                    if (v38 == v36) {
                      int v41 = 1;
                    }
                    else {
                      int v41 = IsNoOp;
                    }
                    v38 += 8;
                  }
                  while (v41 != 1);
                  uint64_t v42 = *(void *)(v34 + 88);
                  uint64_t v43 = *(void *)(v34 + 96);
                  if (v42 != v43)
                  {
                    uint64_t v44 = v42 + 8;
                    uint64_t v45 = v42 + 8;
                    do
                    {
                      unint64_t v46 = *(void *)(*(void *)(v45 - 8) + 120) - *(void *)(*(void *)(v45 - 8) + 112);
                      BOOL v47 = v46 > 8 || v45 == v43;
                      v45 += 8;
                    }
                    while (!v47);
                    do
                    {
                      BOOL IsNELayer = ZinIrOpLayer::IsNELayer(*(ZinIrOpLayer **)(v44 - 8));
                      BOOL v49 = IsNELayer;
                      BOOL v50 = v44 != v43 && IsNELayer;
                      v44 += 8;
                    }
                    while (v50);
                    uint64_t v52 = *(ZinIrOpLayer ***)(v34 + 88);
                    long long v51 = *(ZinIrOpLayer ***)(v34 + 96);
                    while (v52 != v51)
                    {
                      if (!ZinIrOpLayer::IsPELayer(*v52))
                      {
                        if (v46 > 8) {
                          int v53 = 1;
                        }
                        else {
                          int v53 = IsNoOp;
                        }
                        if ((v53 | v49) != 1)
                        {
                          char v54 = 0;
                          goto LABEL_87;
                        }
                        break;
                      }
                      ++v52;
                    }
                  }
                }
              }
              ++v32;
            }
            while (v32 != v33);
            char v54 = 1;
LABEL_87:
            uint64_t v31 = (ZinIrSymbol *)v106;
            unint64_t v4 = v79;
          }
          unint64_t v5 = v82;
        }
        else
        {
          char v54 = 1;
        }
        ZinMirL2HazardAnalysis::SymbolTimeEventTable::AddSymbol(v81, v31);
        ZinMirL2HazardAnalysis::SymbolSpaceEventTable::AddSymbol(v80, v31, v54);
        LODWORD(v105) = 3;
        LODWORD(p_L2WrSymbol) = 0;
        uint64_t v55 = *((void *)this + 46);
        *((void *)this + 46) = v55 + 1;
        *(void *)&long long v103 = v55;
        std::allocate_shared[abi:ne180100]<ZinIrHazardNode,std::allocator<ZinIrHazardNode>,ZinIrSymbol *&,ZinANELayer *&,ZinIrHazardNode::OperandType,ZinIrHazardNode::ExecutionType,long,void>(&v106, &v116, (unsigned int *)&v105, (unsigned int *)&p_L2WrSymbol, &v103, &v125);
        ZinIrNgraph<std::shared_ptr<ZinIrHazardNode>,HazardNodeCompare>::AddNode(*(uint64_t ***)this, (uint64_t *)&v125);
        ZinMirL2HazardAnalysis::UpdateSymbolToHazardNodeMap((uint64_t)this, v106, &v125);
        LODWORD(p_L2WrSymbol) = 3;
        LODWORD(v108) = 1;
        uint64_t v56 = *((void *)this + 46);
        *((void *)this + 46) = v56 + 1;
        *(void *)&long long v105 = v56;
        std::allocate_shared[abi:ne180100]<ZinIrHazardNode,std::allocator<ZinIrHazardNode>,ZinIrSymbol *&,ZinANELayer *&,ZinIrHazardNode::OperandType,ZinIrHazardNode::ExecutionType,long,void>(&v106, &v116, (unsigned int *)&p_L2WrSymbol, (unsigned int *)&v108, &v105, &v103);
        ZinIrNgraph<std::shared_ptr<ZinIrHazardNode>,HazardNodeCompare>::AddNode(*(uint64_t ***)this, (uint64_t *)&v103);
        ZinMirL2HazardAnalysis::UpdateSymbolToHazardNodeMap((uint64_t)this, v106, &v103);
        uint64_t v57 = (std::__shared_weak_count *)*((void *)&v125 + 1);
        long long v98 = v125;
        if (*((void *)&v125 + 1)) {
          atomic_fetch_add_explicit((atomic_ullong *volatile)(*((void *)&v125 + 1) + 8), 1uLL, memory_order_relaxed);
        }
        unsigned __int8 v58 = (std::__shared_weak_count *)*((void *)&v103 + 1);
        long long v97 = v103;
        if (*((void *)&v103 + 1)) {
          atomic_fetch_add_explicit((atomic_ullong *volatile)(*((void *)&v103 + 1) + 8), 1uLL, memory_order_relaxed);
        }
        ZinMirL2HazardAnalysis::CreateIntraEngineInvariantEdges((uint64_t *)this, (uint64_t *)&v113, &v110, (uint64_t *)&v98, (uint64_t *)&v97);
        if (v58) {
          std::__shared_weak_count::__release_shared[abi:ne180100](v58);
        }
        if (v57) {
          std::__shared_weak_count::__release_shared[abi:ne180100](v57);
        }
        if (ZinIrOpLayer::IsNELayer(v116))
        {
          if (*(unsigned char *)(**((void **)this + 3) + 1104))
          {
            uint64_t v95 = v74;
            uint64_t v96 = v4;
            if (v4) {
              atomic_fetch_add_explicit(&v4->__shared_owners_, 1uLL, memory_order_relaxed);
            }
            uint64_t v59 = (std::__shared_weak_count *)*((void *)&v125 + 1);
            long long v94 = v125;
            if (*((void *)&v125 + 1)) {
              atomic_fetch_add_explicit((atomic_ullong *volatile)(*((void *)&v125 + 1) + 8), 1uLL, memory_order_relaxed);
            }
            ZinMirL2HazardAnalysis::CreateInterEngineInvariantEdges((uint64_t *)this, v122, &v113, &v95, (uint64_t *)&v94);
            if (v59) {
              std::__shared_weak_count::__release_shared[abi:ne180100](v59);
            }
            uint64_t v60 = v96;
            if (v96) {
              goto LABEL_108;
            }
          }
          else
          {
            uint64_t v92 = v74;
            uint64_t v93 = v4;
            if (v4) {
              atomic_fetch_add_explicit(&v4->__shared_owners_, 1uLL, memory_order_relaxed);
            }
            uint64_t v68 = (std::__shared_weak_count *)*((void *)&v125 + 1);
            long long v91 = v125;
            if (*((void *)&v125 + 1)) {
              atomic_fetch_add_explicit((atomic_ullong *volatile)(*((void *)&v125 + 1) + 8), 1uLL, memory_order_relaxed);
            }
            ZinMirL2HazardAnalysis::CreateInterEngineInvariantEdges((uint64_t *)this, v123, &v113, &v92, (uint64_t *)&v91);
            if (v68) {
              std::__shared_weak_count::__release_shared[abi:ne180100](v68);
            }
            uint64_t v60 = v93;
            if (v93) {
LABEL_108:
            }
              std::__shared_weak_count::__release_shared[abi:ne180100](v60);
          }
          std::vector<std::shared_ptr<ZinIrHazardNode>>::__assign_with_size[abi:ne180100]<std::shared_ptr<ZinIrHazardNode>*,std::shared_ptr<ZinIrHazardNode>*>((uint64_t)v123, v113, v114, ((char *)v114 - (char *)v113) >> 4);
          std::vector<std::shared_ptr<ZinIrHazardNode>>::__assign_with_size[abi:ne180100]<std::shared_ptr<ZinIrHazardNode>*,std::shared_ptr<ZinIrHazardNode>*>((uint64_t)v122, v110, v111, ((char *)v111 - (char *)v110) >> 4);
          char v61 = (std::__shared_weak_count *)*((void *)&v125 + 1);
          if (*((void *)&v125 + 1)) {
            atomic_fetch_add_explicit((atomic_ullong *volatile)(*((void *)&v125 + 1) + 8), 1uLL, memory_order_relaxed);
          }
          if (v76) {
            std::__shared_weak_count::__release_shared[abi:ne180100](v76);
          }
          uint64_t v62 = (std::__shared_weak_count *)*((void *)&v103 + 1);
          uint64_t v74 = v103;
          if (*((void *)&v103 + 1)) {
            atomic_fetch_add_explicit((atomic_ullong *volatile)(*((void *)&v103 + 1) + 8), 1uLL, memory_order_relaxed);
          }
          uint64_t v63 = v4;
          uint64_t v64 = v5;
          uint64_t v76 = v61;
          if (v4) {
            goto LABEL_133;
          }
          goto LABEL_134;
        }
        if (*(unsigned char *)(**((void **)this + 3) + 1104))
        {
          uint64_t v89 = v73;
          BOOL v90 = v5;
          if (v5) {
            atomic_fetch_add_explicit(&v5->__shared_owners_, 1uLL, memory_order_relaxed);
          }
          char v65 = (std::__shared_weak_count *)*((void *)&v125 + 1);
          long long v88 = v125;
          if (*((void *)&v125 + 1)) {
            atomic_fetch_add_explicit((atomic_ullong *volatile)(*((void *)&v125 + 1) + 8), 1uLL, memory_order_relaxed);
          }
          ZinMirL2HazardAnalysis::CreateInterEngineInvariantEdges((uint64_t *)this, v120, &v113, &v89, (uint64_t *)&v88);
          if (v65) {
            std::__shared_weak_count::__release_shared[abi:ne180100](v65);
          }
          uint64_t v66 = v90;
          if (v90) {
            goto LABEL_125;
          }
        }
        else
        {
          uint64_t v86 = v73;
          uint64_t v87 = v5;
          if (v5) {
            atomic_fetch_add_explicit(&v5->__shared_owners_, 1uLL, memory_order_relaxed);
          }
          uint64_t v69 = (std::__shared_weak_count *)*((void *)&v125 + 1);
          long long v85 = v125;
          if (*((void *)&v125 + 1)) {
            atomic_fetch_add_explicit((atomic_ullong *volatile)(*((void *)&v125 + 1) + 8), 1uLL, memory_order_relaxed);
          }
          ZinMirL2HazardAnalysis::CreateInterEngineInvariantEdges((uint64_t *)this, v121, &v113, &v86, (uint64_t *)&v85);
          if (v69) {
            std::__shared_weak_count::__release_shared[abi:ne180100](v69);
          }
          uint64_t v66 = v87;
          if (v87) {
LABEL_125:
          }
            std::__shared_weak_count::__release_shared[abi:ne180100](v66);
        }
        std::vector<std::shared_ptr<ZinIrHazardNode>>::__assign_with_size[abi:ne180100]<std::shared_ptr<ZinIrHazardNode>*,std::shared_ptr<ZinIrHazardNode>*>((uint64_t)v121, v113, v114, ((char *)v114 - (char *)v113) >> 4);
        std::vector<std::shared_ptr<ZinIrHazardNode>>::__assign_with_size[abi:ne180100]<std::shared_ptr<ZinIrHazardNode>*,std::shared_ptr<ZinIrHazardNode>*>((uint64_t)v120, v110, v111, ((char *)v111 - (char *)v110) >> 4);
        uint64_t v67 = (std::__shared_weak_count *)*((void *)&v125 + 1);
        if (*((void *)&v125 + 1)) {
          atomic_fetch_add_explicit((atomic_ullong *volatile)(*((void *)&v125 + 1) + 8), 1uLL, memory_order_relaxed);
        }
        if (v75) {
          std::__shared_weak_count::__release_shared[abi:ne180100](v75);
        }
        uint64_t v64 = (std::__shared_weak_count *)*((void *)&v103 + 1);
        uint64_t v73 = v103;
        if (*((void *)&v103 + 1)) {
          atomic_fetch_add_explicit((atomic_ullong *volatile)(*((void *)&v103 + 1) + 8), 1uLL, memory_order_relaxed);
        }
        uint64_t v63 = v5;
        uint64_t v75 = v67;
        uint64_t v62 = v4;
        if (v5) {
LABEL_133:
        }
          std::__shared_weak_count::__release_shared[abi:ne180100](v63);
LABEL_134:
        int8x8_t v6 = v84;
        if (*((void *)&v103 + 1)) {
          std::__shared_weak_count::__release_shared[abi:ne180100](*((std::__shared_weak_count **)&v103 + 1));
        }
        if (*((void *)&v125 + 1)) {
          std::__shared_weak_count::__release_shared[abi:ne180100](*((std::__shared_weak_count **)&v125 + 1));
        }
        *(void *)&long long v125 = &v110;
        std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v125);
        *(void *)&long long v125 = &v113;
        std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v125);
        uint64_t v9 = v78 + 1;
        unint64_t v4 = v62;
        unint64_t v5 = v64;
      }
      while (v78 + 1 != v77);
      uint64_t v9 = (ZinANELayer **)__p;
      unint64_t v5 = v64;
      unint64_t v4 = v62;
LABEL_157:
      if (v9)
      {
        uint64_t v118 = v9;
        operator delete(v9);
      }
      uint64_t v8 = v72 + 24;
    }
    while (v72 + 24 != v71);
    uint64_t v1 = **((void **)this + 3);
LABEL_161:
    uint64_t v3 = v70 + 1;
  }
  while (v70 + 1 < *(int *)(v1 + 4));
  if (v5) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v5);
  }
  if (v75) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v75);
  }
LABEL_167:
  *(void *)&long long v125 = v120;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v125);
  *(void *)&long long v125 = v121;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v125);
  if (v4) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v4);
  }
  if (v76) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v76);
  }
  *(void *)&long long v125 = v122;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v125);
  *(void *)&long long v125 = v123;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v125);
}

void sub_211390D74(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, std::__shared_weak_count *a15)
{
  uint64_t v19 = (std::__shared_weak_count *)a14;
  if (v15)
  {
    std::__shared_weak_count::__release_shared[abi:ne180100](v15);
    uint64_t v19 = (std::__shared_weak_count *)a14;
  }
  if (v19) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v19);
  }
  *(void *)(v17 - 136) = v17 - 248;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100]((void ***)(v17 - 136));
  *(void *)(v17 - 136) = v17 - 224;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100]((void ***)(v17 - 136));
  if (v16) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v16);
  }
  if (a15) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a15);
  }
  *(void *)(v17 - 136) = v17 - 200;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100]((void ***)(v17 - 136));
  *(void *)(v17 - 136) = v17 - 176;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100]((void ***)(v17 - 136));
  _Unwind_Resume(a1);
}

void ZinMirL2HazardAnalysis::CreateHazardEdges(ZinMirL2HazardAnalysis *this)
{
  v19[0] = 0;
  v19[1] = 0;
  uint64_t v18 = v19;
  uint64_t v1 = (char *)*((void *)this + 37);
  unint64_t v2 = (char *)this + 304;
  if (v1 == (char *)this + 304)
  {
    uint64_t v13 = 0;
  }
  else
  {
    unint64_t v4 = (ZinMirL2HazardAnalysis *)((char *)this + 176);
    do
    {
      unint64_t v5 = *((void *)v1 + 4);
      ZinMirL2HazardAnalysis::SymbolEventTable::GetEndSymbols(v4, v5, &v16);
      int8x8_t v6 = (void **)v16;
      long long v7 = v17;
      while (v6 != v7)
      {
        std::string __p = 0;
        std::string __p = *v6;
        std::__tree<ZinIrSymbol const*,ZinIrSymbol::Compare,std::allocator<ZinIrSymbol const*>>::__erase_unique<ZinIrSymbol const*>(&v18, (uint64_t *)&__p);
        ++v6;
      }
      ZinMirL2HazardAnalysis::SymbolEventTable::GetBeginSymbols(v4, v5, &__p);
      uint64_t v8 = (uint64_t *)__p;
      uint64_t v9 = v15;
      while (v8 != v9)
      {
        std::__tree<ZinIrSymbol *,ZinIrSymbol::Compare,std::allocator<ZinIrSymbol *>>::__emplace_hint_unique_key_args<ZinIrSymbol *,ZinIrSymbol * const&>(&v18, v19, v8, v8);
        ++v8;
      }
      ZinMirL2HazardAnalysis::CreateHazardEdgesForLiveSymbols(this, &v18);
      if (__p)
      {
        uint64_t v15 = (uint64_t *)__p;
        operator delete(__p);
      }
      if (v16)
      {
        uint64_t v17 = (void **)v16;
        operator delete(v16);
      }
      uint64_t v10 = (char *)*((void *)v1 + 1);
      if (v10)
      {
        do
        {
          uint64_t v11 = v10;
          uint64_t v10 = *(char **)v10;
        }
        while (v10);
      }
      else
      {
        do
        {
          uint64_t v11 = (char *)*((void *)v1 + 2);
          BOOL v12 = *(void *)v11 == (void)v1;
          uint64_t v1 = v11;
        }
        while (!v12);
      }
      uint64_t v1 = v11;
    }
    while (v11 != v2);
    uint64_t v13 = (void *)v19[0];
  }
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v18, v13);
}

void sub_211391124(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *a10, uint64_t a11, uint64_t a12, void *__p, uint64_t a14, uint64_t a15, char a16, void *a17)
{
  if (__p) {
    operator delete(__p);
  }
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&a16, a17);
  _Unwind_Resume(a1);
}

void ZinMirL2HazardAnalysis::HandleL2Barriers(ZinMirL2HazardAnalysis *this)
{
  uint64_t v1 = **((void **)this + 3);
  if (*(int *)(v1 + 4) >= 1)
  {
    unint64_t v2 = this;
    uint64_t v3 = 0;
    uint64_t v4 = -1;
    do
    {
      uint64_t v35 = v3;
      unint64_t v5 = (uint64_t *)(*((void *)v2 + 48) + 24 * v3);
      uint64_t v6 = *v5;
      uint64_t v37 = v5[1];
      if (*v5 != v37)
      {
        do
        {
          unint64_t v46 = 0;
          BOOL v47 = 0;
          uint64_t v48 = 0;
          std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(&v46, *(const void **)v6, *(void *)(v6 + 8), (uint64_t)(*(void *)(v6 + 8) - *(void *)v6) >> 3);
          long long v7 = v46;
          uint64_t v8 = v47;
          if (v46 != v47)
          {
            do
            {
              uint64_t v9 = *(void *)v7;
              uint64_t v10 = *(_DWORD **)(*(void *)v7 + 264);
              if (v10[408] == 4)
              {
                uint64_t v11 = **(ZinEngineLayerMirInfo ****)(v9 + 112);
                if (ZinIrOpLayer::IsANELayer((ZinIrOpLayer *)v11)
                  && ZinBondedUtils::AreAssignedToSameANE((ZinBondedUtils *)v11, (const ZinANELayer *)v9, v12)
                  && ZinIrOpLayer::IsPELayer((ZinIrOpLayer *)v11)
                  && (*((unsigned int (**)(ZinEngineLayerMirInfo **))*v11 + 71))(v11))
                {
                  *(unsigned char *)(*(void *)(v9 + 264) + 344) = 1;
                  ZinMirL2HazardAnalysis::CreateL2BarrierEdges(v2, (ZinANELayer *)v9, v11);
                }
              }
              else
              {
                LODWORD(v41[0]) = 0;
                if ((ZinEngineLayerMirInfo::HasChainRead(v10, (int *)v41) & 1) == 0 && *(void *)(v9 + 360) != v4)
                {
                  FirstConsumerOnSameANE = ZinIrRegAllocUtil::GetFirstConsumerOnSameANE((ZinIrRegAllocUtil *)v9, v13);
                  if (FirstConsumerOnSameANE)
                  {
                    std::string __p = 0;
                    uint64_t v44 = 0;
                    uint64_t v45 = 0;
                    memset(v41, 0, sizeof(v41));
                    int v42 = 1065353216;
                    if (ZinMirL2HazardAnalysis::IsQualifiedForDependentMode((uint64_t)v2, (const ZinIrOpLayer *)v9, (uint64_t)FirstConsumerOnSameANE, (char **)&__p, (uint64_t)v41))
                    {
                      BOOL IsNELayer = ZinIrOpLayer::IsNELayer((ZinIrOpLayer *)v9);
                      if (IsNELayer != ZinIrOpLayer::IsNELayer(FirstConsumerOnSameANE)
                        || (BOOL v16 = ZinIrOpLayer::IsPELayer((ZinIrOpLayer *)v9),
                            v16 != ZinIrOpLayer::IsPELayer(FirstConsumerOnSameANE)))
                      {
                        if (ZinIrOpLayer::IsPELayer(FirstConsumerOnSameANE)
                          && (*(unsigned int (**)(ZinIrOpLayer *))(*(void *)FirstConsumerOnSameANE + 568))(FirstConsumerOnSameANE))
                        {
                          if (v44 == __p) {
                            ZinAssertImpl("It must have incoming index for L2-dep pair");
                          }
                          uint64_t L2RdSymbol = ZinEngineLayerMirInfo::GetL2RdSymbol(*((void *)FirstConsumerOnSameANE + 33), *(void *)__p != 1);
                          uint64_t v18 = ZinEngineLayerMirInfo::GetL2RdSymbol(*((void *)FirstConsumerOnSameANE + 33), 0);
                          BOOL v19 = v18 != ZinEngineLayerMirInfo::GetL2RdSymbol(*((void *)FirstConsumerOnSameANE + 33), 1)
                             && L2RdSymbol != ZinEngineLayerMirInfo::GetL2RdSymbol(*(void *)(v9 + 264), 0);
                          uint64_t v21 = *((void *)FirstConsumerOnSameANE + 11);
                          uint64_t v22 = *((void *)FirstConsumerOnSameANE + 12);
                          if (v21 == v22)
                          {
                            char v26 = 1;
                          }
                          else
                          {
                            uint64_t v23 = v21 + 8;
                            do
                            {
                              BOOL IsPELayer = ZinIrOpLayer::IsPELayer(*(ZinIrOpLayer **)(v23 - 8));
                              int v25 = v23 == v22 || IsPELayer;
                              v23 += 8;
                            }
                            while (v25 != 1);
                            char v26 = !IsPELayer;
                          }
                          char v20 = v19 & v26;
                        }
                        else
                        {
                          char v20 = 0;
                        }
                        uint64_t v27 = (unint64_t *)__p;
                        uint64_t v28 = v44;
                        while (v27 != v28)
                        {
                          unint64_t v40 = 0;
                          unint64_t v40 = *v27;
                          uint64_t v29 = *(void *)(*((void *)FirstConsumerOnSameANE + 11) + 8 * v40);
                          uint64_t v30 = (ZinIrTensor *)(*(uint64_t (**)(uint64_t, void, void))(*(void *)v29 + 32))(v29, 0, 0);
                          BOOL v49 = &v40;
                          uint64_t v31 = std::__hash_table<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::__unordered_map_hasher<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::hash<long>,std::equal_to<long>,true>,std::__unordered_map_equal<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::equal_to<long>,std::hash<long>,true>,std::allocator<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>>>::__emplace_unique_key_args<long,std::piecewise_construct_t const&,std::tuple<long const&>,std::tuple<>>((uint64_t)v41, &v40, (uint64_t)&std::piecewise_construct, &v49);
                          std::unordered_map<ZinDependencyOffsetDim,long>::unordered_map((uint64_t)v38, (uint64_t)(v31 + 3));
                          for (uint64_t i = v39; i; uint64_t i = (void *)*i)
                          {
                            BOOL v34 = *(_DWORD *)(*(void *)(*((void *)ZinIrTensor::GetRootTensor(v30) + 12) + 64) + 8) == 7
                               && i[3] > 0;
                            v20 |= v34;
                          }
                          std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v38);
                          ++v27;
                        }
                        unint64_t v2 = this;
                        if (v20)
                        {
                          *(unsigned char *)(*(void *)(v9 + 264) + 344) = 1;
                          ZinMirL2HazardAnalysis::CreateL2BarrierEdges(this, (ZinANELayer *)v9, (ZinEngineLayerMirInfo **)FirstConsumerOnSameANE);
                        }
                        uint64_t v4 = *((void *)FirstConsumerOnSameANE + 45);
                      }
                    }
                    std::__hash_table<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::__unordered_map_hasher<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::hash<long>,std::equal_to<long>,true>,std::__unordered_map_equal<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::equal_to<long>,std::hash<long>,true>,std::allocator<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>>>::~__hash_table((uint64_t)v41);
                    if (__p)
                    {
                      uint64_t v44 = (unint64_t *)__p;
                      operator delete(__p);
                    }
                  }
                }
              }
              v7 += 8;
            }
            while (v7 != v8);
            long long v7 = v46;
          }
          if (v7)
          {
            BOOL v47 = v7;
            operator delete(v7);
          }
          v6 += 24;
        }
        while (v6 != v37);
        uint64_t v1 = **((void **)v2 + 3);
      }
      uint64_t v3 = v35 + 1;
    }
    while (v35 + 1 < *(int *)(v1 + 4));
  }
}

void sub_2113915A4(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, char a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, char a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,void *__p,uint64_t a25)
{
  std::__hash_table<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::__unordered_map_hasher<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::hash<long>,std::equal_to<long>,true>,std::__unordered_map_equal<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::equal_to<long>,std::hash<long>,true>,std::allocator<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>>>::~__hash_table((uint64_t)&a19);
  if (__p)
  {
    a25 = (uint64_t)__p;
    operator delete(__p);
  }
  uint64_t v27 = *(void **)(v25 - 128);
  if (v27)
  {
    *(void *)(v25 - 12std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v27;
    operator delete(v27);
  }
  _Unwind_Resume(a1);
}

uint64_t ZinMirL2HazardAnalysis::SetL2Dependent(ZinMirL2HazardAnalysis *this)
{
  v81[0] = 0;
  v81[1] = 0;
  uint64_t v80 = (uint64_t *)v81;
  uint64_t v1 = *(void *)this + 8;
  unint64_t v2 = **(void ***)this;
  if (v2 != (void *)v1)
  {
    do
    {
      uint64_t v4 = (ZinANELayer ***)(v2 + 4);
      unint64_t v5 = *(void ***)this;
      uint64_t v6 = (void *)(*(void *)this + 64);
      uint64_t v67 = v2 + 4;
      long long v7 = std::__hash_table<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::__unordered_map_hasher<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::__unordered_map_equal<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>>>::find<std::reference_wrapper<ZinIrOpLayer * const>>(v6, (unint64_t **)&v67);
      uint64_t v8 = v5 + 13;
      if (v7) {
        uint64_t v8 = v7 + 3;
      }
      uint64_t v9 = (uint64_t **)*v8;
      uint64_t v10 = (uint64_t **)v8[1];
      while (v9 != v10)
      {
        uint64_t v11 = *v9;
        int v79 = 0;
        BOOL v12 = *(void **)this;
        uint64_t v13 = (std::__shared_weak_count *)v11[1];
        uint64_t v77 = *v11;
        uint64_t v78 = v13;
        if (v13) {
          atomic_fetch_add_explicit(&v13->__shared_owners_, 1uLL, memory_order_relaxed);
        }
        unint64_t v14 = (std::__shared_weak_count *)v2[5];
        uint64_t v75 = v2[4];
        uint64_t v76 = v14;
        if (v14) {
          atomic_fetch_add_explicit(&v14->__shared_owners_, 1uLL, memory_order_relaxed);
        }
        BOOL EdgeType = ZinIrHazardGraph::GetEdgeType((uint64_t)v12, (unint64_t *)&v77, &v75, &v79);
        BOOL v16 = v79 != 1 && EdgeType;
        if (v76) {
          std::__shared_weak_count::__release_shared[abi:ne180100](v76);
        }
        if (v78) {
          std::__shared_weak_count::__release_shared[abi:ne180100](v78);
        }
        if (!v16)
        {
          int v74 = 0;
          if ((ZinEngineLayerMirInfo::HasChainRead(*((_DWORD **)**v4 + 33), &v74) & 1) == 0
            && ZinMirL2HazardAnalysis::TryDependencyBitSet(this, *(ZinANELayer **)*v11, **v4))
          {
            uint64_t v67 = v11;
            uint64_t v17 = std::__tree<std::__value_type<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,std::__map_value_compare<std::shared_ptr<ZinIrHazardNode>,std::__value_type<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,std::less<std::shared_ptr<ZinIrHazardNode>>,true>,std::allocator<std::__value_type<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>>>::__emplace_unique_key_args<std::shared_ptr<ZinIrHazardNode>,std::piecewise_construct_t const&,std::tuple<std::shared_ptr<ZinIrHazardNode> const&>,std::tuple<>>(&v80, (unint64_t *)v11, (uint64_t)&std::piecewise_construct, &v67);
            BOOL v19 = (uint64_t *)v2[4];
            uint64_t v18 = (uint64_t *)v2[5];
            if (v18) {
              atomic_fetch_add_explicit(v18 + 1, 1uLL, memory_order_relaxed);
            }
            char v20 = (std::__shared_weak_count *)v17[7];
            v17[6] = v19;
            v17[7] = v18;
            if (v20) {
              std::__shared_weak_count::__release_shared[abi:ne180100](v20);
            }
          }
        }
        ++v9;
      }
      uint64_t v21 = (void *)v2[1];
      if (v21)
      {
        do
        {
          uint64_t v22 = v21;
          uint64_t v21 = (void *)*v21;
        }
        while (v21);
      }
      else
      {
        do
        {
          uint64_t v22 = (void *)v2[2];
          BOOL v23 = *v22 == (void)v2;
          unint64_t v2 = v22;
        }
        while (!v23);
      }
      unint64_t v2 = v22;
    }
    while (v22 != (void *)v1);
    unint64_t v24 = v80;
    if (v80 != (uint64_t *)v81)
    {
      do
      {
        uint64_t v25 = (std::__shared_weak_count *)v24[5];
        char v26 = (ZinIrHazardNode **)(v24 + 4);
        uint64_t v27 = *(void *)this;
        uint64_t v72 = v24[4];
        uint64_t v73 = v25;
        if (v25) {
          atomic_fetch_add_explicit(&v25->__shared_owners_, 1uLL, memory_order_relaxed);
        }
        uint64_t v28 = (std::__shared_weak_count *)v24[7];
        uint64_t v70 = v24[6];
        uint64_t v71 = v28;
        if (v28) {
          atomic_fetch_add_explicit(&v28->__shared_owners_, 1uLL, memory_order_relaxed);
        }
        ZinIrHazardGraph::RemoveEdge(v27, &v72, &v70);
        if (v71) {
          std::__shared_weak_count::__release_shared[abi:ne180100](v71);
        }
        if (v73) {
          std::__shared_weak_count::__release_shared[abi:ne180100](v73);
        }
        uint64_t v29 = (ZinIrHazardNode **)(v24 + 6);
        int v79 = 0;
        if (ZinIrHazardNode::GetL2SourceType(v24[6], &v79))
        {
          L2SrcDep = (_DWORD *)ZinMirL2Config::GetL2SrcDep(*(void *)(*(void *)*v29 + 264) + 120, v79);
          LODWORD(v67) = *L2SrcDep;
          std::unordered_map<ZinDependencyOffsetDim,long>::unordered_map((uint64_t)v68, (uint64_t)(L2SrcDep + 2));
          uint64_t v31 = v69;
          if (v69)
          {
            while ((uint64_t)v31[3] <= 0)
            {
              uint64_t v31 = (void *)*v31;
              if (!v31) {
                goto LABEL_44;
              }
            }
            std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v68);
            goto LABEL_84;
          }
LABEL_44:
          std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v68);
        }
        unint64_t v33 = v24[4];
        uint64_t v32 = (std::__shared_weak_count *)v24[5];
        BOOL v34 = (ZinIrHazardNode *)v33;
        if (v32)
        {
          atomic_fetch_add_explicit(&v32->__shared_owners_, 1uLL, memory_order_relaxed);
          BOOL v34 = *v26;
        }
        if (*((_DWORD *)v34 + 5) == 1)
        {
          char v61 = v32;
          uint64_t v35 = *(void *)this;
          uint64_t v36 = (void *)(*(void *)this + 64);
          uint64_t v67 = v24 + 4;
          uint64_t v37 = std::__hash_table<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::__unordered_map_hasher<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::__unordered_map_equal<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>>>::find<std::reference_wrapper<ZinIrOpLayer * const>>(v36, (unint64_t **)&v67);
          uint64_t v38 = (uint64_t **)(v35 + 104);
          if (v37) {
            uint64_t v38 = v37 + 3;
          }
          unint64_t v39 = (ZinIrHazardNode ***)*v38;
          unint64_t v40 = (ZinIrHazardNode ***)v38[1];
          while (1)
          {
            if (v39 == v40)
            {
              uint64_t v32 = v61;
              unint64_t v43 = v33;
              goto LABEL_58;
            }
            int v41 = *v39;
            uint64_t LayerTID = ZinIrHazardNode::GetLayerTID(**v39);
            if (LayerTID == ZinIrHazardNode::GetLayerTID(*v26))
            {
              unint64_t v43 = (unint64_t)*v41;
              if (!*((_DWORD *)*v41 + 5) && *(_DWORD *)(v43 + 16) == *((_DWORD *)*v26 + 4)) {
                break;
              }
            }
            ++v39;
          }
          uint64_t v32 = (std::__shared_weak_count *)v41[1];
          if (v32) {
            atomic_fetch_add_explicit(&v32->__shared_owners_, 1uLL, memory_order_relaxed);
          }
          if (v61) {
            std::__shared_weak_count::__release_shared[abi:ne180100](v61);
          }
        }
        else
        {
          unint64_t v43 = v33;
        }
LABEL_58:
        uint64_t v44 = v24[6];
        uint64_t v45 = (std::__shared_weak_count *)v24[7];
        unint64_t v46 = (ZinIrHazardNode *)v44;
        if (v45)
        {
          atomic_fetch_add_explicit(&v45->__shared_owners_, 1uLL, memory_order_relaxed);
          unint64_t v46 = *v29;
        }
        if (*((_DWORD *)v46 + 5) == 1)
        {
          uint64_t v60 = v45;
          uint64_t v62 = v32;
          uint64_t v47 = *(void *)this;
          uint64_t v48 = (void *)(*(void *)this + 64);
          uint64_t v67 = v24 + 6;
          BOOL v49 = std::__hash_table<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::__unordered_map_hasher<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::__unordered_map_equal<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>>>::find<std::reference_wrapper<ZinIrOpLayer * const>>(v48, (unint64_t **)&v67);
          BOOL v50 = (uint64_t **)(v47 + 104);
          if (v49) {
            BOOL v50 = v49 + 3;
          }
          uint64_t v52 = (ZinIrHazardNode ***)*v50;
          long long v51 = (ZinIrHazardNode ***)v50[1];
          while (1)
          {
            if (v52 == v51)
            {
              uint64_t v45 = v60;
              uint64_t v32 = v62;
              uint64_t v55 = v44;
              goto LABEL_71;
            }
            int v53 = *v52;
            uint64_t v54 = ZinIrHazardNode::GetLayerTID(**v52);
            if (v54 == ZinIrHazardNode::GetLayerTID(*v29))
            {
              uint64_t v55 = (uint64_t)*v53;
              if (!*((_DWORD *)*v53 + 5) && *(_DWORD *)(v55 + 16) == *((_DWORD *)*v29 + 4)) {
                break;
              }
            }
            ++v52;
          }
          uint64_t v45 = (std::__shared_weak_count *)v53[1];
          if (v45) {
            atomic_fetch_add_explicit(&v45->__shared_owners_, 1uLL, memory_order_relaxed);
          }
          uint64_t v32 = v62;
          if (v60) {
            std::__shared_weak_count::__release_shared[abi:ne180100](v60);
          }
        }
        else
        {
          uint64_t v55 = v44;
        }
LABEL_71:
        uint64_t v56 = *(void *)this;
        unint64_t v65 = v43;
        uint64_t v66 = v32;
        if (v32) {
          atomic_fetch_add_explicit(&v32->__shared_owners_, 1uLL, memory_order_relaxed);
        }
        uint64_t v63 = v55;
        uint64_t v64 = v45;
        if (v45) {
          atomic_fetch_add_explicit(&v45->__shared_owners_, 1uLL, memory_order_relaxed);
        }
        ZinIrHazardGraph::AddSymbolAliasEdge(v56, &v65, &v63);
        if (v64) {
          std::__shared_weak_count::__release_shared[abi:ne180100](v64);
        }
        if (v66) {
          std::__shared_weak_count::__release_shared[abi:ne180100](v66);
        }
        if (v45) {
          std::__shared_weak_count::__release_shared[abi:ne180100](v45);
        }
        if (v32) {
          std::__shared_weak_count::__release_shared[abi:ne180100](v32);
        }
LABEL_84:
        uint64_t v57 = (uint64_t *)v24[1];
        if (v57)
        {
          do
          {
            unsigned __int8 v58 = v57;
            uint64_t v57 = (uint64_t *)*v57;
          }
          while (v57);
        }
        else
        {
          do
          {
            unsigned __int8 v58 = (uint64_t *)v24[2];
            BOOL v23 = *v58 == (void)v24;
            unint64_t v24 = v58;
          }
          while (!v23);
        }
        unint64_t v24 = v58;
      }
      while (v58 != (uint64_t *)v81);
    }
  }
  std::__tree<std::__value_type<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,ZinIrHazardGraph::EdgeType>,std::__map_value_compare<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,std::__value_type<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,ZinIrHazardGraph::EdgeType>,HazardEdgeCompare,true>,std::allocator<std::__value_type<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,ZinIrHazardGraph::EdgeType>>>::destroy((uint64_t)&v80, v81[0]);
  return 0;
}

void sub_211391B34(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, std::__shared_weak_count *a10, std::__shared_weak_count *a11)
{
  if (a10) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a10);
  }
  if (a11) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a11);
  }
  std::__tree<std::__value_type<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,ZinIrHazardGraph::EdgeType>,std::__map_value_compare<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,std::__value_type<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,ZinIrHazardGraph::EdgeType>,HazardEdgeCompare,true>,std::allocator<std::__value_type<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,ZinIrHazardGraph::EdgeType>>>::destroy(v11 - 120, *(void **)(v11 - 112));
  _Unwind_Resume(a1);
}

void ZinMirL2HazardAnalysis::OptimizeHazardEdges(ZinMirL2HazardAnalysis *this)
{
  unint64_t v2 = (void *)*((void *)this + 3);
  if ((*(unsigned char *)(v2[1] + 96) & 0x10) != 0)
  {
    std::string::basic_string[abi:ne180100]<0>(__p, "before.hz_graph.dot");
    ZinMirL2HazardAnalysis::CreateDotFile((uint64_t *****)this, (uint64_t)__p, 0, 0x7FFFFFFFuLL);
    if (v4 < 0) {
      operator delete(__p[0]);
    }
    unint64_t v2 = (void *)*((void *)this + 3);
  }
  ZinIrNgraphUtils::TransitiveReduction<ZinIrHazardGraph>(*(void **)this, 7 * *(void *)(*v2 + 1096));
  if ((*(unsigned char *)(*(void *)(*((void *)this + 3) + 8) + 96) & 0x10) != 0)
  {
    std::string::basic_string[abi:ne180100]<0>(__p, "after.hz_graph.dot");
    ZinMirL2HazardAnalysis::CreateDotFile((uint64_t *****)this, (uint64_t)__p, 0, 0x7FFFFFFFuLL);
    if (v4 < 0) {
      operator delete(__p[0]);
    }
  }
}

void sub_211391CB0(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11, int a12, __int16 a13, char a14, char a15)
{
  if (a15 < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

void ZinMirL2HazardAnalysis::OptimizeL2DepWithPositiveOffset(ZinMirL2HazardAnalysis *this)
{
  uint64_t v1 = **((void **)this + 3);
  if (*(int *)(v1 + 4) >= 1)
  {
    uint64_t v3 = 0;
    do
    {
      uint64_t v42 = v3;
      char v4 = (uint64_t *)(*((void *)this + 48) + 24 * v3);
      uint64_t v6 = *v4;
      uint64_t v5 = v4[1];
      uint64_t v43 = v5;
      if (*v4 != v5)
      {
        do
        {
          uint64_t v67 = 0;
          uint64_t v68 = 0;
          uint64_t v69 = 0;
          std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(&v67, *(const void **)v6, *(void *)(v6 + 8), (uint64_t)(*(void *)(v6 + 8) - *(void *)v6) >> 3);
          long long v7 = v67;
          if (v68 - (unsigned char *)v67 == 16)
          {
            uint64_t v8 = (ZinBondedUtils *)*v67;
            uint64_t v9 = (const ZinANELayer *)v67[1];
            uint64_t v10 = *(void *)(*v67 + 264);
            uint64_t v11 = *((void *)v9 + 33);
            BOOL v12 = operator new(0xCuLL);
            uint64_t v44 = v10;
            char v46 = 0;
            uint64_t v13 = 0;
            *(void *)BOOL v12 = 0x100000000;
            void v12[2] = 2;
            do
            {
              unint64_t v14 = v12;
              L2SrcDep = (_DWORD *)ZinMirL2Config::GetL2SrcDep(v11 + 120, v12[v13]);
              LODWORD(v63) = *L2SrcDep;
              std::unordered_map<ZinDependencyOffsetDim,long>::unordered_map((uint64_t)&v64, (uint64_t)(L2SrcDep + 2));
              BOOL v16 = v66;
              if (v63) {
                BOOL v17 = v66 == 0;
              }
              else {
                BOOL v17 = 1;
              }
              if (!v17)
              {
                while ((uint64_t)v16[1].__vftable <= 0)
                {
                  BOOL v16 = (std::__shared_weak_count *)v16->__vftable;
                  if (!v16) {
                    goto LABEL_14;
                  }
                }
                char v46 = 1;
              }
LABEL_14:
              std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&v64);
              ++v13;
              BOOL v12 = v14;
            }
            while (v13 != 3);
            if (*(unsigned char *)(*(void *)(*((void *)this + 3) + 8) + 158)
              && !ZinBondedUtils::AreAssignedToSameANE(v8, v9, v18))
            {
              ZinAssertImpl("An L2 dep pair must be assigned to the same ANE");
            }
            uint64_t v60 = 0;
            char v61 = 0;
            uint64_t v62 = 0;
            ZinMirL2HazardAnalysis::GetReadBeginHazardNodes(this, (uint64_t)v9, (uint64_t *)&v60);
            ZinMirL2HazardAnalysis::GetWriteBeginHazardNodes(this, (uint64_t)v9, (uint64_t *)&v60);
            uint64_t v45 = v6;
            uint64_t v57 = 0;
            unsigned __int8 v58 = 0;
            uint64_t v59 = 0;
            BOOL v19 = v60;
            char v20 = v61;
            if (v60 != v61)
            {
              do
              {
                uint64_t v21 = (std::__shared_weak_count *)v19[1];
                uint64_t v55 = *v19;
                uint64_t v56 = v21;
                if (v21) {
                  atomic_fetch_add_explicit(&v21->__shared_owners_, 1uLL, memory_order_relaxed);
                }
                uint64_t v22 = *(void **)this;
                BOOL v23 = (void *)(*(void *)this + 64);
                v70[0] = (unint64_t *)&v55;
                unint64_t v24 = std::__hash_table<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::__unordered_map_hasher<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::__unordered_map_equal<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>>>::find<std::reference_wrapper<ZinIrOpLayer * const>>(v23, v70);
                uint64_t v25 = (uint64_t **)(v22 + 13);
                if (v24) {
                  uint64_t v25 = v24 + 3;
                }
                uint64_t v27 = (unint64_t **)*v25;
                char v26 = (unint64_t **)v25[1];
                while (v27 != v26)
                {
                  uint64_t v28 = *v27;
                  LODWORD(v70[0]) = 0;
                  uint64_t v29 = *(void **)this;
                  uint64_t v30 = (std::__shared_weak_count *)v28[1];
                  int v53 = (void **)*v28;
                  uint64_t v54 = v30;
                  if (v30) {
                    atomic_fetch_add_explicit(&v30->__shared_owners_, 1uLL, memory_order_relaxed);
                  }
                  uint64_t v51 = v55;
                  uint64_t v52 = v56;
                  if (v56) {
                    atomic_fetch_add_explicit(&v56->__shared_owners_, 1uLL, memory_order_relaxed);
                  }
                  BOOL EdgeType = ZinIrHazardGraph::GetEdgeType((uint64_t)v29, (unint64_t *)&v53, &v51, v70);
                  BOOL v32 = LODWORD(v70[0]) != 1 && EdgeType;
                  if (v52) {
                    std::__shared_weak_count::__release_shared[abi:ne180100](v52);
                  }
                  if (v54) {
                    std::__shared_weak_count::__release_shared[abi:ne180100](v54);
                  }
                  if (!v32 && *(ZinBondedUtils **)*v28 != v8)
                  {
                    unint64_t v33 = (std::__shared_weak_count *)v28[1];
                    uint64_t v63 = (void **)*v28;
                    uint64_t v64 = v33;
                    if (v33) {
                      atomic_fetch_add_explicit(&v33->__shared_owners_, 1uLL, memory_order_relaxed);
                    }
                    uint64_t v65 = v55;
                    uint64_t v66 = v56;
                    if (v56) {
                      atomic_fetch_add_explicit(&v56->__shared_owners_, 1uLL, memory_order_relaxed);
                    }
                    std::vector<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>>::push_back[abi:ne180100]((uint64_t *)&v57, (uint64_t)&v63);
                    if (v66) {
                      std::__shared_weak_count::__release_shared[abi:ne180100](v66);
                    }
                    if (v64) {
                      std::__shared_weak_count::__release_shared[abi:ne180100](v64);
                    }
                  }
                  ++v27;
                }
                if (v56) {
                  std::__shared_weak_count::__release_shared[abi:ne180100](v56);
                }
                v19 += 2;
              }
              while (v19 != v20);
              uint64_t v35 = v57;
              BOOL v34 = v58;
              if ((v46 & (v58 != v57)) != 0)
              {
                *(unsigned char *)(v44 + 344) = 1;
                do
                {
                  uint64_t v36 = *v35;
                  uint64_t v63 = *v35;
                  uint64_t v37 = (std::__shared_weak_count *)v35[1];
                  uint64_t v64 = v37;
                  if (v37) {
                    atomic_fetch_add_explicit(&v37->__shared_owners_, 1uLL, memory_order_relaxed);
                  }
                  uint64_t v38 = (uint64_t)v35[2];
                  uint64_t v65 = v38;
                  unint64_t v39 = (std::__shared_weak_count *)v35[3];
                  uint64_t v66 = v39;
                  if (v39) {
                    atomic_fetch_add_explicit(&v39->__shared_owners_, 1uLL, memory_order_relaxed);
                  }
                  unint64_t v40 = *(void **)this;
                  BOOL v49 = v36;
                  BOOL v50 = v37;
                  if (v37) {
                    atomic_fetch_add_explicit(&v37->__shared_owners_, 1uLL, memory_order_relaxed);
                  }
                  uint64_t v47 = v38;
                  uint64_t v48 = v39;
                  if (v39) {
                    atomic_fetch_add_explicit(&v39->__shared_owners_, 1uLL, memory_order_relaxed);
                  }
                  char v41 = ZinIrHazardGraph::RemoveEdge((uint64_t)v40, (uint64_t *)&v49, &v47);
                  if (v48) {
                    std::__shared_weak_count::__release_shared[abi:ne180100](v48);
                  }
                  if (v50) {
                    std::__shared_weak_count::__release_shared[abi:ne180100](v50);
                  }
                  if ((v41 & 1) == 0) {
                    ZinAssertImpl("edge is not removed properly");
                  }
                  if (v39) {
                    std::__shared_weak_count::__release_shared[abi:ne180100](v39);
                  }
                  if (v37) {
                    std::__shared_weak_count::__release_shared[abi:ne180100](v37);
                  }
                  v35 += 4;
                }
                while (v35 != v34);
              }
            }
            uint64_t v63 = (void **)&v57;
            std::vector<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>>::__destroy_vector::operator()[abi:ne180100](&v63);
            uint64_t v63 = (void **)&v60;
            std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100](&v63);
            operator delete(v14);
            long long v7 = v67;
            uint64_t v5 = v43;
            uint64_t v6 = v45;
          }
          if (v7)
          {
            uint64_t v68 = v7;
            operator delete(v7);
          }
          v6 += 24;
        }
        while (v6 != v5);
        uint64_t v1 = **((void **)this + 3);
      }
      uint64_t v3 = v42 + 1;
    }
    while (v42 + 1 < *(int *)(v1 + 4));
  }
}

void sub_211392124(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,char a26,uint64_t a27,uint64_t a28,char a29,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33,uint64_t a34,uint64_t a35)
{
  operator delete(v35);
  uint64_t v38 = *(void **)(v36 - 136);
  if (v38)
  {
    *(void *)(v36 - 128) = v38;
    operator delete(v38);
  }
  _Unwind_Resume(a1);
}

uint64_t ZinMirL2HazardAnalysis::SetL2HazardBits(ZinMirL2HazardAnalysis *this)
{
  ZinMirL2HazardAnalysis::SetFirstTdL2HazardBits((uint64_t)this);
  unint64_t v2 = **(void ***)this;
  uint64_t v52 = *(void *)this + 8;
  if (v2 == (void *)v52) {
    goto LABEL_123;
  }
  do
  {
    uint64_t v3 = v2 + 4;
    char v4 = *(void ***)this;
    uint64_t v5 = (void *)(*(void *)this + 64);
    uint64_t v57 = v2 + 4;
    uint64_t v6 = std::__hash_table<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::__unordered_map_hasher<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::__unordered_map_equal<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>>>::find<std::reference_wrapper<ZinIrOpLayer * const>>(v5, &v57);
    long long v7 = v4 + 13;
    if (v6) {
      long long v7 = v6 + 3;
    }
    uint64_t v8 = (unint64_t **)*v7;
    uint64_t v9 = (unint64_t **)v7[1];
    while (v8 != v9)
    {
      uint64_t v10 = *v8;
      uint64_t v11 = *v3;
      unint64_t v12 = **v8;
      if (*(void *)(*(void *)*v3 + 360) - *(void *)(*(void *)v12 + 360) >= *(void *)(**((void **)this + 3)
                                                                                                  + 1096))
        goto LABEL_105;
      int v65 = 0;
      uint64_t v13 = *(void **)this;
      unint64_t v14 = (std::__shared_weak_count *)v10[1];
      unint64_t v63 = v12;
      uint64_t v64 = v14;
      if (v14)
      {
        atomic_fetch_add_explicit(&v14->__shared_owners_, 1uLL, memory_order_relaxed);
        uint64_t v11 = *v3;
      }
      uint64_t v15 = (std::__shared_weak_count *)v2[5];
      uint64_t v61 = v11;
      uint64_t v62 = v15;
      if (v15) {
        atomic_fetch_add_explicit(&v15->__shared_owners_, 1uLL, memory_order_relaxed);
      }
      BOOL EdgeType = ZinIrHazardGraph::GetEdgeType((uint64_t)v13, &v63, &v61, &v65);
      BOOL v17 = v65 != 1 && EdgeType;
      if (v62) {
        std::__shared_weak_count::__release_shared[abi:ne180100](v62);
      }
      if (v64) {
        std::__shared_weak_count::__release_shared[abi:ne180100](v64);
      }
      if (v17) {
        goto LABEL_105;
      }
      int v60 = 0;
      if (ZinEngineLayerMirInfo::HasChainRead(*(_DWORD **)(*(void *)*v3 + 264), &v60)) {
        goto LABEL_105;
      }
      uint64_t v18 = *(unsigned char **)(*(void *)*v3 + 264);
      unsigned int v19 = *(_DWORD *)(*v3 + 16);
      if (v19 > 2)
      {
        unint64_t v20 = *v10;
        if (v19 == 3)
        {
          unsigned int v21 = *(_DWORD *)(v20 + 16);
          if (v21 == 3)
          {
            if (ZinIrOpLayer::IsNELayer(*(ZinIrOpLayer **)v20)) {
              v18[335] = 1;
            }
            else {
              v18[343] = 1;
            }
            goto LABEL_105;
          }
          if (v21 <= 2)
          {
            if (ZinIrOpLayer::IsNELayer(*(ZinIrOpLayer **)v20)) {
              v18[334] = 1;
            }
            else {
              v18[342] = 1;
            }
            goto LABEL_105;
          }
        }
      }
      else
      {
        unint64_t v20 = *v10;
        if (*(_DWORD *)(*v10 + 16) <= 2u)
        {
          if (ZinIrOpLayer::IsNELayer(*(ZinIrOpLayer **)v20))
          {
            if (v19 == 2)
            {
              v18[332] = 1;
            }
            else if (v19 == 1)
            {
              v18[330] = 1;
            }
            else
            {
              v18[328] = 1;
            }
          }
          else if (v19 == 2)
          {
            v18[340] = 1;
          }
          else if (v19 == 1)
          {
            v18[338] = 1;
          }
          else
          {
            v18[336] = 1;
          }
          goto LABEL_105;
        }
      }
      if (!ZinIrOpLayer::IsNELayer(*(ZinIrOpLayer **)v20))
      {
        unsigned __int8 v58 = 0;
        uint64_t v59 = 0;
        uint64_t v57 = (unint64_t *)&v58;
        BOOL HasL2DependentMode = ZinMirL2Config::HasL2DependentMode((_DWORD *)(*(void *)(*(void *)*v3 + 264) + 120), 2, (uint64_t)&v57);
        switch(v19)
        {
          case 0u:
            uint64_t v28 = v58;
            if (v58) {
              BOOL v29 = HasL2DependentMode;
            }
            else {
              BOOL v29 = 0;
            }
            if (!v29) {
              goto LABEL_57;
            }
            while (1)
            {
              int v30 = *((_DWORD *)v28 + 7);
              if (v30 <= 0)
              {
                if ((v30 & 0x80000000) == 0)
                {
                  char v31 = 0;
                  goto LABEL_58;
                }
                ++v28;
              }
              uint64_t v28 = (void *)*v28;
              if (!v28)
              {
LABEL_57:
                char v31 = 1;
LABEL_58:
                v18[337] = v31;
                goto LABEL_104;
              }
            }
          case 1u:
            unint64_t v40 = v58;
            if (v58) {
              BOOL v41 = HasL2DependentMode;
            }
            else {
              BOOL v41 = 0;
            }
            if (!v41) {
              goto LABEL_90;
            }
            while (1)
            {
              int v42 = *((_DWORD *)v40 + 7);
              if (v42 <= 1)
              {
                if (v42 == 1)
                {
                  char v43 = 0;
                  goto LABEL_91;
                }
                ++v40;
              }
              unint64_t v40 = (void *)*v40;
              if (!v40)
              {
LABEL_90:
                char v43 = 1;
LABEL_91:
                v18[339] = v43;
                goto LABEL_104;
              }
            }
          case 2u:
            uint64_t v44 = v58;
            if (v58) {
              BOOL v45 = HasL2DependentMode;
            }
            else {
              BOOL v45 = 0;
            }
            if (!v45) {
              goto LABEL_100;
            }
            break;
          case 3u:
            if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
              ZinMirL2HazardAnalysis::SetL2HazardBits(&v53, v54);
            }
            goto LABEL_104;
          default:
            goto LABEL_104;
        }
        while (1)
        {
          int v46 = *((_DWORD *)v44 + 7);
          if (v46 <= 2)
          {
            if (v46 == 2)
            {
              char v47 = 0;
              goto LABEL_101;
            }
            ++v44;
          }
          uint64_t v44 = (void *)*v44;
          if (!v44)
          {
LABEL_100:
            char v47 = 1;
LABEL_101:
            v18[341] = v47;
            goto LABEL_104;
          }
        }
      }
      unsigned __int8 v58 = 0;
      uint64_t v59 = 0;
      uint64_t v57 = (unint64_t *)&v58;
      BOOL v22 = ZinMirL2Config::HasL2DependentMode((_DWORD *)(*(void *)(*(void *)*v3 + 264) + 120), 1, (uint64_t)&v57);
      switch(v19)
      {
        case 0u:
          BOOL v23 = v58;
          if (v58) {
            BOOL v24 = v22;
          }
          else {
            BOOL v24 = 0;
          }
          if (!v24)
          {
LABEL_46:
            char v26 = 1;
            goto LABEL_47;
          }
          while (2)
          {
            int v25 = *((_DWORD *)v23 + 7);
            if (v25 > 0) {
              goto LABEL_45;
            }
            if (v25 < 0)
            {
              ++v23;
LABEL_45:
              BOOL v23 = (void *)*v23;
              if (!v23) {
                goto LABEL_46;
              }
              continue;
            }
            break;
          }
          char v26 = 0;
LABEL_47:
          v18[329] = v26;
          goto LABEL_104;
        case 1u:
          BOOL v32 = v58;
          if (v58) {
            BOOL v33 = v22;
          }
          else {
            BOOL v33 = 0;
          }
          if (!v33) {
            goto LABEL_68;
          }
          while (1)
          {
            int v34 = *((_DWORD *)v32 + 7);
            if (v34 <= 1)
            {
              if (v34 == 1)
              {
                char v35 = 0;
                goto LABEL_69;
              }
              ++v32;
            }
            BOOL v32 = (void *)*v32;
            if (!v32)
            {
LABEL_68:
              char v35 = 1;
LABEL_69:
              v18[331] = v35;
              goto LABEL_104;
            }
          }
        case 2u:
          uint64_t v36 = v58;
          if (v58) {
            BOOL v37 = v22;
          }
          else {
            BOOL v37 = 0;
          }
          if (!v37) {
            goto LABEL_78;
          }
          break;
        case 3u:
          if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
            ZinMirL2HazardAnalysis::SetL2HazardBits(&buf, v56);
          }
          goto LABEL_104;
        default:
          goto LABEL_104;
      }
      while (1)
      {
        int v38 = *((_DWORD *)v36 + 7);
        if (v38 <= 2) {
          break;
        }
LABEL_77:
        uint64_t v36 = (void *)*v36;
        if (!v36)
        {
LABEL_78:
          char v39 = 1;
          goto LABEL_79;
        }
      }
      if (v38 != 2)
      {
        ++v36;
        goto LABEL_77;
      }
      char v39 = 0;
LABEL_79:
      v18[333] = v39;
LABEL_104:
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v57, v58);
LABEL_105:
      ++v8;
    }
    uint64_t v48 = (void *)v2[1];
    if (v48)
    {
      do
      {
        BOOL v49 = v48;
        uint64_t v48 = (void *)*v48;
      }
      while (v48);
    }
    else
    {
      do
      {
        BOOL v49 = (void *)v2[2];
        BOOL v50 = *v49 == (void)v2;
        unint64_t v2 = v49;
      }
      while (!v50);
    }
    unint64_t v2 = v49;
  }
  while (v49 != (void *)v52);
LABEL_123:
  ZinMirL2HazardAnalysis::DebugPrintHazardResults((uint64_t)this);
  return 0;
}

void sub_21139273C(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, char a16, void *a17)
{
}

void ZinMirL2HazardAnalysis::MaterializeParallelExecution(ZinMirL2HazardAnalysis *this)
{
  uint64_t v31 = *MEMORY[0x263EF8340];
  uint64_t v1 = **((void **)this + 3);
  if (!*(_DWORD *)(v1 + 4)) {
    return;
  }
  unint64_t v3 = 0;
  char v4 = &_os_log_internal;
  do
  {
    uint64_t v5 = (uint64_t *)(*((void *)this + 48) + 24 * v3);
    uint64_t v7 = *v5;
    uint64_t v6 = v5[1];
    if (*v5 == v6) {
      goto LABEL_29;
    }
    uint64_t v8 = 0;
    do
    {
      BOOL v22 = 0;
      BOOL v23 = 0;
      uint64_t v24 = 0;
      std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(&v22, *(const void **)v7, *(void *)(v7 + 8), (uint64_t)(*(void *)(v7 + 8) - *(void *)v7) >> 3);
      uint64_t v9 = v22;
      if ((char *)v23 - (char *)v22 == 8)
      {
        BOOL v21 = 0;
        if (ZinMirL2HazardAnalysis::TryEnablingParallelExecution(this, (const ZinANELayer *)v8, *v22, &v21)&& *((unsigned char *)this + 376))
        {
          if (v21) {
            uint64_t v10 = "True";
          }
          else {
            uint64_t v10 = "False";
          }
          std::string::basic_string[abi:ne180100]<0>(__p, v10);
          if (os_log_type_enabled(v4, OS_LOG_TYPE_INFO))
          {
            std::to_string(&v18, v8[45]);
            int v11 = SHIBYTE(v18.__r_.__value_.__r.__words[2]);
            std::string::size_type v12 = v18.__r_.__value_.__r.__words[0];
            std::to_string(&v17, (uint64_t)(*v22)[45]);
            uint64_t v13 = &v18;
            if (v11 < 0) {
              uint64_t v13 = (std::string *)v12;
            }
            unint64_t v14 = &v17;
            if ((v17.__r_.__value_.__r.__words[2] & 0x8000000000000000) != 0) {
              unint64_t v14 = (std::string *)v17.__r_.__value_.__r.__words[0];
            }
            uint64_t v15 = __p;
            if (v20 < 0) {
              uint64_t v15 = (void **)__p[0];
            }
            *(_DWORD *)uint8_t buf = 136315650;
            char v26 = v13;
            __int16 v27 = 2080;
            uint64_t v28 = v14;
            __int16 v29 = 2080;
            int v30 = v15;
            _os_log_impl(&dword_210C72000, v4, OS_LOG_TYPE_INFO, "Info: parallel execution is materialized: TID%s->TID%s (L2_barrier=%s)", buf, 0x20u);
            if (SHIBYTE(v17.__r_.__value_.__r.__words[2]) < 0) {
              operator delete(v17.__r_.__value_.__l.__data_);
            }
            if (SHIBYTE(v18.__r_.__value_.__r.__words[2]) < 0) {
              operator delete(v18.__r_.__value_.__l.__data_);
            }
          }
          if (v20 < 0) {
            operator delete(__p[0]);
          }
        }
        uint64_t v9 = v22;
        BOOL v16 = *v22;
      }
      else
      {
        BOOL v16 = 0;
        uint64_t v8 = 0;
        if (!v22) {
          goto LABEL_27;
        }
      }
      BOOL v23 = v9;
      operator delete(v9);
      uint64_t v8 = (uint64_t *)v16;
LABEL_27:
      v7 += 24;
    }
    while (v7 != v6);
    uint64_t v1 = **((void **)this + 3);
LABEL_29:
    ++v3;
  }
  while (v3 < *(int *)(v1 + 4));
}

void sub_2113929EC(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, void *__p, uint64_t a16, int a17, __int16 a18, char a19, char a20,void *a21,uint64_t a22,int a23,__int16 a24,char a25,char a26,uint64_t a27,void *a28,uint64_t a29)
{
  if (a20 < 0) {
    operator delete(__p);
  }
  if (a26 < 0) {
    operator delete(a21);
  }
  if (a28) {
    operator delete(a28);
  }
  _Unwind_Resume(exception_object);
}

void **ZinMirL2HazardAnalysis::UpdateSymbolToHazardNodeMap(uint64_t a1, uint64_t a2, long long *a3)
{
  uint64_t v6 = a2;
  uint64_t v7 = &v6;
  char v4 = std::__hash_table<std::__hash_value_type<ZinIrOpLayerGraph *,std::vector<std::shared_ptr<ZinPattern>>>,std::__unordered_map_hasher<ZinIrOpLayerGraph *,std::__hash_value_type<ZinIrOpLayerGraph *,std::vector<std::shared_ptr<ZinPattern>>>,std::hash<ZinIrOpLayerGraph *>,std::equal_to<ZinIrOpLayerGraph *>,true>,std::__unordered_map_equal<ZinIrOpLayerGraph *,std::__hash_value_type<ZinIrOpLayerGraph *,std::vector<std::shared_ptr<ZinPattern>>>,std::equal_to<ZinIrOpLayerGraph *>,std::hash<ZinIrOpLayerGraph *>,true>,std::allocator<std::__hash_value_type<ZinIrOpLayerGraph *,std::vector<std::shared_ptr<ZinPattern>>>>>::__emplace_unique_key_args<ZinIrOpLayerGraph *,std::piecewise_construct_t const&,std::tuple<ZinIrOpLayerGraph * const&>,std::tuple<>>(a1 + 328, &v6, (uint64_t)&std::piecewise_construct, &v7);
  return std::vector<std::shared_ptr<ZinIrHazardNode>>::push_back[abi:ne180100](v4 + 3, a3);
}

void **std::vector<std::shared_ptr<ZinIrHazardNode>>::push_back[abi:ne180100](uint64_t *a1, long long *a2)
{
  unint64_t v6 = a1[2];
  uint64_t result = (void **)(a1 + 2);
  unint64_t v5 = v6;
  uint64_t v7 = *(result - 1);
  if ((unint64_t)v7 >= v6)
  {
    uint64_t v10 = ((uint64_t)v7 - *a1) >> 4;
    unint64_t v11 = v10 + 1;
    if ((unint64_t)(v10 + 1) >> 60) {
      std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
    }
    uint64_t v12 = v5 - *a1;
    if (v12 >> 3 > v11) {
      unint64_t v11 = v12 >> 3;
    }
    if ((unint64_t)v12 >= 0x7FFFFFFFFFFFFFF0) {
      unint64_t v13 = 0xFFFFFFFFFFFFFFFLL;
    }
    else {
      unint64_t v13 = v11;
    }
    v18[4] = result;
    unint64_t v14 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<std::pair<unsigned long,unsigned long>>>((uint64_t)result, v13);
    uint64_t v15 = &v14[16 * v10];
    v18[0] = v14;
    v18[1] = v15;
    v18[3] = &v14[16 * v16];
    long long v17 = *a2;
    *(_OWORD *)uint64_t v15 = *a2;
    if (*((void *)&v17 + 1)) {
      atomic_fetch_add_explicit((atomic_ullong *volatile)(*((void *)&v17 + 1) + 8), 1uLL, memory_order_relaxed);
    }
    v18[2] = v15 + 16;
    std::vector<std::shared_ptr<ZinIrHazardNode>>::__swap_out_circular_buffer(a1, v18);
    uint64_t v9 = (void *)a1[1];
    uint64_t result = std::__split_buffer<std::shared_ptr<ZinIrConstData>>::~__split_buffer(v18);
  }
  else
  {
    void *v7 = *(void *)a2;
    uint64_t v8 = *((void *)a2 + 1);
    v7[1] = v8;
    if (v8) {
      atomic_fetch_add_explicit((atomic_ullong *volatile)(v8 + 8), 1uLL, memory_order_relaxed);
    }
    uint64_t v9 = v7 + 2;
    a1[1] = (uint64_t)(v7 + 2);
  }
  a1[1] = (uint64_t)v9;
  return result;
}

void sub_211392BA8(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::__split_buffer<std::shared_ptr<ZinIrConstData>>::~__split_buffer((void **)va);
  _Unwind_Resume(a1);
}

void *ZinMirL2HazardAnalysis::GetHazardNodes@<X0>(ZinMirL2HazardAnalysis *this@<X0>, ZinIrSymbol *a2@<X1>, void *a3@<X8>)
{
  unint64_t v5 = a2;
  uint64_t result = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)this + 41, &v5);
  *a3 = 0;
  a3[1] = 0;
  a3[2] = 0;
  if (result) {
    return std::vector<std::shared_ptr<ZinIrHazardNode>>::__init_with_size[abi:ne180100]<std::shared_ptr<ZinIrHazardNode>*,std::shared_ptr<ZinIrHazardNode>*>(a3, (void *)result[3], (void *)result[4], (uint64_t)(result[4] - result[3]) >> 4);
  }
  return result;
}

BOOL ZinIrNgraph<std::shared_ptr<ZinIrHazardNode>,HazardNodeCompare>::AddNode(uint64_t **a1, uint64_t *a2)
{
  uint64_t v4 = std::__tree<std::shared_ptr<ZinIrHazardNode>,HazardNodeCompare,std::allocator<std::shared_ptr<ZinIrHazardNode>>>::__count_unique<std::shared_ptr<ZinIrHazardNode>>((uint64_t)a1, a2);
  if (!v4) {
    std::__tree<std::shared_ptr<ZinIrHazardNode>,HazardNodeCompare,std::allocator<std::shared_ptr<ZinIrHazardNode>>>::__emplace_unique_key_args<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode> const&>(a1, (uint64_t)a2, a2);
  }
  return v4 == 0;
}

void ZinMirL2HazardAnalysis::CreateIntraEngineInvariantEdges(uint64_t *a1, uint64_t *a2, void *a3, uint64_t *a4, uint64_t *a5)
{
  uint64_t v10 = *a2;
  if (a2[1] != *a2)
  {
    unint64_t v11 = 0;
    do
    {
      uint64_t v12 = *a1;
      long long v13 = *(_OWORD *)(v10 + 16 * v11);
      long long v37 = v13;
      if (*((void *)&v13 + 1)) {
        atomic_fetch_add_explicit((atomic_ullong *volatile)(*((void *)&v13 + 1) + 8), 1uLL, memory_order_relaxed);
      }
      long long v14 = *(_OWORD *)(*a3 + 16 * v11);
      long long v36 = v14;
      if (*((void *)&v14 + 1)) {
        atomic_fetch_add_explicit((atomic_ullong *volatile)(*((void *)&v14 + 1) + 8), 1uLL, memory_order_relaxed);
      }
      ZinIrHazardGraph::AddInvariantEdge(v12, (uint64_t *)&v37, (uint64_t *)&v36);
      if (*((void *)&v36 + 1)) {
        std::__shared_weak_count::__release_shared[abi:ne180100](*((std::__shared_weak_count **)&v36 + 1));
      }
      if (*((void *)&v37 + 1)) {
        std::__shared_weak_count::__release_shared[abi:ne180100](*((std::__shared_weak_count **)&v37 + 1));
      }
      ++v11;
      uint64_t v10 = *a2;
    }
    while (v11 < (a2[1] - *a2) >> 4);
  }
  uint64_t v15 = *a1;
  uint64_t v16 = (std::__shared_weak_count *)a4[1];
  uint64_t v34 = *a4;
  char v35 = v16;
  if (v16) {
    atomic_fetch_add_explicit(&v16->__shared_owners_, 1uLL, memory_order_relaxed);
  }
  long long v17 = (std::__shared_weak_count *)a5[1];
  uint64_t v32 = *a5;
  BOOL v33 = v17;
  if (v17) {
    atomic_fetch_add_explicit(&v17->__shared_owners_, 1uLL, memory_order_relaxed);
  }
  ZinIrHazardGraph::AddInvariantEdge(v15, &v34, &v32);
  if (v33) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v33);
  }
  if (v35) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v35);
  }
  uint64_t v18 = *a2;
  if (a2[1] != *a2)
  {
    unint64_t v19 = 0;
    do
    {
      uint64_t v20 = *a1;
      long long v21 = *(_OWORD *)(v18 + 16 * v19);
      long long v31 = v21;
      if (*((void *)&v21 + 1)) {
        atomic_fetch_add_explicit((atomic_ullong *volatile)(*((void *)&v21 + 1) + 8), 1uLL, memory_order_relaxed);
      }
      BOOL v22 = (std::__shared_weak_count *)a4[1];
      uint64_t v29 = *a4;
      int v30 = v22;
      if (v22) {
        atomic_fetch_add_explicit(&v22->__shared_owners_, 1uLL, memory_order_relaxed);
      }
      ZinIrHazardGraph::AddInvariantEdge(v20, (uint64_t *)&v31, &v29);
      if (v30) {
        std::__shared_weak_count::__release_shared[abi:ne180100](v30);
      }
      if (*((void *)&v31 + 1)) {
        std::__shared_weak_count::__release_shared[abi:ne180100](*((std::__shared_weak_count **)&v31 + 1));
      }
      uint64_t v23 = *a1;
      long long v24 = *(_OWORD *)(*a3 + 16 * v19);
      long long v28 = v24;
      if (*((void *)&v24 + 1)) {
        atomic_fetch_add_explicit((atomic_ullong *volatile)(*((void *)&v24 + 1) + 8), 1uLL, memory_order_relaxed);
      }
      int v25 = (std::__shared_weak_count *)a5[1];
      uint64_t v26 = *a5;
      __int16 v27 = v25;
      if (v25) {
        atomic_fetch_add_explicit(&v25->__shared_owners_, 1uLL, memory_order_relaxed);
      }
      ZinIrHazardGraph::AddInvariantEdge(v23, (uint64_t *)&v28, &v26);
      if (v27) {
        std::__shared_weak_count::__release_shared[abi:ne180100](v27);
      }
      if (*((void *)&v28 + 1)) {
        std::__shared_weak_count::__release_shared[abi:ne180100](*((std::__shared_weak_count **)&v28 + 1));
      }
      ++v19;
      uint64_t v18 = *a2;
    }
    while (v19 < (a2[1] - *a2) >> 4);
  }
}

void sub_211392E70(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, std::__shared_weak_count *a18, uint64_t a19, std::__shared_weak_count *a20,uint64_t a21,uint64_t a22)
{
  if (a18) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a18);
  }
  if (a20) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a20);
  }
  _Unwind_Resume(exception_object);
}

void ZinMirL2HazardAnalysis::CreateInterEngineInvariantEdges(uint64_t *a1, uint64_t **a2, uint64_t **a3, uint64_t *a4, uint64_t *a5)
{
  unint64_t v6 = *a2;
  unint64_t v5 = a2[1];
  if (v5 != *a2)
  {
    do
    {
      uint64_t v10 = *v6;
      uint64_t v9 = (std::__shared_weak_count *)v6[1];
      if (v9) {
        atomic_fetch_add_explicit(&v9->__shared_owners_, 1uLL, memory_order_relaxed);
      }
      unint64_t v11 = *a3;
      uint64_t v12 = a3[1];
      while (v11 != v12)
      {
        uint64_t v13 = *v11;
        long long v14 = (std::__shared_weak_count *)v11[1];
        if (v14) {
          atomic_fetch_add_explicit(&v14->__shared_owners_, 1uLL, memory_order_relaxed);
        }
        uint64_t v15 = *a1;
        uint64_t v27 = v10;
        long long v28 = v9;
        if (v9) {
          atomic_fetch_add_explicit(&v9->__shared_owners_, 1uLL, memory_order_relaxed);
        }
        uint64_t v25 = v13;
        uint64_t v26 = v14;
        if (v14) {
          atomic_fetch_add_explicit(&v14->__shared_owners_, 1uLL, memory_order_relaxed);
        }
        ZinIrHazardGraph::AddInvariantEdge(v15, &v27, &v25);
        if (v26) {
          std::__shared_weak_count::__release_shared[abi:ne180100](v26);
        }
        if (v28) {
          std::__shared_weak_count::__release_shared[abi:ne180100](v28);
        }
        if (v14) {
          std::__shared_weak_count::__release_shared[abi:ne180100](v14);
        }
        v11 += 2;
      }
      if (v9) {
        std::__shared_weak_count::__release_shared[abi:ne180100](v9);
      }
      v6 += 2;
    }
    while (v6 != v5);
    uint64_t v16 = *a1;
    long long v17 = (std::__shared_weak_count *)a4[1];
    uint64_t v23 = *a4;
    long long v24 = v17;
    if (v17) {
      atomic_fetch_add_explicit(&v17->__shared_owners_, 1uLL, memory_order_relaxed);
    }
    uint64_t v18 = (std::__shared_weak_count *)a5[1];
    uint64_t v21 = *a5;
    BOOL v22 = v18;
    if (v18) {
      atomic_fetch_add_explicit(&v18->__shared_owners_, 1uLL, memory_order_relaxed);
    }
    ZinIrHazardGraph::AddInvariantEdge(v16, &v23, &v21);
    if (v22) {
      std::__shared_weak_count::__release_shared[abi:ne180100](v22);
    }
    if (v24) {
      std::__shared_weak_count::__release_shared[abi:ne180100](v24);
    }
  }
}

void sub_211393048(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, std::__shared_weak_count *a12, uint64_t a13, std::__shared_weak_count *a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18)
{
  if (a12) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a12);
  }
  if (a14) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a14);
  }
  _Unwind_Resume(exception_object);
}

void ZinMirL2HazardAnalysis::CreateHazardEdgesForLiveSymbols(ZinMirL2HazardAnalysis *this, void *a2)
{
  uint64_t v39 = 0;
  unint64_t v40 = 0;
  uint64_t v41 = 0;
  long long v36 = 0;
  long long v37 = 0;
  uint64_t v38 = 0;
  BOOL v33 = 0;
  uint64_t v34 = 0;
  uint64_t v35 = 0;
  int v30 = 0;
  long long v31 = 0;
  uint64_t v32 = 0;
  unint64_t v3 = a2 + 1;
  uint64_t v4 = (void *)*a2;
  if ((void *)*a2 == a2 + 1)
  {
    unint64_t v19 = 0;
    uint64_t v18 = 0;
  }
  else
  {
    do
    {
      ZinMirL2HazardAnalysis::GetHazardNodes(this, (ZinIrSymbol *)v4[4], v29);
      unint64_t v6 = v29[0];
      unint64_t v5 = v29[1];
      while (v6 != v5)
      {
        uint64_t v7 = (ZinIrOpLayer **)*v6;
        *(void *)&long long v28 = *v6;
        uint64_t v8 = (atomic_ullong *)v6[1];
        *((void *)&v28 + 1) = v8;
        if (v8) {
          atomic_fetch_add_explicit(v8 + 1, 1uLL, memory_order_relaxed);
        }
        BOOL IsNELayer = ZinIrOpLayer::IsNELayer(*v7);
        unsigned int v10 = *(_DWORD *)(v28 + 16);
        BOOL v11 = v10 >= 3;
        if (v10 >= 3) {
          uint64_t v12 = &v30;
        }
        else {
          uint64_t v12 = &v36;
        }
        if (v11) {
          uint64_t v13 = (uint64_t *)&v33;
        }
        else {
          uint64_t v13 = &v39;
        }
        if (IsNELayer) {
          long long v14 = v13;
        }
        else {
          long long v14 = (uint64_t *)v12;
        }
        std::vector<std::shared_ptr<ZinIrHazardNode>>::push_back[abi:ne180100](v14, &v28);
        if (*((void *)&v28 + 1)) {
          std::__shared_weak_count::__release_shared[abi:ne180100](*((std::__shared_weak_count **)&v28 + 1));
        }
        v6 += 2;
      }
      *(void *)&long long v28 = v29;
      std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v28);
      uint64_t v15 = (void *)v4[1];
      if (v15)
      {
        do
        {
          uint64_t v16 = v15;
          uint64_t v15 = (void *)*v15;
        }
        while (v15);
      }
      else
      {
        do
        {
          uint64_t v16 = (void *)v4[2];
          BOOL v17 = *v16 == (void)v4;
          uint64_t v4 = v16;
        }
        while (!v17);
      }
      uint64_t v4 = v16;
    }
    while (v16 != v3);
    uint64_t v18 = v39;
    unint64_t v19 = v40;
  }
  unint64_t v20 = 126 - 2 * __clz(((uint64_t)v19 - v18) >> 4);
  if (v19 == (ZinIrHazardNode **)v18) {
    uint64_t v21 = 0;
  }
  else {
    uint64_t v21 = v20;
  }
  std::__introsort<std::_ClassicAlgPolicy,ZinMirL2HazardAnalysis::HazardNodeSorter &,std::shared_ptr<ZinIrHazardNode> *,false>(v18, v19, (uint64_t)&v28, v21, 1);
  unint64_t v22 = 126 - 2 * __clz(((char *)v34 - (char *)v33) >> 4);
  if (v34 == (ZinIrHazardNode **)v33) {
    uint64_t v23 = 0;
  }
  else {
    uint64_t v23 = v22;
  }
  std::__introsort<std::_ClassicAlgPolicy,ZinMirL2HazardAnalysis::HazardNodeSorter &,std::shared_ptr<ZinIrHazardNode> *,false>((uint64_t)v33, v34, (uint64_t)&v28, v23, 1);
  unint64_t v24 = 126 - 2 * __clz(((char *)v37 - (char *)v36) >> 4);
  if (v37 == (ZinIrHazardNode **)v36) {
    uint64_t v25 = 0;
  }
  else {
    uint64_t v25 = v24;
  }
  std::__introsort<std::_ClassicAlgPolicy,ZinMirL2HazardAnalysis::HazardNodeSorter &,std::shared_ptr<ZinIrHazardNode> *,false>((uint64_t)v36, v37, (uint64_t)&v28, v25, 1);
  unint64_t v26 = 126 - 2 * __clz(((char *)v31 - (char *)v30) >> 4);
  if (v31 == (ZinIrHazardNode **)v30) {
    uint64_t v27 = 0;
  }
  else {
    uint64_t v27 = v26;
  }
  std::__introsort<std::_ClassicAlgPolicy,ZinMirL2HazardAnalysis::HazardNodeSorter &,std::shared_ptr<ZinIrHazardNode> *,false>((uint64_t)v30, v31, (uint64_t)&v28, v27, 1);
  ZinMirL2HazardAnalysis::CreateHazardEdgesForHazardNodeGroups((uint64_t)this, &v39, (uint64_t *)&v36);
  ZinMirL2HazardAnalysis::CreateHazardEdgesForHazardNodeGroups((uint64_t)this, &v39, (uint64_t *)&v30);
  ZinMirL2HazardAnalysis::CreateHazardEdgesForHazardNodeGroups((uint64_t)this, &v33, (uint64_t *)&v36);
  ZinMirL2HazardAnalysis::CreateHazardEdgesForHazardNodeGroups((uint64_t)this, &v33, (uint64_t *)&v30);
  ZinMirL2HazardAnalysis::CreateHazardEdgesForHazardNodeGroups((uint64_t)this, &v39, (uint64_t *)&v33);
  ZinMirL2HazardAnalysis::CreateHazardEdgesForHazardNodeGroups((uint64_t)this, &v39, &v39);
  ZinMirL2HazardAnalysis::CreateHazardEdgesForHazardNodeGroups((uint64_t)this, &v33, (uint64_t *)&v33);
  ZinMirL2HazardAnalysis::CreateHazardEdgesForHazardNodeGroups((uint64_t)this, &v33, &v39);
  ZinMirL2HazardAnalysis::CreateHazardEdgesForHazardNodeGroups((uint64_t)this, &v36, (uint64_t *)&v30);
  ZinMirL2HazardAnalysis::CreateHazardEdgesForHazardNodeGroups((uint64_t)this, &v36, (uint64_t *)&v36);
  ZinMirL2HazardAnalysis::CreateHazardEdgesForHazardNodeGroups((uint64_t)this, &v30, (uint64_t *)&v30);
  ZinMirL2HazardAnalysis::CreateHazardEdgesForHazardNodeGroups((uint64_t)this, &v30, (uint64_t *)&v36);
  v29[0] = (void **)&v30;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100](v29);
  int v30 = (void **)&v33;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100](&v30);
  BOOL v33 = (void **)&v36;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100](&v33);
  long long v36 = (void **)&v39;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100](&v36);
}

void sub_2113933B4(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, void *****a12, uint64_t a13, uint64_t a14, void ****a15, uint64_t a16, uint64_t a17, void ***a18, uint64_t a19, uint64_t a20,void **a21)
{
  a12 = &a15;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100]((void ***)&a12);
  a15 = &a18;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100]((void ***)&a15);
  a18 = &a21;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100]((void ***)&a18);
  a21 = (void **)(v21 - 104);
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100](&a21);
  _Unwind_Resume(a1);
}

void ZinMirL2HazardAnalysis::CreateL2BarrierEdges(ZinMirL2HazardAnalysis *this, ZinANELayer *a2, ZinEngineLayerMirInfo **a3)
{
  uint64_t v59 = 0;
  int v60 = 0;
  uint64_t v61 = 0;
  uint64_t L2RdSymbol = (ZinIrSymbol *)ZinEngineLayerMirInfo::GetL2RdSymbol(*((void *)a2 + 33), 0);
  ZinMirL2HazardAnalysis::GetHazardNodes(this, L2RdSymbol, &v56);
  uint64_t v7 = v56;
  for (uint64_t i = v57; v7 != i; v7 += 2)
  {
    uint64_t v9 = (ZinANELayer **)*v7;
    *(void *)&long long __p = *v7;
    unsigned int v10 = (atomic_ullong *)v7[1];
    *((void *)&__p + 1) = v10;
    if (v10) {
      atomic_fetch_add_explicit(v10 + 1, 1uLL, memory_order_relaxed);
    }
    if (*v9 == a2 && !*((_DWORD *)v9 + 5)) {
      std::vector<std::shared_ptr<ZinIrHazardNode>>::push_back[abi:ne180100]((uint64_t *)&v59, &__p);
    }
    if (*((void *)&__p + 1)) {
      std::__shared_weak_count::__release_shared[abi:ne180100](*((std::__shared_weak_count **)&__p + 1));
    }
  }
  *(void *)&long long __p = &v56;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100]((void ***)&__p);
  uint64_t L2WrSymbol = (ZinIrSymbol *)ZinEngineLayerMirInfo::GetL2WrSymbol(*((ZinEngineLayerMirInfo **)a2 + 33));
  ZinMirL2HazardAnalysis::GetHazardNodes(this, L2WrSymbol, &v56);
  uint64_t v12 = v56;
  for (unint64_t j = v57; v12 != j; v12 += 2)
  {
    long long v14 = (ZinANELayer **)*v12;
    *(void *)&long long __p = *v12;
    uint64_t v15 = (atomic_ullong *)v12[1];
    *((void *)&__p + 1) = v15;
    if (v15) {
      atomic_fetch_add_explicit(v15 + 1, 1uLL, memory_order_relaxed);
    }
    if (*v14 == a2 && !*((_DWORD *)v14 + 5)) {
      std::vector<std::shared_ptr<ZinIrHazardNode>>::push_back[abi:ne180100]((uint64_t *)&v59, &__p);
    }
    if (*((void *)&__p + 1)) {
      std::__shared_weak_count::__release_shared[abi:ne180100](*((std::__shared_weak_count **)&__p + 1));
    }
  }
  *(void *)&long long __p = &v56;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100]((void ***)&__p);
  uint64_t v56 = 0;
  uint64_t v57 = 0;
  uint64_t v58 = 0;
  ZinMirL2HazardAnalysis::GetReadBeginHazardNodes(this, (uint64_t)a3, (uint64_t *)&v56);
  uint64_t v16 = (ZinIrSymbol *)ZinEngineLayerMirInfo::GetL2WrSymbol(a3[33]);
  ZinMirL2HazardAnalysis::GetHazardNodes(this, v16, &__p);
  uint64_t v18 = (uint64_t *)*((void *)&__p + 1);
  for (k = (uint64_t *)__p; k != v18; k += 2)
  {
    uint64_t v19 = *k;
    *(void *)&long long v53 = *k;
    uint64_t v20 = k[1];
    *((void *)&v53 + 1) = v20;
    if (v20) {
      atomic_fetch_add_explicit((atomic_ullong *volatile)(v20 + 8), 1uLL, memory_order_relaxed);
    }
    if (*(ZinEngineLayerMirInfo ***)v19 == a3 && !*(_DWORD *)(v19 + 20)) {
      std::vector<std::shared_ptr<ZinIrHazardNode>>::push_back[abi:ne180100]((uint64_t *)&v56, &v53);
    }
    if (*((void *)&v53 + 1)) {
      std::__shared_weak_count::__release_shared[abi:ne180100](*((std::__shared_weak_count **)&v53 + 1));
    }
  }
  *(void *)&long long v53 = &__p;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v53);
  long long __p = 0uLL;
  uint64_t v55 = 0;
  uint64_t v21 = a3[11];
  if (a3[12] != v21)
  {
    unint64_t v22 = 0;
    do
    {
      uint64_t v23 = (ZinIrTensor *)(*(uint64_t (**)(void, void, void))(**((void **)v21 + v22) + 32))(*((void *)v21 + v22), 0, 0);
      ZinIrTensor::GetTensorFamily(v23, (uint64_t)&v53);
      uint64_t v25 = (char *)*((void *)&v53 + 1);
      unint64_t v24 = (char *)v53;
      if ((void)v53 != *((void *)&v53 + 1))
      {
        do
        {
          if (*(ZinANELayer **)(*(void *)v24 + 96) == a2)
          {
            v62[0] = 0;
            if (ZinMemSourceIndexTranslator::GetL2SrcType(a3, v22, v62)) {
              ZinAssertImpl("Error: Trying to create L2 barrier edges for invalid L2 source");
            }
            unint64_t v26 = (char *)*((void *)&__p + 1);
            if (*((void *)&__p + 1) >= (unint64_t)v55)
            {
              long long v28 = (char *)__p;
              uint64_t v29 = (uint64_t)(*((void *)&__p + 1) - __p) >> 2;
              unint64_t v30 = v29 + 1;
              if ((unint64_t)(v29 + 1) >> 62) {
                std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
              }
              uint64_t v31 = (uint64_t)&v55[-__p];
              if ((uint64_t)&v55[-__p] >> 1 > v30) {
                unint64_t v30 = v31 >> 1;
              }
              if ((unint64_t)v31 >= 0x7FFFFFFFFFFFFFFCLL) {
                unint64_t v32 = 0x3FFFFFFFFFFFFFFFLL;
              }
              else {
                unint64_t v32 = v30;
              }
              if (v32)
              {
                BOOL v33 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ZinIrPaddingMode>>((uint64_t)&v55, v32);
                unint64_t v26 = (char *)*((void *)&__p + 1);
                long long v28 = (char *)__p;
              }
              else
              {
                BOOL v33 = 0;
              }
              uint64_t v34 = &v33[4 * v29];
              *(_DWORD *)uint64_t v34 = v62[0];
              uint64_t v27 = v34 + 4;
              while (v26 != v28)
              {
                int v35 = *((_DWORD *)v26 - 1);
                v26 -= 4;
                *((_DWORD *)v34 - 1) = v35;
                v34 -= 4;
              }
              *(void *)&long long __p = v34;
              *((void *)&__p + 1) = v27;
              uint64_t v55 = &v33[4 * v32];
              if (v28) {
                operator delete(v28);
              }
            }
            else
            {
              **((_DWORD **)&__p + 1) = v62[0];
              uint64_t v27 = v26 + 4;
            }
            *((void *)&__p + 1) = v27;
          }
          v24 += 8;
        }
        while (v24 != v25);
        unint64_t v24 = (char *)v53;
      }
      if (v24)
      {
        *((void *)&v53 + 1) = v24;
        operator delete(v24);
      }
      ++v22;
      uint64_t v21 = a3[11];
    }
    while (v22 < (a3[12] - v21) >> 3);
  }
  long long v36 = v59;
  char v47 = v60;
  if (v59 != v60)
  {
    while (1)
    {
      uint64_t v38 = *v36;
      long long v37 = (std::__shared_weak_count *)v36[1];
      uint64_t v48 = v36;
      if (v37) {
        atomic_fetch_add_explicit(&v37->__shared_owners_, 1uLL, memory_order_relaxed);
      }
      uint64_t v39 = v56;
      unint64_t v40 = v57;
LABEL_59:
      if (v39 != v40) {
        break;
      }
      if (v37) {
        std::__shared_weak_count::__release_shared[abi:ne180100](v37);
      }
      long long v36 = v48 + 2;
      if (v48 + 2 == v47) {
        goto LABEL_90;
      }
    }
    uint64_t v42 = (uint64_t)*v39;
    uint64_t v41 = (std::__shared_weak_count *)v39[1];
    if (v41) {
      atomic_fetch_add_explicit(&v41->__shared_owners_, 1uLL, memory_order_relaxed);
    }
    char v43 = (int *)*((void *)&__p + 1);
    for (m = (int *)__p; ; ++m)
    {
      if (m == v43)
      {
        if (v41) {
          std::__shared_weak_count::__release_shared[abi:ne180100](v41);
        }
        v39 += 2;
        goto LABEL_59;
      }
      int v45 = *m;
      if (*m == 2)
      {
        if (*(_DWORD *)(v38 + 16) == 3 && *(_DWORD *)(v42 + 16) == 2) {
          continue;
        }
      }
      else if (v45 == 1)
      {
        if (*(_DWORD *)(v38 + 16) == 3 && *(_DWORD *)(v42 + 16) == 1) {
          continue;
        }
      }
      else if (!v45 && *(_DWORD *)(v38 + 16) == 3 && !*(_DWORD *)(v42 + 16))
      {
        continue;
      }
      uint64_t v46 = *(void *)this;
      uint64_t v51 = v38;
      uint64_t v52 = v37;
      if (v37) {
        atomic_fetch_add_explicit(&v37->__shared_owners_, 1uLL, memory_order_relaxed);
      }
      uint64_t v49 = v42;
      BOOL v50 = v41;
      if (v41) {
        atomic_fetch_add_explicit(&v41->__shared_owners_, 1uLL, memory_order_relaxed);
      }
      ZinIrHazardGraph::AddInvariantEdge(v46, &v51, &v49);
      if (v50) {
        std::__shared_weak_count::__release_shared[abi:ne180100](v50);
      }
      if (v52) {
        std::__shared_weak_count::__release_shared[abi:ne180100](v52);
      }
    }
  }
LABEL_90:
  if ((void)__p)
  {
    *((void *)&__p + 1) = __p;
    operator delete((void *)__p);
  }
  *(void *)&long long __p = &v56;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100]((void ***)&__p);
  uint64_t v56 = (void **)&v59;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100](&v56);
}

void sub_211393928(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, void *a15, uint64_t a16, uint64_t a17, void *__p, uint64_t a19, uint64_t a20,char a21,uint64_t a22,uint64_t a23,char a24)
{
  *(void *)(v24 - 96) = &a21;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100]((void ***)(v24 - 96));
  *(void *)(v24 - 96) = &a24;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100]((void ***)(v24 - 96));
  _Unwind_Resume(a1);
}

uint64_t ZinMirL2HazardAnalysis::IsQualifiedForDependentMode(uint64_t a1, const ZinIrOpLayer *a2, uint64_t a3, char **a4, uint64_t a5)
{
  unsigned int v10 = (ZinIrOpLayerGraph *)*((void *)a2 + 19);
  BOOL v11 = (ZinIrTensor *)(*(uint64_t (**)(const ZinIrOpLayer *, void, void))(*(void *)a2 + 32))(a2, 0, 0);
  uint64_t RootTensor = ZinIrTensor::GetRootTensor(v11);
  uint64_t v12 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)(a1 + 408), &RootTensor);
  if (*((void *)a2 + 45) + 1 == *(void *)(a3 + 360) && *(_DWORD *)(*(void *)(a3 + 64) + 8) != 93)
  {
    uint64_t v13 = v12;
    uint64_t v14 = *((void *)a2 + 33);
    if (!v14 || (*(_DWORD *)(v14 + 1632) - 3) <= 1)
    {
      if (*(unsigned char *)(**(void **)(a1 + 24) + 1117)
        || (uint64_t v17 = *(void *)(v14 + 200),
            v17 == (*(uint64_t (**)(const ZinIrOpLayer *, uint64_t))(*(void *)a2 + 368))(a2, 3))
        && (uint64_t v18 = *(void *)(*(void *)(a3 + 264) + 200),
            v18 == (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)a3 + 368))(a3, 3)))
      {
        int v57 = 0;
        ZinIrOpLayerGraph::GetIndicesOfMatchedIncomingLayer(*(ZinIrOpLayerGraph **)(a3 + 152), (ZinIrOpLayer *)a3, a2, (unint64_t **)&__p);
        uint64_t v15 = __p;
        if ((unint64_t)(v56 - (unsigned char *)__p) > 8)
        {
          uint64_t v16 = 0;
          if (!__p) {
            return v16;
          }
          goto LABEL_71;
        }
        if (__p == v56)
        {
          uint64_t L2RdSymbol = 0;
          unint64_t v54 = -1;
        }
        else
        {
          unint64_t v20 = *(void *)__p;
          unint64_t v54 = v20;
          if ((v20 & 0x8000000000000000) != 0)
          {
            uint64_t L2RdSymbol = 0;
          }
          else
          {
            uint64_t v16 = 0;
            if (ZinMemSourceIndexTranslator::GetL2SrcType((void *)a3, v20, &v57) || v57 == 2)
            {
LABEL_70:
              uint64_t v15 = __p;
              if (!__p) {
                return v16;
              }
LABEL_71:
              uint64_t v56 = v15;
              operator delete(v15);
              return v16;
            }
            uint64_t L2RdSymbol = ZinEngineLayerMirInfo::GetL2RdSymbol(*(void *)(a3 + 264), v57);
          }
        }
        if (!ZinIrOpLayer::IsPELayer((ZinIrOpLayer *)a3)
          || !(*(unsigned int (**)(uint64_t))(*(void *)a3 + 568))(a3)
          || (LODWORD(v51) = 0,
              !ZinMemSourceIndexTranslator::GetL2SrcType((void *)a3, v54 == 0, (int *)&v51))
          && ((uint64_t v22 = ZinEngineLayerMirInfo::GetL2RdSymbol(*(void *)(a3 + 264), (int)v51),
               uint64_t L2WrSymbol = ZinEngineLayerMirInfo::GetL2WrSymbol(*(ZinEngineLayerMirInfo **)(a3 + 264)),
               *(void *)(v22 + 24) != *(void *)(L2WrSymbol + 24))
           || !*(void *)(v22 + 184)
            ? (BOOL v24 = 0)
            : (BOOL v24 = *(void *)(L2WrSymbol + 184) != 0),
              (uint64_t v25 = ZinEngineLayerMirInfo::GetL2RdSymbol(*((void *)a2 + 33), 0),
               *(void *)(v22 + 24) != *(void *)(v25 + 24))
           || !*(void *)(v22 + 184)
           || (*(void *)(v25 + 184) ? (BOOL v26 = v24) : (BOOL v26 = 0), !v26)))
        {
          if ((v54 & 0x8000000000000000) != 0)
          {
            if (v13 && *a4 == a4[1])
            {
              uint64_t v51 = 0;
              uint64_t v52 = 0;
              uint64_t v53 = 0;
              std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(&v51, *(const void **)(a3 + 88), *(void *)(a3 + 96), (uint64_t)(*(void *)(a3 + 96) - *(void *)(a3 + 88)) >> 3);
              uint64_t v44 = v52;
              if (v52 == v51)
              {
LABEL_67:
                if (v44)
                {
                  uint64_t v52 = v44;
                  operator delete(v44);
                }
              }
              else
              {
                unint64_t v45 = 0;
                uint64_t v44 = v51;
                while (1)
                {
                  uint64_t v46 = (ZinIrTensor *)(*(uint64_t (**)(void, void, void))(**((void **)v44 + v45)
                                                                                         + 32))(*((void *)v44 + v45), 0, 0);
                  char v47 = ZinIrTensor::GetRootTensor(v46);
                  if (v47 == RootTensor) {
                    break;
                  }
                  ++v45;
                  uint64_t v44 = v51;
                  if (v45 >= ((unsigned char *)v52 - (unsigned char *)v51) >> 3) {
                    goto LABEL_67;
                  }
                }
                ZinMirL2HazardAnalysis::ComputeDependencyMap((uint64_t)v47, a2, (ZinIrOpLayer *)a3, v10, **(void **)(a1 + 24), a5);
                if (*(void *)(a5 + 24))
                {
                  if (v51)
                  {
                    uint64_t v52 = v51;
                    operator delete(v51);
                  }
                  goto LABEL_41;
                }
                uint64_t v49 = a3;
                BOOL v50 = a2;
                BOOL IsConnected = ZinIrNgraph<ZinIrOpLayer *,ZinIrIdComparator<ZinIrOpLayer *>>::IsConnected((uint64_t)v10, (unint64_t *)&v50, &v49);
                if (v51)
                {
                  uint64_t v52 = v51;
                  operator delete(v51);
                }
                if (IsConnected) {
                  goto LABEL_41;
                }
              }
            }
            else if (ZinMirL2HazardAnalysis::IsQualifiedForExtensiveL2Dependency(a1, a2, (ZinIrOpLayer *)a3, v10, **(const ZinIrTensor ***)(a1 + 24), a5))
            {
              goto LABEL_41;
            }
          }
          else if (ZinEngineLayerMirInfo::GetL2WrSymbol(*((ZinEngineLayerMirInfo **)a2 + 33)) == L2RdSymbol)
          {
            uint64_t v27 = (*(uint64_t (**)(const ZinIrOpLayer *, uint64_t))(*(void *)a2 + 368))(a2, 2);
            uint64_t v28 = (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)a3 + 360))(a3, 2);
            if (*(unsigned char *)(**(void **)(a1 + 24) + 1117)
              || *(void *)(*((void *)a2 + 33) + 104) * v27 == *(void *)(*(void *)(a3 + 264) + 104) * v28)
            {
              uint64_t v51 = &v54;
              uint64_t v29 = std::__hash_table<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::__unordered_map_hasher<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::hash<long>,std::equal_to<long>,true>,std::__unordered_map_equal<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::equal_to<long>,std::hash<long>,true>,std::allocator<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>>>::__emplace_unique_key_args<long,std::piecewise_construct_t const&,std::tuple<long const&>,std::tuple<>>(a5, &v54, (uint64_t)&std::piecewise_construct, (void **)&v51);
              LODWORD(v5std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
              uint64_t v51 = &v50;
              std::__hash_table<std::__hash_value_type<ZinDependencyOffsetDim,long>,std::__unordered_map_hasher<ZinDependencyOffsetDim,std::__hash_value_type<ZinDependencyOffsetDim,long>,std::hash<ZinDependencyOffsetDim>,std::equal_to<ZinDependencyOffsetDim>,true>,std::__unordered_map_equal<ZinDependencyOffsetDim,std::__hash_value_type<ZinDependencyOffsetDim,long>,std::equal_to<ZinDependencyOffsetDim>,std::hash<ZinDependencyOffsetDim>,true>,std::allocator<std::__hash_value_type<ZinDependencyOffsetDim,long>>>::__emplace_unique_key_args<ZinDependencyOffsetDim,std::piecewise_construct_t const&,std::tuple<ZinDependencyOffsetDim const&>,std::tuple<>>((uint64_t)(v29 + 3), (int *)&v50, (uint64_t)&std::piecewise_construct, (_DWORD **)&v51)[3] = 0;
LABEL_41:
              unint64_t v30 = *(void **)(a5 + 16);
              if (!v30)
              {
LABEL_62:
                uint64_t v16 = 1;
                goto LABEL_70;
              }
              while (1)
              {
                unint64_t v31 = v30[2];
                if ((v31 & 0x8000000000000000) != 0) {
                  break;
                }
                uint64_t HasResidentSymbolAlias = ZinIrRegAllocUtil::HasResidentSymbolAlias(a2, (const ZinANELayer *)a3, *(const ZinANELayer **)(*(void *)(a1 + 16) + 48), v31);
                if ((HasResidentSymbolAlias & 1) != 0
                  || !ZinMirL2HazardAnalysis::ConfigureExtensiveL2Dependency(HasResidentSymbolAlias, (void *)a3, v30[2], (uint64_t)(v30 + 3)))
                {
                  break;
                }
                uint64_t v34 = a4[1];
                unint64_t v33 = (unint64_t)a4[2];
                if ((unint64_t)v34 >= v33)
                {
                  long long v36 = *a4;
                  uint64_t v37 = (v34 - *a4) >> 3;
                  unint64_t v38 = v37 + 1;
                  if ((unint64_t)(v37 + 1) >> 61) {
                    std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
                  }
                  uint64_t v39 = v33 - (void)v36;
                  if (v39 >> 2 > v38) {
                    unint64_t v38 = v39 >> 2;
                  }
                  if ((unint64_t)v39 >= 0x7FFFFFFFFFFFFFF8) {
                    unint64_t v40 = 0x1FFFFFFFFFFFFFFFLL;
                  }
                  else {
                    unint64_t v40 = v38;
                  }
                  if (v40)
                  {
                    uint64_t v41 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)(a4 + 2), v40);
                    long long v36 = *a4;
                    uint64_t v34 = a4[1];
                  }
                  else
                  {
                    uint64_t v41 = 0;
                  }
                  uint64_t v42 = &v41[8 * v37];
                  *(void *)uint64_t v42 = v30[2];
                  int v35 = v42 + 8;
                  while (v34 != v36)
                  {
                    uint64_t v43 = *((void *)v34 - 1);
                    v34 -= 8;
                    *((void *)v42 - 1) = v43;
                    v42 -= 8;
                  }
                  *a4 = v42;
                  a4[1] = v35;
                  a4[2] = &v41[8 * v40];
                  if (v36) {
                    operator delete(v36);
                  }
                }
                else
                {
                  *(void *)uint64_t v34 = v30[2];
                  int v35 = v34 + 8;
                }
                a4[1] = v35;
                unint64_t v30 = (void *)*v30;
                if (!v30) {
                  goto LABEL_62;
                }
              }
            }
          }
        }
        uint64_t v16 = 0;
        goto LABEL_70;
      }
    }
  }
  return 0;
}

void sub_211394058(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, void *__p, uint64_t a13, uint64_t a14, uint64_t a15, void *a16, uint64_t a17)
{
  if (__p) {
    operator delete(__p);
  }
  if (a16) {
    operator delete(a16);
  }
  _Unwind_Resume(exception_object);
}

void ZinMirL2HazardAnalysis::GetReadBeginHazardNodes(ZinMirL2HazardAnalysis *a1, uint64_t a2, uint64_t *a3)
{
  uint64_t L2RdSymbol = (ZinIrSymbol *)ZinEngineLayerMirInfo::GetL2RdSymbol(*(void *)(a2 + 264), 0);
  ZinMirL2HazardAnalysis::GetHazardNodes(a1, L2RdSymbol, &v22);
  uint64_t v7 = v22;
  for (uint64_t i = v23; v7 != i; v7 += 16)
  {
    uint64_t v9 = *(void **)v7;
    *(void *)&long long v21 = *(void *)v7;
    uint64_t v10 = *(void *)(v7 + 8);
    *((void *)&v21 + 1) = v10;
    if (v10) {
      atomic_fetch_add_explicit((atomic_ullong *volatile)(v10 + 8), 1uLL, memory_order_relaxed);
    }
    if (*v9 == a2 && v9[2] <= 2uLL) {
      std::vector<std::shared_ptr<ZinIrHazardNode>>::push_back[abi:ne180100](a3, &v21);
    }
    if (*((void *)&v21 + 1)) {
      std::__shared_weak_count::__release_shared[abi:ne180100](*((std::__shared_weak_count **)&v21 + 1));
    }
  }
  *(void *)&long long v21 = &v22;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v21);
  BOOL v11 = (ZinIrSymbol *)ZinEngineLayerMirInfo::GetL2RdSymbol(*(void *)(a2 + 264), 1);
  ZinMirL2HazardAnalysis::GetHazardNodes(a1, v11, &v22);
  uint64_t v12 = v22;
  for (uint64_t j = v23; v12 != j; v12 += 16)
  {
    uint64_t v14 = *(void **)v12;
    *(void *)&long long v21 = *(void *)v12;
    uint64_t v15 = *(void *)(v12 + 8);
    *((void *)&v21 + 1) = v15;
    if (v15) {
      atomic_fetch_add_explicit((atomic_ullong *volatile)(v15 + 8), 1uLL, memory_order_relaxed);
    }
    if (*v14 == a2 && v14[2] <= 2uLL) {
      std::vector<std::shared_ptr<ZinIrHazardNode>>::push_back[abi:ne180100](a3, &v21);
    }
    if (*((void *)&v21 + 1)) {
      std::__shared_weak_count::__release_shared[abi:ne180100](*((std::__shared_weak_count **)&v21 + 1));
    }
  }
  *(void *)&long long v21 = &v22;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v21);
  uint64_t v16 = (ZinIrSymbol *)ZinEngineLayerMirInfo::GetL2RdSymbol(*(void *)(a2 + 264), 2);
  ZinMirL2HazardAnalysis::GetHazardNodes(a1, v16, &v22);
  uint64_t v17 = v22;
  for (uint64_t k = v23; v17 != k; v17 += 16)
  {
    uint64_t v19 = *(void **)v17;
    *(void *)&long long v21 = *(void *)v17;
    uint64_t v20 = *(void *)(v17 + 8);
    *((void *)&v21 + 1) = v20;
    if (v20) {
      atomic_fetch_add_explicit((atomic_ullong *volatile)(v20 + 8), 1uLL, memory_order_relaxed);
    }
    if (*v19 == a2 && v19[2] <= 2uLL) {
      std::vector<std::shared_ptr<ZinIrHazardNode>>::push_back[abi:ne180100](a3, &v21);
    }
    if (*((void *)&v21 + 1)) {
      std::__shared_weak_count::__release_shared[abi:ne180100](*((std::__shared_weak_count **)&v21 + 1));
    }
  }
  *(void *)&long long v21 = &v22;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v21);
}

void sub_2113942DC(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, void **a10, std::__shared_weak_count *a11, char a12)
{
  if (a11) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a11);
  }
  a10 = (void **)&a12;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100](&a10);
  _Unwind_Resume(a1);
}

void ZinMirL2HazardAnalysis::GetWriteBeginHazardNodes(ZinMirL2HazardAnalysis *a1, uint64_t a2, uint64_t *a3)
{
  uint64_t L2WrSymbol = (ZinIrSymbol *)ZinEngineLayerMirInfo::GetL2WrSymbol(*(ZinEngineLayerMirInfo **)(a2 + 264));
  ZinMirL2HazardAnalysis::GetHazardNodes(a1, L2WrSymbol, &v12);
  uint64_t v7 = v12;
  for (uint64_t i = v13; v7 != i; v7 += 2)
  {
    uint64_t v9 = *v7;
    *(void *)&long long v11 = *v7;
    uint64_t v10 = v7[1];
    *((void *)&v11 + 1) = v10;
    if (v10) {
      atomic_fetch_add_explicit((atomic_ullong *volatile)(v10 + 8), 1uLL, memory_order_relaxed);
    }
    if (*(void *)v9 == a2 && !*(_DWORD *)(v9 + 20) && *(_DWORD *)(v9 + 16) == 3) {
      std::vector<std::shared_ptr<ZinIrHazardNode>>::push_back[abi:ne180100](a3, &v11);
    }
    if (*((void *)&v11 + 1)) {
      std::__shared_weak_count::__release_shared[abi:ne180100](*((std::__shared_weak_count **)&v11 + 1));
    }
  }
  *(void *)&long long v11 = &v12;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v11);
}

void sub_2113943E4(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, void **a10, std::__shared_weak_count *a11, char a12)
{
  if (a11) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a11);
  }
  a10 = (void **)&a12;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100](&a10);
  _Unwind_Resume(a1);
}

BOOL ZinMirL2HazardAnalysis::IsQualifiedHazardPair(uint64_t a1, ZinIrOpLayer ***a2, ZinIrOpLayer ***a3)
{
  unint64_t v5 = *a3;
  unint64_t v6 = **a3;
  BOOL result = 0;
  if (*((_DWORD *)*a2 + 4) > 2u
    || *((_DWORD *)v5 + 4) > 2u
    || *((_DWORD *)(*a2)[1] + 38) != 2
    || *((_DWORD *)v5[1] + 38) != 2)
  {
    BOOL IsNELayer = ZinIrOpLayer::IsNELayer(**a2);
    if (IsNELayer != ZinIrOpLayer::IsNELayer(v6) || *((_DWORD *)*a2 + 4) > 2u || *((_DWORD *)*a3 + 4) != 3) {
      return 1;
    }
  }
  return result;
}

uint64_t ZinMirL2HazardAnalysis::CreateHazardEdge(uint64_t *a1, ZinIrHazardNode **a2, ZinIrHazardNode **a3)
{
  uint64_t LayerTID = ZinIrHazardNode::GetLayerTID(*a2);
  if (LayerTID == ZinIrHazardNode::GetLayerTID(*a3)
    || ZinIrNgraph<ZinIrOpLayer *,ZinIrIdComparator<ZinIrOpLayer *>>::IsConnected(*a1, (unint64_t *)a2, (uint64_t *)a3))
  {
    return 0;
  }
  uint64_t v9 = ZinIrHazardNode::GetLayerTID(*a2);
  if (v9 >= ZinIrHazardNode::GetLayerTID(*a3)) {
    uint64_t v10 = (ZinIrOpLayer ***)a3;
  }
  else {
    uint64_t v10 = (ZinIrOpLayer ***)a2;
  }
  uint64_t v12 = *v10;
  long long v11 = v10[1];
  v24[0] = *v10;
  v24[1] = v11;
  if (v11) {
    atomic_fetch_add_explicit((atomic_ullong *volatile)v11 + 1, 1uLL, memory_order_relaxed);
  }
  uint64_t v13 = ZinIrHazardNode::GetLayerTID(*a2);
  uint64_t v14 = ZinIrHazardNode::GetLayerTID(*a3);
  if (v13 >= v14) {
    uint64_t v15 = (ZinIrOpLayer ***)a2;
  }
  else {
    uint64_t v15 = (ZinIrOpLayer ***)a3;
  }
  uint64_t v17 = *v15;
  uint64_t v16 = v15[1];
  v23[0] = *v15;
  v23[1] = v16;
  if (v16) {
    atomic_fetch_add_explicit((atomic_ullong *volatile)v16 + 1, 1uLL, memory_order_relaxed);
  }
  if (ZinMirL2HazardAnalysis::IsQualifiedHazardPair(v14, v24, v23))
  {
    uint64_t v18 = *a1;
    long long v21 = v12;
    uint64_t v22 = (std::__shared_weak_count *)v11;
    if (v11) {
      atomic_fetch_add_explicit((atomic_ullong *volatile)v11 + 1, 1uLL, memory_order_relaxed);
    }
    uint64_t v19 = v17;
    uint64_t v20 = (std::__shared_weak_count *)v16;
    if (v16) {
      atomic_fetch_add_explicit((atomic_ullong *volatile)v16 + 1, 1uLL, memory_order_relaxed);
    }
    uint64_t v7 = ZinIrHazardGraph::AddSymbolAliasEdge(v18, (unint64_t *)&v21, (uint64_t *)&v19);
    if (v20) {
      std::__shared_weak_count::__release_shared[abi:ne180100](v20);
    }
    if (v22) {
      std::__shared_weak_count::__release_shared[abi:ne180100](v22);
    }
  }
  else
  {
    uint64_t v7 = 0;
  }
  if (v16) {
    std::__shared_weak_count::__release_shared[abi:ne180100]((std::__shared_weak_count *)v16);
  }
  if (v11) {
    std::__shared_weak_count::__release_shared[abi:ne180100]((std::__shared_weak_count *)v11);
  }
  return v7;
}

void sub_21139462C(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, std::__shared_weak_count *a10, uint64_t a11, std::__shared_weak_count *a12)
{
  if (a10) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a10);
  }
  if (a12)
  {
    std::__shared_weak_count::__release_shared[abi:ne180100](a12);
    if (!v13)
    {
LABEL_5:
      if (!v12) {
        goto LABEL_7;
      }
      goto LABEL_6;
    }
  }
  else if (!v13)
  {
    goto LABEL_5;
  }
  std::__shared_weak_count::__release_shared[abi:ne180100](v13);
  if (!v12) {
LABEL_7:
  }
    _Unwind_Resume(exception_object);
LABEL_6:
  std::__shared_weak_count::__release_shared[abi:ne180100](v12);
  goto LABEL_7;
}

void sub_211394680()
{
  if (!v0) {
    JUMPOUT(0x211394654);
  }
  JUMPOUT(0x21139464CLL);
}

void ZinMirL2HazardAnalysis::CreateHazardEdgesForHazardNodeGroups(uint64_t a1, void *a2, uint64_t *a3)
{
  unint64_t v5 = 0;
  unint64_t v6 = 0;
  uint64_t v7 = **(void **)(a1 + 24);
  do
  {
    if (v6 >= (uint64_t)(a2[1] - *a2) >> 4) {
      break;
    }
    uint64_t v8 = *a3;
    if (v5 >= (a3[1] - *a3) >> 4) {
      break;
    }
    long long v9 = *(_OWORD *)(*a2 + 16 * v6);
    *(_OWORD *)uint64_t v46 = v9;
    if (*((void *)&v9 + 1))
    {
      atomic_fetch_add_explicit((atomic_ullong *volatile)(*((void *)&v9 + 1) + 8), 1uLL, memory_order_relaxed);
      uint64_t v8 = *a3;
    }
    long long v10 = *(_OWORD *)(v8 + 16 * v5);
    *(_OWORD *)unint64_t v45 = v10;
    if (*((void *)&v10 + 1)) {
      atomic_fetch_add_explicit((atomic_ullong *volatile)(*((void *)&v10 + 1) + 8), 1uLL, memory_order_relaxed);
    }
    uint64_t LayerTID = ZinIrHazardNode::GetLayerTID((ZinIrHazardNode *)v9);
    if (LayerTID >= ZinIrHazardNode::GetLayerTID(v45[0]))
    {
      unint64_t v16 = v5 + 1;
      if (v5 + 1 >= (a3[1] - *a3) >> 4
        || (uint64_t v17 = ZinIrHazardNode::GetLayerTID(*(ZinIrHazardNode **)(*a3 + 16 * v16)),
            v17 >= ZinIrHazardNode::GetLayerTID(v46[0])))
      {
        if (*((_DWORD *)v45[0] + 5) == 1 && !*((_DWORD *)v46[0] + 5) && *(void *)v45[0] != *(void *)v46[0])
        {
          uint64_t LayerSchedule = ZinIrHazardNode::GetLayerSchedule(v45[0]);
          if (LayerSchedule == ZinIrHazardNode::GetLayerSchedule(v46[0])
            && *((_DWORD *)v45[0] + 4) == 3
            && *((_DWORD *)v46[0] + 4) <= 2u)
          {
            ZinMirL2HazardAnalysis::CreateHazardEdge((uint64_t *)a1, (ZinIrHazardNode **)(*a3 + 16 * v5 - 16), v46);
            uint64_t v19 = (ZinIrHazardNode **)(*a2 + 16 * v6 + 16);
          }
          else
          {
            uint64_t v19 = v46;
          }
          ZinMirL2HazardAnalysis::CreateHazardEdge((uint64_t *)a1, v45, v19);
        }
      }
      if (*((_DWORD *)v45[0] + 5) == 1 && *((_DWORD *)v45[0] + 4) == 3 && v16 < (a3[1] - *a3) >> 4)
      {
        uint64_t v31 = *a3 + 16 * v16;
        unint64_t v33 = *(ZinIrHazardNode **)v31;
        unint64_t v32 = *(std::__shared_weak_count **)(v31 + 8);
        if (v32) {
          atomic_fetch_add_explicit(&v32->__shared_owners_, 1uLL, memory_order_relaxed);
        }
        uint64_t v42 = v32;
        unint64_t v34 = v6 + 1;
        do
        {
          if (v34 >= (uint64_t)(a2[1] - *a2) >> 4) {
            break;
          }
          uint64_t v35 = ZinIrHazardNode::GetLayerTID(*(ZinIrHazardNode **)(*a2 + 16 * v34));
          if (v35 > ZinIrHazardNode::GetLayerTID(v33)) {
            break;
          }
          long long v36 = *(_OWORD *)(*a2 + 16 * v34);
          long long v44 = v36;
          if (*((void *)&v36 + 1)) {
            atomic_fetch_add_explicit((atomic_ullong *volatile)(*((void *)&v36 + 1) + 8), 1uLL, memory_order_relaxed);
          }
          uint64_t v37 = ZinIrHazardNode::GetLayerTID((ZinIrHazardNode *)v36);
          unint64_t v38 = v37 - ZinIrHazardNode::GetLayerTID(v45[0]);
          unint64_t v39 = *(void *)(v7 + 1096);
          if (v38 < v39)
          {
            if (*(_DWORD *)(v44 + 16) <= 2u && !*(_DWORD *)(v44 + 20)) {
              ZinMirL2HazardAnalysis::CreateHazardEdge((uint64_t *)a1, v45, (ZinIrHazardNode **)&v44);
            }
            ++v34;
          }
          if (*((void *)&v44 + 1)) {
            std::__shared_weak_count::__release_shared[abi:ne180100](*((std::__shared_weak_count **)&v44 + 1));
          }
        }
        while (v38 < v39);
        if (v42) {
          std::__shared_weak_count::__release_shared[abi:ne180100](v42);
        }
      }
      if (v5 >= ((a3[1] - *a3) >> 4) - 1)
      {
        if (v6 + 1 >= (uint64_t)(a2[1] - *a2) >> 4
          || (unint64_t v40 = ZinIrHazardNode::GetLayerTID(*(ZinIrHazardNode **)(*a2 + 16 * (v6 + 1))),
              v40 >= *(void *)(v7 + 1096) + ZinIrHazardNode::GetLayerTID(v45[0])))
        {
LABEL_81:
          char v29 = 0;
          goto LABEL_82;
        }
        char v29 = 1;
        ++v6;
      }
      else
      {
        char v29 = 1;
        ++v5;
      }
    }
    else
    {
      unint64_t v12 = v6 + 1;
      if (v6 + 1 >= (uint64_t)(a2[1] - *a2) >> 4
        || (uint64_t v13 = ZinIrHazardNode::GetLayerTID(*(ZinIrHazardNode **)(*a2 + 16 * v12)),
            v13 >= ZinIrHazardNode::GetLayerTID(v45[0])))
      {
        if (*((_DWORD *)v46[0] + 5) == 1 && !*((_DWORD *)v45[0] + 5) && *(void *)v46[0] != *(void *)v45[0])
        {
          uint64_t v14 = ZinIrHazardNode::GetLayerSchedule(v46[0]);
          if (v14 == ZinIrHazardNode::GetLayerSchedule(v45[0])
            && *((_DWORD *)v46[0] + 4) == 3
            && *((_DWORD *)v45[0] + 4) <= 2u)
          {
            ZinMirL2HazardAnalysis::CreateHazardEdge((uint64_t *)a1, (ZinIrHazardNode **)(*a2 + 16 * v6 - 16), v45);
            uint64_t v15 = (ZinIrHazardNode **)(*a3 + 16 * v5 + 16);
          }
          else
          {
            uint64_t v15 = v45;
          }
          ZinMirL2HazardAnalysis::CreateHazardEdge((uint64_t *)a1, v46, v15);
        }
      }
      if (*((_DWORD *)v46[0] + 5) == 1 && *((_DWORD *)v46[0] + 4) == 3 && v12 < (uint64_t)(a2[1] - *a2) >> 4)
      {
        uint64_t v20 = *a2 + 16 * v12;
        uint64_t v22 = *(ZinIrHazardNode **)v20;
        long long v21 = *(std::__shared_weak_count **)(v20 + 8);
        if (v21) {
          atomic_fetch_add_explicit(&v21->__shared_owners_, 1uLL, memory_order_relaxed);
        }
        uint64_t v41 = v21;
        unint64_t v23 = v5 + 1;
        do
        {
          if (v23 >= (a3[1] - *a3) >> 4) {
            break;
          }
          uint64_t v24 = ZinIrHazardNode::GetLayerTID(*(ZinIrHazardNode **)(*a3 + 16 * v23));
          if (v24 > ZinIrHazardNode::GetLayerTID(v22)) {
            break;
          }
          long long v25 = *(_OWORD *)(*a3 + 16 * v23);
          long long v44 = v25;
          if (*((void *)&v25 + 1)) {
            atomic_fetch_add_explicit((atomic_ullong *volatile)(*((void *)&v25 + 1) + 8), 1uLL, memory_order_relaxed);
          }
          uint64_t v26 = ZinIrHazardNode::GetLayerTID((ZinIrHazardNode *)v25);
          unint64_t v27 = v26 - ZinIrHazardNode::GetLayerTID(v46[0]);
          unint64_t v28 = *(void *)(v7 + 1096);
          if (v27 < v28)
          {
            if (*(_DWORD *)(v44 + 16) <= 2u && !*(_DWORD *)(v44 + 20)) {
              ZinMirL2HazardAnalysis::CreateHazardEdge((uint64_t *)a1, v46, (ZinIrHazardNode **)&v44);
            }
            ++v23;
          }
          if (*((void *)&v44 + 1)) {
            std::__shared_weak_count::__release_shared[abi:ne180100](*((std::__shared_weak_count **)&v44 + 1));
          }
        }
        while (v27 < v28);
        if (v41) {
          std::__shared_weak_count::__release_shared[abi:ne180100](v41);
        }
      }
      if (v6 >= ((uint64_t)(a2[1] - *a2) >> 4) - 1)
      {
        if (v5 + 1 >= (a3[1] - *a3) >> 4) {
          goto LABEL_81;
        }
        unint64_t v30 = ZinIrHazardNode::GetLayerTID(*(ZinIrHazardNode **)(*a3 + 16 * (v5 + 1)));
        if (v30 >= *(void *)(v7 + 1096) + ZinIrHazardNode::GetLayerTID(v46[0])) {
          goto LABEL_81;
        }
        char v29 = 1;
        ++v5;
      }
      else
      {
        char v29 = 1;
        ++v6;
      }
    }
LABEL_82:
    if (v45[1]) {
      std::__shared_weak_count::__release_shared[abi:ne180100]((std::__shared_weak_count *)v45[1]);
    }
    if (v46[1]) {
      std::__shared_weak_count::__release_shared[abi:ne180100]((std::__shared_weak_count *)v46[1]);
    }
  }
  while ((v29 & 1) != 0);
}

void sub_211394C10(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, std::__shared_weak_count *a14, uint64_t a15, std::__shared_weak_count *a16)
{
  if (a14) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a14);
  }
  if (a16) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a16);
  }
  _Unwind_Resume(exception_object);
}

void ZinMirL2HazardAnalysis::CreateDotFile(uint64_t *****a1, uint64_t a2, unint64_t a3, unint64_t a4)
{
  v94[19] = *MEMORY[0x263EF8340];
  uint64_t v7 = a1[3][1];
  if (*((char *)v7 + 47) >= 0) {
    size_t v8 = *((unsigned __int8 *)v7 + 47);
  }
  else {
    size_t v8 = (size_t)v7[4];
  }
  long long v9 = &v93;
  std::string::basic_string[abi:ne180100]((uint64_t)&v93, v8 + 1);
  if ((v93.__r_.__value_.__r.__words[2] & 0x8000000000000000) != 0) {
    long long v9 = (std::string *)v93.__r_.__value_.__r.__words[0];
  }
  if (v8)
  {
    unint64_t v12 = (char *)v7[3];
    long long v11 = (char *)(v7 + 3);
    long long v10 = v12;
    if (v11[23] >= 0) {
      uint64_t v13 = v11;
    }
    else {
      uint64_t v13 = v10;
    }
    memmove(v9, v13, v8);
  }
  *(_WORD *)((char *)&v9->__r_.__value_.__l.__data_ + v8) = 46;
  int v14 = *(char *)(a2 + 23);
  if (v14 >= 0) {
    uint64_t v15 = (const std::string::value_type *)a2;
  }
  else {
    uint64_t v15 = *(const std::string::value_type **)a2;
  }
  if (v14 >= 0) {
    std::string::size_type v16 = *(unsigned __int8 *)(a2 + 23);
  }
  else {
    std::string::size_type v16 = *(void *)(a2 + 8);
  }
  uint64_t v17 = std::string::append(&v93, v15, v16);
  long long v18 = *(_OWORD *)&v17->__r_.__value_.__l.__data_;
  std::string::size_type v91 = v17->__r_.__value_.__r.__words[2];
  *(_OWORD *)BOOL v90 = v18;
  v17->__r_.__value_.__l.__size_ = 0;
  v17->__r_.__value_.__r.__words[2] = 0;
  v17->__r_.__value_.__r.__words[0] = 0;
  if (SHIBYTE(v93.__r_.__value_.__r.__words[2]) < 0) {
    operator delete(v93.__r_.__value_.__l.__data_);
  }
  uint64_t v19 = MEMORY[0x263F8C310] + 64;
  v94[0] = MEMORY[0x263F8C310] + 64;
  std::string::size_type v20 = *(void *)(MEMORY[0x263F8C2B0] + 16);
  v93.__r_.__value_.__r.__words[0] = *(void *)(MEMORY[0x263F8C2B0] + 8);
  *(std::string::size_type *)((char *)v93.__r_.__value_.__r.__words + *(void *)(v93.__r_.__value_.__r.__words[0] - 24)) = v20;
  long long v21 = (std::ios_base *)((char *)&v93 + *(void *)(v93.__r_.__value_.__r.__words[0] - 24));
  std::ios_base::init(v21, &v93.__r_.__value_.__r.__words[1]);
  uint64_t v22 = MEMORY[0x263F8C310] + 24;
  v21[1].__vftable = 0;
  v21[1].__fmtflags_ = -1;
  v93.__r_.__value_.__r.__words[0] = v22;
  v94[0] = v19;
  MEMORY[0x21667CDD0](&v93.__r_.__value_.__r.__words[1]);
  std::ofstream::open();
  unint64_t v23 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v93, (uint64_t)"digraph D {", 11);
  std::ios_base::getloc((const std::ios_base *)((char *)v23 + *(void *)(*v23 - 24)));
  uint64_t v24 = std::locale::use_facet(&v84, MEMORY[0x263F8C108]);
  ((void (*)(const std::locale::facet *, uint64_t))v24->__vftable[2].~facet_0)(v24, 10);
  std::locale::~locale(&v84);
  std::ostream::put();
  std::ostream::flush();
  long long v25 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v93, (uint64_t)"\tnode [shape=box style=\"rounded, filled\"]", 41);
  std::ios_base::getloc((const std::ios_base *)((char *)v25 + *(void *)(*v25 - 24)));
  uint64_t v26 = std::locale::use_facet(&v84, MEMORY[0x263F8C108]);
  ((void (*)(const std::locale::facet *, uint64_t))v26->__vftable[2].~facet_0)(v26, 10);
  std::locale::~locale(&v84);
  std::ostream::put();
  std::ostream::flush();
  uint64_t v28 = (uint64_t)(*a1 + 1);
  unint64_t v27 = **a1;
  if (v27 != (uint64_t ***)v28)
  {
    int v74 = *(std::locale::__imp **)(MEMORY[0x263F8C2B8] + 64);
    uint64_t v75 = (std::locale::__imp *)*MEMORY[0x263F8C2B8];
    uint64_t v73 = *(void *)(MEMORY[0x263F8C2B8] + 72);
    do
    {
      if (ZinIrHazardNode::GetLayerTID((ZinIrHazardNode *)v27[4]) >= a3
        && ZinIrHazardNode::GetLayerTID((ZinIrHazardNode *)v27[4]) <= a4)
      {
        uint64_t v29 = std::basic_stringstream<char,std::char_traits<char>,std::allocator<char>>::basic_stringstream[abi:ne180100]((uint64_t)&v84);
        ZinMirL2HazardAnalysis::DebugPrintNode(v29, v27 + 4, (uint64_t)&v84, 1);
        std::stringbuf::str[abi:ne180100]<std::allocator<char>>((uint64_t)v87, &__p);
        if ((__p.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
          p_p = &__p;
        }
        else {
          p_p = (std::string *)__p.__r_.__value_.__r.__words[0];
        }
        if ((__p.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
          std::string::size_type size = HIBYTE(__p.__r_.__value_.__r.__words[2]);
        }
        else {
          std::string::size_type size = __p.__r_.__value_.__l.__size_;
        }
        std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v93, (uint64_t)p_p, size);
        if (SHIBYTE(__p.__r_.__value_.__r.__words[2]) < 0) {
          operator delete(__p.__r_.__value_.__l.__data_);
        }
        v84.__locale_ = v75;
        *(std::locale::__imp **)((char *)&v84.__locale_ + *((void *)v75 - 3)) = v74;
        uint64_t v86 = v73;
        v87[0] = MEMORY[0x263F8C318] + 16;
        if (v88 < 0) {
          operator delete((void *)v87[8]);
        }
        std::streambuf::~streambuf();
        std::iostream::~basic_iostream();
        MEMORY[0x21667D2B0](&v89);
      }
      unint64_t v32 = v27[1];
      if (v32)
      {
        do
        {
          unint64_t v33 = (uint64_t ***)v32;
          unint64_t v32 = (uint64_t **)*v32;
        }
        while (v32);
      }
      else
      {
        do
        {
          unint64_t v33 = (uint64_t ***)v27[2];
          BOOL v34 = *v33 == (uint64_t **)v27;
          unint64_t v27 = v33;
        }
        while (!v34);
      }
      unint64_t v27 = v33;
    }
    while (v33 != (uint64_t ***)v28);
  }
  std::ios_base::getloc((const std::ios_base *)((char *)&v93 + *(void *)(v93.__r_.__value_.__r.__words[0] - 24)));
  uint64_t v35 = std::locale::use_facet(&v84, MEMORY[0x263F8C108]);
  ((void (*)(const std::locale::facet *, uint64_t))v35->__vftable[2].~facet_0)(v35, 10);
  std::locale::~locale(&v84);
  std::ostream::put();
  std::ostream::flush();
  uint64_t v36 = (uint64_t)(*a1 + 1);
  uint64_t v37 = **a1;
  if (v37 != (uint64_t ***)v36)
  {
    do
    {
      unint64_t v38 = (ZinIrHazardNode **)(v37 + 4);
      unint64_t v39 = *a1;
      unint64_t v40 = *a1 + 3;
      v84.__locale_ = (std::locale::__imp *)(v37 + 4);
      uint64_t v41 = std::__hash_table<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::__unordered_map_hasher<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::__unordered_map_equal<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>>>::find<std::reference_wrapper<ZinIrOpLayer * const>>(v40, (unint64_t **)&v84);
      uint64_t v42 = (uint64_t **)(v39 + 13);
      if (v41) {
        uint64_t v42 = v41 + 3;
      }
      long long v44 = (ZinIrHazardNode ***)*v42;
      uint64_t v43 = (ZinIrHazardNode ***)v42[1];
      while (v44 != v43)
      {
        unint64_t v45 = *v44;
        if (ZinIrHazardNode::GetLayerTID(*v38) >= a3
          && ZinIrHazardNode::GetLayerTID(*v38) <= a4
          && ZinIrHazardNode::GetLayerTID(*v45) >= a3
          && ZinIrHazardNode::GetLayerTID(*v45) <= a4)
        {
          int v82 = 0;
          uint64_t v46 = *a1;
          char v47 = (std::__shared_weak_count *)v37[5];
          uint64_t v80 = v37[4];
          uint64_t v81 = v47;
          if (v47) {
            atomic_fetch_add_explicit(&v47->__shared_owners_, 1uLL, memory_order_relaxed);
          }
          uint64_t v48 = (std::__shared_weak_count *)v45[1];
          uint64_t v78 = *v45;
          int v79 = v48;
          if (v48) {
            atomic_fetch_add_explicit(&v48->__shared_owners_, 1uLL, memory_order_relaxed);
          }
          ZinIrHazardGraph::GetEdgeType((uint64_t)v46, (unint64_t *)&v80, (uint64_t *)&v78, &v82);
          if (v79) {
            std::__shared_weak_count::__release_shared[abi:ne180100](v79);
          }
          if (v81) {
            std::__shared_weak_count::__release_shared[abi:ne180100](v81);
          }
          if (v82) {
            uint64_t v49 = "black";
          }
          else {
            uint64_t v49 = "blue";
          }
          std::string::basic_string[abi:ne180100]<0>(&v84, v49);
          BOOL v50 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v93, (uint64_t)"\t", 1);
          uint64_t v51 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v50, (uint64_t)"\"", 1);
          uint64_t v52 = *v38;
          if (*((char *)*v38 + 47) < 0) {
            std::string::__init_copy_ctor_external(&__p, *((const std::string::value_type **)v52 + 3), *((void *)v52 + 4));
          }
          else {
            std::string __p = *(std::string *)((unsigned char *)v52 + 1);
          }
          if ((__p.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
            uint64_t v53 = &__p;
          }
          else {
            uint64_t v53 = (std::string *)__p.__r_.__value_.__r.__words[0];
          }
          if ((__p.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
            std::string::size_type v54 = HIBYTE(__p.__r_.__value_.__r.__words[2]);
          }
          else {
            std::string::size_type v54 = __p.__r_.__value_.__l.__size_;
          }
          uint64_t v55 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v51, (uint64_t)v53, v54);
          uint64_t v56 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v55, (uint64_t)"\"", 1);
          int v57 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v56, (uint64_t)" -> ", 4);
          uint64_t v58 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v57, (uint64_t)"\"", 1);
          uint64_t v59 = (std::string *)*v45;
          if (*((char *)*v45 + 47) < 0) {
            std::string::__init_copy_ctor_external(&v77, v59[1].__r_.__value_.__l.__data_, v59[1].__r_.__value_.__l.__size_);
          }
          else {
            std::string v77 = v59[1];
          }
          if ((v77.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
            int v60 = &v77;
          }
          else {
            int v60 = (std::string *)v77.__r_.__value_.__r.__words[0];
          }
          if ((v77.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
            std::string::size_type v61 = HIBYTE(v77.__r_.__value_.__r.__words[2]);
          }
          else {
            std::string::size_type v61 = v77.__r_.__value_.__l.__size_;
          }
          uint64_t v62 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v58, (uint64_t)v60, v61);
          unint64_t v63 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v62, (uint64_t)"\"", 1);
          uint64_t v64 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v63, (uint64_t)"[color=", 7);
          if (v86 >= 0) {
            locale = &v84;
          }
          else {
            locale = v84.__locale_;
          }
          if (v86 >= 0) {
            uint64_t v66 = HIBYTE(v86);
          }
          else {
            uint64_t v66 = v85;
          }
          uint64_t v67 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v64, (uint64_t)locale, v66);
          uint64_t v68 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v67, (uint64_t)"]", 1);
          std::ios_base::getloc((const std::ios_base *)((char *)v68 + *(void *)(*v68 - 24)));
          uint64_t v69 = std::locale::use_facet(&v92, MEMORY[0x263F8C108]);
          ((void (*)(const std::locale::facet *, uint64_t))v69->__vftable[2].~facet_0)(v69, 10);
          std::locale::~locale(&v92);
          std::ostream::put();
          std::ostream::flush();
          if (SHIBYTE(v77.__r_.__value_.__r.__words[2]) < 0) {
            operator delete(v77.__r_.__value_.__l.__data_);
          }
          if (SHIBYTE(__p.__r_.__value_.__r.__words[2]) < 0) {
            operator delete(__p.__r_.__value_.__l.__data_);
          }
          if (SHIBYTE(v86) < 0) {
            operator delete(v84.__locale_);
          }
        }
        ++v44;
      }
      uint64_t v70 = v37[1];
      if (v70)
      {
        do
        {
          uint64_t v71 = (uint64_t ***)v70;
          uint64_t v70 = (uint64_t **)*v70;
        }
        while (v70);
      }
      else
      {
        do
        {
          uint64_t v71 = (uint64_t ***)v37[2];
          BOOL v34 = *v71 == (uint64_t **)v37;
          uint64_t v37 = v71;
        }
        while (!v34);
      }
      uint64_t v37 = v71;
    }
    while (v71 != (uint64_t ***)v36);
  }
  std::ios_base::getloc((const std::ios_base *)((char *)&v93 + *(void *)(v93.__r_.__value_.__r.__words[0] - 24)));
  uint64_t v72 = std::locale::use_facet(&v84, MEMORY[0x263F8C108]);
  ((void (*)(const std::locale::facet *, uint64_t))v72->__vftable[2].~facet_0)(v72, 10);
  std::locale::~locale(&v84);
  std::ostream::put();
  std::ostream::flush();
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v93, (uint64_t)"}", 1);
  if (!std::filebuf::close()) {
    std::ios_base::clear((std::ios_base *)((char *)&v93 + *(void *)(v93.__r_.__value_.__r.__words[0] - 24)), *(_DWORD *)((char *)&v93 + *(void *)(v93.__r_.__value_.__r.__words[0] - 24) + 32) | 4);
  }
  v93.__r_.__value_.__r.__words[0] = *MEMORY[0x263F8C2B0];
  *(std::string::size_type *)((char *)v93.__r_.__value_.__r.__words + *(void *)(v93.__r_.__value_.__r.__words[0] - 24)) = *(void *)(MEMORY[0x263F8C2B0] + 24);
  MEMORY[0x21667CDE0](&v93.__r_.__value_.__r.__words[1]);
  std::ostream::~ostream();
  MEMORY[0x21667D2B0](v94);
  if (SHIBYTE(v91) < 0) {
    operator delete(v90[0]);
  }
}

void sub_211395740(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, void *a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,void *a23,uint64_t a24,uint64_t a25,std::locale a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33,uint64_t a34,uint64_t a35,uint64_t a36,uint64_t a37,uint64_t a38,uint64_t a39,uint64_t a40,uint64_t a41,uint64_t a42,uint64_t a43,uint64_t a44,uint64_t a45,uint64_t a46,uint64_t a47,uint64_t a48,uint64_t a49,uint64_t a50,uint64_t a51,uint64_t a52,uint64_t a53,uint64_t a54,uint64_t a55,uint64_t a56,uint64_t a57,uint64_t a58,uint64_t a59,uint64_t a60,void *__p,uint64_t a62,int a63)
{
  std::ostream::~ostream();
  MEMORY[0x21667D2B0](a10);
  if (a66 < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(a1);
}

uint64_t ZinIrNgraphUtils::TransitiveReduction<ZinIrHazardGraph>(void *a1, unint64_t a2)
{
  uint64_t v49 = (uint64_t)&v49;
  BOOL v50 = &v49;
  uint64_t v51 = 0;
  if (ZinIrNgraph<std::shared_ptr<ZinIrHazardNode>,HazardNodeCompare>::TopologicalSortImpl<std::list<std::shared_ptr<ZinIrHazardNode>>>(a1, &v49))
  {
    memset(v47, 0, sizeof(v47));
    int v48 = 1065353216;
    if (a2 != -1)
    {
      ZinIrNgraphUtils::impl::CalculateAsapSchedules<ZinIrHazardGraph>(a1, (uint64_t)v45);
      std::__hash_table<std::__hash_value_type<std::shared_ptr<ZinIrHazardNode>,long>,std::__unordered_map_hasher<std::shared_ptr<ZinIrHazardNode>,std::__hash_value_type<std::shared_ptr<ZinIrHazardNode>,long>,std::hash<std::shared_ptr<ZinIrHazardNode>>,std::equal_to<std::shared_ptr<ZinIrHazardNode>>,true>,std::__unordered_map_equal<std::shared_ptr<ZinIrHazardNode>,std::__hash_value_type<std::shared_ptr<ZinIrHazardNode>,long>,std::equal_to<std::shared_ptr<ZinIrHazardNode>>,std::hash<std::shared_ptr<ZinIrHazardNode>>,true>,std::allocator<std::__hash_value_type<std::shared_ptr<ZinIrHazardNode>,long>>>::__move_assign((uint64_t)v47, v45);
      std::__hash_table<std::__hash_value_type<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>,long>,std::__unordered_map_hasher<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>,std::__hash_value_type<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>,long>,std::hash<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>>,std::equal_to<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>>,true>,std::__unordered_map_equal<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>,std::__hash_value_type<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>,long>,std::equal_to<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>>,std::hash<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>>,true>,std::allocator<std::__hash_value_type<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>,long>>>::~__hash_table((uint64_t)v45);
    }
    memset(v45, 0, sizeof(v45));
    int v46 = 1065353216;
    unint64_t v3 = v50;
    if (v50 == &v49)
    {
      char v31 = 0;
      long long v42 = 0uLL;
      long long v43 = 0uLL;
      int v44 = 1065353216;
    }
    else
    {
      do
      {
        *(void *)&v37[0] = v3 + 2;
        *(void *)&long long v42 = v37;
        *((_DWORD *)std::__hash_table<std::__hash_value_type<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,int>,std::__unordered_map_hasher<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::__hash_value_type<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,int>,std::hash<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,std::equal_to<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,true>,std::__unordered_map_equal<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::__hash_value_type<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,int>,std::equal_to<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,std::hash<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,int>>>::__emplace_unique_key_args<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::piecewise_construct_t const&,std::tuple<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>&&>,std::tuple<>>((uint64_t)v45, (unint64_t **)v37, (uint64_t)&std::piecewise_construct, (void **)&v42)+ 6) = 0;
        unint64_t v3 = (uint64_t *)v3[1];
      }
      while (v3 != &v49);
      uint64_t v4 = v50;
      long long v42 = 0u;
      long long v43 = 0u;
      int v44 = 1065353216;
      if (v50 == &v49)
      {
        char v31 = 0;
      }
      else
      {
        char v31 = 0;
        do
        {
          *(void *)&v37[0] = v4 + 2;
          unint64_t v5 = std::__hash_table<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::__unordered_map_hasher<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::__unordered_map_equal<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>>>::find<std::reference_wrapper<ZinIrOpLayer * const>>(a1 + 8, (unint64_t **)v37);
          unint64_t v6 = v5 + 3;
          if (!v5) {
            unint64_t v6 = (uint64_t **)(a1 + 13);
          }
          unint64_t v40 = 0;
          uint64_t v41 = 0;
          std::string __p = 0;
          std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(&__p, *v6, (uint64_t)v6[1], v6[1] - *v6);
          memset(v37, 0, sizeof(v37));
          int v38 = 1065353216;
          uint64_t v7 = (unint64_t **)__p;
          size_t v8 = v40;
          if (__p != v40)
          {
            do
            {
              long long v9 = *v7;
              uint64_t v36 = *v7;
              v52[0] = &v36;
              for (uint64_t i = std::__hash_table<std::__hash_value_type<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::unordered_set<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>,std::__unordered_map_hasher<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::__hash_value_type<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::unordered_set<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>,std::hash<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,std::equal_to<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,true>,std::__unordered_map_equal<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::__hash_value_type<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::unordered_set<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>,std::equal_to<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,std::hash<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::unordered_set<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>>>::__emplace_unique_key_args<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::piecewise_construct_t const&,std::tuple<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>&&>,std::tuple<>>((uint64_t)&v42, &v36, (uint64_t)&std::piecewise_construct, v52)[5]; i; uint64_t i = (uint64_t *)*i)
              {
                long long v11 = (void *)i[2];
                if (a2 != -1)
                {
                  unint64_t v12 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(v47, v9);
                  uint64_t v13 = v12 ? v12[4] : -1;
                  int v14 = std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>(v47, v11);
                  uint64_t v15 = v14 ? v14[4] : -1;
                  if (v13 - v15 > a2) {
                    continue;
                  }
                }
                v52[0] = v11;
                std::__hash_table<std::reference_wrapper<ZinIrOpLayer * const>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,std::allocator<std::reference_wrapper<ZinIrOpLayer * const>>>::__emplace_unique_key_args<std::reference_wrapper<ZinIrOpLayer * const>,std::reference_wrapper<ZinIrOpLayer * const> const&>((uint64_t)v37, v52, v52);
              }
              v52[0] = v9;
              std::string::size_type v16 = std::__hash_table<std::__hash_value_type<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::vector<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>,std::__unordered_map_hasher<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::__hash_value_type<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::vector<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>,std::hash<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,std::equal_to<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,true>,std::__unordered_map_equal<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::__hash_value_type<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::vector<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>,std::equal_to<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,std::hash<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::vector<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>>>::find<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>(v45, v52);
              v52[0] = v9;
              uint64_t v17 = std::__hash_table<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::__unordered_map_hasher<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::__unordered_map_equal<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>>>::find<std::reference_wrapper<ZinIrOpLayer * const>>(a1 + 3, v52);
              long long v18 = v17 + 3;
              if (!v17) {
                long long v18 = a1 + 13;
              }
              uint64_t v19 = v18[1] - *v18;
              uint64_t v20 = *((int *)v16 + 6) + 1;
              *((_DWORD *)v16 + 6) = v20;
              if (v20 == v19 >> 3)
              {
                v52[0] = v9;
                std::__hash_table<std::__hash_value_type<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::unordered_set<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>,std::__unordered_map_hasher<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::__hash_value_type<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::unordered_set<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>,std::hash<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,std::equal_to<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,true>,std::__unordered_map_equal<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::__hash_value_type<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::unordered_set<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>,std::equal_to<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,std::hash<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::unordered_set<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>>>::__erase_unique<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>(&v42, v52);
              }
              ++v7;
            }
            while (v7 != v8);
            long long v21 = (unint64_t **)__p;
            uint64_t v22 = v40;
            while (v21 != v22)
            {
              unint64_t v23 = *v21;
              v52[0] = *v21;
              if (std::__hash_table<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::__unordered_map_hasher<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::__unordered_map_equal<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>>>::find<std::reference_wrapper<ZinIrOpLayer * const>>(v37, v52))
              {
                uint64_t v24 = (std::__shared_weak_count *)v23[1];
                unint64_t v34 = *v23;
                uint64_t v35 = v24;
                if (v24) {
                  atomic_fetch_add_explicit(&v24->__shared_owners_, 1uLL, memory_order_relaxed);
                }
                long long v25 = (std::__shared_weak_count *)v4[3];
                uint64_t v32 = v4[2];
                unint64_t v33 = v25;
                if (v25) {
                  atomic_fetch_add_explicit(&v25->__shared_owners_, 1uLL, memory_order_relaxed);
                }
                char v26 = ZinIrHazardGraph::RemoveEdge((uint64_t)a1, (uint64_t *)&v34, &v32);
                if (v33) {
                  std::__shared_weak_count::__release_shared[abi:ne180100](v33);
                }
                if (v35) {
                  std::__shared_weak_count::__release_shared[abi:ne180100](v35);
                }
                v31 |= v26;
              }
              else
              {
                v52[0] = v23;
                std::__hash_table<std::reference_wrapper<ZinIrOpLayer * const>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,std::allocator<std::reference_wrapper<ZinIrOpLayer * const>>>::__emplace_unique_key_args<std::reference_wrapper<ZinIrOpLayer * const>,std::reference_wrapper<ZinIrOpLayer * const> const&>((uint64_t)v37, v52, v52);
              }
              ++v21;
            }
          }
          uint64_t v36 = (unint64_t *)(v4 + 2);
          v52[0] = &v36;
          unint64_t v27 = std::__hash_table<std::__hash_value_type<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::unordered_set<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>,std::__unordered_map_hasher<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::__hash_value_type<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::unordered_set<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>,std::hash<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,std::equal_to<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,true>,std::__unordered_map_equal<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::__hash_value_type<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::unordered_set<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>,std::equal_to<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,std::hash<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::unordered_set<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>>>::__emplace_unique_key_args<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::piecewise_construct_t const&,std::tuple<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>&&>,std::tuple<>>((uint64_t)&v42, &v36, (uint64_t)&std::piecewise_construct, v52);
          std::__hash_table<std::__hash_value_type<ZinDependencyOffsetDim,long>,std::__unordered_map_hasher<ZinDependencyOffsetDim,std::__hash_value_type<ZinDependencyOffsetDim,long>,std::hash<ZinDependencyOffsetDim>,std::equal_to<ZinDependencyOffsetDim>,true>,std::__unordered_map_equal<ZinDependencyOffsetDim,std::__hash_value_type<ZinDependencyOffsetDim,long>,std::equal_to<ZinDependencyOffsetDim>,std::hash<ZinDependencyOffsetDim>,true>,std::allocator<std::__hash_value_type<ZinDependencyOffsetDim,long>>>::__move_assign((uint64_t)(v27 + 3), (uint64_t *)v37);
          std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v37);
          if (__p)
          {
            unint64_t v40 = (unint64_t **)__p;
            operator delete(__p);
          }
          uint64_t v4 = (uint64_t *)v4[1];
        }
        while (v4 != &v49);
      }
    }
    std::__hash_table<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::__unordered_map_hasher<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::hash<long>,std::equal_to<long>,true>,std::__unordered_map_equal<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::equal_to<long>,std::hash<long>,true>,std::allocator<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>>>::~__hash_table((uint64_t)&v42);
    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v45);
    std::__hash_table<std::__hash_value_type<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>,long>,std::__unordered_map_hasher<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>,std::__hash_value_type<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>,long>,std::hash<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>>,std::equal_to<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>>,true>,std::__unordered_map_equal<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>,std::__hash_value_type<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>,long>,std::equal_to<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>>,std::hash<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>>,true>,std::allocator<std::__hash_value_type<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>,long>>>::~__hash_table((uint64_t)v47);
    char v28 = v31;
  }
  else
  {
    char v28 = 0;
  }
  std::__list_imp<std::shared_ptr<ZinMirUnit>>::clear(&v49);
  return v28 & 1;
}

void sub_211395C78(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, char a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,void *__p,uint64_t a25,uint64_t a26,char a27,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,char a33)
{
  std::__hash_table<std::__hash_value_type<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>,long>,std::__unordered_map_hasher<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>,std::__hash_value_type<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>,long>,std::hash<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>>,std::equal_to<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>>,true>,std::__unordered_map_equal<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>,std::__hash_value_type<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>,long>,std::equal_to<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>>,std::hash<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>>,true>,std::allocator<std::__hash_value_type<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>,long>>>::~__hash_table(v33 - 176);
  std::__list_imp<std::shared_ptr<ZinMirUnit>>::clear((uint64_t *)(v33 - 136));
  _Unwind_Resume(a1);
}

BOOL ZinMirL2HazardAnalysis::TryDependencyBitSet(ZinMirL2HazardAnalysis *this, ZinANELayer *a2, ZinANELayer *a3)
{
  uint64_t v38 = *MEMORY[0x263EF8340];
  std::string __p = 0;
  unint64_t v30 = 0;
  uint64_t v31 = 0;
  memset(v27, 0, sizeof(v27));
  int v28 = 1065353216;
  if ((ZinMirL2HazardAnalysis::IsQualifiedForDependentMode((uint64_t)this, a2, (uint64_t)a3, (char **)&__p, (uint64_t)v27) & 1) == 0)
  {
    BOOL v8 = 0;
    goto LABEL_6;
  }
  uint64_t v6 = *((void *)a3 + 33);
  int v26 = 0;
  int L2SrcType = ZinMemSourceIndexTranslator::GetL2SrcType(a3, *(void *)__p, &v26);
  BOOL v8 = L2SrcType == 0;
  if (L2SrcType)
  {
    if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
      ZinMirL2HazardAnalysis::TryDependencyBitSet();
    }
    goto LABEL_6;
  }
  if (ZinIrOpLayer::IsNELayer(a3)) {
    long long v10 = "NE";
  }
  else {
    long long v10 = "PE";
  }
  std::string::basic_string[abi:ne180100]<0>(v24, v10);
  long long v11 = (_DWORD *)(v6 + 120);
  if (ZinIrOpLayer::IsNELayer(a2))
  {
    uint64_t L2SrcDep = ZinMirL2Config::GetL2SrcDep(v6 + 120, v26);
    std::unordered_map<ZinDependencyOffsetDim,long>::unordered_map((uint64_t)v23, L2SrcDep + 8);
    int v22 = 1;
    ZinMirL2Config::SetL2SrcDep(v11, (uint64_t)&v22, v26);
    if ((*(unsigned char *)(*(void *)(*((void *)this + 3) + 8) + 96) & 0x10) != 0
      && os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_INFO))
    {
      uint64_t v13 = *((void *)a2 + 45);
      int v14 = v24;
      if (v25 < 0) {
        int v14 = (void **)v24[0];
      }
      uint64_t v15 = *((void *)a3 + 45);
      *(_DWORD *)uint8_t buf = 134218498;
      uint64_t v33 = v13;
      __int16 v34 = 2080;
      uint64_t v35 = v14;
      __int16 v36 = 2048;
      uint64_t v37 = v15;
      std::string::size_type v16 = &_os_log_internal;
      uint64_t v17 = "Info: kDependentConv is set to NE(TID=%zi) -> %s(TID=%zi)";
LABEL_23:
      _os_log_impl(&dword_210C72000, v16, OS_LOG_TYPE_INFO, v17, buf, 0x20u);
    }
  }
  else
  {
    uint64_t v18 = ZinMirL2Config::GetL2SrcDep(v6 + 120, v26);
    std::unordered_map<ZinDependencyOffsetDim,long>::unordered_map((uint64_t)v23, v18 + 8);
    int v22 = 2;
    ZinMirL2Config::SetL2SrcDep(v11, (uint64_t)&v22, v26);
    if ((*(unsigned char *)(*(void *)(*((void *)this + 3) + 8) + 96) & 0x10) != 0
      && os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_INFO))
    {
      uint64_t v19 = *((void *)a2 + 45);
      uint64_t v20 = v24;
      if (v25 < 0) {
        uint64_t v20 = (void **)v24[0];
      }
      uint64_t v21 = *((void *)a3 + 45);
      *(_DWORD *)uint8_t buf = 134218498;
      uint64_t v33 = v19;
      __int16 v34 = 2080;
      uint64_t v35 = v20;
      __int16 v36 = 2048;
      uint64_t v37 = v21;
      std::string::size_type v16 = &_os_log_internal;
      uint64_t v17 = "Info: kDependentPlanar is set to PE(TID=%zi) -> %s(TID=%zi)";
      goto LABEL_23;
    }
  }
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v23);
  if (v25 < 0) {
    operator delete(v24[0]);
  }
LABEL_6:
  std::__hash_table<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::__unordered_map_hasher<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::hash<long>,std::equal_to<long>,true>,std::__unordered_map_equal<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::equal_to<long>,std::hash<long>,true>,std::allocator<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>>>::~__hash_table((uint64_t)v27);
  if (__p)
  {
    unint64_t v30 = __p;
    operator delete(__p);
  }
  return v8;
}

void sub_211396004(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, void *__p, uint64_t a16, int a17, __int16 a18, char a19, char a20,uint64_t a21,char a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,void *a27,uint64_t a28)
{
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table(v28);
  if (a20 < 0) {
    operator delete(__p);
  }
  std::__hash_table<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::__unordered_map_hasher<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::hash<long>,std::equal_to<long>,true>,std::__unordered_map_equal<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::equal_to<long>,std::hash<long>,true>,std::allocator<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>>>::~__hash_table((uint64_t)&a22);
  if (a27)
  {
    a28 = (uint64_t)a27;
    operator delete(a27);
  }
  _Unwind_Resume(a1);
}

uint64_t ZinMirL2HazardAnalysis::SetFirstTdL2HazardBits(uint64_t this)
{
  if (*(_DWORD *)(**(void **)(this + 24) + 4))
  {
    uint64_t v1 = this;
    unint64_t v2 = 0;
    do
    {
      unint64_t v3 = (ZinIrOpLayer ****)(*(void *)(v1 + 384) + 24 * v2);
      uint64_t v4 = *v3;
      unint64_t v5 = v3[1];
LABEL_4:
      if (v4 != v5)
      {
        uint64_t v6 = *v4;
        uint64_t v7 = v4[1];
        while (1)
        {
          if (v6 == v7)
          {
            v4 += 3;
            goto LABEL_4;
          }
          BOOL v8 = *v6;
          this = ZinIrOpLayer::IsANELayer(*v6);
          if (this) {
            break;
          }
          ++v6;
        }
        uint64_t v9 = *((void *)v8 + 33);
        *(void *)(v9 + 328) = 0x101010101010101;
        *(void *)(v9 + 336) = 0x101010101010101;
      }
      ++v2;
    }
    while (v2 < *(int *)(**(void **)(v1 + 24) + 4));
  }
  return this;
}

uint64_t ZinMirL2HazardAnalysis::DebugPrintHazardResults(uint64_t this)
{
  uint64_t v93 = *MEMORY[0x263EF8340];
  if ((*(unsigned char *)(*(void *)(*(void *)(this + 24) + 8) + 96) & 0x10) != 0)
  {
    uint64_t v1 = this;
    if (*(unsigned char *)(this + 376))
    {
      std::basic_stringstream<char,std::char_traits<char>,std::allocator<char>>::basic_stringstream[abi:ne180100]((uint64_t)v86);
      unint64_t v2 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v87, (uint64_t)"\n[DEBUG_BEGIN] Hazard results", 29);
      std::ios_base::getloc((const std::ios_base *)((char *)v2 + *(void *)(*v2 - 24)));
      unint64_t v3 = std::locale::use_facet(__dst, MEMORY[0x263F8C108]);
      ((void (*)(const std::locale::facet *, uint64_t))v3->__vftable[2].~facet_0)(v3, 10);
      std::locale::~locale(__dst);
      std::ostream::put();
      std::ostream::flush();
      uint64_t v4 = **(void **)(v1 + 24);
      if (*(int *)(v4 + 4) >= 1)
      {
        uint64_t v5 = 0;
        uint64_t v6 = (std::locale::id *)MEMORY[0x263F8C108];
        uint64_t v73 = v1;
        do
        {
          uint64_t v74 = v5;
          uint64_t v7 = (uint64_t *)(*(void *)(v1 + 384) + 24 * v5);
          uint64_t v8 = *v7;
          uint64_t v75 = v7[1];
          if (*v7 != v75)
          {
            do
            {
              long long buf = 0uLL;
              uint64_t v92 = 0;
              uint64_t v76 = v8;
              std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(&buf, *(const void **)v8, *(void *)(v8 + 8), (uint64_t)(*(void *)(v8 + 8) - *(void *)v8) >> 3);
              uint64_t v9 = (char *)*((void *)&buf + 1);
              long long v10 = (char *)buf;
              if ((void)buf != *((void *)&buf + 1))
              {
                do
                {
                  long long v11 = *(ZinIrOpLayer **)v10;
                  unint64_t v12 = *(_DWORD **)(*(void *)v10 + 264);
                  memcpy(__dst, v12 + 30, 0x1C4uLL);
                  std::unordered_map<ZinDependencyOffsetDim,long>::unordered_map((uint64_t)v83, (uint64_t)(v12 + 144));
                  v83[10] = v12[154];
                  std::unordered_map<ZinDependencyOffsetDim,long>::unordered_map((uint64_t)v84, (uint64_t)(v12 + 156));
                  v84[10] = v12[166];
                  std::unordered_map<ZinDependencyOffsetDim,long>::unordered_map((uint64_t)v85, (uint64_t)(v12 + 168));
                  if (ZinIrOpLayer::IsNELayer(v11)) {
                    uint64_t v13 = "(NE";
                  }
                  else {
                    uint64_t v13 = "(PE";
                  }
                  std::string::basic_string[abi:ne180100]<0>(&v81, v13);
                  BondedInfo = (ZinBondedInfo *)ZinANELayer::GetBondedInfo(v11);
                  AneIndex = (unint64_t *)ZinBondedInfo::GetAneIndex(BondedInfo);
                  std::to_string(&v78, *AneIndex);
                  std::string::size_type v16 = std::string::insert(&v78, 0, ", ane_index=", 0xCuLL);
                  long long v17 = *(_OWORD *)&v16->__r_.__value_.__l.__data_;
                  int64_t v80 = v16->__r_.__value_.__r.__words[2];
                  *(_OWORD *)std::string __p = v17;
                  v16->__r_.__value_.__l.__size_ = 0;
                  v16->__r_.__value_.__r.__words[2] = 0;
                  v16->__r_.__value_.__r.__words[0] = 0;
                  if (v80 >= 0) {
                    uint64_t v18 = __p;
                  }
                  else {
                    uint64_t v18 = (void **)__p[0];
                  }
                  if (v80 >= 0) {
                    std::string::size_type v19 = HIBYTE(v80);
                  }
                  else {
                    std::string::size_type v19 = (std::string::size_type)__p[1];
                  }
                  std::string::append(&v81, (const std::string::value_type *)v18, v19);
                  if (SHIBYTE(v80) < 0) {
                    operator delete(__p[0]);
                  }
                  if (SHIBYTE(v78.__r_.__value_.__r.__words[2]) < 0) {
                    operator delete(v78.__r_.__value_.__l.__data_);
                  }
                  std::to_string(&v78, *((void *)v11 + 45));
                  uint64_t v20 = std::string::insert(&v78, 0, ", tid=", 6uLL);
                  long long v21 = *(_OWORD *)&v20->__r_.__value_.__l.__data_;
                  int64_t v80 = v20->__r_.__value_.__r.__words[2];
                  *(_OWORD *)std::string __p = v21;
                  v20->__r_.__value_.__l.__size_ = 0;
                  v20->__r_.__value_.__r.__words[2] = 0;
                  v20->__r_.__value_.__r.__words[0] = 0;
                  if (v80 >= 0) {
                    int v22 = __p;
                  }
                  else {
                    int v22 = (void **)__p[0];
                  }
                  if (v80 >= 0) {
                    std::string::size_type v23 = HIBYTE(v80);
                  }
                  else {
                    std::string::size_type v23 = (std::string::size_type)__p[1];
                  }
                  std::string::append(&v81, (const std::string::value_type *)v22, v23);
                  if (SHIBYTE(v80) < 0) {
                    operator delete(__p[0]);
                  }
                  if (SHIBYTE(v78.__r_.__value_.__r.__words[2]) < 0) {
                    operator delete(v78.__r_.__value_.__l.__data_);
                  }
                  std::to_string(&v77, *((void *)v11 + 6));
                  uint64_t v24 = std::string::insert(&v77, 0, ", sched=", 8uLL);
                  long long v25 = *(_OWORD *)&v24->__r_.__value_.__l.__data_;
                  v78.__r_.__value_.__r.__words[2] = v24->__r_.__value_.__r.__words[2];
                  *(_OWORD *)&v78.__r_.__value_.__l.__data_ = v25;
                  v24->__r_.__value_.__l.__size_ = 0;
                  v24->__r_.__value_.__r.__words[2] = 0;
                  v24->__r_.__value_.__r.__words[0] = 0;
                  int v26 = std::string::append(&v78, ")", 1uLL);
                  long long v27 = *(_OWORD *)&v26->__r_.__value_.__l.__data_;
                  int64_t v80 = v26->__r_.__value_.__r.__words[2];
                  *(_OWORD *)std::string __p = v27;
                  v26->__r_.__value_.__l.__size_ = 0;
                  v26->__r_.__value_.__r.__words[2] = 0;
                  v26->__r_.__value_.__r.__words[0] = 0;
                  if (v80 >= 0) {
                    uint64_t v28 = __p;
                  }
                  else {
                    uint64_t v28 = (void **)__p[0];
                  }
                  if (v80 >= 0) {
                    std::string::size_type v29 = HIBYTE(v80);
                  }
                  else {
                    std::string::size_type v29 = (std::string::size_type)__p[1];
                  }
                  std::string::append(&v81, (const std::string::value_type *)v28, v29);
                  if (SHIBYTE(v80) < 0) {
                    operator delete(__p[0]);
                  }
                  if (SHIBYTE(v78.__r_.__value_.__r.__words[2]) < 0) {
                    operator delete(v78.__r_.__value_.__l.__data_);
                  }
                  if (SHIBYTE(v77.__r_.__value_.__r.__words[2]) < 0) {
                    operator delete(v77.__r_.__value_.__l.__data_);
                  }
                  uint64_t v32 = *((void *)v11 + 3);
                  uint64_t v31 = (void *)((char *)v11 + 24);
                  uint64_t v30 = v32;
                  int v33 = *((char *)v31 + 23);
                  if (v33 >= 0) {
                    uint64_t v34 = (uint64_t)v31;
                  }
                  else {
                    uint64_t v34 = v30;
                  }
                  if (v33 >= 0) {
                    uint64_t v35 = *((unsigned __int8 *)v31 + 23);
                  }
                  else {
                    uint64_t v35 = v31[1];
                  }
                  __int16 v36 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v87, v34, v35);
                  if ((v81.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
                    uint64_t v37 = &v81;
                  }
                  else {
                    uint64_t v37 = (std::string *)v81.__r_.__value_.__r.__words[0];
                  }
                  if ((v81.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
                    std::string::size_type size = HIBYTE(v81.__r_.__value_.__r.__words[2]);
                  }
                  else {
                    std::string::size_type size = v81.__r_.__value_.__l.__size_;
                  }
                  unint64_t v39 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v36, (uint64_t)v37, size);
                  unint64_t v40 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v39, (uint64_t)" = {", 4);
                  std::ios_base::getloc((const std::ios_base *)((char *)v40 + *(void *)(*v40 - 24)));
                  uint64_t v41 = std::locale::use_facet((const std::locale *)__p, v6);
                  ((void (*)(const std::locale::facet *, uint64_t))v41->__vftable[2].~facet_0)(v41, 10);
                  std::locale::~locale((std::locale *)__p);
                  std::ostream::put();
                  std::ostream::flush();
                  if (LOBYTE(__dst[26].__locale_))
                  {
                    long long v42 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v87, (uint64_t)"\tsource1_cfg_alias_conv_src,", 28);
                    std::ios_base::getloc((const std::ios_base *)((char *)v42 + *(void *)(*v42 - 24)));
                    long long v43 = std::locale::use_facet((const std::locale *)__p, v6);
                    ((void (*)(const std::locale::facet *, uint64_t))v43->__vftable[2].~facet_0)(v43, 10);
                    std::locale::~locale((std::locale *)__p);
                    std::ostream::put();
                    std::ostream::flush();
                  }
                  if (BYTE1(__dst[26].__locale_))
                  {
                    int v44 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v87, (uint64_t)"\tsource1_cfg_alias_conv_rslt,", 29);
                    std::ios_base::getloc((const std::ios_base *)((char *)v44 + *(void *)(*v44 - 24)));
                    unint64_t v45 = std::locale::use_facet((const std::locale *)__p, v6);
                    ((void (*)(const std::locale::facet *, uint64_t))v45->__vftable[2].~facet_0)(v45, 10);
                    std::locale::~locale((std::locale *)__p);
                    std::ostream::put();
                    std::ostream::flush();
                  }
                  if (BYTE2(__dst[26].__locale_))
                  {
                    int v46 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v87, (uint64_t)"\tsource2_cfg_alias_conv_src,", 28);
                    std::ios_base::getloc((const std::ios_base *)((char *)v46 + *(void *)(*v46 - 24)));
                    char v47 = std::locale::use_facet((const std::locale *)__p, v6);
                    ((void (*)(const std::locale::facet *, uint64_t))v47->__vftable[2].~facet_0)(v47, 10);
                    std::locale::~locale((std::locale *)__p);
                    std::ostream::put();
                    std::ostream::flush();
                  }
                  if (BYTE3(__dst[26].__locale_))
                  {
                    int v48 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v87, (uint64_t)"\tsource2_cfg_alias_conv_rslt,", 29);
                    std::ios_base::getloc((const std::ios_base *)((char *)v48 + *(void *)(*v48 - 24)));
                    uint64_t v49 = std::locale::use_facet((const std::locale *)__p, v6);
                    ((void (*)(const std::locale::facet *, uint64_t))v49->__vftable[2].~facet_0)(v49, 10);
                    std::locale::~locale((std::locale *)__p);
                    std::ostream::put();
                    std::ostream::flush();
                  }
                  if (BYTE6(__dst[26].__locale_))
                  {
                    BOOL v50 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v87, (uint64_t)"\tresult_cfg_alias_conv_src,", 27);
                    std::ios_base::getloc((const std::ios_base *)((char *)v50 + *(void *)(*v50 - 24)));
                    uint64_t v51 = std::locale::use_facet((const std::locale *)__p, v6);
                    ((void (*)(const std::locale::facet *, uint64_t))v51->__vftable[2].~facet_0)(v51, 10);
                    std::locale::~locale((std::locale *)__p);
                    std::ostream::put();
                    std::ostream::flush();
                  }
                  if (HIBYTE(__dst[26].__locale_))
                  {
                    uint64_t v52 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v87, (uint64_t)"\tresult_cfg_alias_conv_rslt,", 28);
                    std::ios_base::getloc((const std::ios_base *)((char *)v52 + *(void *)(*v52 - 24)));
                    uint64_t v53 = std::locale::use_facet((const std::locale *)__p, v6);
                    ((void (*)(const std::locale::facet *, uint64_t))v53->__vftable[2].~facet_0)(v53, 10);
                    std::locale::~locale((std::locale *)__p);
                    std::ostream::put();
                    std::ostream::flush();
                  }
                  if (LOBYTE(__dst[27].__locale_))
                  {
                    std::string::size_type v54 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v87, (uint64_t)"\tsource1_cfg_alias_planar_src,", 30);
                    std::ios_base::getloc((const std::ios_base *)((char *)v54 + *(void *)(*v54 - 24)));
                    uint64_t v55 = std::locale::use_facet((const std::locale *)__p, v6);
                    ((void (*)(const std::locale::facet *, uint64_t))v55->__vftable[2].~facet_0)(v55, 10);
                    std::locale::~locale((std::locale *)__p);
                    std::ostream::put();
                    std::ostream::flush();
                  }
                  if (BYTE1(__dst[27].__locale_))
                  {
                    uint64_t v56 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v87, (uint64_t)"\tsource1_cfg_alias_planar_rslt,", 31);
                    std::ios_base::getloc((const std::ios_base *)((char *)v56 + *(void *)(*v56 - 24)));
                    int v57 = std::locale::use_facet((const std::locale *)__p, v6);
                    ((void (*)(const std::locale::facet *, uint64_t))v57->__vftable[2].~facet_0)(v57, 10);
                    std::locale::~locale((std::locale *)__p);
                    std::ostream::put();
                    std::ostream::flush();
                  }
                  if (BYTE2(__dst[27].__locale_))
                  {
                    uint64_t v58 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v87, (uint64_t)"\tsource2_cfg_alias_planar_src,", 30);
                    std::ios_base::getloc((const std::ios_base *)((char *)v58 + *(void *)(*v58 - 24)));
                    uint64_t v59 = std::locale::use_facet((const std::locale *)__p, v6);
                    ((void (*)(const std::locale::facet *, uint64_t))v59->__vftable[2].~facet_0)(v59, 10);
                    std::locale::~locale((std::locale *)__p);
                    std::ostream::put();
                    std::ostream::flush();
                  }
                  if (BYTE3(__dst[27].__locale_))
                  {
                    int v60 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v87, (uint64_t)"\tsource2_cfg_alias_planar_rslt,", 31);
                    std::ios_base::getloc((const std::ios_base *)((char *)v60 + *(void *)(*v60 - 24)));
                    std::string::size_type v61 = std::locale::use_facet((const std::locale *)__p, v6);
                    ((void (*)(const std::locale::facet *, uint64_t))v61->__vftable[2].~facet_0)(v61, 10);
                    std::locale::~locale((std::locale *)__p);
                    std::ostream::put();
                    std::ostream::flush();
                  }
                  if (BYTE6(__dst[27].__locale_))
                  {
                    uint64_t v62 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v87, (uint64_t)"\tresult_cfg_alias_planar_src,", 29);
                    std::ios_base::getloc((const std::ios_base *)((char *)v62 + *(void *)(*v62 - 24)));
                    unint64_t v63 = std::locale::use_facet((const std::locale *)__p, v6);
                    ((void (*)(const std::locale::facet *, uint64_t))v63->__vftable[2].~facet_0)(v63, 10);
                    std::locale::~locale((std::locale *)__p);
                    std::ostream::put();
                    std::ostream::flush();
                  }
                  if (HIBYTE(__dst[27].__locale_))
                  {
                    uint64_t v64 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v87, (uint64_t)"\tresult_cfg_alias_planar_rslt,", 30);
                    std::ios_base::getloc((const std::ios_base *)((char *)v64 + *(void *)(*v64 - 24)));
                    int v65 = std::locale::use_facet((const std::locale *)__p, v6);
                    ((void (*)(const std::locale::facet *, uint64_t))v65->__vftable[2].~facet_0)(v65, 10);
                    std::locale::~locale((std::locale *)__p);
                    std::ostream::put();
                    std::ostream::flush();
                  }
                  uint64_t v66 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v87, (uint64_t)"}", 1);
                  std::ios_base::getloc((const std::ios_base *)((char *)v66 + *(void *)(*v66 - 24)));
                  uint64_t v67 = std::locale::use_facet((const std::locale *)__p, v6);
                  ((void (*)(const std::locale::facet *, uint64_t))v67->__vftable[2].~facet_0)(v67, 10);
                  std::locale::~locale((std::locale *)__p);
                  std::ostream::put();
                  std::ostream::flush();
                  if (SHIBYTE(v81.__r_.__value_.__r.__words[2]) < 0) {
                    operator delete(v81.__r_.__value_.__l.__data_);
                  }
                  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v85);
                  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v84);
                  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v83);
                  v10 += 8;
                }
                while (v10 != v9);
                long long v10 = (char *)buf;
              }
              if (v10)
              {
                *((void *)&buf + 1) = v10;
                operator delete(v10);
              }
              uint64_t v8 = v76 + 24;
            }
            while (v76 + 24 != v75);
            uint64_t v4 = **(void **)(v73 + 24);
          }
          uint64_t v1 = v73;
          uint64_t v5 = v74 + 1;
        }
        while (v74 + 1 < *(int *)(v4 + 4));
      }
      uint64_t v68 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v87, (uint64_t)"\n[DEBUG_END] Hazard results", 27);
      std::ios_base::getloc((const std::ios_base *)((char *)v68 + *(void *)(*v68 - 24)));
      uint64_t v69 = std::locale::use_facet(__dst, MEMORY[0x263F8C108]);
      ((void (*)(const std::locale::facet *, uint64_t))v69->__vftable[2].~facet_0)(v69, 10);
      std::locale::~locale(__dst);
      std::ostream::put();
      std::ostream::flush();
      std::ios_base::getloc((const std::ios_base *)((char *)v68 + *(void *)(*v68 - 24)));
      uint64_t v70 = std::locale::use_facet(__dst, MEMORY[0x263F8C108]);
      ((void (*)(const std::locale::facet *, uint64_t))v70->__vftable[2].~facet_0)(v70, 10);
      std::locale::~locale(__dst);
      std::ostream::put();
      std::ostream::flush();
      if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_INFO))
      {
        std::stringbuf::str[abi:ne180100]<std::allocator<char>>((uint64_t)v88, __dst);
        uint64_t v71 = SHIBYTE(__dst[2].__locale_) >= 0 ? __dst : (std::locale *)__dst[0].__locale_;
        LODWORD(buf) = 136315138;
        *(void *)((char *)&buf + 4) = v71;
        _os_log_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_INFO, "%s", (uint8_t *)&buf, 0xCu);
        if (SHIBYTE(__dst[2].__locale_) < 0) {
          operator delete(__dst[0].__locale_);
        }
      }
      v86[0] = *MEMORY[0x263F8C2B8];
      uint64_t v72 = *(void *)(MEMORY[0x263F8C2B8] + 72);
      *(void *)((char *)v86 + *(void *)(v86[0] - 24)) = *(void *)(MEMORY[0x263F8C2B8] + 64);
      uint64_t v87 = v72;
      v88[0] = MEMORY[0x263F8C318] + 16;
      if (v89 < 0) {
        operator delete((void *)v88[8]);
      }
      std::streambuf::~streambuf();
      std::iostream::~basic_iostream();
      return MEMORY[0x21667D2B0](&v90);
    }
  }
  return this;
}

void sub_211397068(_Unwind_Exception *a1)
{
  uint64_t v2 = MEMORY[0x263F8C2B8];
  uint64_t v3 = *MEMORY[0x263F8C2B8];
  STACK[0x2E8] = *MEMORY[0x263F8C2B8];
  unint64_t v4 = *(void *)(v2 + 72);
  *(unint64_t *)((char *)&STACK[0x2E8] + *(void *)(v3 - 24)) = *(void *)(v2 + 64);
  STACK[0x2F8] = v4;
  STACK[0x300] = MEMORY[0x263F8C318] + 16;
  if (SLOBYTE(STACK[0x357]) < 0) {
    operator delete((void *)STACK[0x340]);
  }
  std::streambuf::~streambuf();
  std::iostream::~basic_iostream();
  MEMORY[0x21667D2B0](&STACK[0x368]);
  _Unwind_Resume(a1);
}

uint64_t std::vector<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>>::push_back[abi:ne180100](uint64_t *a1, uint64_t a2)
{
  unint64_t v6 = a1[2];
  uint64_t result = (uint64_t)(a1 + 2);
  unint64_t v5 = v6;
  uint64_t v7 = *(_OWORD **)(result - 8);
  if ((unint64_t)v7 >= v6)
  {
    uint64_t v9 = ((uint64_t)v7 - *a1) >> 5;
    unint64_t v10 = v9 + 1;
    if ((unint64_t)(v9 + 1) >> 59) {
      std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
    }
    uint64_t v11 = v5 - *a1;
    if (v11 >> 4 > v10) {
      unint64_t v10 = v11 >> 4;
    }
    if ((unint64_t)v11 >= 0x7FFFFFFFFFFFFFE0) {
      unint64_t v12 = 0x7FFFFFFFFFFFFFFLL;
    }
    else {
      unint64_t v12 = v10;
    }
    v16[4] = result;
    uint64_t v13 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ControlEdgeInfo>>(result, v12);
    int v14 = &v13[32 * v9];
    v16[0] = v13;
    v16[1] = v14;
    v16[3] = &v13[32 * v15];
    *(_OWORD *)int v14 = *(_OWORD *)a2;
    *(void *)a2 = 0;
    *(void *)(a2 + 8) = 0;
    *((_OWORD *)v14 + 1) = *(_OWORD *)(a2 + 16);
    *(void *)(a2 + 16) = 0;
    *(void *)(a2 + 24) = 0;
    v16[2] = v14 + 32;
    std::vector<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>>::__swap_out_circular_buffer(a1, v16);
    uint64_t v8 = (_OWORD *)a1[1];
    uint64_t result = std::__split_buffer<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>>::~__split_buffer((uint64_t)v16);
  }
  else
  {
    _OWORD *v7 = *(_OWORD *)a2;
    *(void *)a2 = 0;
    *(void *)(a2 + 8) = 0;
    v7[1] = *(_OWORD *)(a2 + 16);
    *(void *)(a2 + 16) = 0;
    *(void *)(a2 + 24) = 0;
    uint64_t v8 = v7 + 2;
    a1[1] = (uint64_t)(v7 + 2);
  }
  a1[1] = (uint64_t)v8;
  return result;
}

void sub_2113973D0(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::__split_buffer<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>>::~__split_buffer((uint64_t)va);
  _Unwind_Resume(a1);
}

uint64_t ZinMirL2HazardAnalysis::ConfigureExtensiveL2Dependency(uint64_t a1, void *a2, unint64_t a3, uint64_t a4)
{
  uint64_t v6 = a2[33];
  unsigned int v18 = 0;
  int L2SrcType = ZinMemSourceIndexTranslator::GetL2SrcType(a2, a3, (int *)&v18);
  uint64_t result = 0;
  if (L2SrcType || v18 == 2) {
    return result;
  }
  int v15 = 1;
  if (std::__hash_table<ZinIrDimension,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,std::allocator<ZinIrDimension>>::find<ZinIrDimension>((void *)a4, &v15))
  {
    int v9 = v18;
    if (v18 <= 1)
    {
      unint64_t v10 = (void *)a2[33];
      if (v10[13] >= 2uLL)
      {
        if (v10[11] >= 2uLL)
        {
          uint64_t v11 = *(void *)(ZinMirL2Config::GetTileSrc(v6 + 120, v18) + 32);
          uint64_t v12 = *(void *)(a2[33] + 88);
          if (v11 != *(void *)(ZinMirL2Config::GetTileSrc(v6 + 120, v9) + 16) * v12) {
            return 0;
          }
          unint64_t v10 = (void *)a2[33];
          if (v10[13] < 2uLL) {
            goto LABEL_11;
          }
        }
        unint64_t v13 = v10[10];
        if (v13 < 2 || *(void *)(v6 + 288) == *(void *)(v6 + 280) * v13) {
          goto LABEL_11;
        }
        return 0;
      }
    }
  }
LABEL_11:
  uint64_t L2SrcDep = (int *)ZinMirL2Config::GetL2SrcDep(v6 + 120, v18);
  int v15 = *L2SrcDep;
  std::unordered_map<ZinDependencyOffsetDim,long>::unordered_map((uint64_t)v16, (uint64_t)(L2SrcDep + 2));
  if (v16 != (void *)a4)
  {
    int v17 = *(_DWORD *)(a4 + 32);
    std::__hash_table<std::__hash_value_type<ZinIrDimension,unsigned long>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,unsigned long>>>::__assign_multi<std::__hash_const_iterator<std::__hash_node<std::__hash_value_type<ZinIrDimension,unsigned long>,void *> *>>(v16, *(uint64_t **)(a4 + 16), 0);
  }
  ZinMirL2Config::SetL2SrcDep((_DWORD *)(v6 + 120), (uint64_t)&v15, v18);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v16);
  return 1;
}

void sub_21139756C(_Unwind_Exception *a1)
{
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table(v1);
  _Unwind_Resume(a1);
}

BOOL ZinMirL2HazardAnalysis::IsQualifiedForExtensiveL2Dependency(uint64_t a1, const ZinIrOpLayer *a2, ZinIrOpLayer *a3, ZinIrOpLayerGraph *a4, const ZinIrTensor *a5, uint64_t a6)
{
  if (!*((unsigned char *)a5 + 1316)) {
    return 0;
  }
  uint64_t v11 = (ZinIrTensor *)(*(uint64_t (**)(const ZinIrOpLayer *, void, void))(*(void *)a2 + 32))(a2, 0, 0);
  uint64_t RootTensor = ZinIrTensor::GetRootTensor(v11);
  std::string::size_type v19 = 0;
  uint64_t v20 = 0;
  uint64_t v21 = 0;
  int ShouldUseL2Dependent = ZinIrRegAllocUtil::ShouldUseL2Dependent(RootTensor, a5, &v19);
  int v14 = v19;
  if (v20 - v19 != 16) {
    int ShouldUseL2Dependent = 0;
  }
  if (ShouldUseL2Dependent == 1)
  {
    if (*(const ZinIrOpLayer **)v19 != a2 || *((ZinIrOpLayer **)v19 + 1) != a3)
    {
      BOOL IsConnected = 0;
LABEL_10:
      uint64_t v20 = v14;
      operator delete(v14);
      return IsConnected;
    }
    ZinMirL2HazardAnalysis::ComputeDependencyMap((uint64_t)v19, a2, a3, a4, (uint64_t)a5, a6);
    if (*(void *)(a6 + 24))
    {
      BOOL IsConnected = 1;
    }
    else
    {
      int v17 = a3;
      unsigned int v18 = a2;
      BOOL IsConnected = ZinIrNgraph<ZinIrOpLayer *,ZinIrIdComparator<ZinIrOpLayer *>>::IsConnected((uint64_t)a4, (unint64_t *)&v18, (uint64_t *)&v17);
    }
    int v14 = v19;
    if (v19) {
      goto LABEL_10;
    }
  }
  else
  {
    BOOL IsConnected = 0;
    if (v19) {
      goto LABEL_10;
    }
  }
  return IsConnected;
}

void sub_2113976BC(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, void *__p, uint64_t a13)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

void ZinMirL2HazardAnalysis::ComputeDependencyMap(uint64_t a1, const ZinIrOpLayer *a2, ZinIrOpLayer *a3, ZinIrOpLayerGraph *a4, uint64_t a5, uint64_t a6)
{
  std::string::size_type v16 = 0;
  int v17 = 0;
  uint64_t v18 = 0;
  std::__hash_table<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::__unordered_map_hasher<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::hash<long>,std::equal_to<long>,true>,std::__unordered_map_equal<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::equal_to<long>,std::hash<long>,true>,std::allocator<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>>>::clear(a6);
  if (!ZinTensorFamilyUtil::FindAllIntermediateLayerPaths((uint64_t)a2, a3, (uint64_t *)&v16)
    && v16 != v17
    && 0xAAAAAAAAAAAAAAABLL * (v17 - v16) <= 1)
  {
    ZinIrRegAllocUtil::ComputeDependencyOffset(&v16, a2, (uint64_t)a3, a4, a5, 0, (uint64_t)v15);
    std::__hash_table<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::__unordered_map_hasher<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::hash<long>,std::equal_to<long>,true>,std::__unordered_map_equal<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::equal_to<long>,std::hash<long>,true>,std::allocator<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>>>::__move_assign(a6, (uint64_t *)v15);
    std::__hash_table<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::__unordered_map_hasher<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::hash<long>,std::equal_to<long>,true>,std::__unordered_map_equal<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::equal_to<long>,std::hash<long>,true>,std::allocator<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>>>::~__hash_table((uint64_t)v15);
    if (*(void *)(a6 + 24))
    {
      uint64_t v11 = *(void **)(a6 + 16);
      if (v11)
      {
        while (1)
        {
          if (!*(unsigned char *)(a5 + 1324))
          {
            int v14 = (void *)v11[5];
            if (v14) {
              break;
            }
          }
LABEL_8:
          LODWORD(v15[0]) = 3;
          uint64_t v12 = std::__hash_table<ZinIrDimension,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,std::allocator<ZinIrDimension>>::find<ZinIrDimension>(v11 + 3, (int *)v15);
          if (*(unsigned char *)(a5 + 1322)) {
            BOOL v13 = 1;
          }
          else {
            BOOL v13 = v12 == 0;
          }
          if (!v13 && v12[3]) {
            goto LABEL_19;
          }
          uint64_t v11 = (void *)*v11;
          if (!v11) {
            goto LABEL_2;
          }
        }
        while ((v14[3] & 0x8000000000000000) == 0)
        {
          int v14 = (void *)*v14;
          if (!v14) {
            goto LABEL_8;
          }
        }
LABEL_19:
        std::__hash_table<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::__unordered_map_hasher<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::hash<long>,std::equal_to<long>,true>,std::__unordered_map_equal<long,std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,std::equal_to<long>,std::hash<long>,true>,std::allocator<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>>>::clear(a6);
      }
    }
  }
LABEL_2:
  v15[0] = (void **)&v16;
  std::vector<std::vector<ZinIrOpLayer *>>::__destroy_vector::operator()[abi:ne180100](v15);
}

void sub_211397830(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, void **a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, char a14)
{
  a9 = (void **)&a14;
  std::vector<std::vector<ZinIrOpLayer *>>::__destroy_vector::operator()[abi:ne180100](&a9);
  _Unwind_Resume(a1);
}

uint64_t ZinMirL2HazardAnalysis::TryEnablingParallelExecution(ZinMirL2HazardAnalysis *this, const ZinANELayer *a2, ZinEngineLayerMirInfo **a3, BOOL *a4)
{
  if (a2 && a3 && !ZinBondedUtils::AreAssignedToSameANE(a2, (const ZinANELayer *)a3, (const ZinANELayer *)a3)) {
    ZinAssertImpl("Layers must be assigned to the same ANE");
  }
  *a4 = 0;
  uint64_t v70 = 0;
  uint64_t v71 = 0;
  uint64_t v72 = 0;
  uint64_t v8 = *((void *)this + 1);
  int v9 = *(const void **)(v8 + 352);
  uint64_t v10 = *(void *)(v8 + 360);
  if ((const void *)v10 == v9) {
    ZinAssertImpl("Must run scheduler first");
  }
  std::string __p = 0;
  uint64_t v68 = 0;
  uint64_t v69 = 0;
  std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(&__p, v9, v10, (v10 - (uint64_t)v9) >> 3);
  if (!ZinIrRegAllocUtil::IsQualifiedForParallelExecution(a2, (ZinIrOpLayer *)a3, (ZinIrOpLayer ***)&__p, *((void *)this + 3), &v70)|| ((v11 = a3[33], v12 = (ZinMirL2Config *)(*((void *)a2 + 33) + 120), !ZinIrOpLayer::IsNELayer(a2))? (int v13 = 1): (int v13 = 2), ZinMirL2Config::HasL2DependentMode(v12, v13)|| !ZinMirL2Config::HasAlias(v12)|| (!ZinIrOpLayer::IsNELayer((ZinIrOpLayer *)a3) ? (v14 = 1) : (v14 = 2), ZinMirL2Config::HasL2DependentMode((_DWORD *)v11 + 30, v14))))
  {
    uint64_t v15 = 0;
    goto LABEL_16;
  }
  if (!ZinMirL2Config::HasAlias((ZinEngineLayerMirInfo *)((char *)v11 + 120)))
  {
    uint64_t v15 = 1;
    goto LABEL_16;
  }
  uint64_t v64 = 0;
  uint64_t v65 = 0;
  uint64_t v66 = 0;
  ZinMirL2HazardAnalysis::GetReadBeginHazardNodes(this, (uint64_t)a3, &v64);
  uint64_t v17 = v64;
  for (uint64_t i = v65; v17 != i; v17 += 16)
  {
    uint64_t v18 = *(std::__shared_weak_count **)(v17 + 8);
    uint64_t v58 = *(std::__shared_weak_count **)v17;
    uint64_t v59 = v18;
    if (v18) {
      atomic_fetch_add_explicit(&v18->__shared_owners_, 1uLL, memory_order_relaxed);
    }
    uint64_t v19 = *(void *)this;
    uint64_t v20 = (void *)(*(void *)this + 64);
    v73[0] = (unint64_t *)&v58;
    uint64_t v21 = std::__hash_table<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::__unordered_map_hasher<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::__unordered_map_equal<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>>>::find<std::reference_wrapper<ZinIrOpLayer * const>>(v20, v73);
    int v22 = (uint64_t **)(v19 + 104);
    if (v21) {
      int v22 = v21 + 3;
    }
    std::string::size_type v23 = *v22;
    uint64_t v24 = v22[1];
    while (1)
    {
      if (v23 == v24)
      {
        char v30 = 1;
        goto LABEL_45;
      }
      long long v25 = (void *)*v23;
      LODWORD(v56) = 0;
      uint64_t v26 = *(void *)this;
      long long v27 = (std::__shared_weak_count *)v25[1];
      unint64_t v62 = *v25;
      unint64_t v63 = v27;
      if (v27) {
        atomic_fetch_add_explicit(&v27->__shared_owners_, 1uLL, memory_order_relaxed);
      }
      int v60 = (void **)&v58->__vftable;
      std::string::size_type v61 = v59;
      if (v59) {
        atomic_fetch_add_explicit(&v59->__shared_owners_, 1uLL, memory_order_relaxed);
      }
      BOOL EdgeType = ZinIrHazardGraph::GetEdgeType(v26, &v62, (uint64_t *)&v60, &v56);
      if (v56) {
        BOOL v29 = 0;
      }
      else {
        BOOL v29 = EdgeType;
      }
      if (v61) {
        std::__shared_weak_count::__release_shared[abi:ne180100](v61);
      }
      if (v63) {
        std::__shared_weak_count::__release_shared[abi:ne180100](v63);
      }
      if (!v29 && *(void *)(*(void *)*v25 + 360) == *((void *)a2 + 45)) {
        break;
      }
      ++v23;
    }
    char v30 = 0;
LABEL_45:
    if (v59) {
      std::__shared_weak_count::__release_shared[abi:ne180100](v59);
    }
    if ((v30 & 1) == 0) {
      goto LABEL_83;
    }
  }
  uint64_t L2WrSymbol = (ZinIrSymbol *)ZinEngineLayerMirInfo::GetL2WrSymbol(a3[33]);
  ZinMirL2HazardAnalysis::GetHazardNodes(this, L2WrSymbol, &v58);
  uint64_t v32 = (void **)&v58->__vftable;
  int v33 = v59;
  if (v58 != v59)
  {
    uint64_t v51 = v59;
    while (1)
    {
      uint64_t v34 = (void **)*v32;
      uint64_t v35 = (std::__shared_weak_count *)v32[1];
      uint64_t v56 = (std::__shared_weak_count **)*v32;
      int v57 = v35;
      if (v35) {
        atomic_fetch_add_explicit(&v35->__shared_owners_, 1uLL, memory_order_relaxed);
      }
      if (*v34 == a3)
      {
        uint64_t v37 = *(void *)this;
        uint64_t v38 = (void *)(*(void *)this + 64);
        v73[0] = (unint64_t *)&v56;
        unint64_t v39 = std::__hash_table<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::__unordered_map_hasher<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::__unordered_map_equal<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>>>::find<std::reference_wrapper<ZinIrOpLayer * const>>(v38, v73);
        unint64_t v40 = (uint64_t **)(v37 + 104);
        if (v39) {
          unint64_t v40 = v39 + 3;
        }
        uint64_t v41 = *v40;
        long long v42 = v40[1];
        while (1)
        {
          if (v41 == v42)
          {
            char v36 = 1;
            goto LABEL_75;
          }
          long long v43 = (void *)*v41;
          LODWORD(v73[0]) = 0;
          uint64_t v44 = *(void *)this;
          unint64_t v45 = (std::__shared_weak_count *)v43[1];
          unint64_t v54 = *v43;
          uint64_t v55 = v45;
          if (v45) {
            atomic_fetch_add_explicit(&v45->__shared_owners_, 1uLL, memory_order_relaxed);
          }
          uint64_t v52 = (void **)v56;
          uint64_t v53 = v57;
          if (v57) {
            atomic_fetch_add_explicit(&v57->__shared_owners_, 1uLL, memory_order_relaxed);
          }
          BOOL v46 = ZinIrHazardGraph::GetEdgeType(v44, &v54, (uint64_t *)&v52, v73);
          if (LODWORD(v73[0])) {
            BOOL v47 = 0;
          }
          else {
            BOOL v47 = v46;
          }
          if (v53) {
            std::__shared_weak_count::__release_shared[abi:ne180100](v53);
          }
          if (v55) {
            std::__shared_weak_count::__release_shared[abi:ne180100](v55);
          }
          if (!v47 && *(void *)(*(void *)*v43 + 360) == *((void *)a2 + 45)) {
            break;
          }
          ++v41;
        }
        char v36 = 0;
LABEL_75:
        int v33 = v51;
      }
      else
      {
        char v36 = 1;
      }
      if (v57) {
        std::__shared_weak_count::__release_shared[abi:ne180100](v57);
      }
      if ((v36 & 1) == 0) {
        break;
      }
      v32 += 2;
      if (v32 == (void **)v33) {
        goto LABEL_80;
      }
    }
    uint64_t v56 = &v58;
    std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v56);
LABEL_83:
    uint64_t v15 = 0;
    goto LABEL_84;
  }
LABEL_80:
  uint64_t v56 = &v58;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v56);
  int v48 = a3[33];
  *((void *)v48 + 41) = 0;
  *((void *)v48 + 42) = 0;
  uint64_t v49 = *((void *)a2 + 33);
  uint64_t v15 = 1;
  *(unsigned char *)(v49 + 344) = 1;
  *a4 = 1;
LABEL_84:
  uint64_t v58 = (std::__shared_weak_count *)&v64;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100]((void ***)&v58);
LABEL_16:
  if (__p)
  {
    uint64_t v68 = __p;
    operator delete(__p);
  }
  if (v70)
  {
    uint64_t v71 = v70;
    operator delete(v70);
  }
  return v15;
}

void sub_211397C80(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, char *a15, uint64_t a16, char a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,char a24,uint64_t a25,uint64_t a26,void *__p,uint64_t a28)
{
  a15 = &a24;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100]((void ***)&a15);
  if (__p)
  {
    a28 = (uint64_t)__p;
    operator delete(__p);
  }
  char v30 = *(void **)(v28 - 120);
  if (v30)
  {
    *(void *)(v28 - 112) = v30;
    operator delete(v30);
  }
  _Unwind_Resume(a1);
}

void ZinMirL2HazardAnalysis::DebugPrintNode(uint64_t a1, uint64_t ***a2, uint64_t a3, int a4)
{
  uint64_t v7 = **a2;
  uint64_t v8 = (*a2)[1];
  if (ZinIrOpLayer::IsNELayer((ZinIrOpLayer *)v7)) {
    int v9 = "(NE";
  }
  else {
    int v9 = "(PE";
  }
  std::string::basic_string[abi:ne180100]<0>(&v106, v9);
  BondedInfo = (ZinBondedInfo *)ZinANELayer::GetBondedInfo((ZinANELayer *)v7);
  AneIndex = (unint64_t *)ZinBondedInfo::GetAneIndex(BondedInfo);
  std::to_string(&v98, *AneIndex);
  uint64_t v12 = std::string::insert(&v98, 0, ", ane_index=", 0xCuLL);
  long long v13 = *(_OWORD *)&v12->__r_.__value_.__l.__data_;
  v99.__r_.__value_.__r.__words[2] = v12->__r_.__value_.__r.__words[2];
  *(_OWORD *)&v99.__r_.__value_.__l.__data_ = v13;
  v12->__r_.__value_.__l.__size_ = 0;
  v12->__r_.__value_.__r.__words[2] = 0;
  v12->__r_.__value_.__r.__words[0] = 0;
  int v14 = std::string::append(&v99, ", sched=", 8uLL);
  long long v15 = *(_OWORD *)&v14->__r_.__value_.__l.__data_;
  v100.__r_.__value_.__r.__words[2] = v14->__r_.__value_.__r.__words[2];
  *(_OWORD *)&v100.__r_.__value_.__l.__data_ = v15;
  v14->__r_.__value_.__l.__size_ = 0;
  v14->__r_.__value_.__r.__words[2] = 0;
  v14->__r_.__value_.__r.__words[0] = 0;
  std::to_string(&v97, v7[6]);
  if ((v97.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
    std::string::size_type v16 = &v97;
  }
  else {
    std::string::size_type v16 = (std::string *)v97.__r_.__value_.__r.__words[0];
  }
  if ((v97.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
    std::string::size_type size = HIBYTE(v97.__r_.__value_.__r.__words[2]);
  }
  else {
    std::string::size_type size = v97.__r_.__value_.__l.__size_;
  }
  uint64_t v18 = std::string::append(&v100, (const std::string::value_type *)v16, size);
  long long v19 = *(_OWORD *)&v18->__r_.__value_.__l.__data_;
  v101.__r_.__value_.__r.__words[2] = v18->__r_.__value_.__r.__words[2];
  *(_OWORD *)&v101.__r_.__value_.__l.__data_ = v19;
  v18->__r_.__value_.__l.__size_ = 0;
  v18->__r_.__value_.__r.__words[2] = 0;
  v18->__r_.__value_.__r.__words[0] = 0;
  uint64_t v20 = std::string::append(&v101, ", tid=", 6uLL);
  long long v21 = *(_OWORD *)&v20->__r_.__value_.__l.__data_;
  v102.__r_.__value_.__r.__words[2] = v20->__r_.__value_.__r.__words[2];
  *(_OWORD *)&v102.__r_.__value_.__l.__data_ = v21;
  v20->__r_.__value_.__l.__size_ = 0;
  v20->__r_.__value_.__r.__words[2] = 0;
  v20->__r_.__value_.__r.__words[0] = 0;
  std::to_string(&v96, v7[45]);
  if ((v96.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
    int v22 = &v96;
  }
  else {
    int v22 = (std::string *)v96.__r_.__value_.__r.__words[0];
  }
  if ((v96.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
    std::string::size_type v23 = HIBYTE(v96.__r_.__value_.__r.__words[2]);
  }
  else {
    std::string::size_type v23 = v96.__r_.__value_.__l.__size_;
  }
  uint64_t v24 = std::string::append(&v102, (const std::string::value_type *)v22, v23);
  long long v25 = *(_OWORD *)&v24->__r_.__value_.__l.__data_;
  v103.__r_.__value_.__r.__words[2] = v24->__r_.__value_.__r.__words[2];
  *(_OWORD *)&v103.__r_.__value_.__l.__data_ = v25;
  v24->__r_.__value_.__l.__size_ = 0;
  v24->__r_.__value_.__r.__words[2] = 0;
  v24->__r_.__value_.__r.__words[0] = 0;
  uint64_t v26 = std::string::append(&v103, ")", 1uLL);
  long long v27 = *(_OWORD *)&v26->__r_.__value_.__l.__data_;
  int64_t v105 = v26->__r_.__value_.__r.__words[2];
  long long v104 = v27;
  v26->__r_.__value_.__l.__size_ = 0;
  v26->__r_.__value_.__r.__words[2] = 0;
  v26->__r_.__value_.__r.__words[0] = 0;
  if (v105 >= 0) {
    uint64_t v28 = (const std::string::value_type *)&v104;
  }
  else {
    uint64_t v28 = (const std::string::value_type *)v104;
  }
  if (v105 >= 0) {
    std::string::size_type v29 = HIBYTE(v105);
  }
  else {
    std::string::size_type v29 = *((void *)&v104 + 1);
  }
  std::string::append(&v106, v28, v29);
  if (SHIBYTE(v105) < 0) {
    operator delete((void *)v104);
  }
  if (SHIBYTE(v103.__r_.__value_.__r.__words[2]) < 0) {
    operator delete(v103.__r_.__value_.__l.__data_);
  }
  if (SHIBYTE(v96.__r_.__value_.__r.__words[2]) < 0) {
    operator delete(v96.__r_.__value_.__l.__data_);
  }
  if (SHIBYTE(v102.__r_.__value_.__r.__words[2]) < 0) {
    operator delete(v102.__r_.__value_.__l.__data_);
  }
  if (SHIBYTE(v101.__r_.__value_.__r.__words[2]) < 0) {
    operator delete(v101.__r_.__value_.__l.__data_);
  }
  if (SHIBYTE(v97.__r_.__value_.__r.__words[2]) < 0) {
    operator delete(v97.__r_.__value_.__l.__data_);
  }
  if (SHIBYTE(v100.__r_.__value_.__r.__words[2]) < 0) {
    operator delete(v100.__r_.__value_.__l.__data_);
  }
  if (SHIBYTE(v99.__r_.__value_.__r.__words[2]) < 0) {
    operator delete(v99.__r_.__value_.__l.__data_);
  }
  if (SHIBYTE(v98.__r_.__value_.__r.__words[2]) < 0) {
    operator delete(v98.__r_.__value_.__l.__data_);
  }
  if (a4) {
    char v30 = "\\l";
  }
  else {
    char v30 = "\n";
  }
  std::string::basic_string[abi:ne180100]<0>(&v104, v30);
  uint64_t v31 = (void *)(a3 + 16);
  uint64_t v32 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v31, (uint64_t)"\t", 1);
  int v33 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v32, (uint64_t)"\"", 1);
  uint64_t v34 = (std::string *)*a2;
  if (*((char *)*a2 + 47) < 0) {
    std::string::__init_copy_ctor_external(&v103, v34[1].__r_.__value_.__l.__data_, v34[1].__r_.__value_.__l.__size_);
  }
  else {
    std::string v103 = v34[1];
  }
  if ((v103.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
    uint64_t v35 = &v103;
  }
  else {
    uint64_t v35 = (std::string *)v103.__r_.__value_.__r.__words[0];
  }
  if ((v103.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
    std::string::size_type v36 = HIBYTE(v103.__r_.__value_.__r.__words[2]);
  }
  else {
    std::string::size_type v36 = v103.__r_.__value_.__l.__size_;
  }
  uint64_t v37 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v33, (uint64_t)v35, v36);
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v37, (uint64_t)"\" [", 3);
  if (SHIBYTE(v103.__r_.__value_.__r.__words[2]) < 0) {
    operator delete(v103.__r_.__value_.__l.__data_);
  }
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v31, (uint64_t)"label=\"", 7);
  uint64_t v38 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v31, (uint64_t)"L=", 2);
  uint64_t v41 = v7[3];
  unint64_t v40 = v7 + 3;
  uint64_t v39 = v41;
  int v42 = *((char *)v40 + 23);
  if (v42 >= 0) {
    uint64_t v43 = (uint64_t)v40;
  }
  else {
    uint64_t v43 = v39;
  }
  if (v42 >= 0) {
    uint64_t v44 = *((unsigned __int8 *)v40 + 23);
  }
  else {
    uint64_t v44 = v40[1];
  }
  unint64_t v45 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v38, v43, v44);
  if (v105 >= 0) {
    BOOL v46 = &v104;
  }
  else {
    BOOL v46 = (long long *)v104;
  }
  if (v105 >= 0) {
    uint64_t v47 = HIBYTE(v105);
  }
  else {
    uint64_t v47 = *((void *)&v104 + 1);
  }
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v45, (uint64_t)v46, v47);
  if ((v106.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
    int v48 = &v106;
  }
  else {
    int v48 = (std::string *)v106.__r_.__value_.__r.__words[0];
  }
  if ((v106.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
    std::string::size_type v49 = HIBYTE(v106.__r_.__value_.__r.__words[2]);
  }
  else {
    std::string::size_type v49 = v106.__r_.__value_.__l.__size_;
  }
  BOOL v50 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v31, (uint64_t)v48, v49);
  if (v105 >= 0) {
    uint64_t v51 = &v104;
  }
  else {
    uint64_t v51 = (long long *)v104;
  }
  if (v105 >= 0) {
    uint64_t v52 = HIBYTE(v105);
  }
  else {
    uint64_t v52 = *((void *)&v104 + 1);
  }
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v50, (uint64_t)v51, v52);
  uint64_t v53 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v31, (uint64_t)"S=", 2);
  uint64_t v56 = v8[20];
  uint64_t v55 = (uint64_t)(v8 + 20);
  uint64_t v54 = v56;
  int v57 = *(char *)(v55 + 23);
  if (v57 >= 0) {
    uint64_t v58 = v55;
  }
  else {
    uint64_t v58 = v54;
  }
  if (v57 >= 0) {
    uint64_t v59 = *(unsigned __int8 *)(v55 + 23);
  }
  else {
    uint64_t v59 = *(void *)(v55 + 8);
  }
  int v60 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v53, v58, v59);
  if (v105 >= 0) {
    std::string::size_type v61 = &v104;
  }
  else {
    std::string::size_type v61 = (long long *)v104;
  }
  if (v105 >= 0) {
    uint64_t v62 = HIBYTE(v105);
  }
  else {
    uint64_t v62 = *((void *)&v104 + 1);
  }
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v60, (uint64_t)v61, v62);
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v31, (uint64_t)"range=[", 7);
  unint64_t v63 = (void *)std::ostream::operator<<();
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v63, (uint64_t)", ", 2);
  uint64_t v64 = (void *)std::ostream::operator<<();
  uint64_t v65 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v64, (uint64_t)"]", 1);
  if (v105 >= 0) {
    uint64_t v66 = &v104;
  }
  else {
    uint64_t v66 = (long long *)v104;
  }
  if (v105 >= 0) {
    uint64_t v67 = HIBYTE(v105);
  }
  else {
    uint64_t v67 = *((void *)&v104 + 1);
  }
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v65, (uint64_t)v66, v67);
  if (*((_DWORD *)*a2 + 5)) {
    uint64_t v68 = "End";
  }
  else {
    uint64_t v68 = "Begin";
  }
  std::string::basic_string[abi:ne180100]<0>(&v103, v68);
  uint64_t v69 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v31, (uint64_t)"ExecutionType=", 14);
  if ((v103.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
    uint64_t v70 = &v103;
  }
  else {
    uint64_t v70 = (std::string *)v103.__r_.__value_.__r.__words[0];
  }
  if ((v103.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
    std::string::size_type v71 = HIBYTE(v103.__r_.__value_.__r.__words[2]);
  }
  else {
    std::string::size_type v71 = v103.__r_.__value_.__l.__size_;
  }
  uint64_t v72 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v69, (uint64_t)v70, v71);
  if (v105 >= 0) {
    uint64_t v73 = &v104;
  }
  else {
    uint64_t v73 = (long long *)v104;
  }
  if (v105 >= 0) {
    uint64_t v74 = HIBYTE(v105);
  }
  else {
    uint64_t v74 = *((void *)&v104 + 1);
  }
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v72, (uint64_t)v73, v74);
  uint64_t v75 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v31, (uint64_t)"Ty=", 3);
  uint64_t v76 = *((int *)*a2 + 4);
  if (v76 >= 4) {
    ZinAssertImpl("Unreachable.");
  }
  std::string v77 = v75;
  std::string::basic_string[abi:ne180100]<0>(&v102, (&off_26418C878)[v76]);
  if ((v102.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
    std::string v78 = &v102;
  }
  else {
    std::string v78 = (std::string *)v102.__r_.__value_.__r.__words[0];
  }
  if ((v102.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
    std::string::size_type v79 = HIBYTE(v102.__r_.__value_.__r.__words[2]);
  }
  else {
    std::string::size_type v79 = v102.__r_.__value_.__l.__size_;
  }
  int64_t v80 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v77, (uint64_t)v78, v79);
  if (v105 >= 0) {
    std::string v81 = &v104;
  }
  else {
    std::string v81 = (long long *)v104;
  }
  if (v105 >= 0) {
    uint64_t v82 = HIBYTE(v105);
  }
  else {
    uint64_t v82 = *((void *)&v104 + 1);
  }
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v80, (uint64_t)v81, v82);
  if (SHIBYTE(v102.__r_.__value_.__r.__words[2]) < 0) {
    operator delete(v102.__r_.__value_.__l.__data_);
  }
  uint64_t v83 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v31, (uint64_t)"Name=", 5);
  std::locale v84 = (std::string *)*a2;
  if (*((char *)*a2 + 47) < 0) {
    std::string::__init_copy_ctor_external(&v102, v84[1].__r_.__value_.__l.__data_, v84[1].__r_.__value_.__l.__size_);
  }
  else {
    std::string v102 = v84[1];
  }
  if ((v102.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
    uint64_t v85 = &v102;
  }
  else {
    uint64_t v85 = (std::string *)v102.__r_.__value_.__r.__words[0];
  }
  if ((v102.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
    std::string::size_type v86 = HIBYTE(v102.__r_.__value_.__r.__words[2]);
  }
  else {
    std::string::size_type v86 = v102.__r_.__value_.__l.__size_;
  }
  uint64_t v87 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v83, (uint64_t)v85, v86);
  if (v105 >= 0) {
    char v88 = &v104;
  }
  else {
    char v88 = (long long *)v104;
  }
  if (v105 >= 0) {
    uint64_t v89 = HIBYTE(v105);
  }
  else {
    uint64_t v89 = *((void *)&v104 + 1);
  }
  uint64_t v90 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v87, (uint64_t)v88, v89);
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v90, (uint64_t)" \"", 2);
  if (SHIBYTE(v102.__r_.__value_.__r.__words[2]) < 0) {
    operator delete(v102.__r_.__value_.__l.__data_);
  }
  int v91 = *((_DWORD *)*a2 + 4);
  if (v91 == 3) {
    uint64_t v92 = ", fillcolor=grey";
  }
  else {
    uint64_t v92 = ", fillcolor=white";
  }
  if (v91 == 3) {
    uint64_t v93 = 16;
  }
  else {
    uint64_t v93 = 17;
  }
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v31, (uint64_t)v92, v93);
  long long v94 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v31, (uint64_t)"]", 1);
  std::ios_base::getloc((const std::ios_base *)((char *)v94 + *(void *)(*v94 - 24)));
  uint64_t v95 = std::locale::use_facet((const std::locale *)&v102, MEMORY[0x263F8C108]);
  ((void (*)(const std::locale::facet *, uint64_t))v95->__vftable[2].~facet_0)(v95, 10);
  std::locale::~locale((std::locale *)&v102);
  std::ostream::put();
  std::ostream::flush();
  if (SHIBYTE(v103.__r_.__value_.__r.__words[2]) < 0) {
    operator delete(v103.__r_.__value_.__l.__data_);
  }
  if (SHIBYTE(v105) < 0) {
    operator delete((void *)v104);
  }
  if (SHIBYTE(v106.__r_.__value_.__r.__words[2]) < 0) {
    operator delete(v106.__r_.__value_.__l.__data_);
  }
}

void sub_2113984C0(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11, int a12, __int16 a13, char a14, char a15, void *a16, uint64_t a17, int a18, __int16 a19, char a20,char a21,uint64_t a22,uint64_t a23,int a24,__int16 a25,char a26,char a27,void *a28,uint64_t a29,int a30,__int16 a31,char a32,char a33,uint64_t a34,void *a35,uint64_t a36,int a37,__int16 a38,char a39,char a40,uint64_t a41,void *a42,uint64_t a43,int a44,__int16 a45,char a46,char a47,uint64_t a48,std::locale a49,uint64_t a50,int a51,__int16 a52,char a53,char a54)
{
  if (*(char *)(v54 - 137) < 0) {
    operator delete(*(void **)(v54 - 160));
  }
  if (*(char *)(v54 - 105) < 0) {
    operator delete(*(void **)(v54 - 128));
  }
  if (*(char *)(v54 - 81) < 0) {
    operator delete(*(void **)(v54 - 104));
  }
  _Unwind_Resume(exception_object);
}

BOOL ZinMirL2HazardAnalysis::HazardNodeSorter::operator()(uint64_t a1, ZinIrHazardNode **a2, ZinIrHazardNode **a3)
{
  uint64_t LayerTID = ZinIrHazardNode::GetLayerTID(*a2);
  if (LayerTID < ZinIrHazardNode::GetLayerTID(*a3)) {
    return 1;
  }
  uint64_t v6 = ZinIrHazardNode::GetLayerTID(*a2);
  if (v6 > ZinIrHazardNode::GetLayerTID(*a3)) {
    return 0;
  }
  int v7 = *((_DWORD *)*a2 + 4);
  int v8 = *((_DWORD *)*a3 + 4);
  if (v7 < v8) {
    return 1;
  }
  if (v7 > v8) {
    return 0;
  }
  if (*((_DWORD *)*a2 + 5)) {
    BOOL v10 = 1;
  }
  else {
    BOOL v10 = *((_DWORD *)*a3 + 5) == 0;
  }
  return !v10;
}

void std::vector<std::vector<std::vector<ZinANELayer *>>>::__vdeallocate(void ***a1)
{
  uint64_t v1 = *a1;
  if (*a1)
  {
    uint64_t v3 = a1[1];
    unint64_t v4 = *a1;
    if (v3 != v1)
    {
      do
      {
        v3 -= 3;
        unint64_t v5 = v3;
        std::vector<std::vector<ZinIrOpLayer *>>::__destroy_vector::operator()[abi:ne180100](&v5);
      }
      while (v3 != v1);
      unint64_t v4 = *a1;
    }
    a1[1] = v1;
    operator delete(v4);
    *a1 = 0;
    a1[1] = 0;
    a1[2] = 0;
  }
}

uint64_t std::vector<std::shared_ptr<ZinIrHazardNode>>::__swap_out_circular_buffer(uint64_t *a1, void *a2)
{
  uint64_t result = std::__uninitialized_allocator_move_if_noexcept[abi:ne180100]<std::allocator<std::shared_ptr<ZinIrHazardNode>>,std::reverse_iterator<std::shared_ptr<ZinIrHazardNode>*>,std::reverse_iterator<std::shared_ptr<ZinIrHazardNode>*>,std::reverse_iterator<std::shared_ptr<ZinIrHazardNode>*>>((uint64_t)(a1 + 2), a1[1], (void *)a1[1], *a1, (void *)*a1, a2[1], a2[1]);
  a2[1] = v5;
  uint64_t v6 = *a1;
  *a1 = v5;
  a2[1] = v6;
  uint64_t v7 = a1[1];
  a1[1] = a2[2];
  a2[2] = v7;
  uint64_t v8 = a1[2];
  a1[2] = a2[3];
  a2[3] = v8;
  *a2 = a2[1];
  return result;
}

uint64_t std::__uninitialized_allocator_move_if_noexcept[abi:ne180100]<std::allocator<std::shared_ptr<ZinIrHazardNode>>,std::reverse_iterator<std::shared_ptr<ZinIrHazardNode>*>,std::reverse_iterator<std::shared_ptr<ZinIrHazardNode>*>,std::reverse_iterator<std::shared_ptr<ZinIrHazardNode>*>>(uint64_t a1, uint64_t a2, void *a3, uint64_t a4, void *a5, uint64_t a6, uint64_t a7)
{
  uint64_t v7 = a7;
  *(void *)&long long v15 = a6;
  *((void *)&v15 + 1) = a7;
  long long v14 = v15;
  v12[0] = a1;
  v12[1] = &v14;
  void v12[2] = &v15;
  if (a3 == a5)
  {
    uint64_t v10 = a6;
  }
  else
  {
    uint64_t v8 = (_OWORD *)(a7 - 16);
    do
    {
      long long v9 = *((_OWORD *)a3 - 1);
      a3 -= 2;
      *uint64_t v8 = v9;
      *a3 = 0;
      a3[1] = 0;
      *((void *)&v15 + 1) = v8;
      v7 -= 16;
      --v8;
    }
    while (a3 != a5);
    uint64_t v10 = v15;
  }
  char v13 = 1;
  std::__exception_guard_exceptions<std::_AllocatorDestroyRangeReverse<std::allocator<std::shared_ptr<ZinIrHazardNode>>,std::reverse_iterator<std::shared_ptr<ZinIrHazardNode>*>>>::~__exception_guard_exceptions[abi:ne180100]((uint64_t)v12);
  return v10;
}

uint64_t std::__exception_guard_exceptions<std::_AllocatorDestroyRangeReverse<std::allocator<std::shared_ptr<ZinIrHazardNode>>,std::reverse_iterator<std::shared_ptr<ZinIrHazardNode>*>>>::~__exception_guard_exceptions[abi:ne180100](uint64_t a1)
{
  if (!*(unsigned char *)(a1 + 24)) {
    std::_AllocatorDestroyRangeReverse<std::allocator<std::shared_ptr<ZinIrConstData>>,std::reverse_iterator<std::shared_ptr<ZinIrConstData>*>>::operator()[abi:ne180100](a1);
  }
  return a1;
}

void *std::vector<std::shared_ptr<ZinIrHazardNode>>::__init_with_size[abi:ne180100]<std::shared_ptr<ZinIrHazardNode>*,std::shared_ptr<ZinIrHazardNode>*>(void *result, void *a2, void *a3, unint64_t a4)
{
  if (a4)
  {
    uint64_t v6 = result;
    std::vector<std::pair<unsigned long,unsigned long>>::__vallocate[abi:ne180100](result, a4);
    uint64_t result = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::shared_ptr<ZinIrHazardNode>>,std::shared_ptr<ZinIrHazardNode>*,std::shared_ptr<ZinIrHazardNode>*,std::shared_ptr<ZinIrHazardNode>*>((uint64_t)(v6 + 2), a2, a3, (void *)v6[1]);
    v6[1] = result;
  }
  return result;
}

void sub_2113988E8(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, void **a9)
{
  *(void *)(v9 + 8) = v10;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100](&a9);
  _Unwind_Resume(a1);
}

void *std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::shared_ptr<ZinIrHazardNode>>,std::shared_ptr<ZinIrHazardNode>*,std::shared_ptr<ZinIrHazardNode>*,std::shared_ptr<ZinIrHazardNode>*>(uint64_t a1, void *a2, void *a3, void *a4)
{
  unint64_t v4 = a4;
  uint64_t v10 = a4;
  uint64_t v9 = a4;
  v7[0] = a1;
  v7[1] = &v9;
  v7[2] = &v10;
  if (a2 != a3)
  {
    do
    {
      *unint64_t v4 = *a2;
      uint64_t v5 = a2[1];
      v4[1] = v5;
      if (v5) {
        atomic_fetch_add_explicit((atomic_ullong *volatile)(v5 + 8), 1uLL, memory_order_relaxed);
      }
      v4 += 2;
      a2 += 2;
    }
    while (a2 != a3);
    uint64_t v10 = v4;
  }
  char v8 = 1;
  std::__exception_guard_exceptions<std::_AllocatorDestroyRangeReverse<std::allocator<std::shared_ptr<ZinIrHazardNode>>,std::shared_ptr<ZinIrHazardNode>*>>::~__exception_guard_exceptions[abi:ne180100]((uint64_t)v7);
  return v4;
}

uint64_t std::__exception_guard_exceptions<std::_AllocatorDestroyRangeReverse<std::allocator<std::shared_ptr<ZinIrHazardNode>>,std::shared_ptr<ZinIrHazardNode>*>>::~__exception_guard_exceptions[abi:ne180100](uint64_t a1)
{
  if (!*(unsigned char *)(a1 + 24)) {
    std::_AllocatorDestroyRangeReverse<std::allocator<std::shared_ptr<ZinIrConstData>>,std::shared_ptr<ZinIrConstData>*>::operator()[abi:ne180100](a1);
  }
  return a1;
}

void std::vector<std::shared_ptr<ZinIrHazardNode>>::__assign_with_size[abi:ne180100]<std::shared_ptr<ZinIrHazardNode>*,std::shared_ptr<ZinIrHazardNode>*>(uint64_t a1, uint64_t *a2, uint64_t *a3, unint64_t a4)
{
  uint64_t v8 = a1 + 16;
  uint64_t v9 = *(void **)a1;
  if (a4 > (uint64_t)(*(void *)(a1 + 16) - *(void *)a1) >> 4)
  {
    std::vector<std::shared_ptr<ZinIrConstData>>::__vdeallocate((uint64_t *)a1);
    if (a4 >> 60) {
      std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
    }
    uint64_t v10 = *(void *)(a1 + 16) - *(void *)a1;
    uint64_t v11 = v10 >> 3;
    if (v10 >> 3 <= a4) {
      uint64_t v11 = a4;
    }
    if ((unint64_t)v10 >= 0x7FFFFFFFFFFFFFF0) {
      unint64_t v12 = 0xFFFFFFFFFFFFFFFLL;
    }
    else {
      unint64_t v12 = v11;
    }
    std::vector<std::pair<unsigned long,unsigned long>>::__vallocate[abi:ne180100]((void *)a1, v12);
    char v13 = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::shared_ptr<ZinIrHazardNode>>,std::shared_ptr<ZinIrHazardNode>*,std::shared_ptr<ZinIrHazardNode>*,std::shared_ptr<ZinIrHazardNode>*>(v8, a2, a3, *(void **)(a1 + 8));
    goto LABEL_11;
  }
  unint64_t v14 = (uint64_t)(*(void *)(a1 + 8) - (void)v9) >> 4;
  if (v14 < a4)
  {
    long long v15 = &a2[2 * v14];
    std::__copy_loop<std::_ClassicAlgPolicy>::operator()[abi:ne180100]<std::shared_ptr<ZinIrConstData> const*,std::shared_ptr<ZinIrConstData> const*,std::shared_ptr<ZinIrConstData>*>((uint64_t)&v20, a2, v15, v9);
    char v13 = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::shared_ptr<ZinIrHazardNode>>,std::shared_ptr<ZinIrHazardNode>*,std::shared_ptr<ZinIrHazardNode>*,std::shared_ptr<ZinIrHazardNode>*>(v8, v15, a3, *(void **)(a1 + 8));
LABEL_11:
    *(void *)(a1 + 8) = v13;
    return;
  }
  std::__copy_loop<std::_ClassicAlgPolicy>::operator()[abi:ne180100]<std::shared_ptr<ZinIrConstData> const*,std::shared_ptr<ZinIrConstData> const*,std::shared_ptr<ZinIrConstData>*>((uint64_t)&v21, a2, a3, v9);
  uint64_t v17 = v16;
  uint64_t v18 = *(void *)(a1 + 8);
  if (v18 != v16)
  {
    do
    {
      long long v19 = *(std::__shared_weak_count **)(v18 - 8);
      if (v19) {
        std::__shared_weak_count::__release_shared[abi:ne180100](v19);
      }
      v18 -= 16;
    }
    while (v18 != v17);
  }
  *(void *)(a1 + 8) = v17;
}

void sub_211398B14(_Unwind_Exception *a1)
{
  *(void *)(v1 + 8) = v2;
  _Unwind_Resume(a1);
}

void sub_211398B1C(_Unwind_Exception *a1)
{
  *(void *)(v1 + 8) = v2;
  _Unwind_Resume(a1);
}

void std::__introsort<std::_ClassicAlgPolicy,ZinMirL2HazardAnalysis::HazardNodeSorter &,std::shared_ptr<ZinIrHazardNode> *,false>(uint64_t a1, ZinIrHazardNode **a2, uint64_t a3, uint64_t a4, char a5)
{
  uint64_t v10 = (ZinIrHazardNode **)a1;
LABEL_2:
  uint64_t v11 = (uint64_t)v10;
LABEL_3:
  uint64_t v12 = 1 - a4;
  while (1)
  {
    uint64_t v10 = (ZinIrHazardNode **)v11;
    uint64_t v13 = v12;
    uint64_t v14 = (uint64_t)a2 - v11;
    unint64_t v15 = ((uint64_t)a2 - v11) >> 4;
    if (!(!v6 & v5))
    {
      switch(v15)
      {
        case 0uLL:
        case 1uLL:
          return;
        case 2uLL:
          if (ZinMirL2HazardAnalysis::HazardNodeSorter::operator()(a1, a2 - 2, (ZinIrHazardNode **)v11))
          {
            std::string::size_type v23 = *(ZinIrHazardNode **)v11;
            *(void *)uint64_t v11 = *(a2 - 2);
            *(a2 - 2) = v23;
            uint64_t v24 = *(ZinIrHazardNode **)(v11 + 8);
            *(void *)(v11 + 8) = *(a2 - 1);
            *(a2 - 1) = v24;
          }
          break;
        case 3uLL:
          std::__sort3[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirL2HazardAnalysis::HazardNodeSorter &,std::shared_ptr<ZinIrHazardNode> *>(v11, v11 + 16, (uint64_t)(a2 - 2));
          break;
        case 4uLL:
          std::__sort4[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirL2HazardAnalysis::HazardNodeSorter &,std::shared_ptr<ZinIrHazardNode> *>(v11, v11 + 16, v11 + 32, (uint64_t)(a2 - 2));
          break;
        case 5uLL:
          std::__sort5[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirL2HazardAnalysis::HazardNodeSorter &,std::shared_ptr<ZinIrHazardNode> *>(v11, v11 + 16, v11 + 32, v11 + 48, (uint64_t)(a2 - 2));
          break;
        default:
          JUMPOUT(0);
      }
      return;
    }
    if (v14 <= 383) {
      break;
    }
    if (v13 == 1)
    {
      if ((ZinIrHazardNode **)v11 != a2)
      {
        std::__partial_sort_impl[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirL2HazardAnalysis::HazardNodeSorter &,std::shared_ptr<ZinIrHazardNode> *,std::shared_ptr<ZinIrHazardNode> *>(v11, (uint64_t)a2, (uint64_t)a2, a3);
      }
      return;
    }
    unint64_t v16 = v15 >> 1;
    uint64_t v17 = (_OWORD *)(v11 + 16 * (v15 >> 1));
    if ((unint64_t)v14 >= 0x801)
    {
      std::__sort3[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirL2HazardAnalysis::HazardNodeSorter &,std::shared_ptr<ZinIrHazardNode> *>(v11, v11 + 16 * (v15 >> 1), (uint64_t)(a2 - 2));
      std::__sort3[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirL2HazardAnalysis::HazardNodeSorter &,std::shared_ptr<ZinIrHazardNode> *>(v11 + 16, (uint64_t)(v17 - 1), (uint64_t)(a2 - 4));
      std::__sort3[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirL2HazardAnalysis::HazardNodeSorter &,std::shared_ptr<ZinIrHazardNode> *>(v11 + 32, v11 + 16 + 16 * v16, (uint64_t)(a2 - 6));
      uint64_t v19 = std::__sort3[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirL2HazardAnalysis::HazardNodeSorter &,std::shared_ptr<ZinIrHazardNode> *>((uint64_t)(v17 - 1), (uint64_t)v17, v11 + 16 + 16 * v16);
      long long v18 = *(_OWORD *)v11;
      *(_OWORD *)uint64_t v11 = *v17;
      _OWORD *v17 = v18;
      if (a5) {
        goto LABEL_14;
      }
    }
    else
    {
      uint64_t v19 = std::__sort3[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirL2HazardAnalysis::HazardNodeSorter &,std::shared_ptr<ZinIrHazardNode> *>(v11 + 16 * (v15 >> 1), v11, (uint64_t)(a2 - 2));
      if (a5) {
        goto LABEL_14;
      }
    }
    if (!ZinMirL2HazardAnalysis::HazardNodeSorter::operator()(v19, (ZinIrHazardNode **)(v11 - 16), (ZinIrHazardNode **)v11))
    {
      a1 = (uint64_t)std::__partition_with_equals_on_left[abi:ne180100]<std::_ClassicAlgPolicy,std::shared_ptr<ZinIrHazardNode> *,ZinMirL2HazardAnalysis::HazardNodeSorter &>((ZinIrHazardNode **)v11, (unint64_t)a2);
      uint64_t v11 = a1;
      goto LABEL_19;
    }
LABEL_14:
    unint64_t v20 = std::__partition_with_equals_on_right[abi:ne180100]<std::_ClassicAlgPolicy,std::shared_ptr<ZinIrHazardNode> *,ZinMirL2HazardAnalysis::HazardNodeSorter &>(v11, a2);
    if ((v21 & 1) == 0) {
      goto LABEL_17;
    }
    BOOL v22 = std::__insertion_sort_incomplete[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirL2HazardAnalysis::HazardNodeSorter &,std::shared_ptr<ZinIrHazardNode> *>(v11, v20);
    uint64_t v11 = v20 + 16;
    a1 = std::__insertion_sort_incomplete[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirL2HazardAnalysis::HazardNodeSorter &,std::shared_ptr<ZinIrHazardNode> *>(v20 + 16, (uint64_t)a2);
    if (a1)
    {
      a4 = -v13;
      a2 = (ZinIrHazardNode **)v20;
      if (v22) {
        return;
      }
      goto LABEL_2;
    }
    uint64_t v12 = v13 + 1;
    if (!v22)
    {
LABEL_17:
      a1 = std::__introsort<std::_ClassicAlgPolicy,ZinMirL2HazardAnalysis::HazardNodeSorter &,std::shared_ptr<ZinIrHazardNode> *,false>(v10, v20, a3, -v13, a5 & 1);
      uint64_t v11 = v20 + 16;
LABEL_19:
      a5 = 0;
      a4 = -v13;
      goto LABEL_3;
    }
  }
  if (a5)
  {
    std::__insertion_sort[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirL2HazardAnalysis::HazardNodeSorter &,std::shared_ptr<ZinIrHazardNode> *>(v11, (uint64_t)a2);
  }
  else
  {
    std::__insertion_sort_unguarded[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirL2HazardAnalysis::HazardNodeSorter &,std::shared_ptr<ZinIrHazardNode> *>(v11, (uint64_t)a2);
  }
}

void std::__insertion_sort[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirL2HazardAnalysis::HazardNodeSorter &,std::shared_ptr<ZinIrHazardNode> *>(uint64_t a1, uint64_t a2)
{
  if (a1 != a2)
  {
    uint64_t v3 = a1;
    unint64_t v4 = (ZinIrHazardNode **)(a1 + 16);
    if (a1 + 16 != a2)
    {
      uint64_t v5 = 0;
      uint64_t v6 = a1;
      do
      {
        uint64_t v7 = (ZinIrHazardNode **)v6;
        uint64_t v6 = (uint64_t)v4;
        LODWORD(a1) = ZinMirL2HazardAnalysis::HazardNodeSorter::operator()(a1, v4, v7);
        if (a1)
        {
          long long v16 = *(_OWORD *)v6;
          *(void *)uint64_t v6 = 0;
          *(void *)(v6 + 8) = 0;
          uint64_t v8 = v5;
          while (1)
          {
            uint64_t v9 = v3 + v8;
            long long v10 = *(_OWORD *)(v3 + v8);
            *(void *)uint64_t v9 = 0;
            *(void *)(v9 + 8) = 0;
            uint64_t v11 = *(std::__shared_weak_count **)(v3 + v8 + 24);
            *(_OWORD *)(v9 + 16) = v10;
            if (v11) {
              std::__shared_weak_count::__release_shared[abi:ne180100](v11);
            }
            if (!v8) {
              break;
            }
            BOOL v12 = ZinMirL2HazardAnalysis::HazardNodeSorter::operator()((uint64_t)v11, (ZinIrHazardNode **)&v16, (ZinIrHazardNode **)(v3 + v8 - 16));
            v8 -= 16;
            if (!v12)
            {
              uint64_t v13 = v3 + v8 + 16;
              goto LABEL_12;
            }
          }
          uint64_t v13 = v3;
LABEL_12:
          long long v14 = v16;
          long long v16 = 0uLL;
          unint64_t v15 = *(std::__shared_weak_count **)(v13 + 8);
          *(_OWORD *)uint64_t v13 = v14;
          if (v15) {
            std::__shared_weak_count::__release_shared[abi:ne180100](v15);
          }
          a1 = *((void *)&v16 + 1);
          if (*((void *)&v16 + 1)) {
            std::__shared_weak_count::__release_shared[abi:ne180100](*((std::__shared_weak_count **)&v16 + 1));
          }
        }
        unint64_t v4 = (ZinIrHazardNode **)(v6 + 16);
        v5 += 16;
      }
      while (v6 + 16 != a2);
    }
  }
}

void sub_211398FEC(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, std::__shared_weak_count *a10)
{
  if (a10) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a10);
  }
  _Unwind_Resume(exception_object);
}

void std::__insertion_sort_unguarded[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirL2HazardAnalysis::HazardNodeSorter &,std::shared_ptr<ZinIrHazardNode> *>(uint64_t a1, uint64_t a2)
{
  if (a1 != a2)
  {
    uint64_t v3 = a1;
    unint64_t v4 = (ZinIrHazardNode **)(a1 + 16);
    if (a1 + 16 != a2)
    {
      uint64_t v5 = a1 - 16;
      do
      {
        uint64_t v6 = (ZinIrHazardNode **)v3;
        uint64_t v3 = (uint64_t)v4;
        LODWORD(a1) = ZinMirL2HazardAnalysis::HazardNodeSorter::operator()(a1, v4, v6);
        if (a1)
        {
          long long v13 = *(_OWORD *)v3;
          *(void *)uint64_t v3 = 0;
          *(void *)(v3 + 8) = 0;
          uint64_t v7 = v5;
          do
          {
            long long v8 = *(_OWORD *)(v7 + 16);
            *(void *)(v7 + 16) = 0;
            *(void *)(v7 + 24) = 0;
            uint64_t v9 = *(std::__shared_weak_count **)(v7 + 40);
            *(_OWORD *)(v7 + 32) = v8;
            if (v9) {
              std::__shared_weak_count::__release_shared[abi:ne180100](v9);
            }
            BOOL v10 = ZinMirL2HazardAnalysis::HazardNodeSorter::operator()((uint64_t)v9, (ZinIrHazardNode **)&v13, (ZinIrHazardNode **)v7);
            v7 -= 16;
          }
          while (v10);
          long long v11 = v13;
          long long v13 = 0uLL;
          BOOL v12 = *(std::__shared_weak_count **)(v7 + 40);
          *(_OWORD *)(v7 + 32) = v11;
          if (v12) {
            std::__shared_weak_count::__release_shared[abi:ne180100](v12);
          }
          a1 = *((void *)&v13 + 1);
          if (*((void *)&v13 + 1)) {
            std::__shared_weak_count::__release_shared[abi:ne180100](*((std::__shared_weak_count **)&v13 + 1));
          }
        }
        unint64_t v4 = (ZinIrHazardNode **)(v3 + 16);
        v5 += 16;
      }
      while (v3 + 16 != a2);
    }
  }
}

void sub_2113990D4(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, std::__shared_weak_count *a10)
{
  if (a10) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a10);
  }
  _Unwind_Resume(exception_object);
}

uint64_t std::__sort3[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirL2HazardAnalysis::HazardNodeSorter &,std::shared_ptr<ZinIrHazardNode> *>(uint64_t a1, uint64_t a2, uint64_t a3)
{
  BOOL v6 = ZinMirL2HazardAnalysis::HazardNodeSorter::operator()(a1, (ZinIrHazardNode **)a2, (ZinIrHazardNode **)a1);
  BOOL v7 = v6;
  uint64_t result = ZinMirL2HazardAnalysis::HazardNodeSorter::operator()(v6, (ZinIrHazardNode **)a3, (ZinIrHazardNode **)a2);
  if (v7)
  {
    uint64_t v9 = *(ZinIrHazardNode **)a1;
    if (result)
    {
      *(void *)a1 = *(void *)a3;
      *(void *)a3 = v9;
      BOOL v10 = (uint64_t *)(a3 + 8);
      uint64_t result = 1;
      long long v11 = (uint64_t *)(a1 + 8);
LABEL_9:
      long long v14 = v10;
      goto LABEL_10;
    }
    *(void *)a1 = *(void *)a2;
    *(void *)a2 = v9;
    uint64_t v16 = *(void *)(a1 + 8);
    *(void *)(a1 + 8) = *(void *)(a2 + 8);
    *(void *)(a2 + 8) = v16;
    if (ZinMirL2HazardAnalysis::HazardNodeSorter::operator()(result, (ZinIrHazardNode **)a3, (ZinIrHazardNode **)a2))
    {
      uint64_t v17 = *(ZinIrHazardNode **)a2;
      *(void *)a2 = *(void *)a3;
      *(void *)a3 = v17;
      BOOL v10 = (uint64_t *)(a3 + 8);
      uint64_t result = 2;
      long long v11 = (uint64_t *)(a2 + 8);
      goto LABEL_9;
    }
  }
  else
  {
    if (!result) {
      return result;
    }
    BOOL v12 = *(ZinIrHazardNode **)a2;
    *(void *)a2 = *(void *)a3;
    *(void *)a3 = v12;
    long long v14 = (uint64_t *)(a2 + 8);
    uint64_t v13 = *(void *)(a2 + 8);
    *(void *)(a2 + 8) = *(void *)(a3 + 8);
    *(void *)(a3 + 8) = v13;
    if (ZinMirL2HazardAnalysis::HazardNodeSorter::operator()(result, (ZinIrHazardNode **)a2, (ZinIrHazardNode **)a1))
    {
      unint64_t v15 = *(ZinIrHazardNode **)a1;
      *(void *)a1 = *(void *)a2;
      long long v11 = (uint64_t *)(a1 + 8);
      *(void *)a2 = v15;
      uint64_t result = 2;
LABEL_10:
      uint64_t v18 = *v11;
      uint64_t *v11 = *v14;
      *long long v14 = v18;
      return result;
    }
  }
  return 1;
}

ZinIrHazardNode **std::__partition_with_equals_on_left[abi:ne180100]<std::_ClassicAlgPolicy,std::shared_ptr<ZinIrHazardNode> *,ZinMirL2HazardAnalysis::HazardNodeSorter &>(ZinIrHazardNode **a1, unint64_t a2)
{
  unint64_t v2 = a2;
  unint64_t v4 = a1[1];
  *(void *)&long long v16 = *a1;
  *((void *)&v16 + 1) = v4;
  *a1 = 0;
  a1[1] = 0;
  BOOL v5 = ZinMirL2HazardAnalysis::HazardNodeSorter::operator()((uint64_t)a1, (ZinIrHazardNode **)&v16, (ZinIrHazardNode **)(a2 - 16));
  if (v5)
  {
    BOOL v6 = a1;
    do
    {
      v6 += 2;
      BOOL v5 = ZinMirL2HazardAnalysis::HazardNodeSorter::operator()(v5, (ZinIrHazardNode **)&v16, v6);
    }
    while (!v5);
  }
  else
  {
    BOOL v7 = a1 + 2;
    do
    {
      BOOL v6 = v7;
      if ((unint64_t)v7 >= v2) {
        break;
      }
      BOOL v5 = ZinMirL2HazardAnalysis::HazardNodeSorter::operator()(v5, (ZinIrHazardNode **)&v16, v7);
      BOOL v7 = v6 + 2;
    }
    while (!v5);
  }
  if ((unint64_t)v6 < v2)
  {
    do
    {
      v2 -= 16;
      BOOL v5 = ZinMirL2HazardAnalysis::HazardNodeSorter::operator()(v5, (ZinIrHazardNode **)&v16, (ZinIrHazardNode **)v2);
    }
    while (v5);
  }
  while ((unint64_t)v6 < v2)
  {
    long long v8 = *v6;
    *BOOL v6 = *(ZinIrHazardNode **)v2;
    *(void *)unint64_t v2 = v8;
    uint64_t v9 = v6[1];
    v6[1] = *(ZinIrHazardNode **)(v2 + 8);
    *(void *)(v2 + 8) = v9;
    do
    {
      v6 += 2;
      BOOL v5 = ZinMirL2HazardAnalysis::HazardNodeSorter::operator()(v5, (ZinIrHazardNode **)&v16, v6);
    }
    while (!v5);
    do
    {
      v2 -= 16;
      BOOL v5 = ZinMirL2HazardAnalysis::HazardNodeSorter::operator()(v5, (ZinIrHazardNode **)&v16, (ZinIrHazardNode **)v2);
    }
    while (v5);
  }
  BOOL v10 = v6 - 2;
  if (v6 - 2 != a1)
  {
    long long v11 = *(_OWORD *)v10;
    *BOOL v10 = 0;
    *(v6 - 1) = 0;
    BOOL v12 = (std::__shared_weak_count *)a1[1];
    *(_OWORD *)a1 = v11;
    if (v12) {
      std::__shared_weak_count::__release_shared[abi:ne180100](v12);
    }
  }
  long long v13 = v16;
  long long v16 = 0uLL;
  long long v14 = (std::__shared_weak_count *)*(v6 - 1);
  *((_OWORD *)v6 - 1) = v13;
  if (v14) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v14);
  }
  if (*((void *)&v16 + 1)) {
    std::__shared_weak_count::__release_shared[abi:ne180100](*((std::__shared_weak_count **)&v16 + 1));
  }
  return v6;
}

void sub_21139935C(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10)
{
  if (v10) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v10);
  }
  _Unwind_Resume(exception_object);
}

unint64_t std::__partition_with_equals_on_right[abi:ne180100]<std::_ClassicAlgPolicy,std::shared_ptr<ZinIrHazardNode> *,ZinMirL2HazardAnalysis::HazardNodeSorter &>(uint64_t a1, ZinIrHazardNode **a2)
{
  uint64_t v3 = a1;
  uint64_t v4 = 0;
  long long v16 = *(_OWORD *)a1;
  *(void *)a1 = 0;
  *(void *)(a1 + 8) = 0;
  do
  {
    a1 = ZinMirL2HazardAnalysis::HazardNodeSorter::operator()(a1, (ZinIrHazardNode **)(v3 + v4 + 16), (ZinIrHazardNode **)&v16);
    v4 += 16;
  }
  while ((a1 & 1) != 0);
  unint64_t v5 = v3 + v4;
  if (v4 == 16)
  {
    do
    {
      if (v5 >= (unint64_t)a2) {
        break;
      }
      a2 -= 2;
      a1 = ZinMirL2HazardAnalysis::HazardNodeSorter::operator()(a1, a2, (ZinIrHazardNode **)&v16);
    }
    while ((a1 & 1) == 0);
  }
  else
  {
    do
    {
      a2 -= 2;
      a1 = ZinMirL2HazardAnalysis::HazardNodeSorter::operator()(a1, a2, (ZinIrHazardNode **)&v16);
    }
    while (!a1);
  }
  unint64_t v6 = v3 + v4;
  if (v5 < (unint64_t)a2)
  {
    BOOL v7 = a2;
    do
    {
      long long v8 = *(ZinIrHazardNode **)v6;
      *(void *)unint64_t v6 = *v7;
      uint64_t *v7 = v8;
      uint64_t v9 = *(ZinIrHazardNode **)(v6 + 8);
      *(void *)(v6 + 8) = v7[1];
      v7[1] = v9;
      do
      {
        v6 += 16;
        a1 = ZinMirL2HazardAnalysis::HazardNodeSorter::operator()(a1, (ZinIrHazardNode **)v6, (ZinIrHazardNode **)&v16);
      }
      while ((a1 & 1) != 0);
      do
      {
        v7 -= 2;
        a1 = ZinMirL2HazardAnalysis::HazardNodeSorter::operator()(a1, v7, (ZinIrHazardNode **)&v16);
      }
      while (!a1);
    }
    while (v6 < (unint64_t)v7);
  }
  BOOL v10 = (long long *)(v6 - 16);
  if (v6 - 16 != v3)
  {
    long long v11 = *v10;
    *(void *)BOOL v10 = 0;
    *(void *)(v6 - 8) = 0;
    BOOL v12 = *(std::__shared_weak_count **)(v3 + 8);
    *(_OWORD *)uint64_t v3 = v11;
    if (v12) {
      std::__shared_weak_count::__release_shared[abi:ne180100](v12);
    }
  }
  long long v13 = v16;
  long long v16 = 0uLL;
  long long v14 = *(std::__shared_weak_count **)(v6 - 8);
  *(_OWORD *)(v6 - 16) = v13;
  if (v14) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v14);
  }
  if (*((void *)&v16 + 1)) {
    std::__shared_weak_count::__release_shared[abi:ne180100](*((std::__shared_weak_count **)&v16 + 1));
  }
  return v6 - 16;
}

void sub_2113994E8(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, std::__shared_weak_count *a10)
{
  if (a10) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a10);
  }
  _Unwind_Resume(exception_object);
}

BOOL std::__insertion_sort_incomplete[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirL2HazardAnalysis::HazardNodeSorter &,std::shared_ptr<ZinIrHazardNode> *>(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = (a2 - a1) >> 4;
  BOOL result = 1;
  switch(v4)
  {
    case 0:
    case 1:
      return result;
    case 2:
      if (ZinMirL2HazardAnalysis::HazardNodeSorter::operator()(1, (ZinIrHazardNode **)(a2 - 16), (ZinIrHazardNode **)a1))
      {
        unint64_t v6 = *(ZinIrHazardNode **)a1;
        *(void *)a1 = *(void *)(a2 - 16);
        *(void *)(a2 - 16) = v6;
        uint64_t v7 = *(void *)(a1 + 8);
        *(void *)(a1 + 8) = *(void *)(a2 - 8);
        *(void *)(a2 - 8) = v7;
      }
      return 1;
    case 3:
      std::__sort3[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirL2HazardAnalysis::HazardNodeSorter &,std::shared_ptr<ZinIrHazardNode> *>(a1, a1 + 16, a2 - 16);
      return 1;
    case 4:
      std::__sort4[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirL2HazardAnalysis::HazardNodeSorter &,std::shared_ptr<ZinIrHazardNode> *>(a1, a1 + 16, a1 + 32, a2 - 16);
      return 1;
    case 5:
      std::__sort5[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirL2HazardAnalysis::HazardNodeSorter &,std::shared_ptr<ZinIrHazardNode> *>(a1, a1 + 16, a1 + 32, a1 + 48, a2 - 16);
      return 1;
    default:
      long long v8 = (ZinIrHazardNode **)(a1 + 32);
      uint64_t v9 = std::__sort3[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirL2HazardAnalysis::HazardNodeSorter &,std::shared_ptr<ZinIrHazardNode> *>(a1, a1 + 16, a1 + 32);
      uint64_t v10 = a1 + 48;
      if (a1 + 48 == a2) {
        return 1;
      }
      uint64_t v11 = 0;
      int v12 = 0;
      break;
  }
  while (1)
  {
    LODWORD(v9) = ZinMirL2HazardAnalysis::HazardNodeSorter::operator()(v9, (ZinIrHazardNode **)v10, v8);
    if (v9)
    {
      long long v21 = *(_OWORD *)v10;
      *(void *)uint64_t v10 = 0;
      *(void *)(v10 + 8) = 0;
      uint64_t v13 = v11;
      while (1)
      {
        uint64_t v14 = a1 + v13;
        long long v15 = *(_OWORD *)(a1 + v13 + 32);
        *(void *)(v14 + 32) = 0;
        *(void *)(v14 + 4std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
        long long v16 = *(std::__shared_weak_count **)(a1 + v13 + 56);
        *(_OWORD *)(v14 + 48) = v15;
        if (v16) {
          std::__shared_weak_count::__release_shared[abi:ne180100](v16);
        }
        if (v13 == -32) {
          break;
        }
        BOOL v17 = ZinMirL2HazardAnalysis::HazardNodeSorter::operator()((uint64_t)v16, (ZinIrHazardNode **)&v21, (ZinIrHazardNode **)(a1 + v13 + 16));
        v13 -= 16;
        if (!v17)
        {
          uint64_t v18 = a1 + v13 + 48;
          goto LABEL_14;
        }
      }
      uint64_t v18 = a1;
LABEL_14:
      long long v19 = v21;
      long long v21 = 0uLL;
      unint64_t v20 = *(std::__shared_weak_count **)(v18 + 8);
      *(_OWORD *)uint64_t v18 = v19;
      if (v20) {
        std::__shared_weak_count::__release_shared[abi:ne180100](v20);
      }
      uint64_t v9 = *((void *)&v21 + 1);
      if (*((void *)&v21 + 1)) {
        std::__shared_weak_count::__release_shared[abi:ne180100](*((std::__shared_weak_count **)&v21 + 1));
      }
      if (++v12 == 8) {
        return v10 + 16 == a2;
      }
    }
    long long v8 = (ZinIrHazardNode **)v10;
    v11 += 16;
    v10 += 16;
    if (v10 == a2) {
      return 1;
    }
  }
}

void sub_2113996FC(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, std::__shared_weak_count *a10)
{
  if (a10) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a10);
  }
  _Unwind_Resume(exception_object);
}

BOOL std::__sort4[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirL2HazardAnalysis::HazardNodeSorter &,std::shared_ptr<ZinIrHazardNode> *>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v8 = std::__sort3[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirL2HazardAnalysis::HazardNodeSorter &,std::shared_ptr<ZinIrHazardNode> *>(a1, a2, a3);
  BOOL result = ZinMirL2HazardAnalysis::HazardNodeSorter::operator()(v8, (ZinIrHazardNode **)a4, (ZinIrHazardNode **)a3);
  if (result)
  {
    uint64_t v10 = *(ZinIrHazardNode **)a3;
    *(void *)a3 = *(void *)a4;
    *(void *)a4 = v10;
    uint64_t v11 = *(void *)(a3 + 8);
    *(void *)(a3 + 8) = *(void *)(a4 + 8);
    *(void *)(a4 + 8) = v11;
    BOOL result = ZinMirL2HazardAnalysis::HazardNodeSorter::operator()(result, (ZinIrHazardNode **)a3, (ZinIrHazardNode **)a2);
    if (result)
    {
      int v12 = *(ZinIrHazardNode **)a2;
      *(void *)a2 = *(void *)a3;
      *(void *)a3 = v12;
      uint64_t v13 = *(void *)(a2 + 8);
      *(void *)(a2 + 8) = *(void *)(a3 + 8);
      *(void *)(a3 + 8) = v13;
      BOOL result = ZinMirL2HazardAnalysis::HazardNodeSorter::operator()(result, (ZinIrHazardNode **)a2, (ZinIrHazardNode **)a1);
      if (result)
      {
        uint64_t v14 = *(ZinIrHazardNode **)a1;
        *(void *)a1 = *(void *)a2;
        *(void *)a2 = v14;
        uint64_t v15 = *(void *)(a1 + 8);
        *(void *)(a1 + 8) = *(void *)(a2 + 8);
        *(void *)(a2 + 8) = v15;
      }
    }
  }
  return result;
}

BOOL std::__sort5[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirL2HazardAnalysis::HazardNodeSorter &,std::shared_ptr<ZinIrHazardNode> *>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  BOOL v10 = std::__sort4[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirL2HazardAnalysis::HazardNodeSorter &,std::shared_ptr<ZinIrHazardNode> *>(a1, a2, a3, a4);
  BOOL result = ZinMirL2HazardAnalysis::HazardNodeSorter::operator()(v10, (ZinIrHazardNode **)a5, (ZinIrHazardNode **)a4);
  if (result)
  {
    int v12 = *(ZinIrHazardNode **)a4;
    *(void *)a4 = *(void *)a5;
    *(void *)a5 = v12;
    uint64_t v13 = *(void *)(a4 + 8);
    *(void *)(a4 + 8) = *(void *)(a5 + 8);
    *(void *)(a5 + 8) = v13;
    BOOL result = ZinMirL2HazardAnalysis::HazardNodeSorter::operator()(result, (ZinIrHazardNode **)a4, (ZinIrHazardNode **)a3);
    if (result)
    {
      uint64_t v14 = *(ZinIrHazardNode **)a3;
      *(void *)a3 = *(void *)a4;
      *(void *)a4 = v14;
      uint64_t v15 = *(void *)(a3 + 8);
      *(void *)(a3 + 8) = *(void *)(a4 + 8);
      *(void *)(a4 + 8) = v15;
      BOOL result = ZinMirL2HazardAnalysis::HazardNodeSorter::operator()(result, (ZinIrHazardNode **)a3, (ZinIrHazardNode **)a2);
      if (result)
      {
        long long v16 = *(ZinIrHazardNode **)a2;
        *(void *)a2 = *(void *)a3;
        *(void *)a3 = v16;
        uint64_t v17 = *(void *)(a2 + 8);
        *(void *)(a2 + 8) = *(void *)(a3 + 8);
        *(void *)(a3 + 8) = v17;
        BOOL result = ZinMirL2HazardAnalysis::HazardNodeSorter::operator()(result, (ZinIrHazardNode **)a2, (ZinIrHazardNode **)a1);
        if (result)
        {
          uint64_t v18 = *(ZinIrHazardNode **)a1;
          *(void *)a1 = *(void *)a2;
          *(void *)a2 = v18;
          uint64_t v19 = *(void *)(a1 + 8);
          *(void *)(a1 + 8) = *(void *)(a2 + 8);
          *(void *)(a2 + 8) = v19;
        }
      }
    }
  }
  return result;
}

uint64_t std::__partial_sort_impl[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirL2HazardAnalysis::HazardNodeSorter &,std::shared_ptr<ZinIrHazardNode> *,std::shared_ptr<ZinIrHazardNode> *>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  if (a1 != a2)
  {
    uint64_t v6 = a2;
    uint64_t v7 = a1;
    uint64_t v8 = a2 - a1;
    uint64_t v9 = (a2 - a1) >> 4;
    if (a2 - a1 >= 17)
    {
      unint64_t v10 = (unint64_t)(v9 - 2) >> 1;
      unint64_t v11 = v10 + 1;
      int v12 = (long long *)(a1 + 16 * v10);
      do
      {
        std::__sift_down[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirL2HazardAnalysis::HazardNodeSorter &,std::shared_ptr<ZinIrHazardNode> *>(v7, a4, v9, v12--);
        --v11;
      }
      while (v11);
    }
    uint64_t v13 = v6;
    if (v6 != a3)
    {
      uint64_t v14 = v6;
      do
      {
        LODWORD(a1) = ZinMirL2HazardAnalysis::HazardNodeSorter::operator()(a1, (ZinIrHazardNode **)v14, (ZinIrHazardNode **)v7);
        if (a1)
        {
          uint64_t v15 = *(ZinIrHazardNode **)v14;
          *(void *)uint64_t v14 = *(void *)v7;
          *(void *)uint64_t v7 = v15;
          uint64_t v16 = *(void *)(v14 + 8);
          *(void *)(v14 + 8) = *(void *)(v7 + 8);
          *(void *)(v7 + 8) = v16;
          std::__sift_down[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirL2HazardAnalysis::HazardNodeSorter &,std::shared_ptr<ZinIrHazardNode> *>(v7, a4, v9, (long long *)v7);
        }
        v14 += 16;
      }
      while (v14 != a3);
      uint64_t v13 = a3;
    }
    if (v8 >= 17)
    {
      unint64_t v17 = (unint64_t)v8 >> 4;
      do
      {
        std::__pop_heap[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirL2HazardAnalysis::HazardNodeSorter,std::shared_ptr<ZinIrHazardNode> *>((std::__shared_weak_count *)v7, v6, a4, v17);
        v6 -= 16;
      }
      while (v17-- > 2);
    }
    return v13;
  }
  return a3;
}

void std::__sift_down[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirL2HazardAnalysis::HazardNodeSorter &,std::shared_ptr<ZinIrHazardNode> *>(BOOL a1, uint64_t a2, uint64_t a3, long long *a4)
{
  unint64_t v4 = a3 - 2;
  if (a3 >= 2)
  {
    unint64_t v5 = a4;
    BOOL v6 = a1;
    uint64_t v7 = v4 >> 1;
    if ((uint64_t)(v4 >> 1) >= ((uint64_t)a4 - a1) >> 4)
    {
      uint64_t v9 = ((uint64_t)a4 - a1) >> 3;
      uint64_t v10 = v9 + 1;
      uint64_t v11 = a1 + 16 * (v9 + 1);
      uint64_t v12 = v9 + 2;
      if (v9 + 2 < a3)
      {
        a1 = ZinMirL2HazardAnalysis::HazardNodeSorter::operator()(a1, (ZinIrHazardNode **)(a1 + 16 * (v9 + 1)), (ZinIrHazardNode **)(v11 + 16));
        if (a1)
        {
          v11 += 16;
          uint64_t v10 = v12;
        }
      }
      if (!ZinMirL2HazardAnalysis::HazardNodeSorter::operator()(a1, (ZinIrHazardNode **)v11, (ZinIrHazardNode **)v5))
      {
        long long v19 = *v5;
        *(void *)unint64_t v5 = 0;
        *((void *)v5 + 1) = 0;
        do
        {
          uint64_t v13 = v11;
          long long v14 = *(_OWORD *)v11;
          *(void *)uint64_t v11 = 0;
          *(void *)(v11 + 8) = 0;
          uint64_t v15 = *((void *)v5 + 1);
          *unint64_t v5 = v14;
          if (v15) {
            std::__shared_weak_count::__release_shared[abi:ne180100]((std::__shared_weak_count *)v15);
          }
          if (v7 < v10) {
            break;
          }
          uint64_t v16 = (2 * v10) | 1;
          uint64_t v11 = v6 + 16 * v16;
          uint64_t v10 = 2 * v10 + 2;
          if (v10 >= a3)
          {
            uint64_t v10 = v16;
          }
          else
          {
            uint64_t v15 = ZinMirL2HazardAnalysis::HazardNodeSorter::operator()(v15, (ZinIrHazardNode **)(v6 + 16 * v16), (ZinIrHazardNode **)(v11 + 16));
            if (v15) {
              v11 += 16;
            }
            else {
              uint64_t v10 = v16;
            }
          }
          unint64_t v5 = (long long *)v13;
        }
        while (!ZinMirL2HazardAnalysis::HazardNodeSorter::operator()(v15, (ZinIrHazardNode **)v11, (ZinIrHazardNode **)&v19));
        long long v17 = v19;
        long long v19 = 0uLL;
        uint64_t v18 = *(std::__shared_weak_count **)(v13 + 8);
        *(_OWORD *)uint64_t v13 = v17;
        if (v18) {
          std::__shared_weak_count::__release_shared[abi:ne180100](v18);
        }
        if (*((void *)&v19 + 1)) {
          std::__shared_weak_count::__release_shared[abi:ne180100](*((std::__shared_weak_count **)&v19 + 1));
        }
      }
    }
  }
}

void sub_211399B78(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, std::__shared_weak_count *a10)
{
  if (a10) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a10);
  }
  _Unwind_Resume(exception_object);
}

void std::__pop_heap[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirL2HazardAnalysis::HazardNodeSorter,std::shared_ptr<ZinIrHazardNode> *>(std::__shared_weak_count *a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  if (a4 >= 2)
  {
    uint64_t v8 = a1->__vftable;
    uint64_t shared_owners = a1->__shared_owners_;
    a1->__vftable = 0;
    a1->__shared_owners_ = 0;
    uint64_t v9 = std::__floyd_sift_down[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirL2HazardAnalysis::HazardNodeSorter &,std::shared_ptr<ZinIrHazardNode> *>(a1, a3, a4);
    uint64_t v10 = (void *)v9;
    if (v9 == a2 - 16)
    {
      uint64_t v15 = *(std::__shared_weak_count **)(v9 + 8);
      *uint64_t v10 = v8;
      v10[1] = shared_owners;
      if (v15)
      {
        std::__shared_weak_count::__release_shared[abi:ne180100](v15);
      }
    }
    else
    {
      long long v11 = *(_OWORD *)(a2 - 16);
      *(void *)(a2 - 16) = 0;
      *(void *)(a2 - 8) = 0;
      uint64_t v12 = *(std::__shared_weak_count **)(v9 + 8);
      *(_OWORD *)uint64_t v10 = v11;
      if (v12) {
        std::__shared_weak_count::__release_shared[abi:ne180100](v12);
      }
      uint64_t v13 = (uint64_t)(v10 + 2);
      long long v14 = *(std::__shared_weak_count **)(a2 - 8);
      *(void *)(a2 - 16) = v8;
      *(void *)(a2 - 8) = shared_owners;
      if (v14) {
        std::__shared_weak_count::__release_shared[abi:ne180100](v14);
      }
      std::__sift_up[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirL2HazardAnalysis::HazardNodeSorter &,std::shared_ptr<ZinIrHazardNode> *>((uint64_t)a1, v13, a3, (v13 - (uint64_t)a1) >> 4);
    }
  }
}

void sub_211399C88(_Unwind_Exception *exception_object)
{
  if (v1) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v1);
  }
  _Unwind_Resume(exception_object);
}

uint64_t std::__floyd_sift_down[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirL2HazardAnalysis::HazardNodeSorter &,std::shared_ptr<ZinIrHazardNode> *>(std::__shared_weak_count *a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = (uint64_t)a1;
  uint64_t v5 = 0;
  uint64_t v6 = a3 - 2;
  if (a3 < 2) {
    uint64_t v6 = a3 - 1;
  }
  uint64_t v7 = v6 >> 1;
  do
  {
    uint64_t v8 = v4 + 16 * v5 + 16;
    uint64_t v9 = 2 * v5;
    uint64_t v5 = (2 * v5) | 1;
    uint64_t v10 = v9 + 2;
    if (v9 + 2 < a3
      && ZinMirL2HazardAnalysis::HazardNodeSorter::operator()((uint64_t)a1, (ZinIrHazardNode **)v8, (ZinIrHazardNode **)(v8 + 16)))
    {
      v8 += 16;
      uint64_t v5 = v10;
    }
    long long v11 = *(_OWORD *)v8;
    *(void *)uint64_t v8 = 0;
    *(void *)(v8 + 8) = 0;
    a1 = *(std::__shared_weak_count **)(v4 + 8);
    *(_OWORD *)uint64_t v4 = v11;
    if (a1) {
      std::__shared_weak_count::__release_shared[abi:ne180100](a1);
    }
    uint64_t v4 = v8;
  }
  while (v5 <= v7);
  return v8;
}

void std::__sift_up[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirL2HazardAnalysis::HazardNodeSorter &,std::shared_ptr<ZinIrHazardNode> *>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  unint64_t v4 = a4 - 2;
  if (a4 >= 2)
  {
    unint64_t v6 = v4 >> 1;
    uint64_t v7 = a1 + 16 * (v4 >> 1);
    uint64_t v8 = (long long *)(a2 - 16);
    if (ZinMirL2HazardAnalysis::HazardNodeSorter::operator()(a1, (ZinIrHazardNode **)v7, (ZinIrHazardNode **)(a2 - 16)))
    {
      long long v13 = *v8;
      *(void *)uint64_t v8 = 0;
      *((void *)v8 + 1) = 0;
      do
      {
        uint64_t v9 = v7;
        long long v10 = *(_OWORD *)v7;
        *(void *)uint64_t v7 = 0;
        *(void *)(v7 + 8) = 0;
        long long v11 = (std::__shared_weak_count *)*((void *)v8 + 1);
        *uint64_t v8 = v10;
        if (v11) {
          std::__shared_weak_count::__release_shared[abi:ne180100](v11);
        }
        if (!v6) {
          break;
        }
        unint64_t v6 = (v6 - 1) >> 1;
        uint64_t v7 = a1 + 16 * v6;
        uint64_t v8 = (long long *)v9;
      }
      while (ZinMirL2HazardAnalysis::HazardNodeSorter::operator()((uint64_t)v11, (ZinIrHazardNode **)v7, (ZinIrHazardNode **)&v13));
      uint64_t v12 = *(std::__shared_weak_count **)(v9 + 8);
      *(_OWORD *)uint64_t v9 = v13;
      if (v12) {
        std::__shared_weak_count::__release_shared[abi:ne180100](v12);
      }
    }
  }
}

void sub_211399E14(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, std::__shared_weak_count *a10)
{
  if (a10) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a10);
  }
  _Unwind_Resume(exception_object);
}

uint64_t *std::vector<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>>::__swap_out_circular_buffer(uint64_t *result, void *a2)
{
  uint64_t v3 = *result;
  uint64_t v2 = result[1];
  uint64_t v4 = a2[1];
  while (v2 != v3)
  {
    long long v5 = *(_OWORD *)(v2 - 32);
    v2 -= 32;
    *(_OWORD *)(v4 - 32) = v5;
    v4 -= 32;
    *(void *)uint64_t v2 = 0;
    *(void *)(v2 + 8) = 0;
    *(_OWORD *)(v4 + 16) = *(_OWORD *)(v2 + 16);
    *(void *)(v2 + 16) = 0;
    *(void *)(v2 + 24) = 0;
  }
  a2[1] = v4;
  uint64_t v6 = *result;
  *BOOL result = v4;
  a2[1] = v6;
  uint64_t v7 = result[1];
  result[1] = a2[2];
  a2[2] = v7;
  uint64_t v8 = result[2];
  result[2] = a2[3];
  a2[3] = v8;
  *a2 = a2[1];
  return result;
}

uint64_t std::__split_buffer<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>>::~__split_buffer(uint64_t a1)
{
  uint64_t v3 = *(void *)(a1 + 8);
  for (uint64_t i = *(void *)(a1 + 16); i != v3; uint64_t i = *(void *)(a1 + 16))
  {
    *(void *)(a1 + 16) = i - 32;
    std::__destroy_at[abi:ne180100]<std::pair<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>> const,ZinIrHazardGraph::EdgeType>,0>(i - 32);
  }
  if (*(void *)a1) {
    operator delete(*(void **)a1);
  }
  return a1;
}

void std::vector<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>>::__destroy_vector::operator()[abi:ne180100](void ***a1)
{
  uint64_t v1 = *a1;
  uint64_t v2 = **a1;
  if (v2)
  {
    uint64_t v4 = (uint64_t)v1[1];
    long long v5 = **a1;
    if ((void *)v4 != v2)
    {
      do
      {
        v4 -= 32;
        std::__destroy_at[abi:ne180100]<std::pair<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>> const,ZinIrHazardGraph::EdgeType>,0>(v4);
      }
      while ((void *)v4 != v2);
      long long v5 = **a1;
    }
    v1[1] = v2;
    operator delete(v5);
  }
}

ZinIrHazardGraph *std::unique_ptr<ZinIrHazardGraph>::reset[abi:ne180100](ZinIrHazardGraph **a1, ZinIrHazardGraph *a2)
{
  BOOL result = *a1;
  *a1 = a2;
  if (result)
  {
    ZinIrHazardGraph::~ZinIrHazardGraph(result);
    JUMPOUT(0x21667D3C0);
  }
  return result;
}

void ZinIrHazardGraph::~ZinIrHazardGraph(ZinIrHazardGraph *this)
{
  std::__tree<std::__value_type<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,ZinIrHazardGraph::EdgeType>,std::__map_value_compare<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,std::__value_type<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,ZinIrHazardGraph::EdgeType>,HazardEdgeCompare,true>,std::allocator<std::__value_type<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,ZinIrHazardGraph::EdgeType>>>::destroy((uint64_t)this + 152, *((void **)this + 20));
  if (*((char *)this + 151) < 0) {
    operator delete(*((void **)this + 16));
  }
  uint64_t v2 = (void *)*((void *)this + 13);
  if (v2)
  {
    *((void *)this + 14) = v2;
    operator delete(v2);
  }
  std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::~__hash_table((uint64_t)this + 64);
  std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::~__hash_table((uint64_t)this + 24);
  std::__tree<std::shared_ptr<ZinIrTensor>,ZinIrIdComparator<std::shared_ptr<ZinIrTensor>>,std::allocator<std::shared_ptr<ZinIrTensor>>>::destroy((uint64_t)this, *((void **)this + 1));
}

void std::__tree<std::__value_type<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,ZinIrHazardGraph::EdgeType>,std::__map_value_compare<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,std::__value_type<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,ZinIrHazardGraph::EdgeType>,HazardEdgeCompare,true>,std::allocator<std::__value_type<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,ZinIrHazardGraph::EdgeType>>>::destroy(uint64_t a1, void *a2)
{
  if (a2)
  {
    std::__tree<std::__value_type<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,ZinIrHazardGraph::EdgeType>,std::__map_value_compare<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,std::__value_type<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,ZinIrHazardGraph::EdgeType>,HazardEdgeCompare,true>,std::allocator<std::__value_type<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,ZinIrHazardGraph::EdgeType>>>::destroy(a1, *a2);
    std::__tree<std::__value_type<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,ZinIrHazardGraph::EdgeType>,std::__map_value_compare<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,std::__value_type<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,ZinIrHazardGraph::EdgeType>,HazardEdgeCompare,true>,std::allocator<std::__value_type<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,ZinIrHazardGraph::EdgeType>>>::destroy(a1, a2[1]);
    std::__destroy_at[abi:ne180100]<std::pair<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>> const,ZinIrHazardGraph::EdgeType>,0>((uint64_t)(a2 + 4));
    operator delete(a2);
  }
}

void *std::allocate_shared[abi:ne180100]<ZinIrHazardNode,std::allocator<ZinIrHazardNode>,ZinIrSymbol *&,ZinANELayer *&,ZinIrHazardNode::OperandType &,ZinIrHazardNode::ExecutionType,long,void>@<X0>(void *a1@<X1>, void *a2@<X2>, unsigned int *a3@<X3>, unsigned int *a4@<X4>, void *a5@<X5>, void *a6@<X8>)
{
  uint64_t v12 = operator new(0x50uLL);
  BOOL result = std::__shared_ptr_emplace<ZinIrHazardNode>::__shared_ptr_emplace[abi:ne180100]<ZinIrSymbol *&,ZinANELayer *&,ZinIrHazardNode::OperandType &,ZinIrHazardNode::ExecutionType,long,std::allocator<ZinIrHazardNode>,0>(v12, a1, a2, a3, a4, a5);
  *a6 = v12 + 3;
  a6[1] = v12;
  return result;
}

void sub_21139A0F8(_Unwind_Exception *a1)
{
  operator delete(v1);
  _Unwind_Resume(a1);
}

void *std::__shared_ptr_emplace<ZinIrHazardNode>::__shared_ptr_emplace[abi:ne180100]<ZinIrSymbol *&,ZinANELayer *&,ZinIrHazardNode::OperandType &,ZinIrHazardNode::ExecutionType,long,std::allocator<ZinIrHazardNode>,0>(void *a1, void *a2, void *a3, unsigned int *a4, unsigned int *a5, void *a6)
{
  a1[1] = 0;
  a1[2] = 0;
  *a1 = &unk_26C388C48;
  ZinIrHazardNode::ZinIrHazardNode(a1 + 3, *a2, *a3, *a4, *a5, *a6);
  return a1;
}

void sub_21139A168(_Unwind_Exception *a1)
{
  std::__shared_weak_count::~__shared_weak_count(v1);
  _Unwind_Resume(a1);
}

void std::__shared_ptr_emplace<ZinIrHazardNode>::~__shared_ptr_emplace(std::__shared_weak_count *this)
{
  this->__vftable = (std::__shared_weak_count_vtbl *)&unk_26C388C48;
  std::__shared_weak_count::~__shared_weak_count(this);
}

void std::__shared_ptr_emplace<ZinIrHazardNode>::~__shared_ptr_emplace(std::__shared_weak_count *a1)
{
  a1->__vftable = (std::__shared_weak_count_vtbl *)&unk_26C388C48;
  std::__shared_weak_count::~__shared_weak_count(a1);

  JUMPOUT(0x21667D3C0);
}

void std::__shared_ptr_emplace<ZinIrHazardNode>::__on_zero_shared(uint64_t a1)
{
  if (*(char *)(a1 + 71) < 0) {
    operator delete(*(void **)(a1 + 48));
  }
}

uint64_t *std::__tree<std::shared_ptr<ZinIrHazardNode>,HazardNodeCompare,std::allocator<std::shared_ptr<ZinIrHazardNode>>>::__emplace_unique_key_args<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode> const&>(uint64_t **a1, uint64_t a2, uint64_t *a3)
{
  long long v5 = (uint64_t **)std::__tree<std::shared_ptr<ZinIrHazardNode>,HazardNodeCompare,std::allocator<std::shared_ptr<ZinIrHazardNode>>>::__find_equal<std::shared_ptr<ZinIrHazardNode>>((uint64_t)a1, &v10, a2);
  uint64_t v6 = *v5;
  if (!*v5)
  {
    uint64_t v7 = v5;
    uint64_t v6 = (uint64_t *)operator new(0x30uLL);
    uint64_t v8 = a3[1];
    v6[4] = *a3;
    v6[5] = v8;
    if (v8) {
      atomic_fetch_add_explicit((atomic_ullong *volatile)(v8 + 8), 1uLL, memory_order_relaxed);
    }
    std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::__insert_node_at(a1, v10, v7, v6);
  }
  return v6;
}

void *std::__tree<std::shared_ptr<ZinIrHazardNode>,HazardNodeCompare,std::allocator<std::shared_ptr<ZinIrHazardNode>>>::__find_equal<std::shared_ptr<ZinIrHazardNode>>(uint64_t a1, void *a2, uint64_t a3)
{
  long long v5 = (void *)(a1 + 8);
  uint64_t v4 = *(void **)(a1 + 8);
  if (v4)
  {
    uint64_t v7 = a1 + 16;
    do
    {
      while (1)
      {
        uint64_t v8 = v4;
        uint64_t v9 = (uint64_t)(v4 + 4);
        if (!HazardNodeCompare::operator()(v7, a3, (uint64_t)(v4 + 4))) {
          break;
        }
        uint64_t v4 = (void *)*v8;
        long long v5 = v8;
        if (!*v8) {
          goto LABEL_10;
        }
      }
      if (!HazardNodeCompare::operator()(v7, v9, a3)) {
        break;
      }
      long long v5 = v8 + 1;
      uint64_t v4 = (void *)v8[1];
    }
    while (v4);
  }
  else
  {
    uint64_t v8 = (void *)(a1 + 8);
  }
LABEL_10:
  *a2 = v8;
  return v5;
}

void *std::allocate_shared[abi:ne180100]<ZinIrHazardNode,std::allocator<ZinIrHazardNode>,ZinIrSymbol *&,ZinANELayer *&,ZinIrHazardNode::OperandType,ZinIrHazardNode::ExecutionType,long,void>@<X0>(void *a1@<X1>, void *a2@<X2>, unsigned int *a3@<X3>, unsigned int *a4@<X4>, void *a5@<X5>, void *a6@<X8>)
{
  uint64_t v12 = operator new(0x50uLL);
  BOOL result = std::__shared_ptr_emplace<ZinIrHazardNode>::__shared_ptr_emplace[abi:ne180100]<ZinIrSymbol *&,ZinANELayer *&,ZinIrHazardNode::OperandType &,ZinIrHazardNode::ExecutionType,long,std::allocator<ZinIrHazardNode>,0>(v12, a1, a2, a3, a4, a5);
  *a6 = v12 + 3;
  a6[1] = v12;
  return result;
}

void sub_21139A3B4(_Unwind_Exception *a1)
{
  operator delete(v1);
  _Unwind_Resume(a1);
}

void ZinIrNgraphUtils::impl::CalculateAsapSchedules<ZinIrHazardGraph>(void *a1@<X0>, uint64_t a2@<X8>)
{
  *(_OWORD *)a2 = 0u;
  *(_OWORD *)(a2 + 16) = 0u;
  *(_DWORD *)(a2 + 32) = 1065353216;
  uint64_t v14 = (uint64_t)&v14;
  uint64_t v15 = &v14;
  uint64_t v16 = 0;
  ZinIrNgraph<std::shared_ptr<ZinIrHazardNode>,HazardNodeCompare>::TopologicalSortImpl<std::list<std::shared_ptr<ZinIrHazardNode>>>(a1, &v14);
  for (uint64_t i = v15; i != &v14; uint64_t i = (uint64_t *)i[1])
  {
    long long v5 = (std::__shared_weak_count *)i[3];
    uint64_t v12 = i[2];
    long long v13 = v5;
    if (v5) {
      atomic_fetch_add_explicit(&v5->__shared_owners_, 1uLL, memory_order_relaxed);
    }
    long long v17 = &v12;
    uint64_t v6 = std::__hash_table<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::__unordered_map_hasher<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::__unordered_map_equal<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>>>::find<std::reference_wrapper<ZinIrOpLayer * const>>(a1 + 8, (unint64_t **)&v17);
    uint64_t v7 = v6 + 3;
    if (!v6) {
      uint64_t v7 = a1 + 13;
    }
    uint64_t v9 = (void **)*v7;
    uint64_t v8 = (void **)v7[1];
    if ((void **)*v7 == v8)
    {
      long long v17 = &v12;
      std::__hash_table<std::__hash_value_type<std::shared_ptr<ZinIrHazardNode>,long>,std::__unordered_map_hasher<std::shared_ptr<ZinIrHazardNode>,std::__hash_value_type<std::shared_ptr<ZinIrHazardNode>,long>,std::hash<std::shared_ptr<ZinIrHazardNode>>,std::equal_to<std::shared_ptr<ZinIrHazardNode>>,true>,std::__unordered_map_equal<std::shared_ptr<ZinIrHazardNode>,std::__hash_value_type<std::shared_ptr<ZinIrHazardNode>,long>,std::equal_to<std::shared_ptr<ZinIrHazardNode>>,std::hash<std::shared_ptr<ZinIrHazardNode>>,true>,std::allocator<std::__hash_value_type<std::shared_ptr<ZinIrHazardNode>,long>>>::__emplace_unique_key_args<std::shared_ptr<ZinIrHazardNode>,std::piecewise_construct_t const&,std::tuple<std::shared_ptr<ZinIrHazardNode> const&>,std::tuple<>>(a2, &v12, (uint64_t)&std::piecewise_construct, &v17)[4] = 0;
    }
    else
    {
      uint64_t v10 = 0;
      do
      {
        long long v11 = std::__hash_table<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::__unordered_map_hasher<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::hash<ZinIrTensor *>,std::equal_to<ZinIrTensor *>,true>,std::__unordered_map_equal<ZinIrTensor *,std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>,std::equal_to<ZinIrTensor *>,std::hash<ZinIrTensor *>,true>,std::allocator<std::__hash_value_type<ZinIrTensor *,std::vector<ZinIrTensor *>>>>::find<ZinIrTensor *>((void *)a2, *v9);
        if (v10 <= v11[4]) {
          uint64_t v10 = v11[4];
        }
        ++v9;
      }
      while (v9 != v8);
      long long v17 = &v12;
      std::__hash_table<std::__hash_value_type<std::shared_ptr<ZinIrHazardNode>,long>,std::__unordered_map_hasher<std::shared_ptr<ZinIrHazardNode>,std::__hash_value_type<std::shared_ptr<ZinIrHazardNode>,long>,std::hash<std::shared_ptr<ZinIrHazardNode>>,std::equal_to<std::shared_ptr<ZinIrHazardNode>>,true>,std::__unordered_map_equal<std::shared_ptr<ZinIrHazardNode>,std::__hash_value_type<std::shared_ptr<ZinIrHazardNode>,long>,std::equal_to<std::shared_ptr<ZinIrHazardNode>>,std::hash<std::shared_ptr<ZinIrHazardNode>>,true>,std::allocator<std::__hash_value_type<std::shared_ptr<ZinIrHazardNode>,long>>>::__emplace_unique_key_args<std::shared_ptr<ZinIrHazardNode>,std::piecewise_construct_t const&,std::tuple<std::shared_ptr<ZinIrHazardNode> const&>,std::tuple<>>(a2, &v12, (uint64_t)&std::piecewise_construct, &v17)[4] = v10 + 1;
    }
    if (v13) {
      std::__shared_weak_count::__release_shared[abi:ne180100](v13);
    }
  }
  std::__list_imp<std::shared_ptr<ZinMirUnit>>::clear(&v14);
}

void sub_21139A52C(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, ...)
{
  va_start(va, a4);
  std::__list_imp<std::shared_ptr<ZinMirUnit>>::clear((uint64_t *)va);
  std::__hash_table<std::__hash_value_type<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>,long>,std::__unordered_map_hasher<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>,std::__hash_value_type<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>,long>,std::hash<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>>,std::equal_to<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>>,true>,std::__unordered_map_equal<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>,std::__hash_value_type<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>,long>,std::equal_to<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>>,std::hash<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>>,true>,std::allocator<std::__hash_value_type<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>,long>>>::~__hash_table(v4);
  _Unwind_Resume(a1);
}

uint64_t ZinIrNgraph<std::shared_ptr<ZinIrHazardNode>,HazardNodeCompare>::TopologicalSortImpl<std::list<std::shared_ptr<ZinIrHazardNode>>>(void *a1, uint64_t *a2)
{
  v56[1] = *(void **)MEMORY[0x263EF8340];
  std::__list_imp<std::shared_ptr<ZinMirUnit>>::clear(a2);
  if (!a1[2]) {
    return 1;
  }
  uint64_t v54 = 0;
  uint64_t v55 = 0;
  uint64_t v53 = (uint64_t *)&v54;
  uint64_t v3 = a1 + 1;
  uint64_t v4 = (void *)*a1;
  if ((void *)*a1 == a1 + 1) {
    goto LABEL_59;
  }
  do
  {
    *(void *)&v48[0] = v4 + 4;
    long long v5 = std::__hash_table<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::__unordered_map_hasher<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::__unordered_map_equal<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>>>::find<std::reference_wrapper<ZinIrOpLayer * const>>(a1 + 8, (unint64_t **)v48);
    uint64_t v6 = v5 + 3;
    if (!v5) {
      uint64_t v6 = a1 + 13;
    }
    if (v6[1] == *v6)
    {
      *(void *)&v48[0] = v4 + 4;
      std::__tree<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,HazardNodeCompare,std::allocator<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>::__emplace_unique_key_args<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>(&v53, (uint64_t *)v48, (uint64_t *)v48);
    }
    uint64_t v7 = (void *)v4[1];
    if (v7)
    {
      do
      {
        uint64_t v8 = v7;
        uint64_t v7 = (void *)*v7;
      }
      while (v7);
    }
    else
    {
      do
      {
        uint64_t v8 = (void *)v4[2];
        BOOL v9 = *v8 == (void)v4;
        uint64_t v4 = v8;
      }
      while (!v9);
    }
    uint64_t v4 = v8;
  }
  while (v8 != v3);
  if (!v55)
  {
LABEL_59:
    uint64_t v42 = 0;
  }
  else
  {
    v52[0] = 0;
    v52[1] = 0;
    uint64_t v51 = (uint64_t *)v52;
    uint64_t v10 = (void *)*a1;
    if ((void *)*a1 != v3)
    {
      do
      {
        v50[0] = v10 + 4;
        *(void *)&v48[0] = v50;
        *((_DWORD *)std::__tree<std::__value_type<std::reference_wrapper<std::shared_ptr<ZinMirUnit> const>,int>,std::__map_value_compare<std::reference_wrapper<std::shared_ptr<ZinMirUnit> const>,std::__value_type<std::reference_wrapper<std::shared_ptr<ZinMirUnit> const>,int>,std::less<std::reference_wrapper<std::shared_ptr<ZinMirUnit> const>>,true>,std::allocator<std::__value_type<std::reference_wrapper<std::shared_ptr<ZinMirUnit> const>,int>>>::__emplace_unique_key_args<std::reference_wrapper<std::shared_ptr<ZinMirUnit> const>,std::piecewise_construct_t const&,std::tuple<std::reference_wrapper<std::shared_ptr<ZinMirUnit> const>&&>,std::tuple<>>(&v51, v50, (uint64_t)&std::piecewise_construct, (void **)v48)+ 1std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
        long long v11 = (void *)v10[1];
        if (v11)
        {
          do
          {
            uint64_t v12 = v11;
            long long v11 = (void *)*v11;
          }
          while (v11);
        }
        else
        {
          do
          {
            uint64_t v12 = (void *)v10[2];
            BOOL v9 = *v12 == (void)v10;
            uint64_t v10 = v12;
          }
          while (!v9);
        }
        uint64_t v10 = v12;
      }
      while (v12 != v3);
    }
    v50[0] = (unint64_t *)v50;
    v50[1] = (unint64_t *)v50;
    v50[2] = 0;
    long long v13 = v53;
    if (v53 != (uint64_t *)&v54)
    {
      long long v14 = 0uLL;
      do
      {
        uint64_t v15 = (void *)v13[4];
        v48[1] = v14;
        long long v49 = v14;
        v48[0] = v14;
        v56[0] = v15;
        std::list<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>::list(v46, (uint64_t)v56, 1);
        std::deque<std::list<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>::push_back(v48, v46);
        std::__list_imp<ZinIrSection *>::clear(v46);
        while (*((void *)&v49 + 1))
        {
          uint64_t v16 = *((void *)&v48[0] + 1);
          unint64_t v17 = *((void *)&v49 + 1) + v49 - 1;
          unint64_t v18 = v17 / 0xAA;
          unint64_t v19 = v17 % 0xAA;
          unint64_t v20 = *(unint64_t **)(*(void *)(*(void *)(*((void *)&v48[0] + 1) + 8 * v18) + 24 * v19 + 8) + 16);
          long long v21 = v52[0];
          if (!v52[0]) {
            goto LABEL_35;
          }
          unint64_t v22 = *v20;
          std::string::size_type v23 = v52;
          do
          {
            uint64_t v24 = v21;
            long long v25 = v23;
            unint64_t v26 = *(void *)v21[4];
            if (v26 >= v22) {
              std::string::size_type v23 = (void **)v21;
            }
            else {
              ++v21;
            }
            long long v21 = (void *)*v21;
          }
          while (v21);
          if (v23 == v52) {
            goto LABEL_35;
          }
          if (v26 < v22) {
            uint64_t v24 = v25;
          }
          if (v22 < *(void *)v24[4]) {
LABEL_35:
          }
            std::string::size_type v23 = v52;
          int v27 = *((_DWORD *)v23 + 10);
          if (v27 < 1)
          {
            v56[0] = *(void **)(*(void *)(*(void *)(*((void *)&v48[0] + 1) + 8 * v18) + 24 * v19 + 8) + 16);
            v46[0] = v56;
            uint64_t v32 = std::__tree<std::__value_type<std::reference_wrapper<std::shared_ptr<ZinMirUnit> const>,int>,std::__map_value_compare<std::reference_wrapper<std::shared_ptr<ZinMirUnit> const>,std::__value_type<std::reference_wrapper<std::shared_ptr<ZinMirUnit> const>,int>,std::less<std::reference_wrapper<std::shared_ptr<ZinMirUnit> const>>,true>,std::allocator<std::__value_type<std::reference_wrapper<std::shared_ptr<ZinMirUnit> const>,int>>>::__emplace_unique_key_args<std::reference_wrapper<std::shared_ptr<ZinMirUnit> const>,std::piecewise_construct_t const&,std::tuple<std::reference_wrapper<std::shared_ptr<ZinMirUnit> const>&&>,std::tuple<>>(&v51, v56, (uint64_t)&std::piecewise_construct, v46);
            ++*((_DWORD *)v32 + 10);
            v46[0] = v46;
            v46[1] = v46;
            uint64_t v47 = 0;
            v56[0] = v20;
            int v33 = std::__hash_table<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::__unordered_map_hasher<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::__unordered_map_equal<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>>>::find<std::reference_wrapper<ZinIrOpLayer * const>>(a1 + 3, v56);
            if (v33)
            {
              uint64_t v35 = (unint64_t **)v33[3];
              uint64_t v34 = v33[4];
              while (v35 != (unint64_t **)v34)
              {
                std::string::size_type v36 = *v35;
                unint64_t v45 = *v35;
                v56[0] = &v45;
                int v37 = *((_DWORD *)std::__tree<std::__value_type<std::reference_wrapper<std::shared_ptr<ZinMirUnit> const>,int>,std::__map_value_compare<std::reference_wrapper<std::shared_ptr<ZinMirUnit> const>,std::__value_type<std::reference_wrapper<std::shared_ptr<ZinMirUnit> const>,int>,std::less<std::reference_wrapper<std::shared_ptr<ZinMirUnit> const>>,true>,std::allocator<std::__value_type<std::reference_wrapper<std::shared_ptr<ZinMirUnit> const>,int>>>::__emplace_unique_key_args<std::reference_wrapper<std::shared_ptr<ZinMirUnit> const>,std::piecewise_construct_t const&,std::tuple<std::reference_wrapper<std::shared_ptr<ZinMirUnit> const>&&>,std::tuple<>>(&v51, &v45, (uint64_t)&std::piecewise_construct, v56)+ 10);
                if (v37)
                {
                  if (v37 == 1)
                  {
                    std::__list_imp<ZinIrSection *>::clear(v46);
                    std::deque<std::list<std::reference_wrapper<std::shared_ptr<ZinMirUnit> const>>>::~deque[abi:ne180100](v48);
                    uint64_t v42 = 0;
                    goto LABEL_61;
                  }
                }
                else
                {
                  uint64_t v38 = operator new(0x18uLL);
                  v38[1] = v46;
                  _OWORD v38[2] = v36;
                  uint64_t v39 = v46[0];
                  void *v38 = v46[0];
                  v39[1] = v38;
                  v46[0] = v38;
                  ++v47;
                }
                ++v35;
              }
            }
            if (v47) {
              std::deque<std::list<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>::push_back(v48, (uint64_t)v46);
            }
            std::__list_imp<ZinIrSection *>::clear(v46);
          }
          else
          {
            if (v27 == 1)
            {
              *((_DWORD *)v23 + 1std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 2;
              std::list<std::shared_ptr<ZinMirUnit>>::emplace_front<std::shared_ptr<ZinMirUnit> const&>((uint64_t)a2, v20);
              uint64_t v16 = *((void *)&v48[0] + 1);
              unint64_t v28 = *((void *)&v49 + 1) + v49 - 1;
              unint64_t v18 = v28 / 0xAA;
              unint64_t v19 = v28 % 0xAA;
            }
            uint64_t v29 = *(void *)(v16 + 8 * v18) + 24 * v19;
            char v30 = *(uint64_t **)(v29 + 8);
            uint64_t v31 = *v30;
            *(void *)(v31 + 8) = v30[1];
            *(void *)v30[1] = v31;
            --*(void *)(v29 + 16);
            operator delete(v30);
            if (!*(void *)(*(void *)(*((void *)&v48[0] + 1)
                                        + 8 * ((*((void *)&v49 + 1) + (void)v49 - 1) / 0xAAuLL))
                            + 24 * ((*((void *)&v49 + 1) + (void)v49 - 1) % 0xAAuLL)
                            + 16))
              std::deque<std::list<std::reference_wrapper<std::shared_ptr<ZinMirUnit> const>>>::pop_back(v48);
          }
        }
        std::deque<std::list<std::reference_wrapper<std::shared_ptr<ZinMirUnit> const>>>::~deque[abi:ne180100](v48);
        unint64_t v40 = (uint64_t *)v13[1];
        if (v40)
        {
          do
          {
            uint64_t v41 = v40;
            unint64_t v40 = (uint64_t *)*v40;
          }
          while (v40);
        }
        else
        {
          do
          {
            uint64_t v41 = (uint64_t *)v13[2];
            BOOL v9 = *v41 == (void)v13;
            long long v13 = v41;
          }
          while (!v9);
        }
        long long v13 = v41;
        long long v14 = 0uLL;
      }
      while (v41 != (uint64_t *)&v54);
    }
    uint64_t v42 = 1;
LABEL_61:
    std::__list_imp<ZinIrSection *>::clear(v50);
    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v51, v52[0]);
  }
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v53, v54);
  return v42;
}

void sub_21139AA48(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,char a27,void *a28)
{
  std::__list_imp<ZinIrSection *>::clear(&a14);
  std::deque<std::list<std::reference_wrapper<std::shared_ptr<ZinMirUnit> const>>>::~deque[abi:ne180100](&a17);
  std::__list_imp<ZinIrSection *>::clear(&a24);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&a27, a28);
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy(v28 - 136, *(void **)(v28 - 128));
  _Unwind_Resume(a1);
}

uint64_t *std::__tree<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,HazardNodeCompare,std::allocator<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>::__emplace_unique_key_args<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>(uint64_t **a1, uint64_t *a2, uint64_t *a3)
{
  long long v5 = (uint64_t **)std::__tree<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,HazardNodeCompare,std::allocator<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>::__find_equal<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>((uint64_t)a1, &v9, a2);
  uint64_t v6 = *v5;
  if (!*v5)
  {
    uint64_t v7 = v5;
    uint64_t v6 = (uint64_t *)operator new(0x28uLL);
    v6[4] = *a3;
    std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::__insert_node_at(a1, v9, v7, v6);
  }
  return v6;
}

void *std::__tree<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,HazardNodeCompare,std::allocator<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>::__find_equal<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>(uint64_t a1, void *a2, uint64_t *a3)
{
  long long v5 = (void *)(a1 + 8);
  uint64_t v4 = *(void **)(a1 + 8);
  if (v4)
  {
    uint64_t v7 = a1 + 16;
    do
    {
      while (1)
      {
        uint64_t v8 = v4;
        if (!HazardNodeCompare::operator()(v7, *a3, v4[4])) {
          break;
        }
        uint64_t v4 = (void *)*v8;
        long long v5 = v8;
        if (!*v8) {
          goto LABEL_10;
        }
      }
      if (!HazardNodeCompare::operator()(v7, v8[4], *a3)) {
        break;
      }
      long long v5 = v8 + 1;
      uint64_t v4 = (void *)v8[1];
    }
    while (v4);
  }
  else
  {
    uint64_t v8 = (void *)(a1 + 8);
  }
LABEL_10:
  *a2 = v8;
  return v5;
}

uint64_t *std::deque<std::list<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>::push_back(void *a1, void *a2)
{
  uint64_t v4 = a1[1];
  uint64_t v5 = a1[2];
  uint64_t v6 = 170 * ((v5 - v4) >> 3) - 1;
  if (v5 == v4) {
    uint64_t v6 = 0;
  }
  if (v6 == a1[5] + a1[4])
  {
    std::deque<std::list<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>::__add_back_capacity(a1);
    uint64_t v4 = a1[1];
    uint64_t v5 = a1[2];
  }
  if (v5 == v4)
  {
    uint64_t v8 = 0;
  }
  else
  {
    unint64_t v7 = a1[5] + a1[4];
    uint64_t v8 = (uint64_t *)(*(void *)(v4 + 8 * (v7 / 0xAA)) + 24 * (v7 % 0xAA));
  }
  BOOL result = std::construct_at[abi:ne180100]<std::list<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,std::list<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,std::list<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>*>(v8, a2);
  ++a1[5];
  return result;
}

void std::deque<std::list<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>::__add_back_capacity(void *a1)
{
  unint64_t v2 = a1[4];
  BOOL v3 = v2 >= 0xAA;
  unint64_t v4 = v2 - 170;
  if (v3)
  {
    uint64_t v5 = (uint64_t)(a1 + 3);
    uint64_t v6 = (char *)a1[3];
    a1[4] = v4;
    unint64_t v7 = (void *)a1[1];
    uint64_t v8 = (char *)a1[2];
    uint64_t v11 = *v7;
    uint64_t v9 = (char *)(v7 + 1);
    uint64_t v10 = v11;
    a1[1] = v9;
    if (v8 != v6)
    {
LABEL_33:
      *(void *)uint64_t v8 = v10;
      a1[2] += 8;
      return;
    }
    uint64_t v12 = (uint64_t)&v9[-*a1];
    if ((unint64_t)v9 <= *a1)
    {
      if (v8 == (char *)*a1) {
        unint64_t v33 = 1;
      }
      else {
        unint64_t v33 = (uint64_t)&v8[-*a1] >> 2;
      }
      uint64_t v34 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>(v5, v33);
      uint64_t v35 = &v34[8 * (v33 >> 2)];
      int v37 = &v34[8 * v36];
      uint64_t v38 = (uint64_t *)a1[1];
      uint64_t v8 = v35;
      uint64_t v39 = a1[2] - (void)v38;
      if (v39)
      {
        uint64_t v8 = &v35[v39 & 0xFFFFFFFFFFFFFFF8];
        uint64_t v40 = 8 * (v39 >> 3);
        uint64_t v41 = &v34[8 * (v33 >> 2)];
        do
        {
          uint64_t v42 = *v38++;
          *(void *)uint64_t v41 = v42;
          v41 += 8;
          v40 -= 8;
        }
        while (v40);
      }
      goto LABEL_30;
    }
LABEL_5:
    uint64_t v13 = v12 >> 3;
    BOOL v14 = v12 >> 3 < -1;
    uint64_t v15 = (v12 >> 3) + 2;
    if (v14) {
      uint64_t v16 = v15;
    }
    else {
      uint64_t v16 = v13 + 1;
    }
    uint64_t v17 = -(v16 >> 1);
    uint64_t v18 = v16 >> 1;
    unint64_t v19 = &v9[-8 * v18];
    int64_t v20 = v8 - v9;
    if (v8 != v9)
    {
      memmove(&v9[-8 * v18], v9, v8 - v9);
      uint64_t v9 = (char *)a1[1];
    }
    uint64_t v8 = &v19[v20];
    a1[1] = &v9[8 * v17];
    a1[2] = &v19[v20];
    goto LABEL_33;
  }
  uint64_t v21 = a1[2];
  unint64_t v22 = (v21 - a1[1]) >> 3;
  uint64_t v23 = a1[3];
  uint64_t v24 = v23 - *a1;
  if (v22 < v24 >> 3)
  {
    if (v23 != v21)
    {
      *(void *)&long long v54 = operator new(0xFF0uLL);
      std::__split_buffer<unsigned long *>::push_back(a1, &v54);
      return;
    }
    *(void *)&long long v54 = operator new(0xFF0uLL);
    std::__split_buffer<unsigned long *>::push_front((uint64_t)a1, &v54);
    uint64_t v44 = (void *)a1[1];
    uint64_t v8 = (char *)a1[2];
    uint64_t v45 = *v44;
    uint64_t v9 = (char *)(v44 + 1);
    uint64_t v10 = v45;
    a1[1] = v9;
    if (v8 != (char *)a1[3]) {
      goto LABEL_33;
    }
    uint64_t v12 = (uint64_t)&v9[-*a1];
    if ((unint64_t)v9 <= *a1)
    {
      if (v8 == (char *)*a1) {
        unint64_t v46 = 1;
      }
      else {
        unint64_t v46 = (uint64_t)&v8[-*a1] >> 2;
      }
      uint64_t v34 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)(a1 + 3), v46);
      uint64_t v35 = &v34[8 * (v46 >> 2)];
      int v37 = &v34[8 * v47];
      int v48 = (uint64_t *)a1[1];
      uint64_t v8 = v35;
      uint64_t v49 = a1[2] - (void)v48;
      if (v49)
      {
        uint64_t v8 = &v35[v49 & 0xFFFFFFFFFFFFFFF8];
        uint64_t v50 = 8 * (v49 >> 3);
        uint64_t v51 = &v34[8 * (v46 >> 2)];
        do
        {
          uint64_t v52 = *v48++;
          *(void *)uint64_t v51 = v52;
          v51 += 8;
          v50 -= 8;
        }
        while (v50);
      }
LABEL_30:
      uint64_t v43 = (char *)*a1;
      *a1 = v34;
      a1[1] = v35;
      a1[2] = v8;
      a1[3] = v37;
      if (v43)
      {
        operator delete(v43);
        uint64_t v8 = (char *)a1[2];
      }
      goto LABEL_33;
    }
    goto LABEL_5;
  }
  if (v23 == *a1) {
    unint64_t v25 = 1;
  }
  else {
    unint64_t v25 = v24 >> 2;
  }
  uint64_t v56 = a1 + 3;
  *(void *)&long long v54 = std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)(a1 + 3), v25);
  *((void *)&v54 + 1) = v54 + 8 * v22;
  *(void *)&long long v55 = *((void *)&v54 + 1);
  *((void *)&v55 + 1) = v54 + 8 * v26;
  uint64_t v53 = operator new(0xFF0uLL);
  std::__split_buffer<unsigned long *>::push_back(&v54, &v53);
  int v27 = (void *)a1[2];
  uint64_t v28 = -7 - (void)v27;
  while (v27 != (void *)a1[1])
  {
    --v27;
    v28 += 8;
    std::__split_buffer<unsigned long *>::push_front((uint64_t)&v54, v27);
  }
  uint64_t v29 = (char *)*a1;
  long long v30 = v54;
  long long v31 = v55;
  *(void *)&long long v54 = *a1;
  *((void *)&v54 + 1) = v27;
  long long v32 = *((_OWORD *)a1 + 1);
  *(_OWORD *)a1 = v30;
  *((_OWORD *)a1 + 1) = v31;
  long long v55 = v32;
  if (v27 != (void *)v32) {
    *(void *)&long long v55 = v32 + (-(v32 + v28) & 0xFFFFFFFFFFFFFFF8);
  }
  if (v29) {
    operator delete(v29);
  }
}

void sub_21139AF54(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, void *__p, uint64_t a12, uint64_t a13)
{
  operator delete(v13);
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(a1);
}

uint64_t *std::construct_at[abi:ne180100]<std::list<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,std::list<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,std::list<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>*>(uint64_t *a1, void *a2)
{
  *a1 = (uint64_t)a1;
  a1[1] = (uint64_t)a1;
  a1[2] = 0;
  std::list<ZinIrOpLayer *>::splice((uint64_t)a1, a1, a2);
  return a1;
}

void *std::list<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>::list(void *a1, uint64_t a2, uint64_t a3)
{
  *a1 = a1;
  a1[1] = a1;
  a1[2] = 0;
  if (a3)
  {
    uint64_t v5 = 0;
    uint64_t v6 = 8 * a3;
    unint64_t v7 = a1;
    do
    {
      uint64_t v8 = operator new(0x18uLL);
      uint64_t v9 = *(void *)(a2 + 8 * v5);
      v8[1] = a1;
      _OWORD v8[2] = v9;
      *uint64_t v8 = v7;
      v7[1] = v8;
      *a1 = v8;
      a1[2] = ++v5;
      unint64_t v7 = v8;
      v6 -= 8;
    }
    while (v6);
  }
  return a1;
}

void sub_21139B05C(_Unwind_Exception *a1)
{
  std::__list_imp<ZinIrSection *>::clear(v1);
  _Unwind_Resume(a1);
}

void *std::deque<std::list<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>::push_back(void *a1, uint64_t a2)
{
  uint64_t v4 = a1[1];
  uint64_t v5 = a1[2];
  uint64_t v6 = 170 * ((v5 - v4) >> 3) - 1;
  if (v5 == v4) {
    uint64_t v6 = 0;
  }
  if (v6 == a1[5] + a1[4])
  {
    std::deque<std::list<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>::__add_back_capacity(a1);
    uint64_t v4 = a1[1];
    uint64_t v5 = a1[2];
  }
  if (v5 == v4)
  {
    uint64_t v8 = 0;
  }
  else
  {
    unint64_t v7 = a1[5] + a1[4];
    uint64_t v8 = (void *)(*(void *)(v4 + 8 * (v7 / 0xAA)) + 24 * (v7 % 0xAA));
  }
  BOOL result = std::list<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>::list(v8, a2);
  ++a1[5];
  return result;
}

void *std::list<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>::list(void *a1, uint64_t a2)
{
  *a1 = a1;
  a1[1] = a1;
  a1[2] = 0;
  uint64_t v3 = *(void *)(a2 + 8);
  if (v3 != a2)
  {
    uint64_t v5 = 1;
    uint64_t v6 = a1;
    do
    {
      unint64_t v7 = operator new(0x18uLL);
      uint64_t v8 = *(void *)(v3 + 16);
      v7[1] = a1;
      v7[2] = v8;
      void *v7 = v6;
      v6[1] = v7;
      *a1 = v7;
      a1[2] = v5;
      uint64_t v3 = *(void *)(v3 + 8);
      ++v5;
      uint64_t v6 = v7;
    }
    while (v3 != a2);
  }
  return a1;
}

void sub_21139B1A8(_Unwind_Exception *a1)
{
  std::__list_imp<ZinIrSection *>::clear(v1);
  _Unwind_Resume(a1);
}

void *std::__hash_table<std::__hash_value_type<std::shared_ptr<ZinIrHazardNode>,long>,std::__unordered_map_hasher<std::shared_ptr<ZinIrHazardNode>,std::__hash_value_type<std::shared_ptr<ZinIrHazardNode>,long>,std::hash<std::shared_ptr<ZinIrHazardNode>>,std::equal_to<std::shared_ptr<ZinIrHazardNode>>,true>,std::__unordered_map_equal<std::shared_ptr<ZinIrHazardNode>,std::__hash_value_type<std::shared_ptr<ZinIrHazardNode>,long>,std::equal_to<std::shared_ptr<ZinIrHazardNode>>,std::hash<std::shared_ptr<ZinIrHazardNode>>,true>,std::allocator<std::__hash_value_type<std::shared_ptr<ZinIrHazardNode>,long>>>::__emplace_unique_key_args<std::shared_ptr<ZinIrHazardNode>,std::piecewise_construct_t const&,std::tuple<std::shared_ptr<ZinIrHazardNode> const&>,std::tuple<>>(uint64_t a1, void *a2, uint64_t a3, void **a4)
{
  unint64_t v7 = 0x9DDFEA08EB382D69 * ((8 * *a2 + 8) ^ HIDWORD(*a2));
  unint64_t v8 = 0x9DDFEA08EB382D69 * (HIDWORD(*a2) ^ (v7 >> 47) ^ v7);
  unint64_t v9 = 0x9DDFEA08EB382D69 * (v8 ^ (v8 >> 47));
  unint64_t v10 = *(void *)(a1 + 8);
  if (v10)
  {
    uint8x8_t v11 = (uint8x8_t)vcnt_s8((int8x8_t)v10);
    v11.i16[0] = vaddlv_u8(v11);
    if (v11.u32[0] > 1uLL)
    {
      unint64_t v4 = 0x9DDFEA08EB382D69 * (v8 ^ (v8 >> 47));
      if (v9 >= v10) {
        unint64_t v4 = v9 % v10;
      }
    }
    else
    {
      unint64_t v4 = v9 & (v10 - 1);
    }
    uint64_t v12 = *(void ***)(*(void *)a1 + 8 * v4);
    if (v12)
    {
      for (uint64_t i = *v12; i; uint64_t i = (void *)*i)
      {
        unint64_t v14 = i[1];
        if (v14 == v9)
        {
          if (i[2] == *a2) {
            return i;
          }
        }
        else
        {
          if (v11.u32[0] > 1uLL)
          {
            if (v14 >= v10) {
              v14 %= v10;
            }
          }
          else
          {
            v14 &= v10 - 1;
          }
          if (v14 != v4) {
            break;
          }
        }
      }
    }
  }
  uint64_t v15 = (void *)(a1 + 16);
  uint64_t v16 = operator new(0x28uLL);
  uint64_t i = v16;
  void *v16 = 0;
  v16[1] = v9;
  uint64_t v17 = *a4;
  v16[2] = **a4;
  uint64_t v18 = v17[1];
  v16[3] = v18;
  if (v18) {
    atomic_fetch_add_explicit((atomic_ullong *volatile)(v18 + 8), 1uLL, memory_order_relaxed);
  }
  void v16[4] = 0;
  float v19 = (float)(unint64_t)(*(void *)(a1 + 24) + 1);
  float v20 = *(float *)(a1 + 32);
  if (!v10 || (float)(v20 * (float)v10) < v19)
  {
    BOOL v21 = 1;
    if (v10 >= 3) {
      BOOL v21 = (v10 & (v10 - 1)) != 0;
    }
    unint64_t v22 = v21 | (2 * v10);
    unint64_t v23 = vcvtps_u32_f32(v19 / v20);
    if (v22 <= v23) {
      size_t v24 = v23;
    }
    else {
      size_t v24 = v22;
    }
    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::__rehash<true>(a1, v24);
    unint64_t v10 = *(void *)(a1 + 8);
    if ((v10 & (v10 - 1)) != 0)
    {
      if (v9 >= v10) {
        unint64_t v4 = v9 % v10;
      }
      else {
        unint64_t v4 = v9;
      }
    }
    else
    {
      unint64_t v4 = (v10 - 1) & v9;
    }
  }
  uint64_t v25 = *(void *)a1;
  uint64_t v26 = *(void **)(*(void *)a1 + 8 * v4);
  if (v26)
  {
    *uint64_t i = *v26;
LABEL_40:
    *uint64_t v26 = i;
    goto LABEL_41;
  }
  *uint64_t i = *v15;
  void *v15 = i;
  *(void *)(v25 + 8 * v4) = v15;
  if (*i)
  {
    unint64_t v27 = *(void *)(*i + 8);
    if ((v10 & (v10 - 1)) != 0)
    {
      if (v27 >= v10) {
        v27 %= v10;
      }
    }
    else
    {
      v27 &= v10 - 1;
    }
    uint64_t v26 = (void *)(*(void *)a1 + 8 * v27);
    goto LABEL_40;
  }
LABEL_41:
  ++*(void *)(a1 + 24);
  return i;
}

void sub_21139B440(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10)
{
  std::__hash_node_destructor<std::allocator<std::__hash_node<std::__hash_value_type<std::shared_ptr<ZinBondedAne::ZinDeploymentComponent<std::vector<ZinIrOpLayer *>>>,long>,void *>>>::operator()[abi:ne180100](v11, v10);
  _Unwind_Resume(a1);
}

void std::__hash_table<std::__hash_value_type<std::shared_ptr<ZinIrHazardNode>,long>,std::__unordered_map_hasher<std::shared_ptr<ZinIrHazardNode>,std::__hash_value_type<std::shared_ptr<ZinIrHazardNode>,long>,std::hash<std::shared_ptr<ZinIrHazardNode>>,std::equal_to<std::shared_ptr<ZinIrHazardNode>>,true>,std::__unordered_map_equal<std::shared_ptr<ZinIrHazardNode>,std::__hash_value_type<std::shared_ptr<ZinIrHazardNode>,long>,std::equal_to<std::shared_ptr<ZinIrHazardNode>>,std::hash<std::shared_ptr<ZinIrHazardNode>>,true>,std::allocator<std::__hash_value_type<std::shared_ptr<ZinIrHazardNode>,long>>>::__move_assign(uint64_t a1, uint64_t *a2)
{
  std::__hash_table<std::shared_ptr<ZinMirUnit>,std::hash<std::shared_ptr<ZinMirUnit>>,std::equal_to<std::shared_ptr<ZinMirUnit>>,std::allocator<std::shared_ptr<ZinMirUnit>>>::clear(a1);
  uint64_t v4 = *a2;
  *a2 = 0;
  uint64_t v5 = *(void **)a1;
  *(void *)a1 = v4;
  if (v5) {
    operator delete(v5);
  }
  uint64_t v8 = a2[2];
  unint64_t v7 = a2 + 2;
  uint64_t v6 = v8;
  uint64_t v9 = *(v7 - 1);
  *(void *)(a1 + 16) = v8;
  *(void *)(a1 + 8) = v9;
  *(v7 - 1) = 0;
  uint64_t v10 = v7[1];
  *(void *)(a1 + 24) = v10;
  *(_DWORD *)(a1 + 32) = *((_DWORD *)v7 + 4);
  if (v10)
  {
    unint64_t v11 = *(void *)(v6 + 8);
    unint64_t v12 = *(void *)(a1 + 8);
    if ((v12 & (v12 - 1)) != 0)
    {
      if (v11 >= v12) {
        v11 %= v12;
      }
    }
    else
    {
      v11 &= v12 - 1;
    }
    *(void *)(*(void *)a1 + 8 * v11) = a1 + 16;
    void *v7 = 0;
    v7[1] = 0;
  }
}

void *std::__hash_table<std::__hash_value_type<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,int>,std::__unordered_map_hasher<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::__hash_value_type<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,int>,std::hash<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,std::equal_to<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,true>,std::__unordered_map_equal<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::__hash_value_type<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,int>,std::equal_to<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,std::hash<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,int>>>::__emplace_unique_key_args<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::piecewise_construct_t const&,std::tuple<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>&&>,std::tuple<>>(uint64_t a1, unint64_t **a2, uint64_t a3, void **a4)
{
  unint64_t v7 = **a2;
  unint64_t v8 = 0x9DDFEA08EB382D69 * (((8 * v7) + 8) ^ HIDWORD(v7));
  unint64_t v9 = 0x9DDFEA08EB382D69 * (HIDWORD(v7) ^ (v8 >> 47) ^ v8);
  unint64_t v10 = 0x9DDFEA08EB382D69 * (v9 ^ (v9 >> 47));
  unint64_t v11 = *(void *)(a1 + 8);
  if (v11)
  {
    uint8x8_t v12 = (uint8x8_t)vcnt_s8((int8x8_t)v11);
    v12.i16[0] = vaddlv_u8(v12);
    if (v12.u32[0] > 1uLL)
    {
      unint64_t v4 = 0x9DDFEA08EB382D69 * (v9 ^ (v9 >> 47));
      if (v10 >= v11) {
        unint64_t v4 = v10 % v11;
      }
    }
    else
    {
      unint64_t v4 = v10 & (v11 - 1);
    }
    uint64_t v13 = *(void ***)(*(void *)a1 + 8 * v4);
    if (v13)
    {
      unint64_t v14 = *v13;
      if (*v13)
      {
        do
        {
          unint64_t v15 = v14[1];
          if (v15 == v10)
          {
            if (*(void *)v14[2] == v7) {
              return v14;
            }
          }
          else
          {
            if (v12.u32[0] > 1uLL)
            {
              if (v15 >= v11) {
                v15 %= v11;
              }
            }
            else
            {
              v15 &= v11 - 1;
            }
            if (v15 != v4) {
              break;
            }
          }
          unint64_t v14 = (void *)*v14;
        }
        while (v14);
      }
    }
  }
  unint64_t v14 = operator new(0x20uLL);
  *unint64_t v14 = 0;
  v14[1] = v10;
  void v14[2] = **a4;
  *((_DWORD *)v14 + 6) = 0;
  float v16 = (float)(unint64_t)(*(void *)(a1 + 24) + 1);
  float v17 = *(float *)(a1 + 32);
  if (!v11 || (float)(v17 * (float)v11) < v16)
  {
    BOOL v18 = 1;
    if (v11 >= 3) {
      BOOL v18 = (v11 & (v11 - 1)) != 0;
    }
    unint64_t v19 = v18 | (2 * v11);
    unint64_t v20 = vcvtps_u32_f32(v16 / v17);
    if (v19 <= v20) {
      size_t v21 = v20;
    }
    else {
      size_t v21 = v19;
    }
    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::__rehash<true>(a1, v21);
    unint64_t v11 = *(void *)(a1 + 8);
    if ((v11 & (v11 - 1)) != 0)
    {
      if (v10 >= v11) {
        unint64_t v4 = v10 % v11;
      }
      else {
        unint64_t v4 = v10;
      }
    }
    else
    {
      unint64_t v4 = (v11 - 1) & v10;
    }
  }
  uint64_t v22 = *(void *)a1;
  unint64_t v23 = *(void **)(*(void *)a1 + 8 * v4);
  if (v23)
  {
    *unint64_t v14 = *v23;
LABEL_38:
    *unint64_t v23 = v14;
    goto LABEL_39;
  }
  *unint64_t v14 = *(void *)(a1 + 16);
  *(void *)(a1 + 16) = v14;
  *(void *)(v22 + 8 * v4) = a1 + 16;
  if (*v14)
  {
    unint64_t v24 = *(void *)(*v14 + 8);
    if ((v11 & (v11 - 1)) != 0)
    {
      if (v24 >= v11) {
        v24 %= v11;
      }
    }
    else
    {
      v24 &= v11 - 1;
    }
    unint64_t v23 = (void *)(*(void *)a1 + 8 * v24);
    goto LABEL_38;
  }
LABEL_39:
  ++*(void *)(a1 + 24);
  return v14;
}

void sub_21139B750(_Unwind_Exception *a1)
{
  operator delete(v1);
  _Unwind_Resume(a1);
}

uint64_t **std::__hash_table<std::__hash_value_type<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::unordered_set<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>,std::__unordered_map_hasher<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::__hash_value_type<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::unordered_set<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>,std::hash<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,std::equal_to<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,true>,std::__unordered_map_equal<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::__hash_value_type<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::unordered_set<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>,std::equal_to<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,std::hash<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::unordered_set<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>>>::__emplace_unique_key_args<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::piecewise_construct_t const&,std::tuple<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>&&>,std::tuple<>>(uint64_t a1, unint64_t **a2, uint64_t a3, void **a4)
{
  unint64_t v7 = **a2;
  unint64_t v8 = 0x9DDFEA08EB382D69 * (((8 * v7) + 8) ^ HIDWORD(v7));
  unint64_t v9 = 0x9DDFEA08EB382D69 * (HIDWORD(v7) ^ (v8 >> 47) ^ v8);
  unint64_t v10 = 0x9DDFEA08EB382D69 * (v9 ^ (v9 >> 47));
  unint64_t v11 = *(void *)(a1 + 8);
  if (v11)
  {
    uint8x8_t v12 = (uint8x8_t)vcnt_s8((int8x8_t)v11);
    v12.i16[0] = vaddlv_u8(v12);
    if (v12.u32[0] > 1uLL)
    {
      unint64_t v4 = 0x9DDFEA08EB382D69 * (v9 ^ (v9 >> 47));
      if (v10 >= v11) {
        unint64_t v4 = v10 % v11;
      }
    }
    else
    {
      unint64_t v4 = v10 & (v11 - 1);
    }
    uint64_t v13 = *(uint64_t ****)(*(void *)a1 + 8 * v4);
    if (v13)
    {
      for (uint64_t i = *v13; i; uint64_t i = (uint64_t **)*i)
      {
        unint64_t v15 = (unint64_t)i[1];
        if (v15 == v10)
        {
          if (*i[2] == v7) {
            return i;
          }
        }
        else
        {
          if (v12.u32[0] > 1uLL)
          {
            if (v15 >= v11) {
              v15 %= v11;
            }
          }
          else
          {
            v15 &= v11 - 1;
          }
          if (v15 != v4) {
            break;
          }
        }
      }
    }
  }
  uint64_t v16 = a1 + 16;
  float v17 = (char *)operator new(0x40uLL);
  v27[0] = v17;
  v27[1] = a1 + 16;
  *(void *)float v17 = 0;
  *((void *)v17 + 1) = v10;
  *((void *)v17 + 2) = **a4;
  *(_OWORD *)(v17 + 4std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0u;
  *(_OWORD *)(v17 + 24) = 0u;
  *((_DWORD *)v17 + 14) = 1065353216;
  char v28 = 1;
  float v18 = (float)(unint64_t)(*(void *)(a1 + 24) + 1);
  float v19 = *(float *)(a1 + 32);
  if (!v11 || (float)(v19 * (float)v11) < v18)
  {
    BOOL v20 = 1;
    if (v11 >= 3) {
      BOOL v20 = (v11 & (v11 - 1)) != 0;
    }
    unint64_t v21 = v20 | (2 * v11);
    unint64_t v22 = vcvtps_u32_f32(v18 / v19);
    if (v21 <= v22) {
      size_t v23 = v22;
    }
    else {
      size_t v23 = v21;
    }
    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::__rehash<true>(a1, v23);
    unint64_t v11 = *(void *)(a1 + 8);
    if ((v11 & (v11 - 1)) != 0)
    {
      if (v10 >= v11) {
        unint64_t v4 = v10 % v11;
      }
      else {
        unint64_t v4 = v10;
      }
    }
    else
    {
      unint64_t v4 = (v11 - 1) & v10;
    }
  }
  unint64_t v24 = *(void **)(*(void *)a1 + 8 * v4);
  if (v24)
  {
    *(void *)v27[0] = *v24;
    *unint64_t v24 = v27[0];
  }
  else
  {
    *(void *)v27[0] = *(void *)(a1 + 16);
    *(void *)(a1 + 16) = v27[0];
    *(void *)(*(void *)a1 + 8 * v4) = v16;
    if (*(void *)v27[0])
    {
      unint64_t v25 = *(void *)(*(void *)v27[0] + 8);
      if ((v11 & (v11 - 1)) != 0)
      {
        if (v25 >= v11) {
          v25 %= v11;
        }
      }
      else
      {
        v25 &= v11 - 1;
      }
      *(void *)(*(void *)a1 + 8 * v25) = v27[0];
    }
  }
  uint64_t i = (uint64_t **)v27[0];
  v27[0] = 0;
  ++*(void *)(a1 + 24);
  std::unique_ptr<std::__hash_node<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,void *>,std::__hash_node_destructor<std::allocator<std::__hash_node<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,void *>>>>::reset[abi:ne180100]((uint64_t)v27, 0);
  return i;
}

void sub_21139B9FC(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::unique_ptr<std::__hash_node<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,void *>,std::__hash_node_destructor<std::allocator<std::__hash_node<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,void *>>>>::reset[abi:ne180100]((uint64_t)va, 0);
  _Unwind_Resume(a1);
}

uint64_t **std::__hash_table<std::__hash_value_type<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::unordered_set<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>,std::__unordered_map_hasher<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::__hash_value_type<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::unordered_set<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>,std::hash<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,std::equal_to<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,true>,std::__unordered_map_equal<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::__hash_value_type<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::unordered_set<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>,std::equal_to<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,std::hash<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::unordered_set<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>>>::__erase_unique<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>(void *a1, unint64_t **a2)
{
  BOOL result = std::__hash_table<std::__hash_value_type<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::vector<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>,std::__unordered_map_hasher<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::__hash_value_type<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::vector<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>,std::hash<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,std::equal_to<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,true>,std::__unordered_map_equal<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::__hash_value_type<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::vector<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>,std::equal_to<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,std::hash<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>,std::vector<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>>>>::find<std::reference_wrapper<std::shared_ptr<ZinIrHazardNode> const>>(a1, a2);
  if (result)
  {
    std::__hash_table<std::__hash_value_type<ZinIrDimension,unsigned long>,std::__unordered_map_hasher<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,true>,std::__unordered_map_equal<ZinIrDimension,std::__hash_value_type<ZinIrDimension,unsigned long>,std::equal_to<ZinIrDimension>,std::hash<ZinIrDimension>,true>,std::allocator<std::__hash_value_type<ZinIrDimension,unsigned long>>>::remove(a1, result, (uint64_t)v4);
    std::unique_ptr<std::__hash_node<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,void *>,std::__hash_node_destructor<std::allocator<std::__hash_node<std::__hash_value_type<long,std::unordered_map<ZinDependencyOffsetDim,long>>,void *>>>>::reset[abi:ne180100]((uint64_t)v4, 0);
    return (uint64_t **)1;
  }
  return result;
}

uint64_t **std::__tree<std::__value_type<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,std::__map_value_compare<std::shared_ptr<ZinIrHazardNode>,std::__value_type<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,std::less<std::shared_ptr<ZinIrHazardNode>>,true>,std::allocator<std::__value_type<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>>>::__emplace_unique_key_args<std::shared_ptr<ZinIrHazardNode>,std::piecewise_construct_t const&,std::tuple<std::shared_ptr<ZinIrHazardNode> const&>,std::tuple<>>(uint64_t **a1, unint64_t *a2, uint64_t a3, uint64_t **a4)
{
  unint64_t v7 = a1 + 1;
  uint64_t v6 = a1[1];
  unint64_t v8 = a1 + 1;
  unint64_t v9 = a1 + 1;
  if (v6)
  {
    unint64_t v10 = *a2;
    while (1)
    {
      while (1)
      {
        unint64_t v9 = (uint64_t **)v6;
        unint64_t v11 = v6[4];
        if (v10 >= v11) {
          break;
        }
        uint64_t v6 = *v9;
        unint64_t v8 = v9;
        if (!*v9) {
          goto LABEL_9;
        }
      }
      if (v11 >= v10) {
        return v9;
      }
      uint64_t v6 = v9[1];
      if (!v6)
      {
        unint64_t v8 = v9 + 1;
        goto LABEL_9;
      }
    }
  }
  else
  {
LABEL_9:
    uint8x8_t v12 = (uint64_t *)operator new(0x40uLL);
    uint64_t v13 = v12;
    v17[1] = v7;
    unint64_t v14 = *a4;
    v12[4] = **a4;
    uint64_t v15 = v14[1];
    v12[5] = v15;
    if (v15) {
      atomic_fetch_add_explicit((atomic_ullong *volatile)(v15 + 8), 1uLL, memory_order_relaxed);
    }
    v12[6] = 0;
    v12[7] = 0;
    char v18 = 1;
    std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::__insert_node_at(a1, (uint64_t)v9, v8, v12);
    v17[0] = 0;
    std::unique_ptr<std::__tree_node<std::__value_type<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,ZinIrHazardGraph::EdgeType>,void *>,std::__tree_node_destructor<std::allocator<std::__tree_node<std::__value_type<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,ZinIrHazardGraph::EdgeType>,void *>>>>::reset[abi:ne180100]((uint64_t)v17, 0);
  }
  return (uint64_t **)v13;
}

void ZinMirL2HazardAnalysis::CreateHazardNodes(uint8_t *buf, uint64_t a2, void *a3)
{
  uint64_t v3 = (void *)(*(void *)a2 + 24);
  if (*(char *)(*(void *)a2 + 47) < 0) {
    uint64_t v3 = (void *)*v3;
  }
  *(_DWORD *)long long buf = 136315138;
  *a3 = v3;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "Error: Engine layer %s has invalid L2 source", buf, 0xCu);
}

void ZinMirL2HazardAnalysis::SetL2HazardBits(uint8_t *buf, unsigned char *a2)
{
  *long long buf = 0;
  *a2 = 0;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "Error: (RAW) Dst read node cannot have Rslt operand type", buf, 2u);
}

void ZinMirL2HazardAnalysis::TryDependencyBitSet()
{
  *(_WORD *)uint64_t v0 = 0;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "Error: Trying to set dependency bit for invalid L2 source", v0, 2u);
}

long long *ZinIrHalM9::GetParams(ZinIrHalM9 *this)
{
  uint64_t v16 = *MEMORY[0x263EF8340];
  {
    ZinIrHalM9::GetParams(void)const::ZinIrHalM9Parameters = xmmword_211F07EF0;
    dword_267780650 = 8;
    unk_267780658 = xmmword_211EDE750;
    unk_267780668 = xmmword_211ED25D0;
    unk_267780678 = xmmword_211ED25E0;
    unk_267780688 = xmmword_211ED25F0;
    unk_267780698 = xmmword_211ED2600;
    unk_2677806A8 = xmmword_211ED25E0;
    unk_2677806B8 = vdupq_n_s64(1uLL);
    unk_2677806C8 = xmmword_211EDE760;
    unk_2677806D8 = xmmword_211EDE770;
    unk_2677806E8 = unk_2677806B8;
    unk_2677806F8 = vdupq_n_s64(4uLL);
    qword_267780708 = 1;
    xmmword_267780710 = xmmword_211F07F10;
    unk_267780720 = unk_211F07F20;
    xmmword_267780730 = xmmword_211F07F10;
    unk_267780740 = unk_211F07F20;
    qword_267780760 = 4;
    xmmword_267780750 = xmmword_211F07F30;
    xmmword_267780768 = xmmword_211EDE780;
    xmmword_267780778 = xmmword_211ED2660;
    xmmword_267780788 = xmmword_211ED2660;
    xmmword_267780798 = unk_2677806B8;
    xmmword_2677807A8 = xmmword_211ED2670;
    xmmword_2677807B8 = xmmword_211ED2680;
    xmmword_2677807C8 = xmmword_211EDE790;
    xmmword_2677807D8 = xmmword_211F07F00;
    xmmword_2677807E8 = xmmword_211ED26B0;
    xmmword_2677807F8 = xmmword_211ED26C0;
    xmmword_267780808 = xmmword_211EDE7A0;
    xmmword_267780818 = xmmword_211EDE7B0;
    xmmword_267780828 = xmmword_211EDE7C0;
    xmmword_267780838 = xmmword_211ED2700;
    xmmword_267780848 = xmmword_211ED4660;
    xmmword_267780858 = xmmword_211ED4670;
    xmmword_267780868 = xmmword_211EDE7D0;
    xmmword_267780878 = (__int128)vdupq_n_s64(0x20uLL);
    xmmword_267780888 = xmmword_211ED2740;
    qword_2677808A8 = 0;
    xmmword_267780898 = 0u;
    xmmword_2677808B0 = xmmword_211ED2750;
    word_2677808C0 = 257;
    xmmword_2677808C8 = xmmword_211ED2760;
    xmmword_2677808D8 = xmmword_211ED2770;
    xmmword_2677808E8 = xmmword_211ED2780;
    qword_2677808F8 = 0x10000;
    byte_267780900 = 8;
    xmmword_267780908 = xmmword_211ED2790;
    dword_267780918 = 520097776;
    qword_26778091C = 0xFFFFFFEB0000000BLL;
    xmmword_267780928 = xmmword_211EDE7E0;
    xmmword_267780938 = xmmword_211EDE7F0;
    xmmword_267780948 = xmmword_211ED27C0;
    int64x2_t v15 = vdupq_n_s64(8uLL);
    std::vector<std::pair<unsigned long,unsigned long>>::vector[abi:ne180100](&qword_267780958, (uint64_t)&v15, 1uLL);
    xmmword_267780970 = xmmword_211ED27D0;
    unk_267780980 = xmmword_211ED27E0;
    xmmword_267780990 = (__int128)vdupq_n_s64(0x20uLL);
    unk_2677809A0 = xmmword_211ED2610;
    xmmword_2677809B0 = (__int128)vdupq_n_s64(8uLL);
    unk_2677809C0 = xmmword_211ED27F0;
    qword_2677809D0 = 1;
    unk_2677809D8 = 0u;
    unk_2677809E8 = 0u;
    unk_2677809F8 = 0u;
    unk_267780A08 = 0u;
    unk_267780A18 = 0u;
    unk_267780A28 = 0u;
    unk_267780A38 = 0u;
    unk_267780A48 = xmmword_211ED4670;
    unk_267780A58 = xmmword_211ED2790;
    xmmword_267780A68 = 0u;
    xmmword_267780A78 = 0u;
    qword_267780A88 = 12;
    word_267780A90 = 257;
    dword_267780A92 = 0;
    byte_267780A96 = 0;
    dword_267780A97 = 1;
    byte_267780A9B = 1;
    xmmword_267780A9C = 0u;
    dword_267780AAC = 0;
    byte_267780AB0 = 1;
    dword_267780AB1 = 0;
    byte_267780AB5 = 1;
    word_267780ABA = 0;
    dword_267780AB6 = 0;
    dword_267780ABC = 257;
    xmmword_267780AC0 = xmmword_211ED2870;
    unk_267780AD0 = xmmword_211ED2880;
    qword_267780AE0 = 40;
    *(void *)((char *)&xmmword_267780AE8 + 13) = 0;
    xmmword_267780AE8 = 0u;
    dword_267780AFD = 1;
    xmmword_267780B08 = 0u;
    dword_267780B18 = 0;
    word_267780B1C = 1;
    byte_267780B1E = 1;
    qword_267780B1F = 0;
    byte_267780B27 = 0;
    dword_267780B28 = 65793;
    word_267780B2C = 0;
    byte_267780B2E = 1;
    dword_267780B2F = 0;
    byte_267780B33 = 1;
    dword_267780B34 = 0;
    word_267780B38 = 0;
    qword_267780B40 = 128;
    unk_267780B48 = -1;
    qword_267780B50 = -1;
    word_267780B58 = 0;
    dword_267780B5C = 0;
    word_267780B60 = 257;
    *(uint64_t *)((char *)&qword_267780B62 + 7) = 0;
    qword_267780B62 = 0;
    dword_267780B71 = 1542;
    byte_267780B75 = 1;
    dword_267780B76 = 0;
    std::string::basic_string[abi:ne180100]<0>(&qword_267780B80, "None");
    qword_267780B98 = 0;
    dword_267780BA4 = 0;
    unk_267780BA8 = 0;
    dword_267780BA0 = 1071225242;
    unk_267780BB0 = xmmword_211ED2890;
    unk_267780BC0 = vdupq_n_s64(0x40uLL);
    unk_267780BD0 = xmmword_211ED27D0;
    qword_267780BE0 = 8;
    byte_267780BE8 = 0;
    unk_267780BEC = 1048576000;
    byte_267780BF4 = 0;
    uint64_t v13 = 0x200000001;
    int v14 = 4;
    std::vector<ZinIrPaddingMode>::vector[abi:ne180100](&qword_267780BF8, &v13, 3uLL);
    long long v11 = xmmword_211F07F48;
    v12[0] = unk_211F07F58;
    *(_OWORD *)((char *)v12 + 12) = unk_211F07F64;
    std::vector<ZinIrPoolingMode>::vector[abi:ne180100](&qword_267780C10, &v11, 0xBuLL);
    int v10 = 7;
    v9[0] = xmmword_211F07F74;
    v9[1] = unk_211F07F84;
    void v9[2] = xmmword_211F07F94;
    std::vector<ZinIrNeuronType>::vector[abi:ne180100](&qword_267780C28, v9, 0xDuLL);
    v7[0] = xmmword_211F07FA8;
    v7[1] = unk_211F07FB8;
    v8[0] = xmmword_211F07FC8;
    *(_OWORD *)((char *)v8 + 12) = *(long long *)((char *)&xmmword_211F07FC8 + 12);
    std::vector<ZinIrNonLinearMode>::vector[abi:ne180100](&qword_267780C40, v7, 0xFuLL);
    xmmword_267780C88 = 0u;
    unk_267780C98 = 0u;
    unk_267780CB0 = xmmword_211F07FE8;
    qword_267780C68 = 0;
    qword_267780C60 = 0;
    qword_267780C58 = (uint64_t)&qword_267780C60;
    word_267780C70 = 0;
    byte_267780C72 = 1;
    *(_DWORD *)algn_267780C73 = 0;
    qword_267780C78 = 0;
    dword_267780C80 = 0;
    word_267780CA8 = 1;
    unk_267780CC0 = unk_211F07FF8;
    qword_267780CD0 = 8;
    xmmword_267780CD8 = xmmword_211EDE800;
    uint64_t v6 = 0x41B7D78400000000;
    std::vector<double>::vector[abi:ne180100](&qword_267780CE8, &v6, 1uLL);
    uint64_t v5 = 0x41B1E1A300000000;
    std::vector<double>::vector[abi:ne180100](&qword_267780D00, &v5, 1uLL);
    uint64_t v4 = 0x41D5DC2930000000;
    std::vector<double>::vector[abi:ne180100](&qword_267780D18, &v4, 1uLL);
    int64x2_t v3 = vdupq_n_s64(0x41B7D78400000000uLL);
    std::map<double,double>::map[abi:ne180100]((uint64_t)&unk_267780D30, (double *)v3.i64, 1);
    xmmword_267780D48 = xmmword_211ED28E0;
    v2[0] = xmmword_211F08010;
    *(_OWORD *)((char *)v2 + 12) = *(long long *)((char *)&xmmword_211F08010 + 12);
    std::vector<ZinKernelFormat>::vector[abi:ne180100](qword_267780D58, v2, 7uLL);
    xmmword_267780D70 = xmmword_211ED2790;
    xmmword_267780D80 = xmmword_211ED28F0;
    qword_267780D90 = 64;
    word_267780D98 = 256;
    dword_267780E50 = 0;
    word_267780E54 = 0;
    qword_267780E70 = 0;
    byte_267780E78 = 0;
    qword_267780E80 = 0;
    byte_267780E88 = 0;
    unk_267780D9A = 0;
    unk_267780DA2 = 0;
    xmmword_267780DA8 = 0u;
    unk_267780DB8 = 0u;
    xmmword_267780DC8 = 0u;
    unk_267780DD8 = 0u;
    xmmword_267780DE8 = 0u;
    unk_267780DF8 = 0u;
    xmmword_267780E08 = 0u;
    unk_267780E18 = 0u;
    xmmword_267780E28 = 0u;
    unk_267780E38 = 0u;
    unk_267780E46 = 0;
    byte_267780E68 = 0;
    xmmword_267780E58 = 0u;
    word_267780E89 = 257;
    qword_267780E90 = 0x40000000;
    __cxa_atexit((void (*)(void *))ZinIrHalParameters::~ZinIrHalParameters, &ZinIrHalM9::GetParams(void)const::ZinIrHalM9Parameters, &dword_210C72000);
  }
  return &ZinIrHalM9::GetParams(void)const::ZinIrHalM9Parameters;
}

void sub_21139C434(_Unwind_Exception *a1)
{
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy(v2, *(void **)(v2 + 8));
  if (qword_267780D18)
  {
    qword_267780D20 = qword_267780D18;
    operator delete((void *)qword_267780D18);
  }
  if (qword_267780D00)
  {
    qword_267780D08 = qword_267780D00;
    operator delete((void *)qword_267780D00);
  }
  if (qword_267780CE8)
  {
    qword_267780CF0 = qword_267780CE8;
    operator delete((void *)qword_267780CE8);
  }
  std::__tree<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::__map_value_compare<ZinIr4CCFormat,std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>,std::less<ZinIr4CCFormat>,true>,std::allocator<std::__value_type<ZinIr4CCFormat,std::vector<ZinMirInterchangeInfo>>>>::destroy(v1 + 24, *(void **)(v1 + 32));
  uint64_t v4 = *(void **)v1;
  if (*(void *)v1)
  {
    qword_267780C48 = *(void *)v1;
    operator delete(v4);
  }
  if (qword_267780C28)
  {
    qword_267780C30 = qword_267780C28;
    operator delete((void *)qword_267780C28);
  }
  if (qword_267780C10)
  {
    qword_267780C18 = qword_267780C10;
    operator delete((void *)qword_267780C10);
  }
  if (qword_267780BF8)
  {
    qword_267780C00 = qword_267780BF8;
    operator delete((void *)qword_267780BF8);
  }
  if (byte_267780B97 < 0) {
    operator delete((void *)qword_267780B80);
  }
  if (qword_267780958)
  {
    qword_267780960 = qword_267780958;
    operator delete((void *)qword_267780958);
  }
  _Unwind_Resume(a1);
}

void sub_21139C578()
{
}

void sub_21139C580()
{
}

uint64_t ZinIrRegSpill::ZinIrRegSpill(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, char a7)
{
  *(void *)a1 = a2;
  *(void *)(a1 + 8) = a3;
  *(void *)(a1 + 16) = a5;
  std::set<ZinIrTensor *,ZinIrIdComparator<ZinIrTensor *>,std::allocator<ZinIrTensor *>>::set[abi:ne180100]((uint64_t *)(a1 + 24), a4);
  *(_OWORD *)(a1 + 48) = 0u;
  *(_OWORD *)(a1 + 64) = 0u;
  *(_DWORD *)(a1 + 8std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 1065353216;
  *(unsigned char *)(a1 + 88) = a7;
  *(void *)(a1 + 96) = a6;
  return a1;
}

BOOL ZinIrRegSpill::IsStressTestMode(ZinIrRegSpill *this, const ZinIrCompilerParameters *a2)
{
  uint64_t v2 = *((unsigned __int8 *)this + 239);
  int v3 = (char)v2;
  if ((v2 & 0x80u) != 0) {
    uint64_t v2 = *((void *)this + 28);
  }
  if (v2 != 15) {
    return 0;
  }
  uint64_t v6 = (uint64_t *)*((void *)this + 27);
  uint64_t v4 = (char *)this + 216;
  uint64_t v5 = v6;
  if (v3 >= 0) {
    unint64_t v7 = (uint64_t *)v4;
  }
  else {
    unint64_t v7 = v5;
  }
  uint64_t v8 = *v7;
  uint64_t v9 = *(uint64_t *)((char *)v7 + 7);
  return v8 == 0x6572646568636163 && v9 == 0x6574697277646165;
}

uint64_t ZinIrRegSpill::Run(ZinIrLocalRegAlloc **this)
{
  ZinIrRegSpill::InitSpillCandidates((ZinIrRegSpill *)this);
  uint64_t v2 = ZinIrRegSpill::ClearCandidateL2Symbols((ZinIrRegSpill *)this);
  if (v2)
  {
    uint64_t v3 = v2;
    BOOL v4 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (v4) {
      ZinIrRegSpill::Run(v4, v5, v6, v7, v8, v9, v10, v11);
    }
    return v3;
  }
  uint64_t v12 = ZinIrRegSpill::DoSpillOnCandidates((ZinIrRegSpill *)this);
  if (v12)
  {
    uint64_t v3 = v12;
    BOOL v13 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (v13) {
      ZinIrRegSpill::Run(v13, v14, v15, v16, v17, v18, v19, v20);
    }
    return v3;
  }
  uint64_t v21 = ZinIrLocalRegAlloc::LowerKernelAfterChannelAssignmentParamUpdate(this[2], 0);
  if (v21)
  {
    uint64_t v3 = v21;
    BOOL v22 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (v22) {
      ZinIrRegSpill::Run(v22, v23, v24, v25, v26, v27, v28, v29);
    }
    return v3;
  }
  uint64_t v30 = ZinIrRegSpill::VerifyL2Symbols((ZinIrRegSpill *)this);
  if (v30)
  {
    uint64_t v3 = v30;
    BOOL v31 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (v31) {
      ZinIrRegSpill::Run(v31, v32, v33, v34, v35, v36, v37, v38);
    }
    return v3;
  }

  return ZinIrRegSpill::VerifyChainSymbols((ZinIrRegSpill *)this);
}

uint64_t ZinIrRegSpill::InitSpillCandidates(ZinIrRegSpill *this)
{
  if (*((unsigned char *)this + 88))
  {
    uint64_t v1 = (void *)((char *)this + 32);
    uint64_t v2 = (uint64_t **)((char *)this + 24);
    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)this + 24, *((void **)this + 4));
    *(v1 - 1) = v1;
    *uint64_t v1 = 0;
    v1[1] = 0;
    uint64_t v3 = *(v1 - 3);
    BOOL v4 = *(void **)v3;
    uint64_t v5 = *(void **)(v3 + 8);
    while (1)
    {
      if (v4 == v5) {
        return 0;
      }
      uint64_t v6 = (ZinIrTensor *)(*(uint64_t (**)(void, void, void))(*(void *)*v4 + 32))(*v4, 0, 0);
      if (!ZinIrTensor::HasParent(v6)) {
        break;
      }
LABEL_21:
      ++v4;
    }
    uint64_t v23 = v6;
    ZinIrTensor::GetSymbols(v6, &v21);
    uint64_t v7 = v21;
    if (v21 == v22)
    {
      BOOL v10 = 1;
      if (!v21)
      {
LABEL_19:
        if (v10) {
          std::__tree<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const*>(v2, (uint64_t *)&v23, (uint64_t *)&v23);
        }
        goto LABEL_21;
      }
LABEL_18:
      BOOL v22 = v7;
      operator delete(v7);
      goto LABEL_19;
    }
    ZinIrTensor::GetSymbols(v23, v20);
    uint64_t v8 = v20[0];
    if (*(void *)v20[0])
    {
      ZinIrTensor::GetSymbols(v23, __p);
      BOOL v10 = ZinIrSymbol::GetMemType(*(ZinIrSymbol **)__p[0]) == 2
         && ZinIrRegSpill::IsQualifiedForSpill(v6, v9);
      if (__p[0])
      {
        __p[1] = __p[0];
        operator delete(__p[0]);
      }
      uint64_t v8 = v20[0];
      if (!v20[0])
      {
LABEL_17:
        uint64_t v7 = v21;
        if (!v21) {
          goto LABEL_19;
        }
        goto LABEL_18;
      }
    }
    else
    {
      BOOL v10 = 0;
    }
    v20[1] = v8;
    operator delete(v8);
    goto LABEL_17;
  }
  uint64_t v11 = (uint64_t **)*((void *)this + 1);
  uint64_t v12 = *v11;
  BOOL v13 = v11[1];
  if (*v11 != v13)
  {
    uint64_t v14 = (uint64_t **)((char *)this + 24);
    do
    {
      uint64_t v15 = *v12;
      v20[0] = 0;
      v20[0] = (ZinIrTensor *)(*(uint64_t (**)(uint64_t, void, void))(*(void *)v15 + 32))(v15, 0, 0);
      if (!ZinIrTensor::HasParent(v20[0]))
      {
        ZinIrTensor::GetSymbols((void *)v20[0], &v21);
        uint64_t v16 = v21;
        uint64_t v17 = v22;
        if (v21)
        {
          BOOL v22 = v21;
          operator delete(v21);
        }
        if (v16 == v17) {
          std::__tree<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const*>(v14, (uint64_t *)v20, (uint64_t *)v20);
        }
      }
      ++v12;
    }
    while (v12 != v13);
  }
  return 0;
}

void sub_21139C954(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, void *a9, uint64_t a10, uint64_t a11, void *__p, uint64_t a13, uint64_t a14, void *a15, uint64_t a16)
{
  if (__p) {
    operator delete(__p);
  }
  if (a15) {
    operator delete(a15);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinIrRegSpill::ClearCandidateL2Symbols(ZinIrRegSpill *this)
{
  uint64_t v2 = (char *)this + 24;
  std::set<ZinIrTensor *,ZinIrIdComparator<ZinIrTensor *>,std::allocator<ZinIrTensor *>>::set[abi:ne180100]((uint64_t *)&v20, (uint64_t)this + 24);
  uint64_t v3 = v20;
  if (v20 == v21)
  {
LABEL_13:
    uint64_t v7 = 0;
  }
  else
  {
    while (1)
    {
      uint64_t RootTensor = ZinIrTensor::GetRootTensor((ZinIrTensor *)v3[4]);
      uint64_t v5 = *((void *)RootTensor + 13);
      if (v5)
      {
        uint64_t v6 = *(ZinIrSymbol ***)(v5 + 40);
        if (v6 != *(ZinIrSymbol ***)(v5 + 48))
        {
          if (*v6)
          {
            if (ZinIrSymbol::GetMemType(*v6) == 2)
            {
              uint64_t v7 = ZinIrRegSpill::SpillResidentTensor((uint64_t)this, (uint64_t)RootTensor, (uint64_t)v2);
              if (v7) {
                break;
              }
            }
          }
        }
      }
      uint64_t v8 = v3[1];
      if (v8)
      {
        do
        {
          uint64_t v9 = (void **)v8;
          uint64_t v8 = (void *)*v8;
        }
        while (v8);
      }
      else
      {
        do
        {
          uint64_t v9 = (void **)v3[2];
          BOOL v10 = *v9 == v3;
          uint64_t v3 = v9;
        }
        while (!v10);
      }
      uint64_t v3 = v9;
      if (v9 == v21) {
        goto LABEL_13;
      }
    }
    BOOL v12 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (v12) {
      ZinIrRegSpill::ClearCandidateL2Symbols(v12, v13, v14, v15, v16, v17, v18, v19);
    }
  }
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v20, v21[0]);
  return v7;
}

void sub_21139CAB0(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, char a10, void *a11)
{
}

uint64_t ZinIrRegSpill::DoSpillOnCandidates(ZinIrRegSpill *this)
{
  uint64_t v2 = (uint64_t **)((char *)this + 24);
  std::set<ZinIrTensor *,ZinIrIdComparator<ZinIrTensor *>,std::allocator<ZinIrTensor *>>::set[abi:ne180100]((uint64_t *)&v31, (uint64_t)this + 24);
  uint64_t v3 = v31;
  if (v31 == v32) {
    goto LABEL_13;
  }
  do
  {
    BOOL v4 = (ZinIrTensor *)v3[4];
    uint64_t RootTensor = 0;
    uint64_t v30 = v4;
    uint64_t RootTensor = ZinIrTensor::GetRootTensor(v4);
    if (!ZinIrRegSpill::IsQualifiedForSpill(RootTensor, v5))
    {
      BOOL v20 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v20) {
        ZinIrRegSpill::DoSpillOnCandidates(v20, v21, v22, v23, v24, v25, v26, v27);
      }
      uint64_t DMABuffers = 3;
      goto LABEL_20;
    }
    if (v30 != RootTensor)
    {
      std::__tree<std::__value_type<ZinIrOpLayer *,float>,std::__map_value_compare<ZinIrOpLayer *,std::__value_type<ZinIrOpLayer *,float>,ZinIrIdComparator<ZinIrOpLayer *>,true>,std::allocator<std::__value_type<ZinIrOpLayer *,float>>>::__erase_unique<ZinIrOpLayer *>(v2, (uint64_t *)&v30);
      std::__tree<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const*>(v2, (uint64_t *)&RootTensor, (uint64_t *)&RootTensor);
    }
    uint64_t v6 = v3[1];
    if (v6)
    {
      do
      {
        uint64_t v7 = (void **)v6;
        uint64_t v6 = (void *)*v6;
      }
      while (v6);
    }
    else
    {
      do
      {
        uint64_t v7 = (void **)v3[2];
        BOOL v8 = *v7 == v3;
        uint64_t v3 = v7;
      }
      while (!v8);
    }
    uint64_t v3 = v7;
  }
  while (v7 != v32);
  do
  {
LABEL_13:
    if (!*((void *)this + 5))
    {
      uint64_t DMABuffers = 0;
      goto LABEL_20;
    }
    uint64_t v9 = (uint64_t *)*((void *)this + 3);
    BOOL v10 = (ZinIrTensor *)v9[4];
    std::__tree<std::__value_type<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,ZinIrHazardGraph::EdgeType>,std::__map_value_compare<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,std::__value_type<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,ZinIrHazardGraph::EdgeType>,HazardEdgeCompare,true>,std::allocator<std::__value_type<std::pair<std::shared_ptr<ZinIrHazardNode>,std::shared_ptr<ZinIrHazardNode>>,ZinIrHazardGraph::EdgeType>>>::__remove_node_pointer(v2, v9);
    operator delete(v9);
    uint64_t DMABuffers = ZinIrRegSpill::SpillAndAllocateDMABuffers(this, v10);
  }
  while (!DMABuffers);
  BOOL v12 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
  if (v12) {
    ZinIrRegSpill::DoSpillOnCandidates(v12, v13, v14, v15, v16, v17, v18, v19);
  }
LABEL_20:
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v31, v32[0]);
  return DMABuffers;
}

void sub_21139CC28(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, char a12, void *a13)
{
}

uint64_t ZinIrRegSpill::VerifyL2Symbols(ZinIrRegSpill *this)
{
  v4[4] = *MEMORY[0x263EF8340];
  uint64_t v1 = *(void **)this;
  v4[0] = &unk_26C332DE8;
  v4[3] = v4;
  uint64_t v2 = ZinIrControlFlowGraph::TraverseForward(v1, (uint64_t)v4, 1);
  std::__function::__value_func<ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::~__value_func[abi:ne180100](v4);
  return v2;
}

void sub_21139CCD8(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::__function::__value_func<ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::~__value_func[abi:ne180100]((uint64_t *)va);
  _Unwind_Resume(a1);
}

uint64_t ZinIrRegSpill::VerifyChainSymbols(ZinIrRegSpill *this)
{
  v4[4] = *MEMORY[0x263EF8340];
  uint64_t v1 = *(void **)this;
  v4[0] = &unk_26C332E40;
  v4[3] = v4;
  uint64_t v2 = ZinIrControlFlowGraph::TraverseForward(v1, (uint64_t)v4, 1);
  std::__function::__value_func<ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::~__value_func[abi:ne180100](v4);
  return v2;
}

void sub_21139CD80(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::__function::__value_func<ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::~__value_func[abi:ne180100]((uint64_t *)va);
  _Unwind_Resume(a1);
}

BOOL ZinIrRegSpill::IsQualifiedForSpill(ZinIrRegSpill *this, ZinIrTensor *a2)
{
  uint64_t v3 = (*(uint64_t (**)(void, ZinIrRegSpill *))(**((void **)this + 12) + 56))(*((void *)this + 12), this);
  if (v4) {
    BOOL v5 = v3 == 0;
  }
  else {
    BOOL v5 = 0;
  }
  if (!v5) {
    return 0;
  }
  ZinIrTensor::GetTensorFamily(this, (uint64_t)&__p);
  uint64_t v7 = (char *)__p;
  BOOL v8 = v17;
  if (__p == v17)
  {
    BOOL v6 = 1;
    if (!__p) {
      return v6;
    }
    goto LABEL_20;
  }
  while (2)
  {
    uint64_t v9 = *(void **)(*(void *)v7 + 96);
    int v10 = *(_DWORD *)(v9[8] + 8);
    BOOL v6 = v10 != 33;
    if (v10 != 33)
    {
      uint64_t v11 = (ZinIrOpLayer **)v9[14];
      BOOL v12 = (ZinIrOpLayer **)v9[15];
      while (v11 != v12)
      {
        uint64_t v13 = *v11;
        if (ZinIrOpLayer::IsNELayer(*v11)
          && *((void *)v13 + 12) - *((void *)v13 + 11) == 16
          && (uint64_t InputTensor = ZinIrOpLayer::GetInputTensor(v13, 1uLL),
              !(*(unsigned int (**)(ZinIrOpLayer *, uint64_t))(*(void *)v13 + 200))(v13, InputTensor))
          || *(_DWORD *)(*((void *)v13 + 8) + 8) == 81 && *((void *)v13 + 57))
        {
          BOOL v6 = 0;
          goto LABEL_19;
        }
        ++v11;
      }
      v7 += 8;
      if (v7 != v8) {
        continue;
      }
    }
    break;
  }
LABEL_19:
  uint64_t v7 = (char *)__p;
  if (__p)
  {
LABEL_20:
    uint64_t v17 = v7;
    operator delete(v7);
  }
  return v6;
}

void sub_21139CF04(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

void ZinIrRegSpill::InsertL2Copy(ZinIrRegSpill *this, ZinPELayer *a2, unint64_t a3)
{
  uint64_t v30 = *MEMORY[0x263EF8340];
  uint64_t v27 = a2;
  char v4 = *(void **)(*((void *)a2 + 11) + 8 * a3);
  uint64_t InputTensor = ZinIrOpLayer::GetInputTensor(a2, a3);
  (*(void (**)(void *, uint64_t))(*v4 + 56))(v4, InputTensor);
  if (*((char *)a2 + 47) >= 0) {
    size_t v6 = *((unsigned __int8 *)a2 + 47);
  }
  else {
    size_t v6 = *((void *)a2 + 4);
  }
  uint64_t v7 = &v25;
  std::string::basic_string[abi:ne180100]((uint64_t)&v25, v6 + 1);
  if ((v25.__r_.__value_.__r.__words[2] & 0x8000000000000000) != 0) {
    uint64_t v7 = (std::string *)v25.__r_.__value_.__r.__words[0];
  }
  if (v6)
  {
    if (*((char *)a2 + 47) >= 0) {
      BOOL v8 = (char *)a2 + 24;
    }
    else {
      BOOL v8 = (char *)*((void *)a2 + 3);
    }
    memmove(v7, v8, v6);
  }
  *(_WORD *)((char *)&v7->__r_.__value_.__l.__data_ + v6) = 95;
  uint64_t v9 = (std::string *)std::string::basic_string[abi:ne180100]<0>(&v28, "spill_l2_copy");
  int v10 = std::string::append(v9, "_xfm", 4uLL);
  long long v11 = *(_OWORD *)&v10->__r_.__value_.__l.__data_;
  int64_t v24 = v10->__r_.__value_.__r.__words[2];
  long long v23 = v11;
  v10->__r_.__value_.__l.__size_ = 0;
  v10->__r_.__value_.__r.__words[2] = 0;
  v10->__r_.__value_.__r.__words[0] = 0;
  if (v24 >= 0) {
    BOOL v12 = (const std::string::value_type *)&v23;
  }
  else {
    BOOL v12 = (const std::string::value_type *)v23;
  }
  if (v24 >= 0) {
    std::string::size_type v13 = HIBYTE(v24);
  }
  else {
    std::string::size_type v13 = *((void *)&v23 + 1);
  }
  uint64_t v14 = std::string::append(&v25, v12, v13);
  long long v15 = *(_OWORD *)&v14->__r_.__value_.__l.__data_;
  std::string::size_type v20 = v14->__r_.__value_.__r.__words[2];
  *(_OWORD *)std::string __p = v15;
  v14->__r_.__value_.__l.__size_ = 0;
  v14->__r_.__value_.__r.__words[2] = 0;
  v14->__r_.__value_.__r.__words[0] = 0;
  __n128 v16 = ZinObjectNameFactory::ZinObjectNameFactory(v26, __p);
  if (SHIBYTE(v20) < 0) {
    operator delete(__p[0]);
  }
  if (SHIBYTE(v24) < 0) {
    operator delete((void *)v23);
  }
  if (v29 < 0) {
    operator delete(v28);
  }
  if (SHIBYTE(v25.__r_.__value_.__r.__words[2]) < 0) {
    operator delete(v25.__r_.__value_.__l.__data_);
  }
  uint64_t v17 = v4[2];
  uint64_t v18 = *(unsigned int *)((*(uint64_t (**)(void *, void, void, __n128))(*v4 + 32))(v4, 0, 0, v16)
                        + 88);
  uint64_t v22 = 0;
  v21[0] = 0;
  v21[168] = 0;
  ZinBuilder::CreateNEBypass(v17, (uint64_t)v26, (uint64_t)v4, v18, &v22, 0, (uint64_t)v21, 1.0);
}

void sub_21139D4A0(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, void *a13, void *__p, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33,uint64_t a34,uint64_t a35,uint64_t a36,uint64_t a37,uint64_t a38,uint64_t a39,char a40,uint64_t a41,uint64_t a42,int a43,__int16 a44,char a45,char a46)
{
  std::__function::__value_func<ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::~__value_func[abi:ne180100]((void *)(v47 - 160));
  std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)(v47 - 128), 0);
  if (__p) {
    operator delete(__p);
  }
  *(void *)(v46 + 56) = &unk_26C34DA98;
  if (*(char *)(v47 - 177) < 0) {
    operator delete(*(void **)(v46 + 64));
  }
  _Unwind_Resume(a1);
}

BOOL ZinIrRegSpill::HasMismatchedDualInput(ZinIrRegSpill *this, ZinIrOpLayer *a2)
{
  if (!ZinIrOpLayer::IsPELayer(this) || *((void *)this + 12) - *((void *)this + 11) != 16) {
    return 0;
  }
  uint64_t InputTensor = ZinIrOpLayer::GetInputTensor(this, 0);
  uint64_t v4 = 1;
  uint64_t v5 = ZinIrOpLayer::GetInputTensor(this, 1uLL);
  if (ZinTensorDimensionsEqual((void *)(InputTensor + 48), (void *)(v5 + 48)))
  {
    if (*(_DWORD *)(InputTensor + 88) == *(_DWORD *)(v5 + 88))
    {
      uint64_t Interleave = ZinIrTensor::GetInterleave((ZinIrTensor *)InputTensor);
      char v8 = v7;
      uint64_t v9 = ZinIrTensor::GetInterleave((ZinIrTensor *)v5);
      if (v10) {
        BOOL v11 = Interleave != v9;
      }
      else {
        BOOL v11 = v8 != 0;
      }
      if (v8) {
        return v11;
      }
      else {
        return v10 != 0;
      }
    }
    else
    {
      return 1;
    }
  }
  return v4;
}

uint64_t ZinIrRegSpill::SpillAndAllocateDMABuffers(ZinIrRegSpill *this, ZinIrTensor *a2)
{
  uint64_t v42 = a2;
  if (ZinIrTensor::HasParent(a2)) {
    ZinAssertImpl("Spiller: non-root tensor.");
  }
  ZinIrTensor::GetSymbols(a2, &__p);
  uint64_t v4 = __p;
  uint64_t v5 = v41;
  if (__p)
  {
    uint64_t v41 = (char *)__p;
    operator delete(__p);
  }
  if (v4 != v5) {
    ZinAssertImpl("Spiller: symbol not freed.");
  }
  Section = (ZinIrSection *)ZinIrLocalRegAlloc::GetSection(*((void *)this + 2), 0, 4);
  if (!ZinIrLocalRegAlloc::AllocateNonResidentTensor(*((ZinIrLocalRegAlloc **)this + 2), v42, Section, 1)) {
    return 3;
  }
  ZinIrTensor::GetTensorFamily(v42, (uint64_t)&__p);
  std::__tree<std::__value_type<ZinIrOpLayer *,float>,std::__map_value_compare<ZinIrOpLayer *,std::__value_type<ZinIrOpLayer *,float>,ZinIrIdComparator<ZinIrOpLayer *>,true>,std::allocator<std::__value_type<ZinIrOpLayer *,float>>>::__erase_unique<ZinIrOpLayer *>((uint64_t **)(*((void *)this + 2) + 344), (uint64_t *)&v42);
  char v7 = (char *)__p;
  char v8 = v41;
  if (__p == v41)
  {
LABEL_27:
    uint64_t v11 = ZinIrRegSpill::RevertL2DepOrChain((uint64_t)this, v42, (uint64_t **)this + 3);
  }
  else
  {
    while (1)
    {
      uint64_t v9 = *(void *)v7;
      char v10 = *(ZinANELayer **)(*(void *)v7 + 96);
      if (ZinIrOpLayer::IsANELayer(v10))
      {
        uint64_t v11 = ZinIrRegSpill::SpillWrite(this, v10);
        if (v11)
        {
          BOOL v30 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
          if (v30) {
            ZinIrRegSpill::SpillAndAllocateDMABuffers(v30, v31, v32, v33, v34, v35, v36, v37);
          }
          goto LABEL_32;
        }
      }
      v39[0] = 0;
      v39[1] = 0;
      uint64_t v38 = (uint64_t *)v39;
      BOOL v12 = (uint64_t *)*((void *)v10 + 14);
      std::string::size_type v13 = (uint64_t *)*((void *)v10 + 15);
      if (v12 != v13)
      {
        do
        {
          std::__tree<ZinIrTensor *,ZinIrIdComparator<ZinIrTensor *>,std::allocator<ZinIrTensor *>>::__emplace_hint_unique_key_args<ZinIrTensor *,ZinIrTensor * const&>(&v38, v39, v12, v12);
          ++v12;
        }
        while (v12 != v13);
        uint64_t v14 = v38;
        if (v38 != (uint64_t *)v39) {
          break;
        }
      }
LABEL_26:
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v38, v39[0]);
      v7 += 8;
      if (v7 == v8) {
        goto LABEL_27;
      }
    }
    while (1)
    {
      long long v15 = (ZinIrOpLayer *)v14[4];
      if (ZinIrOpLayer::IsANELayer(v15) && *((void *)v15 + 12) != *((void *)v15 + 11)) {
        break;
      }
LABEL_20:
      uint64_t v18 = (uint64_t *)v14[1];
      if (v18)
      {
        do
        {
          uint64_t v19 = v18;
          uint64_t v18 = (uint64_t *)*v18;
        }
        while (v18);
      }
      else
      {
        do
        {
          uint64_t v19 = (uint64_t *)v14[2];
          BOOL v20 = *v19 == (void)v14;
          uint64_t v14 = v19;
        }
        while (!v20);
      }
      uint64_t v14 = v19;
      if (v19 == (uint64_t *)v39) {
        goto LABEL_26;
      }
    }
    unint64_t v16 = 0;
    while (1)
    {
      if (ZinIrOpLayer::GetInputTensor(v15, v16) == v9)
      {
        if (ZinIrRegSpill::NeedMemCopyCache(this, v15, v17, v42)) {
          ZinIrRegSpill::InsertL2Copy(this, v15, v16);
        }
        uint64_t v11 = ZinIrRegSpill::SpillRead(this, v15, v16);
        if (v11) {
          break;
        }
      }
      if (++v16 >= (uint64_t)(*((void *)v15 + 12) - *((void *)v15 + 11)) >> 3) {
        goto LABEL_20;
      }
    }
    BOOL v21 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (v21) {
      ZinIrRegSpill::SpillAndAllocateDMABuffers(v21, v22, v23, v24, v25, v26, v27, v28);
    }
    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v38, v39[0]);
  }
LABEL_32:
  if (__p)
  {
    uint64_t v41 = (char *)__p;
    operator delete(__p);
  }
  return v11;
}

void sub_21139D9C4(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, char a10, uint64_t a11, uint64_t a12, void *__p, uint64_t a14)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinIrRegSpill::SpillWrite(ZinIrRegSpill *this, ZinANELayer *a2)
{
  ZinIrLocalRegAlloc::FreeDMABuffers(*((ZinIrLocalRegAlloc **)this + 2), a2);
  uint64_t v4 = (*(uint64_t (**)(ZinANELayer *, void, void))(*(void *)a2 + 32))(a2, 0, 0);
  while (1)
  {
    uint64_t v5 = *(void *)(v4 + 104);
    if ((!v5
       || *(_DWORD *)(v5 + 96) != 1
       || ZinIrLocalRegAlloc::AllocateOutputDMACachedBuffer(*((ZinIrLocalRegAlloc **)this + 2), a2))
      && (ZinIrLocalRegAlloc::AllocateOptimizedDMABuffer(*((ZinIrLocalRegAlloc **)this + 2), a2) & 1) != 0)
    {
      break;
    }
    ZinIrLocalRegAlloc::FreeCachedDMAOutputBuffer(*((ZinIrLocalRegAlloc **)this + 2), (ZinEngineLayerMirInfo **)a2);
    ZinIrLocalRegAlloc::FreeDMABuffers(*((ZinIrLocalRegAlloc **)this + 2), a2);
    v15[0] = *((void *)a2 + 6);
    v15[1] = v15[0];
    std::string::size_type v13 = 0;
    uint64_t v14 = 0;
    BOOL v12 = &v13;
    if (ZinIrRegSpill::SpillResidentTensor((uint64_t)this, v15, (uint64_t)&v12))
    {
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v12, v13);
      return 3;
    }
    if (!v14) {
      ZinAssertImpl("It should have rollbackable tensor");
    }
    size_t v6 = v12;
    if (v12 != &v13)
    {
      do
      {
        uint64_t RootTensor = ZinIrTensor::GetRootTensor((ZinIrTensor *)v6[4]);
        std::__tree<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const*>((uint64_t **)this + 3, (uint64_t *)&RootTensor, (uint64_t *)&RootTensor);
        char v7 = v6[1];
        if (v7)
        {
          do
          {
            char v8 = (void **)v7;
            char v7 = (void *)*v7;
          }
          while (v7);
        }
        else
        {
          do
          {
            char v8 = (void **)v6[2];
            BOOL v9 = *v8 == v6;
            size_t v6 = v8;
          }
          while (!v9);
        }
        size_t v6 = v8;
      }
      while (v8 != &v13);
    }
    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v12, v13);
  }
  return 0;
}

void sub_21139DBA8(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, char a10, void *a11)
{
}

uint64_t ZinIrRegSpill::NeedMemCopyCache(ZinIrRegSpill *this, ZinIrOpLayer *a2, unint64_t a3, ZinIrTensor *a4)
{
  uint64_t result = ZinIrOpLayer::IsPELayer(a2);
  if (result)
  {
    unint64_t v16 = a2;
    uint64_t result = (*(uint64_t (**)(ZinIrOpLayer *))(*(void *)a2 + 568))(a2);
    if (result)
    {
      if ((*((void *)a2 + 25) && *((void *)a2 + 24) < 2uLL
         || !*(unsigned char *)(*((void *)this + 12) + 1252)
         && ((uint64_t InputTensor = (ZinIrTensor *)ZinIrOpLayer::GetInputTensor(a2, 0),
              uint64_t RootTensor = ZinIrTensor::GetRootTensor(InputTensor),
              uint64_t v11 = (ZinIrTensor *)ZinIrOpLayer::GetInputTensor(a2, 1uLL),
              BOOL v12 = ZinIrTensor::GetRootTensor(v11),
              uint64_t Interleave = ZinIrLocalRegAlloc::GetInterleave(*((ZinIrLocalRegAlloc **)this + 2), RootTensor),
              uint64_t v14 = ZinIrLocalRegAlloc::GetInterleave(*((ZinIrLocalRegAlloc **)this + 2), v12),
              ZinIrRegSpill::HasMismatchedDualInput(a2, v15))
          || Interleave != v14))
        && (uint64_t v8 = *((void *)a4 + 13)) != 0
        && *(_DWORD *)(v8 + 96) == 1)
      {
        return std::__hash_table<std::__hash_value_type<ZinANELayer const*,int>,std::__unordered_map_hasher<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::hash<ZinANELayer const*>,std::equal_to<ZinANELayer const*>,true>,std::__unordered_map_equal<ZinANELayer const*,std::__hash_value_type<ZinANELayer const*,int>,std::equal_to<ZinANELayer const*>,std::hash<ZinANELayer const*>,true>,std::allocator<std::__hash_value_type<ZinANELayer const*,int>>>::find<ZinANELayer const*>((void *)this + 6, &v16) == 0;
      }
      else
      {
        return 0;
      }
    }
  }
  return result;
}

uint64_t ZinIrRegSpill::SpillReadWithCopy(ZinIrRegSpill *this, ZinNEBypassLayer *a2, ZinPELayer *a3, const ZinANELayer *a4)
{
  ZinIrLocalRegAlloc::FreeDMABuffers(*((ZinIrLocalRegAlloc **)this + 2), a3);
  ZinIrLocalRegAlloc::FreeInputDMABufferForL2CacheCopy(*((ZinIrLocalRegAlloc **)this + 2), a2);
  while (!ZinIrLocalRegAlloc::AllocateReadL2CacheCopyTensor(*((ZinIrLocalRegAlloc **)this + 2), a2, a3, a4)|| !ZinIrLocalRegAlloc::AllocateOptimizedDMABuffer(*((ZinIrLocalRegAlloc **)this + 2), a3)|| (ZinIrLocalRegAlloc::AllocateInputDMAbufferForL2CacheCopy(*((ZinIrLocalRegAlloc **)this + 2), a2) & 1) == 0)
  {
    uint64_t v8 = (ZinIrLocalRegAlloc *)*((void *)this + 2);
    BOOL v9 = (ZinIrTensor *)(*(uint64_t (**)(ZinNEBypassLayer *, void, void))(*(void *)a2 + 32))(a2, 0, 0);
    ZinIrLocalRegAlloc::RemoveSymbolFromLayerAndTensor(v8, v9);
    ZinIrLocalRegAlloc::FreeDMABuffers(*((ZinIrLocalRegAlloc **)this + 2), a3);
    ZinIrLocalRegAlloc::FreeDMABuffers(*((ZinIrLocalRegAlloc **)this + 2), a2);
    unint64_t v10 = *((void *)a3 + 6);
    v23[0] = *((void *)a2 + 6);
    v23[1] = v10;
    BOOL v21 = 0;
    uint64_t v22 = 0;
    BOOL v20 = &v21;
    if (ZinIrRegSpill::SpillResidentTensor((uint64_t)this, v23, (uint64_t)&v20))
    {
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v20, v21);
      return 3;
    }
    if (!v22) {
      ZinAssertImpl("It should have rollbackable tensor");
    }
    uint64_t v11 = v20;
    if (v20 != &v21)
    {
      do
      {
        uint64_t RootTensor = ZinIrTensor::GetRootTensor((ZinIrTensor *)v11[4]);
        std::__tree<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const*>((uint64_t **)this + 3, (uint64_t *)&RootTensor, (uint64_t *)&RootTensor);
        BOOL v12 = v11[1];
        if (v12)
        {
          do
          {
            std::string::size_type v13 = (void **)v12;
            BOOL v12 = (void *)*v12;
          }
          while (v12);
        }
        else
        {
          do
          {
            std::string::size_type v13 = (void **)v11[2];
            BOOL v14 = *v13 == v11;
            uint64_t v11 = v13;
          }
          while (!v14);
        }
        uint64_t v11 = v13;
      }
      while (v13 != &v21);
    }
    std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v20, v21);
  }
  uint64_t v16 = *(void *)(ZinIrOpLayer::GetInputTensor(a2, 0) + 104);
  if (!v16 || (unint64_t v17 = *(uint64_t **)(v16 + 40), v17 == *(uint64_t **)(v16 + 48))) {
    uint64_t v18 = 0;
  }
  else {
    uint64_t v18 = *v17;
  }
  (*(void (**)(ZinNEBypassLayer *, void, uint64_t, void))(*(void *)a2 + 456))(a2, 0, v18, *((void *)this + 12));
  return 0;
}

void sub_21139DF24(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, char a10, void *a11)
{
}

uint64_t ZinIrRegSpill::SpillRead(ZinIrRegSpill *this, ZinANELayer *a2, unint64_t a3)
{
  ZinIrLocalRegAlloc::FreeDMABuffers(*((ZinIrLocalRegAlloc **)this + 2), a2);
  uint64_t InputTensor = ZinIrOpLayer::GetInputTensor(a2, a3);
  unsigned int v18 = 0;
  if (ZinMemSourceIndexTranslator::GetL2SrcType(a2, a3, (int *)&v18))
  {
    if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
      ZinIrLocalRegAlloc::SetChainSymbolToLayers();
    }
    return 3;
  }
  else
  {
    while (1)
    {
      uint64_t v7 = *(void *)(InputTensor + 104);
      if ((!v7
         || *(_DWORD *)(v7 + 96) != 1
         || ZinIrLocalRegAlloc::AllocateInputDMACachedBuffer(*((ZinIrLocalRegAlloc **)this + 2), a2, v18))
        && (ZinIrLocalRegAlloc::AllocateOptimizedDMABuffer(*((ZinIrLocalRegAlloc **)this + 2), a2) & 1) != 0)
      {
        break;
      }
      ZinIrLocalRegAlloc::FreeCachedDMAInputBuffer(*((void *)this + 2), (uint64_t)a2, v18);
      ZinIrLocalRegAlloc::FreeDMABuffers(*((ZinIrLocalRegAlloc **)this + 2), a2);
      v17[0] = *((void *)a2 + 6);
      v17[1] = v17[0];
      long long v15 = 0;
      uint64_t v16 = 0;
      BOOL v14 = &v15;
      if (ZinIrRegSpill::SpillResidentTensor((uint64_t)this, v17, (uint64_t)&v14))
      {
        std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v14, v15);
        return 3;
      }
      if (!v16) {
        ZinAssertImpl("It should have rollbackable tensor");
      }
      uint64_t v8 = v14;
      if (v14 != &v15)
      {
        do
        {
          uint64_t RootTensor = ZinIrTensor::GetRootTensor((ZinIrTensor *)v8[4]);
          std::__tree<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const*>((uint64_t **)this + 3, (uint64_t *)&RootTensor, (uint64_t *)&RootTensor);
          BOOL v9 = v8[1];
          if (v9)
          {
            do
            {
              unint64_t v10 = (void **)v9;
              BOOL v9 = (void *)*v9;
            }
            while (v9);
          }
          else
          {
            do
            {
              unint64_t v10 = (void **)v8[2];
              BOOL v11 = *v10 == v8;
              uint64_t v8 = v10;
            }
            while (!v11);
          }
          uint64_t v8 = v10;
        }
        while (v10 != &v15);
      }
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v14, v15);
    }
    return 0;
  }
}

void sub_21139E0F8(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, char a11, void *a12)
{
}

uint64_t ZinIrRegSpill::RevertL2DepOrChain(uint64_t a1, ZinIrTensor *a2, uint64_t **a3)
{
  v56[0] = 0;
  v56[1] = 0;
  long long v55 = (uint64_t *)v56;
  ZinIrTensor::GetTensorFamily(a2, (uint64_t)&v51);
  size_t v6 = v51;
  uint64_t v7 = (ZinIrOpLayer ***)v52;
  if (v51 == (ZinIrOpLayer ***)v52)
  {
    int v20 = 2;
    if (v51) {
      goto LABEL_36;
    }
    goto LABEL_37;
  }
  uint64_t v53 = 0;
  long long v54 = 0;
LABEL_3:
  uint64_t v8 = *v6;
  uint64_t IsANELayer = (uint64_t)ZinIrRegSpill::IsL2DepOrChain((ZinIrRegSpill *)IsANELayer, *v6, &v54, &v53);
  if (IsANELayer)
  {
    uint64_t IsANELayer = ZinIrRegSpill::SpillL2DepOrChain(a1, &v54, &v53, &v55);
    if (IsANELayer)
    {
      BOOL v22 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v22) {
        goto LABEL_33;
      }
      goto LABEL_34;
    }
  }
  BOOL v9 = v8[12];
  BOOL v11 = (ZinIrOpLayer **)*((void *)v9 + 14);
  unint64_t v10 = (ZinIrOpLayer **)*((void *)v9 + 15);
  while (1)
  {
    if (v11 == v10)
    {
      if (++v6 != v7) {
        goto LABEL_3;
      }
      int v20 = 2;
      goto LABEL_35;
    }
    BOOL v12 = *v11;
    if (ZinIrOpLayer::IsANELayer(*v11))
    {
      std::string::size_type v13 = (ZinIrTensor *)(*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)v12 + 32))(v12, 0, 0);
      uint64_t RootTensor = ZinIrTensor::GetRootTensor(v13);
      if (ZinIrRegSpill::IsL2DepOrChain(RootTensor, (ZinIrOpLayer **)RootTensor, &v54, &v53))
      {
        if (ZinIrRegSpill::SpillL2DepOrChain(a1, &v54, &v53, &v55)) {
          break;
        }
      }
    }
    uint64_t IsANELayer = ZinIrOpLayer::IsANELayer(v12);
    if (!IsANELayer) {
      goto LABEL_27;
    }
    uint64_t IsANELayer = (uint64_t)(*(void *(**)(ZinIrTensor ***__return_ptr, ZinIrOpLayer *))(*(void *)v12 + 512))(&v49, v12);
    uint64_t v16 = v49;
    long long v15 = v50;
    if (v49)
    {
      uint64_t v50 = v49;
      operator delete(v49);
    }
    if ((char *)v15 - (char *)v16 != 16) {
      goto LABEL_27;
    }
    uint64_t IsANELayer = (uint64_t)(*(void *(**)(ZinIrTensor ***__return_ptr, ZinIrOpLayer *))(*(void *)v12 + 512))(&v49, v12);
    unint64_t v17 = v49;
    unsigned int v18 = v50;
    if (v49 == v50)
    {
      int v20 = 6;
      int v21 = 1;
      if (v49) {
        goto LABEL_25;
      }
    }
    else
    {
      while (1)
      {
        uint64_t v19 = ZinIrTensor::GetRootTensor(*v17);
        uint64_t IsANELayer = (uint64_t)ZinIrRegSpill::IsL2DepOrChain(v19, (ZinIrOpLayer **)v19, &v54, &v53);
        if (IsANELayer)
        {
          uint64_t IsANELayer = ZinIrRegSpill::SpillL2DepOrChain(a1, &v54, &v53, &v55);
          if (IsANELayer) {
            break;
          }
        }
        if (++v17 == v18)
        {
          int v20 = 6;
          int v21 = 1;
          goto LABEL_24;
        }
      }
      uint64_t IsANELayer = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (IsANELayer) {
        ZinIrRegSpill::RevertL2DepOrChain(&buf, v48);
      }
      int v21 = 0;
      int v20 = 1;
LABEL_24:
      unint64_t v17 = v49;
      if (v49)
      {
LABEL_25:
        uint64_t v50 = v17;
        operator delete(v17);
      }
    }
    if (!v21) {
      goto LABEL_35;
    }
LABEL_27:
    ++v11;
  }
  BOOL v22 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
  if (!v22) {
    goto LABEL_34;
  }
LABEL_33:
  ZinIrRegSpill::RevertL2DepOrChain(v22, v23, v24, v25, v26, v27, v28, v29);
LABEL_34:
  int v20 = 1;
LABEL_35:
  size_t v6 = v51;
  if (v51)
  {
LABEL_36:
    uint64_t v52 = (ZinIrTensor *)v6;
    operator delete(v6);
  }
LABEL_37:
  if (v20 == 2)
  {
    BOOL v30 = v55;
    if (v55 == (uint64_t *)v56)
    {
LABEL_55:
      uint64_t v31 = 0;
    }
    else
    {
      while (1)
      {
        uint64_t v31 = ZinIrRegSpill::RevertL2DepOrChain(a1, v30[4], a3);
        if (v31) {
          break;
        }
        uint64_t v32 = (uint64_t *)v30[1];
        if (v32)
        {
          do
          {
            uint64_t v33 = v32;
            uint64_t v32 = (uint64_t *)*v32;
          }
          while (v32);
        }
        else
        {
          do
          {
            uint64_t v33 = (uint64_t *)v30[2];
            BOOL v34 = *v33 == (void)v30;
            BOOL v30 = v33;
          }
          while (!v34);
        }
        BOOL v30 = v33;
        if (v33 == (uint64_t *)v56)
        {
          uint64_t v35 = v55;
          if (v55 != (uint64_t *)v56)
          {
            do
            {
              uint64_t v51 = (ZinIrOpLayer ***)v35[4];
              if (!ZinIrTensor::HasParent((ZinIrTensor *)v51)) {
                std::__tree<ZinIrTensor const*,ZinIrIdComparator<ZinIrTensor const*>,std::allocator<ZinIrTensor const*>>::__emplace_unique_key_args<ZinIrTensor const*,ZinIrTensor const*>(a3, (uint64_t *)&v51, (uint64_t *)&v51);
              }
              uint64_t v36 = (uint64_t *)v35[1];
              if (v36)
              {
                do
                {
                  uint64_t v37 = v36;
                  uint64_t v36 = (uint64_t *)*v36;
                }
                while (v36);
              }
              else
              {
                do
                {
                  uint64_t v37 = (uint64_t *)v35[2];
                  BOOL v34 = *v37 == (void)v35;
                  uint64_t v35 = v37;
                }
                while (!v34);
              }
              uint64_t v35 = v37;
            }
            while (v37 != (uint64_t *)v56);
          }
          goto LABEL_55;
        }
      }
      BOOL v38 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v38) {
        ZinIrRegSpill::RevertL2DepOrChain(v38, v39, v40, v41, v42, v43, v44, v45);
      }
    }
  }
  else
  {
    uint64_t v31 = 3;
  }
  std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v55, v56[0]);
  return v31;
}

void sub_21139E508(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, void *a12, uint64_t a13, uint64_t a14, void *__p, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, char a20,void *a21)
{
}

uint64_t ZinIrRegSpill::SpillResidentTensor(uint64_t a1, unint64_t *a2, uint64_t a3)
{
  std::string __p = 0;
  std::string::size_type v13 = 0;
  uint64_t v14 = 0;
  int v5 = ZinIrLocalRegAlloc::FreeL2Symbol(*(ZinIrLocalRegAlloc **)(a1 + 16), a2, &__p);
  size_t v6 = (uint64_t *)__p;
  if (v5)
  {
    uint64_t v7 = 3;
  }
  else
  {
    uint64_t v8 = v13;
    if (__p == v13) {
      goto LABEL_13;
    }
    do
    {
      std::__tree<ZinIrTensor *,ZinIrIdComparator<ZinIrTensor *>,std::allocator<ZinIrTensor *>>::__emplace_hint_unique_key_args<ZinIrTensor *,ZinIrTensor * const&>((uint64_t **)a3, (void *)(a3 + 8), v6, v6);
      ++v6;
    }
    while (v6 != v8);
    size_t v6 = v13;
    if (__p == v13)
    {
LABEL_13:
      uint64_t v7 = 0;
    }
    else
    {
      BOOL v9 = (uint64_t *)((char *)__p + 8);
      do
      {
        uint64_t v7 = ZinIrRegSpill::RevertL2DepOrChain(a1, (ZinIrTensor *)*(v9 - 1), (uint64_t **)a3);
        if (v7) {
          BOOL v10 = 1;
        }
        else {
          BOOL v10 = v9 == v6;
        }
        ++v9;
      }
      while (!v10);
      size_t v6 = (uint64_t *)__p;
    }
  }
  if (v6)
  {
    std::string::size_type v13 = v6;
    operator delete(v6);
  }
  return v7;
}

void sub_21139E648(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinIrRegSpill::SpillResidentTensor(uint64_t a1, uint64_t a2, uint64_t a3)
{
  std::string __p = 0;
  uint64_t v16 = 0;
  uint64_t v17 = 0;
  int v5 = *(ZinIrLocalRegAlloc **)(a1 + 16);
  uint64_t v6 = *(void *)(a2 + 104);
  if (!v6 || (uint64_t v7 = *(ZinIrSymbol ***)(v6 + 40), v7 == *(ZinIrSymbol ***)(v6 + 48))) {
    uint64_t v8 = 0;
  }
  else {
    uint64_t v8 = *v7;
  }
  ZinIrLocalRegAlloc::FreeL2Symbol(v5, v8, &__p);
  BOOL v9 = (uint64_t *)__p;
  BOOL v10 = v16;
  if (__p == v16) {
    goto LABEL_16;
  }
  do
  {
    std::__tree<ZinIrTensor *,ZinIrIdComparator<ZinIrTensor *>,std::allocator<ZinIrTensor *>>::__emplace_hint_unique_key_args<ZinIrTensor *,ZinIrTensor * const&>((uint64_t **)a3, (void *)(a3 + 8), v9, v9);
    ++v9;
  }
  while (v9 != v10);
  BOOL v9 = v16;
  if (__p == v16)
  {
LABEL_16:
    uint64_t v12 = 0;
    if (!v9) {
      return v12;
    }
LABEL_17:
    uint64_t v16 = v9;
    operator delete(v9);
    return v12;
  }
  BOOL v11 = (uint64_t *)((char *)__p + 8);
  do
  {
    uint64_t v12 = ZinIrRegSpill::RevertL2DepOrChain(a1, (ZinIrTensor *)*(v11 - 1), (uint64_t **)a3);
    if (v12) {
      BOOL v13 = 1;
    }
    else {
      BOOL v13 = v11 == v9;
    }
    ++v11;
  }
  while (!v13);
  BOOL v9 = (uint64_t *)__p;
  if (__p) {
    goto LABEL_17;
  }
  return v12;
}

void sub_21139E764(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

ZinIrOpLayer *ZinIrRegSpill::IsL2DepOrChain(ZinIrRegSpill *this, ZinIrOpLayer **a2, ZinANELayer **a3, ZinANELayer **a4)
{
  uint64_t result = (ZinIrOpLayer *)ZinIrOpLayer::IsANELayer(a2[12]);
  if (result)
  {
    BOOL v9 = a2[12];
    *a3 = v9;
    uint64_t result = ZinIrRegAllocUtil::GetFirstConsumer(v9, v8);
    *a4 = result;
    if (result) {
      return (ZinIrOpLayer *)(*((void *)*a3 + 6) == *((void *)result + 6));
    }
  }
  return result;
}

uint64_t ZinIrRegSpill::SpillL2DepOrChain(uint64_t a1, ZinANELayer **a2, ZinANELayer **a3, uint64_t **a4)
{
  BOOL HasLockedPEWorkUnit = ZinIrLocalRegAlloc::HasLockedPEWorkUnit(*(ZinIrLocalRegAlloc **)(a1 + 16), *a2);
  BOOL v9 = *a2;
  if (!HasLockedPEWorkUnit) {
    *(unsigned char *)(*((void *)v9 + 33) + 256) = 0;
  }
  BOOL HasLockedNEWorkUnit = ZinIrLocalRegAlloc::HasLockedNEWorkUnit(*(ZinIrLocalRegAlloc **)(a1 + 16), v9);
  uint64_t v11 = *((void *)*a2 + 33);
  if (!HasLockedNEWorkUnit) {
    *(unsigned char *)(v11 + 15std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  }
  *(unsigned char *)(v11 + 233) = 0;
  BOOL v12 = ZinIrLocalRegAlloc::HasLockedPEWorkUnit(*(ZinIrLocalRegAlloc **)(a1 + 16), *a3);
  BOOL v13 = *a3;
  if (!v12) {
    *(unsigned char *)(*((void *)v13 + 33) + 256) = 0;
  }
  BOOL v14 = ZinIrLocalRegAlloc::HasLockedNEWorkUnit(*(ZinIrLocalRegAlloc **)(a1 + 16), v13);
  long long v15 = *a3;
  uint64_t v16 = *((void *)*a3 + 33);
  if (!v14) {
    *(unsigned char *)(v16 + 15std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  }
  *(unsigned char *)(v16 + 233) = 0;
  uint64_t v17 = *a2;
  uint64_t v18 = *((void *)*a2 + 6);
  std::string __p = 0;
  uint64_t v31 = 0;
  uint64_t v32 = 0;
  int IntermediateLayers = ZinTensorFamilyUtil::GetIntermediateLayers((uint64_t)v17, v15, 0, 0, &__p);
  uint64_t v20 = v18 + 1;
  if (IntermediateLayers || (v22 = (uint64_t *)__p, uint64_t v23 = v31, __p == v31))
  {
    unint64_t v21 = v18 + 1;
  }
  else
  {
    do
    {
      uint64_t v24 = *v22++;
      unint64_t v21 = v20 + 1;
      *(void *)(v24 + 48) = v20++;
    }
    while (v22 != v23);
  }
  if (ZinIrLocalRegAlloc::ChangeEngineLayerSchedule(*(ZinIrLocalRegAlloc **)(a1 + 16), *a3, v21, 0))
  {
    uint64_t v25 = *(void **)(a1 + 16);
    uint64_t v26 = (ZinIrTensor *)(*(uint64_t (**)(ZinANELayer *, void, void))(*(void *)*a2 + 32))(*a2, 0, 0);
    uint64_t RootTensor = ZinIrTensor::GetRootTensor(v26);
    ZinIrLocalRegAlloc::RemoveSymbolFromLayerAndTensor(v25, (uint64_t)RootTensor, a4);
    uint64_t v28 = 0;
  }
  else
  {
    if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
      ZinIrRegSpill::SpillL2DepOrChain();
    }
    uint64_t v28 = 3;
  }
  if (__p)
  {
    uint64_t v31 = (uint64_t *)__p;
    operator delete(__p);
  }
  return v28;
}

void sub_21139E98C(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

void std::__function::__func<ZinIrRegSpill::VerifyL2Symbols(void)::$_0,std::allocator<ZinIrRegSpill::VerifyL2Symbols(void)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::~__func()
{
}

void *std::__function::__func<ZinIrRegSpill::VerifyL2Symbols(void)::$_0,std::allocator<ZinIrRegSpill::VerifyL2Symbols(void)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::__clone()
{
  uint64_t result = operator new(0x10uLL);
  *uint64_t result = &unk_26C332DE8;
  return result;
}

void std::__function::__func<ZinIrRegSpill::VerifyL2Symbols(void)::$_0,std::allocator<ZinIrRegSpill::VerifyL2Symbols(void)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::__clone(uint64_t a1, void *a2)
{
  *a2 = &unk_26C332DE8;
}

uint64_t std::__function::__func<ZinIrRegSpill::VerifyL2Symbols(void)::$_0,std::allocator<ZinIrRegSpill::VerifyL2Symbols(void)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::operator()(uint64_t a1, uint64_t a2, ZinIrOpLayer **a3)
{
  uint64_t v25 = *MEMORY[0x263EF8340];
  uint64_t v3 = *a3;
  if (!ZinIrOpLayer::IsANELayer(*a3)) {
    return 0;
  }
  if (*((void *)v3 + 12) == *((void *)v3 + 11))
  {
LABEL_13:
    ZinEngineLayerMirInfo::GetL2WrSymbols(*((ZinEngineLayerMirInfo **)v3 + 33), &v20);
    BOOL v9 = v20;
    uint64_t v10 = v21 - v20;
    if (v10)
    {
      if (v10 != 1)
      {
        uint64_t v11 = 0;
        if (!v20) {
          return v11;
        }
        goto LABEL_22;
      }
      if (*v20)
      {
        uint64_t v11 = 0;
        goto LABEL_22;
      }
    }
    if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR))
    {
      uint64_t v19 = (void *)((char *)v3 + 24);
      if (*((char *)v3 + 47) < 0) {
        uint64_t v19 = (void *)*v19;
      }
      *(_DWORD *)uint8_t buf = 136315138;
      uint64_t v24 = v19;
      _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "Error: L2 write symbol does not exist in %s", buf, 0xCu);
      uint64_t v11 = 3;
      BOOL v9 = v20;
      if (!v20) {
        return v11;
      }
    }
    else
    {
      uint64_t v11 = 3;
      if (!v9) {
        return v11;
      }
    }
LABEL_22:
    unint64_t v21 = v9;
    operator delete(v9);
    return v11;
  }
  unint64_t v4 = 0;
  int v5 = (void *)((char *)v3 + 24);
  while (1)
  {
    uint64_t InputTensor = ZinIrOpLayer::GetInputTensor(v3, v4);
    if ((*(uint64_t (**)(ZinIrOpLayer *, uint64_t))(*(void *)v3 + 200))(v3, InputTensor)) {
      goto LABEL_12;
    }
    int v22 = 0;
    if (ZinMemSourceIndexTranslator::GetL2SrcType(v3, v4, &v22))
    {
      if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
        ZinIrLocalRegAlloc::VerifyL2Symbols((uint64_t)v3 + 47, (uint64_t)v3 + 24, v12, v13, v14, v15, v16, v17);
      }
      return 3;
    }
    ZinEngineLayerMirInfo::GetL2RdSymbols(*((void *)v3 + 33), v22, &v20);
    uint64_t v7 = v20;
    uint64_t v8 = v21 - v20;
    if (v8 == 1) {
      break;
    }
    if (!v8) {
      goto LABEL_25;
    }
    if (v20) {
      goto LABEL_11;
    }
LABEL_12:
    if (++v4 >= (uint64_t)(*((void *)v3 + 12) - *((void *)v3 + 11)) >> 3) {
      goto LABEL_13;
    }
  }
  if (*v20)
  {
LABEL_11:
    unint64_t v21 = v20;
    operator delete(v20);
    goto LABEL_12;
  }
LABEL_25:
  if (!os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR))
  {
    if (!v7) {
      return 3;
    }
    goto LABEL_27;
  }
  if (*((char *)v3 + 47) < 0) {
    int v5 = (void *)*v5;
  }
  *(_DWORD *)uint8_t buf = 136315138;
  uint64_t v24 = v5;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "Error: L2 read symbol does not exist in %s", buf, 0xCu);
  uint64_t v7 = v20;
  if (v20)
  {
LABEL_27:
    unint64_t v21 = v7;
    operator delete(v7);
  }
  return 3;
}

uint64_t std::__function::__func<ZinIrRegSpill::VerifyL2Symbols(void)::$_0,std::allocator<ZinIrRegSpill::VerifyL2Symbols(void)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::target(uint64_t a1, uint64_t a2)
{
    return a1 + 8;
  else {
    return 0;
  }
}

void *std::__function::__func<ZinIrRegSpill::VerifyL2Symbols(void)::$_0,std::allocator<ZinIrRegSpill::VerifyL2Symbols(void)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::target_type()
{
}

void std::__function::__func<ZinIrRegSpill::VerifyChainSymbols(void)::$_0,std::allocator<ZinIrRegSpill::VerifyChainSymbols(void)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::~__func()
{
}

void *std::__function::__func<ZinIrRegSpill::VerifyChainSymbols(void)::$_0,std::allocator<ZinIrRegSpill::VerifyChainSymbols(void)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::__clone()
{
  uint64_t result = operator new(0x10uLL);
  *uint64_t result = &unk_26C332E40;
  return result;
}

void std::__function::__func<ZinIrRegSpill::VerifyChainSymbols(void)::$_0,std::allocator<ZinIrRegSpill::VerifyChainSymbols(void)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::__clone(uint64_t a1, void *a2)
{
  *a2 = &unk_26C332E40;
}

uint64_t std::__function::__func<ZinIrRegSpill::VerifyChainSymbols(void)::$_0,std::allocator<ZinIrRegSpill::VerifyChainSymbols(void)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::operator()(uint64_t a1, ZinIrOpLayerGraph **a2, ZinIrOpLayer **a3)
{
  uint64_t v3 = *a2;
  unint64_t v4 = *a3;
  uint64_t result = ZinIrOpLayer::IsANELayer(*a3);
  if (result)
  {
    if (*(_DWORD *)(*((void *)v4 + 33) + 1632) != 4) {
      return 0;
    }
    uint64_t v6 = (uint64_t *)**((void **)v4 + 14);
    if (!ZinIrOpLayer::IsANELayer((ZinIrOpLayer *)v6)) {
      return 3;
    }
    uint64_t result = ZinIrOpLayer::IsPELayer((ZinIrOpLayer *)v6);
    if (result)
    {
      uint64_t result = (*(uint64_t (**)(uint64_t *))(*v6 + 568))(v6);
      if (result)
      {
        unint64_t IndexOfMatchedIncomingLayer = ZinIrOpLayerGraph::GetIndexOfMatchedIncomingLayer(v3, (ZinIrOpLayer *)v6, v4);
        int v9 = 0;
        if (ZinMemSourceIndexTranslator::GetL2SrcType(v6, IndexOfMatchedIncomingLayer, &v9))
        {
          if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
            std::__function::__func<ZinIrRegSpill::VerifyChainSymbols(void)::$_0,std::allocator<ZinIrRegSpill::VerifyChainSymbols(void)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::operator()();
          }
          return 3;
        }
        int v8 = v9;
        if (v9 == 2)
        {
          if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
            std::__function::__func<ZinIrRegSpill::VerifyChainSymbols(void)::$_0,std::allocator<ZinIrRegSpill::VerifyChainSymbols(void)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::operator()();
          }
          return 3;
        }
        if (!ZinEngineLayerMirInfo::HasL2Read(*((ZinEngineLayerMirInfo **)v4 + 33))
          && !ZinEngineLayerMirInfo::HasL2Read(v6[33], v8 == 0))
        {
          if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
            std::__function::__func<ZinIrRegSpill::VerifyChainSymbols(void)::$_0,std::allocator<ZinIrRegSpill::VerifyChainSymbols(void)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::operator()((uint64_t)v4);
          }
          return 3;
        }
        return 0;
      }
    }
  }
  return result;
}

uint64_t std::__function::__func<ZinIrRegSpill::VerifyChainSymbols(void)::$_0,std::allocator<ZinIrRegSpill::VerifyChainSymbols(void)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::target(uint64_t a1, uint64_t a2)
{
  {
    return a1 + 8;
  }
  else
  {
    return 0;
  }
}

void *std::__function::__func<ZinIrRegSpill::VerifyChainSymbols(void)::$_0,std::allocator<ZinIrRegSpill::VerifyChainSymbols(void)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::target_type()
{
}

void std::__function::__func<ZinIrRegSpill::InsertL2Copy(ZinPELayer *,unsigned long)::$_0,std::allocator<ZinIrRegSpill::InsertL2Copy(ZinPELayer *,unsigned long)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::~__func()
{
}

__n128 std::__function::__func<ZinIrRegSpill::InsertL2Copy(ZinPELayer *,unsigned long)::$_0,std::allocator<ZinIrRegSpill::InsertL2Copy(ZinPELayer *,unsigned long)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::__clone(uint64_t a1)
{
  uint64_t v2 = (char *)operator new(0x18uLL);
  *(void *)uint64_t v2 = &unk_26C32D758;
  __n128 result = *(__n128 *)(a1 + 8);
  *(__n128 *)(v2 + 8) = result;
  return result;
}

__n128 std::__function::__func<ZinIrRegSpill::InsertL2Copy(ZinPELayer *,unsigned long)::$_0,std::allocator<ZinIrRegSpill::InsertL2Copy(ZinPELayer *,unsigned long)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::__clone(uint64_t a1, uint64_t a2)
{
  *(void *)a2 = &unk_26C32D758;
  __n128 result = *(__n128 *)(a1 + 8);
  *(__n128 *)(a2 + 8) = result;
  return result;
}

uint64_t std::__function::__func<ZinIrRegSpill::InsertL2Copy(ZinPELayer *,unsigned long)::$_0,std::allocator<ZinIrRegSpill::InsertL2Copy(ZinPELayer *,unsigned long)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::operator()(uint64_t a1, uint64_t *a2, unint64_t *a3)
{
  uint64_t v4 = *a2;
  unint64_t v5 = *a3;
  unint64_t v8 = v5;
  if (**(void **)(a1 + 8) == v5)
  {
    *(void *)(v5 + 48) = **(void **)(a1 + 16);
  }
  else if (*(void *)(v5 + 48) >= **(void **)(a1 + 16))
  {
    uint64_t v7 = **(void **)(a1 + 8);
    if (!ZinIrNgraph<ZinIrOpLayer *,ZinIrIdComparator<ZinIrOpLayer *>>::IsConnected(v4, &v8, &v7)) {
      ++*(void *)(v8 + 48);
    }
  }
  return 0;
}

uint64_t std::__function::__func<ZinIrRegSpill::InsertL2Copy(ZinPELayer *,unsigned long)::$_0,std::allocator<ZinIrRegSpill::InsertL2Copy(ZinPELayer *,unsigned long)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::target(uint64_t a1, uint64_t a2)
{
  {
    return a1 + 8;
  }
  else
  {
    return 0;
  }
}

void *std::__function::__func<ZinIrRegSpill::InsertL2Copy(ZinPELayer *,unsigned long)::$_0,std::allocator<ZinIrRegSpill::InsertL2Copy(ZinPELayer *,unsigned long)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::target_type()
{
}

void ZinIrRegSpill::Run(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "Spiller lower kernel error.", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "Spiller do spill on candidates error.", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "Spiller clear l2 symbol error.", a5, a6, a7, a8, 0);
}

void ZinIrRegSpill::ClearCandidateL2Symbols(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void ZinIrRegSpill::DoSpillOnCandidates(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "Spiller candidate is not qualified.", a5, a6, a7, a8, 0);
}

void ZinIrRegSpill::InsertL2Copy(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void ZinIrRegSpill::InsertL2Copy()
{
  OUTLINED_FUNCTION_6_0();
  OUTLINED_FUNCTION_4_1(&dword_210C72000, &_os_log_internal, v0, "SetAllocationHint failure  %s:%d\n", v1, v2, v3, v4, v5);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint8_t v5;

  OUTLINED_FUNCTION_6_0();
  OUTLINED_FUNCTION_4_1(&dword_210C72000, &_os_log_internal, v0, "Insert copy failure  %s:%d\n", v1, v2, v3, v4, v5);
}

void ZinIrRegSpill::SpillAndAllocateDMABuffers(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "Spiller spill read error.", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "Spiller spill write error.", a5, a6, a7, a8, 0);
}

void ZinIrRegSpill::RevertL2DepOrChain(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void ZinIrRegSpill::RevertL2DepOrChain(uint8_t *buf, unsigned char *a2)
{
  *uint8_t buf = 0;
  *a2 = 0;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "Spiller spill l2-dep/chain error.", buf, 2u);
}

void ZinIrRegSpill::SpillL2DepOrChain()
{
  OUTLINED_FUNCTION_6_0();
  OUTLINED_FUNCTION_4_1(&dword_210C72000, &_os_log_internal, v0, "Schedule update must be done succesfully.  %s:%d\n", v1, v2, v3, v4, v5);
}

void std::__function::__func<ZinIrRegSpill::VerifyChainSymbols(void)::$_0,std::allocator<ZinIrRegSpill::VerifyChainSymbols(void)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::operator()()
{
  OUTLINED_FUNCTION_3_0(*MEMORY[0x263EF8340]);
  OUTLINED_FUNCTION_5();
  OUTLINED_FUNCTION_2(&dword_210C72000, &_os_log_internal, v0, "Error: Attempting to set chained symbol for SrcIdx of %s, SrcIdx should be resident.", v1, v2, v3, v4, v5);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint8_t v5;

  OUTLINED_FUNCTION_3_0(*MEMORY[0x263EF8340]);
  OUTLINED_FUNCTION_5();
  OUTLINED_FUNCTION_2(&dword_210C72000, &_os_log_internal, v0, "Error: Engine layer %s has invalid L2 source", v1, v2, v3, v4, v5);
}

void std::__function::__func<ZinIrRegSpill::VerifyChainSymbols(void)::$_0,std::allocator<ZinIrRegSpill::VerifyChainSymbols(void)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::operator()(uint64_t a1)
{
  (*(void (**)(uint64_t, void, void))(*(void *)a1 + 32))(a1, 0, 0);
  OUTLINED_FUNCTION_5();
  OUTLINED_FUNCTION_2(&dword_210C72000, &_os_log_internal, v1, "Error: We found illegal chaining %s", v2, v3, v4, v5, v6);
}

void *ZinMirPEReductionAccumulationRetention::ZinMirPEReductionAccumulationRetention(void *a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  *a1 = a3;
  a1[1] = a2;
  a1[2] = a4;
  uint64_t v5 = a1 + 3;
  std::string::basic_string[abi:ne180100]<0>(__p, "pe_reduction_acc_retention");
  ZinObjectNameFactory::ZinObjectNameFactory(v5, __p);
  if (v8 < 0) {
    operator delete(__p[0]);
  }
  a1[8] = 0;
  a1[9] = 0;
  a1[10] = 0;
  return a1;
}

void sub_21139F790(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11, int a12, __int16 a13, char a14, char a15)
{
  if (a15 < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinMirPEReductionAccumulationRetention::UpdateGraphWithConst(ZinMirPEReductionAccumulationRetention *this, ZinIrOpLayerGraph *a2, ZinPEElementWiseLayer *a3)
{
  uint64_t v46 = *MEMORY[0x263EF8340];
  (*(void (**)(ZinPEElementWiseLayer *, void, void))(*(void *)a3 + 40))(a3, 0, 0);
  uint64_t v4 = (*(uint64_t (**)(ZinPEElementWiseLayer *, uint64_t))(*(void *)a3 + 360))(a3, 3);
  uint64_t v5 = (*(uint64_t (**)(ZinPEElementWiseLayer *, uint64_t))(*(void *)a3 + 360))(a3, 4);
  uint64_t v6 = (*(uint64_t (**)(ZinPEElementWiseLayer *, uint64_t))(*(void *)a3 + 360))(a3, 1);
  int v7 = *(_DWORD *)(*(void *)(*((void *)a3 + 63) + 64) + 12);
  float v42 = 0.0;
  ZinPEElementWiseLayer::GetOutputReductionFinalScaleValue(a3, &v42);
  if (v7 == 3) {
    float v42 = v42 / (float)(v5 * v4 * v6);
  }
  int v8 = *(_DWORD *)((*(uint64_t (**)(void, void, void))(***((void ***)a3 + 11) + 32))(**((void **)a3 + 11), 0, 0)+ 88);
  int64x2_t v39 = vdupq_n_s64(1uLL);
  int64x2_t v40 = v39;
  uint64_t v41 = 1;
  switch(*(_DWORD *)(*(void *)(*((void *)a3 + 63) + 64) + 12))
  {
    case 0:
    case 3:
      switch(v8)
      {
        case 1:
          LOBYTE(v37) = 0;
          std::vector<signed char>::vector(__p, 1uLL, &v37);
          std::allocate_shared[abi:ne180100]<ZinIrConstData_specialization<signed char>,std::allocator<ZinIrConstData_specialization<signed char>>,std::vector<signed char>,void>((uint64_t)__p, &v45);
          goto LABEL_30;
        case 2:
          goto LABEL_22;
        case 3:
          LOWORD(v44) = 0;
          std::vector<half>::vector(__p, 1, &v44);
          std::allocate_shared[abi:ne180100]<ZinIrConstData_specialization<half>,std::allocator<ZinIrConstData_specialization<half>>,std::vector<half>,void>((uint64_t)__p, &v45);
          goto LABEL_30;
        case 11:
          LODWORD(v44) = 0;
          std::vector<float>::vector(__p, 1uLL, &v44);
          std::allocate_shared[abi:ne180100]<ZinIrConstData_specialization<float>,std::allocator<ZinIrConstData_specialization<float>>,std::vector<float>,void>((uint64_t)__p, &v45);
          goto LABEL_30;
        case 12:
          LOBYTE(v37) = 0;
          std::vector<e4m3_t>::vector(__p, 1uLL, &v37);
          std::allocate_shared[abi:ne180100]<ZinIrConstData_specialization<e4m3_t>,std::allocator<ZinIrConstData_specialization<e4m3_t>>,std::vector<e4m3_t>,void>((uint64_t)__p, &v45);
          goto LABEL_30;
        default:
          BOOL v17 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
          if (v17) {
            goto LABEL_18;
          }
          goto LABEL_19;
      }
    case 1:
    case 4:
      switch(v8)
      {
        case 1:
          LOBYTE(v37) = 127;
          std::vector<signed char>::vector(__p, 1uLL, &v37);
          std::allocate_shared[abi:ne180100]<ZinIrConstData_specialization<signed char>,std::allocator<ZinIrConstData_specialization<signed char>>,std::vector<signed char>,void>((uint64_t)__p, &v45);
          goto LABEL_30;
        case 2:
          LOBYTE(v37) = -1;
          std::vector<unsigned char>::vector(__p, 1uLL, &v37);
          std::allocate_shared[abi:ne180100]<ZinIrConstData_specialization<unsigned char>,std::allocator<ZinIrConstData_specialization<unsigned char>>,std::vector<unsigned char>,void>((uint64_t)__p, &v45);
          goto LABEL_30;
        case 3:
          LOWORD(v44) = 31744;
          std::vector<half>::vector(__p, 1, &v44);
          std::allocate_shared[abi:ne180100]<ZinIrConstData_specialization<half>,std::allocator<ZinIrConstData_specialization<half>>,std::vector<half>,void>((uint64_t)__p, &v45);
          goto LABEL_30;
        case 11:
          LODWORD(v44) = 2139095040;
          std::vector<float>::vector(__p, 1uLL, &v44);
          std::allocate_shared[abi:ne180100]<ZinIrConstData_specialization<float>,std::allocator<ZinIrConstData_specialization<float>>,std::vector<float>,void>((uint64_t)__p, &v45);
          goto LABEL_30;
        case 12:
          LOBYTE(v37) = -64;
          std::vector<e4m3_t>::vector(__p, 1uLL, &v37);
          std::allocate_shared[abi:ne180100]<ZinIrConstData_specialization<e4m3_t>,std::allocator<ZinIrConstData_specialization<e4m3_t>>,std::vector<e4m3_t>,void>((uint64_t)__p, &v45);
          goto LABEL_30;
        default:
          BOOL v17 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
          if (v17) {
            goto LABEL_18;
          }
          goto LABEL_19;
      }
    case 2:
    case 5:
      switch(v8)
      {
        case 1:
          LOBYTE(v37) = 0x80;
          std::vector<signed char>::vector(__p, 1uLL, &v37);
          std::allocate_shared[abi:ne180100]<ZinIrConstData_specialization<signed char>,std::allocator<ZinIrConstData_specialization<signed char>>,std::vector<signed char>,void>((uint64_t)__p, &v45);
          break;
        case 2:
LABEL_22:
          LOBYTE(v37) = 0;
          std::vector<unsigned char>::vector(__p, 1uLL, &v37);
          std::allocate_shared[abi:ne180100]<ZinIrConstData_specialization<unsigned char>,std::allocator<ZinIrConstData_specialization<unsigned char>>,std::vector<unsigned char>,void>((uint64_t)__p, &v45);
          break;
        case 3:
          LOWORD(v44) = -1024;
          std::vector<half>::vector(__p, 1, &v44);
          std::allocate_shared[abi:ne180100]<ZinIrConstData_specialization<half>,std::allocator<ZinIrConstData_specialization<half>>,std::vector<half>,void>((uint64_t)__p, &v45);
          break;
        case 11:
          LODWORD(v44) = -8388608;
          std::vector<float>::vector(__p, 1uLL, &v44);
          std::allocate_shared[abi:ne180100]<ZinIrConstData_specialization<float>,std::allocator<ZinIrConstData_specialization<float>>,std::vector<float>,void>((uint64_t)__p, &v45);
          break;
        case 12:
          LOBYTE(v37) = 64;
          std::vector<e4m3_t>::vector(__p, 1uLL, &v37);
          std::allocate_shared[abi:ne180100]<ZinIrConstData_specialization<e4m3_t>,std::allocator<ZinIrConstData_specialization<e4m3_t>>,std::vector<e4m3_t>,void>((uint64_t)__p, &v45);
          break;
        default:
          BOOL v17 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
          if (v17) {
LABEL_18:
          }
            ZinMirPEReductionAccumulationRetention::UpdateGraphWithConst(v17, v18, v19, v20, v21, v22, v23, v24);
          goto LABEL_19;
      }
LABEL_30:
      long long v26 = v45;
      long long v45 = 0uLL;
      if (__p[0])
      {
        __p[1] = __p[0];
        long long v36 = v26;
        operator delete(__p[0]);
        long long v26 = v36;
      }
      uint64_t v25 = (std::__shared_weak_count *)*((void *)&v26 + 1);
      if ((void)v26)
      {
        long long v38 = v26;
        if (*((void *)&v26 + 1)) {
          atomic_fetch_add_explicit((atomic_ullong *volatile)(*((void *)&v26 + 1) + 8), 1uLL, memory_order_relaxed);
        }
        ZinBuilder::CreateConstLayer();
      }
      goto LABEL_36;
    case 6:
      BOOL v9 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v9) {
        ZinLogEventFlags::EventFlagsV4::GetDebugLogEventFlags(v9, v10, v11, v12, v13, v14, v15, v16);
      }
      goto LABEL_19;
    default:
LABEL_19:
      uint64_t v25 = 0;
LABEL_36:
      BOOL v27 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v27) {
        ZinMirPEReductionAccumulationRetention::UpdateGraphWithConst(v27, v28, v29, v30, v31, v32, v33, v34);
      }
      if (v25) {
        std::__shared_weak_count::__release_shared[abi:ne180100](v25);
      }
      return 3;
  }
}

void sub_2113A03DC(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, char a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,void *a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,void *a27,uint64_t a28,int a29,__int16 a30,char a31,char a32,uint64_t a33,uint64_t a34,uint64_t a35,uint64_t a36,uint64_t a37,uint64_t a38,uint64_t a39,uint64_t a40,uint64_t a41,uint64_t a42,uint64_t a43,uint64_t a44,uint64_t a45,void *__p,void *a47,uint64_t a48)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

char *std::vector<ZinIrOpLayer *>::insert(uint64_t a1, char *__src, void *a3)
{
  uint64_t v4 = __src;
  uint64_t v6 = *(char **)(a1 + 8);
  unint64_t v9 = *(void *)(a1 + 16);
  uint64_t v7 = a1 + 16;
  unint64_t v8 = v9;
  if ((unint64_t)v6 >= v9)
  {
    uint64_t v14 = *(unsigned char **)a1;
    unint64_t v15 = ((uint64_t)&v6[-*(void *)a1] >> 3) + 1;
    if (v15 >> 61) {
      std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
    }
    uint64_t v16 = (__src - v14) >> 3;
    uint64_t v17 = v8 - (void)v14;
    if (v17 >> 2 > v15) {
      unint64_t v15 = v17 >> 2;
    }
    if ((unint64_t)v17 >= 0x7FFFFFFFFFFFFFF8) {
      unint64_t v18 = 0x1FFFFFFFFFFFFFFFLL;
    }
    else {
      unint64_t v18 = v15;
    }
    uint64_t v25 = v7;
    if (v18) {
      uint64_t v19 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>(v7, v18);
    }
    else {
      uint64_t v19 = 0;
    }
    std::string __p = v19;
    uint64_t v22 = &v19[8 * v16];
    uint64_t v23 = v22;
    uint64_t v24 = &v19[8 * v18];
    std::__split_buffer<unsigned long *>::push_back(&__p, a3);
    uint64_t v4 = std::vector<ZinGOCLayer const*>::__swap_out_circular_buffer((void **)a1, (uint64_t)&__p, v4);
    if (v23 != v22) {
      v23 += (v22 - v23 + 7) & 0xFFFFFFFFFFFFFFF8;
    }
    if (__p) {
      operator delete(__p);
    }
  }
  else if (__src == v6)
  {
    *(void *)__src = *a3;
    *(void *)(a1 + 8) = __src + 8;
  }
  else
  {
    uint64_t v10 = __src + 8;
    uint64_t v11 = v6 - 8;
    uint64_t v12 = v6;
    while (v11 < v6)
    {
      uint64_t v13 = *(void *)v11;
      v11 += 8;
      *(void *)uint64_t v12 = v13;
      v12 += 8;
    }
    *(void *)(a1 + 8) = v12;
    if (v6 != v10) {
      memmove(&v6[-8 * ((v6 - v10) >> 3)], __src, v6 - v10);
    }
    *(void *)uint64_t v4 = *a3;
  }
  return v4;
}

void sub_2113A07EC(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11, uint64_t a12)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinMirPEReductionAccumulationRetention::Run(ZinMirPEReductionAccumulationRetention *this)
{
  v45[3] = *MEMORY[0x263EF8340];
  if (!*(unsigned char *)(**((void **)this + 1) + 1126)) {
    return 0;
  }
  std::string::basic_string[abi:ne180100]<0>(v37, "any");
  memset(&v39[3], 0, 40);
  int v40 = 1065353216;
  uint64_t v24 = 0;
  uint64_t v25 = 0;
  uint64_t v23 = 0;
  std::string __p = &v23;
  char v32 = 0;
  uint64_t v23 = (char *)operator new(0x60uLL);
  uint64_t v24 = (uint64_t)v23;
  uint64_t v25 = v23 + 96;
  uint64_t v24 = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<ZinLinearPattern::AtomItemDesc>,ZinLinearPattern::AtomItemDesc const*,ZinLinearPattern::AtomItemDesc const*,ZinLinearPattern::AtomItemDesc*>((uint64_t)&v25, (uint64_t)v37, (uint64_t)v41, (uint64_t)v23);
  v26[0] = &v23;
  std::string::basic_string[abi:ne180100]<0>(&__p, "pe_ew");
  v34[0] = &unk_26C380F00;
  v34[1] = MatchPEEW;
  v34[3] = v34;
  memset(v35, 0, sizeof(v35));
  int v36 = 1065353216;
  uint64_t v21 = 0;
  uint64_t v22 = 0;
  uint64_t v20 = 0;
  BOOL v27 = &v20;
  char v28 = 0;
  uint64_t v20 = (char *)operator new(0x60uLL);
  uint64_t v21 = (uint64_t)v20;
  uint64_t v22 = v20 + 96;
  uint64_t v21 = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<ZinLinearPattern::AtomItemDesc>,ZinLinearPattern::AtomItemDesc const*,ZinLinearPattern::AtomItemDesc const*,ZinLinearPattern::AtomItemDesc*>((uint64_t)&v22, (uint64_t)&__p, (uint64_t)v37, (uint64_t)v20);
  v26[1] = &v20;
  uint64_t v2 = *((void *)this + 1);
  v30[0] = &unk_26C386A70;
  v30[1] = this;
  v30[3] = v30;
  ZinOneToVariablePattern::ZinOneToVariablePattern(v41, v26, v2, 0, v30, 0);
  std::__function::__value_func<BOOL ()(ZinIrOpLayerGraph const*,ZinIrParameters const&,ZinPattern const*)>::~__value_func[abi:ne180100](v30);
  BOOL v27 = &v20;
  std::vector<ZinLinearPattern::AtomItemDesc>::__destroy_vector::operator()[abi:ne180100]((void ***)&v27);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v35);
  std::__function::__value_func<MatchStatus ()(MatchParams const&)>::~__value_func[abi:ne180100](v34);
  if (v33 < 0) {
    operator delete(__p);
  }
  std::string __p = &v23;
  std::vector<ZinLinearPattern::AtomItemDesc>::__destroy_vector::operator()[abi:ne180100]((void ***)&__p);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&v39[4]);
  std::__function::__value_func<MatchStatus ()(MatchParams const&)>::~__value_func[abi:ne180100](v39);
  uint64_t v3 = (uint64_t *)v38;
  if ((v3 & 0x80000000) != 0) {
    operator delete(v37[0]);
  }
  uint64_t v4 = *(void *)this + 8;
  uint64_t v5 = **(uint64_t ***)this;
  if (v5 == (uint64_t *)v4)
  {
LABEL_14:
    uint64_t v10 = 0;
  }
  else
  {
    while (1)
    {
      Hal = ZinIrTarget::GetHal(v3, (ZinIrTarget *)v5[4]);
      v29[0] = &unk_26C386A18;
      v29[1] = v41;
      v29[2] = this;
      v29[3] = v29;
      int v7 = ZinIrOpLayerGraph::TraverseForward((uint64_t)Hal, (uint64_t)v29, 1);
      std::__function::__value_func<ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::~__value_func[abi:ne180100](v29);
      if (v7) {
        break;
      }
      unint64_t v8 = (uint64_t *)v5[1];
      if (v8)
      {
        do
        {
          uint64_t v3 = v8;
          unint64_t v8 = (uint64_t *)*v8;
        }
        while (v8);
      }
      else
      {
        do
        {
          uint64_t v3 = (uint64_t *)v5[2];
          BOOL v9 = *v3 == (void)v5;
          uint64_t v5 = v3;
        }
        while (!v9);
      }
      uint64_t v5 = v3;
      if (v3 == (uint64_t *)v4) {
        goto LABEL_14;
      }
    }
    BOOL v11 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (v11) {
      ZinMirPEReductionAccumulationRetention::Run(v11, v12, v13, v14, v15, v16, v17, v18);
    }
    uint64_t v10 = 3;
  }
  v41[0] = &unk_26C350430;
  v37[0] = v45;
  std::vector<ZinLinearPattern>::__destroy_vector::operator()[abi:ne180100]((void ***)v37);
  uint64_t v43 = &unk_26C349BA8;
  v37[0] = &v44;
  std::vector<ZinLinearPattern::AtomItemDesc>::__destroy_vector::operator()[abi:ne180100]((void ***)v37);
  ZinPattern::~ZinPattern((ZinPattern *)&v43);
  v37[0] = &v42;
  std::vector<ZinLinearPattern::AtomItemDesc>::__destroy_vector::operator()[abi:ne180100]((void ***)v37);
  ZinPattern::~ZinPattern((ZinPattern *)v41);
  return v10;
}

void sub_2113A0BB8(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, char a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, char a19, uint64_t a20,uint64_t a21,uint64_t a22,char a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33,uint64_t a34,uint64_t a35,uint64_t a36,uint64_t a37,uint64_t a38,char a39,uint64_t a40,uint64_t a41,uint64_t a42,uint64_t a43,uint64_t a44,uint64_t a45,uint64_t a46,uint64_t a47,uint64_t a48,uint64_t a49,uint64_t a50,char a51)
{
}

void std::__function::__func<ZinMirPEReductionAccumulationRetention::Run(void)::$_1,std::allocator<ZinMirPEReductionAccumulationRetention::Run(void)::$_1>,BOOL ()(ZinIrOpLayerGraph const*,ZinIrParameters const&,ZinPattern const*)>::~__func()
{
}

void *std::__function::__func<ZinMirPEReductionAccumulationRetention::Run(void)::$_1,std::allocator<ZinMirPEReductionAccumulationRetention::Run(void)::$_1>,BOOL ()(ZinIrOpLayerGraph const*,ZinIrParameters const&,ZinPattern const*)>::__clone(uint64_t a1)
{
  __n128 result = operator new(0x10uLL);
  uint64_t v3 = *(void *)(a1 + 8);
  *__n128 result = &unk_26C386A70;
  result[1] = v3;
  return result;
}

uint64_t std::__function::__func<ZinMirPEReductionAccumulationRetention::Run(void)::$_1,std::allocator<ZinMirPEReductionAccumulationRetention::Run(void)::$_1>,BOOL ()(ZinIrOpLayerGraph const*,ZinIrParameters const&,ZinPattern const*)>::__clone(uint64_t result, void *a2)
{
  uint64_t v2 = *(void *)(result + 8);
  *a2 = &unk_26C386A70;
  a2[1] = v2;
  return result;
}

uint64_t std::__function::__func<ZinMirPEReductionAccumulationRetention::Run(void)::$_1,std::allocator<ZinMirPEReductionAccumulationRetention::Run(void)::$_1>,BOOL ()(ZinIrOpLayerGraph const*,ZinIrParameters const&,ZinPattern const*)>::operator()(uint64_t a1, uint64_t a2, uint64_t a3, ZinPattern **a4)
{
  uint64_t v4 = *a4;
  uint64_t v58 = *(void *)(a1 + 8);
  if (ZinPattern::MatchCount(*a4))
  {
    std::string::basic_string[abi:ne180100]<0>(&__p, "pe_ew");
    ZinPattern::GetMatch((uint64_t)v4, (unsigned __int8 *)&__p, &v62);
    if (SHIBYTE(v61) < 0) {
      operator delete(__p);
    }
    uint64_t v5 = v62;
    uint64_t v6 = v63;
    if (v62 == v63) {
      goto LABEL_10;
    }
    uint64_t v7 = 0;
    unint64_t v8 = v62;
    do
    {
      if (!*v8++) {
        ++v7;
      }
    }
    while (v8 != v63);
    if ((unint64_t)(v63 - v62 - v7) < 2)
    {
LABEL_10:
      char v10 = 0;
      if (!v62) {
        return v10 & 1;
      }
      goto LABEL_95;
    }
    char v10 = 0;
    do
    {
      BOOL v11 = (void *)*v5;
      if (*v5)
      {
        uint64_t v12 = *(char ***)(v58 + 64);
        uint64_t v13 = *(char ***)(v58 + 72);
        while (v12 != v13)
        {
          uint64_t v14 = *(void **)*v12;
          uint64_t v15 = *(void *)(v14[63] + 64);
          uint64_t v16 = *(void *)(v11[63] + 64);
          int v17 = *(_DWORD *)(v15 + 12);
          int v18 = *(_DWORD *)(v16 + 12);
          if (v17 == v18
            || (v17 == 5 ? (BOOL v19 = v18 == 2) : (BOOL v19 = 0),
                v19
             || (v17 == 4 ? (BOOL v20 = v18 == 1) : (BOOL v20 = 0),
                 v20 || (v17 == 2 ? (v21 = v18 == 5) : (v21 = 0), v21 || (v17 == 1 ? (BOOL v22 = v18 == 4) : (BOOL v22 = 0), v22)))))
          {
            uint64_t v23 = (*(uint64_t (**)(void))(*v14 + 624))(*(void *)*v12);
            uint64_t v24 = (*(uint64_t (**)(void *))(*v11 + 624))(v11);
            if (!(v23 | v24)
              || (v23 ? (BOOL v41 = v24 == 0) : (BOOL v41 = 1), !v41 && ZinIrActivationParams::operator==(v23 + 192, v24 + 192)))
            {
              uint64_t v25 = (*(uint64_t (**)(void *))(*v14 + 632))(v14);
              uint64_t v26 = (*(uint64_t (**)(void *))(*v11 + 632))(v11);
              if (!(v25 | v26)
                || (v25 ? (BOOL v42 = v26 == 0) : (BOOL v42 = 1), !v42 && ZinIrActivationParams::operator==(v25 + 192, v26 + 192)))
              {
                uint64_t v27 = (*(uint64_t (**)(void *))(*v14 + 712))(v14);
                uint64_t v28 = (*(uint64_t (**)(void *))(*v11 + 712))(v11);
                if (IsLayerInfoEqual<ZinTransposeLayer,ZinIrTransposeInfo>(v27, v28))
                {
                  uint64_t v29 = (*(uint64_t (**)(void *))(*v14 + 720))(v14);
                  uint64_t v30 = (*(uint64_t (**)(void *))(*v11 + 720))(v11);
                  if (IsLayerInfoEqual<ZinTransposeLayer,ZinIrTransposeInfo>(v29, v30))
                  {
                    uint64_t v31 = (*(uint64_t (**)(void *))(*v14 + 696))(v14);
                    uint64_t v32 = (*(uint64_t (**)(void *))(*v11 + 696))(v11);
                    if (IsLayerInfoEqual<ZinBroadcastLayer,ZinIrBroadcastInfo>(v31, v32))
                    {
                      uint64_t v33 = (*(uint64_t (**)(void *))(*v14 + 704))(v14);
                      uint64_t v34 = (*(uint64_t (**)(void *))(*v11 + 704))(v11);
                      if (IsLayerInfoEqual<ZinBroadcastLayer,ZinIrBroadcastInfo>(v33, v34))
                      {
                        uint64_t v35 = v14[60];
                        uint64_t v36 = v11[60];
                        if (!(v35 | v36)
                          || v35 && v36 && ZinIrScaledEWInfo::operator==(*(void *)(v35 + 64), *(void *)(v36 + 64)))
                        {
                          uint64_t v37 = (*(uint64_t (**)(void *))(*v14 + 808))(v14);
                          uint64_t v38 = (*(uint64_t (**)(void *))(*v11 + 808))(v11);
                          if (!(v37 | v38)
                            || v37
                            && v38
                            && *(_DWORD *)(*(void *)(v37 + 64) + 12) == *(_DWORD *)(*(void *)(v38 + 64) + 12))
                          {
                            uint64_t v39 = (*(uint64_t (**)(void *))(*v14 + 816))(v14);
                            uint64_t v40 = (*(uint64_t (**)(void *))(*v11 + 816))(v11);
                            if (!(v39 | v40) || v39 && v40 && ZinIrActivationParams::operator==(v39 + 192, v40 + 192))
                            {
                              std::string __p = *(void **)(v15 + 24);
                              uint64_t v64 = *(void *)(v16 + 24);
                              if (std::__equal_aligned[abi:ne180100]<std::__bitset<1ul,5ul>,true,true>(&__p, 0, (uint64_t)&__p, 5u, &v64))
                              {
                                long long v45 = v12[2];
                                uint64_t v46 = v12[1];
                                if (v46 >= v45)
                                {
                                  uint64_t v47 = (v46 - *v12) >> 3;
                                  unint64_t v48 = v47 + 1;
                                  if ((unint64_t)(v47 + 1) >> 61) {
                                    std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
                                  }
                                  uint64_t v49 = v45 - *v12;
                                  if (v49 >> 2 > v48) {
                                    unint64_t v48 = v49 >> 2;
                                  }
                                  if ((unint64_t)v49 >= 0x7FFFFFFFFFFFFFF8) {
                                    unint64_t v50 = 0x1FFFFFFFFFFFFFFFLL;
                                  }
                                  else {
                                    unint64_t v50 = v48;
                                  }
                                  if (v50) {
                                    uint64_t v51 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)(v12 + 2), v50);
                                  }
                                  else {
                                    uint64_t v51 = 0;
                                  }
                                  uint64_t v52 = &v51[8 * v47];
                                  *(void *)uint64_t v52 = v11;
                                  uint64_t v53 = v52 + 8;
                                  long long v55 = *v12;
                                  long long v54 = v12[1];
                                  if (v54 != *v12)
                                  {
                                    do
                                    {
                                      uint64_t v56 = *((void *)v54 - 1);
                                      v54 -= 8;
                                      *((void *)v52 - 1) = v56;
                                      v52 -= 8;
                                    }
                                    while (v54 != v55);
                                    long long v54 = *v12;
                                  }
                                  *uint64_t v12 = v52;
                                  v12[1] = v53;
                                  _OWORD v12[2] = &v51[8 * v50];
                                  if (v54) {
                                    operator delete(v54);
                                  }
                                  v12[1] = v53;
                                }
                                else
                                {
                                  *(void *)uint64_t v46 = v11;
                                  v12[1] = v46 + 8;
                                }
                                char v44 = 1;
                                goto LABEL_73;
                              }
                            }
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          }
          v12 += 3;
        }
        uint64_t v43 = operator new(8uLL);
        std::string __p = v43;
        *uint64_t v43 = v11;
        int v60 = v43 + 1;
        std::string::size_type v61 = v43 + 1;
        std::vector<std::vector<ZinPEElementWiseLayer *>>::push_back[abi:ne180100]((uint64_t *)(v58 + 64), (uint64_t)&__p);
        if (__p)
        {
          int v60 = __p;
          operator delete(__p);
        }
        char v44 = 0;
LABEL_73:
        v10 |= v44;
      }
      ++v5;
    }
    while (v5 != v6);
    uint64_t v5 = v62;
    if (v62)
    {
LABEL_95:
      unint64_t v63 = v5;
      operator delete(v5);
    }
  }
  else
  {
    char v10 = 0;
  }
  return v10 & 1;
}

void sub_2113A14E8(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, void *a12, uint64_t a13, int a14, __int16 a15, char a16, char a17, void *__p, uint64_t a19)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t std::__function::__func<ZinMirPEReductionAccumulationRetention::Run(void)::$_1,std::allocator<ZinMirPEReductionAccumulationRetention::Run(void)::$_1>,BOOL ()(ZinIrOpLayerGraph const*,ZinIrParameters const&,ZinPattern const*)>::target(uint64_t a1, uint64_t a2)
{
  {
    return a1 + 8;
  }
  else
  {
    return 0;
  }
}

void *std::__function::__func<ZinMirPEReductionAccumulationRetention::Run(void)::$_1,std::allocator<ZinMirPEReductionAccumulationRetention::Run(void)::$_1>,BOOL ()(ZinIrOpLayerGraph const*,ZinIrParameters const&,ZinPattern const*)>::target_type()
{
}

uint64_t std::vector<std::vector<ZinPEElementWiseLayer *>>::push_back[abi:ne180100](uint64_t *a1, uint64_t a2)
{
  unint64_t v6 = a1[2];
  uint64_t result = (uint64_t)(a1 + 2);
  unint64_t v5 = v6;
  uint64_t v7 = *(void **)(result - 8);
  if ((unint64_t)v7 >= v6)
  {
    unint64_t v9 = 0xAAAAAAAAAAAAAAABLL * (((uint64_t)v7 - *a1) >> 3);
    unint64_t v10 = v9 + 1;
    if (v9 + 1 > 0xAAAAAAAAAAAAAAALL) {
      std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
    }
    unint64_t v11 = 0xAAAAAAAAAAAAAAABLL * ((uint64_t)(v5 - *a1) >> 3);
    if (2 * v11 > v10) {
      unint64_t v10 = 2 * v11;
    }
    if (v11 >= 0x555555555555555) {
      unint64_t v12 = 0xAAAAAAAAAAAAAAALL;
    }
    else {
      unint64_t v12 = v10;
    }
    void v16[4] = result;
    uint64_t v13 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<std::string>>(result, v12);
    uint64_t v14 = &v13[24 * v9];
    v16[0] = v13;
    v16[1] = v14;
    v16[3] = &v13[24 * v15];
    *((void *)v14 + 1) = 0;
    *((void *)v14 + 2) = 0;
    *(void *)uint64_t v14 = 0;
    *(_OWORD *)uint64_t v14 = *(_OWORD *)a2;
    *((void *)v14 + 2) = *(void *)(a2 + 16);
    *(void *)a2 = 0;
    *(void *)(a2 + 8) = 0;
    *(void *)(a2 + 16) = 0;
    v16[2] = v14 + 24;
    std::vector<std::vector<ZinPEElementWiseLayer *>>::__swap_out_circular_buffer(a1, v16);
    unint64_t v8 = (void *)a1[1];
    uint64_t result = std::__split_buffer<std::vector<ZinIrOpLayer *>>::~__split_buffer((uint64_t)v16);
  }
  else
  {
    void *v7 = 0;
    v7[1] = 0;
    _OWORD v7[2] = 0;
    *(_OWORD *)uint64_t v7 = *(_OWORD *)a2;
    _OWORD v7[2] = *(void *)(a2 + 16);
    *(void *)a2 = 0;
    *(void *)(a2 + 8) = 0;
    *(void *)(a2 + 16) = 0;
    unint64_t v8 = v7 + 3;
    a1[1] = (uint64_t)(v7 + 3);
  }
  a1[1] = (uint64_t)v8;
  return result;
}

void sub_2113A16B8(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::__split_buffer<std::vector<ZinIrOpLayer *>>::~__split_buffer((uint64_t)va);
  _Unwind_Resume(a1);
}

BOOL IsLayerInfoEqual<ZinTransposeLayer,ZinIrTransposeInfo>(uint64_t a1, uint64_t a2)
{
  if (!(a1 | a2)) {
    return 1;
  }
  BOOL result = 0;
  if (a1)
  {
    if (a2) {
      return ZinIrTransposeInfo::operator==(*(void *)(a1 + 64), *(void *)(a2 + 64));
    }
  }
  return result;
}

BOOL IsLayerInfoEqual<ZinBroadcastLayer,ZinIrBroadcastInfo>(uint64_t a1, uint64_t a2)
{
  if (!(a1 | a2)) {
    return 1;
  }
  BOOL result = 0;
  if (a1)
  {
    if (a2) {
      return std::operator==[abi:ne180100]<ZinIrDimension,unsigned long,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,std::allocator<std::pair<ZinIrDimension const,unsigned long>>>(*(void *)(a1 + 64) + 16, (void *)(*(void *)(a2 + 64) + 16));
    }
  }
  return result;
}

BOOL std::operator==[abi:ne180100]<ZinIrDimension,unsigned long,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,std::allocator<std::pair<ZinIrDimension const,unsigned long>>>(uint64_t a1, void *a2)
{
  if (*(void *)(a1 + 24) != a2[3]) {
    return 0;
  }
  uint64_t v3 = (int *)(a1 + 16);
  do
  {
    uint64_t v3 = *(int **)v3;
    BOOL v4 = v3 == 0;
    if (!v3) {
      break;
    }
    unint64_t v5 = std::__hash_table<ZinIrDimension,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,std::allocator<ZinIrDimension>>::find<ZinIrDimension>(a2, v3 + 4);
    if (!v5) {
      break;
    }
  }
  while (v3[4] == *((_DWORD *)v5 + 4) && *((void *)v3 + 3) == v5[3]);
  return v4;
}

BOOL ZinIrScaledEWInfo::operator==(uint64_t a1, uint64_t a2)
{
  return *(float *)(a1 + 16) == *(float *)(a2 + 16)
      && *(float *)(a1 + 20) == *(float *)(a2 + 20)
      && *(float *)(a1 + 24) == *(float *)(a2 + 24)
      && *(unsigned __int8 *)(a1 + 28) == *(unsigned __int8 *)(a2 + 28)
      && *(unsigned __int8 *)(a1 + 29) == *(unsigned __int8 *)(a2 + 29)
      && *(_DWORD *)(a1 + 12) == *(_DWORD *)(a2 + 12);
}

uint64_t std::vector<std::vector<ZinPEElementWiseLayer *>>::__swap_out_circular_buffer(uint64_t *a1, void *a2)
{
  uint64_t result = std::__uninitialized_allocator_move_if_noexcept[abi:ne180100]<std::allocator<std::vector<ZinPEElementWiseLayer *>>,std::reverse_iterator<std::vector<ZinPEElementWiseLayer *>*>,std::reverse_iterator<std::vector<ZinPEElementWiseLayer *>*>,std::reverse_iterator<std::vector<ZinPEElementWiseLayer *>*>>((uint64_t)(a1 + 2), a1[1], (void *)a1[1], *a1, (void *)*a1, a2[1], a2[1]);
  a2[1] = v5;
  uint64_t v6 = *a1;
  *a1 = v5;
  a2[1] = v6;
  uint64_t v7 = a1[1];
  a1[1] = a2[2];
  a2[2] = v7;
  uint64_t v8 = a1[2];
  a1[2] = a2[3];
  a2[3] = v8;
  *a2 = a2[1];
  return result;
}

uint64_t std::__uninitialized_allocator_move_if_noexcept[abi:ne180100]<std::allocator<std::vector<ZinPEElementWiseLayer *>>,std::reverse_iterator<std::vector<ZinPEElementWiseLayer *>*>,std::reverse_iterator<std::vector<ZinPEElementWiseLayer *>*>,std::reverse_iterator<std::vector<ZinPEElementWiseLayer *>*>>(uint64_t a1, uint64_t a2, void *a3, uint64_t a4, void *a5, uint64_t a6, uint64_t a7)
{
  uint64_t v7 = a7;
  *(void *)&long long v14 = a6;
  *((void *)&v14 + 1) = a7;
  long long v13 = v14;
  v11[0] = a1;
  v11[1] = &v13;
  uint64_t v11[2] = &v14;
  if (a3 == a5)
  {
    uint64_t v9 = a6;
  }
  else
  {
    do
    {
      *(void *)(v7 - 24) = 0;
      *(void *)(v7 - 16) = 0;
      *(void *)(v7 - 8) = 0;
      long long v8 = *(_OWORD *)(a3 - 3);
      a3 -= 3;
      *(_OWORD *)(v7 - 24) = v8;
      *(void *)(v7 - 8) = a3[2];
      *a3 = 0;
      a3[1] = 0;
      a3[2] = 0;
      uint64_t v7 = *((void *)&v14 + 1) - 24;
      *((void *)&v14 + 1) -= 24;
    }
    while (a3 != a5);
    uint64_t v9 = v14;
  }
  char v12 = 1;
  std::__exception_guard_exceptions<std::_AllocatorDestroyRangeReverse<std::allocator<std::vector<ZinPEElementWiseLayer *>>,std::reverse_iterator<std::vector<ZinPEElementWiseLayer *>*>>>::~__exception_guard_exceptions[abi:ne180100]((uint64_t)v11);
  return v9;
}

uint64_t std::__exception_guard_exceptions<std::_AllocatorDestroyRangeReverse<std::allocator<std::vector<ZinPEElementWiseLayer *>>,std::reverse_iterator<std::vector<ZinPEElementWiseLayer *>*>>>::~__exception_guard_exceptions[abi:ne180100](uint64_t a1)
{
  if (!*(unsigned char *)(a1 + 24)) {
    std::_AllocatorDestroyRangeReverse<std::allocator<std::vector<ZinIrOpLayer *>>,std::reverse_iterator<std::vector<ZinIrOpLayer *>*>>::operator()[abi:ne180100](a1);
  }
  return a1;
}

void std::__function::__func<ZinMirPEReductionAccumulationRetention::Run(void)::$_0,std::allocator<ZinMirPEReductionAccumulationRetention::Run(void)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::~__func()
{
}

__n128 std::__function::__func<ZinMirPEReductionAccumulationRetention::Run(void)::$_0,std::allocator<ZinMirPEReductionAccumulationRetention::Run(void)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::__clone(uint64_t a1)
{
  uint64_t v2 = (char *)operator new(0x18uLL);
  *(void *)uint64_t v2 = &unk_26C386A18;
  __n128 result = *(__n128 *)(a1 + 8);
  *(__n128 *)(v2 + 8) = result;
  return result;
}

__n128 std::__function::__func<ZinMirPEReductionAccumulationRetention::Run(void)::$_0,std::allocator<ZinMirPEReductionAccumulationRetention::Run(void)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::__clone(uint64_t a1, uint64_t a2)
{
  *(void *)a2 = &unk_26C386A18;
  __n128 result = *(__n128 *)(a1 + 8);
  *(__n128 *)(a2 + 8) = result;
  return result;
}

uint64_t std::__function::__func<ZinMirPEReductionAccumulationRetention::Run(void)::$_0,std::allocator<ZinMirPEReductionAccumulationRetention::Run(void)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::operator()(uint64_t a1, const ZinIrOpLayerGraph **a2, ZinIrOpLayer **a3)
{
  uint64_t v3 = *a2;
  BOOL v4 = *(uint64_t **)(a1 + 16);
  uint64_t result = ZinOneToVariablePattern::Match(*(ZinOneToVariablePattern **)(a1 + 8), *a2, *a3);
  if (!result) {
    return result;
  }
  uint64_t v6 = (uint64_t *)v4[8];
  uint64_t v7 = (uint64_t *)v4[9];
  if (v6 == v7)
  {
LABEL_16:
    std::vector<std::vector<ZinIrOpLayer *>>::__clear[abi:ne180100](v4 + 8);
    return 0;
  }
  while (1)
  {
    long long v8 = (uint64_t *)v6[1];
    if ((uint64_t *)*v6 != v8)
    {
      std::__introsort<std::_ClassicAlgPolicy,ZinMirPEReductionAccumulationRetention::Run(void)::$_0::operator() const(ZinIrOpLayerGraph *,ZinIrOpLayer *)::{lambda(ZinPEElementWiseLayer *,ZinPEElementWiseLayer *)#1} &,ZinPEElementWiseLayer **,false>(*v6, v8, 126 - 2 * __clz(((uint64_t)v8 - *v6) >> 3), 1);
      uint64_t v9 = *v6;
      if (v6[1] - *v6 != 8) {
        break;
      }
    }
LABEL_15:
    v6 += 3;
    if (v6 == v7) {
      goto LABEL_16;
    }
  }
  unint64_t v10 = 0;
  BOOL v11 = 0;
  do
  {
    char v12 = (ZinPEElementWiseLayer **)(v9 + 8 * v10);
    long long v13 = *v12;
    uint64_t v14 = *((void *)*v12 + 45);
    uint64_t v15 = *((void *)v12[1] + 45) - 1;
    if (v14 == v15)
    {
      uint64_t v16 = *(void *)(*((void *)v13 + 63) + 64);
      *(_DWORD *)(v16 + 4std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 1;
      if (!v11) {
        goto LABEL_12;
      }
    }
    else
    {
      if (!v11) {
        goto LABEL_12;
      }
      uint64_t v16 = *(void *)(*((void *)v13 + 63) + 64);
    }
    *(_DWORD *)(v16 + 44) = 1;
    uint64_t result = ZinMirPEReductionAccumulationRetention::UpdateGraphWithConst((ZinMirPEReductionAccumulationRetention *)v4, v3, v13);
    if (result) {
      return result;
    }
LABEL_12:
    ++v10;
    uint64_t v9 = *v6;
    unint64_t v17 = ((v6[1] - *v6) >> 3) - 1;
    BOOL v11 = v14 == v15;
  }
  while (v10 < v17);
  if (v14 != v15) {
    goto LABEL_15;
  }
  int v18 = *(ZinPEElementWiseLayer **)(v9 + 8 * v17);
  *(_DWORD *)(*(void *)(*((void *)v18 + 63) + 64) + 44) = 1;
  uint64_t result = ZinMirPEReductionAccumulationRetention::UpdateGraphWithConst((ZinMirPEReductionAccumulationRetention *)v4, v3, v18);
  if (!result) {
    goto LABEL_15;
  }
  return result;
}

uint64_t std::__function::__func<ZinMirPEReductionAccumulationRetention::Run(void)::$_0,std::allocator<ZinMirPEReductionAccumulationRetention::Run(void)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::target(uint64_t a1, uint64_t a2)
{
  {
    return a1 + 8;
  }
  else
  {
    return 0;
  }
}

void *std::__function::__func<ZinMirPEReductionAccumulationRetention::Run(void)::$_0,std::allocator<ZinMirPEReductionAccumulationRetention::Run(void)::$_0>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::target_type()
{
}

uint64_t std::__introsort<std::_ClassicAlgPolicy,ZinMirPEReductionAccumulationRetention::Run(void)::$_0::operator() const(ZinIrOpLayerGraph *,ZinIrOpLayer *)::{lambda(ZinPEElementWiseLayer *,ZinPEElementWiseLayer *)#1} &,ZinPEElementWiseLayer **,false>(uint64_t result, uint64_t *a2, uint64_t a3, char a4)
{
  uint64_t v9 = (uint64_t *)result;
  while (2)
  {
    unint64_t v10 = v9;
    while (1)
    {
      while (1)
      {
        while (1)
        {
          uint64_t v9 = v10;
          uint64_t v11 = (char *)a2 - (char *)v10;
          unint64_t v12 = a2 - v10;
          if (v5 || !v4)
          {
            switch(v12)
            {
              case 0uLL:
              case 1uLL:
                return result;
              case 2uLL:
                uint64_t v40 = *(a2 - 1);
                uint64_t v41 = *v10;
                if (*(void *)(v40 + 48) < *(void *)(*v10 + 48))
                {
                  *unint64_t v10 = v40;
                  *(a2 - 1) = v41;
                }
                break;
              case 3uLL:
                uint64_t result = (uint64_t)std::__sort3[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirSpatialSplitUtils::ComputeScheduleAndTensorResidency(ZinIrControlFlowGraph *,ZinIrParameters const&,SplitConfiguration &)::$_0 &,ZinIrOpLayer **>(v10, v10 + 1, a2 - 1);
                break;
              case 4uLL:
                uint64_t result = (uint64_t)std::__sort4[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirSpatialSplitUtils::ComputeScheduleAndTensorResidency(ZinIrControlFlowGraph *,ZinIrParameters const&,SplitConfiguration &)::$_0 &,ZinIrOpLayer **>(v10, v10 + 1, v10 + 2, a2 - 1);
                break;
              case 5uLL:
                BOOL v42 = v10 + 1;
                uint64_t v43 = v10 + 2;
                char v44 = v10 + 3;
                uint64_t result = (uint64_t)std::__sort4[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirSpatialSplitUtils::ComputeScheduleAndTensorResidency(ZinIrControlFlowGraph *,ZinIrParameters const&,SplitConfiguration &)::$_0 &,ZinIrOpLayer **>(v10, v10 + 1, v10 + 2, v10 + 3);
                uint64_t v45 = *(a2 - 1);
                uint64_t v46 = v10[3];
                if (*(void *)(v45 + 48) < *(void *)(v46 + 48))
                {
                  *char v44 = v45;
                  *(a2 - 1) = v46;
                  uint64_t v47 = *v44;
                  uint64_t v48 = *v43;
                  uint64_t v49 = *(void *)(*v44 + 48);
                  if (v49 < *(void *)(*v43 + 48))
                  {
                    *uint64_t v43 = v47;
                    *char v44 = v48;
                    uint64_t v50 = *v42;
                    if (v49 < *(void *)(*v42 + 48))
                    {
                      v10[1] = v47;
                      uint64_t v10[2] = v50;
                      uint64_t v51 = *v10;
                      if (v49 < *(void *)(*v10 + 48))
                      {
                        *unint64_t v10 = v47;
                        v10[1] = v51;
                      }
                    }
                  }
                }
                break;
              default:
                JUMPOUT(0);
            }
            return result;
          }
          if (v11 <= 191)
          {
            uint64_t v52 = v10 + 1;
            BOOL v54 = v10 == a2 || v52 == a2;
            if (a4)
            {
              if (!v54)
              {
                uint64_t v55 = 0;
                uint64_t v56 = v10;
                do
                {
                  uint64_t v58 = *v56;
                  uint64_t v57 = v56[1];
                  uint64_t v56 = v52;
                  uint64_t v59 = *(void *)(v57 + 48);
                  if (v59 < *(void *)(v58 + 48))
                  {
                    uint64_t v60 = v55;
                    while (1)
                    {
                      *(uint64_t *)((char *)v10 + v60 + 8) = v58;
                      if (!v60) {
                        break;
                      }
                      uint64_t v58 = *(uint64_t *)((char *)v10 + v60 - 8);
                      v60 -= 8;
                      if (v59 >= *(void *)(v58 + 48))
                      {
                        std::string::size_type v61 = (uint64_t *)((char *)v10 + v60 + 8);
                        goto LABEL_85;
                      }
                    }
                    std::string::size_type v61 = v10;
LABEL_85:
                    *std::string::size_type v61 = v57;
                  }
                  uint64_t v52 = v56 + 1;
                  v55 += 8;
                }
                while (v56 + 1 != a2);
              }
            }
            else if (!v54)
            {
              do
              {
                uint64_t v92 = *v9;
                uint64_t v91 = v9[1];
                uint64_t v9 = v52;
                uint64_t v93 = *(void *)(v91 + 48);
                if (v93 < *(void *)(v92 + 48))
                {
                  do
                  {
                    *uint64_t v52 = v92;
                    uint64_t v92 = *(v52 - 2);
                    --v52;
                  }
                  while (v93 < *(void *)(v92 + 48));
                  *uint64_t v52 = v91;
                }
                uint64_t v52 = v9 + 1;
              }
              while (v9 + 1 != a2);
            }
            return result;
          }
          if (!a3)
          {
            if (v10 != a2)
            {
              int64_t v62 = (v12 - 2) >> 1;
              int64_t v63 = v62;
              do
              {
                int64_t v64 = v63;
                if (v62 >= v63)
                {
                  uint64_t v65 = (2 * v63) | 1;
                  uint64_t v66 = &v10[v65];
                  uint64_t v67 = *v66;
                  if (2 * v64 + 2 < (uint64_t)v12)
                  {
                    uint64_t result = *(void *)(v67 + 48);
                    if (result < *(void *)(v66[1] + 48))
                    {
                      uint64_t v67 = v66[1];
                      ++v66;
                      uint64_t v65 = 2 * v64 + 2;
                    }
                  }
                  uint64_t v68 = &v10[v64];
                  uint64_t v69 = *v68;
                  uint64_t v70 = *(void *)(*v68 + 48);
                  if (*(void *)(v67 + 48) >= v70)
                  {
                    do
                    {
                      std::string::size_type v71 = v66;
                      *uint64_t v68 = v67;
                      if (v62 < v65) {
                        break;
                      }
                      uint64_t result = (2 * v65) | 1;
                      uint64_t v66 = &v10[result];
                      uint64_t v72 = 2 * v65 + 2;
                      uint64_t v67 = *v66;
                      if (v72 < (uint64_t)v12 && *(void *)(v67 + 48) < *(void *)(v66[1] + 48))
                      {
                        uint64_t v67 = v66[1];
                        ++v66;
                        uint64_t result = v72;
                      }
                      uint64_t v68 = v71;
                      uint64_t v65 = result;
                    }
                    while (*(void *)(v67 + 48) >= v70);
                    *std::string::size_type v71 = v69;
                  }
                }
                int64_t v63 = v64 - 1;
              }
              while (v64);
              uint64_t v73 = (unint64_t)v11 >> 3;
              do
              {
                uint64_t v74 = 0;
                uint64_t v75 = *v10;
                uint64_t v76 = v10;
                do
                {
                  std::string v77 = &v76[v74];
                  uint64_t v80 = v77[1];
                  std::string v78 = v77 + 1;
                  uint64_t v79 = v80;
                  uint64_t v81 = (2 * v74) | 1;
                  uint64_t v82 = 2 * v74 + 2;
                  if (v82 < v73)
                  {
                    uint64_t result = *(void *)(v79 + 48);
                    if (result < *(void *)(v78[1] + 48))
                    {
                      uint64_t v79 = v78[1];
                      ++v78;
                      uint64_t v81 = v82;
                    }
                  }
                  *uint64_t v76 = v79;
                  uint64_t v76 = v78;
                  uint64_t v74 = v81;
                }
                while (v81 <= (uint64_t)((unint64_t)(v73 - 2) >> 1));
                if (v78 == --a2)
                {
                  *std::string v78 = v75;
                }
                else
                {
                  *std::string v78 = *a2;
                  *a2 = v75;
                  uint64_t v83 = (char *)v78 - (char *)v10 + 8;
                  if (v83 >= 9)
                  {
                    unint64_t v84 = (((unint64_t)v83 >> 3) - 2) >> 1;
                    uint64_t v85 = &v10[v84];
                    uint64_t v86 = *v85;
                    uint64_t v87 = *v78;
                    uint64_t v88 = *(void *)(*v78 + 48);
                    if (*(void *)(*v85 + 48) < v88)
                    {
                      do
                      {
                        uint64_t v89 = v85;
                        *std::string v78 = v86;
                        if (!v84) {
                          break;
                        }
                        unint64_t v84 = (v84 - 1) >> 1;
                        uint64_t v85 = &v10[v84];
                        uint64_t v86 = *v85;
                        std::string v78 = v89;
                      }
                      while (*(void *)(*v85 + 48) < v88);
                      *uint64_t v89 = v87;
                    }
                  }
                }
              }
              while (v73-- > 2);
            }
            return result;
          }
          unint64_t v13 = v12 >> 1;
          uint64_t v14 = &v10[v12 >> 1];
          if ((unint64_t)v11 >= 0x401)
          {
            std::__sort3[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirSpatialSplitUtils::ComputeScheduleAndTensorResidency(ZinIrControlFlowGraph *,ZinIrParameters const&,SplitConfiguration &)::$_0 &,ZinIrOpLayer **>(v9, &v9[v12 >> 1], a2 - 1);
            std::__sort3[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirSpatialSplitUtils::ComputeScheduleAndTensorResidency(ZinIrControlFlowGraph *,ZinIrParameters const&,SplitConfiguration &)::$_0 &,ZinIrOpLayer **>(v9 + 1, v14 - 1, a2 - 2);
            std::__sort3[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirSpatialSplitUtils::ComputeScheduleAndTensorResidency(ZinIrControlFlowGraph *,ZinIrParameters const&,SplitConfiguration &)::$_0 &,ZinIrOpLayer **>(v9 + 2, &v9[v13 + 1], a2 - 3);
            uint64_t result = (uint64_t)std::__sort3[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirSpatialSplitUtils::ComputeScheduleAndTensorResidency(ZinIrControlFlowGraph *,ZinIrParameters const&,SplitConfiguration &)::$_0 &,ZinIrOpLayer **>(v14 - 1, v14, &v9[v13 + 1]);
            uint64_t v15 = *v9;
            *uint64_t v9 = *v14;
            *uint64_t v14 = v15;
          }
          else
          {
            uint64_t result = (uint64_t)std::__sort3[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirSpatialSplitUtils::ComputeScheduleAndTensorResidency(ZinIrControlFlowGraph *,ZinIrParameters const&,SplitConfiguration &)::$_0 &,ZinIrOpLayer **>(&v9[v12 >> 1], v9, a2 - 1);
          }
          --a3;
          uint64_t v16 = *v9;
          if (a4) {
            break;
          }
          uint64_t v17 = *(void *)(v16 + 48);
          if (*(void *)(*(v9 - 1) + 48) < v17) {
            goto LABEL_13;
          }
          if (v17 >= *(void *)(*(a2 - 1) + 48))
          {
            uint64_t v32 = v9 + 1;
            do
            {
              unint64_t v10 = v32;
              if (v32 >= a2) {
                break;
              }
              ++v32;
            }
            while (v17 >= *(void *)(*v10 + 48));
          }
          else
          {
            unint64_t v10 = v9;
            do
            {
              uint64_t v31 = v10[1];
              ++v10;
            }
            while (v17 >= *(void *)(v31 + 48));
          }
          uint64_t v33 = a2;
          if (v10 < a2)
          {
            uint64_t v33 = a2;
            do
              uint64_t v34 = *--v33;
            while (v17 < *(void *)(v34 + 48));
          }
          if (v10 < v33)
          {
            uint64_t v35 = *v10;
            uint64_t v36 = *v33;
            do
            {
              *unint64_t v10 = v36;
              *uint64_t v33 = v35;
              do
              {
                uint64_t v37 = v10[1];
                ++v10;
                uint64_t v35 = v37;
              }
              while (v17 >= *(void *)(v37 + 48));
              do
              {
                uint64_t v38 = *--v33;
                uint64_t v36 = v38;
              }
              while (v17 < *(void *)(v38 + 48));
            }
            while (v10 < v33);
          }
          uint64_t v39 = v10 - 1;
          BOOL v4 = v10 - 1 >= v9;
          BOOL v5 = v10 - 1 == v9;
          if (v10 - 1 != v9) {
            *uint64_t v9 = *v39;
          }
          a4 = 0;
          *uint64_t v39 = v16;
        }
        uint64_t v17 = *(void *)(v16 + 48);
LABEL_13:
        uint64_t v18 = 0;
        do
          uint64_t v19 = v9[++v18];
        while (*(void *)(v19 + 48) < v17);
        BOOL v20 = &v9[v18];
        BOOL v21 = a2;
        if (v18 == 1)
        {
          BOOL v21 = a2;
          do
          {
            if (v20 >= v21) {
              break;
            }
            uint64_t v23 = *--v21;
          }
          while (*(void *)(v23 + 48) >= v17);
        }
        else
        {
          do
            uint64_t v22 = *--v21;
          while (*(void *)(v22 + 48) >= v17);
        }
        if (v20 >= v21)
        {
          uint64_t v29 = v20 - 1;
        }
        else
        {
          uint64_t v24 = *v21;
          uint64_t v25 = &v9[v18];
          uint64_t v26 = v21;
          do
          {
            *uint64_t v25 = v24;
            *uint64_t v26 = v19;
            do
            {
              uint64_t v27 = v25[1];
              ++v25;
              uint64_t v19 = v27;
            }
            while (*(void *)(v27 + 48) < v17);
            do
            {
              uint64_t v28 = *--v26;
              uint64_t v24 = v28;
            }
            while (*(void *)(v28 + 48) >= v17);
          }
          while (v25 < v26);
          uint64_t v29 = v25 - 1;
        }
        if (v29 != v9) {
          *uint64_t v9 = *v29;
        }
        *uint64_t v29 = v16;
        if (v20 >= v21) {
          break;
        }
LABEL_34:
        uint64_t result = std::__introsort<std::_ClassicAlgPolicy,ZinMirPEReductionAccumulationRetention::Run(void)::$_0::operator() const(ZinIrOpLayerGraph *,ZinIrOpLayer *)::{lambda(ZinPEElementWiseLayer *,ZinPEElementWiseLayer *)#1} &,ZinPEElementWiseLayer **,false>(v9, v29, a3, a4 & 1);
        a4 = 0;
        unint64_t v10 = v29 + 1;
      }
      BOOL v30 = std::__insertion_sort_incomplete[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirPEReductionAccumulationRetention::Run(void)::$_0::operator() const(ZinIrOpLayerGraph *,ZinIrOpLayer *)::{lambda(ZinPEElementWiseLayer *,ZinPEElementWiseLayer *)#1} &,ZinPEElementWiseLayer **>(v9, v29);
      unint64_t v10 = v29 + 1;
      uint64_t result = std::__insertion_sort_incomplete[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirPEReductionAccumulationRetention::Run(void)::$_0::operator() const(ZinIrOpLayerGraph *,ZinIrOpLayer *)::{lambda(ZinPEElementWiseLayer *,ZinPEElementWiseLayer *)#1} &,ZinPEElementWiseLayer **>(v29 + 1, a2);
      if (result) {
        break;
      }
      if (!v30) {
        goto LABEL_34;
      }
    }
    a2 = v29;
    if (!v30) {
      continue;
    }
    return result;
  }
}

BOOL std::__insertion_sort_incomplete[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirPEReductionAccumulationRetention::Run(void)::$_0::operator() const(ZinIrOpLayerGraph *,ZinIrOpLayer *)::{lambda(ZinPEElementWiseLayer *,ZinPEElementWiseLayer *)#1} &,ZinPEElementWiseLayer **>(uint64_t *a1, uint64_t *a2)
{
  uint64_t v4 = a2 - a1;
  BOOL result = 1;
  switch(v4)
  {
    case 0:
    case 1:
      return result;
    case 2:
      uint64_t v6 = *(a2 - 1);
      uint64_t v7 = *a1;
      if (*(void *)(v6 + 48) < *(void *)(*a1 + 48))
      {
        *a1 = v6;
        *(a2 - 1) = v7;
      }
      return result;
    case 3:
      std::__sort3[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirSpatialSplitUtils::ComputeScheduleAndTensorResidency(ZinIrControlFlowGraph *,ZinIrParameters const&,SplitConfiguration &)::$_0 &,ZinIrOpLayer **>(a1, a1 + 1, a2 - 1);
      return 1;
    case 4:
      std::__sort4[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirSpatialSplitUtils::ComputeScheduleAndTensorResidency(ZinIrControlFlowGraph *,ZinIrParameters const&,SplitConfiguration &)::$_0 &,ZinIrOpLayer **>(a1, a1 + 1, a1 + 2, a2 - 1);
      return 1;
    case 5:
      uint64_t v18 = a1 + 1;
      uint64_t v19 = a1 + 2;
      BOOL v20 = a1 + 3;
      std::__sort4[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirSpatialSplitUtils::ComputeScheduleAndTensorResidency(ZinIrControlFlowGraph *,ZinIrParameters const&,SplitConfiguration &)::$_0 &,ZinIrOpLayer **>(a1, a1 + 1, a1 + 2, a1 + 3);
      uint64_t v21 = *(a2 - 1);
      uint64_t v22 = a1[3];
      if (*(void *)(v21 + 48) < *(void *)(v22 + 48))
      {
        *BOOL v20 = v21;
        *(a2 - 1) = v22;
        uint64_t v23 = *v20;
        uint64_t v24 = *v19;
        uint64_t v25 = *(void *)(*v20 + 48);
        if (v25 < *(void *)(*v19 + 48))
        {
          *uint64_t v19 = v23;
          *BOOL v20 = v24;
          uint64_t v26 = *v18;
          if (v25 < *(void *)(*v18 + 48))
          {
            a1[1] = v23;
            a1[2] = v26;
            uint64_t v27 = *a1;
            if (v25 < *(void *)(*a1 + 48))
            {
              *a1 = v23;
              a1[1] = v27;
            }
          }
        }
      }
      return 1;
    default:
      long long v8 = a1 + 2;
      std::__sort3[abi:ne180100]<std::_ClassicAlgPolicy,ZinMirSpatialSplitUtils::ComputeScheduleAndTensorResidency(ZinIrControlFlowGraph *,ZinIrParameters const&,SplitConfiguration &)::$_0 &,ZinIrOpLayer **>(a1, a1 + 1, a1 + 2);
      uint64_t v9 = a1 + 3;
      if (a1 + 3 == a2) {
        return 1;
      }
      int v10 = 0;
      uint64_t v11 = 24;
      break;
  }
  while (1)
  {
    uint64_t v12 = *v9;
    uint64_t v13 = *v8;
    uint64_t v14 = *(void *)(*v9 + 48);
    if (v14 < *(void *)(*v8 + 48))
    {
      uint64_t v15 = v11;
      while (1)
      {
        *(uint64_t *)((char *)a1 + v15) = v13;
        uint64_t v16 = v15 - 8;
        if (v15 == 8) {
          break;
        }
        uint64_t v13 = *(uint64_t *)((char *)a1 + v15 - 16);
        v15 -= 8;
        if (v14 >= *(void *)(v13 + 48))
        {
          uint64_t v17 = (uint64_t *)((char *)a1 + v16);
          goto LABEL_13;
        }
      }
      uint64_t v17 = a1;
LABEL_13:
      uint64_t *v17 = v12;
      if (++v10 == 8) {
        return v9 + 1 == a2;
      }
    }
    long long v8 = v9;
    v11 += 8;
    if (++v9 == a2) {
      return 1;
    }
  }
}

void ZinMirPEReductionAccumulationRetention::UpdateGraphWithConst(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "Unsupported data format!\n", a5, a6, a7, a8, 0);
}

void ZinMirPEReductionAccumulationRetention::Run(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void ZinSoftmaxLayer::Clone()
{
  uint64_t v0 = *MEMORY[0x263EF8340];
  operator new();
}

void sub_2113A27F8(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, void *__p, uint64_t a17)
{
  if (v18) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v18);
  }
  if (a10) {
    (*(void (**)(uint64_t))(*(void *)a10 + 8))(a10);
  }
  MEMORY[0x21667D3C0](v17, 0x10B3C409D855DA1);
  _Unwind_Resume(a1);
}

void *ZinSoftmaxLayer::OpCodeKindToString@<X0>(void *a1@<X8>)
{
  return std::string::basic_string[abi:ne180100]<0>(a1, "SOFTMAX");
}

uint64_t ZinSoftmaxLayer::DebugDetailPrint@<X0>(void *a1@<X8>)
{
  std::basic_stringstream<char,std::char_traits<char>,std::allocator<char>>::basic_stringstream[abi:ne180100]((uint64_t)v5);
  std::stringbuf::str[abi:ne180100]<std::allocator<char>>((uint64_t)v6, a1);
  v5[0] = *MEMORY[0x263F8C2B8];
  uint64_t v3 = *(void *)(MEMORY[0x263F8C2B8] + 72);
  *(void *)((char *)v5 + *(void *)(v5[0] - 24)) = *(void *)(MEMORY[0x263F8C2B8] + 64);
  v5[2] = v3;
  v6[0] = MEMORY[0x263F8C318] + 16;
  if (v7 < 0) {
    operator delete((void *)v6[8]);
  }
  std::streambuf::~streambuf();
  std::iostream::~basic_iostream();
  return MEMORY[0x21667D2B0](&v8);
}

void sub_2113A2A18(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
}

void ZinIrKernel::ComputeSummationOfKSubChannelWeightValues(ZinIrKernel *this@<X0>, uint64_t a2@<X8>)
{
  *(void *)a2 = 0;
  *(void *)(a2 + 8) = 0;
  *(void *)(a2 + 16) = 0;
  uint64_t v4 = *((void *)this + 31);
  uint64_t v56 = *((void *)this + 32);
  int64_t v5 = *((void *)this + 35);
  uint64_t v6 = *((int *)this + 87);
  int64_t v66 = *((int *)this + 85);
  int64_t v67 = *((void *)this + 34);
  int64_t v61 = *((int *)this + 86);
  int64_t v62 = *((void *)this + 33);
  std::vector<float>::reserve((void **)a2, v4 * v66 * v61 * v6);
  if (ZinKernelFormatIsUnity(*((_DWORD *)this + 44)))
  {
    if ((*((unsigned char *)this + 448) & 2) != 0) {
      ZinAssertImpl("Unity kernel can't have zero_point");
    }
    if (v4 >= 1)
    {
      uint64_t v7 = 0;
      uint64_t v8 = (void *)(a2 + 16);
      uint64_t v51 = v4;
      do
      {
        float v9 = 1.0;
        if ((*((unsigned char *)this + 448) & 8) != 0)
        {
          ZinIrVector::GetAt<float>(*((void *)this + 71), v7);
          float v9 = v10;
        }
        uint64_t v54 = v7;
        uint64_t v59 = v6;
        if ((int)v6 >= 1)
        {
          do
          {
            uint64_t v57 = v59--;
            if ((int)v61 >= 1)
            {
              float v11 = ceilf((float)(v5 - v59) / (float)(int)v6);
              uint64_t v64 = v61;
              do
              {
                uint64_t v12 = v64--;
                if ((int)v66 >= 1)
                {
                  uint64_t v13 = v66;
                  float v14 = ceilf((float)(v62 - v64) / (float)(int)v61) * (float)v56;
                  uint64_t v15 = *(float **)(a2 + 8);
                  do
                  {
                    float v16 = v9 * (float)(v11 * (float)(v14 * ceilf((float)(v67 - (v13 - 1)) / (float)(int)v66)));
                    if ((unint64_t)v15 >= *v8)
                    {
                      uint64_t v18 = *(float **)a2;
                      uint64_t v19 = ((uint64_t)v15 - *(void *)a2) >> 2;
                      unint64_t v20 = v19 + 1;
                      if ((unint64_t)(v19 + 1) >> 62) {
                        std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
                      }
                      uint64_t v21 = *v8 - (void)v18;
                      if (v21 >> 1 > v20) {
                        unint64_t v20 = v21 >> 1;
                      }
                      if ((unint64_t)v21 >= 0x7FFFFFFFFFFFFFFCLL) {
                        unint64_t v22 = 0x3FFFFFFFFFFFFFFFLL;
                      }
                      else {
                        unint64_t v22 = v20;
                      }
                      if (v22)
                      {
                        uint64_t v23 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ZinIrPaddingMode>>(a2 + 16, v22);
                        uint64_t v18 = *(float **)a2;
                        uint64_t v15 = *(float **)(a2 + 8);
                      }
                      else
                      {
                        uint64_t v23 = 0;
                      }
                      uint64_t v24 = (float *)&v23[4 * v19];
                      *uint64_t v24 = v16;
                      uint64_t v17 = v24 + 1;
                      while (v15 != v18)
                      {
                        int v25 = *((_DWORD *)v15-- - 1);
                        *((_DWORD *)v24-- - 1) = v25;
                      }
                      *(void *)a2 = v24;
                      *(void *)(a2 + 8) = v17;
                      *(void *)(a2 + 16) = &v23[4 * v22];
                      if (v18) {
                        operator delete(v18);
                      }
                    }
                    else
                    {
                      float *v15 = v16;
                      uint64_t v17 = v15 + 1;
                    }
                    *(void *)(a2 + 8) = v17;
                    uint64_t v15 = v17;
                  }
                  while (v13-- > 1);
                }
              }
              while (v12 >= 2);
            }
          }
          while (v57 >= 2);
        }
        uint64_t v7 = v54 + 1;
      }
      while (v54 + 1 != v51);
    }
  }
  else if (v4 >= 1)
  {
    uint64_t v27 = 0;
    uint64_t v52 = v4;
    do
    {
      char v28 = *((unsigned char *)this + 448);
      if ((v28 & 2) != 0)
      {
        int ValueAsInt32 = ZinIrVector::GetValueAsInt32(*((ZinIrVector **)this + 74), v27);
        char v28 = *((unsigned char *)this + 448);
      }
      else
      {
        int ValueAsInt32 = 0;
      }
      float v30 = 1.0;
      if ((v28 & 8) != 0)
      {
        ZinIrVector::GetAt<float>(*((void *)this + 71), v27);
        float v30 = v31;
      }
      if ((int)v6 >= 1)
      {
        uint64_t v32 = v6;
        do
        {
          uint64_t v63 = v32;
          int64_t v65 = v32 - 1;
          int64_t v33 = v61;
          if ((int)v61 >= 1)
          {
            do
            {
              uint64_t v53 = v33--;
              if ((int)v66 >= 1)
              {
                int64_t v60 = v66;
                int64_t v55 = v33;
                do
                {
                  uint64_t v58 = v60--;
                  if (v56 < 1)
                  {
                    double v35 = 0.0;
                  }
                  else
                  {
                    unint64_t v34 = 0;
                    double v35 = 0.0;
                    do
                    {
                      if (v62 >= v53)
                      {
                        do
                        {
                          int64_t v36 = v60;
                          if (v67 >= v58)
                          {
                            do
                            {
                              int64_t v37 = v65;
                              if (v5 >= v63)
                              {
                                do
                                {
                                  v68[0] = v27;
                                  v68[1] = v34;
                                  v68[2] = v33;
                                  v68[3] = v36;
                                  v68[4] = v37;
                                  ZinIrWeight::GetWeightValueAsFloat(*((void *)this + 73), v68);
                                  double v35 = v35 + (float)(v30 * (float)(v38 - (float)ValueAsInt32));
                                  v37 += v6;
                                }
                                while (v5 > v37);
                              }
                              v36 += v66;
                            }
                            while (v67 > v36);
                          }
                          v33 += v61;
                        }
                        while (v62 > v33);
                      }
                      ++v34;
                      int64_t v33 = v55;
                    }
                    while (v34 != v56);
                  }
                  float v39 = v35;
                  uint64_t v41 = *(float **)(a2 + 8);
                  unint64_t v40 = *(void *)(a2 + 16);
                  if ((unint64_t)v41 >= v40)
                  {
                    uint64_t v43 = *(float **)a2;
                    uint64_t v44 = ((uint64_t)v41 - *(void *)a2) >> 2;
                    unint64_t v45 = v44 + 1;
                    uint64_t v4 = v52;
                    if ((unint64_t)(v44 + 1) >> 62) {
                      std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
                    }
                    uint64_t v46 = v40 - (void)v43;
                    if (v46 >> 1 > v45) {
                      unint64_t v45 = v46 >> 1;
                    }
                    if ((unint64_t)v46 >= 0x7FFFFFFFFFFFFFFCLL) {
                      unint64_t v47 = 0x3FFFFFFFFFFFFFFFLL;
                    }
                    else {
                      unint64_t v47 = v45;
                    }
                    if (v47)
                    {
                      uint64_t v48 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ZinIrPaddingMode>>(a2 + 16, v47);
                      uint64_t v43 = *(float **)a2;
                      uint64_t v41 = *(float **)(a2 + 8);
                    }
                    else
                    {
                      uint64_t v48 = 0;
                    }
                    uint64_t v49 = (float *)&v48[4 * v44];
                    *uint64_t v49 = v39;
                    BOOL v42 = v49 + 1;
                    if (v41 == v43)
                    {
                      int64_t v33 = v55;
                    }
                    else
                    {
                      int64_t v33 = v55;
                      do
                      {
                        int v50 = *((_DWORD *)v41-- - 1);
                        *((_DWORD *)v49-- - 1) = v50;
                      }
                      while (v41 != v43);
                    }
                    *(void *)a2 = v49;
                    *(void *)(a2 + 8) = v42;
                    *(void *)(a2 + 16) = &v48[4 * v47];
                    if (v43) {
                      operator delete(v43);
                    }
                  }
                  else
                  {
                    float *v41 = v39;
                    BOOL v42 = v41 + 1;
                    uint64_t v4 = v52;
                  }
                  *(void *)(a2 + 8) = v42;
                }
                while (v58 > 1);
              }
            }
            while (v53 >= 2);
          }
          uint64_t v32 = v65;
        }
        while (v63 >= 2);
      }
      ++v27;
    }
    while (v27 != v4);
  }
}

void sub_2113A302C(_Unwind_Exception *exception_object)
{
  uint64_t v3 = *(void **)v1;
  if (*(void *)v1)
  {
    *(void *)(v1 + 8) = v3;
    operator delete(v3);
  }
  _Unwind_Resume(exception_object);
}

BOOL ZinIrKernel::HasUnityWeight(ZinIrKernel *this)
{
  return ZinKernelFormatIsUnity(*((_DWORD *)this + 44));
}

uint64_t ZinIrKernel::HasZeroPoint(ZinIrKernel *this)
{
  return (*((unsigned __int8 *)this + 448) >> 1) & 1;
}

uint64_t ZinIrKernel::HasNonUnityValue(ZinIrKernel *this)
{
  uint64_t v1 = (uint64_t *)*((void *)this + 73);
  if (v1[7] < 1) {
    return 0;
  }
  uint64_t v3 = 0;
  while (1)
  {
    if ((*((unsigned char *)this + 448) & 2) != 0) {
      ZinIrVector::GetValueAsInt32(*((ZinIrVector **)this + 74), v3);
    }
    uint64_t v4 = v1[8];
    if (v4 >= 1) {
      break;
    }
LABEL_21:
    uint64_t result = 0;
    if (v1[7] <= ++v3) {
      return result;
    }
  }
  unint64_t v5 = 0;
  uint64_t v6 = v1[9];
  while (v6 < 1)
  {
LABEL_20:
    if (v4 <= (uint64_t)++v5) {
      goto LABEL_21;
    }
  }
  unint64_t v7 = 0;
  uint64_t v8 = v1[10];
  while (v8 < 1)
  {
LABEL_18:
    if (v6 <= (uint64_t)++v7)
    {
      uint64_t v4 = v1[8];
      goto LABEL_20;
    }
  }
  unint64_t v9 = 0;
  uint64_t v10 = v1[11];
  while (v10 < 1)
  {
LABEL_16:
    if (v8 <= (uint64_t)++v9)
    {
      uint64_t v6 = v1[9];
      goto LABEL_18;
    }
  }
  int64_t v11 = 0;
  while (1)
  {
    v14[0] = v3;
    v14[1] = v5;
    void v14[2] = v7;
    v14[3] = v9;
    v14[4] = v11;
    ZinIrWeight::GetWeightValueAsFloat(*((void *)this + 73), v14);
    if (v12 != 1.0) {
      return 1;
    }
    ++v11;
    uint64_t v10 = v1[11];
    if (v10 <= v11)
    {
      uint64_t v8 = v1[10];
      goto LABEL_16;
    }
  }
}

BOOL ZinIrKernel::ShouldUseSparseBinaryForCompression(ZinIrKernel *this)
{
  BOOL result = 0;
  if ((*((unsigned char *)this + 448) & 4) != 0)
  {
    uint64_t v4 = 0;
    BOOL v2 = !ZinKernelFormatGetBitDepth(*((_DWORD *)this + 44), &v4) && v4 == 1;
    if (v2 && (*((unsigned char *)this + 448) & 0x22) == 0) {
      return 1;
    }
  }
  return result;
}

uint64_t ZinIrKernel::HasPaletteThatRequiresCompression(ZinIrKernel *this)
{
  BOOL v2 = ZinKernelDescriptor::KernelExpands((ZinIrKernel *)((char *)this + 176));
  uint64_t v3 = *((void *)this + 73);
  if (!v3
    || !*(void *)(v3 + 280)
    || (*(_DWORD *)(v3 + 8) - 7) > 0x14
    || ((*(unsigned int (**)(void))(**(void **)(v3 + 136) + 184))(*(void *)(v3 + 136)) | v2) != 1)
  {
    return 0;
  }
  if (ZinIrWeight::IsFirstPaletteLUTEntryNonZero(*((ZinIrWeight **)this + 73))) {
    return 1;
  }
  return (*((unsigned __int8 *)this + 448) >> 1) & 1;
}

uint64_t ZinIrKernel::AddWeightsToSHA(ZinIrKernel *this)
{
  uint64_t v65 = *MEMORY[0x263EF8340];
  uint64_t v2 = *((void *)this + 73);
  if (v2)
  {
    int v3 = *(_DWORD *)(v2 + 8);
  }
  else
  {
    uint64_t v4 = *((void *)this + 77);
    if (v4) {
      int v3 = ZinTensorFormatToKernelFormat(*(unsigned int *)(v4 + 88));
    }
    else {
      int v3 = 0;
    }
  }
  int v60 = v3;
  long long v61 = xmmword_211F08444;
  LODWORD(v62) = 6;
  std::unordered_set<ZinKernelFormat>::unordered_set((uint64_t)v59, (int *)&v61, 5);
  if (!ZinKernelFormatIsUnity(*((_DWORD *)this + 44)))
  {
    if (!std::__hash_table<ZinIrDimension,std::hash<ZinIrDimension>,std::equal_to<ZinIrDimension>,std::allocator<ZinIrDimension>>::find<ZinIrDimension>(v59, &v60)&& (v60 - 7) > 0x14)
    {
      BOOL v30 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v30) {
        ZinIrKernel::AddWeightsToSHA(v30, v31, v32, v33, v34, v35, v36, v37);
      }
      goto LABEL_45;
    }
    uint64_t v6 = (void *)*((void *)this + 73);
    if ((uint64_t)v6[7] >= 1)
    {
      uint64_t v7 = 0;
      do
      {
        if ((uint64_t)v6[8] >= 1)
        {
          uint64_t v8 = 0;
          do
          {
            if ((uint64_t)v6[9] >= 1)
            {
              uint64_t v9 = 0;
              do
              {
                if ((uint64_t)v6[10] >= 1)
                {
                  uint64_t v10 = 0;
                  do
                  {
                    if ((uint64_t)v6[11] >= 1)
                    {
                      uint64_t v11 = 0;
                      while (2)
                      {
                        *(void *)&long long v61 = v7;
                        *((void *)&v61 + 1) = v8;
                        uint64_t v62 = v9;
                        uint64_t v63 = v10;
                        uint64_t v64 = v11;
                        switch(v60)
                        {
                          case 0:
                          case 3:
                          case 28:
                          case 29:
                          case 30:
                          case 31:
                          case 32:
                            BOOL v22 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
                            if (v22) {
                              ZinIrKernel::AddWeightsToSHA(v22, v23, v24, v25, v26, v27, v28, v29);
                            }
                            goto LABEL_45;
                          case 1:
                            LOBYTE(data) = 0;
                            LOBYTE(data) = ZinIrWeightBase::GetAt<signed char>((uint64_t)v6);
                            CC_SHA256_Update((CC_SHA256_CTX *)((char *)this + 52), &data, 1u);
                            goto LABEL_26;
                          case 2:
                          case 27:
                            LOBYTE(data) = 0;
                            LOBYTE(data) = ZinIrWeightBase::GetAt<unsigned char>((uint64_t)v6);
                            CC_SHA256_Update((CC_SHA256_CTX *)((char *)this + 52), &data, 1u);
                            goto LABEL_26;
                          case 4:
                            LOWORD(data) = 0;
                            ZinIrWeightBase::GetAt<half>((uint64_t)v6);
                            LOWORD(data) = v13;
                            CC_SHA256_Update((CC_SHA256_CTX *)((char *)this + 52), &data, 2u);
                            goto LABEL_26;
                          case 5:
                            LOBYTE(data) = ZinIrWeightBase::GetAt<e4m3_t>((uint64_t)v6);
                            CC_SHA256_Update((CC_SHA256_CTX *)((char *)this + 52), &data, 1u);
                            goto LABEL_26;
                          case 6:
                            LODWORD(data) = 0;
                            ZinIrWeightBase::GetAt<float>((uint64_t)v6);
                            LODWORD(data) = v12;
                            CC_SHA256_Update((CC_SHA256_CTX *)((char *)this + 52), &data, 4u);
                            goto LABEL_26;
                          case 7:
                          case 8:
                          case 9:
                          case 10:
                            LOBYTE(data) = 0;
                            LOBYTE(data) = ZinIrWeightBase::GetAt<ZinIrWeightBase::uint1>((uint64_t)v6) & 1;
                            CC_SHA256_Update((CC_SHA256_CTX *)((char *)this + 52), &data, 1u);
                            goto LABEL_26;
                          case 11:
                          case 12:
                          case 13:
                          case 14:
                            LOBYTE(data) = 0;
                            LOBYTE(data) = ZinIrWeightBase::GetAt<ZinIrWeightBase::uint2>((uint64_t)v6) & 3;
                            CC_SHA256_Update((CC_SHA256_CTX *)((char *)this + 52), &data, 1u);
                            goto LABEL_26;
                          case 15:
                          case 16:
                          case 17:
                          case 18:
                            LOBYTE(data) = 0;
                            LOBYTE(data) = ZinIrWeightBase::GetAt<ZinIrWeightBase::uint3>((uint64_t)v6) & 7;
                            CC_SHA256_Update((CC_SHA256_CTX *)((char *)this + 52), &data, 1u);
                            goto LABEL_26;
                          case 19:
                          case 20:
                          case 21:
                          case 22:
                            LOBYTE(data) = 0;
                            LOBYTE(data) = ZinIrWeightBase::GetAt<ZinIrWeightBase::uint4>((uint64_t)v6) & 0xF;
                            CC_SHA256_Update((CC_SHA256_CTX *)((char *)this + 52), &data, 1u);
                            goto LABEL_26;
                          case 23:
                          case 24:
                          case 25:
                          case 26:
                            LOBYTE(data) = 0;
                            LOBYTE(data) = ZinIrWeightBase::GetAt<ZinIrWeightBase::uint6>((uint64_t)v6) & 0x3F;
                            CC_SHA256_Update((CC_SHA256_CTX *)((char *)this + 52), &data, 1u);
                            goto LABEL_26;
                          default:
LABEL_26:
                            ++v11;
                            uint64_t v6 = (void *)*((void *)this + 73);
                            if (v11 >= v6[11]) {
                              break;
                            }
                            continue;
                        }
                        break;
                      }
                    }
                    ++v10;
                  }
                  while (v10 < v6[10]);
                }
                ++v9;
              }
              while (v9 < v6[9]);
            }
            ++v8;
          }
          while (v8 < v6[8]);
        }
        ++v7;
      }
      while (v7 < v6[7]);
    }
    if ((v60 - 7) > 0x14) {
      goto LABEL_7;
    }
    *(void *)&long long v61 = 0;
    uint64_t data = 0;
    if (ZinKernelGetPaletteLUTSize(v60, *((void *)this + 52), &v61))
    {
      BOOL v14 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v14) {
        ZinIrKernel::AddWeightsToSHA(v14, v15, v16, v17, v18, v19, v20, v21);
      }
      goto LABEL_45;
    }
    int v57 = 0;
    if (ZinKernelFormatGetPaletteFormat(v60, &v57))
    {
      BOOL v39 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (!v39)
      {
LABEL_45:
        uint64_t v5 = 3;
        goto LABEL_46;
      }
    }
    else
    {
      if (!ZinKernelFormatGetBitDepth(v57, &data))
      {
        uint64_t v47 = *((void *)this + 73);
        uint64_t v48 = *(void **)(v47 + 280);
        if (v48)
        {
          unint64_t v49 = 0;
          uint64_t v50 = 8 * (uint64_t)v61 / data;
          do
          {
            if ((*(_DWORD *)(v47 + 8) - 7) >= 0x15) {
              break;
            }
            if (v49 >= (uint64_t)(v48[1] - *v48) >> 4) {
              goto LABEL_7;
            }
            if (v50 >= 1)
            {
              for (uint64_t i = 0; i != v50; ++i)
              {
                switch(v57)
                {
                  case 1:
                    LOBYTE(v56) = 0;
                    PaletteData = (void *)ZinIrWeight::GetPaletteData(*((ZinIrWeight **)this + 73), v49);
                    LOBYTE(v56) = (*(uint64_t (**)(void, uint64_t))(*(void *)*PaletteData + 72))(*PaletteData, i);
                    CC_SHA256_Update((CC_SHA256_CTX *)((char *)this + 52), &v56, 1u);
                    break;
                  case 2:
                    LOBYTE(v56) = 0;
                    uint64_t v54 = (void *)ZinIrWeight::GetPaletteData(*((ZinIrWeight **)this + 73), v49);
                    LOBYTE(v56) = (*(uint64_t (**)(void, uint64_t))(*(void *)*v54 + 120))(*v54, i);
                    CC_SHA256_Update((CC_SHA256_CTX *)((char *)this + 52), &v56, 1u);
                    break;
                  case 4:
                    unsigned __int16 v56 = 0;
                    uint64_t v53 = (void *)ZinIrWeight::GetPaletteData(*((ZinIrWeight **)this + 73), v49);
                    unsigned __int16 v56 = ((__n128 (*)(void, uint64_t))*(void *)(*(void *)*v53 + 56))(*v53, i).n128_u16[0];
                    CC_SHA256_Update((CC_SHA256_CTX *)((char *)this + 52), &v56, 2u);
                    break;
                  case 5:
                    int64_t v55 = (void *)ZinIrWeight::GetPaletteData(*((ZinIrWeight **)this + 73), v49);
                    LOBYTE(v56) = (*(uint64_t (**)(void, uint64_t))(*(void *)*v55 + 88))(*v55, i);
                    CC_SHA256_Update((CC_SHA256_CTX *)((char *)this + 52), &v56, 1u);
                    break;
                  default:
                    continue;
                }
              }
              uint64_t v47 = *((void *)this + 73);
            }
            ++v49;
            uint64_t v48 = *(void **)(v47 + 280);
          }
          while (v48);
        }
        ZinAssertImpl("Error: This weight does not have palette info.");
      }
      BOOL v39 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (!v39) {
        goto LABEL_45;
      }
    }
    ZinIrKernel::AddWeightsToSHA(v39, v40, v41, v42, v43, v44, v45, v46);
    goto LABEL_45;
  }
LABEL_7:
  uint64_t v5 = 0;
LABEL_46:
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v59);
  return v5;
}

void sub_2113A392C(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, ...)
{
  va_start(va, a3);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)va);
  _Unwind_Resume(a1);
}

void ZinIrKernel::UpdateSHAContextForMemberVariables(SHAUpdateMode)::$_0::operator()(std::string *a1, int a2, CC_SHA256_CTX *a3)
{
  v16[2] = *MEMORY[0x263EF8340];
  p_std::string::size_type size = &a1[1].__r_.__value_.__l.__size_;
  if (a1[1].__r_.__value_.__l.__size_)
  {
    ZinGetFileNameOnly(a1, &__p);
    std::to_string(&v14, a2);
    if ((__p.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
      p_p = &__p;
    }
    else {
      p_p = (std::string *)__p.__r_.__value_.__r.__words[0];
    }
    if ((__p.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
      std::string::size_type size = HIBYTE(__p.__r_.__value_.__r.__words[2]);
    }
    else {
      std::string::size_type size = __p.__r_.__value_.__l.__size_;
    }
    uint64_t v9 = std::string::insert(&v14, 0, (const std::string::value_type *)p_p, size);
    std::string::size_type v10 = v9->__r_.__value_.__r.__words[0];
    v16[0] = v9->__r_.__value_.__l.__size_;
    *(void *)((char *)v16 + 7) = *(std::string::size_type *)((char *)&v9->__r_.__value_.__r.__words[1] + 7);
    CC_LONG v11 = HIBYTE(v9->__r_.__value_.__r.__words[2]);
    v9->__r_.__value_.__l.__size_ = 0;
    v9->__r_.__value_.__r.__words[2] = 0;
    v9->__r_.__value_.__r.__words[0] = 0;
    if (SHIBYTE(__p.__r_.__value_.__r.__words[2]) < 0) {
      operator delete(__p.__r_.__value_.__l.__data_);
    }
    __p.__r_.__value_.__r.__words[0] = v10;
    __p.__r_.__value_.__l.__size_ = v16[0];
    *(std::string::size_type *)((char *)&__p.__r_.__value_.__r.__words[1] + 7) = *(void *)((char *)v16 + 7);
    *((unsigned char *)&__p.__r_.__value_.__s + 23) = v11;
    if (SHIBYTE(v14.__r_.__value_.__r.__words[2]) < 0)
    {
      operator delete(v14.__r_.__value_.__l.__data_);
      CC_LONG v11 = HIBYTE(__p.__r_.__value_.__r.__words[2]);
      std::string::size_type v10 = __p.__r_.__value_.__r.__words[0];
    }
    if ((v11 & 0x80u) == 0) {
      int v12 = &__p;
    }
    else {
      int v12 = (std::string *)v10;
    }
    if ((v11 & 0x80u) == 0) {
      CC_LONG v13 = v11;
    }
    else {
      CC_LONG v13 = __p.__r_.__value_.__r.__words[1];
    }
    CC_SHA256_Update(a3, v12, v13);
    CC_SHA256_Update(a3, &a1[1], 8u);
    CC_SHA256_Update(a3, p_size, 8u);
    if (SHIBYTE(__p.__r_.__value_.__r.__words[2]) < 0) {
      operator delete(__p.__r_.__value_.__l.__data_);
    }
  }
}

void sub_2113A3BA0(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11, int a12, __int16 a13, char a14, char a15, void *a16, uint64_t a17, int a18, __int16 a19, char a20,char a21)
{
  if (a15 < 0) {
    operator delete(__p);
  }
  if (a21 < 0) {
    operator delete(a16);
  }
  _Unwind_Resume(exception_object);
}

void ZinIrKernel::AddVectorToSHA(ZinIrKernel *this, const ZinIrVector *a2)
{
  ZinIrVector::GetValuesAsVector<float>((uint64_t)a2, *((void *)a2 + 7), 1, (uint64_t)&data);
  CC_SHA256_Update((CC_SHA256_CTX *)((char *)this + 52), data, (v4 - data) & 0xFFFFFFFC);
  if (data)
  {
    uint64_t v4 = data;
    operator delete(data);
  }
}

void sub_2113A3C48(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinIrKernel::GetWeightFormat(ZinIrKernel *this)
{
  uint64_t v1 = *((void *)this + 73);
  if (v1) {
    return *(unsigned int *)(v1 + 8);
  }
  uint64_t v3 = *((void *)this + 77);
  if (v3) {
    return ZinTensorFormatToKernelFormat(*(unsigned int *)(v3 + 88));
  }
  else {
    return 0;
  }
}

void ZinIrKernel::GetCurrentHash(ZinIrKernel *this@<X0>, std::string *a2@<X8>)
{
}

void ZinIrKernel::GetHash(ZinIrKernel *this@<X0>, char a2@<W1>, std::string *a3@<X8>)
{
  uint64_t v16 = *MEMORY[0x263EF8340];
  if (!*((unsigned char *)this + 48))
  {
    *(_OWORD *)md = 0u;
    long long v15 = 0u;
    if (a2)
    {
      CC_SHA256_Final(md, (CC_SHA256_CTX *)((char *)this + 52));
    }
    else
    {
      long long v8 = *(_OWORD *)((char *)this + 100);
      long long v9 = *(_OWORD *)((char *)this + 132);
      *(_OWORD *)&c.wbuf[6] = *(_OWORD *)((char *)this + 116);
      *(_OWORD *)&c.wbuf[10] = v9;
      *(void *)&c.wbuf[14] = *(void *)((char *)this + 148);
      long long v10 = *(_OWORD *)((char *)this + 68);
      *(_OWORD *)c.count = *(_OWORD *)((char *)this + 52);
      *(_OWORD *)&c.hash[2] = v10;
      *(_OWORD *)&c.hash[6] = *(_OWORD *)((char *)this + 84);
      *(_OWORD *)&c.wbuf[2] = v8;
      CC_SHA256_Final(md, &c);
    }
    uint64_t v11 = 0;
    p_CC_SHA256_CTX c = (char *)&c;
    do
    {
      snprintf(p_c, 3uLL, "%02X", md[v11++]);
      p_c += 2;
    }
    while (v11 != 32);
    LOBYTE(c.wbuf[6]) = 0;
    if ((a2 & 1) == 0)
    {
      std::string::basic_string[abi:ne180100]<0>(a3, (char *)&c);
      return;
    }
    if (*((unsigned char *)this + 156))
    {
      std::string::__assign_external((std::string *)this + 1, (const std::string::value_type *)&c);
      *((unsigned char *)this + 156) = 0;
    }
    *((unsigned char *)this + 48) = 1;
    if (*((char *)this + 47) < 0)
    {
      std::string::__init_copy_ctor_external(a3, *((const std::string::value_type **)this + 3), *((void *)this + 4));
      return;
    }
LABEL_15:
    *(_OWORD *)&a3->__r_.__value_.__l.__data_ = *(_OWORD *)((char *)this + 24);
    a3->__r_.__value_.__r.__words[2] = *((void *)this + 5);
    return;
  }
  if ((*((char *)this + 47) & 0x80000000) == 0) {
    goto LABEL_15;
  }
  uint64_t v5 = (const std::string::value_type *)*((void *)this + 3);
  std::string::size_type v6 = *((void *)this + 4);

  std::string::__init_copy_ctor_external(a3, v5, v6);
}

void ZinIrKernel::GetFinalHash(ZinIrKernel *this@<X0>, std::string *a2@<X8>)
{
}

uint64_t ZinIrKernel::GetHash(ZinIrKernel *this)
{
  uint64_t v24 = *MEMORY[0x263EF8340];
  *(_OWORD *)md = 0u;
  long long v23 = 0u;
  long long v1 = *(_OWORD *)((char *)this + 100);
  long long v2 = *(_OWORD *)((char *)this + 132);
  *(_OWORD *)&c.wbuf[6] = *(_OWORD *)((char *)this + 116);
  *(_OWORD *)&c.wbuf[10] = v2;
  *(void *)&c.wbuf[14] = *(void *)((char *)this + 148);
  long long v3 = *(_OWORD *)((char *)this + 68);
  *(_OWORD *)c.count = *(_OWORD *)((char *)this + 52);
  *(_OWORD *)&c.hash[2] = v3;
  *(_OWORD *)&c.hash[6] = *(_OWORD *)((char *)this + 84);
  *(_OWORD *)&c.wbuf[2] = v1;
  CC_SHA256_Final(md, &c);
  uint64_t v4 = 0;
  uint64_t v5 = 0;
  uint64_t v18 = 0;
  uint64_t v19 = 0;
  uint64_t v20 = 0;
  do
  {
    int v6 = md[v5];
    if (v4 >= v20)
    {
      uint64_t v7 = v18;
      uint64_t v8 = (v4 - v18) >> 2;
      unint64_t v9 = v8 + 1;
      if ((unint64_t)(v8 + 1) >> 62) {
        std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
      }
      uint64_t v10 = v20 - v18;
      if ((v20 - v18) >> 1 > v9) {
        unint64_t v9 = v10 >> 1;
      }
      if ((unint64_t)v10 >= 0x7FFFFFFFFFFFFFFCLL) {
        unint64_t v11 = 0x3FFFFFFFFFFFFFFFLL;
      }
      else {
        unint64_t v11 = v9;
      }
      if (v11)
      {
        int v12 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ZinIrPaddingMode>>((uint64_t)&v20, v11);
        uint64_t v7 = v18;
        uint64_t v4 = v19;
      }
      else
      {
        int v12 = 0;
      }
      CC_LONG v13 = &v12[4 * v8];
      *(_DWORD *)CC_LONG v13 = v6;
      std::string v14 = v13 + 4;
      while (v4 != v7)
      {
        int v15 = *((_DWORD *)v4 - 1);
        v4 -= 4;
        *((_DWORD *)v13 - 1) = v15;
        v13 -= 4;
      }
      uint64_t v18 = v13;
      uint64_t v20 = &v12[4 * v11];
      if (v7) {
        operator delete(v7);
      }
      uint64_t v4 = v14;
    }
    else
    {
      *(_DWORD *)uint64_t v4 = v6;
      v4 += 4;
    }
    uint64_t v19 = v4;
    ++v5;
  }
  while (v5 != 32);
  if (v18 == v4)
  {
    uint64_t v16 = 0;
  }
  else
  {
    uint64_t v16 = ZinHash(v18, (int)v4 - (int)v18);
    uint64_t v4 = v18;
    if (!v18) {
      return v16;
    }
  }
  operator delete(v4);
  return v16;
}

void sub_2113A4028(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

BOOL ZinIrKernel::ShouldPreserveCompressionInfo(ZinIrKernel *this, const ZinIrKernel *a2, const ZinIrHalParameters *a3, ZinKernelSparsityCache *a4)
{
  if (!*((unsigned char *)a2 + 160)) {
    return 0;
  }
  if (ZinIrKernel::HasPaletteThatRequiresCompression(a2)) {
    return 1;
  }
  if (!*((void *)this + 73)) {
    return 0;
  }
  ZinIrKernel::GetSparsityRatio(this, 4, a4);
  return v7 > 0.14286;
}

BOOL ZinIrKernel::IsWeightSparse(ZinIrKernel *this, char a2, BOOL a3, ZinKernelSparsityCache *a4, float a5)
{
  if (fabsf(a5) >= 1.0) {
    return 0;
  }
  uint64_t v7 = *((void *)this + 73);
  if (!v7) {
    return 0;
  }
  if ((a2 & 1) != 0
    && ((*(uint64_t (**)(void))(**(void **)(v7 + 136) + 184))(*(void *)(v7 + 136)) & 1) != 0)
  {
    return 1;
  }
  ZinIrKernel::GetSparsityRatio(this, a2, a4);
  return v11 > a5;
}

uint64_t ZinIrKernel::InitializeDescriptor(uint64_t a1, int a2, long long *a3)
{
  *(_OWORD *)(a1 + 176) = 0u;
  *(void *)(a1 + 448) = 0;
  *(_OWORD *)(a1 + 416) = 0u;
  *(_OWORD *)(a1 + 432) = 0u;
  *(_OWORD *)(a1 + 384) = 0u;
  *(_OWORD *)(a1 + 40std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0u;
  *(_OWORD *)(a1 + 352) = 0u;
  *(_OWORD *)(a1 + 368) = 0u;
  *(_OWORD *)(a1 + 32std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0u;
  *(_OWORD *)(a1 + 336) = 0u;
  *(_OWORD *)(a1 + 288) = 0u;
  *(_OWORD *)(a1 + 304) = 0u;
  *(_OWORD *)(a1 + 256) = 0u;
  *(_OWORD *)(a1 + 272) = 0u;
  *(_OWORD *)(a1 + 224) = 0u;
  *(_OWORD *)(a1 + 24std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0u;
  *(_OWORD *)(a1 + 192) = 0u;
  *(_OWORD *)(a1 + 208) = 0u;
  uint64_t v3 = *(void *)(a1 + 520);
  *(void *)(a1 + 384) = *(void *)(a1 + 528);
  *(_DWORD *)(a1 + 392) = *(_DWORD *)(a1 + 536);
  char v4 = *(unsigned char *)(a1 + 552);
  *(void *)(a1 + 40std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = *(void *)(a1 + 544);
  char v5 = (*(unsigned char *)(a1 + 553) << 6) | (v4 << 7);
  *(unsigned char *)(a1 + 448) = v5;
  *(_DWORD *)(a1 + 176) = a2;
  *(void *)(a1 + 328) = *(void *)(a1 + 480);
  *(_DWORD *)(a1 + 336) = *(_DWORD *)(a1 + 488);
  *(_DWORD *)(a1 + 348) = *(_DWORD *)(a1 + 500);
  *(void *)(a1 + 34std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = *(void *)(a1 + 492);
  *(_OWORD *)(a1 + 352) = *(_OWORD *)(a1 + 504);
  *(void *)(a1 + 368) = v3;
  int v6 = *(_DWORD *)(a1 + 556);
  *(_DWORD *)(a1 + 376) = *(_DWORD *)(a1 + 540);
  *(_DWORD *)(a1 + 38std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v6;
  long long v8 = *a3;
  long long v7 = a3[1];
  *(void *)(a1 + 28std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = *((void *)a3 + 4);
  *(_OWORD *)(a1 + 248) = v8;
  *(_OWORD *)(a1 + 264) = v7;
  if (*(void *)(a1 + 592)) {
    ZinAssertImpl("Unity kernels do not support zero points");
  }
  uint64_t v10 = (void *)(a1 + 248);
  uint64_t v11 = *(void *)(a1 + 568);
  if (v11)
  {
    *(unsigned char *)(a1 + 448) = v5 | 8;
    if (*(unsigned char *)(v11 + 288))
    {
      *(float *)(a1 + 18std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = ZinIrVector::GetSingularVal((ZinIrVector *)v11);
      uint64_t v11 = *(void *)(a1 + 568);
    }
    else
    {
      *(unsigned char *)(a1 + 185) = 1;
      if (!*(void *)(a1 + 248)) {
        *uint64_t v10 = *(void *)(v11 + 56);
      }
    }
    *(unsigned char *)(a1 + 184) = *(unsigned char *)(v11 + 280);
  }
  uint64_t result = *(void *)(a1 + 576);
  if (result)
  {
    *(unsigned char *)(a1 + 448) |= 0x10u;
    if (*(unsigned char *)(result + 288))
    {
      *(float *)(a1 + 188) = ZinIrVector::GetSingularVal((ZinIrVector *)result);
      uint64_t result = *(void *)(a1 + 576);
    }
    else
    {
      *(unsigned char *)(a1 + 193) = 1;
      uint64_t v13 = *(void *)(a1 + 248);
      uint64_t v14 = *(void *)(result + 56);
      if (v13)
      {
        if (v13 != v14 && v13 == *(int *)(a1 + 344) * (uint64_t)*(int *)(a1 + 348) * (v14 / *(int *)(a1 + 340))) {
          ZinAssertImpl("Number of channels in bias does not match the number of channels in kernel");
        }
      }
      else
      {
        *uint64_t v10 = v14;
      }
    }
    *(unsigned char *)(a1 + 192) = *(unsigned char *)(result + 280);
  }
  return result;
}

uint64_t ZinIrKernel::ZinIrKernel(uint64_t a1, long long *a2, uint64_t a3, uint64_t *a4, uint64_t *a5, uint64_t *a6, uint64_t a7, void *a8)
{
  long long v15 = *a2;
  *(void *)(a1 + 16) = *((void *)a2 + 2);
  *(_OWORD *)a1 = v15;
  *((void *)a2 + 1) = 0;
  *((void *)a2 + 2) = 0;
  *(void *)a2 = 0;
  std::string::basic_string[abi:ne180100]<0>((void *)(a1 + 24), &byte_211F4AA5D);
  *(unsigned char *)(a1 + 48) = 0;
  *(unsigned char *)(a1 + 156) = 0;
  *(unsigned char *)(a1 + 16std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  *(void *)(a1 + 164) = 0;
  *(_WORD *)(a1 + 172) = 0;
  memcpy((void *)(a1 + 176), (const void *)a3, 0x118uLL);
  *(int64x2_t *)(a1 + 456) = vdupq_n_s64(1uLL);
  *(void *)(a1 + 472) = 1;
  *(void *)&long long v16 = 0x100000001;
  *((void *)&v16 + 1) = 0x100000001;
  *(_OWORD *)(a1 + 48std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v16;
  *(void *)(a1 + 496) = 0x100000001;
  *(void *)(a1 + 52std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  *(void *)(a1 + 504) = 0;
  *(void *)(a1 + 512) = 0;
  *(_OWORD *)(a1 + 528) = v16;
  *(void *)(a1 + 544) = 1;
  *(_WORD *)(a1 + 552) = 0;
  *(_DWORD *)(a1 + 556) = 0;
  *(unsigned char *)(a1 + 56std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  uint64_t v17 = *a4;
  *a4 = 0;
  *(void *)(a1 + 568) = v17;
  uint64_t v18 = *a5;
  *a5 = 0;
  *(void *)(a1 + 576) = v18;
  *(void *)(a1 + 584) = 0;
  uint64_t v19 = *a6;
  *a6 = 0;
  *(void *)(a1 + 592) = v19;
  uint64_t v20 = a8[1];
  *(void *)(a1 + 60std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = *a8;
  *(void *)(a1 + 608) = v20;
  if (v20) {
    atomic_fetch_add_explicit((atomic_ullong *volatile)(v20 + 8), 1uLL, memory_order_relaxed);
  }
  uint64_t v21 = *(void *)(a7 + 8);
  *(void *)(a1 + 616) = *(void *)a7;
  *(void *)(a1 + 624) = v21;
  if (v21) {
    atomic_fetch_add_explicit((atomic_ullong *volatile)(v21 + 8), 1uLL, memory_order_relaxed);
  }
  uint64_t v22 = a1 + 568;
  uint64_t v23 = a1 + 576;
  uint64_t v24 = (ZinIrVector **)(a1 + 592);
  double v25 = ZinIrActivationParams::ZinIrActivationParams(a1 + 632, 0);
  *(void *)(a1 + 80std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  if (!*(void *)(a1 + 616)
    || *(void *)v22 && !*(unsigned char *)(*(void *)v22 + 288)
    || *(void *)v23 && !*(unsigned char *)(*(void *)v23 + 288)
    || *v24
    || (uint64_t v26 = *((void *)ZinIrTensor::GetRootTensor(*(ZinIrTensor **)a7) + 13)) == 0
    || *(_DWORD *)(v26 + 96) != 2)
  {
    ZinAssertImpl("Invalid kernel configuration", v25);
  }
  int v27 = ZinTensorFormatToKernelFormat(*(unsigned int *)(*(void *)(a1 + 616) + 88));
  *(_DWORD *)(a1 + 176) = v27;
  if (!v27) {
    ZinAssertImpl("Unexpected tensor format %d to convert to kernel format", *(_DWORD *)(*(void *)(a1 + 616) + 88));
  }
  char v29 = *(unsigned char *)(a1 + 448);
  *(unsigned char *)(a1 + 448) = v29 | 4;
  if (*(void *)(a1 + 600) && (v27 - 7) <= 0x14) {
    *(void *)(a1 + 416) = *(void *)(*a8 + 24);
  }
  uint64_t v30 = *(void *)v22;
  if (*(void *)v22)
  {
    *(unsigned char *)(a1 + 448) = v29 | 0xC;
    *(unsigned char *)(a1 + 184) = *(unsigned char *)(v30 + 280);
    if (*(unsigned char *)(v30 + 288))
    {
      *(float *)&double v28 = ZinIrVector::GetSingularVal((ZinIrVector *)v30);
      *(_DWORD *)(a1 + 18std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = LODWORD(v28);
    }
    else
    {
      *(unsigned char *)(a1 + 185) = 1;
      if (*(void *)(a1 + 248) != *(void *)(v30 + 56)) {
        goto LABEL_38;
      }
    }
  }
  uint64_t v31 = *(void *)v23;
  if (*(void *)v23)
  {
    *(unsigned char *)(a1 + 448) |= 0x10u;
    *(unsigned char *)(a1 + 192) = *(unsigned char *)(v31 + 280);
    if (*(unsigned char *)(v31 + 288))
    {
      *(float *)(a1 + 188) = ZinIrVector::GetSingularVal((ZinIrVector *)v31);
    }
    else
    {
      *(unsigned char *)(a1 + 193) = 1;
      uint64_t v32 = *(void *)(a1 + 248);
      uint64_t v33 = *(void *)(v31 + 56);
      if (v32 != v33 && v32 * *(int *)(a1 + 340) * *(int *)(a1 + 344) * *(int *)(a1 + 348) != v33) {
        goto LABEL_38;
      }
    }
  }
  if (*v24)
  {
    if (ZinIrVector::HasAllZero(*v24))
    {
      uint64_t v34 = (uint64_t)*v24;
      *uint64_t v24 = 0;
      if (!v34) {
        goto LABEL_35;
      }
      std::default_delete<ZinIrVector>::operator()[abi:ne180100](a1 + 592, v34);
    }
    uint64_t v35 = *v24;
    if (*v24)
    {
      *(unsigned char *)(a1 + 448) |= 2u;
      if (*((unsigned char *)v35 + 288))
      {
        *(float *)(a1 + 196) = ZinIrVector::GetSingularVal(v35);
        goto LABEL_35;
      }
      *(unsigned char *)(a1 + 201) = 1;
      uint64_t v36 = *(void *)(a1 + 248);
      uint64_t v37 = *((void *)v35 + 7);
      if (v36 != v37 && v36 * *(int *)(a1 + 340) * *(int *)(a1 + 344) * *(int *)(a1 + 348) != v37) {
LABEL_38:
      }
        ZinAssertImpl("Invalid dimensions", v28);
    }
  }
LABEL_35:
  ZinIrKernel::UpdateSHAContextForMemberVariables(a1, 2);
  uint64_t v38 = *(void *)(a3 + 152);
  *(_DWORD *)(a1 + 488) = *(_DWORD *)(a3 + 160);
  *(void *)(a1 + 48std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v38;
  uint64_t v39 = *(void *)(a3 + 164);
  *(_DWORD *)(a1 + 50std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = *(_DWORD *)(a3 + 172);
  *(void *)(a1 + 492) = v39;
  *(_DWORD *)(a1 + 54std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = *(_DWORD *)(a3 + 200);
  uint64_t v40 = *(void *)(a3 + 104);
  *(int8x16_t *)(a1 + 456) = vextq_s8(*(int8x16_t *)(a3 + 88), *(int8x16_t *)(a3 + 88), 8uLL);
  *(void *)(a1 + 472) = v40;
  uint64_t v41 = *(void *)(a3 + 208);
  *(_DWORD *)(a1 + 536) = *(_DWORD *)(a3 + 216);
  *(void *)(a1 + 528) = v41;
  long long v42 = *(_OWORD *)(a3 + 176);
  *(void *)(a1 + 52std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = *(void *)(a3 + 192);
  *(_OWORD *)(a1 + 504) = v42;
  *(void *)(a1 + 544) = *(void *)(a3 + 224);
  *(unsigned char *)(a1 + 552) = *(unsigned char *)(a3 + 272) >> 7;
  *(unsigned char *)(a1 + 553) = (*(unsigned char *)(a3 + 272) & 0x40) != 0;
  *(_DWORD *)(a1 + 556) = *(_DWORD *)(a3 + 204);
  return a1;
}

void sub_2113A4728(_Unwind_Exception *a1)
{
  std::unique_ptr<ZinMirAneKernel>::reset[abi:ne180100]((uint64_t *)(v1 + 800), 0);
  long long v7 = *(std::__shared_weak_count **)(v1 + 624);
  if (v7) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v7);
  }
  long long v8 = *(std::__shared_weak_count **)(v1 + 608);
  if (v8) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v8);
  }
  uint64_t v9 = *v5;
  *char v5 = 0;
  if (v9) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)v5, v9);
  }
  uint64_t v10 = *(void *)(v1 + 584);
  *(void *)(v1 + 584) = 0;
  if (v10) {
    (*(void (**)(uint64_t))(*(void *)v10 + 16))(v10);
  }
  uint64_t v11 = *v4;
  *char v4 = 0;
  if (v11) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)v4, v11);
  }
  uint64_t v12 = *v3;
  *uint64_t v3 = 0;
  if (v12) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)v3, v12);
  }
  if (*(char *)(v1 + 47) < 0) {
    operator delete(*v2);
  }
  if (*(char *)(v1 + 23) < 0) {
    operator delete(*(void **)v1);
  }
  _Unwind_Resume(a1);
}

uint64_t ZinIrKernel::GetPaletteVectorSize(ZinIrKernel *this)
{
  uint64_t v1 = *((void *)this + 75);
  if (v1 && (*((_DWORD *)this + 44) - 7) <= 0x14) {
    return *(void *)(v1 + 24);
  }
  else {
    return 1;
  }
}

uint64_t ZinIrKernel::ZinIrKernel(uint64_t a1, long long *a2, int a3, long long *a4, uint64_t *a5, uint64_t *a6, uint64_t *a7, uint64_t a8, int a9)
{
  long long v16 = *a2;
  *(void *)(a1 + 16) = *((void *)a2 + 2);
  *(_OWORD *)a1 = v16;
  *((void *)a2 + 1) = 0;
  *((void *)a2 + 2) = 0;
  *(void *)a2 = 0;
  std::string::basic_string[abi:ne180100]<0>((void *)(a1 + 24), &byte_211F4AA5D);
  *(unsigned char *)(a1 + 48) = 0;
  *(unsigned char *)(a1 + 156) = 0;
  *(unsigned char *)(a1 + 16std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  *(_DWORD *)(a1 + 188) = 0;
  *(_WORD *)(a1 + 192) = 0;
  *(_DWORD *)(a1 + 196) = 0;
  *(_WORD *)(a1 + 20std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  *(void *)(a1 + 164) = 0;
  *(_WORD *)(a1 + 172) = 0;
  *(void *)(a1 + 176) = 0;
  *(_WORD *)(a1 + 184) = 0;
  *(_OWORD *)(a1 + 208) = 0u;
  *(_OWORD *)(a1 + 224) = 0u;
  *(void *)(a1 + 24std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  int64x2_t v17 = vdupq_n_s64(1uLL);
  *(int64x2_t *)(a1 + 248) = v17;
  *(void *)(a1 + 264) = 1;
  *(int64x2_t *)(a1 + 272) = v17;
  *(int64x2_t *)(a1 + 288) = v17;
  *(int64x2_t *)(a1 + 304) = v17;
  *(void *)(a1 + 32std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 1;
  v17.i64[0] = 0x100000001;
  v17.i64[1] = 0x100000001;
  *(int64x2_t *)(a1 + 328) = v17;
  *(void *)(a1 + 344) = 0x100000001;
  *(void *)(a1 + 36std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  *(void *)(a1 + 368) = 0;
  *(void *)(a1 + 352) = 0;
  *(_OWORD *)(a1 + 376) = xmmword_211EDA8E0;
  *(_DWORD *)(a1 + 392) = 1;
  *(void *)(a1 + 40std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 1;
  *(_DWORD *)(a1 + 408) = 0;
  *(_DWORD *)(a1 + 448) = 0;
  *(void *)(a1 + 416) = 1;
  *(void *)(a1 + 424) = 0;
  *(void *)(a1 + 432) = 0;
  *(void *)(a1 + 44std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  long long v18 = *a4;
  long long v19 = a4[2];
  *(_OWORD *)(a1 + 472) = a4[1];
  *(_OWORD *)(a1 + 488) = v19;
  *(_OWORD *)(a1 + 456) = v18;
  long long v20 = a4[3];
  long long v21 = a4[4];
  long long v22 = a4[5];
  *(void *)(a1 + 552) = *((void *)a4 + 12);
  *(_OWORD *)(a1 + 52std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v21;
  *(_OWORD *)(a1 + 536) = v22;
  *(_OWORD *)(a1 + 504) = v20;
  *(unsigned char *)(a1 + 56std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  uint64_t v23 = *a6;
  *a6 = 0;
  *(void *)(a1 + 568) = v23;
  *(void *)(a1 + 576) = 0;
  uint64_t v24 = *a5;
  *a5 = 0;
  *(void *)(a1 + 584) = v24;
  uint64_t v25 = *a7;
  *a7 = 0;
  *(void *)(a1 + 592) = v25;
  *(_OWORD *)(a1 + 60std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0u;
  *(_OWORD *)(a1 + 616) = 0u;
  ZinIrActivationParams::ZinIrActivationParams(a1 + 632, 0);
  *(void *)(a1 + 80std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  uint64_t v26 = *(void *)(a1 + 584);
  if (v26)
  {
    uint64_t v27 = *(void *)(v26 + 280);
    if (v27)
    {
      if ((*(_DWORD *)(v26 + 8) - 7) <= 0x14)
      {
        uint64_t v28 = *(void *)(v26 + 288);
        if (v28) {
          atomic_fetch_add_explicit((atomic_ullong *volatile)(v28 + 8), 1uLL, memory_order_relaxed);
        }
        *(void *)(a1 + 60std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v27;
        char v29 = *(std::__shared_weak_count **)(a1 + 608);
        *(void *)(a1 + 608) = v28;
        if (v29) {
          std::__shared_weak_count::__release_shared[abi:ne180100](v29);
        }
      }
    }
  }
  ZinIrKernel::InitializeDescriptor(a1, a3, 1uLL);
  if (a8)
  {
    if (!*(unsigned char *)(a8 + 156)) {
      ZinAssertImpl("kernel with invalid sha.");
    }
    long long v30 = *(_OWORD *)(a8 + 52);
    long long v31 = *(_OWORD *)(a8 + 68);
    *(_OWORD *)(a1 + 84) = *(_OWORD *)(a8 + 84);
    *(_OWORD *)(a1 + 68) = v31;
    *(_OWORD *)(a1 + 52) = v30;
    long long v32 = *(_OWORD *)(a8 + 100);
    long long v33 = *(_OWORD *)(a8 + 116);
    long long v34 = *(_OWORD *)(a8 + 132);
    *(void *)(a1 + 148) = *(void *)(a8 + 148);
    *(_OWORD *)(a1 + 132) = v34;
    *(_OWORD *)(a1 + 116) = v33;
    *(_OWORD *)(a1 + 10std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v32;
    *(unsigned char *)(a1 + 156) = 1;
  }
  else
  {
    ZinIrKernel::UpdateSHAContextForMemberVariables(a1, a9);
  }
  return a1;
}

{
  return ZinIrKernel::ZinIrKernel(a1, a2, a3, a4, a5, a6, a7, a8, a9);
}

void sub_2113A4A6C(_Unwind_Exception *a1)
{
  std::unique_ptr<ZinMirAneKernel>::reset[abi:ne180100]((uint64_t *)(v1 + 800), 0);
  char v4 = *(std::__shared_weak_count **)(v1 + 624);
  if (v4) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v4);
  }
  char v5 = (uint64_t *)(v1 + 592);
  int v6 = *(std::__shared_weak_count **)(v1 + 608);
  if (v6) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v6);
  }
  uint64_t v7 = *v5;
  *char v5 = 0;
  if (v7) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100](v1 + 592, v7);
  }
  long long v8 = (uint64_t *)(v1 + 576);
  uint64_t v9 = *(void *)(v1 + 584);
  *(void *)(v1 + 584) = 0;
  if (v9) {
    (*(void (**)(uint64_t))(*(void *)v9 + 16))(v9);
  }
  uint64_t v10 = (uint64_t *)(v1 + 568);
  uint64_t v11 = *v8;
  *long long v8 = 0;
  if (v11) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100](v1 + 576, v11);
  }
  uint64_t v12 = *v10;
  *uint64_t v10 = 0;
  if (v12) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100](v1 + 568, v12);
  }
  if (*(char *)(v1 + 47) < 0) {
    operator delete(*v2);
  }
  if (*(char *)(v1 + 23) < 0) {
    operator delete(*(void **)v1);
  }
  _Unwind_Resume(a1);
}

uint64_t ZinIrKernel::ZinIrKernel(uint64_t a1, long long *a2, char *__src, long long *a4)
{
  long long v6 = *a2;
  *(void *)(a1 + 16) = *((void *)a2 + 2);
  *(_OWORD *)a1 = v6;
  *((void *)a2 + 1) = 0;
  *((void *)a2 + 2) = 0;
  *(void *)a2 = 0;
  if (*((char *)a4 + 23) < 0)
  {
    std::string::__init_copy_ctor_external((std::string *)(a1 + 24), *(const std::string::value_type **)a4, *((void *)a4 + 1));
  }
  else
  {
    long long v7 = *a4;
    *(void *)(a1 + 4std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = *((void *)a4 + 2);
    *(_OWORD *)(a1 + 24) = v7;
  }
  *(unsigned char *)(a1 + 48) = 1;
  *(unsigned char *)(a1 + 156) = 1;
  *(unsigned char *)(a1 + 16std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  *(void *)(a1 + 164) = 0;
  *(_WORD *)(a1 + 172) = 0;
  memcpy((void *)(a1 + 176), __src, 0x118uLL);
  *(int64x2_t *)(a1 + 456) = vdupq_n_s64(1uLL);
  *(void *)(a1 + 472) = 1;
  *(void *)&long long v8 = 0x100000001;
  *((void *)&v8 + 1) = 0x100000001;
  *(_OWORD *)(a1 + 48std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v8;
  *(void *)(a1 + 496) = 0x100000001;
  *(void *)(a1 + 52std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  *(void *)(a1 + 504) = 0;
  *(void *)(a1 + 512) = 0;
  *(_OWORD *)(a1 + 528) = v8;
  *(void *)(a1 + 544) = 1;
  *(_WORD *)(a1 + 552) = 0;
  *(_DWORD *)(a1 + 556) = 0;
  *(unsigned char *)(a1 + 56std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  *(_OWORD *)(a1 + 568) = 0u;
  *(_OWORD *)(a1 + 584) = 0u;
  *(_OWORD *)(a1 + 60std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0u;
  *(_OWORD *)(a1 + 616) = 0u;
  ZinIrActivationParams::ZinIrActivationParams(a1 + 632, 0);
  *(void *)(a1 + 80std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  uint64_t v9 = *((void *)__src + 19);
  *(_DWORD *)(a1 + 488) = *((_DWORD *)__src + 40);
  *(void *)(a1 + 48std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v9;
  uint64_t v10 = *(void *)(__src + 164);
  *(_DWORD *)(a1 + 50std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = *((_DWORD *)__src + 43);
  *(void *)(a1 + 492) = v10;
  *(_DWORD *)(a1 + 54std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = *((_DWORD *)__src + 50);
  uint64_t v11 = *((void *)__src + 13);
  *(int8x16_t *)(a1 + 456) = vextq_s8(*(int8x16_t *)(__src + 88), *(int8x16_t *)(__src + 88), 8uLL);
  *(void *)(a1 + 472) = v11;
  uint64_t v12 = *((void *)__src + 26);
  *(_DWORD *)(a1 + 536) = *((_DWORD *)__src + 54);
  *(void *)(a1 + 528) = v12;
  long long v13 = *((_OWORD *)__src + 11);
  *(void *)(a1 + 52std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = *((void *)__src + 24);
  *(_OWORD *)(a1 + 504) = v13;
  *(void *)(a1 + 544) = *((void *)__src + 28);
  *(unsigned char *)(a1 + 552) = __src[272] >> 7;
  *(unsigned char *)(a1 + 553) = (__src[272] & 0x40) != 0;
  *(_DWORD *)(a1 + 556) = *((_DWORD *)__src + 51);
  return a1;
}

void sub_2113A4CF8(_Unwind_Exception *exception_object)
{
  if (*(char *)(v1 + 23) < 0) {
    operator delete(*(void **)v1);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinIrKernel::ZinIrKernel(uint64_t a1, long long *a2, long long *a3, uint64_t a4)
{
  long long v7 = *a2;
  *(void *)(a1 + 16) = *((void *)a2 + 2);
  *(_OWORD *)a1 = v7;
  *((void *)a2 + 1) = 0;
  *((void *)a2 + 2) = 0;
  *(void *)a2 = 0;
  std::string::basic_string[abi:ne180100]<0>((void *)(a1 + 24), &byte_211F4AA5D);
  *(unsigned char *)(a1 + 48) = 0;
  *(unsigned char *)(a1 + 156) = 0;
  *(void *)(a1 + 16std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = *(void *)(a4 + 160);
  *(_DWORD *)(a1 + 168) = 0;
  *(_WORD *)(a1 + 172) = 0;
  *(_DWORD *)(a1 + 188) = 0;
  *(_WORD *)(a1 + 192) = 0;
  *(_DWORD *)(a1 + 196) = 0;
  *(_WORD *)(a1 + 20std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  *(void *)(a1 + 176) = 0;
  *(_WORD *)(a1 + 184) = 0;
  *(_OWORD *)(a1 + 208) = 0u;
  *(_OWORD *)(a1 + 224) = 0u;
  *(void *)(a1 + 24std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  int64x2_t v8 = vdupq_n_s64(1uLL);
  *(int64x2_t *)(a1 + 248) = v8;
  *(void *)(a1 + 264) = 1;
  *(int64x2_t *)(a1 + 272) = v8;
  *(int64x2_t *)(a1 + 288) = v8;
  *(int64x2_t *)(a1 + 304) = v8;
  *(void *)(a1 + 32std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 1;
  v8.i64[0] = 0x100000001;
  v8.i64[1] = 0x100000001;
  *(int64x2_t *)(a1 + 328) = v8;
  *(void *)(a1 + 344) = 0x100000001;
  *(void *)(a1 + 36std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  *(void *)(a1 + 368) = 0;
  *(void *)(a1 + 352) = 0;
  *(_OWORD *)(a1 + 376) = xmmword_211EDA8E0;
  *(_DWORD *)(a1 + 392) = 1;
  *(void *)(a1 + 40std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 1;
  *(_DWORD *)(a1 + 408) = 0;
  *(_DWORD *)(a1 + 448) = 0;
  *(void *)(a1 + 416) = 1;
  *(void *)(a1 + 424) = 0;
  *(void *)(a1 + 432) = 0;
  *(void *)(a1 + 44std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  long long v9 = *a3;
  long long v10 = a3[2];
  *(_OWORD *)(a1 + 472) = a3[1];
  *(_OWORD *)(a1 + 488) = v10;
  *(_OWORD *)(a1 + 456) = v9;
  long long v11 = a3[3];
  long long v12 = a3[4];
  long long v13 = a3[5];
  *(void *)(a1 + 552) = *((void *)a3 + 12);
  *(_OWORD *)(a1 + 52std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v12;
  *(_OWORD *)(a1 + 536) = v13;
  *(_OWORD *)(a1 + 504) = v11;
  *(unsigned char *)(a1 + 56std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = *(unsigned char *)(a4 + 560);
  if (*(void *)(a4 + 568)) {
    std::make_unique[abi:ne180100]<ZinIrVector,ZinIrVector&>();
  }
  *(void *)(a1 + 568) = 0;
  if (*(void *)(a4 + 576)) {
    std::make_unique[abi:ne180100]<ZinIrVector,ZinIrVector&>();
  }
  *(void *)(a1 + 576) = 0;
  if (*(void *)(a4 + 584)) {
    operator new();
  }
  *(void *)(a1 + 584) = 0;
  if (*(void *)(a4 + 592)) {
    std::make_unique[abi:ne180100]<ZinIrVector,ZinIrVector&>();
  }
  *(void *)(a1 + 592) = 0;
  *(void *)(a1 + 60std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = *(void *)(a4 + 600);
  uint64_t v14 = *(void *)(a4 + 608);
  *(void *)(a1 + 608) = v14;
  if (v14) {
    atomic_fetch_add_explicit((atomic_ullong *volatile)(v14 + 8), 1uLL, memory_order_relaxed);
  }
  *(void *)(a1 + 616) = *(void *)(a4 + 616);
  uint64_t v15 = *(void *)(a4 + 624);
  *(void *)(a1 + 624) = v15;
  if (v15) {
    atomic_fetch_add_explicit((atomic_ullong *volatile)(v15 + 8), 1uLL, memory_order_relaxed);
  }
  long long v16 = *(_OWORD *)(a4 + 632);
  long long v17 = *(_OWORD *)(a4 + 664);
  *(_OWORD *)(a1 + 648) = *(_OWORD *)(a4 + 648);
  *(_OWORD *)(a1 + 664) = v17;
  *(_OWORD *)(a1 + 632) = v16;
  long long v18 = *(_OWORD *)(a4 + 680);
  long long v19 = *(_OWORD *)(a4 + 696);
  long long v20 = *(_OWORD *)(a4 + 728);
  *(_OWORD *)(a1 + 712) = *(_OWORD *)(a4 + 712);
  *(_OWORD *)(a1 + 728) = v20;
  *(_OWORD *)(a1 + 68std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v18;
  *(_OWORD *)(a1 + 696) = v19;
  long long v21 = *(_OWORD *)(a4 + 744);
  long long v22 = *(_OWORD *)(a4 + 760);
  long long v23 = *(_OWORD *)(a4 + 776);
  *(void *)(a1 + 792) = *(void *)(a4 + 792);
  *(_OWORD *)(a1 + 76std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v22;
  *(_OWORD *)(a1 + 776) = v23;
  *(_OWORD *)(a1 + 744) = v21;
  *(void *)(a1 + 80std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  ZinIrKernel::InitializeDescriptor(a1, *(_DWORD *)(a4 + 176), 1uLL);
  if (!*(unsigned char *)(a4 + 156)) {
    ZinAssertImpl("kernel with invalid sha.");
  }
  long long v24 = *(_OWORD *)(a4 + 52);
  long long v25 = *(_OWORD *)(a4 + 68);
  *(_OWORD *)(a1 + 84) = *(_OWORD *)(a4 + 84);
  *(_OWORD *)(a1 + 68) = v25;
  *(_OWORD *)(a1 + 52) = v24;
  long long v26 = *(_OWORD *)(a4 + 100);
  long long v27 = *(_OWORD *)(a4 + 116);
  long long v28 = *(_OWORD *)(a4 + 132);
  *(void *)(a1 + 148) = *(void *)(a4 + 148);
  *(_OWORD *)(a1 + 132) = v28;
  *(_OWORD *)(a1 + 116) = v27;
  *(_OWORD *)(a1 + 10std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v26;
  *(unsigned char *)(a1 + 156) = 1;
  if (ZinIrConvInfo::NeedSHAUpdate(a1 + 456, a4 + 456))
  {
    CC_SHA256_Update((CC_SHA256_CTX *)(a1 + 52), "desc", 4u);
    ZinIrKernel::UpdateSHAContextForDescriptor((ZinIrKernel *)a1);
  }
  return a1;
}

void sub_2113A5098(_Unwind_Exception *exception_object)
{
  uint64_t v6 = *(void *)(v1 + 584);
  *(void *)(v1 + 584) = 0;
  if (v6) {
    (*(void (**)(uint64_t))(*(void *)v6 + 16))(v6);
  }
  uint64_t v7 = *v4;
  *char v4 = 0;
  if (v7) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)v4, v7);
  }
  uint64_t v8 = *v3;
  *uint64_t v3 = 0;
  if (v8) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)v3, v8);
  }
  if (*(char *)(v1 + 47) < 0) {
    operator delete(*v2);
  }
  if (*(char *)(v1 + 23) < 0) {
    operator delete(*(void **)v1);
  }
  _Unwind_Resume(exception_object);
}

unint64_t ZinIrKernel::BytesPerSerializedCoutElement(ZinIrKernel *this, const ZinKernelDescriptor *a2)
{
  return ZinKernelSizeEstimateUtil::EstimateKMEMFootprintPerCoutElement((ZinIrKernel *)((char *)this + 176), a2);
}

uint64_t ZinIrKernel::KernelExpansionFactor(ZinIrKernel *this)
{
  return *((int *)this + 86) * (uint64_t)*((int *)this + 85) * *((int *)this + 87);
}

uint64_t ZinIrKernel::GetPaletteData(ZinIrKernel *this, unint64_t a2)
{
  long long v2 = (uint64_t *)*((void *)this + 75);
  if (!v2 || (*((_DWORD *)this + 44) - 7) >= 0x15) {
    ZinAssertImpl("Error: This weight does not have palette info.");
  }
  uint64_t result = *v2;
  uint64_t v4 = v2[1];
  if (result == v4) {
    ZinAssertImpl("Error: Palette data is empty.");
  }
  uint64_t v5 = v4 - result;
  if ((unint64_t)v5 >= 0x11)
  {
    if (a2 >= v5 >> 4) {
      ZinAssertImpl("GetPaletteData: out of bound access.");
    }
    result += 16 * a2;
  }
  return result;
}

void ZinIrKernel::Partial(void *a1, uint64_t *a2, uint64_t a3)
{
  uint64_t v32 = *MEMORY[0x263EF8340];
  uint64_t v6 = (unsigned int *)(a1 + 22);
  memcpy(__dst, a1 + 22, sizeof(__dst));
  uint64_t v25 = 0;
  uint64_t v26 = 0;
  uint64_t v23 = 0;
  uint64_t v24 = 0;
  uint64_t v7 = a1[73];
  if (v7)
  {
    uint64_t v8 = (std::__shared_weak_count *)a2[1];
    uint64_t v30 = *a2;
    long long v31 = v8;
    if (v8) {
      atomic_fetch_add_explicit(&v8->__shared_owners_, 1uLL, memory_order_relaxed);
    }
    memset(&__p, 0, sizeof(__p));
    uint64_t data = &__p;
    char v29 = 0;
    __p.__r_.__value_.__r.__words[0] = (std::string::size_type)operator new(0x10uLL);
    __p.__r_.__value_.__l.__size_ = __p.__r_.__value_.__r.__words[0];
    __p.__r_.__value_.__r.__words[2] = __p.__r_.__value_.__r.__words[0] + 16;
    __p.__r_.__value_.__l.__size_ = (std::string::size_type)std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::shared_ptr<ZinIrWeightTransform>>,std::shared_ptr<ZinIrWeightTransform> const*,std::shared_ptr<ZinIrWeightTransform> const*,std::shared_ptr<ZinIrWeightTransform>*>((uint64_t)&__p.__r_.__value_.__r.__words[2], &v30, &v32, __p.__r_.__value_.__l.__data_);
    ZinIrWeight::Transform(v7, (uint64_t)&__p, &v26);
    uint64_t data = &__p;
    std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100]((void ***)&data);
    if (v31) {
      std::__shared_weak_count::__release_shared[abi:ne180100](v31);
    }
    uint64_t v9 = *(void *)(v26 + 56);
    __dst[4] = *(void *)(v26 + 16);
    __dst[9] = v9;
  }
  uint64_t v10 = a1[72];
  if (v10)
  {
    long long v11 = (std::__shared_weak_count *)a2[1];
    if (*a2) {
      uint64_t v12 = *a2 + 8;
    }
    else {
      uint64_t v12 = 0;
    }
    uint64_t v30 = v12;
    long long v31 = v11;
    if (v11) {
      atomic_fetch_add_explicit(&v11->__shared_owners_, 1uLL, memory_order_relaxed);
    }
    memset(&__p, 0, sizeof(__p));
    uint64_t data = &__p;
    char v29 = 0;
    __p.__r_.__value_.__r.__words[0] = (std::string::size_type)operator new(0x10uLL);
    __p.__r_.__value_.__l.__size_ = __p.__r_.__value_.__r.__words[0];
    __p.__r_.__value_.__r.__words[2] = __p.__r_.__value_.__r.__words[0] + 16;
    __p.__r_.__value_.__l.__size_ = (std::string::size_type)std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::shared_ptr<ZinIrVectorTransform>>,std::shared_ptr<ZinIrVectorTransform> const*,std::shared_ptr<ZinIrVectorTransform> const*,std::shared_ptr<ZinIrVectorTransform>*>((uint64_t)&__p.__r_.__value_.__r.__words[2], &v30, &v32, __p.__r_.__value_.__l.__data_);
    ZinIrVector::Transform(v10, (uint64_t)&__p, &v25);
    uint64_t data = &__p;
    std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100]((void ***)&data);
    if (v31) {
      std::__shared_weak_count::__release_shared[abi:ne180100](v31);
    }
    uint64_t v13 = *(void *)(v25 + 56);
    __dst[4] = *(void *)(v25 + 16);
    __dst[9] = v13;
  }
  uint64_t v14 = a1[71];
  if (v14)
  {
    uint64_t v15 = (std::__shared_weak_count *)a2[1];
    if (*a2) {
      uint64_t v16 = *a2 + 8;
    }
    else {
      uint64_t v16 = 0;
    }
    uint64_t v30 = v16;
    long long v31 = v15;
    if (v15) {
      atomic_fetch_add_explicit(&v15->__shared_owners_, 1uLL, memory_order_relaxed);
    }
    memset(&__p, 0, sizeof(__p));
    uint64_t data = &__p;
    char v29 = 0;
    __p.__r_.__value_.__r.__words[0] = (std::string::size_type)operator new(0x10uLL);
    __p.__r_.__value_.__l.__size_ = __p.__r_.__value_.__r.__words[0];
    __p.__r_.__value_.__r.__words[2] = __p.__r_.__value_.__r.__words[0] + 16;
    __p.__r_.__value_.__l.__size_ = (std::string::size_type)std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::shared_ptr<ZinIrVectorTransform>>,std::shared_ptr<ZinIrVectorTransform> const*,std::shared_ptr<ZinIrVectorTransform> const*,std::shared_ptr<ZinIrVectorTransform>*>((uint64_t)&__p.__r_.__value_.__r.__words[2], &v30, &v32, __p.__r_.__value_.__l.__data_);
    ZinIrVector::Transform(v14, (uint64_t)&__p, &v24);
    uint64_t data = &__p;
    std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100]((void ***)&data);
    if (v31) {
      std::__shared_weak_count::__release_shared[abi:ne180100](v31);
    }
    uint64_t v17 = *(void *)(v24 + 56);
    __dst[4] = *(void *)(v24 + 16);
    __dst[9] = v17;
  }
  uint64_t v18 = a1[74];
  if (v18)
  {
    if (a1[73] || a1[77])
    {
      if (!ZinKernelFormatIsQuantizationCompatible(*v6)) {
        ZinAssertImpl("kernel zero point is only supported for int8/uint8 kernels");
      }
      uint64_t v18 = a1[74];
    }
    long long v19 = (std::__shared_weak_count *)a2[1];
    if (*a2) {
      uint64_t v20 = *a2 + 8;
    }
    else {
      uint64_t v20 = 0;
    }
    uint64_t v30 = v20;
    long long v31 = v19;
    if (v19) {
      atomic_fetch_add_explicit(&v19->__shared_owners_, 1uLL, memory_order_relaxed);
    }
    memset(&__p, 0, sizeof(__p));
    uint64_t data = &__p;
    char v29 = 0;
    __p.__r_.__value_.__r.__words[0] = (std::string::size_type)operator new(0x10uLL);
    __p.__r_.__value_.__l.__size_ = __p.__r_.__value_.__r.__words[0];
    __p.__r_.__value_.__r.__words[2] = __p.__r_.__value_.__r.__words[0] + 16;
    __p.__r_.__value_.__l.__size_ = (std::string::size_type)std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::shared_ptr<ZinIrVectorTransform>>,std::shared_ptr<ZinIrVectorTransform> const*,std::shared_ptr<ZinIrVectorTransform> const*,std::shared_ptr<ZinIrVectorTransform>*>((uint64_t)&__p.__r_.__value_.__r.__words[2], &v30, &v32, __p.__r_.__value_.__l.__data_);
    ZinIrVector::Transform(v18, (uint64_t)&__p, &v23);
    uint64_t data = &__p;
    std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100]((void ***)&data);
    if (v31) {
      std::__shared_weak_count::__release_shared[abi:ne180100](v31);
    }
    uint64_t v21 = *(void *)(v23 + 56);
    __dst[4] = *(void *)(v23 + 16);
    __dst[9] = v21;
  }
  if (*(char *)(a3 + 23) < 0) {
    std::string::__init_copy_ctor_external(&__p, *(const std::string::value_type **)a3, *(void *)(a3 + 8));
  }
  else {
    std::string __p = *(std::string *)a3;
  }
  operator new();
}

void sub_2113A5788(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, void *__p, uint64_t a10, int a11, __int16 a12, char a13, char a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19)
{
  uint64_t v20 = a16;
  a16 = 0;
  if (v20) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&a16, v20);
  }
  uint64_t v21 = a17;
  a17 = 0;
  if (v21) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&a17, v21);
  }
  uint64_t v22 = a18;
  a18 = 0;
  if (v22) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&a18, v22);
  }
  uint64_t v23 = a19;
  a19 = 0;
  if (v23) {
    (*(void (**)(uint64_t))(*(void *)v23 + 16))(v23);
  }
  _Unwind_Resume(exception_object);
}

void *ZinIrKernel::FoldWeightsWithScale@<X0>(void *this@<X0>, ZinIrKernel *a2@<X1>, uint64_t a3@<X8>)
{
  v33[4] = *MEMORY[0x263EF8340];
  if (!this[72])
  {
    uint64_t v3 = this;
    if (!this[71] && !this[74])
    {
      uint64_t v5 = this[73];
      long long v6 = *(_OWORD *)(v5 + 72);
      long long v26 = *(_OWORD *)(v5 + 56);
      long long v27 = v6;
      uint64_t v28 = *(void *)(v5 + 88);
      v33[3] = 0;
      if (*((void *)a2 + 71))
      {
        __p[0] = &unk_26C388520;
        __p[1] = (char *)a2 + 568;
      }
      else
      {
        __p[0] = &unk_26C3884C8;
      }
      *((void *)&v30 + 1) = __p;
      std::__function::__value_func<float ()(unsigned long)>::swap[abi:ne180100](__p, v33);
      std::__function::__value_func<float ()(unsigned long)>::~__value_func[abi:ne180100](__p);
      _OWORD v32[3] = 0;
      if (*((void *)a2 + 72))
      {
        __p[0] = &unk_26C3885D0;
        __p[1] = (char *)a2 + 576;
      }
      else
      {
        __p[0] = &unk_26C388578;
      }
      *((void *)&v30 + 1) = __p;
      std::__function::__value_func<float ()(unsigned long)>::swap[abi:ne180100](__p, v32);
      std::__function::__value_func<float ()(unsigned long)>::~__value_func[abi:ne180100](__p);
      v25[4] = 0;
      if (*((void *)a2 + 72))
      {
        std::vector<float>::vector(__p, v26);
        if ((void)v26)
        {
          unint64_t v7 = 0;
          do
          {
            std::function<float ()(unsigned long)>::operator()((uint64_t)v32, v7);
            float v9 = v8;
            std::function<float ()(unsigned long)>::operator()((uint64_t)v33, v7);
            *((float *)__p[0] + v7++) = v9 * v10;
          }
          while (v7 < (unint64_t)v26);
        }
        std::allocate_shared[abi:ne180100]<ZinIrConstData_specialization<float>,std::allocator<ZinIrConstData_specialization<float>>,std::vector<float>,void>((uint64_t)__p, v25);
        operator new();
      }
      details::ZinIrMappedData_Impl<float>::ZinIrMappedData_Impl((uint64_t)v25, *((void *)&v26 + 1) * v26 * v27 * *((void *)&v27 + 1) * v28);
      int v11 = (*(uint64_t (**)(uint64_t))(*(void *)details::ZinIrMappedDataBase_Impl::backing_ + 24))(details::ZinIrMappedDataBase_Impl::backing_);
      uint64_t v31 = 0;
      *(_OWORD *)std::string __p = 0u;
      long long v30 = 0u;
      uint64_t v12 = v26;
      if ((uint64_t)v26 >= 1)
      {
        uint64_t v13 = 0;
        if (v11) {
          uint64_t v14 = (float *)v25[1];
        }
        else {
          uint64_t v14 = (float *)v25;
        }
        uint64_t v15 = *((void *)&v26 + 1);
        do
        {
          __p[1] = 0;
          if (v15 >= 1)
          {
            uint64_t v16 = 0;
            uint64_t v17 = v27;
            do
            {
              *(void *)&long long v30 = 0;
              if (v17 >= 1)
              {
                uint64_t v18 = 0;
                uint64_t v19 = *((void *)&v27 + 1);
                do
                {
                  *((void *)&v30 + 1) = 0;
                  if (v19 >= 1)
                  {
                    uint64_t v20 = 0;
                    uint64_t v21 = v28;
                    do
                    {
                      uint64_t v31 = 0;
                      if (v21 >= 1)
                      {
                        do
                        {
                          ZinIrWeightBase::GetAt<float>(v3[73]);
                          float v23 = v22;
                          std::function<float ()(unsigned long)>::operator()((uint64_t)v33, (uint64_t)__p[0]);
                          *v14++ = v23 * v24;
                          ++v31;
                          uint64_t v21 = v28;
                        }
                        while (v31 < v28);
                        uint64_t v20 = *((void *)&v30 + 1);
                        uint64_t v19 = *((void *)&v27 + 1);
                      }
                      *((void *)&v30 + 1) = ++v20;
                    }
                    while (v20 < v19);
                    uint64_t v18 = v30;
                    uint64_t v17 = v27;
                  }
                  *(void *)&long long v30 = ++v18;
                }
                while (v18 < v17);
                uint64_t v16 = (char *)__p[1];
                uint64_t v15 = *((void *)&v26 + 1);
              }
              __p[1] = ++v16;
            }
            while ((uint64_t)v16 < v15);
            uint64_t v13 = (char *)__p[0];
            uint64_t v12 = v26;
          }
          __p[0] = ++v13;
        }
        while ((uint64_t)v13 < v12);
      }
      std::allocate_shared[abi:ne180100]<ZinIrScratchBufferBackedConstData_specialization<float>,std::allocator<ZinIrScratchBufferBackedConstData_specialization<float>>,ZinIrScratchBuffer<float>,void>((uint64_t)v25, __p);
      __p[0] = 0;
      std::make_unique[abi:ne180100]<ZinIrWeight,std::shared_ptr<ZinIrConstData> &,decltype(nullptr),ZinKernelFormat,ZinKernelDimensions &>();
    }
  }
  *(_DWORD *)a3 = 3;
  *(void *)(a3 + 8) = 0;
  *(void *)(a3 + 16) = 0;
  return this;
}

void sub_2113A5FA8(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, char a12, void *__p, uint64_t a14, int a15, __int16 a16, char a17, char a18, ZinIrKernel *a19, uint64_t a20,uint64_t a21,uint64_t a22,std::__shared_weak_count *a23,uint64_t a24,char a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33,uint64_t a34,uint64_t a35,void *a36,uint64_t a37)
{
  if (a18 < 0) {
    operator delete(__p);
  }
  std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a19, 0);
  uint64_t v39 = a21;
  a21 = 0;
  if (v39) {
    (*(void (**)(uint64_t))(*(void *)v39 + 16))(v39);
  }
  if (a23) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a23);
  }
  details::ZinIrMappedData_Impl<float>::~ZinIrMappedData_Impl((uint64_t)&a25);
  uint64_t v40 = a29;
  a29 = 0;
  if (v40) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&a29, v40);
  }
  std::__function::__value_func<float ()(unsigned long)>::~__value_func[abi:ne180100]((void *)(v37 - 168));
  std::__function::__value_func<float ()(unsigned long)>::~__value_func[abi:ne180100]((void *)(v37 - 136));
  _Unwind_Resume(a1);
}

void std::make_unique[abi:ne180100]<ZinIrKernel,std::string,ZinKernelDescriptor &,std::unique_ptr<ZinIrWeight>,decltype(nullptr),decltype(nullptr),decltype(nullptr),SHAUpdateMode const&>()
{
}

void sub_2113A61C4(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va2, a2);
  va_start(va1, a2);
  va_start(va, a2);
  uint64_t v5 = va_arg(va1, void);
  va_copy(va2, va1);
  uint64_t v7 = va_arg(va2, void);
  uint64_t v4 = v5;
  uint64_t v5 = 0;
  if (v4) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)va, v4);
  }
  std::make_unique[abi:ne180100]<ZinIrKernel,std::string,ZinKernelDescriptor &,std::unique_ptr<ZinIrWeight>,decltype(nullptr),decltype(nullptr),decltype(nullptr)>((uint64_t)va, (uint64_t *)va1, (uint64_t *)va2);
  MEMORY[0x21667D3C0](v2, 0x1032C40C25AA5B7);
  _Unwind_Resume(a1);
}

void std::make_unique[abi:ne180100]<ZinIrKernel,std::string,ZinKernelDescriptor &,decltype(nullptr),decltype(nullptr),std::unique_ptr<ZinIrVector>,decltype(nullptr),SHAUpdateMode const&>()
{
}

void sub_2113A62F0(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va2, a2);
  va_start(va1, a2);
  va_start(va, a2);
  uint64_t v5 = va_arg(va1, void);
  va_copy(va2, va1);
  uint64_t v7 = va_arg(va2, void);
  uint64_t v4 = v5;
  uint64_t v5 = 0;
  if (v4) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)va, v4);
  }
  std::make_unique[abi:ne180100]<ZinIrKernel,std::string,ZinKernelDescriptor &,decltype(nullptr),decltype(nullptr),std::unique_ptr<ZinIrVector>,decltype(nullptr),SHAUpdateMode const&>((uint64_t)va, (uint64_t *)va1, (uint64_t *)va2);
  MEMORY[0x21667D3C0](v2, 0x1032C40C25AA5B7);
  _Unwind_Resume(a1);
}

void ZinIrKernel::FoldKernelQuantDataIntoWeight(ZinIrKernel *this@<X0>, void *a2@<X8>)
{
  if ((*((unsigned char *)this + 448) & 2) != 0)
  {
    unsigned __int8 v19 = 0;
    ZinFoldKernelQuantInfoIntoWeight((uint64_t *)this + 73, *((int **)this + 74), *((ZinIrVector **)this + 71), &v19, &v18);
    if (v18)
    {
      if (*((char *)this + 23) >= 0) {
        size_t v4 = *((unsigned __int8 *)this + 23);
      }
      else {
        size_t v4 = *((void *)this + 1);
      }
      if (v19) {
        uint64_t v5 = "_zero_point_and_scale_folded";
      }
      else {
        uint64_t v5 = "_zero_point_folded";
      }
      if (v19) {
        size_t v6 = 28;
      }
      else {
        size_t v6 = 18;
      }
      uint64_t v7 = v16;
      std::string::basic_string[abi:ne180100]((uint64_t)v16, v4 + v6);
      if (v17 < 0) {
        uint64_t v7 = (void *)v16[0];
      }
      if (v4)
      {
        if (*((char *)this + 23) >= 0) {
          float v8 = this;
        }
        else {
          float v8 = *(ZinIrKernel **)this;
        }
        memmove(v7, v8, v4);
      }
      float v9 = (char *)v7 + v4;
      memcpy(v9, v5, v6);
      v9[v6] = 0;
      char v10 = *((unsigned char *)this + 448);
      if ((v10 & 8) != 0 && !v19) {
        std::make_unique[abi:ne180100]<ZinIrVector,ZinIrVector&>();
      }
      uint64_t v15 = 0;
      if ((v10 & 0x10) == 0)
      {
        uint64_t v14 = 0;
        memcpy(__dst, (char *)this + 176, sizeof(__dst));
        int v11 = *(_DWORD *)(v18 + 8);
        char v12 = __dst[68];
        LOBYTE(__dst[68]) &= ~2u;
        __dst[0] = v11;
        __dst[5] = 0;
        LOWORD(__dst[6]) = 0;
        LOBYTE(__dst[68]) = v12 & 0xF5;
        __dst[1] = 0;
        LOWORD(__dst[2]) = 0;
        operator new();
      }
      std::make_unique[abi:ne180100]<ZinIrVector,ZinIrVector&>();
    }
  }
  *a2 = 0;
}

void sub_2113A6594(_Unwind_Exception *exception_object)
{
  uint64_t v3 = *(void *)(v1 - 120);
  *(void *)(v1 - 12std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  if (v3) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100](v1 - 120, v3);
  }
  if (*(char *)(v1 - 89) < 0) {
    operator delete(*(void **)(v1 - 112));
  }
  uint64_t v4 = *(void *)(v1 - 88);
  *(void *)(v1 - 88) = 0;
  if (v4) {
    (*(void (**)(uint64_t))(*(void *)v4 + 16))(v4);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinIrKernel::RemapWeightForUnflatten@<X0>(uint64_t a1@<X0>, const ZinTensorDimensions *a2@<X2>, void *a3@<X8>)
{
  uint64_t v29 = *MEMORY[0x263EF8340];
  uint64_t v24 = 0;
  std::allocate_shared[abi:ne180100]<ZinIrTransformRemap,std::allocator<ZinIrTransformRemap>,ZinTensorDimensions const&,void>(a2, &v22);
  uint64_t v5 = *(void *)(a1 + 584);
  if (v5)
  {
    if (v22) {
      uint64_t v6 = v22 + 8;
    }
    else {
      uint64_t v6 = 0;
    }
    uint64_t v27 = v6;
    uint64_t v28 = v23;
    if (v23) {
      atomic_fetch_add_explicit(&v23->__shared_owners_, 1uLL, memory_order_relaxed);
    }
    unsigned __int8 v19 = 0;
    uint64_t v20 = 0;
    uint64_t v21 = 0;
    uint64_t v25 = (void **)&v19;
    char v26 = 0;
    unsigned __int8 v19 = operator new(0x10uLL);
    uint64_t v20 = v19;
    uint64_t v21 = v19 + 2;
    uint64_t v20 = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::shared_ptr<ZinIrWeightTransform>>,std::shared_ptr<ZinIrWeightTransform> const*,std::shared_ptr<ZinIrWeightTransform> const*,std::shared_ptr<ZinIrWeightTransform>*>((uint64_t)&v21, &v27, &v29, v19);
    ZinIrWeight::Transform(v5, (uint64_t)&v19, &v24);
    uint64_t v25 = (void **)&v19;
    std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100](&v25);
    if (v28) {
      std::__shared_weak_count::__release_shared[abi:ne180100](v28);
    }
    if (!v24) {
      goto LABEL_16;
    }
  }
  uint64_t v18 = 0;
  uint64_t v7 = *(void *)(a1 + 568);
  if (*(unsigned char *)(a1 + 185))
  {
    uint64_t v27 = v22;
    uint64_t v28 = v23;
    if (v23) {
      atomic_fetch_add_explicit(&v23->__shared_owners_, 1uLL, memory_order_relaxed);
    }
    unsigned __int8 v19 = 0;
    uint64_t v20 = 0;
    uint64_t v21 = 0;
    uint64_t v25 = (void **)&v19;
    char v26 = 0;
    unsigned __int8 v19 = operator new(0x10uLL);
    uint64_t v20 = v19;
    uint64_t v21 = v19 + 2;
    uint64_t v20 = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::shared_ptr<ZinIrVectorTransform>>,std::shared_ptr<ZinIrVectorTransform> const*,std::shared_ptr<ZinIrVectorTransform> const*,std::shared_ptr<ZinIrVectorTransform>*>((uint64_t)&v21, &v27, &v29, v19);
    ZinIrVector::Transform(v7, (uint64_t)&v19, (uint64_t *)&v18);
    uint64_t v25 = (void **)&v19;
    std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100](&v25);
    if (v28) {
      std::__shared_weak_count::__release_shared[abi:ne180100](v28);
    }
    if (!v18)
    {
LABEL_16:
      *a3 = 0;
      goto LABEL_42;
    }
  }
  else if (v7)
  {
    ZinIrVector::Clone(*(ZinIrVector **)(a1 + 568), (uint64_t *)&v19);
    float v8 = v19;
    uint64_t v18 = v19;
    unsigned __int8 v19 = 0;
    if (!v8) {
      ZinAssertImpl("Failed to clone scale");
    }
  }
  char v17 = 0;
  uint64_t v9 = *(void *)(a1 + 576);
  if (!*(unsigned char *)(a1 + 193))
  {
    if (v9)
    {
      ZinIrVector::Clone(*(ZinIrVector **)(a1 + 576), (uint64_t *)&v19);
      char v10 = v19;
      unsigned __int8 v19 = 0;
      char v17 = v10;
      if (!v10) {
        ZinAssertImpl("Failed to clone bias");
      }
    }
LABEL_28:
    uint64_t v16 = 0;
    uint64_t v11 = *(void *)(a1 + 592);
    if (*(unsigned char *)(a1 + 201))
    {
      uint64_t v27 = v22;
      uint64_t v28 = v23;
      if (v23) {
        atomic_fetch_add_explicit(&v23->__shared_owners_, 1uLL, memory_order_relaxed);
      }
      unsigned __int8 v19 = 0;
      uint64_t v20 = 0;
      uint64_t v21 = 0;
      uint64_t v25 = (void **)&v19;
      char v26 = 0;
      unsigned __int8 v19 = operator new(0x10uLL);
      uint64_t v20 = v19;
      uint64_t v21 = v19 + 2;
      uint64_t v20 = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::shared_ptr<ZinIrVectorTransform>>,std::shared_ptr<ZinIrVectorTransform> const*,std::shared_ptr<ZinIrVectorTransform> const*,std::shared_ptr<ZinIrVectorTransform>*>((uint64_t)&v21, &v27, &v29, v19);
      ZinIrVector::Transform(v11, (uint64_t)&v19, (uint64_t *)&v16);
      uint64_t v25 = (void **)&v19;
      std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100](&v25);
      if (v28) {
        std::__shared_weak_count::__release_shared[abi:ne180100](v28);
      }
      if (!v16)
      {
        *a3 = 0;
        uint64_t v13 = (uint64_t)v17;
        char v17 = 0;
        if (v13) {
          std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&v17, v13);
        }
        goto LABEL_40;
      }
    }
    else if (v11)
    {
      ZinIrVector::Clone(*(ZinIrVector **)(a1 + 592), (uint64_t *)&v19);
      char v12 = v19;
      unsigned __int8 v19 = 0;
      uint64_t v16 = v12;
      if (!v12) {
        ZinAssertImpl("Failed to clone zero point");
      }
    }
    operator new();
  }
  uint64_t v27 = v22;
  uint64_t v28 = v23;
  if (v23) {
    atomic_fetch_add_explicit(&v23->__shared_owners_, 1uLL, memory_order_relaxed);
  }
  unsigned __int8 v19 = 0;
  uint64_t v20 = 0;
  uint64_t v21 = 0;
  uint64_t v25 = (void **)&v19;
  char v26 = 0;
  unsigned __int8 v19 = operator new(0x10uLL);
  uint64_t v20 = v19;
  uint64_t v21 = v19 + 2;
  uint64_t v20 = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::shared_ptr<ZinIrVectorTransform>>,std::shared_ptr<ZinIrVectorTransform> const*,std::shared_ptr<ZinIrVectorTransform> const*,std::shared_ptr<ZinIrVectorTransform>*>((uint64_t)&v21, &v27, &v29, v19);
  ZinIrVector::Transform(v9, (uint64_t)&v19, (uint64_t *)&v17);
  uint64_t v25 = (void **)&v19;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100](&v25);
  if (v28) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v28);
  }
  if (v17) {
    goto LABEL_28;
  }
  *a3 = 0;
LABEL_40:
  uint64_t v14 = (uint64_t)v18;
  uint64_t v18 = 0;
  if (v14) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&v18, v14);
  }
LABEL_42:
  if (v23) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v23);
  }
  uint64_t result = v24;
  uint64_t v24 = 0;
  if (result) {
    return (*(uint64_t (**)(uint64_t))(*(void *)result + 16))(result);
  }
  return result;
}

void sub_2113A6BD4(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, std::__shared_weak_count *a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21)
{
  uint64_t v22 = a9;
  a9 = 0;
  if (v22) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&a9, v22);
  }
  uint64_t v23 = a10;
  a10 = 0;
  if (v23) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&a10, v23);
  }
  uint64_t v24 = a11;
  a11 = 0;
  if (v24) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&a11, v24);
  }
  if (a16) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a16);
  }
  uint64_t v25 = a17;
  a17 = 0;
  if (v25) {
    (*(void (**)(uint64_t))(*(void *)v25 + 16))(v25);
  }
  _Unwind_Resume(exception_object);
}

void ZinIrKernel::ShuffleChannels(uint64_t a1@<X0>, uint64_t a2@<X2>, void *a3@<X8>)
{
  uint64_t v45 = *MEMORY[0x263EF8340];
  memcpy(__dst, (const void *)(a1 + 176), sizeof(__dst));
  __n128 __p = 0uLL;
  uint64_t v39 = 0;
  std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(&__p, *(const void **)a2, *(void *)(a2 + 8), (uint64_t)(*(void *)(a2 + 8) - *(void *)a2) >> 3);
  *(void *)&long long v29 = *(void *)(a1 + 592);
  std::allocate_shared[abi:ne180100]<ZinIrTransformShuffle,std::allocator<ZinIrTransformShuffle>,std::vector<unsigned long>,ZinIrVector *,void>(&__p, (unint64_t *)&v29, &v36);
  uint64_t v35 = 0;
  uint64_t v6 = *(void *)(a1 + 584);
  if (v6)
  {
    if (v36) {
      uint64_t v7 = v36 + 8;
    }
    else {
      uint64_t v7 = 0;
    }
    uint64_t v43 = v7;
    uint64_t v44 = v37;
    if (v37) {
      atomic_fetch_add_explicit(&v37->__shared_owners_, 1uLL, memory_order_relaxed);
    }
    long long v29 = 0uLL;
    *(void *)&long long v30 = 0;
    uint64_t v41 = (void **)&v29;
    char v42 = 0;
    *(void *)&long long v29 = operator new(0x10uLL);
    *((void *)&v29 + 1) = v29;
    *(void *)&long long v30 = v29 + 16;
    *((void *)&v29 + 1) = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::shared_ptr<ZinIrWeightTransform>>,std::shared_ptr<ZinIrWeightTransform> const*,std::shared_ptr<ZinIrWeightTransform> const*,std::shared_ptr<ZinIrWeightTransform>*>((uint64_t)&v30, &v43, &v45, (void *)v29);
    ZinIrWeight::Transform(v6, (uint64_t)&v29, (uint64_t *)&v35);
    uint64_t v41 = (void **)&v29;
    std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100](&v41);
    if (v44) {
      std::__shared_weak_count::__release_shared[abi:ne180100](v44);
    }
    if (!v35)
    {
      *a3 = 0;
      goto LABEL_65;
    }
    long long v8 = *(_OWORD *)((char *)v35 + 56);
    long long v9 = *(_OWORD *)((char *)v35 + 72);
    *(void *)&__dst[104] = *((void *)v35 + 11);
    *(_OWORD *)&__dst[88] = v9;
    *(_OWORD *)&__dst[72] = v8;
    long long v10 = *((_OWORD *)v35 + 1);
    long long v11 = *((_OWORD *)v35 + 2);
    *(void *)&__dst[64] = *((void *)v35 + 6);
    *(_OWORD *)&__dst[32] = v10;
    *(_OWORD *)&__dst[48] = v11;
    uint64_t v12 = *(void *)(a1 + 584);
    if (*(void *)(v12 + 280) && (*(_DWORD *)(v12 + 8) - 7) <= 0x14)
    {
      if (ZinIrWeight::IsFirstPaletteLUTEntryNonZero(v35)) {
        char v13 = 32;
      }
      else {
        char v13 = 0;
      }
      __dst[272] = __dst[272] & 0xDF | v13;
      *(void *)&__dst[240] = ZinIrWeight::GetPaletteVectorSize(v35);
    }
  }
  uint64_t v34 = 0;
  uint64_t v14 = *(void *)(a1 + 568);
  if (!*(unsigned char *)(a1 + 185))
  {
    if (v14)
    {
      ZinIrVector::Clone(*(ZinIrVector **)(a1 + 568), (uint64_t *)&v29);
      uint64_t v15 = v29;
      *(void *)&long long v29 = 0;
      uint64_t v16 = v34;
      uint64_t v34 = v15;
      if (v16)
      {
        std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&v34, v16);
        uint64_t v17 = v29;
        *(void *)&long long v29 = 0;
        if (v17) {
          std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&v29, v17);
        }
        uint64_t v15 = v34;
      }
      if (!v15) {
        ZinAssertImpl("Failed to clone scale");
      }
    }
LABEL_29:
    uint64_t v33 = 0;
    uint64_t v18 = *(void *)(a1 + 576);
    if (*(unsigned char *)(a1 + 193))
    {
      uint64_t v43 = v36;
      uint64_t v44 = v37;
      if (v37) {
        atomic_fetch_add_explicit(&v37->__shared_owners_, 1uLL, memory_order_relaxed);
      }
      long long v29 = 0uLL;
      *(void *)&long long v30 = 0;
      uint64_t v41 = (void **)&v29;
      char v42 = 0;
      *(void *)&long long v29 = operator new(0x10uLL);
      *((void *)&v29 + 1) = v29;
      *(void *)&long long v30 = v29 + 16;
      *((void *)&v29 + 1) = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::shared_ptr<ZinIrVectorTransform>>,std::shared_ptr<ZinIrVectorTransform> const*,std::shared_ptr<ZinIrVectorTransform> const*,std::shared_ptr<ZinIrVectorTransform>*>((uint64_t)&v30, &v43, &v45, (void *)v29);
      ZinIrVector::Transform(v18, (uint64_t)&v29, &v33);
      uint64_t v41 = (void **)&v29;
      std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100](&v41);
      if (v44) {
        std::__shared_weak_count::__release_shared[abi:ne180100](v44);
      }
      if (!v33)
      {
        *a3 = 0;
LABEL_61:
        uint64_t v27 = v34;
        uint64_t v34 = 0;
        if (v27) {
          std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&v34, v27);
        }
        goto LABEL_63;
      }
      *(void *)&__dst[72] = *(void *)(v33 + 56);
    }
    else if (v18)
    {
      ZinIrVector::Clone(*(ZinIrVector **)(a1 + 576), (uint64_t *)&v29);
      uint64_t v19 = v29;
      *(void *)&long long v29 = 0;
      uint64_t v20 = v33;
      uint64_t v33 = v19;
      if (v20)
      {
        std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&v33, v20);
        uint64_t v21 = v29;
        *(void *)&long long v29 = 0;
        if (v21) {
          std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&v29, v21);
        }
        uint64_t v19 = v33;
      }
      if (!v19) {
        ZinAssertImpl("Failed to clone bias");
      }
    }
    uint64_t v32 = 0;
    uint64_t v22 = *(void *)(a1 + 592);
    if (!*(unsigned char *)(a1 + 201))
    {
      if (v22)
      {
        ZinIrVector::Clone(*(ZinIrVector **)(a1 + 592), (uint64_t *)&v29);
        uint64_t v23 = v29;
        *(void *)&long long v29 = 0;
        uint64_t v24 = v32;
        uint64_t v32 = v23;
        if (v24)
        {
          std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&v32, v24);
          uint64_t v25 = v29;
          *(void *)&long long v29 = 0;
          if (v25) {
            std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&v29, v25);
          }
          uint64_t v23 = v32;
        }
        if (!v23) {
          ZinAssertImpl("Failed to clone zero point");
        }
      }
LABEL_57:
      ZinKernelDescriptorStrides((int *)&__dst[152], (int *)&__dst[164], &__dst[72], &__dst[176], &v29);
      *(_OWORD *)&__dst[112] = v29;
      *(_OWORD *)&__dst[128] = v30;
      *(void *)&__dst[144] = v31;
      operator new();
    }
    uint64_t v43 = v36;
    uint64_t v44 = v37;
    if (v37) {
      atomic_fetch_add_explicit(&v37->__shared_owners_, 1uLL, memory_order_relaxed);
    }
    long long v29 = 0uLL;
    *(void *)&long long v30 = 0;
    uint64_t v41 = (void **)&v29;
    char v42 = 0;
    *(void *)&long long v29 = operator new(0x10uLL);
    *((void *)&v29 + 1) = v29;
    *(void *)&long long v30 = v29 + 16;
    *((void *)&v29 + 1) = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::shared_ptr<ZinIrVectorTransform>>,std::shared_ptr<ZinIrVectorTransform> const*,std::shared_ptr<ZinIrVectorTransform> const*,std::shared_ptr<ZinIrVectorTransform>*>((uint64_t)&v30, &v43, &v45, (void *)v29);
    ZinIrVector::Transform(v22, (uint64_t)&v29, &v32);
    uint64_t v41 = (void **)&v29;
    std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100](&v41);
    if (v44) {
      std::__shared_weak_count::__release_shared[abi:ne180100](v44);
    }
    if (v32)
    {
      *(void *)&__dst[72] = *(void *)(v32 + 56);
      goto LABEL_57;
    }
    *a3 = 0;
    uint64_t v26 = v33;
    uint64_t v33 = 0;
    if (v26) {
      std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&v33, v26);
    }
    goto LABEL_61;
  }
  uint64_t v43 = v36;
  uint64_t v44 = v37;
  if (v37) {
    atomic_fetch_add_explicit(&v37->__shared_owners_, 1uLL, memory_order_relaxed);
  }
  long long v29 = 0uLL;
  *(void *)&long long v30 = 0;
  uint64_t v41 = (void **)&v29;
  char v42 = 0;
  *(void *)&long long v29 = operator new(0x10uLL);
  *((void *)&v29 + 1) = v29;
  *(void *)&long long v30 = v29 + 16;
  *((void *)&v29 + 1) = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::shared_ptr<ZinIrVectorTransform>>,std::shared_ptr<ZinIrVectorTransform> const*,std::shared_ptr<ZinIrVectorTransform> const*,std::shared_ptr<ZinIrVectorTransform>*>((uint64_t)&v30, &v43, &v45, (void *)v29);
  ZinIrVector::Transform(v14, (uint64_t)&v29, &v34);
  uint64_t v41 = (void **)&v29;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100](&v41);
  if (v44) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v44);
  }
  if (v34)
  {
    *(void *)&__dst[72] = *(void *)(v34 + 56);
    goto LABEL_29;
  }
  *a3 = 0;
LABEL_63:
  uint64_t v28 = v35;
  uint64_t v35 = 0;
  if (v28) {
    (*(void (**)(ZinIrWeight *))(*(void *)v28 + 16))(v28);
  }
LABEL_65:
  if (v37) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v37);
  }
  if (__p.n128_u64[0])
  {
    __p.n128_u64[1] = __p.n128_u64[0];
    operator delete((void *)__p.n128_u64[0]);
  }
}

void sub_2113A7428(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, std::__shared_weak_count *a19, void *__p,uint64_t a21)
{
  uint64_t v22 = a14;
  a14 = 0;
  if (v22) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&a14, v22);
  }
  uint64_t v23 = a15;
  a15 = 0;
  if (v23) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&a15, v23);
  }
  uint64_t v24 = a16;
  a16 = 0;
  if (v24) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&a16, v24);
  }
  uint64_t v25 = a17;
  a17 = 0;
  if (v25) {
    (*(void (**)(uint64_t))(*(void *)v25 + 16))(v25);
  }
  if (a19) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a19);
  }
  if (__p)
  {
    a21 = (uint64_t)__p;
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

void ZinIrKernel::DuplicateChannels(uint64_t a1@<X0>, uint64_t a2@<X2>, void *a3@<X8>)
{
  uint64_t v20 = *MEMORY[0x263EF8340];
  uint64_t data = a2;
  std::allocate_shared[abi:ne180100]<ZinIrTransformDuplicate,std::allocator<ZinIrTransformDuplicate>,unsigned long &,void>(&data, &v13);
  if (*(void *)(a1 + 584))
  {
LABEL_2:
    *a3 = 0;
    goto LABEL_25;
  }
  uint64_t v12 = 0;
  uint64_t v5 = *(void *)(a1 + 568);
  if (*(unsigned char *)(a1 + 185))
  {
    uint64_t v18 = v13;
    uint64_t v19 = v14;
    if (v14) {
      atomic_fetch_add_explicit(&v14->__shared_owners_, 1uLL, memory_order_relaxed);
    }
    long long v9 = 0;
    long long v10 = 0;
    long long v11 = 0;
    uint64_t v16 = (void **)&v9;
    char v17 = 0;
    long long v9 = operator new(0x10uLL);
    long long v10 = v9;
    long long v11 = v9 + 2;
    long long v10 = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::shared_ptr<ZinIrVectorTransform>>,std::shared_ptr<ZinIrVectorTransform> const*,std::shared_ptr<ZinIrVectorTransform> const*,std::shared_ptr<ZinIrVectorTransform>*>((uint64_t)&v11, &v18, &v20, v9);
    ZinIrVector::Transform(v5, (uint64_t)&v9, &v12);
    uint64_t v16 = (void **)&v9;
    std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100](&v16);
    if (v19) {
      std::__shared_weak_count::__release_shared[abi:ne180100](v19);
    }
    if (!v12) {
      goto LABEL_2;
    }
  }
  else if (v5)
  {
    ZinIrVector::GetSingularVal(*(ZinIrVector **)(a1 + 568));
    operator new();
  }
  uint64_t v8 = 0;
  uint64_t v6 = *(void *)(a1 + 576);
  if (!*(unsigned char *)(a1 + 193))
  {
    if (v6)
    {
      ZinIrVector::GetSingularVal(*(ZinIrVector **)(a1 + 576));
      operator new();
    }
LABEL_21:
    if (!*(void *)(a1 + 592))
    {
      LODWORD(v18) = 0;
      long long v9 = 0;
      uint64_t v16 = 0;
      std::make_unique[abi:ne180100]<ZinIrKernel,std::string,ZinKernelDescriptor const&,decltype(nullptr),std::unique_ptr<ZinIrVector>,std::unique_ptr<ZinIrVector>,decltype(nullptr),SHAUpdateMode const&>();
    }
    ZinAssertImpl("This transformation is only used for GOC and should not have zero point in kernel");
  }
  uint64_t v18 = v13;
  uint64_t v19 = v14;
  if (v14) {
    atomic_fetch_add_explicit(&v14->__shared_owners_, 1uLL, memory_order_relaxed);
  }
  long long v9 = 0;
  long long v10 = 0;
  long long v11 = 0;
  uint64_t v16 = (void **)&v9;
  char v17 = 0;
  long long v9 = operator new(0x10uLL);
  long long v10 = v9;
  long long v11 = v9 + 2;
  long long v10 = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::shared_ptr<ZinIrVectorTransform>>,std::shared_ptr<ZinIrVectorTransform> const*,std::shared_ptr<ZinIrVectorTransform> const*,std::shared_ptr<ZinIrVectorTransform>*>((uint64_t)&v11, &v18, &v20, v9);
  ZinIrVector::Transform(v6, (uint64_t)&v9, &v8);
  uint64_t v16 = (void **)&v9;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100](&v16);
  if (v19) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v19);
  }
  if (v8) {
    goto LABEL_21;
  }
  *a3 = 0;
  uint64_t v7 = v12;
  uint64_t v12 = 0;
  if (v7) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&v12, v7);
  }
LABEL_25:
  if (v14) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v14);
  }
}

void sub_2113A79A8(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, std::__shared_weak_count *a16)
{
  MEMORY[0x21667D3C0](v16, 0x10B3C400A1ACBE3);
  uint64_t v18 = a10;
  a10 = 0;
  if (v18) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&a10, v18);
  }
  uint64_t v19 = a14;
  a14 = 0;
  if (v19) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&a14, v19);
  }
  if (a16) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a16);
  }
  _Unwind_Resume(a1);
}

void std::make_unique[abi:ne180100]<ZinIrKernel,std::string,ZinKernelDescriptor const&,decltype(nullptr),std::unique_ptr<ZinIrVector>,std::unique_ptr<ZinIrVector>,decltype(nullptr),SHAUpdateMode const&>()
{
}

void sub_2113A7B9C(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10)
{
  uint64_t v12 = a9;
  a9 = 0;
  if (v12) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&a9, v12);
  }
  std::make_unique[abi:ne180100]<ZinIrKernel,std::string,ZinKernelDescriptor const&,decltype(nullptr),std::unique_ptr<ZinIrVector>,std::unique_ptr<ZinIrVector>,decltype(nullptr),SHAUpdateMode const&>((uint64_t)&a9, &a10);
  MEMORY[0x21667D3C0](v10, 0x1032C40C25AA5B7);
  _Unwind_Resume(a1);
}

void ZinIrKernel::ShuffleKernel(uint64_t a1@<X0>, uint64_t a2@<X2>, int a3@<W3>, int a4@<W4>, int a5@<W5>, int a6@<W6>, int a7@<W7>, void *a8@<X8>, uint64_t a9, uint64_t a10, uint64_t a11, ZinKernelSparsityCache *a12, long long *a13, char a14, int a15)
{
  v94[1] = *MEMORY[0x263EF8340];
  if (!*(void *)(a1 + 584))
  {
    *a8 = 0;
    return;
  }
  uint64_t v50 = *(void **)(a1 + 592);
  std::allocate_shared[abi:ne180100]<ZinIrTransformWeightShuffle,std::allocator<ZinIrTransformWeightShuffle>,ZinKernelDimensions const&,ZinIrScratchBuffer<ZinKernelPosition> &,ZinIrVector *,void>((long long *)a10, a2, (uint64_t *)&v50, &v88);
  uint64_t v87 = 0;
  uint64_t v21 = *(void *)(a1 + 584);
  __n128 v93 = v88;
  if (v88.n128_u64[1]) {
    atomic_fetch_add_explicit((atomic_ullong *volatile)(v88.n128_u64[1] + 8), 1uLL, memory_order_relaxed);
  }
  uint64_t v50 = 0;
  uint64_t v51 = 0;
  uint64_t v52 = 0;
  uint64_t v85 = (void **)&v50;
  LOBYTE(v86) = 0;
  uint64_t v50 = operator new(0x10uLL);
  uint64_t v51 = v50;
  uint64_t v52 = v50 + 2;
  uint64_t v51 = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::shared_ptr<ZinIrWeightTransform>>,std::shared_ptr<ZinIrWeightTransform> const*,std::shared_ptr<ZinIrWeightTransform> const*,std::shared_ptr<ZinIrWeightTransform>*>((uint64_t)&v52, &v93, v94, v50);
  ZinIrWeight::Transform(v21, (uint64_t)&v50, (uint64_t *)&v87);
  uint64_t v85 = (void **)&v50;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100](&v85);
  if (v93.n128_u64[1]) {
    std::__shared_weak_count::__release_shared[abi:ne180100]((std::__shared_weak_count *)v93.n128_u64[1]);
  }
  if (v87)
  {
    unint64_t v22 = v87[7];
    uint64_t v50 = 0;
    std::vector<unsigned long>::vector(&v85, v22, &v50);
    int v23 = (*(uint64_t (**)(void *))(*v87 + 72))(v87);
    uint64_t v24 = v85;
    if (v23)
    {
      uint64_t v25 = v86;
    }
    else
    {
      uint64_t v25 = v85;
      if (v86 != v85)
      {
        uint64_t v26 = 0;
        unint64_t v27 = 0;
        uint64_t v28 = 40 * v87[12];
        do
        {
          int v29 = (*(uint64_t (**)(uint64_t))(*(void *)details::ZinIrMappedDataBase_Impl::backing_ + 24))(details::ZinIrMappedDataBase_Impl::backing_);
          long long v30 = (void **)(*(void *)(a2 + 48) + v26);
          if (!v29) {
            long long v30 = (void **)a2;
          }
          uint64_t v24 = v85;
          v85[v27++] = *v30;
          uint64_t v25 = v86;
          v26 += v28;
        }
        while (v27 < v86 - v24);
      }
    }
    __n128 v93 = 0uLL;
    v94[0] = 0;
    std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>(&v93, v24, (uint64_t)v25, v25 - v24);
    uint64_t v50 = *(void **)(a1 + 592);
    std::allocate_shared[abi:ne180100]<ZinIrTransformShuffle,std::allocator<ZinIrTransformShuffle>,std::vector<unsigned long>,ZinIrVector *,void>(&v93, (unint64_t *)&v50, &v83);
    uint64_t v82 = 0;
    uint64_t v31 = *(void *)(a1 + 568);
    if (*(unsigned char *)(a1 + 185))
    {
      uint64_t v91 = v83;
      uint64_t v92 = v84;
      if (v84) {
        atomic_fetch_add_explicit(&v84->__shared_owners_, 1uLL, memory_order_relaxed);
      }
      uint64_t v50 = 0;
      uint64_t v51 = 0;
      uint64_t v52 = 0;
      uint64_t v89 = (void **)&v50;
      char v90 = 0;
      uint64_t v50 = operator new(0x10uLL);
      uint64_t v51 = v50;
      uint64_t v52 = v50 + 2;
      uint64_t v51 = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::shared_ptr<ZinIrVectorTransform>>,std::shared_ptr<ZinIrVectorTransform> const*,std::shared_ptr<ZinIrVectorTransform> const*,std::shared_ptr<ZinIrVectorTransform>*>((uint64_t)&v52, &v91, &v93, v50);
      ZinIrVector::Transform(v31, (uint64_t)&v50, (uint64_t *)&v82);
      uint64_t v89 = (void **)&v50;
      std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100](&v89);
      if (v92) {
        std::__shared_weak_count::__release_shared[abi:ne180100](v92);
      }
      if (!v82)
      {
        *a8 = 0;
LABEL_63:
        if (v84) {
          std::__shared_weak_count::__release_shared[abi:ne180100](v84);
        }
        if (v93.n128_u64[0])
        {
          v93.n128_u64[1] = v93.n128_u64[0];
          operator delete((void *)v93.n128_u64[0]);
        }
        if (v85)
        {
          uint64_t v86 = v85;
          operator delete(v85);
        }
        uint64_t v47 = (uint64_t)v87;
        uint64_t v87 = 0;
        if (v47) {
          (*(void (**)(uint64_t))(*(void *)v47 + 16))(v47);
        }
        goto LABEL_71;
      }
    }
    else if (v31)
    {
      ZinIrVector::Clone(*(ZinIrVector **)(a1 + 568), (uint64_t *)&v50);
      uint64_t v32 = v50;
      uint64_t v50 = 0;
      uint64_t v33 = (uint64_t)v82;
      uint64_t v82 = v32;
      if (v33)
      {
        std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&v82, v33);
        uint64_t v34 = v50;
        uint64_t v50 = 0;
        if (v34) {
          std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&v50, (uint64_t)v34);
        }
        uint64_t v32 = v82;
      }
      if (!v32) {
        ZinAssertImpl("Failed to clone scale");
      }
    }
    uint64_t v81 = 0;
    uint64_t v35 = *(void *)(a1 + 576);
    if (*(unsigned char *)(a1 + 193))
    {
      uint64_t v91 = v83;
      uint64_t v92 = v84;
      if (v84) {
        atomic_fetch_add_explicit(&v84->__shared_owners_, 1uLL, memory_order_relaxed);
      }
      uint64_t v50 = 0;
      uint64_t v51 = 0;
      uint64_t v52 = 0;
      uint64_t v89 = (void **)&v50;
      char v90 = 0;
      uint64_t v50 = operator new(0x10uLL);
      uint64_t v51 = v50;
      uint64_t v52 = v50 + 2;
      uint64_t v51 = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::shared_ptr<ZinIrVectorTransform>>,std::shared_ptr<ZinIrVectorTransform> const*,std::shared_ptr<ZinIrVectorTransform> const*,std::shared_ptr<ZinIrVectorTransform>*>((uint64_t)&v52, &v91, &v93, v50);
      ZinIrVector::Transform(v35, (uint64_t)&v50, (uint64_t *)&v81);
      uint64_t v89 = (void **)&v50;
      std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100](&v89);
      if (v92) {
        std::__shared_weak_count::__release_shared[abi:ne180100](v92);
      }
      if (!v81)
      {
        *a8 = 0;
LABEL_61:
        uint64_t v46 = (uint64_t)v82;
        uint64_t v82 = 0;
        if (v46) {
          std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&v82, v46);
        }
        goto LABEL_63;
      }
    }
    else if (v35)
    {
      ZinIrVector::Clone(*(ZinIrVector **)(a1 + 576), (uint64_t *)&v50);
      uint64_t v36 = v50;
      uint64_t v50 = 0;
      uint64_t v37 = (uint64_t)v81;
      uint64_t v81 = v36;
      if (v37)
      {
        std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&v81, v37);
        uint64_t v38 = v50;
        uint64_t v50 = 0;
        if (v38) {
          std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&v50, (uint64_t)v38);
        }
        uint64_t v36 = v81;
      }
      if (!v36) {
        ZinAssertImpl("Failed to clone bias");
      }
    }
    uint64_t v80 = 0;
    uint64_t v39 = *(void *)(a1 + 592);
    if (*(unsigned char *)(a1 + 201))
    {
      uint64_t v91 = v83;
      uint64_t v92 = v84;
      if (v84) {
        atomic_fetch_add_explicit(&v84->__shared_owners_, 1uLL, memory_order_relaxed);
      }
      uint64_t v50 = 0;
      uint64_t v51 = 0;
      uint64_t v52 = 0;
      uint64_t v89 = (void **)&v50;
      char v90 = 0;
      uint64_t v50 = operator new(0x10uLL);
      uint64_t v51 = v50;
      uint64_t v52 = v50 + 2;
      uint64_t v51 = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::shared_ptr<ZinIrVectorTransform>>,std::shared_ptr<ZinIrVectorTransform> const*,std::shared_ptr<ZinIrVectorTransform> const*,std::shared_ptr<ZinIrVectorTransform>*>((uint64_t)&v52, &v91, &v93, v50);
      ZinIrVector::Transform(v39, (uint64_t)&v50, (uint64_t *)&v80);
      uint64_t v89 = (void **)&v50;
      std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100](&v89);
      if (v92) {
        std::__shared_weak_count::__release_shared[abi:ne180100](v92);
      }
      if (!v80)
      {
        *a8 = 0;
        uint64_t v45 = (uint64_t)v81;
        uint64_t v81 = 0;
        if (v45) {
          std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&v81, v45);
        }
        goto LABEL_61;
      }
    }
    else if (v39)
    {
      ZinIrVector::Clone(*(ZinIrVector **)(a1 + 592), (uint64_t *)&v50);
      uint64_t v40 = v50;
      uint64_t v50 = 0;
      uint64_t v41 = (uint64_t)v80;
      uint64_t v80 = v40;
      if (v41)
      {
        std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&v80, v41);
        char v42 = v50;
        uint64_t v50 = 0;
        if (v42) {
          std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&v50, (uint64_t)v42);
        }
        uint64_t v40 = v80;
      }
      if (!v40) {
        ZinAssertImpl("Failed to clone zero point");
      }
    }
    long long v54 = 0u;
    long long v55 = 0u;
    int64x2_t v60 = vdupq_n_s64(1uLL);
    int64x2_t v61 = v60;
    long long v72 = xmmword_211EF5F90;
    long long v43 = *(_OWORD *)(a10 + 16);
    long long v57 = *(_OWORD *)a10;
    HIDWORD(v51) = 0;
    LOWORD(v52) = 0;
    HIDWORD(v52) = 0;
    __int16 v53 = 0;
    uint64_t v56 = 0;
    uint64_t v50 = 0;
    LOWORD(v51) = 0;
    uint64_t v62 = 1;
    int v74 = 0;
    uint64_t v75 = 1;
    uint64_t v76 = 0;
    uint64_t v77 = 0;
    uint64_t v78 = 0;
    int v79 = 0;
    long long v58 = v43;
    uint64_t v59 = *(void *)(a10 + 32);
    int v63 = a3;
    int v64 = a4;
    int v65 = a5;
    int v66 = a6;
    int v67 = a7;
    int v68 = a9;
    long long v69 = *a13;
    uint64_t v70 = *((void *)a13 + 2);
    int v71 = a15;
    uint64_t v73 = *(void *)(a1 + 400);
    if (a14) {
      char v44 = 64;
    }
    else {
      char v44 = 0;
    }
    LOBYTE(v79) = *(unsigned char *)(a1 + 448) & 0x80 | v44;
    LODWORD(v5std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = *(_DWORD *)(a1 + 176);
    operator new();
  }
  *a8 = 0;
LABEL_71:
  if (v88.n128_u64[1]) {
    std::__shared_weak_count::__release_shared[abi:ne180100]((std::__shared_weak_count *)v88.n128_u64[1]);
  }
}

void sub_2113A8468(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15)
{
  uint64_t v17 = *(void *)(v15 - 240);
  *(void *)(v15 - 24std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  if (v17) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100](v15 - 240, v17);
  }
  uint64_t v18 = *(void *)(v15 - 232);
  *(void *)(v15 - 232) = 0;
  if (v18) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100](v15 - 232, v18);
  }
  uint64_t v19 = *(void *)(v15 - 224);
  *(void *)(v15 - 224) = 0;
  if (v19) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100](v15 - 224, v19);
  }
  uint64_t v20 = *(std::__shared_weak_count **)(v15 - 208);
  if (v20) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v20);
  }
  uint64_t v21 = *(void **)(v15 - 120);
  if (v21)
  {
    *(void *)(v15 - 112) = v21;
    operator delete(v21);
  }
  unint64_t v22 = *(void **)(v15 - 200);
  if (v22)
  {
    *(void *)(v15 - 192) = v22;
    operator delete(v22);
  }
  uint64_t v23 = *(void *)(v15 - 176);
  *(void *)(v15 - 176) = 0;
  if (v23) {
    (*(void (**)(uint64_t))(*(void *)v23 + 16))(v23);
  }
  uint64_t v24 = *(std::__shared_weak_count **)(v15 - 160);
  if (v24) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v24);
  }
  _Unwind_Resume(exception_object);
}

void ZinIrKernel::Create4bitPalKernelFrom3bitPalKernel(ZinIrKernel *this@<X0>, const ZinIrHalParameters *a2@<X1>, void *a3@<X8>)
{
  uint64_t v5 = *((void *)this + 73);
  if (!v5)
  {
    *a3 = 0;
    return;
  }
  int v8 = *(_DWORD *)(v5 + 8);
  if (*((char *)this + 23) >= 0) {
    size_t v9 = *((unsigned __int8 *)this + 23);
  }
  else {
    size_t v9 = *((void *)this + 1);
  }
  uint64_t v10 = v33;
  std::string::basic_string[abi:ne180100]((uint64_t)v33, v9 + 12);
  if (v34 < 0) {
    uint64_t v10 = (void **)v33[0];
  }
  if (v9)
  {
    if (*((char *)this + 23) >= 0) {
      long long v11 = this;
    }
    else {
      long long v11 = *(ZinIrKernel **)this;
    }
    memmove(v10, v11, v9);
  }
  strcpy((char *)v10 + v9, "_4b_upcasted");
  if (NeedsUpcastingFrom3bitPaletteTo4bitPalette((uint64_t)a2, v8))
  {
    if (ZinIrKernel::IsMutable(this))
    {
      BOOL v12 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v12) {
        ZinIrKernel::Create4bitPalKernelFrom3bitPalKernel(v12, v13, v14, v15, v16, v17, v18, v19);
      }
    }
    else if (!(*(unsigned int (**)(void))(**((void **)this + 73) + 72))(*((void *)this + 73)))
    {
      int Upcasted4bitPaletteFormatFrom3bitPaletteFormat = GetUpcasted4bitPaletteFormatFrom3bitPaletteFormat(v8);
      uint64_t v21 = (ZinIrVector *)*((void *)this + 71);
      if (v21) {
        ZinIrVector::Clone(v21, &v32);
      }
      else {
        uint64_t v32 = 0;
      }
      unint64_t v22 = (ZinIrVector *)*((void *)this + 72);
      if (v22) {
        ZinIrVector::Clone(v22, &v31);
      }
      else {
        uint64_t v31 = 0;
      }
      uint64_t v23 = (ZinIrVector *)*((void *)this + 74);
      if (v23) {
        ZinIrVector::Clone(v23, &v30);
      }
      else {
        uint64_t v30 = 0;
      }
      memcpy(__dst, (char *)this + 176, sizeof(__dst));
      __dst[0] = Upcasted4bitPaletteFormatFrom3bitPaletteFormat;
      uint64_t v28 = 0;
      ZinIrWeight::Create4bitPalWeightFrom3bitPalWeight(*((ZinIrWeight **)this + 73), &v27);
      uint64_t v28 = v27;
      if (v27) {
        operator new();
      }
      *a3 = 0;
      uint64_t v24 = v30;
      uint64_t v30 = 0;
      if (v24) {
        std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&v30, v24);
      }
      uint64_t v25 = v31;
      uint64_t v31 = 0;
      if (v25) {
        std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&v31, v25);
      }
      uint64_t v26 = v32;
      uint64_t v32 = 0;
      if (v26) {
        std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&v32, v26);
      }
      goto LABEL_19;
    }
  }
  *a3 = 0;
LABEL_19:
  if (v34 < 0) {
    operator delete(v33[0]);
  }
}

void sub_2113A8980(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11)
{
  MEMORY[0x21667D3C0](v11, 0x1032C40C25AA5B7);
  if (a11) {
    (*(void (**)(uint64_t))(*(void *)a11 + 16))(a11);
  }
  uint64_t v14 = *(void *)(v12 - 112);
  *(void *)(v12 - 112) = 0;
  if (v14) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100](v12 - 112, v14);
  }
  uint64_t v15 = *(void *)(v12 - 104);
  *(void *)(v12 - 104) = 0;
  if (v15) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100](v12 - 104, v15);
  }
  uint64_t v16 = *(void *)(v12 - 96);
  *(void *)(v12 - 96) = 0;
  if (v16) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100](v12 - 96, v16);
  }
  if (*(char *)(v12 - 65) < 0) {
    operator delete(*(void **)(v12 - 88));
  }
  _Unwind_Resume(a1);
}

void *ZinIrKernel::DilateKernel@<X0>(uint64_t a1@<X0>, uint64_t a2@<X3>, uint64_t a3@<X4>, void *a4@<X8>)
{
  v10[1] = a3;
  uint64_t v10[2] = a2;
  uint64_t result = *(void **)(a1 + 584);
  if (result)
  {
    uint64_t result = (*(void *(**)(void *__return_ptr))(*result + 64))(v10);
    if (v10[0])
    {
      char v7 = *(unsigned char *)(a1 + 448);
      if ((v7 & 8) == 0)
      {
        uint64_t v9 = 0;
        if ((v7 & 2) == 0)
        {
          uint64_t v8 = 0;
          operator new();
        }
        std::make_unique[abi:ne180100]<ZinIrVector,ZinIrVector&>();
      }
      std::make_unique[abi:ne180100]<ZinIrVector,ZinIrVector&>();
    }
  }
  *a4 = 0;
  return result;
}

void sub_2113A8C18(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12)
{
  uint64_t v13 = a11;
  a11 = 0;
  if (v13) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&a11, v13);
  }
  uint64_t v14 = a12;
  a12 = 0;
  if (v14) {
    (*(void (**)(uint64_t))(*(void *)v14 + 16))(v14);
  }
  _Unwind_Resume(exception_object);
}

void ZinIrKernel::MergeResizeNNIntoConvKernel(uint64_t a1@<X0>, uint64_t a2@<X1>, void *a3@<X8>)
{
  if ((*(unsigned char *)(a1 + 448) & 0x10) != 0)
  {
    BOOL v12 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (v12) {
      ZinIrKernel::MergeResizeNNIntoConvKernel(v12, v13, v14, v15, v16, v17, v18, v19);
    }
  }
  else
  {
    if ((*(unsigned char *)(a1 + 448) & 0xA) == 0) {
      ZinIrWeight::MergeResizeNNConvWeight(*(void *)(a1 + 584), (int *)(a2 + 36));
    }
    BOOL v4 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (v4) {
      ZinIrKernel::MergeResizeNNIntoConvKernel(v4, v5, v6, v7, v8, v9, v10, v11);
    }
  }
  *a3 = 0;
}

void sub_2113A8E84(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14)
{
  if (a14) {
    (*(void (**)(uint64_t))(*(void *)a14 + 16))(a14);
  }
  _Unwind_Resume(exception_object);
}

void std::make_unique[abi:ne180100]<ZinIrKernel,std::string,ZinKernelFormat const&,ZinIrConvInfo const&,std::unique_ptr<ZinIrWeight>,decltype(nullptr),decltype(nullptr),decltype(nullptr),SHAUpdateMode const&>()
{
}

void sub_2113A8F9C(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12)
{
  uint64_t v14 = a11;
  a11 = 0;
  if (v14) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&a11, v14);
  }
  uint64_t v15 = a12;
  a12 = 0;
  if (v15) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&a12, v15);
  }
  MEMORY[0x21667D3C0](v12, 0x1032C40C25AA5B7);
  _Unwind_Resume(a1);
}

void ZinIrKernel::DeInterleaveDeconvKernelHeight(uint64_t a1@<X0>, uint64_t a2@<X2>, uint64_t a3@<X3>, void *a4@<X8>)
{
  v11[1] = a3;
  uint64_t v6 = *(ZinIrWeight **)(a1 + 584);
  if (v6)
  {
    ZinIrWeight::HeightSplitDeconv(v6, a3, *(void *)(a2 + 88), v11);
    if (v11[0])
    {
      char v7 = *(unsigned char *)(a1 + 448);
      if ((v7 & 8) == 0)
      {
        uint64_t v10 = 0;
        if ((v7 & 0x10) == 0)
        {
          uint64_t v9 = 0;
          if ((v7 & 2) == 0)
          {
            uint64_t v8 = 0;
            operator new();
          }
          std::make_unique[abi:ne180100]<ZinIrVector,ZinIrVector&>();
        }
        std::make_unique[abi:ne180100]<ZinIrVector,ZinIrVector&>();
      }
      std::make_unique[abi:ne180100]<ZinIrVector,ZinIrVector&>();
    }
  }
  *a4 = 0;
}

void sub_2113A9208(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13)
{
  uint64_t v14 = a11;
  a11 = 0;
  if (v14) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&a11, v14);
  }
  uint64_t v15 = a12;
  a12 = 0;
  if (v15) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&a12, v15);
  }
  uint64_t v16 = a13;
  a13 = 0;
  if (v16) {
    (*(void (**)(uint64_t))(*(void *)v16 + 16))(v16);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinIrKernel::SetActivationParams(ZinIrKernel *this, const ZinIrActivationParams *a2)
{
  uint64_t v2 = (char *)this + 632;
  long long v3 = *(_OWORD *)a2;
  long long v4 = *((_OWORD *)a2 + 2);
  *(_OWORD *)((char *)this + 648) = *((_OWORD *)a2 + 1);
  *(_OWORD *)((char *)this + 664) = v4;
  *(_OWORD *)((char *)this + 632) = v3;
  long long v5 = *((_OWORD *)a2 + 3);
  long long v6 = *((_OWORD *)a2 + 4);
  long long v7 = *((_OWORD *)a2 + 6);
  *(_OWORD *)((char *)this + 712) = *((_OWORD *)a2 + 5);
  *(_OWORD *)((char *)this + 728) = v7;
  *(_OWORD *)((char *)this + 68std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v5;
  *(_OWORD *)((char *)this + 696) = v6;
  long long v8 = *((_OWORD *)a2 + 7);
  long long v9 = *((_OWORD *)a2 + 8);
  long long v10 = *((_OWORD *)a2 + 9);
  *((void *)this + 99) = *((void *)a2 + 20);
  *(_OWORD *)((char *)this + 76std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v9;
  *(_OWORD *)((char *)this + 776) = v10;
  *(_OWORD *)((char *)this + 744) = v8;
  *((unsigned char *)this + 448) = *((unsigned char *)this + 448) & 0xFE | (*(_DWORD *)a2 > 1u);
  uint64_t v11 = (CC_SHA256_CTX *)((char *)this + 52);
  CC_SHA256_Update((CC_SHA256_CTX *)((char *)this + 52), "lut", 3u);

  return CC_SHA256_Update(v11, v2, 0xA8u);
}

uint64_t ZinIrKernel::SetMustCompressWeight(uint64_t a1, unsigned int a2)
{
  if (!*(unsigned char *)(a1 + 160)
    || ((uint64_t result = IsFormatDMAConvertibleToFP16(a2), !result) ? (v5 = a2) : (v5 = 3), v5 != *(_DWORD *)(a1 + 164)))
  {
    *(unsigned char *)(a1 + 16std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 1;
    if (IsFormatDMAConvertibleToFP16(a2)) {
      int v6 = 3;
    }
    else {
      int v6 = a2;
    }
    *(_DWORD *)(a1 + 164) = v6;
    char data = *(unsigned char *)(a1 + 160);
    CC_SHA256_Update((CC_SHA256_CTX *)(a1 + 52), &data, 1u);
    return CC_SHA256_Update((CC_SHA256_CTX *)(a1 + 52), (const void *)(a1 + 164), 4u);
  }
  return result;
}

void ZinIrKernel::CopyWithUpdatedInfo()
{
}

void sub_2113A949C(_Unwind_Exception *a1)
{
  std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](v1, 0);
  _Unwind_Resume(a1);
}

void ZinIrKernel::CopyWithPaddingChanged(uint64_t a1, uint64_t a2, long long *a3)
{
  uint64_t v3 = *(void *)(a1 + 552);
  long long v4 = *(_OWORD *)(a1 + 536);
  long long v12 = *(_OWORD *)(a1 + 520);
  long long v13 = v4;
  long long v5 = *(_OWORD *)(a1 + 472);
  long long v8 = *(_OWORD *)(a1 + 456);
  long long v9 = v5;
  long long v6 = *a3;
  long long v10 = *(_OWORD *)(a1 + 488);
  long long v11 = v6;
  uint64_t v7 = *((void *)a3 + 2);
  uint64_t v14 = v3;
  *(void *)&long long v12 = v7;
  operator new();
}

void sub_2113A957C(_Unwind_Exception *a1)
{
  std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](v1, 0);
  _Unwind_Resume(a1);
}

void ZinIrKernel::CopyWithGroupCountChanged(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v3 = *(void *)(a1 + 552);
  long long v4 = *(_OWORD *)(a1 + 536);
  long long v11 = *(_OWORD *)(a1 + 520);
  long long v12 = v4;
  long long v5 = *(_OWORD *)(a1 + 472);
  long long v7 = *(_OWORD *)(a1 + 456);
  long long v8 = v5;
  long long v6 = *(_OWORD *)(a1 + 504);
  long long v9 = *(_OWORD *)(a1 + 488);
  long long v10 = v6;
  *((void *)&v12 + 1) = a3;
  uint64_t v13 = v3;
  operator new();
}

void sub_2113A9650(_Unwind_Exception *a1)
{
  std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](v1, 0);
  _Unwind_Resume(a1);
}

void ZinIrKernel::CreateOneHotKernel(uint64_t a1, uint64_t a2, void *a3, void *a4, uint64_t a5)
{
  unint64_t v8 = a3[1] * *a3 * a3[2] * a3[3] * a3[4];
  LODWORD(__p) = 0;
  std::vector<float>::vector(&v14, v8, &__p);
  v14[a4[4] + (a4[3] + (a4[2] + (a4[1] + a3[1] * *a4) * a3[2]) * a3[3]) * a3[4]] = 1.0;
  ZinIrWeight::CreatePalettizedWeight(2, &v14, 2uLL, a5, &v13);
  if (!v13)
  {
    size_t v9 = a3[1] * *a3 * a3[2] * a3[3] * a3[4];
    LOBYTE(v11) = 0;
    std::vector<unsigned char>::vector(&__p, v9, &v11);
    *((unsigned char *)__p + a4[4] + (a4[3] + (a4[2] + (a4[1] + a3[1] * *a4) * a3[2]) * a3[3]) * a3[4]) = 1;
    std::allocate_shared[abi:ne180100]<ZinIrConstData_specialization<unsigned char>,std::allocator<ZinIrConstData_specialization<unsigned char>>,std::vector<unsigned char>,void>((uint64_t)&__p, &v10);
    long long v11 = v10;
    std::make_unique[abi:ne180100]<ZinIrWeight,std::shared_ptr<ZinIrConstData> &,decltype(nullptr),ZinKernelFormat,ZinKernelDimensions const&>();
  }
  LODWORD(v1std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = *(_DWORD *)(v13 + 8);
  __n128 __p = 0;
  *(void *)&long long v11 = 0;
  std::make_unique[abi:ne180100]<ZinIrKernel,std::string,ZinKernelFormat,ZinIrConvInfo const&,std::unique_ptr<ZinIrWeight>,decltype(nullptr),decltype(nullptr)>();
}

void sub_2113A9900(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, std::__shared_weak_count *a14, uint64_t a15, void *__p, uint64_t a17, uint64_t a18, uint64_t a19)
{
  if (a14) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a14);
  }
  if (__p) {
    operator delete(__p);
  }
  if (a19) {
    (*(void (**)(uint64_t))(*(void *)a19 + 16))(a19);
  }
  uint64_t v21 = *(void **)(v19 - 72);
  if (v21)
  {
    *(void *)(v19 - 64) = v21;
    operator delete(v21);
  }
  _Unwind_Resume(exception_object);
}

void std::make_unique[abi:ne180100]<ZinIrWeight,std::shared_ptr<ZinIrConstData> &,decltype(nullptr),ZinKernelFormat,ZinKernelDimensions const&>()
{
}

void sub_2113A9A40(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, std::__shared_weak_count *a10, uint64_t a11, std::__shared_weak_count *a12)
{
  if (a10) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a10);
  }
  if (a12) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a12);
  }
  MEMORY[0x21667D3C0](v12, 0x10B3C4034FA82A5);
  _Unwind_Resume(a1);
}

void std::make_unique[abi:ne180100]<ZinIrKernel,std::string,ZinKernelFormat,ZinIrConvInfo const&,std::unique_ptr<ZinIrWeight>,decltype(nullptr),decltype(nullptr)>()
{
}

void sub_2113A9B38(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12)
{
  uint64_t v14 = a11;
  a11 = 0;
  if (v14) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&a11, v14);
  }
  uint64_t v15 = a12;
  a12 = 0;
  if (v15) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&a12, v15);
  }
  MEMORY[0x21667D3C0](v12, 0x1032C40C25AA5B7);
  _Unwind_Resume(a1);
}

void ZinIrKernel::CreateDynamicKernel(float **a1@<X2>, uint64_t a2@<X3>, void *a3@<X4>, unint64_t a4@<X5>, uint64_t a5@<X6>, int a6@<W7>, void *a7@<X8>)
{
  int v50 = a2;
  if (a3[1] * *a3 * a3[2] * a3[3] * a3[4] == a1[1] - *a1)
  {
    int v8 = a2;
    if (a2 <= 5 && ((1 << a2) & 0x36) != 0)
    {
      std::vector<char>::pointer v49 = 0;
      if (!a6 || (ZinIrWeight::CreatePalettizedWeight(a2, a1, a4, a5, &v47), (std::vector<char>::pointer v49 = v47.__begin_) == 0))
      {
        long long v48 = 0uLL;
        switch(v8)
        {
          case 2:
            memset(&v47, 0, sizeof(v47));
            uint64_t v35 = *a1;
            uint64_t v36 = a1[1];
            int64_t begin = (char *)v36 - (char *)*a1;
            if (v36 != *a1)
            {
              std::vector<char>::__append(&v47, begin >> 2);
              uint64_t v35 = *a1;
              uint64_t v36 = a1[1];
              int64_t begin = (int64_t)v47.__begin_;
            }
            while (v35 != v36)
            {
              float v38 = *v35++;
              *(unsigned char *)begin++ = (int)v38;
            }
            std::allocate_shared[abi:ne180100]<ZinIrConstData_specialization<unsigned char>,std::allocator<ZinIrConstData_specialization<unsigned char>>,std::vector<unsigned char>,void>((uint64_t)&v47, &v46);
            break;
          case 5:
            memset(&v47, 0, sizeof(v47));
            uint64_t v39 = *a1;
            uint64_t v40 = a1[1];
            if (v40 == *a1)
            {
              std::vector<char>::pointer v41 = 0;
            }
            else
            {
              std::vector<char>::__append(&v47, v40 - *a1);
              uint64_t v39 = *a1;
              uint64_t v40 = a1[1];
              std::vector<char>::pointer v41 = v47.__begin_;
            }
            while (v39 != v40)
              *v41++ = ZinF32ToE4M3(*v39++, 1, 0);
            std::allocate_shared[abi:ne180100]<ZinIrConstData_specialization<e4m3_t>,std::allocator<ZinIrConstData_specialization<e4m3_t>>,std::vector<e4m3_t>,void>((uint64_t)&v47, &v46);
            break;
          case 4:
            memset(&v47, 0, sizeof(v47));
            std::vector<half>::resize((uint64_t)&v47, a1[1] - *a1);
            long long v10 = *a1;
            long long v11 = a1[1];
            if (*a1 != v11)
            {
              std::vector<char>::pointer v12 = v47.__begin_;
              do
              {
                int v13 = *(_DWORD *)v10++;
                _S0 = v13;
                __asm { FCVT            H0, S0 }
                *(_WORD *)std::vector<char>::pointer v12 = _S0;
                v12 += 2;
              }
              while (v10 != v11);
            }
            std::allocate_shared[abi:ne180100]<ZinIrConstData_specialization<half>,std::allocator<ZinIrConstData_specialization<half>>,std::vector<half>,void>((uint64_t)&v47, &v46);
            break;
          default:
            memset(&v47, 0, sizeof(v47));
            char v42 = *a1;
            long long v43 = a1[1];
            int64_t v44 = (char *)v43 - (char *)*a1;
            if (v43 != *a1)
            {
              std::vector<char>::__append(&v47, v44 >> 2);
              char v42 = *a1;
              long long v43 = a1[1];
              int64_t v44 = (int64_t)v47.__begin_;
            }
            while (v42 != v43)
            {
              float v45 = *v42++;
              *(unsigned char *)v44++ = (int)v45;
            }
            std::allocate_shared[abi:ne180100]<ZinIrConstData_specialization<signed char>,std::allocator<ZinIrConstData_specialization<signed char>>,std::vector<signed char>,void>((uint64_t)&v47, &v46);
            break;
        }
        long long v48 = v46;
        if (v47.__begin_)
        {
          v47.__end_ = v47.__begin_;
          operator delete(v47.__begin_);
        }
        *(void *)&long long v46 = 0;
        std::make_unique[abi:ne180100]<ZinIrWeight,std::shared_ptr<ZinIrConstData>,decltype(nullptr),ZinKernelFormat &,ZinKernelDimensions const&,ZinKernelLayout &>();
      }
      LODWORD(v46) = *((_DWORD *)v47.__begin_ + 2);
      v47.__begin_ = 0;
      *(void *)&long long v48 = 0;
      std::make_unique[abi:ne180100]<ZinIrKernel,std::string,ZinKernelFormat,ZinIrConvInfo const&,std::unique_ptr<ZinIrWeight>,decltype(nullptr),decltype(nullptr)>();
    }
    BOOL v27 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (v27) {
      ZinIrKernel::CreateDynamicKernel(v27, v28, v29, v30, v31, v32, v33, v34);
    }
  }
  else
  {
    BOOL v19 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (v19) {
      ZinIrKernel::CreateDynamicKernel(v19, v20, v21, v22, v23, v24, v25, v26);
    }
  }
  *a7 = 0;
}

void sub_2113A9EF4(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, void *__p, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

void std::make_unique[abi:ne180100]<ZinIrWeight,std::shared_ptr<ZinIrConstData>,decltype(nullptr),ZinKernelFormat &,ZinKernelDimensions const&,ZinKernelLayout &>()
{
}

void sub_2113AA008(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, std::__shared_weak_count *a10, uint64_t a11, std::__shared_weak_count *a12)
{
  if (a10) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a10);
  }
  if (a12) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a12);
  }
  MEMORY[0x21667D3C0](v12, 0x10B3C4034FA82A5);
  _Unwind_Resume(a1);
}

void ZinIrKernel::FuseBiasWithBottom(uint64_t a1@<X0>, uint64_t *a2@<X1>, uint64_t *a3@<X8>)
{
  uint64_t v36 = *MEMORY[0x263EF8340];
  uint64_t v4 = *a2;
  if ((*(unsigned char *)(a1 + 448) & 0x10) == 0)
  {
    if ((*(unsigned char *)(*a2 + 448) & 0x10) == 0)
    {
      *a3 = 0;
      return;
    }
LABEL_39:
    std::make_unique[abi:ne180100]<ZinIrVector,ZinIrVector&>();
  }
  if ((*(unsigned char *)(*a2 + 448) & 0x18) == 0) {
    goto LABEL_39;
  }
  *a3 = 0;
  uint64_t v7 = *(void *)(a1 + 576);
  if (!v7 || !*(unsigned char *)(v7 + 152))
  {
    uint64_t v8 = *(void *)(v4 + 568);
    if (!v8 || !*(unsigned char *)(v8 + 152))
    {
      uint64_t v9 = *(void *)(v4 + 576);
      if (!v9 || !*(unsigned char *)(v9 + 152)) {
        goto LABEL_27;
      }
    }
    uint64_t v10 = *(void *)(v4 + 576);
    if (v10)
    {
      if (*(unsigned char *)(v10 + 152))
      {
        long long v31 = 0uLL;
        long long v30 = 0uLL;
        uint64_t v11 = *(void *)(v4 + 568);
        if (v11)
        {
          std::allocate_shared[abi:ne180100]<ZinIrVector,std::allocator<ZinIrVector>,ZinIrVector&,void>(v11, &v26);
          long long v12 = v26;
          long long v26 = 0uLL;
          int v13 = (std::__shared_weak_count *)*((void *)&v31 + 1);
          long long v31 = v12;
          if (v13)
          {
            std::__shared_weak_count::__release_shared[abi:ne180100](v13);
            if (*((void *)&v26 + 1)) {
              std::__shared_weak_count::__release_shared[abi:ne180100](*((std::__shared_weak_count **)&v26 + 1));
            }
          }
          uint64_t v7 = *(void *)(a1 + 576);
        }
        if (v7)
        {
          std::allocate_shared[abi:ne180100]<ZinIrVector,std::allocator<ZinIrVector>,ZinIrVector&,void>(v7, &v26);
          long long v14 = v26;
          long long v26 = 0uLL;
          uint64_t v15 = (std::__shared_weak_count *)*((void *)&v30 + 1);
          long long v30 = v14;
          if (v15)
          {
            std::__shared_weak_count::__release_shared[abi:ne180100](v15);
            if (*((void *)&v26 + 1)) {
              std::__shared_weak_count::__release_shared[abi:ne180100](*((std::__shared_weak_count **)&v26 + 1));
            }
          }
        }
        std::allocate_shared[abi:ne180100]<ZinIrVectorFoldBotBiasWithBotScaleBias,std::allocator<ZinIrVectorFoldBotBiasWithBotScaleBias>,std::shared_ptr<ZinIrVector> &,std::shared_ptr<ZinIrVector> &,void>((uint64_t *)&v31, (uint64_t *)&v30, &v28);
        uint64_t v16 = *(void *)(*a2 + 576);
        uint64_t v34 = v28;
        uint64_t v35 = v29;
        if (v29) {
          atomic_fetch_add_explicit(&v29->__shared_owners_, 1uLL, memory_order_relaxed);
        }
        goto LABEL_53;
      }
      long long v31 = 0uLL;
      long long v30 = 0uLL;
      std::allocate_shared[abi:ne180100]<ZinIrVector,std::allocator<ZinIrVector>,ZinIrVector&,void>(v10, &v26);
      long long v22 = v26;
      long long v26 = 0uLL;
      uint64_t v23 = (std::__shared_weak_count *)*((void *)&v31 + 1);
      long long v31 = v22;
      if (v23)
      {
        std::__shared_weak_count::__release_shared[abi:ne180100](v23);
        if (*((void *)&v26 + 1)) {
          std::__shared_weak_count::__release_shared[abi:ne180100](*((std::__shared_weak_count **)&v26 + 1));
        }
      }
      uint64_t v7 = *(void *)(a1 + 576);
      if (v7) {
        goto LABEL_48;
      }
    }
    else
    {
      long long v31 = 0uLL;
      long long v30 = 0uLL;
      if (v7)
      {
LABEL_48:
        std::allocate_shared[abi:ne180100]<ZinIrVector,std::allocator<ZinIrVector>,ZinIrVector&,void>(v7, &v26);
        long long v24 = v26;
        long long v26 = 0uLL;
        uint64_t v25 = (std::__shared_weak_count *)*((void *)&v30 + 1);
        long long v30 = v24;
        if (v25)
        {
          std::__shared_weak_count::__release_shared[abi:ne180100](v25);
          if (*((void *)&v26 + 1)) {
            std::__shared_weak_count::__release_shared[abi:ne180100](*((std::__shared_weak_count **)&v26 + 1));
          }
        }
      }
    }
    std::allocate_shared[abi:ne180100]<ZinIrVectorFoldBotScaleWithBotBiasBias,std::allocator<ZinIrVectorFoldBotScaleWithBotBiasBias>,std::shared_ptr<ZinIrVector> &,std::shared_ptr<ZinIrVector> &,void>((uint64_t *)&v31, (uint64_t *)&v30, &v28);
    uint64_t v16 = *(void *)(*a2 + 568);
    uint64_t v34 = v28;
    uint64_t v35 = v29;
    if (v29) {
      atomic_fetch_add_explicit(&v29->__shared_owners_, 1uLL, memory_order_relaxed);
    }
    goto LABEL_53;
  }
  uint64_t v8 = *(void *)(v4 + 568);
LABEL_27:
  long long v31 = 0uLL;
  long long v30 = 0uLL;
  if (v8)
  {
    std::allocate_shared[abi:ne180100]<ZinIrVector,std::allocator<ZinIrVector>,ZinIrVector&,void>(v8, &v26);
    long long v17 = v26;
    long long v26 = 0uLL;
    uint64_t v18 = (std::__shared_weak_count *)*((void *)&v31 + 1);
    long long v31 = v17;
    if (v18)
    {
      std::__shared_weak_count::__release_shared[abi:ne180100](v18);
      if (*((void *)&v26 + 1)) {
        std::__shared_weak_count::__release_shared[abi:ne180100](*((std::__shared_weak_count **)&v26 + 1));
      }
    }
    uint64_t v4 = *a2;
  }
  uint64_t v19 = *(void *)(v4 + 576);
  if (v19)
  {
    std::allocate_shared[abi:ne180100]<ZinIrVector,std::allocator<ZinIrVector>,ZinIrVector&,void>(v19, &v26);
    long long v20 = v26;
    long long v26 = 0uLL;
    uint64_t v21 = (std::__shared_weak_count *)*((void *)&v30 + 1);
    long long v30 = v20;
    if (v21)
    {
      std::__shared_weak_count::__release_shared[abi:ne180100](v21);
      if (*((void *)&v26 + 1)) {
        std::__shared_weak_count::__release_shared[abi:ne180100](*((std::__shared_weak_count **)&v26 + 1));
      }
    }
  }
  std::allocate_shared[abi:ne180100]<ZinIrVectorFoldBiasWithBotScaleBotBias,std::allocator<ZinIrVectorFoldBiasWithBotScaleBotBias>,std::shared_ptr<ZinIrVector> &,std::shared_ptr<ZinIrVector> &,void>((uint64_t *)&v31, (uint64_t *)&v30, &v28);
  uint64_t v16 = *(void *)(a1 + 576);
  uint64_t v34 = v28;
  uint64_t v35 = v29;
  if (v29) {
    atomic_fetch_add_explicit(&v29->__shared_owners_, 1uLL, memory_order_relaxed);
  }
LABEL_53:
  long long v26 = 0uLL;
  uint64_t v27 = 0;
  uint64_t v32 = (void **)&v26;
  char v33 = 0;
  *(void *)&long long v26 = operator new(0x10uLL);
  *((void *)&v26 + 1) = v26;
  uint64_t v27 = v26 + 16;
  *((void *)&v26 + 1) = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::shared_ptr<ZinIrVectorTransform>>,std::shared_ptr<ZinIrVectorTransform> const*,std::shared_ptr<ZinIrVectorTransform> const*,std::shared_ptr<ZinIrVectorTransform>*>((uint64_t)&v27, &v34, &v36, (void *)v26);
  ZinIrVector::Transform(v16, (uint64_t)&v26, a3);
  uint64_t v32 = (void **)&v26;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100](&v32);
  if (v35) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v35);
  }
  if (v29) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v29);
  }
  if (*((void *)&v30 + 1)) {
    std::__shared_weak_count::__release_shared[abi:ne180100](*((std::__shared_weak_count **)&v30 + 1));
  }
  if (*((void *)&v31 + 1)) {
    std::__shared_weak_count::__release_shared[abi:ne180100](*((std::__shared_weak_count **)&v31 + 1));
  }
}

void sub_2113AA4D0(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, std::__shared_weak_count *a16, uint64_t a17, std::__shared_weak_count *a18)
{
  if (a16) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a16);
  }
  if (a18) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a18);
  }
  uint64_t v20 = *v18;
  *uint64_t v18 = 0;
  if (v20) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)v18, v20);
  }
  _Unwind_Resume(exception_object);
}

BOOL ZinIrKernel::HasMutableBias(ZinIrKernel *this)
{
  uint64_t v1 = *((void *)this + 72);
  return v1 && *(unsigned char *)(v1 + 152) != 0;
}

BOOL ZinIrKernel::HasMutableScale(ZinIrKernel *this)
{
  uint64_t v1 = *((void *)this + 71);
  return v1 && *(unsigned char *)(v1 + 152) != 0;
}

uint64_t ZinIrKernel::HasKernelConstData(ZinIrKernel *this)
{
  uint64_t result = *((void *)this + 100);
  if (result)
  {
    if (!*((void *)this + 77)) {
      return 1;
    }
    uint64_t result = ZinMirAneKernel::HasAlignedKDMAData((ZinMirAneKernel *)result);
    if (result) {
      return 1;
    }
  }
  return result;
}

void ZinIrKernel::FuseScaleWithBottom(uint64_t a1@<X0>, uint64_t *a2@<X1>, uint64_t *a3@<X8>)
{
  uint64_t v21 = *MEMORY[0x263EF8340];
  uint64_t v4 = *a2;
  if ((*(unsigned char *)(a1 + 448) & 8) == 0)
  {
    if ((*(unsigned char *)(*a2 + 448) & 8) == 0)
    {
      *a3 = 0;
      return;
    }
LABEL_5:
    std::make_unique[abi:ne180100]<ZinIrVector,ZinIrVector&>();
  }
  if ((*(unsigned char *)(*a2 + 448) & 8) == 0) {
    goto LABEL_5;
  }
  *a3 = 0;
  uint64_t v7 = *(void *)(v4 + 568);
  if (v7 && *(unsigned char *)(v7 + 152))
  {
    uint64_t v8 = *(void *)(a1 + 568);
  }
  else
  {
    uint64_t v8 = *(void *)(a1 + 568);
    if (*(unsigned char *)(v8 + 152))
    {
      std::allocate_shared[abi:ne180100]<ZinIrVector,std::allocator<ZinIrVector>,ZinIrVector&,void>(v7, &v15);
      std::allocate_shared[abi:ne180100]<ZinIrVectorEWMultiply,std::allocator<ZinIrVectorEWMultiply>,std::shared_ptr<ZinIrVector> &,void>(&v15, &v13);
      uint64_t v9 = *(void *)(a1 + 568);
      uint64_t v19 = v13;
      uint64_t v20 = v14;
      if (v14) {
        atomic_fetch_add_explicit(&v14->__shared_owners_, 1uLL, memory_order_relaxed);
      }
      goto LABEL_17;
    }
  }
  std::allocate_shared[abi:ne180100]<ZinIrVector,std::allocator<ZinIrVector>,ZinIrVector&,void>(v8, &v15);
  std::allocate_shared[abi:ne180100]<ZinIrVectorEWMultiply,std::allocator<ZinIrVectorEWMultiply>,std::shared_ptr<ZinIrVector> &,void>(&v15, &v13);
  uint64_t v9 = *(void *)(*a2 + 568);
  uint64_t v19 = v13;
  uint64_t v20 = v14;
  if (v14) {
    atomic_fetch_add_explicit(&v14->__shared_owners_, 1uLL, memory_order_relaxed);
  }
LABEL_17:
  uint64_t v10 = 0;
  uint64_t v11 = 0;
  long long v12 = 0;
  long long v17 = (void **)&v10;
  char v18 = 0;
  uint64_t v10 = operator new(0x10uLL);
  uint64_t v11 = v10;
  long long v12 = v10 + 2;
  uint64_t v11 = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::shared_ptr<ZinIrVectorTransform>>,std::shared_ptr<ZinIrVectorTransform> const*,std::shared_ptr<ZinIrVectorTransform> const*,std::shared_ptr<ZinIrVectorTransform>*>((uint64_t)&v12, &v19, &v21, v10);
  ZinIrVector::Transform(v9, (uint64_t)&v10, a3);
  long long v17 = (void **)&v10;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100](&v17);
  if (v20) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v20);
  }
  if (v14) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v14);
  }
  if (v16) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v16);
  }
}

void sub_2113AA850(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, std::__shared_weak_count *a6, uint64_t a7, std::__shared_weak_count *a8, ...)
{
  va_start(va, a8);
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100]((void ***)va);
  uint64_t v11 = *(std::__shared_weak_count **)(v9 - 48);
  if (v11) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v11);
  }
  if (a6) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a6);
  }
  if (a8) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a8);
  }
  uint64_t v12 = *v8;
  *uint64_t v8 = 0;
  if (v12) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)v8, v12);
  }
  _Unwind_Resume(a1);
}

void std::make_unique[abi:ne180100]<ZinIrKernel,std::unique_ptr<ZinIrKernel> const&,std::string,std::unique_ptr<ZinIrVector>,std::unique_ptr<ZinIrVector>,SHAUpdateMode>()
{
}

void sub_2113AA9A0(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10)
{
  uint64_t v12 = a9;
  a9 = 0;
  if (v12) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&a9, v12);
  }
  std::make_unique[abi:ne180100]<ZinIrKernel,std::unique_ptr<ZinIrKernel> const&,std::string>(&a10);
  MEMORY[0x21667D3C0](v10, 0x1032C40C25AA5B7);
  _Unwind_Resume(a1);
}

ZinIrVector *ZinIrKernel::TransformPerCoutGOCKernelToSingularGOCKernel@<X0>(uint64_t a1@<X0>, char *a2@<X1>, ZinIrVector **a3@<X2>, ZinIrVector **a4@<X3>, uint64_t a5@<X4>, void *a6@<X8>)
{
  memcpy(__dst, (const void *)(a1 + 176), sizeof(__dst));
  if (*a3)
  {
    BOOL IsQualifiedToConvertPerCoutVectorToSingularVector = ZinIrVector::IsQualifiedToConvertPerCoutVectorToSingularVector(*a3, a2[730], a2[731]);
    uint64_t result = *a4;
    if (!*a4)
    {
      int v13 = 0;
      if (IsQualifiedToConvertPerCoutVectorToSingularVector)
      {
LABEL_10:
        if (IsQualifiedToConvertPerCoutVectorToSingularVector) {
          __dst[9] = 0;
        }
        if (v13) {
          __dst[17] = 0;
        }
        long long v14 = *a3;
        if (IsQualifiedToConvertPerCoutVectorToSingularVector) {
          ZinIrVector::ConvertPerCoutVectorToSingularVector(v14, a2[730], a2[731]);
        }
        if (v14) {
          std::make_unique[abi:ne180100]<ZinIrVector,ZinIrVector&>();
        }
        uint64_t v19 = 0;
        uint64_t v15 = *a4;
        if (v13) {
          ZinIrVector::ConvertPerCoutVectorToSingularVector(v15, a2[728], a2[729]);
        }
        if (v15) {
          std::make_unique[abi:ne180100]<ZinIrVector,ZinIrVector&>();
        }
        uint64_t v18 = 0;
        uint64_t v17 = 0;
        if (*(char *)(a5 + 23) < 0) {
          std::string::__init_copy_ctor_external(&__p, *(const std::string::value_type **)a5, *(void *)(a5 + 8));
        }
        else {
          std::string __p = *(std::string *)a5;
        }
        operator new();
      }
      goto LABEL_8;
    }
  }
  else
  {
    uint64_t result = *a4;
    if (!*a4) {
      goto LABEL_9;
    }
    BOOL IsQualifiedToConvertPerCoutVectorToSingularVector = 0;
  }
  uint64_t result = (ZinIrVector *)ZinIrVector::IsQualifiedToConvertPerCoutVectorToSingularVector(result, a2[728], a2[729]);
  int v13 = (int)result;
  if (IsQualifiedToConvertPerCoutVectorToSingularVector) {
    goto LABEL_10;
  }
LABEL_8:
  if (v13) {
    goto LABEL_10;
  }
LABEL_9:
  *a6 = 0;
  return result;
}

void sub_2113AABF0(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, void *__p, uint64_t a10, int a11, __int16 a12, char a13, char a14, uint64_t a15, uint64_t a16, uint64_t a17)
{
  if (a15) {
    (*(void (**)(uint64_t))(*(void *)a15 + 16))(a15);
  }
  uint64_t v18 = a16;
  a16 = 0;
  if (v18) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&a16, v18);
  }
  uint64_t v19 = a17;
  a17 = 0;
  if (v19) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)&a17, v19);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinIrKernel::AdjustPalettizedKernel(const void **a1, ZinIrKernel **a2)
{
  std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](a2, 0);
  uint64_t v3 = (ZinIrWeight *)a1[73];
  if (v3)
  {
    ZinIrWeight::CreateDePalettizedWeight(v3, 0, &v11);
    if (v11)
    {
      if (*((char *)a1 + 23) >= 0) {
        size_t v4 = *((unsigned __int8 *)a1 + 23);
      }
      else {
        size_t v4 = (size_t)a1[1];
      }
      long long v5 = &v10;
      std::string::basic_string[abi:ne180100]((uint64_t)&v10, v4 + 23);
      if ((v10.__r_.__value_.__r.__words[2] & 0x8000000000000000) != 0) {
        long long v5 = (std::string *)v10.__r_.__value_.__r.__words[0];
      }
      if (v4)
      {
        if (*((char *)a1 + 23) >= 0) {
          long long v6 = a1;
        }
        else {
          long long v6 = *a1;
        }
        memmove(v5, v6, v4);
      }
      strcpy((char *)v5 + v4, "_AdjustPalettizedKernel");
      memcpy(__dst, a1 + 22, sizeof(__dst));
      __dst[0] = *(_DWORD *)(v11 + 8);
      if (SHIBYTE(v10.__r_.__value_.__r.__words[2]) < 0) {
        std::string::__init_copy_ctor_external(&__p, v10.__r_.__value_.__l.__data_, v10.__r_.__value_.__l.__size_);
      }
      else {
        std::string __p = v10;
      }
      operator new();
    }
  }
  return 0;
}

void sub_2113AAEEC(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, void *__p, uint64_t a10, int a11, __int16 a12, char a13, char a14)
{
  if (*(char *)(v14 - 65) < 0) {
    operator delete(*(void **)(v14 - 88));
  }
  uint64_t v16 = *(void *)(v14 - 64);
  *(void *)(v14 - 64) = 0;
  if (v16) {
    (*(void (**)(uint64_t))(*(void *)v16 + 16))(v16);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinIrKernel::AdjustUnityKernel(uint64_t a1, ZinIrKernel **a2)
{
  std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](a2, 0);
  uint64_t result = ZinKernelFormatIsUnity(*(_DWORD *)(a1 + 176));
  if (result)
  {
    if ((*(unsigned char *)(a1 + 448) & 2) == 0) {
      ZinIrWeight::CreatePalettizedUnityWeight(*(_DWORD *)(a1 + 176));
    }
    BOOL v4 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (v4) {
      ZinIrKernel::AdjustUnityKernel(v4, v5, v6, v7, v8, v9, v10, v11);
    }
    return 3;
  }
  return result;
}

void sub_2113AB210(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, void *__p, uint64_t a10, int a11, __int16 a12, char a13, char a14)
{
  if (*(char *)(v14 - 65) < 0) {
    operator delete(*(void **)(v14 - 88));
  }
  uint64_t v16 = *(void *)(v14 - 64);
  *(void *)(v14 - 64) = 0;
  if (v16) {
    (*(void (**)(uint64_t))(*(void *)v16 + 16))(v16);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinIrKernel::SetSmallSourceMode(uint64_t result, int a2)
{
  if (*(_DWORD *)(result + 168) != a2) {
    *(_DWORD *)(result + 168) = a2;
  }
  return result;
}

uint64_t ZinIrKernel::SetDoubleInt8Mode(uint64_t this, char a2)
{
  *(unsigned char *)(this + 172) = a2;
  return this;
}

uint64_t ZinIrKernel::SetHalfWorkUnitMode(uint64_t result, char a2)
{
  *(unsigned char *)(result + 173) = a2;
  return result;
}

uint64_t ZinIrKernel::CompressionInfo::Enable(uint64_t a1, unsigned int a2)
{
  *(unsigned char *)a1 = 1;
  uint64_t result = IsFormatDMAConvertibleToFP16(a2);
  if (result) {
    int v5 = 3;
  }
  else {
    int v5 = a2;
  }
  *(_DWORD *)(a1 + 4) = v5;
  return result;
}

uint64_t ZinIrKernel::SetKernelLayoutFormat(uint64_t a1, int a2)
{
  int data = a2;
  *(_DWORD *)(a1 + 408) = a2;
  return CC_SHA256_Update((CC_SHA256_CTX *)(a1 + 52), &data, 4u);
}

BOOL ZinIrKernel::AreAllSerializedComponentsMutable(ZinIrKernel *this)
{
  uint64_t v1 = *((void *)this + 71);
  if (v1) {
    BOOL v2 = *(unsigned char *)(v1 + 288) == 0;
  }
  else {
    BOOL v2 = 0;
  }
  uint64_t v3 = *((void *)this + 72);
  if (v3) {
    BOOL v4 = *(unsigned char *)(v3 + 288) == 0;
  }
  else {
    BOOL v4 = 0;
  }
  BOOL result = *((_DWORD *)this + 158) <= 1u
        && ((uint64_t v6 = *((void *)this + 74), v7 = *((void *)this + 73), !v2) || *(unsigned char *)(v1 + 152))
        && (!v4 || *(unsigned char *)(v3 + 152))
        && (!v6 || *(unsigned char *)(v6 + 152))
        && (!v7 || *(unsigned char *)(v7 + 152));
  return result;
}

BOOL ZinIrKernel::HasSingularScale(ZinIrKernel *this, float *a2)
{
  *a2 = *((float *)this + 45);
  return (*((unsigned char *)this + 448) & 8) != 0 && *((unsigned char *)this + 185) == 0;
}

BOOL ZinIrKernel::ReplaceTensorKernel(uint64_t a1, uint64_t *a2)
{
  uint64_t v2 = *(void *)(a1 + 616);
  if (v2)
  {
    uint64_t v3 = *a2;
    uint64_t v4 = a2[1];
    if (v4) {
      atomic_fetch_add_explicit((atomic_ullong *volatile)(v4 + 8), 1uLL, memory_order_relaxed);
    }
    *(void *)(a1 + 616) = v3;
    int v5 = *(std::__shared_weak_count **)(a1 + 624);
    *(void *)(a1 + 624) = v4;
    if (v5) {
      std::__shared_weak_count::__release_shared[abi:ne180100](v5);
    }
  }
  return v2 != 0;
}

BOOL ZinIrKernel::HasSingularBias(ZinIrKernel *this, float *a2)
{
  *a2 = *((float *)this + 47);
  return (*((unsigned char *)this + 448) & 0x10) != 0 && *((unsigned char *)this + 193) == 0;
}

__n128 ZinIrKernel::GetBiasDimensions@<Q0>(ZinIrKernel *this@<X0>, uint64_t a2@<X8>)
{
  uint64_t v9 = 0;
  memset(v8, 0, sizeof(v8));
  uint64_t v2 = *((void *)this + 72);
  uint64_t v3 = (_OWORD *)(v2 + 56);
  BOOL v4 = v2 == 0;
  int v5 = v8;
  if (!v4) {
    int v5 = v3;
  }
  __n128 result = *(__n128 *)v5;
  long long v7 = v5[1];
  *(_OWORD *)a2 = *v5;
  *(_OWORD *)(a2 + 16) = v7;
  *(void *)(a2 + 32) = *((void *)v5 + 4);
  return result;
}

double ZinIrKernel::GetWeightDimensions@<D0>(ZinIrKernel *this@<X0>, uint64_t a2@<X8>)
{
  uint64_t v2 = *((void *)this + 73);
  if (v2)
  {
    long long v3 = *(_OWORD *)(v2 + 56);
    long long v4 = *(_OWORD *)(v2 + 72);
    *(_OWORD *)a2 = v3;
    *(_OWORD *)(a2 + 16) = v4;
    *(void *)(a2 + 32) = *(void *)(v2 + 88);
  }
  else if (*((void *)this + 77))
  {
    long long v3 = *(_OWORD *)((char *)this + 248);
    *(void *)(a2 + 32) = *((void *)this + 35);
    long long v5 = *(_OWORD *)((char *)this + 264);
    *(_OWORD *)a2 = v3;
    *(_OWORD *)(a2 + 16) = v5;
  }
  else
  {
    *(void *)(a2 + 32) = 0;
    *(void *)&long long v3 = 0;
    *(_OWORD *)a2 = 0u;
    *(_OWORD *)(a2 + 16) = 0u;
  }
  return *(double *)&v3;
}

BOOL ZinIrKernel::HasVectorPalettizedWeight(ZinIrKernel *this)
{
  return (*((unsigned char *)this + 448) & 4) != 0
      && (*((_DWORD *)this + 44) - 7) <= 0x14
      && *((void *)this + 52) > 1uLL;
}

BOOL ZinIrKernel::HasSingularZeroPoint(ZinIrKernel *this)
{
  return (*((unsigned char *)this + 448) & 2) != 0 && *((unsigned char *)this + 201) == 0;
}

BOOL ZinIrKernel::HasPerCoutZeroPoint(ZinIrKernel *this)
{
  return (*((unsigned char *)this + 448) & 2) != 0 && *((unsigned char *)this + 201) != 0;
}

BOOL ZinIrKernel::HasSingularZeroPoint(ZinIrKernel *this, int *a2)
{
  *a2 = (int)*((float *)this + 49);
  return (*((unsigned char *)this + 448) & 2) != 0 && *((unsigned char *)this + 201) == 0;
}

double ZinIrKernel::GetWeightElementSizeInBytes(ZinIrKernel *this)
{
  return ZinGetWeightElementSizeInBytes(*((_DWORD *)this + 44));
}

void ZinIrKernel::GetSparsityRatio(ZinIrKernel *this, char a2, ZinKernelSparsityCache *a3)
{
  if (*((void *)this + 73))
  {
    if ((a2 & 2) != 0) {
      ZinIrKernel::CalculateSparsityFromPadding(this);
    }
    if ((a2 & 4) != 0)
    {
      int Hash = ZinIrKernel::GetHash(this);
      if (ZinKernelSparsityCache::Contains(a3, Hash))
      {
        ZinKernelSparsityCache::Get(a3, Hash);
      }
      else
      {
        float v8 = ZinIrKernel::CalculateSparsityFromWeightScan(this, v7);
        ZinKernelSparsityCache::Add(a3, Hash, v8);
      }
    }
  }
}

float ZinIrKernel::CalculateSparsityFromPadding(ZinIrKernel *this)
{
  uint64_t ProgrammedKernelDimension = details::ZinGetProgrammedKernelDimension(*((int *)this + 82), *((int *)this + 85), *((void *)this + 34), *((_DWORD *)this + 88));
  uint64_t v3 = details::ZinGetProgrammedKernelDimension(*((int *)this + 83), *((int *)this + 86), *((void *)this + 33), *((_DWORD *)this + 90));
  uint64_t v4 = details::ZinGetProgrammedKernelDimension(*((int *)this + 84), *((int *)this + 87), *((void *)this + 35), *((_DWORD *)this + 92));
  unint64_t v5 = *((void *)this + 33) * *((void *)this + 34) * *((void *)this + 35);
  unint64_t v6 = v3
     * ProgrammedKernelDimension
     * v4
     * *((int *)this + 86)
     * (uint64_t)*((int *)this + 85)
     * *((int *)this + 87)
     * *((int *)this + 82)
     * *((int *)this + 83)
     * *((int *)this + 84);
  if (v5 >= v6) {
    unint64_t v5 = v3
  }
       * ProgrammedKernelDimension
       * v4
       * *((int *)this + 86)
       * (uint64_t)*((int *)this + 85)
       * *((int *)this + 87)
       * *((int *)this + 82)
       * *((int *)this + 83)
       * *((int *)this + 84);
  return 1.0 - (float)((float)v5 / (float)v6);
}

float ZinIrKernel::CalculateSparsityFromWeightScan(ZinIrKernel *this, float a2)
{
  uint64_t v3 = (ZinIrWeight *)*((void *)this + 73);
  if (!*((void *)v3 + 17)) {
    ZinAssertImpl("Weight must have data for sparsity check");
  }
  unsigned int PaletteVectorSize = ZinIrWeight::GetPaletteVectorSize(v3);
  if ((*((unsigned char *)this + 448) & 2) != 0)
  {
    uint64_t v4 = *((void *)this + 73);
    if (v4)
    {
      unsigned int v5 = *(_DWORD *)(v4 + 8);
    }
    else
    {
      uint64_t v6 = *((void *)this + 77);
      if (v6) {
        unsigned int v5 = ZinTensorFormatToKernelFormat(*(unsigned int *)(v6 + 88));
      }
      else {
        unsigned int v5 = 0;
      }
    }
    if ((ZinKernelFormatIsQuantizationCompatible(v5) & 1) == 0) {
      ZinAssertImpl("incompatible format with zero point");
    }
    if (PaletteVectorSize != 1) {
      ZinAssertImpl("zero point is not supported for vector palettized kernel.");
    }
  }
  uint64_t v7 = *((void *)this + 73);
  if (v7)
  {
    uint64_t v25 = *(void *)(v7 + 56);
    uint64_t v8 = *(void *)(v7 + 80);
    uint64_t v28 = *(void *)(v7 + 64);
    uint64_t v29 = *(void *)(v7 + 72);
    uint64_t v9 = *(void *)(v7 + 88);
    int v10 = *(_DWORD *)(v7 + 8);
LABEL_12:
    long long v11 = *(_OWORD *)(v7 + 72);
    long long v30 = *(_OWORD *)(v7 + 56);
    long long v31 = v11;
    uint64_t v32 = *(void *)(v7 + 88);
    goto LABEL_13;
  }
  uint64_t v20 = *((void *)this + 77);
  if (v20)
  {
    uint64_t v25 = *((void *)this + 31);
    uint64_t v8 = *((void *)this + 34);
    uint64_t v28 = *((void *)this + 32);
    uint64_t v29 = *((void *)this + 33);
    uint64_t v9 = *((void *)this + 35);
    int v10 = ZinTensorFormatToKernelFormat(*(unsigned int *)(v20 + 88));
    uint64_t v7 = *((void *)this + 73);
    if (v7) {
      goto LABEL_12;
    }
  }
  else
  {
    int v10 = 0;
    uint64_t v25 = 0;
    uint64_t v28 = 0;
    uint64_t v29 = 0;
    uint64_t v8 = 0;
    uint64_t v9 = 0;
  }
  if (*((void *)this + 77))
  {
    long long v22 = *(_OWORD *)((char *)this + 248);
    uint64_t v32 = *((void *)this + 35);
    long long v23 = *(_OWORD *)((char *)this + 264);
    long long v30 = v22;
    long long v31 = v23;
  }
  else
  {
    uint64_t v32 = 0;
    long long v30 = 0u;
    long long v31 = 0u;
  }
LABEL_13:
  unint64_t SerializedWeightElementCount = GetSerializedWeightElementCount(v10, (unint64_t *)&v30, PaletteVectorSize);
  if (v25 < 1)
  {
    unint64_t v13 = 0;
  }
  else
  {
    uint64_t v12 = 0;
    unint64_t v13 = 0;
    int v14 = 0;
    do
    {
      int v27 = v14;
      if ((*((unsigned char *)this + 448) & 2) != 0) {
        int ValueAsInt32 = ZinIrVector::GetValueAsInt32(*((ZinIrVector **)this + 74), v12);
      }
      else {
        int ValueAsInt32 = 0;
      }
      if (v28 >= 1)
      {
        for (uint64_t i = 0; i != v28; ++i)
        {
          if (v29 >= 1)
          {
            for (uint64_t j = 0; j != v29; ++j)
            {
              if (v8 >= 1)
              {
                for (uint64_t k = 0; k != v8; ++k)
                {
                  if (v9 >= 1)
                  {
                    for (uint64_t m = 0; m != v9; ++m)
                    {
                      *(void *)&long long v30 = v12;
                      *((void *)&v30 + 1) = i;
                      *(void *)&long long v31 = j;
                      *((void *)&v31 + 1) = k;
                      uint64_t v32 = m;
                      v13 += ZinIrWeight::IsZeroPointAt(*((ZinIrWeight **)this + 73), (uint64_t *)&v30, 0, ValueAsInt32);
                    }
                  }
                }
              }
            }
          }
        }
      }
      int v14 = v27 + PaletteVectorSize;
      uint64_t v12 = (int)(v27 + PaletteVectorSize);
    }
    while (v25 > v12);
  }
  return (float)v13 / (float)SerializedWeightElementCount;
}

uint64_t ZinIrKernel::MirGetPaletteSerializedSize(ZinIrKernel *this, char a2)
{
  int v3 = *((_DWORD *)this + 44);
  if ((v3 - 7) > 0x14) {
    return 0;
  }
  uint64_t v9 = 0;
  if (ZinKernelGetPaletteLUTSize(v3, *((void *)this + 52), &v9)) {
    ZinAssertImpl("Invalid palette information.");
  }
  if ((a2 & 1) == 0) {
    return v9;
  }
  BOOL ShouldUseSparseBinaryForCompression = ZinIrKernel::ShouldUseSparseBinaryForCompression(this);
  if (v9 >= 0) {
    uint64_t v6 = v9;
  }
  else {
    uint64_t v6 = v9 + 1;
  }
  uint64_t v7 = v6 >> 1;
  if (ShouldUseSparseBinaryForCompression) {
    return v7;
  }
  else {
    return v9;
  }
}

BOOL ZinIrKernel::GetPreferredKernelLayoutFormat(ZinIrKernel *this, const ZinIrHalParameters *a2, int a3, int a4, char a5)
{
  uint64_t v7 = *((void *)this + 73);
  if (v7)
  {
    uint64_t v8 = (void *)*((void *)this + 75);
    if (v8)
    {
      if ((*((_DWORD *)this + 44) - 7) <= 0x14 && v8[1] - *v8 > 0x10uLL) {
        return 0;
      }
    }
  }
  uint64_t v9 = *((void *)this + 77);
  if (*((unsigned char *)a2 + 1208)) {
    BOOL v10 = v9 == 0;
  }
  else {
    BOOL v10 = 1;
  }
  if (!v10) {
    return 1;
  }
  if (*((unsigned char *)a2 + 1258)) {
    BOOL v11 = a4 == 0;
  }
  else {
    BOOL v11 = 1;
  }
  if (!v11 && (a5 & 1) == 0)
  {
    if (!*((unsigned char *)a2 + 1208)) {
      ZinAssertImpl("Aligned kernels are required for this FillLowerNEFirst config.");
    }
    return 1;
  }
  unint64_t v12 = *((void *)this + 50);
  if (!*((unsigned char *)a2 + 1208) || v9 || v12 > 1 || (ZinIrKernel::IsMutable(this) & 1) != 0) {
    return a3 && v12 < 2;
  }
  BOOL v14 = !*((unsigned char *)a2 + 1209) && v7 == 0;
  BOOL result = 1;
  if (!v14 && !a3) {
    return 0;
  }
  return result;
}

unint64_t ZinIrKernel::GetOCGChannelCountAfterPaddingFromKernel(ZinIrKernel *this, ZinIrCodegenKernelUtil *a2, const ZinIrHalParameters *a3, char a4)
{
  uint64_t v8 = *((int *)this + 84);
  uint64_t v9 = *((void *)this + 73);
  if (v9)
  {
    BOOL v10 = (uint64_t *)(v9 + 88);
  }
  else
  {
    if (!*((void *)this + 77))
    {
      uint64_t v11 = 0;
      goto LABEL_6;
    }
    BOOL v10 = (uint64_t *)((char *)this + 280);
  }
  uint64_t v11 = *v10;
LABEL_6:
  uint64_t v12 = details::ZinIrSubchannelKernelDimension(v8, *((int *)this + 87), v11, *((_DWORD *)this + 92));
  LOBYTE(v14) = a4;
  return ZinIrCodegenKernelUtil::GetOCGChannelCountAfterPadding((uint64_t)this + 160, a2, *((int *)this + 85), *((int *)this + 86), *((int *)this + 87), *((_DWORD *)this + 42), v12, *((unsigned __int8 *)this + 172), 0, (uint64_t)a3, (unint64_t)a2, v14);
}

uint64_t std::unordered_set<ZinKernelFormat>::unordered_set(uint64_t a1, int *a2, uint64_t a3)
{
  *(_OWORD *)a1 = 0u;
  *(_OWORD *)(a1 + 16) = 0u;
  *(_DWORD *)(a1 + 32) = 1065353216;
  if (a3)
  {
    uint64_t v5 = 4 * a3;
    do
    {
      std::__hash_table<Attribute,std::hash<Attribute>,std::equal_to<Attribute>,std::allocator<Attribute>>::__emplace_unique_key_args<Attribute,Attribute const&>(a1, a2, a2);
      ++a2;
      v5 -= 4;
    }
    while (v5);
  }
  return a1;
}

void sub_2113ABC40(_Unwind_Exception *a1)
{
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table(v1);
  _Unwind_Resume(a1);
}

void std::__function::__func<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_0,std::allocator<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_0>,float ()(unsigned long)>::~__func()
{
}

void *std::__function::__func<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_0,std::allocator<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_0>,float ()(unsigned long)>::__clone()
{
  BOOL result = operator new(0x10uLL);
  *BOOL result = &unk_26C3884C8;
  return result;
}

void std::__function::__func<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_0,std::allocator<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_0>,float ()(unsigned long)>::__clone(uint64_t a1, void *a2)
{
  *a2 = &unk_26C3884C8;
}

float std::__function::__func<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_0,std::allocator<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_0>,float ()(unsigned long)>::operator()()
{
  return 1.0;
}

uint64_t std::__function::__func<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_0,std::allocator<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_0>,float ()(unsigned long)>::target(uint64_t a1, uint64_t a2)
{
  {
    return a1 + 8;
  }
  else
  {
    return 0;
  }
}

void *std::__function::__func<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_0,std::allocator<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_0>,float ()(unsigned long)>::target_type()
{
}

void *std::__function::__value_func<float ()(unsigned long)>::swap[abi:ne180100](void *result, void *a2)
{
  v6[3] = *MEMORY[0x263EF8340];
  if (a2 != result)
  {
    int v3 = result;
    uint64_t v4 = (void *)result[3];
    uint64_t v5 = (void *)a2[3];
    if (v4 == result)
    {
      if (v5 == a2)
      {
        (*(void (**)(void *, void *))(*result + 24))(result, v6);
        (*(void (**)(void))(*(void *)v3[3] + 32))(v3[3]);
        v3[3] = 0;
        (*(void (**)(void, void *))(*(void *)a2[3] + 24))(a2[3], v3);
        (*(void (**)(void))(*(void *)a2[3] + 32))(a2[3]);
        a2[3] = 0;
        v3[3] = v3;
        (*(void (**)(void *, void *))(v6[0] + 24))(v6, a2);
        BOOL result = (void *)(*(uint64_t (**)(void *))(v6[0] + 32))(v6);
      }
      else
      {
        (*(void (**)(void *, void *))(*result + 24))(result, a2);
        BOOL result = (void *)(*(uint64_t (**)(void))(*(void *)v3[3] + 32))(v3[3]);
        v3[3] = a2[3];
      }
      a2[3] = a2;
    }
    else if (v5 == a2)
    {
      (*(void (**)(void *, void *))(*a2 + 24))(a2, result);
      BOOL result = (void *)(*(uint64_t (**)(void))(*(void *)a2[3] + 32))(a2[3]);
      a2[3] = v3[3];
      v3[3] = v3;
    }
    else
    {
      result[3] = v5;
      a2[3] = v4;
    }
  }
  return result;
}

void sub_2113ABF80(_Unwind_Exception *a1, int a2)
{
  if (!a2) {
    _Unwind_Resume(a1);
  }
  __clang_call_terminate(a1);
}

void std::__function::__func<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_1,std::allocator<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_1>,float ()(unsigned long)>::~__func()
{
}

void *std::__function::__func<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_1,std::allocator<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_1>,float ()(unsigned long)>::__clone(uint64_t a1)
{
  BOOL result = operator new(0x10uLL);
  uint64_t v3 = *(void *)(a1 + 8);
  *BOOL result = &unk_26C388520;
  result[1] = v3;
  return result;
}

uint64_t std::__function::__func<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_1,std::allocator<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_1>,float ()(unsigned long)>::__clone(uint64_t result, void *a2)
{
  uint64_t v2 = *(void *)(result + 8);
  *a2 = &unk_26C388520;
  a2[1] = v2;
  return result;
}

uint64_t std::__function::__func<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_1,std::allocator<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_1>,float ()(unsigned long)>::operator()(uint64_t a1, uint64_t *a2)
{
  return ZinIrVector::GetAt<float>(**(void **)(a1 + 8), *a2);
}

uint64_t std::__function::__func<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_1,std::allocator<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_1>,float ()(unsigned long)>::target(uint64_t a1, uint64_t a2)
{
  {
    return a1 + 8;
  }
  else
  {
    return 0;
  }
}

void *std::__function::__func<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_1,std::allocator<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_1>,float ()(unsigned long)>::target_type()
{
}

void std::__function::__func<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_2,std::allocator<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_2>,float ()(unsigned long)>::~__func()
{
}

void *std::__function::__func<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_2,std::allocator<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_2>,float ()(unsigned long)>::__clone()
{
  BOOL result = operator new(0x10uLL);
  *BOOL result = &unk_26C388578;
  return result;
}

void std::__function::__func<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_2,std::allocator<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_2>,float ()(unsigned long)>::__clone(uint64_t a1, void *a2)
{
  *a2 = &unk_26C388578;
}

double std::__function::__func<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_2,std::allocator<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_2>,float ()(unsigned long)>::operator()()
{
  return 0.0;
}

uint64_t std::__function::__func<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_2,std::allocator<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_2>,float ()(unsigned long)>::target(uint64_t a1, uint64_t a2)
{
  {
    return a1 + 8;
  }
  else
  {
    return 0;
  }
}

void *std::__function::__func<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_2,std::allocator<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_2>,float ()(unsigned long)>::target_type()
{
}

void std::__function::__func<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_3,std::allocator<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_3>,float ()(unsigned long)>::~__func()
{
}

void *std::__function::__func<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_3,std::allocator<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_3>,float ()(unsigned long)>::__clone(uint64_t a1)
{
  BOOL result = operator new(0x10uLL);
  uint64_t v3 = *(void *)(a1 + 8);
  *BOOL result = &unk_26C3885D0;
  result[1] = v3;
  return result;
}

uint64_t std::__function::__func<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_3,std::allocator<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_3>,float ()(unsigned long)>::__clone(uint64_t result, void *a2)
{
  uint64_t v2 = *(void *)(result + 8);
  *a2 = &unk_26C3885D0;
  a2[1] = v2;
  return result;
}

uint64_t std::__function::__func<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_3,std::allocator<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_3>,float ()(unsigned long)>::operator()(uint64_t a1, uint64_t *a2)
{
  return ZinIrVector::GetAt<float>(**(void **)(a1 + 8), *a2);
}

uint64_t std::__function::__func<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_3,std::allocator<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_3>,float ()(unsigned long)>::target(uint64_t a1, uint64_t a2)
{
  {
    return a1 + 8;
  }
  else
  {
    return 0;
  }
}

void *std::__function::__func<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_3,std::allocator<ZinIrKernel::FoldWeightsWithScale(ZinIrKernel*)::$_3>,float ()(unsigned long)>::target_type()
{
}

void *std::allocate_shared[abi:ne180100]<ZinIrTransformRemap,std::allocator<ZinIrTransformRemap>,ZinTensorDimensions const&,void>@<X0>(const ZinTensorDimensions *a1@<X1>, void *a2@<X8>)
{
  uint64_t v4 = operator new(0x50uLL);
  BOOL result = std::__shared_ptr_emplace<ZinIrTransformRemap>::__shared_ptr_emplace[abi:ne180100]<ZinTensorDimensions const&,std::allocator<ZinIrTransformRemap>,0>(v4, a1);
  *a2 = v4 + 3;
  a2[1] = v4;
  return result;
}

void sub_2113AC270(_Unwind_Exception *a1)
{
  operator delete(v1);
  _Unwind_Resume(a1);
}

void *std::__shared_ptr_emplace<ZinIrTransformRemap>::__shared_ptr_emplace[abi:ne180100]<ZinTensorDimensions const&,std::allocator<ZinIrTransformRemap>,0>(void *a1, const ZinTensorDimensions *a2)
{
  a1[1] = 0;
  a1[2] = 0;
  *a1 = &unk_26C388E78;
  ZinIrTransformRemap::ZinIrTransformRemap((ZinIrTransformRemap *)(a1 + 3), a2);
  return a1;
}

void sub_2113AC2CC(_Unwind_Exception *a1)
{
  std::__shared_weak_count::~__shared_weak_count(v1);
  _Unwind_Resume(a1);
}

void std::__shared_ptr_emplace<ZinIrTransformRemap>::~__shared_ptr_emplace(std::__shared_weak_count *this)
{
  this->__vftable = (std::__shared_weak_count_vtbl *)&unk_26C388E78;
  std::__shared_weak_count::~__shared_weak_count(this);
}

void std::__shared_ptr_emplace<ZinIrTransformRemap>::~__shared_ptr_emplace(std::__shared_weak_count *a1)
{
  a1->__vftable = (std::__shared_weak_count_vtbl *)&unk_26C388E78;
  std::__shared_weak_count::~__shared_weak_count(a1);

  JUMPOUT(0x21667D3C0);
}

uint64_t std::__shared_ptr_emplace<ZinIrTransformRemap>::__on_zero_shared(uint64_t a1)
{
  return (**(uint64_t (***)(void))(a1 + 24))();
}

uint64_t std::allocate_shared[abi:ne180100]<ZinIrTransformShuffle,std::allocator<ZinIrTransformShuffle>,std::vector<unsigned long>,ZinIrVector *,void>@<X0>(__n128 *a1@<X1>, unint64_t *a2@<X2>, void *a3@<X8>)
{
  uint64_t v6 = (char *)operator new(0x48uLL);
  uint64_t result = std::__shared_ptr_emplace<ZinIrTransformShuffle>::__shared_ptr_emplace[abi:ne180100]<std::vector<unsigned long>,ZinIrVector *,std::allocator<ZinIrTransformShuffle>,0>((uint64_t)v6, a1, a2);
  *a3 = v6 + 24;
  a3[1] = v6;
  return result;
}

void sub_2113AC3CC(_Unwind_Exception *a1)
{
  operator delete(v1);
  _Unwind_Resume(a1);
}

uint64_t std::__shared_ptr_emplace<ZinIrTransformShuffle>::__shared_ptr_emplace[abi:ne180100]<std::vector<unsigned long>,ZinIrVector *,std::allocator<ZinIrTransformShuffle>,0>(uint64_t a1, __n128 *a2, unint64_t *a3)
{
  *(void *)(a1 + 8) = 0;
  *(void *)(a1 + 16) = 0;
  *(void *)a1 = &unk_26C3890A8;
  ZinIrTransformShuffle::ZinIrTransformShuffle((__n128 *)(a1 + 24), a2, *a3);
  return a1;
}

void sub_2113AC42C(_Unwind_Exception *a1)
{
  std::__shared_weak_count::~__shared_weak_count(v1);
  _Unwind_Resume(a1);
}

void std::__shared_ptr_emplace<ZinIrTransformShuffle>::~__shared_ptr_emplace(std::__shared_weak_count *this)
{
  this->__vftable = (std::__shared_weak_count_vtbl *)&unk_26C3890A8;
  std::__shared_weak_count::~__shared_weak_count(this);
}

void std::__shared_ptr_emplace<ZinIrTransformShuffle>::~__shared_ptr_emplace(std::__shared_weak_count *a1)
{
  a1->__vftable = (std::__shared_weak_count_vtbl *)&unk_26C3890A8;
  std::__shared_weak_count::~__shared_weak_count(a1);

  JUMPOUT(0x21667D3C0);
}

uint64_t std::__shared_ptr_emplace<ZinIrTransformShuffle>::__on_zero_shared(uint64_t a1)
{
  return (**(uint64_t (***)(void))(a1 + 24))();
}

void *std::allocate_shared[abi:ne180100]<ZinIrTransformDuplicate,std::allocator<ZinIrTransformDuplicate>,unsigned long &,void>@<X0>(uint64_t *a1@<X1>, void *a2@<X8>)
{
  uint64_t v4 = operator new(0x30uLL);
  uint64_t result = std::__shared_ptr_emplace<ZinIrTransformDuplicate>::__shared_ptr_emplace[abi:ne180100]<unsigned long &,std::allocator<ZinIrTransformDuplicate>,0>(v4, a1);
  *a2 = v4 + 3;
  a2[1] = v4;
  return result;
}

void sub_2113AC524(_Unwind_Exception *a1)
{
  operator delete(v1);
  _Unwind_Resume(a1);
}

void *std::__shared_ptr_emplace<ZinIrTransformDuplicate>::__shared_ptr_emplace[abi:ne180100]<unsigned long &,std::allocator<ZinIrTransformDuplicate>,0>(void *a1, uint64_t *a2)
{
  a1[1] = 0;
  a1[2] = 0;
  *a1 = &unk_26C389118;
  ZinIrTransformDuplicate::ZinIrTransformDuplicate((ZinIrTransformDuplicate *)(a1 + 3), *a2, 1);
  return a1;
}

void sub_2113AC588(_Unwind_Exception *a1)
{
  std::__shared_weak_count::~__shared_weak_count(v1);
  _Unwind_Resume(a1);
}

void *std::allocate_shared[abi:ne180100]<ZinIrTransformWeightShuffle,std::allocator<ZinIrTransformWeightShuffle>,ZinKernelDimensions const&,ZinIrScratchBuffer<ZinKernelPosition> &,ZinIrVector *,void>@<X0>(long long *a1@<X1>, uint64_t a2@<X2>, uint64_t *a3@<X3>, void *a4@<X8>)
{
  uint64_t v8 = operator new(0x98uLL);
  uint64_t result = std::__shared_ptr_emplace<ZinIrTransformWeightShuffle>::__shared_ptr_emplace[abi:ne180100]<ZinKernelDimensions const&,ZinIrScratchBuffer<ZinKernelPosition> &,ZinIrVector *,std::allocator<ZinIrTransformWeightShuffle>,0>(v8, a1, a2, a3);
  *a4 = v8 + 3;
  a4[1] = v8;
  return result;
}

void sub_2113AC5FC(_Unwind_Exception *a1)
{
  operator delete(v1);
  _Unwind_Resume(a1);
}

void *std::__shared_ptr_emplace<ZinIrTransformWeightShuffle>::__shared_ptr_emplace[abi:ne180100]<ZinKernelDimensions const&,ZinIrScratchBuffer<ZinKernelPosition> &,ZinIrVector *,std::allocator<ZinIrTransformWeightShuffle>,0>(void *a1, long long *a2, uint64_t a3, uint64_t *a4)
{
  a1[1] = 0;
  a1[2] = 0;
  *a1 = &unk_26C389268;
  ZinIrTransformWeightShuffle::ZinIrTransformWeightShuffle((uint64_t)(a1 + 3), a2, a3, *a4);
  return a1;
}

void sub_2113AC65C(_Unwind_Exception *a1)
{
  std::__shared_weak_count::~__shared_weak_count(v1);
  _Unwind_Resume(a1);
}

void std::__shared_ptr_emplace<ZinIrTransformWeightShuffle>::~__shared_ptr_emplace(std::__shared_weak_count *this)
{
  this->__vftable = (std::__shared_weak_count_vtbl *)&unk_26C389268;
  std::__shared_weak_count::~__shared_weak_count(this);
}

void std::__shared_ptr_emplace<ZinIrTransformWeightShuffle>::~__shared_ptr_emplace(std::__shared_weak_count *a1)
{
  a1->__vftable = (std::__shared_weak_count_vtbl *)&unk_26C389268;
  std::__shared_weak_count::~__shared_weak_count(a1);

  JUMPOUT(0x21667D3C0);
}

uint64_t std::__shared_ptr_emplace<ZinIrTransformWeightShuffle>::__on_zero_shared(uint64_t a1)
{
  return (**(uint64_t (***)(void))(a1 + 24))();
}

void *std::allocate_shared[abi:ne180100]<ZinIrVector,std::allocator<ZinIrVector>,ZinIrVector&,void>@<X0>(uint64_t a1@<X1>, void *a2@<X8>)
{
  uint64_t v4 = operator new(0x140uLL);
  uint64_t result = std::__shared_ptr_emplace<ZinIrVector>::__shared_ptr_emplace[abi:ne180100]<ZinIrVector&,std::allocator<ZinIrVector>,0>(v4, a1);
  *a2 = v4 + 3;
  a2[1] = v4;
  return result;
}

void sub_2113AC754(_Unwind_Exception *a1)
{
  operator delete(v1);
  _Unwind_Resume(a1);
}

void *std::__shared_ptr_emplace<ZinIrVector>::__shared_ptr_emplace[abi:ne180100]<ZinIrVector&,std::allocator<ZinIrVector>,0>(void *a1, uint64_t a2)
{
  a1[1] = 0;
  a1[2] = 0;
  *a1 = &unk_26C388970;
  std::construct_at[abi:ne180100]<ZinIrVector,ZinIrVector&,ZinIrVector*>((uint64_t)(a1 + 3), a2);
  return a1;
}

void sub_2113AC7B0(_Unwind_Exception *a1)
{
  std::__shared_weak_count::~__shared_weak_count(v1);
  _Unwind_Resume(a1);
}

uint64_t std::construct_at[abi:ne180100]<ZinIrVector,ZinIrVector&,ZinIrVector*>(uint64_t a1, uint64_t a2)
{
  *(void *)a1 = &unk_26C348E90;
  long long v4 = *(_OWORD *)(a2 + 8);
  long long v5 = *(_OWORD *)(a2 + 24);
  long long v6 = *(_OWORD *)(a2 + 40);
  *(_OWORD *)(a1 + 56) = *(_OWORD *)(a2 + 56);
  *(_OWORD *)(a1 + 4std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v6;
  *(_OWORD *)(a1 + 24) = v5;
  *(_OWORD *)(a1 + 8) = v4;
  long long v7 = *(_OWORD *)(a2 + 72);
  long long v8 = *(_OWORD *)(a2 + 88);
  long long v9 = *(_OWORD *)(a2 + 104);
  *(_OWORD *)(a1 + 12std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = *(_OWORD *)(a2 + 120);
  *(_OWORD *)(a1 + 104) = v9;
  *(_OWORD *)(a1 + 88) = v8;
  *(_OWORD *)(a1 + 72) = v7;
  uint64_t v10 = *(void *)(a2 + 144);
  *(void *)(a1 + 136) = *(void *)(a2 + 136);
  *(void *)(a1 + 144) = v10;
  if (v10) {
    atomic_fetch_add_explicit((atomic_ullong *volatile)(v10 + 8), 1uLL, memory_order_relaxed);
  }
  uint64_t v11 = *(void *)(a2 + 152);
  *(void *)(a1 + 16std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  *(void *)(a1 + 152) = v11;
  *(void *)(a1 + 168) = 0;
  *(void *)(a1 + 176) = 0;
  std::vector<std::shared_ptr<ZinIrTransform>>::__init_with_size[abi:ne180100]<std::shared_ptr<ZinIrTransform>*,std::shared_ptr<ZinIrTransform>*>((void *)(a1 + 160), *(void **)(a2 + 160), *(void **)(a2 + 168), (uint64_t)(*(void *)(a2 + 168) - *(void *)(a2 + 160)) >> 4);
  uint64_t v12 = (std::string *)(a1 + 184);
  if (*(char *)(a2 + 207) < 0)
  {
    std::string::__init_copy_ctor_external(v12, *(const std::string::value_type **)(a2 + 184), *(void *)(a2 + 192));
  }
  else
  {
    long long v13 = *(_OWORD *)(a2 + 184);
    *(void *)(a1 + 20std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = *(void *)(a2 + 200);
    *(_OWORD *)&v12->__r_.__value_.__l.__data_ = v13;
  }
  long long v14 = *(_OWORD *)(a2 + 208);
  *(_DWORD *)(a1 + 224) = *(_DWORD *)(a2 + 224);
  *(_OWORD *)(a1 + 208) = v14;
  long long v15 = *(_OWORD *)(a2 + 232);
  long long v16 = *(_OWORD *)(a2 + 248);
  *(_OWORD *)(a1 + 26std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = *(_OWORD *)(a2 + 260);
  *(_OWORD *)(a1 + 248) = v16;
  *(_OWORD *)(a1 + 232) = v15;
  *(void *)a1 = &unk_26C343C60;
  uint64_t v17 = *(void *)(a2 + 280);
  *(unsigned char *)(a1 + 288) = *(unsigned char *)(a2 + 288);
  *(void *)(a1 + 28std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v17;
  return a1;
}

void sub_2113AC920(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100]((void ***)va);
  long long v4 = *(std::__shared_weak_count **)(v2 + 144);
  if (v4) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v4);
  }
  _Unwind_Resume(a1);
}

void *std::allocate_shared[abi:ne180100]<ZinIrVectorFoldBiasWithBotScaleBotBias,std::allocator<ZinIrVectorFoldBiasWithBotScaleBotBias>,std::shared_ptr<ZinIrVector> &,std::shared_ptr<ZinIrVector> &,void>@<X0>(uint64_t *a1@<X1>, uint64_t *a2@<X2>, void *a3@<X8>)
{
  long long v6 = operator new(0x40uLL);
  uint64_t result = std::__shared_ptr_emplace<ZinIrVectorFoldBiasWithBotScaleBotBias>::__shared_ptr_emplace[abi:ne180100]<std::shared_ptr<ZinIrVector> &,std::shared_ptr<ZinIrVector> &,std::allocator<ZinIrVectorFoldBiasWithBotScaleBotBias>,0>(v6, a1, a2);
  *a3 = v6 + 3;
  a3[1] = v6;
  return result;
}

void sub_2113AC99C(_Unwind_Exception *a1)
{
  operator delete(v1);
  _Unwind_Resume(a1);
}

void *std::__shared_ptr_emplace<ZinIrVectorFoldBiasWithBotScaleBotBias>::__shared_ptr_emplace[abi:ne180100]<std::shared_ptr<ZinIrVector> &,std::shared_ptr<ZinIrVector> &,std::allocator<ZinIrVectorFoldBiasWithBotScaleBotBias>,0>(void *a1, uint64_t *a2, uint64_t *a3)
{
  a1[1] = 0;
  a1[2] = 0;
  *a1 = &unk_26C389508;
  std::construct_at[abi:ne180100]<ZinIrVectorFoldBiasWithBotScaleBotBias,std::shared_ptr<ZinIrVector> &,std::shared_ptr<ZinIrVector> &,ZinIrVectorFoldBiasWithBotScaleBotBias*>(a1 + 3, a2, a3);
  return a1;
}

void sub_2113AC9F8(_Unwind_Exception *a1)
{
  std::__shared_weak_count::~__shared_weak_count(v1);
  _Unwind_Resume(a1);
}

void std::__shared_ptr_emplace<ZinIrVectorFoldBiasWithBotScaleBotBias>::~__shared_ptr_emplace(std::__shared_weak_count *this)
{
  this->__vftable = (std::__shared_weak_count_vtbl *)&unk_26C389508;
  std::__shared_weak_count::~__shared_weak_count(this);
}

void std::__shared_ptr_emplace<ZinIrVectorFoldBiasWithBotScaleBotBias>::~__shared_ptr_emplace(std::__shared_weak_count *a1)
{
  a1->__vftable = (std::__shared_weak_count_vtbl *)&unk_26C389508;
  std::__shared_weak_count::~__shared_weak_count(a1);

  JUMPOUT(0x21667D3C0);
}

uint64_t std::__shared_ptr_emplace<ZinIrVectorFoldBiasWithBotScaleBotBias>::__on_zero_shared(uint64_t a1)
{
  return (**(uint64_t (***)(void))(a1 + 24))();
}

void *std::construct_at[abi:ne180100]<ZinIrVectorFoldBiasWithBotScaleBotBias,std::shared_ptr<ZinIrVector> &,std::shared_ptr<ZinIrVector> &,ZinIrVectorFoldBiasWithBotScaleBotBias*>(void *a1, uint64_t *a2, uint64_t *a3)
{
  long long v4 = (std::__shared_weak_count *)a2[1];
  uint64_t v9 = *a2;
  uint64_t v10 = v4;
  if (v4) {
    atomic_fetch_add_explicit(&v4->__shared_owners_, 1uLL, memory_order_relaxed);
  }
  long long v5 = (std::__shared_weak_count *)a3[1];
  uint64_t v7 = *a3;
  long long v8 = v5;
  if (v5) {
    atomic_fetch_add_explicit(&v5->__shared_owners_, 1uLL, memory_order_relaxed);
  }
  ZinIrVectorFoldBiasWithBotScaleBotBias::ZinIrVectorFoldBiasWithBotScaleBotBias(a1, &v9, &v7);
  if (v8) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v8);
  }
  if (v10) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v10);
  }
  return a1;
}

void sub_2113ACB2C(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, std::__shared_weak_count *a10, uint64_t a11, std::__shared_weak_count *a12)
{
  if (a10) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a10);
  }
  if (a12) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a12);
  }
  _Unwind_Resume(exception_object);
}

void *std::allocate_shared[abi:ne180100]<ZinIrVectorFoldBotBiasWithBotScaleBias,std::allocator<ZinIrVectorFoldBotBiasWithBotScaleBias>,std::shared_ptr<ZinIrVector> &,std::shared_ptr<ZinIrVector> &,void>@<X0>(uint64_t *a1@<X1>, uint64_t *a2@<X2>, void *a3@<X8>)
{
  long long v6 = operator new(0x40uLL);
  uint64_t result = std::__shared_ptr_emplace<ZinIrVectorFoldBotBiasWithBotScaleBias>::__shared_ptr_emplace[abi:ne180100]<std::shared_ptr<ZinIrVector> &,std::shared_ptr<ZinIrVector> &,std::allocator<ZinIrVectorFoldBotBiasWithBotScaleBias>,0>(v6, a1, a2);
  *a3 = v6 + 3;
  a3[1] = v6;
  return result;
}

void sub_2113ACBA0(_Unwind_Exception *a1)
{
  operator delete(v1);
  _Unwind_Resume(a1);
}

void *std::__shared_ptr_emplace<ZinIrVectorFoldBotBiasWithBotScaleBias>::__shared_ptr_emplace[abi:ne180100]<std::shared_ptr<ZinIrVector> &,std::shared_ptr<ZinIrVector> &,std::allocator<ZinIrVectorFoldBotBiasWithBotScaleBias>,0>(void *a1, uint64_t *a2, uint64_t *a3)
{
  a1[1] = 0;
  a1[2] = 0;
  *a1 = &unk_26C389540;
  std::construct_at[abi:ne180100]<ZinIrVectorFoldBotBiasWithBotScaleBias,std::shared_ptr<ZinIrVector> &,std::shared_ptr<ZinIrVector> &,ZinIrVectorFoldBotBiasWithBotScaleBias*>(a1 + 3, a2, a3);
  return a1;
}

void sub_2113ACBFC(_Unwind_Exception *a1)
{
  std::__shared_weak_count::~__shared_weak_count(v1);
  _Unwind_Resume(a1);
}

void std::__shared_ptr_emplace<ZinIrVectorFoldBotBiasWithBotScaleBias>::~__shared_ptr_emplace(std::__shared_weak_count *this)
{
  this->__vftable = (std::__shared_weak_count_vtbl *)&unk_26C389540;
  std::__shared_weak_count::~__shared_weak_count(this);
}

void std::__shared_ptr_emplace<ZinIrVectorFoldBotBiasWithBotScaleBias>::~__shared_ptr_emplace(std::__shared_weak_count *a1)
{
  a1->__vftable = (std::__shared_weak_count_vtbl *)&unk_26C389540;
  std::__shared_weak_count::~__shared_weak_count(a1);

  JUMPOUT(0x21667D3C0);
}

uint64_t std::__shared_ptr_emplace<ZinIrVectorFoldBotBiasWithBotScaleBias>::__on_zero_shared(uint64_t a1)
{
  return (**(uint64_t (***)(void))(a1 + 24))();
}

void *std::construct_at[abi:ne180100]<ZinIrVectorFoldBotBiasWithBotScaleBias,std::shared_ptr<ZinIrVector> &,std::shared_ptr<ZinIrVector> &,ZinIrVectorFoldBotBiasWithBotScaleBias*>(void *a1, uint64_t *a2, uint64_t *a3)
{
  long long v4 = (std::__shared_weak_count *)a2[1];
  uint64_t v9 = *a2;
  uint64_t v10 = v4;
  if (v4) {
    atomic_fetch_add_explicit(&v4->__shared_owners_, 1uLL, memory_order_relaxed);
  }
  long long v5 = (std::__shared_weak_count *)a3[1];
  uint64_t v7 = *a3;
  long long v8 = v5;
  if (v5) {
    atomic_fetch_add_explicit(&v5->__shared_owners_, 1uLL, memory_order_relaxed);
  }
  ZinIrVectorFoldBotBiasWithBotScaleBias::ZinIrVectorFoldBotBiasWithBotScaleBias(a1, &v9, &v7);
  if (v8) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v8);
  }
  if (v10) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v10);
  }
  return a1;
}

void sub_2113ACD30(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, std::__shared_weak_count *a10, uint64_t a11, std::__shared_weak_count *a12)
{
  if (a10) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a10);
  }
  if (a12) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a12);
  }
  _Unwind_Resume(exception_object);
}

void *std::allocate_shared[abi:ne180100]<ZinIrVectorFoldBotScaleWithBotBiasBias,std::allocator<ZinIrVectorFoldBotScaleWithBotBiasBias>,std::shared_ptr<ZinIrVector> &,std::shared_ptr<ZinIrVector> &,void>@<X0>(uint64_t *a1@<X1>, uint64_t *a2@<X2>, void *a3@<X8>)
{
  long long v6 = operator new(0x40uLL);
  uint64_t result = std::__shared_ptr_emplace<ZinIrVectorFoldBotScaleWithBotBiasBias>::__shared_ptr_emplace[abi:ne180100]<std::shared_ptr<ZinIrVector> &,std::shared_ptr<ZinIrVector> &,std::allocator<ZinIrVectorFoldBotScaleWithBotBiasBias>,0>(v6, a1, a2);
  *a3 = v6 + 3;
  a3[1] = v6;
  return result;
}

void sub_2113ACDA4(_Unwind_Exception *a1)
{
  operator delete(v1);
  _Unwind_Resume(a1);
}

void *std::__shared_ptr_emplace<ZinIrVectorFoldBotScaleWithBotBiasBias>::__shared_ptr_emplace[abi:ne180100]<std::shared_ptr<ZinIrVector> &,std::shared_ptr<ZinIrVector> &,std::allocator<ZinIrVectorFoldBotScaleWithBotBiasBias>,0>(void *a1, uint64_t *a2, uint64_t *a3)
{
  a1[1] = 0;
  a1[2] = 0;
  *a1 = &unk_26C389578;
  std::construct_at[abi:ne180100]<ZinIrVectorFoldBotScaleWithBotBiasBias,std::shared_ptr<ZinIrVector> &,std::shared_ptr<ZinIrVector> &,ZinIrVectorFoldBotScaleWithBotBiasBias*>(a1 + 3, a2, a3);
  return a1;
}

void sub_2113ACE00(_Unwind_Exception *a1)
{
  std::__shared_weak_count::~__shared_weak_count(v1);
  _Unwind_Resume(a1);
}

void std::__shared_ptr_emplace<ZinIrVectorFoldBotScaleWithBotBiasBias>::~__shared_ptr_emplace(std::__shared_weak_count *this)
{
  this->__vftable = (std::__shared_weak_count_vtbl *)&unk_26C389578;
  std::__shared_weak_count::~__shared_weak_count(this);
}

void std::__shared_ptr_emplace<ZinIrVectorFoldBotScaleWithBotBiasBias>::~__shared_ptr_emplace(std::__shared_weak_count *a1)
{
  a1->__vftable = (std::__shared_weak_count_vtbl *)&unk_26C389578;
  std::__shared_weak_count::~__shared_weak_count(a1);

  JUMPOUT(0x21667D3C0);
}

uint64_t std::__shared_ptr_emplace<ZinIrVectorFoldBotScaleWithBotBiasBias>::__on_zero_shared(uint64_t a1)
{
  return (**(uint64_t (***)(void))(a1 + 24))();
}

void *std::construct_at[abi:ne180100]<ZinIrVectorFoldBotScaleWithBotBiasBias,std::shared_ptr<ZinIrVector> &,std::shared_ptr<ZinIrVector> &,ZinIrVectorFoldBotScaleWithBotBiasBias*>(void *a1, uint64_t *a2, uint64_t *a3)
{
  long long v4 = (std::__shared_weak_count *)a2[1];
  uint64_t v9 = *a2;
  uint64_t v10 = v4;
  if (v4) {
    atomic_fetch_add_explicit(&v4->__shared_owners_, 1uLL, memory_order_relaxed);
  }
  long long v5 = (std::__shared_weak_count *)a3[1];
  uint64_t v7 = *a3;
  long long v8 = v5;
  if (v5) {
    atomic_fetch_add_explicit(&v5->__shared_owners_, 1uLL, memory_order_relaxed);
  }
  ZinIrVectorFoldBotScaleWithBotBiasBias::ZinIrVectorFoldBotScaleWithBotBiasBias(a1, &v9, &v7);
  if (v8) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v8);
  }
  if (v10) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v10);
  }
  return a1;
}

void sub_2113ACF34(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, std::__shared_weak_count *a10, uint64_t a11, std::__shared_weak_count *a12)
{
  if (a10) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a10);
  }
  if (a12) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a12);
  }
  _Unwind_Resume(exception_object);
}

void *std::allocate_shared[abi:ne180100]<ZinIrVectorEWMultiply,std::allocator<ZinIrVectorEWMultiply>,std::shared_ptr<ZinIrVector> &,void>@<X0>(uint64_t *a1@<X1>, void *a2@<X8>)
{
  long long v4 = operator new(0x30uLL);
  uint64_t result = std::__shared_ptr_emplace<ZinIrVectorEWMultiply>::__shared_ptr_emplace[abi:ne180100]<std::shared_ptr<ZinIrVector> &,std::allocator<ZinIrVectorEWMultiply>,0>(v4, a1);
  *a2 = v4 + 3;
  a2[1] = v4;
  return result;
}

void sub_2113ACFA0(_Unwind_Exception *a1)
{
  operator delete(v1);
  _Unwind_Resume(a1);
}

void *std::__shared_ptr_emplace<ZinIrVectorEWMultiply>::__shared_ptr_emplace[abi:ne180100]<std::shared_ptr<ZinIrVector> &,std::allocator<ZinIrVectorEWMultiply>,0>(void *a1, uint64_t *a2)
{
  a1[1] = 0;
  a1[2] = 0;
  *a1 = &unk_26C3890E0;
  std::construct_at[abi:ne180100]<ZinIrVectorEWMultiply,std::shared_ptr<ZinIrVector> &,ZinIrVectorEWMultiply*>(a1 + 3, a2);
  return a1;
}

void sub_2113ACFFC(_Unwind_Exception *a1)
{
  std::__shared_weak_count::~__shared_weak_count(v1);
  _Unwind_Resume(a1);
}

void std::__shared_ptr_emplace<ZinIrVectorEWMultiply>::~__shared_ptr_emplace(std::__shared_weak_count *this)
{
  this->__vftable = (std::__shared_weak_count_vtbl *)&unk_26C3890E0;
  std::__shared_weak_count::~__shared_weak_count(this);
}

void std::__shared_ptr_emplace<ZinIrVectorEWMultiply>::~__shared_ptr_emplace(std::__shared_weak_count *a1)
{
  a1->__vftable = (std::__shared_weak_count_vtbl *)&unk_26C3890E0;
  std::__shared_weak_count::~__shared_weak_count(a1);

  JUMPOUT(0x21667D3C0);
}

uint64_t std::__shared_ptr_emplace<ZinIrVectorEWMultiply>::__on_zero_shared(uint64_t a1)
{
  return (**(uint64_t (***)(void))(a1 + 24))();
}

void *std::construct_at[abi:ne180100]<ZinIrVectorEWMultiply,std::shared_ptr<ZinIrVector> &,ZinIrVectorEWMultiply*>(void *a1, uint64_t *a2)
{
  uint64_t v3 = (std::__shared_weak_count *)a2[1];
  uint64_t v5 = *a2;
  long long v6 = v3;
  if (v3) {
    atomic_fetch_add_explicit(&v3->__shared_owners_, 1uLL, memory_order_relaxed);
  }
  ZinIrVectorEWMultiply::ZinIrVectorEWMultiply(a1, &v5);
  if (v6) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v6);
  }
  return a1;
}

void sub_2113AD108(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, std::__shared_weak_count *a10)
{
  if (a10) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a10);
  }
  _Unwind_Resume(exception_object);
}

void ZinIrKernel::AddWeightsToSHA(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "Invalid kernel weight format to add to the SHA\n", a5, a6, a7, a8, 0);
}

uint64_t std::make_unique[abi:ne180100]<ZinIrKernel,std::string,ZinKernelDescriptor &,decltype(nullptr),decltype(nullptr),std::unique_ptr<ZinIrVector>,decltype(nullptr),SHAUpdateMode const&>(uint64_t a1, uint64_t *a2, uint64_t *a3)
{
  uint64_t v4 = *a2;
  *a2 = 0;
  if (v4) {
    std::default_delete<ZinIrVector>::operator()[abi:ne180100]((uint64_t)a2, v4);
  }
  uint64_t result = *a3;
  if (*a3)
  {
    OUTLINED_FUNCTION_0_4();
    return (*(uint64_t (**)(void))(v6 + 16))();
  }
  return result;
}

uint64_t std::make_unique[abi:ne180100]<ZinIrKernel,std::string,ZinKernelDescriptor const&,decltype(nullptr),std::unique_ptr<ZinIrVector>,std::unique_ptr<ZinIrVector>,decltype(nullptr),SHAUpdateMode const&>(uint64_t a1, uint64_t *a2)
{
  uint64_t result = *a2;
  if (*a2)
  {
    OUTLINED_FUNCTION_0_4();
    return (*(uint64_t (**)(void))(v3 + 16))();
  }
  return result;
}

void ZinIrKernel::Create4bitPalKernelFrom3bitPalKernel(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void ZinIrKernel::MergeResizeNNIntoConvKernel(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "Bias is assumed to be nullptr at this time.", a5, a6, a7, a8, 0);
}

void ZinIrKernel::CreateDynamicKernel(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "Insufficient kernel coeff\n", a5, a6, a7, a8, 0);
}

void ZinIrKernel::FuseScaleBiasWithBottom(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void ZinIrKernel::AdjustUnityKernel(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void ZinIrMatrixDecompositionUnit::ZinIrMatrixDecompositionUnit(ZinIrMatrixDecompositionUnit *this, const ZinIrMatrixDecompositionUnitInfo *a2)
{
  std::string __p = 0;
  uint64_t v5 = 0;
  uint64_t v6 = 0;
  ZinIrUnit::ZinIrUnit(this, (uint64_t)&__p);
  if (__p)
  {
    uint64_t v5 = __p;
    operator delete(__p);
  }
  *(void *)this = &unk_26C352648;
  ZinIrMatrixDecompositionUnitInfo::ZinIrMatrixDecompositionUnitInfo((ZinIrMatrixDecompositionUnit *)((char *)this + 56), a2);
}

void sub_2113AD450(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11)
{
  ZinIrUnit::~ZinIrUnit(v11);
  _Unwind_Resume(a1);
}

uint64_t ZinIrMatrixDecompositionUnit::TensorDimensions(ZinIrMatrixDecompositionUnit *this, const ZinIrHalParameters *a2, ZinTensorDimensions *a3, ZinIrUnitStatus *a4)
{
  int v4 = *((_DWORD *)this + 34);
  if (!v4)
  {
    uint64_t v5 = 4;
    goto LABEL_5;
  }
  if (v4 == 1)
  {
    uint64_t v5 = 3;
LABEL_5:
    *(void *)a3 = *(void *)(*((void *)this + 1) + 8);
    *((void *)a3 + 1) = v5;
    *((void *)a3 + 2) = 1;
    *((void *)a3 + 3) = v5;
    *((void *)a3 + 4) = 1;
  }
  return 0;
}

uint64_t ZinIrMatrixDecompositionUnit::ValidateBottomDimensions(ZinIrMatrixDecompositionUnit *this, CFArrayRef *a2)
{
  uint64_t v2 = (int64x2_t *)*((void *)this + 1);
  int v3 = *((_DWORD *)this + 34);
  if (v3 == 1)
  {
    if ((vmaxv_u16((uint16x4_t)vmovn_s32((int32x4_t)vmvnq_s8((int8x16_t)vuzp1q_s32((int32x4_t)vceqq_s64(v2[1], (int64x2_t)xmmword_211ED5560), (int32x4_t)vceqq_s64(v2[2], vdupq_n_s64(1uLL)))))) & 1) == 0)return 0; {
  }
    }
  else
  {
    if (v3) {
      return 0;
    }
    if ((vmaxv_u16((uint16x4_t)vmovn_s32((int32x4_t)vmvnq_s8((int8x16_t)vuzp1q_s32((int32x4_t)vceqq_s64(v2[1], (int64x2_t)xmmword_211EF1030), (int32x4_t)vceqq_s64(v2[2], vdupq_n_s64(1uLL)))))) & 1) == 0)
    {
      uint64_t v4 = *((void *)this + 19);
      if (v4 == v2->i64[1] && *((void *)this + 22) == v4 && *((void *)this + 25) == v4) {
        return 0;
      }
    }
  }
  ZinIrUnitStatus::SetError(a2, @"InvalidMatrixDecompositionInputDims");
  return 3;
}

uint64_t ZinIrMatrixDecompositionUnit::Validate(ZinIrUnit *this, uint64_t a2, int a3, int a4, CFArrayRef *a5)
{
  if (*(unsigned char *)(*(void *)(a2 + 8) + 492)
    && (*(unsigned int (**)(ZinIrUnit *, CFArrayRef *))(*(void *)this + 144))(this, a5))
  {
    ZinIrUnit::GetUnitTypeString(this, v10);
    if (v11 >= 0) {
      uint64_t v9 = (const char *)v10;
    }
    else {
      uint64_t v9 = (const char *)v10[0];
    }
    ZinAssertImpl("Unit %s is not supported for dynamic shapes", v9);
  }
  uint64_t result = ZinIrUnit::ValidateBottomCount(this, 1, a5);
  if (!result)
  {
    uint64_t result = ZinIrUnit::ValidateFormats(this, a5);
    if (!result)
    {
      return ZinIrMatrixDecompositionUnit::HWLimits(this, (const ZinIrHalParameters **)a2, a5);
    }
  }
  return result;
}

void sub_2113AD690(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11, int a12, __int16 a13, char a14, char a15)
{
  if (a15 < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinIrMatrixDecompositionUnit::HWLimits(ZinIrMatrixDecompositionUnit *a1, const ZinIrHalParameters **a2, CFArrayRef *a3)
{
  if (ValidateBasicTensorConstraints((const ZinTensorDimensions *)(*((void *)a1 + 1) + 8), *a2, a3)) {
    return 3;
  }

  return ZinIrMatrixDecompositionUnit::ValidateBottomDimensions(a1, a3);
}

void ZinIrMatrixDecompositionUnit::CreateOpcode(ZinIrMatrixDecompositionUnit *this)
{
}

void sub_2113AD764(_Unwind_Exception *a1)
{
  MEMORY[0x21667D3C0](v1, 0x10B3C402F70AE97);
  _Unwind_Resume(a1);
}

void ZinIrMatrixDecompositionUnit::CreateLayer(ZinIrMatrixDecompositionUnit *a1)
{
}

void sub_2113AD880(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, std::__shared_weak_count *a10, uint64_t a11, uint64_t a12)
{
  if (a10) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a10);
  }
  MEMORY[0x21667D3C0](v12, 0x10B3C4024B96488);
  if (a12) {
    (*(void (**)(uint64_t))(*(void *)a12 + 8))(a12);
  }
  _Unwind_Resume(a1);
}

void ZinIrMatrixDecompositionUnit::~ZinIrMatrixDecompositionUnit(ZinIrMatrixDecompositionUnit *this)
{
  ZinIrMatrixDecompositionUnit::~ZinIrMatrixDecompositionUnit(this);

  JUMPOUT(0x21667D3C0);
}

{
  void **v2;
  void *v3;
  void *v4;
  void *v5;
  uint64_t vars8;

  *(void *)this = &unk_26C352648;
  uint64_t v2 = (void **)((char *)this + 56);
  *((void *)this + 7) = &unk_26C353A40;
  int v3 = (void *)*((void *)this + 24);
  if (v3) {
    operator delete(v3);
  }
  uint64_t v4 = (void *)*((void *)this + 21);
  if (v4) {
    operator delete(v4);
  }
  uint64_t v5 = (void *)*((void *)this + 18);
  if (v5) {
    operator delete(v5);
  }
  ZinIrUnitInfo::~ZinIrUnitInfo(v2);

  ZinIrUnit::~ZinIrUnit(this);
}

__n128 ToTensorDimensions@<Q0>(uint64_t a1@<X0>, uint64_t a2@<X8>)
{
  __n128 result = *(__n128 *)a1;
  long long v3 = *(_OWORD *)(a1 + 16);
  *(_OWORD *)a2 = *(_OWORD *)a1;
  *(_OWORD *)(a2 + 16) = v3;
  *(void *)(a2 + 32) = *(void *)(a1 + 32);
  return result;
}

void FindDimension(const ZinTensorDimensions *a1@<X0>, uint64_t a2@<X1>, std::vector<int> *a3@<X8>)
{
  a3->__begin_ = 0;
  a3->__end_ = 0;
  a3->__end_cap_.__value_ = 0;
  std::vector<unsigned int>::reserve(a3, 5uLL);
  for (uint64_t i = 0; i != 5; ++i)
  {
    int v7 = dword_211F08A50[i];
    if (GetValueAtDimension<ZinTensorDimensions>((uint64_t *)a1, v7) == a2)
    {
      std::vector<int>::pointer end = a3->__end_;
      value = a3->__end_cap_.__value_;
      if (end >= value)
      {
        std::vector<int>::pointer begin = a3->__begin_;
        uint64_t v12 = end - a3->__begin_;
        unint64_t v13 = v12 + 1;
        if ((unint64_t)(v12 + 1) >> 62) {
          std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
        }
        uint64_t v14 = (char *)value - (char *)begin;
        if (v14 >> 1 > v13) {
          unint64_t v13 = v14 >> 1;
        }
        if ((unint64_t)v14 >= 0x7FFFFFFFFFFFFFFCLL) {
          unint64_t v15 = 0x3FFFFFFFFFFFFFFFLL;
        }
        else {
          unint64_t v15 = v13;
        }
        if (v15)
        {
          long long v16 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ZinIrPaddingMode>>((uint64_t)&a3->__end_cap_, v15);
          std::vector<int>::pointer begin = a3->__begin_;
          std::vector<int>::pointer end = a3->__end_;
        }
        else
        {
          long long v16 = 0;
        }
        uint64_t v17 = (int *)&v16[4 * v12];
        int *v17 = v7;
        uint64_t v10 = v17 + 1;
        while (end != begin)
        {
          int v18 = *--end;
          *--uint64_t v17 = v18;
        }
        a3->__begin_ = v17;
        a3->__end_ = v10;
        a3->__end_cap_.__value_ = (int *)&v16[4 * v15];
        if (begin) {
          operator delete(begin);
        }
      }
      else
      {
        *std::vector<int>::pointer end = v7;
        uint64_t v10 = end + 1;
      }
      a3->__end_ = v10;
    }
  }
}

void sub_2113ADB14(_Unwind_Exception *exception_object)
{
  long long v3 = *(void **)v1;
  if (*(void *)v1)
  {
    *(void *)(v1 + 8) = v3;
    operator delete(v3);
  }
  _Unwind_Resume(exception_object);
}

BOOL HasInterleaveMismatch(uint64_t a1, char a2, uint64_t a3, char a4)
{
  if (!a2) {
    return 0;
  }
  if (a4) {
    return a1 != a3;
  }
  return 0;
}

BOOL IsVector(const ZinTensorDimensions *a1)
{
  uint64_t v2 = *((void *)a1 + 3);
  uint64_t v1 = *((void *)a1 + 4);
  uint64_t v3 = *(void *)a1;
  uint64_t v4 = *((void *)a1 + 1);
  uint64_t v5 = *((void *)a1 + 2);
  uint64_t v6 = operator new(0x28uLL);
  uint64_t v7 = 0;
  unsigned int v8 = 0;
  *uint64_t v6 = v3;
  v6[1] = v1;
  v6[2] = v4;
  v6[3] = v5;
  void v6[4] = v2;
  do
  {
    if ((uint64_t)v6[v7] > 1) {
      ++v8;
    }
    ++v7;
  }
  while (v7 != 5);
  BOOL v9 = v8 < 2;
  operator delete(v6);
  return v9;
}

uint64_t IsSingularValue(const ZinTensorDimensions *a1)
{
  int64x2_t v2 = vdupq_n_s64(1uLL);
  v1.i64[1] = *((void *)a1 + 4);
  v1.i64[0] = *(void *)a1;
  *(int16x4_t *)v1.i8 = vmovn_s32((int32x4_t)vmvnq_s8((int8x16_t)vuzp1q_s32((int32x4_t)vceqq_s64(v1, v2), (int32x4_t)vceqq_s64(*(int64x2_t *)((char *)a1 + 8), v2))));
  v1.i16[0] = vmaxv_u16(*(uint16x4_t *)v1.i8);
  return (*((void *)a1 + 3) == 1) & ~v1.i32[0];
}

uint64_t GetMacroblockSize(int a1)
{
  if (a1 == 1) {
    return 32;
  }
  else {
    return 16 * (a1 == 2);
  }
}

uint64_t GetHWDMAFormatMode(int a1, int *a2)
{
  switch(a1)
  {
    case 0:
    case 8:
    case 14:
    case 15:
    case 16:
      BOOL v4 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v4) {
        GetHWDMAFormatMode(v4, v5, v6, v7, v8, v9, v10, v11);
      }
      uint64_t result = 3;
      break;
    case 1:
    case 2:
    case 12:
    case 13:
      uint64_t result = 0;
      *a2 = 0;
      break;
    case 3:
    case 4:
    case 5:
    case 6:
    case 7:
    case 9:
    case 10:
      uint64_t result = 0;
      int v3 = 2;
      goto LABEL_3;
    case 11:
      uint64_t result = 0;
      int v3 = 3;
LABEL_3:
      *a2 = v3;
      break;
    default:
      uint64_t result = 0;
      break;
  }
  return result;
}

uint64_t GetHWDMAMemoryFormat(int a1, int *a2)
{
  switch(a1)
  {
    case 0:
    case 8:
    case 14:
    case 15:
    case 16:
      BOOL v3 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v3) {
        GetHWDMAMemoryFormat(v3, v4, v5, v6, v7, v8, v9, v10);
      }
      return 3;
    case 1:
    case 9:
      uint64_t result = 0;
      int v11 = 1;
      goto LABEL_11;
    case 2:
    case 4:
    case 5:
    case 6:
    case 7:
    case 10:
      uint64_t result = 0;
      *a2 = 0;
      return result;
    case 3:
    case 13:
      uint64_t result = 0;
      int v11 = 2;
      goto LABEL_11;
    case 11:
      uint64_t result = 0;
      int v11 = 3;
      goto LABEL_11;
    case 12:
      uint64_t result = 0;
      int v11 = 4;
LABEL_11:
      *a2 = v11;
      break;
    default:
      uint64_t result = 0;
      break;
  }
  return result;
}

uint64_t GetHWDMAFormatBytes(int *a1, uint64_t a2)
{
  int v2 = *a1;
  uint64_t v3 = 2 * a2;
  uint64_t v4 = 4;
  if (*a1 != 1) {
    uint64_t v4 = a2;
  }
  if (v2 != 2) {
    uint64_t v3 = v4;
  }
  if (v2 == 3) {
    return 4 * a2;
  }
  else {
    return v3;
  }
}

uint64_t GetHWChannelFormat(int a1, int *a2)
{
  switch(a1)
  {
    case 0:
    case 14:
    case 15:
    case 16:
      BOOL v4 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v4) {
        GetHWChannelFormat(v4, v5, v6, v7, v8, v9, v10, v11);
      }
      return 3;
    case 1:
      uint64_t result = 0;
      int v3 = 1;
      goto LABEL_3;
    case 2:
      uint64_t result = 0;
      *a2 = 0;
      return result;
    case 3:
    case 4:
    case 5:
    case 6:
    case 7:
    case 8:
    case 9:
    case 10:
    case 11:
    case 13:
      uint64_t result = 0;
      int v3 = 2;
      goto LABEL_3;
    case 12:
      uint64_t result = 0;
      int v3 = 4;
LABEL_3:
      *a2 = v3;
      break;
    default:
      uint64_t result = 0;
      break;
  }
  return result;
}

BOOL ZinTensorFormatSizeGreaterEqual(int a1, int a2)
{
  uint64_t v5 = 0;
  ZinTensorFormatGetSizeInBytes(a1, &v5);
  uint64_t v3 = v5;
  uint64_t v5 = 0;
  ZinTensorFormatGetSizeInBytes(a2, &v5);
  return v3 >= v5;
}

void GetHWDMAFormatMode(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void GetHWDMAMemoryFormat(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void GetHWChannelFormat(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

void ZinOperation::ZinOperation(ZinOperation *this, const ZinIrHalParameters *a2)
{
  *(void *)this = &unk_26C320208;
  *((void *)this + 1) = a2;
}

uint64_t ZinIrAffineTransformUnit::ZinIrAffineTransformUnit(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v5 = ZinIrUnit::ZinIrUnit((void *)a1, a3);
  *uint64_t v5 = &unk_26C350CA0;
  ZinIrTextureUnitInfo::ZinIrTextureUnitInfo((ZinIrTextureUnitInfo *)(v5 + 7), (const ZinIrTextureUnitInfo *)a2);
  *(void *)(a1 + 56) = &unk_26C3525E0;
  long long v6 = *(_OWORD *)(a2 + 160);
  uint64_t v7 = *(void *)(a2 + 192);
  *(_OWORD *)(a1 + 232) = *(_OWORD *)(a2 + 176);
  *(_OWORD *)(a1 + 216) = v6;
  *(void *)(a1 + 248) = v7;
  *(void *)(a1 + 256) = 0;
  *(void *)(a1 + 264) = 0;
  *(void *)(a1 + 272) = 0;
  std::vector<ANEDebugInfo::DebugInfoInMem::Layer>::__init_with_size[abi:ne180100]<ANEDebugInfo::DebugInfoInMem::Layer*,ANEDebugInfo::DebugInfoInMem::Layer*>((void *)(a1 + 256), *(const void **)(a2 + 200), *(void *)(a2 + 208), 0xAAAAAAAAAAAAAAABLL * ((uint64_t)(*(void *)(a2 + 208) - *(void *)(a2 + 200)) >> 2));
  return a1;
}

void sub_2113AE0F8(_Unwind_Exception *a1)
{
  ZinIrTextureUnitInfo::~ZinIrTextureUnitInfo(v2);
  ZinIrUnit::~ZinIrUnit(v1);
  _Unwind_Resume(a1);
}

uint64_t ZinIrAffineTransformUnit::TensorDimensions(ZinIrAffineTransformUnit *this, const ZinIrHalParameters *a2, int8x16_t *a3, ZinIrUnitStatus *a4)
{
  BOOL v4 = (void *)*((void *)this + 1);
  a3->i64[1] = v4[2];
  a3[2].i64[0] = v4[5];
  uint64_t v5 = v4[1];
  uint64_t v6 = v4[16];
  if (v5 > v6) {
    uint64_t v6 = v5;
  }
  a3->i64[0] = v6;
  a3[1] = vextq_s8(*(int8x16_t *)((char *)this + 216), *(int8x16_t *)((char *)this + 216), 8uLL);
  return 0;
}

void ZinIrAffineTransformUnit::CreateOpcode(ZinIrAffineTransformUnit *this)
{
}

void sub_2113AE1B4(_Unwind_Exception *a1)
{
  MEMORY[0x21667D3C0](v1, 0x10B3C40B2E4BD66);
  _Unwind_Resume(a1);
}

void ZinIrAffineTransformUnit::CreateLayer(ZinIrAffineTransformUnit *a1)
{
}

void sub_2113AE30C(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, std::__shared_weak_count *a10, uint64_t a11, uint64_t a12)
{
  if (a10) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a10);
  }
  MEMORY[0x21667D3C0](v12, 0x10B3C4024B96488);
  if (a12) {
    (*(void (**)(uint64_t))(*(void *)a12 + 8))(a12);
  }
  _Unwind_Resume(a1);
}

void ZinMirChannelSplit::ComputeChannelDistributionVector(ZinMirChannelSplit *this@<X0>, uint64_t a2@<X1>, uint64_t **a3@<X8>)
{
  *a3 = 0;
  a3[1] = 0;
  a3[2] = 0;
  uint64_t v5 = (void *)*((void *)this + 11);
  uint64_t v6 = (void *)*((void *)this + 12);
  uint64_t v7 = v5 + 1;
  if (v5 != v6 && v7 != v6)
  {
    do
    {
      uint64_t v9 = *v7;
      uint64_t v10 = *(void *)((*(uint64_t (**)(void, void, void))(*(void *)*v5 + 32))(*v5, 0, 0) + 56);
      if (v10 < *(void *)((*(uint64_t (**)(uint64_t, void, void))(*(void *)v9 + 32))(v9, 0, 0)
                           + 56))
        uint64_t v5 = v7;
      ++v7;
    }
    while (v7 != v6);
  }
  uint64_t v11 = *(void *)((*(uint64_t (**)(void, void, void))(*(void *)*v5 + 32))(*v5, 0, 0) + 56);
  unsigned int v12 = vcvtps_u32_f32((float)v11 / (float)(unint64_t)a2);
  if (v12)
  {
    unint64_t v13 = 0;
    int v14 = 0;
    unint64_t v15 = a3 + 2;
    do
    {
      uint64_t v16 = v11;
      BOOL v17 = v11 < a2;
      v11 -= a2;
      if (v17) {
        uint64_t v18 = v16;
      }
      else {
        uint64_t v18 = a2;
      }
      if ((unint64_t)v13 >= *v15)
      {
        uint64_t v20 = *a3;
        uint64_t v21 = v13 - *a3;
        unint64_t v22 = v21 + 1;
        if ((unint64_t)(v21 + 1) >> 61) {
          std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
        }
        uint64_t v23 = *v15 - (void)v20;
        if (v23 >> 2 > v22) {
          unint64_t v22 = v23 >> 2;
        }
        if ((unint64_t)v23 >= 0x7FFFFFFFFFFFFFF8) {
          unint64_t v24 = 0x1FFFFFFFFFFFFFFFLL;
        }
        else {
          unint64_t v24 = v22;
        }
        if (v24)
        {
          uint64_t v25 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)(a3 + 2), v24);
          uint64_t v20 = *a3;
          unint64_t v13 = a3[1];
        }
        else
        {
          uint64_t v25 = 0;
        }
        long long v26 = (uint64_t *)&v25[8 * v21];
        *long long v26 = v18;
        uint64_t v19 = v26 + 1;
        while (v13 != v20)
        {
          uint64_t v27 = *--v13;
          *--long long v26 = v27;
        }
        *a3 = v26;
        a3[1] = v19;
        a3[2] = (uint64_t *)&v25[8 * v24];
        if (v20) {
          operator delete(v20);
        }
      }
      else
      {
        *unint64_t v13 = v18;
        uint64_t v19 = v13 + 1;
      }
      a3[1] = v19;
      ++v14;
      unint64_t v13 = v19;
    }
    while (v14 != v12);
  }
}

void sub_2113AE5B4(_Unwind_Exception *exception_object)
{
  uint64_t v3 = *(void **)v1;
  if (*(void *)v1)
  {
    *(void *)(v1 + 8) = v3;
    operator delete(v3);
  }
  _Unwind_Resume(exception_object);
}

BOOL ZinMirChannelSplit::IsValidInputChannelSplit(ZinMirChannelSplit *this, unint64_t a2)
{
  if (*(_DWORD *)(*((void *)this + 8) + 8) != 85 || !*((void *)this + 54))
  {
    unsigned int v12 = (void *)*((void *)this + 11);
    unint64_t v13 = (void *)*((void *)this + 12);
    while (1)
    {
      if (v12 == v13)
      {
        int v19 = (*(uint64_t (**)(ZinMirChannelSplit *))(*(void *)this + 408))(this);
        Hal = ZinIrTarget::GetHal(*((uint64_t **)this + 2), *(ZinIrTarget **)(*((void *)this + 2) + 160));
        uint64_t v21 = (*(uint64_t (**)(uint64_t *))(*Hal + 16))(Hal);
        uint64_t v37 = 0;
        uint64_t v22 = (*(uint64_t (**)(ZinMirChannelSplit *, void, void))(*(void *)this + 32))(this, 0, 0);
        if (ZinTensorFormatGetSizeInBytes(*(_DWORD *)(v22 + 88), &v37)) {
          ZinAssertImpl("Error in getting tensor format size in bytes");
        }
        if (!v19 || !(v37 * a2 % *(void *)(v21 + 528))) {
          return 1;
        }
        BOOL result = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
        if (!result) {
          return result;
        }
        ZinMirChannelSplit::IsValidInputChannelSplit(result, v23, v24, v25, v26, v27, v28, v29);
        return 0;
      }
      int v14 = (ZinIrTensor *)(*(uint64_t (**)(void, void, void))(*(void *)*v12 + 32))(*v12, 0, 0);
      uint64_t RootTensor = ZinIrTensor::GetRootTensor(v14);
      uint64_t Interleave = ZinIrTensor::GetInterleave(RootTensor);
      unint64_t v18 = v17 ? Interleave : 1;
      if (a2 % v18) {
        break;
      }
      ++v12;
    }
    BOOL result = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (!result) {
      return result;
    }
    ZinMirChannelSplit::IsValidInputChannelSplit(result, v30, v31, v32, v33, v34, v35, v36);
    return 0;
  }
  BOOL result = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
  if (result)
  {
    ZinMirChannelSplit::IsValidInputChannelSplit(result, v5, v6, v7, v8, v9, v10, v11);
    return 0;
  }
  return result;
}

uint64_t ZinMirChannelSplit::ComputeOutDims_Default@<X0>(ZinMirChannelSplit *this@<X0>, const ZinTensorDimensions *a2@<X1>, uint64_t a3@<X2>, uint64_t a4@<X8>)
{
  long long v7 = *((_OWORD *)this + 1);
  *(_OWORD *)a4 = *(_OWORD *)this;
  *(_OWORD *)(a4 + 16) = v7;
  *(void *)(a4 + 32) = *((void *)this + 4);
  uint64_t result = (*(uint64_t (**)(uint64_t))(*(void *)a3 + 408))(a3);
  uint64_t v9 = 8;
  if (result) {
    uint64_t v9 = 24;
  }
  *(void *)(a4 + v9) = a2;
  return result;
}

void ZinMirChannelSplit::SplitPEElementWiseLayerWithPreOps(ZinMirChannelSplit *this, ZinIrOpLayerGraph *a2, ZinPEElementWiseLayer *a3, uint64_t a4, uint64_t a5, ZinObjectNameFactory *a6)
{
  v10[4] = *MEMORY[0x263EF8340];
  ZinMirChannelSplit::PrepareInputViews(a2, a3, a4, a5, &v9);
  v10[0] = &unk_26C32CF70;
  v10[1] = ZinMirChannelSplit::ComputeOutDims_Default;
  void v10[3] = v10;
  ZinMirChannelSplit::CreateOutputTensor((uint64_t)a2, (uint64_t)a3, a5, (uint64_t)v10);
}

void sub_2113AEA5C(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, void *a15, uint64_t a16, uint64_t a17, uint64_t a18, std::__shared_weak_count *a19, void *a20,uint64_t a21,uint64_t a22,void *a23,uint64_t a24,int a25,__int16 a26,char a27,char a28)
{
  if (__p) {
    operator delete(__p);
  }
  if (a15) {
    operator delete(a15);
  }
  if (a19) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a19);
  }
  if (a20) {
    operator delete(a20);
  }
  _Unwind_Resume(exception_object);
}

void *ZinMirChannelSplit::PrepareInputViews@<X0>(ZinIrOpLayerGraph *a1@<X1>, const ZinIrOpLayer *a2@<X2>, uint64_t a3@<X3>, uint64_t a4@<X4>, void *a5@<X8>)
{
  uint64_t v38 = *MEMORY[0x263EF8340];
  uint64_t v11 = (uint64_t *)((char *)a1 + 88);
  unsigned int v12 = (void *)((char *)a1 + 96);
  unint64_t v13 = (uint64_t)(*((void *)a1 + 12) - *((void *)a1 + 11)) >> 3;
  *(void *)&long long v35 = 0;
  uint64_t result = std::vector<ZinIrOpLayer *>::vector(a5, v13, &v35);
  uint64_t v15 = *v11;
  if (*v12 != *v11)
  {
    unint64_t v16 = 0;
    int64x2_t v21 = vdupq_n_s64(1uLL);
    while (1)
    {
      uint64_t v17 = (*(uint64_t (**)(void, void, void))(**(void **)(v15 + 8 * v16) + 32))(*(void *)(v15 + 8 * v16), 0, 0);
      long long v18 = *(_OWORD *)(v17 + 64);
      long long v35 = *(_OWORD *)(v17 + 48);
      long long v36 = v18;
      uint64_t v37 = *(void *)(v17 + 80);
      if (!ZinIrOpLayer::IsPELayer(a1)) {
        break;
      }
      uint64_t result = (void *)ZinANELayer::GetTextureIndexInput(a1);
      if (result != *(void **)(*((void *)a1 + 11) + 8 * v16)
        || *(_DWORD *)(*(void *)(*((void *)a1 + 25) + 64) + 8) != 54)
      {
        if (ZinPELayer::HasInputTranspose(a1, v16)) {
          int v19 = 4;
        }
        else {
          int v19 = 2;
        }
        goto LABEL_10;
      }
LABEL_12:
      *(void *)(*a5 + 8 * v16++) = result;
      uint64_t v15 = *((void *)a1 + 11);
      if (v16 >= (*((void *)a1 + 12) - v15) >> 3) {
        return result;
      }
    }
    int v19 = 2;
LABEL_10:
    if (GetValueAtDimension<ZinTensorDimensions>((uint64_t *)&v35, v19) != 1)
    {
      v33[0] = v35;
      v33[1] = v36;
      uint64_t v34 = v37;
      SetValueAtDimension<ZinTensorDimensions>(v33, v19, (uint64_t)a2);
      uint64_t v20 = *(void *)(*((void *)a1 + 11) + 8 * v16);
      uint64_t v32 = 0;
      long long v30 = 0u;
      long long v31 = 0u;
      SetValueAtDimension<ZinTensorPosition>(&v30, v19, a3);
      (*(void (**)(void **__return_ptr, uint64_t, void))(*(void *)a4 + 16))(&__p, a4, 0);
      (*(void (**)(uint64_t, void, void))(*(void *)v20 + 32))(v20, 0, 0);
      long long v24 = v30;
      long long v25 = v31;
      uint64_t v26 = v32;
      int64x2_t v27 = v21;
      int64x2_t v28 = v21;
      uint64_t v29 = 1;
      ZinBuilder::CreateView();
    }
    uint64_t result = *(void **)(*((void *)a1 + 11) + 8 * v16);
    goto LABEL_12;
  }
  return result;
}

void sub_2113AEE30(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, void *__p, uint64_t a17)
{
}

void ZinMirChannelSplit::CreateOutputTensor(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v8 = (*(uint64_t (**)(uint64_t, void, void))(*(void *)a1 + 32))(a1, 0, 0);
  std::function<ZinTensorDimensions ()(ZinTensorDimensions const&,long,ZinANELayer const*)>::operator()(a4, v8 + 48, a2, a1);
  (*(void (**)(uint64_t, void, void))(*(void *)a1 + 32))(a1, 0, 0);
  (*(void (**)(void **__return_ptr, uint64_t, void))(*(void *)a3 + 16))(&__p, a3, 0);
  ZinIrTensor::CreateTensor();
}

void sub_2113AF090(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, char a15, uint64_t a16, char a17, int a18, __int16 a19, char a20,char a21,uint64_t a22,uint64_t a23,uint64_t a24,std::__shared_weak_count *a25)
{
  if (a25) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a25);
  }
  _Unwind_Resume(exception_object);
}

void ZinMirChannelSplit::ConnectSplitNodeAndViewLayers(uint64_t **a1, void *a2, ZinIrOpLayer *a3, ZinIrOpLayer *a4)
{
  v21[1] = *MEMORY[0x263EF8340];
  v21[0] = a3;
  long long v18 = (ZinIrOpLayer ***)v21;
  uint64_t v19 = 1;
  Layer2TDMapper::SourceLayer::SourceLayer(&v14, &v18);
  char v8 = ZinIrOpLayerGraph::AddNode(a1, a4, &v14);
  int v14 = (ZinIrOpLayer **)&unk_26C359A08;
  if (__p)
  {
    unint64_t v16 = __p;
    operator delete(__p);
  }
  uint64_t v9 = *((void *)a3 + 11);
  if (*((void *)a3 + 12) != v9)
  {
    unint64_t v10 = 0;
    do
    {
      unint64_t IndexOfMatchedIncomingLayer = ZinIrOpLayerGraph::GetIndexOfMatchedIncomingLayer((ZinIrOpLayerGraph *)a1, a3, *(const ZinIrOpLayer **)(v9 + 8 * v10));
      if (v8) {
        char v8 = ZinIrOpLayerGraph::AddEdge((uint64_t)a1, *(void *)(*a2 + 8 * v10), (uint64_t)a4, 0xFFFFFFFFFFFFFFFFLL, IndexOfMatchedIncomingLayer, 0);
      }
      else {
        char v8 = 0;
      }
      ++v10;
      uint64_t v9 = *((void *)a3 + 11);
    }
    while (v10 < (*((void *)a3 + 12) - v9) >> 3);
  }
  ZinIrContext::GetParameters(*(ZinIrContext **)(*(void *)*a2 + 16), (uint64_t)&v14);
  uint64_t v19 = 0;
  uint64_t v20 = 0;
  long long v18 = &v14;
  unint64_t v13 = (void *)*a2;
  unsigned int v12 = (void *)a2[1];
  while (v13 != v12)
  {
    v8 &= (*(unsigned int (**)(void, uint64_t **, ZinIrOpLayer ****))(*(void *)*v13 + 168))(*v13, a1, &v18) == 0;
    ++v13;
  }
  if ((v8 & 1) == 0) {
    ZinAssertImpl("Failed to update graph");
  }
  if (v20) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v20);
  }
  if (v17 < 0) {
    operator delete(v16);
  }
}

void sub_2113AF2A4(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, void *__p, uint64_t a13, int a14, __int16 a15, char a16, char a17, uint64_t a18, uint64_t a19, uint64_t a20,std::__shared_weak_count *a21)
{
  if (a21) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a21);
  }
  if (a17 < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

void ZinMirChannelSplit::ZinSplitLayerByInputChannelByDistribution(ZinMirChannelSplit *a1, uint64_t a2, uint64_t **a3, uint64_t a4, uint64_t a5)
{
  uint64_t v6 = a2;
  v64[4] = *MEMORY[0x263EF8340];
  int v54 = (*(uint64_t (**)(uint64_t))(*(void *)a2 + 408))(a2);
  if (*(char *)(v6 + 47) >= 0) {
    size_t v7 = *(unsigned __int8 *)(v6 + 47);
  }
  else {
    size_t v7 = *(void *)(v6 + 32);
  }
  std::string::basic_string[abi:ne180100]((uint64_t)&v62, v7 + 1);
  if ((v62.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
    char v8 = &v62;
  }
  else {
    char v8 = (std::string *)v62.__r_.__value_.__r.__words[0];
  }
  if (v7)
  {
    if (*(char *)(v6 + 47) >= 0) {
      uint64_t v9 = (const void *)(v6 + 24);
    }
    else {
      uint64_t v9 = *(const void **)(v6 + 24);
    }
    memmove(v8, v9, v7);
  }
  *(_WORD *)((char *)&v8->__r_.__value_.__l.__data_ + v7) = 95;
  std::string::basic_string[abi:ne180100]<0>(&v59, "split_inpc");
  unint64_t v10 = std::string::append(&v59, "_xfm", 4uLL);
  long long v11 = *(_OWORD *)&v10->__r_.__value_.__l.__data_;
  int64x2_t v61 = (char *)v10->__r_.__value_.__r.__words[2];
  *(_OWORD *)int64x2_t v60 = v11;
  v10->__r_.__value_.__l.__size_ = 0;
  v10->__r_.__value_.__r.__words[2] = 0;
  v10->__r_.__value_.__r.__words[0] = 0;
  if (SHIBYTE(v61) >= 0) {
    unsigned int v12 = v60;
  }
  else {
    unsigned int v12 = (void **)v60[0];
  }
  if (SHIBYTE(v61) >= 0) {
    std::string::size_type v13 = HIBYTE(v61);
  }
  else {
    std::string::size_type v13 = (std::string::size_type)v60[1];
  }
  int v14 = std::string::append(&v62, (const std::string::value_type *)v12, v13);
  long long v15 = *(_OWORD *)&v14->__r_.__value_.__l.__data_;
  std::string::size_type v57 = v14->__r_.__value_.__r.__words[2];
  *(_OWORD *)std::string __p = v15;
  v14->__r_.__value_.__l.__size_ = 0;
  v14->__r_.__value_.__r.__words[2] = 0;
  v14->__r_.__value_.__r.__words[0] = 0;
  ZinObjectNameFactory::ZinObjectNameFactory(&v63, __p);
  if (SHIBYTE(v57) < 0) {
    operator delete(__p[0]);
  }
  if (SHIBYTE(v61) < 0) {
    operator delete(v60[0]);
  }
  if (SHIBYTE(v59.__r_.__value_.__r.__words[2]) < 0) {
    operator delete(v59.__r_.__value_.__l.__data_);
  }
  if (SHIBYTE(v62.__r_.__value_.__r.__words[2]) < 0) {
    operator delete(v62.__r_.__value_.__l.__data_);
  }
  memset(&v62, 0, sizeof(v62));
  v60[0] = 0;
  v60[1] = 0;
  int64x2_t v61 = 0;
  unint64_t v16 = *a3;
  char v17 = a3[1];
  uint64_t v52 = v6;
  if (*a3 != v17)
  {
    unint64_t v18 = 0;
    uint64_t v19 = 0;
    int64x2_t v51 = vdupq_n_s64(1uLL);
    do
    {
      uint64_t v20 = *v16;
      std::__function::__value_func<ZinTensorDimensions ()(ZinTensorDimensions const&,long,ZinANELayer const*)>::__value_func[abi:ne180100]((uint64_t)v64, a5);
      uint64_t SplitByInputChannel = ZinMirChannelSplit::CreateSplitByInputChannel(a1, (ZinIrOpLayerGraph *)v6, v20, v18, (uint64_t)&v63, (uint64_t)v64);
      std::__function::__value_func<ZinTensorDimensions ()(ZinTensorDimensions const&,long,ZinANELayer const*)>::~__value_func[abi:ne180100](v64);
      if (!SplitByInputChannel) {
        ZinAssertImpl("failed create split by input channel, graph is changed");
      }
      uint64_t v22 = *(uint64_t (**)(uint64_t, void, void))(*(void *)SplitByInputChannel + 32);
      if (v54)
      {
        uint64_t v23 = 0;
        long long v24 = (uint64_t *)(v22(SplitByInputChannel, 0, 0) + 72);
        uint64_t v25 = v19;
      }
      else
      {
        uint64_t v25 = 0;
        long long v24 = (uint64_t *)(v22(SplitByInputChannel, 0, 0) + 56);
        uint64_t v23 = v19;
      }
      uint64_t v26 = *v24;
      std::string::size_type size = v62.__r_.__value_.__l.__size_;
      if (v62.__r_.__value_.__l.__size_ >= v62.__r_.__value_.__r.__words[2])
      {
        uint64_t v29 = (void *)v62.__r_.__value_.__r.__words[0];
        unint64_t v30 = 0xCCCCCCCCCCCCCCCDLL * ((uint64_t)(v62.__r_.__value_.__l.__size_ - v62.__r_.__value_.__r.__words[0]) >> 4);
        unint64_t v31 = v30 + 1;
        if (v30 + 1 > 0x333333333333333) {
          std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
        }
        if (0x999999999999999ALL
           * ((uint64_t)(v62.__r_.__value_.__r.__words[2] - v62.__r_.__value_.__r.__words[0]) >> 4) > v31)
          unint64_t v31 = 0x999999999999999ALL
              * ((uint64_t)(v62.__r_.__value_.__r.__words[2] - v62.__r_.__value_.__r.__words[0]) >> 4);
        if (0xCCCCCCCCCCCCCCCDLL
           * ((uint64_t)(v62.__r_.__value_.__r.__words[2] - v62.__r_.__value_.__r.__words[0]) >> 4) >= 0x199999999999999)
          unint64_t v32 = 0x333333333333333;
        else {
          unint64_t v32 = v31;
        }
        if (v32)
        {
          uint64_t v33 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ZinIrCodegenTDPartitionStats>>((uint64_t)&v62.__r_.__value_.__r.__words[2], v32);
          std::string::size_type size = v62.__r_.__value_.__l.__size_;
          uint64_t v29 = (void *)v62.__r_.__value_.__r.__words[0];
        }
        else
        {
          uint64_t v33 = 0;
        }
        uint64_t v34 = (int64x2_t *)&v33[80 * v30];
        v34->i64[0] = 0;
        v34->i64[1] = v23;
        v34[1].i64[0] = 0;
        v34[1].i64[1] = v25;
        int64x2_t v35 = vdupq_n_s64(1uLL);
        v34[2] = (int64x2_t)xmmword_211ED5A80;
        v34[3] = v35;
        void v34[4] = v35;
        if ((void *)size == v29)
        {
          std::string::size_type v40 = (std::string::size_type)&v33[80 * v30];
          uint64_t v6 = v52;
        }
        else
        {
          long long v36 = &v33[80 * v30];
          uint64_t v6 = v52;
          do
          {
            *((_OWORD *)v36 - 5) = *(_OWORD *)(size - 80);
            long long v37 = *(_OWORD *)(size - 64);
            long long v38 = *(_OWORD *)(size - 48);
            long long v39 = *(_OWORD *)(size - 16);
            std::string::size_type v40 = (std::string::size_type)(v36 - 80);
            *((_OWORD *)v36 - 2) = *(_OWORD *)(size - 32);
            *((_OWORD *)v36 - 1) = v39;
            *((_OWORD *)v36 - 4) = v37;
            *((_OWORD *)v36 - 3) = v38;
            size -= 80;
            v36 -= 80;
          }
          while ((void *)size != v29);
        }
        std::string::size_type v28 = (std::string::size_type)&v34[5];
        v62.__r_.__value_.__r.__words[0] = v40;
        v62.__r_.__value_.__l.__size_ = (std::string::size_type)&v34[5];
        v62.__r_.__value_.__r.__words[2] = (std::string::size_type)&v33[80 * v32];
        if (v29) {
          operator delete(v29);
        }
      }
      else
      {
        *(void *)v62.__r_.__value_.__l.__size_ = 0;
        *(void *)(size + 8) = v23;
        *(void *)(size + 16) = 0;
        *(void *)(size + 24) = v25;
        *(_OWORD *)(size + 32) = xmmword_211ED5A80;
        *(int64x2_t *)(size + 48) = v51;
        std::string::size_type v28 = size + 80;
        *(int64x2_t *)(size + 64) = v51;
      }
      v62.__r_.__value_.__l.__size_ = v28;
      std::vector<char>::pointer v41 = (char *)v60[1];
      if (v60[1] >= v61)
      {
        int64_t v43 = ((char *)v60[1] - (char *)v60[0]) >> 3;
        if ((unint64_t)(v43 + 1) >> 61) {
          std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
        }
        unint64_t v44 = (v61 - (char *)v60[0]) >> 2;
        if (v44 <= v43 + 1) {
          unint64_t v44 = v43 + 1;
        }
        if ((unint64_t)(v61 - (char *)v60[0]) >= 0x7FFFFFFFFFFFFFF8) {
          unint64_t v45 = 0x1FFFFFFFFFFFFFFFLL;
        }
        else {
          unint64_t v45 = v44;
        }
        if (v45) {
          long long v46 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)&v61, v45);
        }
        else {
          long long v46 = 0;
        }
        std::vector<char> v47 = (uint64_t *)&v46[8 * v43];
        uint64_t *v47 = SplitByInputChannel;
        char v42 = v47 + 1;
        std::vector<char>::pointer v49 = (char *)v60[0];
        long long v48 = (char *)v60[1];
        if (v60[1] != v60[0])
        {
          do
          {
            uint64_t v50 = *((void *)v48 - 1);
            v48 -= 8;
            *--std::vector<char> v47 = v50;
          }
          while (v48 != v49);
          long long v48 = (char *)v60[0];
        }
        v60[0] = v47;
        v60[1] = v42;
        int64x2_t v61 = &v46[8 * v45];
        if (v48) {
          operator delete(v48);
        }
      }
      else
      {
        *(void *)v60[1] = SplitByInputChannel;
        char v42 = v41 + 8;
      }
      v19 += v26;
      v60[1] = v42;
      v18 += v20;
      ++v16;
    }
    while (v16 != v17);
  }
  uint64_t v58 = 0;
  ZinBuilder::CreateConcat();
}

void sub_2113AFA5C(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,void *__p,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,void *a30,uint64_t a31,int a32,__int16 a33,char a34,char a35,void *a36,uint64_t a37,int a38,__int16 a39,char a40,char a41)
{
  if (__p) {
    operator delete(__p);
  }
  if (a30) {
    operator delete(a30);
  }
  if (a36) {
    operator delete(a36);
  }
  int64_t v43 = *(void **)(v41 - 200);
  if (v43)
  {
    *(void *)(v41 - 192) = v43;
    operator delete(v43);
  }
  *(void *)(v41 - 176) = &unk_26C34DA98;
  if (*(char *)(v41 - 145) < 0) {
    operator delete(*(void **)(v41 - 168));
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinMirChannelSplit::CreateSplitByInputChannel(ZinMirChannelSplit *this, ZinIrOpLayerGraph *a2, uint64_t a3, unint64_t a4, uint64_t a5, uint64_t a6)
{
  v35[5] = *MEMORY[0x263EF8340];
  int v12 = *(_DWORD *)(*((void *)a2 + 8) + 8);
  if (v12 == 81)
  {
    if (((*(uint64_t (**)(ZinIrOpLayerGraph *))(*(void *)a2 + 656))(a2) & 1) != 0
      || ((*(uint64_t (**)(ZinIrOpLayerGraph *))(*(void *)a2 + 664))(a2) & 1) != 0
      || ((*(uint64_t (**)(ZinIrOpLayerGraph *))(*(void *)a2 + 640))(a2) & 1) != 0
      || ((*(uint64_t (**)(ZinIrOpLayerGraph *))(*(void *)a2 + 648))(a2) & 1) != 0)
    {
      ZinMirChannelSplit::SplitPEElementWiseLayerWithPreOps(this, a2, (ZinPEElementWiseLayer *)a3, a4, a5, v13);
    }
    int v12 = *(_DWORD *)(*((void *)a2 + 8) + 8);
  }
  if (v12 != 85)
  {
    if (v12 == 89)
    {
      std::__function::__value_func<ZinTensorDimensions ()(ZinTensorDimensions const&,long,ZinANELayer const*)>::__value_func[abi:ne180100]((uint64_t)v32, a6);
      uint64_t v28 = a4;
      uint64_t __val = a3;
      ZinMirChannelSplit::PrepareInputViews(a2, (const ZinIrOpLayer *)a3, a4, a5, &v27);
      std::__function::__value_func<ZinTensorDimensions ()(ZinTensorDimensions const&,long,ZinANELayer const*)>::__value_func[abi:ne180100]((uint64_t)v35, (uint64_t)v32);
      ZinMirChannelSplit::CreateOutputTensor((uint64_t)a2, a3, a5, (uint64_t)v35);
    }
    if (v12 == 90)
    {
      ZinMirChannelSplit::PrepareInputViews(a2, (const ZinIrOpLayer *)a3, a4, a5, &v26);
      uint64_t v14 = *(void *)((*(uint64_t (**)(void, void, void))(***((void ***)a2 + 11) + 32))(**((void **)a2 + 11), 0, 0)+ 56);
      uint64_t v15 = *(void *)((*(uint64_t (**)(ZinIrOpLayerGraph *, void, void))(*(void *)a2 + 32))(a2, 0, 0)+ 56);
      if (!(v14 % v15))
      {
        v33.__r_.__value_.__r.__words[0] = (std::string::size_type)&unk_26C32CF70;
        v33.__r_.__value_.__l.__size_ = (std::string::size_type)ZinMirChannelSplit::ComputeOutDims_Default;
        uint64_t v34 = &v33;
        ZinMirChannelSplit::CreateOutputTensor((uint64_t)a2, a3 / (unint64_t)(v14 / v15), a5, (uint64_t)&v33);
      }
      ZinAssertImpl("In ZinNEElementWiseLayer, input channel count must be a multiple of output channel count.");
    }
LABEL_17:
    ZinMirChannelSplit::PrepareInputViews(a2, (const ZinIrOpLayer *)a3, a4, a5, &v33);
    std::__function::__value_func<ZinTensorDimensions ()(ZinTensorDimensions const&,long,ZinANELayer const*)>::__value_func[abi:ne180100]((uint64_t)v30, a6);
    ZinMirChannelSplit::CreateOutputTensor((uint64_t)a2, a3, a5, (uint64_t)v30);
  }
  if (*((void *)a2 + 54)) {
    goto LABEL_17;
  }
  std::__function::__value_func<ZinTensorDimensions ()(ZinTensorDimensions const&,long,ZinANELayer const*)>::__value_func[abi:ne180100]((uint64_t)v31, a6);
  uint64_t v28 = a4;
  uint64_t __val = a3;
  if (*((void *)a2 + 54)) {
    ZinAssertImpl("SplitNEConvLayer: NEConv with kernel coefficients should be handled by the kernel splitter.");
  }
  if ((*(unsigned int (**)(ZinIrOpLayerGraph *))(*(void *)a2 + 408))(a2)
    && (Hal = ZinIrTarget::GetHal(*((uint64_t **)a2 + 2), *(ZinIrTarget **)(*((void *)a2 + 2) + 160)),
        a4 % *(void *)((*(uint64_t (**)(uint64_t *))(*Hal + 16))(Hal) + 528)))
  {
    BOOL v17 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
    if (v17) {
      ZinMirChannelSplit::CreateSplitByInputChannel(v17, v18, v19, v20, v21, v22, v23, v24);
    }
  }
  else if ((*(uint64_t (**)(ZinIrOpLayerGraph *))(*(void *)a2 + 88))(a2) == 1 && !*((void *)a2 + 51))
  {
    std::__function::__value_func<ZinTensorDimensions ()(ZinTensorDimensions const&,long,ZinANELayer const*)>::__value_func[abi:ne180100]((uint64_t)v35, (uint64_t)v31);
    ZinMirChannelSplit::CreateOutputTensor((uint64_t)a2, a3, a5, (uint64_t)v35);
  }
  std::__function::__value_func<ZinTensorDimensions ()(ZinTensorDimensions const&,long,ZinANELayer const*)>::~__value_func[abi:ne180100](v31);
  return 0;
}

void sub_2113B136C(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, void *a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, void *a17, void *a18, int a19, __int16 a20,char a21,char a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,void *a27,uint64_t a28,uint64_t a29,void *a30,uint64_t a31,uint64_t a32,void *a33,uint64_t a34,uint64_t a35,void *a36,uint64_t a37,uint64_t a38,uint64_t a39,void *a40,uint64_t a41,uint64_t a42,uint64_t a43,void *__p,uint64_t a45,uint64_t a46,uint64_t a47,uint64_t a48,std::__shared_weak_count *a49,uint64_t a50,uint64_t a51,uint64_t a52,uint64_t a53,uint64_t a54,uint64_t a55,uint64_t a56)
{
  if (__p) {
    operator delete(__p);
  }
  if (a22 < 0) {
    operator delete(a17);
  }
  if (a49) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a49);
  }
  std::__function::__value_func<ZinTensorDimensions ()(ZinTensorDimensions const&,long,ZinANELayer const*)>::~__value_func[abi:ne180100](&a56);
  _Unwind_Resume(a1);
}

uint64_t ZinMirChannelSplit::ZinSplitLayerByInputChannel(ZinMirChannelSplit *a1, ZinMirChannelSplit *this, ZinANELayer *a3, uint64_t a4, uint64_t a5)
{
  uint64_t v13 = *MEMORY[0x263EF8340];
  if (ZinMirChannelSplit::IsValidInputChannelSplit(this, (unint64_t)a3)
    && (*(_DWORD *)(*((void *)this + 8) + 8) != 85 || !*((void *)this + 54)))
  {
    ZinMirChannelSplit::ComputeChannelDistributionVector(this, (uint64_t)a3, (uint64_t **)&__p);
    std::__function::__value_func<ZinTensorDimensions ()(ZinTensorDimensions const&,long,ZinANELayer const*)>::__value_func[abi:ne180100]((uint64_t)v12, a5);
    ZinMirChannelSplit::ZinSplitLayerByInputChannelByDistribution(a1, (uint64_t)this, (uint64_t **)&__p, a4, (uint64_t)v12);
  }
  return 0;
}

void sub_2113B1AC8(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, void *__p, uint64_t a10, uint64_t a11, uint64_t a12)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(a1);
}

uint64_t ZinMirChannelSplit::SplitByOutputChannelWithTranspose(ZinMirChannelSplit *this, ZinIrOpLayerGraph *a2, uint64_t a3)
{
  v69[3] = *MEMORY[0x263EF8340];
  if (ZinIrOpLayer::IsPELayer(a2))
  {
    if ((*(uint64_t (**)(ZinIrOpLayerGraph *))(*(void *)a2 + 640))(a2)) {
      int v5 = 1;
    }
    else {
      int v5 = (*(uint64_t (**)(ZinIrOpLayerGraph *))(*(void *)a2 + 648))(a2);
    }
  }
  else
  {
    int v5 = 0;
  }
  if ((((*(uint64_t (**)(ZinIrOpLayerGraph *))(*(void *)a2 + 408))(a2) & 1) != 0 || v5)
    && ((*(unsigned int (**)(ZinIrOpLayerGraph *))(*(void *)a2 + 408))(a2) & v5 & 1) == 0)
  {
    if (*(_DWORD *)(*((void *)a2 + 8) + 8) == 85)
    {
      BOOL v7 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
      if (v7) {
        ZinMirChannelSplit::SplitByOutputChannelWithTranspose(v7, v8, v9, v10, v11, v12, v13, v14);
      }
    }
    else
    {
      uint64_t v15 = (ZinIrTensor *)(*(uint64_t (**)(ZinIrOpLayerGraph *, void, void))(*(void *)a2 + 32))(a2, 0, 0);
      uint64_t Interleave = ZinIrTensor::GetInterleave(v15);
      if (v17) {
        unint64_t v18 = Interleave;
      }
      else {
        unint64_t v18 = 1;
      }
      if (a3 % v18)
      {
        BOOL v19 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
        if (v19) {
          ZinMirChannelSplit::SplitByOutputChannelWithTranspose(v19, v20, v21, v22, v23, v24, v25, v26);
        }
      }
      else
      {
        Hal = ZinIrTarget::GetHal(*((uint64_t **)a2 + 2), *(ZinIrTarget **)(*((void *)a2 + 2) + 160));
        uint64_t v28 = (*(uint64_t (**)(uint64_t *))(*Hal + 16))(Hal);
        v67[0] = 0;
        uint64_t v29 = (*(uint64_t (**)(ZinIrOpLayerGraph *, void, void))(*(void *)a2 + 32))(a2, 0, 0);
        if (ZinTensorFormatGetSizeInBytes(*(_DWORD *)(v29 + 88), v67)) {
          ZinAssertImpl("Error in getting tensor format size in bytes");
        }
        if (!((unint64_t)(v67[0] * a3) % *(void *)(v28 + 528)))
        {
          std::operator+[abi:ne180100]<char,std::char_traits<char>,std::allocator<char>>("_SplitByCoutWithOutputTranspose", (const void **)a2 + 3, (void **)&__p);
          ZinObjectNameFactory::ZinObjectNameFactory(&v66, &__p);
          if (v58.i8[7] < 0) {
            operator delete((void *)__p.i64[0]);
          }
          uint64_t v63 = 0;
          uint64_t v64 = 0;
          uint64_t v65 = 0;
          int64x2_t v60 = 0;
          uint64_t v61 = 0;
          uint64_t v62 = 0;
          uint64_t v38 = *(void *)((*(uint64_t (**)(ZinIrOpLayerGraph *, void, void))(*(void *)a2 + 32))(a2, 0, 0)+ 56);
          if (v38 >= 1)
          {
            if (v38 < a3) {
              a3 = v38;
            }
            unint64_t v39 = (uint64_t)(*((void *)a2 + 12) - *((void *)a2 + 11)) >> 3;
            __p.i64[0] = 0;
            std::vector<ZinIrOpLayer *>::vector(v69, v39, &__p);
            int64x2_t __p = vdupq_n_s64(1uLL);
            int64x2_t v58 = __p;
            uint64_t v59 = 1;
            std::string::size_type v40 = (void *)*((void *)a2 + 11);
            if (*((void **)a2 + 12) != v40)
            {
              uint64_t v41 = (*(uint64_t (**)(void, void, void))(*(void *)*v40 + 32))(*v40, 0, 0);
              int64x2_t v42 = *(int64x2_t *)(v41 + 64);
              int64x2_t __p = *(int64x2_t *)(v41 + 48);
              int64x2_t v58 = v42;
              uint64_t v43 = *(void *)(v41 + 80);
              v58.i64[1] = a3;
              uint64_t v59 = v43;
              uint64_t v44 = **((void **)a2 + 11);
              ZinObjectNameFactory::CreateName((uint64_t)&v66, 0, (std::string *)v47);
              (*(void (**)(uint64_t, void, void))(*(void *)v44 + 32))(v44, 0, 0);
              uint64_t v50 = 0;
              uint64_t v51 = 0;
              uint64_t v52 = 0;
              uint64_t v53 = 0;
              long long v54 = xmmword_211ED5A80;
              int64x2_t v55 = vdupq_n_s64(1uLL);
              int64x2_t v56 = v55;
              ZinBuilder::CreateView();
            }
            uint64_t v45 = (*(uint64_t (**)(ZinIrOpLayerGraph *, void, void))(*(void *)a2 + 32))(a2, 0, 0);
            long long v46 = *(_OWORD *)(v45 + 64);
            *(_OWORD *)std::vector<char> v47 = *(_OWORD *)(v45 + 48);
            long long v48 = v46;
            uint64_t v49 = *(void *)(v45 + 80);
            v47[1] = (void *)a3;
            (*(void (**)(ZinIrOpLayerGraph *, void, void))(*(void *)a2 + 32))(a2, 0, 0);
            ZinObjectNameFactory::CreateName((uint64_t)&v66, 0, &v68);
            v67[1] = 0;
            v67[2] = 0;
            ZinIrTensor::CreateTensor();
          }
          __p.i32[0] = 0;
          std::make_unique[abi:ne180100]<ZinIrConcatInfo,ZinIrConcatMode,std::vector<ZinIrTensor::ViewOriginAndStep> &>();
        }
        BOOL v30 = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
        if (v30) {
          ZinMirChannelSplit::IsValidInputChannelSplit(v30, v31, v32, v33, v34, v35, v36, v37);
        }
      }
    }
  }
  return 0;
}

void sub_2113B2704(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,void *a25,std::__shared_weak_count *a26,int a27,__int16 a28,char a29,char a30,uint64_t a31,uint64_t a32,uint64_t a33,uint64_t a34,uint64_t a35,void *a36,uint64_t a37,int a38,__int16 a39,char a40,char a41,uint64_t a42,uint64_t a43,uint64_t a44,uint64_t a45,uint64_t a46,uint64_t a47,uint64_t a48,uint64_t a49,uint64_t a50,uint64_t a51,uint64_t a52,uint64_t a53,uint64_t a54,void *a55,void *__p,uint64_t a57,uint64_t a58,uint64_t a59,void *a60,uint64_t a61)
{
  if (__p) {
    operator delete(__p);
  }
  if (a26) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a26);
  }
  uint64_t v63 = *(void *)(v61 - 152);
  *(void *)(v61 - 152) = 0;
  if (v63) {
    (*(void (**)(uint64_t))(*(void *)v63 + 8))(v63);
  }
  if (a60) {
    operator delete(a60);
  }
  uint64_t v64 = *(void **)(v61 - 240);
  if (v64)
  {
    *(void *)(v61 - 232) = v64;
    operator delete(v64);
  }
  *(void *)(v61 - 216) = &unk_26C34DA98;
  if (*(char *)(v61 - 185) < 0) {
    operator delete(*(void **)(v61 - 208));
  }
  _Unwind_Resume(exception_object);
}

void std::make_unique[abi:ne180100]<ZinIrConcatInfo,ZinIrConcatMode,std::vector<ZinIrTensor::ViewOriginAndStep> &>()
{
}

void sub_2113B2A30(_Unwind_Exception *a1)
{
  MEMORY[0x21667D3C0](v1, 0x10A1C405897D53FLL);
  _Unwind_Resume(a1);
}

BOOL ZinMirChannelSplit::HasSufficientCinToSplit(ZinMirChannelSplit *this, const ZinIrOpLayer *a2)
{
  uint64_t v2 = *((void *)this + 11);
  uint64_t v3 = *((void *)this + 12);
  if (v2 == v3) {
    return 0;
  }
  uint64_t v5 = v2 + 8;
  do
  {
    unint64_t v6 = *(void *)((*(uint64_t (**)(void, void, void))(**(void **)(v5 - 8) + 32))(*(void *)(v5 - 8), 0, 0)+ 56);
    BOOL result = v6 >= (unint64_t)a2;
    BOOL v8 = v6 >= (unint64_t)a2 || v5 == v3;
    v5 += 8;
  }
  while (!v8);
  return result;
}

uint64_t std::function<ZinTensorDimensions ()(ZinTensorDimensions const&,long,ZinANELayer const*)>::operator()(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v6 = a4;
  uint64_t v7 = a3;
  uint64_t v4 = *(void *)(a1 + 24);
  if (!v4) {
    std::__throw_bad_function_call[abi:ne180100]();
  }
  return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t *, uint64_t *))(*(void *)v4 + 48))(v4, a2, &v7, &v6);
}

void ***std::back_insert_iterator<std::vector<ZinTensorDimensions>>::operator=[abi:ne180100](void ***a1, long long *a2)
{
  uint64_t v4 = *a1;
  uint64_t v5 = (char *)(*a1)[1];
  uint64_t v6 = *a1;
  uint64_t v9 = (char *)v6[2];
  uint64_t v7 = (uint64_t)(v6 + 2);
  BOOL v8 = v9;
  if (v5 >= v9)
  {
    unint64_t v13 = 0xCCCCCCCCCCCCCCCDLL * ((v5 - (unsigned char *)*v4) >> 3);
    unint64_t v14 = v13 + 1;
    if (v13 + 1 > 0x666666666666666) {
      std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
    }
    unint64_t v15 = 0xCCCCCCCCCCCCCCCDLL * ((v8 - (unsigned char *)*v4) >> 3);
    if (2 * v15 > v14) {
      unint64_t v14 = 2 * v15;
    }
    if (v15 >= 0x333333333333333) {
      unint64_t v16 = 0x666666666666666;
    }
    else {
      unint64_t v16 = v14;
    }
    if (v16) {
      char v17 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ZinMirInterchangeInfo>>(v7, v16);
    }
    else {
      char v17 = 0;
    }
    unint64_t v18 = &v17[40 * v13];
    BOOL v19 = &v17[40 * v16];
    long long v20 = *a2;
    long long v21 = a2[1];
    *((void *)v18 + 4) = *((void *)a2 + 4);
    *(_OWORD *)unint64_t v18 = v20;
    *((_OWORD *)v18 + 1) = v21;
    uint64_t v12 = v18 + 40;
    uint64_t v23 = (char *)*v4;
    uint64_t v22 = (char *)v4[1];
    if (v22 != *v4)
    {
      do
      {
        long long v24 = *(_OWORD *)(v22 - 40);
        long long v25 = *(_OWORD *)(v22 - 24);
        *((void *)v18 - 1) = *((void *)v22 - 1);
        *(_OWORD *)(v18 - 24) = v25;
        *(_OWORD *)(v18 - 4std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v24;
        v18 -= 40;
        v22 -= 40;
      }
      while (v22 != v23);
      uint64_t v22 = (char *)*v4;
    }
    *uint64_t v4 = v18;
    v4[1] = v12;
    v4[2] = v19;
    if (v22) {
      operator delete(v22);
    }
  }
  else
  {
    long long v10 = *a2;
    long long v11 = a2[1];
    *((void *)v5 + 4) = *((void *)a2 + 4);
    *(_OWORD *)uint64_t v5 = v10;
    *((_OWORD *)v5 + 1) = v11;
    uint64_t v12 = v5 + 40;
  }
  v4[1] = v12;
  return a1;
}

ZinIrKernel **ZinMirChannelSplit::SplitGOCWithPerCoutScaleBias(ZinIrKernel **a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v26 = a4;
  uint64_t v27 = a3;
  if (a1)
  {
    uint64_t v5 = a1[17];
    if (!v5) {
      ZinAssertImpl("Error: GOC layer should contain a kernel");
    }
    if (ZinIrKernel::HasPerCoutScale(v5) || ZinIrKernel::HasPerCoutBias(a1[17]))
    {
      uint64_t v7 = ZinObjectNameFactory::ZinObjectNameFactory(&v25, a2);
      ZinObjectNameFactory::CreateName(v7, 2u, &v24);
      v11[0] = 0;
      std::allocate_shared[abi:ne180100]<ZinIrTransformPartial,std::allocator<ZinIrTransformPartial>,unsigned long &,unsigned long &,ZinPartialTransformDimension,void>(&v27, &v26, v11, &v23);
      uint64_t v8 = (*((uint64_t (**)(ZinIrKernel **, void, void))*a1 + 4))(a1, 0, 0);
      long long v9 = *(_OWORD *)(v8 + 64);
      long long v20 = *(_OWORD *)(v8 + 48);
      long long v21 = v9;
      uint64_t v22 = *(void *)(v8 + 80);
      *((void *)&v20 + 1) = v27;
      ZinObjectNameFactory::CreateName((uint64_t)&v25, 0, &__p);
      uint64_t v17 = 0;
      uint64_t v18 = 0;
      uint64_t v16 = 0;
      *(_DWORD *)long long v11 = 0;
      uint64_t v13 = 0;
      uint64_t v14 = 0;
      uint64_t v12 = 0;
      int v15 = 0;
      ZinIrTensor::CreateTensor();
    }
  }
  return a1;
}

void sub_2113B2E68(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, std::__shared_weak_count *a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,std::__shared_weak_count *a21,void *__p,uint64_t a23,int a24,__int16 a25,char a26,char a27)
{
  if (a11) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a11);
  }
  if (a21) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a21);
  }
  if (a27 < 0) {
    operator delete(__p);
  }
  uint64_t v29 = *(std::__shared_weak_count **)(v27 - 120);
  if (v29) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v29);
  }
  if (*(char *)(v27 - 89) < 0) {
    operator delete(*(void **)(v27 - 112));
  }
  *(void *)(v27 - 88) = &unk_26C34DA98;
  if (*(char *)(v27 - 57) < 0) {
    operator delete(*(void **)(v27 - 80));
  }
  _Unwind_Resume(exception_object);
}

void *std::allocate_shared[abi:ne180100]<ZinIrTransformPartial,std::allocator<ZinIrTransformPartial>,unsigned long &,unsigned long &,ZinPartialTransformDimension,void>@<X0>(uint64_t *a1@<X1>, uint64_t *a2@<X2>, char *a3@<X3>, void *a4@<X8>)
{
  uint64_t v8 = operator new(0x40uLL);
  BOOL result = std::__shared_ptr_emplace<ZinIrTransformPartial>::__shared_ptr_emplace[abi:ne180100]<unsigned long const&,unsigned long &,ZinPartialTransformDimension,std::allocator<ZinIrTransformPartial>,0>(v8, a1, a2, a3);
  *a4 = v8 + 3;
  a4[1] = v8;
  return result;
}

void sub_2113B2F8C(_Unwind_Exception *a1)
{
  operator delete(v1);
  _Unwind_Resume(a1);
}

uint64_t std::__function::__value_func<ZinTensorDimensions ()(ZinTensorDimensions const&,long,ZinANELayer const*)>::__value_func[abi:ne180100](uint64_t a1, uint64_t a2)
{
  uint64_t v3 = *(void *)(a2 + 24);
  if (v3)
  {
    if (v3 == a2)
    {
      *(void *)(a1 + 24) = a1;
      (*(void (**)(void, uint64_t))(**(void **)(a2 + 24) + 24))(*(void *)(a2 + 24), a1);
    }
    else
    {
      *(void *)(a1 + 24) = (*(uint64_t (**)(uint64_t))(*(void *)v3 + 16))(v3);
    }
  }
  else
  {
    *(void *)(a1 + 24) = 0;
  }
  return a1;
}

void ZinMirChannelSplit::IsValidInputChannelSplit(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "the split channel number should be divisible by interleave factor", a5, a6, a7, a8, 0);
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "Should not split a logical conv layer by input channel", a5, a6, a7, a8, 0);
}

void ZinMirChannelSplit::CreateSplitByInputChannel(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "SplitNEConvLayer: unable to split non-logical conv because of output cw transpose alignment.", a5, a6, a7, a8, 0);
}

void ZinMirChannelSplit::SplitByOutputChannelWithTranspose(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
}

{
  OUTLINED_FUNCTION_0(&dword_210C72000, &_os_log_internal, a3, "output channel should be a multiple of interleave factor.", a5, a6, a7, a8, 0);
}

uint64_t ZinMirUnit::ZinMirUnit(uint64_t a1, int a2, long long *a3)
{
  char v5 = 0;
  uint64_t v6 = 0;
  *(void *)a1 = &unk_26C342E50;
  long long v7 = *a3;
  *(void *)(a1 + 24) = *((void *)a3 + 2);
  *(_OWORD *)(a1 + 8) = v7;
  *((void *)a3 + 1) = 0;
  *((void *)a3 + 2) = 0;
  *(void *)a3 = 0;
  *(_DWORD *)(a1 + 32) = a2;
  *(void *)(a1 + 4std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  *(void *)(a1 + 48) = 0;
  *(void *)(a1 + 56) = 0;
  *(_OWORD *)(a1 + 4std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = *(long long *)((char *)a3 + 24);
  *(void *)(a1 + 56) = *((void *)a3 + 5);
  *((void *)a3 + 3) = 0;
  *((void *)a3 + 4) = 0;
  *((void *)a3 + 5) = 0;
  *(_DWORD *)(a1 + 64) = *((_DWORD *)a3 + 12);
  *(_OWORD *)(a1 + 72) = *(long long *)((char *)a3 + 56);
  uint64_t v8 = *((void *)a3 + 9);
  *(_OWORD *)(a1 + 96) = 0u;
  *(void *)(a1 + 88) = v8;
  *(_OWORD *)(a1 + 112) = 0u;
  *(void *)(a1 + 128) = *((void *)a3 + 10);
  *(_OWORD *)(a1 + 136) = *(long long *)((char *)a3 + 88);
  long long v9 = *(long long *)((char *)a3 + 104);
  long long v10 = *(long long *)((char *)a3 + 120);
  *(void *)(a1 + 184) = *((void *)a3 + 17);
  *(_OWORD *)(a1 + 168) = v10;
  *(_OWORD *)(a1 + 152) = v9;
  uint64_t v11 = a1 + 192;
  uint64_t v12 = a3 + 9;
  do
  {
    char v13 = v5;
    std::__optional_copy_base<ZinIrDMAConvertInfo,false>::__optional_copy_base[abi:ne180100]((ZinIrOpLayerOpCode *)(v11 + 32 * v6), (uint64_t)&v12[2 * v6]);
    char v5 = 1;
    uint64_t v6 = 1;
  }
  while ((v13 & 1) == 0);
  std::__optional_copy_base<ZinIrDMAConvertInfo,false>::__optional_copy_base[abi:ne180100]((ZinIrOpLayerOpCode *)(a1 + 256), (uint64_t)(a3 + 13));
  return a1;
}

void sub_2113B3324(_Unwind_Exception *a1, void **a2, ...)
{
  va_start(va, a2);
  uint64_t v6 = 0;
  while (1)
  {
    if (*(unsigned char *)(v2 + v6 + 248)) {
      ZinIrHalH13g::~ZinIrHalH13g((ZinIrHalH13g *)(v2 + v6 + 224));
    }
    v6 -= 32;
    if (v6 == -64)
    {
      uint64_t v7 = *(void *)(v2 + 120);
      *(void *)(v2 + 12std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
      if (v7) {
        MEMORY[0x21667D3C0](v7, 0x1000C40E8BD624ALL);
      }
      uint64_t v8 = *(void *)(v2 + 112);
      *(void *)(v2 + 112) = 0;
      if (v8) {
        MEMORY[0x21667D3C0](v8, 0x1000C40B1DE44C5);
      }
      std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100](v3, 0);
      uint64_t v9 = *v4;
      *uint64_t v4 = 0;
      if (v9) {
        (*(void (**)(uint64_t))(*(void *)v9 + 8))(v9);
      }
      std::vector<std::string>::__destroy_vector::operator()[abi:ne180100]((void ***)va);
      if (*(char *)(v2 + 31) < 0) {
        operator delete(*a2);
      }
      _Unwind_Resume(a1);
    }
  }
}

BOOL ZinMirUnit::IsValid(ZinMirUnit *this, ZinMirUnitValidationContext *a2)
{
  int v2 = *((_DWORD *)this + 8);
  if (v2 == 106) {
    return 0;
  }
  if (*((char *)this + 31) < 0)
  {
    if (!*((void *)this + 2)) {
      return 0;
    }
  }
  else if (!*((unsigned char *)this + 31))
  {
    return 0;
  }
  if (!*((_DWORD *)this + 16)
    || (*((void *)this + 9) & 0x8000000000000000) != 0
    || *((void *)this + 16) == -1
    || *((unsigned char *)this + 144) && (*((void *)this + 17) & 0x8000000000000000) != 0)
  {
    return 0;
  }
  unsigned int v5 = v2 - 28;
  if ((v5 > 0x2D || ((1 << v5) & 0x200000000003) == 0) && *((void *)this + 6) == *((void *)this + 5)) {
    return 0;
  }
  BOOL result = ZinMirUnitValidationContext::InsertValueToSet<std::string>((uint64_t)a2, a2, (unsigned __int8 *)this + 8);
  if (result)
  {
    unint64_t v7 = *((void *)this + 10);
    BOOL result = ZinMirUnitValidationContext::InsertValueToSet<unsigned long long>((uint64_t)a2, (void *)a2 + 5, &v7);
    if (result)
    {
      if (!*((unsigned char *)this + 144)) {
        return 1;
      }
      unint64_t v7 = *((void *)this + 17);
      BOOL result = ZinMirUnitValidationContext::InsertValueToSet<unsigned long long>((uint64_t)a2, (void *)a2 + 10, &v7);
      if (result) {
        return 1;
      }
    }
  }
  return result;
}

BOOL ZinMirUnit::IsInput(ZinMirUnit *this)
{
  int v1 = *((_DWORD *)this + 8);
  return v1 == 28 || v1 == 73;
}

BOOL ZinMirUnit::IsConstIn(ZinMirUnit *this)
{
  return *((_DWORD *)this + 8) == 29;
}

uint64_t ZinMirUnit::Format(ZinMirUnit *this)
{
  return *((unsigned int *)this + 16);
}

uint64_t ZinMirUnit::SetLayerMirInfo(uint64_t a1, ZinEngineLayerMirInfo **a2)
{
  int v2 = *a2;
  *a2 = 0;
  std::unique_ptr<ZinEngineLayerMirInfo>::reset[abi:ne180100]((ZinEngineLayerMirInfo **)(a1 + 104), v2);
  return 0;
}

uint64_t ZinMirUnit::SetLayerL2Symbols(uint64_t a1, uint64_t *a2)
{
  uint64_t v3 = *a2;
  *a2 = 0;
  uint64_t v4 = *(void *)(a1 + 112);
  *(void *)(a1 + 112) = v3;
  if (v4) {
    MEMORY[0x21667D3C0](v4, 0x1000C40B1DE44C5);
  }
  return 0;
}

uint64_t ZinMirUnit::SetLayerDRAMSymbols(uint64_t a1, uint64_t *a2)
{
  uint64_t v3 = *a2;
  *a2 = 0;
  uint64_t v4 = *(void *)(a1 + 120);
  *(void *)(a1 + 12std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v3;
  if (v4) {
    MEMORY[0x21667D3C0](v4, 0x1000C40E8BD624ALL);
  }
  return 0;
}

uint64_t ZinMirUnit::InitializeEngineLayer(uint64_t a1, ZinIrOpLayer *this, uint64_t *a3, uint64_t *a4)
{
  uint64_t v42 = *MEMORY[0x263EF8340];
  if (ZinIrOpLayer::IsANELayer(this))
  {
    if (!*(void *)(a1 + 104)) {
      ZinAssertImpl("Invalid mir info");
    }
    ZinMirUnit::CreateSymbols(a1, a3, a4);
    ZinANELayer::SetMirInfo((uint64_t)this, (int **)(a1 + 104));
    if (!*(unsigned char *)(a1 + 144)) {
      ZinAssertImpl("Missing TID.");
    }
    uint64_t v8 = *(void *)(a1 + 136);
    if (v8 < 0) {
      ZinAssertImpl("Invalid TD id");
    }
    *((void *)this + 45) = v8;
    ZinObjectNameFactory::ZinObjectNameFactory(v32, (char *)this + 24);
    uint64_t v9 = 0;
    char v10 = 1;
    do
    {
      char v11 = v10;
      if (*(unsigned char *)(a1 + 192 + 32 * v9 + 24))
      {
        (*(void (**)(long long *__return_ptr, ZinIrOpLayer *, void, void))(*(void *)this + 80))(&v34, this, 0, 0);
        uint64_t v12 = operator new(0x78uLL);
        BOOL v30 = (char *)v12 + 120;
        uint64_t v31 = (char *)v12 + 120;
        long long v13 = v39;
        v12[4] = v38;
        v12[5] = v13;
        v12[6] = v40;
        *((_DWORD *)v12 + 28) = v41;
        long long v14 = v35;
        *uint64_t v12 = v34;
        v12[1] = v14;
        long long v15 = v37;
        _OWORD v12[2] = v36;
        void v12[3] = v15;
        uint64_t v29 = v12;
        std::to_string(&v26, v9);
        uint64_t v16 = std::string::insert(&v26, 0, "_src", 4uLL);
        long long v17 = *(_OWORD *)&v16->__r_.__value_.__l.__data_;
        std::string::size_type v28 = v16->__r_.__value_.__r.__words[2];
        *(_OWORD *)std::string __p = v17;
        v16->__r_.__value_.__l.__size_ = 0;
        v16->__r_.__value_.__r.__words[2] = 0;
        v16->__r_.__value_.__r.__words[0] = 0;
        uint64_t v18 = (*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)this + 32))(this, 0, 0);
        ZinIrTensor::CopyTensorMirInfo(v18, &v25);
        ZinBuilder::CreateDMAConvertLayer();
      }
      char v10 = 0;
      uint64_t v9 = 1;
    }
    while ((v11 & 1) != 0);
    if (*(unsigned char *)(a1 + 280))
    {
      (*(void (**)(long long *__return_ptr, ZinIrOpLayer *, void, void))(*(void *)this + 80))(&v34, this, 0, 0);
      BOOL v19 = operator new(0x78uLL);
      BOOL v30 = (char *)v19 + 120;
      uint64_t v31 = (char *)v19 + 120;
      long long v20 = v39;
      v19[4] = v38;
      v19[5] = v20;
      v19[6] = v40;
      *((_DWORD *)v19 + 28) = v41;
      long long v21 = v35;
      *BOOL v19 = v34;
      v19[1] = v21;
      long long v22 = v37;
      void v19[2] = v36;
      v19[3] = v22;
      uint64_t v29 = v19;
      std::string::basic_string[abi:ne180100]<0>(__p, "_dst");
      uint64_t v23 = (*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)this + 32))(this, 0, 0);
      ZinIrTensor::CopyTensorMirInfo(v23, &v26);
      ZinBuilder::CreateDMAConvertLayer();
    }
    v32[0] = &unk_26C34DA98;
    if (v33 < 0) {
      operator delete((void *)v32[1]);
    }
  }
  return 0;
}

void sub_2113B39D4(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *a10, uint64_t a11, int a12, __int16 a13, char a14, char a15, void *__p, uint64_t a17, int a18, __int16 a19, char a20,char a21,uint64_t a22,void *a23,uint64_t a24,uint64_t a25,void *a26,void *a27,uint64_t a28,int a29,__int16 a30,char a31,char a32)
{
  char v33 = a10;
  a10 = 0;
  if (v33) {
    std::default_delete<ZinIrTensor::MirInfo>::operator()[abi:ne180100]((uint64_t)&a10, v33);
  }
  if (a21 < 0) {
    operator delete(__p);
  }
  if (a23)
  {
    a24 = (uint64_t)a23;
    operator delete(a23);
  }
  a26 = &unk_26C34DA98;
  if (a32 < 0) {
    operator delete(a27);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinMirUnit::CreateSymbols(uint64_t a1, uint64_t *a2, uint64_t *a3)
{
  if (ZinMirUnit::CreateL2Symbols(a1, a2)) {
    ZinAssertImpl("Unable to create L2 symbols");
  }
  uint64_t result = ZinMirUnit::CreateDRAMSymbols(a1, a3);
  if (result) {
    ZinAssertImpl("Unable to create DRAM symbols");
  }
  return result;
}

uint64_t ZinMirUnit::CreateL2Symbols(uint64_t a1, uint64_t *a2)
{
  int v2 = *(unsigned int **)(a1 + 112);
  if (!v2) {
    return 3;
  }
  unint64_t v4 = *v2;
  uint64_t v5 = *a2;
  if (0x4FA4FA4FA4FA4FA5 * ((a2[1] - *a2) >> 3) <= v4) {
    ZinAssertImpl("L2 src1 symbol index is out of bounds.");
  }
  uint64_t v6 = *(void *)(v5 + 360 * v4 + 352);
  if (!v6) {
    goto LABEL_31;
  }
  uint64_t Symbol = ZinMirCreateSymbol(v5 + 360 * v4, v6, a2);
  uint64_t v9 = *(void *)(a1 + 104);
  char v10 = operator new(8uLL);
  std::string __p = v10;
  *char v10 = Symbol;
  long long v36 = v10 + 1;
  long long v37 = v10 + 1;
  char v11 = ZinEngineLayerMirInfo::SetL2RdSymbols(v9, (const ZinIrSymbol ***)&__p, 0, *(_DWORD *)(*(void *)(a1 + 112) + 4));
  if (__p)
  {
    long long v36 = __p;
    operator delete(__p);
  }
  if ((v11 & 1) == 0) {
    return 3;
  }
  uint64_t v12 = *(void *)(a1 + 112);
  if (*(unsigned char *)(v12 + 16))
  {
    unint64_t v13 = *(unsigned int *)(v12 + 8);
    uint64_t v14 = *a2;
    if (0x4FA4FA4FA4FA4FA5 * ((a2[1] - *a2) >> 3) <= v13) {
      ZinAssertImpl("L2 src2 symbol index is out of bounds.");
    }
    uint64_t v15 = *(void *)(v14 + 360 * v13 + 352);
    if (!v15) {
      goto LABEL_31;
    }
    uint64_t v16 = ZinMirCreateSymbol(v14 + 360 * v13, v15, a2);
    uint64_t v17 = *(void *)(a1 + 104);
    uint64_t v18 = operator new(8uLL);
    std::string __p = v18;
    *uint64_t v18 = v16;
    long long v36 = v18 + 1;
    long long v37 = v18 + 1;
    int v19 = ZinEngineLayerMirInfo::SetL2RdSymbols(v17, (const ZinIrSymbol ***)&__p, 1, *(_DWORD *)(*(void *)(a1 + 112) + 12));
    if (__p)
    {
      long long v36 = __p;
      operator delete(__p);
    }
    if (!v19) {
      return 3;
    }
    uint64_t v12 = *(void *)(a1 + 112);
  }
  if (!*(unsigned char *)(v12 + 28)) {
    goto LABEL_22;
  }
  unint64_t v20 = *(unsigned int *)(v12 + 20);
  uint64_t v21 = *a2;
  if (0x4FA4FA4FA4FA4FA5 * ((a2[1] - *a2) >> 3) <= v20) {
    ZinAssertImpl("L2 idx symbol index is out of bounds.");
  }
  if (!*(unsigned char *)(v12 + 16)) {
    std::__throw_bad_optional_access[abi:ne180100]();
  }
  uint64_t v22 = *(void *)(v21 + 360 * *(unsigned int *)(v12 + 8) + 352);
  if (!v22) {
LABEL_31:
  }
    ZinAssertImpl("L2 section is not initialized\n");
  uint64_t v23 = ZinMirCreateSymbol(v21 + 360 * v20, v22, a2);
  uint64_t v24 = *(void *)(a1 + 104);
  uint64_t v25 = operator new(8uLL);
  std::string __p = v25;
  *uint64_t v25 = v23;
  long long v36 = v25 + 1;
  long long v37 = v25 + 1;
  int v26 = ZinEngineLayerMirInfo::SetL2RdSymbols(v24, (const ZinIrSymbol ***)&__p, 2, *(_DWORD *)(*(void *)(a1 + 112) + 24));
  if (__p)
  {
    long long v36 = __p;
    operator delete(__p);
  }
  if (!v26) {
    return 3;
  }
  uint64_t v12 = *(void *)(a1 + 112);
LABEL_22:
  unint64_t v27 = *(unsigned int *)(v12 + 32);
  uint64_t v28 = *a2;
  if (0x4FA4FA4FA4FA4FA5 * ((a2[1] - *a2) >> 3) <= v27) {
    ZinAssertImpl("L2 dst symbol index is out of bounds.");
  }
  uint64_t v29 = *(void *)(v28 + 360 * v27 + 352);
  if (!v29) {
    goto LABEL_31;
  }
  uint64_t v30 = ZinMirCreateSymbol(v28 + 360 * v27, v29, a2);
  uint64_t v31 = *(void *)(a1 + 104);
  uint64_t v32 = operator new(8uLL);
  std::string __p = v32;
  void *v32 = v30;
  long long v36 = v32 + 1;
  long long v37 = v32 + 1;
  int v33 = ZinEngineLayerMirInfo::SetL2WrSymbols(v31, (const ZinIrSymbol ***)&__p, *(_DWORD *)(*(void *)(a1 + 112) + 36));
  if (__p)
  {
    long long v36 = __p;
    operator delete(__p);
  }
  if (v33) {
    return 0;
  }
  else {
    return 3;
  }
}

void sub_2113B3E20(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11)
{
  if (__p) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinMirUnit::CreateDRAMSymbols(uint64_t a1, uint64_t *a2)
{
  int v2 = *(unsigned int **)(a1 + 120);
  if (!v2) {
    return 3;
  }
  if (*((unsigned char *)v2 + 4))
  {
    unint64_t v5 = *v2;
    uint64_t v6 = *a2;
    if (0x4FA4FA4FA4FA4FA5 * ((a2[1] - *a2) >> 3) <= v5) {
      ZinAssertImpl("DRAM src1 symbol index is out of bounds.");
    }
    uint64_t v7 = *(void *)(v6 + 360 * v5 + 352);
    if (!v7) {
      goto LABEL_16;
    }
    *(void *)(*(void *)(a1 + 104) + 752) = ZinMirCreateSymbol(v6 + 360 * v5, v7, a2);
    int v2 = *(unsigned int **)(a1 + 120);
  }
  if (*((unsigned char *)v2 + 12))
  {
    unint64_t v8 = v2[2];
    uint64_t v9 = *a2;
    if (0x4FA4FA4FA4FA4FA5 * ((a2[1] - *a2) >> 3) <= v8) {
      ZinAssertImpl("DRAM src2 symbol index is out of bounds.");
    }
    uint64_t v10 = *(void *)(v9 + 360 * v8 + 352);
    if (!v10) {
      goto LABEL_16;
    }
    *(void *)(*(void *)(a1 + 104) + 848) = ZinMirCreateSymbol(v9 + 360 * v8, v10, a2);
    int v2 = *(unsigned int **)(a1 + 120);
  }
  if (*((unsigned char *)v2 + 20))
  {
    unint64_t v11 = v2[4];
    uint64_t v12 = *a2;
    if (0x4FA4FA4FA4FA4FA5 * ((a2[1] - *a2) >> 3) <= v11) {
      ZinAssertImpl("DRAM dst symbol index is out of bounds.");
    }
    uint64_t v13 = *(void *)(v12 + 360 * v11 + 352);
    if (v13)
    {
      uint64_t Symbol = ZinMirCreateSymbol(v12 + 360 * v11, v13, a2);
      uint64_t result = 0;
      *(void *)(*(void *)(a1 + 104) + 944) = Symbol;
      return result;
    }
LABEL_16:
    ZinAssertImpl("DRAM section is not initialized\n");
  }
  return 0;
}

uint64_t ZinMirCreateSymbol(uint64_t a1, uint64_t a2, void *a3)
{
  v16[38] = *MEMORY[0x263EF8340];
  uint64_t v6 = (const std::string *)(a1 + 8);
  uint64_t SymbolByName = ZinIrSymbolTable::GetSymbolByName(a2 + 64, (void **)(a1 + 8));
  if (!SymbolByName)
  {
    if (*(unsigned char *)(a1 + 348))
    {
      unint64_t v8 = *(unsigned int *)(a1 + 344);
      if (0x4FA4FA4FA4FA4FA5 * ((uint64_t)(a3[1] - *a3) >> 3) <= v8) {
        ZinAssertImpl("Symbol index is out of bounds.");
      }
      uint64_t Symbol = ZinMirCreateSymbol(*a3 + 360 * v8, a2, a3);
    }
    else
    {
      uint64_t Symbol = 0;
    }
    ZinIrSymbol::Descriptor::Descriptor((ZinIrSymbol::Descriptor *)&v14);
    std::string::operator=(&v15, v6);
    int32x2_t v14 = vrev64_s32(*(int32x2_t *)a1);
    v16[0] = *(void *)(a1 + 48);
    *(_OWORD *)&v16[1] = *(_OWORD *)(a1 + 56);
    if (*(unsigned char *)(a1 + 280))
    {
      *(_OWORD *)&v16[21] = *(_OWORD *)(a1 + 216);
      *(_OWORD *)&v16[23] = *(_OWORD *)(a1 + 232);
      *(_OWORD *)&v16[25] = *(_OWORD *)(a1 + 248);
      *(_OWORD *)&v16[13] = *(_OWORD *)(a1 + 152);
      *(_OWORD *)&v16[15] = *(_OWORD *)(a1 + 168);
      *(_OWORD *)&v16[17] = *(_OWORD *)(a1 + 184);
      *(_OWORD *)&v16[19] = *(_OWORD *)(a1 + 200);
      *(_OWORD *)&void v16[5] = *(_OWORD *)(a1 + 88);
      *(_OWORD *)&v16[7] = *(_OWORD *)(a1 + 104);
      *(_OWORD *)&v16[9] = *(_OWORD *)(a1 + 120);
      *(_OWORD *)&v16[11] = *(_OWORD *)(a1 + 136);
      *(_OWORD *)&void v16[3] = *(_OWORD *)(a1 + 72);
      *(_OWORD *)&v16[27] = *(_OWORD *)(a1 + 264);
    }
    int32x2_t v11 = v14;
    if (SHIBYTE(v15.__r_.__value_.__r.__words[2]) < 0) {
      std::string::__init_copy_ctor_external(&__p, v15.__r_.__value_.__l.__data_, v15.__r_.__value_.__l.__size_);
    }
    else {
      std::string __p = v15;
    }
    memcpy(v13, v16, sizeof(v13));
    if (*(unsigned char *)(a1 + 304)) {
      ZinIrSection::CreateSymbolAtOffset(a2, (uint64_t)&v11, Symbol, *(void *)(a1 + 32), *(void *)(a1 + 40), *(void *)(a1 + 288), *(void *)(a1 + 296));
    }
    std::__throw_bad_optional_access[abi:ne180100]();
  }
  return SymbolByName;
}

void sub_2113B420C(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, void *a11, uint64_t a12, int a13, __int16 a14, char a15, char a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33,uint64_t a34,uint64_t a35,uint64_t a36,uint64_t a37,uint64_t a38,uint64_t a39,uint64_t a40,uint64_t a41,uint64_t a42,uint64_t a43,uint64_t a44,uint64_t a45,uint64_t a46,uint64_t a47,uint64_t a48,uint64_t a49,uint64_t a50,uint64_t a51,uint64_t a52,uint64_t a53,uint64_t a54,uint64_t a55,void *__p,uint64_t a57,int a58,__int16 a59,char a60,char a61)
{
}

BOOL ZinMirUnit::IsOutput(ZinMirUnit *this)
{
  return *((_DWORD *)this + 8) == 31;
}

uint64_t ZinMirUnit::GetAotTensorDims(ZinMirUnit *this)
{
  return (uint64_t)this + 152;
}

uint64_t ZinMirUnit::Print@<X0>(ZinMirUnit *this@<X0>, void *a2@<X8>)
{
  std::basic_stringstream<char,std::char_traits<char>,std::allocator<char>>::basic_stringstream[abi:ne180100]((uint64_t)v34);
  unint64_t v4 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v35, (uint64_t)"\t\t\t", 3);
  int v5 = *((char *)this + 31);
  if (v5 >= 0) {
    uint64_t v6 = (char *)this + 8;
  }
  else {
    uint64_t v6 = (char *)*((void *)this + 1);
  }
  if (v5 >= 0) {
    uint64_t v7 = *((unsigned __int8 *)this + 31);
  }
  else {
    uint64_t v7 = *((void *)this + 2);
  }
  unint64_t v8 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v4, (uint64_t)v6, v7);
  uint64_t v9 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v8, (uint64_t)"</font><br/>", 12);
  std::ios_base::getloc((const std::ios_base *)((char *)v9 + *(void *)(*v9 - 24)));
  uint64_t v10 = std::locale::use_facet(&v31, MEMORY[0x263F8C108]);
  ((void (*)(const std::locale::facet *, uint64_t))v10->__vftable[2].~facet_0)(v10, 10);
  std::locale::~locale(&v31);
  std::ostream::put();
  std::ostream::flush();
  int32x2_t v11 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v35, (uint64_t)"\t\t\t<font face='Arial Rounded MT Bold'>Op:</font> ", 49);
  ZinIrEnumToStringUtil::OpCodeToString(*((_DWORD *)this + 8), &v31);
  if ((v33 & 0x80u) == 0) {
    locale = &v31;
  }
  else {
    locale = v31.__locale_;
  }
  if ((v33 & 0x80u) == 0) {
    uint64_t v13 = v33;
  }
  else {
    uint64_t v13 = v32;
  }
  int32x2_t v14 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v11, (uint64_t)locale, v13);
  std::string v15 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v14, (uint64_t)"<br align='left'/>", 18);
  std::ios_base::getloc((const std::ios_base *)((char *)v15 + *(void *)(*v15 - 24)));
  uint64_t v16 = std::locale::use_facet(&v39, MEMORY[0x263F8C108]);
  ((void (*)(const std::locale::facet *, uint64_t))v16->__vftable[2].~facet_0)(v16, 10);
  std::locale::~locale(&v39);
  std::ostream::put();
  std::ostream::flush();
  if ((char)v33 < 0) {
    operator delete(v31.__locale_);
  }
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v35, (uint64_t)"\t\t\t<font face='Arial Rounded MT Bold'>ID:</font> ", 49);
  uint64_t v17 = (void *)std::ostream::operator<<();
  uint64_t v18 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v17, (uint64_t)"<br align='left'/>", 18);
  std::ios_base::getloc((const std::ios_base *)((char *)v18 + *(void *)(*v18 - 24)));
  int v19 = std::locale::use_facet(&v31, MEMORY[0x263F8C108]);
  ((void (*)(const std::locale::facet *, uint64_t))v19->__vftable[2].~facet_0)(v19, 10);
  std::locale::~locale(&v31);
  std::ostream::put();
  std::ostream::flush();
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v35, (uint64_t)"\t\t\t<font face='Arial Rounded MT Bold'>SCHED:</font> ", 52);
  unint64_t v20 = (void *)std::ostream::operator<<();
  uint64_t v21 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v20, (uint64_t)"<br align='left'/>", 18);
  std::ios_base::getloc((const std::ios_base *)((char *)v21 + *(void *)(*v21 - 24)));
  uint64_t v22 = std::locale::use_facet(&v31, MEMORY[0x263F8C108]);
  ((void (*)(const std::locale::facet *, uint64_t))v22->__vftable[2].~facet_0)(v22, 10);
  std::locale::~locale(&v31);
  std::ostream::put();
  std::ostream::flush();
  if (*((unsigned char *)this + 144))
  {
    std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v35, (uint64_t)"\t\t\t<font face='Arial Rounded MT Bold'>TID:</font> ", 50);
    if (!*((unsigned char *)this + 144)) {
      std::__throw_bad_optional_access[abi:ne180100]();
    }
    uint64_t v23 = (void *)std::ostream::operator<<();
    uint64_t v24 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v23, (uint64_t)"<br align='left'/>", 18);
    std::ios_base::getloc((const std::ios_base *)((char *)v24 + *(void *)(*v24 - 24)));
    uint64_t v25 = std::locale::use_facet(&v31, MEMORY[0x263F8C108]);
    ((void (*)(const std::locale::facet *, uint64_t))v25->__vftable[2].~facet_0)(v25, 10);
    std::locale::~locale(&v31);
    std::ostream::put();
    std::ostream::flush();
  }
  std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(&v35, (uint64_t)"\t\t\t<font face='Arial Rounded MT Bold'>GROUP ID:</font> ", 55);
  int v26 = (void *)std::ostream::operator<<();
  unint64_t v27 = std::__put_character_sequence[abi:ne180100]<char,std::char_traits<char>>(v26, (uint64_t)"<br align='left'/>", 18);
  std::ios_base::getloc((const std::ios_base *)((char *)v27 + *(void *)(*v27 - 24)));
  uint64_t v28 = std::locale::use_facet(&v31, MEMORY[0x263F8C108]);
  ((void (*)(const std::locale::facet *, uint64_t))v28->__vftable[2].~facet_0)(v28, 10);
  std::locale::~locale(&v31);
  std::ostream::put();
  std::ostream::flush();
  std::stringbuf::str[abi:ne180100]<std::allocator<char>>((uint64_t)v36, a2);
  v34[0] = *MEMORY[0x263F8C2B8];
  uint64_t v29 = *(void *)(MEMORY[0x263F8C2B8] + 72);
  *(void *)((char *)v34 + *(void *)(v34[0] - 24)) = *(void *)(MEMORY[0x263F8C2B8] + 64);
  uint64_t v35 = v29;
  v36[0] = MEMORY[0x263F8C318] + 16;
  if (v37 < 0) {
    operator delete((void *)v36[8]);
  }
  std::streambuf::~streambuf();
  std::iostream::~basic_iostream();
  return MEMORY[0x21667D2B0](&v38);
}

void sub_2113B482C(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, std::locale a10, uint64_t a11, int a12, __int16 a13, char a14, char a15, char a16)
{
}

BOOL ZinMirUnitValidationContext::InsertValueToSet<std::string>(uint64_t a1, void *a2, unsigned __int8 *a3)
{
  int v5 = std::__hash_table<std::__hash_value_type<std::string,PerfTracerCategory>,std::__unordered_map_hasher<std::string,std::__hash_value_type<std::string,PerfTracerCategory>,std::hash<std::string>,std::equal_to<std::string>,true>,std::__unordered_map_equal<std::string,std::__hash_value_type<std::string,PerfTracerCategory>,std::equal_to<std::string>,std::hash<std::string>,true>,std::allocator<std::__hash_value_type<std::string,PerfTracerCategory>>>::find<std::string>(a2, a3);
  if (!v5) {
    std::__hash_table<std::string,std::hash<std::string>,std::equal_to<std::string>,std::allocator<std::string>>::__emplace_unique_key_args<std::string,std::string const&>((uint64_t)a2, a3, (uint64_t)a3);
  }
  return v5 == 0;
}

BOOL ZinMirUnitValidationContext::InsertValueToSet<unsigned long long>(uint64_t a1, void *a2, unint64_t *a3)
{
  int v5 = std::__hash_table<std::__hash_value_type<unsigned long long,CpAllocUtils::AllocationType>,std::__unordered_map_hasher<unsigned long long,std::__hash_value_type<unsigned long long,CpAllocUtils::AllocationType>,std::hash<unsigned long long>,std::equal_to<unsigned long long>,true>,std::__unordered_map_equal<unsigned long long,std::__hash_value_type<unsigned long long,CpAllocUtils::AllocationType>,std::equal_to<unsigned long long>,std::hash<unsigned long long>,true>,std::allocator<std::__hash_value_type<unsigned long long,CpAllocUtils::AllocationType>>>::find<unsigned long long>(a2, a3);
  if (!v5) {
    std::__hash_table<ZinNamedType<unsigned long,AneIndexTag>,std::hash<ZinNamedType<unsigned long,AneIndexTag>>,std::equal_to<ZinNamedType<unsigned long,AneIndexTag>>,std::allocator<ZinNamedType<unsigned long,AneIndexTag>>>::__emplace_unique_key_args<ZinNamedType<unsigned long,AneIndexTag>,ZinNamedType<unsigned long,AneIndexTag> const&>((uint64_t)a2, a3, a3);
  }
  return v5 == 0;
}

void ZinParseMirAliasUnit()
{
}

void sub_2113B4A08(_Unwind_Exception *a1)
{
  MEMORY[0x21667D3C0](v1, 0x10B3C400EEE3B5BLL);
  _Unwind_Resume(a1);
}

void ZinParseMirConcatUnit(ZinSerial::Deserializer *a1, ZinMirUnit::CommonUnitInfo *a2, ZinIrUnitStatus *a3)
{
}

void sub_2113B4B10(_Unwind_Exception *a1)
{
  MEMORY[0x21667D3C0](v1, 0x10B3C4070E01257);
  _Unwind_Resume(a1);
}

void ZinParseMirTransposeUnit(ZinSerial::Deserializer *a1, ZinMirUnit::CommonUnitInfo *a2, ZinIrUnitStatus *a3)
{
}

void sub_2113B4C18(_Unwind_Exception *a1)
{
  MEMORY[0x21667D3C0](v1, 0x10B3C4070E01257);
  _Unwind_Resume(a1);
}

void ZinParseMirViewUnit(ZinSerial::Deserializer *a1, ZinMirUnit::CommonUnitInfo *a2, ZinIrUnitStatus *a3)
{
}

void sub_2113B4D20(_Unwind_Exception *a1)
{
  MEMORY[0x21667D3C0](v1, 0x10B3C40BB21B309);
  _Unwind_Resume(a1);
}

void ZinParseMirReshapeUnit(ZinSerial::Deserializer *a1, ZinMirUnit::CommonUnitInfo *a2, ZinIrUnitStatus *a3)
{
}

void sub_2113B4E28(_Unwind_Exception *a1)
{
  MEMORY[0x21667D3C0](v1, 0x10B3C40AC1374BELL);
  _Unwind_Resume(a1);
}

void ZinParseMirConstInUnit()
{
}

void sub_2113B4F30(_Unwind_Exception *a1)
{
  MEMORY[0x21667D3C0](v1, 0x10B3C405AFEF507);
  _Unwind_Resume(a1);
}

uint64_t ZinIrPadUnit::ZinIrPadUnit(uint64_t a1, uint64_t a2, uint64_t a3)
{
  int v5 = ZinIrUnit::ZinIrUnit((void *)a1, a3);
  *int v5 = &unk_26C3448D0;
  ZinIrTextureUnitInfo::ZinIrTextureUnitInfo((ZinIrTextureUnitInfo *)(v5 + 7), (const ZinIrTextureUnitInfo *)a2);
  *(void *)(a1 + 56) = &unk_26C3499A0;
  long long v6 = *(_OWORD *)(a2 + 156);
  long long v7 = *(_OWORD *)(a2 + 172);
  *(void *)(a1 + 244) = *(void *)(a2 + 188);
  *(_OWORD *)(a1 + 228) = v7;
  *(_OWORD *)(a1 + 212) = v6;
  *(void *)(a1 + 264) = 0;
  *(void *)(a1 + 272) = 0;
  *(void *)(a1 + 256) = 0;
  std::vector<ZinIrOpLayer *>::__init_with_size[abi:ne180100]<ZinIrOpLayer **,ZinIrOpLayer **>((void *)(a1 + 256), *(const void **)(a2 + 200), *(void *)(a2 + 208), (uint64_t)(*(void *)(a2 + 208) - *(void *)(a2 + 200)) >> 3);
  *(_WORD *)(a1 + 28std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = *(_WORD *)(a2 + 224);
  return a1;
}

void sub_2113B5028(_Unwind_Exception *a1)
{
  ZinIrTextureUnitInfo::~ZinIrTextureUnitInfo(v2);
  ZinIrUnit::~ZinIrUnit(v1);
  _Unwind_Resume(a1);
}

uint64_t ZinIrPadUnit::TensorDimensions(ZinIrPadUnit *this, const ZinIrHalParameters *a2, ZinTensorDimensions *a3, ZinIrUnitStatus *a4)
{
  unint64_t v4 = (void *)*((void *)this + 1);
  uint64_t v5 = v4[2];
  uint64_t v6 = v4[1] + *((int *)this + 61) + (uint64_t)*((int *)this + 62);
  *((void *)a3 + 4) = v4[5] + *((int *)this + 57) + (uint64_t)*((int *)this + 58);
  uint64_t v7 = v5 + *((int *)this + 59) + (uint64_t)*((int *)this + 60);
  *(void *)a3 = v6;
  *((void *)a3 + 1) = v7;
  uint64_t v8 = v4[3] + *((int *)this + 55) + (uint64_t)*((int *)this + 56);
  uint64_t v9 = v4[4] + *((int *)this + 53) + (uint64_t)*((int *)this + 54);
  *((void *)a3 + 2) = v8;
  *((void *)a3 + 3) = v9;
  return 0;
}

void ZinIrPadUnit::CreateOpcode(unsigned int **this)
{
  int v2 = *(_DWORD *)((*((uint64_t (**)(unsigned int **))*this + 14))(this) + 64);
  unsigned int v3 = *this[1];
  if (!v2)
  {
    if (v3 == 8) {
      ZinAssertImpl("Invalid input tensor format: packed10 for pad layer");
    }
    if ((IsFormatDMAConvertibleToFP16(v3) & 1) == 0 && CheckValidFormat(*this[1]))
    {
      ZinTensorFormatToString(*this[1], v5);
      if (v6 >= 0) {
        unint64_t v4 = (const char *)v5;
      }
      else {
        unint64_t v4 = (const char *)v5[0];
      }
      ZinAssertImpl("Invalid input tensor format: %s for pad layer", v4);
    }
  }
  operator new();
}

void sub_2113B51D0(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11, int a12, __int16 a13, char a14, char a15)
{
  if (a15 < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

void ZinIrPadUnit::CreateLayer(unsigned int **a1)
{
}

void sub_2113B537C(_Unwind_Exception *exception_object)
{
  unsigned int v3 = *(void **)(v1 - 104);
  if (v3)
  {
    *(void *)(v1 - 96) = v3;
    operator delete(v3);
  }
  uint64_t v4 = *(void *)(v1 - 56);
  *(void *)(v1 - 56) = 0;
  if (v4) {
    (*(void (**)(uint64_t))(*(void *)v4 + 8))(v4);
  }
  _Unwind_Resume(exception_object);
}

uint64_t ZinIrOpt::MergeIntCast(void *a1, uint64_t a2)
{
  v29[1] = *MEMORY[0x263EF8340];
  std::string::basic_string[abi:ne180100]<0>(v20, "op_pattern");
  v21[0] = &unk_26C38C718;
  v21[3] = v21;
  int v8 = 1;
  std::unordered_set<Attribute>::unordered_set((uint64_t)&v22, &v8, 1);
  std::string::basic_string[abi:ne180100]<0>(v23, "cast_pattern");
  v24[0] = &unk_26C38C798;
  v24[3] = v24;
  int v7 = 1;
  std::unordered_set<Attribute>::unordered_set((uint64_t)v25, &v7, 1);
  uint64_t v9 = 0;
  uint64_t v10 = 0;
  int32x2_t v11 = 0;
  uint64_t v16 = &v9;
  char v17 = 0;
  uint64_t v9 = (char *)operator new(0xC0uLL);
  uint64_t v10 = (uint64_t)v9;
  int32x2_t v11 = v9 + 192;
  uint64_t v10 = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<ZinLinearPattern::AtomItemDesc>,ZinLinearPattern::AtomItemDesc const*,ZinLinearPattern::AtomItemDesc const*,ZinLinearPattern::AtomItemDesc*>((uint64_t)&v11, (uint64_t)v20, (uint64_t)v26, (uint64_t)v9);
  v19[3] = 0;
  ZinLinearPattern::ZinLinearPattern(v26, &v9, a2, 0, v19, 0);
  std::allocate_shared[abi:ne180100]<ZinLinearPattern,std::allocator<ZinLinearPattern>,ZinLinearPattern,void>((uint64_t)v26, &v12);
  long long v28 = v12;
  long long v12 = 0uLL;
  int32x2_t v14 = 0;
  std::string v15 = 0;
  uint64_t v13 = 0;
  uint64_t v16 = (char **)&v13;
  char v17 = 0;
  uint64_t v13 = operator new(0x10uLL);
  int32x2_t v14 = v13;
  std::string v15 = v13 + 2;
  int32x2_t v14 = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::shared_ptr<ZinPattern>>,std::shared_ptr<ZinPattern> const*,std::shared_ptr<ZinPattern> const*,std::shared_ptr<ZinPattern>*>((uint64_t)&v15, &v28, v29, v13);
  if (*((void *)&v28 + 1)) {
    std::__shared_weak_count::__release_shared[abi:ne180100](*((std::__shared_weak_count **)&v28 + 1));
  }
  if (*((void *)&v12 + 1)) {
    std::__shared_weak_count::__release_shared[abi:ne180100](*((std::__shared_weak_count **)&v12 + 1));
  }
  v26[0] = (void **)&unk_26C349BA8;
  uint64_t v16 = (char **)&v27;
  std::vector<ZinLinearPattern::AtomItemDesc>::__destroy_vector::operator()[abi:ne180100]((void ***)&v16);
  ZinPattern::~ZinPattern((ZinPattern *)v26);
  std::__function::__value_func<BOOL ()(ZinIrOpLayerGraph const*,ZinIrParameters const&,ZinPattern const*)>::~__value_func[abi:ne180100](v19);
  uint64_t v16 = &v9;
  std::vector<ZinLinearPattern::AtomItemDesc>::__destroy_vector::operator()[abi:ne180100]((void ***)&v16);
  for (uint64_t i = 0; i != -24; i -= 12)
  {
    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&v25[i * 8]);
    std::__function::__value_func<MatchStatus ()(MatchParams const&)>::~__value_func[abi:ne180100](&v24[i]);
    if (SHIBYTE(v23[i + 2]) < 0) {
      operator delete((void *)v23[i]);
    }
  }
  v18[0] = &unk_26C38C818;
  v18[1] = &v13;
  v18[3] = v18;
  uint64_t v5 = ZinIrControlFlowGraph::TraverseForward(a1, (uint64_t)v18, 1);
  std::__function::__value_func<ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::~__value_func[abi:ne180100](v18);
  v26[0] = (void **)&v13;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100](v26);
  return v5;
}

void sub_2113B5708(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,uint64_t a31,uint64_t a32,uint64_t a33,uint64_t a34,uint64_t a35,uint64_t a36,uint64_t a37,uint64_t a38,uint64_t a39,uint64_t a40,uint64_t a41,uint64_t a42,uint64_t a43,uint64_t a44,uint64_t a45,uint64_t a46,uint64_t a47,uint64_t a48,uint64_t a49,uint64_t a50,uint64_t a51,uint64_t a52,void **a53)
{
}

void std::__function::__func<ZinIrOpt::MergeIntCast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0,std::allocator<ZinIrOpt::MergeIntCast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0>,MatchStatus ()(MatchParams const&)>::~__func()
{
}

void *std::__function::__func<ZinIrOpt::MergeIntCast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0,std::allocator<ZinIrOpt::MergeIntCast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0>,MatchStatus ()(MatchParams const&)>::__clone()
{
  uint64_t result = operator new(0x10uLL);
  *uint64_t result = &unk_26C38C718;
  return result;
}

void std::__function::__func<ZinIrOpt::MergeIntCast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0,std::allocator<ZinIrOpt::MergeIntCast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0>,MatchStatus ()(MatchParams const&)>::__clone(uint64_t a1, void *a2)
{
  *a2 = &unk_26C38C718;
}

uint64_t std::__function::__func<ZinIrOpt::MergeIntCast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0,std::allocator<ZinIrOpt::MergeIntCast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0>,MatchStatus ()(MatchParams const&)>::operator()(uint64_t a1, uint64_t a2)
{
  int v2 = *(void **)(a2 + 8);
  BOOL v3 = *(_DWORD *)(v2[8] + 8) == 16
    && *(_DWORD *)((*(uint64_t (**)(void *, void, void))(*v2 + 32))(v2, 0, 0) + 88) == 10;
  return v3 | 0x100u;
}

uint64_t std::__function::__func<ZinIrOpt::MergeIntCast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0,std::allocator<ZinIrOpt::MergeIntCast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0>,MatchStatus ()(MatchParams const&)>::target(uint64_t a1, uint64_t a2)
{
  {
    return a1 + 8;
  }
  else
  {
    return 0;
  }
}

void *std::__function::__func<ZinIrOpt::MergeIntCast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0,std::allocator<ZinIrOpt::MergeIntCast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0>,MatchStatus ()(MatchParams const&)>::target_type()
{
}

void std::__function::__func<ZinIrOpt::MergeIntCast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1,std::allocator<ZinIrOpt::MergeIntCast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1>,MatchStatus ()(MatchParams const&)>::~__func()
{
}

void *std::__function::__func<ZinIrOpt::MergeIntCast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1,std::allocator<ZinIrOpt::MergeIntCast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1>,MatchStatus ()(MatchParams const&)>::__clone()
{
  uint64_t result = operator new(0x10uLL);
  *uint64_t result = &unk_26C38C798;
  return result;
}

void std::__function::__func<ZinIrOpt::MergeIntCast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1,std::allocator<ZinIrOpt::MergeIntCast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1>,MatchStatus ()(MatchParams const&)>::__clone(uint64_t a1, void *a2)
{
  *a2 = &unk_26C38C798;
}

uint64_t std::__function::__func<ZinIrOpt::MergeIntCast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1,std::allocator<ZinIrOpt::MergeIntCast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1>,MatchStatus ()(MatchParams const&)>::operator()(uint64_t a1, uint64_t a2)
{
  int v2 = *(void **)(a2 + 8);
  BOOL v3 = *(_DWORD *)(v2[8] + 8) == 2
    && ZinGOCLayer::HasDefaultScaleBias(*(ZinGOCLayer **)(a2 + 8))
    && *(_DWORD *)((*(uint64_t (**)(void *, void, void))(*v2 + 32))(v2, 0, 0) + 88) == 2;
  return v3 | 0x100u;
}

uint64_t std::__function::__func<ZinIrOpt::MergeIntCast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1,std::allocator<ZinIrOpt::MergeIntCast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1>,MatchStatus ()(MatchParams const&)>::target(uint64_t a1, uint64_t a2)
{
  {
    return a1 + 8;
  }
  else
  {
    return 0;
  }
}

void *std::__function::__func<ZinIrOpt::MergeIntCast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1,std::allocator<ZinIrOpt::MergeIntCast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1>,MatchStatus ()(MatchParams const&)>::target_type()
{
}

void std::__function::__func<ZinIrOpt::MergeIntCast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_2,std::allocator<ZinIrOpt::MergeIntCast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_2>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::~__func()
{
}

void *std::__function::__func<ZinIrOpt::MergeIntCast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_2,std::allocator<ZinIrOpt::MergeIntCast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_2>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::__clone(uint64_t a1)
{
  uint64_t result = operator new(0x10uLL);
  uint64_t v3 = *(void *)(a1 + 8);
  *uint64_t result = &unk_26C38C818;
  result[1] = v3;
  return result;
}

uint64_t std::__function::__func<ZinIrOpt::MergeIntCast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_2,std::allocator<ZinIrOpt::MergeIntCast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_2>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::__clone(uint64_t result, void *a2)
{
  uint64_t v2 = *(void *)(result + 8);
  *a2 = &unk_26C38C818;
  a2[1] = v2;
  return result;
}

uint64_t std::__function::__func<ZinIrOpt::MergeIntCast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_2,std::allocator<ZinIrOpt::MergeIntCast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_2>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::operator()(uint64_t a1, uint64_t *a2, uint64_t *a3)
{
  uint64_t v3 = *(uint64_t ***)(a1 + 8);
  uint64_t v4 = *v3;
  uint64_t v5 = v3[1];
  if (*v3 != v5)
  {
    uint64_t v6 = *a2;
    uint64_t v7 = *a3;
    do
    {
      if ((*(unsigned int (**)(uint64_t, uint64_t, uint64_t))(*(void *)*v4 + 8))(*v4, v6, v7))
      {
        uint64_t v8 = *v4;
        std::string::basic_string[abi:ne180100]<0>(&__p, "op_pattern");
        uint64_t SingleMatch = ZinPattern::GetSingleMatch(v8, (unsigned __int8 *)&__p);
        if (v28 < 0) {
          operator delete(__p);
        }
        uint64_t v10 = *v4;
        std::string::basic_string[abi:ne180100]<0>(&__p, "cast_pattern");
        ZinPattern::GetSingleMatch(v10, (unsigned __int8 *)&__p);
        if (v28 < 0) {
          operator delete(__p);
        }
        if (*(char *)(SingleMatch + 47) >= 0) {
          size_t v11 = *(unsigned __int8 *)(SingleMatch + 47);
        }
        else {
          size_t v11 = *(void *)(SingleMatch + 32);
        }
        std::string::basic_string[abi:ne180100]((uint64_t)&v26, v11 + 1);
        if ((v26.__r_.__value_.__r.__words[2] & 0x8000000000000000) == 0) {
          long long v12 = &v26;
        }
        else {
          long long v12 = (std::string *)v26.__r_.__value_.__r.__words[0];
        }
        if (v11)
        {
          if (*(char *)(SingleMatch + 47) >= 0) {
            uint64_t v13 = (const void *)(SingleMatch + 24);
          }
          else {
            uint64_t v13 = *(const void **)(SingleMatch + 24);
          }
          memmove(v12, v13, v11);
        }
        *(_WORD *)((char *)&v12->__r_.__value_.__l.__data_ + v11) = 95;
        std::string::basic_string[abi:ne180100]<0>(&v23, "merge_cast");
        int32x2_t v14 = std::string::append(&v23, "_xfm", 4uLL);
        long long v15 = *(_OWORD *)&v14->__r_.__value_.__l.__data_;
        int64_t v25 = v14->__r_.__value_.__r.__words[2];
        *(_OWORD *)uint64_t v24 = v15;
        v14->__r_.__value_.__l.__size_ = 0;
        v14->__r_.__value_.__r.__words[2] = 0;
        v14->__r_.__value_.__r.__words[0] = 0;
        if (v25 >= 0) {
          uint64_t v16 = v24;
        }
        else {
          uint64_t v16 = (void **)v24[0];
        }
        if (v25 >= 0) {
          std::string::size_type v17 = HIBYTE(v25);
        }
        else {
          std::string::size_type v17 = (std::string::size_type)v24[1];
        }
        uint64_t v18 = std::string::append(&v26, (const std::string::value_type *)v16, v17);
        long long v19 = *(_OWORD *)&v18->__r_.__value_.__l.__data_;
        v22.__r_.__value_.__r.__words[2] = v18->__r_.__value_.__r.__words[2];
        *(_OWORD *)&v22.__r_.__value_.__l.__data_ = v19;
        v18->__r_.__value_.__l.__size_ = 0;
        v18->__r_.__value_.__r.__words[2] = 0;
        v18->__r_.__value_.__r.__words[0] = 0;
        __n128 v20 = ZinObjectNameFactory::ZinObjectNameFactory(&__p, &v22);
        if (SHIBYTE(v22.__r_.__value_.__r.__words[2]) < 0) {
          operator delete(v22.__r_.__value_.__l.__data_);
        }
        if (SHIBYTE(v25) < 0) {
          operator delete(v24[0]);
        }
        if (SHIBYTE(v23.__r_.__value_.__r.__words[2]) < 0) {
          operator delete(v23.__r_.__value_.__l.__data_);
        }
        if (SHIBYTE(v26.__r_.__value_.__r.__words[2]) < 0) {
          operator delete(v26.__r_.__value_.__l.__data_);
        }
        (*(void (**)(uint64_t, void, void, __n128))(*(void *)SingleMatch + 32))(SingleMatch, 0, 0, v20);
        ZinObjectNameFactory::CreateName((uint64_t)&__p, 0, &v22);
        ZinIrTensor::CreateTensor();
      }
      v4 += 2;
    }
    while (v4 != v5);
  }
  return 0;
}

void sub_2113B5F54(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, void *a9, void *a10, uint64_t a11, uint64_t a12, uint64_t a13, void *a14, uint64_t a15, int a16, __int16 a17, char a18, char a19, void *a20,uint64_t a21,int a22,__int16 a23,char a24,char a25,uint64_t a26,std::__shared_weak_count *a27,int a28,__int16 a29,char a30,char a31,uint64_t a32,void *__p,int a34,__int16 a35,char a36,char a37,int a38,__int16 a39,char a40,char a41)
{
  if (a27) {
    std::__shared_weak_count::__release_shared[abi:ne180100](a27);
  }
  if (a41 < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t std::__function::__func<ZinIrOpt::MergeIntCast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_2,std::allocator<ZinIrOpt::MergeIntCast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_2>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::target(uint64_t a1, uint64_t a2)
{
  {
    return a1 + 8;
  }
  else
  {
    return 0;
  }
}

void *std::__function::__func<ZinIrOpt::MergeIntCast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_2,std::allocator<ZinIrOpt::MergeIntCast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_2>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::target_type()
{
}

void std::__function::__func<ZinIrOpt::MergeIntCast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_2,std::allocator<ZinIrOpt::MergeIntCast(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_2>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::operator()()
{
  *(_WORD *)uint64_t v0 = 0;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "Error: Unable to merge with cast\n", v0, 2u);
}

BOOL ZinSeedUtils::ValidateHWSeeds(unsigned int *a1, uint64_t a2, uint64_t a3, unsigned int *a4)
{
  unsigned int v5 = *a1;
  unsigned int v12 = 0;
  BOOL v7 = 0;
  if (ZinSeedUtils::GenerateOrValidateLFSR113Seed(0, v5, &v12, a4))
  {
    BOOL v7 = 0;
    unint64_t v8 = 1;
    do
    {
      if (v5 != v12 || v12 == 0) {
        break;
      }
      if (v8 == 4) {
        return 1;
      }
      BOOL v7 = v8 - 1 > 2;
      unsigned int v5 = a1[v8];
      unsigned int v12 = 0;
    }
    while (ZinSeedUtils::GenerateOrValidateLFSR113Seed(v8++, v5, &v12, v6));
  }
  return v7;
}

BOOL ZinSeedUtils::GenerateOrValidateLFSR113Seed(unint64_t this, unsigned int a2, unsigned int *a3, unsigned int *a4)
{
  if (ZinSeedUtils::minimum_seed_values[this] > a2)
  {
    *a3 = 0;
    return 1;
  }
  if (this < 4)
  {
    *a3 = ((((dword_211EFDCC0[this] & a2) << dword_211EFDCD0[this]) ^ dword_211EFDCC0[this] & a2) >> dword_211EFDCE0[this]) | dword_211EFDCC0[this] & a2;
    return 1;
  }
  BOOL result = os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR);
  if (result)
  {
    ZinSeedUtils::GenerateOrValidateLFSR113Seed();
    return 0;
  }
  return result;
}

uint64_t ZinSeedUtils::CreateDeterministicSeeds(uint64_t a1, uint64_t a2)
{
  uint64_t v23 = *MEMORY[0x263EF8340];
  if (*(char *)(a1 + 23) >= 0) {
    uint64_t v4 = (const char *)a1;
  }
  else {
    uint64_t v4 = *(const char **)a1;
  }
  CC_LONG v5 = strlen(v4);
  CC_SHA512(v4, v5, (unsigned __int8 *)md);
  unint64_t v7 = 0;
  int v8 = 0;
  while (2)
  {
    unsigned int v21 = 0;
    if (!ZinSeedUtils::GenerateOrValidateLFSR113Seed(v7, md[v7], &v21, v6)) {
      return 3;
    }
    while (!v21)
    {
      if (v8 >= 10)
      {
        if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
          ZinSeedUtils::CreateDeterministicSeeds();
        }
        return 3;
      }
      std::to_string(&v18, v8 + 1);
      int v9 = *(char *)(a1 + 23);
      if (v9 >= 0) {
        uint64_t v10 = (const std::string::value_type *)a1;
      }
      else {
        uint64_t v10 = *(const std::string::value_type **)a1;
      }
      if (v9 >= 0) {
        std::string::size_type v11 = *(unsigned __int8 *)(a1 + 23);
      }
      else {
        std::string::size_type v11 = *(void *)(a1 + 8);
      }
      unsigned int v12 = std::string::insert(&v18, 0, v10, v11);
      long long v13 = *(_OWORD *)&v12->__r_.__value_.__l.__data_;
      int64_t v20 = v12->__r_.__value_.__r.__words[2];
      *(_OWORD *)std::string __p = v13;
      v12->__r_.__value_.__l.__size_ = 0;
      v12->__r_.__value_.__r.__words[2] = 0;
      v12->__r_.__value_.__r.__words[0] = 0;
      if (v20 >= 0) {
        int32x2_t v14 = __p;
      }
      else {
        int32x2_t v14 = (void **)__p[0];
      }
      CC_LONG v15 = strlen((const char *)v14);
      CC_SHA512(v14, v15, (unsigned __int8 *)md);
      if (SHIBYTE(v20) < 0) {
        operator delete(__p[0]);
      }
      if (SHIBYTE(v18.__r_.__value_.__r.__words[2]) < 0) {
        operator delete(v18.__r_.__value_.__l.__data_);
      }
      ++v8;
      if (!ZinSeedUtils::GenerateOrValidateLFSR113Seed(v7, md[v7], &v21, v16)) {
        return 3;
      }
    }
    *(_DWORD *)(a2 + 4 * v7++) = v21;
    if (v7 != 4) {
      continue;
    }
    break;
  }
  return 0;
}

void sub_2113B6418(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *a10, uint64_t a11, int a12, __int16 a13, char a14, char a15, void *__p, uint64_t a17, int a18, __int16 a19, char a20,char a21)
{
  if (a21 < 0) {
    operator delete(__p);
  }
  if (a15 < 0) {
    operator delete(a10);
  }
  _Unwind_Resume(exception_object);
}

void ZinSeedUtils::GenerateOrValidateLFSR113Seed()
{
  *(_WORD *)uint64_t v0 = 0;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "invalid seed index", v0, 2u);
}

void ZinSeedUtils::CreateDeterministicSeeds()
{
  *(_WORD *)uint64_t v0 = 0;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "Unable to find suitable random number for seed.", v0, 2u);
}

void Layer2TDMapper::LayerTracker::GetRootSourceLayerNames(Layer2TDMapper::LayerTracker *this@<X0>, void *a2@<X8>)
{
  *a2 = 0;
  a2[1] = 0;
  a2[2] = 0;
  uint64_t v2 = *(void **)this;
  uint64_t v3 = (void *)*((void *)this + 1);
  if (*(void **)this != v3)
  {
    CC_LONG v5 = 0;
    do
    {
      uint64_t v6 = (long long *)(*v2 + 24);
      if ((unint64_t)v5 >= a2[2])
      {
        CC_LONG v5 = std::vector<std::string>::__push_back_slow_path<std::string const&>((uint64_t)a2, (uint64_t)v6);
      }
      else
      {
        std::vector<std::string>::__construct_one_at_end[abi:ne180100]<std::string const&>((uint64_t)a2, v6);
        ++v5;
      }
      a2[1] = v5;
      ++v2;
    }
    while (v2 != v3);
  }
}

void sub_2113B656C(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::vector<std::string>::__destroy_vector::operator()[abi:ne180100]((void ***)va);
  _Unwind_Resume(a1);
}

uint64_t Layer2TDMapper::LayerTracker::SetOption(uint64_t result, int a2)
{
  if (!a2) {
    *(unsigned char *)(result + 88) = 1;
  }
  return result;
}

uint64_t std::vector<std::unordered_set<unsigned long>>::push_back[abi:ne180100](uint64_t *a1, uint64_t a2)
{
  unint64_t v3 = a1[1];
  if (v3 >= a1[2])
  {
    uint64_t result = std::vector<std::unordered_set<unsigned long>>::__push_back_slow_path<std::unordered_set<unsigned long> const&>(a1, a2);
  }
  else
  {
    std::unordered_set<unsigned long>::unordered_set(a1[1], a2);
    uint64_t result = v3 + 40;
    a1[1] = v3 + 40;
  }
  a1[1] = result;
  return result;
}

void sub_2113B65E8(_Unwind_Exception *a1)
{
  *(void *)(v1 + 8) = v2;
  _Unwind_Resume(a1);
}

long long *Layer2TDMapper::LayerTracker::EmptySourceIds(Layer2TDMapper::LayerTracker *this)
{
  {
    Layer2TDMapper::LayerTracker::EmptySourceIds(void)const::EMPTY_SOURCE_IDS = 0u;
    *(_OWORD *)algn_267780EB0 = 0u;
    dword_267780EC0 = 1065353216;
    __cxa_atexit((void (*)(void *))std::unordered_set<unsigned long>::~unordered_set[abi:ne180100], &Layer2TDMapper::LayerTracker::EmptySourceIds(void)const::EMPTY_SOURCE_IDS, &dword_210C72000);
  }
  return &Layer2TDMapper::LayerTracker::EmptySourceIds(void)const::EMPTY_SOURCE_IDS;
}

long long *Layer2TDMapper::LayerTracker::GetSourceLayerIds(Layer2TDMapper::LayerTracker *this, const ZinIrOpLayer *a2)
{
  uint64_t v2 = *((void *)this + 9) - *((void *)this + 8);
  if (v2
    && (uint64_t v4 = this,
        unint64_t v5 = 0xCCCCCCCCCCCCCCCDLL * (v2 >> 3),
        this = (Layer2TDMapper::LayerTracker *)ZinIrOpLayer::GetGroupId(a2),
        v5 > *(void *)this))
  {
    GroupId = (void *)ZinIrOpLayer::GetGroupId(a2);
    uint64_t v7 = *((void *)v4 + 8);
    if (0xCCCCCCCCCCCCCCCDLL * ((*((void *)v4 + 9) - v7) >> 3) <= *GroupId) {
      std::vector<ZinMirPerfTracerConfig::ConfigInfo>::__throw_out_of_range[abi:ne180100]();
    }
    return (long long *)(v7 + 40 * *GroupId);
  }
  else
  {
    Layer2TDMapper::LayerTracker::EmptySourceIds(this);
    return &Layer2TDMapper::LayerTracker::EmptySourceIds(void)const::EMPTY_SOURCE_IDS;
  }
}

void Layer2TDMapper::LayerTracker::GetRootSourceLayers(Layer2TDMapper::LayerTracker *this@<X0>, const ZinIrOpLayer *a2@<X1>, char **a3@<X8>)
{
  *a3 = 0;
  a3[1] = 0;
  a3[2] = 0;
  unint64_t v5 = (void *)*((void *)Layer2TDMapper::LayerTracker::GetSourceLayerIds(this, a2) + 2);
  if (v5)
  {
    uint64_t v6 = 0;
    uint64_t v7 = a3 + 2;
    do
    {
      uint64_t v8 = v5[2];
      uint64_t v9 = *(void *)this;
      if ((unint64_t)v6 >= *v7)
      {
        uint64_t v10 = (v6 - *a3) >> 3;
        if ((unint64_t)(v10 + 1) >> 61) {
          std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
        }
        uint64_t v11 = *v7 - (void)*a3;
        uint64_t v12 = v11 >> 2;
        if (v11 >> 2 <= (unint64_t)(v10 + 1)) {
          uint64_t v12 = v10 + 1;
        }
        if ((unint64_t)v11 >= 0x7FFFFFFFFFFFFFF8) {
          unint64_t v13 = 0x1FFFFFFFFFFFFFFFLL;
        }
        else {
          unint64_t v13 = v12;
        }
        if (v13) {
          int32x2_t v14 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)(a3 + 2), v13);
        }
        else {
          int32x2_t v14 = 0;
        }
        CC_LONG v15 = &v14[8 * v10];
        *(void *)CC_LONG v15 = *(void *)(v9 + 8 * v8);
        uint64_t v6 = v15 + 8;
        std::string::size_type v17 = *a3;
        uint64_t v16 = a3[1];
        if (v16 != *a3)
        {
          do
          {
            uint64_t v18 = *((void *)v16 - 1);
            v16 -= 8;
            *((void *)v15 - 1) = v18;
            v15 -= 8;
          }
          while (v16 != v17);
          uint64_t v16 = *a3;
        }
        *a3 = v15;
        a3[1] = v6;
        a3[2] = &v14[8 * v13];
        if (v16) {
          operator delete(v16);
        }
      }
      else
      {
        *(void *)uint64_t v6 = *(void *)(v9 + 8 * v8);
        v6 += 8;
      }
      a3[1] = v6;
      unint64_t v5 = (void *)*v5;
    }
    while (v5);
  }
}

void sub_2113B6848(_Unwind_Exception *exception_object)
{
  unint64_t v3 = *(void **)v1;
  if (*(void *)v1)
  {
    *(void *)(v1 + 8) = v3;
    operator delete(v3);
  }
  _Unwind_Resume(exception_object);
}

uint64_t std::vector<std::unordered_set<unsigned long>>::__push_back_slow_path<std::unordered_set<unsigned long> const&>(uint64_t *a1, uint64_t a2)
{
  uint64_t v3 = *a1;
  unint64_t v4 = 0xCCCCCCCCCCCCCCCDLL * ((a1[1] - *a1) >> 3);
  unint64_t v5 = v4 + 1;
  if (v4 + 1 > 0x666666666666666) {
    std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
  }
  uint64_t v7 = (uint64_t)(a1 + 2);
  unint64_t v8 = 0xCCCCCCCCCCCCCCCDLL * ((a1[2] - v3) >> 3);
  if (2 * v8 > v5) {
    unint64_t v5 = 2 * v8;
  }
  if (v8 >= 0x333333333333333) {
    unint64_t v9 = 0x666666666666666;
  }
  else {
    unint64_t v9 = v5;
  }
  std::string::size_type v17 = a1 + 2;
  if (v9) {
    uint64_t v10 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<ZinMirInterchangeInfo>>(v7, v9);
  }
  else {
    uint64_t v10 = 0;
  }
  unint64_t v13 = v10;
  int32x2_t v14 = &v10[40 * v4];
  uint64_t v16 = &v10[40 * v9];
  std::unordered_set<unsigned long>::unordered_set((uint64_t)v14, a2);
  CC_LONG v15 = v14 + 40;
  std::vector<std::unordered_map<ZinIrDimension,ZinIrDynamicOffsetPerAxisInfo>>::__swap_out_circular_buffer(a1, &v13);
  uint64_t v11 = a1[1];
  std::__split_buffer<std::unordered_map<ZinIrOpLayer *,ZinIrOpLayer *>>::~__split_buffer((uint64_t)&v13);
  return v11;
}

void sub_2113B6960(_Unwind_Exception *a1, uint64_t a2, ...)
{
  va_start(va, a2);
  std::__split_buffer<std::unordered_map<ZinIrOpLayer *,ZinIrOpLayer *>>::~__split_buffer((uint64_t)va);
  _Unwind_Resume(a1);
}

uint64_t ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(void *a1, uint64_t a2)
{
  v38[1] = *MEMORY[0x263EF8340];
  std::string::basic_string[abi:ne180100]<0>(v23, "conv");
  v24[0] = &unk_26C332AD0;
  v24[3] = v24;
  int v10 = 1;
  std::unordered_set<Attribute>::unordered_set((uint64_t)&v25, &v10, 1);
  std::string::basic_string[abi:ne180100]<0>(v26, "any_goc");
  v27[0] = &unk_26C332B28;
  v27[3] = v27;
  int v9 = 2;
  std::unordered_set<Attribute>::unordered_set((uint64_t)&v28, &v9, 1);
  std::string::basic_string[abi:ne180100]<0>(v29, "relu");
  v30[0] = &unk_26C332BD8;
  v30[3] = v30;
  int v8 = 1;
  std::unordered_set<Attribute>::unordered_set((uint64_t)&v31, &v8, 1);
  std::string::basic_string[abi:ne180100]<0>(v32, "positive_goc");
  v33[0] = &unk_26C332B80;
  v33[3] = v33;
  int v7 = 1;
  std::unordered_set<Attribute>::unordered_set((uint64_t)&v34, &v7, 1);
  uint64_t v11 = 0;
  uint64_t v12 = 0;
  unint64_t v13 = 0;
  uint64_t v18 = &v11;
  v19[0] = 0;
  uint64_t v11 = (char *)operator new(0x180uLL);
  uint64_t v12 = (uint64_t)v11;
  unint64_t v13 = v11 + 384;
  uint64_t v12 = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<ZinLinearPattern::AtomItemDesc>,ZinLinearPattern::AtomItemDesc const*,ZinLinearPattern::AtomItemDesc const*,ZinLinearPattern::AtomItemDesc*>((uint64_t)&v13, (uint64_t)v23, (uint64_t)v35, (uint64_t)v11);
  v22[3] = 0;
  ZinLinearPattern::ZinLinearPattern(v35, &v11, a2, 0, v22, 0);
  std::allocate_shared[abi:ne180100]<ZinLinearPattern,std::allocator<ZinLinearPattern>,ZinLinearPattern,void>((uint64_t)v35, &v14);
  long long v37 = v14;
  long long v14 = 0uLL;
  uint64_t v16 = 0;
  std::string::size_type v17 = 0;
  CC_LONG v15 = 0;
  uint64_t v18 = (char **)&v15;
  v19[0] = 0;
  CC_LONG v15 = operator new(0x10uLL);
  uint64_t v16 = v15;
  std::string::size_type v17 = v15 + 2;
  uint64_t v16 = std::__uninitialized_allocator_copy_impl[abi:ne180100]<std::allocator<std::shared_ptr<ZinPattern>>,std::shared_ptr<ZinPattern> const*,std::shared_ptr<ZinPattern> const*,std::shared_ptr<ZinPattern>*>((uint64_t)&v17, &v37, v38, v15);
  if (*((void *)&v37 + 1)) {
    std::__shared_weak_count::__release_shared[abi:ne180100](*((std::__shared_weak_count **)&v37 + 1));
  }
  if (*((void *)&v14 + 1)) {
    std::__shared_weak_count::__release_shared[abi:ne180100](*((std::__shared_weak_count **)&v14 + 1));
  }
  v35[0] = &unk_26C349BA8;
  uint64_t v18 = (char **)&v36;
  std::vector<ZinLinearPattern::AtomItemDesc>::__destroy_vector::operator()[abi:ne180100]((void ***)&v18);
  ZinPattern::~ZinPattern((ZinPattern *)v35);
  std::__function::__value_func<BOOL ()(ZinIrOpLayerGraph const*,ZinIrParameters const&,ZinPattern const*)>::~__value_func[abi:ne180100](v22);
  uint64_t v18 = &v11;
  std::vector<ZinLinearPattern::AtomItemDesc>::__destroy_vector::operator()[abi:ne180100]((void ***)&v18);
  unint64_t v4 = 48;
  do
  {
    std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)&v22[v4 - 1]);
    std::__function::__value_func<MatchStatus ()(MatchParams const&)>::~__value_func[abi:ne180100](&v19[v4 * 8]);
    if ((char)v19[v4 * 8 - 1] < 0) {
      operator delete((&v17)[v4]);
    }
    v4 -= 12;
  }
  while (v4 * 8);
  v20[0] = &unk_26C332C30;
  v20[1] = &v15;
  unsigned int v21 = v20;
  uint64_t v5 = ZinIrControlFlowGraph::TraverseForward(a1, (uint64_t)v20, 1);
  std::__function::__value_func<ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::~__value_func[abi:ne180100](v20);
  v23[0] = (void **)&v15;
  std::vector<std::shared_ptr<ZinIrTransform>>::__destroy_vector::operator()[abi:ne180100](v23);
  return v5;
}

void sub_2113B6CE4(_Unwind_Exception *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,void **a31)
{
}

void sub_2113B6DD8(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, uint64_t a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,uint64_t a23,uint64_t a24,uint64_t a25,uint64_t a26,uint64_t a27,uint64_t a28,uint64_t a29,uint64_t a30,char a31)
{
}

void sub_2113B6DE8()
{
}

uint64_t ZinIrOpt::ActivationWithSingularScaleGOC(ZinIrOpt *this, ZinIrOpLayerGraph *a2, ZinIrOpLayer *a3)
{
  unint64_t v84 = a2;
  if (*(_DWORD *)(*((void *)a2 + 8) + 8) != 4
    || ZinIrOpLayer::IsTensorFmtQuantized(a2)
    || *((void *)a2 + 15) - *((void *)a2 + 14) != 8
    || !ZinActivationLayer::HasEligibleModeToMergeWithScale(a2, 1.0))
  {
    return 0;
  }
  uint64_t v83 = 0;
  uint64_t v5 = (void *)((char *)this + 24);
  *(void *)&v89[0] = &v84;
  uint64_t v6 = std::__hash_table<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::__unordered_map_hasher<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::__unordered_map_equal<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>>>::find<std::reference_wrapper<ZinIrOpLayer * const>>((void *)this + 3, (unint64_t **)v89);
  int v7 = (ZinIrOpLayer ****)(v6 + 3);
  if (!v6) {
    int v7 = (ZinIrOpLayer ****)((char *)this + 104);
  }
  uint64_t v83 = ***v7;
  int v8 = v84;
  int v9 = operator new(8uLL);
  __p[0] = v9;
  *int v9 = v8;
  __p[1] = v9 + 1;
  v82[0] = v9 + 1;
  if (*((void *)v8 + 15) - *((void *)v8 + 14) != 8)
  {
LABEL_120:
    uint64_t v71 = 0;
    goto LABEL_121;
  }
  char v10 = 0;
  float v11 = 1.0;
  uint64_t v12 = &_os_log_internal;
  do
  {
    unint64_t v13 = v83;
    if (!v83) {
      break;
    }
    if (*(_DWORD *)(*((void *)v83 + 8) + 8) != 2) {
      break;
    }
    Hal = ZinIrTarget::GetHal(*((uint64_t **)v83 + 2), *(ZinIrTarget **)(*((void *)v83 + 2) + 160));
    uint64_t v15 = (*(uint64_t (**)(uint64_t *))(*Hal + 16))(Hal);
    if (!*((void *)v13 + 17)
      || !ZinIrKernel::HasNoBiasNoWeightButSingularScale(*((ZinIrKernel **)v13 + 17), *(unsigned __int8 *)(v15 + 1244)))
    {
      break;
    }
    uint64_t v16 = v83;
    int HasScale = ZinIrKernel::HasScale(*((ZinIrKernel **)v83 + 17));
    float SingularVal = 1.0;
    if (HasScale) {
      float SingularVal = ZinIrVector::GetSingularVal(*(ZinIrVector **)(*((void *)v16 + 17) + 568));
    }
    float v11 = v11 * SingularVal;
    if (ZinActivationLayer::HasEligibleModeToMergeWithScale(a2, v11))
    {
      uint64_t v19 = (*(uint64_t (**)(ZinIrOpLayerGraph *, void, void))(*(void *)v84 + 32))(v84, 0, 0);
      *(_DWORD *)(v19 + 88) = *(_DWORD *)((*(uint64_t (**)(ZinIrOpLayer *, void, void))(*(void *)v16 + 32))(v16, 0, 0)+ 88);
      *(float *)&double v20 = ZinActivationLayer::FuseIntoPostScale(a2, v11);
      unsigned int v21 = (char *)__p[1];
      if (__p[1] >= (void *)v82[0])
      {
        int64_t v29 = ((char *)__p[1] - (char *)__p[0]) >> 3;
        if ((unint64_t)(v29 + 1) >> 61) {
LABEL_127:
        }
          std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
        unint64_t v30 = (uint64_t)(v82[0] - (unint64_t)__p[0]) >> 2;
        if (v30 <= v29 + 1) {
          unint64_t v30 = v29 + 1;
        }
        if (v82[0] - (unint64_t)__p[0] >= 0x7FFFFFFFFFFFFFF8) {
          unint64_t v31 = 0x1FFFFFFFFFFFFFFFLL;
        }
        else {
          unint64_t v31 = v30;
        }
        if (v31) {
          uint64_t v32 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)v82, v31);
        }
        else {
          uint64_t v32 = 0;
        }
        std::locale v39 = (ZinIrOpLayer **)&v32[8 * v29];
        *std::locale v39 = v83;
        std::string v22 = v39 + 1;
        int v41 = (char *)__p[0];
        long long v40 = (char *)__p[1];
        if (__p[1] != __p[0])
        {
          do
          {
            uint64_t v42 = (ZinIrOpLayer *)*((void *)v40 - 1);
            v40 -= 8;
            *--std::locale v39 = v42;
          }
          while (v40 != v41);
          long long v40 = (char *)__p[0];
        }
        __p[0] = v39;
        __p[1] = v22;
        v82[0] = &v32[8 * v31];
        if (v40) {
          operator delete(v40);
        }
      }
      else
      {
        *(void *)__p[1] = v83;
        std::string v22 = v21 + 8;
      }
      uint64_t v43 = 0;
      __p[1] = v22;
      uint64_t v45 = (uint64_t **)v83;
      uint64_t v44 = v84;
      uint64_t v91 = 0;
      uint64_t v92 = 0;
      v93[0] = 0;
      long long v46 = (uint64_t ***)*((void *)v84 + 14);
      while (1)
      {
        std::vector<char> v47 = *v46;
        if (*v46 == v45) {
          break;
        }
        if ((unint64_t)v43 >= v93[0])
        {
          uint64_t v48 = v43 - v91;
          if ((unint64_t)(v48 + 1) >> 61) {
            goto LABEL_126;
          }
          unint64_t v49 = (uint64_t)(v93[0] - (void)v91) >> 2;
          if (v49 <= v48 + 1) {
            unint64_t v49 = v48 + 1;
          }
          if (v93[0] - (void)v91 >= 0x7FFFFFFFFFFFFFF8uLL) {
            unint64_t v50 = 0x1FFFFFFFFFFFFFFFLL;
          }
          else {
            unint64_t v50 = v49;
          }
          if (v50) {
            uint64_t v51 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)v93, v50);
          }
          else {
            uint64_t v51 = 0;
          }
          uint64_t v52 = (uint64_t ***)&v51[8 * v48];
          *uint64_t v52 = v47;
          uint64_t v43 = v52 + 1;
          long long v54 = v91;
          uint64_t v53 = v92;
          if (v92 != v91)
          {
            do
            {
              int64x2_t v55 = *--v53;
              *--uint64_t v52 = v55;
            }
            while (v53 != v54);
            uint64_t v53 = v91;
          }
          uint64_t v91 = v52;
          uint64_t v92 = v43;
          v93[0] = &v51[8 * v50];
          if (v53) {
            operator delete(v53);
          }
        }
        else
        {
          *v43++ = v47;
        }
        uint64_t v92 = v43;
        long long v46 = (uint64_t ***)v47[14];
        if ((char *)v47[15] - (char *)v46 != 8) {
          ZinAssertImpl("Unexpected number of outgoing layers", v20);
        }
      }
      if ((unint64_t)v43 >= v93[0])
      {
        uint64_t v57 = v43 - v91;
        if ((unint64_t)(v57 + 1) >> 61) {
LABEL_126:
        }
          std::vector<std::pair<unsigned long,unsigned long>>::__throw_length_error[abi:ne180100]();
        unint64_t v58 = (uint64_t)(v93[0] - (void)v91) >> 2;
        if (v58 <= v57 + 1) {
          unint64_t v58 = v57 + 1;
        }
        if (v93[0] - (void)v91 >= 0x7FFFFFFFFFFFFFF8uLL) {
          unint64_t v59 = 0x1FFFFFFFFFFFFFFFLL;
        }
        else {
          unint64_t v59 = v58;
        }
        if (v59) {
          int64x2_t v60 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)v93, v59);
        }
        else {
          int64x2_t v60 = 0;
        }
        uint64_t v61 = (uint64_t ***)&v60[8 * v57];
        *uint64_t v61 = v45;
        int64x2_t v56 = v61 + 1;
        uint64_t v63 = v91;
        uint64_t v62 = v92;
        if (v92 != v91)
        {
          do
          {
            uint64_t v64 = *--v62;
            *--uint64_t v61 = v64;
          }
          while (v62 != v63);
          uint64_t v62 = v91;
        }
        uint64_t v91 = v61;
        uint64_t v92 = v56;
        v93[0] = &v60[8 * v59];
        if (v62) {
          operator delete(v62);
        }
      }
      else
      {
        *uint64_t v43 = v45;
        int64x2_t v56 = v43 + 1;
      }
      uint64_t v92 = v56;
      memset(v89, 0, sizeof(v89));
      int v90 = 1065353216;
      int v65 = ZinIrOpLayerGraph::MoveOutgoingEdges(this, v45, v44, v89);
      std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v89);
      uint64_t v5 = (void *)((char *)this + 24);
      if (v65)
      {
        uint64_t v66 = (ZinIrOpLayer **)v92;
        if (v91 != v92)
        {
          do
          {
            if (!ZinIrOpLayerGraph::RemoveNode(this, *(v66 - 1), 0) && os_log_type_enabled(v12, OS_LOG_TYPE_ERROR)) {
              ZinIrOpt::ActivationWithSingularScaleGOC(&v85, v86);
            }
            uint64_t v66 = (ZinIrOpLayer **)(v92 - 1);
            uint64_t v92 = (uint64_t ***)v66;
          }
          while (v91 != (uint64_t ***)v66);
          int v67 = 0;
          goto LABEL_100;
        }
        int v67 = 0;
        uint64_t v66 = (ZinIrOpLayer **)v91;
        if (v91) {
          goto LABEL_100;
        }
      }
      else
      {
        if (os_log_type_enabled(v12, OS_LOG_TYPE_ERROR)) {
          MirOpt::MergeGOCsToConvs(&buf, v88);
        }
        int v67 = 3;
        uint64_t v66 = (ZinIrOpLayer **)v91;
        if (v91)
        {
LABEL_100:
          uint64_t v92 = (uint64_t ***)v66;
          operator delete(v66);
        }
      }
      if (v67) {
        goto LABEL_125;
      }
      *(void *)&v89[0] = &v84;
      std::string v68 = std::__hash_table<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::__unordered_map_hasher<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::__unordered_map_equal<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>>>::find<std::reference_wrapper<ZinIrOpLayer * const>>((void *)this + 3, (unint64_t **)v89);
      long long v69 = (ZinIrOpLayer ****)(v68 + 3);
      if (!v68) {
        long long v69 = (ZinIrOpLayer ****)((char *)this + 104);
      }
      uint64_t v70 = ***v69;
      uint64_t v83 = v70;
      float v11 = 1.0;
      if (v70 && ZinIrOpLayer::IsTensorFmtQuantized(v70)) {
        goto LABEL_112;
      }
      char v10 = 1;
      continue;
    }
    uint64_t v23 = (char *)__p[1];
    if (__p[1] >= (void *)v82[0])
    {
      int64_t v25 = ((char *)__p[1] - (char *)__p[0]) >> 3;
      if ((unint64_t)(v25 + 1) >> 61) {
        goto LABEL_127;
      }
      unint64_t v26 = (uint64_t)(v82[0] - (unint64_t)__p[0]) >> 2;
      if (v26 <= v25 + 1) {
        unint64_t v26 = v25 + 1;
      }
      if (v82[0] - (unint64_t)__p[0] >= 0x7FFFFFFFFFFFFFF8) {
        unint64_t v27 = 0x1FFFFFFFFFFFFFFFLL;
      }
      else {
        unint64_t v27 = v26;
      }
      if (v27) {
        uint64_t v28 = (char *)std::__allocate_at_least[abi:ne180100]<std::allocator<double>>((uint64_t)v82, v27);
      }
      else {
        uint64_t v28 = 0;
      }
      unsigned __int8 v33 = (ZinIrOpLayer **)&v28[8 * v25];
      *unsigned __int8 v33 = v83;
      uint64_t v24 = v33 + 1;
      uint64_t v35 = (char *)__p[0];
      uint64_t v34 = (char *)__p[1];
      if (__p[1] != __p[0])
      {
        do
        {
          uint64_t v36 = (ZinIrOpLayer *)*((void *)v34 - 1);
          v34 -= 8;
          *--unsigned __int8 v33 = v36;
        }
        while (v34 != v35);
        uint64_t v34 = (char *)__p[0];
      }
      __p[0] = v33;
      __p[1] = v24;
      v82[0] = &v28[8 * v27];
      if (v34) {
        operator delete(v34);
      }
    }
    else
    {
      *(void *)__p[1] = v83;
      uint64_t v24 = v23 + 8;
    }
    __p[1] = v24;
    *(void *)&v89[0] = &v83;
    long long v37 = std::__hash_table<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::__unordered_map_hasher<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::__unordered_map_equal<std::reference_wrapper<ZinIrOpLayer * const>,std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>,std::equal_to<std::reference_wrapper<ZinIrOpLayer * const>>,std::hash<std::reference_wrapper<ZinIrOpLayer * const>>,true>,std::allocator<std::__hash_value_type<std::reference_wrapper<ZinIrOpLayer * const>,std::vector<std::reference_wrapper<ZinIrOpLayer * const>>>>>::find<std::reference_wrapper<ZinIrOpLayer * const>>(v5, (unint64_t **)v89);
    uint64_t v38 = (ZinIrOpLayer ****)(v37 + 3);
    if (!v37) {
      uint64_t v38 = (ZinIrOpLayer ****)((char *)this + 104);
    }
    uint64_t v83 = ***v38;
    if (*((void *)v83 + 15) - *((void *)v83 + 14) != 8) {
      goto LABEL_120;
    }
  }
  while (*((void *)v84 + 15) - *((void *)v84 + 14) == 8);
  if ((v10 & 1) == 0) {
    goto LABEL_120;
  }
LABEL_112:
  uint64_t v73 = (uint64_t *)(*(uint64_t (**)(ZinIrOpLayerGraph *, void, void))(*(void *)a2 + 40))(a2, 0, 0);
  int v74 = (std::__shared_weak_count *)v73[1];
  uint64_t v79 = *v73;
  uint64_t v80 = v74;
  if (v74) {
    atomic_fetch_add_explicit(&v74->__shared_owners_, 1uLL, memory_order_relaxed);
  }
  uint64_t v75 = (ZinIrOpLayer *)(*(uint64_t (**)(ZinIrOpLayerGraph *, uint64_t *, char *))(*(void *)a2 + 176))(a2, &v79, (char *)a2 + 24);
  if (v80) {
    std::__shared_weak_count::__release_shared[abi:ne180100](v80);
  }
  *(void *)&v89[0] = &unk_26C359A08;
  *(_OWORD *)((char *)v89 + 8) = *(_OWORD *)__p;
  *((void *)&v89[1] + 1) = v82[0];
  __p[0] = 0;
  __p[1] = 0;
  v82[0] = 0;
  ZinIrOpLayerGraph::AddNode((uint64_t **)this, v75, (ZinIrOpLayer ***)v89);
  *(void *)&v89[0] = &unk_26C359A08;
  if (*((void *)&v89[0] + 1))
  {
    *(void *)&v89[1] = *((void *)&v89[0] + 1);
    operator delete(*((void **)&v89[0] + 1));
  }
  ZinIrOpLayerGraph::MoveIncomingEdges(this, a2, v75);
  memset(v77, 0, sizeof(v77));
  int v78 = 1065353216;
  char v76 = ZinIrOpLayerGraph::MoveOutgoingEdges(this, (uint64_t **)a2, v75, v77);
  std::__hash_table<unsigned int,std::hash<unsigned int>,std::equal_to<unsigned int>,std::allocator<unsigned int>>::~__hash_table((uint64_t)v77);
  if (v76)
  {
    ZinIrOpLayerGraph::RemoveNode(this, a2, 0);
    uint64_t v71 = 0;
    goto LABEL_121;
  }
  if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
    MirOpt::MergeGOCsToConvs();
  }
LABEL_125:
  uint64_t v71 = 3;
LABEL_121:
  if (__p[0])
  {
    __p[1] = __p[0];
    operator delete(__p[0]);
  }
  return v71;
}

void sub_2113B763C(_Unwind_Exception *a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14, char a15, uint64_t a16, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20,uint64_t a21,uint64_t a22,void *__p,uint64_t a24)
{
  if (__p)
  {
    a24 = (uint64_t)__p;
    operator delete(__p);
  }
  _Unwind_Resume(a1);
}

void std::__function::__func<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0,std::allocator<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0>,MatchStatus ()(MatchParams const&)>::~__func()
{
}

void *std::__function::__func<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0,std::allocator<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0>,MatchStatus ()(MatchParams const&)>::__clone()
{
  uint64_t result = operator new(0x10uLL);
  *uint64_t result = &unk_26C332AD0;
  return result;
}

void std::__function::__func<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0,std::allocator<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0>,MatchStatus ()(MatchParams const&)>::__clone(uint64_t a1, void *a2)
{
  *a2 = &unk_26C332AD0;
}

uint64_t std::__function::__func<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0,std::allocator<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0>,MatchStatus ()(MatchParams const&)>::operator()(uint64_t a1, uint64_t a2)
{
  return (*(_DWORD *)(*(void *)(*(void *)(a2 + 8) + 64) + 8) == 0) | 0x100u;
}

uint64_t std::__function::__func<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0,std::allocator<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0>,MatchStatus ()(MatchParams const&)>::target(uint64_t a1, uint64_t a2)
{
  {
    return a1 + 8;
  }
  else
  {
    return 0;
  }
}

void *std::__function::__func<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0,std::allocator<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_0>,MatchStatus ()(MatchParams const&)>::target_type()
{
}

void std::__function::__func<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1,std::allocator<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1>,MatchStatus ()(MatchParams const&)>::~__func()
{
}

void *std::__function::__func<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1,std::allocator<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1>,MatchStatus ()(MatchParams const&)>::__clone()
{
  uint64_t result = operator new(0x10uLL);
  *uint64_t result = &unk_26C332B28;
  return result;
}

void std::__function::__func<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1,std::allocator<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1>,MatchStatus ()(MatchParams const&)>::__clone(uint64_t a1, void *a2)
{
  *a2 = &unk_26C332B28;
}

uint64_t std::__function::__func<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1,std::allocator<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1>,MatchStatus ()(MatchParams const&)>::operator()(uint64_t a1, uint64_t a2)
{
  return (*(_DWORD *)(*(void *)(*(void *)(a2 + 8) + 64) + 8) == 2) | 0x100u;
}

uint64_t std::__function::__func<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1,std::allocator<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1>,MatchStatus ()(MatchParams const&)>::target(uint64_t a1, uint64_t a2)
{
  {
    return a1 + 8;
  }
  else
  {
    return 0;
  }
}

void *std::__function::__func<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1,std::allocator<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_1>,MatchStatus ()(MatchParams const&)>::target_type()
{
}

void std::__function::__func<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_3,std::allocator<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_3>,MatchStatus ()(MatchParams const&)>::~__func()
{
}

void *std::__function::__func<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_3,std::allocator<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_3>,MatchStatus ()(MatchParams const&)>::__clone()
{
  uint64_t result = operator new(0x10uLL);
  *uint64_t result = &unk_26C332BD8;
  return result;
}

void std::__function::__func<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_3,std::allocator<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_3>,MatchStatus ()(MatchParams const&)>::__clone(uint64_t a1, void *a2)
{
  *a2 = &unk_26C332BD8;
}

uint64_t std::__function::__func<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_3,std::allocator<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_3>,MatchStatus ()(MatchParams const&)>::operator()(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = *(void *)(a2 + 8);
  BOOL v3 = *(_DWORD *)(*(void *)(v2 + 64) + 8) == 4
    && *(_DWORD *)(v2 + 192) == 1
    && *(_DWORD *)((*(uint64_t (**)(uint64_t, void, void))(*(void *)v2 + 32))(v2, 0, 0) + 88) == 3;
  return v3 | 0x100u;
}

uint64_t std::__function::__func<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_3,std::allocator<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_3>,MatchStatus ()(MatchParams const&)>::target(uint64_t a1, uint64_t a2)
{
  {
    return a1 + 8;
  }
  else
  {
    return 0;
  }
}

void *std::__function::__func<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_3,std::allocator<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_3>,MatchStatus ()(MatchParams const&)>::target_type()
{
}

void std::__function::__func<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_2,std::allocator<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_2>,MatchStatus ()(MatchParams const&)>::~__func()
{
}

void *std::__function::__func<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_2,std::allocator<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_2>,MatchStatus ()(MatchParams const&)>::__clone()
{
  uint64_t result = operator new(0x10uLL);
  *uint64_t result = &unk_26C332B80;
  return result;
}

void std::__function::__func<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_2,std::allocator<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_2>,MatchStatus ()(MatchParams const&)>::__clone(uint64_t a1, void *a2)
{
  *a2 = &unk_26C332B80;
}

uint64_t std::__function::__func<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_2,std::allocator<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_2>,MatchStatus ()(MatchParams const&)>::operator()(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = *(void **)(a2 + 8);
  if (*(_DWORD *)(v2[8] + 8) == 2
    && *(_DWORD *)((*(uint64_t (**)(void *, void, void))(*v2 + 32))(v2, 0, 0) + 88) == 3
    && ZinGOCLayer::IsSingularScaleBias(*(ZinGOCLayer **)(a2 + 8)))
  {
    float v9 = 0.0;
    signed __int8 v8 = 0;
    ZinGOCLayer::GetSingularScale(*(ZinGOCLayer **)(a2 + 8), &v9, &v8);
    float v7 = 0.0;
    signed __int8 v6 = 0;
    ZinGOCLayer::GetSingularBias(*(ZinGOCLayer **)(a2 + 8), &v7, &v6);
    BOOL v4 = v9 > 0.0;
    if (v7 != 0.0) {
      BOOL v4 = 0;
    }
  }
  else
  {
    BOOL v4 = 0;
  }
  return v4 | 0x100u;
}

uint64_t std::__function::__func<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_2,std::allocator<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_2>,MatchStatus ()(MatchParams const&)>::target(uint64_t a1, uint64_t a2)
{
  {
    return a1 + 8;
  }
  else
  {
    return 0;
  }
}

void *std::__function::__func<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_2,std::allocator<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_2>,MatchStatus ()(MatchParams const&)>::target_type()
{
}

void std::__function::__func<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_4,std::allocator<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_4>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::~__func()
{
}

void *std::__function::__func<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_4,std::allocator<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_4>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::__clone(uint64_t a1)
{
  uint64_t result = operator new(0x10uLL);
  uint64_t v3 = *(void *)(a1 + 8);
  *uint64_t result = &unk_26C332C30;
  result[1] = v3;
  return result;
}

uint64_t std::__function::__func<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_4,std::allocator<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_4>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::__clone(uint64_t result, void *a2)
{
  uint64_t v2 = *(void *)(result + 8);
  *a2 = &unk_26C332C30;
  a2[1] = v2;
  return result;
}

uint64_t std::__function::__func<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_4,std::allocator<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_4>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::operator()(uint64_t a1, ZinIrOpLayerGraph **a2, uint64_t *a3)
{
  uint64_t v3 = *(uint64_t ***)(a1 + 8);
  BOOL v4 = *v3;
  uint64_t v5 = v3[1];
  if (*v3 == v5) {
    return 0;
  }
  signed __int8 v6 = *a2;
  uint64_t v7 = *a3;
  while (1)
  {
    if ((*(unsigned int (**)(uint64_t, ZinIrOpLayerGraph *, uint64_t))(*(void *)*v4 + 8))(*v4, v6, v7))
    {
      uint64_t v8 = *v4;
      std::string::basic_string[abi:ne180100]<0>(__p, "relu");
      uint64_t SingleMatch = (ZinIrOpLayer *)ZinPattern::GetSingleMatch(v8, (unsigned __int8 *)__p);
      if (v14 < 0) {
        operator delete(__p[0]);
      }
      uint64_t v10 = *v4;
      std::string::basic_string[abi:ne180100]<0>(__p, "positive_goc");
      float v11 = (ZinIrOpLayer *)ZinPattern::GetSingleMatch(v10, (unsigned __int8 *)__p);
      if (v14 < 0) {
        operator delete(__p[0]);
      }
      if ((ZinIrOpLayerGraph::SwapNodes(v6, SingleMatch, v11) & 1) == 0) {
        break;
      }
    }
    v4 += 2;
    if (v4 == v5) {
      return 0;
    }
  }
  return 3;
}

void sub_2113B7D18(_Unwind_Exception *exception_object, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, void *__p, uint64_t a11, int a12, __int16 a13, char a14, char a15)
{
  if (a15 < 0) {
    operator delete(__p);
  }
  _Unwind_Resume(exception_object);
}

uint64_t std::__function::__func<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_4,std::allocator<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_4>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::target(uint64_t a1, uint64_t a2)
{
  {
    return a1 + 8;
  }
  else
  {
    return 0;
  }
}

void *std::__function::__func<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_4,std::allocator<ZinIrOpt::ZinIrOptSwapReluSingularScalePositive(ZinIrControlFlowGraph *,ZinIrParameters const&)::$_4>,ZinIrStatus ()(ZinIrOpLayerGraph *,ZinIrOpLayer *)>::target_type()
{
}

void ZinIrOpt::ActivationWithSingularScaleGOC(uint8_t *buf, unsigned char *a2)
{
  *uint8_t buf = 0;
  *a2 = 0;
  _os_log_error_impl(&dword_210C72000, &_os_log_internal, OS_LOG_TYPE_ERROR, "Failed in removing node.\n", buf, 2u);
}

uint64_t MirOpt::CpBasedCWTransposeUtil::TransposerWrapper(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  if (!MirOpt::CpBasedCWTransposeUtil::TransposerWrapper(std::unique_ptr<CpTransposeGraph> &,std::unordered_set<unsigned long long> const&,std::string const&,CpTransposeUtils::CpTransposeOptimizationResult &)::dlhandle)
  {
    uint64_t v10 = dlopen("/System/Library/PrivateFrameworks/ANECompiler.framework/libORTools.dylib", 10);
    MirOpt::CpBasedCWTransposeUtil::TransposerWrapper(std::unique_ptr<CpTransposeGraph> &,std::unordered_set<unsigned long long> const&,std::string const&,CpTransposeUtils::CpTransposeOptimizationResult &)::dlhandle = (uint64_t)v10;
    if (v10)
    {
      uint64_t v8 = dlsym(v10, "ORToolsCpBasedTransposerUtil_CallCpTransposer");
      MirOpt::CpBasedCWTransposeUtil::TransposerWrapper(std::unique_ptr<CpTransposeGraph> &,std::unordered_set<unsigned long long> const&,std::string const&,CpTransposeUtils::CpTransposeOptimizationResult &)::dlfunCC_SHA256_CTX c = v8;
      if (v8) {
        goto LABEL_3;
      }
      float v11 = dlerror();
      if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
        MirOpt::CpBasedCWTransposeUtil::TransposerWrapper(v11);
      }
      if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
        MirOpt::CpBasedCWTransposeUtil::TransposerWrapper();
      }
    }
    else
    {
      uint64_t v12 = dlerror();
      if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
        MirOpt::CpBasedCWTransposeUtil::TransposerWrapper(v12);
      }
      if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
        MirOpt::CpBasedCWTransposeUtil::TransposerWrapper();
      }
    }
    return 0;
  }
  uint64_t v8 = MirOpt::CpBasedCWTransposeUtil::TransposerWrapper(std::unique_ptr<CpTransposeGraph> &,std::unordered_set<unsigned long long> const&,std::string const&,CpTransposeUtils::CpTransposeOptimizationResult &)::dlfunc;
LABEL_3:

  return ((uint64_t (*)(uint64_t, uint64_t, uint64_t, uint64_t))v8)(a1, a2, a3, a4);
}

uint64_t ZinCpBasedAllocatorUtil::AllocatorWrapper(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  if (!ZinCpBasedAllocatorUtil::AllocatorWrapper(CpAllocGraph *,std::unordered_map<unsigned long long,CpAllocUtils::AllocationType> const&,unsigned long,std::string const&,std::unordered_map<unsigned long long,CpAllocUtils::AllocationType>&)::dlhandle)
  {
    uint64_t v12 = dlopen("/System/Library/PrivateFrameworks/ANECompiler.framework/libORTools.dylib", 10);
    ZinCpBasedAllocatorUtil::AllocatorWrapper(CpAllocGraph *,std::unordered_map<unsigned long long,CpAllocUtils::AllocationType> const&,unsigned long,std::string const&,std::unordered_map<unsigned long long,CpAllocUtils::AllocationType>&)::dlhandle = (uint64_t)v12;
    if (v12)
    {
      uint64_t v10 = dlsym(v12, "ORToolsCpBasedAllocatorUtil_CallCpAllocator");
      ZinCpBasedAllocatorUtil::AllocatorWrapper(CpAllocGraph *,std::unordered_map<unsigned long long,CpAllocUtils::AllocationType> const&,unsigned long,std::string const&,std::unordered_map<unsigned long long,CpAllocUtils::AllocationType>&)::dlfunCC_SHA256_CTX c = v10;
      if (v10) {
        goto LABEL_3;
      }
      unint64_t v13 = dlerror();
      if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
        MirOpt::CpBasedCWTransposeUtil::TransposerWrapper(v13);
      }
      if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
        MirOpt::CpBasedCWTransposeUtil::TransposerWrapper();
      }
    }
    else
    {
      char v14 = dlerror();
      if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
        MirOpt::CpBasedCWTransposeUtil::TransposerWrapper(v14);
      }
      if (os_log_type_enabled(&_os_log_internal, OS_LOG_TYPE_ERROR)) {
        MirOpt::CpBasedCWTransposeUtil::TransposerWrapper();
      }
    }
    return 0;
  }
  uint64_t v10 = ZinCpBasedAllocatorUtil::AllocatorWrapper(CpAllocGraph *,std::unordered_map<unsigned long long,CpAllocUtils::AllocationType> const&,unsigned long,std::string const&,std::unordered_map<unsigned long long,CpAllocUtils::AllocationType>&)::dlfunc;
LABEL_3:

  return ((uint64_t (*)(uint64_t, uint64_t, uint64_t, uint64_t, uint64_t))v10)(a1, a2, a3, a4, a5);
}

uint64_t mlir::MemoryMapperInterface::canMapOperands(mlir::MemoryMapperInterface *this)
{
  return (**((uint64_t (***)(void, void))this + 1))(*((void *)this + 1), *(void *)this);
}

uint64_t mlir::MemoryMapperInterface::getOperandRange(mlir::MemoryMapperInterface *this)
{
  return (*(uint64_t (**)(void, void))(*((void *)this + 1) + 8))(*((void *)this + 1), *(void *)this);
}

void mlir::detail::AllocRange::getRangeForValue(_DWORD *a1@<X0>, unint64_t a2@<X1>, uint64_t a3@<X8>)
{
  v59[4] = *MEMORY[0x263EF8340];
  unint64_t v50 = a1;
  BOOL v5 = (~a1[2] & 7) == 0 && mlir::detail::AllocRange::allocBlockArgs == 0;
  if (v5
    || (uint64_t v57 = a1, (DefiningOp = mlir::Value::getDefiningOp((mlir::Value *)&v57)) != 0)
    && (uint64_t v8 = DefiningOp,
        uint64_t v9 = mlir::TypeID::get<mlir::OpTrait::ConstantLike<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::ConstantLike>(void)::Empty>>(),
        (*(unsigned int (**)(void, uint64_t))(**(void **)(v8 + 48) + 32))(*(void *)(v8 + 48), v9)))
  {
    *(void *)a3 = a1;
LABEL_8:
    *(void *)&long long v10 = -1;
    *((void *)&v10 + 1) = -1;
    *(_OWORD *)(a3 + 8) = v10;
    *(_OWORD *)(a3 + 24) = v10;
    return;
  }
  if (*(_UNKNOWN **)(*(void *)(*((void *)a1 + 1) & 0xFFFFFFFFFFFFFFF8) + 136) == &mlir::detail::TypeIDResolver<mlir::MemRefType,void>::id) {
    float v11 = (void **)(*((void *)a1 + 1) & 0xFFFFFFFFFFFFFFF8);
  }
  else {
    float v11 = 0;
  }
  if (!v11)
  {
    *(void *)a3 = 0;
    goto LABEL_8;
  }
  if ((unint64_t)mlir::detail::AllocRange::minimumAlignment <= 1) {
    uint64_t v12 = 1;
  }
  else {
    uint64_t v12 = mlir::detail::AllocRange::minimumAlignment;
  }
  uint64_t v48 = 0;
  uint64_t v49 = v12;
  if (mlir::matchThrough<mlir::MinimumAlignmentInterface,mlir::MemoryMapperInterface>((uint64_t)a1, &v48))
  {
    uint64_t InterfaceFor = mlir::Value::getDefiningOp((mlir::Value *)&v48);
    char v14 = (void *)InterfaceFor;
    if (InterfaceFor)
    {
      uint64_t InterfaceFor = mlir::OpInterface<mlir::MinimumAlignmentInterface,mlir::detail::MinimumAlignmentInterfaceInterfaceTraits>::getInterfaceFor(InterfaceFor);
      if (InterfaceFor) {
        uint64_t InterfaceFor = mlir::OpInterface<mlir::MinimumAlignmentInterface,mlir::detail::MinimumAlignmentInterfaceInterfaceTraits>::getInterfaceFor((uint64_t)v14);
      }
      else {
        char v14 = 0;
      }
    }
    uint64_t v57 = v14;
    uint64_t v58 = InterfaceFor;
    uint64_t OperandRange = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&v57);
    if (v12 >= 0) {
      uint64_t v16 = v12;
    }
    else {
      uint64_t v16 = -v12;
    }
    LODWORD(v56) = 64;
    int64x2_t v55 = (void **)v16;
    if (OperandRange >= 0) {
      uint64_t v17 = OperandRange;
    }
    else {
      uint64_t v17 = -OperandRange;
    }
    unsigned int v52 = 64;
    uint64_t v51 = v17;
    llvm::APIntOps::GreatestCommonDivisor((uint64_t)&v55, (uint64_t)&v51, (uint64_t)&v57);
    if (v58 > 0x40)
    {
      unint64_t v18 = *(void *)v57;
      MEMORY[0x21667D390]();
    }
    else
    {
      unint64_t v18 = (unint64_t)v57;
    }
    if (v52 >= 0x41 && v51) {
      MEMORY[0x21667D390](v51, 0x1000C8000313F17);
    }
    if (v56 >= 0x41 && v55) {
      MEMORY[0x21667D390](v55, 0x1000C8000313F17);
    }
    uint64_t v12 = v16 * v17 / v18;
    uint64_t v49 = v12;
  }
  ParentRegion = mlir::Value::getParentRegion((mlir::Value *)&v50);
  uint64_t v57 = &v50;
  uint64_t v58 = (uint64_t)&v49;
  double v20 = (mlir::Block *)*((void *)ParentRegion + 1);
  if (v20 != ParentRegion)
  {
    unsigned int v21 = ParentRegion;
    do
    {
      std::string v22 = (void *)((char *)v20 - 8);
      if (!v20) {
        std::string v22 = 0;
      }
      uint64_t v23 = (ZinIrHalH13g *)(v22 + 4);
      uint64_t v24 = (ZinIrHalH13g *)v22[5];
      if (v24 != (ZinIrHalH13g *)(v22 + 4))
      {
        do
        {
          int64_t v25 = (ZinIrHalH13g *)*((void *)v24 + 1);
          ZinIrHalH13g::~ZinIrHalH13g(v24);
          int64x2_t v55 = &v57;
          mlir::detail::walk<mlir::ForwardIterator>(v26, (mlir::Operation *)_ZN4llvm12function_refIFvPN4mlir9OperationEEE11callback_fnIZNS1_6detail4walkILNS1_9WalkOrderE1ENS1_15ForwardIteratorERZNS7_10AllocRange16getRangeForValueENS1_5ValueExE3__0NS1_25MinimumAlignmentInterfaceEvEENSt3__19enable_ifIXaantsr4llvm9is_one_ofIT2_S3_PNS1_6RegionEPNS1_5BlockEEE5valuesr3std7is_sameIT3_vEE5valueESN_E4typeES3_OT1_EUlS3_E_EEvlS3_, (uint64_t)&v55, 1);
          uint64_t v24 = v25;
        }
        while (v25 != v23);
      }
      double v20 = (mlir::Block *)*((void *)v20 + 1);
    }
    while (v20 != v21);
    uint64_t v12 = v49;
  }
  if (a2 == -1) {
    unint64_t v27 = 0;
  }
  else {
    unint64_t v27 = a2;
  }
  unint64_t v28 = v27;
  if (v12) {
    unint64_t v28 = (v27 + v12 - 1) / v12 * v12;
  }
  int64_t v29 = *v11;
  unint64_t v30 = mlir::TypeID::get<mlir::ShapedType>();
  unint64_t v31 = *((unsigned int *)v29 + 4);
  if (!v31) {
    goto LABEL_60;
  }
  uint64_t v32 = (void *)v29[1];
  unsigned __int8 v33 = &v32[2 * v31];
  do
  {
    unint64_t v34 = v31 >> 1;
    uint64_t v35 = &v32[2 * (v31 >> 1)];
    unint64_t v37 = *v35;
    uint64_t v36 = v35 + 2;
    v31 += ~(v31 >> 1);
    if (v37 < v30) {
      uint64_t v32 = v36;
    }
    else {
      unint64_t v31 = v34;
    }
  }
  while (v31);
  if (v32 != v33 && *v32 == v30) {
    uint64_t v38 = v32[1];
  }
  else {
LABEL_60:
  }
    uint64_t v38 = 0;
  int64x2_t v55 = v11;
  uint64_t v56 = v38;
  mlir::ShapedType::getShape((mlir::ShapedType *)&v55);
  if (v39)
  {
    if (*((_UNKNOWN **)*v55 + 17) == &mlir::detail::TypeIDResolver<mlir::MemRefType,void>::id) {
      uint64_t v40 = (uint64_t)v55;
    }
    else {
      uint64_t v40 = 0;
    }
    uint64_t v51 = v40;
    if (v40)
    {
      uint64_t v57 = v59;
      uint64_t v58 = 0x400000000;
      uint64_t v54 = 0;
      mlir::getStridesAndOffset(v40, (uint64_t)&v57, &v54);
      unint64_t v41 = *(void *)v57;
      unint64_t v42 = *(void *)mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v51) * v41;
      uint64_t v53 = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&v55);
      uint64_t v43 = v42 * (mlir::Type::getIntOrFloatBitWidth((mlir::Type *)&v53) >> 3);
      if (v57 != v59) {
        free(v57);
      }
    }
    else
    {
      Shape = (uint64_t *)mlir::ShapedType::getShape((mlir::ShapedType *)&v55);
      uint64_t NumElements = mlir::ShapedType::getNumElements(Shape, v45);
      uint64_t v57 = (void *)mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&v55);
      uint64_t v43 = NumElements * (mlir::Type::getIntOrFloatBitWidth((mlir::Type *)&v57) >> 3);
    }
  }
  else
  {
    uint64_t v57 = (void *)mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&v55);
    uint64_t v43 = mlir::Type::getIntOrFloatBitWidth((mlir::Type *)&v57) >> 3;
  }
  uint64_t v47 = v49;
  *(void *)a3 = v50;
  *(void *)(a3 + 8) = v27;
  *(void *)(a3 + 16) = v28;
  *(void *)(a3 + 24) = v28 + v43 - 1;
  *(void *)(a3 + 32) = v47;
}

uint64_t mlir::matchThrough<mlir::MinimumAlignmentInterface,mlir::MemoryMapperInterface>(uint64_t a1, void *a2)
{
  uint64_t v12 = a1;
  uint64_t result = mlir::Value::getDefiningOp((mlir::Value *)&v12);
  if (result)
  {
    uint64_t v4 = result;
    uint64_t DefiningOp = mlir::Value::getDefiningOp((mlir::Value *)&v12);
    if (DefiningOp
      && (uint64_t v6 = DefiningOp,
          mlir::OpInterface<mlir::MinimumAlignmentInterface,mlir::detail::MinimumAlignmentInterfaceInterfaceTraits>::getInterfaceFor(DefiningOp)))
    {
      mlir::OpInterface<mlir::MinimumAlignmentInterface,mlir::detail::MinimumAlignmentInterfaceInterfaceTraits>::getInterfaceFor(v6);
      if (a2) {
        *a2 = v12;
      }
      return 1;
    }
    else
    {
      uint64_t result = mlir::Value::getDefiningOp((mlir::Value *)&v12);
      if (result)
      {
        uint64_t result = mlir::OpInterface<mlir::MemoryMapperInterface,mlir::detail::MemoryMapperInterfaceInterfaceTraits>::getInterfaceFor(result);
        if (result)
        {
          if ((*(unsigned char *)(v4 + 46) & 0x80) != 0 && (uint64_t v7 = *(unsigned int *)(v4 + 68), v7))
          {
            uint64_t v8 = v7 - 1;
            uint64_t v9 = (uint64_t *)(*(void *)(v4 + 72) + 24);
            do
            {
              uint64_t v10 = v8;
              uint64_t v11 = *v9;
              v9 += 4;
              uint64_t result = mlir::matchThrough<mlir::MinimumAlignmentInterface,mlir::MemoryMapperInterface>(v11, a2);
              if (result) {
                break;
              }
              uint64_t v8 = v10 - 1;
            }
            while (v10);
          }
          else
          {
            return 0;
          }
        }
      }
    }
  }
  return result;
}

void mlir::dataflow::OffsetLatticeValue::join(unint64_t **a1@<X0>, uint64_t a2@<X1>, unint64_t **a3@<X8>)
{
  unint64_t v6 = *((unsigned int *)a1 + 2);
  unint64_t v7 = *(unsigned int *)(a2 + 8);
  if (v6 == v7)
  {
    if (!v6)
    {
      *a3 = (unint64_t *)(a3 + 2);
      a3[1] = (unint64_t *)0xA00000000;
      return;
    }
    uint64_t v8 = 0;
    uint64_t v9 = (char *)*a1;
    uint64_t v10 = *(unint64_t **)a2;
    while (*(void *)&v9[v8 * 8] == v10[v8])
    {
      v8 += 5;
      if (5 * v6 == v8)
      {
        uint64_t v11 = (unint64_t *)(a3 + 2);
        *a3 = (unint64_t *)(a3 + 2);
        a3[1] = (unint64_t *)0xA00000000;
        if (a3 == a1) {
          return;
        }
        if (v6 < 0xB)
        {
          unint64_t v12 = v6;
        }
        else
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)a3, a3 + 2, v6, 40);
          unint64_t v12 = *((unsigned int *)a1 + 2);
          if (!v12) {
            goto LABEL_90;
          }
          uint64_t v11 = *a3;
          uint64_t v9 = (char *)*a1;
        }
        size_t v45 = 40 * v12;
        goto LABEL_89;
      }
    }
  }
  else
  {
    uint64_t v10 = *(unint64_t **)a2;
  }
  if (!v7)
  {
LABEL_21:
    if (!v6)
    {
      uint64_t v48 = 0;
      uint64_t v49 = 0;
      unsigned int v50 = 0;
      uint64_t v51 = &v53;
      uint64_t v52 = 0;
      goto LABEL_41;
    }
    uint64_t v17 = *a1;
    uint64_t v18 = 40 * v6;
    uint64_t v19 = *a1 + 3;
    while (1)
    {
      BOOL v20 = *(v19 - 2) == -1 || *(v19 - 1) == -1;
      if (v20 || *v19 == -1) {
        break;
      }
      v19 += 5;
      v18 -= 40;
      if (!v18)
      {
        uint64_t v48 = 0;
        uint64_t v49 = 0;
        unsigned int v50 = 0;
        uint64_t v51 = &v53;
        uint64_t v52 = 0;
        uint64_t v22 = 40 * v6;
        do
        {
          llvm::SetVector<mlir::detail::AllocRange,llvm::SmallVector<mlir::detail::AllocRange,0u>,llvm::DenseSet<mlir::detail::AllocRange,llvm::DenseMapInfo<mlir::detail::AllocRange,void>>,0u>::insert((uint64_t)&v48, v17);
          v17 += 5;
          v22 -= 40;
        }
        while (v22);
        uint64_t v10 = *(unint64_t **)a2;
        unint64_t v7 = *(unsigned int *)(a2 + 8);
LABEL_41:
        if (v7)
        {
          uint64_t v24 = 40 * v7;
          do
          {
            llvm::SetVector<mlir::detail::AllocRange,llvm::SmallVector<mlir::detail::AllocRange,0u>,llvm::DenseSet<mlir::detail::AllocRange,llvm::DenseMapInfo<mlir::detail::AllocRange,void>>,0u>::insert((uint64_t)&v48, v10);
            v10 += 5;
            v24 -= 40;
          }
          while (v24);
        }
        if (v49)
        {
          if (v50 <= 4 * (int)v49 || v50 < 0x41)
          {
            if (v50)
            {
              unint64_t v27 = v48;
              unint64_t v28 = (llvm *)((char *)v48 + 40 * v50);
              *(void *)&long long v29 = -1;
              *((void *)&v29 + 1) = -1;
              do
              {
                *(void *)unint64_t v27 = -4096;
                *(_OWORD *)((char *)v27 + 8) = v29;
                *(_OWORD *)((char *)v27 + 24) = v29;
                unint64_t v27 = (llvm *)((char *)v27 + 40);
              }
              while (v27 != v28);
            }
            uint64_t v49 = 0;
          }
          else
          {
            llvm::DenseMap<mlir::detail::AllocRange,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::detail::AllocRange,void>,llvm::detail::DenseSetPair<mlir::detail::AllocRange>>::shrink_and_clear((uint64_t)&v48);
          }
        }
        long long v46 = &v48;
        uint64_t v47 = 0;
        if (v52)
        {
          llvm::SmallVectorImpl<mlir::detail::AllocRange>::operator=((uint64_t)&v46, (uint64_t)&v51);
          unint64_t v30 = (char *)v46;
        }
        else
        {
          unint64_t v30 = (char *)&v48;
        }
        uint64_t v31 = 0;
        for (uint64_t i = 1; ; ++i)
        {
          if (*(void *)&v30[v31 + 8] != -1 && *(void *)&v30[v31 + 16] != -1)
          {
            uint64_t v33 = (uint64_t)&v30[v31];
            if (*(void *)&v30[v31 + 24] != -1) {
              break;
            }
          }
          v31 += 40;
        }
        unint64_t v34 = v47;
        if (v47 != i)
        {
          uint64_t v36 = 0;
          do
          {
            unint64_t v37 = &v30[v36 + v31];
            if (*((void *)v37 + 6) != -1)
            {
              uint64_t v38 = *((void *)v37 + 7);
              if (v38 != -1)
              {
                uint64_t v39 = &v30[v36 + v31];
                uint64_t v40 = *((void *)v39 + 8);
                if (v40 != -1)
                {
                  uint64_t v41 = *(void *)(v33 + 24);
                  unint64_t v42 = v41 + 1;
                  *((void *)v37 + 6) = v41 + 1;
                  unint64_t v43 = *((void *)v39 + 9);
                  if (v43) {
                    unint64_t v42 = (v43 + v41) / v43 * v43;
                  }
                  uint64_t v33 = (uint64_t)&v30[v31 + 40 + v36];
                  *((void *)v37 + 7) = v42;
                  *((void *)v39 + 8) = v40 - v38 + v42;
                }
              }
            }
            v36 += 40;
          }
          while (40 * v34 - v31 - 40 != v36);
        }
        *a3 = (unint64_t *)(a3 + 2);
        a3[1] = (unint64_t *)0xA00000000;
        if (v34 >= 0xB)
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)a3, a3 + 2, v34, 40);
          unsigned int v35 = *((_DWORD *)a3 + 2);
          goto LABEL_78;
        }
        if (v34)
        {
          unsigned int v35 = 0;
LABEL_78:
          memcpy(&(*a3)[5 * v35], v30, 40 * v34);
          int v44 = *((_DWORD *)a3 + 2);
        }
        else
        {
          int v44 = 0;
        }
        *((_DWORD *)a3 + 2) = v44 + v34;
        if (v46 != &v48) {
          free(v46);
        }
        if (v51 != &v53) {
          free(v51);
        }
        llvm::deallocate_buffer(v48, (void *)(40 * v50));
      }
    }
    int64_t v25 = (unint64_t *)(a3 + 2);
    *a3 = (unint64_t *)(a3 + 2);
    a3[1] = (unint64_t *)0xA00000000;
    if (a3 == (unint64_t **)a2 || !v7) {
      return;
    }
    if (v7 < 0xB)
    {
      unint64_t v26 = v7;
    }
    else
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)a3, v25, v7, 40);
      unint64_t v26 = *(unsigned int *)(a2 + 8);
      if (!v26)
      {
LABEL_93:
        *((_DWORD *)a3 + 2) = v7;
        return;
      }
      int64_t v25 = *a3;
      uint64_t v10 = *(unint64_t **)a2;
    }
    memcpy(v25, v10, 40 * v26);
    goto LABEL_93;
  }
  uint64_t v13 = 40 * v7;
  char v14 = v10 + 3;
  while (1)
  {
    BOOL v15 = *(v14 - 2) == -1 || *(v14 - 1) == -1;
    if (v15 || *v14 == -1) {
      break;
    }
    v14 += 5;
    v13 -= 40;
    if (!v13) {
      goto LABEL_21;
    }
  }
  uint64_t v11 = (unint64_t *)(a3 + 2);
  *a3 = (unint64_t *)(a3 + 2);
  a3[1] = (unint64_t *)0xA00000000;
  if (a3 != a1 && v6)
  {
    if (v6 < 0xB)
    {
      unsigned int v23 = v6;
    }
    else
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)a3, a3 + 2, v6, 40);
      unsigned int v23 = *((_DWORD *)a1 + 2);
      if (!v23)
      {
LABEL_90:
        *((_DWORD *)a3 + 2) = v6;
        return;
      }
      uint64_t v11 = *a3;
    }
    uint64_t v9 = (char *)*a1;
    size_t v45 = 40 * v23;
LABEL_89:
    memcpy(v11, v9, v45);
    goto LABEL_90;
  }
}

llvm::raw_ostream *mlir::dataflow::OffsetLatticeValue::print(llvm::raw_ostream *this, llvm::raw_ostream *a2)
{
  uint64_t v3 = (uint64_t)this;
  uint64_t v4 = (unsigned char *)*((void *)a2 + 4);
  if (*((unsigned char **)a2 + 3) == v4)
  {
    this = llvm::raw_ostream::write(a2, "{", 1uLL);
  }
  else
  {
    *uint64_t v4 = 123;
    ++*((void *)a2 + 4);
  }
  uint64_t v5 = *(unsigned int *)(v3 + 8);
  if (v5 == 1)
  {
    this = mlir::detail::operator<<(a2, *(unint64_t **)v3);
  }
  else if (v5)
  {
    unint64_t v6 = *(unint64_t **)v3;
    uint64_t v7 = 40 * v5;
    do
    {
      uint64_t v9 = *((void *)a2 + 4);
      if ((unint64_t)(*((void *)a2 + 3) - v9) > 2)
      {
        *(unsigned char *)(v9 + 2) = 32;
        *(_WORD *)uint64_t v9 = 11552;
        *((void *)a2 + 4) += 3;
        uint64_t v8 = a2;
      }
      else
      {
        uint64_t v8 = llvm::raw_ostream::write(a2, " - ", 3uLL);
      }
      this = mlir::detail::operator<<(v8, v6);
      v6 += 5;
      v7 -= 40;
    }
    while (v7);
  }
  uint64_t v10 = (unsigned char *)*((void *)a2 + 4);
  if (*((unsigned char **)a2 + 3) == v10)
  {
    return llvm::raw_ostream::write(a2, "}", 1uLL);
  }
  else
  {
    *uint64_t v10 = 125;
    ++*((void *)a2 + 4);
  }
  return this;
}

llvm::raw_ostream *mlir::detail::operator<<(llvm::raw_ostream *this, unint64_t *a2)
{
  uint64_t v2 = this;
  uint64_t v4 = *((void *)this + 3);
  uint64_t v3 = *((void *)this + 4);
  if (*a2)
  {
    if (v4 == v3)
    {
      this = llvm::raw_ostream::write(this, "[", 1uLL);
    }
    else
    {
      *(unsigned char *)uint64_t v3 = 91;
      ++*((void *)this + 4);
    }
    unint64_t v6 = llvm::raw_ostream::operator<<(this, a2[1]);
    uint64_t v7 = (unsigned char *)*((void *)v6 + 4);
    if (*((unsigned char **)v6 + 3) == v7)
    {
      unint64_t v6 = llvm::raw_ostream::write(v6, "/", 1uLL);
    }
    else
    {
      unsigned char *v7 = 47;
      ++*((void *)v6 + 4);
    }
    uint64_t v8 = llvm::raw_ostream::operator<<(v6, a2[2]);
    uint64_t v9 = (_WORD *)*((void *)v8 + 4);
    if (*((void *)v8 + 3) - (void)v9 > 1uLL)
    {
      *uint64_t v9 = 8236;
      *((void *)v8 + 4) += 2;
    }
    else
    {
      uint64_t v8 = llvm::raw_ostream::write(v8, ", ", 2uLL);
    }
    uint64_t v10 = llvm::raw_ostream::operator<<(v8, a2[3]);
    uint64_t v11 = (void *)*((void *)v10 + 4);
    if (*((void *)v10 + 3) - (void)v11 > 0xDuLL)
    {
      qmemcpy(v11, "] provenance: ", 14);
      *((void *)v10 + 4) += 14;
    }
    else
    {
      llvm::raw_ostream::write(v10, "] provenance: ", 0xEuLL);
    }
    if ((~*(_DWORD *)(*a2 + 8) & 7) != 0)
    {
      unint64_t v15 = *a2;
      mlir::Value::print((mlir::Value *)&v15, v2);
    }
    else
    {
      unint64_t v12 = (_DWORD *)*((void *)v2 + 4);
      if (*((void *)v2 + 3) - (void)v12 > 3uLL)
      {
        *unint64_t v12 = 1735549221;
        *((void *)v2 + 4) += 4;
        uint64_t v13 = v2;
      }
      else
      {
        uint64_t v13 = llvm::raw_ostream::write(v2, "%arg", 4uLL);
      }
      llvm::raw_ostream::operator<<(v13, *(unsigned int *)(*a2 + 24));
    }
  }
  else if ((unint64_t)(v4 - v3) > 0xA)
  {
    *(_DWORD *)(v3 + 7) = 1046834799;
    *(void *)uint64_t v3 = *(void *)"<tombstone>";
    *((void *)this + 4) += 11;
  }
  else
  {
    llvm::raw_ostream::write(this, "<tombstone>", 0xBuLL);
  }
  return v2;
}

void mlir::dataflow::TensorAllocAnalysis::TensorAllocAnalysis(mlir::dataflow::AbstractSparseForwardDataFlowAnalysis *a1, mlir::DataFlowSolver *a2)
{
}

{
  mlir::dataflow::TensorAllocAnalysis::TensorAllocAnalysis(a1, a2);
}

void mlir::dataflow::TensorAllocAnalysis::visitOperation(uint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t *a5, uint64_t a6)
{
  v58[50] = *MEMORY[0x263EF8340];
  uint64_t v12 = mlir::TypeID::get<mlir::OpTrait::ConstantLike<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::ConstantLike>(void)::Empty>>();
  if ((*(unsigned int (**)(void, uint64_t))(**(void **)(a2 + 48) + 32))(*(void *)(a2 + 48), v12)) {
    mlir::dataflow::AbstractSparseForwardDataFlowAnalysis::setAllToEntryStates((uint64_t)a1, a5, a6);
  }
  if (!a4) {
    mlir::dataflow::AbstractSparseForwardDataFlowAnalysis::setAllToEntryStates((uint64_t)a1, a5, a6);
  }
  uint64_t v56 = v58;
  uint64_t v57 = 0xA00000000;
  uint64_t v48 = a5;
  uint64_t v49 = a6;
  if (mlir::OpInterface<mlir::MemoryMapperInterface,mlir::detail::MemoryMapperInterfaceInterfaceTraits>::getInterfaceFor(a2))
  {
    uint64_t v50 = a2;
    uint64_t InterfaceFor = mlir::OpInterface<mlir::MemoryMapperInterface,mlir::detail::MemoryMapperInterfaceInterfaceTraits>::getInterfaceFor(a2);
    if (a2)
    {
      uint64_t OperandRange = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&v50);
      uint64_t v15 = OperandRange;
      uint64_t v16 = (void *)(a3 + 8 * OperandRange);
      if (v14 == OperandRange)
      {
        BOOL v17 = 0;
      }
      else
      {
        uint64_t v18 = a3 + 8 * OperandRange;
        while (2)
        {
          uint64_t v19 = *(unsigned int *)(*(void *)v18 + 176);
          BOOL v17 = *(_DWORD *)(*(void *)v18 + 176) == 0;
          if (v19)
          {
            uint64_t v20 = 40 * v19;
            unsigned int v21 = (void *)(*(void *)(*(void *)v18 + 168) + 24);
            do
            {
              if (*(v21 - 2) == -1 || *(v21 - 1) == -1 || *v21 == -1)
              {
                BOOL v17 = 1;
                goto LABEL_25;
              }
              v21 += 5;
              v20 -= 40;
            }
            while (v20);
            v18 += 8;
            if (v18 != a3 + 8 * v14) {
              continue;
            }
          }
          break;
        }
      }
LABEL_25:
      if ((*(unsigned char *)(a2 + 46) & 0x80) != 0) {
        uint64_t v24 = *(void *)(a2 + 72);
      }
      else {
        uint64_t v24 = 0;
      }
      uint64_t v25 = v14 - OperandRange;
      uint64_t v46 = v14;
      if (v14 == OperandRange)
      {
        int v47 = 0;
        int64_t v26 = 0;
      }
      else
      {
        uint64_t v27 = ~OperandRange + v14;
        unint64_t v28 = (void **)(v24 + 32 * OperandRange + 24);
        do
        {
          long long v29 = *v28;
          v28 += 4;
          BOOL isDeadAfter = mlir::Liveness::isDeadAfter(a1[2], v29, v50);
          BOOL v32 = v27-- != 0;
        }
        while (isDeadAfter && v32);
        int64_t v26 = 0;
        int v47 = !isDeadAfter;
        uint64_t v33 = (_DWORD **)(v24 + 32 * v15 + 24);
        do
        {
          unint64_t v34 = *v33;
          v33 += 4;
          mlir::detail::AllocRange::getRangeForValue(v34, v26 + 1, (uint64_t)v52);
          if (v54 != -1) {
            int64_t v26 = v54;
          }
          --v25;
        }
        while (v25);
      }
      uint64_t v35 = *(unsigned int *)(a2 + 36);
      if (v35) {
        uint64_t v36 = a2 - 16;
      }
      else {
        uint64_t v36 = 0;
      }
      if (v35)
      {
        unint64_t v37 = 0;
        uint64_t v38 = 0;
        while (1)
        {
          NextResultAtOffset = (_DWORD *)mlir::detail::OpResultImpl::getNextResultAtOffset(v36, v38);
          mlir::detail::AllocRange::getRangeForValue(NextResultAtOffset, v37, (uint64_t)v52);
          if (v55) {
            unint64_t v37 = (v37 + v55 - 1) / v55 * v55;
          }
          if ((uint64_t)(v54 - v53 + v37) > v26) {
            break;
          }
          unint64_t v37 = v54 + 1;
          if (v35 == ++v38) {
            goto LABEL_48;
          }
        }
      }
      else
      {
LABEL_48:
        if (((v17 | v47) & 1) == 0
          && mlir::MemoryMapperInterface::canMapOperands((mlir::MemoryMapperInterface *)&v50)
          && v46 != v15)
        {
          uint64_t v40 = 8 * v46 - 8 * v15;
          do
          {
            mlir::dataflow::OffsetLatticeValue::join((unint64_t **)&v56, *v16 + 168, (unint64_t **)v52);
            llvm::SmallVectorImpl<mlir::detail::AllocRange>::operator=((uint64_t)&v56, (uint64_t)v52);
            if (v52[0] != &v53) {
              free(v52[0]);
            }
            ++v16;
            v40 -= 8;
          }
          while (v40);
        }
      }
    }
  }
  else
  {
    uint64_t v50 = 0;
    uint64_t InterfaceFor = 0;
  }
  if (!v57) {
    mlir::dataflow::AbstractSparseForwardDataFlowAnalysis::setAllToEntryStates((uint64_t)a1, v48, v49);
  }
  uint64_t v41 = *(unsigned int *)(a2 + 36);
  if (v41) {
    uint64_t v42 = a2 - 16;
  }
  else {
    uint64_t v42 = 0;
  }
  if (v41)
  {
    for (uint64_t i = 0; i != v41; ++i)
    {
      uint64_t v44 = mlir::detail::OpResultImpl::getNextResultAtOffset(v42, i);
      uint64_t v45 = (*(uint64_t (**)(uint64_t *, uint64_t))(*a1 + 48))(a1, v44);
      mlir::dataflow::Lattice<mlir::dataflow::OffsetLatticeValue>::join(v45, (uint64_t)&v56);
    }
  }
  if (v56 != v58) {
    free(v56);
  }
}

uint64_t mlir::dataflow::Lattice<mlir::dataflow::OffsetLatticeValue>::join(uint64_t a1, uint64_t a2)
{
  v13[50] = *MEMORY[0x263EF8340];
  uint64_t v3 = (void **)(a1 + 168);
  mlir::dataflow::OffsetLatticeValue::join((unint64_t **)(a1 + 168), a2, (unint64_t **)&__src);
  unint64_t v4 = v12;
  uint64_t v5 = *(unsigned int *)(a1 + 176);
  if (v12 == v5)
  {
    if (!v12)
    {
LABEL_6:
      uint64_t v9 = 0;
      goto LABEL_20;
    }
    unint64_t v6 = __src;
    uint64_t v7 = *v3;
    uint64_t v8 = 40 * v12;
    while (*v6 == *v7)
    {
      v6 += 5;
      v7 += 5;
      v8 -= 40;
      if (!v8) {
        goto LABEL_6;
      }
    }
  }
  if (v3 != &__src)
  {
    if (v5 >= v12)
    {
      if (v12) {
        memmove(*v3, __src, 40 * v12);
      }
      goto LABEL_18;
    }
    if (*(_DWORD *)(a1 + 180) >= v12)
    {
      if (v5)
      {
        memmove(*v3, __src, 40 * v5);
        goto LABEL_16;
      }
    }
    else
    {
      *(_DWORD *)(a1 + 176) = 0;
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)v3, (void *)(a1 + 184), v4, 40);
    }
    uint64_t v5 = 0;
LABEL_16:
    if (v5 != v12) {
      memcpy((char *)*v3 + 40 * v5, (char *)__src + 40 * v5, 40 * v12 - 40 * v5);
    }
LABEL_18:
    *(_DWORD *)(a1 + 176) = v4;
  }
  uint64_t v9 = 1;
LABEL_20:
  if (__src != v13) {
    free(__src);
  }
  return v9;
}

{
  return mlir::dataflow::Lattice<mlir::dataflow::OffsetLatticeValue>::join(a1, a2 + 168);
}

void mlir::dataflow::TensorAllocAnalysis::buildAllocInfoMap(mlir::dataflow::TensorAllocAnalysis *this, mlir::Operation *a2)
{
  v276[21] = *MEMORY[0x263EF8340];
  uint64_t v3 = *(void *)((((unint64_t)a2
                   + 16 * (((unint64_t)*((unsigned int *)a2 + 11) >> 23) & 1)
                   + (((unint64_t)*((unsigned int *)a2 + 11) >> 21) & 0x7F8)
                   + 71) & 0xFFFFFFFFFFFFFFF8)
                 + 32 * *((unsigned int *)a2 + 10)
                 + 8);
  if (v3) {
    unint64_t v4 = (ZinIrHalH13g **)(v3 - 8);
  }
  else {
    unint64_t v4 = 0;
  }
  uint64_t v230 = (uint64_t **)((char *)this + 64);
  if (*((_DWORD *)this + 18))
  {
    uint64_t v5 = 0;
    unint64_t v6 = (void *)*((void *)this + 8);
    uint64_t v7 = (char *)this + 104;
    BOOL v243 = (char *)a2 + 56;
    do
    {
      if (*v6 == -3)
      {
        mlir::Block::getTerminator(v4);
        if ((*(unsigned char *)(v13 + 46) & 0x80) != 0 && *(_DWORD *)(v13 + 68))
        {
          uint64_t v14 = *((void *)this + 13);
          uint64_t v15 = v14 + 8 * v5;
          uint64_t v16 = *((unsigned int *)this + 28);
          uint64_t v17 = v14 + 8 * v16;
          if (v17 != v15 + 8)
          {
            memmove((void *)v15, (const void *)(v15 + 8), v17 - (v15 + 8));
            LODWORD(v16) = *((_DWORD *)this + 28);
            uint64_t v14 = *((void *)this + 13);
          }
          *((_DWORD *)this + 28) = v16 - 1;
          if (*((unsigned char *)a2 + 47)
            && (uint64_t InherentAttr = mlir::Operation::getInherentAttr((uint64_t)a2, (uint64_t)"output_names", 12), v19))
          {
            if (InherentAttr)
            {
LABEL_22:
              if (*(_UNKNOWN **)(*(void *)InherentAttr + 136) == &mlir::detail::TypeIDResolver<mlir::ArrayAttr,void>::id) {
                uint64_t v20 = InherentAttr;
              }
              else {
                uint64_t v20 = 0;
              }
              goto LABEL_27;
            }
          }
          else
          {
            uint64_t InherentAttr = mlir::DictionaryAttr::get((uint64_t)v243, "output_names", 0xCuLL);
            if (InherentAttr) {
              goto LABEL_22;
            }
          }
          uint64_t v20 = 0;
LABEL_27:
          *(void *)&long long v263 = v20;
          CFDictionaryRef Value = (char *)mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v263);
          uint64_t v22 = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v263);
          llvm::SmallVectorImpl<mlir::Attribute>::insert<mlir::Attribute const*,void>((uint64_t)v7, v14 + 8 * v5, Value, (char *)(v22 + 8 * v23));
          uint64_t v252 = &v254;
          uint64_t v253 = (void *)0x500000000;
          mlir::Block::getTerminator(v4);
          if ((*(unsigned char *)(v24 + 46) & 0x80) != 0 && (uint64_t v25 = *(unsigned int *)(v24 + 68), v25))
          {
            int64_t v26 = (_DWORD **)(*(void *)(v24 + 72) + 24);
            do
            {
              mlir::detail::AllocRange::getRangeForValue(*v26, 0, (uint64_t)&v271);
              unint64_t v27 = v273;
              uint64_t v28 = v272;
              uint64_t v29 = v253;
              if (v253 >= (unint64_t)HIDWORD(v253))
              {
                llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v252, &v254, v253 + 1, 8);
                uint64_t v29 = v253;
              }
              *((void *)v252 + v29) = v27 - v28 + 1;
              unsigned int v30 = v253 + 1;
              LODWORD(v253) = v253 + 1;
              v26 += 4;
              --v25;
            }
            while (v25);
          }
          else
          {
            unsigned int v30 = v253;
          }
          uint64_t v31 = (char *)v252 + 8 * v30;
          BOOL v32 = (char *)v252 + 8;
          *unint64_t v6 = *(void *)v252;
          unint64_t v6 = (void *)llvm::SmallVectorImpl<mlir::Attribute>::insert<mlir::Attribute const*,void>((uint64_t)v230, (uint64_t)(v6 + 1), v32, v31);
          if (v252 != &v254) {
            free(v252);
          }
        }
      }
      else if (*v6 == -2)
      {
        mlir::Block::getTerminator(v4);
        if ((*(unsigned char *)(v8 + 46) & 0x80) != 0 && (uint64_t v9 = *(unsigned int *)(v8 + 68), v9))
        {
          unint64_t v10 = 0;
          uint64_t v11 = (_DWORD **)(*(void *)(v8 + 72) + 24);
          do
          {
            unsigned int v12 = *v11;
            v11 += 4;
            mlir::detail::AllocRange::getRangeForValue(v12, v10, (uint64_t)&v252);
            unint64_t v10 = v10 + v255[0] - (void)v253 + 1;
            --v9;
          }
          while (v9);
          *unint64_t v6 = v10;
        }
        else
        {
          *unint64_t v6 = 0;
        }
      }
      ++v5;
      ++v6;
    }
    while (v6 != (void *)(*((void *)this + 8) + 8 * *((unsigned int *)this + 18)));
  }
  mlir::OpPrintingFlags::OpPrintingFlags((mlir::OpPrintingFlags *)&v252);
  mlir::AsmState::AsmState(&v244, a2, &v252, 0, 0);
  uint64_t v33 = this;
  unint64_t v34 = (uint64_t *)*((void *)this + 8);
  unint64_t v35 = *((unsigned int *)this + 18);
  LOBYTE(v252) = *((unsigned char *)this + 160);
  uint64_t v253 = v255;
  uint64_t v254 = 0x300000000;
  if (v35)
  {
    if (v35 < 4)
    {
      unsigned int v42 = 0;
      uint64_t v36 = v255;
    }
    else
    {
      long long v271 = 0;
      uint64_t v36 = llvm::SmallVectorBase<unsigned int>::mallocForGrow((uint64_t)&v253, v255, v35, 1000, (unint64_t *)&v271);
      unint64_t v37 = (char *)v253;
      if (v254)
      {
        uint64_t v38 = 0;
        uint64_t v39 = (char *)v253 + 1000 * v254;
        do
        {
          uint64_t v40 = &v36[v38];
          uint64_t v41 = &v37[v38 * 8];
          *uint64_t v40 = *(void *)&v37[v38 * 8];
          v36[v38 + 1] = &v36[v38 + 3];
          v40[2] = 0xA00000000;
          if (*(_DWORD *)&v37[v38 * 8 + 16]) {
            llvm::SmallVectorImpl<mlir::detail::AllocRange>::operator=((uint64_t)&v36[v38 + 1], (uint64_t)(v41 + 8));
          }
          v40[53] = v40 + 55;
          v40[54] = 0xA00000000;
          if (*((_DWORD *)v41 + 108)) {
            llvm::SmallVectorImpl<llvm::SmallSetVector<mlir::Value,2u>>::operator=((uint64_t)(v40 + 53), (uint64_t *)&v37[v38 * 8 + 424]);
          }
          v38 += 125;
        }
        while (v41 + 1000 != v39);
        unint64_t v37 = (char *)v253;
        int v43 = v254;
      }
      else
      {
        int v43 = 0;
      }
      int v44 = (int)v271;
      if (v253 != v255) {
        free(v253);
      }
      uint64_t v253 = v36;
      HIDWORD(v254) = v44;
      unsigned int v42 = v254;
      uint64_t v33 = this;
      if (v254 == v35) {
        goto LABEL_55;
      }
    }
    uint64_t v45 = 1000 * v42;
    uint64_t v46 = 1000 * v35;
    do
    {
      int v47 = &v36[(unint64_t)v45 / 8];
      bzero(&v36[(unint64_t)v45 / 8 + 3], 0x3D0uLL);
      void *v47 = -1;
      v47[1] = &v36[(unint64_t)v45 / 8 + 3];
      v47[2] = 0xA00000000;
      v47[53] = v47 + 55;
      v46 -= 1000;
      v36 += 125;
      *((_DWORD *)v47 + 109) = 10;
    }
    while (v45 != v46);
    uint64_t v36 = v253;
    uint64_t v33 = this;
LABEL_55:
    LODWORD(v254) = v35;
    uint64_t v48 = 1000 * v35;
    do
    {
      uint64_t v49 = *v34++;
      uint64_t v50 = v49 - 1;
      if (v49 == -1) {
        uint64_t v51 = -1;
      }
      else {
        uint64_t v51 = v50;
      }
      void *v36 = v51;
      v36 += 125;
      v48 -= 1000;
    }
    while (v48);
  }
  uint64_t v52 = v4[4];
  uint64_t v229 = (ZinIrHalH13g *)(v4 + 4);
  if (v52 == (ZinIrHalH13g *)(v4 + 4)) {
    goto LABEL_371;
  }
  uint64_t v233 = (uint64_t)v33 + 24;
  uint64_t v228 = (char *)v33 + 80;
  while (2)
  {
    uint64_t v231 = (ZinIrHalH13g **)v52;
    ZinIrHalH13g::~ZinIrHalH13g(v52);
    uint64_t v240 = v53;
    if ((*((unsigned char *)v53 + 46) & 0x80) == 0) {
      goto LABEL_291;
    }
    uint64_t v238 = *((unsigned int *)v53 + 17);
    if (!v238) {
      goto LABEL_218;
    }
    uint64_t v55 = 0;
    uint64_t v235 = *((void *)v53 + 9);
    do
    {
      uint64_t v56 = *(void **)(v235 + 32 * v55 + 24);
      uint64_t v57 = (*(uint64_t (**)(mlir::dataflow::TensorAllocAnalysis *, void *))(*(void *)v33 + 48))(v33, v56);
      unint64_t v58 = *(unsigned int *)(v57 + 176);
      if (!v58) {
        goto LABEL_66;
      }
      uint64_t v59 = v57;
      BOOL v251 = v56;
      __b = v270;
      HIDWORD(v269) = 4;
      if (v58 <= 4)
      {
        memset(v270, 255, 8 * v58);
        LODWORD(v269) = v58;
        int64x2_t v60 = (uint64_t **)v270;
        uint64_t v62 = *(void **)(v59 + 168);
        uint64_t v63 = &v62[5 * v58];
      }
      else
      {
        LODWORD(v269) = 0;
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&__b, v270, v58, 8);
        int64x2_t v60 = (uint64_t **)__b;
        memset(__b, 255, 8 * v58);
        unsigned int v61 = *(_DWORD *)(v59 + 176);
        LODWORD(v269) = v58;
        if (!v61)
        {
          int v74 = 1;
          goto LABEL_93;
        }
        uint64_t v62 = *(void **)(v59 + 168);
        uint64_t v63 = &v62[5 * v61];
      }
      uint64_t v64 = 0;
      do
      {
        if (v62[1] != -1 && v62[2] != -1 && v62[3] != -1 && v254)
        {
          uint64_t v65 = 0;
          uint64_t v66 = v253;
          while (1)
          {
            uint64_t v67 = v66[1];
            uint64_t v68 = *((unsigned int *)v66 + 4);
            if (v68)
            {
              uint64_t v69 = 40 * v68;
              uint64_t v70 = (void *)v66[1];
              while (*v70 != *v62)
              {
                v70 += 5;
                v69 -= 40;
                if (!v69)
                {
                  uint64_t v70 = (void *)(v67 + 40 * v68);
                  break;
                }
              }
            }
            else
            {
              uint64_t v70 = (void *)v66[1];
            }
            uint64_t v71 = (char *)v70 - v67;
            unint64_t v72 = 0xCCCCCCCCCCCCCCCDLL * (((uint64_t)v70 - v67) >> 3);
            BOOL v73 = v71 == (char *)-40 || v72 == v68;
            if (!v73) {
              break;
            }
            ++v65;
            v66 += 125;
            if (v66 == (void *)((char *)v253 + 1000 * v254)) {
              goto LABEL_73;
            }
          }
          long long v271 = v251;
          llvm::SetVector<mlir::Value,llvm::SmallVector<mlir::Value,2u>,llvm::DenseSet<mlir::Value,llvm::DenseMapInfo<mlir::Value,void>>,2u>::insert(v66[53] + 56 * v72, (unint64_t *)&v271);
          int64x2_t v60 = (uint64_t **)__b;
          *((void *)__b + v64) = v65;
        }
LABEL_73:
        ++v64;
        v62 += 5;
      }
      while (v62 != v63);
      unint64_t v58 = v269;
      int v74 = (int)v269;
      uint64_t v33 = this;
LABEL_93:
      *(void *)&long long v263 = &v264;
      *((void *)&v263 + 1) = 0x200000000;
      uint64_t v266 = 0;
      unint64_t v267 = 0;
      uint64_t v265 = (unint64_t *)&v266;
      if (!v74) {
        goto LABEL_148;
      }
      uint64_t v75 = 8 * v58;
      do
      {
        llvm::SmallSet<long long,2u,std::less<long long>>::insert((uint64_t)&v263, v60++, (uint64_t)&v271);
        v75 -= 8;
      }
      while (v75);
      if (!v267)
      {
        if (DWORD2(v263) > 2)
        {
LABEL_117:
          LoCC_SHA256_CTX c = mlir::Value::getLoc((mlir::Value *)&v251);
          uint64_t v87 = "Cannot pack an OffsetLatticeValue that contains ranges that were already allocated to different buffers."
                " This is an invalid program state.";
          goto LABEL_124;
        }
        if (DWORD2(v263) == 1)
        {
          __n128 v88 = (void *)v263;
          goto LABEL_128;
        }
        if (DWORD2(v263) == 2)
        {
          uint64_t v79 = (unint64_t *)v263;
          if (*(void *)v263 != -1 && *(void *)(v263 + 8) != -1) {
            goto LABEL_123;
          }
          uint64_t v80 = (unint64_t *)(v263 + 16);
          while (1)
          {
LABEL_133:
            int v90 = v79 + 4;
            if (!v267) {
              int v90 = v79;
            }
            unint64_t v81 = *v90;
            if (v81 != -1) {
              break;
            }
            if (v267)
            {
              uint64_t v91 = (unint64_t *)v79[1];
              if (v91)
              {
                do
                {
                  uint64_t v89 = v91;
                  uint64_t v91 = (unint64_t *)*v91;
                }
                while (v91);
              }
              else
              {
                do
                {
                  uint64_t v89 = (unint64_t *)v79[2];
                  BOOL v73 = *v89 == (void)v79;
                  uint64_t v79 = v89;
                }
                while (!v73);
              }
            }
            else
            {
              uint64_t v89 = v79 + 1;
            }
            uint64_t v79 = v89;
            if (v89 == v80) {
              goto LABEL_107;
            }
          }
LABEL_108:
          uint64_t v82 = v269;
          if (v269)
          {
            if (v269 < 4)
            {
              uint64_t v83 = (unint64_t *)__b;
              uint64_t v84 = v269;
LABEL_146:
              unint64_t v95 = v84 + 1;
              do
              {
                *v83++ = v81;
                --v95;
              }
              while (v95 > 1);
              goto LABEL_148;
            }
            uint64_t v83 = (unint64_t *)((char *)__b + 8 * (v269 & 0xFFFFFFFC));
            uint64_t v84 = v269 & 3;
            int64x2_t v92 = vdupq_n_s64(v81);
            __n128 v93 = (int64x2_t *)((char *)__b + 16);
            uint64_t v94 = v269 & 0xFFFFFFFC;
            do
            {
              v93[-1] = v92;
              *__n128 v93 = v92;
              v93 += 2;
              v94 -= 4;
            }
            while (v94);
            if ((v82 & 0xFFFFFFFC) != v82) {
              goto LABEL_146;
            }
          }
        }
LABEL_148:
        uint64_t v96 = *(void *)__b;
        uint64_t v97 = *(unsigned int *)(v59 + 176);
        if (v97)
        {
          uint64_t v98 = 40 * v97;
          std::string v99 = *(void **)(v59 + 168);
          while (1)
          {
            BOOL v100 = v99[1] == -1 || v99[2] == -1;
            if (!v100 && v99[3] != -1) {
              break;
            }
            v99 += 5;
            v98 -= 40;
            if (!v98)
            {
              unsigned int v101 = 0;
              long long v271 = (char *)&v272 + 8;
              DWORD1(v272) = 4;
              goto LABEL_183;
            }
          }
        }
        else
        {
          std::string v99 = *(void **)(v59 + 168);
        }
        uint64_t v102 = *(void *)(v59 + 168) + 40 * v97;
        long long v271 = (char *)&v272 + 8;
        *(void *)&long long v272 = 0x400000000;
        if (v99 == (void *)v102)
        {
          unsigned int v101 = 0;
        }
        else
        {
          unint64_t v103 = 0;
          long long v104 = v99;
LABEL_161:
          unint64_t v105 = v103++;
          while (1)
          {
            v104 += 5;
            if (v104 == (void *)v102) {
              break;
            }
            BOOL v106 = v104[1] == -1 || v104[2] == -1;
            if (!v106 && v104[3] != -1)
            {
              if (v104 != (void *)v102) {
                goto LABEL_161;
              }
              break;
            }
          }
          if (v105 < 4)
          {
            int v107 = 0;
            uint64_t v108 = (char *)&v272 + 8;
          }
          else
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v271, (char *)&v272 + 8, v103, 40);
            int v107 = v272;
            uint64_t v108 = (char *)v271;
          }
          unsigned int v109 = &v108[40 * v107];
LABEL_174:
          long long v110 = *(_OWORD *)v99;
          long long v111 = *((_OWORD *)v99 + 1);
          *((void *)v109 + 4) = v99[4];
          *(_OWORD *)unsigned int v109 = v110;
          *((_OWORD *)v109 + 1) = v111;
          while (1)
          {
            v99 += 5;
            if (v99 == (void *)v102) {
              break;
            }
            BOOL v112 = v99[1] == -1 || v99[2] == -1;
            if (!v112 && v99[3] != -1)
            {
              v109 += 40;
              if (v99 != (void *)v102) {
                goto LABEL_174;
              }
              break;
            }
          }
          unsigned int v101 = v272 + v103;
        }
LABEL_183:
        LODWORD(v272) = v101;
        BOOL v260 = v262;
        uint64_t v261 = 0x400000000;
        uint64_t v113 = (char *)v253;
        if (v96 == -1)
        {
          if (v254)
          {
            uint64_t v114 = 1000 * v254;
            while (1)
            {
              LODWORD(v261) = 0;
              v113 += 1000;
              v114 -= 1000;
              if (!v114) {
                goto LABEL_190;
              }
            }
          }
          else
          {
LABEL_190:
            uint64_t v113 = 0;
          }
        }
        else
        {
          uint64_t v113 = (char *)v253 + 1000 * v96;
          {
LABEL_209:
            if (v260 != v262) {
              free(v260);
            }
            uint64_t v33 = this;
            if (v271 != (char *)&v272 + 8) {
              free(v271);
            }
            goto LABEL_213;
          }
        }
        if (*(_DWORD *)(v59 + 176)) {
          BOOL v115 = v261 == 0;
        }
        else {
          BOOL v115 = 1;
        }
        if (!v115)
        {
          uint64_t v116 = *(void *)(v59 + 168);
          unint64_t v117 = *(void *)v260;
          unint64_t v118 = *(void *)(v116 + 32);
          long long v119 = *(_OWORD *)(v116 + 16);
          *(void *)&long long v248 = *(void *)v116;
          long long v249 = v119;
          uint64_t v250 = v118;
          *((void *)&v248 + 1) = v117;
          if (v118) {
            unint64_t v117 = (v117 + v118 - 1) / v118 * v118;
          }
          *(void *)&long long v249 = v117;
          *((void *)&v249 + 1) = *((void *)&v119 + 1) - v119 + v117;
          long long v256 = 0uLL;
          LODWORD(v257) = 0;
          *((void *)&v257 + 1) = v259;
          uint64_t v258 = 0x200000000;
          llvm::SetVector<mlir::Value,llvm::SmallVector<mlir::Value,2u>,llvm::DenseSet<mlir::Value,llvm::DenseMapInfo<mlir::Value,void>>,2u>::insert((uint64_t)&v256, (unint64_t *)&v248);
          llvm::SetVector<mlir::Value,llvm::SmallVector<mlir::Value,2u>,llvm::DenseSet<mlir::Value,llvm::DenseMapInfo<mlir::Value,void>>,2u>::insert((uint64_t)&v256, (unint64_t *)&v251);
          uint64_t v247 = v250;
          long long v245 = v248;
          long long v246 = v249;
          uint64_t v120 = *((void *)v113 + 1);
          unint64_t v121 = *((unsigned int *)v113 + 4);
          if (!v121)
          {
            uint64_t v122 = *((void *)v113 + 1);
LABEL_206:
            uint64_t v126 = v122 - v120;
            llvm::SmallVectorImpl<llvm::SmallSetVector<mlir::Value,2u>>::insert_one_impl<llvm::SmallSetVector<mlir::Value,2u> const&>((uint64_t)(v113 + 424), *((void *)v113 + 53) - 0x3333333333333328 * ((v122 - v120) >> 3), (unint64_t)&v256);
            llvm::SmallVectorImpl<mlir::detail::AllocRange>::insert_one_impl<mlir::detail::AllocRange const&>((uint64_t)(v113 + 8), *((void *)v113 + 1) + v126, (unint64_t)&v245);
            if (*((unsigned char **)&v257 + 1) != v259) {
              free(*((void **)&v257 + 1));
            }
            llvm::deallocate_buffer((llvm *)v256, (void *)(8 * v257));
          }
          uint64_t v122 = *((void *)v113 + 1);
          while (2)
          {
            unint64_t v123 = v121 >> 1;
            uint64_t v124 = v122 + 40 * (v121 >> 1);
            uint64_t v125 = *(void *)(v124 + 8);
            if (*((void *)&v245 + 1) == v125)
            {
              if (*((void *)&v246 + 1) - *((void *)&v245 + 1) + 1 >= *(void *)(v122 + 40 * v123 + 24)
                                                                          - *((void *)&v245 + 1)
                                                                          + 1)
              {
LABEL_204:
                uint64_t v122 = v124 + 40;
                unint64_t v123 = v121 + ~v123;
              }
            }
            else if (*((uint64_t *)&v245 + 1) >= v125)
            {
              goto LABEL_204;
            }
            unint64_t v121 = v123;
            if (!v123) {
              goto LABEL_206;
            }
            continue;
          }
        }
        goto LABEL_209;
      }
      if (v267 > 2) {
        goto LABEL_117;
      }
      if (v267 == 2)
      {
        char v76 = v266;
        if (v266)
        {
          uint64_t v77 = v266;
          while (1)
          {
            uint64_t v78 = v77[4];
            if (v78 < 0)
            {
              if (v78 == -1)
              {
                uint64_t v79 = v265;
                uint64_t v80 = (unint64_t *)&v266;
                if (v265 != (unint64_t *)&v266) {
                  goto LABEL_133;
                }
LABEL_107:
                unint64_t v81 = -1;
                goto LABEL_108;
              }
              ++v77;
            }
            uint64_t v77 = (void *)*v77;
            if (!v77)
            {
              while (1)
              {
                uint64_t v85 = v76[4];
                if (v85 < 0)
                {
                  if (v85 == -1) {
                    goto LABEL_148;
                  }
                  ++v76;
                }
                char v76 = (void *)*v76;
                if (!v76) {
                  goto LABEL_123;
                }
              }
            }
          }
        }
LABEL_123:
        LoCC_SHA256_CTX c = mlir::Value::getLoc((mlir::Value *)&v251);
        uint64_t v87 = "Operands were allocated into multiple buffers. This is an invalid program state.";
LABEL_124:
        *(void *)&long long v256 = v87;
        LOWORD(v258) = 259;
        mlir::emitError(Loc, (uint64_t)&v256, (uint64_t)&v271);
        mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v271);
        if (v271) {
          mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v271);
        }
        std::__optional_destruct_base<mlir::Diagnostic,false>::~__optional_destruct_base[abi:nn180100]((uint64_t)&v272);
        goto LABEL_213;
      }
      __n128 v88 = v265 + 4;
LABEL_128:
      if (*v88 == -1) {
        goto LABEL_148;
      }
LABEL_213:
      std::__tree<std::__value_type<double,double>,std::__map_value_compare<double,std::__value_type<double,double>,std::less<double>,true>,std::allocator<std::__value_type<double,double>>>::destroy((uint64_t)&v265, v266);
      if ((long long *)v263 != &v264) {
        free((void *)v263);
      }
      if (__b != v270) {
        free(__b);
      }
LABEL_66:
      ++v55;
    }
    while (v55 != v238);
    uint64_t v53 = v240;
    if ((*((unsigned char *)v240 + 46) & 0x80) != 0)
    {
LABEL_218:
      uint64_t v236 = *((unsigned int *)v53 + 17);
      if (v236)
      {
        uint64_t v127 = 0;
        uint64_t v234 = *((void *)v53 + 9);
        do
        {
          uint64_t v239 = v127;
          uint64_t v129 = *(_DWORD **)(v234 + 32 * v127 + 24);
          BOOL v260 = v129;
          if (v254)
          {
            uint64_t v130 = 0;
            uint64_t v131 = (char *)v253;
            uint64_t v241 = (char *)v253 + 1000 * v254;
            while (1)
            {
              long long v271 = (char *)&v272 + 8;
              *(void *)&long long v272 = 0x400000000;
              unsigned int v134 = *((_DWORD *)v131 + 108);
              if (v134)
              {
                unsigned int v135 = 0;
                uint64_t v136 = 0;
                uint64_t v137 = *((void *)v131 + 53);
                uint64_t v138 = v137 + 56 * v134;
                do
                {
                  uint64_t v142 = *(void *)(v137 + 24);
                  uint64_t v143 = *(unsigned int *)(v137 + 32);
                  if (v143)
                  {
                    uint64_t v144 = 8 * v143;
                    uint64_t v145 = *(void **)(v137 + 24);
                    while ((_DWORD *)*v145 != v129)
                    {
                      ++v145;
                      v144 -= 8;
                      if (!v144)
                      {
                        uint64_t v145 = (void *)(v142 + 8 * v143);
                        break;
                      }
                    }
                  }
                  else
                  {
                    uint64_t v145 = *(void **)(v137 + 24);
                  }
                  uint64_t v146 = ((uint64_t)v145 - v142) >> 3;
                  if (v146 != v143)
                  {
                    uint64_t v147 = *((void *)v131 + 1) + 40 * v136;
                    long long v256 = *(_OWORD *)v147;
                    long long v257 = *(_OWORD *)(v147 + 16);
                    uint64_t v258 = *(void *)(v147 + 32);
                    if (v135 < DWORD1(v272))
                    {
                      uint64_t v139 = (char *)v271 + 48 * v135;
                      __n128 v54 = *(__n128 *)v147;
                      long long v140 = *(_OWORD *)(v147 + 16);
                      uint64_t v141 = *(void *)(v147 + 32);
                      *(__n128 *)uint64_t v139 = v54;
                      *((_OWORD *)v139 + 1) = v140;
                      *((void *)v139 + 4) = v141;
                      *((void *)v139 + 5) = v146;
                    }
                    else
                    {
                      long long v263 = v256;
                      long long v264 = v257;
                      uint64_t v265 = (unint64_t *)v258;
                      uint64_t v266 = (void *)v146;
                      unint64_t v148 = v135 + 1;
                      BOOL v149 = (char *)v271 + 48 * v135 > (char *)&v263;
                      if (v271 <= &v263 && v149)
                      {
                        int64_t v154 = (char *)&v263 - (unsigned char *)v271;
                        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v271, (char *)&v272 + 8, v148, 48);
                        uint64_t v151 = (char *)v271;
                        uint64_t v150 = (__n128 *)((char *)v271 + v154);
                      }
                      else
                      {
                        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v271, (char *)&v272 + 8, v148, 48);
                        uint64_t v150 = (__n128 *)&v263;
                        uint64_t v151 = (char *)v271;
                      }
                      uint64_t v152 = (__n128 *)&v151[48 * v272];
                      __n128 v54 = *v150;
                      __n128 v153 = v150[2];
                      v152[1] = v150[1];
                      v152[2] = v153;
                      *uint64_t v152 = v54;
                    }
                    unsigned int v135 = v272 + 1;
                    LODWORD(v272) = v272 + 1;
                  }
                  ++v136;
                  v137 += 56;
                }
                while (v137 != v138);
                uint64_t v155 = (char *)v271;
                if (v135)
                {
                  unint64_t v156 = v135;
                  uint64_t v157 = (char *)v271 + 48 * v135;
                  unint64_t v158 = v135;
                  if (v135 < 0x81)
                  {
LABEL_255:
                  }
                  else
                  {
                    while (1)
                    {
                      uint64_t v159 = operator new(48 * v158, MEMORY[0x263F8C180]);
                      if (v159) {
                        break;
                      }
                      BOOL v160 = v158 > 1;
                      v158 >>= 1;
                      if (!v160) {
                        goto LABEL_255;
                      }
                    }
                    uint64_t v165 = v159;
                    operator delete(v165);
                  }
                  uint64_t v155 = (char *)v271;
                  uint64_t v161 = *(void **)v271;
                  uint64_t v164 = *((void *)v271 + 1);
                  uint64_t v163 = *((void *)v271 + 2);
                  uint64_t v162 = *((void *)v271 + 3);
                }
                else
                {
                  uint64_t v161 = 0;
                  uint64_t v162 = -1;
                  uint64_t v163 = -1;
                  uint64_t v164 = -1;
                }
                if (v155 != (char *)&v272 + 8) {
                  free(v155);
                }
                BOOL v132 = v164 == -1 || v163 == -1;
                if (!v132 && v162 != -1) {
                  break;
                }
              }
              ++v130;
              v131 += 1000;
              if (v131 == v241) {
                goto LABEL_278;
              }
            }
            uint64_t DefiningOp = mlir::Value::getDefiningOp((mlir::Value *)&v260);
            if (!DefiningOp
              || (uint64_t v167 = DefiningOp,
                  !mlir::OpInterface<mlir::MemoryMapperInterface,mlir::detail::MemoryMapperInterfaceInterfaceTraits>::getInterfaceFor(DefiningOp))
              || (mlir::OpInterface<mlir::MemoryMapperInterface,mlir::detail::MemoryMapperInterfaceInterfaceTraits>::getInterfaceFor(v167),
                  uint64_t v242 = *(unsigned int *)(v167 + 36),
                  v242 < 2)
              || v161 == v260)
            {
              uint64_t v33 = this;
LABEL_271:
              uint64_t v171 = *(void *)(*((void *)v33 + 13) + 8 * v130);
              long long v271 = v129;
              *(void *)&long long v272 = v163;
              *((void *)&v272 + 1) = v171;
              llvm::MapVector<mlir::Value,mlir::dataflow::TensorAllocAnalysis::AllocInfo,llvm::DenseMap<mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>,llvm::SmallVector<std::pair<mlir::Value,mlir::dataflow::TensorAllocAnalysis::AllocInfo>,0u>>::try_emplace<mlir::dataflow::TensorAllocAnalysis::AllocInfo>(v233, (unint64_t *)&v271, &v272);
              uint64_t v172 = v239;
              goto LABEL_221;
            }
            uint64_t v168 = 0;
            uint64_t v232 = (mlir::detail::OpResultImpl *)(v167 - 16);
            unint64_t v169 = v164;
            while (1)
            {
              NextResultAtOffset = (_DWORD *)mlir::detail::OpResultImpl::getNextResultAtOffset((uint64_t)v232, v168);
              mlir::detail::AllocRange::getRangeForValue(NextResultAtOffset, v169, (uint64_t)&v263);
              if (*((uint64_t *)&v264 + 1) > v162)
              {
                uint64_t v173 = mlir::Value::getLoc((mlir::Value *)&v260);
                *(void *)&long long v256 = "Attempted to subdivide a range that isn't large enough. This usually happens when the"
                                   " requested alignment is incompatible with your tensor shapes. The required alignment was: ";
                LOWORD(v258) = 259;
                mlir::emitError(v173, (uint64_t)&v256, (uint64_t)&v271);
                if (v271)
                {
                  LODWORD(__b) = 2;
                  v269 = v265;
                  unint64_t v174 = v273;
                  if (v274 >= v275)
                  {
                    unint64_t v181 = v274 + 1;
                    if (v273 <= (unint64_t)&__b && v273 + 24 * v274 > (unint64_t)&__b)
                    {
                      uint64_t v182 = (char *)&__b - v273;
                      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v273, v276, v181, 24);
                      unint64_t v174 = v273;
                      p_b = (void **)&v182[v273];
                    }
                    else
                    {
                      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v273, v276, v181, 24);
                      p_b = &__b;
                      unint64_t v174 = v273;
                    }
                  }
                  else
                  {
                    p_b = &__b;
                  }
                  unint64_t v176 = v174 + 24 * v274;
                  long long v177 = *(_OWORD *)p_b;
                  *(void *)(v176 + 16) = p_b[2];
                  *(_OWORD *)unint64_t v176 = v177;
                  ++v274;
                  if (v271) {
                    mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v271);
                  }
                }
                std::__optional_destruct_base<mlir::Diagnostic,false>::~__optional_destruct_base[abi:nn180100]((uint64_t)&v272);
                goto LABEL_278;
              }
              if (v260 == NextResultAtOffset) {
                break;
              }
              unint64_t v169 = *((void *)&v264 + 1) + 1;
              if (v242 == ++v168) {
                goto LABEL_283;
              }
            }
            uint64_t v164 = *((void *)&v263 + 1);
            uint64_t v162 = *((void *)&v264 + 1);
            uint64_t v163 = v264;
LABEL_283:
            uint64_t v33 = this;
            if (v164 != -1 && v163 != -1 && v162 != -1) {
              goto LABEL_271;
            }
          }
          else
          {
LABEL_278:
            uint64_t v33 = this;
          }
          uint64_t v172 = v239;
          if ((~v129[2] & 7) != 0)
          {
            long long v271 = v129;
            uint64_t v178 = mlir::Value::getDefiningOp((mlir::Value *)&v271);
            if (v178)
            {
              uint64_t v179 = v178;
              uint64_t v180 = mlir::TypeID::get<mlir::OpTrait::ConstantLike<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::ConstantLike>(void)::Empty>>();
              (*(void (**)(void, uint64_t))(**(void **)(v179 + 48) + 32))(*(void *)(v179 + 48), v180);
            }
          }
          uint64_t v128 = *((void *)v33 + 18);
          long long v271 = v129;
          *(void *)&long long v272 = -1;
          *((void *)&v272 + 1) = v128;
          llvm::MapVector<mlir::Value,mlir::dataflow::TensorAllocAnalysis::AllocInfo,llvm::DenseMap<mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>,llvm::SmallVector<std::pair<mlir::Value,mlir::dataflow::TensorAllocAnalysis::AllocInfo>,0u>>::try_emplace<mlir::dataflow::TensorAllocAnalysis::AllocInfo>(v233, (unint64_t *)&v271, &v272);
LABEL_221:
          uint64_t v127 = v172 + 1;
        }
        while (v127 != v236);
      }
    }
LABEL_291:
    uint64_t v183 = v254;
    uint64_t v184 = *((unsigned int *)v33 + 18);
    int v185 = v254 - v184;
    if (v254 == v184)
    {
      unsigned int v186 = v254;
      if (!v254) {
        goto LABEL_62;
      }
LABEL_300:
      uint64_t v192 = (char *)v253;
      uint64_t v193 = *v230;
      BOOL v194 = (char *)v253 + 8;
      uint64_t v195 = 1000 * v183;
      while (2)
      {
        uint64_t v196 = *((void *)v194 - 1);
        if (v196 == -1)
        {
          unsigned int v198 = *((_DWORD *)v194 + 2);
          if (!v198)
          {
            uint64_t v197 = 0;
            goto LABEL_305;
          }
          uint64_t v196 = *(void *)(*(void *)v194 + 40 * v198 - 16);
        }
        if (v196) {
          uint64_t v197 = v196 + 1;
        }
        else {
          uint64_t v197 = 0;
        }
LABEL_305:
        if (*v193 > v197) {
          uint64_t v197 = *v193;
        }
        *v193++ = v197;
        v194 += 1000;
        v195 -= 1000;
        if (!v195)
        {
          if (!(_BYTE)v252) {
            goto LABEL_62;
          }
          uint64_t v199 = &v192[1000 * v186];
          while (2)
          {
            BOOL v202 = (void *)*((void *)v192 + 1);
            uint64_t v203 = *((unsigned int *)v192 + 4);
            uint64_t v204 = &v202[5 * v203];
            if (v203)
            {
              uint64_t v205 = 40 * v203;
              while (1)
              {
                BOOL v206 = v202[1] == -1 || v202[2] == -1;
                if (v206 || v202[3] == -1) {
                  break;
                }
                if ((~*(_DWORD *)(*v202 + 8) & 7) != 0)
                {
                  uint64_t v208 = (mlir::Operation *)mlir::Value::getDefiningOp((mlir::Value *)v202);
                  if (mlir::Operation::isBeforeInBlock((mlir::Block **)v240, v208) || v208 == v240) {
                    break;
                  }
                }
                v202 += 5;
                v205 -= 40;
                if (!v205)
                {
                  BOOL v202 = v204;
                  goto LABEL_349;
                }
              }
            }
            uint64_t v209 = v202 + 5;
            if (v202 != v204 && v209 != v204)
            {
              do
              {
                if (v209[1] != -1 && v209[2] != -1 && v209[3] != -1)
                {
                  if ((~*(_DWORD *)(*v209 + 8) & 7) == 0
                    || (uint64_t v215 = (mlir::Operation *)mlir::Value::getDefiningOp((mlir::Value *)v209),
                        !mlir::Operation::isBeforeInBlock((mlir::Block **)v240, v215))
                    && v215 != v240)
                  {
                    long long v211 = *(_OWORD *)v209;
                    long long v212 = *((_OWORD *)v209 + 1);
                    v202[4] = v209[4];
                    *(_OWORD *)BOOL v202 = v211;
                    *((_OWORD *)v202 + 1) = v212;
                    v202 += 5;
                  }
                }
                v209 += 5;
              }
              while (v209 != v204);
            }
LABEL_349:
            uint64_t v216 = (void *)*((void *)v192 + 1);
            unint64_t v217 = 0xCCCCCCCCCCCCCCCDLL * (v202 - v216);
            *((_DWORD *)v192 + 4) = v217;
            uint64_t v200 = *((void *)v192 + 53);
            unsigned int v201 = *((_DWORD *)v192 + 108);
            uint64_t v218 = v200 + 56 * v201;
            uint64_t v219 = v200;
            if (v201 && (uint64_t v219 = *((void *)v192 + 53), v217))
            {
              uint64_t v219 = *((void *)v192 + 53);
              do
              {
                unint64_t v220 = 0xFFFFFFF800000008 * (v202 - v216);
                uint64_t v221 = v216;
                while (*v221 != **(void **)(v219 + 24))
                {
                  v221 += 5;
                  v220 -= 40;
                  if (!v220) {
                    goto LABEL_358;
                  }
                }
                v219 += 56;
              }
              while (v219 != v218);
LABEL_368:
              uint64_t v223 = v200 + 56 * v201;
            }
            else
            {
LABEL_358:
              if (v219 == v218) {
                goto LABEL_368;
              }
              uint64_t v222 = v219 + 56;
              if (v219 + 56 == v218)
              {
                uint64_t v223 = v219;
              }
              else
              {
                uint64_t v223 = v219;
                do
                {
                  uint64_t v224 = v219;
                  uint64_t v219 = v222;
                  uint64_t v225 = *((unsigned int *)v192 + 4);
                  if (v225)
                  {
                    uint64_t v226 = (void *)*((void *)v192 + 1);
                    uint64_t v227 = 40 * v225;
                    do
                    {
                      if (*v226 == **(void **)(v224 + 80)) {
                        llvm::deallocate_buffer(*(llvm **)v223, (void *)(8 * *(unsigned int *)(v223 + 16)));
                      }
                      v226 += 5;
                      v227 -= 40;
                    }
                    while (v227);
                  }
                  uint64_t v222 = v219 + 56;
                }
                while (v219 + 56 != v218);
                uint64_t v200 = *((void *)v192 + 53);
                unsigned int v201 = *((_DWORD *)v192 + 108);
              }
            }
            llvm::SmallVectorImpl<llvm::SmallSetVector<mlir::Value,2u>>::erase((uint64_t *)v192 + 53, v223, v200 + 56 * v201);
            v192 += 1000;
            if (v192 == v199) {
              goto LABEL_62;
            }
            continue;
          }
        }
        continue;
      }
    }
    if (v254 >= v184)
    {
      int v188 = v254;
      unsigned int v189 = *((_DWORD *)v33 + 19);
      unsigned int v186 = v254;
      uint64_t v190 = v184;
      int v191 = v184;
      if (v189 < v254)
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)v230, v228, v254, 8);
        uint64_t v190 = *((unsigned int *)this + 18);
        int v188 = v254;
        unsigned int v186 = v254;
        int v191 = *((_DWORD *)this + 18);
      }
      bzero(&(*v230)[v190], 8 * (v183 - v184));
      int v187 = v185 + v191;
      LODWORD(v183) = v188;
    }
    else
    {
      unsigned int v186 = v254;
      int v187 = v254;
    }
    *((_DWORD *)this + 18) = v187;
    if (v186) {
      goto LABEL_300;
    }
LABEL_62:
    uint64_t v52 = *v231;
    uint64_t v33 = this;
    if (*v231 != v229) {
      continue;
    }
    break;
  }
  LODWORD(v35) = v254;
LABEL_371:
  if (v253 != v255) {
    free(v253);
  }
  mlir::AsmState::~AsmState(&v244);
}

uint64_t llvm::SmallVectorImpl<mlir::Attribute>::insert<mlir::Attribute const*,void>(uint64_t a1, uint64_t a2, char *__src, char *a4)
{
  uint64_t v7 = *(void *)a1;
  uint64_t v8 = (a2 - *(void *)a1) >> 3;
  uint64_t v10 = *(unsigned int *)(a1 + 8);
  unint64_t v9 = *(unsigned int *)(a1 + 12);
  unsigned int v11 = *(_DWORD *)(a1 + 8);
  size_t v12 = a4 - __src;
  unint64_t v13 = (a4 - __src) >> 3;
  unint64_t v14 = v13 + v10;
  if (*(void *)a1 + 8 * v10 != a2)
  {
    if (v14 > v9)
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod(a1, (void *)(a1 + 16), v14, 8);
      uint64_t v7 = *(void *)a1;
      uint64_t v10 = *(unsigned int *)(a1 + 8);
      unsigned int v11 = *(_DWORD *)(a1 + 8);
    }
    uint64_t v15 = (char *)(v7 + 8 * v10);
    __srca = (char *)(v7 + 8 * v8);
    size_t v16 = v15 - __srca;
    unint64_t v17 = (v15 - __srca) >> 3;
    if (v17 < v13)
    {
      unsigned int v18 = v11 + (v12 >> 3);
      *(_DWORD *)(a1 + 8) = v18;
      if (v8 == v10)
      {
        char v19 = __src;
        uint64_t v21 = v7 + 8 * v8;
        uint64_t v20 = a4;
        goto LABEL_34;
      }
      uint64_t v21 = v7 + 8 * v8;
      memcpy((void *)(v7 + 8 * v18 - 8 * v17), __srca, v16);
      if (v16 < 0x20 || (unint64_t)(__srca - __src) < 0x20)
      {
        uint64_t v28 = (char *)(v7 + 8 * v8);
        uint64_t v29 = (v15 - __srca) >> 3;
        char v19 = __src;
        uint64_t v20 = a4;
      }
      else
      {
        unint64_t v27 = 8 * (v17 & 0xFFFFFFFFFFFFFFFCLL);
        uint64_t v28 = &__srca[v27];
        uint64_t v29 = (v16 >> 3) & 3;
        char v19 = &__src[v27];
        unsigned int v30 = (long long *)(__src + 16);
        uint64_t v31 = (_OWORD *)(v7 + 8 * v8 + 16);
        unint64_t v32 = v17 & 0xFFFFFFFFFFFFFFFCLL;
        do
        {
          long long v33 = *v30;
          *(v31 - 1) = *(v30 - 1);
          *uint64_t v31 = v33;
          v30 += 2;
          v31 += 2;
          v32 -= 4;
        }
        while (v32);
        uint64_t v20 = a4;
        if (v17 == (v17 & 0xFFFFFFFFFFFFFFFCLL))
        {
LABEL_34:
          if (v19 != v20) {
            memcpy(v15, v19, v20 - v19);
          }
          return v21;
        }
      }
      do
      {
        uint64_t v42 = *(void *)v19;
        v19 += 8;
        *(void *)uint64_t v28 = v42;
        v28 += 8;
        --v29;
      }
      while (v29);
      goto LABEL_34;
    }
    uint64_t v22 = 8 * v13;
    uint64_t v23 = v10;
    if (v13 + v10 > *(unsigned int *)(a1 + 12))
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod(a1, (void *)(a1 + 16), v13 + v10, 8);
      uint64_t v23 = *(unsigned int *)(a1 + 8);
      unsigned int v11 = *(_DWORD *)(a1 + 8);
    }
    uint64_t v24 = &v15[-v22];
    if (a4 == __src) {
      goto LABEL_28;
    }
    uint64_t v25 = (void *)(*(void *)a1 + 8 * v23);
    if (v12 - 8 >= 0x78)
    {
      uint64_t v34 = 8 * v23 + *(void *)a1;
      int64_t v26 = &v15[-v22];
      if ((v12 & 0xFFFFFFFFFFFFFFF8) - v7 - 8 * v10 + v34 >= 0x20)
      {
        unint64_t v35 = ((v12 - 8) >> 3) + 1;
        uint64_t v36 = 8 * (v35 & 0x3FFFFFFFFFFFFFFCLL);
        uint64_t v25 = (void *)((char *)v25 + v36);
        int64_t v26 = &v24[v36];
        unint64_t v37 = (long long *)(8 * v10 - 8 * v13 + v7 + 16);
        uint64_t v38 = (_OWORD *)(v34 + 16);
        uint64_t v39 = v35 & 0x3FFFFFFFFFFFFFFCLL;
        do
        {
          long long v40 = *v37;
          *(v38 - 1) = *(v37 - 1);
          _OWORD *v38 = v40;
          v37 += 2;
          v38 += 2;
          v39 -= 4;
        }
        while (v39);
        if (v35 == (v35 & 0x3FFFFFFFFFFFFFFCLL)) {
          goto LABEL_28;
        }
      }
    }
    else
    {
      int64_t v26 = &v15[-v22];
    }
    do
    {
      uint64_t v41 = *(void *)v26;
      v26 += 8;
      *v25++ = v41;
    }
    while (v26 != v15);
LABEL_28:
    *(_DWORD *)(a1 + 8) = v11 + v13;
    uint64_t v21 = v7 + 8 * v8;
    if (v24 != __srca) {
      memmove(&__srca[v22], __srca, &v15[-v22] - __srca);
    }
    if (a4 != __src) {
      memmove(__srca, __src, v12);
    }
    return v21;
  }
  if (v14 > v9)
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod(a1, (void *)(a1 + 16), v14, 8);
    unsigned int v11 = *(_DWORD *)(a1 + 8);
    uint64_t v7 = *(void *)a1;
  }
  if (__src != a4)
  {
    memcpy((void *)(v7 + 8 * v11), __src, v12);
    unsigned int v11 = *(_DWORD *)(a1 + 8);
    uint64_t v7 = *(void *)a1;
  }
  *(_DWORD *)(a1 + 8) = v11 + (v12 >> 3);
  return v7 + 8 * v8;
}

void mlir::dataflow::TensorAllocAnalysis::getAnalysis(mlir::dataflow::TensorAllocAnalysis *this, mlir::DataFlowSolver *a2, mlir::Operation *a3)
{
}

void mlir::dataflow::TensorAllocAnalysis::~TensorAllocAnalysis(mlir::dataflow::TensorAllocAnalysis *this)
{
  *(void *)this = &unk_26C380240;
  uint64_t v2 = (char *)*((void *)this + 13);
  if (v2 != (char *)this + 120) {
    free(v2);
  }
  uint64_t v3 = (char *)*((void *)this + 8);
  if (v3 != (char *)this + 80) {
    free(v3);
  }
  unint64_t v4 = (char *)*((void *)this + 6);
  if (v4 != (char *)this + 64) {
    free(v4);
  }
  llvm::deallocate_buffer(*((llvm **)this + 3), (void *)(16 * *((unsigned int *)this + 10)));
}

{
  char *v2;
  char *v3;
  char *v4;

  *(void *)this = &unk_26C380240;
  uint64_t v2 = (char *)*((void *)this + 13);
  if (v2 != (char *)this + 120) {
    free(v2);
  }
  uint64_t v3 = (char *)*((void *)this + 8);
  if (v3 != (char *)this + 80) {
    free(v3);
  }
  unint64_t v4 = (char *)*((void *)this + 6);
  if (v4 != (char *)this + 64) {
    free(v4);
  }
  llvm::deallocate_buffer(*((llvm **)this + 3), (void *)(16 * *((unsigned int *)this + 10)));
}

void sub_2113BB100(int a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12)
{
  uint64_t v13 = *((void *)v12 + 2);
  *((void *)v12 + 2) = 0;
  if (v13) {
    std::default_delete<mlir::Liveness>::operator()[abi:nn180100]((uint64_t)v12 + 16, v13);
  }
  ZinIrHalH13g::~ZinIrHalH13g(v12);
}

void sub_2113BB1B4(int a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12)
{
  uint64_t v13 = *((void *)v12 + 2);
  *((void *)v12 + 2) = 0;
  if (v13) {
    std::default_delete<mlir::Liveness>::operator()[abi:nn180100]((uint64_t)v12 + 16, v13);
  }
  ZinIrHalH13g::~ZinIrHalH13g(v12);
  JUMPOUT(0x21667D3C0);
}

uint64_t mlir::dataflow::SparseForwardDataFlowAnalysis<mlir::dataflow::Lattice<mlir::dataflow::OffsetLatticeValue>>::visitOperationImpl(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 64))();
}

uint64_t mlir::dataflow::SparseForwardDataFlowAnalysis<mlir::dataflow::Lattice<mlir::dataflow::OffsetLatticeValue>>::visitNonControlFlowArgumentsImpl(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 72))();
}

uint64_t mlir::dataflow::SparseForwardDataFlowAnalysis<mlir::dataflow::Lattice<mlir::dataflow::OffsetLatticeValue>>::getLatticeElement(uint64_t a1, uint64_t a2)
{
  return mlir::DataFlowSolver::getOrCreateState<mlir::dataflow::Lattice<mlir::dataflow::OffsetLatticeValue>,mlir::Value>(*(void *)(a1 + 8), a2);
}

uint64_t mlir::dataflow::SparseForwardDataFlowAnalysis<mlir::dataflow::Lattice<mlir::dataflow::OffsetLatticeValue>>::setToEntryState(uint64_t a1)
{
  return (*(uint64_t (**)(void))(*(void *)a1 + 80))();
}

uint64_t mlir::dataflow::SparseForwardDataFlowAnalysis<mlir::dataflow::Lattice<mlir::dataflow::OffsetLatticeValue>>::visitNonControlFlowArguments(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t *a4, unint64_t a5, unsigned int a6)
{
  uint64_t v10 = a6;
  if (a5 >= a6) {
    uint64_t v11 = a6;
  }
  else {
    uint64_t v11 = a5;
  }
  mlir::dataflow::AbstractSparseForwardDataFlowAnalysis::setAllToEntryStates(a1, a4, v11);
  uint64_t v12 = *(void *)(a3 + 16) + v10;

  return mlir::dataflow::AbstractSparseForwardDataFlowAnalysis::setAllToEntryStates(a1, &a4[v12], a5 - v12);
}

void mlir::dataflow::TensorAllocAnalysis::setToEntryState(uint64_t a1, uint64_t a2)
{
  v6[50] = *MEMORY[0x263EF8340];
  mlir::detail::AllocRange::getRangeForValue((_DWORD *)(*(void *)(a2 + 8) & 0xFFFFFFFFFFFFFFF8), 0xFFFFFFFFFFFFFFFFLL, (uint64_t)v6);
  v5[0] = v6;
  v5[1] = (void *)0xA00000001;
  int v4 = mlir::dataflow::Lattice<mlir::dataflow::OffsetLatticeValue>::join(a2, (uint64_t)v5);
  mlir::DataFlowAnalysis::propagateIfChanged(a1, a2, v4);
  if (v5[0] != v6) {
    free(v5[0]);
  }
}

uint64_t mlir::TypeID::get<mlir::ShapedType>()
{
  uint64_t v0 = &unk_267770000;
  {
    uint64_t v0 = (void *)&unk_267770000;
    if (v2)
    {
      uint64_t v10 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ShapedType]";
      unint64_t v11 = 66;
      unint64_t v3 = llvm::StringRef::find((uint64_t *)&v10, "DesiredTypeName = ", 0x12uLL, 0);
      if (v11 >= v3) {
        unint64_t v4 = v3;
      }
      else {
        unint64_t v4 = v11;
      }
      uint64_t v5 = &v10[v4];
      unint64_t v6 = v11 - v4;
      if (v11 - v4 >= 0x12) {
        uint64_t v7 = 18;
      }
      else {
        uint64_t v7 = v11 - v4;
      }
      unint64_t v8 = v6 - v7;
      if (v8 >= v8 - 1) {
        uint64_t v9 = v8 - 1;
      }
      else {
        uint64_t v9 = v8;
      }
      mlir::detail::TypeIDResolver<mlir::ShapedType,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v5[v7], v9);
      uint64_t v0 = (void *)&unk_267770000;
    }
  }
  return v0[381];
}

uint64_t mlir::OpInterface<mlir::MemoryMapperInterface,mlir::detail::MemoryMapperInterfaceInterfaceTraits>::getInterfaceFor(uint64_t a1)
{
  uint64_t v1 = *(void *)(a1 + 48);
  int v2 = *(void **)(v1 + 16);
  BOOL v3 = v2 == &mlir::detail::TypeIDResolver<void,void>::id;
  if (v2 == &mlir::detail::TypeIDResolver<void,void>::id) {
    uint64_t v4 = 0;
  }
  else {
    uint64_t v4 = *(void *)(a1 + 48);
  }
  if (v3)
  {
    uint64_t v22 = *(void *)(v1 + 8);
    uint64_t result = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)&v22);
    if (result)
    {
      uint64_t v20 = result;
      uint64_t v21 = mlir::TypeID::get<mlir::MemoryMapperInterface>();
      return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t))(*(void *)v20 + 104))(v20, v21, v1);
    }
  }
  else
  {
    unint64_t v6 = v4 | v1 & 0xFFFFFFFFFFFFFF00;
    unint64_t v7 = mlir::TypeID::get<mlir::MemoryMapperInterface>();
    unint64_t v8 = *(unsigned int *)(v6 + 40);
    if (!v8) {
      goto LABEL_14;
    }
    uint64_t v9 = *(void **)(v6 + 32);
    uint64_t v10 = &v9[2 * v8];
    do
    {
      unint64_t v11 = v8 >> 1;
      uint64_t v12 = &v9[2 * (v8 >> 1)];
      unint64_t v14 = *v12;
      uint64_t v13 = v12 + 2;
      v8 += ~(v8 >> 1);
      if (v14 < v7) {
        uint64_t v9 = v13;
      }
      else {
        unint64_t v8 = v11;
      }
    }
    while (v8);
    if (v9 == v10 || *v9 != v7 || (uint64_t result = v9[1]) == 0)
    {
LABEL_14:
      uint64_t v16 = *(void *)(v6 + 24);
      uint64_t v17 = *(void *)(a1 + 48);
      uint64_t v18 = mlir::TypeID::get<mlir::MemoryMapperInterface>();
      char v19 = *(uint64_t (**)(uint64_t, uint64_t, uint64_t))(*(void *)v16 + 104);
      return v19(v16, v18, v17);
    }
  }
  return result;
}

uint64_t mlir::TypeID::get<mlir::MemoryMapperInterface>()
{
  uint64_t v0 = &unk_267770000;
  {
    uint64_t v0 = (void *)&unk_267770000;
    if (v2)
    {
      uint64_t v10 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::MemoryMapperInterface]";
      unint64_t v11 = 77;
      unint64_t v3 = llvm::StringRef::find((uint64_t *)&v10, "DesiredTypeName = ", 0x12uLL, 0);
      if (v11 >= v3) {
        unint64_t v4 = v3;
      }
      else {
        unint64_t v4 = v11;
      }
      uint64_t v5 = &v10[v4];
      unint64_t v6 = v11 - v4;
      if (v11 - v4 >= 0x12) {
        uint64_t v7 = 18;
      }
      else {
        uint64_t v7 = v11 - v4;
      }
      unint64_t v8 = v6 - v7;
      if (v8 >= v8 - 1) {
        uint64_t v9 = v8 - 1;
      }
      else {
        uint64_t v9 = v8;
      }
      mlir::detail::TypeIDResolver<mlir::MemoryMapperInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v5[v7], v9);
      uint64_t v0 = (void *)&unk_267770000;
    }
  }
  return v0[383];
}

uint64_t llvm::SmallVectorImpl<mlir::detail::AllocRange>::operator=(uint64_t a1, uint64_t a2)
{
  if (a1 != a2)
  {
    uint64_t v5 = (const void *)(a2 + 16);
    unint64_t v4 = *(const void **)a2;
    if (v4 != v5)
    {
      unint64_t v6 = *(void **)a1;
      if (*(void *)a1 != a1 + 16)
      {
        free(v6);
        unint64_t v4 = *(const void **)a2;
      }
      *(void *)a1 = v4;
      uint64_t v7 = (_DWORD *)(a2 + 8);
      *(void *)(a1 + 8) = *(void *)(a2 + 8);
      *(void *)a2 = v5;
      *(_DWORD *)(a2 + 12) = 0;
      goto LABEL_17;
    }
    uint64_t v7 = (_DWORD *)(a2 + 8);
    unint64_t v8 = *(unsigned int *)(a2 + 8);
    uint64_t v9 = *(unsigned int *)(a1 + 8);
    if (v9 >= v8)
    {
      if (v8) {
        memmove(*(void **)a1, v4, 40 * v8);
      }
      goto LABEL_16;
    }
    if (*(_DWORD *)(a1 + 12) >= v8)
    {
      if (v9)
      {
        memmove(*(void **)a1, v4, 40 * v9);
        goto LABEL_14;
      }
    }
    else
    {
      *(_DWORD *)(a1 + 8) = 0;
      llvm::SmallVectorBase<unsigned int>::grow_pod(a1, (void *)(a1 + 16), v8, 40);
    }
    uint64_t v9 = 0;
LABEL_14:
    uint64_t v10 = *v7;
    if (v9 != v10) {
      memcpy((void *)(*(void *)a1 + 40 * v9), (const void *)(*(void *)a2 + 40 * v9), *(void *)a2 + 40 * v10 - (*(void *)a2 + 40 * v9));
    }
LABEL_16:
    *(_DWORD *)(a1 + 8) = v8;
LABEL_17:
    _DWORD *v7 = 0;
  }
  return a1;
}

void llvm::SmallVectorTemplateBase<anonymous namespace'::CurrentlyLive::Buffer,false>::destroy_range(uint64_t a1, uint64_t a2)
{
  if (a2 != a1)
  {
    uint64_t v2 = a2;
    do
    {
      uint64_t v4 = v2 - 1000;
      uint64_t v5 = *(void *)(v2 - 576);
      uint64_t v6 = *(unsigned int *)(v2 - 568);
      if (v6)
      {
        uint64_t v7 = 56 * v6;
        unint64_t v8 = *(void **)(v5 + v7 - 32);
        if ((void *)(v5 + v7 - 16) != v8) {
          free(v8);
        }
        llvm::deallocate_buffer(*(llvm **)(v5 + v7 - 56), (void *)(8 * *(unsigned int *)(v5 + v7 - 40)));
      }
      if (v5 != v2 - 560) {
        free(*(void **)(v2 - 576));
      }
      uint64_t v9 = *(void **)(v2 - 992);
      if (v9 != (void *)(v2 - 976)) {
        free(v9);
      }
      v2 -= 1000;
    }
    while (v4 != a1);
  }
}

uint64_t llvm::SmallVectorImpl<llvm::SmallSetVector<mlir::Value,2u>>::operator=(uint64_t a1, uint64_t *a2)
{
  if ((uint64_t *)a1 != a2)
  {
    uint64_t v4 = a2 + 2;
    if ((uint64_t *)*a2 == a2 + 2)
    {
      uint64_t v9 = a2 + 1;
      unint64_t v11 = *((unsigned int *)a2 + 2);
      uint64_t v12 = *(unsigned int *)(a1 + 8);
      if (v12 >= v11)
      {
        uint64_t v16 = *(llvm ***)a1;
        if (v11) {
          llvm::deallocate_buffer(*v16, (void *)(8 * *((unsigned int *)v16 + 4)));
        }
        if (&v16[7 * v12] != v16)
        {
          uint64_t v20 = &v16[7 * v12];
          uint64_t v21 = v20 - 2;
          uint64_t v22 = (llvm **)*(v20 - 4);
          if (v21 != v22) {
            free(v22);
          }
          llvm::deallocate_buffer(*(v21 - 5), (void *)(8 * *((unsigned int *)v21 - 6)));
        }
        *(_DWORD *)(a1 + 8) = 0;
        uint64_t v23 = *((unsigned int *)a2 + 2);
        if (v23)
        {
          uint64_t v24 = *a2;
          uint64_t v25 = 56 * v23;
          int64_t v26 = *(void **)(v24 + v25 - 32);
          if ((void *)(v24 + v25 - 16) != v26) {
            free(v26);
          }
          llvm::deallocate_buffer(*(llvm **)(v24 + v25 - 56), (void *)(8 * *(unsigned int *)(v24 + v25 - 40)));
        }
      }
      else
      {
        if (*(_DWORD *)(a1 + 12) >= v11)
        {
          uint64_t v17 = *(llvm ***)a1;
          if (v12) {
            llvm::deallocate_buffer(*v17, (void *)(8 * *((unsigned int *)v17 + 4)));
          }
        }
        else
        {
          if (v12)
          {
            uint64_t v13 = *(llvm ***)a1;
            uint64_t v14 = 7 * v12;
            uint64_t v15 = (llvm **)v13[v14 - 4];
            if (&v13[v14 - 2] != v15) {
              free(v15);
            }
            llvm::deallocate_buffer(v13[v14 - 7], (void *)(8 * LODWORD(v13[v14 - 5])));
          }
          *(_DWORD *)(a1 + 8) = 0;
          unint64_t v35 = 0;
          uint64_t v18 = a1 + 16;
          uint64_t v17 = (llvm **)llvm::SmallVectorBase<unsigned int>::mallocForGrow(a1, (void *)(a1 + 16), v11, 56, &v35);
          llvm::SmallVectorTemplateBase<llvm::SmallSetVector<mlir::Value,2u>,false>::moveElementsForGrow(a1, (uint64_t)v17);
          int v19 = v35;
          if (*(void *)a1 != v18) {
            free(*(void **)a1);
          }
          *(void *)a1 = v17;
          *(_DWORD *)(a1 + 12) = v19;
        }
        uint64_t v27 = *a2;
        if (*((_DWORD *)a2 + 2))
        {
          uint64_t v28 = v27 + 56 * *((unsigned int *)a2 + 2);
          do
          {
            uint64_t v29 = v27;
            unint64_t *v17 = 0;
            v17[1] = 0;
            *((_DWORD *)v17 + 4) = 0;
            unint64_t *v17 = *(llvm **)v27;
            *(void *)uint64_t v27 = 0;
            *((_DWORD *)v17 + 2) = *(_DWORD *)(v27 + 8);
            *(_DWORD *)(v27 + 8) = 0;
            v17[3] = (llvm *)(v17 + 5);
            int v30 = *((_DWORD *)v17 + 3);
            *((_DWORD *)v17 + 3) = *(_DWORD *)(v27 + 12);
            *(_DWORD *)(v27 + 12) = v30;
            int v31 = *((_DWORD *)v17 + 4);
            *((_DWORD *)v17 + 4) = *(_DWORD *)(v27 + 16);
            *(_DWORD *)(v27 + 16) = v31;
            v17[4] = (llvm *)0x200000000;
            if (*(_DWORD *)(v27 + 32)) {
              llvm::SmallVectorImpl<mlir::Value>::operator=((uint64_t)(v17 + 3), v27 + 24);
            }
            v17 += 7;
            v27 += 56;
          }
          while (v29 + 56 != v28);
          uint64_t v27 = *a2;
        }
        *(_DWORD *)(a1 + 8) = v11;
        uint64_t v32 = *v9;
        if (v32)
        {
          uint64_t v33 = 56 * v32;
          uint64_t v34 = *(void **)(v27 + v33 - 32);
          if ((void *)(v27 + v33 - 16) != v34) {
            free(v34);
          }
          llvm::deallocate_buffer(*(llvm **)(v27 + v33 - 56), (void *)(8 * *(unsigned int *)(v27 + v33 - 40)));
        }
      }
    }
    else
    {
      uint64_t v5 = *(char **)a1;
      uint64_t v6 = *(unsigned int *)(a1 + 8);
      if (v6)
      {
        uint64_t v7 = 56 * v6;
        unint64_t v8 = *(char **)&v5[v7 - 32];
        if (&v5[v7 - 16] != v8) {
          free(v8);
        }
        llvm::deallocate_buffer(*(llvm **)&v5[v7 - 56], (void *)(8 * *(unsigned int *)&v5[v7 - 40]));
      }
      if (v5 != (char *)(a1 + 16)) {
        free(*(void **)a1);
      }
      *(void *)a1 = *a2;
      uint64_t v9 = a2 + 1;
      *(void *)(a1 + 8) = a2[1];
      *a2 = (uint64_t)v4;
      *((_DWORD *)a2 + 3) = 0;
    }
    *uint64_t v9 = 0;
  }
  return a1;
}

uint64_t llvm::SmallVectorImpl<mlir::Value>::operator=(uint64_t a1, uint64_t a2)
{
  if (a1 != a2)
  {
    uint64_t v5 = (const void *)(a2 + 16);
    uint64_t v4 = *(const void **)a2;
    if (v4 != v5)
    {
      uint64_t v6 = *(void **)a1;
      if (*(void *)a1 != a1 + 16)
      {
        free(v6);
        uint64_t v4 = *(const void **)a2;
      }
      *(void *)a1 = v4;
      uint64_t v7 = (_DWORD *)(a2 + 8);
      *(void *)(a1 + 8) = *(void *)(a2 + 8);
      *(void *)a2 = v5;
      *(_DWORD *)(a2 + 12) = 0;
      goto LABEL_17;
    }
    uint64_t v7 = (_DWORD *)(a2 + 8);
    unint64_t v8 = *(unsigned int *)(a2 + 8);
    uint64_t v9 = *(unsigned int *)(a1 + 8);
    if (v9 >= v8)
    {
      if (v8) {
        memmove(*(void **)a1, v4, 8 * v8);
      }
      goto LABEL_16;
    }
    if (*(_DWORD *)(a1 + 12) >= v8)
    {
      if (v9)
      {
        memmove(*(void **)a1, v4, 8 * v9);
        goto LABEL_14;
      }
    }
    else
    {
      *(_DWORD *)(a1 + 8) = 0;
      llvm::SmallVectorBase<unsigned int>::grow_pod(a1, (void *)(a1 + 16), v8, 8);
    }
    uint64_t v9 = 0;
LABEL_14:
    uint64_t v10 = *v7;
    if (v9 != v10) {
      memcpy((void *)(*(void *)a1 + 8 * v9), (const void *)(*(void *)a2 + 8 * v9), *(void *)a2 + 8 * v10 - (*(void *)a2 + 8 * v9));
    }
LABEL_16:
    *(_DWORD *)(a1 + 8) = v8;
LABEL_17:
    _DWORD *v7 = 0;
  }
  return a1;
}

uint64_t llvm::SmallVectorTemplateBase<llvm::SmallSetVector<mlir::Value,2u>,false>::moveElementsForGrow(uint64_t result, uint64_t a2)
{
  unsigned int v2 = *(_DWORD *)(result + 8);
  if (v2)
  {
    uint64_t v4 = result;
    uint64_t v5 = 0;
    uint64_t v6 = *(void *)result;
    uint64_t v7 = *(void *)result + 56 * v2;
    do
    {
      uint64_t v8 = v6 + v5;
      uint64_t v9 = a2 + v5;
      *(void *)uint64_t v9 = 0;
      *(void *)(v9 + 8) = 0;
      *(_DWORD *)(v9 + 16) = 0;
      *(void *)uint64_t v9 = *(void *)(v6 + v5);
      *(void *)uint64_t v8 = 0;
      *(_DWORD *)(v9 + 8) = *(_DWORD *)(v6 + v5 + 8);
      *(_DWORD *)(v8 + 8) = 0;
      *(void *)(a2 + v5 + 24) = a2 + v5 + 40;
      uint64_t result = a2 + v5 + 24;
      int v10 = *(_DWORD *)(a2 + v5 + 12);
      *(_DWORD *)(result - 12) = *(_DWORD *)(v6 + v5 + 12);
      *(_DWORD *)(v8 + 12) = v10;
      int v11 = *(_DWORD *)(a2 + v5 + 16);
      *(_DWORD *)(v9 + 16) = *(_DWORD *)(v6 + v5 + 16);
      *(_DWORD *)(v8 + 16) = v11;
      *(void *)(result + 8) = 0x200000000;
      if (*(_DWORD *)(v6 + v5 + 32)) {
        uint64_t result = llvm::SmallVectorImpl<mlir::Value>::operator=(result, v8 + 24);
      }
      v5 += 56;
    }
    while (v8 + 56 != v7);
    uint64_t v12 = *(unsigned int *)(v4 + 8);
    if (v12)
    {
      uint64_t v13 = *(void *)v4;
      uint64_t v14 = 56 * v12;
      uint64_t v15 = *(void **)(v13 + v14 - 32);
      if ((void *)(v13 + v14 - 16) != v15) {
        free(v15);
      }
      llvm::deallocate_buffer(*(llvm **)(v13 + v14 - 56), (void *)(8 * *(unsigned int *)(v13 + v14 - 40)));
    }
  }
  return result;
}

uint64_t anonymous namespace'::CurrentlyLive::Buffer::findSlotsFor(uint64_t a1, void *a2, uint64_t a3, uint64_t a4)
{
  v46[70] = *MEMORY[0x263EF8340];
  if (!a3) {
    return 0;
  }
  if (a3 != 1)
  {
    uint64_t v41 = -1;
    uint64_t v42 = &v44;
    uint64_t v43 = 0xA00000000;
    v45[0] = v46;
    v45[1] = (void *)0xA00000000;
    uint64_t v10 = *(void *)(a1 + 8);
    uint64_t v11 = *(unsigned int *)(a1 + 16);
    if (v11)
    {
      uint64_t v12 = 40 * v11;
      uint64_t v13 = *(void **)(a1 + 8);
      do
      {
        if (*v13 == *a2) {
          goto LABEL_16;
        }
        v13 += 5;
        v12 -= 40;
      }
      while (v12);
      uint64_t v13 = (void *)(v10 + 40 * v11);
    }
    else
    {
      uint64_t v13 = *(void **)(a1 + 8);
    }
LABEL_16:
    uint64_t v14 = (uint64_t)v13 - v10;
    if (v14 != -40 && 0xCCCCCCCCCCCCCCCDLL * (v14 >> 3) != v11)
    {
      int64_t v26 = (long long *)(v10 + 8 * (v14 >> 3));
      long long v27 = *v26;
      long long v28 = v26[1];
      uint64_t v36 = *((void *)v26 + 4);
      v35[0] = v27;
      v35[1] = v28;
      v38[0] = 0;
      long long v39 = 0u;
      uint64_t v40 = 0;
      *(_OWORD *)unint64_t v37 = 0u;
      v38[1] = (char *)&v39 + 8;
      DWORD1(v39) = 2;
      uint64_t v30 = 40 * v43;
      llvm::SmallVectorImpl<llvm::SmallSetVector<mlir::Value,2u>>::insert_one_impl<llvm::SmallSetVector<mlir::Value,2u> const&>((uint64_t)v45, (uint64_t)v45[0] - 0x3333333333333328 * (v30 >> 3), (unint64_t)v37);
      int v31 = (char *)v42 + v30;
      uint64_t v32 = v35;
      goto LABEL_33;
    }
    unint64_t v17 = a2[4];
    unint64_t v18 = FirstSlotFor;
    if (v17) {
      unint64_t v18 = (FirstSlotFor + v17 - 1) / v17 * v17;
    }
    unint64_t v19 = a2[3] - a2[2] + v18;
    v34[0] = *a2;
    v34[1] = FirstSlotFor;
    void v34[2] = v18;
    v34[3] = v19;
    void v34[4] = v17;
    v38[0] = 0;
    long long v39 = 0u;
    uint64_t v40 = 0;
    *(_OWORD *)unint64_t v37 = 0u;
    v38[1] = (char *)&v39 + 8;
    DWORD1(v39) = 2;
    unint64_t v20 = v43;
    if (!v43)
    {
      uint64_t v22 = (char *)v42 + 40 * v43;
LABEL_32:
      uint64_t v29 = v22 - (unsigned char *)v42;
      llvm::SmallVectorImpl<llvm::SmallSetVector<mlir::Value,2u>>::insert_one_impl<llvm::SmallSetVector<mlir::Value,2u> const&>((uint64_t)v45, (uint64_t)v45[0] - 0x3333333333333328 * ((v22 - (unsigned char *)v42) >> 3), (unint64_t)v37);
      int v31 = (char *)v42 + v29;
      uint64_t v32 = v34;
LABEL_33:
      llvm::SmallVectorImpl<mlir::detail::AllocRange>::insert_one_impl<mlir::detail::AllocRange const&>((uint64_t)&v42, (unint64_t)v31, (unint64_t)v32);
      if (v38[1] != (char *)&v39 + 8) {
        free(v38[1]);
      }
      llvm::deallocate_buffer(v37[0], (void *)(8 * LODWORD(v38[0])));
    }
    uint64_t v21 = v19 - FirstSlotFor + 1;
    uint64_t v22 = (char *)v42;
    while (1)
    {
      unint64_t v23 = v20 >> 1;
      uint64_t v24 = &v22[40 * (v20 >> 1)];
      uint64_t v25 = *((void *)v24 + 1);
      if (FirstSlotFor == v25)
      {
        if (v21 >= *(void *)&v22[40 * v23 + 24] - FirstSlotFor + 1) {
          goto LABEL_30;
        }
      }
      else if (FirstSlotFor >= v25)
      {
LABEL_30:
        uint64_t v22 = v24 + 40;
        unint64_t v23 = v20 + ~v23;
      }
      unint64_t v20 = v23;
      if (!v23) {
        goto LABEL_32;
      }
    }
  }
  if (v6 == -1) {
    return 0;
  }
  uint64_t v7 = v6;
  uint64_t v8 = *(unsigned int *)(a4 + 8);
  if (v8 >= *(_DWORD *)(a4 + 12))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod(a4, (void *)(a4 + 16), v8 + 1, 8);
    LODWORD(v8) = *(_DWORD *)(a4 + 8);
  }
  *(void *)(*(void *)a4 + 8 * v8) = v7;
  ++*(_DWORD *)(a4 + 8);
  return 1;
}

uint64_t llvm::SetVector<mlir::Value,llvm::SmallVector<mlir::Value,2u>,llvm::DenseSet<mlir::Value,llvm::DenseMapInfo<mlir::Value,void>>,2u>::insert(uint64_t a1, unint64_t *a2)
{
  if (!*(_DWORD *)(a1 + 8))
  {
    uint64_t v6 = (void **)(a1 + 24);
    uint64_t v7 = *(void **)(a1 + 24);
    uint64_t v8 = *(unsigned int *)(a1 + 32);
    uint64_t v9 = v7;
    if (v8)
    {
      uint64_t v10 = 8 * v8;
      uint64_t v9 = *(void **)(a1 + 24);
      while (*v9 != *a2)
      {
        ++v9;
        v10 -= 8;
        if (!v10)
        {
          uint64_t v9 = &v7[v8];
          break;
        }
      }
    }
    if (v8 == v9 - v7)
    {
      unint64_t v11 = *a2;
      if (v8 >= *(_DWORD *)(a1 + 36))
      {
        uint64_t v16 = (void **)(a1 + 24);
        llvm::SmallVectorBase<unsigned int>::grow_pod(a1 + 24, (void *)(a1 + 40), v8 + 1, 8);
        uint64_t v6 = v16;
        uint64_t v8 = *(unsigned int *)(a1 + 32);
        uint64_t v7 = *(void **)(a1 + 24);
      }
      v7[v8] = v11;
      unsigned int v12 = *(_DWORD *)(a1 + 32) + 1;
      *(_DWORD *)(a1 + 32) = v12;
      if (v12 >= 3)
      {
        uint64_t v13 = *v6;
        uint64_t v14 = 8 * v12;
        do
        {
          unint64_t v17 = 0;
          if ((llvm::DenseMapBase<llvm::DenseMap<mlir::Value,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseSetPair<mlir::Value>>,mlir::Value,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseSetPair<mlir::Value>>::LookupBucketFor<mlir::Value>((uint64_t *)a1, v13, &v17) & 1) == 0)*llvm::DenseMapBase<llvm::DenseMap<mlir::Value,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseSetPair<mlir::Value>>,mlir::Value,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseSetPair<mlir::Value>>::InsertIntoBucketImpl<mlir::Value>(a1, (uint64_t)v13, v13, v17) = *v13; {
          ++v13;
          }
          v14 -= 8;
        }
        while (v14);
      }
      return 1;
    }
    return 0;
  }
  unint64_t v17 = 0;
  if (llvm::DenseMapBase<llvm::DenseMap<mlir::Value,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseSetPair<mlir::Value>>,mlir::Value,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseSetPair<mlir::Value>>::LookupBucketFor<mlir::Value>((uint64_t *)a1, a2, &v17))return 0; {
  *llvm::DenseMapBase<llvm::DenseMap<mlir::Value,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseSetPair<mlir::Value>>,mlir::Value,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseSetPair<mlir::Value>>::InsertIntoBucketImpl<mlir::Value>(a1, (uint64_t)a2, a2, v17) = *a2;
  }
  unint64_t v4 = *a2;
  uint64_t v5 = *(unsigned int *)(a1 + 32);
  if (v5 >= *(_DWORD *)(a1 + 36))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod(a1 + 24, (void *)(a1 + 40), v5 + 1, 8);
    LODWORD(v5) = *(_DWORD *)(a1 + 32);
  }
  *(void *)(*(void *)(a1 + 24) + 8 * v5) = v4;
  ++*(_DWORD *)(a1 + 32);
  return 1;
}

void llvm::SmallSet<long long,2u,std::less<long long>>::insert(uint64_t a1@<X0>, uint64_t **a2@<X1>, uint64_t a3@<X8>)
{
  if (!*(void *)(a1 + 48))
  {
    uint64_t v15 = *(uint64_t ***)a1;
    uint64_t v16 = *(unsigned int *)(a1 + 8);
    unint64_t v17 = *a2;
    if (!v16) {
      goto LABEL_21;
    }
    uint64_t v18 = 8 * v16;
    uint64_t v9 = *(uint64_t ***)a1;
    while (*v9 != v17)
    {
      ++v9;
      v18 -= 8;
      if (!v18) {
        goto LABEL_20;
      }
    }
    if (v18)
    {
      char v19 = 0;
      char v14 = 1;
      goto LABEL_25;
    }
LABEL_20:
    if (v16 <= 1)
    {
LABEL_21:
      if (v16 >= *(_DWORD *)(a1 + 12))
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod(a1, (void *)(a1 + 16), v16 + 1, 8);
        uint64_t v16 = *(unsigned int *)(a1 + 8);
        uint64_t v15 = *(uint64_t ***)a1;
      }
      v15[v16] = v17;
      unsigned int v20 = *(_DWORD *)(a1 + 8) + 1;
      *(_DWORD *)(a1 + 8) = v20;
      uint64_t v9 = (uint64_t **)(*(void *)a1 + 8 * v20 - 8);
      char v14 = 1;
      goto LABEL_24;
    }
    uint64_t v7 = (uint64_t **)(a1 + 40);
    do
    {
      uint64_t v22 = *(uint64_t **)(a1 + 40);
      uint64_t v23 = *(void *)(*(void *)a1 + 8 * v16 - 8);
      uint64_t v24 = (uint64_t **)(a1 + 40);
      uint64_t v25 = (uint64_t **)(a1 + 40);
      if (v22)
      {
        while (1)
        {
          while (1)
          {
            uint64_t v25 = (uint64_t **)v22;
            uint64_t v26 = v22[4];
            if (v23 >= v26) {
              break;
            }
            uint64_t v22 = *v25;
            uint64_t v24 = v25;
            if (!*v25) {
              goto LABEL_37;
            }
          }
          if (v26 >= v23) {
            break;
          }
          uint64_t v22 = v25[1];
          if (!v22)
          {
            uint64_t v24 = v25 + 1;
            goto LABEL_37;
          }
        }
      }
      else
      {
LABEL_37:
        long long v27 = (uint64_t *)operator new(0x28uLL);
        void v27[4] = v23;
        *long long v27 = 0;
        v27[1] = 0;
        void v27[2] = (uint64_t)v25;
        *uint64_t v24 = v27;
        uint64_t v28 = **(void **)(a1 + 32);
        if (v28)
        {
          *(void *)(a1 + 32) = v28;
          uint64_t v21 = *v24;
        }
        else
        {
          uint64_t v21 = v27;
        }
        std::__tree_balance_after_insert[abi:nn180100]<std::__tree_node_base<void *> *>(*(uint64_t **)(a1 + 40), v21);
        ++*(void *)(a1 + 48);
        LODWORD(v16) = *(_DWORD *)(a1 + 8);
      }
      LODWORD(v16) = v16 - 1;
      *(_DWORD *)(a1 + 8) = v16;
    }
    while (v16);
    uint64_t v8 = *a2;
    uint64_t v29 = *v7;
    uint64_t v9 = (uint64_t **)(a1 + 40);
    if (*v7)
    {
      while (1)
      {
        while (1)
        {
          uint64_t v9 = (uint64_t **)v29;
          uint64_t v30 = v29[4];
          if ((uint64_t)v8 >= v30) {
            break;
          }
          uint64_t v29 = *v9;
          uint64_t v7 = v9;
          if (!*v9) {
            goto LABEL_9;
          }
        }
        if (v30 >= (uint64_t)v8) {
          break;
        }
        uint64_t v29 = v9[1];
        if (!v29)
        {
LABEL_8:
          uint64_t v7 = v9 + 1;
          goto LABEL_9;
        }
      }
      char v14 = 0;
      goto LABEL_24;
    }
LABEL_9:
    unint64_t v11 = (uint64_t *)v9;
    uint64_t v9 = (uint64_t **)operator new(0x28uLL);
    v9[4] = v8;
    *uint64_t v9 = 0;
    v9[1] = 0;
    void v9[2] = v11;
    void *v7 = (uint64_t *)v9;
    uint64_t v12 = **(void **)(a1 + 32);
    uint64_t v13 = (uint64_t *)v9;
    if (v12)
    {
      *(void *)(a1 + 32) = v12;
      uint64_t v13 = *v7;
    }
    std::__tree_balance_after_insert[abi:nn180100]<std::__tree_node_base<void *> *>(*(uint64_t **)(a1 + 40), v13);
    char v14 = 0;
    ++*(void *)(a1 + 48);
LABEL_24:
    char v19 = 1;
    goto LABEL_25;
  }
  uint64_t v7 = (uint64_t **)(a1 + 40);
  uint64_t v6 = *(uint64_t **)(a1 + 40);
  uint64_t v8 = *a2;
  if (!v6)
  {
    uint64_t v9 = (uint64_t **)(a1 + 40);
    goto LABEL_9;
  }
  while (1)
  {
    while (1)
    {
      uint64_t v9 = (uint64_t **)v6;
      uint64_t v10 = (uint64_t *)v6[4];
      if ((uint64_t)v8 >= (uint64_t)v10) {
        break;
      }
      uint64_t v6 = *v9;
      uint64_t v7 = v9;
      if (!*v9) {
        goto LABEL_9;
      }
    }
    if ((uint64_t)v10 >= (uint64_t)v8) {
      break;
    }
    uint64_t v6 = v9[1];
    if (!v6) {
      goto LABEL_8;
    }
  }
  char v14 = 0;
  char v19 = 0;
LABEL_25:
  *(unsigned char *)(a3 + 8) = v14;
  *(void *)a3 = v9;
  *(unsigned char *)(a3 + 16) = v19;
}

void std::__throw_bad_array_new_length[abi:nn180100]()
{
}

uint64_t *std::__tree_balance_after_insert[abi:nn180100]<std::__tree_node_base<void *> *>(uint64_t *result, uint64_t *a2)
{
  *((unsigned char *)a2 + 24) = a2 == result;
  if (a2 != result)
  {
    do
    {
      uint64_t v2 = a2[2];
      if (*(unsigned char *)(v2 + 24)) {
        break;
      }
      unint64_t v3 = *(uint64_t **)(v2 + 16);
      uint64_t v4 = *v3;
      if (*v3 == v2)
      {
        uint64_t v7 = v3[1];
        if (!v7 || (int v8 = *(unsigned __int8 *)(v7 + 24), v5 = (unsigned char *)(v7 + 24), v8))
        {
          if (*(uint64_t **)v2 == a2)
          {
            uint64_t v9 = (uint64_t *)a2[2];
          }
          else
          {
            uint64_t v9 = *(uint64_t **)(v2 + 8);
            uint64_t v10 = *v9;
            *(void *)(v2 + 8) = *v9;
            if (v10)
            {
              *(void *)(v10 + 16) = v2;
              unint64_t v3 = *(uint64_t **)(v2 + 16);
            }
            void v9[2] = (uint64_t)v3;
            *(void *)(*(void *)(v2 + 16) + 8 * (**(void **)(v2 + 16) != v2)) = v9;
            *uint64_t v9 = v2;
            *(void *)(v2 + 16) = v9;
            unint64_t v3 = (uint64_t *)v9[2];
            uint64_t v2 = *v3;
          }
          *((unsigned char *)v9 + 24) = 1;
          *((unsigned char *)v3 + 24) = 0;
          uint64_t v14 = *(void *)(v2 + 8);
          *unint64_t v3 = v14;
          if (v14) {
            *(void *)(v14 + 16) = v3;
          }
          *(void *)(v2 + 16) = v3[2];
          *(void *)(v3[2] + 8 * (*(void *)v3[2] != (void)v3)) = v2;
          *(void *)(v2 + 8) = v3;
          v3[2] = v2;
          return result;
        }
      }
      else if (!v4 || (int v6 = *(unsigned __int8 *)(v4 + 24), v5 = (unsigned char *)(v4 + 24), v6))
      {
        if (*(uint64_t **)v2 == a2)
        {
          uint64_t v11 = a2[1];
          *(void *)uint64_t v2 = v11;
          if (v11)
          {
            *(void *)(v11 + 16) = v2;
            unint64_t v3 = *(uint64_t **)(v2 + 16);
          }
          a2[2] = (uint64_t)v3;
          *(void *)(*(void *)(v2 + 16) + 8 * (**(void **)(v2 + 16) != v2)) = a2;
          a2[1] = v2;
          *(void *)(v2 + 16) = a2;
          unint64_t v3 = (uint64_t *)a2[2];
        }
        else
        {
          a2 = (uint64_t *)a2[2];
        }
        *((unsigned char *)a2 + 24) = 1;
        *((unsigned char *)v3 + 24) = 0;
        uint64_t v12 = (uint64_t *)v3[1];
        uint64_t v13 = *v12;
        v3[1] = *v12;
        if (v13) {
          *(void *)(v13 + 16) = v3;
        }
        _OWORD v12[2] = v3[2];
        *(void *)(v3[2] + 8 * (*(void *)v3[2] != (void)v3)) = v12;
        *uint64_t v12 = (uint64_t)v3;
        v3[2] = (uint64_t)v12;
        return result;
      }
      *(unsigned char *)(v2 + 24) = 1;
      a2 = v3;
      *((unsigned char *)v3 + 24) = v3 == result;
      *uint64_t v5 = 1;
    }
    while (v3 != result);
  }
  return result;
}

uint64_t std::__optional_destruct_base<mlir::Diagnostic,false>::~__optional_destruct_base[abi:nn180100](uint64_t a1)
{
  if (*(unsigned char *)(a1 + 176))
  {
    uint64_t v2 = *(void **)(a1 + 152);
    if (v2)
    {
      unint64_t v3 = *(void **)(a1 + 160);
      uint64_t v4 = *(void **)(a1 + 152);
      if (v3 != v2)
      {
        do
          unint64_t v3 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v3 - 1);
        while (v3 != v2);
        uint64_t v4 = *(void **)(a1 + 152);
      }
      *(void *)(a1 + 16std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v2;
      operator delete(v4);
    }
    uint64_t v5 = *(void **)(a1 + 128);
    if (v5)
    {
      int v6 = *(void **)(a1 + 136);
      uint64_t v7 = *(void **)(a1 + 128);
      if (v6 != v5)
      {
        do
        {
          uint64_t v9 = *--v6;
          uint64_t v8 = v9;
          *int v6 = 0;
          if (v9) {
            MEMORY[0x21667D390](v8, 0x1000C8077774924);
          }
        }
        while (v6 != v5);
        uint64_t v7 = *(void **)(a1 + 128);
      }
      *(void *)(a1 + 136) = v5;
      operator delete(v7);
    }
    uint64_t v10 = *(void **)(a1 + 16);
    if (v10 != (void *)(a1 + 32)) {
      free(v10);
    }
  }
  return a1;
}

void *std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](void *a1)
{
  uint64_t v2 = (void *)*a1;
  *a1 = 0;
  if (v2)
  {
    uint64_t v3 = v2[19];
    if (v3)
    {
      uint64_t v4 = v2[20];
      uint64_t v5 = (void *)v2[19];
      if (v4 != v3)
      {
        do
          uint64_t v4 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v4 - 8);
        while (v4 != v3);
        uint64_t v5 = (void *)v2[19];
      }
      v2[20] = v3;
      operator delete(v5);
    }
    int v6 = (void *)v2[16];
    if (v6)
    {
      uint64_t v7 = (void *)v2[17];
      uint64_t v8 = (void *)v2[16];
      if (v7 != v6)
      {
        do
        {
          uint64_t v10 = *--v7;
          uint64_t v9 = v10;
          void *v7 = 0;
          if (v10) {
            MEMORY[0x21667D390](v9, 0x1000C8077774924);
          }
        }
        while (v7 != v6);
        uint64_t v8 = (void *)v2[16];
      }
      v2[17] = v6;
      operator delete(v8);
    }
    uint64_t v11 = (void *)v2[2];
    if (v11 != v2 + 4) {
      free(v11);
    }
    MEMORY[0x21667D3C0](v2, 0x10A0C403EC7AAD9);
  }
  return a1;
}

uint64_t anonymous namespace'::CurrentlyLive::Buffer::findFirstSlotFor(uint64_t a1, void *a2)
{
  int64_t v2 = *(void *)a1;
  unsigned int v3 = *(_DWORD *)(a1 + 16);
  if (*(void *)a1 == -1)
  {
    if (v3)
    {
      uint64_t v4 = a1 + 8;
      if (v3 != 1) {
        goto LABEL_26;
      }
      return *(void *)(*(void *)v4 + 24) + 1;
    }
    return 0;
  }
  if (!v3)
  {
    unint64_t v9 = a2[4];
    if (v9) {
      unint64_t v10 = (v9 - 1) / v9 * v9;
    }
    else {
      unint64_t v10 = 0;
    }
    uint64_t v14 = a2[3] - a2[2];
    if ((uint64_t)(v14 + v10) > v2) {
      return -1;
    }
    if (v9) {
      v9 *= (v9 - 1) / v9;
    }
    if ((uint64_t)(v14 + v9) > v2) {
      return 0;
    }
    return 0;
  }
  uint64_t v5 = *(void *)(a1 + 8);
  uint64_t v4 = a1 + 8;
  uint64_t v6 = *(void *)(v5 + 40 * v3 - 16);
  unint64_t v7 = a2[4];
  if (v7) {
    unint64_t v8 = (v7 + v6) / v7 * v7;
  }
  else {
    unint64_t v8 = v6 + 1;
  }
  uint64_t v11 = a2[3] - a2[2];
  if ((uint64_t)(v11 + v8) > v2) {
    return -1;
  }
  if (v3 != 1) {
    goto LABEL_26;
  }
  uint64_t v12 = *(void *)(*(void *)v4 + 24);
  if (v7) {
    unint64_t v13 = (v7 + v12) / v7 * v7;
  }
  else {
    unint64_t v13 = v12 + 1;
  }
  if ((uint64_t)(v11 + v13) <= v2) {
    return *(void *)(*(void *)v4 + 24) + 1;
  }
  unsigned int v3 = 1;
LABEL_26:
  unint64_t v16 = a2[4];
  uint64_t v17 = 40 * v3;
  uint64_t v18 = (uint64_t *)(*(void *)v4 + 24);
  uint64_t v19 = -1;
  do
  {
    uint64_t v20 = *(v18 - 2);
    uint64_t v21 = *v18;
    uint64_t v22 = v19 + 1;
    if (v20 > v19 + 1)
    {
      if (v16) {
        uint64_t v22 = (v16 + v19) / v16 * v16;
      }
      if (a2[3] - a2[2] + v22 < v20) {
        break;
      }
    }
    v18 += 5;
    uint64_t v19 = v21;
    v17 -= 40;
  }
  while (v17);
  return v19 + 1;
}

uint64_t llvm::DenseMapBase<llvm::DenseMap<mlir::Value,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseSetPair<mlir::Value>>,mlir::Value,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseSetPair<mlir::Value>>::LookupBucketFor<mlir::Value>(uint64_t *a1, unint64_t *a2, void *a3)
{
  int v3 = *((_DWORD *)a1 + 4);
  if (v3)
  {
    uint64_t v4 = *a1;
    unint64_t v5 = *a2;
    uint64_t v6 = &unk_267770000;
    {
      uint64_t v23 = a3;
      uint64_t v21 = a2;
      uint64_t v24 = v4;
      int v22 = v3;
      unint64_t v25 = v5;
      uint64_t v6 = &unk_267770000;
      uint64_t v4 = v24;
      unint64_t v5 = v25;
      int v3 = v22;
      a2 = v21;
      a3 = v23;
      if (v19)
      {
        unint64_t v20 = llvm::hashing::detail::fixed_seed_override;
        if (!llvm::hashing::detail::fixed_seed_override) {
          unint64_t v20 = 0xFF51AFD7ED558CCDLL;
        }
        llvm::hashing::detail::get_execution_seed(void)::seed = v20;
        uint64_t v6 = (void *)&unk_267770000;
        uint64_t v4 = v24;
        unint64_t v5 = v25;
        int v3 = v22;
        a2 = v21;
        a3 = v23;
      }
    }
    uint64_t v7 = (v6[385] + 8 * v5) ^ HIDWORD(v5);
    unint64_t v8 = 0x9DDFEA08EB382D69 * (HIDWORD(v5) ^ ((0x9DDFEA08EB382D69 * v7) >> 47) ^ (0x9DDFEA08EB382D69 * v7));
    int v9 = -348639895 * ((v8 >> 47) ^ v8);
    int v10 = v3 - 1;
    unsigned int v11 = v9 & (v3 - 1);
    uint64_t v12 = (void *)(v4 + 8 * v11);
    uint64_t v13 = *v12;
    if (*a2 == *v12)
    {
      uint64_t result = 1;
    }
    else
    {
      uint64_t v15 = 0;
      int v16 = 1;
      uint64_t result = 1;
      while (v13 != -4096)
      {
        if (v15) {
          BOOL v17 = 0;
        }
        else {
          BOOL v17 = v13 == -8192;
        }
        if (v17) {
          uint64_t v15 = v12;
        }
        unsigned int v18 = v11 + v16++;
        unsigned int v11 = v18 & v10;
        uint64_t v12 = (void *)(v4 + 8 * (v18 & v10));
        uint64_t v13 = *v12;
        if (*a2 == *v12) {
          goto LABEL_6;
        }
      }
      uint64_t result = 0;
      if (v15) {
        uint64_t v12 = v15;
      }
    }
  }
  else
  {
    uint64_t v12 = 0;
    uint64_t result = 0;
  }
LABEL_6:
  *a3 = v12;
  return result;
}

void *llvm::DenseMapBase<llvm::DenseMap<mlir::Value,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseSetPair<mlir::Value>>,mlir::Value,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseSetPair<mlir::Value>>::InsertIntoBucketImpl<mlir::Value>(uint64_t a1, uint64_t a2, unint64_t *a3, void *a4)
{
  int v6 = *(_DWORD *)(a1 + 8);
  unsigned int v7 = *(_DWORD *)(a1 + 16);
  if (4 * v6 + 4 >= 3 * v7)
  {
    v7 *= 2;
  }
  else if (v7 + ~v6 - *(_DWORD *)(a1 + 12) > v7 >> 3)
  {
    goto LABEL_3;
  }
  llvm::DenseMap<mlir::Value,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseSetPair<mlir::Value>>::grow(a1, v7);
  int v9 = 0;
  llvm::DenseMapBase<llvm::DenseMap<mlir::Value,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseSetPair<mlir::Value>>,mlir::Value,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseSetPair<mlir::Value>>::LookupBucketFor<mlir::Value>((uint64_t *)a1, a3, &v9);
  a4 = v9;
LABEL_3:
  ++*(_DWORD *)(a1 + 8);
  if (*a4 != -4096) {
    --*(_DWORD *)(a1 + 12);
  }
  return a4;
}

int64x2_t *llvm::DenseMap<mlir::Value,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseSetPair<mlir::Value>>::grow(uint64_t a1, int a2)
{
  uint64_t v3 = *(unsigned int *)(a1 + 16);
  uint64_t v4 = *(llvm **)a1;
  unint64_t v5 = (a2 - 1) | ((unint64_t)(a2 - 1) >> 1);
  unint64_t v6 = v5 | (v5 >> 2) | ((v5 | (v5 >> 2)) >> 4);
  int v7 = ((v6 | (v6 >> 8)) >> 16) | v6 | (v6 >> 8);
  if ((v7 + 1) > 0x40) {
    unsigned int v8 = v7 + 1;
  }
  else {
    unsigned int v8 = 64;
  }
  *(_DWORD *)(a1 + 16) = v8;
  uint64_t result = (int64x2_t *)llvm::allocate_buffer(8 * v8, (std::align_val_t)8uLL);
  int v10 = (char *)result;
  *(void *)a1 = result;
  if (v4)
  {
    *(void *)(a1 + 8) = 0;
    uint64_t v11 = *(unsigned int *)(a1 + 16);
    if (v11)
    {
      unint64_t v12 = (v11 - 1) & 0x1FFFFFFFFFFFFFFFLL;
      if (v12 < 3) {
        goto LABEL_10;
      }
      unint64_t v13 = v12 + 1;
      int v10 = &result->i8[8 * (v13 & 0x3FFFFFFFFFFFFFFCLL)];
      uint64_t v14 = result + 1;
      int64x2_t v15 = vdupq_n_s64(0xFFFFFFFFFFFFF000);
      uint64_t v16 = v13 & 0x3FFFFFFFFFFFFFFCLL;
      do
      {
        v14[-1] = v15;
        *uint64_t v14 = v15;
        v14 += 2;
        v16 -= 4;
      }
      while (v16);
      if (v13 != (v13 & 0x3FFFFFFFFFFFFFFCLL))
      {
LABEL_10:
        BOOL v17 = &result->i8[8 * v11];
        do
        {
          *(void *)int v10 = -4096;
          v10 += 8;
        }
        while (v10 != v17);
      }
    }
    unsigned int v18 = (void *)(8 * v3);
    if (v3)
    {
      uint64_t v19 = 8 * v3;
      unint64_t v20 = (unint64_t *)v4;
      do
      {
        if ((*v20 | 0x1000) != 0xFFFFFFFFFFFFF000)
        {
          uint64_t v28 = 0;
          llvm::DenseMapBase<llvm::DenseMap<mlir::Value,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseSetPair<mlir::Value>>,mlir::Value,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseSetPair<mlir::Value>>::LookupBucketFor<mlir::Value>((uint64_t *)a1, v20, &v28);
          *uint64_t v28 = *v20;
          ++*(_DWORD *)(a1 + 8);
        }
        ++v20;
        v19 -= 8;
      }
      while (v19);
    }
    llvm::deallocate_buffer(v4, v18);
  }
  *(void *)(a1 + 8) = 0;
  uint64_t v21 = *(unsigned int *)(a1 + 16);
  if (v21)
  {
    unint64_t v22 = (v21 - 1) & 0x1FFFFFFFFFFFFFFFLL;
    if (v22 < 3) {
      goto LABEL_23;
    }
    unint64_t v23 = v22 + 1;
    int v10 = &result->i8[8 * (v23 & 0x3FFFFFFFFFFFFFFCLL)];
    uint64_t v24 = result + 1;
    int64x2_t v25 = vdupq_n_s64(0xFFFFFFFFFFFFF000);
    uint64_t v26 = v23 & 0x3FFFFFFFFFFFFFFCLL;
    do
    {
      v24[-1] = v25;
      *uint64_t v24 = v25;
      v24 += 2;
      v26 -= 4;
    }
    while (v26);
    if (v23 != (v23 & 0x3FFFFFFFFFFFFFFCLL))
    {
LABEL_23:
      long long v27 = &result->i8[8 * v21];
      do
      {
        *(void *)int v10 = -4096;
        v10 += 8;
      }
      while (v10 != v27);
    }
  }
  return result;
}

unint64_t llvm::SmallVectorImpl<llvm::SmallSetVector<mlir::Value,2u>>::insert_one_impl<llvm::SmallSetVector<mlir::Value,2u> const&>(uint64_t a1, uint64_t a2, unint64_t a3)
{
  if (*(void *)a1 + 56 * *(unsigned int *)(a1 + 8) == a2) {
    llvm::SmallVectorTemplateBase<llvm::SmallSetVector<mlir::Value,2u>,false>::push_back(a1, a3);
  }
  uint64_t v4 = a2 - *(void *)a1;
  Address = llvm::SmallVectorTemplateBase<llvm::SmallSetVector<mlir::Value,2u>,false>::reserveForParamAndGetAddress(a1, a3, 1);
  unint64_t v6 = *(void *)a1 + v4;
  uint64_t v7 = *(void *)a1 + 56 * *(unsigned int *)(a1 + 8);
  *(void *)uint64_t v7 = *(void *)(v7 - 56);
  *(void *)(v7 + 8) = *(void *)(v7 - 48);
  *(void *)(v7 - 56) = 0;
  *(void *)(v7 - 48) = 0;
  *(_DWORD *)(v7 + 16) = *(_DWORD *)(v7 - 40);
  *(_DWORD *)(v7 - 4std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  *(void *)(v7 + 24) = v7 + 40;
  *(void *)(v7 + 32) = 0x200000000;
  if (*(_DWORD *)(v7 - 24)) {
    llvm::SmallVectorImpl<mlir::Value>::operator=(v7 + 24, v7 - 32);
  }
  uint64_t v8 = *(void *)a1;
  unsigned int v9 = *(_DWORD *)(a1 + 8);
  int v10 = (llvm **)(*(void *)a1 + 56 * v9 - 56);
  if (v10 != (llvm **)v6) {
    llvm::deallocate_buffer(*v10, (void *)(8 * *(unsigned int *)(*(void *)a1 + 56 * v9 - 40)));
  }
  unsigned int v11 = v9 + 1;
  *(_DWORD *)(a1 + 8) = v11;
  unint64_t v12 = v8 + 56 * v11;
  BOOL v14 = (unint64_t)Address >= v6 && (unint64_t)Address < v12;
  llvm::SetVector<mlir::Value,llvm::SmallVector<mlir::Value,2u>,llvm::DenseSet<mlir::Value,llvm::DenseMapInfo<mlir::Value,void>>,2u>::operator=(v6, (uint64_t)&Address[56 * v14]);
  return v6;
}

void llvm::SmallVectorTemplateBase<llvm::SmallSetVector<mlir::Value,2u>,false>::push_back(uint64_t a1, unint64_t a2)
{
  llvm::SmallVectorTemplateBase<llvm::SmallSetVector<mlir::Value,2u>,false>::reserveForParamAndGetAddress(a1, a2, 1);
  uint64_t v3 = *(void *)a1 + 56 * *(unsigned int *)(a1 + 8);
  *(void *)uint64_t v3 = 0;
  *(void *)(v3 + 8) = 0;
  *(_DWORD *)(v3 + 16) = 0;
  llvm::deallocate_buffer(0, 0);
}

void sub_2113BD378()
{
  uint64_t v3 = *(unsigned int *)(v1 + 16);
  *(_DWORD *)(v2 + 16) = v3;
  if (v3)
  {
    buffer = llvm::allocate_buffer(8 * v3, (std::align_val_t)8uLL);
    *(void *)uint64_t v2 = buffer;
    *(void *)(v2 + 8) = *(void *)(v1 + 8);
    memcpy(buffer, *(const void **)v1, 8 * *(unsigned int *)(v2 + 16));
  }
  else
  {
    *(void *)uint64_t v2 = 0;
    *(void *)(v2 + 8) = 0;
  }
  unint64_t v5 = (void *)(v2 + 40);
  *(void *)(v2 + 24) = v2 + 40;
  *(void *)(v2 + 32) = 0x200000000;
  unsigned int v6 = *(_DWORD *)(v1 + 32);
  if (v2 != v1 && v6 != 0)
  {
    if (v6 < 3)
    {
      unsigned int v8 = *(_DWORD *)(v1 + 32);
    }
    else
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod(v2 + 24, (void *)(v2 + 40), *(unsigned int *)(v1 + 32), 8);
      unsigned int v8 = *(_DWORD *)(v1 + 32);
      if (!v8)
      {
LABEL_13:
        *(_DWORD *)(v2 + 32) = v6;
        goto LABEL_14;
      }
      unint64_t v5 = *(void **)(v2 + 24);
    }
    memcpy(v5, *(const void **)(v1 + 24), 8 * v8);
    goto LABEL_13;
  }
LABEL_14:
  ++*(_DWORD *)(v0 + 8);
}

char *llvm::SmallVectorTemplateBase<llvm::SmallSetVector<mlir::Value,2u>,false>::reserveForParamAndGetAddress(uint64_t a1, unint64_t a2, uint64_t a3)
{
  unint64_t v3 = a2;
  uint64_t v4 = *(unsigned int *)(a1 + 8);
  unint64_t v5 = v4 + a3;
  if (v5 > *(unsigned int *)(a1 + 12))
  {
    unint64_t v8 = *(void *)a1 + 56 * v4;
    if (*(void *)a1 <= a2 && v8 > a2)
    {
      uint64_t v13 = 0x6DB6DB6DB6DB6DB7 * ((uint64_t)(a2 - *(void *)a1) >> 3);
      unint64_t v17 = 0;
      uint64_t v14 = a1 + 16;
      int64x2_t v15 = (char *)llvm::SmallVectorBase<unsigned int>::mallocForGrow(a1, (void *)(a1 + 16), v5, 56, &v17);
      llvm::SmallVectorTemplateBase<llvm::SmallSetVector<mlir::Value,2u>,false>::moveElementsForGrow(a1, (uint64_t)v15);
      int v16 = v17;
      if (*(void *)a1 != v14) {
        free(*(void **)a1);
      }
      *(void *)a1 = v15;
      *(_DWORD *)(a1 + 12) = v16;
      return &v15[56 * v13];
    }
    else
    {
      unint64_t v17 = 0;
      uint64_t v10 = a1 + 16;
      unsigned int v11 = llvm::SmallVectorBase<unsigned int>::mallocForGrow(a1, (void *)(a1 + 16), v5, 56, &v17);
      llvm::SmallVectorTemplateBase<llvm::SmallSetVector<mlir::Value,2u>,false>::moveElementsForGrow(a1, (uint64_t)v11);
      int v12 = v17;
      if (*(void *)a1 != v10) {
        free(*(void **)a1);
      }
      *(void *)a1 = v11;
      *(_DWORD *)(a1 + 12) = v12;
    }
  }
  return (char *)v3;
}

uint64_t llvm::SetVector<mlir::Value,llvm::SmallVector<mlir::Value,2u>,llvm::DenseSet<mlir::Value,llvm::DenseMapInfo<mlir::Value,void>>,2u>::operator=(uint64_t result, uint64_t a2)
{
  if (a2 != result) {
    llvm::deallocate_buffer(*(llvm **)result, (void *)(8 * *(unsigned int *)(result + 16)));
  }
  return result;
}

uint64_t llvm::SmallVectorImpl<mlir::detail::AllocRange>::insert_one_impl<mlir::detail::AllocRange const&>(uint64_t a1, unint64_t a2, unint64_t a3)
{
  unint64_t v5 = *(void *)a1;
  uint64_t v6 = *(unsigned int *)(a1 + 8);
  unint64_t v7 = *(void *)a1 + 40 * v6;
  if (v7 == a2)
  {
    if (v6 >= *(_DWORD *)(a1 + 12))
    {
      unint64_t v28 = v6 + 1;
      if (v5 <= a3 && a2 > a3)
      {
        unint64_t v31 = a3 - v5;
        llvm::SmallVectorBase<unsigned int>::grow_pod(a1, (void *)(a1 + 16), v28, 40);
        unint64_t v5 = *(void *)a1;
        a3 = *(void *)a1 + v31;
      }
      else
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod(a1, (void *)(a1 + 16), v28, 40);
        unint64_t v5 = *(void *)a1;
      }
    }
    unint64_t v22 = v5 + 40 * *(unsigned int *)(a1 + 8);
    long long v23 = *(_OWORD *)a3;
    long long v24 = *(_OWORD *)(a3 + 16);
    *(void *)(v22 + 32) = *(void *)(a3 + 32);
    *(_OWORD *)unint64_t v22 = v23;
    *(_OWORD *)(v22 + 16) = v24;
    LODWORD(v22) = *(_DWORD *)(a1 + 8) + 1;
    *(_DWORD *)(a1 + 8) = v22;
    return *(void *)a1 + 40 * v22 - 40;
  }
  else
  {
    unint64_t v8 = 0xCCCCCCCCCCCCCCCDLL * ((uint64_t)(a2 - v5) >> 3);
    if (v6 >= *(_DWORD *)(a1 + 12))
    {
      unint64_t v26 = v6 + 1;
      if (v5 <= a3 && v7 > a3)
      {
        unint64_t v30 = a3 - v5;
        llvm::SmallVectorBase<unsigned int>::grow_pod(a1, (void *)(a1 + 16), v26, 40);
        unint64_t v5 = *(void *)a1;
        a3 = *(void *)a1 + v30;
      }
      else
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod(a1, (void *)(a1 + 16), v26, 40);
        unint64_t v5 = *(void *)a1;
      }
    }
    unsigned int v9 = (_OWORD *)(v5 + 40 * v8);
    unint64_t v10 = v5 + 40 * *(unsigned int *)(a1 + 8);
    long long v11 = *(_OWORD *)(v10 - 24);
    *(_OWORD *)unint64_t v10 = *(_OWORD *)(v10 - 40);
    *(_OWORD *)(v10 + 16) = v11;
    *(void *)(v10 + 32) = *(void *)(v10 - 8);
    unint64_t v12 = *(void *)a1;
    unsigned int v13 = *(_DWORD *)(a1 + 8);
    uint64_t v14 = *(void *)a1 + 40 * v13 - 40;
    if ((_OWORD *)v14 != v9)
    {
      memmove((char *)v9 + 40, v9, v14 - (void)v9);
      unsigned int v13 = *(_DWORD *)(a1 + 8);
      unint64_t v12 = *(void *)a1;
    }
    unsigned int v15 = v13 + 1;
    *(_DWORD *)(a1 + 8) = v15;
    unint64_t v16 = v12 + 40 * v15;
    BOOL v18 = a3 >= (unint64_t)v9 && a3 < v16;
    unint64_t v19 = a3 + 40 * v18;
    long long v20 = *(_OWORD *)v19;
    long long v21 = *(_OWORD *)(v19 + 16);
    *((void *)v9 + 4) = *(void *)(v19 + 32);
    *unsigned int v9 = v20;
    v9[1] = v21;
  }
  return (uint64_t)v9;
}

__n128 std::__stable_sort<std::_ClassicAlgPolicy,anonymous namespace'::CurrentlyLive::Buffer::lookupRangeForValue(mlir::Value)::{lambda(anonymous namespace'::CurrentlyLive::Buffer::lookupRangeForValue(mlir::Value)::Match const&,anonymous namespace'::CurrentlyLive::Buffer::lookupRangeForValue(mlir::Value)::Match const&)#1} &,anonymous namespace'::CurrentlyLive::Buffer::lookupRangeForValue(mlir::Value)::Match*>(uint64_t a1, char *a2, unint64_t a3, uint64_t a4, uint64_t a5, __n128 result)
{
  if (a3 >= 2)
  {
    uint64_t v7 = a1;
    if (a3 == 2)
    {
      if (*((void *)a2 - 1) < *(void *)(a1 + 40))
      {
        uint64_t result = *(__n128 *)a1;
        long long v8 = *(_OWORD *)(a1 + 16);
        long long v9 = *(_OWORD *)(a1 + 32);
        long long v11 = *((_OWORD *)a2 - 2);
        long long v10 = *((_OWORD *)a2 - 1);
        *(_OWORD *)a1 = *((_OWORD *)a2 - 3);
        *(_OWORD *)(a1 + 16) = v11;
        *(_OWORD *)(a1 + 32) = v10;
        *((_OWORD *)a2 - 2) = v8;
        *((_OWORD *)a2 - 1) = v9;
        *((__n128 *)a2 - 3) = result;
      }
    }
    else if ((uint64_t)a3 > 128)
    {
      uint64_t v23 = a4;
      unint64_t v24 = a3 >> 1;
      uint64_t v25 = a1 + 48 * (a3 >> 1);
      unint64_t v26 = a3 >> 1;
      if ((uint64_t)a3 <= a5)
      {
        uint64_t v28 = v23 + 48 * v24;
        unint64_t v29 = v23 + 48 * a3;
        uint64_t v30 = v28;
        while (v30 != v29)
        {
          if (*(void *)(v30 + 40) >= *(void *)(v23 + 40))
          {
            uint64_t result = *(__n128 *)v23;
            long long v31 = *(_OWORD *)(v23 + 32);
            *(_OWORD *)(v7 + 16) = *(_OWORD *)(v23 + 16);
            *(_OWORD *)(v7 + 32) = v31;
            *(__n128 *)uint64_t v7 = result;
            v23 += 48;
          }
          else
          {
            uint64_t result = *(__n128 *)v30;
            long long v32 = *(_OWORD *)(v30 + 32);
            *(_OWORD *)(v7 + 16) = *(_OWORD *)(v30 + 16);
            *(_OWORD *)(v7 + 32) = v32;
            *(__n128 *)uint64_t v7 = result;
            v30 += 48;
          }
          v7 += 48;
          if (v23 == v28)
          {
            if (v30 != v29)
            {
              uint64_t v36 = 0;
              do
              {
                uint64_t v37 = v7 + v36;
                uint64_t result = *(__n128 *)(v30 + v36);
                long long v38 = *(_OWORD *)(v30 + v36 + 32);
                *(_OWORD *)(v37 + 16) = *(_OWORD *)(v30 + v36 + 16);
                *(_OWORD *)(v37 + 32) = v38;
                *(__n128 *)uint64_t v37 = result;
                v36 += 48;
              }
              while (v30 + v36 != v29);
            }
            return result;
          }
        }
        if (v23 != v28)
        {
          uint64_t v33 = 0;
          do
          {
            uint64_t v34 = v7 + v33;
            uint64_t result = *(__n128 *)(v23 + v33);
            long long v35 = *(_OWORD *)(v23 + v33 + 32);
            *(_OWORD *)(v34 + 16) = *(_OWORD *)(v23 + v33 + 16);
            *(_OWORD *)(v34 + 32) = v35;
            *(__n128 *)uint64_t v34 = result;
            v33 += 48;
          }
          while (v23 + v33 != v28);
        }
      }
      else
      {
      }
    }
    else if ((char *)a1 != a2)
    {
      uint64_t v13 = a1 + 48;
      if ((char *)(a1 + 48) != a2)
      {
        uint64_t v14 = 0;
        uint64_t v15 = a1;
        do
        {
          unint64_t v17 = *(void *)(v15 + 88);
          unint64_t v18 = *(void *)(v15 + 40);
          uint64_t v15 = v13;
          if (v17 < v18)
          {
            __n128 v39 = *(__n128 *)v13;
            long long v40 = *(_OWORD *)(v13 + 16);
            uint64_t v41 = *(void *)(v13 + 32);
            uint64_t v19 = v14;
            do
            {
              long long v20 = (_OWORD *)(a1 + v19);
              long long v21 = *(_OWORD *)(a1 + v19 + 16);
              void v20[3] = *(_OWORD *)(a1 + v19);
              v20[4] = v21;
              v20[5] = *(_OWORD *)(a1 + v19 + 32);
              if (!v19)
              {
                uint64_t v16 = a1;
                goto LABEL_10;
              }
              v19 -= 48;
            }
            while (v17 < *((void *)v20 - 1));
            uint64_t v16 = a1 + v19 + 48;
LABEL_10:
            uint64_t result = v39;
            *(__n128 *)uint64_t v16 = v39;
            *(_OWORD *)(v16 + 16) = v40;
            *(void *)(v16 + 32) = v41;
            *(void *)(v16 + 4std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v17;
          }
          uint64_t v13 = v15 + 48;
          v14 += 48;
        }
        while ((char *)(v15 + 48) != a2);
      }
    }
  }
  return result;
}

__n128 std::__stable_sort_move<std::_ClassicAlgPolicy,anonymous namespace'::CurrentlyLive::Buffer::lookupRangeForValue(mlir::Value)::{lambda(anonymous namespace'::CurrentlyLive::Buffer::lookupRangeForValue(mlir::Value)::Match const&,anonymous namespace'::CurrentlyLive::Buffer::lookupRangeForValue(mlir::Value)::Match const&)#1} &,anonymous namespace'::CurrentlyLive::Buffer::lookupRangeForValue(mlir::Value)::Match*>(uint64_t a1, uint64_t a2, unint64_t a3, uint64_t a4, __n128 result)
{
  if (a3)
  {
    uint64_t v5 = a4;
    uint64_t v8 = a1;
    if (a3 == 2)
    {
      long long v10 = (__n128 *)(a2 - 48);
      if (*(void *)(a2 - 8) >= *(void *)(a1 + 40))
      {
        __n128 v26 = *(__n128 *)a1;
        long long v27 = *(_OWORD *)(a1 + 32);
        *(_OWORD *)(a4 + 16) = *(_OWORD *)(a1 + 16);
        *(_OWORD *)(a4 + 32) = v27;
        *(__n128 *)a4 = v26;
        uint64_t result = *v10;
        long long v13 = *(_OWORD *)(a2 - 32);
        long long v14 = *(_OWORD *)(a2 - 16);
      }
      else
      {
        __n128 v11 = *v10;
        long long v12 = *(_OWORD *)(a2 - 16);
        *(_OWORD *)(a4 + 16) = *(_OWORD *)(a2 - 32);
        *(_OWORD *)(a4 + 32) = v12;
        *(__n128 *)a4 = v11;
        uint64_t result = *(__n128 *)a1;
        long long v13 = *(_OWORD *)(a1 + 16);
        long long v14 = *(_OWORD *)(a1 + 32);
      }
      *(_OWORD *)(a4 + 64) = v13;
      *(_OWORD *)(a4 + 8std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v14;
      *(__n128 *)(a4 + 48) = result;
    }
    else if (a3 == 1)
    {
      uint64_t result = *(__n128 *)a1;
      long long v9 = *(_OWORD *)(a1 + 32);
      *(_OWORD *)(a4 + 16) = *(_OWORD *)(a1 + 16);
      *(_OWORD *)(a4 + 32) = v9;
      *(__n128 *)a4 = result;
    }
    else if ((uint64_t)a3 > 8)
    {
      unint64_t v28 = a3 >> 1;
      uint64_t v29 = 48 * (a3 >> 1);
      uint64_t v30 = a1 + v29;
      uint64_t v31 = v8 + v29;
      while (v31 != a2)
      {
        if (*(void *)(v31 + 40) >= *(void *)(v8 + 40))
        {
          uint64_t result = *(__n128 *)v8;
          long long v32 = *(_OWORD *)(v8 + 32);
          *(_OWORD *)(v5 + 16) = *(_OWORD *)(v8 + 16);
          *(_OWORD *)(v5 + 32) = v32;
          *(__n128 *)uint64_t v5 = result;
          v8 += 48;
        }
        else
        {
          uint64_t result = *(__n128 *)v31;
          long long v33 = *(_OWORD *)(v31 + 32);
          *(_OWORD *)(v5 + 16) = *(_OWORD *)(v31 + 16);
          *(_OWORD *)(v5 + 32) = v33;
          *(__n128 *)uint64_t v5 = result;
          v31 += 48;
        }
        v5 += 48;
        if (v8 == v30)
        {
          if (v31 != a2)
          {
            uint64_t v37 = 0;
            do
            {
              uint64_t v38 = v5 + v37;
              uint64_t result = *(__n128 *)(v31 + v37);
              long long v39 = *(_OWORD *)(v31 + v37 + 32);
              *(_OWORD *)(v38 + 16) = *(_OWORD *)(v31 + v37 + 16);
              *(_OWORD *)(v38 + 32) = v39;
              *(__n128 *)uint64_t v38 = result;
              v37 += 48;
            }
            while (v31 + v37 != a2);
          }
          return result;
        }
      }
      if (v8 != v30)
      {
        uint64_t v34 = 0;
        do
        {
          uint64_t v35 = v5 + v34;
          uint64_t result = *(__n128 *)(v8 + v34);
          long long v36 = *(_OWORD *)(v8 + v34 + 32);
          *(_OWORD *)(v35 + 16) = *(_OWORD *)(v8 + v34 + 16);
          *(_OWORD *)(v35 + 32) = v36;
          *(__n128 *)uint64_t v35 = result;
          v34 += 48;
        }
        while (v8 + v34 != v30);
      }
    }
    else if (a1 != a2)
    {
      uint64_t result = *(__n128 *)a1;
      long long v15 = *(_OWORD *)(a1 + 32);
      *(_OWORD *)(a4 + 16) = *(_OWORD *)(a1 + 16);
      *(_OWORD *)(a4 + 32) = v15;
      *(__n128 *)a4 = result;
      uint64_t v16 = a1 + 48;
      if (a1 + 48 != a2)
      {
        uint64_t v17 = 0;
        unint64_t v18 = (_OWORD *)a4;
        do
        {
          uint64_t v20 = v8;
          long long v21 = v18;
          uint64_t v8 = v16;
          v18 += 3;
          unint64_t v22 = v18;
          if (*(void *)(v20 + 88) < *((void *)v21 + 5))
          {
            long long v23 = v21[1];
            *unint64_t v18 = *v21;
            v18[1] = v23;
            v18[2] = v21[2];
            unint64_t v22 = (_OWORD *)a4;
            if (v21 != (_OWORD *)a4)
            {
              uint64_t v24 = v17;
              while (1)
              {
                unint64_t v22 = (_OWORD *)(a4 + v24);
                if (*(void *)(v20 + 88) >= *(void *)(a4 + v24 - 8)) {
                  break;
                }
                long long v25 = *(v22 - 2);
                *unint64_t v22 = *(v22 - 3);
                v22[1] = v25;
                _OWORD v22[2] = *(v22 - 1);
                v24 -= 48;
                if (!v24)
                {
                  unint64_t v22 = (_OWORD *)a4;
                  break;
                }
              }
            }
          }
          uint64_t result = *(__n128 *)v8;
          long long v19 = *(_OWORD *)(v8 + 32);
          v22[1] = *(_OWORD *)(v8 + 16);
          _OWORD v22[2] = v19;
          *unint64_t v22 = result;
          uint64_t v16 = v8 + 48;
          v17 += 48;
        }
        while (v8 + 48 != a2);
      }
    }
  }
  return result;
}

char *std::__inplace_merge<std::_ClassicAlgPolicy,anonymous namespace'::CurrentlyLive::Buffer::lookupRangeForValue(mlir::Value)::{lambda(anonymous namespace'::CurrentlyLive::Buffer::lookupRangeForValue(mlir::Value)::Match const&,anonymous namespace'::CurrentlyLive::Buffer::lookupRangeForValue(mlir::Value)::Match const&)#1} &,anonymous namespace'::CurrentlyLive::Buffer::lookupRangeForValue(mlir::Value)::Match*>(char *result, char *a2, char *a3, uint64_t a4, uint64_t a5, char *a6, uint64_t a7)
{
  if (a5)
  {
    uint64_t v7 = a5;
    while (v7 > a7 && a4 > a7)
    {
      if (!a4) {
        return result;
      }
      uint64_t v10 = 0;
      uint64_t v11 = -a4;
      while (1)
      {
        long long v12 = &result[v10];
        if (*((void *)a2 + 5) < *(void *)&result[v10 + 40]) {
          break;
        }
        v10 += 48;
        BOOL v71 = __CFADD__(v11++, 1);
        if (v71) {
          return result;
        }
      }
      uint64_t v13 = -v11;
      if (-v11 >= v7)
      {
        if (v11 == -1)
        {
          uint64_t v84 = (long long *)&result[v10];
          long long v105 = v84[1];
          long long v110 = v84[2];
          long long v101 = *v84;
          long long v85 = *(_OWORD *)a2;
          long long v86 = *((_OWORD *)a2 + 2);
          v84[1] = *((_OWORD *)a2 + 1);
          _OWORD v84[2] = v86;
          *uint64_t v84 = v85;
          *((_OWORD *)a2 + 1) = v105;
          *((_OWORD *)a2 + 2) = v110;
          *(_OWORD *)a2 = v101;
          return result;
        }
        if (v11 > 0) {
          uint64_t v13 = 1 - v11;
        }
        uint64_t v23 = v13 >> 1;
        if (a3 == a2)
        {
          long long v25 = a3;
        }
        else
        {
          unint64_t v24 = 0xAAAAAAAAAAAAAAABLL * ((a3 - a2) >> 4);
          long long v25 = a2;
          do
          {
            unint64_t v26 = v24 >> 1;
            long long v27 = &v25[48 * (v24 >> 1)];
            unint64_t v28 = *((void *)v27 + 5);
            uint64_t v29 = v27 + 48;
            v24 += ~(v24 >> 1);
            if (v28 < *(void *)&result[48 * v23 + 40 + v10]) {
              long long v25 = v29;
            }
            else {
              unint64_t v24 = v26;
            }
          }
          while (v24);
        }
        unint64_t v18 = &result[48 * v23 + v10];
        uint64_t v15 = 0xAAAAAAAAAAAAAAABLL * ((v25 - a2) >> 4);
      }
      else
      {
        if (v7 >= 0) {
          uint64_t v14 = v7;
        }
        else {
          uint64_t v14 = v7 + 1;
        }
        uint64_t v15 = v14 >> 1;
        if (v12 == a2)
        {
          uint64_t v16 = &result[v10];
          unint64_t v18 = a2;
        }
        else
        {
          uint64_t v16 = &result[v10];
          unint64_t v17 = 0xAAAAAAAAAAAAAAABLL * ((a2 - result - v10) >> 4);
          unint64_t v18 = &result[v10];
          do
          {
            unint64_t v19 = v17 >> 1;
            uint64_t v20 = &v18[48 * (v17 >> 1)];
            unint64_t v21 = *((void *)v20 + 5);
            unint64_t v22 = v20 + 48;
            v17 += ~(v17 >> 1);
            if (*(void *)&a2[48 * v15 + 40] < v21) {
              unint64_t v17 = v19;
            }
            else {
              unint64_t v18 = v22;
            }
          }
          while (v17);
        }
        long long v25 = &a2[48 * v15];
        uint64_t v23 = 0xAAAAAAAAAAAAAAABLL * ((v18 - v16) >> 4);
      }
      uint64_t v30 = v25;
      uint64_t v96 = a6;
      if (v18 != a2)
      {
        uint64_t v30 = v18;
        if (a2 != v25)
        {
          if (v18 + 48 == a2)
          {
            long long v103 = *((_OWORD *)v18 + 1);
            long long v107 = *((_OWORD *)v18 + 2);
            long long v98 = *(_OWORD *)v18;
            uint64_t v37 = (char *)(v25 - a2);
            uint64_t v38 = a3;
            uint64_t v91 = a7;
            uint64_t v93 = v23;
            uint64_t v39 = v15;
            memmove(v18, a2, v25 - a2);
            a7 = v91;
            uint64_t v23 = v93;
            uint64_t v15 = v39;
            a3 = v38;
            uint64_t v30 = &v37[(void)v18];
            *(_OWORD *)uint64_t v30 = v98;
            *((_OWORD *)v30 + 1) = v103;
            *((_OWORD *)v30 + 2) = v107;
          }
          else if (a2 + 48 == v25)
          {
            uint64_t v30 = v18 + 48;
            long long v104 = *((_OWORD *)v25 - 2);
            long long v108 = *((_OWORD *)v25 - 1);
            long long v99 = *((_OWORD *)v25 - 3);
            if (v25 - 48 != v18)
            {
              long long v40 = a3;
              uint64_t v92 = a7;
              uint64_t v94 = v23;
              uint64_t v41 = v15;
              memmove(v18 + 48, v18, v25 - 48 - v18);
              a7 = v92;
              uint64_t v23 = v94;
              uint64_t v15 = v41;
              a3 = v40;
            }
            *((_OWORD *)v18 + 1) = v104;
            *((_OWORD *)v18 + 2) = v108;
            *(_OWORD *)unint64_t v18 = v99;
          }
          else
          {
            unint64_t v31 = 0xAAAAAAAAAAAAAAABLL * ((a2 - v18) >> 4);
            if (v31 == 0xAAAAAAAAAAAAAAABLL * ((v25 - a2) >> 4))
            {
              uint64_t v32 = 0;
              do
              {
                long long v33 = &a2[v32];
                uint64_t v34 = &v18[v32];
                long long v102 = *(_OWORD *)&v18[v32 + 16];
                long long v106 = *(_OWORD *)&v18[v32 + 32];
                long long v97 = *(_OWORD *)&v18[v32];
                long long v35 = *(_OWORD *)&a2[v32];
                long long v36 = *(_OWORD *)&a2[v32 + 32];
                *((_OWORD *)v34 + 1) = *(_OWORD *)&a2[v32 + 16];
                *((_OWORD *)v34 + 2) = v36;
                *(_OWORD *)uint64_t v34 = v35;
                *((_OWORD *)v33 + 1) = v102;
                *((_OWORD *)v33 + 2) = v106;
                *(_OWORD *)long long v33 = v97;
                if (&v18[v32 + 48] == a2) {
                  break;
                }
                v32 += 48;
              }
              while (v33 + 48 != v25);
              uint64_t v30 = a2;
            }
            else
            {
              uint64_t v42 = 0xAAAAAAAAAAAAAAABLL * ((v25 - a2) >> 4);
              unint64_t v43 = 0xAAAAAAAAAAAAAAABLL * ((a2 - v18) >> 4);
              do
              {
                uint64_t v44 = v43;
                unint64_t v43 = v42;
                uint64_t v42 = v44 % v42;
              }
              while (v42);
              if (v43)
              {
                uint64_t v45 = &v18[48 * v43];
                do
                {
                  long long v46 = *((_OWORD *)v45 - 3);
                  long long v47 = *((_OWORD *)v45 - 2);
                  long long v48 = *((_OWORD *)v45 - 1);
                  v45 -= 48;
                  long long v109 = v48;
                  long long v100 = v46;
                  uint64_t v49 = &v45[16 * ((a2 - v18) >> 4)];
                  uint64_t v50 = v45;
                  do
                  {
                    uint64_t v51 = v50;
                    uint64_t v50 = v49;
                    long long v52 = *(_OWORD *)v49;
                    long long v53 = *((_OWORD *)v49 + 2);
                    *((_OWORD *)v51 + 1) = *((_OWORD *)v49 + 1);
                    *((_OWORD *)v51 + 2) = v53;
                    *(_OWORD *)uint64_t v51 = v52;
                    unint64_t v54 = 0xAAAAAAAAAAAAAAABLL * ((v25 - v49) >> 4);
                    BOOL v55 = __OFSUB__(v31, v54);
                    uint64_t v57 = v31 - v54;
                    char v56 = (v57 < 0) ^ v55;
                    uint64_t v49 = &v18[48 * v57];
                    if (v56) {
                      uint64_t v49 = &v50[16 * ((a2 - v18) >> 4)];
                    }
                  }
                  while (v49 != v45);
                  *((_OWORD *)v50 + 1) = v47;
                  *((_OWORD *)v50 + 2) = v109;
                  *(_OWORD *)uint64_t v50 = v100;
                }
                while (v45 != v18);
              }
              uint64_t v30 = &v18[16 * ((v25 - a2) >> 4)];
            }
          }
        }
      }
      a4 = -(v23 + v11);
      uint64_t v58 = v7 - v15;
      if (v23 + v15 >= v7 - (v23 + v15) - v11)
      {
        uint64_t v95 = v23;
        uint64_t v61 = -(v23 + v11);
        uint64_t v62 = v15;
        uint64_t v59 = a7;
        long long v25 = v18;
        uint64_t v58 = v62;
        a4 = v95;
        a3 = v30;
      }
      else
      {
        uint64_t v59 = a7;
        int64x2_t v60 = a3;
        a3 = v60;
        long long v12 = v30;
      }
      uint64_t v7 = v58;
      uint64_t result = v12;
      a2 = v25;
      a6 = v96;
      a7 = v59;
      if (!v58) {
        return result;
      }
    }
    if (a4 <= v7)
    {
      if (result != a2)
      {
        uint64_t v75 = 0;
        do
        {
          char v76 = &a6[v75];
          long long v77 = *(_OWORD *)&result[v75];
          long long v78 = *(_OWORD *)&result[v75 + 32];
          *((_OWORD *)v76 + 1) = *(_OWORD *)&result[v75 + 16];
          *((_OWORD *)v76 + 2) = v78;
          *(_OWORD *)char v76 = v77;
          v75 += 48;
        }
        while (&result[v75] != a2);
        if (v75)
        {
          uint64_t v79 = a6;
          while (a2 != a3)
          {
            if (*((void *)a2 + 5) >= *((void *)v79 + 5))
            {
              long long v80 = *(_OWORD *)v79;
              long long v81 = *((_OWORD *)v79 + 2);
              *((_OWORD *)result + 1) = *((_OWORD *)v79 + 1);
              *((_OWORD *)result + 2) = v81;
              *(_OWORD *)uint64_t result = v80;
              v79 += 48;
            }
            else
            {
              long long v82 = *(_OWORD *)a2;
              long long v83 = *((_OWORD *)a2 + 2);
              *((_OWORD *)result + 1) = *((_OWORD *)a2 + 1);
              *((_OWORD *)result + 2) = v83;
              *(_OWORD *)uint64_t result = v82;
              a2 += 48;
            }
            result += 48;
            if (&a6[v75] == v79) {
              return result;
            }
          }
          return (char *)memmove(result, v79, a6 - v79 + v75);
        }
      }
    }
    else if (a2 != a3)
    {
      uint64_t v63 = 0;
      do
      {
        uint64_t v64 = &a6[v63];
        long long v65 = *(_OWORD *)&a2[v63];
        long long v66 = *(_OWORD *)&a2[v63 + 32];
        *((_OWORD *)v64 + 1) = *(_OWORD *)&a2[v63 + 16];
        *((_OWORD *)v64 + 2) = v66;
        *(_OWORD *)uint64_t v64 = v65;
        v63 += 48;
      }
      while (&a2[v63] != a3);
      if (v63)
      {
        uint64_t v67 = &a6[v63];
        uint64_t v68 = a3 - 48;
        while (a2 != result)
        {
          unint64_t v69 = *((void *)v67 - 1);
          unint64_t v70 = *((void *)a2 - 1);
          BOOL v71 = v69 >= v70;
          if (v69 >= v70) {
            unint64_t v72 = v67 - 48;
          }
          else {
            unint64_t v72 = a2 - 48;
          }
          if (v71) {
            v67 -= 48;
          }
          else {
            a2 -= 48;
          }
          long long v73 = *(_OWORD *)v72;
          long long v74 = *((_OWORD *)v72 + 2);
          *((_OWORD *)v68 + 1) = *((_OWORD *)v72 + 1);
          *((_OWORD *)v68 + 2) = v74;
          *(_OWORD *)uint64_t v68 = v73;
          v68 -= 48;
          if (v67 == a6) {
            return result;
          }
        }
        unint64_t v87 = 0;
        do
        {
          __n128 v88 = &v68[v87];
          long long v89 = *(_OWORD *)&v67[v87 - 48];
          long long v90 = *(_OWORD *)&v67[v87 - 16];
          *((_OWORD *)v88 + 1) = *(_OWORD *)&v67[v87 - 32];
          *((_OWORD *)v88 + 2) = v90;
          *(_OWORD *)__n128 v88 = v89;
          v87 -= 48;
        }
        while (&v67[v87] != a6);
      }
    }
  }
  return result;
}

uint64_t llvm::SmallVectorImpl<llvm::SmallSetVector<mlir::Value,2u>>::erase(uint64_t *a1, uint64_t a2, uint64_t a3)
{
  uint64_t v3 = *a1;
  unsigned int v4 = *((_DWORD *)a1 + 2);
  if (*a1 + 56 * v4 != a3) {
    llvm::deallocate_buffer(*(llvm **)a2, (void *)(8 * *(unsigned int *)(a2 + 16)));
  }
  if (v3 + 56 * v4 != a2)
  {
    uint64_t v5 = v3 + 56 * v4;
    uint64_t v6 = (llvm **)(v5 - 16);
    uint64_t v7 = *(llvm ***)(v5 - 32);
    if (v6 != v7) {
      free(v7);
    }
    llvm::deallocate_buffer(*(v6 - 5), (void *)(8 * *((unsigned int *)v6 - 6)));
  }
  *((_DWORD *)a1 + 2) = -1227133513 * ((unint64_t)(a2 - v3) >> 3);
  return a2;
}

uint64_t mlir::TypeID::get<mlir::OpTrait::ConstantLike<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::ConstantLike>(void)::Empty>>()
{
  uint64_t v0 = &unk_267770000;
  {
    uint64_t v0 = (void *)&unk_267770000;
    if (v2)
    {
      uint64_t v10 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::ConstantLike<Empty>]";
      unint64_t v11 = 84;
      unint64_t v3 = llvm::StringRef::find((uint64_t *)&v10, "DesiredTypeName = ", 0x12uLL, 0);
      if (v11 >= v3) {
        unint64_t v4 = v3;
      }
      else {
        unint64_t v4 = v11;
      }
      uint64_t v5 = &v10[v4];
      unint64_t v6 = v11 - v4;
      if (v11 - v4 >= 0x12) {
        uint64_t v7 = 18;
      }
      else {
        uint64_t v7 = v11 - v4;
      }
      unint64_t v8 = v6 - v7;
      if (v8 >= v8 - 1) {
        uint64_t v9 = v8 - 1;
      }
      else {
        uint64_t v9 = v8;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::ConstantLike<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::ConstantLike>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v5[v7], v9);
      uint64_t v0 = (void *)&unk_267770000;
    }
  }
  return v0[387];
}

uint64_t mlir::OpInterface<mlir::MinimumAlignmentInterface,mlir::detail::MinimumAlignmentInterfaceInterfaceTraits>::getInterfaceFor(uint64_t a1)
{
  uint64_t v1 = *(void *)(a1 + 48);
  int v2 = *(void **)(v1 + 16);
  BOOL v3 = v2 == &mlir::detail::TypeIDResolver<void,void>::id;
  if (v2 == &mlir::detail::TypeIDResolver<void,void>::id) {
    uint64_t v4 = 0;
  }
  else {
    uint64_t v4 = *(void *)(a1 + 48);
  }
  if (v3)
  {
    uint64_t v22 = *(void *)(v1 + 8);
    uint64_t result = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)&v22);
    if (result)
    {
      uint64_t v20 = result;
      uint64_t v21 = mlir::TypeID::get<mlir::MinimumAlignmentInterface>();
      return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t))(*(void *)v20 + 104))(v20, v21, v1);
    }
  }
  else
  {
    unint64_t v6 = v4 | v1 & 0xFFFFFFFFFFFFFF00;
    unint64_t v7 = mlir::TypeID::get<mlir::MinimumAlignmentInterface>();
    unint64_t v8 = *(unsigned int *)(v6 + 40);
    if (!v8) {
      goto LABEL_14;
    }
    uint64_t v9 = *(void **)(v6 + 32);
    uint64_t v10 = &v9[2 * v8];
    do
    {
      unint64_t v11 = v8 >> 1;
      long long v12 = &v9[2 * (v8 >> 1)];
      unint64_t v14 = *v12;
      uint64_t v13 = v12 + 2;
      v8 += ~(v8 >> 1);
      if (v14 < v7) {
        uint64_t v9 = v13;
      }
      else {
        unint64_t v8 = v11;
      }
    }
    while (v8);
    if (v9 == v10 || *v9 != v7 || (uint64_t result = v9[1]) == 0)
    {
LABEL_14:
      uint64_t v16 = *(void *)(v6 + 24);
      uint64_t v17 = *(void *)(a1 + 48);
      uint64_t v18 = mlir::TypeID::get<mlir::MinimumAlignmentInterface>();
      unint64_t v19 = *(uint64_t (**)(uint64_t, uint64_t, uint64_t))(*(void *)v16 + 104);
      return v19(v16, v18, v17);
    }
  }
  return result;
}

uint64_t mlir::TypeID::get<mlir::MinimumAlignmentInterface>()
{
  uint64_t v0 = &unk_267770000;
  {
    uint64_t v0 = (void *)&unk_267770000;
    if (v2)
    {
      uint64_t v10 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::MinimumAlignmentInterface]";
      unint64_t v11 = 81;
      unint64_t v3 = llvm::StringRef::find((uint64_t *)&v10, "DesiredTypeName = ", 0x12uLL, 0);
      if (v11 >= v3) {
        unint64_t v4 = v3;
      }
      else {
        unint64_t v4 = v11;
      }
      uint64_t v5 = &v10[v4];
      unint64_t v6 = v11 - v4;
      if (v11 - v4 >= 0x12) {
        uint64_t v7 = 18;
      }
      else {
        uint64_t v7 = v11 - v4;
      }
      unint64_t v8 = v6 - v7;
      if (v8 >= v8 - 1) {
        uint64_t v9 = v8 - 1;
      }
      else {
        uint64_t v9 = v8;
      }
      mlir::detail::TypeIDResolver<mlir::MinimumAlignmentInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v5[v7], v9);
      uint64_t v0 = (void *)&unk_267770000;
    }
  }
  return v0[389];
}

ZinIrHalH13g *mlir::detail::walk<mlir::ForwardIterator>(mlir::ForwardIterator *a1, mlir::Operation *a2, uint64_t a3, int a4)
{
  if (!a4) {
    ((void (*)(uint64_t, mlir::ForwardIterator *))a2)(a3, a1);
  }
  uint64_t result = (ZinIrHalH13g *)mlir::ForwardIterator::makeIterable(a1, a2);
  if (v8)
  {
    uint64_t v9 = result;
    uint64_t v10 = (ZinIrHalH13g *)((char *)result + 24 * v8);
    do
    {
      for (uint64_t i = (ZinIrHalH13g *)*((void *)v9 + 1); i != v9; uint64_t i = (ZinIrHalH13g *)*((void *)i + 1))
      {
        long long v12 = (void *)((char *)i - 8);
        if (!i) {
          long long v12 = 0;
        }
        uint64_t v13 = (ZinIrHalH13g *)(v12 + 4);
        uint64_t result = (ZinIrHalH13g *)v12[5];
        if (result != (ZinIrHalH13g *)(v12 + 4))
        {
          do
          {
            unint64_t v14 = (ZinIrHalH13g *)*((void *)result + 1);
            ZinIrHalH13g::~ZinIrHalH13g(result);
            mlir::detail::walk<mlir::ForwardIterator>();
            uint64_t result = v14;
          }
          while (v14 != v13);
        }
      }
      uint64_t v9 = (ZinIrHalH13g *)((char *)v9 + 24);
    }
    while (v9 != v10);
  }
  if (a4 == 1)
  {
    return (ZinIrHalH13g *)((uint64_t (*)(uint64_t, mlir::ForwardIterator *))a2)(a3, a1);
  }
  return result;
}

void _ZN4llvm12function_refIFvPN4mlir9OperationEEE11callback_fnIZNS1_6detail4walkILNS1_9WalkOrderE1ENS1_15ForwardIteratorERZNS7_10AllocRange16getRangeForValueENS1_5ValueExE3__0NS1_25MinimumAlignmentInterfaceEvEENSt3__19enable_ifIXaantsr4llvm9is_one_ofIT2_S3_PNS1_6RegionEPNS1_5BlockEEE5valuesr3std7is_sameIT3_vEE5valueESN_E4typeES3_OT1_EUlS3_E_EEvlS3_(uint64_t ***a1, uint64_t a2)
{
  if (mlir::OpInterface<mlir::MinimumAlignmentInterface,mlir::detail::MinimumAlignmentInterfaceInterfaceTraits>::getInterfaceFor(a2))
  {
    if (a2)
    {
      uint64_t InterfaceFor = mlir::OpInterface<mlir::MinimumAlignmentInterface,mlir::detail::MinimumAlignmentInterfaceInterfaceTraits>::getInterfaceFor(a2);
      uint64_t v5 = *a1;
      v12[0] = a2;
      v12[1] = InterfaceFor;
      if ((*(unsigned char *)(a2 + 46) & 0x80) != 0)
      {
        uint64_t v6 = *(unsigned int *)(a2 + 68);
        if (v6)
        {
          uint64_t v7 = (uint64_t *)(*(void *)(a2 + 72) + 24);
          do
          {
            if (mlir::matchValueThrough<mlir::MemoryMapperInterface>(*v7, **v5))
            {
              uint64_t v8 = *v5[1];
              uint64_t canMapOperands = mlir::MemoryMapperInterface::canMapOperands((mlir::MemoryMapperInterface *)v12);
              if (v8 < 0) {
                uint64_t v8 = -v8;
              }
              unsigned int v16 = 64;
              uint64_t v15 = v8;
              if (canMapOperands >= 0) {
                uint64_t v10 = canMapOperands;
              }
              else {
                uint64_t v10 = -canMapOperands;
              }
              unsigned int v14 = 64;
              uint64_t v13 = v10;
              llvm::APIntOps::GreatestCommonDivisor((uint64_t)&v15, (uint64_t)&v13, (uint64_t)&v17);
              if (v18 > 0x40)
              {
                unint64_t v11 = *v17;
                MEMORY[0x21667D390](v17, 0x1000C8000313F17);
              }
              else
              {
                unint64_t v11 = (unint64_t)v17;
              }
              if (v14 >= 0x41 && v13) {
                MEMORY[0x21667D390](v13, 0x1000C8000313F17);
              }
              if (v16 >= 0x41)
              {
                if (v15) {
                  MEMORY[0x21667D390](v15, 0x1000C8000313F17);
                }
              }
              *v5[1] = v10 * v8 / v11;
            }
            v7 += 4;
            --v6;
          }
          while (v6);
        }
      }
    }
  }
}

uint64_t mlir::matchValueThrough<mlir::MemoryMapperInterface>(uint64_t a1, uint64_t a2)
{
  uint64_t v10 = a1;
  if (a1 == a2) {
    return 1;
  }
  uint64_t result = mlir::Value::getDefiningOp((mlir::Value *)&v10);
  if (result)
  {
    uint64_t v4 = result;
    uint64_t result = mlir::OpInterface<mlir::MemoryMapperInterface,mlir::detail::MemoryMapperInterfaceInterfaceTraits>::getInterfaceFor(result);
    if (result)
    {
      if ((*(unsigned char *)(v4 + 46) & 0x80) != 0 && (uint64_t v5 = *(unsigned int *)(v4 + 68), v5))
      {
        uint64_t v6 = v5 - 1;
        uint64_t v7 = (uint64_t *)(*(void *)(v4 + 72) + 24);
        do
        {
          uint64_t v8 = v6;
          uint64_t v9 = *v7;
          v7 += 4;
          uint64_t result = mlir::matchValueThrough<mlir::MemoryMapperInterface>(v9, a2);
          if (result) {
            break;
          }
          uint64_t v6 = v8 - 1;
        }
        while (v8);
      }
      else
      {
        return 0;
      }
    }
  }
  return result;
}

uint64_t llvm::SetVector<mlir::detail::AllocRange,llvm::SmallVector<mlir::detail::AllocRange,0u>,llvm::DenseSet<mlir::detail::AllocRange,llvm::DenseMapInfo<mlir::detail::AllocRange,void>>,0u>::insert(uint64_t a1, unint64_t *a2)
{
  unint64_t v2 = (unint64_t)a2;
  uint64_t v17 = 0;
  int v4 = llvm::DenseMapBase<llvm::DenseMap<mlir::detail::AllocRange,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::detail::AllocRange,void>,llvm::detail::DenseSetPair<mlir::detail::AllocRange>>,mlir::detail::AllocRange,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::detail::AllocRange,void>,llvm::detail::DenseSetPair<mlir::detail::AllocRange>>::LookupBucketFor<mlir::detail::AllocRange>((uint64_t *)a1, a2, &v17);
  if ((v4 & 1) == 0)
  {
    uint64_t v5 = llvm::DenseMapBase<llvm::DenseMap<mlir::detail::AllocRange,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::detail::AllocRange,void>,llvm::detail::DenseSetPair<mlir::detail::AllocRange>>,mlir::detail::AllocRange,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::detail::AllocRange,void>,llvm::detail::DenseSetPair<mlir::detail::AllocRange>>::InsertIntoBucketImpl<mlir::detail::AllocRange>(a1, v2, (unint64_t *)v2, v17);
    long long v6 = *(_OWORD *)v2;
    long long v7 = *(_OWORD *)(v2 + 16);
    v5[4] = *(void *)(v2 + 32);
    *(_OWORD *)uint64_t v5 = v6;
    *((_OWORD *)v5 + 1) = v7;
    uint64_t v8 = a1 + 24;
    unint64_t v9 = *(void *)(a1 + 24);
    uint64_t v10 = *(unsigned int *)(a1 + 32);
    if (v10 >= *(_DWORD *)(a1 + 36))
    {
      unint64_t v15 = v10 + 1;
      if (v9 <= v2 && v9 + 40 * v10 > v2)
      {
        unint64_t v16 = v2 - v9;
        llvm::SmallVectorBase<unsigned int>::grow_pod(v8, (void *)(a1 + 40), v15, 40);
        unint64_t v9 = *(void *)(a1 + 24);
        unint64_t v2 = v9 + v16;
      }
      else
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod(v8, (void *)(a1 + 40), v15, 40);
        unint64_t v9 = *(void *)(a1 + 24);
      }
    }
    unint64_t v11 = v9 + 40 * *(unsigned int *)(a1 + 32);
    long long v12 = *(_OWORD *)v2;
    long long v13 = *(_OWORD *)(v2 + 16);
    *(void *)(v11 + 32) = *(void *)(v2 + 32);
    *(_OWORD *)unint64_t v11 = v12;
    *(_OWORD *)(v11 + 16) = v13;
    ++*(_DWORD *)(a1 + 32);
  }
  return v4 ^ 1u;
}

uint64_t llvm::DenseMapBase<llvm::DenseMap<mlir::detail::AllocRange,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::detail::AllocRange,void>,llvm::detail::DenseSetPair<mlir::detail::AllocRange>>,mlir::detail::AllocRange,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::detail::AllocRange,void>,llvm::detail::DenseSetPair<mlir::detail::AllocRange>>::LookupBucketFor<mlir::detail::AllocRange>(uint64_t *a1, unint64_t *a2, void *a3)
{
  int v3 = *((_DWORD *)a1 + 4);
  if (v3)
  {
    uint64_t v4 = *a1;
    unint64_t v5 = *a2;
    long long v6 = &unk_267770000;
    {
      uint64_t v23 = a3;
      uint64_t v21 = a2;
      uint64_t v24 = v4;
      int v22 = v3;
      unint64_t v25 = v5;
      long long v6 = &unk_267770000;
      uint64_t v4 = v24;
      unint64_t v5 = v25;
      int v3 = v22;
      a2 = v21;
      a3 = v23;
      if (v19)
      {
        unint64_t v20 = llvm::hashing::detail::fixed_seed_override;
        if (!llvm::hashing::detail::fixed_seed_override) {
          unint64_t v20 = 0xFF51AFD7ED558CCDLL;
        }
        llvm::hashing::detail::get_execution_seed(void)::seed = v20;
        long long v6 = (void *)&unk_267770000;
        uint64_t v4 = v24;
        unint64_t v5 = v25;
        int v3 = v22;
        a2 = v21;
        a3 = v23;
      }
    }
    uint64_t v7 = (v6[385] + 8 * v5) ^ HIDWORD(v5);
    unint64_t v8 = 0x9DDFEA08EB382D69 * (HIDWORD(v5) ^ ((0x9DDFEA08EB382D69 * v7) >> 47) ^ (0x9DDFEA08EB382D69 * v7));
    int v9 = -348639895 * ((v8 >> 47) ^ v8);
    int v10 = v3 - 1;
    unsigned int v11 = v9 & (v3 - 1);
    long long v12 = (void *)(v4 + 40 * v11);
    uint64_t v13 = *v12;
    if (*a2 == *v12)
    {
      uint64_t result = 1;
    }
    else
    {
      unint64_t v15 = 0;
      int v16 = 1;
      uint64_t result = 1;
      while (v13 != -4096)
      {
        if (v15) {
          BOOL v17 = 0;
        }
        else {
          BOOL v17 = v13 == -8192;
        }
        if (v17) {
          unint64_t v15 = v12;
        }
        unsigned int v18 = v11 + v16++;
        unsigned int v11 = v18 & v10;
        long long v12 = (void *)(v4 + 40 * (v18 & v10));
        uint64_t v13 = *v12;
        if (*a2 == *v12) {
          goto LABEL_6;
        }
      }
      uint64_t result = 0;
      if (v15) {
        long long v12 = v15;
      }
    }
  }
  else
  {
    long long v12 = 0;
    uint64_t result = 0;
  }
LABEL_6:
  *a3 = v12;
  return result;
}

void *llvm::DenseMapBase<llvm::DenseMap<mlir::detail::AllocRange,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::detail::AllocRange,void>,llvm::detail::DenseSetPair<mlir::detail::AllocRange>>,mlir::detail::AllocRange,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::detail::AllocRange,void>,llvm::detail::DenseSetPair<mlir::detail::AllocRange>>::InsertIntoBucketImpl<mlir::detail::AllocRange>(uint64_t a1, uint64_t a2, unint64_t *a3, void *a4)
{
  int v6 = *(_DWORD *)(a1 + 8);
  unsigned int v7 = *(_DWORD *)(a1 + 16);
  if (4 * v6 + 4 >= 3 * v7)
  {
    v7 *= 2;
  }
  else if (v7 + ~v6 - *(_DWORD *)(a1 + 12) > v7 >> 3)
  {
    goto LABEL_3;
  }
  llvm::DenseMap<mlir::detail::AllocRange,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::detail::AllocRange,void>,llvm::detail::DenseSetPair<mlir::detail::AllocRange>>::grow(a1, v7);
  int v9 = 0;
  llvm::DenseMapBase<llvm::DenseMap<mlir::detail::AllocRange,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::detail::AllocRange,void>,llvm::detail::DenseSetPair<mlir::detail::AllocRange>>,mlir::detail::AllocRange,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::detail::AllocRange,void>,llvm::detail::DenseSetPair<mlir::detail::AllocRange>>::LookupBucketFor<mlir::detail::AllocRange>((uint64_t *)a1, a3, &v9);
  a4 = v9;
LABEL_3:
  ++*(_DWORD *)(a1 + 8);
  if (*a4 != -4096) {
    --*(_DWORD *)(a1 + 12);
  }
  return a4;
}

char *llvm::DenseMap<mlir::detail::AllocRange,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::detail::AllocRange,void>,llvm::detail::DenseSetPair<mlir::detail::AllocRange>>::grow(uint64_t a1, int a2)
{
  uint64_t v3 = *(unsigned int *)(a1 + 16);
  uint64_t v4 = *(llvm **)a1;
  unint64_t v5 = (a2 - 1) | ((unint64_t)(a2 - 1) >> 1);
  unint64_t v6 = v5 | (v5 >> 2) | ((v5 | (v5 >> 2)) >> 4);
  int v7 = ((v6 | (v6 >> 8)) >> 16) | v6 | (v6 >> 8);
  if ((v7 + 1) > 0x40) {
    unsigned int v8 = v7 + 1;
  }
  else {
    unsigned int v8 = 64;
  }
  *(_DWORD *)(a1 + 16) = v8;
  uint64_t result = (char *)llvm::allocate_buffer(40 * v8, (std::align_val_t)8uLL);
  *(void *)a1 = result;
  if (v4)
  {
    *(void *)(a1 + 8) = 0;
    int v10 = *(_DWORD *)(a1 + 16);
    if (v10)
    {
      unsigned int v11 = &result[40 * v10];
      *(void *)&long long v12 = -1;
      *((void *)&v12 + 1) = -1;
      do
      {
        *(void *)uint64_t result = -4096;
        *(_OWORD *)(result + 8) = v12;
        *(_OWORD *)(result + 24) = v12;
        result += 40;
      }
      while (result != v11);
    }
    if (v3)
    {
      uint64_t v13 = 40 * v3;
      unsigned int v14 = v4;
      do
      {
        if ((*(void *)v14 | 0x1000) != 0xFFFFFFFFFFFFF000)
        {
          uint64_t v21 = 0;
          llvm::DenseMapBase<llvm::DenseMap<mlir::detail::AllocRange,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::detail::AllocRange,void>,llvm::detail::DenseSetPair<mlir::detail::AllocRange>>,mlir::detail::AllocRange,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::detail::AllocRange,void>,llvm::detail::DenseSetPair<mlir::detail::AllocRange>>::LookupBucketFor<mlir::detail::AllocRange>((uint64_t *)a1, (unint64_t *)v14, &v21);
          unint64_t v15 = (_OWORD *)v21;
          long long v16 = *(_OWORD *)v14;
          long long v17 = *((_OWORD *)v14 + 1);
          *(void *)(v21 + 32) = *((void *)v14 + 4);
          _OWORD *v15 = v16;
          v15[1] = v17;
          ++*(_DWORD *)(a1 + 8);
        }
        unsigned int v14 = (llvm *)((char *)v14 + 40);
        v13 -= 40;
      }
      while (v13);
    }
    llvm::deallocate_buffer(v4, (void *)(40 * v3));
  }
  *(void *)(a1 + 8) = 0;
  int v18 = *(_DWORD *)(a1 + 16);
  if (v18)
  {
    int v19 = &result[40 * v18];
    *(void *)&long long v20 = -1;
    *((void *)&v20 + 1) = -1;
    do
    {
      *(void *)uint64_t result = -4096;
      *(_OWORD *)(result + 8) = v20;
      *(_OWORD *)(result + 24) = v20;
      result += 40;
    }
    while (result != v19);
  }
  return result;
}

uint64_t llvm::DenseMap<mlir::detail::AllocRange,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::detail::AllocRange,void>,llvm::detail::DenseSetPair<mlir::detail::AllocRange>>::shrink_and_clear(uint64_t result)
{
  uint64_t v1 = *(unsigned int *)(result + 16);
  int v2 = *(_DWORD *)(result + 8);
  int v3 = 1 << (33 - __clz(v2 - 1));
  if (v3 <= 64) {
    int v3 = 64;
  }
  if (v2) {
    int v4 = v3;
  }
  else {
    int v4 = 0;
  }
  if (v4 != v1) {
    llvm::deallocate_buffer(*(llvm **)result, (void *)(40 * v1));
  }
  *(void *)(result + 8) = 0;
  if (v1)
  {
    unint64_t v5 = *(llvm **)result;
    uint64_t v6 = *(void *)result + 40 * v1;
    *(void *)&long long v7 = -1;
    *((void *)&v7 + 1) = -1;
    do
    {
      *(void *)unint64_t v5 = -4096;
      *(_OWORD *)((char *)v5 + 8) = v7;
      *(_OWORD *)((char *)v5 + 24) = v7;
      unint64_t v5 = (llvm *)((char *)v5 + 40);
    }
    while (v5 != (llvm *)v6);
  }
  return result;
}

void std::default_delete<mlir::Liveness>::operator()[abi:nn180100](uint64_t a1, uint64_t a2)
{
  if (a2)
  {
    unsigned int v3 = *(_DWORD *)(a2 + 24);
    int v4 = *(llvm **)(a2 + 8);
    if (v3)
    {
      uint64_t v5 = 336 * v3;
      do
      {
        if ((*(void *)v4 | 0x1000) != 0xFFFFFFFFFFFFF000)
        {
          uint64_t v6 = (void *)*((void *)v4 + 23);
          if (v6 != *((void **)v4 + 22)) {
            free(v6);
          }
          long long v7 = (void *)*((void *)v4 + 3);
          if (v7 != *((void **)v4 + 2)) {
            free(v7);
          }
        }
        int v4 = (llvm *)((char *)v4 + 336);
        v5 -= 336;
      }
      while (v5);
      int v4 = *(llvm **)(a2 + 8);
      uint64_t v8 = 336 * *(unsigned int *)(a2 + 24);
    }
    else
    {
      uint64_t v8 = 0;
    }
    llvm::deallocate_buffer(v4, (void *)v8);
  }
}

void sub_2113BF180()
{
  JUMPOUT(0x21667D3C0);
}

uint64_t mlir::DataFlowSolver::getOrCreateState<mlir::dataflow::Lattice<mlir::dataflow::OffsetLatticeValue>,mlir::Value>(uint64_t a1, uint64_t a2)
{
  uint64_t v8 = *MEMORY[0x263EF8340];
  int v2 = (uint64_t *)(a1 + 120);
  unint64_t v6 = a2 & 0xFFFFFFFFFFFFFFF9 | 4;
  uint64_t v7 = mlir::TypeID::get<mlir::dataflow::Lattice<mlir::dataflow::OffsetLatticeValue>>();
  uint64_t v5 = 0;
  if ((llvm::DenseMapBase<llvm::DenseMap<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::TypeID>,void>,llvm::detail::DenseMapPair<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>>>,std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::TypeID>,void>,llvm::detail::DenseMapPair<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>>>::LookupBucketFor<std::pair<mlir::ProgramPoint,mlir::TypeID>>(v2, (uint64_t *)&v6, &v5) & 1) == 0)
  {
    int v4 = llvm::DenseMapBase<llvm::DenseMap<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::TypeID>,void>,llvm::detail::DenseMapPair<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>>>,std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::TypeID>,void>,llvm::detail::DenseMapPair<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>>>::InsertIntoBucketImpl<std::pair<mlir::ProgramPoint,mlir::TypeID>>((uint64_t)v2, (uint64_t)&v6, (uint64_t *)&v6, v5);
    *int v4 = v6;
    v4[1] = v7;
    v4[2] = 0;
    goto LABEL_5;
  }
  uint64_t result = v5[2];
  if (!result) {
LABEL_5:
  }
    operator new();
  return result;
}

uint64_t mlir::TypeID::get<mlir::dataflow::Lattice<mlir::dataflow::OffsetLatticeValue>>()
{
  uint64_t v0 = &unk_267770000;
  {
    uint64_t v0 = (void *)&unk_267770000;
    if (v2)
    {
      int v10 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::dataflow::Lattice<mlir::dataflow::OffsetLatticeValue>]";
      unint64_t v11 = 109;
      unint64_t v3 = llvm::StringRef::find((uint64_t *)&v10, "DesiredTypeName = ", 0x12uLL, 0);
      if (v11 >= v3) {
        unint64_t v4 = v3;
      }
      else {
        unint64_t v4 = v11;
      }
      uint64_t v5 = &v10[v4];
      unint64_t v6 = v11 - v4;
      if (v11 - v4 >= 0x12) {
        uint64_t v7 = 18;
      }
      else {
        uint64_t v7 = v11 - v4;
      }
      unint64_t v8 = v6 - v7;
      if (v8 >= v8 - 1) {
        uint64_t v9 = v8 - 1;
      }
      else {
        uint64_t v9 = v8;
      }
      mlir::detail::TypeIDResolver<mlir::dataflow::Lattice<mlir::dataflow::OffsetLatticeValue>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v5[v7], v9);
      uint64_t v0 = (void *)&unk_267770000;
    }
  }
  return v0[391];
}

uint64_t llvm::DenseMapBase<llvm::DenseMap<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::TypeID>,void>,llvm::detail::DenseMapPair<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>>>,std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::TypeID>,void>,llvm::detail::DenseMapPair<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>>>::LookupBucketFor<std::pair<mlir::ProgramPoint,mlir::TypeID>>(uint64_t *a1, uint64_t *a2, void *a3)
{
  int v3 = *((_DWORD *)a1 + 4);
  if (v3)
  {
    uint64_t v4 = *a1;
    uint64_t v5 = *a2;
    uint64_t v6 = a2[1];
    unint64_t v7 = ((0x2500000000 * *a2) | (v6 >> 4) ^ (v6 >> 9))
       + ~((unint64_t)((v6 >> 4) ^ (v6 >> 9)) << 32);
    unint64_t v8 = (v7 ^ (v7 >> 22)) + ~((v7 ^ (v7 >> 22)) << 13);
    unint64_t v9 = (9 * (v8 ^ (v8 >> 8))) ^ ((9 * (v8 ^ (v8 >> 8))) >> 15);
    int v10 = ((v9 + ~(v9 << 27)) >> 31) ^ (v9 + ~(v9 << 27));
    int v11 = v3 - 1;
    unsigned int v12 = (v3 - 1) & v10;
    uint64_t v13 = (void *)(*a1 + 24 * v12);
    uint64_t v15 = *v13;
    uint64_t v14 = v13[1];
    if (v5 == *v13 && v6 == v14)
    {
      uint64_t result = 1;
      *a3 = v13;
    }
    else
    {
      long long v17 = 0;
      int v18 = 1;
      uint64_t result = 1;
      while (v15 != -4096 || v14 != -4096)
      {
        if (v17) {
          BOOL v20 = 0;
        }
        else {
          BOOL v20 = v14 == -8192;
        }
        if (v20 && v15 == -8192) {
          long long v17 = v13;
        }
        unsigned int v22 = v12 + v18++;
        unsigned int v12 = v22 & v11;
        uint64_t v13 = (void *)(v4 + 24 * (v22 & v11));
        uint64_t v15 = *v13;
        uint64_t v14 = v13[1];
        if (v5 == *v13 && v6 == v14)
        {
          *a3 = v13;
          return result;
        }
      }
      uint64_t result = 0;
      if (v17) {
        uint64_t v13 = v17;
      }
      *a3 = v13;
    }
  }
  else
  {
    uint64_t result = 0;
    *a3 = 0;
  }
  return result;
}

void *llvm::DenseMapBase<llvm::DenseMap<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::TypeID>,void>,llvm::detail::DenseMapPair<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>>>,std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::TypeID>,void>,llvm::detail::DenseMapPair<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>>>::InsertIntoBucketImpl<std::pair<mlir::ProgramPoint,mlir::TypeID>>(uint64_t a1, uint64_t a2, uint64_t *a3, void *a4)
{
  int v6 = *(_DWORD *)(a1 + 8);
  unsigned int v7 = *(_DWORD *)(a1 + 16);
  if (4 * v6 + 4 >= 3 * v7)
  {
    v7 *= 2;
    goto LABEL_8;
  }
  if (v7 + ~v6 - *(_DWORD *)(a1 + 12) <= v7 >> 3)
  {
LABEL_8:
    llvm::DenseMap<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::TypeID>,void>,llvm::detail::DenseMapPair<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>>>::grow(a1, v7);
    unint64_t v9 = 0;
    llvm::DenseMapBase<llvm::DenseMap<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::TypeID>,void>,llvm::detail::DenseMapPair<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>>>,std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::TypeID>,void>,llvm::detail::DenseMapPair<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>>>::LookupBucketFor<std::pair<mlir::ProgramPoint,mlir::TypeID>>((uint64_t *)a1, a3, &v9);
    a4 = v9;
  }
  ++*(_DWORD *)(a1 + 8);
  if (*a4 != -4096 || a4[1] != -4096) {
    --*(_DWORD *)(a1 + 12);
  }
  return a4;
}

int64x2_t *llvm::DenseMap<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::TypeID>,void>,llvm::detail::DenseMapPair<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>>>::grow(uint64_t a1, int a2)
{
  uint64_t v3 = *(unsigned int *)(a1 + 16);
  uint64_t v4 = *(uint64_t **)a1;
  unint64_t v5 = (a2 - 1) | ((unint64_t)(a2 - 1) >> 1);
  unint64_t v6 = v5 | (v5 >> 2) | ((v5 | (v5 >> 2)) >> 4);
  int v7 = ((v6 | (v6 >> 8)) >> 16) | v6 | (v6 >> 8);
  if ((v7 + 1) > 0x40) {
    unsigned int v8 = v7 + 1;
  }
  else {
    unsigned int v8 = 64;
  }
  *(_DWORD *)(a1 + 16) = v8;
  uint64_t result = (int64x2_t *)llvm::allocate_buffer(24 * v8, (std::align_val_t)8uLL);
  *(void *)a1 = result;
  if (v4)
  {
    uint64_t v10 = 3 * v3;
    llvm::DenseMapBase<llvm::DenseMap<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::TypeID>,void>,llvm::detail::DenseMapPair<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>>>,std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::TypeID>,void>,llvm::detail::DenseMapPair<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>>>::moveFromOldBuckets(a1, v4, &v4[v10]);
    llvm::deallocate_buffer((llvm *)v4, (void *)(v10 * 8));
  }
  *(void *)(a1 + 8) = 0;
  unsigned int v11 = *(_DWORD *)(a1 + 16);
  if (v11)
  {
    unint64_t v12 = 24 * v11 - 24;
    if (v12 < 0x18)
    {
      uint64_t v13 = result;
LABEL_14:
      int v18 = (int64x2_t *)((char *)result + 24 * v11);
      int64x2_t v19 = vdupq_n_s64(0xFFFFFFFFFFFFF000);
      do
      {
        *uint64_t v13 = v19;
        uint64_t v13 = (int64x2_t *)((char *)v13 + 24);
      }
      while (v13 != v18);
      return result;
    }
    unint64_t v14 = v12 / 0x18 + 1;
    uint64_t v13 = (int64x2_t *)((char *)result + 24 * (v14 & 0x1FFFFFFFFFFFFFFELL));
    int64x2_t v15 = vdupq_n_s64(0xFFFFFFFFFFFFF000);
    uint64_t v16 = v14 & 0x1FFFFFFFFFFFFFFELL;
    long long v17 = result;
    do
    {
      int64x2_t *v17 = v15;
      *(int64x2_t *)((char *)v17 + 24) = v15;
      v17 += 3;
      v16 -= 2;
    }
    while (v16);
    if (v14 != (v14 & 0x1FFFFFFFFFFFFFFELL)) {
      goto LABEL_14;
    }
  }
  return result;
}

uint64_t llvm::DenseMapBase<llvm::DenseMap<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::TypeID>,void>,llvm::detail::DenseMapPair<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>>>,std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::TypeID>,void>,llvm::detail::DenseMapPair<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>>>::moveFromOldBuckets(uint64_t result, uint64_t *a2, uint64_t *a3)
{
  uint64_t v5 = result;
  *(void *)(result + 8) = 0;
  unsigned int v6 = *(_DWORD *)(result + 16);
  if (v6)
  {
    int v7 = *(int64x2_t **)result;
    unint64_t v8 = 24 * v6 - 24;
    if (v8 < 0x18)
    {
      unint64_t v9 = *(int64x2_t **)result;
LABEL_7:
      unint64_t v14 = (int64x2_t *)((char *)v7 + 24 * v6);
      int64x2_t v15 = vdupq_n_s64(0xFFFFFFFFFFFFF000);
      do
      {
        *unint64_t v9 = v15;
        unint64_t v9 = (int64x2_t *)((char *)v9 + 24);
      }
      while (v9 != v14);
      goto LABEL_11;
    }
    unint64_t v10 = v8 / 0x18 + 1;
    unint64_t v9 = (int64x2_t *)((char *)v7 + 24 * (v10 & 0x1FFFFFFFFFFFFFFELL));
    int64x2_t v11 = vdupq_n_s64(0xFFFFFFFFFFFFF000);
    uint64_t v12 = v10 & 0x1FFFFFFFFFFFFFFELL;
    uint64_t v13 = *(int64x2_t **)result;
    do
    {
      *uint64_t v13 = v11;
      *(int64x2_t *)((char *)v13 + 24) = v11;
      v13 += 3;
      v12 -= 2;
    }
    while (v12);
    if (v10 != (v10 & 0x1FFFFFFFFFFFFFFELL)) {
      goto LABEL_7;
    }
  }
LABEL_11:
  while (a2 != a3)
  {
    uint64_t v16 = a2[1];
    if ((*a2 != -4096 || v16 != -4096) && (*a2 != -8192 || v16 != -8192))
    {
      int64x2_t v19 = 0;
      llvm::DenseMapBase<llvm::DenseMap<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::TypeID>,void>,llvm::detail::DenseMapPair<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>>>,std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::TypeID>,void>,llvm::detail::DenseMapPair<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>>>::LookupBucketFor<std::pair<mlir::ProgramPoint,mlir::TypeID>>((uint64_t *)v5, a2, &v19);
      long long v17 = v19;
      *int64x2_t v19 = *a2;
      v17[1] = a2[1];
      uint64_t v18 = a2[2];
      a2[2] = 0;
      unint64_t v17[2] = v18;
      ++*(_DWORD *)(v5 + 8);
      uint64_t result = a2[2];
      a2[2] = 0;
      if (result) {
        uint64_t result = (*(uint64_t (**)(uint64_t))(*(void *)result + 8))(result);
      }
    }
    a2 += 3;
  }
  return result;
}

void mlir::dataflow::Lattice<mlir::dataflow::OffsetLatticeValue>::~Lattice(mlir::AnalysisState *this)
{
  *(void *)this = &unk_26C3803A8;
  int v2 = (char *)*((void *)this + 21);
  if (v2 != (char *)this + 184) {
    free(v2);
  }
  *(void *)this = &unk_26C3802A8;
  uint64_t v3 = (char *)*((void *)this + 15);
  if (v3 != (char *)this + 136) {
    free(v3);
  }
  uint64_t v4 = (void *)*((void *)this + 8);
  if (v4 != *((void **)this + 7)) {
    free(v4);
  }

  mlir::AnalysisState::~AnalysisState(this);
}

{
  char *v2;
  char *v3;
  void *v4;

  *(void *)this = &unk_26C3803A8;
  int v2 = (char *)*((void *)this + 21);
  if (v2 != (char *)this + 184) {
    free(v2);
  }
  *(void *)this = &unk_26C3802A8;
  uint64_t v3 = (char *)*((void *)this + 15);
  if (v3 != (char *)this + 136) {
    free(v3);
  }
  uint64_t v4 = (void *)*((void *)this + 8);
  if (v4 != *((void **)this + 7)) {
    free(v4);
  }
  mlir::AnalysisState::~AnalysisState(this);
}

void sub_2113BF9A4()
{
  JUMPOUT(0x21667D3C0);
}

llvm::raw_ostream *mlir::dataflow::Lattice<mlir::dataflow::OffsetLatticeValue>::print(uint64_t a1, llvm::raw_ostream *a2)
{
  return mlir::dataflow::OffsetLatticeValue::print((llvm::raw_ostream *)(a1 + 168), a2);
}

uint64_t mlir::dataflow::Lattice<mlir::dataflow::OffsetLatticeValue>::meet()
{
  return 0;
}

uint64_t llvm::MapVector<mlir::Value,mlir::dataflow::TensorAllocAnalysis::AllocInfo,llvm::DenseMap<mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>,llvm::SmallVector<std::pair<mlir::Value,mlir::dataflow::TensorAllocAnalysis::AllocInfo>,0u>>::try_emplace<mlir::dataflow::TensorAllocAnalysis::AllocInfo>(uint64_t a1, unint64_t *a2, long long *a3)
{
  unint64_t v6 = *a2;
  BOOL v20 = 0;
  unint64_t v21 = v6;
  LODWORD(v22) = 0;
  if (llvm::DenseMapBase<llvm::DenseMap<mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>,mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>::LookupBucketFor<mlir::Value>((uint64_t *)a1, &v21, &v20))return *(void *)(a1 + 24) + 24 * *((unsigned int *)v20 + 2); {
  unint64_t v8 = llvm::DenseMapBase<llvm::DenseMap<mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>,mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>::InsertIntoBucketImpl<mlir::Value>(a1, (uint64_t)&v21, &v21, v20);
  }
  *unint64_t v8 = v21;
  *((_DWORD *)v8 + 2) = v22;
  unint64_t v9 = (void *)(a1 + 24);
  uint64_t v10 = *(unsigned int *)(a1 + 32);
  *((_DWORD *)v8 + 2) = v10;
  if (v10 >= *(_DWORD *)(a1 + 36))
  {
    unint64_t v21 = *a2;
    long long v22 = *a3;
    unint64_t v13 = v10 + 1;
    BOOL v14 = *v9 + 24 * (unint64_t)v10 > (unint64_t)&v21;
    if (*v9 <= (unint64_t)&v21 && v14)
    {
      int64x2_t v19 = (char *)&v21 - *v9;
      llvm::SmallVectorBase<unsigned int>::grow_pod(a1 + 24, (void *)(a1 + 40), v13, 24);
      uint64_t v15 = *(void *)(a1 + 24);
      uint64_t v16 = (unint64_t *)&v19[v15];
    }
    else
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod(a1 + 24, (void *)(a1 + 40), v13, 24);
      uint64_t v15 = *(void *)(a1 + 24);
      uint64_t v16 = &v21;
    }
    uint64_t v17 = v15 + 24 * *(unsigned int *)(a1 + 32);
    long long v18 = *(_OWORD *)v16;
    *(void *)(v17 + 16) = v16[2];
    *(_OWORD *)uint64_t v17 = v18;
  }
  else
  {
    uint64_t v11 = *(void *)(a1 + 24) + 24 * v10;
    *(void *)uint64_t v11 = *a2;
    *(_OWORD *)(v11 + 8) = *a3;
  }
  unsigned int v12 = *(_DWORD *)(a1 + 32) + 1;
  *(_DWORD *)(a1 + 32) = v12;
  return *v9 + 24 * v12 - 24;
}

uint64_t llvm::DenseMapBase<llvm::DenseMap<mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>,mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>::LookupBucketFor<mlir::Value>(uint64_t *a1, unint64_t *a2, void *a3)
{
  int v3 = *((_DWORD *)a1 + 4);
  if (v3)
  {
    uint64_t v4 = *a1;
    unint64_t v5 = *a2;
    unint64_t v6 = &unk_267770000;
    {
      uint64_t v23 = a3;
      unint64_t v21 = a2;
      uint64_t v24 = v4;
      int v22 = v3;
      unint64_t v25 = v5;
      unint64_t v6 = &unk_267770000;
      uint64_t v4 = v24;
      unint64_t v5 = v25;
      int v3 = v22;
      a2 = v21;
      a3 = v23;
      if (v19)
      {
        unint64_t v20 = llvm::hashing::detail::fixed_seed_override;
        if (!llvm::hashing::detail::fixed_seed_override) {
          unint64_t v20 = 0xFF51AFD7ED558CCDLL;
        }
        llvm::hashing::detail::get_execution_seed(void)::seed = v20;
        unint64_t v6 = (void *)&unk_267770000;
        uint64_t v4 = v24;
        unint64_t v5 = v25;
        int v3 = v22;
        a2 = v21;
        a3 = v23;
      }
    }
    uint64_t v7 = (v6[385] + 8 * v5) ^ HIDWORD(v5);
    unint64_t v8 = 0x9DDFEA08EB382D69 * (HIDWORD(v5) ^ ((0x9DDFEA08EB382D69 * v7) >> 47) ^ (0x9DDFEA08EB382D69 * v7));
    int v9 = -348639895 * ((v8 >> 47) ^ v8);
    int v10 = v3 - 1;
    unsigned int v11 = v9 & (v3 - 1);
    unsigned int v12 = (void *)(v4 + 16 * v11);
    uint64_t v13 = *v12;
    if (*a2 == *v12)
    {
      uint64_t result = 1;
    }
    else
    {
      uint64_t v15 = 0;
      int v16 = 1;
      uint64_t result = 1;
      while (v13 != -4096)
      {
        if (v15) {
          BOOL v17 = 0;
        }
        else {
          BOOL v17 = v13 == -8192;
        }
        if (v17) {
          uint64_t v15 = v12;
        }
        unsigned int v18 = v11 + v16++;
        unsigned int v11 = v18 & v10;
        unsigned int v12 = (void *)(v4 + 16 * (v18 & v10));
        uint64_t v13 = *v12;
        if (*a2 == *v12) {
          goto LABEL_6;
        }
      }
      uint64_t result = 0;
      if (v15) {
        unsigned int v12 = v15;
      }
    }
  }
  else
  {
    unsigned int v12 = 0;
    uint64_t result = 0;
  }
LABEL_6:
  *a3 = v12;
  return result;
}

void *llvm::DenseMapBase<llvm::DenseMap<mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>,mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>::InsertIntoBucketImpl<mlir::Value>(uint64_t a1, uint64_t a2, unint64_t *a3, void *a4)
{
  int v6 = *(_DWORD *)(a1 + 8);
  unsigned int v7 = *(_DWORD *)(a1 + 16);
  if (4 * v6 + 4 >= 3 * v7)
  {
    v7 *= 2;
  }
  else if (v7 + ~v6 - *(_DWORD *)(a1 + 12) > v7 >> 3)
  {
    goto LABEL_3;
  }
  llvm::DenseMap<mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>::grow(a1, v7);
  int v9 = 0;
  llvm::DenseMapBase<llvm::DenseMap<mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>,mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>::LookupBucketFor<mlir::Value>((uint64_t *)a1, a3, &v9);
  a4 = v9;
LABEL_3:
  ++*(_DWORD *)(a1 + 8);
  if (*a4 != -4096) {
    --*(_DWORD *)(a1 + 12);
  }
  return a4;
}

void *llvm::DenseMap<mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>::grow(uint64_t a1, int a2)
{
  uint64_t v3 = *(unsigned int *)(a1 + 16);
  uint64_t v4 = *(llvm **)a1;
  unint64_t v5 = (a2 - 1) | ((unint64_t)(a2 - 1) >> 1);
  unint64_t v6 = v5 | (v5 >> 2) | ((v5 | (v5 >> 2)) >> 4);
  int v7 = ((v6 | (v6 >> 8)) >> 16) | v6 | (v6 >> 8);
  if ((v7 + 1) > 0x40) {
    unsigned int v8 = v7 + 1;
  }
  else {
    unsigned int v8 = 64;
  }
  *(_DWORD *)(a1 + 16) = v8;
  uint64_t result = llvm::allocate_buffer(16 * v8, (std::align_val_t)8uLL);
  int v10 = result;
  *(void *)a1 = result;
  if (v4)
  {
    *(void *)(a1 + 8) = 0;
    uint64_t v11 = *(unsigned int *)(a1 + 16);
    if (v11)
    {
      if (((v11 - 1) & 0xFFFFFFFFFFFFFFFLL) == 0) {
        goto LABEL_10;
      }
      uint64_t v12 = ((v11 - 1) & 0xFFFFFFFFFFFFFFFLL) + 1;
      int v10 = &result[2 * (v12 & 0x1FFFFFFFFFFFFFFELL)];
      uint64_t v13 = result + 2;
      uint64_t v14 = v12 & 0x1FFFFFFFFFFFFFFELL;
      do
      {
        *(v13 - 2) = -4096;
        *uint64_t v13 = -4096;
        v13 += 4;
        v14 -= 2;
      }
      while (v14);
      if (v12 != (v12 & 0x1FFFFFFFFFFFFFFELL))
      {
LABEL_10:
        uint64_t v15 = &result[2 * v11];
        do
        {
          *int v10 = -4096;
          v10 += 2;
        }
        while (v10 != v15);
      }
    }
    int v16 = (void *)(16 * v3);
    if (v3)
    {
      uint64_t v17 = 16 * v3;
      unsigned int v18 = v4;
      do
      {
        if ((*(void *)v18 | 0x1000) != 0xFFFFFFFFFFFFF000)
        {
          unint64_t v25 = 0;
          llvm::DenseMapBase<llvm::DenseMap<mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>,mlir::Value,unsigned int,llvm::DenseMapInfo<mlir::Value,void>,llvm::detail::DenseMapPair<mlir::Value,unsigned int>>::LookupBucketFor<mlir::Value>((uint64_t *)a1, (unint64_t *)v18, &v25);
          int v19 = v25;
          *unint64_t v25 = *(void *)v18;
          *((_DWORD *)v19 + 2) = *((_DWORD *)v18 + 2);
          ++*(_DWORD *)(a1 + 8);
        }
        unsigned int v18 = (llvm *)((char *)v18 + 16);
        v17 -= 16;
      }
      while (v17);
    }
    llvm::deallocate_buffer(v4, v16);
  }
  *(void *)(a1 + 8) = 0;
  uint64_t v20 = *(unsigned int *)(a1 + 16);
  if (v20)
  {
    if (((v20 - 1) & 0xFFFFFFFFFFFFFFFLL) == 0) {
      goto LABEL_23;
    }
    uint64_t v21 = ((v20 - 1) & 0xFFFFFFFFFFFFFFFLL) + 1;
    int v10 = &result[2 * (v21 & 0x1FFFFFFFFFFFFFFELL)];
    int v22 = result + 2;
    uint64_t v23 = v21 & 0x1FFFFFFFFFFFFFFELL;
    do
    {
      *(v22 - 2) = -4096;
      *int v22 = -4096;
      v22 += 4;
      v23 -= 2;
    }
    while (v23);
    if (v21 != (v21 & 0x1FFFFFFFFFFFFFFELL))
    {
LABEL_23:
      uint64_t v24 = &result[2 * v20];
      do
      {
        *int v10 = -4096;
        v10 += 2;
      }
      while (v10 != v24);
    }
  }
  return result;
}

uint64_t llvm::SmallVectorTemplateBase<std::unique_ptr<mlir::DataFlowAnalysis>,false>::growAndEmplaceBack<mlir::dataflow::DeadCodeAnalysis *>(uint64_t a1, void *a2)
{
  unint64_t v27 = 0;
  uint64_t v4 = (char *)(a1 + 16);
  unint64_t v5 = (char *)llvm::SmallVectorBase<unsigned int>::mallocForGrow(a1, (void *)(a1 + 16), 0, 8, &v27);
  uint64_t v6 = *(unsigned int *)(a1 + 8);
  uint64_t v7 = 8 * v6;
  *(void *)&v5[8 * v6] = *a2;
  unsigned int v8 = *(char **)a1;
  int v9 = *(char **)a1;
  if (!v6) {
    goto LABEL_19;
  }
  unint64_t v10 = (v6 - 1) & 0x1FFFFFFFFFFFFFFFLL;
  if (v10 < 0xB)
  {
    uint64_t v11 = v5;
LABEL_12:
    uint64_t v20 = &v8[v7];
    do
    {
      uint64_t v21 = *(void *)v9;
      *(void *)int v9 = 0;
      v9 += 8;
      *(void *)uint64_t v11 = v21;
      v11 += 8;
    }
    while (v9 != v20);
    goto LABEL_14;
  }
  BOOL v12 = v8 >= &v5[v7] || v5 >= &v8[v7];
  uint64_t v11 = v5;
  if (!v12) {
    goto LABEL_12;
  }
  unint64_t v13 = v10 + 1;
  uint64_t v14 = 8 * (v13 & 0x3FFFFFFFFFFFFFFCLL);
  uint64_t v11 = &v5[v14];
  int v9 = &v8[v14];
  uint64_t v15 = (long long *)(v8 + 16);
  int v16 = v5 + 16;
  uint64_t v17 = v13 & 0x3FFFFFFFFFFFFFFCLL;
  do
  {
    long long v18 = *(v15 - 1);
    long long v19 = *v15;
    *(v15 - 1) = 0uLL;
    long long *v15 = 0uLL;
    *(v16 - 1) = v18;
    _OWORD *v16 = v19;
    v15 += 2;
    v16 += 2;
    v17 -= 4;
  }
  while (v17);
  if (v13 != (v13 & 0x3FFFFFFFFFFFFFFCLL)) {
    goto LABEL_12;
  }
LABEL_14:
  uint64_t v22 = *(void *)a1 - 8;
  do
  {
    uint64_t v23 = *(void *)(v22 + v7);
    *(void *)(v22 + v7) = 0;
    if (v23) {
      (*(void (**)(uint64_t))(*(void *)v23 + 8))(v23);
    }
    v7 -= 8;
  }
  while (v7);
  int v9 = *(char **)a1;
LABEL_19:
  int v24 = v27;
  if (v9 != v4) {
    free(v9);
  }
  *(void *)a1 = v5;
  unsigned int v25 = *(_DWORD *)(a1 + 8) + 1;
  *(_DWORD *)(a1 + 8) = v25;
  *(_DWORD *)(a1 + 12) = v24;
  return (uint64_t)&v5[8 * v25 - 8];
}

uint64_t mlir::Pass::initialize()
{
  return 1;
}

BOOL llvm::cl::OptionValueCopy<long long>::compare(uint64_t a1, uint64_t a2)
{
  return *(unsigned char *)(a2 + 16) && *(unsigned char *)(a1 + 16) && *(void *)(a1 + 8) == *(void *)(a2 + 8);
}

uint64_t std::__throw_bad_function_call[abi:nn180100]()
{
  return mlir::detail::PassOptions::ListOption<std::string,llvm::cl::parser<std::string>>::handleOccurrence();
}

BOOL mlir::detail::PassOptions::ListOption<std::string,llvm::cl::parser<std::string>>::handleOccurrence(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, unint64_t a6)
{
  if (*(unsigned char *)(a1 + 176))
  {
    *(void *)(a1 + 192) = *(void *)(a1 + 184);
    uint64_t v11 = *(void *)(a1 + 128);
    for (uint64_t i = *(void *)(a1 + 136); i != v11; i -= 24)
    {
      if (*(char *)(i - 1) < 0) {
        operator delete(*(void **)(i - 24));
      }
    }
    *(void *)(a1 + 136) = v11;
    *(unsigned char *)(a1 + 176) = 0;
  }
  *(unsigned char *)(a1 + 256) = 1;
  uint64_t v14 = a1;
  v15[0] = a1 + 264;
  v16[0] = a3;
  v16[1] = a4;
  v15[1] = a1;
  unint64_t v15[2] = v16;
  v15[3] = &v14;
  return mlir::detail::pass_options::parseCommaSeparatedList(a1, a3, a4, a5, a6, (uint64_t (*)(uint64_t, uint64_t, unint64_t))llvm::function_ref<mlir::LogicalResult ()(llvm::StringRef)>::callback_fn<mlir::LogicalResult mlir::detail::pass_options::parseCommaSeparatedList<llvm::cl::parser<std::string>,mlir::detail::PassOptions::ListOption<std::string,llvm::cl::parser<std::string>>::handleOccurrence(unsigned int,llvm::StringRef,llvm::StringRef)::{lambda(std::string const&)#1}>(llvm::cl::Option &,llvm::StringRef,llvm::StringRef,llvm::cl::parser<std::string> &,mlir::detail::PassOptions::ListOption<std::string,llvm::cl::parser<std::string>>::handleOccurrence(unsigned int,llvm::StringRef,llvm::StringRef)::{lambda(std::string const&)#1} &&)::{lambda(llvm::StringRef)#1}>, (uint64_t)v15) == 0;
}

uint64_t llvm::cl::list<std::string,BOOL,llvm::cl::parser<std::string>>::getValueExpectedFlagDefault()
{
  return 2;
}

void mlir::Pass::ListOption<std::string,llvm::cl::parser<std::string>>::~ListOption(void *a1)
{
  llvm::cl::list<std::string,BOOL,llvm::cl::parser<std::string>>::~list(a1);

  JUMPOUT(0x21667D3C0);
}

uint64_t llvm::cl::list<std::string,BOOL,llvm::cl::parser<std::string>>::getOptionWidth(uint64_t a1)
{
  return llvm::cl::basic_parser_impl::getOptionWidth(a1 + 208, a1);
}

llvm::raw_ostream *llvm::cl::list<std::string,BOOL,llvm::cl::parser<std::string>>::printOptionInfo(uint64_t a1, unsigned int a2)
{
  return llvm::cl::basic_parser_impl::printOptionInfo((llvm::cl::basic_parser_impl *)(a1 + 208), (const llvm::cl::Option *)a1, a2);
}

void llvm::cl::list<std::string,BOOL,llvm::cl::parser<std::string>>::setDefault(void *a1)
{
  uint64_t v2 = (uint64_t)(a1 + 16);
  uint64_t v3 = (std::string *)a1[16];
  a1[24] = a1[23];
  for (uint64_t i = (std::string *)a1[17]; i != v3; --i)
  {
    if (SHIBYTE(i[-1].__r_.__value_.__r.__words[2]) < 0) {
      operator delete(i[-1].__r_.__value_.__l.__data_);
    }
  }
  a1[17] = v3;
  uint64_t v5 = a1[19];
  uint64_t v6 = a1[20];
  while (v5 != v6)
  {
    uint64_t v7 = (long long *)(v5 + 8);
    if ((unint64_t)v3 >= a1[18])
    {
      uint64_t v3 = std::vector<std::string>::__push_back_slow_path<std::string const&>(v2, (uint64_t)v7);
    }
    else
    {
      if (*(char *)(v5 + 31) < 0)
      {
        std::string::__init_copy_ctor_external(v3, *(const std::string::value_type **)(v5 + 8), *(void *)(v5 + 16));
      }
      else
      {
        long long v8 = *v7;
        v3->__r_.__value_.__r.__words[2] = *(void *)(v5 + 24);
        *(_OWORD *)&v3->__r_.__value_.__l.__data_ = v8;
      }
      ++v3;
    }
    a1[17] = v3;
    v5 += 40;
  }
}

llvm::raw_ostream *mlir::detail::PassOptions::ListOption<std::string,llvm::cl::parser<std::string>>::print(llvm::raw_ostream *result, llvm::raw_ostream *this)
{
  if (*((void *)result + 17) != *((void *)result + 16))
  {
    uint64_t v3 = result;
    uint64_t v4 = (const void *)*((void *)result + 2);
    size_t v5 = *((void *)result + 3);
    uint64_t result = (llvm::raw_ostream *)*((void *)this + 4);
    if (v5 <= *((void *)this + 3) - (void)result)
    {
      if (v5)
      {
        memcpy(result, v4, v5);
        uint64_t result = (llvm::raw_ostream *)(*((void *)this + 4) + v5);
        *((void *)this + 4) = result;
      }
      uint64_t v6 = this;
    }
    else
    {
      uint64_t v6 = llvm::raw_ostream::write(this, (const char *)v4, v5);
      uint64_t result = (llvm::raw_ostream *)*((void *)v6 + 4);
    }
    if ((unint64_t)result >= *((void *)v6 + 3))
    {
      uint64_t result = llvm::raw_ostream::write(v6, 61);
    }
    else
    {
      *((void *)v6 + 4) = (char *)result + 1;
      *(unsigned char *)uint64_t result = 61;
    }
    uint64_t v8 = *((void *)v3 + 16);
    uint64_t v7 = *((void *)v3 + 17);
    if (v8 != v7)
    {
      int v9 = *(char *)(v8 + 23);
      unint64_t v10 = v9 >= 0 ? (const char *)*((void *)v3 + 16) : *(const char **)v8;
      size_t v11 = v9 >= 0 ? *(unsigned __int8 *)(v8 + 23) : *(void *)(v8 + 8);
      uint64_t result = llvm::raw_ostream::write(this, v10, v11);
      for (uint64_t i = v8 + 24; i != v7; i += 24)
      {
        int v16 = (unsigned char *)*((void *)this + 4);
        if (*((unsigned char **)this + 3) == v16)
        {
          llvm::raw_ostream::write(this, ",", 1uLL);
        }
        else
        {
          unsigned char *v16 = 44;
          ++*((void *)this + 4);
        }
        int v13 = *(char *)(i + 23);
        if (v13 >= 0) {
          uint64_t v14 = (const char *)i;
        }
        else {
          uint64_t v14 = *(const char **)i;
        }
        if (v13 >= 0) {
          size_t v15 = *(unsigned __int8 *)(i + 23);
        }
        else {
          size_t v15 = *(void *)(i + 8);
        }
        uint64_t result = llvm::raw_ostream::write(this, v14, v15);
      }
    }
  }
  return result;
}

void mlir::detail::PassOptions::ListOption<std::string,llvm::cl::parser<std::string>>::copyValueFrom(uint64_t a1, uint64_t a2)
{
  *(unsigned char *)(a1 + 256) = 1;
  *(unsigned char *)(a1 + 256) = *(unsigned char *)(a2 + 8);
}

void *non-virtual thunk to'mlir::Pass::ListOption<std::string,llvm::cl::parser<std::string>>::~ListOption(uint64_t a1)
{
  return llvm::cl::list<std::string,BOOL,llvm::cl::parser<std::string>>::~list((void *)(a1 - 248));
}

void non-virtual thunk to'mlir::Pass::ListOption<std::string,llvm::cl::parser<std::string>>::~ListOption(uint64_t a1)
{
  llvm::cl::list<std::string,BOOL,llvm::cl::parser<std::string>>::~list((void *)(a1 - 248));

  JUMPOUT(0x21667D3C0);
}

llvm::raw_ostream *non-virtual thunk to'mlir::detail::PassOptions::ListOption<std::string,llvm::cl::parser<std::string>>::print(uint64_t a1, llvm::raw_ostream *a2)
{
  return mlir::detail::PassOptions::ListOption<std::string,llvm::cl::parser<std::string>>::print((llvm::raw_ostream *)(a1 - 248), a2);
}

uint64_t non-virtual thunk to'mlir::detail::PassOptions::ListOption<std::string,llvm::cl::parser<std::string>>::getOption(uint64_t a1)
{
  return a1 - 248;
}

void non-virtual thunk to'mlir::detail::PassOptions::ListOption<std::string,llvm::cl::parser<std::string>>::copyValueFrom(uint64_t a1, uint64_t a2)
{
  *(unsigned char *)(a1 + 8) = 1;
  *(unsigned char *)(a1 + 8) = *(unsigned char *)(a2 + 8);
}

void mlir::detail::PassOptions::ListOption<std::string,llvm::cl::parser<std::string>>::~ListOption(void *a1)
{
  llvm::cl::list<std::string,BOOL,llvm::cl::parser<std::string>>::~list(a1);

  JUMPOUT(0x21667D3C0);
}

void *non-virtual thunk to'mlir::detail::PassOptions::ListOption<std::string,llvm::cl::parser<std::string>>::~ListOption(uint64_t a1)
{
  return llvm::cl::list<std::string,BOOL,llvm::cl::parser<std::string>>::~list((void *)(a1 - 248));
}

void non-virtual thunk to'mlir::detail::PassOptions::ListOption<std::string,llvm::cl::parser<std::string>>::~ListOption(uint64_t a1)
{
  llvm::cl::list<std::string,BOOL,llvm::cl::parser<std::string>>::~list((void *)(a1 - 248));

  JUMPOUT(0x21667D3C0);
}

uint64_t llvm::cl::list<std::string,BOOL,llvm::cl::parser<std::string>>::handleOccurrence(uint64_t a1, int a2, int a3, int a4, void *__src, size_t __len)
{
  __p[0] = 0;
  __p[1] = 0;
  unint64_t v41 = 0;
  if (*(unsigned char *)(a1 + 176))
  {
    *(void *)(a1 + 192) = *(void *)(a1 + 184);
    uint64_t v10 = *(void *)(a1 + 128);
    for (uint64_t i = *(void *)(a1 + 136); i != v10; i -= 24)
    {
      if (*(char *)(i - 1) < 0) {
        operator delete(*(void **)(i - 24));
      }
    }
    *(void *)(a1 + 136) = v10;
    *(unsigned char *)(a1 + 176) = 0;
  }
  if (!__src)
  {
    long long __dst = 0uLL;
    unint64_t v43 = 0;
    goto LABEL_20;
  }
  if (__len >= 0x7FFFFFFFFFFFFFF8) {
    goto LABEL_51;
  }
  if (__len >= 0x17)
  {
    size_t v13 = (__len & 0xFFFFFFFFFFFFFFF8) + 8;
    if ((__len | 7) != 0x17) {
      size_t v13 = __len | 7;
    }
    size_t v14 = v13 + 1;
    p_dst = (long long *)operator new(v13 + 1);
    *((void *)&__dst + 1) = __len;
    unint64_t v43 = v14 | 0x8000000000000000;
    *(void *)&long long __dst = p_dst;
    goto LABEL_17;
  }
  HIBYTE(v43) = __len;
  p_dst = &__dst;
  if (__len) {
LABEL_17:
  }
    memmove(p_dst, __src, __len);
  *((unsigned char *)p_dst + __len) = 0;
  if (SHIBYTE(v41) < 0) {
    operator delete(__p[0]);
  }
LABEL_20:
  *(_OWORD *)std::string __p = __dst;
  unint64_t v41 = v43;
  unint64_t v15 = *(void *)(a1 + 136);
  if (v15 >= *(void *)(a1 + 144))
  {
    uint64_t v17 = std::vector<std::string>::__push_back_slow_path<std::string const&>(a1 + 128, (uint64_t)__p);
  }
  else
  {
    if (SHIBYTE(v41) < 0)
    {
      std::string::__init_copy_ctor_external(*(std::string **)(a1 + 136), (const std::string::value_type *)__p[0], (std::string::size_type)__p[1]);
    }
    else
    {
      long long v16 = *(_OWORD *)__p;
      *(void *)(v15 + 16) = v41;
      *(_OWORD *)unint64_t v15 = v16;
    }
    uint64_t v17 = (std::string *)(v15 + 24);
  }
  *(void *)(a1 + 136) = v17;
  *(_WORD *)(a1 + 12) = a2;
  long long v19 = *(char **)(a1 + 192);
  unint64_t v18 = *(void *)(a1 + 200);
  if ((unint64_t)v19 >= v18)
  {
    uint64_t v21 = *(char **)(a1 + 184);
    uint64_t v22 = (v19 - v21) >> 2;
    unint64_t v23 = v22 + 1;
    if (!((unint64_t)(v22 + 1) >> 62))
    {
      uint64_t v24 = v18 - (void)v21;
      if (v24 >> 1 > v23) {
        unint64_t v23 = v24 >> 1;
      }
      if ((unint64_t)v24 >= 0x7FFFFFFFFFFFFFFCLL) {
        unint64_t v25 = 0x3FFFFFFFFFFFFFFFLL;
      }
      else {
        unint64_t v25 = v23;
      }
      if (v25)
      {
        if (v25 >> 62) {
          goto LABEL_53;
        }
        unint64_t v26 = operator new(4 * v25);
      }
      else
      {
        unint64_t v26 = 0;
      }
      unint64_t v27 = &v26[4 * v22];
      unint64_t v28 = &v26[4 * v25];
      *unint64_t v27 = a2;
      uint64_t v20 = v27 + 1;
      if (v19 != v21)
      {
        unint64_t v29 = v19 - v21 - 4;
        if (v29 < 0x2C) {
          goto LABEL_56;
        }
        if ((unint64_t)(v21 - v26) < 0x20) {
          goto LABEL_56;
        }
        uint64_t v30 = (v29 >> 2) + 1;
        uint64_t v31 = 4 * (v30 & 0x7FFFFFFFFFFFFFF8);
        uint64_t v32 = &v19[-v31];
        unint64_t v27 = (_DWORD *)((char *)v27 - v31);
        long long v33 = &v26[4 * v22 - 16];
        uint64_t v34 = v19 - 16;
        uint64_t v35 = v30 & 0x7FFFFFFFFFFFFFF8;
        do
        {
          long long v36 = *(_OWORD *)v34;
          *(v33 - 1) = *((_OWORD *)v34 - 1);
          *long long v33 = v36;
          v33 -= 2;
          v34 -= 32;
          v35 -= 8;
        }
        while (v35);
        long long v19 = v32;
        if (v30 != (v30 & 0x7FFFFFFFFFFFFFF8))
        {
LABEL_56:
          do
          {
            int v37 = *((_DWORD *)v19 - 1);
            v19 -= 4;
            *--unint64_t v27 = v37;
          }
          while (v19 != v21);
        }
      }
      *(void *)(a1 + 184) = v27;
      *(void *)(a1 + 192) = v20;
      *(void *)(a1 + 20std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v28;
      if (v21) {
        operator delete(v21);
      }
      goto LABEL_47;
    }
LABEL_51:
    abort();
  }
  *(_DWORD *)long long v19 = a2;
  uint64_t v20 = v19 + 4;
LABEL_47:
  *(void *)(a1 + 192) = v20;
  uint64_t v38 = *(void *)(a1 + 240);
  if (!v38)
  {
    std::__throw_bad_function_call[abi:nn180100]();
LABEL_53:
    std::__throw_bad_array_new_length[abi:nn180100]();
  }
  (*(void (**)(uint64_t, void **))(*(void *)v38 + 48))(v38, __p);
  if (SHIBYTE(v41) < 0) {
    operator delete(__p[0]);
  }
  return 0;
}

void llvm::cl::list<std::string,BOOL,llvm::cl::parser<std::string>>::~list(void *a1)
{
  llvm::cl::list<std::string,BOOL,llvm::cl::parser<std::string>>::~list(a1);

  JUMPOUT(0x21667D3C0);
}

void std::__function::__func<llvm::cl::list<std::string,BOOL,llvm::cl::parser<std::string>>::{lambda(std::string const&)#1},std::allocator<llvm::cl::list<std::string,BOOL,llvm::cl::parser<std::string>>::{lambda(std::string const&)#1}>,void ()(std::string const&)>::~__func()
{
}

void *std::__function::__func<llvm::cl::list<std::string,BOOL,llvm::cl::parser<std::string>>::{lambda(std::string const&)#1},std::allocator<llvm::cl::list<std::string,BOOL,llvm::cl::parser<std::string>>::{lambda(std::string const&)#1}>,void ()(std::string const&)>::__clone()
{
  uint64_t result = operator new(0x10uLL);
  *uint64_t result = &unk_26C380E18;
  return result;
}

void std::__function::__func<llvm::cl::list<std::string,BOOL,llvm::cl::parser<std::string>>::{lambda(std::string const&)#1},std::allocator<llvm::cl::list<std::string,BOOL,llvm::cl::parser<std::string>>::{lambda(std::string const&)#1}>,void ()(std::string const&)>::__clone(uint64_t a1, void *a2)
{
  *a2 = &unk_26C380E18;
}

uint64_t llvm::cl::OptionValueCopy<std::string>::compare(uint64_t a1, uint64_t a2)
{
  if (!*(unsigned char *)(a2 + 32) || !*(unsigned char *)(a1 + 32)) {
    return 0;
  }
  uint64_t v2 = *(unsigned __int8 *)(a1 + 31);
  if ((v2 & 0x80u) == 0) {
    uint64_t v3 = *(unsigned __int8 *)(a1 + 31);
  }
  else {
    uint64_t v3 = *(void *)(a1 + 16);
  }
  uint64_t v4 = *(unsigned __int8 *)(a2 + 31);
  int v5 = (char)v4;
  if ((v4 & 0x80u) != 0) {
    uint64_t v4 = *(void *)(a2 + 16);
  }
  if (v3 != v4) {
    return 0;
  }
  uint64_t v6 = (const void **)(a1 + 8);
  if (v5 >= 0) {
    uint64_t v7 = (unsigned __int8 *)(a2 + 8);
  }
  else {
    uint64_t v7 = *(unsigned __int8 **)(a2 + 8);
  }
  if ((v2 & 0x80) != 0) {
    return memcmp(*v6, v7, *(void *)(a1 + 16)) == 0;
  }
  if (!*(unsigned char *)(a1 + 31)) {
    return 1;
  }
  uint64_t v8 = v2 - 1;
  do
  {
    int v10 = *(unsigned __int8 *)v6;
    uint64_t v6 = (const void **)((char *)v6 + 1);
    int v9 = v10;
    int v12 = *v7++;
    int v11 = v12;
    BOOL v14 = v8-- != 0;
    uint64_t result = v9 == v11;
  }
  while (v9 == v11 && v14);
  return result;
}

void *llvm::cl::list<std::string,BOOL,llvm::cl::parser<std::string>>::~list(void *a1)
{
  *a1 = &unk_26C35BF80;
  uint64_t v2 = a1 + 27;
  uint64_t v3 = (void *)a1[30];
  if (v3 == v2)
  {
    (*(void (**)(void *))(*v2 + 32))(v2);
    uint64_t v4 = (void *)a1[23];
    if (v4)
    {
LABEL_5:
      a1[24] = v4;
      operator delete(v4);
    }
  }
  else
  {
    if (v3) {
      (*(void (**)(void *))(*v3 + 40))(v3);
    }
    uint64_t v4 = (void *)a1[23];
    if (v4) {
      goto LABEL_5;
    }
  }
  uint64_t v5 = a1[19];
  if (v5)
  {
    uint64_t v6 = a1[20];
    uint64_t v7 = (void *)a1[19];
    if (v6 != v5)
    {
      uint64_t v8 = v6 - 40;
      uint64_t v9 = a1[20];
      do
      {
        *(void *)(v9 - 4std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = &unk_26C35BD58;
        v9 -= 40;
        if (*(char *)(v9 + 31) < 0) {
          operator delete(*(void **)(v6 - 32));
        }
        v8 -= 40;
        uint64_t v6 = v9;
      }
      while (v9 != v5);
      uint64_t v7 = (void *)a1[19];
    }
    a1[20] = v5;
    operator delete(v7);
  }
  uint64_t v10 = a1[16];
  if (v10)
  {
    uint64_t v11 = a1[17];
    int v12 = (void *)a1[16];
    if (v11 != v10)
    {
      do
      {
        if (*(char *)(v11 - 1) < 0) {
          operator delete(*(void **)(v11 - 24));
        }
        v11 -= 24;
      }
      while (v11 != v10);
      int v12 = (void *)a1[16];
    }
    a1[17] = v10;
    operator delete(v12);
  }
  *a1 = &unk_26C35BFE8;
  size_t v13 = (void *)a1[12];
  if (v13 != (void *)a1[11]) {
    free(v13);
  }
  BOOL v14 = (void *)a1[8];
  if (v14 != a1 + 10) {
    free(v14);
  }
  return a1;
}

uint64_t mlir::detail::pass_options::parseCommaSeparatedList<llvm::cl::parser<std::string>,mlir::detail::PassOptions::ListOption<std::string,llvm::cl::parser<std::string>>::handleOccurrence(unsigned int,llvm::StringRef,llvm::StringRef)::{lambda(std::string const&)#1}>(llvm::cl::Option &,llvm::StringRef,llvm::StringRef,llvm::cl::parser<std::string> &,mlir::detail::PassOptions::ListOption<std::string,llvm::cl::parser<std::string>>::handleOccurrence(unsigned int,llvm::StringRef,llvm::StringRef)::{lambda(std::string const&)#1} &&)::{lambda(llvm::StringRef)#1}::operator()(uint64_t a1, void *__src, size_t __len)
{
  __p[0] = 0;
  __p[1] = 0;
  unint64_t v17 = 0;
  if (!__src)
  {
    long long __dst = 0uLL;
    unint64_t v19 = 0;
    goto LABEL_13;
  }
  if (__len >= 0x7FFFFFFFFFFFFFF8) {
    abort();
  }
  if (__len >= 0x17)
  {
    size_t v7 = (__len & 0xFFFFFFFFFFFFFFF8) + 8;
    if ((__len | 7) != 0x17) {
      size_t v7 = __len | 7;
    }
    size_t v8 = v7 + 1;
    p_dst = (long long *)operator new(v7 + 1);
    *((void *)&__dst + 1) = __len;
    unint64_t v19 = v8 | 0x8000000000000000;
    *(void *)&long long __dst = p_dst;
    goto LABEL_10;
  }
  HIBYTE(v19) = __len;
  p_dst = &__dst;
  if (__len) {
LABEL_10:
  }
    memmove(p_dst, __src, __len);
  *((unsigned char *)p_dst + __len) = 0;
  if (SHIBYTE(v17) < 0) {
    operator delete(__p[0]);
  }
LABEL_13:
  *(_OWORD *)std::string __p = __dst;
  unint64_t v17 = v19;
  uint64_t v9 = **(void **)(a1 + 24);
  unint64_t v10 = *(void *)(v9 + 136);
  if (v10 >= *(void *)(v9 + 144))
  {
    size_t v13 = std::vector<std::string>::__push_back_slow_path<std::string const&>(v9 + 128, (uint64_t)__p);
    char v14 = HIBYTE(v17);
    *(void *)(v9 + 136) = v13;
    if (v14 < 0) {
LABEL_17:
    }
      operator delete(__p[0]);
  }
  else
  {
    char v11 = HIBYTE(v17);
    if (SHIBYTE(v17) < 0)
    {
      std::string::__init_copy_ctor_external(*(std::string **)(v9 + 136), (const std::string::value_type *)__p[0], (std::string::size_type)__p[1]);
    }
    else
    {
      long long v12 = *(_OWORD *)__p;
      *(void *)(v10 + 16) = v17;
      *(_OWORD *)unint64_t v10 = v12;
    }
    *(void *)(v9 + 136) = v10 + 24;
    if (v11 < 0) {
      goto LABEL_17;
    }
  }
  return 1;
}

void std::vector<std::string>::__assign_with_size[abi:nn180100]<std::string const*,std::string const*>(uint64_t a1, std::string *__str, std::string *a3, size_t __sz)
{
  uint64_t v6 = __str;
  uint64_t v8 = *(void *)(a1 + 16);
  uint64_t v9 = *(std::string **)a1;
  if (0xAAAAAAAAAAAAAAABLL * ((v8 - *(void *)a1) >> 3) >= __sz)
  {
    long long v12 = *(std::string **)(a1 + 8);
    if (0xAAAAAAAAAAAAAAABLL * (((char *)v12 - (char *)v9) >> 3) >= __sz)
    {
      if (__str == a3)
      {
        unint64_t v18 = *(std::string **)a1;
      }
      else
      {
        unint64_t v18 = *(std::string **)a1;
        do
        {
          std::string::operator=(v9++, v6++);
          ++v18;
        }
        while (v6 != a3);
        long long v12 = *(std::string **)(a1 + 8);
      }
      while (v12 != v18)
      {
        if (SHIBYTE(v12[-1].__r_.__value_.__r.__words[2]) < 0) {
          operator delete(v12[-1].__r_.__value_.__l.__data_);
        }
        --v12;
      }
      *(void *)(a1 + 8) = v18;
    }
    else
    {
      size_t v13 = (std::string *)((char *)__str + 8 * (((char *)v12 - (char *)v9) >> 3));
      if (v12 != v9)
      {
        uint64_t v14 = 8 * (((char *)v12 - (char *)v9) >> 3);
        do
        {
          std::string::operator=(v9++, v6++);
          v14 -= 24;
        }
        while (v14);
        uint64_t v9 = *(std::string **)(a1 + 8);
      }
      unint64_t v15 = v9;
      if (v13 != a3)
      {
        unint64_t v15 = v9;
        long long v16 = v9;
        do
        {
          if (SHIBYTE(v13->__r_.__value_.__r.__words[2]) < 0)
          {
            std::string::__init_copy_ctor_external(v16, v13->__r_.__value_.__l.__data_, v13->__r_.__value_.__l.__size_);
          }
          else
          {
            long long v17 = *(_OWORD *)&v13->__r_.__value_.__l.__data_;
            v16->__r_.__value_.__r.__words[2] = v13->__r_.__value_.__r.__words[2];
            *(_OWORD *)&v16->__r_.__value_.__l.__data_ = v17;
          }
          ++v13;
          ++v16;
          ++v15;
        }
        while (v13 != a3);
      }
      *(void *)(a1 + 8) = v15;
    }
  }
  else
  {
    if (v9)
    {
      unint64_t v10 = *(std::string **)(a1 + 8);
      char v11 = *(std::string **)a1;
      if (v10 != v9)
      {
        do
        {
          if (SHIBYTE(v10[-1].__r_.__value_.__r.__words[2]) < 0) {
            operator delete(v10[-1].__r_.__value_.__l.__data_);
          }
          --v10;
        }
        while (v10 != v9);
        char v11 = *(std::string **)a1;
      }
      *(void *)(a1 + 8) = v9;
      operator delete(v11);
      uint64_t v8 = 0;
      *(void *)a1 = 0;
      *(void *)(a1 + 8) = 0;
      *(void *)(a1 + 16) = 0;
    }
    if (__sz > 0xAAAAAAAAAAAAAAALL) {
      goto LABEL_46;
    }
    unint64_t v19 = 0xAAAAAAAAAAAAAAABLL * (v8 >> 3);
    uint64_t v20 = 2 * v19;
    if (2 * v19 <= __sz) {
      uint64_t v20 = __sz;
    }
    unint64_t v21 = v19 >= 0x555555555555555 ? 0xAAAAAAAAAAAAAAALL : v20;
    if (v21 > 0xAAAAAAAAAAAAAAALL) {
LABEL_46:
    }
      abort();
    uint64_t v22 = v21;
    unint64_t v23 = (std::string *)operator new(24 * v21);
    *(void *)a1 = v23;
    *(void *)(a1 + 8) = v23;
    *(void *)(a1 + 16) = &v23[v22];
    while (v6 != a3)
    {
      if (SHIBYTE(v6->__r_.__value_.__r.__words[2]) < 0)
      {
        std::string::__init_copy_ctor_external(v23, v6->__r_.__value_.__l.__data_, v6->__r_.__value_.__l.__size_);
      }
      else
      {
        *(_OWORD *)&v23->__r_.__value_.__l.__data_ = *(_OWORD *)&v6->__r_.__value_.__l.__data_;
        v23->__r_.__value_.__r.__words[2] = v6->__r_.__value_.__r.__words[2];
      }
      ++v6;
      ++v23;
    }
    *(void *)(a1 + 8) = v23;
  }
}

void *mlir::detail::PassOptions::Option<long long,llvm::cl::parser<long long>>::Option<llvm::cl::desc,llvm::cl::initializer<int>>(void *a1, void *a2, uint64_t a3, uint64_t a4, __n128 *a5, int **a6)
{
  uint64_t v36 = *MEMORY[0x263EF8340];
  v31[0] = a3;
  v31[1] = a4;
  v34[0] = a2;
  uint64_t v8 = llvm::cl::opt<long long,false,llvm::cl::parser<long long>>::opt<llvm::StringRef,llvm::cl::sub,llvm::cl::desc,llvm::cl::initializer<int>>((uint64_t)a1, (uint64_t)v31, v34, a5, a6);
  uint64_t v9 = v8 + 200;
  *(unsigned char *)(v8 + 208) = 0;
  *(void *)uint64_t v8 = &unk_26C37F720;
  *(void *)(v8 + 20std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = &unk_26C37F7A0;
  char v11 = (uint64_t *)a2[21];
  unint64_t v10 = a2[22];
  long long v12 = v11;
  if ((unint64_t)v11 >= v10)
  {
    uint64_t v14 = (uint64_t *)a2[20];
    uint64_t v15 = v11 - v14;
    unint64_t v16 = v15 + 1;
    if ((unint64_t)(v15 + 1) >> 61) {
      abort();
    }
    uint64_t v17 = v10 - (void)v14;
    if (v17 >> 2 > v16) {
      unint64_t v16 = v17 >> 2;
    }
    if ((unint64_t)v17 >= 0x7FFFFFFFFFFFFFF8) {
      unint64_t v18 = 0x1FFFFFFFFFFFFFFFLL;
    }
    else {
      unint64_t v18 = v16;
    }
    if (v18)
    {
      if (v18 >> 61) {
        std::__throw_bad_array_new_length[abi:nn180100]();
      }
      unint64_t v19 = (char *)operator new(8 * v18);
    }
    else
    {
      unint64_t v19 = 0;
    }
    uint64_t v20 = (uint64_t *)&v19[8 * v15];
    unint64_t v21 = &v19[8 * v18];
    *uint64_t v20 = v9;
    size_t v13 = v20 + 1;
    if (v11 != v14)
    {
      unint64_t v22 = (char *)v11 - (char *)v14 - 8;
      if (v22 < 0x58) {
        goto LABEL_36;
      }
      if ((unint64_t)((char *)v14 - v19) < 0x20) {
        goto LABEL_36;
      }
      uint64_t v23 = (v22 >> 3) + 1;
      uint64_t v24 = 8 * (v23 & 0x3FFFFFFFFFFFFFFCLL);
      long long v12 = &v11[v24 / 0xFFFFFFFFFFFFFFF8];
      uint64_t v20 = (uint64_t *)((char *)v20 - v24);
      unint64_t v25 = &v19[8 * v15 - 16];
      unint64_t v26 = v11 - 2;
      uint64_t v27 = v23 & 0x3FFFFFFFFFFFFFFCLL;
      do
      {
        long long v28 = *(_OWORD *)v26;
        *((_OWORD *)v25 - 1) = *((_OWORD *)v26 - 1);
        *(_OWORD *)unint64_t v25 = v28;
        v25 -= 32;
        v26 -= 4;
        v27 -= 4;
      }
      while (v27);
      if (v23 != (v23 & 0x3FFFFFFFFFFFFFFCLL))
      {
LABEL_36:
        do
        {
          uint64_t v29 = *--v12;
          *--uint64_t v20 = v29;
        }
        while (v12 != v14);
      }
      long long v12 = (uint64_t *)a2[20];
    }
    a2[20] = v20;
    a2[21] = v13;
    a2[22] = v21;
    if (v12) {
      operator delete(v12);
    }
  }
  else
  {
    uint64_t *v11 = v9;
    size_t v13 = v11 + 1;
  }
  a2[21] = v13;
  v32[0] = &unk_26C387BF8;
  v32[1] = a1;
  uint64_t v35 = v34;
  long long v33 = v32;
  v34[0] = &unk_26C387BF8;
  v34[1] = a1;
  std::__function::__value_func<void ()(long long const&)>::swap[abi:nn180100](v34, a1 + 21);
  if (v35 == v34)
  {
    (*((void (**)(const void **))v34[0] + 4))(v34);
  }
  else if (v35)
  {
    (*((void (**)(void))*v35 + 5))();
  }
  if (v33 == v32)
  {
    (*(void (**)(void *))(v32[0] + 32))(v32);
  }
  else if (v33)
  {
    (*(void (**)(void))(*v33 + 40))();
  }
  return a1;
}

uint64_t llvm::cl::opt<long long,false,llvm::cl::parser<long long>>::handleOccurrence(uint64_t a1, __int16 a2, uint64_t a3, uint64_t a4, char *a5, uint64_t a6)
{
  uint64_t v11 = 0;
  uint64_t v8 = llvm::cl::parser<long long>::parse(a1 + 160, (void *)a1, a3, a4, a5, a6, &v11);
  if (v8) {
    return v8;
  }
  *(void *)(a1 + 128) = v11;
  *(_WORD *)(a1 + 12) = a2;
  uint64_t v9 = *(void *)(a1 + 192);
  if (v9)
  {
    (*(void (**)(uint64_t, uint64_t *))(*(void *)v9 + 48))(v9, &v11);
    return v8;
  }
  std::__throw_bad_function_call[abi:nn180100]();
  return llvm::cl::opt<long long,false,llvm::cl::parser<long long>>::getValueExpectedFlagDefault();
}

uint64_t llvm::cl::opt<long long,false,llvm::cl::parser<long long>>::getValueExpectedFlagDefault()
{
  return 2;
}

void *mlir::Pass::Option<long long,llvm::cl::parser<long long>>::~Option(void *a1)
{
  *a1 = &unk_26C35BF18;
  uint64_t v2 = a1 + 21;
  uint64_t v3 = (void *)a1[24];
  if (v3 == v2)
  {
    (*(void (**)(void *))(*v2 + 32))(v2);
  }
  else if (v3)
  {
    (*(void (**)(void *))(*v3 + 40))(v3);
  }
  *a1 = &unk_26C35BFE8;
  uint64_t v4 = (void *)a1[12];
  if (v4 != (void *)a1[11]) {
    free(v4);
  }
  uint64_t v5 = (void *)a1[8];
  if (v5 != a1 + 10) {
    free(v5);
  }
  return a1;
}

void mlir::Pass::Option<long long,llvm::cl::parser<long long>>::~Option(void *a1)
{
  *a1 = &unk_26C35BF18;
  uint64_t v2 = a1 + 21;
  uint64_t v3 = (void *)a1[24];
  if (v3 == v2)
  {
    (*(void (**)(void *))(*v2 + 32))(v2);
  }
  else if (v3)
  {
    (*(void (**)(void *))(*v3 + 40))(v3);
  }
  *a1 = &unk_26C35BFE8;
  uint64_t v4 = (void *)a1[12];
  if (v4 != (void *)a1[11]) {
    free(v4);
  }
  uint64_t v5 = (void *)a1[8];
  if (v5 != a1 + 10) {
    free(v5);
  }

  JUMPOUT(0x21667D3C0);
}

uint64_t llvm::cl::opt<long long,false,llvm::cl::parser<long long>>::getOptionWidth(uint64_t a1)
{
  return llvm::cl::basic_parser_impl::getOptionWidth(a1 + 160, a1);
}

llvm::raw_ostream *llvm::cl::opt<long long,false,llvm::cl::parser<long long>>::printOptionInfo(uint64_t a1, unsigned int a2)
{
  return llvm::cl::basic_parser_impl::printOptionInfo((llvm::cl::basic_parser_impl *)(a1 + 160), (const llvm::cl::Option *)a1, a2);
}

void llvm::cl::opt<long long,false,llvm::cl::parser<long long>>::printOptionValue(uint64_t a1, int a2, char a3)
{
  if ((a3 & 1) != 0 || !*(unsigned char *)(a1 + 152) || *(void *)(a1 + 144) != *(void *)(a1 + 128))
  {
    unint64_t v3 = *(void *)(a1 + 128);
    uint64_t v4 = *(void *)(a1 + 144);
    char v6 = *(unsigned char *)(a1 + 152);
    v5[0] = &unk_26C35BD18;
    v5[1] = v4;
    llvm::cl::parser<long long>::printOptionDiff((llvm *)(a1 + 160), a1, v3, (uint64_t)v5, a2);
  }
}

uint64_t llvm::cl::opt<long long,false,llvm::cl::parser<long long>>::setDefault(uint64_t result)
{
  if (*(unsigned char *)(result + 152)) {
    *(void *)(result + 128) = *(void *)(result + 144);
  }
  else {
    *(void *)(result + 128) = 0;
  }
  return result;
}

llvm::raw_ostream *mlir::detail::PassOptions::Option<long long,llvm::cl::parser<long long>>::print(void *a1, llvm::raw_ostream *this)
{
  uint64_t v4 = (const void *)a1[2];
  size_t v5 = a1[3];
  char v6 = (unsigned char *)*((void *)this + 4);
  if (v5 <= *((void *)this + 3) - (void)v6)
  {
    if (v5)
    {
      memcpy(v6, v4, v5);
      char v6 = (unsigned char *)(*((void *)this + 4) + v5);
      *((void *)this + 4) = v6;
    }
    size_t v7 = this;
  }
  else
  {
    size_t v7 = llvm::raw_ostream::write(this, (const char *)v4, v5);
    char v6 = (unsigned char *)*((void *)v7 + 4);
  }
  if ((unint64_t)v6 >= *((void *)v7 + 3))
  {
    llvm::raw_ostream::write(v7, 61);
  }
  else
  {
    *((void *)v7 + 4) = v6 + 1;
    *char v6 = 61;
  }
  unint64_t v8 = a1[16];

  return llvm::raw_ostream::operator<<(this, v8);
}

uint64_t mlir::detail::PassOptions::Option<long long,llvm::cl::parser<long long>>::copyValueFrom(uint64_t result, uint64_t a2)
{
  *(void *)(result + 128) = *(void *)(a2 - 72);
  *(unsigned char *)(result + 208) = *(unsigned char *)(a2 + 8);
  return result;
}

void non-virtual thunk to'mlir::Pass::Option<long long,llvm::cl::parser<long long>>::~Option(uint64_t a1)
{
  *(void *)(a1 - 20std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = &unk_26C35BF18;
  uint64_t v2 = a1 - 32;
  uint64_t v3 = *(void *)(a1 - 8);
  if (v3 == v2)
  {
    (*(void (**)(uint64_t))(*(void *)v2 + 32))(v2);
  }
  else if (v3)
  {
    (*(void (**)(uint64_t))(*(void *)v3 + 40))(v3);
  }
  *(void *)(a1 - 20std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = &unk_26C35BFE8;
  uint64_t v4 = *(void **)(a1 - 104);
  if (v4 != *(void **)(a1 - 112)) {
    free(v4);
  }
  size_t v5 = *(void **)(a1 - 136);
  if (v5 != (void *)(a1 - 120)) {
    free(v5);
  }
}

{
  uint64_t v2;
  uint64_t v3;
  void *v4;
  void *v5;
  uint64_t vars8;

  *(void *)(a1 - 20std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = &unk_26C35BF18;
  uint64_t v2 = a1 - 32;
  uint64_t v3 = *(void *)(a1 - 8);
  if (v3 == v2)
  {
    (*(void (**)(uint64_t))(*(void *)v2 + 32))(v2);
  }
  else if (v3)
  {
    (*(void (**)(uint64_t))(*(void *)v3 + 40))(v3);
  }
  *(void *)(a1 - 20std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = &unk_26C35BFE8;
  uint64_t v4 = *(void **)(a1 - 104);
  if (v4 != *(void **)(a1 - 112)) {
    free(v4);
  }
  size_t v5 = *(void **)(a1 - 136);
  if (v5 != (void *)(a1 - 120)) {
    free(v5);
  }

  JUMPOUT(0x21667D3C0);
}

llvm::raw_ostream *non-virtual thunk to'mlir::detail::PassOptions::Option<long long,llvm::cl::parser<long long>>::print(uint64_t a1, llvm::raw_ostream *this)
{
  uint64_t v4 = *(const void **)(a1 - 184);
  size_t v5 = *(void *)(a1 - 176);
  char v6 = (unsigned char *)*((void *)this + 4);
  if (v5 <= *((void *)this + 3) - (void)v6)
  {
    if (v5)
    {
      memcpy(v6, v4, v5);
      char v6 = (unsigned char *)(*((void *)this + 4) + v5);
      *((void *)this + 4) = v6;
    }
    size_t v7 = this;
  }
  else
  {
    size_t v7 = llvm::raw_ostream::write(this, (const char *)v4, v5);
    char v6 = (unsigned char *)*((void *)v7 + 4);
  }
  if ((unint64_t)v6 >= *((void *)v7 + 3))
  {
    llvm::raw_ostream::write(v7, 61);
  }
  else
  {
    *((void *)v7 + 4) = v6 + 1;
    *char v6 = 61;
  }
  unint64_t v8 = *(void *)(a1 - 72);

  return llvm::raw_ostream::operator<<(this, v8);
}

uint64_t non-virtual thunk to'mlir::detail::PassOptions::Option<long long,llvm::cl::parser<long long>>::getOption(uint64_t a1)
{
  return a1 - 200;
}

uint64_t non-virtual thunk to'mlir::detail::PassOptions::Option<long long,llvm::cl::parser<long long>>::copyValueFrom(uint64_t result, uint64_t a2)
{
  *(void *)(result - 72) = *(void *)(a2 - 72);
  *(unsigned char *)(result + 8) = *(unsigned char *)(a2 + 8);
  return result;
}

uint64_t llvm::cl::opt<long long,false,llvm::cl::parser<long long>>::opt<llvm::StringRef,llvm::cl::sub,llvm::cl::desc,llvm::cl::initializer<int>>(uint64_t a1, uint64_t a2, const void **a3, __n128 *a4, int **a5)
{
  *(void *)a1 = &unk_26C35BFE8;
  *(_WORD *)(a1 + 8) = 0;
  *(_WORD *)(a1 + 10) &= 0x8000u;
  unint64_t v10 = (void *)(a1 + 80);
  *(void *)(a1 + 64) = a1 + 80;
  uint64_t v11 = a1 + 64;
  *(_OWORD *)(a1 + 12) = 0u;
  *(_OWORD *)(a1 + 28) = 0u;
  *(_OWORD *)(a1 + 44) = 0u;
  *(_DWORD *)(a1 + 6std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  *(void *)(a1 + 72) = 0x100000000;
  *(void *)(a1 + 88) = a1 + 120;
  *(void *)(a1 + 96) = a1 + 120;
  *(void *)(a1 + 104) = 1;
  *(_DWORD *)(a1 + 112) = 0;
  GeneralCategory = llvm::cl::getGeneralCategory((llvm::cl *)a1);
  uint64_t v13 = *(unsigned int *)(a1 + 72);
  if (v13 >= *(_DWORD *)(a1 + 76))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod(v11, v10, v13 + 1, 8);
    LODWORD(v13) = *(_DWORD *)(a1 + 72);
  }
  *(void *)(*(void *)(a1 + 64) + 8 * v13) = GeneralCategory;
  ++*(_DWORD *)(a1 + 72);
  *(_OWORD *)(a1 + 128) = 0u;
  *(_OWORD *)(a1 + 144) = 0u;
  *(void *)(a1 + 136) = &unk_26C35BD18;
  *(void *)a1 = &unk_26C35BF18;
  *(void *)(a1 + 16std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = &unk_26C35C130;
  *(void *)(a1 + 168) = &unk_26C380DD0;
  *(void *)(a1 + 192) = a1 + 168;
  llvm::cl::apply<llvm::cl::opt<long long,false,llvm::cl::parser<long long>>,llvm::StringRef,llvm::cl::sub,llvm::cl::desc,llvm::cl::initializer<int>>(a1, a2, a3, a4, a5);
  llvm::cl::Option::addArgument((llvm::cl::Option *)a1);
  return a1;
}

void *mlir::detail::PassOptions::Option<long long,llvm::cl::parser<long long>>::~Option(void *a1)
{
  *a1 = &unk_26C35BF18;
  uint64_t v2 = a1 + 21;
  uint64_t v3 = (void *)a1[24];
  if (v3 == v2)
  {
    (*(void (**)(void *))(*v2 + 32))(v2);
  }
  else if (v3)
  {
    (*(void (**)(void *))(*v3 + 40))(v3);
  }
  *a1 = &unk_26C35BFE8;
  uint64_t v4 = (void *)a1[12];
  if (v4 != (void *)a1[11]) {
    free(v4);
  }
  size_t v5 = (void *)a1[8];
  if (v5 != a1 + 10) {
    free(v5);
  }
  return a1;
}

void mlir::detail::PassOptions::Option<long long,llvm::cl::parser<long long>>::~Option(void *a1)
{
  *a1 = &unk_26C35BF18;
  uint64_t v2 = a1 + 21;
  uint64_t v3 = (void *)a1[24];
  if (v3 == v2)
  {
    (*(void (**)(void *))(*v2 + 32))(v2);
  }
  else if (v3)
  {
    (*(void (**)(void *))(*v3 + 40))(v3);
  }
  *a1 = &unk_26C35BFE8;
  uint64_t v4 = (void *)a1[12];
  if (v4 != (void *)a1[11]) {
    free(v4);
  }
  size_t v5 = (void *)a1[8];
  if (v5 != a1 + 10) {
    free(v5);
  }

  JUMPOUT(0x21667D3C0);
}

void non-virtual thunk to'mlir::detail::PassOptions::Option<long long,llvm::cl::parser<long long>>::~Option(uint64_t a1)
{
  *(void *)(a1 - 20std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = &unk_26C35BF18;
  uint64_t v2 = a1 - 32;
  uint64_t v3 = *(void *)(a1 - 8);
  if (v3 == v2)
  {
    (*(void (**)(uint64_t))(*(void *)v2 + 32))(v2);
  }
  else if (v3)
  {
    (*(void (**)(uint64_t))(*(void *)v3 + 40))(v3);
  }
  *(void *)(a1 - 20std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = &unk_26C35BFE8;
  uint64_t v4 = *(void **)(a1 - 104);
  if (v4 != *(void **)(a1 - 112)) {
    free(v4);
  }
  size_t v5 = *(void **)(a1 - 136);
  if (v5 != (void *)(a1 - 120)) {
    free(v5);
  }
}

{
  mlir::detail::PassOptions::Option<long long,llvm::cl::parser<long long>>::~Option((void *)(a1 - 200));
}

__n128 llvm::cl::apply<llvm::cl::opt<long long,false,llvm::cl::parser<long long>>,llvm::StringRef,llvm::cl::sub,llvm::cl::desc,llvm::cl::initializer<int>>(uint64_t a1, uint64_t a2, const void **a3, __n128 *a4, int **a5)
{
  llvm::cl::Option::setArgStr(a1, *(int8x16_t **)a2, *(const unsigned __int8 **)(a2 + 8));
  uint64_t v9 = *a3;
  uint64_t v10 = *(void *)(a1 + 96);
  if (v10 != *(void *)(a1 + 88))
  {
LABEL_2:
    llvm::SmallPtrSetImplBase::insert_imp_big((llvm::SmallPtrSetImplBase *)(a1 + 88), v9);
    goto LABEL_3;
  }
  uint64_t v13 = *(unsigned int *)(a1 + 108);
  if (!v13)
  {
LABEL_12:
    if (v13 < *(_DWORD *)(a1 + 104))
    {
      *(_DWORD *)(a1 + 108) = v13 + 1;
      *(void *)(v10 + 8 * v13) = v9;
      goto LABEL_3;
    }
    goto LABEL_2;
  }
  uint64_t v14 = 0;
  uint64_t v15 = 8 * v13;
  unint64_t v16 = *(void **)(a1 + 96);
  while ((const void *)*v16 != v9)
  {
    if (*v16 == -2) {
      uint64_t v14 = v16;
    }
    ++v16;
    v15 -= 8;
    if (!v15)
    {
      if (!v14) {
        goto LABEL_12;
      }
      *uint64_t v14 = v9;
      --*(_DWORD *)(a1 + 112);
      break;
    }
  }
LABEL_3:
  __n128 result = *a4;
  *(__n128 *)(a1 + 32) = *a4;
  uint64_t v12 = **a5;
  *(void *)(a1 + 128) = v12;
  *(unsigned char *)(a1 + 152) = 1;
  *(void *)(a1 + 144) = v12;
  return result;
}

void *llvm::cl::opt<long long,false,llvm::cl::parser<long long>>::~opt(void *a1)
{
  *a1 = &unk_26C35BF18;
  uint64_t v2 = a1 + 21;
  uint64_t v3 = (void *)a1[24];
  if (v3 == v2)
  {
    (*(void (**)(void *))(*v2 + 32))(v2);
  }
  else if (v3)
  {
    (*(void (**)(void *))(*v3 + 40))(v3);
  }
  *a1 = &unk_26C35BFE8;
  uint64_t v4 = (void *)a1[12];
  if (v4 != (void *)a1[11]) {
    free(v4);
  }
  size_t v5 = (void *)a1[8];
  if (v5 != a1 + 10) {
    free(v5);
  }
  return a1;
}

void llvm::cl::opt<long long,false,llvm::cl::parser<long long>>::~opt(void *a1)
{
  *a1 = &unk_26C35BF18;
  uint64_t v2 = a1 + 21;
  uint64_t v3 = (void *)a1[24];
  if (v3 == v2)
  {
    (*(void (**)(void *))(*v2 + 32))(v2);
  }
  else if (v3)
  {
    (*(void (**)(void *))(*v3 + 40))(v3);
  }
  *a1 = &unk_26C35BFE8;
  uint64_t v4 = (void *)a1[12];
  if (v4 != (void *)a1[11]) {
    free(v4);
  }
  size_t v5 = (void *)a1[8];
  if (v5 != a1 + 10) {
    free(v5);
  }

  JUMPOUT(0x21667D3C0);
}

void std::__function::__func<llvm::cl::opt<long long,false,llvm::cl::parser<long long>>::{lambda(long long const&)#1},std::allocator<llvm::cl::opt<long long,false,llvm::cl::parser<long long>>::{lambda(long long const&)#1}>,void ()(long long const&)>::~__func()
{
}

void *std::__function::__func<llvm::cl::opt<long long,false,llvm::cl::parser<long long>>::{lambda(long long const&)#1},std::allocator<llvm::cl::opt<long long,false,llvm::cl::parser<long long>>::{lambda(long long const&)#1}>,void ()(long long const&)>::__clone()
{
  __n128 result = operator new(0x10uLL);
  *__n128 result = &unk_26C380DD0;
  return result;
}

void std::__function::__func<llvm::cl::opt<long long,false,llvm::cl::parser<long long>>::{lambda(long long const&)#1},std::allocator<llvm::cl::opt<long long,false,llvm::cl::parser<long long>>::{lambda(long long const&)#1}>,void ()(long long const&)>::__clone(uint64_t a1, void *a2)
{
  *a2 = &unk_26C380DD0;
}

void *std::__function::__value_func<void ()(long long const&)>::swap[abi:nn180100](void *result, void *a2)
{
  v6[3] = *MEMORY[0x263EF8340];
  if (a2 != result)
  {
    uint64_t v3 = result;
    uint64_t v4 = (void *)result[3];
    size_t v5 = (void *)a2[3];
    if (v4 == result)
    {
      if (v5 == a2)
      {
        (*(void (**)(void *, void *))(*result + 24))(result, v6);
        (*(void (**)(void))(*(void *)v3[3] + 32))(v3[3]);
        v3[3] = 0;
        (*(void (**)(void, void *))(*(void *)a2[3] + 24))(a2[3], v3);
        (*(void (**)(void))(*(void *)a2[3] + 32))(a2[3]);
        a2[3] = 0;
        v3[3] = v3;
        (*(void (**)(void *, void *))(v6[0] + 24))(v6, a2);
        __n128 result = (void *)(*(uint64_t (**)(void *))(v6[0] + 32))(v6);
      }
      else
      {
        (*(void (**)(void *, void *))(*result + 24))(result, a2);
        __n128 result = (void *)(*(uint64_t (**)(void))(*(void *)v3[3] + 32))(v3[3]);
        v3[3] = a2[3];
      }
      a2[3] = a2;
    }
    else if (v5 == a2)
    {
      (*(void (**)(void *, void *))(*a2 + 24))(a2, result);
      __n128 result = (void *)(*(uint64_t (**)(void))(*(void *)a2[3] + 32))(a2[3]);
      a2[3] = v3[3];
      v3[3] = v3;
    }
    else
    {
      result[3] = v5;
      a2[3] = v4;
    }
  }
  return result;
}

void _ZNSt3__110__function6__funcIZN4mlir6detail11PassOptions6OptionIxN4llvm2cl6parserIxEEEC1IJNS7_4descENS7_11initializerIiEEEEERS4_NS6_9StringRefEDpOT_EUlRKT_E_NS_9allocatorISN_EEFvRKxEED0Ev()
{
}

void *_ZNKSt3__110__function6__funcIZN4mlir6detail11PassOptions6OptionIxN4llvm2cl6parserIxEEEC1IJNS7_4descENS7_11initializerIiEEEEERS4_NS6_9StringRefEDpOT_EUlRKT_E_NS_9allocatorISN_EEFvRKxEE7__cloneEv(uint64_t a1)
{
  __n128 result = operator new(0x10uLL);
  uint64_t v3 = *(void *)(a1 + 8);
  *__n128 result = &unk_26C387BF8;
  result[1] = v3;
  return result;
}

uint64_t _ZNKSt3__110__function6__funcIZN4mlir6detail11PassOptions6OptionIxN4llvm2cl6parserIxEEEC1IJNS7_4descENS7_11initializerIiEEEEERS4_NS6_9StringRefEDpOT_EUlRKT_E_NS_9allocatorISN_EEFvRKxEE7__cloneEPNS0_6__baseISS_EE(uint64_t result, void *a2)
{
  uint64_t v2 = *(void *)(result + 8);
  *a2 = &unk_26C387BF8;
  a2[1] = v2;
  return result;
}

uint64_t _ZNSt3__110__function6__funcIZN4mlir6detail11PassOptions6OptionIxN4llvm2cl6parserIxEEEC1IJNS7_4descENS7_11initializerIiEEEEERS4_NS6_9StringRefEDpOT_EUlRKT_E_NS_9allocatorISN_EEFvRKxEEclESR_(uint64_t result)
{
  *(unsigned char *)(*(void *)(result + 8) + 208) = 1;
  return result;
}

void *mlir::detail::PassOptions::Option<BOOL,llvm::cl::parser<BOOL>>::Option<llvm::cl::desc,llvm::cl::initializer<BOOL>>(void *a1, void *a2, uint64_t a3, uint64_t a4, __n128 *a5, unsigned char **a6)
{
  uint64_t v36 = *MEMORY[0x263EF8340];
  v31[0] = a3;
  v31[1] = a4;
  v34[0] = a2;
  uint64_t v8 = llvm::cl::opt<BOOL,false,llvm::cl::parser<BOOL>>::opt<llvm::StringRef,llvm::cl::sub,llvm::cl::desc,llvm::cl::initializer<BOOL>>((uint64_t)a1, (uint64_t)v31, v34, a5, a6);
  uint64_t v9 = v8 + 192;
  *(unsigned char *)(v8 + 20std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  *(void *)uint64_t v8 = &unk_26C37F5A0;
  *(void *)(v8 + 192) = &unk_26C37F620;
  uint64_t v11 = (uint64_t *)a2[21];
  unint64_t v10 = a2[22];
  uint64_t v12 = v11;
  if ((unint64_t)v11 >= v10)
  {
    uint64_t v14 = (uint64_t *)a2[20];
    uint64_t v15 = v11 - v14;
    unint64_t v16 = v15 + 1;
    if ((unint64_t)(v15 + 1) >> 61) {
      abort();
    }
    uint64_t v17 = v10 - (void)v14;
    if (v17 >> 2 > v16) {
      unint64_t v16 = v17 >> 2;
    }
    if ((unint64_t)v17 >= 0x7FFFFFFFFFFFFFF8) {
      unint64_t v18 = 0x1FFFFFFFFFFFFFFFLL;
    }
    else {
      unint64_t v18 = v16;
    }
    if (v18)
    {
      if (v18 >> 61) {
        std::__throw_bad_array_new_length[abi:nn180100]();
      }
      unint64_t v19 = (char *)operator new(8 * v18);
    }
    else
    {
      unint64_t v19 = 0;
    }
    uint64_t v20 = (uint64_t *)&v19[8 * v15];
    unint64_t v21 = &v19[8 * v18];
    *uint64_t v20 = v9;
    uint64_t v13 = v20 + 1;
    if (v11 != v14)
    {
      unint64_t v22 = (char *)v11 - (char *)v14 - 8;
      if (v22 < 0x58) {
        goto LABEL_36;
      }
      if ((unint64_t)((char *)v14 - v19) < 0x20) {
        goto LABEL_36;
      }
      uint64_t v23 = (v22 >> 3) + 1;
      uint64_t v24 = 8 * (v23 & 0x3FFFFFFFFFFFFFFCLL);
      uint64_t v12 = &v11[v24 / 0xFFFFFFFFFFFFFFF8];
      uint64_t v20 = (uint64_t *)((char *)v20 - v24);
      unint64_t v25 = &v19[8 * v15 - 16];
      unint64_t v26 = v11 - 2;
      uint64_t v27 = v23 & 0x3FFFFFFFFFFFFFFCLL;
      do
      {
        long long v28 = *(_OWORD *)v26;
        *((_OWORD *)v25 - 1) = *((_OWORD *)v26 - 1);
        *(_OWORD *)unint64_t v25 = v28;
        v25 -= 32;
        v26 -= 4;
        v27 -= 4;
      }
      while (v27);
      if (v23 != (v23 & 0x3FFFFFFFFFFFFFFCLL))
      {
LABEL_36:
        do
        {
          uint64_t v29 = *--v12;
          *--uint64_t v20 = v29;
        }
        while (v12 != v14);
      }
      uint64_t v12 = (uint64_t *)a2[20];
    }
    a2[20] = v20;
    a2[21] = v13;
    a2[22] = v21;
    if (v12) {
      operator delete(v12);
    }
  }
  else
  {
    uint64_t *v11 = v9;
    uint64_t v13 = v11 + 1;
  }
  a2[21] = v13;
  v32[0] = &unk_26C387B20;
  v32[1] = a1;
  uint64_t v35 = v34;
  long long v33 = v32;
  v34[0] = &unk_26C387B20;
  v34[1] = a1;
  std::__function::__value_func<void ()(BOOL const&)>::swap[abi:nn180100](v34, a1 + 20);
  if (v35 == v34)
  {
    (*((void (**)(const void **))v34[0] + 4))(v34);
  }
  else if (v35)
  {
    (*((void (**)(void))*v35 + 5))();
  }
  if (v33 == v32)
  {
    (*(void (**)(void *))(v32[0] + 32))(v32);
  }
  else if (v33)
  {
    (*(void (**)(void))(*v33 + 40))();
  }
  return a1;
}

void *mlir::Pass::Option<BOOL,llvm::cl::parser<BOOL>>::~Option(void *a1)
{
  *a1 = &unk_26C35BE48;
  uint64_t v2 = a1 + 20;
  uint64_t v3 = (void *)a1[23];
  if (v3 == v2)
  {
    (*(void (**)(void *))(*v2 + 32))(v2);
  }
  else if (v3)
  {
    (*(void (**)(void *))(*v3 + 40))(v3);
  }
  *a1 = &unk_26C35BFE8;
  uint64_t v4 = (void *)a1[12];
  if (v4 != (void *)a1[11]) {
    free(v4);
  }
  size_t v5 = (void *)a1[8];
  if (v5 != a1 + 10) {
    free(v5);
  }
  return a1;
}

void mlir::Pass::Option<BOOL,llvm::cl::parser<BOOL>>::~Option(void *a1)
{
  *a1 = &unk_26C35BE48;
  uint64_t v2 = a1 + 20;
  uint64_t v3 = (void *)a1[23];
  if (v3 == v2)
  {
    (*(void (**)(void *))(*v2 + 32))(v2);
  }
  else if (v3)
  {
    (*(void (**)(void *))(*v3 + 40))(v3);
  }
  *a1 = &unk_26C35BFE8;
  uint64_t v4 = (void *)a1[12];
  if (v4 != (void *)a1[11]) {
    free(v4);
  }
  size_t v5 = (void *)a1[8];
  if (v5 != a1 + 10) {
    free(v5);
  }

  JUMPOUT(0x21667D3C0);
}

llvm::raw_ostream *mlir::detail::PassOptions::Option<BOOL,llvm::cl::parser<BOOL>>::print(uint64_t a1, llvm::raw_ostream *this)
{
  uint64_t v4 = *(const void **)(a1 + 16);
  size_t v5 = *(void *)(a1 + 24);
  char v6 = (unsigned char *)*((void *)this + 4);
  if (v5 <= *((void *)this + 3) - (void)v6)
  {
    if (v5)
    {
      memcpy(v6, v4, v5);
      char v6 = (unsigned char *)(*((void *)this + 4) + v5);
      *((void *)this + 4) = v6;
    }
    size_t v7 = this;
  }
  else
  {
    size_t v7 = llvm::raw_ostream::write(this, (const char *)v4, v5);
    char v6 = (unsigned char *)*((void *)v7 + 4);
  }
  if ((unint64_t)v6 >= *((void *)v7 + 3))
  {
    llvm::raw_ostream::write(v7, 61);
  }
  else
  {
    *((void *)v7 + 4) = v6 + 1;
    *char v6 = 61;
  }
  BOOL v8 = *(unsigned char *)(a1 + 128) == 0;
  if (*(unsigned char *)(a1 + 128)) {
    size_t v9 = 4;
  }
  else {
    size_t v9 = 5;
  }
  if (v8) {
    unint64_t v10 = "false";
  }
  else {
    unint64_t v10 = "true";
  }
  uint64_t v11 = (void *)*((void *)this + 4);
  if (v9 <= *((void *)this + 3) - (void)v11)
  {
    __n128 result = (llvm::raw_ostream *)memcpy(v11, v10, v9);
    *((void *)this + 4) += v9;
  }
  else
  {
    return llvm::raw_ostream::write(this, v10, v9);
  }
  return result;
}

uint64_t mlir::detail::PassOptions::Option<BOOL,llvm::cl::parser<BOOL>>::copyValueFrom(uint64_t result, uint64_t a2)
{
  *(unsigned char *)(result + 128) = *(unsigned char *)(a2 - 64);
  *(unsigned char *)(result + 20std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = *(unsigned char *)(a2 + 8);
  return result;
}

void non-virtual thunk to'mlir::Pass::Option<BOOL,llvm::cl::parser<BOOL>>::~Option(uint64_t a1)
{
  *(void *)(a1 - 192) = &unk_26C35BE48;
  uint64_t v2 = a1 - 32;
  uint64_t v3 = *(void *)(a1 - 8);
  if (v3 == v2)
  {
    (*(void (**)(uint64_t))(*(void *)v2 + 32))(v2);
  }
  else if (v3)
  {
    (*(void (**)(uint64_t))(*(void *)v3 + 40))(v3);
  }
  *(void *)(a1 - 192) = &unk_26C35BFE8;
  uint64_t v4 = *(void **)(a1 - 96);
  if (v4 != *(void **)(a1 - 104)) {
    free(v4);
  }
  size_t v5 = *(void **)(a1 - 128);
  if (v5 != (void *)(a1 - 112)) {
    free(v5);
  }
}

{
  uint64_t v2;
  uint64_t v3;
  void *v4;
  void *v5;
  uint64_t vars8;

  *(void *)(a1 - 192) = &unk_26C35BE48;
  uint64_t v2 = a1 - 32;
  uint64_t v3 = *(void *)(a1 - 8);
  if (v3 == v2)
  {
    (*(void (**)(uint64_t))(*(void *)v2 + 32))(v2);
  }
  else if (v3)
  {
    (*(void (**)(uint64_t))(*(void *)v3 + 40))(v3);
  }
  *(void *)(a1 - 192) = &unk_26C35BFE8;
  uint64_t v4 = *(void **)(a1 - 96);
  if (v4 != *(void **)(a1 - 104)) {
    free(v4);
  }
  size_t v5 = *(void **)(a1 - 128);
  if (v5 != (void *)(a1 - 112)) {
    free(v5);
  }

  JUMPOUT(0x21667D3C0);
}

llvm::raw_ostream *non-virtual thunk to'mlir::detail::PassOptions::Option<BOOL,llvm::cl::parser<BOOL>>::print(uint64_t a1, llvm::raw_ostream *a2)
{
  return mlir::detail::PassOptions::Option<BOOL,llvm::cl::parser<BOOL>>::print(a1 - 192, a2);
}

uint64_t non-virtual thunk to'mlir::detail::PassOptions::Option<BOOL,llvm::cl::parser<BOOL>>::getOption(uint64_t a1)
{
  return a1 - 192;
}

uint64_t non-virtual thunk to'mlir::detail::PassOptions::Option<BOOL,llvm::cl::parser<BOOL>>::copyValueFrom(uint64_t result, uint64_t a2)
{
  *(unsigned char *)(result - 64) = *(unsigned char *)(a2 - 64);
  *(unsigned char *)(result + 8) = *(unsigned char *)(a2 + 8);
  return result;
}

uint64_t llvm::cl::opt<BOOL,false,llvm::cl::parser<BOOL>>::opt<llvm::StringRef,llvm::cl::sub,llvm::cl::desc,llvm::cl::initializer<BOOL>>(uint64_t a1, uint64_t a2, const void **a3, __n128 *a4, unsigned char **a5)
{
  *(void *)a1 = &unk_26C35BFE8;
  *(_WORD *)(a1 + 8) = 0;
  *(_WORD *)(a1 + 10) &= 0x8000u;
  unint64_t v10 = (void *)(a1 + 80);
  *(void *)(a1 + 64) = a1 + 80;
  uint64_t v11 = a1 + 64;
  *(_OWORD *)(a1 + 12) = 0u;
  *(_OWORD *)(a1 + 28) = 0u;
  *(_OWORD *)(a1 + 44) = 0u;
  *(_DWORD *)(a1 + 6std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  *(void *)(a1 + 72) = 0x100000000;
  *(void *)(a1 + 88) = a1 + 120;
  *(void *)(a1 + 96) = a1 + 120;
  *(void *)(a1 + 104) = 1;
  *(_DWORD *)(a1 + 112) = 0;
  GeneralCategory = llvm::cl::getGeneralCategory((llvm::cl *)a1);
  uint64_t v13 = *(unsigned int *)(a1 + 72);
  if (v13 >= *(_DWORD *)(a1 + 76))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod(v11, v10, v13 + 1, 8);
    LODWORD(v13) = *(_DWORD *)(a1 + 72);
  }
  *(void *)(*(void *)(a1 + 64) + 8 * v13) = GeneralCategory;
  ++*(_DWORD *)(a1 + 72);
  *(unsigned char *)(a1 + 128) = 0;
  *(void *)(a1 + 136) = &unk_26C35BCD8;
  *(void *)(a1 + 144) = 0;
  *(void *)a1 = &unk_26C35BE48;
  *(void *)(a1 + 152) = &unk_26C35C0D0;
  *(void *)(a1 + 16std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = &unk_26C380D40;
  *(void *)(a1 + 184) = a1 + 160;
  llvm::cl::apply<llvm::cl::opt<BOOL,false,llvm::cl::parser<BOOL>>,llvm::StringRef,llvm::cl::sub,llvm::cl::desc,llvm::cl::initializer<BOOL>>(a1, a2, a3, a4, a5);
  llvm::cl::Option::addArgument((llvm::cl::Option *)a1);
  return a1;
}

void *mlir::detail::PassOptions::Option<BOOL,llvm::cl::parser<BOOL>>::~Option(void *a1)
{
  *a1 = &unk_26C35BE48;
  uint64_t v2 = a1 + 20;
  uint64_t v3 = (void *)a1[23];
  if (v3 == v2)
  {
    (*(void (**)(void *))(*v2 + 32))(v2);
  }
  else if (v3)
  {
    (*(void (**)(void *))(*v3 + 40))(v3);
  }
  *a1 = &unk_26C35BFE8;
  uint64_t v4 = (void *)a1[12];
  if (v4 != (void *)a1[11]) {
    free(v4);
  }
  size_t v5 = (void *)a1[8];
  if (v5 != a1 + 10) {
    free(v5);
  }
  return a1;
}

void mlir::detail::PassOptions::Option<BOOL,llvm::cl::parser<BOOL>>::~Option(void *a1)
{
  *a1 = &unk_26C35BE48;
  uint64_t v2 = a1 + 20;
  uint64_t v3 = (void *)a1[23];
  if (v3 == v2)
  {
    (*(void (**)(void *))(*v2 + 32))(v2);
  }
  else if (v3)
  {
    (*(void (**)(void *))(*v3 + 40))(v3);
  }
  *a1 = &unk_26C35BFE8;
  uint64_t v4 = (void *)a1[12];
  if (v4 != (void *)a1[11]) {
    free(v4);
  }
  size_t v5 = (void *)a1[8];
  if (v5 != a1 + 10) {
    free(v5);
  }

  JUMPOUT(0x21667D3C0);
}

void non-virtual thunk to'mlir::detail::PassOptions::Option<BOOL,llvm::cl::parser<BOOL>>::~Option(uint64_t a1)
{
  *(void *)(a1 - 192) = &unk_26C35BE48;
  uint64_t v2 = a1 - 32;
  uint64_t v3 = *(void *)(a1 - 8);
  if (v3 == v2)
  {
    (*(void (**)(uint64_t))(*(void *)v2 + 32))(v2);
  }
  else if (v3)
  {
    (*(void (**)(uint64_t))(*(void *)v3 + 40))(v3);
  }
  *(void *)(a1 - 192) = &unk_26C35BFE8;
  uint64_t v4 = *(void **)(a1 - 96);
  if (v4 != *(void **)(a1 - 104)) {
    free(v4);
  }
  size_t v5 = *(void **)(a1 - 128);
  if (v5 != (void *)(a1 - 112)) {
    free(v5);
  }
}

{
  mlir::detail::PassOptions::Option<BOOL,llvm::cl::parser<BOOL>>::~Option((void *)(a1 - 192));
}

__n128 llvm::cl::apply<llvm::cl::opt<BOOL,false,llvm::cl::parser<BOOL>>,llvm::StringRef,llvm::cl::sub,llvm::cl::desc,llvm::cl::initializer<BOOL>>(uint64_t a1, uint64_t a2, const void **a3, __n128 *a4, unsigned char **a5)
{
  llvm::cl::Option::setArgStr(a1, *(int8x16_t **)a2, *(const unsigned __int8 **)(a2 + 8));
  size_t v9 = *a3;
  uint64_t v10 = *(void *)(a1 + 96);
  if (v10 != *(void *)(a1 + 88))
  {
LABEL_2:
    llvm::SmallPtrSetImplBase::insert_imp_big((llvm::SmallPtrSetImplBase *)(a1 + 88), v9);
    goto LABEL_3;
  }
  uint64_t v13 = *(unsigned int *)(a1 + 108);
  if (!v13)
  {
LABEL_12:
    if (v13 < *(_DWORD *)(a1 + 104))
    {
      *(_DWORD *)(a1 + 108) = v13 + 1;
      *(void *)(v10 + 8 * v13) = v9;
      goto LABEL_3;
    }
    goto LABEL_2;
  }
  uint64_t v14 = 0;
  uint64_t v15 = 8 * v13;
  unint64_t v16 = *(void **)(a1 + 96);
  while ((const void *)*v16 != v9)
  {
    if (*v16 == -2) {
      uint64_t v14 = v16;
    }
    ++v16;
    v15 -= 8;
    if (!v15)
    {
      if (!v14) {
        goto LABEL_12;
      }
      *uint64_t v14 = v9;
      --*(_DWORD *)(a1 + 112);
      break;
    }
  }
LABEL_3:
  __n128 result = *a4;
  *(__n128 *)(a1 + 32) = *a4;
  uint64_t v12 = *a5;
  *(unsigned char *)(a1 + 128) = **a5;
  *(unsigned char *)(a1 + 145) = 1;
  *(unsigned char *)(a1 + 144) = *v12;
  return result;
}

BOOL llvm::cl::OptionValueCopy<BOOL>::compare(uint64_t a1, uint64_t a2)
{
  return *(unsigned char *)(a2 + 9) && *(unsigned char *)(a1 + 9) && *(unsigned __int8 *)(a1 + 8) == *(unsigned __int8 *)(a2 + 8);
}

void std::__function::__func<llvm::cl::opt<BOOL,false,llvm::cl::parser<BOOL>>::{lambda(BOOL const&)#1},std::allocator<llvm::cl::opt<BOOL,false,llvm::cl::parser<BOOL>>::{lambda(BOOL const&)#1}>,void ()(BOOL const&)>::~__func()
{
}

void *std::__function::__func<llvm::cl::opt<BOOL,false,llvm::cl::parser<BOOL>>::{lambda(BOOL const&)#1},std::allocator<llvm::cl::opt<BOOL,false,llvm::cl::parser<BOOL>>::{lambda(BOOL const&)#1}>,void ()(BOOL const&)>::__clone()
{
  __n128 result = operator new(0x10uLL);
  *__n128 result = &unk_26C380D40;
  return result;
}

void std::__function::__func<llvm::cl::opt<BOOL,false,llvm::cl::parser<BOOL>>::{lambda(BOOL const&)#1},std::allocator<llvm::cl::opt<BOOL,false,llvm::cl::parser<BOOL>>::{lambda(BOOL const&)#1}>,void ()(BOOL const&)>::__clone(uint64_t a1, void *a2)
{
  *a2 = &unk_26C380D40;
}

void *std::__function::__value_func<void ()(BOOL const&)>::swap[abi:nn180100](void *result, void *a2)
{
  v6[3] = *MEMORY[0x263EF8340];
  if (a2 != result)
  {
    uint64_t v3 = result;
    uint64_t v4 = (void *)result[3];
    size_t v5 = (void *)a2[3];
    if (v4 == result)
    {
      if (v5 == a2)
      {
        (*(void (**)(void *, void *))(*result + 24))(result, v6);
        (*(void (**)(void))(*(void *)v3[3] + 32))(v3[3]);
        v3[3] = 0;
        (*(void (**)(void, void *))(*(void *)a2[3] + 24))(a2[3], v3);
        (*(void (**)(void))(*(void *)a2[3] + 32))(a2[3]);
        a2[3] = 0;
        v3[3] = v3;
        (*(void (**)(void *, void *))(v6[0] + 24))(v6, a2);
        __n128 result = (void *)(*(uint64_t (**)(void *))(v6[0] + 32))(v6);
      }
      else
      {
        (*(void (**)(void *, void *))(*result + 24))(result, a2);
        __n128 result = (void *)(*(uint64_t (**)(void))(*(void *)v3[3] + 32))(v3[3]);
        v3[3] = a2[3];
      }
      a2[3] = a2;
    }
    else if (v5 == a2)
    {
      (*(void (**)(void *, void *))(*a2 + 24))(a2, result);
      __n128 result = (void *)(*(uint64_t (**)(void))(*(void *)a2[3] + 32))(a2[3]);
      a2[3] = v3[3];
      v3[3] = v3;
    }
    else
    {
      result[3] = v5;
      a2[3] = v4;
    }
  }
  return result;
}

void _ZNSt3__110__function6__funcIZN4mlir6detail11PassOptions6OptionIbN4llvm2cl6parserIbEEEC1IJNS7_4descENS7_11initializerIbEEEEERS4_NS6_9StringRefEDpOT_EUlRKT_E_NS_9allocatorISN_EEFvRKbEED0Ev()
{
}

void *_ZNKSt3__110__function6__funcIZN4mlir6detail11PassOptions6OptionIbN4llvm2cl6parserIbEEEC1IJNS7_4descENS7_11initializerIbEEEEERS4_NS6_9StringRefEDpOT_EUlRKT_E_NS_9allocatorISN_EEFvRKbEE7__cloneEv(uint64_t a1)
{
  __n128 result = operator new(0x10uLL);
  uint64_t v3 = *(void *)(a1 + 8);
  *__n128 result = &unk_26C387B20;
  result[1] = v3;
  return result;
}

uint64_t _ZNKSt3__110__function6__funcIZN4mlir6detail11PassOptions6OptionIbN4llvm2cl6parserIbEEEC1IJNS7_4descENS7_11initializerIbEEEEERS4_NS6_9StringRefEDpOT_EUlRKT_E_NS_9allocatorISN_EEFvRKbEE7__cloneEPNS0_6__baseISS_EE(uint64_t result, void *a2)
{
  uint64_t v2 = *(void *)(result + 8);
  *a2 = &unk_26C387B20;
  a2[1] = v2;
  return result;
}

uint64_t _ZNSt3__110__function6__funcIZN4mlir6detail11PassOptions6OptionIbN4llvm2cl6parserIbEEEC1IJNS7_4descENS7_11initializerIbEEEEERS4_NS6_9StringRefEDpOT_EUlRKT_E_NS_9allocatorISN_EEFvRKbEEclESR_(uint64_t result)
{
  *(unsigned char *)(*(void *)(result + 8) + 20std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 1;
  return result;
}

void mlir::Pass::~Pass(mlir::Pass *this)
{
  *(void *)this = &unk_26C37E8C0;
  uint64_t v2 = (void *)*((void *)this + 39);
  if (v2)
  {
    *((void *)this + 4std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v2;
    operator delete(v2);
  }
  if (*((_DWORD *)this + 73))
  {
    uint64_t v3 = *((unsigned int *)this + 72);
    if (v3)
    {
      uint64_t v4 = 0;
      do
      {
        size_t v5 = *(llvm **)(*((void *)this + 35) + v4);
        if (v5 != (llvm *)-8 && v5 != 0) {
          llvm::deallocate_buffer(v5, (void *)(*(void *)v5 + 17));
        }
        v4 += 8;
      }
      while (8 * v3 != v4);
    }
  }
  free(*((void **)this + 35));
  size_t v7 = (char *)*((void *)this + 29);
  if (v7 != (char *)this + 248) {
    free(v7);
  }
  BOOL v8 = (char *)*((void *)this + 23);
  if (v8 != (char *)this + 200) {
    free(v8);
  }
  size_t v9 = (void *)*((void *)this + 16);
  if (v9)
  {
    *((void *)this + 17) = v9;
    operator delete(v9);
  }
  if (*((unsigned char *)this + 120))
  {
    uint64_t v10 = (void *)*((void *)this + 8);
    if (v10 != *((void **)this + 7)) {
      free(v10);
    }
  }
}

void mlir::Operation::setAttr(uint64_t a1, uint64_t a2, uint64_t a3)
{
  v11[9] = *MEMORY[0x263EF8340];
  uint64_t v9 = a2;
  if (*(unsigned char *)(a1 + 47)
    && (uint64_t AttrData = mlir::OpaqueAttr::getAttrData((mlir::OpaqueAttr *)&v9),
        mlir::Operation::getInherentAttr(a1, AttrData, v6),
        v7))
  {
    mlir::Operation::setInherentAttr(a1, v9, a3);
  }
  else
  {
    mlir::NamedAttrList::NamedAttrList(v10, *(void *)(a1 + 56));
    if (mlir::NamedAttrList::set((uint64_t)v10, v9, a3) != a3)
    {
      Context = (mlir::MLIRContext *)mlir::Attribute::getContext((mlir::Attribute *)(a1 + 24));
      *(void *)(a1 + 56) = mlir::NamedAttrList::getDictionary((mlir::NamedAttrList *)v10, Context);
    }
    if (v10[0] != v11) {
      free(v10[0]);
    }
  }
}

void mlir::DataFlowSolver::~DataFlowSolver(mlir::DataFlowSolver *this)
{
  unsigned int v2 = *((_DWORD *)this + 34);
  uint64_t v3 = (llvm *)*((void *)this + 15);
  if (v2)
  {
    uint64_t v4 = (char *)v3 + 24 * v2;
    size_t v5 = (uint64_t *)((char *)v3 + 16);
    do
    {
      uint64_t v7 = *(v5 - 2);
      uint64_t v6 = *(v5 - 1);
      BOOL v8 = v5 - 2;
      if ((v7 != -4096 || v6 != -4096) && (v7 != -8192 || v6 != -8192))
      {
        uint64_t v9 = *v5;
        *size_t v5 = 0;
        if (v9) {
          (*(void (**)(uint64_t))(*(void *)v9 + 8))(v9);
        }
      }
      v5 += 3;
    }
    while (v8 + 3 != (uint64_t *)v4);
    uint64_t v3 = (llvm *)*((void *)this + 15);
    uint64_t v10 = 24 * *((unsigned int *)this + 34);
  }
  else
  {
    uint64_t v10 = 0;
  }
  llvm::deallocate_buffer(v3, (void *)v10);
}

uint64_t std::deque<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>>::~deque[abi:nn180100](uint64_t a1)
{
  unsigned int v2 = *(void ***)(a1 + 8);
  uint64_t v3 = *(void ***)(a1 + 16);
  *(void *)(a1 + 4std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  unint64_t v4 = (char *)v3 - (char *)v2;
  if ((unint64_t)((char *)v3 - (char *)v2) >= 0x11)
  {
    do
    {
      operator delete(*v2);
      uint64_t v3 = *(void ***)(a1 + 16);
      unsigned int v2 = (void **)(*(void *)(a1 + 8) + 8);
      *(void *)(a1 + 8) = v2;
      unint64_t v4 = (char *)v3 - (char *)v2;
    }
    while ((unint64_t)((char *)v3 - (char *)v2) > 0x10);
  }
  unint64_t v5 = v4 >> 3;
  if (v5 == 1)
  {
    uint64_t v6 = 128;
    goto LABEL_7;
  }
  if (v5 == 2)
  {
    uint64_t v6 = 256;
LABEL_7:
    *(void *)(a1 + 32) = v6;
  }
  if (v2 != v3)
  {
    do
    {
      uint64_t v7 = *v2++;
      operator delete(v7);
    }
    while (v2 != v3);
    uint64_t v9 = *(void *)(a1 + 8);
    uint64_t v8 = *(void *)(a1 + 16);
    if (v8 != v9) {
      *(void *)(a1 + 16) = v8 + ((v9 - v8 + 7) & 0xFFFFFFFFFFFFFFF8);
    }
  }
  if (*(void *)a1) {
    operator delete(*(void **)a1);
  }
  return a1;
}

void mlir::AnalysisState::~AnalysisState(mlir::AnalysisState *this)
{
  *(void *)this = &unk_26C361DE8;
  unsigned int v2 = (char *)*((void *)this + 5);
  if (v2 != (char *)this + 56) {
    free(v2);
  }
  llvm::deallocate_buffer(*((llvm **)this + 2), (void *)(16 * *((unsigned int *)this + 8)));
}

uint64_t sub_2113C3A58()
{
  return v0;
}

uint64_t mlir::ProgramPoint::getLoc(mlir::ProgramPoint *this)
{
  uint64_t v1 = *(void *)this & 6;
  unsigned int v2 = (mlir::Block *)(*(void *)this & 0xFFFFFFFFFFFFFFF8);
  if (v1) {
    BOOL v3 = 1;
  }
  else {
    BOOL v3 = v2 == 0;
  }
  if (v3)
  {
    if (v1 != 2 || v2 == 0)
    {
      if (v1 == 4) {
        unint64_t v5 = v2;
      }
      else {
        unint64_t v5 = 0;
      }
      uint64_t v9 = v5;
      if (v5)
      {
        return mlir::Value::getLoc((mlir::Value *)&v9);
      }
      else
      {
        Parent = (mlir::Region *)mlir::Block::getParent(v2);
        return mlir::Region::getLoc(Parent);
      }
    }
    else
    {
      return *((void *)v2 + 3);
    }
  }
  else
  {
    uint64_t v6 = *(uint64_t (**)(void))(*(void *)v2 + 16);
    return v6();
  }
}

uint64_t mlir::DataFlowSolver::initializeAndRun(mlir::DataFlowSolver *this, Operation *a2)
{
  uint64_t v3 = *((unsigned int *)this + 14);
  if (v3)
  {
    unint64_t v5 = (void *)*((void *)this + 6);
    uint64_t v6 = 8 * v3;
    while ((*(unsigned __int8 (**)(void, Operation *))(*(void *)*v5 + 16))(*v5, a2))
    {
      ++v5;
      v6 -= 8;
      if (!v6) {
        goto LABEL_7;
      }
    }
    return 0;
  }
  else
  {
LABEL_7:
    while (1)
    {
      uint64_t v7 = *((void *)this + 5);
      if (!v7) {
        break;
      }
      uint64_t v8 = (void **)*((void *)this + 1);
      unint64_t v9 = *((void *)this + 4);
      uint64_t v10 = (uint64_t *)(*(char **)((char *)v8 + ((v9 >> 5) & 0x7FFFFFFFFFFFFF8)) + 16 * v9);
      uint64_t v11 = *v10;
      uint64_t v12 = v10[1];
      *((void *)this + 4) = ++v9;
      *((void *)this + 5) = v7 - 1;
      if (v9 >= 0x200)
      {
        operator delete(*v8);
        *((void *)this + 1) += 8;
        *((void *)this + 4) -= 256;
      }
      if (!(*(unsigned __int8 (**)(uint64_t, uint64_t))(*(void *)v12 + 24))(v12, v11)) {
        return 0;
      }
    }
    return 1;
  }
}

void *mlir::DataFlowAnalysis::DataFlowAnalysis(void *this, mlir::DataFlowSolver *a2)
{
  *this = &unk_26C3620D8;
  this[1] = a2;
  return this;
}

void mlir::DataFlowAnalysis::addDependency(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v9 = *MEMORY[0x263EF8340];
  v8[0] = a3;
  v8[1] = a1;
  llvm::DenseMapBase<llvm::DenseMap<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>,void>,llvm::detail::DenseSetPair<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>>>,std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>,void>,llvm::detail::DenseSetPair<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>>>::try_emplace<llvm::detail::DenseSetEmpty&>(a2 + 16, v8, (uint64_t)v7);
  if (v7[16])
  {
    long long v4 = *(_OWORD *)v8;
    uint64_t v5 = *(unsigned int *)(a2 + 48);
    if (v5 >= *(_DWORD *)(a2 + 52))
    {
      long long v6 = *(_OWORD *)v8;
      llvm::SmallVectorBase<unsigned int>::grow_pod(a2 + 40, (void *)(a2 + 56), v5 + 1, 16);
      long long v4 = v6;
      LODWORD(v5) = *(_DWORD *)(a2 + 48);
    }
    *(_OWORD *)(*(void *)(a2 + 40) + 16 * v5) = v4;
    ++*(_DWORD *)(a2 + 48);
  }
}

uint64_t mlir::DataFlowAnalysis::propagateIfChanged(uint64_t result, uint64_t a2, int a3)
{
  if (a3 == 1) {
    return (*(uint64_t (**)(uint64_t, void))(*(void *)a2 + 24))(a2, *(void *)(result + 8));
  }
  return result;
}

void mlir::AnalysisState::onUpdate(mlir::AnalysisState *this, mlir::DataFlowSolver *a2)
{
  uint64_t v2 = *((unsigned int *)this + 12);
  if (v2)
  {
    long long v4 = (long long *)*((void *)this + 5);
    uint64_t v5 = *((void *)a2 + 5);
    uint64_t v6 = 16 * v2;
    do
    {
      uint64_t v7 = *((void *)a2 + 2);
      uint64_t v8 = *((void *)a2 + 1);
      long long v9 = *v4;
      if (v7 == v8) {
        uint64_t v10 = 0;
      }
      else {
        uint64_t v10 = 32 * (v7 - v8) - 1;
      }
      unint64_t v11 = v5 + *((void *)a2 + 4);
      if (v10 == v11)
      {
        long long v12 = *v4;
        std::deque<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>>::__add_back_capacity((uint64_t)a2);
        long long v9 = v12;
        uint64_t v8 = *((void *)a2 + 1);
        unint64_t v11 = *((void *)a2 + 5) + *((void *)a2 + 4);
      }
      *(_OWORD *)(*(void *)(v8 + ((v11 >> 5) & 0x7FFFFFFFFFFFFF8)) + 16 * v11) = v9;
      uint64_t v5 = *((void *)a2 + 5) + 1;
      *((void *)a2 + 5) = v5;
      ++v4;
      v6 -= 16;
    }
    while (v6);
  }
}

void std::deque<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>>::__add_back_capacity(uint64_t a1)
{
  unint64_t v2 = *(void *)(a1 + 32);
  BOOL v3 = v2 >= 0x100;
  unint64_t v4 = v2 - 256;
  if (v3)
  {
    *(void *)(a1 + 32) = v4;
    uint64_t v6 = *(void **)(a1 + 8);
    uint64_t v5 = *(char **)(a1 + 16);
    uint64_t v7 = (char *)(v6 + 1);
    uint64_t v8 = *v6;
    *(void *)(a1 + 8) = v6 + 1;
    if (v5 != *(char **)(a1 + 24))
    {
LABEL_78:
      *(void *)uint64_t v5 = v8;
      *(void *)(a1 + 16) += 8;
      return;
    }
    long long v9 = *(char **)a1;
    uint64_t v10 = (uint64_t)&v7[-*(void *)a1];
    if ((unint64_t)v7 <= *(void *)a1)
    {
      unint64_t v34 = (v5 - v9) >> 2;
      if (v5 == v9) {
        unint64_t v34 = 1;
      }
      if (!(v34 >> 61))
      {
        unint64_t v35 = v34 >> 2;
        uint64_t v36 = 8 * v34;
        int v37 = (char *)operator new(8 * v34);
        uint64_t v38 = &v37[8 * v35];
        uint64_t v39 = &v37[v36];
        int64_t v41 = v5 - v7;
        BOOL v40 = v5 == v7;
        uint64_t v5 = v38;
        if (!v40)
        {
          uint64_t v5 = &v38[v41 & 0xFFFFFFFFFFFFFFF8];
          unint64_t v42 = v41 - 8;
          if ((unint64_t)(v41 - 8) >= 0x38)
          {
            char v76 = &v37[8 * v35];
            unint64_t v43 = v76;
            if ((unint64_t)(v76 - v7) >= 0x20)
            {
              uint64_t v77 = (v42 >> 3) + 1;
              uint64_t v78 = 8 * (v77 & 0x3FFFFFFFFFFFFFFCLL);
              unint64_t v43 = &v38[v78];
              v7 += v78;
              uint64_t v79 = (long long *)(v6 + 3);
              long long v80 = v76 + 16;
              uint64_t v81 = v77 & 0x3FFFFFFFFFFFFFFCLL;
              do
              {
                long long v82 = *v79;
                *(v80 - 1) = *(v79 - 1);
                *long long v80 = v82;
                v79 += 2;
                v80 += 2;
                v81 -= 4;
              }
              while (v81);
              if (v77 == (v77 & 0x3FFFFFFFFFFFFFFCLL)) {
                goto LABEL_76;
              }
            }
          }
          else
          {
            unint64_t v43 = &v37[8 * v35];
          }
          do
          {
            uint64_t v83 = *(void *)v7;
            v7 += 8;
            *(void *)unint64_t v43 = v83;
            v43 += 8;
          }
          while (v43 != v5);
        }
        goto LABEL_76;
      }
LABEL_86:
      std::__throw_bad_array_new_length[abi:nn180100]();
    }
LABEL_5:
    uint64_t v11 = v10 >> 3;
    if (v11 >= -1) {
      uint64_t v12 = v11 + 1;
    }
    else {
      uint64_t v12 = v11 + 2;
    }
    uint64_t v13 = v12 >> 1;
    uint64_t v14 = -v13;
    uint64_t v15 = &v7[-8 * v13];
    int64_t v16 = v5 - v7;
    if (v5 != v7)
    {
      memmove(&v7[-8 * v13], v7, v5 - v7);
      uint64_t v7 = *(char **)(a1 + 8);
    }
    uint64_t v5 = &v15[v16];
    *(void *)(a1 + 8) = &v7[8 * v14];
    *(void *)(a1 + 16) = &v15[v16];
    goto LABEL_78;
  }
  uint64_t v18 = *(void *)(a1 + 16);
  uint64_t v17 = *(void *)(a1 + 24);
  uint64_t v19 = *(void *)(a1 + 8);
  uint64_t v20 = v18 - v19;
  uint64_t v21 = (v18 - v19) >> 3;
  uint64_t v22 = v17 - *(void *)a1;
  if (v21 < (unint64_t)(v22 >> 3))
  {
    if (v17 != v18)
    {
      uint64_t v92 = operator new(0x1000uLL);
      std::__split_buffer<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *> *,std::allocator<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *> *>>::push_back((char **)a1, &v92);
      return;
    }
    uint64_t v92 = operator new(0x1000uLL);
    std::__split_buffer<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *> *,std::allocator<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *> *>>::push_front((void **)a1, &v92);
    uint64_t v44 = *(void **)(a1 + 8);
    uint64_t v5 = *(char **)(a1 + 16);
    uint64_t v7 = (char *)(v44 + 1);
    uint64_t v8 = *v44;
    *(void *)(a1 + 8) = v44 + 1;
    if (v5 != *(char **)(a1 + 24)) {
      goto LABEL_78;
    }
    long long v9 = *(char **)a1;
    uint64_t v10 = (uint64_t)&v7[-*(void *)a1];
    if ((unint64_t)v7 <= *(void *)a1)
    {
      unint64_t v45 = (v5 - v9) >> 2;
      if (v5 == v9) {
        unint64_t v45 = 1;
      }
      if (!(v45 >> 61))
      {
        unint64_t v46 = v45 >> 2;
        uint64_t v47 = 8 * v45;
        int v37 = (char *)operator new(8 * v45);
        uint64_t v38 = &v37[8 * v46];
        uint64_t v39 = &v37[v47];
        int64_t v48 = v5 - v7;
        BOOL v40 = v5 == v7;
        uint64_t v5 = v38;
        if (!v40)
        {
          uint64_t v5 = &v38[v48 & 0xFFFFFFFFFFFFFFF8];
          unint64_t v49 = v48 - 8;
          if ((unint64_t)(v48 - 8) >= 0x38)
          {
            uint64_t v84 = &v37[8 * v46];
            uint64_t v50 = v84;
            if ((unint64_t)(v84 - v7) >= 0x20)
            {
              uint64_t v85 = (v49 >> 3) + 1;
              uint64_t v86 = 8 * (v85 & 0x3FFFFFFFFFFFFFFCLL);
              uint64_t v50 = &v38[v86];
              v7 += v86;
              unint64_t v87 = (long long *)(v44 + 3);
              __n128 v88 = v84 + 16;
              uint64_t v89 = v85 & 0x3FFFFFFFFFFFFFFCLL;
              do
              {
                long long v90 = *v87;
                *(v88 - 1) = *(v87 - 1);
                *__n128 v88 = v90;
                v87 += 2;
                v88 += 2;
                v89 -= 4;
              }
              while (v89);
              if (v85 == (v85 & 0x3FFFFFFFFFFFFFFCLL)) {
                goto LABEL_76;
              }
            }
          }
          else
          {
            uint64_t v50 = &v37[8 * v46];
          }
          do
          {
            uint64_t v91 = *(void *)v7;
            v7 += 8;
            *(void *)uint64_t v50 = v91;
            v50 += 8;
          }
          while (v50 != v5);
        }
LABEL_76:
        *(void *)a1 = v37;
        *(void *)(a1 + 8) = v38;
        *(void *)(a1 + 16) = v5;
        *(void *)(a1 + 24) = v39;
        if (v9)
        {
          operator delete(v9);
          uint64_t v5 = *(char **)(a1 + 16);
        }
        goto LABEL_78;
      }
      goto LABEL_86;
    }
    goto LABEL_5;
  }
  uint64_t v23 = v22 >> 2;
  if (v17 == *(void *)a1) {
    unint64_t v24 = 1;
  }
  else {
    unint64_t v24 = v23;
  }
  if (v24 >> 61) {
    goto LABEL_86;
  }
  unint64_t v25 = (char *)operator new(8 * v24);
  unint64_t v26 = &v25[8 * v21];
  uint64_t v27 = &v25[8 * v24];
  long long v28 = operator new(0x1000uLL);
  uint64_t v29 = v28;
  if (v21 != v24) {
    goto LABEL_23;
  }
  if (v20 >= 1)
  {
    unint64_t v30 = v21 + 2;
    if (v21 >= -1) {
      unint64_t v30 = v21 + 1;
    }
    v26 -= 8 * (v30 >> 1);
LABEL_23:
    *(void *)unint64_t v26 = v28;
    uint64_t v31 = v26 + 8;
    if (v18 != v19) {
      goto LABEL_51;
    }
    goto LABEL_24;
  }
  if (v18 == v19) {
    unint64_t v51 = 1;
  }
  else {
    unint64_t v51 = v20 >> 2;
  }
  if (v51 >> 61) {
    goto LABEL_86;
  }
  uint64_t v52 = 8 * v51;
  long long v53 = (char *)operator new(8 * v51);
  unint64_t v26 = &v53[8 * (v51 >> 2)];
  uint64_t v27 = &v53[v52];
  operator delete(v25);
  uint64_t v54 = *(void *)(a1 + 8);
  uint64_t v18 = *(void *)(a1 + 16);
  unint64_t v25 = v53;
  *(void *)unint64_t v26 = v29;
  uint64_t v31 = v26 + 8;
  if (v18 != v54)
  {
    while (1)
    {
LABEL_51:
      if (v26 == v25)
      {
        if (v31 >= v27)
        {
          unint64_t v61 = (v27 - v26) >> 2;
          if (v27 == v26) {
            unint64_t v61 = 1;
          }
          if (v61 >> 61) {
            goto LABEL_86;
          }
          unint64_t v62 = (v61 + 3) >> 2;
          uint64_t v63 = 8 * v61;
          uint64_t v64 = (char *)operator new(8 * v61);
          unint64_t v25 = v64;
          BOOL v55 = &v64[8 * v62];
          int64_t v65 = v31 - v26;
          BOOL v40 = v31 == v26;
          uint64_t v31 = v55;
          if (!v40)
          {
            uint64_t v31 = &v55[v65 & 0xFFFFFFFFFFFFFFF8];
            unint64_t v66 = v65 - 8;
            uint64_t v67 = &v64[8 * v62];
            uint64_t v68 = v26;
            if (v66 < 0x38) {
              goto LABEL_89;
            }
            uint64_t v67 = &v64[8 * v62];
            uint64_t v68 = v26;
            if ((unint64_t)(v67 - v26) < 0x20) {
              goto LABEL_89;
            }
            uint64_t v69 = (v66 >> 3) + 1;
            uint64_t v70 = 8 * (v69 & 0x3FFFFFFFFFFFFFFCLL);
            uint64_t v67 = &v55[v70];
            uint64_t v68 = &v26[v70];
            BOOL v71 = (long long *)(v26 + 16);
            unint64_t v72 = &v64[8 * v62 + 16];
            uint64_t v73 = v69 & 0x3FFFFFFFFFFFFFFCLL;
            do
            {
              long long v74 = *v71;
              *((_OWORD *)v72 - 1) = *(v71 - 1);
              *(_OWORD *)unint64_t v72 = v74;
              v71 += 2;
              v72 += 32;
              v73 -= 4;
            }
            while (v73);
            if (v69 != (v69 & 0x3FFFFFFFFFFFFFFCLL))
            {
LABEL_89:
              do
              {
                uint64_t v75 = *(void *)v68;
                v68 += 8;
                *(void *)uint64_t v67 = v75;
                v67 += 8;
              }
              while (v67 != v31);
            }
          }
          uint64_t v27 = &v64[v63];
          operator delete(v26);
        }
        else
        {
          uint64_t v57 = (v27 - v31) >> 3;
          if (v57 >= -1) {
            unint64_t v58 = v57 + 1;
          }
          else {
            unint64_t v58 = v57 + 2;
          }
          uint64_t v59 = &v31[8 * (v58 >> 1)];
          BOOL v55 = &v59[-(v31 - v26)];
          size_t v60 = v31 - v26;
          BOOL v40 = v31 == v26;
          uint64_t v31 = v59;
          if (!v40) {
            memmove(v55, v26, v60);
          }
          unint64_t v25 = v26;
        }
      }
      else
      {
        BOOL v55 = v26;
      }
      uint64_t v56 = *(void *)(v18 - 8);
      v18 -= 8;
      *((void *)v55 - 1) = v56;
      uint64_t v32 = v55 - 8;
      unint64_t v26 = v32;
      if (v18 == *(void *)(a1 + 8)) {
        goto LABEL_25;
      }
    }
  }
LABEL_24:
  uint64_t v32 = v26;
LABEL_25:
  long long v33 = *(char **)a1;
  *(void *)a1 = v25;
  *(void *)(a1 + 8) = v32;
  *(void *)(a1 + 16) = v31;
  *(void *)(a1 + 24) = v27;
  if (v33)
  {
    operator delete(v33);
  }
}

void std::__split_buffer<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *> *,std::allocator<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *> *>>::push_back(char **a1, void *a2)
{
  unint64_t v4 = a1[2];
  if (v4 != a1[3]) {
    goto LABEL_22;
  }
  uint64_t v5 = *a1;
  uint64_t v6 = a1[1];
  if (v6 > *a1)
  {
    uint64_t v7 = (v6 - *a1) >> 3;
    if (v7 >= -1) {
      uint64_t v8 = v7 + 1;
    }
    else {
      uint64_t v8 = v7 + 2;
    }
    uint64_t v9 = v8 >> 1;
    uint64_t v10 = -v9;
    uint64_t v11 = &v6[-8 * v9];
    int64_t v12 = v4 - v6;
    if (v4 != v6)
    {
      memmove(&v6[-8 * v9], a1[1], v4 - v6);
      unint64_t v4 = a1[1];
    }
    uint64_t v13 = &v4[8 * v10];
    unint64_t v4 = &v11[v12];
    a1[1] = v13;
    a1[2] = &v11[v12];
    goto LABEL_22;
  }
  unint64_t v14 = (v4 - v5) >> 2;
  if (v4 == v5) {
    unint64_t v14 = 1;
  }
  if (v14 >> 61) {
    std::__throw_bad_array_new_length[abi:nn180100]();
  }
  unint64_t v15 = v14 >> 2;
  uint64_t v16 = 8 * v14;
  uint64_t v17 = (char *)operator new(8 * v14);
  uint64_t v18 = &v17[8 * v15];
  int64_t v20 = v4 - v6;
  BOOL v19 = v4 == v6;
  unint64_t v4 = v18;
  if (!v19)
  {
    unint64_t v4 = &v18[v20 & 0xFFFFFFFFFFFFFFF8];
    unint64_t v21 = v20 - 8;
    if ((unint64_t)(v20 - 8) < 0x38)
    {
      uint64_t v22 = &v17[8 * v15];
      do
      {
LABEL_19:
        uint64_t v31 = *(void *)v6;
        v6 += 8;
        *(void *)uint64_t v22 = v31;
        v22 += 8;
      }
      while (v22 != v4);
      goto LABEL_20;
    }
    uint64_t v23 = &v17[8 * v15];
    uint64_t v22 = v23;
    if ((unint64_t)(v23 - v6) < 0x20) {
      goto LABEL_19;
    }
    uint64_t v24 = (v21 >> 3) + 1;
    uint64_t v25 = 8 * (v24 & 0x3FFFFFFFFFFFFFFCLL);
    uint64_t v22 = &v18[v25];
    unint64_t v26 = &v6[v25];
    uint64_t v27 = (long long *)(v6 + 16);
    long long v28 = v23 + 16;
    uint64_t v29 = v24 & 0x3FFFFFFFFFFFFFFCLL;
    do
    {
      long long v30 = *v27;
      *(v28 - 1) = *(v27 - 1);
      *long long v28 = v30;
      v27 += 2;
      v28 += 2;
      v29 -= 4;
    }
    while (v29);
    uint64_t v6 = v26;
    if (v24 != (v24 & 0x3FFFFFFFFFFFFFFCLL)) {
      goto LABEL_19;
    }
  }
LABEL_20:
  *a1 = v17;
  a1[1] = v18;
  a1[2] = v4;
  a1[3] = &v17[v16];
  if (v5)
  {
    operator delete(v5);
    unint64_t v4 = a1[2];
  }
LABEL_22:
  *(void *)unint64_t v4 = *a2;
  a1[2] += 8;
}

void std::__split_buffer<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *> *,std::allocator<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *> *>>::push_front(void **a1, void *a2)
{
  unint64_t v4 = (char *)a1[1];
  if (v4 == *a1)
  {
    uint64_t v7 = a1[2];
    uint64_t v6 = a1[3];
    if (v7 >= v6)
    {
      uint64_t v13 = v6 - v4;
      BOOL v12 = v13 == 0;
      unint64_t v14 = v13 >> 2;
      if (v12) {
        unint64_t v14 = 1;
      }
      if (v14 >> 61) {
        std::__throw_bad_array_new_length[abi:nn180100]();
      }
      unint64_t v15 = (v14 + 3) >> 2;
      uint64_t v16 = 8 * v14;
      uint64_t v17 = (char *)operator new(8 * v14);
      uint64_t v5 = &v17[8 * v15];
      uint64_t v18 = v5;
      uint64_t v19 = v7 - v4;
      if (v7 != v4)
      {
        uint64_t v18 = &v5[v19 & 0xFFFFFFFFFFFFFFF8];
        unint64_t v20 = v19 - 8;
        unint64_t v21 = &v17[8 * v15];
        uint64_t v22 = v4;
        if (v20 < 0x38) {
          goto LABEL_27;
        }
        uint64_t v23 = &v17[8 * v15];
        unint64_t v21 = v23;
        uint64_t v22 = v4;
        if ((unint64_t)(v23 - v4) < 0x20) {
          goto LABEL_27;
        }
        uint64_t v24 = (v20 >> 3) + 1;
        uint64_t v25 = 8 * (v24 & 0x3FFFFFFFFFFFFFFCLL);
        unint64_t v21 = &v5[v25];
        uint64_t v22 = &v4[v25];
        unint64_t v26 = (long long *)(v4 + 16);
        uint64_t v27 = v23 + 16;
        uint64_t v28 = v24 & 0x3FFFFFFFFFFFFFFCLL;
        do
        {
          long long v29 = *v26;
          *(v27 - 1) = *(v26 - 1);
          *uint64_t v27 = v29;
          v26 += 2;
          v27 += 2;
          v28 -= 4;
        }
        while (v28);
        if (v24 != (v24 & 0x3FFFFFFFFFFFFFFCLL))
        {
LABEL_27:
          do
          {
            uint64_t v30 = *(void *)v22;
            v22 += 8;
            *(void *)unint64_t v21 = v30;
            v21 += 8;
          }
          while (v21 != v18);
        }
      }
      *a1 = v17;
      a1[1] = v5;
      a1[2] = v18;
      a1[3] = &v17[v16];
      if (v4)
      {
        operator delete(v4);
        uint64_t v5 = (char *)a1[1];
      }
    }
    else
    {
      uint64_t v8 = (v6 - v7) >> 3;
      if (v8 >= -1) {
        uint64_t v9 = v8 + 1;
      }
      else {
        uint64_t v9 = v8 + 2;
      }
      uint64_t v10 = v9 >> 1;
      uint64_t v11 = &v7[8 * (v9 >> 1)];
      uint64_t v5 = &v11[-(v7 - v4)];
      if (v7 != v4)
      {
        memmove(&v11[-(v7 - v4)], v4, v7 - v4);
        unint64_t v4 = (char *)a1[2];
      }
      a1[1] = v5;
      a1[2] = &v4[8 * v10];
    }
  }
  else
  {
    uint64_t v5 = (char *)a1[1];
  }
  *((void *)v5 - 1) = *a2;
  a1[1] = (char *)a1[1] - 8;
}

void *llvm::DenseMapBase<llvm::DenseMap<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>,void>,llvm::detail::DenseSetPair<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>>>,std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>,void>,llvm::detail::DenseSetPair<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>>>::try_emplace<llvm::detail::DenseSetEmpty&>@<X0>(uint64_t a1@<X0>, uint64_t *a2@<X1>, uint64_t a3@<X8>)
{
  unsigned int v6 = *(_DWORD *)(a1 + 16);
  if (v6)
  {
    uint64_t v7 = *(void *)a1;
    uint64_t v8 = *a2;
    uint64_t v9 = a2[1];
    unint64_t v10 = ((0x2500000000 * *a2) | (v9 >> 4) ^ (v9 >> 9))
        + ~((unint64_t)((v9 >> 4) ^ (v9 >> 9)) << 32);
    unint64_t v11 = (v10 ^ (v10 >> 22)) + ~((v10 ^ (v10 >> 22)) << 13);
    unint64_t v12 = (9 * (v11 ^ (v11 >> 8))) ^ ((9 * (v11 ^ (v11 >> 8))) >> 15);
    unsigned int v13 = (v6 - 1) & (((v12 + ~(v12 << 27)) >> 31) ^ (v12 + ~(v12 << 27)));
    __n128 result = (void *)(*(void *)a1 + 16 * v13);
    uint64_t v15 = *result;
    uint64_t v16 = result[1];
    if (*a2 == *result && v9 == v16)
    {
LABEL_7:
      *(void *)a3 = result;
      *(void *)(a3 + 8) = v7 + 16 * v6;
      *(unsigned char *)(a3 + 16) = 0;
      return result;
    }
    unint64_t v20 = 0;
    int v21 = 1;
    while (v15 != -4096 || v16 != -4096)
    {
      if (v20) {
        BOOL v22 = 0;
      }
      else {
        BOOL v22 = v16 == -8192;
      }
      if (v22 && v15 == -8192) {
        unint64_t v20 = result;
      }
      unsigned int v24 = v13 + v21++;
      unsigned int v13 = v24 & (v6 - 1);
      __n128 result = (void *)(v7 + 16 * v13);
      uint64_t v15 = *result;
      uint64_t v16 = result[1];
      if (v8 == *result && v9 == v16) {
        goto LABEL_7;
      }
    }
    if (v20) {
      uint64_t v18 = v20;
    }
    else {
      uint64_t v18 = result;
    }
  }
  else
  {
    uint64_t v18 = 0;
  }
  __n128 result = llvm::DenseMapBase<llvm::DenseMap<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>,void>,llvm::detail::DenseSetPair<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>>>,std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>,void>,llvm::detail::DenseSetPair<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>>>::InsertIntoBucket<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *> const&,llvm::detail::DenseSetEmpty&>(a1, v18, a2);
  uint64_t v19 = *(void *)a1 + 16 * *(unsigned int *)(a1 + 16);
  *(void *)a3 = result;
  *(void *)(a3 + 8) = v19;
  *(unsigned char *)(a3 + 16) = 1;
  return result;
}

void *llvm::DenseMapBase<llvm::DenseMap<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>,void>,llvm::detail::DenseSetPair<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>>>,std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>,void>,llvm::detail::DenseSetPair<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>>>::InsertIntoBucket<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *> const&,llvm::detail::DenseSetEmpty&>(uint64_t a1, void *a2, void *a3)
{
  int v6 = *(_DWORD *)(a1 + 8);
  unsigned int v7 = *(_DWORD *)(a1 + 16);
  if (4 * v6 + 4 >= 3 * v7)
  {
    v7 *= 2;
  }
  else if (v7 + ~v6 - *(_DWORD *)(a1 + 12) > v7 >> 3)
  {
    goto LABEL_3;
  }
  llvm::DenseMap<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>,void>,llvm::detail::DenseSetPair<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>>>::grow(a1, v7);
  int v9 = *(_DWORD *)(a1 + 16);
  if (v9)
  {
    uint64_t v10 = a3[1];
    unint64_t v11 = ((0x2500000000 * *a3) | (v10 >> 4) ^ (v10 >> 9))
        + ~((unint64_t)((v10 >> 4) ^ (v10 >> 9)) << 32);
    unint64_t v12 = (v11 ^ (v11 >> 22)) + ~((v11 ^ (v11 >> 22)) << 13);
    unint64_t v13 = (9 * (v12 ^ (v12 >> 8))) ^ ((9 * (v12 ^ (v12 >> 8))) >> 15);
    int v14 = ((v13 + ~(v13 << 27)) >> 31) ^ (v13 + ~(v13 << 27));
    int v15 = v9 - 1;
    unsigned int v16 = (v9 - 1) & v14;
    a2 = (void *)(*(void *)a1 + 16 * v16);
    uint64_t v17 = *a2;
    uint64_t v18 = a2[1];
    if (*a3 != *a2 || v10 != v18)
    {
      unint64_t v20 = 0;
      int v21 = 1;
      while (v17 != -4096 || v18 != -4096)
      {
        if (v20) {
          BOOL v22 = 0;
        }
        else {
          BOOL v22 = v18 == -8192;
        }
        if (v22 && v17 == -8192) {
          unint64_t v20 = a2;
        }
        unsigned int v24 = v16 + v21++;
        unsigned int v16 = v24 & v15;
        a2 = (void *)(*(void *)a1 + 16 * (v24 & v15));
        uint64_t v17 = *a2;
        uint64_t v18 = a2[1];
        if (*a3 == *a2 && v10 == v18) {
          goto LABEL_3;
        }
      }
      if (v20) {
        a2 = v20;
      }
    }
  }
  else
  {
    a2 = 0;
  }
LABEL_3:
  ++*(_DWORD *)(a1 + 8);
  if (*a2 != -4096 || a2[1] != -4096) {
    --*(_DWORD *)(a1 + 12);
  }
  *a2 = *a3;
  a2[1] = a3[1];
  return a2;
}

void llvm::DenseMap<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>,void>,llvm::detail::DenseSetPair<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>>>::grow(uint64_t a1, int a2)
{
  uint64_t v3 = *(unsigned int *)(a1 + 16);
  unint64_t v4 = *(uint64_t **)a1;
  unint64_t v5 = (a2 - 1) | ((unint64_t)(a2 - 1) >> 1);
  unint64_t v6 = v5 | (v5 >> 2) | ((v5 | (v5 >> 2)) >> 4);
  int v7 = ((v6 | (v6 >> 8)) >> 16) | v6 | (v6 >> 8);
  if ((v7 + 1) > 0x40) {
    unsigned int v8 = v7 + 1;
  }
  else {
    unsigned int v8 = 64;
  }
  *(_DWORD *)(a1 + 16) = v8;
  buffer = llvm::allocate_buffer(16 * v8, (std::align_val_t)8uLL);
  *(void *)a1 = buffer;
  if (v4)
  {
    uint64_t v10 = (char *)(16 * v3);
    llvm::DenseMapBase<llvm::DenseMap<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>,void>,llvm::detail::DenseSetPair<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>>>,std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>,void>,llvm::detail::DenseSetPair<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>>>::moveFromOldBuckets(a1, v4, (uint64_t *)&v10[(void)v4]);
    llvm::deallocate_buffer((llvm *)v4, v10);
  }
  *(void *)(a1 + 8) = 0;
  uint64_t v11 = *(unsigned int *)(a1 + 16);
  if (v11)
  {
    memset_pattern16(buffer, &unk_211F093D0, 16 * v11);
  }
}

void llvm::DenseMapBase<llvm::DenseMap<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>,void>,llvm::detail::DenseSetPair<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>>>,std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>,void>,llvm::detail::DenseSetPair<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>>>::moveFromOldBuckets(uint64_t a1, uint64_t *a2, uint64_t *a3)
{
  *(void *)(a1 + 8) = 0;
  uint64_t v6 = *(unsigned int *)(a1 + 16);
  if (v6) {
    memset_pattern16(*(void **)a1, &unk_211F093D0, 16 * v6);
  }
  for (; a2 != a3; a2 += 2)
  {
    uint64_t v17 = *a2;
    uint64_t v18 = a2[1];
    if ((*a2 != -4096 || v18 != -4096) && (v17 != -8192 || v18 != -8192))
    {
      unint64_t v7 = ((0x2500000000 * v17) | (v18 >> 4) ^ (v18 >> 9))
         + ~((unint64_t)((v18 >> 4) ^ (v18 >> 9)) << 32);
      unint64_t v8 = (v7 ^ (v7 >> 22)) + ~((v7 ^ (v7 >> 22)) << 13);
      unint64_t v9 = (9 * (v8 ^ (v8 >> 8))) ^ ((9 * (v8 ^ (v8 >> 8))) >> 15);
      int v10 = ((v9 + ~(v9 << 27)) >> 31) ^ (v9 + ~(v9 << 27));
      int v11 = *(_DWORD *)(a1 + 16) - 1;
      unsigned int v12 = v11 & v10;
      unint64_t v13 = (void *)(*(void *)a1 + 16 * v12);
      uint64_t v14 = *v13;
      uint64_t v15 = v13[1];
      if (v17 != *v13 || v18 != v15)
      {
        uint64_t v19 = 0;
        int v20 = 1;
        while (v14 != -4096 || v15 != -4096)
        {
          if (v19) {
            BOOL v21 = 0;
          }
          else {
            BOOL v21 = v15 == -8192;
          }
          if (v21 && v14 == -8192) {
            uint64_t v19 = v13;
          }
          unsigned int v23 = v12 + v20++;
          unsigned int v12 = v23 & v11;
          unint64_t v13 = (void *)(*(void *)a1 + 16 * (v23 & v11));
          uint64_t v14 = *v13;
          uint64_t v15 = v13[1];
          if (v17 == *v13 && v18 == v15) {
            goto LABEL_10;
          }
        }
        if (v19) {
          unint64_t v13 = v19;
        }
      }
LABEL_10:
      *unint64_t v13 = v17;
      v13[1] = a2[1];
      ++*(_DWORD *)(a1 + 8);
    }
  }
}

void mlir::Liveness::build(mlir::ForwardIterator **this)
{
  uint64_t v70 = 0;
  uint64_t v71 = 0;
  unsigned int v72 = 0;
  uint64_t v1 = *this;
  uint64_t v73 = 0;
  int32x2_t v74 = 0;
  unsigned int v75 = 0;
  char v76 = &v78;
  uint64_t v77 = 0;
  uint64_t v78 = &v70;
  uint64_t v79 = &v73;
  unsigned int v2 = v77;
  if (!v77)
  {
LABEL_133:
    if (v76 != &v78) {
      free(v76);
    }
    llvm::deallocate_buffer(v73, (void *)(8 * v75));
  }
  while (1)
  {
    uint64_t v3 = (void **)*((void *)v76 + v2 - 1);
    unsigned int v4 = v3 >> 4;
    if (v75)
    {
      LODWORD(v5) = (v4 ^ (v3 >> 9)) & (v75 - 1);
      uint64_t v6 = (char *)v73 + 8 * v5;
      unint64_t v7 = *(void ***)v6;
      if (v3 != *(void ***)v6)
      {
        int v62 = 1;
        do
        {
          if (v7 == (void **)-4096) {
            goto LABEL_7;
          }
          int v63 = v5 + v62++;
          uint64_t v5 = v63 & (v75 - 1);
          unint64_t v7 = (void **)*((void *)v73 + v5);
        }
        while (v3 != v7);
        uint64_t v6 = (char *)v73 + 8 * v5;
      }
      *(void *)uint64_t v6 = -8192;
      int32x2_t v74 = vadd_s32(v74, (int32x2_t)0x1FFFFFFFFLL);
    }
LABEL_7:
    LODWORD(v77) = v2 - 1;
    int v8 = v72;
    if (!v72) {
      goto LABEL_117;
    }
    unsigned int v9 = (v72 - 1) & (v4 ^ (v3 >> 9));
    int v10 = (char *)v70 + 656 * v9;
    uint64_t v11 = *(void *)v10;
    if (*(void ***)v10 == v3) {
      goto LABEL_23;
    }
    unsigned int v12 = 0;
    int v13 = 1;
    while (v11 != -4096)
    {
      if (v12) {
        BOOL v14 = 0;
      }
      else {
        BOOL v14 = v11 == -8192;
      }
      if (v14) {
        unsigned int v12 = v10;
      }
      unsigned int v15 = v9 + v13++;
      unsigned int v9 = v15 & (v72 - 1);
      int v10 = (char *)v70 + 656 * v9;
      uint64_t v11 = *(void *)v10;
      if (*(void ***)v10 == v3) {
        goto LABEL_23;
      }
    }
    if (v12) {
      int v10 = v12;
    }
    if (4 * (int)v71 + 4 < 3 * v72)
    {
      if (v72 + ~v71 - HIDWORD(v71) > v72 >> 3) {
        goto LABEL_20;
      }
    }
    else
    {
LABEL_117:
      int v8 = 2 * v72;
    }
    unsigned int v64 = (v72 - 1) & (v4 ^ (v3 >> 9));
    int v10 = (char *)v70 + 656 * v64;
    uint64_t v65 = *(void *)v10;
    if (*(void ***)v10 == v3)
    {
LABEL_119:
      LODWORD(v71) = v71 + 1;
      if (v3 == (void **)-4096) {
        goto LABEL_22;
      }
LABEL_21:
      --HIDWORD(v71);
      goto LABEL_22;
    }
    unint64_t v66 = 0;
    int v67 = 1;
    while (v65 != -4096)
    {
      if (v66) {
        BOOL v68 = 0;
      }
      else {
        BOOL v68 = v65 == -8192;
      }
      if (v68) {
        unint64_t v66 = v10;
      }
      unsigned int v69 = v64 + v67++;
      unsigned int v64 = v69 & (v72 - 1);
      int v10 = (char *)v70 + 656 * v64;
      uint64_t v65 = *(void *)v10;
      if (*(void ***)v10 == v3) {
        goto LABEL_119;
      }
    }
    if (v66) {
      int v10 = v66;
    }
LABEL_20:
    uint64_t v16 = *(void *)v10;
    LODWORD(v71) = v71 + 1;
    if (v16 != -4096) {
      goto LABEL_21;
    }
LABEL_22:
    *(void *)int v10 = v3;
    bzero(v10 + 8, 0x288uLL);
    *((void *)v10 + 2) = v10 + 48;
    *((void *)v10 + 3) = v10 + 48;
    *((_DWORD *)v10 + 8) = 16;
    *((void *)v10 + 22) = v10 + 208;
    *((void *)v10 + 23) = v10 + 208;
    *((_DWORD *)v10 + 48) = 16;
    *((void *)v10 + 42) = v10 + 368;
    *((void *)v10 + 43) = v10 + 368;
    *((_DWORD *)v10 + 88) = 16;
    *((void *)v10 + 62) = v10 + 528;
    *((void *)v10 + 63) = v10 + 528;
    *((_DWORD *)v10 + 128) = 16;
LABEL_23:
    mlir::SuccessorRange::SuccessorRange((mlir::SuccessorRange *)&v78, *((mlir::Block **)v10 + 1));
    uint64_t v17 = v79;
    if (v79)
    {
      uint64_t v18 = 0;
      uint64_t v19 = v78;
      do
      {
        if (v72)
        {
          int v20 = v19[4 * (void)v18 + 3];
          unsigned int v21 = ((v20 >> 4) ^ (v20 >> 9)) & (v72 - 1);
          BOOL v22 = (void *)((char *)v70 + 656 * v21);
          unsigned int v23 = (llvm *)*v22;
          if ((llvm *)*v22 == v20) {
            goto LABEL_33;
          }
          int v24 = 1;
          while (v23 != (llvm *)-4096)
          {
            unsigned int v25 = v21 + v24++;
            unsigned int v21 = v25 & (v72 - 1);
            BOOL v22 = (void *)((char *)v70 + 656 * v21);
            unsigned int v23 = (llvm *)*v22;
            if ((llvm *)*v22 == v20) {
              goto LABEL_33;
            }
          }
        }
        BOOL v22 = (void *)((char *)v70 + 656 * v72);
LABEL_33:
        uint64_t v26 = v22[3];
        if (v26 == v22[2]) {
          uint64_t v27 = (unsigned int *)v22 + 9;
        }
        else {
          uint64_t v27 = (unsigned int *)(v22 + 4);
        }
        uint64_t v28 = *v27;
        if (v28)
        {
          uint64_t v29 = 8 * v28;
          uint64_t v30 = (const void **)v22[3];
          while ((unint64_t)*v30 >= 0xFFFFFFFFFFFFFFFELL)
          {
            ++v30;
            v29 -= 8;
            if (!v29) {
              goto LABEL_25;
            }
          }
        }
        else
        {
          uint64_t v30 = (const void **)v22[3];
        }
        uint64_t v31 = (const void **)(v26 + 8 * v28);
        if (v30 != v31)
        {
          uint64_t v32 = (void *)*((void *)v10 + 22);
          long long v33 = (void *)*((void *)v10 + 23);
          unint64_t v34 = *v30;
          while (v33 == v32)
          {
            uint64_t v35 = *((unsigned int *)v10 + 49);
            if (!v35) {
              goto LABEL_61;
            }
            uint64_t v36 = 0;
            uint64_t v37 = 8 * v35;
            uint64_t v38 = v32;
            do
            {
              if ((const void *)*v38 == v34) {
                goto LABEL_46;
              }
              if (*v38 == -2) {
                uint64_t v36 = v38;
              }
              ++v38;
              v37 -= 8;
            }
            while (v37);
            if (v36)
            {
              void *v36 = v34;
              --*((_DWORD *)v10 + 50);
            }
            else
            {
LABEL_61:
              if (v35 >= *((_DWORD *)v10 + 48)) {
                break;
              }
              *((_DWORD *)v10 + 49) = v35 + 1;
              v32[v35] = v34;
            }
LABEL_46:
            if (++v30 != v31)
            {
              uint64_t v32 = (void *)*((void *)v10 + 22);
              long long v33 = (void *)*((void *)v10 + 23);
              while (1)
              {
                unint64_t v34 = *v30;
                if ((unint64_t)*v30 < 0xFFFFFFFFFFFFFFFELL) {
                  break;
                }
                if (++v30 == v31) {
                  goto LABEL_25;
                }
              }
              if (v30 != v31) {
                continue;
              }
            }
            goto LABEL_25;
          }
          llvm::SmallPtrSetImplBase::insert_imp_big((llvm::SmallPtrSetImplBase *)(v10 + 176), v34);
          goto LABEL_46;
        }
LABEL_25:
        uint64_t v18 = (llvm **)((char *)v18 + 1);
      }
      while (v18 != v17);
    }
    llvm::SmallPtrSetImplBase::SmallPtrSetImplBase((llvm::SmallPtrSetImplBase *)&v78, &v82, (const llvm::SmallPtrSetImplBase *)(v10 + 496));
    llvm::set_union<llvm::SmallPtrSet<mlir::Value,16u>,llvm::SmallPtrSet<mlir::Value,16u>>((llvm::SmallPtrSetImplBase *)&v78, (void *)v10 + 22);
    llvm::set_subtract<llvm::SmallPtrSet<mlir::Value,16u>,llvm::SmallPtrSet<mlir::Value,16u>>((const void **)&v78, (void *)v10 + 42);
    int v39 = v80 - v81;
    int v40 = *((_DWORD *)v10 + 9) - *((_DWORD *)v10 + 10);
    if (&v78 != (llvm ***)(v10 + 16) && v39 != v40) {
      llvm::SmallPtrSetImplBase::MoveFrom((uint64_t)(v10 + 16), 16, (double *)&v78);
    }
    if (v79 != v78) {
      free(v79);
    }
    if (v39 != v40)
    {
      int64_t v41 = *v3;
      if (*v3)
      {
        while (1)
        {
          uint64_t v45 = mlir::PredecessorIterator::unwrap((uint64_t)v41);
          uint64_t v46 = v45;
          int v47 = v75;
          if (!v75) {
            goto LABEL_94;
          }
          unsigned int v42 = ((v45 >> 4) ^ (v45 >> 9)) & (v75 - 1);
          unint64_t v43 = (char *)v73 + 8 * v42;
          uint64_t v44 = *(void *)v43;
          if (v45 != *(void *)v43) {
            break;
          }
LABEL_72:
          int64_t v41 = (void *)*v41;
          if (!v41) {
            goto LABEL_3;
          }
        }
        uint64_t v50 = 0;
        int v51 = 1;
        while (v44 != -4096)
        {
          if (v50) {
            BOOL v52 = 0;
          }
          else {
            BOOL v52 = v44 == -8192;
          }
          if (v52) {
            uint64_t v50 = v43;
          }
          unsigned int v53 = v42 + v51++;
          unsigned int v42 = v53 & (v75 - 1);
          unint64_t v43 = (char *)v73 + 8 * v42;
          uint64_t v44 = *(void *)v43;
          if (v45 == *(void *)v43) {
            goto LABEL_72;
          }
        }
        if (v50) {
          uint64_t v54 = v50;
        }
        else {
          uint64_t v54 = v43;
        }
        if (4 * v74.i32[0] + 4 < 3 * v75)
        {
          if (v75 + ~v74.i32[0] - v74.i32[1] <= v75 >> 3) {
            goto LABEL_95;
          }
        }
        else
        {
LABEL_94:
          int v47 = 2 * v75;
LABEL_95:
          llvm::DenseMap<mlir::Block *,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::Block *,void>,llvm::detail::DenseSetPair<mlir::Block *>>::grow((uint64_t)&v73, v47);
          unsigned int v55 = v75 - 1;
          unsigned int v56 = (v75 - 1) & ((v46 >> 4) ^ (v46 >> 9));
          uint64_t v54 = (char *)v73 + 8 * v56;
          uint64_t v57 = *(void *)v54;
          if (v46 == *(void *)v54)
          {
LABEL_96:
            ++v74.i32[0];
            if (v46 == -4096) {
              goto LABEL_78;
            }
LABEL_77:
            --v74.i32[1];
LABEL_78:
            *(void *)uint64_t v54 = v46;
            uint64_t v49 = v77;
            if (v77 >= (unint64_t)HIDWORD(v77))
            {
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v76, &v78, v77 + 1, 8);
              uint64_t v49 = v77;
            }
            *((void *)v76 + v49) = v46;
            LODWORD(v77) = v77 + 1;
            goto LABEL_72;
          }
          unint64_t v58 = 0;
          int v59 = 1;
          while (v57 != -4096)
          {
            if (v58) {
              BOOL v60 = 0;
            }
            else {
              BOOL v60 = v57 == -8192;
            }
            if (v60) {
              unint64_t v58 = v54;
            }
            unsigned int v61 = v56 + v59++;
            unsigned int v56 = v61 & v55;
            uint64_t v54 = (char *)v73 + 8 * (v61 & v55);
            uint64_t v57 = *(void *)v54;
            if (v46 == *(void *)v54) {
              goto LABEL_96;
            }
          }
          if (v58) {
            uint64_t v54 = v58;
          }
        }
        uint64_t v48 = *(void *)v54;
        ++v74.i32[0];
        if (v48 != -4096) {
          goto LABEL_77;
        }
        goto LABEL_78;
      }
    }
LABEL_3:
    unsigned int v2 = v77;
    if (!v77) {
      goto LABEL_133;
    }
  }
}

void mlir::Liveness::Liveness(mlir::Liveness *this, mlir::Operation *a2)
{
  *((void *)this + 1) = 0;
  *((void *)this + 2) = 0;
  *(void *)this = a2;
  *((_DWORD *)this + 6) = 0;
  mlir::Liveness::build((mlir::ForwardIterator **)this);
}

uint64_t sub_2113C5510()
{
  return v0;
}

uint64_t *mlir::Liveness::getLiveness(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = *(void *)(a1 + 8);
  unsigned int v3 = *(_DWORD *)(a1 + 24);
  if (!v3) {
    return 0;
  }
  unsigned int v4 = (v3 - 1) & ((a2 >> 4) ^ (a2 >> 9));
  uint64_t v5 = (uint64_t *)(v2 + 336 * v4);
  uint64_t v6 = *v5;
  if (*v5 != a2)
  {
    int v8 = 1;
    while (v6 != -4096)
    {
      unsigned int v9 = v4 + v8++;
      unsigned int v4 = v9 & (v3 - 1);
      uint64_t v5 = (uint64_t *)(v2 + 336 * v4);
      uint64_t v6 = *v5;
      if (*v5 == a2) {
        goto LABEL_3;
      }
    }
    return 0;
  }
LABEL_3:
  if (v5 == (uint64_t *)(v2 + 336 * v3)) {
    return 0;
  }
  else {
    return v5 + 1;
  }
}

void mlir::LivenessBlockInfo::getEndOperation(uint64_t a1, uint64_t **a2, mlir::Block **a3)
{
  uint64_t v8 = *(void *)(a1 + 168);
  uint64_t v7 = *(void *)(a1 + 176);
  uint64_t v6 = (llvm::SmallPtrSetImplBase *)(a1 + 168);
  if (v7 == v8)
  {
    uint64_t v12 = *(unsigned int *)(a1 + 188);
    BucketFor = (const void **)(v7 + 8 * v12);
    if (v12)
    {
      uint64_t v13 = 0;
      uint64_t v14 = 8 * v12;
      while (*(uint64_t ***)(v7 + v13) != a2)
      {
        v13 += 8;
        if (v14 == v13) {
          goto LABEL_12;
        }
      }
      BucketFor = (const void **)(v7 + v13);
    }
LABEL_12:
    uint64_t v10 = v7;
  }
  else
  {
    BucketFor = llvm::SmallPtrSetImplBase::FindBucketFor(v6, a2);
    uint64_t v7 = *(void *)(a1 + 168);
    uint64_t v10 = *(void *)(a1 + 176);
    if (*BucketFor != a2)
    {
      uint64_t v11 = 184;
      if (v10 == v7) {
        uint64_t v11 = 188;
      }
      BucketFor = (const void **)(v10 + 8 * *(unsigned int *)(a1 + v11));
    }
  }
  BOOL v15 = v10 == v7;
  uint64_t v16 = 184;
  if (v15) {
    uint64_t v16 = 188;
  }
  if (BucketFor == (const void **)(v10 + 8 * *(unsigned int *)(a1 + v16)))
  {
    uint64_t v18 = (uint64_t **)*a2;
    if (*a2)
    {
      do
      {
        AncestorOpInBlocuint64_t k = mlir::Block::findAncestorOpInBlock(*(mlir::Block **)a1, (Operation *)v18[2]);
        if (AncestorOpInBlock)
        {
          int v20 = (mlir::Block **)AncestorOpInBlock;
          if (mlir::Operation::isBeforeInBlock(a3, AncestorOpInBlock)) {
            a3 = v20;
          }
        }
        uint64_t v18 = (uint64_t **)*v18;
      }
      while (v18);
    }
  }
  else
  {
    uint64_t v17 = *(ZinIrHalH13g **)(*(void *)a1 + 32);
    ZinIrHalH13g::~ZinIrHalH13g(v17);
  }
}

BOOL mlir::Liveness::isDeadAfter(uint64_t a1, void *a2, uint64_t a3)
{
  uint64_t v5 = *(void *)(a1 + 8);
  unsigned int v6 = *(_DWORD *)(a1 + 24);
  if (v6)
  {
    uint64_t v7 = *(void *)(a3 + 16);
    unsigned int v8 = ((v7 >> 4) ^ (v7 >> 9)) & (v6 - 1);
    unsigned int v9 = (uint64_t *)(v5 + 336 * v8);
    uint64_t v10 = *v9;
    if (*v9 == v7) {
      goto LABEL_8;
    }
    int v11 = 1;
    while (v10 != -4096)
    {
      unsigned int v12 = v8 + v11++;
      unsigned int v8 = v12 & (v6 - 1);
      unsigned int v9 = (uint64_t *)(v5 + 336 * v8);
      uint64_t v10 = *v9;
      if (*v9 == v7) {
        goto LABEL_8;
      }
    }
  }
  unsigned int v9 = (uint64_t *)(v5 + 336 * v6);
LABEL_8:
  if (v9 == (uint64_t *)(v5 + 336 * v6)) {
    uint64_t v13 = 0;
  }
  else {
    uint64_t v13 = (uint64_t)(v9 + 1);
  }
  uint64_t v14 = *(void *)(v13 + 176);
  if (v14 == *(void *)(v13 + 168))
  {
    uint64_t v18 = *(unsigned int *)(v13 + 188);
    BucketFor = (const void **)(v14 + 8 * v18);
    if (v18)
    {
      uint64_t v19 = 0;
      uint64_t v20 = 8 * v18;
      while (*(void **)(v14 + v19) != a2)
      {
        v19 += 8;
        if (v20 == v19) {
          goto LABEL_22;
        }
      }
      BucketFor = (const void **)(v14 + v19);
    }
LABEL_22:
    uint64_t v16 = *(void *)(v13 + 176);
  }
  else
  {
    BucketFor = llvm::SmallPtrSetImplBase::FindBucketFor((llvm::SmallPtrSetImplBase *)(v13 + 168), a2);
    uint64_t v14 = *(void *)(v13 + 168);
    uint64_t v16 = *(void *)(v13 + 176);
    if (*BucketFor != a2)
    {
      uint64_t v17 = 184;
      if (v16 == v14) {
        uint64_t v17 = 188;
      }
      BucketFor = (const void **)(v16 + 8 * *(unsigned int *)(v13 + v17));
    }
  }
  BOOL v21 = v16 == v14;
  uint64_t v22 = 184;
  if (v21) {
    uint64_t v22 = 188;
  }
  if (BucketFor != (const void **)(v16 + 8 * *(unsigned int *)(v13 + v22))) {
    return 0;
  }
  mlir::LivenessBlockInfo::getEndOperation(v13, (uint64_t **)a2, (mlir::Block **)a3);
  if (v24 == (mlir::Block **)a3) {
    return 1;
  }

  return mlir::Operation::isBeforeInBlock(v24, (mlir::Operation *)a3);
}

uint64_t mlir::detail::walk<mlir::ForwardIterator>(mlir::ForwardIterator *a1, mlir::Operation *a2, uint64_t a3, int a4)
{
  uint64_t result = mlir::ForwardIterator::makeIterable(a1, a2);
  if (v8)
  {
    uint64_t v9 = result;
    uint64_t v10 = result + 24 * v8;
    if (a4)
    {
      if (a4 == 1)
      {
        do
        {
          uint64_t v16 = *(void *)(v9 + 8);
          if (v16 != v9)
          {
            do
            {
              uint64_t v17 = *(void *)(v16 + 8);
              if (v16) {
                uint64_t v18 = v16 - 8;
              }
              else {
                uint64_t v18 = 0;
              }
              for (uint64_t i = *(ZinIrHalH13g **)(v18 + 40);
                    i != (ZinIrHalH13g *)(v18 + 32);
                    uint64_t i = (ZinIrHalH13g *)*((void *)i + 1))
              {
                ZinIrHalH13g::~ZinIrHalH13g(i);
                mlir::detail::walk<mlir::ForwardIterator>();
              }
              uint64_t result = ((uint64_t (*)(uint64_t, uint64_t))a2)(a3, v18);
              uint64_t v16 = v17;
            }
            while (v17 != v9);
          }
          v9 += 24;
        }
        while (v9 != v10);
      }
      else
      {
        do
        {
          uint64_t v20 = *(void *)(v9 + 8);
          if (v20 != v9)
          {
            do
            {
              uint64_t v21 = *(void *)(v20 + 8);
              if (v20) {
                uint64_t v22 = v20 - 8;
              }
              else {
                uint64_t v22 = 0;
              }
              unsigned int v23 = (ZinIrHalH13g *)(v22 + 32);
              int v24 = *(ZinIrHalH13g **)(v22 + 40);
              if (v24 != (ZinIrHalH13g *)(v22 + 32))
              {
                do
                {
                  ZinIrHalH13g::~ZinIrHalH13g(v24);
                  uint64_t result = mlir::detail::walk<mlir::ForwardIterator>();
                  int v24 = (ZinIrHalH13g *)*((void *)v24 + 1);
                }
                while (v24 != v23);
              }
              uint64_t v20 = v21;
            }
            while (v21 != v9);
          }
          v9 += 24;
        }
        while (v9 != v10);
      }
    }
    else
    {
      do
      {
        uint64_t v11 = *(void *)(v9 + 8);
        if (v11 != v9)
        {
          do
          {
            uint64_t v12 = *(void *)(v11 + 8);
            if (v11) {
              uint64_t v13 = v11 - 8;
            }
            else {
              uint64_t v13 = 0;
            }
            uint64_t result = ((uint64_t (*)(uint64_t, uint64_t))a2)(a3, v13);
            uint64_t v14 = (ZinIrHalH13g *)(v13 + 32);
            for (uint64_t j = *(ZinIrHalH13g **)(v13 + 40); j != v14; uint64_t j = (ZinIrHalH13g *)*((void *)j + 1))
            {
              ZinIrHalH13g::~ZinIrHalH13g(j);
              uint64_t result = mlir::detail::walk<mlir::ForwardIterator>();
            }
            uint64_t v11 = v12;
          }
          while (v12 != v9);
        }
        v9 += 24;
      }
      while (v9 != v10);
    }
  }
  return result;
}

{
  uint64_t Iterable;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t i;
  uint64_t v12;
  ZinIrHalH13g *v13;
  ZinIrHalH13g *v14;
  ZinIrHalH13g *v15;
  int v16;
  uint64_t result;
  uint64_t vars8;

  if (!a4)
  {
    uint64_t result = ((uint64_t (*)(uint64_t, mlir::ForwardIterator *))a2)(a3, a1);
    if (!result) {
      return result;
    }
    if (result == 2) {
      return 1;
    }
  }
  Iterable = mlir::ForwardIterator::makeIterable(a1, a2);
  if (v8)
  {
    uint64_t v9 = Iterable;
    uint64_t v10 = Iterable + 24 * v8;
    do
    {
      for (uint64_t i = *(void *)(v9 + 8); i != v9; uint64_t i = *(void *)(i + 8))
      {
        uint64_t v12 = i - 8;
        if (!i) {
          uint64_t v12 = 0;
        }
        uint64_t v13 = (ZinIrHalH13g *)(v12 + 32);
        uint64_t v14 = *(ZinIrHalH13g **)(v12 + 40);
        while (v14 != v13)
        {
          BOOL v15 = (ZinIrHalH13g *)*((void *)v14 + 1);
          ZinIrHalH13g::~ZinIrHalH13g(v14);
          uint64_t v16 = mlir::detail::walk<mlir::ForwardIterator>();
          uint64_t v14 = v15;
          if (!v16) {
            return 0;
          }
        }
      }
      v9 += 24;
    }
    while (v9 != v10);
  }
  if (a4 != 1) {
    return 1;
  }

  return ((uint64_t (*)(uint64_t, mlir::ForwardIterator *))a2)(a3, a1);
}

{
  uint64_t Iterable;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  BOOL v13;
  uint64_t v14;
  uint64_t result;
  ZinIrHalH13g *v16;
  ZinIrHalH13g *v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  ZinIrHalH13g *v21;
  ZinIrHalH13g *v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  ZinIrHalH13g *v26;

  Iterable = mlir::ForwardIterator::makeIterable(a1, a2);
  if (!v8) {
    return 1;
  }
  uint64_t v9 = Iterable;
  uint64_t v10 = Iterable + 24 * v8;
  if (a4 == 1)
  {
    while (1)
    {
      unsigned int v23 = *(void *)(v9 + 8);
      if (v23 != v9) {
        break;
      }
LABEL_30:
      v9 += 24;
      uint64_t result = 1;
      if (v9 == v10) {
        return result;
      }
    }
    while (1)
    {
      int v24 = *(void *)(v23 + 8);
      unsigned int v25 = v23 ? v23 - 8 : 0;
      uint64_t v26 = *(ZinIrHalH13g **)(v25 + 40);
      if (v26 != (ZinIrHalH13g *)(v25 + 32)) {
        break;
      }
LABEL_38:
      uint64_t result = ((uint64_t (*)(uint64_t, uint64_t))a2)(a3, v25);
      if (!result) {
        return result;
      }
      unsigned int v23 = v24;
      if (v24 == v9) {
        goto LABEL_30;
      }
    }
    while (1)
    {
      ZinIrHalH13g::~ZinIrHalH13g(v26);
      uint64_t result = mlir::detail::walk<mlir::ForwardIterator>();
      if (!result) {
        break;
      }
      uint64_t v26 = (ZinIrHalH13g *)*((void *)v26 + 1);
      if (v26 == (ZinIrHalH13g *)(v25 + 32)) {
        goto LABEL_38;
      }
    }
  }
  else if (a4)
  {
    while (1)
    {
      uint64_t v18 = *(void *)(v9 + 8);
      if (v18 != v9) {
        break;
      }
LABEL_26:
      v9 += 24;
      uint64_t result = 1;
      if (v9 == v10) {
        return result;
      }
    }
    while (1)
    {
      uint64_t v19 = *(void *)(v18 + 8);
      uint64_t v20 = v18 ? v18 - 8 : 0;
      uint64_t v21 = (ZinIrHalH13g *)(v20 + 32);
      uint64_t v22 = *(ZinIrHalH13g **)(v20 + 40);
      if (v22 != (ZinIrHalH13g *)(v20 + 32)) {
        break;
      }
LABEL_17:
      uint64_t v18 = v19;
      if (v19 == v9) {
        goto LABEL_26;
      }
    }
    while (1)
    {
      ZinIrHalH13g::~ZinIrHalH13g(v22);
      uint64_t result = mlir::detail::walk<mlir::ForwardIterator>();
      if (!result) {
        break;
      }
      uint64_t v22 = (ZinIrHalH13g *)*((void *)v22 + 1);
      if (v22 == v21) {
        goto LABEL_17;
      }
    }
  }
  else
  {
    while (2)
    {
      uint64_t v11 = *(void *)(v9 + 8);
LABEL_5:
      while (v11 != v9)
      {
        uint64_t v12 = v11 - 8;
        uint64_t v13 = v11 == 0;
        uint64_t v11 = *(void *)(v11 + 8);
        if (v13) {
          uint64_t v14 = 0;
        }
        else {
          uint64_t v14 = v12;
        }
        uint64_t result = ((uint64_t (*)(uint64_t, uint64_t))a2)(a3, v14);
        if (result != 2)
        {
          if (!result) {
            return result;
          }
          uint64_t v16 = (ZinIrHalH13g *)(v14 + 32);
          uint64_t v17 = *(ZinIrHalH13g **)(v14 + 40);
          if (v17 != v16)
          {
            while (1)
            {
              ZinIrHalH13g::~ZinIrHalH13g(v17);
              uint64_t result = mlir::detail::walk<mlir::ForwardIterator>();
              if (!result) {
                return result;
              }
              uint64_t v17 = (ZinIrHalH13g *)*((void *)v17 + 1);
              if (v17 == v16) {
                goto LABEL_5;
              }
            }
          }
        }
      }
      v9 += 24;
      uint64_t result = 1;
      if (v9 != v10) {
        continue;
      }
      break;
    }
  }
  return result;
}

void llvm::function_ref<void ()(mlir::Block *)>::callback_fn<buildBlockMapping(mlir::Operation *,llvm::DenseMap<mlir::Block *,anonymous namespace'::BlockInfoBuilder,llvm::DenseMapInfo<mlir::Block *,void>,llvm::detail::DenseMapPair<mlir::Block *,anonymous namespace'::BlockInfoBuilder>> &)::$_0>(uint64_t *a1, mlir::Block *a2)
{
  unsigned int v3 = a1;
  uint64_t v4 = *a1;
  unsigned int v5 = *(_DWORD *)(*a1 + 16);
  if (!v5) {
    goto LABEL_91;
  }
  unsigned int v6 = (v5 - 1) & ((a2 >> 4) ^ (a2 >> 9));
  uint64_t v7 = *(void *)v4 + 656 * v6;
  uint64_t v8 = *(void *)v7;
  if (*(mlir::Block **)v7 == a2) {
    goto LABEL_72;
  }
  uint64_t v9 = 0;
  int v10 = 1;
  while (v8 != -4096)
  {
    if (v9) {
      BOOL v11 = 0;
    }
    else {
      BOOL v11 = v8 == -8192;
    }
    if (v11) {
      uint64_t v9 = v7;
    }
    unsigned int v12 = v6 + v10++;
    unsigned int v6 = v12 & (v5 - 1);
    uint64_t v7 = *(void *)v4 + 656 * v6;
    uint64_t v8 = *(void *)v7;
    if (*(mlir::Block **)v7 == a2) {
      goto LABEL_72;
    }
  }
  if (v9) {
    uint64_t v7 = v9;
  }
  int v54 = *(_DWORD *)(v4 + 8);
  if (4 * v54 + 4 < 3 * v5)
  {
    if (v5 + ~v54 - *(_DWORD *)(v4 + 12) > v5 >> 3) {
      goto LABEL_14;
    }
  }
  else
  {
LABEL_91:
    v5 *= 2;
  }
  int v55 = *(_DWORD *)(v4 + 16) - 1;
  unsigned int v56 = v55 & ((a2 >> 4) ^ (a2 >> 9));
  uint64_t v7 = *(void *)v4 + 656 * v56;
  uint64_t v57 = *(void *)v7;
  if (*(mlir::Block **)v7 != a2)
  {
    uint64_t v58 = 0;
    int v59 = 1;
    while (v57 != -4096)
    {
      if (v58) {
        BOOL v60 = 0;
      }
      else {
        BOOL v60 = v57 == -8192;
      }
      if (v60) {
        uint64_t v58 = v7;
      }
      unsigned int v61 = v56 + v59++;
      unsigned int v56 = v61 & v55;
      uint64_t v7 = *(void *)v4 + 656 * v56;
      uint64_t v57 = *(void *)v7;
      if (*(mlir::Block **)v7 == a2) {
        goto LABEL_93;
      }
    }
    if (v58) {
      uint64_t v7 = v58;
    }
LABEL_14:
    uint64_t v13 = *(void *)v7;
    ++*(_DWORD *)(v4 + 8);
    if (v13 == -4096) {
      goto LABEL_16;
    }
    goto LABEL_15;
  }
LABEL_93:
  ++*(_DWORD *)(v4 + 8);
  if (a2 != (mlir::Block *)-4096) {
LABEL_15:
  }
    --*(_DWORD *)(v4 + 12);
LABEL_16:
  *(void *)(v7 + 8) = a2;
  *(void *)uint64_t v7 = a2;
  *(void *)(v7 + 16) = v7 + 48;
  *(void *)(v7 + 24) = v7 + 48;
  *(void *)(v7 + 32) = 16;
  *(_DWORD *)(v7 + 4std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  *(void *)(v7 + 176) = v7 + 208;
  *(void *)(v7 + 184) = v7 + 208;
  *(void *)(v7 + 192) = 16;
  *(_DWORD *)(v7 + 20std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  *(void *)(v7 + 336) = v7 + 368;
  *(void *)(v7 + 344) = v7 + 368;
  *(void *)(v7 + 352) = 16;
  *(_DWORD *)(v7 + 36std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  int v63 = (llvm::SmallPtrSetImplBase *)(v7 + 336);
  *(void *)(v7 + 496) = v7 + 528;
  *(void *)(v7 + 504) = v7 + 528;
  *(void *)(v7 + 512) = 16;
  *(_DWORD *)(v7 + 52std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  uint64_t v14 = (const void **)*((void *)a2 + 6);
  BOOL v15 = (const void **)*((void *)a2 + 7);
  if (v15 != v14)
  {
    while (1)
    {
      uint64_t v30 = *v14;
      uint64_t v31 = *(void *)(v7 + 344);
      if (v31 != *(void *)(v7 + 336)) {
        goto LABEL_44;
      }
      uint64_t v40 = *(unsigned int *)(v7 + 356);
      if (!v40) {
        break;
      }
      int64_t v41 = 0;
      uint64_t v42 = 8 * v40;
      unint64_t v43 = *(void **)(v7 + 344);
      while ((void *)*v43 != v30)
      {
        if (*v43 == -2) {
          int64_t v41 = v43;
        }
        ++v43;
        v42 -= 8;
        if (!v42)
        {
          if (!v41) {
            goto LABEL_65;
          }
          void *v41 = v30;
          --*(_DWORD *)(v7 + 360);
          break;
        }
      }
LABEL_45:
      uint64_t v32 = v30;
      do
      {
        uint64_t v32 = (void *)*v32;
        if (!v32) {
          goto LABEL_42;
        }
        long long v33 = *(mlir::Block **)(v32[2] + 16);
        Parent = (mlir::Region *)mlir::Block::getParent(a2);
      }
      while (mlir::Region::findAncestorBlockInRegion(Parent, v33) == a2);
      uint64_t v35 = *(void *)(v7 + 184);
      if (v35 != *(void *)(v7 + 176))
      {
LABEL_41:
        llvm::SmallPtrSetImplBase::insert_imp_big((llvm::SmallPtrSetImplBase *)(v7 + 176), v30);
        goto LABEL_42;
      }
      uint64_t v36 = *(unsigned int *)(v7 + 196);
      if (v36)
      {
        uint64_t v37 = 0;
        uint64_t v38 = 8 * v36;
        int v39 = *(void **)(v7 + 184);
        while ((void *)*v39 != v30)
        {
          if (*v39 == -2) {
            uint64_t v37 = v39;
          }
          ++v39;
          v38 -= 8;
          if (!v38)
          {
            if (!v37) {
              goto LABEL_67;
            }
            void *v37 = v30;
            --*(_DWORD *)(v7 + 200);
            break;
          }
        }
      }
      else
      {
LABEL_67:
        if (v36 >= *(_DWORD *)(v7 + 192)) {
          goto LABEL_41;
        }
        *(_DWORD *)(v7 + 196) = v36 + 1;
        *(void *)(v35 + 8 * v36) = v30;
      }
LABEL_42:
      if (++v14 == v15) {
        goto LABEL_17;
      }
    }
LABEL_65:
    if (v40 < *(_DWORD *)(v7 + 352))
    {
      *(_DWORD *)(v7 + 356) = v40 + 1;
      *(void *)(v31 + 8 * v4std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v30;
      goto LABEL_45;
    }
LABEL_44:
    llvm::SmallPtrSetImplBase::insert_imp_big(v63, *v14);
    goto LABEL_45;
  }
LABEL_17:
  uint64_t v16 = (ZinIrHalH13g *)*((void *)a2 + 5);
  if (v16 != (mlir::Block *)((char *)a2 + 32))
  {
    int v62 = v3;
    unsigned int v64 = (mlir::Block *)((char *)a2 + 32);
    do
    {
      ZinIrHalH13g::~ZinIrHalH13g(v16);
      uint64_t v18 = *(unsigned int *)(v17 + 36);
      if (v18) {
        uint64_t v19 = v17 - 16;
      }
      else {
        uint64_t v19 = 0;
      }
      if (v18)
      {
        uint64_t v20 = 0;
        while (1)
        {
          NextResultAtOffset = (void *)mlir::detail::OpResultImpl::getNextResultAtOffset(v19, v20);
          uint64_t v22 = NextResultAtOffset;
          do
          {
            uint64_t v22 = (void *)*v22;
            if (!v22) {
              goto LABEL_26;
            }
            unsigned int v23 = *(mlir::Block **)(v22[2] + 16);
            int v24 = (mlir::Region *)mlir::Block::getParent(a2);
          }
          while (mlir::Region::findAncestorBlockInRegion(v24, v23) == a2);
          uint64_t v25 = *(void *)(v7 + 184);
          if (v25 != *(void *)(v7 + 176)) {
            break;
          }
          uint64_t v26 = *(unsigned int *)(v7 + 196);
          if (v26)
          {
            uint64_t v27 = 0;
            uint64_t v28 = 8 * v26;
            uint64_t v29 = *(void **)(v7 + 184);
            while ((void *)*v29 != NextResultAtOffset)
            {
              if (*v29 == -2) {
                uint64_t v27 = v29;
              }
              ++v29;
              v28 -= 8;
              if (!v28)
              {
                if (!v27) {
                  goto LABEL_39;
                }
                *uint64_t v27 = NextResultAtOffset;
                --*(_DWORD *)(v7 + 200);
                break;
              }
            }
          }
          else
          {
LABEL_39:
            if (v26 >= *(_DWORD *)(v7 + 192)) {
              break;
            }
            *(_DWORD *)(v7 + 196) = v26 + 1;
            *(void *)(v25 + 8 * v26) = NextResultAtOffset;
          }
LABEL_26:
          if (++v20 == v18) {
            goto LABEL_19;
          }
        }
        llvm::SmallPtrSetImplBase::insert_imp_big((llvm::SmallPtrSetImplBase *)(v7 + 176), NextResultAtOffset);
        goto LABEL_26;
      }
LABEL_19:
      uint64_t v16 = (ZinIrHalH13g *)*((void *)v16 + 1);
    }
    while (v16 != v64);
    uint64_t v44 = (ZinIrHalH13g *)*((void *)a2 + 5);
    unsigned int v3 = v62;
    uint64_t v65 = (void *)(v7 + 8);
    if (v44 != v64)
    {
      do
      {
        uint64_t v45 = (ZinIrHalH13g *)*((void *)v44 + 1);
        ZinIrHalH13g::~ZinIrHalH13g(v44);
        uint64_t v44 = v45;
      }
      while (v45 != v64);
    }
  }
  llvm::set_subtract<llvm::SmallPtrSet<mlir::Value,16u>,llvm::SmallPtrSet<mlir::Value,16u>>((const void **)(v7 + 496), v63);
LABEL_72:
  llvm::SmallPtrSetImplBase::SmallPtrSetImplBase((llvm::SmallPtrSetImplBase *)&v65, &v70, (const llvm::SmallPtrSetImplBase *)(v7 + 496));
  llvm::set_union<llvm::SmallPtrSet<mlir::Value,16u>,llvm::SmallPtrSet<mlir::Value,16u>>((llvm::SmallPtrSetImplBase *)&v65, (void *)(v7 + 176));
  llvm::set_subtract<llvm::SmallPtrSet<mlir::Value,16u>,llvm::SmallPtrSet<mlir::Value,16u>>((const void **)&v65, (void *)(v7 + 336));
  int v47 = v68 - v69;
  int v48 = *(_DWORD *)(v7 + 36) - *(_DWORD *)(v7 + 40);
  if (&v65 != (void **)(v7 + 16) && v47 != v48) {
    llvm::SmallPtrSetImplBase::MoveFrom(v7 + 16, 16, (double *)&v65);
  }
  if (v66 != v65) {
    free(v66);
  }
  if (v47 != v48)
  {
    uint64_t v50 = *(void **)a2;
    if (v50)
    {
      int v51 = (int64x2_t *)v3[1];
      do
      {
        uint64_t v71 = mlir::PredecessorIterator::unwrap((uint64_t)v50);
        llvm::DenseMapBase<llvm::DenseMap<mlir::Block *,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::Block *,void>,llvm::detail::DenseSetPair<mlir::Block *>>,mlir::Block *,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::Block *,void>,llvm::detail::DenseSetPair<mlir::Block *>>::try_emplace<llvm::detail::DenseSetEmpty&>(v51, &v71, (uint64_t)&v65);
        if (v67)
        {
          uint64_t v52 = v71;
          unint64_t v53 = v51[2].u32[0];
          if (v53 >= v51[2].u32[1])
          {
            llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v51[1].i64[1], &v51[2].u64[1], v53 + 1, 8);
            unint64_t v53 = v51[2].u32[0];
          }
          *(void *)(v51[1].i64[1] + 8 * v53) = v52;
          ++v51[2].i32[0];
        }
        uint64_t v50 = (void *)*v50;
      }
      while (v50);
    }
  }
}

void *llvm::DenseMapBase<llvm::DenseMap<mlir::Block *,anonymous namespace'::BlockInfoBuilder,llvm::DenseMapInfo<mlir::Block *,void>,llvm::detail::DenseMapPair<mlir::Block *,anonymous namespace'::BlockInfoBuilder>>,mlir::Block *,anonymous namespace'::BlockInfoBuilder,llvm::DenseMapInfo<mlir::Block *,void>,llvm::detail::DenseMapPair<mlir::Block *,anonymous namespace'::BlockInfoBuilder>>::grow(uint64_t a1, int a2)
{
  unsigned int v3 = *(_DWORD *)(a1 + 16);
  uint64_t v4 = *(llvm **)a1;
  unint64_t v5 = (a2 - 1) | ((unint64_t)(a2 - 1) >> 1);
  unint64_t v6 = v5 | (v5 >> 2) | ((v5 | (v5 >> 2)) >> 4);
  int v7 = ((v6 | (v6 >> 8)) >> 16) | v6 | (v6 >> 8);
  if ((v7 + 1) > 0x40) {
    unsigned int v8 = v7 + 1;
  }
  else {
    unsigned int v8 = 64;
  }
  *(_DWORD *)(a1 + 16) = v8;
  uint64_t result = llvm::allocate_buffer(656 * v8, (std::align_val_t)8uLL);
  *(void *)a1 = result;
  if (v4)
  {
    *(void *)(a1 + 8) = 0;
    unsigned int v10 = *(_DWORD *)(a1 + 16);
    if (!v10) {
      goto LABEL_16;
    }
    unint64_t v11 = 656 * v10 - 656;
    if (v11 >= 0x290)
    {
      unint64_t v16 = v11 / 0x290 + 1;
      unsigned int v12 = &result[82 * (v16 & 0xFFFFFFFFFFFFFELL)];
      uint64_t v17 = v16 & 0xFFFFFFFFFFFFFELL;
      uint64_t v18 = result;
      do
      {
        *uint64_t v18 = -4096;
        v18[82] = -4096;
        v18 += 164;
        v17 -= 2;
      }
      while (v17);
      if (v16 == (v16 & 0xFFFFFFFFFFFFFELL))
      {
LABEL_16:
        if (v3)
        {
          uint64_t v20 = v4;
          do
          {
            uint64_t v21 = *(void *)v20;
            if ((*(void *)v20 | 0x1000) != 0xFFFFFFFFFFFFF000)
            {
              int v22 = *(_DWORD *)(a1 + 16);
              if (v22)
              {
                int v23 = v22 - 1;
                unsigned int v24 = v23 & ((v21 >> 4) ^ (v21 >> 9));
                uint64_t v25 = (void *)(*(void *)a1 + 656 * v24);
                uint64_t v26 = *v25;
                if (*v25 != v21)
                {
                  uint64_t v27 = 0;
                  int v28 = 1;
                  while (v26 != -4096)
                  {
                    if (v27) {
                      BOOL v29 = 0;
                    }
                    else {
                      BOOL v29 = v26 == -8192;
                    }
                    if (v29) {
                      uint64_t v27 = v25;
                    }
                    unsigned int v30 = v24 + v28++;
                    unsigned int v24 = v30 & v23;
                    uint64_t v25 = (void *)(*(void *)a1 + 656 * v24);
                    uint64_t v26 = *v25;
                    if (*v25 == v21) {
                      goto LABEL_32;
                    }
                  }
                  if (v27) {
                    uint64_t v25 = v27;
                  }
                }
              }
              else
              {
                uint64_t v25 = 0;
              }
LABEL_32:
              *uint64_t v25 = v21;
              v25[1] = *((void *)v20 + 1);
              llvm::SmallPtrSetImplBase::SmallPtrSetImplBase((uint64_t)(v25 + 2), v25 + 6, 16, (uint64_t *)v20 + 2);
              llvm::SmallPtrSetImplBase::SmallPtrSetImplBase((uint64_t)(v25 + 22), v25 + 26, 16, (uint64_t *)v20 + 22);
              llvm::SmallPtrSetImplBase::SmallPtrSetImplBase((uint64_t)(v25 + 42), v25 + 46, 16, (uint64_t *)v20 + 42);
              llvm::SmallPtrSetImplBase::SmallPtrSetImplBase((uint64_t)(v25 + 62), v25 + 66, 16, (uint64_t *)v20 + 62);
              ++*(_DWORD *)(a1 + 8);
              uint64_t v31 = (void *)*((void *)v20 + 63);
              if (v31 != *((void **)v20 + 62)) {
                free(v31);
              }
              uint64_t v32 = (void *)*((void *)v20 + 43);
              if (v32 != *((void **)v20 + 42)) {
                free(v32);
              }
              long long v33 = (void *)*((void *)v20 + 23);
              if (v33 != *((void **)v20 + 22)) {
                free(v33);
              }
              unint64_t v34 = (void *)*((void *)v20 + 3);
              if (v34 != *((void **)v20 + 2)) {
                free(v34);
              }
            }
            uint64_t v20 = (llvm *)((char *)v20 + 656);
          }
          while (v20 != (llvm *)((char *)v4 + 656 * v3));
        }
        llvm::deallocate_buffer(v4, (void *)(656 * v3));
      }
    }
    else
    {
      unsigned int v12 = result;
    }
    uint64_t v19 = &result[82 * v10];
    do
    {
      *unsigned int v12 = -4096;
      v12 += 82;
    }
    while (v12 != v19);
    goto LABEL_16;
  }
  *(void *)(a1 + 8) = 0;
  unsigned int v13 = *(_DWORD *)(a1 + 16);
  if (v13)
  {
    unint64_t v14 = 656 * v13 - 656;
    if (v14 < 0x290)
    {
      BOOL v15 = result;
LABEL_49:
      uint64_t v38 = &result[82 * v13];
      do
      {
        void *v15 = -4096;
        v15 += 82;
      }
      while (v15 != v38);
      return result;
    }
    unint64_t v35 = v14 / 0x290 + 1;
    BOOL v15 = &result[82 * (v35 & 0xFFFFFFFFFFFFFELL)];
    uint64_t v36 = v35 & 0xFFFFFFFFFFFFFELL;
    uint64_t v37 = result;
    do
    {
      void *v37 = -4096;
      v37[82] = -4096;
      v37 += 164;
      v36 -= 2;
    }
    while (v36);
    if (v35 != (v35 & 0xFFFFFFFFFFFFFELL)) {
      goto LABEL_49;
    }
  }
  return result;
}

const void **llvm::set_subtract<llvm::SmallPtrSet<mlir::Value,16u>,llvm::SmallPtrSet<mlir::Value,16u>>(const void **this, void *a2)
{
  uint64_t v2 = (uint64_t)this;
  uint64_t v3 = a2[1];
  if (v3 == *a2) {
    uint64_t v4 = (unsigned int *)a2 + 5;
  }
  else {
    uint64_t v4 = (unsigned int *)(a2 + 2);
  }
  uint64_t v5 = *v4;
  if (v5)
  {
    uint64_t v6 = 8 * v5;
    for (uint64_t i = (const void **)a2[1]; (unint64_t)*i >= 0xFFFFFFFFFFFFFFFELL; ++i)
    {
      v6 -= 8;
      if (!v6) {
        return this;
      }
    }
  }
  else
  {
    uint64_t i = (const void **)a2[1];
  }
  unsigned int v8 = (const void **)(v3 + 8 * v5);
  while (i != v8)
  {
    uint64_t v9 = *i;
    uint64_t v10 = *(void *)(v2 + 8);
    if (v10 == *(void *)v2)
    {
      uint64_t v15 = *(unsigned int *)(v2 + 20);
      this = (const void **)(v10 + 8 * v15);
      if (v15)
      {
        uint64_t v16 = 0;
        while (*(const void **)(v10 + v16) != v9)
        {
          v16 += 8;
          if (8 * v15 == v16) {
            goto LABEL_31;
          }
        }
        this = (const void **)(v10 + v16);
      }
LABEL_31:
      if (this == (const void **)(*(void *)(v2 + 8) + 8 * v15)) {
        goto LABEL_21;
      }
LABEL_20:
      *this = (const void *)-2;
      ++*(_DWORD *)(v2 + 24);
      goto LABEL_21;
    }
    this = llvm::SmallPtrSetImplBase::FindBucketFor((llvm::SmallPtrSetImplBase *)v2, *i);
    uint64_t v11 = *(void *)v2;
    uint64_t v12 = *(void *)(v2 + 8);
    if (*this != v9)
    {
      unsigned int v13 = *(_DWORD *)(v2 + 16);
      if (v12 == v11) {
        unsigned int v13 = *(_DWORD *)(v2 + 20);
      }
      this = (const void **)(v12 + 8 * v13);
    }
    if (v12 == v11) {
      unsigned int v14 = *(_DWORD *)(v2 + 20);
    }
    else {
      unsigned int v14 = *(_DWORD *)(v2 + 16);
    }
    if (this != (const void **)(v12 + 8 * v14)) {
      goto LABEL_20;
    }
    do
    {
LABEL_21:
      if (++i == v8) {
        return this;
      }
    }
    while ((unint64_t)*i >= 0xFFFFFFFFFFFFFFFELL);
  }
  return this;
}

uint64_t *llvm::function_ref<void ()(mlir::Operation *)>::callback_fn<anonymous namespace'::BlockInfoBuilder::BlockInfoBuilder(mlir::Block *)::{lambda(mlir::Operation *)#1}>(uint64_t *result, uint64_t a2)
{
  uint64_t v3 = *result;
  uint64_t v4 = *(unsigned int *)(a2 + 36);
  if (v4) {
    uint64_t v5 = a2 - 16;
  }
  else {
    uint64_t v5 = 0;
  }
  if (v4)
  {
    for (uint64_t i = 0; i != v4; ++i)
    {
      uint64_t result = (uint64_t *)mlir::detail::OpResultImpl::getNextResultAtOffset(v5, i);
      uint64_t v7 = *(void *)(v3 + 336);
      if (v7 != *(void *)(v3 + 328)) {
        goto LABEL_6;
      }
      uint64_t v8 = *(unsigned int *)(v3 + 348);
      if (v8)
      {
        uint64_t v9 = 0;
        uint64_t v10 = 8 * v8;
        uint64_t v11 = *(uint64_t ***)(v3 + 336);
        while (*v11 != result)
        {
          if (*v11 == (uint64_t *)-2) {
            uint64_t v9 = v11;
          }
          ++v11;
          v10 -= 8;
          if (!v10)
          {
            if (!v9) {
              goto LABEL_17;
            }
            *uint64_t v9 = result;
            --*(_DWORD *)(v3 + 352);
            goto LABEL_7;
          }
        }
        continue;
      }
LABEL_17:
      if (v8 < *(_DWORD *)(v3 + 344))
      {
        *(_DWORD *)(v3 + 348) = v8 + 1;
        *(void *)(v7 + 8 * v8) = result;
      }
      else
      {
LABEL_6:
        uint64_t result = (uint64_t *)llvm::SmallPtrSetImplBase::insert_imp_big((llvm::SmallPtrSetImplBase *)(v3 + 328), result);
      }
LABEL_7:
      ;
    }
  }
  if ((*(unsigned char *)(a2 + 46) & 0x80) != 0)
  {
    uint64_t v12 = *(unsigned int *)(a2 + 68);
    if (v12)
    {
      uint64_t v13 = 0;
      uint64_t v14 = *(void *)(a2 + 72);
      do
      {
        uint64_t v15 = *(void *)(v3 + 496);
        uint64_t v16 = *(const void **)(v14 + 32 * v13 + 24);
        if (v15 != *(void *)(v3 + 488)) {
          goto LABEL_22;
        }
        uint64_t v17 = *(unsigned int *)(v3 + 508);
        if (v17)
        {
          uint64_t v18 = 0;
          uint64_t v19 = 8 * v17;
          uint64_t v20 = *(void **)(v3 + 496);
          while ((const void *)*v20 != v16)
          {
            if (*v20 == -2) {
              uint64_t v18 = v20;
            }
            ++v20;
            v19 -= 8;
            if (!v19)
            {
              if (!v18) {
                goto LABEL_33;
              }
              *uint64_t v18 = v16;
              --*(_DWORD *)(v3 + 512);
              goto LABEL_23;
            }
          }
          goto LABEL_23;
        }
LABEL_33:
        if (v17 < *(_DWORD *)(v3 + 504))
        {
          *(_DWORD *)(v3 + 508) = v17 + 1;
          *(void *)(v15 + 8 * v17) = v16;
        }
        else
        {
LABEL_22:
          uint64_t result = (uint64_t *)llvm::SmallPtrSetImplBase::insert_imp_big((llvm::SmallPtrSetImplBase *)(v3 + 488), v16);
        }
LABEL_23:
        ++v13;
      }
      while (v13 != v12);
    }
  }
  return result;
}

uint64_t llvm::set_union<llvm::SmallPtrSet<mlir::Value,16u>,llvm::SmallPtrSet<mlir::Value,16u>>(llvm::SmallPtrSetImplBase *this, void *a2)
{
  uint64_t v3 = a2[1];
  if (v3 == *a2) {
    uint64_t v4 = (unsigned int *)a2 + 5;
  }
  else {
    uint64_t v4 = (unsigned int *)(a2 + 2);
  }
  uint64_t v5 = *v4;
  if (v5)
  {
    uint64_t v6 = 8 * v5;
    uint64_t v7 = (const void **)a2[1];
    while ((unint64_t)*v7 >= 0xFFFFFFFFFFFFFFFELL)
    {
      ++v7;
      v6 -= 8;
      if (!v6) {
        goto LABEL_32;
      }
    }
  }
  else
  {
    uint64_t v7 = (const void **)a2[1];
  }
  uint64_t v8 = (const void **)(v3 + 8 * v5);
  if (v7 != v8)
  {
    char v9 = 0;
    uint64_t v10 = *(void **)this;
    uint64_t v11 = (void *)*((void *)this + 1);
    while (1)
    {
      uint64_t v12 = *v7;
      if (v11 != v10) {
        goto LABEL_13;
      }
      uint64_t v15 = *((unsigned int *)this + 5);
      if (v15)
      {
        uint64_t v16 = 0;
        uint64_t v17 = 8 * v15;
        uint64_t v18 = v10;
        do
        {
          if ((const void *)*v18 == v12)
          {
            int v14 = 0;
            goto LABEL_14;
          }
          if (*v18 == -2) {
            uint64_t v16 = v18;
          }
          ++v18;
          v17 -= 8;
        }
        while (v17);
        if (!v16) {
          goto LABEL_29;
        }
        void *v16 = v12;
        --*((_DWORD *)this + 6);
        int v14 = 1;
        goto LABEL_14;
      }
LABEL_29:
      if (v15 < *((_DWORD *)this + 4))
      {
        *((_DWORD *)this + 5) = v15 + 1;
        v10[v15] = v12;
        int v14 = 1;
      }
      else
      {
LABEL_13:
        llvm::SmallPtrSetImplBase::insert_imp_big(this, v12);
        int v14 = v13;
      }
LABEL_14:
      v9 |= v14 != 0;
      if (++v7 != v8)
      {
        uint64_t v10 = *(void **)this;
        uint64_t v11 = (void *)*((void *)this + 1);
        while ((unint64_t)*v7 >= 0xFFFFFFFFFFFFFFFELL)
        {
          if (++v7 == v8) {
            return v9 & 1;
          }
        }
        if (v7 != v8) {
          continue;
        }
      }
      return v9 & 1;
    }
  }
LABEL_32:
  char v9 = 0;
  return v9 & 1;
}

int64x2_t *llvm::DenseMapBase<llvm::DenseMap<mlir::Block *,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::Block *,void>,llvm::detail::DenseSetPair<mlir::Block *>>,mlir::Block *,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::Block *,void>,llvm::detail::DenseSetPair<mlir::Block *>>::try_emplace<llvm::detail::DenseSetEmpty&>@<X0>(int64x2_t *result@<X0>, uint64_t *a2@<X1>, uint64_t a3@<X8>)
{
  uint64_t v4 = result;
  unsigned int v6 = result[1].u32[0];
  if (!v6) {
    goto LABEL_23;
  }
  uint64_t v7 = result->i64[0];
  unsigned int v8 = v6 - 1;
  unsigned int v9 = ((*a2 >> 4) ^ (*a2 >> 9)) & (v6 - 1);
  uint64_t v10 = (uint64_t *)(result->i64[0] + 8 * v9);
  uint64_t v11 = *v10;
  if (*a2 == *v10)
  {
LABEL_3:
    char v12 = 0;
    goto LABEL_10;
  }
  int v14 = 0;
  int v15 = 1;
  while (v11 != -4096)
  {
    if (v14) {
      BOOL v16 = 0;
    }
    else {
      BOOL v16 = v11 == -8192;
    }
    if (v16) {
      int v14 = v10;
    }
    unsigned int v17 = v9 + v15++;
    unsigned int v9 = v17 & v8;
    uint64_t v10 = (uint64_t *)(v7 + 8 * (v17 & v8));
    uint64_t v11 = *v10;
    if (*a2 == *v10) {
      goto LABEL_3;
    }
  }
  if (v14) {
    uint64_t v10 = v14;
  }
  __int32 v18 = result->i32[2];
  if (4 * v18 + 4 < 3 * v6)
  {
    if (v6 + ~v18 - result->i32[3] > v6 >> 3) {
      goto LABEL_6;
    }
  }
  else
  {
LABEL_23:
    v6 *= 2;
  }
  uint64_t result = llvm::DenseMap<mlir::Block *,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::Block *,void>,llvm::detail::DenseSetPair<mlir::Block *>>::grow((uint64_t)result, v6);
  unsigned int v6 = v4[1].u32[0];
  uint64_t v13 = *a2;
  unsigned int v19 = v6 - 1;
  unsigned int v20 = ((*a2 >> 4) ^ (*a2 >> 9)) & (v6 - 1);
  uint64_t v10 = (uint64_t *)(v4->i64[0] + 8 * v20);
  uint64_t v21 = *v10;
  if (*a2 == *v10) {
    goto LABEL_7;
  }
  int v22 = 0;
  int v23 = 1;
  while (v21 != -4096)
  {
    if (v22) {
      BOOL v24 = 0;
    }
    else {
      BOOL v24 = v21 == -8192;
    }
    if (v24) {
      int v22 = v10;
    }
    unsigned int v25 = v20 + v23++;
    unsigned int v20 = v25 & v19;
    uint64_t v10 = (uint64_t *)(v4->i64[0] + 8 * (v25 & v19));
    uint64_t v21 = *v10;
    if (v13 == *v10) {
      goto LABEL_7;
    }
  }
  if (v22) {
    uint64_t v10 = v22;
  }
LABEL_6:
  uint64_t v13 = *v10;
LABEL_7:
  ++v4->i32[2];
  if (v13 != -4096) {
    --v4->i32[3];
  }
  *uint64_t v10 = *a2;
  uint64_t v7 = v4->i64[0];
  char v12 = 1;
LABEL_10:
  *(void *)a3 = v10;
  *(void *)(a3 + 8) = v7 + 8 * v6;
  *(unsigned char *)(a3 + 16) = v12;
  return result;
}

int64x2_t *llvm::DenseMap<mlir::Block *,llvm::detail::DenseSetEmpty,llvm::DenseMapInfo<mlir::Block *,void>,llvm::detail::DenseSetPair<mlir::Block *>>::grow(uint64_t a1, int a2)
{
  uint64_t v3 = *(unsigned int *)(a1 + 16);
  uint64_t v4 = *(llvm **)a1;
  unint64_t v5 = (a2 - 1) | ((unint64_t)(a2 - 1) >> 1);
  unint64_t v6 = v5 | (v5 >> 2) | ((v5 | (v5 >> 2)) >> 4);
  int v7 = ((v6 | (v6 >> 8)) >> 16) | v6 | (v6 >> 8);
  if ((v7 + 1) > 0x40) {
    unsigned int v8 = v7 + 1;
  }
  else {
    unsigned int v8 = 64;
  }
  *(_DWORD *)(a1 + 16) = v8;
  uint64_t result = (int64x2_t *)llvm::allocate_buffer(8 * v8, (std::align_val_t)8uLL);
  uint64_t v10 = (char *)result;
  *(void *)a1 = result;
  if (v4)
  {
    *(void *)(a1 + 8) = 0;
    uint64_t v11 = *(unsigned int *)(a1 + 16);
    if (v11)
    {
      unint64_t v12 = (v11 - 1) & 0x1FFFFFFFFFFFFFFFLL;
      if (v12 < 3) {
        goto LABEL_41;
      }
      unint64_t v13 = v12 + 1;
      uint64_t v10 = &result->i8[8 * (v13 & 0x3FFFFFFFFFFFFFFCLL)];
      int v14 = result + 1;
      int64x2_t v15 = vdupq_n_s64(0xFFFFFFFFFFFFF000);
      uint64_t v16 = v13 & 0x3FFFFFFFFFFFFFFCLL;
      do
      {
        v14[-1] = v15;
        *int v14 = v15;
        v14 += 2;
        v16 -= 4;
      }
      while (v16);
      if (v13 != (v13 & 0x3FFFFFFFFFFFFFFCLL))
      {
LABEL_41:
        do
        {
          *(void *)uint64_t v10 = -4096;
          v10 += 8;
        }
        while (v10 != (char *)result + 8 * v11);
      }
    }
    if (v3)
    {
      int v17 = 0;
      int v18 = v11 - 1;
      unsigned int v19 = v4;
      do
      {
        uint64_t v28 = *(void *)v19;
        if ((*(void *)v19 | 0x1000) != 0xFFFFFFFFFFFFF000)
        {
          unsigned int v29 = ((v28 >> 4) ^ (v28 >> 9)) & v18;
          uint64_t v27 = (void *)(*(void *)a1 + 8 * v29);
          uint64_t v30 = *v27;
          if (v28 != *v27)
          {
            uint64_t v31 = 0;
            int v32 = 1;
            while (v30 != -4096)
            {
              if (v31) {
                BOOL v33 = 0;
              }
              else {
                BOOL v33 = v30 == -8192;
              }
              if (v33) {
                uint64_t v31 = v27;
              }
              unsigned int v34 = v29 + v32++;
              unsigned int v29 = v34 & v18;
              uint64_t v27 = (void *)(*(void *)a1 + 8 * (v34 & v18));
              uint64_t v30 = *v27;
              if (v28 == *v27) {
                goto LABEL_23;
              }
            }
            if (v31) {
              uint64_t v27 = v31;
            }
          }
LABEL_23:
          *uint64_t v27 = v28;
          *(_DWORD *)(a1 + 8) = ++v17;
        }
        unsigned int v19 = (llvm *)((char *)v19 + 8);
      }
      while (v19 != (llvm *)((char *)v4 + 8 * v3));
    }
    llvm::deallocate_buffer(v4, (void *)(8 * v3));
  }
  *(void *)(a1 + 8) = 0;
  uint64_t v20 = *(unsigned int *)(a1 + 16);
  if (v20)
  {
    unint64_t v21 = (v20 - 1) & 0x1FFFFFFFFFFFFFFFLL;
    if (v21 < 3) {
      goto LABEL_18;
    }
    unint64_t v22 = v21 + 1;
    uint64_t v10 = &result->i8[8 * (v22 & 0x3FFFFFFFFFFFFFFCLL)];
    int v23 = result + 1;
    int64x2_t v24 = vdupq_n_s64(0xFFFFFFFFFFFFF000);
    uint64_t v25 = v22 & 0x3FFFFFFFFFFFFFFCLL;
    do
    {
      v23[-1] = v24;
      *int v23 = v24;
      v23 += 2;
      v25 -= 4;
    }
    while (v25);
    if (v22 != (v22 & 0x3FFFFFFFFFFFFFFCLL))
    {
LABEL_18:
      uint64_t v26 = &result->i8[8 * v20];
      do
      {
        *(void *)uint64_t v10 = -4096;
        v10 += 8;
      }
      while (v10 != v26);
    }
  }
  return result;
}

char *llvm::DenseMapBase<llvm::DenseMap<mlir::Block *,mlir::LivenessBlockInfo,llvm::DenseMapInfo<mlir::Block *,void>,llvm::detail::DenseMapPair<mlir::Block *,mlir::LivenessBlockInfo>>,mlir::Block *,mlir::LivenessBlockInfo,llvm::DenseMapInfo<mlir::Block *,void>,llvm::detail::DenseMapPair<mlir::Block *,mlir::LivenessBlockInfo>>::InsertIntoBucket<mlir::Block * const&>(uint64_t a1, char *a2, uint64_t *a3)
{
  int v5 = *(_DWORD *)(a1 + 8);
  unsigned int v6 = *(_DWORD *)(a1 + 16);
  if (4 * v5 + 4 >= 3 * v6)
  {
    int v9 = 2 * v6;
  }
  else
  {
    if (v6 + ~v5 - *(_DWORD *)(a1 + 12) > v6 >> 3)
    {
LABEL_3:
      uint64_t v7 = *(void *)a2;
      goto LABEL_4;
    }
    int v9 = *(_DWORD *)(a1 + 16);
  }
  uint64_t v10 = *(uint64_t **)a1;
  unint64_t v11 = (v9 - 1) | ((unint64_t)(v9 - 1) >> 1);
  unint64_t v12 = v11 | (v11 >> 2) | ((v11 | (v11 >> 2)) >> 4);
  int v13 = ((v12 | (v12 >> 8)) >> 16) | v12 | (v12 >> 8);
  if ((v13 + 1) > 0x40) {
    unsigned int v14 = v13 + 1;
  }
  else {
    unsigned int v14 = 64;
  }
  *(_DWORD *)(a1 + 16) = v14;
  buffer = llvm::allocate_buffer(336 * v14, (std::align_val_t)8uLL);
  *(void *)a1 = buffer;
  if (v10)
  {
    llvm::DenseMapBase<llvm::DenseMap<mlir::Block *,mlir::LivenessBlockInfo,llvm::DenseMapInfo<mlir::Block *,void>,llvm::detail::DenseMapPair<mlir::Block *,mlir::LivenessBlockInfo>>,mlir::Block *,mlir::LivenessBlockInfo,llvm::DenseMapInfo<mlir::Block *,void>,llvm::detail::DenseMapPair<mlir::Block *,mlir::LivenessBlockInfo>>::moveFromOldBuckets(a1, v10, &v10[42 * v6]);
    llvm::deallocate_buffer((llvm *)v10, (void *)(336 * v6));
  }
  *(void *)(a1 + 8) = 0;
  unsigned int v16 = *(_DWORD *)(a1 + 16);
  unint64_t v17 = 336 * v16 - 336;
  int v18 = buffer;
  if (v17 < 0x150) {
    goto LABEL_34;
  }
  unint64_t v19 = v17 / 0x150 + 1;
  int v18 = &buffer[42 * (v19 & 0x1FFFFFFFFFFFFFELL)];
  uint64_t v20 = v19 & 0x1FFFFFFFFFFFFFELL;
  unint64_t v21 = buffer;
  do
  {
    void *v21 = -4096;
    v21[42] = -4096;
    v21 += 84;
    v20 -= 2;
  }
  while (v20);
  if (v19 != (v19 & 0x1FFFFFFFFFFFFFELL))
  {
LABEL_34:
    do
    {
      *int v18 = -4096;
      v18 += 42;
    }
    while (v18 != &buffer[42 * v16]);
  }
  uint64_t v7 = *a3;
  unsigned int v22 = v16 - 1;
  unsigned int v23 = ((*a3 >> 4) ^ (*a3 >> 9)) & v22;
  a2 = (char *)&buffer[42 * v23];
  uint64_t v24 = *(void *)a2;
  if (*a3 != *(void *)a2)
  {
    uint64_t v25 = 0;
    int v26 = 1;
    while (v24 != -4096)
    {
      if (v25) {
        BOOL v27 = 0;
      }
      else {
        BOOL v27 = v24 == -8192;
      }
      if (v27) {
        uint64_t v25 = a2;
      }
      unsigned int v28 = v23 + v26++;
      unsigned int v23 = v28 & v22;
      a2 = (char *)&buffer[42 * v23];
      uint64_t v24 = *(void *)a2;
      if (v7 == *(void *)a2) {
        goto LABEL_4;
      }
    }
    if (v25) {
      a2 = v25;
    }
    goto LABEL_3;
  }
LABEL_4:
  ++*(_DWORD *)(a1 + 8);
  if (v7 != -4096) {
    --*(_DWORD *)(a1 + 12);
  }
  *(void *)a2 = *a3;
  *(_OWORD *)(a2 + 24) = 0u;
  *(_OWORD *)(a2 + 4std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0u;
  *(_OWORD *)(a2 + 56) = 0u;
  *(_OWORD *)(a2 + 72) = 0u;
  *(_OWORD *)(a2 + 88) = 0u;
  *(_OWORD *)(a2 + 104) = 0u;
  *(_OWORD *)(a2 + 12std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0u;
  *(_OWORD *)(a2 + 136) = 0u;
  *(_OWORD *)(a2 + 152) = 0u;
  *(_OWORD *)(a2 + 168) = 0u;
  *(_OWORD *)(a2 + 184) = 0u;
  *(_OWORD *)(a2 + 20std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0u;
  *(_OWORD *)(a2 + 216) = 0u;
  *(_OWORD *)(a2 + 232) = 0u;
  *(_OWORD *)(a2 + 248) = 0u;
  *((void *)a2 + 41) = 0;
  *(_OWORD *)(a2 + 8) = 0u;
  *(_OWORD *)(a2 + 264) = 0u;
  *(_OWORD *)(a2 + 28std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0u;
  *(_OWORD *)(a2 + 296) = 0u;
  *(_OWORD *)(a2 + 312) = 0u;
  *((void *)a2 + 2) = a2 + 48;
  *((void *)a2 + 3) = a2 + 48;
  *((_DWORD *)a2 + 8) = 16;
  *((_DWORD *)a2 + 1std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  *((void *)a2 + 22) = a2 + 208;
  *((void *)a2 + 23) = a2 + 208;
  *((_DWORD *)a2 + 48) = 16;
  *((_DWORD *)a2 + 5std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  return a2;
}

void llvm::DenseMapBase<llvm::DenseMap<mlir::Block *,mlir::LivenessBlockInfo,llvm::DenseMapInfo<mlir::Block *,void>,llvm::detail::DenseMapPair<mlir::Block *,mlir::LivenessBlockInfo>>,mlir::Block *,mlir::LivenessBlockInfo,llvm::DenseMapInfo<mlir::Block *,void>,llvm::detail::DenseMapPair<mlir::Block *,mlir::LivenessBlockInfo>>::moveFromOldBuckets(uint64_t a1, uint64_t *a2, uint64_t *a3)
{
  uint64_t v4 = a2;
  *(void *)(a1 + 8) = 0;
  unsigned int v6 = *(_DWORD *)(a1 + 16);
  if (v6)
  {
    uint64_t v7 = *(void **)a1;
    unint64_t v8 = 336 * v6 - 336;
    if (v8 < 0x150)
    {
      int v9 = *(void **)a1;
LABEL_7:
      int v13 = &v7[42 * v6];
      do
      {
        *int v9 = -4096;
        v9 += 42;
      }
      while (v9 != v13);
      goto LABEL_9;
    }
    unint64_t v10 = v8 / 0x150 + 1;
    int v9 = &v7[42 * (v10 & 0x1FFFFFFFFFFFFFELL)];
    uint64_t v11 = v10 & 0x1FFFFFFFFFFFFFELL;
    unint64_t v12 = *(void **)a1;
    do
    {
      *unint64_t v12 = -4096;
      v12[42] = -4096;
      v12 += 84;
      v11 -= 2;
    }
    while (v11);
    if (v10 != (v10 & 0x1FFFFFFFFFFFFFELL)) {
      goto LABEL_7;
    }
  }
LABEL_9:
  if (a2 != a3)
  {
    do
    {
      uint64_t v14 = *v4;
      if ((*v4 | 0x1000) != 0xFFFFFFFFFFFFF000)
      {
        int v15 = *(_DWORD *)(a1 + 16);
        if (v15)
        {
          int v16 = v15 - 1;
          unsigned int v17 = v16 & ((v14 >> 4) ^ (v14 >> 9));
          int v18 = (void *)(*(void *)a1 + 336 * v17);
          uint64_t v19 = *v18;
          if (v14 != *v18)
          {
            uint64_t v20 = 0;
            int v21 = 1;
            while (v19 != -4096)
            {
              if (v20) {
                BOOL v22 = 0;
              }
              else {
                BOOL v22 = v19 == -8192;
              }
              if (v22) {
                uint64_t v20 = v18;
              }
              unsigned int v23 = v17 + v21++;
              unsigned int v17 = v23 & v16;
              int v18 = (void *)(*(void *)a1 + 336 * v17);
              uint64_t v19 = *v18;
              if (v14 == *v18) {
                goto LABEL_25;
              }
            }
            if (v20) {
              int v18 = v20;
            }
          }
        }
        else
        {
          int v18 = 0;
        }
LABEL_25:
        *int v18 = v14;
        v18[1] = v4[1];
        llvm::SmallPtrSetImplBase::SmallPtrSetImplBase((uint64_t)(v18 + 2), v18 + 6, 16, v4 + 2);
        llvm::SmallPtrSetImplBase::SmallPtrSetImplBase((uint64_t)(v18 + 22), v18 + 26, 16, v4 + 22);
        ++*(_DWORD *)(a1 + 8);
        uint64_t v24 = (void *)v4[23];
        if (v24 != (void *)v4[22]) {
          free(v24);
        }
        uint64_t v25 = (void *)v4[3];
        if (v25 != (void *)v4[2]) {
          free(v25);
        }
      }
      v4 += 42;
    }
    while (v4 != a3);
  }
}

void *llvm::DenseMap<mlir::Operation *,unsigned long,llvm::DenseMapInfo<mlir::Operation *,void>,llvm::detail::DenseMapPair<mlir::Operation *,unsigned long>>::grow(uint64_t a1, int a2)
{
  uint64_t v3 = *(unsigned int *)(a1 + 16);
  uint64_t v4 = *(llvm **)a1;
  unint64_t v5 = (a2 - 1) | ((unint64_t)(a2 - 1) >> 1);
  unint64_t v6 = v5 | (v5 >> 2) | ((v5 | (v5 >> 2)) >> 4);
  int v7 = ((v6 | (v6 >> 8)) >> 16) | v6 | (v6 >> 8);
  if ((v7 + 1) > 0x40) {
    unsigned int v8 = v7 + 1;
  }
  else {
    unsigned int v8 = 64;
  }
  *(_DWORD *)(a1 + 16) = v8;
  uint64_t result = llvm::allocate_buffer(16 * v8, (std::align_val_t)8uLL);
  unint64_t v10 = result;
  *(void *)a1 = result;
  if (v4)
  {
    *(void *)(a1 + 8) = 0;
    uint64_t v11 = *(unsigned int *)(a1 + 16);
    if (v11)
    {
      if (((v11 - 1) & 0xFFFFFFFFFFFFFFFLL) == 0) {
        goto LABEL_41;
      }
      uint64_t v12 = ((v11 - 1) & 0xFFFFFFFFFFFFFFFLL) + 1;
      unint64_t v10 = &result[2 * (v12 & 0x1FFFFFFFFFFFFFFELL)];
      int v13 = result + 2;
      uint64_t v14 = v12 & 0x1FFFFFFFFFFFFFFELL;
      do
      {
        *(v13 - 2) = -4096;
        *int v13 = -4096;
        v13 += 4;
        v14 -= 2;
      }
      while (v14);
      if (v12 != (v12 & 0x1FFFFFFFFFFFFFFELL))
      {
LABEL_41:
        do
        {
          *unint64_t v10 = -4096;
          v10 += 2;
        }
        while (v10 != &result[2 * v11]);
      }
    }
    if (v3)
    {
      int v15 = 0;
      int v16 = v11 - 1;
      unsigned int v17 = v4;
      do
      {
        uint64_t v25 = *(void *)v17;
        if ((*(void *)v17 | 0x1000) != 0xFFFFFFFFFFFFF000)
        {
          unsigned int v26 = ((v25 >> 4) ^ (v25 >> 9)) & v16;
          unsigned int v23 = (void *)(*(void *)a1 + 16 * v26);
          uint64_t v27 = *v23;
          if (v25 != *v23)
          {
            unsigned int v28 = 0;
            int v29 = 1;
            while (v27 != -4096)
            {
              if (v28) {
                BOOL v30 = 0;
              }
              else {
                BOOL v30 = v27 == -8192;
              }
              if (v30) {
                unsigned int v28 = v23;
              }
              unsigned int v31 = v26 + v29++;
              unsigned int v26 = v31 & v16;
              unsigned int v23 = (void *)(*(void *)a1 + 16 * (v31 & v16));
              uint64_t v27 = *v23;
              if (v25 == *v23) {
                goto LABEL_23;
              }
            }
            if (v28) {
              unsigned int v23 = v28;
            }
          }
LABEL_23:
          uint64_t v24 = *((void *)v17 + 1);
          *unsigned int v23 = v25;
          v23[1] = v24;
          *(_DWORD *)(a1 + 8) = ++v15;
        }
        unsigned int v17 = (llvm *)((char *)v17 + 16);
      }
      while (v17 != (llvm *)((char *)v4 + 16 * v3));
    }
    llvm::deallocate_buffer(v4, (void *)(16 * v3));
  }
  *(void *)(a1 + 8) = 0;
  uint64_t v18 = *(unsigned int *)(a1 + 16);
  if (v18)
  {
    if (((v18 - 1) & 0xFFFFFFFFFFFFFFFLL) == 0) {
      goto LABEL_18;
    }
    uint64_t v19 = ((v18 - 1) & 0xFFFFFFFFFFFFFFFLL) + 1;
    unint64_t v10 = &result[2 * (v19 & 0x1FFFFFFFFFFFFFFELL)];
    uint64_t v20 = result + 2;
    uint64_t v21 = v19 & 0x1FFFFFFFFFFFFFFELL;
    do
    {
      *(v20 - 2) = -4096;
      *uint64_t v20 = -4096;
      v20 += 4;
      v21 -= 2;
    }
    while (v21);
    if (v19 != (v19 & 0x1FFFFFFFFFFFFFFELL))
    {
LABEL_18:
      BOOL v22 = &result[2 * v18];
      do
      {
        *unint64_t v10 = -4096;
        v10 += 2;
      }
      while (v10 != v22);
    }
  }
  return result;
}

uint64_t mlir::DataFlowSolver::getOrCreateState<mlir::dataflow::Lattice<mlir::dataflow::ConstantValue>,mlir::Value>(uint64_t a1, uint64_t a2)
{
  uint64_t v33 = *MEMORY[0x263EF8340];
  unint64_t v2 = a2 & 0xFFFFFFFFFFFFFFF9 | 4;
  {
    uint64_t v30 = a1;
    a1 = v30;
    if (v22)
    {
      unsigned int v31 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::dataflow::Lattice<mlir::dataflow::ConstantValue>]";
      unint64_t v32 = 104;
      unint64_t v23 = llvm::StringRef::find((uint64_t *)&v31, "DesiredTypeName = ", 0x12uLL, 0);
      if (v32 >= v23) {
        unint64_t v24 = v23;
      }
      else {
        unint64_t v24 = v32;
      }
      uint64_t v25 = &v31[v24];
      unint64_t v26 = v32 - v24;
      if (v32 - v24 >= 0x12) {
        uint64_t v27 = 18;
      }
      else {
        uint64_t v27 = v32 - v24;
      }
      unint64_t v28 = v26 - v27;
      if (v28 >= v28 - 1) {
        uint64_t v29 = v28 - 1;
      }
      else {
        uint64_t v29 = v28;
      }
      mlir::detail::TypeIDResolver<mlir::dataflow::Lattice<mlir::dataflow::ConstantValue>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v25[v27], v29);
      a1 = v30;
    }
  }
  unsigned int v31 = (const char *)v2;
  unint64_t v32 = mlir::detail::TypeIDResolver<mlir::dataflow::Lattice<mlir::dataflow::ConstantValue>,void>::resolveTypeID(void)::id;
  int v3 = *(_DWORD *)(a1 + 136);
  if (!v3)
  {
    uint64_t v20 = 0;
LABEL_24:
    unint64_t v10 = llvm::DenseMapBase<llvm::DenseMap<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::TypeID>,void>,llvm::detail::DenseMapPair<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>>>,std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::TypeID>,void>,llvm::detail::DenseMapPair<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>>>::InsertIntoBucketImpl<std::pair<mlir::ProgramPoint,mlir::TypeID>>(a1 + 120, (uint64_t)&v31, (uint64_t *)&v31, v20);
    *unint64_t v10 = v31;
    v10[1] = v32;
    void v10[2] = 0;
    goto LABEL_25;
  }
  uint64_t v4 = *(void *)(a1 + 120);
  unint64_t v5 = ((0x2500000000 * v2) | (mlir::detail::TypeIDResolver<mlir::dataflow::Lattice<mlir::dataflow::ConstantValue>,void>::resolveTypeID(void)::id >> 4) ^ (mlir::detail::TypeIDResolver<mlir::dataflow::Lattice<mlir::dataflow::ConstantValue>,void>::resolveTypeID(void)::id >> 9))
     + ~((unint64_t)((mlir::detail::TypeIDResolver<mlir::dataflow::Lattice<mlir::dataflow::ConstantValue>,void>::resolveTypeID(void)::id >> 4) ^ (mlir::detail::TypeIDResolver<mlir::dataflow::Lattice<mlir::dataflow::ConstantValue>,void>::resolveTypeID(void)::id >> 9)) << 32);
  unint64_t v6 = (v5 ^ (v5 >> 22)) + ~((v5 ^ (v5 >> 22)) << 13);
  unint64_t v7 = (9 * (v6 ^ (v6 >> 8))) ^ ((9 * (v6 ^ (v6 >> 8))) >> 15);
  int v8 = v3 - 1;
  unsigned int v9 = v8 & (((v7 + ~(v7 << 27)) >> 31) ^ (v7 + ~(v7 << 27)));
  unint64_t v10 = (void *)(v4 + 24 * v9);
  uint64_t v11 = *v10;
  uint64_t v12 = v10[1];
  if (v2 != *v10
    || mlir::detail::TypeIDResolver<mlir::dataflow::Lattice<mlir::dataflow::ConstantValue>,void>::resolveTypeID(void)::id != v12)
  {
    uint64_t v14 = 0;
    int v15 = 1;
    while (v11 != -4096 || v12 != -4096)
    {
      if (v14) {
        BOOL v16 = 0;
      }
      else {
        BOOL v16 = v12 == -8192;
      }
      if (v16 && v11 == -8192) {
        uint64_t v14 = v10;
      }
      unsigned int v18 = v9 + v15++;
      unsigned int v9 = v18 & v8;
      unint64_t v10 = (void *)(v4 + 24 * v9);
      uint64_t v11 = *v10;
      uint64_t v12 = v10[1];
      if (v2 == *v10
        && mlir::detail::TypeIDResolver<mlir::dataflow::Lattice<mlir::dataflow::ConstantValue>,void>::resolveTypeID(void)::id == v12)
      {
        goto LABEL_25;
      }
    }
    if (v14) {
      uint64_t v20 = v14;
    }
    else {
      uint64_t v20 = v10;
    }
    goto LABEL_24;
  }
LABEL_25:
  uint64_t result = v10[2];
  if (!result) {
    operator new();
  }
  return result;
}

void mlir::dataflow::Lattice<mlir::dataflow::ConstantValue>::~Lattice(mlir::AnalysisState *this)
{
  *(void *)this = &unk_26C3802A8;
  unint64_t v2 = (char *)*((void *)this + 15);
  if (v2 != (char *)this + 136) {
    free(v2);
  }
  int v3 = (void *)*((void *)this + 8);
  if (v3 != *((void **)this + 7)) {
    free(v3);
  }

  mlir::AnalysisState::~AnalysisState(this);
}

{
  char *v2;
  void *v3;

  *(void *)this = &unk_26C3802A8;
  unint64_t v2 = (char *)*((void *)this + 15);
  if (v2 != (char *)this + 136) {
    free(v2);
  }
  int v3 = (void *)*((void *)this + 8);
  if (v3 != *((void **)this + 7)) {
    free(v3);
  }
  mlir::AnalysisState::~AnalysisState(this);
}

void sub_2113C75B8()
{
  JUMPOUT(0x21667D3C0);
}

void mlir::dataflow::Lattice<mlir::dataflow::ConstantValue>::print(uint64_t a1, llvm::raw_ostream *this)
{
  if (*(unsigned char *)(a1 + 176))
  {
    if (*(void *)(a1 + 168))
    {
      uint64_t v7 = *(void *)(a1 + 168);
      mlir::Attribute::print((mlir::Attribute *)&v7, this);
      return;
    }
    uint64_t v6 = *((void *)this + 4);
    if ((unint64_t)(*((void *)this + 3) - v6) <= 8)
    {
      int v3 = this;
      uint64_t v4 = "<UNKNOWN>";
      size_t v5 = 9;
LABEL_7:
      llvm::raw_ostream::write(v3, v4, v5);
      return;
    }
    *(unsigned char *)(v6 + 8) = 62;
    *(void *)uint64_t v6 = *(void *)"<UNKNOWN>";
    *((void *)this + 4) += 9;
  }
  else
  {
    unint64_t v2 = (void *)*((void *)this + 4);
    if (*((void *)this + 3) - (void)v2 <= 0xEuLL)
    {
      int v3 = this;
      uint64_t v4 = "<UNINITIALIZED>";
      size_t v5 = 15;
      goto LABEL_7;
    }
    qmemcpy(v2, "<UNINITIALIZED>", 15);
    *((void *)this + 4) += 15;
  }
}

uint64_t mlir::dataflow::Lattice<mlir::dataflow::ConstantValue>::join(uint64_t a1, uint64_t a2)
{
  if (*(unsigned char *)(a1 + 176))
  {
    if (*(unsigned char *)(a2 + 176))
    {
      uint64_t v2 = *(void *)(a1 + 168);
      if (v2 != *(void *)(a2 + 168) && v2 != 0)
      {
        uint64_t v4 = 0;
        uint64_t v5 = 0;
        char v6 = 1;
LABEL_10:
        *(void *)(a1 + 168) = v5;
        *(unsigned char *)(a1 + 176) = v6;
        *(_DWORD *)(a1 + 177) = *(_DWORD *)v8;
        *(_DWORD *)(a1 + 18std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = *(_DWORD *)&v8[3];
        *(void *)(a1 + 184) = v4;
        return 1;
      }
    }
  }
  else
  {
    uint64_t v5 = *(void *)(a2 + 168);
    char v6 = *(unsigned char *)(a2 + 176);
    *(_DWORD *)int v8 = *(_DWORD *)(a2 + 177);
    *(_DWORD *)&uint64_t v8[3] = *(_DWORD *)(a2 + 180);
    if (v6)
    {
      uint64_t v4 = *(void *)(a2 + 184);
      goto LABEL_10;
    }
  }
  return 0;
}

uint64_t mlir::dataflow::Lattice<mlir::dataflow::ConstantValue>::meet()
{
  return 0;
}

llvm::raw_ostream *mlir::dataflow::Executable::print(llvm::raw_ostream *this, llvm::raw_ostream *a2)
{
  if (*((unsigned char *)this + 56)) {
    uint64_t v2 = "live";
  }
  else {
    uint64_t v2 = "dead";
  }
  int v3 = (_DWORD *)*((void *)a2 + 4);
  if (*((void *)a2 + 3) - (void)v3 <= 3uLL) {
    return llvm::raw_ostream::write(a2, v2, 4uLL);
  }
  *int v3 = *(_DWORD *)v2;
  *((void *)a2 + 4) += 4;
  return this;
}

void mlir::dataflow::Executable::onUpdate(mlir::dataflow::Executable *this, mlir::DataFlowSolver *a2)
{
  uint64_t v4 = *((unsigned int *)this + 12);
  if (v4)
  {
    uint64_t v5 = (long long *)*((void *)this + 5);
    uint64_t v6 = *((void *)a2 + 5);
    uint64_t v7 = 16 * v4;
    do
    {
      uint64_t v8 = *((void *)a2 + 2);
      uint64_t v9 = *((void *)a2 + 1);
      long long v10 = *v5;
      if (v8 == v9) {
        uint64_t v11 = 0;
      }
      else {
        uint64_t v11 = 32 * (v8 - v9) - 1;
      }
      unint64_t v12 = *((void *)a2 + 4) + v6;
      if (v11 == v12)
      {
        long long v59 = *v5;
        std::deque<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>>::__add_back_capacity((uint64_t)a2);
        long long v10 = v59;
        uint64_t v9 = *((void *)a2 + 1);
        unint64_t v12 = *((void *)a2 + 5) + *((void *)a2 + 4);
      }
      *(_OWORD *)(*(void *)(v9 + ((v12 >> 5) & 0x7FFFFFFFFFFFFF8)) + 16 * v12) = v10;
      uint64_t v6 = *((void *)a2 + 5) + 1;
      *((void *)a2 + 5) = v6;
      ++v5;
      v7 -= 16;
    }
    while (v7);
  }
  uint64_t v13 = *((void *)this + 1);
  unint64_t v14 = v13 & 0xFFFFFFFFFFFFFFF8;
  if ((v13 & 6) != 6 || v14 == 0)
  {
    if ((v13 & 6) == 0 && v14 != 0)
    {
      uint64_t v17 = *(void *)(v14 + 8);
      {
        BOOL v60 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::dataflow::CFGEdge]";
        unint64_t v61 = 73;
        unint64_t v52 = llvm::StringRef::find((uint64_t *)&v60, "DesiredTypeName = ", 0x12uLL, 0);
        if (v61 >= v52) {
          unint64_t v53 = v52;
        }
        else {
          unint64_t v53 = v61;
        }
        int v54 = &v60[v53];
        unint64_t v55 = v61 - v53;
        if (v61 - v53 >= 0x12) {
          uint64_t v56 = 18;
        }
        else {
          uint64_t v56 = v61 - v53;
        }
        unint64_t v57 = v55 - v56;
        if (v57 >= v57 - 1) {
          uint64_t v58 = v57 - 1;
        }
        else {
          uint64_t v58 = v57;
        }
        mlir::detail::TypeIDResolver<mlir::dataflow::CFGEdge,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v54[v56], v58);
      }
      if (v17 == mlir::detail::TypeIDResolver<mlir::dataflow::CFGEdge,void>::resolveTypeID(void)::id)
      {
        uint64_t v18 = *((unsigned int *)this + 34);
        if (v18)
        {
          uint64_t v19 = (uint64_t *)*((void *)this + 16);
          uint64_t v20 = *((void *)a2 + 5);
          uint64_t v21 = 8 * v18;
          do
          {
            uint64_t v23 = *((void *)a2 + 2);
            uint64_t v24 = *((void *)a2 + 1);
            uint64_t v25 = *v19;
            uint64_t v26 = *(void *)(v14 + 24);
            if (v23 == v24) {
              uint64_t v27 = 0;
            }
            else {
              uint64_t v27 = 32 * (v23 - v24) - 1;
            }
            unint64_t v28 = v20 + *((void *)a2 + 4);
            if (v27 == v28)
            {
              std::deque<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>>::__add_back_capacity((uint64_t)a2);
              uint64_t v24 = *((void *)a2 + 1);
              unint64_t v28 = *((void *)a2 + 5) + *((void *)a2 + 4);
            }
            int v22 = (uint64_t *)(*(void *)(v24 + ((v28 >> 5) & 0x7FFFFFFFFFFFFF8)) + 16 * v28);
            *int v22 = v26 | 6;
            v22[1] = v25;
            uint64_t v20 = *((void *)a2 + 5) + 1;
            *((void *)a2 + 5) = v20;
            ++v19;
            v21 -= 8;
          }
          while (v21);
        }
      }
    }
  }
  else
  {
    uint64_t v29 = *((unsigned int *)this + 34);
    if (v29)
    {
      uint64_t v30 = (unint64_t *)*((void *)this + 16);
      uint64_t v31 = *((void *)a2 + 5);
      uint64_t v32 = 8 * v29;
      do
      {
        uint64_t v34 = *((void *)a2 + 2);
        uint64_t v35 = *((void *)a2 + 1);
        unint64_t v36 = *v30;
        if (v34 == v35) {
          uint64_t v37 = 0;
        }
        else {
          uint64_t v37 = 32 * (v34 - v35) - 1;
        }
        unint64_t v38 = v31 + *((void *)a2 + 4);
        if (v37 == v38)
        {
          std::deque<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>>::__add_back_capacity((uint64_t)a2);
          uint64_t v35 = *((void *)a2 + 1);
          unint64_t v38 = *((void *)a2 + 5) + *((void *)a2 + 4);
        }
        uint64_t v33 = (unint64_t *)(*(void *)(v35 + ((v38 >> 5) & 0x7FFFFFFFFFFFFF8)) + 16 * v38);
        *uint64_t v33 = v14 | 6;
        v33[1] = v36;
        uint64_t v31 = *((void *)a2 + 5) + 1;
        *((void *)a2 + 5) = v31;
        ++v30;
        v32 -= 8;
      }
      while (v32);
      uint64_t v39 = *((unsigned int *)this + 34);
      if (v39)
      {
        uint64_t v40 = (ZinIrHalH13g *)(v14 + 32);
        if (*(void *)(v14 + 40) != v14 + 32)
        {
          int64_t v41 = (unint64_t *)*((void *)this + 16);
          uint64_t v42 = &v41[v39];
          do
          {
            unint64_t v43 = *(ZinIrHalH13g **)(v14 + 40);
            if (v43 != v40)
            {
              unint64_t v44 = *v41;
              do
              {
                ZinIrHalH13g::~ZinIrHalH13g(v43);
                uint64_t v47 = v46;
                uint64_t v48 = *((void *)a2 + 2);
                uint64_t v49 = *((void *)a2 + 1);
                uint64_t v50 = 32 * (v48 - v49) - 1;
                if (v48 == v49) {
                  uint64_t v50 = 0;
                }
                unint64_t v51 = *((void *)a2 + 5) + *((void *)a2 + 4);
                if (v50 == v51)
                {
                  std::deque<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>>::__add_back_capacity((uint64_t)a2);
                  uint64_t v49 = *((void *)a2 + 1);
                  unint64_t v51 = *((void *)a2 + 5) + *((void *)a2 + 4);
                }
                uint64_t v45 = (unint64_t *)(*(void *)(v49 + ((v51 >> 5) & 0x7FFFFFFFFFFFFF8))
                                         + 16 * v51);
                *uint64_t v45 = v47 & 0xFFFFFFFFFFFFFFF9 | 2;
                v45[1] = v44;
                ++*((void *)a2 + 5);
                unint64_t v43 = (ZinIrHalH13g *)*((void *)v43 + 1);
              }
              while (v43 != v40);
            }
            ++v41;
          }
          while (v41 != v42);
        }
      }
    }
  }
}

llvm::raw_ostream *mlir::dataflow::PredecessorState::print(llvm::raw_ostream *this, llvm::raw_ostream *a2)
{
  int v3 = this;
  if (!*((unsigned char *)this + 56))
  {
LABEL_4:
    uint64_t v5 = (void *)*((void *)a2 + 4);
    if (*((void *)a2 + 3) - (void)v5 <= 0xDuLL) {
      goto LABEL_5;
    }
LABEL_8:
    qmemcpy(v5, "predecessors:\n", 14);
    *((void *)a2 + 4) += 14;
    if (!*((_DWORD *)v3 + 34)) {
      return this;
    }
LABEL_9:
    uint64_t v6 = (mlir::Block **)**((void **)v3 + 16);
    uint64_t v7 = (_WORD *)*((void *)a2 + 4);
    if (*((void *)a2 + 3) - (void)v7 > 1uLL)
    {
      _WORD *v7 = 8224;
      *((void *)a2 + 4) += 2;
      uint64_t v8 = a2;
    }
    else
    {
      uint64_t v8 = llvm::raw_ostream::write(a2, "  ", 2uLL);
    }
    mlir::OpPrintingFlags::OpPrintingFlags((mlir::OpPrintingFlags *)v10);
    uint64_t v9 = (const mlir::OpPrintingFlags *)mlir::OpPrintingFlags::useLocalScope((uint64_t)v10);
    mlir::Operation::print(v6, v8, v9);
  }
  uint64_t v4 = *((void *)a2 + 4);
  if ((unint64_t)(*((void *)a2 + 3) - v4) <= 5)
  {
    this = llvm::raw_ostream::write(a2, "(all) ", 6uLL);
    goto LABEL_4;
  }
  *(_WORD *)(v4 + 4) = 8233;
  *(_DWORD *)uint64_t v4 = 1819042088;
  *((void *)a2 + 4) += 6;
  uint64_t v5 = (void *)*((void *)a2 + 4);
  if (*((void *)a2 + 3) - (void)v5 > 0xDuLL) {
    goto LABEL_8;
  }
LABEL_5:
  this = llvm::raw_ostream::write(a2, "predecessors:\n", 0xEuLL);
  if (*((_DWORD *)v3 + 34)) {
    goto LABEL_9;
  }
  return this;
}

BOOL llvm::SetVector<mlir::Operation *,llvm::SmallVector<mlir::Operation *,4u>,llvm::SmallPtrSet<mlir::Operation *,4u>,0u>::insert(llvm::SmallPtrSetImplBase *this, const void **a2)
{
  uint64_t v4 = *a2;
  uint64_t v5 = *((void *)this + 1);
  if (v5 != *(void *)this) {
    goto LABEL_2;
  }
  uint64_t v11 = *((unsigned int *)this + 5);
  if (v11)
  {
    unint64_t v12 = 0;
    uint64_t v13 = 8 * v11;
    unint64_t v14 = (void *)*((void *)this + 1);
    do
    {
      if ((const void *)*v14 == v4)
      {
        BOOL v7 = 0;
        goto LABEL_3;
      }
      if (*v14 == -2) {
        unint64_t v12 = v14;
      }
      ++v14;
      v13 -= 8;
    }
    while (v13);
    if (!v12) {
      goto LABEL_16;
    }
    *unint64_t v12 = v4;
    --*((_DWORD *)this + 6);
    BOOL v7 = 1;
  }
  else
  {
LABEL_16:
    if (v11 >= *((_DWORD *)this + 4))
    {
LABEL_2:
      llvm::SmallPtrSetImplBase::insert_imp_big(this, v4);
      BOOL v7 = v6 != 0;
      goto LABEL_3;
    }
    *((_DWORD *)this + 5) = v11 + 1;
    *(void *)(v5 + 8 * v11) = v4;
    BOOL v7 = 1;
  }
LABEL_3:
  if (v7)
  {
    uint64_t v8 = *a2;
    uint64_t v9 = *((unsigned int *)this + 18);
    if (v9 >= *((_DWORD *)this + 19))
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)this + 64, (char *)this + 80, v9 + 1, 8);
      LODWORD(v9) = *((_DWORD *)this + 18);
    }
    *(void *)(*((void *)this + 8) + 8 * v9) = v8;
    ++*((_DWORD *)this + 18);
  }
  return v7;
}

uint64_t mlir::dataflow::PredecessorState::join(uint64_t a1, const void *a2, uint64_t a3, uint64_t a4)
{
  uint64_t v34 = *MEMORY[0x263EF8340];
  uint64_t v29 = a2;
  uint64_t v32 = a2;
  BOOL v8 = llvm::SetVector<mlir::Operation *,llvm::SmallVector<mlir::Operation *,4u>,llvm::SmallPtrSet<mlir::Operation *,4u>,0u>::insert((llvm::SmallPtrSetImplBase *)(a1 + 64), &v32);
  if (!a4) {
    return v8;
  }
  uint64_t v11 = *(void *)(a1 + 176);
  uint64_t v10 = a1 + 176;
  uint64_t v9 = v11;
  int v12 = *(_DWORD *)(v10 + 16);
  if (!v12)
  {
    uint64_t v21 = 0;
LABEL_14:
    int v15 = llvm::DenseMapBase<llvm::DenseMap<mlir::Operation *,mlir::ValueRange,llvm::DenseMapInfo<mlir::Operation *,void>,llvm::detail::DenseMapPair<mlir::Operation *,mlir::ValueRange>>,mlir::Operation *,mlir::ValueRange,llvm::DenseMapInfo<mlir::Operation *,void>,llvm::detail::DenseMapPair<mlir::Operation *,mlir::ValueRange>>::InsertIntoBucket<mlir::Operation * const&>(v10, v21, (uint64_t *)&v29);
    goto LABEL_15;
  }
  int v13 = v12 - 1;
  unsigned int v14 = ((a2 >> 4) ^ (a2 >> 9)) & v13;
  int v15 = (uint64_t *)(v9 + 24 * v14);
  uint64_t v16 = *v15;
  if ((const void *)*v15 != a2)
  {
    uint64_t v17 = 0;
    int v18 = 1;
    while (v16 != -4096)
    {
      if (v17) {
        BOOL v19 = 0;
      }
      else {
        BOOL v19 = v16 == -8192;
      }
      if (v19) {
        uint64_t v17 = v15;
      }
      unsigned int v20 = v14 + v18++;
      unsigned int v14 = v20 & v13;
      int v15 = (uint64_t *)(v9 + 24 * v14);
      uint64_t v16 = *v15;
      if ((const void *)*v15 == a2) {
        goto LABEL_15;
      }
    }
    if (v17) {
      uint64_t v21 = v17;
    }
    else {
      uint64_t v21 = v15;
    }
    goto LABEL_14;
  }
LABEL_15:
  if (v15[2] == a4)
  {
    uint64_t v22 = 0;
    uint64_t v23 = (const void *)v15[1];
    uint64_t v32 = v23;
    uint64_t v33 = 0;
    uint64_t v30 = a3;
    uint64_t v31 = 0;
    do
    {
      uint64_t v24 = mlir::ValueRange::dereference_iterator(&v32, v22);
      if (v24 != mlir::ValueRange::dereference_iterator(&v30, v31)) {
        break;
      }
      uint64_t v22 = ++v33;
      uint64_t v25 = ++v31;
      if (v32 == v23 && v22 == a4)
      {
        if (v30 == a3 && v25 == a4) {
          return v8;
        }
        break;
      }
    }
    while (v30 != a3 || v25 != a4);
  }
  v15[1] = a3;
  unint64_t v15[2] = a4;
  return 1;
}

void mlir::dataflow::CFGEdge::getLoc(mlir::Block **this)
{
  v6[2] = *(uint64_t **)MEMORY[0x263EF8340];
  Parent = (mlir::Region *)mlir::Block::getParent(this[2]);
  Context = (mlir::UnknownLoc *)mlir::Region::getContext(Parent);
  uint64_t v4 = (mlir::Region *)mlir::Block::getParent(this[2]);
  v6[0] = (uint64_t *)mlir::Region::getLoc(v4);
  uint64_t v5 = (mlir::Region *)mlir::Block::getParent(this[3]);
  v6[1] = (uint64_t *)mlir::Region::getLoc(v5);
  mlir::FusedLoc::get(v6, (mlir::MLIRContext *)2, 0, Context);
}

llvm::raw_ostream *mlir::dataflow::CFGEdge::print(mlir::Block **this, llvm::raw_ostream *a2)
{
  mlir::Block::print(this[2], a2);
  uint64_t v4 = *((void *)a2 + 4);
  if ((unint64_t)(*((void *)a2 + 3) - v4) > 5)
  {
    *(_WORD *)(v4 + 4) = 2592;
    *(_DWORD *)uint64_t v4 = 1043144714;
    *((void *)a2 + 4) += 6;
    uint64_t v5 = this[3];
    char v6 = a2;
  }
  else
  {
    llvm::raw_ostream::write(a2, "\n -> \n", 6uLL);
    uint64_t v5 = this[3];
    char v6 = a2;
  }
  return mlir::Block::print(v5, v6);
}

void mlir::dataflow::DeadCodeAnalysis::DeadCodeAnalysis(mlir::dataflow::DeadCodeAnalysis *this, mlir::DataFlowSolver *a2)
{
  uint64_t v2 = mlir::DataFlowAnalysis::DataFlowAnalysis(this, a2);
  void *v2 = &unk_26C3801E0;
  v2[3] = 0;
  v2[4] = 0;
  *((_DWORD *)v2 + 1std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  mlir::StorageUniquer::registerParametricStorageType<mlir::dataflow::CFGEdge>();
}

uint64_t mlir::dataflow::DeadCodeAnalysis::initialize(mlir::dataflow::DeadCodeAnalysis *this, mlir::Operation *a2)
{
  unint64_t v4 = *((unsigned int *)a2 + 11);
  if ((v4 & 0x7FFFFF) != 0)
  {
    uint64_t v5 = (void *)((((unint64_t)a2 + 16 * ((v4 >> 23) & 1) + ((v4 >> 21) & 0x7F8) + 71) & 0xFFFFFFFFFFFFFFF8)
                  + 32 * *((unsigned int *)a2 + 10));
    uint64_t v6 = 24 * (v4 & 0x7FFFFF);
    do
    {
      if (v5 != (void *)*v5)
      {
        uint64_t v8 = v5[1];
        if (v8) {
          uint64_t v9 = v8 - 8;
        }
        else {
          uint64_t v9 = 0;
        }
        uint64_t v10 = mlir::DataFlowSolver::getOrCreateState<mlir::dataflow::Executable,mlir::Block *>(*((void *)this + 1), v9);
        if (*(unsigned char *)(v10 + 56))
        {
          int v7 = 0;
        }
        else
        {
          int v7 = 1;
          *(unsigned char *)(v10 + 56) = 1;
        }
        mlir::DataFlowAnalysis::propagateIfChanged((uint64_t)this, v10, v7);
      }
      v5 += 3;
      v6 -= 24;
    }
    while (v6);
  }
  *((void *)this + 2) = a2;
  v12[0] = this;
  v12[1] = &v13;
  int v13 = a2;
  mlir::SymbolTable::walkSymbolTables((uint64_t)a2, *((void *)a2 + 2) == 0, (uint64_t (*)(uint64_t, uint64_t, BOOL))llvm::function_ref<void ()(mlir::Operation *,BOOL)>::callback_fn<mlir::dataflow::DeadCodeAnalysis::initializeSymbolCallables(mlir::Operation *)::$_0>, (uint64_t)v12);
  return mlir::dataflow::DeadCodeAnalysis::initializeRecursively(this, (unint64_t)a2);
}

uint64_t mlir::dataflow::DeadCodeAnalysis::initializeRecursively(mlir::dataflow::DeadCodeAnalysis *this, unint64_t a2)
{
  if ((*(_DWORD *)(a2 + 44) & 0x7FFFFF) != 0 || *(_DWORD *)(a2 + 40)) {
    goto LABEL_3;
  }
  ParentOp = *(mlir::Block **)(a2 + 16);
  if (ParentOp) {
    ParentOp = (mlir::Block *)mlir::Block::getParentOp(ParentOp);
  }
  *(void *)&long long v21 = ParentOp;
  if (_ZN4llvm3isaIN4mlir23RegionBranchOpInterfaceENS1_19CallableOpInterfaceEJEPNS1_9OperationEEEbRKT2_((uint64_t *)&v21))
  {
    mlir::Block::getTerminator(*(ZinIrHalH13g ***)(a2 + 16));
    if (v14 == (mlir::Operation *)a2) {
      goto LABEL_3;
    }
  }
  uint64_t v15 = *(void *)(a2 + 48);
  uint64_t v16 = *(void **)(v15 + 16);
  BOOL v17 = v16 == &mlir::detail::TypeIDResolver<void,void>::id;
  if (v16 == &mlir::detail::TypeIDResolver<void,void>::id) {
    uint64_t v18 = 0;
  }
  else {
    uint64_t v18 = *(void *)(a2 + 48);
  }
  if (v17)
  {
    *(void *)&long long v21 = *(void *)(v15 + 8);
    uint64_t Values = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)&v21);
    if (!Values || !mlir::Dialect::getRegisteredInterfaceForOp<mlir::CallOpInterface>(Values, v15)) {
      goto LABEL_6;
    }
LABEL_3:
    uint64_t v4 = *(void *)(a2 + 16);
    if (v4)
    {
      uint64_t v5 = mlir::DataFlowSolver::getOrCreateState<mlir::dataflow::Executable,mlir::Block *>(*((void *)this + 1), v4);
      *(void *)&long long v21 = this;
      llvm::SetVector<mlir::Operation *,llvm::SmallVector<mlir::Operation *,4u>,llvm::SmallPtrSet<mlir::Operation *,4u>,0u>::insert((llvm::SmallPtrSetImplBase *)(v5 + 64), (const void **)&v21);
    }
    if (!(*(unsigned __int8 (**)(mlir::dataflow::DeadCodeAnalysis *, unint64_t))(*(void *)this
                                                                                                  + 24))(this, a2 & 0xFFFFFFFFFFFFFFF9 | 2))return 0;
    goto LABEL_6;
  }
  unint64_t v19 = v18 | v15 & 0xFFFFFFFFFFFFFF00;
  if (mlir::detail::InterfaceMap::lookup<mlir::CallOpInterface>(v19 + 32)
    || mlir::Dialect::getRegisteredInterfaceForOp<mlir::CallOpInterface>(*(void *)(v19 + 24), *(void *)(a2 + 48)))
  {
    goto LABEL_3;
  }
LABEL_6:
  unint64_t v6 = *(unsigned int *)(a2 + 44);
  if ((v6 & 0x7FFFFF) == 0) {
    return 1;
  }
  int v7 = (mlir::Region *)(((a2 + 16 * ((v6 >> 23) & 1) + ((v6 >> 21) & 0x7F8) + 71) & 0xFFFFFFFFFFFFFFF8)
                      + 32 * *(unsigned int *)(a2 + 40));
  uint64_t v8 = (mlir::Region *)((char *)v7 + 24 * (v6 & 0x7FFFFF));
  while (1)
  {
    mlir::Region::OpIterator::OpIterator(&v25, v7, 0);
    mlir::Region::OpIterator::OpIterator(&v23, v7, 1);
    uint64_t v9 = v26;
    uint64_t v22 = v26;
    long long v21 = v25;
    uint64_t v10 = v24;
    if (v26 != v24) {
      break;
    }
LABEL_11:
    int v7 = (mlir::Region *)((char *)v7 + 24);
    if (v7 == v8) {
      return 1;
    }
  }
  while (1)
  {
    ZinIrHalH13g::~ZinIrHalH13g(v9);
    if (!mlir::dataflow::DeadCodeAnalysis::initializeRecursively(this, v11)) {
      return 0;
    }
    mlir::Region::OpIterator::operator++((uint64_t *)&v25);
    uint64_t v9 = v26;
    if (v26 == v10) {
      goto LABEL_11;
    }
  }
}

uint64_t mlir::dataflow::DeadCodeAnalysis::markEdgeLive(mlir::dataflow::DeadCodeAnalysis *this, mlir::Block *a2, mlir::Block *a3)
{
  uint64_t v9 = a3;
  uint64_t v10 = a2;
  uint64_t v4 = mlir::DataFlowSolver::getOrCreateState<mlir::dataflow::Executable,mlir::Block *>(*((void *)this + 1), (uint64_t)a3);
  if (*(unsigned char *)(v4 + 56))
  {
    int v5 = 0;
  }
  else
  {
    int v5 = 1;
    *(unsigned char *)(v4 + 56) = 1;
  }
  mlir::DataFlowAnalysis::propagateIfChanged((uint64_t)this, v4, v5);
  uint64_t v6 = mlir::StorageUniquer::get<mlir::dataflow::CFGEdge,mlir::Block *&,mlir::Block *&>((unsigned __int8 **)(*((void *)this + 1) + 112), 0, 0, &v10, &v9);
  uint64_t v7 = mlir::DataFlowSolver::getOrCreateState<mlir::dataflow::Executable,mlir::dataflow::CFGEdge *>(*((void *)this + 1), v6);
  if (*(unsigned char *)(v7 + 56)) {
    return mlir::DataFlowAnalysis::propagateIfChanged((uint64_t)this, v7, 0);
  }
  *(unsigned char *)(v7 + 56) = 1;
  return mlir::DataFlowAnalysis::propagateIfChanged((uint64_t)this, v7, 1);
}

uint64_t mlir::dataflow::DeadCodeAnalysis::markEntryBlocksLive(uint64_t this, mlir::Operation *a2)
{
  unint64_t v2 = *((unsigned int *)a2 + 11);
  if ((v2 & 0x7FFFFF) != 0)
  {
    uint64_t v3 = this;
    uint64_t v4 = (void *)((((unint64_t)a2 + 16 * ((v2 >> 23) & 1) + ((v2 >> 21) & 0x7F8) + 71) & 0xFFFFFFFFFFFFFFF8)
                  + 32 * *((unsigned int *)a2 + 10));
    uint64_t v5 = 24 * (v2 & 0x7FFFFF);
    do
    {
      if (v4 != (void *)*v4)
      {
        uint64_t v7 = v4[1];
        if (v7) {
          uint64_t v8 = v7 - 8;
        }
        else {
          uint64_t v8 = 0;
        }
        uint64_t v9 = mlir::DataFlowSolver::getOrCreateState<mlir::dataflow::Executable,mlir::Block *>(*(void *)(v3 + 8), v8);
        if (*(unsigned char *)(v9 + 56))
        {
          int v6 = 0;
        }
        else
        {
          int v6 = 1;
          *(unsigned char *)(v9 + 56) = 1;
        }
        this = mlir::DataFlowAnalysis::propagateIfChanged(v3, v9, v6);
      }
      v4 += 3;
      v5 -= 24;
    }
    while (v5);
  }
  return this;
}

uint64_t mlir::dataflow::DeadCodeAnalysis::visit(uint64_t *a1, uint64_t a2)
{
  v52[1] = *MEMORY[0x263EF8340];
  v52[0] = a2;
  if ((a2 & 6) == 6) {
    return 1;
  }
  if ((a2 & 6) == 2 && (unint64_t v4 = a2 & 0xFFFFFFFFFFFFFFF8, (a2 & 0xFFFFFFFFFFFFFFF8) != 0))
  {
    if (!*(unsigned char *)(mlir::DataFlowSolver::getOrCreateState<mlir::dataflow::Executable,mlir::Block *>(a1[1], *(void *)(v4 + 16))+ 56))return 1; {
    uint64_t v6 = llvm::DefaultDoCastIfPossible<mlir::CallOpInterface,mlir::Operation *,llvm::CastInfo<mlir::CallOpInterface,mlir::Operation *,void>>::doCastIfPossible(v4);
    }
    if (v6) {
      mlir::dataflow::DeadCodeAnalysis::visitCallOperation((uint64_t)a1, v6, v7);
    }
    if ((*(_DWORD *)(v4 + 44) & 0x7FFFFF) != 0)
    {
      uint64_t v8 = (void *)llvm::DefaultDoCastIfPossible<mlir::RegionBranchOpInterface,mlir::Operation *,llvm::CastInfo<mlir::RegionBranchOpInterface,mlir::Operation *,void>>::doCastIfPossible(v4);
      if (v8)
      {
        mlir::dataflow::DeadCodeAnalysis::visitRegionBranchOperation(a1, v8, v9);
      }
      else
      {
        uint64_t v19 = llvm::DefaultDoCastIfPossible<mlir::CallableOpInterface,mlir::Operation *,llvm::CastInfo<mlir::CallableOpInterface,mlir::Operation *,void>>::doCastIfPossible(v4);
        if (v19)
        {
          unsigned int v20 = (mlir::Operation *)v19;
          uint64_t v21 = mlir::DataFlowSolver::getOrCreateState<mlir::dataflow::PredecessorState,mlir::Operation *>(a1[1], v19);
          mlir::DataFlowAnalysis::addDependency((uint64_t)a1, v21, v4 | 2);
          if (!*(unsigned char *)(v21 + 56) || *(_DWORD *)(v21 + 136)) {
            mlir::dataflow::DeadCodeAnalysis::markEntryBlocksLive((uint64_t)a1, v20);
          }
        }
        else
        {
          unint64_t v22 = *(unsigned int *)(v4 + 44);
          if ((v22 & 0x7FFFFF) != 0)
          {
            uint64_t v23 = (void *)(((v4 + 16 * ((v22 >> 23) & 1) + ((v22 >> 21) & 0x7F8) + 64) & 0xFFFFFFFFFFFFFFF8)
                           + 32 * *(unsigned int *)(v4 + 40));
            uint64_t v24 = 24 * (v22 & 0x7FFFFF);
            do
            {
              if (v23 != (void *)*v23)
              {
                uint64_t v26 = v23[1];
                if (v26) {
                  uint64_t v27 = v26 - 8;
                }
                else {
                  uint64_t v27 = 0;
                }
                uint64_t v28 = mlir::DataFlowSolver::getOrCreateState<mlir::dataflow::Executable,mlir::Block *>(a1[1], v27);
                if (*(unsigned char *)(v28 + 56))
                {
                  int v25 = 0;
                }
                else
                {
                  int v25 = 1;
                  *(unsigned char *)(v28 + 56) = 1;
                }
                mlir::DataFlowAnalysis::propagateIfChanged((uint64_t)a1, v28, v25);
              }
              v23 += 3;
              v24 -= 24;
            }
            while (v24);
          }
        }
      }
    }
    if (!*(_DWORD *)(v4 + 40))
    {
      ParentOp = *(mlir::Block **)(v4 + 16);
      if (ParentOp) {
        ParentOp = (mlir::Block *)mlir::Block::getParentOp(ParentOp);
      }
      unint64_t v43 = ParentOp;
      if (_ZN4llvm3isaIN4mlir23RegionBranchOpInterfaceENS1_19CallableOpInterfaceEJEPNS1_9OperationEEEbRKT2_((uint64_t *)&v43))
      {
        mlir::Block::getTerminator(*(ZinIrHalH13g ***)(v4 + 16));
        if (v30 == v4)
        {
          uint64_t v31 = *(mlir::Block **)(v4 + 16);
          if (v31) {
            uint64_t v31 = (mlir::Block *)mlir::Block::getParentOp(v31);
          }
          uint64_t v32 = llvm::DefaultDoCastIfPossible<mlir::RegionBranchOpInterface,mlir::Operation *,llvm::CastInfo<mlir::RegionBranchOpInterface,mlir::Operation *,void>>::doCastIfPossible((uint64_t)v31);
          if (v32)
          {
            mlir::dataflow::DeadCodeAnalysis::visitRegionTerminator(a1, (mlir::Operation *)v4, v32, v33);
          }
          else
          {
            uint64_t v34 = *(mlir::Block **)(v4 + 16);
            if (v34) {
              uint64_t v34 = (mlir::Block *)mlir::Block::getParentOp(v34);
            }
            uint64_t v35 = llvm::DefaultDoCastIfPossible<mlir::CallableOpInterface,mlir::Operation *,llvm::CastInfo<mlir::CallableOpInterface,mlir::Operation *,void>>::doCastIfPossible((uint64_t)v34);
            if (v35) {
              mlir::dataflow::DeadCodeAnalysis::visitCallableTerminator((uint64_t)a1, v4, v35);
            }
          }
        }
      }
    }
    if (!*(_DWORD *)(v4 + 40)) {
      return 1;
    }
    unint64_t v36 = (Operation *)llvm::DefaultDoCastIfPossible<mlir::BranchOpInterface,mlir::Operation *,llvm::CastInfo<mlir::BranchOpInterface,mlir::Operation *,void>>::doCastIfPossible(v4);
    if (v36)
    {
      mlir::dataflow::DeadCodeAnalysis::visitBranchOperation((mlir::dataflow::DeadCodeAnalysis *)a1, v36, v37);
      return 1;
    }
    mlir::SuccessorRange::SuccessorRange((unint64_t *)&v43, (Operation *)v4);
    uint64_t v38 = v44;
    if (!v44) {
      return 1;
    }
    uint64_t v39 = (mlir::Block **)((char *)v43 + 24);
    uint64_t v2 = 1;
    do
    {
      uint64_t v40 = *v39;
      v39 += 4;
      mlir::dataflow::DeadCodeAnalysis::markEdgeLive((mlir::dataflow::DeadCodeAnalysis *)a1, *(mlir::Block **)(v4 + 16), v40);
      --v38;
    }
    while (v38);
  }
  else
  {
    LoCC_SHA256_CTX c = mlir::ProgramPoint::getLoc((mlir::ProgramPoint *)v52);
    int64_t v41 = "unknown program point kind";
    __int16 v42 = 259;
    mlir::emitError(Loc, (uint64_t)&v41, (uint64_t)&v43);
    uint64_t v2 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v43);
    if (v43) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v43);
    }
    if (v51)
    {
      uint64_t v11 = __p;
      if (__p)
      {
        int v12 = v50;
        int v13 = __p;
        if (v50 != __p)
        {
          do
            int v12 = std::unique_ptr<mlir::Diagnostic>::~unique_ptr[abi:nn180100](v12 - 1);
          while (v12 != v11);
          int v13 = __p;
        }
        uint64_t v50 = v11;
        operator delete(v13);
      }
      unsigned int v14 = v47;
      if (v47)
      {
        uint64_t v15 = v48;
        uint64_t v16 = v47;
        if (v48 != v47)
        {
          do
          {
            uint64_t v18 = *--v15;
            uint64_t v17 = v18;
            void *v15 = 0;
            if (v18) {
              MEMORY[0x21667D390](v17, 0x1000C8077774924);
            }
          }
          while (v15 != v14);
          uint64_t v16 = v47;
        }
        uint64_t v48 = v14;
        operator delete(v16);
      }
      if (v45 != &v46) {
        free(v45);
      }
    }
  }
  return v2;
}

uint64_t mlir::dataflow::DeadCodeAnalysis::visitCallOperation(uint64_t a1, uint64_t a2, uint64_t a3)
{
  v14[0] = a2;
  v14[1] = a3;
  unint64_t v4 = (mlir::SymbolOpInterface *)mlir::CallOpInterface::resolveCallable((uint64_t)v14, a1 + 24);
  if (v4
    && (uint64_t v6 = v4, mlir::SymbolOpInterface::classof(v4, v5))
    && ((uint64_t v7 = *(mlir::Operation **)(a1 + 16), v7 == v6) || mlir::Operation::isProperAncestor(v7, v6))
    && ((v15[0] = (const void *)llvm::DefaultDoCastIfPossible<mlir::CallableOpInterface,mlir::Operation *,llvm::CastInfo<mlir::CallableOpInterface,mlir::Operation *,void>>::doCastIfPossible((uint64_t)v6),
         v15[1] = v8,
         !v15[0])
     || mlir::MemoryMapperInterface::canMapOperands((mlir::MemoryMapperInterface *)v15)))
  {
    uint64_t v9 = mlir::DataFlowSolver::getOrCreateState<mlir::dataflow::PredecessorState,mlir::Operation *>(*(void *)(a1 + 8), (uint64_t)v6);
    v15[0] = (const void *)v14[0];
    BOOL v10 = llvm::SetVector<mlir::Operation *,llvm::SmallVector<mlir::Operation *,4u>,llvm::SmallPtrSet<mlir::Operation *,4u>,0u>::insert((llvm::SmallPtrSetImplBase *)(v9 + 64), v15);
    return mlir::DataFlowAnalysis::propagateIfChanged(a1, v9, v10);
  }
  else
  {
    uint64_t v12 = mlir::DataFlowSolver::getOrCreateState<mlir::dataflow::PredecessorState,mlir::Operation *>(*(void *)(a1 + 8), v14[0]);
    int v13 = *(unsigned __int8 *)(v12 + 56);
    *(unsigned char *)(v12 + 56) = 0;
    return mlir::DataFlowAnalysis::propagateIfChanged(a1, v12, v13);
  }
}

void mlir::dataflow::DeadCodeAnalysis::visitRegionBranchOperation(uint64_t *a1, void *a2, const void *a3)
{
  uint64_t v21 = *MEMORY[0x263EF8340];
  v13[0] = a2;
  v13[1] = a3;
  mlir::dataflow::DeadCodeAnalysis::getOperandValues((mlir::dataflow::DeadCodeAnalysis *)a1, (mlir::Operation *)a2, (uint64_t)&v17);
  if (!v20) {
    return;
  }
  unsigned int v14 = v16;
  uint64_t v15 = 0x200000000;
  mlir::RegionBranchOpInterface::getEntrySuccessorRegions(v13, (uint64_t)v17, v18, (uint64_t)&v14);
  unint64_t v4 = (uint64_t *)v14;
  if (!v15) {
    goto LABEL_15;
  }
  uint64_t v5 = (uint64_t *)((char *)v14 + 24 * v15);
  do
  {
    if (*v4)
    {
      uint64_t v9 = *(void *)(*v4 + 8);
      if (v9) {
        uint64_t v10 = v9 - 8;
      }
      else {
        uint64_t v10 = 0;
      }
      uint64_t v11 = (const char *)(v10 | 6);
      uint64_t v12 = mlir::DataFlowSolver::getOrCreateState<mlir::dataflow::Executable,mlir::ProgramPoint>(a1[1], (const char *)(v10 | 6));
      if (!v12[56])
      {
LABEL_4:
        int v6 = 1;
        *((unsigned char *)v12 + 56) = 1;
        goto LABEL_5;
      }
    }
    else
    {
      uint64_t v11 = (const char *)((unint64_t)v13[0] & 0xFFFFFFFFFFFFFFF9 | 2);
      uint64_t v12 = mlir::DataFlowSolver::getOrCreateState<mlir::dataflow::Executable,mlir::ProgramPoint>(a1[1], v11);
      if (!v12[56]) {
        goto LABEL_4;
      }
    }
    int v6 = 0;
LABEL_5:
    mlir::DataFlowAnalysis::propagateIfChanged((uint64_t)a1, (uint64_t)v12, v6);
    uint64_t v7 = mlir::DataFlowSolver::getOrCreateState<mlir::dataflow::PredecessorState,mlir::ProgramPoint>(a1[1], v11);
    int v8 = mlir::dataflow::PredecessorState::join((uint64_t)v7, v13[0], v4[1], v4[2]);
    mlir::DataFlowAnalysis::propagateIfChanged((uint64_t)a1, (uint64_t)v7, v8);
    v4 += 3;
  }
  while (v4 != v5);
  unint64_t v4 = (uint64_t *)v14;
LABEL_15:
  if (v4 != (uint64_t *)v16) {
    free(v4);
  }
  if (v20)
  {
    if (v17 != &v19) {
      free(v17);
    }
  }
}

void mlir::dataflow::DeadCodeAnalysis::visitRegionTerminator(uint64_t *a1, mlir::Operation *a2, uint64_t a3, uint64_t a4)
{
  uint64_t v31 = *MEMORY[0x263EF8340];
  v23[0] = a3;
  v23[1] = a4;
  mlir::dataflow::DeadCodeAnalysis::getOperandValues((mlir::dataflow::DeadCodeAnalysis *)a1, a2, (uint64_t)&v27);
  if (!v30) {
    return;
  }
  uint64_t v24 = v26;
  uint64_t v25 = 0x200000000;
  v22[0] = llvm::DefaultDoCastIfPossible<mlir::RegionBranchTerminatorOpInterface,mlir::Operation *,llvm::CastInfo<mlir::RegionBranchTerminatorOpInterface,mlir::Operation *,void>>::doCastIfPossible((uint64_t)a2);
  v22[1] = v6;
  if (!v22[0])
  {
    uint64_t v9 = (mlir::Block *)*((void *)a2 + 2);
    if (v9) {
      unint64_t Parent = mlir::Block::getParent(v9);
    }
    else {
      unint64_t Parent = 0;
    }
    mlir::BranchOpInterface::getSuccessorForOperands(v23, Parent, (uint64_t)&v24);
    uint64_t v7 = (uint64_t *)v24;
    unsigned int v8 = v25;
    if (!v25) {
      goto LABEL_24;
    }
LABEL_9:
    uint64_t v11 = &v7[3 * v8];
    do
    {
      uint64_t v15 = *v7;
      if (*v7)
      {
        uint64_t v16 = *(void *)(v15 + 8);
        if (v16) {
          uint64_t v17 = v16 - 8;
        }
        else {
          uint64_t v17 = 0;
        }
        uint64_t v18 = mlir::DataFlowSolver::getOrCreateState<mlir::dataflow::Executable,mlir::Block *>(a1[1], v17);
        if (*(unsigned char *)(v18 + 56))
        {
          int v19 = 0;
        }
        else
        {
          int v19 = 1;
          *(unsigned char *)(v18 + 56) = 1;
        }
        mlir::DataFlowAnalysis::propagateIfChanged((uint64_t)a1, v18, v19);
        uint64_t v20 = *(void *)(v15 + 8);
        if (v20) {
          uint64_t v21 = v20 - 8;
        }
        else {
          uint64_t v21 = 0;
        }
        uint64_t v12 = mlir::DataFlowSolver::getOrCreateState<mlir::dataflow::PredecessorState,mlir::Block *>(a1[1], v21);
      }
      else
      {
        uint64_t v12 = mlir::DataFlowSolver::getOrCreateState<mlir::dataflow::PredecessorState,mlir::Operation *>(a1[1], v23[0]);
      }
      uint64_t v13 = v12;
      int v14 = mlir::dataflow::PredecessorState::join(v12, a2, v7[1], v7[2]);
      mlir::DataFlowAnalysis::propagateIfChanged((uint64_t)a1, v13, v14);
      v7 += 3;
    }
    while (v7 != v11);
    uint64_t v7 = (uint64_t *)v24;
    goto LABEL_24;
  }
  mlir::RegionBranchOpInterface::getEntrySuccessorRegions(v22, (uint64_t)v27, v28, (uint64_t)&v24);
  uint64_t v7 = (uint64_t *)v24;
  unsigned int v8 = v25;
  if (v25) {
    goto LABEL_9;
  }
LABEL_24:
  if (v7 != (uint64_t *)v26) {
    free(v7);
  }
  if (v30)
  {
    if (v27 != &v29) {
      free(v27);
    }
  }
}

uint64_t mlir::dataflow::DeadCodeAnalysis::visitCallableTerminator(uint64_t a1, unint64_t a2, uint64_t a3)
{
  unint64_t v5 = a2 & 0xFFFFFFFFFFFFFFF9 | 2;
  uint64_t v6 = mlir::DataFlowSolver::getOrCreateState<mlir::dataflow::PredecessorState,mlir::Operation *>(*(void *)(a1 + 8), a3);
  mlir::DataFlowAnalysis::addDependency(a1, v6, v5);
  uint64_t result = mlir::OperationName::hasTrait<mlir::OpTrait::ReturnLike>((void *)(a2 + 48));
  uint64_t v8 = *(unsigned int *)(v6 + 136);
  if (v8)
  {
    uint64_t v9 = *(uint64_t **)(v6 + 128);
    if (result)
    {
      uint64_t v10 = 8 * v8;
      do
      {
        uint64_t v11 = *v9++;
        uint64_t v12 = mlir::DataFlowSolver::getOrCreateState<mlir::dataflow::PredecessorState,mlir::Operation *>(*(void *)(a1 + 8), v11);
        unint64_t v18 = a2;
        BOOL v13 = llvm::SetVector<mlir::Operation *,llvm::SmallVector<mlir::Operation *,4u>,llvm::SmallPtrSet<mlir::Operation *,4u>,0u>::insert((llvm::SmallPtrSetImplBase *)(v12 + 64), (const void **)&v18);
        uint64_t result = mlir::DataFlowAnalysis::propagateIfChanged(a1, v12, v13);
        v10 -= 8;
      }
      while (v10);
    }
    else
    {
      uint64_t v14 = 8 * v8;
      do
      {
        uint64_t v15 = *v9++;
        uint64_t v16 = mlir::DataFlowSolver::getOrCreateState<mlir::dataflow::PredecessorState,mlir::Operation *>(*(void *)(a1 + 8), v15);
        int v17 = *(unsigned __int8 *)(v16 + 56);
        *(unsigned char *)(v16 + 56) = 0;
        uint64_t result = mlir::DataFlowAnalysis::propagateIfChanged(a1, v16, v17);
        v14 -= 8;
      }
      while (v14);
    }
  }
  return result;
}

void mlir::dataflow::DeadCodeAnalysis::visitBranchOperation(mlir::dataflow::DeadCodeAnalysis *a1, Operation *a2, Operation *a3)
{
  uint64_t v15 = *MEMORY[0x263EF8340];
  v8[0] = a2;
  v8[1] = a3;
  mlir::dataflow::DeadCodeAnalysis::getOperandValues(a1, a2, (uint64_t)&v11);
  if (v14)
  {
    SuccessorForOperands = (mlir::Block *)mlir::BranchOpInterface::getSuccessorForOperands(v8, (uint64_t)v11, v12);
    if (SuccessorForOperands)
    {
      mlir::dataflow::DeadCodeAnalysis::markEdgeLive(a1, *((mlir::Block **)v8[0] + 2), SuccessorForOperands);
    }
    else
    {
      mlir::SuccessorRange::SuccessorRange(&v9, v8[0]);
      uint64_t v5 = v10;
      if (v10)
      {
        uint64_t v6 = (mlir::Block **)(v9 + 24);
        do
        {
          uint64_t v7 = *v6;
          v6 += 4;
          mlir::dataflow::DeadCodeAnalysis::markEdgeLive(a1, *((mlir::Block **)v8[0] + 2), v7);
          --v5;
        }
        while (v5);
      }
    }
    if (v14)
    {
      if (v11 != &v13) {
        free(v11);
      }
    }
  }
}

void mlir::dataflow::DeadCodeAnalysis::getOperandValues(mlir::dataflow::DeadCodeAnalysis *this@<X0>, mlir::Operation *a2@<X1>, uint64_t a3@<X8>)
{
  v22[6] = *MEMORY[0x263EF8340];
  uint64_t v20 = v22;
  uint64_t v21 = 0x600000000;
  if ((*((unsigned char *)a2 + 46) & 0x80) == 0) {
    goto LABEL_12;
  }
  unint64_t v6 = *((unsigned int *)a2 + 17);
  if (v6 >= 7)
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v20, v22, v6, 8);
    if ((*((unsigned char *)a2 + 46) & 0x80) == 0) {
      goto LABEL_12;
    }
    LODWORD(v6) = *((_DWORD *)a2 + 17);
  }
  if (v6)
  {
    uint64_t v7 = v6;
    uint64_t v8 = (uint64_t *)(*((void *)a2 + 9) + 24);
    while (1)
    {
      uint64_t v9 = mlir::DataFlowSolver::getOrCreateState<mlir::dataflow::Lattice<mlir::dataflow::ConstantValue>,mlir::Value>(*((void *)this + 1), *v8);
      int v19 = this;
      llvm::SetVector<mlir::Operation *,llvm::SmallVector<mlir::Operation *,4u>,llvm::SmallPtrSet<mlir::Operation *,4u>,0u>::insert((llvm::SmallPtrSetImplBase *)(v9 + 56), &v19);
      if (!*(unsigned char *)(v9 + 176)) {
        break;
      }
      uint64_t v10 = *(void *)(v9 + 168);
      uint64_t v11 = v21;
      if (v21 >= (unint64_t)HIDWORD(v21))
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v20, v22, v21 + 1, 8);
        uint64_t v11 = v21;
      }
      *((void *)v20 + v11) = v10;
      unsigned int v12 = v21 + 1;
      LODWORD(v21) = v21 + 1;
      v8 += 4;
      if (!--v7) {
        goto LABEL_13;
      }
    }
    char v14 = 0;
    *(unsigned char *)a3 = 0;
    goto LABEL_18;
  }
LABEL_12:
  unsigned int v12 = v21;
LABEL_13:
  uint64_t v13 = (void *)(a3 + 16);
  *(void *)a3 = a3 + 16;
  *(void *)(a3 + 8) = 0x600000000;
  char v14 = 1;
  if (!v12 || &v20 == (void **)a3)
  {
LABEL_18:
    *(unsigned char *)(a3 + 64) = v14;
    uint64_t v16 = v20;
    if (v20 == v22) {
      return;
    }
    goto LABEL_19;
  }
  if (v20 != v22)
  {
    *(void *)a3 = v20;
    int v15 = HIDWORD(v21);
    *(_DWORD *)(a3 + 8) = v12;
    *(_DWORD *)(a3 + 12) = v15;
    uint64_t v20 = v22;
    HIDWORD(v21) = 0;
    goto LABEL_27;
  }
  if (v12 < 7)
  {
    unint64_t v18 = v22;
    unsigned int v17 = v12;
    goto LABEL_25;
  }
  llvm::SmallVectorBase<unsigned int>::grow_pod(a3, (void *)(a3 + 16), v12, 8);
  unsigned int v17 = v21;
  if (v21)
  {
    unint64_t v18 = v20;
    uint64_t v13 = *(void **)a3;
LABEL_25:
    memcpy(v13, v18, 8 * v17);
  }
  *(_DWORD *)(a3 + 8) = v12;
LABEL_27:
  LODWORD(v21) = 0;
  *(unsigned char *)(a3 + 64) = 1;
  uint64_t v16 = v20;
  if (v20 == v22) {
    return;
  }
LABEL_19:
  free(v16);
}

void mlir::dataflow::Executable::~Executable(mlir::dataflow::Executable *this)
{
  *(void *)this = &unk_26C3801B0;
  uint64_t v2 = (char *)*((void *)this + 16);
  if (v2 != (char *)this + 144) {
    free(v2);
  }
  uint64_t v3 = (void *)*((void *)this + 9);
  if (v3 != *((void **)this + 8)) {
    free(v3);
  }

  mlir::AnalysisState::~AnalysisState(this);
}

{
  char *v2;
  void *v3;

  *(void *)this = &unk_26C3801B0;
  uint64_t v2 = (char *)*((void *)this + 16);
  if (v2 != (char *)this + 144) {
    free(v2);
  }
  uint64_t v3 = (void *)*((void *)this + 9);
  if (v3 != *((void **)this + 8)) {
    free(v3);
  }
  mlir::AnalysisState::~AnalysisState(this);
}

void sub_2113C9300()
{
  JUMPOUT(0x21667D3C0);
}

void mlir::dataflow::PredecessorState::~PredecessorState(llvm **this)
{
  *this = (llvm *)&unk_26C380210;
  llvm::deallocate_buffer(this[22], (void *)(24 * *((unsigned int *)this + 48)));
}

{
  *this = (llvm *)&unk_26C380210;
  llvm::deallocate_buffer(this[22], (void *)(24 * *((unsigned int *)this + 48)));
}

void sub_2113C9374(int a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12)
{
  uint64_t v13 = (void *)*((void *)v12 + 16);
  if (v13 != (void *)((char *)v12 + 144)) {
    free(v13);
  }
  char v14 = (void *)*((void *)v12 + 9);
  if (v14 != *((void **)v12 + 8)) {
    free(v14);
  }
  mlir::AnalysisState::~AnalysisState(v12);
}

void sub_2113C9400()
{
  uint64_t v1 = (void *)*((void *)v0 + 16);
  if (v1 != (void *)((char *)v0 + 144)) {
    free(v1);
  }
  uint64_t v2 = (void *)*((void *)v0 + 9);
  if (v2 != *((void **)v0 + 8)) {
    free(v2);
  }
  mlir::AnalysisState::~AnalysisState(v0);
}

void sub_2113C942C()
{
  JUMPOUT(0x21667D3C0);
}

void mlir::dataflow::CFGEdge::~CFGEdge(mlir::dataflow::CFGEdge *this)
{
  ZinIrHalH13g::~ZinIrHalH13g(this);

  JUMPOUT(0x21667D3C0);
}

void mlir::dataflow::DeadCodeAnalysis::~DeadCodeAnalysis(mlir::dataflow::DeadCodeAnalysis *this)
{
  *(void *)this = &unk_26C3801E0;
  uint64_t v2 = *((unsigned int *)this + 10);
  uint64_t v3 = (llvm *)*((void *)this + 3);
  if (v2)
  {
    unint64_t v4 = (uint64_t *)((char *)v3 + 8);
    uint64_t v5 = 16 * v2;
    do
    {
      if ((*(v4 - 1) | 0x1000) != 0xFFFFFFFFFFFFF000)
      {
        uint64_t v6 = *v4;
        *unint64_t v4 = 0;
        if (v6) {
          llvm::deallocate_buffer(*(llvm **)(v6 + 8), (void *)(16 * *(unsigned int *)(v6 + 24)));
        }
      }
      v4 += 2;
      v5 -= 16;
    }
    while (v5);
    uint64_t v3 = (llvm *)*((void *)this + 3);
    uint64_t v7 = (void *)(16 * *((unsigned int *)this + 10));
  }
  else
  {
    uint64_t v7 = 0;
  }
  llvm::deallocate_buffer(v3, v7);
}

{
  uint64_t v2;
  llvm *v3;
  uint64_t *v4;
  uint64_t v5;
  uint64_t v6;
  void *v7;

  *(void *)this = &unk_26C3801E0;
  uint64_t v2 = *((unsigned int *)this + 10);
  uint64_t v3 = (llvm *)*((void *)this + 3);
  if (v2)
  {
    unint64_t v4 = (uint64_t *)((char *)v3 + 8);
    uint64_t v5 = 16 * v2;
    do
    {
      if ((*(v4 - 1) | 0x1000) != 0xFFFFFFFFFFFFF000)
      {
        uint64_t v6 = *v4;
        *unint64_t v4 = 0;
        if (v6) {
          llvm::deallocate_buffer(*(llvm **)(v6 + 8), (void *)(16 * *(unsigned int *)(v6 + 24)));
        }
      }
      v4 += 2;
      v5 -= 16;
    }
    while (v5);
    uint64_t v3 = (llvm *)*((void *)this + 3);
    uint64_t v7 = (void *)(16 * *((unsigned int *)this + 10));
  }
  else
  {
    uint64_t v7 = 0;
  }
  llvm::deallocate_buffer(v3, v7);
}

void sub_2113C9554(int a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14)
{
  ZinIrHalH13g::~ZinIrHalH13g(v14);
}

void sub_2113C9638(int a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13, uint64_t a14)
{
  ZinIrHalH13g::~ZinIrHalH13g(v14);
  JUMPOUT(0x21667D3C0);
}

BOOL _ZN4llvm3isaIN4mlir23RegionBranchOpInterfaceENS1_19CallableOpInterfaceEJEPNS1_9OperationEEEbRKT2_(uint64_t *a1)
{
  uint64_t v2 = *a1;
  uint64_t v3 = *(void *)(*a1 + 48);
  unint64_t v4 = *(void **)(v3 + 16);
  BOOL v5 = v4 == &mlir::detail::TypeIDResolver<void,void>::id;
  if (v4 == &mlir::detail::TypeIDResolver<void,void>::id) {
    uint64_t v6 = 0;
  }
  else {
    uint64_t v6 = *(void *)(*a1 + 48);
  }
  if (v5)
  {
    uint64_t v18 = *(void *)(v3 + 8);
    uint64_t Values = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)&v18);
    if (!Values || !mlir::Dialect::getRegisteredInterfaceForOp<mlir::RegionBranchOpInterface>(Values, v3)) {
      goto LABEL_11;
    }
    return 1;
  }
  unint64_t v7 = v6 | v3 & 0xFFFFFFFFFFFFFF00;
  if (mlir::detail::InterfaceMap::lookup<mlir::RegionBranchOpInterface>(v7 + 32)) {
    return 1;
  }
  if (mlir::Dialect::getRegisteredInterfaceForOp<mlir::RegionBranchOpInterface>(*(void *)(v7 + 24), *(void *)(v2 + 48)))
  {
    return 1;
  }
LABEL_11:
  uint64_t v10 = *a1;
  uint64_t v11 = *(void *)(*a1 + 48);
  unsigned int v12 = *(void **)(v11 + 16);
  BOOL v13 = v12 == &mlir::detail::TypeIDResolver<void,void>::id;
  if (v12 == &mlir::detail::TypeIDResolver<void,void>::id) {
    uint64_t v14 = 0;
  }
  else {
    uint64_t v14 = v11;
  }
  if (v13)
  {
    uint64_t v18 = *(void *)(v11 + 8);
    uint64_t v16 = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)&v18);
    if (v16)
    {
      uint64_t v17 = v11;
      goto LABEL_19;
    }
  }
  else
  {
    unint64_t v15 = v14 | v11 & 0xFFFFFFFFFFFFFF00;
    uint64_t v16 = mlir::detail::InterfaceMap::lookup<mlir::CallableOpInterface>(v15 + 32);
    if (!v16)
    {
      uint64_t v16 = *(void *)(v15 + 24);
      uint64_t v17 = *(void *)(v10 + 48);
LABEL_19:
      uint64_t v16 = mlir::Dialect::getRegisteredInterfaceForOp<mlir::CallableOpInterface>(v16, v17);
    }
  }
  return v16 != 0;
}

uint64_t mlir::Dialect::getRegisteredInterfaceForOp<mlir::RegionBranchOpInterface>(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = a2;
  uint64_t v3 = &unk_267770000;
  {
    uint64_t v15 = a1;
    uint64_t v3 = (void *)&unk_267770000;
    int v6 = v5;
    uint64_t v2 = a2;
    a1 = v15;
    if (v6)
    {
      uint64_t v16 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::RegionBranchOpInterface]";
      unint64_t v17 = 79;
      unint64_t v7 = llvm::StringRef::find((uint64_t *)&v16, "DesiredTypeName = ", 0x12uLL, 0);
      if (v17 >= v7) {
        unint64_t v8 = v7;
      }
      else {
        unint64_t v8 = v17;
      }
      uint64_t v9 = &v16[v8];
      unint64_t v10 = v17 - v8;
      if (v17 - v8 >= 0x12) {
        uint64_t v11 = 18;
      }
      else {
        uint64_t v11 = v17 - v8;
      }
      unint64_t v12 = v10 - v11;
      if (v12 >= v12 - 1) {
        uint64_t v13 = v12 - 1;
      }
      else {
        uint64_t v13 = v12;
      }
      mlir::detail::TypeIDResolver<mlir::RegionBranchOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v9[v11], v13);
      uint64_t v3 = (void *)&unk_267770000;
      uint64_t v2 = a2;
      a1 = v15;
    }
  }
  return (*(uint64_t (**)(uint64_t, void, uint64_t))(*(void *)a1 + 104))(a1, v3[397], v2);
}

uint64_t mlir::detail::InterfaceMap::lookup<mlir::RegionBranchOpInterface>(uint64_t a1)
{
  uint64_t v1 = &unk_267770000;
  {
    uint64_t v20 = a1;
    uint64_t v1 = (void *)&unk_267770000;
    int v12 = v11;
    a1 = v20;
    if (v12)
    {
      uint64_t v21 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::RegionBranchOpInterface]";
      unint64_t v22 = 79;
      unint64_t v13 = llvm::StringRef::find((uint64_t *)&v21, "DesiredTypeName = ", 0x12uLL, 0);
      if (v22 >= v13) {
        unint64_t v14 = v13;
      }
      else {
        unint64_t v14 = v22;
      }
      uint64_t v15 = &v21[v14];
      unint64_t v16 = v22 - v14;
      if (v22 - v14 >= 0x12) {
        uint64_t v17 = 18;
      }
      else {
        uint64_t v17 = v22 - v14;
      }
      unint64_t v18 = v16 - v17;
      if (v18 >= v18 - 1) {
        uint64_t v19 = v18 - 1;
      }
      else {
        uint64_t v19 = v18;
      }
      mlir::detail::TypeIDResolver<mlir::RegionBranchOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v15[v17], v19);
      uint64_t v1 = (void *)&unk_267770000;
      a1 = v20;
    }
  }
  unint64_t v2 = *(unsigned int *)(a1 + 8);
  if (!v2) {
    return 0;
  }
  unint64_t v3 = v1[397];
  unint64_t v4 = *(void **)a1;
  uint64_t v5 = *(void *)a1 + 16 * v2;
  do
  {
    unint64_t v6 = v2 >> 1;
    unint64_t v7 = &v4[2 * (v2 >> 1)];
    unint64_t v9 = *v7;
    unint64_t v8 = v7 + 2;
    v2 += ~(v2 >> 1);
    if (v9 < v3) {
      unint64_t v4 = v8;
    }
    else {
      unint64_t v2 = v6;
    }
  }
  while (v2);
  if (v4 != (void *)v5 && *v4 == v3) {
    return v4[1];
  }
  else {
    return 0;
  }
}

uint64_t mlir::Dialect::getRegisteredInterfaceForOp<mlir::CallableOpInterface>(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = a2;
  unint64_t v3 = &unk_267770000;
  {
    uint64_t v15 = a1;
    unint64_t v3 = (void *)&unk_267770000;
    int v6 = v5;
    uint64_t v2 = a2;
    a1 = v15;
    if (v6)
    {
      unint64_t v16 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::CallableOpInterface]";
      unint64_t v17 = 75;
      unint64_t v7 = llvm::StringRef::find((uint64_t *)&v16, "DesiredTypeName = ", 0x12uLL, 0);
      if (v17 >= v7) {
        unint64_t v8 = v7;
      }
      else {
        unint64_t v8 = v17;
      }
      unint64_t v9 = &v16[v8];
      unint64_t v10 = v17 - v8;
      if (v17 - v8 >= 0x12) {
        uint64_t v11 = 18;
      }
      else {
        uint64_t v11 = v17 - v8;
      }
      unint64_t v12 = v10 - v11;
      if (v12 >= v12 - 1) {
        uint64_t v13 = v12 - 1;
      }
      else {
        uint64_t v13 = v12;
      }
      mlir::detail::TypeIDResolver<mlir::CallableOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v9[v11], v13);
      unint64_t v3 = (void *)&unk_267770000;
      uint64_t v2 = a2;
      a1 = v15;
    }
  }
  return (*(uint64_t (**)(uint64_t, void, uint64_t))(*(void *)a1 + 104))(a1, v3[399], v2);
}

uint64_t mlir::detail::InterfaceMap::lookup<mlir::CallableOpInterface>(uint64_t a1)
{
  uint64_t v1 = &unk_267770000;
  {
    uint64_t v20 = a1;
    uint64_t v1 = (void *)&unk_267770000;
    int v12 = v11;
    a1 = v20;
    if (v12)
    {
      uint64_t v21 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::CallableOpInterface]";
      unint64_t v22 = 75;
      unint64_t v13 = llvm::StringRef::find((uint64_t *)&v21, "DesiredTypeName = ", 0x12uLL, 0);
      if (v22 >= v13) {
        unint64_t v14 = v13;
      }
      else {
        unint64_t v14 = v22;
      }
      uint64_t v15 = &v21[v14];
      unint64_t v16 = v22 - v14;
      if (v22 - v14 >= 0x12) {
        uint64_t v17 = 18;
      }
      else {
        uint64_t v17 = v22 - v14;
      }
      unint64_t v18 = v16 - v17;
      if (v18 >= v18 - 1) {
        uint64_t v19 = v18 - 1;
      }
      else {
        uint64_t v19 = v18;
      }
      mlir::detail::TypeIDResolver<mlir::CallableOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v15[v17], v19);
      uint64_t v1 = (void *)&unk_267770000;
      a1 = v20;
    }
  }
  unint64_t v2 = *(unsigned int *)(a1 + 8);
  if (!v2) {
    return 0;
  }
  unint64_t v3 = v1[399];
  unint64_t v4 = *(void **)a1;
  uint64_t v5 = *(void *)a1 + 16 * v2;
  do
  {
    unint64_t v6 = v2 >> 1;
    unint64_t v7 = &v4[2 * (v2 >> 1)];
    unint64_t v9 = *v7;
    unint64_t v8 = v7 + 2;
    v2 += ~(v2 >> 1);
    if (v9 < v3) {
      unint64_t v4 = v8;
    }
    else {
      unint64_t v2 = v6;
    }
  }
  while (v2);
  if (v4 != (void *)v5 && *v4 == v3) {
    return v4[1];
  }
  else {
    return 0;
  }
}

uint64_t llvm::DefaultDoCastIfPossible<mlir::CallOpInterface,mlir::Operation *,llvm::CastInfo<mlir::CallOpInterface,mlir::Operation *,void>>::doCastIfPossible(uint64_t a1)
{
  uint64_t v1 = a1;
  uint64_t v2 = *(void *)(a1 + 48);
  unint64_t v3 = *(void **)(v2 + 16);
  BOOL v4 = v3 == &mlir::detail::TypeIDResolver<void,void>::id;
  if (v3 == &mlir::detail::TypeIDResolver<void,void>::id) {
    uint64_t v5 = 0;
  }
  else {
    uint64_t v5 = *(void *)(a1 + 48);
  }
  if (v4)
  {
    uint64_t v16 = *(void *)(v2 + 8);
    uint64_t Values = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)&v16);
    if (!Values || !mlir::Dialect::getRegisteredInterfaceForOp<mlir::CallOpInterface>(Values, v2)) {
      return 0;
    }
  }
  else
  {
    unint64_t v6 = v5 | v2 & 0xFFFFFFFFFFFFFF00;
    if (!mlir::detail::InterfaceMap::lookup<mlir::CallOpInterface>(v6 + 32)
      && !mlir::Dialect::getRegisteredInterfaceForOp<mlir::CallOpInterface>(*(void *)(v6 + 24), *(void *)(v1 + 48)))
    {
      return 0;
    }
  }
  uint64_t v8 = *(void *)(v1 + 48);
  unint64_t v9 = *(void **)(v8 + 16);
  BOOL v10 = v9 == &mlir::detail::TypeIDResolver<void,void>::id;
  if (v9 == &mlir::detail::TypeIDResolver<void,void>::id) {
    uint64_t v11 = 0;
  }
  else {
    uint64_t v11 = *(void *)(v1 + 48);
  }
  if (v10)
  {
    uint64_t v16 = *(void *)(v8 + 8);
    uint64_t v14 = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)&v16);
    if (!v14) {
      return v1;
    }
    uint64_t v15 = v8;
  }
  else
  {
    unint64_t v12 = v11 | v8 & 0xFFFFFFFFFFFFFF00;
    if (mlir::detail::InterfaceMap::lookup<mlir::CallOpInterface>(v12 + 32)) {
      return v1;
    }
    uint64_t v14 = *(void *)(v12 + 24);
    uint64_t v15 = *(void *)(v1 + 48);
  }
  mlir::Dialect::getRegisteredInterfaceForOp<mlir::CallOpInterface>(v14, v15);
  return v1;
}

uint64_t mlir::Dialect::getRegisteredInterfaceForOp<mlir::CallOpInterface>(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = a2;
  unint64_t v3 = &unk_267770000;
  {
    uint64_t v15 = a1;
    unint64_t v3 = (void *)&unk_267770000;
    int v6 = v5;
    uint64_t v2 = a2;
    a1 = v15;
    if (v6)
    {
      uint64_t v16 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::CallOpInterface]";
      unint64_t v17 = 71;
      unint64_t v7 = llvm::StringRef::find((uint64_t *)&v16, "DesiredTypeName = ", 0x12uLL, 0);
      if (v17 >= v7) {
        unint64_t v8 = v7;
      }
      else {
        unint64_t v8 = v17;
      }
      unint64_t v9 = &v16[v8];
      unint64_t v10 = v17 - v8;
      if (v17 - v8 >= 0x12) {
        uint64_t v11 = 18;
      }
      else {
        uint64_t v11 = v17 - v8;
      }
      unint64_t v12 = v10 - v11;
      if (v12 >= v12 - 1) {
        uint64_t v13 = v12 - 1;
      }
      else {
        uint64_t v13 = v12;
      }
      mlir::detail::TypeIDResolver<mlir::CallOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v9[v11], v13);
      unint64_t v3 = (void *)&unk_267770000;
      uint64_t v2 = a2;
      a1 = v15;
    }
  }
  return (*(uint64_t (**)(uint64_t, void, uint64_t))(*(void *)a1 + 104))(a1, v3[401], v2);
}

uint64_t mlir::detail::InterfaceMap::lookup<mlir::CallOpInterface>(uint64_t a1)
{
  uint64_t v1 = &unk_267770000;
  {
    uint64_t v20 = a1;
    uint64_t v1 = (void *)&unk_267770000;
    int v12 = v11;
    a1 = v20;
    if (v12)
    {
      uint64_t v21 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::CallOpInterface]";
      unint64_t v22 = 71;
      unint64_t v13 = llvm::StringRef::find((uint64_t *)&v21, "DesiredTypeName = ", 0x12uLL, 0);
      if (v22 >= v13) {
        unint64_t v14 = v13;
      }
      else {
        unint64_t v14 = v22;
      }
      uint64_t v15 = &v21[v14];
      unint64_t v16 = v22 - v14;
      if (v22 - v14 >= 0x12) {
        uint64_t v17 = 18;
      }
      else {
        uint64_t v17 = v22 - v14;
      }
      unint64_t v18 = v16 - v17;
      if (v18 >= v18 - 1) {
        uint64_t v19 = v18 - 1;
      }
      else {
        uint64_t v19 = v18;
      }
      mlir::detail::TypeIDResolver<mlir::CallOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v15[v17], v19);
      uint64_t v1 = (void *)&unk_267770000;
      a1 = v20;
    }
  }
  unint64_t v2 = *(unsigned int *)(a1 + 8);
  if (!v2) {
    return 0;
  }
  unint64_t v3 = v1[401];
  BOOL v4 = *(void **)a1;
  uint64_t v5 = *(void *)a1 + 16 * v2;
  do
  {
    unint64_t v6 = v2 >> 1;
    unint64_t v7 = &v4[2 * (v2 >> 1)];
    unint64_t v9 = *v7;
    unint64_t v8 = v7 + 2;
    v2 += ~(v2 >> 1);
    if (v9 < v3) {
      BOOL v4 = v8;
    }
    else {
      unint64_t v2 = v6;
    }
  }
  while (v2);
  if (v4 != (void *)v5 && *v4 == v3) {
    return v4[1];
  }
  else {
    return 0;
  }
}

uint64_t llvm::DefaultDoCastIfPossible<mlir::RegionBranchOpInterface,mlir::Operation *,llvm::CastInfo<mlir::RegionBranchOpInterface,mlir::Operation *,void>>::doCastIfPossible(uint64_t a1)
{
  uint64_t v1 = a1;
  uint64_t v2 = *(void *)(a1 + 48);
  unint64_t v3 = *(void **)(v2 + 16);
  BOOL v4 = v3 == &mlir::detail::TypeIDResolver<void,void>::id;
  if (v3 == &mlir::detail::TypeIDResolver<void,void>::id) {
    uint64_t v5 = 0;
  }
  else {
    uint64_t v5 = *(void *)(a1 + 48);
  }
  if (v4)
  {
    uint64_t v16 = *(void *)(v2 + 8);
    uint64_t Values = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)&v16);
    if (!Values || !mlir::Dialect::getRegisteredInterfaceForOp<mlir::RegionBranchOpInterface>(Values, v2)) {
      return 0;
    }
  }
  else
  {
    unint64_t v6 = v5 | v2 & 0xFFFFFFFFFFFFFF00;
    if (!mlir::detail::InterfaceMap::lookup<mlir::RegionBranchOpInterface>(v6 + 32)
      && !mlir::Dialect::getRegisteredInterfaceForOp<mlir::RegionBranchOpInterface>(*(void *)(v6 + 24), *(void *)(v1 + 48)))
    {
      return 0;
    }
  }
  uint64_t v8 = *(void *)(v1 + 48);
  unint64_t v9 = *(void **)(v8 + 16);
  BOOL v10 = v9 == &mlir::detail::TypeIDResolver<void,void>::id;
  if (v9 == &mlir::detail::TypeIDResolver<void,void>::id) {
    uint64_t v11 = 0;
  }
  else {
    uint64_t v11 = *(void *)(v1 + 48);
  }
  if (v10)
  {
    uint64_t v16 = *(void *)(v8 + 8);
    uint64_t v14 = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)&v16);
    if (!v14) {
      return v1;
    }
    uint64_t v15 = v8;
  }
  else
  {
    unint64_t v12 = v11 | v8 & 0xFFFFFFFFFFFFFF00;
    if (mlir::detail::InterfaceMap::lookup<mlir::RegionBranchOpInterface>(v12 + 32)) {
      return v1;
    }
    uint64_t v14 = *(void *)(v12 + 24);
    uint64_t v15 = *(void *)(v1 + 48);
  }
  mlir::Dialect::getRegisteredInterfaceForOp<mlir::RegionBranchOpInterface>(v14, v15);
  return v1;
}

uint64_t llvm::DefaultDoCastIfPossible<mlir::CallableOpInterface,mlir::Operation *,llvm::CastInfo<mlir::CallableOpInterface,mlir::Operation *,void>>::doCastIfPossible(uint64_t a1)
{
  uint64_t v1 = a1;
  uint64_t v2 = *(void *)(a1 + 48);
  unint64_t v3 = *(void **)(v2 + 16);
  BOOL v4 = v3 == &mlir::detail::TypeIDResolver<void,void>::id;
  if (v3 == &mlir::detail::TypeIDResolver<void,void>::id) {
    uint64_t v5 = 0;
  }
  else {
    uint64_t v5 = *(void *)(a1 + 48);
  }
  if (v4)
  {
    uint64_t v16 = *(void *)(v2 + 8);
    uint64_t Values = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)&v16);
    if (!Values || !mlir::Dialect::getRegisteredInterfaceForOp<mlir::CallableOpInterface>(Values, v2)) {
      return 0;
    }
  }
  else
  {
    unint64_t v6 = v5 | v2 & 0xFFFFFFFFFFFFFF00;
    if (!mlir::detail::InterfaceMap::lookup<mlir::CallableOpInterface>(v6 + 32)
      && !mlir::Dialect::getRegisteredInterfaceForOp<mlir::CallableOpInterface>(*(void *)(v6 + 24), *(void *)(v1 + 48)))
    {
      return 0;
    }
  }
  uint64_t v8 = *(void *)(v1 + 48);
  unint64_t v9 = *(void **)(v8 + 16);
  BOOL v10 = v9 == &mlir::detail::TypeIDResolver<void,void>::id;
  if (v9 == &mlir::detail::TypeIDResolver<void,void>::id) {
    uint64_t v11 = 0;
  }
  else {
    uint64_t v11 = *(void *)(v1 + 48);
  }
  if (v10)
  {
    uint64_t v16 = *(void *)(v8 + 8);
    uint64_t v14 = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)&v16);
    if (!v14) {
      return v1;
    }
    uint64_t v15 = v8;
  }
  else
  {
    unint64_t v12 = v11 | v8 & 0xFFFFFFFFFFFFFF00;
    if (mlir::detail::InterfaceMap::lookup<mlir::CallableOpInterface>(v12 + 32)) {
      return v1;
    }
    uint64_t v14 = *(void *)(v12 + 24);
    uint64_t v15 = *(void *)(v1 + 48);
  }
  mlir::Dialect::getRegisteredInterfaceForOp<mlir::CallableOpInterface>(v14, v15);
  return v1;
}

uint64_t llvm::DefaultDoCastIfPossible<mlir::BranchOpInterface,mlir::Operation *,llvm::CastInfo<mlir::BranchOpInterface,mlir::Operation *,void>>::doCastIfPossible(uint64_t a1)
{
  uint64_t v1 = a1;
  uint64_t v2 = *(void *)(a1 + 48);
  unint64_t v3 = *(void **)(v2 + 16);
  BOOL v4 = v3 == &mlir::detail::TypeIDResolver<void,void>::id;
  if (v3 == &mlir::detail::TypeIDResolver<void,void>::id) {
    uint64_t v5 = 0;
  }
  else {
    uint64_t v5 = *(void *)(a1 + 48);
  }
  if (v4)
  {
    uint64_t v16 = *(void *)(v2 + 8);
    uint64_t Values = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)&v16);
    if (!Values || !mlir::Dialect::getRegisteredInterfaceForOp<mlir::BranchOpInterface>(Values, v2)) {
      return 0;
    }
  }
  else
  {
    unint64_t v6 = v5 | v2 & 0xFFFFFFFFFFFFFF00;
    if (!mlir::detail::InterfaceMap::lookup<mlir::BranchOpInterface>(v6 + 32)
      && !mlir::Dialect::getRegisteredInterfaceForOp<mlir::BranchOpInterface>(*(void *)(v6 + 24), *(void *)(v1 + 48)))
    {
      return 0;
    }
  }
  uint64_t v8 = *(void *)(v1 + 48);
  unint64_t v9 = *(void **)(v8 + 16);
  BOOL v10 = v9 == &mlir::detail::TypeIDResolver<void,void>::id;
  if (v9 == &mlir::detail::TypeIDResolver<void,void>::id) {
    uint64_t v11 = 0;
  }
  else {
    uint64_t v11 = *(void *)(v1 + 48);
  }
  if (v10)
  {
    uint64_t v16 = *(void *)(v8 + 8);
    uint64_t v14 = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)&v16);
    if (!v14) {
      return v1;
    }
    uint64_t v15 = v8;
  }
  else
  {
    unint64_t v12 = v11 | v8 & 0xFFFFFFFFFFFFFF00;
    if (mlir::detail::InterfaceMap::lookup<mlir::BranchOpInterface>(v12 + 32)) {
      return v1;
    }
    uint64_t v14 = *(void *)(v12 + 24);
    uint64_t v15 = *(void *)(v1 + 48);
  }
  mlir::Dialect::getRegisteredInterfaceForOp<mlir::BranchOpInterface>(v14, v15);
  return v1;
}

uint64_t mlir::Dialect::getRegisteredInterfaceForOp<mlir::BranchOpInterface>(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = a2;
  unint64_t v3 = &unk_267770000;
  {
    uint64_t v15 = a1;
    unint64_t v3 = (void *)&unk_267770000;
    int v6 = v5;
    uint64_t v2 = a2;
    a1 = v15;
    if (v6)
    {
      uint64_t v16 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::BranchOpInterface]";
      unint64_t v17 = 73;
      unint64_t v7 = llvm::StringRef::find((uint64_t *)&v16, "DesiredTypeName = ", 0x12uLL, 0);
      if (v17 >= v7) {
        unint64_t v8 = v7;
      }
      else {
        unint64_t v8 = v17;
      }
      unint64_t v9 = &v16[v8];
      unint64_t v10 = v17 - v8;
      if (v17 - v8 >= 0x12) {
        uint64_t v11 = 18;
      }
      else {
        uint64_t v11 = v17 - v8;
      }
      unint64_t v12 = v10 - v11;
      if (v12 >= v12 - 1) {
        uint64_t v13 = v12 - 1;
      }
      else {
        uint64_t v13 = v12;
      }
      mlir::detail::TypeIDResolver<mlir::BranchOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v9[v11], v13);
      unint64_t v3 = (void *)&unk_267770000;
      uint64_t v2 = a2;
      a1 = v15;
    }
  }
  return (*(uint64_t (**)(uint64_t, void, uint64_t))(*(void *)a1 + 104))(a1, v3[403], v2);
}

uint64_t mlir::detail::InterfaceMap::lookup<mlir::BranchOpInterface>(uint64_t a1)
{
  uint64_t v1 = &unk_267770000;
  {
    uint64_t v20 = a1;
    uint64_t v1 = (void *)&unk_267770000;
    int v12 = v11;
    a1 = v20;
    if (v12)
    {
      uint64_t v21 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::BranchOpInterface]";
      unint64_t v22 = 73;
      unint64_t v13 = llvm::StringRef::find((uint64_t *)&v21, "DesiredTypeName = ", 0x12uLL, 0);
      if (v22 >= v13) {
        unint64_t v14 = v13;
      }
      else {
        unint64_t v14 = v22;
      }
      uint64_t v15 = &v21[v14];
      unint64_t v16 = v22 - v14;
      if (v22 - v14 >= 0x12) {
        uint64_t v17 = 18;
      }
      else {
        uint64_t v17 = v22 - v14;
      }
      unint64_t v18 = v16 - v17;
      if (v18 >= v18 - 1) {
        uint64_t v19 = v18 - 1;
      }
      else {
        uint64_t v19 = v18;
      }
      mlir::detail::TypeIDResolver<mlir::BranchOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v15[v17], v19);
      uint64_t v1 = (void *)&unk_267770000;
      a1 = v20;
    }
  }
  unint64_t v2 = *(unsigned int *)(a1 + 8);
  if (!v2) {
    return 0;
  }
  unint64_t v3 = v1[403];
  BOOL v4 = *(void **)a1;
  uint64_t v5 = *(void *)a1 + 16 * v2;
  do
  {
    unint64_t v6 = v2 >> 1;
    unint64_t v7 = &v4[2 * (v2 >> 1)];
    unint64_t v9 = *v7;
    unint64_t v8 = v7 + 2;
    v2 += ~(v2 >> 1);
    if (v9 < v3) {
      BOOL v4 = v8;
    }
    else {
      unint64_t v2 = v6;
    }
  }
  while (v2);
  if (v4 != (void *)v5 && *v4 == v3) {
    return v4[1];
  }
  else {
    return 0;
  }
}

uint64_t llvm::DefaultDoCastIfPossible<mlir::RegionBranchTerminatorOpInterface,mlir::Operation *,llvm::CastInfo<mlir::RegionBranchTerminatorOpInterface,mlir::Operation *,void>>::doCastIfPossible(uint64_t a1)
{
  uint64_t v1 = a1;
  uint64_t v2 = *(void *)(a1 + 48);
  unint64_t v3 = *(void **)(v2 + 16);
  BOOL v4 = v3 == &mlir::detail::TypeIDResolver<void,void>::id;
  if (v3 == &mlir::detail::TypeIDResolver<void,void>::id) {
    uint64_t v5 = 0;
  }
  else {
    uint64_t v5 = *(void *)(a1 + 48);
  }
  if (v4)
  {
    uint64_t v16 = *(void *)(v2 + 8);
    uint64_t Values = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)&v16);
    if (!Values || !mlir::Dialect::getRegisteredInterfaceForOp<mlir::RegionBranchTerminatorOpInterface>(Values, v2)) {
      return 0;
    }
  }
  else
  {
    unint64_t v6 = v5 | v2 & 0xFFFFFFFFFFFFFF00;
    if (!mlir::detail::InterfaceMap::lookup<mlir::RegionBranchTerminatorOpInterface>(v6 + 32)
      && !mlir::Dialect::getRegisteredInterfaceForOp<mlir::RegionBranchTerminatorOpInterface>(*(void *)(v6 + 24), *(void *)(v1 + 48)))
    {
      return 0;
    }
  }
  uint64_t v8 = *(void *)(v1 + 48);
  unint64_t v9 = *(void **)(v8 + 16);
  BOOL v10 = v9 == &mlir::detail::TypeIDResolver<void,void>::id;
  if (v9 == &mlir::detail::TypeIDResolver<void,void>::id) {
    uint64_t v11 = 0;
  }
  else {
    uint64_t v11 = *(void *)(v1 + 48);
  }
  if (v10)
  {
    uint64_t v16 = *(void *)(v8 + 8);
    uint64_t v14 = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)&v16);
    if (!v14) {
      return v1;
    }
    uint64_t v15 = v8;
  }
  else
  {
    unint64_t v12 = v11 | v8 & 0xFFFFFFFFFFFFFF00;
    if (mlir::detail::InterfaceMap::lookup<mlir::RegionBranchTerminatorOpInterface>(v12 + 32)) {
      return v1;
    }
    uint64_t v14 = *(void *)(v12 + 24);
    uint64_t v15 = *(void *)(v1 + 48);
  }
  mlir::Dialect::getRegisteredInterfaceForOp<mlir::RegionBranchTerminatorOpInterface>(v14, v15);
  return v1;
}

uint64_t mlir::Dialect::getRegisteredInterfaceForOp<mlir::RegionBranchTerminatorOpInterface>(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = a2;
  unint64_t v3 = &unk_267770000;
  {
    uint64_t v15 = a1;
    unint64_t v3 = (void *)&unk_267770000;
    int v6 = v5;
    uint64_t v2 = a2;
    a1 = v15;
    if (v6)
    {
      uint64_t v16 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::RegionBranchTerminatorOpInterface]";
      unint64_t v17 = 89;
      unint64_t v7 = llvm::StringRef::find((uint64_t *)&v16, "DesiredTypeName = ", 0x12uLL, 0);
      if (v17 >= v7) {
        unint64_t v8 = v7;
      }
      else {
        unint64_t v8 = v17;
      }
      unint64_t v9 = &v16[v8];
      unint64_t v10 = v17 - v8;
      if (v17 - v8 >= 0x12) {
        uint64_t v11 = 18;
      }
      else {
        uint64_t v11 = v17 - v8;
      }
      unint64_t v12 = v10 - v11;
      if (v12 >= v12 - 1) {
        uint64_t v13 = v12 - 1;
      }
      else {
        uint64_t v13 = v12;
      }
      mlir::detail::TypeIDResolver<mlir::RegionBranchTerminatorOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v9[v11], v13);
      unint64_t v3 = (void *)&unk_267770000;
      uint64_t v2 = a2;
      a1 = v15;
    }
  }
  return (*(uint64_t (**)(uint64_t, void, uint64_t))(*(void *)a1 + 104))(a1, v3[405], v2);
}

uint64_t mlir::detail::InterfaceMap::lookup<mlir::RegionBranchTerminatorOpInterface>(uint64_t a1)
{
  uint64_t v1 = &unk_267770000;
  {
    uint64_t v20 = a1;
    uint64_t v1 = (void *)&unk_267770000;
    int v12 = v11;
    a1 = v20;
    if (v12)
    {
      uint64_t v21 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::RegionBranchTerminatorOpInterface]";
      unint64_t v22 = 89;
      unint64_t v13 = llvm::StringRef::find((uint64_t *)&v21, "DesiredTypeName = ", 0x12uLL, 0);
      if (v22 >= v13) {
        unint64_t v14 = v13;
      }
      else {
        unint64_t v14 = v22;
      }
      uint64_t v15 = &v21[v14];
      unint64_t v16 = v22 - v14;
      if (v22 - v14 >= 0x12) {
        uint64_t v17 = 18;
      }
      else {
        uint64_t v17 = v22 - v14;
      }
      unint64_t v18 = v16 - v17;
      if (v18 >= v18 - 1) {
        uint64_t v19 = v18 - 1;
      }
      else {
        uint64_t v19 = v18;
      }
      mlir::detail::TypeIDResolver<mlir::RegionBranchTerminatorOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v15[v17], v19);
      uint64_t v1 = (void *)&unk_267770000;
      a1 = v20;
    }
  }
  unint64_t v2 = *(unsigned int *)(a1 + 8);
  if (!v2) {
    return 0;
  }
  unint64_t v3 = v1[405];
  BOOL v4 = *(void **)a1;
  uint64_t v5 = *(void *)a1 + 16 * v2;
  do
  {
    unint64_t v6 = v2 >> 1;
    unint64_t v7 = &v4[2 * (v2 >> 1)];
    unint64_t v9 = *v7;
    unint64_t v8 = v7 + 2;
    v2 += ~(v2 >> 1);
    if (v9 < v3) {
      BOOL v4 = v8;
    }
    else {
      unint64_t v2 = v6;
    }
  }
  while (v2);
  if (v4 != (void *)v5 && *v4 == v3) {
    return v4[1];
  }
  else {
    return 0;
  }
}

uint64_t *llvm::DenseMapBase<llvm::DenseMap<mlir::Operation *,mlir::ValueRange,llvm::DenseMapInfo<mlir::Operation *,void>,llvm::detail::DenseMapPair<mlir::Operation *,mlir::ValueRange>>,mlir::Operation *,mlir::ValueRange,llvm::DenseMapInfo<mlir::Operation *,void>,llvm::detail::DenseMapPair<mlir::Operation *,mlir::ValueRange>>::InsertIntoBucket<mlir::Operation * const&>(uint64_t a1, uint64_t *a2, uint64_t *a3)
{
  int v6 = *(_DWORD *)(a1 + 8);
  unsigned int v7 = *(_DWORD *)(a1 + 16);
  if (4 * v6 + 4 >= 3 * v7)
  {
    v7 *= 2;
  }
  else if (v7 + ~v6 - *(_DWORD *)(a1 + 12) > v7 >> 3)
  {
LABEL_3:
    uint64_t v8 = *a2;
    goto LABEL_4;
  }
  llvm::DenseMap<mlir::Operation *,mlir::ValueRange,llvm::DenseMapInfo<mlir::Operation *,void>,llvm::detail::DenseMapPair<mlir::Operation *,mlir::ValueRange>>::grow(a1, v7);
  uint64_t v8 = *a3;
  int v10 = *(_DWORD *)(a1 + 16) - 1;
  unsigned int v11 = ((*a3 >> 4) ^ (*a3 >> 9)) & v10;
  a2 = (uint64_t *)(*(void *)a1 + 24 * v11);
  uint64_t v12 = *a2;
  if (*a3 != *a2)
  {
    unint64_t v13 = 0;
    int v14 = 1;
    while (v12 != -4096)
    {
      if (v13) {
        BOOL v15 = 0;
      }
      else {
        BOOL v15 = v12 == -8192;
      }
      if (v15) {
        unint64_t v13 = a2;
      }
      unsigned int v16 = v11 + v14++;
      unsigned int v11 = v16 & v10;
      a2 = (uint64_t *)(*(void *)a1 + 24 * v11);
      uint64_t v12 = *a2;
      if (v8 == *a2) {
        goto LABEL_4;
      }
    }
    if (v13) {
      a2 = v13;
    }
    goto LABEL_3;
  }
LABEL_4:
  ++*(_DWORD *)(a1 + 8);
  if (v8 != -4096) {
    --*(_DWORD *)(a1 + 12);
  }
  *a2 = *a3;
  mlir::ValueRange::ValueRange((unint64_t *)a2 + 1, 0, 0);
  return a2;
}

void *llvm::DenseMap<mlir::Operation *,mlir::ValueRange,llvm::DenseMapInfo<mlir::Operation *,void>,llvm::detail::DenseMapPair<mlir::Operation *,mlir::ValueRange>>::grow(uint64_t a1, int a2)
{
  uint64_t v3 = *(unsigned int *)(a1 + 16);
  BOOL v4 = *(llvm **)a1;
  unint64_t v5 = (a2 - 1) | ((unint64_t)(a2 - 1) >> 1);
  unint64_t v6 = v5 | (v5 >> 2) | ((v5 | (v5 >> 2)) >> 4);
  int v7 = ((v6 | (v6 >> 8)) >> 16) | v6 | (v6 >> 8);
  if ((v7 + 1) > 0x40) {
    unsigned int v8 = v7 + 1;
  }
  else {
    unsigned int v8 = 64;
  }
  *(_DWORD *)(a1 + 16) = v8;
  uint64_t result = llvm::allocate_buffer(24 * v8, (std::align_val_t)8uLL);
  *(void *)a1 = result;
  if (v4)
  {
    *(void *)(a1 + 8) = 0;
    unsigned int v10 = *(_DWORD *)(a1 + 16);
    if (!v10) {
      goto LABEL_16;
    }
    unint64_t v11 = 24 * v10 - 24;
    if (v11 >= 0x18)
    {
      unint64_t v16 = v11 / 0x18 + 1;
      uint64_t v12 = &result[3 * (v16 & 0x1FFFFFFFFFFFFFFELL)];
      uint64_t v17 = v16 & 0x1FFFFFFFFFFFFFFELL;
      unint64_t v18 = result;
      do
      {
        *unint64_t v18 = -4096;
        v18[3] = -4096;
        v18 += 6;
        v17 -= 2;
      }
      while (v17);
      if (v16 == (v16 & 0x1FFFFFFFFFFFFFFELL))
      {
LABEL_16:
        if (v3)
        {
          uint64_t v20 = v4;
          do
          {
            uint64_t v22 = *(void *)v20;
            if ((*(void *)v20 | 0x1000) != 0xFFFFFFFFFFFFF000)
            {
              int v23 = *(_DWORD *)(a1 + 16);
              if (v23)
              {
                int v24 = v23 - 1;
                unsigned int v25 = (v23 - 1) & ((v22 >> 4) ^ (v22 >> 9));
                uint64_t v21 = *(void *)a1 + 24 * v25;
                uint64_t v26 = *(void *)v21;
                if (v22 != *(void *)v21)
                {
                  uint64_t v27 = 0;
                  int v28 = 1;
                  while (v26 != -4096)
                  {
                    if (v27) {
                      BOOL v29 = 0;
                    }
                    else {
                      BOOL v29 = v26 == -8192;
                    }
                    if (v29) {
                      uint64_t v27 = v21;
                    }
                    unsigned int v30 = v25 + v28++;
                    unsigned int v25 = v30 & v24;
                    uint64_t v21 = *(void *)a1 + 24 * (v30 & v24);
                    uint64_t v26 = *(void *)v21;
                    if (v22 == *(void *)v21) {
                      goto LABEL_19;
                    }
                  }
                  if (v27) {
                    uint64_t v21 = v27;
                  }
                }
              }
              else
              {
                uint64_t v21 = 0;
              }
LABEL_19:
              *(void *)uint64_t v21 = v22;
              *(_OWORD *)(v21 + 8) = *(_OWORD *)((char *)v20 + 8);
              ++*(_DWORD *)(a1 + 8);
            }
            uint64_t v20 = (llvm *)((char *)v20 + 24);
          }
          while (v20 != (llvm *)((char *)v4 + 24 * v3));
        }
        llvm::deallocate_buffer(v4, (void *)(24 * v3));
      }
    }
    else
    {
      uint64_t v12 = result;
    }
    uint64_t v19 = &result[3 * v10];
    do
    {
      *uint64_t v12 = -4096;
      v12 += 3;
    }
    while (v12 != v19);
    goto LABEL_16;
  }
  *(void *)(a1 + 8) = 0;
  unsigned int v13 = *(_DWORD *)(a1 + 16);
  if (v13)
  {
    unint64_t v14 = 24 * v13 - 24;
    if (v14 < 0x18)
    {
      BOOL v15 = result;
LABEL_42:
      uint64_t v34 = &result[3 * v13];
      do
      {
        void *v15 = -4096;
        v15 += 3;
      }
      while (v15 != v34);
      return result;
    }
    unint64_t v31 = v14 / 0x18 + 1;
    BOOL v15 = &result[3 * (v31 & 0x1FFFFFFFFFFFFFFELL)];
    uint64_t v32 = v31 & 0x1FFFFFFFFFFFFFFELL;
    uint64_t v33 = result;
    do
    {
      *uint64_t v33 = -4096;
      v33[3] = -4096;
      v33 += 6;
      v32 -= 2;
    }
    while (v32);
    if (v31 != (v31 & 0x1FFFFFFFFFFFFFFELL)) {
      goto LABEL_42;
    }
  }
  return result;
}

void mlir::StorageUniquer::registerParametricStorageType<mlir::dataflow::CFGEdge>()
{
  {
    int v7 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::dataflow::CFGEdge]";
    unint64_t v8 = 73;
    unint64_t v0 = llvm::StringRef::find((uint64_t *)&v7, "DesiredTypeName = ", 0x12uLL, 0);
    if (v8 >= v0) {
      unint64_t v1 = v0;
    }
    else {
      unint64_t v1 = v8;
    }
    unint64_t v2 = &v7[v1];
    unint64_t v3 = v8 - v1;
    if (v8 - v1 >= 0x12) {
      uint64_t v4 = 18;
    }
    else {
      uint64_t v4 = v8 - v1;
    }
    unint64_t v5 = v3 - v4;
    if (v5 >= v5 - 1) {
      uint64_t v6 = v5 - 1;
    }
    else {
      uint64_t v6 = v5;
    }
    mlir::detail::TypeIDResolver<mlir::dataflow::CFGEdge,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v2[v4], v6);
  }
  mlir::StorageUniquer::registerParametricStorageTypeImpl();
}

uint64_t llvm::function_ref<void ()(mlir::StorageUniquer::BaseStorage *)>::callback_fn<void mlir::StorageUniquer::registerParametricStorageType<mlir::dataflow::CFGEdge>(mlir::TypeID)::{lambda(mlir::StorageUniquer::BaseStorage *)#1}>(uint64_t a1, uint64_t (***a2)(void))
{
  return (**a2)(a2);
}

uint64_t mlir::DataFlowSolver::getOrCreateState<mlir::dataflow::Executable,mlir::Block *>(uint64_t a1, uint64_t a2)
{
  uint64_t v33 = *MEMORY[0x263EF8340];
  uint64_t v2 = a2 | 6;
  {
    uint64_t v30 = a1;
    a1 = v30;
    if (v22)
    {
      unint64_t v31 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::dataflow::Executable]";
      unint64_t v32 = 76;
      unint64_t v23 = llvm::StringRef::find((uint64_t *)&v31, "DesiredTypeName = ", 0x12uLL, 0);
      if (v32 >= v23) {
        unint64_t v24 = v23;
      }
      else {
        unint64_t v24 = v32;
      }
      unsigned int v25 = &v31[v24];
      unint64_t v26 = v32 - v24;
      if (v32 - v24 >= 0x12) {
        uint64_t v27 = 18;
      }
      else {
        uint64_t v27 = v32 - v24;
      }
      unint64_t v28 = v26 - v27;
      if (v28 >= v28 - 1) {
        uint64_t v29 = v28 - 1;
      }
      else {
        uint64_t v29 = v28;
      }
      mlir::detail::TypeIDResolver<mlir::dataflow::Executable,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v25[v27], v29);
      a1 = v30;
    }
  }
  unint64_t v31 = (const char *)v2;
  unint64_t v32 = mlir::detail::TypeIDResolver<mlir::dataflow::Executable,void>::resolveTypeID(void)::id;
  int v3 = *(_DWORD *)(a1 + 136);
  if (!v3)
  {
    uint64_t v20 = 0;
LABEL_24:
    unsigned int v10 = llvm::DenseMapBase<llvm::DenseMap<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::TypeID>,void>,llvm::detail::DenseMapPair<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>>>,std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::TypeID>,void>,llvm::detail::DenseMapPair<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>>>::InsertIntoBucketImpl<std::pair<mlir::ProgramPoint,mlir::TypeID>>(a1 + 120, (uint64_t)&v31, (uint64_t *)&v31, v20);
    *unsigned int v10 = v31;
    v10[1] = v32;
    void v10[2] = 0;
    goto LABEL_25;
  }
  uint64_t v4 = *(void *)(a1 + 120);
  unint64_t v5 = ((0x2500000000 * v2) | (mlir::detail::TypeIDResolver<mlir::dataflow::Executable,void>::resolveTypeID(void)::id >> 4) ^ (mlir::detail::TypeIDResolver<mlir::dataflow::Executable,void>::resolveTypeID(void)::id >> 9))
     + ~((unint64_t)((mlir::detail::TypeIDResolver<mlir::dataflow::Executable,void>::resolveTypeID(void)::id >> 4) ^ (mlir::detail::TypeIDResolver<mlir::dataflow::Executable,void>::resolveTypeID(void)::id >> 9)) << 32);
  unint64_t v6 = (v5 ^ (v5 >> 22)) + ~((v5 ^ (v5 >> 22)) << 13);
  unint64_t v7 = (9 * (v6 ^ (v6 >> 8))) ^ ((9 * (v6 ^ (v6 >> 8))) >> 15);
  int v8 = v3 - 1;
  unsigned int v9 = v8 & (((v7 + ~(v7 << 27)) >> 31) ^ (v7 + ~(v7 << 27)));
  unsigned int v10 = (void *)(v4 + 24 * v9);
  uint64_t v11 = *v10;
  uint64_t v12 = v10[1];
  if (v2 != *v10 || mlir::detail::TypeIDResolver<mlir::dataflow::Executable,void>::resolveTypeID(void)::id != v12)
  {
    unint64_t v14 = 0;
    int v15 = 1;
    while (v11 != -4096 || v12 != -4096)
    {
      if (v14) {
        BOOL v16 = 0;
      }
      else {
        BOOL v16 = v12 == -8192;
      }
      if (v16 && v11 == -8192) {
        unint64_t v14 = v10;
      }
      unsigned int v18 = v9 + v15++;
      unsigned int v9 = v18 & v8;
      unsigned int v10 = (void *)(v4 + 24 * v9);
      uint64_t v11 = *v10;
      uint64_t v12 = v10[1];
      if (v2 == *v10 && mlir::detail::TypeIDResolver<mlir::dataflow::Executable,void>::resolveTypeID(void)::id == v12) {
        goto LABEL_25;
      }
    }
    if (v14) {
      uint64_t v20 = v14;
    }
    else {
      uint64_t v20 = v10;
    }
    goto LABEL_24;
  }
LABEL_25:
  uint64_t result = v10[2];
  if (!result) {
    operator new();
  }
  return result;
}

uint64_t mlir::DataFlowSolver::getOrCreateState<mlir::dataflow::PredecessorState,mlir::Operation *>(uint64_t a1, uint64_t a2)
{
  uint64_t v33 = *MEMORY[0x263EF8340];
  unint64_t v2 = a2 & 0xFFFFFFFFFFFFFFF9 | 2;
  {
    uint64_t v30 = a1;
    a1 = v30;
    if (v22)
    {
      unint64_t v31 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::dataflow::PredecessorState]";
      unint64_t v32 = 82;
      unint64_t v23 = llvm::StringRef::find((uint64_t *)&v31, "DesiredTypeName = ", 0x12uLL, 0);
      if (v32 >= v23) {
        unint64_t v24 = v23;
      }
      else {
        unint64_t v24 = v32;
      }
      unsigned int v25 = &v31[v24];
      unint64_t v26 = v32 - v24;
      if (v32 - v24 >= 0x12) {
        uint64_t v27 = 18;
      }
      else {
        uint64_t v27 = v32 - v24;
      }
      unint64_t v28 = v26 - v27;
      if (v28 >= v28 - 1) {
        uint64_t v29 = v28 - 1;
      }
      else {
        uint64_t v29 = v28;
      }
      mlir::detail::TypeIDResolver<mlir::dataflow::PredecessorState,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v25[v27], v29);
      a1 = v30;
    }
  }
  unint64_t v31 = (const char *)v2;
  unint64_t v32 = mlir::detail::TypeIDResolver<mlir::dataflow::PredecessorState,void>::resolveTypeID(void)::id;
  int v3 = *(_DWORD *)(a1 + 136);
  if (!v3)
  {
    uint64_t v20 = 0;
LABEL_24:
    unsigned int v10 = llvm::DenseMapBase<llvm::DenseMap<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::TypeID>,void>,llvm::detail::DenseMapPair<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>>>,std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::TypeID>,void>,llvm::detail::DenseMapPair<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>>>::InsertIntoBucketImpl<std::pair<mlir::ProgramPoint,mlir::TypeID>>(a1 + 120, (uint64_t)&v31, (uint64_t *)&v31, v20);
    *unsigned int v10 = v31;
    v10[1] = v32;
    void v10[2] = 0;
    goto LABEL_25;
  }
  uint64_t v4 = *(void *)(a1 + 120);
  unint64_t v5 = ((0x2500000000 * v2) | (mlir::detail::TypeIDResolver<mlir::dataflow::PredecessorState,void>::resolveTypeID(void)::id >> 4) ^ (mlir::detail::TypeIDResolver<mlir::dataflow::PredecessorState,void>::resolveTypeID(void)::id >> 9))
     + ~((unint64_t)((mlir::detail::TypeIDResolver<mlir::dataflow::PredecessorState,void>::resolveTypeID(void)::id >> 4) ^ (mlir::detail::TypeIDResolver<mlir::dataflow::PredecessorState,void>::resolveTypeID(void)::id >> 9)) << 32);
  unint64_t v6 = (v5 ^ (v5 >> 22)) + ~((v5 ^ (v5 >> 22)) << 13);
  unint64_t v7 = (9 * (v6 ^ (v6 >> 8))) ^ ((9 * (v6 ^ (v6 >> 8))) >> 15);
  int v8 = v3 - 1;
  unsigned int v9 = v8 & (((v7 + ~(v7 << 27)) >> 31) ^ (v7 + ~(v7 << 27)));
  unsigned int v10 = (void *)(v4 + 24 * v9);
  uint64_t v11 = *v10;
  uint64_t v12 = v10[1];
  if (v2 != *v10 || mlir::detail::TypeIDResolver<mlir::dataflow::PredecessorState,void>::resolveTypeID(void)::id != v12)
  {
    unint64_t v14 = 0;
    int v15 = 1;
    while (v11 != -4096 || v12 != -4096)
    {
      if (v14) {
        BOOL v16 = 0;
      }
      else {
        BOOL v16 = v12 == -8192;
      }
      if (v16 && v11 == -8192) {
        unint64_t v14 = v10;
      }
      unsigned int v18 = v9 + v15++;
      unsigned int v9 = v18 & v8;
      unsigned int v10 = (void *)(v4 + 24 * v9);
      uint64_t v11 = *v10;
      uint64_t v12 = v10[1];
      if (v2 == *v10
        && mlir::detail::TypeIDResolver<mlir::dataflow::PredecessorState,void>::resolveTypeID(void)::id == v12)
      {
        goto LABEL_25;
      }
    }
    if (v14) {
      uint64_t v20 = v14;
    }
    else {
      uint64_t v20 = v10;
    }
    goto LABEL_24;
  }
LABEL_25:
  uint64_t result = v10[2];
  if (!result) {
    operator new();
  }
  return result;
}

void llvm::function_ref<void ()(mlir::Operation *,BOOL)>::callback_fn<mlir::dataflow::DeadCodeAnalysis::initializeSymbolCallables(mlir::Operation *)::$_0>(uint64_t a1, uint64_t a2, char a3)
{
  uint64_t v5 = *(void *)a1;
  unint64_t v6 = (mlir::SymbolTable *)(((a2
                             + 16 * (((unint64_t)*(unsigned int *)(a2 + 44) >> 23) & 1)
                             + (((unint64_t)*(unsigned int *)(a2 + 44) >> 21) & 0x7F8)
                             + 71) & 0xFFFFFFFFFFFFFFF8)
                           + 32 * *(unsigned int *)(a2 + 40));
  uint64_t v7 = *((void *)v6 + 1);
  if (v7) {
    uint64_t v8 = v7 - 8;
  }
  else {
    uint64_t v8 = 0;
  }
  mlir::Block::getOps<mlir::CallableOpInterface>(v8, (ZinIrHalH13g **)&__p);
  unsigned int v9 = (ZinIrHalH13g *)__p;
  unsigned int v10 = v44;
  if (__p != v44)
  {
    char v11 = 0;
    uint64_t v12 = v41;
    unsigned int v13 = v42;
    unint64_t v14 = v43;
    do
    {
      ZinIrHalH13g::~ZinIrHalH13g(v9);
      v39[0] = (mlir::SymbolOpInterface *)v14(v15, v16);
      v39[1] = v17;
      if (mlir::MemoryMapperInterface::canMapOperands((mlir::MemoryMapperInterface *)v39))
      {
        v38[0] = llvm::DefaultDoCastIfPossible<mlir::SymbolOpInterface,mlir::Operation *,llvm::CastInfo<mlir::SymbolOpInterface,mlir::Operation *,void>>::doCastIfPossible(v39[0], v18);
        v38[1] = v19;
        if (v38[0])
        {
          if ((mlir::SymbolOpInterface::isPublic((mlir::SymbolOpInterface *)v38) & 1) != 0
            || (a3 & 1) == 0 && mlir::ShapedType::getShape((mlir::ShapedType *)v38))
          {
            uint64_t v20 = mlir::DataFlowSolver::getOrCreateState<mlir::dataflow::PredecessorState,mlir::Operation *>(*(void *)(v5 + 8), (uint64_t)v39[0]);
            int v21 = *(unsigned __int8 *)(v20 + 56);
            *(unsigned char *)(v20 + 56) = 0;
            mlir::DataFlowAnalysis::propagateIfChanged(v5, v20, v21);
          }
          char v11 = 1;
        }
      }
      int v22 = (ZinIrHalH13g *)*((void *)v9 + 1);
      unsigned int v9 = v12;
      if (v22 != v12)
      {
        unsigned int v9 = v22;
        while (1)
        {
          ZinIrHalH13g::~ZinIrHalH13g(v9);
          if (v13(v23, v24)) {
            break;
          }
          unsigned int v9 = (ZinIrHalH13g *)*((void *)v9 + 1);
          if (v9 == v12)
          {
            unsigned int v9 = v12;
            break;
          }
        }
      }
    }
    while (v9 != v10);
    if (v11)
    {
      mlir::SymbolTable::getSymbolUses(v6, (uint64_t)&__p);
      if ((_BYTE)v43)
      {
        unsigned int v25 = (uint64_t *)__p;
        unint64_t v26 = (uint64_t *)v41;
        if (__p != v41)
        {
          do
          {
            uint64_t v30 = *v25;
            uint64_t v31 = *(void *)(*v25 + 48);
            unint64_t v32 = *(void **)(v31 + 16);
            BOOL v33 = v32 == &mlir::detail::TypeIDResolver<void,void>::id;
            if (v32 == &mlir::detail::TypeIDResolver<void,void>::id) {
              uint64_t v34 = 0;
            }
            else {
              uint64_t v34 = *(void *)(*v25 + 48);
            }
            if (v33)
            {
              v39[0] = *(mlir::SymbolOpInterface **)(v31 + 8);
              uint64_t Values = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)v39);
              if (Values && mlir::Dialect::getRegisteredInterfaceForOp<mlir::CallOpInterface>(Values, v31)) {
                goto LABEL_24;
              }
            }
            else
            {
              unint64_t v35 = v34 | v31 & 0xFFFFFFFFFFFFFF00;
              if (mlir::detail::InterfaceMap::lookup<mlir::CallOpInterface>(v35 + 32)
                || mlir::Dialect::getRegisteredInterfaceForOp<mlir::CallOpInterface>(*(void *)(v35 + 24), *(void *)(v30 + 48)))
              {
                goto LABEL_24;
              }
            }
            uint64_t v27 = mlir::SymbolTableCollection::lookupSymbolIn(v5 + 24, **(void **)(a1 + 8), v25[1]);
            uint64_t v28 = mlir::DataFlowSolver::getOrCreateState<mlir::dataflow::PredecessorState,mlir::Operation *>(*(void *)(v5 + 8), v27);
            int v29 = *(unsigned __int8 *)(v28 + 56);
            *(unsigned char *)(v28 + 56) = 0;
            mlir::DataFlowAnalysis::propagateIfChanged(v5, v28, v29);
LABEL_24:
            v25 += 2;
          }
          while (v25 != v26);
        }
      }
      else
      {
        uint64_t v37 = **(mlir::ForwardIterator ***)(a1 + 8);
        v38[0] = v5;
        v39[0] = (mlir::SymbolOpInterface *)v38;
        mlir::detail::walk<mlir::ForwardIterator>(v37, (mlir::Operation *)_ZN4llvm12function_refIFvPN4mlir9OperationEEE11callback_fnIZNS1_6detail4walkILNS1_9WalkOrderE1ENS1_15ForwardIteratorEZZNS1_8dataflow16DeadCodeAnalysis25initializeSymbolCallablesES3_ENK3__0clES3_bEUlNS1_19CallableOpInterfaceEE_SE_vEENSt3__19enable_ifIXaantsr4llvm9is_one_ofIT2_S3_PNS1_6RegionEPNS1_5BlockEEE5valuesr3std7is_sameIT3_vEE5valueESN_E4typeES3_OT1_EUlS3_E_EEvlS3_, (uint64_t)v39, 1);
      }
      if ((_BYTE)v43)
      {
        if (__p)
        {
          int64_t v41 = (ZinIrHalH13g *)__p;
          operator delete(__p);
        }
      }
    }
  }
}

uint64_t mlir::Block::getOps<mlir::CallableOpInterface>@<X0>(uint64_t result@<X0>, ZinIrHalH13g **a2@<X8>)
{
  int v3 = (ZinIrHalH13g *)(result + 32);
  uint64_t v4 = (ZinIrHalH13g *)(result + 32);
  if (*(void *)(result + 40) != result + 32)
  {
    uint64_t v4 = *(ZinIrHalH13g **)(result + 40);
    do
    {
      ZinIrHalH13g::~ZinIrHalH13g(v4);
      uint64_t v8 = *(void *)(v7 + 48);
      unsigned int v9 = *(void **)(v8 + 16);
      BOOL v10 = v9 == &mlir::detail::TypeIDResolver<void,void>::id;
      if (v9 == &mlir::detail::TypeIDResolver<void,void>::id) {
        uint64_t v11 = 0;
      }
      else {
        uint64_t v11 = *(void *)(v7 + 48);
      }
      if (v10)
      {
        uint64_t v12 = *(void *)(v8 + 8);
        uint64_t result = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)&v12);
        if (result)
        {
          uint64_t result = mlir::Dialect::getRegisteredInterfaceForOp<mlir::CallableOpInterface>(result, v8);
          if (result) {
            goto LABEL_15;
          }
        }
      }
      else
      {
        uint64_t v5 = v7;
        unint64_t v6 = v11 | v8 & 0xFFFFFFFFFFFFFF00;
        uint64_t result = mlir::detail::InterfaceMap::lookup<mlir::CallableOpInterface>(v6 + 32);
        if (result) {
          goto LABEL_15;
        }
        uint64_t result = mlir::Dialect::getRegisteredInterfaceForOp<mlir::CallableOpInterface>(*(void *)(v6 + 24), *(void *)(v5 + 48));
        if (result) {
          goto LABEL_15;
        }
      }
      uint64_t v4 = (ZinIrHalH13g *)*((void *)v4 + 1);
    }
    while (v4 != v3);
    uint64_t v4 = v3;
  }
LABEL_15:
  *a2 = v4;
  a2[1] = v3;
  a2[2] = (ZinIrHalH13g *)mlir::detail::op_filter_iterator<mlir::CallableOpInterface,llvm::ilist_iterator<llvm::ilist_detail::node_options<mlir::Operation,false,false,void,false>,false,false>>::filter;
  a2[3] = (ZinIrHalH13g *)mlir::detail::op_iterator<mlir::CallableOpInterface,llvm::ilist_iterator<llvm::ilist_detail::node_options<mlir::Operation,false,false,void,false>,false,false>>::unwrap;
  a2[4] = v3;
  a2[5] = v3;
  a2[6] = (ZinIrHalH13g *)mlir::detail::op_filter_iterator<mlir::CallableOpInterface,llvm::ilist_iterator<llvm::ilist_detail::node_options<mlir::Operation,false,false,void,false>,false,false>>::filter;
  a2[7] = (ZinIrHalH13g *)mlir::detail::op_iterator<mlir::CallableOpInterface,llvm::ilist_iterator<llvm::ilist_detail::node_options<mlir::Operation,false,false,void,false>,false,false>>::unwrap;
  return result;
}

BOOL mlir::detail::op_filter_iterator<mlir::CallableOpInterface,llvm::ilist_iterator<llvm::ilist_detail::node_options<mlir::Operation,false,false,void,false>,false,false>>::filter(uint64_t a1)
{
  uint64_t v1 = *(void *)(a1 + 48);
  unint64_t v2 = *(void **)(v1 + 16);
  BOOL v3 = v2 == &mlir::detail::TypeIDResolver<void,void>::id;
  if (v2 == &mlir::detail::TypeIDResolver<void,void>::id) {
    uint64_t v4 = 0;
  }
  else {
    uint64_t v4 = *(void *)(a1 + 48);
  }
  if (v3)
  {
    uint64_t v10 = *(void *)(v1 + 8);
    uint64_t Values = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)&v10);
    if (!Values) {
      return Values != 0;
    }
    uint64_t v9 = v1;
  }
  else
  {
    unint64_t v6 = v4 | v1 & 0xFFFFFFFFFFFFFF00;
    uint64_t Values = mlir::detail::InterfaceMap::lookup<mlir::CallableOpInterface>(v6 + 32);
    if (Values) {
      return Values != 0;
    }
    uint64_t Values = *(void *)(v6 + 24);
    uint64_t v9 = *(void *)(a1 + 48);
  }
  return mlir::Dialect::getRegisteredInterfaceForOp<mlir::CallableOpInterface>(Values, v9) != 0;
}

uint64_t mlir::detail::op_iterator<mlir::CallableOpInterface,llvm::ilist_iterator<llvm::ilist_detail::node_options<mlir::Operation,false,false,void,false>,false,false>>::unwrap(uint64_t a1)
{
  uint64_t v2 = *(void *)(a1 + 48);
  BOOL v3 = *(void **)(v2 + 16);
  BOOL v4 = v3 == &mlir::detail::TypeIDResolver<void,void>::id;
  if (v3 == &mlir::detail::TypeIDResolver<void,void>::id) {
    uint64_t v5 = 0;
  }
  else {
    uint64_t v5 = *(void *)(a1 + 48);
  }
  if (!v4)
  {
    unint64_t v6 = v5 | v2 & 0xFFFFFFFFFFFFFF00;
    if (mlir::detail::InterfaceMap::lookup<mlir::CallableOpInterface>(v6 + 32)) {
      return a1;
    }
    uint64_t Values = *(void *)(v6 + 24);
    uint64_t v9 = *(void *)(a1 + 48);
    goto LABEL_10;
  }
  uint64_t v10 = *(void *)(v2 + 8);
  uint64_t Values = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)&v10);
  if (Values)
  {
    uint64_t v9 = v2;
LABEL_10:
    mlir::Dialect::getRegisteredInterfaceForOp<mlir::CallableOpInterface>(Values, v9);
    return a1;
  }
  return a1;
}

mlir::SymbolOpInterface *llvm::DefaultDoCastIfPossible<mlir::SymbolOpInterface,mlir::Operation *,llvm::CastInfo<mlir::SymbolOpInterface,mlir::Operation *,void>>::doCastIfPossible(mlir::SymbolOpInterface *a1, mlir::Operation *a2)
{
  uint64_t v2 = a1;
  if (!mlir::SymbolOpInterface::classof(a1, a2)) {
    return 0;
  }
  if (!v2) {
    return v2;
  }
  uint64_t v3 = *((void *)v2 + 6);
  BOOL v4 = *(void **)(v3 + 16);
  BOOL v5 = v4 == &mlir::detail::TypeIDResolver<void,void>::id;
  if (v4 == &mlir::detail::TypeIDResolver<void,void>::id) {
    uint64_t v6 = 0;
  }
  else {
    uint64_t v6 = *((void *)v2 + 6);
  }
  if (!v5)
  {
    unint64_t v7 = v6 | v3 & 0xFFFFFFFFFFFFFF00;
    if (mlir::detail::InterfaceMap::lookup<mlir::SymbolOpInterface>(v7 + 32)) {
      return v2;
    }
    uint64_t Values = *(void *)(v7 + 24);
    uint64_t v10 = *((void *)v2 + 6);
    goto LABEL_14;
  }
  uint64_t v11 = *(void *)(v3 + 8);
  uint64_t Values = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)&v11);
  if (!Values) {
    return v2;
  }
  uint64_t v10 = v3;
LABEL_14:
  mlir::Dialect::getRegisteredInterfaceForOp<mlir::SymbolOpInterface>(Values, v10);
  return v2;
}

uint64_t mlir::SymbolOpInterface::classof(mlir::SymbolOpInterface *this, mlir::Operation *a2)
{
  uint64_t v3 = *((void *)this + 6);
  BOOL v4 = *(void **)(v3 + 16);
  BOOL v5 = v4 == &mlir::detail::TypeIDResolver<void,void>::id;
  if (v4 == &mlir::detail::TypeIDResolver<void,void>::id) {
    uint64_t v6 = 0;
  }
  else {
    uint64_t v6 = *((void *)this + 6);
  }
  if (v5)
  {
    uint64_t v11 = *(void *)(v3 + 8);
    uint64_t result = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)&v11);
    if (!result) {
      return result;
    }
    uint64_t result = mlir::Dialect::getRegisteredInterfaceForOp<mlir::SymbolOpInterface>(result, v3);
    if (!result) {
      return result;
    }
  }
  else
  {
    unint64_t v7 = v6 | v3 & 0xFFFFFFFFFFFFFF00;
    if (!mlir::detail::InterfaceMap::lookup<mlir::SymbolOpInterface>(v7 + 32))
    {
      uint64_t result = mlir::Dialect::getRegisteredInterfaceForOp<mlir::SymbolOpInterface>(*(void *)(v7 + 24), *((void *)this + 6));
      if (!result) {
        return result;
      }
    }
  }
  if (*((unsigned char *)this + 47)
    && (uint64_t InherentAttr = mlir::Operation::getInherentAttr((uint64_t)this, (uint64_t)"sym_name", 8), v10))
  {
    return InherentAttr != 0;
  }
  else
  {
    return mlir::DictionaryAttr::contains((uint64_t)this + 56, "sym_name", 8uLL);
  }
}

uint64_t mlir::Dialect::getRegisteredInterfaceForOp<mlir::SymbolOpInterface>(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = a2;
  uint64_t v3 = &unk_267770000;
  {
    uint64_t v15 = a1;
    uint64_t v3 = (void *)&unk_267770000;
    int v6 = v5;
    uint64_t v2 = a2;
    a1 = v15;
    if (v6)
    {
      uint64_t v16 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::SymbolOpInterface]";
      unint64_t v17 = 73;
      unint64_t v7 = llvm::StringRef::find((uint64_t *)&v16, "DesiredTypeName = ", 0x12uLL, 0);
      if (v17 >= v7) {
        unint64_t v8 = v7;
      }
      else {
        unint64_t v8 = v17;
      }
      uint64_t v9 = &v16[v8];
      unint64_t v10 = v17 - v8;
      if (v17 - v8 >= 0x12) {
        uint64_t v11 = 18;
      }
      else {
        uint64_t v11 = v17 - v8;
      }
      unint64_t v12 = v10 - v11;
      if (v12 >= v12 - 1) {
        uint64_t v13 = v12 - 1;
      }
      else {
        uint64_t v13 = v12;
      }
      mlir::detail::TypeIDResolver<mlir::SymbolOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v9[v11], v13);
      uint64_t v3 = (void *)&unk_267770000;
      uint64_t v2 = a2;
      a1 = v15;
    }
  }
  return (*(uint64_t (**)(uint64_t, void, uint64_t))(*(void *)a1 + 104))(a1, v3[411], v2);
}

uint64_t mlir::detail::InterfaceMap::lookup<mlir::SymbolOpInterface>(uint64_t a1)
{
  uint64_t v1 = &unk_267770000;
  {
    uint64_t v20 = a1;
    uint64_t v1 = (void *)&unk_267770000;
    int v12 = v11;
    a1 = v20;
    if (v12)
    {
      int v21 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::SymbolOpInterface]";
      unint64_t v22 = 73;
      unint64_t v13 = llvm::StringRef::find((uint64_t *)&v21, "DesiredTypeName = ", 0x12uLL, 0);
      if (v22 >= v13) {
        unint64_t v14 = v13;
      }
      else {
        unint64_t v14 = v22;
      }
      uint64_t v15 = &v21[v14];
      unint64_t v16 = v22 - v14;
      if (v22 - v14 >= 0x12) {
        uint64_t v17 = 18;
      }
      else {
        uint64_t v17 = v22 - v14;
      }
      unint64_t v18 = v16 - v17;
      if (v18 >= v18 - 1) {
        uint64_t v19 = v18 - 1;
      }
      else {
        uint64_t v19 = v18;
      }
      mlir::detail::TypeIDResolver<mlir::SymbolOpInterface,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v15[v17], v19);
      uint64_t v1 = (void *)&unk_267770000;
      a1 = v20;
    }
  }
  unint64_t v2 = *(unsigned int *)(a1 + 8);
  if (!v2) {
    return 0;
  }
  unint64_t v3 = v1[411];
  BOOL v4 = *(void **)a1;
  uint64_t v5 = *(void *)a1 + 16 * v2;
  do
  {
    unint64_t v6 = v2 >> 1;
    unint64_t v7 = &v4[2 * (v2 >> 1)];
    unint64_t v9 = *v7;
    unint64_t v8 = v7 + 2;
    v2 += ~(v2 >> 1);
    if (v9 < v3) {
      BOOL v4 = v8;
    }
    else {
      unint64_t v2 = v6;
    }
  }
  while (v2);
  if (v4 != (void *)v5 && *v4 == v3) {
    return v4[1];
  }
  else {
    return 0;
  }
}

uint64_t _ZN4llvm12function_refIFvPN4mlir9OperationEEE11callback_fnIZNS1_6detail4walkILNS1_9WalkOrderE1ENS1_15ForwardIteratorEZZNS1_8dataflow16DeadCodeAnalysis25initializeSymbolCallablesES3_ENK3__0clES3_bEUlNS1_19CallableOpInterfaceEE_SE_vEENSt3__19enable_ifIXaantsr4llvm9is_one_ofIT2_S3_PNS1_6RegionEPNS1_5BlockEEE5valuesr3std7is_sameIT3_vEE5valueESN_E4typeES3_OT1_EUlS3_E_EEvlS3_(uint64_t **a1, uint64_t a2)
{
  uint64_t result = llvm::DefaultDoCastIfPossible<mlir::CallableOpInterface,mlir::Operation *,llvm::CastInfo<mlir::CallableOpInterface,mlir::Operation *,void>>::doCastIfPossible(a2);
  if (result)
  {
    uint64_t v4 = **a1;
    uint64_t v5 = mlir::DataFlowSolver::getOrCreateState<mlir::dataflow::PredecessorState,mlir::Operation *>(*(void *)(v4 + 8), result);
    int v6 = *(unsigned __int8 *)(v5 + 56);
    *(unsigned char *)(v5 + 56) = 0;
    return mlir::DataFlowAnalysis::propagateIfChanged(v4, v5, v6);
  }
  return result;
}

uint64_t mlir::StorageUniquer::get<mlir::dataflow::CFGEdge,mlir::Block *&,mlir::Block *&>(unsigned __int8 **a1, const char *a2, unint64_t a3, void *a4, void *a5)
{
  uint64_t v5 = &unk_267770000;
  {
    uint64_t v24 = a5;
    unsigned int v25 = a1;
    unint64_t v22 = a3;
    uint64_t v23 = a4;
    int v21 = a2;
    uint64_t v5 = (void *)&unk_267770000;
    a2 = v21;
    a3 = v22;
    a4 = v23;
    a5 = v24;
    int v13 = v12;
    a1 = v25;
    if (v13)
    {
      int v29 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::dataflow::CFGEdge]";
      unint64_t v30 = 73;
      unint64_t v14 = llvm::StringRef::find((uint64_t *)&v29, "DesiredTypeName = ", 0x12uLL, 0);
      if (v30 >= v14) {
        unint64_t v15 = v14;
      }
      else {
        unint64_t v15 = v30;
      }
      unint64_t v16 = &v29[v15];
      unint64_t v17 = v30 - v15;
      if (v30 - v15 >= 0x12) {
        uint64_t v18 = 18;
      }
      else {
        uint64_t v18 = v30 - v15;
      }
      unint64_t v19 = v17 - v18;
      if (v19 >= v19 - 1) {
        uint64_t v20 = v19 - 1;
      }
      else {
        uint64_t v20 = v19;
      }
      mlir::detail::TypeIDResolver<mlir::dataflow::CFGEdge,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v16[v18], v20);
      uint64_t v5 = (void *)&unk_267770000;
      a2 = v21;
      a3 = v22;
      a4 = v23;
      a5 = v24;
      a1 = v25;
    }
  }
  uint64_t v6 = v5[395];
  int v29 = a2;
  unint64_t v30 = a3;
  uint64_t v7 = *a5;
  v28[0] = *a4;
  v28[1] = v7;
  unint64_t v8 = ((v7 >> 4) ^ (v7 >> 9) | ((unint64_t)((LODWORD(v28[0]) >> 4) ^ (LODWORD(v28[0]) >> 9)) << 32))
     + ~((unint64_t)((v7 >> 4) ^ (v7 >> 9)) << 32);
  unint64_t v9 = (v8 ^ (v8 >> 22)) + ~((v8 ^ (v8 >> 22)) << 13);
  unint64_t v10 = (9 * (v9 ^ (v9 >> 8))) ^ ((9 * (v9 ^ (v9 >> 8))) >> 15);
  v26[0] = v28;
  v26[1] = &v29;
  uint64_t v27 = v28;
  return mlir::StorageUniquer::getParametricStorageTypeImpl(a1, v6, ((v10 + ~(v10 << 27)) >> 31) ^ (v10 + ~(v10 << 27)), (uint64_t (*)(uint64_t))llvm::function_ref<BOOL ()(mlir::StorageUniquer::BaseStorage const*)>::callback_fn<mlir::dataflow::CFGEdge * mlir::StorageUniquer::get<mlir::dataflow::CFGEdge,mlir::Block *&,mlir::Block *&>(llvm::function_ref<void ()(mlir::dataflow::CFGEdge *)>,mlir::TypeID,mlir::Block *&,mlir::Block *&)::{lambda(mlir::StorageUniquer::BaseStorage const*)#1}>, (uint64_t)&v27, llvm::function_ref<mlir::StorageUniquer::BaseStorage * ()(mlir::StorageUniquer::StorageAllocator &)>::callback_fn<mlir::dataflow::CFGEdge * mlir::StorageUniquer::get<mlir::dataflow::CFGEdge,mlir::Block *&,mlir::Block *&>(llvm::function_ref<void ()(mlir::dataflow::CFGEdge *)>,mlir::TypeID,mlir::Block *&,mlir::Block *&)::{lambda(mlir::StorageUniquer::StorageAllocator &)#1}>, (uint64_t)v26);
}

BOOL llvm::function_ref<BOOL ()(mlir::StorageUniquer::BaseStorage const*)>::callback_fn<mlir::dataflow::CFGEdge * mlir::StorageUniquer::get<mlir::dataflow::CFGEdge,mlir::Block *&,mlir::Block *&>(llvm::function_ref<void ()(mlir::dataflow::CFGEdge *)>,mlir::TypeID,mlir::Block *&,mlir::Block *&)::{lambda(mlir::StorageUniquer::BaseStorage const*)#1}>(uint64_t a1, uint64_t a2)
{
  return *(void *)(a2 + 16) == **(void **)a1 && *(void *)(a2 + 24) == *(void *)(*(void *)a1 + 8);
}

uint64_t llvm::function_ref<mlir::StorageUniquer::BaseStorage * ()(mlir::StorageUniquer::StorageAllocator &)>::callback_fn<mlir::dataflow::CFGEdge * mlir::StorageUniquer::get<mlir::dataflow::CFGEdge,mlir::Block *&,mlir::Block *&>(llvm::function_ref<void ()(mlir::dataflow::CFGEdge *)>,mlir::TypeID,mlir::Block *&,mlir::Block *&)::{lambda(mlir::StorageUniquer::StorageAllocator &)#1}>(uint64_t a1, uint64_t a2)
{
  __n128 v4 = mlir::GenericProgramPointBase<mlir::dataflow::CFGEdge,std::pair<mlir::Block *,mlir::Block *>>::construct<std::pair<mlir::Block *,mlir::Block *>>(a2, (__n128 *)*(void *)a1);
  uint64_t v5 = v3;
  uint64_t v6 = *(void *)(a1 + 8);
  if (*(void *)v6) {
    (*(void (**)(void, uint64_t, __n128))v6)(*(void *)(v6 + 8), v3, v4);
  }
  return v5;
}

__n128 mlir::GenericProgramPointBase<mlir::dataflow::CFGEdge,std::pair<mlir::Block *,mlir::Block *>>::construct<std::pair<mlir::Block *,mlir::Block *>>(uint64_t a1, __n128 *a2)
{
  *(void *)(a1 + 80) += 32;
  if (*(void *)a1) {
    BOOL v4 = ((*(void *)a1 + 7) & 0xFFFFFFFFFFFFFFF8) - *(void *)a1 + 32 > *(void *)(a1 + 8) - *(void *)a1;
  }
  else {
    BOOL v4 = 1;
  }
  if (v4)
  {
    unsigned int v5 = *(_DWORD *)(a1 + 24) >> 7;
    if (v5 >= 0x1E) {
      LOBYTE(v5) = 30;
    }
    uint64_t v6 = 4096 << v5;
    buffer = (char *)llvm::allocate_buffer(4096 << v5, (std::align_val_t)8uLL);
    uint64_t v8 = *(unsigned int *)(a1 + 24);
    if (v8 >= *(_DWORD *)(a1 + 28))
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod(a1 + 16, (void *)(a1 + 32), v8 + 1, 8);
      LODWORD(v8) = *(_DWORD *)(a1 + 24);
    }
    *(void *)(*(void *)(a1 + 16) + 8 * v8) = buffer;
    ++*(_DWORD *)(a1 + 24);
    *(void *)(a1 + 8) = &buffer[v6];
    unint64_t v9 = (unint64_t)(buffer + 7) & 0xFFFFFFFFFFFFFFF8;
  }
  else
  {
    unint64_t v9 = (*(void *)a1 + 7) & 0xFFFFFFFFFFFFFFF8;
  }
  *(void *)a1 = v9 + 32;
  {
    unint64_t v12 = v9;
    unint64_t v9 = v12;
    if (v13)
    {
      int v21 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::dataflow::CFGEdge]";
      unint64_t v22 = 73;
      unint64_t v14 = llvm::StringRef::find((uint64_t *)&v21, "DesiredTypeName = ", 0x12uLL, 0);
      if (v22 >= v14) {
        unint64_t v15 = v14;
      }
      else {
        unint64_t v15 = v22;
      }
      unint64_t v16 = &v21[v15];
      unint64_t v17 = v22 - v15;
      if (v22 - v15 >= 0x12) {
        uint64_t v18 = 18;
      }
      else {
        uint64_t v18 = v22 - v15;
      }
      unint64_t v19 = v17 - v18;
      if (v19 >= v19 - 1) {
        uint64_t v20 = v19 - 1;
      }
      else {
        uint64_t v20 = v19;
      }
      mlir::detail::TypeIDResolver<mlir::dataflow::CFGEdge,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v16[v18], v20);
      unint64_t v9 = v12;
    }
  }
  uint64_t v10 = mlir::detail::TypeIDResolver<mlir::dataflow::CFGEdge,void>::resolveTypeID(void)::id;
  *(void *)unint64_t v9 = &unk_26C362688;
  *(void *)(v9 + 8) = v10;
  __n128 result = *a2;
  *(__n128 *)(v9 + 16) = *a2;
  *(void *)unint64_t v9 = &unk_26C380338;
  return result;
}

uint64_t mlir::DataFlowSolver::getOrCreateState<mlir::dataflow::Executable,mlir::dataflow::CFGEdge *>(uint64_t a1, uint64_t a2)
{
  uint64_t v33 = *MEMORY[0x263EF8340];
  unint64_t v2 = a2 & 0xFFFFFFFFFFFFFFF9;
  {
    uint64_t v30 = a1;
    a1 = v30;
    if (v22)
    {
      uint64_t v31 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::dataflow::Executable]";
      unint64_t v32 = 76;
      unint64_t v23 = llvm::StringRef::find((uint64_t *)&v31, "DesiredTypeName = ", 0x12uLL, 0);
      if (v32 >= v23) {
        unint64_t v24 = v23;
      }
      else {
        unint64_t v24 = v32;
      }
      unsigned int v25 = &v31[v24];
      unint64_t v26 = v32 - v24;
      if (v32 - v24 >= 0x12) {
        uint64_t v27 = 18;
      }
      else {
        uint64_t v27 = v32 - v24;
      }
      unint64_t v28 = v26 - v27;
      if (v28 >= v28 - 1) {
        uint64_t v29 = v28 - 1;
      }
      else {
        uint64_t v29 = v28;
      }
      mlir::detail::TypeIDResolver<mlir::dataflow::Executable,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v25[v27], v29);
      a1 = v30;
    }
  }
  uint64_t v31 = (const char *)v2;
  unint64_t v32 = mlir::detail::TypeIDResolver<mlir::dataflow::Executable,void>::resolveTypeID(void)::id;
  int v3 = *(_DWORD *)(a1 + 136);
  if (!v3)
  {
    uint64_t v20 = 0;
LABEL_24:
    uint64_t v10 = llvm::DenseMapBase<llvm::DenseMap<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::TypeID>,void>,llvm::detail::DenseMapPair<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>>>,std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::TypeID>,void>,llvm::detail::DenseMapPair<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>>>::InsertIntoBucketImpl<std::pair<mlir::ProgramPoint,mlir::TypeID>>(a1 + 120, (uint64_t)&v31, (uint64_t *)&v31, v20);
    *uint64_t v10 = v31;
    v10[1] = v32;
    void v10[2] = 0;
    goto LABEL_25;
  }
  uint64_t v4 = *(void *)(a1 + 120);
  unint64_t v5 = ((0x2500000000 * v2) | (mlir::detail::TypeIDResolver<mlir::dataflow::Executable,void>::resolveTypeID(void)::id >> 4) ^ (mlir::detail::TypeIDResolver<mlir::dataflow::Executable,void>::resolveTypeID(void)::id >> 9))
     + ~((unint64_t)((mlir::detail::TypeIDResolver<mlir::dataflow::Executable,void>::resolveTypeID(void)::id >> 4) ^ (mlir::detail::TypeIDResolver<mlir::dataflow::Executable,void>::resolveTypeID(void)::id >> 9)) << 32);
  unint64_t v6 = (v5 ^ (v5 >> 22)) + ~((v5 ^ (v5 >> 22)) << 13);
  unint64_t v7 = (9 * (v6 ^ (v6 >> 8))) ^ ((9 * (v6 ^ (v6 >> 8))) >> 15);
  int v8 = v3 - 1;
  unsigned int v9 = v8 & (((v7 + ~(v7 << 27)) >> 31) ^ (v7 + ~(v7 << 27)));
  uint64_t v10 = (void *)(v4 + 24 * v9);
  uint64_t v11 = *v10;
  uint64_t v12 = v10[1];
  if (v2 != *v10 || mlir::detail::TypeIDResolver<mlir::dataflow::Executable,void>::resolveTypeID(void)::id != v12)
  {
    unint64_t v14 = 0;
    int v15 = 1;
    while (v11 != -4096 || v12 != -4096)
    {
      if (v14) {
        BOOL v16 = 0;
      }
      else {
        BOOL v16 = v12 == -8192;
      }
      if (v16 && v11 == -8192) {
        unint64_t v14 = v10;
      }
      unsigned int v18 = v9 + v15++;
      unsigned int v9 = v18 & v8;
      uint64_t v10 = (void *)(v4 + 24 * v9);
      uint64_t v11 = *v10;
      uint64_t v12 = v10[1];
      if (v2 == *v10 && mlir::detail::TypeIDResolver<mlir::dataflow::Executable,void>::resolveTypeID(void)::id == v12) {
        goto LABEL_25;
      }
    }
    if (v14) {
      uint64_t v20 = v14;
    }
    else {
      uint64_t v20 = v10;
    }
    goto LABEL_24;
  }
LABEL_25:
  uint64_t result = v10[2];
  if (!result) {
    operator new();
  }
  return result;
}

const char *mlir::DataFlowSolver::getOrCreateState<mlir::dataflow::Executable,mlir::ProgramPoint>(uint64_t a1, const char *a2)
{
  uint64_t v33 = *MEMORY[0x263EF8340];
  {
    uint64_t v30 = a1;
    a1 = v30;
    if (v22)
    {
      uint64_t v31 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::dataflow::Executable]";
      unint64_t v32 = 76;
      unint64_t v23 = llvm::StringRef::find((uint64_t *)&v31, "DesiredTypeName = ", 0x12uLL, 0);
      if (v32 >= v23) {
        unint64_t v24 = v23;
      }
      else {
        unint64_t v24 = v32;
      }
      unsigned int v25 = &v31[v24];
      unint64_t v26 = v32 - v24;
      if (v32 - v24 >= 0x12) {
        uint64_t v27 = 18;
      }
      else {
        uint64_t v27 = v32 - v24;
      }
      unint64_t v28 = v26 - v27;
      if (v28 >= v28 - 1) {
        uint64_t v29 = v28 - 1;
      }
      else {
        uint64_t v29 = v28;
      }
      mlir::detail::TypeIDResolver<mlir::dataflow::Executable,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v25[v27], v29);
      a1 = v30;
    }
  }
  uint64_t v31 = a2;
  unint64_t v32 = mlir::detail::TypeIDResolver<mlir::dataflow::Executable,void>::resolveTypeID(void)::id;
  int v3 = *(_DWORD *)(a1 + 136);
  if (!v3)
  {
    uint64_t v20 = 0;
LABEL_24:
    uint64_t v10 = (const char **)llvm::DenseMapBase<llvm::DenseMap<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::TypeID>,void>,llvm::detail::DenseMapPair<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>>>,std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::TypeID>,void>,llvm::detail::DenseMapPair<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>>>::InsertIntoBucketImpl<std::pair<mlir::ProgramPoint,mlir::TypeID>>(a1 + 120, (uint64_t)&v31, (uint64_t *)&v31, v20);
    *uint64_t v10 = v31;
    v10[1] = (const char *)v32;
    void v10[2] = 0;
    goto LABEL_25;
  }
  uint64_t v4 = *(void *)(a1 + 120);
  unint64_t v5 = ((0x2500000000 * (void)a2) | (mlir::detail::TypeIDResolver<mlir::dataflow::Executable,void>::resolveTypeID(void)::id >> 4) ^ (mlir::detail::TypeIDResolver<mlir::dataflow::Executable,void>::resolveTypeID(void)::id >> 9))
     + ~((unint64_t)((mlir::detail::TypeIDResolver<mlir::dataflow::Executable,void>::resolveTypeID(void)::id >> 4) ^ (mlir::detail::TypeIDResolver<mlir::dataflow::Executable,void>::resolveTypeID(void)::id >> 9)) << 32);
  unint64_t v6 = (v5 ^ (v5 >> 22)) + ~((v5 ^ (v5 >> 22)) << 13);
  unint64_t v7 = (9 * (v6 ^ (v6 >> 8))) ^ ((9 * (v6 ^ (v6 >> 8))) >> 15);
  int v8 = v3 - 1;
  unsigned int v9 = v8 & (((v7 + ~(v7 << 27)) >> 31) ^ (v7 + ~(v7 << 27)));
  uint64_t v10 = (const char **)(v4 + 24 * v9);
  uint64_t v11 = *v10;
  uint64_t v12 = v10[1];
  if (a2 != *v10
    || mlir::detail::TypeIDResolver<mlir::dataflow::Executable,void>::resolveTypeID(void)::id != (void)v12)
  {
    unint64_t v14 = 0;
    int v15 = 1;
    while (v11 != (const char *)-4096 || v12 != (const char *)-4096)
    {
      if (v14) {
        BOOL v16 = 0;
      }
      else {
        BOOL v16 = v12 == (const char *)-8192;
      }
      if (v16 && v11 == (const char *)-8192) {
        unint64_t v14 = v10;
      }
      unsigned int v18 = v9 + v15++;
      unsigned int v9 = v18 & v8;
      uint64_t v10 = (const char **)(v4 + 24 * v9);
      uint64_t v11 = *v10;
      uint64_t v12 = v10[1];
      if (a2 == *v10
        && mlir::detail::TypeIDResolver<mlir::dataflow::Executable,void>::resolveTypeID(void)::id == (void)v12)
      {
        goto LABEL_25;
      }
    }
    if (v14) {
      uint64_t v20 = v14;
    }
    else {
      uint64_t v20 = v10;
    }
    goto LABEL_24;
  }
LABEL_25:
  uint64_t result = v10[2];
  if (!result) {
    operator new();
  }
  return result;
}

const char *mlir::DataFlowSolver::getOrCreateState<mlir::dataflow::PredecessorState,mlir::ProgramPoint>(uint64_t a1, const char *a2)
{
  uint64_t v33 = *MEMORY[0x263EF8340];
  {
    uint64_t v30 = a1;
    a1 = v30;
    if (v22)
    {
      uint64_t v31 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::dataflow::PredecessorState]";
      unint64_t v32 = 82;
      unint64_t v23 = llvm::StringRef::find((uint64_t *)&v31, "DesiredTypeName = ", 0x12uLL, 0);
      if (v32 >= v23) {
        unint64_t v24 = v23;
      }
      else {
        unint64_t v24 = v32;
      }
      unsigned int v25 = &v31[v24];
      unint64_t v26 = v32 - v24;
      if (v32 - v24 >= 0x12) {
        uint64_t v27 = 18;
      }
      else {
        uint64_t v27 = v32 - v24;
      }
      unint64_t v28 = v26 - v27;
      if (v28 >= v28 - 1) {
        uint64_t v29 = v28 - 1;
      }
      else {
        uint64_t v29 = v28;
      }
      mlir::detail::TypeIDResolver<mlir::dataflow::PredecessorState,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v25[v27], v29);
      a1 = v30;
    }
  }
  uint64_t v31 = a2;
  unint64_t v32 = mlir::detail::TypeIDResolver<mlir::dataflow::PredecessorState,void>::resolveTypeID(void)::id;
  int v3 = *(_DWORD *)(a1 + 136);
  if (!v3)
  {
    uint64_t v20 = 0;
LABEL_24:
    uint64_t v10 = (const char **)llvm::DenseMapBase<llvm::DenseMap<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::TypeID>,void>,llvm::detail::DenseMapPair<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>>>,std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::TypeID>,void>,llvm::detail::DenseMapPair<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>>>::InsertIntoBucketImpl<std::pair<mlir::ProgramPoint,mlir::TypeID>>(a1 + 120, (uint64_t)&v31, (uint64_t *)&v31, v20);
    *uint64_t v10 = v31;
    v10[1] = (const char *)v32;
    void v10[2] = 0;
    goto LABEL_25;
  }
  uint64_t v4 = *(void *)(a1 + 120);
  unint64_t v5 = ((0x2500000000 * (void)a2) | (mlir::detail::TypeIDResolver<mlir::dataflow::PredecessorState,void>::resolveTypeID(void)::id >> 4) ^ (mlir::detail::TypeIDResolver<mlir::dataflow::PredecessorState,void>::resolveTypeID(void)::id >> 9))
     + ~((unint64_t)((mlir::detail::TypeIDResolver<mlir::dataflow::PredecessorState,void>::resolveTypeID(void)::id >> 4) ^ (mlir::detail::TypeIDResolver<mlir::dataflow::PredecessorState,void>::resolveTypeID(void)::id >> 9)) << 32);
  unint64_t v6 = (v5 ^ (v5 >> 22)) + ~((v5 ^ (v5 >> 22)) << 13);
  unint64_t v7 = (9 * (v6 ^ (v6 >> 8))) ^ ((9 * (v6 ^ (v6 >> 8))) >> 15);
  int v8 = v3 - 1;
  unsigned int v9 = v8 & (((v7 + ~(v7 << 27)) >> 31) ^ (v7 + ~(v7 << 27)));
  uint64_t v10 = (const char **)(v4 + 24 * v9);
  uint64_t v11 = *v10;
  uint64_t v12 = v10[1];
  if (a2 != *v10
    || mlir::detail::TypeIDResolver<mlir::dataflow::PredecessorState,void>::resolveTypeID(void)::id != (void)v12)
  {
    unint64_t v14 = 0;
    int v15 = 1;
    while (v11 != (const char *)-4096 || v12 != (const char *)-4096)
    {
      if (v14) {
        BOOL v16 = 0;
      }
      else {
        BOOL v16 = v12 == (const char *)-8192;
      }
      if (v16 && v11 == (const char *)-8192) {
        unint64_t v14 = v10;
      }
      unsigned int v18 = v9 + v15++;
      unsigned int v9 = v18 & v8;
      uint64_t v10 = (const char **)(v4 + 24 * v9);
      uint64_t v11 = *v10;
      uint64_t v12 = v10[1];
      if (a2 == *v10
        && mlir::detail::TypeIDResolver<mlir::dataflow::PredecessorState,void>::resolveTypeID(void)::id == (void)v12)
      {
        goto LABEL_25;
      }
    }
    if (v14) {
      uint64_t v20 = v14;
    }
    else {
      uint64_t v20 = v10;
    }
    goto LABEL_24;
  }
LABEL_25:
  uint64_t result = v10[2];
  if (!result) {
    operator new();
  }
  return result;
}

uint64_t mlir::DataFlowSolver::getOrCreateState<mlir::dataflow::PredecessorState,mlir::Block *>(uint64_t a1, uint64_t a2)
{
  uint64_t v33 = *MEMORY[0x263EF8340];
  uint64_t v2 = a2 | 6;
  {
    uint64_t v30 = a1;
    a1 = v30;
    if (v22)
    {
      uint64_t v31 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::dataflow::PredecessorState]";
      unint64_t v32 = 82;
      unint64_t v23 = llvm::StringRef::find((uint64_t *)&v31, "DesiredTypeName = ", 0x12uLL, 0);
      if (v32 >= v23) {
        unint64_t v24 = v23;
      }
      else {
        unint64_t v24 = v32;
      }
      unsigned int v25 = &v31[v24];
      unint64_t v26 = v32 - v24;
      if (v32 - v24 >= 0x12) {
        uint64_t v27 = 18;
      }
      else {
        uint64_t v27 = v32 - v24;
      }
      unint64_t v28 = v26 - v27;
      if (v28 >= v28 - 1) {
        uint64_t v29 = v28 - 1;
      }
      else {
        uint64_t v29 = v28;
      }
      mlir::detail::TypeIDResolver<mlir::dataflow::PredecessorState,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v25[v27], v29);
      a1 = v30;
    }
  }
  uint64_t v31 = (const char *)v2;
  unint64_t v32 = mlir::detail::TypeIDResolver<mlir::dataflow::PredecessorState,void>::resolveTypeID(void)::id;
  int v3 = *(_DWORD *)(a1 + 136);
  if (!v3)
  {
    uint64_t v20 = 0;
LABEL_24:
    uint64_t v10 = llvm::DenseMapBase<llvm::DenseMap<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::TypeID>,void>,llvm::detail::DenseMapPair<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>>>,std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>,llvm::DenseMapInfo<std::pair<mlir::ProgramPoint,mlir::TypeID>,void>,llvm::detail::DenseMapPair<std::pair<mlir::ProgramPoint,mlir::TypeID>,std::unique_ptr<mlir::AnalysisState>>>::InsertIntoBucketImpl<std::pair<mlir::ProgramPoint,mlir::TypeID>>(a1 + 120, (uint64_t)&v31, (uint64_t *)&v31, v20);
    *uint64_t v10 = v31;
    v10[1] = v32;
    void v10[2] = 0;
    goto LABEL_25;
  }
  uint64_t v4 = *(void *)(a1 + 120);
  unint64_t v5 = ((0x2500000000 * v2) | (mlir::detail::TypeIDResolver<mlir::dataflow::PredecessorState,void>::resolveTypeID(void)::id >> 4) ^ (mlir::detail::TypeIDResolver<mlir::dataflow::PredecessorState,void>::resolveTypeID(void)::id >> 9))
     + ~((unint64_t)((mlir::detail::TypeIDResolver<mlir::dataflow::PredecessorState,void>::resolveTypeID(void)::id >> 4) ^ (mlir::detail::TypeIDResolver<mlir::dataflow::PredecessorState,void>::resolveTypeID(void)::id >> 9)) << 32);
  unint64_t v6 = (v5 ^ (v5 >> 22)) + ~((v5 ^ (v5 >> 22)) << 13);
  unint64_t v7 = (9 * (v6 ^ (v6 >> 8))) ^ ((9 * (v6 ^ (v6 >> 8))) >> 15);
  int v8 = v3 - 1;
  unsigned int v9 = v8 & (((v7 + ~(v7 << 27)) >> 31) ^ (v7 + ~(v7 << 27)));
  uint64_t v10 = (void *)(v4 + 24 * v9);
  uint64_t v11 = *v10;
  uint64_t v12 = v10[1];
  if (v2 != *v10 || mlir::detail::TypeIDResolver<mlir::dataflow::PredecessorState,void>::resolveTypeID(void)::id != v12)
  {
    unint64_t v14 = 0;
    int v15 = 1;
    while (v11 != -4096 || v12 != -4096)
    {
      if (v14) {
        BOOL v16 = 0;
      }
      else {
        BOOL v16 = v12 == -8192;
      }
      if (v16 && v11 == -8192) {
        unint64_t v14 = v10;
      }
      unsigned int v18 = v9 + v15++;
      unsigned int v9 = v18 & v8;
      uint64_t v10 = (void *)(v4 + 24 * v9);
      uint64_t v11 = *v10;
      uint64_t v12 = v10[1];
      if (v2 == *v10
        && mlir::detail::TypeIDResolver<mlir::dataflow::PredecessorState,void>::resolveTypeID(void)::id == v12)
      {
        goto LABEL_25;
      }
    }
    if (v14) {
      uint64_t v20 = v14;
    }
    else {
      uint64_t v20 = v10;
    }
    goto LABEL_24;
  }
LABEL_25:
  uint64_t result = v10[2];
  if (!result) {
    operator new();
  }
  return result;
}

uint64_t mlir::OperationName::hasTrait<mlir::OpTrait::ReturnLike>(void *a1)
{
  uint64_t v1 = &unk_267770000;
  {
    uint64_t v12 = a1;
    uint64_t v1 = (void *)&unk_267770000;
    int v4 = v3;
    a1 = v12;
    if (v4)
    {
      int v13 = "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::ReturnLike<Empty>]";
      unint64_t v14 = 82;
      unint64_t v5 = llvm::StringRef::find((uint64_t *)&v13, "DesiredTypeName = ", 0x12uLL, 0);
      if (v14 >= v5) {
        unint64_t v6 = v5;
      }
      else {
        unint64_t v6 = v14;
      }
      unint64_t v7 = &v13[v6];
      unint64_t v8 = v14 - v6;
      if (v14 - v6 >= 0x12) {
        uint64_t v9 = 18;
      }
      else {
        uint64_t v9 = v14 - v6;
      }
      unint64_t v10 = v8 - v9;
      if (v10 >= v10 - 1) {
        uint64_t v11 = v10 - 1;
      }
      else {
        uint64_t v11 = v10;
      }
      mlir::detail::TypeIDResolver<mlir::OpTrait::ReturnLike<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::ReturnLike>(void)::Empty>,void>::resolveTypeID(void)::id = mlir::detail::FallbackTypeIDResolver::registerImplicitTypeID((uint64_t)&v7[v9], v11);
      uint64_t v1 = (void *)&unk_267770000;
      a1 = v12;
    }
  }
  return (*(uint64_t (**)(void, void))(*(void *)*a1 + 32))(*a1, v1[413]);
}

void mlir::dataflow::AbstractSparseLattice::onUpdate(mlir::dataflow::AbstractSparseLattice *this, mlir::DataFlowSolver *a2)
{
  uint64_t v4 = *((unsigned int *)this + 12);
  if (v4)
  {
    unint64_t v5 = (long long *)*((void *)this + 5);
    uint64_t v6 = *((void *)a2 + 5);
    uint64_t v7 = 16 * v4;
    do
    {
      uint64_t v8 = *((void *)a2 + 2);
      uint64_t v9 = *((void *)a2 + 1);
      long long v10 = *v5;
      if (v8 == v9) {
        uint64_t v11 = 0;
      }
      else {
        uint64_t v11 = 32 * (v8 - v9) - 1;
      }
      unint64_t v12 = *((void *)a2 + 4) + v6;
      if (v11 == v12)
      {
        long long v25 = *v5;
        std::deque<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>>::__add_back_capacity((uint64_t)a2);
        long long v10 = v25;
        uint64_t v9 = *((void *)a2 + 1);
        unint64_t v12 = *((void *)a2 + 5) + *((void *)a2 + 4);
      }
      *(_OWORD *)(*(void *)(v9 + ((v12 >> 5) & 0x7FFFFFFFFFFFFF8)) + 16 * v12) = v10;
      uint64_t v6 = *((void *)a2 + 5) + 1;
      *((void *)a2 + 5) = v6;
      ++v5;
      v7 -= 16;
    }
    while (v7);
  }
  for (uint64_t i = *(void **)(*((void *)this + 1) & 0xFFFFFFFFFFFFFFF8); i; uint64_t i = (void *)*i)
  {
    uint64_t v14 = *((unsigned int *)this + 32);
    if (v14)
    {
      int v15 = (unint64_t *)*((void *)this + 15);
      unint64_t v16 = i[2] & 0xFFFFFFFFFFFFFFF9 | 2;
      uint64_t v17 = *((void *)a2 + 5);
      uint64_t v18 = 8 * v14;
      do
      {
        uint64_t v20 = *((void *)a2 + 2);
        uint64_t v21 = *((void *)a2 + 1);
        unint64_t v22 = *v15;
        if (v20 == v21) {
          uint64_t v23 = 0;
        }
        else {
          uint64_t v23 = 32 * (v20 - v21) - 1;
        }
        unint64_t v24 = v17 + *((void *)a2 + 4);
        if (v23 == v24)
        {
          std::deque<std::pair<mlir::ProgramPoint,mlir::DataFlowAnalysis *>>::__add_back_capacity((uint64_t)a2);
          uint64_t v21 = *((void *)a2 + 1);
          unint64_t v24 = *((void *)a2 + 5) + *((void *)a2 + 4);
        }
        unint64_t v19 = (unint64_t *)(*(void *)(v21 + ((v24 >> 5) & 0x7FFFFFFFFFFFFF8)) + 16 * v24);
        *unint64_t v19 = v16;
        v19[1] = v22;
        uint64_t v17 = *((void *)a2 + 5) + 1;
        *((void *)a2 + 5) = v17;
        ++v15;
        v18 -= 8;
      }
      while (v18);
    }
  }
}

void mlir::dataflow::AbstractSparseForwardDataFlowAnalysis::AbstractSparseForwardDataFlowAnalysis(mlir::dataflow::AbstractSparseForwardDataFlowAnalysis *this, mlir::DataFlowSolver *a2)
{
  *mlir::DataFlowAnalysis::DataFlowAnalysis(this, a2) = &unk_26C3802E8;
  mlir::StorageUniquer::registerParametricStorageType<mlir::dataflow::CFGEdge>();
}

uint64_t mlir::dataflow::AbstractSparseForwardDataFlowAnalysis::initialize(mlir::dataflow::AbstractSparseForwardDataFlowAnalysis *this, mlir::Operation *a2)
{
  unint64_t v4 = *((unsigned int *)a2 + 11);
  if ((v4 & 0x7FFFFF) != 0)
  {
    unint64_t v5 = (void *)((((unint64_t)a2 + 16 * ((v4 >> 23) & 1) + ((v4 >> 21) & 0x7F8) + 71) & 0xFFFFFFFFFFFFFFF8)
                  + 32 * *((unsigned int *)a2 + 10));
    uint64_t v6 = &v5[3 * (v4 & 0x7FFFFF)];
    do
    {
      if ((void *)*v5 != v5)
      {
        uint64_t v7 = v5[1];
        uint64_t v8 = v7 ? v7 - 8 : 0;
        uint64_t v9 = *(uint64_t **)(v8 + 48);
        uint64_t v10 = *(void *)(v8 + 56) - (void)v9;
        if (v10)
        {
          uint64_t v11 = 8 * (v10 >> 3);
          do
          {
            uint64_t v12 = *v9++;
            uint64_t v13 = (*(uint64_t (**)(mlir::dataflow::AbstractSparseForwardDataFlowAnalysis *, uint64_t))(*(void *)this + 48))(this, v12);
            (*(void (**)(mlir::dataflow::AbstractSparseForwardDataFlowAnalysis *, uint64_t))(*(void *)this + 56))(this, v13);
            v11 -= 8;
          }
          while (v11);
        }
      }
      v5 += 3;
    }
    while (v5 != v6);
  }

  return mlir::dataflow::AbstractSparseForwardDataFlowAnalysis::initializeRecursively(this, a2);
}

uint64_t mlir::dataflow::AbstractSparseForwardDataFlowAnalysis::initializeRecursively(mlir::dataflow::AbstractSparseForwardDataFlowAnalysis *this, mlir::Operation *a2)
{
  mlir::dataflow::AbstractSparseForwardDataFlowAnalysis::visitOperation(this, (uint64_t)a2);
  unint64_t v4 = *((unsigned int *)a2 + 11);
  if ((v4 & 0x7FFFFF) != 0)
  {
    unint64_t v5 = (((unint64_t)a2 + 16 * ((v4 >> 23) & 1) + ((v4 >> 21) & 0x7F8) + 71) & 0xFFFFFFFFFFFFFFF8)
       + 32 * *((unsigned int *)a2 + 10);
    unint64_t v6 = v5 + 24 * (v4 & 0x7FFFFF);
LABEL_3:
    for (uint64_t i = *(void *)(v5 + 8); ; uint64_t i = *(void *)(i + 8))
    {
      if (i == v5)
      {
        v5 += 24;
        if (v5 != v6) {
          goto LABEL_3;
        }
        return 1;
      }
      if (i) {
        uint64_t v8 = i - 8;
      }
      else {
        uint64_t v8 = 0;
      }
      uint64_t v9 = mlir::DataFlowSolver::getOrCreateState<mlir::dataflow::Executable,mlir::Block *>(*((void *)this + 1), v8);
      uint64_t v10 = *(void *)(v9 + 72);
      if (v10 != *(void *)(v9 + 64)) {
        goto LABEL_10;
      }
      uint64_t v16 = *(unsigned int *)(v9 + 84);
      if (!v16) {
        break;
      }
      uint64_t v17 = 0;
      uint64_t v18 = 8 * v16;
      unint64_t v19 = *(void **)(v9 + 72);
      while ((mlir::dataflow::AbstractSparseForwardDataFlowAnalysis *)*v19 != this)
      {
        if (*v19 == -2) {
          uint64_t v17 = v19;
        }
        ++v19;
        v18 -= 8;
        if (!v18)
        {
          if (!v17) {
            goto LABEL_26;
          }
          void *v17 = this;
          --*(_DWORD *)(v9 + 88);
          goto LABEL_11;
        }
      }
LABEL_14:
      mlir::dataflow::AbstractSparseForwardDataFlowAnalysis::visitBlock(this, v8);
      uint64_t v13 = (ZinIrHalH13g *)(v8 + 32);
      for (uint64_t j = *(ZinIrHalH13g **)(v8 + 40); j != v13; uint64_t j = (ZinIrHalH13g *)*((void *)j + 1))
      {
        ZinIrHalH13g::~ZinIrHalH13g(j);
        if (!mlir::dataflow::AbstractSparseForwardDataFlowAnalysis::initializeRecursively(this, v15)) {
          return 0;
        }
      }
    }
LABEL_26:
    if (v16 >= *(_DWORD *)(v9 + 80))
    {
LABEL_10:
      llvm::SmallPtrSetImplBase::insert_imp_big((llvm::SmallPtrSetImplBase *)(v9 + 64), this);
      if (!v11) {
        goto LABEL_14;
      }
    }
    else
    {
      *(_DWORD *)(v9 + 84) = v16 + 1;
      *(void *)(v10 + 8 * v16) = this;
    }
LABEL_11:
    unint64_t v12 = *(unsigned int *)(v9 + 136);
    if (v12 >= *(unsigned int *)(v9 + 140))
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod(v9 + 128, (void *)(v9 + 144), v12 + 1, 8);
      unint64_t v12 = *(unsigned int *)(v9 + 136);
    }
    *(void *)(*(void *)(v9 + 128) + 8 * v12) = this;
    ++*(_DWORD *)(v9 + 136);
    goto LABEL_14;
  }
  return 1;
}

void mlir::dataflow::AbstractSparseForwardDataFlowAnalysis::visitOperation(mlir::dataflow::AbstractSparseForwardDataFlowAnalysis *this, uint64_t a2)
{
  v48[6] = *MEMORY[0x263EF8340];
  if (*(_DWORD *)(a2 + 36)
    && *(unsigned char *)(mlir::DataFlowSolver::getOrCreateState<mlir::dataflow::Executable,mlir::Block *>(*((void *)this + 1), *(void *)(a2 + 16))+ 56))
  {
    uint64_t v46 = v48;
    uint64_t v47 = 0x600000000;
    unint64_t v4 = *(unsigned int *)(a2 + 36);
    if (v4 >= 7)
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v46, v48, v4, 8);
      LODWORD(v4) = *(_DWORD *)(a2 + 36);
    }
    if (v4) {
      unint64_t v5 = (char *)(a2 - 16);
    }
    else {
      unint64_t v5 = 0;
    }
    if (v4)
    {
      uint64_t v6 = 0;
      uint64_t v7 = v4;
      do
      {
        uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset((uint64_t)v5, v6);
        uint64_t v9 = (*(uint64_t (**)(mlir::dataflow::AbstractSparseForwardDataFlowAnalysis *, uint64_t))(*(void *)this + 48))(this, NextResultAtOffset);
        uint64_t v10 = v47;
        if (v47 >= (unint64_t)HIDWORD(v47))
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v46, v48, v47 + 1, 8);
          uint64_t v10 = v47;
        }
        *((void *)v46 + v1std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v9;
        LODWORD(v47) = v47 + 1;
        ++v6;
      }
      while (v7 != v6);
    }
    uint64_t v11 = llvm::DefaultDoCastIfPossible<mlir::RegionBranchOpInterface,mlir::Operation *,llvm::CastInfo<mlir::RegionBranchOpInterface,mlir::Operation *,void>>::doCastIfPossible(a2);
    if (v11)
    {
      mlir::dataflow::AbstractSparseForwardDataFlowAnalysis::visitRegionSuccessors((uint64_t *)this, v11 & 0xFFFFFFFFFFFFFFF9 | 2, v11, v12, 0, (uint64_t *)v46, v47);
    }
    else
    {
      uint64_t v13 = llvm::DefaultDoCastIfPossible<mlir::CallOpInterface,mlir::Operation *,llvm::CastInfo<mlir::CallOpInterface,mlir::Operation *,void>>::doCastIfPossible(a2);
      if (v13)
      {
        unint64_t v14 = a2 & 0xFFFFFFFFFFFFFFF9 | 2;
        uint64_t v15 = mlir::DataFlowSolver::getOrCreateState<mlir::dataflow::PredecessorState,mlir::Operation *>(*((void *)this + 1), v13);
        mlir::DataFlowAnalysis::addDependency((uint64_t)this, v15, v14);
        if (*(unsigned char *)(v15 + 56))
        {
          uint64_t v16 = *(unsigned int *)(v15 + 136);
          if (v16)
          {
            uint64_t v17 = *(uint64_t **)(v15 + 128);
            uint64_t v18 = &v17[v16];
            do
            {
              uint64_t v19 = *v17;
              if ((*(unsigned char *)(*v17 + 46) & 0x80) != 0)
              {
                uint64_t v20 = *(unsigned int *)(v19 + 68);
                if (v20 && v47 != 0)
                {
                  unint64_t v22 = (uint64_t *)v46;
                  uint64_t v23 = 8 * v47 - 8;
                  unint64_t v24 = (uint64_t *)(*(void *)(v19 + 72) + 24);
                  uint64_t v25 = v20 - 1;
                  do
                  {
                    uint64_t v27 = *v24;
                    v24 += 4;
                    uint64_t v26 = v27;
                    uint64_t v28 = *v22++;
                    uint64_t v29 = (*(uint64_t (**)(mlir::dataflow::AbstractSparseForwardDataFlowAnalysis *, uint64_t))(*(void *)this + 48))(this, v26);
                    mlir::DataFlowAnalysis::addDependency((uint64_t)this, v29, v14);
                    int v30 = (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)v28 + 32))(v28, v29);
                    mlir::DataFlowAnalysis::propagateIfChanged((uint64_t)this, v28, v30);
                    if (v25-- == 0) {
                      break;
                    }
                    uint64_t v32 = v23;
                    v23 -= 8;
                  }
                  while (v32);
                }
              }
              ++v17;
            }
            while (v17 != v18);
          }
        }
        else if (v47)
        {
          uint64_t v39 = (uint64_t *)v46;
          uint64_t v40 = 8 * v47;
          do
          {
            uint64_t v41 = *v39++;
            (*(void (**)(mlir::dataflow::AbstractSparseForwardDataFlowAnalysis *, uint64_t))(*(void *)this + 56))(this, v41);
            v40 -= 8;
          }
          while (v40);
        }
      }
      else
      {
        unint64_t v43 = v45;
        uint64_t v44 = 0x600000000;
        if ((*(unsigned char *)(a2 + 46) & 0x80) != 0
          && ((unint64_t v33 = *(unsigned int *)(a2 + 68), v33 < 7)
           || (llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v43, v45, v33, 8),
               (*(unsigned char *)(a2 + 46) & 0x80) != 0))
          && (uint64_t v34 = *(unsigned int *)(a2 + 68), v34))
        {
          unint64_t v35 = (void *)(*(void *)(a2 + 72) + 24);
          do
          {
            uint64_t v36 = (*(uint64_t (**)(mlir::dataflow::AbstractSparseForwardDataFlowAnalysis *, void))(*(void *)this + 48))(this, *v35);
            __int16 v42 = this;
            llvm::SetVector<mlir::Operation *,llvm::SmallVector<mlir::Operation *,4u>,llvm::SmallPtrSet<mlir::Operation *,4u>,0u>::insert((llvm::SmallPtrSetImplBase *)(v36 + 56), &v42);
            uint64_t v37 = v44;
            if (v44 >= (unint64_t)HIDWORD(v44))
            {
              llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v43, v45, v44 + 1, 8);
              uint64_t v37 = v44;
            }
            *((void *)v43 + v37) = v36;
            unsigned int v38 = v44 + 1;
            LODWORD(v44) = v44 + 1;
            v35 += 4;
            --v34;
          }
          while (v34);
        }
        else
        {
          unsigned int v38 = v44;
        }
        (*(void (**)(mlir::dataflow::AbstractSparseForwardDataFlowAnalysis *, uint64_t, void *, void, void *, void))(*(void *)this + 32))(this, a2, v43, v38, v46, v47);
        if (v43 != v45) {
          free(v43);
        }
      }
    }
    if (v46 != v48) {
      free(v46);
    }
  }
}

void mlir::dataflow::AbstractSparseForwardDataFlowAnalysis::visitBlock(mlir::dataflow::AbstractSparseForwardDataFlowAnalysis *this, uint64_t a2)
{
  v76[6] = *MEMORY[0x263EF8340];
  uint64_t v69 = a2;
  if (((*(void *)(a2 + 56) - *(void *)(a2 + 48)) & 0x7FFFFFFF8) == 0
    || !*(unsigned char *)(mlir::DataFlowSolver::getOrCreateState<mlir::dataflow::Executable,mlir::Block *>(*((void *)this + 1), a2)+ 56))
  {
    return;
  }
  int32x2_t v74 = v76;
  uint64_t v75 = 0x600000000;
  unint64_t v5 = *(char **)(a2 + 48);
  unint64_t v4 = *(char **)(a2 + 56);
  uint64_t v6 = v4 - v5;
  unint64_t v7 = ((unint64_t)(v4 - v5) >> 3);
  if (v7 >= 7)
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v74, v76, v7, 8);
    unint64_t v5 = *(char **)(a2 + 48);
    unint64_t v4 = *(char **)(a2 + 56);
    uint64_t v6 = v4 - v5;
  }
  if (v4 != v5)
  {
    uint64_t v8 = 8 * (v6 >> 3);
    do
    {
      uint64_t v9 = (*(uint64_t (**)(mlir::dataflow::AbstractSparseForwardDataFlowAnalysis *, void))(*(void *)this + 48))(this, *(void *)v5);
      uint64_t v10 = v75;
      if (v75 >= (unint64_t)HIDWORD(v75))
      {
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v74, v76, v75 + 1, 8);
        uint64_t v10 = v75;
      }
      *((void *)v74 + v1std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v9;
      LODWORD(v75) = v75 + 1;
      v5 += 8;
      v8 -= 8;
    }
    while (v8);
  }
  if (mlir::Block::isEntryBlock((mlir::Block *)a2))
  {
    uint64_t ParentOp = mlir::Block::getParentOp((mlir::Block *)a2);
    char v67 = (mlir::BlockOperand **)llvm::DefaultDoCastIfPossible<mlir::CallableOpInterface,mlir::Operation *,llvm::CastInfo<mlir::CallableOpInterface,mlir::Operation *,void>>::doCastIfPossible(ParentOp);
    int v68 = v12;
    if (!v67
      || (uint64_t canMapOperands = mlir::MemoryMapperInterface::canMapOperands((mlir::MemoryMapperInterface *)&v67),
          canMapOperands != mlir::Block::getParent((mlir::Block *)a2)))
    {
      uint64_t v14 = mlir::Block::getParentOp((mlir::Block *)a2);
      uint64_t v15 = llvm::DefaultDoCastIfPossible<mlir::RegionBranchOpInterface,mlir::Operation *,llvm::CastInfo<mlir::RegionBranchOpInterface,mlir::Operation *,void>>::doCastIfPossible(v14);
      if (v15)
      {
        uint64_t v17 = v15;
        uint64_t v18 = v16;
        unint64_t Parent = mlir::Block::getParent((mlir::Block *)a2);
        mlir::dataflow::AbstractSparseForwardDataFlowAnalysis::visitRegionSuccessors((uint64_t *)this, a2 | 6, v17, v18, Parent, (uint64_t *)v74, v75);
      }
      else
      {
        uint64_t v32 = mlir::Block::getParentOp((mlir::Block *)a2);
        unint64_t v70 = mlir::Block::getParent((mlir::Block *)a2);
        mlir::ValueRange::ValueRange(v71, 0, 0);
        (*(void (**)(mlir::dataflow::AbstractSparseForwardDataFlowAnalysis *, uint64_t, unint64_t *, void *, void, void))(*(void *)this + 40))(this, v32, &v70, v74, v75, 0);
      }
      goto LABEL_58;
    }
    unint64_t v36 = a2 | 6;
    uint64_t v37 = mlir::DataFlowSolver::getOrCreateState<mlir::dataflow::PredecessorState,mlir::Operation *>(*((void *)this + 1), (uint64_t)v67);
    mlir::DataFlowAnalysis::addDependency((uint64_t)this, v37, v36);
    if (!*(unsigned char *)(v37 + 56))
    {
      if (v75)
      {
        int v62 = (uint64_t *)v74;
        uint64_t v63 = 8 * v75;
        do
        {
          uint64_t v64 = *v62++;
          (*(void (**)(mlir::dataflow::AbstractSparseForwardDataFlowAnalysis *, uint64_t))(*(void *)this + 56))(this, v64);
          v63 -= 8;
        }
        while (v63);
      }
      goto LABEL_58;
    }
    uint64_t v38 = *(unsigned int *)(v37 + 136);
    if (!v38) {
      goto LABEL_58;
    }
    uint64_t v39 = *(void ***)(v37 + 128);
    uint64_t v40 = &v39[v38];
    while (1)
    {
      uint64_t v41 = *v39;
      if (!*v39)
      {
        uint64_t Values = 0;
        goto LABEL_48;
      }
      uint64_t v42 = v41[6];
      unint64_t v43 = *(void **)(v42 + 16);
      BOOL v44 = v43 == &mlir::detail::TypeIDResolver<void,void>::id;
      if (v43 == &mlir::detail::TypeIDResolver<void,void>::id) {
        uint64_t v45 = 0;
      }
      else {
        uint64_t v45 = v41[6];
      }
      if (v44)
      {
        unint64_t v70 = *(void *)(v42 + 8);
        uint64_t Values = mlir::SparseElementsAttr::getValues((mlir::SparseElementsAttr *)&v70);
        if (!Values) {
          goto LABEL_48;
        }
        uint64_t v48 = v42;
      }
      else
      {
        unint64_t v46 = v45 | v42 & 0xFFFFFFFFFFFFFF00;
        uint64_t Values = mlir::detail::InterfaceMap::lookup<mlir::CallOpInterface>(v46 + 32);
        if (Values) {
          goto LABEL_48;
        }
        uint64_t Values = *(void *)(v46 + 24);
        uint64_t v48 = v41[6];
      }
      uint64_t Values = mlir::Dialect::getRegisteredInterfaceForOp<mlir::CallOpInterface>(Values, v48);
LABEL_48:
      unint64_t v70 = (unint64_t)v41;
      v71[0] = Values;
      uint64_t ArgOperands = mlir::CallOpInterface::getArgOperands((mlir::CallOpInterface *)&v70);
      if (v50 && v75)
      {
        char v51 = (uint64_t *)v74;
        uint64_t v52 = 8 * v75 - 8;
        unint64_t v53 = (uint64_t *)(ArgOperands + 24);
        uint64_t v54 = v50 - 1;
        do
        {
          uint64_t v56 = *v53;
          v53 += 4;
          uint64_t v55 = v56;
          uint64_t v57 = *v51++;
          uint64_t v58 = (*(uint64_t (**)(mlir::dataflow::AbstractSparseForwardDataFlowAnalysis *, uint64_t))(*(void *)this + 48))(this, v55);
          mlir::DataFlowAnalysis::addDependency((uint64_t)this, v58, v36);
          int v59 = (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)v57 + 32))(v57, v58);
          mlir::DataFlowAnalysis::propagateIfChanged((uint64_t)this, v57, v59);
          if (v54-- == 0) {
            break;
          }
          uint64_t v61 = v52;
          v52 -= 8;
        }
        while (v61);
      }
      if (++v39 == v40) {
        goto LABEL_58;
      }
    }
  }
  char v67 = *(mlir::BlockOperand ***)a2;
  int v68 = (uint64_t (*)(void))mlir::PredecessorIterator::unwrap;
  if (!v67) {
    goto LABEL_58;
  }
  while (1)
  {
    unint64_t v66 = 0;
    unint64_t v66 = (mlir::Block *)v68();
    uint64_t v20 = mlir::StorageUniquer::get<mlir::dataflow::CFGEdge,mlir::Block *&,mlir::Block *&>((unsigned __int8 **)(*((void *)this + 1) + 112), 0, 0, &v66, &v69);
    uint64_t v21 = mlir::DataFlowSolver::getOrCreateState<mlir::dataflow::Executable,mlir::dataflow::CFGEdge *>(*((void *)this + 1), v20);
    unint64_t v70 = (unint64_t)this;
    llvm::SetVector<mlir::Operation *,llvm::SmallVector<mlir::Operation *,4u>,llvm::SmallPtrSet<mlir::Operation *,4u>,0u>::insert((llvm::SmallPtrSetImplBase *)(v21 + 64), (const void **)&v70);
    if (*(unsigned char *)(v21 + 56)) {
      break;
    }
LABEL_17:
    char v67 = (mlir::BlockOperand **)*v67;
    if (!v67) {
      goto LABEL_58;
    }
  }
  mlir::Block::getTerminator((ZinIrHalH13g **)v66);
  v65[0] = llvm::DefaultDoCastIfPossible<mlir::BranchOpInterface,mlir::Operation *,llvm::CastInfo<mlir::BranchOpInterface,mlir::Operation *,void>>::doCastIfPossible(v22);
  v65[1] = v23;
  if (v65[0])
  {
    unint64_t SuccessorIndex = mlir::PredecessorIterator::getSuccessorIndex((mlir::BlockOperand **)&v67);
    mlir::BranchOpInterface::getSuccessorOperands((mlir::BranchOpInterface *)v65, SuccessorIndex);
    if (v75)
    {
      uint64_t v25 = 0;
      uint64_t v26 = v74;
      uint64_t v27 = 8 * v75;
      do
      {
        while (v70 > v25
             || !*(void *)(mlir::MutableOperandRange::operator[](v71, (int)v25 - (int)v70) + 24))
        {
          (*(void (**)(mlir::dataflow::AbstractSparseForwardDataFlowAnalysis *, void))(*(void *)this
                                                                                                  + 56))(this, v26[v25++]);
          v27 -= 8;
          if (!v27) {
            goto LABEL_26;
          }
        }
        uint64_t v28 = v26[v25];
        uint64_t v29 = v69 | 6;
        uint64_t v30 = (*(uint64_t (**)(mlir::dataflow::AbstractSparseForwardDataFlowAnalysis *))(*(void *)this + 48))(this);
        mlir::DataFlowAnalysis::addDependency((uint64_t)this, v30, v29);
        int v31 = (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)v28 + 32))(v28, v30);
        mlir::DataFlowAnalysis::propagateIfChanged((uint64_t)this, v28, v31);
        ++v25;
        v27 -= 8;
      }
      while (v27);
    }
LABEL_26:
    if (v72 != &v73) {
      free(v72);
    }
    goto LABEL_17;
  }
  if (v75)
  {
    unint64_t v33 = (uint64_t *)v74;
    uint64_t v34 = 8 * v75;
    do
    {
      uint64_t v35 = *v33++;
      (*(void (**)(mlir::dataflow::AbstractSparseForwardDataFlowAnalysis *, uint64_t))(*(void *)this + 56))(this, v35);
      v34 -= 8;
    }
    while (v34);
  }
LABEL_58:
  if (v74 != v76) {
    free(v74);
  }
}

uint64_t mlir::dataflow::AbstractSparseForwardDataFlowAnalysis::visit(mlir::dataflow::AbstractSparseForwardDataFlowAnalysis *a1, uint64_t a2)
{
  uint64_t v2 = a2 & 6;
  unint64_t v3 = a2 & 0xFFFFFFFFFFFFFFF8;
  if (v2 == 2 && v3 != 0)
  {
    mlir::dataflow::AbstractSparseForwardDataFlowAnalysis::visitOperation(a1, v3);
    return 1;
  }
  uint64_t v5 = 0;
  if (v2 == 6 && v3)
  {
    mlir::dataflow::AbstractSparseForwardDataFlowAnalysis::visitBlock(a1, v3);
    return 1;
  }
  return v5;
}

void mlir::dataflow::AbstractSparseForwardDataFlowAnalysis::visitRegionSuccessors(uint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t *a6, uint64_t a7)
{
  void v63[4] = *MEMORY[0x263EF8340];
  v59[0] = a3;
  v59[1] = a4;
  uint64_t v10 = mlir::DataFlowSolver::getOrCreateState<mlir::dataflow::PredecessorState,mlir::ProgramPoint>(a1[1], (const char *)a2);
  mlir::DataFlowAnalysis::addDependency((uint64_t)a1, (uint64_t)v10, a2);
  uint64_t v11 = *((unsigned int *)v10 + 34);
  if (!v11) {
    return;
  }
  uint64_t v12 = (uint64_t *)*((void *)v10 + 16);
  BOOL v13 = (a2 & 6) != 2;
  if ((a2 & 0xFFFFFFFFFFFFFFF8) == 0) {
    BOOL v13 = 1;
  }
  BOOL v53 = v13;
  uint64_t v54 = 8 * a7;
  uint64_t v55 = &v12[v11];
  uint64_t v52 = (mlir::Block *)(a2 & 0xFFFFFFFFFFFFFFF8);
  uint64_t v56 = v10;
  while (1)
  {
    uint64_t v14 = *v12;
    if (*v12 != v59[0]) {
      break;
    }
    uint64_t EntrySuccessorOperands = mlir::RegionBranchOpInterface::getEntrySuccessorOperands((uint64_t)v59, a5);
    uint64_t v18 = v20;
    int v19 = *((_DWORD *)v10 + 48);
    if (!v19) {
      goto LABEL_21;
    }
LABEL_13:
    uint64_t v21 = *((void *)v10 + 22);
    int v22 = v19 - 1;
    unsigned int v23 = (v19 - 1) & ((v14 >> 4) ^ (v14 >> 9));
    uint64_t v24 = *(void *)(v21 + 24 * v23);
    if (v24 == v14)
    {
LABEL_14:
      long long v61 = *(_OWORD *)(v21 + 24 * v23 + 8);
      uint64_t v25 = *((void *)&v61 + 1);
      long long v60 = v61;
      if (*((void *)&v61 + 1) == a7) {
        goto LABEL_15;
      }
      goto LABEL_22;
    }
    int v27 = 1;
    while (v24 != -4096)
    {
      unsigned int v28 = v23 + v27++;
      unsigned int v23 = v28 & v22;
      uint64_t v24 = *(void *)(v21 + 24 * v23);
      if (v24 == v14) {
        goto LABEL_14;
      }
    }
LABEL_21:
    mlir::ValueRange::ValueRange((unint64_t *)&v61, 0, 0);
    uint64_t v25 = *((void *)&v61 + 1);
    long long v60 = v61;
    if (*((void *)&v61 + 1) == a7)
    {
LABEL_15:
      LODWORD(v26) = 0;
      if (v18) {
        goto LABEL_48;
      }
      goto LABEL_5;
    }
LABEL_22:
    if (v53)
    {
      uint64_t v29 = EntrySuccessorOperands;
      if (v25)
      {
        uint64_t v26 = *(unsigned int *)(mlir::ValueRange::dereference_iterator(&v60, 0) + 24);
        unint64_t Parent = (void *)mlir::Block::getParent(v52);
        uint64_t v31 = v59[0];
        if ((void *)*Parent != Parent) {
          goto LABEL_25;
        }
LABEL_34:
        uint64_t v34 = 0;
      }
      else
      {
        uint64_t v26 = 0;
        unint64_t Parent = (void *)mlir::Block::getParent(v52);
        uint64_t v31 = v59[0];
        if ((void *)*Parent == Parent) {
          goto LABEL_34;
        }
LABEL_25:
        uint64_t v32 = Parent[1];
        if (v32) {
          uint64_t v33 = v32 - 8;
        }
        else {
          uint64_t v33 = 0;
        }
        uint64_t v34 = *(void *)(v33 + 48);
      }
      *(void *)&long long v61 = Parent;
      mlir::ValueRange::ValueRange((unint64_t *)&v61 + 1, v34 + 8 * v26, *((unint64_t *)&v60 + 1));
      (*(void (**)(uint64_t *, uint64_t, long long *, uint64_t *, uint64_t, uint64_t))(*a1 + 40))(a1, v31, &v61, a6, a7, v26);
      goto LABEL_47;
    }
    if (v25)
    {
      uint64_t v35 = mlir::ValueRange::dereference_iterator(&v60, 0);
      if (v35 && (*(void *)(v35 + 8) & 7) == 6)
      {
        uint64_t v29 = EntrySuccessorOperands;
        uint64_t v26 = (*(_DWORD *)(v35 + 16) + 6);
      }
      else
      {
        uint64_t v29 = EntrySuccessorOperands;
        uint64_t v26 = *(void *)(v35 + 8) & 7;
      }
      uint64_t v36 = v59[0];
      if (*(_DWORD *)(v59[0] + 36)) {
        uint64_t NextResultAtOffset = v59[0] - 16;
      }
      else {
        uint64_t NextResultAtOffset = 0;
      }
      unint64_t v38 = *((void *)&v60 + 1);
      if (v26) {
        uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(NextResultAtOffset, v26);
      }
    }
    else
    {
      uint64_t v29 = EntrySuccessorOperands;
      uint64_t v26 = 0;
      uint64_t v36 = v59[0];
      if (*(_DWORD *)(v59[0] + 36)) {
        uint64_t NextResultAtOffset = v59[0] - 16;
      }
      else {
        uint64_t NextResultAtOffset = 0;
      }
      unint64_t v38 = *((void *)&v60 + 1);
    }
    *(void *)&long long v61 = 0;
    mlir::ValueRange::ValueRange((unint64_t *)&v61 + 1, NextResultAtOffset, v38);
    (*(void (**)(uint64_t *, uint64_t, long long *, uint64_t *, uint64_t, uint64_t))(*a1 + 40))(a1, v36, &v61, a6, a7, v26);
LABEL_47:
    uint64_t EntrySuccessorOperands = v29;
    if (v18)
    {
LABEL_48:
      if (a7 != v26)
      {
        uint64_t v39 = v26;
        uint64_t v40 = &a6[v39];
        uint64_t v41 = 8 * a7 - 8 - v39 * 8;
        uint64_t v42 = (uint64_t *)(EntrySuccessorOperands + 24);
        uint64_t v43 = v18 - 1;
        do
        {
          uint64_t v45 = *v42;
          v42 += 4;
          uint64_t v44 = v45;
          uint64_t v46 = *v40++;
          uint64_t v47 = (*(uint64_t (**)(uint64_t *, uint64_t))(*a1 + 48))(a1, v44);
          mlir::DataFlowAnalysis::addDependency((uint64_t)a1, v47, a2);
          int v48 = (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)v46 + 32))(v46, v47);
          mlir::DataFlowAnalysis::propagateIfChanged((uint64_t)a1, v46, v48);
          if (v43-- == 0) {
            break;
          }
          uint64_t v50 = v41;
          v41 -= 8;
        }
        while (v50);
      }
    }
LABEL_5:
    ++v12;
    uint64_t v10 = v56;
    if (v12 == v55) {
      return;
    }
  }
  *(void *)&long long v60 = llvm::DefaultDoCastIfPossible<mlir::RegionBranchTerminatorOpInterface,mlir::Operation *,llvm::CastInfo<mlir::RegionBranchTerminatorOpInterface,mlir::Operation *,void>>::doCastIfPossible(*v12);
  *((void *)&v60 + 1) = v15;
  if ((void)v60)
  {
    mlir::BranchOpInterface::getSuccessorOperands((mlir::BranchOpInterface *)&v60, a5);
    uint64_t EntrySuccessorOperands = mlir::MutableOperandRange::operator mlir::OperandRange((unsigned int *)&v61);
    uint64_t v18 = v17;
    if (v62 != v63) {
      free(v62);
    }
    int v19 = *((_DWORD *)v10 + 48);
    if (!v19) {
      goto LABEL_21;
    }
    goto LABEL_13;
  }
  if (a7)
  {
    do
    {
      uint64_t v51 = *a6++;
      (*(void (**)(uint64_t *, uint64_t))(*a1 + 56))(a1, v51);
      v54 -= 8;
    }
    while (v54);
  }
}

uint64_t mlir::dataflow::AbstractSparseForwardDataFlowAnalysis::setAllToEntryStates(uint64_t result, uint64_t *a2, uint64_t a3)
{
  if (a3)
  {
    uint64_t v4 = result;
    uint64_t v5 = 8 * a3;
    do
    {
      uint64_t v6 = *a2++;
      uint64_t result = (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)v4 + 56))(v4, v6);
      v5 -= 8;
    }
    while (v5);
  }
  return result;
}

uint64_t mlir::dataflow::AbstractSparseLattice::join()
{
  return 0;
}

uint64_t mlir::dataflow::AbstractSparseLattice::meet()
{
  return 0;
}

void mlir::anec::ANECDialect::ANECDialect(mlir::anec::ANECDialect *this, mlir::MLIRContext *a2)
{
  *(void *)mlir::Dialect::Dialect((uint64_t)this, (uint64_t)"anec", 4, (uint64_t)a2, (uint64_t)&mlir::detail::TypeIDResolver<mlir::anec::ANECDialect,void>::id) = &unk_26C37E958;
  mlir::Dialect::addOperations<mlir::anec::A11Legacy,mlir::anec::A12,mlir::anec::A13,mlir::anec::A14,mlir::anec::A15,mlir::anec::A16,mlir::anec::A17,mlir::anec::ArgMinMax,mlir::anec::AveragePool,mlir::anec::BatchToSpace,mlir::anec::Broadcast,mlir::anec::Cast,mlir::anec::Ceil,mlir::anec::ChannelToSpace,mlir::anec::ClampedRelu,mlir::anec::Concat,mlir::anec::Convolution,mlir::anec::Cos,mlir::anec::CropResize,mlir::anec::DeQuant,mlir::anec::Deconvolution,mlir::anec::Degamma,mlir::anec::Dirac,mlir::anec::ElementwiseAbs,mlir::anec::ElementwiseAdd,mlir::anec::ElementwiseDiv,mlir::anec::ElementwiseEqual,mlir::anec::ElementwiseEqualZero,mlir::anec::ElementwiseGreaterThan,mlir::anec::ElementwiseGreaterThanEqual,mlir::anec::ElementwiseGreaterThanEqualZero,mlir::anec::ElementwiseGreaterThanZero,mlir::anec::ElementwiseLessThan,mlir::anec::ElementwiseLessThanEqual,mlir::anec::ElementwiseLessThanEqualZero,mlir::anec::ElementwiseLessThanZero,mlir::anec::ElementwiseMax,mlir::anec::ElementwiseMin,mlir::anec::ElementwiseMult,mlir::anec::ElementwiseNotEqual,mlir::anec::ElementwiseNotEqualZero,mlir::anec::ElementwisePower,mlir::anec::ElementwiseSquare,mlir::anec::ElementwiseSub,mlir::anec::Elu,mlir::anec::Erf,mlir::anec::Exp2,mlir::anec::Flatten,mlir::anec::Floor,mlir::anec::GOC,mlir::anec::GatherND,mlir::anec::Gelu,mlir::anec::GlobalArgMinMax,mlir::anec::HighPrecisionSigmoid,mlir::anec::InputView,mlir::anec::InstanceNorm,mlir::anec::Invert,mlir::anec::L2NormPool,mlir::anec::LeakyRelu,mlir::anec::Linear,mlir::anec::Log2,mlir::anec::MatMul,mlir::anec::MaxPool,mlir::anec::NRelu,mlir::anec::Padding,mlir::anec::PixelShuffle,mlir::anec::PixelUnshuffle,mlir::anec::Quant,mlir::anec::ReduceAvg,mlir::anec::ReduceMax,mlir::anec::ReduceMin,mlir::anec::ReduceSum,mlir::anec::RegionReturn,mlir::anec::Relu,mlir::anec::Reshape,mlir::anec::Resize,mlir::anec::RoundNearest,mlir::anec::Rsqrt,mlir::anec::Sigmoid,mlir::anec::Sign,mlir::anec::Sin,mlir::anec::Softmax,mlir::anec::SpaceToBatch,mlir::anec::SpaceToChannel,mlir::anec::Sqr,mlir::anec::Sqrt,mlir::anec::Swish,mlir::anec::T0,mlir::anec::Tanh,mlir::anec::Tile,mlir::anec::Transpose,mlir::anec::Trunc,mlir::anec::Unflatten,mlir::anec::UnrealizedConversionCast>();
}

void mlir::anec::ANECDialect::~ANECDialect(llvm **this)
{
}

void sub_2113CE228()
{
  JUMPOUT(0x21667D3C0);
}

uint64_t mlir::anec::BoxCoordinateModeAttr::classof(uint64_t a1)
{
  if (*(_UNKNOWN **)(*(void *)a1 + 136) != &mlir::detail::TypeIDResolver<mlir::IntegerAttr,void>::id) {
    return 0;
  }
  uint64_t v19 = a1;
  uint64_t Value = mlir::AffineMapAttr::getValue((mlir::AffineMapAttr *)&v19);
  uint64_t result = mlir::Type::isSignlessInteger((mlir::Type *)&Value, 64);
  if (result)
  {
    uint64_t v18 = a1;
    if (mlir::IntegerAttr::getInt((mlir::IntegerAttr *)&v18))
    {
      uint64_t v17 = a1;
      uint64_t result = mlir::IntegerAttr::getInt((mlir::IntegerAttr *)&v17);
      if (result == 1) {
        return result;
      }
      uint64_t v16 = a1;
      if (mlir::IntegerAttr::getInt((mlir::IntegerAttr *)&v16) != 2)
      {
        uint64_t v15 = a1;
        if (mlir::IntegerAttr::getInt((mlir::IntegerAttr *)&v15) != 3)
        {
          uint64_t v14 = a1;
          if (mlir::IntegerAttr::getInt((mlir::IntegerAttr *)&v14) != 4)
          {
            uint64_t v13 = a1;
            if (mlir::IntegerAttr::getInt((mlir::IntegerAttr *)&v13) != 5)
            {
              uint64_t v12 = a1;
              if (mlir::IntegerAttr::getInt((mlir::IntegerAttr *)&v12) != 6)
              {
                uint64_t v11 = a1;
                if (mlir::IntegerAttr::getInt((mlir::IntegerAttr *)&v11) != 7)
                {
                  uint64_t v10 = a1;
                  if (mlir::IntegerAttr::getInt((mlir::IntegerAttr *)&v10) != 8)
                  {
                    uint64_t v9 = a1;
                    if (mlir::IntegerAttr::getInt((mlir::IntegerAttr *)&v9) != 9)
                    {
                      uint64_t v8 = a1;
                      if (mlir::IntegerAttr::getInt((mlir::IntegerAttr *)&v8) != 10)
                      {
                        uint64_t v7 = a1;
                        if (mlir::IntegerAttr::getInt((mlir::IntegerAttr *)&v7) != 11)
                        {
                          uint64_t v6 = a1;
                          if (mlir::IntegerAttr::getInt((mlir::IntegerAttr *)&v6) != 12)
                          {
                            uint64_t v5 = a1;
                            if (mlir::IntegerAttr::getInt((mlir::IntegerAttr *)&v5) != 13)
                            {
                              uint64_t v4 = a1;
                              if (mlir::IntegerAttr::getInt((mlir::IntegerAttr *)&v4) != 14)
                              {
                                uint64_t v3 = a1;
                                return mlir::IntegerAttr::getInt((mlir::IntegerAttr *)&v3) == 15;
                              }
                            }
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          }
        }
      }
    }
    return 1;
  }
  return result;
}

uint64_t mlir::anec::BoxCoordinateModeAttr::get(uint64_t a1, unint64_t a2)
{
  uint64_t v3 = mlir::IntegerType::get(a1, 0x40u, 0);

  return mlir::IntegerAttr::get(v3, a2);
}

uint64_t mlir::anec::PaddingModeAttr::classof(uint64_t a1)
{
  if (*(_UNKNOWN **)(*(void *)a1 + 136) != &mlir::detail::TypeIDResolver<mlir::IntegerAttr,void>::id) {
    return 0;
  }
  uint64_t v12 = a1;
  uint64_t Value = mlir::AffineMapAttr::getValue((mlir::AffineMapAttr *)&v12);
  uint64_t result = mlir::Type::isSignlessInteger((mlir::Type *)&Value, 64);
  if (result)
  {
    uint64_t v11 = a1;
    if (mlir::IntegerAttr::getInt((mlir::IntegerAttr *)&v11))
    {
      uint64_t v10 = a1;
      uint64_t result = mlir::IntegerAttr::getInt((mlir::IntegerAttr *)&v10);
      if (result == 1) {
        return result;
      }
      uint64_t v9 = a1;
      if (mlir::IntegerAttr::getInt((mlir::IntegerAttr *)&v9) != 2)
      {
        uint64_t v8 = a1;
        if (mlir::IntegerAttr::getInt((mlir::IntegerAttr *)&v8) != 3)
        {
          uint64_t v7 = a1;
          if (mlir::IntegerAttr::getInt((mlir::IntegerAttr *)&v7) != 4)
          {
            uint64_t v6 = a1;
            if (mlir::IntegerAttr::getInt((mlir::IntegerAttr *)&v6) != 5)
            {
              uint64_t v5 = a1;
              if (mlir::IntegerAttr::getInt((mlir::IntegerAttr *)&v5) != 6)
              {
                uint64_t v4 = a1;
                if (mlir::IntegerAttr::getInt((mlir::IntegerAttr *)&v4) != 7)
                {
                  uint64_t v3 = a1;
                  return mlir::IntegerAttr::getInt((mlir::IntegerAttr *)&v3) == 8;
                }
              }
            }
          }
        }
      }
    }
    return 1;
  }
  return result;
}

void mlir::Dialect::addOperations<mlir::anec::A11Legacy,mlir::anec::A12,mlir::anec::A13,mlir::anec::A14,mlir::anec::A15,mlir::anec::A16,mlir::anec::A17,mlir::anec::ArgMinMax,mlir::anec::AveragePool,mlir::anec::BatchToSpace,mlir::anec::Broadcast,mlir::anec::Cast,mlir::anec::Ceil,mlir::anec::ChannelToSpace,mlir::anec::ClampedRelu,mlir::anec::Concat,mlir::anec::Convolution,mlir::anec::Cos,mlir::anec::CropResize,mlir::anec::DeQuant,mlir::anec::Deconvolution,mlir::anec::Degamma,mlir::anec::Dirac,mlir::anec::ElementwiseAbs,mlir::anec::ElementwiseAdd,mlir::anec::ElementwiseDiv,mlir::anec::ElementwiseEqual,mlir::anec::ElementwiseEqualZero,mlir::anec::ElementwiseGreaterThan,mlir::anec::ElementwiseGreaterThanEqual,mlir::anec::ElementwiseGreaterThanEqualZero,mlir::anec::ElementwiseGreaterThanZero,mlir::anec::ElementwiseLessThan,mlir::anec::ElementwiseLessThanEqual,mlir::anec::ElementwiseLessThanEqualZero,mlir::anec::ElementwiseLessThanZero,mlir::anec::ElementwiseMax,mlir::anec::ElementwiseMin,mlir::anec::ElementwiseMult,mlir::anec::ElementwiseNotEqual,mlir::anec::ElementwiseNotEqualZero,mlir::anec::ElementwisePower,mlir::anec::ElementwiseSquare,mlir::anec::ElementwiseSub,mlir::anec::Elu,mlir::anec::Erf,mlir::anec::Exp2,mlir::anec::Flatten,mlir::anec::Floor,mlir::anec::GOC,mlir::anec::GatherND,mlir::anec::Gelu,mlir::anec::GlobalArgMinMax,mlir::anec::HighPrecisionSigmoid,mlir::anec::InputView,mlir::anec::InstanceNorm,mlir::anec::Invert,mlir::anec::L2NormPool,mlir::anec::LeakyRelu,mlir::anec::Linear,mlir::anec::Log2,mlir::anec::MatMul,mlir::anec::MaxPool,mlir::anec::NRelu,mlir::anec::Padding,mlir::anec::PixelShuffle,mlir::anec::PixelUnshuffle,mlir::anec::Quant,mlir::anec::ReduceAvg,mlir::anec::ReduceMax,mlir::anec::ReduceMin,mlir::anec::ReduceSum,mlir::anec::RegionReturn,mlir::anec::Relu,mlir::anec::Reshape,mlir::anec::Resize,mlir::anec::RoundNearest,mlir::anec::Rsqrt,mlir::anec::Sigmoid,mlir::anec::Sign,mlir::anec::Sin,mlir::anec::Softmax,mlir::anec::SpaceToBatch,mlir::anec::SpaceToChannel,mlir::anec::Sqr,mlir::anec::Sqrt,mlir::anec::Swish,mlir::anec::T0,mlir::anec::Tanh,mlir::anec::Tile,mlir::anec::Transpose,mlir::anec::Trunc,mlir::anec::Unflatten,mlir::anec::UnrealizedConversionCast>()
{
}

uint64_t *mlir::anec::ANECDialect::materializeConstant(uint64_t a1, mlir::OpBuilder *a2, uint64_t *a3, uint64_t a4, uint64_t a5)
{
  uint64_t v10 = a4;
  uint64_t result = llvm::DefaultDoCastIfPossible<mlir::ElementsAttr,mlir::Attribute const,llvm::CastInfo<mlir::ElementsAttr,mlir::Attribute const,void>>::doCastIfPossible(a3);
  v9[0] = result;
  v9[1] = v8;
  if (result) {
    return (uint64_t *)mlir::OpBuilder::create<mlir::mps::ConstantOp,mlir::Type &,mlir::ElementsAttr &>(a2, a5, &v10, v9);
  }
  return result;
}

ZinIrHalH13g *mlir::OpBuilder::create<mlir::mps::ConstantOp,mlir::Type &,mlir::ElementsAttr &>(mlir::OpBuilder *a1, uint64_t a2, uint64_t *a3, void **a4)
{
  v19[38] = *MEMORY[0x263EF8340];
  uint64_t v14 = a2;
  Context = (uint64_t *)mlir::Attribute::getContext((mlir::Attribute *)&v14);
  uint64_t v9 = mlir::RegisteredOperationName::lookup((int8x16_t *)"mps.constant", (const unsigned __int8 *)0xC, Context);
  if (!v10)
  {
    __int16 v18 = 1283;
    unint64_t v17[2] = (uint64_t)"mps.constant";
    v17[3] = 12;
          " the dialect. See also https://mlir.llvm.org/getting_started/Faq/#registered-loaded-dependent-whats-up-with-di"
          "alects-management";
    __int16 v16 = 259;
    llvm::operator+(v17, (uint64_t *)&v15, (uint64_t)v19);
    llvm::report_fatal_error((llvm::Twine *)v19, 1);
  }
  mlir::OperationState::OperationState(v19, a2, v9);
  mlir::mps::ConstantOp::build((uint64_t)a1, (uint64_t)v19, *a3, *a4);
  uint64_t v11 = mlir::OpBuilder::create(a1, (const mlir::OperationState *)v19);
  if (*(_UNKNOWN **)(*((void *)v11 + 6) + 16) == &mlir::detail::TypeIDResolver<mlir::mps::ConstantOp,void>::id) {
    uint64_t v12 = v11;
  }
  else {
    uint64_t v12 = 0;
  }
  mlir::OperationState::~OperationState((mlir::OperationState *)v19);
  return v12;
}

void mlir::anec::getANECInputName(uint64_t a1@<X0>, std::string *a2@<X8>)
{
  uint64_t v4 = *(unsigned int *)(a1 + 24);
  v2[0] = "__arg";
  _OWORD v2[2] = &v4;
  __int16 v3 = 3331;
  llvm::Twine::str((llvm::Twine *)v2, a2);
}

uint64_t *llvm::operator+@<X0>(uint64_t *result@<X0>, uint64_t *a2@<X1>, uint64_t a3@<X8>)
{
  int v3 = *((unsigned __int8 *)result + 32);
  if (*((unsigned char *)result + 32) && (int v4 = *((unsigned __int8 *)a2 + 32), *((unsigned char *)a2 + 32)))
  {
    if (v3 == 1)
    {
      long long v5 = *((_OWORD *)a2 + 1);
      *(_OWORD *)a3 = *(_OWORD *)a2;
      *(_OWORD *)(a3 + 16) = v5;
      *(void *)(a3 + 32) = a2[4];
    }
    else if (v4 == 1)
    {
      long long v6 = *((_OWORD *)result + 1);
      *(_OWORD *)a3 = *(_OWORD *)result;
      *(_OWORD *)(a3 + 16) = v6;
      *(void *)(a3 + 32) = result[4];
    }
    else
    {
      uint64_t v7 = (uint64_t *)*result;
      uint64_t v8 = result[1];
      if (*((unsigned char *)result + 33) != 1)
      {
        LOBYTE(v3) = 2;
        uint64_t v7 = result;
      }
      uint64_t v9 = a2[1];
      if (*((unsigned char *)a2 + 33) == 1)
      {
        char v10 = (uint64_t *)*a2;
      }
      else
      {
        LOBYTE(v4) = 2;
        char v10 = a2;
      }
      *(void *)a3 = v7;
      *(void *)(a3 + 8) = v8;
      *(void *)(a3 + 16) = v10;
      *(void *)(a3 + 24) = v9;
      *(unsigned char *)(a3 + 32) = v3;
      *(unsigned char *)(a3 + 33) = v4;
    }
  }
  else
  {
    *(_WORD *)(a3 + 32) = 256;
  }
  return result;
}

uint64_t mlir::anec::getOpMinimumFamilyImpl<(mlir::anec::Family)0>(uint64_t a1)
{
  v7[23] = *MEMORY[0x263EF8340];
  uint64_t v2 = mlir::TypeID::get<mlir::OpTrait::anec::MinimumFamily<(mlir::anec::Family)0>::Impl<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::anec::MinimumFamily<(mlir::anec::Family)0>::Impl>(void)::Empty>>();
  if ((*(uint64_t (**)(void, uint64_t))(**(void **)(a1 + 48) + 32))(*(void *)(a1 + 48), v2)) {
    return 0x100000000;
  }
  __int16 v5 = 259;
  mlir::Operation::emitOpError(a1, &v4, (uint64_t)&v6);
  mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v6);
  if (v6) {
    mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v6);
  }
  std::__optional_destruct_base<mlir::Diagnostic,false>::~__optional_destruct_base[abi:nn180100]((uint64_t)v7);
  return 0;
}

void mlir::InFlightDiagnostic::~InFlightDiagnostic(mlir::InFlightDiagnostic *this)
{
  if (*(void *)this) {
    mlir::InFlightDiagnostic::report(this);
  }
  std::__optional_destruct_base<mlir::Diagnostic,false>::~__optional_destruct_base[abi:nn180100]((uint64_t)this + 8);
}

uint64_t mlir::anec::getOpMinimumFamilyImpl<(mlir::anec::Family)6>(uint64_t a1)
{
  uint64_t v2 = 0x100000004;
  uint64_t v3 = mlir::TypeID::get<mlir::OpTrait::anec::MinimumFamily<(mlir::anec::Family)6>::Impl<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::anec::MinimumFamily<(mlir::anec::Family)6>::Impl>(void)::Empty>>();
  if ((*(uint64_t (**)(void, uint64_t))(**(void **)(a1 + 48) + 32))(*(void *)(a1 + 48), v3)) {
    return 0x100000006;
  }
  uint64_t v4 = mlir::TypeID::get<mlir::OpTrait::anec::MinimumFamily<(mlir::anec::Family)5>::Impl<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::anec::MinimumFamily<(mlir::anec::Family)5>::Impl>(void)::Empty>>();
  if ((*(uint64_t (**)(void, uint64_t))(**(void **)(a1 + 48) + 32))(*(void *)(a1 + 48), v4)) {
    return 0x100000005;
  }
  uint64_t v5 = mlir::TypeID::get<mlir::OpTrait::anec::MinimumFamily<(mlir::anec::Family)4>::Impl<mlir::TypeID mlir::TypeID::get<mlir::OpTrait::anec::MinimumFamily<(mlir::anec::Family)4>::Impl>(void)::Empty>>();
  if ((*(uint64_t (**)(void, uint64_t))(**(void **)(a1 + 48) + 32))(*(void *)(a1 + 48), v5)) {
    return v2;
  }

  return mlir::anec::getOpMinimumFamilyImpl<(mlir::anec::Family)3>(a1);
}

BOOL mlir::anec::isCompatibleWithFamily(uint64_t a1, int a2)
{
  uint64_t v3 = mlir::anec::getOpMinimumFamilyImpl<(mlir::anec::Family)6>(a1);
  return (v3 & 0xFF00000000) == 0 || (int)v3 <= a2;
}

void mlir::anec::anonymous namespace'::getZinIrEWUnitInfo(mlir::anec::_anonymous_namespace_ *this, mlir::Operation *a2)
{
}

void mlir::anec::Broadcast::getZinIrUnitInfo(mlir::anec::Broadcast *this)
{
}

void mlir::anec::anonymous namespace'::fillZinIrCommonInfo(uint64_t a1, uint64_t a2, int a3, unint64_t a4, char a5)
{
  mlir::anec::computeOpKeyString((mlir::anec *)a1, &__str);
  std::string::operator=((std::string *)(a2 + 8), &__str);
  int v70 = a3;
  *(_DWORD *)(a2 + 32) = a3;
  char v10 = (const char *)(*(void *)(*(void *)(*(void *)(a1 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8);
  if (!v10) {
    goto LABEL_10;
  }
  uint64_t v11 = *(void *)v10;
  unint64_t v12 = mlir::TypeID::get<mlir::ShapedType>();
  unint64_t v13 = *(unsigned int *)(v11 + 16);
  if (!v13) {
    goto LABEL_10;
  }
  uint64_t v14 = *(void **)(v11 + 8);
  uint64_t v15 = &v14[2 * v13];
  do
  {
    unint64_t v16 = v13 >> 1;
    uint64_t v17 = &v14[2 * (v13 >> 1)];
    unint64_t v19 = *v17;
    __int16 v18 = v17 + 2;
    v13 += ~(v13 >> 1);
    if (v19 < v12) {
      uint64_t v14 = v18;
    }
    else {
      unint64_t v13 = v16;
    }
  }
  while (v13);
  if (v14 != v15 && *v14 == v12) {
    uint64_t v20 = v14[1];
  }
  else {
LABEL_10:
  }
    uint64_t v20 = 0;
  int32x2_t v74 = v10;
  uint64_t v75 = v20;
  uint64_t OperandRange = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&v74);
  uint64_t v69 = a1;
  if ((*(unsigned char *)(a1 + 46) & 0x80) != 0)
  {
    uint64_t v22 = *(unsigned int *)(a1 + 68);
    if (v22)
    {
      unint64_t v23 = 0;
      uint64_t v24 = *(void *)(a1 + 72);
      do
      {
        uint64_t v25 = v24 + 32 * v23;
        uint64_t v26 = *(void *)(v25 + 24);
        if (a5 && v23 >= a4) {
          break;
        }
        uint64_t v73 = *(void *)(v25 + 24);
        if (mlir::Value::getDefiningOp((mlir::Value *)&v73))
        {
          uint64_t DefiningOp = (mlir::anec *)mlir::Value::getDefiningOp((mlir::Value *)&v73);
          mlir::anec::computeOpKeyString(DefiningOp, &__p);
        }
        else
        {
          uint64_t v28 = v73;
          if ((~*(_DWORD *)(v73 + 8) & 7) != 0) {
            uint64_t v28 = 0;
          }
          uint64_t v78 = *(unsigned int *)(v28 + 24);
          int32x2_t v74 = "__arg";
          char v76 = &v78;
          __int16 v77 = 3331;
          llvm::Twine::str((llvm::Twine *)&v74, &__p);
        }
        uint64_t v29 = (const char *)(*(void *)(v26 + 8) & 0xFFFFFFFFFFFFFFF8);
        if (!v29) {
          goto LABEL_31;
        }
        uint64_t v30 = *(void *)v29;
        unint64_t v31 = mlir::TypeID::get<mlir::ShapedType>();
        unint64_t v32 = *(unsigned int *)(v30 + 16);
        if (!v32) {
          goto LABEL_31;
        }
        uint64_t v33 = *(void **)(v30 + 8);
        uint64_t v34 = &v33[2 * v32];
        do
        {
          unint64_t v35 = v32 >> 1;
          uint64_t v36 = &v33[2 * (v32 >> 1)];
          unint64_t v38 = *v36;
          uint64_t v37 = v36 + 2;
          v32 += ~(v32 >> 1);
          if (v38 < v31) {
            uint64_t v33 = v37;
          }
          else {
            unint64_t v32 = v35;
          }
        }
        while (v32);
        if (v33 != v34 && *v33 == v31) {
          uint64_t v39 = v33[1];
        }
        else {
LABEL_31:
        }
          uint64_t v39 = 0;
        int32x2_t v74 = v29;
        uint64_t v75 = v39;
        if (OperandRange != mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&v74)) {
          uint64_t OperandRange = 0;
        }
        unint64_t v40 = *(void *)(a2 + 48);
        if (v40 >= *(void *)(a2 + 56))
        {
          uint64_t v42 = std::vector<std::string>::__push_back_slow_path<std::string const&>(a2 + 40, (uint64_t)&__p);
        }
        else
        {
          if (SHIBYTE(__p.__r_.__value_.__r.__words[2]) < 0)
          {
            std::string::__init_copy_ctor_external(*(std::string **)(a2 + 48), __p.__r_.__value_.__l.__data_, __p.__r_.__value_.__l.__size_);
          }
          else
          {
            long long v41 = *(_OWORD *)&__p.__r_.__value_.__l.__data_;
            *(void *)(v40 + 16) = *((void *)&__p.__r_.__value_.__l + 2);
            *(_OWORD *)unint64_t v40 = v41;
          }
          uint64_t v42 = (std::string *)(v40 + 24);
        }
        *(void *)(a2 + 48) = v42;
        if (SHIBYTE(__p.__r_.__value_.__r.__words[2]) < 0) {
          operator delete(__p.__r_.__value_.__l.__data_);
        }
        ++v23;
      }
      while (v23 != v22);
    }
  }
  if (OperandRange)
  {
    uint64_t v43 = *(void **)(*(void *)OperandRange + 136);
    uint64_t v44 = v69;
    if (v43 == &mlir::detail::TypeIDResolver<mlir::IntegerType,void>::id)
    {
      int32x2_t v74 = (const char *)OperandRange;
      int Width = mlir::IntegerType::getWidth((mlir::IntegerType *)&v74);
      if (Width == 16)
      {
        if (mlir::IntegerType::getSignedness((mlir::IntegerType *)&v74) == 2) {
          int v46 = 10;
        }
        else {
          int v46 = 9;
        }
      }
      else if (Width == 8)
      {
        if (mlir::IntegerType::getSignedness((mlir::IntegerType *)&v74) == 2) {
          int v46 = 2;
        }
        else {
          int v46 = 1;
        }
      }
      else
      {
        int v46 = 0;
      }
    }
    else
    {
      if (v43 == &mlir::detail::TypeIDResolver<mlir::Float32Type,void>::id) {
        int v45 = 11;
      }
      else {
        int v45 = 0;
      }
      if (v43 == &mlir::detail::TypeIDResolver<mlir::Float16Type,void>::id) {
        int v46 = 3;
      }
      else {
        int v46 = v45;
      }
    }
  }
  else
  {
    int v46 = 0;
    uint64_t v44 = v69;
  }
  *(_DWORD *)(a2 + 64) = v46;
  uint64_t v47 = (const char *)(*(void *)(v44 - 8) & 0xFFFFFFFFFFFFFFF8);
  if (!v47) {
    goto LABEL_61;
  }
  uint64_t v48 = *(void *)v47;
  unint64_t v49 = mlir::TypeID::get<mlir::ShapedType>();
  unint64_t v50 = *(unsigned int *)(v48 + 16);
  if (!v50) {
    goto LABEL_61;
  }
  uint64_t v51 = *(void **)(v48 + 8);
  uint64_t v52 = &v51[2 * v50];
  do
  {
    unint64_t v53 = v50 >> 1;
    uint64_t v54 = &v51[2 * (v50 >> 1)];
    unint64_t v56 = *v54;
    uint64_t v55 = v54 + 2;
    v50 += ~(v50 >> 1);
    if (v56 < v49) {
      uint64_t v51 = v55;
    }
    else {
      unint64_t v50 = v53;
    }
  }
  while (v50);
  if (v51 != v52 && *v51 == v49) {
    uint64_t v57 = v51[1];
  }
  else {
LABEL_61:
  }
    uint64_t v57 = 0;
  int32x2_t v74 = v47;
  uint64_t v75 = v57;
  uint64_t v58 = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&v74);
  int v59 = *(void **)(*(void *)v58 + 136);
  if (v59 != &mlir::detail::TypeIDResolver<mlir::IntegerType,void>::id)
  {
    if (v59 == &mlir::detail::TypeIDResolver<mlir::Float16Type,void>::id)
    {
      int v60 = 3;
    }
    else if (v59 == &mlir::detail::TypeIDResolver<mlir::Float32Type,void>::id)
    {
      int v60 = 11;
    }
    else
    {
      int v60 = 0;
    }
LABEL_81:
    int v62 = v70;
    goto LABEL_82;
  }
  __p.__r_.__value_.__r.__words[0] = v58;
  int v61 = mlir::IntegerType::getWidth((mlir::IntegerType *)&__p);
  if (v61 == 16)
  {
    if (mlir::IntegerType::getSignedness((mlir::IntegerType *)&__p) == 2) {
      int v60 = 10;
    }
    else {
      int v60 = 9;
    }
    goto LABEL_81;
  }
  int v62 = v70;
  if (v61 == 8)
  {
    if (mlir::IntegerType::getSignedness((mlir::IntegerType *)&__p) == 2) {
      int v60 = 2;
    }
    else {
      int v60 = 1;
    }
  }
  else
  {
    int v60 = 0;
  }
LABEL_82:
  *(_DWORD *)(a2 + 68) = v60;
  if ((v62 - 23) > 0xFFFFFFFD)
  {
    uint64_t v67 = 0;
  }
  else
  {
    mlir::ShapedType::getShape((mlir::ShapedType *)&v74);
    IndexFromDiuint64_t m = mlir::anec::getIndexFromDim(1, v64);
    if (!v66)
    {
      uint64_t v68 = std::__throw_bad_optional_access[abi:nn180100]();
      mlir::Type::cast<mlir::ShapedType>(v68);
      return;
    }
    uint64_t v67 = *(void *)(mlir::ShapedType::getShape((mlir::ShapedType *)&v74) + 8 * IndexFromDim);
  }
  *(void *)(a2 + 72) = v67;
  if (SHIBYTE(__str.__r_.__value_.__r.__words[2]) < 0) {
    operator delete(__str.__r_.__value_.__l.__data_);
  }
}

uint64_t *mlir::Type::cast<mlir::ShapedType>(uint64_t **a1)
{
  uint64_t v1 = *a1;
  if (*a1)
  {
    uint64_t v2 = *v1;
    unint64_t v3 = mlir::TypeID::get<mlir::ShapedType>();
    unint64_t v4 = *(unsigned int *)(v2 + 16);
    if (v4)
    {
      uint64_t v5 = *(void **)(v2 + 8);
      do
      {
        unint64_t v6 = v4 >> 1;
        uint64_t v7 = &v5[2 * (v4 >> 1)];
        unint64_t v9 = *v7;
        uint64_t v8 = v7 + 2;
        v4 += ~(v4 >> 1);
        if (v9 < v3) {
          uint64_t v5 = v8;
        }
        else {
          unint64_t v4 = v6;
        }
      }
      while (v4);
    }
  }
  return v1;
}

void mlir::anec::Broadcast::addOpToNetwork(mlir::anec::Broadcast *this, mlir::anec::ANECIRNetwork *a2, mlir::anec::ANECIRWeights *a3)
{
}

uint64_t mlir::anec::Convolution::inferPromotedReturnTypes(mlir::UnknownLoc *this, mlir::MLIRContext *a2, char a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11)
{
  v128[22] = *MEMORY[0x263EF8340];
  uint64_t v119 = a6;
  LOBYTE(v12std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = 0;
  char v121 = 0;
  uint64_t v122 = a7;
  uint64_t v123 = a8;
  if (a6)
  {
    uint64_t Context = mlir::Attribute::getContext((mlir::Attribute *)&v119);
    if (v121) {
      char v121 = 0;
    }
    mlir::OperationName::OperationName(&v120, "anec.convolution", 16, Context);
    char v121 = 1;
  }
  uint64_t v124 = a4;
  uint64_t v125 = a5;
  uint64_t v17 = mlir::UnknownLoc::get(this, a2);
  if (a3) {
    uint64_t v18 = (uint64_t)a2;
  }
  else {
    uint64_t v18 = v17;
  }
  if (!mlir::anec::ConvolutionAdaptor::verify(&v119, v18)) {
    return 0;
  }
  unint64_t v19 = (void *)mlir::TypeRange::dereference_iterator(a9, 0);
  uint64_t v20 = v19;
  if (!v19)
  {
    long long v102 = 0;
    uint64_t v103 = 0;
    if (a3)
    {
      mlir::emitError((uint64_t)a2, (uint64_t)&v126);
      if (v126)
      {
        unint64_t v32 = "input must be a ShapedType";
        goto LABEL_26;
      }
LABEL_27:
      uint64_t v33 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v126);
      if (v126) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v126);
      }
      std::__optional_destruct_base<mlir::Diagnostic,false>::~__optional_destruct_base[abi:nn180100]((uint64_t)&v127);
      return v33;
    }
    return 0;
  }
  uint64_t v21 = *v19;
  unint64_t v22 = mlir::TypeID::get<mlir::ShapedType>();
  unint64_t v23 = *(unsigned int *)(v21 + 16);
  if (!v23) {
    goto LABEL_18;
  }
  uint64_t v24 = *(void **)(v21 + 8);
  uint64_t v25 = &v24[2 * v23];
  do
  {
    unint64_t v26 = v23 >> 1;
    int v27 = &v24[2 * (v23 >> 1)];
    unint64_t v29 = *v27;
    uint64_t v28 = v27 + 2;
    v23 += ~(v23 >> 1);
    if (v29 < v22) {
      uint64_t v24 = v28;
    }
    else {
      unint64_t v23 = v26;
    }
  }
  while (v23);
  if (v24 != v25 && *v24 == v22) {
    uint64_t v30 = v24[1];
  }
  else {
LABEL_18:
  }
    uint64_t v30 = 0;
  long long v102 = v20;
  uint64_t v103 = v30;
  mlir::ShapedType::getShape((mlir::ShapedType *)&v102);
  if (v31 >= 6)
  {
    if (a3)
    {
      mlir::emitError((uint64_t)a2, (uint64_t)&v126);
      if (v126)
      {
        unint64_t v32 = "input must be a tensor of rank 4 or 5";
LABEL_26:
        mlir::Diagnostic::operator<<((uint64_t)&v127, v32);
        goto LABEL_27;
      }
      goto LABEL_27;
    }
    return 0;
  }
  Shape = (const char **)mlir::ShapedType::getShape((mlir::ShapedType *)&v102);
  v117[0] = v118;
  v117[1] = (void *)0x300000000;
  uint64_t v36 = (MirInfoChannelAssignment *)(mlir::AffineMapAttr::getValue((mlir::AffineMapAttr *)&v119) + 32);
  uint64_t v37 = (MirInfoChannelAssignment *)mlir::DictionaryAttr::end((mlir::DictionaryAttr *)&v119);
  unint64_t v38 = mlir::impl::findAttrSorted<mlir::NamedAttribute const*>(v36, v37, *(void *)(*(void *)(v120 + 96) + 56));
  if (v39) {
    uint64_t v40 = *((void *)v38 + 1);
  }
  else {
    uint64_t v40 = 0;
  }
  mlir::getValues<unsigned long long>(v40, (uint64_t)v117);
  v115[0] = v116;
  v115[1] = (void *)0x300000000;
  uint64_t Value = (MirInfoChannelAssignment *)mlir::AffineMapAttr::getValue((mlir::AffineMapAttr *)&v119);
  uint64_t v42 = mlir::DictionaryAttr::end((mlir::DictionaryAttr *)&v119);
  uint64_t v43 = mlir::impl::findAttrSorted<mlir::NamedAttribute const*>(Value, (MirInfoChannelAssignment *)(v42 - 32), *(void *)(*(void *)(v120 + 96) + 8));
  if (v44) {
    uint64_t v45 = *((void *)v43 + 1);
  }
  else {
    uint64_t v45 = 0;
  }
  mlir::getValues<unsigned long long>(v45, (uint64_t)v115);
  v113[0] = v114;
  v113[1] = (void *)0x600000000;
  int v46 = (MirInfoChannelAssignment *)(mlir::AffineMapAttr::getValue((mlir::AffineMapAttr *)&v119) + 16);
  uint64_t v47 = mlir::DictionaryAttr::end((mlir::DictionaryAttr *)&v119);
  uint64_t v48 = mlir::impl::findAttrSorted<mlir::NamedAttribute const*>(v46, (MirInfoChannelAssignment *)(v47 - 16), *(void *)(*(void *)(v120 + 96) + 40));
  if (v49) {
    uint64_t v50 = *((void *)v48 + 1);
  }
  else {
    uint64_t v50 = 0;
  }
  mlir::getValues<unsigned long long>(v50, (uint64_t)v113);
  uint64_t v51 = (void *)mlir::TypeRange::dereference_iterator(a9, 1);
  uint64_t v52 = v51;
  if (!v51) {
    goto LABEL_50;
  }
  uint64_t v53 = *v51;
  unint64_t v54 = mlir::TypeID::get<mlir::ShapedType>();
  unint64_t v55 = *(unsigned int *)(v53 + 16);
  if (!v55) {
    goto LABEL_50;
  }
  unint64_t v56 = *(void **)(v53 + 8);
  uint64_t v57 = &v56[2 * v55];
  do
  {
    unint64_t v58 = v55 >> 1;
    int v59 = &v56[2 * (v55 >> 1)];
    unint64_t v61 = *v59;
    int v60 = v59 + 2;
    v55 += ~(v55 >> 1);
    if (v61 < v54) {
      unint64_t v56 = v60;
    }
    else {
      unint64_t v55 = v58;
    }
  }
  while (v55);
  if (v56 != v57 && *v56 == v54) {
    uint64_t v62 = v56[1];
  }
  else {
LABEL_50:
  }
    uint64_t v62 = 0;
  v101[0] = v52;
  v101[1] = v62;
  uint64_t v63 = mlir::ShapedType::getShape((mlir::ShapedType *)v101);
  mlir::ShapedType::getShape((mlir::ShapedType *)v101);
  if (v64 >= 6)
  {
    if (a3)
    {
      mlir::emitError((uint64_t)a2, (uint64_t)&v126);
      if (v126) {
        mlir::Diagnostic::operator<<((uint64_t)&v127, "filter must be a tensor of rank 4 or 5");
      }
LABEL_63:
      uint64_t v33 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v126);
      if (v126) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v126);
      }
      std::__optional_destruct_base<mlir::Diagnostic,false>::~__optional_destruct_base[abi:nn180100]((uint64_t)&v127);
      goto LABEL_90;
    }
LABEL_66:
    uint64_t v33 = 0;
LABEL_90:
    if (v113[0] != v114) {
      free(v113[0]);
    }
    if (v115[0] != v116) {
      free(v115[0]);
    }
    if (v117[0] != v118) {
      free(v117[0]);
    }
    return v33;
  }
  mlir::ShapedType::getShape((mlir::ShapedType *)v101);
  if (v65 == 4) {
    uint64_t v66 = -1;
  }
  else {
    uint64_t v66 = 4;
  }
  Groups = mlir::anec::detail::ConvolutionGenericAdaptorBase::getGroups((mlir::anec::detail::ConvolutionGenericAdaptorBase *)&v119);
  mlir::ShapedType::getShape((mlir::ShapedType *)&v102);
  IndexFromDiuint64_t m = mlir::anec::getIndexFromDim(1, v67);
  if (v69)
  {
    uint64_t v99 = 0;
    uint64_t v99 = (uint64_t)Shape[IndexFromDim];
    if (v99 % (uint64_t)Groups)
    {
      long long v106 = "input channels {0} should be divisible by groups {1}";
      uint64_t v107 = 52;
      long long v108 = v112;
      uint64_t v109 = 2;
      v110[0] = &unk_26C35C280;
      v110[1] = &v99;
      v111[0] = &unk_26C35C280;
      v111[1] = &Groups;
      v112[0] = v110;
      v112[1] = v111;
      if (a3)
      {
        mlir::emitError((uint64_t)a2, (uint64_t)&v126);
        if (v126)
        {
          __int16 v105 = 263;
          v104[0] = (void **)&v106;
          mlir::Diagnostic::operator<<((uint64_t)&v127, v104);
        }
        goto LABEL_63;
      }
      goto LABEL_66;
    }
    int v70 = (MirInfoChannelAssignment *)mlir::AffineMapAttr::getValue((mlir::AffineMapAttr *)&v119);
    uint64_t v71 = mlir::DictionaryAttr::end((mlir::DictionaryAttr *)&v119);
    unsigned int v72 = mlir::impl::findAttrSorted<mlir::NamedAttribute const*>(v70, (MirInfoChannelAssignment *)(v71 - 48), **(void **)(v120 + 96));
    if ((v73 & 1) != 0
      && (uint64_t v74 = *((void *)v72 + 1)) != 0
      && *(_UNKNOWN **)(*(void *)v74 + 136) == &mlir::detail::TypeIDResolver<mlir::UnitAttr,void>::id)
    {
      uint64_t v75 = *(void *)(v63 + 8) * *(void *)v63;
    }
    else
    {
      uint64_t v75 = *(void *)v63;
    }
    uint64_t v98 = v75;
    if (v75 % (uint64_t)Groups)
    {
      llvm::formatv<long long &,long long &>("output channels {0} should be divisible by groups {1}", (const char *)&v98, (const char *)&Groups, (const char **)&v126);
      uint64_t v33 = mlir::emitOptionalError<llvm::formatv_object<std::tuple<llvm::detail::provider_format_adapter<long long &>,llvm::detail::provider_format_adapter<long long &>>>>((uint64_t)a2, a3, &v126);
      goto LABEL_90;
    }
    mlir::ShapedType::getShape((mlir::ShapedType *)&v102);
    mlir::anec::getIndexFromDim(1, v76);
    if (v77)
    {
      if (*(void *)(v63 + 8) * (void)Groups == v99)
      {
        mlir::ShapedType::getShape((mlir::ShapedType *)&v102);
        unint64_t v79 = mlir::anec::getIndexFromDim(3, v78);
        if (v80)
        {
          unint64_t v81 = v79;
          mlir::ShapedType::getShape((mlir::ShapedType *)&v102);
          unint64_t v83 = mlir::anec::getIndexFromDim(4, v82);
          if (v84)
          {
            unint64_t v85 = (unint64_t)&Shape[v81][*((void *)v113[0] + 2)
                                              + *((void *)v113[0] + 3)
                                              - *(void *)(v63 + 16)
                                              + *((void *)v115[0] + 1)
                                              - 1
                                              - (*((void *)v115[0] + 1) - 1) * *(void *)(v63 + 16)]
                / *((void *)v117[0] + 1)
                + 1;
            unint64_t v86 = (unint64_t)&Shape[v83][*((void *)v113[0] + 4)
                                              + *((void *)v113[0] + 5)
                                              - *(void *)(v63 + 24)
                                              + *((void *)v115[0] + 2)
                                              - 1
                                              - (*((void *)v115[0] + 2) - 1) * *(void *)(v63 + 24)]
                / *((void *)v117[0] + 2)
                + 1;
            unint64_t v87 = *Shape;
            mlir::ShapedType::getShape((mlir::ShapedType *)&v102);
            unint64_t v89 = mlir::anec::getIndexFromDim(2, v88);
            if (v90) {
              uint64_t v91 = (const char *)((unint64_t)&Shape[v89][*(void *)v113[0]
            }
                                                               + *((void *)v113[0] + 1)
                                                               - *(void *)(v63 + 8 * v66)
                                                               + *(void *)v115[0]
                                                               - 1
                                                               - (*(void *)v115[0] - 1) * *(void *)(v63 + 8 * v66)]
                                 / *(void *)v117[0]
                                 + 1);
            else {
              uint64_t v91 = 0;
            }
            long long v106 = v87;
            uint64_t v107 = v75;
            long long v108 = (void *)v85;
            uint64_t v109 = v86;
            llvm::SmallVector<long long,6u>::SmallVector(&v126, &v106, 4);
            if (v91)
            {
              long long v106 = v91;
              llvm::SmallVectorImpl<long long>::insert_one_impl<long long>((uint64_t)&v126, (uint64_t)v126 + 8, (uint64_t *)&v106);
            }
            uint64_t v92 = (uint64_t *)v126;
            uint64_t v93 = (mlir::AffineMap *)v127;
            uint64_t OperandRange = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&v102);
            uint64_t v95 = mlir::MemRefType::get(v92, v93, OperandRange, 0, 0, 0);
            llvm::SmallVectorTemplateBase<mlir::Type,true>::push_back(a11, v95);
            if (v126 != v128) {
              free(v126);
            }
            uint64_t v33 = 1;
            goto LABEL_90;
          }
        }
      }
      else if (a3)
      {
        llvm::formatv<long long const&,long long &,long long &>("Filter shape Cin {0} * groups {1} must match input Cin {2}", (const char *)(v63 + 8), (const char *)&Groups, (const char *)&v99, &v106);
        __int16 v105 = 263;
        v104[0] = (void **)&v106;
        mlir::emitError((uint64_t)a2, (uint64_t)v104, (uint64_t)&v126);
        uint64_t v33 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v126);
        mlir::InFlightDiagnostic::~InFlightDiagnostic((mlir::InFlightDiagnostic *)&v126);
        goto LABEL_90;
      }
    }
  }
  uint64_t v96 = (uint64_t *)std::__throw_bad_optional_access[abi:nn180100]();
  return mlir::anec::ConvolutionAdaptor::verify(v96, v97);
}

uint64_t mlir::anec::ConvolutionAdaptor::verify(uint64_t *a1, uint64_t a2)
{
  v89[23] = *MEMORY[0x263EF8340];
  uint64_t v83 = *a1;
  uint64_t Value = (uint64_t *)mlir::AffineMapAttr::getValue((mlir::AffineMapAttr *)&v83);
  unint64_t v82 = 0;
  if (Value == (uint64_t *)mlir::DictionaryAttr::end((mlir::DictionaryAttr *)&v83))
  {
LABEL_7:
    unint64_t v6 = "'anec.convolution' op requires attribute 'dilation'";
LABEL_70:
    unint64_t v79 = (uint64_t *)v6;
    __int16 v81 = 259;
    mlir::emitError(a2, (uint64_t)&v79, (uint64_t)&v88);
    uint64_t v48 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v88);
    if (v88) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v88);
    }
    std::__optional_destruct_base<mlir::Diagnostic,false>::~__optional_destruct_base[abi:nn180100]((uint64_t)v89);
    return v48;
  }
  uint64_t v5 = 0;
  while (*(void *)(*(void *)(a1[1] + 96) + 8) != MirInfoChannelAssignment::GetNumNeededNEs((MirInfoChannelAssignment *)Value))
  {
    if (**(void **)(a1[1] + 96) == MirInfoChannelAssignment::GetNumNeededNEs((MirInfoChannelAssignment *)Value)) {
      uint64_t v5 = Value[1];
    }
    Value += 2;
    if (Value == (uint64_t *)mlir::DictionaryAttr::end((mlir::DictionaryAttr *)&v83)) {
      goto LABEL_7;
    }
  }
  unint64_t v82 = (uint64_t *)Value[1];
  char v77 = 0;
  unint64_t v78 = 0;
  unint64_t v76 = 0;
  if (Value == (uint64_t *)mlir::DictionaryAttr::end((mlir::DictionaryAttr *)&v83))
  {
LABEL_18:
    unint64_t v6 = "'anec.convolution' op requires attribute 'padding'";
    goto LABEL_70;
  }
  uint64_t v7 = 0;
  uint64_t v8 = 0;
  unint64_t v9 = 0;
  while (*(void *)(*(void *)(a1[1] + 96) + 40) != MirInfoChannelAssignment::GetNumNeededNEs((MirInfoChannelAssignment *)Value))
  {
    if (*(void *)(*(void *)(a1[1] + 96) + 16) == MirInfoChannelAssignment::GetNumNeededNEs((MirInfoChannelAssignment *)Value))
    {
      unint64_t v9 = (uint64_t *)Value[1];
    }
    else if (*(void *)(*(void *)(a1[1] + 96) + 24) == MirInfoChannelAssignment::GetNumNeededNEs((MirInfoChannelAssignment *)Value))
    {
      uint64_t v8 = (uint64_t *)Value[1];
      char v77 = v8;
    }
    else if (*(void *)(*(void *)(a1[1] + 96) + 32) == MirInfoChannelAssignment::GetNumNeededNEs((MirInfoChannelAssignment *)Value))
    {
      uint64_t v7 = (uint64_t *)Value[1];
      unint64_t v76 = v7;
    }
    Value += 2;
    if (Value == (uint64_t *)mlir::DictionaryAttr::end((mlir::DictionaryAttr *)&v83)) {
      goto LABEL_18;
    }
  }
  unint64_t v78 = (uint64_t *)Value[1];
  if (Value == (uint64_t *)mlir::DictionaryAttr::end((mlir::DictionaryAttr *)&v83))
  {
LABEL_25:
    unint64_t v6 = "'anec.convolution' op requires attribute 'stride'";
    goto LABEL_70;
  }
  uint64_t v10 = 0;
  while (*(void *)(*(void *)(a1[1] + 96) + 56) != MirInfoChannelAssignment::GetNumNeededNEs((MirInfoChannelAssignment *)Value))
  {
    if (*(void *)(*(void *)(a1[1] + 96) + 48) == MirInfoChannelAssignment::GetNumNeededNEs((MirInfoChannelAssignment *)Value)) {
      uint64_t v10 = Value[1];
    }
    Value += 2;
    if (Value == (uint64_t *)mlir::DictionaryAttr::end((mlir::DictionaryAttr *)&v83)) {
      goto LABEL_25;
    }
  }
  uint64_t v11 = (uint64_t *)Value[1];
  if (v11)
  {
    if (!mlir::DenseIntElementsAttr::classof(Value[1])) {
      goto LABEL_68;
    }
    uint64_t v12 = *v11;
    unint64_t v13 = mlir::TypeID::get<mlir::ElementsAttr>();
    unint64_t v14 = *(unsigned int *)(v12 + 16);
    if (!v14) {
      goto LABEL_36;
    }
    uint64_t v15 = *(void **)(v12 + 8);
    unint64_t v16 = &v15[2 * v14];
    do
    {
      unint64_t v17 = v14 >> 1;
      uint64_t v18 = &v15[2 * (v14 >> 1)];
      unint64_t v20 = *v18;
      unint64_t v19 = v18 + 2;
      v14 += ~(v14 >> 1);
      if (v20 < v13) {
        uint64_t v15 = v19;
      }
      else {
        unint64_t v14 = v17;
      }
    }
    while (v14);
    if (v15 != v16 && *v15 == v13) {
      uint64_t v21 = v15[1];
    }
    else {
LABEL_36:
    }
      uint64_t v21 = 0;
    unint64_t v79 = v11;
    uint64_t v80 = v21;
    Type = (uint64_t *)mlir::ElementsAttr::getType((mlir::ElementsAttr *)&v79);
    unint64_t v23 = Type;
    if (!Type) {
      goto LABEL_46;
    }
    uint64_t v24 = *Type;
    unint64_t v25 = mlir::TypeID::get<mlir::ShapedType>();
    unint64_t v26 = *(unsigned int *)(v24 + 16);
    if (!v26) {
      goto LABEL_46;
    }
    int v27 = *(void **)(v24 + 8);
    uint64_t v28 = &v27[2 * v26];
    do
    {
      unint64_t v29 = v26 >> 1;
      uint64_t v30 = &v27[2 * (v26 >> 1)];
      unint64_t v32 = *v30;
      uint64_t v31 = v30 + 2;
      v26 += ~(v26 >> 1);
      if (v32 < v25) {
        int v27 = v31;
      }
      else {
        unint64_t v26 = v29;
      }
    }
    while (v26);
    if (v27 != v28 && *v27 == v25) {
      uint64_t v33 = v27[1];
    }
    else {
LABEL_46:
    }
      uint64_t v33 = 0;
    unint64_t v88 = v23;
    v89[0] = v33;
    Shape = (uint64_t **)mlir::ShapedType::getShape((mlir::ShapedType *)&v88);
    uint64_t v86 = 3;
    if (v35 != 1
      || *Shape != (uint64_t *)v86
      || (uint64_t v67 = (uint64_t)v11,
          uint64_t v74 = (uint64_t *)mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v67),
          uint64_t v75 = v36,
          uint64_t OperandRange = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&v74),
          !mlir::Type::isUnsignedInteger((mlir::Type *)&OperandRange, 64)))
    {
LABEL_68:
      unint64_t v6 = "'anec.convolution' op attribute 'stride' failed to satisfy constraint: ui64 elements attribute of shape {3}";
      goto LABEL_70;
    }
  }
  if (v82)
  {
    if (!mlir::DenseIntElementsAttr::classof((uint64_t)v82)) {
      goto LABEL_69;
    }
    unint64_t v79 = mlir::Attribute::cast<mlir::ElementsAttr>(&v82);
    uint64_t v80 = v37;
    uint64_t v86 = mlir::ElementsAttr::getType((mlir::ElementsAttr *)&v79);
    unint64_t v88 = mlir::Type::cast<mlir::ShapedType>((uint64_t **)&v86);
    v89[0] = v38;
    char v39 = (void *)mlir::ShapedType::getShape((mlir::ShapedType *)&v88);
    uint64_t OperandRange = 3;
    if (v40 != 1
      || *v39 != OperandRange
      || (char v73 = v82,
          uint64_t v74 = (uint64_t *)mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v73),
          uint64_t v75 = v41,
          uint64_t v67 = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&v74),
          !mlir::Type::isUnsignedInteger((mlir::Type *)&v67, 64)))
    {
LABEL_69:
      unint64_t v6 = "'anec.convolution' op attribute 'dilation' failed to satisfy constraint: ui64 elements attribute of shape {3}";
      goto LABEL_70;
    }
  }
  if (!v78) {
    goto LABEL_61;
  }
  if (!mlir::DenseIntElementsAttr::classof((uint64_t)v78)) {
    goto LABEL_74;
  }
  unint64_t v79 = mlir::Attribute::cast<mlir::ElementsAttr>(&v78);
  uint64_t v80 = v42;
  uint64_t v86 = mlir::ElementsAttr::getType((mlir::ElementsAttr *)&v79);
  unint64_t v88 = mlir::Type::cast<mlir::ShapedType>((uint64_t **)&v86);
  v89[0] = v43;
  char v44 = (void *)mlir::ShapedType::getShape((mlir::ShapedType *)&v88);
  uint64_t OperandRange = 6;
  if (v45 != 1) {
    goto LABEL_74;
  }
  if (*v44 == OperandRange
    && (char v73 = v78,
        uint64_t v74 = (uint64_t *)mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v73),
        uint64_t v75 = v46,
        uint64_t v67 = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&v74),
        mlir::Type::isUnsignedInteger((mlir::Type *)&v67, 64)))
  {
LABEL_61:
    if (v10 && (mlir::anec::PaddingModeAttr::classof(v10) & 1) == 0)
    {
      uint64_t v47 = "'anec.convolution' op attribute 'padding_mode' failed to satisfy constraint: valid PaddingMode";
    }
    else if (!v9 {
           || *(_UNKNOWN **)(*v9 + 136) == &mlir::detail::TypeIDResolver<mlir::IntegerAttr,void>::id
    }
           && (unint64_t v79 = v9,
               unint64_t v88 = (uint64_t *)mlir::AffineMapAttr::getValue((mlir::AffineMapAttr *)&v79),
               mlir::Type::isUnsignedInteger((mlir::Type *)&v88, 64)))
    {
      if (!v5 || *(_UNKNOWN **)(*(void *)v5 + 136) == &mlir::detail::TypeIDResolver<mlir::UnitAttr,void>::id)
      {
        if (!v8) {
          goto LABEL_97;
        }
        if (!mlir::DenseFPElementsAttr::classof((uint64_t)v8)) {
          goto LABEL_93;
        }
        unint64_t v79 = mlir::Attribute::cast<mlir::ElementsAttr>(&v77);
        uint64_t v80 = v50;
        char v73 = (uint64_t *)mlir::ElementsAttr::getType((mlir::ElementsAttr *)&v79);
        unint64_t v88 = mlir::Type::cast<mlir::ShapedType>(&v73);
        v89[0] = v51;
        mlir::ShapedType::getShape((mlir::ShapedType *)&v88);
        if (v52)
        {
          uint64_t v86 = (uint64_t)mlir::Attribute::cast<mlir::ElementsAttr>(&v77);
          uint64_t v87 = v53;
          unsigned int v72 = (uint64_t *)mlir::ElementsAttr::getType((mlir::ElementsAttr *)&v86);
          uint64_t v74 = mlir::Type::cast<mlir::ShapedType>(&v72);
          uint64_t v75 = v54;
          mlir::ShapedType::getShape((mlir::ShapedType *)&v74);
          if (v55 != 1) {
            goto LABEL_93;
          }
        }
        int v70 = v77;
        uint64_t OperandRange = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v70);
        uint64_t v85 = v56;
        uint64_t v71 = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&OperandRange);
        if (mlir::Type::isF16((mlir::Type *)&v71)
          || (uint64_t v66 = v77,
              uint64_t v67 = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v66),
              uint64_t v68 = v57,
              uint64_t v69 = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&v67),
              mlir::Type::isF32((mlir::Type *)&v69)))
        {
LABEL_97:
          if (!v7) {
            return 1;
          }
          if (mlir::DenseIntElementsAttr::classof((uint64_t)v7))
          {
            unint64_t v79 = mlir::Attribute::cast<mlir::ElementsAttr>(&v76);
            uint64_t v80 = v58;
            char v73 = (uint64_t *)mlir::ElementsAttr::getType((mlir::ElementsAttr *)&v79);
            unint64_t v88 = mlir::Type::cast<mlir::ShapedType>(&v73);
            v89[0] = v59;
            mlir::ShapedType::getShape((mlir::ShapedType *)&v88);
            if (!v60
              || (uint64_t v86 = (uint64_t)mlir::Attribute::cast<mlir::ElementsAttr>(&v76),
                  uint64_t v87 = v61,
                  unsigned int v72 = (uint64_t *)mlir::ElementsAttr::getType((mlir::ElementsAttr *)&v86),
                  uint64_t v74 = mlir::Type::cast<mlir::ShapedType>(&v72),
                  uint64_t v75 = v62,
                  mlir::ShapedType::getShape((mlir::ShapedType *)&v74),
                  v63 == 1))
            {
              int v70 = v76;
              uint64_t OperandRange = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v70);
              uint64_t v85 = v64;
              uint64_t v71 = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&OperandRange);
              if (mlir::Type::isSignedInteger((mlir::Type *)&v71, 8)) {
                return 1;
              }
              uint64_t v66 = v76;
              uint64_t v67 = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v66);
              uint64_t v68 = v65;
              uint64_t v69 = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&v67);
              if (mlir::Type::isUnsignedInteger((mlir::Type *)&v69, 8)) {
                return 1;
              }
            }
          }
          uint64_t v47 = "'anec.convolution' op attribute 'kernel_zero_point' failed to satisfy constraint: si8 or ui8 elements at"
                "tribute of rank 0/1";
        }
        else
        {
LABEL_93:
          uint64_t v47 = "'anec.convolution' op attribute 'kernel_scale' failed to satisfy constraint: f16 or f32 elements attribute of rank 0/1";
        }
      }
      else
      {
        uint64_t v47 = "'anec.convolution' op attribute 'channel_wise' failed to satisfy constraint: unit attribute";
      }
    }
    else
    {
      uint64_t v47 = "'anec.convolution' op attribute 'groups' failed to satisfy constraint: 64-bit unsigned integer attribute";
    }
  }
  else
  {
LABEL_74:
    uint64_t v47 = "'anec.convolution' op attribute 'padding' failed to satisfy constraint: ui64 elements attribute of shape {6}";
  }
  unint64_t v79 = (uint64_t *)v47;
  __int16 v81 = 259;
  mlir::emitError(a2, (uint64_t)&v79, (uint64_t)&v88);
  uint64_t v48 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v88);
  mlir::InFlightDiagnostic::~InFlightDiagnostic((mlir::InFlightDiagnostic *)&v88);
  return v48;
}

void mlir::getValues<unsigned long long>(uint64_t a1, uint64_t a2)
{
  uint64_t v18 = a1;
  mlir::DenseElementsAttr::IntElementIterator::IntElementIterator(&v15, a1, 0);
  uint64_t NumElements = mlir::DenseElementsAttr::getNumElements((mlir::DenseElementsAttr *)&v18);
  mlir::DenseElementsAttr::IntElementIterator::IntElementIterator(&v12, a1, NumElements);
  while (1)
  {
    BOOL v5 = v15 == v12 && v16 == v13;
    if (v5 && v17 == v14) {
      break;
    }
    mlir::DenseElementsAttr::IntElementIterator::operator*(&v15, (llvm::APInt *)&v10);
    unsigned int v6 = v11;
    uint64_t v7 = v10;
    if (v11 < 0x41) {
      uint64_t v7 = (uint64_t *)&v10;
    }
    uint64_t v8 = *v7;
    uint64_t v9 = *(unsigned int *)(a2 + 8);
    if (v9 >= *(_DWORD *)(a2 + 12))
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod(a2, (void *)(a2 + 16), v9 + 1, 8);
      *(void *)(*(void *)a2 + 8 * *(unsigned int *)(a2 + 8)) = v8;
      LODWORD(v9) = *(_DWORD *)(a2 + 8);
      unsigned int v6 = v11;
    }
    else
    {
      *(void *)(*(void *)a2 + 8 * v9) = v8;
    }
    *(_DWORD *)(a2 + 8) = v9 + 1;
    if (v6 >= 0x41)
    {
      if (v10) {
        MEMORY[0x21667D390](v10, 0x1000C8000313F17);
      }
    }
    ++v17;
  }
}

uint64_t *mlir::anec::detail::ConvolutionGenericAdaptorBase::getGroups(mlir::anec::detail::ConvolutionGenericAdaptorBase *this)
{
  uint64_t v2 = (MirInfoChannelAssignment *)(mlir::AffineMapAttr::getValue(this) + 16);
  uint64_t v3 = mlir::DictionaryAttr::end(this);
  unint64_t v4 = mlir::impl::findAttrSorted<mlir::NamedAttribute const*>(v2, (MirInfoChannelAssignment *)(v3 - 32), *(void *)(*(void *)(*((void *)this + 1) + 96) + 16));
  if (v5)
  {
    uint64_t v6 = *((void *)v4 + 1);
    if (v6 && *(_UNKNOWN **)(*(void *)v6 + 136) != &mlir::detail::TypeIDResolver<mlir::IntegerAttr,void>::id) {
      uint64_t v6 = 0;
    }
  }
  else
  {
    uint64_t v6 = 0;
  }
  uint64_t v11 = v6;
  mlir::IntegerAttr::getValue((uint64_t)&v11, (llvm::APInt *)&v9);
  if (v10 <= 0x40) {
    return v9;
  }
  uint64_t v7 = *v9;
  MEMORY[0x21667D390]();
  return (uint64_t *)v7;
}

uint64_t mlir::emitOptionalError<llvm::formatv_object<std::tuple<llvm::detail::provider_format_adapter<long long &>,llvm::detail::provider_format_adapter<long long &>>>>(uint64_t a1, char a2, void **a3)
{
  v9[23] = *MEMORY[0x263EF8340];
  if (!a2) {
    return 0;
  }
  mlir::emitError(a1, (uint64_t)&v8);
  if (v8)
  {
    __int16 v7 = 263;
    uint64_t v6 = a3;
    mlir::Diagnostic::operator<<((uint64_t)v9, &v6);
  }
  uint64_t v4 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v8);
  if (v8) {
    mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v8);
  }
  std::__optional_destruct_base<mlir::Diagnostic,false>::~__optional_destruct_base[abi:nn180100]((uint64_t)v9);
  return v4;
}

const char *llvm::formatv<long long &,long long &>@<X0>(const char *__s@<X0>, const char *a2@<X1>, const char *a3@<X2>, const char **a4@<X8>)
{
  uint64_t v6 = __s;
  if (__s) {
    __s = (const char *)strlen(__s);
  }
  *a4 = v6;
  a4[1] = __s;
  a4[8] = (const char *)(a4 + 4);
  a4[2] = (const char *)(a4 + 8);
  a4[3] = (const char *)2;
  a4[4] = (const char *)&unk_26C35C280;
  a4[5] = a2;
  a4[6] = (const char *)&unk_26C35C280;
  a4[7] = a3;
  a4[9] = (const char *)(a4 + 6);
  return __s;
}

const char *llvm::formatv<long long const&,long long &,long long &>@<X0>(const char *__s@<X0>, const char *a2@<X1>, const char *a3@<X2>, const char *a4@<X3>, const char **a5@<X8>)
{
  uint64_t v8 = __s;
  if (__s) {
    __s = (const char *)strlen(__s);
  }
  *a5 = v8;
  a5[1] = __s;
  a5[10] = (const char *)(a5 + 4);
  a5[2] = (const char *)(a5 + 10);
  a5[3] = (const char *)3;
  a5[4] = (const char *)&unk_26C35C1F0;
  a5[5] = a2;
  a5[6] = (const char *)&unk_26C35C280;
  a5[7] = a3;
  a5[8] = (const char *)&unk_26C35C280;
  a5[9] = a4;
  a5[11] = (const char *)(a5 + 6);
  a5[12] = (const char *)(a5 + 8);
  return __s;
}

void *llvm::SmallVector<long long,6u>::SmallVector(void *a1, const void *a2, uint64_t a3)
{
  *a1 = a1 + 2;
  a1[1] = 0x600000000;
  size_t v6 = 8 * a3;
  if ((unint64_t)(8 * a3) >= 0x31)
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)a1, a1 + 2, (8 * a3) >> 3, 8);
    unsigned int v7 = *((_DWORD *)a1 + 2);
    if (!a3) {
      goto LABEL_6;
    }
    goto LABEL_5;
  }
  unsigned int v7 = 0;
  if (a3)
  {
LABEL_5:
    memcpy((void *)(*a1 + 8 * v7), a2, v6);
    unsigned int v7 = *((_DWORD *)a1 + 2);
  }
LABEL_6:
  *((_DWORD *)a1 + 2) = v7 + (v6 >> 3);
  return a1;
}

void llvm::SmallVectorTemplateBase<mlir::Type,true>::push_back(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = *(unsigned int *)(a1 + 8);
  if (v4 >= *(_DWORD *)(a1 + 12))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod(a1, (void *)(a1 + 16), v4 + 1, 8);
    LODWORD(v4) = *(_DWORD *)(a1 + 8);
  }
  *(void *)(*(void *)a1 + 8 * v4) = a2;
  ++*(_DWORD *)(a1 + 8);
}

BOOL mlir::anec::anonymous namespace'::defaultMixedDataTypesIsCompatibleReturnType(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  BOOL result = 1;
  if (a2 && a4)
  {
    uint64_t v9 = 0;
    while (1)
    {
      unsigned int v10 = (void *)mlir::TypeRange::dereference_iterator(a1, v9);
      uint64_t v11 = (uint64_t *)mlir::TypeRange::dereference_iterator(a3, v9);
      if (!v10) {
        goto LABEL_13;
      }
      uint64_t v12 = *v10;
      unint64_t v13 = mlir::TypeID::get<mlir::ShapedType>();
      unint64_t v14 = *(unsigned int *)(v12 + 16);
      if (!v14) {
        goto LABEL_13;
      }
      uint64_t v15 = *(void **)(v12 + 8);
      char v16 = &v15[2 * v14];
      do
      {
        unint64_t v17 = v14 >> 1;
        uint64_t v18 = &v15[2 * (v14 >> 1)];
        unint64_t v20 = *v18;
        unint64_t v19 = v18 + 2;
        v14 += ~(v14 >> 1);
        if (v20 < v13) {
          uint64_t v15 = v19;
        }
        else {
          unint64_t v14 = v17;
        }
      }
      while (v14);
      if (v15 != v16 && *v15 == v13)
      {
        uint64_t v31 = v15[1];
        char v39 = v10;
        uint64_t v40 = v31;
        if (!v11) {
          goto LABEL_24;
        }
      }
      else
      {
LABEL_13:
        char v39 = v10;
        uint64_t v40 = 0;
        if (!v11) {
          goto LABEL_24;
        }
      }
      uint64_t v21 = *v11;
      unint64_t v22 = mlir::TypeID::get<mlir::ShapedType>();
      unint64_t v23 = *(unsigned int *)(v21 + 16);
      if (!v23) {
        goto LABEL_24;
      }
      uint64_t v24 = *(void **)(v21 + 8);
      unint64_t v25 = &v24[2 * v23];
      do
      {
        unint64_t v26 = v23 >> 1;
        int v27 = &v24[2 * (v23 >> 1)];
        unint64_t v29 = *v27;
        uint64_t v28 = v27 + 2;
        v23 += ~(v23 >> 1);
        if (v29 < v22) {
          uint64_t v24 = v28;
        }
        else {
          unint64_t v23 = v26;
        }
      }
      while (v23);
      if (v24 == v25 || *v24 != v22)
      {
LABEL_24:
        uint64_t v30 = 0;
        goto LABEL_25;
      }
      uint64_t v30 = v24[1];
LABEL_25:
      v38[0] = v11;
      v38[1] = v30;
      if (!mlir::CallOpInterface::getArgOperands((mlir::CallOpInterface *)&v39)) {
        return 0;
      }
      if (!mlir::CallOpInterface::getArgOperands((mlir::CallOpInterface *)v38)) {
        return 0;
      }
      Shape = (const void *)mlir::ShapedType::getShape((mlir::ShapedType *)&v39);
      uint64_t v34 = v33;
      uint64_t v35 = (const void *)mlir::ShapedType::getShape((mlir::ShapedType *)v38);
      if (v34 != v36) {
        return 0;
      }
      int v37 = memcmp(Shape, v35, 8 * v34);
      BOOL result = v37 == 0;
      if (!v37 && ++v9 != a2 && v9 != a4) {
        continue;
      }
      return result;
    }
  }
  return result;
}

void mlir::anec::Convolution::addOpToNetwork(mlir::Operation **this, mlir::anec::ANECIRNetwork *a2, mlir::anec::ANECIRWeights *a3)
{
  v61[2] = *MEMORY[0x263EF8340];
  uint64_t v4 = *this;
  uint64_t v5 = *((void *)*this + 9);
  uint64_t v6 = *(void *)(v5 + 24);
  uint64_t v51 = *(void **)(v5 + 56);
  uint64_t v52 = v4;
  if (*((_DWORD *)v4 + 9)) {
    uint64_t v7 = (uint64_t)v4 - 16;
  }
  else {
    uint64_t v7 = 0;
  }
  uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v7, 0);
  v54[0] = (void *)mlir::anec::Convolution::getGroupsAttr(&v52);
  mlir::IntegerAttr::getValue((uint64_t)v54, (llvm::APInt *)&v55);
  if (v56 > 0x40) {
    MEMORY[0x21667D390]();
  }
  mlir::anec::AveragePool::getIncPadAttr(&v52);
  v60[0] = v61;
  v60[1] = 0x200000000;
  uint64_t StrideAttr = mlir::anec::Convolution::getStrideAttr(&v52);
  mlir::getValues<unsigned long long>(StrideAttr, (uint64_t)v60);
  v58[0] = &v59;
  v58[1] = 0x200000000;
  uint64_t KsizeAttr = mlir::anec::AveragePool::getKsizeAttr(&v52);
  mlir::getValues<unsigned long long>(KsizeAttr, (uint64_t)v58);
  uint64_t v55 = &v57;
  uint64_t v56 = 0x400000000;
  uint64_t PaddingAttr = mlir::anec::Convolution::getPaddingAttr(&v52);
  mlir::getValues<unsigned long long>(PaddingAttr, (uint64_t)&v55);
  uint64_t v12 = (uint64_t *)(*(void *)(NextResultAtOffset + 8) & 0xFFFFFFFFFFFFFFF8);
  if (!v12) {
    goto LABEL_15;
  }
  uint64_t v13 = *v12;
  unint64_t v14 = mlir::TypeID::get<mlir::ShapedType>();
  unint64_t v15 = *(unsigned int *)(v13 + 16);
  if (!v15) {
    goto LABEL_15;
  }
  char v16 = *(void **)(v13 + 8);
  unint64_t v17 = &v16[2 * v15];
  do
  {
    unint64_t v18 = v15 >> 1;
    unint64_t v19 = &v16[2 * (v15 >> 1)];
    unint64_t v21 = *v19;
    unint64_t v20 = v19 + 2;
    v15 += ~(v15 >> 1);
    if (v21 < v14) {
      char v16 = v20;
    }
    else {
      unint64_t v15 = v18;
    }
  }
  while (v15);
  if (v16 != v17 && *v16 == v14) {
    uint64_t v22 = v16[1];
  }
  else {
LABEL_15:
  }
    uint64_t v22 = 0;
  v50[0] = v12;
  v50[1] = v22;
  mlir::ShapedType::getShape((mlir::ShapedType *)v50);
  unint64_t v23 = (uint64_t *)(*(void *)(v6 + 8) & 0xFFFFFFFFFFFFFFF8);
  if (!v23) {
    goto LABEL_25;
  }
  uint64_t v24 = *v23;
  unint64_t v25 = mlir::TypeID::get<mlir::ShapedType>();
  unint64_t v26 = *(unsigned int *)(v24 + 16);
  if (!v26) {
    goto LABEL_25;
  }
  int v27 = *(void **)(v24 + 8);
  uint64_t v28 = &v27[2 * v26];
  do
  {
    unint64_t v29 = v26 >> 1;
    uint64_t v30 = &v27[2 * (v26 >> 1)];
    unint64_t v32 = *v30;
    uint64_t v31 = v30 + 2;
    v26 += ~(v26 >> 1);
    if (v32 < v25) {
      int v27 = v31;
    }
    else {
      unint64_t v26 = v29;
    }
  }
  while (v26);
  if (v27 != v28 && *v27 == v25) {
    uint64_t v33 = v27[1];
  }
  else {
LABEL_25:
  }
    uint64_t v33 = 0;
  v49[0] = v23;
  v49[1] = v33;
  mlir::ShapedType::getShape((mlir::ShapedType *)v49);
  uint64_t v34 = (uint64_t *)(v51[1] & 0xFFFFFFFFFFFFFFF8);
  if (!v34) {
    goto LABEL_35;
  }
  uint64_t v35 = *v34;
  unint64_t v36 = mlir::TypeID::get<mlir::ShapedType>();
  unint64_t v37 = *(unsigned int *)(v35 + 16);
  if (!v37) {
    goto LABEL_35;
  }
  uint64_t v38 = *(void **)(v35 + 8);
  char v39 = &v38[2 * v37];
  do
  {
    unint64_t v40 = v37 >> 1;
    uint64_t v41 = &v38[2 * (v37 >> 1)];
    unint64_t v43 = *v41;
    uint64_t v42 = v41 + 2;
    v37 += ~(v37 >> 1);
    if (v43 < v36) {
      uint64_t v38 = v42;
    }
    else {
      unint64_t v37 = v40;
    }
  }
  while (v37);
  if (v38 != v39 && *v38 == v36) {
    uint64_t v44 = v38[1];
  }
  else {
LABEL_35:
  }
    uint64_t v44 = 0;
  v48[0] = v34;
  v48[1] = v44;
  mlir::ShapedType::getShape((mlir::ShapedType *)v48);
  v47[0] = 0;
  v47[1] = 0;
  uint64_t v53 = (uint64_t **)v47;
  v54[0] = v51;
  uint64_t DefiningOp = mlir::Value::getDefiningOp((mlir::Value *)v54);
  if (DefiningOp) {
    mlir::detail::constant_op_binder<mlir::ElementsAttr>::match(&v53, DefiningOp);
  }
  uint64_t v46 = (mlir::Operation *)mlir::Value::getDefiningOp((mlir::Value *)&v51);
  mlir::anec::ANECIRWeights::lookupConstant(a3, v46);
  operator new();
}

uint64_t mlir::anec::findDilatedConvTiles(uint64_t this, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t *a8, uint64_t *a9, uint64_t *a10, uint64_t *a11, uint64_t *a12)
{
  uint64_t v12 = 1;
  uint64_t v13 = a3;
  if ((a3 & 1) == 0)
  {
    do
    {
      if (v13 >= 0) {
        uint64_t v14 = v13;
      }
      else {
        uint64_t v14 = v13 + 1;
      }
      uint64_t v13 = v14 >> 1;
      ++v12;
    }
    while (((v14 >> 1) & 1) == 0);
  }
  if (0xAAAAAAAAAAAAAAABLL * v13 + 0x2AAAAAAAAAAAAAAALL <= 0x5555555555555554)
  {
    uint64_t v15 = 1;
    do
    {
      v13 /= 3;
      ++v15;
    }
    while ((unint64_t)(0x2AAAAAAAAAAAAAAALL - 0x5555555555555555 * v13) < 0x5555555555555555);
  }
  else
  {
    uint64_t v15 = 1;
  }
  uint64_t v16 = 1;
  uint64_t v17 = a4;
  if ((a4 & 1) == 0)
  {
    do
    {
      if (v17 >= 0) {
        uint64_t v18 = v17;
      }
      else {
        uint64_t v18 = v17 + 1;
      }
      uint64_t v17 = v18 >> 1;
      ++v16;
    }
    while (((v18 >> 1) & 1) == 0);
  }
  if (0xAAAAAAAAAAAAAAABLL * v17 + 0x2AAAAAAAAAAAAAAALL <= 0x5555555555555554)
  {
    uint64_t v19 = 1;
    do
    {
      v17 /= 3;
      ++v19;
    }
    while ((unint64_t)(0x2AAAAAAAAAAAAAAALL - 0x5555555555555555 * v17) < 0x5555555555555555);
  }
  else
  {
    uint64_t v19 = 1;
  }
  uint64_t v20 = 0;
  uint64_t v21 = a5 - 1;
  uint64_t v22 = a6 - 1;
  uint64_t v23 = this - 1;
  uint64_t v24 = a2 - 1;
  uint64_t v25 = -1;
  do
  {
    unint64_t v26 = (uint64_t *)((char *)&unk_211F095B0 + 16 * v20);
    uint64_t v27 = *v26;
    uint64_t v28 = v26[1];
    uint64_t v29 = 1;
    uint64_t v30 = 1;
    do
    {
      if (v15)
      {
        uint64_t v31 = 0;
        uint64_t v32 = -1;
        uint64_t v33 = 1;
        uint64_t v34 = v29;
        do
        {
          uint64_t v35 = v12;
          for (uint64_t i = v33; v35; --v35)
          {
            if (i > v29 && (v32 == -1 || ((v23 + i) / i + v28 - 1) / v28 * v28 * i - this <= v32))
            {
              uint64_t v32 = ((v23 + i) / i + v28 - 1) / v28 * v28 * i - this;
              uint64_t v34 = i;
            }
            i *= 2;
          }
          ++v31;
          v33 *= 3;
        }
        while (v31 != v15);
      }
      else
      {
        uint64_t v34 = v29;
      }
      uint64_t v37 = a7 + a7 * a3 / v34 * v21;
      uint64_t v38 = v37 + v37 * a4 / v30 * v22;
      if (v38 >= 0) {
        uint64_t v39 = v37 + v37 * a4 / v30 * v22;
      }
      else {
        uint64_t v39 = v38 + 1;
      }
      uint64_t v40 = v39 >> 1;
      if (v34 * v30 > 8) {
        uint64_t v38 = v40;
      }
      if (v38 <= 0x10000)
      {
        uint64_t v44 = v30;
        goto LABEL_56;
      }
      uint64_t v41 = 0;
      uint64_t v42 = -1;
      uint64_t v43 = 1;
      uint64_t v44 = v30;
      do
      {
        uint64_t v45 = v16;
        uint64_t v46 = v43;
        do
        {
          if (v46 > v30 && (v42 == -1 || ((v24 + v46) / v46 + v27 - 1) / v27 * v27 * v46 - a2 <= v42))
          {
            uint64_t v42 = ((v24 + v46) / v46 + v27 - 1) / v27 * v27 * v46 - a2;
            uint64_t v44 = v46;
          }
          v46 *= 2;
          --v45;
        }
        while (v45);
        ++v41;
        v43 *= 3;
      }
      while (v41 != v19);
      uint64_t v47 = v37 + v37 * a4 / v44 * v22;
      if (v47 >= 0) {
        uint64_t v48 = v37 + v37 * a4 / v44 * v22;
      }
      else {
        uint64_t v48 = v47 + 1;
      }
      uint64_t v49 = v48 >> 1;
      if (v44 * v34 > 8) {
        uint64_t v47 = v49;
      }
      if (v42 == -1) {
        break;
      }
      uint64_t v29 = v34;
      uint64_t v30 = v44;
    }
    while (v47 > 0x10000);
    if (v47 > 0x10000) {
      goto LABEL_21;
    }
LABEL_56:
    if (v25 == -1
      || v34 * v27 * v44 * ((v27 + (v24 + v44) / v44 - 1) / v27) * ((v23 + v34) / v34 + v28 - 1) / v28 * v28 - a2 * this < v25)
    {
      *a8 = v28;
      *a9 = v27;
      *a10 = v34;
      uint64_t v25 = v34 * v27 * v44 * ((v27 + (v24 + v44) / v44 - 1) / v27) * ((v23 + v34) / v34 + v28 - 1) / v28 * v28
          - a2 * this;
      *a11 = v44;
    }
LABEL_21:
    ++v20;
  }
  while (v20 != 4);
  return this;
}

float mlir::anec::Convolution::getExecutionCost(mlir::anec::AveragePool *a1, uint64_t a2)
{
  v190[6] = *MEMORY[0x263EF8340];
  uint64_t v3 = (uint64_t *)(*(void *)(*(void *)(*(void *)(*(void *)a1 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8);
  if (!v3) {
    goto LABEL_10;
  }
  uint64_t v4 = *v3;
  unint64_t v5 = mlir::TypeID::get<mlir::ShapedType>();
  unint64_t v6 = *(unsigned int *)(v4 + 16);
  if (!v6) {
    goto LABEL_10;
  }
  uint64_t v7 = *(void **)(v4 + 8);
  uint64_t v8 = &v7[2 * v6];
  do
  {
    unint64_t v9 = v6 >> 1;
    unsigned int v10 = &v7[2 * (v6 >> 1)];
    unint64_t v12 = *v10;
    uint64_t v11 = v10 + 2;
    v6 += ~(v6 >> 1);
    if (v12 < v5) {
      uint64_t v7 = v11;
    }
    else {
      unint64_t v6 = v9;
    }
  }
  while (v6);
  if (v7 != v8 && *v7 == v5) {
    uint64_t v13 = v7[1];
  }
  else {
LABEL_10:
  }
    uint64_t v13 = 0;
  v184[0] = v3;
  v184[1] = v13;
  uint64_t v14 = (uint64_t *)(*(void *)(*(void *)(*(void *)(*(void *)a1 + 72) + 56) + 8) & 0xFFFFFFFFFFFFFFF8);
  if (!v14) {
    goto LABEL_20;
  }
  uint64_t v15 = *v14;
  unint64_t v16 = mlir::TypeID::get<mlir::ShapedType>();
  unint64_t v17 = *(unsigned int *)(v15 + 16);
  if (!v17) {
    goto LABEL_20;
  }
  uint64_t v18 = *(void **)(v15 + 8);
  uint64_t v19 = &v18[2 * v17];
  do
  {
    unint64_t v20 = v17 >> 1;
    uint64_t v21 = &v18[2 * (v17 >> 1)];
    unint64_t v23 = *v21;
    uint64_t v22 = v21 + 2;
    v17 += ~(v17 >> 1);
    if (v23 < v16) {
      uint64_t v18 = v22;
    }
    else {
      unint64_t v17 = v20;
    }
  }
  while (v17);
  if (v18 != v19 && *v18 == v16) {
    uint64_t v24 = v18[1];
  }
  else {
LABEL_20:
  }
    uint64_t v24 = 0;
  v183[0] = v14;
  v183[1] = v24;
  if (*(_DWORD *)(*(void *)a1 + 36)) {
    uint64_t v25 = *(void *)a1 - 16;
  }
  else {
    uint64_t v25 = 0;
  }
  unint64_t v26 = (uint64_t *)(*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v25, 0) + 8) & 0xFFFFFFFFFFFFFFF8);
  BOOL v170 = a1;
  if (!v26) {
    goto LABEL_33;
  }
  uint64_t v27 = *v26;
  unint64_t v28 = mlir::TypeID::get<mlir::ShapedType>();
  unint64_t v29 = *(unsigned int *)(v27 + 16);
  if (!v29) {
    goto LABEL_33;
  }
  uint64_t v30 = *(void **)(v27 + 8);
  uint64_t v31 = &v30[2 * v29];
  do
  {
    unint64_t v32 = v29 >> 1;
    uint64_t v33 = &v30[2 * (v29 >> 1)];
    unint64_t v35 = *v33;
    uint64_t v34 = v33 + 2;
    v29 += ~(v29 >> 1);
    if (v35 < v28) {
      uint64_t v30 = v34;
    }
    else {
      unint64_t v29 = v32;
    }
  }
  while (v29);
  if (v30 != v31 && *v30 == v28) {
    uint64_t v36 = v30[1];
  }
  else {
LABEL_33:
  }
    uint64_t v36 = 0;
  v182[0] = v26;
  v182[1] = v36;
  uint64_t Shape = mlir::ShapedType::getShape((mlir::ShapedType *)v184);
  uint64_t v38 = (int64_t *)mlir::ShapedType::getShape((mlir::ShapedType *)v183);
  uint64_t v40 = v39;
  uint64_t v41 = mlir::ShapedType::getShape((mlir::ShapedType *)v182);
  int64_t v42 = *v38;
  uint64_t v176 = v38[v40 - 2];
  uint64_t v172 = v38[v40 - 1];
  uint64_t OperandRange = (int *)mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)v183);
  IntOrFloatBitint Width = mlir::Type::getIntOrFloatBitWidth((mlir::Type *)&OperandRange);
  mlir::ShapedType::getShape((mlir::ShapedType *)v184);
  IndexFromDiuint64_t m = mlir::anec::getIndexFromDim(0, v44);
  if (!v46) {
    goto LABEL_136;
  }
  unint64_t v47 = IndexFromDim;
  int64_t v167 = v42;
  mlir::ShapedType::getShape((mlir::ShapedType *)v184);
  unint64_t v49 = mlir::anec::getIndexFromDim(1, v48);
  if (!v50
    || (unint64_t v51 = v49, mlir::ShapedType::getShape((mlir::ShapedType *)v184), v53 = mlir::anec::getIndexFromDim(3, v52), !v54)
    || (unint64_t v55 = v53, mlir::ShapedType::getShape((mlir::ShapedType *)v184), v57 = mlir::anec::getIndexFromDim(4, v56), !v58))
  {
LABEL_136:
    std::__throw_bad_optional_access[abi:nn180100]();
  }
  uint64_t v164 = *(uint64_t **)(Shape + 8 * v47);
  unint64_t v59 = *(void *)(Shape + 8 * v51);
  uint64_t v174 = *(void *)(v41 + 8 * v57);
  uint64_t v175 = *(void *)(v41 + 8 * v55);
  mlir::ShapedType::getShape((mlir::ShapedType *)v184);
  unint64_t v61 = mlir::anec::getIndexFromDim(2, v60);
  if (v62)
  {
    uint64_t v168 = *(void *)(v41 + 8 * v61);
    int v63 = v38[v40 - 1];
    uint64_t v176 = v38[v40 - 3];
    uint64_t v64 = v38[v40 - 2];
    uint64_t v65 = (mlir::Operation **)v170;
  }
  else
  {
    uint64_t v168 = 1;
    int v63 = 1;
    uint64_t v65 = (mlir::Operation **)v170;
    uint64_t v64 = v172;
  }
  uint64_t v66 = IntOrFloatBitWidth >> 3;
  uint64_t OperandRange = (int *)v190;
  uint64_t v189 = 0xC00000000;
  uint64_t KsizeAttr = mlir::anec::AveragePool::getKsizeAttr(v65);
  mlir::getValues<int>(KsizeAttr, (uint64_t)&OperandRange);
  if (v189)
  {
    int v68 = *OperandRange;
    if (v189 == 1)
    {
      int v69 = 1;
      int v70 = 1;
    }
    else
    {
      int v69 = OperandRange[1];
      if (v189 < 3) {
        int v70 = 1;
      }
      else {
        int v70 = OperandRange[2];
      }
    }
  }
  else
  {
    int v69 = 1;
    int v68 = 1;
    int v70 = 1;
  }
  uint64_t v71 = v70;
  int v72 = v68 * (v63 - 1) + 1;
  uint64_t GroupsAttr = mlir::anec::Convolution::getGroupsAttr(v65);
  mlir::IntegerAttr::getValue((uint64_t)&GroupsAttr, (llvm::APInt *)&v185);
  int v166 = v63;
  if (v186 > 0x40)
  {
    unint64_t v73 = *v185;
    MEMORY[0x21667D390]();
  }
  else
  {
    unint64_t v73 = (unint64_t)v185;
  }
  uint64_t v74 = v64 - 1;
  uint64_t v75 = v176 - 1;
  uint64_t v76 = v69;
  uint64_t v77 = v72;
  if (v175 <= 0) {
    uint64_t v78 = -(-v175 & 7);
  }
  else {
    uint64_t v78 = v175 & 7;
  }
  BOOL v79 = v78 == 0;
  uint64_t v80 = v175 - v78 + 8;
  BOOL v82 = v168 < 9 && v175 < 9;
  if (v82 && v174 < 9 || v79) {
    uint64_t v83 = v175;
  }
  else {
    uint64_t v83 = v80;
  }
  if (v69 > 5 || (int)v71 > 5)
  {
    int v169 = v77;
    int v171 = v66;
    uint64_t GroupsAttr = 8;
    uint64_t v181 = 16;
    uint64_t v179 = 1;
    uint64_t v180 = 1;
    uint64_t v173 = v64;
    mlir::anec::findDilatedConvTiles(v174, v175, v71, v69, v64, v176, v59, &GroupsAttr, &v181, &v180, &v179, v164);
    uint64_t v86 = v179;
    uint64_t v87 = v180;
    uint64_t v88 = (v174 + v180 - 1) / v180;
    uint64_t v89 = (v175 + v179 - 1) / v179;
    uint64_t v90 = (int)(v71 / v180) * v74 + 1;
    uint64_t v91 = (int)(v76 / v179) * (v176 - 1) + 1;
    unint64_t v92 = v59 / v73;
    if (v180 != 1 || (float v93 = 0.0, v179 != 1))
    {
      uint64_t v94 = (v175 + v179 - 1) / v179;
      if (v180 == 1)
      {
        uint64_t v100 = 0;
      }
      else
      {
        uint64_t v95 = v179;
        int v185 = (unint64_t *)mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)v184);
        unsigned int v96 = mlir::Type::getIntOrFloatBitWidth((mlir::Type *)&v185);
        uint64_t v97 = (uint64_t *)mlir::ShapedType::getShape((mlir::ShapedType *)v184);
        uint64_t NumElements = mlir::ShapedType::getNumElements(v97, v98);
        uint64_t v86 = v95;
        uint64_t v100 = NumElements * ((v96 >> 2) & 0x3FFFFFFE);
      }
      uint64_t v129 = v86;
      if (v86 != 1)
      {
        int v185 = (unint64_t *)mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)v184);
        unsigned int v130 = mlir::Type::getIntOrFloatBitWidth((mlir::Type *)&v185);
        uint64_t v131 = (uint64_t *)mlir::ShapedType::getShape((mlir::ShapedType *)v184);
        v100 += mlir::ShapedType::getNumElements(v131, v132) * ((v130 >> 2) & 0x3FFFFFFE);
      }
      int v185 = (unint64_t *)mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)v182);
      unsigned int v133 = mlir::Type::getIntOrFloatBitWidth((mlir::Type *)&v185);
      unsigned int v134 = (uint64_t *)mlir::ShapedType::getShape((mlir::ShapedType *)v182);
      unint64_t v136 = v100 + mlir::ShapedType::getNumElements(v134, v135) * ((v133 >> 2) & 0x3FFFFFFE);
      float v137 = (float)v136;
      uint64_t v138 = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)v184);
      if (v136 <= 0x200000) {
        float v137 = 0.0;
      }
      int v185 = (unint64_t *)v138;
      float v139 = *(float *)(a2 + 40) * 1.0e12;
      BOOL isF16 = mlir::Type::isF16((mlir::Type *)&v185);
      float v141 = v139 + v139;
      if (isF16) {
        float v141 = v139;
      }
      float v142 = (float)(0.0 / v141) / 0.65;
      if (v142 < (float)(v137 / (float)(*(float *)(a2 + 44) * 1000000000.0))) {
        float v142 = v137 / (float)(*(float *)(a2 + 44) * 1000000000.0);
      }
      float v93 = v142 + 0.0;
      uint64_t v86 = v129;
      uint64_t v89 = v94;
    }
    uint64_t v143 = 0x10000 / (uint64_t)(v169 * (uint64_t)v171 * v90 * v92 * v91);
    if ((unint64_t)v143 <= 1) {
      uint64_t v143 = 1;
    }
    if (v143 >= 8) {
      uint64_t v143 = 8;
    }
    uint64_t v144 = 16 * v143;
    uint64_t v145 = v167 / (16 * v143);
    uint64_t v146 = v87 * (void)v165 * v86 * ((v88 + GroupsAttr - 1) / GroupsAttr) * ((v89 + v181 - 1) / v181);
    uint64_t v147 = v176 * v173 * v166 * v92;
    uint64_t v148 = (v147 * 16 * v143 * v146 * v145) << 9;
    uint64_t v149 = (v146 * v145) << 8;
    if (v167 != v145 * v144)
    {
      int64_t v150 = v167 - v144 * v145;
      uint64_t v151 = v150 + 15;
      unint64_t v152 = v150 + 30;
      if (v151 >= 0) {
        unint64_t v152 = v151;
      }
      v148 += 32 * v147 * (v152 >> 4) * (v146 << 8);
      v149 += v146 << 8;
    }
    float v153 = (float)(uint64_t)(v149 * v92);
    int v185 = (unint64_t *)mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)v182);
    uint64_t v154 = mlir::Type::getIntOrFloatBitWidth((mlir::Type *)&v185) >> 3;
    uint64_t v155 = (uint64_t *)mlir::ShapedType::getShape((mlir::ShapedType *)v182);
    float v157 = v153 + (float)(mlir::ShapedType::getNumElements(v155, v156) * v154);
    uint64_t v158 = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)v184);
    if (v157 <= 2097200.0) {
      float v157 = 0.0;
    }
    int v185 = (unint64_t *)v158;
    float v159 = *(float *)(a2 + 40) * 1.0e12;
    BOOL v160 = mlir::Type::isF16((mlir::Type *)&v185);
    float v161 = v159 + v159;
    if (v160) {
      float v161 = v159;
    }
    float v162 = (float)((float)v148 / v161) / 0.65;
    if (v162 < (float)(v157 / (float)(*(float *)(a2 + 44) * 1000000000.0))) {
      float v162 = v157 / (float)(*(float *)(a2 + 44) * 1000000000.0);
    }
    float v105 = v93 + v162;
  }
  else
  {
    uint64_t v84 = v75 * v69 + 1;
    if (v71 == 1)
    {
      uint64_t v85 = v74 * v71 + 1;
    }
    else
    {
      v59 *= v71;
      v73 *= v71;
      uint64_t v85 = v64;
    }
    if ((uint64_t)(v176 * v64 * v66 * v166 * (v59 / v73)) <= 0x8000)
    {
      BOOL v109 = v84 == v176 && v85 == v64;
      float v101 = 0.0;
      if (!v109 && (uint64_t)(v84 * v77 * v85 * (v59 / v73) * v66) > 0x8000)
      {
        uint64_t v177 = v64 * v77;
        do
        {
          if (v101 == 0.0)
          {
            uint64_t v113 = v75;
            int v185 = (unint64_t *)mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)v184);
            uint64_t v114 = mlir::Type::getIntOrFloatBitWidth((mlir::Type *)&v185) >> 3;
            BOOL v115 = (uint64_t *)mlir::ShapedType::getShape((mlir::ShapedType *)v184);
            uint64_t v117 = mlir::ShapedType::getNumElements(v115, v116) * v114;
            int v185 = (unint64_t *)mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)v182);
            uint64_t v118 = v66;
            uint64_t v119 = mlir::Type::getIntOrFloatBitWidth((mlir::Type *)&v185) >> 3;
            uint64_t v120 = (uint64_t *)mlir::ShapedType::getShape((mlir::ShapedType *)v182);
            unint64_t v122 = 2 * (v117 + mlir::ShapedType::getNumElements(v120, v121) * v119);
            float v123 = (float)v122;
            uint64_t v124 = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)v184);
            if (v122 <= 0x200000) {
              float v123 = 0.0;
            }
            int v185 = (unint64_t *)v124;
            float v125 = *(float *)(a2 + 40) * 1.0e12;
            BOOL v126 = mlir::Type::isF16((mlir::Type *)&v185);
            uint64_t v75 = v113;
            float v127 = v125 + v125;
            if (v126) {
              float v127 = v125;
            }
            float v128 = (float)(0.0 / v127) / 0.65;
            uint64_t v66 = v118;
            if (v128 >= (float)(v123 / (float)(*(float *)(a2 + 44) * 1000000000.0))) {
              float v101 = v128;
            }
            else {
              float v101 = v123 / (float)(*(float *)(a2 + 44) * 1000000000.0);
            }
          }
          if (v69)
          {
            if (v69 != 3 * (v69 / 3)) {
              break;
            }
            uint64_t v111 = 2;
            uint64_t v112 = 3;
            v69 /= 3;
            v59 *= 3;
            v73 *= 3;
          }
          else
          {
            if (v69 >= 0) {
              int v110 = v69;
            }
            else {
              int v110 = v69 + 1;
            }
            int v69 = v110 >> 1;
            v59 *= 2;
            v73 *= 2;
            uint64_t v111 = 1;
            uint64_t v112 = 2;
          }
          uint64_t v83 = (v83 + v111) / v112;
        }
        while ((uint64_t)((v177 * (v59 / v73) + v177 * (v59 / v73) * v75 * v69) * v66) > 0x8000);
      }
    }
    else
    {
      float v101 = 0.0;
    }
    uint64_t v102 = *(void *)v170;
    uint64_t v103 = (void *)mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)v184);
    float v105 = v101 + v104;
    int v185 = (unint64_t *)mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)v184);
    unsigned int v106 = mlir::Type::getIntOrFloatBitWidth((mlir::Type *)&v185);
    if ((uint64_t)v59 >= v167
      && (uint64_t)v59 >= 64
      && ((v174 * v175 * v168 * (v106 >> 3)) & 0x7FFFF) == 0)
    {
      float v105 = v105 + v105;
    }
  }
  if (OperandRange != (int *)v190) {
    free(OperandRange);
  }
  return v105;
}

uint64_t mlir::anec::Convolution::getFilter(mlir::anec::Convolution *this)
{
  return *(void *)(*(void *)(*(void *)this + 72) + 56);
}

uint64_t mlir::anec::Convolution::getResult(mlir::anec::Convolution *this)
{
  if (*(_DWORD *)(*(void *)this + 36)) {
    uint64_t v1 = *(void *)this - 16;
  }
  else {
    uint64_t v1 = 0;
  }
  return mlir::detail::OpResultImpl::getNextResultAtOffset(v1, 0);
}

void mlir::getValues<int>(uint64_t a1, uint64_t a2)
{
  uint64_t v16 = a1;
  mlir::DenseElementsAttr::IntElementIterator::IntElementIterator(&v13, a1, 0);
  uint64_t NumElements = mlir::DenseElementsAttr::getNumElements((mlir::DenseElementsAttr *)&v16);
  mlir::DenseElementsAttr::IntElementIterator::IntElementIterator(&v10, a1, NumElements);
  while (1)
  {
    BOOL v5 = v13 == v10 && v14 == v11;
    if (v5 && v15 == v12) {
      break;
    }
    mlir::DenseElementsAttr::IntElementIterator::operator*(&v13, (llvm::APInt *)&v8);
    if (v9 > 0x40) {
      uint64_t v6 = *v8;
    }
    else {
      uint64_t v6 = (uint64_t)((void)v8 << -(uint64_t)v9) >> -(uint64_t)v9;
    }
    uint64_t v7 = *(unsigned int *)(a2 + 8);
    if (v7 >= *(_DWORD *)(a2 + 12))
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod(a2, (void *)(a2 + 16), v7 + 1, 4);
      uint64_t v7 = *(unsigned int *)(a2 + 8);
    }
    *(_DWORD *)(*(void *)a2 + 4 * v7) = v6;
    ++*(_DWORD *)(a2 + 8);
    if (v9 >= 0x41)
    {
      if (v8) {
        MEMORY[0x21667D390](v8, 0x1000C8000313F17);
      }
    }
    ++v15;
  }
}

uint64_t *mlir::anec::Convolution::getGroups(mlir::Operation **this)
{
  uint64_t GroupsAttr = mlir::anec::Convolution::getGroupsAttr(this);
  mlir::IntegerAttr::getValue((uint64_t)&GroupsAttr, (llvm::APInt *)&v3);
  if (v4 <= 0x40) {
    return v3;
  }
  uint64_t v1 = *v3;
  MEMORY[0x21667D390]();
  return (uint64_t *)v1;
}

BOOL mlir::anec::anonymous namespace'::executionCost(uint64_t a1, uint64_t a2, void *a3)
{
  float v5 = 0.0;
  if ((*(unsigned char *)(a2 + 46) & 0x80) != 0)
  {
    uint64_t v6 = *(unsigned int *)(a2 + 68);
    if (v6)
    {
      uint64_t v7 = 0;
      uint64_t v8 = *(void *)(a2 + 72);
      do
      {
        uint64_t v13 = (void *)(*(void *)(*(void *)(v8 + 32 * v7 + 24) + 8) & 0xFFFFFFFFFFFFFFF8);
        if (!v13) {
          goto LABEL_4;
        }
        uint64_t v14 = *v13;
        unint64_t v15 = mlir::TypeID::get<mlir::ShapedType>();
        unint64_t v16 = *(unsigned int *)(v14 + 16);
        if (!v16) {
          goto LABEL_4;
        }
        unint64_t v17 = *(void **)(v14 + 8);
        uint64_t v18 = &v17[2 * v16];
        do
        {
          unint64_t v19 = v16 >> 1;
          unint64_t v20 = &v17[2 * (v16 >> 1)];
          unint64_t v22 = *v20;
          uint64_t v21 = v20 + 2;
          v16 += ~(v16 >> 1);
          if (v22 < v15) {
            unint64_t v17 = v21;
          }
          else {
            unint64_t v16 = v19;
          }
        }
        while (v16);
        if (v17 != v18 && *v17 == v15) {
          uint64_t v9 = v17[1];
        }
        else {
LABEL_4:
        }
          uint64_t v9 = 0;
        uint64_t v41 = v13;
        uint64_t v42 = v9;
        uint64_t OperandRange = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&v41);
        uint64_t v10 = mlir::Type::getIntOrFloatBitWidth((mlir::Type *)&OperandRange) >> 3;
        uint64_t Shape = (uint64_t *)mlir::ShapedType::getShape((mlir::ShapedType *)&v41);
        float v5 = v5 + (float)(mlir::ShapedType::getNumElements(Shape, v12) * v10);
        ++v7;
      }
      while (v7 != v6);
    }
  }
  uint64_t v23 = *(unsigned int *)(a2 + 36);
  if (v23) {
    uint64_t v24 = a2 - 16;
  }
  else {
    uint64_t v24 = 0;
  }
  if (v23)
  {
    for (uint64_t i = 0; i != v23; ++i)
    {
      unint64_t v26 = (void *)(*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v24, i) + 8) & 0xFFFFFFFFFFFFFFF8);
      if (!v26) {
        goto LABEL_30;
      }
      uint64_t v27 = *v26;
      unint64_t v28 = mlir::TypeID::get<mlir::ShapedType>();
      unint64_t v29 = *(unsigned int *)(v27 + 16);
      if (!v29) {
        goto LABEL_30;
      }
      uint64_t v30 = *(void **)(v27 + 8);
      uint64_t v31 = &v30[2 * v29];
      do
      {
        unint64_t v32 = v29 >> 1;
        uint64_t v33 = &v30[2 * (v29 >> 1)];
        unint64_t v35 = *v33;
        uint64_t v34 = v33 + 2;
        v29 += ~(v29 >> 1);
        if (v35 < v28) {
          uint64_t v30 = v34;
        }
        else {
          unint64_t v29 = v32;
        }
      }
      while (v29);
      if (v30 != v31 && *v30 == v28) {
        uint64_t v36 = v30[1];
      }
      else {
LABEL_30:
      }
        uint64_t v36 = 0;
      uint64_t v41 = v26;
      uint64_t v42 = v36;
      uint64_t OperandRange = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&v41);
      uint64_t v37 = mlir::Type::getIntOrFloatBitWidth((mlir::Type *)&OperandRange) >> 3;
      uint64_t v38 = (uint64_t *)mlir::ShapedType::getShape((mlir::ShapedType *)&v41);
      float v5 = v5 + (float)(mlir::ShapedType::getNumElements(v38, v39) * v37);
    }
  }
  uint64_t v41 = a3;
  return mlir::Type::isF16((mlir::Type *)&v41);
}

uint64_t mlir::anec::Linear::inferPromotedReturnTypes(mlir::UnknownLoc *this, mlir::MLIRContext *a2, char a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11)
{
  uint64_t v72 = *MEMORY[0x263EF8340];
  uint64_t v65 = a6;
  v66[0] = 0;
  char v67 = 0;
  uint64_t v68 = a7;
  uint64_t v69 = a8;
  if (a6)
  {
    uint64_t Context = mlir::Attribute::getContext((mlir::Attribute *)&v65);
    if (v67) {
      char v67 = 0;
    }
    mlir::OperationName::OperationName(v66, "anec.linear", 11, Context);
    char v67 = 1;
  }
  uint64_t v70 = a4;
  uint64_t v71 = a5;
  uint64_t v17 = mlir::UnknownLoc::get(this, a2);
  if (a3) {
    uint64_t v18 = (uint64_t)a2;
  }
  else {
    uint64_t v18 = v17;
  }
  if (!mlir::anec::LinearAdaptor::verify(&v65, v18)) {
    return 0;
  }
  unint64_t v19 = (void *)mlir::TypeRange::dereference_iterator(a9, 0);
  unint64_t v20 = v19;
  if (!v19) {
    goto LABEL_18;
  }
  uint64_t v21 = *v19;
  unint64_t v22 = mlir::TypeID::get<mlir::ShapedType>();
  unint64_t v23 = *(unsigned int *)(v21 + 16);
  if (!v23) {
    goto LABEL_18;
  }
  uint64_t v24 = *(void **)(v21 + 8);
  uint64_t v25 = &v24[2 * v23];
  do
  {
    unint64_t v26 = v23 >> 1;
    uint64_t v27 = &v24[2 * (v23 >> 1)];
    unint64_t v29 = *v27;
    unint64_t v28 = v27 + 2;
    v23 += ~(v23 >> 1);
    if (v29 < v22) {
      uint64_t v24 = v28;
    }
    else {
      unint64_t v23 = v26;
    }
  }
  while (v23);
  if (v24 != v25 && *v24 == v22) {
    uint64_t v30 = v24[1];
  }
  else {
LABEL_18:
  }
    uint64_t v30 = 0;
  v61[0] = v20;
  v61[1] = v30;
  uint64_t Shape = (const void *)mlir::ShapedType::getShape((mlir::ShapedType *)v61);
  uint64_t v33 = v32;
  uint64_t v34 = (void *)mlir::TypeRange::dereference_iterator(a9, 1);
  unint64_t v35 = v34;
  if (!v34) {
    goto LABEL_28;
  }
  uint64_t v36 = *v34;
  unint64_t v37 = mlir::TypeID::get<mlir::ShapedType>();
  unint64_t v38 = *(unsigned int *)(v36 + 16);
  if (!v38) {
    goto LABEL_28;
  }
  uint64_t v39 = *(void **)(v36 + 8);
  uint64_t v40 = &v39[2 * v38];
  do
  {
    unint64_t v41 = v38 >> 1;
    uint64_t v42 = &v39[2 * (v38 >> 1)];
    unint64_t v44 = *v42;
    uint64_t v43 = v42 + 2;
    v38 += ~(v38 >> 1);
    if (v44 < v37) {
      uint64_t v39 = v43;
    }
    else {
      unint64_t v38 = v41;
    }
  }
  while (v38);
  if (v39 != v40 && *v39 == v37) {
    uint64_t v45 = v39[1];
  }
  else {
LABEL_28:
  }
    uint64_t v45 = 0;
  v60[0] = v35;
  v60[1] = v45;
  uint64_t v46 = *(void *)(mlir::ShapedType::getShape((mlir::ShapedType *)v60) + 8);
  mlir::ShapedType::getShape((mlir::ShapedType *)v61);
  IndexFromDiuint64_t m = mlir::anec::getIndexFromDim(1, v47);
  if (!v49)
  {
    char v58 = (uint64_t *)std::__throw_bad_optional_access[abi:nn180100]();
    return mlir::anec::LinearAdaptor::verify(v58, v59);
  }
  unint64_t v50 = IndexFromDim;
  char v62 = v64;
  uint64_t v63 = 0x600000000;
  if ((unint64_t)(8 * v33) >= 0x31)
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v62, v64, (8 * v33) >> 3, 8);
    int v51 = v63;
    unint64_t v52 = (uint64_t *)v62;
    if (!v33) {
      goto LABEL_36;
    }
    goto LABEL_35;
  }
  int v51 = 0;
  unint64_t v52 = (uint64_t *)v64;
  if (v33)
  {
LABEL_35:
    memcpy(&v52[v51], Shape, 8 * v33);
    int v51 = v63;
    unint64_t v52 = (uint64_t *)v62;
  }
LABEL_36:
  char v54 = (mlir::AffineMap *)(v51 + v33);
  LODWORD(v63) = v51 + v33;
  v52[v50] = v46;
  uint64_t OperandRange = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)v61);
  uint64_t v56 = mlir::MemRefType::get(v52, v54, OperandRange, 0, 0, 0);
  uint64_t v57 = *(unsigned int *)(a11 + 8);
  if (v57 >= *(_DWORD *)(a11 + 12))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod(a11, (void *)(a11 + 16), v57 + 1, 8);
    LODWORD(v57) = *(_DWORD *)(a11 + 8);
  }
  *(void *)(*(void *)a11 + 8 * v57) = v56;
  ++*(_DWORD *)(a11 + 8);
  if (v62 != v64) {
    free(v62);
  }
  return 1;
}

uint64_t mlir::anec::LinearAdaptor::verify(uint64_t *a1, uint64_t a2)
{
  v123[23] = *MEMORY[0x263EF8340];
  uint64_t v121 = *a1;
  uint64_t Value = (MirInfoChannelAssignment *)mlir::AffineMapAttr::getValue((mlir::AffineMapAttr *)&v121);
  if (Value == (MirInfoChannelAssignment *)mlir::DictionaryAttr::end((mlir::DictionaryAttr *)&v121))
  {
    uint64_t v6 = 0;
  }
  else
  {
    float v5 = 0;
    uint64_t v6 = 0;
    do
    {
      if (**(void **)(a1[1] + 96) == MirInfoChannelAssignment::GetNumNeededNEs(Value))
      {
        float v5 = (const char *)*((void *)Value + 1);
      }
      else if (*(void *)(*(void *)(a1[1] + 96) + 8) == MirInfoChannelAssignment::GetNumNeededNEs(Value))
      {
        uint64_t v6 = (const char *)*((void *)Value + 1);
      }
      uint64_t Value = (MirInfoChannelAssignment *)((char *)Value + 16);
    }
    while (Value != (MirInfoChannelAssignment *)mlir::DictionaryAttr::end((mlir::DictionaryAttr *)&v121));
    if (v5)
    {
      if (!mlir::DenseFPElementsAttr::classof((uint64_t)v5)) {
        goto LABEL_52;
      }
      uint64_t v7 = *(void *)v5;
      unint64_t v8 = mlir::TypeID::get<mlir::ElementsAttr>();
      unint64_t v9 = *(unsigned int *)(v7 + 16);
      if (!v9) {
        goto LABEL_18;
      }
      uint64_t v10 = *(void **)(v7 + 8);
      char v11 = &v10[2 * v9];
      do
      {
        unint64_t v12 = v9 >> 1;
        uint64_t v13 = &v10[2 * (v9 >> 1)];
        unint64_t v15 = *v13;
        uint64_t v14 = v13 + 2;
        v9 += ~(v9 >> 1);
        if (v15 < v8) {
          uint64_t v10 = v14;
        }
        else {
          unint64_t v9 = v12;
        }
      }
      while (v9);
      if (v10 != v11 && *v10 == v8) {
        uint64_t v16 = v10[1];
      }
      else {
LABEL_18:
      }
        uint64_t v16 = 0;
      unsigned int v106 = v5;
      uint64_t v107 = v16;
      Type = (void *)mlir::ElementsAttr::getType((mlir::ElementsAttr *)&v106);
      uint64_t v18 = Type;
      if (!Type) {
        goto LABEL_28;
      }
      uint64_t v19 = *Type;
      unint64_t v20 = mlir::TypeID::get<mlir::ShapedType>();
      unint64_t v21 = *(unsigned int *)(v19 + 16);
      if (!v21) {
        goto LABEL_28;
      }
      unint64_t v22 = *(void **)(v19 + 8);
      unint64_t v23 = &v22[2 * v21];
      do
      {
        unint64_t v24 = v21 >> 1;
        uint64_t v25 = &v22[2 * (v21 >> 1)];
        unint64_t v27 = *v25;
        unint64_t v26 = v25 + 2;
        v21 += ~(v21 >> 1);
        if (v27 < v20) {
          unint64_t v22 = v26;
        }
        else {
          unint64_t v21 = v24;
        }
      }
      while (v21);
      if (v22 != v23 && *v22 == v20) {
        uint64_t v28 = v22[1];
      }
      else {
LABEL_28:
      }
        uint64_t v28 = 0;
      unint64_t v122 = v18;
      v123[0] = v28;
      mlir::ShapedType::getShape((mlir::ShapedType *)&v122);
      if (v29)
      {
        uint64_t v30 = *(void *)v5;
        unint64_t v31 = mlir::TypeID::get<mlir::ElementsAttr>();
        unint64_t v32 = *(unsigned int *)(v30 + 16);
        if (!v32) {
          goto LABEL_38;
        }
        uint64_t v33 = *(void **)(v30 + 8);
        uint64_t v34 = &v33[2 * v32];
        do
        {
          unint64_t v35 = v32 >> 1;
          uint64_t v36 = &v33[2 * (v32 >> 1)];
          unint64_t v38 = *v36;
          unint64_t v37 = v36 + 2;
          v32 += ~(v32 >> 1);
          if (v38 < v31) {
            uint64_t v33 = v37;
          }
          else {
            unint64_t v32 = v35;
          }
        }
        while (v32);
        if (v33 != v34 && *v33 == v31) {
          uint64_t v39 = v33[1];
        }
        else {
LABEL_38:
        }
          uint64_t v39 = 0;
        uint64_t v117 = v5;
        uint64_t v118 = v39;
        uint64_t v40 = (void *)mlir::ElementsAttr::getType((mlir::ElementsAttr *)&v117);
        unint64_t v41 = v40;
        if (!v40) {
          goto LABEL_48;
        }
        uint64_t v42 = *v40;
        unint64_t v43 = mlir::TypeID::get<mlir::ShapedType>();
        unint64_t v44 = *(unsigned int *)(v42 + 16);
        if (!v44) {
          goto LABEL_48;
        }
        uint64_t v45 = *(void **)(v42 + 8);
        uint64_t v46 = &v45[2 * v44];
        do
        {
          unint64_t v47 = v44 >> 1;
          unint64_t v48 = &v45[2 * (v44 >> 1)];
          unint64_t v50 = *v48;
          char v49 = v48 + 2;
          v44 += ~(v44 >> 1);
          if (v50 < v43) {
            uint64_t v45 = v49;
          }
          else {
            unint64_t v44 = v47;
          }
        }
        while (v44);
        if (v45 != v46 && *v45 == v43) {
          uint64_t v51 = v45[1];
        }
        else {
LABEL_48:
        }
          uint64_t v51 = 0;
        uint64_t v119 = v41;
        uint64_t v120 = v51;
        mlir::ShapedType::getShape((mlir::ShapedType *)&v119);
        if (v52 != 1) {
          goto LABEL_52;
        }
      }
      uint64_t v113 = v5;
      uint64_t v114 = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v113);
      uint64_t v115 = v53;
      uint64_t OperandRange = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&v114);
      if (!mlir::Type::isF16((mlir::Type *)&OperandRange))
      {
        BOOL v109 = v5;
        uint64_t v110 = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v109);
        uint64_t v111 = v54;
        uint64_t v112 = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&v110);
        if (!mlir::Type::isF32((mlir::Type *)&v112))
        {
LABEL_52:
          unint64_t v55 = "'anec.linear' op attribute 'kernel_scale' failed to satisfy constraint: f16 or f32 elements attribute of rank 0/1";
          goto LABEL_100;
        }
      }
    }
  }
  if (!v6) {
    return 1;
  }
  if (mlir::DenseIntElementsAttr::classof((uint64_t)v6))
  {
    uint64_t v56 = *(void *)v6;
    unint64_t v57 = mlir::TypeID::get<mlir::ElementsAttr>();
    unint64_t v58 = *(unsigned int *)(v56 + 16);
    if (!v58) {
      goto LABEL_64;
    }
    uint64_t v59 = *(void **)(v56 + 8);
    unint64_t v60 = &v59[2 * v58];
    do
    {
      unint64_t v61 = v58 >> 1;
      char v62 = &v59[2 * (v58 >> 1)];
      unint64_t v64 = *v62;
      uint64_t v63 = v62 + 2;
      v58 += ~(v58 >> 1);
      if (v64 < v57) {
        uint64_t v59 = v63;
      }
      else {
        unint64_t v58 = v61;
      }
    }
    while (v58);
    if (v59 != v60 && *v59 == v57) {
      uint64_t v65 = v59[1];
    }
    else {
LABEL_64:
    }
      uint64_t v65 = 0;
    unsigned int v106 = v6;
    uint64_t v107 = v65;
    uint64_t v66 = (void *)mlir::ElementsAttr::getType((mlir::ElementsAttr *)&v106);
    char v67 = v66;
    if (!v66) {
      goto LABEL_74;
    }
    uint64_t v68 = *v66;
    unint64_t v69 = mlir::TypeID::get<mlir::ShapedType>();
    unint64_t v70 = *(unsigned int *)(v68 + 16);
    if (!v70) {
      goto LABEL_74;
    }
    uint64_t v71 = *(void **)(v68 + 8);
    uint64_t v72 = &v71[2 * v70];
    do
    {
      unint64_t v73 = v70 >> 1;
      uint64_t v74 = &v71[2 * (v70 >> 1)];
      unint64_t v76 = *v74;
      uint64_t v75 = v74 + 2;
      v70 += ~(v70 >> 1);
      if (v76 < v69) {
        uint64_t v71 = v75;
      }
      else {
        unint64_t v70 = v73;
      }
    }
    while (v70);
    if (v71 != v72 && *v71 == v69) {
      uint64_t v77 = v71[1];
    }
    else {
LABEL_74:
    }
      uint64_t v77 = 0;
    unint64_t v122 = v67;
    v123[0] = v77;
    mlir::ShapedType::getShape((mlir::ShapedType *)&v122);
    if (!v78) {
      goto LABEL_96;
    }
    uint64_t v79 = *(void *)v6;
    unint64_t v80 = mlir::TypeID::get<mlir::ElementsAttr>();
    unint64_t v81 = *(unsigned int *)(v79 + 16);
    if (!v81) {
      goto LABEL_84;
    }
    BOOL v82 = *(void **)(v79 + 8);
    uint64_t v83 = &v82[2 * v81];
    do
    {
      unint64_t v84 = v81 >> 1;
      uint64_t v85 = &v82[2 * (v81 >> 1)];
      unint64_t v87 = *v85;
      uint64_t v86 = v85 + 2;
      v81 += ~(v81 >> 1);
      if (v87 < v80) {
        BOOL v82 = v86;
      }
      else {
        unint64_t v81 = v84;
      }
    }
    while (v81);
    if (v82 != v83 && *v82 == v80) {
      uint64_t v88 = v82[1];
    }
    else {
LABEL_84:
    }
      uint64_t v88 = 0;
    uint64_t v117 = v6;
    uint64_t v118 = v88;
    uint64_t v89 = (void *)mlir::ElementsAttr::getType((mlir::ElementsAttr *)&v117);
    uint64_t v90 = v89;
    if (!v89) {
      goto LABEL_94;
    }
    uint64_t v91 = *v89;
    unint64_t v92 = mlir::TypeID::get<mlir::ShapedType>();
    unint64_t v93 = *(unsigned int *)(v91 + 16);
    if (!v93) {
      goto LABEL_94;
    }
    uint64_t v94 = *(void **)(v91 + 8);
    uint64_t v95 = &v94[2 * v93];
    do
    {
      unint64_t v96 = v93 >> 1;
      uint64_t v97 = &v94[2 * (v93 >> 1)];
      unint64_t v99 = *v97;
      uint64_t v98 = v97 + 2;
      v93 += ~(v93 >> 1);
      if (v99 < v92) {
        uint64_t v94 = v98;
      }
      else {
        unint64_t v93 = v96;
      }
    }
    while (v93);
    if (v94 != v95 && *v94 == v92) {
      uint64_t v100 = v94[1];
    }
    else {
LABEL_94:
    }
      uint64_t v100 = 0;
    uint64_t v119 = v90;
    uint64_t v120 = v100;
    mlir::ShapedType::getShape((mlir::ShapedType *)&v119);
    if (v101 == 1)
    {
LABEL_96:
      uint64_t v113 = v6;
      uint64_t v114 = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v113);
      uint64_t v115 = v102;
      uint64_t OperandRange = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&v114);
      if (mlir::Type::isSignedInteger((mlir::Type *)&OperandRange, 8)) {
        return 1;
      }
      BOOL v109 = v6;
      uint64_t v110 = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v109);
      uint64_t v111 = v103;
      uint64_t v112 = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&v110);
      if (mlir::Type::isUnsignedInteger((mlir::Type *)&v112, 8)) {
        return 1;
      }
    }
  }
  unint64_t v55 = "'anec.linear' op attribute 'kernel_zero_point' failed to satisfy constraint: si8 or ui8 elements attribute of rank 0/1";
LABEL_100:
  unsigned int v106 = v55;
  __int16 v108 = 259;
  mlir::emitError(a2, (uint64_t)&v106, (uint64_t)&v122);
  uint64_t v104 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v122);
  if (v122) {
    mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v122);
  }
  std::__optional_destruct_base<mlir::Diagnostic,false>::~__optional_destruct_base[abi:nn180100]((uint64_t)v123);
  return v104;
}

void mlir::anec::Linear::addOpToNetwork(mlir::anec::Linear *this, mlir::anec::ANECIRNetwork *a2, mlir::anec::ANECIRWeights *a3)
{
  uint64_t v4 = *(void *)this;
  uint64_t v5 = *(void *)(*(void *)this + 72);
  uint64_t v6 = *(void *)(v5 + 24);
  uint64_t v46 = *(void *)(v5 + 56);
  LODWORD(v5) = *(_DWORD *)(v4 + 36);
  uint64_t v7 = v4 - 16;
  if (v5) {
    uint64_t v8 = v7;
  }
  else {
    uint64_t v8 = 0;
  }
  unint64_t v9 = (uint64_t *)(*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v8, 0) + 8) & 0xFFFFFFFFFFFFFFF8);
  if (!v9) {
    goto LABEL_13;
  }
  uint64_t v10 = *v9;
  unint64_t v11 = mlir::TypeID::get<mlir::ShapedType>();
  unint64_t v12 = *(unsigned int *)(v10 + 16);
  if (!v12) {
    goto LABEL_13;
  }
  uint64_t v13 = *(void **)(v10 + 8);
  uint64_t v14 = &v13[2 * v12];
  do
  {
    unint64_t v15 = v12 >> 1;
    uint64_t v16 = &v13[2 * (v12 >> 1)];
    unint64_t v18 = *v16;
    uint64_t v17 = v16 + 2;
    v12 += ~(v12 >> 1);
    if (v18 < v11) {
      uint64_t v13 = v17;
    }
    else {
      unint64_t v12 = v15;
    }
  }
  while (v12);
  if (v13 != v14 && *v13 == v11) {
    uint64_t v19 = v13[1];
  }
  else {
LABEL_13:
  }
    uint64_t v19 = 0;
  v45[0] = v9;
  v45[1] = v19;
  mlir::ShapedType::getShape((mlir::ShapedType *)v45);
  unint64_t v20 = (uint64_t *)(*(void *)(v6 + 8) & 0xFFFFFFFFFFFFFFF8);
  if (!v20) {
    goto LABEL_23;
  }
  uint64_t v21 = *v20;
  unint64_t v22 = mlir::TypeID::get<mlir::ShapedType>();
  unint64_t v23 = *(unsigned int *)(v21 + 16);
  if (!v23) {
    goto LABEL_23;
  }
  unint64_t v24 = *(void **)(v21 + 8);
  uint64_t v25 = &v24[2 * v23];
  do
  {
    unint64_t v26 = v23 >> 1;
    unint64_t v27 = &v24[2 * (v23 >> 1)];
    unint64_t v29 = *v27;
    uint64_t v28 = v27 + 2;
    v23 += ~(v23 >> 1);
    if (v29 < v22) {
      unint64_t v24 = v28;
    }
    else {
      unint64_t v23 = v26;
    }
  }
  while (v23);
  if (v24 != v25 && *v24 == v22) {
    uint64_t v30 = v24[1];
  }
  else {
LABEL_23:
  }
    uint64_t v30 = 0;
  v44[0] = v20;
  v44[1] = v30;
  mlir::ShapedType::getShape((mlir::ShapedType *)v44);
  unint64_t v31 = (uint64_t *)(*(void *)(v46 + 8) & 0xFFFFFFFFFFFFFFF8);
  if (!v31) {
    goto LABEL_33;
  }
  uint64_t v32 = *v31;
  unint64_t v33 = mlir::TypeID::get<mlir::ShapedType>();
  unint64_t v34 = *(unsigned int *)(v32 + 16);
  if (!v34) {
    goto LABEL_33;
  }
  unint64_t v35 = *(void **)(v32 + 8);
  uint64_t v36 = &v35[2 * v34];
  do
  {
    unint64_t v37 = v34 >> 1;
    unint64_t v38 = &v35[2 * (v34 >> 1)];
    unint64_t v40 = *v38;
    uint64_t v39 = v38 + 2;
    v34 += ~(v34 >> 1);
    if (v40 < v33) {
      unint64_t v35 = v39;
    }
    else {
      unint64_t v34 = v37;
    }
  }
  while (v34);
  if (v35 != v36 && *v35 == v33) {
    uint64_t v41 = v35[1];
  }
  else {
LABEL_33:
  }
    uint64_t v41 = 0;
  v43[0] = v31;
  v43[1] = v41;
  mlir::ShapedType::getShape((mlir::ShapedType *)v43);
  uint64_t DefiningOp = (mlir::Operation *)mlir::Value::getDefiningOp((mlir::Value *)&v46);
  mlir::anec::ANECIRWeights::lookupConstant(a3, DefiningOp);
  operator new();
}

uint64_t mlir::anec::Deconvolution::inferPromotedReturnTypes(mlir::UnknownLoc *this, mlir::MLIRContext *a2, unsigned __int8 a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11)
{
  v114[21] = *MEMORY[0x263EF8340];
  uint64_t v104 = a6;
  LOBYTE(v105) = 0;
  char v106 = 0;
  uint64_t v107 = a7;
  uint64_t v108 = a8;
  if (a6)
  {
    uint64_t Context = mlir::Attribute::getContext((mlir::Attribute *)&v104);
    if (v106) {
      char v106 = 0;
    }
    mlir::OperationName::OperationName(&v105, "anec.deconvolution", 18, Context);
    char v106 = 1;
  }
  uint64_t v109 = a4;
  uint64_t v110 = a5;
  uint64_t v17 = mlir::UnknownLoc::get(this, a2);
  uint64_t v18 = a3;
  if (a3) {
    uint64_t v19 = (uint64_t)a2;
  }
  else {
    uint64_t v19 = v17;
  }
  if (!mlir::anec::DeconvolutionAdaptor::verify(&v104, v19)) {
    return 0;
  }
  unint64_t v20 = (uint64_t *)mlir::TypeRange::dereference_iterator(a9, 0);
  v95[0] = llvm::DefaultDoCastIfPossible<mlir::ShapedType,mlir::Type const,llvm::CastInfo<mlir::ShapedType,mlir::Type const,void>>::doCastIfPossible(v20);
  v95[1] = v21;
  if (!v95[0])
  {
    if (a3)
    {
      mlir::emitError((uint64_t)a2, (uint64_t)&v111);
      if (v111)
      {
        unint64_t v24 = "input must be a ShapedType";
        goto LABEL_17;
      }
LABEL_18:
      uint64_t v25 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v111);
      if (v111) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v111);
      }
      std::__optional_destruct_base<mlir::Diagnostic,false>::~__optional_destruct_base[abi:nn180100]((uint64_t)&v112);
      return v25;
    }
    return 0;
  }
  uint64_t Shape = mlir::ShapedType::getShape((mlir::ShapedType *)v95);
  if (v23 >= 6)
  {
    if (a3)
    {
      mlir::emitError((uint64_t)a2, (uint64_t)&v111);
      if (v111)
      {
        unint64_t v24 = "input tensor rank of 4 or 5 are supported";
LABEL_17:
        mlir::Diagnostic::operator<<((uint64_t)&v112, v24);
        goto LABEL_18;
      }
      goto LABEL_18;
    }
    return 0;
  }
  unint64_t v27 = (uint64_t *)Shape;
  v102[0] = v103;
  v102[1] = (void *)0x300000000;
  uint64_t v28 = (MirInfoChannelAssignment *)(mlir::AffineMapAttr::getValue((mlir::AffineMapAttr *)&v104) + 32);
  unint64_t v29 = (MirInfoChannelAssignment *)mlir::DictionaryAttr::end((mlir::DictionaryAttr *)&v104);
  uint64_t v30 = mlir::impl::findAttrSorted<mlir::NamedAttribute const*>(v28, v29, *(void *)(*(void *)(v105 + 96) + 56));
  if (v31) {
    uint64_t v32 = *((void *)v30 + 1);
  }
  else {
    uint64_t v32 = 0;
  }
  mlir::getValues<unsigned long long>(v32, (uint64_t)v102);
  v100[0] = v101;
  v100[1] = (void *)0x300000000;
  uint64_t Value = (MirInfoChannelAssignment *)mlir::AffineMapAttr::getValue((mlir::AffineMapAttr *)&v104);
  uint64_t v34 = mlir::DictionaryAttr::end((mlir::DictionaryAttr *)&v104);
  unint64_t v35 = mlir::impl::findAttrSorted<mlir::NamedAttribute const*>(Value, (MirInfoChannelAssignment *)(v34 - 32), *(void *)(*(void *)(v105 + 96) + 8));
  if (v36) {
    uint64_t v37 = *((void *)v35 + 1);
  }
  else {
    uint64_t v37 = 0;
  }
  mlir::getValues<unsigned long long>(v37, (uint64_t)v100);
  v98[0] = v99;
  v98[1] = (void *)0x600000000;
  unint64_t v38 = (MirInfoChannelAssignment *)(mlir::AffineMapAttr::getValue((mlir::AffineMapAttr *)&v104) + 16);
  uint64_t v39 = mlir::DictionaryAttr::end((mlir::DictionaryAttr *)&v104);
  unint64_t v40 = mlir::impl::findAttrSorted<mlir::NamedAttribute const*>(v38, (MirInfoChannelAssignment *)(v39 - 16), *(void *)(*(void *)(v105 + 96) + 40));
  if (v41) {
    uint64_t v42 = *((void *)v40 + 1);
  }
  else {
    uint64_t v42 = 0;
  }
  mlir::getValues<unsigned long long>(v42, (uint64_t)v98);
  unint64_t v43 = (void *)mlir::TypeRange::dereference_iterator(a9, 1);
  unint64_t v44 = v43;
  if (!v43) {
    goto LABEL_41;
  }
  uint64_t v45 = *v43;
  unint64_t v46 = mlir::TypeID::get<mlir::ShapedType>();
  unint64_t v47 = *(unsigned int *)(v45 + 16);
  if (!v47) {
    goto LABEL_41;
  }
  unint64_t v48 = *(void **)(v45 + 8);
  char v49 = &v48[2 * v47];
  do
  {
    unint64_t v50 = v47 >> 1;
    uint64_t v51 = &v48[2 * (v47 >> 1)];
    unint64_t v53 = *v51;
    uint64_t v52 = v51 + 2;
    v47 += ~(v47 >> 1);
    if (v53 < v46) {
      unint64_t v48 = v52;
    }
    else {
      unint64_t v47 = v50;
    }
  }
  while (v47);
  if (v48 != v49 && *v48 == v46) {
    uint64_t v54 = v48[1];
  }
  else {
LABEL_41:
  }
    uint64_t v54 = 0;
  v94[0] = v44;
  v94[1] = v54;
  unint64_t v55 = (void *)mlir::ShapedType::getShape((mlir::ShapedType *)v94);
  mlir::ShapedType::getShape((mlir::ShapedType *)v94);
  if (v56 >= 6)
  {
    if (v18)
    {
      mlir::emitError((uint64_t)a2, (uint64_t)&v111);
      if (v111) {
        mlir::Diagnostic::operator<<((uint64_t)&v112, "filter must be a tensor of rank 4 or 5");
      }
LABEL_51:
      uint64_t v25 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v111);
      if (v111) {
        mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v111);
      }
      std::__optional_destruct_base<mlir::Diagnostic,false>::~__optional_destruct_base[abi:nn180100]((uint64_t)&v112);
      goto LABEL_71;
    }
    goto LABEL_54;
  }
  Groups = mlir::anec::detail::ConvolutionGenericAdaptorBase::getGroups((mlir::anec::detail::ConvolutionGenericAdaptorBase *)&v104);
  unint64_t v93 = Groups;
  mlir::ShapedType::getShape((mlir::ShapedType *)v95);
  IndexFromDiuint64_t m = mlir::anec::getIndexFromDim(1, v58);
  if (v60)
  {
    uint64_t v92 = v27[IndexFromDim];
    if (v92 % (uint64_t)Groups)
    {
      v88[0] = (uint64_t)"input channels {0} should be divisible by groups {1}";
      v88[1] = 52;
      _OWORD v88[2] = (uint64_t)v91;
      v88[3] = 2;
      v89[0] = &unk_26C35C280;
      v89[1] = &v92;
      v90[0] = &unk_26C35C280;
      v90[1] = &v93;
      v91[0] = v89;
      v91[1] = v90;
      if (v18)
      {
        mlir::emitError((uint64_t)a2, (uint64_t)&v111);
        if (v111)
        {
          __int16 v97 = 263;
          unint64_t v96 = (void **)v88;
          mlir::Diagnostic::operator<<((uint64_t)&v112, &v96);
        }
        goto LABEL_51;
      }
LABEL_54:
      uint64_t v25 = 0;
LABEL_71:
      if (v98[0] != v99) {
        free(v98[0]);
      }
      if (v100[0] != v101) {
        free(v100[0]);
      }
      if (v102[0] != v103) {
        free(v102[0]);
      }
      return v25;
    }
    uint64_t v61 = v55[1];
    mlir::ShapedType::getShape((mlir::ShapedType *)v95);
    unint64_t v63 = mlir::anec::getIndexFromDim(3, v62);
    if (v64)
    {
      unint64_t v65 = v63;
      mlir::ShapedType::getShape((mlir::ShapedType *)v95);
      unint64_t v67 = mlir::anec::getIndexFromDim(4, v66);
      if (v68)
      {
        unint64_t v69 = v67;
        uint64_t v87 = v61 * (void)Groups;
        mlir::ShapedType::getShape((mlir::ShapedType *)v94);
        uint64_t v71 = v70;
        uint64_t v72 = *((void *)v98[0] + 2) + *((void *)v102[0] + 1) * v27[v65] + *((void *)v98[0] + 3) - v55[2] + 1;
        uint64_t v73 = *((void *)v98[0] + 4) + *((void *)v102[0] + 2) * v27[v69] + *((void *)v98[0] + 5) - v55[3] + 1;
        uint64_t v74 = *v27;
        mlir::ShapedType::getShape((mlir::ShapedType *)v95);
        unint64_t v76 = mlir::anec::getIndexFromDim(2, v75);
        if (v77)
        {
          uint64_t v78 = 4;
          if (v71 == 4) {
            uint64_t v78 = 0x1FFFFFFFFFFFFFFFLL;
          }
          uint64_t v79 = *(void *)v98[0] + *(void *)v102[0] * v27[v76] + *((void *)v98[0] + 1) - v55[v78] + 1;
        }
        else
        {
          uint64_t v79 = 0;
        }
        uint64_t v111 = &v113;
        uint64_t v113 = v74;
        v114[0] = v87;
        v114[1] = v72;
        v114[2] = v73;
        uint64_t v112 = 0x600000004;
        if (v79)
        {
          v88[0] = v79;
          llvm::SmallVectorImpl<long long>::insert_one_impl<long long>((uint64_t)&v111, (uint64_t)v114, v88);
          unint64_t v80 = (uint64_t *)v111;
          uint64_t v81 = v112;
        }
        else
        {
          uint64_t v81 = 4;
          unint64_t v80 = &v113;
        }
        uint64_t OperandRange = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)v95);
        uint64_t v83 = mlir::MemRefType::get(v80, (mlir::AffineMap *)v81, OperandRange, 0, 0, 0);
        uint64_t v84 = *(unsigned int *)(a11 + 8);
        if (v84 >= *(_DWORD *)(a11 + 12))
        {
          llvm::SmallVectorBase<unsigned int>::grow_pod(a11, (void *)(a11 + 16), v84 + 1, 8);
          LODWORD(v84) = *(_DWORD *)(a11 + 8);
        }
        *(void *)(*(void *)a11 + 8 * v84) = v83;
        ++*(_DWORD *)(a11 + 8);
        if (v111 != &v113) {
          free(v111);
        }
        uint64_t v25 = 1;
        goto LABEL_71;
      }
    }
  }
  uint64_t v85 = (uint64_t *)std::__throw_bad_optional_access[abi:nn180100]();
  return mlir::anec::DeconvolutionAdaptor::verify(v85, v86);
}

uint64_t mlir::anec::DeconvolutionAdaptor::verify(uint64_t *a1, uint64_t a2)
{
  v89[23] = *MEMORY[0x263EF8340];
  uint64_t v83 = *a1;
  uint64_t Value = (uint64_t *)mlir::AffineMapAttr::getValue((mlir::AffineMapAttr *)&v83);
  BOOL v82 = 0;
  if (Value == (uint64_t *)mlir::DictionaryAttr::end((mlir::DictionaryAttr *)&v83))
  {
LABEL_7:
    uint64_t v6 = "'anec.deconvolution' op requires attribute 'dilation'";
LABEL_70:
    uint64_t v79 = (uint64_t *)v6;
    __int16 v81 = 259;
    mlir::emitError(a2, (uint64_t)&v79, (uint64_t)&v88);
    uint64_t v48 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v88);
    if (v88) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v88);
    }
    std::__optional_destruct_base<mlir::Diagnostic,false>::~__optional_destruct_base[abi:nn180100]((uint64_t)v89);
    return v48;
  }
  uint64_t v5 = 0;
  while (*(void *)(*(void *)(a1[1] + 96) + 8) != MirInfoChannelAssignment::GetNumNeededNEs((MirInfoChannelAssignment *)Value))
  {
    if (**(void **)(a1[1] + 96) == MirInfoChannelAssignment::GetNumNeededNEs((MirInfoChannelAssignment *)Value)) {
      uint64_t v5 = Value[1];
    }
    Value += 2;
    if (Value == (uint64_t *)mlir::DictionaryAttr::end((mlir::DictionaryAttr *)&v83)) {
      goto LABEL_7;
    }
  }
  BOOL v82 = (uint64_t *)Value[1];
  char v77 = 0;
  uint64_t v78 = 0;
  unint64_t v76 = 0;
  if (Value == (uint64_t *)mlir::DictionaryAttr::end((mlir::DictionaryAttr *)&v83))
  {
LABEL_18:
    uint64_t v6 = "'anec.deconvolution' op requires attribute 'padding'";
    goto LABEL_70;
  }
  uint64_t v7 = 0;
  uint64_t v8 = 0;
  unint64_t v9 = 0;
  while (*(void *)(*(void *)(a1[1] + 96) + 40) != MirInfoChannelAssignment::GetNumNeededNEs((MirInfoChannelAssignment *)Value))
  {
    if (*(void *)(*(void *)(a1[1] + 96) + 16) == MirInfoChannelAssignment::GetNumNeededNEs((MirInfoChannelAssignment *)Value))
    {
      unint64_t v9 = (uint64_t *)Value[1];
    }
    else if (*(void *)(*(void *)(a1[1] + 96) + 24) == MirInfoChannelAssignment::GetNumNeededNEs((MirInfoChannelAssignment *)Value))
    {
      uint64_t v8 = (uint64_t *)Value[1];
      char v77 = v8;
    }
    else if (*(void *)(*(void *)(a1[1] + 96) + 32) == MirInfoChannelAssignment::GetNumNeededNEs((MirInfoChannelAssignment *)Value))
    {
      uint64_t v7 = (uint64_t *)Value[1];
      unint64_t v76 = v7;
    }
    Value += 2;
    if (Value == (uint64_t *)mlir::DictionaryAttr::end((mlir::DictionaryAttr *)&v83)) {
      goto LABEL_18;
    }
  }
  uint64_t v78 = (uint64_t *)Value[1];
  if (Value == (uint64_t *)mlir::DictionaryAttr::end((mlir::DictionaryAttr *)&v83))
  {
LABEL_25:
    uint64_t v6 = "'anec.deconvolution' op requires attribute 'stride'";
    goto LABEL_70;
  }
  uint64_t v10 = 0;
  while (*(void *)(*(void *)(a1[1] + 96) + 56) != MirInfoChannelAssignment::GetNumNeededNEs((MirInfoChannelAssignment *)Value))
  {
    if (*(void *)(*(void *)(a1[1] + 96) + 48) == MirInfoChannelAssignment::GetNumNeededNEs((MirInfoChannelAssignment *)Value)) {
      uint64_t v10 = Value[1];
    }
    Value += 2;
    if (Value == (uint64_t *)mlir::DictionaryAttr::end((mlir::DictionaryAttr *)&v83)) {
      goto LABEL_25;
    }
  }
  unint64_t v11 = (uint64_t *)Value[1];
  if (v11)
  {
    if (!mlir::DenseIntElementsAttr::classof(Value[1])) {
      goto LABEL_68;
    }
    uint64_t v12 = *v11;
    unint64_t v13 = mlir::TypeID::get<mlir::ElementsAttr>();
    unint64_t v14 = *(unsigned int *)(v12 + 16);
    if (!v14) {
      goto LABEL_36;
    }
    unint64_t v15 = *(void **)(v12 + 8);
    uint64_t v16 = &v15[2 * v14];
    do
    {
      unint64_t v17 = v14 >> 1;
      uint64_t v18 = &v15[2 * (v14 >> 1)];
      unint64_t v20 = *v18;
      uint64_t v19 = v18 + 2;
      v14 += ~(v14 >> 1);
      if (v20 < v13) {
        unint64_t v15 = v19;
      }
      else {
        unint64_t v14 = v17;
      }
    }
    while (v14);
    if (v15 != v16 && *v15 == v13) {
      uint64_t v21 = v15[1];
    }
    else {
LABEL_36:
    }
      uint64_t v21 = 0;
    uint64_t v79 = v11;
    uint64_t v80 = v21;
    Type = (uint64_t *)mlir::ElementsAttr::getType((mlir::ElementsAttr *)&v79);
    unint64_t v23 = Type;
    if (!Type) {
      goto LABEL_46;
    }
    uint64_t v24 = *Type;
    unint64_t v25 = mlir::TypeID::get<mlir::ShapedType>();
    unint64_t v26 = *(unsigned int *)(v24 + 16);
    if (!v26) {
      goto LABEL_46;
    }
    unint64_t v27 = *(void **)(v24 + 8);
    uint64_t v28 = &v27[2 * v26];
    do
    {
      unint64_t v29 = v26 >> 1;
      uint64_t v30 = &v27[2 * (v26 >> 1)];
      unint64_t v32 = *v30;
      char v31 = v30 + 2;
      v26 += ~(v26 >> 1);
      if (v32 < v25) {
        unint64_t v27 = v31;
      }
      else {
        unint64_t v26 = v29;
      }
    }
    while (v26);
    if (v27 != v28 && *v27 == v25) {
      uint64_t v33 = v27[1];
    }
    else {
LABEL_46:
    }
      uint64_t v33 = 0;
    uint64_t v88 = v23;
    v89[0] = v33;
    uint64_t Shape = (uint64_t **)mlir::ShapedType::getShape((mlir::ShapedType *)&v88);
    uint64_t v86 = 3;
    if (v35 != 1
      || *Shape != (uint64_t *)v86
      || (uint64_t v67 = (uint64_t)v11,
          uint64_t v74 = (uint64_t *)mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v67),
          uint64_t v75 = v36,
          uint64_t OperandRange = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&v74),
          !mlir::Type::isUnsignedInteger((mlir::Type *)&OperandRange, 64)))
    {
LABEL_68:
      uint64_t v6 = "'anec.deconvolution' op attribute 'stride' failed to satisfy constraint: ui64 elements attribute of shape {3}";
      goto LABEL_70;
    }
  }
  if (v82)
  {
    if (!mlir::DenseIntElementsAttr::classof((uint64_t)v82)) {
      goto LABEL_69;
    }
    uint64_t v79 = mlir::Attribute::cast<mlir::ElementsAttr>(&v82);
    uint64_t v80 = v37;
    uint64_t v86 = mlir::ElementsAttr::getType((mlir::ElementsAttr *)&v79);
    uint64_t v88 = mlir::Type::cast<mlir::ShapedType>((uint64_t **)&v86);
    v89[0] = v38;
    uint64_t v39 = (void *)mlir::ShapedType::getShape((mlir::ShapedType *)&v88);
    uint64_t OperandRange = 3;
    if (v40 != 1
      || *v39 != OperandRange
      || (uint64_t v73 = v82,
          uint64_t v74 = (uint64_t *)mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v73),
          uint64_t v75 = v41,
          uint64_t v67 = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&v74),
          !mlir::Type::isUnsignedInteger((mlir::Type *)&v67, 64)))
    {
LABEL_69:
      uint64_t v6 = "'anec.deconvolution' op attribute 'dilation' failed to satisfy constraint: ui64 elements attribute of shape {3}";
      goto LABEL_70;
    }
  }
  if (!v78) {
    goto LABEL_61;
  }
  if (!mlir::DenseIntElementsAttr::classof((uint64_t)v78)) {
    goto LABEL_74;
  }
  uint64_t v79 = mlir::Attribute::cast<mlir::ElementsAttr>(&v78);
  uint64_t v80 = v42;
  uint64_t v86 = mlir::ElementsAttr::getType((mlir::ElementsAttr *)&v79);
  uint64_t v88 = mlir::Type::cast<mlir::ShapedType>((uint64_t **)&v86);
  v89[0] = v43;
  unint64_t v44 = (void *)mlir::ShapedType::getShape((mlir::ShapedType *)&v88);
  uint64_t OperandRange = 6;
  if (v45 != 1) {
    goto LABEL_74;
  }
  if (*v44 == OperandRange
    && (uint64_t v73 = v78,
        uint64_t v74 = (uint64_t *)mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v73),
        uint64_t v75 = v46,
        uint64_t v67 = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&v74),
        mlir::Type::isUnsignedInteger((mlir::Type *)&v67, 64)))
  {
LABEL_61:
    if (v10 && (mlir::anec::PaddingModeAttr::classof(v10) & 1) == 0)
    {
      unint64_t v47 = "'anec.deconvolution' op attribute 'padding_mode' failed to satisfy constraint: valid PaddingMode";
    }
    else if (!v9 {
           || *(_UNKNOWN **)(*v9 + 136) == &mlir::detail::TypeIDResolver<mlir::IntegerAttr,void>::id
    }
           && (uint64_t v79 = v9,
               uint64_t v88 = (uint64_t *)mlir::AffineMapAttr::getValue((mlir::AffineMapAttr *)&v79),
               mlir::Type::isUnsignedInteger((mlir::Type *)&v88, 64)))
    {
      if (!v5 || *(_UNKNOWN **)(*(void *)v5 + 136) == &mlir::detail::TypeIDResolver<mlir::UnitAttr,void>::id)
      {
        if (!v8) {
          goto LABEL_97;
        }
        if (!mlir::DenseFPElementsAttr::classof((uint64_t)v8)) {
          goto LABEL_93;
        }
        uint64_t v79 = mlir::Attribute::cast<mlir::ElementsAttr>(&v77);
        uint64_t v80 = v50;
        uint64_t v73 = (uint64_t *)mlir::ElementsAttr::getType((mlir::ElementsAttr *)&v79);
        uint64_t v88 = mlir::Type::cast<mlir::ShapedType>(&v73);
        v89[0] = v51;
        mlir::ShapedType::getShape((mlir::ShapedType *)&v88);
        if (v52)
        {
          uint64_t v86 = (uint64_t)mlir::Attribute::cast<mlir::ElementsAttr>(&v77);
          uint64_t v87 = v53;
          uint64_t v72 = (uint64_t *)mlir::ElementsAttr::getType((mlir::ElementsAttr *)&v86);
          uint64_t v74 = mlir::Type::cast<mlir::ShapedType>(&v72);
          uint64_t v75 = v54;
          mlir::ShapedType::getShape((mlir::ShapedType *)&v74);
          if (v55 != 1) {
            goto LABEL_93;
          }
        }
        uint64_t v70 = v77;
        uint64_t OperandRange = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v70);
        uint64_t v85 = v56;
        uint64_t v71 = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&OperandRange);
        if (mlir::Type::isF16((mlir::Type *)&v71)
          || (unint64_t v66 = v77,
              uint64_t v67 = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v66),
              uint64_t v68 = v57,
              uint64_t v69 = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&v67),
              mlir::Type::isF32((mlir::Type *)&v69)))
        {
LABEL_97:
          if (!v7) {
            return 1;
          }
          if (mlir::DenseIntElementsAttr::classof((uint64_t)v7))
          {
            uint64_t v79 = mlir::Attribute::cast<mlir::ElementsAttr>(&v76);
            uint64_t v80 = v58;
            uint64_t v73 = (uint64_t *)mlir::ElementsAttr::getType((mlir::ElementsAttr *)&v79);
            uint64_t v88 = mlir::Type::cast<mlir::ShapedType>(&v73);
            v89[0] = v59;
            mlir::ShapedType::getShape((mlir::ShapedType *)&v88);
            if (!v60
              || (uint64_t v86 = (uint64_t)mlir::Attribute::cast<mlir::ElementsAttr>(&v76),
                  uint64_t v87 = v61,
                  uint64_t v72 = (uint64_t *)mlir::ElementsAttr::getType((mlir::ElementsAttr *)&v86),
                  uint64_t v74 = mlir::Type::cast<mlir::ShapedType>(&v72),
                  uint64_t v75 = v62,
                  mlir::ShapedType::getShape((mlir::ShapedType *)&v74),
                  v63 == 1))
            {
              uint64_t v70 = v76;
              uint64_t OperandRange = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v70);
              uint64_t v85 = v64;
              uint64_t v71 = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&OperandRange);
              if (mlir::Type::isSignedInteger((mlir::Type *)&v71, 8)) {
                return 1;
              }
              unint64_t v66 = v76;
              uint64_t v67 = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v66);
              uint64_t v68 = v65;
              uint64_t v69 = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&v67);
              if (mlir::Type::isUnsignedInteger((mlir::Type *)&v69, 8)) {
                return 1;
              }
            }
          }
          unint64_t v47 = "'anec.deconvolution' op attribute 'kernel_zero_point' failed to satisfy constraint: si8 or ui8 elements "
                "attribute of rank 0/1";
        }
        else
        {
LABEL_93:
          unint64_t v47 = "'anec.deconvolution' op attribute 'kernel_scale' failed to satisfy constraint: f16 or f32 elements attri"
                "bute of rank 0/1";
        }
      }
      else
      {
        unint64_t v47 = "'anec.deconvolution' op attribute 'channel_wise' failed to satisfy constraint: unit attribute";
      }
    }
    else
    {
      unint64_t v47 = "'anec.deconvolution' op attribute 'groups' failed to satisfy constraint: 64-bit unsigned integer attribute";
    }
  }
  else
  {
LABEL_74:
    unint64_t v47 = "'anec.deconvolution' op attribute 'padding' failed to satisfy constraint: ui64 elements attribute of shape {6}";
  }
  uint64_t v79 = (uint64_t *)v47;
  __int16 v81 = 259;
  mlir::emitError(a2, (uint64_t)&v79, (uint64_t)&v88);
  uint64_t v48 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v88);
  mlir::InFlightDiagnostic::~InFlightDiagnostic((mlir::InFlightDiagnostic *)&v88);
  return v48;
}

void mlir::anec::Deconvolution::addOpToNetwork(mlir::Operation **this, mlir::anec::ANECIRNetwork *a2, mlir::anec::ANECIRWeights *a3)
{
  void v61[2] = *MEMORY[0x263EF8340];
  uint64_t v4 = *this;
  uint64_t v5 = *((void *)*this + 9);
  uint64_t v6 = *(void *)(v5 + 24);
  uint64_t v51 = *(void **)(v5 + 56);
  uint64_t v52 = v4;
  if (*((_DWORD *)v4 + 9)) {
    uint64_t v7 = (uint64_t)v4 - 16;
  }
  else {
    uint64_t v7 = 0;
  }
  uint64_t NextResultAtOffset = mlir::detail::OpResultImpl::getNextResultAtOffset(v7, 0);
  v54[0] = (void *)mlir::anec::Convolution::getGroupsAttr(&v52);
  mlir::IntegerAttr::getValue((uint64_t)v54, (llvm::APInt *)&v55);
  if (v56 > 0x40) {
    MEMORY[0x21667D390]();
  }
  mlir::anec::AveragePool::getIncPadAttr(&v52);
  v60[0] = v61;
  v60[1] = 0x200000000;
  uint64_t StrideAttr = mlir::anec::Convolution::getStrideAttr(&v52);
  mlir::getValues<unsigned long long>(StrideAttr, (uint64_t)v60);
  v58[0] = &v59;
  v58[1] = 0x200000000;
  uint64_t KsizeAttr = mlir::anec::AveragePool::getKsizeAttr(&v52);
  mlir::getValues<unsigned long long>(KsizeAttr, (uint64_t)v58);
  uint64_t v55 = &v57;
  uint64_t v56 = 0x400000000;
  uint64_t PaddingAttr = mlir::anec::Convolution::getPaddingAttr(&v52);
  mlir::getValues<unsigned long long>(PaddingAttr, (uint64_t)&v55);
  uint64_t v12 = (uint64_t *)(*(void *)(NextResultAtOffset + 8) & 0xFFFFFFFFFFFFFFF8);
  if (!v12) {
    goto LABEL_15;
  }
  uint64_t v13 = *v12;
  unint64_t v14 = mlir::TypeID::get<mlir::ShapedType>();
  unint64_t v15 = *(unsigned int *)(v13 + 16);
  if (!v15) {
    goto LABEL_15;
  }
  uint64_t v16 = *(void **)(v13 + 8);
  unint64_t v17 = &v16[2 * v15];
  do
  {
    unint64_t v18 = v15 >> 1;
    uint64_t v19 = &v16[2 * (v15 >> 1)];
    unint64_t v21 = *v19;
    unint64_t v20 = v19 + 2;
    v15 += ~(v15 >> 1);
    if (v21 < v14) {
      uint64_t v16 = v20;
    }
    else {
      unint64_t v15 = v18;
    }
  }
  while (v15);
  if (v16 != v17 && *v16 == v14) {
    uint64_t v22 = v16[1];
  }
  else {
LABEL_15:
  }
    uint64_t v22 = 0;
  v50[0] = v12;
  v50[1] = v22;
  mlir::ShapedType::getShape((mlir::ShapedType *)v50);
  unint64_t v23 = (uint64_t *)(*(void *)(v6 + 8) & 0xFFFFFFFFFFFFFFF8);
  if (!v23) {
    goto LABEL_25;
  }
  uint64_t v24 = *v23;
  unint64_t v25 = mlir::TypeID::get<mlir::ShapedType>();
  unint64_t v26 = *(unsigned int *)(v24 + 16);
  if (!v26) {
    goto LABEL_25;
  }
  unint64_t v27 = *(void **)(v24 + 8);
  uint64_t v28 = &v27[2 * v26];
  do
  {
    unint64_t v29 = v26 >> 1;
    uint64_t v30 = &v27[2 * (v26 >> 1)];
    unint64_t v32 = *v30;
    char v31 = v30 + 2;
    v26 += ~(v26 >> 1);
    if (v32 < v25) {
      unint64_t v27 = v31;
    }
    else {
      unint64_t v26 = v29;
    }
  }
  while (v26);
  if (v27 != v28 && *v27 == v25) {
    uint64_t v33 = v27[1];
  }
  else {
LABEL_25:
  }
    uint64_t v33 = 0;
  v49[0] = v23;
  v49[1] = v33;
  mlir::ShapedType::getShape((mlir::ShapedType *)v49);
  uint64_t v34 = (uint64_t *)(v51[1] & 0xFFFFFFFFFFFFFFF8);
  if (!v34) {
    goto LABEL_35;
  }
  uint64_t v35 = *v34;
  unint64_t v36 = mlir::TypeID::get<mlir::ShapedType>();
  unint64_t v37 = *(unsigned int *)(v35 + 16);
  if (!v37) {
    goto LABEL_35;
  }
  uint64_t v38 = *(void **)(v35 + 8);
  uint64_t v39 = &v38[2 * v37];
  do
  {
    unint64_t v40 = v37 >> 1;
    uint64_t v41 = &v38[2 * (v37 >> 1)];
    unint64_t v43 = *v41;
    uint64_t v42 = v41 + 2;
    v37 += ~(v37 >> 1);
    if (v43 < v36) {
      uint64_t v38 = v42;
    }
    else {
      unint64_t v37 = v40;
    }
  }
  while (v37);
  if (v38 != v39 && *v38 == v36) {
    uint64_t v44 = v38[1];
  }
  else {
LABEL_35:
  }
    uint64_t v44 = 0;
  v48[0] = v34;
  v48[1] = v44;
  mlir::ShapedType::getShape((mlir::ShapedType *)v48);
  v47[0] = 0;
  v47[1] = 0;
  uint64_t v53 = (uint64_t **)v47;
  v54[0] = v51;
  uint64_t DefiningOp = mlir::Value::getDefiningOp((mlir::Value *)v54);
  if (DefiningOp) {
    mlir::detail::constant_op_binder<mlir::ElementsAttr>::match(&v53, DefiningOp);
  }
  uint64_t v46 = (mlir::Operation *)mlir::Value::getDefiningOp((mlir::Value *)&v51);
  mlir::anec::ANECIRWeights::lookupConstant(a3, v46);
  operator new();
}

uint64_t mlir::anec::Deconvolution::getExecutionCost(uint64_t *a1, uint64_t a2)
{
  uint64_t v4 = (uint64_t *)(*(void *)(*(void *)(*(void *)(*a1 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8);
  if (!v4) {
    goto LABEL_10;
  }
  uint64_t v5 = *v4;
  unint64_t v6 = mlir::TypeID::get<mlir::ShapedType>();
  unint64_t v7 = *(unsigned int *)(v5 + 16);
  if (!v7) {
    goto LABEL_10;
  }
  uint64_t v8 = *(void **)(v5 + 8);
  unint64_t v9 = &v8[2 * v7];
  do
  {
    unint64_t v10 = v7 >> 1;
    unint64_t v11 = &v8[2 * (v7 >> 1)];
    unint64_t v13 = *v11;
    uint64_t v12 = v11 + 2;
    v7 += ~(v7 >> 1);
    if (v13 < v6) {
      uint64_t v8 = v12;
    }
    else {
      unint64_t v7 = v10;
    }
  }
  while (v7);
  if (v8 != v9 && *v8 == v6) {
    uint64_t v14 = v8[1];
  }
  else {
LABEL_10:
  }
    uint64_t v14 = 0;
  v53[0] = v4;
  v53[1] = v14;
  unint64_t v15 = (uint64_t *)(*(void *)(*(void *)(*(void *)(*a1 + 72) + 56) + 8) & 0xFFFFFFFFFFFFFFF8);
  if (!v15) {
    goto LABEL_20;
  }
  uint64_t v16 = *v15;
  unint64_t v17 = mlir::TypeID::get<mlir::ShapedType>();
  unint64_t v18 = *(unsigned int *)(v16 + 16);
  if (!v18) {
    goto LABEL_20;
  }
  uint64_t v19 = *(void **)(v16 + 8);
  unint64_t v20 = &v19[2 * v18];
  do
  {
    unint64_t v21 = v18 >> 1;
    uint64_t v22 = &v19[2 * (v18 >> 1)];
    unint64_t v24 = *v22;
    unint64_t v23 = v22 + 2;
    v18 += ~(v18 >> 1);
    if (v24 < v17) {
      uint64_t v19 = v23;
    }
    else {
      unint64_t v18 = v21;
    }
  }
  while (v18);
  if (v19 != v20 && *v19 == v17) {
    uint64_t v25 = v19[1];
  }
  else {
LABEL_20:
  }
    uint64_t v25 = 0;
  v52[0] = v15;
  v52[1] = v25;
  if (*(_DWORD *)(*a1 + 36)) {
    uint64_t v26 = *a1 - 16;
  }
  else {
    uint64_t v26 = 0;
  }
  unint64_t v27 = (uint64_t *)(*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v26, 0) + 8) & 0xFFFFFFFFFFFFFFF8);
  if (!v27) {
    goto LABEL_33;
  }
  uint64_t v28 = *v27;
  unint64_t v29 = mlir::TypeID::get<mlir::ShapedType>();
  unint64_t v30 = *(unsigned int *)(v28 + 16);
  if (!v30) {
    goto LABEL_33;
  }
  char v31 = *(void **)(v28 + 8);
  unint64_t v32 = &v31[2 * v30];
  do
  {
    unint64_t v33 = v30 >> 1;
    uint64_t v34 = &v31[2 * (v30 >> 1)];
    unint64_t v36 = *v34;
    uint64_t v35 = v34 + 2;
    v30 += ~(v30 >> 1);
    if (v36 < v29) {
      char v31 = v35;
    }
    else {
      unint64_t v30 = v33;
    }
  }
  while (v30);
  if (v31 != v32 && *v31 == v29) {
    uint64_t v37 = v31[1];
  }
  else {
LABEL_33:
  }
    uint64_t v37 = 0;
  v51[0] = v27;
  v51[1] = v37;
  mlir::ShapedType::getShape((mlir::ShapedType *)v53);
  mlir::ShapedType::getShape((mlir::ShapedType *)v52);
  mlir::ShapedType::getShape((mlir::ShapedType *)v51);
  mlir::ShapedType::getShape((mlir::ShapedType *)v53);
  mlir::anec::getIndexFromDim(0, v38);
  if (v39
    && (mlir::ShapedType::getShape((mlir::ShapedType *)v53), mlir::anec::getIndexFromDim(1, v40), v41)
    && (mlir::ShapedType::getShape((mlir::ShapedType *)v53), mlir::anec::getIndexFromDim(3, v42), v43)
    && (mlir::ShapedType::getShape((mlir::ShapedType *)v53), mlir::anec::getIndexFromDim(4, v44), v45))
  {
    mlir::ShapedType::getShape((mlir::ShapedType *)v53);
    mlir::anec::getIndexFromDim(2, v46);
    uint64_t v47 = *a1;
    uint64_t OperandRange = (void *)mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)v53);
  }
  else
  {
    uint64_t v50 = (mlir::anec::Deconvolution *)std::__throw_bad_optional_access[abi:nn180100]();
    return mlir::anec::Deconvolution::getInput(v50);
  }
}

uint64_t mlir::anec::Deconvolution::getInput(mlir::anec::Deconvolution *this)
{
  return *(void *)(*(void *)(*(void *)this + 72) + 24);
}

uint64_t mlir::anec::inferElementwiseReturnTypes(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11)
{
  v68[4] = *MEMORY[0x263EF8340];
  unint64_t v13 = (uint64_t *)mlir::TypeRange::dereference_iterator(a9, 0);
  uint64_t v14 = v13;
  if (!v13) {
    goto LABEL_10;
  }
  uint64_t v15 = *v13;
  unint64_t v16 = mlir::TypeID::get<mlir::ShapedType>();
  unint64_t v17 = *(unsigned int *)(v15 + 16);
  if (!v17) {
    goto LABEL_10;
  }
  unint64_t v18 = *(void **)(v15 + 8);
  uint64_t v19 = &v18[2 * v17];
  do
  {
    unint64_t v20 = v17 >> 1;
    unint64_t v21 = &v18[2 * (v17 >> 1)];
    unint64_t v23 = *v21;
    uint64_t v22 = v21 + 2;
    v17 += ~(v17 >> 1);
    if (v23 < v16) {
      unint64_t v18 = v22;
    }
    else {
      unint64_t v17 = v20;
    }
  }
  while (v17);
  if (v18 != v19 && *v18 == v16) {
    uint64_t v24 = v18[1];
  }
  else {
LABEL_10:
  }
    uint64_t v24 = 0;
  __srCC_SHA256_CTX c = v14;
  uint64_t v67 = v24;
  uint64_t Shape = (const void *)mlir::ShapedType::getShape((mlir::ShapedType *)&__src);
  uint64_t v27 = v25;
  size_t v28 = 8 * v25;
  __srCC_SHA256_CTX c = v68;
  uint64_t v67 = 0x400000000;
  if ((unint64_t)(8 * v25) < 0x21)
  {
    unsigned int v29 = 0;
    if (!v25) {
      goto LABEL_16;
    }
    goto LABEL_15;
  }
  llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&__src, v68, (8 * v25) >> 3, 8);
  unsigned int v29 = v67;
  if (v27)
  {
LABEL_15:
    memcpy((char *)__src + 8 * v29, Shape, v28);
    unsigned int v29 = v67;
  }
LABEL_16:
  size_t v30 = v28 >> 3;
  uint64_t v63 = v65;
  uint64_t v64 = 0x400000000;
  unsigned int v31 = v29 + (v28 >> 3);
  LODWORD(v67) = v31;
  if (!v31) {
    goto LABEL_23;
  }
  if (v31 < 5)
  {
    unint64_t v33 = v65;
    unsigned int v32 = v29 + v30;
    goto LABEL_21;
  }
  llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v63, v65, v29 + v30, 8);
  unsigned int v32 = v67;
  if (v67)
  {
    unint64_t v33 = v63;
LABEL_21:
    memcpy(v33, __src, 8 * v32);
  }
  LODWORD(v64) = v31;
LABEL_23:
  if (a10 != 1)
  {
    uint64_t v60 = a4;
    uint64_t v61 = a5;
    uint64_t v34 = 1;
    while (1)
    {
      uint64_t v35 = (void *)mlir::TypeRange::dereference_iterator(a9, v34);
      unint64_t v36 = v35;
      uint64_t v37 = (uint64_t *)__src;
      unint64_t v38 = v67;
      if (!v35) {
        goto LABEL_35;
      }
      uint64_t v39 = *v35;
      unint64_t v40 = mlir::TypeID::get<mlir::ShapedType>();
      unint64_t v41 = *(unsigned int *)(v39 + 16);
      if (!v41) {
        goto LABEL_35;
      }
      unint64_t v42 = *(void **)(v39 + 8);
      char v43 = &v42[2 * v41];
      do
      {
        unint64_t v44 = v41 >> 1;
        char v45 = &v42[2 * (v41 >> 1)];
        unint64_t v47 = *v45;
        unint64_t v46 = v45 + 2;
        v41 += ~(v41 >> 1);
        if (v47 < v40) {
          unint64_t v42 = v46;
        }
        else {
          unint64_t v41 = v44;
        }
      }
      while (v41);
      if (v42 != v43 && *v42 == v40) {
        uint64_t v48 = v42[1];
      }
      else {
LABEL_35:
      }
        uint64_t v48 = 0;
      v62[0] = v36;
      v62[1] = v48;
      char v49 = (uint64_t *)mlir::ShapedType::getShape((mlir::ShapedType *)v62);
      if ((mlir::OpTrait::util::getBroadcastedShape(v37, v38, v49, v50, (uint64_t)&v63) & 1) == 0)
      {
        uint64_t MostDefinedTypeForANE = mlir::getMostDefinedTypeForANE(v60, v61);
        goto LABEL_51;
      }
      int v51 = v64;
      uint64_t v52 = v67;
      if (v67 >= v64)
      {
        if (v64) {
          memmove(__src, v63, 8 * v64);
        }
        goto LABEL_25;
      }
      if (HIDWORD(v67) >= v64)
      {
        if (v67)
        {
          memmove(__src, v63, 8 * v67);
          goto LABEL_45;
        }
      }
      else
      {
        LODWORD(v67) = 0;
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&__src, v68, v64, 8);
      }
      uint64_t v52 = 0;
LABEL_45:
      if (v52 != v64) {
        memcpy((char *)__src + 8 * v52, (char *)v63 + 8 * v52, 8 * v64 - 8 * v52);
      }
LABEL_25:
      LODWORD(v67) = v51;
      if (++v34 == a10)
      {
        unsigned int v31 = v64;
        break;
      }
    }
  }
  uint64_t v54 = (uint64_t *)v63;
  uint64_t v55 = (void *)mlir::TypeRange::dereference_iterator(a9, 0);
  uint64_t ElementTypeOrSelf = mlir::getElementTypeOrSelf(v55);
  uint64_t MostDefinedTypeForANE = mlir::MemRefType::get(v54, (mlir::AffineMap *)v31, ElementTypeOrSelf, 0, 0, 0);
LABEL_51:
  uint64_t v57 = MostDefinedTypeForANE;
  unsigned int v58 = *(_DWORD *)(a11 + 8);
  if (v58 >= *(_DWORD *)(a11 + 12))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod(a11, (void *)(a11 + 16), v58 + 1, 8);
    unsigned int v58 = *(_DWORD *)(a11 + 8);
  }
  *(void *)(*(void *)a11 + 8 * v58) = v57;
  ++*(_DWORD *)(a11 + 8);
  if (v63 != v65) {
    free(v63);
  }
  if (__src != v68) {
    free(__src);
  }
  return 1;
}

uint64_t mlir::anec::inferElementwiseCompareReturnTypes(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11)
{
  v67[4] = *MEMORY[0x263EF8340];
  unint64_t v13 = (uint64_t *)mlir::TypeRange::dereference_iterator(a9, 0);
  uint64_t v14 = v13;
  if (!v13) {
    goto LABEL_10;
  }
  uint64_t v15 = *v13;
  unint64_t v16 = mlir::TypeID::get<mlir::ShapedType>();
  unint64_t v17 = *(unsigned int *)(v15 + 16);
  if (!v17) {
    goto LABEL_10;
  }
  unint64_t v18 = *(void **)(v15 + 8);
  uint64_t v19 = &v18[2 * v17];
  do
  {
    unint64_t v20 = v17 >> 1;
    unint64_t v21 = &v18[2 * (v17 >> 1)];
    unint64_t v23 = *v21;
    uint64_t v22 = v21 + 2;
    v17 += ~(v17 >> 1);
    if (v23 < v16) {
      unint64_t v18 = v22;
    }
    else {
      unint64_t v17 = v20;
    }
  }
  while (v17);
  if (v18 != v19 && *v18 == v16) {
    uint64_t v24 = v18[1];
  }
  else {
LABEL_10:
  }
    uint64_t v24 = 0;
  __srCC_SHA256_CTX c = v14;
  uint64_t v66 = v24;
  uint64_t Shape = (const void *)mlir::ShapedType::getShape((mlir::ShapedType *)&__src);
  uint64_t v27 = v25;
  size_t v28 = 8 * v25;
  __srCC_SHA256_CTX c = v67;
  uint64_t v66 = 0x400000000;
  if ((unint64_t)(8 * v25) < 0x21)
  {
    unsigned int v29 = 0;
    if (!v25) {
      goto LABEL_16;
    }
    goto LABEL_15;
  }
  llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&__src, v67, (8 * v25) >> 3, 8);
  unsigned int v29 = v66;
  if (v27)
  {
LABEL_15:
    memcpy((char *)__src + 8 * v29, Shape, v28);
    unsigned int v29 = v66;
  }
LABEL_16:
  uint64_t v62 = v64;
  uint64_t v63 = 0x400000000;
  unint64_t v30 = v29 + (v28 >> 3);
  LODWORD(v66) = v30;
  if (!v30) {
    goto LABEL_23;
  }
  if (v30 < 5)
  {
    unsigned int v32 = v64;
    unsigned int v31 = v30;
    goto LABEL_21;
  }
  llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v62, v64, v30, 8);
  unsigned int v31 = v66;
  if (v66)
  {
    unsigned int v32 = v62;
LABEL_21:
    memcpy(v32, __src, 8 * v31);
  }
  LODWORD(v63) = v30;
LABEL_23:
  if (a10 != 1)
  {
    uint64_t v58 = a1;
    uint64_t v59 = a5;
    uint64_t v33 = 1;
    while (1)
    {
      uint64_t v34 = (void *)mlir::TypeRange::dereference_iterator(a9, v33);
      uint64_t v35 = v34;
      unint64_t v36 = (uint64_t *)__src;
      unint64_t v37 = v66;
      if (!v34) {
        goto LABEL_35;
      }
      uint64_t v38 = *v34;
      unint64_t v39 = mlir::TypeID::get<mlir::ShapedType>();
      unint64_t v40 = *(unsigned int *)(v38 + 16);
      if (!v40) {
        goto LABEL_35;
      }
      unint64_t v41 = *(void **)(v38 + 8);
      unint64_t v42 = &v41[2 * v40];
      do
      {
        unint64_t v43 = v40 >> 1;
        unint64_t v44 = &v41[2 * (v40 >> 1)];
        unint64_t v46 = *v44;
        char v45 = v44 + 2;
        v40 += ~(v40 >> 1);
        if (v46 < v39) {
          unint64_t v41 = v45;
        }
        else {
          unint64_t v40 = v43;
        }
      }
      while (v40);
      if (v41 != v42 && *v41 == v39) {
        uint64_t v47 = v41[1];
      }
      else {
LABEL_35:
      }
        uint64_t v47 = 0;
      v61[0] = v35;
      v61[1] = v47;
      uint64_t v48 = (uint64_t *)mlir::ShapedType::getShape((mlir::ShapedType *)v61);
      if ((mlir::OpTrait::util::getBroadcastedShape(v36, v37, v48, v49, (uint64_t)&v62) & 1) == 0)
      {
        uint64_t MostDefinedTypeForANE = mlir::getMostDefinedTypeForANE(a4, v59);
        goto LABEL_51;
      }
      int v50 = v63;
      uint64_t v51 = v66;
      if (v66 >= v63)
      {
        if (v63) {
          memmove(__src, v62, 8 * v63);
        }
        goto LABEL_25;
      }
      if (HIDWORD(v66) >= v63)
      {
        if (v66)
        {
          memmove(__src, v62, 8 * v66);
          goto LABEL_45;
        }
      }
      else
      {
        LODWORD(v66) = 0;
        llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&__src, v67, v63, 8);
      }
      uint64_t v51 = 0;
LABEL_45:
      if (v51 != v63) {
        memcpy((char *)__src + 8 * v51, (char *)v62 + 8 * v51, 8 * v63 - 8 * v51);
      }
LABEL_25:
      LODWORD(v66) = v50;
      if (++v33 == a10)
      {
        LODWORD(v3std::unique_ptr<ZinIrKernel>::reset[abi:ne180100](&a9, 0) = v63;
        a1 = v58;
        break;
      }
    }
  }
  uint64_t v53 = (uint64_t *)v62;
  uint64_t v54 = mlir::IntegerType::get(a1, 8u, 1u);
  uint64_t MostDefinedTypeForANE = mlir::MemRefType::get(v53, (mlir::AffineMap *)v30, v54, 0, 0, 0);
LABEL_51:
  uint64_t v55 = MostDefinedTypeForANE;
  unsigned int v56 = *(_DWORD *)(a11 + 8);
  if (v56 >= *(_DWORD *)(a11 + 12))
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod(a11, (void *)(a11 + 16), v56 + 1, 8);
    unsigned int v56 = *(_DWORD *)(a11 + 8);
  }
  *(void *)(*(void *)a11 + 8 * v56) = v55;
  ++*(_DWORD *)(a11 + 8);
  if (v62 != v64) {
    free(v62);
  }
  if (__src != v67) {
    free(__src);
  }
  return 1;
}

uint64_t mlir::anec::ElementwiseAdd::canonicalize(uint64_t a1, uint64_t a2, mlir::PatternRewriter *a3)
{
  uint64_t v111 = *MEMORY[0x263EF8340];
  uint64_t v104 = 0;
  uint64_t v105 = 0;
  v102[0] = &v105;
  v102[1] = &v104;
  uint64_t v103 = 0;
  if (*(_UNKNOWN **)(*(void *)(a1 + 48) + 16) != &mlir::detail::TypeIDResolver<mlir::anec::ElementwiseAdd,void>::id
    || (*(unsigned char *)(a1 + 46) & 0x80) == 0
    || *(_DWORD *)(a1 + 68) != 2
    || (v5 = mlir::detail::matchOperandOrValueAtIndex<mlir::detail::RecursivePatternMatcherBinder<mlir::anec::MatMul,mlir::detail::any_value_binder,mlir::detail::op_matcher_with_bind<mlir::mps::ConstantOp>>>(a1, 0, v102), v107 = *(uint64_t **)(*(void *)(a1 + 72) + 56), (DefiningOp = mlir::Value::getDefiningOp((mlir::Value *)&v107)) == 0)|| (*(_UNKNOWN **)(*(void *)(DefiningOp + 48) + 16) == &mlir::detail::TypeIDResolver<mlir::mps::ConstantOp,void>::id? (char v7 = v5): (char v7 = 0), (v7 & 1) == 0))
  {
    unint64_t v11 = "does not match pattern";
    goto LABEL_13;
  }
  uint64_t v8 = v103;
  uint64_t v100 = v104;
  uint64_t v101 = v103;
  uint64_t v99 = DefiningOp;
  mlir::anec::MatMul::getBias(&v101, (uint64_t)&v107);
  if ((_BYTE)v110)
  {
    unint64_t v10 = (void *)v108;
    if (llvm::APFloatBase::PPCDoubleDouble(v9) == v10) {
      llvm::detail::DoubleAPFloat::~DoubleAPFloat((llvm::detail::DoubleAPFloat *)&v108);
    }
    else {
      llvm::detail::IEEEFloat::~IEEEFloat((llvm::detail::IEEEFloat *)&v108);
    }
    unint64_t v11 = "MatMul already has bias";
LABEL_13:
    uint64_t v107 = (uint64_t *)v11;
    __int16 v110 = 259;
    v106[0] = (uint64_t)&v107;
    uint64_t v12 = *(void *)(a2 + 16);
    if (v12 && mlir::RewriterBase::Listener::classof(*(void *)(a2 + 16))) {
      char v13 = (*(uint64_t (**)(uint64_t, void, uint64_t (*)(void ****, uint64_t), uint64_t *))(*(void *)v12 + 64))(v12, *(void *)(a1 + 24), llvm::function_ref<void ()(mlir::Diagnostic &)>::callback_fn<mlir::LogicalResult mlir::RewriterBase::notifyMatchFailure<mlir::anec::ElementwiseAdd &>(mlir::anec::ElementwiseAdd &,llvm::Twine const&)::{lambda(mlir::Diagnostic &)#1}>, v106);
    }
    else {
      char v13 = 0;
    }
    if (v13) {
      return 1;
    }
    else {
  }
    }
  if (*((_DWORD *)v8 + 9)) {
    uint64_t v15 = (uint64_t)v8 - 16;
  }
  else {
    uint64_t v15 = 0;
  }
  uint64_t NextResultAtOffset = (void *)mlir::detail::OpResultImpl::getNextResultAtOffset(v15, 0);
  if (!*NextResultAtOffset || *(void *)*NextResultAtOffset)
  {
    unint64_t v11 = "MatMul has multiple users";
    goto LABEL_13;
  }
  v98[0] = (uint64_t)mlir::mps::ConstantOp::getValue((mlir::mps::ConstantOp *)&v100);
  v98[1] = v17;
  v97[0] = (uint64_t)mlir::mps::ConstantOp::getValue((mlir::mps::ConstantOp *)&v99);
  v97[1] = v18;
  Type = (void *)mlir::ElementsAttr::getType((mlir::ElementsAttr *)v98);
  unint64_t v20 = Type;
  if (!Type) {
    goto LABEL_38;
  }
  uint64_t v21 = *Type;
  unint64_t v22 = mlir::TypeID::get<mlir::ShapedType>();
  unint64_t v23 = *(unsigned int *)(v21 + 16);
  if (!v23) {
    goto LABEL_38;
  }
  uint64_t v24 = *(void **)(v21 + 8);
  uint64_t v25 = &v24[2 * v23];
  do
  {
    unint64_t v26 = v23 >> 1;
    uint64_t v27 = &v24[2 * (v23 >> 1)];
    unint64_t v29 = *v27;
    size_t v28 = v27 + 2;
    v23 += ~(v23 >> 1);
    if (v29 < v22) {
      uint64_t v24 = v28;
    }
    else {
      unint64_t v23 = v26;
    }
  }
  while (v23);
  if (v24 != v25 && *v24 == v22) {
    unint64_t v30 = (void *)v24[1];
  }
  else {
LABEL_38:
  }
    unint64_t v30 = 0;
  v96[0] = v20;
  v96[1] = v30;
  unsigned int v31 = (void *)mlir::ElementsAttr::getType((mlir::ElementsAttr *)v97);
  unsigned int v32 = v31;
  if (!v31) {
    goto LABEL_48;
  }
  uint64_t v33 = *v31;
  unint64_t v34 = mlir::TypeID::get<mlir::ShapedType>();
  unint64_t v35 = *(unsigned int *)(v33 + 16);
  if (!v35) {
    goto LABEL_48;
  }
  unint64_t v36 = *(void **)(v33 + 8);
  unint64_t v37 = &v36[2 * v35];
  do
  {
    unint64_t v38 = v35 >> 1;
    unint64_t v39 = &v36[2 * (v35 >> 1)];
    unint64_t v41 = *v39;
    unint64_t v40 = v39 + 2;
    v35 += ~(v35 >> 1);
    if (v41 < v34) {
      unint64_t v36 = v40;
    }
    else {
      unint64_t v35 = v38;
    }
  }
  while (v35);
  if (v36 != v37 && *v36 == v34) {
    unint64_t v42 = (void *)v36[1];
  }
  else {
LABEL_48:
  }
    unint64_t v42 = 0;
  v95[0] = v32;
  v95[1] = v42;
  mlir::ShapedType::getShape((mlir::ShapedType *)v96);
  uint64_t v44 = v43;
  mlir::ShapedType::getShape((mlir::ShapedType *)v95);
  if (v44 != v45
    || (uint64_t ElementTypeOrSelf = mlir::getElementTypeOrSelf(v96[0]), ElementTypeOrSelf != mlir::getElementTypeOrSelf(v95[0])))
  {
    unint64_t v11 = "unsupported kernel and bias fusion";
    goto LABEL_13;
  }
  uint64_t Shape = (void *)mlir::ShapedType::getShape((mlir::ShapedType *)v96);
  uint64_t v90 = v48;
  uint64_t v49 = mlir::ShapedType::getShape((mlir::ShapedType *)v95);
  mlir::ShapedType::getShape((mlir::ShapedType *)v96);
  IndexFromDiuint64_t m = mlir::anec::getIndexFromDim(4, v50);
  char v53 = v52;
  mlir::ShapedType::getShape((mlir::ShapedType *)v95);
  unint64_t v55 = mlir::anec::getIndexFromDim(4, v54);
  char v57 = v56;
  mlir::ShapedType::getShape((mlir::ShapedType *)v96);
  unint64_t v59 = mlir::anec::getIndexFromDim(1, v58);
  if (!v53 || !v57 || !v60 || IndexFromDim != v55)
  {
    unint64_t v11 = "cannot get axes";
    goto LABEL_13;
  }
  unint64_t v61 = v59;
  int v62 = v60;
  mlir::ShapedType::getShape((mlir::ShapedType *)v96);
  if (v63)
  {
    uint64_t v64 = 0;
    while (1)
    {
      uint64_t v66 = IndexFromDim == v64 ? Shape[IndexFromDim] : 1;
      if (*(void *)(v49 + 8 * v64) != v66) {
        break;
      }
      if (!v62) {
        goto LABEL_83;
      }
      if (v61 != v64 && IndexFromDim != v64 && Shape[v64] != 1)
      {
        unint64_t v11 = "unsupported kernel shape";
        goto LABEL_13;
      }
      ++v64;
      mlir::ShapedType::getShape((mlir::ShapedType *)v96);
      if (v64 == v65) {
        goto LABEL_71;
      }
    }
    unint64_t v11 = "unsupported bias shape";
    goto LABEL_13;
  }
LABEL_71:
  mlir::ShapedType::getShape((mlir::ShapedType *)v96);
  if (IndexFromDim != v67 - 1
    || (mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)v98) & 1) != 0
    || mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)v97))
  {
    unint64_t v11 = "unsupported concatenation dimension";
    goto LABEL_13;
  }
  uint64_t v107 = (uint64_t *)v109;
  uint64_t v108 = 0x400000000;
  if ((unint64_t)(8 * v90) < 0x21)
  {
    int v68 = 0;
  }
  else
  {
    llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v107, v109, (8 * v90) >> 3, 8);
    int v68 = v108;
  }
  if (v90)
  {
    memcpy(&v107[v68], Shape, 8 * v90);
    int v68 = v108;
  }
  uint64_t v69 = (v68 + v90);
  LODWORD(v108) = v68 + v90;
  if (v62)
  {
    uint64_t v70 = (uint64_t)v107;
    ++v107[v61];
    uint64_t v71 = mlir::getElementTypeOrSelf(v96[0]);
    uint64_t v72 = (void *)mlir::RankedTensorType::get(v70, v69, v71, 0);
    BufferTensorAttr = (uint64_t *)mlir::mps::getBufferTensorAttr(v72);
    ElementsAttrRawData = (const void *)mlir::getElementsAttrRawData(v98[0]);
    size_t v75 = v74;
    unint64_t v76 = (const void *)mlir::getElementsAttrRawData(v97[0]);
    size_t v78 = v77;
    MutableRawData = (char *)mlir::mps::MPSBufferTensorAttr::getMutableRawData((mlir::mps::MPSBufferTensorAttr *)&BufferTensorAttr);
    memcpy(MutableRawData, ElementsAttrRawData, v75);
    memcpy(&MutableRawData[v75], v76, v78);
    uint64_t v80 = v107;
    __int16 v81 = (mlir::AffineMap *)v108;
    uint64_t v82 = mlir::getElementTypeOrSelf((void *)(*(void *)(v100 - 8) & 0xFFFFFFFFFFFFFFF8));
    uint64_t v93 = mlir::MemRefType::get(v80, v81, v82, 0, 0, 0);
    uint64_t v92 = mlir::OpBuilder::create<mlir::mps::ConstantOp,mlir::MemRefType &,mlir::mps::MPSBufferTensorAttr &>((mlir::OpBuilder *)(a2 + 8), *(void *)(v100 + 24), &v93, &BufferTensorAttr);
    uint64_t F16Type = mlir::Builder::getF16Type((mlir::Float16Type **)(a2 + 8), v83);
    FloatAttr = mlir::Builder::getFloatAttr(1.0, a2 + 8, F16Type);
    uint64_t v85 = *(void *)(a1 + 24);
    v106[0] = *(void *)(*((void *)v8 + 9) + 24);
    uint64_t v86 = mlir::OpBuilder::create<mlir::anec::MatMul,mlir::detail::TypedValue<mlir::MemRefType>,mlir::mps::ConstantOp &,mlir::FloatAttr &>((mlir::UnknownLoc **)(a2 + 8), v85, v106, &v92, (uint64_t *)&FloatAttr);
    mlir::verify(v86, (mlir::Operation *)1);
  }
LABEL_83:
  uint64_t v87 = (mlir::anec::_anonymous_namespace_ *)std::__throw_bad_optional_access[abi:nn180100]();
}

uint64_t mlir::anec::anonymous namespace'::canonicalizeElementwiseToGOC(mlir::anec::_anonymous_namespace_ *this, mlir::Float16Type **a2, mlir::PatternRewriter *a3)
{
  v149[5] = *MEMORY[0x263EF8340];
  RawElementsAttr = 0;
  uint64_t v135 = 0;
  char v5 = *(char **)(*((void *)this + 9) + 56);
  float v141 = &RawElementsAttr;
  uint64_t v144 = v5;
  uint64_t DefiningOp = mlir::Value::getDefiningOp((mlir::Value *)&v144);
  if (DefiningOp && mlir::detail::constant_op_binder<mlir::ElementsAttr>::match((uint64_t ***)&v141, DefiningOp))
  {
    uint64_t v7 = *((void *)this + 9);
    uint64_t v8 = *(void *)(v7 + 24);
    uint64_t v133 = v8;
    uint64_t v9 = v7 + 56;
    int v10 = 1;
  }
  else
  {
    unint64_t v11 = *(char **)(*((void *)this + 9) + 24);
    float v141 = &RawElementsAttr;
    uint64_t v144 = v11;
    uint64_t v12 = mlir::Value::getDefiningOp((mlir::Value *)&v144);
    if (!v12 || !mlir::detail::constant_op_binder<mlir::ElementsAttr>::match((uint64_t ***)&v141, v12)) {
      return 0;
    }
    int v10 = 0;
    uint64_t v13 = *((void *)this + 9);
    uint64_t v8 = *(void *)(v13 + 56);
    uint64_t v133 = v8;
    uint64_t v9 = v13 + 24;
  }
  uint64_t v14 = (void *)(*(void *)(*(void *)v9 + 8) & 0xFFFFFFFFFFFFFFF8);
  if (!v14) {
    goto LABEL_16;
  }
  uint64_t v15 = *v14;
  unint64_t v16 = mlir::TypeID::get<mlir::ShapedType>();
  unint64_t v17 = *(unsigned int *)(v15 + 16);
  if (!v17) {
    goto LABEL_16;
  }
  uint64_t v18 = *(void **)(v15 + 8);
  uint64_t v19 = &v18[2 * v17];
  do
  {
    unint64_t v20 = v17 >> 1;
    uint64_t v21 = &v18[2 * (v17 >> 1)];
    unint64_t v23 = *v21;
    unint64_t v22 = v21 + 2;
    v17 += ~(v17 >> 1);
    if (v23 < v16) {
      uint64_t v18 = v22;
    }
    else {
      unint64_t v17 = v20;
    }
  }
  while (v17);
  if (v18 != v19 && *v18 == v16) {
    uint64_t v24 = v18[1];
  }
  else {
LABEL_16:
  }
    uint64_t v24 = 0;
  uint64_t v131 = v14;
  uint64_t v132 = v24;
  mlir::ShapedType::getShape((mlir::ShapedType *)&v131);
  mlir::anec::getIndexFromDim(1, v25);
  if (v26)
  {
    if ((mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&RawElementsAttr) & 1) == 0
      && !mlir::anec::allElementsOnAxis((uint64_t)v131, v132, 1))
    {
      return 0;
    }
    uint64_t v27 = (uint64_t *)(*(void *)(v8 + 8) & 0xFFFFFFFFFFFFFFF8);
    if (!v27) {
      goto LABEL_29;
    }
    uint64_t v28 = *v27;
    unint64_t v29 = mlir::TypeID::get<mlir::ShapedType>();
    unint64_t v30 = *(unsigned int *)(v28 + 16);
    if (!v30) {
      goto LABEL_29;
    }
    unsigned int v31 = *(void **)(v28 + 8);
    unsigned int v32 = &v31[2 * v30];
    do
    {
      unint64_t v33 = v30 >> 1;
      unint64_t v34 = &v31[2 * (v30 >> 1)];
      unint64_t v36 = *v34;
      unint64_t v35 = v34 + 2;
      v30 += ~(v30 >> 1);
      if (v36 < v29) {
        unsigned int v31 = v35;
      }
      else {
        unint64_t v30 = v33;
      }
    }
    while (v30);
    if (v31 != v32 && *v31 == v29) {
      uint64_t v37 = v31[1];
    }
    else {
LABEL_29:
    }
      uint64_t v37 = 0;
    v130[0] = v27;
    v130[1] = v37;
    unint64_t v38 = (uint64_t *)(*((void *)this - 1) & 0xFFFFFFFFFFFFFFF8);
    if (!v38) {
      goto LABEL_39;
    }
    uint64_t v39 = *v38;
    unint64_t v40 = mlir::TypeID::get<mlir::ShapedType>();
    unint64_t v41 = *(unsigned int *)(v39 + 16);
    if (!v41) {
      goto LABEL_39;
    }
    unint64_t v42 = *(void **)(v39 + 8);
    uint64_t v43 = &v42[2 * v41];
    do
    {
      unint64_t v44 = v41 >> 1;
      uint64_t v45 = &v42[2 * (v41 >> 1)];
      unint64_t v47 = *v45;
      unint64_t v46 = v45 + 2;
      v41 += ~(v41 >> 1);
      if (v47 < v40) {
        unint64_t v42 = v46;
      }
      else {
        unint64_t v41 = v44;
      }
    }
    while (v41);
    if (v42 != v43 && *v42 == v40) {
      uint64_t v48 = v42[1];
    }
    else {
LABEL_39:
    }
      uint64_t v48 = 0;
    v129[0] = (uint64_t)v38;
    v129[1] = v48;
    uint64_t Shape = (const void *)mlir::ShapedType::getShape((mlir::ShapedType *)v130);
    uint64_t v51 = v50;
    char v52 = (const void *)mlir::ShapedType::getShape((mlir::ShapedType *)v129);
    if (v51 != v53 || memcmp(Shape, v52, 8 * v51)) {
      return 0;
    }
    char v57 = (const void *)mlir::ShapedType::getShape((mlir::ShapedType *)&v131);
    uint64_t v58 = v56;
    uint64_t v147 = v149;
    uint64_t v148 = 0x500000000;
    size_t v59 = 8 * v56;
    if ((unint64_t)(8 * v56) < 0x29)
    {
      int v60 = 0;
    }
    else
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v147, v149, (8 * v56) >> 3, 8);
      int v60 = v148;
    }
    if (v58)
    {
      memcpy(&v147[v60], v57, v59);
      int v60 = v148;
    }
    LODWORD(v148) = v60 + (v59 >> 3);
    if (!mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&RawElementsAttr))
    {
LABEL_73:
      uint64_t v70 = v147;
      uint64_t v71 = (mlir::AffineMap *)v148;
      uint64_t F16Type = mlir::Builder::getF16Type(a2 + 1, (mlir::MLIRContext *)v61);
      uint64_t v128 = mlir::MemRefType::get(v70, v71, F16Type, 0, 0, 0);
      Type = (void *)mlir::ElementsAttr::getType((mlir::ElementsAttr *)&RawElementsAttr);
      if (*(_UNKNOWN **)(*(void *)mlir::getElementTypeOrSelf(Type) + 136) == &mlir::detail::TypeIDResolver<mlir::IntegerType,void>::id)
      {
        uint64_t v144 = (char *)v146;
        uint64_t v145 = 0xC00000000;
        mlir::getIntValues<float>((uint64_t)RawElementsAttr, v135, (uint64_t)&v144, 0);
        uint64_t v101 = (uint64_t)v147;
        uint64_t v102 = v148;
        uint64_t F32Type = mlir::Builder::getF32Type(a2 + 1, v103);
        uint64_t v105 = (void *)mlir::RankedTensorType::get(v101, v102, F32Type, 0);
        RawElementsAttr = (char *)mlir::createRawElementsAttr(v105, v144, (const void *)(4 * v145));
        uint64_t v135 = v106;
        if (v144 != (char *)v146) {
          free(v144);
        }
      }
      else if (mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&RawElementsAttr))
      {
        uint64_t v144 = RawElementsAttr;
        uint64_t v74 = (uint64_t)v147;
        uint64_t v75 = v148;
        uint64_t ElementTypeOrSelf = mlir::getElementTypeOrSelf(RawElementsAttr);
        size_t v77 = (uint64_t *)mlir::RankedTensorType::get(v74, v75, ElementTypeOrSelf, 0);
        uint64_t v78 = (uint64_t)v77;
        if (!v77) {
          goto LABEL_84;
        }
        uint64_t v79 = *v77;
        unint64_t v80 = mlir::TypeID::get<mlir::ShapedType>();
        unint64_t v81 = *(unsigned int *)(v79 + 16);
        if (!v81) {
          goto LABEL_84;
        }
        uint64_t v82 = *(void **)(v79 + 8);
        uint64_t v83 = &v82[2 * v81];
        do
        {
          unint64_t v84 = v81 >> 1;
          uint64_t v85 = &v82[2 * (v81 >> 1)];
          unint64_t v87 = *v85;
          uint64_t v86 = v85 + 2;
          v81 += ~(v81 >> 1);
          if (v87 < v80) {
            uint64_t v82 = v86;
          }
          else {
            unint64_t v81 = v84;
          }
        }
        while (v81);
        if (v82 != v83 && *v82 == v80) {
          uint64_t v88 = v82[1];
        }
        else {
LABEL_84:
        }
          uint64_t v88 = 0;
        uint64_t v89 = (char *)mlir::DenseElementsAttr::reshape((uint64_t *)&v144, v78, v88);
        uint64_t v90 = v89;
        if (!v89) {
          goto LABEL_94;
        }
        uint64_t v91 = *(void *)v89;
        unint64_t v92 = mlir::TypeID::get<mlir::ElementsAttr>();
        unint64_t v93 = *(unsigned int *)(v91 + 16);
        if (!v93) {
          goto LABEL_94;
        }
        uint64_t v94 = *(void **)(v91 + 8);
        uint64_t v95 = &v94[2 * v93];
        do
        {
          unint64_t v96 = v93 >> 1;
          __int16 v97 = &v94[2 * (v93 >> 1)];
          unint64_t v99 = *v97;
          uint64_t v98 = v97 + 2;
          v93 += ~(v93 >> 1);
          if (v99 < v92) {
            uint64_t v94 = v98;
          }
          else {
            unint64_t v93 = v96;
          }
        }
        while (v93);
        if (v94 != v95 && *v94 == v92) {
          uint64_t v100 = v94[1];
        }
        else {
LABEL_94:
        }
          uint64_t v100 = 0;
        RawElementsAttr = v90;
        uint64_t v135 = v100;
      }
      float v127 = mlir::OpBuilder::create<mlir::mps::ConstantOp,mlir::Type &,mlir::ElementsAttr &>((mlir::OpBuilder *)(a2 + 1), *((void *)this + 3), &v128, (void **)&RawElementsAttr);
      uint64_t v107 = (uint64_t)v147;
      uint64_t v108 = v148;
      uint64_t v110 = mlir::Builder::getF32Type(a2 + 1, v109);
      uint64_t v111 = (void *)mlir::RankedTensorType::get(v107, v108, v110, 0);
      uint64_t v144 = (char *)v146;
      v146[0] = 0;
      uint64_t v145 = 0xC00000001;
      float v141 = v143;
      v143[0] = 1065353216;
      uint64_t v142 = 0xC00000001;
      uint64_t v138 = v140;
      v140[0] = -1082130432;
      uint64_t v139 = 0xC00000001;
      uint64_t v112 = *((void *)this + 3);
      unint64_t v122 = mlir::createRawElementsAttr(v111, v140, (const void *)4);
      uint64_t v123 = v113;
      uint64_t v124 = (uint64_t)mlir::OpBuilder::create<mlir::mps::ConstantOp,mlir::Type &,mlir::ElementsAttr &>((mlir::OpBuilder *)(a2 + 1), v112, &v128, &v122)- 16;
      uint64_t v114 = *((void *)this + 3);
      unint64_t v122 = mlir::createRawElementsAttr(v111, v144, (const void *)(4 * v145));
      uint64_t v123 = v115;
      uint64_t v126 = (uint64_t)mlir::OpBuilder::create<mlir::mps::ConstantOp,mlir::Type &,mlir::ElementsAttr &>((mlir::OpBuilder *)(a2 + 1), v114, &v128, &v122)- 16;
      uint64_t v116 = *((void *)this + 3);
      unint64_t v122 = mlir::createRawElementsAttr(v111, v141, (const void *)(4 * v142));
      uint64_t v123 = v117;
      uint64_t v125 = (uint64_t)mlir::OpBuilder::create<mlir::mps::ConstantOp,mlir::Type &,mlir::ElementsAttr &>((mlir::OpBuilder *)(a2 + 1), v116, &v128, &v122)- 16;
      uint64_t v118 = *(void **)(*((void *)this + 6) + 16);
      if (v118 == &mlir::detail::TypeIDResolver<mlir::anec::ElementwiseAdd,void>::id)
      {
        uint64_t v119 = mlir::OpBuilder::create<mlir::anec::GOC,mlir::ShapedType &,mlir::Value &,mlir::Value &,mlir::mps::ConstantOp &>((mlir::OpBuilder *)(a2 + 1), *((void *)this + 3), v129, &v133, &v125, &v127);
      }
      else
      {
        if (v118 != &mlir::detail::TypeIDResolver<mlir::anec::ElementwiseMult,void>::id)
        {
          if (v118 == &mlir::detail::TypeIDResolver<mlir::anec::ElementwiseSub,void>::id)
          {
            unint64_t v122 = (void *)((char *)mlir::OpBuilder::create<mlir::anec::GOC,mlir::ShapedType &,mlir::Value &,mlir::Value &,mlir::Value &>((mlir::OpBuilder *)(a2 + 1), *((void *)this + 3), v129, &v133, &v124, &v126)- 16);
            uint64_t v120 = (char *)mlir::OpBuilder::create<mlir::anec::GOC,mlir::ShapedType &,mlir::Value &,mlir::Value &,mlir::mps::ConstantOp &>((mlir::OpBuilder *)(a2 + 1), *((void *)this + 3), v129, (uint64_t *)&v122, &v125, &v127)- 16;
            unint64_t v122 = v120;
            if (v10)
            {
              uint64_t v120 = (char *)mlir::OpBuilder::create<mlir::anec::GOC,mlir::ShapedType &,mlir::Value &,mlir::Value &,mlir::Value &>((mlir::OpBuilder *)(a2 + 1), *((void *)this + 3), v129, (uint64_t *)&v122, &v124, &v126)- 16;
              unint64_t v122 = v120;
            }
            unint64_t v136 = v120;
            uint64_t v54 = 1;
            mlir::ValueRange::ValueRange(v137, (uint64_t)&v136, 1uLL);
            (*((void (**)(mlir::Float16Type **, mlir::anec::_anonymous_namespace_ *, unint64_t, unint64_t))*a2
             + 3))(a2, this, v137[0], v137[1]);
          }
          else
          {
            uint64_t v54 = 0;
          }
          goto LABEL_105;
        }
        uint64_t v119 = mlir::OpBuilder::create<mlir::anec::GOC,mlir::ShapedType &,mlir::Value &,mlir::mps::ConstantOp &,mlir::Value &>((mlir::OpBuilder *)(a2 + 1), *((void *)this + 3), v129, &v133, &v127, &v126);
      }
      (*((void (**)(mlir::Float16Type **, mlir::anec::_anonymous_namespace_ *, ZinIrHalH13g *))*a2 + 4))(a2, this, v119);
      uint64_t v54 = 1;
LABEL_105:
      if (v138 != v140) {
        free(v138);
      }
      if (v141 != v143) {
        free(v141);
      }
      if (v144 != (char *)v146) {
        free(v144);
      }
      goto LABEL_111;
    }
    int v62 = (uint64_t *)mlir::ShapedType::getShape((mlir::ShapedType *)v130);
    if (mlir::ShapedType::getNumElements(v62, v63) != 1)
    {
      uint64_t v64 = (uint64_t *)mlir::ShapedType::getShape((mlir::ShapedType *)v130);
      uint64_t NumElements = mlir::ShapedType::getNumElements(v64, v65);
      if (NumElements < mlir::ElementsAttr::getNumElements((uint64_t)RawElementsAttr, v135))
      {
        uint64_t v54 = 0;
LABEL_111:
        if (v147 != v149) {
          free(v147);
        }
        return v54;
      }
    }
    mlir::ShapedType::getShape((mlir::ShapedType *)v130);
    unint64_t v67 = v61;
    uint64_t v144 = (char *)v146;
    HIDWORD(v145) = 5;
    if (v61 < 6)
    {
      if (v61) {
        memset_pattern16(v146, &unk_211ED5510, 8 * v61);
      }
      int v68 = v146;
    }
    else
    {
      LODWORD(v145) = 0;
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v144, v146, v61, 8);
      int v68 = v144;
      memset_pattern16(v144, &unk_211ED5510, 8 * v67);
    }
    LODWORD(v145) = v67;
    uint64_t v69 = v148;
    if (v148 >= v67)
    {
      if (v67) {
        memmove(v147, v68, 8 * v67);
      }
      goto LABEL_71;
    }
    if (HIDWORD(v148) >= v67)
    {
      if (v148)
      {
        memmove(v147, v68, 8 * v148);
        goto LABEL_69;
      }
    }
    else
    {
      LODWORD(v148) = 0;
      llvm::SmallVectorBase<unsigned int>::grow_pod((uint64_t)&v147, v149, v67, 8);
    }
    uint64_t v69 = 0;
LABEL_69:
    if (v69 != v145) {
      memcpy(&v147[v69], &v144[8 * v69], 8 * v145 - 8 * v69);
    }
LABEL_71:
    LODWORD(v148) = v67;
    if (v144 != (char *)v146) {
      free(v144);
    }
    goto LABEL_73;
  }
  uint64_t v121 = std::__throw_bad_optional_access[abi:nn180100]();
  return mlir::anec::ElementwiseSub::canonicalize(v121);
}

uint64_t mlir::anec::ElementwiseMax::canonicalize(uint64_t a1, uint64_t a2)
{
  uint64_t v22 = *MEMORY[0x263EF8340];
  uint64_t v15 = 0;
  uint64_t v4 = *(const char **)(*(void *)(a1 + 72) + 56);
  unint64_t v17 = (const char **)&v15;
  uint64_t v19 = v4;
  uint64_t DefiningOp = mlir::Value::getDefiningOp((mlir::Value *)&v19);
  if (DefiningOp
    && mlir::detail::constant_op_binder<mlir::DenseFPElementsAttr>::match((unint64_t **)&v17, DefiningOp)
    && mlir::DenseElementsAttr::isSplat((mlir::DenseElementsAttr *)&v15)
    && (*(_DWORD *)(a1 + 36) ? (uint64_t v6 = a1 - 16) : (uint64_t v6 = 0),
        (*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v6, 0) + 8) & 0xFFFFFFFFFFFFFFF8) == (*(void *)(*(void *)(*(void *)(a1 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8)))
  {
    uint64_t v16 = *(void *)(*(void *)(a1 + 72) + 24);
    uint64_t v9 = mlir::DenseElementsAttr::getSplatValue<llvm::APFloat>((mlir::DenseElementsAttr *)&v15, (uint64_t)&v19);
    int v10 = llvm::APFloatBase::IEEEhalf(v9);
    LOBYTE(v17) = 0;
    unint64_t v11 = (llvm::APFloatBase *)llvm::APFloat::convert((uint64_t)&v19, v10, 1, &v17);
    uint64_t v12 = v20[0];
    uint64_t v13 = llvm::APFloatBase::PPCDoubleDouble(v11);
    if (v13 == (void *)v12) {
      llvm::detail::DoubleAPFloat::DoubleAPFloat(v18, v12);
    }
    llvm::detail::IEEEFloat::IEEEFloat((uint64_t)v18, v12);
    if (v13 == (void *)v18[0]) {
      llvm::detail::DoubleAPFloat::makeLargest((llvm::detail::DoubleAPFloat *)v18, 0);
    }
    else {
      llvm::detail::IEEEFloat::makeLargest((llvm::detail::IEEEFloat *)v18, 0);
    }
    uint64_t v14 = mlir::OpBuilder::create<mlir::anec::ClampedRelu,mlir::Value &,llvm::APFloat &,llvm::APFloat>((mlir::Float16Type **)(a2 + 8), *(void *)(a1 + 24), &v16, (uint64_t)&v19, (uint64_t)&v17);
    (*(void (**)(uint64_t, uint64_t, ZinIrHalH13g *))(*(void *)a2 + 32))(a2, a1, v14);
    if (v13 == (void *)v18[0]) {
      llvm::detail::DoubleAPFloat::~DoubleAPFloat((llvm::detail::DoubleAPFloat *)v18);
    }
    else {
      llvm::detail::IEEEFloat::~IEEEFloat((llvm::detail::IEEEFloat *)v18);
    }
    if (v13 == (void *)v20[0]) {
      llvm::detail::DoubleAPFloat::~DoubleAPFloat((llvm::detail::DoubleAPFloat *)v20);
    }
    else {
      llvm::detail::IEEEFloat::~IEEEFloat((llvm::detail::IEEEFloat *)v20);
    }
    return 1;
  }
  else
  {
    uint64_t v19 = "rhs is not a non-broadcasting scalar constant";
    __int16 v21 = 259;
    unint64_t v17 = &v19;
    uint64_t v7 = *(void *)(a2 + 16);
    if (v7)
    {
      uint64_t result = mlir::RewriterBase::Listener::classof(v7);
      if (result) {
        return (*(uint64_t (**)(uint64_t, void, uint64_t (*)(void ****, uint64_t), const char ***))(*(void *)v7 + 64))(v7, *(void *)(a1 + 24), llvm::function_ref<void ()(mlir::Diagnostic &)>::callback_fn<mlir::LogicalResult mlir::RewriterBase::notifyMatchFailure<mlir::anec::ElementwiseMax &>(mlir::anec::ElementwiseMax &,llvm::Twine const&)::{lambda(mlir::Diagnostic &)#1}>, &v17);
      }
    }
    else
    {
      return 0;
    }
  }
  return result;
}

llvm::detail::IEEEFloat *mlir::DenseElementsAttr::getSplatValue<llvm::APFloat>@<X0>(mlir::DenseElementsAttr *a1@<X0>, uint64_t a2@<X8>)
{
  mlir::DenseElementsAttr::tryGetFloatValues(a1, (uint64_t)v8);
  v7[0] = v8[0];
  v7[1] = v8[1];
  _OWORD v7[2] = v9;
  void v7[3] = v10;
  v7[4] = v11;
  void v7[5] = v12;
  uint64_t v3 = (llvm::APFloatBase *)mlir::DenseElementsAttr::IntElementIterator::operator*(v8, (llvm::APInt *)v7);
  uint64_t v4 = (void *)v9;
  char v5 = (llvm::detail::IEEEFloat *)(a2 + 8);
  if (llvm::APFloatBase::PPCDoubleDouble(v3) == v4) {
    llvm::detail::DoubleAPFloat::DoubleAPFloat(v5, (uint64_t)v4);
  }
  uint64_t result = llvm::detail::IEEEFloat::IEEEFloat(v5, v4, (const llvm::APInt **)v7);
  if (DWORD2(v7[0]) >= 0x41)
  {
    uint64_t result = *(llvm::detail::IEEEFloat **)&v7[0];
    if (*(void *)&v7[0]) {
      return (llvm::detail::IEEEFloat *)MEMORY[0x21667D390](*(void *)&v7[0], 0x1000C8000313F17);
    }
  }
  return result;
}

uint64_t mlir::anec::ElementwiseMin::canonicalize(uint64_t a1, uint64_t a2)
{
  uint64_t v22 = *MEMORY[0x263EF8340];
  uint64_t v15 = 0;
  uint64_t v4 = *(const char **)(*(void *)(a1 + 72) + 56);
  unint64_t v17 = (const char **)&v15;
  uint64_t v19 = v4;
  uint64_t DefiningOp = mlir::Value::getDefiningOp((mlir::Value *)&v19);
  if (DefiningOp
    && mlir::detail::constant_op_binder<mlir::DenseFPElementsAttr>::match((unint64_t **)&v17, DefiningOp)
    && mlir::DenseElementsAttr::isSplat((mlir::DenseElementsAttr *)&v15)
    && (*(_DWORD *)(a1 + 36) ? (uint64_t v6 = a1 - 16) : (uint64_t v6 = 0),
        (*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v6, 0) + 8) & 0xFFFFFFFFFFFFFFF8) == (*(void *)(*(void *)(*(void *)(a1 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8)))
  {
    uint64_t v16 = *(void *)(*(void *)(a1 + 72) + 24);
    long long v9 = mlir::DenseElementsAttr::getSplatValue<llvm::APFloat>((mlir::DenseElementsAttr *)&v15, (uint64_t)&v19);
    long long v10 = llvm::APFloatBase::IEEEhalf(v9);
    LOBYTE(v17) = 0;
    long long v11 = (llvm::APFloatBase *)llvm::APFloat::convert((uint64_t)&v19, v10, 1, &v17);
    uint64_t v12 = v20[0];
    uint64_t v13 = llvm::APFloatBase::PPCDoubleDouble(v11);
    if (v13 == (void *)v12) {
      llvm::detail::DoubleAPFloat::DoubleAPFloat(v18, v12);
    }
    llvm::detail::IEEEFloat::IEEEFloat((uint64_t)v18, v12);
    if (v13 == (void *)v18[0]) {
      llvm::detail::DoubleAPFloat::makeLargest((llvm::detail::DoubleAPFloat *)v18, 1);
    }
    else {
      llvm::detail::IEEEFloat::makeLargest((llvm::detail::IEEEFloat *)v18, 1);
    }
    uint64_t v14 = mlir::OpBuilder::create<mlir::anec::ClampedRelu,mlir::Value &,llvm::APFloat,llvm::APFloat&>((mlir::Float16Type **)(a2 + 8), *(void *)(a1 + 24), &v16, (uint64_t)&v17, (uint64_t)&v19);
    (*(void (**)(uint64_t, uint64_t, ZinIrHalH13g *))(*(void *)a2 + 32))(a2, a1, v14);
    if (v13 == (void *)v18[0]) {
      llvm::detail::DoubleAPFloat::~DoubleAPFloat((llvm::detail::DoubleAPFloat *)v18);
    }
    else {
      llvm::detail::IEEEFloat::~IEEEFloat((llvm::detail::IEEEFloat *)v18);
    }
    if (v13 == (void *)v20[0]) {
      llvm::detail::DoubleAPFloat::~DoubleAPFloat((llvm::detail::DoubleAPFloat *)v20);
    }
    else {
      llvm::detail::IEEEFloat::~IEEEFloat((llvm::detail::IEEEFloat *)v20);
    }
    return 1;
  }
  else
  {
    uint64_t v19 = "rhs is not a non-broadcasting scalar constant";
    __int16 v21 = 259;
    unint64_t v17 = &v19;
    uint64_t v7 = *(void *)(a2 + 16);
    if (v7)
    {
      uint64_t result = mlir::RewriterBase::Listener::classof(v7);
      if (result) {
        return (*(uint64_t (**)(uint64_t, void, uint64_t (*)(void ****, uint64_t), const char ***))(*(void *)v7 + 64))(v7, *(void *)(a1 + 24), llvm::function_ref<void ()(mlir::Diagnostic &)>::callback_fn<mlir::LogicalResult mlir::RewriterBase::notifyMatchFailure<mlir::anec::ElementwiseMin &>(mlir::anec::ElementwiseMin &,llvm::Twine const&)::{lambda(mlir::Diagnostic &)#1}>, &v17);
      }
    }
    else
    {
      return 0;
    }
  }
  return result;
}

void mlir::anec::Ceil::addOpToNetwork(mlir::anec **this, mlir::anec::ANECIRNetwork *a2, mlir::anec::ANECIRWeights *a3)
{
  v13[4] = *MEMORY[0x263EF8340];
  uint64_t v3 = *this;
  uint64_t v4 = *(void *)(*((void *)*this + 9) + 24);
  if (*((_DWORD *)*this + 9)) {
    uint64_t v5 = (uint64_t)*this - 16;
  }
  else {
    uint64_t v5 = 0;
  }
  mlir::detail::OpResultImpl::getNextResultAtOffset(v5, 0);
  mlir::anec::computeOpKeyString(v3, &v9);
  uint64_t v10 = v4;
  if (mlir::Value::getDefiningOp((mlir::Value *)&v10))
  {
    uint64_t DefiningOp = (mlir::anec *)mlir::Value::getDefiningOp((mlir::Value *)&v10);
    mlir::anec::computeOpKeyString(DefiningOp, &__p);
  }
  else
  {
    uint64_t v7 = v10;
    if ((~*(_DWORD *)(v10 + 8) & 7) != 0) {
      uint64_t v7 = 0;
    }
    v13[0] = *(unsigned int *)(v7 + 24);
    v11[0] = "__arg";
    void v11[2] = v13;
    __int16 v12 = 3331;
    llvm::Twine::str((llvm::Twine *)v11, &__p);
  }
  operator new();
}

BOOL mlir::anec::ElementwiseAdd::mutateOpForReshapeSwap(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t *a4, uint64_t a5)
{
  if (!a5) {
    return 0;
  }
  if (a5 == 1)
  {
    LODWORD(v5) = *(_DWORD *)a4;
  }
  else
  {
    uint64_t v5 = *a4;
    if (*a4 == a4[1]) {
      return 1;
    }
  }
  uint64_t v7 = (uint64_t *)(*(void *)(*(void *)(*(void *)(*(void *)a1 + 72) + 32 * (v5 ^ 1) + 24) + 8) & 0xFFFFFFFFFFFFFFF8);
  if (!v7) {
    goto LABEL_16;
  }
  uint64_t v8 = *v7;
  unint64_t v9 = mlir::TypeID::get<mlir::ShapedType>();
  unint64_t v10 = *(unsigned int *)(v8 + 16);
  if (!v10) {
    goto LABEL_16;
  }
  long long v11 = *(void **)(v8 + 8);
  __int16 v12 = &v11[2 * v10];
  do
  {
    unint64_t v13 = v10 >> 1;
    uint64_t v14 = &v11[2 * (v10 >> 1)];
    unint64_t v16 = *v14;
    uint64_t v15 = v14 + 2;
    v10 += ~(v10 >> 1);
    if (v16 < v9) {
      long long v11 = v15;
    }
    else {
      unint64_t v10 = v13;
    }
  }
  while (v10);
  if (v11 != v12 && *v11 == v9) {
    uint64_t v17 = v11[1];
  }
  else {
LABEL_16:
  }
    uint64_t v17 = 0;
  v20[0] = v7;
  v20[1] = v17;
  uint64_t Shape = (uint64_t *)mlir::ShapedType::getShape((mlir::ShapedType *)v20);
  return mlir::ShapedType::getNumElements(Shape, v19) == 1;
}

BOOL mlir::anec::getExecutionCostFromInputSize(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = (uint64_t *)(*(void *)(*(void *)(*(void *)(a2 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8);
  if (!v4) {
    goto LABEL_10;
  }
  uint64_t v5 = *v4;
  unint64_t v6 = mlir::TypeID::get<mlir::ShapedType>();
  unint64_t v7 = *(unsigned int *)(v5 + 16);
  if (!v7) {
    goto LABEL_10;
  }
  uint64_t v8 = *(void **)(v5 + 8);
  unint64_t v9 = &v8[2 * v7];
  do
  {
    unint64_t v10 = v7 >> 1;
    long long v11 = &v8[2 * (v7 >> 1)];
    unint64_t v13 = *v11;
    __int16 v12 = v11 + 2;
    v7 += ~(v7 >> 1);
    if (v13 < v6) {
      uint64_t v8 = v12;
    }
    else {
      unint64_t v7 = v10;
    }
  }
  while (v7);
  if (v8 != v9 && *v8 == v6) {
    uint64_t v14 = v8[1];
  }
  else {
LABEL_10:
  }
    uint64_t v14 = 0;
  v19[0] = v4;
  v19[1] = v14;
  uint64_t Shape = (uint64_t *)mlir::ShapedType::getShape((mlir::ShapedType *)v19);
  mlir::ShapedType::getNumElements(Shape, v16);
  uint64_t OperandRange = (void *)mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)v19);
}

float mlir::anec::getPoolExecutionCost<mlir::anec::MaxPool>(uint64_t a1, mlir::Operation *a2)
{
  v21[6] = *MEMORY[0x263EF8340];
  uint64_t v18 = a2;
  uint64_t KsizeAttr = mlir::anec::L2NormPool::getKsizeAttr(&v18);
  mlir::anec::L2NormPool::getStrideAttr(&v18);
  uint64_t v19 = v21;
  uint64_t v20 = 0x600000000;
  mlir::getValues<unsigned long long>(KsizeAttr, (uint64_t)&v19);
  if (v20)
  {
    uint64_t v5 = (v20 - 1) & 0x1FFFFFFFFFFFFFFFLL;
    if (v5)
    {
      uint64_t v6 = v5 + 1;
      uint64_t v7 = (v5 + 1) & 0x3FFFFFFFFFFFFFFELL;
      uint64_t v8 = (uint64_t *)((char *)v19 + 8 * v7);
      unint64_t v9 = (char *)v19 + 8;
      uint64_t v10 = 1;
      uint64_t v11 = v7;
      uint64_t v12 = 1;
      do
      {
        v10 *= *(v9 - 1);
        v12 *= *v9;
        v9 += 2;
        v11 -= 2;
      }
      while (v11);
      uint64_t v13 = v12 * v10;
      if (v6 == v7) {
        goto LABEL_10;
      }
    }
    else
    {
      uint64_t v13 = 1;
      uint64_t v8 = (uint64_t *)v19;
    }
    do
    {
      uint64_t v14 = *v8++;
      v13 *= v14;
    }
    while (v8 != (uint64_t *)((char *)v19 + 8 * v20));
  }
LABEL_10:
  float v16 = v15;
  if (v19 != v21) {
    free(v19);
  }
  return v16;
}

float mlir::anec::getPoolExecutionCost<mlir::anec::AveragePool>(uint64_t a1, mlir::Operation *a2)
{
  v21[6] = *MEMORY[0x263EF8340];
  uint64_t v18 = a2;
  uint64_t KsizeAttr = mlir::anec::AveragePool::getKsizeAttr(&v18);
  mlir::anec::AveragePool::getStrideAttr(&v18);
  uint64_t v19 = v21;
  uint64_t v20 = 0x600000000;
  mlir::getValues<unsigned long long>(KsizeAttr, (uint64_t)&v19);
  if (v20)
  {
    uint64_t v5 = (v20 - 1) & 0x1FFFFFFFFFFFFFFFLL;
    if (v5)
    {
      uint64_t v6 = v5 + 1;
      uint64_t v7 = (v5 + 1) & 0x3FFFFFFFFFFFFFFELL;
      uint64_t v8 = (uint64_t *)((char *)v19 + 8 * v7);
      unint64_t v9 = (char *)v19 + 8;
      uint64_t v10 = 1;
      uint64_t v11 = v7;
      uint64_t v12 = 1;
      do
      {
        v10 *= *(v9 - 1);
        v12 *= *v9;
        v9 += 2;
        v11 -= 2;
      }
      while (v11);
      uint64_t v13 = v12 * v10;
      if (v6 == v7) {
        goto LABEL_10;
      }
    }
    else
    {
      uint64_t v13 = 1;
      uint64_t v8 = (uint64_t *)v19;
    }
    do
    {
      uint64_t v14 = *v8++;
      v13 *= v14;
    }
    while (v8 != (uint64_t *)((char *)v19 + 8 * v20));
  }
LABEL_10:
  float v16 = v15;
  if (v19 != v21) {
    free(v19);
  }
  return v16;
}

BOOL mlir::anec::anonymous namespace'::getElementWiseOpExecutionCost(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = (uint64_t *)(*(void *)(a2 - 8) & 0xFFFFFFFFFFFFFFF8);
  if (!v4) {
    goto LABEL_10;
  }
  uint64_t v5 = *v4;
  unint64_t v6 = mlir::TypeID::get<mlir::ShapedType>();
  unint64_t v7 = *(unsigned int *)(v5 + 16);
  if (!v7) {
    goto LABEL_10;
  }
  uint64_t v8 = *(void **)(v5 + 8);
  unint64_t v9 = &v8[2 * v7];
  do
  {
    unint64_t v10 = v7 >> 1;
    uint64_t v11 = &v8[2 * (v7 >> 1)];
    unint64_t v13 = *v11;
    uint64_t v12 = v11 + 2;
    v7 += ~(v7 >> 1);
    if (v13 < v6) {
      uint64_t v8 = v12;
    }
    else {
      unint64_t v7 = v10;
    }
  }
  while (v7);
  if (v8 != v9 && *v8 == v6) {
    uint64_t v14 = v8[1];
  }
  else {
LABEL_10:
  }
    uint64_t v14 = 0;
  v19[0] = v4;
  v19[1] = v14;
  uint64_t Shape = (uint64_t *)mlir::ShapedType::getShape((mlir::ShapedType *)v19);
  mlir::ShapedType::getNumElements(Shape, v16);
  uint64_t OperandRange = (void *)mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)v19);
}

float mlir::anec::InstanceNorm::getExecutionCost(uint64_t *a1, uint64_t a2)
{
  uint64_t v4 = (void *)(*(void *)(*(void *)(*(void *)(*a1 + 72) + 24) + 8) & 0xFFFFFFFFFFFFFFF8);
  if (!v4) {
    goto LABEL_10;
  }
  uint64_t v5 = *v4;
  unint64_t v6 = mlir::TypeID::get<mlir::ShapedType>();
  unint64_t v7 = *(unsigned int *)(v5 + 16);
  if (!v7) {
    goto LABEL_10;
  }
  uint64_t v8 = *(void **)(v5 + 8);
  unint64_t v9 = &v8[2 * v7];
  do
  {
    unint64_t v10 = v7 >> 1;
    uint64_t v11 = &v8[2 * (v7 >> 1)];
    unint64_t v13 = *v11;
    uint64_t v12 = v11 + 2;
    v7 += ~(v7 >> 1);
    if (v13 < v6) {
      uint64_t v8 = v12;
    }
    else {
      unint64_t v7 = v10;
    }
  }
  while (v7);
  if (v8 != v9 && *v8 == v6) {
    uint64_t v14 = v8[1];
  }
  else {
LABEL_10:
  }
    uint64_t v14 = 0;
  uint64_t v50 = v4;
  uint64_t v51 = v14;
  uint64_t OperandRange = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&v50);
  IntOrFloatBitint Width = mlir::Type::getIntOrFloatBitWidth((mlir::Type *)&OperandRange);
  uint64_t Shape = (uint64_t *)mlir::ShapedType::getShape((mlir::ShapedType *)&v50);
  uint64_t NumElements = mlir::ShapedType::getNumElements(Shape, v17);
  if (*(_DWORD *)(*a1 + 36)) {
    uint64_t v19 = *a1 - 16;
  }
  else {
    uint64_t v19 = 0;
  }
  uint64_t v20 = (void *)(*(void *)(mlir::detail::OpResultImpl::getNextResultAtOffset(v19, 0) + 8) & 0xFFFFFFFFFFFFFFF8);
  if (!v20) {
    goto LABEL_23;
  }
  uint64_t v21 = *v20;
  unint64_t v22 = mlir::TypeID::get<mlir::ShapedType>();
  unint64_t v23 = *(unsigned int *)(v21 + 16);
  if (!v23) {
    goto LABEL_23;
  }
  uint64_t v24 = *(void **)(v21 + 8);
  unint64_t v25 = &v24[2 * v23];
  do
  {
    unint64_t v26 = v23 >> 1;
    uint64_t v27 = &v24[2 * (v23 >> 1)];
    unint64_t v29 = *v27;
    uint64_t v28 = v27 + 2;
    v23 += ~(v23 >> 1);
    if (v29 < v22) {
      uint64_t v24 = v28;
    }
    else {
      unint64_t v23 = v26;
    }
  }
  while (v23);
  if (v24 != v25 && *v24 == v22) {
    uint64_t v30 = v24[1];
  }
  else {
LABEL_23:
  }
    uint64_t v30 = 0;
  uint64_t v31 = NumElements * (IntOrFloatBitWidth >> 3);
  float v32 = (float)v31;
  uint64_t v50 = v20;
  uint64_t v51 = v30;
  uint64_t v33 = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&v50);
  unint64_t v34 = (uint64_t *)mlir::ShapedType::getShape((mlir::ShapedType *)&v50);
  float v36 = (float)mlir::ShapedType::getNumElements(v34, v35);
  if (v31 <= 0x200000) {
    float v32 = 0.0;
  }
  uint64_t OperandRange = v33;
  float v37 = *(float *)(a2 + 40) * 1.0e12;
  BOOL isF16 = mlir::Type::isF16((mlir::Type *)&OperandRange);
  float v39 = v37 + v37;
  if (isF16) {
    float v39 = v37;
  }
  float v40 = v36 / v39;
  float v41 = *(float *)(a2 + 40);
  if (v40 >= (float)(v32 / (float)(*(float *)(a2 + 44) * 1000000000.0))) {
    float v42 = v40;
  }
  else {
    float v42 = v32 / (float)(*(float *)(a2 + 44) * 1000000000.0);
  }
  uint64_t OperandRange = v33;
  float v43 = v41 * 1.0e12;
  BOOL v44 = mlir::Type::isF16((mlir::Type *)&OperandRange);
  float v45 = v43 + v43;
  if (v44) {
    float v45 = v43;
  }
  float v46 = v36 / v45;
  if (v46 < (float)(v32 / (float)(*(float *)(a2 + 44) * 1000000000.0))) {
    float v46 = v32 / (float)(*(float *)(a2 + 44) * 1000000000.0);
  }
  float v47 = v42 + v46;
  return v48 + v47;
}

void mlir::anec::ElementwiseAbs::addOpToNetwork(mlir::anec::_anonymous_namespace_ **this, mlir::anec::ANECIRNetwork *a2, mlir::anec::ANECIRWeights *a3)
{
}

unint64_t mlir::anec::Rsqrt::fold(mlir::Operation **a1, uint64_t a2)
{
  v42[3] = *MEMORY[0x263EF8340];
  uint64_t v3 = **(uint64_t ***)(a2 + 40);
  if (!v3)
  {
    float v39 = 0;
    uint64_t v40 = 0;
    return 0;
  }
  float v39 = llvm::DefaultDoCastIfPossible<mlir::ElementsAttr,mlir::Attribute const,llvm::CastInfo<mlir::ElementsAttr,mlir::Attribute const,void>>::doCastIfPossible(v3);
  uint64_t v40 = v4;
  if (!v39) {
    return 0;
  }
  mlir::mps::CPUNDArray::CPUNDArray(v37);
  Type = (void *)mlir::ElementsAttr::getType((mlir::ElementsAttr *)&v39);
  unint64_t v6 = Type;
  if (!Type) {
    goto LABEL_12;
  }
  uint64_t v7 = *Type;
  unint64_t v8 = mlir::TypeID::get<mlir::ShapedType>();
  unint64_t v9 = *(unsigned int *)(v7 + 16);
  if (!v9) {
    goto LABEL_12;
  }
  unint64_t v10 = *(void **)(v7 + 8);
  uint64_t v11 = &v10[2 * v9];
  do
  {
    unint64_t v12 = v9 >> 1;
    unint64_t v13 = &v10[2 * (v9 >> 1)];
    unint64_t v15 = *v13;
    uint64_t v14 = v13 + 2;
    v9 += ~(v9 >> 1);
    if (v15 < v8) {
      unint64_t v10 = v14;
    }
    else {
      unint64_t v9 = v12;
    }
  }
  while (v9);
  if (v10 != v11 && *v10 == v8) {
    uint64_t v16 = v10[1];
  }
  else {
LABEL_12:
  }
    uint64_t v16 = 0;
  mlir::mps::CPUNDArray::CPUNDArray(v36, v6, v16, 0);
  v35[0] = mlir::anec::BatchToSpace::getFactorsAttr(a1);
  mlir::FloatAttr::getValue((mlir::FloatAttr *)v35, (uint64_t)&v41);
  double v17 = llvm::APFloat::convertToDouble((llvm::APFloat *)&v41);
  uint64_t v18 = (llvm::APFloatBase *)mlir::mps::CPUNDArrayArithmeticUnaryKernel::CPUNDArrayArithmeticUnaryKernel((uint64_t)v35, 6, v17);
  uint64_t v19 = (void *)v42[0];
  if (llvm::APFloatBase::PPCDoubleDouble(v18) == v19) {
    llvm::detail::DoubleAPFloat::~DoubleAPFloat((llvm::detail::DoubleAPFloat *)v42);
  }
  else {
    llvm::detail::IEEEFloat::~IEEEFloat((llvm::detail::IEEEFloat *)v42);
  }
  uint64_t v21 = operator new(8uLL);
  float v41 = v21;
  void *v21 = v37;
  v42[0] = v21 + 1;
  v42[1] = v21 + 1;
  unint64_t v22 = operator new(8uLL);
  float v32 = v22;
  *unint64_t v22 = v36;
  uint64_t v33 = v22 + 1;
  unint64_t v34 = v22 + 1;
  unint64_t v23 = operator new(8uLL);
  unint64_t v29 = v23;
  *unint64_t v23 = 0;
  uint64_t v30 = v23 + 1;
  uint64_t v31 = v23 + 1;
  uint64_t v24 = operator new(8uLL);
  std::string __p = v24;
  *uint64_t v24 = 0;
  uint64_t v27 = v24 + 1;
  uint64_t v28 = v24 + 1;
  mlir::mps::CPUNDArrayKernel::cpuTilingEngine((uint64_t)v35, (uint64_t *)&v41, (uint64_t **)&v32, (uint64_t)&v29, (uint64_t)&__p, 0, v38, (uint64_t)v35);
  if (__p)
  {
    uint64_t v27 = __p;
    operator delete(__p);
  }
  if (v29)
  {
    uint64_t v30 = v29;
    operator delete(v29);
  }
  if (v32)
  {
    uint64_t v33 = v32;
    operator delete(v32);
  }
  if (v41)
  {
    v42[0] = v41;
    operator delete(v41);
  }
  unint64_t v20 = (unint64_t)mlir::mps::CPUNDArray::getElementsAttr((mlir::mps::CPUNDArray *)v36, 0, 0) & 0xFFFFFFFFFFFFFFFBLL;
  mlir::mps::CPUNDArray::~CPUNDArray((mlir::mps::CPUNDArray *)v36);
  mlir::mps::CPUNDArray::~CPUNDArray((mlir::mps::CPUNDArray *)v37);
  return v20;
}

uint64_t mlir::anec::inferPoolOpReturnTypes(uint64_t a1, char a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
  v59[22] = *MEMORY[0x263EF8340];
  uint64_t v14 = (void *)mlir::TypeRange::dereference_iterator(a7, 0);
  unint64_t v15 = v14;
  if (!v14) {
    goto LABEL_10;
  }
  uint64_t v16 = *v14;
  unint64_t v17 = mlir::TypeID::get<mlir::ShapedType>();
  unint64_t v18 = *(unsigned int *)(v16 + 16);
  if (!v18) {
    goto LABEL_10;
  }
  uint64_t v19 = *(void **)(v16 + 8);
  unint64_t v20 = &v19[2 * v18];
  do
  {
    unint64_t v21 = v18 >> 1;
    unint64_t v22 = &v19[2 * (v18 >> 1)];
    unint64_t v24 = *v22;
    unint64_t v23 = v22 + 2;
    v18 += ~(v18 >> 1);
    if (v24 < v17) {
      uint64_t v19 = v23;
    }
    else {
      unint64_t v18 = v21;
    }
  }
  while (v18);
  if (v19 != v20 && *v19 == v17) {
    uint64_t v25 = v19[1];
  }
  else {
LABEL_10:
  }
    uint64_t v25 = 0;
  v47[0] = v15;
  v47[1] = v25;
  mlir::ShapedType::getShape((mlir::ShapedType *)v47);
  if (v26)
  {
    uint64_t Shape = (uint64_t *)mlir::ShapedType::getShape((mlir::ShapedType *)v47);
    char v57 = v59;
    uint64_t v58 = 0x600000000;
    mlir::getValues<unsigned long long>(a4, (uint64_t)&v57);
    v55[0] = v56;
    v55[1] = (void *)0x600000000;
    mlir::getValues<unsigned long long>(a5, (uint64_t)v55);
    v53[0] = v54;
    v53[1] = (void *)0x600000000;
    mlir::getValues<unsigned long long>(a6, (uint64_t)v53);
    mlir::ShapedType::getShape((mlir::ShapedType *)v47);
    uint64_t v29 = v28;
    mlir::ShapedType::getShape((mlir::ShapedType *)v47);
    uint64_t v31 = v30;
    mlir::ShapedType::getShape((mlir::ShapedType *)v47);
    uint64_t v33 = v32;
    mlir::ShapedType::getShape((mlir::ShapedType *)v47);
    uint64_t v35 = v34;
    mlir::ShapedType::getShape((mlir::ShapedType *)v47);
    unint64_t v36 = (unint64_t)(*(void *)v57
                           + Shape[v35 - 2]
                           + *((void *)v57 + 1)
                           - *(void *)v55[0]
                           + *(void *)v53[0])
        / *(void *)v53[0];
    uint64_t v38 = Shape[v33 - 3];
    unint64_t v39 = (unint64_t)(*((void *)v57 + 2)
                           + Shape[v37 - 1]
                           + *((void *)v57 + 3)
                           - *((void *)v55[0] + 1)
                           + *((void *)v53[0] + 1))
        / *((void *)v53[0] + 1);
    if (v29 == 5)
    {
      unint64_t v40 = (unint64_t)(*((void *)v57 + 4)
                             + Shape[v31 - 4]
                             + *((void *)v57 + 5)
                             - *((void *)v55[0] + 2)
                             + *((void *)v53[0] + 2))
          / *((void *)v53[0] + 2);
      uint64_t v48 = *Shape;
      unint64_t v49 = v40;
      unint64_t v50 = v38;
      unint64_t v51 = v36;
      unint64_t v52 = v39;
      uint64_t OperandRange = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)v47);
      uint64_t v42 = 5;
    }
    else
    {
      uint64_t v48 = *Shape;
      unint64_t v49 = v38;
      unint64_t v50 = v36;
      unint64_t v51 = v39;
      uint64_t OperandRange = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)v47);
      uint64_t v42 = 4;
    }
    uint64_t v44 = mlir::MemRefType::get(&v48, (mlir::AffineMap *)v42, OperandRange, 0, 0, 0);
    uint64_t v45 = *(unsigned int *)(a9 + 8);
    if (v45 >= *(_DWORD *)(a9 + 12))
    {
      llvm::SmallVectorBase<unsigned int>::grow_pod(a9, (void *)(a9 + 16), v45 + 1, 8);
      LODWORD(v45) = *(_DWORD *)(a9 + 8);
    }
    *(void *)(*(void *)a9 + 8 * v45) = v44;
    ++*(_DWORD *)(a9 + 8);
    if (v53[0] != v54) {
      free(v53[0]);
    }
    if (v55[0] != v56) {
      free(v55[0]);
    }
    if (v57 != v59) {
      free(v57);
    }
    return 1;
  }
  else if (a2)
  {
    mlir::emitError(a1, (uint64_t)&v57);
    if (v57) {
      mlir::Diagnostic::operator<<((uint64_t)&v58, "input must be a rank 4 tensor of shape [N, Cin, H, W]or rank 5 tensor of shape [N, D, Cin, H, W]");
    }
    uint64_t v43 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v57);
    if (v57) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v57);
    }
    std::__optional_destruct_base<mlir::Diagnostic,false>::~__optional_destruct_base[abi:nn180100]((uint64_t)&v58);
  }
  else
  {
    return 0;
  }
  return v43;
}

uint64_t mlir::anec::MaxPool::inferPromotedReturnTypes(mlir::UnknownLoc *this, mlir::MLIRContext *a2, char a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11)
{
  void v43[2] = *MEMORY[0x263EF8340];
  uint64_t v36 = a6;
  LOBYTE(v37) = 0;
  char v38 = 0;
  uint64_t v39 = a7;
  uint64_t v40 = a8;
  if (a6)
  {
    uint64_t Context = mlir::Attribute::getContext((mlir::Attribute *)&v36);
    if (v38) {
      char v38 = 0;
    }
    mlir::OperationName::OperationName(&v37, "anec.max_pool", 13, Context);
    char v38 = 1;
  }
  uint64_t v41 = a4;
  uint64_t v42 = a5;
  uint64_t v17 = mlir::UnknownLoc::get(this, a2);
  if (a3) {
    uint64_t v18 = (uint64_t)a2;
  }
  else {
    uint64_t v18 = v17;
  }
  if (!mlir::anec::MaxPoolAdaptor::verify(&v36, v18)) {
    return 0;
  }
  v43[0] = v41;
  v43[1] = 0;
  mlir::ValueRange::dereference_iterator(v43, 0);
  uint64_t v19 = (MirInfoChannelAssignment *)(mlir::AffineMapAttr::getValue((mlir::AffineMapAttr *)&v36) + 16);
  uint64_t v20 = mlir::DictionaryAttr::end((mlir::DictionaryAttr *)&v36);
  unint64_t v21 = mlir::impl::findAttrSorted<mlir::NamedAttribute const*>(v19, (MirInfoChannelAssignment *)(v20 - 16), *(void *)(*(void *)(v37 + 96) + 8));
  uint64_t v22 = 0;
  if (v23) {
    uint64_t v22 = *((void *)v21 + 1);
  }
  uint64_t Value = (MirInfoChannelAssignment *)mlir::AffineMapAttr::getValue((mlir::AffineMapAttr *)&v36);
  uint64_t v25 = mlir::DictionaryAttr::end((mlir::DictionaryAttr *)&v36);
  uint64_t v26 = mlir::impl::findAttrSorted<mlir::NamedAttribute const*>(Value, (MirInfoChannelAssignment *)(v25 - 32), **(void **)(v37 + 96));
  if (v27) {
    uint64_t v28 = *((void *)v26 + 1);
  }
  else {
    uint64_t v28 = 0;
  }
  uint64_t v30 = (MirInfoChannelAssignment *)(mlir::AffineMapAttr::getValue((mlir::AffineMapAttr *)&v36) + 32);
  uint64_t v31 = (MirInfoChannelAssignment *)mlir::DictionaryAttr::end((mlir::DictionaryAttr *)&v36);
  uint64_t v32 = mlir::impl::findAttrSorted<mlir::NamedAttribute const*>(v30, v31, *(void *)(*(void *)(v37 + 96) + 16));
  if (v34) {
    uint64_t v35 = *((void *)v32 + 1);
  }
  else {
    uint64_t v35 = 0;
  }
  return mlir::anec::inferPoolOpReturnTypes((uint64_t)a2, a3, v33, v22, v28, v35, a9, a10, a11);
}

uint64_t mlir::anec::MaxPoolAdaptor::verify(uint64_t *a1, uint64_t a2)
{
  void v59[23] = *MEMORY[0x263EF8340];
  uint64_t v55 = *a1;
  for (uint64_t i = (uint64_t *)mlir::AffineMapAttr::getValue((mlir::AffineMapAttr *)&v55); ; i += 2)
  {
    if (i == (uint64_t *)mlir::DictionaryAttr::end((mlir::DictionaryAttr *)&v55))
    {
      uint64_t v5 = "'anec.max_pool' op requires attribute 'ksize'";
      goto LABEL_53;
    }
    if (**(void **)(a1[1] + 96) == MirInfoChannelAssignment::GetNumNeededNEs((MirInfoChannelAssignment *)i)) {
      break;
    }
  }
  unint64_t v6 = (uint64_t *)i[1];
  uint64_t v54 = v6;
  while (1)
  {
    if (i == (uint64_t *)mlir::DictionaryAttr::end((mlir::DictionaryAttr *)&v55))
    {
      uint64_t v5 = "'anec.max_pool' op requires attribute 'padding'";
      goto LABEL_53;
    }
    if (*(void *)(*(void *)(a1[1] + 96) + 8) == MirInfoChannelAssignment::GetNumNeededNEs((MirInfoChannelAssignment *)i)) {
      break;
    }
    i += 2;
  }
  uint64_t v7 = (uint64_t *)i[1];
  unint64_t v50 = v7;
  while (1)
  {
    if (i == (uint64_t *)mlir::DictionaryAttr::end((mlir::DictionaryAttr *)&v55))
    {
      uint64_t v5 = "'anec.max_pool' op requires attribute 'stride'";
      goto LABEL_53;
    }
    if (*(void *)(*(void *)(a1[1] + 96) + 16) == MirInfoChannelAssignment::GetNumNeededNEs((MirInfoChannelAssignment *)i)) {
      break;
    }
    i += 2;
  }
  unint64_t v8 = (uint64_t *)i[1];
  if (!v8) {
    goto LABEL_62;
  }
  if (!mlir::DenseIntElementsAttr::classof(i[1])) {
    goto LABEL_51;
  }
  uint64_t v9 = *v8;
  unint64_t v10 = mlir::TypeID::get<mlir::ElementsAttr>();
  unint64_t v11 = *(unsigned int *)(v9 + 16);
  if (!v11) {
    goto LABEL_26;
  }
  unint64_t v12 = *(void **)(v9 + 8);
  unint64_t v13 = &v12[2 * v11];
  do
  {
    unint64_t v14 = v11 >> 1;
    unint64_t v15 = &v12[2 * (v11 >> 1)];
    unint64_t v17 = *v15;
    uint64_t v16 = v15 + 2;
    v11 += ~(v11 >> 1);
    if (v17 < v10) {
      unint64_t v12 = v16;
    }
    else {
      unint64_t v11 = v14;
    }
  }
  while (v11);
  if (v12 != v13 && *v12 == v10) {
    uint64_t v18 = v12[1];
  }
  else {
LABEL_26:
  }
    uint64_t v18 = 0;
  unint64_t v51 = v8;
  uint64_t v52 = v18;
  Type = (uint64_t *)mlir::ElementsAttr::getType((mlir::ElementsAttr *)&v51);
  uint64_t v20 = Type;
  if (!Type) {
    goto LABEL_36;
  }
  uint64_t v21 = *Type;
  unint64_t v22 = mlir::TypeID::get<mlir::ShapedType>();
  unint64_t v23 = *(unsigned int *)(v21 + 16);
  if (!v23) {
    goto LABEL_36;
  }
  unint64_t v24 = *(void **)(v21 + 8);
  uint64_t v25 = &v24[2 * v23];
  do
  {
    unint64_t v26 = v23 >> 1;
    char v27 = &v24[2 * (v23 >> 1)];
    unint64_t v29 = *v27;
    uint64_t v28 = v27 + 2;
    v23 += ~(v23 >> 1);
    if (v29 < v22) {
      unint64_t v24 = v28;
    }
    else {
      unint64_t v23 = v26;
    }
  }
  while (v23);
  if (v24 != v25 && *v24 == v22) {
    uint64_t v30 = v24[1];
  }
  else {
LABEL_36:
  }
    uint64_t v30 = 0;
  uint64_t v58 = v20;
  v59[0] = v30;
  uint64_t Shape = (uint64_t **)mlir::ShapedType::getShape((mlir::ShapedType *)&v58);
  uint64_t v57 = 3;
  if (v32 != 1) {
    goto LABEL_51;
  }
  if (*Shape == (uint64_t *)v57
    && (uint64_t OperandRange = (uint64_t)v8,
        uint64_t Value = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&OperandRange),
        uint64_t v49 = v33,
        uint64_t v56 = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&Value),
        mlir::Type::isUnsignedInteger((mlir::Type *)&v56, 64)))
  {
LABEL_62:
    if (!v7) {
      goto LABEL_63;
    }
    if (mlir::DenseIntElementsAttr::classof((uint64_t)v7))
    {
      unint64_t v51 = mlir::Attribute::cast<mlir::ElementsAttr>(&v50);
      uint64_t v52 = v34;
      uint64_t v57 = mlir::ElementsAttr::getType((mlir::ElementsAttr *)&v51);
      uint64_t v58 = mlir::Type::cast<mlir::ShapedType>((uint64_t **)&v57);
      v59[0] = v35;
      uint64_t v36 = (void *)mlir::ShapedType::getShape((mlir::ShapedType *)&v58);
      uint64_t v56 = 6;
      if (v37 == 1 && *v36 == v56)
      {
        float v46 = v50;
        uint64_t Value = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v46);
        uint64_t v49 = v38;
        uint64_t OperandRange = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&Value);
        if (mlir::Type::isUnsignedInteger((mlir::Type *)&OperandRange, 64))
        {
LABEL_63:
          if (!v6) {
            return 1;
          }
          if (!mlir::DenseIntElementsAttr::classof((uint64_t)v6)) {
            goto LABEL_57;
          }
          unint64_t v51 = mlir::Attribute::cast<mlir::ElementsAttr>(&v54);
          uint64_t v52 = v39;
          uint64_t v57 = mlir::ElementsAttr::getType((mlir::ElementsAttr *)&v51);
          uint64_t v58 = mlir::Type::cast<mlir::ShapedType>((uint64_t **)&v57);
          v59[0] = v40;
          uint64_t v41 = (void *)mlir::ShapedType::getShape((mlir::ShapedType *)&v58);
          uint64_t v56 = 3;
          if (v42 != 1) {
            goto LABEL_57;
          }
          if (*v41 == v56)
          {
            float v46 = v54;
            uint64_t Value = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v46);
            uint64_t v49 = v43;
            uint64_t OperandRange = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&Value);
            if (mlir::Type::isUnsignedInteger((mlir::Type *)&OperandRange, 64)) {
              return 1;
            }
          }
LABEL_57:
          unint64_t v51 = (uint64_t *)"'anec.max_pool' op attribute 'ksize' failed to satisfy constraint: ui64 elements attribute of shape {3}";
          __int16 v53 = 259;
          mlir::emitError(a2, (uint64_t)&v51, (uint64_t)&v58);
          uint64_t v44 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v58);
          mlir::InFlightDiagnostic::~InFlightDiagnostic((mlir::InFlightDiagnostic *)&v58);
          return v44;
        }
      }
    }
    uint64_t v5 = "'anec.max_pool' op attribute 'padding' failed to satisfy constraint: ui64 elements attribute of shape {6}";
  }
  else
  {
LABEL_51:
    uint64_t v5 = "'anec.max_pool' op attribute 'stride' failed to satisfy constraint: ui64 elements attribute of shape {3}";
  }
LABEL_53:
  unint64_t v51 = (uint64_t *)v5;
  __int16 v53 = 259;
  mlir::emitError(a2, (uint64_t)&v51, (uint64_t)&v58);
  uint64_t v44 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v58);
  if (v58) {
    mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v58);
  }
  std::__optional_destruct_base<mlir::Diagnostic,false>::~__optional_destruct_base[abi:nn180100]((uint64_t)v59);
  return v44;
}

uint64_t mlir::anec::AveragePool::inferPromotedReturnTypes(mlir::UnknownLoc *this, mlir::MLIRContext *a2, char a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11)
{
  void v43[2] = *MEMORY[0x263EF8340];
  uint64_t v36 = a6;
  LOBYTE(v37) = 0;
  char v38 = 0;
  uint64_t v39 = a7;
  uint64_t v40 = a8;
  if (a6)
  {
    uint64_t Context = mlir::Attribute::getContext((mlir::Attribute *)&v36);
    if (v38) {
      char v38 = 0;
    }
    mlir::OperationName::OperationName(&v37, "anec.average_pool", 17, Context);
    char v38 = 1;
  }
  uint64_t v41 = a4;
  uint64_t v42 = a5;
  uint64_t v17 = mlir::UnknownLoc::get(this, a2);
  if (a3) {
    uint64_t v18 = (uint64_t)a2;
  }
  else {
    uint64_t v18 = v17;
  }
  if (!mlir::anec::AveragePoolAdaptor::verify(&v36, v18)) {
    return 0;
  }
  v43[0] = v41;
  v43[1] = 0;
  mlir::ValueRange::dereference_iterator(v43, 0);
  uint64_t v19 = (MirInfoChannelAssignment *)(mlir::AffineMapAttr::getValue((mlir::AffineMapAttr *)&v36) + 16);
  uint64_t v20 = mlir::DictionaryAttr::end((mlir::DictionaryAttr *)&v36);
  uint64_t v21 = mlir::impl::findAttrSorted<mlir::NamedAttribute const*>(v19, (MirInfoChannelAssignment *)(v20 - 16), *(void *)(*(void *)(v37 + 96) + 16));
  uint64_t v22 = 0;
  if (v23) {
    uint64_t v22 = *((void *)v21 + 1);
  }
  uint64_t Value = (MirInfoChannelAssignment *)mlir::AffineMapAttr::getValue((mlir::AffineMapAttr *)&v36);
  uint64_t v25 = mlir::DictionaryAttr::end((mlir::DictionaryAttr *)&v36);
  unint64_t v26 = mlir::impl::findAttrSorted<mlir::NamedAttribute const*>(Value, (MirInfoChannelAssignment *)(v25 - 32), *(void *)(*(void *)(v37 + 96) + 8));
  if (v27) {
    uint64_t v28 = *((void *)v26 + 1);
  }
  else {
    uint64_t v28 = 0;
  }
  uint64_t v30 = (MirInfoChannelAssignment *)(mlir::AffineMapAttr::getValue((mlir::AffineMapAttr *)&v36) + 32);
  uint64_t v31 = (MirInfoChannelAssignment *)mlir::DictionaryAttr::end((mlir::DictionaryAttr *)&v36);
  uint64_t v32 = mlir::impl::findAttrSorted<mlir::NamedAttribute const*>(v30, v31, *(void *)(*(void *)(v37 + 96) + 24));
  if (v34) {
    uint64_t v35 = *((void *)v32 + 1);
  }
  else {
    uint64_t v35 = 0;
  }
  return mlir::anec::inferPoolOpReturnTypes((uint64_t)a2, a3, v33, v22, v28, v35, a9, a10, a11);
}

uint64_t mlir::anec::AveragePoolAdaptor::verify(uint64_t *a1, uint64_t a2)
{
  v61[23] = *MEMORY[0x263EF8340];
  uint64_t v57 = *a1;
  uint64_t Value = (uint64_t *)mlir::AffineMapAttr::getValue((mlir::AffineMapAttr *)&v57);
  if (Value == (uint64_t *)mlir::DictionaryAttr::end((mlir::DictionaryAttr *)&v57))
  {
LABEL_7:
    unint64_t v6 = "'anec.average_pool' op requires attribute 'ksize'";
LABEL_57:
    __int16 v53 = (uint64_t *)v6;
    __int16 v55 = 259;
    mlir::emitError(a2, (uint64_t)&v53, (uint64_t)&v60);
    uint64_t v46 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v60);
    if (v60) {
      mlir::InFlightDiagnostic::report((mlir::InFlightDiagnostic *)&v60);
    }
    std::__optional_destruct_base<mlir::Diagnostic,false>::~__optional_destruct_base[abi:nn180100]((uint64_t)v61);
    return v46;
  }
  uint64_t v5 = 0;
  while (*(void *)(*(void *)(a1[1] + 96) + 8) != MirInfoChannelAssignment::GetNumNeededNEs((MirInfoChannelAssignment *)Value))
  {
    if (**(void **)(a1[1] + 96) == MirInfoChannelAssignment::GetNumNeededNEs((MirInfoChannelAssignment *)Value)) {
      uint64_t v5 = Value[1];
    }
    Value += 2;
    if (Value == (uint64_t *)mlir::DictionaryAttr::end((mlir::DictionaryAttr *)&v57)) {
      goto LABEL_7;
    }
  }
  uint64_t v7 = (uint64_t *)Value[1];
  uint64_t v56 = v7;
  while (1)
  {
    if (Value == (uint64_t *)mlir::DictionaryAttr::end((mlir::DictionaryAttr *)&v57))
    {
      unint64_t v6 = "'anec.average_pool' op requires attribute 'padding'";
      goto LABEL_57;
    }
    if (*(void *)(*(void *)(a1[1] + 96) + 16) == MirInfoChannelAssignment::GetNumNeededNEs((MirInfoChannelAssignment *)Value)) {
      break;
    }
    Value += 2;
  }
  unint64_t v8 = (uint64_t *)Value[1];
  uint64_t v52 = v8;
  while (1)
  {
    if (Value == (uint64_t *)mlir::DictionaryAttr::end((mlir::DictionaryAttr *)&v57))
    {
      unint64_t v6 = "'anec.average_pool' op requires attribute 'stride'";
      goto LABEL_57;
    }
    if (*(void *)(*(void *)(a1[1] + 96) + 24) == MirInfoChannelAssignment::GetNumNeededNEs((MirInfoChannelAssignment *)Value)) {
      break;
    }
    Value += 2;
  }
  uint64_t v9 = (uint64_t *)Value[1];
  if (v9)
  {
    if (!mlir::DenseIntElementsAttr::classof(Value[1])) {
      goto LABEL_55;
    }
    uint64_t v10 = *v9;
    unint64_t v11 = mlir::TypeID::get<mlir::ElementsAttr>();
    unint64_t v12 = *(unsigned int *)(v10 + 16);
    if (!v12) {
      goto LABEL_28;
    }
    unint64_t v13 = *(void **)(v10 + 8);
    unint64_t v14 = &v13[2 * v12];
    do
    {
      unint64_t v15 = v12 >> 1;
      uint64_t v16 = &v13[2 * (v12 >> 1)];
      unint64_t v18 = *v16;
      uint64_t v17 = v16 + 2;
      v12 += ~(v12 >> 1);
      if (v18 < v11) {
        unint64_t v13 = v17;
      }
      else {
        unint64_t v12 = v15;
      }
    }
    while (v12);
    if (v13 != v14 && *v13 == v11) {
      uint64_t v19 = v13[1];
    }
    else {
LABEL_28:
    }
      uint64_t v19 = 0;
    __int16 v53 = v9;
    uint64_t v54 = v19;
    Type = (uint64_t *)mlir::ElementsAttr::getType((mlir::ElementsAttr *)&v53);
    uint64_t v21 = Type;
    if (!Type) {
      goto LABEL_38;
    }
    uint64_t v22 = *Type;
    unint64_t v23 = mlir::TypeID::get<mlir::ShapedType>();
    unint64_t v24 = *(unsigned int *)(v22 + 16);
    if (!v24) {
      goto LABEL_38;
    }
    uint64_t v25 = *(void **)(v22 + 8);
    unint64_t v26 = &v25[2 * v24];
    do
    {
      unint64_t v27 = v24 >> 1;
      uint64_t v28 = &v25[2 * (v24 >> 1)];
      unint64_t v30 = *v28;
      unint64_t v29 = v28 + 2;
      v24 += ~(v24 >> 1);
      if (v30 < v23) {
        uint64_t v25 = v29;
      }
      else {
        unint64_t v24 = v27;
      }
    }
    while (v24);
    if (v25 != v26 && *v25 == v23) {
      uint64_t v31 = v25[1];
    }
    else {
LABEL_38:
    }
      uint64_t v31 = 0;
    int v60 = v21;
    v61[0] = v31;
    uint64_t Shape = (uint64_t **)mlir::ShapedType::getShape((mlir::ShapedType *)&v60);
    uint64_t v59 = 3;
    if (v33 != 1
      || *Shape != (uint64_t *)v59
      || (uint64_t v49 = (uint64_t)v9,
          uint64_t v50 = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v49),
          uint64_t v51 = v34,
          uint64_t OperandRange = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&v50),
          !mlir::Type::isUnsignedInteger((mlir::Type *)&OperandRange, 64)))
    {
LABEL_55:
      unint64_t v6 = "'anec.average_pool' op attribute 'stride' failed to satisfy constraint: ui64 elements attribute of shape {3}";
      goto LABEL_57;
    }
  }
  if (v8)
  {
    if (!mlir::DenseIntElementsAttr::classof((uint64_t)v8)) {
      goto LABEL_56;
    }
    __int16 v53 = mlir::Attribute::cast<mlir::ElementsAttr>(&v52);
    uint64_t v54 = v35;
    uint64_t v59 = mlir::ElementsAttr::getType((mlir::ElementsAttr *)&v53);
    int v60 = mlir::Type::cast<mlir::ShapedType>((uint64_t **)&v59);
    v61[0] = v36;
    uint64_t v37 = (void *)mlir::ShapedType::getShape((mlir::ShapedType *)&v60);
    uint64_t OperandRange = 6;
    if (v38 != 1
      || *v37 != OperandRange
      || (uint64_t v48 = v52,
          uint64_t v50 = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v48),
          uint64_t v51 = v39,
          uint64_t v49 = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&v50),
          !mlir::Type::isUnsignedInteger((mlir::Type *)&v49, 64)))
    {
LABEL_56:
      unint64_t v6 = "'anec.average_pool' op attribute 'padding' failed to satisfy constraint: ui64 elements attribute of shape {6}";
      goto LABEL_57;
    }
  }
  if (!v7) {
    goto LABEL_53;
  }
  if (!mlir::DenseIntElementsAttr::classof((uint64_t)v7)) {
    goto LABEL_61;
  }
  __int16 v53 = mlir::Attribute::cast<mlir::ElementsAttr>(&v56);
  uint64_t v54 = v40;
  uint64_t v59 = mlir::ElementsAttr::getType((mlir::ElementsAttr *)&v53);
  int v60 = mlir::Type::cast<mlir::ShapedType>((uint64_t **)&v59);
  v61[0] = v41;
  uint64_t v42 = (void *)mlir::ShapedType::getShape((mlir::ShapedType *)&v60);
  uint64_t OperandRange = 3;
  if (v43 != 1) {
    goto LABEL_61;
  }
  if (*v42 == OperandRange
    && (uint64_t v48 = v56,
        uint64_t v50 = mlir::ArrayAttr::getValue((mlir::ArrayAttr *)&v48),
        uint64_t v51 = v44,
        uint64_t v49 = mlir::MemoryMapperInterface::getOperandRange((mlir::MemoryMapperInterface *)&v50),
        mlir::Type::isUnsignedInteger((mlir::Type *)&v49, 64)))
  {
LABEL_53:
    if (!v5 || *(_UNKNOWN **)(*(void *)v5 + 136) == &mlir::detail::TypeIDResolver<mlir::UnitAttr,void>::id) {
      return 1;
    }
    uint64_t v45 = "'anec.average_pool' op attribute 'inc_pad' failed to satisfy constraint: unit attribute";
  }
  else
  {
LABEL_61:
    uint64_t v45 = "'anec.average_pool' op attribute 'ksize' failed to satisfy constraint: ui64 elements attribute of shape {3}";
  }
  __int16 v53 = (uint64_t *)v45;
  __int16 v55 = 259;
  mlir::emitError(a2, (uint64_t)&v53, (uint64_t)&v60);
  uint64_t v46 = mlir::InFlightDiagnostic::operator mlir::LogicalResult((uint64_t)&v60);
  mlir::InFlightDiagnostic::~InFlightDiagnostic((mlir::InFlightDiagnostic *)&v60);
  return v46;
}